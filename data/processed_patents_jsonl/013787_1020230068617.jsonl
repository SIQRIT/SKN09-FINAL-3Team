{"patent_id": "10-2023-0068617", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0126787", "출원번호": "10-2023-0068617", "발명의 명칭": "오디오 분리 방법 및 이를 수행하는 전자 장치", "출원인": "삼성전자주식회사", "발명자": "엄덕준"}}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "오디오 분리 시스템을 이용하여, 하나 이상의 분리 대상 오디오 및 배경음을 포함하는 음원으로부터 상기 하나이상의 분리 대상 오디오를 분리하는 방법에 있어서,상기 음원으로부터 제1 오디오 특징을 추출하는 단계;상기 음원으로부터 배경음 특징을 추출하는 단계;상기 배경음이 조절된 제2 오디오 특징을 생성하기 위해, 상기 배경음을 제어하기 위한 배경음 제어 파라미터및 상기 배경음 특징에 기초하여, 상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오특징을 처리하는 단계;상기 분리 대상 오디오에 대응되는 타겟 정보, 상기 제1 오디오 특징, 및 상기 배경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리된 오디오를 생성하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 음원으로부터 제1 오디오 특징을 추출하는 단계는,상기 음원에 대하여 단시간 푸리에 변환(STFT, Short-Time Fourier Transform)을 수행하여 상기 음원의 스펙트로그램(spectrogram)을 생성하는 단계, 및상기 음원으로부터 상기 제1 오디오 특징을 추출하기 위해, 복수의 컨볼루션 블록을 포함하는 오디오 특징 추출모듈(210)을 이용하여 상기 음원의 스펙트로그램을 처리하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서,상기 음원으로부터 배경음 특징을 추출하는 단계는,상기 음원에 대하여 단시간 푸리에 변환(STFT, Short-Time Fourier Transform)을 수행하여 음원의 스펙트로그램(spectrogram)을 생성하는 단계, 및상기 음원으로부터 상기 배경음 특징을 추출하기 위해, 복수의 컨볼루션 블록을 포함하는 배경음 분석 모듈(220)을 이용하여 상기 음원의 스펙트로그램을 처리하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오 특징(hi)을 처리하는 단계는,상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하는 단계, 및상기 스케일링 배수를 이용하여 상기 제1 오디오 특징을 스케일링 함으로써 상기 배경음이 조절된 제2 오디오특징을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서,상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하는 단계는,공개특허 10-2024-0126787-3-상기 배경음 제어 파라미터가 1인 경우, 상기 스케일링 배수를 1로 결정하는 단계,상기 배경음 제어 파라미터가 0인 경우, 상기 배경음 특징의 크기가 클수록 상기 스케일링 배수를 더 작은 수로결정하는 단계, 및상기 배경음 제어 파라미터가 0인 경우, 상기 배경음 특징의 크기가 작을수록 상기 스케일링 배수를 더 큰 수로결정하는 단계를 포함하고,상기 스케일링 배수는 0보다 크고 1보다 작거나 같은 수인, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하는 단계는,에 의해 상기 스케일링 배수를 결정하되,f(x)는 f(0) = 1이고, x = 0을 기준으로 좌우 대칭이며, x의 크기가 커질수록 0으로 수렴하는, 배경음 제어 함수인, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 배경음 제어 함수는,인, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 분리 대상 오디오에 대응되는 타겟 정보, 상기 제1 오디오 특징, 및 상기 배경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리된 오디오를 생성하는 단계는,타겟 특징 추출 모듈(240)을 이용하여 상기 분리 대상 오디오에 대응되는 타겟 정보로부터 타겟 측징을 추출하는 단계,분리된 오디오의 스펙트로그램을 생성하기 위해, 복수의 업-컨볼루션 블록을 포함하는 오디오 생성 모듈(250)을이용하여 상기 타겟 특징, 상기 제1 오디오 특징, 및 상기 제2 오디오 특징을 처리하는 단계, 및상기 분리된 오디오의 스펙트로그램에 대하여 역 단시간 푸리에 변환(ISTFT, Inverse Short-Time FourierTransform)을 수행하여 상기 분리된 오디오를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서,상기 오디오 분리 시스템은 하나 이상의 학습용 분리 대상 오디오 및 학습용 배경음을 포함하는 학습용 음원에대하여, 상기 오디오 분리 시스템에 의해 예측된 오디오 분리 결과와 타겟 결과를 비교함으로써 학습되고,상기 학습은 복수의 배경음 파라미터에 대응하는 복수의 케이스(case)에 대하여 수행되고,각각의 케이스에 대하여 별도의 타겟 결과가 사용되는, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2024-0126787-4-제1항 내지 제9항 중 어느 한 항에 있어서,상기 음원으로부터 배경음 특징을 추출하는 단계는,상기 음원으로부터 제1 배경음 특징을 추출하는 단계, 및상기 음원으로부터 제2 배경음 특징을 추출하는 단계를 포함하고,상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오 특징을 처리하는 단계는,제1 배경음 제어 파라미터, 제2 배경음 제어 파라미터, 상기 제1 배경음 특징 및 상기 제2 배경음 특징에 기초하여 스케일링 배수를 결정하는 단계, 및상기 스케일링 배수를 이용하여 상기 제1 오디오 특징을 스케일링 함으로써 상기 배경음이 조절된 제2 오디오특징을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항에 있어서,제1 배경음 제어 파라미터, 제2 배경음 제어 파라미터, 상기 제1 배경음 특징 및 상기 제2 배경음 특징에 기초하여 스케일링 배수를 결정하는 단계는,에 의해 상기 스케일링 배수를 결정하되,f(x)는 f(0) = 1이고, x = 0을 기준으로 좌우 대칭이며, x의 크기가 커질수록 0으로 수렴하는, 배경음 제어 함수인, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항 내지 제11항 중 어느 한 항에 있어서,상기 분리 대상 오디오에 대응되는 타겟 정보는 시각적 정보 또는 상기 분리 대상 오디오와는 별개의 오디오 정보 중 어느 하나인, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항 내지 제12항 중 어느 한 항에 있어서,각각의 상기 분리 대상 오디오는 사람의 음성, 또는 악기로 연주되거나 기계음으로 만들어진 소리이고,상기 배경음은 사람의 음성, 주변 소음, 또는 배경 음악 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "하나 이상의 프로세서에 의해 실행될 때, 상기 하나 이상의 프로세서가 제1항 내지 제12항 중 어느 한 항의 방법을 수행하도록 하는 컴퓨터 프로그램이 기록된, 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "하나 이상의 프로세서(840); 및오디오 분리 시스템을 이용하여, 하나 이상의 분리 대상 오디오 및 배경음을 포함하는 음원으로부터 상기 하나이상의 분리 대상 오디오를 분리하기 위한 프로그램이 저장되는 메모리(850)를 포함하고,상기 하나 이상의 프로세서(840)는 상기 프로그램을 실행함으로써,상기 음원으로부터 제1 오디오 특징을 추출하고,상기 음원으로부터 배경음 특징을 추출하고,상기 배경음이 조절된 제2 오디오 특징을 생성하기 위해, 상기 배경음을 제어하기 위한 배경음 제어 파라미터및 상기 배경음 특징에 기초하여, 상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오공개특허 10-2024-0126787-5-특징을 처리하고,상기 분리 대상 오디오에 대응되는 타겟 정보, 상기 제1 오디오 특징, 및 상기 배경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리된 오디오를 생성하는, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 하나 이상의 프로세서(840)가 상기 음원으로부터 제1 오디오 특징을 추출하는 것은,상기 음원에 대하여 단시간 푸리에 변환(STFT, Short-Time Fourier Transform)을 수행하여 상기 음원의 스펙트로그램(spectrogram)을 생성하고,상기 음원으로부터 상기 제1 오디오 특징을 추출하기 위해, 복수의 컨볼루션 블록을 포함하는 오디오 특징 추출모듈(210)을 이용하여 상기 음원의 스펙트로그램을 처리하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항 또는 제16항에 있어서,상기 하나 이상의 프로세서(840)가 상기 음원으로부터 배경음 특징을 추출하는 것은,상기 음원에 대하여 단시간 푸리에 변환(STFT, Short-Time Fourier Transform)을 수행하여 음원의 스펙트로그램(spectrogram)을 생성하고,상기 음원으로부터 상기 배경음 특징을 추출하기 위해, 복수의 컨볼루션 블록을 포함하는 배경음 분석 모듈(220)을 이용하여 상기 음원의 스펙트로그램을 처리하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항 내지 제17항 중 어느 한 항에 있어서,상기 하나의 이상의 프로세서(840)가 상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오 특징을 처리하는 것은,상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하고,상기 스케일링 배수를 이용하여 상기 제1 오디오 특징을 스케일링 함으로써 상기 배경음이 조절된 제2 오디오특징을 생성하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항 내지 제18항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서(840)가 상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하는 것은,상기 배경음 제어 파라미터가 1인 경우, 상기 스케일링 배수를 1로 결정하고,상기 배경음 제어 파라미터가 0인 경우, 상기 배경음 특징의 크기가 클수록 상기 스케일링 배수를 더 작은 수로결정하고,상기 배경음 제어 파라미터가 0인 경우, 상기 배경음 특징의 크기가 작을수록 상기 스케일링 배수를 더 큰 수로결정하는 것을 포함하고,상기 스케일링 배수는 0보다 크고 1보다 작거나 같은 수인, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항 내지 제19항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서(840)가 상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하는 것은,공개특허 10-2024-0126787-6-에 의해 상기 스케일링 배수를 결정하되,f(x)는 f(0) = 1이고, x = 0을 기준으로 좌우 대칭이며, x의 크기가 커질수록 0으로 수렴하는, 배경음 제어 함수인, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제15항 내지 제20항 중 어느 한 항에 있어서,상기 배경음 제어 함수는,인, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제15항 내지 제21항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서(840)가 상기 분리 대상 오디오에 대응되는 타겟 정보, 상기 제1 오디오 특징, 및 상기 배경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리된 오디오를 생성하는 것은,타겟 특징 추출 모듈(240)을 이용하여 상기 분리 대상 오디오에 대응되는 타겟 정보로부터 타겟 측징을 추출하고,분리된 오디오의 스펙트로그램을 생성하기 위해, 복수의 업-컨볼루션 블록을 포함하는 오디오 생성 모듈(250)을이용하여 상기 타겟 특징, 상기 제1 오디오 특징, 및 상기 제2 오디오 특징을 처리하고,상기 분리된 오디오의 스펙트로그램에 대하여 역 단시간 푸리에 변환(ISTFT, Inverse Short-Time FourierTransform)을 수행하여 상기 분리된 오디오를 생성하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제15항 내지 제22항 중 어느 한 항에 있어서,상기 오디오 분리 시스템은 하나 이상의 학습용 분리 대상 오디오 및 학습용 배경음을 포함하는 학습용 음원에대하여, 상기 오디오 분리 시스템에 의해 예측된 오디오 분리 결과와 타겟 결과를 비교함으로써 학습되고,상기 학습은 복수의 배경음 파라미터에 대응하는 복수의 케이스(case)에 대하여 수행되고,각각의 케이스에 대하여 별도의 타겟 결과가 사용되는, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제15항 내지 제23항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서(840)가 상기 음원으로부터 배경음 특징을 추출하는 것은,상기 음원으로부터 제1 배경음 특징을 추출하고,상기 음원으로부터 제2 배경음 특징을 추출하는 것을 포함하고,상기 하나 이상의 프로세서(840)가 상기 제1 오디오 특징(hi)이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오 특징(hi)을 처리하는 것은,제1 배경음 제어 파라미터, 제2 배경음 제어 파라미터, 상기 제1 배경음 특징 및 상기 제2 배경음 특징에 기초하여 스케일링 배수를 결정하고,상기 스케일링 배수를 이용하여 상기 제1 오디오 특징을 스케일링 함으로써 상기 배경음이 조절된 제2 오디오공개특허 10-2024-0126787-7-특징을 생성하는 것을 포함하는, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제15항 내지 제24항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서(840)가 제1 배경음 제어 파라미터, 제2 배경음 제어 파라미터, 상기 제1 배경음 특징 및 상기 제2 배경음 특징에 기초하여 스케일링 배수를 결정하는 것은,에 의해 상기 스케일링 배수를 결정하되,f(x)는 f(0) = 1이고, x = 0을 기준으로 좌우 대칭이며, x의 크기가 커질수록 0으로 수렴하는, 배경음 제어 함수인, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제15항 내지 제25항 중 어느 한 항에 있어서,상기 분리 대상 오디오에 대응되는 타겟 정보는 시각적 정보 또는 상기 분리 대상 오디오와는 별개의 오디오 정보 중 어느 하나인, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제15항 내지 제26항 중 어느 한 항에 있어서,각각의 상기 분리 대상 오디오는 사람의 음성, 또는 악기로 연주되거나 기계음으로 만들어진 소리이고,상기 배경음은 사람의 음성, 주변 소음, 또는 배경 음악 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에서, 오디오 분리 시스템을 이용하여, 하나 이상의 분리 대상 오디오 및 배경음을 포함하는 음원으로 부터 상기 하나 이상의 분리 대상 오디오를 분리하는 방법은, 상기 음원으로부터 제1 오디오 특징을 추출하는 단 계, 상기 음원으로부터 배경음 특징을 추출하는 단계, 배경음이 조절된 제2 오디오 특징을 생성하기 위해, 상기 배경음을 제어하기 위한 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여, 상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오 특징을 처리하는 단계, 및 상기 분리 대상 오디오에 대응되는 타 겟 정보, 상기 제1 오디오 특징, 및 상기 배경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리된 오디 오를 생성하는 단계를 포함한다."}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 하나 이상의 분리 대상 오디오 및 배경음을 포함하는 음원으로부터 하나 이상의 분리 대상 오디오를 분리하는 방법 및 이를 수행하는 장치에 관한 것이다."}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "오디오 분리 기술은 하나 이상의 분리 대상 오디오를 포함하는 음원으로부터 각각의 분리 대상 오디오를 분리하 는 것이다. 예를 들어, 컨볼루션 블록(convolution block)을 이용하여 음원으로부터 오디오 특징을 추출하고, 업-컨볼루션 블록(up-convolution block)을 이용하여 오디오 특징으로부터 각각의 분리 대상 오디오에 대응하는 스펙트로그램을 생성한 후 최종적으로 분리된 오디오를 얻는 것이 일반적이다. 이때 각각의 분리 대상 오디오에 대응되는 타겟 정보가 요구되는데, 일반적으로 시각적 정보(예: 분리 대상 음성에 대응되는 화자의 얼굴의 전부 또는 일부가 포함된 이미지) 또는 오디오 정보(예: 분리 대상 음성에 대응되는 화자의 미리 녹음된 음성)가 타 겟 정보로서 사용된다. 종래의 오디오 분리 기술들은 음원에 포함된 배경음을 고려하지 않고 분리 대상 오디오의 특징을 추출하는 것에 만 집중하기 때문에 분리된 오디오에 배경음이 포함되는 문제점이 있다. 이 경우 분리된 오디오에서 배경음을 조절(예: 배경음의 볼륨을 줄이거나 배경음을 제거)하기 위해서는 배경음 특징을 추출하기 위한 별도의 모델이 필요하다. 그러나 음원으로부터 분리 대상 오디오를 분리한 후 분리된 오디오에서 배경음을 제거하는 과정에서 두 번의 추론(inference)이 수행되기 때문에 최종 분리 완료된 오디오에 인공적인 소리(artifact)가 많이 섞이 게 되고, 듣기에 어색한 오디오가 생성될 수 있다."}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른, 오디오 분리 시스템을 이용하여, 하나 이상의 분리 대상 오디오 및 배경음을 포함 하는 음원으로부터 상기 하나 이상의 분리 대상 오디오를 분리하는 방법은 상기 음원으로부터 제1 오디오 특징 을 추출하는 단계를 포함할 수 있다. 일 실시예에서, 상기 방법은, 상기 음원으로부터 배경음 특징을 추출하는 단계를 포함할 수 있다. 일 실시예에서, 상기 방법은, 상기 배경음이 조절된 제2 오디오 특징을 생성하기 위해, 상기 배경음을 제어하기 위한 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여, 상기 제1 오디오 특징이 상기 배경음과 연관된 정 도에 따라 상기 제1 오디오 특징을 처리하는 단계를 포함할 수 있다. 일 실시예에서, 상기 방법은, 상기 분리 대상 오디오에 대응되는 타겟 정보, 상기 제1 오디오 특징, 및 상기 배 경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리된 오디오를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른, 전자 장치는 하나 이상의 프로세서, 및 오디오 분리 시스템을 이용하여, 하나 이 상의 분리 대상 오디오 및 배경음을 포함하는 음원으로부터 상기 하나 이상의 분리 대상 오디오를 분리하기 위 한 프로그램이 저장되는 메모리를 포함한다. 일 실시예에서, 상기 하나 이상의 프로세서는 상기 프로그램을 실행함으로써, 상기 음원으로부터 제1 오디오 특 징을 추출할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서는 상기 프로그램을 실행함으로써, 상기 음원으로부터 배경음 특징을 추출할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서는 상기 프로그램을 실행함으로써, 상기 배경음이 조절된 제2 오디오 특징을 생성하기 위해, 상기 배경음을 제어하기 위한 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여, 상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오 특징을 처리할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서는 상기 프로그램을 실행함으로써, 상기 분리 대상 오디오에 대응되 는 타겟 정보, 상기 제1 오디오 특징, 및 상기 배경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리 된 오디오를 생성할 수 있다."}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, “a, b 및 c 중 적어도 하나”의 표현은 “a”, “b”, “c”, “a 및 b”, “a 및 c”, “b 및 c ”, “a, b 및 c 모두”, 또는 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 실시예에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는 데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 실시예의 권리범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 “연결되어” 있다거나 “접속되어” 있다고 언급된 때에는 그 다른 구성요소 에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 “직접 연결되어” 있다거나 “직접 접속되어 ” 있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인"}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술분야에서 통상의 지식을 가진 자에 의해 일 반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시에서, “포함하다” 또는 “가지다” 등의 용어는 본 개시에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 개시에서 ‘~부(유닛)’, ‘모듈’ 등으로 표현되는 구성요소는 2개 이상의 구성요소가 하나의 구성요소로 합쳐지거나 또는 하나의 구성요소가 보다 세분화된 기능별로 2개 이상으로 분화될 수도 있다. 또한 이하에서 설 명할 구성요소 각각은 자신이 담당하는 주기능 이외에도 다른 구성요소가 담당하는 기능 중 일부 또는 전부의 기능을 추가적으로 수행할 수도 있으며, 구성요소 각각이 담당하는 주기능 중 일부 기능이 다른 구성요소에 의 해 전담되어 수행될 수도 있음은 물론이다. 본 개시에서, 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프 로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지 능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지 능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로 세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특정(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공신경망은 심층신경망(DNN: Deep Neural Network)을 포함할 수 있으며, 예를 들어, CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 DQN(Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시에서, 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이하에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 본 개시에서 배경음(background sound)은 음원에 포함된 복수의 오디오 중에서 분리 대상 오디오를 제외한 나머 지 오디오로 이해될 수 있다. 예를 들어, 특정 화자 두 명의 음성을 포함하는 음원에서 각 화자의 음성이 분리 대상 오디오인 경우, 배경음은 화자의 주변에 있는 다른 사람들의 음성(voice), 자동차 경적 소리 또는 군중의 함성 소리와 같은 주변 환경에서 발생하는 주변 소음(ambient noise), 또는 두 명의 화자가 등장하는 장면의 분 위기를 형성하기 위한 배경 음악(background music) 등일 수 있다 분리 대상 오디오와 배경음은 소리의 유형에 의해 구별되는 것이 아님에 유의해야 한다. 즉, 분리 대상 오디오 와 배경음은 동일한 유형의 소리일 수도 있고, 다른 유형의 소리일 수도 있다. 일 예로서, 분리 대상 오디오는 특정 화자의 음성이고, 배경음은 그 특정 화자의 주변에 있는 다른 사람의 음성일 수 있다. 다른 예로서, 분리 대상 오디오는 가수의 보컬이고, 배경음은 가수가 부르는 노래의 반주일 수 있다. 도 1은 본 개시의 일 실시예에 따른 오디오 분리 방법이 적용될 수 있는 상황을 설명하기 위한 도면이다. 도 1의 화면에서는 전쟁 영화가 재생되고 있으며, 두 명의 인물(11, 12)이 전쟁터에서 대화를 나누는 장면이 표 시되고 있다. 해당 장면에서는 제1 인물과 제2 인물의 음성뿐만 아니라, 주변의 부상당한 다른 인물의 고통스러운 신음, 총 소리, 주변에서 폭탄이 터지는 것을 나타내는 효과음, 또는 해당 장면의 분위기를 고조시 키기 위한 음악 등의 배경음이 함께 출력될 것이다. 이러한 배경음의 볼륨이 제1 인물과 제2 인물의 음 성의 볼륨보다 훨씬 크다면, 시청자는 제1 인물과 제2 인물 간의 대화 내용을 완전히 이해하기 어려울 것이다. 도 1에 도시된 것과 같이, 제1 인물의 음성의 볼륨, 제2 인물의 음성의 볼륨, 및 배경음의 볼 륨을 별도로 조절할 수 있다면, 시청자는 해당 장면에서 배경음의 볼륨을 낮춤으로써 제1 인물과 제2 인물 간의 대화 내용을 더 잘 이해할 수 있을 것이다. 이를 위해서는 다양한 오디오가 섞인 음원에서 제1 인물의 음성과 제2 인물의 음성을 분리하되, 분리된 각 인물의 음성에 포함되는 배경음의 크기(즉, 볼 륨)를 조절할 수 있어야 한다. 이하에서는 하나 이상의 분리 대상 오디오 및 배경음을 포함하는 음원으로부터 상기 하나 이상의 분리 대상 오 디오를 분리하되, 분리된 오디오에 포함되는 배경음의 크기를 조절할 수 있는 방법에 대해서 자세히 설명한다. 도 2는 본 개시의 일 실시예에 따른 오디오 분리 시스템을 도시한다. 일 실시예에서, 오디오 분리 시스템은 하나 이상의 분리 대상 오디오(Audio#1, …, Audio#N) 및 배경음을 포함하는 음원, 각각의 분리 대상 오디오에 대응되는 타겟 정보, 및 배경음을 제어하기 위한 배경음 제어 파라미터(α)를 입력으로 하여, 배경음 제어 파라미터(α)에 따라 배경음의 크기(즉, 볼륨)가 조절된 분리된 오디오(204, 205)를 출력할 수 있다. 오디오 분리 시스템은 학습 데이터를 이용하여 학습된 인공지능 모델일 수 있다. 분리 대상 오디오의 유형은 다양하게 결정될 수 있다. 일 실시예에서, 분리 대상 오디오는 사람의 음성일 수 있 다. 예를 들어, 분리 대상 오디오는 화자의 연설, 가수의 보컬 등일 수 있다. 일 실시예에서, 분리 대상 오디오는 악기로 연주되거나 기계음으로 만들어진 소리일 수 있다. 예를 들어, 분리 대상 오디오는 오케스트라가 연주 한 음악 중 피아노 연주 부분, 가수가 부르는 노래의 반주 등일 수 있다. 학습 데이터의 유형에 따라, 분리 대상 오디오가 복수 개인 경우 각각의 분리 대상 오디오의 유형은 동일할 수 도 있고, 상이할 수도 있다. 일 실시예에서, 오디오 분리 시스템은 음원으로부터 동일한 유형의 복수 의 분리 대상 오디오를 분리할 수 있다. 예를 들어, 오디오 분리 시스템은 두 명의 화자의 대화로부터 각 각의 화자의 음성을 분리할 수 있다. 일 실시예에서, 오디오 분리 시스템은 음원으로부터 상이한 유 형의 복수의 분리 대상 오디오를 분리할 수 있다. 예를 들어, 오디오 분리 시스템은 가수가 부른 노래로부 터 가수의 보컬 및 노래의 반주를 분리할 수 있다. 오디오 분리 시스템의 학습 과정에 관하여는 도 4를 참 조하여 후술한다. 배경음의 유형은 다양하게 결정될 수 있다. 일 실시예에서, 배경음의 유형은 분리 대상 오디오의 유형과 동일할 수 있다. 예를 들어, 분리 대상 오디오가 사람의 음성인 경우, 배경음은 분리 대상 오디오에 대응되는 화자가 아닌 다른 화자의 음성일 수 있다. 일 실시예에서, 배경음의 유형은 분리 대상 오디오의 유형과 상이할 수 있다. 예를 들어, 분리 대상 오디오가 사람의 음성인 경우, 배경음은 자동차 경적 소리와 같은 분리 대상 오디 오에 대응되는 화자의 주변에서 발생한 소음일 수 있다. 분리 대상 오디오에 대응되는 타겟 정보는 음원에 포함된 복수의 오디오 중 오디오 분리 시스템(20 0)이 어떤 오디오를 분리해야 하는지를 지정하기 위한 추가 정보로 이해될 수 있다. 일 실시예에서, 타겟 정보 는 시각적 정보일 수 있다. 예를 들어, 분리 대상 오디오가 사람의 음성인 경우, 타겟 정보는 대응되 는 화자의 얼굴의 전부 또는 일부(예: 입 주변부)가 포함된 이미지일 수 있다. 일 실시예에서, 타겟 정보 는, 분리 대상 오디오와는 별개의, 오디오 정보일 수 있다. 일 예로서, 분리 대상 오디오가 사람의 음성인 경우, 타겟 정보는 대응되는 화자의 미리 녹음된 음성일 수 있다. 다른 예로서, 분리 대상 오디오가 피아 노 연주음인 경우, 타겟 정보는 미리 녹음된 피아노 연주음일 수 있다. 분리 대상 오디오에 대응되는 타겟 정보는 분리 대상 오디오 및 원본 데이터에 따라 결정될 수 있다. 일 예로서, 오디오와 이미지를 포함하는 동영상에서 동영상에 등장하는 두 명의 화자의 음성을 분리하는 경우, 타 겟 화자가 포함된 이미지가 타겟 정보로서 사용될 수 있다. 다른 예로서, 오디오와 이미지를 포함하는 동 영상에서 동영상에 등장하는 화자와 동영상에 등장하지 않는 다른 화자의 음성을 분리하는 경우, 동영상에 등장 하는 화자가 포함된 이미지 및 동영상에 등장하지 않는 화자의 미리 녹음된 음성이 각각 타겟 정보로서 사 용될 수 있다. 배경음 제어 파라미터(α)는 분리된 음원에 포함될 배경음의 볼륨을 결정하기 위한 파라미터이다. 배 경음 제어 파라미터(α)는 사용자에 의해 결정될 수 있다. 예를 들어, 배경음 제어 파라미터(α)는 도 1에 도시된 것과 같이 사용자가 배경음의 볼륨을 조절하는 것에 의해 결정될 수 있다. 일 실시예에서, 배경 음 제어 파라미터(α)는 0 이상 1 이하의 실수일 수 있다. 예를 들어, 오디오 분리 시스템은 배경음 제어 파라미터(α)가 0인 경우 배경음이 제거된 분리된 오디오를 출력할 수 있고, 배경음 제어 파라 미터(α)가 1인 경우 배경음을 그대로 포함하는 분리된 오디오를 출력할 수 있다. 다시 말하면, 오디 오 분리 시스템은 배경음 제어 파라미터(α)가 0에 가까울수록 배경음을 많이 제거할 수 있고, 배경 음 제어 파라미터(α)가 1에 가까울수록 배경음을 적게 제거할 수 있다. 일 실시예에서, 오디오 분리 시스템은 음원에 대하여 단시간 푸리에 변환(STFT, Short-Time Fourier Transform)을 수행하여 음원의 스펙트로그램(spectrogram)을 생성할 수 있다. 스펙트로그램은 음원을 시각화한 이미지로서, 시간-주파수 도메인에서 시간과 주파수의 변화에 따른 진폭의 차이를 각 픽셀의 색상 또 는 농도의 차이로 나타낸다. 일 실시예에서, 오디오 분리 시스템은 오디오 특징 추출 모듈을 이용하여 음원의 스펙트로그램 을 처리함으로써, 음원으로부터 제1 오디오 특징(hi)을 추출할 수 있다. 일 실시예에서, 오디오 특징 추출 모듈은 복수의 컨볼루션 블록을 포함하도록 구현될 수 있으며, 각각의 컨볼루션 블록은 하나 이상의 컨볼 루션 레이어, 배치 정규화(batch normalization), 및 활성화 함수(예: ReLu, Sigmoid 등)를 포함할 수 있다. 오디오 특징 추출 모듈 내부에서, 하나의 컨볼루션 블록에서 추출된 특징이 다음 컨볼루션 블록으로 전달 되면서 각각의 컨볼루션 블록에서 제1 오디오 특징(hi)이 추출될 수 있다. 여기서, i는 자연수이고, hi는 i 번째 컨볼루션 블록에서 추출된 제1 오디오 특징이다. 예를 들어, 도 2에 도시된 바와 같이, 오디오 특징 추출 모듈 이 8개의 컨볼루션 블록을 포함하는 경우, 각각의 컨볼루션 블록은 대응되는 제1 오디오 특징(즉, h1, h2,…, h8)을 추출할 수 있다. 일 실시예에서, 오디오 분리 시스템은 배경음 분석 모듈을 이용하여 음원의 스펙트로그램을 처 리함으로써, 음원으로부터 배경음 특징(hic)을 추출할 수 있다. 일 실시예에서, 배경음 분석 모듈은 복수의 컨볼루션 블록을 포함하도록 구현될 수 있으며, 각각의 컨볼루션 블록은 하나 이상의 컨볼루션 레이어, 배치 정규화(batch normalization), 및 활성화 함수(예: ReLu, Sigmoid 등)를 포함할 수 있다. 일 실시예에서, 배경음 분석 모듈은 오디오 특징 추출 모듈과 동일한 구조로 구현될 수 있다. 배경음 분석 모듈 내부에서 하나의 컨볼루션 블록에서 추출된 특징이 다음 컨볼루션 블록으로 전달되면서 각각의 컨볼루션 블록에 서 배경음 특징(hic)이 추출될 수 있다. 여기서, i는 자연수이고, hic는 i 번째 컨볼루션 블록에서 추출된 배경 음 특징이다. 예를 들어, 도 2에 도시된 바와 같이, 배경음 분석 모듈이 8개의 컨볼루션 블록을 포함하는 경우, 각각의 컨볼루션 블록은 대응되는 배경음 특징(즉, h1c, h2c, …, h8c)을 추출할 수 있다. 배경음 특징(hic)은 실수 전체 범위의 값을 가질 수 있으며, 대응하는 제1 오디오 특징(hi)이 배경음과 연관된 정도를 나타내는 것으로 이해될 수 있다. 즉, 배경음 특징(hic)의 크기가 클수록 대응하는 제1 오디오 특징(hi) 이 배경음을 생성하는데 많은 기여를 한다고 이해될 수 있으며, 배경음 특징(hic)의 크기가 작을수록 대응하는 제1 오디오 특징(hi)이 배경음을 생성하는데 적은 기여를 한다고 이해될 수 있다. 일 실시예에서, 오디오 분리 시스템은 배경음 특징 제어 모듈을 이용하여 제1 오디오 특징(hi)을 처 리함으로써, 배경음이 조절된 제2 오디오 특징(hi')을 생성할 수 있다. 배경음 특징 제어 모듈의 동작에 관하여는 도 3을 참조하여 후술한다. 일 실시예에서, 오디오 분리 시스템은 타겟 특징 추출 모듈을 이용하여 타겟 정보를 처리함으로 써, 타겟 정보로부터 타겟 특징을 추출할 수 있다. 타겟 특징 추출 모듈은 타겟 정보를 처리하 기 적합한 형태로 구현될 수 있다. 일 예로서, 타겟 정보가 시각적 정보인 경우, 타겟 특징 추출 모듈 은 시각적 정보로부터 시각적 특징을 추출할 수 있는 시각적 특징 네트워크(visual feature network)(예: 컨볼루션 신경망)일 수 있다. 다른 예로서, 타겟 정보가 오디오 정보인 경우, 타겟 특징 추출 모듈은 오디오 정보로부터 오디오 임베딩을 생성할 수 있는 보이스 임베딩 네트워크(voice embedding network)(예: 컨 볼루션 신경망)일 수 있다. 일 실시예에서, 오디오 분리 시스템은 오디오 생성 모듈을 이용하여 제1 오디오 특징, 제2 오디오 특 징, 및 타겟 특징을 처리함으로써 분리된 오디오의 스펙트로그램을 생성할 수 있다. 일 실시예에서, 오디오 생 성 모듈은 복수의 업-컨볼루션 블록을 포함하도록 구현될 수 있으며, 각각의 업-컨볼루션 블록은 하나 이 상의 전치(transposed) 컨볼루션 레이어, 결합(concatenation), 및 컨볼루션 블록을 포함할 수 있다. 오디오 생 성 모듈 내부에서 하나의 업-컨볼루션 블록에서 생성된 특징이 다음 업-컨볼루션 블록으로 전달되면서 분 리된 오디오의 스펙트로그램이 생성될 수 있다. 각각의 업-컨볼루션 블록은 이전의 업-컨볼루션 블록에서 생성 된 특징 및 제2 오디오 특징(hi')을 처리함으로써 다음 업-컨볼루션 블록으로 전달할 특징을 생성한다. 이때, j 번째 업-컨볼루션 블록은 j-1 번째 업-컨볼루션 블록에서 생성된 특징, 및 대응되는 컨볼루션 블록(예: 컨볼루 션 블록 및 업-컨볼루션 블록의 개수가 각각 n인 경우, n-j+1 번째 컨볼루션 블록)에서 추출된 제1 오디오 특징 (hi)을 처리함으로써 생성된 제2 오디오 특징(hi')을 이용하여 다음 업-컨볼루션 블록에 전달할 특징을 생성한다. 첫 번째 업-컨볼루션 블록은 마지막 컨볼루션 블록에서 추출된 제1 오디오 특징(hi) 및 타겟 특징을 결합(concatenation)한 특징, 및 마지막 컨볼루션 블록에서 추출된 제1 오디오 특징을 처리함으로써 생성된 제2 오디오 특징을 이용하여 두 번째 업-컨볼루션 블록에 전달할 특징을 생성한다. 제2 오디오 특징(hi')은 대응되는 컨볼루션 블록에서 생성된 제1 오디오 특징(hi)으로부터 생성된 것이며, 대응 되는 업-컨볼루션 블록에 전달되므로 일종의 스킵-연결(skip-connection)로 이해될 수 있다. 다시 말하면, 오디 오 분리 시스템은 배경음 분석 모듈 및 배경음 특징 제어 모듈을 통해 컨볼루션 블록에서 업-컨 볼루션 블록으로 직접 전달되는 특징의 크기를 조절함으로써 분리된 오디오에 포함된 배경음의 크기를 조절할 수 있다. 일 실시예에서, 오디오 분리 시스템은 분리된 오디오의 스펙트로그램에 대하여 역 단시간 푸리에 변환 (ISTFT, Inverse Short-Time Fourier Transform)을 수행하여 분리된 오디오를 생성할 수 있다. 도 3a는 본 개시의 일 실시예에 따른 배경음 특징 제어 모듈의 동작을 설명하기 위한 도면이고, 도 3b는 배경음 제어 함수의 일 예를 나타낸다. 도 3a에 도시된 바와 같이, 일 실시예에서, 배경음 특징 제어 모듈은 배경음 제어 파라미터(α) 및 배경음 특징(hic)에 기초하여, 제1 오디오 특징(hi)이 배경음과 연관된 정도에 따라 제1 오디오 특징(hi)을 스케 일링 함으로써 배경음이 조절된 제2 오디오 특징(hi')을 생성할 수 있다. 여기서, 제1 오디오 특징(hi)이 배경음 과 연관된 정도는 오디오 생성 모듈에 의해 분리된 오디오가 생성될 때 분리된 오디오에 포함될 배경음에 대한 제1 오디오 특징(hi)의 기여도로 이해될 수 있다. 예를 들어, 배경음 제어 파라미터(α)가 1인 경우, 사용자가 배경음을 조절하기를 원하지 않는 것이므로, 제1 오디오 특징(hi)이 그대로 업-컨볼루션 블록에 전달되도록, 배경음 특징 제어 모듈은 제1 오디오 특징 (hi)을 스케일링 하지 않을 수 있다. 다시 말하면, 배경음 특징 제어 모듈은 제1 오디오 특징(hi)을 1배로 스케일링 할 수 있다. 예를 들어, 배경음 제어 파라미터(α)가 0인 경우, 사용자가 배경음을 제거하기를 원하는 것이므로, 배경 음을 생성하는데 많은 기여를 하는 제1 오디오 특징(hi)은 크기가 감소되어 업-컨볼루션 블록에 전달되도록, 배 경음 특징 제어 모듈은 배경음 특징(hic)의 크기가 클수록 대응되는 제1 오디오 특징(hi)을 더 작은 배수로 스케일링 할 수 있다. 다시 말하면, 배경음 특징(hic)의 크기가 클수록 스케일링 배수는 0에 가까워질 수 있다. 예를 들어, 배경음 제어 파라미터(α)가 0인 경우, 사용자가 배경음을 제거하기를 원하는 것이므로, 배경 음을 생성하는데 적은 기여를 하는 제1 오디오 특징(hi)은 최대한 온전하게 업-컨볼루션 블록에 전달되도록, 배 경음 특징 제어 모듈은 배경음 특징(hic)의 크기가 작을수록 대응되는 제1 오디오 특징(hi)을 더 큰 배수로 스케일링 할 수 있다. 다시 말하면, 배경음 특징(hic)의 크기가 작을수록 스케일링 배수는 1에 가까워질 수 있다. 일 실시예에서, 배경음 특징 제어 모듈은 수학식 1에 의해 제1 오디오 특징(hi)을 스케일링 함으로써 배경 음이 조절된 제2 오디오 특징(hi')을 생성할 수 있다. 수학식 1"}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, hi는 제1 오디오 특징이고, hic는 배경음 특징이고, hi'은 제2 오디오 특징이고, α는 배경음 제어 파라 미터이고, f(x)는 배경음 제어 함수이다. 도 3b에 도시된 바와 같이, 일 실시예에서, 배경음 제어 함수(f(x))는 f = 1이고, x = 0을 기준으로 좌우 대 칭이며(즉, y축 대칭), x의 크기(즉, |x|)가 커질수록 0으로 수렴하는 임의의 함수일 수 있다. 예를 들어, 배경 음 제어 함수(f(x))는 수학식 2의 함수일 수 있다. 수학식 2 배경음 제어 파라미터(α)가 1인 경우, hi' = f×hi = hi 가 되어, 배경음 특징 제어 모듈은 제1 오디오 특징(hi)을 스케일링 하지 않는다. 다시 말하면, 배경음 특징 제어 모듈은 제1 오디오 특징(hi)을 1 배로 스케일링 한다. 배경음 제어 파라미터(α)가 0에 가까운 경우, |hic|가 충분히 크면 f(hic×(1-α))가 0으로 수렴하므로, 배경음 특징 제어 모듈은 크기가 큰 배경음 특징(hic)에 대응되는 제1 오디오 특징(hi)을 0에 가까운 배수 로 스케일링 한다. |hic|가 충분히 작은 경우, 배경음 제어 파라미터(α)가 0에 가까워지더라도 f(hic×(1-α))가 1에 수렴하 므로, 배경음 특징 제어 모듈은 크기가 작은 배경음 특징(hic)에 대응되는 제1 오디오 특징(hi)을 1에 가까 운 배수로 스케일링 한다. 도 4는 본 개시의 일 실시예에 따른 오디오 분리 시스템의 학습 방법을 설명하기 위한 도면이다. 일 실시예에서, 오디오 분리 시스템의 학습은, 학습용 음원에 대하여, 오디오 분리 시스템에 의 해 예측된 오디오 분리 결과와 타겟 결과를 비교함으로써 수행될 수 있다. 여기서, 학습은 오디오 분 리 시스템에 포함된 오디오 특징 추출 모듈, 배경음 분석 모듈, 배경음 특징 제어 모듈, 및 오디오 생성 모듈 내의 가중치들을 업데이트하는 것으로 이해될 수 있다. 예측된 오디오 분리 결과 와 타겟 결과를 비교할 때 소정의 손실 함수(예: 평균 제곱 오차(mean squared error), 교차 엔트로 피 오차(cross entropy error) 등)가 사용될 수 있다. 일 실시예에서, 학습용 음원은 하나 이상의 학습용 분리 대상 오디오를 포함할 수 있다. 일 실시예에서, 학습용 분리 대상 오디오는 오디오 분리 시스템의 목적에 따라 결정될 수 있다. 일 예로서, 도 1에 도시된 바와 같이, 영화에서 각 등장 인물의 음성과 배경음의 볼륨을 조절할 수 있도록 하기 위 해 각 등장 인물의 음성을 분리하고자 하는 경우, 학습용 분리 대상 오디오는 사람의 음성으로 결정될 수 있다. 다른 예로서, 관객의 함성 소리가 포함된 가수의 라이브 공연 영상에서 가수의 보컬과 가수가 부르는 노래의 반 주를 분리하고자 하는 경우, 학습용 분리 대상 오디오는 사람의 음성과 악기로 연주한 소리로 결정될 수 있다. 일 실시예에서, 학습용 음원은 학습용 배경음을 포함할 수 있다. 일 실시예에서, 학습용 배경음은 오디오 분리 시스템의 목적에 따라 결정될 수 있다. 예를 들어, 가수의 라이브 공연 영상에서 가수의 보컬을 분리하고자 하는 경우, 학습용 배경음은 악기로 연주한 소리로 결정될 수 있다. 일 실시예에서, 학습용 배경음은 임의의 잡음일 수 있다. 예를 들어, 학습용 배경음은 백색 잡음(white noise) 일 수 있다. 일 실시예에서, 학습용 음원은 하나 이상의 학습용 분리 대상 오디오와 학습용 배경음을 소정의 볼륨 비율 로 혼합함으로써 생성될 수 있다. 예를 들어, 학습용 음원은 두 명의 화자의 음성과 백색 잡음을 2:1의 볼 륨 비율로 혼합한 음원일 수 있다. 일 실시예에서, 학습용 타겟 정보는 학습용 분리 대상 오디오에 대응되도록 결정될 수 있다. 일 예로서, 학습용 분리 대상 오디오가 사람의 음성인 경우, 학습용 타겟 정보는 대응되는 화자의 대응되는 화자의 얼 굴의 전부 또는 일부(예: 입 주변부)가 포함된 이미지 또는 대응되는 화자의 미리 녹음된 음성일 수 있다. 다른 예로서, 학습용 분리 대상 오디오가 악기로 연주한 소리인 경우, 학습용 타겟 정보는 미리 녹음된, 대응되 는 악기가 연주한 소리일 수 있다. 일 실시예에서, 오디오 분리 시스템은 복수의 배경음 파라미터(α)에 대응하는 복수의 케이스(case) 에 대하여 학습될 수 있다. 이때, 각각의 케이스에 대해 별도의 타겟 결과가 사용될 수 있다. 예를 들어, 도 4 에 도시된 바와 같이, 오디오 분리 시스템은 배경음 파라미터(α)가 0인 제1 케이스, 배경음 파라미 터(α)가 0.5인 제2 케이스, 및 배경음 파라미터(α)가 1인 제3 케이스에 대하여 학습될 수 있다. 이 때 제1 케이스에 대한 타겟 결과는 배경음이 제거된 학습용 분리 대상 오디오( )일 수 있고, 제2 케이스에대한 타겟 결과는 배경음이 제거된 학습용 분리 대상 오디오( )와 배경음이 포함된 학습용 분리 대상 오디오 (x)의 평균( )일 수 있고, 제3 케이스에 대한 타겟 결과는 배경음이 포함된 학습용 분리 대상 오디오 (x)일 수 있다. 일 실시예에서, 학습용 음원은 하나 이상 분리 대상 오디오를 포함하는 원본 오디오에 임의의 잡음을 혼합 함으로써 생성될 수 있고, 타겟 결과는 별도의 잡음 제거 모델을 이용하여 학습용 음원에서 잡음을 제거함으로써 생성될 수 있다. 예를 들어, 잡음 제거 모델은 인공지능 모델일 수 있다. 도 5는 본 개시의 일 실시예에 따른 오디오 분리 시스템을 도시하고, 도 6은 본 개시의 일 실시예에 따른 배경음 특징 제어 모듈의 동작을 설명하기 위한 도면이다. 복수의 오디오를 포함하는 음원으로부터 하나 이상의 오디오를 분리함에 있어서, 분리 대상 오디오와 배경 음은 오디오 분리 시스템의 설계(예: 네트워크 구조, 분리 대상 오디오, 타겟 정보의 설정 등)와 학습 방법(예: 학습용 분리 대상 오디오, 학습용 배경음, 타겟 결과의 설정 등)에 따라 결정될 수 있다. 또한 배경음도 오디오 분리 시스템의 설계와 학습 방법에 따라 둘 이상으로 구별될 수 있다. 예를 들어, 가수의 보컬, 노래의 반주 및 주변 소음(예: 관객의 함성 또는 박수)을 포함하는 음원에서 가수의 보컬과 노래의 반주를 분리 대상 오디오로 설정하고 주변 소음을 배경음으로 설정할 수도 있고, 이와 달리, 가수의 보컬을 분리 대상 오디오로 설정하고 노래의 반주와 주변 소음을 배경음으로 설정할 수도 있다. 노래의 반주와 주변 소음을 배경음으로 설정하는 경 우와 같이, 둘 이상의 배경음을 개별적으로 조정 가능한 오디오 분리 결과를 얻기 위해, 도 5에 도시된 오디오 분리 시스템이 사용될 수 있다. 도 2의 오디오 분리 시스템과 비교하면, 도 5의 오디오 분리 시스템은 추가적인 입력으로서 배경음 제어 파라미터(β)를 입력 받고, 추가적인 배경음 특징 추출 모듈(520B)을 포함한다. 도 5의 오디오 분리 시스템은 두 개의 배경음을 조절하는 경우에 적용될 수 있는 예시이나, 이에 제한되는 것은 아니며, 더 많 은 수의 배경음을 조절하기 위해서, 더 많은 수의 배경음 제어 파라미터를 입력 받고 더 많은 수의 배경음 특징 추출 모듈을 포함하도록, 오디오 분리 시스템을 수정하는 것은 통상의 기술자에게 자명할 것이다. 이하에 서는 오디오 분리 시스템의 동작과 중복되지 않는 범위에서 오디오 분리 시스템의 동작을 설명한다. 일 실시예에서, 오디오 분리 시스템은 하나 이상의 분리 대상 오디오(Audio#1, …, Audio#N) 및 배경음을 포함하는 음원, 각각의 분리 대상 오디오에 대응되는 타겟 정보, 및 배경음 제어 파라미터(α, β)를 입력으로 하여, 배경음 제어 파라미터(α, β)에 따라 배경음의 크기가 조절된 분리된 오디오 (504, 505)를 출력할 수 있다. 오디오 분리 시스템은 학습 데이터를 이용하여 학습된 인공지능 모델일 수 있다. 배경음 제어 파라미터(α)는 분리된 음원(504, 505)에 포함될 제1 배경음의 볼륨을 결정하기 위한 파라미터이다. 배경음 제어 파라미터(α)는 사용자에 의해 결정될 수 있다. 일 실시예에서, 배경음 제어 파라미 터(α)는 0 이상 1 이하의 실수일 수 있다. 예를 들어, 오디오 분리 시스템은 배경음 제어 파라미터(α)가 0인 경우 제1 배경음이 제거된 분리된 오디오를 출력할 수 있고, 배경음 제어 파라미터(α)가 1인 경우 제 1 배경음을 그대로 포함하는 분리된 오디오를 출력할 수 있다. 다시 말하면, 오디오 분리 시스템은 배경음 제어 파라미터(α)가 0에 가까울수록 제1 배경음을 많이 제거할 수 있고, 배경음 제어 파라미터(α)가 1 에 가까울수록 제1 배경음을 적게 제거할 수 있다. 배경음 제어 파라미터(β)는 분리된 음원(504, 505)에 포함될 제2 배경음의 볼륨을 결정하기 위한 파라미터이다. 배경음 제어 파라미터(β)는 사용자에 의해 결정될 수 있다. 일 실시예에서, 배경음 제어 파라미 터(β)는 0 이상 1 이하의 실수일 수 있다. 예를 들어, 오디오 분리 시스템은 배경음 제어 파라미터(β)가 0인 경우 제2 배경음이 제거된 분리된 오디오를 출력할 수 있고, 배경음 제어 파라미터(β)가 1인 경우 제 2 배경음을 그대로 포함하는 분리된 오디오를 출력할 수 있다. 다시 말하면, 오디오 분리 시스템은 배경음 제어 파라미터(β)가 0에 가까울수록 제2 배경음을 많이 제거할 수 있고, 배경음 제어 파라미터(β)가 1 에 가까울수록 제2 배경음을 적게 제거할 수 있다. 일 실시예에서, 오디오 분리 시스템은 제1 배경음 분석 모듈(520A)을 이용하여 음원의 스펙트로그램 을 처리함으로써, 음원으로부터 제1 배경음 특징(hic1)을 추출할 수 있다. 일 실시예에서, 제1 배경음 분석모듈(520A)은 복수의 컨볼루션 블록을 포함하도록 구현될 수 있으며, 각각의 컨볼루션 블록은 하나 이상의 컨볼 루션 레이어, 배치 정규화(batch normalization), 및 활성화 함수(예: ReLu, Sigmoid 등)를 포함할 수 있다. 일 실시예에서, 제1 배경음 분석 모듈(520A)은 오디오 특징 추출 모듈과 동일한 구조로 구현될 수 있다. 제1 배경음 분석 모듈(520A) 내부에서 하나의 컨볼루션 블록에서 추출된 특징이 다음 컨볼루션 블록으로 전달되 면서 각각의 컨볼루션 블록에서 제1 배경음 특징(hic1)이 추출될 수 있다. 여기서, i는 자연수이고, hic1는 i 번 째 컨볼루션 블록에서 추출된 제1 배경음 특징이다. 예를 들어, 도 5에 도시된 바와 같이, 제1 배경음 분석 모 듈(520A)이 8개의 컨볼루션 블록을 포함하는 경우, 각각의 컨볼루션 블록은 대응되는 제1 배경음 특징(즉, h1c1, h2c1, …, h8c1)을 추출할 수 있다. 제1 배경음 특징(hic1)은 실수 전체 범위의 값을 가질 수 있으며, 대응하는 제1 오디오 특징(hi)이 제1 배경음과 연관된 정도를 나타내는 것으로 이해될 수 있다. 즉, 제1 배경음 특징(hic1)의 크기가 클수록 대응하는 제1 오디 오 특징(hi)이 제1 배경음을 생성하는데 많은 기여를 한다고 이해될 수 있으며, 제1 배경음 특징(hic)의 크기가 작을수록 대응하는 제1 오디오 특징(hi)이 제1 배경음을 생성하는데 적은 기여를 한다고 이해될 수 있다. 일 실시예에서, 오디오 분리 시스템은 제2 배경음 분석 모듈(520B)을 이용하여 음원의 스펙트로그램 을 처리함으로써, 음원으로부터 제2 배경음 특징(hic2)을 추출할 수 있다. 일 실시예에서, 제2 배경음 분석 모듈(520B)은 복수의 컨볼루션 블록을 포함하도록 구현될 수 있으며, 각각의 컨볼루션 블록은 하나 이상의 컨볼 루션 레이어, 배치 정규화(batch normalization), 및 활성화 함수(예: ReLu, Sigmoid 등)를 포함할 수 있다. 일 실시예에서, 제2 배경음 분석 모듈(520B)은 오디오 특징 추출 모듈과 동일한 구조로 구현될 수 있다. 제2 배경음 분석 모듈 내부에서 하나의 컨볼루션 블록에서 추출된 특징이 다음 컨볼루션 블록으로 전달되 면서 각각의 컨볼루션 블록에서 제2 배경음 특징(hic2)이 추출될 수 있다. 여기서, i는 자연수이고, hic2는 i 번 째 컨볼루션 블록에서 추출된 제2 배경음 특징이다. 예를 들어, 도 5에 도시된 바와 같이, 제2 배경음 분석 모 듈이 8개의 컨볼루션 블록을 포함하는 경우, 각각의 컨볼루션 블록은 대응되는 제2 배경음 특징(즉, h1c2, h2c2, …, h8c2)을 추출할 수 있다. 제2 배경음 특징(hic2)은 실수 전체 범위의 값을 가질 수 있으며, 대응하는 제1 오디오 특징(hi)이 제2 배경음과 연관된 정도를 나타내는 것으로 이해될 수 있다. 즉, 제1 배경음 특징(hic1)의 크기가 클수록 대응하는 제1 오디 오 특징(hi)이 제1 배경음을 생성하는데 많은 기여를 한다고 이해될 수 있으며, 제1 배경음 특징(hic)의 크기가 작을수록 대응하는 제1 오디오 특징(hi)이 제1 배경음을 생성하는데 적은 기여를 한다고 이해될 수 있다. 일 실시예에서, 오디오 분리 시스템은 배경음 특징 제어 모듈을 이용하여 제1 오디오 특징(hi)을 처 리함으로써, 제1 배경음 및 제2 배경음이 조절된 제2 오디오 특징(hi')을 생성할 수 있다. 도 6에 도시된 바와 같이, 배경음 특징 제어 모듈은 배경음 제어 파라미터(α, β), 제1 배경음 특징(hic1) 및 제2 배경음 특징(hic2)에 기초하여, 제1 오디오 특징(hi)이 제1 배경음 및 제2 배경음과 연관된 정도에 따라 제1 오디오 특징(hi)을 스케일링 함으로써 제1 배경음 및 제2 배경음이 조절된 제2 오디오 특징(hi')을 생성할 수 있다. 여기서, 제1 오디오 특징(hi)이 제1 배경음 및 제2 배경음과 연관된 정도는 오디오 생성 모듈에 의해 분리된 오디오가 생성될 때 분리된 오디오에 포함될 제1 배경음 및 제2 배경음에 대한 제1 오디오 특징 (hi)의 기여도로 이해될 수 있다. 일 실시예에서, 배경음 특징 제어 모듈은 수학식 3에 의해 제1 오디오 특징(hi)을 스케일링 함으로써 제1 배경음 및 제2 배경음이 조절된 제2 오디오 특징(hi')을 생성할 수 있다.수학식 3"}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, hi는 제1 오디오 특징이고, hic1는 제1 배경음 특징이고, hic2는 제2 배경음 특징이고, hi'은 제2 오디오 특징이고, α 및 β는 배경음 제어 파라미터이고, f(x)는 배경음 제어 함수이다. 일 실시예에서, 배경음 제어 함수(f(x))는 f = 1이고, x = 0을 기준으로 좌우 대칭이며(즉, y축 대칭), x의 크기(즉, |x|)가 커질수록 0으로 수렴하는 임의의 함수일 수 있다. 예를 들어, 배경음 제어 함수(f(x))는 도 3b 에 도시된 것과 같이 수학식 2의 함수일 수 있다. 도 7은 본 개시의 일 실시예에 따른 오디오 분리 방법의 순서도이다. 도 7의 오디오 분리 방법은 오디오 분리 시스템(200, 500)을 이용하여, 하나 이상의 분리 대상 오디오 및 배경음을 포함하는 음원으로부터 하나 이상의 분리 대상 오디오를 분리하기 위한 것이다. 오디오 분리 방법 은 도 8의 전자 장치에 의해 수행될 수 있다. 동작 710에서, 음원으로부터 제1 오디오 특징(hi)을 추출한다. 일 실시예에서, 동작 710은 음원에 대하여 단시간 푸리에 변환(STFT, Short-Time Fourier Transform)을 수행하 여 상기 음원의 스펙트로그램(spectrogram)을 생성하고, 그리고 음원으로부터 제1 오디오 특징(hi)을 추출하기 위해, 복수의 컨볼루션 블록을 포함하는 오디오 특징 추출 모듈(210, 510)을 이용하여 음원의 스펙트로그램을 처리하는 것을 포함할 수 있다. 동작 720에서, 음원으로부터 배경음 특징(hic)을 추출한다. 일 실시예에서, 동작 720은 음원에 대하여 단시간 푸리에 변환(STFT, Short-Time Fourier Transform)을 수행하 여 음원의 스펙트로그램(spectrogram)을 생성하고, 그리고 음원으로부터 배경음 특징(hic)을 추출하기 위해, 복 수의 컨볼루션 블록을 포함하는 배경음 분석 모듈(220, 520A, 520B)을 이용하여 음원의 스펙트로그램을 처리하 는 것을 포함할 수 있다. 일 실시예에서, 동작 720은 음원으로부터 제1 배경음 특징(hic1)을 추출하고, 음원으로부터 제2 배경음 특징 (hic2)을 추출하는 것을 포함할 수 있다. 동작 730에서, 배경음이 조절된 제2 오디오 특징(hi')을 생성하기 위해, 배경음 제어 파라미터(α) 및 배경음 특징(hic)에 기초하여, 제1 오디오 특징(hi)이 배경음과 연관된 정도에 따라 제1 오디오 특징(hi)을 처리한다. 일 실시예에서, 동작 730은 배경음 제어 파라미터(α) 및 상기 배경음 특징(hic)에 기초하여 스케일링 배수를 결 정하고, 그리고 스케일링 배수를 이용하여 제1 오디오 특징(hi)을 스케일링 함으로써 배경음이 조절된 제2 오디 오 특징(hi')을 생성하는 것을 포함할 수 있다. 일 실시예에서, 배경음 제어 파라미터(α) 및 상기 배경음 특징(hic)에 기초하여 스케일링 배수를 결정하는 것은 상기 배경음 제어 파라미터(α)가 1인 경우, 상기 스케일링 배수를 1로 결정하고, 상기 배경음 제어 파라미터 (α)가 0인 경우, 상기 배경음 특징(hic)의 크기가 클수록 상기 스케일링 배수를 더 작은 수로 결정하고, 그리고 상기 배경음 제어 파라미터(α)가 0인 경우, 상기 배경음 특징(hic)의 크기가 작을수록 상기 스케일링 배수를 더 큰 수로 결정하는 하는 것을 포함할 수 있다. 여기서, 스케일링 배수는 0보다 크고 1보다 작거나 같은 수이다. 일 실시예에서, 배경음 제어 파라미터(α) 및 상기 배경음 특징(hic)에 기초하여 스케일링 배수를 결정하는 것 은 에 의해 상기 스케일링 배수를 결정할 수 있다. 여기서, f(x)는 f = 1이고, x = 0을 기준으로 좌우 대칭이며, x의 크기가 커질수록 0으로 수렴하는, 배경음 제어 함수이다. 일 실시예에서, 배경음 제어 함수는 수학식 2의 함수일 수 있다. 일 실시예에서, 동작 730은 제1 배경음 제어 파라미터(α), 제2 배경음 제어 파라미터(β), 제1 배경음 특징 (hic1) 및 제2 배경음 특징(hic2)에 기초하여 스케일링 배수를 결정하고, 그리고 스케일링 배수를 이용하여 제1 오디오 특징(hi)을 스케일링 함으로써 배경음이 조절된 제2 오디오 특징(hi')을 생성하는 것을 포함할 수 있다. 일 실시예에서, 제1 배경음 제어 파라미터(α), 제2 배경음 제어 파라미터(β), 제1 배경음 특징(hic1) 및 제2 배경음 특징(hic2)에 기초하여 스케일링 배수를 결정하는 것은 에 의해 상기 스케일링 배수를 결정하는 것을 포함할 수 있다. 여기서, f(x)는 f = 1이고, x = 0을 기준으로 좌우 대칭이며, x의 크기가 커질수록 0으로 수렴하는, 배경음 제어 함수이다. 동작 740에서, 분리 대상 오디오에 대응되는 타겟 정보, 제1 오디오 특징, 및 배경음이 조절된 제2 오디오 특징 을 이용하여 하나 이상의 분리된 오디오를 생성한다. 일 실시예에서, 동작 740은 타겟 특징 추출 모듈을 이용하여 상기 분리 대상 오디오에 대응되는 타겟 정보 로부터 타겟 측징을 추출하고, 분리된 오디오의 스펙트로그램을 생성하기 위해, 복수의 업-컨볼루션 블록을 포 함하는 오디오 생성 모듈을 이용하여 상기 타겟 특징, 상기 제1 오디오 특징, 및 상기 제2 오디오 특징을 처리하고, 그리고 상기 분리된 오디오의 스펙트로그램에 대하여 역 단시간 푸리에 변환(ISTFT, Inverse Short- Time Fourier Transform)을 수행하여 상기 분리된 오디오를 생성하는 것을 포함할 수 있다. 도 8은 본 개시의 일 실시예에 따른 오디오 분리 방법을 수행하는 전자 장치의 구성을 개략적으로 도시한 블록도이다. 도 8에 도시된 전자 장치는 동영상을 재생하는 디스플레이 장치(예: 스마트폰, 태블릿, 텔레비전 등)일 수 도 있고, 또는 디스플레이 장치와 유무선 통신을 통해 연결된 별도의 서버일 수도 있다. 본 개시에서 설명된 실 시예들에 따른 오디오 분리 방법은 동영상을 재생하는 디스플레이 장치에 의해 수행될 수도 있고, 디스플레이 장치와 연결된 별도의 서버에서 수행될 수도 있으며, 또는 디스플레이 장치 및 서버에 의해 공동으로 수행될 수 도 있다. 도 8을 참조하면, 일 실시예에서, 전자 장치는 통신 인터페이스, 입출력 인터페이스, 오디오 출 력부, 프로세서 및 메모리를 포함할 수 있다. 다만, 전자 장치의 구성요소는 전술한 예에 한정 되는 것은 아니고, 전자 장치는 전술한 구성요소들보다 더 많은 구성요소를 포함하거나, 또는 더 적은 구성요소 를 포함할 수 있다. 일 실시예에서, 통신 인터페이스, 입출력 인터페이스, 오디오 출력부, 프로 세서 및 메모리 중 일부 또는 전부는 하나의 칩(chip) 형태로 구현될 수도 있으며, 프로세서는 하나 이상의 프로세서를 포함할 수도 있다. 예를 들어, 전자 장치는 통신 인터페이스를 통해 외부의 장치로부터 하나 이상의 분리 대상 오디오 및 배경음을 포함하는 음원을 수신할 수 있다. 이때 음원은 오디오 신호만을 포함하는 형태로 수신될 수도 있고, 동영상에 포함된 형태로 수신될 수도 있다. 수신된 음원은 메모리에 저장될 수 있다. 한편, 전자 장 치는 메모리에 미리 저장되어 있는 음원을 분리할 수도 있다. 또한 전자 장치는 입출력 인터페이스를 통해 사용자로부터 배경음의 볼륨을 입력 받을 수 있다. 이때 프로세서는 입력 받은 배경음의 볼륨에 기초하여 배경음 제어 파라미터(α, β)를 결정할 수 있다. 또한 전자 장치는 프로세서를 통해 메모리에 저장된 오디오 분리 시스템(200, 500)을 이용하여 음원을 분리할 수 있다. 오디오 분리가 완료되면, 전자 장치는 오디오 출력부를 통해 배경음이 조절된 분리된 오디오 (Audio#1, ?, Audio#N)을 출력할 수 있다. 이때 사용자는 각각의 분리된 오디오의 볼륨을 개별적으로 조절할 수 있다. 일 실시예에서, 통신 인터페이스는 외부의 장치와 유선 또는 무선으로 신호(예: 제어 명령, 데이터 등)를 송수신하기 위한 구성으로서, 다양한 통신 프로토콜을 지원하는 통신 칩셋을 포함하도록 구성될 수 있다. 통신 인터페이스는 외부로부터 신호를 수신하여 프로세서로 출력하거나, 프로세서로부터 출력된 신호 를 외부로 전송할 수 있다. 일 실시예에 따르면, 통신 인터페이스는 외부로부터 하나 이상의 분리 대상 오 디오 및 배경음을 포함하는 음원을 수신할 수 있다. 일 실시예에서, 입출력 인터페이스는 사용자로부터 제어 명령이나 정보 등을 입력받기 위한 입력 인터페이 스(예: 터치 스크린, 하드 버튼, 마이크 등)와, 사용자의 제어에 따른 동작의 실행 결과나 전자 장치의 상태를 표시하기 위한 출력 인터페이스(예: 디스플레이 패널)를 포함할 수 있다. 일 실시예에 따르면, 입출력 인터페이 스는 재생되는 동영상을 표시하고, 사용자로부터 음원에 포함된 배경음의 볼륨을 조절하기 위한 입력을 수 신할 수 있다. 일 실시예에서, 오디오 출력부는 오디오 신호를 출력하기 위한 구성으로서, 전자 장치에 내장되어 오디오 신호에 대응하는 소리를 직접 재생할 수 있는 출력 장치(예: 내장 스피커)일 수도 있고, 전자 장치가 유선 오디 오 재생 장치(예: 스피커, 사운드바, 이어폰, 헤드폰 등)와 오디오 신호를 송수신할 수 있도록 하는 인터페이스 (예: 3.5mm 단자, 4.4mm 단자, RCA 단자, USB 등)일 수도 있고, 전자 장치가 무선 오디오 재생 장치(예: 무선 이어폰, 무선 헤드폰, 무선 스피커 등)와 오디오 신호를 송수신할 수 있도록 하는 인터페이스(예: 블루투 스 모듈, 무선 랜(WLAN) 모듈 등)일 수도 있다. 일 실시예에서, 프로세서는 본 개시에서 설명된 실시예들에 따라 전자 장치가 동작하도록 일련의 과정을 제어하는 구성으로서, 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU(Central Processing Unit), AP(Application Processor), DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서, 또는 NPU(Neural Processing Unit)와 같은 인공지능 전용 프로세서일 수 있다. 예를 들어, 하나 또는 복수의 프로세 서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨 어 구조로 설계될 수 있다. 일 실시예에서, 프로세서는 메모리에 데이터를 기록하거나, 메모리에 저장된 데이터를 읽을 수 있으며, 특히 메모리에 저장된 프로그램을 실행함으로써 미리 정의된 동작 규칙 또는 인공지능 모델에 따 라 데이터를 처리할 수 있다. 따라서, 프로세서는 본 개시에서 설명된 실시예들에 포함되는 동작들을 수행 할 수 있으며, 본 개시에서 전자 장치가 수행한다고 설명된 동작들은 특별한 설명이 없는 한 프로세서가 수행하는 것으로 볼 수 있다. 일 실시예에서, 메모리는 다양한 프로그램이나 데이터를 저장하기 위한 구성으로서, 롬(ROM), 램(RAM), 하 드디스크, CD-ROM 및 DVD 등과 같은 저장 매체 또는 저장 매체들의 조합으로 구성될 수 있다. 메모리는 별 도로 존재하지 않고 프로세서에 포함되도록 구성될 수도 있다. 메모리는 휘발성 메모리, 비휘발명 메 모리 또는 휘발성 메모리와 비휘발성 메모리의 조합으로 구성될 수도 있다. 메모리에는 본 개시에서 설명 된 실시예들에 따른 동작들을 수행하기 위한 프로그램이 저장될 수 있다. 예를 들어, 메모리에는 오디오 분리 시스템에 대응하는 프로그램이 저장될 수 있다. 메모리는 프로세서의 요청에 따라 저장된 데이 터를 프로세서에 제공할 수도 있다. 도 9a, 도 9b, 도 10a, 도 10b 및 도 10c는 본 개시의 일 실시예에 따른 오디오 분리 시스템(200, 500)을 이용 하여 오디오를 분리하는 다양한 실시예들을 설명하기 위한 도면들이다. 도 9a는 카메라를 포함하는 전자 장치(예: 스마트폰, 태블릿 등)에 의해 촬영된 동영상의 한 장면을 나타낸 것 이다. 동영상에는 등장 인물의 음성뿐만 아니라 \"촬영 중이야\"와 같은 동영상에 등장하지 않는 촬영자 의 음성, 및 등장 인물 주변의 다른 사람들의 음성과 같은 주변 소음이 함께 녹음되어 있다고 가정한 다. 동영상에서 등장 인물의 음성과 촬영자의 음성을 분리하면서 분리된 음성에 포함될 주변 소음의 볼륨을 조절하기 위해 오디오 분리 시스템이 이용될 수 있다. 도 9b에 도시된 바와 같이, 오디오 분리 시스템은 등장 인물의 음성과 촬영자의 음성을 분리 대 상 오디오로서 처리하고 주변 소음을 배경음으로서 처리하여 음원으로부터 등장 인물의 음성과 촬영자 의 음성을 분리할 수 있다. 이때, 등장 인물의 얼굴이 포함된 이미지 및 촬영자의 미리 녹음된 음성이 각각 등장 인물의 음성 및 촬영자의 음성에 대한 타겟 정보로서 이용될 수 있다. 배경음 조절 파라미터(α)는 볼륨 조절 인터페이스를 통해 사용자가 조절한 주변 소음의 볼륨에 기초하여 결정될 수 있 다.사용자가 볼륨 조절 인터페이스(921, 922, 923)를 통해 등장 인물의 음성, 촬영자의 음성, 및 주변 소음의 볼륨을 각각 조절하면, 각각의 소리의 볼륨이 개별적으로 조절될 수 있다. 도 10a는 가수의 라이브 공연 동영상의 한 장면을 나타낸 것이다. 공연 동영상에는 가수의 보컬, 가수가 부르는 노래의 반주, 관객의 함성이 함께 녹음되어 있다고 가정한다. 도 10b에 도시된 바와 같이, 공연 동영상에서 가수의 보컬과 노래의 반주를 분리하면서 분리된 소리에 포 함될 관객의 함성의 볼륨을 조절하기 위해 오디오 분리 시스템이 이용될 수 있다. 오디오 분리 시스템은 가수의 보컬과 노래의 반주를 분리 대상 오디오로서 처리하고 관객의 함성을 배경음으로서 처리하여 음원으로부터 가수의 보컬과 노래의 반주를 분리할 수 있다. 이때, 가수의 얼굴이 포함된 이미지와 미리 연주된 음악이 각각 가수의 보컬과 노래의 반주에 대한 타겟 정보로서 이용 될 수 있다. 배경음 조절 파라미터(α)는 볼륨 조절 인터페이스를 통해 사용자가 조절한 관객의 함성의 볼륨에 기초하여 결정될 수 있다. 한편, 도 10c에 도시된 바와 같이, 공연 동영상에서 가수의 보컬만을 분리하면서 분리된 소리에 포함된 노래의 반주 및 관객의 함성의 볼륨을 각각 조절하기 위해 오디오 분리 시스템이 이용될 수 있다. 오디오 분리 시스템은 가수의 보컬을 분리 대상 오디오로서 처리하고, 노래의 반주를 제1 배경음으 로서 처리하고, 관객의 함성을 제2 배경음으로서 처리하여 음원으로부터 가수의 보컬을 분리할 수 있다. 이때, 가수의 얼굴이 포함된 이미지가 가수의 보컬에 대한 타겟 정보로서 이용될 수 있다. 배경음 조절 파라미터(α)는 볼륨 조절 인터페이스를 통해 사용자가 조절한 노래의 반주의 볼륨에 기초하여 결정 될 수 있고, 배경음 조절 파라미터(β)는 볼륨 조절 인터페이스를 통해 사용자가 조절한 노래의 반주의 볼륨에 기초하여 결정될 수 있다. 사용자가 볼륨 조절 인터페이스(1021, 1022, 1023)를 통해 가수의 보컬, 노래의 반주, 및 관객의 함성의 볼륨을 각각 조절하면, 각각의 소리의 볼륨이 개별적으로 조절될 수 있다. 본 개시의 일 실시예에 따른, 오디오 분리 시스템을 이용하여, 하나 이상의 분리 대상 오디오 및 배경음을 포함 하는 음원으로부터 상기 하나 이상의 분리 대상 오디오를 분리하는 방법은 상기 음원으로부터 제1 오디오 특징 을 추출하는 단계를 포함할 수 있다. 일 실시예에서, 상기 방법은, 상기 음원으로부터 배경음 특징을 추출하는 단계를 포함할 수 있다. 일 실시예에서, 상기 방법은, 상기 배경음이 조절된 제2 오디오 특징을 생성하기 위해, 상기 배경음을 제어하기 위한 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여, 상기 제1 오디오 특징이 상기 배경음과 연관된 정 도에 따라 상기 제1 오디오 특징을 처리하는 단계를 포함할 수 있다. 일 실시예에서, 상기 방법은, 상기 분리 대상 오디오에 대응되는 타겟 정보, 상기 제1 오디오 특징, 및 상기 배 경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리된 오디오를 생성하는 단계를 포함할 수 있다. 일 실시예에서, 상기 음원으로부터 제1 오디오 특징을 추출하는 단계는, 상기 음원에 대하여 단시간 푸리에 변 환(STFT, Short-Time Fourier Transform)을 수행하여 상기 음원의 스펙트로그램(spectrogram)을 생성하는 단계, 및 상기 음원으로부터 상기 제1 오디오 특징을 추출하기 위해, 복수의 컨볼루션 블록을 포함하는 오디오 특징 추출 모듈을 이용하여 상기 음원의 스펙트로그램을 처리하는 단계를 포함할 수 있다. 일 실시예에서, 상기 음원으로부터 배경음 특징을 추출하는 단계는, 상기 음원에 대하여 단시간 푸리에 변환 (STFT, Short-Time Fourier Transform)을 수행하여 음원의 스펙트로그램(spectrogram)을 생성하는 단계, 및 상 기 음원으로부터 상기 배경음 특징을 추출하기 위해, 복수의 컨볼루션 블록을 포함하는 배경음 분석 모듈 을 이용하여 상기 음원의 스펙트로그램을 처리하는 단계를 포함할 수 있다. 일 실시예에서, 상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오 특징을 처리하는 단계는, 상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하는 단계, 및 상기 스케일링 배수를 이용하여 상기 제1 오디오 특징을 스케일링 함으로써 상기 배경음이 조절된 제2 오디오 특징을 생성하는 단계를 포함할 수 있다. 일 실시예에서, 상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하는 단계는, 상기 배경음 제어 파라미터가 1인 경우, 상기 스케일링 배수를 1로 결정하는 단계, 상기 배경음 제어 파라미터 가 0인 경우, 상기 배경음 특징의 크기가 클수록 상기 스케일링 배수를 더 작은 수로 결정하는 단계, 및 상기배경음 제어 파라미터가 0인 경우, 상기 배경음 특징의 크기가 작을수록 상기 스케일링 배수를 더 큰 수로 결정 하는 단계를 포함할 수 있고, 상기 스케일링 배수는 0보다 크고 1보다 작거나 같은 수일 수 있다. 일 실시예에서, 상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하는 단계는,"}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "에 의해 상기 스케일링 배수를 결정할 수 있다. 여기서, f(x)는 f = 1이고, x = 0을 기준으로 좌우 대칭이며, x의 크기가 커질수록 0으로 수렴하는, 배경음 제어 함수이다. 일 실시예에서, 상기 배경음 제어 함수는,"}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "일 수 있다. 일 실시예에서, 상기 분리 대상 오디오에 대응되는 타겟 정보, 상기 제1 오디오 특징, 및 상기 배경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리된 오디오를 생성하는 단계는, 타겟 특징 추출 모듈을 이용 하여 상기 분리 대상 오디오에 대응되는 타겟 정보로부터 타겟 측징을 추출하는 단계, 분리된 오디오의 스펙트 로그램을 생성하기 위해, 복수의 업-컨볼루션 블록을 포함하는 오디오 생성 모듈을 이용하여 상기 타겟 특 징, 상기 제1 오디오 특징, 및 상기 제2 오디오 특징을 처리하는 단계, 및 상기 분리된 오디오의 스펙트로그램 에 대하여 역 단시간 푸리에 변환(ISTFT, Inverse Short-Time Fourier Transform)을 수행하여 상기 분리된 오 디오를 생성하는 단계를 포함할 수 있다. 일 실시예에서, 상기 오디오 분리 시스템은 하나 이상의 학습용 분리 대상 오디오 및 학습용 배경음을 포함하는 학습용 음원에 대하여, 상기 오디오 분리 시스템에 의해 예측된 오디오 분리 결과와 타겟 결과를 비교함으로써 학습될 수 있고, 상기 학습은 복수의 배경음 파라미터에 대응하는 복수의 케이스(case)에 대하여 수행될 수 있 고, 각각의 케이스에 대하여 별도의 타겟 결과가 사용될 수 있다. 일 실시예에서, 상기 음원으로부터 배경음 특징을 추출하는 단계는, 상기 음원으로부터 제1 배경음 특징을 추출 하는 단계, 및 상기 음원으로부터 제2 배경음 특징을 추출하는 단계를 포함할 수 있다. 일 실시예에서, 상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오 특징을 처리하는 단계는, 제1 배경음 제어 파라미터, 제2 배경음 제어 파라미터, 상기 제1 배경음 특징 및 상기 제2 배경음 특징 에 기초하여 스케일링 배수를 결정하는 단계, 및 상기 스케일링 배수를 이용하여 상기 제1 오디오 특징을 스케 일링 함으로써 상기 배경음이 조절된 제2 오디오 특징을 생성하는 단계를 포함할 수 있다. 일 실시예에서, 제1 배경음 제어 파라미터, 제2 배경음 제어 파라미터, 상기 제1 배경음 특징 및 상기 제2 배경 음 특징에 기초하여 스케일링 배수를 결정하는 단계는,"}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "에 의해 상기 스케일링 배수를 결정할 수 있다. 여기서, f(x)는 f = 1이고, x = 0을 기준으로 좌우 대칭이며, x의 크기가 커질수록 0으로 수렴하는, 배경음 제어 함수이다. 일 실시예에서, 상기 분리 대상 오디오에 대응되는 타겟 정보는 시각적 정보 또는 상기 분리 대상 오디오와는 별개의 오디오 정보 중 어느 하나일 수 있다. 일 실시예에서, 각각의 상기 분리 대상 오디오는 사람의 음성, 또는 악기로 연주되거나 기계음으로 만들어진 소 리일 수 있다. 일 실시예에서, 상기 배경음은 사람의 음성, 주변 소음, 또는 배경 음악 중 적어도 하나를 포함할 수 있다. 본 개시의 일 실시예에 따른, 전자 장치는 하나 이상의 프로세서, 및 오디오 분리 시스템을 이용하여, 하 나 이상의 분리 대상 오디오 및 배경음을 포함하는 음원으로부터 상기 하나 이상의 분리 대상 오디오를 분리하기 위한 프로그램이 저장되는 메모리를 포함한다. 일 실시예에서, 상기 하나 이상의 프로세서는 상기 프로그램을 실행함으로써, 상기 음원으로부터 제1 오디 오 특징을 추출할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서는 상기 프로그램을 실행함으로써, 상기 음원으로부터 배경음 특징을 추출할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서는 상기 프로그램을 실행함으로써, 상기 배경음이 조절된 제2 오디오 특징을 생성하기 위해, 상기 베경음을 제어하기 위한 배경음 제어 파라미터 및 상기 배경음 특징에 기초 하여, 상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오 특징을 처리할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서는 상기 프로그램을 실행함으로써, 상기 분리 대상 오디오에 대 응되는 타겟 정보, 상기 제1 오디오 특징, 및 상기 배경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리된 오디오를 생성할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서가 상기 음원으로부터 제1 오디오 특징을 추출하는 것은, 상기 음원에 대하여 단시간 푸리에 변환(STFT, Short-Time Fourier Transform)을 수행하여 상기 음원의 스펙트로그램 (spectrogram)을 생성하고, 그리고 상기 음원으로부터 상기 제1 오디오 특징을 추출하기 위해, 복수의 컨볼루션 블록을 포함하는 오디오 특징 추출 모듈을 이용하여 상기 음원의 스펙트로그램을 처리하는 것을 포함할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서가 상기 음원으로부터 배경음 특징(hic)을 추출하는 것은, 상기 음원에 대하여 단시간 푸리에 변환(STFT, Short-Time Fourier Transform)을 수행하여 음원의 스펙트로그램 (spectrogram)을 생성하고, 그리고 상기 음원으로부터 상기 배경음 특징을 추출하기 위해, 복수의 컨볼루션 블 록을 포함하는 배경음 분석 모듈을 이용하여 상기 음원의 스펙트로그램을 처리하는 것을 포함할 수 있다. 일 실시예에서, 상기 하나의 이상의 프로세서가 상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따 라 상기 제1 오디오 특징을 처리하는 것은, 상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일 링 배수를 결정하고, 그리고 상기 스케일링 배수를 이용하여 상기 제1 오디오 특징을 스케일링 함으로써 상기 배경음이 조절된 제2 오디오 특징을 생성하는 것을 포함할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서가 상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하는 것은, 상기 배경음 제어 파라미터가 1인 경우, 상기 스케일링 배수를 1로 결정하고, 상기 배경음 제어 파라미터가 0인 경우, 상기 배경음 특징의 크기가 클수록 상기 스케일링 배수를 더 작은 수로 결정하고, 그리고 상기 배경음 제어 파라미터가 0인 경우, 상기 배경음 특징의 크기가 작을수록 상기 스케일링 배수를 더 큰 수로 결정하는 것을 포함할 수 있고, 상기 스케일링 배수는 0보다 크고 1보다 작거나 같은 수일 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서가 상기 배경음 제어 파라미터 및 상기 배경음 특징에 기초하여 스케일링 배수를 결정하는 것은,"}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "에 의해 상기 스케일링 배수를 결정할 수 있다. 여기서, f(x)는 f = 1이고, x = 0을 기준으로 좌우 대칭이며, x의 크기가 커질수록 0으로 수렴하는, 배경음 제어 함수이다. 일 실시예에서, 상기 배경음 제어 함수는,"}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "일 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서가 상기 분리 대상 오디오에 대응되는 타겟 정보, 상기 제1 오 디오 특징, 및 상기 배경음이 조절된 제2 오디오 특징을 이용하여 하나 이상의 분리된 오디오를 생성하는 것은,타겟 특징 추출 모듈을 이용하여 상기 분리 대상 오디오에 대응되는 타겟 정보로부터 타겟 측징을 추출하 고, 분리된 오디오의 스펙트로그램을 생성하기 위해, 복수의 업-컨볼루션 블록을 포함하는 오디오 생성 모듈 을 이용하여 상기 타겟 특징, 상기 제1 오디오 특징, 및 상기 제2 오디오 특징을 처리하고, 그리고 상기 분리된 오디오의 스펙트로그램에 대하여 역 단시간 푸리에 변환(ISTFT, Inverse Short-Time Fourier Transform)을 수행하여 상기 분리된 오디오를 생성하는 것을 포함할 수 있다. 일 실시예에서, 상기 오디오 분리 시스템은 하나 이상의 학습용 분리 대상 오디오 및 학습용 배경음을 포함하는 학습용 음원에 대하여, 상기 오디오 분리 시스템에 의해 예측된 오디오 분리 결과와 타겟 결과를 비교함으로써 학습될 수 있고, 상기 학습은 복수의 배경음 파라미터에 대응하는 복수의 케이스(case)에 대하여 수행될 수 있 고, 각각의 케이스에 대하여 별도의 타겟 결과가 사용될 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서가 상기 음원으로부터 배경음 특징(hic)을 추출하는 것은, 상기 음원으로부터 제1 배경음 특징을 추출하고, 그리고 상기 음원으로부터 제2 배경음 특징을 추출하는 것을 포함할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서가 상기 제1 오디오 특징이 상기 배경음과 연관된 정도에 따라 상기 제1 오디오 특징을 처리하는 것은, 제1 배경음 제어 파라미터, 제2 배경음 제어 파라미터, 상기 제1 배경 음 특징 및 상기 제2 배경음 특징에 기초하여 스케일링 배수를 결정하고, 그리고 상기 스케일링 배수를 이용하 여 상기 제1 오디오 특징을 스케일링 함으로써 상기 배경음이 조절된 제2 오디오 특징을 생성하는 것을 포함할 수 있다. 일 실시예에서, 상기 하나 이상의 프로세서가 제1 배경음 제어 파라미터, 제2 배경음 제어 파라미터, 상기 제1 배경음 특징 및 상기 제2 배경음 특징에 기초하여 스케일링 배수를 결정하는 것은,"}
{"patent_id": "10-2023-0068617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "에 의해 상기 스케일링 배수를 결정할 수 있다. 여기서, f(x)는 f = 1이고, x = 0을 기준으로 좌우 대칭이며, x의 크기가 커질수록 0으로 수렴하는, 배경음 제어 함수이다. 일 실시예에서, 상기 분리 대상 오디오에 대응되는 타겟 정보는 시각적 정보 또는 상기 분리 대상 오디오와는 별개의 오디오 정보 중 어느 하나일 수 있다. 일 실시예에서, 각각의 상기 분리 대상 오디오는 사람의 음성, 또는 악기로 연주되거나 기계음으로 만들어진 소 리일 수 있다. 일 실시예에서, 상기 배경음은 사람의 음성, 주변 소음, 또는 배경 음악 중 적어도 하나를 포함할 수 있다. 도면 도면1 도면2 도면3a 도면3b 도면4 도면5 도면6 도면7 도면8 도면9a 도면9b 도면10a 도면10b 도면10c"}
{"patent_id": "10-2023-0068617", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 오디오 분리 방법이 적용될 수 있는 상황을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시예에 따른 오디오 분리 시스템을 도시한다. 도 3a는 본 개시의 일 실시예에 따른 배경음 특징 제어 모듈의 동작을 설명하기 위한 도면이다. 도 3b는 배경음 제어 함수의 일 예를 나타낸다. 도 4는 본 개시의 일 실시예에 따른 오디오 분리 시스템의 학습 방법을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시예에 따른 오디오 분리 시스템을 도시한다. 도 6은 본 개시의 일 실시예에 따른 배경음 특징 제어 모듈의 동작을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른 오디오 분리 방법의 순서도이다. 도 8는 본 개시의 일 실시예에 따른 오디오 분리 방법을 수행하는 전자 장치의 구성을 개략적으로 도시한 블록 도이다. 도 9a, 도 9b, 도 10a, 도 10b 및 도 10c는 본 개시의 일 실시예에 따른 오디오 분리 시스템을 이용하여 오디오 를 분리하는 다양한 실시예들을 설명하기 위한 도면들이다."}
