{"patent_id": "10-2023-0035506", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0141101", "출원번호": "10-2023-0035506", "발명의 명칭": "모범적 공감형 인공지능의 대화 방법 및 시스템", "출원인": "김만돌", "발명자": "김만돌"}}
{"patent_id": "10-2023-0035506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터로 구현되는 인공지능 대화방법에 있어서,사용자의 대화유형을 분류하는 부분;맞장구 표현의 문장을 제시하는 부분;호칭표현의 문장을 제시하는 부분;대화내용요약 표현의 문장을 제시하는 부분;대화촉진질문표현의 문장을 제시하는 부분;사용자의 요청에 대한 답변을 제시하는 부분;답변내용에 대응하는 해결의 실시를 출력하는 부분;답변제시 또는 해결실시 결과에 대한 사용자의 만족 여부를 확인하는 질문을 하는 부분;및 추가정보 필요여부 또는 추가정보사항을 질문하는 부분;중 적어도 네 개 이상의 부분을 포함하는인공지능 대화 방법 및 장치."}
{"patent_id": "10-2023-0035506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "컴퓨터로 구현되는 인공지능 대화방법에 있어서,사용자대화내용을 분류하는 부분은,사용자의 대화내용, 전달감정의 유형과 강도에 대응하여,사용자의 대화유형을 분류하는 부분;을 포함하는 것을 특징으로 하는 인공지능 대화 방법 및 장치."}
{"patent_id": "10-2023-0035506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "컴퓨터로 구현되는 인공지능 대화방법에 있어서,대화유형과 전달감정유형에 대응하는 맞장구표현, 호칭표현, 대화요약표현, 공감표현, 대화촉진질문표현, 답변제시, 해결실시, 만족확인질문표현, 추가사항질문표현의 문장을 제시하는 부분은,사용자의 대화내용에 포함된 감정표현언어 각각에 대하여 음성입력 정보, 문자입력 정보, 얼굴영상 정보, 상태관찰정보 중 적어도 하나 이상의 형태 내에서의 수집분석된 사용자의 감정의 유형과 강도에 관한 정보에 대응하는 강도의 맞장구표현, 호칭표현, 대화요약표현, 공감표현, 대화촉진질문표현, 답변제시, 해결실시, 만족확인질문표현, 추가사항질문표현 문장을 형성하는 부분;분류된 사용자의 대화 대화유형과 전달감정유형에 대응하는 맞장구표현, 호칭표현, 대화요약표현, 공감표현, 대화촉진질문표현, 답변제시, 해결실시, 만족확인질문표현, 추가사항질문표현 답변문장 형성을, 저장된 감정표현언어 및 맞장구표현, 호칭표현, 대화요약표현, 공감표현, 대화촉진질문표현, 만족확인질문표현, 추가사항질문표현 문장 세트 중에서 상기 맞장구표현, 호칭표현, 대화요약표현, 공감표현, 대화촉진질문표현, 만족확인질문표현, 추가사항질문표현 답변문장을 선택하거나 이를 수정하여 사용하거나 사용자가 직접 표현한 감정표현언어 단어를 사용하여 맞장구표현, 호칭표현, 대화요약표현, 공감표현, 대화촉진질문표현, 만족확인질문표현, 추가사항공개특허 10-2024-0141101-3-질문표현 답변문장을 형성하는 부분;맞장구표현, 호칭표현, 대화요약표현, 공감표현, 대화촉진질문표현, 만족확인질문표현, 추가사항질문표현을 음성파일, 문자파일, 영상파일 중 적어도 하나 이상의 형태로 변환하여 사용자에게 제시하는 부분;을 포함하는 것을 특징으로 하는 공감표현이 가능한 인공지능 대화 방법 및 장치."}
{"patent_id": "10-2023-0035506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "컴퓨터와 결합되어 제1항 내지 제3항 중 어느 한 항의 인공지능 대화 방법을 컴퓨터에 실행시키기 위해 컴퓨터판독 가능한 기록매체에 저장된 컴퓨터 프로그램"}
{"patent_id": "10-2023-0035506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제3항 중 어느 한 항의 인공지능 대화 방법을 컴퓨터에 실행시키기 위한 프로그램이 기록되어 있는것을 특징으로 하는 컴퓨터에서 판독이 가능한 기록매체."}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 기계와 인간간의 모범적인 공감표현이 가능한 대화 방법 및 시스템에 관한 것이다. 본 발명인 모범적 공감형 인공지능 대화 방법은 컴퓨터로 구현되는 인공지능 대화 방법에 있어서, (뒷면에 계속)"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 모범적인 공감표현이 가능한 인공지능 대화 방법 및 시스템에 관한 것이다. 사용자의 대화내용과 감"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "정전달유형에 분석하여 대화유형에 따라 분류된 맞장구표현, 호칭표현, 대화요약표현, 공감표현, 대화촉진질문 표현, 대답제시. 해결실시제공, 작동제어명령, 답변만족여부질문표현, 추가필요사항필요질문표현을 포함하는, 교육적이고 모범적인 공감표현이 가능한 대화답변을 제공하는, 공감표현이 가능한 인공지능 대화 방법 및 시스 템입니다."}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재 시점의 기술수준에서 일반적으로 통용되는 무인자동응답시스템, 개인비서 시스템, 챗봇 플랫폼, 인공지능 스피커 등에서 사용되는 인공지능 대화시스템은 사용자의 명령을 인식하고 그에 대응하는 검색된 내용의 답변이 나 작동지시의 이행만을 제공하는 방식 정도의 시스템이다. 대한민국 특허등록 제1020342550000호(2019. 10. 14.)로 등록한 기술을 적용한 네이버(클로버), 대한민국 특허 공개 제1020210106657호(2021. 08. 31.)로 공개한 기술을 적용한 KT(기가지니), 대한민국 특허등록 제 102394289호(2022. 04. 29.)로 등록한 기술을 적용한 구글(어시스턴트), 애플(시리), 아마존(알렉사), IBM, 삼 성전자(빅스비), 카카오(헤이카타오) 등 현재 시점에서 이 분야에서 세계적으로 선두에 자리잡은 기관들의 인공 지능 대화 시스템의 기술수준은 사용자가 컴퓨터에게 정보제공을 요구하거나 기능적인 요구를 전달하고 이에 사 용자에게 기계가 사용자의 요구에 대한 정보를 제공하거나 기계의 작동을 제공하는 방식으로 이루어지는 수준이 고, 사용자가 마이크를 통해 사용자의 음성을 입력하거나, 키보드를 통해 문자를 입력하고, 이에 대해 인공지능 대화시스템이 수신된 음성입력정보 또는 문자입력정보에 기반하여 장치의 작동이나 컨텐츠 제공을 제어할 수 있 는 수준이다. 또한, 가정이나 사무실의 네트워크 서비스에서 이동통신망 외에 와이파이와 같은 제2 통신망을 이용하여 가정이 나 사무실의 네트워크 서비스를 제공하는 것이 가능하고, 가정이나 사무실 내 복수의 멀티미디어 기기를 사용자 가 별도의 버튼 조작 없이도 음성 명령을 통해 다중 제어할 수 있는 기술이 개시되어 있다. 지금까지의 발전된 기술을 반영한 기존의 인공지능 대화 시스템은 사용자의 감정 파악이나 기계의 감정표현이 부족하며 사용자의 명령어 표현 및 컴퓨터 표현의 방식 역시, 단순히 문자나 음성으로 제한되어 있어, 인공지능 대화시스템 이용시에 사용자로 하여금 거부함과 딱딱함을 느끼게 하였고, 공감이나 위로, 따스함을 느낄 수 없 게 되었다. 지금까지의 발전된 기술을 반영한 기존의 인공지능 대화 시스템은 사용자에 의한 정보요구에 대한 정보제공이나 기능적 요구에 대한 해결로서 작동실행에는 적합하나, 컴퓨터의 대화표현을 사람들끼리의 대화표현처럼 공감적인 표현이 풍부하고 자연스럽게 느껴지게 하고 사용자-컴퓨터 간 공감적 정서적 교류를 불러일으 키는 상호작용을 구현하기에는 부족하다. 기존의 기능형 AI(Artificial Intelligence) 채팅 서비스의 경우에도, 사용자가 입력한 텍스트 내용에 대한 지 시와 명령을 수행하며, 기존의 관계형 AI 채팅 서비스의 경우, 사용자가 입력한 텍스트 내용에 대해 데이터베이 스에 기입력된 내용만을 단순하게 대답하는 형식으로 사용자에게 정보를 전달하는 구조로 서비스되었다. 이러한 기존 기술은 기설정된 데이터를 기반으로 채팅 서비스를 제공하는 것이므로, 사용자의 한정된 텍스트에 대해서 만 응답하거나, 직전 문장에 대해서만 추론하여 응답을 제공한다는 한계가 존재하였다. 또한, 기존 기술은 문맥 을 통한 복잡한 상호작용을 반영하지 못하여 응답 상의 오류가 빈번히 발생한다는 한계가 존재하였다. 기존 기술들은 앞선 문장에 대한 오답을 제안하거나, 명령으로 인지하여 온라인상의 검색정보를 제공하는 것을 알 수 있다. 기존의 딥러닝으로 학습된 인공지능 대화시스템의 답변도 다수의 인간의 평균적인 답변을 축적한 것으로써 다수 의 사용자가 현재 사용하고 있는 낮은 수준의 소통표현을 답변으로 채택할 수밖에 없는 한계를 가지고 있다. 이것을 극복하여 기존의 딥러닝으로 학습된 다수의 인간의 평균적인 답변을 축적한 인공지능 대화시스템보다 공 감성이 훨씬 더 높은 교육적이고 모범적인 공감표현 답변문구를 제공하고, 산업계에서 사용되고 있는 수많은 인 공지능 대화시스템의 사용자에게 거부함과 딱딱함을 없애고, 따뜻한 인간적인 위로, 공감, 친근감을 제공하는 것이 본 발명인 모범적인 공감표현이 가능한 인공지능 대화방법 및 시스템이다. 본 발명인 모범적 공감형 인공지능 대화시스템은 사용자의 대화내용과 전달감정유형과 강도를 파악하여 대화유 형을 정보요구형, 작동요구형, 사실전달형, 감정전달형, 태도표현형 등으로 분류하고, 감정전달형은 다시 인정 칭찬형, 공감위로형 등으로 분류하고, 공감위로형은 다시 걱정공감형, 고통공감형 등으로 분류하고, 각각의 대"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "화유형에 맞는 공감표시 답변문장으로 맞장구표현부분, 호칭표현부분, 대화요약표현부분, 공감표현부분를 포함 하는 공감표시 답변문장을 제시하고. 대화촉진질문표현부분, 답변만족여부질문 표현부분, 추가필요사항질문표현 부분의 답변문장제시를 포함하는 대화를 가능하게 하여, 공감표현이 가능한 인공지능대화의 모범적인 답변문장 을 제시함으로써, 기존의 딥러닝으로 학습된 다수의 인간의 평균적인 답변을 축적한 인공지능 대화시스템보다 공감성이 훨씬 더 높은 공감표현 답변문구를 제공하여 모범적인 공감표현이 가능한 대화방법 및 시스템방식이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 특허등록 제1020342550000호 (특허문헌 0002) 대한민국 특허공개 제1020210106657호 (특허문헌 0003) 대한민국 특허등록 제102394289호"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "기존의 인공지능 대화시스템은 딥러닝으로 학습된 다수의 인간의 평균적인 답변을 축적한 것으로써, 소통역량이 낮은 대부분의 평균적인 대화방식이나 표현을 축적하여 사용하고 있으므로, 모범적이고 바람직한 공감적인 대화 가 곤란한 것이 현재의 기술수준이다. 그래서 기존의 인공지능 대화시스템을 이용하는 사용자는 공감적인 사람 과 대화하는 것과 같은 인간적인 대화느낌을 전혀 느끼지 못하고 딱딱하고 불편한 느끼고 있다. 이와 같은 문제점을 해결하기 위해 본 발명이 이루고자 하는 기술적 과제는, 본 발명인 모범적인 공감표현이 가 능한 인공지능 대화방법 및 시스템은, 인공지능대화 시스템과 사용자의 대화에서의 사용자의 사고, 감정, 요구, 태도 등을 통해 사용자의 대화유형 및 전달감정유형을 파악하여 대화유형을 정보요구형, 작동요구형, 사실전달형, 감정전달형, 태도표현형 등으로 1차분류하고, 감정전달형은 인정칭찬형, 감정위로형 등으로 2차 분류하고, 감정위로형은 걱정공감형, 고통공감형"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "등으로 3차 분류하고, 이에 대응하는 다양한 감정유형에 따른 답변문장을 맞장구표현, 대화요약표현, 공감표현, 대화촉진질문표현, 답변만족여부 질문표현, 답변제시표현, 추가필요사항 질문표현을 포함하는 답변을 형성하고, 상기 답변을 음성, 시각, 동작 등 통합정보로 표현할 수 있는 인공지능의 환경을 통해 사용자-컴퓨터 간 공감적 정서적 교감을 불러일으킬 수 있는 대화가 가능하여, 모범적인 공감표현이 가능한 인공지능의 대화방법 및 시스 템을 제공한다. 본 발명은, 딥러닝으로 학습된 다수의 인간의 평균적인 답변을 축적한 기존의 인공지능 대화시스템보다 공감성 이 훨씬 더 높은 공감표현 답변문구를 사용하는, 교육적이고 모범적인 인공지능 대화를 가능하게 하여, 산업계 에서 사용되고 있는 수많은 인공지능 대화시스템의 사용자에게 거부함과 딱딱함을 없애고, 따뜻한 인간적인 위 로, 공감, 친근감을 제공하는 것이다."}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이와 같은 기술적 과제를 해결하기 위하여, 본 발명인 모범적 공감형 인공지능 대화 방법 및 시스템은, 컴퓨터로 구현되는 인공지능 대화 방법에 있어서, 사용자의 대화내용을 인식하는 부분; 사용자의 대화내용을 저장하는 부분; 사용자의 대화내용과 전달감정유형을 분석하는 부분: 분석한 사용자의 대화의 내용과 감정전달유형에 따라 대화유형을 정보요구형, 작동요구형, 사실전달형, 감정전 달형, 태도표현형 등 적어도 두개 이상의 유형으로 1차 분류하고, 감정전달형은 인정칭찬형, 감정위로형 등으로 2차 분류하고, 감정위로형은 걱정공감형, 고통공감형 등으로 3차 분류하는 부분; 사용자의 대화유형과 감정전달유형에 대응되는 각 답변유형에 따라 맞장구 표현의 답변문장을 형성하여 제시하 는 부분; 사용자의 대화유형과 감정전달유형에 대응되는 각 답변유형에 따라 호칭표현의 답변문장을 형성하여 제시하는 부분;"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "사용자의 대화유형과 감정전달유형에 대응되는 각 답변유형에 따라 대화내용요약 표현의 답변문장을 형성하여 제시하는 부분; 사용자의 대화유형과 감정전달유형에 대응되는 각 답변유형에 따라 공감표현의 답변문장을 형성하여 제시하는 부분; 사용자의 대화유형과 감정전달유형에 대응되는 각 답변유형에 따라 대화촉진질문표현의 답변문장을 형성하여 제 시하는 부분; 사용자의 요청에 대한 답변을 제시하는 부분; 답변내용에 대응하는 정보제공, 해결방법제공, 실행작동 제공 중 적어도 하나 이상의 형태를 실시하는 부분; 공감답변 문장, 답변제시 문장, 해결실시 작동에 해당되는 음성파일, 영상파일, 작동제어명령을 출력하되 상기 답변문장에 포함된 감정표현언어가 포함되는 음성파일, 영상파일을 출력하는 시점에 상기 감정표현언어에 대응 되는 작동제어명령을 함께 출력하는 부분; 공감답변, 답변제시 또는 해결실시 결과에 대한 사용자의 만족여부를 확인하는 질문을 하는 부분; 및 답변제시 또는 해결실시 이외에 사용자에게 추가정보 필요여부 또는 추가정보사항을 질문하는 부분; 을 포함하는 모범적 공감형 인공지능 대화 방법 및 시스템을 제공한다. 본 발명은, 상기 사용자 대화내용을 인식하는 부분에서는, 사용자의 문자입력정보, 음성입력정보, 얼굴영상정보, 상태관찰정보 중 적어도 하나 이상의 형태를 이용하여 상 기 사용자가 외부적으로 적극적으로 표현한 대화내용, 감정표현언어, 표정, 동작, 태도, 상태 정보를 통해 대화 의도에 관한 정보를 포함하여, 대화유형과 전달감정유형의 파악에 필요한 정보를 인식 수집하는 부분: 사용자가 대화내용, 감정표현언어, 표정, 동작, 태도, 상태 정보 중 적어도 하나 이상의 형태를 이용하여 표현 한 감정표현 각각에 대하여 포함된, 아직 적극적으로 외부에 표현되지 않은 내면의 감정상태에 관한 정보를 수 집하는 부분; 을 포함한다. 본 발명은, 상기 사용자 대화내용을 저장하는 부분에서는, 인공지능 대화시스템이 인식한 사용자의 대화내용을 대화유형 및 전달감정유형 별로 저장하는 부분: 사용자의 대화유형 및 전달감정유형 별로 분류된 복수 개의 감정표현언어 및 공감표현 문장세트 예시에 추가적 으로 저장하여 다음 사용자에 대한 공감표현 답변문장 형성을 위해 사전에 준비되어 제공되도록 하는 부분; 을 포함한다. 본 발명은, 상기 사용자대화내용을 분석하는 부분에서는, 사용자의 문자입력정보, 음성입력정보, 얼굴영상정보, 상태관찰정보 중 적어도 하나 이상의 형태로부터 판단되 는, 상기 사용자가 음성, 문자, 표정, 동작, 태도로 외부로 적극적으로 표현한 감정, 대화의도 뿐만 아니라 상 기 사용자가 표현된 대화의 내용의 문장, 얼굴표정, 행동, 태도의 상태관찰 정보로부터, 사용자가 아직 외부적 으로 적극적으로 표현하지 않은 내면 감정상태에 관한 정보를 분석하는 부분: 사용자가 표현한 감정표현 각각에 대하여 상기 감정표현에 대응되는 공감표현언어 및 공감표현문장 정보를 수집 분석하는 부분; 사용자가 문자입력 정보, 음성입력 정보, 얼굴영상 정보, 상태관찰 정보 중 적어도 하나 이상의 형태로 외부적 으로 적극적으로 표현한 감정표현 및 아직 외부적으로 적극적으로 표현하지 않은 내면 감정상태 정보를 통하여 수집한 상기 감정표현 각각에 대하여 사용자의 감정의 강도에 관한 정보를 수집분석하는 부분; 문자입력, 음성입력, 얼굴영상 파일, 관찰측정상태정보 중 적어도 하나 이상의 형태로부터 수신한 사용자의 감 정의 강도에 관한 정보를 종합하여 사용자의 답변문장의 감정정보 표현의 강도와 수준의 조율을 수행하는 부분; 사용자가 음성, 문자로 외부적으로 적극적으로 표현한, 대화의 내용의 문장, 얼굴표정, 행동, 태도, 상태관찰 정보로부터 수집된, 사용자의 표정, 행동, 태도에 포함된, 사용자가 아직 외부적으로 적극적으로 표현하지 않은 내면 상태감정에 관한 정보에 포함된, 감정의 강도에 관한 정보에 대응되는 공감표현언어 및 공감표현문장 정보 를 수집분석하는 부분; 을 포함한다. 본 발명은, 상기 사용자대화내용을 분류하는 부분에서는, 분석된 사용자의 대화내용, 전달감정의 유형과 강도에 대응하여, 사용자의 대화유형을 정보요구형, 작동요구형, 사실전달형, 감정전달형, 태도표현형 등 적어도 두 개 이상의 유 형으로 1차 분류하고, 감정전달형는 다시 인정칭찬형, 공감위로형 등으로 2차 분류하고, 공감위로형은 다시 걱 정공감형, 고통공감형 등으로 3차 분류하는 부분; 을 포함한다. 본 발명은, 대화유형과 전달감정유형에 대응하는 맞장구표현 답변문장을 형성하여 제시하는 부분에서는, 사용자의 대화내용에 포함된 감정표현언어 각각에 대하여 음성입력 정보, 문자입력 정보, 얼굴영상 정보, 상태 관찰정보 중 적어도 하나 이상의 형태 내에서의 수집분석된 사용자의 감정의 유형과 강도에 관한 정보에 대응하 는 강도의 맞장구표현 문장을 포함하여 이루어지는 맞장구 답변문장을 제시하는 부분; 분석 분류된 사용자의 대화 대화유형과 전달감정유형에 대응하는 맞장구표현 답변문장 형성을, 저장된 감정표현 언어 및 맞장구표현 문장 세트 중에서 맞장구표현 답변문장을 선택하거나 이를 수정하여 사용하거나 사용자가 직접 표현한 감정표현언어 단어를 사용하여 맞장구 표현답변장을 형성하는 부분; 맞장구표현의 문장이 포함된 맞장구표현 답변내용을 음성파일, 문자파일, 영상파일 중 적어도 하나 이상의 형태 로 변환하여 사용자에게 제시하는 부분; 을 포함한다. 본 발명은, 대화유형과 전달감정유형에 대응하는 호칭표현 답변문장을 형성하여 제시하는 부분에서는, 사용자의 대화내용에 포함된 감정표현언어 각각에 대하여 음성입력정보, 문자입력정보, 얼굴영상정보, 상태관찰 정보 중 적어도 하나 이상의 형태 내에서의 수집분석된 사용자의 감정의 유형과 강도에 관한 정보에 대응하는 강도의 호칭표현 문장을 포함하여 이루어지는 호칭표현 답변문장을 형성하여 제시하는 부분; 분석 분류된 사용자의 대화유형과 전달감정유형에 대응하는 호칭표현 답변문장 형성을, 저장된 감정표현언어 및 호칭표현 문장 세트 중에서 상기 공감표현 답변문장을 선택하거나 이를 수정하여 사용하거나 사용자가 직접 표 현한 감정표현언어 단어를 사용하여 호칭표현 답변문장을 형성하는 부분; 호칭표현의 문장이 포함된 호칭표현 답변내용을 음성파일, 문자파일, 영상파일 중 적어도 하나 이상의 형태로 변환하여 사용자에게 제시하는 부분; 을 포함한다."}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "본 발명은, 대화유형과 전달감정유형에 대응하는 대화요약표현 답변문장을 형성하여 제시하는 부분에서는, 사용자의 대화내용에 포함된 감정표현언어 각각에 대하여 음성입력정보, 문자입력정보, 얼굴영상정보, 상태관찰 정보 중 적어도 하나 이상의 형태 내에서의 수집분석된 사용자의 감정의 유형과 강도에 관한 정보에 대응하는"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "강도의 대화요약 표현문장을 포함하여 이루어지는 대화요약 답변문장을 형성하여 제시하는 부분;"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 5, "content": "분석 분류된 사용자의 대화 대화유형과 전달감정유형에 대응하는 대화요약표현 답변문장 형성을, 저장된 감정표"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 6, "content": "현언어 및 대화요약 표현 문장 세트 중에서 대화요약 표현 답변문장을 선택하거나 이를 수정하여 사용하거나 사"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 7, "content": "용자가 직접 표현한 감정표현언어 단어를 사용하여 대화요약 표현 답변문장을 형성하는 부분;"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 8, "content": "상기 대화요약 표현의 문장이 포함된 대화요약표현 답변내용을 음성파일, 문자파일, 영상파일 중 적어도 하나 이상의 형태로 변환하여 사용자에게 제시하는 부분; 을 포함한다. 본 발명은, 대화유형과 전달감정유형에 대응하는 공감표현 답변문장을 형성하여 제시하는 부분에서는, 사용자의 대화내용에 포함된 감정표현언어 각각에 대하여 음성입력정보, 문자입력정보, 얼굴영상정보, 상태관찰 정보 중 적어도 하나 이상의 형태 내에서의 수집분석된 사용자의 감정의 유형과 강도에 관한 정보에 대응하는 강도의 공감표현문장을 포함하여 이루어지는 공감표현 답변문장을 형성하여 제시하는 부분; 분석 분류된 사용자의 대화 대화유형과 전달감정유형에 대응하는 공감표현 답변문장 형성을, 저장된 감정표현언 어 및 공감표현 문장 세트 중에서 상기 공감표현 답변문장을 선택하거나 이를 수정하여 사용하거나 사용자가 직 접 표현한 감정표현언어 단어를 사용하여 공감표현 답변문장을 형성하는 부분; 상기 공감표현의 문장이 포함된 공감표현 답변내용을 음성파일, 문자파일, 영상파일 중 적어도 하나 이상의 형 태로 변환하여 사용자에게 제시하는 부분;을 포함한다. 본 발명은, 대화유형과 전달감정유형에 대응하는 대화촉진질문표현 답변문장을 형성하여 제시하는 부분에서는, 사용자의 대화내용에 포함된 감정표현언어 각각에 대하여 음성입력정보, 문자입력정보, 얼굴영상정보, 상태관찰 정보 중 적어도 하나 이상의 형태 내에서의 수집분석된 사용자의 감정의 유형과 강도에 관한 정보에 대응하는 강도의 대화촉진 표현문장을 포함하여 이루어지는 대화촉진질문표현 답변문장을 형성하여 제시하는 부분; 분석 분류된 사용자의 대화 대화유형과 전달감정유형에 대응하는 대화촉진질문표현 답변문장 형성을, 저장된 감 정표현언어 및 대화촉진질문표현 문장 세트 중에서 공감표현 답변문장을 선택하거나 이를 수정하여 사용하거나 사용자가 직접 표현한 감정표현언어 단어를 사용하여 대화촉진질문표현 답변문장을 형성하는 부분; 대화촉진질문표현의 문장이 포함된 대화촉진질문표현 답변내용을 음성파일, 문자파일, 영상파일 중 적어도 하나 이상의 형태로 변환하여 사용자에게 제시하는 부분; 을 포함한다. 본 발명은, 사용자의 요청에 대응하는 답변의 제공을 제시하는 부분에서는, 정보제공, 해결방법 제공, 실행작동 제공 중 적어도 하나 이상의 형태에 대한 정보가 담긴 문장표현이 포함된 답변내용을 음성파일, 문자파일, 영상파일 중 적어도 하나 이상의 형태로 변환하여 사용자에게 제시하는 부분; 사용자의 대화내용에 포함된 감정표현언어 각각에 대하여 음성입력정보, 문자입력정보, 얼굴영상정보, 상태관찰 정보 중 적어도 하나 이상의 형태 내에서의 수집분석된 사용자의 감정의 유형과 강도에 관한 정보에 대응하는 강도의 답변문장을 포함하여 이루어지는 답변문장을 형성하여 제시하는 부분; 분석 분류된 사용자의 대화 대화유형과 전달감정유형에 대응하는 답변문장 형성을, 저장된 감정표현언어 및 답 변표현 문장 세트 중에서 답변문장을 선택하거나 이를 수정하여 사용하거나 사용자가 직접 표현한 감정표현언어 단어를 사용하여 답변문장을 형성하는 부분; 을 포함한다. 본 발명은, 답변내용에 대응하는 해결을 실시하는 부분에서는, 사용자의 요청에 대한 답변내용에 대응하는 정보제공, 해결방법 실시, 실행작동 제공 중 적어도 하나 이상의 형 태를 실시하기 위하여, 프로세서 및 네트워크를 통하여 필요한 정보를 검색 수집하기 위한 검색명령, 저장명령, 작동명령 중 적어도 하나 이상의 명령을 실행하는 부분; 상기 프로세서 및 네트워크를 통하여 검색 수집된 내용이 포함된 해결실시 내용을 음성파일, 문자파일, 영상파 일, 정보제공 파일, 작동제어명령 중 적어도 하나 이상의 형태로 변환하는 부분; 사용자의 요청에 대한 답변내용에 대응하는 정보제공, 해결방법 실시, 실행작동 제공 중 적어도 하나 이상의 형 태를 실시하여 출력하는 부분; 음성파일 정보, 영상파일 정보, 정보제공 정보, 해결방법 실시, 작동제어명령의 출력과 함께 상기 사용자의 감 정의 유형과 강도에 관한 정보에 대응되는 상기 정보제공, 해결방법 실시, 작동제어명령 정보를 출력하는 부분; 상기 답변내용에 대응하는 정보제공, 해결방법 실시, 실행작동 제공 중 적어도 하나 이상의 형태의 해결실시에 대응되는 작동제어명령 정보를 디스플레이 장치, 모터제어 작동장치, 시스템제어 장치, 네트워크 장치 중 적어 도 하나 이상의 장치를 통해 작동제어명령을 출력하는 부분; 을 포함한다."}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 9, "content": "본 발명은, 사용자의 감정의 유형과 강도에 관한 정보에 대응되는 맞장구표현 답변, 호칭표현답변, 대화요약답 변, 공감표현답변, 답변제시, 해결실시(해결방안실시, 정보제공, 작동제어명령) 정보를 출력하는 부분에서는,음성파일, 얼굴영상 파일, 해결방안 정보제공 파일, 작동제어명령을 출력함에 있어서 상기 사용자가 외부적으로 적극적으로 표현된 감정과 아직 표현되지 않은 내면 상태감정에 대응하는 공감표현의 수준과 강도에 관한 정보 를 포함하여 출력하는 부분; 조율된 사용자의 감정표현수준과 강도에 대응되는 공감표현형태를 포함하는 답변을 디스플레이 장치, 모터 제어 동작 장치, 시스템제어 장치, 네트워크 장치 중 적어도 하나의 장치를 통해 출력하는 부분; 을 포함한다. 본 발명은, 본 발명인 모범적 공감형 인공지능 대화시스템이 제공한 답변제시 및 해결실시 결과에 대한 만족여 부확인질문 표현을, 대화유형과 전달감정유형에 대응하는 만족여부확인질문 표현 답변문장을 형성하여 사용자에 게 확인하는 질문을 제시하는 부분에서는, 사용자의 대화내용에 포함된 감정표현언어 각각에 대하여 음성입력정보, 문자입력정보, 얼굴영상정보, 상태관찰 정보 중 적어도 하나 이상의 형태 내에서의 수집분석된 사용자의 감정의 유형과 강도에 관한 정보에 대응하는 강도의 만족여부 질문 표현문장을 포함하여 이루어지는 실시결과 만족여부 질문표현 답변문장을 형성하여 제시 하는 부분; 분석 분류된 사용자의 대화 대화유형과 전달감정유형에 대응하는 실시결과 만족여부 질문표현 답변문장 형성을, 저장된 감정표현언어 및 실시결과 만족여부 질문표현 문장 세트 중에서 만족여부 질문표현 답변문장을 선택하거 나 이를 수정하여 사용하거나 사용자가 직접 표현한 감정표현언어 단어를 사용하여 실시결과 만족여부 질문표현 답변문장을 형성하는 부분; 만족여부 질문표현의 문장이 포함된 실시결과 만족여부 질문표현 답변내용을 음성파일, 문자파일, 영상파일 중 적어도 하나 이상의 형태로 변환하여 사용자에게 제시하는 부분; 을 포함한다. 본 발명은, 본 발명인 모범적 공감형 인공지능 대화시스템이 제공한 답변제시 또는 해결실시, 이외에 추가정보 가 더 필요로 하는지 여부 또는 필요로 추가정보사항을, 대화유형과 전달감정유형에 대응하는 추가필요사항 질 문표현 답변문장을 형성하여 상기 사용자에게 질문을 제시하는 부분에서는, 사용자의 대화내용에 포함된 감정표현언어 각각에 대하여 음성입력정보, 문자입력정보, 얼굴영상정보, 상태관찰 정보 중 적어도 하나 이상의 형태 내에서의 수집분석된 사용자의 감정의 유형과 강도에 관한 정보에 대응하는 강도의 추가필요사항 질문 표현문장을 포함하여 이루어지는 추가필요사항 질문표현 답변문장을 형성하여 제시하 는 부분; 분석 분류된 사용자의 대화 대화유형과 전달감정유형에 대응하는 추가필요사항 질문표현 답변문장 형성을, 저장 된 감정표현언어 및 추가필요사항 질문표현 문장 세트 중에서 추가필요사항 질문표현 답변문장을 선택하거나 이 를 수정하여 사용하거나 사용자가 직접 표현한 감정표현언어 단어를 사용하여 추가필요사항 질문표현 답변문장 을 형성하는 부분; 추가필요사항 질문표현의 문장이 포함된 추가필요사항 질문표현 답변내용을 상기 음성파일, 문자파일, 영상파일 중 적어도 하나 이상의 형태로 변환하여 사용자에게 제시하는 부분; 을 포함한다. 본 발명은, 모범적 공감형 인공지능 대화 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저 장된 컴퓨터 프로그램을 제공한다. 본 발명은, 모범적 공감형 인공지능 대화 방법을 컴퓨터에 실행시키기 위한 프로그램이 기록되어 있는 것을 특 징으로 하는, 컴퓨터에서 판독 가능한 기록매체를 제공한다.본 발명은, 컴퓨터로 구현되는 인공지능의 모범적인 공감표현이 가능한 대화 시스템에 있어서, 컴퓨터에서 판독 가능한 명령을 실행하도록 구현되는 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 사용자의 대화내용을 인식하고 대화유형 및 감정전달 유형을 분석하여 대화유형을 정보요구형, 작동요구형, 사 실전달형, 감정전달형, 태도표현형 등 적어도 두개 이상의 유형으로 분류하고, 감정전달형은 다시 인정칭찬형, 공감위로형으로 2차 분류하고, 공감위로형은 다시 걱정공감형, 고통공감형으로 3차 분류하고, 상기 사용자의 대"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 10, "content": "화유형, 감정전달유형에 대응되는 답변 문장표현을 맞장구표현, 호칭표현, 대화요약표현, 공감표현, 대화촉진질 문표현, 실시결과 만족여부 질문표현, 추가정보필요 질문표현 등을 포함하는 모범적인 공감표현이 가능한 답변 문장으로 형성하고, 모범적인 공감표현이 가능한 답변문장에 해당되는 음성 파일, 문자파일, 영상 파일, 정보제 공 파일, 해결방안실시파일, 작동제어명령 중 적어도 하나 이상의 형태로 출력하고,"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 11, "content": "맞장구표현, 호칭표현, 대화요약표현, 공감표현, 대화촉진질문표현 등이 포함된 공감표현정도가 높은 형태의 답 변 제시 및 해결실시 내용의 문장이 포함된 답변제시의 출력; 정보제공, 해결방안실시, 실행작동제공 중 적어도 하나 이상의 형태의 해결실시를 출력함에 있어서, 상기 공감 표현이 가능한 답변형태의 제시 및 답변제시내용에 대응되는, 해결방안실시 파일, 정보제공 파일, 작동제어명령 정보를 함께 출력하여 장치의 제어를 통해 사용자가 요구한 상황에 대응하는 작동을 만들어 내는 것; 을 포함한다."}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예들에 따르면, 사용자의 대화 속에 포함된 사용자의 사고, 감정을 인식하고 분석하여 대화유형 및 감정전달유형을 파악하고, 대화유형을 정보요구형, 작동요구형, 사실전달형, 감정전달형, 태도표현형 등으로 1차 분류하고, 감정전달형은 인정칭찬형, 감정위로형 등으로 2차 분류하고, 감정위로형은 걱정공감형, 고통공감"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "형으로 3차 분류하여, 이에 대응하는 다양한 감정을 담은 공감표현 답변문장을 맞장구표현, 호칭표현, 대화요약 표현, 공감표현, 대화촉진질문표현, 실시결과 만족여부 질문표현, 추가필요사항 질문표현을 포함하는 답변문장 을 형성하여 제시하고, 답변을 음성파일, 시각파일, 정보제공파일, 해결실시파일, 작동제어명령 등 통합정보로 표현할 수 있는, 모범적 공감표현이 가능한 인공지능 시스템을 통해 사용자와 컴퓨터 간 공감적 정서적 교감을 불러일으킬 수 있는 인공지능대화 컴퓨터 시스템을 통해 평균적인 사람보다 더 공감적인 위로를 받을 수 있는, 모범적인 공감표현이 가능한 인공지능을 제공하여, 딥러닝으로 학습된 다수의 인간의 평균적인 답변을 축적한 기존의 인공지능 대화시스템보다 공감성이 훨씬 더 높은 공감표현 답변문구를 사용하는, 교육적이고 모범적인 인공지능 대화를 가능하게 하여, 산업계에서 사용되고 있는 수많은 인공지능 대화시스템의 사용자에게 거부함과 딱딱함을 없애고, 따뜻한 인간적인 위로, 공감, 친근감을 제공하는 효과가 있다."}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시의 구체적인 내용을 첨부된 도면을 참조하여 상세하게 설명한다. 도 2는 본 발명에 따른 대화 기반 인터페이스를 활용한 모범적 공감형 인공지능 대화시스템의 메인 서버의 내부 구성과 단말기(전자기기)의 구성을 도시한 도면이다. 본 발명인 모범적 공감형 인공지능 대화시스템은 본 발명에 따른 사용자와의 대화를 기반으로 동작하는 인터페 이스를 제공하는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치를 통해서도 구현 될 수 있고, 메인서버를 통해서 직접 구현될 수도 있다. 이때, 모범적 공감형 인공지능 대화시스템은 사용자의 감정에 대응하여 평균인보다 더 풍부하고 자연스러운 공감과 위로를 담은 공감적인 답변표현을 구현할 수 있다. 본 발명에 따른, 모범적 공감형 인공지능 대화 방법은 주로 위에서 설명한 모범적 공감형 인공지능 대화시스템 에 연결될 수 있는 단말기, 전자기기 장치를 통해 수행된다. 이때, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치에는 본 발명의 일실시 예에 따른 컴퓨터 프로그램이 설치 및 구동될 수 있고, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치는 구동된 컴퓨터 프로그램의 제어에 따라 본 발명에 따른 모범적 공감형 인공지능 대화 방법을 수행할 수 있다. 위에서 설명한 컴퓨터 프로그램은 컴퓨터로 구현되는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단 말기, 전자기기 장치와 결합되어 모범적 공감형 인공지능 대화 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장될 수 있다. 도 2의 실시 예의 가장 기초적인 형태로, 스마트홈이나 홈 네트워크 서비스와 같이 주택, 사무실, 공장 내의 장 치들을 연결하여 제어하는 방식 뿐만 아니라 네트워크를 통한 중앙의 메인 서버의 시스템 프로세서를 이용하여 제어하는 방식의 기술에서, 사용자와의 대화를 기반으로 동작하는 인터페이스를 제공하는, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서 버 플랫폼이 사용자의 발화에 따른 음성입력 정보뿐만 아니라 문자입력 정보, 관찰측정상태정보를 통 해 수신되는 작동요구형 지시에 대해 \"불 꺼줘\", \"청소해줘\", \"음악을 틀어줘\", \"영화를 보여줘\", \"온도를 내려 줘\" 등을 요구하는 사용자의 요구를 인식하고 분석하여, 주택, 사무실. 공장 내에서 모범적 공감형 인공지능 대 화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫 폼와 내부 네트워크를 통해 연계된 주택, 사무실, 공장 내 조명기기, 청소기기, 음향기기, 영상기기, 온도 조절장치 등의 전자제품의 전원, 작동상태를 제어하는 흐름도의 예를 나타내고 있다. 예를 들어, 주택, 사무실, 공장 내의 장치들은 위에서 설명한 주택, 사무실, 공장 내 조명기기, 청소기기, 음향 기기, 영상기기, 온도조절장치 외에도 텔레비전, PC(Personal Computer), 주변기기, 에어컨, 냉장고 등과 같은 가전제품을 비롯하여, 수도, 전기, 냉난방 기기 등과 같은 에너지소비장치, 도어록, 감시카메라 등과 같은 보안기기 등 온라인 상에서 연결되어 제어될 수 있는 다양한 장치들을 포함할 수 있다. 또한, 내부 네트워크는 이더넷, HomePNA, IEEE 1394와 같은 유선 네트워크 기술이나, 블루투스, UWB(ultra Wide Band), 지그비(ZigBee), Wireless 1394, Home RF와 같은 무선네트워크 기술 등이 활용될 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 주택, 사무실, 공장 내의 장치들 중 하나일 수 있다. 예를 들어, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감 형 인공지능 대화시스템 중앙 서버 플랫폼은 주택, 사무실, 공장 내에 구비된 인공지능 스피커, 대화 로봇, 로봇 청소기 등과 같은 장치들 중 하나일 수 있다. 또한, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인 공지능 대화시스템 중앙 서버 플랫폼은 컴퓨터 장치로 구현되는 고정형 단말기이거나 이동형 단말기일 수 있다. 단말기, 전자기기의 예를 들면, 스마트폰(smart phone), 휴대폰, 네비게이션, 컴퓨터, 노트북, 디지털방송 용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 태블릿 PC 등과 같은 사용 자의 모바일 기기일 수도 있다. 일례로 단말기, 전자기기는 무선 또는 유선 통신 방식을 이용하여 네 트워크를 통해 다른 전자기기 또는 개인비서 시스템과 통신할 수 있다. 사용자 단말기, 전자기기는 네트워크(N)를 통해 원격지의 서버에 접속하거나, 타 단말 및 서버와 연결 가 능한 컴퓨터, 휴대용 단말기 및 텔레비전 등으로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 웹 브라우저 (WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱(laptop) 등을 포함하고, 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobilecommunications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA, IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W- Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 등과 같은 모든 종류의 핸드헬 드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 또한, 텔레비전은 IPTV(Internet Protocol Television), 인터넷 TV(Internet Television), 스마트 TV(Smart Television) 등을 포함할 수 있다. 이처럼 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인 공지능 대화시스템 중앙 서버 플랫폼은 사용자의 감정을 인식하여 그에 대응되는 동작을 위해 각종 장치들과 연결 가능한 기능을 포함하는 기기라면 특별히 제한되지 않는다. 또한, 위에서 설명한 사용자의 모바일 기기들이 주택, 사무실, 공장 내의 장치들로서 포함될 수도 있다. 또한 도 2는 사용자와의 대화를 기반으로 동작하는 인터페이스를 제공하는 모범적 공감형 인공지능 대화시스템 에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼 이 사용자의 발화에 따른 음성입력 정보뿐만 아니라, 문자입력 정보, 관찰측정상태정보를 통해 수신되는 정보요구형 지시에 대해 \"내일 주식시세가 어떻게 될 것 같니?\"를 인식 및 분석하여 외부 네트워크를 통해 외부 서버로부터 내일의 주식시세에 대한 정보를 획득하고, 획득한 정보를 \"내일의 주식시세는...\"과 같이 음성, 영상, 작동제어명령으로 출력하는 예를 나타내고 있다. 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용하는 통신 방식뿐만 아니라 기기들간의 근거리 무선 통신 역시 포함될 수 있다. 예를 들어, 외부 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네트 워크, 링네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포함하 는 네트워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 도 2의 실시 예에서도 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모 범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 주택, 사무실, 공장 내의 장치들 중 하나이거나 사 용자의 모바일 기기 중 하나일 수 있으며, 사용자의 감정을 인식하여 처리하기 위한 기능과 외부 네 트워크를 통해 중앙 서버에 접속하여 외부 서버가 제공하는 서비스나 컨텐츠를 사용자에게 제공 하기 위한 기능을 포함하는 기기라면 특별히 제한되지 않는다. 이처럼, 본 발명에 따른, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화 기반 인터페이스를 통해 사용자의 문자 입력, 음성입력, 얼굴영상정보, 관찰측정상태정보 등을 포함하는 사용자 명령을 처리할 수 있는 기기라면 특별 히 제한되지 않을 수 있다. 상태관찰측정장치(134, 234)는 각종 복수의 센서를 포함하여 복수의 센서 각각에 지정된 다양한 물리량을 측정 또는 센싱한다. 상태관찰측정장치(134, 234)에는 서로 다른 물리량을 측정 가능한 다양한 유형의 센서를 포함한 다. 상태관찰측정장치(134, 234)는 예를 들어, 하나 이상의 형상감지 센서, 온도 센서, 하나 이상의 자이로 센 서, 광 센서, 하나 이상의 압력 센서, 가속도 센서, 근접 센서, 수분함량 센서, 알콜농도 센서, 이산화탄소 센 서 등을 포함하거나 그 중 일부를 포함할 수 있다. 예를 들어, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감 형 인공지능 대화시스템 중앙 서버 플랫폼은 직접 사용자의 감정을 인식 및 분석하여 그에 대응되는 동작 을 수행함으로써 사용자 명령을 처리할 수도 있으나, 실시 예에 따라 사용자의 감정 인식이나 분석, 사용자에게 제공될 음성, 영상, 관찰측정상태 정보를 합성, 조율, 종합 등의 처리를 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 이와 연계된, 모범적 공감형 인공지능 대화시스템 중앙 서버 플 랫폼을 통해 수행할 수도 있다. 도 2는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치들과 모범적인 공감표 현이 가능한 인공지능 시스템의 중앙 서버 플랫폼 및 외부서버의 정보 컨텐츠 및 서비스 제공를 나타 내고 있다. 도 3은 본 발명에 따른, 대화 기반 인터페이스를 활용한 모범적 공감형 인공지능 대화시스템 프로세서의 흐름도 를 도시한 도면이다. 도 4는 본 발명에 있어서, 모범적 공감형 인공지능 대화시스템의 사용자 대화정보 인식장치의 예를 도시한 도면 이다. 일례로, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치들은 주택, 사무실, 공장 내에 구비되는 장치들을 의미할 수 있으며, 적어도 앞서 설명한 모범적 공감형 인공지능 대화시스템에 연 결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼를 포 함할 수 있다. 이러한 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치들이나 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치들에 설치 및 구동되는 어플리케이션들(이하, 앱들)은 통신 연결장치, 인터페이스 커넥트를 통해 모범적 공감형 인공지능 대화시 스템의 중앙 서버 플랫폼을 거쳐서 외부의 클라우드 서버와 연계될 수 있다. 여기서 통신 연결장치, 인터페이스 커넥트는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치들이나 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장 치들에 설치 및 구동되는 앱들의 개발을 위한 SDK(Software Development Kit) 또는 개발 문서들을 개발자 들에게 제공할 수 있다. 또한, 통신 연결장치, 인터페이스 커넥트는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치들이나 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치들(10 0)에 설치 및 구동되는 앱들이 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼이 제공하는 기능들 을 활용할 수 있는 API(Application Program Interface)를 제공할 수 있다. 구체적인 예로, 개발자들은 통신연결장치, 인터페이스 커넥트가 제공하는 SDK(Software Development Kit) 또는 개발 문서를 이용하여 개발한 기기나 앱은 통신 연결장치, 인터페이스 커넥트가 제공하는 API를 이용하여 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼이 제공하는 기능들을 활용할 수 있게 된다. 여기서 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼은 대화 기반의 서비스를 제공하기 위한 기 능을 제공할 수 있다. 예를 들어, 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼은 수신된 음성입력 정보, 얼굴영상 정 보, 관찰측정상태 정보를 인식하고 분석하고, 출력될 정보를 합성하기 위한 문자정보처리장치(131, 231), 음성 처리장치(132, 232), 수신된 영상이나 동영상을 분석하여 처리하기 위한 영상처리장치(133, 233), 수신된 문자 입력 정보, 음성입력 정보, 얼굴영상 정보, 관찰상황 정보(134, 234)에 따라 알맞은 정보를 출력하기 위해 적절 한 대화를 결정하기 위한 대화분석장치(151, 251), 수신된 문자입력 정보, 음성입력 정보, 얼굴영상 정보, 관찰 측정상태 정보에 알맞은 기능을 추천하기 위한 대화유형 분류장치(160, 260) 및 공감표현 등 답변문장추천장치 (170, 270), 인공지능이 데이터학습을 통해 문장 단위로 언어를 번역할 수 있도록 지원하는 인공신경망 기반 기 계 번역(Neural Machine Translation, NMT) 등과 같이 대화 기반 서비스를 제공하기 위한 다양한 모듈들을 포함 할 수 있다. 예를 들어, 도 2에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모 범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 문자입력, 음성입력, 얼굴영상정보, 관찰측정상태정보 등을 통신 연결장치, 인터페이스 커넥트에서 제공하는 API를 이용하여 모범적 공감 형 인공지능 대화시스템의 중앙 서버 플랫폼으로 전송할 수 있다. 이 경우, 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼은 수신된 문자입력, 음성입력, 얼굴영상 정보, 관찰측정상태정보 등을 통해 상술한 대화정보 인식장치들(131 내지 134, 231 내지 234)을 활용하여 사용 자의 감정을 인식 및 분석할 수 있으며, 사용자의 감정에 따라 적절한 공감표현 답변의 음성과 영상 을 합성하여 제공하거나, 요구사항에 대한 정보제공, 해결방법실시를 제공하거나, 적절한 기계장비, 전자제품의 작동을 추천하거나 작동제어 명령을 출력할 수 있다. 또한, 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼은 모범적 공감형 인공지능 대화시스템에 연 결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼들로부 터, 서버가 보유하고 있는 정보를 벗어나는 범위의 정보의 제공을 요구받거나 서버가 보유한 정보를 보완, 확장 하기 위한 정보가 필요한 경우, 이를 수집하기 위해 외부 네트워크를 통해 정보검색 기능을 활용하여 제3자 컨 텐츠 개발자 또는 회사들이 제공하는 컨텐츠정보, 서비스를 연결하여 모범적 공감형 인공지능 대화시스템의 중 앙 서버 플랫폼에 기반으로 한, 더 확장되고 새로운 인공지능 대화 기반 기능을 구현할 수 있는 서비스를 제공 받을 수 있다. 예를 들어, 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼은 도 2의 문자입력, 음성입력, 얼굴영 상정보, 관찰측정상태정보 등을 외부 서버로 전송할 수 있고, 외부 서버는 네트워크를 통해 제공되는 API를 통해 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼으로부터 수신한 문자입력, 음성입력, 얼굴영상정보, 관찰측정상태정보 등을 통해 분석한 해결방안에 대한 답변의 정보를 모범적 공감형 인공지능 대 화시스템의 중앙 서버 플랫폼으로 전송할 수 있다. 이 경우, 앞서 설명한 바와 유사하게 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼은 모범적 공 감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스 템 중앙 서버 플랫폼들로부터 수신되는 문자입력, 음성입력, 얼굴영상정보, 관찰측정상태정보 등을 인식, 분석하여 추천답변어 저장 장치(140, 240)의 정보와 합성하여 적절한 공감표현 답변정보를 제공하거나문자입력, 음성입력, 얼굴영상정보, 관찰측정상태정보 등을 통해 처리되어야 할 공감표현 답변 추천문장 정보, 해결방안 정보에 대한 보완할 수 있는 정보, 기능을 외부 서버로부터 제공받을 수 있다. 일례로, 도 2에서, 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼는 모범적 공감형 인공지능 대 화시스템에 연결될 수 있는 단말기, 전자기기 장치들들을 통해 수신한 \"내일의 주식시세가 어떻게 될 것 같니?\"의 인식을 통해 수집되는 자연어를 수신하거나, 키워드 \"내일\" 및 \"주식시세\"를 수신할 수 있다. 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼는 문자입력, 음성입력, 얼굴영상, 관찰측정상태정 보 등을 통해 사용자가 요구하는 정보가 정확히 무엇인지를 인식하고, 문자입력, 음성입력, 얼굴영상정보, 관찰 측정상태정보 등의 수신을 통해 파악된 사용자의 정확한 대화유형과 요구정보 내용인 \"내일 주식시세는 어떻게 될 것 같니?\"를 네트워크 망을 통해 정보검색기능을 활용하여 외부 서버로 전송하고, 외부 서버로부 터 ‘내일 주식시세 예측’에 관한 분석정보를 전송받을 수 있다. 이 경우, 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼과 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치는 사용자로부터 수신한 자연어 \"내일 주식시세는 어떻게 될 것 같니?\", 또는 키워드 \"내일\" 및 \"주식시세\"와 문자입력, 음성입력, 얼굴영상정보, 관찰측정상태정보 및 외부 서버로부터 수신한 ‘내일 주식시세 예측’ 정보의 결합을 통해 \"내일의 주식 시세는...\"과 같은 문자파일, 음성파일, 영상파일 정보를 생성하여 입출력장치를 통해 다시 사용자에게 새롭게 생성된 정보를 전송할 수 있다. 이때, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치는 사용자로부터 수신한 문자입력, 음성입력, 얼굴영상정보, 관찰측정상태정보를 다른 문자입력, 음성입력, 얼굴영상정보, 관찰 측정상태정보와 합성하여 외부 서버로 제공할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 합성된 문자입력, 음성입력, 얼굴영상정보, 관찰측정상태정보를 통해 파악 분석된 사용자의 대화유형, 전달감정유형, 요구정보의 내용을 외부 서버로 전송할 수 있고, 외부 서버는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼로부터 얻은 사용자의 대화유형, 전달감정유형, 요구정보의 내용에 대한 답변 내용이나 해결방안 정보를 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼으로 전송할 수 있고, 모범적 공감형 인공지능 대 화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫 폼은 합성된 문자입력, 음성입력, 얼굴영상정보, 관찰측정상태정보에 대응하는 공감표현 답변과 외부 서버 로부터 수신한 요구정보에 대한 답변, 해결방안 정보 등을 결합해 \"내일의 주식 시세는 ...\"을 스피커, 디 스플레이, 기타 장치를 통해 출력함으로써, 사용자로부터 수신한 문자입력, 음성입력, 얼굴영상정보, 관찰 측정상태정보에 맞은 \"내일 주식 시세 예측\" 정보 요청에 대한 대답을 제공함과 아울러 공감표현 답변 문장을 추가적으로 제공하여 사람의 대화와 유사한 자연스럽고 공감적인 대화유형 실현할 수 있다. 이때, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인 공지능 대화시스템 중앙 서버 플랫폼은 문자입력, 음성입력, 얼굴영상정보, 관찰측정상태정보 등에 대응되 는 장치 작동이나 컨텐츠 정보제공 뿐만 아니라 공감표현 답변과 대화를 위해 본 발명에 따른 모범적인 공감표 현을 갖춘 공감적 인공지능 대화 방법을 수행할 수 있다. 도 2는 본 발명에 있어서, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템의 중앙 서버 플렛품의 내부 구성을 설명하기 위한 블록도이다. 도 2의 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인 공지능 대화시스템 중앙 서버 플랫폼와 앞서 설명한 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫 폼은 모범적인 공감표현이 가능한 인공지능 대화 서비스를 구현하는 하나의 컴퓨터 장치라고 할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼과 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼는 공통적으로 저장장치(140, 240), 프로세서(150, 250), 통신 연결장치(190, 290), 입출력 인터페이스(130, 230)를 포함 할 수 있다. 추천답변어 등 저장장치(140, 240)는 컴퓨터에서 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치(permanent massstorage device) 를 포함할 수 있다. 여기서 ROM과 디스크 드라이브와 같은 비소멸성 대용량 기록장치는 추천 답변어 등 저장장치(140, 240)와는 구 분되는 별도의 영구 저장 장치로서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장 치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼나 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼에 포함될 수도 있다. 또한, 추천답변어 등 저장장치(140, 240)에는 운영체제와 적어도 하나의 프로그램 코드(일례로 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중 앙 서버 플랫폼에 설치되어 특정 서비스의 제공을 위해 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼에서 구동되는 어플리케이션 등을 위한 코드)가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 추천답변어 등 저장장치(140, 240)와는 별도의 컴퓨터에서 판독 가능한 기록매 체로부터 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판독 가능한 기록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메 모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시 예에서 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록매체가 아닌 통신 연결 장치(190, 29 0)을 통해 추천답변어 등 저장장치(140, 240)에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또는 어플리케이션의 설치 파일을 배포하는 파일 배포 시스템이 네트워크를 통해 제공하는 파일들에 의해 설치되는 컴퓨터 프로그램(일례로 위에서 설명한 어플리케이션) 에 기반하여 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감 형 인공지능 대화시스템 중앙 서버 플랫폼의 추천답변어 등 저장장치(140, 240)에 로딩될 수 있다. 프로세서(150, 250)는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하 도록 구성될 수 있다. 명령은 추천답변어 등 저장장치(140, 240) 또는 통신 연결 장치(190, 290)에 의해 프로세서(150, 250)로 제공될 수 있다. 예를 들어 프로세서(150, 250)는 추천답변어 등 저장장치(140, 240)와 같은 기록 장치에 저장된 프로그램 코드 에 따라 수신되는 명령을 실행하도록 구성될 수 있다. 통신 연결 장치(190, 290)는 네트워크를 통해 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말 기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 서로 통신하기 위한 기능을 제공할 수 있으며, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 다른 외부 서버와 통신하기 위한 기능을 제공할 수 있다. 일례로, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼의 프로세서(150, 250)가 추천답변어 등 저장장치와 같은 기록 장치에 저장된 프로그램 코드에 따라 생성한 요청이 통신 연결 장치(190, 290)의 제어에 따라 네트워크를 통해 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼로 전달될 수 있다. 역으로, 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼의 프로세서의 제어에 따라 제공되는 제어 신호나 명령, 컨텐츠, 파일 등이 통신 연결 장치과 네트워크를 거쳐 모범적 공감형 인공지능 대 화시스템에 연결될 수 있는 단말기, 전자기기 장치 로 수신될 수도 있다. 모범적 공감형 인공지능 대화시 스템 중앙 서버 플랫폼의 통신 연결 장치과 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단 말기, 전자기기 장치의 통신 연결 장치을 통해 직접 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼과 수신할 수도 있다.예를 들어 통신 연결 장치을 통해 수신된 모범적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼의 제어 신호나 명령, 컨텐츠, 파일 등은 프로세서나 추천답변어 등 저장장치(140, 240)로 전달될 수 있고, 컨텐츠나 파일 등은 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범 적 공감형 인공지능 대화시스템 중앙 서버 플랫폼가 더 포함할 수 있는 저장 매체(위에서 설명한 영구저장 장치)로 저장될 수 있다. 입출력 인터페이스(130, 230)는 입출력 장치(120, 220)와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력장치는 마이크, 키보드 또는 마우스, 터치패드, 카메라, 상태관찰측정장치 등의 장치를, 그리고 출력장치는 디스플레이, 스피커와 같은 내부장치 및 외부장치를 포함할 수 있다. 다른 예로 입출력 인터페이스(130, 230)는 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와 의 인터페이스를 위한 수단일 수도 있다. 입출력 장치(120, 220)는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼과 하나의 장치로 구성될 수도 있다. 또한, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치의 입출력 인터페이스 는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치와 연결되거나, 모범 적 공감형 인공지능 대화시스템의 중앙 서버 플랫폼이 포함할 수 있는 입력 또는 출력을 위한 장치와의 인 터페이스를 위한 수단일 수 있다. 또한, 다른 실시 예들에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼 및 다른 외부 서버는 도 2의 구성요소들보 다 더 적은 또는 더 많은 구성요소들을 포함할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감 형 인공지능 대화시스템 중앙 서버 플랫폼은 위에서 설명한 입출력 장치(120, 220) 중 적어도 일부를 포함 하도록 구현되거나 또는 송수신기, GPS(Global Positioning System) 모듈, 카메라, 각종 센서, 데이터베이스 등 과 같은 다른 구성요소들을 더 포함할 수도 있다. 보다 구체적인 예로, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모 범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼이 스마트폰인 경우, 일반적으로 스마트폰이 포함하고 있는 가속도 센서나 자이로 센서, 카메라 모듈, 각종 물리적인 버튼, 터치패널을 이용한 버튼, 입출력 포트, 진 동을 위한 진동기 등의 다양한 구성요소들이 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전 자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼에 더 포함되도록 구현될 수 있 다. 본 실시 예들에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 음성입력을 수신하기 위한 마이크(132, 232) 또 는 사용자의 얼굴 영상을 수신하기 위한 카메라(133, 233), 키보드(131, 231), 관찰측정장치(134, 234)를 입출 력 장치(130, 230)로서 기본적으로 포함할 수 있으며, 사용자의 감정에 대응하는 음성이나 오디오 컨텐츠와 같 은 소리를 출력하기 위한 스피커, 사용자의 감정에 대응하는 감정 정보를 시각적으로 출력하기 위한 디스플레이, 사용자의 감정에 대응하는 동작 정보를 출력하기 위한 장치 중 적어도 하나 이상의 장치를 입출력 장치(131 내지 134, 231 내지 234)로서 더 포함할 수 있다. 도 6은 본 발명에 있어서, 모범적 공감형 인공지능 대화시스템의 사용자 대화에 대응하는 공감문장 표현장치의 예를 도시한 도면이다. 본 발명에 따른, 모범적 공감형 인공지능 대화 방법은 앞서 설명한 모범적 공감형 인공지능 대화시스템에 연결 될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼과 같은 컴퓨터 장치에 의해 수행될 수 있다. 이때, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자 기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼의 프로세서(150, 250)는 추천답 변어 등 저장장치(140, 240)가 포함하는 운영체제의 코드나 적어도 하나의 프로그램의 코드에 따른 제어 명령을실행하도록 구현될 수 있다. 여기서, 프로세서(150, 250)는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼에 저장된 코드가 제공하는 제어명령에 따 라, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공 지능 대화시스템 중앙 서버 플랫폼이 도 3의 모범적 공감형 인공지능 대화 방법이 포함하는 부분들을 수행 하도록 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인 공지능 대화시스템 중앙 서버 플랫폼를 서로 제어할 수 있다. 도 4에서 대화정보 인식부분(130, 230)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자 기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화 기반 인터페이스를 통해 사용자의 문자입력정보, 음성입력정보, 얼굴영상정보, 관찰측정상태정보 등을 수신할 수 있다. 예를 들어, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감 형 인공지능 대화시스템 중앙 서버 플랫폼은 대화 기반 인터페이스로서, 모범적 공감형 인공지능 대화시스 템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼 이 포함하는 마이크 또는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼과 연동된 마이크와 같은 음성입력 장치 (132, 232)를 통해 사용자의 발화에 따른 음성입력정보를 수신할 수 있고, 카메라와 같은 영상입력 장치(131, 231)를 통해 사용자의 발화에 따른 얼굴영상 정보, 상태관찰 정보 등을 수신할 수 있고, 키보드와 같은 문자입 력 장치(133, 233)를 통해 사용자의 발화에 따른 문자입력 정보를 수신할 수 있다. 대화정보 인식부분(130, 230)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화 기반 인터페이스를 통해 사용자의 얼굴영상 정보를 수신할 수 있다. 예를 들어, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감 형 인공지능 대화시스템 중앙 서버 플랫폼은 대화 기반 인터페이스로서, 모범적 공감형 인공지능 대화시스 템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼 이 포함하는 카메라 또는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼와 연동된 카메라와 같은 영상입력장치를 통해 사용자의 얼굴영상 정보를 수신할 수 있다. 대화정보 인식부분(130, 230)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화정보 인식부분(130, 230)에서 수신 된 음성입력정보, 문자정보, 영상정보, 관찰정보, 측정정보를 분석하여 사용자의 대화유형, 전달감정유형, 요구 정보 내용에 관한 정보를 수집할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 음성입력에 따른 문장 자체가 담고 있는 사용자의 대화유형, 전 달감정유형, 요구정보 내용을 인식하고 분석하여, 정보요구형, 작동요구형, 사실전달형, 감정전달형, 태도표현 형 등으로 분류하는 것으로, 일례로, 문맥자유문법 및 의존문법 등을 이용하여 사용자의 발화로부터 인식된 음 성에 대한 문장에 따른 사용자의 대화유형, 전달감정유형, 요구정보 내용을 분석할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 문맥자유문법을 이용하여 각 단어 또는 구문에 대한 의미 역할 및 각 단어 나 구문 사이의 문법적 연관관계를 파악할 수 있고, 의존문법을 이용하여 문장의 문법성 또는 의미적 유효성을 파악할 수 있다. 문장에 문맥자유문법이 적용되면 문장의 단어 또는 구문에 의미 역할이 부착되고 문장 전체에 대해 분석된 대화유형, 전달감정유형, 요구정보 내용을 파악할 수 있다. 위에서 설명한 문장에 의한 대화유형, 전달감정유형, 요구정보 내용을 수집하는 기술은 예시적인 것으로 이에 한정되는 것은 아니며, 이미 잘 알려진 다른 기술들을 이용하는 것 또한 가능하다. 대화정보 인식부분(130, 230)에서. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장 치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화정보 인식부분(130, 230)에서 수신된 음성입력의 문장에서 감정정보(문장감정정보)를 수집할 수 있다. 이때, 문장감정정보는 감정 종류와 감정 강도(감정 정도)를 포함할 수 있다. 감정을 나타내는 용어, 즉 감정표 현언어들은 사전에 정해지며 소정 기준에 따라 복수 개의 감정 종류(예컨대, 기쁨, 슬픔, 놀람, 고민, 괴로움, 불안, 공포, 혐오, 분노 등)로 분류되고 감정표현언어의 강약에 따라 복수 개의 강도 등급(예컨대, 1~10)으로 분류될 수 있다. 감정표현언어는 감정을 나타내는 특정 단어는 물론, 특정 단어를 포함한 구절이나 문장 등을 포함할 수 있다. 예를 들어, '사랑해요'나 '행복해요'와 같은 단어, 혹은 '너무너무 사랑해요'와 같은 구절이나 문장 등이 감정 표현언어의 범주에 포함될 수 있다. 일례로, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 문자입력, 음성입력에 따른 문장에서 형태소를 수집한 후 수집된 형태소에서 미리 정해진 감정표현언어를 수집하고, 얼굴영상정보, 관찰측정상태정보를 종합하여 수집 된 감정표현언어에 대응되는 사용자의 감정 종류와 감정 강도를 분류할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 문자입력, 음성입력의 문장에 복수 개의 감정표현언어가 포함된 경우 감정 표현언어가 속한 감정 종류와 감정 강도에 따라 가중치를 계산할 수 있고 이를 통해 문장의 감정정보에 대한 감 정벡터를 계산하여 해당 문장을 대표하는 감정정보를 수집할 수 있다. 상기한 문장감정정보를 수집하는 기술은 예시적인 것으로 이에 한정되는 것은 아니며, 이미 잘 알려진 다른 기 술들을 이용하는 것 또한 가능하다. 대화정보 인식 부분(130, 230)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장 치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화정보 인식 부분(130, 230)에서 수 신된 얼굴영상에서 감정정보(이하, '얼굴감정정보'라 칭함)를 수집할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 영상을 기반으로 얼굴표정으로부터 감정 종류와 감정 강도를 포함한 얼굴 감정정보를 수집할 수 있다. 얼굴 표정은 눈썹, 눈, 코, 입, 피부와 같은 얼굴 요소들의 변형이 일어날 때 발생하는 얼굴 근육의 수축에 의 하여 나타나며, 얼굴 표정의 강도는 얼굴 특징의 기하학적 변화 또는 근육 표현의 밀도에 따라서 결정될 수 있 다. 일례로, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 표정에 따른 특징을 수집하기 위한 관심영역(예컨대, 눈 영역, 눈썹 영역, 코 영역, 입 영역 등)을 수집한 후 관심 영역에서 특징점을 수집하고 특징점을 이용하여 일정한 특 징값을 결정할 수 있다. 특징값은 특징점 사이의 거리 등을 기반으로 사용자의 표정을 나타내는 특정한 수치에 해당한다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중 앙 서버 플랫폼은 결정한 특징값을 감정 감응치 모델에 적용하기 위하여 영상에 나타난 특징값에 대한 수 치의 정도에 따라 일정한 세기값을 결정하고, 미리 마련한 맵핑 테이블을 이용하여 각 특정값의 수치에 매칭하 는 일정한 세기값을 결정한다. 맵핑 테이블은 감정 감응치 모델에 따라 사전에 마련된다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있 는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 감정 감응치 모델과 세기값을 맵핑하고 해당 세기값을 감정 감응치 모델에 적용한 결과에 따라 결정한 감정의 종류와 강도를 수집할 수 있다. 상기한 얼굴 감정 정보를 수집하는 기술은 예시적인 것으로 이에 한정되는 것은 아니며, 이미 잘 알려진 다른 기술들을 이용하는 것 또한 가능하다. 대화정보 인식 부분(130, 230)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장 치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화정보 인식 부분(130, 230)에서 수 집된 문장감정정보와 대화정보 인식 부분(130, 230)에서 수집된 얼굴감정정보, 관찰측정상태정보를 종합하여 사용자 감정을 판단할 수 있다. 일례로, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 문장감정정보와 얼굴감정정보에 따라 가중치를 계산할 수 있고 이를 통해 종합적인 사용자 감정정보를 판단할 수 있다. 대화정보 인식 부분(130, 230)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장 치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화정보 인식 부분(130, 230)에서 수 집된 문장 대화유형과 대화정보 인식 부분(130, 230)에서 사용자의 표정, 동작, 태도에서 판단된 사용자 감정을 종합하여 사용자의 최종 대화유형, 전달감정유형, 요구정보의 내용을 판단할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 문장대화유형과 사용자 감정에 따라 가중치를 계산할 수 있고 이를 통해 문장 자체에서 나타나는 사전적 대화유형, 음성입력에 따른 문장에서 나타내는 감정, 얼굴영상의 표정과 동작, 태도 및 관찰측정상태정보에서 나타나는 감정을 종합하여 최종적인 대화 대화유형, 전달감정유형, 요구정보의 내용을 분석할 수 있다. 대화정보 분석 부분(151, 251)와 대화유형 분류 부분(160, 260)에서 모범적 공감형 인공지능 대화시스템에 연결 될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용 자의 최종 대화유형, 전달감정유형, 요구정보의 내용에 대응되는 공감표현 답변문장을 선택할 수 있다. 공감표현 답변문장은 대화유형과 전달감정유형 별로 복수 개의 공감표현 언어와 공감표현 답변문장 세트가 사전 에 정해질 수 있으며(140, 240), 이를 통해 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자 기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 최종 대화유형에 대 응하는 공감표현 언어와 공감표현 답변문장 세트 중 사용자가 표현한 감정표현언어와 동일하거나 유사한 감정표 현언어를 선택하고, 이에 해당하는 감정표현언어가 없으면, 그 다음 순위로는 이전에 선택된 횟수 등을 고려한 추천 방식을 하고 그 다음 순위로는 모범적인 감정표현언어를 추천하는 방식 등에 따라 공감표현 답변문장을 선 택할 수 있다. 더 나아가, 공감표현 답변문장은 감정 종류 및 감정 강도에 따라 소정 기준에 따라 분류될 수 있으며, 이를 통 해 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지 능 대화시스템 중앙 서버 플랫폼은 사용자의 최종 대화유형, 전달감정유형, 요구정보의 내용에 포함된 감 정 종류 및 감정 강도에 대응되는 공감표현 답변문장을 선택하는 것 또한 가능하다. 위에서 설명한 공감표현 답 변문장을 선택하는 기술은 예시적인 것으로 이에 한정되지 않으며, 학습을 통해 사용자의 최종 대화유형, 전달 감정유형, 요구정보의 내용에 따른 공감표현 답변문장을 생성하는 기술 등 이미 잘 알려진 다른 기술들을 이용 하는 것 또한 가능하다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 공감문장표현 부분(151, 251)와 대화촉진질문표현부분(175, 275), 실시결 과 만족확인질문부분(191, 291), 추가필요사항질문부분(192, 292)에서 선택된 사용자의 반응문장에서 감정정보 (반응감정정보)를 수집할 수 있다. 이때, 반응감정정보는 감정 종류와 감정 강도를 포함할 수 있다. 감정표현언어들은 사전에 정해지며 소정 기준 에 따라 복수 개의 감정 종류(예컨대, 기쁨, 슬픔, 놀람, 고민, 괴로움, 불안, 공포, 혐오, 분노 등)로 분류되 고 감정표현언어의 강약에 따라 복수 개의 강도 등급(예컨대, 1~10)으로 분류될 수 있다. 일례로, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 모범적 공감형 인공지능 대화시스템이 사용자에게 행한 질문에 대한 사용자의 반응문장에서 형태소를 수집한 후 수집된 형태소에서 사전에 정해진 감정표현언어를 수집하여 수 집된 감정표현언어에 대응되는 감정 종류와 감정 강도를 분류할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 반응문장에 복수 개의 감정표현언어가 포함된 경우 각각의 감정 표현언어에 따른 감정 종류와 감정 강도를 수집할 수 있다. 상기한 반응감정정보를 수집하는 기술은 예시적인 것으로 이에 한정되는 것은 아니며, 이미 잘 알려진 다른 기 술들을 이용하는 것 또한 가능하다.대화정보 인식 부분(130, 230), 대화정보 분석 부분(151, 251), 대화유형 분류 부분(160, 260)에서 모범적 공감 형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화정보 분석 부분(151, 251), 대화유형 분류 부분(160, 260)에서 판단된 사용자 감 정에 대응되는 외부적으로 적극적으로 표현된 감정과 아직 외부적으로 적극적으로 표현되지 않은 내면 상태감정 을 판단할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 문장감정정보와 얼굴감정정보, 동작감정정보, 태도감정정보를 종합하여 판 단한 사용자 감정에 대해, 외부적으로 적극적으로 표현한 감정정보와 내면적 상태감정을 판단하고 이를 조율한 최종적 감정에 대응하는 공감답변문장을 형성하여 제시할 수 있다. 이때, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인 공지능 대화시스템 중앙 서버 플랫폼은 사용자의 문자입력 정보, 음성입력 정보, 얼굴영상 정보, 관찰측정 상태정보 등을 실시간으로 추적분석하여 외부적으로 적극적으로 표현된 감정과 아직 외부적으로 적극적으로 표 현되지 않은 내면 상태감정을 판단할 수 있다. 외부적으로 적극적으로 표현된 감정과 아직 외부적으로 적극적으로 표현되지 않은 내면 상태감정에 대한 정보에 는 마찬가지로 감정 종류와 감정 강도가 포함될 수 있다. 예를 들어, 사용자가 슬픈 이야기를 하거나 슬픈 표정을 지으면 '슬픔'을, 놀라운 이야기를 하거나 놀란 표정을 지으면 '놀람'을 외부적으로 적극적으로 표현된 감정과 아직 외부적으로 적극적으로 표현되지 않은 내면 상태감 정으로 결정할 수 있다. 따라서, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 음성입력 또는 얼굴영상을 통해 실시간으로 판단되는 사용자 감정에 대해 외부적으로 적극적으로 표현된 감정과 아직 표현되지 않은 내면 상태감정을 실시간으로 결 정하고 조율하여 사용자의 현재의 감정유형에 대응하기 위한 공감표현 답변문장을 형성할 수 있다. 도 6은 본 발명에 있어서, 통합 공감표현 등 답변문장생성과정(170, 270)의 예를 도시한 도면이다. 공감표현 등 답변형성부분(170, 270)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기 기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 공감표현 등 답변결정부분(170, 270)에서 선택된 공감표현 반응 문장과, 실시결과만족확인질문부분(191, 291) 및 추가필요사항질문부분(192, 292)에서 수집된 반응감정정보, 그리고 대화인식부분(130, 230) 및 대화분석부분(151, 251)에서 판단된 외부적 으로 적극적으로 표현된 감정과 아직 외부적으로 적극적으로 표현되지 않은 내면 상태감정을 조합한 새로운 통 합 공감표현 답변문장 정보를 생성할 수 있다. 새로운 통합답변정보에는 시각적, 청각적, 촉각적 출력 등이 가능한 복수의 서로 다른 정보가 포함될 수 있으며, 일례로 음성답변, 표정정보, 동작정보, 태도정보, 관찰측정상태정보 등이 포함될 수 있다. 새로운 통합 답변정보를 생성하는 과정에서 대해서는 이하에서 구체적으로 설명하기로 한다. 답변제시 부분(176, 276)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 최종 대화유형, 전달감정유형, 요구정보의 내용에 대해 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼이 포함하는 스피커 또는 모범적 공감형 인공지능 대 화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫 폼과 연동된 스피커와 같은 음성출력 장치, 영상출력 장치(120, 220)를 통해 통합답변정보에 따른 음성답 변, 영상답변, 문자답변을 출력할 수 있다. 답변제시 부분(176, 276) 및 해결실시 부분(190, 280)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있 는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 최종 대화유형, 전달감정유형, 요구정보의 내용에 대해 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼이 포함하는 디스플 레이 또는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼과 연동된 디스플레이와 같은 영상출력장치를 통해 통합답변정보에따른 표정정보를 출력할 수 있다. 예를 들어, 영상출력장치는 대화 기반 인터페이스에 해당되는 소정의 캐릭터를 표시할 수 있고, 사용자의 문자 입력 정보, 음성입력 정보, 얼굴영상 정보, 관찰행동태도 정보에 대응하는 답변으로서 표정정보를 해당 캐릭터 에 반영할 수 있다. 해결실시 부분(190, 280)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 최종 대화유형, 전달감정유형, 요구정보의 내용에 대해 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼가 포함하는 모터제어 작동장치 또는 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중 앙 서버 플랫폼과 연동된 모터제어 작동장치를 통해 통합답변정보에 따른 음성정보, 표정정보, 동작정보, 요구한 정보에 대한 답변제시, 해결방안실시를 출력할 수 있다. 예컨대, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼이 대화 로봇인 경우 사용자의 최종 대화유형, 감정전달유형, 요구정보의 내용에 대응하는 통합답변정보에 따라 해 당 답변과 관련된 동작을 구현할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 공감표현 등 답변문장형성부분(170, 270)에서 조합한 통합답변정보를 각종 장치로 출력할 수 있으며, 예를 들어 공감표현 답변문장의 음성파일은 스피커로 출력될 수 있고, 공감표현 답변 문장에서 수집된 감정정보는 그에 대응하는 표정, 동작, 태도 영상이나 전기기기 등의 작동을 위해 디스플레이 장치와 모터제어 작동장치 중 적어도 하나 이상의 장치로 출력될 수 있다. 답변제시 부분(176, 276)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 공감표현 등 답변형성부분(170, 270)에 서 선택된 공감표현 등 답변문장을 포함한 답변제시를 음성파일, 영상파일로 변환하여 출력할 수 있다. 다시 말해, 모범적 공감형 인공지능 대화시스템에 연결될 수있는 단말기, 전자기기 장치는 입출력장치 (120, 220)를 통해 수집된 문자입력정보, 음성입력정보, 영상입력정보를 TTS(text to speech) 음성 합성기를 이 용하여 다른 유형의 음성파일, 문자파일, 영상파일로 변형하여 수집할 수 있고, 반대로 합성 형성된 공감표현 등 답변문장을 TTS 음성 합성기를 이용하여 영상정보파일, 문자정보파일, 음성정보파일로 변형하여 입출력장치 (120, 220)를 통해 출력할 수 있다. 대화촉진질문표현 부분(175, 275), 실시결과 만족확인질문부분(191, 291), 추가필요사항질문 부분(192, 292)에 서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지 능 대화시스템 중앙 서버 플랫폼은 사용자의 반응답변문장에 포함된 감정표현언어 각각에 대하여 음성파일, 영상파일, 관찰측정상태파일 내에서의 감정의 강도에 관한 정보를 수집할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 사용자의 반응답변문장의 음성파일, 영상파일, 관찰측정상태파일에서 감정 표현언어의 성격과 유형을 파악하여 전달감정의 유형, 대화유형을 변별할 수 있다. 예를 들어, 반응답변문장 ‘엄청 좋아해요.’, ‘아주 많이 사랑해요.’에서 감정의 강도에 해당되는 '엄청', '아주', ‘많이’ 및 ‘좋아해요.’, ‘사랑해요.’의 감정표현언어에 관한 정보를 각각 수집할 수 있다. 공감표현 등 답변형성부분(170, 270)에서 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기 기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화인식부분(130, 230), 대화정 보분석부분(151, 251)에서 수집된 대화유형별, 전달감정유형별 사용자 감정에 대응되는 외부적으로 적극적으로 표현된 감정과 아직 외부적으로 적극적으로 표현되지 않은 내면 상태감정 정보뿐만 아니라, 대화촉진질문표현 부분(175, 275), 실시결과 만족확인질문부분(191, 291), 추가필요사항질문 부분(192, 292)에서의 사용자의 반응 답변문장에서 수집된 반응감정정보, 반응답변문장의 음성파일, 영상파일, 관찰측성상태파일 내 감정표현언어별 감정의 강도에 관한 정보를 이용하여 새로운 통합 공감표현답변을 위한 조율, 수정과정을 수행할 수 있다. 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 대화촉진질문표현부분(175, 275)에서 수집한 문자입력정보, 음성입력정보,영상입력정보, 관찰측정상태정보로부터 분석한 대화유형별, 감정표현언어 별 감정의 강도에 관한 정보를 바탕으 로 형성된 공감표현 등 답변문장(170, 270)의 내용을 대화촉진질문표현부분(175, 275)에서 수집한 사용자의 반 응답변문장의 음성파일, 표정, 동작, 태도 영상파일정보, 반응답변문장에서 수집된 반응감정정보와 비교하여 공 감표현 등 답변문장제시부분(170, 270)의 공감표현 답변내용과 해결실시부분(190, 280)의 정보제공, 해결방안실 시, 동작제어 명령의 내용을 조율, 변경할 수 있다. 일례로, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼은 답변제시 부분(176, 276)에서 공감표현 답변문장 음성파일, 영상 파일이 출력 되기 전에 대화인식 부분(130, 230)에서 외부적으로 적극적으로 표현된 감정과 아직 표현되지 않은 내면 상태감정이 수집분석 되고, 대화정보분석 부분(151, 251)에서 외부적으로 적극적으로 표현된 감정과 아직 표현되지 않은 내면 상태감정이 반영 조율된 후 공감표현 등 답변형성부분(170, 270)에서 공감표현 답변문장 음 성 파일이 형성되고 답변제시 부분(176, 276)에서 공감표현 답변문장의 음성파일, 영상파일의 출력과 함께 감정 표현언어 별 감정의 강도에 관한 정보에 대응되는 강도에 해당하는 공감표현 답변문장이 출력되도록 하는 답변 출력 제어정보를 생성할 수 있고, 해결실시 부분(180, 280)에서 사용자의 최종 대화유형, 전달감정유형, 요구정 보의 내용에 대응되는 통합 공감표현 답변이 이루어지도록 상기한 답변 출력제어 정보, 전자기기 작동제어 명령 정보, 시스템작동 제어명령 정보와 함께 답변문장의 음성파일, 영상파일을 답변출력장치(예컨대, 음성출력장치, 영상출력장치, 모터제어 작동장치, 전자기기 작동장치, 시스템 작동장치 등)로 전달할 수 있다. 이때, 해결실시 부분(180, 280)에서 해결방안실시 출력장치(180, 280)에서는 전자기기 장치 별로 정해진 규칙에 따라 사용자의 최종 대화유형, 감정전달유형, 요구정보의 내용에 대응하는 공감표현 답변 데이터로서 통합 공감 표현 답변정보를 공감표현 답변 출력제어 정보에 맞게 출력할 수 있다. 도 8은 본 발명에 있어서, 모범적 공감형 인공지능 대화시스템의 사용자의 대화유형별 및 감정전달유형별 공감 답변 표현들의 통합답변정보의 유형들을 도시한 것이다. 도 9는 본 발명에 있어서, 본 발명과 현존 최고급 기술수준의 인공지능들의 답변의 내용 유형의 비교를 도시한 것이다. 도 10은 본 발명의 일실시 예에 있어서, 본 발명과 현존 최고급 기술수준의 인공지능인 구글 어시스턴트(특허등 록 제10-2394289호)의 답변 유형 및 답변내용의 비교를 도시한 것이다. 도 11은 본 발명의 일실시 예에 있어서, 본 발명과 현존 최고급 기술수준의 인공지능인 애플(시리)과 아마존(알 렉사)의 답변 유형 및 답변내용의 비교를 도시한 것이다. 도 12는 본 발명의 일실시 예에 있어서, 본 발명과 현존 최고급 기술수준의 인공지능인 네이버(클로버)(특허등 록 제1020342550000호)와 카카오(헤이 카카오)의 답변 유형 및 답변내용의 비교를 도시한 것이다. 도 13은 본 발명의 일실시 예에 있어서, 본 발명과 현존 최고급 기술수준의 인공지능인 삼성전자(빅스비)와 KT (기자 지니)(특허공개 제1020210106657호)의 답변 유형 및 답변내용의 비교를 도시한 것이다. 도 10 내지 도 13은 사용자가 표현한 음성입력 '내일 주식시세가 어떻게 될 것 같니?'(지시형, 정보요구형), ‘ 내방에 불을 켜줘!’(지시형, 작동요구형), ‘김과장은 나쁜 사람이야.’(대화형, 사실전달형), ‘나 오늘 상사 로부터 칭찬받았어.’(대화형, 감정전달형, 인정칭찬형), ‘나 오늘 회사 상사로부터 꾸중을 들었어.’(대화형, 감정전달형, 공감위로형)에 대해 생성된 본 발명과 현존 최고급 기술수준의 인공지능들의 답변유형 및 답변내용 의 비교를 나타낸 것이다. 도 10은 사용자의 음성입력 ‘내일 주식시세가 어떻게 될 것 같니?’(지시형, 정보요구형) 등에 대해 생성된 본 발명과 현존 최고급 인공지능 중 하나인 구글 어시스턴트(특허등록 제10-2394289호)의 답변유형 및 답변내용의 비교를 나타낸 것이다. 도 10은 사용자가 표현한 음성입력 '내일 주식시세가 어떻게 될 것 같니?'에 대해 답변문장으로 본 발명은 '네. (김영광)님. 내일 주식시세가 어떻게 될 것 같으냐는 질문이군요. 내일 주식시세가 궁금해 답답하시군요. 내일 주식시세 예측에 대해서 말씀드리겠습니다. '라고 답변제시표현을 한 후 검색정보를 제공한 후 ‘답변내용이 도 움이 되었습니까? 더 추가적으로 필요하신 사항은 없으세요?’라고 질문을 하였으나, 구글 어시스턴트는 답변문장으로 ‘다음 내용을 찾았습니다.’ 라고 말한 후 관련성이 희박한 검색정보를 제공 한 후 더 이상 아무런 응답이 없어, 사용자가 기계와 대화하는 딱딱하고 무미건조함을 느끼게 하였다. 도 11에서는 애플(시리)은 아무런 대답표현이 없이 관련성이 희박한 검색된 정보를 제공하였고, 아마존(알렉 사)도 아무런 답변제시표현이 없이 관련성이 희박한 검색된 정보를 제공하였다. 도 12에서는 네이버(클로버)(특허등록 제1020342550000호)는 ‘“내일 주식시세가 어떻게 될 것 같니?”에 대한 내용을 찾아봤어요.’라는 답변제시표현을 하고 관련성이 희박한 검색된 정보를 제공하였고, 카카오(헤이카카오)는 ‘오늘의 종목만 알려줄 수 있어요.’라는 답변제시표현만을 하고 아무런 검색정보도 제 공하지 않았다. 도 13의 예시에서는 삼성전자(빅스비)는 ‘“음 내일에 대한 주식정보를 찾을 수 없네요. 종목을 인터넷에서 검 색해볼까요.’라는 답변제시표현만을 하고 검색된 정보를 제공하지 않았고, KT(기가지니)는 ‘오늘의 종목만 알 려줄 수 있어요.’라는 답변제시표현만을 하고 아무런 검색정보도 제공하지 않았다. 본 발명은 음성입력 '내일 주식시세가 어떻게 될 것 같니?'에 대해 대화인식(130, 230) 후 대화유형, 전달감정 유형을 분석(151, 251)하고 분류한(160, 260) 후 사용자가 표현한 음성정보를 통해 대화유형을 지시형, 정보요"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "구형으로 판단하고 분류하여 이에 대한 맞장구표현(171, 271), 호칭표현(172. 272). 대화요약표현(173, 273), 공감표현표현(174, 274)을 한 후 답변제시표현(176, 276)을 하였다. 사용자가 표현한 음성입력 '내일 주식시세가 어떻게 될 것 같니?'에 대해 외부적으로 적극적으로 표현된 감정 [궁금함]과 아직 표현되지 않은 내면 상태감정[답답함]이 판단되고, 사용자의 대화 문장에 포함된 감정표현언어 에 대해 감정정보 [궁금함], 음성파일 내 감정의 강도에 관한 정보가 수집되어, 공감표현 등 문장형성 부분 (170, 270)에서 감정표현언어에 대해 감정정보 [답답함], 음성파일내 감정의 강도에 관한 정보에 대응하는 공감 표현 답변문장을 형성하여 제시하였다. 이에, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인 공지능 대화시스템 중앙 서버 플랫폼은 답변제시부분(176, 276)에서 답변문장 ‘내일 주식시세예측에 대해 서 말씀드리겠습니다.’의 음성파일을 출력하기에 앞서 사용자가 표현한 음성입력 '내일 주식시세가 어떻게 될 것 같니?'에 대해 대화인식부분(130, 230) 및 대화분석부분(151, 251)에서 바로 외부적으로 적극적으로 표현된 감정[궁금함]과 아직 적극적으로 표현되지 않은 내면 상태감정 [답답함]을 공감표현 답변문장으로 먼저 분석 수 집한 이후 이를 반영한 공감표현 답변문장 ‘내일 주식시세가 궁금해 답답하시군요.’를 공감표현 등 문장형성 부분(170, 270)에서 형성하여 그 음성파일을 출력한 후 답변제시부분(176, 276)에서 답변문장의 음성파일 ‘내 일 주식시세에 대해서 말씀드리겠습니다.’를 답변제시한 후에 해결실시부분(180, 280)에서 검색된 정보인 ‘내 일 주식시세 예측’에 관한 정보를 제공하는 출력을 하였습니다. 감정표현언어를 표현하는 공감표현 등 답변형 성부분(170, 270)에서 감정 [궁금함, 답답함]에 대응하는 공감표현 답변을 출력하고 이어 사용자의 감정 [궁금 함, 답답함]을 해결하기 위한 답변출력 제어정보, 감정표현언어에 대응하는 해결방안실시(180, 280) 및 전자기 기 작동에 필요한 동작제어명령 정보를 생성하였다. 도 10의 다른 예시는 사용자가 표현한 음성입력 ‘나 오늘 회사 상사로부터 꾸중을 들었어.’에 대해 생성된 본 발명과 현존 최고급 기술수준의 인공지능 중 하나인 구글 어시스턴트의 답변유형 및 답변내용의 비교를 나타낸 것이다. 도 10의 다른 예시에서는 사용자가 표현한 음성입력‘나 오늘 회사 상사로부터 꾸중을 들었어.’에 대해 답변문 장으로 본 발명은 '아 그랬군요. (김영광)님. 오늘 회사 상사로부터 꾸중을 들었군요. 많이 속상하셨겠네요. 그래서 어떻게 했어요? 회사 상사로부터 꾸중들어서 속상했을 경우에 해소하는 방법을 알려드리겠습니다.'라고 답 변제시표현을 한 후 검색정보를 제공한 후 ‘답변 내용이 도움이 되었습니까? 더 추가적으로 필요하신 사항은 없으세요?’라고 답변하였으나, 구글 어시스턴트는 답변문장으로 ‘검색된 결과입니다.’라고 답변제시표현을 한 후 사용자가 요구한 정보내용이나 공감표현 답변과 전혀 다른 정보인 엉뚱한 검색정보를 제공한 후 더 이상 아무런 응답이 없어, 사용자가 기계와 대화하는 딱딱하고 무미건조함을 느끼고 전혀 공감이나 위로를 얻지 못하 였다. 도 11에서는 애플(시리)은 아무런 답변제시표현이 없이 관련성이 희박한 검색된 정보를 제공하였고, 아마존(알 렉사)도 아무런 답변제시표현이 없이 관련성이 희박한 검색된 정보를 제공하였다. 도 12에서는 네이버(클로버)는 ‘“나 오늘 상사로부터 꾸중을 들었어.”에 대한 내용을 찾아봤어요.’라는 대 답제시표현을 하고 관련성이 희박한 검색된 정보를 제공하였고, 카카오(헤이카카오)는 ‘흥, 왜요?’라는 대화 촉진질문표현만을 하고 아무런 검색정보도 제공하지 않았다. 도 13에서는 삼성전자(빅스비)는 ‘적절한 답이 떠오르지 않네요.’라는 답변제시표현만을 하고 검색된 정보를 제공하지 않았고, KT(기가지니)는 ‘미안해요. 잘 이해하지 못했어요.’라는 답변제시표현만을 하고 아무런 검 색정보도 제공하지 않았다. 본 발명은 사용자가 표현한 음성입력 ‘나 오늘 회사 상사로부터 꾸중을 들었어.’에 대해 대화인식(130, 230) 후 대화유형, 전달감정유형을 분석(151, 251)하고 분류한(160, 260) 후 사용자가 표현한 음성정보를 통해 대화 유형을 대화형, 감정전달형, 공감위로형으로 판단하고 분류하고 이에 대한 맞장구표현(171, 271), 호칭표현"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "(172. 272). 대화요약표현(173, 273), 공감표현표현(174, 274)을 한 후 답변제시표현(176, 276)을 하였다. 사용자가 표현한 음성입력 '나 오늘 회사 상사로부터 꾸중을 들었어.'에 대해 외부적으로 적극적으로 표현된 감 정과 아직 표현되지 않은 내면 상태감정 [속상함, 우울함]이 판단되고, 사용자의 대화 문장에 포함된 감정표현 언어에 대해 감정 정보 [속상함], 음성파일 내 감정의 강도에 관한 정보가 수집 분석되어, 공감표현 등 답변문 장형성부분(170, 270)에서 감정표현언어에 대해 감정정보 [속상함], 음성파일 내 감정의 강도에 관한 정보에 대 응하는 공감표현 답변문장을 형성하여 제시하였다. 이에, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인 공지능 대화시스템 중앙 서버 플랫폼은 답변제시부분(176, 276)에서 답변문장 ‘회사 상사로부터 꾸중들어 서 속상했을 경우에 해소하는 방법을 알려드리겠습니다.’의 음성파일을 출력하기에 앞서 사용자가 표현한 음성 입력 ‘나 오늘 회사 상사로부터 꾸중을 들었어.’에 대해 대화인식부분(130,230) 및 대화분석부분(151, 251)에 서 바로 외부적으로 적극적으로 표현된 감정[속상함]과 아직 외부적으로 적극적으로 표현되지 않은 상태[우울함]를 먼저 분석 수집한 이후 이를 반영한 공감표현 답변문장을 ‘많이 속상하셨겠네요.’를 공감표현 등 답변문장형성부분(170, 270)에서 형성하여 그 음성파일을 출력한 후 답변제시부분(176, 276)에서 답변문장의 음성파일 ‘회사 상사로부터 꾸중들어서 속상했을 경우에 해소하는 방법을 알려드리겠습니다.’를 답변제시한 후에 해결실시부분(180, 280)에서 검색된 정보인 ‘회사 상사로부터 꾸중들어서 속상했을 경우에 해소하는 방법 ’에 대한 정보를 제공하는 출력을 하였습니다. 감정표현언어를 표현하는 공감표현 등 답변형성부분(170, 270) 에서 감정 [속상함, 우울함]에 대응하는 공감표현 답변을 출력하고 이어 사용자의 감정 [속상함, 우울함]을 해 결하기 위한 답변출력 제어정보, 감정표현언어에 대응하는 해결방안실시(180, 280) 및 전자기기 작동에 필요한 동작제어명령 정보를 생성하였다. 도 10의 또 다른 예시는 사용자가 표현한 음성입력 ‘나 오늘 상사로부터 칭찬을 받았어.’에 대해 생성된 본 발명과 현존 최고급 기술수준의 인공지능 중 하나인 구글 어시스턴트의 답변유형 및 답변내용의 비교를 나타낸 것이다. 도 10의 또 다른 예시에서는 사용자가 표현한 음성입력 ‘나 오늘 상사로부터 칭찬받았어.’에 대해 답변 문장 으로 본 발명은 ‘와. 대단하군요. (김영광)님. 오늘 회사상사로부터 칭찬을 받았군요. 엄청 기분이 좋았겠네요. (김영광님)이 참 부러워요. 어떻게 해서 칭찬받았어요? 다음에도 회사상사로부터 더 많이 칭찬받을 수 있은 방법을 알려드리겠습니다.'를 답변제시표현을 한 후 검색한 정보를 제공한 후 ‘답변 내용이 도움이 되 었습니까? 더 추가적으로 자랑할 사항은 없으세요?’ 라고 답변하였으나, 구글 어시스턴트는 답변문장으로 ‘죄송하지만 잘 알아듣지 못했습니다.’라고 답변한 후 사용자가 요구한 공감 표현 답변과 전혀 다른 엉뚱한 답변을 제공한 후 더 이상 아무런 응답이 없어, 사용자가 기계와 대화하는 딱딱 하고 무미건조함을 느끼고 전혀 공감이나 위로를 얻지 못하게 되었다. 도 11의 예시에서 애플(시리)은 아무런 답변제시표현이 없이 관련성이 희박한 검색된 정보를 제공하였고, 아마 존(알렉사)도 아무런 답변제시표현이 없이 관련성이 희박한 검색된 정보를 제공하였다. 도 12의 예시에서 네이버(클로버)는 ‘“나 오늘 상사로부터 칭찬을 받았어.”에 대한 내용을 찾아봤어요.’라 는 답변제시표현을 하고 관련성이 희박한 검색된 정보를 제공하였고, 카카오(헤이카카오)는 ‘정말 대단한데. 우리 친구는 최고.’라는 공감표현만을 하고 아무런 검색정보도 제공하지 않았다. 도 13의 예시에서 삼성전자(빅스비)는 ‘“적절한 답이 떠오르지 않네요.’라는 답변제시표현만을 하고 관련성 이 희박한 검색된 정보를 제공하였고, KT(기가지니)는 ‘죄송한데, 무슨 말씀인지 모르겠어요.’라는 답변제시 표현만을 하고 아무런 검색정보도 제공하지 않았다. 본 발명은 사용자가 표현한 음성입력 ‘나 오늘 회사 상사로부터 칭찬을 받었어.’에 대해 대화인식(130, 230) 후 대화유형, 전달감정유형을 분석(151, 251)하고 분류한(160, 260) 후 사용자가 표현한 음성정보를 통해 대화 유형을 대화형, 감정전달형, 인정칭찬형으로 판단하고 분류하고 이에 대한 맞장구표현(171, 271), 호칭표현"}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "(172. 272). 대화요약표현(173, 273), 공감표현표현(174, 274)을 한 후 답변제시표현(176, 276)을 하였다. 사용자가 표현한 음성입력 '나 오늘 회사 상사로부터 칭찬을 받았어.'에 대해 외부적으로 적극적으로 표현된 감 정과 아직 외부적으로 적극적으로 표현되지 않은 내면 상태감정 [기분이 좋음. 뿌듯함, 자랑스러움]이 판단되고, 사용자의 대화 문장에 포함된 감정표현언어에 대해 감정 정보 [기분이 좋음. 뿌듯함, 자랑스러움], 음성파일 내 감정의 강도에 관한 정보가 수집 분석되어, 공감표현 등 답변문장형성부분(170, 270)에서 감정표현 언어에 대해 감정 정보 [기분이 좋음. 뿌듯함, 자랑스러움], 음성파일 내 감정의 강도에 관한 정보에 대응하는 공감표현 답변문장을 형성하였다. 이에, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인 공지능 대화시스템 중앙 서버 플랫폼은 답변제시부분(186, 296)에서 답변문장 ‘다음에도 회사 상사로부터 더 많은 칭찬을 받을 수 있는 방법을 알려드리겠습니다.’의 음성파일을 출력하기에 앞서 사용자가 표현한 음성 입력 ‘나 오늘 회사 상사로부터 꾸중을 들었어.’에 대해 대화인식부분(130,230) 및 대화분석부분(151, 251)에 서 바로 외부적으로 적극적으로 표현된 감정 [기분이 좋음. 뿌듯함, 자랑스러움]를 먼저 분석 수집한 이후 이를 반영한 공감표현 답변문장을 ‘엄청 기분이 좋았겠네요. (김영광)님이 참 부러워요.’를 공감표현 등 답변문장 형성부분(170, 270)에서 형성하여 그 음성파일을 출력한 후 답변제시부분(176, 276)에서 답변문장의 음성 파일 ‘다음에도 회사 상사로부터 더 많은 칭찬을 받을 수 있는 방법을 알려드리겠습니다.’를 답변제시한 후에 해결 실시부분(180, 280)에서 검색된 정보인 ‘회사 상사로부터 더 많은 칭찬을 받는 방법’에 관한 정보를 제공하는 출력을 하게 됩니다. 감정표현언어를 표현하는 공감표현 등 답변형성부분(170, 270)에서 감정 [기분이 좋음, 뿌 듯함, 자랑스러움]에 대응하는 공감표현 답변을 출력하고 이어 사용자의 감정 [기분이 좋음, 뿌듯함, 자랑스러 움]을 해결하기 위한 답변출력 제어정보, 감정표현언어에 대응하는 해결방안실시(180, 280) 및 전자기기 작동에 필요한 동작제어명령 정보를 생성하였다. 따라서, 모범적 공감형 인공지능 대화시스템에 연결될 수 있는 단말기, 전자기기 장치 및 모범적 공감형 인공지능 대화시스템 중앙 서버 플랫폼는 사용자의 최종 대화유형, 전달감정유형에 대응하는 공감표현 등답변문장의 음성파일, 영상파일, 작동제어명령을 출력하는 과정에서 사용자가 표현한 음성입력정보, 영상입력정 보, 관찰측정상태정보의 특정영역에서 발현되는 사용자의 특정한 감정들을 음성형태, 디스플레이 형태, 동작형 태, 태도정보형태 등으로 표현할 수 있고, 답변표현의 음성파일, 영상파일, 문자파일을 출력하는 것과 동시에 사용자가 표현한 음성입력정보, 문자입력정보, 얼굴영상정보, 관찰측정상태정보를 통해 실시간으로 판단되는 사 용자 감정에 대해 공감적으로 대응하고 해결하기 위한 해결방안실시, 요구정보제시, 전자기기 작동제어 명령을 출력할 수 있다. 이처럼 본 발명의 실시 예들에 따르면, 사용자의 감정을 파악하여 이에 대응하는 다양한 감정을 음성정보, 시각 정보, 동작정보, 태도정보, 관찰측정상태정보 등 통합정보로 표현할 수 있는 환경을 통해 사용자-기계 간 공감 적 정서적 교감을 불러일으킬 수 있고, 평균적인 인간들보다 더 뛰어나고 따뜻하게 공감할 줄 아는 모범적 공감 형 인공지능 대화시스템을 구현할 수 있다. 도 14는 본 발명의 일실시 예에 있어서, 대화자의 전달감정유형에 따라 사전에 저장된 추천 공감표현 단어 예시 (칭찬공감형)를 도시한 것이다. 도 15는 본 발명의 일실시 예에 있어서, 대화자의 전달감정유형에 따라 사전에 저장된 추천 공감표현 단어 예시 (위로공감형1 - 걱정공감형)를 도시한 것이다. 도 16은 본 발명의 일실시 예에 있어서, 대화자의 전달감정유형에 따라 사전에 저장된 추천 공감표현 단어 예시 (위로공감형2 - 고통공감형)를 도시한 것이다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 하드웨어 구성요소와 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시 예들에서 설명된 장치 및 구성요소는, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지 털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적컴퓨터를 이용하여 구현될 수 있다. 처리장치는 운영체제 및 상 기 운영체제상에서 수행되는 하나 이상의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다."}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이해의 편의를 위하여, 처리장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리장치가 복수 개의 처리요소(processing element) 또는 복수 유형의 처리요소를 포함할 수 있다. 예를 들어, 처리장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리장치를 구성하거나 독립적으로 또는 결합적 (collectively) 으로 처리장치를 명령할 수 있다. 소프트웨어 또는 데이터는, 처리장치에 의하여 해석되거나 처리장치에 명령 또는 데이터를 제공하기 위하여, 어 떤 유형의 기계, 구성요소(component), 물리적 장치, 가상장치(virtual equipment), 컴퓨터 저장 매체 또는 장 치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody) 될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독가능 기록 매체에 저장될 수 있다. 실시 예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다.컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있 다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트 웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 이때, 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것 일 수도 있다. 또한, 매체는 단일 또는 수 개의 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM 및 DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용 해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수 행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 또한, 다른 매체의 예시로, 어플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하 는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다."}
{"patent_id": "10-2023-0035506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 또는 설명된 시스템, 구조, 장치, 회로 등 의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치 되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한다. 산업상 이용가능성 본 발명은, 딥러닝으로 학습된 다수의 인간의 평균적인 답변을 축적한 기존의 인공지능 대화시스템보다 공감성 이 훨씬 더 높은 공감표현 답변문구를 사용하는, 교육적이고 모범적인 인공지능 대화를 가능하게 하여, 산업계 에서 사용되고 있는 수많은 인공지능 대화시스템의 사용자에게 거부함과 딱딱함을 없애고, 따뜻한 인간적인 위 로, 공감, 친근감을 제공하는 것이다."}
{"patent_id": "10-2023-0035506", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명인 모범적 공감형 인공지능 대화시스템과 기존의 딥러닝에 기반한 인공지능 대화시스템의 차이점 을 비교한 도면이다. 도 2는 본 발명에 있어서, 단말기(전자기기) 및 모범적 공감형 인공지능 대화시스템의 메인 서버의 내부 구성을 설명하기 위한 블록도이다. 도 3은 본 발명에 따른, 모범적 공감형 인공지능 대화시스템의 구현과정을 나타내는 흐름도이다. 도 4는 본 발명에 따른, 문자, 음성, 영상, 관찰측정상태정보를 인식하는 기반의 인터페이스를 활용한 모범적 공감형 인공지능 대화시스템의 사용자 대화정보를 인식하는 장치들의 예를 도시한 도면이다. 도 5는 본 발명에 있어서, 모범적 공감형 인공지능 대화시스템의 사용자 대화정보를 분석하는 장치 및 대화유형 분류장치들의 예를 나타내는 도면이다. 도 6은 본 발명에 있어서, 모범적 공감형 인공지능 대화시스템의 사용자 대화에 대응하는 공감문장 표현장치들의 예를 나타내는 도면이다. 도 7은 본 발명에 있어서, 모범적 공감형 인공지능 대화시스템의 사용자 대화에 대한 해결방안실시의 제시장치 유형들의 예를 나타내는 도면이다. 도 8은 본 발명에 있어서, 모범적 공감형 인공지능 대화시스템의 사용자의 대화유형별 및 감정전달유형별 공감 답변 표현들의 예를 나타내는 도면이다. 도 9는 본 발명에 있어서, 본 발명과 현존 최고급 기술수준의 인공지능들의 답변의 내용 유형의 비교들을 나타 내는 것이다. 도 10은 본 발명의 일실시 예에 있어서, 본 발명과 현존 최고급 기술수준의 인공지능인 구글(특허등록 제10- 2394289호)의 어시스턴트의 답변 유형 및 답변내용의 비교의 예시들을 나타내는 것이다. 도 11은 본 발명의 일실시 예에 있어서, 본 발명과 현존 최고급 기술수준의 인공지능인 애플(시리)과 아마존(알 렉사)의 답변 유형 및 답변내용의 비교의 예시들을 나타내는 것이다. 도 12는 본 발명의 일실시 예에 있어서, 본 발명과 현존 최고급 기술수준의 인공지능인 네이버(클로버)(특허등 록 제1020342550000호)와 카카오(헤이 카카오)의 답변 유형 및 답변내용의 비교의 예시들을 나타내는 것이다. 도 13은 본 발명의 일실시 예에 있어서, 본 발명과 현존 최고급 기술수준의 인공지능인 삼성전자(빅스비)와 KT (기자 지니)(특허공개 제1020210106657호)의 답변 유형 및 답변내용의 비교의 예시들을 나타내는 것이다. 도 14는 본 발명의 일실시 예에 있어서, 대화자의 전달감정유형에 따라 사전에 저장된 추천 공감표현 단어 예시 들(칭찬 공감형)을 나타내는 것이다. 도 15는 본 발명의 일실시 예에 있어서, 대화자의 전달감정유형에 따라 사전에 저장된 추천 공감표현 단어 예시 들(위로 공감형1 - 걱정공감형)을 나타내는 것이다. 도 16은 본 발명의 일실시 예에 있어서, 대화자의 전달감정유형에 따라 사전에 저장된 추천 공감표현 단어 예시 들(위로 공감형2 - 고통공감형)을 나타내는 것이다."}
