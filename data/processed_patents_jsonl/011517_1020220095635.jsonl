{"patent_id": "10-2022-0095635", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0017665", "출원번호": "10-2022-0095635", "발명의 명칭": "전자 장치 및 그 촬영 이미지 획득 방법", "출원인": "삼성전자주식회사", "발명자": "응우옌 둑 부옹"}}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서, 카메라; 메모리; 및하나 이상의 프로세서;를 포함하며, 상기 하나 이상의 프로세서는, 상기 메모리에 저장된 적어도 하나의 명령을 실행함으로써,일정 시간 동안 연속 활영하여 복수의 이미지 프레임을 획득하도록 상기 카메라를 제어하고, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 포즈(pose) 정보에 기초하여 상기 복수의 이미지프레임 중 베스트 이미지 프레임을 식별하고, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 페이스(face) 형상 정보에 기초하여 상기 복수의오브젝트 각각의 베스트 페이스 이미지를 획득하고, 상기 식별된 베스트 이미지 프레임 및 상기 복수의 오브젝트 각각의 베스트 페이스 이미지를 병합하여 추천 이미지 프레임을 획득하는, 전자 장치."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 신체 포즈에 기초하여 상기 복수의 이미지 프레임각각에 대한 프레임 스코어를 획득하고, 상기 프레임 스코어가 가장 작은 이미지 프레임을 상기 베스트 이미지 프레임으로 식별하고, 상기 복수의 이미지 프레임 각각에 포함된 페이스 영역에 페이스 ID를 맵핑하여 상기 복수의 이미지 프레임 각각에서 각 페이스 ID에 대한 페이스 스코어를 획득하고,특정 페이스 ID에 대한 상기 페이스 스코어가 가장 작은 이미지 프레임에서 상기 특정 페이스 ID의 베스트 페이스 이미지를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 하나 이상의 프로세서는, 상기 복수의 이미지 프레임에 포함된 적어도 하나의 오브젝트 각각의 신체 포즈를 식별하고, 각 오브젝트에 대해 특정 이미지 프레임에 포함된 제1 포즈와 나머지 이미지 프레임들에 포함된 제2 포즈 간 포즈 차이 값을 획득하고, 상기 획득된 포즈 차이 값을 합산하여 상기 복수의 이미지 프레임 각각에 대한 프레임 스코어를 획득하는, 전자장치."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 하나 이상의 프로세서는, 공개특허 10-2024-0017665-3-각 오브젝트에 대해 특정 이미지 프레임에 포함된 제1 포즈와 나머지 이미지 프레임들에 포함된 제2 포즈를 동일한 사이즈로 정규화하고, 상기 정규화된 제1 포즈 및 상기 정규화된 제2 포즈를 하나의 좌표 원점(one origin of coordination)으로 이동시키고, 상기 제1 포즈에 포함된 키 포인트의 위치 및 상기 제2 포즈에 포함된 키 포인트의 위치 간 차이를 상기 포즈차이 값으로 획득하는, 전자 장치."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 하나 이상의 프로세서는, 상기 복수의 이미지 프레임 각각에서 각 페이스 ID에 대한 랜드마크를 식별하고, 각 페이스 ID에 대해 특정 이미지 프레임에 포함된 제1 랜드마크와 나머지 이미지 프레임들 간 제2 랜드마크의차이 값을 획득하고, 각 ID 페이스 별로 상기 획득된 랜드마크의 차이 값을 합산하여 상기 복수의 이미지 프레임 각각에 대한 페이스스코어를 획득하고, 특정 페이스 ID에 대한 상기 페이스 스코어가 가장 작은 이미지 프레임에서 상기 특정 페이스 ID의 베스트 페이스 이미지를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 하나 이상의 프로세서는, 각 페이스 ID에 대해 특정 이미지 프레임에 포함된 제1 랜드마크와 나머지 이미지 프레임들 간 제2 랜드마크를동일한 사이즈로 정규화하고, 상기 정규화된 제1 랜드마크 및 상기 정규화된 제2 랜드마크를 하나의 좌표 원점으로 이동시키고, 상기 제1 랜드마크에 포함된 키 포인트의 위치 및 상기 제2 랜드마크에 포함된 키 포인트의 위치 간 차이를 상기 차이 값으로 획득하는, 전자 장치."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서, 상기 하나 이상의 프로세서는, 상기 촬영이 이루어진 시점의 컨텍스트 정보를 획득하고, 상기 획득된 컨텍스트 정보의 타입에 대응되는 페이스 스코어를 가지는 이미지 프레임에서 상기 특정 페이스 ID의 베스트 페이스 이미지를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 베스트 이미지 프레임에 포함된 복수의 오브젝트의 페이스 ID 및 위치 정보를 식별하고, 상기 페이스 ID 각각에 대응되는 베스트 페이스 이미지를 식별하고, 상기 베스트 이미지 프레임, 상기 페이스 ID 각각에 대응되는 베스트 페이스 이미지 및 위치 정보를 학습된 인공 지능 모델에 입력하여 상기 추천 이미지 프레임을 획득하는, 전자 장치."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2024-0017665-4-제1항에 있어서, 디스플레이;를 더 포함하며, 상기 하나 이상의 프로세서는, 상기 추천 이미지 프레임 또는 상기 카메라를 통해 획득된 상기 복수의 이미지 프레임 중 어느 하나를 선택하기위한 UI 화면을 제공하도록 상기 디스플레이를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 제1 촬영 모드에서 상기 일정 시간 동안 연속 활영하여 복수의 이미지 프레임을 획득하도록 상기 카메라를 제어하거나, 제2 촬영 모드에서 촬영 시간 전후 기설정된 시간 간격으로 촬영하여 추가 이미지 프레임을 포함하는 상기 복수의 이미지 프레임을 획득하는, 전자 장치."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치의 촬영 이미지 획득 방법에 있어서, 카메라를 이용하여 일정 시간 동안 연속 활영하여 복수의 이미지 프레임을 획득하는 단계;상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 포즈(pose) 정보에 기초하여 상기 복수의 이미지프레임 중 베스트 이미지 프레임을 식별하는 단계;상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 페이스(face) 형상 정보에 기초하여 상기 복수의오브젝트 각각의 베스트 페이스 이미지를 획득하는 단계; 및 상기 식별된 베스트 이미지 프레임 및 상기 복수의 오브젝트 각각의 베스트 페이스 이미지를 병합하여 추천 이미지 프레임을 획득하는 단계;를 포함하는 촬영 이미지 획득 방법."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 베스트 이미지 프레임을 식별하는 단계는, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 신체 포즈에 기초하여 상기 복수의 이미지 프레임각각에 대한 프레임 스코어를 획득하는 단계; 및 상기 프레임 스코어가 가장 작은 이미지 프레임을 상기 베스트 이미지 프레임으로 식별하는 단계;를 포함하고, 상기 베스트 페이스 이미지를 획득하는 단계는, 상기 복수의 이미지 프레임 각각에 포함된 페이스 영역에 페이스 ID를 맵핑하여 상기 복수의 이미지 프레임 각각에서 각 페이스 ID에 대한 페이스 스코어를 획득하는 단계; 및 특정 페이스 ID에 대한 상기 페이스 스코어가 가장 작은 이미지 프레임에서 상기 특정 페이스 ID의 베스트 페이스 이미지를 획득하는 단계;를 포함하는, 촬영 이미지 획득 방법."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 베스트 이미지 프레임을 식별하는 단계는, 상기 복수의 이미지 프레임에 포함된 적어도 하나의 오브젝트 각각의 신체 포즈를 식별하는 단계;각 오브젝트에 대해 특정 이미지 프레임에 포함된 제1 포즈와 나머지 이미지 프레임들에 포함된 제2 포즈 간 포즈 차이 값을 획득하는 단계; 및공개특허 10-2024-0017665-5-상기 획득된 포즈 차이 값을 합산하여 상기 복수의 이미지 프레임 각각에 대한 프레임 스코어를 획득하는 단계;를 포함하는, 촬영 이미지 획득 방법."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 포즈 차이 값을 획득하는 단계는, 각 오브젝트에 대해 특정 이미지 프레임에 포함된 제1 포즈와 나머지 이미지 프레임들에 포함된 제2 포즈를 동일한 사이즈로 정규화하는 단계;상기 정규화된 제1 포즈 및 상기 정규화된 제2 포즈를 하나의 좌표 원점(one origin of coordination)으로 이동시키는 단계; 및 상기 제1 포즈에 포함된 키 포인트의 위치 및 상기 제2 포즈에 포함된 키 포인트의 위치 간 차이를 상기 포즈차이 값으로 획득하는 단계;를 포함하는, 촬영 이미지 획득 방법."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서, 상기 베스트 페이스 이미지를 획득하는 단계는, 상기 복수의 이미지 프레임 각각에서 각 페이스 ID에 대한 랜드마크를 식별하는 단계;각 페이스 ID에 대해 특정 이미지 프레임에 포함된 제1 랜드마크와 나머지 이미지 프레임들 간 제2 랜드마크의차이 값을 획득하는 단계; 각 ID 페이스 별로 상기 획득된 랜드마크의 차이 값을 합산하여 상기 복수의 이미지 프레임 각각에 대한 페이스스코어를 획득하는 단계; 및특정 페이스 ID에 대한 상기 페이스 스코어가 가장 작은 이미지 프레임에서 상기 특정 페이스 ID의 베스트 페이스 이미지를 획득하는 단계;를 포함하는, 촬영 이미지 획득 방법."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 차이 값을 획득하는 단계는, 각 페이스 ID에 대해 특정 이미지 프레임에 포함된 제1 랜드마크와 나머지 이미지 프레임들 간 제2 랜드마크를동일한 사이즈로 정규화하는 단계;상기 정규화된 제1 랜드마크 및 상기 정규화된 제2 랜드마크를 하나의 좌표 원점으로 이동시키는 단계; 및상기 제1 랜드마크에 포함된 키 포인트의 위치 및 상기 제2 랜드마크에 포함된 키 포인트의 위치 간 차이를 상기 차이 값으로 획득하는 단계;를 포함하는, 촬영 이미지 획득 방법."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서, 상기 베스트 페이스 이미지를 획득하는 단계는, 상기 촬영이 이루어진 시점의 컨텍스트 정보를 획득하고, 상기 획득된 컨텍스트 정보의 타입에 대응되는 페이스 스코어를 가지는 이미지 프레임에서 상기 특정 페이스 ID의 베스트 페이스 이미지를 획득하는, 촬영 이미지 획득 방법."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서, 상기 추천 이미지 프레임을 획득하는 단계는, 공개특허 10-2024-0017665-6-상기 베스트 이미지 프레임에 포함된 복수의 오브젝트의 페이스 ID 및 위치 정보를 식별하고, 상기 페이스 ID 각각에 대응되는 베스트 페이스 이미지를 식별하고, 상기 베스트 이미지 프레임, 상기 페이스 ID 각각에 대응되는 베스트 페이스 이미지 및 위치 정보를 학습된 인공 지능 모델에 입력하여 상기 추천 이미지 프레임을 획득하는, 촬영 이미지 획득 방법."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 추천 이미지 프레임 또는 상기 카메라를 통해 획득된 상기 복수의 이미지 프레임 중 어느 하나를 선택하기위한 UI 화면을 디스플레이하는 단계;를 더 포함하는, 촬영 이미지 획득 방법."}
{"patent_id": "10-2022-0095635", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서, 상기 복수의 이미지 프레임을 획득하는 단계는, 제1 촬영 모드에서 상기 일정 시간 동안 연속 활영하여 복수의 이미지 프레임을 획득하도록 상기 카메라를 제어하거나, 제2 촬영 모드에서 촬영 시간 전후 기설정된 시간 간격으로 촬영하여 추가 이미지 프레임을 포함하는 상기 복수의 이미지 프레임을 획득하는, 촬영 이미지 획득 방법."}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 전자 장치는, 카메라, 메모리 및 하나 이상의 프로세서를 포함하며, 하나 이상의 프로세 서는, 메모리에 저장된 적어도 하나의 명령을 실행함으로써, 일정 시간 동안 연속 활영하여 복수의 이미지 프레 임을 획득하도록 카메라를 제어하고, 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 포즈(pose) 정보에 기초하여 복수의 이미지 프레임 중 베스트 이미지 프레임을 식별하고, 복수의 이미지 프레임에 포함된 복수의 오 브젝트 각각의 페이스(face) 형상 정보에 기초하여 복수의 오브젝트 각각의 베스트 페이스 이미지를 획득하고, 식별된 베스트 이미지 프레임 및 복수의 오브젝트 각각의 베스트 페이스 이미지를 병합하여 추천 이미지 프레임 을 획득할 수 있다."}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 촬영 이미지 획득 방법에 관한 것으로, 더욱 상세하게는 연속 촬영된 이미지 프레임 에서 베스트 모멘트 프레임을 획득하는 전자 장치 및 그 촬영 이미지 획득 방법에 관한 것이다."}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 기술의 발달에 힘입어 다양한 유형의 전자 장치가 개발되고 있다. 특히, 더 새롭고 다양한 기능을 원하는 사용자의 니즈(needs)에 부합하기 위하여 카메라를 구비하는 장치에서 복수의 이미지를 연속 촬영하는 기능이 제공되고 있다.이 경우 복수의 촬영 이미지 중 최상의 이미지를 추천하는 기능이 요구된다."}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 전자 장치는, 카메라, 메모리 및 하나 이상의 프로세서를 포함하며, 상기 하나 이 상의 프로세서는, 상기 메모리에 저장된 적어도 하나의 명령을 실행함으로써, 일정 시간 동안 연속 활영하여 복 수의 이미지 프레임을 획득하도록 상기 카메라를 제어하고, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝 트 각각의 포즈(pose) 정보에 기초하여 상기 복수의 이미지 프레임 중 베스트 이미지 프레임을 식별한다. 또한, 하나 이상의 프로세서는, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 페이스(face) 형상 정보 에 기초하여 상기 복수의 오브젝트 각각의 베스트 페이스 이미지를 획득하고, 상기 식별된 베스트 이미지 프레 임 및 상기 복수의 오브젝트 각각의 베스트 페이스 이미지를 병합하여 추천 이미지 프레임을 획득한다. 또한, 상기 하나 이상의 프로세서는, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 신체 포즈에 기초하여 상기 복수의 이미지 프레임 각각에 대한 프레임 스코어를 획득하고, 상기 프레임 스코어가 가장 작은이미지 프레임을 상기 베스트 이미지 프레임으로 식별할 수 있다. 또한, 상기 하나 이상의 프로세서는,상기 복 수의 이미지 프레임 각각에 포함된 페이스 영역에 페이스 ID를 맵핑하여 상기 복수의 이미지 프레임 각각에서 각 페이스 ID에 대한 페이스 스코어를 획득하고, 특정 페이스 ID에 대한 상기 페이스 스코어가 가장 작은 이미 지 프레임에서 상기 특정 페이스 ID의 베스트 페이스 이미지를 획득할 수 있다. 또한, 상기 하나 이상의 프로세서는, 상기 복수의 이미지 프레임에 포함된 적어도 하나의 오브젝트 각각의 신체 포즈를 식별하고, 각 오브젝트에 대해 특정 이미지 프레임에 포함된 제1 포즈와 나머지 이미지 프레임들에 포함 된 제2 포즈 간 포즈 차이 값을 획득하고, 상기 획득된 포즈 차이 값을 합산하여 상기 복수의 이미지 프레임 각 각에 대한 프레임 스코어를 획득할 수 있다. 또한, 상기 하나 이상의 프로세서는, 각 오브젝트에 대해 특정 이미지 프레임에 포함된 제1 포즈와 나머지 이미 지 프레임들에 포함된 제2 포즈를 동일한 사이즈로 정규화하고, 상기 정규화된 제1 포즈 및 상기 정규화된 제2 포즈를 하나의 좌표 원점(one origin of coordination)으로 이동시키고, 상기 제1 포즈에 포함된 키 포인트의 위치 및 상기 제2 포즈에 포함된 키 포인트의 위치 간 차이를 상기 포즈 차이 값으로 획득할 수 있다. 또한, 상기 하나 이상의 프로세서는, 상기 복수의 이미지 프레임 각각에서 각 페이스 ID에 대한 랜드마크를 식 별하고, 각 페이스 ID에 대해 특정 이미지 프레임에 포함된 제1 랜드마크와 나머지 이미지 프레임들 간 제2 랜 드마크의 차이 값을 획득하고, 각 ID 페이스 별로 상기 획득된 랜드마크의 차이 값을 합산하여 상기 복수의 이 미지 프레임 각각에 대한 페이스 스코어를 획득하고, 특정 페이스 ID에 대한 상기 페이스 스코어가 가장 작은 이미지 프레임에서 상기 특정 페이스 ID의 베스트 페이스 이미지를 획득할 수 있다. 또한, 상기 하나 이상의 프로세서는, 각 페이스 ID에 대해 특정 이미지 프레임에 포함된 제1 랜드마크와 나머지 이미지 프레임들 간 제2 랜드마크를 동일한 사이즈로 정규화하고, 상기 정규화된 제1 랜드마크 및 상기 정규화 된 제2 랜드마크를 하나의 좌표 원점으로 이동시키고, 상기 제1 랜드마크에 포함된 키 포인트의 위치 및 상기 제2 랜드마크에 포함된 키 포인트의 위치 간 차이를 상기 차이 값으로 획득할 수 있다. 또한, 상기 하나 이상의 프로세서는, 상기 촬영이 이루어진 시점의 컨텍스트 정보를 획득하고, 상기 획득된 컨 텍스트 정보의 타입에 대응되는 페이스 스코어를 가지는 이미지 프레임에서 상기 특정 페이스 ID의 베스트 페이 스 이미지를 획득할 수 있다. 또한, 상기 하나 이상의 프로세서는, 상기 베스트 이미지 프레임에 포함된 복수의 오브젝트의 페이스 ID 및 위 치 정보를 식별하고, 상기 페이스 ID 각각에 대응되는 베스트 페이스 이미지를 식별하고, 상기 베스트 이미지 프레임, 상기 페이스 ID 각각에 대응되는 베스트 페이스 이미지 및 위치 정보를 학습된 인공 지능 모델에 입력 하여 상기 추천 이미지 프레임을 획득할 수 있다. 또한, 디스플레이를 더 포함하며, 상기 하나 이상의 프로세서는, 상기 추천 이미지 프레임 또는 상기 카메라를 통해 획득된 상기 복수의 이미지 프레임 중 어느 하나를 선택하기 위한 UI 화면을 제공하도록 상기 디스플레이 를 제어할 수 있다. 또한, 상기 하나 이상의 프로세서는, 제1 촬영 모드에서 상기 일정 시간 동안 연속 활영하여 복수의 이미지 프 레임을 획득하도록 상기 카메라를 제어하거나, 제2 촬영 모드에서 촬영 시간 전후 기설정된 시간 간격으로 촬영 하여 추가 이미지 프레임을 포함하는 상기 복수의 이미지 프레임을 획득할 수 있다. 일 실시 에에 따른 전자 장치의 촬영 이미지 획득 방법은, 카메라를 이용하여 일정 시간 동안 연속 활영하여 복 수의 이미지 프레임을 획득하는 단계, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 포즈(pose) 정보에 기초하여 상기 복수의 이미지 프레임 중 베스트 이미지 프레임을 식별하는 단계를 포함할 수 있다. 또한, 전자 장치의 촬영 이미지 획득 방법은, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 페 이스(face) 형상 정보에 기초하여 상기 복수의 오브젝트 각각의 베스트 페이스 이미지를 획득하는 단계 및 상기 식별된 베스트 이미지 프레임 및 상기 복수의 오브젝트 각각의 베스트 페이스 이미지를 병합하여 추천 이미지 프레임을 획득하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 전자 장치의 프로세서에 의해 실행되는 경우 상기 전자 장치가 동작을 수행하도록 하는 컴퓨터 명령을 저장하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 동작은, 카메라를 이용하여 일정 시간 동안 연속 활영하여 복수의 이미지 프레임을 획득하는 단계, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 포즈(pose) 정보에 기초하여 상기 복수의 이미지 프레임 중 베스트 이미지 프레임을 식별하는 단계를 포함할 수 있다. 또한, 상기 동작은, 상기 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 페이 스(face) 형상 정보에 기초하여 상기 복수의 오브젝트 각각의 베스트 페이스 이미지를 획득하는 단계 및 상기식별된 베스트 이미지 프레임 및 상기 복수의 오브젝트 각각의 베스트 페이스 이미지를 병합하여 추천 이미지 프레임을 획득하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 명세서에서 이용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 이용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 이용되는 일반적인 용어들을 선 택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부분에서 상 세히 그 의미를 기재할 것이다. 따라서 본 개시에서 이용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가 지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 이용될 수 있지만, 구성요소들은 용어들에 의해 한정되 어서는 안 된다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 이용된다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. A 또는 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 하나 이상의 프로 세서(미도시)로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 도 1에 따르면, 전자 장치는 카메라를 구비하거나, 외부 카메라(미도시)로부터 수신된 촬영 영상을 처리하는 장치로 구현될 수 있다. 일 예에 따라 전자 장치는 스마트폰, 태블릿 PC, 캠코더, 디지털 카메라, TV, 데스크탑 PC, 랩탑 PC, PDA, PMP(portable multimedia player), LFD(large format display), Digital Signage(디지털 간판), DID(Digital Information Display), 비디오 월(video wall) 등과 같이 카메라 기능 또는/및 영상 처리 기능을 가지는 장치라면 한정되지 않고 적용 가능하다. 다만, 이하에서는 설명의 편의 를 위하여 전자 장치가 카메라를 구비하는 경우를 상정하여 설명하도록 한다. 일 실시 예에 따르면, 전자 장치는 카메라를 이용하여 일정 시간동안 연속 촬영된 복수의 촬영 이미 지 프레임을 획득할 수 있다. 예를 들어, 전자 장치는 카메라를 이용하여 복수의 오브젝트, 예를 들 어 복수의 사람을 연속 촬영할 수 있다. 일 예에 따라 연속 촬영 모드에서 복수의 이미지 프레임이 촬영되거나, 일반 촬영 모드에서 촬영 시점 전후로 추가 이미지 프레임을 획득하여 복수의 연속된 촬영 이미지 프레임을 획 득할 수 있다. 또는 일 예에 따라 도 1에 도시된 같이 복수의 촬영 이미지 프레임 중 가장 안정적인 순간 이미 지 프레임을 획득하는 촬영 모드, 예를 들어 best stable moment mode에서 연속 촬영된 복수의 촬영 이미지 프 레임을 획득할 수 있다. 일 실시 예에 따르면, 전자 장치는 복수의 촬영 이미지 프레임에 기초하여 사용자가 원하는 가장 안정적인 이미지 프레임, 예를 들어, 베스트 모멘트 프레임을 획득할 수 있다. 예를 들어, 전자 장치는 복수의 촬영 이미지 프레임에 포함된 복수의 오브젝트의 포즈 및 페이스 형상에 기초하여 베스트 모멘트 프레임을 획득할 수 있다. 이하에서는 연속 촬영된 복수의 촬영 이미지 프레임에 기초하여 베스트 모멘트 프레임을 획득하는 다양한 실시 예에 대해 설명하도록 한다. 도 2a는 일 실시 예에 따른 전자 장치의 구성을 나타내는 도면이다. 도 2a에 따르면, 전자 장치는 카메라, 메모리 및 프로세서를 포함한다. 카메라는 기 설정된 이벤트에 따라 턴 온 되어 촬영을 수행할 수 있다. 카메라는 촬상된 영상을 전기 적인 신호로 변환하고 변환된 신호에 기초하여 영상 데이터를 생성할 수 있다. 예를 들어, 피사체는 반도체 광 학소자(CCD; Charge Coupled Device)를 통해 전기적인 영상 신호로 변환되고, 이와 같이 변환된 영상 신호는 증 폭 및 디지털 신호로 변환된 후 신호 처리될 수 있다. 다만, 카메라는 전자 장치의 구현 예에 따라 외부 장치에 구비되는 것도 가능하다. 메모리는 프로세서와 전기적으로 연결되며, 본 개시의 다양한 실시 예를 위해 필요한 데이터를 저장 할 수 있다. 메모리는 데이터 저장 용도에 따라 전자 장치에 임베디드된 메모리 형태로 구현되거나, 전자 장치에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 전자 장치의 구동을 위한 데이터의 경우 전자 장치에 임베디드된 메모리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드된 메모리 의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이 브(solid state drive(SSD)) 중 적어도 하나로 구현될 수 있다. 또한, 전자 장치에 탈부착이 가능한 메모 리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결가능한 외 부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 일 예에 따라 메모리는 전자 장치를 제어하기 위한 적어도 하나의 인스트럭션(instruction) 또는 인 스트럭션들을 포함하는 컴퓨터 프로그램을 저장할 수 있다. 다른 예에 따라 메모리는 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB), 외부 서버 (예를 들어 웹 하드) 등으로부터 수신된 촬영 영상을 저장할 수 있다. 일 실시 예에 따르면, 메모리는 본 개시에 따른 다양한 동작들에서 생성되는 데이터를 저장하는 단일 메모 리로 구현될 수 있다. 다만, 다른 실시 예에 따르면, 메모리는 상이한 타입의 데이터를 각각 저장하거나,상이한 단계에서 생성되는 데이터를 각각 저장하는 복수의 메모리를 포함하도록 구현될 수도 있다. 상술한 실시 예에서는 다양한 데이터가 프로세서의 외부 메모리에 저장되는 것으로 설명하였으나, 상 술한 데이터 중 적어도 일부는 전자 장치 또는 프로세서 중 적어도 하나의 구현 예에 따라 프로세서 내부 메모리에 저장될 수도 있다. 하나 이상의 프로세서(이하, 프로세서)는 카메라 및 메모리와 전기적으로 연결되어 전자 장치 의 전반적인 동작을 제어한다. 하나 이상의 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 여기서, 하나 또는 복수의 프로세서는 적어도 하나의 소프트웨어 또는 적어도 하나의 하드웨어 또는, 적 어도 하나의 소프트웨어 및 적어도 하나의 하드웨어의 조합으로 구현될 수 있다. 일 예에 따라 하나 이상의 프 로세서에 해당하는 소프트웨어 또는 하드웨어 로직이 하나의 칩 내에 구현될 수 있다. 다른 예에 따라 복수의 프로세서 중 일부에 해당하는 소프트웨어 또는 하드웨어 로직은 하나의 칩 내에, 나머지에 해당하는 소프트웨어 또는 하드웨어 로직은 다른 칩 내에 구현될 수 있다. 구체적으로, 프로세서는 메모리에 저장된 적어도 하나의 인스트럭션(instruction)을 실행함으로써, 본 개시의 다양한 실시 예에 따른 전자 장치의 동작을 수행할 수 있다. 일 실시 예에 따라 프로세서는 디지털 영상 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세서(microprocessor), GPU(Graphics Processing Unit), AI(Artificial Intelligence) 프로세서, NPU (Neural Processing Unit), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)), 또 는 커뮤니케이션 프로세서(communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 또한, 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, ASIC(application specific integrated circuit), FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 또한, 일 실시 예에 따른 신경망 모델을 실행하기 위한 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU(Neural Processing Unit)와 같은 인공 지능 전용 프로세서과 소프트웨어의 조합을 통해 구현될 수 있다. 프 로세서는, 메모리(미도시)에 저장된 기 정의된 동작 규칙 또는 신경망 모델에 따라, 입력 데이터를 처리하 도록 제어할 수 있다. 또는, 프로세서가 전용 프로세서(또는 인공 지능 전용 프로세서)인 경우, 특정 신경 망 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 예를 들어, 특정 신경망 모델의 처리에 특화된 하드 웨어는 ASIC, FPGA 등의 하드웨어 칩으로 설계될 수 있다. 프로세서가 전용 프로세서로 구현되는 경우, 본 개시의 실시 예를 구현하기 위한 메모리를 포함하도록 구현되거나, 외부 메모리를 이용하기 위한 메모리 처리 기능을 포함하도록 구현될 수 있다. 도 2b는 본 개시의 일 실시 예에 따른 전자 장치의 일 구현 예의 세부 구성를 나타내는 도면이다. 도 2b에 따르면, 전자 장치(100')는 카메라, 메모리, 프로세서, 디스플레이, 통신 인터페 이스, 사용자 인터페이스 및 출력부를 포함한다. 도 2b에 도시된 구성 중 도 2a에 도시된 구성 과 중복되는 구성에 대해서는 자세한 설명을 생략하도록 한다. 디스플레이는 자발광 소자를 포함하는 디스플레이 또는 비자발광 소자 및 백라이트를 포함하는 디스플레이 로 구현될 수 있다. 예를 들어, LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플레 이, LED(Light Emitting Diodes), PDP(Plasma Display Panel), QLED(Quantum dot light-emitting diodes) 등 과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 디스플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유 닛 등도 함께 포함될 수 있다. 한편, 디스플레이는 터치 센서와 결합된 터치 스크린, 플렉시블 디스플레이 (flexible display), 롤러블 디스플레이(rollable display), 3차원 디스플레이(3D display), 복수의 디스플레 이 모듈이 물리적으로 연결된 디스플레이 등으로 구현될 수 있다. 일 실시 예에 따라 프로세서는 베스트 모멘트 프레임 또는 카메라를 통해 획득된 복수의 이미지 프레임 중 어느 하나를 선택하기 위한 UI 화면을 제공하도록 디스플레이를 제어할 수 있다. 통신 인터페이스는 외부 장치와 통신을 수행하는 구성 요소일 수 있다. 예를 들어 통신 인터페이스는 AP 기반의 Wi-Fi(와이파이, Wireless LAN 네트워크), 블루투스(Bluetooth), 지그비(Zigbee), 유/무선LAN(Local Area Network), WAN(Wide Area Network), 이더넷(Ethernet), IEEE 1394, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), MHL(Mobile High-Definition Link), AES/EBU(Audio Engineering Society/ European Broadcasting Union), 옵티컬(Optical), 코액셜(Coaxial) 등과 같은 통신 방식 을 통해 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB 메모리), 외부 서버(예를 들어 웹 하드) 등으로부터 스트리밍 또는 다운로드 방식으로 영상 신호를 입력받을 수 있다. 여기서, 영상 신호는 SD(Standard Definition), HD(High Definition), Full HD 또는 Ultra HD 영상 중 어느 하나의 디지털 영상 신 호가 될 수 있으나 이에 한정되는 것은 아니다. 일 실시 예에 따라 통신 인터페이스는 외부 장치로부터 복 수의 이미지 프레임을 포함하는 촬영 영상을 수신할 수 있다. 사용자 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린으로 구현될 수 있다. 일 실시 예에 따라 사용자 인터 페이스는 촬영 모드를 선택하기 위한 사용자 명령, 촬영을 수행하기 위한 사용자 명령, UI 화면 상에서 특 정 이미지 프레임을 선택하기 위한 사용자 명령 등을 수신할 수 있다. 출력부는 음향 신호를 출력한다. 예를 들어, 출력부는 프로세서에서 처리된 디지털 음향 신호를 아날로그 음향 신호로 변환하고 증폭하여 출력할 수 있다. 예를 들어, 출력부는 적어도 하나의 채널을 출 력할 수 있는, 적어도 하나의 스피커 유닛, D/A 컨버터, 오디오 앰프(audio amplifier) 등을 포함할 수 있다. 일 예에 따라 출력부는 다양한 멀티 채널 음향 신호를 출력하도록 구현될 수 있다. 도 3은 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 흐름도이다. 도 3에 따르면, 전자 장치(100, 100')는 기 설정된 모드가 턴 온되면(S310), 일정 시간 동안 카메라를 통 해 복수의 이미지 프레임을 획득한다(S320). 예를 들어, 프로세서는 일정 시간 동안 연속 활영하여 복수의 이미지 프레임을 획득하도록 카메라를 제어할 수 있다. 예를 들어, 제1 촬영 모드에서 일정 시간 동안 연 속 활영하여 복수의 이미지 프레임을 획득하거나, 제2 촬영 모드에서 촬영 시간 전후 기설정된 시간 간격으로 촬영하여 추가 이미지 프레임을 포함하는 복수의 이미지 프레임을 획득할 수 있다. 여기서, 제1 촬영 모드는 best stable moment mode 또는 연속 촬영 모드 중 어느 하나일 수 있고, 제2 촬영 모드는 일반 촬영 모드일 수 있다. 이 후. 전자 장치는 복수의 이미지 프레임에 기초하여 추천 이미지 프레임 예를 들어, 베스트 모멘트 프레 임을 획득한다(S330). 일 예에 따라 프로세서는 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 포즈에 기초하여 복수의 이미지 프레임 중 베스트 이미지 프레임을 식별할 수 있다. 또한, 프로세서는 복수의 이미지 프레임에 포 함된 복수의 오브젝트 각각의 페이스 형상에 기초하여 복수의 오브젝트 각각의 베스트 페이스 이미지를 획득할 수 있다. 이 후, 프로세서는 식별된 베스트 이미지 프레임 및 복수의 오브젝트 각각의 베스트 페이스 이미 지를 병합하여 추천 이미지 프레임 예를 들어, 베스트 모멘트 프레임을 획득할 수 있다. 일 실시 예에 따르면, 프로세서는 복수의 이미지 프레임에 포함된 복수의 오브젝트 각각의 신체 포즈에 기 초하여 복수의 이미지 프레임 각각에 대한 프레임 스코어를 획득할 수 있다. 프로세서는 프레임 스코어가 가장 작은 이미지 프레임을 베스트 이미지 프레임으로 식별할 수 있다. 일 실시 예에 따르면, 프로세서는 복수의 이미지 프레임에 포함된 적어도 하나의 오브젝트 각각의 신체 포 즈를 식별하고, 각 오브젝트에 대해 특정 이미지 프레임에 포함된 제1 포즈와 나머지 이미지 프레임들에 포함된 제2 포즈 간 포즈 차이 값을 획득할 수 있다. 프로세서는 획득된 포즈 차이 값을 합산하여 복수의 이미지 프레임 각각에 대한 프레임 스코어를 획득할 수 있다. 일 예에 따르면, 프로세서는 복수의 이미지 프레임 각각에 포함된 페이스 영역에 페이스 ID를 맵핑하고 복 수의 이미지 프레임 각각에서 각 페이스 ID에 대한 페이스 스코어를 획득할 수 있다. 프로세서는 특정 페 이스 ID에 대한 페이스 스코어가 가장 작은 이미지 프레임에서 특정 페이스 ID의 베스트 페이스 이미지를 획득 할 수 있다. 일 예에 따르면, 프로세서는 복수의 이미지 프레임 각각에서 각 페이스 ID에 대한 랜드마크를 식별하고, 각 페이스 ID에 대해 특정 이미지 프레임에 포함된 제1 랜드마크와 나머지 이미지 프레임들 간 제2 랜드마크의 차이 값을 획득할 수 있다. 프로세서는 각 ID 페이스 별로 획득된 랜드마크의 차이 값을 합산하여 복수의 이미지 프레임 각각에 대한 페이스 스코어를 획득할 수 있다.도 4는 일 실시 예에 따른 베스트 모멘트 프레임 획득 방법을 설명하기 위한 흐름도이다. 도 4에 따르면, 프로세서는 첫번째 이미지 프레임이 획득되면(S410), 첫번째 이미지 프레임에 포함된 각 페이스 영역에 페이스 ID를 맵핑하고, 각 페이스 ID 별로 페이스 스코어를 산출할 수 있다(S420). 또한, 프로세 서는 첫번째 이미지 프레임에 포함된 오브젝트 각각의 포즈를 식별할 수 있다(S430). 이 경우, 프로세서 는 일 실시 예에 따라 연속 촬영으로 획득된 복수의 이미지 프레임 각각에 대해 S420 단계 및 S430 단계를 수행할 수 있다. 프로세서는 마지막 이미지 프레임까지 S420 단계 및 S430 단계가 수행되면(S450:Y), 각 페이스 ID에 대응 되는 베스트 페이스 이미지를 식별하고(S470), 오브젝트 각각의 포즈에 기초하여 베스트 이미지 프레임을 식별 한다(S480). 이 후, 프로세서는 베스트 페이스 이미지 및 베스트 이미지 프레임에 기초하여 베스트 모멘트 프레임 (best moment frame)을 획득할 수 있다(S490). 여기서, 베스트 모멘트 프레임은 가장 안정적인 순간 프레임이라 는 의미일 수 있다. 도 5, 도 6a 내지 도 6d는 일 실시 예에 따른 베스트 페이스 식별 방법을 구체적으로 설명하기 위한 도면들이다. 도 5에 따르면, 프로세서는 이미지 프레임에 포함된 각 페이스 영역에 페이스 ID를 맵핑할 수 있다(S510). 예를 들어, 프로세서는 도 6a에 도시된 바와 같이 첫번째 이미지 프레임에서 식별된 각 페이스 영역 (611, 612, 613)에 ID_1, ID_2, ID_3를 맵핑하고, 다음 이미지 프레임에서 각 페이스 ID에 대응되는 페이 스 영역(621, 622, 623)을 식별할 수 있다. 이어서, 프로세서는 각 페이스 ID에 대한 페이스 스코어를 산출할 수 있다(S520). 예를 들어, 프로세서 는 도 6b에 도시된 바와 같이 특정 페이스 ID에 대응되는 페이스 영역에서 랜드마크를 식별하고, 식별된 랜드마크의 포인트(이하, 랜드마크 포인트)에 기초하여 페이스 스코어를 산출할 수 있다. 일 예로, 도 6b에 도 시된 바와 같이 페이스 라인, 눈, 코, 입을 랜드마크로 식별하고, 각 랜드마크에서 기 설정된 간격으로 이격된 랜드마크 포인트를 식별할 수 있다. 예를 들어 도 6b에서는 랜드마크 포인트가 68개인 것으로 도시하였으나, 이 에 한정되는 것은 아니다. 또한, 프로세서는 랜드마크 포인트의 위치에 기초하여 페이스의 fullness, style, emotion 등을 식별할 수 있다. 이 후, 프로세서는 각 ID에 대한 페이스 스코어에 기초하여 각 오브젝트에 대해 가장 안정적인 페이스를 획득할 수 있다(S530). 일반적인 사용자는 일정 시간 동안 사진을 촬영할 때 특정 얼굴 형태와 얼굴 표정을 유 지하려고 하는 경향이 있다. 이에 따라 도 6c에 도시된 바와 같이 모든 이미지 프레임의 사용자 얼굴 중에서 가 장 안정적인 얼굴을 선택함으로써, 비정상적인 행동(abnormal behavior)을 제외시킬 수 있다. 일 실시 예에 따라 프로세서는 복수의 이미지 프레임 각각에서 각 페이스 ID에 대한 랜드마크를 식별하고, 각 페이스 ID에 대해 특정 이미지 프레임에 포함된 제1 랜드마크와 나머지 이미지 프레임들 간 제2 랜드마크의 차이 값을 획득할 수 있다. 프로세서는 각 ID 페이스 별로 획득된 랜드마크의 차이 값을 합산하여 복수의 이미지 프레임 각각에 대한 페이스 스코어를 획득할 수 있다. 이어서, 프로세서는 특정 페이스 ID에 대한 페이스 스코어가 가장 작은 이미지 프레임에서 특정 페이스 ID의 베스트 페이스 이미지를 획득할 수 있다. 구체적으로, 도 6d를 참고하면 프로세서는 각 페이스 ID에 대해 특정 이미지 프레임에 포함된 제1 랜드마 크와 나머지 이미지 프레임들 간 제2 랜드마크를 동일한 사이즈로 정규화하고, 정규화된 제1 랜드마크 및 정규 화된 제2 랜드마크를 하나의 좌표 원점으로 이동시킬 수 있다. 이어서, 프로세서는 제1 랜드마크에 포함된 키 포인트의 위치 및 제2 랜드마크에 포함된 키 포인트의 위치 간 차이를 랜드마크의 차이 값으로 획득할 수 있다. 예를 들어, 프로세서는 페이스 i에 대해 두 이미지 프 레임 j, k에서 두 랜드마크의 차이(랜드마크에서 키 포인트의 위치 간 차이) FDi,j,k를 산출할 수 있다. 이 후, 프로세서는 각 ID 페이스 별로 획득된 랜드마크의 차이 값을 합산하여 복수의 이미지 프레임 각각 에 대한 페이스 스코어를 획득할 수 있다. 예를 들어, 이미지 프레임 j에 포함된 사람의 페이스 스코어(FSj)는 이미지 프레임 j에 포함된 모든 페이스 i와 다른 이미지 프레임에 포함된 모든 페이스 i의 차이 값을 합산하여 산출될 수 있다. 예를 들어, 페이스 스코어(FSj)는 하기 수학식 1과 같이 산출될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 N은 모든 이미지 프레임의 합일 수 있다. 이 후, 프로세서는 특정 페이스 ID에 대한 페이스 스코어가 가장 작은 이미지 프레임(j_min)에서 특정 페 이스 ID에 대응되는 베스트 페이스 이미지를 획득할 수 있다. 예를 들어, 수학식 2와 같이 1에서 N까지의 이미 지 프레임 중 FSi,j가 가장 작은 이미지 프레임을 식별할 수 있다. 수학식 2"}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 7, 도 8a 내지 도 8c는 일 실시 예에 따른 베스트 이미지 프레임 식별 방법을 구체적으로 설명하기 위한 도 면들이다. 도 7에 따르면, 프로세서는 복수의 이미지 프레임에 포함된 오브젝트, 예를 들어 사람을 동일한 좌표 축으 로 변환할 수 있다(S710). 이어서, 프로세서는 복수의 이미지 프레임 사이의 차이 스코어(different score)를 산출할 수 있다(S720). 예를 들어, 프로세서는 각 사람들에게 오브젝트 ID를 할당하고 각 오브젝 트 ID에 해당하는 사람의 포즈 차이에 기초하여 포즈 차이 스코어를 산출할 수 있다. 프로세서는 복수의 이미지 프레임 즉, 모든 이미지 프레임 사이에서 각 사람의 포즈 차이 스코어를 합산하 여 복수의 이미지 프레임 각각에 대한 프레임 스코어를 산출할 수 있다(S730). 이어서, 프로세서는 프레임 스코어가 가장 작은 이미지 프레임을 베스트 이미지 프레임으로 식별할 수 있 다(S740). 일 실시 예에 따르면, 프로세서는 각 오브젝트에 대해 특정 이미지 프레임에 포함된 제1 포즈와 나머지 이 미지 프레임들에 포함된 제2 포즈를 동일한 사이즈로 정규화할 수 있다. 이어서, 프로세서는 정규화된 제1 포즈 및 정규화된 제2 포즈를 도 8a에 도시된 바와 같이 하나의 좌표 원점(one origin of coordination)으로 이 동시키고, 제1 포즈에 포함된 키 포인트의 위치 및 제2 포즈에 포함된 키 포인트의 위치 간 차이를 포즈 차이 값 즉, 포즈 차이 스코어로 획득할 수 있다. 예를 들어, 프로세서는 하기 수학식 3과 같이 포즈 차이 값을 산출할 수 있다. 수학식 3"}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, m, n은 이미지 프레임 인덱스이고, i는 오브젝트 인덱스일 수 있다. 이에 따라 poseIDmi는 이미지 프레 임 m에서 오브젝트 i의 포즈이고, poseIDni는 미지 프레임 n에서 오브젝트 i의 포즈일 수 있다. 일 예에 따라, 프로세서는 특정 이미지 프레임과 다른 이미지 프레임의 포즈 차이 값을 합산하여 프레임 스코어를 산출할 수 있다. 예를 들어, 프레임 스코어는 하기 수학식 4와 같이 산출될 수 있다. 수학식 4"}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, FSi는 이미지 프레임 i의 프레임 스코어이고, j는 다른 이미지 프레임의 인덱스일 수 있다. 예를 들어, 이미지 프레임들 간 포즈 차이 스코어는 도 8b에 도시된 표와 같이 정의될 수 있다. 프로세서는 상술한 바와 같이 각 이미지 프레임에 대한 프레임 스코어가 산출되면, 가장 작은 프레임 스코 어를 가지는 이미지 프레임을 베스트 이미지 프레임으로 식별할 수 있다. 상술한 바와 같이 베스트 이미지 프레임 및 각 오브젝트에 대한 베스트 페이스가 획득되면, 프로세서는 베 스트 이미지 프레임 및 각 오브젝트에 대한 베스트 페이스를 병합하여 베스트 모멘트 프레임을 획득할 수 있다. 도 9는 일 실시 예에 따른 베스트 모멘트 프레임 획득 방법을 설명하기 위한 도면이다. 일 실시 예에 따라 프로세서는 베스트 이미지 프레임(또는 베스트 이미지 프레임)에 포함된 복수의 오브젝 트의 페이스 ID 및 위치 정보를 식별할 수 있다(S910). 여기서, 위치 정보는 복수의 오브젝트의 좌표 정보일 수 있다. 이어서, 프로세서는 식별된 페이스 ID에 대응되는 베스트 페이스를 획득할 수 있다(S920). 프로세서는 베스트 이미지 프레임, 페이스 ID 각각에 대응되는 베스트 페이스 이미지 및 위치 정보를 학습 된 인공 지능 모델에 입력하여(S930), 베스트 모멘트 프레임을 획득할 수 있다(S940). 여기서, 인공 지능 모델 은 이미지 프레임, 페이스 이미지 및 프레임 상에서 페이스 위치 정보가 입력되면, 병합 프레임을 출력하도록 학습된 모델일 수 있다. 일 예에 따라 인공 지능 모델은 CNN (Convolutional Neural Network), DNN(Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등으로 구현될 수 있으나, 이에 한정되지 않는다. 일 실시 예에 따르면, 인공 지능 모델은 입력 훈련 데이터 및 출력 훈련 데이터 쌍에 기초하여 학습되거나, 입 력 훈련 데이터에 기초하여 학습될 수 있다. 여기서, 인공 지능 모델이 학습된다는 것은, 기본 인공 지능 모델 (예를 들어 임의의 랜덤한 파라미터를 포함하는 인공 지능 모델)이 학습 알고리즘에 의하여 다수의 훈련 데이터 들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공 지 능 모델이 만들어짐을 의미한다. 이러한 학습은 전자 장치를 통해 이루어질 수 있으나, 이에 한정되는 것 은 아니며 별도의 서버 및/또는 시스템을 통해 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습 (supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또 는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 다만, 학습된 인공 지능 모델을 이용하지 않고, 프로세서가 베스트 이미지 프레임, 페이스 ID 각각에 대응 되는 베스트 페이스 이미지 및 위치 정보에 기초하여 영상 처리를 통해 베스트 모멘트 프레임을 획득할 수 있음 은 물론이다. 도 10은 일 실시 예에 따른 셀피 모드에서의 베스트 모멘트 프레임 획득 방법을 설명하기 위한 도면이다. 도 10에 도시된 실시 예에 따르면, 셀피 모드에서 베스트 모멘트 모드가 턴 온되면(S1010), 프로세서는 일 정 시간 동안 전방 카메라를 통해 복수의 촬영 이미지, 즉 복수의 이미지 프레임을 획득할 수 있다(S1020). 이어서, 프로세서는 도 2 내지 도 9에서 설명한 다양한 실시 예를 통해 베스트 모멘트 프레임을 획득할 수 있다(S1030). 도 11은 일 실시 예에 따른 베스트 모멘트 프레임의 제공 방법을 설명하기 위한 도면이다. 도 11에 도시된 실시 예에 따르면, 베스트 모멘트 모드가 턴 온되면(S1110), 일정 시간 동안 복수의 촬영 이미 지, 즉 복수의 이미지 프레임을 획득할 수 있다(S1120).이어서, 프로세서는 도 2 내지 도 9에서 설명한 다양한 실시 예를 베스트 모멘트 프레임을 획득할 수 있다 (S1130). 이 후, 프로세서는 S1130 단계에서 획득된 베스트 모멘트 프레임을 오리지널 이미지 프레임, 예를 들어, 도 1120 단계에서 획득된 복수의 이미지 프레임과 비교할 수 있는 UI 화면을 제공할 수 있다(S1140). 이 경우 사용자는 베스트 모멘트 프레임 또는 복수의 이미지 프레임 중 어느 하나를 최종 이미지 프레임으로 선택할 수 있게 된다. 도 12는 일 실시 예에 따른 감정에 기초하여 베스트 모멘트 프레임을 획득하는 방법을 설명하기 위한 도면이다."}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "일 실시 예에 따르면, 프로세서는 베스트 모멘트 모드가 턴 온되면(S1210), 일정 시간 동안 복수의 촬영 이미지, 즉 복수의 이미지 프레임을 획득할 수 있다(S1220). 이어서, 프로세서는 도 2 내지 도 9에서 설명한 다양한 실시 예를 베스트 모멘트 프레임을 획득할 수 있다 (S1230). 이어서, 프로세서는 감정 기준(emotion criteria)이 존재하는 경우(S1240), 이모션 페이스 스코어에 기초 하여 이미지(예를 들어, 베스트 모멘트 프레임)의 컨텍스트를 식별할 수 있다(S1250). 여기서, 감정 기준이란 감정을 식별할 수 있는 다양한 기준을 의미하며, 예를 들어, 프로세서는 이미지 프레임에서 감정의 타입을 식별할 수 있는 임의의 기준이 있는지를 판단할 수 있다. 예를 들어, 감정의 타입 및 해당 감정에 타입에 해당 하는지 여부를 식별할 수 있는 기준이 있는 경우 감정 기준이 있는 것으로 판단할 수 있다. 이어서, 프로세서는 S1250 단계에서 식별된 컨텍스트에 가장 적합한 페이스를 식별할 수 있다(S1260). 예 를 들어, 프로세서는 컨텍스트가 \"happy, funny 또는 smiling\"로 식별되면, 가장 높은 이모션 스코어를 가 지는 페이스를 선택할 수 있다. 프로세서는 컨텍스트가 serious로 식별되면, 평균 스코어(median score)에 가장 가까운 이모션 스코어를 가지는 페이스를 선택할 수 있다. 또한, 프로세서는 컨텍스트가 \"sad 또는 unhappy\"로 식별되면, 가장 낮은 이모션 스코어를 가지는 페이스를 선택할 수 있다. 이 후, S1260 단계에서 식별된 페이스를 베스트 모멘트 프레임(또는 베스트 이미지 프레임)과 병합하여 최종 이 미지 프레임을 획득할 수 있다(S1270). 반면, 프로세서는 S1240 단게에서 감정 기준이 존재하지 않는 경우 추가 처리 없이 베스트 모멘트 프레임을 최종 이미지 프레임으로 선택할 수 있다(S1280). 다만, 상술한 실시 예에서는 베스트 모멘트 프레임을 획득한 후 컨텍스트를 식별하는 것으로 설명하였으나 반드 시 이에 한정되는 것은 아니다. 예를 들어, S1220 단계에서 복수의 이미지 프레임 중 적어도 하나에 기초하여 컨텍스트를 식별하고, 식별된 컨텍스트에 가장 적합한 페이스를 식별하여 베스트 모멘트 프레임을 획득하는 것 도 가능하다. 도 13은 일 실시 예에 따른 컨텍스트에 기초하여 베스트 모멘트 프레임을 획득하는 방법을 설명하기 위한 도면 이다. 일 실시 예에 따르면, 프로세서는 촬영이 이루어진 시점의 컨텍스트 정보를 획득하고, 획득된 컨텍스트 정 보의 타입에 대응되는 페이스 스코어를 가지는 이미지 프레임에서 특정 페이스 ID의 베스트 페이스 이미지를 획 득할 수 있다. 도 13에 따르면, 프로세서는 베스트 모멘트 모드가 턴 온되면(S1310), 일정 시간 동안 복수의 촬영 이미지, 즉 복수의 이미지 프레임을 획득할 수 있다(S1320). 이어서, 프로세서는 도 2 내지 도 9에서 설명한 다양한 실시 예를 베스트 모멘트 프레임을 획득할 수 있다 (S1330). 프로세서는 이미지 프레임에 포함된 아이들의 얼굴이 컨텍스트에 적합하지 않다고 판단되면(S1340), 아이 들의 사진을 별도로 촬영하고(S1350), 촬영된 사진에서 아이들 얼굴 위치를 검출한 후(S1360), 아이들 얼굴을 베스트 모멘트 프레임과 병합하여 최종 이미지 프레임을 획득할 수 있다(S1370). 이는 아이들의 경우 컨텍스트 에 적합한 얼굴 표정을 유지하는 것이 어려울 수 있기 때문이다. 일 예에 따라 프로세서는 S1330 단계에서 획득된 베스트 모멘트 프레임 및/또는 S1320 단계에서 획득된 복 수의 이미지 프레임에 기초하여 컨텍스트를 식별할 수 있다. 또한, 프로세는 도 12에서 설명한 이모션 스 코어에 기초하여 아이들의 얼굴이 컨텍스트에 적합한지 여부를 식별할 수 있다. 또는, 프로세서는 사용자명령에 기초하여 아이들의 얼굴이 컨텍스트에 적합한지 여부를 식별할 수 있다. 다만, 상술한 실시 예에서는 베스트 모멘트 프레임을 획득한 후 컨텍스트를 식별하는 것으로 설명하였으나 반드 시 이에 한정되는 것은 아니다. 예를 들어, S1320 단계에서 복수의 이미지 프레임 중 적어도 하나에 기초하여 컨텍스트를 식별하고, 식별된 컨텍스트에 가장 적합한 페이스를 식별하여 베스트 모멘트 프레임을 획득하는 것 도 가능하다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 어플리케이션 형태 로 구현될 수 있다. 또는 상술한 본 개시의 다양한 실시 예들에 따른 방법들 중 적어도 일부는 딥 러닝 기반의 인공 지능 모델 즉, 학습 네트워크 모델을 이용하여 수행될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또 는 하드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실 시 예들에 따른 전자 장치(예: 전자 장치(A))를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세 서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저 장 매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신 호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시 적으로 저장됨을 구분하지 않는다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2022-0095635", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2022-0095635", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 도 2a는 일 실시 예에 따른 전자 장치의 구성을 나타내는 도면이다. 도 2b는 본 개시의 일 실시 예에 따른 전자 장치의 일 구현 예의 세부 구성를 나타내는 도면이다. 도 3은 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 흐름도이다. 도 4는 일 실시 예에 따른 베스트 모멘트 프레임 획득 방법을 설명하기 위한 흐름도이다. 도 5, 도 6a 내지 도 6d는 일 실시 예에 따른 베스트 페이스 식별 방법을 설명하기 위한 도면들이다. 도 7, 도 8a 내지 도 8c는 일 실시 예에 따른 베스트 이미지 프레임 식별 방법을 설명하기 위한 도면들이다. 도 9는 일 실시 예에 따른 베스트 모멘트 프레임 획득 방법을 설명하기 위한 도면이다. 도 10은 일 실시 예에 따른 셀피 모드에서의 베스트 모멘트 프레임 획득 방법을 설명하기 위한 도면이다. 도 11은 일 실시 예에 따른 베스트 모멘트 프레임의 제공 방법을 설명하기 위한 도면이다. 도 12는 일 실시 예에 따른 감정에 기초하여 베스트 모멘트 프레임을 획득하는 방법을 설명하기 위한 도면이다. 도 13은 일 실시 예에 따른 컨텍스트에 기초하여 베스트 모멘트 프레임을 획득하는 방법을 설명하기 위한 도면 이다."}
