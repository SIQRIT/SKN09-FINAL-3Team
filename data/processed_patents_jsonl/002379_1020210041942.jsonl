{"patent_id": "10-2021-0041942", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0120400", "출원번호": "10-2021-0041942", "발명의 명칭": "엣지 인공지능의 표적 추론 방법", "출원인": "(주)솔빛시스템", "발명자": "김영구"}}
{"patent_id": "10-2021-0041942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라 모듈로부터 프레임 순서 정보를 포함하는 일련의 이미지 데이터들을 수신하고, 상기 수신된 이미지 데이터를 미리 설정된 영상 코덱에 따라 변환하고, 영상 데이터를 포함하는 프레임 데이터를 생성하는 영상편집모듈로서,상기 영상편집모듈은, 표적추론모듈로부터 수신한 표적 정보를 포함하는 프레임 데이터를 생성하되, 상기 표적추론모듈이 표적 정보를 생성할 때 사용된 분석 대상 이미지의 프레임 순서 정보에 대응한 프레임 데이터에 상기 표적 정보를 포함시키는 것을 특징으로 하는, 영상편집모듈."}
{"patent_id": "10-2021-0041942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 프레임 데이터는 NAL 유닛(Network Abstraction Layer Unit)이고,상기 영상편집모듈은, 상기 표적추론모듈이 표적 정보를 생성할 때 사용된 분석 대상 이미지의 프레임 순서 정보에 대응하여 SEI NAL 유닛을 생성하는 것을 특징으로 하는, 영상편집모듈."}
{"patent_id": "10-2021-0041942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 영상편집모듈은 미리 설정된 프레임 순서 정보에 따라 표적 정보를 포함하는 프레임 데이터를 생성하는,영상편집모듈."}
{"patent_id": "10-2021-0041942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 영상편집모듈은 상기 카메라 모듈로부터 상기 표적추론모듈이 표적 정보를 생성할 때 사용된 분석 대상 이미지의 프레임 순서 정보를 수신하고, 수신된 분석 대상 이미지의 프레임 순서 정보를 이용하여 표적 정보를 포함하는 프레임 데이터를 생성하는, 영상편집모듈."}
{"patent_id": "10-2021-0041942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 영상편집모듈은 상기 표적추론모듈로부터 수신한 표적 정보 내에 포함된 분석 대상 이미지의 프레임 순서정보를 이용하여 표적 정보를 포함하는 프레임 데이터를 생성하는, 영상편집모듈."}
{"patent_id": "10-2021-0041942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1 내지 5 중 어느 한 청구항에 따른 영상편집모듈;전방을 촬영하여 이미지 데이터를 출력하는 카메라 모듈; 및상기 카메라 모듈로부터 분석 대상 이미지를 수신하고, 분석 대상 이미지를 이용하여 표적 정보를 생성하는 표적추론모듈;을 포함하는 감시 장치."}
{"patent_id": "10-2021-0041942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "에 따른 감시 장치; 및상기 감시 장치로부터 데이터를 수신하는 중앙 관제 장치;를 포함하는 엣지 인공지능 시스템."}
{"patent_id": "10-2021-0041942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "영상편집모듈, 전방을 촬영하여 이미지 데이터를 출력하는 카메라 모듈 및 상기 카메라 모듈로부터 분석 대상이미지를 수신하고 분석 대상 이미지를 이용하여 표적 정보를 생성하는 표적추론모듈을 포함하는 감시 장치가영상을 편집하는 방법으로서, (a) 상기 영상편집모듈이 상기 카메라 모듈로부터 프레임 순서 정보를 포함하는 일련의 이미지 데이터들을 수신하는 단계;(b) 상기 영상편집모듈이 상기 수신된 이미지 데이터를 미리 설정된 영상 코덱에 따라 변환하는 단계; 및 (c) 상기 영상편집모듈이 영상 데이터를 포함하는 프레임 데이터를 생성하는 단계;를 포함하되,상기 (c) 단계는, 상기 영상편집모듈이 상기 표적추론모듈로부터 수신한 표적 정보를 포함하는 프레임 데이터를생성하되, 상기 표적추론모듈이 표적 정보를 생성할 때 사용된 분석 대상 이미지의 프레임 순서 정보에 대응한프레임 데이터에 상기 표적 정보를 포함시키는 단계인 것을 특징으로 하는, 영상편집방법."}
{"patent_id": "10-2021-0041942", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터에서 청구항 9에 따른 영상편집방법의 각 단계들을 수행하도록 작성되어 컴퓨터로 독출 가능한 기록 매체에 기록된 컴퓨터프로그램."}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 명세서는 카메라를 탑재한 감시 장치가 전방에서 촬영한 영상을 분석하고, 분석한 정보를 중앙 관제 장치에게 제공하는 엣지 인공지능 시스템을 개시한다. 감시 장치가 드론과 같은 형태로 구현될 경우, 드론에 탑재 가능한 배터리의 용량, 데이터 처리 연산 능력 등을 고려하여, 효율적인 운영이 가능하도록 영상 분석 방법, 영상 편집 방법 및 전송 방법을 개시한다."}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 엣지 인공지능의 표적 추론 방법에 관한 것이며, 보다 상세하게는 엣지환경에서 인공지능이 영상 내 표적을 효율적으로 추론할 수 있는 방법에 관한 것이다."}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 명세서에 기재된 실시예에 대한 배경 정보를 제공할 뿐 반드시 종래 기술을 구성하는 것은 아니다. 드론, 로봇, IoT는 미래전장에서 엣지단에서 역할을 수행할 핵심 요소로서 영상으로부터 표적탐지/인식 및 추적 을 통해 의미(Semantic) 정보를 추출할 수 있는 지능화와 보안성 강화가 요구되고 있다. 현재 지능 엣지 환경의 보안 위협대응 및 의미(Semantic) 처리 AI 기능이 통합된 소형/저전력의 SoC(System on Chip)가 세계적으로 상용화되어 있지 않아서, 가공되지 않은 다량의 고해상도 영상 전송에 따른 엣지단의 주파 수 부족, 배터리 소모, 지상 지휘통제소에서의 정보처리/융합을 위한 비용 및 인력 소요가 증가되고, 또한 해킹, 감청, 분실/탈취시 정보유출에 대한 사이버 위협도 급증하고 있다. 따라서 AI 및 H/W 기반의 강력한 보안기능과 영상 표적의 탐지/인식, 추적 기능이 탑재된 저전력/소형 지능 엣 지용 SoC의 개발 및 운영 방법이 필요하다. 선행기술문헌 특허문헌"}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "(특허문헌 0001) 공개특허공보 제10-2016-0061613호 발명의 내용"}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서는 엣지 인공지능 시스템에서 효율적이고 정확도가 높은 영상 분석이 가능한 표적추론방법을 제공하는 것을 목적으로 한다. 또한, 본 명세서는 엣지 인공지능 시스템에서 다양한 환경에 적응할 수 있으며 효율적으로 영상 및/또는 표적 정보를 전송할 수 있는 영상편집방법을 제공하는 것을 목적으로 한다. 또한, 본 명세서는 엣지 인공지능 시스템에서 다양한 환경에 따라 운영 모드를 설정하고, 운영자에게 효율적인 표적 정보를 제공할 수 있는 중앙 관제장치를 제공하는 것을 목적으로 한다. 본 명세서는 상기 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 명세서에 따른 표적추론모듈은 표적영상처리부, 제1 영상분석부, 제2 영상분석 부 및 추론정보관리부를 포함하는 표적추론모듈로서, 상기 표적영상처리부는 카메라 모듈로부터 분석 대상 이미 지를 수신하고, 수신된 이미지를 미리 설정된 해상도로 변경하거나, 상기 추론정보관리부에서 출력된 관심영역 정보에 따라 수신된 이미지를 크롭핑하고, 상기 제1 영상분석부는 상기 표적영상처리부가 변경한 해상도를 가진 이미지를 이용하여 영상 분석을 실시하고, 이를 통해 생성된 제1 분석 정보를 상기 추론정보관리부에 출력하고, 상기 제2 영상분석부는 상기 표적영상처리부가 관심영역을 크롭핑한 이미지를 이용하여 영상 분석을 실시하고, 이를 통해 생성된 제2 분석 정보를 상기 추론정보관리부에 출력하고, 상기 추론정보관리부는 상기 제1 영상분석 부에서 출력된 제1 분석 정보를 이용하여 관심영역정보를 생성하고, 생성된 관심영역정보를 상기 표적영상처리 부에 출력하고, 상기 제2 영상분석부에서 출력된 제2 분석 정보를 이용하여 표적 정보를 생성할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 제1 분석 정보는 영상 내 배경과 구분되는 대상물이 존재하는지 여부와 대상물의 영상 내 위치 정보를 포함할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 제2 분석 정보는 영상 내 배경과 구분되는 대상물의 의미 정보를 포함할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 추론정보관리부는 상기 제1 분석 정보와 제2 분석 정보를 비교하여 표적 정보의 신뢰도 정보를 생성할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 추론정보관리부는 이전에 생성한 표적 정보(이하 '이전 표적 정보')를 이용하여 새로운 표적 정보를 생성할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 추론정보관리부는 이전 표적 정보에서 관심영역정보를 추출하고, 상기 추출된 관심영역정보를 상기 표적영상처리부에 출력할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 추론정보관리부는 상기 제1 분석 정보에 포함된 관심영역정보와 이전 표 적 정보의 관심영역정보가 미리 설정된 오차범위 초과의 차이값을 가질 경우, 상기 제1 분석 정보에 포함된 관 심영역정보를 상기 표적영상처리부에 다시 출력할 수 있다. 상술한 과제를 해결하기 위한 본 명세서에 따른 표적추론방법은, (a) 표적영상처리부가 카메라 모듈로부터 분석 대상 이미지를 수신하는 단계; (b) 상기 표적영상처리부가 수신된 이미지를 미리 설정된 해상도로 변경하는 단 계; (c) 제1 영상분석부()가 상기 표적영상처리부가 변경한 해상도를 가진 이미지를 이용하여 영상 분석을 실시 하고, 이를 통해 생성된 제1 분석 정보를 출력하는 단계; (d) 추론정보관리부가 상기 제1 영상분석부에서 출력 된 제1 분석 정보를 이용하여 관심영역정보를 생성하고, 생성된 관심영역정보를 상기 표적영상처리부에 출력하 는 단계; (e) 상기 표적영상처리부가 상기 추론정보관리부에서 출력된 관심영역정보에 따라 수신된 이미지를 크 롭핑하는 단계; (f) 제2 영상분석부가 상기 표적영상처리부가 관심영역을 크롭핑한 이미지를 이용하여 영상 분 석을 실시하고, 이를 통해 생성된 제2 분석 정보를 상기 추론정보관리부에 출력하는 단계; 및 (g) 상기 추론정 보관리부가 상기 제2 영상분석부에서 출력된 제2 분석 정보를 이용하여 표적 정보를 생성하는 단계;를 포함할 수 있다.본 명세서의 일 실시예에 따르면, 상기 제1 분석 정보는 영상 내 배경과 구분되는 대상물이 존재하는지 여부와 대상물의 영상 내 위치 정보를 포함할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 제2 분석 정보는 영상 내 배경과 구분되는 대상물의 의미 정보를 포함할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 (g) 단계는, 상기 추론정보관리부가 상기 제1 분석 정보와 제2 분석 정 보를 비교하여 표적 정보의 신뢰도 정보를 더 생성하는 단계일 수 있다. 본 명세서에 따른 표적추론방법은, 상기 추론정보관리부가 이전 표적 정보에서 관심영역정보를 추출하고, 상기 추출된 관심영역정보를 상기 표적영상처리부에 출력하는 단계;를 더 포함할 수 있다. 본 명세서에 따른 표적추론방법은, 상기 추론정보관리부가 상기 제1 분석 정보에 포함된 관심영역정보와 이전 표적 정보의 관심영역정보가 미리 설정된 오차범위 초과의 차이값을 가질 경우, 상기 (d) 단계에서 생성된 관심 영역정보를 상기 표적영상처리부에 다시 출력하는 단계;를 더 포함할 수 있다. 본 명세서에 따른 표적추론방법은 컴퓨터에서 표적추론방법의 각 단계들을 수행하도록 작성되어 컴퓨터로 독출 가능한 기록 매체에 기록된 컴퓨터프로그램의 형태로 구현될 수 있다. 상술한 과제를 해결하기 위한 본 명세서에 따른 영상편집모듈은, 카메라 모듈로부터 프레임 순서 정보를 포함하 는 일련의 이미지 데이터들을 수신하고, 상기 수신된 이미지 데이터를 미리 설정된 영상 코덱에 따라 변환하고, 영상 데이터를 포함하는 프레임 데이터를 생성하는 영상편집모듈로서, 상기 영상편집모듈은, 표적추론모듈로부 터 수신한 표적 정보를 포함하는 프레임 데이터를 생성하되, 상기 표적추론모듈이 표적 정보를 생성할 때 사용 된 분석 대상 이미지의 프레임 순서 정보에 대응한 프레임 데이터에 상기 표적 정보를 포함시킬 수 있다. 본 명세서의 일 실시예에 따르면, 상기 프레임 데이터는 NAL 유닛(Network Abstraction Layer Unit)이고, 상기 영상편집모듈은, 상기 표적추론모듈이 표적 정보를 생성할 때 사용된 분석 대상 이미지의 프레임 순서 정보에 대응하여 SEI NAL 유닛을 생성할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 영상편집모듈은 미리 설정된 프레임 순서 정보에 따라 표적 정보를 포함 하는 프레임 데이터를 생성할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 영상편집모듈은 상기 카메라 모듈로부터 상기 표적추론모듈이 표적 정보 를 생성할 때 사용된 분석 대상 이미지의 프레임 순서 정보를 수신하고, 수신된 분석 대상 이미지의 프레임 순 서 정보를 이용하여 표적 정보를 포함하는 프레임 데이터를 생성할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 영상편집모듈은 상기 표적추론모듈로부터 수신한 표적 정보 내에 포함된 분석 대상 이미지의 프레임 순서 정보를 이용하여 표적 정보를 포함하는 프레임 데이터를 생성할 수 있다. 상술한 과제를 해결하기 위한 본 명세서에 따른 영상편집방법은, 영상편집모듈, 전방을 촬영하여 이미지 데이터 를 출력하는 카메라 모듈 및 상기 카메라 모듈로부터 분석 대상 이미지를 수신하고 분석 대상 이미지를 이용하 여 표적 정보를 생성하는 표적추론모듈을 포함하는 감시 장치가 영상을 편집하는 방법으로서, (a) 상기 영상편 집모듈이 상기 카메라 모듈로부터 프레임 순서 정보를 포함하는 일련의 이미지 데이터들을 수신하는 단계; (b) 상기 영상편집모듈이 상기 수신된 이미지 데이터를 미리 설정된 영상 코덱에 따라 변환하는 단계; 및 (c) 상기 영상편집모듈이 영상 데이터를 포함하는 프레임 데이터를 생성하는 단계;를 포함하되, 상기 (c) 단계는, 상기 영상편집모듈이 상기 표적추론모듈로부터 수신한 표적 정보를 포함하는 프레임 데이터를 생성하되, 상기 표적추 론모듈이 표적 정보를 생성할 때 사용된 분석 대상 이미지의 프레임 순서 정보에 대응한 프레임 데이터에 상기 표적 정보를 포함시키는 단계일 수 있다. 본 명세서에 따른 영상편집방법은 컴퓨터에서 영상편집방법의 각 단계들을 수행하도록 작성되어 컴퓨터로 독출 가능한 기록 매체에 기록된 컴퓨터프로그램로 구현될 수 있다. 상술한 과제를 해결하기 위한 본 명세서에 따른 엣지 인공지능 시스템은 탑재된 카메라로 전방을 촬영한 이미지 데이터를 이용하여 영상 분석을 실시하고, 영상 분석 결과를 표적 정보로 생성하는 적어도 하나의 감시 장치; 및 상기 감시 장치로부터 표적 정보를 수신하고, 상기 감시 장치의 운영 모드를 제어하는 신호를 출력하는 중앙 관제 장치;를 포함할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 운영모드는 상기 감시 장치가 표적 정보만 전송하는 제1 모드, 상기 감 시 장치가 표적 정보와 영상 정보를 각각 전송하는 제2 모드, 영상 정보의 프레임에 표적 정보를 담아서 전송하는 제3 모드 및 영상 자체에 표적 정보를 표시하여 영상 정보를 전송하는 제4 모드를 포함할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 중앙 관제 장치는 상기 감시 장치로부터 수신한 표적 정보에 포함된 대 상물이 미리 설정된 주요 대상물 리스트에 포함된 대상물일 때, 상기 감시 장치의 운영모드를 제1 모드에서 제2 내지 제4 모드 중 어느 한 운영모드로 전환하도록 제어할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 감시 장치의 운영 모드가 제3 모드일 때, 상기 중앙 관제 장치는 표적 정보를 포함하는 데이터 프레임을 수신하고, 수신한 데이터 프레임에서 표적 정보를 추출하고, 추출된 표적 정 보를 이용하여 표적 정보를 포함하는 데이터 프레임의 영상에 표적 정보를 표시하고, 표적 정보가 표시된 영상 을 재생시킬 수 있다. 본 명세서의 일 실시예에 따르면, 상기 중앙 관제 장치는 표적 정보를 이용하여 수신한 데이터 프레임 중 표적 정보를 포함하고 있지 않는 데이터 프레임에 포함된 영상에서 대상물을 추적하고, 영상 내 추적된 대상물에 표 적 정보를 표시할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 감시 장치는 공중 비행을 위한 구동 장치; 및 상기 구동 장치에 전력을 제공하는 배터리;를 더 포함할 수 있다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 명세서의 일 측면에 따르면, 엣지 인공지능 시스템에서 효율적이고 정확도가 높은 영상 분석이 가능한 표적 추론방법을 제공할 수 있다. 본 명세서의 다른 측면에 따르면, 엣지 인공지능 시스템에서 다양한 환경에 적응할 수 있으며 효율적으로 영상 및/또는 표적 정보를 전송할 수 있는 영상편집방법을 제공할 수 있다. 본 명세서의 또 다른 측면에 따르면, 엣지 인공지능 시스템에서 다양한 환경에 따라 운영 모드를 설정하고, 운 영자에게 효율적인 표적 정보를 제공할 수 있는 중앙 관제장치를 제공할 수 있다."}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시된 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후 술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나, 본 명세서가 이하에서 개시되는 실시예들에 제한되 는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 명세서의 개시가 완전하도 록 하고, 본 명세서가 속하는 기술 분야의 통상의 기술자(이하 '당업자')에게 본 명세서의 범주를 완전하게 알 려주기 위해 제공되는 것이며, 본 명세서의 권리 범위는 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 명세서의 권리 범위를 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다(comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성요 소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 명세서가 속하는 기 술분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용 되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되 지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 도 1은 본 명세서에 따른 엣지 인공지능 시스템의 개략적인 개념도이다. 도 1을 참조하면, 본 명세서에 따른 엣지 인공지능 시스템은 감시 장치와 중앙 관제 장치를 포함할 수 있다. 감시 장치는 전방의 영상을 촬영하여 표적의 종류나 추적 등의 임무를 수행하는 장치이다. 감시 장치는 자체적으로 이동이 가능한 차량, 드론과 같은 형태로 구현될 수 있으며, 카메라를 탑재할 수 있다. 중앙 관제 장치는 감시 장치를 동작을 제어하거나 감시 장치의 임무를 지시/설정하는 역할을 할 수 있다. 도 1에 도시된 예시에는, 군사용 목적으로 전방을 감시하는 환경을 가정하였지만, 이 것은 발명의 이해를 돕기 위한 설명임을 이해해야 한다. 본 명세서에 따른 엣지 인공지능 시스템이 군사용에 제한되지 않으며, 상기 감시 장치 역시 드론에 한정되지 않는다. 한편, 엣지 인공지능 시스템에서 다수의 감시 장치가 동시에 사용될 경우, 중앙 관제 장치에 수신 되는 다량의 이미지 데이터를 동시에 모두 처리하는 것은 물리적으로 한계가 있으며 또한 비효율적이다. 시스템 의 엣지에 위치한 감시 장치가 이미지 데이터에 대한 추론 과정을 처리하고, 처리된 결과를 중앙 관제 장치 에게 전송하는 것이 엣지 인공지능 시스템 전체의 관점에서 보다 효율적인 운영이 가능하다. 그러나, 감시 장치가 이미지 데이터에 대한 모든 것을 처리하는 것은 물리적으로 한계가 있으며 설계 관점 에서 비효율적이다. 감시 장치가 드론과 같은 소형 장치로 제작될 경우, 감시 장치에 탑재되는 배터리 의 용량, 이미지 데이터를 처리할 수 있는 프로세서의 성능, 부품의 비용 등을 고려하여 제작될 것이다. 이 경 우, 카메라로 촬영한 이미지 데이터 전부 감시 장치에서 처리할 경우, 고성능의 이미지 처리 프로세서가 필 요하여 감시 장치의 제작 비용 증가로 연결된다. 뿐만 아니라, 고성능의 이미지 처리 프로세서는 전력 소모 량이 높아서, 배터리 용량의 증가 또는 드론의 체공 시간 단축과 같은 문제로 연결된다. 따라서, 시스템의 엣지 에 위치한 감시 장치는 비용 절감, 전력 소모량의 감소 등을 다양한 환경에서 다양한 운영 모드를 제공할 필요가 있다. <감시 장치의 구성 개요> 도 2는 본 명세서에 따른 감시 장치에 포함될 수 있는 구성의 개략적인 블럭도이다. 도 2에 도시된 구성들은, 감시 장치에 포함될 수 있는 다양한 구성 중 카메라로 촬영한 영상에서 표적을 추 론하고, 추론된 결과를 전송하는 구성에 대한 블럭도이다. 따라서, 본 명세서에 따른 감시 장치에는 도 2에 도시된 구성들 외 다른 구성이 추가될 수 있음은 자명하다. 도 2를 참조하면, 감시 장치는 카메라모듈, 표적추론모듈, 중앙제어모듈, 영상편집모듈 및 통신모듈을 포함할 수 있다. 상기 카메라모듈은 전방을 촬영하여 원본 이미지 데이터를 출력할 수 있다. 카메라모듈에는 촬영 대 상, 촬영 환경을 고려하여 EO 카메라(Electro-Optical Camera), IR 카메라(InfraRed Camera) 등 다양한 카메라 를 포함할 수 있다. 또한, 상기 카메라모듈은 카메라에서 출력된 원본 이미지 데이터를 가공할 수 있는 영 상전처리부를 포함할 수 있다. 영상전처리부는 EO 카메라 및 IR 카메라에서 각각 출력된 원본 이미지 데이터를 합성하여 하나의 영상 데이터로 생성하거나, 원본 이미지 데이터의 원하는 해상도를 변경하거나, 노이즈를 제거 하는 등 필요한 영상 처리 기능을 수행할 수 있다. 상기 카메라모듈은 원본 이미지 데이터 또는 전처리된 이미지 데이터를 상기 중앙제어모듈에게 제공 할 수 있다. 상기 중앙제어모듈에게 제공된 이미지 데이터는 상기 표적추론모듈 또는 영상편집모듈에게 제공할 수도 있다. 도 2에는 상기 카메라모듈이 이미지 데이터를 상기 중앙제어모듈을 통 해 간접적으로 제공하는 예시가 되시어 있으나, 상기 카메라모듈이 원본 이미지 데이터 또는 전처리된 이 미지 데이터를 직접 상기 표적추론모듈 또는 영상편집모듈에게 제공할 수 있다. 상기 카메라모듈 이 제공하는 이미지 데이터는 정지 영상 또는 동영상일 수 있으며, 본 명세서에서는 이해의 편의를 위해 다수의 정지 영상으로 이루어진 동영상 데이터를 제공하는 것으로 설명하겠다. 상기 표적추론모듈은 상기 카메라모듈로부터 수신한 이미지 데이터를 이용하여 영상 분석을 실시할 수 있다. 영상 분석은 영상 내 표적의 존재 여부, 표적의 종류, 표적 식별 정보, 표적의 상태 등 원하는 정보를 추출하기 위한 이미지 분석을 의미한다. 상기 이미지 분석은 인공지능 알고리즘 또는 머신러닝 알고리즘을 통해 구현된 이미지 분석 방법으로서, 본 명세서의 출원 당시 존재하는 다양한 이미지 분석 방법뿐만 아니라, 출원 이후 당업자가 사용 가능한 모든 이미지 분석 방법이 적용될 수 있다. 따라서, 상기 표적추론모듈은 영상 분석을 실시하여, 영상 내 물체에 대한 정보를 생성할 수 있다. 앞서 언급하였듯이, 시스템의 엣지에 위치한 감 시 장치로서 비용 절감, 전력 소모량의 감소 등을 효율적인 이미지 분석을 위한 상기 표적추론모듈의 보다 구체적인 구성은 이후에 자세히 설명하겠다. 상기 영상편집모듈은 상기 카메라모듈로부터 수신한 이미지 데이터를 이용하여 영상 편집을 실시할 수 있다. 영상 편집이란, 이미지 데이터를 H.265와 같이 미리 설정된 동영상 코덱(CODEC)으로 변환하거나, 영상 내 표적의 정보, 위치와 같은 정보를 추가하는 것 등을 의미한다. 상기 영상편집모듈은, 필요에 따라서, 영상 자체에 정보를 추가할 수 있으며, 비디오 코딩 레이어 상에 특정 프레임 또는 프레임 내 특정 위치에 정보 를 추가하는 것도 가능하다. 상기 영상편집모듈의 구체적인 동작에 대해서는 이후 다양한 동작 모드에 따 라 추가적으로 설명하도록 하겠다. 상기 중앙제어모듈은 본 명세서에 따른 감시 장치의 다양한 동작을 통합적으로 제어하는 역할을 할 수 있다. 본 명세서에 따른 감시 장치는 다양한 환경에서 다양한 모드로 동작할 수 있는바, 각각의 모드에 맞 추어 상기 카메라모듈, 표적추론모듈, 영상편집모듈, 중앙제어모듈 및 통신모듈이 동 작하도록 제어할 수 있다. 한편, 도 2에는 각 구성 요소들이 상기 중앙제어모듈을 통해 데이터를 주고 받 는 것으로 도시하였으나, 각 구성 요소들이 반드시 상기 중앙제어모듈을 통해서만 데이터를 주고 받아야 하는 것은 아니다. 도 2에 도시된 각 구성 요소뿐만 아니라, 도 2에 도시되지 않은 다른 구성 요소 역시 상호 직접 데이터를 주고 받는 것이 가능하다. 또한, 본 명세서에서는 설명의 편의를 위해 기능적 측면에서 물리적으 로 구분 가능한 중앙제어모듈을 기본 실시예로 설명하겠다. 그러나, 상기 중앙제어모듈은 도 2에 도 시된 각 구성 요소들에 일부로서 포함되어 물리적으로 구분하기 어려울 수 있으며, 상기 중앙제어모듈의 기능이 소프트웨어적으로 구현될 때, 가상의 구성 요소로 존재할 수도 있다. 상기 통신모듈은 본 명세서에 따른 감시 장치와 중앙 관제 장치 사이에서 무선으로 데이터를 송수 신하는 역할을 할 수 있다. 또한, 상기 통신모듈은 하나의 감시 장치와 다른 감시 장치 사이에서 데이터를 송수신하는 역할을 할 수도 있다. 상기 통신모듈은 5G와 같이 이동통신을 위한 기술표준 또는 Wi-Fi와 같이 무선 인터넷 접속을 위한 기술표준 등을 사용하여 데이터를 무선으로 송수신할 수 있다. 상기 통 신모듈은 본 명세서 출원 당시뿐만 아니라 추후 당업자 수준에서 적용 가능한 모든 무선 통신 기술을 사용 할 수 있다. <표적추론모듈> 상기 표적추론모듈은 상기 카메라모듈로부터 수신한 이미지 데이터를 이용하여 영상 분석을 실시할 수 있다. 일반적인 환경에서 촬영된 이미지에서 영상에서 배경과 구분되는 대상물(object)를 구별하고, 구별된 대상물의 정보(종류, 크기, 위치, 상태 등)를 식별하는 것은 본 출원 당시 당업자에 알려진 다양한 인공지능 알 고리즘을 통해 구현하는 것이 가능하다. 그러나 본 명세서에서 제시한 설정 및 환경과 같이, 군용 드론이 전장 에서 이동하면서 촬영한 이미지 데이터에서 대상물을 구별 및 식별하는 것은 일반적인 환경과 달리 용이하지 않 다. 우선, 군의 특수 환경을 고려할 때, 배경과 잘 구분되지 않는 대상물이 먼 거리에서 발견되었을 때, 해당 이미지에서는 굉장히 작은 픽셀을 차지하는 물체로 촬영될 가능성이 높다. 따라서, 먼거리에 있는 대상물을 정 확하게 분석하기 위해서는 고해상도 이미지가 필요하다. 그러나 체공 시간이 작전 시간과 직접 연결되는 드론의 하드웨어 특성을 고려할 때, 고해상도의 이미지 프레임을 연속적으로 분석하는 것은 매우 제한적이다. 따라서, 고해상도 이미지에서 높은 정확도로 영상을 분석하는 효율적인 방법이 필요하다.도 3은 본 명세서에 따른 표적추론모듈의 구성을 개략적으로 도시한 블럭도이다. 도 3을 참조하면, 본 명세서에 따른 표적추론모듈은 표적영상처리부, 제1 영상분석부, 제2 영상 분석부 및 추론정보관리부를 포함할 수 있다. 상기 표적영상처리부는 카메라모듈로부터 분석 대상 이미지를 수신할 수 있다. 상기 카메라모듈(10 0)은 카메라에서 출력된 원본 이미지 데이터 또는 가공된 이미지 데이터 전부 또는 일부를 분석 대상 이미지로 제공할 수 있다. 상기 카메라모듈이 원본 이미지 데이터(또는 가공된 이미지 데이터)를 전부 제공할 경우, 상기 표적영상처리부는 일부 이미지 데이터를 선택하여 분석 대상 이미지로 수신할 수 있다. 또는 상기 카 메라모듈이 미리 설정된 기준에 따라 선택한 원본 이미지 데이터(또는 가공된 이미지 데이터)를 분석 대상 이미지로 제공할 수 있다. 이 경우, 상기 표적영상처리부는 상기 카메라모듈로부터 제공된 이미지 데 이터를 분석 대상 이미지로 수신할 수 있다. 원본 이미지 데이터(또는 가공된 이미지 데이터)의 전부가 아닌 일부만 분석 대상 이미지로 사용하는 것은 영상 분석 하드웨어의 성능, 소모 전력량, 분석 속도 등을 고려하여 효율적인 분석을 실시하기 위함이다. 상기 카메 라모듈이 동영상 형태로 이미지 데이터를 생성할 때, 동영상에 포함된 모든 이미지 프레임의 영상을 분석 하는 것은 상당히 비효율적인다. 또한, 상기 제1 영상분석부 및 상기 제2 영상분석부의 성능이 아무 리 좋아도, 상기 제1 영상분석부 또는 상기 제2 영상분석부가 하나의 이미지 데이터를 분석하는데 소 요되는 시간은 상기 카메라모듈이 동영상 형태로 이미지 데이터를 생성하는 속도보다 느릴 수 있다. 따라 서, 상기 제1 영상분석부 또는 상기 제2 영상분석부가 하나의 이미지 데이터를 분석하는데 소요되는 시간을 고려하여 분석 대상 이미지의 시간 간격이 설정할 수도 있다. 본 명세서에서는 이해의 편의를 위해 기 카메라모듈이 생성한 동영상에서 5프레임마다 하나의 이미지를 분석 대상 이미지로 사용하는 예시를 이용 하여 설명하겠다. 상기 표적영상처리부는 수신된 이미지를 미리 설정된 해상도로 변경할 수 있다. 보다 구체적으로, 상기 표 적영상처리부는 상기 카메라모듈이 제공한 분석 대상 이미지보다 낮은 해상도로 이미지를 변경할 수 있다. 이 과정에서 영상의 품질은 저하될 수 있다. 일 예로, 상기 카메라모듈이 제공한 이미지 데이터의 해상도가 1920 x 1080일 때, 상기 표적영상처리부는 512 x 512 해상도를 가진 이미지 데이터로 변경할 수 있다. 이처럼 해상도를 낮추는 과정은 상기 제1 영상분석부가 보다 빠르게 영상을 분석할 수 있도록 하기 위함이다. 상기 표적영상처리부는 상기 추론정보관리부에서 출력된 관심영역정보(ROI, region of interest)에 따라 수신된 이미지를 크롭핑(cropping)할 수 있다. 크롭핑(cropping)이란, 이미지 데이터의 품질은 유지하되, 특정 영역을 제외한 나머지 영역을 제거하는 것을 의미한다. 상기 표적영상처리부는 관심영역정보의 위치 및 크기에 따라 분석 대상 이미지에서 관심영역을 제외한 나머지 영역을 전부 제거할 수 있다. 그 결과, 분석 대상 이미지에서 관심영역에 대한 이미지 데이터만 상기 제2 영상분석부에게 제공할 수 있다. 일 예로, 관 심영역의 크기는 512 x 512 해상도를 가진 이미지 데이터일 수 있다. 상기 제1 영상분석부는 상기 표적영상처리부가 변경한 해상도를 가진 이미지를 이용하여 영상 분석을 실시할 수 있다. 상기 제1 영상분석부는 이를 통해 성성된 제1 분석 정보를 상기 추론정보관리부에 출력할 수 있다. 상기 제1 분석 정보는 영상 내 배경과 구분되는 대상물(object)이 존재하는지 여부와 대상물의 영상 내 위치 정보를 포함할 수 있다. 나아가, 상기 제1 분석 정보는 대상물이 미리 설정된 표적의 종류에 해당 할 경우, 표적의 종류에 대한 정보를 더 포함할 수 있다. 상기 제2 영상분석부는 상기 표적영상처리부가 관심영역을 크롭핑한 이미지를 이용하여 영상 분석을 실시할 수 있다. 상기 제2 영상분석부는 이를 통해 생성된 제2 분석 정보를 상기 추론정보관리부에 출력할 수 있다. 상기 제2 분석 정보는 영상 내 배경과 구분되는 대상물(object)의 의미(semantic)정보를 포함 할 수 있다. 즉, 제2 분석 정보는 대상물이 미리 설정된 표적의 종류에 해당할 경우, 표적의 종류/크기/개수/상 태 등에 대한 포함할 수 있다. 상기 제1 영상분석부와 상기 제2 영상분석부는 ANN(Artificial Neural Network), DNN(Deep Neural Network), CNN(Convolution Neural Network), RNN(Recurrent Neural Network) 등을 이용하여 상술한 기능을 구 현할 수 있다. 또한, 상기 제1 영상분석부와 상기 제2 영상분석부는 동일한 알고리즘을 사용할 수도 있고, 서로 다른 알고리즘을 사용할 수도 있다. 또한, 도 3에는 물리적으로 구분 가능한 구성으로 도시하였으나, 하나의 물리적 장치에 소프트웨어적으로 구분 가능한 구성일 수 있다. 또한, 동일한 물리적 장치가 상기 제1 영상분석부와 상기 제2 영상분석부의 역할을 교대로 수행하는 것 역시 가능하다. 상기 추론정보관리부는 상기 제1 영상분석부에서 출력된 제1 분석 정보를 이용하여 관심영역정보 (ROI)를 생성할 수 있다. 그리고 상기 추론정보관리부는 생성된 관심영역정보(ROI)를 상기 표적영상처리부 에 출력할 수 있다. 이때, 상기 표적영상처리부는 상기 추론정보관리부에서 출력된 관심영역정 보(ROI, region of interest)에 따라 수신된 이미지를 크롭핑(cropping)할 수 있다. 그리고 상기 추론정보관리 부는 상기 제2 영상분석부에서 출력된 제2 분석 정보를 이용하여 표적 정보를 생성할 수 있다. 도 4는 본 명세서에 따른 표적추론모듈의 영상 분석 흐름을 개략적으로 도시한 참고도이다. 도 4를 참조하면, 상기 표적영상처리부가 분석 대상 이미지를 수신하는 것을 확인할 수 있다. 상기 표적영 상처리부는 상기 분석 대상 이미지를 미리 설정된 해상도로 변경할 수 있다(①). 상기 제1 영상분석부 는 상기 표적영상처리부가 변경한 해상도를 가진 이미지를 이용하여 영상 분석을 실시하고, 이를 통 해 생성된 제1 분석 정보를 상기 추론정보관리부에 출력할 수 있다(②). 이때, 상기 제1 분석 정보에는 관 심영역정보가 포함될 수 있다. 상기 추론정보관리부는 제1 분석 정보의 관심영역정보를 상기 표적영상처리 부에 출력할 수 있다(③). 상기 표적영상처리부는 상기 추론정보관리부에서 출력된 관심영역정 보에 따라 수신된 이미지를 크롭핑할 수 있다(④). 상기 제2 영상분석부는 상기 표적영상처리부가 관 심영역을 크롭핑한 이미지를 이용하여 영상 분석을 실시하고, 이를 통해 생성된 제2 분석 정보를 상기 추론정보 관리부에 출력할 수 있다(⑤). 상기 추론정보관리부는 상기 제2 영상분석부에서 출력된 제2 분 석 정보를 이용하여 표적 정보를 생성할 수 있다(⑥). 한편, 상기 추론정보관리부는 상기 제1 분석 정보와 제2 분석 정보를 비교하여 표적 정보의 신뢰도 정보를 생성할 수 있다. 상기 제1 분석 정보는 대상물이 미리 설정된 표적의 종류에 해당할 경우, 표적의 종류에 대한 정보를 더 포함할 수 있다. 따라서, 상기 추론정보관리부는 제1 분석 정보에 포함된 표적에 대한 정보와 제2 분석 정보에 포함된 표적의 정보가 동일한지 여부를 비교하여 신뢰도를 측정할 수 있다. 만약, 제1 분석 정 보에 포함된 표적에 대한 정보와 제2 분석 정보에 포함된 표적의 정보가 서로 동일한 경우, 상기 추론정보관리 부는 상기 표적 정보에 대한 신뢰도를 높게 측정할 수 있다. 만약, 제1 분석 정보에 포함된 표적에 대한 정보와 제2 분석 정보에 포함된 표적의 정보가 서로 동일하지 않지만 동일 카테고리로 분류된 표적인 경우, 상 기 추론정보관리부는 상기 표적 정보에 대한 신뢰도를 중간정도로 측정할 수 있다. 반면, 제1 분석 정보에 포함된 표적에 대한 정보와 제2 분석 정보에 포함된 표적의 정보가 서로 다르며 동일 카테고리에 해당하지 않는 경우, 상기 추론정보관리부는 상기 표적 정보에 대한 신뢰도를 낮게 측정할 수 있다. 다만, 상기 추론정보 관리부는 제2 분석 정보에 더 높은 가중치를 부가하여 표적 정보를 생성할 수 있다. 또한 이 경우 중앙 관 제 장치에서 표적 정보의 신뢰도를 판단할 수 있도록, 상기 추론정보관리부는 제1 분석 정보에 포함된 표적에 대한 정보를 상기 표적 정보에 추가할 수 있다. 한편, 상기 추론정보관리부는 이전에 생성한 표적 정보를 이용하여 새로운 표적 정보를 생성할 수 있다. 본 명세서에 따른 표적추론모듈은 동영상에서 주기적 간격으로 분석 대상 이미지를 수신할 수 있다. 따라 서, 상기 추론정보관리부는 앞선 프레임을 분석하여 표적 정보를 생성했으며, 현재 다음 프레임을 분석하 여 표적 정보를 생성할 수 있다. 이 때, 프레임과 프레임 사이의 간격이 존재하지만, 표적의 위치 및 종류가 크 게 변화할 가능성은 낮을 수 있다. 따라서, 앞선 프레임을 분석하여 생성한 이전 표적 정보를 이용할 경우, 보 다 빠르고 정확한 분석 정보 생성이 가능하다. 보다 구체적으로, 상기 추론정보관리부는 이전 표적 정보에서 관심영역정보를 추출하고, 상기 추출된 관심영역 정보를 상기 표적영상처리부에 출력할 수 있다. 상기 표적영상처리부는 상기 추론정보관리부에서 출 력된 이전 표적 정보의 관심영역정보에 따라 수신된 이미지를 크롭핑할 수 있다. 이후, 상기 제1 영상분석부 는 앞서 설명한 바와 같이, 상기 표적영상처리부가 변경한 해상도를 가진 이미지를 이용하여 영상 분 석을 실시하고, 이를 통해 생성된 제1 분석 정보를 상기 추론정보관리부에 출력할 수 있다. 동시에, 상기 제2 영상분석부는 상기 표적영상처리부가 관심영역을 크롭핑한 이미지를 이용하여 영상 분석을 실시 하고, 이를 통해 생성된 제2 분석 정보를 상기 추론정보관리부에 출력할 수 있다. 즉, 앞선 실시예에서는 제1 분석 정보에 포함된 관심영역정보가 생성된 이후에 제2 분석 정보가 생성될 수 있지만, 이전 표적 정보의 관심 영역정보를 이용할 경우, 제1 분석 정보와 제2 분석 정보가 동시에 또는 거의 비슷하게 생성될 수 있다. 이후, 상기 추론정보관리부는 제1 분석 정보에 포함된 관심영역정보와 이전 표적 정보의 관심영역정보를 비교할 수 있다. 상기 두 관심영역정보가 동일하거나 미리 설정된 오차범위 이하의 차이값을 가질 경우, 상기 제1 분석 정보에 포함된 관심영역정보와 제2 표적 분석 정보에 포함된 대상물의 의미 정보를 이용하여 표적 정보를 생성할 수 있다. 반면, 상기 두 관심영역정보가 미리 설정된 오차범위 초과의 차이값을 가질 경우, 상기 제1 분석 정보에 포함된 관심영역정보를 상기 표적영상처리부에 다시 출력할 수 있다. 이때, 상기 제2 영 상분석부는 새롭게 크롭핑된 이미지를 이용하여 영상 분석을 다시 실시하고, 새롭게 제2 분석 정보를 출력 할 수 있다. <중앙제어모듈> 본 명세서에 따른 감시 장치는 다양한 환경에서 다양한 모드로 동작할 수 있다. 특히, 상기 표적추론모듈 에서 생성된 표적 정보를 상기 통신모듈을 통해 상기 중앙 관제 장치에게 전송하는 방식에 따라 운영모드가 다양해질 수 있다. 상기 운영모드는 상기 감시 장치가 연산, 처리 또는 전송하는 데이터의 양에 따라 달라질 수 있다. 상기 중앙제어모듈은 각 운영모드에 따라 상기 카메라모듈, 표적추론모듈 , 영상편집모듈 및 통신모듈이 동작하도록 제어할 수 있다. 이하, 각 운영모드에 대해서 설명하 겠다. 다만, 본 명세서에서는 각 운영모드를 구별하기 위해서 \"제n 모드\"라고 명칭할 것이며, 상기 명칭은 다른 운영모드와 우선관계를 나타내는 것은 아니다. 도 5는 본 명세서에 따른 운영모드의 참고도이다. 제1 모드는 표적 정보만 전송하는 운영 방법이다. 이때, 상기 중앙제어모듈은 상기 카메라모듈 및 표 적추론모듈이 앞서 설명한대로 표적 정보를 생성하도록 제어할 수 있다. 상기 중앙제어모듈은 상기 표적 정보를 상기 통신모듈을 통해서 중앙 관제 장치에게 전송할 수 있다. 즉, 제1 모드에서는 상기 카메라모듈이 촬영한 영상 정보는 전송하지 않을 수 있다. 제1 모드는 다른 모드에 비해 연산, 처리 및 전 송하는 데이터의 양이 가장 적을 수 있는바, 전력 소모량이 상대적으로 적을 수 있다. 따라서, 제1 모드는 감시 장치를 장시간 운영할 수 있는 모드이다. 제2 모드는 표적 정보와 영상 정보를 각각 전송하는 운영 방법이다. 상기 중앙제어모듈은 상기 카메라모듈 및 표적추론모듈이 앞서 설명한대로 표적 정보를 생성하도록 제어할 수 있다. 그리고 상기 중앙제어 모듈은 상기 영상편집모듈이 상기 카메라모듈로부터 수신한 이미지 데이터를 이용하여 영상 편 집을 실시하도록 제어할 수 있다. 이때, 영상 편집은 이미지 데이터를 H.265와 같이 미리 설정된 동영상 코덱 (CODEC)으로 변환하는 것을 의미한다. 그리고 상기 중앙제어모듈은 상기 표적 정보 및 편집된 영상 정보를 상기 통신모듈을 통해서 중앙 관제 장치에게 전송할 수 있다. 즉, 제2 모드는 표적 정보와 영상 정보 를 결합시키지 않고, 그대로 전송하는 모드이다. 제2 모드는 제1 모드에 비해 연산, 처리 및 전송하는 데이터의 양이 증가할 수 있으나, 영상 편집 과정에서 표적 정보를 반영하지 않아서, 이후에 설명할 다른 모드에 비해 전 력 소모량이 상대적으로 적을 수 있다. 제3 모드는 영상 정보의 프레임에 표적 정보를 담아서 전송하는 운영 방법이다. 영상 압축 코덱은 데이터를 프 레임 단위로 생성할 수 있다. 이때, 각각의 프레임에는 비디오 데이터외에 영상과 관련된 데이터를 추가로 입력 할 수 있는 필드가 존재한다. 제3 모드는 상기 프레임 내 필드에 표적 정보를 입력해서 전송하는 운영 방법이다. 일단, 상기 중앙제어모듈은 상기 카메라모듈 및 표적추론모듈이 앞서 설명한대로 표 적 정보를 생성하도록 제어할 수 있다. 그리고 상기 중앙제어모듈은 상기 영상편집모듈이 상기 카메 라모듈로부터 수신한 이미지 데이터를 이용하여 영상 편집을 실시하도록 제어할 수 있다. 이때, 상기 영상 편집모듈은 프레임 내 필드에 표적 정보를 입력할 수 있다. 상기 영상편집모듈이 프레임 내 필드에 표정 정보를 입력하는 방법은 이후에 보다 자세히 설명하겠다. 그리고 상기 중앙제어모듈은 편집된 영상 정보를 상기 통신모듈을 통해서 중앙 관제 장치에게 전송할 수 있다. 상기 표적 정보는 이미 영상 정 보에 포함되어 있는바, 별도로 전송하지 않는다. 즉, 제3 모드는 표적 정보를 포함한 영상 정보를 전송하는 모 드이다. 영상 정보에 포함된 표적 정보는 중앙 관제 장치가 추출하여 사용할 수 있다. 제4 모드는 영상 자체에 표적 정보를 표시하여 영상 정보를 전송하는 운영 방법이다. 표적 정보는 이미지 내 표 적의 위치 및 의미 정보를 포함하고 있다. 일단, 상기 중앙제어모듈은 상기 카메라모듈 및 표적추론 모듈이 앞서 설명한대로 표적 정보를 생성하도록 제어할 수 있다. 그리고 상기 중앙제어모듈은 상기 영상편집모듈이 상기 카메라모듈로부터 수신한 이미지 데이터를 이용하여 영상 편집을 실시하도록 제 어할 수 있다. 이때, 상기 영상편집모듈은 표적 정보에 포함된 표적의 위치를 영상에 표시하고, 영상 내에 표적의 의미와 관련된 문자를 추가하여 영상을 편집할 수 있다. 그리고 상기 중앙제어모듈은 편집된 영상 정보를 상기 통신모듈을 통해서 중앙 관제 장치에게 전송할 수 있다. 상기 표적 정보는 이미 영상에표현되어 있는바 별도로 전송하지 않는다. 즉, 제4 모드는 영상 자체에 모든 정보가 표시된 영상 정보를 전송하 는 모드이다. 이 경우, 중앙 관제 장치는 영상 정보를 그대로 재생시키면 영상과 함께 표적 정보를 확인할 수 있다. <영상편집모듈> 상기 영상편집모듈은 상기 카메라모듈로부터 수신한 이미지 데이터를 이용하여 영상 편집을 실시할 수 있다. 영상 편집이란, 이미지 데이터를 H.265와 같이 미리 설정된 동영상 코덱(CODEC)으로 변환하거나, 영상 내 표적의 정보, 위치와 같은 정보를 추가하는 것 등을 의미한다. 앞서 설명한 운영모드 중 제1 모드에서 상기 영상편집모듈은 영상 편집을 실시하지 않을 수 있다. 앞서 설명한 운영모드 중 제1 모드에서 상기 영상편 집모듈은 미리 설정된 코덱에 따라 영상 편집을 실실할 수 있다. 미리 설정된 코덱에 따라 영상을 압축하 거나 편집하는 것은 당업자에게 알려진 기술인바, 상세한 설명은 생략하도록 하겠다. 또한, 운영모드 중 제4 모 드에서 상기 영상편집모듈은 표적 정보에 포함된 정보를 영상 자체에 표시하고, 표적 정보가 표시된 영상 을 압축/편집하는 것 역시 업자에게 알려진 기술인바, 상세한 설명은 생략하도록 하겠다. 이하에서는, 운영모드 중 제3 모드에서 상기 영상편집모듈의 동작에 대해서 설명하겠다. -제3 모드에서 영상편집모듈의 동작- 도 6은 본 명세서에 따른 영상편집모듈의 구성을 개략적으로 도시한 블럭도이다. 도 6을 참조하면, 본 명세서에 따른 영상편집모듈은 상기 카메라모듈로부터 일년의 이미지 데이터들 을 수신하는 것을 확인할 수 있다. 상기 수신된 이미지 데이터는 상기 상기 카메라모듈이 생성한 원본 이 미지 데이터 또는 전처리된 이미지 데이터로서, 각각의 이미지 데이터는 프레임 순서 정보를 포함할 수 있다. 상기 영상편집모듈은 상기 수신된 원본 이미지 데이터를 미리 설정된 영상 코덱에 따라 변환하고, 영상 데 이터를 포함하는 프레임 데이터를 생성할 수 있다. 도 6에는 상기 영상편집모듈이 프레임 데이터를 생성함 에 있어서, 데이터 포맷을 RGB에서 YUV로 변환하고, H.265 코덱에 따라 영상을 압축하고, NAL 유닛(Network Abstraction Layer Unit)을 생성하는 예시가 도시되어 있다. 그러나, 본 명세서에 따른 영상편집모듈이 도 6에 도시된 예시에 제한되는 것은 아니다. 영상 데이터를 변환하는 포맷는 다양할 수 있으며, 영상 압축 코덱 역시 다양할 수 있다. 상기 영상편집모듈은 상기 표적추론모듈로부터 수신한 표적 정보를 포함하는 프레임 데이터를 생성하 되, 상기 표적추론모듈이 표적 정보를 생성할 때 사용된 분석 대상 이미지의 프레임 순서 정보에 대응한 프레임 데이터에 상기 표적 정보를 포함시킬 수 있다. 일반적인 프레임 데이터는 이미지 데이터를 기록하는 필 드와 이미지 데이터 외 정보를 기록하는 필드를 포함한다. 이미지 데이터 외 정보를 기록하는 필드에는 프레임 순서 정보, 설정 정보, 파라미터 정보 등 다양한 정보가 기록될 수 있다. 이러한 프레임 데이터에는 미리 설정 된 정보가 기록되는 것이 일반적이지만, 사용자에 따라 자유롭게 설정하고 입력할 수 있는 예비 필드를 포함하 는 경우가 있다. 본 명세서에 따른 상기 영상편집모듈은 상기 자유롭게 정보를 입력할 수 있는 필드에 상 기 표적 정보를 기록할 수 있다. 도 6에는 H.265 코덱을 사용하는 예시가 도시되어 있는바, 상기 영상편집모듈은 상기 표적추론모듈로 부터 수신한 표적 정보를 SEI(Supplement Enhancement Information) NAL 유닛으로 생성하되, 표적추론모듈이 표적 정보를 생성할 때 사용된 분석 대상 이미지의 프레임 순서 정보에 대응하여 SEI NAL 유닛을 생성할 수 있 다. 한편, 본 명세서에 따른 영상편집모듈이 어느 프레임에 표적 정보를 입력하는지 알 수 있는 프레임 순서 정보는 다양한 방법으로 획득할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 영상편집모듈은 미리 설 정된 프레임 순서 정보에 따라 표적 정보를 포함하는 프레임 데이터를 생성할 수 있다. 도 6에 도시된 예시를 참조하여 설명하자면, 상기 영상편집모듈은 가장 처음으로 입력되는 이미지 데이터부터 4개의 간격으로 표 적 정보가 전달될 것이 미리 설정된 경우이다. 본 명세서의 다른 실시예에 따르면, 상기 영상편집모듈은 상기 카메라모듈로부터 상기 표적추론모듈이 표적 정보를 생성할 때 사용된 분석 대상 이미지의 프레 임 순서 정보를 수신하고, 수신된 분석 대상 이미지의 프레임 순서 정보를 이용하여 표적 정보를 포함하는 프레 임 데이터를 생성할 수 있다. 도 6에 도시된 예시를 참조하여 설명하자면, 상기 상기 카메라모듈은 분석 대상 이미지의 프레임 순서에 대한 정보로서 \"0, 4, 8, ...\"을 영상편집모듈에게 제공할 수 있다. 상기 영 상편집모듈은 상기 표적추론모듈에서 출력된 표적 정보를 상기 프레임 순서 정보에 맞추어 표적 정보를 포함하는 프레임 데이터를 생성할 수 있다. 본 명세서의 또 다른 실시예에 따르면, 상기 영상편집모듈 은 상기 표적추론모듈로부터 수신한 표적 정보 내에 포함된 분석 대상 이미지의 프레임 순서 정보를 이용 하여 표적 정보를 포함하는 프레임 데이터를 생성할 수 있다. 이 경우, 상기 표적추론모듈은 상기 카메라 모듈로부터 수신한 분석 대상 이미지의 프레임 순서에 대한 정보를 표적 정보에 포함시킬 수 있다. 따라서, 상기 영상편집모듈은 표적 정보에 포함된 프레임 순서 정보를 읽고, 읽어낸 프레임 순서 정보에 대응하는 영상과 함께 프레임 데이터를 생성할 수 있다. 상기 설명된 과정을 거쳐서 생성된 프레임 데이터는 상기 통신모듈를 거쳐, 상기 중앙 관제 장치에게 전달될 수 있다. <중앙 관제 장치> 본 명세서에 따른 중앙 관제 장치는 본 명세서에 따른 감시 장치의 운영과 관련된 전반적인 사항을 제 어할 수 있다. 상기 감시 장치가 드론과 같이 이동 가능한 형태로 구현된 경우, 상기 중앙 관제 장치는 감시 장치의 이동 방향, 속도, 고도 등을 제어할 수 있다. 또한, 상기 중앙 관제 장치는 상기 감시 장 치에 포함된 카메라 등이 전방을 촬영하도록 제어할 수 있다. 또한, 상기 중앙 관제 장치는 앞서 설명 한 감시 장치의 운영모드 중 어느 모드로 동작할 것인지 제어 신호를 출력할 수 있다. 또한, 본 명세서에 따른 중앙 관제 장치는 본 명세서에 따른 감시 장치로부터 영상 및/또는 표적 정보 를 수신할 수 있다. 상기 감시 장치로부터 수신된 영상 및/또는 표적 정보는 운영모드에 따라 다르게 처리 할 수 있다. 상기 중앙 관제 장치는 상기 감시 장치로부터 수신한 표적 정보에 포함된 대상물이 미리 설정된 주요 대상물 리스트에 포함된 대상물일 때, 상기 감시 장치의 운영모드를 제1 모드에서 제2 내지 제4 모드 중 어느 한 운영모드로 전환하도록 제어할 수 있다. 상기 감시 장치가 제1 모드로 운영될 때, 상기 중앙 관제 장치 는 영상 없이 표적 정보만 수신할 수 있다. 상기 중앙 관제 장치는 수신된 표적 정보에 포함된 데이터 를 분석하고, 상기 감시 장치의 운영모드를 제1 모드로 유지할 것인지 또는 다른 모드로 변환할 것인지 제 어할 수 있다. 예를 들어 상기 중앙 관제 장치는 대상물이 동물로 분석된 표적 정보인 경우 제1 모드를 유 지하도록 설정되어 있고, 대상물이 사람으로 분석된 표적 정보인 경우 제2 모드 내지 제4 모드 중 어느 하나로 변경하도록 설정된 것을 가정해보겠다. 상기 중앙 관제 장치가 대상물이 동물로 분석된 표적 정보를 수신했 을 때, 상기 상기 중앙 관제 장치는 상기 감시 장치의 운영모드를 제1 모드로 유지하도록 제어할 수 있 다. 반면, 상기 중앙 관제 장치가 대상물이 사람으로 분석된 표적 정보를 수신했을 때, 상기 중앙 관제 장 치는 상기 감시 장치의 운영모드를 제2 모드 내지 제4 모드 중 어느 하나로 변경하도록 제어할 수 있다. 상기 제2 모드 내지 제4 모드 중 어느 모드로 변경할 것인가는 다양하게 설정될 수 있다. 일 예에 따르면, 상기 중앙 관제 장치의 운영자가 임의 또는 미리 정해진 규칙에 따라 수동으로 모드 변경을 제어할 수 있다. 다른 예에 따르면, 상기 중앙 관제 장치가 처리해야 하는 데이터양에 따라 설정될 수 있다. 제2 모드 및 제3 모드의 경우, 표적 정보와 영상 정보를 처리하는 과정이 필요하므로 상기 중앙 관제 장치에 데 이터 처리 부하가 발생할 수 있다. 반면, 제4 모드의 경우, 영상 정보에 표적 정보가 표시되어 있는바, 상기 중 앙 관제 장치에 영상 처리 외 추가적인 데이터 처리 부하가 발생하지 않을 수 있다. 상기 중앙 관제 장치 가 다수의 감시 장치로부터 동시에 데이터를 수신하고 이들을 처리해야 할 경우, 상기 중앙 관제 장치 는 상기 감시 장치의 운영모드를 제4 모드로 변환하도록 제어할 수 있다. 반면, 상기 중앙 관제 장치 가 데이터를 처리할 능력이 충분한 경우, 상기 중앙 관제 장치는 상기 감시 장치의 운영모드를 제2 모드 또는 제3 모드로 변환하도록 제어할 수 있다. 상기 제3 모드보다 제2 모드의 전력 소모량이 상대적으로 적 으므로, 상기 중앙 관제 장치는 상기 감시 장치의 잔여 전력량 또는 소모 전력량을 고려하여 운영모드 를 변환할 수 있다. 한편, 상기 감시 장치가 제3 모드로 동작할 때 수신된 데이터는 표적 정보와 영상 정보가 통합된 상태이므 로 이를 분리해서 처리할 필요가 있다. 상기 감시 장치의 운영 모드가 제3 모드일 때, 상기 중앙 관제 장치(3 0)는 표적 정보를 포함하는 데이터 프레임을 수신할 수 있다. 상기 중앙 관제 장치는 수신한 데이터 프레임 에서 표적 정보를 추출하고, 추출된 표적 정보를 이용하여 표적 정보를 포함하는 데이터 프레임의 영상에 표적 정보를 표시할 수 있다. 이때, 표적 정보가 표시된 영상은 도 5에 도시된 제4 모드의 예시와 동일할 수 있다. 그리고 상기 중앙 관제 장치는 표적 정보가 표시된 영상을 디스플레이를 통해 재생시킬 수 있다.한편, 상기 중앙 관제 장치가 수신한 데이터 프레임들 중 표적 정보를 포함하지 않는 데이터 프레임이 있다. 이러한 데이터 프레임에 포함된 영상을 디스플레이를 통해 재생할 때, 화면에는 표적 정보가 깜빡이는 것 처럼 보일 수 있다. 깜박임 방지를 위해 상기 중앙 관제 장치는 표적 정보를 이용하여 수신한 데이터 프레 임 중 표적 정보를 포함하고 있지 않는 데이터 프레임에 포함된 영상에서 대상물을 추적할 수 있다. 영상 내 대 상물을 특정하고, 이를 추적하는 방법은 당업자에게 알려진 다양한 방법이 있으므로 상세한 설명은 생략하겠다. 그리고 상기 중앙 관제 장치는 영상 내 추적된 대상물에 표적 정보를 표시할 수 있다. 보다 구제적으로, 4 개의 프레임 데이터마다 표적 정보가 포함될 경우, 표적 정보가 수신된 프레임 데이터를 제외한 이후 3개의 프 레임 데이터에 포함된 영상에서 대상물 추적 알고리즘을 실행시킬 수 있다. 표적 정보에는 표적 정보를 포함한 프레임 데이터의 영상 내에서 대상물이 어디에 위치하고 있는 그 위치 정보가 있을 수 있다. 따라서, 표적 정보 가 포함되지 않은 이후 3개의 프레임 데이터 내 영상 전체를 검색하지 않더라도, 대상물의 위치를 파악하는 것 은 용이할 수가 있다. 이상 도면을 참조하여 본 명세서에 따른 엣지 인공지능 시스템을 설명하였으며, 상기 엣지 인공지능 시스템 에 포함된 감시 장치 및 중앙 관제 장치, 또한 상기 감시 장치에 포함된 카메라모듈, 표 적추론모듈, 중앙제어모듈, 영상편집모듈 및 통신모듈 등은 본 명세서에서 설명된 다양한"}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "제어 로직을 실행하기 위해 본 발명이 속한 기술분야에 알려진 프로세서, ASIC(application-specific integrated circuit), 다른 칩셋, 논리 회로, 레지스터, 통신 모뎀, 데이터 처리 장치 등을 포함할 수 있다. 또 한, 상술한 제어 로직이 소프트웨어로 구현될 때, 상기 각 구성 요소들은 프로그램 모듈의 집합으로 구현될 수 있다. 이 때, 프로그램 모듈은 상기 메모리장치에 저장되고, 프로세서에 의해 실행될 수 있다. 상기 프로그램은, 상기 컴퓨터가 프로그램을 읽어 들여 프로그램으로 구현된 상기 방법들을 실행시키기 위하여, 상기 컴퓨터의 프로세서(CPU)가 상기 컴퓨터의 장치 인터페이스를 통해 읽힐 수 있는 C/C++, C#, JAVA, Python, 기계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 상기 방법들을 실행하는 필 요한 기능들을 정의한 함수 등과 관련된 기능적인 코드(Functional Code)를 포함할 수 있고, 상기 기능들을 상 기 컴퓨터의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수 있다. 또 한, 이러한 코드는 상기 기능들을 상기 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 상기 컴퓨터의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조되어야 하는지에 대한 메모리 참조관련 코드 를 더 포함할 수 있다. 또한, 상기 컴퓨터의 프로세서가 상기 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠한 다른 컴퓨터나 서버 등과 통신이 필요한 경우, 코드는 상기 컴퓨터의 통신 모듈을 이용하여 원격에 있는 어떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하는지 등에 대한 통신 관련 코드를 더 포함할 수 있다. 상기 저장되는 매체는, 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반 영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상기 저 장되는 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있지만, 이에 제한되지 않는다. 즉, 상기 프로그램은 상기 컴퓨터가 접속할 수 있는 다양한 서버 상의 다양한 기록매체 또는 사용자의 상기 컴퓨터상의 다양한 기록매체에 저장될 수 있다. 또한, 상기 매체는 네트워크로 연결된 컴퓨터 시 스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장될 수 있다."}
{"patent_id": "10-2021-0041942", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 명세서의 실시예를 설명하였지만, 본 명세서가 속하는 기술분야의 통상의 기술자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있 다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한 적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2021-0041942", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 명세서에 따른 엣지 인공지능 시스템의 개략적인 개념도이다. 도 2는 본 명세서에 따른 감시 장치에 포함될 수 있는 구성의 개략적인 블럭도이다. 도 3은 본 명세서에 따른 표적추론모듈의 구성을 개략적으로 도시한 블럭도이다. 도 4는 본 명세서에 따른 표적추론모듈의 영상 분석 흐름을 개략적으로 도시한 참고도이다. 도 5는 본 명세서에 따른 운영모드의 참고도이다. 도 6은 본 명세서에 따른 영상편집모듈의 구성을 개략적으로 도시한 블럭도이다."}
