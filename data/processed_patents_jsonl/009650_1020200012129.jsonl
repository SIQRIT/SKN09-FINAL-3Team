{"patent_id": "10-2020-0012129", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0098220", "출원번호": "10-2020-0012129", "발명의 명칭": "시청자 반응에 따른 컨텐츠 변환 장치", "출원인": "주식회사 아이티엑스에이아이", "발명자": "박동욱"}}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "메모리와;메모리에 저장된 제어 데이터를 읽어 들여 입력되는 데이터를 처리하는 적어도 하나의 정보 처리 시스템을 포함하며, 상기 정보 처리 시스템은 :출력되는 멀티미디어 컨텐츠에 대한 시청자 반응을 검출하는 반응 검출부와;반응 검출부에서 검출된 시청자 반응에 따라 멀티미디어 컨텐츠에 대한 맞춤 반응을 결정하는 맞춤 반응 결정부와;출력되는 멀티미디어 컨텐츠의 반응 클립을 결정된 맞춤 반응이 반영된 맞춤반응 클립으로 변환하되, 케릭터의동일성(identity)은 변경하지 않고 그 반응을 변경하는 반응 클립 변환부;를 포함하는 멀티미디어 컨텐츠 변환 장치."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 반응 검출부는 : 시청자의 얼굴의 표정을 정해진 카테고리 중 하나로 분류하여 반응을 검출하는 표정 기반 반응 검출부;시청자의 자세의 변화로부터 동작을 정해진 카테고리 중 하나로 분류하여 반응을 검출하는 동작 기반 반응 검출부;시청자의 음성을 정해진 카테고리 중 하나로 분류하여 반응을 검출하는 음성 기반 반응 검출부;중의 적어도 하나를 포함하는 멀티미디어 컨텐츠 변환 장치."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서, 상기 반응 검출부는 네트워크를 통해 수신한 다수의 시청자 영상으로부터 각각의 시청자의 반응을 검출하고 종합하여 시청자 반응을결정하는 멀티미디어 컨텐츠 변환 장치."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서, 상기 맞춤 반응 결정부는 검출된 시청자 반응과, 추가로 반응 클립의 내용에 따라 멀티미디어 컨텐츠의 반응 클립에 대응되는 맞춤 반응을 결정하는 멀티미디어 컨텐츠 변환 장치."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서, 반응 클립 변환부는 : 인공 지능 알고리즘에 기반하여 멀티미디어 컨텐츠에 포함된 반응 클립과, 결정된 맞춤 반응 정보로부터 맞춤반응이 반영된 맞춤반응 클립을 생성하여 출력하는 반응 클립 생성부와;멀티미디어 컨텐츠에 포함된 반응 클립을 생성된 맞춤 반응 클립으로 치환하여 출력하는 반응 클립 치환부;를 포함하는 멀티미디어 컨텐츠 변환 장치."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서, 공개특허 10-2021-0098220-3-상기 맞춤 반응 결정부는 검출된 시청자 반응에 따라 케릭터의 맞춤 반응 동작을 결정하는 맞춤 반응 동작 결정부를 포함하고, 상기 반응 클립 변환부는 출력되는 멀티미디어 컨텐츠의 반응 클립을 결정된 맞춤 반응 동작이 반영된 맞춤 반응 클립으로 변환하되, 케릭터의 동일성은 변경하지 않고 그 동작을 변경하는 반응 클립 동작 변환부를 포함하는 멀티미디어 컨텐츠 변환 장치."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서, 상기 맞춤 반응 결정부는 검출된 시청자 반응에 따라 케릭터의 맞춤 반응 표정을 결정하는 맞춤 반응 표정 결정부를 더 포함하고, 상기 반응 클립 변환부는 출력되는 멀티미디어 컨텐츠의 반응 클립을 결정된 맞춤 반응 표정이 반영된 맞춤 반응 클립으로 변환하되, 케릭터의 동일성은 변경하지 않고 그 반응 표정을 변경하는 반응 클립 표정 변환부를 포함하는 멀티미디어 컨텐츠 변환 장치."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "메모리와; 메모리에 저장된 제어 데이터를 읽어 들여 입력되는 데이터를 처리하는 적어도 하나의 정보 처리 시스템에서 실행되는 멀티미디어 컨텐츠 변환 방법에 있어서, 출력되는 멀티미디어 컨텐츠에 대한 시청자 반응을 검출하는 반응 검출 단계와;반응 검출 단계에서 검출된 시청자 반응에 따라 멀티미디어 컨텐츠에 대한 맞춤 반응을 결정하는 맞춤 반응 결정 단계와;출력되는 멀티미디어 컨텐츠의 반응 클립을 결정된 맞춤 반응이 반영된 맞춤반응 클립으로 변환하되, 케릭터의동일성(identity)은 변경하지 않고 그 반응을 변경하는 반응 클립 변환 단계;를 포함하는 멀티미디어 컨텐츠 변환 방법."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서, 반응 검출 단계는 : 시청자의 얼굴의 표정을 정해진 카테고리 중 하나로 분류하여 반응을 검출하는 표정 기반 반응 검출 단계;시청자의 자세의 변화로부터 동작을 정해진 카테고리 중 하나로 분류하여 반응을 검출하는 동작 기반 반응 검출단계;시청자의 음성을 정해진 카테고리 중 하나로 분류하여 반응을 검출하는 음성 기반 반응 검출 단계;중의 적어도 하나를 포함하는 멀티미디어 컨텐츠 변환 방법."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 1에 있어서, 상기 반응 검출 단계는 네트워크를 통해 수신한 다수의 시청자 영상으로부터 각각의 시청자의 반응을 검출하고 종합하여 시청자 반응을 결정하는 멀티미디어 컨텐츠 변환 방법."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 8에 있어서, 상기 맞춤 반응 결정 단계는 검출된 시청자 반응과, 추가로 반응 클립의 내용에 따라 멀티미디어 컨텐츠의 반응클립에 대응되는 맞춤 반응을 결정하는 멀티미디어 컨텐츠 변환 방법."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 8에 있어서, 반응 클립 변환 단계는 : 인공 지능 알고리즘에 기반하여 멀티미디어 컨텐츠에 포함된 반응 클립과, 결정된 맞춤 반응 정보로부터 맞춤공개특허 10-2021-0098220-4-반응이 반영된 맞춤반응 클립을 생성하여 출력하는 반응 클립 생성 단계와;멀티미디어 컨텐츠에 포함된 반응 클립을 생성된 맞춤 반응 클립으로 치환하여 출력하는 반응 클립 치환 단계;를 포함하는 멀티미디어 컨텐츠 변환 방법."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 8에 있어서, 상기 맞춤 반응 결정 단계는 검출된 시청자 반응에 따라 케릭터의 맞춤 반응 동작을 결정하는 맞춤 반응 동작결정 단계를 포함하고, 상기 반응 클립 변환 단계는 출력되는 멀티미디어 컨텐츠의 반응 클립을 결정된 맞춤 반응 동작이 반영된 맞춤반응 클립으로 변환하되, 케릭터의 동일성은 변경하지 않고 그 동작을 변경하는 반응 클립 동작 변환 단계를 포함하는 멀티미디어 컨텐츠 변환 방법."}
{"patent_id": "10-2020-0012129", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 8에 있어서, 상기 맞춤 반응 결정 단계는 검출된 시청자 반응에 따라 케릭터의 맞춤 반응 표정을 결정하는 맞춤 반응 표정결정 단계를 더 포함하고, 상기 반응 클립 변환 단계는 출력되는 멀티미디어 컨텐츠의 반응 클립을 결정된 맞춤 반응 표정이 반영된 맞춤반응 클립으로 변환하되, 케릭터의 동일성은 변경하지 않고 그 반응 표정을 변경하는 반응 클립 표정 변환 단계를 포함하는 멀티미디어 컨텐츠 변환 방법."}
{"patent_id": "10-2020-0012129", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "멀티미디어 컨텐츠의 자동 편집에 관한 기술이 개시된다. 당초 일방성 컨텐츠로 제작된 멀티미디어 컨텐츠의 일부인 반응 클립이 시청자 반응에 따라 결정된 맞춤 반응 클립으로 변환된다. 시청자 반응을 검출하고, 그에 대응하여 맞춤 반응이 결정된다. 멀티미디어 컨텐츠의 일부인 반응 클립이 결정된 맞춤 반응에 따른 맞춤 반응 클립으로 변환된다. 시청자의 얼굴의 표정이나 자세의 변화 또는 음성을 분석하여 시청자 반응을 검출할 수 있다. 맞춤 반응으로의 변환은 케릭터의 동일성을 변경하지 않고 반응 동작이나 반응 표정을 변경하는 과정을 포함할 수 있다."}
{"patent_id": "10-2020-0012129", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "멀티미디어 컨텐츠의 자동 편집에 관한 기술이 개시된다."}
{"patent_id": "10-2020-0012129", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "2009.04.24.자 출원되어 2010.11.01.자 등록된 한국 특허제992,509호는 컨텐츠의 케릭터의 목소리나 동작/표정 을 부호, 형제 등 지인의 목소리나 동작/표정으로 변조하여 제공하는 아이디어를 개시하고 있다. 그러나 목소 리를 변조하는 구체적인 방법에 대해 실현 가능한 방안을 제시하지 못하고 있으며, 동작이나 표정의 변조와 관 련해서도 구체적인 변조 방법에 대해 제시하지 못하고 있다. 아이디어의 제시에 그친 이러한 수준에서 발전하여, 최근의 딥러닝에 기초한 기술은 동작이나 목소리, 얼굴의 변환 분야에서 혁신적인 기술을 제시하고 있다. GAN(Generative -Adversarial Network) 기술을 통해 사진의 표정을 바꾼다든지 자세를 바꾸는 것이 섬세하게 가능해졌다. Liqian Ma, et al. “Pose Guided Person Image Generation”, 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA, 25 May 2017 논문은 이러한 GAN 네트워크의 한 형태를 이용하여 자세(pose) 정보에 기초하여 영상 속의 사 람의 자세를 바꾸는 기술을 개시하고 있다. VLSI 기술의 적용이 인공 지능 엔진에서도 확대되고 있어 이러한 기술들의 실시간 구현도 가능해지고 있다. 한편, 사용자 반응형(interactive) 멀티미디어 컨텐츠의 제작은 장면마다 다양한 경우의 수를 고려하여야 하기 때문에 현실적으로 불가능하다. 최근 들어 사람과 자연어 소통을 하면서 저장된 모션 클립을 적절히 선택하여 재생하는 제한된 범위의 인공 지능 로봇이 제시되고 있으나 그 응용 분야 별로 방대한 량의 데이터에 의한 학습 이 선행되어야 한다."}
{"patent_id": "10-2020-0012129", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "제안된 발명은 멀티미디어 컨텐츠를 재생시 시청자 반응에 따라 재생되는 아바타의 동작을 변화시키는 새로운 기술을 제시하는 것을 목적으로 한다. 나아가 제안된 발명은 사용자 반응형으로 제작되지 않은 멀티미디어 컨텐츠를 사용자 반응형으로 변환하는 것을 목적으로 한다."}
{"patent_id": "10-2020-0012129", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제안된 발명의 일 양상에 따르면, 당초 일방성 컨텐츠로 제작된 멀티미디어 컨텐츠의 일부인 반응 클립이 시청 자 반응에 따라 결정된 맞춤 반응 클립으로 변환된다. 시청자 반응을 검출하고, 그에 대응하여 맞춤 반응이 결 정된다. 멀티미디어 컨텐츠의 일부인 반응 클립이 결정된 맞춤 반응에 따른 맞춤 반응 클립으로 변환된다. 추가적인 양상에 따르면, 시청자의 반응은 클라우드 서버에 의해 검출될 수 있다. 나아가 클라우드 서버는 네 트워크를 통해 수신한 다수의 시청자 영상으로부터 각각의 시청자의 반응을 검출하고 종합하여 시청자 반응을 결정할 수 있다. 추가적인 양상에 따르면, 시청자의 얼굴의 표정을 정해진 카테고리들 중 하나로 분류함으로써 시청자 반응을 검 출할 수 있다. 나아가 또 다른 양상에 따르면, 시청자의 자세의 변화로부터 동작을 정해진 카테고리들 중 하나 로 분류함으로써 시청자 반응을 검출할 수 있다. 나아가 또 다른 양상에 따르면, 시청자의 음성을 정해진 카테 고리들 중 하나로 분류함으로써 시청자 반응을 검출할 수 있다. 추가적인 양상에 따르면, 맞춤 반응은 반응 동작을 포함할 수 있다. 나아가 또 다른 양상에 따르면, 맞춤 반응 은 반응 표정을 포함할 수 있다. 추가적인 양상에 따르면, 시청자 반응은 시청자 영상을 입력 받아 소정 범위의 반응 중 하나를 결정하여 출력하 는 인공 지능 엔진에 의해 처리될 수 있다."}
{"patent_id": "10-2020-0012129", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "제안된 발명에 따라, 당초 일방성으로 제작된 멀티미디어 컨텐츠로 시청자 반응에 응답하는 응답형 서비스를 제 공할 수 있다. 예를 들어 인터넷 강의의 경우 많은 시청자들을 대상으로 동일한 컨텐츠가 제공되어 시청자의 반응에 전혀 반응하지 않으므로 집중력을 떨어뜨린다. 시청자가 해당 강의에 집중하고 있는 정도나 순간적인 반응을 포착하여 강사가 그에 따른 적절한 행동을 하도록 변형함으로써, 녹화 강의에 대한 집중력을 높일 수 있 다."}
{"patent_id": "10-2020-0012129", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한, 그리고 추가적인 양상들은 첨부된 도면을 참조하여 설명하는 실시예들을 통해 구체화된다. 각 실시예 들이 다른 실시예들과 비교하여 차이가 나거나 추가적으로 구비하는 구성요소들은 다른 언급이나 상호간에 모순 이 없는 한 상호간에 다양한 조합이 가능한 것으로 이해되어야 한다. 청구범위는 개시된 실시예들의 구성요소 들 간의 조합에 의해 파생되는 다양한 실시예들을 포괄하도록 의도되었다. 도 1은 제안된 발명의 일 실시예에 따른 컨텐츠 변환 장치가 적용된 멀티미디어 서비스 시스템의 일 예를 도시 한다. 도시된 멀티미디어 서비스 시스템은 컨텐츠 서비스 서버(30,31)와, 공중망 및 수신단 시스템(11 내 지 17)을 포함할 수 있다. 컨텐츠 서비스 서버(30,31)는 방송 스케쥴에 따라 디지털 컨텐츠를 스트리밍 서비스 하는 방송 송출 시스템일 수 있다. 또 다른 예로, 컨텐츠 서비스 서버(30,31)는 주문형 컨텐츠 서비스 시스템 일 수 있다. 컨텐츠 데이터베이스에 저장된 컨텐츠들은 재생 서버에서 재생되고 스트리밍 서버에 의해 클라이언트들에게 스트리밍 서비스될 수 있다. 부하 분산 시스템에 의해 클라이언트 접속 부하가 분산될 수 있다. 공중망은 유선, 무선, 혹은 이들의 조합일 수 있다. 이들은 인터넷 서비스 제공자들의 유선 네트워 크나, 이동통신 사업자들의 이동 통신망을 포함할 수 있으며, 건물 내 유, 무선 통신망을 포함할 수 있다. 도 시된 시스템에서 수신단 시스템은 셋탑 박스, 예를 들면 OTT(Over-The-Top) 박스와, 디스플레이로 구성 될 수 있다. 또 다른 예로, 수신단 시스템은 테블릿이나 스마트폰과 같은 이동통신 단말기일 수 있다. 일 양상에 따르면, 제안 발명에 따른 컨텐츠 변환 장치는 수신단 시스템, 예를 들면 셋탑 박스의 일부로 구 현될 수 있다. 또 다른 예로, 제안 발명에 따른 컨텐츠 변환 장치는 스마트 폰이나 테블릿에 포함된 응용 프로그램과, 이 응용 프로그램과 협업하는 전용 하드웨어, 예를 들면 인공 지능 엔진이 탑재된 주변 기기 로 구현될 수 있다. 또 다른 예로, 제안 발명에 따른 컨텐츠 변환 장치는 스마트 폰이나 테블릿에 포함 된 응용 프로그램과, 이 응용 프로그램과 협업하는 컨텐츠 변환 서버, 예를 들면 인공 지능 프로그램을 고 속으로 실행하는 고성능 그래픽 서버로 구현될 수 있다. 컨텐츠 서비스 서버에서 스트리밍으로 송출되는 일방성 컨텐츠의 일부인 반응 클립이 이러한 컨텐츠 변환 장치에 따라 시청자 반응에 따라 결정된 맞춤 반응 클 립으로 변환될 수 있다. 이하에 설명하는 실시예들은 장치로 설명되고 있지만, 정보 처리 시스템에서 구현되는 경우 하드웨어는 정보 흐 름의 순서를 따라 구현되며 경우에 따라서는 소프트웨어, 즉 컴퓨터에서 실행 가능한 프로그램으로 구현될 수도 있다. 특히 인공지능 알고리즘과 같은 고도의 복잡성을 가진 알고리즘은 범용 프로세서가 필요한 실행 속도를 따라가지 못하는 부분을 중심으로 전용 하드웨어로 구현되는 경우가 많으므로 하드웨어, 즉 장치적인 면과 소프 트웨어, 즉 방법적인 구분이 의미가 없는 경우가 많다. 도시된 실시예들은 장치 관점에서 설명되지만 이들은 그 자체로 첨부된 방법에 관한 청구항들을 뒷받침하고 있다. 제안된 발명의 일 양상에 따르면, 당초 일방성 컨텐츠로 제작된 멀티미디어 컨텐츠의 일부인 반응 클립이 시청 자 반응에 따라 결정된 맞춤 반응 클립으로 변환된다. 시청자 반응을 검출하고, 그에 대응하여 맞춤 반응이 결 정된다. 멀티미디어 컨텐츠의 일부인 반응 클립이 결정된 맞춤 반응에 따른 맞춤 반응 클립으로 변환된다. 도 2는 이러한 제안된 발명의 일 양상이 적용된 일 실시예에 따른 컨텐츠 변환 장치의 구성을 도시한 블록도이 다. 컨텐츠 변환 장치는 메모리와, 메모리에 저장된 제어 데이터를 읽어 들여 입력되는 데이터를 처 리하는 정보 처리 시스템을 포함할 수 있다. 예를 들어 정보 처리 시스템은 전체 장치를 제어하는 범 용 마이크로 프로세서와, 전용 하드웨어로 구현되고 각각이 특정한 딥러닝 알고리즘의 수행에 최적화된 구조를 가지는 복수의 인공 지능 엔진, 그리고 가변적인 구조를 가지고 속도에 민감하지 않은 인공 지능 알고리즘들 혹 은 그 일부를 처리하는 재구성 가능한(re-configurable) 구조를 가진 프로세서 어레이를 포함할 수 있다. 정보 처리 시스템의 입력인 멀티미디어 컨텐츠는, 예를 들면 단말기가통신 모듈을 통해 스트리밍으로 수신하여 코덱을 통해 재생하여 출력하는 컨텐츠일 수 있다. 또 다른 예로, 단말기가 메모리에서 읽어 들 여 코덱을 통해 재생하여 출력하는 컨텐츠일 수 있다. 일 실시예에 따르면, 컨텐츠 변환 장치는 반응 검출부와, 맞춤 반응 결정부와, 반응 클립 변환부 를 포함할 수 있다. 반응 검출부는 출력되는 멀티미디어 컨텐츠에 대한 시청자 반응을 검출한다. 일 양상에 따르면, 시청자의 반응은 클라우드 서버에 의해 검출될 수 있다. 이 실시예에 있어서, 정보 처리 시 스템의 반응 검출부는 카메라로부터 수신한 영상 중 적어도 일부의 프레임 혹은 프레임 중 전처 리하여 추출한 얼굴, 몸통 등의 일부 영역을 클라우드 서버로 전송하고, 그 검출된 반응 정보를 수신할 수 있다. 나아가 클라우드 서버는 네트워크를 통해 수신한 다수의 시청자 영상으로부터 각각의 시청자의 반응을 검출하고 종합하여 시청자 반응을 결정할 수 있다. 즉, 도 1의 클라우드 서버는 다수의 정보 처리 시스템 으로부터 시청자의 영상, 음성, 센서 정보 등을 수신하여 각각의 시청자의 반응을 검출한다. 이후에 이들 을 종합하여, 예를 들면 시청자 반응 중 가장 많은 반응을 최종적인 시청자 그룹 반응으로 결정할 수 있다. 도 3은 일 실시예에 따른 반응 검출부의 구성을 도시한 블록도이다. 제안된 발명의 일 양상에 따라, 반응 검출부는 표정 기반 반응 검출부를 포함할 수 있다. 표정 기반 반응 검출부는 시청자의 얼굴의 표정을 정해진 카테고리들 중 하나로 분류함으로써 시청자 반응을 검출할 수 있다. 표정 기반 반응 검출부(11 0)는 먼저 입력 영상에서 얼굴 영역을 검출하여 얼굴 영상을 추출한다. 이후에 예를 들어서 표정 기반 반응 검출부는 추출된 얼굴 영상을 분석하여 시청자의 반응을 검출한다. 일 양상에 따르면, 표정 기반 반응 검출 부는 얼굴 영상에서 표정을 분석하여 시청자의 반응을 결정할 수 있다. 일 실시예에서, 표정 기반 반응 검출부는, 예를 들면 {지루함, 무표정, 놀람, 기쁨, 관심 있음} 과 같이 범위가 정해진 카테고리 중 하나 의 반응을 결정하는 인공 지능 엔진, 예를 들면 심층 컨볼루션 신경망(Deep-Layered Convolutional Neural Network) 모델로 구현될 수 있다. 감정의 분류는 다수의 상이한 카테고리의 감정 중 하나로 분류하는 접근 외에, 예를 들면 흥분 정도 혹은 긍정적/부정적 정도를 연속적인 수치화하는 접근도 알려져 있다. 예를 들면 AffectNet 데이터셋은 이러한 감정 인식을 위한 인공 지능 엔진의 학습에 공개적으로 제공되고 있다. 제안된 발명의 일 양상에 따라, 반응 검출부는 동작 기반 반응 검출부를 포함할 수 있다. 동작 기반 반응 검출부는 시청자의 자세의 변화로부터 동작을 정해진 카테고리 중 하나로 분류하여 반응을 검출할 수 있다. 동작 기반 반응 검출부는 동영상에서 시청자의 머리, 몸통, 팔 등의 골격(skeleton)을 구성하는 관 절과 같은 특징점들로부터 자세(pose)를 검출하고, 이 자세의 변화, 즉 움직임을 정해진 카테고리 중 하나로 분 류하여 반응을 결정할 수 있다. 제안된 발명의 일 양상에 따라, 반응 검출부는 음성 기반 반응 검출부를 포함할 수 있다. 음성 기 반 반응 검출부는 시청자의 얼굴의 표정을 정해진 카테고리들 중 하나로 분류함으로써 시청자 반응을 검출 할 수 있다. 멀티미디어 컨텐츠 속에 산발적으로 존재하는 음성 기반 감정 인식 기술은 여러 개의 분류기를 사 용하는 계층적 분류 방법론에 따라 음성에서 비슷한 감정의 인자를 나누어 분류하는 고전적인 방식, 예를 들면 Z. Xiao, Dellandrea, L. Chen, W. Dou, “Recognition of emotions in speech by a hierarchical approach, ” ACII 2009, 2009, pp.401-408.에 개시된 것과 같은 기술들이 알려져 있다. 또 다른 예로 딥러닝을 이용한 음성 기반 감정 인식 기술들, 예를 들면 이지원 외, “다중 작업 기반의 합성곱 신경망을 이용한 음성 감정인식 ”, 2017년 한국통신학회 하계종합학술대회, 2017. 6. 등의 기술도 알려져 있다. 종합 반응 결정부는 각각의 반응 검출부(110 내지 150)의 출력 정보를 종합하여 최종적으로 반응을 결정한 다. 예를 들어 종합 반응 결정부는 각각의 반응 검출부(110 내지 150)의 출력인 감정값과, 그 감정값의 확률값을 고려하여 가장 확률이 높은 감정값을 선택할 수 있다. 도 3에서 반응 검출부는 표정 기반 반응 검출부와, 동작 기반 반응 검출부와 그리고 음성 기반 반응 검출부를 모두 포함하는 것으로 도시되었지만 제안된 발명은 이들 중 하나를 포함하는 세가지 실시예 도 모두 포함한다. 이 경우 종합 반응 결정부는 생략될 수 있다. 제안된 발명은 또 다른 실시예들로, 표 정 기반 반응 검출부와, 동작 기반 반응 검출부와 그리고 음성 기반 반응 검출부 중 둘의 조합 또는 셋을 모두 포함하며 각각의 출력들을 종합하여 반응을 결정하는 실시예들을 모두 포함한다. 예를 들어 시청자를 촬영한 음성, 영상을 동시에 처리하여 감정을 판단하는 멀티모달 딥러닝 기반 감정 인식 기 술, 예를 들면 Z. Xiao, Dellandrea, L. Chen, W. Dou, “Recognition of emotions in speech by a hierarchical approach,” ACII 2009, 2009, pp.401-408.이 제안된 발명에 적용될 수 있다. 전술한 바와 같이, 도 3의 실시예에 있어서 각각의 반응 검출부(110,130,150)의 처리 과정의 적어도 일부는 클 라우드 서버에서 실행될 수 있다. 도 2로 돌아가서 맞춤 반응 결정부는 반응 검출부에서 검출된 시청자 반응에 따라 멀티미디어 컨텐츠 에 대한 맞춤 반응을 결정한다. 예를 들어 맞춤 반응은 주의를 환기시키는 몇 가지 제스쳐, 익살스런 표정, 좌 우로 왕복하는 동작, 몇 가지 포즈들이 될 수 있다. 맞춤 반응의 결정은 매핑 함수에 의해 단순하게 구현될 수 있다. 예를 들어 시청자 반응에 경험적으로 적절하다고 생각되는 맞춤 반응이 매핑될 수 있다. 검출된 시청자 반응에 일률적으로 매핑된 맞춤 반응은 단조롭고 흥미를 잃게 하기 쉬우므로, 하나의 시청자 반응값에 매핑되는 맞춤 반응을 복수 개 중 랜덤하게 선택하거나, 아니면 시간값 등 다른 추가적인 변수값을 함께 고려하여 결정할 수 있다. 추가적인 양상에 따라, 맞춤 반응 결정부는 검출된 시청자 반응과, 추가로 반응 클립의 내용에 따라 멀티 미디어 컨텐츠의 반응 클립에 대응되는 맞춤 반응을 결정할 수 있다. 일 실시예에서, 멀티미디어 컨텐츠에 서 변환될 부분에 해당하는 반응 클립의 내용은, 예를 들면 {고난이도 논리 설명 중, 단순 지식 전달 중, 흥미 유도 중, 잠시 중단 중} 과 같이 정해진 카테고리 중 하나로 결정될 수 있다. 이들은 인덱스로 참조될 수있다. 추가적인 양상이 적용된 일 실시예에서, 맞춤 반응은 f(r,c)와 같은 매핑 함수로 구현될 수 있다. 여기서 r 은 시청자 반응 인덱스, c는 변환될 반응 클립의 내용 인덱스이다. 즉, 이 실시예에서 맞춤 반응은 시청자 반 응과 반응 클립의 내용에 따라 매핑되어 결정될 수 있다. 이러한 매핑은 컨텐츠의 변환 컨셉이나 방향을 결정 하는 기획자의 의도에 따라 결정될 수 있다. 도 2를 참조하면, 반응 클립 변환부는 출력되는 멀티미디어 컨텐츠의 반응 클립을 결정된 맞춤 반응이 반 영된 맞춤반응 클립으로 변환하되, 케릭터의 동일성(identity)은 변경하지 않고 그 반응을 변경한다. 일 실시 예에서, 반응 클립 변환부는 멀티미디어 컨텐츠의 반응 클립을 영상 프레임 단위로 입력 받아, 결정된 맞 춤 반응이 반영된 맞춤반응 클립으로 변환한다. 반응 클립 변환부는 이러한 타겟 자세로 변환된 정지 영 상들을 생성한다. 동영상의 모든 프레임에 대해 반응 클립을 변환하기 보다, 샘플링된 프레임만 변환한 후 또 다른 영상처리 엔진을 통해 그 사이의 프레임들을 추정하는 방식으로 동영상을 생성할 수 있다. 도 2에 도시된 실시예에 있어서, 반응 검출부는 6층의 깊이를 가진 (layered) CNN(Convolutional Neural Network)으로 구현될 수 있다. 이러한 인공 지능 회로는 멀티 코어를 가진 그래픽 처리 회로로 구현될 수 있다. 또 다른 예로, 실시간 구현을 위해 설계된 게이트 어레이 기반의 전용 회로로 구현될 수도 있다. 또 맞 춤 반응 결정부는 규칙 기반(rule-based)의 맞춤 반응을 결정하는 마이크로프로세서에서 실행되는 컴퓨터 프로그램으로 구현될 수 있다. 또 반응 클립 변환부는 딥 컨볼루션(Deep Convolutional) GAN (DCGAN) 모 델을 포함하여 구현될 수 있다. 이러한 DCGAN 은 목표하는 처리 속도에 맞춘 전용 하드웨어로 설계되어 구현될 수 있다. 또 다른 예에서, 반응 클립 변환부의 처리 과정의 적어도 일부는 클라우드 서버에서 실행될 수 있다. 이러한 구현 기술은 각 기능 블록별로 설계 목적에 따라, 사양에 따라 또 공정 기술의 선택에 따라 몇 가지 방 식이 알려져 있으며, 제안된 발명과 같이 복잡한 알고리즘을 하나의 신호 처리 프로세서나 범용 마이크로프로세 서에서, 또는 하나의 서버 컴퓨터에서 구현하는 것은 현재로는 쉽지 않아 보인다. 도 4는 또 다른 실시예에 따른 컨텐츠 변환 장치의 구성을 도시한 블록도이다. 일 양상에 따르면, 일방성 컨텐 츠로 당초 제작된 멀티미디어 컨텐츠의 일부인 반응 클립이 시청자 반응에 따라 결정된 맞춤 반응 클립으로 치 환된다. 도 4에 도시된 실시예에 있어서, 반응 클립 변환부는 반응 클립 생성부와, 반응 클립 치환 부를 포함할 수 있다. 반응 클립 생성부는 인공 지능 알고리즘에 기반하여 멀티미디어 컨텐츠에 포함 된 반응 클립과, 결정된 맞춤 반응 정보로부터 맞춤 반응이 반영된 맞춤반응 클립을 생성하여 출력할 수 있다. 반응 클립 치환부는 멀티미디어 컨텐츠에 포함된 반응 클립을 생성된 맞춤 반응 클립으로 치환하여 출력할 수 있다. 제안된 발명의 추가적인 양상에 따르면, 맞춤 반응은 반응 동작을 포함할 수 있다. 도시된 실시예에서, 맞춤 반응 결정부는 맞춤 반응 동작 결정부를 포함할 수 있다. 맞춤 반응 동작은 예를 들면 {손 제스쳐 1, 손 제스쳐 2, 고개 추임새, 일어나기} 등 정해진 범주의 동작 중 하나로 인덱스에 의해 지정될 수 있다. 또 다 른 예로, 맞춤 반응 동작 정보는 시계열 순서로 나열된 각 관절 점의 좌표값들의 집합일 수 있다. 인체의 그래 프 모델의 각 관절점들에 대해 순서를 정의하고 각 관절점들의 어떤 시각에서의 위치를 좌표값으로 표현할 수 있다. 한 시각에서의 각 관절점들의 좌표를 나타내는 순서쌍들을 시간 순서로 나열하여 케릭터의 동작 정보를 표현할 수 있다. 맞춤 반응 동작 결정부는 검출된 시청자 반응에 따라 맞춤 반응 동작을 매핑하여 결정한다. 검출된 시청 자 반응에 일률적으로 매핑된 반응 동작은 단조롭고 흥미를 잃게 하기 쉬우므로, 하나의 시청자 반응값에 매핑 되는 맞춤 반응 동작을 복수 개 중 랜덤하게 선택하거나, 아니면 시간값 등 다른 추가적인 변수값을 함께 고려 하여 결정할 수 있다. 추가적인 양상에 따라, 맞춤 반응 동작 결정부는 멀티미디어 컨텐츠에서 변환 될 반응 클립의 내용을 맞춤 반응의 결정에 반영할 수 있다. 일 실시예에서, 멀티미디어 컨텐츠에서 변환 될 부분에 해당하는 반응 클립의 내용은, 예를 들면 {고난이도 논리 설명 중, 단순 지식 전달 중, 흥미 유도 중, 잠시 중단 중} 과 같이 정해진 카테고리 중 하나로 결정될 수 있다. 이들은 인덱스로 참조될 수 있다.일 양상에 따라 반응 클립 생성부는 반응 클립 동작 변환부를 포함할 수 있다. 반응 클립 동작 변환 부는 출력되는 멀티미디어 컨텐츠의 반응 클립을 결정된 맞춤 반응 동작이 반영된 맞춤 반응 클립으로 변 환하되, 케릭터의 동일성(identity)은 변경하지 않고 그 동작을 변경한다. 일 실시예에서, 생성적 적대 신경망 (Generative Adversarial Networks : GANs)을 이용하여 반응 클립을 변환할 수 있다. 전술한 Liqian Ma, et al. “Pose Guided Person Image Generation”, 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA, 25 May 2017 논문은 새로운 자세(novel pose)와 입력 영상으로부터 타겟 영상을 생성하는 기술을 개시하고 있다. 이 장치는 2 단계로 된 구조를 가진다. 1단계는 U-Net 과 유사한 구조 를 가진 길쌈 오토인코더(convolutional autoencoder)를 포함하며, 입력 영상과, 18개의 키 포인트들의 좌표로 표현되는 새로운 자세(novel pose)를 합성(integrate)하여 타겟과 기본적으로 동일한 색상과 자세를 가진 다소 희미한(blurry) 영상을 생성한다. 2단계는 변형된 조건부 DCGAN(variant of conditional Deep Convolution GAN) 을 포함하며, 적대적 학습(adversarial training)을 통해 입력된 다소 희미한 영상을 정교화(refinemen t)한다. 도시된 실시예에서, 반응 클립 치환부는 멀티 미디어 컨텐츠의 일부를 구성하는 반응 클립을 반응 클립 동 작 변환부가 생성한 맞춤반응 클립으로 치환하여 출력한다. 제안된 발명의 추가적인 양상에 따르면, 맞춤 반응은 반응 표정을 포함할 수 있다. 도 5는 또 다른 실시예에 따 른 컨텐츠 변환 장치의 구성을 도시한 블록도이다. 도시된 실시예에서, 맞춤 반응 결정부는 맞춤 반응 표 정 결정부를 포함할 수 있다. 맞춤 반응 표정은 예를 들면 {큰 웃음, 미소, 찡그림, 코메디1, 코메디2, 화 난 표정} 등 정해진 범주의 동작 중 하나로 인덱스에 의해 지정될 수 있다. 또 다른 예로, 맞춤 반응 동작 정 보는 시계열 순서로 나열된 각 특징 점의 좌표값들의 집합일 수 있다. 얼굴의 그래프 모델의 각 특징점들에 대 해 순서를 정의하고 각 특징점들의 어떤 시각에서의 위치를 좌표값으로 표현할 수 있다. 한 시각에서의 각 관 절점들의 좌표를 나타내는 순서쌍들을 시간 순서로 나열하여 얼굴의 표정 정보를 표현할 수 있다. 맞춤 반응 표정 결정부는 검출된 시청자 반응에 따라 맞춤 반응 표정을 매핑하여 결정한다. 검출된 시청 자 반응에 일률적으로 매핑된 반응 표정은 단조롭고 흥미를 잃게 하기 쉬우므로, 하나의 시청자 반응값에 매핑 되는 맞춤 반응 표정을 복수 개 중 랜덤하게 선택하거나, 아니면 시간값 등 다른 추가적인 변수값을 함께 고려 하여 결정할 수 있다. 추가적인 양상에 따라, 맞춤 반응 표정 결정부는 멀티미디어 컨텐츠에서 변환 될 반응 클립의 내용을 맞춤 반응의 결정에 반영할 수 있다. 일 실시예에서, 멀티미디어 컨텐츠에서 변환 될 부분에 해당하는 반응 클립의 내용은, 예를 들면 {고난이도 논리 설명 중, 단순 지식 전달 중, 흥미 유도 중, 잠시 중단 중} 과 같이 정해진 카테고리 중 하나로 결정될 수 있다. 이들은 인덱스로 참조될 수 있다. 일 양상에 따라 반응 클립 생성부는 반응 클립 표정 변환부를 포함할 수 있다. 반응 클립 표정 변환 부는 출력되는 멀티미디어 컨텐츠의 반응 클립을 결정된 맞춤 반응 표정이 반영된 맞춤 반응 클립으로 변 환하되, 케릭터의 동일성(identity)은 변경하지 않고 그 표정을 변경한다. 일 실시예에서, 생성적 적대 신경망 (Generative Adversarial Networks : GANs)을 이용하여 반응 클립을 변환할 수 있다. 생성적 적대 신경망 (Generative Adversarial Networks : GANs)에 기반하여 케릭터의 동일성을 유지하면서 타겟 표정으로 바꾸어주 는 표정 변환(facial expression translation) 기술이 알려져 있다. Hao Tang et al., “Expression Conditional GAN for Facial Expression-to-Expression Translation”, ICIP 2019 논문은 부가적인 표정 속성 (additional expression attribute)에 기초하여 한 이미지 도메인에서 다른 것으로 매핑하는 EC- GAN(Expression Conditional GAN) 기술을 개시하고 있다. 도시된 실시예에서, 반응 클립 치환부는 멀티 미디어 컨텐츠의 일부를 구성하는 반응 클립을 반응 클립 표 정 변환부가 생성한 맞춤반응 클립으로 치환하여 출력한다. 도 6은 또 다른 실시예에 따른 컨텐츠 변환 장치의 구성을 도시한 블록도이다. 도시된 실시예에서 맞춤 반응 결정부는 맞춤 반응 표정 결정부와 맞춤 반응 동작 결정부를 포함한다. 또 반응 클립 변환부 는 반응 클립 표정 변환부와 반응 클립 동작 변환부 및 반응 클립 치환부를 포함한다. 맞춤 반응 표정 결정부는 도 5에 도시된 실시예의 대응되는 구성과, 맞춤 반응 동작 결정부는 도 4에 도시된 실시예의 대응되는 구성과 유사하다. 반응 클립 표정 변환부는 도 5에 도시된 실시예의 대응되는 구성과 유사하다. 반응 클립 동작 변환부는 입력이 반응 클립 표정 변환부에서 생성된 영상인 점을제외하고는 도 4에 도시된 실시예의 대응되는 구성과 유사하다. 이상에서 본 발명을 첨부된 도면을 참조하는 실시예들을 통해 설명하였지만 이에 한정되는 것은 아니며, 이들로 부터 당업자라면 자명하게 도출할 수 있는 다양한 변형예들을 포괄하도록 해석되어야 한다. 특허청구범위는 이 러한 변형예들을 포괄하도록 의도되었다."}
{"patent_id": "10-2020-0012129", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 컨텐츠 변환 장치가 적용된 디지털 방송 시스템의 일 예를 도시한다. 도 2는 일 실시예에 따른 컨텐츠 변환 장치의 구성을 도시한 블록도이다. 도 3은 도 2의 반응 검출부의 일 실시예의 구성을 도시한 블록도이다. 도 4는 또 다른 실시예에 따른 컨텐츠 변환 장치의 구성을 도시한 블록도이다. 도 5는 또 다른 실시예에 따른 컨텐츠 변환 장치의 구성을 도시한 블록도이다. 도 6은 또 다른 실시예에 따른 컨텐츠 변환 장치의 구성을 도시한 블록도이다."}
