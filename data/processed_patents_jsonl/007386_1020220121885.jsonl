{"patent_id": "10-2022-0121885", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0043216", "출원번호": "10-2022-0121885", "발명의 명칭": "객체 인식 장치 및 방법", "출원인": "현대자동차주식회사", "발명자": "김준형"}}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "2D 이미지를 획득하는 카메라;3D 정보를 획득하는 라이다; 및3D 정보를 바탕으로 생성된 2차원 평면 조감도(Bird's Eye View; BEV)에서 특징을 추출하여 BEV 특징맵을 생성하고, 2D 이미지에 상기 3D 정보가 추가된 다채널 2D 이미지에 대한 특징을 추출하여 이미지 특징맵을생성하며, 상기 이미지 특징맵과 상기 BEV 특징맵을 혼합하여 복합 특징맵을 생성하고, 상기 복합 특징맵을 인공지능 학습하여 객체를 인식하는 프로세서;를 포함하는 객체 인식 장치."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 프로세서는상기 라이다로부터 강도 정보, 밀도 정보, 및 높이 정보를 바탕으로 BEV 이미지를 획득하고, 컨볼루션 신경망을이용하여 상기 BEV 이미지를 학습하여 BEW 특징맵을 생성하는 것을 특징으로 하는 객체 인식 장치."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 프로세서는상기 2D 이미지에 상기 3D 정보를 맵핑하여, 다채널 2D 이미지를 생성하며, 상기 다채널 2D 이미지를 학습하여이미지 특징맵을 생성하는 것을 특징으로 하는 객체 인식 장치."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 프로세서는 상기 2D 이미지에 상기 라이다가 획득한 상기 강도 정보, 상기 밀도 정보, 및 상기 3차원 좌표 정보를 맵핑하여채널 수가 확장된 상기 다채널 2D 이미지를 생성하는 것을 특징으로 하는 객체 인식 장치."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서,상기 프로세서는상기 강도 정보, 상기 밀도 정보, 및 상기 3차원 좌표 정보의 Z값을 0~1의 크기로 정규화하는 것을 특징으로 하는 객체 인식 장치.공개특허 10-2024-0043216-3-청구항 6 제 3 항에 있어서,상기 프로세서는 확장된 컨볼루션(dilated convolution) 신경망을 이용하여, 상기 다채널 2D 이미지를 학습하는 것을 특징으로하는 객체 인식 장치."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 프로세서는 상기 이미지 특징맵과 상기 BEV 특징맵의 채널 수를 확장하여 상기 복합 특징맵을 생성하는 것을 특징으로 하는객체 인식 장치."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 프로세서는상기 이미지 특징맵의 해상도를 보정하여 상기 BEV 특징맵의 해상도와 동일한 보정 이미지 특징맵을 생성하고,상기 보정 이미지 특징맵과 상기 BEV 특징맵에서 서로 대응되는 좌표들의 성분을 혼합하여 상기 복합 특징맵을생성하는 것을 특징으로 하는 객체 인식 장치."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 프로세서는가산법, 결합법, 또는 평균, 또는 이들의 조합 중에서 적어도 하나를 이용하여 상기 보정 이미지 특징맵과 상기BEV 특징맵에서 서로 대응되는 좌표들의 특징값을 혼합하는 것을 특징으로 하는 객체 인식 장치."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 프로세서는 YOLO(You Only Look Once) 모델을 이용하여, 상기 복합 특징맵을 학습하는 것을 특징으로 하는 객체 인식 장치."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "프로세서가, 3D 정보를 바탕으로 생성된 2차원 평면 조감도(Bird's Eye View; BEV)에서 특징을 추출하여, BEV특징맵을 생성하는 단계;상기 프로세서가, 2D 이미지에 상기 3D 정보를 추가된 다채널 2D 이미지에 대한 특징을 추출하여, 이미지 특징맵을 생성하는 단계; 상기 프로세서가, 상기 이미지 특징맵과 상기 BEV 특징맵을 혼합하여, 복합 특징맵을 생성하는 단계; 및공개특허 10-2024-0043216-4-상기 복합 특징맵을 학습하여 객체를 인식하는 단계;를 포함하는 객체 인식 방법."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 BEV 특징맵을 생성하는 단계는라이다가, 강도 정보, 밀도 정보, 및 3차원 좌표 정보를 포함하는 상기 3D 정보를 획득하는 단계;상기 프로세서가, 상기 강도 정보, 밀도 정보, 및 상기 3차원 좌표 정보 중에서 높이 정보를 포함하는 BEV 이미지를 획득하는 단계; 및상기 프로세서가, 컨볼루션 신경망을 이용하여 상기 BEV 이미지를 학습하는 단계;를 포함하는 것을 특징으로 하는 객체 인식 방법."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 이미지 특징맵을 생성하는 단계는카메라가, RGB 이미지를 획득하는 단계;상기 프로세서가, 상기 RGB 이미지에 상기 3D 정보를 맵핑하여, 다채널 2D 이미지를 생성하는 단계; 및 상기 프로세서가, 상기 다채널 2D 이미지를 학습하는 단계;를 포함하는 것을 특징으로 하는 객체 인식 방법."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 다채널 2D 이미지를 생성하는 단계는 상기 RGB 이미지에 상기 라이다가 획득한 상기 강도 정보, 상기 밀도 정보, 및 상기 3차원 좌표 정보를 맵핑하여 8개의 채널 수를 갖는 상기 다채널 2D 이미지를 생성하는 것을 특징으로 하는 객체 인식 방법."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 13 항에 있어서,상기 다채널 2D 이미지를 생성하는 단계는상기 강도 정보, 상기 밀도 정보, 및 상기 3차원 좌표 정보 중에서 Z값을 0~1의 크기로 정규화하는 단계를 더포함하는 것을 특징으로 하는 객체 인식 방법."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 13 항에 있어서,상기 다채널 2D 이미지를 학습하는 단계는확장된 컨볼루션(dilated convolution) 신경망을 이용하는 것을 특징으로 하는 객체 인식 방법.공개특허 10-2024-0043216-5-청구항 17 제 11 항에 있어서,상기 이미지 특징맵과 상기 BEV 특징맵을 혼합하여 상기 복합 특징맵을 생성하는 단계는상기 이미지 특징맵과 상기 BEV 특징맵의 채널 수를 확장하는 단계를 포함하는 것을 특징으로 하는 객체 인식방법."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 이미지 특징맵과 상기 BEV 특징맵을 혼합하여, 복합 특징맵을 생성하는 단계는상기 이미지 특징맵의 해상도와 상기 BEV 특징맵의 해상도를 일치시키는 단계; 및상기 이미지 특징맵과 상기 BEV 특징맵에서 서로 대응되는 좌표들의 성분을 혼합하는 단계;를 포함하는 것을 특징으로 하는 객체 인식 방법."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서,상기 이미지 특징맵과 상기 BEV 특징맵에서 서로 대응되는 좌표들의 특징값을 혼합하는 단계는가산법, 결합법, 또는 평균, 또는 이들의 조합 중에서 적어도 하나를 이용하는 것을 특징으로 하는 객체 인식방법."}
{"patent_id": "10-2022-0121885", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 11 항에 있어서,상기 복합 특징맵을 학습하여 객체를 인식하는 단계는YOLO(You Only Look Once) 모델을 이용하는 것을 특징으로 하는 객체 인식 방법."}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 객체 인식 장치 및 방법에 관한 것으로, 본 발명의 실시 예에 의한 객체 인식 장치는 2D 이미지를 획 득하는 카메라, 3D 정보를 획득하는 라이다, 및 3D 정보를 바탕으로 생성된 2차원 평면 조감도(Bird's Eye View; BEV)에서 추출된 특징값으로 BEV 특징맵을 생성하고, 2D 이미지에 3D 정보가 추가된 다채널 2D 이미지에 대한 특 징을 추출하여 이미지 특징맵을 생성하며, 이미지 특징맵과 BEV 특징맵을 혼합하여 복합 특징맵을 생성하고, 복 합 특징맵을 인공지능 학습하여 객체를 인식하는 프로세서를 포함할 수 있다."}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 객체 인식 장치 및 방법에 관한 것으로, 보다 상세하게는 보다 정확하게 객체를 판별할 수 있는 기술 에 관한 것이다."}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자동차는 사용되는 원동기의 종류에 따라, 내연기관(internal combustion engine) 자동차, 외연기관(external combustion engine) 자동차, 가스터빈(gas turbine) 자동차 또는 전기자동차(electric vehicle) 등으로 분류될 수 있다. 자율주행 자동차(Autonomous Vehicle)란 운전자 또는 승객의 조작 없이 자동차 스스로 운행이 가능한 자동차를 말하며, 자율주행 시스템(Automated Vehicle & Highway Systems)은 이러한 자율주행자동차가 스스로 운행될 수 있도록 모니터링하고 제어하는 시스템을 말한다. 자율주행 자동차뿐만 아니라, 운전자의 운전 보조를 위해서 차량의 외부를 모니터링하고, 모니터링 된 차량 외 부 환경을 바탕으로 다양한 운전 보조 수단을 동작하는 기술들이 제안되고 있다. 따라서, 운전 보조 수단의 동작을 더욱 정밀하게 제어하기 위해서는 차량의 외부 환경을 보다 빠르고 정확하게 모니터링할 필요성이 있다."}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 차량의 외부 환경을 보다 빠르고 정확하게 모니터링할 수 있는 객체 인식 장치 및 방법을 제공하기 위한 것이다. 또한, 본 발명은 사이즈만으로 분류하기 어려운 객체를 보다 정확하게 분류할 수 있는 객체 인식 장치 및 방법 을 제공하기 위한 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재들로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 의한 객체 인식 장치는 2D 이미지를 획득하는 카메라, 3D 정보를 획득하는 라이다, 및 3D 정보를 바탕으로 생성된 2차원 평면 조감도(Bird's Eye View; BEV)에서 추출된 특징값으로 BEV 특징맵을 생성하 고, 2D 이미지에 3D 정보가 추가된 다채널 2D 이미지에 대한 특징을 추출하여 이미지 특징맵을 생성하며, 이미 지 특징맵과 BEV 특징맵을 혼합하여 복합 특징맵을 생성하고, 복합 특징맵을 인공지능 학습하여 객체를 인식하 는 프로세서를 포함할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 라이다로부터 강도 정보, 밀도 정보, 및 높이 정보를 바탕으로 BEV 이 미지를 획득하고, 컨볼루션 신경망을 이용하여 상기 BEV 이미지를 학습하여 BEW 특징맵을 생성할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 2D 이미지에 상기 3D 정보를 맵핑하여, 다채널 2D 이미지를 생성하며, 상기 다채널 2D 이미지를 학습하여 이미지 특징맵을 생성할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 2D 이미지에 상기 라이다가 획득한 상기 강도 정보, 상기 밀도 정보, 및 상기 3차원 좌표 정보를 맵핑하여 채널 수가 확장된 상기 다채널 2D 이미지를 생성할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 강도 정보, 상기 밀도 정보, 및 상기 3차원 좌표 정보의 Z값을 0~1의 크기로 정규화할 수 있다. 실시 예에 의하면, 상기 프로세서는 확장된 컨볼루션(dilated convolution) 신경망을 이용하여, 상기 다채널 2D 이미지를 학습할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 이미지 특징맵과 상기 BEV 특징맵의 채널 수를 확장하여 상기 복합 특 징맵을 생성할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 이미지 특징맵의 해상도를 보정하여 상기 BEV 특징맵의 해상도와 동일 한 보정 이미지 특징맵을 생성하고, 상기 보정 이미지 특징맵과 상기 BEV 특징맵에서 서로 대응되는 좌표들의 성분을 혼합하여 상기 복합 특징맵을 생성할 수 있다. 실시 예에 의하면, 상기 프로세서는 가산법, 결합법, 또는 평균, 또는 이들의 조합 중에서 적어도 하나를 이용 하여 상기 보정 이미지 특징맵과 상기 BEV 특징맵에서 서로 대응되는 좌표들의 특징값을 혼합할 수 있다. 실시 예에 의하면, 상기 프로세서는 YOLO(You Only Look Once) 모델을 이용하여, 상기 복합 특징맵을 학습할 수 있다. 본 발명의 실시 예에 의한 객체 인식 방법은 프로세서가 3D 정보를 바탕으로 생성된 2차원 평면 조감도(Bird's Eye View; BEV)에서 특징을 추출하여 BEV 특징맵을 생성하는 단계, 프로세서가 2D 이미지에 상기 3D 정보를 추 가된 다채널 2D 이미지에 대한 특징을 추출하여 이미지 특징맵을 생성하는 단계, 프로세서가 이미지 특징맵과 BEV 특징맵을 혼합하여 복합 특징맵을 생성하는 단계, 및 복합 특징맵을 학습하여 객체를 인식하는 단계를 포함 할 수 있다. 실시 예에 의하면, 상기 BEV 특징맵을 생성하는 단계는 라이다가 강도 정보, 밀도 정보, 및 3차원 좌표 정보를 포함하는 상기 3D 정보를 획득하는 단계, 상기 프로세서가 상기 강도 정보, 밀도 정보, 및 상기 3차원 좌표 정 보 중에서 높이 정보를 포함하는 BEV 이미지를 획득하는 단계 및 상기 프로세서가 컨볼루션 신경망을 이용하여상기 BEV 이미지를 학습하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 이미지 특징맵을 생성하는 단계는 카메라가 RGB 이미지를 획득하는 단계, 상기 프로세 서가 상기 RGB 이미지에 상기 3D 정보를 맵핑하여, 다채널 2D 이미지를 생성하는 단계 및 상기 프로세서가 상기 다채널 2D 이미지를 학습하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 다채널 2D 이미지를 생성하는 단계는 상기 RGB 이미지에 상기 라이다가 획득한 상기 강 도 정보, 상기 밀도 정보, 및 상기 3차원 좌표 정보를 맵핑하여 8개의 채널 수를 갖는 상기 다채널 2D 이미지를 생성하는 것일 수 있다. 실시 예에 의하면, 상기 다채널 2D 이미지를 생성하는 단계는 상기 강도 정보, 상기 밀도 정보, 및 상기 3차원 좌표 정보 중에서 Z값을 0~1의 크기로 정규화하는 단계를 더 포함할 수 있다. 실시 예에 의하면, 상기 다채널 2D 이미지를 학습하는 단계는 확장된 컨볼루션(dilated convolution) 신경망을 이용하는 것일 수 있다. 실시 예에 의하면, 상기 이미지 특징맵과 상기 BEV 특징맵을 혼합하여 상기 복합 특징맵을 생성하는 단계는 상 기 이미지 특징맵과 상기 BEV 특징맵의 채널 수를 확장하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 이미지 특징맵과 상기 BEV 특징맵을 혼합하여, 복합 특징맵을 생성하는 단계는 상기 이 미지 특징맵의 해상도와 상기 BEV 특징맵의 해상도를 일치시키는 단계 및 상기 이미지 특징맵과 상기 BEV 특징 맵에서 서로 대응되는 좌표들의 성분을 혼합하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 이미지 특징맵과 상기 BEV 특징맵에서 서로 대응되는 좌표들의 특징값을 혼합하는 단계 는 가산법, 결합법, 또는 평균, 또는 이들의 조합 중에서 적어도 하나를 이용하는 것일 수 있다. 실시 예에 의하면, 상기 복합 특징맵을 학습하여 객체를 인식하는 단계는 YOLO(You Only Look Once) 모델을 이 용하는 것일 수 있다."}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 의하면, 객체의 사이즈를 판별할 수 있는 3D 정보와 객체의 형상을 판별할 수 있는 2D 정 보를 혼합한 복합 특징맵을 이용하여 YOLO 모델 기반의 학습을 진행함으로써, 보다 빠르게 개체를 인식할 수 있 다. 또한, 본 발명의 실시 예에 의하면, 복합 특징맵을 이용하기 때문에, 형태와 사이즈가 유사하여 3D 정보로 분류 가 난해한 객체들을 2D 이미지 정보에 기반하여 보다 정확하게 분류할 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시예를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 실시예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생략한 다. 본 발명의 실시예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소 의 본질이나 차례 또는 순서 등이 한정되지 않는다. 또한, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용 어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들 은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정 의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 도 1 내지 도 17을 참조하여, 본 발명의 실시 예들을 구체적으로 설명하기로 한다. 도 1은 본 발명의 일 실시 예에 객체 추적 장치를 포함하는 차량을 나타내는 도면이다. 도 2는 객체 추적 장치 의 구성을 나타내는 도면이다. 도 1을 참조하면, 본 발명의 실시 예에 의한 차량은 외관을 형성하는 본체, 차량을 이동시키는 차륜 (61, 62), 차량 내부를 외부로부터 차폐시키는 도어, 차량 내부의 사용자에게 차량 전방의 시야를 제공하는 전면 유리, 사용자에게 차량의 측, 후방 시야를 제공하는 사이드미러(81, 82)을 포함할 수 있 다. 차륜(61, 62)은 차량의 전방에 마련되는 전륜, 차량의 후방에 마련되는 후륜을 포함하며, 전륜 및 후륜은 구동장치에 의해서 회전하여 차량을 이동시킬 수 있다. 도어는 본체의 좌측 및 우측에 회동 가능하게 마련되어 개방 시에 탑승자가 차량의 내부에 탑승할 수 있도록 하며, 폐쇄 시에 차량의 내부를 외부로부터 차폐시킬 수 있다. 윈드 스크린의 일종인 전면 유리는 본체의 전방 상측에 마련되어 차량 내부의 운전자 또는 사용자에 게 차량 전방의 시야 정보를 제공할 수 있다. 사이드미러(81, 82)는 본체의 좌측에 마련되는 좌측 사이드미러 및 우측에 마련되는 우측 사이드미러 를 포함하며, 차량 내부의 운전자가 차량 측, 후방의 시야 정보를 제공할 수 있다. 차량은 전기자동차(Electric Vehicle, EV), 하이브리드 차량(Hybrid Electric Vehicle, HEV), 플러그인 하 이브리드 차량(Plug-in Hybrid Electric Vehicle, PHEV), 또는 수소전기차 (Fuel Cell Electric Vehicle, FCEV) 등의 전동화 기반의 차량일 수 있다. 전동화 기반의 차량일 경우, 구동 장치는 구동 모터일 수 있다. 도 2는 본 발명의 실시 예에 의한 객체 인식 장치를 나타내는 블록도이다. 도 2를 참조하면, 본 발명의 실시 예에 의한 객체 인식 장치는 센서부 및 프로세서를 포함할 수 있다. 센서부는 차량 주위의 객체를 추출하기 위한 센싱 데이터를 획득하기 위한 것으로, 카메라, 및 라이다 (LIDAR) 등을 포함할 수 있다. 카메라, 및 라이다가 형성되는 위치는 도 1에 한정되지 않을 수 있 다. 카메라는 차량 전방에서 가시광선 영역의 빛을 감지한 것을 바탕으로 영상 데이터를 획득할 수 있다. 라이다는 레이저 펄스를 송출하고, 송출된 레이저 펄스가 반사되는 시간을 측정하여 객체를 판별할 수 있다. 라이다는 3차원 정보를 제공할 수 있다. 또한 센서부는 도 1에서와 같이, 전자기파를 송출하고 되돌아오는 전자파를 분석하여 객체를 분석하는 레이 더를 더 포함할 수 있다. 레이더는 2차원 정보를 제공할 수 있으며, 객체에 대한 정보를 빠르게 제공 할 수 있다. 프로세서는 카메라 및 라이다가 획득한 정보를 바탕으로 객체를 추출하고 객체를 분류할 수 있다. 프로세서는 3D 정보를 바탕으로 2차원 평면 조감도(Bird's Eye View; BEV)에 대한 특징을 추출하여 BEV 특 징맵을 생성할 수 있다. 또한, 프로세서는 2D 이미지에 3D 정보가 추가된 다채널 2D 이미지를 획득할 수 있다. 또한, 프로세서는 다채널 2D 이미지에 대한 특징을 추출하여 이미지 특징맵을 생성할 수 있다. 또한, 프로세서는 이미지 특징맵과 BEV 특징맵을 혼합하여 복합 특징맵을 생성하고, 복합 특징맵을 인공지 능 학습하여 객체를 인식할 수 있다. 저장부는 객체 인식을 위한 알고리즘을 저장할 수 있다. 객체 인식을 위한 알고리즘은 인공지능 기반으로 수행될 수 있고, 이를 위해서, 프로세서는 인공지능 (artificial intelligence; 이하, AI) 프로세서를 포함할 수 있다. AI 프로세서는 미리 저장된 프로그램을 이 용하여 신경망을 학습할 수 있다. 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며, 인 간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네 트워크 모드들은 뉴런이 시냅스(synapse)를 통해 신호를 주고 받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데이터를 주고 받을 수 있다. 신경망은 신경망 모델에서 발전한 딥러닝 모델을 포함할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치하면서 컨볼루션(convolution) 연결 관계 에 따라 데이터를 주고 받을 수 있다. 신경망 모델의 예는 심층 신경망(DNN, deep neural networks), 합성곱 신 경망(CNN, convolutional deep neural networks), 순환 신경망(RNN, Recurrent Boltzmann Machine), 제한 볼츠 만 머신(RBM, Restricted Boltzmann Machine), 심층 신뢰 신경망(DBN, deep belief networks), 심층 Q-네트워 크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들을 포함할 수 있다. 또한, 저장부는 YOLO(You Only Look Once) 모델을 포함할 수 있다. 저장부는 프로세서 내에 구비 될 수 있고, 별도의 메모리가 될 수 있다. 따라서, 저장부는 하드 디스크 드라이브, 플래시 메모리, EEPROM(Electrically erasable programmable read-only memory), SRAM(Static RAM), FRAM (Ferro-electric RAM), PRAM (Phase-change RAM), MRAM(Magnetic RAM), DRAM(Dynamic Random Access Memory), SDRAM(Synchronous Dynamic Random Access Memory), DDR-SDRAM(Double Date Rate- SDRAM) 등으로 이루어질 수 있다. 도 3은 본 발명의 실시 예에 의한 객체 인식 방법을 설명하는 순서도이다. 도 4는 본 발명의 실시 예에 의한 객 체 인식 방법을 설명하는 모식도이다. 도 3은 도 1 및 도 2에 도시된 객체 인식 장치에 의해서 수행되는 절차를 설명하고 있다. 도 3 및 도 4를 참조하여, 본 발명의 실시 예에 의한 객체 인식 방법을 살펴보면 다음과 같다. S310에서, 프로세서는 BEV 이미지에서 특징값(feature)를 추출하여 BEV 특징맵을 생성할 수 있다. 이를 위해서, 프로세서는 라이다로부터 BEV 이미지를 제공받을 수 있고, 또는 라이다로부터 제공 받은 3D 정보를 바탕으로 BEV 이미지를 생성할 수 있다. 또한, 프로세서는 컨볼루션 신경망(Convolutional Neural Network; CNN)을 바탕으로, BEV 이미지로부터 BEV 특징맵을 생성할 수 있다. S320에서, 프로세서는 2D 이미지로부터 이미지 특징맵을 생성할 수 있다. 2D 이미지는 카메라를 통해서 획득된 칼라 영상일 수 있다. 프로세서는 2D 이미지에서 특징값을 추출하여 이미지 특징맵을 생성할 수 있다. 이를 위해서, 프로세서 는 2D 이미지를 인공지능 학습할 수 있다. S330에서, 프로세서는 BEV 특징맵과 이미지 특징맵을 혼합하여, 복합 특징맵을 생성할 수 있다. 복합 특징맵을 생성하기 위해서, 프로세서는 BEV 특징맵과 이미지 특징맵의 해상도를 일치시킬 수 있다. 실시 예에 의하면, 프로세서는 이미지 특징맵의 해상도를 BEV 특징맵의 해상도에 대응하도록 보정하여, 보 정 이미지 특징맵을 생성할 수 있다. S340에서, 프로세서는 복합 특징맵을 인공지능 학습하여 객체를 인식할 수 있다. 프로세서는 객체 인식의 결과는 객체의 3차원 좌표를 출력할 수 있다. 또한, 프로세서는 객체의 폭, 길이 요(yaw) 정보를 출력할 수 있다. 또한, 프로세서는 객체의 클래스(class)를 분류할 수 있고, 분류된 객체들을 라벨링 박스로 표현할 수 있 다. 실시 예에 의하면, 프로세서는 YOLO 모델을 이용하여 복합 특징맵을 학습할 수 있다. 본 발명의 실시 예에 의한 프로세서는 복합 특징맵을 바탕으로 객체를 인식하기 때문에, 2D 이미지 정보 및 3D 라이다 정보를 모두 활용하여 객체를 판별할 수 있다. 따라서, 본 발명의 실시 예에 의하면 보다 정확하 게 객체를 판별함으로써, 객체를 보다 정확하게 분류할 수 있고, 객체가 검출되지 않는 문제점을 개선할 수 있 다. 이하, 본 발명의 실시 예에 의한 각각의 절차들을 보다 자세하게 설명하면 다음과 같다. 도 5는 BEV 이미지의 일례를 나타내는 도면이다. 도 5를 참조하여, 전술한 S310의 절차를 보다 구체적으로 살펴보면 다음과 같다. BEV 이미지를 생성하기 위해서, 프로세서는 라이다로부터 3D 정보를 제공받을 수 있다. 3D 정보는 라이다가 출력하는 로우 데이터(raw data)를 바탕으로 획득될 수 있다. 3D 정보는 객체의 3차원 위치를 나타내는 좌표값(X, Y, Z), 강도(Intensity; I), 및 밀도(Density; D)에 대한 정보를 포함할 수 있다. 프로세서는 3D 정보를 바탕으로 도 5에서와 같은 BEV 이미지를 획득할 수 있다. BEV 이미지는 3차원 라이 다 정보를 2차원 평면에 투사한 조감도일 수 있다. 2차원 평면은 지면에 해당할 수 있다. 또한, 실시 예에 의한 BEV 이미지는 강도 정보, 밀도 정보, 및 3차원 좌표 정보 중에서 높이 정보를 포함할 수 있다. 따라서, BEV 이미지는 3개의 채널을 포함할 수 있다. 일례로 BEV 이미지의 사이즈는 448×896×3일 수 있 다. 프로세서는 컨볼루션 신경망(Convolutional Neural Network; CNN)을 바탕으로, BEV 이미지로부터 BEV 특 징맵을 생성할 수 있다. 프로세서는 컨볼루션 신경망을 기반으로 448×896×32 사이즈로 채널이 확장된 BEV 특징맵을 생성할 수 있다. 도 6은 다채널 2D 이미지의 일례를 나타내는 도면이다. 도 7은 이미지 특징맵을 생성하기 위한 모델을 모식화한 도면이다. 도 8은 이미지 특징맵의 일례를 나타내는 도면이다. 도 6 내지 도 8을 참조하여, 전술한 S320의 절차를 보다 구체적으로 살펴보면 다음과 같다. 프로세서는 카메라로부터 2D 이미지를 제공받을 수 있다. 2D 이미지는 RGB 성분을 포함하는 칼라 영상 일 수 있고, 이에 따라 R채널, G채널, 및 B채널을 포함할 수 있다. 실시 예에 의한 2D 이미지의 해상도는 384× 80일 수 있고, 채널은 R채널, G채널, 및 B채널을 포함하는 3개일 수 있다. 즉, 2D 이미지의 사이즈는 384×80× 3일 수 있다. 프로세서는 2D 이미지에 3D 정보를 부가할 수 있다. 3D 정보는 라이다가 출력하는 로우 데이터(raw data)를 바탕으로 획득될 수 있다. 3D 정보는 객체의 3차원 위치를 나타내는 좌표값(X, Y, Z), 강도(Intensity; I), 및 밀도(Density; D)에 대한 정보를 포함할 수 있다. 프로세서는 2D 이미지에 3D 정보를 부가하여, 채널이 확장된 다채널 2D 이미지를 생성할 수 있다. 실시 예에 의하면, 프로세서는 2D 이미지의 3개의 채널에 3D 정보의 5개 채널을 추가하여 8개의 채널을 갖 는 다채널 2D 이미지를 생성할 수 있다. 다채널 2D 이미지를 생성하기 위해서 추가되는 3D 정보는 좌표값(X, Y, Z), 강도(Intensity; I), 및 밀도 (Density; D)를 포함할 수 있다. 높이 정보(Z)는 0~1의 범위로 조정되어 정규화될 수 있다. 강도(I)는 0~1의 범위로 조정되어 정규화될 수 있다. 밀도(D)는 0~1의 범위로 조정되어 정규화될 수 있다. 다채널 2D 이미지의 사이즈는 다음과 같은 [수학식 1] 및 [수학식 2]을 바탕으로 획득될 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[수학식 2]"}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이때, ximg는 다채널 2D 이미지의 X축 사이즈를 의미하고, yimg는 다채널 2D 이미지의 Y축 사이즈를 의미한다. h_max는 다채널 2D 이미지의 수평 최대 화각을 의미하고, h_min은 다채널 2D 이미지의 수평 최소 화각을 의미한 다. v_max는 다채널 2D 이미지의 수직 최대 화각을 의미하고, v_min는 다채널 2D 이미지의 수직 최소 화각을 의미한다. h_res 및, v_res은 다채널 2D 이미지의 가로세로 픽셀 사이즈를 결정하는 계수를 의미한다. 따라서, (h_max - h_min)은 다채널 2D 이미지에서 보이는 수평 화각이 될 수 있다. 또한, 수평 화각을 h_res로 나누면 다채널 2D 이미지에서 가로 방향으로 몇 픽셀로 표현할지를 나타내는 값을 구할 수 있다. 예를 들어, h_max = 50도, h_min = -50도, h_rev = 1 인 경우, (h_max - h_min)/h_rev = 100으로 계산될 수 있다. 즉, 이와 같은 경우의 다채널 2D 이미지의 가로 사이즈는 100픽셀로 결정될 수 있다. 또한, v_max = 15도, v_min = -15도, v_rev=0.6 인 경우, (v_max - v_min)/v_rev = 50으로 계산될 수 있다. 즉, 이와 같은 경우 다채널 2D 이미지의 세로 사이즈는 50픽셀로 결정될 수 있다. 이와 같은 방법으로 프로세서는 2D 이미지에 3D 정보가 부가된 다채널 2D 이미지를 획득할 수 있다. 프로세서는 도 6에서와 같은 다채널 2D 이미지를 바탕으로 이미지 특징맵을 생성할 수 있다. 이를 위해서, 프로세서는 확장된 컨볼루션(Dilated Convolution)을 이용하여 이미지 특징맵을 생성할 수 있다. 프로세서 는 확장된 컨볼루션에 기반하여 필터 내부에 제로 패딩(zero padding)을 추가해 강제로 수용 필드 (receptive field)를 늘릴 수 있다. 프로세서는 확장된 컨볼루션을 바탕으로 풀링(Pooling)을 수행하지 않 고도 수용 필드의 크기를 크게 할 수 있으며 연산의 효율을 높일 수 있다. 도 7을 참조하면, 확장된 컨볼루션 모델은 제1 내지 제11 모듈들(101~111)을 포함할 수 있다. 제1 모듈은 2D 이미지를 대상으로 3×3 필터를 이용하여, 해상도를 유지하면서 출력 채널이 32인 특징맵을 생성할 수 있다. 제2 모듈은 제1 모듈이 출력한 특징맵을 대상으로, 해상도를 유지하면서 출력 채널이 64인 특징맵을 생성할 수 있다. 제3 모듈은 제2 모듈이 출력한 특징맵을 대상으로, 해상도를 1/4로 줄이면서 출력 채널이 128인 특징 맵을 생성할 수 있다. 제4 모듈은 제3 모듈이 출력한 특징맵을 대상으로, 해상도를 1/4로 줄이면서 출력 채널이 128인 특징 맵을 생성할 수 있다. 제5 모듈은 제4 모듈이 출력한 특징맵을 대상으로, 해상도를 1/4로 줄이면서 출력 채널이 256인 특징 맵을 생성할 수 있다. 제6 모듈은 제5 모듈이 출력한 특징맵을 대상으로, 해상도를 1/4로 줄이면서 출력 채널이 256인 특징 맵을 생성할 수 있다.제7 모듈은 제6 모듈이 출력한 특징맵을 대상으로, 해상도를 4배로 줄이면서 출력 채널이 128인 특징 맵을 생성할 수 있다. 제8 모듈은 제7 모듈이 출력한 특징맵을 대상으로, 해상도를 4배로 줄이면서 출력 채널이 128인 특징 맵을 생성할 수 있다. 제9 모듈은 제8 모듈이 출력한 특징맵을 대상으로, 해상도를 4배로 줄이면서 출력 채널이 64인 특징 맵을 생성할 수 있다. 제10 모듈은 제9 모듈이 출력한 특징맵을 대상으로, 해상도를 4배로 줄이면서 출력 채널이 64인 특징 맵을 생성할 수 있다. 제11 모듈은 제10 모듈이 출력한 특징맵을 대상으로, 해상도를 유지하면서 출력 채널이 32인 특징맵 을 생성할 수 있다. 프로세서는 이와 같이 H×W×8 사이즈의 다채널 2D 이미지를 바탕으로 채널 수가 확장된 H×W×32 사이즈 의 이미지 특징맵을 생성할 수 있다. S330절차에서, 프로세서는 복합 특징맵을 생성하기 위해서, 이미지 특징맵의 해상도와 BEV 특징맵의 해상 도를 일치시킬 수 있다. 이를 위해서, 프로세서는 미리 설정된 좌표 변환맵을 이용할 수 있다. 좌표 변환맵은 2D 이미지와 BEV 이미지간의 맵핑 정보를 포함할 수 있다. 프로세서는 좌표 변환맵을 바탕으로 2D 이미지의 해상도를 BEV 이미지의 해상도로 변환할 수 있다. 좌표 변환맵은 2D 이미지를 획득하는 카메라와 3D 정보를 획득하는 라이다의 캘리브레이션을 이용하여 획득될 수 있다. 도 9는 캘리브레이션을 설명하는 모식도이다. 도 9에서, 월드 좌표(world coordinates)는 라이다가 획득하는 3D 정보의 위치를 표현하는 좌표일 수 있고, 카메라 좌표(camera coordinates)는 카메라가 획득하는 카메라의 렌즈 및 이미지 센서들의 위치를 표현하기 위한 좌표일 수 있다. 이미지 좌표(image coordinates)는 카메라가 획득한 2D 이미지의 픽셀의 위치를 표현하기 위한 좌표일 수 있다. 도 9를 참조하면, 캘리브레이션은 3차원 공간상의 점들이 2차원 이미지 평면에 투영될 때 카메라의 내부 또 는 외부 환경으로 인해 발생하는 기하학적인 요인에 대한 파라미터를 획득하기 위한 것일 수 있다. 파라미터는 현실 3차원 좌표계와 비교하여 카메라의 상대적인 위치를 나타내는 외부 파라미터(Extrinsic parameter) 및 카 메라의 내부 요인 또는 내부 특성을 정의하는 요소들로 구성된 파라미터들을 내부 파라미터(Intrinsic parameters)를 포함할 수 있다. 좌표 변환맵은 파라미터들을 포함하는 캘리브레이션 정보를 바탕으로 미리 설정되어, 저장부에 저장될 수 있다. 도 10은 보정 이미지 특징맵을 생성하는 절차를 설명하는 모식도이다. 도 10을 참조하면, 프로세서는 좌표 변환맵을 이용하여 이미지 특징맵의 해상도를 보정한 보정 이미지 특 징맵을 생성할 수 있다. 예를 들어, 프로세서는 좌표 변환맵을 이용하여, 이미지 특징맵의 x 좌표를 BEV 특징맵의 해상도에 대응하 도록 bev x 좌표로 변환할 수 있다. 마찬가지로, 프로세서는 좌표 변환맵을 이용하여, 이미지 특징맵의 y 좌표를 BEV 특징맵의 해상도에 대응하도록 bev y 좌표로 변환할 수 있다. 즉, 프로세서는 이미지 특징맵의 (x,y) 좌표를 바탕으로 (bev x, bev y)의 좌표를 갖는 보정 이미지 특징맵을 생성할 수 있다. 보정 이미지 특징맵은 BEV 특징맵과 동일한 해상도를 갖는 448×896의 사이즈가 될 수 있다. 이미지 특징맵과 보정 이미지 특징맵의 좌표는 일대일로 매칭되는 것이 아니기 때문에, 보정 이미지 특징맵의 좌표들은 이미지 특징맵의 좌표를 바탕으로 보간된 정보를 이용할 수도 있다. 프로세서는 보정 이미지 특징맵과 BEV 특징맵에서 서로 대응되는 좌표들의 특징값을 혼합하여 복합 특징맵 을 생성하는 절차는 다양한 방법이 이용될 수 있다. 실시 예에 의하면, 프로세서는 가산법을 이용하여 복합 특징맵을 생성할 수 있다. 실시 예에 의하면, 프로세서는 결합법(concatenation)을 이용하여 복합 특징맵을 생성할 수 있다. 실시 예에 의하면, 프로세서는 특징값을 평균하여 복합 특징맵을 생성할 수 있다. 프로세서는 복합 특징맵을 바탕으로 객체를 인식하기 위해서 YOLO 모델을 이용할 수 있다. YOLO 모델은 단일 단계 방식의 객체 인식 알고리즘으로, 이미지 내에 존재하는 객체와 해당 객체의 위치를 한 번만 보고 예측할 수 있는 모델일 수 있다. YOLO 모델은 바운딩 박스와 객체의 속성을 동시에 판별하고, 이를 바탕으로 결과값을 표시할 수 있다. 도 11 내지 도 16은 본 발명의 실시 예에 의한 객체 인식 시뮬레이션 결과를 설명하는 도면이다. 도 11 내지 도 16에서, 일반 YOLO 출력은 YOLO 모델의 입력으로 BEV 특징맵 만을 이용한 결과를 나타내는 도면이고, 실시 예에 의한 YOLO 출력은 이미지 특징맵과 BEV 특징맵을 혼합한 복합 특징맵을 이용하여 YOLO 모델을 구동한 결과를 나 타내는 도면이다. Ground Truth는 정답 데이터를 나타내는 도면이다. 도 11 및 도 12는 클래스 분류의 정확도가 개선된 것을 설명하는 도면이다. 도 11 및 도 12를 참조하면, 일반 YOLO 출력은 3D 정보에 기반하여 사이즈 및 외관의 형태를 중심으로 객체를 판별하기 때문에, 도 12에 도시된 차량을 버스로 오판할 수 있다. 이에 반해서 본 발명의 실시 예에 의하면 3D 정보 이외에 이미지 정보가 혼합된 복합 특징맵을 바탕으로 인공지능 학습을 진행하기 때문에, 도 12에 도시된 차량을 트럭이라고 판별할 수 있다. 도 13 및 도 14는 원거리 객체의 판별 오류의 개선 결과를 나타내는 도면이다. 도 13 및 도 14를 참조하면, 일반 YOLO 출력은 3D 정보에 기반하여 사이즈 및 외관의 형태를 중심으로 객체를 판별하기 때문에, 도 14에서와 같이 차량이 아닌 고정된 구조물을 버스로 오판할 수 있다. 이에 반해서 본 발명 의 실시 예에 의하면 차량의 이미지 정보가 혼합된 복합 특징맵을 바탕으로 인공지능 학습을 진행하기 때문에, 도 14에 도시된 구조물을 차량으로 분류하지 않을 수 있다. 도 15 및 도 16은 원거리 객체의 검출 누락의 개선 결과를 나타내는 도면이다. 도 15 및 도 16을 참조하면, 일반 YOLO 출력은 3D 정보에 기반하여 객체를 판별하기 때문에, 도 16에서와 같이 원거리의 객체로부터 획득되어 3D 정보의 강도가 약한 경우 해당 객체를 검출하지 못할 수 있다. 이에 반해서, 본 발명의 실시 예에 의하면 차량의 이미지 정보가 혼합된 복합 특징맵을 바탕으로 인공지능 학습을 진행하기 때문에, 객체 검출의 정확도를 높일 수 있고, 이에 따라 도 16에서와 같이 원거리에 있는 차량도 보다 정확하게 검출할 수 있다. 본 발명의 실시 예에 의한 객체 인식의 성능 평가를 살펴보면 다음과 같다. [표 1]은 제안 기술을 이용한 정량적 성능 평가를 나타내는 표이고, [표 2]는 공지된 기술에 의한 정량적 성능 평가를 나타내는 표이다. [표 1] 및 [표 2]에서, AP는 평균 정밀도(Average Precision)를 의미하고, mAP(mean Average Precision)는 각 각의 클래스에 대한 AP의 평균을 의미하고, f1 score는 정밀도(precision)와 재현율(recall)의 조화 평균을 의 미한다. 또한, RV는 복합 특징맵을 의미하고, ORI는 BEW 특징맵을 의미한다.[표 1]"}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[표 2]"}
{"patent_id": "10-2022-0121885", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[표 1] 및 [표 2]를 참조하면, 본 발명의 실시 예에 의한 객체 인식 성능은 0~50m 구간과 50m~100m 구간에서 전 반적으로 향상된 것을 확인할 수 있다. 클래스에 따라 살펴보면, 버스 클래스의 경우 50~100m 구간에서 AP가 8% 정도 상승한 것을 알 수 있다. 보행자 클래스의 경우, 50~100m 구간에서 AP가 8% 정도 상승한 것을 확인할 수 있다. 도 17은 본 발명의 일 실시 예에 따른 컴퓨팅 시스템을 도시한다. 도 17을 참조하면, 컴퓨팅 시스템은 버스를 통해 연결되는 적어도 하나의 프로세서, 메모리 , 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치, 스토리지, 및 네트워 크 인터페이스를 포함할 수 있다. 프로세서는 중앙 처리 장치(CPU) 또는 메모리 및/또는 스토리지에 저장된 명령어들에 대한 처리를 실행하는 반도체 장치일 수 있으며, 전술한 프로세서의 일부 또는 모든 기능을 포함할 수 있다. 메 모리 및 스토리지는 다양한 종류의 휘발성 또는 불휘발성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM(Read Only Memory) 및 RAM(Random Access Memory)을 포함할 수 있다. 따라서, 본 명세서에 개시된 실시예들과 관련하여 설명된 방법 또는 알고리즘의 단계는 프로세서에 의해 실행되는 하드웨어, 소프트웨어 모듈, 또는 그 2 개의 결합으로 직접 구현될 수 있다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 디스크, 착탈형 디스크, CD-ROM과 같은 저장 매체(즉, 메모리 및/또는 스토리지)에 상주할 수도 있다. 예시적인 저장 매체는 프로세서에 커플링되며, 그 프로세서는 저장 매체로부터 정보를 판독할 수 있고 저장 매체에 정보를 기입할 수 있다. 다른 방법으로, 저장 매체는 프로세서와 일체형일 수도 있다. 프로세서 및 저장 매체는 주문형 집적회로(ASIC) 내에 상주할 수도 있다. ASIC는 사용자 단말기 내에 상주할 수 도 있다. 다른 방법으로, 프로세서 및 저장 매체는 사용자 단말기 내에 개별 컴포넌트로서 상주할 수도 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위 에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17"}
{"patent_id": "10-2022-0121885", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 객체 추적 장치를 포함하는 차량을 나타내는 도면이다. 도 2는 객체 추적 장치 의 구성을 나타내는 도면이다. 도 3은 본 발명의 실시 예에 의한 객체 인식 방법을 설명하는 순서도이다. 도 4는 본 발명의 실시 예에 의한 객체 인식 방법을 설명하는 모식도이다. 도 5는 BEV 이미지의 일례를 나타내는 도면이다. 도 6은 다채널 2D 이미지의 일례를 나타내는 도면이다. 도 7은 이미지 특징맵을 생성하기 위한 모델을 모식화한 도면이다. 도 8은 이미지 특징맵의 일례를 나타내는 도면이다. 도 9는 캘리브레이션을 설명하는 모식도이다. 도 10은 보정 이미지 특징맵을 생성하는 절차를 설명하는 모식도이다. 도 11 및 도 12는 클래스 분류의 정확도가 개선된 것을 설명하는 도면이다. 도 13 및 도 14는 원거리 객체의 판별 오류의 개선 결과를 나타내는 도면이다. 도 15 및 도 16은 원거리 객체의 검출 누락의 개선 결과를 나타내는 도면이다. 도 17은 본 발명의 실시 예에 따른 컴퓨팅 시스템을 나타내는 도면이다."}
