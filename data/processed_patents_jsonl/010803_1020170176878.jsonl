{"patent_id": "10-2017-0176878", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0075356", "출원번호": "10-2017-0176878", "발명의 명칭": "객체를 식별하기 위한 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "민준홍"}}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치(electronic device)에 있어서,인공 지능 알고리즘에 기반하여 획득된 적어도 하나의 객체(object)에 대한 데이터를 포함하는 트레이닝 데이터베이스(data base)와 명령어들(instructions)을 포함하는 메모리; 적어도 하나의 센서; 및상기 적어도 하나의 센서 및 상기 메모리와 연결된 프로세서를 포함하고, 상기 프로세서는, 상기 적어도 하나의 센서를 이용하여 적어도 하나의 객체를 포함하는 지정된 영역(designated area)에 대한 데이터를 획득하고,상기 트레이닝 데이터 베이스에 기반하여, 상기 적어도 하나의 객체의 위치(location)에 대한 정보 및 자세에대한 정보를 식별하고, 및상기 식별된 위치에 대한 정보 및 상기 자세에 대한 정보에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를 상기 전자 장치와 관련된 피킹툴에게 송신하기 위해 상기 명령어들을 실행하도록 설정되는 전자장치."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 적어도 하나의 센서는, 상기 적어도 하나의 객체가 상기 지정된 영역 내에 포함되는 지 여부, 상기 적어도 하나의 객체의 모양(shape),상기 적어도 하나의 객체의 위치, 상기 적어도 하나의 객체의 자세(position) 중 적어도 하나를 측정하기 위한센서를 포함하는 전자 장치."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 지정된 영역에 대한 데이터는 상기 지정된 영역과 관련된 이미지(image)를 나타내는 정보를 포함하는 전자장치."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서, 상기 적어도 하나의 객체의 위치에 대한 정보는, 상기 적어도 하나의 객체의 상기 지정된 영역 상의 x축의 값,y축의 값 또는 z축의 값 중 적어도 하나를 포함하고, 및상기 적어도 하나의 객체의 자세에 대한 정보는, 상기 적어도 하나의 객체에 대한 요(yaw)에 대한 정보, 롤(roll)에 대한 정보, 또는 피치(pitch)에 대한 정보 중 적어도 하나를 포함하는 전자 장치."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서, 공개특허 10-2019-0075356-3-상기 적어도 하나의 객체의 위치에 대한 정보는, 상기 적어도 하나의 객체의 상기 지정된 영역 상의 x축의 값및 y축의 값을 포함하고, 및상기 적어도 하나의 객체의 자세에 대한 정보는, 상기 적어도 하나의 객체의 요에 대한 정보를 포함하는 전자장치."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에서, 상기 프로세서는, 상기 식별된 상기 적어도 하나의 객체의 위치에 대한 정보에 기반하여, 상기 위치에 대한 정보를 나타내는 위치맵(location map)을 생성하고, 및상기 식별된 상기 적어도 하나의 객체의 자세에 대한 정보에 기반하여, 상기 위치에 대한 정보를 나타내는 자세맵(position map)을 생성하기 위해 상기 명령어들을 실행하도록 더 설정되는 전자 장치."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에서, 상기 프로세서는, 인공 지능 알고리즘에 기반하여, 상기 위치맵 및 상기 자세맵을 생성하도록 설정되는 전자 장치."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에서, 상기 프로세서는, 상기 생성된 위치맵 및 상기 생성된 자세맵에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를상기 전자 장치와 관련된 상기 피킹툴에게 송신하기 위해 상기 명령어들을 실행하도록 더 설정되는 전자 장치."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에서, 상기 프로세서는, 상기 인공 지능 알고리즘에 기반하여 상기 지정된 영역에 대한 데이터, 상기 적어도 하나의 객체의 위치에 대한정보, 및 상기 자세에 대한 정보를 처리(process)하고,상기 처리에 기반하여 상기 트레이닝 데이터 베이스를 갱신하기 위해 상기 명령어들을 실행하도록 더 설정되는전자 장치."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 1에서, 상기 트레이닝 데이터 베이스는 상기 적어도 하나의 객체의 위치에 대한 정보, 상기 적어도 하나의 객체의 자세에 대한 정보, 및 상기 적어도 하나의 객체에 대한 영상 정보를 포함하고, 및상기 영상 정보는 상기 적어도 하나의 객체를 나타내는 가상 데이터 및 상기 인공 지능 알고리즘에 기반하여 생성된 정보를 포함하는 전자 장치."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2019-0075356-4-전자 장치(electronic device)의 방법에 있어서,적어도 하나의 센서를 이용하여 적어도 하나의 객체(object)를 포함하는 지정된 영역(designated area)에 대한데이터를 획득하는 동작,인공 지능 알고리즘에 기반하여 획득된 적어도 하나의 객체에 대한 데이터를 포함하는 트레이닝 데이터 베이스(data base)에 기반하여, 상기 적어도 하나의 객체의 위치(location)에 대한 정보 및 자세에 대한 정보를 식별하는 동작, 및상기 식별된 위치에 대한 정보 및 상기 자세에 대한 정보에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를 상기 전자 장치와 관련된 피킹툴에게 송신하는 동작을 포함하는 방법."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서, 상기 적어도 하나의 센서는, 상기 적어도 하나의 객체가 상기 지정된 영역 내에 포함되는 지 여부, 상기 적어도 하나의 객체의 모양(shape),상기 적어도 하나의 객체의 위치, 상기 적어도 하나의 객체의 자세(position) 중 적어도 하나를 측정하기 위한센서를 포함하는 방법."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 11에 있어서,상기 지정된 영역에 대한 데이터는 상기 지정된 영역과 관련된 이미지(image)를 나타내는 정보를 포함하는방법."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 11에 있어서, 상기 적어도 하나의 객체의 위치에 대한 정보는, 상기 적어도 하나의 객체의 상기 지정된 영역 상의 x축의 값,y축의 값 또는 z축의 값 중 적어도 하나를 포함하고, 및상기 적어도 하나의 객체의 자세에 대한 정보는, 상기 적어도 하나의 객체에 대한 요(yaw)에 대한 정보, 롤(roll)에 대한 정보, 또는 피치(pitch)에 대한 정보 중 적어도 하나를 포함하는 방법."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 11에 있어서, 상기 적어도 하나의 객체의 위치에 대한 정보는, 상기 적어도 하나의 객체의 상기 지정된 영역 상의 x축의 값및 y축의 값을 포함하고, 및상기 적어도 하나의 객체의 자세에 대한 정보는, 상기 적어도 하나의 객체의 요에 대한 정보를 포함하는 방법."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 11에서, 상기 식별된 상기 적어도 하나의 객체의 위치에 대한 정보에 기반하여, 상기 위치에 대한 정보를 나타내는 위치맵(location map)을 생성하는 동작과, 및상기 식별된 상기 적어도 하나의 객체의 자세에 대한 정보에 기반하여, 상기 위치에 대한 정보를 나타내는 자세공개특허 10-2019-0075356-5-맵(position map)을 생성하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 16에서, 인공 지능 알고리즘에 기반하여, 상기 위치맵 및 상기 자세맵을 생성하는 동작과, 및 상기 생성된 위치맵 및 상기 생성된 자세맵에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를상기 전자 장치와 관련된 상기 피킹툴에게 송신하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 11에서, 상기 인공 지능 알고리즘에 기반하여 상기 지정된 영역에 대한 데이터, 상기 적어도 하나의 객체의 위치에 대한정보, 및 상기 자세에 대한 정보를 처리(process)하는 동작과,상기 처리에 기반하여 상기 트레이닝 데이터 베이스를 갱신하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 11에서, 상기 트레이닝 데이터 베이스는 상기 적어도 하나의 객체의 위치에 대한 정보, 상기 적어도 하나의 객체의 자세에 대한 정보, 및 상기 적어도 하나의 객체에 대한 영상 정보를 포함하고, 및상기 영상 정보는 상기 적어도 하나의 객체를 나타내는 가상 데이터 및 상기 인공 지능 알고리즘에 기반하여 생성된 정보를 포함하는 방법."}
{"patent_id": "10-2017-0176878", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "비-일시적(non-transitory) 컴퓨터-판독 가능(computer-readable) 저장(storage) 매체(medium)에 있어서, 적어도 하나의 센서를 이용하여 적어도 하나의 객체를 포함하는 지정된 영역에 대한 데이터를 획득하는 동작과, 인공 지능 알고리즘에 기반하여 획득된 적어도 하나의 객체에 대한 데이터를 포함하는 트레이닝 데이터 베이스에 기반하여, 상기 적어도 하나의 객체의 위치에 대한 정보 및 자세에 대한 정보를 식별하는 동작과, 및 상기 식별된 위치에 대한 정보 및 상기 자세에 대한 정보에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를 전자 장치와 관련된 피킹툴에게 송신하는 동작을 실행하기 위한 하나 이상의 프로그램들을 저장하기 위한 비-일시적 컴퓨터-판독 가능 저장 매체."}
{"patent_id": "10-2017-0176878", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 다양한 실시 예들은, 전자 장치(electronic device)에서, 인공 지능 알고리즘에 기반하여 획득된 적어 도 하나의 객체에 대한 데이터를 포함하는 트레이닝 데이터 베이스(data base)와 명령어들을 포함하는 메모리; 적어도 하나의 센서; 및 상기 적어도 하나의 센서 및 상기 메모리와 연결된 프로세서를 포함하고, 상기 프로세서 는, 상기 적어도 하나의 센서를 이용하여 적어도 하나의 객체를 포함하는 지정된 영역(designated area)에 대한 데이터를 획득하고, 상기 트레이닝 데이터 베이스에 기반하여, 상기 적어도 하나의 객체(object)의 위치 (location)에 대한 정보 및 자세에 대한 정보를 식별하고, 및 상기 식별된 위치에 대한 정보 및 상기 자세에 대 한 정보에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를 상기 전자 장치와 관련된 피킹툴에 게 송신하기 위해 상기 명령어들을 실행하도록 설정될 수 있다."}
{"patent_id": "10-2017-0176878", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "다양한 실시 예들은, 지정된 객체(a designated object)에 대한 정보를 획득하고, 획득된 정보를 트레이닝하는 것에 기반하여 객체를 식별하기 위한 방법 및 전자 장치(electronic device)에 관한 것이다."}
{"patent_id": "10-2017-0176878", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 장치(electronic device)에 대한 기술이 발달됨에 따라, 전자 장치는 사용자를 대신하여 다양한 동작들을 수행함으로써 사용자에게 편리함을 제공할 수 있다. 예를 들면, 전자 장치는 공장에서 사용자를 대신하여 객체 를 피킹한 후, 피킹된 객체를 특정 위치로 옮길 수 있다. 이러한 동작은 빈피킹(bin-picking)으로 지칭될 수 있 다. 빈피킹 동작의 수행 과정에서, 전자 장치는 피킹을 위한 객체를 식별할 수 있다. 전자 장치는 객체의 특징 점을 추출하는 방식으로 객체를 식별할 수 있다."}
{"patent_id": "10-2017-0176878", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전자 장치(electronic device)는 특징점을 추출하는 방식에 기반하여 객체를 식별할 수 있다. 전자 장치의 특징 점을 추출하는 방식은 물체에 따라 특징 추출의 방식을 달리하여야 하며, 외부 환경의 변화에 민감하다는 문제 점이 있다. 다양한 실시 예들은, 인공 지능(artificial intelligence, AI) 알고리즘(algorithm) 및/또는 시뮬레이션 (simulcation)에 기반한 트레이닝 데이터를 이용하여 객체(object)를 식별하기 위한 전자 장치 및 방법을 제공 할 수 있다. 본 문서에서 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2017-0176878", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2017-0176878", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "다양한 실시 예들에 따른 전자 장치(electronic device)는, 인공 지능 알고리즘(artificial intelligence algorithm)에 기반하여 획득된 적어도 하나의 객체(object)에 대한 데이터를 포함하는 트레이닝 데이터 베이스 (data base)와 명령어들(instructions)을 포함하는 메모리, 적어도 하나의 센서, 및 상기 적어도 하나의 센서 및 상기 메모리와 연결된 프로세서를 포함할 수 있다. 상기 프로세서는, 상기 적어도 하나의 센서를 이용하여 적어도 하나의 객체를 포함하는 지정된 영역에 대한 데이터를 획득하고, 상기 트레이닝 데이터 베이스에 기반하 여, 상기 적어도 하나의 객체의 위치에 대한 정보 및 자세에 대한 정보를 식별하고, 및 상기 식별된 위치에 대 한 정보 및 상기 자세에 대한 정보에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를 상기 전 자 장치와 관련된 피킹툴에게 송신하기 위해 상기 명령어들을 실행하도록 설정될 수 있다. 다양한 실시 예들에 따른 전자 장치의 방법은, 적어도 하나의 센서를 이용하여 적어도 하나의 객체를 포함하는 지정된 영역에 대한 데이터를 획득하는 동작, 인공 지능 알고리즘에 기반하여 획득된 적어도 하나의 객체에 대 한 데이터를 포함하는 트레이닝 데이터 베이스에 기반하여, 상기 적어도 하나의 객체의 위치에 대한 정보 및 자 세에 대한 정보를 식별하는 동작, 및 상기 식별된 위치에 대한 정보 및 상기 자세에 대한 정보에 기반하여, 상 기 적어도 하나의 객체를 피킹하기 위한 제어 신호를 상기 전자 장치와 관련된 피킹툴에게 송신하는 동작을 포 함할 수 있다. 다양한 실시 예들에 따른 비-일시적(non-transitory) 컴퓨터-판독 가능(computer-readable) 저장(storage) 매 체(medium)는, 적어도 하나의 센서를 이용하여 적어도 하나의 객체를 포함하는 지정된 영역에 대한 데이터를 획 득하는 동작과, 인공 지능 알고리즘에 기반하여 획득된 적어도 하나의 객체에 대한 데이터를 포함하는 트레이닝 데이터 베이스에 기반하여, 상기 적어도 하나의 객체의 위치에 대한 정보 및 자세에 대한 정보를 식별하는 동작 과, 및 상기 식별된 위치에 대한 정보 및 상기 자세에 대한 정보에 기반하여, 상기 적어도 하나의 객체를 피킹 하기 위한 제어 신호를 전자 장치와 관련된 피킹툴에게 송신하는 동작을 실행하기 위한 하나 이상의 프로그램들 을 저장할 수 있다."}
{"patent_id": "10-2017-0176878", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "다양한 실시 예들에 따른 전자 장치(electronic device) 및 그의 동작 방법은, 인공 지능 알고리즘 및 트레이닝 데이터를 이용함으로써 다양한 물체에 범용적으로 사용 가능하다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2017-0176878", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서 사용되는 용어들은 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다른 실시 예의 범위를 한정하려는 의도가 아닐 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함 할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 개시에 기재된 기술 분야에 서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시에 사용된 용어들 중 일반적인 사전에 정의된 용어들은, 관련 기술의 문맥상 가지는 의미와 동일 또는 유사한 의미로 해석 될 수 있으며, 본 개시에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는 다. 경우에 따라서, 본 개시에서 정의된 용어일지라도 본 개시의 실시 예들을 배제하도록 해석될 수 없다. 이하에서 설명되는 본 개시의 다양한 실시 예들에서는 하드웨어적인 접근 방법을 예시로서 설명한다. 하지만, 본 개시의 다양한 실시 예들에서는 하드웨어와 소프트웨어를 모두 사용하는 기술을 포함하고 있으므로, 본 개시 의 다양한 실시 예들이 소프트웨어 기반의 접근 방법을 제외하는 것은 아니다. 도 1은, 다양한 실시 예들에 따른, 전자 장치(electronic device)를 포함하는 환경의 예를 도시한다. 다양한 실 시 예들에서, 도 1은 전자 장치를 이용하여 객체(또는 물체)를 피킹하기 위한 시스템(예: 빈피킹(bin picking) 시스템)을 나타낼 수 있다. 빈피킹 시스템은 지정된 영역(예: 상자(bin 또는 box)) 안에 위치된 객체를 파지하여 지정된 영역 밖으로 옮기는 시스템을 지칭할 수 있다. 도 1을 참조하면, 전자 장치는 다양한 구성 요소를 이용하여 객체를 피킹(picking)(또는 파지)하고 옮길 수 있다. 다양한 실시 예들에서, 전자 장치는 객체를 피킹하기 위해 지정된 영역 내에 위치된(또는 포함된) 객체를 식별할 수 있다. 예를 들면, 전자 장치는 센서를 이용하여 지정된 영역 내에 객 체가 존재하는 지 여부, 객체의 위치에 대한 정보 또는 객체의 자세에 대한 정보 중 적어도 하나를 식별할 수 있다. 전자 장치는 피킹툴을 이용하여 식별된 객체를 피킹하고, 회전 모듈(또는 로봇 팔)의 움 직임을 제어함으로써 피킹된 객체를 특정 위치로 옮길 수 있다. 다양한 실시 예들에서, 센서는 객체에 대한 정보를 획득하기 위한 다양한 센서를 포함할 수 있다. 예를 들 면, 센서는 이미지(image)(또는 영상(video), 또는 멀티미디어(multimedia) 데이터)를 획득할 수 있는 카메라(또는 광학 카메라, 또는 이미지 센서(image sensor))를 포함할 수 있다. 다른 예를 들면, 센서는 객 체와 관련된 거리 정보 또는 객체와 관련된 깊이 정보를 획득하기 위한 깊이 카메라(depth camera)를 포함할 수 있다. 또 다른 예를 들면, 센서는 초음파 카메라(또는 초음파 센서) 또는 적외선 카메라(infrared camera)(또는 적외선 센서)를 포함할 수 있다. 다양한 실시 예들에서, 센서는 단수 또는 복수의 센서를 포함할 수 있다. 예를 들면, 센서는 이미지 센서, 광 센서, 조도 센서, 또는 컬러 센서 중 적어도 하나를 포함할 수 있다. 센서는 지정된 영역에 대한 정보를 획득하기 위한 다양한 종류의 센서를 포함할 수 있으며, 상술한 예에 한정되지 않는다. 다양한 실시 예들에서, 센서는 지정된 영역에 대한 정보를 획득할 수 있는 다양한 위치에 위치될 수 있다. 일실시예에 따르면, 센서는 전자 장치 또는 지정된 영역의 근처에 위치된 프레임에 위치될 수 있다. 프레임은 지상에서 고정된 상태로 위치될 수 있으며, 센서는 프레임의 상단 부분에 위치될 수 있다. 예를 들면, 센서는 지정된 영역의 상단를 향하여 돌출된 프레임의 끝 부분(또 는 말단 부분)에 위치될 수 있다. 상기 센서는 상기 프레임의 끝 부분에서 지정된 영역을 내려 다보는 방향으로 위치될 수 있다. 센서는 지정된 영역을 내려다보는 방향으로 위치됨에 기반하여, 지 정된 영역 또는 지정된 영역 내에 포함된 객체에 대한 정보를 획득(obtain, 또는 acquire)할 수 있다. 예를 들면, 센서는 지정된 영역과 관련된 위치에서, 지정된 영역을 나타내는 이미지(또는 영상)에 대한 정보를 획득할 수 있다. 지정된 영역을 나타내는 이미지에 대한 정보는 지정된 영역에 포함된 적어도 하나의 객체에 대한 이미지(또는 영상)에 대한 정보를 포함할 수 있다. 다양한 실시 예들에서, 전자 장치는 네트워크(예: 유선 통신 또는 무선 통신)를 이용하여 센서와 연 결될 수 있다. 전자 장치는 상기 연결에 기반하여 센서를 통해 획득된 정보를 식별할 수 있다. 전자 장치는 센서를 통해 지정된 영역에 대한 정보를 획득하는 것에 기반하여, 지정된 영역에 포함된 적어도 하나의 객체의 수, 적어도 하나의 객체의 각각의 위치, 적어도 하나의 객체의 형태, 적어도 하나의 객체 의 자세(position) 중 적어도 하나를 식별할 수 있다. 식별과 관련된 동작은 후술될 것이다. 도시하지는 않았으나, 다양한 실시 예들에서, 전자 장치는 센서를 포함할 수 있다. 이러한 경우, 센 서는 지정된 영역에 대한 정보를 획득하기 위해 지정된 영역과 인접하게 위치될 수 있다. 예를 들면, 센서는 지정된 영역의 상단에 위치될 수 있는 전자 장치의 회전 모듈의 끝부분에 위 치될 수 있다. 회전 모듈의 끝부분은 파지툴이 이동 가능하게 연결된 부분일 수 있다. 센서는 회전 모듈의 끝부분에 위치됨으로써 지정된 영역에 대한 정보를 획득할 수 있다. 예를 들면, 센서 는 지정된 영역의 상단 부에 위치된 회전 모듈의 끝부분에 위치하여 지정된 영역에 대한 이미지를 획득할 수 있다. 다양한 실시 예들에서, 회전 모듈은 피킹툴의 이동을 위한 전자 장치의 일부를 지칭할 수 있다. 예를 들면, 회전 모듈은 로봇 팔로 지칭될 수 있다. 회전 모듈은 이동 가능한 다양한 형태를 포함할 수 있으며, 도시된 예에 한정되지 않는다. 다양한 실시 예들에서, 전자 장치는 객체를 피킹하기 위한 피킹툴을 이용하여 객체를 피킹할 수 있다. 일부 실시 예들에서, 전자 장치는 센서를 통해 획득된 정보에 기반하여 피킹툴을 제어함 으로써 객체를 피킹할 수 있다. 예를 들면, 전자 장치는 센서를 통해 획득된 정보에 기반하여 객체의 위치 또는 자세를 식별할 수 있다. 전자 장치는 식별에 기반하여, 피킹툴을 객체가 위치된 지정된 영역 에 접근시킴으로써 객체를 피킹할 수 있다. 다른 일부 실시 예들에서, 전자 장치는 객체를 식별하는 것에 기반하여 객체를 피킹하기 위한 제어 신호를 생성할 수 있다. 전자 장치는 객체의 피킹을 위한 제어 신호를 피킹툴에게 송신할 수 있다. 상기 제어 신호를 송신함으로써, 전자 장치는 객체의 피킹을 야 기(cause)할 수 있다. 다양한 실시 예들에서, 전자 장치는 피킹된 객체를 이동하기 위한 회전 모듈을 포함할 수 있다. 전자 장치는 회전 모듈의 움직임(movement)을 제어(control)하는 것에 기반하여, 피킹된 객체를 특정 위치 로 이동할 수 있다. 상기 특정 위치는 객체의 이동과 관련된 최종 목적지를 지칭할 수 있다. 예를 들면, 전자 장치는 객체를 피킹하여 컨베이어 벨트(conveyor belt) 상으로 옮길 수 있다. 다른 예를 들면, 전자 장치는 객체를 제1 상자 내에서 피킹하여 제2 상자로 옮길 수 있다. 여기서 제1 상자는 지정된 영역 에 상응할 수 있고, 제2 상자는 컨베이어 벨트에 상응할 수 있다. 객체의 이동에 대한 출발지(예: 지정된 영역, 또는 제1 상자)와 목적지(예: 컨베이어 벨트, 또는 제2 상자)는 전자 장치의 사용자에 의 해 미리 지정될 수 있으며, 상술한 예에 한정되지 않는다. 다양한 실시 예들에서, 전자 장치는 고정된 위치에서 회전 모듈의 회전을 제어함으로써 객체를 이동 할 수 있다. 전자 장치는 전자 장치의 중심축을 기준으로 회전 모듈을 일방향으로(또는 컨베이 어 벨트 방향으로) 회전하는 것에 의해 컨베이어 벨트 상에 객체를 옮길 수 있다. 예를 들면, 전자 장치는 전자 장치의 회전 모듈을 왼쪽 방향으로 회전하는 것에 의해 컨베이어 벨트 상에 객체를 옮길 수 있다. 다양한 실시 예들에서, 회전 모듈은 전자 장치의 중심축(또는 고정된 축)으로부터 돌출된 형태일 수 있다. 회전 모듈의 일부는 전자 장치의 중심축 상에 연결(또는 포함)될 수 있고, 회전 모듈의 다른 일부(또는 말단 부분)는 피킹툴과 연결(또는 피킹툴을 포함)될 수 있다. 회전 모듈은 가동 범위 내에서 객체를 이동할 수 있다. 예를 들면, 가동 범위는 회전 모듈의 길이를 반경으로 하 는 원형의 범위를 포함할 수 있다. 회전 모듈의 길이는 전자 장치의 중심 축으로부터 피킹툴이 연결된 회전 모듈의 말단 부분까지의 길이를 나타낼 수 있다. 실시 예들에 따라, 전자 장치는 회전 모듈의 길이를 조절할 수 있다. 조절에 기반하여, 전자 장치의 가동 범위는 회전 모듈의 길이에 따라 변경될 수 있다. 다양한 실시 예들에서, 회전 모듈은 객체의 이동을 위한 전자 장치의 움직임을 설명하기 위한 기능적 구성일 수 있으며, 상술된 예에 한정되지 않는다. 다양한 실시 예에 따른 전자 장치가 포함된 환경은 객체의 이동이 반복적으로 요구되는 물류 창고 또 는 물류 공장을 포함할 수 있다. 환경에서, 전자 장치는 사람을 대신하여 객체를 피킹하고, 객체를 특정 위치로 이동시킬 수 있다. 전자 장치의 사용에 기반하여, 물류 자동화 시스템의 구축이 가능할 수 있 다. 도 2는 다양한 실시 예들에 따른 전자 장치의 블록도이다. 도 2를 참조하면, 전자 장치는 프로세서, 센서, 피킹툴 또는 메모리를 포함할 수 있다. 실시 예들에 따라, 전자 장치 내에 상기 구 성 요소들 중 적어도 하나(예: 센서)가 생략되거나 다른 구성 요소가 추가될 수 있다. 예를 들면, 센서 는 전자 장치의 외부에 위치될 수 있다. 프로세서는, 예를 들면, 소프트웨어(software)를 구동하여 프로세서에 연결된, 전자 장치의 적 어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처리 및 연산을 수행할 수 있다. 프로세서는 다른 구성요소(예: 센서)로부터 수신된 명령 또는 데이터를 메모 리의 일부(예: 휘발성 메모리)에 로드하여 처리하고, 결과 데이터를 메모리의 다른 일부(예: 비휘발 성 메모리)에 저장할 수 있다. 일부 실시 예에서, 프로세서는 메인 프로세서(예: 중앙 처리 장치 또는 어 플리케이션 프로세서), 및 이와는 독립적으로 운영되고, 추가적으로 또는 대체적으로, 메인 프로세서보다 저전 력을 사용하거나, 또는 지정된 기능에 특화된 보조 프로세서(예: 그래픽 처리 장치, 이미지 시그널 프로세서, 센서 허브 프로세서, 또는 커뮤니케이션 프로세서)를 포함할 수 있다. 여기서, 보조 프로세서는 메인 프로세서 와 별개로 또는 임베디드되어 운영될 수 있다. 보조 프로세서는, 예를 들면, 메인 프로세서가 인액티브(예: 슬립) 상태에 있는 동안 메인 프로세서를 대신하 여, 또는 메인 프로세서가 액티브(예: 어플리케이션 수행) 상태에 있는 동안 메인 프로세서와 함께, 전자 장치 의 구성요소들 중 적어도 하나의 구성요소(예: 센서)와 관련된 기능 또는 상태들의 적어도 일부를 제 어할 수 있다. 일실시 예에 따르면, 보조 프로세서(예: 커뮤니케이션 프로세서)는 기능적으로 관련 있는 다른 구성 요소(예: 센서)의 일부 구성 요소로서 구현될 수 있다. 프로세서는, 객체를 식별하기 위한 트레이닝 데이터를 생성할 수 있다. 프로세서는 인공 지능 알고리 즘(artificial intelligence algorithm)(예: 제1 인공 지능 알고리즘)에 기반하여 트레이닝 데이터를 생성할 수 있다. 프로세서는 인공 지능 알고리즘에 기반하여 적어도 하나의 객체에 대한 가상 데이터 또는 실제 데이터 중 적어도 하나를 처리함으로써 트레이닝 데이터를 생성할 수 있다. 인공 지능 알고리즘은, 예를 들면, 기계 학습 알고리즘, 신경망 알고리즘, 딥러닝 알고리즘, 또는 규칙 기반 모델 중 적어도 하나를 포함할 수 있 다. 프로세서는 생성된 트레이닝 데이터를 트레이닝 데이터 베이스(training data base)(또는 학습 데이터 베이스, 또는 트레이닝 DB, 또는 학습 DB) 내에 저장할 수 있다. 프로세서는 생성된 트레이닝 데이터를 메 모리에 제공함으로써 트레이닝 데이터 베이스 내에 저장할 수 있다. 다양한 실시 예들에서서 프로세서는 인공 지능 알고리즘과 관련된 외부 장치(예: 서버(server))에 적어도 하나의 객체에 대한 가상 데이터 또는 실제 데이터를 제공할 수 있다. 트레이닝 데이터는 서버에 의해 생성될수 있다. 프로세서는 서버에 의해 생성된 트레이닝 데이터를 서버로부터 수신할 수 있다. 다양한 실시 예들에서, 적어도 하나의 객체에 대한 가상 데이터는, 객체의 형태, 크기, 또는 모양과 관련된 데 이터를 포함할 수 있다. 예를 들면, 상기 가상 데이터는 2차원의 이미지에 광원, 위치, 색상, 형태, 모양 중 적 어도 하나에 기반하여 생성된 삼차원(3D, 3-dimensions)의 데이터(또는 렌더링(rendering) 데이터)를 포함할 수 있다. 가상 데이터와 관련된 구체적인 설명은 도 8 또는 도 9를 통해 후술될 것이다. 다른 예를 들면, 가상 데 이터는 하나의 객체를 나타내기 위한 세부적인 데이터를 포함할 수 있다. 객체와 관련된 실제 데이터는, 다양한 센서를 통해 객체를 센싱함으로써 획득된 객체에 대한 실제 정보를 포함할 수 있다. 예를 들면, 실제 데이터는, 전자 장치에 포함된 센서를 통해 획득된(또는 인식된) 객체에 대한 데이터(예: 영상 데이터, 이미지 데이터)를 포함할 수 있다. 다른 예를 들면, 실제 데이터는 외부 장치(또는 다른 장치)로부터 수신되고, 외부 장치에 의해 획득된 객체에 대한 데이터(예: 영상 데이터, 이미지 데이터)를 포함할 수 있다. 프로세서는 물리 시뮬레이터(또는 물리 엔진)에 기반하여 가상 데이터를 처리할 수 있다. 물리 시뮬레이터 는, 물리 시스템을 시뮬레이션 하기 위한 전자 장치의 구성 요소일 수 있다. 물리 시스템은, 예를 들면, 강체동역학, 유동역학, 동역학, 또는 정역학과 관련된 시스템을 포함할 수 있다. 프로세서는 물리 시뮬레 이터에 기반하여 가상 데이터를 시뮬레이션(이하 물리 시뮬레이션)할 수 있다. 프로세서는 물리 시뮬레이 터에 기반하여 다양한 물리적 수치를 이용함으로써 가상 데이터를 처리할 수 있다. 프로세서는 물리 시뮬 레이션에 기반하여 객체에 대한 센서 데이터를 획득할 수 있다. 센서 데이터와 관련된 구체적인 설명은 도 8 또 는 도 9를 통해 후술될 것이다. 프로세서는 영상 시뮬레이터(또는 영상 엔진, 또는 영상 기반 시뮬레이터)에 기반하여 객체와 관련된 데이 터를 처리할 수 있다. 프로세서는 영상 시뮬레이터에 기반하여 물리 시뮬레이터를 통해 획득된 센서 데이 터를 처리할 수 있다. 프로세서는 영상 시뮬레이터에 기반하여 센서 데이터를 영상 시뮬레이션할 수 있다. 영상 시뮬레이터는 인공 지능 알고리즘(예: 제1 인공 지능 알고리즘)과 관련될 수 있으며, 프로세서는 인 공 지능 알고리즘에 기반하여 영상 시뮬레이션을 수행할 수 있다. 다양한 실시 예들에서, 제1 인공 지능 알고리즘은 GMM(gaussian mixture model), AE(autoencoder), 또는 GAN(generative adversarial network)를 포함할 수 있다. 제1 인공 지능 알고리즘이 GAN을 포함하는 경우, 객 체와 관련된 가상 데이터를 생성하는 생성 모듈 및 객체와 관련된 실제 데이터와 가상 데이터를 구별(또는 구분, 또는 식별)하기 위한 판별 모듈을 포함할 수 있다. 생성 모듈은, 가상 데이터를 생성함에 있어서, 실제 데이터와 구별되지 않도록, 즉, 가장 유사한 형태로 가상 데이터를 생성하도록 트레이닝할 수 있다. 판별 모듈 은, 생성 모듈을 통해 생성된 가상 데이터와 입력된 실제 데이터의 차이점을 구별하도록 트레이닝할 수 있다. 생성 모듈과 판별 모듈을 통한 트레이닝에 기반하여, 프로세서는 제1 인공 지능 알고리즘에 대한 트레이닝 데이터를 생성할 수 있다. 실시 예들에 따라, 프로세서는 미리 저장된 실제 데이터 또는 가상 데이터와 관 련된 데이터를 이용하여 제1 인공 지능 알고리즘에 기반한 트레이닝을 수행할 수 있다. 프로세서는 트레이 닝에 기반하여 트레이닝 데이터를 생성할 수 있다. 트레이닝 데이터와 관련된 구체적인 설명은 도 8 또는 도 9 를 통해 후술될 것이다. 다양한 실시 예들에서, 물리 시뮬레이터 또는 영상 시뮬레이터는 하드웨어, 소프트웨어 또는 펌웨어로 구성될 수 있다. 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 물리 시 뮬레이터 또는 영상 시뮬레이터는, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수 있다 다른 일부 실시 예들에서, 트레이닝 데이터 베이스는 인공 지능 알고리즘에 기반하여 지속적으로 갱신되는 데이 터를 포함할 수 있다. 프로세서는 제1 인공 지능 알고리즘에 기반하여 센서를 통해 획득된 정보 또는 사용자의 입력을 식별함으로써, 트레이닝 데이터를 갱신(update)할 수 있다. 트레이닝 데이터의 갱신에 대응하 여, 프로세서는 트레이닝 데이터 베이스를 갱신할 수 있다. 프로세서는, 센서를 이용하여 지정된 영역에 대한 정보를 획득할 수 있다. 지정된 영역은 적어도 하나의 객체를 포함할 수 있다. 상기 획득된 정보는 지정된 영역에 대한 이미지 정보 또는 영상 정 보를 포함할 수 있다. 프로세서는 트레이닝 데이터 베이스(training data base)(또는 학습 데이터 베이 스)에 기반하여, 상기 획득된 정보를 식별할 수 있다. 상기 트레이닝 데이터 베이스는 제1 인공 지능 알고리즘 에 기반하여 생성된 트레이닝 데이터를 포함할 수 있다. 다양한 실시 예들에서, 프로세서는 제2 인공 지능 알고리즘에 기반하여 센서를 통해 획득된 정보를 식별할 수 있다. 프로세서는 제2 인공 지능 알고리즘에 기반하여 제1 인공 지능 알고리즘과 관련된 트레이 닝(또는 학습) 데이터를 이용함으로써 센서를 통해 획득된 정보를 식별할 수 있다. 다양한 실시 예들에서, 제2 인공 지능 알고리즘은 신경망 네트워크를 포함할 수 있다. 상기 제2 인공 지능 알고 리즘은, 예를 들면, 완전연결레이어(fully connected layer)를 포함하지 않는 완전콘볼루션네트워크(fully convolutional network)를 포함할 수 있다. 이러한 경우, 제2 인공 지능 알고리즘에 기반하여 프로세서는 입력 영상의 해상도에 상응하는 해상도의 영상(예: 흑백 영상 또는 컬러 영상)을 획득할 수 있다. 프로세서 는, 제2 인공 지능 알고리즘에 기반하여, 입력 값을 고속으로 또는 병렬적으로 처리할 수 있다. 프로세서 는, 제2 인공 지능 알고리즘에 기반한 트레이닝에 대해 가변적인 크기를 가지는 영상을 이용할 수 있다. 일부 실시 예들에서, 트레이닝 데이터의 획득과 관련된 제1 인공 지능 알고리즘과 센서를 통해 획득된 정보의 식별과 관련된 제2 인공 지능 알고리즘은 상이할 수(또는 다를 수(different), 또는 구별될 수(distinct)) 있다. 다른 일부 실시 예들에서, 트레이닝 데이터의 획득과 관련된 제1 인공 지능 알고리즘은, 센서를 통해 획 득된 정보의 식별과 관련된 제2 인공 지능 알고리즘과 대응(또는 동일, 또는 상응)할 수 있다. 프로세서는, 획득된 정보를 식별함으로써 적어도 하나의 객체를 식별할 수 있다. 예를 들면, 프로세서 는 획득된 정보를 식별함으로써 적어도 하나의 객체의 6자유도(예: x축 좌표 값, y축 좌표 값, z축 좌표 값, 요(yaw), 롤(roll), 및/또는 피치(pitch)) 중 적어도 하나에 대한 정보를 획득할 수 있다. 다른 예를 들면, 프로세서는 획득된 정보를 식별함으로써 객체가 놓인 방향을 3차원의 공간에 대해 나타내기 위한 오일러 각(euler angles)에 대한 값을 획득할 수 있다. 또 다른 예를 들면, 프로세서는 획득된 정보를 식별함으로 써 객체의 회전을 나타내기 위한 사원수(또는 쿼터니언(quaternion))에 대한 값을 획득할 수 있다. 또 다른 예 를 들면, 프로세서는 획득된 정보를 식별함으로써 적어도 하나의 객체의 위치에 대한 정보 및/또는 적어도 하나의 객체의 자세에 대한 정보를 획득할 수 있다. 일부 실시 예들에서, 적어도 하나의 객체의 위치에 대한 정보는 지정된 영역 내에서 적어도 하나의 객체가 존재하는 지 여부에 대한 정보 및/또는 적어도 하나의 객체의 지정된 영역 상에서의 위치를 나타내는 정보 를 포함할 수 있다. 예를 들면, 적어도 하나의 객체의 위치에 대한 정보는 지정된 영역에 대한 x축, y축, 또는 z축 중 적어도 하나에 대한 좌표값에 대한 정보를 포함할 수 있다. 다른 일부 실시 예들에서, 적어도 하나의 객체의 자세(예: 3자유도)에 대한 정보는 지정된 영역 내에서 적 어도 하나의 객체가 위치된 형태를 포함할 수 있다. 예를 들면, 상기 자세에 대한 정보는, 적어도 하나의 객체 의 회전, 각도, 또는 기울기에 대한 정보를 포함할 수 있다. 다른 예를 들면, 상기 자세에 대한 정보는, 적어도 하나의 객체에 대한 요(yaw), 롤(roll), 또는 피치(pitch) 중 적어도 하나에 대한 정보를 포함할 수 있다. 실시 예들에서, 피킹툴의 이동 방향이 x축 방향인 경우에 대응하여, 요의 회전축은 z축(또는 중력 방향의 축), 피치의 회전축은 y축, 롤의 회전 축은 x축일 수 있다. 다양한 실시 예들에서, 프로세서는 객체를 식별하는 것에 기반하여, 객체의 피킹을 위한 동작을 수행할 수 있다. 예를 들면, 프로세서는 객체를 피킹하기 위한 제어 신호를 생성할 수 있다. 프로세서는 생성된 제어 신호를 피킹툴에게 송신할 수 있다. 송신에 기반하여 피킹툴의 움직임이 야기될 수 있으며, 지 정된 영역 내에 위치된 적어도 하나의 객체가 피킹툴에 의해 피킹될 수 있다. 센서는, 객체에 대한 정보를 획득하기 위한 다양한 센서를 포함할 수 있다. 예를 들면, 센서는 이미 지를 획득할 수 있는 카메라 센서(또는 이미지 센서(image sensor))를 포함할 수 있다. 다른 예를 들면, 센서 는 객체와 관련된 거리 정보 또는 깊이 정보, 또는 3차원의 정보를 획득하기 위한 깊이 카메라를 포함할 수 있다. 센서는 객체에 대한 정보를 획득하기 위해 전자 장치의 일부에 위치될 수 있다. 예를 들면, 센서 는 피킹툴의 상단부에 위치될 수 있다. 다른 예를 들면, 센서는 회전 모듈의 일부에 위치될 수 있다. 도시하지는 않았으나, 센서는 전자 장치와 별도의 구성일 수 있다. 예를 들면, 센서는 외 부 장치에 포함될 수 있다. 센서는 객체에 대한 정보를 획득하기 위한 다양한 위치에 위치될 수 있으며, 상술한 예에 한정되지 않는다. 다양한 실시 예들에서, 센서가 전자 장치의 외부에 위치된 경우, 프로세서는 센서와 무선 또는 유선으로 연결될 수 있다. 도시하지는 않았으나, 프로세서는 통신 인터페이스(communication interface)를 포함할 수 있고, 프로세서는 통신 인터페이스를 통해 센서로부터 정보를 수신할 수 있 다. 프로세서는 센서로부터 수신된 정보(예: 이미지 정보, 또는 영상 정보)에 기반하여 적어도 하나 의 객체가 포함된 지정된 영역을 식별할 수 있다. 다양한 실시 예들에 따른 통신 인터페이스는, 외부 장치(예: 다른 장치)와 유선 또는 무선으로 연결할 수 있는 지정된 프로토콜을 지원할 수 있다. 일실시예에 따르면, 통신 인터페이스는 HDMI(high definition multimedia interface), USB(universal serial bus) 인터페이스, SD카드(secure digital card) 인터페이스, 또 는 오디오(audio) 인터페이스를 포함할 수 있다. 통신 인터페이스는 전자 장치와 외부 전자 장치(예: 센서 )를 물리적으로 연결시킬 수 있는 연결 단자(또는 커넥터)를 포함할 수 있다. 연결 단자는, 예를 들면, HDMI 커넥터(connector), USB 커넥터, SD 카드 커넥터, 또는 오디오 커넥터(예: 헤드폰 커넥터)를 포함할 수 있 다. 통신 인터페이스는, 전자 장치와 외부 장치(예: 서버)간의 유선 또는 무선 통신 채널의 수립, 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 통신 인터페이스는 프로세서(예: 어플리케이션 프로세서) 와 독립적으로 운영되는, 유선 통신 또는 무선 통신을 지원하는 하나 이상의 커뮤니케이션 프로세서를 포함할 수 있다. 일실시 예에 따르면, 통신 인터페이스는 무선 통신 모듈(예: 셀룰러 통신 모듈, 근거리 무선 통신 모 듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예: LAN(local area network) 통신 모듈, 또는 전력선 통신 모듈)을 포함하고, 그 중 해당하는 통신 모듈을 이용하여 제 1 네트워크 (예: 블루투스, WiFi direct 또는 IrDA(infrared data association) 같은 근거리 통신 네트워크) 또는 제 2 네 트워크(예: 셀룰러 네트워크, 인터넷, 또는 컴퓨터 네트워크(예: LAN 또는 WAN)와 같은 원거리 통신 네트워크) 를 통하여 외부 전자 장치와 통신할 수 있다. 상술한 여러 종류의 통신 인터페이스는 하나의 칩으로 구현되거나 또는 각각 별도의 칩으로 구현될 수 있다. 일실시 예에 따르면, 무선 통신 모듈은 가입자 식별 모듈에 저장된 사용자 정보를 이용하여 통신 네트워크 내에서 전자 장치를 구별 및 인증할 수 있다. 통신 인터페이스는 안테나 모듈을 포함할 수 있다. 안테나 모듈은 신호 또는 전력을 외부로 송신하거나 외부로 부터 수신하기 위한 하나 이상의 안테나들을 포함할 수 있다. 일시예에 따르면, 통신 인터페이스(예: 무선 통신 모듈)는 통신 방식에 적합한 안테나를 통하여 신호를 외부 전자 장치로 송신하거나, 외부 전자 장치로부터 수신 할 수 있다. 전자 장치의 구성요소들 중 일부 구성요소들은 주변 기기들간 통신 방식(예: 버스, GPIO(general purpose input/output), SPI(serial peripheral interface), 또는 MIPI(mobile industry processor interface))를 통 해 서로 연결되어 신호(예: 명령 또는 데이터)를 상호간에 교환할 수 있다. 일실시 예에 따르면, 명령 또는 데 이터는 제 2 네트워크에 연결된 서버를 통해서 전자 장치와 다른 장치간에 송신 또는 수신될 수 있다. 다 른 장치는 전자 장치와 동일한 또는 다른 종류의 장치일 수 있다. 일실시 예에 따르면, 전자 장치에 서 실행되는 동작들의 전부 또는 일부는 다른 하나 또는 복수의 외부 전자 장치에서 실행될 수 있다. 일실시 예 에 따르면, 전자 장치가 어떤 기능이나 서비스를 자동으로 또는 요청에 의하여 수행해야 할 경우에, 전자 장치는 기능 또는 서비스를 자체적으로 실행시키는 대신에 또는 추가적으로, 그와 연관된 적어도 일부 기 능을 외부 전자 장치에게 요청할 수 있다. 상기 요청을 수신한 외부 전자 장치는 요청된 기능 또는 추가 기능을 실행하고, 그 결과를 전자 장치로 전달할 수 있다. 전자 장치는 수신된 결과를 그대로 또는 추가적으 로 처리하여 요청된 기능이나 서비스를 제공할 수 있다. 이를 위하여, 예를 들면, 클라우드 컴퓨팅, 분산 컴퓨 팅, 또는 클라이언트-서버 컴퓨팅 기술이 이용될 수 있다. 메모리는, 전자 장치의 적어도 하나의 구성요소(예: 프로세서)에 의해 사용되는 다양한 데이터, 예를 들어, 소프트웨어 및, 이와 관련된 명령에 대한 입력 데이터 또는 출력 데이터를 저장할 수 있다. 다른 예 를 들면, 메모리는 프로세서에 의해 생성된 트레이닝 데이터(또는 트레이닝 데이터 베이스)를 저장할 수 있다. 메모리는, 휘발성 메모리 또는 비휘발성 메모리를 포함할 수 있다. 다양한 실시 예들에서, 메모리는 객체와 관련된 트레이닝 데이터 베이스를 포함할 수 있다. 트레이닝 데이 터 베이스는, 센서에 의해 획득된 객체에 대한 실제 데이터, 다른 전자 장치로부터 획득된 객체에 대한 실제 데 이터, 객체에 대한 가상 데이터, 객체에 대한 3D 모델링 데이터, 객체에 대한 물리 시뮬레이션 데이터, 객체에 대한 영상 시뮬레이션 데이터, 객체에 대한 영상(예: 흑백 영상 또는 컬러 영상) 데이터, 또는 객체의 위치에 대한 정보, 객체의 자세에 대한 정보 중 적어도 하나를 포함할 수 있다. 피킹툴은, 객체를 파지하기 위한 그리퍼(gripper), 공압형 흡착기, 전자석, 액추에이터(actuator), 가변연 결장치(floating joint) 또는 충격 완화 장치 중 적어도 하나를 포함할 수 있다. 다양한 실시 예들에서, 피킹툴 은 도1의 회전 모듈의 끝단에 부착가능하게 위치될 수 있다. 피킹툴은 회전 모듈의 움직임 에 의해 좌측 또는 우측 방향으로 이동될 수 있다. 피킹툴은 회전 모듈과 연결된 부분을 기준으로 상 측 또는 하측 방향으로 이동될 수 있다. 실시 예들에 따라, 피킹툴에 포함된 전자석의 하단에는 환봉형의홈이 존재할 수 있다. 피킹툴은 전류가 흐르는 것에 기반하여, 전자석을 이용하여 객체를 파지할 수 있다. 다양한 실시 예들에서, 피킹툴은 프로세서으로부터 제어 신호를 수신할 수 있다. 상기 제어 신호는 프로세서에 의해 생성된 신호를 포함할 수 있다. 상기 제어 신호는 객체의 피킹을 위한 신호를 포함할 수 있다. 객체의 피킹을 위한 신호는, 예를 들면, 지정된 영역 내에서의 객체의 위치에 대한 정보 또는 객체 의 자세에 대한 정보를 나타내기 위한 신호를 포함할 수 있다. 상기 제어 신호에 기반하여, 피킹툴은 객체 를 피킹하기 위한 이동(movement)을 수행할 수 있다. 다양한 실시 예들에서, 전자 장치는 고성능의 삼차원 센서에 비해 상대적으로 저가의 센서를 이용하여 객 체에 대한 데이터를 획득할 수 있다. 고성능의 삼차원 센서는, 예를 들면, 구조화 빛 삼차원 센서(structured light 3D sensor), 삼차원 레이저 스캐닝 센서(3D laser scanning sensor), 또는 비행시간 깊이 카메라(time of flight depth camera)를 포함할 수 있다. 저가의 센서는, 예를 들면, 이미지 센서, 키넥트(kinect) 센서, 초음파 센서, 또는 적외선 센서를 포함할 수 있다. 저가의 센서는, 다른 예를 들면, 물체의 유무나 형상을 식별 할 수 있는 형상 인식 센서 또는 물체의 위치를 측정하는 2차원 위치 센서(2-dimensional sensor)(또는 2차원 광센서, 또는 영상 센서)를 포함할 수 있다. 실시예들에 따라 전자 장치는 고성능의 삼차원 센서를 대신하 여 저가의 센서를 사용함으로써 빈 피킹 시스템의 구성 비용을 감소시킬 수 있다. 다양한 실시 예들에서, 전자 장치는 저가의 센서를 통해 획득된 데이터에 대해 인공 지능 알고리즘을 적용 함으로써 인공 지능 학습 모델을 생성(또는 획득)할 수 있다. 전자 장치는 인공 지능 학습 모델을 이용함 으로써 전자 장치는 객체를 인식하고 객체의 자세를 추정할 수 있다. 전자 장치는 객체의 피킹을 위 한 과정에서 발생되는 다양한 예외의 상황을 처리할 수 있다. 다양한 실시 예들에 따른 전자 장치는, 인공 지능 알고리즘에 기반하여 획득된 적어도 하나의 객체에 대한 데이터를 포함하는 트레이닝 데이터 베이스(data base)와 명령어들을 포함하는 메모리, 적어도 하나의 센 서, 및 상기 적어도 하나의 센서 및 상기 메모리와 연결된 프로세서를 포함할 수 있다. 상 기 프로세서는, 상기 적어도 하나의 센서를 이용하여 적어도 하나의 객체를 포함하는 지정된 영역에 대한 데이터를 획득하고, 상기 트레이닝 데이터 베이스에 기반하여, 상기 적어도 하나의 객체의 위치에 대한 정 보 및 자세에 대한 정보를 식별하고, 및 상기 식별된 위치에 대한 정보 및 상기 자세에 대한 정보에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를 상기 전자 장치와 관련된 피킹툴에게 송신하 기 위해 상기 명령어들을 실행하도록 설정될 수 있다. 다양한 실시 예들에서, 상기 적어도 하나의 센서는, 상기 적어도 하나의 객체가 상기 지정된 영역 내에 포 함되는 지 여부, 상기 적어도 하나의 객체의 모양(shape), 상기 적어도 하나의 객체의 위치, 상기 적어도 하나 의 객체의 자세 중 적어도 하나를 측정하기 위한 센서를 포함할 수 있다. 다양한 실시 예들에서, 상기 지정된 영역에 대한 데이터는 상기 지정된 영역과 관련된 이미지를 나타내는 정보 를 포함할 수 있다. 다양한 실시 예들에서, 상기 적어도 하나의 객체의 위치에 대한 정보는, 상기 적어도 하나의 객체의 상기 지정 된 영역 상의 x축의 값, y축의 값 또는 z축의 값 중 적어도 하나를 포함하고, 및 상기 적어도 하나의 객체의 자 세에 대한 정보는, 상기 적어도 하나의 객체에 대한 요에 대한 정보, 롤에 대한 정보, 또는 피치에 대한 정보 중 적어도 하나를 포함할 수 있다. 다양한 실시 예들에서, 상기 적어도 하나의 객체의 위치에 대한 정보는, 상기 적어도 하나의 객체의 상기 지정 된 영역 상의 x축의 값 및 y축의 값을 포함할 수 있다. 상기 적어도 하나의 객체의 자세에 대한 정보는, 상기 적어도 하나의 객체의 요에 대한 정보를 포함할 수 있다. 다양한 실시 예들에서, 상기 프로세서는, 상기 식별된 상기 적어도 하나의 객체의 위치에 대한 정보에 기 반하여, 상기 위치에 대한 정보를 나타내는 위치맵(location map)을 생성하고, 및 상기 식별된 상기 적어도 하 나의 객체의 자세에 대한 정보에 기반하여, 상기 위치에 대한 정보를 나타내는 자세맵(position map)을 생성하 기 위해 상기 명령어들을 실행하도록 더 설정될 수 있다. 일부 실시 예들에서, 상기 프로세서는, 인공 지 능 알고리즘에 기반하여, 상기 위치맵 및 상기 자세맵을 생성하도록 설정될 수 있다. 다른 일부 실시 예들에서, 프로세서는 상기 생성된 위치맵 및 상기 생성된 자세맵에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를 상기 전자 장치와 관련된 상기 피킹툴에게 송신하기 위해 상기 명령어들을 실행하도록 더 설정될 수 있다. 다양한 실시 예들에서, 상기 프로세서는, 상기 인공 지능 알고리즘에 기반하여 상기 지정된 영역에 대한 데이터, 상기 적어도 하나의 객체의 위치에 대한 정보, 및 상기 자세에 대한 정보를 처리(process)하고, 상기 처리에 기반하여 상기 트레이닝 데이터 베이스를 갱신하기 위해 상기 명령어들을 실행하도록 더 설정될 수 있다. 다양한 실시 예들에서, 상기 트레이닝 데이터 베이스는 상기 적어도 하나의 객체의 위치에 대한 정보, 상기 적 어도 하나의 객체의 자세에 대한 정보, 및 상기 적어도 하나의 객체에 대한 영상 정보를 포함하고, 및 상기 영 상 정보는 상기 적어도 하나의 객체를 나타내는 가상 데이터 및 상기 인공 지능 알고리즘에 기반하여 생성된 정 보를 포함할 수 있다. 본 문서에 개시된 다양한 실시 예들에 따른 전자 장치는 다양한 형태의 장치가 될 수 있다. 전자 장치 는, 예를 들면, 휴대용 통신 장치 (예: 스마트폰), 컴퓨터 장치, 휴대용 멀티미디어 장치, 휴대용 의료 기 기, 카메라, 웨어러블 장치, 또는 가전 장치 중 적어도 하나를 포함할 수 있다. 본 문서의 실시 예에 따른 전자 장치는 전술한 기기들에 한정되지 않는다. 본 문서의 다양한 실시 예들 및 이에 사용된 용어들은 본 문서에 기재된 기술을 특정한 실시 형태에 대해 한정 하려는 것이 아니며, 해당 실시 예의 다양한 변경, 균등물, 및/또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 단수의 표현 은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및/ 또는 B 중 적어도 하나\", \"A, B 또는 C\" 또는 \"A, B 및/또는 C 중 적어도 하나\" 등의 표현은 함께 나열된 항목 들의 모든 가능한 조합을 포함할 수 있다. \"제 1\", \"제 2\", \"첫째\" 또는 \"둘째\" 등의 표현들은 해당 구성요소들 을, 순서 또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해 당 구성요소들을 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제 2) 구성요소에 \"(기능적으로 또는 통신적으로) 연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소 에 직접적으로 연결되거나, 다른 구성요소(예: 제 3 구성요소)를 통하여 연결될 수 있다. 본 문서에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구성된 유닛을 포함하며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수 있다. 예를 들면, 모듈은 ASIC(application-specific integrated circuit)으로 구성될 수 있다. 본 문서의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)(예: 내장 메모리 또는 외장 메모리)에 저장된 명령어를 포함하는 소프트웨어(예: 프로그램)로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장 치로서, 개시된 실시 예들에 따른 전자 장치(예: 전자 장치)를 포함할 수 있다. 상기 명령이 프로세서(예: 프로세서)에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세서의 제어하에 다른 구성요소들을 이용 하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되 는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제 공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 일시예에 따르면, 본 문서에 개시된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경 우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 도 3은 다양한 실시 예들에 따른 전자 장치의 동작의 예를 도시한다. 도 3을 참조하면, 동작 301에서, 프로세서는 객체(또는 적어도 하나의 객체)를 포함하는 지정된 영역(10 5)에 대한 정보를 획득할 수 있다. 프로세서는 센서를 통해 객체를 포함하는 지정된 영역에 대한 정 보를 획득할 수 있다. 프로세서는 센서를 통해 실시간으로 획득된 지정된 영역에 대한 이미지 정보를 획득할 수 있다. 객체는 프로세서가 피킹하고자 하는 대상에 대응될 수 있으며 한개 또는 그 이상의 객체 들을 포함할 수 있다. 지정된 영역은 객체가 포함된 특정 영역을 지칭하는 것으로, 사용자에 의해 미리 설 정된 특정 위치에 대응될 수 있다. 예를 들면, 지정된 영역은 전자 장치의 주변에 위치된 상자 내부 의 일정 영역을 포함할 수 있다. 지정된 영역에 대한 설명은 도 4에 대한 설명을 통해 후술될 것이다. 도 4를 참조하면, 전자 장치는 인접한 위치에 있는 지정된 영역에 대한 정보를 획득할 수 있다. 지정 된 영역은 객체를 포함하는 특정 구간(또는 장소)의 일부를 포함할 수 있다. 지정된 영역 내에서 객 체는 랜덤(random)하게(또는 무작위하게) 위치될 수 있다. 프로세서는, 지정된 영역의 상부(above)에 위치된 센서를 통해 지정된 영역에 대한 정보를 획득 할 수 있다. 센서는 지정된 영역으로부터 위쪽으로 일정 거리만큼 떨어진 상태로 위치될 수 있다. 다 양한 실시 예들에서, 센서는 지상에서 고정된 프레임에 부착된 상태로 위치될 수 있다. 도시하지는 않았으나, 실시 예들에 따라, 센서는 전자 장치의 적어도 일부로서 지정된 영역의 상부에 위치 될 수 있다. 예를 들면, 센서는 지정된 영역의 상부로 돌출된 전자 장치의 일부(예: 회전 모듈 )에 부착된 채로(또는 포함되어) 위치될 수 있다. 다양한 실시 예들에서, 센서는 카메라 센서 또는 이미지 센서를 포함할 수 있다. 지정된 영역에 대한 정보 는, 예를 들면, 지정된 영역을 나타내는 이미지 정보(또는 영상 정보)를 포함할 수 있다. 동작 303에서, 프로세서는 트레이닝 데이터에 기반하여 객체의 위치에 대한 정보 및 자세에 대한 정보를 식별할 수 있다. 트레이닝 데이터는, 인공 지능 알고리즘에 기반하여 미리 생성된 데이터를 포함할 수 있다. 트 레이닝 데이터는, 예를 들면, 객체의 형상을 나타내는 가상 데이터에 기반하여 학습된 데이터를 포함할 수 있다. 다른 예를 들면, 트레이닝 데이터는, 객체의 위치, 객체의 존재 여부, 또는 객체의 자세를 식별하기 위해 사용자의 입력에 기반하여 생성된 객체의 레이블 정보(또는 레이블링 정보, 또는 테이블 정보)를 포함할 수 있 다. 트레이닝 데이터와 관련된 설명은, 도 8 내지 도 11을 통해 후술될 것이다. 다양한 실시 예들에서, 트레이닝 데이터는 외부 전자 장치로부터 생성되어, 외부 전자 장치로부터 수신될 수 있 다. 이러한 경우, 프로세서는 수신된 트레이닝 데이터에 기반하여 객체의 위치에 대한 정보 및 객체의 자 세에 대한 정보를 식별할 수 있다. 다양한 실시 예들에서, 객체의 위치에 대한 정보는, 지정된 영역 내의 객체의 위치를 나타내기 위한 정보 를 포함할 수 있다. 객체의 위치에 대한 정보는 지정된 영역을 xy평면으로 가정한 상태에서, x축의 좌표값 및 y축의 좌표값에 대한 정보를 포함할 수 있다. 예를 들면, 객체가 50cm의 길이를 가지는 정사각형 형태의 지 정된 영역의 정중앙에 위치되는 경우, 객체의 위치에 대한 정보는 (25,25)일 수 있다. 다양한 실시 예들에서, 객체의 자세에 대한 정보는, 지정된 영역 내에서 객체가 위치된 방향, 각도, 또는 기울기 중 적어도 하나에 대한 정보를 포함할 수 있다. 예를 들면, 객체의 자세에 대한 정보는, 요(yaw), 롤 (roll), 또는 피치(pitch) 중 적어도 하나에 대한 정보를 나타내기 위한 값을 포함할 수 있다. 다른 예를 들면, 객체의 자세에 대한 정보는, 지정된 영역을 xy 평면으로 하고, xy 평면 상에서 y축을 기준으로 기울어진 각도에 대한 정보를 포함할 수 있다. 동작 305에서, 프로세서는 객체를 식별하는 것에 기반하여, 객체를 피킹하기 위한 제어 신호를 피킹툴 에게 송신할 수 있다. 다양한 실시 예들에서, 전자 장치는 전자 장치의 일부로서 피킹툴을 포함할 수 있다. 일부 실시 예들에서, 프로세서는 객체를 피킹하기 위해 피킹툴을 제어할 수 있다. 실시 예들에따라, 프로세서는 객체를 피킹하기 위한 제어 신호를 생성하여 피킹툴에게 송신할 수 있 다. 송신에 기반하여, 프로세서는 피킹툴의 움직임을 제어할 수 있다. 프로세서는 피킹툴을 움직임으로써 객체를 피킹(또는 파지)할 수 있다. 다른 일부 실시 예들에서, 프로세서는 피킹툴의 제어를 위한 보조 프로세서를 통해 피킹툴을 제어할 수 있다. 프로세서는 객체를 피킹하기 위한 제어 신호를 생성하여 보조 프로세서에게 송신할 수 있다. 송신에 기반하여, 프로세서는 보조 프로세서에 기반 하여 피킹툴의 움직임을 제어할 수 있다. 프로세서는 보조 프로세서에 기반하여 피킹툴을 움직 임으로써 객체를 피킹(또는 파지)할 수 있다. 다양한 실시 예들에서, 피킹툴은 전자 장치의 외부에 위치될 수 있다. 이러한 경우, 전자 장치 는, 무선 또는 유선으로 피킹툴과 연결될 수 있다. 프로세서는 피킹툴에게 제어 신호를 송신함 으로써 객체를 피킹하도록 제어할 수 있다. 실시 예들에 따라, 프로세서는 객체를 피킹하기 위한 제어 신 호를 생성할 수 있다. 프로세서는 생성된 제어 신호를 피킹툴에 송신함으로써, 피킹툴을 제어할 수 있다. 다양한 실시 예들에서, 프로세서는 피킹툴의 움직임을 나타내기(또는 제어하기) 위한 제어 신호를 생 성할 수 있다. 예를 들면, 제어 신호는 피킹툴을 객체의 위치에 상응하는 위치로 이동시키기 위한 신호를 포함할 수 있다. 다른 예를 들면, 제어 신호는 객체를 피킹하기 위해, 객체의 자세에 상응하는 방향으로 피킹툴 의 위치 또는 방향을 조정하기 위한 신호를 포함할 수 있다. 프로세서는 피킹툴에게 제어 신호 를 송신함으로써 피킹툴의 움직임을 제어할 수 있다. 제어 신호를 수신하는 것에 기반하여, 피킹툴은 지정된 영역내에 포함된 객체를 피킹할 수 있다. 객체를 피킹하기 위한 피킹툴의 동작은 도 5를 참조 할 수 있다. 도 5를 참조하면, 장면은 객체를 피킹하는 피킹툴의 동작을 확대하여 도시한다. 피킹툴은 프로세서로부터 수신된 제어 신호에 기반하여 객체를 피킹하기 위한 동작을 수행할 수있다. 피킹툴 은 객체와 접촉되는 접촉부를 포함할 수 있다. 접촉부의 하단에는 객체의 피킹을 위한 홈을 포 함할 수 있다. 접촉부의 하단의 홈은 객체의 모양에 상응하는 형태를 가질 수 있다. 실시 예들에 따라, 접 촉부는 전자석으로 구성될 수 있으며, 전기적인 신호에 기반하여 객체를 피킹할 수 있다. 피킹툴은 상기 제어 신호에 기반하여 접촉부를 객체에 접근시킴으로써, 객체를 피킹할 수 있다. 도시하지는 않 았으나, 제어 신호에 기반하여 피킹툴은 피킹된 객체를 컨베이어 벨트 위로 옮길 수 있다. 도 5에 도시된 피킹툴의 접촉부 또는 객체는 본 발명을 설명하기 위한 예시로서, 상술된 예에 의해 본 발명이 제한되지 않는다. 다양한 실시 예들에서, 전자 장치는 객체의 이동이 반복적으로 요구되는 물류 공장, 제조 공장 등에서 사 용됨으로써 공장의 자동화 시스템을 구축할 수 있다. 저가의 센서를 사용함으로써 물류의 자동화 시스템에 소요 되는 비용이 감소될 수 있다. 도 6은 다양한 실시 예들에 따라 트레이닝(training) 과 관련된 전자 장치의 동작의 다른 예를 도시한다. 도 6 의 동작 601 내지 동작 607은 도 4의 동작 405와 관련될 수 있다. 도 6에 예시된 동작들은 도 4의 동작 405를 실시하기 위한 필수적 요소가 아닐 수 있다. 다시 말해, 도 6의 동작 601 내지 동작 605는 하나의 실시 예이므 로, 실시 예들에 따라 생략될 수도 있음을 유의하여야 한다. 도 6을 참조하면, 동작 601에서, 프로세서는 트레이닝 데이터를 이용하여 위치에 대한 정보를 획득함으로 써 위치맵을 생성할 수 있다. 프로세서는, 트레이닝 데이터에 기반하여 센서를 통해 획득된 지정된 영역 에 대한 정보를 처리함으로써 위치맵을 생성할 수 있다. 위치맵은 지정된 영역에 포함된 객체의 위치 에 대한 정보를 포함할 수 있다. 다양한 실시 예들에서, 프로세서는 미리 저장된 트레이닝 데이터에 기반하여 객체의 위치에 대한 정보를 획득할 수 있다. 실시 예들에 따라, 프로세서는 실시간으로 트레이닝 데이터를 갱신할 수 있으며, 갱신되 는 트레이닝 데이터에 기반하여 객체의 위치에 대한 정보를 획득할 수 있다. 프로세서는 위치에 대한 정보 에 기반하여, 위치맵을 생성할 수 있다. 위치맵에 대한 설명은 도 7을 참조할 수 있다. 도 7을 참조하면, 위치맵은 지정된 영역 내에서 객체가 놓여진 위치를 나타낼 수 있다. 위치맵 에 표시된 두개의 지점(예: 제1 지점, 제2 지점)은 각각 객체가 놓여진 위치를 나타낼 수 있다. 프로 세서는 트레이닝 데이터를 이용하여 객체의 위치에 대한 정보를 획득함으로써 위치맵을 생성할 수 있 다. 예를 들면, 프로세서는 트레이닝 데이터에 기반하여 지정된 영역의 범위 내에서 객체의 위치에 상응하는 지점을 포함하는 위치맵을 생성할 수 있다. 동작 603에서, 프로세서는 트레이닝 데이터를 이용하여 자세에 대한 정보를 획득함으로써 자세맵을 생성할 수 있다. 프로세서는, 트레이닝 데이터에 기반하여 센서를 통해 획득된 지정된 영역에 대한 정보를 처리함으로써 자세맵을 생성할 수 있다. 자세맵은 지정된 영역에 포함된 객체의 자세에 대한 정보를 포함 할 수 있다. 다양한 실시 예들에서, 프로세서는 미리 저장된 트레이닝 데이터에 기반하여 객체의 자세에 대한 정보를 획득할 수 있다. 실시 예들에 따라, 프로세서는 실시간으로 트레이닝 데이터를 갱신할 수 있으며, 갱신되 는 트레이닝 데이터에 기반하여 객체의 자세에 대한 정보를 획득할 수 있다. 프로세서는 자세에 대한 정보 에 기반하여, 자세맵을 생성할 수 있다. 자세맵에 대한 설명은 도 7을 참조할 수 있다. 도 7을 참조하면, 자세맵은 지정된 영역 내에 포함된 객체의 자세를 나타낼 수 있다. 자세맵에 표시된 두 개의 화살표은 각각 객체가 놓여진 자세를 나타낼 수 있다. 예를 들면, 자세맵의 제1 화살표 는 왼쪽 방향을 나타낼 수 있다. 제1 화살표는 제1 화살표의 상응하는 위치에 놓여진 객체가 왼 쪽 방향을 향하도록 위치되어 있음을 나타낼 수 있다. 다른 예를 들면, 자세맵의 제2 화살표는 위쪽 방향을 나타낼 수 있다. 제2 화살표는 제2 화살표의 상응하는 위치에 놓여진 객체가 위쪽 방향을 향 하도록 위치되어 있음을 나타낼 수 있다. 객체의 자세를 표현하기 위한 화살표(예: 제1 화살표, 제2 화살 표)의 표시 기준은 객체의 형태 또는 종류에 따라 서로 다르게 결정될 수 있다. 예를 들면, 객체가 나사못 의 형태인 경우, 나사못의 머리 부분이 항하는 방향을 화살표의 방향으로 할 수 있다. 다른 예를 들면, 객체가 나사못의 형태인 경우, 나사못의 꼬리 부분이 항하는 방향을 화살표의 방향으로 할 수 있다. 다양한 실시 예들에서, 제1 지점과 제1 화살표는 동일한 객체에 대한 각각의 위치 및 자세를 나타내 기 위한 정보일 수 있다. 제2 지점과 제2 화살표는 동일한 객체에 대한 각각의 위치 및 자세를 나타 내기 위한 정보일 수 있다. 다양한 실시 예들에서, 객체의 자세를 나타내기 위해 자세맵을 구성하는 정보(예: 제1 화살표, 제2 화살표 )는 수학적인 값으로 표현될 수 있다. 자세맵을 구성하는 정보는 지정된 영역 내에서 객체의 위치에 상응하는 픽셀(pixel)에 대한 정보를 포함할 수 있다. 수학적인 값은, 예를 들면, 제1 화살표의 방향을 나 타내기 위한 오일러(euler)에 대한 값, 또는 쿼터니언(quaternion)에 대한 값을 포함할 수 있다. 다양한 실시 예들에서, 위치맵 또는 자세맵은 프로세서에 의해 생성 가능한 위치맵과 자세맵의 일 실시 예를 나타낸 것이며, 상술된 예에 한정되지 않는다. 실시 예들에 따라, 동작 601과 동작 603은, 동시에 또는 순서에 무관하게 수행될 수 있다. 동작 605에서, 프로세서는 위치맵과 자세맵에 기반하여 객체의 위치 및 객체의 자세를 식별할 수 있다. 프 로세서는 생성된 위치맵에 기반하여 객체의 위치를 식별할 수 있다. 예를 들면, 프로세서는 생성된 위치맵에 기반하여, 객체가 위치된 좌표값에 대한 정보를 획득(또는 식별)할 수 있다. 다른 예를 들면, 프로세 서는 객체의 로컬피크(local peak)를 찾기 위한 알고리즘(또는 수식)에 기반하여 객체의 위치를 식별할 수 있다. 로컬피크(local peak)를 찾기 위한 알고리즘은, 예를 들면, 가우시안 비선형 가우시안 피팅 방식을 포함 할 수 있다. 프로세서는 생성된 자세맵에 기반하여 객체의 자세에 대한 자세값을 획득(또는 식별)할 수 있 다. 예를 들면, 프로세서는 생성된 위치맵에 기반하여, 객체의 요(yaw)와 관련된 자세값을 획득(또는 식별)할 수 있다. 다른 예를 들면, 프로세서는 생성된 위치맵에 기반하여, 객체가 y축을 기준으로 기울어 진 각도에 대한 값을 획득할 수 있다. 실시 예들에 따라, 자세를 나타내는 방식은 상이할 수 있으며, 자세를 나 타내는 방식에 따라 자세값은 n차원의 이미지에 대한 정보로 표현될 수 있다. 동작 607에서, 프로세서는 레이블 정보를 이용하여, 위치맵의 생성 또는 자세맵의 생성과 관련된 트레이닝 을 수행할 수 있다. 프로세서는 인공 지능 알고리즘(이하 제2 인공 지능 알고리즘)에 기반하여 레이블 정 보를 이용함으로써 상기 트레이닝을 수행할 수 있다. 다양한 실시 예들에서, 프로세서는 제2 인공 지능 알고리즘에 기반하여 레이블링 정보를 이용하여 객체를 식별하기 위한 프로세서의 동작을 갱신할 수 있다. 프로세서는 제2 인공 지능 알고리즘에 기반하여 위치맵 또는 자세맵을 회기 분석(regression)함으로써 객체의 식별과 관련된 오차를 갱신할 수 있다. 예를 들면, 프로세서는 회기 분석에 기반하여 프로세서의 객체를 식별하는 동작에 대한 일정한 결과값을을 정답으로써 제공하는 것에 의해, 위치맵 또는 자세맵의 생성과 관련된 동작을 갱신할 수 있다. 다양한 실시 예들에서, 프로세서는 센서를 통해 획득된 정보와 관련하여 일정한 크기를 가지는 객체 의 위치를 정확한 숫자의 형태로 표현하기 어려울 수 있다. 프로세서는 확률맵(예: 위치맵, 자세맵)을 이용하여 객체와 관련된 적어도 하나의 동작들을 처리함으로써 객체의 위치 또는 자세에 대한 오차를 최소화 할 수 있다. 확률맵을 이용함으로써, 프로세서는 객체의 위치에 대한 좌표값 또는 객체의 자세에 대한 자세값 을 획득할 수 있다. 레이블 정보는 프로세서 또는 외부 장치에 의해 미리 생성된 객체의 식별을 위한 데이터를 포함할 수 있다. 레이블 정보는 객체의 위치와 관련된 위치 레이블 정보 또는 객체의 자세와 관련된 자세 레이블 정보를 포함할 수 있다. 레이블 정보는, 예를 들면, 프로세서에게 피드백을 제공함으로써 인공 지능 알고리즘을 통한 트레이닝을 수행하기 위한 기준 데이터를 포함할 수 있다. 다양한 실시 예들에서, 프로세서는 사용자의 입력을 검출하는 것에 기반하여 레이블 정보를 생성할 수 있 다. 레이블 정보는 객체의 위치에 대한 사용자의 복수의 입력을 검출하는 것에 기반하여 생성된 결과값에 대한 정보를 포함할 수 있다. 레이블 정보는 객체의 자세에 대한 사용자의 복수의 입력을 검출하는 것에 기반하여 생 성된 결과값에 대한 정보를 포함할 수 있다. 레이블 정보와 관련된 설명은 도 10 또는 도 11을 통해 후술하겠다. 다양한 실시 예들에서, 동작 605 와 동작 607은 동시에 또는 순서에 무관하게 수행될 수 있다. 예를 들면, 프로 세서는 위치맵과 자세맵에 기반하여 객체의 위치 및 객체의 자세를 식별함과 동시에, 레이블 정보를 이용 하여 위치맵과 자세맵의 생성에 대한 트레이닝을 수행할 수 있다. 도 8은 다양한 실시 예들에 따라 트레이닝 데이터의 획득을 위한 전자 장치의 동작의 예를 도시한다. 도 8은 객 체를 식별하기 위해 이용되는 트레이닝 베이스를 생성하는 프로세서의 동작의 예를 나타낼 수 있다. 실시 예들에 따라, 도 8의 동작 801 내지 동작 807 중 적어도 일부는 외부 장치에 의해 수행될 수 있다. 이러한 경우, 프로세서는 외부 장치와의 연결에 기반하여 트레이닝 데이터를 획득(또는 생성)할 수 있다. 도 8을 참조하면, 동작 801에서, 프로세서는 가상 데이터를 이용하여 물리 시뮬레이션을 수행할 수 있다. 프로세서는 물리 시뮬레이터에 기반하여 객체에 대한 가상 데이터에 대한 물리 시뮬레이션을 수행할 수 있 다 .가상 데이터는, 하나의 객체를 나타내기 위한 2차원의 이미지에 광원, 위치, 색상, 형태, 모양 중 적어도 하나에 기반하여 생성된 삼차원의 데이터를 포함할 수 있다. 가상 데이터에 대한 설명은 도 9를 참조할 수 있다. 도 9를 참조하면, 다양한 실시 예들에서, 가상 데이터는 이미지를 포함할 수 있다. 가상 데이터는 객체에 대한 실제의 데이터에 기반하여 객체를 나타내기 위한 정보를 포함할 수 있다. 예를 들면, 가상 데이터는, 객체 의 형상, 모양, 또는 크기 중 적어도 하나를 나타내기 위한 정보를 포함할 수 있다. 실시 예들에 따라, 가상 데 이터는 3차원의 이미지를 포함할 수 있다. 도시하지는 않았으나, 예를 들면, 이미지에 대한 정보는 객체의 크기 정보, 모양 정보, 또는 컬러 정보를 포함할 수 있다. 이미지를 식별함으로써 프로세서는 객체와 관련된 보다 구체적인 정보를 획득할 수 있다. 예를 들면, 프로세서는 객체의 크기, 객체의 형상, 또는 객 체의 색을 식별할 수 있다. 다양한 실시 예들에서, 프로세서는 객체에 대한 가상 데이터를 이용하여 물리 시뮬레이션을 수행할 수 있 다. 물리 시뮬레이션은 다양한 물리적 수치를 이용하여, 객체에 대한 사실적인 정보를 획득하기 위한 적어도 하 나의 동작을 포함할 수 있다. 물리적 수치는 예를 들면, 질량, 마찰력, 관성, 또는 속도 중 적어도 하나에 대한 정보를 포함할 수 있다. 프로세서는 물리 시뮬레이터에 기반하여, 객체에 대한 물리적 수치를 이용함으로 써 객체와 관련된 현실의 상황들을 시뮬레이션 할 수 있다. 물리 시뮬레이터는 물리 시스템을 시뮬레이션 하기 위한 전자 장치의 하드웨어 또는 소프트웨어일 수 있다. 물리 시스템은, 예를 들면, 광학, 강체동역학, 유 동역학, 동역학, 또는 정역학과 관련된 시스템을 포함할 수 있다. 동작 803에서, 프로세서는 물리 시뮬레이션에 대한 센서 데이터를 획득(또는 생성)할 수 있다. 프로세서 는 가상 데이터를 식별하는 것에 기반하여, 센서 데이터를 획득할 수 있다. 예를 들면, 프로세서는 가상 데이터를 입력으로 하는 물리 시뮬레이션에 기반하여 센서 데이터를 획득할 수 있다. 이러한 경우 센서 데 이터는, 물리 시뮬레이션의 출력값에 대응될 수 있다. 센서 데이터에 대한 설명은 도 9를 참조할 수 있다. 도 9를 참조하면, 다양한 실시 예들에서, 프로세서는 가상 데이터(예: 이미지)에 기반하여, 센서 데 이터(예: 이미지)를 획득할 수 있다. 프로세서는 가상 데이터를 이용하여 물리 시뮬레이션을 수행함 으로써 복수의 객체들에 대한 센서 데이터를 획득할 수 있다. 프로세서는 가상 데이터 및 다양한 물리적 수치에 기반하여 복수의 객체들에 대한 센서 데이터를 획득할 수 있다. 프로세서는 복수의 객체들 각각에물리적 수치를 적용함으로써 센서 데이터를 획득할 수 있다. 센서 데이터는 실제와 가장 유사한 형태의 이미지 를 포함할 수 있다. 예를 들면, 센서 데이터는 복수의 객체들이 임의로 배열된 경우를 나타내는 이미지 를 포함할 수 있다. 동작 805에서 프로세서는 인공 지능 알고리즘을 이용하여 센서 데이터의 영상 시뮬레이션을 수행할 수 있 다. 프로세서는 인공 지능 알고리즘과 관련된 영상 시뮬레이터(또는 영상 기반 시뮬레이터)에 기반하여, 센서 데이터의 영상 시뮬레이션을 수행할 수 있다. 프로세서는 객체와 관련된 실제 데이터 및 센서 데이터 를 이용하여 영상 시뮬레이션을 수행할 수 있다. 일부 실시 예들에서, 객체와 관련된 실제 데이터는 전자 장치 에 포함된 센서를 통해 미리 획득된 객체에 대한 실제의 정보를 포함할 수 있다. 다른 일부 실시 예 들에서, 객체와 관련된 실제 데이터는 전자 장치에 포함된 센서를 통해 실시간으로 획득되는 지정된 영역 내에 포함된 객체에 대한 실제의 정보를 포함할 수 있다. 지정된 영역 내에 포함된 객체에 대한 정보는 실제의 데이터일 수 있으며, 주변의 상황에 따라 실시간으로 갱신될 수 있다. 또 다른 일부 실시 예들에 서, 객체와 관련된 실제 데이터는, 외부 장치로부터 수신된 객체에 대한 실제의 정보를 포함할 수 있다. 동작 807에서, 프로세서는 영상 시뮬레이션에 대한 트레이닝 데이터를 획득할 수 있다. 프로세서는 영상 시뮬레이션을 수행함으로써 객체와 관련된 실제와 유사한 이미지(예: 트레이닝 데이터)를 생성할 수 있다. 트레이닝 데이터에 대한 설명은 도 9를 참조할 수 있다. 도 9를 참조하면, 다양한 실시 예들에서, 프로세서는 센서 데이터(예: 이미지 903))에 기반하여, 트레이닝 데이터(예: 이미지)를 획득할 수 있다. 프로세서는 센서 데이터를 이용하여 영상 시뮬레이션을 수행 함으로써 복수의 객체들에 대한 트레이닝 데이터를 획득(또는 생성)할 수 있다. 트레이닝 데이터는 지정된 영역 내에 포함된 복수의 객체들을 나타내는 이미지를 포함할 수 있다. 프로세서는 이미지를 영상 시뮬레이션함으로써, 복수의 객체들을 보다 사실적으로 나타내기 위한 이미지를 획득할 수 있다. 도시하지는 않았으나, 다양한 실시 예들에서, 프로세서는 다양한 경로를 통해 실제 데이터를 획득할 수 있 다. 프로세서는 획득된 실제 데이터 및 센서 데이터에 기반하여 복수의 객체들에 대한 트레이닝 데이터를 획득할 수 있다. 프로세서는 실제 데이터에 기반하여 복수의 객체들에 대한 센서 데이터를 처리함으로써 트레이닝 데이터를 획득할 수 있다. 센서 데이터를 처리하는 동작은, 인공 지능 알고리즘에 기반하여 수행될 수 있다. 다양한 실시 예들에서, 인공 지능 알고리즘(이하 제1 인공 지능 알고리즘)은 센서 데이터에 실제 데이터를 반영 하여 보다 정확한 트레이닝 데이터를 생성하기 위한 다양한 알고리즘을 포함할 수 있다. 예를 들면, 제1 인공 지능 알고리즘은, GMM, AE, 또는 GAN을 포함할 수 있다. 실시 예들에 따라, 제1 인공 지능 알고리즘은 도 6의 동작 607 과정의 인공 지능 알고리즘과 구분될 수 있다(또는 상이할 수 있다). 다양한 실시 예들에서, 제1 인공 지능 알고리즘은 센서 데이터에 기반하여 객체를 나타내기 위한 제1 데이터를 생성하는 생성 모듈 및 객체와 관련된 실제 데이터와 제1 데이터를 구별하기 위한 판별 모듈을 포함할 수 있다. 생성 모듈은 제1 데이터와 실제 데이터가 서로 구별되지 않도록 제1 데이터를 생성하는 방향으로 트레이닝될 수 있다. 판별 모듈은, 생성 모듈을 통해 생성된 제1 데이터와 입력된 실제 데이터의 차이점을 구별하도록 트레이 닝할 수 있다. 생성 모듈과 판별 모듈을 통한 트레이닝에 기반하여, 프로세서는 제1 인공 지능 알고리즘에 대한 제2 데이터(예: 트레이닝 데이터)를 생성할 수 있다. 실시 예들에 따라, 프로세서는 미리 저장된 실 제 데이터 또는 가상 데이터와 관련된 데이터를 이용하여 제1 인공 지능 알고리즘에 기반한 트레이닝을 수행할 수 있다. 다양한 실시 예들에서, 프로세서는 제1 인공 지능 알고리즘에 기반하여 트레이닝 데이터를 생성할 수 있다. 예를 들면, 제1 인공 지능 알고리즘에 기반하여 프로세서는 센서 데이터와 실제 데이터를 식별할 수 있다. 프로세서는 센서 데이터와 실제 데이터 사이의 오차(또는 차이점)를 식별할 수 있다. 식별된 오차는 예를 들면, 물리적 수치와 관련된 오차, 조명(또는 빛, 또는 음영)과 관련된 오차, 또는 센서와 관련된 오 차를 포함할 수 있다. 오차를 이용함으로써, 프로세서는 실제와 유사하게 트레이닝 데이터를 생성하기 위 한 트레이닝(또는 학습)을 수행할 수 있다. 생성된 트레이닝 데이터는 센서 데이터에 대해 실제적인 수치들이 반영되고, 실제와 유사하게 생성된 데이터를 포함할 수 있다. 실시 예들에 따라, 도 9의 이미지들(901, 903, 또는 905)는 시각적인 정보를 나타내기 위한 형식(예: 영상, 비 디오, 또는 움직이는 이미지)으로 표현될 수 있으며, 상술된 예에 한정되지 않는다. 도 10 은 다양한 실시 예들에 따라 레이블(label) 정보를 생성하기 위한 전자 장치의 동작의 예를 도시한다. 도 10은, 도 6의 동작 607과 관련된 레이블 정보를 생성하기 위한 프로세서의 동작의 예를 나타낼 수 있다. 실시 예들에 따라, 도 10의 동작 1001 내지 동작 1007 중 적어도 일부는 외부 장치에 의해 수행될 수 있다. 이 러한 경우, 프로세서는 외부 장치와의 연결에 기반하여 레이블 정보를 획득(또는 생성)할 수 있다. 도 10을 참조하면, 동작 1001에서, 프로세서는 객체의 중심점에 대한 제1 입력을 검출할 수 있다. 프로세 서는 지정된 영역에 포함된 하나의 객체에 대한 사용자의 입력(또는 사용자 입력(user input))을 검 출할 수 있다. 사용자의 입력은 객체의 중심점을 나타내기 위한 제1 입력을 포함할 수 있다. 제1 입력과 관련된 설명은 도 11에 대한 설명을 통해 후술될 것이다. 동작 1003에서, 프로세서는 객체의 끝점에 대한 제2 입력을 검출할 수 있다. 프로세서는 지정된 영 역에 포함된 하나의 객체에 대한 사용자의 입력을 검출할 수 있다. 사용자의 입력은 객체의 끝점을 나타내 기 위한 제2 입력을 포함할 수 있다. 객체의 끝점은 객체의 중심점과는 구별되는 상기 객체의 다른 한점(또는 특징점)을 포함할 수 있다. 객체의 끝 점은 실시 예마다 달라질 수 있으며, 본 발명에서 서술되는 예에 한정되 지 않는다. 제2 입력과 관련된 설명은 도 11에 대한 설명을 통해 후술될 것이다. 실시 예들에 따라, 동작 1001 및 동작 1003은 동시에 또는 순서에 무관하게 수행될 수 있다. 도 11을 참조하면, 프로세서는 지정된 영역에 포함된 복수의 객체들 중 적어도 하나의 객체의 중심점 또는 끝점에 대한 사용자의 입력을 검출할 수 있다. 프로세서는 지정된 영역 내에 포함된 제1 객체 의 중심점에 대한 입력(이하 제1 입력) (예: click 1)을 검출할 수 있다. 다양한 실시 예들에서, 제1 입 력은 제1 객체의 위치를 나타내기 위한 사용자의 입력을 포함할 수 있다. 제1 입력은, 예를 들면, 객체의 중심에 대한 사용자의 클릭(click), 더블 클릭(double click), 롱 클릭(long click), 또는 터치 입력(touch input)중 적어도 하나일 수 있다. 제1 입력은 객체의 위치를 나타내기 위한 지점과 관련된 다양한 입력을 포함 할 수 있으며, 상술된 예에 한정되지 않는다. 객체의 형태, 모양, 또는 색깔은 도시된 예에 제한되지 않으며, 실시 예에 따라, 객체에 따라 제1 입력을 검출하기 위한 지점은 달라질 수 있다. 예를 들면, 객체가 직각삼각형 의 모양인 경우, 제1 입력을 검출하기 위한 지점은, 객체의 적어도 하나의 꼭지점에 상응하는 지점일 수 있다. 프로세서는 지정된 영역 내에 포함된 제1 객체의 끝점에 대한 입력(이하 제2 입력)(예: click 2)을 검출할 수 있다. 다양한 실시 예들에서, 제2 입력은 제1 객체의 자세를 나타내기 위한 사용자의 입 력을 포함할 수 있다. 제2 입력은, 예를 들면, 객체의 끝점에 대한 사용자의 클릭, 더블 클릭, 롱 클릭, 또는 터치 입력 중 적어도 하나일 수 있다. 제2 입력은, 다른 예를 들면, 객체의 중심점으로부터 객체의 끝점까지 드 래그 하는 입력을 포함할 수 있다. 제2 입력은 객체의 자세를 나타내기 위한 지점(또는 포인트, 또는 특징점)과 관련된 다양한 입력을 포함할 수 있으며, 상술된 예에 한정되지 않는다. 객체의 형태, 모양, 또는 색깔은 도시 된 예에 제한되지 않으며, 실시 예에 따라, 객체의 외형에 따라 제2 입력을 검출하기 위한 지점이 변경될 수 있 다. 예를 들면, 제2 입력을 검출하기 위한 지점은, 객체가 나사못의 형태인 경우에 대응하여, 객체의 머리 부분 일 수 있다. 다양한 실시 예들에서, 프로세서는 지정된 영역 내에 포함된 복수의 객체들 중 적어도 2개의 객체들 의 중심점 또는 끝점에 대한 입력을 추가적으로 검출할 수 있다. 일부 실시 예들에서, 프로세서는, 제1 객 체의 중심점과 끝점에 대한 사용자의 입력들(예: click 1 및 click 2)을 검출한 후에, 제2 객체의 중심점과 끝점에 대한 사용자의 입력들(예: click 3 및 click 4) 검출할 수 있다. 다른 일부 실시 예들에서, 프 로세서는, 제1 객체의 중심점에 대한 사용자의 입력(예: click 1)과 제2 객체의 중심점에 대 한 사용자의 입력(예: click 3)을 검출한 후에, 제1 객체의 끝점에 대한 사용자의 입력(예: click 2)과 제2 객체의 끝점에 대한 사용자의 입력(예: click 4)을 검출할 수 있다. 프로세서는 제1 객체(110 1)에 대한 사용자의 입력들을 검출하는 동작에 상응하는 동작으로 제2 객체에 대한 사용자의 입력들을 검 출할 수 있다. 동작 1005에서, 프로세서는 제1 입력 및 제2 입력에 기반하여, 위치 정보 및 자세 정보를 획득할 수 있다. 프로세서는 제1 입력에 기반하여 객체에 대한 위치 정보를 획득할 수 있다. 위치 정보는 지정된 영역 내에서 객체의 위치를 나타내기 위한 정보를 포함할 수 있다. 일실시예에서, 프로세서는 제1 입력에 기반 하여 xy 평면 상에서 객체의 위치를 나타내기 위한 좌표값(예: x축의 값(또는 x 좌표 값) 및 y축의 값(또는 y 좌표 값))에 대한 정보를 획득할 수 있다. 프로세서는 제2 입력에 기반하여 객체에 대한 자세 정보를 획득 할 수 있다. 자세 정보는 지정된 영역 내에 위치된 객체의 자세를 나타내기 위한 정보를 포함할 수 있다. 일실시예에서, 프로세서는 제2 입력에 기반하여 객체의 자세를 나타내기 위한 요(yaw)에 대한 정보를 획득할 수 있다. 다양한 실시 예들에서, 프로세서는 위치 정보 또는 자세 정보를 시각적인 정보의 형태로 생성할 수 있다. 예를 들면, 프로세서는 맵(map)으로 나타나는 이미지 정보에 상응하도록 위치 정보 또는 자세 정보를 생성 할 수 있다. 다른 예를 들면, 프로세서는 맵(map)으로 나타나는 영상 정보에 상응하도록 위치 정보 또는 자세 정보를 생성할 수 있다. 위치 정보 또는 자세 정보와 관련된 설명은 도 11을 통해 후술하겠다. 동작 1007에서, 프로세서는 위치 정보 및 자세 정보에 대한 레이블 정보를 생성할 수 있다. 프로세서(22 0)는 획득된 위치 정보 및/또는 획득된 자세 정보에 기반하여 레이블 정보를 생성할 수 있다. 레이블 정보는 객 체의 위치 정보 및 객체의 자세 정보를 포함하는 데이터 베이스를 지칭할 수 있다. 도시하지는 않았으나, 프로세서는 생성된 레이블 정보를 메모리 내에 저장할 수 있다. 실시예들에 따 라, 프로세서는 메모리 내의 트레이닝 데이터 베이스 내에 레이블 정보를 저장할 수 있다. 레이블 정 보와 관련된 설명은 도 11을 통해 후술하겠다. 도 11을 참조하면, 프로세서는 제1 객체와 제2 객체에 대한 정보에 기반하여, 레이블 정보 를 생성할 수 있다. 레이블 정보는 제1 객체와 제2 객체에 대한 위치 정보 및/ 또는 제1 객체와 제2 객체에 대한 자세 정보를 포함할 수 있다. 위치 정보는, 지정된 영역에 상응하는 특정 영역 내에서 제1 객체 또는 제2 객체가 위 치된 지점을 나타내기 위한 정보를 포함할 수 있다. 위치 정보는 제1 객체 또는 제2 객체가 위치된 지점을 각각 나타내기 위한 원, 또는 가우시안(gaussian) 함수를 포함할 수 있다. 위치 정보는 도 시된 예에 제한되지 않으며, 객체의 위치를 나타내기 위한 다양한 정보로 구성될 수 있다. 예를 들면, 위치 정 보는, 제1 객체 또는 제2 객체가 xy 평면상에 놓여있음을 가정하는 것에 대응하여, 제1 객체 또는 제2 객체의 x축상에서의 좌표와 y축상에서의 좌표를 나타내기 위한 정보(예: 좌표값, 위치좌 표의 신뢰정도)를 포함할 수 있다. 자세 정보는, 지정된 영역에 상응하는 특정 영역 내에서 제1 객체 또는 제2 객체의 자 세를 나타내기 위한 정보를 포함할 수 있다. 예를 들면, 제1 객체와 관련된 자세 정보는 오른쪽에 서 왼쪽으로 제1 객체가 위치됨을 나타내기 위한 정보를 포함할 수 있다. 다른 예를 들면, 제2 객체 와 관련된 자세 정보는, 아래쪽에서 위쪽으로 제2 객체가 위치됨을 나타내기 위한 정보를 포 함할 수 있다. 자세 정보는 상술된 예에 제한되지 않으며, 객체가 놓여진 방향을 나타내기 위한 다양한 정보로 구성될 수 있다. 예를 들면, 자세 정보는, 제1 객체 또는 제2 객체가 지정된 영역 과 관련된 하나의 축으로부터 기울어진 각도를 나타내기 위한 정보(예: 각도값)를 포함할 수 있다. 다양한 실시 예들에서, 프로세서는 제1 입력 및 제2 입력에 기반하여 객체의 피킹을 위해 요구되는 최소한 의 정보를 획득할 수 있다. 최소한의 정보는, 예를 들면 6자유도에 대한 6개의 값들(예: x축의 값, y축의 값, z 축의 값, 요의 값, 롤의 값, 피치의 값) 중 x축의 값, y축의 값 및 요의 값을 포함할 수 있다. 실시 예들에 따 라, x축의 값과 y축의 값은 객체의 위치를 나타내기 위한 최소한의 정보일 수 있다. 요의 값은 객체의 자세를 나타내기 위한 최소한의 정보일 수 있다. 다양한 실시 예들에서, 프로세서는 최소한의 정보를 획득할 수 있다. 최소한의 정보를 획득하는 것 기반하 여, 프로세서와 관련된 불필요한 동작이 생략될 수 있다. 이를 통해, 효율적인 빈피킹 시스템의 구현이 가 능하다. 다양한 실시 예들에 따른 전자 장치의 방법은, 상기 적어도 하나의 센서를 이용하여 적어도 하나의 객체를 포함 하는 지정된 영역에 대한 데이터를 획득하는 동작, 인공 지능 알고리즘에 기반하여 획득된 적어도 하나의 객체 에 대한 데이터를 포함하는 트레이닝 데이터 베이스에 기반하여, 상기 적어도 하나의 객체의 위치에 대한 정보 및 자세에 대한 정보를 식별하는 동작, 및 상기 식별된 위치에 대한 정보 및 상기 자세에 대한 정보에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를 상기 전자 장치와 관련된 피킹툴에게 송신하 는 동작을 포함할 수 있다. 다양한 실시 예들에서, 상기 적어도 하나의 센서는, 상기 적어도 하나의 객체가 상기 지정된 영역 내에 포 함되는 지 여부, 상기 적어도 하나의 객체의 모양상기 적어도 하나의 객체의 위치, 상기 적어도 하나의 객체의 자세 중 적어도 하나를 측정하기 위한 센서를 포함할 수 있다. 다양한 실시 예들에서, 상기 지정된 영역에 대한 데이터는 상기 지정된 영역과 관련된 이미지를 나타내는 정보 를 포함할 수 있다. 다양한 실시 예들에서, 상기 적어도 하나의 객체의 위치에 대한 정보는, 상기 적어도 하나의 객체의 상기 지정 된 영역 상의 x축의 값, y축의 값 또는 z축의 값 중 적어도 하나를 포함하고, 및 상기 적어도 하나의 객체의 자 세에 대한 정보는, 상기 적어도 하나의 객체에 대한 요에 대한 정보, 롤에 대한 정보, 또는 피치에 대한 정보 중 적어도 하나를 포함할 수 있다. 다양한 실시 예들에서, 상기 적어도 하나의 객체의 위치에 대한 정보는, 상기 적어도 하나의 객체의 상기 지정 된 영역 상의 x축의 값 및 y축의 값을 포함하고, 및 상기 적어도 하나의 객체의 자세에 대한 정보는, 상기 적어 도 하나의 객체의 요에 대한 정보를 포함할 수 있다. 다양한 실시 예들에서, 전자 장치의 방법은, 상기 식별된 상기 적어도 하나의 객체의 위치에 대한 정보에 기반하여, 상기 위치에 대한 정보를 나타내는 위치맵(location map)을 생성하는 동작과, 및 상기 식별된 상기 적어도 하나의 객체의 자세에 대한 정보에 기반하여, 상기 위치에 대한 정보를 나타내는 자세맵(position map) 을 생성하는 동작을 더 포함할 수 있다. 일부 실시 예들에서, 전자 장치의 방법은, 인공 지능 알고리즘에 기반하여, 상기 위치맵및 상기 자세맵을 생성하는 동작을 더 포함할 수 있다. 다른 실시 예들에서, 전자 장치 의 방법은, 상기 생성된 위치맵 및 상기 생성된 자세맵에 기반하여, 상기 적어도 하나의 객체를 피킹하기 위한 제어 신호를 상기 전자 장치와 관련된 상기 피킹툴에게 송신하는 동작을 더 포함할 수 있다. 다양한 실시 예들에서, 전자 장치의 방법은, 상기 인공 지능 알고리즘에 기반하여 상기 지정된 영역에 대 한 데이터, 상기 적어도 하나의 객체의 위치에 대한 정보, 및 상기 자세에 대한 정보를 처리(process)하는 동작 과, 상기 처리에 기반하여 상기 트레이닝 데이터 베이스를 갱신하는 동작을 더 포함할 수 있다. 다양한 실시 예들에서, 상기 적어도 하나의 객체의 위치에 대한 정보, 상기 적어도 하나의 객체의 자세에 대한 정보, 및 상기 적어도 하나의 객체에 대한 영상 정보를 포함하고, 및 상기 영상 정보는 상기 적어도 하나의 객 체를 나타내는 가상 데이터 및 상기 인공 지능 알고리즘에 기반하여 생성된 정보를 포함할 수 있다. 다양한 실시 예들에 따른 비-일시적(non-transitory) 컴퓨터-판독 가능(computer-readable) 저장(storage) 매 체(medium)는, 적어도 하나의 센서를 이용하여 적어도 하나의 객체를 포함하는 지정된 영역에 대한 데이터 를 획득하는 동작과, 인공 지능 알고리즘에 기반하여 획득된 적어도 하나의 객체에 대한 데이터를 포함하는 트 레이닝 데이터 베이스에 기반하여, 상기 적어도 하나의 객체의 위치에 대한 정보 및 자세에 대한 정보를 식별하 는 동작과, 및 상기 식별된 위치에 대한 정보 및 상기 자세에 대한 정보에 기반하여, 상기 적어도 하나의 객체 를 피킹하기 위한 제어 신호를 상기 전자 장치와 관련된 피킹툴에게 송신하는 동작을 실행하기 위한 하나 이상의 프로그램들을 저장할 수 있다. 한편 본 개시의 상세한 설명에서는 구체적인 실시 예에 관해 설명하였으나, 본 개시의 범위에서 벗어나지 않는 한도 내에서 여러 가지 변형이 가능함은 물론이다. 그러므로 본 개시의 범위는 설명된 실시 예에 국한되어 정해 져서는 아니 되며 후술하는 특허청구의 범위뿐만 아니라 이 특허청구의 범위와 균등한 것들에 의해 정해져야 한 다."}
{"patent_id": "10-2017-0176878", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "그리고 본 명세서와 도면에 개시된 실시 예들은 본 발명의 내용을 쉽게 설명하고, 이해를 돕기 위해 특정 예를 제시한 것일 뿐이며, 본 발명의 범위를 한정하고자 하는 것은 아니다. 따라서 본 발명의 범위는 여기에 개시된 실시 예들 이외에도 본 발명의 기술적 사상을 바탕으로 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위 에 포함되는 것으로 해석되어야 한다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2017-0176878", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시 예들에 따른 전자 장치(electronic device)를 포함하는 환경의 예를 도시한다. 도 2는 다양한 실시 예들에 따른 전자 장치의 블록도이다. 도 3은 다양한 실시 예들에 따른 전자 장치의 동작의 예를 도시한다. 도 4는 다양한 실시 예들에 따라 지정된 영역(designated area)을 식별하는 전자 장치의 예를 도시한다. 도 5는 다양한 실시 예들에 따라 객체를 피킹(picking)하는 전자 장치의 예를 도시한다. 도 6은 다양한 실시 예들에 따라 트레이닝(training)(또는 학습)과 관련된 전자 장치의 동작의 다른 예를 도시 한다. 도 7은 다양한 실시 예들에 따라 획득된 위치맵(location map)과 자세맵(position map)의 예를 도시한다. 도 8은 다양한 실시 예들에 따라 트레이닝 데이터의 획득을 위한 전자 장치의 동작의 예를 도시한다. 도 9는 다양한 실시 예들에 따라 트레이닝 데이터와 관련된 정보의 예를 도시한다. 도 10은 다양한 실시 예들에 따라 레이블(label) 정보를 생성하기 위한 전자 장치의 동작의 예를 도시한다. 도 11은 다양한 실시 예들에 따른 레이블 정보의 예를 도시한다."}
