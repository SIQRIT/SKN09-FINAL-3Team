{"patent_id": "10-2022-0052705", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0002041", "출원번호": "10-2022-0052705", "발명의 명칭": "이미지 처리를 위한 인공 신경망 모델 학습 방법 및 시스템", "출원인": "주식회사 에너자이", "발명자": "장한힘"}}
{"patent_id": "10-2022-0052705", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 이미지 처리를 위한 인공 신경망을 학습시키는 방법에 있어서,제1 이미지 및 제2 이미지를 포함하는 트레이닝 데이터 세트를 획득하는 a 단계;상기 제2 이미지를 제1 인공 신경망 모델에 입력하여 제3 이미지를 획득하고, 상기 제2 이미지를 제2 인공 신경망 모델에 입력하여 제4 이미지를 획득하는 b 단계; 및상기 제1 인공 신경망 모델 및 상기 제2 인공 신경망 모델을 학습시키는 c 단계;를 포함하되,상기 c 단계는,상기 제1 이미지와 상기 제3 이미지를 비교하여 제1 로스 값을 연산하는 단계;상기 제1 이미지와 상기 제4 이미지를 비교하여 제2 로스 값을 연산하는 단계;상기 제1 인공 신경망 모델 및 상기 제2 인공 신경망 모델에 포함된 제1 모듈의 컨볼루션 레이어의 출력 값 각각을 비교해 제3 로스 값을 연산하는 단계;상기 제3 이미지와 상기 제4 이미지를 비교하여 제4 로스 값을 연산하는 단계;상기 제1 내지 제4 로스 값을 이용하여 최종 로스 값인 제5 로스 값을 연산하는 단계; 및상기 제5 로스 값을 기반으로 상기 제1 인공 신경망 모델 및 상기 제2 인공 신경망 모델을 학습시키는 단계;를더 포함하는,이미지 처리를 위한 인공 신경망 학습 방법."}
{"patent_id": "10-2022-0052705", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 a 단계는,데이터베이스에 저장된 이미지를 이용하여 기 설정된 크기의 제1 이미지를 생성하는 단계; 및제1 이미지에 임의의 노이즈를 추가하여 제2 이미지를 생성하는 단계를 더 포함하는,이미지 처리를 위한 인공 신경망 학습 방법."}
{"patent_id": "10-2022-0052705", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,제1 인공 신경망 모델 및 제2 인공 신경망 모델은 각각 제1 모듈, 제2 모듈, 제3 모듈을 포함하며, 제1 모듈은컨볼루션 레이어 및 활성화 함수를 포함하는 적어도 하나의 블록 및 다운샘플 모듈을 포함하고,제3 모듈은 컨볼루션 레이어 및 활성화 함수를 포함하는 적어도 하나의 블록 및 업샘플 모듈을 포함하되,제1 인공 신경망 모델과 제2 인공 신경망 모델은 제1 모듈 및 제3 모듈의 크기가 상이한 것을 특징으로 하는, 이미지 처리를 위한 인공 신경망 학습 방법.공개특허 10-2023-0002041-3-청구항 4 제3 항에 있어서, 상기 b 단계는,제1 인공 신경망 모델에 제2 이미지를 입력하여 제1 노이즈를 추출하고, 제2 이미지에서 제1 노이즈를 제거하여제3 이미지를 생성하는 단계; 및제2 인공 신경망 모델에 제2 이미지를 입력하여 제2 노이즈를 추출하고, 제2 이미지에서 제2 노이즈를 제거하여제4 이미지를 생성하는 단계를 더 포함하는, 이미지 처리를 위한 인공 신경망 학습 방법."}
{"patent_id": "10-2022-0052705", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,제1 로스 값 내지 제4 로스 값 각각에 가중치를 부여하여 제5 로스 값을 연산하고, 제1 인공 신경망 모델 및 제2 인공 신경망 모델을 학습시키는, 이미지 처리를 위한 인공 신경망 학습 방법."}
{"patent_id": "10-2022-0052705", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 방법은, 상기 제5 로스 값이 기 설정된 로스 임계 값 이하이면 상기 제2 인공 신경망 모델을 사용자 단말에 전송하는 d단계를 더 포함하는,이미지 처리를 위한 인공 신경망 학습 방법."}
{"patent_id": "10-2022-0052705", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 이미지 및 제2 이미지를 포함하는 트레이닝 데이터 세트를 획득하고, 상기 제2 이미지를 제1 인공 신경망모델에 입력하여 제3 이미지를 획득하고, 상기 제2 이미지를 제2 인공 신경망 모델에 입력하여 제4 이미지를 획득하고, 상기 제1 인공 신경망 모델 및 상기 제2 인공 신경망 모델을 학습시키도록 구성된 제어 모듈을 포함하되, 상기 제어 모듈은,상기 제1 이미지와 상기 제3 이미지를 비교하여 제1 로스 값을 연산하고, 상기 제1 이미지와 상기 제4 이미지를비교하여 제2 로스 값을 연산하고, 상기 제1 인공 신경망 모델 및 상기 제2 인공 신경망 모델에 포함된 제1 모듈의 컨볼루션 레이어의 출력 값 각각을 비교해 제3 로스 값을 연산하고, 상기 제3 이미지와 상기 제4 이미지를비교하여 제4 로스 값을 연산하고, 상기 제1 내지 제4 로스 값을 이용하여 최종 로스 값인 제5 로스 값을 연산하고, 상기 제5 로스 값을 기반으로 상기 제1 인공 신경망 모델 및 상기 제2 인공 신경망 모델을 학습시키도록구성되는, 전자 장치."}
{"patent_id": "10-2022-0052705", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 이미지 처리를 위한 인공 신경망 모델 학습 방법 및 시스템에 관한 것으로, 경량화 된 인공 신경망 모 델을 제공하여 저용량 단말에서도 이미지 처리를 충분히 수행할 수 있게 하는 것을 일 목적으로 한다. 이러한 목 적을 달성하기 위한 본 발명은 제1 이미지 및 제2 이미지를 포함하는 트레이닝 데이터 세트를 생성하는 a 단계, 제2 이미지를 제1 인공 신경망 모델 및 제2 인공 신경망 모델에 입력하여 제3 이미지 및 제4 이미지를 각각 추출 하는 b 단계, 상기 b 단계가 수행되는 동안, 제1 인공 신경망 모델 및 제2 인공 신경망 모델에 포함된 적어도 하 나의 레이어의 출력 값을 기반으로 복수 개의 로스 값을 생성하여, 상기 로스 값을 기반으로 제1 인공 신경망 모 델 및 제2 인공 신경망 모델을 학습시키는 c 단계 및 제2 인공 신경망 모델을 사용자 단말에 전송하는 c 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0052705", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지 처리를 위한 인공 신경망 모델 학습 방법 및 시스템에 관한 것으로, 보다 자세하게는 높은 사 양의 서버를 거치지 않고 단말에서 적용 가능하게 경량화 된 인공 신경망 모델을 학습시키는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2022-0052705", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술이 발전함에 따라 이미지의 처리에 인공 신경망 모델을 적용하는 방법이 상용화되고 있다. 그러나 이미지 처리 기능을 수행하는 인공 신경망 모델은 일반적으로 사이즈가 클수록 성능이 우수하기 때문에 높은 사양의 컴퓨팅 리소스를 요구한다. 따라서 우수한 성능의 인공 신경망 모델은 널리 사용되는 단말에서 실 행될 수 없는 단점이 있다."}
{"patent_id": "10-2022-0052705", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위한 것으로서, 단말에서 동작하는 우수한 성능의 경량화 된 인공 신경망 모델을 생성 및 학습시키는 것을 일 목적으로 한다. 또한 본 발명은 인공 신경망 모델을 경량화하기 위하여 구조를 단순화하고, 대형 인공 신경망 모델을 모방 학습 시키는 과정을 제공하는 것을 일 목적으로 한다."}
{"patent_id": "10-2022-0052705", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이러한 목적을 달성하기 위한 본 발명은 전자 장치가 이미지 처리를 위한 인공 신경망을 학습시키는 방법에 있 어서, 제1 이미지 및 제2 이미지를 포함하는 트레이닝 데이터 세트를 생성하는 a 단계, 제2 이미지를 제1 인공 신경망 모델 및 제2 인공 신경망 모델에 입력하여 제3 이미지 및 제4 이미지를 각각 추출하는 b 단계, 상기 b 단계가 수행되는 동안, 제1 인공 신경망 모델 및 제2 인공 신경망 모델에 포함된 적어도 하나의 레이어의 출력 값을 기반으로 복수 개의 로스 값을 생성하여, 상기 로스 값을 기반으로 제1 인공 신경망 모델 및 제2 인공 신 경망 모델을 학습시키는 c 단계 및 제2 인공 신경망 모델을 사용자 단말에 전송하는 c 단계를 포함하는 것을 일 특징으로 한다. 또한 본 발명은 제1 이미지 및 제2 이미지를 포함하는 트레이닝 데이터 세트를 생성하고, 제2 이미지를 제1 인 공 신경망 모델 및 제2 인공 신경망 모델에 입력하여 제3 이미지 및 제4 이미지를 각각 추출하며, 제3 이미지 및 제4 이미지를 추출하는 과정에서 제1 인공 신경망 모델 및 제2 인공 신경망 모델에 포함된 적어도 하나의 레 이어의 출력 값을 기반으로 복수 개의 로스 값을 생성하여, 상기 로스 값을 기반으로 제1 인공 신경망 모델 및 제2 인공 신경망 모델을 학습시키는 제어 모듈, 그리고 제2 인공 신경망 모델을 사용자 단말에 전송하는 통신 모듈을 포함하는 전자 장치 및 상기 전자 장치로부터 제2 인공 신경망 모델을 수신하여 사용자로부터 수신한 이 미지를 처리하는 사용자 단말을 포함하는 것을 일 특징으로 한다."}
{"patent_id": "10-2022-0052705", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 바와 같은 본 발명에 의하면, 단말에서 동작하는 우수한 성능의 경량화 된 인공 신경망 모델을 생성 및 학습시킬 수 있는 효과가 있다. 또한 본 발명은 인공 신경망 모델을 경량화하기 위하여 구조를 단순화하고, 대형 인공 신경망 모델을 모방 학습 시키는 과정을 통해 경량화 된 인공 신경망 모델의 성능을 서버에서 동작하는 대형 인공 신경망 모델의 수준으 로 보장할 수 있는 효과가 있다."}
{"patent_id": "10-2022-0052705", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한 목적, 특징 및 장점은 첨부된 도면을 참조하여 상세하게 후술되며, 이에 따라 본 발명이 속하는 기술 분 야에서 통상의 지식을 가진 자가 본 발명의 기술적 사상을 용이하게 실시할 수 있을 것이다. 본 발명을 설명함 에 있어서 본 발명과 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 상세한 설명을 생략한다. 도면에서 동일한 참조부호는 동일 또는 유사한 구성요소를 가리키는 것으로 사용되며, 명세서 및 특허청구의 범 위에 기재된 모든 조합은 임의의 방식으로 조합될 수 있다. 그리고 다른 식으로 규정하지 않는 한, 단수에 대한 언급은 하나 이상을 포함할 수 있고, 단수 표현에 대한 언급은 또한 복수 표현을 포함할 수 있음이 이해되어야 한다. 본 명세서에서 사용되는 용어는 단지 특정 예시적 실시 예들을 설명할 목적을 가지고 있으며 한정할 의도로 사 용되는 것이 아니다. 본 명세서에서 사용된 바와 같은 단수적 표현들은 또한, 해당 문장에서 명확하게 달리 표 시하지 않는 한, 복수의 의미를 포함하도록 의도될 수 있다. 용어 \"및/또는,\" \"그리고/또는\"은 그 관련되어 나 열되는 항목들의 모든 조합들 및 어느 하나를 포함한다. 용어 \"포함한다\", \"포함하는\", \"포함하고 있는\", \"구비 하는\", \"갖는\", \"가지고 있는\" 등은 내포적 의미를 갖는 바, 이에 따라 이러한 용어들은 그 기재된 특징, 정수, 단계, 동작, 요소, 및/또는 컴포넌트를 특정하며, 하나 이상의 다른 특징, 정수, 단계, 동작, 요소, 컴포넌트, 및/또는 이들의 그룹의 존재 혹은 추가를 배제하지 않는다. 본 명세서에서 설명되는 방법의 단계들, 프로세스들, 동작들은, 구체적으로 그 수행 순서가 확정되는 경우가 아니라면, 이들의 수행을 논의된 혹은 예시 된 그러한 특정 순서로 반드시 해야 하는 것으로 해석돼서는 안 된다. 추가적인 혹은 대안적인 단계들이 사용될 수 있음을 또한 이해해야 한다. 또한, 각각의 구성요소는 각각 하드웨어 프로세서로 구현될 수 있고, 위 구성요소들이 통합되어 하나의 하드웨 어 프로세서로 구현될 수 있으며, 또는 위 구성요소들이 서로 조합되어 복수 개의 하드웨어 프로세서로 구현될 수도 있다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시 예를 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시 예에 의한 이미지 처리를 위한 인공 신경망 모델을 학습시키기 위한 시스템의 블록도 를 나타낸 도면이다. 도 1을 참조하면, 본 발명의 인공 신경망 모델을 학습시키기 위한 시스템은 경량화 된 인공 신경망 모델을 학습 시키기 위한 전자 장치와 경량화 된 인공 신경망 모델을 동작하기 위한 사용자 단말을 포함한다. 전자 장치는 경량화 된 인공 신경망 모델을 학습시키기 위한 장치로, 제어 모듈, 통신 모듈, 저장 모듈을 포함할 수 있다. 전자 장치는 대용량 인공 신경망 모델인 제1 인공 신경망 모델, 경량화 된 인공 신경망 모델인 제2 인공 신 경망 모델을 구비하여, 딥러닝 모델의 지식 증류기법(Knowledge Distillation)을 통해 제2 인공 신경망 모델을 학습시켜 사용자 단말에 제공하는 것을 특징으로 한다. 이하에서는 설명의 편의성을 위해 제1 인공 신경망 모델 및 제2 인공 신경망 모델이 노이즈 제거(image de- noising)를 목적으로 동작하는 것을 대표 실시 예로 하여 설명하며, 이 외 모자이크 제거(de-mosaics), 초해상 화(super-resolution) 등과 같은 다양한 이미지 처리 기법에 적용 가능하다. 제어 모듈은 쿼리 이미지에서 노이즈를 식별하고, 이를 제거할 수 있도록 제1 인공 신경망 모델과 제2 인공 신경망 모델을 학습시킬 수 있다. 제어 모듈은 제1 인공 신경망 모델과 제2 인공 신경망 모델을 학습시키기 위해 트레이닝 데이터 세트를 활 용할 수 있다. 본 발명의 일 실시 예에 의한 트레이닝 데이터 세트는 노이즈가 존재하는 제1 쿼리 이미지와 제1 쿼리 이미지와 동일하나 노이즈가 존재하지 않는 제2 쿼리 이미지를 포함하여, 제어 모듈은 제1 인공 신경 망 모델 및 제2 인공 신경망 모델이 노이즈를 정확하게 식별할 수 있도록 제1 쿼리 이미지와 제2 쿼리 이미지를 이용하여 학습시킬 수 있다.제어 모듈은 제1 인공 신경망 모델과 제2 인공 신경망 모델이 일정 수준 이상의 정확도를 갖는다고 판단하 면, 제2 인공 신경망 모델이 경량화 된 인공 신경망 모델이라고 할 지라도 제1 인공 신경망 모델 대비 성능이 유사하다고 보아, 제2 인공 신경망 모델만으로도 쿼리 이미지의 노이즈를 충분히 제거할 수 있다고 판단하여, 제2 인공 신경망 모델을 사용자 단말에 전송하여 쿼리 이미지의 노이즈 제거를 제공하게 할 수 있다. 통신 모듈은 제2 인공 신경망 모델을 사용자 단말에 전송할 수 있다. 저장 모듈은 제1 인공 신경망 모델 및 제2 인공 신경망 모델을 학습시키기 위한 복수 개의 이미지가 저장된 이미지 데이터베이스와, 제1 인공 신경망 모델 및 제2 인공 신경망 모델을 저장하는 모델 데이터베이스를 포함 할 수 있다. 사용자 단말은 전자 장치로부터 수신한 제2 인공 신경망 모델을 이용하여 사용자로부터 수신된 쿼리 이 미지에서 노이즈를 제거할 수 있으며, 구체적으로 제어 모듈, 통신 모듈, 저장 모듈을 포함할 수 있다. 제어 모듈은 전자 장치로부터 수신한 제2 인공 신경망 모델을 이용하여 사용자로부터 수신한 쿼리 이미 지에서 노이즈를 제거할 수 있다. 통신 모듈은 사용자로부터 쿼리 이미지를 수신하고, 전자 장치로부터 제2 인공 신경망 모델을 수신할 수 있다. 저장 모듈은 제2 인공 신경망 모델을 저장할 수 있다. 도 2는 본 발명의 일 실시 예에 따른 노이즈 제거를 위한 인공 신경망 모델의 구조를 설명하기 위한 도면이다. 도 2에 도시된 제1 인공 신경망 모델 및 제2 인공 신경망 모델은 트레이닝 데이터 세트를 기반으로 학 습될 수 있다. 도 2에 도시된 제1 인공 신경망 모델 및 제2 인공 신경망 모델은 도 1에 도시된 저장 모 듈에 저장될 수 있고, 제어 모듈에 의해 실행될 수 있다. 먼저, 제어 모듈은 제1 인공 신경망 모델 및 제2 인공 신경망 모델를 학습시키기 위해 트레이닝 데 이터 세트를 생성할 수 있다. 제어 모듈은 저장 모듈의 이미지 데이터베이스에 저장된 이미지를 이용하 여 트레이닝 데이터 세트를 생성할 수 있다. 구체적으로, 제어 모듈은 이미지 데이터베이스에 저장된 이미지를 이용하여 기 설정된 크기의 제1 이미지 및 제2 이미지를 생성할 수 있다. 제어 모듈은 이미지 데이터베이스에 저장된 이미지에서 기 설정된 크기를 갖는 패치 단위의 제1 이미지를 생성하고, 제1 이미지에 임의로 노이즈를 생성하여 제2 이미지를 생성할 수 있다. 제어 모듈은 가우시안 노이즈 생성 알고리즘과 같은 노이즈 생성 알고리즘을 활용하여 제1 이미지에 대한 다양한 노이즈를 생성하고 제1 이미지에 더하여 제2 이미지를 생성할 수 있다. 제어 모듈은 제1 이미지 및 제2 이미지를 기반으로 제1 인공 신경망 모델 및 제2 인공 신경망 모델(4 0)를 학습시킬 수 있다. 제1 인공 신경망 모델 및 제2 인공 신경망 모델은 유넷(U-Net) 구조로 형성되 어 있음에 따라 적어도 하나의 다운 샘플링 레이어(down-sampling layer)와 업 샘플링 레이어(up-sampling layer) 로 구성될 수 있다. 본 발명의 일 실시 예에 의한 제1 인공 신경망 모델 및 제2 인공 신경망 모델은 유넷 구조를 통해 이미 지의 미시적 및 거시적 특징을 모두 사용 가능한 것을 특징으로 한다. 제1 인공 신경망 모델와 제2 인공 신경망 모델은 제1 모듈(down-path), 제2 모듈(middle-path), 제3 모듈(up-path)를 각각 포함할 수 있다. 제1 모듈은 컨볼루션 레이어와 활성화 함수(PReLU layer 혹은 ReLU layer)를 포함하는 블록과, 이미지의 크기를 축소시키는 다운샘플 모듈을 포함하고, 제2 모듈은 dense block을, 제3 모듈은 제1 모듈에서 축소된 이미지의 크기를 다시 확대시키는 업샘플 모듈과, 컨볼루션 레이어와 활성화 함수를 포함하는 블록을 포함할 수 있다. 제1 인공 신경망 모델와 제2 인공 신경망 모델은 제1 모듈과 제3 모듈의 크기에 차이를 두고 있으며, 제1 모듈과 제3 모듈의 크기가 제1 인공 신경망 모델보다 작은 제2 인공 신경망 모델은 지식 증류기법 을 통해 제1 인공 신경망 모델를 모방하여 학습될 수 있다.제1 인공 신경망 모델와 제2 인공 신경망 모델의 제1 모듈(31, 41) 및 제3 모듈(36, 46)은 컨볼루션 레 이어와 활성화 함수를 포함하는 블록을 복수 개 구비할 수 있다. 본 발명의 일 실시 예에 의한 제1 모듈(31, 41)은 블록을 3개 구비할 것이다. 제1 인공 신경망 모델의 제1 모듈 및 제3 모듈과 제2 인공 신경 망 모델의 제1 모듈 및 제3 모듈은 컨볼루션 레이어의 파라미터(parameter)에 차이를 두어 그 두께 를 달리 할 수 있다. 이를 통해 제2 인공 신경망 모델은 제1 인공 신경망 모델를 경량화 할 수 있다. 상술한 바와 같이 본 발명의 일 실시 예에서, 제1 모듈(31, 41) 및 제3 모듈(36, 46)은 3개의 블록을 포함함에 따라, 제1 인공 신경망 모델의 제1 모듈은 제1 블록, 제2 블록, 제3 블록를 포함하고, 제3 모듈은 제4 블록, 제5 블록, 제6 블록를 포함할 것이며, 제2 인공 신경망 모델의 제1 모듈 은 제1 블록, 제2 블록, 제3 블록를 포함하고, 제3 모듈은 제4 블록, 제5 블록, 제6 블록을 포함할 것이다. 제2 모듈(35, 45)은 dense block을 포함할 수 있다. Dense block은 제1 모듈(31, 41)에 포함된 모든 컨볼루션 레이어의 출력 값을 순차적으로 합칠 수 있다. 예를 들어, 제1 모듈에 포함된 제1 블록의 컨볼루션 레 이어의 출력 값이 A, 제2 블록의 컨볼루션 레이어의 출력 값이 B, 제3 블록의 컨볼루션 레이어의 출력 값이 C일 때, 제2 모듈의 dense block은 A와 B와 C를 순차적으로 합쳐 ABC를 출력할 수 있다. 제2 모듈(35, 45)은 dense block을 사용함으로써 각 단계의 모든 출력 값(예를 들어 피쳐 맵)을 제1 인공 신경 망 모델 및 제2 인공 신경망 모델의 학습에 반영할 수 있어 제1 인공 신경망 모델 및 제2 인공 신경망 모델의 성능을 더 향상시킬 수 있다. 이하에서는 제어 모듈에 의해 제1 인공 신경망 모델와 제2 인공 신경망 모델가 학습되는 과정을 설 명한다. 제어 모듈은 제1 인공 신경망 모델에 제2 이미지를 입력 데이터로 하여 제2 이미지의 제1 노이즈를 추 출한 후, 제1 노이즈가 제거된 제3 이미지를 출력할 수 있다. 제어 모듈은 제1 인공 신경망 모델에 제2 이미지가 입력되면, 제1 인공 신경망 모델의 제1 모듈 에 포함된 제1 블록의 컨볼루션 레이어의 출력 값을 제1 피쳐-1로, 제2 블록의 컨볼루션 레이어의 출력 값을 제2 피쳐-1로, 제3 블록의 컨볼루션 레이어의 출력 값을 제3 피쳐-1로 설정할 수 있다. 또한 제 어 모듈은 제1 인공 신경망 모델의 제3 모듈에 포함된 제4 블록의 컨볼루션 레이어의 출력 값 을 제4 피쳐-1로, 제5 블록의 컨볼루션 레이어의 출력 값을 제5 피쳐-1로, 제6 블록의 컨볼루션 레이어 의 출력 값을 제6 피쳐-1로 설정할 수 있다. 제어 모듈은 제1 인공 신경망 모델에서 제3 이미지를 추출하면, 제1 이미지와 비교하여 제1 로스 값을 연산할 수 있다. 제어 모듈은 제2 인공 신경망 모델에 제2 이미지를 입력 데이터로 하여 제2 이미지의 제2 노이즈를 추 출한 후, 제2 노이즈가 제거된 제4 이미지를 출력할 수 있다. 제어 모듈은 제2 인공 신경망 모델에 제2 이미지가 입력되면, 제2 인공 신경망 모델의 제1 모듈 에 포함된 제1 블록의 컨볼루션 레이어의 출력 값을 제1 피쳐-2로, 제2 블록의 컨볼루션 레이어의 출력 값을 제2 피쳐-2로, 제3 블록의 컨볼루션 레이어의 출력 값을 제3 피쳐-2로 설정할 수 있다. 또한 제 어 모듈은 제1 인공 신경망 모델의 제3 모듈에 포함된 제4 블록의 컨볼루션 레이어의 출력 값 을 제4 피쳐-2로, 제5 블록의 컨볼루션 레이어의 출력 값을 제5 피쳐-2로, 제6 블록의 컨볼루션 레이어 의 출력 값을 제6 피쳐-2로 설정할 수 있다. 제어 모듈은 제2 인공 신경망 모델에서 제4 이미지를 추출하면, 제1 이미지와 비교하여 제2 로스 값을 연산할 수 있다. 또한 제어 모듈은 제1 인공 신경망 모델와 제2 인공 신경망 모델에서 각각 추출한 제1 내지 제6 피 쳐를 이용하여 제3 로스 값을 더 연산할 수 있다. 구체적으로, 제어 모듈은 제1 피쳐-1과 제1 피쳐-2를 비 교하여 제3 로스 값-1을, 제2 피쳐-1과 제2 피쳐-2를 비교하여 제3 로스 값-2을, ..., 제6 피쳐-1과 제6 피쳐-2 를 비교하여 제3 로스 값-6을 연산할 수 있다. 제3 로스 값의 수는 제1 인공 신경망 모델 및 제2 인공 신경 망 모델에 포함된 제1 모듈(31, 41)의 블록 수에 따를 것이다. 제어 모듈은 제3 이미지 및 제4 이미지를 비교하여 제4 로스 값을 더 연산할 수 있다. 제어 모듈은 제1 로스 값 내지 제4 로스 값을 이용하여 제1 인공 신경망 모델 및 제2 인공 신경망 모델을 학습시킬 수 있다. 제어 모듈은 제1 로스 값 내지 제4 로스 값 각각에 가중치를 부여하여 제5 로스 값을 연 산할 수 있다. 제어 모듈은 제5 로스 값을 연산함에 있어서 제1 모듈(31, 41) 및 제3 모듈(36, 46)에 포함된 복수 개의 컨 볼루션 레이어 각각의 출력 값에 대한 로스 값 즉, 제3 로스 값을 더 이용함으로써, 제2 인공 신경망 모델 가 제1 인공 신경망 모델를 단계별로 보다 잘 모방할 수 있게 한다. 도 3은 본 발명의 일 실시 예에 의한 이미지 처리를 위한 인공 신경망 모델을 학습시키는 방법을 설명하기 위한 순서도이다. 이하에서는 도 3을 참조하여 이미지 처리를 위한 인공 신경망 모델을 학습시키는 방법을 설명한다. 이미지 처리를 위한 인공 신경망 모델을 학습시키는 방법에 대한 설명에 있어서, 앞서 설명한 이미지 처리를 위 한 인공 신경망 모델을 학습시키기 위한 시스템과 중복되는 세부 실시 예는 생략될 수 있다. 단계 100에서, 전자 장치는 트레이닝 데이터 세트를 생성할 수 있다. 전자 장치는 제1 인공 신경망 모델 및 제2 인공 신경망 모델을 학습시키기 위하여 이미지 데이터베이스에 저장된 이미지를 이용하여 트레이닝 데이터 세트 를 생성할 수 있다. 구체적으로 전자 장치는 이미지 데이터베이스에 저장된 이미지를 이용하여 기 설정된 크기의 제1 이미지 및 제2 이미지를 생성할 수 있다. 전자 장치는 이미지 데이터베이스에 저장된 이미지에서 기 설정된 크기를 갖는 패치 단위의 제1 이미지를 생성 하고, 제1 이미지에 임의로 노이즈를 추가하여 제2 이미지를 생성할 수 있다. 전자 장치는 가우시안 노이즈 생성 알고리즘과 같은 노이즈 생성 알고리즘을 활용하여 제1 이미지에 대한 다양 한 노이즈를 생성하고 제1 이미지에 더하여 제2 이미지를 생성할 수 있다. 단계 200에서, 전자 장치는 제1 이미지 및 제2 이미지를 포함하는 트레이닝 데이터 세트를 기반으로 제1 인공 신경망 모델 및 제2 인공 신경망 모델을 학습시킬 수 있다. 본 발명의 제1 인공 신경망 모델 및 제2 인공 신경 망 모델은 유넷(u-net) 구조로 형성되어 있음에 따라 적어도 하나의 풀링 레이어(pooling layer)와 언풀링 레이 어(unpooling layer)로 구성될 수 있다. 제1 인공 신경망 모델와 제2 인공 신경망 모델은 제1 모듈(down-path), 제2 모듈(middle-path), 제3 모듈(up-path)를 각각 포함할 수 있다. 제1 모듈은 컨볼루션 레이어와 활성화 함수를 포함하는 블록과, 이미지 의 크기를 축소시키는 다운샘플 모듈을 포함하고, 제2 모듈은 dense block을, 제3 모듈은 제1 모듈에서 축소된 이미지의 크기를 다시 확대시키는 업샘플 모듈과, 컨볼루션 레이어와 활성화 함수를 포함하는 블록을 포함할 수 있다. 제1 인공 신경망 모델와 제2 인공 신경망 모델의 제1 모듈(31, 41) 및 제3 모듈(36, 46)은 컨볼루션 레 이어와 활성화 함수를 포함하는 블록을 복수 개 구비할 수 있다. 본 발명의 일 실시 예에 의한 제1 모듈(31, 41)은 블록을 3개 구비할 것이다. 제1 인공 신경망 모델의 제1 모듈 및 제3 모듈과 제2 인공 신경 망 모델의 제1 모듈 및 제3 모듈은 컨볼루션 레이어의 파라미터(parameter)에 차이를 두어 그 두께 를 달리 할 수 있다. 즉, 제1 인공 신경망 모델와 제2 인공 신경망 모델은 제1 모듈과 제3 모듈의 크기 에 차이를 두고 있으며, 제1 모듈과 제3 모듈의 크기가 제1 인공 신경망 모델보다 작은 제2 인공 신경망 모 델은 지식 증류기법을 통해 제1 인공 신경망 모델를 모방하여 학습될 수 있다. 도 4는 본 발명의 일 실시 예에 의한 제1 인공 신경망 모델 및 제2 인공 신경망 모델의 학습 방법을 구체적으로 설명하기 위한 도면이다. 도 4를 참조하면, 단계 210에서, 전자 장치는 제1 인공 신경망 모델에 제2 이미지를 입력 데이터로 하여, 제2 이미지에 대한 제1 노이즈를 추출할 수 있다. 단계 210의 과정을 수행함에 있어서, 전자 장치는 제1 인공 신경 망 모델의 제1 모듈에 포함된 제1 블록의 컨볼루션 레이어의 출력 값을 제1 피쳐-1로, 제2 블록 의 컨볼루션 레이어의 출력 값을 제2 피쳐-1로, 제3 블록의 컨볼루션 레이어의 출력 값을 제3 피쳐-1로 설정할 수 있다. 또한 제어 모듈은 제1 인공 신경망 모델의 제3 모듈에 포함된 제4 블록의 컨 볼루션 레이어의 출력 값을 제4 피쳐-1로, 제5 블록의 컨볼루션 레이어의 출력 값을 제5 피쳐-1로, 제6 블 록의 컨볼루션 레이어의 출력 값을 제6 피쳐-1로 설정할 수 있다.단계 220에서, 전자 장치는 제2 이미지에서 제1 노이즈를 제거한 제3 이미지를 출력할 수 있다. 단계 230에서, 전자 장치는 제1 이미지와 제3 이미지를 비교하여 제1 로스 값을 연산할 수 있다. 단계 240에서, 전자 장치는 제2 인공 신경망 모델에 제2 이미지를 입력 데이터로 하여, 제2 이미지에 대한 제2 노이즈를 추출할 수 있다. 단계 240의 과정을 수행함에 있어서, 전자 장치는 제2 인공 신경망 모델의 제1 모듈에 포함된 제1 블록의 컨볼루션 레이어의 출력 값을 제1 피쳐-2로, 제2 블록의 컨볼루션 레이 어의 출력 값을 제2 피쳐-2로, 제3 블록의 컨볼루션 레이어의 출력 값을 제3 피쳐-2로 설정할 수 있다. 또 한 제어 모듈은 제1 인공 신경망 모델의 제3 모듈에 포함된 제4 블록의 컨볼루션 레이어의 출 력 값을 제4 피쳐-2로, 제5 블록의 컨볼루션 레이어의 출력 값을 제5 피쳐-2로, 제6 블록의 컨볼루션 레이어의 출력 값을 제6 피쳐-2로 설정할 수 있다. 단계 250에서, 전자 장치는 제2 이미지에서 제2 노이즈를 제거한 제4 이미지를 출력할 수 있다. 단계 260에서, 전자 장치는 제1 이미지와 제4 이미지를 비교하여 제2 로스 값을 연산할 수 있다. 단계 210 내지 230과 단계 240 내지 260은 동시에 동작할 수도 있고 순차적으로 동작할 수도 있다. 단계 270에서, 전자 장치는 단계 210 및 단계 240에서 각각 추출한 제1 내지 제6 피쳐를 이용하여 제3 로스 값 을 연산할 수 있다. 구체적으로, 전자 장치는 제1 피쳐-1과 제1 피쳐-2를 비교하여 제3 로스 값-1을, 제2 피쳐- 1과 제2 피쳐-2를 비교하여 제3 로스 값-2을, ..., 제6 피쳐-1과 제6 피쳐-2를 비교하여 제3 로스 값-6을 연산 할 수 있다. 단계 280에서, 전자 장치는 제3 이미지 및 제4 이미지를 비교하여 제4 로스 값을 더 연산할 수 있다. 단계 290에서, 전자 장치는 제1 로스 값 내지 제4 로스 값을 이용하여 제1 인공 신경망 모델 및 제2 인공 신경 망 모델을 학습시킬 수 있다. 전자 장치는 제1 로스 값 내지 제4 로스 값 각각에 가중치를 부여하여 제5 로스 값을 연산할 수 있다. 전자 장치는 제5 로스 값을 연산함에 있어서 제1 모듈(31, 41) 및 제3 모듈(36, 46)에 포함된 복수 개의 컨볼루 션 레이어 각각의 출력 값에 대 한 로스 값 즉, 제3 로스 값을 더 이용함으로써, 제2 인공 신경망 모델가 제1 인공 신경망 모델를 보다 잘 모방할 수 있게 한다. 다시 도 3에 대한 설명으로 복귀하면, 단계 300에서, 전자 장치는 제1 인공 신경망 모델과 제2 인공 신경망 모 델에서 출력된 최종 로스 값(제5 로스 값)이 기 설정된 로스 임계 값 이하이면, 제2 인공 신경망 모델을 사용자 단말에 전송할 수 있다. 사용자 단말은 전자 장치로부터 제2 인공 신경망 모델을 수신하면, 경량화 된 제2 인공 신경망 모델을 통해 사 용자에게 노이즈 제거 서비스를 제공할 수 있다. 본 명세서와 도면에 개시된 본 발명의 실시 예들은 본 발명의 기술 내용을 쉽게 설명하고 본 발명의 이해를 돕 기 위해 특정 예를 제시한 것뿐이며, 본 발명의 범위를 한정하고자 하는 것은 아니다. 여기에 개시된 실시 예들 이외에도 본 발명의 기술적 사상에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 자명한 것이다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2022-0052705", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 의한 이미지 처리를 위한 인공 신경망 모델을 학습시키기 위한 시스템의 구성을 나타낸 도면이다. 도 2는 본 발명의 일 실시 예에 의한 이미지 처리를 위한 인공 신경망 모델의 구조를 설명하기 위한 도면이다. 도 3은 본 발명의 일 실시 예에 의한 이미지 처리를 위한 인공 신경망 모델을 학습시키는 방법을 설명하기 위한순서도이다. 도 4는 본 발명의 일 실시 예에 의한 인공 신경망 모델의 학습 방법을 구체적으로 설명하기 위한 도면이다."}
