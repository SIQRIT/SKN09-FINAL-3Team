{"patent_id": "10-2025-7001387", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0037474", "출원번호": "10-2025-7001387", "발명의 명칭": "데이터에 유연하게 접근하기 위한 칩, 방법, 디바이스 및 매체", "출원인": "베이징 요우쭈쥐 네트워크 테크놀러지 컴퍼니 리", "발명자": "스, 연펑"}}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "데이터에 유연하게 접근하기 위한 인공지능 프로세서 칩에 있어서,상기 프로세서 칩 외부에서 읽어온 텐서 데이터를 저장하도록 구성된, 메모리 - 상기 읽어온 텐서 데이터는 인공지능 계산에 포함된 연산자의 텐서 연산을 수행하기 위한 복수의 요소를 포함함 -, 컴퓨팅 유닛으로 상기 요소를 보내기 위해 상기 연산자의 상기 텐서 연산에 따라 상기 메모리로부터 읽기 요소를 제어하도록 구성된, 저장 제어 유닛 - 상기 저장 제어 유닛은 주소 컴퓨팅 모듈을 포함하고, 상기 주소 컴퓨팅 모듈은 소프트웨어에 의해 구성된 파라미터를 수신하기 위한 인터페이스를 갖고, 및 상기 주소 컴퓨팅 모듈은 상기 인터페이스에서 수신된 구성된 파라미터에 따라 단일-계층 읽기 루프 또는 다중-계층 읽기 루프 중첩의상기 메모리에 있는 주소를 계산하여, 계산된 주소에서 상기 요소를 읽고 상기 요소를 상기 컴퓨팅 유닛으로 보냄 -, 및 수신된 상기 요소를 사용하여 상기 연산자의 상기 텐서 연산을 수행하도록 구성된, 컴퓨팅 유닛을 포함하는, 프로세서 칩."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 소프트웨어에 의해 구성된 상기 파라미터는, 상기 단일-계층 읽기 루프에서 상기 읽어온 텐서 데이터로부터 읽어올 요소의 수를 나타내는 값, 및 상기 단일-계층 읽기 루프에서 각각의 단계 사이의 스트라이드를 나타내는 값을 포함하고, 또는 소프트웨어에 의해 구성된 상기 파라미터는, 읽기 루프의 각각의 계층에서 읽기 단계의 수를 나타내는 값, 상기 읽기 루프의 각각의 계층에서 각각의 단계들사이의 스트라이드를 나타내는 값을 포함하고, 상기 읽기 루프의 상기 각각의 계층은, 중첩되는 방식으로 외부 계층에서 내부 계층으로 수행되는, 프로세서 칩."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,소프트웨어에 의해 구성된 상기 파라미터는, 상기 단일-계층 읽기 루프에서 읽은 제1 요소의 주소와 상기 메모리에 있는 입력 텐서의 초기 주소 사이의 간격의 주소의 수를 나타내는 값을 포함하는, 공개특허 10-2025-0037474-3-프로세서 칩."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,소프트웨어에 의해 구성된 상기 파라미터는, 상기 파라미터에 특정한 조건을 포함하고, 및 상기 파라미터는, 상기 조건이 충족될 때와 상기 조건이 충족되지 않을 때, 서로 다른 값을 갖는, 프로세서 칩."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 파라미터는, 읽기 루프의 특정 계층에서 읽기의 단계 수를 나타내는 값이고, 상기 조건은, 상기 특정 계층보다 바깥쪽의 다른 계층에서 읽기가 어느 단계로 진행되는지인, 프로세서 칩."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항 내지 제5항 중 어느 한 항에 있어서,상기 주소 컴퓨팅 모듈은, 상기 단일-계층 읽기 루프 또는 상기 읽기 루프의 상기 각각의 계층에서 현재 진행 중인 단계와 상기 단일-계층읽기 루프 또는 상기 읽기 루프의 상기 각각의 계층의 각각의 스트라이드에 따라 현재 읽어야 하는 주소를 계산하는, 프로세서 칩."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,소프트웨어에 의해 구성된 상기 파라미터는, 상기 연산자의 상기 텐서 연산이 상기 연산자의 상기 텐서 연산에 따라 상기 메모리의 상기 주소에서 상기 요소를 읽는 모드로 대체됨을 나타내는, 프로세서 칩."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2025-0037474-4-제1항에 있어서,상기 텐서 연산은, 입력 텐서의 수치 값을 변경하지 않는 텐서 조작이고, 상기 주소 컴퓨팅 모듈은, 상기 인터페이스를 통해 수신된 구성된 상기 파라미터에 따라 상기 단일-계층 읽기 루프 또는 상기 다중-계층읽기 루프 중첩에서 매번 읽을 상기 메모리의 주소를 계산하여, 상기 텐서 조작이 읽기로 대체되도록 하는, 프로세서 칩."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 텐서 연산은, 전치 연산자의 연산, 재성형 연산자의 연산, 브로드캐스트 연산자의 연산, 수집 연산자의 연산, 역방향 연산자의 연산, 컨캣 연산자의 연산, 및 캐스트 연산자의 연산으로 구성된 그룹에서 적어도 하나를 포함하고, 상기 메모리는, 병렬로 접근할 수 있는 데이터를 각각 저장하기 위한 복수의 뱅크로 나뉘고, 및 상기 저장 제어 유닛은, 상기 메모리의 복수의 뱅크에 저장된 상기 데이터에 병렬로 액세스할 수 있도록, 분리된 읽기 기능과 쓰기 기능을 갖는 크로스바를 포함하는, 프로세서 칩."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공지능의 프로세서 칩에서 데이터에 유연하게 접근하기 위한 방법에 있어서,인공지능의 상기 프로세서 칩 내의 메모리를 통해, 상기 프로세서 칩 외부에서 읽어온 텐서 데이터를 저장하는단계 - 상기 읽어온 텐서 데이터는 인공지능 계산에 포함된 연산자의 텐서 연산을 수행하기 위한 복수의 요소를포함함 -, 컴퓨팅 유닛으로 상기 요소를 보내기 위해 상기 연산자의 상기 텐서 연산에 따라 상기 메모리로부터 읽기 요소를 제어하는 단계 - 계산된 주소에서 상기 요소를 읽고 인공지능의 상기 프로세서 칩에 있는 상기 컴퓨팅 유닛으로 요소를 보내게 하도록, 소프트웨어에 의해 구성되고 수신되는 파라미터에 따라 단일-계층 읽기 루프 또는다중-계층 읽기 루프 중첩의 상기 메모리의 주소를 계산하는 단계를 포함함 -, 및 상기 컴퓨팅 유닛에 의해, 수신된 상기 요소를 사용하여 상기 연산자의 상기 텐서 연산을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 소프트웨어에 의해 구성된 상기 파라미터는, 상기 단일-계층 읽기 루프에서 상기 읽어온 텐서 데이터로부터 읽어올 요소의 수를 나타내는 값, 및상기 단일-계층 읽기 루프에서 각 단계 사이의 스트라이드를 나타내는 값공개특허 10-2025-0037474-5-을 포함하고, 또는 소프트웨어에 의해 구성된 상기 파라미터는, 읽기 루프의 각각의 계층에서 읽기 단계의 수를 나타내는 값, 상기 읽기 루프의 각각의 계층에서 각각의 단계들사이의 스트라이드를 나타내는 값을 포함하고, 상기 읽기 루프의 상기 각각의 계층은, 중첩되는 방식으로 외부 계층에서 내부 계층으로 수행되는, 방법."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,소프트웨어에 의해 구성된 상기 파라미터는, 상기 단일-계층 읽기 루프에서 읽은 제1 요소의 주소와 상기 메모리에 있는 입력 텐서의 초기 주소 사이의 간격의 주소의 수를 나타내는 값을 포함하는, 방법."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,소프트웨어에 의해 구성된 상기 파라미터는, 상기 파라미터에 특정한 조건을 포함하고, 및 상기 파라미터는, 상기 조건이 충족될 때와 상기 조건이 충족되지 않을 때, 서로 다른 값을 갖는, 방법."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 파라미터는, 읽기 루프의 특정 계층에서 읽기의 단계 수를 나타내는 값이고, 상기 조건은, 상기 특정 계층보다 바깥쪽의 다른 계층에서 읽기가 어느 단계로 진행되는지인, 방법."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2025-0037474-6-제11항 내지 제14항 중 어느 한 항에 있어서,상기 단일-계층 읽기 루프 또는 상기 읽기 루프의 상기 각각의 계층에서 현재 진행 중인 단계와 상기 단일-계층읽기 루프 또는 상기 읽기 루프의 상기 각각의 계층의 각각의 스트라이드에 따라 현재 읽어야 하는 주소를 계산하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,소프트웨어에 의해 구성된 상기 파라미터는, 상기 연산자의 상기 텐서 연산이 상기 연산자의 상기 텐서 연산에 따라 상기 메모리의 상기 주소에서 상기 요소를 읽는 모드로 대체됨을 나타내는, 방법."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 텐서 연산은, 입력 텐서의 수치 값을 변경하지 않는 텐서 조작이고, 매번 읽어야 하는 상기 메모리의 주소는, 인터페이스를 통해 수신된 구성된 상기 파라미터에 따라 상기 단일-계층 읽기 루프 또는 상기 다중-계층 읽기루프 중첩으로 계산되므로, 상기 텐서 조작이 읽기로 대체되게 하는, 방법."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 텐서 연산은, 전치 연산자의 연산, 재성형 연산자의 연산, 브로드캐스트 연산자의 연산, 수집 연산자의 연산, 역방향 연산자의 연산, 컨캣 연산자의 연산, 및 캐스트 연산자의 연산으로 구성된 그룹에서 적어도 하나를 포함하고, 상기 메모리는, 병렬로 접근할 수 있는 데이터를 각각 저장하기 위한 복수의 뱅크로 나뉘고, 및 상기 방법은, 분리된 읽기 기능과 쓰기 기능을 갖는 크로스바를 통해 상기 메모리의 상기 복수의 뱅크에 저장된 상기 데이터에 병렬로 액세스하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "전자 디바이스에 있어서,공개특허 10-2025-0037474-7-명령들을 저장하도록 구성된, 메모리, 및 상기 메모리로부터 상기 명령들을 읽고 제10항 내지 제18항 중 어느 하나에 따른 방법을 실행하도록 구성된, 프로세서를 포함하는, 전자 디바이스."}
{"patent_id": "10-2025-7001387", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "비일시적 저장 매체에 있어서,명령들은, 비일시적 저장 매체에 저장되고, 및 상기 명령들은, 프로세서에 의해 판독될 때, 상기 프로세서로 하여금, 제10항 내지 제18항 중 어느 하나에 따른 방법을 실행하게 하는, 비일시적 저장 매체."}
{"patent_id": "10-2025-7001387", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 프로세서 칩, 인공지능 프로세서 칩 내의 데이터에 유연하게 접근하는 방법, 전자 디바이스 및 비일시 적 저장 매체가 제공된다. 칩은: 프로세서 칩 외부에서 읽어온 텐서 데이터를 저장하도록 구성된 메모리 - 읽어 온 텐서 데이터는 인공지능 컴퓨팅에 포함된 연산자의 텐서 연산을 수행하기 위한 복수의 요소를 포함함 -; 연산 (뒷면에 계속)"}
{"patent_id": "10-2025-7001387", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능(artificial intelligence) 분야에 관한 것으로, 보다 구체적으로는 인공지능의 프로세서 칩 (processor chip)에 관한 것으로, 인공지능의 프로세서 칩에서 데이터에 유연하게 액세스하기 위한 방법, 전자 디바이스(electronic device) 및 비일시적 저장 매체(non-transitory storage medium)에 관한 것이다. 본 출원은 2022년 7월 15일에 출원된 중국 특허 출원 번호 202210836577.0의 우선권을 주장하며, 이 출원의 전 체 내용은 본 출원의 개시 내용의 일부로서 참조로 여기에 포함된다."}
{"patent_id": "10-2025-7001387", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(AI) 칩의 성능을 더욱 향상시키고, 컴퓨팅 능력(computing power)을 최대한 활용하며, 미디어 접근 제 어(media access control)(MAC) 주소 사용률(address utilization rate)을 향상시키기 위해서는 데이터 파이프 라인(data pipeline)의 설계가 매우 중요하다. 신경망 계산 프로세스(neural network computation process)에 서, 컴퓨팅 유닛(computing unit)의 입력 데이터(input data)와 출력 데이터(output data)에 대한 다양한 공급 모드(supply modes)와 저장 모드(storage modes)가 있으며, 이에 따라 다양한 칩 저장 컴퓨팅 아키텍처(chip storage computing architectures)도 결정된다. 예를 들어,그래픽 처리 장치(graphic processing unit)(GPU)는 다중-레벨 캐시 시스템(multi-level cache system)을 채택한 병렬 컴퓨팅 프로세서(parallel computing processor)이며, 저장 레벨(storage levels)은 L1 캐시, 공유 메모리(shared memory), 레지스터 그룹(register group), L2 캐시, 외부 저장 DRAM 등을 포함한다. 이러한 저장 레벨을 나누는 주된 목적은 데이터 이동 지연 시 간(data move latency)을 줄이고 대역폭을 개선하는 것이다. L1 캐시는 일반적으로 L1D 캐시와 L1I 캐시로 구분 되며, 각각 데이터와 명령들(instructions)을 저장하는 데 사용된다. 일반적으로, 대응하는 L1 캐시는 각각의 프로세서 코어에 맞게 설정되며, 크기는 각각 16k에서 64k까지 다양하다. L2 캐시는 일반적으로 명령들과 데이 터를 구별하지 않고 개인 캐시(private cache) 역할을 한다. 일반적으로, 대응하는 L2 캐시는 각각의 프로세서 코어에 맞게 설정되며, 크기는 각각 256k에서 1M까지이다. 예를 들어, L1 캐시는 캐시 속도가 가장 빠르지만 공 간이 작으며; L2 캐시는 속도가 느리지만 공간이 더 크며; 그리고 외부 DRAM은 공간이 가장 크지만 속도가 가장 느리다. 따라서, 자주 접근되는 데이터를 DRAM에서 L1 캐시에 저장함으로써, 각각의 접근 시 외부 DRAM에서 메 모리로 데이터를 이동할 때 발생하는 지연 시간을 줄일 수 있고, 이는 데이터 처리의 효율성을 향상시킨다. 그 러나, 프로세서 구조가 보편성과 유연성을 보장하기 위해 데이터 파이프라인은 일정 레벨의 중복성을 가진다.예를 들어, 각각의 계산 프로세스는 레지스터에서 데이터를 가져오는 것부터 시작해서, 데이터를 레지스터에 저 장하는 것으로 끝나야 하므로 전력 소모가 높다. 일부 AI 칩은 사용자 정의 파이프라인을 통해 높은 효율성을 달성할 수 있지만 유연성을 희생하는 대가를 치르 고, 한 번 수정되면 사용할 수 없게 될 수도 있다. 또한, 대용량 온칩 버퍼를 추가하여 대역폭과 지연 시간 문 제를 해결하는 AI 칩도 있지만, 스태틱 랜덤 액세스 메모리(Static Random Access Memory)(SRAM)에 대한 액세 스 모드는 하드웨어에 의해 개시되며, 즉, 계산과 저장이 하드웨어와 결합되어 있다. 이는 융통성 없는 전략의 문제를 야기하고, 소프트웨어가 개입할 수 없는 특정 시나리오에서는 효율성이 낮아지는 결과를 낳는다."}
{"patent_id": "10-2025-7001387", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 한 측면에 따르면, 유연하게 데이터에 액세스할 수 있는 인공지능의 프로세서 칩이 제공된다. 프로세 서 칩(processor chip)은: 프로세서 칩 외부에서 읽어온 텐서 데이터(read-in tensor data)를 저장하도록 구성 된 메모리(memory) - 읽어온 텐서 데이터는 인공지능 계산(artificial intelligence computation)에 포함된 연 산자의 텐서 연산을 수행하기 위한 복수의 요소(element)를 포함함 -; 컴퓨팅 유닛(computing unit)으로 요소를 보내기 위해 연산자의 텐서 연산에 따라 메모리로부터 읽기 요소를 제어하도록 구성된, 저장 제어 유닛(storage control unit) - 여기서 저장 제어 유닛은 주소 컴퓨팅 모듈(address computing module)을 포함하고, 주소 컴 퓨팅 모듈은 소프트웨어에 의해 구성된 파라미터를 수신하기 위한 인터페이스를 가지고, 및 주소 컴퓨팅 모듈은 인터페이스에서 수신된 구성된 파라미터에 따라 단일-계층 읽기 루프(one-layer read loop) 또는 다중-계층 읽 기 루프 중첩(multi-layer read loop nest)의 메모리에 있는 주소를 계산하여, 계산된 주소에서 요소를 읽고 해 당 요소를 컴퓨팅 유닛으로 보냄 -; 및 수신된 요소를 사용하여 연산자(operator)의 텐서 연산(tensor operation)을 수행하도록 구성된, 컴퓨팅 유닛(computing unit)을 포함한다. 또 다른 측면에서, 인공지능의 프로세서 칩에서 데이터에 유연하게 접근하기 위한 방법이 제공된다. 이 방법은: 인공지능의 프로세서 칩의 메모리에 의해, 프로세서 칩 외부에서 읽어온 텐서 데이터를 저장하는(storing) 단계 - 읽어온 텐서 데이터는 인공지능 계산(artificial intelligence computation)에 포함된 연산자의 텐서 연산을 수행하기 위한 복수의 요소를 포함함 -; 컴퓨팅 유닛(computing unit)으로 요소(element)를 보내기 위해 연산자 (operator)의 텐서 연산(tensor operation)에 따라 메모리(memory)로부터 읽기 요소(reading elements)를 제어 하는(controlling) 단계 - 이는 계산된 주소에서 요소를 읽고 인공지능의 프로세서 칩에 있는 컴퓨팅 유닛으로 요소를 보내도록, 소프트웨어로 구성되고 수신된 파라미터에 따라 단일-계층 읽기 루프 또는 다중-계층 읽기 루 프 중첩에서 메모리의 주소를 컴퓨팅하는(computing) 단계를 포함함 -; 및 컴퓨팅 유닛에 의해, 수신된 요소를 사용하여 연산자의 텐서 연산을 수행하는(performing) 단계를 포함한다. 제3 측면에서, 전자 디바이스(electronic device)가 제공된다. 전자 디바이스(electronic device)는: 명령들 (instructions)을 저장하도록 구성된 메모리(memory), 및 메모리에서 명령들을 읽고 본 개시의 각각의 실시예의 방법을 실행하도록 구성된 프로세서(processor)를 포함한다. 또 다른 측면에서, 비일시적 저장 매체(non-transitory storage medium)가 제공되며, 명령들은 비일시적 저장 매체에 저장된다. 이러한 명령들은, 프로세서에 의해 읽혀질 때, 프로세서로 하여금 본 개시의 각각의 실시예의 방법을 실행하게 한다. 이런 식으로, 메모리의 주소는, 메모리에 이러한 요소를 저장하는 순서나 메모리의 주소 정렬에 제한을 받지 않 고, 메모리에서 유연하게 요소를 읽기 위해 소프트웨어 구성 파라미터(software configured parameter)를 통해 유연하게 계산될 수 있다."}
{"patent_id": "10-2025-7001387", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 예는 개시의 구체적인 실시예를 참조하여 첨부 도면에 자세히 설명되어 있다. 본 개시는 특정 실시예 와 관련하여 설명될 것이지만, 본 개시를 설명된 실시예에 한정하려는 것이 아님을 이해해야 할 것이다. 오히려, 이는 첨부된 청구항에 의해 정의된 본 개시 정신 및 범위 내에 포함되는 변경, 수정 및 균등물을 포괄 하도록 의도된다. 여기에 설명된 방법 단계는 어떠한 기능 블록이나 배치에 의해서도 구현될 수 있으며, 어떠한 기능 블록이나 배치도 물리적 개체나 논리적 개체, 또는 그 둘의 조합으로 구현될 수 있다는 점에 유의한다. 본 개시의 다양한 실시예에서 개시된 기술적 솔루션을 이용하기 전에 사용자는 관련 법률, 규정에 따라 적절한 방식으로 본 개시에 포함된 개인정보의 종류, 이용 범위, 이용 시나리오 등을 고지받고 사용자의 승인을 받아야 함을 이해할 수 있다. 예를 들어, 사용자로부터 적극적인 요청을 받은 경우, 사용자가 요청한 연산을 실행하려면 사용자의 개인 정보 를 요청하고 사용해야 한다는 사실을 사용자에게 명확하게 상기시키는 알림 메시지가 사용자에게 전송된다. 따 라서 사용자는 신속한 정보에 따라 본 개시의 기술적 솔루션의 연산을 실행하는 전자 디바이스, 애플리케이션, 서버 또는 저장 매체와 같은 소프트웨어 또는 하드웨어에 개인 정보를 제공할지 여부를 자율적으로 선택할 수 있다. 선택 사항이지만 제한적이지 않은 구현으로, 사용자의 활성 요청을 수신한 경우 팝업 창을 통해 사용자에게 프 롬프트 메시지를 보낼 수 있으며, 프롬프트 메시지는 텍스트로 표시될 수 있다. 또한, 팝업 창(pop-up window) 은 사용자가 개인 정보를 전자 디바이스에 제공하는 것에 대해 \"동의\" 또는 \"동의하지 않음\"을 선택할 수 있는 선택 제어를 수반할 수도 있다. 위의 통지 및 이용자 권한 부여 절차는 단지 예시일 뿐이며, 본 개시의 실시 형태를 제한하지 않는다는 점을 이 해할 수 있다. 관련 법률 및 규정을 준수하는 다른 모드도 이 개시의 구현 모드에 적용될 수 있다. 기술적 솔루션에 관련된 데이터(데이터 그 자체, 데이터의 취득 또는 사용을 포함하되 이에 국한되지 않음)는 해당 법률, 규정 및 관련 규정의 요구 사항을 준수해야 함을 이해할 수 있다. 위에 설명된 애플리케이션 시나리오에 대한 인식 프로세스는 신경망이 다양한 입력 애플리케이션 데이터를 텐서 로 수신하고 신경망을 통해 동일한 데이터를 계산함으로써 구현될 수 있다. 현재, 신경망이나 머신 러닝 시스템 (machine learning system)은 텐서를 기본적인 데이터 구조로 사용한다. 텐서 개념의 핵심은 텐서가 데이터 컨 테이너라는 점에 있으며, 여기에 포함된 데이터는 거의 항상 수치 데이터이므로 텐서는 숫자의 컨테이너이다.텐서의 특정 숫자 값은 애플리케이션 데이터일 수 있으며, 예를 들어 이미지 데이터, 자연어 데이터 등이 있다. 예를 들어, 스칼라는 2, 3, 5와 같이 0-차원 텐서이다. 예를 들어, 이미지 데이터의 특정 응용 프로그램 시나리 오에서 2는 이미지 데이터의 한 픽셀의 회색조 값을 나타내고, 3은 이미지 데이터의 한 픽셀의 회색조 값을 나 타내고, 5는 이미지 데이터의 한 픽셀의 회색조 값을 나타낸다. 예를 들어, 벡터는 1-차원 텐서, 예를 들어 [0, 3, 20]이고, 행렬은 2-차원 텐서, 예를 들면 [ ] 또는 [ [2,3], [1,5] ]이다. 예를 들어, 3-차원 텐서(예: a: (형태:(3,2,1)), [[[1],[2]],[[3],[4]],[[5],[6]]]), 4-차원 텐서 등이 있을 수 있다. 이러한 텐서는, 예를 들어 이미지 데이터, 자연어 데이터 등 특정애플리케이션 시나리오에서 데이터를 표현하는 데 사용될 수 있다. 이러한 애플리케이션 데이터를 위한 신경망 기능에는 이미지 인식(예: 이미지 데이터를 입력하여 이미지에 포함 된 동물이 무엇인지 인식), 자연어 인식(예: 사용자의 언어를 입력하여 사용자의 말 의도를 인식, 예를 들어, 사용자가 음악 플레이어를 여는 목적으로 말하는지 여부 인식) 등을 포함할 수 있다. 위에 설명된 애플리케이션 시나리오에 대한 인식 프로세스는 신경망이 다양한 입력 애플리케이션 데이터를 텐서 로 수신하고 신경망을 통해 동일한 데이터를 계산함으로써 구현될 수 있다. 위에서 설명한 것처럼 신경망의 계 산은 일련의 텐서 연산으로 구성될 수 있으며; 이러한 텐서 연산은 텐서의 여러 차원(dimensions)에 대한 입력 데이터의 복잡한 기하학적 변환이 될 수 있다. 이러한 텐서 연산(tensor operations)을 연산자(operators)라고 부를 수도 있다. 신경망 계산은 계산 그래프로 변환될 수 있으며, 계산 그래프는 복수의 연산자를 갖고, 복수의 연산자는 각각의 연산자의 계산 간의 종속 관계를 나타내는 선으로 연결될 수 있다. 인공지능(AI) 칩은 신경망 연산(neural network operations)에 전념하는 칩으로, 이는 주로 신경망 실행 (neural network execution)을 가속화하기 위해 특별히 설계된 칩이다. 신경망(neural network)은 순수한 수학 공식(mathematical formulas)을 사용하여 표현될 수 있다. 이러한 수학 공식에 따르면, 신경망은 계산 그래프 모델(computational graph model)을 사용하여 표현될 수 있다. 계산 그래프(computational graph)는 이러한 수 학 공식을 시각적으로 표현한 것이다. 계산 그래프 모델은 복합 연산(composite operation)을 복수의 하위 연산 (sub-operation)으로 분할할 수 있으며, 각각의 하위 연산을 연산자(operator)(Op)라고 한다. 신경망의 계산은 대량의 중간 데이터를 생성한다. 모든 중간 데이터가 다이나믹 랜덤 액세스 메모리(dynamic random access memory)(DRAM)에 저장되는 경우, 과도한 지연 시간과 불충분한 대역폭으로 인해 전반적인 성능이 낮아질 수 있다. 이 문제는 L2 캐시를 제공하면 완화될 수 있으며, 이는 프로그래밍에 눈에 띄지 않기 때문에 프로그래밍에 영향을 미치지 않고 대기 시간을 줄일 수 있다. 그러나, L2 캐시에 액세스하는 주소 및 타이밍에 문제는 더 높은 캐시 미스율(cache miss)을 초래할 수 있다. 게다가, 지역성(locality)이 나쁘면 데이터에 접근 하는 데 걸리는 시간도 감추기 어렵다. 신경망 연산에 필요하고 생성되는 데이터는 인공지능 칩의 온칩 SRAM을 이용하여 저장되는데, 이는 소프트웨어 를 통해 데이터 흐름을 적극적으로 제어할 수 있으며, 사전 구성을 통해 SRAM과 DRAM 간의 데이터 이동 시간을 숨길 수 있다. 신경망 연산의 데이터 접근 모드(data access mode)는 유연하기 때문에, SRAM의 접근 유연성이 충분하지 않다면 일부 연산자는 여러 개의 연산 프로세스를 사용하여 완료될 것이다. 그러나, 데이터 계산과 데이터 이동이 완전히 결합되어 하드웨어를 통해 시작되는 경우, 연산자의 계산 모드 (computation mode)는 소프트웨어 조정을 위한 공간 없이, 고정될 것이다. 따라서, 인공지능 칩의 온칩 SRAM에 더 유연하게 접근할 수 있는 모드가 여전히 필요하다. 도 1은 이미지 데이터 처리 및 인식에 적용된 신경망의 예시적인 계산 그래프의 개략도를 나타낸다. 예를 들어, 이미지 데이터(예: 픽셀의 색도 값)를 수반하는 텐서는 도 1에 표시된 예시적인 계산 그래프에 입력 된다. 계산 그래프는 독자의 편의를 위해 일부 연산자만 나타낸다. 계산 그래프의 연산 프로세스는: 먼저 텐서 에 전치 연산자 계산을 처리하고, 그다음 한 브랜치(branch)에 재성형 연산자 계산(Reshape operator computation)을 처리하고, 다른 브랜치에 완전 연결 연산자 계산을 처리한다. 텐서는 우선 전치 연산자(Transpose operator)에 입력된다고 가정아며, 여기서 전치 연산자는 입력 텐서의 숫자 값을 변경하지 않는 텐서 연산(tensor operation)이다. 전치 연산자는 어레이의 차원(축) 배치 순서를 변경하는 역할을 한다. 예를 들어, 2-차원 배치의 경우 2 차원 순서의 역변경(counterchange)은 행렬 전치(matrix transpose)이다. 전치 연산자는 더 많은 차원(축)의 경우에 적용될 수 있다. 전치 연산자의 입력 파라미터는, 서 번호 0에서 카운트하는, 출력 어레이의 차원 배치 순서(dimension arrangement order)이다. 전치 연산자의입력 텐서는 예를 들어, 2-차원 행렬 [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]이거나, 으로 표현되며, 예를 들어, 이미지 데이터는 4*3의 2-차원 행렬과 같이 표현된다고 가정한다. 전 치(Transpose)([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])는 전치를 나타내며, 즉 2-차원 행렬을 [[1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]]로 변경하거나, 또는 와 같이 3*4로 표현된 행렬로 변경하는 것이다. 보시다시피, 전치 연산자는 차원 배치 순서(dimension arrangement order)를 변경하고, 즉 텐서의 형태를 변경 하지만 텐서의 숫자 값은 변경하지 않으며, 예를 들어, 숫자 값은 여전히 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12이다. 물론, 전치 연산자는 텐서의 형태를 변경하지 않고(예: 3*3 행렬은 전치 후에도 여전히 3*3 행렬임) 숫 자 값의 배치 순서를 변경할 수도 있고 텐서의 숫자 값을 변경할 수도 있다. 그러면, 전치 연산자 연산을 거치는 위에서 설명한 텐서 는 두 브랜치로 나뉜다. 한 브랜치는 재성형 연산 계산을 거치고, 다른 브랜치는 완전 연결 연산자 계산을 거친다. 재성형 연산(Reshape operator)의 특정 연산은 텐서의 형태 속성을 변경하는 것으로, m*n 크기의 행렬 a를 i*j 크기의 행렬 b로 배치할 수 있다. 예를 들어, 재성형 연산자(Reshape operator)(재성형(A, 2, 6), 여기서 A는 입력 텐서)는 위에 설명된 텐서 의 형태를 3*4에서 2*6으로 변경한다. 따라서, 재성형 연산를 통해 얻은 출력 텐서는 예를 들어 와 같다. 재성형 연산자는 텐서의 숫자 값을 변경하지 않고 텐서의 형태 만 변경하며, 예를 들어, 숫자 값은 여전히 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12임을 볼 수 있다. 완전 연결 연산자(Fully connected operator)(완전한 연결 연산자(Full Connection operator)라고도 함)는 특 수한 컨볼루셔널 계층(convolutional layer) 또는 텐서의 곱으로 간주될 수 있으며, 여기서 특징 맵(feature map)으로 전체 텐서 입력을 취하고 특징 추출 연산(feature extraction operation)을 수행한다. 즉, 하나의 특 징 공간(feature space)이 다른 특징 공간으로 선형적으로 변환되고, 출력 텐서는 입력 텐서의 가중 합이다. 예 를 들어, 완전 연결 연산자는, 예를 들어 , 와 같은, 4*1 크기의 가중치 행렬 x로 곱해진, 입력 텐서(전치 연산자의 출력 텐서) ) 행렬을 가지며, 즉, 각각 전치 행렬의 행을 판독하는데, 제1 행은 가중 치 행렬 x에 곱해지고, 제2 행은 가중치 행렬 x에 곱해지고, 마지막으로 제3 행은 가중치 행렬 x에 곱해진다. 구체적으로, 1을 40으로 곱한 것, 4를 50으로 곱한 것, 7을 60으로 곱한 것, 10을 70으로 곱한 것을 더한 것은 완전 연결 연산자의 결과 텐서의 제1 값이되며; 2를 40으로 곱한 것, 5를 50으로 곱한 것, 8을 60으로 곱한 것, 11을 70으로 곱한 것을 더한 것은 완전 연결 연산자의 결과 텐서의 제2 값이 되며, 그리고 3을 40으로 곱한 것, 6을 50으로 곱한 것, 9를 60으로 곱한 것, 12를 70으로 곱한 것을 더한 것은 완전 연결 연산자의 결과 텐서의 제3 값이 된다. 기존 기술에서, 도 1에 나타난 계산 그래프에서 전치 연산자부터 완전 연결 연산자(Fully connected operator) 까지의 계산 프로세스를 인공지능 칩을 통해 수행할 때, 인공지능 칩은 먼저 전치 연산자의 입력 텐서를 칩 내부의 저장 유닛(storage unit)의 메모리로 읽어들인다. 입력 텐서는 라고 가정되며, 이는 일반적 으로 칩 내부의 저장 유닛의 메모리에, 즉, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12로 연속적으로 저장된다. 그런 다음, 칩 내의 컴퓨팅 유닛은 전치 연산자의 연산(예:4*3을 3*4로 변환)을 실행하여, 입력 텐서를 으로 변환한다. 다음으로, 칩은 변환된 결과 텐서 를 칩 내부의 저장 유닛의 메 모리에 중간 데이터로 저장한다. 이 경우 결과 텐서는 일반적으로 칩 내부의 저장 유닛의 메모리에, 즉, 1, 4, 7, 10, 2, 5, 8, 11, 3, 6, 9, 12로 연속적으로 저장된다. 지금까지 전치 연산자의 연산이 완료되었다. 그런 다음 완전 연결 연산자의 연산이 실행된다. 입력 텐서(전치 연산자의 출력 텐서) ) 행렬 은, 예를 들어 와 같은, 4*1 크기의 가중치 행렬 x로 곱해진다. 첫째, 칩은 가중치 행렬 x, 예를 들어 을 읽는다. 가중치 행렬 x는 일반적으로 칩 내부의 저장 유닛의 메모리에 40, 50, 60, 70으로 연속적으로 저장된다. 그리고, 컴퓨팅 유닛은 전치 연산자의 출력 텐서로부터 각각 하나의 수치 값을 저장 유닛의 메모리에 서 저장 순서대로 읽어오고, 각각 가중치 행렬 x로부터 대응하는 수치 값을 저장 순서대로 읽어와 곱셈과 덧셈 을 수행한다. 구체적으로, 1을 40으로 곱한 것, 4를 50으로 곱한 것, 7을 60으로 곱한 것, 10을 70으로 곱한 것 을 더한 것은 완전 연결 연산자의 결과 텐서의 제1 값이되며; 2를 40으로 곱한 것, 5를 50으로 곱한 것, 8을 60 으로 곱한 것, 11을 70으로 곱한 것을 더한 것은 완전 연결 연산자의 결과 텐서의 제2 값이 되며, 그리고 3을 40으로 곱한 것, 6을 50으로 곱한 것, 9를 60으로 곱한 것, 12를 70으로 곱한 것을 더한 것은 완전 연결 연산자 의 결과 텐서의 제3 값이 된다. 그러면, 칩의 컴퓨팅 유닛은 계산 결과를 칩 내부의 저장 유닛의 메모리에 저장 한다. 즉, 전치 연산자의 계산과 그에 따른 완전 연결 연산자의 계산을 위해, 칩의 각각의 하드웨어 유닛은 읽기, 계 산, 저장, 다시 읽기, 재계산, 재저장 프로세스에서 협력해야 하지만, 전체 프로세스의 계산 효율성과 유연성은 매우 낮다. 본 개시는 인공지능의 프로세서 칩에서 유연하게 데이터에 접근하기 위해 사용되는 모드를 제안하는데, 이는 인 공지능 프로세서 칩의 소프트웨어 구성 및 관련 파라미터를 활용하여 일부 연산자의 동작을 칩의 읽기 연산으로 대체하여 유연하게 데이터에 접근함으로써 계산 효율성을 개선할 수 있다. 도 2는 본 개시의 실시 예에 따른 유연하게 데이터에 접근하기 위한 인공지능의 프로세서 칩의 개략도를 나타낸 다. 도 2에 도시된 바와 같이, 데이터에 유연하게 접근하기 위한 인공지능 프로세서 칩(artificial intelligence processor chip)은: 프로세서 칩(processor chip) 외부로부터 읽어온 텐서 데이터를 저장하도록 구 성된, 메모리(memory) - 읽어온 텐서 데이터는 인공지능 계산(artificial intelligence computation)에 포함된 연산자의 텐서 연산을 수행하기 위한 복수의 요소를 포함함 -; 컴퓨팅 유닛(computing unit)으로 요소를 보내기 위해 연산자의 텐서 연산에 따라 메모리로부터 읽기 요소를 제어하도록 구성된, 저장 제어 유닛 (storage control unit) - 여기서 저장 제어 유닛은 주소 컴퓨팅 모듈(address computing module)을 포함하고, 주소 컴퓨팅 모듈은 소프트웨어에 의해 구성된 파라미터를 수신하기 위한 인 터페이스를 가지고, 및 주소 컴퓨팅 모듈은 구성된 파라미터에 따라 단일-계층 읽기 루프(one-layer read loop) 또는 다중-계층 읽기 루프 중첩(multi-layer read loop nest)의 메모리에 있는 주소를 계산하여, 계산된 주소에서 요소를 읽고 해당 요소를 컴퓨팅 유닛으로 보냄 -; 및 수신된 요소를 사용하여 연산자(operato r)의 텐서 연산(tensor operation)을 수행하도록 구성된, 컴퓨팅 유닛을 포함한다. 본 실시예에 따르면, 주소 컴퓨팅 모듈은 저장 제어 유닛(storage control unit)에 제공된다. 주소 컴퓨팅 모듈은 소프트웨어 구성 파라미터를 수신하기 위한 인터페이스를 갖추고 있다. 주소 컴퓨팅 모듈 은, 계산된 주소에서 요소를 읽고 이를 컴퓨팅 유닛으로 보내기 위해, 구성된 파라미터에 따라 단일-계층 읽기 루프(one-layer read loop) 또는 다중-계층 읽기 루프 중첩(multi-layer read loop nest)의 메모리 에 있는 주소를 계산할 수 있다. 이런 방식으로, 소프트웨어 구성 파라미터를 사용하여 메모리에서 읽기 위한 주소를 유연하게 계산할 수 있으며, 즉, 이렇게 유연하게 계산된 주소는 저장 순서와 다른 순서를 가질 수 있으 며, 요소는, 기존 기술처럼 저장 순서대로 읽어야 하는 것과 달리, 사용자는 소프트웨어를 통해 파라미터에 따 라 새로운 읽기 순서로 읽혀질 수 있다. 따라서, 소프트웨어 구성 파라미터는, 이러한 요소를 저장하는 순서나 메모리의 주소 분류에 제한 없이, 메모리 의 주소를 유연하게 계산하기 위해 사용될 수 있다. 도 1의 예를 결합하면, 전치 연산자는 텐서의 요소를 변경하지 않고 차원 배치 순서를 변경하며, 요소들은 여전 히 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12이다. 즉, 메모리의 주소가 구성된 파라미터에 따라 단일-계층 읽기 루프(one-layer read loop) 또는 다중-계층 읽기 루프 중첩(multi-layer read loop nest)의 메모리에 있는 주 소를 계산될 수 있어 계산된 주소로부터 요소를 읽고 이를 컴퓨팅 유닛으로 보내게 하고, 그런 다음 사용 자는 소프트웨어로 새로운 읽기 순서를 구성하기 위해 파라미터를 사용할 수 있어, 이들 저장된 요소 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12는 전치 연산자에 의해 전치된 텐서에 의해 읽혀질 수 있다. 구체적으로, 입력 텐서는 이라고 가정되며, 이는 일반적으로 칩 내부의 저장 유닛의 메모리에, 즉, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12로 연속적으로 저장된다(예를 들어, 메모리 주소(16진수)가 00000001, 00000002, 00000003, 00000004, 00000005, 00000006, 00000007, 00000008, 00000009, 00000010, 00000011, 00000012 인 경우). 그런 다음 사용자는 소프트웨어로 새로운 읽기 순서를 구성하기 위해 파라미터를 사용할 수 있으며, 이를 통해 주소 컴퓨팅 모듈은 구성된 파라미터에 따라 메모리의 주소를 계산할 수 있 으며, 예를 들어, 구성된 파라미터에 따라 계산된 메모리의 주소의 순서는 다음과 같다: 00000001, 00000004, 00000007, 00000010, 00000002, 00000005, 00000008, 00000011, 00000003, 00000006, 00000009, 00000012, 즉 주소 읽기 순서는 전치 연산자의 전치 연산을 대체하는 데 직접적으로 사용될 수 있다. 이런 방식으로, 소프트웨어 구성 파라미터는 메모리에서 읽기 위한 주소를 유연하게 계산하기 위해 사용될 수 있으며, 즉, 이렇게 유연하게 계산된 주소는 저장 순서와 다른 순서를 가질 수 있으며, 요소는, 기존 기술처럼 저장 순서대로 읽어야 하는 것과 달리, 사용자는 소프트웨어를 통해 파라미터에 따라 새로운 읽기 순서로 읽혀 질 수 있다. 실시예에서, 소프트웨어에 의해 구성된 파라미터는 연산자의 텐서 연산이 전치 연산자의 텐서 연산에 따라 메모 리의 주소에서 요소를 읽는 모드로 대체됨을 나타낸다. 도 1의 예를 결합하면, 즉 소프트웨어 구성 파라미터는 연산자의 텐서 연산이 전치 연산자의 텐서 연산에 따라 메모리의 주소에서 요소를 읽는 모드로 대체된다는 것을 나타낸다. 실시예에서, 소프트웨어에 의해 구성된 파라미터는: 각각의 읽기 루프의 계층에서 제1 단계에서 제1 요소 읽기 (first element read)의 주소와 메모리의 입력 텐서의 초기 주소(initial address) 사이의 간격의 주소의 수를 나타내는 값, 하나의 읽기 루프에서 읽기의 단계 수를 나타내는 값, 단일-계층 읽기 루프 내의 각각의 단계들 사이의 스트라이드(stride)를 나타내는 값을 포함한다. 여기서의 스트라이드는 신경망 개념의 페이스/스트라이 드(pace/stride)와 비슷하다는 점에 유의한다. 이 구현예에서, 읽기 루프가 하나만 있는 경우, 소프트웨어 구성 파라미터는 시작 주소, 읽어야 할 요소의 총 수, 그리고 각각의 읽기 동안 각각의 요소 사이의 간격의 주소의 수만 알려주면 된다. 즉, 3개의 파라미터만 필 요하다. 예를 들어, 수집 연산자(Gather operator)의 연산이 수행된다고 가정한다. 수집 연산자의 연산은 입력 텐서의 일부 숫자 값 중 일부 숫자 값을 선택하여 출력 텐서로 사용하는 것이다. 수집 연산자의 연산은 입력 텐서의 수 치 값을 변경하지 않는 텐서 연산임을 알 수 있다. 이 경우, 입력 텐서는 [1,2,3,4,5,6,7,8]이고, 수집 연산자 의 연산은 [1,2,3,4,5,6,7,8]에서 [1,3,5,7]을 선택하는 것으로 가정된다. 기존 기술에서는 수집 연산자의 연산을 완료하기 위해, 칩은 먼저 입력 텐서 [1,2,3,4,5,6,7,8]을 메모리 주소 (16진수)로 메모리에 지속적으로 저장해야 하며: 예를 들어, 00000001, 00000002, 00000003, 00000004, 00000005, 00000006, 00000007, 00000008이며; 그런 다음 칩의 컴퓨팅 유닛은 [1,3,5,7]을 획득하기 위해 수집연산자의 연산을 수행하며, 그런 다음 [1,3,5,7]을 주소(16진수)로 저장하며: 예를 들어, 00000009, 000000010, 00000011, 00000012이다. 그런 다음 칩은 컴퓨팅 유닛을 통해 결과 [1,3,5,7]에 대한 추가 연산자 연산을 계속 수행한다. 그러나, 이 실시예를 통해 주소 컴퓨팅 모듈은 소프트웨어 구성 파라미터를 통해 입력 텐서 [1,2,3,4,5,6,7,8] 로부터 1, 3, 5, 7의 주소를 직접 계산할 수 있고, 컴퓨팅 유닛을 통해 결과 [1,3,5,7]에 대한 추가 연산자 연 산을 실행하기 위해 이 주소로부터 [1,3,5,7]을 읽을 수 있다. 구체적으로, 소프트웨어에 의해 구성되는 파라미 터는: 하나의 읽기 루프에서 읽기 단계 수를 나타내는 값 4(총 4개의 읽기를 나타냄), 및 단일-계층 읽기 루프 내의 각각의 단계 사이의 스트라이드를 나타내는 값 2(다음 읽기로 진행하기 전에 각각의 읽기 후에 추가된 2개 의 주소를 나타냄)를 포함할 수 있다. 따라서, 이러한 파라미터에 따라 주소 컴퓨팅 모듈(address computing module)은 다음과 같이 읽혀질 주소 순서 를 계산할 수 있다: 00000001, 00000003, 00000005, 00000007(주소 00000001에서 시작해서 다음 읽기로 넘어가 기 전에 각각의 읽기에 대해 주소 2개를 추가하여 총 4번의 읽기가 필요함). 컴퓨팅 유닛은 이에 대응하여 계산 된 주소 순서의 00000001, 00000003, 00000005, 00000007의 위치에 저장된 주소, 즉 1, 3, 5, 7를 읽는다. 이런 방식으로, 소프트웨어 구성 파라미터는 컴퓨팅 유닛으로 하여금, 계산된 주소 순서의 00000001, 00000003, 00000005, 00000007의 위치에 저장된 주소를, 즉 1, 3, 5, 7를 읽도록 하는데 사용되어, 그래서 수집 연산자의 연산을 직접 대체하고, 기존 기술에서 수집 연산자의 연산을 계산하는 데 드는 시간과 하드웨어 비용, 수집 연 산자의 연산 결과 텐서를 저장하는 데 드는 시간과 하드웨어 비용, 그리고 수집 연산자의 연산 결과 텐서를 저 장하는 주소에서 각각의 요소를 읽어내는 데 드는 시간과 하드웨어 비용을 절약할 수 있다. 더 복잡하고 유연한 읽기 형식에는 다중-계층 읽기 루프 중첩이 채택될 수 있다. 실시예에서, 소프트웨어에 의 해 구성된 파라미터는: 각각의 읽기 루프의 계층에서 읽기 단계의 수를 나타내는 값, 각각의 읽기 루프의 계층 에서 각각의 단계들 사이의 스트라이드를 나타내는 값을 포함할 수 있으며, 여기서 각각의 읽기 루프의 계층은 중첩되는 방식으로 외부 계층에서 내부 계층으로 수행된다. 실시예에서, 소프트웨어에 의해 구성된 파라미터는: 각각의 읽기 루프의 제1 계층의 제1 단계에서 읽은 제1 요소의 주소와 메모리에 있는 입력 텐서의 초기 주소 (initial address) 사이의 간격의 주소의 수를 나타내는 값을 더 포함할 수 있다. 이런 방식으로, 읽기 모드가 더 유연해질 수 있다. 본 실시예에서, 다중-계층 읽기 루프 중첩이 채택된다. 루프 중첩은: 먼저 바깥 계층의 루프 하나를 실행한 다 음, 안쪽 계층의 루프를 실행하고, 다음으로, 바깥 계층의 제2 루프에 들어가서, 다시 안쪽 계층의 루프 하나를 실행하는 것을 말한다. 위에 설명된 외부-계층 루프층(outer-layer loop)와 내부-계층 루프(inner-layer loo p)는 2-계층 루프 중첩(2-layer loop nest)의 예이다. 예를 들어, 2차원 행렬을 읽을 때, 외부-계층 루프는 어 떤 열을 읽을지 제어할 수 있고, 내부-계층 루프는 특정 열의 어떤 행을 읽을지 제어할 수 있다. C 언어에서, 다중-계층 읽기 루프 중첩은 루프 중첩 상태(loop nest statement)를 \"위해\" 다중-계층을 사용하여 실행될 수 있다. 예를 들어, 도 1의 예를 결합하여 2-계층 루프 중첩의 예를 들어보겠다. 입력 텐서는 이라고 가 정되며, 이는 일반적으로 칩 내부의 저장 유닛의 메모리에, 즉, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12로 연 속적으로 저장된다(예를 들어, 메모리 주소(16진수)가 00000001, 00000002, 00000003, 00000004, 00000005, 00000006, 00000007, 00000008, 00000009, 00000010, 00000011, 00000012 인 경우). 전치 연산자의 연산을 대체하기 위해, 즉 1, 4, 7, 10, 2, 5, 8, 11, 3, 6, 9, 12를 순차적으로 읽기 위해, 2- 계층 읽기 루프가 설정될 수 있다. 제1 계층의 읽기 루프(first-layer read loop)는 내부-계층 루프이고, 제2 계층의 읽기 루프(second-layer read loop)는 외부-계층 루프라고 가정한다. 즉, 본 개시에서 다중-계층 루프 중첩에 관하여, 큰 숫자는 외부 계층의 루프를 나타내고, 작은 숫자는 내부 계층의 루프를 나타낸다. 소프트웨어 구성 파라미터는: 각 읽기 루프의 계층에서 읽기 단계의 수를 나타내는 값(제2 계층(외부 계층) 읽 기 루프의 단계 수는 3, 즉 텐서의 열 3을 횡단하고, 제1 계층(내부 계층) 읽기 루프의 단계 수는 4, 즉 열의 모든 행을 횡단함) 및 각각의 읽기 루프의 계층에서 각각의 단계 간의 스트라이드를 나타내는 값(제2 계층 읽기 루프에서 각각의 단계 간의 스트라이드는 1, 즉 제1 단계에서, 00000001에서 읽기 시작하고, 제2 단계에서, 00000001 더하기 1 주소(00000002와 동일함)에서 읽기 시작하고; 제2 계층 읽기 루프에서 각각의 단계 간의 스트라이드는 3, 즉 제1 단계에서, 00000001에서 읽기 시작하고, 제2 단계에서, 00000001 더하기 3 주소 (00000004와 동일함)에서 읽기 시작하고, 여기서 각각의 읽기 루프의 계층은 중첩되는 방식으로 외부 계층에서 내부 계층으로 수행된다. 2-계층 읽기 루프 중첩(2-layer read loop nest)의 의사코드는, 다음과 같다고 가정하면: loop_1의 경우 1부터 loop_1_cnt_max까지, loop_0의 경우 1부터 loop_0_cnt_max까지, 여기서, loop_1은 제2 계층 읽기 루프를 나타내고, loop_0은 제1 계층 읽기 루프를 나타낸다. 그리고 위에 설명 한 파라미터 설정에 따르면, loop_1_cnt_max는 3이고, loop_0_cnt_max는 4이다. 따라서, 다음으로, 주소 컴퓨팅 모듈은 소프트웨어에 구성된 파라미터에 따라 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12를 저장하는 메모리 주소 0000001, 00000002, 00000003, 00000004, 00000005, 00000006, 00000007, 00000008, 00000009, 00000010, 00000011, 00000012에서 데이터를 읽는다. 구체적으로, 소프트웨어 구성 파라미터에 따라, 제2 계층 읽기 루프에서, 컴파일러가 읽기를 위한 초기 주소를 계산했다고 가정하며; 예를 들어, 이 예에서 메모리에 저장된 입력 텐서의 초기 주소는 00000001이고; 제2 계층 읽기 루프에서, 00000001부터 읽기 시작한다. 제1 계층 읽기 루프의 모든 단계는 제2 계층 읽기 루프의 제1 단 계에서 실행된다. 즉, 제1 계층 읽기 루프의 4 개의 단계에서 4개 주소의 스트라이드로 4번의 읽기가 수행되며, 즉, 제2 계층 읽기 루프의 제1 단계에서, 주소 컴퓨팅 모듈(address computing module)은 00000001, 00000004, 00000007, 00000010으로 읽기 주소를 계산하며; 따라서 제2 계층 읽기 루프의 제1 단계에서 읽을 요소는 각각 주소 00000001, 00000004, 00000007, 00000010에 저장되는 1, 4, 7, 10이다. 제2 읽기 루프에서 제2 단계의 초기 주소와 제1 단계의 초기 주소 사이의 스트라이드는 1이며, 즉, 00000001 더 하기 1 주소에서 읽기 시작하며, 즉, 00000002 주소에서 읽기 시작한다. 제1 계층 읽기 루프의 모든 단계는 제2 계층 읽기 루프의 제2 단계에서 실행된다. 즉, 제1 계층 읽기 루프의 4 개의 단계에서 4개 주소의 스트라이드로 4번의 읽기가 수행되며, 즉, 제2 계층 읽기 루프의 제2 단계에서, 주소 컴퓨팅 모듈(address computing modul e)은 00000002, 00000005, 00000008, 00000011로 읽기 주소를 계산하며; 따라서 제2 계층 읽기 루프의 제2 단 계에서 읽을 요소는 각각 주소 00000002, 00000005, 00000008, 00000011에 저장되는 2, 5, 8, 11이다. 제2 읽기 루프에서 제3 단계의 초기 주소와 제2 단계의 초기 주소 사이의 스트라이드는 1이며, 즉, 00000002 더 하기 1 주소에서 읽기 시작하고, 즉, 주소 00000003에서 읽기 시작한다. 제1 계층 읽기 루프의 모든 단계는 제2 계층 읽기 루프의 제3 단계에서 실행된다. 즉, 제1 계층 읽기 루프의 4개의 단계에서 4개 주소의 스트라이드로 4번의 읽기가 수행되고, 즉 제2 계층 읽기 루프의 제3 단계에서, 주소 컴퓨팅 모듈은 읽기 주소 00000003, 00000006, 00000009, 00000012를 계산하므로, 제2 계층 읽기 루프의 제3 단계에서, 읽을 요소는 각각 00000003, 00000006, 00000009, 00000012 주소에 저장되는 3, 6, 9, 12이다. 따라서, 이러한 소프트웨어 구성 파라미터에 따라, 주소 컴퓨팅 모듈에서 계산한 주소의 순서는 00000001, 00000004, 00000007, 00000010, 00000002, 00000005, 00000008, 00000011, 00000003, 00000006, 00000009, 00000012 이므로, 이러한 주소에서 순차적으로 읽혀지는 요소는 1, 4, 7, 10, 2, 5, 8, 11, 3, 6, 9, 12이다. 이러한 소프트웨어 구성 파라미터에 따르면, 제2 계층 읽기 루프의 단계 수(step count)는 3이므로, 주소 컴퓨 팅 모듈은 제2 계층 읽기 루프를 3번 실행한 후 중지되고, 각각의 제2 계층 읽기 루프 내에서 제1 계층 읽기 루 프의 주소 계산이 수행된다. 이 실시예에서, 소프트웨어 구성 파라미터는 루프가 1개만 있는 경우를 구성하는 데에도 사용될 수 있으며, 예 를 들어, 제2 계층 읽기 루프의 단계 수가 1로 설정되며, 즉 제1 계층 읽기 루프의 모든 단계가 한 번만 실행된 다. 또한, 위에 기술된 구체적인 파라미터의 값은 단지 예시일 뿐이며, 즉, 숫자를 사용하여 그 의미를 직접적으로 표현한 것이지, 제한적인 것은 아니다. 숫자 이외의 다른 수치 값 또는 내용을 사용하여 그 의미를 나타낼 수도 있으며, 칩이 값의 대응하는 의미를 추론할 수 있는 한, 예를 들어 0을 사용하여 스트라이드 또는 단계 수가 1 인 것을 나타낼 수도 있으며(칩은 일반적으로 0부터 세기 시작하기 때문이다), 또는 A는 스트라이드 또는 단계 수가 1인 것을 나타내는데 사용될 수도 있다. 이런 방식으로, 다양한 텐서 연산은 주소를 계산하기 위해 주소 컴퓨팅 모듈과 협력하여 소프트웨어 구성 파라 미터로 직접 대체될 수 있다. 더욱이, 하나 이상의 루프 중첩의 주소 계산 프로세스가 설정되며, 이는, 입력 텐 서의 각각의 수치 값을 저장하는 순차적인 주소 그 자체에 제한 없이, 주소 컴퓨팅 모듈에서 계산된 읽기 주소 를 보다 유연하게 만들 수 있다. 또한, 연산자의 연산을 직접 대체하여 기존 기술에서 연산자의 연산을 계산하 는 데 드는 시간과 하드웨어 비용, 연산자의 연산 결과 텐서를 저장하는 데 드는 시간과 하드웨어 비용, 연산자 의 연산 결과 텐서를 저장하는 주소에서 각각의 요소를 읽어내는 데 드는 시간과 하드웨어 비용을 절감할 수 있 어, 계산 지연 시간을 줄이고, 하드웨어 계산 비용을 절감하며, 인공지능 칩의 운영 효율성을 향상시킬 수 있다. 소프트웨어 구성 파라미터는 주소 컴퓨팅 모듈과 협력하여 주소를 계산하는 데 사용된되며, 이를 통해 배치된 주소 시퀀스를 보다 유연하게 계산할 수 있을 뿐만 아니라 다양한 텐서 연산을 대체할 수도 있다. 일 구현예에 서, 대체된 텐서 연산은 입력 텐서의 수치 값을 변경하지 않는 텐서 조작(tensor manipulation)일 수 있으며, 여기서 주소 컴퓨팅 모듈은 인터페이스를 통해 수신된 구성된 파라미터에 따라 단일-계층 읽기 루프 또는 다중- 계층 읽기 루프 중첩에서 매번 읽을 메모리의 주소를 계산하여, 텐서 연산이 읽기로 대체되도록 한다. 실시예에서, 텐서 연산(tensor operations)은: 전치 연산자의 연산, 재성형 연산자의 연산, 브로드캐스트 연산 자(broadcast operator)의 연산, 수집 연산자(gatherer operator)의 연산, 역방향 연산자(reverse operator)의 연산, 컨캣 연산자(concat operator)의 연산, 캐스트 연산자(cast operator)의 연산 등을 포함할 수 있다. 물 론, 본 개시의 실시예에 따르면 주소 컴퓨팅 모듈과 소프트웨어 구성 파라미터를 통해 유연하게 구현될 수 있는 다른 유형의 연산자의 연산도 많이 있다. 물론, 소프트웨어에서 구성된 파라미터는 주소 컴퓨팅 모듈과 협력하여 주소를 계산하는 데 사용되며, 이는 특 정 텐서 연산을 대체할 수 있을 뿐만 아니라 다양하고 유연한 방식으로 읽을 주소를 계산하여 하드웨어 자체의 순차적 읽기의 고유한 한계를 뛰어넘는 유연한 읽기 기능을 구현할 수 있다. 이하에서, 구체적인 칩 하드웨어 사례와 파라미터 사례를 결합하여 구체적인 실제 시나리오에서의 적용 사례를 설명한다. 도 3은 본 개시의 실시 예에 따른 유연하게 데이터에 접근하기 위한 인공지능의 프로세서 칩의 분해 개략도를 나타낸다. 도 3은 인공지능 프로세서 칩의 프로세스 엔진(process engine)(PE)에서 사용되는 내부 유닛 및 파라미터 를 나타낸다. 프로세스 엔진은 구성 유닛(configuring unit), 컴퓨팅 유닛(computing unit), 저장 유닛 (storage unit)을 포함할 수 있다. 저장 제어 유닛(storage control unit)은 컴퓨팅 유닛과 저 장 유닛을 구성하는 데 사용되며; 컴퓨팅 유닛은 주로 컨볼루션/행렬 계산/벡터 계산 ((convolution/matrix computation/vector computation) 등에 사용되며; 저장 유닛은 온칩 SRAM 메모리 (예를 들어 8MB 크기이지만 이에 국한되지 않음)과 프로세스 엔진의 내부 데이터와 외부 데이터를 교환하고 프로세스 엔진 내에서 컴퓨팅 유닛의 데이터에 액세스하는 데 사용되는 메모리 액세스 제어 모듈을 포함한다. 프로세스 엔진은 또한 저장 제어 유닛을 포함하며, 저장 제어 유닛는 다음과 같이 특정 함수 (function)를 구현한다: sram_read 함수는 읽은 데이터의 계산(예: 컨볼루션/행렬 계산/벡터 계산과 같은 텐서 연산)을 위해 SRAM(303 1)에서 데이터를 읽고 이를 컴퓨팅 유닛으로 보내기 위해 사용된다. sram_write 함수는 컴퓨팅 유닛으로부터 계산 결과 데이터를 획득하고 이를 SRAM에 쓰고 저장하는 데 사용된다. sram_upload 함수는 SRAM에 저장된 데이터를 프로세스 엔진 외부(예: 다른 프로세스 엔진 또는 DRAM)로 이동하는 데 사용된다. sram_download 함수는 프로세스 엔진 외부에서 데이터(다른 프로세스 엔진이나 DRAM에서 온 데이터)를 SRAM으로 다운로드하는 데 사용된다. 즉, sram_upload 함수와 sram_download 함수는 프로세스 엔진 외부의 장치와 데이터를 교환하는 데 사용된 다. sram_read 함수와 sram_write 함수는 프로세스 엔진 내의 컴퓨팅 유닛과 저장 유닛 간의데이터 상호작용에 사용된다. SRAM은 프로세스 엔진 내부의 공유 메모리로, 크기가 8MB로 제한되지 않으며, 주로 프로세스 엔진 내부의 중간 데이터(계산 대상 데이터와 계산 결과 포함)를 저장하는 데 사용된다. SRAM은 전체 데 이터 대역폭을 향상시키기 위해 여러 개의 뱅크로 나뉠 수 있다. 크로스바(crossbar)는 프로세스 엔진 내부의 저장 제어 액세스 인터페이스와 SRAM 다중-뱅크(SRAM multi-banks)가 완전히 상호 연결된 구조이다. 크로스바는 저장 유닛의 메모리 액세스 제어 모듈 과 함께 주소 컴퓨팅 모듈에서 계산된 주소를 통해 저장 유닛의 SRAM 메모리에서 주소 의 요소를 읽는 것을 제어한다. 전체 프로세스 엔진의 컴퓨팅 파이프라인(컴퓨팅 유닛)과 데이터 파이프라인(저장 유닛 303)이 별도 로 구성되어 있는 것을 볼 수 있다. 연산자의 계산은 여러 모듈의 협력을 필요로 한다. 예를 들어, 컨볼루션의 하나의 계산은 컴퓨팅 유닛에 피처 데이터를 입력하기 위해 sram_read를 구성하고, 컴퓨팅 유닛에 가 중치를 입력하기 위해 sram_read를 구성하고, 컴퓨팅 유닛에서 행렬 컨볼루션 연산을 수행하고, 계산 결과 를 저장 유닛의 SRAM 메모리에 출력하기 위해 sram_write를 구성하는 것이 필요하다. 이런 방식으로, 계산 모드의 선택이 더욱 유연해진다. 구체적으로, 저장 제어 유닛은 연산자의 텐서 연산에 따라 메모리로부터 데이터 읽기를 제어하고, 이를 컴퓨팅 유닛으로 전송하도록 구성된다. 저장 제어 유닛은 주소 컴퓨팅 모듈(address computing module)을 포함한다. 주소 컴퓨팅 모듈은 소프트웨어 구성 파라미터 data_noc를 수신하기 위한 인 터페이스를 갖는다. 주소 컴퓨팅 모듈은 구성된 파라미터에 따라 단일-계층 읽기 루프 또는 다중-계층 읽 기 루프 중첩으로 메모리의 주소를 계산하여, 계산된 주소에서 요소를 읽고 이를 컴퓨팅 유닛으로 보낸다. 대부분의 인공지능 계산은 정기적으로 어드레스되는데, 예를 들어, 행렬 곱셈, 완전 연결, 컨볼루션 등의 계산 과 관련하여, 데이터가 텐서를 저장하는 주소에서 정기적으로 읽혀진다. 따라서, 소프트웨어 구성 파라미터를 통해 다양하고 복잡한 주소 계산을 구현하는 것이 고려될 수 있다. 실시예에서, 단 하나의 읽기 루프만 설정된 경우, 소프트웨어에 의해 구성된 파라미터는: 하나의 읽기 루프에서 읽기 단계의 수를 나타내는 값, 및 단일-계층 읽기 루프에서 각각의 단계 사이의 스트라이드를 나타내는 값을 포함한다. 실시예에서, 복수의 읽기 루프 중첩(read loop nest)이 설정되는 경우, 소프트웨어에 의해 구성된 파라미터는 다음을 포함한다: 읽기 루프의 각각의 계층에서 읽기 단계 수를 나타내는 값, 읽기 루프의 각각의 계층에서 각 각의 단계들 사이의 스트라이드를 나타내는 값. 각 읽기 루프의 계층은 중첩되는 방식으로 외부 계층에서 내부 계층으로 수행된다. 위에 설명된 복수의 읽기 루프 중첩의 설정은 동일한 텐서 또는 동일한 주소 세그먼트를 저장하는 주소의 여러 읽기를 구현할 수 있으며, 이를 통해 더욱 유연하게 주소를 읽기 위해 다양한 복잡한 주소 계산을 구현한다. 예를 들어, 8-계층 루프 중첩(외부-계층 루프에서 내부-계층 루프로 순차적으로 loop_7로부터 Loop_0까지)을 채 택하는 모드에서 해당 의사코드(pseudocode)는 다음과 같다: loop_7의 경우 1부터 loop_7_cnt_max까지 loop_6의 경우 1부터 loop_6_cnt_max까지 loop_5의 경우 1부터 loop_5_cnt_max까지 loop_4의 경우 1부터 loop_4_cnt_max까지 loop_3의 경우 1부터 loop_3_cnt_max까지 loop_2의 경우 1부터 loop_2_cnt_max까지, loop_1의 경우 1부터 loop_1_cnt_max까지, loop_0의 경우 1부터 loop_0_cnt_max까지, 주소 지정과 관련된 다음의 파라미터는 레지스터에서 구성된다: 각 읽기 루프의 계층에서 읽기 단계 수를 나타 내는 값 loop_xx_cnt_max(여기서 xx는 xx번째 읽기 루프를 나타냄) 및 각 읽기 루프의 계층에서 각각의 단계들 사이의 스트라이드를 나타내는 값 jump_xx_addr(여기서 xx는 xx번째 읽기 루프를 나타냄). 위에서 설명한 8계층 읽기 루프는 다음과 같이 실행된다:우선, 계층 Loop7의 루프에서 loop_7_cnt_max 단계의 전체가 실행되며; 계층 Loop7의 루프의 각각의 단계에서, 계층 Loop6의 루프에서 loop_6_cnt_max 단계의 전체가 실행되며; 계층 Loop6의 루프의 각각의 단계에서, 계층 Loop5의 루프에서 loop_5_cnt_max 단계의 전체가 실행되 며; 계층 Loop5의 루프의 각각의 단계에서, 계층 Loop4의 루프에서 loop_4_cnt_max 단계의 전체가 실행되며; 계 층 Loop4의 루프의 각각의 단계에서, 계층 Loop3의 루프에서 loop_3_cnt_max 단계의 전체가 실행되며; 계층 Loop3의 루프의 각각의 단계에서, 계층 Loop2의 루프에서 loop_2_cnt_max 단계의 전체가 실행되며; 계층 Loop2 의 루프의 각각의 단계에서, 계층 Loop1의 루프에서 loop_1_cnt_max 단계의 전체가 실행되며; 및 계층 Loop1의 루프의 각각의 단계에서, 계층 Loop0의 루프에서 loop_0_cnt_max 단계의 전체가 실행된다. 기본 계층(base layer) Loop0의 루프는 loop_0_cnt_max* loop_1_cnt_max* loop_2_cnt_max* loop_3_cnt_max* loop_4_cnt_max* loop_5_cnt_max* loop_6_cnt_max* loop_7_cnt_max 단계의 전체를 실행하고, 상위 계층(upper layer) Loop1의 루프는 loop_1_cnt_max* loop_2_cnt_max* loop_3_cnt_max* loop_4_cnt_max* loop_5_cnt_max* loop_6_cnt_max* loop_7_cnt_max 단계의 전체를 실행하는 것을 볼 수 있다. 이와 같이, 최상위 계층(top layer) Loop7의 루프는 총 loop_7_cnt_max 단계를 실행한다. 위에서 설정된 바와 같이 8개의 중첩된 루프의 계층은, 추상적인 관점에서 보면 기본 계층에서 최상위 계층으로 의 곱셈 관계로 볼 수 있으며, 즉, 기본 계층의 루프 개수는 모든 상위 계층의 루프의 수의 곱과 같다. 도 4에서 보이는 것처럼, 2차원 공간의 텐서에 2-계층 루프 중첩 읽기를 수행하는 예가 제공된다. 도 4는 본 개 시의 실시예에 따른 입력 텐서에 대해 2-계층 루프 중첩 읽기를 수행하는 예를 나타낸다. 입력 텐서는 이라고 가정되며, 그리고 도 4의 상자 안의 숫자는 입력 텐서의 각각의 요소를 저장 하는 SRAM의 주소를 나타낸다(설명의 편의를 위해, 요소를 저장하는 주소는 그 요소 자체에 대응하는 숫자로 직 접 표기한다). 도 4에서 소프트웨어 구성 파라미터를 통해 읽어야 할(접근해야 할) 주소는 회색 블록이고, 읽기 순서는 0-2-4-6-9-11-13-15라고 가정한다. 그러면 base_address는 시작 주소이고, 이 주소는 컴파일러에서 미리 계산될 수 있으며 일반적으로 SRAM에 입력 텐서가 저장된 주소 세그먼트의 초기 주소이다(즉, 제1 요소가 저장된 위치이며 이 예에서는 주소 0이다). 소프 트웨어에 의해 파라미터 loop_0_cnt_max=4가 구성되었으며, 이는 제1 계층(내부-계층) 읽기 루프의 단계 수가 4 이거나 루프 크기가 4임을 나타낸다. 또 다른 파라미터 jump0_addr=2는 소프트웨어에 의해 구성되는데, 이는 제 1 계층 읽기 루프의 각각의 단계 간 스트라이드는 2임을 나타낸다. 또 다른 파라미터 loop_1_cnt_max=2는 소프 트웨어에 의해 구성되는데, 이는 제2 계층(외부 계층) 읽기 루프의 단계 수가 2이거나 루프 크기가 2임을 나타 낸다. 또 다른 파라미터 jump1_addr=9는 소프트웨어에 의해 구성되는데, 이는 제2 계층 읽기 루프의 각각의 단 계 간 스트라이드가 9임을 나타낸다. 의사코드는 다음과 같다: loop_1의 경우 1에서 2까지 loop_0의 경우 1에서 4까지 각 읽기 루프에 대해 대응하는 카운터 loop_xx_cnt가 설정되며(xx는 xx번째 읽기 루프를 나타냄), 예를 들어, loop_0_cnt는 1에서 4로 순차적으로 증가하고, 예를 들어 loop_1_cnt는 1에서 2로 순차적으로 증가한다. 위의 설명한 구성된 파라미터에 따라, 도 5와 결합하면(도 5는 본 개시의 실시예에 따른 소프트웨어 구성 파라 미터에 따라 주소를 계산하는 개략도를 도시하며, 여기서 sram_addr은 SRAM에 저장된 주소 0~15를 나타냄), 주 소 컴퓨팅 모듈은 다음과 같이 주소를 계산한다: 먼저, 제2 계층(외부 계층) 읽기 루프 loop_1의 1번째 단계(총 2 개의 단계 중)를 실행하여, base_address 초기 주소 0에서 시작하고, 제1 계층(메모리) 읽기 루프 loop_0의 1번째 단계(예: 도 5의 0_0, 총 4개의 단계 중)를 실행하여, 주소 0에서 요소 0을 읽는다. 파라미터 jump0_addr=2는 제1 계층 읽기 루프에서 각각의 단계 사이에2의 스트라이드를 나타내며, 제1 계층(메모리) 읽기 루프 loop_0의 2번째 단계(예: 도 5의 0_1, 총 4개의 단계 중)를 실행하여, 주소 2(주소 0+2)에서 요소 2를 읽으며, 제1 계층(메모리) 읽기 루프 loop_0의 3번째 단계(예: 도 5의 0_2, 총 4개의 단계 중)를 실행하여, 주소 4(주소 2+2)에서 요소 4를 읽으며, 제1 계층(메모리) 읽기 루 프 loop_0의 4번째 단계(예: 도 5의 0_3, 총 4개의 단계 중)를 실행하여, 주소 6(주소 4+2)에서 요소 6을 읽으 며; 및 그런 다음 제1 계층(메모리) 읽기 루프 loop_0의 4개 단계를 완료한다. 다음으로, 제2 계층(외부-계층) 읽기 루프 loop_1의 2번째 단계(전체 2개의 단계 중)를 실행한다. 도 5의 화살 표로 표시된 대로, 제2 계층 읽기 루프의 각각의 단계 사이에 9의 스트라이드를 나타내는 파라미터 jump1_addr=9는, base_address 초기 주소 0+9에서 얻은 주소 9에서 시작하며, 제1 계층(메모리) 읽기 루프 loop_0의 1번째 단계(예: 도 5의 1_0, 총 4개의 단계 중)를 실행하고, 주소 9에서 요소 9를 읽는다. 파라미터 jump0_addr=2는 제1 계층 읽기 루프에서 각각의 단계 사이에 2의 스트라이드를 나타내며, 제1 계층(메모리) 읽 기 루프 loop_0의 2번째 단계(예: 도 5의 1_1, 총 4개의 단계 중)를 실행하여, 주소 11(주소 9+2)에서 요소 11 을 읽으며, 제1 계층(메모리) 읽기 루프 loop_0의 3번째 단계(예: 도 5의 1_2, 총 4개의 단계 중)를 실행하여, 주소 13(주소 11+2)에서 요소 13을 읽으며, 제1 계층(메모리) 읽기 루프 loop_0의 4번째 단계(예: 도 5의 1_3, 총 4개의 단계 중)를 실행하여, 주소 15(주소 13+2)에서 요소 15를 읽는다. 그리고 제1 계층(메모리) 읽기 루프 loop_0의 4개의 단계가 완료된다. 지금까지, 제2 계층(외부 계층) 읽기 루프 loop_1의 총 2개의 단계가 실행되었고, 주소 컴퓨팅 모듈은 주소 계 산과 주소 읽기를 종료한다. 따라서, 요소를 읽는 순서는 0-2-4-6-9-11-13-15이다. 물론, 일 실시예에서 소프트웨어에 의해 구성된 파라미터는: 단일-계층 읽기 루프에서 읽은 제1 요소의 주소와 메모리에 있는 입력 텐서의 초기 주소 사이의 간격의 주소의 수를 나타내는 값을 또한 포함할 수 있다. 이런 방 식으로, 읽기 루프의 각각의 계층의 초기 주소도 유연하게 구성될 수 있다. 위에서 설명한 2-계층 읽기 루프 중첩의 대응하는 파라미터를 소프트웨어로 구성함으로써 SRAM 주소에서 요소를 유연하게 읽을 수 있음을 알 수 있다. 마찬가지로, 읽기 루프 중첩의 2개 이상의 계층을 갖춘 메커니즘이 채택될 수도 있는데, 이는 여기에 국한되지 않다. 위에서 설명한 대로 중첩된 루프의 8개의 계층이 설정되어 있다고 가정하면, 추상적인 관점에서 보면 기본 계층 에서 상위 계층으로의 곱셈 관계로 볼 수 있으며, 즉, 기본 계층의 루프의 수는 모든 상위 계층의 루프 개수의 곱과 같다. 이는 완전히 정렬된 모드이며, 즉, 각각의 중첩 루프 계층은 특정 규칙을 따르므로 읽기 주소도 특 정 규칙을 따른다. 그러나, 특정 시나리오에서, 주소 읽기 순서와 관련하여 불완전하게 정렬된 경우가 있을 수 있으며, 예를 들어, 주소의 한 세그먼트는 제1 규칙을 따르고, 주소의 다른 세그먼트는 제1 규칙과 다른 제2 규칙을 따를 수 있다. 따라서, 2가지의 서로 다른 중첩 루프 모드가 존재할 수 있다. 이러한 경우, 소프트웨어 구성 파라미터는 파라 미터에 특정한 조건을 포함할 수 있으며, 조건이 충족되는 경우와 충족되지 않는 경우 파라미터는 다른 값을 가 질 수 있다. 실시예에서, 파라미터는 읽기 루프의 특정 계층에서 읽기의 단계의 수를 나타내는 값이고, 조건은 특정 계층보 다 더 바깥 계층의 읽기 루프에서 어느 단계로 진행해야 하는지이다. 예를 들어, 하나의 구성은 지정된 읽기 루 프에 추가될 수 있고, 정렬되지 않은 사례를 해결하기 위해 다른 읽기 루프에 바인딩할 수 있다. 예를 들어, Loop5 읽기 루프에 대한 읽기 루프가 선택된 경우, loop_5 읽기 루프로 링크하는 것에 대해, Loop1 읽기 루프에 대해 서로 다른 단계 수를 갖는 loop_1_cnt_max0 및 loop_1_cnt_max1의 2가지 유형의 구성이 있다. loop_7의 경우 1부터 loop_7_cnt_max까지 loop_6의 경우 1부터 loop_6_cnt_max까지 Loop5의 경우 1부터 loop_5_cnt_max까지 Loop4의 경우 1부터 loop_4_cnt_max까지 Loop3의 경우 1부터 loop_3_cnt_max까지 Loop2의 경우 1부터 loop_2_cnt_max까지 { if(loop_5_cnt==loop_5_cnt_max) For Loop1 from 1 to loop_1_cnt_max_1 else For Loop1 from 1 to loop_1_cnt_max_0 } For Loop0 from 1 to loop_0_cnt_max 즉, 소프트웨어 구성 파라미터는 파라미터에 특정한 조건(loop_5_cnt==loop_5_cnt_max)을 포함할 수 있으며(계 층 Loop1의 읽기 루프에서 단계의 수를 나타내는 값, 즉 loop_1_cnt_max), 및 파라미터 loop_1_cnt_max는, 조 건이 충족되는 경우(계층 Loop1의 읽기 루프보다 바깥쪽인 계층 Loop5의 읽기 루프의 마지막 단계로 진행하며, 즉 loop_5_cnt==loop_5_cnt_max이다) 및 조건이 충족되지 않는 경우(loop_5_cnt< >loop_5_cnt_max이다)에, 서 로 다른 값 loop_1_cnt_max_1 및 loop_1_cnt_max_0를 갖는다. 즉, Loop5까지 실행될 때, Loop1은 Loop5의 각각의 단계에서 최소한 한 번씩 실행되며; Loop5가 마지막 단계까 지 실행되지 않는다면, 즉 loop_5_cnt< >loop_5_cnt_max이면, Loop5의 단계에서 실행되는 Loop1의 단계 수는 항상 loop_1_cnt_max_0이다. Loop5가 마지막 단계까지 실행되면, 즉 loop_5_cnt==loop_5_cnt_max이면, Loop5의 단계에서 실행되는 Loop1의 단계 수는 항상 loop_1_cnt_max_1이다. 이런 방식으로, 읽기 위한 주소를 계산하는 모드가 더욱 유연해질 수 있다. 도 6에서 보듯이, 2차원 공간의 텐서에 불완전하게 정렬된 3-계층 루프 중첩 읽기를 수행하는 예가 제공된다. 도 6은 본 개시의 실시예에 따른 입력 텐서에 대해 불완전하게 정렬된 3-계층 루프 중첩 읽기(3-layer loop nest read)를 수행하는 예를 나타낸다. 입력 텐서는 라고 가정되며, 도 6과 같이 SRAM의 주소에 저장된다. 도 6의 상자 안의 숫자는 입 력 텐서의 각각의 요소를 저장하는 SRAM의 주소를 나타낸다(설명의 편의를 위해 요소를 저장하는 주소는 그 자 체로 요소에 대응하는 숫자로 직접 표기하였다). 도 6에서 소프트웨어 구성 파라미터를 통해 읽어야 할(접근해 야 할) 주소는 회색 블록이고, 읽기 순서는 0-8-1-9-2-10-3-11-4-12-16-17-18-19-20이라고 가정한다. 0-8-1-9-2-10-3-11-4-12는 특정 규칙에 따라 완전히 정렬된 모드로 읽히지만, 16-17-18-19-20은 0-8-1-9-2-10- 3-11-4-12를 읽는 모드와 완전히 정렬되지 않은 모드로 읽히는데, 이 모드는 다른 규칙을 따른다. 이 경우, 불 완전하게 정렬된 루프 중첩 읽기를 구현하기 위해 소프트웨어 구성 파라미터를 사용하는 것이 고려된다. 구체적으로, 3-계층 루프 중첩(Loop2, Loop1, Loop0)은 읽어야 할 주소를 계산하고 위에 설명된 읽기 순서를 구 현하도록 설정된다. 소프트웨어에 구성된 파라미터는 다음과 같다: 2는 최상위 계층 Loop2의 단계 수 loop_2_cnt_max이고, 16은 스 트라이드 jump2_addr이고; 5는 최하위 계층 Loop1의 단계 수 loop_0_cnt_max_0이고, 1은 스트라이드 jump1_addr이고; 2는 기본 계층 Loop0의 단계 수 loop_0_cnt_max_0이고, 8은 스트라이드 jump0_addr이고; 그런 다음 구성은 Loop2가 Loop0에 바인딩됨을 지정하고; 및 Loop2가 마지막 단계(loop_2_cnt ==loop_2_cnt_max)로 진행하면, Loop0의 단계 수가 loop_0_cnt_max_0에서 loop_0_cnt_max_1로 변경, 즉 2에서 1로 변경된다는 조건 이 설정된다. 0-8-1-9-2-10-3-11-4-12의 읽기 순서가 1번째 단계에서 실행되고, 16-17-18-19-20의 읽기 순서가 2번째 단계에 서 실행된다는 점을 고려하여, 최상위 계층의 스텝 카운트 loop_2_cnt_max는 2로 설정된다. 2개의 단계가 서로 다른 순서와 다른 규칙에 따라 실행되므로, 다른 읽기 순서를 구현하기 위해 중간-계층 읽기 루프 Loop1과 기본-계층 읽기 루프 Loop0이 2번째 단계에서 어떻게 협력하는지 고려할 필요가 있다. 구체적으로, 위에 설명된 소프트웨어 구성 파라미터에 따라, 루프 중첩의 세 계층이 다음과 같이 주소를 계산하 기 위해 실행된다. 먼저, 최상위 Loop2의 1번째 단계(전체 2개의 단계 중)를 실행하고, 1번째 단계에서 Loop1의 5개의 단계를 실행 한다. Loop1의 1번째 단계에서, Loop0의 모든 단계를 실행하고, 즉, 0에서 시작하여 2개의 단계를 실행하고, 각각의 단계의 스트라이드는 8이므로 먼저 0을 읽은 다음 8을 읽기 위해 8개의 주소를 추가하여, 이러한 2개의 단계에 서, 0-8을 읽는다. Loop1의 2번째 단계에서, 스트라이드는 1이고, 즉 1에서 시작하여 Loop0의 모든 단계를 실행하며, 즉 1에서 시 작하여 2개의 단계를 실행하고, 각각의 단계의 스트라이드는 8이므로 먼저 1을 읽은 다음 9를 읽기 위해 8개의 주소를 추가하여, 이렇게 2개의 단계에서 1~9를 읽는다. Loop1의 3번째 단계에서, 스트라이드가 1이면, 즉 2에서 시작하여 Loop0의 모든 단계를 실행하고, 즉 2에서 시 작하여 2개의 단계를 실행하고, 각각의 단계의 스트라이드가 8이면, 먼저 2를 읽은 다음 10을 읽기 위해 8개의 주소를 추가하여, 이렇게 2개의 단계에서 2-10을 읽는다. Loop1의 4번째 단계에서, 스트라이드가 1이면, 즉 3에서 시작하여 Loop0의 모든 단계를 실행하고, 즉 3에서 시 작하여 2개의 단계를 실행하고, 각각의 단계의 스트라이드가 8이면, 먼저 3을 읽은 다음 11을 읽기 위해 8개의 주소를 추가하여, 이렇게 2개의 단계에서 3~11을 읽는다. Loop1의 5번째 단계에서, 스트라이드가 1이면, 즉 4에서 시작하여 Loop0의 모든 단계를 실행하고, 즉 4에서 시 작하여 2개의 단계를 실행하고, 각각의 단계의 스트라이드가 8이면, 먼저 4를 읽은 다음 12를 읽기 위해 8개의 주소를 추가하여, 이렇게 2개의 단계에서 4-12를 읽는다. 그런 다음, 최상위 계층 Loop2의 2번째 단계(전체 2개의 단계 중)를 실행하는데, 초기 주소 9에서 시작하여 16 의 스트라이드를 추가하며, 즉, 16으로부터 읽는다. 이때, 조건 loop_2_cnt ==loop_2_cnt_max이 충족된다. 따라서, Loop0의 단계 수는 loop_0_cnt_max_1이며, 이는 더 이상 2개의 단계가 아니라 1개의 단계이다. 2번째 단계에서, Loop1의 5개의 단계를 실행하고, Loop1의 각각 의 단계에서, 단계 수가 1인 Loop0 읽기 루프를 실행한다. 구체적으로, Loop1의 1번째 단계에서, Loop0의 모든 단계를 실행하고, 즉 16에서 시작하여 1개의 단계를 실행하 는데, 이는 한 번만 읽고, 그 후에는 스트라이드 8을 더 이상 사용하지 않으므로 16만 읽는다. Loop1의 2번째 단계에서, 스트라이드는 1이고, 즉 16+1=17에서 시작하여 Loop0의 1개의 단계를 실행하므로 17을 읽는다. Loop1의 3번째 단계에서, 스트라이드는 1이고, 즉 17+1=18에서 시작하여 Loop0의 1개의 단계를 실행하므로 18을 읽는다. Loop1의 4번째 단계에서, 스트라이드는 1이고, 즉 18+1=19에서 시작하여 Loop0의 1개의 단계를 실행하므로 19를 읽는다. Loop1의 5번째 단계에서, 스트라이드는 1이고, 즉 19+1=20에서 시작하여 Loop0의 1개의 단계를 실행하므로 20을 읽는다. 이런 방식으로, 소프트웨어 구성 파라미터를 통해 3-계층 읽기 루프 중첩은 복잡한 주소 읽기 순서 0-8-1-9-2- 10-3-11-4-12-16-17-18-19-20을 구현할 수 있다. 물론, 위의 설명은 단지 특정 계층보다 더 바깥 계층의 읽기 루프에서 어느 단계로 진행할지 조건을 설정하는 예시일 뿐이고, 조건이 만족되는 경우와 만족되지 않는 경우 각각 특정 계층의 읽기 루프에서 다른 단계 수를 설정한다. 그러나, 본 개시는 이에 한정되지 않는다. 더 복잡한 주소 읽기 순서를 보다 유연하게 구현하기 위해, 다른 조건과 해당 조건을 충족하는 다른 파라미터의 변경을 고려할 수 있다. 따라서, 본 개시에 따른 소프트웨어 구성 파라미터는 메모리의 주소가 유연하게 계산되고, 계산된 주소에서 요 소를 읽어 컴퓨팅 유닛으로 전송할 수 있도록 하여 유연한 주소 읽기 모드를 구현하고, 계산 효율성을 높이고, 인공지능 프로세서 칩의 비용을 절감할 수 있으며, 어떤 경우에는 인공지능 계산에서 특정 텐서 연산을 그 자체로 대체하여 운영자의 연산을 단순화할 수도 있다. 읽기 루프 중첩의 특정 주소 계산과 관련하여, 일 실시예에서 현재 읽어야 하는 주소는 단일-계층 읽기 루프 또 는 각각의 읽기 루프 계층에서 현재 진행 중인 단계와 단일-계층 읽기 루프 또는 각각의 읽기 루프 계층의 각각 의 스트라이드에 따라 계산된다. 구체적으로, 소프트웨어에 의해 구성된 위의 설명된 파라미터에 따라, SRAM에서 최종적으로 읽어올 주소의 주소 계산과 관련하여, 주소 컴퓨팅 유닛은 다중-차원(읽기 루프) 공간 좌표계에서 점의 위치를 결정하는 접근 방식 과 유사한 모드로 매번 읽혀지는 주소 Address를 계산할 수 있다. Address = base_address + offset_address_dim; base_address는 컴파일러에 의해 미리 계산될 수 있으며, 일반적으로 이는 SRAM에 입력 텐서가 저장된 주소 세 그먼트의 초기 주소(즉, 제1 요소가 저장된 위치)인 반면 offset_address_dim은 각각의 차원(읽기 루프)의 주소 오프셋 합계이다: offset_address_dim = offset_addr_0 + offset_addr_1 + offset_addr_2 + offset_addr_3 + offset_addr_4 + offset_addr_5 + offset_addr_6 + offset_addr_7 여기서, offset_addr_xx는 xx번째 계층 읽기 루프의 초기 주소의 오프셋을 상위 계층 읽기 루프의 초기 주소(또 는 최상위 계층 읽기 루프의 경우 base_address)를 기준으로 나타낸다. 즉, 각각에 대해 차원에 대해 offset_address_xx = (loop_xx_counter -1)* jump_xx_addr이고, 여기서, loop_xx_counter는 현재 xx번째 계층 읽기 루프에서 진행 중인 단계를 나타낸다. 즉, 주소 컴퓨팅 모듈이 실제로 주소를 계산할 때, 현재 단일-계층 읽기 루프 또는 각각의 읽기 루프의 계층에 서 어느 단계를 진행하고 있는지, 그리고 단일-계층 읽기 루프 또는 각각의 읽기 루프의 계층의 각각의 스트라 이드만 알면, 현재 읽어야 할 주소를 파악할 수 있다. 도 7은 본 개시의 실시예에 따른 SRAM의 내부 구조의 개략도를 나타낸다. 또한, SRAM은 여러 개의 뱅크(bank)로 나눌 수도 있다. 데이터 쓰기 및 읽기 속도를 높이기 위해, 외부 소스에 서 작성된 데이터가 다른 뱅크에 직접 배치될 수 있으며, 읽어온 데이터, 중간 계산 데이터, 결과 데이터도 다 른 뱅크에 직접 배치될 수 있다. SRAM의 주소 지정 모드도 구성 가능하다. 기본적으로, 주소의 최상위 비트는 다양한 은행을 구별하는 데 사용될 수 있으며, 다른 세분성(granularities)의 인터리빙은 구성 가능한 주소 해 싱(configurable address hashing)을 통해서도 수행될 수 있다. 하드웨어 설계 관점에서 볼 때, 다중-비트 뱅크 선택 신호(multi-bit bank selection signal) bank_sel은, 서로 다른 SRAM 뱅크 sram_bank(sram_bank0~sram_bank3 등)을 선택하기 위해, port0, port1, port2, port3 등과 같은 각각의 포트의 데이터에 대해 최종적으로 생성된다. 핸드셰이크 신호(Handshake signals)는 다중-포트 액세스에 채택될 수 있으며, 데이터 파이프라인은 백프레셔 (backpressure)를 지원한다(입구 유량이 출구 유량보다 큰 경우 백프레셔가 필요하거나 다운스트림 단계가 준비 되지 않은 경우 현재 단계에서 데이터 전송을 수행하는 경우 업스트림 단계에 백프레셔를 적용해야 하므로 업스 트림 단계는 데이터를 업데이트하기 전에 핸드셰이크가 성공할 때까지 데이터를 고정 상태로 유지해야 함). 저 장 제어 유닛은 분리되어 있고 SRAM의 복수의 뱅크에 병렬로 액세스할 수 있는 읽기 기능과 쓰기 기능을 갖는 크로스바 구조(crossbar structure)를 포함하는데, 이는 크로스바의 2개의 스테이지의 캐스케이드 모드와 동일하여 하드웨어 구현 시 배선 문제를 완화한다. 단일-포트 SRAM(Single-port SRAM)은 사용되어 전력과 면적 을 절약하기 위해 기본-계층 메모리(base-layer memory)에서 사용된다. 크로스바 구조는, 각각 읽어온 데이터, 중간 결과 데이터, 최종 결과 데이터를 저장하는 복수의 뱅크에 병렬 또는 동시에 액세스하여, 인공지능 칩의 읽기 및 쓰기 속도를 더욱 가속화하고 운영 효율성을 향상시킬 수 있다. 이런 방식으로, 다양한 텐서 연산은 주소를 계산하기 위해 주소 컴퓨팅 모듈과 협력하여 소프트웨어 구성 파라 미터로 직접 대체될 수 있다. 더욱이, 하나 이상의 루프 중첩의 주소 계산 프로세스가 설정되며, 이는, 입력 텐 서의 각각의 수치 값을 저장하는 순차적인 주소 그 자체에 제한 없이, 주소 컴퓨팅 모듈에서 계산된 읽기 주소 를 보다 유연하게 만들 수 있다. 또한, 연산자의 연산을 직접 대체하여 기존 기술에서 연산자의 연산을 계산하 는 데 드는 시간과 하드웨어 비용, 연산자의 연산 결과 텐서를 저장하는 데 드는 시간과 하드웨어 비용, 연산자 의 연산 결과 텐서를 저장하는 주소에서 각각의 요소를 읽어내는 데 드는 시간과 하드웨어 비용을 절감할 수 있 어, 계산 지연 시간을 줄이고, 하드웨어 계산 비용을 절감하며, 인공지능 칩의 운영 효율성을 향상시킬 수있다."}
{"patent_id": "10-2025-7001387", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "요약하자면, 데이터 파이프라인과 컴퓨팅 파이프라인을 별도로 구성함으로써, 소프트웨어를 완벽하게 제어하여 유연성을 극대화할 수 있다. 다중-계층 읽기 루프를 통한 주소 지정 모드는 다양하고 복잡한 주소 접근 패턴을 구현할 수 있다. 다중-계층 비대칭 루프(multi-layer asymmetric loop)의 모드는 비정렬 구성을 구현할 수 있어, 더욱 복잡한 주소 접근 패턴을 구현한다. 공유되는 온칩 메모리는 여러 개의 뱅크로 분할되고, 뱅크 간의 주소 지정 모드는 소프트웨어를 통해 유지된다. 데이터 파이프라인을 컴퓨팅 파이프라인에서 분리함으로써, 데 이터 접근의 유연성이 보장된다. 한편, 데이터 이동과 컴퓨팅 파이프라인은, 서로 다른 모듈의 동시성 효과를 얻기 위해, 서로 숨길 수 있다. 컴파일러에 의한 합리적인 중간 데이터 분할을 통해, SRAM의 서로 다른 뱅크는 서로 다른 유형의 데이터를 저장하며, 예를 들어, 동시에 액세스할 수 있는 서로 다른 유형의 데이터를 저장할 수 있어, 이를 통해 이러한 데이터 조각에 동시에 액세스해야 하는 경우 이러한 데이터 조각을 SRAM의 서로 다 른 뱅크에서 병렬로 읽어서 효율성을 높일 수 있다. 계산을 시작한 후, 컨볼루션 계산의 미디어 액세스 제어 (Media Access Control)(MAC) 주소 사용률은 거의 100%에 도달할 수 있다. 도 8은 본 개시의 실시 예에 따른 인공지능의 프로세서 칩에서 데이터에 유연하게 접근하는 방법의 흐름도를 나 타낸다. 도 8에 도시된 바와 같이, 인공지능의 프로세서 칩에서 데이터를 유연하게 접근하기 위한 방법은: 단계 801에서, 인공지능의 프로세서 칩 내의 메모리를 통해, 프로세서 칩 외부에서 읽어온 텐서 데이터를 저장하는 (storing) 단계 - 읽어온 텐서 데이터는 인공지능 계산에 포함된 연산자의 텐서 연산을 수행하기 위한 복수의 요소를 포함함 -; 단계 802에서, 컴퓨팅 유닛으로 요소를 보내기 위해 연산자의 텐서 연산에 따라 메모리로부터 읽기 요소를 제어하는(controlling) 단계 - 계산된 주소에서 요소를 읽고 인공지능의 프로세서 칩에 있는 컴퓨 팅 유닛(computing unit)으로 요소를 보내게 하도록, 소프트웨어에 의해 구성되고 수신되는 파라미터에 따라 단 일-계층 읽기 루프 또는 다중-계층 읽기 루프 중첩의 메모리의 주소를 계산하는(computing) 단계를 포함함 -; 및 단계 803에서, 컴퓨팅 유닛에 의해, 수신된 요소를 사용하여 연산자의 텐서 연산을 수행하는(performing) 단 계를 포함한다. 따라서, 소프트웨어 구성 파라미터는, 이러한 요소를 저장하는 순서나 메모리의 주소 분류에 제한 없이, 메모리 의 주소를 유연하게 계산하기 위해 사용될 수 있다. 실시예에서, 소프트웨어에 의해 구성된 파라미터는: 단일-계층 읽기 루프에서 읽어온 텐서 데이터로부터 읽어올 요소의 수를 나타내는 값, 및 단일-계층 읽기 루프에서 각각의 단계 사이의 스트라이드를 나타내는 값을 포함한 다. 실시예에서, 소프트웨어에 의해 구성된 파라미터는: 각각의 읽기 루프의 계층에서 읽기 단계 수를 나타내는 값, 및 각각의 읽기 루프의 계층에서 각각의 단계들 사이의 스트라이드를 나타내는 값을 포함한다. 각 읽기 루프의 계층은 중첩되는 방식으로 외부 계층에서 내부 계층으로 수행된다. 실시예에서, 소프트웨어에 의해 구성된 파라미터는: 단일-계층 읽기 루프에서 읽은 제1 요소의 주소와 메모리에 있는 입력 텐서의 초기 주소 사이의 간격의 주소의 수를 나타내는 값을 포함한다. 실시예에서, 소프트웨어에 의해 구성된 파라미터는 파라미터에 특정한 조건을 포함하고, 파라미터는 조건이 충 족되는 경우와 조건이 충족되지 않는 경우에 서로 다른 값을 갖는다. 실시예에서, 파라미터는 읽기 루프의 특정 계층에서 읽기 단계 수를 나타내는 값이고, 조건은 특정 계층보다 바 깥쪽에 있는 읽기 루프의 다른 계층에서 어느 단계로 진행해야 하는지이다. 실시예에서, 방법 800은 또한 다음을 포함한다: 단일-계층 읽기 루프 또는 각각의 읽기 루프의 계층에서 현재 진행 중인 단계와 단일-계층 읽기 루프 또는 각각의 읽기 루프의 계층의 각각의 스트라이드에 따라 현재 읽어야 하는 주소를 계산한다. 이런 방식으로, 읽기 위한 주소를 계산하는 모드가 더욱 유연해질 수 있다. 실시예에서, 소프트웨어에 의해 구성된 파라미터는 연산자의 텐서 연산이 연산자의 텐서 연산에 따라 메모리의 주소에서 요소를 읽는 모드로 대체됨을 나타낸다. 일 구현예에서, 텐서 연산은 입력 텐서의 숫자 값을 변경하지 않는 텐서 조작(tensor manipulation)이다. 매번 읽어야 하는 메모리의 주소는 인터페이스를 통해 수신된 구성된 파라미터에 따라 단일-계층 읽기 루프 또는 다중-계층 읽기 루프 중첩으로 계산되므로, 텐서 조작이 읽기로 대체된다. 실시예에서, 텐서 연산(tensor operations)은: 전치 연산자의 연산, 재성형 연산자의 연산, 브로드캐스트 연산 자(broadcast operator)의 연산, 수집 연산자(gatherer operator)의 연산, 역방향 연산자(reverse operator)의 연산, 컨캣 연산자(concat operator)의 연산, 및 캐스트 연산자(cast operator)의 연산으로 구성된 그룹에서 적 어도 하나를 포함한다. 이런 방식으로, 소프트웨어 구성 파라미터는 컴퓨팅 유닛이 계산된 주소 순서에서 계산된 주소의 위치에 저장된 주소를 대응하게 읽도록 하는 데 사용되며, 이는 일부 텐서 연산자의 연산을 직접 대체할 수 있으므로, 기존 기 술에서 이들 텐서 연산자의 연산을 계산하는 데 드는 시간과 하드웨어 비용, 이들 텐서 연산자의 연산 결과 텐 서를 저장하는 데 드는 시간과 하드웨어 비용, 그리고 이들 텐서 연산자의 연산 결과 텐서를 저장하는 주소에서 각각의 요소를 읽는 데 드는 시간과 하드웨어 비용을 절약할 수 있다. 일 실시예에서, 메모리는 각각 병렬로 접근할 수 있는 데이터를 저장하기 위한 복수의 뱅크로 나뉜다. 이 방법 은 분리된 읽기 기능과 쓰기 기능을 갖는 크로스바를 통해 메모리의 복수의 뱅크에 저장된 데이터에 병렬로 액 세스하는(accessing) 단계를 더 포함한다. 이런 방식으로, 다양한 텐서 연산은 계산된 주소와 협력하는 소프트웨어 구성 파라미터로 직접 대체될 수 있다. 더욱이, 하나 이상의 루프 중첩의 주소 계산 프로세스가 설정되며, 이는, 입력 텐서의 각각의 수치 값을 저장하 는 순차적인 주소그 자체 에 제한 없이, 계산된 읽기 주소를 보다 유연하게 만들 수 있다. 또한, 연산자의 연산 을 직접 대체하여 기존 기술에서 연산자의 연산을 계산하는 데 드는 시간과 하드웨어 비용, 연산자의 연산 결과 텐서를 저장하는 데 드는 시간과 하드웨어 비용, 연산자의 연산 결과 텐서를 저장하는 주소에서 각각의 요소를 읽어내는 데 드는 시간과 하드웨어 비용을 절감할 수 있어, 계산 지연 시간을 줄이고, 하드웨어 계산 비용을 절 감하며, 인공지능 칩의 운영 효율성을 향상시킬 수 있다. 도 9는 본 개시의 실시예를 구현하는 데 적합한 예시적인 전자 디바이스의 블록도를 나타낸다. 전자 디바이스(electronic device)는 프로세서(processor)(H1)와 저장 매체(storage medium)(H2)를 포함할 수 있으며, 이는 프로세서(H1)에 결합되어 있으며, 프로세서에 의해 실행될 때 본 개시의 실시예에 따른 각각의 방 법의 단계를 수행하기 위한 컴퓨터 실행가능 명령들(computer-executable instructions)이 저장된다. 프로세서(H1)는, 예를 들어 하나 이상의 프로세서 또는 마이크로프로세서를 포함할 수 있지만 이에 국한되지 않 는다. 저장 매체(H2)는, 예를 들어, 랜덤 액세스 메모리(RAM), 리드 온리 메모리(ROM), 플래시 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 컴퓨터 저장 매체(예: 하드 드라이브, 플로피 디스크, 솔리드 스테이트 드라이브, 이 동식 디스크, CD-ROM, DVD-ROM, 블루 디스크 등)를 포함할 수 있지만 이에 국한되지 않는다. 또한, 전자 디바이스는 데이터 버스(data bus)(H3), 입출력(I/O) 버스(input/output (I/O) bus)(H4), 디스플레 이(display)(H5) 및 입출력 장치(input/output device)(H6)(예: 키보드, 마우스, 스피커 등)를 추가로 포함할 수 있다. 프로세서(H1)는 I/O 버스(H4)를 통해 유선 또는 무선 네트워크(도시되지 않음)를 통해 외부 장치(H5, H6 등)와 통신할 수 있다. 저장 매체(H2)에는 또한, 프로세서(H1)에 의해 실행될 때 본 개시에 설명된 실시 예에 따른 각각의 기능 및/또 는 방법의 단계를 실행하기 위해, 적어도 하나의 컴퓨터 실행가능 명령(computer executable instruction)이 저 장되어 있을 수 있다. 일 실시예에서, 적어도 하나의 컴퓨터 실행가능 명령은 소프트웨어 제품으로 컴파일되거나 소프트웨어 제품을 구성할 수도 있으며, 하나 이상의 컴퓨터 실행가능 명령들은, 프로세서에 의해 실행될 때, 본 개시에 설명된 실 시예에 따른 각각의 기능 및/또는 방법의 단계를 실행한다. 도 10은 본 개시의 실시예에 따른 비일시적 컴퓨터 판독가능 저장 매체(non-transitory computer-readable storage medium)의 개략도를 나타낸다. 도 16에 도시된 바와 같이, 컴퓨터 판독가능 저장 매체(computer readable storage medium)에는 명령들 (instructions)이 저장되어 있으며, 이 명령들은 예를 들어 컴퓨터 판독가능 명령들(computer-readable instructions)이다. 컴퓨터 판독가능 명령은, 프로세서에 의해 실행될 때, 위에 설명된 각각의 방법을 실행할 수 있다. 컴퓨터 판독가능 저장 매체는, 예를 들어 휘발성 메모리 및/또는 비휘발성 메모리가 포함 되지만 이에 국한되지는 않는다. 휘발성 메모리(volatile memory)는, 예를 들면, 램(RAM) 및/또는 캐시 등을 포 함할 수 있다. 비휘발성 메모리는, 예를 들어, 리드 온리 메모리(Read-Only Memory)(ROM), 하드 디스크 및 플래 시 메모리를 포함할 수 있다. 예를 들어, 컴퓨터 판독가능 저장 매체는 컴퓨터와 같은 컴퓨팅 장치에 결 합될 수 있으며; 다음으로, 컴퓨팅 장치가 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 판독가능 명령 을 실행하는 경우, 위에 설명된 각각의 방법이 실행될 수 있다. 본 개시는 다음의 항목을 제공한다. 항목 1. 데이터에 유연하게 접근하기 위한 인공지능 프로세서 칩은: 프로세서 칩 외부에서 읽어온 텐서 데이터를 저장하도록 구성된 메모리 - 읽어온 텐서 데이터는 인공지능 계산 에 포함된 연산자의 텐서 연산을 수행하기 위한 복수의 요소를 포함함 -; 컴퓨팅 유닛으로 요소를 보내기 위해 연산자의 텐서 연산에 따라 메모리로부터 읽기 요소를 제어하도록 구성된, 저장 제어 유닛(storage control unit) - 여기서 저장 제어 유닛은 주소 컴퓨팅 모듈을 포함하고, 주소 컴퓨팅 모듈은 소프트웨어에 의해 구성된 파라미터를 수신하기 위한 인터페이스를 갖고, 및 주소 컴퓨팅 모듈은 인터페 이스에서 수신된 구성된 파라미터에 따라 단일-계층 읽기 루프 또는 다중-계층 읽기 루프 중첩의 메모리에 있는 주소를 계산하여, 계산된 주소에서 요소를 읽고 해당 요소를 컴퓨팅 유닛으로 보냄 -; 및 수신된 요소를 사용하여 연산자의 텐서 연산을 수행하도록 구성된, 컴퓨팅 유닛을 포함한다. 항목 2. 항목 1에 따른 프로세서 칩에서, 여기서 소프트웨어에 의해 구성된 파라미터는: 단일-계층 읽기 루프에서 읽어온 텐서 데이터로부터 읽어올 요소 의 수를 나타내는 값, 및 단일-계층 읽기 루프에서 각각의 단계 사이의 스트라이드를 나타내는 값을 포함하고; 또는 소프트웨어에 의해 구성된 파라미터는: 각각의 읽기 루프의 계층에서 읽기 단계의 수를 나타내는 값, 및 각각의 읽기 루프의 계층에서 각각의 단계들 사이의 스트라이드를 나타내는 값을 포함하고, 여기서 각각의 읽기 루프의 계층은 중첩되는 방식으로 외부 계층에서 내부 계층으로 수행된다. 항목 3. 항목 1에 따른 프로세서 칩에서, 여기서 소프트웨어에 의해 구성된 파라미터는: 단일-계층 읽기 루프에 서 읽은 제1 요소의 주소와 메모리에 있는 입력 텐서의 초기 주소 사이의 간격의 주소의 수를 나타내는 값을 포 함한다. 항목 4. 항목 1에 따른 프로세서 칩에서, 여기서 소프트웨어에 의해 구성된 파라미터는 파라미터에 특정한 조건 을 포함하고, 조건이 충족될 때와 조건이 충족되지 않을 때 파라미터는 다른 값을 갖는다. 항목 5. 항목 1에 따른 프로세서 칩에서, 여기서 파라미터는 특정 계층의 읽기 루프에서 여러 단계를 나타내는 값이고, 조건은 특정 계층보다 바깥쪽의 다른 계층의 읽기 루프에서 읽기가 어느 단계로 진행되는지이다. 항목 6. 2~5항목 중 어느 하나에 따른 프로세서 칩에서, 여기서 주소 컴퓨팅 모듈은 단일-계층 읽기 루프 또는 각각의 읽기 루프의 계층에서 현재 진행 중인 단계와 단일-계층 읽기 루프 또는 각각의 읽기 루프의 계층의 각 각의 스트라이드에 따라 현재 읽어야 하는 주소를 계산한다. 항목 7. 항목 1에 따른 프로세서 칩에서, 여기서 소프트웨어에 의해 구성된 파라미터는 연산자의 텐서 연산이 연산자의 텐서 연산에 따라 메모리의 주소에서 요소를 읽는 모드로 대체됨을 나타낸다. 항목 8. 항목 7에 따른 프로세서 칩에서, 여기서 텐서 연산은 입력 텐서의 수치 값을 변경하지 않는 텐서 조작 일 수 있으며, 주소 컴퓨팅 모듈은 인터페이스를 통해 수신된 구성된 파라미터에 따라 단일-계층 읽기 루프 또 는 다중-계층 읽기 루프 중첩에서 매번 읽을 메모리의 주소를 계산하여, 텐서 조작이 읽기로 대체되도록 한다. 항목 9. 항목 8에 따른 프로세서 칩에서, 여기서 텐서 연산은: 전치 연산자의 연산, 재성형 연산자의 연산, 브 로드캐스트 연산자의 연산, 수집 연산자의 연산, 역방향 연산자의 연산, 컨캣 연산자의 연산, 및 캐스트 연산자 의 연산으로 구성된 그룹에서 적어도 하나를 포함하고, 여기서 메모리는 병렬로 접근할 수 있는 데이터를 각각 저장하기 위한 복수의 뱅크로 나뉘고, 및 저장 제어 유닛은, 메모리의 복수의 뱅크에 저장된 데이터에 병렬로 액세스할 수 있도록, 분리된 읽기 기능과 쓰기 기능을 갖는 크로스바를 포함한다. 항목 10. 인공지능의 프로세서 칩에서 데이터에 유연하게 접근하기 위한 방법으로, 인공지능의 프로세서 칩 내의 메모리를 통해, 프로세서 칩 외부에서 읽어온 텐서 데이터를 저장하는 단계 - 읽 어온 텐서 데이터는 인공지능 계산에 포함된 연산자의 텐서 연산을 수행하기 위한 복수의 요소를 포함함 -; 컴퓨팅 유닛으로 요소를 보내기 위해 연산자의 텐서 연산에 따라 메모리로부터 읽기 요소를 제어하는 단계 - 계 산된 주소에서 요소를 읽고 인공지능의 프로세서 칩에 있는 컴퓨팅 유닛으로 요소를 보내게 하도록, 소프트웨어 에 의해 구성되고 수신되는 파라미터에 따라 단일-계층 읽기 루프 또는 다중-계층 읽기 루프 중첩의 메모리의 주소를 계산하는 단계를 포함함 -; 및 컴퓨팅 유닛에 의해, 수신된 요소를 사용하여 연산자의 텐서 연산을 수행하는 단계를 포함한다. 항목 11. 항목 10에 따른 방법에서, 여기서 소프트웨어에 의해 구성된 파라미터는: 단일-계층 읽기 루프에서 읽어온 텐서 데이터로부터 읽어올 요소 의 수를 나타내는 값, 및 단일-계층 읽기 루프에서 각각의 단계 사이의 스트라이드를 나타내는 값을 포함하고; 또는 소프트웨어에 의해 구성된 파라미터는: 각각의 읽기 루프의 계층에서 읽기 단계의 수를 나타내는 값, 각각의 읽 기 루프의 계층에서 각각의 단계들 사이의 스트라이드를 나타내는 값을 포함할 수 있으며, 여기서 각각의 읽기 루프의 계층은 중첩되는 방식으로 외부 계층에서 내부 계층으로 수행된다. 항목 12. 항목 10에 따른 방법에서, 여기서 소프트웨어에 의해 구성된 파라미터는: 단일-계층 읽기 루프에서 읽 은 제1 요소의 주소와 메모리에 있는 입력 텐서의 초기 주소 사이의 간격의 주소의 수를 나타내는 값을 포함한 다. 항목 13. 항목 10에 따른 방법에서, 여기서 소프트웨어에 의해 구성된 파라미터는 파라미터에 특정한 조건을 포 함하고, 조건이 충족될 때와 조건이 충족되지 않을 때 파라미터는 서로 다른 값을 갖는다. 항목 14. 항목 13에 따른 방법에서, 여기서 파라미터는 읽기 루프의 특정 계층에서 읽기의 단계 수를 나타내는 값이고, 조건은 특정 계층보다 바깥쪽의 다른 계층에서 읽기가 어느 단계로 진행되는 지이다. 항목 15. 항목 11 내지 14 중 하나에 따른 방법에서, 단일-계층 읽기 루프 또는 각각의 읽기 루프의 계층에서 현재 진행 중인 단계와 단일-계층 읽기 루프 또는 각각 의 읽기 루프의 계층의 각각의 스트라이드에 따라 현재 읽어야 하는 주소를 계산하는 단계를 더 포함한다. 항목 16. 항목 10에 따른 방법에서, 여기서 소프트웨어에 의해 구성된 파라미터는 연산자의 텐서 연산이 연산자 의 텐서 연산에 따라 메모리의 주소에서 요소를 읽는 모드로 대체됨을 나타낸다. 항목 17. 항목 16에 따른 방법에서, 여기서 텐서 연산은 입력 텐서의 숫자 값을 변경하지 않는 텐서 조작이고, 및 매번 읽어야 하는 메모리의 주소는 인터페이스를 통해 수신된 구성된 파라미터에 따라 단일-계층 읽기 루프 또는 다중-계층 읽기 루프 중첩으로 계산되므로, 텐서 조작이 읽기로 대체된다. 항목 18. 항목 17에 따른 방법에서, 여기서 텐서 연산은: 전치 연산자의 연산, 재성형 연산자의 연산, 브로드캐 스트 연산자의 연산, 수집 연산자의 연산, 역방향 연산자의 연산, 컨캣 연산자의 연산, 및 캐스트 연산자의 연 산으로 구성된 그룹에서 적어도 하나를 포함하고, 여기서 메모리는 병렬로 접근할 수 있는 데이터를 각각 저장 하기 위한 복수의 뱅크로 나뉘고, 및 방법은 분리된 읽기 기능과 쓰기 기능을 갖는 크로스바를 통해 메모리의 복수의 뱅크에 저장된 데이터에 병렬로 액세스하는 단계를 더 포함한다. 항목 19. 전자 디바이스에 있어서, 명령들을 저장하도록 구성된, 메모리; 및 10~18항목 중 어느 하나에 따라 메모리로부터 명령들을 읽고 방법을 실행하도록 구성된, 프로세서를 포함한다. 항목 20. 비일시적 저장 매체에서, 여기서 명령들은 비일시적 저장 매체에 저장되고, 및 명령들은, 프로세서에 의해 읽혀질 때, 프로세서로 하여금, 항목 10~18 중 하나에 따라 방법을 실행하게 한다. 물론, 위에 설명한 구체적인 실시예는 단지 예시일 뿐 제한이 아니며, 본 발명의 개념에 따라 당해 기술 분야의"}
{"patent_id": "10-2025-7001387", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "숙련자라면 위에 별도로 설명한 각각의 실시예의 일부 단계 및 장치를 병합하고 결합하여 본 발명의 효과를 구 현할 수 있다. 이러한 병합되고 결합된 실시예도 본 개시내용에 포함되며, 여기서는 자세한 내용을 반복하지 않는다. 본 개시에서 언급된 이점 및 효과 등은 단지 예시일 뿐이며 제한 사항이 아니며, 본 개시의 각각의 실시예에 필 수적인 것으로 간주될 수 없음을 유의해야 한다. 또한, 위에 개시된 구체적인 내용은 단지 예시를 제공하고 이 해를 돕기 위한 목적일 뿐, 제한적인 것은 아니다. 위의 세부 사항은 본 개시가 위의 설명한 구체적인 세부 사 항을 구현하기 위해 사용해야 하는 필요성을 제한하지 않는다. 본 개시에 포함된 장치, 기구, 장비 및 시스템의 블록 다이어그램은 단지 설명적인 예일 뿐이며, 블록 다이어그 램에 표시된 방식으로 연결, 배치 또는 구성되어야 함을 요구하거나 암시하는 것이 아니다. 해당 기술 분야 종 사자라면 이러한 디바이스, 장치, 장비 및 시스템이 임의의 모드로 연결, 배치 및 구성될 수 있다는 사실을 알 고 있을 것이다. \"포함하다\", \"구성하다\", \"갖다\" 등의 단어는 \"포함하지만 이에 국한되지 않다\"는 의미의 개방 형 용어이며 서로 바꿔 사용할 수 있다. 여기에서 사용된 \"또는\"과 \"그리고\"라는 용어는 \"그리고/또는\"이라는 단어를 지칭하며, 문맥상 명확히 달리 명시되지 않는 한 서로 바꿔 사용할 수 있다. 여기에서 사용된 \"예를 들 면\" 및 \"예를 들면\"이라는 용어는 \"예를 들면, 그러나 이에 국한되지 않음\"이라는 문구를 지칭하며 후자와 상호 교환적으로 사용될 수 있다. 본 개시의 단계별 흐름도와 위의 방법 설명은 단지 설명적인 예일 뿐이며, 각각의 실시예의 단계가 주어진 순서 에 따라 수행되어야 함을 요구하거나 암시하는 것은 아니다. 해당 기술 분야 종사자라면 알겠지만, 위의 실시예 의 단계는 임의의 순서로 수행될 수 있다. \"이후\", \"그 다음\", \"다음\" 등의 단어는 단계의 순서를 제한하려는 것이 아니며; 이러한 단어는 단지 독자가 이러한 방법을 설명하도록 안내하는 데 사용된다. 또한, \"하나\", \"한\", \"한개\", \"그\"와 같은 관사를 사용하여 단수 요소를 참조하는 것은 해당 요소를 단수로 제한하는 것으로 해석되지 않는다. 또한, 여기 각각의 실시예에 따른 단계 및 장치는 특정 실시예에만 구현되도록 한정되지 않는다. 실제로, 본 발 명의 개념에 따라 새로운 실시예가 각각의 실시예에 따른 단계 및 장치의 관련 부분과 연계하여 구상될 수 있으 며, 이러한 새로운 실시예도 본 발명의 범위에 포함된다. 위에 기술된 방법의 각각의 연산은 대응하는 기능을 수행할 수 있는 적절한 수단을 통해 수행될 수 있다. 이러 한 수단에는 하드웨어 회로, 주문형 집적 회로(application-specific integrated circuits)(ASICs) 또는 프로 세서를 포함하되 이에 국한되지 않는 다양한 하드웨어 및/또는 소프트웨어 구성 요소 및/또는 모듈이 포함될 수 있다. 여기에 설명된 기능을 수행하도록 설계된 범용 프로세서, 디지털 신호 프로세서(DSP), ASIC, 필드 프로그래밍 가능 게이트 어레이(FPGA) 신호 또는 기타 프로그래밍 가능 논리 장치(PLD), 개별 게이트 또는 트랜지스터 논리, 개별 하드웨어 구성 요소 또는 이들의 조합은 설명된 각각의 논리 블록, 모듈 및 회로를 구현하거나 수행 하는 데 활용될 수 있다. 범용 프로세서는 마이크로프로세서일 수 있지만, 대체품으로서 프로세서는 상업적으로 판매되는 프로세서, 제어기, 마이크로제어기 또는 상태 머신이 될 수 있다. 프로세서는 또한 컴퓨팅 장치의 조 합으로 구현될 수 있으며, 예를 들어, DSP와 마이크로프로세서의 조합, 복수의 마이크로프로세서, DSP 코어와 협력하는 마이크로프로세서 또는 이와 유사한 다른 구성일 수 있다. 본 개시에 기술된 방법 또는 알고리즘과 관련된 단계는 하드웨어에 직접 내장될 수도 있고, 프로세서에 의해 실 행되는 소프트웨어 모듈일 수도 있으며, 이 둘의 조합일 수도 있다. 소프트웨어 모듈은 모든 형태의 실제 저장 매체에 존재할 수 있다. 사용될 수 있는 저장 매체의 예로는 랜덤 액세스 메모리(RAM), 리드 온리 메모리(ROM), 플래시 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 드라이브, 이동식 디스크, CD-ROM 등이 있다. 저 장 매체는 프로세서에 결합될 수 있으므로, 프로세서는 저장 매체로부터 정보를 판독하고 저장 매체에 정보를 기록할 수 있다. 또 다른 모드에서, 저장 매체가 프로세서와 전체적으로 통합될 수 있다. 소프트웨어 모듈은 단 일 명령들이거나 복수의 명령들일 수 있으며, 여러 개의 서로 다른 코드 세그먼트, 서로 다른 프로그램에 걸쳐 및 복수의 저장 매체에 분산될 수 있다. 여기에 개시되는 방법은 설명된 방법을 구현하기 위한 동작을 포함한다. 방법 및/또는 동작은 청구항의 범위를 벗어나지 않고 서로 호환될 수 있다. 다시 말해, 특정한 동작 순서가 지정되지 않는 한, 특정 동작의 순서 및/ 또는 사용은 청구항의 범위를 벗어나지 않고도 수정될 수 있다. 위에 설명된 기능은 하드웨어, 소프트웨어, 펌웨어 또는 이들의 조합을 통해 구현될 수 있다. 소프트웨어로 구 현하는 경우 해당 기능은 유형의 컴퓨터 판독가능 매체에 명령들로 저장될 수 있다. 저장 매체는 컴퓨터로 접근 할 수 있는 모든 유형의 매체가 될 수 있다. 제한이 아닌 예시로서, 이러한 컴퓨터 판독 매체에는 RAM, ROM,EEPROM, CD-ROM 또는 기타 광 저장 장치, 자기 저장 장치 또는 기타 자기 저장 장치, 또는 명령 또는 데이터 구 조의 형태로 원하는 프로그램 코드를 수단하거나 저장하는 데 사용될 수 있는 기타 유형의 매체가 포함될 수 있 으며 컴퓨터에서 액세스될 수 있다. 본 명세서에서 사용되는 디스크(disk) 및 디스크는 콤팩트 디스크(CD), 레 이저 디스크, 광 디스크, 디지털 다기능 디스크(DVD), 플로피 디스크, 블루 디스크를 포함하며, 여기서 디스크 는 일반적으로 데이터를 자기적으로 재생하는 반면, 디스크는 레이저를 이용하여 광학적으로 데이터를 재생한다. 따라서, 컴퓨터 프로그램 제품(computer program product)은 여기에 제시된 동작을 수행할 수 있다. 예를 들어, 이러한 컴퓨터 프로그램 제품은 명령들이 유형적으로 저장되어 있거나 인코딩되어 있는 컴퓨터 판독가능한 유형 매체일 수 있으며, 명령들은 프로세서에 의해 실행되어 여기에 설명된 동작을 수행할 수 있다. 컴퓨터 프로그램 제품에는 포장재가 포함될 수 있다. 소프트웨어나 명령들도 전송 매체를 통해 전송될 수 있다. 예를 들어, 소프트웨어는 동축 케이블, 광섬유 케이 블, 연선(twisted pair cable), 디지털 가입자 회선(DSL)이나 적외선, 라디오, 마이크로파와 같은 무선 기술과 같은 전송 매체를 사용하여 웹사이트, 서버 또는 기타 원격 소스에서 전송될 수 있다. 또한, 여기에 설명된 방법 및 기술을 수행하기 위한 모듈 및/또는 기타 적절한 수단은 사용자 단말기 및/또는 기지국에서 필요에 따라 다운로드 및/또는 다른 방법으로 획득될 수 있다. 예를 들어, 이러한 장치는 여기에 설 명된 방법을 수행하기 위한 수단의 전송을 용이하게 하기 위해 서버에 결합될 수 있다. 또는, 여기에 설명된 각 각의 방법은 저장 구성요소(예: RAM, ROM, CD나 플로피 디스크와 같은 물리적 저장 매체 등)에 의해 제공될 수 있으므로, 사용자 단말 및/또는 기지국은 장치에 결합되거나 장치에 저장 구성요소를 제공할 때 다양한 방법을 얻을 수 있다. 또한, 여기에 설명된 방법 및 기술을 장치에 제공하기 위한 다른 적절한 기술이 활용될 수 있다. 다른 예 및 구현 모드는 본 개시 및 첨부된 청구항의 범위 및 사상 내에 포함된다. 예를 들어, 소프트웨어의 특 성상 위에 설명된 기능은 프로세서, 하드웨어, 펌웨어, 하드 와이어링 또는 위의 것들의 조합에 의해 실행되는 소프트웨어를 사용하여 구현될 수 있다. 기능을 구현하는 기능 역시 각각의 위치에 물리적으로 위치할 수 있으 며, 기능의 일부가 서로 다른 물리적 위치에 구현될 수 있도록 분산될 수도 있다. 또한, 본 명세서에서, 청구항 에 사용되는, \"적어도 하나\"로 시작하는 항목의 열거에 사용되는 용어 \"또는\"은 별도의 열거를 나타내므로, 예 를 들어, \"A, B 또는 C 중 적어도 하나\"의 열거는 A 또는 B 또는 C, 또는 AB 또는 AC 또는 BC, 또는 ABC(즉, A 와 B와 C)를 의미한다. 더욱이, \"예시적\"이라는 단어는 설명된 예가 다른 예보다 선호되거나 더 낫다는 것을 의 미하지 않는다. 여기에 설명된 기술에 대한 다양한 변경, 대체 및 수정은 첨부된 청구항에 의해 정의된 교시된 기술에서 벗어나 지 않고 이루어질 수 있다. 또한, 본 개시의 특허청구범위는 위의 기술한 처리, 기계, 제조, 사건의 구성, 수단, 방법 및 동작의 구체적인 측면에 국한되지 않는다. 현재 존재하거나 나중에 개발될 처리, 기계, 제작, 사 건의 구성, 수단, 방법 및 조치는 여기에 설명된 것과 실질적으로 동일한 기능을 수행하거나 실질적으로 동일한 결과를 구현하는 데 활용될 수 있다. 따라서, 첨부된 청구항은 그 범위 내의 처리, 기계, 제작, 사건의 구성, 수단, 방법 및 동작을 포함한다. 위에 개시된 측면에 대한 설명은 해당 기술 분야의 숙련자가 본 개시 내용을 구현하거나 활용할 수 있도록 제공 된 것이다. 이러한 측면에 대한 다양한 수정은 해당 기술 분야의 숙련자에게는 매우 명백하며, 여기에 정의된 일반 원칙은 본 개시의 범위를 벗어나지 않고 다른 측면에도 적용될 수 있다. 따라서, 본 개시는 여기에 나타난 측면에 한정되는 것이 아니라, 여기에 개시된 원리 및 새로운 특징과 일치하는 가장 넓은 범위로 의도된다. 위의 설명은 설명과 이해를 돕기 위해 제공되었다. 더욱이, 이러한 설명은 본 개시의 실시예를 여기에 개시된 형태로 제한하려는 것이 아니다. 위에서 다양한 예시적인 측면과 실시예를 논의했지만, 해당 기술 분야 종사자 라면 그 중 특정 변형, 수정, 변경, 추가 및 하위 조합을 인식할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2025-7001387", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 실시예 또는 기존 기술의 기술적 해결책을 명확하게 설명하기 위해, 실시예 또는 기존 기술을 설명하 는 데 필요한 도면을 아래에 간략하게 기술한다. 분명히, 설명된 도면은 본 개시의 실시예의 일부에 대한 도면 일 뿐이다. 해당 기술 분야의 숙련된 사람은 창의적인 노력 없이도 이러한 도면에 기초하여 다른 첨부된 도면을 획득할 수 있다.도 1은 이미지 데이터 처리 및 인식에 적용된 신경망의 하나의 예시적인 계산 그래프의 개략도를 나타낸다. 도 2는 본 개시의 실시 예에 따른 유연하게 데이터에 접근하기 위한 인공지능의 프로세서 칩의 개략도를 나타낸 다. 도 3은 본 개시의 실시 예에 따른 데이터에 유연하게 접근하기 위한 인공지능의 프로세서 칩의 분해 개략도를 나타낸다. 도 4는 본 개시의 실시예에 따른 입력 텐서에 대해 2-계층 루프 중첩 읽기(2-layer loop nest read)를 수행하는 예를 나타낸다. 도 5는 본 개시의 실시예에 따른 소프트웨어에 의해 구성된 파라미터에 따라 주소를 계산하는 개략도를 나타낸 다. 도 6은 본 개시의 실시예에 따른 입력 텐서에 대해 불완전하게 정렬된 3-계층 루프 중첩 읽기(3-layer loop nest read)를 수행하는 예를 나타낸다. 도 7은 본 개시의 실시예에 따른 SRAM의 내부 구조의 개략도를 나타낸다. 도 8은 본 개시의 실시예에 따른 인공지능의 프로세서 칩에서 데이터에 유연하게 접근하는 방법의 흐름도를 나 타낸다. 도 9는 본 개시의 실시예를 구현하는 데 적합한 예시적인 전자 디바이스의 블록도를 나타낸다. 도 10은 본 개시의 실시예에 따른 비일시적 컴퓨터 판독가능 저장 매체(non-transitory computer-readable storage medium)의 개략도를 나타낸다."}
