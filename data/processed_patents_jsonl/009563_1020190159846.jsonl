{"patent_id": "10-2019-0159846", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0059576", "출원번호": "10-2019-0159846", "발명의 명칭": "인공 지능 기반의 영상 처리 방법 및 이를 수행하는 영상 처리 장치", "출원인": "삼성전자주식회사", "발명자": "강한솔"}}
{"patent_id": "10-2019-0159846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 객체들을 포함하는 제1 영상 및 상기 제1 영상에 대한 제1 영상 정보를 획득하는 단계;사용자의 음성 정보 및 상기 사용자로부터의 터치 정보 중 적어도 하나를 포함하는 사용자 커맨드 신호를 수신하여, 상기 제1 영상에 포함되는 상기 복수의 객체들 중 제1 객체에 대한 적어도 하나의 영상 처리를 수행하기위한 제1 영상 처리 정보를 획득하는 단계; 및상기 제1 영상, 상기 제1 영상 정보 및 상기 사용자 커맨드 신호에 의해 획득되는 상기 제1 영상 처리 정보를기초로 상기 제1 영상에 포함되는 상기 복수의 객체들 중 상기 제1 객체에 대한 상기 적어도 하나의 영상 처리를 수행하여, 상기 제1 영상에 대응하는 제2 영상을 획득하는 단계를 포함하는 영상 처리 방법."}
{"patent_id": "10-2019-0159846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 제1 영상 및 상기 제1 영상 정보를 획득하는 단계는,상기 복수의 객체들 중 하나에 대한 제1 자동 초점 조절(Auto Focus; AF)을 수행하여 상기 제1 영상을 캡쳐하는단계;상기 제1 영상을 분석하여 상기 제1 영상에 대한 장면 타입(scene type)을 검출하는 단계;상기 복수의 객체들을 분석하여 상기 복수의 객체들에 대한 객체 타입을 검출하여 복수의 라벨(label)들을 할당하는 단계; 및상기 제1 영상 내에서 상기 복수의 객체들이 배치되는 복수의 객체 영역들을 검출하는 단계를 포함하는 것을 특징으로 하는 영상 처리 방법."}
{"patent_id": "10-2019-0159846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 제1 영상 처리 정보를 획득하는 단계는,상기 사용자 커맨드 신호를 인식하는 단계;상기 사용자 커맨드 신호를 분석하여 상기 제1 객체에 대한 제1 정보를 검출하는 단계; 및상기 사용자 커맨드 신호를 분석하여 상기 적어도 하나의 영상 처리에 대한 제2 정보를 검출하는 단계를 포함하는 것을 특징으로 하는 영상 처리 방법."}
{"patent_id": "10-2019-0159846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 제2 영상을 획득하는 단계는,상기 복수의 객체들에 대한 상기 복수의 라벨들 중 상기 제1 객체에 대한 상기 제1 정보에 대응하는 제1 라벨이존재하는지 판단하는 단계; 및상기 제1 정보에 대응하는 상기 제1 라벨이 존재하는 경우에, 상기 적어도 하나의 영상 처리에 대한 상기 제2정보를 기초로 상기 제1 객체에 대한 제2 자동 초점 조절을 수행하여 상기 제2 영상을 캡쳐하는 단계를 포함하는 것을 특징으로 하는 영상 처리 방법."}
{"patent_id": "10-2019-0159846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서, 상기 제2 영상을 획득하는 단계는,상기 복수의 객체들에 대한 상기 복수의 라벨들 중 상기 제1 객체에 대한 상기 제1 정보에 대응하는 제1 라벨이존재하는지 판단하는 단계;상기 제1 정보에 대응하는 상기 제1 라벨이 존재하는 경우에, 상기 적어도 하나의 영상 처리에 대한 상기 제2공개특허 10-2021-0059576-3-정보를 기초로 상기 제1 객체에 대한 제2 자동 초점 조절을 수행하여 제3 영상을 캡쳐하는 단계; 및상기 제2 정보를 기초로 상기 제3 영상에 포함되는 상기 제1 객체에 대한 상기 적어도 하나의 영상 처리를 수행하여 상기 제2 영상을 발생하는 단계를 포함하는 것을 특징으로 하는 영상 처리 방법."}
{"patent_id": "10-2019-0159846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 적어도 하나의 영상 처리는 상기 제3 영상 내에서 상기 제1 객체에 대응하는 제1 영역에 대해서만 부분적으로 수행되는 것을 특징으로 하는 영상 처리 방법."}
{"patent_id": "10-2019-0159846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5 항에 있어서,상기 복수의 객체들에 대한 상기 복수의 라벨들 중 상기 제1 객체에 대한 상기 제1 정보에 대응하는 상기 제1라벨이 존재하지 않는 경우에, 추가 사용자 커맨드 신호를 요청하는 단계를 더 포함하는 것을 특징으로 하는 영상 처리 방법."}
{"patent_id": "10-2019-0159846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 5 항에 있어서,상기 제1 정보만으로는 상기 복수의 객체들에 대한 상기 복수의 라벨들 중 상기 제1 객체에 대한 상기 제1 정보에 대응하는 상기 제1 라벨이 존재하는지 확인이 불가능한 경우에, 추가 사용자 커맨드 신호를 요청하는 단계를더 포함하는 것을 특징으로 하는 영상 처리 방법."}
{"patent_id": "10-2019-0159846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "복수의 객체들을 포함하는 제1 영상을 획득하는 영상 촬상 장치;상기 제1 영상을 분석하여 상기 제1 영상에 대한 제1 영상 정보를 획득하는 영상 분석부;사용자의 음성 정보 및 상기 사용자로부터의 터치 정보 중 적어도 하나를 포함하는 사용자 커맨드 신호를 수신하는 커맨드 수신부;상기 사용자 커맨드 신호를 분석하여 상기 제1 영상에 포함되는 상기 복수의 객체들 중 제1 객체에 대한 적어도하나의 영상 처리를 수행하기 위한 제1 영상 처리 정보를 획득하는 커맨드 분석부; 및상기 제1 영상, 상기 제1 영상 정보 및 상기 사용자 커맨드 신호에 의해 획득되는 상기 제1 영상 처리 정보를기초로 상기 제1 영상에 포함되는 상기 복수의 객체들 중 상기 제1 객체에 대한 상기 적어도 하나의 영상 처리를 수행하여, 상기 제1 영상에 대응하는 제2 영상을 획득하는 영상 처리부를 포함하는 영상 처리 장치."}
{"patent_id": "10-2019-0159846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 영상 분석부와 연동하여 동작하고, 상기 제1 영상을 분석하여 상기 제1 영상 정보를 획득하기 위한 인공신경망(Artificial Neural Network; ANN)을 구동하는 적어도 하나의 인공 지능(Artificial Intelligence; AI)프로세싱 소자(processing element)를 더 포함하는 것을 특징으로 하는 영상 처리 장치."}
{"patent_id": "10-2019-0159846", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상 처리 방법에서, 복수의 객체들을 포함하는 제1 영상 및 제1 영상에 대한 제1 영상 정보를 획득한다. 사용자 의 음성 정보 및 사용자로부터의 터치 정보 중 적어도 하나를 포함하는 사용자 커맨드 신호를 수신하여, 제1 영 상에 포함되는 복수의 객체들 중 제1 객체에 대한 적어도 하나의 영상 처리를 수행하기 위한 제1 영상 처리 정보 를 획득한다. 제1 영상, 제1 영상 정보 및 사용자 커맨드 신호에 의해 획득되는 제1 영상 처리 정보를 기초로 제 1 영상에 포함되는 복수의 객체들 중 제1 객체에 대한 적어도 하나의 영상 처리를 수행하여, 제1 영상에 대응하 는 제2 영상을 획득한다."}
{"patent_id": "10-2019-0159846", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 획득 및 처리에 관한 것으로서, 더욱 상세하게는 인공 지능 기반의 영상 처리 방법 및 상기 영 상 처리 방법을 수행하는 영상 처리 장치에 관한 것이다."}
{"patent_id": "10-2019-0159846", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "카메라와 같은 영상 촬상 장치가 다양한 종류의 전자 시스템 및 모바일 시스템에 적용되고 있다. 상기 영상 촬 상 장치에 의해 획득된 영상 정보는 다양한 방식으로 처리될 수 있으며, 예를 들어 영상에 대한 다양한 효과를 표현하기 위한 영상 처리가 수행될 수 있다. 한편, 컴퓨터 과학에서 인공 지능(Artificial Intelligence; AI)이라는 용어는 학습 및 문제 해결 등과 같이 인 간이 인간의 마음과 관련이 있는 인지(cognitive) 기능을 모방한 기계(또는 컴퓨터)를 묘사하는 데 이용된다. 예를 들어, 인공 지능은 머신 러닝(machine learning), 신경망(Neural Network; NN) 또는 인공 신경망 (Artificial Neural Network; ANN)에 기반하여 구현될 수 있다. 인공 신경망이란 연결 선으로 연결된 많은 수의 인공 뉴런들을 사용하여 생물학적인 시스템의 계산 능력을 모방하는 소프트웨어나 하드웨어로 구현된 연산 모델 을 나타낸다. 인공 신경망에서는 생물학적인 뉴런의 기능을 단순화시킨 인공 뉴런을 사용하게 된다. 그리고 연 결 강도를 갖는 연결 선을 통해 상호 연결시켜 인간의 인지 작용이나 학습 과정을 수행하게 된다. 최근에는 인 공 지능 및/또는 인공 신경망을 이용한 영상 처리에 대한 연구가 진행되고 있다."}
{"patent_id": "10-2019-0159846", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 목적은 현재 영상에 대한 다양한 효과를 효과적으로 표현할 수 있는 인공 지능 기반의 영상 처리 방법을 제공하는 것이다. 본 발명의 다른 목적은 상기 영상 처리 방법을 수행하는 영상 처리 장치를 제공하는 것이다."}
{"patent_id": "10-2019-0159846", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 일 목적을 달성하기 위해, 본 발명의 실시예들에 따른 영상 처리 방법에서, 복수의 객체들을 포함하는 제1 영상 및 상기 제1 영상에 대한 제1 영상 정보를 획득한다. 사용자의 음성 정보 및 상기 사용자로부터의 터치 정 보 중 적어도 하나를 포함하는 사용자 커맨드 신호를 수신하여, 상기 제1 영상에 포함되는 상기 복수의 객체들 중 제1 객체에 대한 적어도 하나의 영상 처리를 수행하기 위한 제1 영상 처리 정보를 획득한다. 상기 제1 영상, 상기 제1 영상 정보 및 상기 사용자 커맨드 신호에 의해 획득되는 상기 제1 영상 처리 정보를 기초로 상기 제1 영상에 포함되는 상기 복수의 객체들 중 상기 제1 객체에 대한 상기 적어도 하나의 영상 처리를 수행하여, 상기 제1 영상에 대응하는 제2 영상을 획득한다. 상기 다른 목적을 달성하기 위해, 본 발명의 실시예들에 따른 영상 처리 장치는 영상 촬상 장치, 영상 분석부, 커맨드 수신부, 커맨드 분석부 및 영상 처리부를 포함한다. 상기 영상 촬상 장치는 복수의 객체들을 포함하는 제1 영상을 획득한다. 상기 영상 분석부는 상기 제1 영상을 분석하여 상기 제1 영상에 대한 제1 영상 정보를 획 득한다. 상기 커맨드 수신부는 사용자의 음성 정보 및 상기 사용자로부터의 터치 정보 중 적어도 하나를 포함하 는 사용자 커맨드 신호를 수신한다. 상기 커맨드 분석부는 상기 사용자 커맨드 신호를 분석하여 상기 제1 영상 에 포함되는 상기 복수의 객체들 중 제1 객체에 대한 적어도 하나의 영상 처리를 수행하기 위한 제1 영상 처리 정보를 획득한다. 상기 영상 처리부는 상기 제1 영상, 상기 제1 영상 정보 및 상기 사용자 커맨드 신호에 의해 획득되는 상기 제1 영상 처리 정보를 기초로 상기 제1 영상에 포함되는 상기 복수의 객체들 중 상기 제1 객체에 대한 상기 적어도 하나의 영상 처리를 수행하여, 상기 제1 영상에 대응하는 제2 영상을 획득한다."}
{"patent_id": "10-2019-0159846", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기와 같은 본 발명의 실시예들에 따른 인공 지능 기반의 영상 처리 방법 및 영상 처리 장치에서는, 인공 지능 기반으로 현재 영상을 분석하여 영상 정보를 획득하고, 음성 정보와 같은 사용자의 조작이 최소한으로 요구되는 신호를 사용자 커맨드 신호로서 수신하며, 수신된 사용자 커맨드 신호 및 획득된 영상 정보에 기초하여 현재 영 상에 포함되는 특정 객체에 대해 원하는 특정한 효과를 적용할 수 있다. 따라서, 사용자가 원하는 특정 객체에 초점을 맞추어 그에 적합한 효과를 선택적/부분적으로 적용함으로써, 현재 영상에 대한 다양한 효과를 효과적으 로 표현하고 사용자의 욕구를 만족시킬 수 있다."}
{"patent_id": "10-2019-0159846", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 도면상의 동일 한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 본 발명의 실시예들에 따른 영상 처리 방법을 나타내는 순서도이다. 도 1을 참조하면, 본 발명의 실시예들에 따른 영상 처리 방법은 영상 내의 특정 객체에 대해 원하는 특정한 효 과를 적용하기 위해 수행되며, 특히 인공 지능(Artificial Intelligence; AI) 기반으로 영상을 분석하는 영상 처리 장치에 의해 수행된다. 상기 영상 처리 장치의 구체적인 구조에 대해서는 도 2 등을 참조하여 후술하도록 한다. 본 발명의 실시예들에 따른 영상 처리 방법에서, 복수의 객체들을 포함하는 제1 영상 및 상기 제1 영상에 대한 제1 영상 정보를 획득한다(단계 S100). 예를 들어, 도 4를 참조하여 후술하는 것처럼 제1 자동 초점 조절(Auto Focus; AF)을 수행하여 상기 제1 영상을 캡쳐하며, 상기 제1 영상을 분석하여 상기 제1 영상 정보를 획득할 수 있다. 사용자의 음성 정보 및 상기 사용자로부터의 터치 정보 중 적어도 하나를 포함하는 사용자 커맨드 신호를 수신 하여, 상기 제1 영상에 포함되는 상기 복수의 객체들 중 제1 객체에 대한 적어도 하나의 영상 처리를 수행하기 위한 제1 영상 처리 정보를 획득한다(단계 S200). 예를 들어, 상기 사용자 커맨드 신호는 상기 제1 객체에 대한 제1 정보 및 상기 적어도 하나의 영상 처리에 대한 제2 정보를 포함하며, 도 6을 참조하여 후술하는 것처럼 상 기 사용자 커맨드 신호를 분석하여 상기 제1 정보 및 상기 제2 정보를 포함하는 상기 제1 영상 처리 정보를 획 득할 수 있다. 상기 제1 영상, 상기 제1 영상 정보 및 상기 사용자 커맨드 신호에 의해 획득되는 상기 제1 영상 처리 정보를 기초로 상기 제1 영상에 포함되는 상기 복수의 객체들 중 상기 제1 객체에 대한 상기 적어도 하나의 영상 처리 를 수행하여, 상기 제1 영상에 대응하는 제2 영상을 획득한다(단계 S300). 예를 들어, 도 7을 참조하여 후술하 는 것처럼 상기 제1 객체에 대한 제2 자동 초점 조절을 수행하여 상기 제2 영상을 캡쳐할 수 있다. 다시 말하면, 본 발명의 실시예들에 따른 영상 처리 방법에서는 2회의 자동 초점 조절이 수행될 수 있다. 다른 예에 서, 도 8을 참조하여 후술하는 것처럼 상기 제1 객체에 대한 상기 제2 자동 초점 조절 및 추가 영상 처리를 수 행하여 상기 제2 영상을 발생할 수 있다. 본 발명의 실시예들에 따른 영상 처리 방법에서는, 인공 지능 기반으로 현재 영상을 분석하여 영상 정보를 획득 하고, 음성 정보와 같은 사용자의 조작이 최소한으로 요구되는 신호를 사용자 커맨드 신호로서 수신하며, 수신 된 사용자 커맨드 신호 및 획득된 영상 정보에 기초하여 현재 영상에 포함되는 특정 객체에 대해 원하는 특정한 효과를 적용할 수 있다. 따라서, 사용자가 원하는 특정 객체에 초점을 맞추어 그에 적합한 효과를 선택적/부분 적으로 적용함으로써, 현재 영상에 대한 다양한 효과를 효과적으로 표현하고 사용자의 욕구를 만족시킬 수있다. 도 2는 본 발명의 실시예들에 따른 영상 처리 장치를 나타내는 블록도이다. 도 2를 참조하면, 영상 처리 장치는 영상 촬상 장치, 영상 분석부, 커맨드 수신부, 커맨드 분석부 및 영상 처리부를 포함한다. 영상 처리 장치는 적어도 하나의 인공 지능 프로세싱 소자 (processing element)를 더 포함할 수 있다. 영상 촬상 장치는 피사체로부터 반사되는 광 신호(LS)를 외부로부터 수신하여 광 신호(LS)에 대응하는 제1 영상(IMG1)을 획득한다. 영상 촬상 장치는 렌즈, 셔터, 센서, 렌즈 구동부 및 셔터 구동부를 포함할 수 있다. 렌즈는 외부에서 수신되는 광 신호(LS)를 센서에 집중시킬 수 있다. 광 신호(LS)는 가시광선, 적외선 및/또는 근적외선 등을 포함할 수 있다. 도 2에서는 영상 촬상 장치가 하나의 렌즈를 포함하는 것으 로 도시하였으나, 실시예에 따라서 상기 영상 촬상 장치는 두 개 이상의 렌즈들을 포함하여 구현될 수도 있다. 센서는 렌즈를 통해 집중되는 광 신호(LS')에 기초하여 제1 영상(IMG1)을 획득할 수 있다. 제1 영상 (IMG1)은 도 1의 단계 S100에서 획득되는 제1 영상이며, 상기 제1 자동 초점 조절이 수행된 영상일 수 있다. 일 실시예에서, 센서는 CMOS(complementary metal oxide semiconductor) 이미지 센서일 수 있으며, 예를 들어 RGB 센서일 수 있다. 다른 실시예에서, 센서는 CCD(charge-coupled device) 이미지 센서 등과 같이 영상 정보를 획득할 수 있는 다양한 방식의 이미지 센서들 중 하나일 수 있다. 셔터는 렌즈를 통해 집중되는 광 신호(LS')를 센서에 선택적으로 제공할 수 있다. 실시예에 따 라서, 셔터는 전자식 셔터 또는 광 셔터로 구현될 수도 있고, 기계식 셔터로 구현될 수도 있다. 또한, 실 시예에 따라서, 셔터는 센서와 일체형으로 구현될 수도 있고, 센서와 분리되어 구현될 수도 있 다. 렌즈 구동부는 렌즈의 위치를 제어/조절하는 렌즈 구동 신호(LDS)를 발생할 수 있다. 예를 들어, 렌 즈 구동부는 보이스 코일 모터(Voice Coil Motor; VCM)와 같은 임의의 모터를 포함할 수 있다. 셔터 구동 부는 셔터의 동작, 예를 들어 셔터의 개폐 시점 및/또는 오픈 시간(즉, 셔터 노출 시간 (integration time))을 제어/조절하는 셔터 구동 신호(SDS)를 발생할 수 있다. 도시하지는 않았으나, 렌즈 구동 부 및 셔터 구동부의 동작을 제어하는 제어부를 더 포함할 수도 있다. 영상 분석부는 제1 영상(IMG1)을 분석하여 제1 영상(IMG1)에 대한 제1 영상 정보(IMG_INF1)를 획득한다. 도 4를 참조하여 후술하는 것처럼, 제1 영상 정보(IMG_INF1)는 제1 영상(IMG1)에 대한 장면 타입(scene type) 정보(ISCN), 제1 영상(IMG1)에 포함되는 복수의 객체들에 대한 복수의 라벨(label)들에 대한 정보(ILAB), 제1 영상(IMG1) 내에서 상기 복수의 객체들이 배치되는 복수의 객체 영역들에 대한 정보(IREG) 등을 포함할 수 있다. 도시하지는 않았으나, 영상 분석부는 장면 검출부(scene detector) 및 영상 분할부(semantic segmentation unit)를 포함하여 구현될 수 있다. 커맨드 수신부는 사용자의 음성 정보 및 상기 사용자로부터의 터치 정보 중 적어도 하나를 포함하는 사용 자 커맨드 신호(UCS)를 수신하여 출력한다. 커맨드 분석부는 사용자 커맨드 신호(UCS)를 분석하여 제1 영 상(IMG1)에 포함되는 상기 복수의 객체들 중 제1 객체에 대한 적어도 하나의 영상 처리를 수행하기 위한 제1 영 상 처리 정보(PCS_INF1)를 획득한다. 도 6을 참조하여 후술하는 것처럼, 제1 영상 처리 정보(PCS_INF1)는 상기 제1 객체에 대한 제1 정보(IOBJ), 상기 적어도 하나의 영상 처리에 대한 제2 정보(IPCS) 등을 포함할 수 있다. 도 2의 실시예에서, 사용자 커맨드 신호(UCS)는 상기 사용자의 음성 정보에 대응할 수 있다. 커맨드 수신부 는 상기 사용자의 음성 정보에 대응하는 음성 신호(VS)를 사용자 커맨드 신호(UCS)로서 수신하는 음성 수 신 장치를 포함하고, 커맨드 분석부는 상기 사용자의 음성 정보를 분석하여 제1 영상 처리 정보 (PCS_INF1)를 획득하는 음성 인식 장치를 포함할 수 있다. 예를 들어, 음성 수신 장치는 아날로그 마 이크, 디지털 마이크, 블루투스 마이크 등과 같은 다양한 타입의 마이크를 포함할 수 있다. 예를 들어, 음성 인 식 장치는 음성 보조(voice assistant) 서비스, 자동 음성 인식(Automatic Speech Recognition; ASR) 서 비스 등의 형태로 구현될 수 있다. 영상 처리부는 제1 영상(IMG1), 제1 영상 정보(IMG_INF1) 및 사용자 커맨드 신호(UCS)에 의해 획득되는 제 1 영상 처리 정보(PCS_INF1)를 기초로 제1 영상(IMG1)에 포함되는 상기 복수의 객체들 중 상기 제1 객체에 대한 상기 적어도 하나의 영상 처리를 수행하여, 제1 영상(IMG1)에 대응하는 제2 영상(IMG2)을 획득한다. 예를 들어,상기 적어도 하나의 영상 처리는 자동 초점 조절, 자동 노출 조절, 화이트 밸런스 조절(white balance), 색 포 화도 조절(color saturation), 콘트라스트 조절(contrast), 선명도 조절(sharpness), 이미지 보간(image interpolation), 색 보정(color correction), 감마 보정(gamma correction), 색 변환(color conversion) 중 적 어도 하나를 포함할 수 있다. 인공 지능 프로세싱 소자는 영상 분석부와 연동하여 동작하고, 제1 영상(IMG1)을 분석하여 제1 영상 정보(IMG_INF1)를 획득하기 위한 인공 신경망(Artificial Neural Network; ANN)을 구동할 수 있다. 상기 인공 신경망의 예시적인 구조에 대해서는 도 3a 및 3b를 참조하여 후술하도록 한다. 일 실시예에서, 인공 지능 프로세싱 소자는 중앙 처리 장치(Central Processing Unit; CPU), 그래픽 처리 장치(Graphic Processing Unit; GPU), 신경 처리 장치(Neural Processing Unit; NPU), 디지털 신호 프로세서 (Digital Signal Processor; DSP), 영상 신호 프로세서(Image Signal Processor; ISP) 및 특정 작업 전용 하드 웨어(dedicated hardware, DHW) 중 적어도 하나를 포함할 수 있다. 예를 들어, 특정 작업 전용 하드웨어는 비전 처리 장치(Vision Processing Unit; VPU), 비전 IP(Vision Intellectual Property; VIP) 등을 포함할 수 있다. 프로세싱 소자는 연산 리소스(computing resource)라고 부를 수도 있다. 한편, 영상 촬상 장치, 영상 분석부 및 인공 지능 프로세싱 소자를 통합하여 인공 지능 카메라 라고 부를 수도 있다. 실시예에 따라서, 상기 인공 신경망은 커맨드 분석부에 포함되는 음성 인식 장치와 연동하여 동작하 고 상기 사용자의 음성 정보를 분석하여 제1 영상 처리 정보(PCS_INF1)를 획득하는데 이용될 수도 있고, 영상 처리부와 연동하여 동작하고 상기 적어도 하나의 영상 처리를 수행하는데 이용될 수도 있다. 실시예에 따라서, 영상 분석부, 커맨드 분석부, 영상 처리부 및 인공 지능 프로세싱 소자 의 일부 또는 전부는 하드웨어의 형태로 구현되거나, 소프트웨어(즉, 프로그램)의 형태로 구현되어 저장 장치에 저장될 수 있다. 일 실시예에서, 영상 처리 장치는 휴대폰(mobile phone), 스마트 폰(smart phone), 태블릿(tablet) PC(Personal Computer), 노트북(laptop computer), PDA(Personal Digital Assistant), PMP(Portable Multimedia Player), 디지털 카메라(digital camera), 캠코더(camcorder), 휴대용 게임 콘솔(portable game console), 음악 재생기(music player), 동영상 재생기(video player), 네비게이션(navigation) 기기, 웨어러블 (wearable) 기기, IoT(Internet of Things) 기기, e-북(e-book), VR(Virtual Reality) 기기, AR(Augmented Reality) 기기, PC(Personal Computer), 서버 컴퓨터(server computer), 워크스테이션(workstation), 디지털 TV(digital television), 셋-탑 박스(set-top box), 네비게이션 시스템 등의 임의의 컴퓨팅 시스템 및/또는 모 바일 시스템에 포함될 수 있다. 한편, 도시하지는 않았으나, 영상 처리 장치는 영상 처리와 관련된 데이터를 저장하는 메모리 또는 저장부 를 더 포함할 수 있다. 영상 처리 장치에 의해 도 1에 도시된 본 발명의 실시예들에 따른 영상 처리 방법이 수행될 수 있다. 예를 들어, 영상 촬상 장치, 영상 분석부 및 인공 지능 프로세싱 소자에 의해 도 1의 단계 S100이 수 행되고, 커맨드 수신부 및 커맨드 분석부에 의해 도 1의 단계 S200이 수행되며, 영상 촬상 장치 및 영상 처리부에 의해 도 1의 단계 S300이 수행될 수 있다. 도 3a 및 3b는 본 발명의 실시예들에 따른 영상 처리 장치에 포함되는 인공 지능 프로세싱 소자에 의해 구동되 는 인공 신경망 구조의 예를 설명하기 위한 도면들이다. 도 3a를 참조하면, 일반적인 신경망의 네트워크 구조는 입력 레이어(IL), 복수의 히든 레이어들(HL1, HL2, ..., HLn) 및 출력 레이어(OL)를 포함할 수 있다. 입력 레이어(IL)는 i(i는 자연수)개의 입력 노드들(x1, x2, ..., xi)을 포함할 수 있고, 길이가 i인 벡터 입력 데이터(IDAT)가 각 입력 노드에 입력될 수 있다. 복수의 히든 레이어들(HL1, HL2, ..., HLn)은 n(n은 자연수)개의 히든 레이어들을 포함하며, 히든 노드들(h1 1, h1 2, h1 3, ..., h1 m, h2 1, h2 2, h2 3, ..., h2 m, hn 1, hn 2, hn 3, ..., hn m)을 포함할 수 있다. 예를 들어, 히든 레이어 (HL1)는 m(m은 자연수)개의 히든 노드들(h1 1, h1 2, h1 3, ..., h1 m)을 포함할 수 있고, 히든 레이어(HL2)는 m개의히든 노드들(h2 1, h2 2, h2 3, ..., h2 m)을 포함할 수 있으며, 히든 레이어(HLn)는 m개의 히든 노드들(hn 1, hn 2, hn 3, ..., hn m)을 포함할 수 있다. 출력 레이어(OL)는 분류할 클래스에 대응하는 j(j는 자연수)개의 출력 노드들(y1, y2, ..., yj)을 포함할 수 있 고, 입력 데이터(IDAT)에 대하여 각 클래스 별로 결과(예를 들어, 점수 또는 class score)를 출력할 수 있다. 출력 레이어(OL)는 fully connected 레이어라고 부를 수 있으며, 예를 들어 입력 데이터(IDAT)가 자동차에 대응 할 확률을 수치로 나타낼 수 있다. 도 3a에 도시된 네트워크 구조는, 두 개의 노드들 사이에 직선으로 도시된 노드들 간의 연결(branch)과, 도시되 지는 않았지만 각 연결에서 사용되는 가중치(weight)를 포함할 수 있다. 이 때, 하나의 레이어 내의 노드들 간 에는 연결이 되지 않을 수 있고, 서로 다른 레이어들에 포함되는 노드들은 완전하게 혹은 부분적으로 연결될 수 있다. 도 3a의 각 노드(예를 들어, h1 1)는 이전 노드(예를 들어, x1)의 출력을 입력 받아 연산할 수 있고, 연산 결과를 이후 노드(예를 들어, h2 1)에 출력할 수 있다. 이 때, 각 노드는 입력된 값을 특정 함수, 예를 들어 비선형 함수 에 적용하여 출력할 값을 연산할 수 있다. 일반적으로 신경망의 네트워크 구조는 미리 결정되어 있으며, 노드들 간의 연결에 따른 가중치들은 이미 어떤 클래스에 속할지 정답이 알려진 데이터를 이용하여 적절한 값을 산정하게 된다. 이와 같이 이미 정답이 알려진 데이터들을 '학습 데이터'라고 하고, 가중치를 결정하는 과정을 '학습'이라고 한다. 또한, 독립적으로 학습이 가능한 구조와 가중치의 묶음을 '모델'이라고 가정하고, 가중치가 결정된 모델이 입력 데이터가 어느 클래스에 속할지를 예측하여 그 예측값을 출력하는 것을 '테스트' 과정이라고 한다. 한편, 도 3a에 도시된 일반적인 신경망은 각 노드(예를 들어, h1 1)가 앞쪽 레이어(previous layer)(예를 들어, IL)의 모든 노드들(예를 들어, x1, x2, ..., xi)과 연결되어 있어, 입력 데이터(IDAT)가 영상(또는 음성)인 경우 에 영상의 크기가 증가할수록 필요한 가중치의 개수가 기하급수적으로 증가하며, 따라서 영상을 다루기에 적절 하지 않을 수 있다. 이에 따라, 신경망에 필터 기술을 병합하여, 신경망이 2차원 영상을 잘 습득할 수 있도록 구현된 컨볼루션(convolutional) 신경망이 연구되고 있다. 도 3b를 참조하면, 컨볼루션 신경망의 네트워크 구조는 복수의 레이어들(CONV1, RELU1, CONV2, RELU2, POOL1, CONV3, RELU3, CONV4, RELU4, POOL2, CONV5, RELU5, CONV6, RELU6, POOL3, FC)을 포함할 수 있다. 일반적인 신경망과 다르게, 컨볼루션 신경망의 각 레이어는 가로(또는 폭, width), 세로(또는 높이, height), 깊이(depth)의 3개의 차원을 가질 수 있다. 이에 따라, 각 레이어에 입력되는 데이터 또한 가로, 세로, 깊이의 3개의 차원을 가지는 볼륨 데이터일 수 있다. 예를 들어, 도 3b에서 입력 영상이 가로 32, 세로 32의 크기를 가 지고 세 개의 컬러 채널(R, G, B)을 가지는 경우에, 상기 입력 영상에 대응하는 입력 데이터(IDAT)는 32*32*3의 크기를 가질 수 있다. 도 3b의 입력 데이터(IDAT)는 입력 볼륨 데이터 또는 입력 액티베이션 볼륨(activation volume)이라 부를 수 있다. 컨볼루션 레이어들(CONV1, CONV2, CONV3, CONV4, CONV5, CONV6)은 입력에 대한 컨볼루션 연산을 수행할 수 있 다. 영상 처리에서 컨볼루션이란 가중치를 갖는 마스크를 이용하여 데이터를 처리하는 것을 의미할 수 있으며, 입력 값과 마스크의 가중치를 곱한 후에 그 합을 출력 값으로 정하는 것을 나타낼 수 있다. 이 때, 마스크를 필 터(filter), 윈도우(window) 또는 커널(kernel)이라고 부를 수 있다. 구체적으로, 각 컨볼루션 레이어의 파라미터들은 일련의 학습 가능한 필터들로 이루어져 있을 수 있다. 각 필터 는 가로/세로 차원으로는 각 레이어의 전체 크기보다 작지만 깊이 차원으로는 각 레이어의 전체 깊이를 아우를 수 있다. 예를 들어, 각 필터를 입력 볼륨의 가로/세로 차원으로 슬라이딩(정확히는 convolve) 시키며 필터와 입력의 요소들 사이의 내적 연산(dot product)을 수행하여 2차원의 액티베이션 맵(activation map)을 생성할 수 있고, 이러한 액티베이션 맵을 깊이 차원을 따라 쌓아서 출력 볼륨을 생성할 수 있다. 예를 들어, 컨볼루션 레 이어(CONV1)가 32*32*3의 크기의 입력 볼륨 데이터(IDAT)에 네 개의 필터들을 제로 패딩(zero-padding)과 함께 적용하면, 컨볼루션 레이어(CONV1)의 출력 볼륨은 32*32*12의 크기를 가질 수 있다 (즉, 깊이 증가). RELU 레이어들(RELU1, RELU2, RELU3, RELU4, RELU5, RELU6)은 입력에 대한 정정 선형 유닛 연산을 수행할 수 있다. 예를 들어, 정정 선형 유닛 연산은 max(0, x)와 같이 음수에 대해서만 0으로 처리하는 함수를 나타낼 수 있다. 예를 들어, RELU 레이어(RELU1)가 컨볼루션 레이어(CONV1)로부터 제공된 32*32*12의 크기의 입력 볼륨에 정정 선형 유닛 연산을 수행하면, RELU 레이어(RELU1)의 출력 볼륨은 32*32*12의 크기를 가질 수 있다 (즉, 볼 륨 유지). 풀링 레이어들(POOL1, POOL2, POOL3)은 입력 볼륨의 가로/세로 차원에 대해 다운 샘플링을 수행할 수 있다. 예 를 들어, 2*2 필터를 적용하는 경우에 2*2 영역의 네 개의 입력들을 하나의 출력으로 변환할 수 있다. 구체적으 로, 2*2 최대 값 풀링과 같이 2*2 영역의 네 개의 입력들 중 최대 값을 선택하거나, 2*2 평균 값 풀링과 같이 2*2 영역의 네 개의 입력들의 평균 값을 연산할 수 있다. 예를 들어, 풀링 레이어(POOL1)가 32*32*12의 크기의 입력 볼륨에 2*2 필터를 적용하면, 풀링 레이어(POOL1)의 출력 볼륨은 16*16*12의 크기를 가질 수 있다 (즉, 가 로/세로 감소, 깊이 유지, 볼륨 감소). 일반적으로 컨볼루션 신경망에서는 하나의 컨볼루션 레이어(예를 들어, CONV1)와 하나의 RELU 레이어(예를 들어, RELU1)가 한 쌍을 형성할 수 있고, 컨볼루션/RELU 레이어들의 쌍이 반복 배치될 수 있으며, 컨볼루션 /RELU 레이어들의 쌍이 반복 배치되는 중간 중간에 풀링 레이어를 삽입함으로써, 영상을 줄여나가면서 영상의 특징을 추출할 수 있다. 출력 레이어 또는 fully connected 레이어(FC)는 입력 볼륨 데이터(IDAT)에 대하여 각 클래스 별로 결과를 출력 할 수 있다. 예를 들어, 컨볼루션 및 서브 샘플링을 반복 수행함에 따라 2차원 영상에 대응하는 입력 볼륨 데이 터(IDAT)가 1차원 행렬(또는 벡터)로 변환될 수 있다. 예를 들어, fully connected 레이어(FC)는 입력 볼륨 데 이터(IDAT)가 자동차(CAR), 트럭(TRUCK), 비행기(AIRPLANE), 배(SHIP), 말(HORSE)에 대응할 확률을 수치로 나 타낼 수 있다. 한편, 도시하지는 않았으나, 컨볼루션 신경망에 포함되는 레이어들의 종류 및 개수는 실시예에 따라서 다양하게 변경될 수 있다. 또한, 도시하지는 않았으나, 실시예에 따라서 컨볼루션 신경망은 예측된 결과인 점수(score) 값을 확률 값으로 변환하는 Softmax 레이어, 바이어스(bias)를 추가하는 Bias add 레이어 등을 더 포함할 수 있 다. 도 4는 도 1의 제1 영상 및 제1 영상 정보를 획득하는 단계의 일 예를 나타내는 순서도이다. 도 5는 도 4의 제1 영상 및 제1 영상 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 1, 4 및 5를 참조하면, 상기 제1 영상 및 상기 제1 영상 정보를 획득하는데 있어서(단계 S100), 제1 자동 초 점 조절을 수행하여 제1 영상(IMAGE1)을 캡쳐할 수 있다(단계 S110). 예를 들어, 제1 영상(IMAGE1)은 복수의 객 체들(예를 들어, 사람들 및 나무들) 및 배경(예를 들어, 해 및 산)을 포함하며, 상기 제1 자동 초점 조절은 상 기 복수의 객체들 중 하나에 대하여 수행될 수 있다. 일 실시예에서, 상기 제1 자동 초점 조절은 상기 복수의 객체들 중 가장 큰 객체에 대하여 수행될 수 있다. 예 를 들어, 도 5의 제1 영상(IMAGE1)에서는 가장 큰 객체인 검정색 머리카락을 가진 사람에 대하여 상기 제1 자동 초점 조절이 수행될 수 있다. 다른 실시예에서, 상기 제1 자동 초점 조절은 상기 복수의 객체들 중 제1 영상(IMAGE1)의 중심에 가장 가까운 객체에 대하여 수행될 수 있다. 예를 들어, 도 5의 제1 영상(IMAGE1)에서는 중심에 가장 가까운 객체인 검정색 머리카락을 가진 사람에 대하여 상기 제1 자동 초점 조절이 수행될 수 있다. 또 다른 실시예에서, 상기 제1 자동 초점 조절은 제1 영상(IMAGE1) 내의 임의의 고정된 영역에 대하여 수행될 수 있다. 예를 들어, 가장 관심 있는 영역은 영상의 가운데에 배치되는 것이 일반적이며, 따라서 제1 영상 (IMAGE1)의 가운데 영역에 대하여 상기 제1 자동 초점 조절이 수행될 수 있다. 실시예에 따라서, 제1 영상(IMAGE1)은 영상 데이터의 형태로 제공되거나 상기 영상 데이터를 부호화한 부호화 데이터를 포함하여 제공될 수 있다. 예를 들어, 상기 영상 데이터는 RGB 포맷, YUV 포맷, YCbCr 포맷, YPbPr 포 맷 등과 같은 다양한 영상 포맷들 중 적어도 하나를 가질 수 있다. 예를 들어, 상기 부호화 데이터는 JPEG(Joint Photographic Experts Group), MPEG(Moving Picture Expert Group), H.264, HEVC(High Efficiency Video Coding) 등과 같은 다양한 부호화 방식들 중 하나에 기초하여 부호화될 수 있다. 제1 영상(IMAGE1)을 획득한 이후에, 제1 영상(IMAGE1)을 분석하여 제1 영상(IMAGE1)에 대한 장면 타입을 검출할 수 있다(단계 S120). 예를 들어, 상기 장면 타입은 산, 바다, 시내 등과 같이 영상이 촬영된 장소 또는 배경과 관련하여 분류되며, 상기 영상 처리 방법을 수행하는 영상 처리 장치의 제조 시에 미리 분류되어 저장되어 있을수 있다. 예를 들어, 상술한 인공 지능 프로세싱 소자에 의해 구동되는 인공 신경망을 이용하여, 제1 영상 (IMAGE1)의 상기 장면 타입은 \"산\"으로 검출될 수 있다. 제1 영상(IMAGE1)에 포함되는 상기 복수의 객체들을 분석하여 상기 복수의 객체들에 대한 객체 타입을 검출하여 복수의 라벨(label)들(LAB1, LAB2, LAB3, LAB4)을 할당할 수 있다(단계 S130). 예를 들어, 상기 객체 타입은 사람(또는 얼굴), 자동차 등과 같이 영상 내의 객체(또는 피사체)와 관련하여 분류되며, 상기 장면 타입과 유사 하게 상기 영상 처리 방법을 수행하는 영상 처리 장치의 제조 시에 미리 분류되어 저장되어 있을 수 있다. 예를 들어, 상술한 인공 지능 프로세싱 소자에 의해 구동되는 인공 신경망을 이용하여, 제1 영상(IMAGE1) 내의 상기 복수의 객체들은 2명의 사람들과 2개의 나무들로 검출되며, 복수의 라벨들(LAB1, LAB2, LAB3, LAB4)은 각각 \"얼 굴1\", \"얼굴2\", \"나무1\", \"나무2\"로 설정될 수 있다. 제1 영상(IMAGE1) 내에서 상기 복수의 객체들이 배치되는 복수의 객체 영역들(REG1, REG2, REG3, REG4)을 검출 할 수 있다(단계 S140). 예를 들어, 복수의 객체 영역들(REG1, REG2, REG3, REG4)은 복수의 라벨들(LAB1, LAB2, LAB3, LAB4)이 할당된 상기 복수의 객체들의 위치를 나타낼 수 있다. 도 6은 도 1의 제1 영상 처리 정보를 획득하는 단계의 일 예를 나타내는 순서도이다. 도 1 및 6을 참조하면, 상기 제1 영상 처리 정보를 획득하는데 있어서(단계 S200), 상기 사용자의 음성 정보 및 상기 사용자로부터의 터치 정보 중 적어도 하나를 포함하는 상기 사용자 커맨드 신호를 인식하고(단계 S210), 상기 사용자 커맨드 신호를 분석하여 상기 제1 객체에 대한 제1 정보를 검출하며(단계 S220), 상기 사용자 커맨 드 신호를 분석하여 상기 적어도 하나의 영상 처리에 대한 제2 정보를 검출할 수 있다(단계 S230). 이를 위해, 상기 사용자 커맨드 신호에 대응하는 상기 음성 정보 및/또는 상기 터치 정보는 상기 제1 객체에 대한 상기 제1 정보 및 상기 적어도 하나의 영상 처리에 대한 상기 제2 정보 모두를 포함하고 있어야 한다. 구체적으로, 상기 음성 정보를 상기 사용자 커맨드 신호로서 수신하는 경우, 및 상기 음성 정보가 \"얼굴에 초점 을 맞춰\" 라는 구문을 포함하는 경우에, 상기 음성 정보를 분석하여 \"얼굴\"을 상기 제1 정보로서 추출하고 \"초 점을 맞춰\"를 상기 제2 정보로서 추출할 수 있다. 도 7은 도 1의 제2 영상을 획득하는 단계의 일 예를 나타내는 순서도이다. 도 8a 및 8b는 도 7의 제2 영상을 획 득하는 동작을 설명하기 위한 도면들이다. 도 1, 7, 8a 및 8b를 참조하면, 상기 제2 영상을 획득하는데 있어서(단계 S300), 상기 제1 영상에 포함되는 상 기 복수의 객체들에 대한 상기 복수의 라벨들 중 상기 제1 객체에 대한 상기 제1 정보에 대응하는 제1 라벨이 존재하는지 판단할 수 있다(단계 S310). 상기 제1 정보에 대응하는 상기 제1 라벨이 존재하는 경우에(단계 S310: 예), 상기 적어도 하나의 영상 처리에 대한 상기 제2 정보를 기초로 상기 제1 객체에 대한 제2 자동 초점 조절을 수행하여 상기 제2 영상을 캡쳐할 수 있다(단계 S320). 도 7의 실시예에서, 상기 적어도 하나의 영상 처리는 상기 제1 객체에 대한 상기 제2 자동 초점 조절만을 포함 할 수 있다. 일 실시예에서, 상기 제1 객체에 대한 자동 초점 조절이 이미 수행되어 있는 경우에, 즉 도 4의 단계 S110의 상 기 제1 자동 초점 조절이 상기 제1 객체에 대해 수행된 경우에, 상기 제2 자동 초점 조절은 생략될 수 있다. 상기 제1 정보에 대응하는 상기 제1 라벨이 존재하지 않는 경우에(단계 S310: 아니오), 별다른 영상 처리 없이, 즉 상기 제2 영상을 획득하지 않고 종료할 수 있다. 일 실시예에서, 도 8a의 영상이 상기 제1 영상이고, 도 8b의 영상이 상기 제2 영상일 수 있다. 구체적으로, 얼 굴 및 꽃을 포함하는 도 8a의 영상을 상기 제1 영상으로 캡쳐하고, 이 때 얼굴에 대해 제1 자동 초점 조절을 수 행하여 상기 제1 영상으로 캡쳐할 수 있다. 도 8a의 영상 및 영상 내의 객체들을 분석하여 장면 타입을 \"방\"으 로 검출하고 객체들에 대해 \"얼굴\" 및 \"꽃\"으로 라벨들을 할당하며 객체들의 위치를 나타내는 객체 영역들을 검 출할 수 있다. 이후에, \"꽃에 초점을 맞춰(focus on that flower)\" 라는 구문을 포함하는 음성 정보를 사용자 커맨드 신호로서 수신하는 경우에, 상기 사용자 커맨드 신호를 분석하여 \"꽃\" 및 \"초점을 맞춰\"를 각각 제1 정 보 및 제2 정보로서 추출할 수 있다. 상기 제1 정보인 \"꽃\"에 대응하는 상기 라벨이 존재하므로, 꽃에 대해 제2 자동 초점 조절을 수행하고 이에 대한 도 8b의 영상을 상기 제2 영상으로 캡쳐할 수 있다. 다른 실시예에서, 도 8b의 영상이 상기 제1 영상이고, 도 8a의 영상이 상기 제2 영상일 수 있다. 구체적으로, 꽃에 대해 제1 자동 초점 조절을 수행한 도 8b의 영상을 상기 제1 영상으로 캡쳐할 수 있다. 상술한 영상 분석 을 수행하여 상기 장면 타입을 검출하고 상기 라벨들을 할당하며 상기 객체 영역들을 검출할 수 있다. 이후에, \"얼굴에 초점을 맞춰(focus on that face)\" 라는 구문을 포함하는 음성 정보를 사용자 커맨드 신호로서 수신하 는 경우에, 상기 사용자 커맨드 신호를 분석하여 \"얼굴\" 및 \"초점을 맞춰\"를 각각 제1 정보 및 제2 정보로서 추 출할 수 있다. 상기 제1 정보인 \"얼굴\"에 대응하는 상기 라벨이 존재하므로, 얼굴에 대해 제2 자동 초점 조절을 수행하고 이에 대한 도 8a의 영상을 상기 제2 영상으로 캡쳐할 수 있다. 또 다른 실시예에서, 도 8a의 영상 및 도 8b의 영상은 모두 상기 제2 영상일 수 있다. 구체적으로, 도시하지는 않았으나, 얼굴 및 꽃을 제외한 다른 영역에 대해 제1 자동 초점 조절을 수행한 영상을 상기 제1 영상으로 캡쳐 하고, 상술한 영상 분석을 수행하여 상기 장면 타입을 검출하고 상기 라벨들을 할당하며 상기 객체 영역들을 검 출할 수 있다. 이후에, \"얼굴에 초점을 맞춰\" 라는 구문을 포함하는 음성 정보를 사용자 커맨드 신호로서 수신 하는 경우에는 상술한 과정에 따라 도 8a의 영상을 상기 제2 영상으로 캡쳐하고, \"꽃에 초점을 맞춰\" 라는 구문 을 포함하는 음성 정보를 사용자 커맨드 신호로서 수신하는 경우에는 상술한 과정에 따라 도 8b의 영상을 상기 제2 영상으로 캡쳐할 수 있다. 도 9는 도 1의 제2 영상을 획득하는 단계의 다른 예를 나타내는 순서도이다. 도 10a, 10b, 11a 및 11b는 도 9의 제2 영상을 획득하는 동작을 설명하기 위한 도면들이다. 이하 도 7과 중복되는 설명은 생략한다. 도 1, 9, 10a, 10b, 11a 및 11b를 참조하면, 상기 제2 영상을 획득하는데 있어서(단계 S300), 도 9의 단계 S310은 도 7의 S310과 실질적으로 동일할 수 있다. 상기 제1 정보에 대응하는 상기 제1 라벨이 존재하는 경우에(단계 S310: 예), 상기 적어도 하나의 영상 처리에 대한 상기 제2 정보를 기초로 상기 제1 객체에 대한 제2 자동 초점 조절을 수행하여 상기 제3 영상을 캡쳐하고 (단계 S325), 상기 제2 정보를 기초로 상기 제3 영상에 포함되는 상기 제1 객체에 대한 상기 적어도 하나의 영 상 처리를 수행하여 상기 제2 영상을 발생할 수 있다(단계 S330). 도 9의 실시예에서, 상기 적어도 하나의 영상 처리는 상기 제1 객체에 대한 상기 제2 자동 초점 조절을 포함하 며, 상기 제1 객체에 대응하는 제1 영역에 대한 화이트 밸런스 조절, 색 포화도 조절, 콘트라스트 조절, 선명도 조절 중 적어도 하나를 더 포함할 수 있다. 다만 본 발명은 이에 한정되지 않으며, 상기 적어도 하나의 영상 처 리는 상기 제1 객체에 대응하는 상기 제1 영역에 대한 이미지 보간, 색 보정, 감마 보정, 색 변환 또는 그 밖에 다양한 영상 처리를 더 포함할 수 있다. 상기 제1 정보에 대응하는 상기 제1 라벨이 존재하지 않는 경우에(단계 S310: 아니오), 별다른 영상 처리 없이, 즉 상기 제2 영상을 획득하지 않고 종료할 수 있다. 일 실시예에서, 도 10a의 영상이 상기 제1 영상이고, 도 10b의 영상이 상기 제2 영상일 수 있다. 구체적으로, 글자를 포함하는 전단지 및 자전거를 포함하는 도 10a의 영상을 상기 제1 영상으로 캡쳐하고, 이 때 자전거에 대해 제1 자동 초점 조절을 수행하여 상기 제1 영상으로 캡쳐할 수 있다. 도 10a의 영상 및 영상 내의 객체들을 분석하여 장면 타입을 \"길거리\"로 검출하고 객체들에 대해 \"글자\" 및 \"자전거\"로 라벨들을 할당하며 객체들의 위치를 나타내는 객체 영역들을 검출할 수 있다. 이후에, \"글자를 또렷하게 만들어(make the text clear)\" 라는 구문을 포함하는 음성 정보를 사용자 커맨드 신호로서 수신하는 경우에, 상기 사용자 커맨드 신호를 분석하여 \"글자\" 및 \"또렷하게\"를 각각 제1 정보 및 제2 정보로서 추출할 수 있다. 상기 제1 정보인 \"글자\"에 대응하는 상기 라벨이 존재하므로, 글자를 포함하는 전단지에 대해 제2 자동 초점 조절을 수행하여 제3 영상을 캡쳐하고 상기 제3 영상의 선명도(sharpness)를 증가시키며 이에 대한 도 10b의 영상을 상기 제2 영상으로 획득할 수 있 다. 일 실시예에서, 도 11a의 영상이 상기 제1 영상이고, 도 11b의 영상이 상기 제2 영상일 수 있다. 구체적으로, 피자, 포크, 숟가락 등을 포함하는 도 11a의 영상을 상기 제1 영상으로 캡쳐하고, 이 때 피자에 대해 제1 자동 초점 조절을 수행하여 상기 제1 영상으로 캡쳐할 수 있다. 도 11a의 영상 및 영상 내의 객체들을 분석하여 장면 타입을 \"식당\"으로 검출하고 객체들에 대해 \"피자\", \"포크\" 및 \"숟가락\"으로 라벨들을 할당하며 객체들의 위치 를 나타내는 객체 영역들을 검출할 수 있다. 이후에, \"피자를 컬러풀하게 만들어(make the pizza colorful)\" 라 는 구문을 포함하는 음성 정보를 사용자 커맨드 신호로서 수신하는 경우에, 상기 사용자 커맨드 신호를 분석하 여 \"피자\" 및 \"컬러풀하게\"를 각각 제1 정보 및 제2 정보로서 추출할 수 있다. 상기 제1 정보인 \"피자\"에 대응 하는 상기 라벨이 존재하므로, 피자에 대해 제2 자동 초점 조절을 수행하여 제3 영상을 캡쳐하고 상기 제3 영상 의 색 포화도 및/또는 콘트라스트를 조절하며 이에 대한 도 11b의 영상을 상기 제2 영상으로 획득할 수 있다.또는, 상기 제1 영상에서 이미 피자에 대한 제1 자동 초점 조절이 수행되어 있으므로, 상기 제3 영상을 캡쳐하 는 동작은 생략하며, 상기 제1 영상의 색 포화도 및/또는 콘트라스트를 조절하며 이에 대한 도 11b의 영상을 상 기 제2 영상으로 획득할 수 있다. 일 실시예에서, 상기 적어도 하나의 영상 처리는 상기 제3 영상 내에서 상기 제1 객체에 대응하는 제1 영역에 대해서만 부분적으로 수행될 수 있다. 다만 본 발명은 이에 한정되지 않으며, 상기 적어도 하나의 영상 처리는 상기 제3 영상에 대해 전체적으로 수행될 수도 있다. 도 12는 도 1의 제2 영상을 획득하는 단계의 또 다른 예를 나타내는 순서도이다. 이하 도 7 및 9와 중복되는 설 명은 생략한다. 도 1 및 12를 참조하면, 상기 제2 영상을 획득하는데 있어서(단계 S300), 도 12의 단계 S310, S325 및 S330은 도 9의 단계 S310, S325 및 S330과 각각 실질적으로 동일할 수 있다. 상기 제1 정보에 대응하는 상기 제1 라벨이 존재하지 않는 경우에(단계 S310: 아니오), 상기 제2 영상을 획득하 지 않고 종료하는 대신에, 상기 제1 라벨의 존재 여부를 다시 한번 판단하기 위한 추가적인 정보가 필요한지 확 인할 수 있다(단계 S340). 상기 추가적인 정보가 필요한 경우에(단계 S340: 예), 추가 사용자 커맨드 신호를 요청하고(단계 S350), 상기 추가 사용자 커맨드 신호를 수신 및 분석하여 상기 제1 정보를 다시 검출하며(단계 S360), 다시 검출된 상기 제 1 정보에 기초하여 단계 S310, S325 및 S330을 수행할 수 있다. 상기 추가적인 정보가 필요하지 않은 경우에(단 계 S340: 아니오), 별다른 영상 처리 없이, 즉 상기 제2 영상을 획득하지 않고 종료할 수 있다. 일 실시예에서, 단지 상기 복수의 객체들에 대한 상기 복수의 라벨들 중 상기 제1 객체에 대한 상기 제1 정보에 대응하는 상기 제1 라벨이 존재하지 않는 경우에, 상기 추가 사용자 커맨드 신호를 요청할 수 있다. 예를 들어, 도 8a의 영상이 상기 제1 영상인 경우에, \"글자를 또렷하게 만들어\" 라는 구문을 포함하는 음성 정보를 사용자 커맨드 신호로서 수신하게 되면, 상기 제1 영상 내에 글자가 존재하지 않으므로, \"다른 객체를 선택하세요\" 라 는 메시지를 출력하는 방식으로 상기 추가 사용자 커맨드 신호를 요청할 수 있다. 다른 실시예에서, 상기 제1 정보만으로는 상기 복수의 객체들에 대한 상기 복수의 라벨들 중 상기 제1 객체에 대한 상기 제1 정보에 대응하는 상기 제1 라벨이 존재하는지 확인이 불가능한 경우에, 상기 추가 사용자 커맨드 신호를 요청할 수 있다. 예를 들어, 도 5의 영상이 상기 제1 영상인 경우에, \"얼굴에 초점을 맞춰\" 라는 구문을 포함하는 음성 정보를 사용자 커맨드 신호로서 수신하게 되면, 2명의 얼굴 중 어느 것에 초점을 맞춰야 하는지 명확하지 않으므로, \"누구의 얼굴에 초점을 맞출까요?\" 라는 메시지를 출력하는 방식으로 상기 추가 사용자 커 맨드 신호를 요청할 수 있다. 실시예에 따라서, 최초에 상기 사용자 커맨드 신호를 수신하는 단계에서 보다 구체적이고 상세한 정보를 요청/ 수신하도록 구현될 수도 있다. 예를 들어, 도 5의 영상이 상기 제1 영상인 경우에, \"왼쪽 사람의 얼굴에 초점을 맞춰\" 라는 구문을 포함하는 음성 정보를 사용자 커맨드 신호로서 수신하게 되면, 추가 사용자 커맨드 신호의 요청 없이 영상 처리를 바로 수행할 수 있다. 실시예에 따라서, 영상 처리 방법을 수행하는 영상 처리 장치는 거리 센서 또는 거리 예측이 가능한 장치를 더 포함하여 구현되며, 거리 정보에 기초하여 영상 처리를 수행하도록 구현될 수도 있다. 예를 들어, 카메라로부터 각 객체들까지의 거리가 서로 다른 경우에, \"가장 가깝게 있는 사람에 초점을 맞춰\" 또는 \"가장 멀리 있는 자동 차에 초점을 맞춰\" 등의 구문을 포함하는 음성 정보를 사용자 커맨드 신호로서 수신하게 되면, 상기 거리 센서 또는 상기 거리 예측이 가능한 장치로부터 받은 상기 거리 정보를 이용하여 추가 사용자 커맨드 신호의 요청 없 이 영상 처리를 바로 수행할 수 있다. 한편, 도시하지는 않았으나, 도 12에 도시된 상기 추가 사용자 커맨드 신호를 요청하는 동작은 도 7의 실시예에 도 적용될 수 있다. 이상, 도 4 내지 12를 참조하여 특정 영상, 특정 객체 및 특정 영상 처리에 기초하여 본 발명의 실시예들을 설 명하였으나, 본 발명은 이에 한정되지 않으며, 임의의 영상 내의 임의의 객체에 대해 원하는 임의의 효과를 선 택적/부분적으로 적용하는 경우에 대해 확대 적용될 수 있다. 또한, 복수의 객체들을 포함하는 영상에 기초하여 본 발명의 실시예들을 설명하였으나, 본 발명은 이에 한정되지 않으며, 하나의 객체를 포함하는 경우에 대해 적 용될 수도 있다. 한편, 본 발명의 실시예들은 컴퓨터로 판독 가능한 매체에 저장된 컴퓨터로 판독 가능한 프로그램 코드를 포함 하는 제품 등의 형태로 구현될 수도 있다. 상기 컴퓨터로 판독 가능한 프로그램 코드는 다양한 컴퓨터 또는 다 른 데이터 처리 장치의 프로세서로 제공될 수 있다. 상기 컴퓨터로 판독 가능한 매체는 컴퓨터로 판독 가능한 신호 매체 또는 컴퓨터로 판독 가능한 기록 매체일 수 있다. 상기 컴퓨터로 판독 가능한 기록 매체는 명령어 실 행 시스템, 장비 또는 장치 내에 또는 이들과 접속되어 프로그램을 저장하거나 포함할 수 있는 임의의 유형적인 매체일 수 있다. 예를 들어, 상기 컴퓨터로 판독 가능한 매체는 비일시적(non-transitory) 저장 매체의 형태로 제공될 수 있다. 여기서, 비일시적은 저장 매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장 매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 도 13, 14 및 15는 본 발명의 실시예들에 따른 영상 처리 장치를 나타내는 블록도들이다. 이하 도 2와 중복되는 설명은 생략한다. 도 13을 참조하면, 영상 처리 장치(100a)는 영상 촬상 장치, 영상 분석부(300a), 커맨드 수신부, 커 맨드 분석부 및 영상 처리부를 포함하며, 인공 지능 프로세싱 소자를 더 포함할 수 있다. 인공 지능 프로세싱 소자가 영상 분석부(300a)에 포함되는 것을 제외하면, 도 13의 영상 처리 장치(100a) 는 도 2의 영상 처리 장치와 실질적으로 동일할 수 있다. 도 13의 영상 촬상 장치, 커맨드 수신부 , 커맨드 분석부, 영상 처리부 및 인공 지능 프로세싱 소자는 도 2의 영상 촬상 장치 , 커맨드 수신부, 커맨드 분석부, 영상 처리부 및 인공 지능 프로세싱 소자와 각각 실질적으로 동일할 수 있다. 도 14를 참조하면, 영상 처리 장치(100b)는 영상 촬상 장치, 영상 분석부, 커맨드 수신부, 커맨 드 분석부 및 영상 처리부(600b)를 포함하며, 인공 지능 프로세싱 소자를 더 포함할 수 있다. 인공 지능 프로세싱 소자가 영상 처리부(600b)에 포함되는 것을 제외하면, 도 14의 영상 처리 장치(100a) 는 도 2의 영상 처리 장치와 실질적으로 동일할 수 있다. 도 14의 영상 촬상 장치, 영상 분석부 , 커맨드 수신부, 커맨드 분석부 및 인공 지능 프로세싱 소자는 도 2의 영상 촬상 장치 , 영상 분석부, 커맨드 수신부, 커맨드 분석부 및 인공 지능 프로세싱 소자와 각각 실질적으로 동일할 수 있다. 도 15를 참조하면, 영상 처리 장치(100c)는 영상 촬상 장치, 영상 분석부, 커맨드 수신부(400c), 커 맨드 분석부(500c) 및 영상 처리부를 포함하며, 인공 지능 프로세싱 소자를 더 포함할 수 있다. 커맨드 수신부(400c) 및 커맨드 분석부(500c)의 구성이 변경되는 것을 제외하면, 도 15의 영상 처리 장치(100 c)는 도 2의 영상 처리 장치와 실질적으로 동일할 수 있다. 도 15의 영상 촬상 장치, 영상 분석부 , 영상 처리부 및 인공 지능 프로세싱 소자는 도 2의 영상 촬상 장치, 영상 분석부, 영상 처리부 및 인공 지능 프로세싱 소자와 각각 실질적으로 동일할 수 있다. 도 15의 실시예에서, 사용자 커맨드 신호(UCS)는 상기 사용자로부터의 터치 정보(또는 터치 이벤트)에 대응할 수 있다. 커맨드 수신부(400c)는 상기 사용자로부터의 터치 정보에 대응하는 터치 신호(또는 감지 신호)(TS)를 사용자 커맨드 신호(UCS)로서 수신하는 터치 센서 패널(Touch Sensor Panel; TSP)을 포함하고, 커맨드 분 석부(500c)는 상기 사용자로부터의 터치 정보를 분석하여 제1 영상 처리 정보(PCS_INF1)를 획득하는 터치 컨트 롤러를 포함할 수 있다. 예를 들어, 터치 센서 패널은 복수의 감지 커패시터들을 포함하며, 객체(예 를 들어, 사용자의 손가락)의 접촉 또는 근접에 응답하여 커패시턴스 값이 가변될 수 있다. 예를 들어, 터치 컨 트롤러는 상기 감지 커패시터들의 커패시턴스 값의 가변에 기초하여 객체의 접촉 또는 근접을 인식하고, 그에 따른 적절한 동작(예를 들어, 영상 내의 객체 선택 및/또는 영상 처리)을 수행하도록 명령을 출력할 수 있 다. 한편, 도시하지는 않았으나, 도 15에 도시된 터치 센서 패널 및 터치 컨트롤러를 포함하는 영상 처리 장치(100c)에 대해서도 도 13 및 14를 참조하여 상술한 것처럼 인공 지능 프로세싱 소자의 배치가 변경될 수 있다. 이상, 도 1 내지 15를 참조하여 사용자의 음성 정보 및 사용자로부터의 터치 정보 중 적어도 하나를 사용자 커 맨드 신호로서 수신하는 경우에 기초하여 본 발명의 실시예들을 설명하였으나, 본 발명은 이에 한정되지 않으며, 커맨드 수신부 및 커맨드 분석부는 사용자의 편의를 위해 임의의 트리거 정보(예를 들어, 움직임 (motion) 정보, 제스쳐(gesture) 정보 등)를 사용자 커맨드 신호로서 수신 및 분석하는 것으로 확대 적용될 수 있다.도 16은 본 발명의 실시예들에 따른 전자 시스템을 나타내는 블록도이다. 도 16을 참조하면, 전자 시스템은 프로세서, 통신(connectivity)부, 메모리 장치, 사 용자 인터페이스, 파워 서플라이 및 영상 처리 장치를 포함한다. 예를 들어, 전자 시스템 은 임의의 모바일 시스템 또는 컴퓨팅 시스템일 수 있다. 프로세서는 전자 시스템의 전반적인 동작을 제어하며, 운영 체제, 어플리케이션 등을 실행하고, 특 정 계산들 또는 태스크들과 같은 다양한 컴퓨팅 기능들을 실행할 수 있다. 통신부는 외부 장치와 통신을 수행할 수 있다. 메모리 장치는 프로세서에 의해 처리되는 데이터를 저장하거나, 동작 메모리 (working memory)로서 작동할 수 있다. 사용자 인터페이스는 키패드, 버튼, 마이크, 터치 스크린 등과 같 은 하나 이상의 입력 장치, 및/또는 스피커, 디스플레이 장치 등과 같은 하나 이상의 출력 장치를 포함할 수 있 다. 파워 서플라이는 전자 시스템의 동작 전압을 공급할 수 있다. 영상 처리 장치는 프로세서에 의해 제어되고, 본 발명의 실시예들에 따른 영상 처리 장치일 수 있 다. 영상 처리 장치는 인공 지능 기반으로 현재 영상을 분석하여 영상 정보를 획득하고, 음성 정보와 같 은 사용자의 조작이 최소한으로 요구되는 신호를 사용자 커맨드 신호로서 수신하며, 수신된 사용자 커맨드 신호 및 획득된 영상 정보에 기초하여 현재 영상에 포함되는 특정 객체에 대해 원하는 특정한 효과를 적용할 수 있다. 따라서, 사용자가 원하는 특정 객체에 초점을 맞추어 그에 적합한 효과를 선택적/부분적으로 적용함으로 써, 현재 영상에 대한 다양한 효과를 효과적으로 표현하고 사용자의 욕구를 만족시킬 수 있다. 산업상 이용가능성 본 발명의 실시예들은 영상 처리 장치 및 시스템을 포함하는 임의의 전자 장치 및 시스템에 유용하게 이용될 수 있다. 예를 들어, 본 발명의 실시예들은 PC(Personal Computer), 서버 컴퓨터(server computer), 데이터 센터 (data center), 워크스테이션(workstation), 노트북(laptop), 핸드폰(cellular), 스마트 폰(smart phone), MP3 플레이어, PDA(Personal Digital Assistant), PMP(Portable Multimedia Player), 디지털 TV, 디지털 카메라, 포터블 게임 콘솔(portable game console), 네비게이션(navigation) 기기, 웨어러블(wearable) 기기, IoT(Internet of Things) 기기, IoE(Internet of Everything) 기기, e-북(e-book), VR(Virtual Reality) 기기, AR(Augmented Reality) 기기 등과 같은 전자 시스템에 더욱 유용하게 적용될 수 있다."}
{"patent_id": "10-2019-0159846", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술분야의 숙련된 당업자는 하기의 특 허청구범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 것이다."}
{"patent_id": "10-2019-0159846", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예들에 따른 영상 처리 방법을 나타내는 순서도이다. 도 2는 본 발명의 실시예들에 따른 영상 처리 장치를 나타내는 블록도이다.도 3a 및 3b는 본 발명의 실시예들에 따른 영상 처리 장치에 포함되는 인공 지능 프로세싱 소자에 의해 구동되 는 인공 신경망 구조의 예를 설명하기 위한 도면들이다. 도 4는 도 1의 제1 영상 및 제1 영상 정보를 획득하는 단계의 일 예를 나타내는 순서도이다. 도 5는 도 4의 제1 영상 및 제1 영상 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 6은 도 1의 제1 영상 처리 정보를 획득하는 단계의 일 예를 나타내는 순서도이다. 도 7은 도 1의 제2 영상을 획득하는 단계의 일 예를 나타내는 순서도이다. 도 8a 및 8b는 도 7의 제2 영상을 획득하는 동작을 설명하기 위한 도면들이다. 도 9는 도 1의 제2 영상을 획득하는 단계의 다른 예를 나타내는 순서도이다. 도 10a, 10b, 11a 및 11b는 도 9의 제2 영상을 획득하는 동작을 설명하기 위한 도면들이다. 도 12는 도 1의 제2 영상을 획득하는 단계의 또 다른 예를 나타내는 순서도이다. 도 13, 14 및 15는 본 발명의 실시예들에 따른 영상 처리 장치를 나타내는 블록도들이다. 도 16은 본 발명의 실시예들에 따른 전자 시스템을 나타내는 블록도이다."}
