{"patent_id": "10-2021-7028001", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0121215", "출원번호": "10-2021-7028001", "발명의 명칭": "단열 진화 경로를 예측하기 위한 방법 및 장치, 디바이스 및 저장 매체", "출원인": "텐센트 테크놀로지", "발명자": "천 유친"}}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "단열 진화 경로(adiabatic evolution path)를 예측하기 위한 방법으로서,상기 방법은 컴퓨터 디바이스에 적용되며,상기 방법은,양자 컴퓨테이션 문제(quantum computation problem)의 타깃 해밀토니언(target Hamiltonian)(H1)을 획득하는단계;상기 타깃 해밀토니언(H1)에 기반하여 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(target ground stateenergy)(E1)를 결정하는 단계;상기 초기 해밀토니언(H0)으로부터 상기 타깃 기저 상태 에너지(E1)로의 단열 진화 경로에 대한 검색을 체스판게임(chessboard game)으로 컨버팅(converting)하는 단계;뉴럴 네트워크와 결합한 몬테카를로 트리 검색(Monte Carlo tree search)을 통해 상기 체스판 게임의 최적의 체스판 경로를 결정하는 단계; 및상기 최적의 체스판 경로에 기반하여 상기 단열 진화 경로를 출력하는 단계를 포함하는, 단열 진화 경로를 예측하기 위한 방법."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 상기 체스판 게임의 최적의 체스판 경로를 결정하는단계는,상기 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 상기 체스판 게임의 예측된 체스판 경로를 결정하는단계; 상기 예측된 체스판 경로에 기반하여 예측된 단열 진화 경로를 획득하는 단계;상기 예측된 단열 진화 경로가 최종 상태로 진화할 때, 양자 컴퓨테이션 환경(quantum computationenvironment)에 기반하여, 상기 예측된 단열 진화 경로의 에너지 고유값(energy eigenvalue)(E)을 계산하는 단계;상기 에너지 고유값(E)이 승리 조건을 충족하지 않는 경우, 현재 예측 프로세스에 기반하여 상기 뉴럴 네트워크의 파라미터를 업데이트하는 단계 및 상기 업데이트 후에 다시, 상기 뉴럴 네트워크와 결합한 몬테카를로 트리검색을 통해 상기 체스판 게임의 예측된 체스판 경로를 결정하는 단계를 수행하는 단계; 및상기 에너지 고유값(E)이 승리 조건을 충족하는 경우, 상기 예측된 체스판 경로를 상기 체스판 게임의 최적의체스판 경로로서 결정하는 단계를 포함하고, 상기 승리 조건은, 상기 에너지 고유값(E)과 상기 타깃 기저 상태 에너지(E1) 간의 차이가 임계치 미만임을 지시하는, 단열 진화 경로를 예측하기 위한 방법."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 공개특허 10-2021-0121215-3-상기 뉴럴 네트워크는 정책 네트워크(policy network) 및 가치 네트워크(value network)를 포함하고, 상기 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 상기 체스판 게임의 예측된 체스판 경로를 결정하는단계는, 각각의 계층에서의 노드의 액션 확률 분포(action probability distribution)(π)를 출력하기 위해, 상기 몬테카를로 트리 검색을 통해 상기 체스판 게임에 대응하는 게임 트리를 검색하는 단계 ―각각의 계층에서의 노드의액션 확률 분포(π)는 그 다음 말(piece)의 확률 분포 및 후보 이동 포지션(candidate move position)을 표현함―; 및가장 높은 액션 확률 분포(π)를 갖는 각각의 계층에서의 노드의 타깃 이동 포지션에 기반하여 상기 체스판 게임의 예측된 체스판 경로를 획득하는 단계를 포함하고, 상기 에너지 고유값(E)이 승리 조건을 충족하는 경우, 현재 예측 프로세스에 기반하여 상기 뉴럴 네트워크의 파라미터를 업데이트하는 단계는,상기 에너지 고유값(E)이 승리 조건을 충족하지 않는 경우, 상기 예측된 체스판 경로를 상기 뉴럴 네트워크의입력으로서 취하여, 상기 정책 네트워크에 의해 출력된 정책 벡터(p) 및 상기 가치 네트워크에 의해 출력된 가치 이익(value benefit)(v)을 획득하는 단계; 및상기 정책 벡터(p)와 상기 액션 확률 분포(π) 간의 유사성을 최대화하고 그리고 승리하지 못한 것에 대한 보상값(z)과 상기 가치 이익(v) 간의 에러를 최소화하는 것을 목표로함으로써, 상기 뉴럴 네트워크의 파라미터를 업데이트하는 단계를 포함하는, 단열 진화 경로를 예측하기 위한 방법."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 각각의 계층에서의 노드의 액션 확률 분포(π)를 출력하기 위해, 상기 몬테카를로 트리 검색을 통해 상기체스판 게임에 대응하는 게임 트리를 검색하는 단계는,상기 정책 네트워크에 의해, 상기 체스판 게임의 i번째 계층에서의 타깃 노드(bi)에 이은 (i+1)번째 계층에서의노드(bi+1)의 후보 이동 포지션(ai+1) 및 이동 확률(pi+1)을 출력하는 단계 ―상기 i번째 계층에서의 타깃 노드(bi)는 상기 i번째 계층에서의 노드의 타깃 이동 포지션에 대응하며, i는 (m-1)보다 크지 않은 정수임―;상기 후보 이동 포지션(ai+1)의 가치 이익(vi+1)을 획득하기 위해, 상기 후보 이동 포지션(ai+1)에 기반하여 상기(i+1)번째 계층에서의 노드(bi+1)를 확장하고 상기 가치 네트워크에 의해 상기 (i+1)번째 계층에서의 노드(bi+1)를 평가하는 단계;상기 이동 확률(pi+1) 및 상기 가치 이익(vi+1)에 기반하여 신뢰도 상한(confidence upper limit)(U)을 참조로 상기 (i+1)번째 계층에서의 노드(bi+1)에서 타깃 노드를 결정하는 단계;상기 (i+1)번째 계층에서의 노드가 m번째 계층에서의 노드가 아닌 경우, 상기 (i+1)번째 계층에서의 타깃 노드를 상기 i번째 계층의 새로운 타깃 노드로서 취함으로써, 전술한 3개의 단계들을 수행하는 단계; 및상기 (i+1)번째 계층에서의 노드가 m번째 계층에서의 노드인 경우, 각각의 계층에서의 노드의 액션 확률 분포(π)를 출력하는 단계를 포함하는, 단열 진화 경로를 예측하기 위한 방법."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2021-0121215-4-제4항에 있어서, 상기 신뢰도 상한은 상기 후보 이동 포지션의 이력 검색들의 횟수와 관련되는, 단열 진화 경로를 예측하기 위한방법."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서, 상기 초기 해밀토니언(H0)으로부터 타깃 기저 상태 에너지(E1)로의 단열 진화 경로에 대한 검색을 체스판 게임으로 컨버팅하는 단계는,상기 초기 해밀토니언(H0)으로부터 상기 타깃 기저 상태 에너지(E1)로의 단열 진화 경로를 단열 진화 함수(s(t))로 표현하는 단계;푸리에 변환(Fourier transform)을 통해 주파수 도메인에서 상기 단열 진화 함수(s(t))를 상태 벡터 시퀀스(b)로 변환하는 단계 ―상기 상태 벡터 시퀀스(b)는 m개의 벡터 차원들을 포함하고, 상기 벡터 차원들 각각은 2L의범위를 가짐 ―; 및상기 벡터 차원들의 수(m) 및 상기 벡터 차원들 각각의 범위(2L)에 기반하여 컨버전(conversion)을 통해 체스판게임을 획득하는 단계를 포함하며, 상기 체스판 게임에 대응하는 체스판은 2L/Δ개의 행(row)들 및 m개의 열(column)들을 포함하고, 각각의 열은말의 이동 포지션에 대응하고, Δ는 이산화 스텝 길이(discretization step length)를 표현하는, 단열 진화 경로를 예측하기 위한 방법."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "단열 진화 경로를 예측하기 위한 장치로서,양자 컴퓨테이션 문제의 타깃 해밀토니언(H1)을 획득하도록 구성된, 획득 모듈;상기 타깃 해밀토니언(H1)에 기반하여 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(E1)를 결정하도록구성된, 결정 모듈;상기 초기 해밀토니언(H0)으로부터 상기 타깃 기저 상태 에너지(E1)로의 단열 진화 경로에 대한 검색을 체스판게임으로 컨버팅하도록 구성된, 컨버전 모듈; 및뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 상기 체스판 게임의 최적의 체스판 경로를 결정하고, 상기 최적의 체스판 경로에 기반하여 상기 단열 진화 경로를 출력하도록 구성된, 트리 검색 모듈을 포함하는 단열 진화 경로를 예측하기 위한 장치."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 트리 검색 모듈은 추가로,상기 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 상기 체스판 게임의 예측된 체스판 경로를결정하고; 상기 예측된 체스판 경로에 기반하여 예측된 단열 진화 경로를 획득하고; 상기 예측된 단열 진화 경로가 최종 상태로 진화할 때, 양자 컴퓨테이션 환경에 기반하여, 상기 예측된 단열 진화 경로의 에너지 고유값(E)을 계산하고; 상기 에너지 고유값(E)이 승리 조건을 충족하지 않는 경우, 현재 예측 프로세스에 기반하여 상기 뉴럴 네트워크의 파라미터를 업데이트하고 그리고 상기 업데이트 후에 다시, 상기 뉴럴 네트워크와 결합한 몬테카를로 트리검색을 통해 상기 체스판 게임의 예측된 체스판 경로를 결정하고; 그리고 공개특허 10-2021-0121215-5-상기 에너지 고유값(E)이 승리 조건을 충족하는 경우, 상기 예측된 체스판 경로를 상기 체스판 게임의 최적의체스판 경로로서 결정하도록 구성되고,상기 승리 조건은, 상기 에너지 고유값(E)과 상기 타깃 기저 상태 에너지(E1) 간의 차이가 임계치 미만임을 지시하는, 단열 진화 경로를 예측하기 위한 장치."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 뉴럴 네트워크는 정책 네트워크 및 가치 네트워크를 포함하고, 상기 트리 검색 모듈은 추가로,각각의 계층에서의 노드의 액션 확률 분포(π)를 출력하기 위해, 상기 몬테카를로 트리 검색을 통해 상기 체스판 게임에 대응하는 게임 트리를 검색하고 ―각각의 계층에서의 노드의 액션 확률 분포(π)는 그 다음 말의 확률 분포 및 후보 이동 포지션을 표현함―; 가장 높은 액션 확률 분포(π)를 갖는 각각의 계층에서의 노드의 타깃 이동 포지션에 기반하여 상기 체스판 게임의 예측된 체스판 경로를 획득하도록 구성되고,상기 트리 검색 모듈은 추가로,상기 에너지 고유값(E)이 승리 조건을 충족하지 않는 경우, 상기 예측된 체스판 경로를 상기 뉴럴 네트워크의입력으로서 취하여, 상기 정책 네트워크에 의해 출력된 정책 벡터(p) 및 상기 가치 네트워크에 의해 출력된 가치 이익(v)을 획득하고; 그리고 상기 정책 벡터(p)와 상기 액션 확률 분포(π) 간의 유사성을 최대화하고 그리고 승리하지 못한 것에 대한 보상값(z)과 상기 가치 이익(v) 간의 에러를 최소화하는 것을 목표로 함으로써, 상기 뉴럴 네트워크의 파라미터를업데이트하도록 구성되는, 단열 진화 경로를 예측하기 위한 장치."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 트리 검색 모듈은 추가로,상기 정책 네트워크에 의해, 상기 체스판 게임의 i번째 계층에서의 타깃 노드(bi)에 이은 (i+1)번째 계층에서의노드(bi+1)의 후보 이동 포지션(ai+1) 및 이동 확률(pi+1)을 출력하고 ―상기 i번째 계층에서의 타깃 노드(bi)는 상기 i번째 계층에서의 노드의 타깃 이동 포지션에 대응하며, i는 (m-1)보다 크지 않은 정수임―; 상기 후보 이동 포지션(ai+1)의 가치 이익(vi+1)을 획득하기 위해, 상기 후보 이동 포지션(ai+1)에 기반하여 상기(i+1)번째 계층에서의 노드(bi+1)를 확장하고 상기 가치 네트워크에 의해 상기 (i+1)번째 계층에서의 노드(bi+1)를 평가하고; 상기 이동 확률(pi+1) 및 상기 가치 이익(vi+1)에 기반하여 신뢰도 상한(U)을 참조로 상기 (i+1)번째 계층에서의노드(bi+1)에서 타깃 노드를 결정하고; 상기 (i+1)번째 계층에서의 노드가 m번째 계층에서의 노드가 아닌 경우, 상기 (i+1)번째 계층에서의 타깃 노드를 상기 i번째 계층의 새로운 타깃 노드로서 취함으로써, 전술한 3개의 단계들을 수행하고; 상기 (i+1)번째 계층에서의 노드가 m번째 계층에서의 노드인 경우, 각각의 계층에서의 노드의 액션 확률 분포(π)를 출력하도록 구성되는, 단열 진화 경로를 예측하기 위한 장치."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2021-0121215-6-제10항에 있어서, 상기 신뢰도 상한은 상기 후보 이동 포지션의 이력 검색들의 횟수와 관련되는, 단열 진화 경로를 예측하기 위한장치."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항 내지 제11항 중 어느 한 항에 있어서, 상기 컨버전 모듈은 추가로,초기 해밀토니언(H0)로부터 타깃 기저 상태 에너지(E1)로의 단열 진화 경로를 단열 진화 함수(s(t))로표현하고; 푸리에 변환을 통해 주파수 도메인에서 상기 단열 진화 함수(s(t))를 상태 벡터 시퀀스(b)로 변환하고 ―상기상태 벡터 시퀀스(b)는 m개의 벡터 차원들을 포함하고, 상기 벡터 차원들 각각은 2L의 범위를 가짐―; 상기 벡터 차원들의 수(m) 및 상기 벡터 차원들 각각의 값 범위(2L)에 기반하여 컨버전을 통해 체스판 게임을획득하도록 구성되며, 상기 체스판 게임에 대응하는 체스판은 2L/Δ개의 행들 및 m개의 열들을 포함하고, 각각의 열은 말의 이동 포지션에 대응하고, Δ는 이산화 스텝 길이를 표현하는, 단열 진화 경로를 예측하기 위한 장치."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨터 디바이스로서,적어도 하나의 명령, 적어도 하나의 프로그램, 코드 세트 또는 명령 세트를 저장하도록 구성된 메모리; 및제1항 내지 제6항 중 어느 한 항에 따른 방법을 구현하기 위해, 상기 적어도 하나의 명령, 상기 적어도 하나의프로그램, 상기 코드 세트 또는 명령 세트를 로딩 및 실행하도록 구성된 프로세서를 포함하는, 컴퓨터 디바이스."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항 내지 제6항 중 어느 한 항에 따른 방법에 의해 예측된 단열 진화 경로에 기반하여 단열 진화를 수행하도록 구성된, 양자 컴퓨터."}
{"patent_id": "10-2021-7028001", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "적어도 하나의 명령, 적어도 하나의 프로그램, 코드 세트 또는 명령 세트를 저장하는 컴퓨터-판독가능 저장 매체로서,상기 적어도 하나의 명령, 상기 적어도 하나의 프로그램, 상기 코드 세트 또는 명령 세트는 제1항 내지 제6항중 어느 한 항에 따른 방법을 구현하도록 프로세서에 의해 로딩 및 실행되는, 컴퓨터-판독가능 저장 매체."}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 인공 지능 분야에 관한 것이며, 단열 진화 경로를 예측하기 위한 방법 및 장치, 디바이스 및 저장 매 체를 제공한다. 이 방법은: 양자 컴퓨팅 문제의 타깃 해밀토니언(H1)을 획득하는 단계; 타깃 해밀토니언(H1)에 따라 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(E1)를 결정하는 단계; 초기 해밀토니언(H0)으로부터의 타깃 기저 상태 에너지(E1)에 대해 검색하는 단열 진화 경로를 체스판 게임으로 컨버팅하는 단계; 뉴럴 네트워크와 결 합한 몬테카를로 트리 검색을 사용함으로써 체스판 게임의 최적의 체스판 경로를 해결하는 단계; 및 최적의 체스 판 경로에 따라 단열 진화 경로를 출력하는 단계를 포함한다. 본 출원에서, 모바일 단말의 3차원 얼굴 메시(face mesh)의 재구성의 경우, 단열 진화 경로의 각각의 상태에 대한 복수의 후보 액션들이 존재할 때, 안정적인 수렴 단열 진화 경로가 여전히 신속하고 효율적으로 해결될 수 있다."}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은, 2020년 1월 10일자로 \"단열 진화 경로(adiabatic evolution path)를 예측하기 위한 방법 및 장치, 디바이스 및 저장 매체\"라는 명칭으로 출원된, 중국 특허 출원 제202010027656.8호에 대한 우선권을 주장하며, 이 출원은 그 전체가 인용에 의해 본원에 포함된다. 본 출원의 실시예들은 인공 지능 머신 학습(machine learning of artificial intelligence) 분야에 관한 것으 로, 특히 단열 진화 경로(adiabatic evolution path)를 예측하기 위한 방법 및 장치, 디바이스 및 저장 매체에 관한 것이다."}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "단열 양자 컴퓨테이션(adiabatic quantum computation)은 양자 컴퓨터를 구현하기 위한 이론적 모델을 수반한다. 단열 양자 컴퓨테이션은 컴퓨테이션 문제를 물리적 프로세스를 실현하는 것으로 컨버팅(converting) 함으로써 구현되며, 컴퓨테이션 문제에 대한 답(answer)은 타깃 해밀토니언(target Hamiltonian)의 기저 상태 (ground state)에 의해 반영된다. 단열 양자 컴퓨테이션의 컴퓨테이션 프로세스는, 기저 상태가 용이하게 제공되는 초기 해밀토니언(H0)으로부터 타깃 해밀토니언(H1)으로 단열적으로 진화함으로써 구현된다. 진화 프로세스는 단열 진화 경로(adiabatic evolution path)로 지칭된다. 전체 단열 진화 프로세스의 시간 길이(T)가 충분히 길면(즉, 진화가 충분히 느리 게 수행되면), 양자 컴퓨터(quantum computer)에 의해 제공되는 양자 상태는 순간적인 해밀토니언의 기저 상태 를 유지할 것이다. 종래 기술에서는, 최적의 단열 진화 경로를 결정하기 위해 강화 학습(reinforcement learning)에서의 Q-학습(Q-learning)이 채택되었다. 단열 진화 경로에서 하나의 시스템 상태로부터 그 다음 시스템 상태로 진화하기 위한 더 많은 선택적인 액션들 이 있는 경우, Q-학습의 효율이 감소되고 수렴(convergence)이 불안정해지는 경향이 있다. 본 출원의 실시예들에 따라, 단열 진화 경로를 예측하기 위한 방법 및 장치, 디바이스 및 저장 매체가 제공되며, 이는, 최적의 단열 진화 경로 및 최적의 단열 진화 경로의 수렴을 예측할 때 효율을 향상시킬 수 있 다. 기술적 해결책들은 다음과 같이 설명된다. 본 출원의 일 양상에 따르면, 단열 진화 경로를 예측하기 위한 방법이 제공된다. 이 방법은, 양자 컴퓨테이션 문제(quantum computation problem)의 타깃 해밀토니언(H1)을 획득하는 단계; 타깃 해밀토니언(H1)에 기반하여 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(target ground state energy)(E1)를 결정하는 단계; 초기 해밀토니언(H0)으로부터 타깃 기저 상태 에너지(E1)로의 단열 진화 경로에 대한 검색을 체스판 게임 (chessboard game)으로 컨버팅하는 단계; 뉴럴 네트워크와 결합한 몬테카를로 트리 검색(Monte Carlo tree search)을 통해 체스판 게임의 최적의 체스판 경로를 결정하는 단계; 및 최적의 체스판 경로에 기반하여 단열 진화 경로를 획득하는 단계를 포함한다. 본 출원의 양상에 따르면, 단열 진화 경로를 예측하기 위한 장치가 추가로 제공된다. 이 장치는 획득 모듈, 결 정 모듈, 컨버전 모듈(conversion module), 트리 검색 모듈(tree search module) 및 출력 모듈을 포함한다. 획 득 모듈은, 양자 컴퓨테이션 문제의 타깃 해밀토니언(H1)을 획득하도록 구성된다. 결정 모듈은, 타깃 해밀토니 언(H1)에 기반하여 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(E1)를 결정하도록 구성된다. 컨버전 모듈은, 초기 해밀토니언(H0)으로부터 타깃 기저 상태 에너지(E1)로의 단열 진화 경로에 대한 검색을 체스판 게임으로 컨버팅하도록 구성된다. 트리 검색 모듈은, 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 체스판 게임 의 최적의 체스판 경로를 결정하도록 구성된다. 출력 모듈은, 최적의 체스판 경로에 기반하여 단열 진화 경로를 획득하도록 구성된다. 본 출원의 다른 양상에 따르면, 프로세서 및 메모리를 포함하는, 본 출원의 실시예에 따른 컴퓨터 디바이스가 제공된다. 메모리는 적어도 하나의 명령, 적어도 하나의 프로그램, 코드 세트 또는 명령 세트를 저장한다. 적어 도 하나의 명령, 적어도 하나의 프로그램, 코드 세트 또는 명령 세트는 단열 진화 경로를 예측하기 위한 전술한 방법을 구현하기 위해 프로세서에 의해 로딩 및 실행된다. 본 출원의 다른 양상에 따르면, 본 출원의 실시예에 따른 양자 컴퓨터가 제공되며, 양자 컴퓨터는 전술한 방법 에 의해 예측되는 단열 진화 경로에 기반하여 단열 진화를 수행하도록 구성된다. 본 출원의 다른 양상에 따르면, 본 출원의 실시예에 따른 컴퓨터-판독가능 저장 매체가 제공되며, 컴퓨터-판독 가능 저장 매체는 적어도 하나의 명령, 적어도 하나의 프로그램, 코드 세트 또는 명령 세트를 저장한다. 적어도 하나의 명령, 적어도 하나의 프로그램, 코드 세트 또는 명령 세트는 단열 진화 경로를 예측하기 위한 전술한 방 법을 구현하기 위해 프로세서에 의해 로딩 및 실행된다. 본 출원의 다른 양상에 따르면, 본 출원의 실시예에 따른 컴퓨터 프로그램 제품이 제공되며, 컴퓨터 프로그램 제품은 프로세서에 의해 실행될 때, 단열 진화 경로를 예측하기 위한 전술한 방법을 수행하도록 구성된다. 본 출원의 양상에 따르면, 본 출원의 실시예에 따른 컴퓨터 프로그램 제품이 제공되며, 컴퓨터 프로그램 제품은 컴퓨터 명령들을 포함하고, 컴퓨터 명령들은 컴퓨터-판독가능 저장 매체에 저장된다. 컴퓨터 디바이스의 프로세 서는 컴퓨터-판독가능 저장 매체로부터 컴퓨터 명령들을 판독하고, 컴퓨터 디바이스로 하여금, 단열 진화 경로 를 예측하기 위한 전술한 방법을 수행하게 하기 위해 컴퓨터 명령들을 실행한다. 본 출원의 실시예들에서 제공되는 기술적 해결책들은 적어도 다음의 유익한 효과들을 포함할 수 있다. 먼저, 단 열 진화 경로의 검색 문제가 체스판 게임으로 컨버팅되고, 체스판 게임의 최적의 체스판 경로가 뉴럴 네트워크 와 결합한 몬테카를로 트리 검색을 통해 결정되고, 그리고 최적의 단열 진화 경로가 최적의 체스판 경로에 기반 하여 추론될 수 있다. 따라서, 단열 진화 경로에서 각각의 상태에 대해 너무 많은 후보 액션들이 존재하는 경우, 안정적이고 수렴적인(convergent) 단열 진화 경로가 신속하고 효율적으로 결정될 수 있고, 이로써, 단열 양자 컴퓨테이션 시스템의 단열 진화 효율이 향상되어, 타깃 기저 상태를 제공하기 위한 시간이 단축된다."}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 출원의 목적들, 기술적 해결책들 및 이점들을 더 명확하게 하기 위해, 본 출원의 실시예들이 하기에서 도면 들을 참조하여 상세히 설명된다. 먼저, 본 출원에 수반되는 몇몇 용어들이 소개된다. 1. 양자 컴퓨테이션은, 양자 로직(quantum logic)에 기반하여 컴퓨테이션을 수행하는 방식이며, 여기서 데이터 는 양자 비트(큐비트(qubit)) 단위로 저장된다. 2. 큐비트는, 양자 컴퓨테이션에 대한 단위를 지시한다. 종래의 컴퓨터는 이진 단위로서 0과 1을 사용한다. 차 이는 다음과 같다: 양자 컴퓨테이션에서, 0과 1이 동시에 컴퓨팅될 수 있고, 양자 시스템(줄여서, 시스템)은 0 과 1의 선형 중첩 상태(linear superposition state), 즉, 에 있을 수 있으며, 여기서 α 및 β는, 0 및 1에 관한 시스템의 확률 진폭(probability amplitude)들을 표현하며 복소수들이다. 모듈러 제곱 은, 0 및 1이 될 확률을 표현한다. 예를 들어, 이다. 3. 해밀토니언은, 양자 시스템의 총 에너지를 설명하는 에르미트 공액 행렬(Hermitian conjugate matrix)(H)이 다. 4. 고유상태(eigenstate): 해밀토니언 행렬(H)의 경우, 방정식 에 대한 해는 에너지 고유값 (energy eigenvalue)(E)을 갖는, H의 고유상태( )로 지칭된다. 5. 기저 상태는, 가장 낮은 에너지를 갖는 고유상태이다. 6. 분리가능 상태(separable state) 및 얽힌 상태(entangled state): 2개의 부분들(A 및 B)을 포함하는 양자 시스템의 경우, 양자 시스템의 양자 상태는 로 표현된다. 이 텐서 곱(tensor product), 즉 으로 분해될 수 있는 경우, 양자 상태는 분리가능 상태로 지칭되고, 그렇지 않은 경우, 양자 상태는 얽힌 상태로 지칭된다. 7. 단열 양자 컴퓨테이션은 양자 컴퓨터를 구현하기 위한 이론적 모델을 수반하며, 여기서 컴퓨테이션 문제는 물리적 프로세스를 실현함으로써 해결되며, 컴퓨테이션 문제에 대한 답은 타깃 해밀토니언의 기저 상태에 의해 반영된다. 단열 양자 컴퓨테이션의 컴퓨테이션 프로세스는, 기저 상태가 용이하게 제공되는 초기 해밀턴(H0)으 로부터 타깃 해밀턴(H1)으로 단열적으로 진화함으로써 구현된다. 전체 단열 진화 프로세스의 시간 길이(T)가 충 분히 길면(즉, 진화가 충분히 느리게 수행되면), 양자 컴퓨터에 의해 제공되는 양자 상태는 순간적인 해밀토니 언의 기저 상태를 유지할 것이다. 고전적인 단열 양자 컴퓨테이션 프로세스에서의 해밀토니언은, 초기 해밀토니 언과 타깃 해밀토니언이 시간에 따라 변하는 결합 형태로 표현될 수 있다:"}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 단열 진화의 함수(schedule)는 으로 정의된다. 8. 충실도(fidelity): 2개의 양자 순수 상태들( )의 경우, 충실도는 벡터들의 내적의 절대값 제곱 (modulus square)( )으로 정의된다. 9. 최적의 단열 경로: 고정된 T의 경우, 최적의 단열 경로는 다음의 최적화 문제에 대한 분해능으로 표현된다:"}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 은 H0의 기저 상태를 표현한다. 10. 양자 어닐링(quantum annealing): 단열 진화는 양자 컴퓨테이션의 이상적인 이론적 모델을 수반한다. 실제 로, 양자 하드웨어가 잡음들에 의해 영향을 받을 수 있거나 또는 단열 진화 시간 길이(T)가 충분히 길지 않기 때문에, 양자 컴퓨터에 의해 제공되는 양자 상태는 이론적 단열 진화에서와 같이 순간적인 해밀토니언의 기저 상태로 항상 유지될 수 없다. 이러한 컴퓨테이션 모드가 양자 어닐링으로 지칭된다. 11. 강화 학습(reinforcement learning)은 머신 학습의 분야이며, 여기서 AI 알고리즘은 환경과의 상호작용 프 로세스를 통해, 태스크 피드백을 어떻게 수행할지를 결정하고 그리고 태스크 피드백으로부터, 태스크를 어떻게 효율적으로 수행할지를 학습한다. 12. 결정 정책(π)은 강화 학습 프레임워크(reinforcement learning frame) 하에서의 특정 뉴럴 네트워크를 표 현한다. 시스템의 주어진 상태가 정책 네트워크의 입력으로서 기능한다면, 정책 네트워크는 실행될 액션을 출력 한다. 최적의 단열 진화 경로를 자동으로 결정하고, 양자 어닐링 및 단열 양자 컴퓨테이션을 용이하게 하고, 양자 컴 퓨테이션 문제를 효율적으로 해결하기 위해, \"뉴럴 네트워크와 결합한 몬테카를로 트리 검색(Monte Carlo tree search in combination with a neural network\" is provided in this application)\"을 사용하는 강화 학습 프 레임워크가 본 출원에서 제공된다. 본원에서 \"효율적으로\"는: 타깃 해밀토니언의 기저 상태에 대한 양자 상 태의 충실도를 향상시키는 것; 및 양자 컴퓨테이션에 대한 에너지를 감소시키는 것을 지칭한다. 도 1은 본 출원의 예시적인 실시예에 따른 컴퓨테이션 시스템의 아키텍처의 개략도이다. 컴퓨테이션 시스 템은 전자 컴퓨터 및 양자 컴퓨터를 포함한다. 뉴럴 네트워크와 결합한 몬테카를로 트리 검색(MCTS; Monte Carlo tree search)이 전자 컴퓨터 상에서 실행된다. 예를 들어, 뉴럴 네트워크와 결합한 몬테카를로 트리 검색의 강화 학습 프레임워크 는 본 출원에서 \"양자 제로(quantum zero)\"(줄여서, 양자 도그(quantum dog))로 지칭될 수 있다. 몬테카를로 트 리 검색은 뉴럴 네트워크의 가이드를 이용하여 최적의 단열 진화 경로(s(t))를 예측하도록 구성된다. 전자 컴퓨터는 양자 컴퓨터에 연결된다. 양자 컴퓨터는, 몬테카를로 트리 검색에 의해 출력된 예측된 단열 진화 경로(s(t))를 실행하고 그리 고 예측된 단열 진화 경로가 최종 상태로 진화할 때, 예측된 단열 진화 경로(s(t))의 에너지 고유값(E)을 출력 하고, 에너지 고유값(E)을 전자 컴퓨터에 제공하도록 구성된다. 에너지 고유값(E)이 타깃 기저 상태 에너지(E1) 이하인 것이 승리 조건이라고 가정하면, 에너지 고유값(E)이 승 리 조건을 충족하지 않는 경우, 전자 컴퓨터는 에너지 고유값(E)에 기반하여 뉴럴 네트워크의 파라미 터를 업데이트하는 데, 즉, 강화 학습을 수행한다. 전자 컴퓨터는 강화 학습 뉴럴 네트워크를 획득하고, 그리고 강화 학습 뉴럴 네트워크를 사용하여 최적의 단열 진화 경로(s(t))를 예측하도록 몬테카를로 트리 검색 을 다시 가이드하고; 에너지 고유값(E)이 승리 조건을 충족하는 경우, 전자 컴퓨터는 예측된 단열 진 화 경로(s(t))를 최적의 단열 진화 경로로서 출력한다. 도 2는 본 출원의 예시적 실시예에 따른, 단열 진화 경로를 예측하기 위한 방법의 흐름도이다. 이 실시예에서는, 방법이 도 1에 도시된 전자 컴퓨터에 적용되는 예를 취해 설명한다. 방법은 다음의 단계들 (201내지 205)을 포함한다. 단계에서, 양자 컴퓨테이션 문제의 타깃 해밀토니언(H1)이 획득된다. 양자 컴퓨테이션 문제의 경우, 컴퓨테이션 프로세스는, 기저 상태가 용이하게 제공되는 초기 해밀토니언(H0)으 로부터 타깃 해밀토니언(H1)으로 단열적으로 진화함으로써 구현된다. 전체 단열 진화 프로세스의 시간 길이(T) 가 충분히 길면(즉, 진화가 충분히 느리게 수행되면), 양자 컴퓨터에 의해 제공되는 양자 상태는 순간적인 해밀 토니언의 기저 상태를 유지할 것이다. 구체적으로, 양자 컴퓨테이션 문제는 다음의 문제들 중 적어도 하나를 포함한다: A. 시뮬레이팅될 화학 분자 시 스템; B. 분해될 기저 상태의 양자 다체 물리 모델(quantum many-body physics model); 및 C. 양자 물리 문제 로 컨버팅되는 결합 최적화 문제, 예컨대, 3AT, MaxCut, 또는 MaxQP와 같은 결합 최적화 문제. 단열 양자 컴퓨테이션을 위한 해밀토니언은, 초기 해밀토니언(H0) 및 타깃 해밀토니언(H1)이 시간에 따라 변하 는 결합 형태로 표현될 수 있다:"}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, H0는 초기 해밀토니언을 표현하고, H1은 타깃 해밀토니언(Hamiltonian)이다. s(t)는, 단열 진화(스케줄) 함수를 표현하며 으로 정의된다. T는 미리 설정된 단열 진화 시간 길이를 표현 하고, t는 시간을 표현한다. 단계에서, 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(E1)가 타깃 해밀토니언(H1)에 기반하여 결정된 다. 초기 해밀토니언(H0)은 쉽게 제공된다. 타깃 기저 상태 에너지(E1)는 원하는 에너지 임계치이다. 타깃 기저 상 태 에너지(E1)는, 초기 해밀토니언(H0)으로부터 단열적으로 진화된 최종 상태에서의 원하는 에너지의 양자 상태 (가장 낮은 에너지를 갖는 양자 상태로서 이해될 수 있음)를 지시한다. 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(E1)는 양자 컴퓨테이션 문제의 타깃 해밀토니언(H1)에 기반하여 설정될 수 있다. 예를 들어, 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(E1)는 수동으로(by hand) 설정된다. 대안적으로, 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(E1)는 프로그램에 따라 설정된다. 단계에서, 초기 해밀토니언(H0)으로부터 타깃 기저 상태 에너지(E1)로의 단열 진화 경로에 대한 검색이 체 스판 게임으로 컨버팅된다. 단열 진화 경로(줄여서, 단열 경로)는 초기 해밀토니언(H0)으로부터 타깃 기저 상태 에너지(E1)로의 진화 경로 이다. 단열 진화 경로의 검색 문제는 수학적 양상으로부터의 체스판 게임, 즉, 보드 게임 또는 체스판 게임으로 시뮬레이팅될 수 있다. 도 3에 도시된 바와 같이, 컨버전 프로세스는 적어도 다음의 단계들(203a 내지 203c)을 포함한다. 단계(203a)에서, 초기 해밀토니언(H0)으로부터 타깃 기저 상태 에너지(E1)로의 단열 진화 경로는 단열 진화 함 수(s(t))로 표현된다. 여기서, 단열 진화 함수는 로 정의된다. 단계(203b)에서, 단열 진화 함수(s(t))는 푸리에 변환(Fourier transform)을 통해 주파수 도메인에서 상태 벡터 시퀀스( )로 변환되고, 상태 벡터 시퀀스( )는 m개의 벡터 차원들을 포함하고, 각각의 벡터 차원은 2L의 범 위를 갖는다. 여기서, 단열 진화 함수(s(t))는 다음의 방정식 2에 따라 푸리에 변환을 통해 주파수 도메인에서 표현된다:"}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, t는 시간을 표현하고, T는 미리 설정된 단열 진화 시간 길이를 표현하고, bi는 상태 벡터를 표현하고, i는 M보다 크지 않은 정수를 표현한다. 따라서, 단열 진화를 통해 획득된 최종 상태( )의 에너지는 가능한 낮게 되도록 단열 진화 경로의 검색 문제는 상태 벡터 시퀀스(b1, b2,..., bM)를 검색하는 것으로 컨버팅된다. 즉, 최적의 상태 벡터 시퀀스( )가 발견될 필요가 있다. 각각의 bi는 특정 범위 내의 이산 값 ( )이 되도록 미리 설정되며, 여기서, Δ은 이산화 스텝 길이를 표현하고, -l 및 l은, 각각, bi에 대한 하한 및 상한을 표현한다. 단계(203c)에서, 체스판 게임은 벡터 차원들의 수(m) 및 각각의 벡터 차원의 범위(2L)에 기반하여 컨버전을 통 해 획득된다. 도 4에 예시적으로 도시된 바와 같이, 컨버전을 통해 획득된 체스판 게임에 대응하는 체스판은, 2L/Δ개의 행 (row)들 및 m개의 열(column)들을 포함하고, 각각의 열은 체스의 이동 포지션에 대응하고, Δ는 이산화 스텝 길 이를 지시한다. 즉, 말(piece)들은 체스판의 좌측으로부터 체스판의 우측으로의 순서로 배치되고, 각각의 열에 는 정확히 하나의 말(단 하나의 말)이 있고, 각각의 열에서는 말에 대한 2L/Δ개의 후보 이동 포지션들이 있다. M개의 말들이 배치되는 체스판 레이아웃은, 특정 상태 벡터 시퀀스( )에 대응한다. 상이한 실시예들에서, Δ는 대안적으로 다른 영어 변수로 표현될 수 있으며, 이는 본 출원에서 제한되지 않는다. 단계에서, 체스판 게임의 최적의 체스판 경로는 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 결 정된다. 체스판 게임의 게임 프로세스는 수학에서 게임 트리로 표현될 수 있다. 이 실시예에서, 게임 트리는 m개 계층의 노드들을 포함하고, 각각의 노드는 하위 계층에서의 2L/Δ개의 노드들에 대응하고, i번째 계층에서의 노드들은 체스판의 i번째 열의 이동 포지션들에 대응한다. 게임 트리에서, 최상위 계층에서의 노드는 근 노드(root nod) 이고, 최하위 계층에서의 노드는 잎 노드(leaf node)인 것으로 가정된다. 최적의 체스판 경로는 게임 트리 상에서의 근 노드로부터 잎 노드로의 경로이다. 몬테카를로 트리 검색은, 인공 지능 문제들에 대한 최적의 의사 결정(making optimal decision)들을 위한 방법 이며, 일반적으로, 조합 게임에서 이동 계획 형태이다. 몬테카를로 트리 검색은, 확률론적 시뮬레이션 (stochastic simulation)의 보편성과 트리 검색의 정확도를 결합하여 게임 트리에 적용하며, 예를 들어, 체스 문제에서의 알파 제로(AlphaZero)도 또한 컴퓨테이션 아키텍처를 채택한다. 예를 들어, 몬테카를로 트리 검색은 다음의 4개의 스테이지들을 포함한다: 1. 선택, 2. 확장, 3. 시뮬레이션, 및 4. 역전파. 4개의 스테이지들은 여 러 번 수행될 수 있다. 뉴럴 네트워크와 결합한 몬테카를로 트리 검색의 강화 학습 프레임워크는, 뉴럴 네트워크의 보조를 이용한 몬테 카를로 트리 검색의 머신 학습 프레임워크이다. 예컨대, 뉴럴 네트워크는, 몬테카를로 트리 검색에서 선택 스테 이지 및 시뮬레이션 스테이지를 보조한다. 뉴럴 네트워크는 콘볼루셔널 뉴럴 네트워크(convolutional neural network), 예컨대, 잔차(residual) 아키텍처를 채택하는 잔차 네트워크(ResNet)일 수 있다. 예에서, 뉴럴 네트워크는 정책 네트워크 및 가치 네트워크를 포함한다. 정책 네트워크는, 검색 동안 검색 공간 을 효과적으로 감소시키기 위해, 몬테카를로 트리 검색에서 노드 선택을 보조하도록 구성된다. 가치 네트워크는, 시뮬레이션 스테이지의 정확도 및 속도를 향상시키기 위해, 몬테카를로 트리 검색에서 시뮬레이션 스테이지를 보조하도록 구성된다. 체스판 게임의 최적의 체스판 경로는 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 신속하게 결정될 수 있다. 단계에서, 최적의 체스판 경로에 기반하여 단열 진화 경로가 획득된다. 체스판 게임에서의 최적의 체스판 경로는 최적의 상태 벡터 시퀀스( )에 대응한다. 최적의 단열 진화 경로(s(t))는 최적의 상태 벡터 시퀀스( )에 기반하여 획득될 수 있다. 위의 관점에서, 이 실시예의 방법에 따르면, 먼저, 단열 진화 경로의 검색 문제가 체스판 게임으로 컨버팅되고, 체스판 게임의 최적의 체스판 경로가 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 결정되고, 그리고 최적의 단열 진화 경로가 최적의 체스판 경로에 기반하여 추론될 수 있다. 따라서, 단열 진화 경로에서 각각의 상태에 대해 너무 많은 후보 액션들이 존재하는 경우, 안정적이고 수렴적인 단열 진화 경로가 신속하고 효율적 으로 결정될 수 있고, 이로써, 단열 양자 컴퓨테이션 시스템의 단열 진화 효율이 향상되어, 타깃 기저 상태를 제공하기 위한 시간이 단축된다. 강화 학습은 머신 학습의 한 분야이다. 요컨대, 강화 학습은, 최종 보상을 최대화하기 위해, 환경의 상태에 기 반하여 액션을 결정하는 방법을 학습하기 위해 수행된다. 본 출원에서, 뉴럴 네트워크와 결합한 몬테카를로 트 리 검색을 이용하여, 단열 진화 경로가 예측될 수 있다. 실제로, 단열 진화 경로는 양자 컴퓨터(즉, 환경)에 입 력되고, 양자 컴퓨터가 최종 상태로 진화할 때 양자 컴퓨터의 에너지 고유값(E)이 획득될 수 있고, 그리고 에너 지 고유값(E)은 뉴럴 네트워크에서 강화 학습을 수행하는 것에 대한 보상으로 사용된다. 다수의 시도들을 통해,"}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "몬테카를로 트리 검색은 마지막으로 체스판 게임에서의 최적의 체스 레이아웃을 요약하며, 이는 최적의 단열 진 화 경로가 발견되었음을 의미한다. 도 2에 기반한 실시예에서, 단계는 적어도, 도 5에 도시된 다음의 단계들(204a 내지 204f)을 포함할 수 있 다. 단계(204a)에서, 체스판 게임의 예측된 체스판 경로는 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 결 정된다. 뉴럴 네트워크의 파라미터(θ)가 알려진 경우, 체스판 게임의 예측된 체스판 경로(즉, 현재 예측 능력이 있는 최적의 체스판 경로)를 획득하기 위해, 체스판 게임에 대응하는 게임 트리가 뉴럴 네트워크와 결합한 몬테카를 로 트리 검색을 통해 검색된다. 단계(204b)에서, 예측된 단열 진화 경로는 예측된 체스판 경로에 기반하여 획득된다. 전자 컴퓨터는 상태 벡터 시퀀스( )로서 예측된 체스판 경로를 맵핑하고, 상태 벡터 시퀀스( )에 기반하여, 예측된 단열 진화 경로(s(t))를 획득한다.단계(204c)에서, 예측된 단열 진화 경로가 최종 상태로 진화할 때 예측된 단열 진화 경로의 에너지 고유값(E)은, 양자 컴퓨테이션 환경에 기반하여 계산된다. 전자 컴퓨터는 예측된 단열 진화 경로(s(t))를 양자 컴퓨터에 전송하고, 그리고 양자 컴퓨터는, 예측된 단열 진 화 경로(s(t))에 기반하여 최종 상태로 단열적으로 진화하며, 최종 상태로 진화할 때 양자 상태 및 대응하는 에 너지 고유값(E)을 측정한다. 대안적인 구현에서, 고정된 단열 진화 시간 길이(T)를 이용하여, 전자 컴퓨터는 예측된 단열 진화 경로(s(t))에 기반하여 양자 슈뢰딩거 방정식(quantum Schrodinger equation)을 풀고, 그리고 해의 결과에 기반하여, 최종 상 태로 진화할 때 양자 상태 및 대응하는 에너지 고유값(E)을 획득한다. 단계(204d)에서, 에너지 고유값(E)이 타깃 기저 상태 에너지(E1)보다 큰지 여부가 결정된다. 예에서, 승리 조건은, 에너지 고유값(E)과 타깃 기저 상태 에너지(E1) 간의 차이가 임계치 미만인 것이다. 임계 치가 0일 때, 승리 조건은, 에너지 고유값(E)이 타깃 기저 상태 에너지(E1) 이하인 것이다. 이 실시예에서, 에 너지 고유값(E)이 타깃 기저 상태 에너지(E1) 이하인 것이 승리 조건인 예가 설명을 위해 사용된다. 에너지 고유값(E)이 타깃 기저 상태 에너지(E1) 보다 큰 경우, 결정 결과는, 승리 조건이 충족되지 않았다는 것 을 지시하고, 단계(204e)가 수행된다. 에너지 고유값(E)이 타깃 기저 상태 에너지(E1) 이하인 경우, 결정 결과 는, 승리 조건이 충족된다는 것을 지시하고, 단계(204f)가 수행된다. 단계(204e)에서, 뉴럴 네트워크의 파라미터가 현재 예측 프로세스에 기반하여 업데이트되고, 단계(204a)는 업데 이트 후에 다시 수행된다. 에너지 고유값(E)이 타깃 기저 상태 에너지(E1)보다 큰 경우, 이는, 최적의 단열 진화 경로가 발견되지 않았다 는 것을 지시하며, 승리하지 않은 것에 대한 보상 값(z = -1)이 이러한 예측 프로세스에 기반하여 결정된다. 뉴 럴 네트워크의 파라미터(θ)는, 더 양호한 성과를 갖는 파라미터를 획득하기 위해, 보상 값(z = -1)(및 몬테카 를로 트리 검색에 의해 출력된 액션 정책 확률(π) 및 예측된 체스판 경로(b))에 기반하여 업데이트된다. 뉴럴 네트워크의 파라미터(θ)가 업데이트된 후에, 단계들(204a 내지 204d)이 다시 수행된다. 단계(204f)에서, 예측된 체스판 경로가 체스판 게임의 최적의 체스판 경로로서 결정된다. 에너지 고유값(E)이 타깃 기저 상태 에너지(E1) 이하인 경우, 이는 최적의 단열 진화 경로가 발견되었다는 것을 지시하며, 전자 컴퓨터는 몬테카를로 트리 검색에 의해 현재 출력된 예측된 체스판 경로를 체스판 게임의 최적 의 체스판 경로로 결정한다. 본 출원에서의 \"최적의 체스판 경로(optimal chessboard path)\"는, 이론적으로 최적인 체스판 경로보다는, 승리 조건이 충족되는 경우의 상대적으로 최적인 체스판 경로라는 것이 주목되어야 한다. 즉, 본 출원에서 \"최적\"은 가장 좁은 의미의 이론적 한계로서 이해되지 않아야 한다. 위의 관점에서, 이 실시예의 방법에 따르면, 최적의 예측된 체스판 경로가 현재 능력을 갖는 AI 알고리즘(몬테 카를로 트리 검색 + 뉴럴 네트워크)을 통해 예측된 후, 양자 컴퓨테이션 환경에 의해 피드백된 에너지 고유값 (E)이 보상으로서 사용되며, 그리고 에너지 고유값(E)이 승리 조건을 충족하지 않는 경우, 뉴럴 네트워크의 파 라미터는 더 양호한 뉴럴 네트워크를 획득하기 위해 보상에 기반하여 업데이트된다. 다수의 트레이닝 또는 업데 이트 프로세스들 후에, AI 알고리즘은 승리 조건을 충족시키는 최적의 체스판 경로를 출력할 수 있다. \"몬테카를로 트리 검색 + 뉴럴 네트워크\"를 이용한 동작 프로세스를 이해하는 것을 돕기 위해, 다음 나열된 순 서로 설명이 이루어진다: 1. 게임 트리; 2. 몬테카를로 시뮬레이션; 3. 기본적인 몬테카를로 트리 검색; 및 4. 뉴럴 네트워크와 결합한 몬테카를로 트리 검색. 1. 게임 트리 게임 트리는 트리 형태의 데이터 구조이고, 트리 상에서의 각각의 노드는 게임의 결정 상태를 표현한다. 하나의 노드로부터 그 노드의 자식 노드로의 컨버전이 액션으로 지칭된다. 노드의 자식 노드들의 수는 분기 팩터(branching factor)로 지칭된다. 게임 트리의 근 노드는 게임의 초기 상태를 표현한다. 게임 트리의 잎 노드는 자식 노드가 없는 노드이며, 이는 게임이 계속될 수 없음을 지시한다. 잎 노드의 상태가 평가될 수 있고, 이러 한 게임 라운드의 결과(승리 또는 패배)가 획득될 수 있다. 도 4를 참조하면, 본 출원의 체스판 게임에 대응하는 게임 트리는 (m+1)개 계층들의 노드들을 포함하고, 근 노 드는 0번째 계층에서의 노드이고, i번째 계층에서의 노드는 i번째 상태(bi)의 이동 포지션에 해당하고, 각각의 계층에서의 노드의 분기 팩터는 2L/Δ인데, 즉, 게임 트리의 계층들의 수는 체스판의 열들의 수(m+1)와 동일하 며, 각각의 계층에서의 노드의 분기들의 수는 체스판의 행들의 수와 동일하다. 도 6은, m = 5이고 2L/Δ2= 5인 게임 트리의 예를 개략적으로 도시한다. 초기 상태에서, 근 노드는 빈(empty) 체스판의 체스판 레이아웃에 대응 한다. 첫 번째 계층에서의 노드들에서 좌측으로부터 우측으로의 5개의 노드들은, 각각, 체스판의 첫번째 열에서 최상부로부터 최하부로의 5개의 후보 이동 포지션들에 대응한다. 두 번째 계층에서의 노드들은 b1 상태에서 5번 째 후보 이동 포지션에 이어 제공된다. 두 번째 계층에서의 노드들에서 좌측으로부터 우측으로의 5개의 노드들 은, 각각, 최상부로부터 최하부로 체스판의 두 번째 열에서 5개의 후보 이동 포지션들에 대응한다. 세 번째 계 층에서의 노드들은 b2 상태에서 두 번째 후보 이동 포지션에 이어 제공된다. 세 번째 계층에서의 노드들에서 좌 측으로부터 우측으로의 5개의 노드들은, 각각, 체스판의 세 번째 열에서 최상부로부터 최하부로의 5개의 후보 이동 포지션들에 대응한다. 네 번째 계층에서의 노드들은 b3 상태에서 다섯 번째 후보 이동 포지션에 이어 제공 된다. 네 번째 계층에서의 노드들에서 좌측으로부터 우측으로의 5개의 노드들은, 각각, 최상부로부터 최하부로 체스판의 네 번째 열에서 5개의 후보 이동 포지션들에 대응한다. 다섯 번째 계층에서의 노드들은 b4 상태에서 다섯 번째 후보 이동 포지션에 이어 제공된다. 다섯 번째 계층에서의 노드들에서 좌측으로부터 우측으로의 5개 의 노드들은, 각각, 체스판의 다섯 번째 열에서 최상부로부터 최하부로의 5개의 후보 이동 포지션들에 대응한다. 현재 게임은, b5 상태에서 세번째 후보 이동 포지션이 선택되는 경우 종료된다. 다섯 번째 계층에서의 근 노드로부터 세 번째 잎 노드로의 트리 순회(경로)는 게임 프로세스를 표현한다. 게임 프로세스가 완료된 후, 현재 게임이 승리 조건을 충족하는지 여부를 평가하기 위해, 다섯 번째 계층에서의 세 번째 노드가 평가될 수 있다. 2. 몬테카를로 시뮬레이션들 몬테카를로 시뮬레이션은 확률 통계 이론을 가이드로 사용하는 시뮬레이션 방법이다. 몬테카를로 시뮬레이션은 모나코의 카지노 도시를 기반으로 명명된다. 간단한 그래픽 문제를 취함으로써, 몬테카를로 시뮬레이션의 아이 디어가 설명된다. 지면 상의 불규칙한 패턴의 면적이 계산되는 것으로 가정하면, 볼이 지면 상의 불규칙한 패턴 을 포함하는 직사각형에 무작위로 낙하되고, 볼이 낙하될 때마다, 낙하 카운트(N)가 1씩 증가되고, 그리고 볼이 불규칙한 패턴으로 떨어지면, 승리 카운트(W)가 1씩 증가된다. 볼이 여러 번 낙하된 후, 불규칙한 패턴의 면적 은 W/N인 것으로 간주된다. 즉, 불규칙한 패턴의 면적 합산 방법을 알지 못하는 경우, 확률 통계에서의 확률을 이용하여 불규칙한 패턴의 면적이 예측된다. 몬테카를로 시뮬레이션 및 몬테카를로 트리 검색은 2개의 상이한 프로세스들이지만, 아이디어는 유사하다는 것 이 주목되어야 한다. 3. 기본적인 몬테카를로 트리 검색 다시 몬테카를로 트리 검색을 참조하면, 검색은 몬테카를로 트리 검색의 주요 개념, 즉 게임 트리를 따라 하향 순회 프로세스를 수행하는 것이다. 단일 순회 경로는, 현재 게임이 종료될 때까지, 근 노드(초기 게임 상태 또 는 현재 게임 상태)로부터 완전히 확장되지 않은 노드까지 연장된다. 몬테카를로 트리에서 각각의 노드는 체스 판 레이아웃을 표현하고, 노드에 대한 속성 \"W/N\"은, 노드가 N번 액세스되었고 W번 승리했다는 것을 표현한다. 예컨대, 초기 근 노드는 12/21이고, 이는 총 21번의 시뮬레이션들이 수행되었고, 12번의 승리들이 있다는 것을 의미한다. W는 총 시뮬레이션 보상들로서 간주될 수 있고, N은 액세스들의 총 횟수로서 간주될 수 있다. 도 7에 도시된 바와 같이, 기본적인 몬테카를로 트리 검색은 다음의 4개의 단계들 1) 내지 4)를 포함한다 1). 선택 근 노드로부터 하방으로 가면, \"확장되지 않은 자식 노드들을 갖는” 노드(bi)에 도달할 때까지, \"가장 볼 가치 가 있는 자식 노드\"가 선택된다. \"확장되지 않은 자식 노드들을 갖는다\"는 설명은, 실제로, 체스판 레이아웃에 서 순회되지 않는 이동들이 있다는 것을 의미한다. \"가장 볼 가치가 있는 자식 노드\"를 선택하는 방법이 아래에서 설명된다. 2). 확장 \"0/0\"의 속성을 갖는(계층(bi+1)에 위치된) 자식 노드가, 전술한 단계에서 \"확장되지 않은 자식 노드\"에 대응하 는 노드(bi)에 추가되는 데, 즉, 시도되지 않았던 이동이 제공된다. 3). 시뮬레이션 전술한 단계에서 새롭게 추가된 자식 노드로부터 시작하여, 무작위 이동 정책을 사용하여 마지막 단계로의 이동 이 이루어져, 결과가 획득된다. 일반적인 의견에 따르면, 무작위 이동 정책은 체스 능력은 약하지만 빠른 이동 을 갖는 정책이다. 4). 역전파 새롭게 추가된 자식 노드의 모든 부모 노드들에 시뮬레이션 결과(승리 또는 패배)가 추가(즉, 모든 부모 노드들 에 대해 N+1)되고, 그리고 시뮬레이션 결과가 승리를 지시하면 모든 부모 노드들에 대해 W+1이 추가된다. 시뮬레이션이 여러 번 수행된 후, 각각의 계층에서 가장 큰 시뮬레이션 보상(또는 가장 큰 액세스 횟수)을 갖는 노드들에 의해 형성된 경로가 최적의 체스판 경로로서 결정된다. 4. 뉴럴 네트워크와 결합한 몬테카를로 트리 검색 도 6 및 도 7에 따르면, 게임 트리의 깊이(계층들의 수) 및 폭(각각의 계층에서의 노드들의 수)이 작으면, 모든 분기들을 철저하게 열거함으로써 게임 트리를 기반으로 정확한 최적의 체스판 경로가 획득될 수 있다. 그러나 게임 트리의 깊이 및 폭이 크면, 전술한 컴퓨테이션 동안의 검색 공간이 매우 커서, 컴퓨테이션이 어렵게 된다. 본 출원의 이러한 실시예에서 뉴럴 네트워크를 사용함으로써, 게임 트리의 검색 공간의 깊이 및 폭이 감소된다. 주로 다음의 2개의 양상들이 포함된다. 현재 노드(bi)에 대해, 그 다음 이동 프로세스에서 몇몇 가장 가능성이 높은 후보 이동 포지션들(ai+1), 및 각각의 후보 이동 포지션(ai+1)의 이동 확률(p(ai+1, bi))을 예측할 수 있는 정책 네트워크(P)가 제공된다. 이러한 방식으로, 현재 노드(bi)에 대해, 몬테카를로 트리 검색은, 그 다음 계층에서의 모든 자식 노드들을 검색 하지 않고, 그 다음 계층에서의 몇몇 가장 가능성이 높은 자식 노드들만을 검색할 필요가 있고, 이로써, 게임 트리의 검색 공간의 폭이 감소된다. 그러나 뉴럴 네트워크가 예측할 수 없는 이동을 만들기 위해, 선택 동안, 몬테카를로 트리 검색은 정책 네트워 크(P)에 의해 예측된 이동 확률(p)(정책 벡터(p)로 또한 지칭됨)에 의존함으로써 예측을 수행할 뿐만 아니라, 후보 이동 포지션에 대한 이력 액세스들의 횟수를 참조하여 포괄적인 선택을 수행한다. 즉, 몬테카를로 트리 검 색은, 그 다음 계층에서의 자식 노드들에서 \"높은 이동 확률 + 적은 횟수의 이력 액세스들\"을 갖는 자식 노드를 타깃 자식 노드로서 우선적으로 선택한다. 2) 후보 이동 포지션(ai+1)에 대응하는 자식 노드(bi+1)의 게임 결과가 승리를 지시할 확률(v)을 예측할 수 있는 가치 네트워크(V)가 제공된다. 이 경우, 확장되지 않은 자식 노드(bi+1)의 경우, 랜덤 이동 정책에 기반한 마지막 스텝으로의 이동들은 시뮬레 이팅될 필요가 없고, 게임 결과(v)는 가치 네트워크(V)에 의해 직접 예측되며, 이로써 게임 트리의 검색 공간의 깊이가 감소된다. 뉴럴 네트워크에서 정책 네트워크(P) 및 가치 네트워크(V)의 가이드에 의해, 몬테카를로 트리 검색은 게임 트리 의 최적의 체스판 경로를 신속하게 발견할 수 있다. 도 8에 도시된 예에서, 뉴럴 네트워크는 특징 추출 네트워크, 정책 네트워크(P), 및 가치 네트워크(V)를 포함한 다. 예측 프로세스에서, 현재 체스판 레이아웃(b)(처음 i개의 노드들(bi))이 특징 추출을 위해 특징 추출 네트 워크에 입력되고, 추출된 특징들은 예측을 위해 정책 네트워크(P) 및 가치 네트워크(V)에 제공된다. 정책 네트 워크(P)는 그 다음 말의 이동 확률(줄여서 정책 벡터(p)) 및 후보 이동 포지션을 예측하도록 구성되고, 가치 네 트워크(V)는 그 다음 말에 대응하는 전체 체스판 레이아웃의 가치 이익(v)(승리 가능성)을 예측하도록구성된다. 몬테카를로 트리 검색은, 정책 네트워크(P) 및 가치 네트워크(V)의 가이드를 이용하여, 감소된 검색 공간 내에서 현재 예측 능력을 갖는 최적의 체스판 경로를 신속하게 발견하고, 이 경로를 예측된 체스판 경로로 서 출력한다. 구체적으로, 예측된 체스판 경로는 각각의 상태에서 가장 높은 액션 확률 분포(π)를 갖는 액션을 통해 획득된다. 양자 컴퓨테이션 환경(예컨대, 실제 단열 양자 컴퓨터)은, 최종 상태로 진화할 때 에너지 고유값(E)을 획득하기 위해, 예측된 체스판 경로에 기반하여 단열적으로 진화한다. 에너지 고유값(E)이 승리 조건을 충족하지 않는 경 우, 보상 값(z = -1)은 예측된 체스판 경로에 대응하고, 뉴럴 네트워크의 파라미터(θ)는 (b, π, z)를 사용하 여 업데이트되고, b는 이러한 예측의 예측된 체스판 경로를 지시하고, π는 몬테카를로 트리 검색에 의해 출력 된 액션 확률 분포를 지시하고, z는 승리하지 못한 것에 대한 보상 값을 지시한다. 트레이닝 타깃은, 정책 벡터 (p)와 액션 확률 분포(π) 간의 유사성을 최대화하고 그리고 승리하지 못한 것에 대한 보상 값(z)과 가치 이익 (V) 간의 에러를 최소화하는 것이다. 도 9는 본 출원의 예시적인 실시예에 따른, 단열 진화 경로의 진화 방법의 흐름도이다. 이 실시예에서, 방법이 전자 컴퓨터 또는 컴퓨터 장치에 적용 가능한 예가 설명을 위해 사용된다. 방법은 다음의 단계들(204a-1내지 204f)을 포함한다. 단계(204a-1)에서, 체스판 게임에 대응하는 게임 트리는 각각의 계층에서의 노드의 액션 확률 분포(π)를 출력 하기 위해 몬테카를로 트리 검색을 통해 검색되고, 각각의 계층에서의 노드의 액션 확률 분포(π)는 그 다음 말 의 확률 분포 및 후보 이동 포지션을 표현한다. 본 출원에서, 체스판 게임에 대응하는 게임 트리는 M+1개 계층들의 노드들을 갖는다. 근 노드(또는 특정 계층에 서의 노드들의 타깃 노드)로부터 시작하여, 몬테카를로 트리 검색을 통해 검색이 수행된다. 예컨대, 이 단계는 다음의 서브-단계들(S1 내지 S5)을 포함한다. 단계(S1)에서, (i+1)번째 계층에서의 노드(bi+1)의 후보 이동 포지션(ai+1) 및 이동 확률(pi+1)이, 체스판 게임의 i번째 계층에서의 타깃 노드(bi)에 이어, 정책 네트워크에 의해 출력된다. i번째 계층에서의 타깃 노드(bi)는 i번째 계층에서의 노드의 타깃 이동 포지션에 대응하며, i는 (m-1)보다 크지 않은 정수이다. 타깃 이동 포지션은 현재 예측되는 최적의 이동 포지션이다. 일반적으로, 그 다음 계층에서 다수의 후보 이동 포지션들(ai+1)이 있고 그리고 각각의 후보 이동 포지션(ai+1)이 개개의 이동 확률(pi+1)을 갖기 때문에, 다수의 후보 이동 포지션들(ai+1) 및 이동 확률들(pi+1)은 정책 벡터(p) (또는 이동 확률 분포)로 총칭될 수 있다. 단계(S2)에서, (i+1)번째 계층에서의 노드(bi+1)가 후보 이동 포지션(ai+1)에 기반하여 확장되고, 그리고 (i+1)번 째 계층에서의 노드(bi+1)가 가치 네트워크에 의해 평가되어 각각의 후보 이동 포지션(ai+1)의 가치 이익(vi+1)이 획득된다. (i+1)번째 층에서의 확장된 노드(bi+1)에 대해 실제 시뮬레이션이 수행될 필요가 없다. (i+1)번째 계층에서의 노 드(bi+1)의 가치 이익(vi+1)은 가치 네트워크에 의해 직접적으로 예측된다. 각각의 후보 이동 포지션(ai+1)의 가치 이익(vi+1)은 후보 이동 포지션에서의 승리 확률, 즉, 후보 이동 포지션에서의 게임 결과를 표현한다. 구체적으로, 가치 이익(vi+1)은 1 또는 -1을 사용하여 표현되고, 1은 승리를 표현하고, -1은 손실을 표현한다. 즉, -1은, 에너지 고유값(E)이 타깃 기저 상태 에너지(E1)보다 크다는 예측 결과를 표현하고, 1은, 에너지 고유 값(E)이 타깃 기저 상태 에너지(E1) 이하인 예측 결과를 표현한다. 단계(S3)에서, (i+1)번째 계층에서의 노드(bi+1)에서 타깃 노드는 이동 확률(pi+1) 및 가치 이익(vi+1)에 기반한 신뢰도 상한(confidence upper limit)(U)을 참조로 결정된다. 예컨대, 몬테카를로 트리의 선택 스테이지 동안, (i+1)번째 계층에서의 타깃 노드는 다음의 공식 3에 따라 \"활 용-탐험 트레이드-오프(exploitation-explorationtrade-off)\"의 아이디어에 기반하여 선택된다: 여기서 bi+1은 i번째 계층에서의 노드에 대한 선택이 수행된 후 현재 체스판 상태를 표현하고, a는 수행될 그 다 음 액션(즉, (i+1)번째 이동)을 표현하며, Q는 현재 체스판 상태(bi+1)에서 (i+1)번째 계층에서 검색된 노드들의 가치 이익들(vi+1)의 평균 누적 값을 표현하며, p는 (i+1)번째 계층에서의 노드에서 각각의 후보 이동 포지션의 이동 확률(pi+1)의 확률 분포를 표현하고, N(bi+1, a)은 (i+1)번째 계층에서의 노드들에서 잎 노드의 현재 이력 검색 횟수를 표현하며, 은 (i+1)번째 계층에서의 모든 노드들에 대한 이력 검색의 총 횟수를 표현 하고, c는 검색된 노드들과 검색되지 않은 노드들의 밸런싱을 위해 사용되는 파라미터를 표현한다. 공식 3의 더하기 중 좌측 절반부(Q)는 이동 확률(pi+1) 및 가치 이익(vi+1)과 관련되고, 우측 절반부는 신뢰도 상 한(U)이고, 신뢰도 상한(U)은 이력 검색 횟수와 관련된다. 단계(S4)에서, (i+1)번째 계층에서의 노드가 m번째 계층에서의 노드가 아닌 경우, (i+1)번째 계층에서의 타깃 노드를 i번째 계층의 새로운 타깃 노드로서 사용하여, 전술한 3개의 단계들이 다시 수행된다. 단계(S5)에서, (i+1)번째 계층에서의 노드가 m번째 계층에서의 노드인 경우, 각각의 계층에서의 노드의 액션 확 률 분포(π)가 출력된다. 단계(204a-2)에서, 체스판 게임의 예측된 체스판 경로는 각각의 계층에서의 노드의 가장 높은 액션 확률 분포 (π)를 갖는 타깃 이동 포지션에 기반하여 획득된다. 단계(204b)에서, 예측된 단열 진화 경로는 예측된 체스판 경로에 기반하여 획득된다. 단계(204c)에서, 양자 컴퓨테이션 환경에 기반하여, 최종 상태로 진화할 때 예측된 단열 진화 경로의 에너지 고 유값(E)이 획득된다. 단계(204d)에서, 에너지 고유값(E)이 타깃 기저 상태 에너지(E1)보다 큰지 여부가 결정된다. 예에서, 승리 조건은, 에너지 고유값(E)과 타깃 기저 상태 에너지(E1) 간의 차이가 임계치 미만인 것이다. 임계 치가 0일 때, 승리 조건은, 에너지 고유값(E)이 타깃 기저 상태 에너지(E1) 이하인 것이다. 이 실시예에서, 에 너지 고유값(E)이 타깃 기저 상태 에너지(E1) 이하인 것이 승리 조건인 예가 설명을 위해 사용된다. 에너지 고유값(E)이 타깃 기저 상태 에너지(E1)보다 큰 경우, 결정 결과는 승리 조건이 충족되지 않았다는 것이 며, 단계(204e-1)가 수행된다. 에너지 고유값(E)이 타깃 기저 상태 에너지(E1) 이하인 경우, 결정 결과는 승리 조건이 충족된다는 것이며, 단계(204f)가 수행된다. 단계(204e-1)에서, 에너지 고유값(E)이 승리 조건을 충족하지 않는 경우, 예측된 체스판 경로가 뉴럴 네트워크 의 입력으로 기능하여, 정책 네트워크에 의해 출력되는 정책 벡터(p)와 가치 네트워크에 의해 출력되는 가치 이 익(v)이 획득된다. 단계(204e-2)에서, 정책 벡터(p)와 액션 확률 분포(π) 간의 유사성을 최대화하고 그리고 승리하지 못한 것에 대한 보상 값(z)과 가치 이익(v) 간의 에러를 최소화하는 것을 목표로함으로써, 뉴럴 네트워크의 파라미터가 업 데이트된다. 예컨대, 뉴럴 네트워크의 파라미터는 다음의 손실 함수에 따라 조정된다:"}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, z는 승리하지 않은 것에 대해 보상 값에서 1을 차감함으로써 획득된 것을 표현하고, v는 가치 네트워크 에 의해 예측된 가치 이익을 표현하고, π는 몬테카를로 트리 검색에 의해 출력된 액션 정책 확률을 표현하고, p는 정책 네트워크에 의해 예측된 정책 벡터를 표현하고, c'는 파라미터(L2)의 정규화 항목을 제어하기 위한 계 수를 표현하고, θ는 뉴럴 네트워크의 파라미터를 표현한다. 도 11에 도시된 바와 같이, 트리 검색 스테이지에서, 각각의 계층에서의 노드들(b1, b2, 및 b3)에 대해, 뉴럴 네트워크(fθ)는 대응하는 정책 벡터들(p) 및 평가 값들(v)을 출력하고, 정책 벡터(p) 및 평가 값(v)이 몬테카를로 트리 검색을 가이드하는 데 사용된다. 트레이닝 스테이지에서, 각각의 계층에서의 노드들(b1, b2, 및 b3)에 대해, 몬테카를로 트리 검색에 의해 출력된 액션 확률 분포들(π1, π2, 및 π3) 및 승리하지 못한 것에 대한 보상 값(z)은 뉴럴 네트워크(fθ)를 트레이닝시키기 위한 샘플 데이터로서 사용된다. 단계(204f)에서, 에너지 고유값(E)이 승리 조건을 충족하는 경우, 예측된 체스판 경로는 체스판 게임의 최적의 체스판 경로로서 결정된다. 위의 관점에서, 이 실시예의 방법에 따르면, 뉴럴 네트워크의 가이드를 통해, 몬테카를로 트리 검색은 좁아진 검색 공간 내에서 최적의 예측된 체스판 경로를 신속하게 발견할 수 있고, 이로써 검색 효율이 향상된다. 애플리케이션 시나리오들 1. 캐나다 D-웨이브 시스템이 단열 양자 컴퓨테이션에 기반하여 구현되며, 그러한 컴퓨테이션 시스템의 진화 효 율이 향상될 수 있고, 타깃 기저 상태를 제공하기 위한 시간이 본 출원의 알고리즘을 통해 단축될 수 있다. 매 우 불안정한 양자 시스템의 경우, 짧은 제공 시간은, 본 출원이 전체 진화 프로세스를 보호하고, 양자 이점들을 유지하며 그리고 단열 양자 컴퓨터들의 개발을 가속화할 수 있다는 것을 의미한다. 2. 범용 양자 컴퓨테이션을 위한 회로 설계가 가속화된다. 양자 컴퓨터들의 개발에 대한 주요 장애물은 전체 시 스템의 짧은 코히어런스 시간이며, 이는 하드웨어의 양상들로부터, 과학 인력에 대한 운용과 설계의 어려움을 증가시킨다. 과학자들은 단열 양자 컴퓨테이션 및 회로 양자 컴퓨테이션의 등가성을 입증했으며, 양자 근사화 알고리즘(QAOA; quantum approximate optimization algorithm)은 단열 경로를 양자 회로로 컨버팅하는 것을 용 이하게 할 수 있다. 본 출원에서의 알고리즘은 단열 양자의 효율을 향상시키며, 이는 통상적 의미에서 양자 컴 퓨테이션을 달성하기 위해 본 출원에서 더 짧은 회로가 발견될 수 있는 것과 동등하다. 3. 패스워드 크래킹(Password cracking). 단열 양자 컴퓨테이션은 현재의 메인스트림 암호화 기술들을 크래킹하 는 데 사용될 수 있으며, 본 출원에서의 알고리즘은 또한, 패스워드 크래킹의 효율을 크게 향상하기 위해, 원래 의 가장 간단한 선형 단열 경로에 기반하여 전체 프로세스를 가속시킬 수 있다. 강화 학습 알고리즘들은 최근 몇 년 동안 태스크 경로의 설계에 널리 적용되었다. 특히, 알파 제로(AlphaZero) 알고리즘은 바둑(Go game)과 같은 게임들에서 주요한 돌파구를 이루었다. 최적의 단열 경로(s(t))를 설계하고, 양자 어닐링 및 단열 양자 컴퓨테이션을 용이하게 하고, 컴퓨테이션 문제를 보다 효과적으로 해결하기 위해, \" 결합 뉴럴 네트워크에서 몬테카를로 트리 검색\"을 기반으로 하는 강화 학습 프레임워크가 조정되고 향상될 수 있다는 것을 알 수 있다. 본 출원에서, 단열 진화의 스케줄 함수(s(t))는 상이한 주파수들의 사인 함수들의 중첩으로 확장된다. 즉, s (t)는 푸리에 변환을 통해 주파수 도메인에서 표현된다:"}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 은, 최종 상태( )로 진화할 때의 에너지가 가능한 한 낮도록 구해져야 한다. 본 출원에서, 최적의 단열 진화 경로를 설계하는 문제는 최적의 상태 벡터 시퀀스( )를 검색하는 문제로 컨버 팅된다. 본 출원에서, 이러한 순열 및 결합 문제는, 정확히 동등한 \"싱글-플레이어 게임\"으로 컨버팅되고, 알파 제로의 Go 알고리즘은 최적의 \"싱글-플레이어 게임\" 정책을 검색하도록 수정된다. AI 알고리즘이 진화 경로를 설계할 때마다, 단열 양자 컴퓨터/양자 어닐링 머신(예를 들어, 강화 학습 프레임워크의 환경으로 기능)이 채택 되어, 진화 경로를 한 번 실행하여 이 진화 경로의 효과, 예를 들어, 타깃 해밀토니언의 기저 상태(최저-에너지 양자 상태)가 성공적으로 제공될 수 있는지 여부를 검증한다. 본 출원에서, 양자 하드웨어에 의해 제공되는 에 너지 측정은 AI 알고리즘에 의해 설계된 경로의 품질을 평가하는 데 사용될 수 있다. 본 출원에서, 맞춤화된 기 준들에 기반하여 설계 AI가 이 라운드에서 승리하는지 여부가 결정될 수 있다. 양자 컴퓨터와의 연속적인 상호 작용(AI가 단열 양자 컴퓨테이션의 진화를 가이드하고 그로부터 실시간 에너지 측정 피드백을 획득함)을 통해, 강화 학습에 기반한 AI 알고리즘은, 유효성이 만족스러운 레벨을 충족할 때까지 자신의 게임 정책을 조정한다. 본 출원은 최적의 상태 벡터( )를 검색하는 것을 목표로 한다. 각각의 bi의 값은 특정 범위, 즉 내의 이산 값으로 미리 설정된다. 따라서, 도 4에 도시된 바와 같이, 최적의 파라미터들( )의 그룹의 선택은, 의 크기를 갖는 체스판 상의 이동 포지션의 선택으로 컨버팅되었다. 싱글-플레이어 게임의 규칙은, 각각의 열이 오직 하나의 말(단지 하나의 말)을 가질 필요가 있다는 것이다. 말 들이 배치된 체스판은 특정 상태 벡터( )에 대응하며, 공식을 통해 단열 진화 경로가 획득된다. 공식에 따라, 본 출원의 양자 단열 컴퓨터에서 설계가 수행되고, 이 설계가 게임에서 승리하는지 여부를 결정하기 위해, 컴퓨테이션이 완료되는 경우, 양자 시스템에 대해 에너지 측정이 수행된다. 반복되는 게임 시도들을 통해, AI 알고리즘은 결국 체스판 상의 말들에 대한 최상의 이동 포지션들을 결론짓고, 이는 알고리즘이 최적의 단열 경로를 찾을 수 있다는 것을 의미한다. 본 출원에서, 맨 처음부터 학습하고, 양자 단열 진화 경로의 설계 에 적용되고, 네트워크와 결합한 MCTS의 게임 아키텍처에 기반하는 이 방법은 \"양자 제로(Quantum Zero)\"로 지 칭된다. 도 12를 참조하면, 본 출원에서 제공되는 단열 진화 경로를 예측하기 위한 방법은, 3개의 부분들: 양자 컴퓨테 이션 환경, 체스판 공간, 및 양자 제로 프로세싱을 포함한다. 양자 컴퓨테이션 환경의 경우: 단계에서, 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(E1)가 타깃 해밀토니언(H1)에 기반하여 설정된 다. 단계에서, 양자 슈뢰딩거 방정식이 고정된 단열 진화 시간 길이(T) 내의 예측된 단열 진화 경로(s(t))에 기반하여 풀리거나, 또는 양자 단열 컴퓨터가 진화를 수행하고 최종 상태 시스템을 측정하여, 최종 상태로 진화 할 때 양자 상태 및 대응하는 에너지 고유값(E)이 획득된다. 체스판 공간의 경우: 단계에서, 최적의 단열 진화 경로를 검색하는 문제를 최적의 파라미터 시퀀스(b)를 검색하는 것으로 컨버 팅하기 위해, 푸리에 변환을 통해 주파수 도메인에서 단열 진화 경로(s(t))가 파라미터 시퀀스(b)로 변환된다. 단계에서, 최적의 파라미터 시퀀스(b)에 대한 검색이 이산화되고, 체스판 공간에 맵핑되고, 최적의 체스 판 레이아웃은 양자 제로 싱글-플레이어 게임을 통해 발견된다. 양자 제로 프로세싱의 경우: 단계에서, 정책 네트워크 및 가치 네트워크는 특정 체스판 상태에서 정책 벡터(p) 및 평가 값(v)을 생성 하고, 몬테카를로 트리 검색의 피드백(b, π, z)에 기반하여 네트워크 파라미터를 업데이트한다. 정책 네트워크 및 가치 네트워크는 특정 체스판 상태에서 정책 벡터(p) 및 평가 값(v)을 생성하고, 정책 벡터 (p) 및 평가 값(v)을 사용하여 몬테카를로 트리 검색을 가이드한다. 승리 조건이 충족되지 않는 경우, 몬테카를 로 트리 검색은 뉴럴 네트워크(정책 네트워크 및 가치 네트워크)의 네트워크 파라미터를 업데이트하기 위한 트 레이닝 샘플로서 피드백(b, π, z)을 사용한다. 단계에서, 몬테카를로 트리 검색은, 정책 네트워크 및 가치 네트워크의 가이드를 이용하여, 개발 및 탐험 의 원리에 따라 새로운 액션 확률 분포(π)를 생성하고, 체스판 상태에서 단열 진화 결과를 기반으로 승리 또는 패배를 결정하여 새로운 보상 값(z)을 생성한다. 본 출원에서 개발된 새로운 AI 알고리즘은, 단열 양자 컴퓨테이션의 효율(결과를 획득하는 더 짧은 동작 시간) 및 정확도(타깃 해밀토니언의 기저 상태를 획득할 더 높은 확률) 둘 다를 향상시킬 수 있으며, 이는 본 출원에 서 다음의 두 가지 경우로 증명될 수 있다. 첫번째 경우에서는, 양자 컴퓨테이션의 고전적인 문제, 즉, 그로버 검색(Grover search)이 고려된다. n개의 비 트들이 있다고 가정하면, 2n개의 객체들을 인코딩하는 데 n개의 비트들이 사용될 수 있다. 고전적인 알고리즘에 대한 최악의 경우에서, 이는 2n번 시도할 필요가 있다. 그러나, 양자 컴퓨터는 이차적인 가속을 구현할 수 있는 데, 즉, 본 출원에서 필요한 컴퓨테이션 횟수는 단지 2n/2회이다. 다음의 2가지 정해진 해밀토니언들(H0 및 H1) 에 대한 최적의 단열 경로를 설계하기 위해 단열 그로버 검색이 수행된다."}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, 이고, I는 단위 행렬(identity matrix)을 표현하고, 은 타깃 이진 문자열 (target binary character string)을 표현하다. 몬테카를로 트리 검색과 강화 학습의 양자 제로를 사용하여 설계된 단열 경로를 사용하여 시간 길이(T) 내에 타 깃 기저 상태에 도달할 확률을 종래의 단열 경로(선형 검색)와 비교함으로써, 양자 제로가 최적의 단열 양자 진 화 경로를 설계하는 데 중요한 역할을 할 수 있음을 알 수 있다. 두번째 경우에서, 컴퓨터 과학에서 종종 논의되는 3-SAT 문제가 널리 적용되는 것을 고려하면, 순열 최적화 및 결합 문제는 단열 양자 컴퓨테이션을 통해 다룰 수 있는 문제로 컨버팅되고, 본 출원에서는, 타깃 해밀토니언 (H1) 및 초기 해밀토니언(H0)이 요구된다."}
{"patent_id": "10-2021-7028001", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "타깃 해밀토니언(H1)은 Nc개의 논리 문장들을 포함하고, 각각의 문장(α)의 제한 조건은 3개의 이진 디지트들 에 의해 결정된다. 이 문제에 대한 해결책은 Nc개의 논리 문장들 모두를 충족시킬 수 있는 n-비트 값을 구하는 것이다. 본 출원에서, 단열 진화에 난제를 적용할 수 있는 3-SAT 문제들이 선택되며, 여기서 타깃 해밀토니언은 오직 하나의 기저 상태 및 다수의 제1 여기 상태들을 갖는다. 단열 진화의 프로세스에서, 시스템 은 단열 진화의 효율을 너무 낮게 만드는 국소 최적 해결책의 상태에 갇힐 가능성이 있다. 몬테카를로 트리 검 색과 강화 학습을 사용하는 양자 제로에 의해 설계된 단열 경로를 사용하여 시간 길이(T) 내에 타깃 기저 상태 에 도달하는 승리 확률을 종래의 단열 경로(선형 검색)와 비교하면, 양자 제로가 최적의 단열 양자 진화 경로를 설계하는 데 중요한 역할을 할 수 있음을 알 수 있다. 도 13은 진화 시간 길이(T = 45) 내에서 양자 제로에 의해 설계된 4-큐비트 그로버 검색의 단열 양자 진화 경로 의 결과를 도시한다. 도 13의 좌측 도면에서, 하단부에 위치된 물결선은 양자 제로 게임의 라운드들의 수에 따 라 변하는 정책 네트워크(P)에 의해 출력되는 엔트로피를 도시하고, 상단부에 위치된 물결선은 양자 제로 게임 의 라운드들의 수에 따라 달라지는 정책 네트워크(P)와 가치 네트워크(V)에 의해 출력되는 손실 함수를 도시한 다. 도 13의 우측 도면은 양자 제로에 의해 설계된 진화 경로에서 평가된 최종 상태의 에너지를 도시한다. 양자 제로가 트레이닝을 점진적으로 완료하고, 특정 진화 시간 내에 최적의 경로가 발견되어, 타깃 해밀토니언 기저 상태가 획득되는 것을 알 수 있다. 도 13에 도시된 그로버 검색의 경우들이 계속해서 설명된다. 본 출원에서, 양자 제로에 의해 설계된 단열 진화 경로는 아래에서 보다 심오하게 논의되며, 가장 일반적인 선형 경로와 비교된다. 도 14에서 (a) 부분은, 진화 시간 길이(T = 45) 내에서 4-큐비트 그로버 검색을 위해 양자 제로에 의해 설계된 단열 진화 경로(s(t))를 도시 한다. 도 14에서 (b) 부분에서의 점선은, 양자 제로에 의해 설계된 경로에 기반하여, 단열 진화 시간 길이(t ~(0, T)) 내에서 진화함으로써 타깃 해밀토니언 기저 상태가 성공적으로 제공될 확률을 도시하고, 그리고 실선 은 단열 진화 시간 길이(t ~(0, T)) 내에서 선형 경로에 기반하여 진화함으로써 타깃 해밀토니언 기저 상태가 성공적으로 제공될 확률을 도시한다. 도 14에서 (c) 부분은, 진화 시간 길이(T = 60) 내에서 6-큐비트 그로버 검색을 위해 양자 제로에 의해 설계된 단열 진화 경로(s(t))를 도시한다. 도 14에서 (d) 부분에서의 점선은, 양 자 제로에 의해 설계된 경로에 기반하여, 단열 진화 시간 길이(t ~(0, T)) 내에서 진화함으로써 타깃 해밀토니 언 기저 상태가 성공적으로 제공될 확률을 도시하고, 그리고 실선은 단열 진화 시간 길이(t ~(0, T)) 내에서 선 형 경로에 기반하여 진화함으로써 타깃 해밀토니언 기저 상태가 성공적으로 제공될 확률을 도시한다. 명백하게, 양자 제로에 의해 설계된 경로에 의해, 높은 성공률이 보장될 수 있다. 그러나, 비트들의 수의 증가로, 요구되 는 시간 범위(T) 내에서 종래의 선형 경로를 기반으로 타깃 해밀토니언 기저 상태가 제공될 수 없다. 도 15는 상이한 진화 시간 길이들에 대한 6-큐비트 그로버 검색을 통해 타깃 해밀토니언 기저 상태가 성공적으 로 제공될 확률들을 도시한다. 도트는 양자 제로에 의해 설계된 진화 경로에 기반하여 타깃 해밀토니언 기저 상 태가 성공적으로 제공될 확률을 표현한다. 교차점(cross point)은 선형 진화 경로에 기반하여 타깃 해밀토니언 기저 상태가 성공적으로 제공될 확률을 표현한다. 명백하게, 양자 제로에 의해 설계된 진화 경로에 의해, 타깃 해밀토니언 기저 상태를 성공적으로 제공할 확률이 양자 단열 진화를 통해 크게 향상된다.앞서 언급된 경우 2에 대해, 3-SAT 문제에서 단열 진화 경로의 설계에 양자 제로가 적용됨에 따라, 단열 진화에 난제를 적용하는 3-SAT 문제들이 본 출원에서 전개된다: 타깃 해밀토니언은 단지 하나의 기저 상태 및 다수의 제1 여기 상태들을 갖는다. 단열 진화의 프로세스에서, 시스템은 국소 최적 해결책의 상태에 갇힐 가능성이 있 고, 이는 단열 진화의 효율을 너무 낮게 만든다. 본 출원에서, 전술한 조건을 충족시키는 7개의 큐비트들 및 21 개의 조항들을 포함하는 3-SAT 문제, 및 전술한 조건들을 충족하는 11개의 큐비트들 및 33개의 조항들을 포함하 는 3-SAT 문제가 예들로서 취해지고, 이는, 양자 제로의 점진적인 트레이닝과 함께, 지정된 진화 시간 길이 내 에서 최적의 경로를 안정적으로 찾을 수 있음을 지시한다. 종래의 단열 경로(선형 검색)와 비교하여, 양자 제로 에 의해 설계된 단열 경로를 사용함으로써 시간 길이(T) 내에서 타깃 기저 상태에 도달하는 성공률은 명백하게 더 높다. 도 16에서 (a) 부분은, 진화 시간 길이(T = 85) 내에서 7-큐비트 3-SAT 문제에 의해 양자 제로에 의해 설계된 단열 진화 경로(s(t))를 도시한다. 도 16에서 (b) 부분에서의 점선은, 양자 제로에 의해 설계된 경로에 기반하 여, 단열 진화 시간 길이(t ~(0, T)) 내에서 진화함으로써 타깃 해밀토니언 기저 상태가 성공적으로 제공될 확 률을 도시하고, 그리고 실선은 단열 진화 시간 길이(t ~(0, T)) 내에서 선형 경로에 기반하여 진화함으로써 타 깃 해밀토니언 기저 상태가 성공적으로 제공될 확률을 도시한다. 명백하게, 양자 제로에 의해 설계된 경로는 더 양호한 효과들을 갖는다. 도 17에서 도면 (a) 및 도면 (b)는, 각각, 상이한 진화 시간에 대해 7-큐비트 3-SAT 문제 및 11-큐비트 3-SAT 문제가 고려될 때, 타깃 해밀토니언 기저 상태가 성공적으로 제공될 확률들을 도시한다. 도트는 양자 제로에 의 해 설계된 진화 경로에 기반하여 타깃 해밀토니언 기저 상태가 성공적으로 제공될 확률을 도시하고, 교차점은 선형 진화 경로에 기반하여 타깃 해밀토니언 기저 상태가 성공적으로 제공될 확률을 도시한다. 명백하게, 양자 제로에 의해 설계된 진화 경로는 양자 단열 진화를 통해 타깃 해밀토니언 기저 상태를 성공적으로 제공할 확률 을 크게 향상시킨다. 도 18은 본 출원의 예시적 실시예에 따른, 단열 진화 경로를 예측하기 위한 장치의 블록도이다. 장치는 전자 컴 퓨터의 전부 또는 일부로서 구현될 수 있거나, 전자 컴퓨터에 적용될 수 있다. 장치는 획득 모듈, 결정 모듈, 컨버전 모듈, 트리 검색 모듈 및 출력 모듈을 포함한다. 획득 모듈은, 양자 컴퓨테이션 문제의 타깃 해밀토니언(H1)을 획득하도록 구성된다. 결정 모듈은, 타깃 해밀토니언(H 1)에 기반하여 초기 해밀토니언(H0) 및 타깃 기저 상태 에너지(E1)를 결정하도록 구성된다. 컨버전 모듈 은, 초기 해밀토니언(H0)으로부터 타깃 기저 상태 에너지(E1)로의 단열 진화 경로에 대한 검색을 체스판 게임으 로 컨버팅하도록 구성된다. 트리 검색 모듈은, 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 체 스판 게임의 최적의 체스판 경로를 결정하도록 구성된다. 출력 모듈은, 최적의 체스판 경로에 기반하여 단열 진화 경로를 획득하도록 구성된다. 실시예에서, 트리 검색 모듈은 추가로, 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 체스판 게 임의 예측된 체스판 경로를 결정하고; 예측된 체스판 경로에 기반하여 예측된 단열 진화 경로를 획득하고; 예측 된 단열 진화 경로가 최종 상태로 진화할 때, 양자 컴퓨테이션 환경에 기반하여, 예측된 단열 진화 경로의 에너 지 고유값(E)을 계산하고; 에너지 고유값(E)이 승리 조건을 충족하지 않는 경우, 현재 예측 프로세스에 기반하 여 뉴럴 네트워크의 파라미터를 업데이트하고 그리고 업데이트 후에 다시, 뉴럴 네트워크와 결합한 몬테카를로 트리 검색을 통해 체스판 게임의 예측된 체스판 경로를 결정하고; 그리고 에너지 고유값(E)이 승리 조건을 충족 하는 경우, 예측된 체스판 경로를 체스판 게임의 최적의 체스판 경로로서 결정하도록 구성된다. 승리 조건은, 에너지 고유값(E)과 타깃 기저 상태 에너지(E1) 간의 차이가 임계치 미만임을 지시한다. 실시예에서, 뉴럴 네트워크는 정책 네트워크 및 가치 네트워크를 포함한다. 트리 검색 모듈은 추가로, 각 각의 계층에서의 노드의 액션 확률 분포(π)를 출력하기 위해, 몬테카를로 트리 검색을 통해 체스판 게임에 대 응하는 게임 트리를 검색하고 ―각각의 계층에서의 노드의 액션 확률 분포(π)는 그 다음 말의 확률 분포 및 후 보 이동 포지션을 표현함―; 그리고 가장 높은 액션 확률 분포(π)를 갖는 각각의 계층에서의 노드의 타깃 이동 포지션에 기반하여 체스판 게임의 예측된 체스판 경로를 획득하도록 구성된다. 트리 검색 모듈은 추가로, 에너지 고유값(E)이 승리 조건을 충족하지 않는 경우, 예측된 체스판 경로를 뉴럴 네트워크의 입력으로서 취하 여, 정책 네트워크에 의해 출력된 정책 벡터(p) 및 가치 네트워크에 의해 출력된 가치 이익(v)을 획득하고; 그 리고 정책 벡터(p)와 액션 확률 분포(π) 간의 유사성을 최대화하고 그리고 승리하지 못한 것에 대한 보상 값 (z)과 가치 이익(v) 간의 에러를 최소화하는 것을 목표로함으로써, 뉴럴 네트워크의 파라미터를 업데이트하도록 구성된다.실시예에서, 트리 검색 모듈은, 정책 네트워크에 의해, 체스판 게임의 i번째 계층에서의 타깃 노드(bi)에 이은 (i+1)번째 계층에서의 노드(bi+1)의 후보 이동 포지션(ai+1) 및 이동 확률(pi+1)을 출력하고 ―i번째 계층에 서의 타깃 노드(bi)는 i번째 계층에서의 노드의 타깃 이동 포지션에 대응하며, i는 (m-1)보다 크지 않은 정수임 ―; 각각의 후보 이동 포지션(ai+1)의 가치 이익(vi+1)을 획득하기 위해, 후보 이동 포지션(ai+1)에 기반하여 (i+1)번째 계층에서의 노드(bi+1)를 확장하고 가치 네트워크에 의해 (i+1)번째 계층에서의 노드(bi+1)를 평가하고; 이동 확률(pi+1) 및 가치 이익(vi+1)에 기반하여 신뢰도 상한(U)을 참조로 (i+1)번째 계층에서의 노드 (bi+1)에서 타깃 노드를 결정하고; (i+1)번째 계층에서의 노드가 m번째 계층에서의 노드가 아닌 경우, (i+1)번째 계층에서의 타깃 노드를 i번째 계층의새로운 타깃 노드로서 취함으로써 전술한 3개의 단계들을 수행하고; 그리 고 (i+1)번째 계층에서의 노드가 m번째 계층에서의 노드인 경우, 각각의 계층에서의 노드의 액션 확률 분포 (π)를 출력하도록 구성된다. 실시예에서, 신뢰도 상한은 후보 이동 포지션의 이력 검색들의 횟수와 관련된다. 실시예에서, 컨버전 모듈은 추가로, 초기 해밀토니언(H0)로부터 타깃 기저 상태 에너지(E1)로의 단열 진 화 경로를 단열 진화 함수(s(t))로 표현하고; 푸리에 변환을 통해 주파수 도메인에서 단열 진화 함수(s(t))를 상태 벡터 시퀀스(b)로 변환하고 ―상태 벡터 시퀀스(b)는 m개의 벡터 차원들을 포함하고, 벡터 차원들 각각은 2L의 범위를 가짐 ―; 그리고 벡터 차원들의 수(m) 및 벡터 차원들 각각의 값 범위(2L)에 기반하여 컨버전을 통 해 체스판 게임을 획득하도록 구성되며, 체스판 게임에 대응하는 체스판은 2L/Δ개의 행들 및 m개의 열들을 포 함하고, 각각의 열은 말의 이동 포지션에 대응하고, Δ는 이산화 스텝 길이를 표현한다. 전술한 실시예들에서 제공된 장치가 장치의 기능들을 구현할 때, 전술한 기능 모듈들의 분할은 단지 설명을 위 한 예일뿐이라는 것이 주목되어야한다. 실제 적용에서, 기능들은 요건들에 따라 상이한 기능 모듈들에 할당되고 그에 의해 완료될 수 있는데, 즉, 디바이스의 내부 구조는 위에서 설명된 기능들 전부 또는 일부를 구현하기 위 해 상이한 기능 모듈들로 분할된다. 부가하여, 전술한 실시예들에 제공된 장치 및 방법 실시예들은 동일한 개념 에 속한다. 특정 구현 프로세스에 대해, 방법 실시예들에 대한 참조가 이루어질 수 있으며, 세부 사항들은 본원 에서 다시 설명되지 않는다. 도 19는 본 출원의 실시예에 따른 컴퓨터 디바이스의 구조적 블록도이다. 컴퓨터 디바이스는, 모바 일 폰, 태블릿 컴퓨터, 웨어러블 디바이스, 멀티미디어 재생 디바이스, 카메라 및 다른 전자 디바이스일 수 있 다. 양자 컴퓨터와는 달리, 컴퓨터 디바이스는 또한 전자 컴퓨터로 지칭된다. 일반적으로, 컴퓨터 디바이스는 프로세서 및 메모리를 포함한다. 프로세서는 하나 이상의 프로세싱 코어들을 포함할 수 있다. 예를 들어, 프로세서는 4-코어 프로세서 또 는 19-코어 프로세서일 수 있다. 프로세서는 DSP(digital signal processor), FPGA(field programmable gate array), 및 PLA(programmable logic array) 중 적어도 하나의 하드웨어 형태를 사용함으로써 구현될 수 있다. 프로세서는 대안적으로, 메인 프로세서 및 코프로세서를 포함할 수 있다. 메인 프로세서는 활성 상 태의 데이터를 프로세싱하도록 구성되며, 또한 CPU(central processing unit)으로 지칭된다. 코프로세서는 대기 상태에서 데이터를 프로세싱하도록 구성된 저-전력 프로세서이다. 일부 실시예들에서, 프로세서는 GPU(graphics processing unit)와 통합될 수 있다. GPU는 디스플레이 스크린 상에 디스플레이될 필요가 있는 콘 텐츠를 렌더링 및 드로잉(draw)하도록 구성된다. 일부 실시예들에서, 프로세서는 인공 지능(AI; Artificial Intelligence) 프로세서를 더 포함할 수 있다. AI 프로세서는 머신 학습과 관련된 컴퓨테이션 동작 들을 프로세싱하도록 구성된다. 메모리는 하나 이상의 컴퓨터-판독가능 저장 매체를 포함할 수 있다. 컴퓨터-판독가능 저장 매체는 비-일 시적일 수 있다. 메모리는 고속 랜덤 액세스 메모리 및 비휘발성 메모리, 예컨대, 하나 이상의 디스크 저 장 디바이스들 또는 플래시 저장 디바이스들을 더 포함할 수 있다. 일부 실시예들에서, 메모리 내의 비- 일시적 컴퓨터-판독가능 저장 매체는 적어도 하나의 명령, 적어도 하나의 프로그램, 코드 세트 또는 명령 세트 를 저장하도록 구성된다. 적어도 하나의 명령, 적어도 하나의 프로그램, 코드 세트 또는 명령 세트는 본 출원의 방법 실시예들에서 제공되는 단열 진화 경로를 예측하기 위한 방법을 구현하도록 프로세서에 의해 실행되 도록 구성된다. 일부 실시예들에서, 컴퓨터 디바이스는 주변 인터페이스 및 적어도 하나의 주변 디바이스를 더 포 함할 수 있다. 프로세서, 메모리 및 주변 인터페이스는 버스 또는 신호 케이블에 의해 연결 될 수 있다. 각각의 주변 디바이스는 버스, 신호 케이블, 또는 회로 보드를 사용함으로써 주변 인터페이스 에 연결될 수 있다. 구체적으로, 주변 디바이스는 무선 주파수 회로, 터치 디스플레이 스크린 , 카메라 컴포넌트, 오디오 회로, 포지셔닝 컴포넌트 및 전력 공급부 중 적어도 하나를 포함할 수 있다. 카메라 컴포넌트는 컬러 카메라 및 깊이 카메라에 의해 형성된 3차원 카메라일 수 있다. 당업자는, 도 19에 도시된 구조가 컴퓨터 디바이스에 대한 어떠한 제한도 구성하지 않으며, 컴퓨터 디바 이스가 도 19에 도시된 것들보다 더 많은 컴포넌트들 또는 더 적은 컴포넌트들을 포함할 수 있거나 또는 일부 컴포넌트들이 결합되거나 또는 상이한 컴포넌트 배치가 사용될 수 있다는 것을 이해할 것이다. 예시적인 실시예에서, 적어도 하나의 명령, 적어도 하나의 프로그램, 코드 세트 또는 명령 세트를 저장하는 컴 퓨터-판독가능 저장 매체가 추가로 제공된다. 적어도 하나의 명령, 적어도 하나의 프로그램, 코드 세트 또는 명 령 세트는 단열 진화 경로를 예측하기 위한 전술한 방법을 구현하기 위해 컴퓨터 디바이스의 프로세서에 의해 실행된다. 예시적인 실시예에서, 컴퓨터 프로그램을 저장하는 컴퓨터-판독가능 저장 매체가 추가로 제공되며, 컴퓨터 프로 그램은 단열 진화 경로를 예측하기 위한 전술한 방법을 구현하기 위해 컴퓨터 디바이스의 프로세서에 의해 실행 된다. 구체적으로, 컴퓨터-판독가능 저장 매체는 ROM, RAM, SSD(solid state drive), 광학 디스크 등을 포함할 수 있 다. 랜덤 액세스 메모리는 ReRAM(resistance random access memory) 및 DRAM(dynamic random access memory)를 포함할 수 있다. 예시적인 실시예에서, 컴퓨터 프로그램 제품이 추가로 제공되며, 컴퓨터 프로그램 제품은, 컴퓨터 디바이스의 프로세서에 의해 실행될 때, 단열 진화 경로를 예측하기 위한 전술한 방법을 구현하도록 구성된다. 예시적인 실시예에서, 컴퓨터 프로그램 제품이 추가로 제공되며, 컴퓨터 프로그램 제품은, 단말의 프로세서에 의해 실행될 때, 단열 진화 경로를 예측하기 위한 전술한 방법을 구현하도록 구성된다. 본 명세서에서 언급된 \"다수\"는 2개 이상을 의미하는 것으로 이해되어야 한다. \"및/또는\"은 연관된 객체들에 대 한 연관 관계를 설명하고, 3개의 관계들이 존재할 수 있다는 것을 표현한다. 예컨대, A 및/또는 B는, A만이 존 재하고, A와 B 둘 모두가 존재하고, 그리고 B만이 존재하는 3개의 경우들을 표현할 수 있다. 문자 \"/\"는 일반적 으로 연관된 객체들 간의 \"또는” 관계를 지시한다. 부가하여, 본 명세서에서 설명된 단계 번호들은 단지 예시 적으로 단계들의 가능한 실행 순서를 나타낸다. 일부 다른 실시예들에서, 단계들은 번호 순서로 수행되지 않을 수 있다. 예컨대, 상이한 번호들을 갖는 2개의 단계들이 동시에 수행될 수 있거나, 또는 상이한 번호들을 갖는 2개의 단계들이 도면에 도시된 순서와 상반되는 순서로 수행될 수 있다. 이는 본 출원의 실시예들에서 제한되지 않는다. 전술한 설명들은 단지 본 출원의 예시적인 실시예들일 뿐이며, 본 출원을 제한하려는 것은 아니다. 본 출원의 사상 및 원리 내에서 이루어진 임의의 수정, 등가물 교체 또는 개선은 본 출원의 보호 범위 내에 속할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19"}
{"patent_id": "10-2021-7028001", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 출원의 실시예들에서의 기술적 해결책들을 보다 명확하게 설명하기 위해, 실시예들을 설명하기 위해 요구되 는 도면들이 하기에서 간략하게 소개된다. 분명히, 하기 설명에서 도면들은 본 출원의 일부 실시예들만을 도시 하며, 당업자는 창의적인 노력들 없이도 이러한 도면들로부터 다른 도면들을 계속 도출할 수 있다. 본 출원의 실시예들에서의 기술적 해결책들을 보다 명확하게 설명하기 위해, 실시예들을 설명하기 위해 요구되 는 도면들이 하기에서 간략하게 소개된다. 분명히, 하기 설명에서 도면들은 본 출원의 일부 실시예들만을 도시 하며, 당업자는 창의적인 노력들 없이도 이러한 도면들로부터 다른 도면들을 계속 도출할 수 있다. 도 1은 본 출원의 실시예에 따른 컴퓨테이션 시스템의 구조적 블록도이다. 도 2는 본 출원의 실시예에 따른, 단열 진화 경로를 예측하기 위한 방법의 흐름도이다. 도 3은 본 출원의 실시예에 따른, 단열 진화 경로를 체스판 게임으로 컨버팅하기 위한 프로세스의 흐름도이다. 도 4는 본 출원의 실시예에 따른, 체스판 게임의 체스판의 개략도이다. 도 5는 본 출원의 다른 실시예에 따른, 단열 진화 경로를 예측하기 위한 방법의 흐름도이다. 도 6은 본 출원의 실시예에 따른, 체스판 게임에 대응하는 게임 트리의 개략도이다. 도 7은 본 출원의 실시예에 따른, 몬테카를로 트리 검색의 4개의 스테이지들의 개략도이다. 도 8은 본 출원의 실시예에 따른, 뉴럴 네트워크 및 몬테카를로 트리 검색의 원리들의 개략도이다. 도 9는 본 출원의 실시예에 따른 단열 진화 경로를 예측하기 위한 방법의 흐름도이다. 도 10은 본 출원의 실시예에 따른, 몬테카를로 트리 검색의 검색 프로세스의 흐름도이다. 도 11은 본 출원의 실시예에 따른, 뉴럴 네트워크를 트레이닝시키는 원리들의 개략도이다. 도 12는 본 출원의 실시예에 따른 단열 진화 경로를 예측하기 위한 방법의 흐름도이다. 도 13 내지 도 17은, 각각, 본 출원에서 예측된 단열 진화 경로와 종래의 단열 진화 경로의 효과들의 비교를 도 시하는 도면들이다. 도 18은 본 출원의 실시예에 따른, 단열 진화 경로를 예측하기 위한 장치의 블록도이다. 도 19는 본 출원의 실시예에 따른 컴퓨터 디바이스의 개략적인 구조도이다."}
