{"patent_id": "10-2023-0069212", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0171394", "출원번호": "10-2023-0069212", "발명의 명칭": "컨볼루션 순환신경망을 이용한 잡음 제거 방법 및 시스템", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2023-0069212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 신호 획득 단계;상기 음성 신호에 딥러닝 모델을 적용하여 잡음 제거 마스크를 획득하는 단계;상기 음성 신호를 상기 마스크와 연산하여 잡음이 제거된 최종 음성 신호를 획득하는 단계;를 포함하며,상기 마스크 획득 단계는,상기 음성 신호에서 잡음의 전력값을 추정하는 단계;상기 음성 신호에서 중간 특징 벡터를 추출하는 단계;복수의 은둔 레이어를 이용하여 상기 전력값의 절대값을 복수의 벡터로 변환하는 단계;상기 복수의 벡터를 이용하여 상기 중간 특징 벡터를 컨디셔닝하는 단계를 포함하는,음성 신호 잡음 제거 방법."}
{"patent_id": "10-2023-0069212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 마스크 획득 단계는,제1 은둔 레이어를 이용하여 상기 전력값의 절대값을 스케일링 벡터(γ)로 변환하는 스케일링 벡터(γ)추출 단계;제2 은둔 레이어를 이용하여 상기 전력값의 절대값을 시프트 벡터(β)로 변환하는 시프트 벡터(β)추출 단계;복소수 인코더에 상기 음성 신호를 입력하여 중간 특징 벡터를 추출하는 단계;상기 중간 특징 벡터를 상기 스케일링 벡터 및 상기 시프트 벡터를 이용하여 컨디셔닝하는 단계;상기 컨디셔닝된 데이터를 LSTM(Long short-term memory)에 입력하여 잡음 제거 벡터를 생성 단계;상기 생성된 잡음 제거 벡터를 복소수 디코더에 입력하여 음성 신호와 연산가능한 잡음 제거 마스크 출력단계;를 더 포함하는음성 신호 잡음 제거 방법."}
{"patent_id": "10-2023-0069212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 전력값 추정 단계는,상기 음성 신호의 주파수 대역별로 전력값의 최솟값을 추적하여 이의 절대값을 상기 대역의 잡음의 전력값으로추정하는 단계;를 포함하는,음성 신호 잡음 제거 방법."}
{"patent_id": "10-2023-0069212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2024-0171394-3-제2 항에 있어서,상기 컨디셔닝 단계는,다음의 수학식에 따른 값을 출력하는 단계;를 포함하는,음성 신호 잡음 제거 방법.γ(스케일링 벡터데이터), β(시프트 벡터데이터), F(중간 특징 벡터)"}
{"patent_id": "10-2023-0069212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 항에 있어서,상기 스케일링 벡터 및 시프트 벡터 추출 단계는,1차원 컨벌루션 레이어(one-dimensional convolution layer)를 이용하여 상기 절대값을 상기 중간 특징 벡터와동일한 차원의 벡터로 추출하는 단계;를 포함하고,상기 딥러닝 모델은,입력 데이터의 복소수 연산을 모델링한 심층 복소수 컨벌루션 순환신경망(Deep Complex Convolution RecurrentNetwork, DCCRN)인,음성 신호 잡음 제거 방법."}
{"patent_id": "10-2023-0069212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2 항에 있어서,상기 음성 신호 획득 단계는,시간 영역의 상기 음성 신호를 STFT(Short-Time Fourier Transform)를 통해 주파수 영역의 신호로 변환하는 단계;를 포함하는,음성 신호 잡음 제거 방법."}
{"patent_id": "10-2023-0069212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "음성 신호를 수집하는 신호수집부;상기 음성 신호에 포함된 잡음의 전력값을 추정하는 잡음추정부;상기 음성 신호에 포함된 잡음을 제거하기 위한 마스크를 생성하는 잡음 제거 모델;잡음이 제거된 최종 음성 정보를 출력하는 음성출력부;를 포함하며,상기 잡음 제거 모델은,상기 잡음추정부에서 추정된 잡음의 전력값을 이용하여 입력 데이터로부터 추출된 중간 특징 벡터를 컨디셔닝하고, 상기 컨디셔닝된 데이터를 LSTM(Long short-term memory)에 입력하여 잡음 제거 마스크 생성하며,음성 신호의 복소수 연산을 모델링한 심층 복소수 컨벌루션 순환신경망(Deep Complex Convolution RecurrentNetwork, DCCRN)을 이용하는,음성 신호 잡음 제거 시스템.공개특허 10-2024-0171394-4-청구항 8 제7 항에 있어서,상기 잡음추정부는,MS(Minimum Statistics) 알고리즘을 이용하여 상기 음성 신호에 포함된 잡음의 전력값을 추정하고, 상기 잡음 제거 모델은,제1 은둔 레이어를 이용하여 상기 잡음추정부의 결과값을 스케일링 벡터(γ)로 변환하고, 제2 은둔 레이어를 이용하여 상기 잡음추정부의 결과값을 시프트 벡터(β)로 변환하고, 상기 입력 데이터로부터 추출된 중간 특징 벡터를 상기 스케일링 벡터 및 상시 시프트 벡터를 이용하여 컨디셔닝하는,음성 신호 잡음 제거 시스템."}
{"patent_id": "10-2023-0069212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 잡음 제거 모델은,복소수 인코더에 상기 음성 신호를 입력 데이터로 하여 중간 특징 벡터를 추출하고, 상기 중간 특징 벡터를 상기 스케일링 벡터 및 상기 시프트 벡터를 이용하여 컨디셔닝하고, 상기 컨디셔닝된 데이터를 하나 이상의LSTM(Long short-term memory) 레이어에 제공하여 잡음 제거 벡터를 생성한 후, 이를 복소수 디코더에 입력하여음성 신호와 연산가능한 잡음 제거 마스크 출력하는,음성 신호 잡음 제거 시스템."}
{"patent_id": "10-2023-0069212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7 항에 있어서,상기 신호수집부는,시간 영역의 상기 음성 신호를 STFT(Short-Time Fourier Transform)를 통해 주파수 영역의 신호로 변환하고,상기 잡음추정부는,상기 음성 신호의 주파수 대역별로 전력값의 최솟값을 추적하여 이의 절대값을 상기 대역의 잡음 수준으로 추정하는,음성 신호 잡음 제거 시스템."}
{"patent_id": "10-2023-0069212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8 항에 있어서,상기 잡음 제거 모델은,다음의 수학식에 따라 상기 중간 특징 벡터를 컨디셔닝하는,음성 신호 잡음 제거 시스템.γ(스케일링 벡터데이터), β(시프트 벡터데이터), F(중간 특징 벡터)공개특허 10-2024-0171394-5-"}
{"patent_id": "10-2023-0069212", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 음성 신호 잡음 제거 방법은 음성 신호 획득 단계, 획득된 음성 신호를 입력 데이터 로 하고 딥러닝 모델을 이용하여 잡음 제거 마스크를 획득하는 단계, 획득된 음성 신호를 마스크와 연산하여 잡 음이 제거된 최종 음성 신호를 획득하는 단계를 포함하며, 마스크 획득 단계는, 획득된 음성 신호에서 잡음의 전 (뒷면에 계속)"}
{"patent_id": "10-2023-0069212", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컨볼루션 순환신경망을 이용한 잡음 제거 방법에 관한 것으로서, 더욱 상세하게는 잡음 제거 효율이 향상된 컨볼루션 순환신경망을 이용한 잡음 제거 방법에 관한 것이다."}
{"patent_id": "10-2023-0069212", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공신경망(Artificial Neural Network, ANN)은 심층신경망(Deep Neural Network, DNN) 개발 이후 컨벌루션 신 경망(Convolutional Neural Network, CNN), 순환신경망(Recurrent Neural Network, RNN) 등으로 많은 발전이 있었다. 인공지능 기술의 발전에 따라 음성 처리 분야에도 인공지능 기술이 많이 적용되고 있다. 예를 들면, 머신러닝 기법인 심층신경망(Deep Neural Network, DNN)이 다양한 음성 향상 및 음성 인식 연구에서 우수한 성능을 보이 고 있다. 심층신경망은 다수의 은닉 층과 은닉 노드들을 통하여 입력 특징 벡터와 출력 특징 벡터 사이의 비선 형적인 관계를 효과적으로 모델링하여 우수한 성능을 보인다. 한국등록특허 10-0762596호는 음성 신호 전처리 시스템 및 음성 신호 특징 정보 추출 방법에 관한 것으로, 신경 망 인식 방법을 이용하여 음성 신호를 전처리하는 기술을 기재하고 있다. 한국등록특허 10-1934636호는 음성 신호의 통계적 정보인 잡음 정보 및 에코 정보를 심층신경망(DNN)의 추가적 입력으로 사용하여, 음성 신호에서 잡음 및 에코를 통합 제거하는 기술을 기재하고 있다. 잡음을 포함하는 입력 신호에서 잡음을 제거하여 목적음을 추출하는 분야에도 CNN과 RNN이 결합된 컨벌루션 순 환신경망(Convolutional Recurrent Network, CRN)이 적용되고 있다. 또한, 복소수 입력 시 CRN 알고리즘을 구 현할 수 있는 심층 복소수 컨벌루션 순환신경망(Deep Complex Convolution Recurrent Network, DCCRN)이 좋은 성능을 보이고 있다."}
{"patent_id": "10-2023-0069212", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "심층 복소수 컨벌루션 순환신경망(Deep Complex Convolution Recurrent Network, DCCRN)을 이용한 잡음 제거 방법 및 시스템은 상기 설명한 문제점을 해결하기 위해 고안된 발명으로서, 딥러닝 모델에 고전 신호 처리 방법 을 적용함으로써 소음 제거의 단계별 분석이 가능하고, 파라미터 수가 많지 않아 경량화된 잡음 제거 방법 및 시스템을 제공한다."}
{"patent_id": "10-2023-0069212", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 음성 신호 잡음 제거 방법은 음성 신호 획득 단계, 획득된 음성 신호를 입력 데이 터로 하고 딥러닝 모델을 이용하여 잡음 제거 마스크를 획득하는 단계, 획득된 음성 신호를 마스크와 연산하여 잡음이 제거된 최종 음성 신호를 획득하는 단계를 포함하며, 마스크 획득 단계는, 획득된 음성 신호에서 잡음의 전력값 추정 단계, 제1 은둔 레이어를 이용하여 전력값의 절대값을 스케일링 벡터(γ)로 변환하는 스케일링 벡 터(γ)추출 단계, 제2 은둔 레이어를 이용하여 전력값의 절대값을 시프트 벡터(β)로 변환하는 시프트 벡터 (β)추출 단계, 입력 데이터로부터 추출된 중간 특징 벡터를 스케일링 벡터 및 시프트 벡터를 이용하여 컨디셔 닝하는 단계를 포함하고, 딥러닝 모델은 입력 데이터의 복소수 연산을 모델링한 심층 복소수 컨벌루션 순환신경 망(Deep Complex Convolution Recurrent Network, DCCRN)을 이용한다."}
{"patent_id": "10-2023-0069212", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 잡음 제거 방법은 다양한 상황에서 우수한 잡음 제거 성능을 가지며, 고전 신호 처 리 방법과 딥러닝 모델을 적절히 결합하여 잡음을 제거함으로써 연산량이 적으면서도 우수한 잡음 제거 효율을 보이는 잡음 처리 방법 및 시스템을 제공할 수 있다. 또한, 딥러닝을 이용하여 음성 신호를 처리하면서도 고전적인 신호처리 방법인 MS 알고리즘을 이용하여 획득한 잡음의 추정 전력값을 이용하여 특징 벡터를 컨디셔닝함으로써, 학습되지 않은 상황에서도 잡음 제거 성능이 우 수하며, 연산량이 작은 개선된 잡음 제거 방법 및 시스템을 제공하고자 한다."}
{"patent_id": "10-2023-0069212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 명세서의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 음성 향상 기술은 마이크로폰으로 입력된 잡음 신호를 제거하여 깨끗한 음성을 추정하는 기술로, 음성 인식과 음성 통신과 같은 음성 어플리케이션에 필수적인 기술이다. 예를 들어 음성 인식에서 잡음 및 에코가 존재하지 않은 깨끗한 신호로 음성 인식 모델을 학습시킨 후 잡음이 존재하는 신호로 테스트를 할 경우 성능이 감소하게 된다. 이를 해결하기 위하여 음성 인식 수행 전에 잡음을 제거하는 전처리 기술을 도입하여 음성 인식의 성능을 높일 수 있다. 또한, 음성 향상 기술은 음성 통신에서 잡음을 제거하여 선명하고 명확하게 음성을 전달하여 통 화 품질을 높이기 위해서도 사용될 수 있다. 본 발명에 따른 실시예들은 심층 복소수 컨벌루션 순환신경망(Deep Complex Convolution Recurrent Network, DCCRN)을 개량하여 음성에 존재하는 잡음을 제거하는 기술에 관한 발명으로서, 1차적으로 잡음 신호의 전력값을 MS(Minimum statistics) 알고리즘을 이용하여 독립적으로 추정한 후, 추정된 신호들을 FiLM(Feature wise linear modulation) 컨디셔닝을 이용하여 DCCRN 모델에 적용하여 잡음 제거 마스크를 생성함으로써 보다 우수한 성능을 가지는 잡음 제거 기술에 관한 발명이다. 이하에서는 도 1 내지 도 5를 참고하여, 본 발명의 음성 신호 잡음 제거 시스템 및 방법에 관하여 설명한다. 본 발명은 고전적인 잡음 제거 방법과 딥러닝 모델을 이용한 잡음 제거 방법을 결합하여, 우수한 잡음 제거 성능을 가지는 시스템을 고안하였다. 또한, 본 실시예에서는 STFT(Short Time Fourier Transform) 및 ISTFT(Inverse Short Time Fourier Transform) 변환을 이용하는 경우를 예로 들어 설명하나, 이는 실시예에 해당되며, STFT, ISTFT 이외에 DFT(Discrete Fourier Transform), IDFT(Inverse Discrete Fourier Transform) 변환, FFT(Fast Fourier Transform), IFFT(Inverse Fast Fourier Transform) 변환 등이 이용될 수도 있다. 숏타임 푸리에 변환(STFT)을 수행하는 이유는 인공신경망에 입력할 특징벡터를 추출하기 위해 수행하는 것이며, 이는 연산량의 효율을 가져 올 수 있다. 도 1은 일반적인 Minimum statistics(MS) 알고리즘을 이용한 잡음 제거 블록 다이어그램이다. MS 알고리즘은 고 전 신호처리 모델링 기반의 잡음 추정 모델로, 잡음이 섞인 음성 신호의 전력값이 자주 잡음의 전력값 수준으로 내려간다는 관찰을 기반으로 잡음이 섞인 음성의 전력값의 최솟값을 추적함으로써 해당 대역의 잡음 수준을 추 정하도록 설계한 알고리즘이다. 도 2는 일반적인 딥러닝 모델을 이용한 잡음 제거 블록이다. 딥러닝 기반의 잡음 제거 모델은 주로 잡음이 섞인 신호와 깨끗한 환경에서의 음성 신호의 관계를 학습해 입력 신호에 곱해져 잡음을 제거해줄 mask를 추정하는 방 식으로 설계된다. 이러한 딥러닝 기반의 잡음 제거 모델은 고전 신호처리 모델링 기반의 잡음 제거 기술에서 가 정하고 설계했던 부분이 없기 때문에 가정에 맞지 않는 경우에도 비교적 안정적인 잡음 제거 성능을 보여준다는 장점이 있다. 그러나 딥러닝 모델은 고전 신호처리 모델링 기반의 알고리즘에 비해 모델의 크기가 무겁고 원인 분석이 어렵다는 단점이 존재한다. 도 3은 본 발명의 일 실시예에 따른 잡음 제거 시스템의 구성도이다. 본 발명에 따른 잡음 제거 시스템은 고전 MS 알고리즘을 통해 추정된 잡음의 전력값을 이용하여 딥러닝 모 델의 신호를 컨디셔닝 함으로써 다양한 환경에서 우수한 잡음 제거 성능을 가지는 잡음 제거 시스템을 제공한다. 도 3을 참고하면, 본 발명에 따른 잡음 제거 시스템은 신호수집부, 잡음추정부, 잡음 제거 모델 및 음성출력부를 포함할 수 있다. 신호수집부는 외부로부터 음성 신호를 획득하는 구성이다. 신호수집부는 외부로부터 음성 신호를 획 득하고, 획득된 음성 신호의 성분을 변환할 수 있다. 즉, 획득된 디지털 입력 신호 y(t)는 잡음이 포함된 시간 영역의 신호일 수 있으며, 신호수집부는 단시간 푸리에 변환(Short-Term Fourier Transform, STFT)을 통해 획득된 디지털 입력 신호를 주파수 영역의 신호 y(k,l)로 변환할 수 있다. k와 l은 각각 frequency-bin index와 frame index를 의미한다. 즉, 신호수집부는 수집한 시간 영역의 음성 신호를 STFT(Short-Time Fourier Transform)를 통해 주파수 영역의 신호로 변환할 수 있다. 잡음추정부는 MS(minimum statistics) 알고리즘을 통해 획득된 음성 신호에서 잡음의 전력값을 추정하는 구성을 의미한다. 이는 일반적인 MS 알고리즘을 따르는 것으로, MS 알고리즘은 주파수에 따른 전력 스펙트럼에 서 주파수별 전력의 최솟값을 잡음으로 추정한다. MS 알고리즘은 입력된 음성 신호가 종종 잡음 전력 수준으로 감소하는 점 및 잡음이 섞인 음성 신호의 STFT 계수가 통계적으로 독립적이며, 제로-평균 가우시안 확률 변수로 간주되는 점을 가정한다. 즉, 잡음추정부는 입력된 음성 신호에서 최종 음성 신호가 없는 동안 발생한 전 력 값을 잡음의 전력값으로 추정하는 것이다. 잡음추정부는 MS 알고리즘을 통해 입력된 음성 신호의 주파 수 대역별로 전력값의 최솟값을 추적하여 이의 절대값을 상기 대역의 잡음 수준으로 추정하고, 추정된 값은 이 후 잡음 제거 모델에서 후술하는 중간 특징 벡터의 컨디셔닝시 사용된다. 도 4는 본 발명의 일 실시예에 따른 잡음 제거 모델의 순서도이다. 필요에 따라, 잡음 제거 모델은 연산을 통해 입력된 신호의 잡음을 제거할 수 있는 마스크를 생성하기 위 한 구성을 의미한다. 잡음 제거 모델은 잡음추정부에서 추정된 잡음의 전력값을 이용하여 입력 데이 터로부터 추출된 중간 특징 벡터를 컨디셔닝하고, 컨디셔닝된 데이터를 LSTM(Long short-term memory)에 입력하 여 잡음 제거 마스크를 생성하는 구성을 의미한다. 보다 구체적으로, 잡음 제거 모델은 복소수 인코더에 음성 신호를 입력 데이터로 하여 중간 특징 벡터를 추출하고, 중간 특징 벡터를 스케일링 벡터 및 상기 시프트 벡터를 이용하여 컨디셔닝하고, 컨디셔닝된 데이터를 하나 이상의 LSTM(Long short-term memory) 레이어에 제공 하여 잡음 제거 벡터를 생성한 후, 이를 복소수 디코더에 입력하여 음성 신호와 연산가능한 잡음 제거 마스크 출력한다. 도 4를 참고하면, 잡음 제거 모델은 DCCRN(Deep Complex Convolution Recurrent Network)에 따른다. DCCRN은 복소수 인코더 블록과 복소수 디코더 블록이 대칭적으로 존재하며, 복소수 인코더 블록을 통해 소음 신 호의 스펙트로그램의 고차원 특징 벡터를 추출할 수 있다. 즉, 잡음 제거 모델의 인코더 블록은 획득된 음성 신 호에서 잡음 전력 스펙트럼 밀도(power spectral density) 추정치를 포함하는 고차원의 특징 벡터를 추출할 수 있다. 본 발명에서는 컨디셔닝의 대상이 되는 특징 벡터를 중간 특징 벡터라고 할 수 있다. 이는 본 발명에 따 른 잡음 제거 모델에서 적어도 하나 이상의 복소수 인코더 블록을 통해 추출된 특징 벡터를 모두 포함할 수 있다. 즉, 내부 중간 인코더 블록으로부터 추출된 특징 벡터를 모두 포함할 수 있다. 잡음 제거 모델은 획득한 중간 특징 벡터를 FiLM(Feature wise linear modulation)방식으로 컨디셔닝할 수 있다. 이는 고전 신호 처리 방식을 이용하여 획득된 신호를 DNN모델인 DCCRN 모델에 통계적모델링에 기반한 모델이 추정한 잡음 정보를 전달해 잡음제거 성능에 도움을 주기 위한 것으로, 이를 통해 해당 모델의 연산 속 도를 향상시키고, 우수한 잡음 제거 성능을 가지도록 하기 위함이다. 잡음 제거 모델의 FilM 컨디셔닝 방 식은 다음과 같다. 잡음 제거 모델은 획득한 중간 특징 벡터를 잡음의 전력값을 이용하여 컨디셔닝하기 위하여 잡음의 전력값 의 절대값을 벡터화해야 한다. 잡음 제거 모델은 잡음의 전력값의 절대값을 벡터화하기 위해 1차원 컨벌루 션 레이어(one-dimensional convolution layer)를 사용한다. 보다 구체적으로, 잡음 제거 모델은 제1 은둔 레이어를 이용하여 잡음추정부의 결과값을 스케일링 벡터(γ)로 변환하고, 제2 은둔 레이어를 이용하여 잡음추정부의 결과값을 시프트 벡터(β)로 변환한다. 즉, 잡 음 제거 모델은 두 개의 1차원 컨벌루션 레이어를 이용하여 잡음의 전력값의 절대값을 두 번 벡터화할 수 있으며, 이들의 결과값을 각각 스케일링 벡터γ와 시프트 벡터 라고 한다. 벡터화를 통해 생성된 각각의 벡터는중간 특징 벡터와 동일한 차원의 벡터값으로 변환되며, 중간 특징 벡터는 스케일링 벡터와 시프트 벡터와 연산 되어 FilM 컨디셔닝될 수 있으며, 컨디셔닝은 다음과 같은 수학식에 따라 이루어질 수 있다."}
{"patent_id": "10-2023-0069212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "잡음 제거 모델은 컨디셔닝된 데이터를 LSTM(Long short-term memory)에 입력하여 잡음 제거 벡터를 생성할 수 있으며, 생성된 잡음 제거 벡터는 복소수 디코터에 입력되어 음성 신호와 연산가능한 잡음 제거 마스크가 출력 된다. LSTM은 Recurrent Neural Network(RNN) 아키텍처의 한 종류로 일반적으로 RNN을 지칭할 경우, LSTM구조 로 이루어져 있을 정도로 많이 사용되는 구조이다. 잡음 제거 모델은 LSTM에 잡음이 포함된 소리, 포함되지 않 은 소리, 소음 없는 신호와 다양한 소음 신호 등을 이용하여 학습 및 평가를 통해 심층학습을 수행하도록 함으 로써 잡음 제거 마스크를 생성할 수 있다. 인코더-디코더의 아크텍쳐, LSTM 구조는 종래 기술에 해당하는 바, 이에 대한 자세한 설명은 생략한다. 본 발명의 구체적 일 실시예에 따른 잡음 제거 모델은 학습할 때에 optimizer는 adam을 사용했으며, learning rate는 0.0001, 배치값은 4을 사용했다. dataset은 deep noise suppression (DNS) challange 2020에 서 배포한 dataset을 가져와 사용했으며, train, validation, test set 각각 10000, 2000, 721개의 30초 음원 으로 구성되어 있다. test set의 경우에는 noise dataset를 따로 제공하고 있지 않아 Microsoft scalable noisy speech dataset (MS-SNSD)의 noise dataset을 가져와 음성 데이터와 섞어 test set으로 사용했다. 즉, 잡음 제거 모델은 소음이 포함된 음성 신호을 입력데이터로 하고, 상기 신호와 연산을 통해 소음을 제 거할 수 있는 잡음 제거 마스크를 출력 데이터로하는 딥러닝 모델이다. 음성출력부는 잡음 제거 모델로부터 획득된 잡음 제거 마스크와 획득한 음성 신호를 연산시켜 잡음이 제거된 최종 음성 신호를 획득하고 이를 출력한다. 이하, 본 발명의 또 다른 실시예에 따른 음성 신호 잡음 제거 방법에 대해 설명한다. 도 5는 본 발명의 일 실시예에 따른 잡음 제거 방법의 순서도이다. 도 5를 참고하면, 본 발명의 일 실시예에 따 른 음성 신호 잡음 제거 방법은 음성 신호 획득 단계(S1000), 잡음 제거 마스크 획득 단계(S2000) 및 최종 음성 신호 획득 단계(S3000)를 포함한다. 음성 신호 획득 단계(S1000)는 외부로부터 잡음이 포함된 음성 신호를 획득하는 단계를 의미한다. 필요에 따라, 음성 신호 획득 단계는 획득된 음성 신호의 성분을 변환하는 단계를 포함할 수 있다. 즉, 획득된 디지털 입력 신호 y(t)는 잡음이 포함된 시간 영역의 신호일 수 있으며, 장치는 시간 푸리에 변환(Short-Term Fourier Transform, STFT)을 통해 획득된 디지털 입력 신호를 주파수 영역의 신호 y(k,l)로 변환할 수 있다. 도 6은 본 발명의 일 실시예에 따른 잡음 제거 방법의 마스크 생성 단계(S2000)의 순서도이다. 도 6을 참고하면, 잡음 제거 마스크 획득 단계(S2000)는 획득한 음성 신호를 입력 데이터로 하고 딥러닝 모델을 이용하 여 획득한 음성 신호와 연산을 통해 잡음을 제거할 수 있는 잡음 제거 마스크를 획득하는 단계를 의미한다. 필요에 따라, 잡음 제거 마스크 획득 단계(S2000)는 중간 특징 벡터 추출 단계(S2100), 컨디셔닝 단계(S2200), 잡음 제거 벡터 생성 단계(S2300) 및 잡음 제거 마스크 출력 단계(S2400)를 포함할 수 있다. 중간 특징 벡터 추출 단계(S2100)는 획득된 음성 신호를 DCCRN 모델에 입력하여 잡음의 특성을 나타내는 중간 특징 벡터를 추출하는 단계를 의미한다. 즉, 장치는 복소수 인코더에 획득된 음성 신호를 입력 데이터로 하여 중간 특징 벡터를 추출할 수 있다. 이에 더하여, 잡음 제거 마스크 획득 단계(S2000)는, 획득된 음성 신호에서 잡음의 전력값을 추정하는 단계를 포함할 수 있다. 이는 고전적 신호 처리 모델인 MS 알고리즘을 이용하여 획득된 음성 신호의 잡음을 제거하기 위한 것으로, 획득된 음성 신호의 주파수 대역별로 전력값의 최솟값을 추적하여 이의 절대값을 상기 대역의 잡 음의 전력값으로 추정하는 단계를 의미한다. 해당 값은 후에 중간 특징 벡터를 컨디셔닝하는 데에 사용되며, 이 는 DNN모델인 DCCRN 모델에 통계적모델링에 기반한 모델이 추정한 잡음 정보를 전달해 잡음제거 성능에 도움을 주기 위한 것에 해당한다. 이후, 잡음 제거 마스크 획득 단계(S2000)는 획득된 중간 특징 벡터를 컨디셔닝하는 단계(S2200)를 포함할 수 있다. 보다 구체적으로, 획득된 잡음의 전력값의 절대값은 벡터화될 수 있다. 즉, 장치는 1차원 컨벌루션 레이어를 이 용하여 전력값의 절대값을 중간 특징 벡터와 동일한 차원의 벡터로 추출할 수 있다. 장치는 제1 은둔 레이어를 이용하여 추정된 전력값의 절대값을 스케일링 벡터(γ)로 변환하는 스케일링 벡터(γ)추출 단계 및 제2 은둔 레 이어를 이용하여 추정된 전력값의 전력값을 시프트 벡터(β)로 변환하는 시프트 벡터(β)추출 단계를 포함할 수 있다. 컨디셔닝 단계(S2200)는 입력 데이터로부터 추출된 중간 특징 벡터를 스케일링 벡터 및 시프트 벡터를 이용하여 컨디셔닝하는 단계를 포함한다. 이를 통해 스케일이 큰 특징의 영향이 비대해지는 것을 방지하고, 딥러닝에서 Local minima에 빠질 위험을 감소시킬 수 있다. 컨디셔닝 단계(S2200)는 다음의 수학식에 따른 값을 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0069212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "γ(스케일링 벡터데이터), β(시프트 벡터데이터), F(중간 특징 벡터) 잡음 제거 벡터 생성 단계(S2300)는 컨디셔닝된 데이터를 LSTM(Long short-term memory)에 입력하여 잡음 제거 벡터를 생성하는 단계를 의미한다. 잡음 제거 마스크 출력 단계(S2400)는 생성된 잡음 제거 벡터를 복소수 디코더에 입력하여 음성 신호와 연산을 통해 신호의 잡음 제거가 가능한 잡음 제거 마스크를 출력하는 단계를 의미한다. 이 때, 딥러닝 모델은, 입력 데이터의 복소수 연산을 모델링한 심층 복소수 컨벌루션 순환신경망(Deep Complex Convolution Recurrent Network, DCCRN)을 이용한다. 최종 음성 신호 획득 단계(S3000)는 획득된 음성 신호를 잡음 제거 마스크와 연산하여 잡음이 제거된 최종 음성 신호를 획득하는 단계를 의미한다. 도 7 본 발명의 일 실시예에 따른 소음 제거 효과를 도시화한 표이다. 도 7에 따르면, Clean은 노이즈가 없는 신호를 이용한 평가값, Noise는 소음 신호의 평가값을 의미한다. DCCRNoracle의 경우, 본 발명에 따른 잡음 제거 방법을 따르되, 정답 노이즈 신호를 이용하여 컨디셔닝을 해 준 결과를 의미한다. DCCRNMS의 경우는, 본 발명에 따른 잡음 방법을 이용하고, 추정된 전력값의 절대값을 이용하여 컨디셔닝해 준 결과를 의미한다. DCCRNIMCRA는 improved minima controlled recursive averaging 알고리즘을 이용하여 획득한 값을 이용하여 컨디셔닝한 결과 를 의미한다. 성능지표로 PESQ(Perceptual Evaluation of Speech Quality)는 전화대역의 음성신호를 대상으로 개발된 음성품 질 측정 알고리즘의 결과를 의미하며, -0.5~4.5 사이의 값을 가지고, 값이 더 높을수록 우수한 음성 품질을 의 미한다. SI-SDRi(Scale-Invariant SDR)의 경우, 음성 신호의 분리 성능을 의미하며, 높을수록 분리 성능이 우수함을 나 타낸다. STOI 점수는 음성의 명료함을 나타내는 척도로, 0에서 1의 값을 가지며, 값이 클수록 명료함을 의미한다. MOS는 음성 신호를 평가하는 주관적 지표로, 일정수의 청취자들이 음성을 평가하는 값을 의미한다. 도 7을 참고하면, 본 발명에 따른 잡음 제거 모델은 기존 DCCRN 모델보다 우수한 성능을 가짐을 확인할 수 있다. 또한, 많은 지표에서 DCCRNIMCRA 보다 우수한 성능을 가짐도 확인할 수 있다. 기존의 DCCRN은 end-to-end 딥러닝 잡음 제거 모델로 모델의 성능을 향상시키기 위해서는 모델에 어떤 구조를 추가하거나 데이터의 양을 늘리는 방법이 주로 제시되었지만, 모델이 딥러닝 구조를 추가하거나 데이터의 양을 늘리는 방법은 모델의 크기가 늘어나고 학습시간이 보다 오래 걸리는 등의 단점이 존재하였다. 그러나 가볍고 간단한 MS 알고리즘을 활용한 잡음 제거 모델 개선 기법은 모델의 크기가 늘어나거나 학습시간이 오래 걸리지 않고 모델의 성능을 향상시킴으로써 보다 효율적으로 잡음을 제거할 수 있는 딥러닝 기반의 잡음 제거 방법이다. 즉, 본 발명에 따른 잡음 제거 방법은 우수한 잡음 제거 성능을 가질뿐만 아니라, 고전 모델과 딥러닝 모델의 결합을 통해 비교적 모델이 가벼우면서도 원인 분석이 가능하며, 고전 신호 처리 기술에서 가정하고 설계했던 부분이 없기 때문에 가정에 맞지 않는 경우에도 비교적 안정적인 잡음 제거 성능을 보여준다는 장점이 있다."}
{"patent_id": "10-2023-0069212", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일반적인 Minimum statistics(MS) 알고리즘을 이용한 잡음 제거 블록의 다이어그램이다. 도 2는 일반적인 딥러닝 모델을 이용한 잡음 제거 블록이다. 도 3은 본 발명의 일 실시예에 따른 잡음 제거 시스템의 구성도이다. 도 4는 본 발명의 일 실시예에 따른 잡음 제거 모델의 순서도이다. 도 5는 본 발명의 일 실시예에 따른 잡음 제거 방법의 순서도이다. 도 6은 본 발명의 일 실시예에 따른 잡음 제거 방법의 마스크 생성 단계의 순서도이다. 도 7은 본 발명의 일 실시예에 따른 소음 제거 결과를 도시화한 표이다."}
