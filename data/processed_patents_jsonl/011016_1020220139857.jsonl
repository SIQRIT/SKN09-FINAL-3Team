{"patent_id": "10-2022-0139857", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0059075", "출원번호": "10-2022-0139857", "발명의 명칭": "기계학습 기반 온라인 보컬 분석 서비스 시스템", "출원인": "김기범", "발명자": "김기범"}}
{"patent_id": "10-2022-0139857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "흡음된 소리에서 소음을 제거하고, 세분화해서 특징을 추출하고, 추출된 특징과 기준값을 비교하고, 비교 결과를 출력하는 분석부(31);사용자 유형1(40), 사용자 유형2(60)에 따라 분석, 가창, 녹음, 커뮤니티, 수업, 통계, 교육, 콘테스트, 경험,공유 서비스를 제공하는 사용자 서비스(32); 및키보드(21), 마우스(22), 터치스크린(23)의 조작을 입력받고, 입력된 조작에 따라 마이크(24), 스피커(25)를 이용한 기계학습 기반 온라인 보컬 분석 서비스를 수행하고, 상기 분석부(31), 상기 사용자 서비스(32)의 동작을제어하는 제어부(5);를 포함하는 것을 특징으로 하는, 기계학습 기반 온라인 보컬 분석 서비스 시스템."}
{"patent_id": "10-2022-0139857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 분석부(31)는,음성 신호 입력 단계(S201), 음성을 제외한 악기 및 소음 제거 단계(S202), 음성 신호를 일정 시간 단위로 세분단계(S203), 각 프레임별 신호 분석 및 특징 추출 단계(S204), 원곡과의 비교를 통한 세부 분석 내용 도출 단계(S205), 분석 종료 및 결과 출력 단계(S206)를 수행하는 것을 특징으로 하는, 기계학습 기반 온라인 보컬 분석서비스 시스템."}
{"patent_id": "10-2022-0139857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 단계(S202)는,음성 신호를 STFT(Short Time Fourier Transform) 변환하여 분석하는 방법, 음성 신호를 직접 분석하는 방법을혼합하여 목소리에 해당하는 신호를 분리하는 것을 특징으로 하는, 기계학습 기반 온라인 보컬 분석 서비스 시스템."}
{"patent_id": "10-2022-0139857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 단계(S204)는,주변 소음이 제거된 음성 신호를 프레임 단위로 세분화하여 음정, 세기, 호흡, 발성, 발음, 감정을 분석하고,발음은 한국어 발음을 국제 발음 기호로 변환하는 것을 특징으로 하는, 기계학습 기반 온라인 보컬 분석 서비스시스템."}
{"patent_id": "10-2022-0139857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 단계(S205)는,원곡 또한 단계(204)를 통해 프레임별 분석하고, 각각의 프레임의 박자에 맞추어 대응시키고, 다이나믹 타임 래핑(DTW: Dynamic Time Wraping)을 이용하여 두 개의 시계열 데이터와 각 데이터별 거리 함수를 정의하고, 거리가 최소가 되는 경로를 선택한 후, 각 요소에 맞게 프레임별 비교하고, 각 요소별로 오차를 계산하는 것을 특징으로 하는, 기계학습 기반 온라인 보컬 분석 서비스 시스템."}
{"patent_id": "10-2022-0139857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0059075-3-제1항에 있어서,상기 사용자 유형1(40)은,사용자의 녹음분에 대한 시간별, 총 7가지 가창 요소별 세분 분석을 포함하는 분석 리포트(41); 반복 연습을 원하는 경우 해당 구간만 반복 연습하는 반복 가청부(42); 가창 요소별 다양한 연습을 수행하고, 실시간으로 분석하는 실시간 분석부(43); 연습 환경을 제공하고, 녹음, 재생하는 녹음/재생부(44); 가창 실력을 가시화하고 확인하는 실력 향상부(45); 가창 요소별 원곡과의 유사 정도를 시간에 따라 비교 분석하는 비교부(46); 가창 관련의문에 대해 전문가에게 질의하고 답변하는 커뮤니티부(47); 전문가와 비전문가의 오프라인 수업을 매칭하는 수업 매칭부(48); 피수강자의 가창 실력 변화 데이터를 바탕으로 통계 분석하는 통계 분석부(49); 사용자에게 적합한 교육을 추천하는 교육 추천부(50);를 포함하는 것을 특징으로 하는, 기계학습 기반 온라인 보컬 분석 서비스 시스템."}
{"patent_id": "10-2022-0139857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 사용자 유형2(60)는,지인, 지역, 소속 범위 내에서 경쟁하는 경쟁부(61); 앱을 사용하는 사용자끼리 경쟁하는 콘테스트(62); 지역또는 소속에 포함된 사용자간에 경쟁하는 경쟁 콘테스트(63); 경험치 및 업적을 제공하는 경험치부(64); 듀엣및 화음을 분석하는 화음 분석부(65); 녹음 내용 또는 분석 결과를 공유하는 공유부(66);를 포함하는 것을 특징으로 하는, 기계학습 기반 온라인 보컬 분석 서비스 시스템."}
{"patent_id": "10-2022-0139857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항 또는 제7항 중 어느 한 항에 있어서,상기 반복 가청부(42), 상기 실시간 분석부(43), 상기 화음 분석부(65)의 결과, DB(9)를 이용하여 녹음본과 원곡을 비교 분석하여 분석 리포트를 출력하는 분석 리포트(41)를 더 포함하는 것을 특징으로 하는, 기계학습 기반 온라인 보컬 분석 서비스 시스템."}
{"patent_id": "10-2022-0139857", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 음성을 제외한 악기 및 소음을 제거하고, 음성 신호를 세분화하여 프레임별 특징을 추출하고, 추출된 특징과 원곡을 비교하고 비교 결과를 출력하고, 사용자 유형에 따라 분석, 가창, 녹음, 커뮤니티, 수업, 통계, 교육, 콘테스트, 경험, 공유 서비스를 제공하고, 음성 시계열 데이터, STFT 신호, 프레임 신호, 음정, 세기, 발 성, 호흡, 발음, 감정 특징, 벡터 신호, 분석 결과를 포함하는 샘플링 데이터에 기반한 데이터 오류를 검증한다."}
{"patent_id": "10-2022-0139857", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 기계학습 기반 온라인 보컬 분석 서비스 시스템에 관한 것으로, 보다 상세하게는 다각화된 가창 분석 을 통한 일반화된 통계적 분석을 수행하고, 사용자에게 전문 교육을 제공하고, 강의 제공자에게는 교육 과정의 검증 및 홍보의 수단으로, 수강자에게는 효율적으로 실력을 향상하고, 시스템의 동작 신뢰성을 높이는 기계학습 기반 온라인 보컬 분석 서비스 시스템에 관한 것이다."}
{"patent_id": "10-2022-0139857", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 발명에 관련된 종래기술에는 가이드 음성 재생, 보컬 치료, 음색 분석, 보컬 평가, 발성 분석이 있다. 특허 문헌 1 단말 장치, 가이드 음성 재생 방법 및 기억 매체는 합성되는 가이드 음성의 성질을 연주 데이터에 따라 변화시킨다. 또한, 특허문헌 2 보컬프랙틱 시스템은 피교정자가 교정 정도 및 교정 여부를 시각적으로 인지할 수 있다. 또한, 특허문헌 3 사용자 음색 분석 장치 및 음색 분석 방법은 사용자가 자신의 노래 음색의 기존 가 수들의 음색으로부터 독창성 정도에 대한 정보를 제공받는다. 또한, 특허문헌 4 보컬 평가 시스템은 보컬 관련 입시 준비생과 보컬 관련 지망생이 본인의 보컬 능력을 보다 객관적이고 절대적인 기준에 의해 파악할 수 있고, 다각도로 표준화된 평가 정보에 의해 미비한 점을 보완할 수 있다. 또한, 특허문헌 5 사용자의 발성을 분석하는 방법 및 이를 수행하는 장치는 사용자의 발성과 매칭되는 추천 기획사를 결정하고, 결정된 추천 기획사를 나타 내는 추천 기획사 데이터를 생성한다. 그러나 종래기술은 음성을 제외한 악기 및 소음을 제거하고, 음성 신호를 세분화하여 프레임별 특징을 추출하고, 추출된 특징과 원곡을 비교하고 비교 결과를 출력하지 못하는 문제점이 있다.선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10-0530916호 단말 장치, 가이드 음성 재생 방법 및 기억 매체 (특허문헌 0002) 등록특허공보 제10-1471741호 보컬프랙틱 시스템 (특허문헌 0003) 등록특허공보 제10-1813704호 사용자 음색 분석 장치 및 음색 분석 방법 (특허문헌 0004) 등록특허공보 제10-1917216호 보컬 평가 시스템 (특허문헌 0005) 공개특허공보 제10-2022-0115157호 사용자의 발성을 분석하는 방법 및 이를 수행하는 장치"}
{"patent_id": "10-2022-0139857", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 음성을 제외한 악기 및 소음을 제거하고, 음성 신호를 세분화하여 프레임별 특징을 추출하고, 추출된 특징과 원곡을 비교하고 비교 결과를 출력하는 기계학습 기반 온라인 보컬 분석 서비스 시스템을 제공하는 것을 목적으로 한다. 또한, 본 발명은 사용자 유형에 따라 분석, 가창, 녹음, 커뮤니티, 수업, 통계, 교육, 콘테스트, 경험, 공유 서 비스를 제공하는 기계학습 기반 온라인 보컬 분석 서비스 시스템을 제공하는 것을 또 다른 목적으로 한다. 또한, 본 발명은 음성 시계열 데이터, STFT 신호, 프레임 신호, 음정, 세기, 발성, 호흡, 발음, 감정 특징, 벡 터 신호, 분석 결과를 포함하는 샘플링 데이터에 기반한 데이터 오류를 검증하는 기계학습 기반 온라인 보컬 분 석 서비스 시스템을 제공하는 것을 또 다른 목적으로 한다."}
{"patent_id": "10-2022-0139857", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 바람직한 일 실시예에 따른 기계학습 기반 온라인 보컬 분석 서비스 시스템은, 흡음된 소리에서 소음 을 제거하고, 세분화해서 특징을 추출하고, 추출된 특징과 기준값을 비교하고, 비교 결과를 출력하는 분석부 ; 사용자 유형1, 사용자 유형2에 따라 분석, 가창, 녹음, 커뮤니티, 수업, 통계, 교육, 콘테스트, 경험, 공유 서비스를 제공하는 사용자 서비스; 및 키보드, 마우스, 터치스크린의 조작을 입력 받고, 입력된 조작에 따라 마이크, 스피커를 이용한 기계학습 기반 온라인 보컬 분석 서비스를 수행하 고, 상기 분석부, 상기 사용자 서비스의 동작을 제어하는 제어부;를 포함하는 것을 특징으로 한다. 또한, 상기 분석부는, 음성 신호 입력 단계(S201), 음성을 제외한 악기 및 소음 제거 단계(S202), 음성 신 호를 일정 시간 단위로 세분 단계(S203), 각 프레임별 신호 분석 및 특징 추출 단계(S204), 원곡과의 비교를 통 한 세부 분석 내용 도출 단계(S205), 분석 종료 및 결과 출력 단계(S206)를 수행하는 것을 특징으로 한다. 또한, 상기 단계(S202)는, 음성 신호를 STFT(Short Time Fourier Transform) 변환하여 분석하는 방법, 음성 신 호를 직접 분석하는 방법을 혼합하여 목소리에 해당하는 신호를 분리하는 것을 특징으로 한다. 또한, 상기 단계(S204)는, 주변 소음이 제거된 음성 신호를 프레임 단위로 세분화하여 음정, 세기, 호흡, 발성, 발음, 감정을 분석하고, 발음은 한국어 발음을 국제 발음 기호로 변환하는 것을 특징으로 한다. 또한, 상기 단계(S205)는, 원곡 또한 단계를 통해 프레임별 분석하고, 각각의 프레임의 박자에 맞추어 대 응시키고, 다이나믹 타임 래핑(DTW: Dynamic Time Wraping)을 이용하여 두 개의 시계열 데이터와 각 데이터별 거리 함수를 정의하고, 거리가 최소가 되는 경로를 선택한 후, 각 요소에 맞게 프레임별 비교하고, 각 요소별로 오차를 계산하는 것을 특징으로 한다. 또한, 상기 사용자 유형1은, 사용자의 녹음분에 대한 시간별, 총 7가지 가창 요소별 세분 분석을 포함하는 분석 리포트; 반복 연습을 원하는 경우 해당 구간만 반복 연습하는 반복 가청부; 가창 요소별 다양한 연습을 수행하고, 실시간으로 분석하는 실시간 분석부; 연습 환경을 제공하고, 녹음, 재생하는 녹음/재생부 ; 가창 실력을 가시화하고 확인하는 실력 향상부; 가창 요소별 원곡과의 유사 정도를 시간에 따라 비교 분석하는 비교부; 가창 관련 의문에 대해 전문가에게 질의하고 답변하는 커뮤니티부; 전문가와 비전문가의 오프라인 수업을 매칭하는 수업 매칭부; 피수강자의 가창 실력 변화 데이터를 바탕으로 통계 분석하는 통계 분석부; 사용자에게 적합한 교육을 추천하는 교육 추천부;를 포함하는 것을 특징으로 한다. 또한, 상기 사용자 유형2는, 지인, 지역, 소속 범위 내에서 경쟁하는 경쟁부; 앱을 사용하는 사용자끼 리 경쟁하는 콘테스트; 지역 또는 소속에 포함된 사용자간에 경쟁하는 경쟁 콘테스트; 경험치 및 업적 을 제공하는 경험치부; 듀엣 및 화음을 분석하는 화음 분석부; 녹음 내용 또는 분석 결과를 공유하는 공유부;를 포함하는 것을 특징으로 한다. 또한, 상기 반복 가청부, 상기 실시간 분석부, 상기 화음 분석부의 결과, DB를 이용하여 녹음본 과 원곡을 비교 분석하여 분석 리포트를 출력하는 분석 리포트를 더 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0139857", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 음성을 제외한 악기 및 소음을 제거하고, 음성 신호를 세분화하여 프레임별 특징을 추출하고, 추출된 특징과 원곡을 비교하고 비교 결과를 출력함으로써 다각화된 가창 분석을 통한 일반화된 통계적 분석을 수행하 는 효과를 가질 수 있다. 또한, 본 발명은 사용자 유형에 따라 분석, 가창, 녹음, 커뮤니티, 수업, 통계, 교육, 콘테스트, 경험, 공유 서 비스를 제공함으로써 사용자에게 전문 교육을 제공하고, 강의 제공자에게는 교육 과정의 검증 및 홍보의 수단으 로, 수강자에게는 효율적으로 실력을 향상하는 효과를 가질 수 있다. 또한, 본 발명은 음성 시계열 데이터, STFT 신호, 프레임 신호, 음정, 세기, 발성, 호흡, 발음, 감정 특징, 벡 터 신호, 분석 결과를 포함하는 샘플링 데이터에 기반한 데이터 오류를 검증함으로써 시스템의 동작 신뢰성을 높이는 효과를 가질 수 있다. 또한, 분석 리포트는, 반복 가청부, 실시간 분석부, 화음 분석부의 결과, DB를 이용하여 녹 음본과 원곡을 비교 분석하여 분석 리포트를 출력하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0139857", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 실시 예에 따른 기계학습 기반 온라인 보컬 분석 서비스 시스템에 대하여 상 세히 설명하기로 한다. 이하에서 종래 주지된 사항에 대한 설명은 본 발명의 요지를 명확히 하기 위해 생략하거 나 간단히 한다. 본 발명의 설명에 포함된 구성은 개별 또는 복합 결합 구성되어 동작한다. 도 1은 본 발명 기계학습 기반 온라인 보컬 분석 서비스 장치의 구성을 보인 블록도로서, 도 1을 참조하면, 단 말기는 키보드, 마우스, 터치스크린, 마이크, 스피커, 제어부, 분석부, 사용자 서비스를 포함한다. 단말기는 기계학습 기반 온라인 보컬 분석 서비스를 수행한다. 키보드는 타자기의 자판과 유사한 모양새를 띤 컴퓨터의 입력 장치 중 하나로, 시스템에 숫자, 문자를 입력 할 때 사용되고, 키를 누르면 그에 대응한 신호가 시스템에 입력된다. 마우스는 화면의 커서나 아이콘을 이동시킬 때 사용되는 입력 장치로, 커서 이동, 클릭, 스크롤을 포함하는 명령을 시스템에 입력한다. 터치스크린은 손으로 접촉하면 그 위치를 입력받도록 하는 입력 장치로, 키보드를 사용하지 않고, 화면 에 나타난 문자, 특정 위치에 손이 닿으면 그 위치를 파악하여 시스템에 입력한다. 마이크는 소리를 흡음해서 전기적인 신호로 바꾸어 믹서나 녹음기로 전송하고, 제어부에서 전기 신호를 처리한다. 스피커는 전기 신호를 진동판의 진동으로 바꾸어 공기에 소밀파를 발생시켜 음파를 복사하고, 제어부에 서 전기 신호를 생성한다. 제어부는 키보드, 마우스, 터치스크린의 조작을 입력받고, 입력된 조작에 따라 마이크, 스 피커를 이용한 기계학습 기반 온라인 보컬 분석 서비스를 수행하고, 분석부, 사용자 서비스의 동작 을 제어한다. 분석부는 흡음된 소리에서 소음을 제거하고, 세분화해서 특징을 추출하고, 추출된 특징과 기준값을 비교하 고, 비교 결과를 출력한다. 사용자 서비스는 사용자 유형에 따라 분석, 가창, 녹음, 커뮤니티, 수업, 통계, 교육, 콘테스트, 경험, 공 유 서비스를 제공한다. 도 2는 도 1 기계학습 기반 온라인 보컬 분석 서비스 방법의 분석 동작을 보인 흐름도로서, 도 2를 참조하면, 단말기는 음성 신호 입력 단계(S201), 음성을 제외한 악기 및 소음 제거 단계(S202), 음성 신호를 일정 시간 단위로 세분 단계(S203), 각 프레임별 신호 분석 및 특징 추출 단계(S204), 원곡과의 비교를 통한 세부 분석 내 용 도출 단계(S205), 분석 종료 및 결과 출력 단계(S206)를 수행한다. 도 3은 도 2 분석 동작의 악기 및 소음 제거 과정을 보인 예시도이다. 단계(S202)는 도 3의 91인 음성 신호를 STFT(Short Time Fourier Transform)(진동수 신호) 변환하여 분석하는 방법, 도 3의 92인 음성 신호를 직접 분석하는 방법을 혼합하여 목소리에 해당하는 신호를 분리한다. 단계 (S202)는 인공지능 구조 중 부호기(91, 95), 복호기(92, 96) 구조로 구성한다. 부호기(91, 95)는 음성 신호와 진동수 신호로 구분되며, 각각의 부호기(91, 95)를 통해 음성신호와 진동수 신호는 각각의 잠재벡터(Latent Vector)로 변환된다. 두 개의 부호기를 통한 서로 다른 잠재 벡터는 서로 교차분석되어 목소리에 해당하는 신호 만을 추출하기 위한 잠재벡터로 변환된다. 이후, 교차 분석된 목소리 추출을 위한 음성 신호에 해당하는 잠 재벡터와 진동수 신호에 해당하는 잠재벡터는 다시 구분된 복호기(92, 96)를 통해 목소리 이외의 신호가 제거된 음성 신호와 진동수 신호로 반환된다. 각각 복호화된 두 신호는 다시 교차 분석되어 최종 목소리 신호인 음 성 신호로 분리된다. 도 4는 도 2 분석 동작의 특징 추출 과정을 보인 예시도이다. 단계(S204)는 주변 소음이 제거된 음성 신호를 프레임 단위로 세분화하여 분석한다. 도 4를 참고하면, 세분된 입력 신호는 CNN(Convolution Neural Network) 구조를 이용하여 잠재벡터를 추출한다. 이때, 유사 한 입력신호는 유사한 잠재벡터로 변환되어야 한다. 이를 보정하기 위해 각각의 잠재벡터는 전이 구조 (Transformer)를 거쳐 문맥벡터(content vector)로 변환된다. 또한, 잠재벡터는 MLM(Masked Language Model) 기법이 적용되어 이산화 단계(Quantized representation)를 거쳐 입력신호 간 유사도가 학습된다. 이후, 입력신호는 학습된 기계학습 모델을 통해 잠재벡터로 변환된다. 일반적으로 입력 신호와 잠재벡터의 변환은 모든 음성 신호를 학습 데이터로 사용하지만, 본 발명에서는 음성 신호 중 노래에 대 응되는 보컬 데이터만을 학습 데이터로 사용하여 보컬 정보에 잠재벡터를 추출하고, 보컬 관련 특징을 보다 높은 정확도로 추출한다. 도 4의 단계(S204)를 통해 추출된 잠재벡터는 추가적인 5개의 구분된 기계학습 모델을 통해 음정, 세기, 호흡, 발성, 발음, 감정으로 구분되어 각각의 요소는 분석된다. 발음은 타 가창 요소와 비교하여 한국어 만의 언어적 특성으로 인해 이에 적합한 분석 방법이 적용된다. 본 발명은 한국어 발음을 국제 발음 기호로 변환하고, 적용 된 발음 규칙 및 예외 사항 처리 순서는 예외처리-유기음화(겹받침)-경음화-겹받침단순화-비음화-리을 재음절화-유음화-구개음화-유기음화(홀받침)-연음-종성중화-리을 재음절화로 진행한다. 감정은 한국지능정보사회진흥원 이 운영하는 AI 통합 플랫폼 “AI-hub”의 데이터 바탕으로 '기쁨', '불안', '상처', '슬픔', '분노', '당황' 총 6가지로 분류한다. 도 5는 도 2 분석 동작의 비교 과정을 보인 예시도이다. 단계(S205)는 음성 신호를 프레임별 분석 완료한 후 원곡과 비교한다. 단계(S205)는 원곡 또한 단계를 통 해 프레임별 분석하고, 각각의 프레임의 박자에 맞추어 대응시킨다. 본 발명은 도 5의 다이나믹 타임 래핑(DTW: Dynamic Time Wraping)을 이용한다. 다이나믹 타임 래핑은 두 개의 시계열 데이터와 각 데이터별 거리 함수를 정의하고, 거리가 최소가 되는 경로를 선택한다. 이후, 단계(S205)는 각 요소에 맞게 프레임별 비교하고, 각 요 소별로 오차를 계산하는 방법은 리그레션 모델(Regression Model)인 음정, 세기 모델 Mean Squared Error(MS E)를 적용하고, Classification Model인 호흡, 발성, 발음, 감정 모델 Cross Entropy, Error(CEE)를 적용한다. 단계(S205)는 DTW, MSE, CEE를 통해 박자, 음정, 세기, 호흡, 발성, 발음, 감정의 프레임별 원곡과 음성 신호 사이의 오차를 계산하고, 이동 평균에 따라 분석 결과를 출력한다. 도 6은 도 1 기계학습 기반 온라인 보컬 분석 서비스 장치의 사용자 서비스를 보인 블록도로서, 도 6을 참조하 면, 사용자 서비스는 사용자 유형1, 사용자 유형2를 포함한다. 사용자 서비스는 사용자 유형1, 사용자 유형2에 따라 분석, 가창, 녹음, 커뮤니티, 수업, 통계, 교 육, 콘테스트, 경험, 공유 서비스를 제공한다. 사용자 유형1은 사용자의 녹음분에 대한 시간별, 총 7가지 가창 요소별 세분 분석을 포함하는 분석 리포트 ; 반복 연습을 원하는 경우 해당 구간만 반복 연습하는 반복 가청부; 가창 요소별 다양한 연습을 수행 하고, 실시간으로 분석하는 실시간 분석부; 연습 환경을 제공하고, 녹음, 재생하는 녹음/재생부; 가창 실력을 가시화하고 확인하는 실력 향상부; 가창 요소별 원곡과의 유사 정도를 시간에 따라 비교 분석하는 비교부; 가창 관련 의문에 대해 전문가에게 질의하고 답변하는 커뮤니티부; 전문가와 비전문가의 오프 라인 수업을 매칭하는 수업 매칭부; 피수강자의 가창 실력 변화 데이터를 바탕으로 통계 분석하는 통계 분 석부; 사용자에게 적합한 교육을 추천하는 교육 추천부;를 포함한다. 사용자 유형2는 지인, 지역, 소속 범위 내에서 경쟁하는 경쟁부; 앱을 사용하는 사용자끼리 경쟁하는 콘테스트; 지역 또는 소속에 포함된 사용자간에 경쟁하는 경쟁 콘테스트; 경험치 및 업적을 제공하는 경험치부; 듀엣 및 화음을 분석하는 화음 분석부; 녹음 내용 또는 분석 결과를 공유하는 공유부;를 포함한다. 도 7은 도 1 기계학습 기반 온라인 보컬 분석 서비스 장치의 반복 가청부, 실시간 분석부, 화음 분석부의 결과, DB를 이용하여 녹음본과 원곡을 비교 분석하여 분석 리포트를 출력하는 예시도이다. 도 7을 참조하면, 분석 리포트는 반복 가청부, 실시간 분석부, 화음 분석부의 결과를 이용한다. 분석 리포트는 DB로부터 데이터를 제공받아, 원곡과의 시간 동기화를 이룬 뒤, 다수의 분석부 에서 비동기적으로 분석을 수행하고, 이를 다시 종합하는 과정을 수행한다. 분석 리포트는 비동기적인 분석부를 이용하여 분석 리포트 서비스를 제공하는데 소용되는 시간을 비약적으로 줄일 수 있다. 도 8은 본 발명을 설명하기 위한 데이터 오류를 검증하는 구성을 설명하는 예시도이다. 도 8을 참조하면, 제어부는 샘플링 데이터를 저장하고, 일정 시간 동안 샘플링 데이터의 크기 별로 발생 회 수를 누적하여 확률 분포를 계산하고, 또 다른 일정 시간 동안의 확률 분포를 계산하고, 두 확률 분포의 차, 면 적 차, 차 거리 누적을 계산해서(S101) 샘플링 회로 이상, 데이터 오류, 데이터 변화를 예측하고, 이에 대응할 수 있다(S102). 제어부는 예측 결과를 사용자에게 알림으로써 사용자가 대응하거나 제어부가 하드웨어 고 장, 데이터 오류, 데이터 변화에 대응할 수 있다. 샘플링 데이터는 음성 시계열 데이터, STFT 신호, 프레임 신호, 음정, 세기, 발성, 호흡, 발음, 감정 특징, 벡 터 신호, 분석 결과를 포함하고, 제어부는 샘플링 데이터에 기반하여 하드웨어 고장, 데이터 오류, 데이터 변화에 대응한다. 제어부는 일정 시간 동안 마다 각각의 확률 분포 추이를 보고, 확률 분포 중 특이 현상 이상을 예측하고, 이 상 사고에 대응하고, 확률 분포에 대해 데이터 변화가 일정하면 정상 동작을 외부에 알린다. 또한, 제어부는 일정 시간 간격을 조정하기 위해 데이터 변화율을 피드백한다. 예를 들어, 데이터 변화율이 크면 일정 시간 간격을 늘리고, 데이터 변화율이 작으면 일정 시간 간격을 줄인다. 도 9는 본 발명을 설명하기 위한 하드웨어 자원과 운영체제, 코어인 제어부의 동작, 제어부 동작을 실행할 권한 을 부여하는 시스템 인증 구성을 설명하는 예시도로서, 도 9를 참조하면, 본 발명은 프로세서, 메모리, 입출력장치, 운영체제, 제어부를 포함한다. 프로세서는 CPU(Central Processing Units), GPU(Graphic Processing Unit), FPGA(Field Programmable Gate Array), NPU(Neural Processing Unit)로서, 메모리에 탑재된 운영체제, 제어부의 실행 코드를 수행한다. 메모리는 RAM(random access memory), ROM(read only memory), 디스크 드라이브, SSD(solid state drive), 플래시 메모리(flash memory) 등과 같은 비소멸성 대용량 저장 장치(permanent mass storage device)를 포함할 수 있다. 입출력장치는 입력 장치로, 오디오 센서 및/또는 이미지 센서를 포함한 카메라, 키보드, 마이크로폰, 마우스 등의 장치를, 그리고 출력 장치로, 디스플레이, 스피커, 햅틱 피드백 디바이스(haptic feedback device) 등과 같은 장치를 포함할 수 있다. 운영체제는 윈도우, 리눅스, IOS, 가상 머신, 웹브라우저, 인터프리터를 포함할 수 있고, 태스크, 쓰레드, 타이머 실행, 스케줄링, 자원 관리, 그래픽, 폰트 처리, 통신 등을 지원한다. 제어부는 운영체제의 지원하에 입출력장치의 센서, 키, 터치, 마우스 입력에 의한 상태를 결정하고, 결정된 상태에 따른 동작을 수행한다. 제어부는 병렬 수행 루틴으로 타이머, 쓰레드에 의한 작업 스케줄링을 수행한다. 제어부는 입출력장치의 센서값을 이용하여 상태를 결정하고, 결정된 상태에 따른 알고리즘을 수행한다. 도 9를 참조하면, 시스템 인증 구성은 제어부를 포함하는 단말기, 인증 서버를 포함한다. 단말기는 데이터 채널을 이중화하고, 단말기의 키값, 생체 정보를 입력받아 인증 서버에 제1데이터 채 널을 통해 사용자 인증을 요청하고, 단말기는 생성된 킷값을 디스플레이에 표시하고, 인증 서버로 전송한 다. 단말기는 단말기의 디스플레이에 표시된 킷값을 입력하고, 사용자 정보와 함께 제2데이터 채널을 통해 인 증 서버로 전송한다. 단말기는 킷값과 사용자 정보를 이용하여 단말기에 탑재된 시스템의 인증을 인증 서버에 요청한다. 단말기의 킷값은 컴퓨터 고유의 정보인 CPU 제조번호, 이더넷 칩의 맥주소로부터 생성 될 수 있다. 단말기는 카메라를 이용한 얼굴 인식, 마이크를 이용한 음성 인식, 디스플레이를 이용한 필기 인식을 통해 사용자 정보를 획득하고, 인증에 활용할 수 있다. 인증 서버는 단말기로부터 킷값을 수신하고, 단말기로부터 이중화된 데이터 채널을 통해 킷값과 사용 자 정보를 수신하여 단말기의 킷값과 사용자 정보를 비교하고, 사용자 정보를 대응시켜 단말기의 시스템 이용에 대한 인증을 처리한다. 인증 서버는 인증 결과를 단말기로 전송하여 시스템에 대한 사용자의 사용 을 허가한다. 단말기의 이중화된 데이터 채널로 인해 킷값 손실이 최소화되는 효과를 가질 수 있다. 인증 서버는 사용자 정보의 히스토리 분석을 수행하고, 시간 흐름에 따라 사용자 정보의 일관성, 변화를 비 교 판단한다. 히스토리 분석에서 사용자 정보가 일관성을 나타내면 사용자의 사용을 허가하고, 변화를 나타내면 사용자의 사용을 허가하지 않는다. 사용자 정보가 일관성을 나타낼 때 사용자의 시스템 사용을 허가함으로써 사 용자 정보가 변조된 사용자가 시스템에 접근하지 못하도록 보안을 강화한다. 인증 서버는 일관성, 변화, 빈도, 빈도 추이, 빈도가 높음에 가중치를 부여해서 가중치 조합으로 신뢰되지 않은 사용자의 접근을 차단한다. 예를 들어, 빈도의 임계치가 초과하면 초과 누적수에 비례하여 신뢰되지 않은 사용자의 접근을 차단하고, 장시간에 걸쳐 접근 시도하는 사용자를 인증 처리할 수 있다. 이때, 신뢰되지 않은 사용자에 대해 추가 인증을 요청한다. 시스템의 사용을 인증하는 수단인 단말기는 시스템과 직접 연결하지 않고, 인증 서버를 통한 우회 경로를 형성함으로써 인터넷망을 이루는 네트워크가 내부망과 외부망으로 구성되어 아이피 주소 설정 과정이 번거로울 때 단말기를 이용한 인증 과정이 원활히 수행되는 장점이 있다. 이때, 단말기에는 시스템이 탑재되고, 단 말기는 인증 단말 수단이 되고, 인증 서버는 인증 서버 수단이 된다.클라우드는 프로세서, 메모리, 입출력장치, 통신부를 관리하는 운영체제의 지원 하에 컨테 이너의 모듈화로, 웹, DB, 프로토콜, 라이브러리의 서비스를 제공하며, 제어부는 컨테이너 의 서비스를 이용한 클라우드 애플리케이션을 실행한다. 컨테이너라고 하는 표준 소프트웨어 패키지는 애 플리케이션의 코드를 관련 구성 파일, 라이브러리 및 앱 실행에 필요한 종속성과 함께 번들로 제공한다. 클라우드는 다수의 단말기를 통합 제어하고, 단말기로부터 수신된 센서값을 저장하여 시간 흐름에 따 라 모니터링하고, 단말기의 동작 에러를 처리하고, 에러 메시지를 다른 단말기로 알리고, 제어 대상인 단 말기를 스위칭 제어한다. 신경망 학습은 온도, 고도, 지문 등 각종 센서, 이미지, 적외선 등 카메라, 라이더와 같은 입력 장치로부터 수 집된 시계열 데이터로부터 특징량 선택, 알고리즘 선택을 통해 모델을 선택하고, 학습, 성능 검증 과정에 의한 반복 시행 착오를 거쳐 모델 선택을 반복한다. 성능 검증이 마치면 인공지능 모델이 선택된다. 제어부는 센서값 판단에 신경망을 이용한 딥러닝 알고리즘을 수행하고, 신경망 학습에 훈련 데이터를 이용하 고, 시험 데이터로 신경망 성능을 검증한다. 본 발명은 상술한 특정의 바람직한 실시 예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗 어남이 없이 해당 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 누구든지 다양한 변형실시가 가능한 것은 물론이고, 그와 같은 변경은 청구범위 기재의 범위 내에 있게 된다."}
{"patent_id": "10-2022-0139857", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명 기계학습 기반 온라인 보컬 분석 서비스 장치의 구성을 보인 블록도이다. 도 2는 도 1 기계학습 기반 온라인 보컬 분석 서비스 방법의 분석 동작을 보인 흐름도이다. 도 3은 도 2 분석 동작의 소음 제거 과정을 보인 예시도이다. 도 4는 도 2 분석 동작의 특징 추출 과정을 보인 예시도이다. 도 5는 도 2 분석 동작의 비교 과정을 보인 예시도이다. 도 6은 도 1 기계학습 기반 온라인 보컬 분석 서비스 장치의 사용자 서비스를 보인 블록도이다. 도 7은 도 1 기계학습 기반 온라인 보컬 분석 서비스 장치의 반복 가청부, 실시간 분석부, 화음 분석부의 결과, DB를 이용하여 녹음본과 원곡을 비교 분석하여 분석 리포트를 출력하는 예시도이다. 도 8은 본 발명을 설명하기 위한 데이터 오류를 검증하는 구성을 설명하는 예시도이다. 도 9는 본 발명을 설명하기 위한 하드웨어 자원과 운영체제, 코어인 제어부의 동작, 제어부 동작을 실행할 권한 을 부여하는 시스템 인증 구성을 설명하는 예시도이다."}
