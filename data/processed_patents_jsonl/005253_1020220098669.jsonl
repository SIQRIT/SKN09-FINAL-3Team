{"patent_id": "10-2022-0098669", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0020519", "출원번호": "10-2022-0098669", "발명의 명칭": "트랜스포머 기반 언어모델을 이용하여 문장을 생성하는 장치, 방법 및 컴퓨터 프로그램", "출원인": "주식회사 케이티", "발명자": "류휘정"}}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "트랜스포머(Transformer) 기반 언어모델을 이용하여 문장을 생성하는 문장 생성 장치에 있어서,소스 문장을 수신하는 소스 문장 수신부;미리 학습된 입력 인코더 및 디코더를 이용하여 상기 소스 문장으로부터 미완성 문장을 생성하는 미완성 문장생성부;상기 미완성 문장이 기설정된 조건을 만족하는지 여부를 판단하는 조건 판단부;상기 미완성 문장이 상기 기설정된 조건을 만족하지 않는 경우, 조건 인코더를 통해 생성된 특징 벡터(featurevector)에 기초하여 최종 문장을 생성하는 최종 문장 생성부; 및상기 최종 문장을 출력하는 문장 출력부를 포함하는 것인, 문장 생성 장치."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,조건 인코더 학습부를 더 포함하고,상기 조건 인코더 학습부는,상기 미완성 문장에 대해 상기 기설정된 조건의 만족 여부를 나타내는 판단 정보와 상기 기설정된 조건의 만족여부를 판단하게 된 근거를 나타내는 근거 정보를 포함하는 조건 학습 데이터를 생성하고,상기 조건 학습 데이터에 기초하여 상기 조건 인코더를 학습시키는 것인, 문장 생성 장치."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 조건 인코더 학습부는 상기 미완성 문장이 상기 기설정된 조건을 만족하지 않는 경우, 상기 최종 문장에서상기 근거 정보에 포함된 특정 토큰(token)을 제외하도록 상기 조건 인코더를 학습시키는 것인, 문장 생성장치."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 조건 인코더 학습부는 상기 기설정된 조건을 이용하여 단일의 학습 데이터를 변형하여 상기 기설정된 조건의 수의 상기 조건 학습 데이터를 생성하는 것인, 문장 생성 장치."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 조건 인코더 학습부는 상기 미완성 문장이 상기 기설정된 조건을 만족하는 경우, 상기 특징 벡터의 값을 0으로 출력하도록 상기 조건 인코더를 학습시키는 것인, 문장 생성 장치.공개특허 10-2024-0020519-3-청구항 6 제1항에 있어서,상기 최종 문장 생성부는 상기 특징 벡터를 기초로 디코딩을 수행하여, 상기 최종 문장을 생성하는 것인, 문장생성 장치."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 소스 문장은 제1 형식을 갖는 문장이고, 상기 미완성 문장 및 상기 최종 문장은 상기 제1 형식과 다른 제2형식을 갖는 문장인 것인, 문장 생성 장치."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 트랜스포머 기반 언어모델은,상기 소스 문장의 입력 토큰으로부터 인코딩 벡터를 생성하는 상기 입력 인코더;상기 인코딩 벡터를 이용하여 출력 토큰을 출력하여 문장을 생성하는 상기 디코더; 및상기 기설정된 조건 각각의 만족 여부를 나타내는 판단 정보와 근거 정보로부터 상기 특징 벡터를 생성하는 복수의 조건 인코더를 포함하는 것인, 문장 생성 장치."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 디코더는 학습 데이터에 기초하여 미리 학습된 방식으로 문장이 생성되도록 하는 기본 목적 함수; 및생성된 문장이 상기 기설정된 조건을 만족하는 경우의 근거 정보와 유사하도록 하는 조건 목적 함수를 포함하는것인, 문장 생성 장치."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "트랜스포머(Transformer) 기반 언어모델을 이용하여 문장을 생성하는 방법에 있어서,소스 문장을 수신하는 단계;미리 학습된 입력 인코더 및 디코더를 이용하여 상기 소스 문장으로부터 미완성 문장을 생성하는 단계;상기 미완성 문장이 기설정된 조건을 만족하는지 여부를 판단하는 단계;상기 미완성 문장이 상기 기설정된 조건을 만족하지 않는 경우, 조건 인코더를 통해 생성된 벡터 정보에 기초하여 최종 문장을 생성하는 단계; 및상기 최종 문장을 출력하는 단계를 포함하는, 문장 생성 방법."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,공개특허 10-2024-0020519-4-상기 조건 인코더를 학습시키는 단계를 더 포함하고,상기 조건 인코더를 학습시키는 단계는,상기 미완성 문장에 대해 상기 기설정된 조건의 만족 여부를 나타내는 판단 정보와 상기 기설정된 조건의 만족여부를 판단하게 된 근거를 나타내는 근거 정보를 포함하는 조건 학습 데이터를 생성하는 단계; 및상기 조건 학습 데이터에 기초하여 상기 조건 인코더를 학습시키는 단계를 포함하는, 문장 생성 방법."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 조건 인코더를 학습시키는 단계는,상기 미완성 문장이 상기 기설정된 조건을 만족하지 않는 경우, 상기 최종 문장에서 상기 근거 정보에 포함된특정 토큰을 제외하도록 상기 조건 인코더를 학습시키는 단계를 포함하는, 문장 생성 방법."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 조건 학습 데이터를 생성하는 단계는,상기 기설정된 조건을 이용하여 단일의 학습 데이터를 변형하여 상기 기설정된 조건의 수의 상기 조건 학습 데이터를 생성하는 단계를 포함하는, 문장 생성 방법."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 조건 인코더를 학습시키는 단계는,상기 미완성 문장이 상기 기설정된 조건을 만족하는 경우, 벡터의 값을 0으로 출력하도록 상기 조건 인코더를학습시키는 단계를 더 포함하는, 문장 생성 방법."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 최종 문장을 생성하는 단계는,상기 벡터 정보를 기초로 디코딩을 수행하여, 상기 최종 문장을 생성하는 단계를 포함하는, 문장 생성 방법."}
{"patent_id": "10-2022-0098669", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "트랜스포머(Transformer) 기반 언어모델을 이용하여 문장을 생성하는 명령어들의 시퀀스를 포함하는 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램에 있어서,상기 컴퓨터 프로그램은 컴퓨팅 장치에 의해 실행될 경우,소스 문장을 수신하고,미리 학습된 입력 인코더 및 디코더를 이용하여 상기 소스 문장으로부터 미완성 문장을 생성하고,상기 미완성 문장이 기설정된 조건을 만족하는지 여부를 판단하고,공개특허 10-2024-0020519-5-상기 미완성 문장이 상기 기설정된 조건을 만족하지 않는 경우, 조건 인코더를 통해 생성된 벡터 정보에 기초하여 최종 문장을 생성하고,상기 최종 문장을 출력하는 명령어들의 시퀀스를 포함하는, 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0098669", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "트랜스포머(Transformer) 기반 언어모델을 이용하여 문장을 생성하는 문장 생성 장치에 있어서, 소스 문장을 수 신하는 소스 문장 수신부, 미리 학습된 입력 인코더 및 디코더를 이용하여 상기 소스 문장으로부터 미완성 문장 을 생성하는 미완성 문장 생성부, 상기 미완성 문장이 기설정된 조건을 만족하는지 여부를 판단하는 조건 판단부, 상기 미완성 문장이 상기 기설정된 조건을 만족하지 않는 경우, 조건 인코더를 통해 생성된 특징 벡터 (feature vector)에 기초하여 최종 문장을 생성하는 최종 문장 생성부 및 상기 최종 문장을 출력하는 문장 출력 부를 포함한다."}
{"patent_id": "10-2022-0098669", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 트랜스포머 기반 언어모델을 이용하여 문장을 생성하는 장치, 방법 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2022-0098669", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템으로서, 기계가 스스로 학습하고 판단하며, 사용 할수록 인식률이 향상되는 시스템을 말한다. 이와 같은 인공지능 시스템은 입력 데이터의 특징을 스스로 분류하고 학습하는 알고리즘을 이용한 기계 학습 기 술과, 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지 및 판단과 같은 기능을 모사하는 요소 기술들로 구성될 수 있다. 일례로, 요소 기술은 인간의 언어 또는 문자를 인식하는 언어적 이해 기술을 포함할 수 있다. 언어적 이해 기술은 일상 생활에서 사용하는 인간의 언어나 문자를 인식하고, 그것을 응용하고 처리하는 기술로 서, 자연어 처리, 기계 번역, 대화 시스템, 질의 응답, 음성 인식, 음성 합성 등을 포함할 수 있다. 최근에는 이러한 언어적 이해 기술을 구현하기 위한 다양한 언어모델(language model) 학습 방법이 제안되고 있 다. 언어모델은 자연어로 이루어진 문서를 분류하거나, 자연어에 담긴 화자의 감정을 분석하거나, 또는 기계 독 해를 수행하는 등 다양한 분야에서 폭넓게 응용되고 있다. 트랜스포머(transformer) 기반의 언어모델은 문장 생성을 위한 최초 단어(또는 토큰, token)를 생성한 이후에 발생 확률이 높은 다음 단어를 순차적으로 탐색하여 추출하고, 동일한 과정을 반복하여 최종 문장을 생성한다. 이러한 확률 기반의 문장 생성 방법은 문장 생성 과정을 반복한 이후에 다수의 문장 중에서 사용자가 정의한 조 건을 만족하는 문장을 선택하여 결정하는 방법이다. 즉, 종래의 확률 기반 문장 생성 방법에 의하면, 주어진 조건을 만족하는 문장이 생성될 때까지 문장 생성 과정 을 반복하기 때문에, 과도한 연산 비용(cost)이 소모된다는 문제가 존재하였다. 즉, 종래에는 언어모델을 통해 생성된 문장을 추론하고 탐색하는 과정에서 막대한 비용이 요구되는 문제가 있었다."}
{"patent_id": "10-2022-0098669", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 문제점을 해결하기 위한 것으로, 최종 문장을 획득하는 과정에서 발생하는 연산 처리 비용을 최소화하고, 연산을 보다 효율적으로 수행하는 문장 생성 장치 및 방법을 제공하고자 한다. 또한, 트랜스포머(transformer) 기반의 언어모델을 이용하여 주어진 조건을 만족하는 문장만을 생성하도록 함으 로써, 문장을 무작위로 생성하는 시간과 비용을 절감할 수 있는 동시에 최종적으로 생성된 문장에 대한 신뢰도 를 향상시킬 수 있는 문장 생성 장치 및 방법을 제공하고자 한다. 또한, 조건을 만족하지 않는 문장에 대해 최종 문장으로의 부적합한 이유와 부분을 별도로 표기하고, 이를 학습 데이터로 활용함으로써, 해당 분야에 있어서 빅데이터를 확보하는 문장 생성 장치 및 방법을 제공하고자 한다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2022-0098669", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 수단으로서, 본 발명의 일 실시예는, 트랜스포머(Transformer) 기반 언어 모델을 이용하여 문장을 생성하는 문장 생성 장치에 있어서, 소스 문장을 수신하는 소스 문장 수신부, 미리 학 습된 입력 인코더 및 디코더를 이용하여 상기 소스 문장으로부터 미완성 문장을 생성하는 미완성 문장 생성부, 상기 미완성 문장이 기설정된 조건을 만족하는지 여부를 판단하는 조건 판단부, 상기 미완성 문장이 상기 기설 정된 조건을 만족하지 않는 경우, 조건 인코더를 통해 생성된 특징 벡터(feature vector)에 기초하여 최종 문장 을 생성하는 최종 문장 생성부 및 상기 최종 문장을 출력하는 문장 출력부를 포함한다. 일 실시예에서, 조건 인코더 학습부를 더 포함하고, 상기 조건 인코더 학습부는 상기 미완성 문장에 대해 상기 기설정된 조건의 만족 여부를 나타내는 판단 정보와 상기 기설정된 조건의 만족 여부를 판단하게 된 근거를 나 타내는 근거 정보를 포함하는 조건 학습 데이터를 생성하고, 상기 조건 학습 데이터에 기초하여 상기 조건 인코 더를 학습시키는 것을 포함한다. 일 실시 예에서, 상기 조건 인코더 학습부는 상기 미완성 문장이 상기 기설정된 조건을 만족하지 않는 경우, 상 기 최종 문장에서 상기 근거 정보에 포함된 특정 토큰(token)을 제외하도록 상기 조건 인코더를 학습시키는 것 을 포함한다. 일 실시 예에서, 상기 조건 인코더 학습부는 상기 기설정된 조건을 이용하여 단일의 학습 데이터를 변형하여 상 기 기설정된 조건의 수의 상기 조건 학습 데이터를 생성하는 것을 포함한다. 일 실시 예에서, 상기 조건 인코더 학습부는 상기 미완성 문장이 상기 기설정된 조건을 만족하는 경우, 상기 특 징 벡터의 값을 0으로 출력하도록 상기 조건 인코더를 학습시키는 것을 포함한다. 일 실시 예에서, 상기 최종 문장 생성부는 상기 특징 벡터를 기초로 디코딩을 수행하여, 상기 최종 문장을 생성 하는 것을 포함한다. 일 실시 예에서, 상기 소스 문장은 제1 형식을 갖는 문장이고, 상기 미완성 문장 및 상기 최종 문장은 상기 제1 형식과 다른 제2 형식을 갖는 문장인 것을 포함한다. 일 실시 예에서, 상기 트랜스포머 기반 언어모델은 상기 소스 문장의 입력 토큰으로부터 인코딩 벡터를 생성하 는 상기 입력 인코더, 상기 인코딩 벡터를 이용하여 출력 토큰을 출력하여 문장을 생성하는 상기 디코더 및 상 기 기설정된 조건 각각의 만족 여부를 나타내는 판단 정보와 근거 정보로부터 상기 특징 벡터를 생성하는 복수 의 조건 인코더를 포함한다. 일 실시 예에서, 상기 디코더는 학습 데이터에 기초하여 미리 학습된 방식으로 문장이 생성되도록 하는 기본 목 적 함수 및 생성된 문장이 상기 기설정된 조건을 만족하는 경우의 근거 정보와 유사하도록 하는 조건 목적 함수 를 포함한다. 본 발명의 다른 실시 예에서, 트랜스포머(Transformer) 기반 언어모델을 이용하여 문장을 생성하는 방법에 있어 서, 소스 문장을 수신하는 단계, 미리 학습된 입력 인코더 및 디코더를 이용하여 상기 소스 문장으로부터 미완 성 문장을 생성하는 단계, 상기 미완성 문장이 기설정된 조건을 만족하는지 여부를 판단하는 단계, 상기 미완성 문장이 상기 기설정된 조건을 만족하지 않는 경우, 조건 인코더를 통해 생성된 벡터 정보에 기초하여 최종 문장 을 생성하는 단계 및 상기 최종 문장을 출력하는 단계를 포함한다. 본 발명의 또 다른 실시 예에서, 트랜스포머(Transformer) 기반 언어모델을 이용하여 문장을 생성하는 명령어들 의 시퀀스를 포함하는 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램은 컴퓨팅 장치에 의해 실행될 경우, 소스 문장을 수신하고, 미리 학습된 입력 인코더 및 디코더를 이용하여 상기 소스 문장으로부터 미완성 문장을 생성하고, 상기 미완성 문장이 기설정된 조건을 만족하는지 여부를 판단하고, 상기 미완성 문장이 상기 기설정된 조건을 만족하지 않는 경우, 조건 인코더를 통해 생성된 벡터 정보에 기초하 여 최종 문장을 생성하고, 상기 최종 문장을 출력하는 명령어들의 시퀀스를 포함한다."}
{"patent_id": "10-2022-0098669", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 최종 문장을 획득하는 과정에서 발생하는 연산 처리 비용을 최소화하고, 연산을 보다 효율적으로 수행하는 문장 생성 장치 및 방법을 제공할 수 있다. 또한, 트랜스포머(transformer) 기반의 언어모델을 이용하여 사전에 정의한 조건을 만족하는 문장만을 생성하도 록 함으로써, 문장을 무작위로 생성하는 시간과 비용을 절감할 수 있는 동시에 최종적으로 생성된 문장에 대한 신뢰도를 향상시킬 수 있는 문장 생성 장치 및 방법을 제공할 수 있다. 또한, 조건을 만족하지 않는 문장에 대해 최종 문장으로의 부적합한 이유와 부분을 별도로 표기하고, 이를 학습 데이터로 활용함으로써, 해당 분야에서 빅데이터를 확보하는 문장 생성 장치 및 방법을 제공할 수 있다."}
{"patent_id": "10-2022-0098669", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미하며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 본 명세서에 있어서 단말 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말 또는 디 바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기술된 동작이나 기능 중 일부도 해당 서버와 연결된 단말 또는 디바이스에서 수행될 수도 있다. 구체적인 설명에 앞서, 본 발명에서 트랜스포머(transformer)는 RNN(Recurrent Neural Network)을 사용하지 않 고, 기존의 시퀀스 투 시퀀스(sequence to sequence) 모델 구조와 같이 인코더(encoder)에서 입력 시퀀스를 입 력받고, 디코더(decoder)에서 출력 시퀀스를 출력하는 인코더-디코더 구조를 가진 모델일 수 있다. 예를 들어, 본 발명에서 트랜스포머 기반의 언어모델은 RNN을 사용하지 않고, 어텐션(attention)만으로 언어를 임베딩(embedding)하는 언어모델을 의미할 수 있다. 트랜스포머 모델에 관해서는 2017년에 발표된 논문 \"Attention is all you need\"에 설명되어 있으므로, 보다 상세한 설명은 생략한다. 본 발명에서는 상술한 트랜스포머 기반의 언어모델을 이용하여 주어진 조건을 만족하는 문장만을 생성하도록 함 으로써, 문장 생성 과정의 반복에 의해 발생하는 시간과 비용을 절감할 수 있는 문장 생성 장치 및 방법을 제공 하고자 한다. 도 1은 본 발명의 일 실시 예에 따른 트랜스포머 기반의 언어모델을 설명하기 위한 개략도를 도시한 도면이다. 도 1에 도시되는 바와 같이, 트랜스포머 기반의 언어모델을 이용하는 문장 생성 장치는 소스 문장으로부터 사전에 정의한 조건을 만족하는 최종 문장을 생성하여 출력할 수 있다.이를 구현하기 위해, 문장 생성 장치는 입력 정보로서 소스 문장을 입력받고, 출력 정보로서 소스 문장에 대응하는 최종 문장을 출력하는 방식으로 학습된 기계 학습 모델일 수 있다. 여기서, 문장 생성 장치는 기 계 학습을 위해 문장 쌍으로 이루어진 학습 데이터를 활용할 수 있다."}
{"patent_id": "10-2022-0098669", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "학습 데이터는 예를 들어, 소스 문장으로서 신문 기사 원문과 최종 문장으로서 신문 기사 요약문을 포함하는 문 장 쌍, 소스 문장으로서 사투리 표현과 최종 문장으로서 표준어 표현을 포함하는 문장 쌍 소스 문장으로서 질문 과 최종 문장으로서 답변을 포함하는 문장 쌍을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시 예에 따라, 문장 생성 장치는 주어진 조건을 만족하는 최종 문장만을 출력하도록 추가적인 기계 학습을 수행할 수 있다. 조건은 예를 들어, 문장의 최소 길이, 문장에서 포함되어야 하는 특정 토큰, 문장에서 포함되어야 하는 특정 토큰의 순서, 문장에서 제외되어야 하는 특정 토큰, 문장에서 제외되어야 하는 토큰들의 조합, 문장에서 제외되어야 하는 토큰의 집합 등을 포함할 수 있다. 여기서, 토큰(token, 또는 단어)이라 함은 띄어쓰기, 각각의 글자, 형태소 및 특정한 기준으로 묶인 글자를 의미할 수 있다. 문장 생성 장치는 학습 데이터를 기초로 조건을 만족하는지 여부를 나타내는 조건 학습 데이터를 활용하여 추가적인 기계 학습을 수행할 수 있다. 조건 학습 데이터는 예를 들어, 학습 데이터가 주어진 조건 각각을 만족하는지 여부를 나타내는 추가적인 학습 데이터를 의미할 수 있다. 이하에서는, 학습 데이터와 조건 학습 데이터를 기초로 소스 문장으로부터 최종 문장을 생성하고, 출력하는 트 랜스포머 기반의 언어모델을 이용하는 문장 생성 장치의 개략적인 구성에 대해 보다 상술하기로 한다. 도 1을 참조하면, 트랜스포머 기반의 언어모델을 이용하는 문장 생성 장치는 입력 인코더, 디코더 및 조건 인코더를 포함할 수 있다. 입력 인코더는 소스 문장의 입력 토큰으로부터 인코딩 벡터를 생성할 수 있다. 구체적으로, 입력 인코더는 트랜 스포머 기반의 언어모델로 입력되는 소스 문장 내의 입력 토큰 각각에 대해 인코딩(encoding)을 수행하여 입력 토큰 각각에 대한 N1 차원의 인코딩 벡터를 생성할 수 있다. 인코딩 벡터는 N1 개의 실수 값을 가지는 벡터일 수 있다. 즉, 입력 인코더는 인코딩을 통해 하나의 단어를 N1 차원의 실수 벡터로 표현되는 인코딩 벡터로 변환 할 수 있다. 일 실시 예에 따라, 입력 인코더는 소스 문장에서 유사한 의미를 갖는 문장은 유사한 벡터 값을 갖도록 임베딩 (embedding)할 수 있다. 임베딩은 단어를 N1 차원의 임베딩 데이터로 변환할 수 있다. 임베딩 데이터는 N1 개의 실수 값을 가지는 벡터일 수 있다. 즉, 임베딩을 통해 하나의 단어를 N1 차원의 실수 벡터로 표현되는 임베딩 데이터로 변환할 수 있다. 디코더는 출력 토큰을 출력하여 문장을 생성할 수 있다. 예를 들어, 디코더는 인코딩 벡터와, 후술하는 조건 인 코더의 특징 벡터와, 직전 토큰까지의 디코딩 결과를 이용해 디코딩(decoding)을 수행하여 문장을 생성할 수 있 다. 일 실시 예에 따라, 디코더는 조건을 만족하는지 여부를 판단하기 이전의 미완성 문장을 생성하거나, 또는 조건 을 만족하는지 여부를 판단한 이후의 최종 문장을 생성할 수 있다. 다른 일 실시 예에 따라, 디코더는 학습 데이터에 기초하여 미리 학습된 방식으로 문장이 생성되도록 하는 기본 목적 함수를 포함할 수 있다. 기본 목적 함수는 주어진 입력 정보에 대응하여 생성된 출력 정보가 원하는 출력 정보(정답 정보)에 얼마나 근접하였는지를 평가하고, 생성된 출력 정보와 정답 정보 사이의 오차가 최소가 되도 록 설정되는 매개변수를 포함한 함수일 수 있다. 즉, 디코더는 학습 데이터와 정답 정보를 이용하여 정답 정보 에 근접하도록 기계 학습을 수행할 수 있다. 또 다른 일 실시 예에 따라, 디코더는 생성된 출력 정보가 주어진 조건을 만족하는 경우의 근거 정보와 유사하 도록 하는 조건 목적 함수를 더 포함할 수 있다. 예를 들어, 조건 목적 함수는 조건 인코더에 의해 미세 조정 학습(fine-tuning)이 이루어지도록 설정되는 매개변수를 포함한 함수일 수 있다. 즉, 디코더는 출력 정보가 주 어진 조건을 만족하지 않는 경우, 조건 인코더를 이용해 추가적인 기계 학습을 수행할 수 있다. 즉, 디코더는 조건 인코더에 의한 추가적인 기계 학습을 수행함으로써, 조건을 만족하는 문장의 생성 확률을 높일 수 있게 된 다. 일 실시 예에 따라, 조건 목적 함수는 출력 정보가 주어진 조건을 만족하는 경우, 출력 정보와 근거 정보가 동 일하면 손실이 작고, 출력 정보와 근거 정보가 다르면 손실이 큰 매개변수일 수 있다. 반대로, 출력 정보가 주 어진 조건을 만족하지 않는 경우에는, 출력 정보와 근거 정보가 동일하면 손실이 크고, 출력 정보와 근거 정보 가 다르면 손실이 작은 매개변수일 수 있다. 조건 인코더는 조건 각각에 대해 만족 여부를 나타내는 판단 정보와, 근거 정보로부터 실수 값을 가지는 특징 벡터를 생성할 수 있다. 일 실시 예에 따라, 조건 인코더는 주어진 문장이 조건을 만족하는지 여부를 나타내는 판단 정보와, 조건을 만 족하거나 만족하지 않는 근거가 되는 근거 정보를 입력받아 벡터 공간으로 변환할 수 있다. 일 실시 예에 따라, 조건 인코더는 디코더로부터 생성된 문장이 주어진 조건을 만족하면 특징 벡터의 값을 0에 가까운 값 또는 0으로 출력하여 디코더의 문장 생성에 영향을 주지 않을 수 있다. 반대로, 문장이 주어진 조건 을 만족하지 않으면 근거 정보 내에 포함된 특정 토큰을 제외하도록 하는 특징 벡터의 값을 생성할 수 있다. 즉, 디코더는 조건 인코더를 통해 출력되는 특징 벡터를 기초로 디코딩을 수행함으로써, 사전에 정의한 조건을 모두 만족하는 최종 문장만을 생성할 수 있다. 한편, 도 1에서는 설명의 편의를 위해 조건 인코더가 한 개의 조건 인코더인 것으로 도시하였지만, 복수 개의 조건 인코더를 포함할 수 있다. 이와 관련해서는 이하의 도 6에서 보다 상술하기로 한다. 도 2는 본 발명의 일 실시 예에 따른 트랜스포머 기반의 언어모델을 이용하여 조건을 만족하는 문장을 생성하는 장치의 구성도를 도시한 도면이고, 도 3은 본 발명의 일 실시 예에 따른 트랜스포머 기반의 언어모델을 이용한 문장 생성 장치를 통해 조건을 만족하는 최종 문장을 생성하고, 출력하는 방법의 순서도를 도시한 도면이다. 도 2 및 도 3을 참조하면, 트랜스포머 기반 언어모델을 이용하여 문장을 생성하는 문장 생성 장치는 소스 문장 수신부, 미완성 문장 생성부, 조건 판단부, 최종 문장 생성부, 조건 인코더 학습부 및 문장 출력부를 포함할 수 있다. 다만, 도 2에 도시된 문장 생성 장치는 본 발명의 하나의 구현 예에 불과하며, 도 2에 도시된 구성요소들을 기초로 하여 여러 가지 변형이 가능하다. 소스 문장 수신부는 소스 문장을 수신할 수 있다(S310). 소스 문장 수신부는 사용자로부터의 소스 문 장을 입력받는 기능을 수행할 수 있다. 예를 들어, 소스 문장 수신부는 사용자 단말(미도시)로부터 사용자 로부터의 소스 문장을 수신할 수 있다. 이와 달리, 소스 문장 수신부는 예를 들어, 키보드, 마우스, 터치 센서, 마이크와 같은 물리적인 입력 장치를 이용하여 사용자의 소스 문장을 직접 입력받을 수도 있다. 여기서, 입력받는 소스 문장은 하나 또는 복수 개의 단어(또는 토큰, token)를 포함할 수 있다. 미완성 문장 생성부는 미리 학습된 입력 인코더와 디코더를 이용하여 소스 문장으로부터 미완성 문장을 생 성할 수 있다(S320). 예를 들어, 미완성 문장 생성부는 입력 정보로서 소스 문장을 입력받고, 출력 정보로 서 소스 문장에 대응하는 미완성 문장을 출력하는 방식의 기계 학습을 이용하여 미완성 문장을 생성할 수 있다. 미완성 문장은 일부 단어들이 부분적으로 생성되어 나열된 형태의 문장일 수 있다. 일 실시 예에 따라, 미완성 문장 생성부에서 수행되는 기계 학습은 문장 쌍으로 이루어진 학습 데이터를"}
{"patent_id": "10-2022-0098669", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "활용할 수 있다. 학습 데이터는 예를 들어, 소스 문장으로서 신문 기사 원문과 최종 문장으로서 신문 기사 요약 문을 포함하는 문장 쌍, 소스 문장으로서 사투리 표현과 최종 문장으로서 표준어 표현을 포함하는 문장 쌍 소스 문장으로서 질문과 최종 문장으로서 답변을 포함하는 문장 쌍을 포함할 수 있다. 조건 판단부는 미완성 문장에 대해 사전에 정의한 조건을 만족하는지 여부를 판단할 수 있다(S330). 조건 은 문장의 최소 길이, 문장에서 포함되어야 하는 특정 토큰, 문장에서 포함되어야 하는 특정 토큰의 순서, 문장 에서 제외되어야 하는 특정 토큰, 문장에서 제외되어야 하는 토큰들의 조합, 문장에서 제외되어야 하는 토큰의 집합 등을 포함할 수 있다. 예를 들어, 문장 내에 '취소'라는 특정 토큰이 포함되는 것이 금지라는 조건으로 주어졌을 때, 조건 판단부 는 '취소 가능합니다'라는 미완성 문장에 대해 조건을 만족하지 않는다고 판단할 수 있다. 최종 문장 생성부는 미완성 문장이 조건을 만족하지 않는 경우, 조건 인코더를 통해 생성된 벡터 정보에 기초하여 최종 문장을 생성할 수 있다(S340). 벡터 정보는 최종 문장에서 조건을 만족하지 않는 근거가 되는 특 정 토큰을 제외하도록 하는 벡터 정보를 포함할 수 있다. 즉, 최종 문장 생성부는 조건 인코더를 통해 생 성된 벡터 정보를 기초로 디코딩을 수행하여 주어진 조건을 만족하는 최종 문장을 생성할 수 있다.조건 인코더 학습부는 미완성 문장에 대해 주어진 조건을 만족하는지 여부를 나타내는 판단 정보와, 주어 진 조건의 만족 여부를 판단하게 된 근거를 나타내는 근거 정보를 포함하는 조건 학습 데이터를 생성하고, 생성 된 조건 학습 데이터에 기초하여 조건 인코더를 학습시킬 수 있다. 조건 학습 데이터는 조건을 기초로 단일의 학습 데이터를 변형하여 생성된 추가적인 학습 데이터일 수 있다. 판 단 정보는 미완성 문장이 주어진 조건을 만족하거나 만족하지 않음을 명시적으로 나타낸 정보이고, 근거 정보는 미완성 문장이 주어진 조건을 만족하지 않는 것으로 판단하게 된 근거를 나타내는 정보일 수 있다. 여기서, 근 거는 출력 문장에서 조건을 위배하는 부분(토큰)의 위치 정보일 수 있다. 일 실시 예에 따라, 조건 인코더 학습부는 조건 학습 데이터에서 주어진 조건의 만족 또는 만족하지 않음 을 나타내는 특수한 토큰(special token)을 지정하여 판단 정보를 표시하고, 조건을 만족하지 않는 것으로 판단 하게 된 근거에 대해 태깅 토큰(tagging token)으로 지정하여 근거 정보를 표시할 수 있다. 다른 일 실시 예에 따라, 조건 인코더 학습부는 미완성 문장이 조건을 만족하지 않는 경우, 조건을 만족하 지 않는 근거가 되는 특정 토큰을 최종 문장에서 제외하도록 조건 인코더를 학습시킬 수 있다. 즉, 조건 인코더 는 미완성 문장이 조건을 만족하지 않는 경우, 최종 문장에서 특정 토큰을 제외하도록 하는 특징 벡터를 생성할 수 있다. 또 다른 일 실시 예에 따라, 조건 인코더 학습부는 미완성 문장이 조건을 만족하는 경우, 특징 벡터의 값 을 0으로 출력하도록 조건 인코더를 학습시킬 수 있다. 즉, 조건 인코더는 미완성 문장이 주어진 조건을 만족하 는 경우, 디코더의 문장 생성에 영향을 주지 않도록 특징 벡터의 값을 0에 가깝게 또는 0으로 생성할 수 있다. 문장 출력부는 생성된 최종 문장을 출력할 수 있다(S350). 문장 출력부는 주어진 조건을 만족하는 최 종 문장을 출력하는 기능을 수행할 수 있다. 예를 들어, 문장 출력부는 사용자 단말로 최종 문장을 전송하 여 사용자 단말을 통해 최종 문장이 출력되도록 할 수 있다. 이와 달리, 문장 출력부는 모니터, 터치 스크 린, 스피커와 같은 물리적 디스플레이 장치를 통해 최종 문장을 직접 출력할 수도 있다. 이하에서는, 문장 생성 장치를 이용하여 최종 문장을 생성하는 과정에 대해 보다 상술하기로 한다. 도 4는 본 발명의 일 실시 예에 따라, 사전에 정의한 조건을 만족하는 최종 문장을 생성하는 동작을 설명하기 위한 예시적인 도면이다. 도 4를 참조하면, 소스 문장으로서 신문 기사 원문이 문장 생성 장치에 입력된 실시 예가 도시된다. 미완 성 문장 생성부는 미리 학습된 입력 인코더와 디코더를 이용하여 신문 기사 원문으로부터 '증시가 급락하 고 환율', '증시가 급락하고 ＄'라는 미완성 문장을 생성할 수 있다. 조건 판단부는 미완성 문장에 대해 주어진 조건을 만족하는지 여부를 판단할 수 있다. 예를 들어, 문장 내 에 특수 문자가 포함되지 않는 것이 조건으로서 설정되면, '증시가 급락하고 환율'이라는 문장에 대해서는 조건 을 만족하는 미완성 문장으로 판단하고, '증시가 급락하고 ＄'라는 문장에 대해서는 조건을 만족하지 않는 미완 성 문장으로 판단할 수 있다. 최종 문장 생성부는 미완성 문장이 조건을 만족하지 않는 경우, 최종 문장으로 진행되는 것을 방지할 수 있다. 앞의 예시에서, '증시가 급락하고 환율'이라는 미완성 문장은 조건을 만족하므로 이어서 최종 문장으로 완성되는 반면에 '증시가 급락하고 ＄'라는 미완성 문장은 조건을 만족하지 않으므로 이어서 최종 문장으로 완 성되지 않는다. 즉, 트랜스포머 기반의 언어모델을 이용하는 문장 생성 장치는 입력 정보로서 소스 문장을 입력받고, 출력 정보로서 주어진 조건을 만족하는 최종 문장만을 출력하도록 함으로써, 무작위로 문장을 생성하고, 선택하는 시 간과 비용을 절감할 수 있는 효과가 있다. 예를 들어, 빔 탐색(Beam Search) 등 문장 생성 시 다음 토큰에 대한 후보 탐색 시간을 줄일 수 있다. 도 5는 본 발명의 일 실시 예에 따른 트랜스포머 기반의 언어모델을 이용한 문장 생성 장치에서 조건 인코더를 학습시키는 방법의 순서도를 도시한 도면이고, 도 6은 본 발명의 일 실시 예에 따라, 조건 학습 데이터를 생성 하고, 생성된 조건 학습 데이터를 이용해 조건 인코더를 학습시키는 동작을 설명하기 위한 예시적인 도면이다. 먼저, 도 5를 참조하면, 조건 인코더 학습부는 주어진 문장에 대해 조건의 만족 여부를 나타내는 판단 정 보와, 조건의 만족 여부를 판단하게 된 근거를 나타내는 근거 정보를 포함하는 조건 학습 데이터를 생성할 수 있다(S510). 판단 정보는 주어진 문장이 조건을 만족하거나 만족하지 않음을 명시적으로 나타내는 정보를 의미하고, 근거 정보는 주어진 문장이 조건을 만족하지 않는 것으로 판단하게 된 근거를 나타내는 정보를 의미할 수 있다. 일 실시 예에 따라, 조건 인코더 학습부는 조건 학습 데이터에서 주어진 조건의 만족 또는 만족하지 않음 을 나타내는 특수한 토큰(special token)을 지정하여 판단 정보를 표시하고, 조건을 만족하지 않는 것으로 판단 하게 된 근거에 대해 태깅 토큰(tagging token)으로 지정하여 근거 정보를 표시할 수 있다. 조건 인코더 학습부는 조건 학습 데이터에 기초하여 조건 인코더를 학습시킬 수 있다(S520). 조건 학습 데 이터는 조건을 기초로 단일의 학습 데이터를 변형하여 생성되는 추가적인 학습 데이터일 수 있다. 일 실시 예에 따라, 조건 인코더 학습부는 학습 데이터가 조건을 만족하는 경우, 특징 벡터의 값이 0으로 출력되도록 조건 인코더를 학습시킬 수 있다. 반대로, 학습 데이터가 조건을 만족하지 않는 경우에는 문장 생성 시 근거 정보 내에 포함된 특정 토큰을 제외하는 특징 벡터를 생성하도록 조건 인코더를 학습시킬 수 있다. 도 6을 참조하면, 문장 내에 특수 문자가 포함되지 않을 것이 조건으로서 설정되면, 조건 판단부는 '증시 가 급락하고 환율'이라는 문장에 대해서는 조건을 만족하는 문장으로 판단하고, '증시가 급락하고 ＄'라는 문장 에 대해서는 조건을 만족하지 않는 문장으로 판단할 수 있다. 조건 인코더 학습부는 조건 판단부의 판단 결과에 기초하여 주어진 문장에 대해 조건을 만족하는지 여부를 나타내는 판단 정보와, 조건의 만족 여부를 판단하게 된 근거를 나타내는 근거 정보를 포함하는 조건 학 습 데이터를 생성할 수 있으며, 생성된 조건 학습 데이터에 기초하여 복수의 조건 인코더를 학습시킬 수 있다. 앞의 예시에서, 조건 인코더 학습부는 '증시가 급락하고 환율'이라는 문장에 대해 조건을 만족한다는 판단 정보와, 특수 문자를 포함하지 않는다는 근거 정보의 조건 학습 데이터를 생성하고, 생성된 판단 정보 와 근거 정보를 기초로 제1 조건 인코더를 학습시킬 수 있다. 또한, 조건 인코더 학습부는 '증시가 급락하고 ＄'라는 문장에 대해 조건을 만족하지 않는다는 판단 정보 와, 특수 문자인 '＄'를 포함한다는 근거 정보의 조건 학습 데이터를 생성하고, 생성된 판단 정보 와 근거 정보를 기초로 제2 조건 인코더를 학습시킬 수 있다. 즉, 조건 인코더 학습부는 주어진 문장에서 조건에 적합하거나 부적합한 이유와 부분을 별도로 표기하고, 이를 추가적인 학습 데이터로 활용하도록 함으로써, 해당 분야에서 빅데이터를 확보할 수 있다."}
{"patent_id": "10-2022-0098669", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2022-0098669", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 소스 문장을 입력받아 최종 문장을 생성 및 출력하는 트랜스포머 (transformer) 기반의 언어모델을 설명하기 위한 개략도를 도시한 도면이다. 도 2는 본 발명의 일 실시 예에 따른 트랜스포머 기반의 언어모델을 이용하여 조건을 만족하는 문장을 생성하는 장치의 구성도를 도시한 도면이다. 도 3은 본 발명의 일 실시 예에 따른 트랜스포머 기반의 언어모델을 이용한 문장 생성 장치를 통해 조건을 만족 하는 최종 문장을 생성하고, 생성된 최종 문장을 출력하는 방법의 순서도를 도시한 도면이다. 도 4는 본 발명의 일 실시 예에 따라, 사전에 정의한 조건을 만족하는 최종 문장을 생성하는 동작을 설명하기 위한 예시적인 도면이다. 도 5는 본 발명의 일 실시 예에 따른 트랜스포머 기반의 언어모델을 이용한 문장 생성 장치에서 조건 인코더를 학습시키는 방법의 순서도를 도시한 도면이다. 도 6은 본 발명의 일 실시 예에 따라, 조건 학습 데이터를 생성하고, 생성된 조건 학습 데이터를 이용해 조건 인코더를 학습시키는 동작을 설명하기 위한 예시적인 도면이다."}
