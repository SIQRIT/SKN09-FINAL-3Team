{"patent_id": "10-2023-0095497", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0014839", "출원번호": "10-2023-0095497", "발명의 명칭": "음성 인식 장치 및 그 방법", "출원인": "현대자동차주식회사", "발명자": "박성수"}}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자의 발화를 추출하는 마이크;상기 발화에서 추출된 의도에 매칭되는 시나리오가 저장된 메모리; 및상기 발화를 바탕으로 상기 시나리오를 검색하여 음성 인식 기능을 수행하는 프로세서;를 포함하고,상기 프로세서는제1 발화에서 제1 의도를 추출하고, 제2 발화에서 제2 의도를 추출하며,미리 설정된 구분자들을 이용하여, 상기 제1 의도 및 상기 제2 의도를 부분 의도 단위로 분리하고,상기 구분자들의 정의에 따라 중복되는 부분 의도들이 삭제되도록 상기 제1 의도 및 상기 제2 의도들 각각의 부분 의도들을 결합하여 최종 의도를 생성하는 것을 특징으로 하는 음성 인식 장치."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 프로세서는상기 제1 발화 이후에 획득된 상기 제2 발화에서 액션 또는 타겟 또는 엔티티 중에서 적어도 어느 하나가 누락된 경우, 상기 제1 발화 및 상기 제2 발화를 바탕으로 상기 최종 의도를 생성하는 것을 특징으로 하는 음성 인식 장치."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 프로세서는상기 제1 의도 및 상기 제2 의도 각각에 포함된 액션, 타겟 및 엔티티들에 상기 구분자들 중에서 어느 하나의구분자를 부여하는 것을 특징으로 하는 음성 인식 장치."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 프로세서는상기 제1 의도에서 추출된 제1 부분 의도들 중에서 상기 액션 또는 상기 타겟을 지시하는 제1 부분 의도에 제1구분자를 부여하고,상기 제2 의도에서 추출된 제2 부분 의도들 중에서 상기 제1 구분자가 부여된 상기 부분 의도와 상반되는 상기액션 또는 상반되는 타겟을 지시하는 제2 부분 의도에 제2 구분자를 부여하는 것을 특징으로 하는 음성 인식 장치."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0014839-3-제 4 항에 있어서,상기 프로세서는상기 제1 구분자가 부여된 상기 제1 부분 의도 및 상기 제2 구분자가 부여된 상기 제2 부분 의도가 동일할경우, 상기 동일한 제1 부분 의도 및 제2 부분 의도를 삭제하여 상기 최종 의도를 생성하는 것을 특징으로 하는음성 인식 장치."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 3 항에 있어서,상기 프로세서는상기 제1 부분 의도들 중에서 엔티티에 제3 구분자를 부여하고,상기 제2 부분 의도들 중에서 상기 제3 구분자가 부여된 상기 엔티티를 부정하는 부분 의도에 제4 구분자를 부여하는 것을 특징으로 하는 음성 인식 장치."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 프로세서는상기 제3 구분자가 부여된 상기 엔티티 및 상기 제4 구분자가 부여된 상기 엔티티가 동일할 경우, 상기 동일한엔티티들을 삭제하여 상기 최종 의도를 생성하는 것을 특징으로 하는 음성 인식 장치."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 프로세서는발화 순서의 역순으로 상기 제1 의도 및 상기 제2 의도를 배열하여 상기 최종 의도를 생성하는 것을 특징으로하는 음성 인식 장치."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 프로세서는상기 부분 의도들 중에서 가장 선행하는 액션 이외의 다른 액션들은 삭제하여 상기 최종 의도를 생성하는 것을특징으로 하는 음성 인식 장치."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 프로세서는상기 부분 의도들 중에서, 삭제된 상기 부분 의도들과 매칭되는 부분 의도들을 삭제하여 상기 최종 의도를 생성하는 것을 특징으로 하는 음성 인식 장치.공개특허 10-2025-0014839-4-청구항 11 제1 발화에서 제1 의도를 추출하고, 제2 발화에서 제2 의도를 추출하는 단계;미리 설정된 구분자들을 이용하여, 상기 제1 의도 및 상기 제2 의도를 부분 의도 단위로 분리하는 단계;상기 구분자들의 정의에 따라 중복되는 부분 의도들이 삭제되도록 상기 제1 의도 및 상기 제2 의도들 각각의 부분 의도들을 결합하여 최종 의도를 생성하는 단계; 및상기 최종 의도에 매칭되는 시나리오를 바탕으로, 음성 인식 기능을 수행하는 단계;를 포함하는 음성 인식 방법."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 제2 발화에서 상기 제2 의도를 추출하는 단계는상기 제1 의도가 추출된 이후에 수행되는 것을 특징으로 하는 음성 인식 방법."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 제1 의도 및 상기 제2 의도를 부분 의도 단위로 분리하는 단계는상기 제1 의도 및 상기 제2 의도 각각에 포함된 액션, 타겟 및 엔티티들에 상기 구분자들 중에서 어느 하나의구분자를 부여하는 단계를 포함하는 것을 특징으로 하는 음성 인식 방법."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 제1 의도 및 상기 제2 의도를 부분 의도 단위로 분리하는 단계는상기 제1 의도에서 추출된 제1 부분 의도들 중에서 상기 액션 또는 상기 타겟을 지시하는 제1 부분 의도에 제1구분자를 부여하는 단계; 및상기 제2 의도에서 추출된 제2 부분 의도들 중에서 상기 제1 구분자가 부여된 상기 부분 의도와 상반되는 상기액션 또는 상반되는 타겟을 지시하는 제2 부분 의도에 제2 구분자를 부여하는 단계;를 포함하는 것을 특징으로하는 음성 인식 방법."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 최종 의도를 생성하는 단계는상기 제1 구분자가 부여된 상기 제1 부분 의도 및 상기 제2 구분자가 부여된 상기 제2 부분 의도가 동일할경우, 상기 동일한 제1 부분 의도 및 제2 부분 의도를 삭제하는 단계를 포함하는 것을 특징으로 하는 음성 인식방법."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "공개특허 10-2025-0014839-5-제 13 항에 있어서,상기 제1 의도 및 상기 제2 의도를 부분 의도 단위로 분리하는 단계는상기 제1 부분 의도들 중에서 엔티티에 제3 구분자를 부여하는 단계; 및상기 제2 부분 의도들 중에서 상기 제3 구분자가 부여된 상기 엔티티를 부정하는 부분 의도에 제4 구분자를 부여하는 단계;를 포함하는 것을 특징으로 하는 음성 인식 방법."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 최종 의도를 생성하는 단계는상기 제3 구분자가 부여된 상기 엔티티 및 상기 제4 구분자가 부여된 상기 엔티티가 동일할 경우, 상기 동일한엔티티들을 삭제하는 단계를 포함하는 것을 특징으로 하는 음성 인식 방법."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 11 항에 있어서,상기 최종 의도를 생성하는 단계는 발화 순서의 역순으로 상기 제1 의도 및 상기 제2 의도를 배열하는 단계를 더 포함하는 것을 특징으로 하는 음성 인식 방법."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서,상기 최종 의도를 생성하는 단계는상기 부분 의도들 중에서 가장 선행하는 액션 이외의 다른 액션들은 삭제하는 단계를 더 포함하는 것을 특징으로 하는 음성 인식 방법."}
{"patent_id": "10-2023-0095497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19 항에 있어서,상기 최종 의도를 생성하는 단계는상기 부분 의도들 중에서, 삭제된 상기 부분 의도들과 매칭되는 부분 의도들을 삭제하는 단계를 더 포함하는 것을 특징으로 하는 음성 인식 방법. 음성 인식 방법."}
{"patent_id": "10-2023-0095497", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 음성 인식 장치 및 그 방법에 관한 것으로, 본 발명의 실시 예에 의한 음성 인식 장치는 사용자의 발 화를 추출하는 마이크, 발화에서 추출된 의도에 매칭되는 시나리오가 저장된 메모리 및 발화를 바탕으로 시나리 오를 검색하여 음성 인식 기능을 수행하는 프로세서를 포함할 수 있다. 프로세서는 제1 발화에서 제1 의도를 추 출하고, 제2 발화에서 제2 의도를 추출하며, 미리 설정된 구분자들을 이용하여 제1 의도 및 제2 의도를 부분 의 도 단위로 분리하고, 구분자들의 정의에 따라 중복되는 부분 의도들이 삭제되도록 제1 의도 및 제2 의도들 각각 의 부분 의도들을 결합하여 최종 의도를 생성할 수 있다."}
{"patent_id": "10-2023-0095497", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성 인식 장치 및 그 방법에 관한 것으로, 보다 상세하게는 사용자 의도를 보다 명확하게 판단할 수 있는 기술에 관한 것이다."}
{"patent_id": "10-2023-0095497", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 인식 장치는 사용자의 발화에 포함된 사용자 의도를 파악하고, 파악된 사용자 의도에 대응되는 서비스를 제공할 수 있는 시스템이다. 음성 인식 장치는 특정 장치와 연계되어 사용자 의도에 따라 해당 장치에 대한 제어를 수행하기도 하고, 사용자 의도에 따라 특정 정보를 제공하기도 한다. 음성 인식 장치는 사용자 입력의 편의성으로 인해서 광범위하게 활용되고 있다. 예를 들어, 자동차 산업의 발전 에 따라 운전자에게 편의성을 제공하기 위해 차량 내에서 음성 인식을 이용하여 사용자의 의도에 부합하는 액션 을 자동적으로 수행하는 시스템의 개발이 지속적으로 이루어지고 있다. 차량뿐만 아니라 스마트폰 및 인공지능 스피커 등과 같은 다양한 장치에서 음성 인식을 활용하는 서비스가 제공된다. 예를 들어, 애플의 시리, 아마존 의 알렉사, KT의 지니(Genie) 및 SK의 누구(NUGU) 등과 같이 다양한 서비스 제공자가 음성 인식 서비스를 제공 하고 있다. 음성 인식 장치는 AI를 활용하여 음성 인식 기능을 높이고 있지만, 사용자의 발화가 함축될 경우 해당 발화에 대응하는 의도를 명확하게 판단하기 어려울 수 있다. 보다 폭넓게 발화를 인식하기 위해서는 최대한 많은 발화에 매칭되는 시나리오를 정의하여야 하는데, 이럴 경우, 경우의 수가 너무 많으며, 메모리 용량이 증가하는 단점이 있다."}
{"patent_id": "10-2023-0095497", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시 예는 사용자 발화를 보다 명확하게 판단할 수 있는 음성 인식 장치 및 그 방법을 제공하기 위한 것이다. 또한, 본 발명의 실시 예는 메모리 용량을 줄이면서도 다양한 사용자 발화를 바탕으로 음성 인식을 수행할 수 있는 음성 인식 장치 및 그 방법을 제공하기 위한 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재들로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0095497", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 의한 음성 인식 장치는 사용자의 발화를 추출하는 마이크, 발화에서 추출된 의도에 매칭되 는 시나리오가 저장된 메모리 및 발화를 바탕으로 시나리오를 검색하여 음성 인식 기능을 수행하는 프로세서를 포함할 수 있다. 프로세서는 제1 발화에서 제1 의도를 추출하고, 제2 발화에서 제2 의도를 추출하며, 미리 설정 된 구분자들을 이용하여 제1 의도 및 제2 의도를 부분 의도 단위로 분리하고, 구분자들의 정의에 따라 중복되는 부분 의도들이 삭제되도록 제1 의도 및 제2 의도들 각각의 부분 의도들을 결합하여 최종 의도를 생성할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 제1 발화 이후에 획득된 상기 제2 발화에서 액션 또는 타겟 또는 엔티 티 중에서 적어도 어느 하나가 누락된 경우, 상기 제1 발화 및 상기 제2 발화를 바탕으로 상기 최종 의도를 생 성할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 제1 의도 및 상기 제2 의도 각각에 포함된 액션, 타겟 및 엔티티들에 상기 구분자들 중에서 어느 하나의 구분자를 부여할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 제1 의도에서 추출된 제1 부분 의도들 중에서 상기 액션 또는 상기 타 겟을 지시하는 제1 부분 의도에 제1 구분자를 부여하고, 상기 제2 의도에서 추출된 제2 부분 의도들 중에서 상 기 제1 구분자가 부여된 상기 부분 의도와 상반되는 상기 액션 또는 상반되는 타겟을 지시하는 제2 부분 의도에 제2 구분자를 부여할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 제1 구분자가 부여된 상기 제1 부분 의도 및 상기 제2 구분자가 부여 된 상기 제2 부분 의도가 동일할 경우, 상기 동일한 제1 부분 의도 및 제2 부분 의도를 삭제하여 상기 최종 의 도를 생성할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 제1 부분 의도들 중에서 엔티티에 제3 구분자를 부여하고, 상기 제2 부분 의도들 중에서 상기 제3 구분자가 부여된 상기 엔티티를 부정하는 부분 의도에 제4 구분자를 부여할 수 있 다. 실시 예에 의하면, 상기 프로세서는 상기 제3 구분자가 부여된 상기 엔티티 및 상기 제4 구분자가 부여된 상기 엔티티가 동일할 경우, 상기 동일한 엔티티들을 삭제하여 상기 최종 의도를 생성할 수 있다.실시 예에 의하면, 상기 프로세서는 발화 순서의 역순으로 상기 제1 의도 및 상기 제2 의도를 배열하여 상기 최 종 의도를 생성할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 부분 의도들 중에서 가장 선행하는 액션 이외의 다른 액션들은 삭제하 여 상기 최종 의도를 생성할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 부분 의도들 중에서, 삭제된 상기 부분 의도들과 매칭되는 부분 의도 들을 삭제하여 상기 최종 의도를 생성할 수 있다. 본 발명의 실시 예에 의한 음성 인식 방법은 제1 발화에서 제1 의도를 추출하고, 제2 발화에서 제2 의도를 추출 하는 단계, 미리 설정된 구분자들을 이용하여, 상기 제1 의도 및 상기 제2 의도를 부분 의도 단위로 분리하는 단계, 상기 구분자들의 정의에 따라 중복되는 부분 의도들이 삭제되도록 상기 제1 의도 및 상기 제2 의도들 각 각의 부분 의도들을 결합하여 최종 의도를 생성하는 단계, 및 상기 최종 의도에 매칭되는 시나리오를 바탕으로, 음성 인식 기능을 수행하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 제2 발화에서 상기 제2 의도를 추출하는 단계는 상기 제1 의도가 추출된 이후에 수행될 수 있다. 실시 예에 의하면, 상기 제1 의도 및 상기 제2 의도를 부분 의도 단위로 분리하는 단계는 상기 제1 의도 및 상 기 제2 의도 각각에 포함된 액션, 타겟 및 엔티티들에 상기 구분자들 중에서 어느 하나의 구분자를 부여하는 단 계를 포함할 수 있다. 실시 예에 의하면, 상기 제1 의도 및 상기 제2 의도를 부분 의도 단위로 분리하는 단계는 상기 제1 의도에서 추 출된 제1 부분 의도들 중에서 상기 액션 또는 상기 타겟을 지시하는 제1 부분 의도에 제1 구분자를 부여하는 단 계 및 상기 제2 의도에서 추출된 제2 부분 의도들 중에서 상기 제1 구분자가 부여된 상기 부분 의도와 상반되는 상기 액션 또는 상반되는 타겟을 지시하는 제2 부분 의도에 제2 구분자를 부여하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 최종 의도를 생성하는 단계는 상기 제1 구분자가 부여된 상기 제1 부분 의도 및 상기 제2 구분자가 부여된 상기 제2 부분 의도가 동일할 경우, 상기 동일한 제1 부분 의도 및 제2 부분 의도를 삭제 하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 제1 의도 및 상기 제2 의도를 부분 의도 단위로 분리하는 단계는 상기 제1 부분 의도들 중에서 엔티티에 제3 구분자를 부여하는 단계 및 상기 제2 부분 의도들 중에서 상기 제3 구분자가 부여된 상기 엔티티를 부정하는 부분 의도에 제4 구분자를 부여하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 최종 의도를 생성하는 단계는 상기 제3 구분자가 부여된 상기 엔티티 및 상기 제4 구분 자가 부여된 상기 엔티티가 동일할 경우, 상기 동일한 엔티티들을 삭제하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 최종 의도를 생성하는 단계는 발화 순서의 역순으로 상기 제1 의도 및 상기 제2 의도를 배열하는 단계를 더 포함할 수 있다. 실시 예에 의하면, 상기 최종 의도를 생성하는 단계는 상기 부분 의도들 중에서 가장 선행하는 액션 이외의 다 른 액션들은 삭제하는 단계를 더 포함할 수 있다. 실시 예에 의하면, 상기 최종 의도를 생성하는 단계는 상기 부분 의도들 중에서, 삭제된 상기 부분 의도들과 매 칭되는 부분 의도들을 삭제하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-0095497", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 의하면, 사용자 발화가 불명확할 경우에도 이전 발화들의 의도를 바탕으로 보다 명확한 의 도를 생성할 수 있다. 또한, 본 발명의 실시 예에 의하면, 사용자 발화에 매칭되는 시나리오의 수를 줄이면서도 다양한 사용자 발화에 대응하여 음성 인식 기능을 수행할 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2023-0095497", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시 예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시 예를 설명함에 있어, 관련된 공지 구성 또는 기능 에 대한 구체적인 설명이 본 발명의 실시 예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생 략한다. 본 발명의 실시 예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있 다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질이나 차례 또는 순서 등이 한정되지 않는다. 또한, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어 를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일 반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의 하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 도 1 내지 도 9를 참조하여, 본 발명의 실시 예들을 구체적으로 설명하기로 한다. 도 1은 본 발명의 실시 예에 의한 음성 인식 장치의 구성을 나타내는 블록도이고, 도 2는 본 발명의 실시 예에 의한 음성 인식 장치가 탑재된 차량의 내부 구성을 나타내는 도면이다. 이하의 실시 예에 의한 음성 인식 장치 는 차량에 탑재된 실시 예를 중심으로 설명되지만, 음성 인식 장치는 음성 인식 기능을 위한 어떠한 시스템에도 적용될 수 있다. 도 1 및 도 2를 참조하면, 본 발명의 실시 예에 의한 음성 인식 장치는 마이크, 프로세서, 및 메모리 를 포함할 수 있다. 마이크는 음성 신호를 수신할 수 있으며, 차량에 탑승한 사용자의 음성을 수신하기에 용이한 위치에 배치 될 수 있다. 예를 들어, 마이크는 룸 미러가 위치한 차량 천장 주위에 배치될 수 있으며, 마이크(11 0)의 위치는 이에 한정되지 않을 수 있다. 프로세서는 마이크가 획득한 사용자 음성을 바탕으로 음성 인식 기능을 수행할 수 있다. 이를 위해서, 프로세서는 제1 발화에서 제1 의도를 추출하고, 제2 발화에서 제2 의도를 추출할 수 있다. 제1 발화 및 제2 발화는 마이크를 통해서 획득된 사용자로부터의 발화일 수 있다. 제2 발화는 제1 발화에 대한 제1 의도가 추출된 이후에 수행될 수 있다. 예를 들어, 제2 발화는 제1 발화에 대한 음성 인식 기능이 수 행된 이후에, 획득된 발화를 지칭하는 것일 수 있다. 프로세서는 미리 설정된 구분자들을 이용하여, 제1 의도 및 제2 의도를 부분 의도 단위로 분리할 수 있다. 부분 의도 단위는 품사 또는 어절일 수 있다. 또한 프로세서는 부분 의도들에 선행하도록 구분자를 배치하 여 제1 의도 및 제2 의도를 분리할 수 있다. 구분자들은 둘 이상을 포함할 수 있고, 각각의 구분자들은 상반되 는 타겟 또는 동작을 구분하는 것일 수 있다. 예를 들어, 라디오에 대한 동작을 지시하는 부분 의도에 제1 구분 자를 부여할 수 있고, 라디오에 대한 동작을 정지시키는 부분 의도에 제2 구분자를 부여할 수 있다. 이에 대한 구체적인 실시 예는 후술하기로 한다. 프로세서는 구분자들의 정의에 따라 중복되는 부분 의도들을 삭제함으로써, 최종 의도를 생성할 수 있다. 중복되는 부분 의도들은 서로 다른 의도에서 각각 추출된 부분 의도들일 수 있다. 예를 들어, 중복되는 한 쌍의 부분 의도들 중에서 어느 하나는 제1 의도에서 추출된 것일 수 있고, 다른 하나는 제2 의도에서 추출된 것일 수 있다. 또한 프로세서는 중복되는 부분 의도들이 각각 상반되는 구분자에 매칭될 경우, 중복되는 부분 의도 들을 모두 삭제할 수 있다. 예를 들어, 제1 구분자가 부여된 네비게이션과 제2 구분자가 부여된 네비게이션이 있을 경우, 최종 의도에서는 네비게이션이 삭제될 수 있다. 프로세서는 최종 의도에 매칭되는 시나리오를 바탕으로, 음성 인식 기능을 수행할 수 있다. 또한, 프로세서는 제2 발화에서 액션 또는 타겟 또는 엔티티 중에서 적어도 어느 하나가 누락된 경우, 제1 발화 및 제2 발화를 바탕으로 최종 의도를 생성할 수 있다. 프로세서는 음성 인식 기능을 수행하기 위해서 마이크가 획득한 발화 데이터를 인공지능 학습할 수 있다. 이를 위해서, 프로세서는 인공지능(artificial intelligence; 이하, AI) 프로세서를 포함할 수 있 다. AI 프로세서는 미리 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 타겟 차량 및 위험 차량을 검 출하기 위한 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며, 인간의 신경망의 뉴런 (neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 모드들은 뉴 런이 시냅스(synapse)를 통해 신호를 주고 받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데이 터를 주고 받을 수 있다. 신경망은 신경망 모델에서 발전한 딥러닝 모델을 포함할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 신경망 모델의 예는 심층 신경망(DNN, deep neural networks), 합성곱 신경망(CNN, convolutional deep neural networks), 순환 신경망(RNN, Recurrent Boltzmann Machine), 제한 볼츠만 머신 (RBM, Restricted Boltzmann Machine), 심층 신뢰 신경망(DBN, deep belief networks), 심층 Q-네트워크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들을 포함할 수 있다. 또한, 프로세서는 통신 인터페이스를 통해서 차량 내부에 탑재된 전장 장치들을 제어할 수 있다. 메모리는 발화를 바탕으로 추출된 의도에 매칭되는 시나리오가 저장된 것일 수 있다. 또한, 메모리는 프로세서의 동작을 위한 알고리즘 및 AI 프로세서를 저장할 수 있다. 메모리는 하드 디스크 드라이브, 플래시 메모리, EEPROM(Electrically erasable programmable read-only memory), SRAM(Static RAM), FRAM (Ferro-electric RAM), PRAM (Phase-change RAM), MRAM(Magnetic RAM), DRAM(Dynamic Random Access Memory), SDRAM(Synchronous Dynamic Random Access Memory), DDR-SDRAM(Double Date Rate-SDRAM) 등 을 이용할 수 있다. 전장 장치는 음성 인식 기반으로 제어될 수 있으며, 대시보드에 탑재되는 AVN 장치를 포함할 수 있다. AVN 장치는 오디오, 또는 내비게이션을 포함할 수 있으며, 음성 인식 이외의 사용자 입력을 제공받으면서 동작 상태를 표시하는 AVN 디스플레이를 포함할 수 있다. 대시보드에서 운전석과 근접한 영역에는 차량의 상태 또는 주행 관련 정보를 표시하는 클러스터 디스플레이 가 배치될 수도 있다. 또한, 차량 내부에는 음성 인식 기능이 수행되는 과정에서 사용자와 대화 형태의 음성을 출력하여, 음성 인식 절차를 보조하기 위한 스피커가 배치될 수도 있다. 도 3은 본 발명의 실시 예에 의한 음성 인식 방법을 설명하기 위한 순서도이다. 도 3에 도시된 절차는 도 1에 도시된 프로세서에 의해서 제어될 수 있다. 도 3을 참조하여, 본 발명의 실시 예에 의한 음성 인식 방법을 살펴보면 다음과 같다. S310에서, 프로세서는 제1 발화에서 제1 의도를 추출하고, 제2 발화에서 제2 의도를 추출할 수 있다. 제2 발화는 제1 발화에 대한 제1 의도가 추출된 이후 획득된 것일 수 있다. S320에서, 프로세서는 미리 설정된 구분자들을 이용하여, 제1 의도 및 제2 의도를 부분 의도 단위로 분리 할 수 있다. 부분 의도 단위는 의도에 포함된 액션, 타겟, 또는 엔티티일 수 있다. 프로세서는 제1 의도 및 제2 의도 각각에 포함된 액션, 타겟 및 엔티티들에 어느 하나의 구분자를 부여하 여, 제1 의도 및 제2 의도를 부분 의도 단위로 분리할 수 있다. 제1 의도 및 제2 의도에서 액션 및 타겟은 제1 구분자 및 제2 구분자로 구분될 수 있다. 제1 의도 및 제2 의도 의 액션 및 타겟에는 제1 구분자가 부여될 수 있다. 또한, 제2 의도의 액션 및 타겟 중에서 제1 의도에서 추출 된 것과 중복되며 부정의 의미를 포함하는 액션 및 타겟에는 제2 구분자가 부여될 수 있다. 제1 의도 및 제2 의도에서 엔티티들은 제3 구분자 및 제4 구분자로 구분될 수 있다. 프로세서는 제1 부분 의도들 중에서 엔티티에 제3 구분자를 부여할 수 있다. 또한, 프로세서는 제2 부분 의도들 중에서 제3 구 분자가 부여된 엔티티를 부정하는 부분 의도에 제4 구분자를 부여할 수 있다. S330에서, 프로세서는 구분자들의 정의에 따라 중복되는 부분 의도들을 삭제하여, 최종 의도를 생성할 수 있다. 프로세서는 중복되는 부분 의도에 서로 상반되는 구분자가 부여된 경우, 중복되는 부분 의도를 제거할 수 있다. 실시 예에 의해서 제1 구분자와 제2 구분자는 서로 상반되며, 제3 구분자와 제4 구분자는 서로 상반될 수 있다. 또한, 프로세서는 발화를 획득한 타이밍의 역순으로 제1 의도 및 제2 의도를 배열하여 최종 의도를 획득할 수 있다. 또한, 프로세서는 최종 의도를 생성하는 과정에서, 부분 의도들 중에서 가장 선행하는 액션 이외의 다른 액션들은 삭제할 수 있다. 또한, 프로세서는 최종 의도를 생성하는 과정에서, 부분 의도들 중에서, 삭제된 상기 부분 의도들과 매칭 되는 부분 의도들을 삭제 S340에서, 프로세서는 최종 의도에 매칭되는 시나리오를 바탕으로, 음성 인식 기능을 수행할 수 있다. 이하, 각각의 절차에 대해서 보다 구체적인 실시 예에 대해서 살펴보면 다음과 같다. 도 4는 본 발명의 실시 예에 의한 의도 추출 과정을 설명하기 위한 도면이다. 도 1 및 도 4를 참조하여, 의도 추출 과정을 살펴보면 다음과 같다. 마이크는 사용자의 발화를 수신하고, 프로세서는 딥러닝 알고리즘을 이용하여 사용자의 의도를 추출 할 수 있다. 예를 들어, 프로세서는 사용자 발화를 발화 텍스트로 변환하고, 발화 텍스트에 대응되는 사용 자 의도를 판단할 수 있다. 프로세서는 사용자 발화를 발화 텍스트로 변환하기 위해서 STT(Speech to Test) 엔진을 이용할 수 있다. 프로세서는 사용자 발화에서 특징 벡터를 추출할 수 있고, 추출된 특징 벡터와 훈련된 기준 패턴을 이용하 여 발화 텍스트를 획득할 수 있다. 프로세서는 발화 텍스트에 포함된 사용자 의도를 판단하기 위해서 자연어 이해(Natural Language Understanding: NLU) 기술을 이용할 수 있다. 이를 위해서 프로세서는 입력 문장에 대해 NLU 기술을 적용 하여 사용자 의도를 판단하는 NLU 엔진을 포함할 수 있다. 프로세서는 다음과 같은 자연어 이해를 수행할 수 있다. 프로세서는 발화 텍스트로부터 개체명을 인식할 수 있다. 개체명은 인명, 지명, 조직명, 시간, 날짜, 화폐 등의 고유 명사로서, 개체명 인식은 문장에서 개체명을 식별하고 식별된 개체명의 종류를 결정하는 작업이다. 개체명 인식을 통해 문장에서 중요한 키워드를 추출하여 문장의 의미를 파악할 수 있다. 프로세서는 발화 텍스트로부터 도메인을 결정할 수 있다. 도메인은 사용자 발화의 주제를 식별할 수 있는 것으로서, 예를 들어, 전자장치의 제어, 일정 관리, 날씨 또는 교통 상황 등에 관한 정보 제공, 문자 전송, 전 화 걸기, 내비게이션, 차량 제어 등의 다양한 주제를 나타내는 도메인이 발화 텍스트에 기초하여 결정될 수 있 다. 프로세서는 발화 텍스트가 갖는 화행을 분석할 수 있다. 화행 분석은 발화의 의도를 분석하는 작업으로, 사용자가 질문을 하는 것인지, 요청을 하는 것인지, 응답을 하는 것인지, 단순한 감정 표현을 하는 것인지 등의 발화의 의도를 파악하는 것이다. 프로세서는 발화 텍스트로부터 추출된 도메인, 개체명, 화행 등의 정보에 기초하여 의도(intent) 및 의도 를 수행하는데 필요한 엔티티(entity)를 판단할 수 있다. 예를 들어, 발화 텍스트가 \"에어컨 켜줘\"인 경우 도메인은 [차량 제어]가 되고, 의도는 [turn on, air conditioner]가 될 수 있으며, 에어컨 제어를 수행하기 위해 필요한 엔티티는 [온도, 풍량]이 될 수 있다. 또는, 발화 텍스트가 \"문자 보내줘\"인 경우 도메인은 [문자 송수신]이 되고, 의도는 [send, message]가 될 수 있으며, 문자 송수신을 수행하기 위해 필요한 엔티티는 [수신인, 내용]이 될 수 있다. 의도는 액션과 타겟에 의해 결정될 수 있다. 액션은 도메인의 동작을 지시하는 것일 수 있고, 타겟은 액션의 주 체 또는 객체를 의미할 수 있다. 예를 들어, 액션은 turn on이 되고, 타겟은 air conditioner가 된다. 액션은 오퍼레이터로 지칭될 수 있고, 타겟은 오브젝트로 지칭될 수 있다. 이러한 과정을 통해서, 프로세서는 사용자 발화로부터 다양한 의도를 추출할 수 있고, [call Phonebook], [search POI], [play radiobroadcast], [play music] 등의 사용자 의도를 추출할 수 있다. 도 5는 사용자 의도의 재배열 과정을 설명하기 위한 도면이다. 도 5를 참조하면, 프로세서는 복수의 발화를 바탕으로 부분 의도들을 추출하고, 부분 의도들을 재배열할 수 있다. 부분 의도들을 재배열하는 과정은 최종 의도를 생성하는 중간 과정으로 이해될 수 있다. 프로세서는 다른 타이밍에 획득한 발화들을 구분할 수 있다. 각각의 발화들은 발화들에 의도가 추출된 상 태를 기준으로 구분될 수 있다. 예를 들어, 프로세서는 제1 타이밍(t1)에서 제1 발화를 바탕으로 제1 부분 의도를 생성할 수 있으며, 이후 제2 타이밍(t2)에서 제2 발화를 바탕으로 제2 부분 의도를 생성할 수 있다. 마 찬가지로, 제3 타이밍(t3)에서 제3 발화를 바탕으로 제3 부분 의도를 생성할 수 있다. 제1 부분 의도는 제1 발화를 바탕으로 추출된 제1 의도를 구분자를 이용하여 분리한 것일 수 있다. 마찬가지로, 제2 부분 의도는 제2 발화를 바탕으로 추출된 제2 의도를 구분자를 이용하여 분리한 것일 수 있으며, 제3 부분 의도는 제3 발화를 바탕으로 추출된 제3 의도를 구분자를 이용하여 분리한 것일 수 있다. 프로세서는 액션, 타겟 및 엔티티에 구분자를 부여하여 의도를 분리할 수 있다. 구분자를 부여하는 과정은 각각의 액션, 타겟 또는 엔티티에 선행하여 구분자를 표기하는 절차를 포함할 수 있다. 각각의 의도에서 가장 첫 번째 액션 또는 타겟 또는 엔티티는 구분자를 생략할 수도 있다. 구분자들은 제1 구분자 내지 제4 구분자를 포함할 수 있다. 제1 구분자는 [+]으로 표현될 수 있으며, 액션 또는 타겟에 부여될 수 있다. 예를 들어, [call Phonebook], [search POI], [play radiobroadcast], [play music] 등의 의도들은 각각 제1 구분자를 이용하여 [call+Phonebook], [search+POI], [play+radiobroadcast], [play+music]와 같이 분리될 수 있다. 제2 구분자는 [-]으로 표현될 수 있으며, 제1 구분자가 부여된 액션 또는 타겟을 부정하는 액션 또는 타겟에 부 여될 수 있다. 특히 제2 구분자는 선행하는 의도에서 제1 구분자가 부여된 액션 또는 타겟을 부정하는 과정에서 사용될 수 있다. 예를 들어, 제1 발화에서 [목적지 검색]이라는 의도에 따라 [+Navi]라는 부분 의도가 생성되고, 제2 발화에서 [경로 안내 말고]라는 의도가 추출될 경우 [-Navi]라는 부분 의도가 생성될 수 있다. 제3 구분자는 [*]로 표현될 수 있으며, 엔티티에 부여될 수 있다. 예를 들어, 음악을 재생하는 의도에 가수 또 는 제목의 엔티티가 태깅될 경우, 프로세서는 *{가수}, *{제목}이라는 부분 의도를 생성할 수 있다. 제4 구분자는 [÷]으로 표현될 수 있으며, 제1 구분자가 부여된 엔티티를 부정하는 엔티티에 부여될 수 있다. 또한 제4 구분자는 선행하는 의도에서 제2 구분자가 부여된 엔티티를 부정하는 과정에서 사용될 수 있다. 예를 들어, 제1 발화에서 *{가수1}이라는 부분 의도가 생성되고, 제2 발화에서 [가수1 말고]라는 의도가 추출될 경우, ÷{가수1}이라는 부분 의도가 생성될 수 있다. 이하, 사용자의 발화들을 바탕으로 최종 의도를 생성하는 실시 예를 살펴보면 다음과 같다. 도 6은 본 발명의 실시 예에 의한 최종 의도를 생성하는 방법을 설명하기 위한 도면이다. 도 6을 참조하면, S61에서, 프로세서는 제1 타이밍(t1)에서 제1 발화를 바탕으로 의도를 추출할 수 있다. 마찬가지로, 프로세서는 제2 타이밍(t2)에서 제2 발화를 바탕으로 제2 의도를 추출할 수 있고, 제3 타이밍 (t3)에서 제3 발화를 바탕으로 제3 의도를 추출할 수 있다. 예를 들어, 프로세서는 \"목적지 검색해줘\"라는 제1 발화를 바탕으로 [search POI]라는 제1 의도를 추출하고, \"양화대교 노래 들려줘\"라는 제2 발화를 바탕으로 [Play Music{명칭: 양화대교}]라는 제2 의도를 추출할 수 있다. 그리고 프로세서는 \"다른 거\"라는 제3 발화를 바탕으로 [change]라는 제3 의도를 추출할 수 있다. S62에서, 프로세서는 구분자들을 이용하여 제1 의도, 제2 의도 및 제3 의도들 각각을 분리할 수 있다. [search POI]는 search라는 액션과 POI라는 타겟으로 구분될 수 있으며, 프로세서는 제1 구분자를 이용하 여 제1 의도를 [search+POI]로 분리할 수 있다. [Play Music{명칭: 양화대교}]는 Play라는 액션과 Music이라는 타겟, 그리고 {명칭: 양화대교}라는 엔티티로 구분될 수 있으며, 프로세서는 제1 구분자 및 제3 구분자를 이용하여 제2 의도를 [Play+Music*{명칭: 양화대교}]로 분리할 수 있다. 또한, [change]는 하나의 액션을 포함 하기 때문에, 프로세서는 [change]를 그대로 부분 의도로 판단할 수 있다. [search+POI]에서, search 및 POI들은 각각 제1 부분 의도로 지칭될 수 있으며, [Play+Music*{명칭: 양화대교}]에서 Play Music 및 {명칭: 양화대교}는 각각 제2 부분 의도로 지칭될 수 있다. [change]에서 change는 제3 부분 의도로 지칭될 수 있다. S63에서, 프로세서는 부분 의도들을 재배열할 수 있다. 프로세서는 발화의 역순으로 부분 의도들을 배열할 수 있다. 예를 들어 가장 먼저 획득된 제1 부분 의도들을 가장 후순위에 배치하고, 가장 나중에 획득된 제3 부분 의도들을 가장 앞선 순위에 배치할 수 있다. S64에서, 프로세서는 가장 선행하는 액션을 제외하고 다른 액션들은 제거할 수 있다. 예를 들어, [change Play Music{명칭: 양화대교} search+POI]에서 가장 선행하는 액션인 change만을 남겨두고, play, search는 제 거할 수 있다. S65에서, 프로세서는 비매칭 부분 의도를 제거할 수 있다. 예를 들어, +POI는 search라는 액션에 매칭되는 타겟으로 해석될 수 있으며, S64 단계 이후 search라는 액션은 제거된 상태일 수 있다. 프로세서는 이와 같이 액션이 제거된 타겟이 있을 경우, 해당 타겟 또한 제거할 수 있다. 결과적으로 프로세서는 [change +Music*{명칭: 양화대교}]라는 최종 의도를 생성할 수 있다. 도 6에 도시된 실시 예와 같이, \"다른 거\"라는 제3 발화는 액션 또는 타겟이 불분명하기 때문에, 종래에는 제3 발화만으로는 음성 인식 기능이 정확하게 수행될 수 없는 상황이 발생할 수 있다. 본 발명의 실시 예에 의하면, 불명확한 발화들이 획득될 경우에도, 이전 발화들을 바탕으로 사용자의 의도를 보다 정확하게 반영할 수 있는 최종 의도를 생성할 수 있고, 최종 의도를 바탕으로 음성 인식 기능을 정확하게 수행할 수 있다. 도 7은 본 발명의 다른 실시 예에 의한 최종 의도를 생성하는 방법을 설명하기 위한 도면이다. 도 7을 참조하면, S71에서, 프로세서는 제1 타이밍(t1)에서 제1 발화를 바탕으로 의도를 추출할 수 있다. 마찬가지로, 프로세서는 제2 타이밍(t2)에서 제2 발화를 바탕으로 제2 의도를 추출할 수 있고, 제3 타이밍 (t3)에서 제3 발화를 바탕으로 제3 의도를 추출할 수 있다. 예를 들어, 프로세서는 \"음악 들려줘\"라는 제1 발화를 바탕으로 [Play Music]이라는 제1 의도를 추출하고, \"양화대교\"라는 제2 발화를 바탕으로 [Route Navi {명칭: 양화대교}]라는 제2 의도를 추출할 수 있다. 그리고 프로세서는 \"경로 안내가 아니라 음악 재생\"라 는 제3 발화를 바탕으로 [Play Music not Navi]라는 제3 의도를 추출할 수 있다. S72에서, 프로세서는 구분자들을 이용하여 제1 의도, 제2 의도 및 제3 의도들 각각을 분리할 수 있다. [Play Music]은 Play라는 액션과 Music이라는 타겟을 포함하기 때문에, 프로세서는 제1 의도를 [Play+Music]으로 분리할 수 있다. [Route Navi{명칭: 양화대교}]는 Route라는 액션과 Navi라는 타겟, {명칭: 양화대교}라는 엔티티를 포함하기 때 문에, 프로세서는 제2 의도를 [Route+Navi*{명칭: 양화대교}]으로 분리할 수 있다. [Play Music not Navi]는 Play라는 액션, Music이라는 타겟, not Navi라는 타겟을 포함할 수 있다. 제3 의도에 서 not Navi는 선행하는 제2 부분 의도인 Navi를 부정하는 것일 수 있다. 결과적으로 프로세서는 제3 의도 를 [Play+Music-Navi]로 분리할 수 있다. S73에서, 프로세서는 부분 의도들을 재배열할 수 있다. 프로세서는 발화의 역순으로 부분 의도들을 배열할 수 있다. 예를 들어 가장 먼저 획득된 제1 부분 의도들을 가장 후순위에 배치하고, 가장 나중에 획득된 제3 부분 의도들을 가장 앞선 순위에 배치할 수 있다. S74에서, 프로세서는 가장 선행하는 액션을 제외하고 다른 액션들은 제거할 수 있다. 예를 들어, 프로세서 는 [Play+Music-Navi Route+Navi{명칭: 양화대교} Play Music]에서 가장 선행하는 액션인 Play만을 남겨 두고, 제2 부분 의도의 Route 및 제1 부분 의도의 play를 제거할 수 있다.S75에서, 프로세서는 액션이 제거된 부분 의도들을 결합할 수 있으며, 결합 과정에서 중복 부분 의도들을 제거할 수 있다. 중복 부분 의도들은 서로 상반되는 구분자들이 표기된 동일한 부분 의도들일 수 있다. 제1 구 분자와 제2 구분자는 서로 상반되는 구분자 커플일 수 있고, 제3 구분자와 제4 구분자는 서로 상반되는 구분자 커플일 수 있다. 예를 들어, 프로세서는 -Navi +Navi와 같이 서로 동일한 타겟을 지칭하는 부분 의도들이 상반되는 구분자로 구분될 경우, -Navi +Navi들을 중복되는 부분 의도들로 판단하고, -Navi +Navi을 삭제할 수 있다. 결과적으로 프로세서는 [Play+Music*{명칭: 양화대교}]라는 최종 의도를 생성할 수 있다. 도 7에서와 같이, 제2 발화는 액션이 생략된 상태이기 때문에 의도 파악이 불명확할 수 있다. 또한 제3 발화는 엔티티가 생략된 상태이기 때문에 의도 파악이 불명확할 수 있다. 본 발명의 실시 예에 의하면, 불명확한 발화들이 획득될 경우에도, 이전 발화들을 바탕으로 사용자의 의도를 보 다 정확하게 반영할 수 있는 최종 의도를 생성할 수 있고, 최종 의도를 바탕으로 음성 인식 기능을 정확하게 수 행할 수 있다. 도 8은 본 발명의 다른 실시 예에 의한 최종 의도를 생성하는 방법을 설명하기 위한 도면이다. 도 8을 참조하면, S81에서, 프로세서는 제1 타이밍(t1)에서 제1 발화를 바탕으로 의도를 추출할 수 있고, 제2 타이밍(t2)에서 제2 발화를 바탕으로 제2 의도를 추출할 수 있다. 예를 들어, 프로세서는 \"양화대교 길 안내\"라는 제1 발화를 바탕으로 [Route Navi{명칭: 양화대교}]이라는 제1 의도를 추출하고, \"양화대교 말고 올림픽공원\"라는 제2 발화를 바탕으로 [{명칭: 올림픽공원} not{명칭: 양화대교}]라는 제2 의도를 추출할 수 있 다. S82에서, 프로세서는 구분자들을 이용하여 제1 의도, 제2 의도 및 제3 의도들 각각을 분리할 수 있다. [Route Navi{명칭: 양화대교}]는 Route라는 액션과 Navi라는 타겟 {명칭: 양화대교}이라는 엔티티를 포함하기 때문에, 프로세서는 제1 의도를 [Route+Navi*{명칭: 양화대교}]로 분리할 수 있다. [{명칭: 올림픽공원} not{명칭: 양화대교}]는 {명칭: 올림픽공원}이라는 엔티티와 not{명칭: 양화대교}이라는 엔티티를 포함하기 때문에 프로세서는 제2 의도를 [*{명칭: 올림픽공원}÷{명칭: 양화대교}]으로 분리할 수 있다. S83에서, 프로세서는 액션이 제거된 부분 의도들을 결합할 수 있으며, 결합 과정에서 중복 부분 의도들을 제거할 수 있다. 예를 들어, *{명칭: 양화대교}는 제3 구분자가 부여된 부분 의도이며, ÷{명칭: 양화대교}는 제4 구분자가 부여된 부분 의도이며, 서로 동일한 엔티티이기 때문에, 삭제될 수 있다. 결과적으로 프로세서는 [Route+Navi*{명칭: 올림픽공원}]이라는 최종 의도를 생성할 수 있다. 도 8에 도시된 실시 예와 같이, 제2 발화의 액션이 불명확하여 사용자 의도가 명확하지 않을 경우에도, 본 발명 의 실시 예에 의하면 사용자 의도를 보다 정확하게 반영할 수 있는 최종 의도를 생성할 수 있다. 도 9는 본 발명의 일 실시 예에 따른 컴퓨팅 시스템을 도시한다. 도 9를 참조하면, 컴퓨팅 시스템은 버스를 통해 연결되는 적어도 하나의 프로세서, 메모리 , 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치, 스토리지, 및 네트워 크 인터페이스를 포함할 수 있다. 프로세서는 중앙 처리 장치(CPU) 또는 메모리 및/또는 스토리지에 저장된 명령어들에 대한 처리를 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 다양한 종류의 휘발성 또는 불휘발 성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM(Read Only Memory) 및 RAM(Random Access Memory)을 포함할 수 있다. 따라서, 본 명세서에 개시된 실시 예들과 관련하여 설명된 방법 또는 알고리즘의 단계는 프로세서에 의해 실행되는 하드웨어, 소프트웨어 모듈, 또는 그 2 개의 결합으로 직접 구현될 수 있다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 디스크, 착탈형 디스크, CD-ROM과 같은 저장 매체(즉, 메모리 및/또는 스토리지)에 상주할 수도 있다. 예시적인 저장 매체는 프로세서에 커플링되며, 그 프로세서는 저장 매체로부터 정보를 판독할 수 있고 저장 매체에 정보를 기입할 수 있다. 다른 방법으로, 저장 매체는 프로세서와 일체형일 수도 있다.프로세서 및 저장 매체는 주문형 집적회로(ASIC) 내에 상주할 수도 있다. ASIC는 사용자 단말기 내에 상주할 수 도 있다. 다른 방법으로, 프로세서 및 저장 매체는 사용자 단말기 내에 개별 컴포넌트로서 상주할 수도 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시 예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이 고, 이러한 실시 예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아 래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0095497", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 의한 음성 인식 장치의 구성을 나타내는 블록도이다. 도 2는 본 발명의 실시 예에 의한 음성 인식 장치가 탑재된 차량의 내부 구성을 나타내는 도면이다. 도 3은 본 발명의 실시 예에 의한 음성 인식 방법을 설명하기 위한 순서도이다. 도 4는 본 발명의 실시 예에 의한 의도 추출 과정을 설명하기 위한 도면이다. 도 5는 사용자 의도의 재배열 과정을 설명하기 위한 도면이다. 도 6은 본 발명의 실시 예에 의한 최종 의도를 생성하는 방법을 설명하기 위한 도면이다. 도 7은 본 발명의 다른 실시 예에 의한 최종 의도를 생성하는 방법을 설명하기 위한 도면이다. 도 8은 본 발명의 다른 실시 예에 의한 최종 의도를 생성하는 방법을 설명하기 위한 도면이다. 도 9는 본 발명의 일 실시 예에 따른 컴퓨팅 시스템을 나타내는 도면이다."}
