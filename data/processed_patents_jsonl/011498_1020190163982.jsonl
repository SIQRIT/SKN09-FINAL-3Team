{"patent_id": "10-2019-0163982", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0096102", "출원번호": "10-2019-0163982", "발명의 명칭": "연산 모델의 병렬적 처리", "출원인": "엘지전자 주식회사", "발명자": "이병주"}}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "연산 노드(compute node)로서,하나 이상의 다른 연산 노드(one or more other compute nodes)와의 통신을 위한 통신 인터페이스;상기 다른 연산 노드와 공유할 공유 데이터를 저장하는 메모리; 및상기 메모리와 연결된 프로세서를 포함하고,상기 프로세서는,입력 데이터에 대한 연산 모델을 처리하기 위한 예상 연산 부하(computational load)를 결정하고,상기 통신 인터페이스를 통해 상기 연산 노드 및 상기 다른 연산 노드가 기여가능한 연산 부하를 공유하고,상기 기여가능한 연산 부하에 기반하여 상기 예상 연산 부하를 분배할 마스터 노드를 결정하도록 설정되는,연산 노드."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,외부 센서와의 연결을 위한 센서 인터페이스를 더 포함하고,상기 프로세서는,상기 센서 인터페이스를 통해 상기 외부 센서로부터 상기 입력 데이터를 수신하도록 더 설정되는연산 노드."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,온-칩 커뮤니케이션(on-chip communication)을 위한 버스 인터페이스를 더 포함하고,상기 버스 인터페이스는 상기 프로세서, 상기 메모리 및 상기 통신 인터페이스 간의 상호연결을 제공하는연산 노드."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 프로세서는,상기 연산 노드 및 상기 다른 연산 노드 중에서 상기 마스터 노드를 결정하도록 더 설정되는,공개특허 10-2020-0096102-3-연산 노드."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 마스터 노드는,연산 제한 조건에 기반하여 상기 예상 연산 부하의 처리에 필요한 적어도 하나의 연산 노드를 결정하고,상기 예상 연산 부하를 상기 적어도 하나의 연산 노드에 분배하고,상기 적어도 하나의 연산 노드의 연산 결과를 취합하도록 설정되고,상기 프로세서는,상기 통신 인터페이스를 통해 상기 마스터 노드로부터 상기 연산 결과를 수신하도록 더 설정되는,연산 노드."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 연산 모델의 연산을 수행하는 적어도 하나의 AI 가속기(AI accelerator)를 더 포함하는,연산 노드."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 AI 가속기는,상기 연산을 수행하는 동안 중간 데이터를 생성하고,상기 중간 데이터를 상기 메모리에 저장하도록 구성되는,연산 노드."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 프로세서는,상기 통신 인터페이스를 통해 상기 중간 데이터를 상기 다른 연산 노드로 전송하도록 더 설정되는,연산 노드."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 공유 데이터는 상기 입력 데이터, 상기 기여가능한 연산 부하, 상기 연산 모델의 수행에 수반되는 중간 데이터 및 상기 연산 모델의 연산 결과를 포함하는,공개특허 10-2020-0096102-4-연산 노드."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 따른 연산 노드를 복수 개 포함하는 클러스터."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 복수 개의 연산 노드는 하나의 보드 상에 배치되는,클러스터."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서,상기 복수 개의 연산 노드 중 하나의 연산 노드는 메인 보드에 배치되고,상기 복수 개의 연산 노드 중 나머지 연산 노드는 각각 하나의 서브 보드에 배치되어 상기 메인 보드의 슬롯에장착되는,클러스터."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "복수의 연산 노드에 의한 연산 모델 처리 방법으로서,상기 복수의 연산 노드 중 하나인 홈 노드가 입력 데이터를 수신하는 단계;상기 홈 노드에 의해, 상기 입력 데이터에 대한 연산 모델을 처리하기 위한 예상 연산 부하를 결정하는 단계;상기 홈 노드의 요청에 응답하여 각 연산 노드가 기여가능한 연산 부하를 서로 공유하는 단계; 및상기 홈 노드에 의해, 상기 기여가능한 연산 부하에 기반하여 상기 복수의 연산 노드 중에서 상기 예상 연산 부하를 분배할 마스터 노드를 결정하는 단계;를 포함하는연산 모델 처리 방법."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 예상 연산 부하를 결정하는 단계는,상기 연산 모델의 연산량을 계산하는 단계; 및상기 연산 모델의 대역폭을 계산하는 단계를 포함하는연산 모델 처리 방법.공개특허 10-2020-0096102-5-청구항 15 제 13 항에 있어서,상기 복수의 연산 노드는 통신 인터페이스를 통해 상호연결되고,상기 공유하는 단계는,각 연산 노드가 상기 통신 인터페이스를 통해 상기 기여가능한 연산 부하를 브로드캐스팅하는 단계를 포함하는,연산 모델 처리 방법."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 13 항에 있어서,상기 마스터 노드에 의해, 상기 기여가능한 연산 부하에 기반하여 상기 예상 연산 부하를 상기 복수의 연산 노드 중 적어도 하나의 연산 노드로 분배하는 단계를 더 포함하는,연산 모델 처리 방법."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 분배하는 단계는,연산 제한 조건에 기반하여 상기 예상 연산 부하의 처리에 필요한 상기 적어도 하나의 연산 노드를 선택하는 단계; 및상기 예상 연산 부하를 상기 적어도 하나의 연산 노드로 분배하는 단계를 포함하는연산 모델 처리 방법."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 16 항에 있어서,상기 마스터 노드에 의해, 상기 적어도 하나의 연산 노드로부터 연산 결과를 취합하는 단계; 및상기 취합된 연산 결과를 상기 마스터 노드가 상기 홈 노드로 전송하는 단계를 더 포함하는연산 모델 처리 방법."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 13 항에 있어서,상기 홈 노드에 의해, 상기 입력 데이터에 대한 적어도 하나의 연산 모델을 결정하는 단계를 더 포함하고,공개특허 10-2020-0096102-6-상기 예상 연산 부하를 결정하는 단계, 상기 공유하는 단계 및 상기 마스터 노드를 결정하는 단계는 상기 적어도 하나의 연산 모델의 각 연산 모델별로 수행되는,연산 모델 처리 방법."}
{"patent_id": "10-2019-0163982", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19 항에 있어서,상기 홈 노드에 의해, 각 연산 모델의 마스터 노드로부터 각 연산 모델의 연산 결과를 수신하는 단계; 및상기 홈 노드에 의해, 수신된 적어도 하나의 연산 결과를 서로 비교하는 단계를 더 포함하는,연산 모델 처리 방법."}
{"patent_id": "10-2019-0163982", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 머신 러닝 모델의 연산을 처리하기 위한 인공지능용 칩에 관한 것으로, 연산 노드 및 복수의 연산 노 드를 이용하여 연산 모델을 병렬적으로 처리하는 방법이 제공된다. 이를 통해 디바이스에서 전체적으로 효과적인 학습 및 추론의 수행이 가능하다."}
{"patent_id": "10-2019-0163982", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 연산 노드 및 복수의 연산 노드를 이용하여 연산 모델을 병렬적으로 처리하는 방법에 관한 것이다."}
{"patent_id": "10-2019-0163982", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공 지능 기술의 상용화가 본격화되면서, 인공 신경망을 활용하는 다양한 제품 및 서비스가 개발되고 있 다. 한편, 서버와의 연결 없이 에지 디바이스에서 인공 지능 연산을 수행하는 기술은 네트워크 트래픽, 에너지 효율 및 프라이버시 측면에서 점점 중요성이 강조되고 있다. 온 디바이스(On-device)에서 인공 신경망 알고리즘을 효율적으로 연산할 수 있는 인공 지능 칩이 필요하다."}
{"patent_id": "10-2019-0163982", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 과제는 인공 신경망 연산을 수행하는 연산 노드로서 다중 확장가능한 구조의 연산 노드를 제공하 는 것이다. 본 발명의 일 과제는 복수의 연산 노드에 의한 연산 모델 처리 방법을 제공하는 것이다. 본 발명의 일 과제는 온 디바이스에서 인공 신경망 알고리즘을 연산하는 인공 지능 칩을 제공하는 것이다. 본 발명에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2019-0163982", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0163982", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위하여, 실시예의 일 측면은 고속 통신 인터페이스를 통해 복수의 연산 노드를 대칭적으 로 확장가능한 연산 노드를 제공한다. 이를 위하여 연산 노드는, 하나 이상의 다른 연산 노드와의 통신을 위한 통신 인터페이스, 다른 연산 노드와 공 유할 공유 데이터를 저장하는 메모리 및 메모리와 연결된 프로세서를 포함할 수 있다. 구체적으로 프로세서는, 입력 데이터에 대한 연산 모델을 처리하기 위한 예상 연산 부하를 결정하고, 통신 인터 페이스를 통해 연산 노드 및 다른 연산 노드가 기여가능한 연산 부하를 공유하고, 기여가능한 연산 부하에 기반 하여 예상 연산 부하를 분배할 마스터 노드를 결정하도록 설정될 수 있다. 상기 과제를 달성하기 위하여, 실시예의 일 측면은 복수의 연산 노드가 적어도 하나의 연산 모델을 병렬적으로 처리할 수 있는 연산 모델 처리 방법을 제공한다. 이를 위하여, 복수의 연산 노드에 의한 연산 모델 처리 방법은, 복수의 연산 노드 중 하나인 홈 노드가 입력 데 이터를 수신하는 단계, 홈 노드에 의해, 입력 데이터에 대한 연산 모델을 처리하기 위한 예상 연산 부하를 결정 하는 단계, 홈 노드의 요청에 응답하여 각 연산 노드가 기여가능한 연산 부하를 서로 공유하는 단계 및 홈 노드 에 의해, 기여가능한 연산 부하에 기반하여 복수의 연산 노드 중에서 예상 연산 부하를 분배할 마스터 노드를 결정하는 단계를 포함할 수 있다. 상기 과제를 달성하기 위하여, 실시예의 일 측면은 다양한 인공 신경망 알고리즘을 구현한 연산 모델을 연산가 능한 연산 노드를 포함하는 인공 지능 칩을 제공한다. 이를 위하여 연산 노드는 적어도 하나의 AI 가속기를 포함할 수 있다. 구체적으로, AI 가속기는 연산을 수행하는 동안 중간 데이터를 생성하고, 중간 데이터를 메모리에 저장하도록 구성될 수 있다. 구체적으로, AI 가속기는 통신 인터페이스를 통해 중간 데이터를 다른 연산 노드와 공유할 수 있다. 본 발명에서 이루고자 하는 기술적 과제들의 해결 수단은 이상에서 언급한 해결 수단들로 제한되지 않으며, 언"}
{"patent_id": "10-2019-0163982", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "급하지 않은 또 다른 해결 수단들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자 에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0163982", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면 복수의 연산 노드에서 입력 데이터를 다중 연산 모델로 병렬적으로 분석가능하므로 정확도가 제고된다. 본 발명에 의하면 복수의 연산 노드에서 연산 모델을 연산하므로 연산 속도 및 응답 시간이 개선된다. 본 발명에 의하면 온 디바이스에서 학습 및 추론이 수행되므로 프라이버시 보호가 필요한 제품에 대한 적용성이 제고된다."}
{"patent_id": "10-2019-0163982", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 본 발명이 속한 기술 분야의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0163982", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 동일하거나 유사한 구성요소에는 동일유사한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 명세서에 개시된 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 상기 용어들에 의해 한정되어서 는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 실시예에 대한 설명에 앞서 인공 지능 기술에 대하여 살펴본다. 인공 지능은 인공적인 지능 또는 이를 만들 수 있는 방법론을 연구하는 분야를 의미하며, 머신 러닝(기계 학습, Machine Learning)은 인공 지능 분야에서 다루는 다양한 문제를 정의하고 그것을 해결하는 방법론을 연구하는 분야를 의미한다. 머신 러닝은 어떠한 작업에 대하여 꾸준한 경험을 통해 그 작업에 대한 성능을 높이는 알고리 즘으로 정의하기도 한다. 인공 신경망(ANN: Artificial Neural Network)은 머신 러닝에서 사용되는 모델로서, 시냅스의 결합으로 네트워 크를 형성한 인공 뉴런(노드)들로 구성되는, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 인공 신경 망은 다른 레이어의 뉴런들 사이의 연결 패턴, 모델 파라미터를 갱신하는 학습 과정, 출력값을 생성하는 활성화 함수(Activation Function)에 의해 정의될 수 있다. 인공 신경망은 입력층(Input Layer), 출력층(Output Layer), 그리고 선택적으로 하나 이상의 은닉층(Hidden Layer)를 포함할 수 있다. 각 층은 하나 이상의 뉴런을 포함하고, 인공 신경망은 뉴런과 뉴런을 연결하는 시냅 스를 포함할 수 있다. 인공 신경망에서 각 뉴런은 시냅스를 통해 입력되는 입력 신호들, 가중치, 편향에 대한 활성 함수의 함숫값을 출력할 수 있다. 모델 파라미터는 학습을 통해 결정되는 파라미터를 의미하며, 시냅스 연결의 가중치와 뉴런의 편향 등이 포함된 다. 그리고, 하이퍼파라미터는 머신 러닝 알고리즘에서 학습 전에 설정되어야 하는 파라미터를 의미하며, 학습 률(Learning Rate), 반복 횟수, 미니 배치 크기, 초기화 함수 등이 포함된다. 인공 신경망의 학습의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함수 는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표로 이용될 수 있다. 머신 러닝은 학습 방식에 따라 지도 학습(Supervised Learning), 비지도 학습(Unsupervised Learning), 강화 학습(Reinforcement Learning)으로 분류할 수 있다. 지도 학습은 학습 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시키는 방법을 의미하며, 레이블이란 학습 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 비지도 학습은 학습 데이터에 대한 레이블이 주어지지 않는 상태에서 인공 신경망을 학습시키 는 방법을 의미할 수 있다. 강화 학습은 어떤 환경 안에서 정의된 에이전트가 각 상태에서 누적 보상을 최대화 하는 행동 혹은 행동 순서를 선택하도록 학습시키는 학습 방법을 의미할 수 있다. 인공 신경망 중에서 복수의 은닉층을 포함하는 심층 신경망(DNN: Deep Neural Network)으로 구현되는 머신 러닝 을 딥 러닝(심층 학습, Deep Learning)이라 부르기도 하며, 딥 러닝은 머신 러닝의 일부이다. 이하에서, 머신 러닝은 딥 러닝을 포함하는 의미로 사용된다. 도 1은 일 실시예에 따른 연산 노드의 블록도이다. 연산 노드는 연산 모델에 기반하여 입력 데이터에 대한 학습 및 추론을 수행하도록 구현된 하드웨어 컴포 넌트를 의미한다. 연산 모델이란 머신 러닝에 기반한 학습 및/또는 추론을 위한 신경망 모델을 의미한다. 연산 모델은 머신 러닝 을 위한 신경망을 구현한 소프트웨어 라이브러리로서, 일종의 API(Application Programming Interface)로 제공 될 수 있다. 연산 모델은 후술할 AI 가속기에서 실행될 수 있다. 연산 모델은 학습/추론 연산을 위한 다양한 뉴럴 네트워크 모델을 포함할 수 있다. 예를 들어 연산 모델은 LeNet, SACNet, SqueezeNet, RK-imageNet, AlexNet, PVANet-lite, SegNet, VGG16, GoogleNet, ResNet-50,MobileNet, ERFNet 및 PQNet(TensorFlow) 등을 구현한 소프트웨어 라이브러리를 포함할 수 있다. 연산 노드는 하나 이상의 연산 모델을 동시에 및/또는 순차적으로 수행하고, 그 결과를 비교하여 입력 데 이터에 대한 최적의 결과를 출력할 수 있다. 일 예에서 연산 노드는 시스템 온 칩(SoC; System on Chip)으 로 구현될 수 있다. 연산 노드는 통신 인터페이스, 메모리, 프로세서, AI 가속기(AI Accelerator, 140) 및 센 서 인터페이스를 포함할 수 있다. 도 1에 도시된 구성 요소는 연산 노드를 구현하는 데에 있어서 필 수적인 것은 아니고, 실시예에 따른 연산 노드는 위에서 열거된 구성 요소의 일부를 포함하거나 또는 위에 서 열거된 구성 요소 외에 추가적인 구성 요소를 포함할 수 있다. 연산 노드는 하나 이상의 다른 연산 노드(one or more other compute nodes)와의 통신을 위한 통신 인터 페이스, 다른 연산 노드와 공유할 공유 데이터를 저장하는 메모리 및 메모리와 연결된 프로세서 를 포함할 수 있다. 통신 인터페이스는 연산 노드들 간의 상호 연결을 제공한다. 통신 인터페이스는 연산 노드들 간의 통신을 제어하는 통신 제어기(예를 들어 USB HUB IC, USB to Ethernet Phyceiver, Ethernet Controller, Ethernet Switch Controller 및 SPI to Ethernet Controller 등), 연산 노드들 간의 통신 방식에 따라 데이터를 송수신하기 위한 트랜시버, 송신기 및 수신기와 같은 하드웨 어 컴포넌트를 포함할 수 있다. 통신 인터페이스는 연산 노드 간의 통신 프로토콜에 따른 프로토콜 스택을 구현한 라이브러리와 같은 소프트웨어 컴포넌트를 포함할 수 있다. 일 예에서 통신 인터페이스는 USB(Universal Serial Bus), 이더넷(Ethernet) 또는 SPI(Serial Peripheral Interface) 중 적어도 하나의 통신 방식으로 구현될 수 있으며 이에 제한되는 것은 아니다. 이를테면 통신 인터 페이스는 그밖에 다양한 방식의 고속 통신 인터페이스를 이용하여 구현될 수 있다. 메모리는 연산 노드가 다른 연산 노드와 공유할 공유 데이터를 저장할 수 있다. 예를 들어 공유 데이터는 입력 데이터, 각 연산 노드의 기여가능한 연산 부하, 연산 모델의 수행에 수반되는 중간 데이터 및 연산 모델의 연산 결과를 포함할 수 있다. 메모리는 내장 메모리 및/또는 외장 메모리를 포함할 수 있으며, DRAM, SRAM, 또는 SDRAM 등과 같은 휘발 성 메모리, OTPROM(one time programmable ROM), PROM, EPROM, EEPROM, mask ROM, flash ROM, NAND 플래시 메 모리, 또는 NOR 플래시 메모리 등과 같은 비휘발성 메모리, SSD, CF(compact flash) 카드, SD 카드, Micro-SD 카드, Mini-SD 카드, Xd 카드, 또는 메모리 스틱(memory stick) 등과 같은 플래시 드라이브, 또는 HDD와 같은 저장 장치를 포함할 수 있다. 메모리는 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체 (flash storage media)를 포함할 수 있으나, 이에 한정되는 것은 아니다. 메모리는 프로세서가 실행가능한 명령들(instructions)을 제공할 수 있다. 이러한 명령들은 프로세서 에서 실행되는 경우, 프로세서가 입력 데이터에 대한 연산 모델을 처리하기 위한 예상 연산 부하를 결정하고, 통신 인터페이스를 통해 연산 노드 및 다른 연산 노드가 기여가능한 연산 부하를 공 유하고, 기여가능한 연산 부하에 기반하여 예상 연산 부하를 분배할 마스터 노드를 결정하도록 할 수 있다. 프로세서는 일종의 중앙처리장치로서 메모리에 탑재된 제어 소프트웨어를 구동하여 연산 노드의 동작을 제어할 수 있다. 프로세서는 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있다. 프로세 서는 예를 들어 프로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조 화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이 터 처리 장치의 일 예로서, 마이크로프로세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 처리 장치를 망라할 수 있으나, 이에 한정되는 것은 아 니다. 프로세서는 하나 이상의 프로세서를 포함할 수 있다. 프로세서는 입력 데이터에 대한 연산 모델을 처리하기 위한 예상 연산 부하(computational load)를 결정하 고, 통신 인터페이스를 통해 연산 노드 및 다른 연산 노드가 기여가능한 연산 부하를 공유하고, 기여가능한 연산 부하에 기반하여 예상 연산 부하를 분배할 마스터 노드를 결정하도록 설정될 수 있다.연산 노드는 외부 센서와의 연결을 위한 센서 인터페이스를 포함할 수 있다. 프로세서는 센서 인터페이스를 통해 외부 센서로부터 입력 데이터를 수신하도록 설정될 수 있다. 외부 센서는 하나 이상의 센서를 포함할 수 있다. 예를 들어 외부 센서는 영상 센서, 근접 센서, 조도 센서, 가 속도 센서, 자기 센서, 자이로 센서, 관성 센서, RGB 센서, IR 센서, 지문 인식 센서, 초음파 센서, 광 센서, 마이크로폰, 라이다 및 레이더 등을 포함할 수 있다. 연산 노드는 연산 모델의 연산을 수행하는 적어도 하나의 AI 가속기를 포함할 수 있다. AI 가속기는 연산 노드에 할당된 적어도 하나의 연산 모델을 순차적으로 또는 병렬적으로 연산하는 하드웨어 컴포넌트를 의미한다. AI 가속기는 적어도 하나의 프로세서 및 이러한 적어도 하나의 프로세서가 공유하는 메모리를 포함할 수 있다. AI 가속기는 연산 모델의 연산을 수행하는 동안 중간 데이터를 생성하고, 생성된 중간 데이터를 메모리 에 저장할 수 있다. 또한 AI 가속기는 연산 모델의 연산 결과를 메모리에 저장할 수 있다. 프로 세서는 이와 같은 중간 데이터 및 연산 결과를 통신 인터페이스를 통해 다른 연산 노드와 공유 하도록 설정될 수 있다. 도 2는 일 실시예에 따른 상호연결된 복수의 연산 노드의 블록도이다. 연산 노드는 온-칩 커뮤니케이션(on-chip communication)을 위한 버스 인터페이스를 포함할 수 있다. 버스 인터페이스는 프로세서, 메모리, AI 가속기 및 통신 인터페이스 간의 상호 연결 을 제공할 수 있다. 상호 연결(interconnect)되어 있다는 것은 대상들을 서로 연결하는 물리적/논리적 경로가 제공되어 제어 신호 및 데이터의 송수신이 가능한 상태를 의미한다. 연산 노드는 통신 인터페이스를 통하여 하나 이상의 다른 연산 노드(100', 100'')와 상호 연결될 수 있다. 연산 노드들(100, 100', 100'')이 상호 연결되어 있다는 것은 연산 노드들(100, 100', 100'')을 서로 연결하는 물리적/논리적 경로가 제공되어 연산 노드들(100, 100', 100'') 간에 메시지를 주고 받을 수 있는 상태인 것을 의미한다. 예를 들어 메시지는 제어 정보 및 데이터를 포함할 수 있다. 각 연산 노드(100, 100', 100'')는 자신의 통신 인터페이스(110, 110', 110'')를 통해 이와 같은 물리적/논리적 경로를 제어하고, 데이터를 송수신할 수 있다. 물리적/논리적 경로는 통신 인터페이스가 제공하는 통신 방식에 따라 USB(Universal Serial Bus), 이더넷(Ethernet) 또는 SPI(Serial Peripheral Interface) 중 적어도 하나의 통신 경로를 제공할 수 있으며, 그밖에 다양한 방식의 고속 통신 인터페이스를 위한 통신 경로를 제공할 수 있다. 도 2에는 세 개의 연산 노드들(100, 100', 100'')이 도시되어 있으나 이에 제한되는 것은 아니며, 두 개 또는 더 많은 수의 연산 노드가 통신 인터페이스를 통해 상호 연결될 수 있다. 상호 연결된 복수의 연산 노드는 하나의 클러스터를 형성한다. 복수의 연산 노드를 포함하는 클러스터에 대하여는 도 3a 및 도 3b를 참조하여 후술한다. 일 예에서 클러스터를 구성하는 복수 개의 연산 노드는 하나의 보드 상에 배치될 수 있다. 일 예에서 클러스터를 구성하는 복수 개의 연산 노드 중 하나의 연산 노드는 메인 보드에 배치되고, 나머지 연 산 노드는 각각 하나의 서브 보드에 배치되어 메인 보드의 슬롯에 장착될 수 있다. 도 3a는 일 실시예에 따른 복수의 연산 노드의 동작을 설명하기 위한 도면이다. 클러스터는 여러 개의 상호 연결된 연산 노드의 집합을 의미한다. 클러스터에 포함된 복수 개의 연산 노드 는 함께 태스크를 수행할 수 있다. 예를 들어 태스크는 입력 데이터를 연산 모델에 기반하여 학습하거나 또는 결과값을 추론하는 것을 포함한다. 클러스터는 복수 개의 연산 노드를 포함할 수 있다. 도 3a에 도시된 예시적인 클러스터는 9개의 연산 노드 (N0, N1, N2, N3, N4, N5, N6, N7 및 N8)를 포함한다. 각 연산 노드 Na(a는 0 또는 자연수)는 도 1을 참조하여 하 나의 연산 노드에 대응한다.클러스터는 대칭적 클러스터(symmetric cluster) 구조로 동작할 수 있다. 즉, 클러스터를 구성하는 복수 개의 연산 노드(N0, N1, N2, N3, N4, N5, N6, N7 및 N8)의 각 연산 노드 Na는 동등한 지위를 가질 수 있다. 각 연산 노 드 Na가 동등한 지위를 가진다는 것은 연산 노드 Na가 임의의 태스크에 대한 잠재적 마스터 노드가 될 수 있다는 것을 의미한다. 일 예에서 클러스터는 태스크 마다 마스터 노드를 결정할 수 있다. 예를 들어 클러스터는 연산 노드 N1을 제 1 태스크에 대한 마스터 노드로 결정하고, 연산 노드 N2를 제 2 태스크에 대한 마스터 노드로 결정할 수 있다. 일 예에서 클러스터는 태스크에 대한 마스터 노드를 동적으로 결정할 수 있다. 예를 들어 클러스터는 태스크에 대한 마스터 노드를 결정하기 위하여 각 연산 노드 Na의 현재 연산 부하를 고려할 수 있다. 태스크에 대한 마스터 노드는 태스크를 수행할 적어도 하나의 연산 노드를 결정하고, 결정된 적어도 하나의 연 산 노드에게 서브 태스크를 분배하고, 연산 결과를 취합한다. 서브 태스크는 태스크의 일부로서, 태스크를 수행 하기 위한 전체 연산 부하를 여러 개로 분할하여 생성된 부분 연산 부하를 의미한다. 도 3b는 일 실시예에 따른 복수의 연산 노드의 동작을 설명하기 위한 도면이다. 복수의 연산 노드를 포함하는 클러스터는 적어도 하나의 연산 모델을 처리할 수 있다. 도 3b는 4 개의 연산 모 델(연산 모델 A, 연산 모델 B, 연산 모델 C 및 연산 모델 D)를 처리하는 클러스터를 예시적으로 도시한다. 예시 적인 클러스터는 9 개의 연산 노드(N0, N1, N2, N3, N4, N5, N6, N7 및 N8)를 포함한다. 클러스터는 적어도 하나의 연산 모델을 병렬적으로 처리할 수 있다. 예를 들어 연산 노드 N1, N2 및 N3는 연산 모델 A을 처리하고, 연산 노드 N6 및 N7은 연산 모델 B를 처리할 수 있다. 예를 들어 연산 노드 N4는 연산 모델 C를 처리하고, 연산 노드 N0, N5, N6 및 N8은 연산 모델 D를 처리할 수 있다. 각 연산 노드 Na는 순차적으로 또는 병렬적으로 적어도 하나의 연산 모델을 처리할 수 있다. 예를 들어 연산 노 드 N6는 연산 모델 B의 처리를 완료한 후에 순차적으로 연산 모델 D를 처리할 수 있다. 예를 들어 연산 노드 N6 는 연산 모델 B 및 연산 모델 D를 병렬적으로 처리할 수 있다. 이하에서 도 6, 도 7a 및 도 7b를 참조하여 클러스터의 동작에 대하여 보다 구체적으로 살펴본다. 도 6은 일 실시예에 따른 클러스터의 연산 모델 처리 동작을 설명하기 위한 도면이다. 도 1을 참조하여 연산 노드의 센서 인터페이스를 통해 연산 노드는 센서가 감지한 입력 데이터 를 수신한다. 센서로부터 입력 데이터를 수신한 연산 노드를 홈 노드(NH)라고 칭한다. 홈 노드(NH)는 입력 데이터 마다 결정된다. 예를 들어 제 1 입력 데이터를 제 1 연산 노드가 수신한 경우, 제 1 입력 데이터의 홈 노드(NH1)는 제 1 연산 노드가 된다. 하나의 연산 노드는 여러 개의 입력 데이터에 대한 홈 노드(NH)가 될 수 있다. 예를 들어 제 1 연산 노드 가 제 1 입력 데이터 및 제 2 입력 데이터를 수신한 경우, 제 1 연산 노드는 제 1 입력 데이터의 홈 노드(NH1)이 면서 제 2 입력 데이터의 홈 노드(NH2)가 될 수 있다. 홈 노드(NH)는, 자신의 프로세서에 의해, 입력 데이터에 대한 연산 모델을 결정할 수 있다. 홈 노드(NH)는, 자신의 프로세서에 의해, 입력 데이터에 대한 연산 모델을 처리하기 위한 예상 연산 부하 를 결정할 수 있다. 일 예에서 홈 노드(NH)는 입력 데이터에 대하여 수행할 적어도 하나의 연산 모델을 결정할 수 있다. 이 경우 홈 노드(NH)는 각 연산 모델의 예상 연산 부하를 각각 결정할 수 있다. 후속하여 클러스터 내의 각 연산 노드는 통신 인터페이스를 통해 각 연산 노드가 기여가능한 연 산 부하를 공유할 수 있다. 즉, 홈 노드(NH) 및 홈 노드(NH)와 상호 연결된 클러스터 내의 다른 연산 노드 는 각자가 기여가능한 연산 부하를 통신 인터페이스를 통해 공유할 수 있다. 이를테면, 홈 노드(NH)는 통신 인터페이스를 통해 홈 노드(NH)가 기여가능한 연산 부하를 클러스터 내의 다른 연산 노드에 전송 하고, 통신 인터페이스를 통해 다른 연산 노드가 기여가능한 연산 부하를 수신할 수 있다. 이를 위해 홈 노드(NH) 와 다른 연산 노드는 각자가 기여가능한 연산 부하를 통신 인터페이스를 통해 브로드캐 스팅 할 수 있다. 홈 노드(NH)는, 자신의 프로세서에 의해, 홈 노드(NH)가 기여가능한 연산 부하 및 다른 연산 노드가 기여가능한 연산 부하에 기반하여 앞서 결정한 예상 연산 부하를 분배할 마스터 노드(NM)를 결정할 수 있다. 일 예에서 홈 노드(NH)는 자기 자신을 마스터 노드(NM)로 결정할 수 있다. 마스터 노드(NM)는 입력 데이터에 대한 연산 모델 마다 결정될 수 있다. 예를 들어 홈 노드(NH)가 입력 데이터에 대하여 두 개의 연산 모델(ex. 연산 모델 A 및 연산 모델 B)를 수행하기로 결정한 경우, 홈 노드(NH)는 연산 모 델 A의 예상 연산 부하를 분배할 마스터 노드(NMA) 및 연산 모델 B의 예상 연산 부하를 분배할 마스터 노드(NM B)를 각각 결정할 수 있다. 마스터 노드(NM)는 연산 제한 조건에 기반하여 예상 연산 부하의 처리에 필요한 적어도 하나의 연산 노드(예를 들어 Ni, Nj, ..., Nk)를 결정할 수 있다. 마스터 노드(NM)는 예상 연산 부하를 앞서 결정된 적어도 하나의 연산 노드(Ni, Nj, ..., Nk)에 분배하고, 적어도 하나의 연산 노드(Ni, Nj, ..., Nk)로부터 연산 결과를 수신하여 이를 취합할 수 있다. 마스터 노드(NM)도 예상 연산 부하 중 일부를 담당하여 연산을 수행하고, 마스터 노드(NM)의 연산 결과를 적어도 하나의 연산 노드(Ni, Nj, ..., Nk)로부터 수신한 연산 결과와 함께 취합할 수 있다. 후속하여 마스터 노드(NM)는 취합된 연산 결과를 홈 노드(NH)에게 전송한다. 홈 노드(NH)는 수신된 연산 결과에 기반하여 입력 데이터에 대한 최종 결과값을 출력할 수 있다. 일 예에서 입력 데이터에 대하여 복수의 연산 모델(ex. 연산 모델 A 및 연산 모델 B)를 수행한 경우, 홈 노드 (NH)는 각 연산 모델의 마스터 노드(ex. NMA 및 NMB)로부터 수신한 연산 결과를 비교하고, 비교의 결과에 따라 하 나의 결과값을 결정하여 출력할 수 있다. 예를 들어 홈 노드(NH)는 가장 좋은 결과값을 선택할 수 있다. 예를 들어 홈 노드(NH)는 평균치 또는 중간값을 출력할 수 있다. 일 예에서 홈 노드(NH)는 각 연산 모델의 마스터 노 드(ex. NMA 및 NMB)로부터 수신한 연산 결과를 모두 출력할 수 있다. 도 7a는 일 실시예에 따른 연산 모델 처리 과정을 설명하기 위한 도면이다. 도 6을 참조하여 홈 노드(NH)는 센서 인터페이스를 통해 센서로부터 입력 데이터를 수신한다. 홈 노드(NH)는 입력 데이터에 대하여 수행할 연산 모델을 결정한다. 예를 들어 홈 노드(NH)는 입력 데이터에 대 하여 연산 모델 A를 수행하기로 결정한다고 가정한다. 홈 노드(NH)는 연산 모델 A의 처리를 위한 예상 연산 부하를 결정한다. 홈 노드(NH) 및 클러스터에 속한 다른 연산 노드는 연산 모델 A에 대하여 담당가능한 연산 부하를 브로드캐스팅 한다. 홈 노드(NH)는 연산 모델 A에 대한 마스터 노드(NMA)를 결정한다. 마스터 노드(NMA)는 연산 모델 A에 대한 태스크(TaskA)를 생성하고, 태스크(TaskA)를 수행할 적어도 하나의 연산 노드를 결정한다. 예를 들어 마스터 노드(NMA)는 클러스터의 연산 노드들 중에서 제 1 연산 노드 및 제 2 연산 노드를 태스크(TaskA)를 수행할 연산 노드로 결정한다고 가정한다. 마스터 노드(NMA)는 제 1 연산 노드 및 제 2 연산 노드의 기여가능한 연산 부하에 기반하여 연산 모델 A에 대한 태스크(TaskA)를 제 1 서브태스크(SubTaskA1) 및 제 2 서브태스크(SubTaskA2)로 분할하여 각각 제 1 연산 노드 및 제 2 연산 노드에 할당한다. 제 1 연산 노드 및 제 2 연산 노드는 제 1 서브태스크(SubTaskA1) 및 제 2 서브태스크(SubTaskA2)를 각각 수행하 고 수행 결과를 마스터 노드(NMA)에게 보고한다. 마스터 노드(NMA)는 제 1 서브태스크(SubTaskA1)의 수행 결과 및 제 2 서브태스크(SubTaskA2)의 수행 결과를 취합 하여 연산 모델 A에 대한 태스크(TaskA)의 연산 결과를 생성한다. 마스터 노드(NMA)는 태스크(TaskA)의 연산 결과를 홈 노드(NH)에게 보고한다. 홈 노드(NH)는 필요에 따라 결과값 을 출력할 수 있다. 도 7a에서 연산 모델의 개수, 태스크의 개수 및 서브태스크의 개수는 예시적인 것이며 이에 제한되지 않음을 통 상의 기술자라면 충분히 이해할 것이다. 도 7b는 일 실시예에 따른 연산 모델 처리 과정을 설명하기 위한 도면이다. 도 7b는 입력 데이터에 대한 연산 모델이 복수 개인 경우를 예시적으로 보여준다. 도 6을 참조하여 홈 노드(NH)는 센서 인터페이스를 통해 센서로부터 입력 데이터를 수신한다. 홈 노드(NH)는 입력 데이터에 대하여 수행할 연산 모델을 결정한다. 예를 들어 홈 노드(NH)는 입력 데이터에 대 하여 연산 모델 A 및 연산 모델 B를 수행하기로 결정한다고 가정한다. 앞서 도 7a에서 설명한 연산 모델 A에 대한 태스크(TaskA)를 생성하고 이를 서브태스크들로 분할하여 수행하는 과정을, 도 7b의 예시에서는 연산 모델 A와 연산 모델 B에 대하여 각각 수행한다. 즉, 클러스터는, 연산 모델 A에 대한 태스크(TaskA)를 생성하고 이를 서브태스크들로 분할하여 수행하는 일련의 과정(도 7b의 연산 모델 A 이하의 과정) 및 연산 모델 B에 대한 태스크(TaskB)를 생성하고 이를 서브태스크들로 분할하여 수행하는 또다른 일련의 과정(도 7b의 연산 모델 B 이하의 과정)을, 순차적으로 또는 병렬적으로 또는 교차적으로 수행할 수 있 다. 도 7b에 도시된 예에서 홈 노드(N-H)는 도 7a에서 전술한 과정에 따라 연산 모델 A에 대한 마스터 노드(NMA)를 결정한다. 마스터 노드(NMA)는 연산 모델 A에 대한 태스크(TaskA)를 생성하고, 서브태스크(SubTaskA1)를 클러스터 내의 연산 노드에 할당할 수 있다. 마찬가지로 홈 노드(N-H)는 도 7a에서 전술한 과정에 따라 연산 모델 B에 대한 마스터 노드(NMB)를 결정한다. 마 스터 노드(NMB)는 연산 모델 B에 대한 태스크(TaskB)를 생성하고, 태스크(TaskB)를 서브태스크(SubTaskB1), 서브 태스크(SubTaskB2) 및 서브태스크(SubTaskB3)로 분할하여 클러스터 내의 연산 노드들에 각각 할당할 수 있 다. 연산이 완료되면 마스터 노드(NMA)는 연산 모델 A에 대한 태스크(TaskA)의 연산 결과를 취합하고 홈 노드(NH)에 게 보고한다. 마스터 노드(NMB)는 연산 모델 B에 대한 태스크(TaskB)의 연산 결과를 취합하고 홈 노드(NH)에게 보고한다. 홈 노드(NH)는 연산 모델 A에 대한 태스크(TaskA)의 연산 결과 및 연산 모델 B에 대한 태스크(TaskB)의 연산 결 과에 기반하여 최종 결과값을 결정할 수 있다. 도 7b에서 연산 모델의 개수, 태스크의 개수 및 서브태스크의 개수는 예시적인 것이며 이에 제한되지 않음을 통 상의 기술자라면 충분히 이해할 것이다. 이하에서는 도 4 및 도 5를 참조하여 연산 모델 처리 방법의 과정에 대하여 살펴본다. 도 4는 일 실시예에 따른 연산 모델 처리 방법의 흐름도이다. 실시예에 따른 연산 모델 처리 방법은 클러스터를 구성하는 복수의 연산 노드에 의해 수행될 수 있다. 복수의 연산 노드는 통신 인터페이스를 통해 상호 연결될 수 있다. 연산 모델 처리 방법은 복수의 연산 노드 중 하나인 홈 노드(NH)가 입력 데이터를 수신하는 단계, 홈 노드 (NH)에 의해, 입력 데이터에 대한 연산 모델을 처리하기 위한 예상 연산 부하를 결정하는 단계, 홈 노드 (NH)의 요청에 응답하여 각 연산 노드(Na)가 기여가능한 연산 부하를 서로 공유하는 단계 및 홈 노드(NH)에 의해, 기여가능한 연산 부하에 기반하여 복수의 연산 노드 중에서 예상 연산 부하를 분배할 마스터 노드(NM)를 결정하는 단계를 포함할 수 있다. 단계에서, 복수의 연산 노드 중 하나인 홈 노드(NH)가 입력 데이터를 수신할 수 있다. 홈 노드(NH)는 센서 인터페이스를 통해 센서로부터 입력 데이터를 수신할 수 있다. 센서로부터 입력 데이터를 수신한 연산 노 드가 입력 데이터에 대한 홈 노드(NH)가 된다. 단계에서, 홈 노드(NH)는 단계에서 수신한 입력 데이터에 대한 연산 모델을 처리하기 위한 예상 연산 부하를 결정할 수 있다. 단계은 단계에서 수신한 입력 데이터에 대한 적어도 하나의 연산 모델을 결정하는 단계를 포함할 수 있다. 이하에서 후술할 예상 연산 부하를 결정하는 단계, 기여가능한 연산 부하를 공유하는 단계 및 마스터 노드(NM)를 결정하는 단계는, 도 7a 및 도 7b를 참조하여 전술한대로, 적어도 하나의 연산 모델의 각 연산 모델별로 수행된다. 홈 노드(NH)는 입력 데이터의 속성에 기반하여 입력 데이터의 분석에 사용할 적어도 하나의 연산 모델을 결정할 수 있다. 입력 데이터의 속성은 입력 데이터의 유형, 크기 및 포맷 등을 포함한다. 단계은 연산 모델의 연산량을 계산하는 단계 및 연산 모델의 대역폭을 계산하는 단계를 포함할 수 있다. 여기서 연산량은 연산 모델을 이용하여 입력 데이터에 대한 학습/추론 알고리즘을 수행하기 위해 필요한 연산량 을 의미한다. 대역폭은 연산 모델의 레이어별로 발생하는 중간 데이터 및 파라미터의 수를 의미한다. 단계(42 0)에서 홈 노드(NH)는 연산 모델의 연산량 및 대역폭에 기반하여 입력 데이터에 대한 연산 모델을 처리하기 위한 예상 연산 부하를 결정할 수 있다. 단계에서, 홈 노드(NH)의 요청에 응답하여 복수의 연산 노드의 각 연산 노드(Na)가 기여가능한 연산 부하를 서로 공유할 수 있다. 단계에서 홈 노드(NH)는 통신 인터페이스를 통해 각 연산 노드(Na)의 기여가능한 연산 부하의 공유를 요청하는 메시지를 브로드캐스팅할 수 있다. 이 때 홈 노드(NH)는 연산 제한 조건을 함께 또는 추가로 브로드캐 스팅할 수 있다. 단계에서 클러스터의 각 연산 노드(Na)는, 단계에서 결정된 예상 연산 부하에 대하여 각 연산 노드 (Na)가 기여가능한 연산 부하를 스스로 결정하고, 결정된 기여가능한 연산 부하를 통신 인터페이스를 통해 브로드캐스팅할 수 있다. 예를 들어 각 연산 노드(Na)는 연산 제한 조건 하에 각 연산 노드(Na)가 기여가능한 연산 부하를 결정할 수 있다. 각 연산 노드(Na)는 자신의 현재 연산 부하, 대기 중인 연산 부하, 각 연산 노드(Na)의 연산 능력 및 가용 한 리소스를 고려하여 예상 연산 부하 중에서 자신이 기여가능한 연산 부하를 결정할 수 있다. 예를 들어 연산 제한 조건이 1분이고 예상 연산 부하가 100인 경우, 제 1 연산 노드(N1)는 자신의 현재 연산 부하, 대기 중인 연산 부하, 연산 능력 및 가용한 리소스를 고려하여 연산 제한 조건인 1분 이내에 제 1 연산 노드(N1)가 기여가 능한 연산 부하를 70으로 결정할 수 있다. 단계에서, 홈 노드(NH)는 단계에서 공유된 기여가능한 연산 부하에 기반하여 복수의 연산 노드 중에 서 예상 연산 부하를 분배할 마스터 노드(NM)를 결정할 수 있다. 일 예에서 홈 노드(NH)는 복수의 연산 노드 중 에서 기여가능한 연산 부하가 가장 큰 연산 노드를 마스터 노드(NM)로 결정할 수 있다. 도 5는 일 실시예에 따른 연산 모델 처리 방법의 흐름도이다. 연산 모델 처리 방법은 도 4를 참조하여 단계에서 결정된 마스터 노드(NM)에 의해, 단계에서 공유된 기여가능한 연산 부하에 기반하여 단계에서 결정된 예상 연산 부하를 복수의 연산 노드 중 적어도 하나의 연산 노드로 분배하는 단계를 더 포함할 수 있다. 마스터 노드(NM)가 예상 연산 부하를 복수의 연산 노드 중 적어도 하나의 노드로 분배하는 단계는, 연산 제한 조 건에 기반하여 예상 연산 부하의 처리에 필요한 적어도 하나의 연산 노드를 선택하는 단계 및 예상 연산 부하를 단계에서 선택된 적어도 하나의 연산 노드로 분배하는 단계를 포함할 수 있다. 단계에서 마스터 노드(NM)는 연산 제한 조건에 기반하여 예상 연산 부하의 처리에 필요한 적어도 하나의 연산 노드를 선택할 수 있다. 연산 제한 조건은 연산 제한 시간을 포함할 수 있다. 연산 제한 시간은 연산 결과에 대한 응답 시간을 의미한다. 연산 제한 조건은 연산 모델의 처리를 담당할 연산 노드의 수에 대한 제한을 포함할 수 있다. 일 예에서 도 4를 참조하여 단계에서 홈 노드(NH)는 통신 인터페이스를 통한 브로드캐스팅 방식으로 연산 제한 조건을 복수의 연산 노드와 공유할 수 있다. 단계에서 마스터 노드(NM)는 연산 제한 조건을 만족하기 위하여 예상 연산 부하의 처리에 필요한 적어도 하나의 연산 노드를 선택할 수 있다. 이 과정에서 마스터 노드(NM)는 도 4를 참조하여 단계에서 공유된 각 연산 노드(Na)의 기여가능한 연산 부하를 고려한다. 단계에서 마스터 노드(NM)는 예상 연산 부하를 단계에서 선택된 적어도 하나의 연산 노드로 분배할 수 있다. 예를 들어 마스터 노드(NM)는 입력 데이터를 구간별 및/또는 피처별로 나누어서 단계에서 선택된 적어도 하나의 연산 노드로 분배할 수 있다. 예를 들어 마스터 노드(NM)는 연산 모델을 분산형 구조로 확장하여 단계에서 선택된 적어도 하나의 연산 노드로 분배할 수 있다. 추가적으로 연산 모델 처리 방법은, 단계에서 예상 연산 부하를 분배받은 적어도 하나의 연산 노드의 각각 이 연산 모델에 기반한 학습/추론을 위한 연산을 수행하는 단계를 더 포함할 수 있다. 또한, 연산 모델 처리 방법은, 마스터 노드(NM)가 단계에서 예상 연산 부하를 분배받은 적어도 하나의 연 산 노드로부터 연산 결과를 수신하고, 수신된 연산 결과를 취합하는 단계를 더 포함할 수 있다. 마스터 노드(NM)는 단계에서 취합된 연산 결과를 홈 노드(NH)로 전송한다. 홈 노드(NH)는 마스터 노드(NH) 로부터 연산 결과를 수신한다. 홈 노드(NH)가 도 4를 참조하여 단계에서 입력 데이터에 대한 적어도 하나의 연산 모델을 결정한 경우, 단 계에서 마스터 노드(NM)는 각 연산 모델 마다 결정된다. 마스터 노드(NH)는 도 5의 단계 내지 단계 를 수행하고, 홈 노드(NH)는 각 연산 모델의 마스터 노드(NH)로부터 각 연산 모델의 연산 결과를 수신한다. 홈 노드(NH)는 적어도 하나의 연산 모델의 연산 결과를 서로 비교하고, 비교의 결과에 따라 하나의 결과값을 결 정하여 출력할 수 있다. 예를 들어 홈 노드(NH)는 가장 좋은 결과값을 선택할 수 있다. 예를 들어 홈 노드(NH)는 평균치 또는 중간값을 출력할 수 있다. 일 예에서 홈 노드(NH)는 각 연산 모델의 마스터 노드(NH)로부터 수신한 연산 결과를 모두 출력할 수 있다. 도 8은 일 실시예에 따른 연산 모델 처리 과정의 신호 흐름도이다. 단계에서 홈 노드(NH)는 센서 인터페이스를 통해 입력 데이터를 수신한다. 입력 데이터에 대한 연산 모델을 결정한다. 클러스터에 포함된 복수의 노드 중 입력 데이터를 수신한 노드가 입력 데이터에 대한 홈 노드 (NH)의 기능을 수행한다. 단계에서 홈 노드(NH)는 입력 데이터에 대하여 연산 모델을 수행하기 위해 필요한 예상 연산 부하 및 홈 노드(NH)가 연산 모델의 수행에 기여가능한 연산 부하를 결정한다. 단계에서 홈 노드(NH)는 연산 모델을 수행하는 태스크 정보를 생성한다. 예를 들어 태스크 정보는 태스크 ID, 입력 데이터 정보 및, 연산 모델 정보 및 연산 제한 조건을 포함할 수 있다. 홈 노드(NH)는 태스크 정보를 포함하는 메시지(BROADCAST_CANDIDATE_REQUEST)를 통신 인터페이스를 통해 브로드캐스팅한다. 단계, 단계 및 단계에서 메시지(BROADCAST_CANDIDATE_REQUEST)를 수신한 클러스터 내의 각 연 산 노드는 태스크 정보를 확인하고, 기여가능한 연산 부하를 결정한다. 단계에서 각 연산 노드는 태스크 ID, 연산 노드 ID 및 기여가능한 연산 부하를 포함하는 메시지 (BROADCAST_CANDIDATE_RESPONSE)를 통신 인터페이스를 통해 각각 브로드캐스팅한다. 단계에서 메시지(BROADCAST_CANDIDATE_RESPONSE)를 수신한 홈 노드(NH)는 각 연산 노드의 기여가능한 연산 부하에 기반하여 마스터 노드(NM)을 결정한다. 단계에서 홈 노드(NH)는 태스크 ID 및 단계에서 결정된 마스터 노드의 ID를 포함하는 메시지 (BROADCAST_MASTER_DESIGNATE)를 통신 인터페이스를 통해 브로드캐스팅한다. 단계 내지 단계은 홈 노드(NH)가 연산 모델의 수행을 담당할 마스터 노드(NM)를 결정하기 위한 일련의 단계들로서 도 4를 참조하여 전술한 단계 내지 단계에서 수행되는 동작들을 메시지의 흐름과 함께 보 여준다. 이하에서 설명할 단계 내지 단계은 연산 모델을 연산하는 일련의 단계들로서 도 5를 참조하여 전술한 단계 내지 단계에서 수행되는 동작들을 메시지의 흐름과 함께 보여준다. 단계에서 마스터 노드(NM)는 연산 모델의 연산을 수행할 적어도 하나의 연산 노드를 선택한다. 단계에서 마스터 노드(NM)는 단계에서 선택한 적어도 하나의 연산 노드에게 예상 연산 부하를 분배한 다. 단계에서 마스터 노드(NM)는 단계에서 선택한 적어도 하나의 연산 노드 간의 통신을 위한 멀티캐스트 채널을 수립한다. 멀티 캐스트 채널은 통신 인터페이스를 통해 제공된다. 메시지(MULTICAST_CHANNEL_SETUP)는 태스크 ID 및 멀티캐스트 채널 정보를 포함할 수 있다. 멀티캐스트 채널 정 보는 예를 들어 멀티캐스트 채널 ID 및 멀티캐스트 채널로 연결된 적어도 하나의 연산 노드 ID를 포함할 수 있 다. 단계, 단계 및 단계에서, 멀티캐스트 채널로 연결된 적어도 하나의 연산 노드의 각 연산 노드 는 연산 모델에 대한 기여가능한 연산 부하를 각각 수행한다. 단계에서, 멀티캐스트 채널로 연결된 적어도 하나의 연산 노드는, 단계, 단계 및 단계에서 연산 모델의 연산 중에 수반되는 중간 데이터를 멀티캐스트 채널을 통해 공유할 수 있다. 이를 위하여 메시지 (MULTICAST_DATA_SHARE)는 멀티캐스트 채널 ID 및 중간 데이터를 포함할 수 있다. 단계, 단계 및 단계에서 멀티캐스트 채널로 연결된 적어도 하나의 연산 노드는 각각 연산 결과 를 도출하고, 단계에서 연산 결과를 멀티캐스트 채널로 공유한다. 메시지(MULTICAST_RESULT_SHARE)는 멀티 캐스트 채널 ID, 연산 노드 ID 및 연산 결과를 포함할 수 있다. 단계에서 마스터 노드(NM)는 단계에서 공유된 결과를 취합한다. 단계에서 마스터 노드(NM)는 취합된 연산 결과를 홈 노드(NH)에게 전송한다. 메시지 (UNICAST_RESULT_REPORT)는 태스크 ID 및 취합된 연산 결과를 포함한다. 단계에서 홈 노드(NH)는 취합된 연산 결과를 수신한다. 도 9는 일 실시예에 따른 연산 모델 처리 과정의 메시지 구조를 예시적으로 보여주는 표이다. 도 9에 도시된 표는 연산 모델 처리 과정에서 사용되는 예시적인 메시지를 보여준다. 메시지(BROADCAST_CANDIDATE_REQUEST)는 도 8을 참조하여 단계에서 홈 노드(NH)로부터 클러스터 내의 모든 연산 노드로 브로드캐스팅된다. 메시지(BROADCAST_CANDIDATE_REQUEST)는 전술한 태스크 정보를 포함할 수있다. 메시지(BROADCAST_CANDIDATE_RESPONSE)는 도 8을 참조하여 단계에서 각 연산 노드가 브로드캐스팅하 는 메시지이다. 메시지(BROADCAST_CANDIDATE_RESPONSE)는 태스크 ID, 연산 노드 ID 및 각 연산 노드의 기여가 능한 연산 부하를 포함할 수 있다. 메시지(BROADCAST_MASTER_DESIGNATE)는 도 8을 참조하여 단계에서 홈 노드(NH)로부터 클러스터 내의 모든 연산 노드로 브로드캐스팅된다. 메시지(BROADCAST_MASTER_DESIGNATE)는 태스크 ID 및 마스터 노드 ID를 포함할 수 있다. 도 8을 참조하여 단계의 메시지(MULTICAST_CHANNEL_SETUP), 단계의 메시지(MULTICAST_DATA_SHARE) 및 단계의 메시지(MULTICAST_RESULT_SHARE)는 연산 모델을 연산하도록 선택된 적어도 하나의 연산 노드를 위한 멀티캐스트 채널에서 멀티캐스팅되는 메시지이다. 메시지(UNICAST_RESULT_REPORT)는 도 8을 참조하여 단계에서 마스터 노드(NM)로부터 홈 노드(NH)에게 전송 되는 메시지로서, 태스크 ID 및 연산 결과를 포함할 수 있다. 도 10은 일 실시예에 따른 태스크 테이블의 구조를 보여주는 예시적으로 표이다. 태스크 테이블은 연산 모델을 수행하는 태스크의 태스크 정보를 저장하기 위한 데이터 구조이다. 마스터 노드(NM)는 도 7a 또는 도 7b를 참조하여 태스크(예를 들어 TaskA)를 관리하기 위한 프로세스를 생성하고 태스크 테이블에 저장된 정보에 기반하여 태스크를 관리할 수 있다. 마스터 노드(NM)는 수행 중인 태스크의 태스 크 테이블을 태스크 리스트로서 관리할 수 있다. 태스크 테이블은 태스크를 식별하기 위한 태스크 ID, 태스크가 수행하는 연산 모델을 식별하기 위한 모델 ID, 입력 데이터 정보, 연산 제한 조건, 태스크를 수행하도록 선택된 적어도 하나의 연산 노드를 위한 멀티캐스 트 채널을 식별하기 위한 멀티캐스트 채널 ID 및 태스크를 수행하도록 선택된 적어도 하나의 연산 노드에 대한 정보인 노드 리스트를 포함할 수 있다. 이상 설명된 실시예에 따른 연산 모델의 병렬적 처리 방법은 다중 모델의 동적 스케줄링을 제공할 수 있다. 다중 모델의 동적 스케줄링이란 입력 데이터(예를 들어 영상, 오디오 등)를 연산 제한 조건(예를 들어 학습/추 론 제한 시간) 하에 다중 모델(적어도 하나의 연산 모델)로 분석하기 위하여 클러스터에 포함된 복수의 연산 노 드 중 연산 모델의 연산에 대한 연산 부하를 수행할 적어도 하나의 연산 노드를 결정하고, 결정된 적어도 하나 의 연산 노드 간에 각 연산 모델의 연산 로드를 분배하는 작업을 의미한다. 실시예에 따르면, 각 연산 노드가 수행가능한 연산 모델이 고정되어 있지 않고 획득된 입력 데이터의 속성, 각 노드의 현재 상태(예를 들어 현재/대기 중인 연산 부하) 및 연산 제한 조건에 따라 다중 모델을 수행할 연산 노 드 및 다중 모델 수행에 있어서 각 연산 노드가 담당할 연산 부하를 동적으로 결정한다는 점에서 동적 스케줄링 이 가능하게 된다. 실시예에 따른 연산 노드, 복수의 연산 노드를 포함하는 클러스터 및 복수의 연산 노드에 의한 연산 모델 처리 방법은 다양한 제품 및 서비스에 적용되어 인공 지능에 의한 인식률을 개선할 수 있다. 예를 들어 실시예에 따른 클러스터는 홈 로봇, 로봇 청소기, 에어컨, 세탁기 및 냉장고와 같은 가전 제품에 인 공 지능 칩으로 장착되어 인공 지능 알고리즘에 기반한 작동을 제공할 수 있다. 또한 실시예에 따른 연산 모델 처리 방법은 영상과 음성을 동시에 인식하여 통합 플랫폼에 기반한 인공 지능 기 능을 구현할 수 있다. 예를 들어 제 1 연산 노드는 비전 센서로부터 수신하고, 제 2 연산 노드는 음성 센서로부 터 음성 데이터를 수신하여 클러스터에서 영상 데이터 및 음성 데이터에 대한 연산 모델을 동시에 연산할 수 있 다. 이상 설명된 실시예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램의 형태로 구현 될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프 로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다.한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명의 명세서(특히 청구범위에서)에서 \"상기\"의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모 두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값 을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하는 각 개별적인 값을 기재한 것과 같다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위가 한 정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 청구의 범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 청구의 범위뿐만 아니라 이 청구의 범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다. 앞에서, 본 발명의 특정한 실시예가 설명되고 도시되었지만 본 발명은 기재된 실시예에 한정되는 것이 아니고, 이 기술 분야에서 통상의 지식을 가진 자는 본 발명의 사상 및 범위를 벗어나지 않고서 다른 구체적인 실시예로 다양하게 수정 및 변형할 수 있음을 이해할 수 있을 것이다. 따라서, 본 발명의 범위는 설명된 실시예에 의하여 정하여 질 것이 아니고 청구범위에 기재된 기술적 사상에 의해 정하여져야 할 것이다."}
{"patent_id": "10-2019-0163982", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 연산 노드의 블록도이다. 도 2는 일 실시예에 따른 상호연결된 복수의 연산 노드의 블록도이다. 도 3a는 일 실시예에 따른 복수의 연산 노드의 동작을 설명하기 위한 도면이다. 도 3b는 일 실시예에 따른 복수의 연산 노드의 동작을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 연산 모델 처리 방법의 흐름도이다. 도 5는 일 실시예에 따른 연산 모델 처리 방법의 흐름도이다. 도 6은 일 실시예에 따른 클러스터의 연산 모델 처리 동작을 설명하기 위한 도면이다. 도 7a는 일 실시예에 따른 연산 모델 처리 과정을 설명하기 위한 도면이다. 도 7b는 일 실시예에 따른 연산 모델 처리 과정을 설명하기 위한 도면이다. 도 8은 일 실시예에 따른 연산 모델 처리 과정의 신호 흐름도이다. 도 9는 일 실시예에 따른 연산 모델 처리 과정의 메시지 구조를 예시적으로 보여주는 표이다. 도 10은 일 실시예에 따른 태스크 테이블의 구조를 예시적으로 보여주는 표이다."}
