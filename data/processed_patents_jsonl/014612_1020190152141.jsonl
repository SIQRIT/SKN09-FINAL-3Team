{"patent_id": "10-2019-0152141", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0063701", "출원번호": "10-2019-0152141", "발명의 명칭": "실시간 분산 자율주행 시뮬레이션 프레임워크를 구성 및 제어하는 방법", "출원인": "(주)이노시뮬레이션", "발명자": "김구"}}
{"patent_id": "10-2019-0152141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "다양한 시나리오에서 자율주행 알고리즘 검증을 용이하게 하는 서버와, 센서 시뮬레이션 및 카메라 렌더링 장치들을 클라이언트로 하며, 이들을 서로 동기화하여 제어하는 시뮬레이터로 구성된 실시간 분산 자율주행 시뮬레이션 프레임워크를 구성 및 제어하는 방법으로서,상기 자율주행 시뮬레이션 프레임워크는 공통의 시뮬레이션 모델 및 엔진을 포함 하는 모델 시스템, 센서 및 3차원 영상을 재현 하는 영상 시스템, 그리고 각 시스템을 통신 기반으로 서로 연동 제어하는 제어 시스템으로구성되고,각 시스템들은 멀티 프로세스, 분산 컴퓨팅 환경에서 IPC 및 이더넷 통신 계층을 통해 서로 연동될 수 있도록하며, 전통적인 M&S의 모델과 시뮬레이션 관계를 유지하면서 교체 시험이 용이하도록 추상화된 모델의 인터페이스 계층으로 제어되며,자율주행 도메인에 공통된 개념의 주행 환경 및 객체, 시나리오 등의 주행 DB와 3차원 환경 렌더링을 위한 영상DB를 구분하고, 여러 클라이언트에서 나누어 센서 에뮬레이션을 수행하여 시뮬레이션 부하를 분산시키며,물리적으로, 서버(10)와 클라이언트(30) 사이에 시뮬레이터(20)가 연결되도록 구성된 것을 특징으로 하는 실시간 분산 자율주행 시뮬레이션 프레임워크를 구성 및 제어하는 방법."}
{"patent_id": "10-2019-0152141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 자율주행 시뮬레이션에 대한 아키텍쳐는 MVC 기반으로 구성되고,모델부(40), 제어부(50), 영상부(60)으로 이루어지며,상기 모델부(40)는 자율주행의 주행 알고리즘을 검증하기 위한 각 주행 환경 및 객체 상태, 그리고 동작(행위)및 상호작용을 공통의 개념적인 컴포넌트 모델로 표현하며, 타임스탬프(time-stamp)가 포함된 실제 또는 가상으로 측정된 주변 환경 및 개체 정보(데이터)와 물리적, 수학적 제어 로직을 함께 캡슐화하여 관리하며,다양한 자율주행 알고리즘 및 교통 상황, 주행 시나리오, 차량 동역학 등 기존 서브시스템의 데이터와 제어 로직의 관계는 유지하면서, 각 서브시스템 공통의 고수준 상태 및 행위를 포함한 컴포넌트로 추상화하며,상기 제어부(50)의 지시에 따라 모델부에서 직접 서브시스템이 처리될 수 있도록 구성하여 부하 분산 및 다양한시나리오 시험을 용이 하도록 하며,상기 모델부(40)의 통신 계층은 분산 환경으로 확장이 용이하도록, 주행 상태의 감지된 변경을 영상부(60) 및제어부(50)와 통신하며, 전통적인 MVC의 옵저버 매커니즘을 적용하여 커플링과 동기화 문제를 해결하고, 대용량분산 데이터의 실시간 처리를 위한 별도의 데이터베이스를 쉽게 추가할 수 있도록 한 것을 포함하는 실시간 분산 자율주행 시뮬레이션 프레임워크를 구성 및 제어하는 방법."}
{"patent_id": "10-2019-0152141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 영상부(60)에서,실제 자율주행은 차량에 탑재된 레이다, 라이다 및 카메라, GPS 센서 등에서 측정된 데이터를 기반으로 차량,보행자 및 도로 정보 등의 주변 환경을 인식하도록 구성되며,공개특허 10-2021-0063701-3-시뮬레이션에서도 차량에 탑재된 각종 센서들을 가상의 주행 환경에서 모사하기 위해, 영상 DB, 센서 및 카메라에뮬레이션 시스템, 영상 렌더링 시스템으로 자율주행 시뮬레이션의 영상 생성 장치를 구성하며,영상 객체 모델은 주행 환경 및 시나리오의 시뮬레이션 상태를 모델로부터 얻어 영상으로 재현하고, 주기적으로가상 센서의 에뮬레이션 결과인 자율주행 소스 데이터를 데이터베이스에 추가하며 제어기에 캡처 이벤트를 전달하며,영상부(60)는 고성능 3차원 렌더링 엔진을 탑재한 하나 이상의 시스템으로 구성하여 다양한 가상 카메라 및 센서의 신호 생성의 부하를 분산 시키고 시뮬레이션의 정확성을 높일 수 있도록 하며, 이를 위해 시뮬레이션 모델을 각 3차원 렌더링 엔진의 모델로 재현하기 위해 개별적인 영상 파일을 로딩한 후, 영상 객체 모델을 통해모델부(40)의 주행 객체 정보와 동기화하는 것을 포함하는 실시간 분산 자율주행 시뮬레이션 프레임워크를 구성및 제어하는 방법."}
{"patent_id": "10-2019-0152141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 2에 있어서,상기 제어부(50)는 모의실험에 필요한 각종 환경 설정, HILS/SILS 검증 등 전체적인 시뮬레이션의 감독, 통제의역할을 수행하며, 시험조건에 시나리오 관리, 이벤트 설정 및 각종 데이터 수집과 모니터링 및 분석이 가능하도록 하며, 시뮬레이터는 시뮬레이션 운영/제어와 서브시스템간의 인터페이스, 진단 기능을 제공하며,상기 제어부(50)는 내/외부 사건(렌더러 이벤트, 상태변화 등)의 처리를 전담하고, 생명 주기 및 데이터 동기화된 모델의 로직을 제어하고, 이때 제어부에서 수행 가능한 이벤트를 먼저 처리하고, 불가능한 이벤트는 모델부(40)의 통신 계층을 통해 그 처리를 위임하며, 사용자 및 타 시뮬레이션, 타 응용체계 등과 모델을 연결하는 인터페이스 기능을 수행하고, 인공지능 및 자동차 동역학과 같은 시뮬레이션 주기의 로직을 직/간접 제어하며,영상부(60)와 달리 로드타임에는 시스템 설정만을 로딩하고, 모델부(40) 제어의 대리자 역할을 수행하며, 런타임에는 영상부(50)에서 수집된 이벤트를 처리하도록 모델부(40)를 제어하고, 모델부(40)의 주행 상태 변경으로트리거된 시그널을 영상으로 재현 할 수 있도록 영상부(60)에 지시하는 것을 포함하는 실시간 분산 자율주행 시뮬레이션 프레임워크를 구성 및 제어하는 방법."}
{"patent_id": "10-2019-0152141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 시뮬레이터는 M&S 엔진의 상세한 모델 정보를 자율주행의 개념적 컴포넌트로 함축하여 모델링하며, 이를통해, 복잡한 M&S 엔진들은 무결성의 손실 없이 시뮬레이션 환경 개발을 위한 확장 가능한 토대를 마련하도록하며,상기 시뮬레이터는 게임 엔진에 확장 가능한 플러그인 형태로 시뮬레이션 엔진과 연동하도록 구성하고, 검증용센서 및 인공지능 알고리즘 또한 플러그인으로 관리되도록 하며, 모델 서버과 영상 클라이언트 사이의 분산 환경 시뮬레이션 제어는 타이밍, 동기화, 병렬성, 데이터 포맷과 같은 통신 문제가 있고, 제어 흐름상의 문맥에 맞는 시뮬레이션 엔진의 생명주기 관리와 통신 계층의 중계 역할을통해 이 문제를 해소하도록 한 것을 포함하는 실시간 분산 자율주행 시뮬레이션 프레임워크를 구성 및 제어하는방법."}
{"patent_id": "10-2019-0152141", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 다양한 시나리오에서 자율주행 알고리즘 검증을 용이하게 하는 서버와, 센서 시뮬레이션 및 카메라 렌 더링 장치들을 클라이언트로 하며, 이들을 서로 동기화하여 제어하는 시뮬레이터로 구성된 실시간 분산 자율주행 시뮬레이션 프레임워크를 구성 및 제어하는 방법에 관한 것으로, 다양한 시나리오에서 자율주행 알고리즘 검증을 (뒷면에 계속)"}
{"patent_id": "10-2019-0152141", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 다양한 시나리오에서 자율주행 알고리즘 검증을 용이하게 하는 서버와, 센서 시뮬레이션 및 카메라 렌더링 장치들을 클라이언트로 하며, 이들을 서로 동기화하여 제어하는 시뮬레이터로 구성된 실시간 분산 자율주행 시뮬레이션 프레임워크를 구성 및 제어하는 방법에 관한 것이다."}
{"patent_id": "10-2019-0152141", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "등록번호 10-1916838(자율 주행차량용 시뮬레이션 장치)호에 따르면, \"자율 주행차량용 시뮬레이션 장치는, 지 면에 설치되는 판재형상의 베이스유닛 및 이 베이스유닛의 상부에 간격을 두고 설치되되 그 상부로 차량이 올려 지는 탑재공간을 제공하는 가동유닛; 상기 베이스유닛과 가동유닛의 사이에 설치되어 차폭방향으로 기울어짐을 유도하는 롤링유닛 및 상·하 방향으로 탄성지지력을 작용하는 밸런스유닛; 상기 가동유닛의 상부에 설치되어 차량의 바퀴가 구름 접촉되는 것에 의해 순환 이동되는 트랙벨트 및 이 트랙벨트에 연결되어 연동 회전되어 관 성모멘트를 발생시키는 기어모듈을 구비한 관성유닛; 상기 가동유닛에 일단이 고정되고 타단은 트랙벨트와 위치 간섭없이 상기 차량의 전륜 또는 후륜측 차체하부를 고정 지지하도록 구비되어 조향방향에 따라 회전되게 구비 되는 조향연동유닛으로 구성된다. 이와 같이 구성되는 본 발명에 따른 자율 주행차량용 시뮬레이션 장치는, 실제 도로 주행환경과 유사한 물리적 주행환경의 구현을 통해 차량의 움직임을 능동적으로 구현 및 해석할 수 있으므로 이를 바탕으로 한 자율주행 빅데이터 수집이 가능할 뿐만 아니라 오락이나 기타 어려 콘텐츠로의 적용이 가능하므로 제품에 대한 만족도를 높일 수 있는 유용한 효과가 기대된다. 또한 여러 가지 환경의 주행을 하기 원하는 사용자라면 실제 운행시 느낄 수 있는 생생한 운전시의 느낌을 체감 할 수 있기 때문에 다양한 게임요소를 가진 콘텐츠로의 활용이 가능하고, 차별화된 재미와 호기심을 충족시킬 수 있는 효과가 있다. 또한, 본 발명은 글로벌 자동차 시장을 대상으로 실제 주행과 유사한 환경을 제공하는 신뢰성 높은 자율주행 시 뮬레이터의 개발을 통해 국산화가 가능할 뿐만 아니라 글로벌 자동차 시장을 대상으로 판로를 개척하여 수출할 경우 큰 재원창출이 기대되며, 자율주행 시장에 부합하는 인력에 대한 고용증대 및 4차 산업에 대비하여 국내외 산업 및 국가 기술경쟁력의 제고가 가능한 산업상 대단히 유용한 효과가 기대된다.\"라고 개시된 바가 있다. 등록번호 10-1984762(네트워크 플랫폼을 적용한 자율주행차량 시뮬레이터)호에 따르면, \"데이터베이스 내의 데 이터를 기반으로 가동되는 시뮬레이터를 운용하는 자율주행차량 시뮬레이터 시스템으로, 데이터베이스 내 하나 의 자율주행차량 데이터가 복수의 데이터셋(Dataset)으로 구획되되, 각각의 데이터셋은 적어도 하나 이상의 데 이터패킷(Datapacket)을 포함하도록 구성되어, 상기 각각의 데이터셋 내 하나의 데이터패킷이 선택되도록 구성 되어 다수의 사용자들이 자신들의 알고리즘을 서로 공유하거나, 다른 알고리즘과의 호환을 통해 보다 다양한 환 경에서의 시뮬레이션이 가능하도록 제공되는 자율주행차량 시뮬레이터 시스템에 관한 것이다.\"라고 개시된 바가 있다. 공개번호 10-2014-0144921(가상현실을 이용한 무인 자동차의 자율 주행 시뮬레이션 시스템)호에 따르면, \"3차원 가상현실 내에서 가상의 무인 자동차의 자율 주행 알고리즘을 검증하기 위해 자율 주행 시뮬레이션을 수행하는 가상현실을 이용한 무인 자동차의 자율 주행 시뮬레이션 시스템에 관한 것이다. 본 발명에 따른 가상현실을 이용한 무인 자동차의 자율 주행 시뮬레이션 시스템은, 가상현실 환경이 모델링된 3 차원 영상 정보를 제공하여 자율 주행 시뮬레이션을 구동하는 시뮬레이터부와, 상기 시뮬레이터부에서 제공되는 3차원 영상 내에서 가상의 자동차를 자율 주행시키고, 자율 주행되는 가상의 자동차의 상태정보 및 가상의 자동 차에서 취득하는 주행정보를 수신하는 시뮬레이션 서버와, 상기 시뮬레이션 서버에서 수신한 상태정보 및 주행 정보를 수신하여 로봇서버 타입의 데이터로 변환하여 출력하는 시뮬레이션 컴포넌트 및 상기 시뮬레이션 컴포넌 트에서 출력되는 OPRoS 타입의 데이터를 수신하여 GUI(Graphical User Interface)로 디스플레이하는 시뮬레이션 모니터부를 포함하는 것을 특징으로 한다.\"라고 개시된 바가 있다. 등록번호 10-1850038(자동차 시뮬레이터 장치 및 그 방법)호에 따르면, \"자동차 시뮬레이터 장치 및 그 방법을 개시한다. 본 발명에 따른 자동차 시뮬레이터 장치는 적어도 하나의 편집모듈을 포함하여 구성되고, 상기 적어 도 하나의 편집모듈을 통해 도로 정보, 객체 정보, 교통 정보와 운행 정보를 입력하는 입력부, 상기 입력된 도 로 정보, 객체 정보, 교통 정보와 운행 정보에 따라 가상현실 환경의 3차원 영상 내에서 모델링된 가상의 자동 차를 자율 주행시키고, 상기 자율 주행 중인 자동차에 대한 상태 정보와 주행 정보를 취득하는 시뮬레이터부, 및 상기 시뮬레이터부에서 취득한 상태 정보와 주행 정보를 수신하여 가상의 3차원 영상으로 출력하는 시뮬레이 터 모니터링부를 포함할 수 있다. 본 발명에 따르면, 도로, 객체, 시나리오의 생성 및 편집을 용이하게 하고, 모델링된 3차원 영상의 실시간 검증이 가능한 효과가 있다.\"라고 개시된 바가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 등록번호 10-1916838(자율 주행차량용 시뮬레이션 장치) (특허문헌 0002) 2. 등록번호 10-1984762(네트워크 플랫폼을 적용한 자율주행차량 시뮬레이터) (특허문헌 0003) 3. 공개번호 10-2014-0144921(가상현실을 이용한 무인 자동차의 자율 주행 시뮬레이션 시스템) (특허문헌 0004) 4. 등록번호 10-1850038(자동차 시뮬레이터 장치 및 그 방법)"}
{"patent_id": "10-2019-0152141", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "최근 수년간, 자율주행 기술과 관련하여, 인공지능 및 센서 퓨전, 통신 등 자율주행과 관련하여 많은 연구가 이 루어지고 있다. 특히, 인공지능에 필요한 다양한 주행환경 및 시나리오의 방대한 학습 데이터를 가상의 자율주 행 시뮬레이터를 통해 쉽게 재현해낼 수 있어, 이와 관련한 연구가 활발히 진행 중이다. 자율주행 시뮬레이터는 고품질의 주행 환경을 쉽게 구현할 수 있다는 장점 때문에 게임 엔진 기반으로 많이 개 발되고 있지만, 복잡해지고 대규모화 되고 다양한 주행 환경을 요구하고 있어 점차 그 한계를 보이고 있다. 첫째, 다수의 정밀한 센서 점군 시뮬레이션 및 카메라 렌더링의 포토리얼리즘을 위해서는 단일 시스템 구성에서 는 성능의 한계가 존재한다. 실제 자율주행에 사용되는 센서는 라이다, 레이다, 카메라, GPS 등이 여러 개(보통 10개 수준) 사용 되고, 차량의 ECU, 가속도, 자이로 등의 센서 등을 포함하면 수많은 센서 신호들이 한꺼번에 밀려들어 올 수 있다. 센서 시뮬레이션에서 핵심 센서인 라이다의 경우 많은 양(대략 초당 백만)의 점군 데이터를 생성해야 하며, 센 서마다 다른 샘플링 주기, 해상도, 유효 거리, 노이즈 특성을 갖는다. 이는 주로 게임 엔진의 CPU ray casting 또는 GPU depth buffer 기반으로 개발되는데, 다수 센서의 정밀 시뮬레이션을 위해서는 구현이 어렵고 성능의 한계가 존재한다. 카메라 렌더링은 사진 측량(Photogrammetry), 물리 기반 렌더링(Physically Based Rendering) 등의 방식으로 실사와 같은 렌더링이 필요하지만, 구현이 어렵고 센서와 마찬가지로 많은 리소스를 사용한다. 둘째, 자율주행 인지 알고리즘의 검증 및 학습에 필수적인 정답 데이터(Ground Truth)와 시나리오를 게임 엔진 으로부터 생성하기 때문에 시뮬레이션 모델이 렌더링 모델에 의존적인 문제가 있다. 시뮬레이션 모델은 자율주 행차량 및 차선의 위치, 크기, 종류 등의 3차원 데이터와 센서에서 추출된 이미지 등의 개념적이며 추상화된 모 델로 단순화할 필요가 있다. 게임 엔진에서 지원하는 도로망 제작 플러그인은 복잡한 교차로 등에 많은 수작업이 필요하고, 차선 정보 및 도 로망 토폴로지 추출을 지원하지 않는다. 도로망 제작에 특화된 3rd party 편집 도구를 통해 생성된 차선 편집 및 3차원 메쉬나 HD 맵을 지원할 수 있도록 공통의 시뮬레이션 모델로 단순화할 필요가 있다. 셋째, 자율주행 알고리즘을 빠르고 안전하게 개발, 시험, 검증에 효과적인 시뮬레이터 제어 방법(SIL/HIL, Open/Closed loop, Whole/Partial stack 등)이 부족하다. 정답 데이터를 기준으로 일부 자율주행 알고리즘의 단일 시험, 타 자율주행 시스템으로 교체 시험, 실제 카메라 또는 ECU 연동, 렌더링 엔진 교체 시험, 시나리오 동적 변경 등의 다양한 시험이 가능하도록 외부 시스템과의 체계화된 시뮬레이션 융합 기반 기술이 시급한 상황 이다. 본 발명은 다양한 시나리오에서 자율주행 알고리즘 검증을 용이하게 하는 서버와, 센서 시뮬레이션 및 카메라 렌더링 장치들을 클라이언트로 하며, 이들을 서로 동기화하여 제어하는 시뮬레이터로 구성된 실시간 분산 자율주행 시뮬레이션 프레임워크 구성 및 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0152141", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 다양한 시나리오에서 자율주행 알고리즘 검증을 용이하게 하는 서버와, 센서 시뮬레이션 및 카메라 렌더링 장치들을 클라이언트로 하며, 이들을 서로 동기화하여 제어하는 시뮬레이터로 구성된 실시간 분산 자율 주행 시뮬레이션 프레임워크를 구성 및 제어하는 방법으로 구현된다. 이러한 본 발명의 특징들을 살펴보면 다음과 같다. 상기 자율주행 시뮬레이션 프레임워크는 공통의 시뮬레이션 모델 및 엔진을 포함 하는 모델 시스템, 센서 및 3 차원 영상을 재현 하는 영상 시스템, 그리고 각 시스템을 통신 기반으로 서로 연동 제어하는 제어 시스템으로 구성되고; 각 시스템들은 멀티 프로세스, 분산 컴퓨팅 환경에서 IPC 및 이더넷 통신 계층을 통해 서로 연동될 수 있도록 하며, 전통적인 M&S의 모델과 시뮬레이션 관계를 유지하면서 교체 시험이 용이하도록 추상화된 모델 의 인터페이스 계층으로 제어되며; 자율주행 도메인에 공통된 개념의 주행 환경 및 객체, 시나리오 등의 주행 DB와 3차원 환경 렌더링을 위한 영상 DB를 구분하고, 여러 클라이언트에서 나누어 센서 에뮬레이션을 수행하여 시뮬레이션 부하를 분산시키며; 물리적으로, 서버와 클라이언트 사이에 시뮬레이터가 연결되도록 구성된 것이다. 실시예에서, 상기 자율주행 시뮬레이션에 대한 아키텍쳐는 MVC 기반으로 구성되고, 모델부, 제어부, 영 상부으로 이루어지며, 상기 모델부는 자율주행의 주행 알고리즘을 검증하기 위한 각 주행 환경 및 객체 상태, 그리고 동작(행위) 및 상호작용을 공통의 개념적인 컴포넌트 모델로 표현하며, 타임스탬프(time-stamp)가 포함된 실제 또는 가상으로 측정된 주변 환경 및 개체 정보(데이터)와 물리적, 수학적 제어 로직을 함께 캡슐화 하여 관리하며, 다양한 자율주행 알고리즘 및 교통 상황, 주행 시나리오, 차량 동역학 등 기존 서브시스템의 데 이터와 제어 로직의 관계는 유지하면서, 각 서브시스템 공통의 고수준 상태 및 행위를 포함한 컴포넌트로 추상 화하며, 상기 제어부의 지시에 따라 모델부에서 직접 서브시스템이 처리될 수 있도록 구성하여 부하 분산 및 다양한 시나리오 시험을 용이 하도록 하며, 상기 모델부의 통신 계층은 분산 환경으로 확장이 용이하도 록, 주행 상태의 감지된 변경을 영상부 및 제어부와 통신하며, 전통적인 MVC의 옵저버 매커니즘을 적용 하여 커플링과 동기화 문제를 해결하고, 대용량 분산 데이터의 실시간 처리를 위한 별도의 데이터베이스를 쉽게 추가할 수 있도록 한 것을 포함하는 것이다. 실시예에서, 상기 영상부에서, 실제 자율주행은 차량에 탑재된 레이다, 라이다 및 카메라, GPS 센서 등에서 측정된 데이터를 기반으로 차량, 보행자 및 도로 정보 등의 주변 환경을 인식하도록 구성되며, 시뮬레이션에서 도 차량에 탑재된 각종 센서들을 가상의 주행 환경에서 모사하기 위해, 영상 DB, 센서 및 카메라 에뮬레이션 시 스템, 영상 렌더링 시스템으로 자율주행 시뮬레이션의 영상 생성 장치를 구성하며, 영상 객체 모델은 주행 환경 및 시나리오의 시뮬레이션 상태를 모델로부터 얻어 영상으로 재현하고, 주기적으로 가상 센서의 에뮬레이션 결 과인 자율주행 소스 데이터를 데이터베이스에 추가하며 제어기에 캡처 이벤트를 전달하며, 영상부는 고성능 3차원 렌더링 엔진을 탑재한 하나 이상의 시스템으로 구성하여 다양한 가상 카메라 및 센서의 신호 생성의 부하 를 분산 시키고 시뮬레이션의 정확성을 높일 수 있도록 하며, 이를 위해 시뮬레이션 모델을 각 3차원 렌더링 엔진의 모델로 재현하기 위해 개별적인 영상 파일을 로딩한 후, 영상 객체 모델을 통해 모델부의 주행 객체 정보와 동기화하는 것을 포함하는 것이다. 실시예에서, 상기 제어부는 모의실험에 필요한 각종 환경 설정, HILS/SILS 검증 등 전체적인 시뮬레이션의 감독, 통제의 역할을 수행하며, 시험조건에 시나리오 관리, 이벤트 설정 및 각종 데이터 수집과 모니터링 및 분 석이 가능하도록 하며, 시뮬레이터는 시뮬레이션 운영/제어와 서브시스템간의 인터페이스, 진단 기능을 제공하 며, 상기 제어부는 내/외부 사건(렌더러 이벤트, 상태변화 등)의 처리를 전담하고, 생명 주기 및 데이터 동 기화된 모델의 로직을 제어하고, 이때 제어부에서 수행 가능한 이벤트를 먼저 처리하고, 불가능한 이벤트는 모 델부의 통신 계층을 통해 그 처리를 위임하며, 사용자 및 타 시뮬레이션, 타 응용체계 등과 모델을 연결하 는 인터페이스 기능을 수행하고, 인공지능 및 자동차 동역학과 같은 시뮬레이션 주기의 로직을 직/간접 제어하 며, 영상부와 달리 로드타임에는 시스템 설정만을 로딩하고, 모델부 제어의 대리자 역할을 수행하며, 런타임에는 영상부에서 수집된 이벤트를 처리하도록 모델부를 제어하고, 모델부의 주행 상태 변경 으로 트리거된 시그널을 영상으로 재현 할 수 있도록 영상부에 지시하는 것을 포함하는 것이다. 실시예에서, 상기 시뮬레이터는 M&S 엔진의 상세한 모델 정보를 자율주행의 개념적 컴포넌트로 함축하여 모델링 하며, 이를 통해, 복잡한 M&S 엔진들은 무결성의 손실 없이 시뮬레이션 환경 개발을 위한 확장 가능한 토대를 마련하도록 하며, 상기 시뮬레이터는 게임 엔진에 확장 가능한 플러그인 형태로 시뮬레이션 엔진과 연동하도록 구성하고, 검증용 센서 및 인공지능 알고리즘 또한 플러그인으로 관리되도록 하며, 모델 서버과 영상 클라이언 트 사이의 분산 환경 시뮬레이션 제어는 타이밍, 동기화, 병렬성, 데이터 포맷과 같은 통신 문제가 있고, 제어 흐름상의 문맥에 맞는 시뮬레이션 엔진의 생명주기 관리와 통신 계층의 중계 역할을 통해 이 문제를 해소하도록 한 것을 포함하는 것이다."}
{"patent_id": "10-2019-0152141", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 바람직한 효과에 따르면, 1)3차원 영상 엔진에 의존적이지 않은 분산 시뮬레이션 프레임워크 구성할 수 있고, 2)컴포넌트 기반 자율주행 모델의 재사용성 및 인공지능 알고리즘 테스트가능성을 향상시키며, 3)멀티 센서 에뮬레이션 데이터 동기화 및 병렬 분산 처리 성능을 개선하는 효과가 있으며, 4)자율주행 시뮬레이션의 추상적 모델 및 통신 계층을 통한 자율주행 클라우드 서비스 기반을 마련할 수 있으며, 5)인터페이스 계층을 통 한 타 시뮬레이션 시스템으로 확장, 모델의 검증 및 모의실험 환경을 개선할 수 있는 장점이 있다."}
{"patent_id": "10-2019-0152141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명을 상세히 설명하도록 한다. 1. 프레임워크 자율주행 시뮬레이션은 다양한 모델링-시뮬레이션(M&S) 기술들이 융합되어 구성되는데, 자율주행 알고리즘, 차 량 동역학 시뮬레이션, 시나리오, 그리고 가상 센서와 3차원 영상 렌더링 엔진이 요구된다. 자율주행 시뮬레이션 프레임워크는 공통의 시뮬레이션 모델 및 엔진을 포함 하는 모델 시스템, 센서 및 3차원 영상을 재현 하는 영상 시스템, 그리고 각 시스템을 통신 기반으로 서로 연동 제어하는 제어 시스템으로 구성된 다. 도 1을 참조하여 분산 자율주행 시뮬레이션 프레임워크를 살펴보면, 상단 구성은 서버, 중간 구성은 시뮬레 이터, 하단 구성은 클라이언트로 이루어진다. 각 시스템들은 멀티 프로세스, 분산 컴퓨팅 환경에서 IPC 및 이더넷 통신 계층을 통해 서로 연동될 수 있도록 하며, 전통적인 M&S의 모델과 시뮬레이션 관계를 유지하면서 교체 시험이 용이하도록 추상화된 모델의 인터페이 스 계층으로 제어된다. 자율주행 도메인에 공통된 개념의 주행 환경 및 객체, 시나리오 등의 주행 DB와 3차원 환경 렌더링을 위한 영상 DB를 구분하고, 여러 클라이언트에서 나누어 센서 에뮬레이션을 수행하여 시뮬레이션 부하를 분산시킨다. 2. 모델부 도 2에 나타낸 모델부는 자율주행의 주행 알고리즘을 검증하기 위한 각 주행 환경 및 객체 상태, 그리고 동 작(행위) 및 상호작용을 공통의 개념적인 컴포넌트 모델로 표현 한다. 여기서, 타임스탬프(time-stamp)가 포함된 실제 또는 가상으로 측정된 주변 환경 및 개체 정보(데이터)와 물리 적, 수학적 제어 로직을 함께 캡슐화하여 관리한다. 다양한 자율주행 알고리즘 및 교통 상황, 주행 시나리오, 차량 동역학 등 기존 서브시스템의 데이터와 제어 로 직의 관계는 유지하면서, 각 서브시스템 공통의 고수준 상태 및 행위를 포함한 컴포넌트로 추상화 한다. 이후 제어부의 지시에 따라 모델부에서 직접 서브시스템이 처리될 수 있도록 구성하여 부하 분산 및 다양한 시나리오 시험을 용이 하도록 한다. 모델부의 통신 계층은 분산 환경으로 확장이 용이하도록, 주행 상태의 감지된 변경을 영상부 및 제어부와 통신 한다. 이때, 전통적인 MVC의 옵저버 매커니즘을 적용하여 커플링과 동기화 문제를 해결하고, 대용량 분산 데이 터의 실시간 처리를 위한 별도의 데이터베이스를 쉽게 추가할 수 있도록 한다. 3. 영상부 실제 자율주행은 차량에 탑재된 레이다, 라이다 및 카메라, GPS 센서 등에서 측정된 데이터를 기반으로 차량, 보행자 및 도로 정보 등의 주변 환경을 인식하도록 구성된다. 시뮬레이션에서도 차량에 탑재된 각종 센서들을 가상의 주행 환경에서 모사하기 위해, 영상 DB, 센서 및 카메라 에뮬레이션 시스템, 영상 렌더링 시스템으로 자율주행 시뮬레이션의 영상 생성 장치를 구성한다. 영상 객체 모델은 주행 환경 및 시나리오의 시뮬레이션 상태를 모델로부터 얻어 영상으로 재현하고, 주기적으로 가상 센서의 에뮬레이션 결과인 자율주행 소스 데이터를 데이터베이스에 추가하며 제어기에 캡처 이벤트를 전달 한다. 영상부는 고성능 3차원 렌더링 엔진을 탑재한 하나 이상의 시스템으로 구성하여 다양한 가상 카메라 및 센 서의 신호 생성의 부하를 분산 시키고 시뮬레이션의 정확성을 높일 수 있도록 한다. 이를 위해 시뮬레이션 모델을 각 3차원 렌더링 엔진의 모델로 재현하기 위해 개별적인 영상 파일을 로딩한 후, 영상 객체 모델을 통해 모델부[1]의 주행 객체 정보와 동기 한다. 즉, 주행 객체 모델의 상태 변경이 감지되면 이를 영상부에 통지 하고, 영상부는 변경 상태를 모델로부터 조회 하여 영상 객체 모델에 반영한다. 또한 화면 렌더링은 최대한 자주 변경하지만, 각 센서는 특성에 맞는 주기로 샘플링을 수행하고 결과를 제어부에 이벤트를 전달하는 고정 시간 간격(Fixed Timestep)으로 데이터 동기화 를 수행한다. 4. 제어부 제어부는 모의실험에 필요한 각종 환경 설정, HILS/SILS 검증 등 전체적인 시뮬레이션의 감독, 통제의 역할 을 수행 한다. 시험조건에 시나리오 관리, 이벤트 설정 및 각종 데이터 수집과 모니터링 및 분석이 가능하다. 또한 시뮬레이터는 시뮬레이션 운영/제어와 서브시스템간의 인터페이스, 진단 기능을 제공한다. 제어부는 내/외부 사건(렌더러 이벤트, 상태변화 등)의 처리를 전담하고, 생명 주기 및 데이터 동기화된 모 델의 로직을 제어한다. 이때, 제어부에서 수행 가능한 이벤트를 먼저 처리하고, 불가능한 이벤트는 모델부[1]의 통신 계층을 통해 그 처리를 위임한다. 또한, 제어부는 사용자 및 타 시뮬레이션, 타 응용체계 등과 모델을 연결하는 인터페이스 기능을 수행하고, 인공지능 및 자동차 동역학과 같은 시뮬레이션 주기의 로직을 직/간접 제어 한다. 영상부와 달리 로드타임에는 시스템 설정만을 로딩하고, 모델부 제어의 대리자 역할을 수행 한다. 예를 들어, 시작, 정지, 일시정지와 같은 시뮬레이션 제어는 모델부 각 컴포넌트들 마다 해당 행위를 반복적으로 호출하여 완수 한다. 런타임에는 영상부에서 수집된 이벤트를 처리하도록 모델부를 제어하고, 모델부의 주행 상태 변경 으로 트리거된 시그널을 영상으로 재현 할 수 있도록 영상부에 지시한다. 5. 시뮬레이터 본 발명에서 제안된 핵심 아키텍처는 자율주행 시뮬레이션 개념과 고전적인 MVC 패러다임 사이의 융합으로서, 자율주행 시뮬레이터 구성은 도 5에 도시된 바와 같은 구성을 가진다.도 5를 참조하면, M&S 엔진의 상세한 모델 정보를 자율주행의 개념적 컴포넌트(특히, 도로망과 정답 데이터)로 함축하여 모델링한다. 이를 통해, 복잡한 M&S 엔진들은 무결성의 손실 없이 시뮬레이션 환경 개발을 위한 확장 가능한 토대를 마련하 는 장점이 있다. 본 발명에서 제시된 시뮬레이터는 게임 엔진에 확장 가능한 플러그인 형태로 시뮬레이션 엔진과 연동하도록 구 성하였고, 검증용 센서 및 인공지능 알고리즘 또한 플러그인으로 관리된다. 모델 서버과 영상 클라이언트 사이의 분산 환경 시뮬레이션 제어는 타이밍, 동기화, 병렬성, 데이터 포맷과 같 은 통신 문제가 있고, 제어 흐름상의 문맥에 맞는 시뮬레이션 엔진의 생명주기 관리와 통신 계층의 중계 역할을 통해 이 문제를 해소한다. 일반적으로 시뮬레이터의 목적은 사용자 상호작용과 시뮬레이션 모델의 실험을 용이하게 하는데 있다. 제안된 프레임워크는 지형 및 날씨, 도로망 등 주행환경 편집을 위한 지형 편집기와 주행 시나리오, 동적 객체, 트래픽 생성 등 시나리오 편집 도구와 데이터 분석, 모니터링, 3차원 시뮬레이션 등의 시뮬레이터 개발에 활용되었다."}
{"patent_id": "10-2019-0152141", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 분산 자율주행 시뮬레이션 프레임워크를 나타낸 블록도. 도 2는 본 발명에 따른 MVC 기반 자율주행 시뮬레이션 아키텍쳐를 나타낸 블록도. 도 3은 본 발명에 따른 센서입력신호의 로직제어에 대한 실시간 데이터 처리과정을 나타낸 흐름도. 도 4는 본 발명에 따른 갱신상태의 영상/센서 출력에 대한 실시간 데이터 처리과정을 나타낸 흐름도. 도 5는 본 발명에 따른 자율주행 시뮬레이터 구성을 나타낸 블록도."}
