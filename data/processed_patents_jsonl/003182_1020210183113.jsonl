{"patent_id": "10-2021-0183113", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0098677", "출원번호": "10-2021-0183113", "발명의 명칭": "교통사고 예측 방법 및 시스템", "출원인": "광주과학기술원", "발명자": "류제하"}}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "교통사고 예측 시스템에 있어서, 실시간 영상을 획득하는 영상촬영부; 상기 획득된 영상으로부터 객체를 탐지하고, 탐지된 객체로부터 객체정보를 추출하는 객체정보 추출부; 및 상기 추출한 객체정보로부터 객체의 미래 위치와 크기를 예측하고, 예측된 객체의 미래 위치와 크기에 기반하여사고 가능성을 예측하는 교통사고 예측부를 포함하는, 교통사고 예측 시스템."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 객체정보 추출부는, 상기 실시간으로 획득한 영상에서 차량이나 보행자를 탐지하는 객체탐지부; 및 상기 탐지된 객체의 움직임 정보를 추출하는 객체의 움직임 정보 추출부를 포함하는, 교통사고 예측 시스템."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 객체탐지부는, 상기 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입력하여, 상기 실시간으로 획득한 객체 관련 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어도 하나를 탐지하고, 상기 탐지된 적어도 하나의 객체를 트래킹(tracking) 알고리즘을 통해 실시간 트래킹(tracking)하는, 교통사고 예측 시스템."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 객체탐지부는, 상기 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입력하여, 상기 실시간으로 획득한 객체 관련 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어도 하나를 탐지하고, 상기 탐지된 적어도 하나의 객체에 각각 대응되는 적어도 하나의 바운딩 박스(bounding box)를 생성하고, 상기 탐지된 적어도 하나의 바운딩 박스(bounding box)를 트래킹(tracking) 알고리즘을 통해 실시간 트래킹(tracking)하는, 공개특허 10-2022-0098677-3-교통사고 예측 시스템."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 객체 움직임 정보 추출부는, 상기 생성된 바운딩 박스(bounding box)의 좌표가 시계열적으로 변화하는 변화량 정보를 이용하여 움직임 정보를 추출하는, 교통사고 예측 시스템."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 교통사고 예측부는, 상기 추출한 객체정보를 순환신경망(Recurrent neural network; RNN)모델에 입력하여 나온 결과값을 이용하여객체의 미래 위치 및 크기를 예측하는 객체 미래 위치 및 크기 예측부; 및 상기 예측된 객체의 미래 위치 및 크기를 사고 가능성 예측 모델에 입력하여 나온 결과값을 통해 미래의 사고가능성을 예측하는 사고 가능성 예측부를 포함하는, 교통사고 예측 시스템."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 사고 가능성 예측부는, 사전에 라벨링된 데이터를 이용하여 실시간 영상에서 각각의 객체들의 스코어를 추출하고, 추출된 스코어가 기설정된 임계값을 초과하는지 여부로 미래의 사고의 가능성을 예측하는, 교통사고 예측 시스템."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "교통사고 예측 방법에 있어서, 실시간 영상을 획득하는 영상촬영단계; 상기 획득된 영상으로부터 객체를 탐지하고, 탐지된 객체로부터 객체정보를 추출하는 객체정보 추출단계; 및 상기 추출한 객체정보로부터 객체의 미래 위치를 예측하고, 예측된 객체의 미래 위치에 기반하여 사고 가능성을예측하는 교통사고 예측단계를 포함하는, 교통사고 예측 방법."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 객체정보 추출단계는, 공개특허 10-2022-0098677-4-상기 실시간으로 획득한 영상에서 차량이나 보행자를 탐지하는 객체탐지단계; 및 상기 탐지된 객체의 움직임 정보를 추출하는 단계를 포함하는, 교통사고 예측 방법."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 객체탐지단계는, 상기 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입력하여, 상기 실시간으로 획득한 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어도 하나를 탐지하고, 상기 탐지된 적어도 하나의 객체를 트래킹(tracking) 알고리즘을 통해 실시간 트래킹(tracking)하는 단계인, 교통사고 예측 방법."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 객체탐지단계는, 상기 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입력하여, 상기 실시간으로 획득한 객체 관련 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어도 하나를 탐지하고, 상기 탐지된 적어도 하나의 객체에 각각 대응되는 적어도 하나의 바운딩 박스(bounding box)를 생성하고, 상기 생성된 적어도 하나의 바운딩 박스(bounding box)를 트래킹(tracking) 알고리즘을 통해 실시간 트래킹(tracking)하는 단계인, 교통사고 예측 방법."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 객체의 움직임 정보를 추출하는 단계는,상기 생성된 바운딩 박스(bounding box)의 좌표가 시게열적으로 변화하는 변화량 정보를 이용하여 움직임 정보를 추출하는 단계인, 교통사고 예측 방법."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서, 상기 교통사고예측단계는, 상기 객체정보를 순환신경망(Recurrent neural network; RNN)모델에 입력하여 나온 결과값을 이용하여 객체의미래 위치 및 크기를 예측하는 객체 미래 위치 및 크기 예측 단계; 및 상기 예측된 객체의 미래 위치 및 크기를 사고 가능성 예측 모델에 입력하여 나온 결과값을 통해 미래의 사고가능성을 예측하는 사고 가능성 예측단계를 포함하는, 공개특허 10-2022-0098677-5-교통사고 예측 방법."}
{"patent_id": "10-2021-0183113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 사고 가능성 예측단계는, 사전에 라벨링된 데이터를 이용하여 실시간 영상에서 각각의 객체들의 스코어를 추출하고, 추출된 스코어가 기설정된 임계값을 초과하는지 여부로 미래의 사고 가능성을 예측하는 단계인, 교통사고 예측 방법."}
{"patent_id": "10-2021-0183113", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 교통사고 예측 시스템에 관한 것이다. 본 시스템은 실시간 영상을 획득하는 영상촬영부, 획득된 영상 으로부터 객체를 탐지하고, 탐지된 객체로부터 객체정보를 추출하는 객체정보 추출부 및 추출한 객체정보로부터 객체의 미래 위치와 크기를 예측하고, 예측된 객체의 미래 위치와 크기에 기반하여 사고 가능성을 예측하는 교통 사고 예측부를 포함할 수 있다."}
{"patent_id": "10-2021-0183113", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 교통사고 예측 방법 및 시스템에 관한 것으로, 더욱 상세하게는 차량에 부착된 카메라(블랙박스 등) 정보만을 사용하는 인공지능 기반, 사고를 유발할 가능성이 있는 객체 (차량 및 보행자 등)를 예측하는 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0183113", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래의 주행 중 교통사고예측을 위해 적용된 대표적인 ADAS( Advanced Driver Assistance Systems) 기술들은 미리 정의된 상황에 대해서만 작용하여, 미리 정의되지 못한 사고에 관해서는 그 회피 제어가 불가한 문제점이 존재한다. 이에, 2006년경에는 차량들끼리 서로의 정보를 송수신하여 충돌 가능성을 인지하고 회피하는 방법이 제안되었다 (KR 10-2006-0050427). 하지만, 이는 차량들이 통신할 수 있는 인프라가 구축되어야 하고 일부 통신이 이루어지 지 않는 차량의 경우 충돌 예측 불가한 문제점과 보안 등의 문제점이 존재한다. 최근에는 인공지능 기술을 이용하여 차량 사고를 예측하는 연구가 활발히 이루어지고 있다. 대부분 차량의 장착 된 카메라 정보를 인공지능으로 분석하여 사고 예측하는 방식으로 발명이 이루어졌다. 또한, CNN을 활용하여 사고 확률을 예측하는 방법이 제안되었다(KR 10-2017-0157616). 하지만, 2016 ACCV “ Anticipating Accidents in Dashcam Videos”에 의하면 RNN을 사용하였을 때가 단일 프레임 분류(single frame classify)하는 것을 능가(outperform)하는 것을 보였다. 즉, 사고를 예측하는데 있어서 한 장면만을 분석하는 것보다 시간의 흐름에 따라 분석하였을 때 효과적이다. 또한, 2017년경에는 CNN-RNN기반으로 사고를 예측하는 방안을 제시하였지만, 어떤 차량 또는 보행자가 위험 요 소인지를 판단하지 않는다는 문제점이 존재한다(KR 10-2017-0173141). 가장 최근 등장한, 2019년 경 방법의 경우, 다수의 부가 센서들이 필요하다는 문제점이 존재한다(KR 10-2019- 0166389). 선행기술문헌 특허문헌 (특허문헌 0001) [특허문헌 1] 한국등록특허 제10-0754135호. 2007.08.24. 등록."}
{"patent_id": "10-2021-0183113", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2021-0183113", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위하여 창출된 것으로, 교통사고 예측 방법 및 시스템을 제공하는 것을 그 목적으로 한다. 본 발명의 목적들은 이상에서 언급한 목적들로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재 로부터 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0183113", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적들을 달성하기 위하여, 본 발명의 일 실시예에 따른 교통사고 예측 시스템이 개시된다. 상기 시스템 은 실시간 영상을 획득하는 영상촬영부, 획득된 영상으로부터 객체를 탐지하고, 탐지된 객체로부터 객체정보를 추출하는 객체정보 추출부 및 추출한 객체정보로부터 객체의 미래 위치와 크기를 예측하고, 예측된 객체의 미래 위치와 크기에 기반하여 사고 가능성을 예측하는 교통사고 예측부를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따르면, 객체정보 추출부는, 실시간으로 획득한 영상에서 차량이나 보행자를 탐지 하는 객체탐지부 및 탐지된 객체의 움직임 정보를 추출하는 객체의 움직임 정보 추출부를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따르면, 객체탐지부는, 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입력 하여, 실시간으로 획득한 객체 관련 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어 도 하나를 탐지하고, 탐지된 적어도 하나의 객체를 트래킹(tracking) 알고리즘을 통해 실시간 트래킹(trackin g)할 수 있다. 또한, 본 발명의 일 실시예에 따르면, 객체탐지부는, 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입력 하여, 실시간으로 획득한 객체 관련 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어 도 하나를 탐지하고, 탐지된 적어도 하나의 객체에 각각 대응되는 적어도 하나의 바운딩 박스(bounding box)를 생성하고, 탐지된 적어도 하나의 바운딩 박스(bounding box)를 트래킹(tracking) 알고리즘을 통해 실시간 트래 킹(tracking)할 수 있다. 또한, 본 발명의 일 실시예에 따르면, 객체 움직임 정보 추출부는, 생성된 바운딩 박스(bounding box)의 좌표가 시계열적으로 변화하는 변화량 정보를 이용하여 움직임 정보를 추출할 수 있다. 또한, 본 발명의 일 실시예에 따르면, 교통사고 예측부는, 추출한 객체정보를 순환신경망(Recurrent neural network; RNN)모델에 입력하여 나온 결과값을 이용하여 객체의 미래 위치 및 크기를 예측하는 객체 미래 위치 및 크기 예측부 및 예측된 객체의 미래 위치 및 크기를 사고 가능성 예측 모델에 입력하여 나온 결과값을 통해 미래의 사고 가능성을 예측하는 사고 가능성 예측부를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따르면, 사고 가능성 예측부는, 사전에 라벨링된 데이터를 이용하여 실시간 영상 에서 각각의 객체들의 스코어를 추출하고, 추출된 스코어가 기설정된 임계값을 초과하는지 여부로 미래의 사고 의 가능성을 예측할 수 있다. 또한, 상기한 목적들을 달성하기 위하여, 본 발명의 일 실시예에 따른 교통사고 예측 방법이 개시된다. 상기 방 법은 실시간 영상을 획득하는 영상촬영단계, 획득된 영상으로부터 객체를 탐지하고, 탐지된 객체로부터 객체정 보를 추출하는 객체정보 추출단계 및 추출한 객체정보로부터 객체의 미래 위치를 예측하고, 예측된 객체의 미래 위치에 기반하여 사고 가능성을 예측하는 교통사고 예측단계를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따르면, 객체정보 추출단계는, 실시간으로 획득한 영상에서 차량이나 보행자를 탐 지하는 객체탐지단계 및 탐지된 객체의 움직임 정보를 추출하는 단계를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따르면, 객체탐지단계는, 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입 력하여, 실시간으로 획득한 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어도 하나 를 탐지하고, 탐지된 적어도 하나의 객체를 트래킹(tracking) 알고리즘을 통해 실시간 트래킹(tracking)하는 단 계일 수 있다. 또한, 본 발명의 일 실시예에 따르면, 객체탐지단계는, 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입 력하여, 실시간으로 획득한 객체 관련 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적 어도 하나를 탐지하고, 탐지된 적어도 하나의 객체에 각각 대응되는 적어도 하나의 바운딩 박스(bounding box)를 생성하고, 생성된 적어도 하나의 바운딩 박스(bounding box)를 트래킹(tracking) 알고리즘을 통해 실시간 트 래킹(tracking)하는 단계일 수 있다. 또한, 본 발명의 일 실시예에 따르면, 객체의 움직임 정보를 추출하는 단계는, 생성된 바운딩 박스(bounding box)의 좌표가 시게열적으로 변화하는 변화량 정보를 이용하여 움직임 정보를 추출하는 단계일 수 있다. 또한, 본 발명의 일 실시예에 따르면, 교통사고예측단계는, 객체정보를 순환신경망(Recurrent neural network; RNN)모델에 입력하여 나온 결과값을 이용하여 객체의 미래 위치 및 크기를 예측하는 객체 미래 위치 및 크기 예 측 단계 및 예측된 객체의 미래 위치 및 크기를 사고 가능성 예측 모델에 입력하여 나온 결과값을 통해 미래의 사고 가능성을 예측하는 사고 가능성 예측단계를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따르면, 사고 가능성 예측단계는, 사전에 라벨링된 데이터를 이용하여 실시간 영 상에서 각각의 객체들의 스코어를 추출하고, 추출된 스코어가 기설정된 임계값을 초과하는지 여부로 미래의 사 고 가능성을 예측하는 단계일 수 있다. 상기한 목적들을 달성하기 위한 구체적인 사항들은 첨부된 도면과 함께 상세하게 후술될 실시예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라, 서로 다른 다양한 형태로 구성될 수 있으며, 본 발명의 개시가 완전하도록 하고 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자(이하, \"통 상의 기술자\")에게 발명의 범주를 완전하게 알려주기 위해서 제공되는 것이다."}
{"patent_id": "10-2021-0183113", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 의하면, 객체의 미래 위치 예측을 통해서 예측과정 중 RNN의 숨겨진 상태 (Hidden States)들의 정보만을 교통사고 예측부에서 사용해서 사고를 예측하기 때문에, 사고 위험 가능성이 높은 객체에 대해 운전자에게 경고를 할 수 있어서, 자율 주행 분야에 있어서 능동적 사고 회피 동작 기술에 활용할 수 있다."}
{"patent_id": "10-2021-0183113", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 상술된 효과들로 제한되지 않으며, 본 발명의 기술적 특징들에 의하여 기대되는 잠정적인 효과들은 아래의 기재로부터 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0183113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고, 여러 가지 실시예들을 가질 수 있는 바, 특정 실시예들을 도면에 예시 하고 이를 상세히 설명하고자 한다. 청구범위에 개시된 발명의 다양한 특징들은 도면 및 상세한 설명을 고려하여 더 잘 이해될 수 있을 것이다. 명 세서에 개시된 장치, 방법, 제법 및 다양한 실시예들은 예시를 위해서 제공되는 것이다. 개시된 구조 및 기능상 의 특징들은 통상의 기술자로 하여금 다양한 실시예들을 구체적으로 실시할 수 있도록 하기 위한 것이고, 발명 의 범위를 제한하기 위한 것이 아니다. 개시된 용어 및 문장들은 개시된 발명의 다양한 특징들을 이해하기 쉽게 설명하기 위한 것이고, 발명의 범위를 제한하기 위한 것이 아니다. 본 발명을 설명함에 있어서, 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있 다고 판단되는 경우, 그 상세한 설명을 생략한다. 이하, 본 발명의 일 실시예에 따른 교통사고 예측 방법 및 시스템을 설명한다. 도 1은 본 발명의 일 실시예에 따른 교통사고 예측 시스템의 블록도이고, 도 2는 본 발명의 일 실시예에 따른 교통사고 예측 인공지능 모델 구조도를 도시한 도면이다. 또한, 도 3은 발명의 일 실시예에 따른 객체정보 추출 결과의 예시도이고, 도 4는 발명의 일 실시예에 따른 바 운딩 박스의 좌표값을 통해 바운딩 박스(bounding box) 변화량을 산출하는 예시도를 도시한 도면이다. 또한, 도 5는 발명의 일 실시예에 따른 교통사고 예측 예시도이고, 도 6은 발명의 일 실시예에 따른 교통사고 예측의 다른 예시도이다. 도 1 내지 도 6을 참조하면, 교통사고 예측 시스템은 영상 촬영부, 객체정보 추출부 및 교통사고 예측부를 포함할 수 있다. 일 실시예에서, 영상 촬영부는 차량에 장착되어 있는 카메라를 통해 실시간 영상을 획득할 수 있다. 예컨 대, 차량 주행시 또는 정차시, 차량내에 장착되어 있는 블랙박스 카메라 또는 별도로 부착된 카메라를 통해 실 시간으로 영상을 획득할 수 있다. 일 실시예에서, 객체정보 추출부는 영상 촬영부로부터 획득된 영상으로부터 객체를 탐지하고, 탐지된 객체로부터 객체정보를 추출할 수 있다. 보다 구체적으로, 객체정보 추출부는 영상 촬영부에서 실시간으로 획득한 영상에서 차량이나 보행자 를 탐지하는 객체탐지부 및 탐지된 객체의 움직임 정보를 추출하는 객체의 움직임 정보 추출부를 포함할 수 있다. 또한, 객체탐지부는 영상 촬영부에서 실시간으로 획득한 영상에서 차량이나 보행자를 탐지할 수 있다. 보다 구체적으로, 객체탐지부는 영상 촬영부에서 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입력하여, 실시간으로 획득한 객체 관련 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어도 하나를 탐지하고, 탐지된 적어도 하나의 객체를 트래킹(tracking) 알고리즘을 통해 실시간 트래킹 (tracking) 할 수 있다. 또한, 객체탐지부는 영상 촬영부에서 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입력하여, 실시간으로 획득한 객체 관련 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어도 하 나를 탐지하고, 탐지된 적어도 하나의 객체에 각각 대응되는 적어도 하나의 바운딩 박스(bounding box)를 생성 하여 표시하고, 생성한 바운딩 박스(bounding box)를 트래킹(tracking) 알고리즘을 통해 실시간 트래킹 (tracking)할 수 있다. 또한, 객체탐지부는 바운딩 박스(bounding box)를 설정하여 트래킹(tracking) 함으로써 트래킹(tracking) 대상이 분명해지고, 그에 따라 객체의 움직임의 변화를 용이하게 트래킹(tracking)을 할 수 있다. 또한, 바운딩 박스(bounding box)의 크기 조절이 가능하므로, 객체가 멀어지는지 가까워지는지 바운딩 박스(bounding box) 크 기조절을 통해 용이하게 표현할 수 있다. 또한, 객체 탐지부는 object detection deep learning model (ex. Mask-RCNN)을 사용하여 이미지에서 객 체들을 탐지할 수 있다. 이후, 트래킹(tracking) 기법인 SORT 알고리즘을 사용하여 트래킹(tracking)될 수있다. 또한, 객체 움직임 정보 추출부는 생성된 바운딩 박스(bounding box)의 좌표가 시계열적으로 변화하는 변화량 정보를 이용하여 움직임 정보를 추출할 수 있다. 또한, 바운딩 박스(bounding box) 변화량은 시계열적으로 연속된 바운딩 박스(bounding box) 정보의 좌표값 차 이를 통해 구할 수 있다. 바운딩 박스(bounding box) 변화량을 통해 객체의 움직임 정보를 획득하여, 추가적인 센서나 모델 사용없이 객체의 움직임 정보를 획득가능하여 추가적인 모델 사용을 줄일 수 있다. 보다 구체적으로, 객체 움직임 정보 추출부는 영상촬영부에서 실시간으로 획득한 영상에서 생성된 바운딩 박스(bounding box)의 좌표가 시계열적으로 변화하는 변화량 정보를 이용하여 움직임 정보를 추출할 수 있다. 즉, 영상 촬영부를 통해 실시간으로 획득한 영상은 파일 크기가 상당히 크므로 영상 처리하는데 많은 시간 이 소요되며, 영상 전부를 저장하기 어려우므로, 바운딩 박스(bounding box)의 좌표의 시계열적 변화량 정보를 추출하여 움직임 정보를 획득하는 방법을 통해 획득한 영상의 크기를 줄일 수 있어서, 프로세서 처리 속도를 높 일 수 있으며, 저장 용량을 낮출 수 있다. 또한, 도 4를 참조하면, 객체 움직임 정보 추출부는 바운딩 박스(bounding box)의 변화량은 바운딩 박스 (bounding box) 정보의 좌표값 차이을 통해 구할 수 있으며, 구체적으로 아래의 수식1을 통해 구할 수 있다. 수학식 1"}
{"patent_id": "10-2021-0183113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "따라서, 객체정보 추출부를 통해 추출된 객체정보는 시계열적으로 구성된 객체 위치, 객체 크기와 객체의 움직임 정보가 포함될 수 있다. 또한, 객체정보 추출부는 시계열적(time series) 이미지들에 대해 추출된 여러 시간대의 객체 위치는 트래 킹(tracking) 알고리즘을 통해 시계열적(time series) 데이터로 형성된다. 각 객체의 움직임 정보는 시계열적으 로 연속된 이미지에서 각 객체의 좌표 변화량을 통해 구할 수 있다. 또한, 추출된 시게열적(time series) 객체 위치와 객체 움직임 정보는 교통사고 예측부로 전달된다. 일 실시예에서, 교통사고 예측부는 객체정보 추출부를 통해 추출한 객체정보로부터 객체의 미래 위치 와 크기를 예측하고, 예측된 객체의 미래 위치와 크기에 기반하여 사고 가능성을 예측할 수 있다. 또한, 교통사고 예측부는 인공지능 모델인 객체 미래 위치 예측 모델과 사고 가능성 예측 모델로 이루어져 있다. 객체 미래 위치 예측 모델은 객체정보 추출부를 통해 얻은 정보를 바탕으로 각 객체의 일정 기간 동 안의 미래 위치를 예측한다. 객체 미래 위치 예측 모델은 정상 주행 영상들을 통해 학습된다. 또한, 사고 가능성 예측 모델은 객체 미래 위치 예측 모델을 통해 얻은 미래 위치 정보를 바탕으로 예측과정 중 RNN의 숨겨진 상태(Hidden States)들의 정보만을 교통사고 예측부에서 사용하여 미래의 사고 가능성을 예 측한다. 사고 가능성 예측 모델은 사고 영상 속, 사고 난 차량과 사고 나지 않은 차량들의 정보들을 토대로 학 습된다. 보다 구체적으로, 교통사고 예측부는 추출한 객체정보를 순환신경망(Recurrent neural network; RNN)모델 에 입력하여 나온 결과값을 이용하여 객체의 미래 위치 및 크기를 예측하는 객체 미래 위치 및 크기 예측부 및 예측된 객체의 미래 위치 및 크기를 통해 미래의 사고 가능성을 예측하는 사고 가능성 예측부를 포함할 수 있다. 또한, 교통 사고예측부는 시계열적으로 구성된 객체 위치, 객체 크기와 객체의 움직임 정보가 포함된 객체 정보를 인공신경망 모델을 이용하여, 객체의 미래 위치 및 크기를 시계열적인 흐름에 따라 예측하고, 예측된 객체의 미래 위치 및 크기에 기반하여 자차와의 미래의 사고 가능성을 예측할 수 있다. 또한, 객체 미래 위치 및 크기 예측부는 추출한 객체정보를 순환신경망(Recurrent neural network; RNN) 모델에 입력하여 나온 결과값을 이용하여 객체의 미래 위치 및 크기를 예측할 수 있다. 또한, 객체 미래 위치 및 크기 예측부는 객체 정보 추출부로부터 얻은 정보를 순환신경망(RNN Encoder-Decoder 구조) 모델을 통해 객체의 미래 바운딩 박스(bounding box) 좌표를 예측할 수 있다. 순환신경 망(RNN) 모델은 미래 바운딩 박스(bounding box) 좌표가 되로록 정상 주행 영상을 통해 학습될 수 있다. 본 발명의 일 실시예에 따른 인공 신경망은 컨볼루션 신경망(convolution neural network: CNN), 오토 인코더 (auto encoder), 피드포워드 신경망(feedforward neural network), 방사 신경망(radial basis function network), 코헨 자기조직 신경망(kohonen self-organizing network), 순환 신경망(RNN: recurrent neural network), 다중층 인식망(Multilayer Perceptron) 등으로 구성될 수 있으며 본 발명은 이에 제한되지 않고 임의 의 신경망을 포함할 수 있다. 상기 예시는 본 개시를 설명하기 위한 예시일 뿐, 본 개시는 이에 제한되지 않는 다. 또한, 사고 가능성 예측부는 예측된 객체의 미래 위치 및 크기를 통해 미래의 사고 가능성을 예측할 수 있 다. 보다 구체적으로, 사고 가능성 예측부는 사전에 라벨링된 데이터를 이용하여 실시간 영상에서 각각의 객체 들의 스코어를 추출하고, 추출된 스코어가 기설정된 임계값을 초과하는지 여부로 미래의 사고의 가능성을 예측 할 수 있다. 사고 가능성 예측부는 자차 사고 영상을 통해 학습된 순환신경망 모델을 사용할 수 있다. 또한, 순환신경망(RNN) 모델은 사고가 나지 않는 객체는 0으로 라벨링 되어 있고 미래에 사고가 나는 객체는 1 로 라벨링된 데이터를 사용하여 모델의 출력값이 라벨된 값을 맞추도록 학습될 수 있다. 또한, 사고 가능성 예측부는 상기 방법에 의해 학습된 순환신경망(RNN) 모델을 이용하여 매 프레임에서 각 객체들의 스코어를 추출하고 사전에 설정된 문턱값(임계값)을 기준으로 미래의 사고를 예측할 수 있다. 문턱 값(임계값)은 샘플데이터를 통해 최적의 값으로 선택될 수 있다. 본 발명은 교통사고 예측 방법 및 시스템은 객체들의 미래 위치와 크기를 예측하고, 예측한 미래 정보를 바탕으 로 이 예측과정 중 RNN의 숨겨진 상태 (Hidden States)들의 정보만을 교통사고 예측부에서 사용해서 객체들 각 각의 미래 교통사고를 예측하고자 한다. 또한, 교통사고 예측 방법 및 시스템은 각 객체의 몇 개의 프레임으로 미래 위치를 예측하고 예측한 정보를 사 용해서 각 객체가 미래에 자차와 교통사고를 일으킬 가능성을 계산할 수 있다. 또한, 교통사고 예측 방법 및 시스템은 미래에 사고 위험성이 높은 객체 예측에서 성능의 향상, 자차 교통사고 의 경우, 자차에 대한 객체의 상대적인 위치와 크기, 움직임 정보가 중요하게 작용하며, 전체 이미지에 대한 정 보도 사용하는 것은 학습과 판단에 큰 영향이 없고 오히려 방해 요소가 될 수 있으므로, 객체 정보만을 사용하 여 성능 향상을 도모하고 있다. 또한, 교통사고 예측 방법 및 시스템은 직접적으로 각 객체마다의 사고 가능성을 예측하도록 모델이 구성되어 있고 그 목적으로 학습이 이루어진다. 또한, 교통사고 예측 방법 및 시스템은 객체의 미래 위치 예측을 통해서 사고를 예측하기 때문에, 사고 위험 가 능성이 높은 객체에 대해 운전자에게 경고 가능하므로, 자율 주행 분야에 있어서 능동적 사고 회피 동작 기술에 활용할 수 있다. 도 7은 본 발명의 일 실시예에 따른 교통사고 예측 방법의 순서도이고, 도 8은 본 발명의 일 실시예에 따른 교 통사고 예측단계의 순서도이다. 도 7 및 도 8을 참조하면, 교통사고 예측 방법(S1000)은 차량에 장착되어 있는 카메라를 통해 실시간 영상을 획 득하는 영상촬영단계(S1100), 획득된 영상으로부터 객체를 탐지하고, 탐지된 객체로부터 객체정보를 추출하는 객체정보 추출단계(S1200) 및 추출한 객체정보로부터 객체의 미래 위치를 예측하고, 예측된 객체의 미래 위치에 기반하여 사고 가능성을 예측하는 교통사고 예측단계(S1300)를 포함할 수 있다. 일 실시예에서, 영상촬영단계(S1100)는 차량에 장착되어 있는 카메라를 통해 실시간 영상을 획득하는 단계일 수 있다. 예컨대, 차량 주행시 또는 정차시, 차량내에 장착되어 있는 블랙박스 카메라 또는 별도로 부착된 카메라 를 통해 실시간으로 영상을 획득할 수 있다. 일 실시예에서, 객체정보 추출단계(S1200)는 영상촬영단계(S1100)에서 획득된 영상으로부터 객체를 탐지하고, 탐지된 객체로부터 객체정보를 추출하는 단계일 수 있다. 보다 구체적으로, 객체정보 추출단계(S1200)는 영상촬영단계(S1100)에서 실시간으로 획득한 영상에서 차량이나 보행자를 탐지하는 객체탐지단계 및 탐지된 객체의 움직임 정보를 추출하는 단계를 포함할 수 있다. 또한, 객체탐지단계는 영상촬영단계(S1100)에서 실시간으로 획득한 영상에서 차량이나 보행자를 탐지할 수 있다. 보다 구체적으로, 객체탐지단계는 영상촬영단계(S1100)에서 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입력하여, 실시간으로 획득한 객체 관련 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어도 하나를 탐지하고, 탐지된 적어도 하나의 객체를 트래킹(tracking) 알고리즘을 통해 실시간 트래킹 (tracking)하는 단계일 수 있다. 또한, 객체탐지단계는 실시간으로 획득한 영상을 객체 탐지 딥러닝 모델에 입력하여, 실시간으로 획득한 객체 관련 영상으로부터 적어도 하나의 객체, 객체 식별자 및 객체 표시 시간 중 적어도 하나를 탐지하고, 탐지된 적 어도 하나의 객체에 각각 대응되는 적어도 하나의 바운딩 박스(bounding box)를 생성하여 표시하고, 생성한 바 운딩 박스(bounding box)를 트래킹(tracking) 알고리즘을 통해 실시간 트래킹(tracking)하는 단계일 수 있다. 또한, 객체탐지단계에서 바운딩 박스(bounding box)를 설정하여 트래킹(tracking) 함으로써 트래킹(tracking) 대상이 분명해지고, 그에 따라 객체의 움직임의 변화를 용이하게 트래킹(tracking)을 할 수 있다. 또한, 바운딩 박스(bounding box)의 크기 조절이 가능하므로, 객체가 멀어지는지 가까워지는지 바운딩 박스(bounding box) 크 기조절을 통해 용이하게 표현할 수 있다. 또한, 객체의 움직임 정보를 추출하는 단계는 생성된 바운딩 박스(bounding box)의 좌표가 시게열적으로 변화하 는 변화량 정보를 이용하여 움직임 정보를 추출하는 단계일 수 있다. 또한, 바운딩 박스(bounding box) 변화량은 시계열적으로 연속된 바운딩 박스(bounding box) 정보의 좌표값 차 이를 통해 구할 수 있다. 바운딩 박스(bounding box) 변화량을 통해 객체의 움직임 정보를 획득하여, 추가적인 센서나 모델 사용없이 객체의 움직임 정보를 획득가능하여 추가적인 모델 사용을 줄일 수 있다. 보다 구체적으로, 객체 움직임 정보 추출단계는 영상촬영단계(S1100)에서 실시간으로 획득한 영상에서 생성된 바운딩 박스(bounding box)의 좌표가 시계열적으로 변화하는 변화량 정보를 이용하여 움직임 정보를 추출하는 단계일 수 있다. 즉, 영상 촬영단계(S1100)를 통해 실시간으로 획득한 영상은 파일 크기가 상당히 크므로 영상 처리하는데 많은 시간이 소요되며, 영상 전부를 저장하기 어려우므로, 바운딩 박스(bounding box)의 좌표의 시 계열적 변화량 정보를 추출하여 움직임 정보를 획득하는 방법을 통해 획득한 영상의 크기를 줄일 수 있어서, 프 로세서 처리 속도를 높일 수 있으며, 저장 용량을 낮출 수 있다. 또한, 객체 움직임 정보 추출단계는 바운딩 박스(bounding box)의 변화량은 바운딩 박스(bounding box) 정보의 좌표값 차이을 통해 구할 수 있다. 따라서, 객체정보 추출단계(S1200)를 통해 추출된 객체정보는 시계열적으로 구성된 객체 위치, 객체 크기와 객 체의 움직임 정보가 포함될 수 있다. 일 실시예에서, 교통사고 예측단계(S1300)는 객체정보 추출단계(S1200)를 통해 추출한 객체정보로부터 객체의 미래 위치를 예측하고, 예측된 객체의 미래 위치에 기반하여 사고 가능성을 예측할 수 있다. 보다 구체적으로, 교통사고 예측단계(S1300)는 객체정보 추출단계(S1200)를 통해 추출한 객체정보를 순환신경망 (Recurrent neural network; RNN)모델에 입력하여 나온 결과값을 이용하여, 객체의 미래 위치 및 크기를 예측하 는 객체 미래 위치 및 크기 예측 단계(S1310) 및 예측된 객체의 미래 위치 및 크기를 통해 미래의 사고 가능성 을 예측하는 사고 가능성 예측단계(S1330)를 포함할 수 있다. 또한, 교통사고 예측단계(S1300)는 시계열적으로 구성된 객체 위치, 객체 크기와 객체의 움직임 정보가 포함된 객체 정보를 인공신경망 모델을 이용하여, 객체의 미래 위치 및 크기를 시계열적인 흐름에 따라 예측하고, 예측 된 객체의 미래 위치 및 크기에 기반하여 자차와의 미래의 사고 가능성을 예측할 수 있다. 또한, 객체 미래 위치 및 크기 예측 단계(S1310)는 추출한 객체정보를 순환신경망(Recurrent neural network; RNN)모델에 입력하여 나온 결과값을 이용하여 객체의 미래 위치 및 크기를 예측하는 단계일 수 있다. 또한, 객체 미래 위치 및 크기 예측 단계(S1310)는 객체 정보 추출부로부터 얻은 정보를 순환신경망(RNN Encoder-Decoder 구조) 모델을 통해 객체의 미래 바운딩 박스(bounding box) 좌표를 예측할 수 있다. 순환신경 망 모델은 미래 바운딩 박스(bounding box) 좌표가 되로록 정상 주행 영상을 통해 학습될 수 있다. 본 발명의 일 실시예에 따른 인공 신경망은 컨볼루션 신경망(convolution neural network: CNN), 오토 인코더 (auto encoder), 피드포워드 신경망(feedforward neural network), 방사 신경망(radial basis function network), 코헨 자기조직 신경망(kohonen self-organizing network), 순환 신경망(RNN: recurrent neural network), 다중층 인식망(Multilayer Perceptron) 등으로 구성될 수 있으며 본 발명은 이에 제한되지 않고 임의 의 신경망을 포함할 수 있다. 상기 예시는 본 개시를 설명하기 위한 예시일 뿐, 본 개시는 이에 제한되지 않는 다. 또한, 사고 가능성 예측단계(S1330)는 예측된 객체의 미래 위치 및 크기를 통해 미래의 사고 가능성을 예측하는 단계일 수 있다. 보다 구체적으로, 사고 가능성 예측단계(S1330)는 사전에 라벨링된 데이터를 이용하여 실시간 영상에서 각각의 객체들의 스코어를 추출하고, 추출된 스코어가 기설정된 임계값을 초과하는지 여부로 미래의 사고 가능성을 예 측하는 단계일 수 있다. 사고 가능성 예측 단계(S1330)는 자차 사고 영상을 통해 학습된 순환신경망 모델을 사 용할 수 있다. 또한, 순환신경망(RNN) 모델은 사고가 나지 않는 객체는 0으로 라벨링 되어 있고 미래에 사고가 나는 객체는 1 로 라벨링된 데이터를 사용하여 모델의 출력값이 라벨된 값을 맞추도록 학습될 수 있다. 또한, 사고 가능성 예측단계(S1330)는 상기 방법에 의해 학습된 순환신경망(RNN) 모델을 이용하여 매 프레임에 서 각 객체들의 스코어를 추출하고 사전에 설정된 문턱값(임계값)을 기준으로 미래의 사고를 예측할 수 있다. 문턱값(임계값)은 샘플데이터를 통해 최적의 값으로 선택될 수 있다. 이상의 설명은 본 발명의 기술적 사상을 예시적으로 설명한 것에 불과한 것으로, 통상의 기술자라면 본 발명의 본질적인 특성이 벗어나지 않는 범위에서 다양한 변경 및 수정이 가능할 것이다. 따라서, 본 명세서에 개시된 실시예들은 본 발명의 기술적 사상을 한정하기 위한 것이 아니라, 설명하기 위한 것이고, 이러한 실시예들에 의하여 본 발명의 범위가 한정되는 것은 아니다. 본 발명의 보호범위는 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 이해되어야 한다."}
{"patent_id": "10-2021-0183113", "section": "도면", "subsection": "도면설명", "item": 1, "content": "상기 언급된 본 발명 내용의 특징들이 상세하게, 보다 구체화된 설명으로, 이하의 실시예들을 참조하여 이해될 수 있도록, 실시예들 중 일부는 첨부되는 도면에서 도시된다. 또한, 도면과의 유사한 참조번호는 여러 측면에 걸쳐서 동일하거나 유사한 기능을 지칭하는 것으로 의도된다. 그러나 첨부된 도면들은 단지 본 발명 내용의 특 정한 전형적인 실시예들만을 도시하는 것일 뿐, 본 발명의 범위를 한정하는 것으로 고려되지는 않으며, 동일한 효과를 갖는 다른 실시예들이 충분히 인식될 수 있다는 점을 유의하도록 한다. 도 1은 본 발명의 일 실시예에 따른 교통사고 예측 시스템의 블록도이다. 도 2는 본 발명의 일 실시예에 따른 교통사고 예측 인공지능 모델 구조도를 도시한 도면이다. 도 3은발명의 일 실시예에 따른 객체정보 추출 결과의 예시도이다. 도 4는 발명의 일 실시예에 따른 바운딩 박스의 좌표값을 통해 바운딩 박스(bounding box) 변화량을 산출하는 예시도를 도시한 도면이다. 도 5는 발명의 일 실시예에 따른 교통사고 예측 예시도이다. 도 6은 발명의 일 실시예에 따른 교통사고 예측의 다른 예시도이다. 도 7은 본 발명의 일 실시예에 따른 교통사고 예측 방법의 순서도이다. 도 8은 본 발명의 일 실시예에 따른 교통사고 예측단계의 순서도이다."}
