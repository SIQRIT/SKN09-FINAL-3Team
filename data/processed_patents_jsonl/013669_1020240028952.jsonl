{"patent_id": "10-2024-0028952", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0046129", "출원번호": "10-2024-0028952", "발명의 명칭": "음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시스템", "출원인": "주식회사 보이노시스", "발명자": "신정은"}}
{"patent_id": "10-2024-0028952", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자의 음성 데이터를 수집하기 위한 입력부; 음성 데이터를 수집하기 위한 환경을 체크하는 녹음환경판정부; 음성 데이터를 수집하는 과정에서의 사용자의 음성 크기를 체크하는 음성크기판정부; 수집된 음성 데이터를 기반으로 인공지능(AI) 알고리즘을 이용하여 난청, 인지장애 정도 및 치매를 진단하는 진단예측부; 및 상기 진단예측부의 결과를 제공하는 출력부;를 포함하며, 상기 녹음환경판정부는, 음성 데이터를 수집하기 위한 사용자의 주변 환경을 체크하는 주변환경판정모듈과, 음성 데이터를 수집하기 위한 사용자의 현재 몸상태를 체크하는 사용자상태판정모듈을 포함하고, 상기 주변환경판정모듈은, 판정을 위한 소리를 발생시킨 후 수신되는 소리를 기반으로 주변 환경 상태를 체크하는 제1판정모듈과, 주변 환경에 대한 영상 또는 이미지를 획득하여 주변 환경 상태를 체크하는 제2판정모듈과,상기 입력부를 통해 입력되는 정보를 기반으로 주변 환경 소음을 체크하는 제3판정모듈을 포함하고, 상기 사용자상태판정모듈은, 사용자로부터 입력되는 정보를 기반으로 사용자가 앓고 있는 질병이 음성 데이터수집에 영향을 미치는지 여부를 체크하는 제4판정모듈과, 사용자의 자연 발화를 통해 수집된 정보를 기반으로사용자 음성 품질이 음성 데이터를 수집에 영향을 미치는지 여부를 체크하는 제5판정모듈을 포함하는 것을 특징으로 하는 음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시스템."}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 하나의 시스템을 통해 음성 데이터 수집 환경에 대한 체크에서부터 음성 데이터 수집, 예측/진단 및 결과 확인까지 이루어지는 시스템에 관한 것으로, 보다 구체적으로 음성 데이터를 바이오마커로 한 다양한 뇌 건 강(난청, 인지장애, 치매 등)에 대한 예측 또는 진단을 가능케 하며 특히, 하나의 시스템으로 음성 데이터를 획 득하기 위한 수집 환경 및 사용자 상태에 대한 체크에서부터 음성 데이터 획득 과정에서의 음성 크기 모니터링 및 획득한 음성 데이터를 기반으로 한 난청, 인지장애 및 치매에 대한 예측 및 진단 결과 도출까지 이루어지는 음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시스템에 관한 것이다."}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 하나의 시스템을 통해 음성 데이터 수집 환경에 대한 체크에서부터 음성 데이터 수집, 예측/진단 및 결과 확인까지 이루어지는 시스템에 관한 것으로, 보다 구체적으로 음성 데이터를 바이오마커로 한 다양한 뇌 건강(난청, 인지장애, 치매 등)에 대한 예측 또는 진단을 가능케 하며 특히, 하나의 시스템으로 음성 데이터를 획득하기 위한 수집 환경 및 사용자 상태에 대한 체크에서부터 음성 데이터 획득 과정에서의 음성 크기 모니터 링 및 획득한 음성 데이터를 기반으로 한 난청, 인지장애 및 치매에 대한 예측 및 진단 결과 도출까지 이루어지 는 음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시스템에 관한 것이다."}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "뇌의 건강과 관련하여서는, 인지장애, 알츠하이머(치매), 우울증 등 다양한 질환들이 존재하고 있다. 인지 장애 란 기억력, 주의력, 언어 능력, 시공간 능력, 판단력 등이 저하된 상태를 의미하는 것으로, 인지 장애의 정도는 아주 경미한 경우에서 심한 경우까지 다양한데, 인지 기능 장애가 심하여 일상생활이나 사회생활에 지장을 주는 경우를 치매라고 한다. 알츠하이머(Alzheimer's Disease;AD)는 인지기능이 장기적 및 점진적으로 저하되는 신경 퇴행성 질환으로, 먼저 경도 인지 장애로 진행된 뒤 AD로 진행되는 일반적인 유형의 치매이다. 알츠하이머의 조 기 발견은 시기 적절한 치료를 위해 필수적이며, 이는 인지 저하를 늦추고 치매 전환으로의 위험을 줄일 수 있 다. 우울증은 의욕 저하와 우울감을 주요 증상으로 하여 다양한 인지 및 정신 신체적 증상을 일으켜 일상 기능 의 저하를 가져오는 질환을 의미하는데, 우울장애는 감정, 생각, 신체 상태, 그리고 행동 등에 변화를 일으키는 심각한 질환이다. 음성은 높낮이, 음량, 속도, 리듬, 유창성, 조음, 발음 및 톤 등의 여러가지 성격을 가지고 있다. 이러한 기능 은 우리가 어떻게 상대방이 말하고 있는지를 인식하게 하는 구성요소이기도 하다. 이러한 음성은 뇌의 여러 장 소를 거쳐 다양한 회로를 사용하여 만들어 지며 또한 우리 귀에 들리게 된다. 이러한 이유로 인해 뇌 건강과 관 련한 다양한 질병 및 상태에 대한 음성에 차이점이 발생하게 된다. 이러한 차이점을 가지고 (뇌 건강의)여러 질환에 대한 진단이 가능한데, 이런 음성 바이오 마커를 구축하기 위해서는 데이터의 일관성과 유효성이 매우 중 요하며 이를 보장하기 위해 보안 기술과 잘 통제된 환경에서 수집하는 것이 매우 중요하다. <특허문헌> 국내등록특허 제10-2274072호(2021.07.01.등록) \"사용자의 치매 정도 결정 방법 및 장치\" 상기 <특허문헌>에 개시된 선행특허 역시, 사용자가 입력한 음성의 특성을 시각화하여 이를 이용한 치매 정도를 결정하는 개념을 개시하고 있을 뿐이다. 따라서, 음성데이터 수집 단계에서부터 음성데이터 수집 환경과 수집 방법을 제어 및 정형화하여 데이터의 일관 성과 유효성을 담보할 수 있는 음성데이터를 수집하는 것, 그리고 음성 데이터에 기반한 난청을 진단하고 그 정 확성을 담보할 수 있는 기술, 인지장애 정도를 예측하기 위한 MMSE 점수 예측과 알츠하이머를 진단하는 AD 진단 을 하나의 알고리즘을 이용하여 동시에 수행하는 기술 및 참가자의 음성 녹음(음성 데이터)에서 간편하게 특징 을 추출하여 신속,정확하게 알츠하이머(AD)를 진단할 수 있는 기술 등에 대한 니즈는 증대되고 있다."}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위해 안출된 것으로, 본 발명의 목적은, 음성 데이터를 바이오마커로 한 다양한 뇌 건강(난청, 인지장애, 치매 등)에 대한 예측 또는 진단을 가능케 하며 특히, 하나의 시스템으로 음성 데이터를 획득하기 위한 수집 환경 및 사용자 상태에 대한 체크에서부터 음성 데이터 획득 과정에서의 음성 크기 모니터링 및 획득한 음성 데이터를 기반으로 한 난청, 인 지장애 및 치매에 대한 예측 및 진단 결과 도출까지 이루어지게 되는 음성 데이터를 이용한 AI 기반 난청, 인지 장애 및 치매 선별시스템을 제공하는 것이다. 본 발명의 다른 목적은, 음성데이터를 수집하기 위한 주변 환경 즉, 주변 소음 상태, 방음 상태 등에 대한 체크 및 음성데이터를 수집해야 하는 사용자의 현재 몸 상태에 대한 체크 등을 통해 데이터의 일관성과 유효성을 담 보하고 다양한 뇌 건강 진단의 정확성을 높일 수 있게 하는 음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시스템을 제공하는 것이다. 본 발명의 또 다른 목적은, 난청 질환 유무 진단에 활용되는 음성 데이터를 부정적인 산문(긴 시나리오 형태의 1분 내외 길이의 글)을 읽은 음성 데이터와 긍정적인 산문을 읽은 음성 데이터 특히, 부정적인 산문의 경우 억 울하고 격한 감정을 모두 담아 읽은 음석데이터를, 긍정적인 산문의 경우 감정을 배제한 상태에서 읽은 음성 데 이터를 활용함으로써 대상자의 나이나 성별 등에 무관하게 난청 유무를 정확하고 효과적으로 진단할 수 있으며, 수집 과정 내지 보안 등의 문제로 충분히 확보되기 어려운 음성 데이터에 대해 원본 데이터를 증강시킨 데이터 를 함께 활용함으로써 데이터 수에 따른 과적합을 줄이면서도 효과적으로 획득된 음성 데이터를 활용하여 정확 하게 난청 유무를 진단할 수 있는 음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시스템을 제공하 는 것이다. 본 발명의 또 다른 목적은, 음성데이터에서 추출된 음향 특징을 입력받아 하나의 알고리즘을 이용하여 MMSE 점 수 예측과 알츠하이머 진단을 동시에 수행할 수 있고 이때, 예측 및 진단의 정확도를 높이기 위해 알고리즘에 회귀 손실과 분류 손실을 함께 반영한 손실 함수를 활용함에 있어서 회귀 손실과 분류 손실이 상호 보완적으로 작용할 수 있도록, 평균 제곱 오차(MSE) 함수에는 각 구간의 확률값에 따라 베르누이 페널티를 반영하여 평균 제곱 오차(MSE)의 감소가 크로스 엔트로피(CE)의 감소로 연동되도록 하고, 크로스 엔트로피(CE) 함수에서 정답 구간과 예측 구간 사이의 거리를 가중치로 반영하여 예측된 MMSE 점수를 실제 MMSE 점수와 유사하게 분포시킬 수 있게 하는 음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시스템을 제공하는 것이다. 본 발명의 또 다른 목적은, 음성활동감지(VAD) 시스템을 이용한 음성 분할과 화자 분할을 통해 정적 특징, 참가 자 특징 및 인터뷰어 특징을 포함하는 비유창성 특징을 활용하여 보다 정확하게 알츠하이머(AD)를 감지할 수 있 으며 이때, 다양한 정적 특징들 중에서 특히, 참가자의 발화에서의 정적 특징과 관련한 연속된 참가자 세그먼트 사이의 정적 세그먼트의 수(Num_PS), 연속된 참가자 세그먼트 사이의 정적 세그먼트들의 길이의 평균(Avg_PS), 연속된 참가자 세그먼트 사이의 정적 세그먼트들의 길이의 분산(Var_PS) 특징을 고려하고, 인터뷰어 특징과 관 련하여 인터뷰어의 개입 정도와 관련한, 음성 녹음에서 인터뷰어 세그먼트의 수(Num_I), 음성 녹음에서 참여자 세그먼트와 인터뷰어 세그먼트 사이의 화자 변경 횟수(Num_chn) 특징을 고려함으로써, 보다 정확하게 알츠하이머(AD)를 감지할 수 있는 음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시스템을 제공하는 것이다. 본 발명의 또 다른 목적은, 본 발명의 시스템을 이용한 진단/예측의 결과를 즉각적으로 확인할 수 있고, 획득한 음성 데이터는 암호화하여 저장하고 일정 시간 후 자동으로 삭제함으로써 개인정보를 보호할 수 있는 음성 데이 터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시스템을 제공하는 것이다."}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 앞서 본 목적을 달성하기 위해서 다음과 같은 구성을 가진 실시예에 의해서 구현된다. 본 발명의 일 실시예에 따르면, 본 발명에 따른 음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시 스템은, 사용자의 음성 데이터를 수집하기 위한 입력부; 음성 데이터를 수집하기 위한 환경의 적정 상태를 체크 하는 녹음환경판정부; 음성 데이터를 수집하는 과정에서의 사용자의 음성 크기를 체크하는 음성크기판정부; 수 집된 음성 데이터를 기반으로 인공지능(AI) 알고리즘을 이용하여 난청, 인지장애 정도 및 치매를 진단하는 진단 예측부; 및 상기 진단예측부의 결과를 제공하는 출력부;를 포함하는 것을 특징으로 한다. 본 발명의 다른 실시예에 따르면, 본 발명에 있어서 상기 녹음환경판정부는, 사용자의 주변 환경이 음성 데이터 를 수집하기에 적정한 상태인지를 체크하는 주변환경판정모듈과, 사용자의 현재 몸상태가 음성 데이터를 수집하 기에 적정한 상태인지를 체크하는 사용자상태판정모듈을 포함하는 것을 특징으로 한다. 본 발명의 또 다른 실시예에 따르면, 본 발명에 있어서 상기 주변환경판정모듈은, 판정을 위한 소리를 발생시킨 후 수신되는 소리를 기반으로 주변 환경 상태를 체크하는 제1판정모듈과, 주변 환경에 대한 영상 또는 이미지를 획득하여 주변 환경 상태를 체크하는 제2판정모듈과, 상기 입력부를 통해 입력되는 정보를 기반으로 주변 환경 소음을 체크하는 제3판정모듈을 포함하고, 상기 사용자상태판정모듈은, 사용자로부터 입력되는 정보를 기반으로 사용자가 앓고 있는 질병이 음성 데이터 수집에 적정한지 여부를 체크하는 제4판정모듈과, 사용자의 자연 발화 를 통해 수집된 정보를 기반으로 사용자 음성 품질이 음성 데이터를 수집하기에 적정한지 여부를 체크하는 제5 판정모듈을 포함하는 것을 특징으로 한다. 본 발명의 또 다른 실시예에 따르면, 본 발명에 있어서 상기 진단예측부는, 음성 데이터에서 음성 특징을 추출 하여 추출된 음성 특징을 기반으로 인공지능(AI) 알고리즘을 이용하여 난청을 진단하는 난청진단부와, 음성 데 이터에서 음향 특징을 추출하여 추출된 음향 특징을 기반으로 인공지능(AI) 알고리즘을 이용하여 MMSE(Mini- Mental Status Examination) 점수를 예측하고 알츠하이머(AD; Alzheimer's Disease)를 진단하는 인지장애및AD 진단부를 포함하는 것을 특징으로 한다. 본 발명의 또 다른 실시예에 따르면, 본 발명에 있어서 상기 난청진단부는 wav2vec 음성 특징을 입력 받아 Swin Transformer를 이용하여 난청을 진단하며, 상기 wav2vec 음성 특징은, 감정을 실은 상태에서 부정적인 긴 문장 읽기를 통해 획득한 음성 데이터와 감정을 배제한 상태에서 긍정적인 긴 문장 읽기를 통해 획득한 음성 데이터 를 포함하는 원본 음성 데이터 및 상기 원본 음성 데이터를 타임 인버전(Time Inversion) 방식을 사용하여 역방 향으로 재생하여 증강시킨 리버스드 음성 데이터 모두에서 추출되는 것을 특징으로 한다. 본 발명의 또 다른 실시예에 따르면, 본 발명에 있어서 상기 인지장애및AD진단부는, MMSE 점수 예측과 알츠하이 머 진단을 동시에 수행하는 상호보완적 알고리즘(Complementary Algorithm)을 이용하여 인지장애 정도 예측과 AD 진단을 수행하는 인지장애및AD진단모듈을 포함하며, 상기 상호보완적 알고리즘은 예측값의 정확도를 높이기 위해 회귀 손실과 분류 손실을 함께 반영한 손실 함수를 활용하고, 상기 회귀 손실은 평균 제곱 오차(MSE; Mean Squared Error) 함수를 적용하고, 상기 분류 손실은 크로스 엔트로피(CE; Cross-Entropy) 함수를 적용하는 것을 특징으로 한다. 본 발명의 또 다른 실시예에 따르면, 본 발명에 있어서 상기 평균 제곱 오차(MSE) 함수에는 각 구간의 확률값에 따라 베르누이 페널티를 반영하여, 평균 제곱 오차(MSE)의 감소가 크로스 엔트로피(CE)의 감소로 연동되도록 하 고, 상기 크로스 엔트로피(CE) 함수에는 정답 구간과 예측 구간 사이의 오차 정도를 반영할 수 있도록 정답 구 간과 예측 구간 사이의 거리를 가중치로 반영하는 것을 특징으로 한다. 본 발명의 또 다른 실시예에 따르면, 본 발명에 있어서 상기 인지장애및AD진단부는, 음성 데이터에서 음성 분할 을 진행 후 분할된 음성 패턴을 기반으로 비유창성 특징을 추출하여 추출된 비유창성 특징을 기반으로 인공지능 (AI) 알고리즘을 이용하여 AD를 감지하는 AD감지모듈을 추가로 포함하며, 상기 비유창성 특징은, 정적 특징, 참 가자 특징 및 인터뷰어 특징을 포함하는 것을 특징으로 한다. 본 발명의 또 다른 실시예에 따르면, 본 발명에 있어서 상기 정적 특징은, 음성 녹음에서 정적 세그먼트들의 길 이의 총합(Len_S), 음성 녹음에서 정적 세그먼트들의 길이의 분산(Var_S), 음성 녹음에서 정적 세그먼트들의 길 이의 평균(Avg_S), 음성 녹음에서 정적 세그먼트들의 길이 중 최대길이(Max_S), 전체 음성 길이에 대해 정적 세 그먼트들의 비율(Rat_S), 음성 녹음에서 정적 세그먼트의 수(Num_S), 연속된 참가자 세그먼트 사이의 정적 세그 먼트의 수(Num_PS), 연속된 참가자 세그먼트 사이의 정적 세그먼트들의 길이의 평균(Avg_PS), 연속된 참가자 세 그먼트 사이의 정적 세그먼트들의 길이의 분산(Var_PS)을 포함하고, 상기 참가자 특징은, 전체 음성 길이에 대 해 참가자 세그먼트의 비율(Rat_P), 음성 녹음에서 참가자 세그먼트의 수(Num_P)를 포함하고, 상기 인터뷰어 특 징은, 음성 녹음에서 인터뷰어 세그먼트의 수(Num_I), 음성 녹음에서 참여자 세그먼트와 인터뷰어 세그먼트 사 이의 화자 변경 횟수(Num_chn)를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 앞서 본 실시예와 하기에 설명할 구성과 결합, 사용관계에 의해 다음과 같은 효과를 얻을 수 있다. 본 발명은, 음성 데이터를 바이오마커로 한 다양한 뇌 건강(난청, 인지장애, 치매 등)에 대한 예측 또는 진단을 가능케 하며 특히, 하나의 시스템으로 음성 데이터를 획득하기 위한 수집 환경 및 사용자 상태에 대한 체크에서 부터 음성 데이터 획득 과정에서의 음성 크기 모니터링 및 획득한 음성 데이터를 기반으로 한 난청, 인지장애 및 치매에 대한 예측 및 진단 결과 도출까지 이루어지게 되는 효과를 갖는다. 본 발명은, 음성데이터를 수집하기 위한 주변 환경 즉, 주변 소음 상태, 방음 상태 등에 대한 체크 및 음성데이 터를 수집해야 하는 사용자의 현재 몸 상태에 대한 체크 등을 통해 데이터의 일관성과 유효성을 담보하고 다양 한 뇌 건강 진단의 정확성을 높일 수 있게 하는 효과를 갖는다. 본 발명은, 난청 질환 유무 진단에 활용되는 음성 데이터를 부정적인 산문(긴 시나리오 형태의 1분 내외 길이의 글)을 읽은 음성 데이터와 긍정적인 산문을 읽은 음성 데이터 특히, 부정적인 산문의 경우 억울하고 격한 감정 을 모두 담아 읽은 음석데이터를, 긍정적인 산문의 경우 감정을 배제한 상태에서 읽은 음성 데이터를 활용함으 로써 대상자의 나이나 성별 등에 무관하게 난청 유무를 정확하고 효과적으로 진단할 수 있으며, 수집 과정 내지 보안 등의 문제로 충분히 확보되기 어려운 음성 데이터에 대해 원본 데이터를 증강시킨 데이터를 함께 활용함으 로써 데이터 수에 따른 과적합을 줄이면서도 효과적으로 획득된 음성 데이터를 활용하여 정확하게 난청 유무를 진단할 수 있는 효과를 갖는다. 본 발명은, 음성데이터에서 추출된 음향 특징을 입력받아 하나의 알고리즘을 이용하여 MMSE 점수 예측과 알츠하 이머 진단을 동시에 수행할 수 있고 이때, 예측 및 진단의 정확도를 높이기 위해 알고리즘에 회귀 손실과 분류 손실을 함께 반영한 손실 함수를 활용함에 있어서 회귀 손실과 분류 손실이 상호 보완적으로 작용할 수 있도록, 평균 제곱 오차(MSE) 함수에는 각 구간의 확률값에 따라 베르누이 페널티를 반영하여 평균 제곱 오차(MSE)의 감 소가 크로스 엔트로피(CE)의 감소로 연동되도록 하고, 크로스 엔트로피(CE) 함수에서 정답 구간과 예측 구간 사 이의 거리를 가중치로 반영하여 예측된 MMSE 점수를 실제 MMSE 점수와 유사하게 분포시킬 수 있게 하는 효과를 갖는다. 본 발명은, 음성활동감지(VAD) 시스템을 이용한 음성 분할과 화자 분할을 통해 정적 특징, 참가자 특징 및 인터 뷰어 특징을 포함하는 비유창성 특징을 활용하여 보다 정확하게 알츠하이머(AD)를 감지할 수 있으며 이때, 다양 한 정적 특징들 중에서 특히, 참가자의 발화에서의 정적 특징과 관련한 연속된 참가자 세그먼트 사이의 정적 세 그먼트의 수(Num_PS), 연속된 참가자 세그먼트 사이의 정적 세그먼트들의 길이의 평균(Avg_PS), 연속된 참가자 세그먼트 사이의 정적 세그먼트들의 길이의 분산(Var_PS) 특징을 고려하고, 인터뷰어 특징과 관련하여 인터뷰어 의 개입 정도와 관련한, 음성 녹음에서 인터뷰어 세그먼트의 수(Num_I), 음성 녹음에서 참여자 세그먼트와 인터 뷰어 세그먼트 사이의 화자 변경 횟수(Num_chn) 특징을 고려함으로써, 보다 정확하게 알츠하이머(AD)를 감지할 수 있는 효과를 갖는다. 본 발명은, 본 발명의 시스템을 이용한 진단/예측의 결과를 즉각적으로 확인할 수 있고, 획득한 음성 데이터는 암호화하여 저장하고 일정 시간 후 자동으로 삭제함으로써 개인정보를 보호할 수 있는 효과를 갖는다."}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 발명에 따른 음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치매 선별시스템의 바람직한 실시 예들을 첨부된 도면을 참조하여 상세히 설명한다. 도면들 중 동일한 구성요소들은 가능한 한 어느 곳에서든지 동일한 부호들로 나타내고 있음에 유의해야 한다. 특별한 정의가 없는 한 본 명세서의 모든 용어는 본 발명이"}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야의 통상의 지식을 가진 기술자가 이해하는 당해 용어의 일반적 의미와 동일하고 만약 본 명세서 에 사용된 용어의 의미와 충돌하는 경우에는 본 명세서에 사용된 정의에 따른다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미하며, 또한 명세서에 기재된 \"...부\", \"...모듈\" 등의 용어 는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소 프트웨어의 결합으로 구현될 수 있다. 도 1 내지 도 17을 참조하면, 본 발명의 일 실시예에 따른 음성 데이터를 이용한 AI 기반 난청, 인지장애 및 치 매 선별시스템은, 사용자의 음성 데이터를 수집하기 위한 입력부; 음성 데이터를 수집하기 위한 환경의 적 정 상태를 체크하는 녹음환경판정부; 음성 데이터를 수집하는 과정에서의 사용자의 음성 크기를 체크하는 음성크기판정부; 수집된 음성 데이터를 기반으로 인공지능(AI) 알고리즘을 이용하여 난청, 인지장애 정도 및 치매를 진단하는 진단예측부; 및 상기 진단예측부의 결과를 제공하는 출력부;를 포함할 수 있다. 먼저, 상기 입력부는 사용자의 음성 데이터를 수집하기 위한 구성으로, 일반적으로는 사용자로부터 발화되 는 음성 데이터를 수집할 수 있는 마이크와 같은 구성을 의미하며, 필요에 따라 사용자의 눈 움직임을 포함한 얼굴 영상에 대한 데이터도 같이 수집하기 위한 카메라와 같은 구성을 추가로 포함할 수 있다. 음성녹음에 사용되는 음향장비(마이크)의 기본구조는 입력부분, 가공부분, 증폭부분, 출력부분으로 되어 있다. 사람의 목소리가 입력될 때에는 소리라는 진동을 전기 신호로 바꾸어 저장하게 되는데 이때, 수음 가능한 주파 수 대역이 마이크마다 다르고 수음 가능한 최대 음압대도 모두 차이가 나게 되는데, 사람의 목소리로 발성할 수 있는 모든 음역대의 주파수 영역과 최대 음압대를 커버하여 소리가 찌그러지지 않게 안정적으로 수집 가능한 마 이크이면서 고유 음파가 어떤 가공이나 증폭부분 없이 수집가능해야, 음성 바이오마커로서의 좋은 음성데이터 수집이 가능케 된다. 따라서, 상기 입력부에서 사용되는 마이크는 수음 가능한 주파수 대역이 350Hz에서 17KHz 범위 즉, 모든 음역대의 주파수를 수집할 수 있는 그리고, 수음 가능한 최대 음압대 120dB까지 모든 소리가 뒤틀림이나 변형 없이 녹음 가능한 상태의 마이크가 활용됨이 바람직하다. 한편, 상기 입력부를 통해 획 득한 음성 데이터는 암호화하여 저장하고 일정 시간(결과 도출후 통상 1~2일 경과) 후 자동으로 삭제함으로써 개인정보를 보호할 수 있도록 관리하는 것이 바람직하다. 상기 출력부는 상기 진단예측부의 결과를 제공하는 구성으로, 입력되는 음성 데이터를 기반으로 예측, 진단된 결과치를 사용자 등이 직접 눈으로 확인할 수 있도록 결과물을 보여주는 디스플레이 내지는 출력물로 제 공하거나 또는 파일 형태로 제공하는 다양한 형태의 구성들이 상기 출력부로 활용될 수 있다. 상기 녹음환경판정부는 음성 데이터를 수집하기 위한 환경의 적정 상태를 체크하는 구성으로, 이를 위해 상 기 녹음환경판정부는, 보다 구체적으로, 사용자의 주변 환경이 음성 데이터를 수집하기에 적정한 상태인지 를 체크하는 주변환경판정모듈과, 사용자의 현재 몸상태가 음성 데이터를 수집하기에 적정한 상태인지를 체크하는 사용자상태판정모듈을 포함할 수 있다. 상기 주변환경판정모듈은 사용자의 주변 환경이 음성 데이터를 수집하기에 적정한 상태인지를 체크하는 구 성으로, 이를 위해 보다 구체적으로, 판정을 위한 소리를 발생시킨 후 수신되는 소리를 기반으로 주변 환경 상 태를 체크하는 제1판정모듈과, 주변 환경에 대한 영상 또는 이미지를 획득하여 주변 환경 상태를 체크하는 제2판정모듈과, 상기 입력부를 통해 입력되는 정보를 기반으로 주변 환경 소음을 체크하는 제3판정모 듈을 포함할 수 있다. 상기 제1판정모듈은 판정을 위한 소리를 발생시킨 후 수신되는 소리를 기반으로 주변 환경 상태를 체크하 는 구성으로, 즉 음성 데이터를 녹음하고자 하는 장소에 본 발명의 시스템을 설치 후에 본 발명의 시스템을 통 해 먼저 소리를 발생시킨 후에 상기 입력부 즉, 마이크를 통해 되돌아오는 소리를 수신하고 이를 기반으로 주변 환경 상태 특히, 특정 소리 이외의 소음이나 노이즈가 섞여 있는지, 그 정도가 어느 정도인지 등에 대한 주변 환경 상태를 체크하게 된다. 상기 제2판정모듈은 주변 환경에 대한 영상 또는 이미지를 획득하여 주변 환경 상태를 체크하는 구성으로, 바람직하게는 음성데이터를 수집하고자 하는 곳이 벽면의 80% 이상이 유리로 되어 있는 벽이 2면 이하이면서 넓 이가 1.2㎡ 이상인 방음이 가능한 장소임이 바람직한바, 상기 제2판정모듈에서는 카메라 등을 통해 주변 환경에 대한 영상 또는 이미지를 획득한 후 이를 기반으로 음성데이터를 수집하고자 하는 장소의 방음 상태 즉, 벽면의 80% 이상이 유리로 되어 있는 벽이 2면 이하로 외부 소음 차단이 가능하면서도 해당 장소의 바닥 면적이 최소 1.2㎡ 이상인 방음이 가능한 장소인지 여부를 체크하게 된다. 상기 제3판정모듈은 상기 입력부를 통해 입력되는 정보를 기반으로 주변 환경 소음을 체크하는 구성으 로, 즉 상기 입력부로 활용되는 마이크 등을 이용하여 사용자의 음성을 녹음하고자 하는 공간에서의 주변 소음의 정도가 수득되는 음성데이터의 품질에 영향을 최소화할 수 있는 20dB 이하인지 여부를 체크하게 된다. 체크 결과 주변 환경 소음이 일정 기준치(20dB 이하)를 초과하는 경우에는 음성 데이터 녹음을 실시하지 않고, 기준치를 만족하는 경우에만 음성 데이터를 획득할 수 있도록 한다. 상기 사용자상태판정모듈은 사용자의 현재 몸상태가 음성 데이터를 수집하기에 적정한 상태인지를 체크하 는 구성으로, 이를 위해 보다 구체적으로, 사용자로부터 입력되는 정보를 기반으로 사용자가 앓고 있는 질병이 음성 데이터 수집에 적정한지 여부를 체크하는 제4판정모듈과, 사용자의 자연 발화를 통해 수집된 정보를 기반으로 사용자 음성 품질이 음성 데이터를 수집하기에 적정한지 여부를 체크하는 제5판정모듈을 포함할 수 있다. 상기 제4판정모듈은 사용자로부터 입력되는 정보를 기반으로 사용자가 앓고 있는 질병이 음성 데이터 수집 에 적정한지 여부를 체크하는 구성으로, 사용자에게 관련 질병에 대한 정보를 요청하여 사용자로부터 입력되는 정보를 기반으로, 사용자가 현재 앓고 있는 또는 과거에 앓았던 질병이 음성데이터 수집에 영향을 미칠 수 있는 지 그로 인해 음성데이터 수집이 가능한지 여부를 체크하게 된다. 일 예로, 사용자로부터 입력되는 정보를 기반 으로 사용자가 현재 앓고 있는 질환이 목감기, 폐렴, 성대결절 등인 경우에는 이로 인해 음성데이터 신뢰도가 많은 영향을 받을 수 있는 질환이기 때문에, 이런 경우에는 음성데이터 수집을 할 수 없는 상태로 판단할 수 있 다. 상기 제5판정모듈은 사용자의 자연 발화를 통해 수집된 정보를 기반으로 사용자 음성 품질이 음성 데이터 를 수집하기에 적정한지 여부를 체크하는 구성으로, 앞서 상기 제4판정모듈을 통해 입력되는 정보를 기반 으로는 사용자가 음성데이터 수집에 영향을 미칠 수 있는 질환을 앓고 있지 않는 것으로 확인된다 하더라도, 사 용자가 인지하지 못한 상태에서 현재 사용자의 목 상태가 음성데이터 수집에 악영향을 미칠 수 있는 상태일 수있으므로, 상기 제5판정모듈에서는 사용자로부터의 자연 발화를 통한 음성데이터를 (상기 입력부 등의 구성을 이용하여)수집하고, 이를 기반으로 판단한 사용자 음성 품질이 음성데이터를 수집하기에 적정한지 여부 를 체크하게 된다. 일 예로, 자연 발화를 통해 수집된 음성에 (현재 목상태로 인한)불규칙한 노이즈들이 확인되 는 경우에는 음성데이터 수집을 할 수 없는 상태로 판단할 수 있다. 상기 음성크기판정부는 음성 데이터를 수집하는 과정에서의 사용자의 음성 크기를 체크하는 구성으로, 수집 되는 음성 데이터는 적정한 크기의 음량으로 50~120dB 사이 음성 크기로 녹음되는 것이 바람직한바, 실제 녹음 즉, 음성 데이터 수집이 이루어지는 과정을 실시간으로 모니터링하면서 해당 녹음 과정에서의 사용자 음성 크기 가 적정 범위 내로 유지되는지를 실시간 모니터링하면서 체크하게 된다. 만약, 적정한 음성 크기 범위 내를 벗 어나게 된 것으로 확인되는 경우, 재녹음 등을 진행할 수 있다. 이와 같이 본 발명의 시스템에서는, 상기 녹음환경판정부 및 음성크기판정부 등을 통해 음성 데이터를 획득하기 위한 수집 환경 및 사용자 상태에 대한 체크에서부터 음성 데이터 획득 과정에서의 음성 크기 모니터 링 등을 통해 획득되는 음성 데이터의 일관성과 유효성을 담보할 수 있게 함으로써 이를 기반으로 한 다양한 뇌 건강 진단의 정확성을 높일 수 있게 한다. 상기 진단예측부는 수집된 음성 데이터를 기반으로 인공지능(AI) 알고리즘을 이용하여 난청, 인지장애 정도 및 치매를 진단하는 구성으로, 이를 위해 상기 진단예측부는 보다 구체적으로, 음성 데이터에서 음성 특징 을 추출하여 추출된 음성 특징을 기반으로 인공지능(AI) 알고리즘을 이용하여 난청을 진단하는 난청진단부(41 0)와, 음성 데이터에서 음향 특징을 추출하여 추출된 음향 특징을 기반으로 인공지능(AI) 알고리즘을 이용하여 MMSE(Mini-Mental Status Examination) 점수를 예측하고 알츠하이머(AD; Alzheimer's Disease)를 진단하는 인 지장애및AD진단부를 포함할 수 있다. 상기 난청진단부는 음성 데이터에서 음성 특징을 추출하여 추출된 음성 특징을 기반으로 인공지능(AI) 알 고리즘을 이용하여 난청을 진단하는 구성으로, 이때 난청 진단을 위해 획득하는 음성 데이터는, 부정적인 긴 문 장(긴 시나리오 형태의 1분 내외 길이의 글) 읽기를 통해 획득한 음성 데이터와 긍정적인 긴 문장 읽기를 통해 획득한 음성 데이터를 포함할 수 있는데 특히, 부정적인 긴 문장 읽기를 할 때는 감정을 실은 상태 즉, 억울하 고 격한 감정을 모두 담아서 해당 문장을 읽도록 하여 획득한 음성 데이터이고, 긍정적인 긴 문장 읽기를 할 때 는 감정을 배제한 상태에서 독서하듯 읽도록 하여 획득한 음성 데이터인 것을 특징으로 한다. 이와 같은 형태로 획득된 음성 데이터를 기반으로 함으로써, 대상자로부터 보다 다양한 상태에서의 음성 데이터를 획득할 수 있게 되므로 대상자의 나이나 성별 등에 무관하게 난청 유무를 정확하고 효과적으로 진단할 수 있게 된다. 이와 같이 획득된 원본 음성 데이터만을 활용하는 것이 아니라, 상기 원본 음성 데이터(Original Audio Data)와, 원본 음성 데이터를 타임 인버전(Time Inversion) 방식을 사용하여 역방향으로 재생하여 증강시킨 리 버스드 음성 데이터(Reversed Audio Data)를 함께 활용함으로써, 음성 데이터의 수집 과정 내지 보안 등의 문제 로 충분히 확보되기 어려운 음성 데이터에 대해 원본 데이터를 증강시킨 데이터를 함께 활용함으로써 데이터 수 에 따른 과적합을 줄이면서도 효과적으로 획득된 음성 데이터를 활용하여 정확하게 난청 유무를 진단할 수 있게 한다. 획득된 음성 데이터에서 난청을 진단하는데 활용되는 음성 특징을 추출하게 되는데, 이때 추출되는 음성 특징은 특히, wav2vec 음성 특징일 수 있는데, wav2vec은 Facebook AI Research에서 개발한 자체 지도 음성 인식 모델 로, 상기 wav2vec은 이전 음성 프레임에서 추후 음성 프레임을 예측하도록 훈련된 CNN(Convolution neural network)을 인코더로 사용하며 입력 신호에서 유용한 컨텍스트 정보를 감지하여 고품질의 음성 feature(음성 특 징)을 얻을 수 있다. 음성 신호의 유익하고 추상적인 특징을 포함한 wav2vec는 모델의 마지막 hidden layer에 있는 벡터를 바탕으로 hidden state에 있는 sequence를 출력하여 512 차원의 feature 벡터를 추출하게 된다. 이 때 모든 오디오의 길이가 다르므로 전체 feature의 차원도 (512*입력 오디오의 전체 길이)로 상이하게 나오게 된다. 추출된 음성 특징을 입력받아 난청을 진단하는데 활용되는 인공지능(AI) 알고리즘은 특히, Swin Transformer일 수 있는데, Swin Transformer는 Microsoft Research에서 제안한 이미지 인식 작업을 위한 최신 트랜스포머 기 반 딥러닝 아키텍처이다. 본 특허에서는 Swin Transformer 인코더에 대한 입력으로 이미지가 아닌 wav2vec에서 추출한 사전 훈련된 특징을 사용하였다. 이때 Swin Transformer 아키텍처는 원래 이미지 인식 작업을 위해 설계 되었지만 입력으로 사용하는 wav2vec의 경우 (512*입력 오디오의 전체 길이)차원이라 사용이 가능하였다. 본 특 허에서는 epoch 1000, batch 8, learning rate 5e-4, window size 40, warmup step 20을 사용했으며, optimizer는 AdamW를 사용했다. 본 발명에서는, wav2vec 음성 특징을 입력 받아 Swin Transformer를 이용하여 난청을 진단하는 것이 보다 효과 적으로 난청 유무를 조기에 간편하고 정확하게 진단할 수 있는 음성 데이터를 이용한 AI 기반 난청 진단 방법으 로 제시하고 있는데, 이하 실험을 통해 이를 입증하고 있다. [실험 1] 대상자의 음성 데이터를 이용한 난청 유무 진단 정확성 실험 - 실험 대상자 : 상기 실험 대상자는 483명을 대상으로 아래의 [표 1]에서와 같이 성별을 기준으로는 여자 321 명과 남자 162명으로 나뉘고, 난청 질병 유무를 기준으로는 정상 피실험자 118명과 난청 환자 365명으로 나뉜다. 1) 이비인후-두경부외과의 전문적인 청력검사를 통해 고막이 정상이면서, 주관적 난청 기간이 3년 이상 인 질환자, 2) 더 좋은 쪽의 청력을 기준으로 500Hz, 1000Hz, 2000Hz, 4000Hz 평균이 40dB 이상인 질환자와 같 다. 표 1 정상 환자 총계 여성 89 232 321 남성 29 133 162 총계 118 365 483 - 음성 데이터 수집 : 각 실험 대상자들에 대해 1분 내외의 부정적인 긴 시나리오 읽기(chapter 7)와 긍정적인 긴 신문 사설 읽기(chapter 8) 총 2개의 task를 수행하여 음성 데이터를 수집하였다. 이때 chapter 7에서 부정 적인 긴 문장을 읽을 때는 억울하고 격한 감정을 모두 담아서 읽게 하도록 지시하였고, chapter 8에서 신문 사 설의 읽기 경우는 감정을 배제하고 독서하듯 읽게 지시하였다. - 데이터 증강 : 본 실험에서 획득한 원본 음성 데이터(Original Audio Data)는 정상 피실험자 118명과 난청 환 자 365명 총 483명의 음성 데이터이다. 따라서, 데이터 수에 대한 과적합을 줄이고 모델이 실제 환경에서 잘 동 작할 수 있도록 원본 음성 데이터를 역방향으로 재생하여 feature(음성 특징)를 뽑는 형식으로 데이터 증강 (data augmentation)을 수행(특히, time inversion 방식을 사용하여 데이터 증강을 수행)하였는데, 이 과정을 통해 원본 음성 데이터(Original Audio Data)와 리버스드 음성 데이터(Reversed Audio Data)를 합쳐 학습을 시 키게 되면 normal 236개, patient 730개의 데이터 총 966개의 음성 데이터를 model train과 validation에 사용 할 수 있게 된다. - 실험 환경 : 본 실험은 Linux와 Windows 환경에서 진행되었으며, GPU 환경에서 딥러닝 모델을 학습을 진행하 기 위해 NVIDIA GeForce RTX 2070 16GB 1개와 A100 40GB 2개를 사용하였다. - 실험 방법 : 획득된 모든 음성 데이터(dataset)에서 eGemaps, mel-spectrogram, wav2vec 총 3가지 feature (음성 특징)을 추출하였고, 이후 SVM, MLP-LSTM, VGGish, Swin 총 4가지 model(인공지능 알고리즘)에 각각 적 용하여 normal과 patient 총 2개의 label을 가진 5-Fold Cross-Validation을 이용한 classification을 수행하였다. Unseen 방식은 전체 dataset에서 80%의 사람은 train에 사용하고 20%의 사람은 validation에 사용 함으로써 한 번도 train되지 않은 사람에 대해서 test하게 되는 방식이고, Cross-Subject 방식은 한 사람의 음 성 데이터의 80%는 train, 20%는 validation 과정에 사용함으로써 한 번 train 했던 사람에 대하여 test 하는 것이지만, train에 사용하였던 것과는 다른 부분의 음성 데이터를 사용하게 된다. - 실험 결과 1. 먼저 데이터 증강을 하지 않고 즉, 원본 음성 데이터(Original Audio Data)만을 사용하여 5-Fold Cross- Validation을 이용한 classification을 수행하였는데, 여기서 사용한 음성 특징 및 모델(인공지능 알고리즘)은 eGemaps feature를 사용하는 MLP-LSTM와 SVM, wav2vec feature를 사용하는 Swin Transformer, 오디오를 Mel- stectrogram으로 변환 후 고유한 VGGish feature를 사용하는 VGGish 이었는데, 그 결과 '도 3'에 나타난 바와 같이, Swin과 VGGish 50 epoch의 성능은 비슷하나, epoch의 수를 100으로 늘릴 경우 VGGish의 성능이 Unseen에 서는 약 81.24%, Cross Subject에서는 84.44%로 가장 높음을 확인할 수 있다. 반면, eGemaps feature를 사용한 MLP-LSTM과 SVM은 모든 결과에서 75% 이상의 정확도를 얻지 못한 것으로 나타났다. 한편, Unseen 검증방식의 경 우 한 번도 훈련되지 않은 피실험자 데이터에 대한 검증을 시행하기 때문에 Cross Subject 검증방식보다는 2~3% 가량 낮음을 확인할 수 있다. 2. 데이터 증강을 하지 않았을 때의 eGemaps feature를 사용한 MLP-LSTM과 SVM 모델의 성능은 좋지 않았기 때문 에, 성능이 좋았던 Swin과 VGGish만을 사용하여 데이터 증강 이후의 실험(원본 음성 데이터와 역재생한 리버스 드 음성 데이터를 사용하여 wav2vec, VGGish 피처(feature)를 뽑고, Swin과 VGGish 모델을 5-Fold Cross- Validation으로 훈련 후 검증)을 추가로 진행하였는데, 그 결과 '도 4' 및 '도 5'에 나타난 바와 같이, Unseen 방식에서는 Swin이 약 84.11%의 분류 정확도로 최고 성능을 나타내었고, Cross subject 방식에서는 VGGish가 약 85.54%의 분류 정확도로 최고 성능을 나타내었다. 즉, 본 [실험]을 통해, 본 발명에서 제시한 부정적인 긴 문장 읽기를 통해 획득한 음성 데이터(chapter 7)와 긍 정적인 긴 문장 읽기를 통해 획득한 음성 데이터(chapter 8)를 활용하여 난청 유무에 대한 진단이 가능함을 확 인하였고 특히, 두 데이터를 합쳐서 활용하는 경우에 난청에 대한 분류 정확도가 높아지며 또한, 정상적인 원본 음성 데이터와 데이터 증강시킨 리버스드 음성 데이터를 모두 사용하였을 때 분류 정확도가 더욱 높게 나타남을 확인할 수 있다. 또한, 난청을 진단하는 음성 특징 및 모델에서는, Unseen 검증 방법의 경우 대부분 Swin의 정확도가 80% 초중반 대로 높게 나타나고 있고, Cross-subject 검증 방법의 경우 Swin 또는 VGGish에서 90% 이상의 정확도를 내는 fold도 존재하며 평균을 내었을 때는 대부분 80% 중반의 정확도를 보이고, Swin과 VGGish의 성능이 엇비슷함을 확인할 수 있다. 다만, subject independent 검증 방식에서는 cross-subject 방식보다는 unseen subject task 가 더 어렵다는 점 그리고, 추후 범용적인 활용까지 고려하면 wav2vec 음성 특징을 입력 받아 Swin Transformer 를 이용하여 난청을 진단하는 방법이 가장 효율적이며 정확하게 난청 유무를 분류하는 모델로 적합하다는 것을 확인할 수 있다. 상기 인지장애및AD진단부는 음성 데이터에서 음향 특징을 추출하여 추출된 음향 특징을 기반으로 인공지능 (AI) 알고리즘을 이용하여 인지장애 정도예측과 알츠하이머(AD) 진단을 수행하는 구성으로, 이를 위해 상기 인 지장애및AD진단부는 보다 구체적으로, MMSE 점수 예측과 알츠하이머 진단을 동시에 수행하는 상호보완적 알고리즘(Complementary Algorithm)을 이용하여 인지장애 정도 예측과 AD 진단을 수행하는 인지장애및AD진단모 듈 및 음성 데이터에서 음성 분할을 진행 후 분할된 음성 패턴을 기반으로 비유창성 특징을 추출하여 추출 된 비유창성 특징을 기반으로 인공지능(AI) 알고리즘을 이용하여 AD를 감지하는 AD감지모듈을 포함할 수 있다. 상기 인지장애및AD진단모듈은 MMSE 점수 예측과 알츠하이머 진단을 동시에 수행하는 상호보완적 알고리즘 (Complementary Algorithm)을 이용하여 인지장애 정도 예측과 AD 진단을 수행하는 구성으로, 이와 같은 예측 및 진단을 위해 활용되는 음성 데이터의 음향 특징은 음성 데이터의 문맥을 반영하기 위해 음성 데이터 전체를 대 상으로 하여 음향 특징을 추출하게 되는데, 기존 언어적 특징을 사용한 모델에서는 음성으로부터 수동 방식이나 자동 음성 인식(automatic speech recognition; ASR)을 통해 Transcription을 제작하여 특징을 추출하여야 하 는데, 수동으로 Transcription을 작성하기엔 비용과 시간이 많이 소요되며, ASR을 이용하면 잡음에 취약하고, 모델의 성능이 ASR 성능에 영향을 받는다는 문제점이 발생하고 있는바, 본 발명에서는 음향 특징(음향 특징의 순차적인 정보)만을 이용하여 AD를 정확하게 진단 및 인지장애 정도를 예측할 수 있게 하는 특징이 있다. 이와 같이 추출된 음향 특징을 입력받아 뉴럴 네트워크를 이용하여 MMSE(Mini-Mental Status Examination) 점 수를 예측하고 알츠하이머(AD; Alzheimer's Disease)를 진단하는 과정에서 본 발명은 하나의 알고리즘(상호보완 적 알고리즘(Complementary Algorithm))을 이용하여 MMSE 점수 예측과 알츠하이머 진단을 동시에 수행하는 것이 특징이다. 즉, 음성 특징을 이용하여 인지장애 정도를 예측하기 위해 MMSE 점수를 예측하거나 알츠하이머를 진 단하는 종래의 모델들은 각각 별도의 회귀 모델(Regression Model)과 분류 모델(Classification Model)을 이용 하여 MMSE 점수 예측과 알츠하이머 진단(AD Detection)을 별도로 진행하고 있었던바, 일 예로, 도 7에 도시된 종래의 MMSE 점수 예측 모델은 MMSE 점수 예측을 위해 MSE(Mean Squared Error) 함수를 적용하고 있으나, 예측 값이 평균 주위로 회귀되어 예측된 MMSE 점수로 알츠하이머 여부를 판단하는 것은 불가하기 때문에 여전히 MMSE 점수 예측과 알츠하이머 진단(AD Detection)을 별도의 모델로 수행할 수밖에 없게 된다. 이러한 문제를 해결할 수 있도록, 본 발명에서는 독창적으로 설계된 하나의 상호보완적 알고리즘(Complementary Algorithm)을 이용하여 MMSE 점수 예측과 알츠하이머 진단을 동시에 수행할 수 있게 되는데, 이를 위해 상기 상 호보완적 알고리즘(Complementary Algorithm)은, 도 6에 도시된 바와 같이, 예측값의 정확도를 높이기 위해 회 귀 손실과 분류 손실을 함께 반영한 손실 함수를 활용하게 된다. 한편, 상기 MMSE 점수 예측은 예측값을 실제 분포에 최적화시키기 위해, 도 4에 도시된 예에서와 같이, MMSE 점 수구간을 균등하게 복수의 구간으로 나누어 각 구간의 확률을 예측하고 이때의 MMSE 점수는 확률분포의 기대값 으로 추정된다. 도 8에 도시된 예에서는, MMSE의 총 점수구간(30점)을 3점 단위로 균등하게 10개의 구간으로 나누어 각 구간의 확률을 예측한 후 MMSE 점수를 확률분포의 기대값으로 추정하는 예를 나타내고 있다. 본 발명의 상기 상호보완적 알고리즘(Complementary Algorithm)에서는 상기 회귀 손실로 평균 제곱 오차(MSE; Mean Squared Error) 함수를 적용하고, 상기 분류 손실로는 크로스 엔트로피(CE; Cross-Entropy) 함수를 적용 하는 것을 특징으로 한다. 즉, MMSE 점수 예측에서 적은 데이터만으로도 모델의 예측이 실제 정답 분포와 유사 하도록, 평균 제곱 오차(MSE; Mean Squared Error) 함수뿐만 아니라 분류에서 사용되는 크로스 엔트로피(CE; Cross-Entropy) 함수를 추가적으로 반영하고 있는데, 이는 아래 수학식 4에서 확인할 수 있다. 수학식 1"}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2"}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 3"}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 4"}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "(상기 수학식 1 내지 4에서, 는 N크기의 배치 내에서 i번째 환자의 MMSE 점수이고, 는 i번째 MMSE 점수의 번째 구간 확률, 는 번째 예측 값의 번째 구간 확률이다) 즉, 상기 수학식 4에서, CE를 통해 구간을 잘 예측하게 되면 예측되는 MMSE 점수도 실제 MMSE 점수와 가까워지 고, MSE의 감소로 이어지게 되는 특징을 갖는다. 다만, 일반적으로 의료데이터와 같이 데이터가 적은 상황에서는, MSE는 예측 값을 평균 주위로 회귀시키기 때문 에 MSE가 감소한다고 해서 CE의 감소로 이어지진 않게 되고, 이에 따라 두 손실함수가 상호적으로 보완할 수 없 게 되는 상황이 발생할 수 있는바, 본 발명에서는 추가적으로 데이터가 적은 상황에서도 회귀 손실과 분류 손실 이 상호 보완적으로 작용할 수 있도록, 평균 제곱 오차(MSE) 함수에는 각 구간의 확률값에 따라 베르누이 페널 티를 반영하여, 평균 제곱 오차(MSE)의 감소가 크로스 엔트로피(CE)의 감소로 연동되도록 하는 것을 주요한 특 징으로 한다. 베르누이 페널티를 반영한 수정된 MMSE 산출식(MSE(M,g(P)))은 아래 수학식 5에서 확인할 수 있다. 수학식 5 MSE(M,g(P))="}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "베르누이 분포의 분산은 확률이 0.5일때 가장 높기 때문에 각 구간에서 예측된 확률 값이 나머지 예측 확률과 비슷한 값을 가질 경우 MSE에 손실이 크게 반영된다. 따라서 모델이 각 구간의 확률을 1 또는 0과 가깝게 예측 할 수 있게 된다. 한편, 일반적으로 크로스 엔트로피(CE; Cross-Entropy) 함수는 단순히 정답 구간의 확률만으로 계산되기 때문에 정답 구간과 예측 구간이 어느 정도 오차를 갖는지 반영하지 못한다. 이에 본 특허에서는 정답 구간과 예측 구 간 사이의 오차 정도를 반영하기 위해, 이 둘 사이의 거리를 가중치로 반영한 Weighted CE를 제안한다. 즉, 크 로스 엔트로피(CE) 함수에서 정답 구간과 예측 구간 사이의 거리를 가중치로 반영함으로써, 예측된 MMSE 점수를 실제 MMSE 점수와 유사하게 분포시킬 수 있게 하는 것을 특징으로 한다. 정답 구간과 예측 구간 사이의 거리는 절대값 거리와 제곱 거리 2가지로 정의하며, 아래의 수학식 6 및 수학식 7을 통해 확인할 수 있으며, 제안되는 Weighted CE는 아래 수학식 8을 통해 확인할 수 있다. 수학식 6"}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 7"}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "수학식 8"}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "(이때, 와 는 각각 절대값 거리와 제곱 거리를 나타낸다) 최종적으로 본 발명에서 베르누이 페널티를 적용한 가중 MSE-CE 손실함수는 아래 수학식 9와 같다. 수학식 9"}
{"patent_id": "10-2024-0028952", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "이와 같이 베르누이 페널티를 적용한 가중 MSE-CE 손실함수는, MMSE 산출식에 베르누이 페널티를 부여함으로써 MSE와 CE가 상호 보완하게 되며, CE에 정답 구간과 예측 구간 사이의 거리를 가중치로 반영함으로써 실제 정답 분포와 유사하게 예측하도록 학습이 가능하게 된다. 이하, 실험에서는 본 발명에서 최종적으로 제안하는 베르누이 페널티를 적용한 가중 MSE-CE 손실함수의 효과를 확인하고, ADReSSo 데이터셋(ADReSSo 챌린지 2020에서 1위를 달성한 Koo et al.의 모델(Koo and Junghyun, \"Exploiting multi-modal features from pre-trained networks for Alzheimer's dementia recognition.\" in the Proc. of Interspeech, September 2020))에서 음향 특징만을 사용한 기존 모델들과 성능을 비교한다. [실험 2] 베르누이 페널티를 적용한 가중 MSE-CE 손실함수의 효과 실험 - ADReSSo 데이터셋 ADReSSo 데이터셋은 알츠하이머 구분, 인지능력 평가 점수 추론 및 인지저하 예측을 위한 데이터셋이다. 총 166 개의 학습 데이터셋과 71개의 검증 데이터셋으로 이루어져 있다. 음성 파일은 피검사자가 Cookie Theft 사진(도 9 참조)을 설명하는 음성이며, 간호사의 음성이 포함될 수 있다. 본 특허에서는 음성파일에서 추출되는 VGGish 특징과 발화자별 음성 Segment를 모델의 입력으로 사용한다. - 실험 방법 MMSE Score Prediction 모델은 구간 수 B를 10으로 설정하고, 페널티 튜닝 파라미터 λ를 1로 설정하여 실험한 다. AD Detection은 MMSE Score Prediction을 수행한 모델의 예측 값을 27점을 기준으로 Thresholding하여 예 측한다. 마지막으로 모든 학습 데이터에 Time Inversion으로 데이터를 증강하여 실험한다. - 실험 결과 도 10을 참조하면, ADReSSo 챌린지 2020에서 1위를 달성한 Koo et al.의 모델에서와 같이 손실함수로 MSE만을 사용한 경우 매우 낮은 성능인 6.60의 RMSE를 보였고, 이와 같이 예측된 점수로 AD Detection 분류를 수행할 경 우, 모델이 대부분 평균 주위로 점수를 예측하기 때문에 매우 낮은 49.30%의 정확도를 보였다. 이때 본 발명에서 제안한 모델(Jin et al. 모델)과 같이, 손실함수에 CE를 추가적으로 반영하면, 모델의 예측 값을 실제 MMSE 점수의 분포와 유사하게 예측하도록 학습시킬 수 있게 되는바, 구간에 대한 분류 손실의 감소가 MSE의 감소로 이어져 RMSE가 5.49까지 줄어든 모습을 볼 수 있다. 보다 정확한 MMSE 점수 예측을 통해 AD Detection에서도 분류 정확도가 16.90% 증가하는 것을 확인할 수 있다. 여기에 본 발명에서 최종적으로 제안하는 모델(Proposal 모델)과 같이, MMSE 산출식에 베르누이 페널티를 반영 하면 MSE의 감소가 CE의 감소로 이어지고, 두 손실함수가 상호 보완하게 된다. 따라서 베르누이 페널티를 적용 하지 않았을 때보다 RMSE는 0.70, 정확도는 4.22% 향상된 모습을 확인할 수 있다. 추가적으로 가중 CE를 사용하 면, 절대값 거리를 사용했을 때 가장 좋은 성능인 4.55의 RMSE와 77.46%의 정확도를 달성한다. 그러나 베르누이 페널티 없이 가중 CE만 반영할 경우, (두 손실함수가 상호 보완하지 못하면서)MMSE 점수 예측에서만 성능이 향 상되는 모습을 볼 수 있다. - ADReSSo 데이터셋에서 음향 특징만을 사용한 모델과의 비교 도 11을 참조하면, 1) MMSE 점수 예측을 수행한 모델 중 Luz et al.[S. Luz, F. Haider, S.d.l. Fuente, D. Fromm, B. MacWhinney \"Detecting cognitive decline using speech only: The adresso challenge.\" in Proc, Interspeech, 2021, pp. 3780-3784]에서는 eGeMAPS으로 SVM을 수행하여 6.09의 RMSE를 얻었다. P rez-Toro et al.[P.A. P rez-Toro, et al., \"Influence of the Interviewer on the Automatic Assessment of Alzheimer's Disease in the Context of the ADReSSo Challenge,\" in Proc, Interspeech, 2021, pp. 3785-3789]에서는 Prosody Featrue, X-vector, 그리고 VAD의 Valence와 Dominance 특성을 이용해 선형 회귀로 기존 음향 특성만 을 사용한 모델 중 가장 좋은 5.35의 RMSE를 달성했다. 그러나 본 특허(Weighted MSE-CE Loss with Bernoulli Penalty)에서는 VGGish 특징만으로 동시에 MMSE 점수 예측과 AD Detection을 수행하면서도 크게 향상된 4.55의 RMSE를 달성한다. 2) 또한, AD Detection을 수행한 모델 중에서는 Luz et al.에서 eGeMAPS으로 64.79%의 정확 도를 얻었다. Gauder et al.[L. Gauder, L. Pepino, L. Ferrer, P. Riera, \"Alzheimer Disease Recognition Using Speech-Based Embeddings From Pre-Trained Models,\" in Proc. Interspeech, 2021, pp. 3795-3799]에서 는 Wav2Vec 2.0을 이용해 1차원 CNN 층을 쌓아 음향 특성만을 이용한 모델 중 가장 높은 정확도인 78.9%를 달성 했다. 그러나, 본 특허에서는 동시에 MMSE 점수 예측과 AD Detection을 수행하면서도 이보다 높은 80.28%의 정 확도를 달성하고, 데이터 증강을 하지 않더라도 이와 유사한 77.46%의 정확도를 달성하였다. 3) 최종적으로 본 특허에서는 ADReSSo 데이터셋에서 음향 특징만을 사용한 모델 중 MMSE 점수 예측과 AD Detection에서 모두 가장 높은 성능을 달성하였다. 특히, 기존 모델들이 두 과제를 별도의 모델로 수행한 것과 달리, 본 특허에서는 하나 의 모델로 두 과제 모두를 동시에 수행하면서도 보다 향상된 높은 성능을 달성하였다. 결론적으로, 본 특허에서 제안한 모델은, MMSE 점수 예측에서 회귀 손실과 분류 손실을 함께 반영하고, 예측된 확률 값에 대한 페널티와 분류 손실에 거리 기반 가중치를 반영함으로써, 베르누이 페널티는 회귀 손실과 분류 손실이 학습 시 상호 보완하도록 만들고, 거리 기반 가중치는 모델이 실제 MMSE 점수의 분포를 보다 잘 학습하 도록 한다. 이를 통해 상기 실험 2에서 확인한 바와 같이, ADReSSo 데이터셋에서 음향 특성만을 이용해 MMSE 점수 예측과 AD Detection을 수행한 결과 중 가장 높은 4.55의 RMSE와 80.28%의 정확도를 달성하였다. 이와 같이, 본 발명은 음성데이터에서 추출된 음향 특징을 입력받아 뉴럴 네트워크를 이용하여 MMSE(Mini-Mental Status Examination) 점수를 예측하고 알츠하이머(AD; Alzheimer's Disease)를 진단할 수 있는 즉, 하나의 알고리즘을 이용하여 MMSE 점수 예측과 알츠하이머 진단을 동시에 수행할 수 있으면서도, 회귀 손실과 분류 손실이 상호 보 완적으로 작용할 수 있도록 평균 제곱 오차(MSE) 함수에는 각 구간의 확률값에 따라 베르누이 페널티를 반영하 고, 크로스 엔트로피(CE) 함수에서는 정답 구간과 예측 구간 사이의 거리를 가중치로 반영하여 예측된 MMSE 점 수를 실제 MMSE 점수와 유사하게 분포시킬 수 있도록 함으로써, 보다 정확한 예측과 진단을 가능케 한다. 상기 AD감지모듈은 음성 데이터에서 음성 분할을 진행 후 분할된 음성 패턴을 기반으로 비유창성 특징을 추출하여 추출된 비유창성 특징을 기반으로 인공지능(AI) 알고리즘을 이용하여 AD를 감지하는 구성으로 특히, 화자의 자발적인 발화에서의 비유창성에 포커싱하고 있는바, 음성 분할 역시 화자의 자발적인 발화에서의 음성 데이터를 그 대상으로 하며, 또한 전사(transcription)에 의존하지 않고 음성 녹음에서 비유창성 특징을 추출할 수 있도록 하기 위해 음성활동감지(VAD, Voice Activity Detection) 시스템(알고리즘)을 사용하여 음성 분할을 진행하게 된다. 음성데이터에서 음성을 분할하는 단계는, 뉴럴 네트워크(일 예로, 상기 VAD 알고리즘 또는 사전 훈련된 오디오 신경망(PANN))을 이용하여 입력된 음성데이터에 대해 음성 세그먼트와 정적 세그먼트로 분할하는 과정으로, 목 표는 음성데이터를 음성 부분(음성 세그먼트)과 일시정지 부분(정적 세그먼트)로 나누는 것이다. 이를 위해, 사 전 훈련된 오디오 신경망(PANNs: large-scale pretrained audio neural networks for audio pattern recognition) 등을 활용하여 음성의 패턴을 잡을 수 있는데, 상기 PANN은 원시 녹음된 음성세이터를 입력으로 받아 오디오 태깅을 출력한다. '말하기'로 태그된 오디오 세그먼트는 음성 부분(음성 세그먼트)으로 간주되고, 그 외 다른 부분은 일시정지 부분(정적 세그먼트)로 간주되게 된다. 이후, 뉴럴 네트워크를 이용하여 분할된 음성 세그먼트에 대해 참가자 세그먼트와 인터뷰어 세그먼트로 세분화 하여 분할하게 되는데, 이러한 화자 분할을 위해 앞서 '말하기'로 태그된 오디오 세그먼트(음성 세그먼트)를 뉴 럴 네트워크(일 예로, Pyannote(Pyannote.Audio: neural building blocks for speaker diarization) 등)를 활 용하여 오디오 세그먼트에서 다른 화자를 자동으로 분리할 수 있다. 일 예로, 최소 화자 수를 1로, 최대 화자 수를 2로 설정하게 되면, 오디오 세그먼트에서 더 긴 발화 시간을 갖는 화자를 참가자로, 그 외 다른 화자를 인 터뷰어로 간주하여 자동으로 분리할 수 있다. 결과적으로, 이러한 과정을 통해 음성데이터는 참가자 (Participant)의 음성 세그먼트를 나타내는 P, 인터뷰어(Investigator 또는 Interviewer)의 음성 세그먼트를 나타내는 I, 정적(Silence) 세그먼트를 나타내는 S 의 시퀀스로 표현될 수 있다(도 12 참조). 참고로, 도 12는 AD가 있는 경우와 없는 경우의 발화에서의 비유창성 특징을 시각화한 이미지인데, 도 12를 참 조하면, AD가 있는 참가자들이 응답 시간이 더 길고, 인터뷰어의 개입이 더 많으며, 언어에 관계없이 음성 사이 의 일시정지가 더 길고 많다는 것을 보여주는데, 이러한 부분은 후술할 비유창성 특징을 설계하는데 활용케 된 다. 이후, 분할된 음성 패턴을 기반으로 비유창성 특징을 추출하게 되는데, 이 과정에서의 비유창성 특징은, 정적 (S) 특징, 참가자(P) 특징, 인터뷰어(I) 특징 및 메타데이터(M) 특징을 포함할 수 있다(도 13 참조). 먼저, 상기 정적 특징은, AD 감지에 가장 중요한 특징으로 볼 수 있는데, 비정상적인 말의 중단, 더 긴 정적의 지속 시간, 더 많은 말의 일시정지 횟수는 알츠하이머(AD) 환자에서 나타나는 증상이기 때문이다. 상기 정적 특 징에는 기본적으로 통계적 특징을 포함한다. 즉, 음성 녹음에서 정적 세그먼트들의 길이의 총합(Len_S), 음성 녹음에서 정적 세그먼트들의 길이의 분산(Var_S), 음성 녹음에서 정적 세그먼트들의 길이의 평균(Avg_S), 음성 녹음에서 정적 세그먼트들의 길이 중 최대길이(Max_S), 전체 음성 길이에 대해 정적 세그먼트들의 비율(Rat_S), 음성 녹음에서 정적 세그먼트의 수(Num_S)를 포함할 수 있다. 상기 정적 특징들 중에서 음성 녹음에서 정적 세 그먼트들의 길이의 총합(Len_S), 음성 녹음에서 정적 세그먼트들의 길이의 평균(Avg_S), 전체 음성 길이에 대해 정적 세그먼트들의 비율(Rat_S), 음성 녹음에서 정적 세그먼트의 수(Num_S) 특징들은 입력되는 음성데이터에서 의 정적 세그먼트와 관련한 통계적 특징을 통해 AD 진단 정확성을 높이기 위해 고려되는 정적 특징들이며 특히, 상기 정적 특징들 중에서, 음성 녹음에서 정적 세그먼트들의 길이 중 최대길이(Max_S), 음성 녹음에서 정적 세 그먼트들의 길이의 분산(Var_S) 특징은 음성데이터에 포함될 수 있는 이상 데이터에 의한 영향을 최소화하면서 보다 정확하게 정적 특징에 의한 AD 감지가 이루어질 수 있게 하기 위해 고려되는 특징이다. 한편 상기 정적 특징에서는 화자들 중에서 참가자(P)에 의해 유발되는 즉, 참가자 음성데이터에서의 정적 특징 과 관련한 특징들만을 추가로 더 포함할 수 있는데, 구체적으로 연속된 참가자 세그먼트 사이의 정적 세그먼트의 수(Num_PS), 연속된 참가자 세그먼트 사이의 정적 세그먼트들의 길이의 평균(Avg_PS), 연속된 참가자 세그먼 트 사이의 정적 세그먼트들의 길이의 분산(Var_PS)을 추가로 포함할 수 있다. 연속된 참가자 세그먼트 사이의 정적 세그먼트의 수(Num_PS)는 참가자의 연속적인 발화 과정에서 정적 세그먼트의 수 즉, 발화 과정에서 얼마나 자주 일시 정지(무성 휴지, silence pause)가 나타나는지에 대한 특징을 확인할 수 있고, 연속된 참가자 세그먼 트 사이의 정적 세그먼트들의 길이의 평균(Avg_PS)은 참가자의 연속적인 발화 과정에서 정적 세그먼트 즉, 일시 정지(무성 휴지(silence pause), 무성 휴지는 '어(uh), 음(um) 등'과 같은 유성 유지(filled pause) 대비 발화 신호(음성데이터)에서 더 쉽게 추출할 수 있으면서도 언어에 구분 없이 분석에 활용될 수 있는 장점이 있음)가 평균적으로 얼마나 길게 이어지는지에 대한 특징을 확인할 수 있고, 연속된 참가자 세그먼트 사이의 정적 세그 먼트들의 길이의 분산(Var_PS)은 참가자의 연속적인 발화 과정에서 나타나는 정적 세그먼트 즉, 일시 정지(무성 휴지, silence pause)의 길이가 얼마나 균등한 비율로 나타나는지에 대한 특징을 확인할 수 있게 되므로, 이러 한 특징들을 이용함으로써 (AD 질환이 없는데도)원래 발화를 천천히 하면서 발음과 발음 사이에 일정한 휴지기 를 갖는 발화 성향을 갖는 참가자를 걸러낼 수 있게 되므로, AD 진단의 정확성을 높일 수 있게 한다. 상기 참가자 특징은, 전체 음성 길이에 대해 참가자 세그먼트의 비율(Rat_P), 음성 녹음에서 참가자 세그먼트의 수(Num_P)를 포함하고, 상기 인터뷰어 특징은, 음성 녹음에서 인터뷰어 세그먼트의 수(Num_I), 음성 녹음에서 참여자 세그먼트와 인터뷰어 세그먼트 사이의 화자 변경 횟수(Num_chn)를 포함한다. 상기 인터뷰어 특징에서 인 터뷰어 세그먼트의 비율(Rat_I)을 포함하지 않는 것은 불필요한 중복을 피하기 위함이다(즉, Rat_S+Rat_P+Rat_I 는 항상 1이기 때문이다). 특히, 상기 인터뷰어 특징은 AD 진단의 정확성을 높이는데 중요한 요소로 작용하게 되는데, 이는 AD 환자에 대 한 인터뷰(조사) 과정에서는 인터뷰어(조사자)의 개입이 더 빈번하게 발생되게 되므로, 상기 음성 녹음에서 인 터뷰어 세그먼트의 수(Num_I)뿐 아니라 특히, 음성 녹음에서 참여자 세그먼트와 인터뷰어 세그먼트 사이의 화자 변경 횟수(Num_chn) 특징은 그만큼 AD 진단의 정확성을 높이는데 기여하는 비유창성 특징으로 볼 수 있다. 상기 메타데이터 특징은, 획득한 음성 데이터를 이용한 AD 진단에 있어서, 음성 데이터 및 그로부터 추출된 비 유창성 특징의 상대성을 고려할 수 있게 하는 특징으로, 음성 녹음의 총 녹음길이(Len), 참가자의 나이(Age), 참가자의 연단위 교육수준(Edu)을 포함할 수 있다. 즉, 참가자의 나이가 많을수록 전반적으로 발화에 시간이 더 많이 소요된다는 점과 AD 위험성도 높아진다는 점을 고려할 수 있게 하고, 그리고 참가자의 교육 수준에 따라 자발적 발화에 영향을 미치게 되는 점을 고려할 수 있게 함으로써, 비유창성 특징에 참가자별 상대성까지 고려 되도록 하여 보다 정확한 AD 진단이 가능케 된다. 이렇게 추출된 비유창성 특징을 입력받아 뉴럴 네트워크를 이용하여 알츠하이머(AD; Alzheimer's Disease)를 감 지하게 되는데, 일반적으로 인지장애(AD 포함) 진단을 위한 데이터셋은 타 분야 대비 작은 편이므로, 학습 데이 터에 과적합이 문제될 수 있는바, 이러한 과적합을 방지하기 위해 간단한 기계학습 분류기를 활용하여 AD 분류/ 진단(AD Classification)을 할 수 있는데, 일 예로, 선형 커널과 정규화 매개변수 1을 사용하는 서포트 벡터 머 신(SVM), 20개의 은닉 유닛을 가진 단일 은닉층을 가진 다층 퍼셉트론(MLP), K값이 5인 K-최근접 이웃(KNN)분류 기(K=5), 최대 깊이가 5인 20개의 트리를 가진 랜덤 포레스트(RF) 등이 있다. 이 중 후술할 바와 같이, 상기 추 출된 비유창성 특징을 입력받아 랜덤 포레스트(RF) 모델을 이용하여 알츠하이머(AD; Alzheimer's Disease)를 감 지하는 것이 가장 정확성을 높일 수 있는 모델이다. 이하에서는, [실험 3]을 통해 본 발명에서 제안하는 발화에서의 비유창성 특징을 이용하여 간단한 분류기를 활 용한 AD 탐지 모델의 정확성을 확인토록 한다. - 사용된 데이터 셋 본 발명의 모델의 성능을 평가하기 위해 공개적으로 제공되는 두 개의 데이터 셋인 ADReSSo와 MADReSS를 활용하 였다. 이 데이터셋은 각각 2021년과 2023년에 개최된 AD 인식 챌린지에서 사용했다. 이 데이터셋에는 AD 환자와 인지적으로 정상인 개인들이 만들어낸 사진 설명의 음성 녹음이 포함되어 있다. ADReSSo 데이터셋은 156개의 영 어 훈련 데이터와 71개의 영어 테스트 데이터로 구성되어 있고, MADReSS 데이터셋은 237개의 영어 훈련 데이터 와 46개의 그리스어 테스트 데이터로 구성되어 있다. 두 데이터셋은 모두 어떠한 전사(transcription)도 제공하 지 않고 오디오 녹음만을 제공한다. AD 분류/진단 작업을 위해, 오디오 녹음은 '정상'과 '의심되는 AD'로 라벨 이 지정되었으며, 성별과 연령을 균형있게 조정하여 잠재적인 편향을 최소화하였다. - 기계학습 분류기에 대한 성능 비교 본 발명에서 제안하는 발화에서의 비유창성 특징들을 활용하여 SVM, MLP, KNN, RF 등의 4가지 머신러닝 모델을 통해 AD 식별 정확도를 검증하였는데(이를 위해 ADReSSo 훈련 세트에서 5-fold 교차 검증 정확도를 사용함), 도 14에 도시된 바와 같이, 제안된 비유창성 특징은 상기 다양한 모델들 모두에서 합리적인 성능을 발휘하였음을 확인할 수 있고 특히, 랜덤 포레스트(RF) 모델에서 가장 우수한 성능(정확도는 78.3%, 분산은 낮다)을 보여주었 으며, RF 모델은 훈련 중 다양한 의사결정 트리를 구축하는 앙상블 학습 방법이므로, 이하에서는 RF 모델을 통 해 다음 실험을 수행하였다. - 비유창성 특징들에 대한 분석 본 발명에서 제안한 비유창성 특징들의 특징(기여도)를 살펴보기 위해, 모든 비유창성 특징을 활용한 결과치에 서 순차적으로 몇 가지 특징들을 제거하면서 ADReSSo 훈련 세트에서 5-fold 교차 검증 결과를 사용하였다. 도 15에 도시된 바와 같이, 단순히 전체 음성 길이에 대해 참가자 세그먼트의 비율(Rat_P), 음성 녹음에서 참가자 세그먼트의 수(Num_P) 특징을 제거한 것 대비, 음성 녹음에서 인터뷰어 세그먼트의 수(Num_I) 특징을 제거하였 을 때가 성능에 더 큰 영향을 미치는 결과치를 통해, AD를 가진 참가자가 발화 중에 인터뷰어로부터 더 많은 영 향과 개입을 받기 때문에 인터뷰어 특징이 더 중요한 특징으로 작용하는 점을 확인할 수 있다. 또한, 정적 특징 인 전체 음성 길이에 대해 정적 세그먼트들의 비율(Rat_S), 음성 녹음에서 정적 세그먼트들의 길이의 총합 (Len_S), 음성 녹음에서 정적 세그먼트들의 길이 중 최대길이(Max_S) 특징들을 제거하였을 때 AD 감지 성능에 큰 영향을 미치는 결과치를 통해, 발화 중의 정적 특징 즉, 무성 휴지(silence pause)가 AD와 같은 인지기능 장 애를 감지하는데 중요한 특징으로 작용하는 점을 확인할 수 있다. 마지막으로, 참가자의 연단위 교육수준(Edu) 메타데이터 특징을 제거하였을 때에도 약간의 성능 저하를 유발한다는 점에서 이러한 메타데이터 특징이 AD 진 단에 보조적 기능을 제공한다는 점을 확인할 수 있다. 결론적으로 상기 비유창성 특징들 중에서 정적 특징이 AD 감지에 가장 중요한 요소로 작용하고 있고 또한, 인터뷰어 특징 특히, 개입 횟수 관련 특징이 상당히 중요한 특 징으로 작용한다는 점을 확인할 수 있다. - 다른 AD 식별/진단 방법(모델)들과의 대비 본 발명에서 제안하는 모델의 우수성을 확인하기 위해, wav2vec, MFCC eGeMAPS, 또는 ComParE와 같은 오디오 특 징만 사용하는 다른 모델들과 본 발명의 모델을 비교하였는데, ADReSSo 훈련 세트에서 모델을 훈련시키고 테스 트 세트에서 테스트 결과를 비교하였다. 그 결과, 도 16에서 볼 수 있는 바와 같이, 베이스라인 방법은 ADReSSo 데이터셋을 제시한 것으로 eGeMAPS와 SVM 분류기를 사용하여 간단한 모델을 구축하고 64.8%의 정확도를 달성하 였고, Pappagari et al. [\"Automatic detection and assessment of alzheimer disease using speech and language technologies in low-resource scenarios,\" in Proc. Interspeech, 2021]과 Pan et al. [\"Using the outputs of different automatic speech recognition paradigms for acoustic-and BERT-based alzheimer's dementia detection through spontaneous speech,\" in Proc. Interspeech, 2021]은 ASR 임베딩과 wav2vec 2.0 을 사용하여 ADReSSo 테스트 세트에서 74.7%의 정확도를 달성하였다. 그러나 ASR 임베딩과 wav2vec 특징은 영어 데이터만으로 훈련된 모델에서 추출되며, 다른 언어로의 전이가 어렵다. 이에 반해, 본 발명이 제안한 모델 (Ours)의 비유창성 특징(disfluency 특징)은 다른 특징들을 능가(76.6%의 정확도)하여 다른 언어에서의 사용 가 능성을 보여준다. 추가로, 본 발명에서 제안하는 모델의 성능을 다른 언어 시나리오에서 평가하기 위해, MADReSS 영어 훈련 데이 터로 모델을 훈련하고 그리스어 테스트 데이터에서 결과를 비교하였는데, 도 17에 도시된 바와 같이, 본 발명의 모델의 성능을 MADReSS 베이스라인 [\"Multilingual alzheimer's dementia recognition through spontaneous speech: a signal processing grand challenge,\" in Proc. IEEE Int. Conf. Acoust. Speech Signal Process., 2023]과 비교한 결과, 비유창성 특징을 사용한 본 발명의 모델(Ours)이 그리스어 데이터에서 80.4%의 정확도를 달성하여 베이스라인보다 6.5% 높은 성능을 보였다. 따라서 이 결과는 비유창성 특징이 AD 감지의 문맥에서 다 른 언어 간에 일반화 가능한 음성 특징임을 나타낸다 할 것이다. 종합해보면, 본 발명의 시스템은, 음성 데이터를 바이오마커로 한 다양한 뇌 건강(난청, 인지장애, 치매 등)에 대한 예측 또는 진단을 가능케 하며 특히, 하나의 시스템으로 음성 데이터를 획득하기 위한 수집 환경 및 사용 자 상태에 대한 체크에서부터 음성 데이터 획득 과정에서의 음성 크기 모니터링 및 획득한 음성 데이터를 기반 으로 한 난청, 인지장애 및 치매에 대한 예측 및 진단 결과 도출까지 이루어지게 된다. 이상에서, 출원인은 본 발명의 다양한 실시예들을 설명하였지만, 이와 같은 실시예들은 본 발명의 기술적 사상 을 구현하는 일 실시예일 뿐이며, 본 발명의 기술적 사상을 구현하는 한 어떠한 변경예 또는 수정예도 본 발명의 범위에 속하는 것으로 해석되어야 한다."}
{"patent_id": "10-2024-0028952", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 시스템의 구성도 도 2는 본 발명의 시스템을 이용한 운용 과정을 도시한 순서도도 3은 데이터 증강 전 모델별 5-Fold Cross-Validation 평균 정확도를 도시한 표와 그래프 도 4는 데이터 증강 후 모델별 5-Fold Cross-Validation 평균 정확도를 도시한 표 도 5는 데이터 증강 후 모델별 5-Fold Cross-Validation 평균 정확도를 도시한 그래프 도 6은 본 발명의 일 실시예에 따른 상호보완적 알고리즘 모델의 개념도 도 7은 MSE 함수를 적용한 종래의 MMSE 점수 예측 모델의 참고도 도 8은 MMSE 점수구간을 균등하게 복수의 구간으로 나누어 각 구간의 확률을 예측하는 예를 도시한 상태도 도 9는 피검사자가 Cookie Theft 사진을 설명하는 음성 데이터를 이용한 MMSE 검사과정을 설명한 참고도 도 10은 MMSE 점수 예측에서 베르누이 페널티와 거리 기반 가중치를 반영한 결과값을 도시한 자료 도 11은 ADReSSo 데이터셋에서 음향 특징만을 사용한 기존 모델들과 성능을 비교한 자료 도 12는 AD가 있는 경우와 없는 경우의 발화에서의 비유창성 특징을 시각화한 이미지 도 13은 본 발명에서 제시하는 비유창성 특징 참고도 도 14는 다양한 AD 분류 모델에서의 AD 식별 정확도를 도시한 그래프 도 15는 비유창성 특징들의 기여도를 나타낸 그래프 도 16은 ADReSSo 테스트 세트에서의 AD 식별 정확성 비교도 도 17은 MADReSS 테스트 세트에서 AD 식별 정확도 비교도"}
