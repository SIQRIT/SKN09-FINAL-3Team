{"patent_id": "10-2023-0105667", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0024322", "출원번호": "10-2023-0105667", "발명의 명칭": "인터페이스를 표시하는 헤드 마운티드 디스플레이 장치 및 헤드 마운티드 디스플레이 장치의", "출원인": "삼성전자주식회사", "발명자": "김지인"}}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "헤드 마운티드 디스플레이(Head mounted Display) 장치(100)에 있어서,카메라(130);디스플레이(140);적어도 하나의 명령어(instruction)를 저장하는 메모리(180); 및 적어도 하나의 프로세서(190)를 포함하고,상기 적어도 하나의 프로세서(190)는 상기 적어도 하나의 명령어를 실행함으로써,상기 디스플레이(140)를 통하여, 제1 인터페이스(500)를 표시하고,상기 카메라(130)를 통하여, 사용자를 촬영하여 이미지를 획득하고,상기 획득된 이미지에 기초하여 상기 사용자의 포즈(pose)를 검출하고,복수의 인터페이스들에 각각 대응되도록 미리 설정된 복수의 포즈들과 상기 검출된 포즈를 비교하고,상기 검출된 포즈가 상기 복수의 인터페이스들 중 하나인 제2 인터페이스(510)에 대응됨에 따라, 상기 디스플레이(140)를 통하여 상기 제1 인터페이스(500)를 대체하여 상기 제2 인터페이스(510)를 표시하는 헤드 마운티드디스플레이 장치(100)."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 적어도 하나의 프로세서(190)는 상기 적어도 하나의 명령어를 실행함으로써,상기 제1 인터페이스(500)와 상기 제2 인터페이스(510)를 비교하고,상기 제1 인터페이스(500)와 상기 제2 인터페이스(510)가 상이한 인터페이스로 판단됨에 따라, 상기 디스플레이(140)를 통하여 상기 제1 인터페이스(500)를 대체하여 상기 제2 인터페이스(510)를 표시하는 헤드 마운티드 디스플레이 장치(100)."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 적어도 하나의 프로세서(190)는 상기 적어도 하나의 명령어를 실행함으로써,상기 검출된 포즈와 상기 미리 설정된 복수의 포즈들이 상이하거나, 혹은 상기 제1 인터페이스(500)와 상기 제2인터페이스(510)가 동일한 인터페이스로 판단됨에 따라, 상기 디스플레이(140)를 통하여 표시되는 상기 제1 인터페이스(500)를 유지하는 헤드 마운티드 디스플레이 장치(100)."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 적어도 하나의 프로세서(190)는 상기 적어도 하나의 명령어를 실행함으로써,상기 디스플레이(140)를 통하여 제1 콘텐츠를 표시하고,상기 제1 콘텐츠(300)가 표시되는 동안, 상기 디스플레이(140)를 통하여 상기 제1 인터페이스(500) 및 상기 제2인터페이스(510)를 표시하는 헤드 마운티드 디스플레이 장치(100).공개특허 10-2025-0024322-3-청구항 5 제1 내지 제4 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(190)는 상기 적어도 하나의 명령어를 실행함으로써,상기 카메라(130)를 통하여, 상기 헤드 마운티드 디스플레이 장치(100)가 포함된 공간을 촬영하여 공간 이미지를 획득하고,상기 획득된 공간 이미지에 기초하여 상기 공간을 나타내는 공간맵을 생성하고,상기 공간맵 및 상기 검출된 포즈에 기초하여 상기 제2 인터페이스(510)를 표시할 인터페이스 위치를 결정하고,상기 디스플레이(140)를 통하여 상기 인터페이스 위치에 상기 제2 인터페이스(510)를 표시하는 헤드 마운티드디스플레이 장치(100)."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 내지 제5 항 중 어느 하나의 항에 있어서,상기 헤드 마운티드 디스플레이 장치(100)는,상기 사용자의 시선 방향을 추적하는 시선 추적 센서를 더 포함하고,상기 적어도 하나의 프로세서(190)는 상기 적어도 하나의 명령어를 실행함으로써,상기 시선 방향에 기초하여 상기 사용자의 시점을 획득하는 헤드 마운티드 디스플레이 장치(100)."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 적어도 하나의 프로세서(190)는 상기 적어도 하나의 명령어를 실행함으로써,상기 획득된 사용자의 시점 및 상기 획득된 이미지에 기초하여, 상기 사용자의 포즈를 검출하는 헤드 마운티드디스플레이 장치(100)."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 또는 제7 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(190)는 상기 적어도 하나의 명령어를 실행함으로써,상기 획득된 사용자의 시점에 기초하여 상기 제1 인터페이스(500) 또는 상기 제2 인터페이스(510) 중 적어도 하나의 인터페이스를 통하여 획득되는 사용자 입력이 표시되는 제2 콘텐츠를 표시할 콘텐츠 위치를 결정하고,상기 디스플레이(140)를 통하여 상기 콘텐츠 위치에 상기 제2 콘텐츠를 표시하는 헤드 마운티드 디스플레이 장치(100)."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 내지 제8 항 중 어느 하나의 항에 있어서,상기 제1 인터페이스(500)는, 상기 검출된 포즈가 상기 미리 설정된 복수의 포즈들 중 상기 제1 인터페이스(500)에 대응되도록 설정된 어느 하나의 포즈에 대응됨에 따라 상기 디스플레이(140)에 표시되는 인터페이스이고,상기 제1 인터페이스(500)에 대응되도록 설정된 어느 하나의 포즈와 상기 제2 인터페이스(510)에 대응되도록 설정된 어느 하나의 포즈는 서로 상이한 포즈인 헤드 마운티드 디스플레이 장치(100)."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 내지 제9 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(190)는 상기 적어도 하나의 명령어를 실행함으로써,공개특허 10-2025-0024322-4-상기 검출된 포즈와 미리 설정된 시작 포즈를 비교하고,상기 검출된 포즈가 상기 미리 설정된 시작 포즈에 대응됨에 따라, 상기 검출된 포즈와 상기 미리 설정된 복수의 포즈들을 비교하는 헤드 마운티드 디스플레이 장치(100)."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "헤드 마운티드 디스플레이(Head mounted Display) 장치의 동작 방법에 있어서,카메라를 통하여 사용자를 촬영하여 이미지를 획득하는 단계(S100);상기 획득된 이미지에 기초하여 상기 사용자의 포즈(pose)를 검출하는 단계(S200);복수의 인터페이스들에 각각 대응되도록 미리 설정된 복수의 포즈들과 상기 검출된 포즈를 비교하는 단계(S300);상기 검출된 포즈가 상기 복수의 인터페이스들 중 하나인 제2 인터페이스에 대응됨에 따라, 상기 디스플레이를통하여 상기 제1 인터페이스를 대체하여 상기 제2 인터페이스를 표시하는 단계(S600)를 포함하는 헤드 마운티드디스플레이 장치의 동작 방법."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 헤드 마운티드 디스플레이 장치의 동작 방법은 상기 제1 인터페이스와 상기 제2 인터페이스를 비교하는 단계(S500)를 포함하고,상기 제1 인터페이스와 상기 제2 인터페이스를 비교하는 단계(S500)에서 상기 제1 인터페이스와 상기 제2 인터페이스가 상이한 인터페이스로 판단됨에 따라, 상기 디스플레이를 통하여 상기 제2 인터페이스를 표시하는 단계(S600)에서상기 디스플레이를 통하여 상기 제1 인터페이스를 대체하여 상기 제2 인터페이스를 표시하는 헤드 마운티드 디스플레이 장치의 동작 방법."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,헤드 마운티드 디스플레이 장치의 동작 방법은,상기 미리 설정된 복수의 포즈들과 상기 검출된 포즈를 비교하는 단계(S300)에서, 상기 미리 설정된 복수의 포즈들과 상기 검출된 포즈가 상이하거나, 혹은상기 제1 인터페이스와 상기 제2 인터페이스를 비교하는 단계(S500)에서 상기 제1 인터페이스와 상기 제2 인터페이스가 서로 동일한 인터페이스로 판단됨에 따라, 상기 디스플레이를 통하여 표시되는 상기 제1 인터페이스를 유지하는 단계(S700)를 포함하는 헤드 마운티드 디스플레이 장치의 동작 방법."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11 항에 있어서,헤드 마운티드 디스플레이 장치의 동작 방법은,상기 디스플레이를 통하여 제1 콘텐츠를 표시하는 단계(S50)를 포함하고,상기 제1 콘텐츠가 표시되는 동안, 상기 디스플레이를 통하여 상기 제1 인터페이스 및 상기 제2 인터페이스를표시하는 헤드 마운티드 디스플레이 장치의 동작 방법."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 내지 제14 항 중 어느 하나의 항에 있어서,공개특허 10-2025-0024322-5-헤드 마운티드 디스플레이 장치의 동작 방법은,상기 카메라를 통하여 상기 헤드 마운티드 디스플레이 장치가 포함된 공간을 촬영하여 공간 이미지를 획득하는단계(S610);상기 획득된 공간 이미지에 기초하여 상기 공간을 나타내는 공간맵을 생성하는 단계(S620); 및상기 공간맵 및 상기 검출된 포즈에 기초하여 상기 제2 인터페이스를 표시할 인터페이스 위치를 결정하는 단계(S630)를 포함하고, 상기 디스플레이를 통하여 상기 제2 인터페이스를 표시하는 단계(S640)에서, 상기 인터페이스 위치에 상기 제2인터페이스를 표시하는 헤드 마운티드 디스플레이 장치의 동작 방법."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11 내지 제15 항 중 어느 하나의 항에 있어서,헤드 마운티드 디스플레이 장치의 동작 방법은,시선 추적 센서를 통하여 추적한 상기 사용자의 시선 방향에 기초하여 상기 사용자의 시점을 획득하는 단계(S60)를 포함하고,상기 사용자의 포즈를 검출하는 단계(S210)에서는,상기 획득된 사용자의 시점 및 상기 획득된 이미지에 기초하여, 상기 사용자의 포즈를 검출하는 헤드 마운티드디스플레이 장치의 동작 방법."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서,헤드 마운티드 디스플레이 장치의 동작 방법은,상기 획득된 사용자의 시점에 기초하여 상기 제1 인터페이스 또는 상기 제2 인터페이스 중 적어도 하나의 인터페이스를 통하여 획득되는 사용자의 입력이 표시되는 제2 콘텐츠를 표시할 콘텐츠 위치를 결정하는 단계(S800);및상기 디스플레이를 통하여 상기 콘텐츠 위치에 상기 제2 콘텐츠를 표시하는 단계(S900)를 포함하는 헤드 마운티드 디스플레이 장치의 동작 방법."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11 내지 제17 항 중 어느 하나의 항에 있어서,상기 제1 인터페이스는, 상기 검출된 포즈가 상기 미리 설정된 복수의 포즈들 중 상기 제1 인터페이스에 대응되도록 설정된 어느 하나의 포즈에 대응됨에 따라 상기 디스플레이에 표시되는 인터페이스이고,상기 제1 인터페이스에 대응되도록 설정된 어느 하나의 포즈와 상기 제2 인터페이스에 대응되도록 설정된 어느하나의 포즈는 서로 상이한 포즈인 헤드 마운티드 디스플레이 장치의 동작 방법."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11 내지 제18 항 중 어느 하나의 항에 있어서,헤드 마운티드 디스플레이 장치의 동작 방법은,상기 검출된 포즈와 미리 설정된 시작 포즈를 비교하는 단계(S250)를 포함하고,상기 검출된 포즈가 상기 미리 설정된 시작 포즈에 대응됨에 따라, 상기 검출된 포즈와 상기 미리 설정된 복수의 포즈들을 비교하는 헤드 마운티드 디스플레이 장치의 동작 방법."}
{"patent_id": "10-2023-0105667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11 항 내지 제19 항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수공개특허 10-2025-0024322-6-있는 기록매체."}
{"patent_id": "10-2023-0105667", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 카메라, 디스플레이, 적어도 하나의 명령어(instruction)를 저장하는 메모리 및 적어도 하나의 프로세 서를 포함하고, 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써, 디스플레이를 통하여 제1 인터 페이스를 표시하고, 카메라를 통하여 사용자를 촬영하여 이미지를 획득하고, 획득된 이미지에 기초하여 사용자의 포즈(pose)를 검출하고, 복수의 인터페이스들 각각에 대응되도록 미리 설정된 복수의 포즈들과 검출된 포즈를 비 교하고, 검출된 포즈가 복수의 인터페이스들 중 하나인 제2 인터페이스에 대응됨에 따라, 디스플레이를 통하여 제1 인터페이스를 대체하여 제2 인터페이스를 표시하는 헤드 마운티드 디스플레이(Head mounted Display) 및 그 의 동작 방법을 포함한다."}
{"patent_id": "10-2023-0105667", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 헤드 마운티드 디스플레이 장치 및 헤드 마운티드 디스플레이 장치의 동작 방법에 관한 것이다. 구체 적으로는, 인터페이스를 표시하는 헤드 마운티드 디스플레이 장치 및 헤드 마운티드 디스플레이 장치의 동작 방 법에 관한 것이다."}
{"patent_id": "10-2023-0105667", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기술의 발전에 따라 사용자의 두부(頭部)에 착용된 상태에서, 사용자의 눈에 가깝게 배치된 디스플레이를 통하 여 사용자에게 영상을 제공하는 헤드 마운티드 디스플레이(Head Mounted display) 장치가 개발되고 있다. 헤드 마운티드 디스플레이 장치에 포함되는 디스플레이는 현실 세계(real world)의 물리적 환경 공간이나, 현실 객체(real world object) 상에 가상 이미지를 오버레이(overlay)하여 함께 보여주기 위한 옵티컬 시스루 디스플 레이(optical see-through display)를 포함하거나, 카메라 등을 통하여 현실 세계의 물리적 환경 공간의 이미지 를 촬영한 이미지를 표시하여 사용자에게 제공하는 비디오 시스루 디스플레이(video see-through display)를 포 함할 수 있다. 최근에는, 인터페이스를 통하여 헤드 마운티드 디스플레이 장치를 통하여 제공되는 영상에 사용자의 입력을 제 공하는 기술이 개발되고 있다."}
{"patent_id": "10-2023-0105667", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예는 헤드 마운티드 디스플레이(Head mounted Display) 장치를 제공한다. 헤드 마운티드 디스 플레이(Head mounted Display) 장치는 카메라를 포함할 수 있다. 헤드 마운티드 디스플레이(Head mounted Display) 장치는 디스플레이를 포함할 수 있다. 헤드 마운티드 디스플레이(Head mounted Display) 장치는 적어 도 하나의 명령어(instruction)를 저장하는 메모리 및 적어도 하나의 프로세서를 포함할 수 있다. 적어도 하나 의 프로세서는 적어도 하나의 명령어를 실행함으로써, 디스플레이를 통하여 제1 인터페이스를 표시할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써, 카메라를 통하여 사용자를 촬영하여 이미지를 획득할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써, 획득된 이미지에 기초하여 사용자의 포즈(pose)를 검출할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써, 복수 의 인터페이스들에 각각 대응되도록 미리 설정된 복수의 포즈들과 검출된 포즈를 비교할 수 있다. 적어도 하나 의 프로세서는 적어도 하나의 명령어를 실행함으로써, 검출된 포즈가 복수의 인터페이스들 중 하나인 제2 인터 페이스에 대응됨에 따라, 디스플레이를 통하여 제1 인터페이스를 대체하여 제2 인터페이스를 표시할 수 있다. 본 개시의 일 실시예는 헤드 마운티드 디스플레이(Head mounted Display) 장치의 동작 방법을 제공한다. 헤드 마운티드 디스플레이(Head mounted Display) 장치의 동작 방법은 카메라를 통하여 사용자를 촬영하여 이미지를 획득하는 단계를 포함할 수 있다. 헤드 마운티드 디스플레이(Head mounted Display) 장치의 동작 방법은 획득된 이미지에 기초하여 사용자의 포즈(pose)를 검출하는 단계를 포함할 수 있다. 헤드 마운티드 디스플레이(Head mounted Display) 장치의 동작 방법은 복수의 인터페이스들에 각각 대응되도록 미리 설정된 복수의 포즈들과 검 출된 포즈를 비교하는 단계를 포함할 수 있다. 헤드 마운티드 디스플레이(Head mounted Display) 장치의 동작 방법은 검출된 포즈가 복수의 인터페이스들 중 하나인 제2 인터페이스에 대응됨에 따라, 디스플레이를 통하여 제1 인터페이스를 대체하여 제2 인터페이스를 표시하는 단계를 포함할 수 있다. 본 개시의 일 실시예로, 개시된 동작 방법의 실시예 중 적어도 하나의 방법을 컴퓨터에서 수행하기 위한 프로그 램이 기록된 컴퓨터로 읽을 수 있는 기록 매체를 제공할 수 있다."}
{"patent_id": "10-2023-0105667", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서 사용되는 용어에 대해 간략히 설명하고, 본 개시의 일 실시예에 대해 구체적으로 설명하기로 한다. 본 개시에서 사용되는 용어는 본 개시의 일 실시예에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적 인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 본 개시의 실 시예의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명 칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 개시에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에서 사용된 표현 “~하도록 구성된(또는 설정된)(configured to)”은 상황에 따라, 예를 들면, “~에 적합한(suitable for)”, “~하는 능력을 가지는(having the capacity to)”, “~하도록 설계된(designed to) ”, “~하도록 변경된(adapted to)”, “~하도록 만들어진(made to)”, 또는 “~를 할 수 있는(capable of)” 과 바꾸어 사용될 수 있다. 용어 “~하도록 구성된(또는 설정된)”은 하드웨어적으로 “특별히 설계된 (specifically designed to)” 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, “~하도록 구성 된 시스템”이라는 표현은, 그 시스템이 다른 장치 또는 부품들과 함께 “~할 수 있는” 것을 의미할 수 있다. 예를 들면, 문구 “A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서”는 해당 동작을 수행하기 위한 전 용 프로세서(예: 임베디드 프로세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로 써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 또한, 본 개시에서 일 구성요소가 다른 구성요소와 “연결된다” 거나 “접속된다” 등으로 언급된 때에는, 상 기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재 가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시의 일 실시예는 여러 가지 상이한 형태 로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시의 일 실시예를 명 확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 본 개시 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하에서는 도면을 참조하여 본 개시의 실시예들을 상세하게 설명한다. 도 1은 본 개시의 일 실시예에 따른 헤드 마운티드 디스플레이(Head mounted Display) 장치를 설명하기 위한 도 면이다. 도 1을 참조하면, 본 개시의 일 실시예에 따른 전자 장치는, 전자 장치를 착용한 사용자에게 콘텐츠 를 제공할 수 있다. 일 실시예에서, 전자 장치는 사용자에게 콘텐츠를 제공할 수 있는 장치로서, 헤 드 마운티드 디스플레이(Head Mounted Display, HMD) 장치일 수 있다. 일 실시예에서, 도 1에는 전자 장치가 사용자의 안면부(顔面部)에 걸쳐지는 지지부를 포함하는, 안경과 유 사한 형상으로 도시되어 있다. 다만, 본 개시는 이에 한정되지 않고, 전자 장치는 사용자의 안면부(顔面部) 및 두부(頭部)에 걸쳐지는 지지부를 포함할 수도 있다. 이하, 설명의 편의를 위하여, 전자 장치 는 헤드 마운티드 디스플레이 장치인 것으로 설명한다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 사용자에게 현실 세계(real world)의 물리적 환경 공간이나, 현실 객체(real world object) 상에 가상 영상을 오버레이(overlay)하여 제공하는 옵티컬 시스루 디 스플레이(optical see-through display) 장치일 수 있다. 헤드 마운티드 디스플레이 장치는 외부에서 제공 받은 데이터 또는 헤드 마운티드 디스플레이 장치에 생성한 가상 영상을 사용자에게 제공할 수 있다. 다만, 본 개시는 이에 제한되지 않는다. 헤드 마운티드 디스플레이 장치는 사용자의 시선 방향이 향 하는 곳의 물리적 환경 공간을 카메라로 촬영하여 영상을 획득한 후, 사용자에게 획득한 영상을 제공하는 비디오 시스루(video see-through) 전자 장치일 수 있다. 이하, 설명의 편의를 위하여, 본 개시의 헤드 마운티드 디스플레이 장치는 옵티컬 시스루 디스플레이 장치 인 것으로 설명하나, 본 개시는 이에 제한되지 않는다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 카메라를 포함할 수 있다. 일 실시예에서, 카메라 는 헤드 마운티드 디스플레이 장치의 전방의 영상을 촬영하기 위한 제1 카메라 및 헤드 마운티 드 디스플레이 장치의 하방의 영상을 촬영하기 위한 제2 카메라가 포함될 수 있다. 일 실시예에서, 전방의 영상은 현실 세계, 즉 사용자의 주변 환경에 대한 영상 중 헤드 마운티드 디스플레이 장치의 전방 에 위치한 환경에 대한 영상을 의미할 수 있다. 하방의 영상은 현실 세계에 대한 영상 중 헤드 마운티드 디스플 레이 장치의 아래쪽에 위치한 환경에 대한 영상을 의미할 수 있다. 일 실시예에서, 제1 카메라는 헤드 마운티드 디스플레이 장치의 상단부에 배치될 수 있다. 제2 카메 라는 헤드 마운티드 디스플레이 장치의 하단부에 배치될 수 있다. 다만, 본 개시는 이에 제한되지 않 는다. 헤드 마운티드 디스플레이 장치에 배치되는 제1 카메라의 위치 및 제2 카메라의 위치는제한되지 않는다. 일 실시예에서, 도 1에는 헤드 마운티드 디스플레이 장치가 두 개의 제1 카메라들 및 두 개의 제2 카 메라들을 포함하는 것으로 도시되어 있다. 다만, 본 개시는 이에 제한되지 않고, 제1 카메라 및 제2 카메라의 개수는 각각 하나 또는 세 개 이상일 수도 있다. 또한, 헤드 마운티드 디스플레이 장치에 포함된 카메라는 헤드 마운티드 디스플레이 장치의 전 방의 영상 및 하방의 영상을 촬영하기 위한 카메라일 수 있다. 헤드 마운티드 디스플레이 장치의 전방의 영상 및 하방의 영상을 촬영하기 위한 카메라의 개수는 하나 이상일 수 있다. 이하, 설명의 편의를 위하여 카메라는 헤드 마운티드 디스플레이 장치의 상단부에 배치되어, 헤드 마 운티드 디스플레이 장치의 전방의 영상을 촬영하기 위한 제1 카메라 및 헤드 마운티드 디스플레이 장 치의 하단부에 배치되어, 헤드 마운티드 디스플레이 장치의 하방의 영상을 촬영하기 위한 제2 카메라 를 포함하는 것으로 설명한다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 디스플레이(140, 도 2 참조)를 통하여 콘텐츠를 표 시하여, 사용자에게 콘텐츠를 제공할 수 있다. 일 실시예에서, 콘텐츠는 현실 세계의 물리적 환 경 공간이나, 현실 객체 상에 오버레이되어 사용자에게 제공되는 가상 영상일 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치를 통하여 콘텐츠가 사용자에게 제공되는 동안, 사용자는 헤드 마운티드 디스플레이 장치가 제공하는 인터페이스를 통하여 사용자 입력을 제공할 수 있다. 헤드 마운티드 디스플레이 장치는 사용자에게 제공한 인터페이스를 통하여 사용자 입력을 획득할 수 있다. 본 개시의 헤드 마운티드 디스플레이 장치는 카메라를 통하여 사용자를 촬영하여 이미지를 획득 할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 카메라를 통하여 사용자의 손을 촬영하여 이미지를 획득할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 카메라를 통하여 사용자의 손을 이용한 동작 을 촬영하여 이미지를 획득할 수 있다. 헤드 마운티드 디스플레이 장치는 헤드 마운티드 디스플레이 장치 를 착용한 사용자의 두부의 움직임 없이, 제2 카메라를 통하여 사용자의 손을 이용한 동작 을 촬영하여 이미지를 획득할 수 있다. 일 실시예에서, 사용자가 헤드 마운티드 디스플레이 장치를 착용한 상태에서, 고개를 움직이거나 머 리를 움직이지 않고, 콘텐츠를 바라보면서 손을 움직이더라도, 헤드 마운티드 디스플레이 장치는 제2 카메라를 통하여 사용자의 손을 촬영하여 이미지를 획득할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 획득된 이미지에 기초하여 사용자의 포즈(pose)를 검출 할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 사용자의 손을 포함한 이미지에 기초 하여, 사용자의 손의 포즈를 검출할 수 있다. 이하, 헤드 마운티드 디스플레이 장치가 획득한 이미지 에 기초하여 사용자의 포즈를 검출하는 동작은 도 3 및 도 6에서 후술하도록 한다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 검출된 사용자의 포즈와 미리 설정된 복수의 포즈 들을 비교할 수 있다. 미리 설정된 복수의 포즈들은 키보드를 이용하여 타자를 치는 손의 포즈, 마우스를 이용 하는 손의 포즈, 펜을 이용하여 그림 패드(예를 들어, 종이 또는 패드와 같은 그림을 그리기 위한 대상)에 그림 을 그리는 손의 포즈 또는 터치 패드(예를 들어, 터치를 이용하여 사용자 입력을 제어하는 패드)를 이용하는 손 의 포즈 등을 포함할 수 있다. 다만, 본 개시는 이에 제한되지 않고, 미리 설정된 복수의 포즈들은 특정 동작을 수행하는 사람의 포즈를 포함할 수 있다. 일 실시예에서, 복수의 포즈들 각각은 복수의 인터페이스들에 대응되도록 미리 설정된 것일 수 있다. 일 실시예 에서, 인터페이스는 키보드, 마우스, 그림 패드, 터치 패드 등을 포함할 수 있다. 타자를 치는 손의 포즈는, 키 보드에 대응되도록 설정된 것일 수 있다. 마우스를 이용하는 손의 포즈는, 마우스에 대응되도록 설정된 것일 수 있다. 펜을 이용하여 그림을 그리는 손의 포즈는 그림 패드에 대응되도록 설정된 것일 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 검출된 포즈가 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 대응됨에 따라, 검출된 포즈에 대응되는 어느 하나의 포즈에 대응되도록 설정된 인터페이스를 디 스플레이를 통하여 표시할 수 있다. 헤드 마운티드 디스플레이 장치는 검출된 포즈에 대응되는 인터페이스를 디스플레이를 통하여 사용자에게 제공될 수 있다. 일 실시예에서, 인터페이스는 현실세계의 물리적 환경 공간이나, 현실 객체 상에 오버레이되어 사용자에게 제공되는 가상 영상일 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 카메라를 통하여 헤드 마운티드 디스플레이 장치 가 포함된 공간을 촬영하여 공간 이미지를 획득할 수 있다. 헤드 마운티드 디스플레이 장치는 획득된 공간 이미지에 기초하여 공간을 나타내는 공간맵을 생성할 수 있다. 이하, 헤드 마운티드 디스플레이 장치(10 0)가 획득한 공간 이미지에 기초하여 공간맵을 생성하는 동작은 도 3 및 도 7에서 후술하도록 한다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 공간맵 및 검출된 포즈에 기초하여 인터페이스를 표시할 인터페이스 위치를 결정할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 검출된 포즈 에 대응되는 어느 하나의 포즈에 대응되도록 설정된 인터페이스를 결정하고, 결정된 인터페이스의 형상, 크기 또는 종류 중 적어도 하나와 공간맵에 기초하여 인터페이스 위치를 결정할 수 있다. 이하, 헤드 마운티드 디스 플레이 장치가 인터페이스 위치를 결정하는 동작은 도 3, 도 11a, 도 11b 및 도 11c에서 후술하도록 한다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 디스플레이를 통하여 결정된 인터페이스 위치에 검 출된 포즈에 대응되는 인터페이스를 표시할 수 있다. 일 실시예에서, 검출된 포즈가 미리 설정된 복수의 포즈들 중 타자를 치는 손의 포즈에 대응되는 경우, 헤 드 마운티드 디스플레이 장치는 디스플레이를 통하여 타자를 치는 손의 포즈에 대응되는 키보드(50 0)를 표시할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 공간맵 및 타자를 치는 손의 포즈 에 기초하여 키보드를 표시할 인터페이스 위치(예를 들어, 테이블 중 사용자의 손가락이 위치한 영역)을 결정할 수 있다. 헤드 마운티드 디스플레이 장치는 디스플레이를 통하여 해당 인터페이스 위 치에 키보드를 표시할 수 있다. 일 실시예에서, 사용자는 헤드 마운티드 디스플레이 장치를 통하여 콘텐츠 및 키보드를 제 공받을 수 있다. 사용자는 헤드 마운티드 디스플레이 장치를 통하여 표시되는 키보드를 통하여, 헤드 마운티드 디스플레이 장치에 사용자 입력을 제공할 수 있다. 본 개시를 통하여, 사용자는 타자를 치는 손의 포즈를 취하는 것 외에, 헤드 마운티드 디스플레이 장치 를 통하여 키보드를 요청하기 위한 동작(예를 들어, 인터페이스를 표시하기 위하여 헤드 마운티드 디 스플레이 장치의 물리적 버튼을 조작하거나, 실행되고 있는 콘텐츠의 동작을 멈추고 인터페이스를 표 시하기 위한 조작을 수행하거나 또는 콘텐츠 외에 다른 화면을 보며 인터페이스를 표시하기 위한 조작을 수행하는 등의 동작)을 수행하지 않을 수 있다. 다만, 본 개시는 이에 제한되지 않고, 헤드 마운티드 디스플레이 장치는 사용자의 키보드를 표 시하기 위한 상기와 같은 동작에 의하여 디스플레이에 키보드를 표시할 수도 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 사용자의 타자를 치는 손의 포즈를 검출하여 디스 플레이에 키보드를 표시한 이후에도 사용자의 포즈를 검출할 수 있다. 일 실시예에서, 헤드 마 운티드 디스플레이 장치는 미리 설정된 간격으로 사용자의 포즈를 검출하는 동작을 반복할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 디스플레이를 통하여 콘텐츠가 표시되는 동안 사용자의 포즈를 검출하고, 검출된 포즈와 미리 설정된 복수의 포즈들을 비교하여 대응되는 인터페이스를 디스플레이를 통하여 표시하는 동작을 수행할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 사용자의 손을 포함한 이미지에 기초하여, 사용자 의 손의 포즈를 검출할 수 있다. 헤드 마운티드 디스플레이 장치는 검출된 포즈와 미리 설정된 복수의 포즈들을 비교할 수 있다. 헤드 마운티드 디스플레이 장치는 복수의 포즈들 중 검출된 포즈에 대응 되는 어느 하나의 포즈에 기초하여, 검출된 포즈에 대응되는 인터페이스를 결정할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 이전의 동작에서 디스플레이를 통하여 표시되고 있 던 인터페이스(예를 들어, 키보드, 이하 '제1 인터페이스'로 지칭함)와 검출된 포즈에 대응되는 인터페이 스(이하, '제2 인터페이스'로 지칭함)를 비교할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 제1 인터페이스와 제2 인터페이스가 상이하다고 판단됨 에 따라, 디스플레이를 통하여 제2 인터페이스를 표시하여 사용자에게 제공할 수 있다. 일 실시예에서, 헤 드 마운티드 디스플레이 장치는 디스플레이를 통하여 표시되던 제1 인터페이스를 제2 인터페이스로 대체하여 표시할 수 있다. 일 실시예에서, 검출된 포즈가 미리 설정된 복수의 포즈들 중 펜을 이용하여 그림을 그리는 손의 포즈에 대응되는 경우, 해당 포즈에 대응되는 인터페이스는 노트 패드일 수 있다. 헤드 마운티드 디스플레이 장치 는 디스플레이를 통하여 표시되던 키보드와 노트 패드가 상이하므로, 디스플레이를 통하여 키보드를 노트 패드로 대체하여 표시할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 공간맵 및 펜을 이용하여 그림을 그리는 손의 포즈에 기 초하여, 노트 패드를 표시할 인터페이스 위치(예를 들어, 테이블 중 펜의 펜촉이 위치한 영역)을 결정할 수 있다. 헤드 마운티드 디스플레이 장치는 디스플레이를 통하여 해당 인터페이스 위치에 노트 패드 를 표시할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 제1 인터페이스와 제2 인터페이스가 동일하다고 판단됨 에 따라, 디스플레이를 통하여 표시되는 제1 인터페이스를 유지할 수 있다. 일 실시예에서, 검출된 포즈 가 미리 설정된 복수의 포즈들 중 타자를 치는 손의 포즈에 대응되는 경우, 해당 포즈에 대응되는 인터페 이스는 키보드일 수 있다. 이 경우, 헤드 마운티드 디스플레이 장치는 디스플레이를 통하여 표 시되던 키보드를 유지하여 사용자에게 제공할 수 있다. 본 개시를 통하여, 사용자는 제1 인터페이스를 이용하여 사용자 입력을 입력하던 중에, 다른 종류의 제2 인터페이스를 이용하여 사용자 입력을 입력하기 위하여 별다른 동작(예를 들어, 인터페이스를 표시하기 위하여 헤드 마운티드 디스플레이 장치의 물리적 버튼을 조작하거나, 실행되고 있는 콘텐츠의 동작을 멈추고 인터페이스를 표시하기 위한 조작을 수행하거나 또는 콘텐츠 외에 다른 화면을 보며 인터페이스를 표시하 기 위한 조작을 수행하는 등의 동작)을 수행하지 않아도 된다. 이를 통하여 사용자에게 연속적인 사용 경 험을 제공하고, 사용자의 조작 편의성을 향상시킬 수 있다. 또한, 콘텐츠의 내용에 따라 사용자(20 0)가 원하는 종류의 인터페이스를 이용하여 사용자 입력을 제공할 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 본 개시로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다 도 2는 본 개시의 일 실시예에 따른 헤드 마운티드 디스플레이(Head mounted Display) 장치의 구성을 설명하기 위한 도면이다. 도 1 및 도 2를 참조하면, 헤드 마운티드 디스플레이 장치는 카메라, 디스플레이, 광학 렌즈 , 시선 추적 센서, 프레임(171, 172), 노즈 브릿지(nose bridge, 173), 코 지지부, 안경 다리 (175, 176), 배터리, 디스플레이 엔진(178, 179), 메모리 및 적어도 하나의 프로세서를 포함할 수 있다. 일 실시예에서, 도 2에는 헤드 마운티드 디스플레이 장치의 구조를 설명하기 위한 구성 요소만이 개시되어 있고, 헤드 마운티드 디스플레이 장치가 포함하는 구성 요소가 도 2에 도시된 바와 같이 한정되 는 것은 아니다. 일 실시예에서, 디스플레이 및 광학 렌즈는 각각 프레임(171, 172)에 배치될 수 있다. 프레임(171, 172)은 일반적인 안경 구조의 프레임과 유사한 형태를 포함할 수 있다. 프레임(171, 172)은 디스플레이 및 광학 렌즈를 둘러싸는 림(rim) 형태를 포함할 수 있다. 일 실시예에서, 디스플레이는 사용자의 좌안에 대응되는 제1 디스플레이 및 사용자의 우안(20 2)에 대응되는 제2 디스플레이를 포함할 수 있다. 일 실시예에서, 광학 렌즈는 사용자의 좌안에 대응되는 제1 광학 렌즈 및 사용자의 우안에 대응되는 제2 광학 렌즈를 포함할 수 있다. 일 실 시예에서, 광학 렌즈와 사용자의 눈 간의 거리는, 디스플레이와 사용자의 눈 간의 거리보다 가까울 수 있다. 일 실시예에서, 제1 디스플레이는 제1 광학 렌즈에 대응되고, 제2 디스플레이는 제2 광학 렌즈 에 대응될 수 있다. 일 실시예에서, 제1 광학 렌즈는 제1 디스플레이보다 사용자의 좌안에 인접하게 배치될 수 있다. 제2 광학 렌즈는 제2 디스플레이보다 사용자의 우안에 인접하게 배치 될 수 있다. 일 실시예에서, 시선 추적 센서는 사용자의 좌안에 대응되는 제1 시선 추적 센서 및 사용자의 우안에 대응되는 제2 시선 추적 센서를 포함할 수 있다. 일 실시예에서, 프레임(171, 172)은 사용자의 좌안에 대응되는 제1 프레임 및 사용자의 우안에 대응되는 제2 프레임을 포함할 수 있다. 제1 프레임은 제1 디스플레이 및 제1 광학 렌즈를둘러싸는 림을 포함할 수 있다. 제2 프레임은 제2 디스플레이 및 제2 광학 렌즈를 둘러싸는 림 을 포함할 수 있다. 일 실시예에서, 카메라는 제1 프레임에 대응되는 좌측 카메라 및 제2 프레임에 대응되는 우측 카메라를 포함할 수 있다. 일 실시예에서, 도 2에는 좌측 카메라와 우측 카메라가 각각 하 나씩 도시되어 있으나, 본 개시는 이에 제한되지 않는다. 도 1 및 도 2를 참조하면, 좌측 카메라와 우측 카메라는 각각 제1 카메라 및 제2 카메라를 포함할 수도 있다. 일 실시예에서, 좌측 카메라는 제1 프레임의 주변 환경을 촬영하여 영상을 획득할 수 있다. 좌측 카 메라는 제1 카메라 및 제2 카메라를 포함하고, 제1 프레임의 전방의 영상 및 하방의 영상 을 촬영하여 영상을 획득할 수 있다. 우측 카메라는 제2 프레임의 주변 환경을 촬영하여 영상을 획득 할 수 있다. 우측 카메라는 제1 카메라 및 제2 카메라를 포함하고, 제2 프레임의 전방의 영상 및 하방의 영상을 촬영하여 영상을 획득할 수 있다. 일 실시예에서, 카메라는 디스플레이가 사용자를 향하는 방향과 반대 방향을 향하여, 사용자의 주변 환경을 촬영하여 영상을 획득할 수 있다. 다만, 본 개시는 이에 제한되지 않고, 좌측 카메라 및 우측 카메 라 각각의 배치 또는 성능에 따라, 제1 프레임 및 제2 프레임의 상방, 측면 또는 후면 등을 촬 영하여 영상을 획득할 수도 있다. 일 실시예에서, 제1 프레임에는 제1 디스플레이, 제1 광학 렌즈, 제1 카메라 및 제1 시선 추적 센서가 배치될 수 있다. 일 실시예에서, 제2 프레임에는 제2 디스플레이, 제2 광학 렌즈 , 제2 카메라 및 제2 시선 추적 센서가 배치될 수 있다. 다만, 본 개시는 이에 제한되지 않는다. 제1 디스플레이 및 제2 디스플레이는 일체로 형성되어 프레 임(171, 172)에 배치될 수도 있다. 제1 광학 렌즈 및 제2 광학 렌즈는 일체로 형성되어 프레임(171, 172)에 배치될 수도 있다. 또한, 제1 디스플레이와 제1 광학 렌즈가 일체로 형성되어 프레임(171, 172)에 배치될 수도 있다. 제2 디스플레이와 제1 광학 렌즈가 일체로 형성되어 프레임(171, 172)에 배치될 수도 있다. 일 실시예에서, 안경 다리(175, 176)는 프레임(171, 172)과 연결될 수 있다. 안경 다리(175, 176)는 사용자 가 헤드 마운티드 디스플레이 장치를 착용한 경우, 사용자의 귀 부분에 걸쳐져 헤드 마운티드 디스플 레이 장치를 지지하는 부분이다. 일 실시예에서, 안경 다리(175, 176)는 제1 프레임과 연결된 제1 안 경 다리 및 제2 프레임과 연결된 제2 안경 다리를 포함할 수 있다. 일 실시예에서, 디스플레이 엔진(178, 179)은 제1 디스플레이에 가상 이미지를 투사하는 제1 디스플레이 엔진 및 제2 디스플레이에 가상 이미지를 투사하는 제2 디스플레이 엔진을 포함할 수 있다. 일 실시예에서, 디스플레이 엔진(178, 179)은 프로젝터(projector)와 같은 기능을 수행할 수 있다. 디스플레이 엔 진(178, 179)은 조명 광학계, 광경로 변환기, 화상 패널, 빔 스필리터, 및 투사 광학계를 더 포함할 수 있다. 일 실시예에서, 제1 디스플레이 엔진은 제1 안경 다리에 내장될 수 있다. 제2 디스플레이 엔진 은 제2 안경 다리에 내장될 수 있다. 일 실시예에서, 가상 이미지는 콘텐츠를 포함할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치에 포함된 배터리, 디스플레이 엔진(178, 179), 메모 리 및 적어도 하나의 프로세서는 안경 다리(175, 176)에 내장될 수 있다. 도 2에는 배터리, 메 모리 및 적어도 하나의 프로세서가 제1 안경 다리에 내장되는 것으로 도시되었지만, 이는 예시 적인 구조이고, 본 개시가 도시된 바와 같이 한정되는 것은 아니다. 일 실시예에서, 코 지지부는 프레임(171, 172)과 연결될 수 있다. 코 지지부는 사용자가 헤드 마운티 드 디스플레이 장치를 착용한 경우, 사용자의 코 부분에 걸쳐져 헤드 마운티드 디스플레이 장치를 지 지하는 부분이다. 일 실시예에서, 코 지지부는 코 다리 및 안경 코를 포함할 수 있다. 또한, 코 다리 및 안경 코는 일체형으로 구성될 수 있으나 이에 한정되지 않는다. 본 개시의 일 실시예로, 코 지지부와 프레 임(171, 172)은 일체로 형성될 수도 있다. 일 실시예에서, 노즈 브릿지는 제1 프레임과 제2 프레임을 연결하는 지지대이다. 노즈 브릿지 는 코 지지부와 연결될 수 있다. 다만, 제1 프레임 및 제2 프레임이 일체로 형성되는 경우, 헤드 마운티드 디스플레이 장치는 노즈 브릿지를 포함하지 않을 수도 있다. 일 실시예에서, 시선 추적 센서는 헤드 마운티드 디스플레이 장치를 착용한 사용자의 눈(201, 202)에 광을 조사하고, 사용자의 눈(201, 202)에서 반사된 반사광을 수광하여 사용자의 시선 방향을 추적할 수 있다. 시선 추적 센서의 구성, 동작 및 기능에 관하여는 도 3에서 후술하도록 한다. 일 실시예에서, 배터리는 카메라, 시선 추적 센서, 메모리 및 적어도 하나의 프로세서 와 전기적 및/또는 물리적으로 연결될 수 있다. 배터리는 적어도 하나의 프로세서의 제어에 의 해 카메라 및 시선 추적 센서에 구동 전력을 공급할 수 있다. 일 실시예에서, 배터리는 충전 가능한 2차 전지로 구성된 적어도 하나의 배터리 모듈을 포함할 수 있다. 배터리는 예를 들어, 리튬 이온 배터리(Li-ion Battery), 리튬 이온 폴리머 배터리(Li-Ion Polymer Battery; LIPB), 니켈 카드뮴 배터리(Ni-Cd Battery), 또는 니켈 수소 배터리(Ni-MH Battery) 등으로 구성될 수 있으나, 이에 한정되지 않는다. 메모리 및 적어도 하나의 프로세서에 대한 구체적인 구성, 동작 및 기능에 대해서는 도 3에서 후술하 도록 한다. 도 3은 본 개시의 일 실시예에 따른 헤드 마운티드 디스플레이(Head mounted Display) 장치의 구성을 설명하기 위한 블록도이다. 도 1, 도 2 및 도 3을 참조하면, 헤드 마운티드 디스플레이 장치는 카메라, 디스플레이, 광학 렌즈, 시선 추적 센서, 메모리, 적어도 하나의 프로세서, 통신 인터페이스 및 관성 측정 장치(Inertial Measurement Unit, IMU, 192)를 포함할 수 있다. 그러나, 도 3에 도시된 구성 요소가 모두 필수 구성 요소인 것은 아니다. 도 3에 도시된 구성 요소보다 많은 구성 요소에 의해 헤드 마운티드 디스플레이 장치가 구현될 수도 있고, 그보다 적은 구성 요소에 의해서도 헤드 마운티드 디스플레이 장치는 구현 될 수 있다. 일 실시예에서, 도 3에는 도 2와 비교하여 프레임(171, 172), 노즈 브릿지, 코 지지부, 안경 다리(175, 176), 배터리 및 디스플레이 엔진(178, 179)의 구성이 미도시 되어있다. 일 실시예에서, 카메라, 디스플레이, 광학 렌즈, 시선 추적 센서, 메모리, 적어도 하 나의 프로세서, 통신 인터페이스 및 관성 측정 장치는 각각 전기적 및/또는 물리적으로 서로 연 결될 수 있다. 이하, 도 1 및 도 2에서 설명한 구성과 동일한 구성에 대하여는 동일한 도면 부호를 부여하고, 중복되는 설명은 생략하도록 한다. 일 실시예에서, 카메라는 현실 세계의 물리적 환경 공간이나, 현실 세계의 물리적 객체를 촬영하여 영상을 획득할 수 있다. 일 실시예에서, 카메라는 현실 세계를 촬영하여 RGB 정보를 포함하는 영상을 획득할 수 있는 RGB 카메라를 포함할 수 있다. 일 실시예에서, 카메라는 복수의 RGB 카메라들을 포함할 수 있다. 적어도 하나의 프로세서는 복수의 RGB 카메라들 각각에서 촬영된 RGB 정보를 포함하는 영상을 이용하여 깊이 정보를 획득할 수도 있다. 복수의 RGB 카메라들 각각은 서로 다른 위치에서 현실 세계를 촬영할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 복수의 RGB 카메라들 각각의 위치 관계와, 복수의 RGB 카메라들 각각에서 획득된 영상 내에 포함된 동일한 지점을 촬영한 복수의 픽셀들 간의 거리 및 복수의 픽셀들 각각의 크 기 등에 기초하여 현실세계의 깊이 정보를 획득할 수도 있다. 일 실시예에서, 카메라는 두 개의 RGB 카메 라들을 포함하는 스테레오(stereo) 카메라를 포함할 수도 있다. 또한, 카메라는 현실 세계를 촬영하여 RGB 정보 및 깊이 정보를 포함하는 영상을 획득하는 RGB-Depth 카메 라를 포함할 수도 있다. 일 실시예에서, 디스플레이는 투명 소재로 형성되는 광학 소자를 포함할 수 있다. 디스플레이는 사용 자가 헤드 마운티드 디스플레이 장치를 착용할 때, 배면의 일부 영역이 보이는 투명한 소재로 구성될 수 있다. 일 실시예에서, 디스플레이는 웨이브가이드(waveguide)를 포함할 수 있다. 웨이브가이드는 광이 내부에서 반사되면서 전파될 수 있는 투명 재질의 단층 혹은 다층 구조의 평판으로 구성될 수 있다. 다만, 본 개시는 이에 제한되지 않고, 디스플레이는 사용자에게 가상 이미지(예를 들어, 콘텐츠)를 제공할 수 있는 다른 종류의 디스플레이를 포함할 수도 있다. 일 실시예에서, 디스플레이는 디스플레이 엔진(178, 179)의 출사면에 마주하여, 디스플레이 엔진(178, 179)으로부터 투사된 가상 이미지의 광을 수광할 수 있다. 디스플레이로 투사된 가상 이미지의 광은 전반 사(total reflection) 원리에 의해 디스플레이 내에서 전파될 수 있다. 디스플레이는 광의 경로를 변경하여, 최종적으로는 사용자에게 가상 이미지를 제공할 수 있다. 일 실시예에서, 광학 렌즈는 현실 세계에서 헤드 마운티드 디스플레이 장치를 향하여 제공되는 빛을 통과시킬 수 있는 물질을 포함할 수 있다. 일 실시예에서, 광학 렌즈는 디스플레이를 통하여 제공되 는 영상을 구성하는 빛을 통과시킬 수 있는 물질을 포함할 수 있다. 일 실시예에서, 시선 추적 센서는 사용자의 시선 방향을 획득할 수 있다. 일 실시예에서, 시선 추적 센서는 사용자의 눈동자나 동공의 이미지를 검출하거나, 근적외선 등의 광이 각막에서 반사되는 반사광의 방향 또는 광량을 검출함으로써 사용자의 시선 방향을 추적할 수 있다. 일 실시예에서, 시선 추적 센서는 제1 시선 추적 센서 및 제2 시선 추적 센서를 포함할 수 있다. 제1 시선 추적 센서는 사용자의 좌안의 시선 방향을 추적하여 획득할 수 있다. 제2 시선 추적 센서는 사용자의 우안의 시선 방향을 추적하 여 획득할 수 있다. 일 실시예에서, 시선 추적 센서는 사용자의 눈(201, 202)을 향해 광을 조사하는 광원과, 사용자의 눈(201, 202)으로부터 반사된 반사광을 수광하는 센서를 포함할 수 있다. 이때, 사용자의 눈(201, 202)을 향해 조사하는 광 및 사용자의 눈으로부터 반사되는 반사광은 각각 적외선(infrared ray, IR)일 수 있다. 일 실시예에서, 메모리에는 적어도 하나의 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프 로그램 코드(program code)가 저장될 수 있다. 일 실시예에서, 메모리는 하나 이상일 수 있다. 개시된 실 시예들에서, 적어도 하나의 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의 명령어들 또 는 코드들을 실행함으로써 구현될 수 있다. 일 실시예에서, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀 티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), Mask ROM, Flash ROM 등), 하드 디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 메모리에는 헤드 마운티드 디스플레이 장치의 기능 또는 동작들을 수행하기 위한 명 령어들 또는 프로그램 코드가 저장될 수 있다. 메모리에 저장되는 명령어들, 알고리즘, 데이터 구조, 프로 그램 코드 및 애플리케이션 프로그램은 예를 들어, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로 그래밍 또는 스크립팅 언어로 구현될 수 있다. 일 실시예에서, 메모리에는 이미지 획득 모듈, 포즈 검출 모듈, 포즈 비교 모듈, 인터페이 스 비교 모듈, 공간맵 생성 모듈, 위치 결정 모듈 및 인터페이스 표시 모듈이 저장될 수 있다. 그러나, 도 3에 도시된 모듈 모두가 필수 모듈인 것은 아니다. 메모리에는 도 3에 도시된 모듈보다 더 많은 모듈들이 저장될 수도 있고, 그보다 적은 모듈들이 저장될 수도 있다. 또한, 메모리에는 적어도 하나의 인터페이스에 대응되도록 미리 설정된 복수의 포즈들이 저장될 수도 있다. 일 실시예에서, 메모리에 포함되는 '모듈'은 적어도 하나의 프로세서에 의해 수행되는 기능이나 동작 을 처리하는 단위를 의미할 수 있다. 메모리에 포함되는 '모듈'은 명령어들(instructions), 알고리즘, 데 이터 구조, 또는 프로그램 코드와 같은 소프트웨어로 구현될 수 있다. 일 실시예에서, 이미지 획득 모듈은 카메라를 통하여 현실 세계의 이미지를 획득하는 동작이나 기능 에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 이미지 획득 모듈은 제1 카메라를 통하여 헤드 마운티드 디스플레이 장치의 전방을 촬영하여 이미지를 획득하는 동작이나 기능에 관한 명령어들 또 는 프로그램 코드를 포함할 수 있다. 이미지 획득 모듈은 제2 카메라를 통하여 헤드 마운티드 디스플 레이 장치의 아래쪽을 촬영하여 이미지를 획득하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드를 포함할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 이미지 획득 모듈의 명령어들 또는 프로그램 코드를 실행 함으로써, 카메라를 통하여 현실 세계를 촬영하여 이미지를 획득할 수 있다. 적어도 하나의 프로세서(19 0)는 이미지 획득 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 카메라를 통하여 사용자 를 촬영하여 이미지를 획득할 수 있다. 구체적으로, 적어도 하나의 프로세서는 이미지 획득 모듈 의 명령어들 또는 프로그램 코드를 실행함으로써, 제2 카메라를 통하여 사용자의 동작을 촬영하여, 사용자의 손을 포함하는 이미지를 획득할 수 있다. 일 실시예에서, 포즈 검출 모듈은 획득된 이미지에 기초하여 사용자의 포즈를 검출하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 포즈 검출 모듈은 획득된 이미지에 포함된 사용자의 손에 기초하여, 사용자의 손의 포즈를 검출하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 포즈 검출 모듈은 획득된 이미지에 포함된 사용자의 특징점(feature point)을 검출하 고, 특징점의 위치 정보를 획득하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드를 포함할 수 있다. 포 즈 검출 모듈은 검출된 특징점에 기초하여 사람의 포즈를 검출하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드를 포함할 수 있다. 이때, '특징점'은 이미지 내에서 주위 배경과 구분되거나 식별이 용이한 지점을 의미할 수 있다. 특징점은 관절 (skeleton), 손, 얼굴 등을 포함할 수 있다. '포즈'는 적어도 하나의 특징점으로 이루어진 형상을 의미할 수 있 다. 일 실시예에서 포즈는 복수의 특징점들 및 복수의 특징점들을 각각 선으로 이어 만들어진 형태에 대응되는 형상을 의미할 수 있다. 일 실시예에서, 포즈 검출 모듈은 적어도 하나의 특징점을 검출하고, 검출된 적어도 하나의 특징점을 이어 사람의 포즈를 검출하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드를 포함할 수 있다. 일 실시예에서, 포즈 검출 모듈은 사람의 포즈를 추정하는 Pose Estmiation 모델을 포함할 수 있다. 일 실시예에서, 포즈 검출 모듈은 OpenPose, AlphaPose, CPN(Cascaded Pyramid Network) 등의 모델을 포함할 수 있다. 포즈 검 출 모듈은 CNN(Convolutional Neural Network), Transformer, Vision Transformer 등과 같은 Deep learning 기반의 모델을 이용하여 이미지로부터 사람의 포즈를 검출할 수도 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 검출 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 획득된 이미지에 포함된 사용자의 특징점을 검출할 수 있다. 적어도 하나의 프로세서는 포즈 검출 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 획득된 이미지로부터 특징점을 검출하고, 검출 된 특징점에 기초하여 사용자의 포즈를 검출할 수 있다. 일 실시예에서, 포즈 비교 모듈은 적어도 하나의 인터페이스에 대응되도록 미리 설정된 복수의 포즈들과 검출된 포즈를 비교하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 포즈 비교 모듈 은 미리 설정된 복수의 포즈들과 검출된 포즈를 비교하여, 검출된 포즈가 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 대응되는지 여부를 판단하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, '미리 설정된 복수의 포즈들'은 미리 설정된 특정 형상을 갖는 포즈를 의미할 수 있다. 일 실시 예에서, 미리 설정된 복수의 포즈들은 키보드를 이용하여 타자를 치는 손의 형상으로 설정된 포즈를 포함할 수 있다. 미리 설정된 복수의 포즈들은 마우스를 이용하는 손의 형상으로 설정된 포즈를 포함할 수 있다. 미리 설 정된 복수의 포즈들은 펜을 이용하여 그림을 그리는 손의 형상으로 설정된 포즈를 포함할 수 있다. 다만, 본 개 시는 이에 제한되지 않고, 미리 설정된 복수의 포즈들은 다양한 형상으로 미리 설정된 포즈를 포함할 수 있다. 일 실시예에서, '미리 설정된 복수의 포즈들'은 복수의 인터페이스들에 각각 대응되도록 설정될 수 있다. 일 실 시예에서, 미리 설정된 복수의 포즈들은 특정 인터페이스를 이용할 때의 특정 형상으로 설정된 포즈일 수 있다. 미리 설정된 복수의 포즈들은 특정 인터페이스 및 해당 인터페이스를 이용할 때의 손의 형상을 갖는 포즈로 설 정될 수 있다. 일 실시예에서 타자를 치는 손의 형상으로 설정된 포즈는, 키보드에 대응되도록 설정될 수 있다. 마우스를 이용하는 손의 형상으로 설정된 포즈는, 마우스에 대응되도록 설정될 수 있다. 펜를 이용하여 그림을 그리는 손의 형상으로 설정된 포즈는, 그림을 그리는 대상인 그림 패드에 대응되도록 설정될 수 있다. 다만, 본 개시는 이에 제한되지 않고, 미리 설정된 복수의 포즈들은 다양한 형상으로 미리 설정된 포즈로 이용 하는 인터페이스에 대응되도록 설정될 수 있다. 일 실시예에서, 미리 설정된 복수의 포즈들 각각은 적어도 하나의 특징점을 포함할 수 있다. 미리 설정된 복수 의 포즈들 각각에 포함된 적어도 하나의 특징점은 특정 형상에 대응되는 위치 정보를 포함할 수 있다. 포즈 비 교 모듈은 미리 설정된 복수의 포즈들 각각에 포함된 적어도 하나의 특징점의 위치 정보와 검출된 포즈에 포함된 적어도 하나의 특징점의 위치 정보를 비교하여, 검출된 포즈가 미리 설정된 복수의 포즈들 중 어느 하나 의 포즈에 대응되는지 여부를 판단하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다.일 실시예에서, 포즈 비교 모듈은 검출된 포즈에 포함된 적어도 하나의 특징점의 위치 정보와 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 포함된 적어도 하나의 특징점의 위치 정보의 차이가 오차 범위 내일 경우, 검출된 포즈가 해당되는 어느 하나의 포즈에 대응된다고 판단하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 이때, 오차 범위를 크게 설정할수록 포즈 비교 동작의 속도를 높일 수 있다. 오차 범위를 작게 설정할수록 포즈 비교 동작의 정확도를 높일 수 있다. 일 실시예에서, 오차 범위는 포즈 비교 동작의 속도 및 정확도를 고려하여 미리 설정될 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 비교 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 미리 설정된 복수의 포즈들과 검출된 포즈를 비교할 수 있다. 적어도 하나의 프로세서는 포즈 비 교 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 미리 설정된 복수의 포즈들 중 검출된 포즈에 대 응되는 어느 하나의 포즈를 결정할 수 있다. 일 실시예에서, 인터페이스 비교 모듈은 미리 설정된 복수의 포즈들 중 검출된 포즈에 대응된다고 판단된 어느 하나의 포즈에 대응되는 인터페이스(이하, 제2 인터페이스)와 디스플레이를 통하여 표시되는 인터페 이스(이하, 제1 인터페이스)를 비교하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 인터페이스 비교 모듈은 제1 인터페이스와 제2 인터페이스의 동일 여부를 판단하는 동작이 나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 적어도 하나의 프로세서 는 인터페이스 비교 모듈의 동작이나 기능에 관한 명령어들 또는 프로그램 코드를 실행함으로써, 제1 인터 페이스와 제2 인터페이스를 비교할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 인터페이스 비교 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 디스플레이를 통하여 표시되는 제1 인터페이스와 검출된 포즈에 대응된다고 판단된 어느 하 나의 포즈에 대응되는 제2 인터페이스를 비교할 수 있다. 적어도 하나의 프로세서는 디스플레이를 통 하여 표시되는 제1 인터페이스와 제2 인터페이스를 비교하여, 제1 인터페이스와 제2 인터페이스의 동일 여부를 판단할 수 있다. 일 실시예에서, 이미지 획득 모듈은 카메라를 통하여 헤드 마운티드 디스플레이 장치가 포함된 공간을 촬영하여 공간 이미지를 획득하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 헤드 마운티드 디스플레이 장치가 포함된 공간은 현실 세계를 의미할 수 있다. 일 실시예에서, 공간 이미지는 제1 카메라를 통하여 헤드 마운티드 디스플레이 장치의 전방을 촬영하여 획득된 이미지를 포함할 수 있다. 공간 이미지는 제2 카메라를 통하여 헤드 마운티드 디스플레이 장치의 아래쪽을 촬 영하여 획득된 이미지를 포함할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 LiDAR(Light Detection and Ranging) 센서 또는 RADAR(Radio Detection and Ranging) 센서 등을 포함할 수도 있다. 이미지 생성 모듈은 LiDAR 센서 또는 RADAR 센서를 통하여 헤드 마운티드 디스플레이 장치가 포함된 공간을 촬영하여 공간 이미지를 획득하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 이미지 생성 모듈의 명령어들 또는 프로그램 코드를 실행 함으로써, 카메라를 통하여 공간 이미지를 획득할 수 있다. 일 실시예에서, 적어도 하나의 프로세서 는 이미지 생성 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, LiDAR 센서 또는 RADAR 센서를 통하 여 공간 이미지를 획득할 수 있다. 일 실시예에서, 공간맵 생성 모듈은 획득된 공간 이미지에 기초하여 헤드 마운티드 디스플레이 장치 가 포함된 공간을 나타내는 공간맵을 생성하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, '공간맵'은 헤드 마운티드 디스플레이 장치가 포함된 공간에 대한 정보를 포함하는 맵으로, 공간 이미지에 포함된 배경, 객체의 종류, 객체의 위치, 객체의 형상, 배경과 객체의 깊이 정보 등에 기초하여 생성되는 맵일 수 있다. 일 실시예에서, 공간맵 생성 모듈은 SLAM(Simultaneous Localization and Mapping) 알고리즘을 포함할 수 있다. 공간맵 생성 모듈은 SLAM 알고리즘에 공간 이미지를 적용함으로서 공간 맵을 생성하는 동작이나 기 능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 적어도 하나의 프로세서는 공간맵 생성 모듈 의 명령어들 또는 프로그램 코드를 실행함으로써, SLAM 알고리즘에 공간 이미지를 적용함으로서 공간 맵을 생성할 수 있다.다만, 본 개시는 이에 제한되지 않고, 공간맵 생성 모듈은 헤드 마운티드 디스플레이 장치가 포함된 공간을 나타내는 공간맵을 생성하기 위한 다른 종류의 모델 또는 알고리즘 등을 포함할 수 있다. 일 실시예에서, 위치 결정 모듈은 생성된 공간맵 및 검출된 포즈에 기초하여 인터페이스를 표시할 인터페 이스 위치를 결정하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 위치 결정 모듈은 생성된 공간맵 및 검출된 포즈에 기초하여, 인터페이스를 표시할 인터페이스 위치를 결 정할 수 있다. 이때, '인터페이스 위치'는 헤드 마운티드 디스플레이 장치가 포함된 현실 세계에 디스플레 이를 통하여 인터페이스를 오버레이하여 표시할 위치를 의미할 수 있다. 일 실시예에서, 위치 결정 모듈은 생성된 공간맵 및 검출된 포즈에 기초하여, 현실 세계에서의 객체의 위 치, 객체의 형상, 검출된 포즈에 대응되는 인터페이스의 종류, 검출된 포즈에 대응되는 인터페이스의 형상 또는 현실 세계에서의 검출된 포즈의 위치 정보 중 적어도 하나에 기초하여 인터페이스 위치를 결정하는 동작이나 기 능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 위치 결정 모듈은 공간맵, 검출된 포즈 및 관성 측정 장치에 의하여 획득된 3 DoF(3 Degree of Freedom) 측정값 또는 6DoF(6 Degree of Freedom) 측정값에 기초하여 인터페이스 위치를 결정하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 위치 결정 모듈은 헤드 마운티드 디스플레이 장치를 착용한 사용자의 움직임에 대응하여, 인터페이스가 3DoF 또는 6DoF 로 표시되도록 인터페이스 위치를 결정할 수 있다. 이하, 3 DoF 및 6DoF에 대하여는 관성 측정 장치에서 후술하도록 한다. 일 실시예에서, 인터페이스 표시 모듈은 디스플레이를 통하여 인터페이스를 표시하는 동작이나 기능 에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 인터페이스 표시 모듈은 디스플 레이를 통하여, 결정된 인터페이스 위치에 인터페이스를 표시하는 동작이나 기능에 관한 명령어들 또는 프 로그램 코드로 구성될 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 인터페이스 표시 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 디스플레이를 통하여 인터페이스를 표시할 수 있다. 적어도 하나의 프로세서는 인터페 이스 표시 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 디스플레이를 통하여 결정된 인터페 이스 위치에 인터페이스를 표시할 수 있다. 이때, 적어도 하나의 프로세서는 인터페이스가 현실 세계 중 결정된 인터페이스 위치에 오버레이되어 사용자에게 제공되도록, 디스플레이에 인터페이스를 표시할 수 있다. 일 실시예에서, 메모리에는 디스플레이를 통하여 콘텐츠를 표시하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성된 콘텐츠 표시 모듈이 더 저장될 수 있다. 적어도 하나의 프로세서는 콘텐츠 표시 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 디스플레이를 통하여 콘텐츠를 표시할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 프로세서(Graphic Processing Unit), 애플리케이션 프로세서(Application Processor, AP), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays) 및 뉴럴 프로세서(Neural Processing Unit) 또는 인공지능 모델(Artificial Intelligence, AI)의 학습 및 처리에 특화된 하드웨어 구조로 설계된 인공지능 전용 프로세서 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 일 실시예에서, 적어도 하나의 프로세서는 메모리에 저장된 적어도 하나의 명령어를 실행함으로써, 인터페이스를 표시하는 헤드 마운티드 디스플레이 장치의 동작을 제어할 수 있다. 일 실시예에서, 통신 인터페이스는 적어도 하나의 프로세서의 제어에 의해 외부의 서버와 데이터 통 신을 수행할 수 있다. 또한, 통신 인터페이스는 외부의 서버뿐 아니라, 다른 주변 전자 장치들과도 데이터 통신을 수행할 수 있다. 일 실시예로, 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜(Wireless LAN), 와이파이(Wi-Fi), 블루투스 (Bluetooth), 지그비(zigbee), WFD(Wi-Fi Direct), 적외선 통신(IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로(Wireless Broadband Internet, Wibro),와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Allicance, WiGig) 및 RF 통신을 포함하는 데이터 통신 방식 중 적어도 하나를 이 용하여 서버 또는 다른 주변 전자 장치들과 데이터 통신을 수행할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 통신 인터페이스를 통하여 외부의 서버 또는 주변 전자 장 치들로부터 현실 세계에 대한 공간맵을 제공받을 수 있다. 일 실시예에서, 관성 측정 장치(Inertial Measurement Unit, IMU, 192)는 가속도 계(accelerometer), 자이로스 코프(gyroscope), 또는 자력계(magnetometer) 중 적어도 하나를 포함할 수 있다. 관성 측정 장치는 가속도 계(accelerometer), 자이로스코프(gyroscope), 또는 자력계(magnetometer) 중 적어도 하나를 통하여 헤드 마운 티드 디스플레이 장치의 이동 속도, 방향, 각도 또는 중력 가속도 중 적어도 하나를 측정하도록 구성되는 센서일 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치를 착용한 사용자가 움직이는 경우, 적어도 하나의 프 로세서는 관성 측정 장치를 통하여 헤드 마운티드 디스플레이 장치의 이동 속도, 방향, 각도 또 는 중력 가속도 중 적어도 하나를 측정할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 관성 측정 장치를 이용하여, 3축 각속도 값(롤(roll), 요(yaw), 피치(pitch))을 포함하는 3 DoF(3 Degree of Freedom) 측정값을 획득할 수 있다. 또한, 헤드 마운티드 디스플레이 장치는 관성 측정 장치를 이용 하여, 사용자의 3차원 위치 좌표값(x축, y축, 및 z축 좌표값) 및 3축 각속도 값(롤(roll), 요(yaw), 피치 (pitch))을 포함하는 6 DoF(6 Degree of Freedom) 측정값을 획득할 수도 있다. 도 4는 본 개시의 일 실시예에 따른 헤드 마운티드 디스플레이(Head mounted Display) 장치의 동작 방법을 설명 하기 위한 순서도이다. 도 5는 본 개시의 일 실시예에 따른, 제1 콘텐츠가 표시되는 동안 제1 인터페이스 및 제 2 인터페이스를 표시하는 동작을 설명하기 위한 순서도이다. 도 1, 도 3 및 도 4를 참조하면, 일 실시예에서, 도 4는 디스플레이를 통하여 인터페이스가 표시되고 있는 동안, 헤드 마운티드 디스플레이 장치의 동작 방법이 도시되어 있다. 일 실시예에서, 디스플레이를 통하여 표시되고 있는 인터페이스를 '제1 인터페이스'로 지칭하고, 후술할 검출된 포즈에 따라 디스 플레이를 통하여 표시되는 인터페이스를 '제2 인터페이스'로 지칭하여 설명하도록 한다. 일 실시예에서, 제1 인터페이스는, 본 개시에 따른 사용자를 촬영하여 획득된 이미지로부터 사용자의 동작을 검출하고, 검출된 동작과 미리 설정된 복수의 포즈들을 비교하여 대응되는 어느 하나의 포즈에 따른 인 터페이스로서 디스플레이를 통하여 표시된 것일 수 있다. 다만, 본 개시는 이에 제한되지 않고, 제1 인터 페이스는 사용자 인터페이스 등을 통하여 제공된 사용자 입력과 같이, 다른 방법에 의하여 디스플레이 를 통하여 표시된 것일 수도 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 카메라를 통하여 사용자를 촬영하여 이미지를 획득하는 단계(S100)를 포함할 수 있다. 일 실시예에서, 사용자를 촬영하여 이미지를 획득하는 단계(S100)에서, 적어도 하나의 프로세서는 이미지 획득 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 카메라를 통하여 사용자를 촬영하여 이미 지를 획득할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 획득된 이미지에 기초하여 사용자의 포즈를 검출하는 단계(S200)를 포함할 수 있다. 일 실시예에서, 사용자의 포즈를 검출하는 단계(S200)에서, 적어도 하나의 프로세서는 포즈 검출 모듈 의 명령어들 또는 프로그램 코드를 실행함으로써, 획득된 이미지로부터 사용자의 포즈를 검출할 수 있다. 일 실시예에서, 사용자의 포즈를 검출하는 단계(S200)에서, 적어도 하나의 프로세서는 포즈 검출 모듈 의 명령어들 또는 프로그램 코드를 실행함으로써, 획득된 이미지에 포함된 사용자를 검출(detection), 추 정(estimation) 또는 분할(segmentation)할 수 있다. 적어도 하나의 프로세서는 포즈 검출 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 검출, 추정 또는 분할된 사용자의 적어도 하나의 특징점을 검출 할 수 있다. 일 실시예에서, 사용자의 포즈를 검출하는 단계(S200)에서, 적어도 하나의 프로세서는 포즈 검출 모듈 의 명령어들 또는 프로그램 코드를 실행함으로써, 검출된 적어도 하나의 특징점에 기초하여 사용자의 포즈 를 검출할 수 있다. 일 실시예에서, 획득된 이미지에 사용자의 손이 포함되어 있는 경우, 적어도 하나의 프로세서는 사용자의 손에서 검출된 적어도 하나의 특징점에 기초하여 사용자의 손의 포즈를 검출할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 적어도 하나의 인터페이스에 대응된 미리 설정된 복수의 포즈들과 검출된 포즈를 비교하는 단계(S300)를 포함할 수 있다. 일 실시예에서, 미리 설정된 복수의 포즈들과 검출된 포즈를 비교하는 단계(S300)에서, 적어도 하나의 프 로세서는 포즈 비교 모듈 의 명령어들 또는 프로그램 코드를 실행함으로써 적어도 하나의 인터페이스 에 대응된 미리 설정된 복수의 포즈들과 검출된 포즈를 비교할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 검출된 포즈가 미리 설정된 복수의 포 즈들 중 어느 하나의 포즈에 대응되는지 여부를 판단하는 단계(S400)를 포함할 수 있다. 일 실시예에서, 검출된 포즈가 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 대응되는지 여부를 판단 하는 단계(S400)에서, 적어도 하나의 프로세서는 포즈 비교 모듈의 명령어들 또는 프로그램 코드를 실행함으로써 미리 설정된 복수의 포즈들과 검출된 포즈를 비교하여, 복수의 포즈들 중 검출된 포즈 에 대응되는 포즈가 존재하는지 여부를 판단할 수 있다. 도 4에는 적어도 하나의 인터페이스에 대응된 미리 설정된 복수의 포즈들과 검출된 포즈를 비교하는 단계 (S300) 및 검출된 포즈가 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 대응되는지 여부를 판단하는 단계(S400)가 구분되어 도시되어 있지만, 본 개시는 이에 제한되지 않는다. 미리 설정된 복수의 포즈들과 검출 된 포즈를 비교하는 동작과 검출된 포즈가 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 대응되 는지 여부를 판단하는 동작은 하나의 단계에서 이루어질 수도 있다. 일 실시예에서, 검출된 포즈가 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 대응되는지 여부를 판단 하는 단계(S400)에서 검출된 포즈가 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 대응된다고 판단됨에 따 라, 헤드 마운티드 디스플레이 장치의 동작 방법은 디스플레이에 표시된 제1 인터페이스와 어느 하나의 포즈에 대응되는 제2 인터페이스를 비교하는 단계(S500)를 포함할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 디스플레이에 표시된 제1 인터페이스와 어느 하나의 포즈에 대응되는 제2 인터페이스를 비교하는 단계(S500)에서, 인터페이스 비교 모듈의 명령어들 또는 프로그램 코드를 실행함으로써 제1 인터페이스와 제2 인터페이스를 비교할 수 있다. 일 실시예에서, 디스플레이에 표시된 제1 인터페이스와 어느 하나의 포즈에 대응되는 제2 인터페이스 를 비교하는 단계(S500)에서 제1 인터페이스와 제2 인터페이스가 상이한 인터페이스로 판단됨에 따라, 헤드 마운티드 디스플레이 장치의 동작 방법은 디스플레이를 통하여 제2 인터페이스를 표 시하는 단계(S600)를 포함할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 디스플레이를 통하여 제2 인터페이스를 표시하는 단 계(S600)에서, 인터페이스 표시 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 디스플레이를 통하여 제2 인터페이스를 표시할 수 있다. 일 실시예에서, 디스플레이를 통하여 제2 인터페이스를 표시하는 단계(S600)에서, 디스플레이를 통하여 표시되는 제1 인터페이스를 제2 인터페이스로 대체하여 표시할 수 있다. 일 실시예에서, 적어 도 하나의 프로세서는 디스플레이를 통하여 제2 인터페이스를 표시하는 단계(S600)에서, 인터페 이스 표시 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 디스플레이에 표시되던 제1 인터페 이스를 검출된 포즈에 대응되는 제2 인터페이스로 대체하여 표시하여 사용자에게 제공할 수 있다. 일 실시예에서, 검출된 포즈가 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 대응되는지 여부를 판단 하는 단계(S400)에서 검출된 포즈가 미리 설정된 복수의 포즈들과 상이하여, 검출된 포즈가 복수의 포즈들과 대 응되지 않는다고 판단됨에 따라, 헤드 마운티드 디스플레이 장치의 동작 방법은 디스플레이를 통하여 표시되는 제1 인터페이스를 유지하는 단계(S700)를 포함할 수 있다. 일 실시예에서, 검출된 포즈가 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 대응되는지 여부를 판단 하는 단계(S400)에서 검출된 포즈가 미리 설정된 복수의 포즈들과 상이하다고 판단됨에 따라, 적어도 하나의 프 로세서는 인터페이스 표시 모듈의 명령어들 또는 프로그램 코드를 실행함으로써 디스플레이를 통하여 표시되는 제1 인터페이스를 유지하여 사용자에게 제공할 수 있다.일 실시예에서, 헤드 마운티드 디스플레이 장치는 검출된 포즈가 미리 설정된 복수의 포즈들에 대응되지 않는 경우, 사용자의 동작이 디스플레이에 표시되는 인터페이스를 변경하고자 하는 동작이 아닌 것으 로 판단할 수 있다. 따라서, 헤드 마운티드 디스플레이 장치는 디스플레이를 통하여 표시되는 제1 인 터페이스를 계속 유지할 수 있다. 이를 통하여, 사용자의 동작에 의하여 불필요하게 디스플레이(14 0)를 통하여 표시되는 인터페이스가 변경되는 것을 방지할 수 있다. 일 실시예에서, 디스플레이에 표시된 제1 인터페이스와 어느 하나의 포즈에 대응되는 제2 인터페이스 를 비교하는 단계(S500)에서 제1 인터페이스와 제2 인터페이스가 동일한 인터페이스로 판단됨에 따라, 적어도 하나의 프로세서는 인터페이스 표시 모듈의 명령어들 또는 프로그램 코드를 실행함으로 써 디스플레이를 통하여 표시되는 제1 인터페이스를 유지하여 사용자에게 제공할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 검출된 포즈에 대응되는 제2 인터페이스가 디스플레이 를 통하여 표시되고 있는 제1 인터페이스와 동일한 인터페이스라고 판단된 경우, 사용자의 동작 이 제1 인터페이스를 사용하기 위한 동작인 것으로 판단할 수 있다. 따라서, 헤드 마운티드 디스플레이 장 치는 디스플레이를 통하여 표시되는 제1 인터페이스를 계속 유지할 수 있다. 이를 통하여, 사용 자가 제1 인터페이스를 이용하는 도중에 디스플레이를 통하여 표시되는 인터페이스가 변경되는 것을 방지할 수 있다. 도 1, 도 3, 도 4 및 도 5를 참조하면, 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은, 디 스플레이에 콘텐츠를 표시하는 단계(S50)를 포함할 수 있다. 일 실시예에서, 디스플레이에 콘텐츠를 표시하는 단계(S50)에서 표시하는 콘텐츠를 '제1 콘텐츠'로 지칭하여 설명하도록 한다. 일 실시예에서, 제1 콘텐츠는 디스플레이를 통하여 표시되어 사용자에게 제공되는 콘텐츠로, 이미지 또는 동영상을 포함할 수 있고, 온라인 강의, 인터넷 브라우저, 게임, 채팅 화면, 지도, 책, 광고, 영화, 화상 채팅 등 어느 하나로 제한되지 않는다. 일 실시예에서, 카메라를 통하여 사용자를 촬영하여 이미지를 획득하는 단계(S100)의 동작은 디스플레이 에 콘텐츠를 표시하는 단계(S50)의 동작 이후에 실행될 수 있다. 일 실시예에서, 도 4에 기재된 동작 방법은, 디스플레이에 콘텐츠를 표시하는 단계(S50)의 동작 이후에 실행될 수 있다. 일 실시예에서, 디스플레이를 통하여 제1 인터페이스 및 제2 인터페이스를 표시하는 동작은 디스플레이를 통하여 제1 콘텐츠가 표시되는 동안 이루어질 수 있다. 일 실시예에서, 사용자는 디스플레이에 제1 콘텐츠가 표시되는 동안, 특정한 포즈만(예를 들어, 키보드를 이용하는 손의 포즈, 마우스를 이용하는 손의 포즈)을 취하여 디스플레이에 제1 인터페이스(50 0)가 표시되도록 하거나, 디스플레이에 표시되고 있는 제1 인터페이스를 제1 인터페이스와 상이 한 제2 인터페이스로 변경되어 표시되도록 할 수 있다. 이를 통하여, 사용자의 헤드 마운티드 디스플 레이의 사용 편의성을 향상시킬 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 본 개시로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다 도 6은 본 개시의 일 실시예에 따른, 검출된 사용자의 포즈에 대응되는 인터페이스를 표시하는 동작을 설명하기 위한 도면이다. 도 1, 도 3, 도 4 및 도 6을 참조하면, 일 실시예에서, 적어도 하나의 프로세서는 이미지 획득 모듈 의 명령어들 또는 프로그램 코드를 실행함으로써, 제2 카메라를 통하여 사용자를 촬영하여 이미지를 획득 할 수 있다. 도 6에는 제2 카메라를 통하여 사용자를 촬영하는 것으로 도시되어 있으나, 본 개시는 이에 제한되지 않는다. 촬영하고자 하는 사용자의 동작의 위치, 카메라의 배치 및 카메라의 성능에 따라, 제1 카메라 또는 다른 카메라를 통하여 사용자의 동작을 촬영할 수도 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 검출 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 획득한 이미지에 포함된 사용자의 특징점(600, 610)을 검출할 수 있다. 일 실시예에서, 획득된 이미지 에 사용자의 손이 포함된 경우, 적어도 하나의 프로세서는 사용자의 손의 특징점(600, 610)을 검출할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 검출 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 검출된 특징점(600, 610)에 기초하여 사용자의 포즈를 검출할 수 있다. 일 실시예에서, 제2 카메라가 사용자가 키보드를 이용하여 타자를 치는 손의 동작을 촬영한 경우에 검출된 특징점은 제1 특징점일 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 검출 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 검출된 제1 특징점에 기초하여 사용자의 포즈를 검출할 수 있다. 일 실시예에서, 제1 특징점으로부터 검출된 포즈를 제1 포즈라 지칭할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 비교 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 검출된 제1 포즈와 미리 설정된 복수의 포즈들을 비교할 수 있다. 적어도 하나의 프로세서는 검출된 제1 포즈가 미리 설정된 복수의 포즈들 중 키보드를 이용하여 타자를 치는 손의 포즈로 설정된 어 느 하나의 포즈에 대응된다고 판단할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 비교 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 검출된 제1 포즈가 미리 설정된 복수의 포즈들 중 키보드를 이용하여 타자를 치는 손의 포즈에 대 응된다고 판단하고, 검출된 제1 포즈에 대응되는 인터페이스를 키보드로 결정할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 디스플레이를 통하여 표시되고 있는 인터페이스가 없는 경 우, 인터페이스 표시 모듈의 명령어들 또는 프로그램 코드를 실행함으로써 디스플레이를 통하여 키보 드를 표시할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 디스플레이를 통하여 표시되고 있는 인터페이스가 있는 경 우, 인터페이스 비교 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 디스플레이를 통하여 표 시되고 있는 인터페이스와 키보드의 동일 여부를 판단할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 디스플레이를 통하여 표시되고 있는 인터페이스가 키보드 와 상이한 경우, 디스플레이를 통하여 표시되고 있는 인터페이스를 키보드로 변경하여 표시할 수 있다. 적어도 하나의 프로세서는 디스플레이를 통하여 표시되고 있는 인터페이스가 키보드인 경우, 디스플레이를 통하여 표시되고 있는 키보드가 표시되는 것을 유지할 수 있다. 일 실시예에서, 제2 카메라가 사용자가 펜을 이용하여 그림을 그리는 손의 동작을 촬영한 경우에 검출된 특징점은 제2 특징점일 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 검출 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 검출된 제2 특징점에 기초하여 사용자의 포즈를 검출할 수 있다. 일 실시예에서, 제2 특징점으로부터 검출된 포즈를 제2 포즈라 지칭할 수 있다. 일 실시예에서, 도 6에는 사용자가 펜을 쥐고 그림을 그리는 동작으로 도시되어 있으나, 본 개시는 이에 제한되 지 않는다. 사용자는 펜뿐만 아니라 막대 형상의 객체를 쥐고 그림을 그릴 수도 있다. 또한, 사용자는 아무것도 쥐지 않은 상황에서, 펜으로 그림을 그리는 형태를 취할 수도 있다. 이때, 디스플레이를 통하여 펜의 이미 지가 표시되어 사용자에게 제공될 수도 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 비교 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 검출된 제2 포즈가 미리 설정된 복수의 포즈들 중 펜을 이용하여 그림을 그리는 손의 포즈로 설정 된 어느 하나의 포즈에 대응된다고 판단할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 비교 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 검출된 제2 포즈가 미리 설정된 복수의 포즈들 중 펜을 이용하여 그림을 그리는 손의 포즈에 대응 된다고 판단하고, 검출된 제2 포즈에 대응되는 인터페이스를 그림 패드로 결정할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 디스플레이를 통하여 표시되고 있는 인터페이스가 있는 경 우, 인터페이스 비교 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 디스플레이를 통하여 표 시되고 있는 인터페이스와 그림 패드의 동일 여부를 판단할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 디스플레이를 통하여 표시되고 있는 인터페이스가 키보드 인 경우, 디스플레이를 통하여 표시되고 있는 키보드를 그림 패드로 변경하여 표시할 수 있다. 도 7은 본 개시의 일 실시예에 따른, 카메라를 통하여 생성된 공간맵과 검출된 포즈에 기초하여 인터페이스 위 치를 결정하는 동작을 설명하기 위한 순서도이다. 이하, 도 4에서 설명한 단계와 동일한 단계에 대하여는 동일 한 도면 부호를 부여하고, 중복되는 설명은 생략하도록 한다.도 1, 도 3, 도 4, 도 6 및 도 7을 참조하면, 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법 은 카메라를 통하여 헤드 마운티드 디스플레이 장치가 포함된 공간을 촬영하여 공간 이미지를 획득하 는 단계(S610)를 포함할 수 있다. 일 실시예에서, 공간 이미지를 획득하는 단계(S610)에서, 적어도 하나의 프로세서는 이미지 획득 모듈 의 명령어들 또는 프로그램 코드를 실행함으로써 헤드 마운티드 디스플레이 장치가 포함된 공간을 촬 영하여 공간 이미지를 획득할 수 있다. 일 실시예에서, 공간 이미지를 획득하는 단계(S610)의 동작은 디스플레이에 표시된 제1 인터페이스와 어느 하나의 포즈에 대응되는 제2 인터페이스를 비교하는 단계(S500)에서 제1 인터페이스와 제2 인터 페이스가 상이한 인터페이스로 판단된 이후에 실행될 수 있다. 다만, 본 개시는 이에 제한되지 않는다. 공 간 이미지를 획득하는 단계(S610)의 동작은 사용자의 동작을 촬영하여 이미지를 획득하는 단계(S100)의 동작과 함께 실행되거나, 혹은 제1 인터페이스와 제2 인터페이스를 비교하는 단계(S500)의 동작 이전에 실행 될 수도 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 획득된 공간 이미지에 기초하여 공간을 나 타내는 공간맵을 생성하는 단계(S620)를 포함할 수 있다. 일 실시예에서, 공간맵을 생성하는 단계(S620)에서, 적어도 하나의 프로세서는 공간맵 생성 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 공간 이미지에 기초하여 공간을 나타내는 공간맵을 생성할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 생성된 공간맵 및 검출된 포즈에 기초하여 인터페이스를 표시할 인터페이스 위치를 결정하는 단계(S630)를 포함할 수 있다. 일 실시예에서, 인터페이스 위 치를 결정하는 단계(S630)에서는, 검출된 제2 포즈에 대응되는 제2 인터페이스를 표시할 인터페이스 위치를 결정할 수 있다. 다만, 본 개시는 이에 제한되지 않고, 제1 인터페이스도 사용자의 검출된 포즈에 대응되어 표시되는 경우, 인터페이스를 표시할 인터페이스 위치를 결정하는 단계(S630)에서 검출된 제1 포즈 에 대응되는 제1 인터페이스를 표시할 인터페이스 위치를 결정할 수도 있다. 일 실시예에서, 인터페이스를 표시할 인터페이스 위치를 결정하는 단계(S630)에서 적어도 하나의 프로세서(19 0)는 위치 결정 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 인터페이스를 표시할 인터페이스 위 치를 결정할 수 있다. 적어도 하나의 프로세서는 위치 결정 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 제1 인터페이스를 표시할 인터페이스 위치 또는 제2 인터페이스를 표시할 인터페이스 위치를 결정할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 디스플레이를 통하여 결정된 인터페이 스 위치에 인터페이스를 표시하는 단계(S640)를 포함할 수 있다. 일 실시예에서, 결정된 인터페이스 위치에 인터페이스를 표시하는 단계(S640)에서는, 디스플레이를 통하여 제2 인터페이스를 표시하도록 결정된 인터페이스 위치에 제2 인터페이스를 표시할 수 있다. 다만, 본 개시는 이에 제한되지 않고, 결정된 인터페이스 위치에 인터페이스를 표시하는 단계(S640)에서는, 디스플레이 를 통하여 제1 인터페이스를 표시하도록 결정된 인터페이스 위치에 제1 인터페이스를 표시할 수 도 있다. 일 실시예에서, 결정된 인터페이스 위치에 인터페이스를 표시하는 단계(S640)에서, 적어도 하나의 프로세서 는 인터페이스 표시 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 결정된 인터페이스 위치에 제1 인터페이스 또는 제2 인터페이스를 표시할 수 있다. 도 8은 본 개시의 일 실시예에 따른, 시선 추적 센서를 통하여 사용자의 시점을 획득하고, 획득된 시점 및 획득 된 이미지에 기초하여 사용자의 포즈를 검출하는 동작을 설명하기 위한 순서도이다. 이하, 도 4에서 설명한 단 계와 동일한 단계에 대하여는 동일한 도면 부호를 부여하고, 중복되는 설명은 생략하도록 한다. 도 1, 도 3, 도 4 및 도 8을 참조하면, 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 시 선 추적 센서를 통하여 추적한 사용자의 시선 방향에 기초하여, 사용자의 시점을 획득하는 단계(S60)를 포 함할 수 있다. 일 실시예에서, 사용자의 시점을 획득하는 단계(S60)에서는, 획득된 사용자의 시선 방향에 기초하여, 사용자의 두 눈(201, 202)의 시선이 각각 교차하는 지점을 계산하고, 해당 지점을 시점으로 획득할 수 있다. 일 실시예에 서, 사용자의 시점을 획득하는 단계(S60)에서는 카메라를 통하여 획득한 영상 및 획득한 사용자의 시선 방향에 기초하여, 헤드 마운티드 디스플레이 장치와 주변 환경 간의 거리 및 사용자의 시선 방향에 기초하여, 사용자의 시점을 획득할 수 있다. 일 실시예에서, 사용자의 시점을 획득하는 단계(S60)에서, 적어도 하나의 프로세서는 사용자의 시점을 획 득하기 위한 명령어들 또는 프로그램 코드를 실행함으로써, 사용자의 시선 방향에 기초하여 사용자의 시점을 획 득할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 획득된 사용자의 시점 및 획득된 이미지에 기초하여 사용자의 포즈를 검출하는 단계를 포함할 수 있다. 일 실시예에서, 사용자의 포즈를 검출하는 단 계(S210)에서는, 사용자의 시점을 획득하는 단계(S60)에서 획득된 사용자의 시점 및 이미지를 획득하는 단계 (S100)에서 획득된 이미지에 기초하여 사용자의 포즈를 검출할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 검출 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 획득된 사용자의 시점 및 획득된 이미지에 기초하여 사용자의 포즈를 검출할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 획득된 이미지 중 획득된 사용자의 시점이 위치한 영역에 검출하고자 하는 사용자의 동작이 있다고 판단하고, 해당 영역에 상대적으로 높은 가중치를 주어 획득된 이미지 중 사용자의 포즈를 검출 할 수 있다. 일 실시예에서, 사용자가 손으로 키보드를 치는 동작을 수행하고 있고, 사용자의 시선이 키보드를 치는 동작을 수행하는 손을 바라보는 경우, 획득된 이미지에는 키보드를 치는 동작을 수행하는 손이 포함되고 획득된 사용자 의 시점은 키보드를 치는 동작을 수행하는 손이 존재하는 영역에 대응될 수 있다. 이 경우, 적어도 하나의 프로 세서는 획득된 이미지 중 사용자의 손에 집중하여 사용자의 포즈를 검출할 수 있다. 도 9는 본 개시의 일 실시예에 따른, 시선 추적 센서를 통하여 획득된 사용자의 시점에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정하는 동작을 설명하기 위한 순서도이다. 도 8에서 설명한 단계와 동일한 단계에 대하 여는 동일한 도면 부호를 부여하고, 중복되는 설명은 생략하도록 한다. 도 1, 도 3 및 도 9를 참조하면, 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은, 사용자의 시점을 획득하는 단계(S60) 이후에, 획득된 사용자의 시점에 기초하여 인터페이스를 통하여 획득되는 사용자 입 력이 표시되는 콘텐츠를 표시할 콘텐츠 위치를 결정하는 단계(S800)를 포함할 수 있다. 일 실시예에서, 인터페이스를 통하여 획득되는 사용자 입력이 표시되는 콘텐츠를 '제2 콘텐츠'로 지칭하여 설명 하도록 한다. 일 실시예에서, 제2 콘텐츠(730, 도 10a 참조)는 인터페이스를 통하여 사용자가 입력한 사용자 입력이 표시되는 콘텐츠일 수 있다. 제2 콘텐츠는 제1 인터페이스 또는 제2 인터페이스 중 적어도 하나의 인터페 이스를 통하여 사용자가 입력한 사용자 입력이 표시되는 콘텐츠일 수 있다. 일 실시예에서, 제2 콘텐츠는 메모장, 노트 또는 마우스 커서(mouse cursor) 등을 포함할 수 있고, 어느 하나로 제한되지 않는다. 일 실시예에서, 디스플레이를 통하여 표시되는 제2 콘텐츠에는 인터페이스를 통하여 사용자가 입력한 사용자 입력이 표시될 수 있다. 사용자는 디스플레이를 통하여 표시되는 제2 콘텐츠를 통하여 자신이 입력한 사용자 입력을 확인할 수 있어, 사용자의 편의성이 향상될 수 있다. 일 실시예에서, 획득된 사용자의 시점에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정하는 단계 (S800)에서는, 획득된 사용자의 시점에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정할 수 있다. 일 실시예에서, 획득된 사용자의 시점에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정하는 단계(S800)에 서는, 획득된 사용자의 시점 및 디스플레이에 표시되는 제1 콘텐츠에 기초하여 제2 콘텐츠를 표 시할 콘텐츠 위치를 결정할 수 있다. 일 실시예에서, 획득된 사용자의 시점에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정하는 단계 (S800)에서, 적어도 하나의 프로세서는 위치 결정 모듈의 명령어들 또는 프로그램 코드를 실행함으로 써, 획득된 사용자의 시점에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정할 수 있다. 이하, 제2 콘텐츠를 표시할 콘텐츠 위치를 결정하는 동작에 대하여는 도 10a 및 도 10b에서 후술하도록 한다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은, 디스플레이를 통하여 결정된 콘텐츠 위치에 제2 콘텐츠를 표시하는 단계(S900)를 포함할 수 있다. 일 실시예에서, 디스플레이를 통하여결정된 콘텐츠 위치에 제2 콘텐츠를 표시하는 단계(S900), 적어도 하나의 프로세서는 디스플레이 를 통하여 제2 콘텐츠를 표시하기 위한 명령어들 또는 프로그램 코드를 실행함으로써, 결정된 콘텐츠 위치에 제2 콘텐츠를 표시할 수 있다. 일 실시예에서, 제2 콘텐츠를 표시할 콘텐츠 위치를 결정하는 단계(S800)의 동작 및 디스플레이를 통 하여 콘텐츠 위치에 제2 콘텐츠을 표시하는 단계(S900)의 동작은 디스플레이를 통하여 제1 인터페이 스 또는 제2 인터페이스 중 적어도 하나를 표시하는 동작과 함께 이루어질 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 제1 인터페이스 또는 제2 인터페이스 중 적어도 하나 를 표시할 인터페이스 위치를 결정하고, 제2 콘텐츠를 표시할 콘텐츠 위치를 결정할 수 있다. 적어도 하나 의 프로세서는 디스플레이를 통하여 결정된 인터페이스 위치에 제1 인터페이스 또는 제2 인터페 이스 중 적어도 하나를 표시하고, 결정된 콘텐츠 위치에 제2 콘텐츠를 표시할 수 있다. 도 10a는 본 개시의 일 실시예에 따른, 시선 추적 센서를 통하여 획득된 사용자의 시점에 기초하여 제2 콘텐츠 를 표시할 콘텐츠 위치를 결정하는 동작을 설명하기 위한 도면이다. 도 10b는 본 개시의 일 실시예에 따른, 시 선 추적 센서를 통하여 획득된 사용자의 시점에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정하는 동작을 설명하기 위한 도면이다. 도 1, 도 3 및 도 10a를 참조하면, 일 실시예에서, 도 10a에는 디스플레이를 통하여 표시되는 제1 콘텐츠 및 제2 콘텐츠가 도시되어 있다. 일 실시예에서, 도 10a에는, 획득된 사용자의 시점이 제1 콘텐츠와 중첩되는 것으로 도시되어 있다. 일 실시예에서, 사용자는 제1 콘텐츠를 바라보며 손 등을 이용하여 특정 동작을 취할 수 있다. 일 실 시예에서, 사용자는 제1 콘텐츠를 바라보며 손으로 키보드를 치는 포즈, 마우스를 움직이는 포즈 또 는 펜을 이용하여 그림을 그리는 포즈 등을 취할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 결정된 인터페이스 위치에 사용자의 동작에 의하여 검출된 포즈 에 대응되는 인터페이스(예를 들어, 키보드, 마우스 또는 그림 패드 등)을 디스플레이를 통하여 표시할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 디스플레이를 통하여 표시된 인터페이스를 통하여 사용자 가 제공하는 사용자 입력을 표시하는 제2 콘텐츠를 통하여 디스플레이에 표시할 수 있다. 이때, 적어 도 하나의 프로세서는 위치 결정 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 제2 콘텐츠 가 제1 콘텐츠와 중첩되어 표시되지 않도록 제2 콘텐츠를 표시할 콘텐츠 위치를 결정할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 위치 결정 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 획득한 사용자의 시점으로부터 제1 콘텐츠와 인접한 영역까지의 제1 거리를 계산할 수 있다. 일 실시예에서, 제1 거리는 획득한 사용자의 시점으로부터 제1 콘텐츠와 중첩되지 않는 영역까지의 최단 거리일 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 위치 결정 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 획득한 사용자의 시점에 계산된 제1 거리와 미리 설정된 제2 거리를 더한 값을 계산할 수 있다. 이때, 미리 설정된 제2 거리는 제1 콘텐츠와 제2 콘텐츠가 구분되도록, 제1 콘텐츠 와 제2 콘텐츠가 디스플레이 상에 서로 이격되어 표시되도록 미리 설정된 거리일 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 획득한 사용자의 시점에 계산된 제1 거리와 미리 설 정된 제2 거리를 더하여 계산된 값에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정할 수 있다. 이를 통하여, 디스플레이를 통하여 표시되는 제1 콘텐츠를 보는 사용자의 사용 경험을 방해하지 않으면서 사용자가 인터페이스를 통하여 입력하는 사용자 입력을 확인할 수 있도록 할 수 있다. 이때, 도 10a에는 디스플레이 상에 제2 콘텐츠가 제1 콘텐츠의 우측에 표시되는 것으로 도시되 어 있고, 제1 거리가 획득된 사용자의 시점으로부터 제1 콘텐츠와 중첩되지 않는 영역까지의 우 측 방향으로의 최단 거리인 것으로 도시되어 있다. 다만, 본 개시는 이에 제한되지 않고, 제2 콘텐츠는 제 1 콘텐츠의 좌측, 상측, 하측 또는 대각선 방향에 표시될 수도 있다. 이때, 제1 거리는 획득된 사용 자의 시점으로부터 제2 방향이 제1 콘텐츠를 기준으로 표시되는 방향으로의 최단 거리일 수 있다. 일 실시예에서, 제2 콘텐츠가 제1 콘텐츠를 기준으로 어느 방향에 표시될지는 제1 콘텐츠의 종 류, 형상, 크기, 제2 콘텐츠의 종류, 형상, 크기, 디스플레이의 형상 또는 크기 중 적어도 하나에 기 초하여 설정될 수 있다. 도 10a 및 도 10b를 참조하면, 일 실시예에서, 획득된 사용자의 시점이 제1 콘텐츠와 중첩되지 않는 것이 도시되어 있다. 일 실시예에서, 사용자는 제1 콘텐츠가 아닌, 다른 영역을 바라보며 손 등을 이 용하여 특정 동작을 취할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 위치 결정 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 획득된 사용자의 시점에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정할 수 있다. 이때, 적어도 하나의 프로세서는 미리 설정된 제2 거리에 기초하여, 획득된 사용자의 시점에 기 초하여 표시되는 제2 콘텐츠가 제1 콘텐츠와 중첩된다고 판단되는 경우, 획득된 사용자의 시점 에서 제2 거리만큼 더한 값에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정할 수 있다. 다만, 본 개시는 이에 제한되지 않는다. 일 실시예에서, 적어도 하나의 프로세서는 위치 결정 모듈의 명령어들 또는 프로그램 코드를 실행함으로써 제1 콘텐츠의 종류, 형상, 크기, 제2 콘텐츠의 종류, 형상, 크기, 디스플레이의 형상 또는 크기 중 적어도 하나에 기초하여 제2 콘텐츠가 제1 콘텐츠(30 0)와 중첩되어 표시되도록 제2 콘텐츠를 표시할 콘텐츠 위치를 결정할 수도 있다. 도 11a는 본 개시의 일 실시예에 따른, 제1 콘텐츠 및 제2 콘텐츠를 표시하는 동작을 설명하기 위한 도면이다. 도 11b는 본 개시의 일 실시예에 따른, 제1 콘텐츠 및 제2 콘텐츠를 표시하는 동작을 설명하기 위한 도면이다. 도 11c는 본 개시의 일 실시예에 따른, 제1 콘텐츠 및 제2 콘텐츠를 표시하는 동작을 설명하기 위한 도면이다. 이하, 도 1에서 설명한 구성과 동일한 구성에 대하여는 동일한 도면 부호를 부여하고, 중복되는 설명은 생략하 도록 한다. 도 1, 도 10a 및 도 11a를 참조하면, 일 실시예에서, 도 11a에는 헤드 마운티드 디스플레이 장치가 키보드 를 이용하여 타자를 치는 사용자의 포즈를 검출하고, 검출된 포즈에 기초하여 디스플레이(140, 도 3 참조)를 통하여 키보드를 표시하여 사용자에게 제공하는 것이 도시되어 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 디스플레이를 통하여 제1 콘텐츠, 키보드 외에도, 사용자가 키보드를 이용하여 입력하는 사용자 입력을 표시하는 제2 콘텐츠를 표 시할 수 있다. 일 실시예에서, 사용자는 키보드를 바라보지 않고, 제1 콘텐츠를 바라보며 사용 자 입력을 제공하더라도, 제1 콘텐츠와 인접하게 표시되는 제2 콘텐츠를 통하여 자신이 입력하는 사 용자 입력을 확인할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 사용자가 제1 콘텐츠를 바라보며 키보드를 이 용하여 타자를 치는 포즈를 취하더라도, 제2 카메라를 통하여 사용자의 포즈를 검출하고, 검출된 포 즈에 대응되는 인터페이스인 키보드를 디스플레이를 통하여 표시할 수 있다. 도 1, 도 10a, 도 11a 및 도 11b를 참조하면, 일 실시예에서, 도 11b에는 헤드 마운티드 디스플레이 장치 가 펜을 이용하여 그림을 그리는 사용자의 포즈를 검출하고, 검출된 포즈에 기초하여 디스플레이 를 통하여 그림 패드를 표시하여 사용자에게 제공하는 것이 도시되어 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 디스플레이를 통하여 제1 콘텐츠, 키보드 외에도, 사용자가 그림 패드를 이용하여 입력하는 사용자 입력을 표시하는 제2 콘텐츠를 표시할 수 있다. 일 실시예에서, 사용자는 그림 패드를 바라보지 않고, 제1 콘텐츠를 바라보며 사용자 입력을 제공하더라도, 제1 콘텐츠와 인접하게 표시되는 제2 콘텐츠를 통하여 자신이 입력하는 사용자 입력을 확인할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 사용자가 제1 콘텐츠를 바라보며 펜을 이용하 여 그림을 그리는 포즈를 취하더라도, 제2 카메라를 통하여 사용자의 포즈를 검출하고, 검출된 포즈 에 대응되는 인터페이스인 그림 패드를 디스플레이를 통하여 표시할 수 있다. 일 실시예에서, 도 11a와 비교하여, 헤드 마운티드 디스플레이 장치는 검출된 포즈에 대응되는 인터 페이스가 그림 패드로 판단된 경우, 디스플레이를 통하여 표시되던 키보드를 그림 패드로 변경하여 표시할 수 있다. 이를 통하여 사용자는 제1 콘텐츠를 이용하던 도중에 자신의 포즈를 미리설정된 복수의 포즈들 중 어느 하나의 포즈에 대응되도록 변경하여 헤드 마운티드 디스플레이 장치가 원하 는 인터페이스를 제공하도록 할 수 있다. 도 1, 도 10a, 도 11a 및 도 11c를 참조하면, 일 실시예에서, 도 11c에는 헤드 마운티드 디스플레이 장치 가 터치 패드를 이용하여 마우스 커서를 제어하는 사용자의 포즈를 검출하고, 검출된 포즈에 기초하 여 디스플레이를 통하여 터치 패드를 표시하여 사용자에게 제공하는 것이 도시되어 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 디스플레이를 통하여 제1 콘텐츠, 터치 패드 외에도, 사용자가 터치 패드를 이용하여 입력하는 사용자 입력을 표시하는 제2 콘텐츠를 표시할 수 있다. 일 실시예에서, 사용자는 터치 패드를 바라보지 않고, 제1 콘텐츠를 바라보며 사용자 입력을 제공하더라도, 제1 콘텐츠와 인접하게 표시되는 제2 콘텐츠를 통하여 자신이 입력하는 사용자 입력을 확인할 수 있다. 일 실시예에서, 제2 콘텐츠는 사용자가 터치 패드를 통하여 제 공하는 사용자 입력에 의하여 제어되는 마우스 커서일 수 있다. 일 실시예에서, 제2 콘텐츠는 제1 콘텐츠 에 중첩되어 표시될 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 사용자가 제1 콘텐츠를 바라보며 터치 패드를 이용하여 마우스 커서를 제어하는 포즈를 취하더라도, 제2 카메라를 통하여 사용자의 포즈를 검출하 고, 검출된 포즈에 대응되는 인터페이스인 터치 패드를 디스플레이를 통하여 표시할 수 있다. 일 실시예에서, 도 11a와 비교하여, 헤드 마운티드 디스플레이 장치는 검출된 포즈에 대응되는 인터 페이스가 터치 패드로 판단된 경우, 디스플레이를 통하여 표시되던 키보드를 터치 패드로 변경하여 표시할 수 있다. 이를 통하여 사용자는 제1 콘텐츠를 이용하던 도중에 자신의 포즈를 미리 설정된 복수의 포즈들 중 어느 하나의 포즈에 대응되도록 변경하여 헤드 마운티드 디스플레이 장치가 원하 는 인터페이스를 제공하도록 할 수 있다. 도 12는 본 개시의 일 실시예에 따른, 검출된 포즈와 미리 설정된 시작 포즈를 비교하여, 검출된 포즈와 미리 설정된 복수의 포즈들을 비교하는 동작의 수행 여부를 설명하기 위한 도면이다. 이하, 도 4에서 설명한 단계와 동일한 단계에 대하여는 동일한 도면 부호를 부여하고, 중복되는 설명은 생략하도록 한다. 도 1, 도 3, 도 4 및 도 12를 참조하면, 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 검 출된 포즈를 미리 설정된 시작 포즈와 비교하는 단계(S250)를 포함할 수 있다. 일 실시예에서, 검출된 포 즈를 미리 설정된 시작 포즈와 비교하는 단계(S250)의 동작은 사용자의 포즈를 검출하는 단계(S200)의 동 작 이후에 실행될 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 포즈 비교 모듈의 명령어들 또는 프로그램 코드를 실행함 으로써, 검출된 포즈와 미리 설정된 시작 포즈를 비교할 수 있다. 일 실시예에서, '시작 포즈'는 검출된 포즈와 미리 설정된 복수의 포즈들을 비교하고, 검출된 포즈에 대응되는 인터페이스를 디스플레이를 통하여 표시하는 헤드 마운티드 디스플레이 장치의 동작의 실행 여부를 판단하기 위하여 미리 설정된 포즈일 수 있다. 일 실시예에서, '시작 포즈'는 사용자가 인터페이스를 통하여 사용자 입력을 제공하기 위하여 취하는 포즈가 아 닌, 인터페이스를 이용하는 포즈와 무관한 포즈로 설정될 수 있다. 일 실시예에서, '시작 포즈'는 사용자 가 손을 마우스를 쥔 형태로 만들고 검지를 두 번 움직이는 포즈, 손가락으로 특정 형상을 취하는 포즈, 또는 손으로 코를 만지는 포즈 등을 포함할 수 있다. 일 실시예에서, 검출된 포즈를 미리 설정된 시작 포즈와 비교하는 단계(S250)에서, 검출된 포즈가 미 리 설정된 시작 포즈에 대응된다고 판단된 경우, 헤드 마운티드 디스플레이 장치의 동작 방법은 미리 설정 된 적어도 하나의 포즈와 검출된 포즈를 비교하는 단계(S300)의 동작을 실행할 수 있다. 일 실시예에서, 검출된 포즈를 미리 설정된 시작 포즈와 비교하는 단계(S250)에서, 검출된 포즈가 미 리 설정된 시작 포즈에 대응되지 않는다고 판단된 경우, 헤드 마운티드 디스플레이 장치의 동작 방법은 동 작을 종료할 수 있다. 이를 통하여, 헤드 마운티드 디스플레이 장치를 통하여 인터페이스를 제공받기를 원하는 경우, 사용자 는 시작 포즈에 대응되는 포즈를 취하고, 그 이후에 제공받기를 원하는 인터페이스에 대응되는 포즈를 취 함에 따라, 디스플레이를 통하여 인터페이스가 표시되도록 할 수 있다. 따라서, 사용자의 의도대로인터페이스를 제공하여 사용자의 편의성을 향상시킬 수 있다. 또한, 사용자가 헤드 마운티드 디스플레이 장치를 이용하던 도중에 무의식적으로 특정 인터페이스에 대응되는 포즈를 취하더라도, 사용자가 시작 포즈를 취하지 않았다면 디스플레이를 통하여 인터페이 스가 표시되지 않도록 하여, 사용자의 사용 경험을 의도하지 않게 방해하는 것을 방지할 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 본 개시로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다 상술한 기술적 과제를 해결하기 위하여, 일 실시예에서, 헤드 마운티드 디스플레이(Head mounted Display) 장치 를 제공한다. 헤드 마운티드 디스플레이 장치는 카메라를 포함할 수 있다. 헤드 마운티드 디스플레이 장치는 디 스플레이를 포함할 수 있다. 헤드 마운티드 디스플레이 장치는 적어도 하나의 명령어(instruction)를 저장하는 메모리 및 적어도 하나의 프로세서를 포함할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행 함으로써, 디스플레이를 통하여 제1 인터페이스를 표시할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명 령어를 실행함으로써, 카메라를 통하여 사용자를 촬영하여 이미지를 획득할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써, 획득된 이미지에 기초하여 사용자의 포즈(pose)를 검출할 수 있다. 적어 도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써, 복수의 인터페이스들에 각각 대응되도록 미리 설 정된 복수의 포즈들과 검출된 포즈를 비교할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행 함으로써, 검출된 포즈가 복수의 인터페이스들 중 하나인 제2 인터페이스에 대응됨에 따라, 디스플레이를 통하 여 제1 인터페이스를 대체하여 제2 인터페이스를 표시할 수 있다. 일 실시예에서 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 제1 인터페이스와 제2 인터페이 스를 비교할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 제1 인터페이스와 제2 인터페이스가 상이한 인터페이스로 판단됨에 따라, 디스플레이를 통하여 제1 인터페이스를 대체하여 제2 인터페 이스를 표시할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 검출된 포즈와 미리 설정된 복 수의 포즈들이 상이하거나, 혹은 제1 인터페이스와 제2 인터페이스가 동일한 인터페이스로 판단됨에 따라 디스 플레이를 통하여 표시되는 제1 인터페이스를 유지할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 디스플레이를 통하여 제1 콘텐 츠를 표시할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 제1 콘텐츠가 표시되는 동안 디스플레이를 통하여 제1 인터페이스 및 제2 인터페이스를 표시할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 카메라를 통하여 헤드 마운티 드 디스플레이 장치가 포함된 공간을 촬영하여 공간 이미지를 획득할 수 있다. 적어도 하나의 프로세서는 적어 도 하나의 명령어를 실행함으로써 획득된 공간 이미지에 기초하여 공간을 나타내는 공간맵을 생성할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 공간맵 및 검출된 포즈에 기초하여 제2 인터페 이스를 표시할 인터페이스 위치를 결정할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으 로써 디스플레이를 통하여 인터페이스 위치에 제2 인터페이스를 표시할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치는 사용자의 시선 방향을 추적하는 시선 추적 센서를 더 포함할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 시선 방향에 기초하여 사용자의 시점 을 획득할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 획득된 사용자의 시점 및 획득 된 이미지에 기초하여 사용자의 포즈를 검출할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 획득된 사용자의 시점에 기초 하여 제1 인터페이스 또는 제2 인터페이스 중 적어도 하나의 인터페이스를 통하여 획득되는 사용자 입력이 표시 되는 제2 콘텐츠를 표시할 콘텐츠 위치를 결정할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 디스플레이를 통하여 콘텐츠 위치에 제2 콘텐츠를 표시할 수 있다. 일 실시예에서, 제1 인터페이스는 검출된 포즈가 미리 설정된 복수의 포즈들 중 제1 인터페이스에 대응되도록 설정된 어느 하나의 포즈에 대응됨에 따라 디스플레이에 표시되는 인터페이스일 수 있다. 제1 인터페이스에 대 응되도록 설정된 어느 하나의 포즈와 제2 인터페이스에 대응되도록 설정된 어느 하나의 포즈는 서로 상이한 제 스처일 수 있다.일 실시예에서, 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 검출된 포즈와 미리 설정된 시 작 포즈를 비교할 수 있다. 적어도 하나의 프로세서는 적어도 하나의 명령어를 실행함으로써 검출된 포즈가 미 리 설정된 시작 포즈에 대응됨에 따라, 검출된 포즈와 미리 설정된 복수의 포즈들을 비교할 수 있다. 상술한 기술적 과제를 해결하기 위하여 본 개시의 일 실시예는 헤드 마운티드 디스플레이(Head mounted Display) 장치의 동작 방법을 제공한다. 헤드 마운티드 디스플레이 장치의 동작 방법은 카메라를 통하여 사용자 를 촬영하여 이미지를 획득하는 단계를 포함할 수 있다. 헤드 마운티드 디스플레이 장치의 동작 방법은 획득된 이미지에 기초하여 사용자의 포즈(pose)를 검출하는 단계를 포함할 수 있다. 헤드 마운티드 디스플레이 장치의 동작 방법은 복수의 인터페이스들 각각에 대응되도록 미리 설정된 복수의 포즈들과 검출된 포즈를 비교하는 단 계를 포함할 수 있다. 헤드 마운티드 디스플레이 장치의 동작 방법은 검출된 포즈가 복수의 인터페이스들 중 하 나인 제2 인터페이스에 대응됨에 따라, 디스플레이를 통하여 제1 인터페이스를 대체하여 제2 인터페이스를 표시 하는 단계를 포함할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 제1 인터페이스와 제2 인터페이스를 비교하는 단 계를 포함할 수 있다. 제1 인터페이스와 제2 인터페이스를 비교하는 단계에서 제1 인터페이스와 제2 인터페이스 가 상이한 인터페이스로 판단됨에 따라, 디스플레이를 통하여 제2 인터페이스를 표시하는 단계에서 디스플레이 를 통하여 제1 인터페이스를 대체하여 제2 인터페이스를 표시할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 미리 설정된 복수의 포즈들과 검출된 포즈를 비 교하는 단계에서, 미리 설정된 복수의 포즈들과 검출된 포즈가 상이하거나, 혹은 제1 인터페이스와 제2 인터페 이스를 비교하는 단계에서 제1 인터페이스와 제2 인터페이스가 서로 동일한 인터페이스로 판단됨에 따라 디스플 레이를 통하여 표시되는 제1 인터페이스를 유지하는 단계를 포함할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 디스플레이를 통하여 제1 콘텐츠를 표시하는 단 계를 포함할 수 있다. 헤드 마운티드 디스플레이 장치의 동작 방법은 제1 콘텐츠가 표시되는 동안 디스플레이를 통하여 제1 인터페이스 및 제2 인터페이스를 표시할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 카메라를 통하여 헤드 마운티드 디스플레이 장치 가 포함된 공간을 촬영하여 공간 이미지를 획득하는 단계를 포함할 수 있다. 헤드 마운티드 디스플레이 장치의 동작 방법은 획득된 공간 이미지에 기초하여 공간을 나타내는 공간맵을 생성하는 단계를 포함할 수 있다. 헤드 마운티드 디스플레이 장치의 동작 방법은 공간맵 및 검출된 포즈에 기초하여 제2 인터페이스를 표시할 인터페이 스 위치를 결정하는 단계를 포함할 수 있다. 헤드 마운티드 디스플레이 장치의 동작 방법은 디스플레이를 통하 여 제2 인터페이스를 표시하는 단계에서 인터페이스 위치에 제2 인터페이스를 표시할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 시선 추적 센서를 통하여 추적한 사용자의 시선 방향에 기초하여 사용자의 시점을 획득하는 단계를 포함할 수 있다. 사용자의 포즈를 검출하는 단계에서는 획득 된 사용자의 시점 및 획득된 이미지에 기초하여 사용자의 포즈를 검출할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 획득된 사용자의 시점에 기초하여 제1 인터페이 스 또는 제2 인터페이스 중 적어도 하나의 인터페이스를 통하여 획득되는 사용자의 입력이 표시되는 제2 콘텐츠 를 표시할 콘텐츠 위치를 결정하는 단계를 포함할 수 있다. 헤드 마운티드 디스플레이 장치의 동작 방법은 디스 플레이를 통하여 콘텐츠 위치에 제2 콘텐츠를 표시하는 단계를 포함할 수 있다. 일 실시예에서, 헤드 마운티드 디스플레이 장치의 동작 방법은 검출된 포즈와 미리 설정된 시작 포즈를 비교하 는 단계를 포함할 수 있다. 헤드 마운티드 디스플레이 장치의 동작 방법은 검출된 포즈가 미리 설정된 시작 포 즈에 대응됨에 따라, 검출된 포즈와 미리 설정된 복수의 포즈들을 비교할 수 있다. 상술한 기술적 과제를 해결하기 위하여, 일 실시예에서 개시된 헤드 마운티드 디스플레이 장치의 동작 방법의 실시예 중 적어도 하나의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매 체를 제공할 수 있다. 본 개시에서 설명된 헤드 마운티드 디스플레이 장치에 의해 실행되는 프로그램은 하드웨어 구성요소, 소프트웨 어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 프로그램은 컴퓨 터로 읽을 수 있는 명령어들을 수행할 수 있는 모든 시스템에 의해 수행될 수 있다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령어(instruction), 또는 이들 중 하나 이상 의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처리 장치를 명령할 수 있다. 소프트웨어는, 컴퓨터로 읽을 수 있는 저장 매체(computer-readable storage media)에 저장된 명령어를 포함하 는 컴퓨터 프로그램으로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록 매체로는, 예를 들어 마그네틱 저장 매체 (예컨대, ROM(read-only memory), RAM(random-access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판 독 매체(예컨대, 시디롬(CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등이 있다. 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템들에 분산되어, 분산 방식으로 컴퓨터가 판독 가능한 코드가 저장 되고 실행될 수 있다. 기록 매체는 컴퓨터에 의해 판독 가능하며, 메모리에 저장되고, 프로세서에서 실행될 수 있다. 컴퓨터로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구 분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 또한, 본 명세서에 개시된 실시예들에 따른 프로그램은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 소프트웨어 프로그램, 소프트웨어 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체 를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 헤드 마운티드 디스플레이 장치의 제조사 또는 전 자 마켓(예를 들어, 삼성 갤럭시 스토어)을 통해 전자적으로 배포되는 소프트웨어 프로그램 형태의 상품(예를 들어, 다운로드 가능한 애플리케이션(downloadable application))을 포함할 수 있다. 전자적 배포를 위하여, 소 프트웨어 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저장 매체 는 헤드 마운티드 디스플레이 장치의 제조사의 서버, 전자 마켓의 서버, 또는 소프트웨어 프로그램을 임시 적으로 저장하는 중계 서버의 저장 매체가 될 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10a 도면10b 도면11a 도면11b 도면11c 도면12"}
{"patent_id": "10-2023-0105667", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시는, 다음의 자세한 설명과 그에 수반되는 도면들의 결합으로 쉽게 이해될 수 있으며, 참조 번호 (reference numerals)들은 구조적 구성요소(structural elements)를 의미한다.도 1은 본 개시의 일 실시예에 따른 헤드 마운티드 디스플레이(Head mounted Display) 장치를 설명하기 위한 도 면이다. 도 2는 본 개시의 일 실시예에 따른 헤드 마운티드 디스플레이(Head mounted Display) 장치의 구성을 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시예에 따른 헤드 마운티드 디스플레이(Head mounted Display) 장치의 구성을 설명하기 위한 블록도이다. 도 4는 본 개시의 일 실시예에 따른 헤드 마운티드 디스플레이(Head mounted Display) 장치의 동작 방법을 설명 하기 위한 순서도이다. 도 5는 본 개시의 일 실시예에 따른, 제1 콘텐츠가 표시되는 동안 제1 인터페이스 및 제2 인터페이스를 표시하 는 동작을 설명하기 위한 순서도이다. 도 6은 본 개시의 일 실시예에 따른, 검출된 사용자의 포즈에 대응되는 인터페이스를 표시하는 동작을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른, 카메라를 통하여 생성된 공간맵과 검출된 포즈에 기초하여 인터페이스 위 치를 결정하는 동작을 설명하기 위한 순서도이다. 도 8은 본 개시의 일 실시예에 따른, 시선 추적 센서를 통하여 사용자의 시점을 획득하고, 획득된 시점 및 획득 된 이미지에 기초하여 사용자의 포즈를 검출하는 동작을 설명하기 위한 순서도이다. 도 9는 본 개시의 일 실시예에 따른, 시선 추적 센서를 통하여 획득된 사용자의 시점에 기초하여 제2 콘텐츠를 표시할 콘텐츠 위치를 결정하는 동작을 설명하기 위한 순서도이다. 도 10a는 본 개시의 일 실시예에 따른, 시선 추적 센서를 통하여 획득된 사용자의 시점에 기초하여 제2 콘텐츠 를 표시할 콘텐츠 위치를 결정하는 동작을 설명하기 위한 도면이다. 도 10b는 본 개시의 일 실시예에 따른, 시선 추적 센서를 통하여 획득된 사용자의 시점에 기초하여 제2 콘텐츠 를 표시할 콘텐츠 위치를 결정하는 동작을 설명하기 위한 도면이다. 도 11a는 본 개시의 일 실시예에 따른, 제1 콘텐츠 및 제2 콘텐츠를 표시하는 동작을 설명하기 위한 도면이다. 도 11b는 본 개시의 일 실시예에 따른, 제1 콘텐츠 및 제2 콘텐츠를 표시하는 동작을 설명하기 위한 도면이다. 도 11c는 본 개시의 일 실시예에 따른, 제1 콘텐츠 및 제2 콘텐츠를 표시하는 동작을 설명하기 위한 도면이다. 도 12는 본 개시의 일 실시예에 따른, 검출된 포즈와 미리 설정된 시작 제스쳐를 비교하여, 검출된 포즈와 미리 설정된 복수의 포즈들을 비교하는 동작의 수행 여부를 설명하기 위한 도면이다."}
