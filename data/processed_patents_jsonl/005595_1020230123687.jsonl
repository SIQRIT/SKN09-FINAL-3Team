{"patent_id": "10-2023-0123687", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0041234", "출원번호": "10-2023-0123687", "발명의 명칭": "인공지능 네트워크 기반 호흡이상음 식별 장치 및 그것의 제어 방법", "출원인": "주식회사 닥터스바이오텍", "발명자": "정성관"}}
{"patent_id": "10-2023-0123687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "청진음에 기초하여 호흡이상음을 식별하는 장치에 있어서,청진음을 소정 시간 간격으로 분할하는 분할부;상기 분할된 청진음을 스펙트로그램(Spectrogram)으로 변환시키는 변환부; 및상기 변환된 스펙트로그램을 입력 받아 호흡이상음을 식별하는 인공지능 모델을 포함하는 것을 특징으로 하는,호흡이상음 식별 장치."}
{"patent_id": "10-2023-0123687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 인공지능 모델은,CNN(Convolutional Neural Network) 구조를 포함하는 것을 특징으로 하는,호흡이상음 식별 장치."}
{"patent_id": "10-2023-0123687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 인공지능 모델은,상기 CNN 구조와 함께 LSTM(Long Short-Term Memory)을 함께 포함하는 것을 특징으로 하는,호흡이상음 식별 장치."}
{"patent_id": "10-2023-0123687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 인공지능 모델은,레벨 별 특징을 추출하기 위한 복수 개의 레이어 및상기 복수 개의 레이어에서 추출된 레벨 별 특징으로부터 입력된 호흡이 정상인지 비정상인지 분류하는 분류부를 포함하는 것을 특징으로 하는,호흡이상음 식별 장치."}
{"patent_id": "10-2023-0123687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 분류부는,상기 복수 개의 레이어에서 추출된 레벨 별 특징에 대해서 다단계 기능 융합을 적용하여 상기 분류를 수행하는,호흡이상음 식별 장치."}
{"patent_id": "10-2023-0123687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 인공지능 모델은,공개특허 10-2025-0041234-3-상기 복수 개의 레이어에서 추출된 특징의 차원을 축소시키기 위한 적어도 하나의 차원 변환부를 포함하는,호흡이상음 식별 장치."}
{"patent_id": "10-2023-0123687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 상기 인공지능 모델은,차원이 축소된 특징들에 기초하여 가중치를 산출하기 위한 GAP 부를 더 포함하는,호흡이상음 식별 장치."}
{"patent_id": "10-2023-0123687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 인공지능 모델은,상기 복수 개의 레이어에서 추출된 특징에 상기 산출된 가중치를 적용하기 위한 가중치 적용부를 더 포함하는,호흡이상음 식별 장치."}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 호흡 데이터에 기초하여 정상 호흡인지 비정상 호흡인지 구분하기 위한 기술에 관한 것이다. 보다 구 체적으로 본 발명은, 청진음에 기초하여 호흡이상음을 식별하는 장치에 있어서, 청진음을 소정 시간 간격으로 분 할하고, 상기 분할된 청진음을 스펙트로그램(Spectrogram)으로 변환시키며, 및 상기 변환된 스펙트로그램을 입력 받아 호흡이상음을 식별하는 비정상 호흡을 식별하는 기술에 관한 것이다."}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 호흡이상음을 식별하기 위한 기술에 관한 것으로, 보다 구체적으로는 환자의 신체로부터 녹음한 오디 오 데이터로부터 환자 호흡의 이상음을 식별해내기 위한 인공지능 모델에 관한 것이다."}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "디지털 청진기를 이용하여 심장 및 폐 질환을 조기에 발견하기 위해 호흡음 분류가 광범위하게 연구되어 왔다. 정상적이지 않은 호흡음의 대표적인 예시로는, 천명과 수포음이 있다. 천명(喘鳴)은 우리말 의학용어로 쌕쌕거림이라고 하고 영어로는 wheezing(위징)이라고 한다. 좁아진 기도를 통 해 공기가 빠져나가면서 호흡할 때마다 거칠고 휘파람 같은 쌕쌕거리는 소리가 계속 나는 것이다. 들숨과 날숨 에서 모두 나지만 들숨에서 더 확실하게 들을 수 있다는 특징이 있다. 이는 기도의 경련이나 부종, 분비물, 종 양 때문에 기도가 좁아지고 공기의 흐름이 빨라진 것이 원인이다. 수포음(水泡音)은 우리말 의학용어로 거품소리라고 하고 영어로는 crackle(크래클)이라 한다. 체액이나 분비물 때문에 닫혀 있던 폐포가 숨을 들이마실 때 열리면서 나는 소리이며, 지속적인 천명과 다르게 비연속적이며 청 진기로만 들을 수 있다. 폐렴(pneumonia), 급성기관지염(acute bronchitis), 좌심부전으로 인한 폐부종 (pulmonary edema)이 원인이 될 수 있다. 현재 소아에 대하여 이러한 비정상 호흡음을 확인하는 것은, 많은 노력과 시간이 필요하다. 소아에게 증상이 이 미 발생한 경우 내원하여 의사로부터 직접 진단을 받아야 하기 때문이다. 또한, 낯선 환경에서 소아는 긴장할 수밖에 없게 되어, 의사가 손쉽게 청진할 수 없는 것도 하나의 이유이다. 이에 따라, 좀 더 가벼운 구조를 가지고 있어 가정에서도 휴대 전자기기로 손쉽게 비정상 호흡음을 판단하면서 도, 높은 정확도를 가질 수 있는 딥러닝 모델에 대한 연구가 연구되는 실정이다."}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 스마트폰 등 휴대 전자기기에서도 손쉽게 활용 가능하도록 가벼운 형태로 구 비되는 비정상 호흡음을 식별하는 인공지능 모델을 제공하는 것이다. 본 발명이 해결하고자 하는 다른 과제는 최종 레이어의 출력뿐만 아니라 복수 개의 레이어 각각의 출력들을 모 두 고려하여 정확도를 높일 수 있는 비정상 호흡음을 식별하는 인공지능 모델을 제공하는 것이다. 본 발명에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 또는 다른 과제를 해결하기 위해 본 발명의 일 측면에 따르면, 청진음에 기초하여 호흡이상음을 식별하는 장치에 있어서, 청진음을 소정 시간 간격으로 분할하는 분할부; 상기 분할된 청진음을 스펙트로그램 (Spectrogram)으로 변환시키는 변환부; 및 상기 변환된 스펙트로그램을 입력 받아 호흡이상음을 식별하는 인공 지능 모델을 포함하는 것을 특징으로 하는, 호흡이상음 식별 장치 를 제공한다. 상기 인공지능 모델은, CNN(Convolutional Neural Network) 구조를 포함할 수 있다. 상기 인공지능 모델은, 상기 CNN 구조와 함께 LSTM(Long Short-Term Memory)을 함께 포함할 수 있다. 상기 인공지능 모델은, 레벨 별 특징을 추출하기 위한 복수 개의 레이어 및 상기 복수 개의 레이어에서 추출된 레벨 별 특징으로부터 입력된 호흡이 정상인지 비정상인지 분류하는 분류부를 포함할 수 있다. 상기 분류부는, 상기 복수 개의 레이어에서 추출된 레벨 별 특징에 대해서 다단계 기능 융합을 적용하여 상기 분류를 수행할 수 있다. 상기 인공지능 모델은, 상기 복수 개의 레이어에서 추출된 특징의 차원을 축소시키기 위한 적어도 하나의 차원 변환부를 포함할 수 있다. 상기 인공지능 모델은, 차원이 축소된 특징들에 기초하여 가중치를 산출하기 위한 GAP 부를 더 포함할 수 있다. 상기 인공지능 모델은, 상기 복수 개의 레이어에서 추출된 특징에 상기 산출된 가중치를 적용하기 위한 가중치 적용부를 더 포함할 수 있다."}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 호흡이상음 식별 기술의 효과에 대해 설명하면 다음과 같다. 본 발명의 실시 예들 중 적어도 하나에 의하면, 스마트폰 등 휴대 전자기기에서도 손쉽게 활용 가능하도록 가벼 운 형태로 구비되는 비정상 호흡음을 식별할 수 있다는 장점이 있다. 또한, 본 발명의 실시 예들 중 적어도 하나에 의하면, 최종 레이어의 출력뿐만 아니라 복수 개의 레이어 각각의 출력들을 모두 고려하여 정확도를 높일 수 있는 비정상 호흡음을 식별하는 인공지능 모델을 제공할 수 있다는 장점이 있다. 본 발명의 적용 가능성의 추가적인 범위는 이하의 상세한 설명으로부터 명백해질 것이다. 그러나 본 발명의 사 상 및 범위 내에서 다양한 변경 및 수정은 당업자에게 명확하게 이해될 수 있으므로, 상세한 설명 및 본 발명의 바람직한 실시 예와 같은 특정 실시 예는 단지 예시로 주어진 것으로 이해되어야 한다."}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 발명의 일실시예에 따른 호흡이상음 식별 장치의 블록도를 도시한다. 본 발명의 일실시예에 따른 호흡이상음 식별 장치는 분할부, 변환부 및 인공지능 모델을 포함하도록 구성될 수 있다. 도 1에 도시된 구성요소들은 호흡이상음 식별 장치를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세 서 상에서 설명되는 호흡이상음 식별 장치는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소 들을 가질 수 있다. 분할부는, 분석 대상이 되는 청진음을 소정 시간 간격으로 분할하여 변환부로 제공한다. 변환부는 분할된 청진음을 스펙트로그램(Spectrogram)으로 변환시킨다. 변환부는 청진음(호흡 소리 데이터)을 딥 러닝 모델의 입력으로 사용하기 위해 먼저 스펙트로그램 이미지로 변환시킨다. 변환부는 주 파수 및 진폭 정보를 추출하기 위해 신호 시퀀스를 따라 고속 푸리에 변환(FFT)을 적용하여 스펙트로그램을 얻 을 수 있다. 시간 주파수 기반 정보로 소리를 시각적으로 표현한다. 인공지능 모델은 변환된 스펙트로그램에 기초하여 호흡이상음을 식별한다. 상기 변환된 스펙트로그램이 입 력되면, 인공지능 모델은 정상 호흡음과 비정상 호흡음으로 분류한다. 본 발명의 일실시예에 따른 인공지능 모델은 CNN 기반 아키텍처에 다단계 특징 추출 메커니즘과 \"셀프 어 텐션(self-attention)\"을 구현하여 딥러닝 모델을 제안한다. 이러한 딥러닝 모델의 구조에 대해서 이하 도 2를 참고하여 구체적으로 살펴본다. 도 2는 본 발명의 제1 실시예에 따른 인공지능 모델의 개념도를 도시하는 도면이다. 본 발명의 제1 실시예에 따른 인공지능 모델은 복수 개의 레이어(202-1 ~ 202-4) 및 분류부을 포함하 도록 구성될 수 있다. 도 2에 도시된 구성요소들은 인공지능 모델을 구현하는데 있어서 필수적인 것은 아 니어서, 본 명세서 상에서 설명되는 인공지능 모델은 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 스펙트로그램은 소리나 파동을 시각화하여 파악하기 위한 도구로, 파형(waveform)과 스펙트럼(spectrum)의 특징이 조합되어 있다. 파형에서는 시간축의 변화에 따른 진폭 축의 변화를 볼 수 있고, 스펙트럼에서는 주파수 축의 변화에 따른 진폭 축의 변화를 볼 수 있는 반면, 스펙트로그램에서는 시간축과 주파수 축의 변화에 따라 진폭의 차이를 인쇄 농도 /표시 색상의 차이로 나타낸다. 멜스펙트로그램은 스펙트로그램에 멜 필터(mel-filter)라는 필터를 적용한 결과이다. 도 2에 도시된 예시에서는 멜스펙트로그램을 들고 있지만, 반드시 이에 한정되는 것은 아니다. 복수 개의 레이어(202-1 ~ 202-4)는 스펙트로그램을 입력으로 받아 (레이어별)레벨별 특징을 제공한다. 복수 개의 레이어(202-1 ~ 202-4)는 복수 개의 셀프 어텐션 적용부(210-1 ~ 210-4), 복수 개의 차원 변환부 (204-1 ~ 204-3), GAP 부 및 복수 개의 가중치 적용부(205-1 ~ 205-4)를 포함한다. 복수 개의 셀프 어텐션 적용부(210-1 ~ 210-4)는 본 발명의 제1 실시예에 따른 conv-attn 연산(이하 수학식 1의 연산)을 수행한다. 복수 개의 레이어(202-1 ~ 202-4) 각각(마지막 레이어 제외)에 구비되는 복수 개의 차원 변환부(204-1 ~ 204- 3)는, 추출된 특징의 차원을 축소하여 마지막 레이어에서 추출된 특징과 '차원을 일치'시킨다. GAP 부는 복수 개의 레이어(202-1 ~ 202-4) 각각에서 추출되고 차원이 축소된 특징들을 합산하고 글로벌 평균 풀링(GAP)을 적용시킨다. 복수 개의 가중치 적용부(205-1 ~ 205-4)는 GAP 부의 출력인 가중치를 각 레이어에 적용시킨다. 이하 구체적으로 도면을 함께 참조하여 설명한다. 셀프 어텐션은 더 나은 특징 표현을 추출하기 위해 딥 러닝 모델에서 널리 사용된다. 이하에서 설명되는 본 발 명의 제1 실시예에서는 \"self-attention\" 개념과 컨볼루션 신경망을 통합했다. 셀프 어텐션은 CNN의 표준 컨벌루션 필터 작업을 대체하며, 이렇게 대체된 것을 이하 본 발명의 설명 및 도면에 서는 \"conv-attn\"이라고 부른다. 원래 컨벌루션 필터는 포인트별 곱셈(point-wise multiplicatio) 및 이에 이어지는 덧셈을 수행하여 이미지 특 징(image feature)에 적용된다. 이미지 특징은 컨벌루션 필터에 입력되는 입력 feature를 의미한다. 본 발명의 제1 실시예에 따른 \"conv-attn\"에서 이 포인트별 연산(point-wise operation)은 어텐션 연산의 키와 값이 이미 지 특징의 동일한 윈도우이고 쿼리가 현재 윈도우의 중심인 셀프 어텐션으로 대체된다. \"conv-attn\" 작업은 먼저 전체 이미지 특징에 각 가장자리에 너비가 3인 제로 패드(zero pad)를 추가하여 수행 된다. 그 후, 단일 보폭(single stride)의 7x7 어텐션 윈도우가 이미지 특징에 적용되어 각 특징 값이 다른 관 심 영역(attended region)의 쿼리가 된다. 를 영역의 중심으로 하는 관심 이미지 특징(attended imagefeature)(a,b)에 대한 conv-attn 연산의 출력은 이며 아래 수학식 1의 공식으로 얻을 수 있다. 수학식 1"}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 쿼리 qij = Wqxij, 키(key) kab = Wkxab 그리고 값(value) vab = Wvxab은 관심 이미지 특징 (a,b)의 선형 변 환(linear transformation)이다. 도 2를 참고하면, 복수 개의 레이어(202-1 ~ 202-4)는 연속되도록 배치되어, 스펙트로그램을 입력으로 받 는다. 복수 개의 레이어(202-1 ~ 202-4) 각각은 32 출력 채널로 구성되며, 2x2 맥스 풀링 레이어(max pooling layer)가 뒤따른다. 다만, 본 발명이 이러한 출력의 개수나 맥스 풀링 레이어의 사이즈에 한정되는 것은 아니다. 복수 개의 레이어(202-1 ~ 202-4) 각각에서 추출되는 특징은 레벨별 특징(level-specific features, 211-1 ~ 211-4)일 것이다. 본 발명의 제1 실시예에서는 이러한 특징들을 사용하여 다단계 기능 융합(Multilevel Feature Fusion)을 하도록 제안한다. 복수 개의 레이어(202-1 ~ 202-4)로부터 추출되는 레벨별 특징(211-1 ~ 211-4)은 서로 차원이 다르다. 그렇기 때문에, 초기 세 개(1st ~ (n-1)th)의 레이어(202-1 ~ 202-3)에서 추출된 특징(211-1 ~ 211-3)은 마지막(n-th) 레이어(202-4)에서 추출된 특징(211-4)의 차원과 일치하도록 축소될 수 있다. 즉, 복수 개의 레이어(202-1 ~ 202-4) 각각(마지막 레이어 제외)은, 추출된 특징의 차원을 축소하여 마지막 레 이어에서 추출된 특징과 '차원이 일치'될 수 있도록하는, 복수 개의 차원 변환부(204-1 ~ 204-3)를 포함할 수 있다. 복수 개의 차원 변환부(204-1 ~ 204-3)는 Adaptive pooling을 사용하여 초기 세 개의 레이어(202-1 ~ 202-3)에 서 추출된 특징은 네 번째 수준 기능과 동일한 차원으로 변환된다. 차원 변환(크기 조정) 후 이러한 3D 기능은 포인트 방식으로 함께 합산되고 글로벌 평균 풀링(GAP)이 적용되는 것이다. GAP의 출력이 각 채널(각 레이어)의 가중치가 된다. 그런 다음 가중치 적용부(205-1 ~ 205-4)가 가중치에 각 레이어의 특징들이 곱하여 가중치를 적용 시킨다. 재가중된(re-weighted) 레이어별 특징(이하, 재가중 특징 212-1 ~ 212-4)은 분류부로 제공된다. 분류부는 합산부, 플래튼(Flatten)층, 완전 연결 계층, 소프트맥스 레이어를 포함하 도록 구성될 수 있다. 합산부는 가중치 적용부(205-1 ~ 205-4)에 의해서 가중치가 적용된 재가중 특징들을 다시 합산시킨다. 이 때, 각 채널 별 합산(element-wise addition)이 수행될 수 있음은 자명하다. 플래튼(Flatten)층은 합산된 결과에 평탄화(Flatten) 작업을 수행한다. 평탄화 작업이란, 다차원의 벡터를 1차원으로 변환시키는 것을 의미한다. 합산부에 의해서 합산된 특징들을 이진 분류를 위해 완전히 연결된 계층에 공급되도록 평탄화시킨다. 완전 연결 계층은 복수 개의 레이어 형태로 구성되는 뉴런의 집합으로, 한 층의 모든 뉴런이 다음 층의 모 든 뉴런과 연결된 형태의 계층이다.소프트맥스 레이어는, 소프트맥스 함수를 적용하여 최종 호흡이 이상한지 여부를 최종 판별한다. 이하 상술한 실시예에 대한 실험 결과를 설명한다. 도 3은 본 발명의 제1 실시예에 따른 호흡이상음 식별을 위한 인공지능 모델을 평가하기 위한 ICBHI 데이터 세 트의 통계를 도시한다. 도 4는 평가에 사용되는 ICBHI 데이터 세트의 통계를 도시한다. 도 5는 입력 표현 간의 실험 결과를 비교하는 도면이다. 제안한 모델의 성능을 평가하기 위해 ICBHI 챌린지 공개 데이터 세트를 사용하여 모델을 훈련하고 테스트했다. 공식 80:20 훈련 및 테스트 분할에 이어 정상 및 비정상 호흡음의 이진 분류를 수행했다. 데이터 세트의 통계는 도 3의 Table 1에서 볼 수 있다. 도 4의 Table 2를 참고하면, 세 가지 평가 메트릭인 민감도, 특이성 및 전체 성능 점수를 사용하여 모델을 평가했다. 민감도는 올바르게 분류된 비정상 샘플과 총 비정상 샘플 수의 비율이 고 특이도는 올바르게 분류된 정상 샘플과 전체 정상 샘플 간의 비율이다. 최종 점수는 두 메트릭의 평균이다. 본 발명의 제1 실시예에 따른 모델은 \"proposed\" 항목으로 기재하였다. 딥 러닝 기술을 사용한 사운드 분류에서 신호 시퀀스는 딥 뉴럴 네트워크에 입력되기 전에 도 1의 변환부 에 의해서 먼저 스펙트로그램 이미지로 변환된다. 단시간 푸리에 변환(STFT), Mel-Spectrogram 및 Mel- Frequency Cepstral Coefficient(MFCC)는 신경망 입력에 널리 사용되는 변환이다. 제안한 방법에 적합한 입력 표현을 선택하기 위해 세 가지 다른 사운드 표현으로 실험을 수행했다. 도 5에 도시 된 Table 3의 결과는 Mel-Spectrogram이 우리가 제안한 아키텍처에 가장 적합한 입력 표현임을 보여준다. 다른 두 입력 표현은 Mel-Spectrogram, 특히 MFCC 기능 표현에 비해 좋지 않은 결과를 보여준다. MFCC는 음소 정보만 을 보존하기 위해 오디오 스펙트로그램에서 피치 정보를 제거한 후 얻은 특징으로 음성 인식에 널리 사용된다. 그러나 호흡음에는 이러한 정보가 포함되어 있지 않으므로 MFCC 기능이 분류 모델에 도움이 되지 않는다. 다시 도 4로 복귀하여, 제안한 모델의 효과를 알아보기 위해 다단계 특징 융합 개념과 self-attention 기반 CNN 을 제거하여 ablation 연구를 수행한 후 분류 성능에 미치는 영향을 관찰하였다. Table 2에서 볼 수 있듯이 다 단계 기능 추출을 제거(w/o multilevel feature function)하거나 conv-attn을 표준 CNN으로 교체하면 특히 self-attention이 적용되지 않을 때(w/o attention) 성능이 저하된다. 이것은 self-attention이 분류 성능을 향상시키는 데 중요한 역할을 한다는 것을 보여준다. self-attention이 없는 제안 모델은 다단계 특징 추출이 있는 심층 CNN 모델만 있다. 이 기능 추출 메커니즘을 심층 CNN 모델에 통합해도 모델의 성능이 향상되지 않는 것으로 보인다. 그러나 self-attention 기반 CNN과 결 합하면 전체 성능이 2.7% 향상되었다. 또한 제안된 모델을 시퀀스 기반 네트워크와 같이 널리 사용되는 다른 심 층 신경망과 비교했다. 우리가 제안한 방법은 CNN-LSTM 구조에 비해 더 나은 결과를 보여준다. 도 6은 본 발명의 제1 실시예와 \"RespireNet\"의 비교 결과를 도시한다. 본 발명의 제1 실시예에 따른 모델(도 6의 propose)을 프레임워크를 사용하여 동일한 개방형 데이터 세트에서 모델을 교육하는 최첨단 모델 RespireNet과 비교했다. RespireNet은 사전 학습된 Resnet을 기반으로 미세 조정 된 모델이다. RespireNet과 제안된 모델은 공식 80:20 교육-테스트 분할에 따라 이진 분류 작업에 대해 평가되 었다. 임의성 요소를 제거하기 위해 실행 시간에 증강 모듈이 폐기된다. 우리가 제안한 방법은 RespireNet과 비교하여 경쟁력 있는 결과를 보여준다. 그것은 제안된 방법이 이 작업에서 매우 중요한 비정상적인 호흡음을 인식하는 데 더 효과적이라는 것을 의미하는 더 높은 민감도 점수를 보여준다.본 발명의 제1 실시예에서 제안하는 모델에는 338K 매개변수가 있으며 21M 매개변수가 있는 RespireNet에 비해 모델 크기가 상대적으로 매우 작다. 훈련 가능한 매개변수의 수가 90% 감소함에 따라 제안된 방법은 전체 성능 점수에서도 RespireNet을 능가한 것을 확인할 수 있다. 결과로 저장되는 모델의 크기도 모델 크기가 81.6MB인 RespireNet에 비해 크기가 1.3MB로 더 작다. 모델 크기가 작을수록 자동 호흡음 분류를 위한 IoT 애플리케이션, 특히 모바일 애플리케이션을 구현하는 데 유리할 수 있다. 상술한 본 발명의 제1 실시예에서는 CNN을 기반으로 self-attention 메커니즘과 다단계 특징 추출을 통합하여 호흡음 분류 성능을 향상시키기 위한 가벼운 딥러닝 모델을 제안하였다. ICBHI 개방형 데이터 세트에 대한 실험은 제안한 방법이 최첨단 RespireNet에 비해 작은 모델 크기로 전반적인 성능이 향상되어 IoT 응용 프로그램에 더 적합하다는 것을 확인했다. 제안된 본 발명의 제1 실시예에 따른 방법 은 또한 호흡기 질환의 조기 진단에 중요한 척도인 비정상 샘플을 인식하는 데 더 나은 감도를 보여준다는 것을 알 수 있다. 이하에서는, 본 발명의 다른 제2 실시예에 대해서 설명한다. 본 발명의 제2 실시예에서는 공간적 특징(spatial features)과 시간적 특징(temporal features)을 모두 학습하 기 위해 다중 수준 특징 추출(multilevel feature extraction)을 사용하는 CNN-LSTM 기반 딥 러닝 모델을 제안 한다. 도 7은 본 발명의 제2 실시예에 따른 인공지능 모델의 개념도를 도시하는 도면이다. 도 7에서 볼 수 있듯이 다단계 특징 추출 아키텍처(multilevel feature extraction architecture)를 사용한다. 3D-CNN 대신 2D-CNN을 사용하여 입력 표현을 일치시킨다. CNN의 공간적 속성과 LSTM 네트워크의 시간적 속성을 활용하여 다단계 특징 추출 아키텍처를 구성하고 추출된 특징을 Softmax 레이어에 공급하여 호흡음을 정상 및 비정상으로 분류시킨다. 이를 위하여 본 발명의 제2 실시예에 따른 인공지능 모델은 복수 개의 레이어(202-1 ~ 202-4) 및 분류부 을 포함하도록 구성될 수 있다. 도 7에 도시된 구성요소들은 인공지능 모델을 구현하는데 있어서 필 수적인 것은 아니어서, 본 명세서 상에서 설명되는 인공지능 모델은 위에서 열거된 구성요소들 보다 많거 나, 또는 적은 구성요소들을 가질 수 있다. 스펙트로그램은 소리나 파동을 시각화하여 파악하기 위한 도구로, 파형(waveform)과 스펙트럼(spectrum)의 특징이 조합되어 있다. 파형에서는 시간축의 변화에 따른 진폭 축의 변화를 볼 수 있고, 스펙트럼에서는 주파수 축의 변화에 따른 진폭 축의 변화를 볼 수 있는 반면, 스펙트로그램에서는 시간축과 주파수 축의 변화에 따라 진폭의 차이를 인쇄 농도 /표시 색상의 차이로 나타낸다. 멜스펙트로그램은 스펙트로그램에 멜 필터(mel-filter)라는 필터를 적용한 결과이다. 도 7에 도시된 예시에서는 스펙트로그램을 들고 있지만, 반드시 이에 한정되는 것은 아니다. 복수 개의 레이어(202-1 ~ 202-4)는 스펙트로그램을 입력으로 받아 (레이어별)레벨별 특징을 제공한다. 복수 개의 레이어(202-1 ~ 202-4) 각각은, CNN 모델(710-1 ~ 710-4) 및 LSTM 모델(711-1 ~ 711-4)을 포함하도 록 구성된다. 먼저 도 1에서 상술한 분할부 및 변환부에서는 소정 시간 간격에 대한 복수 개의 스펙트로그램 을 인공지능 모델에 입력한다. 도시된 도면에서는 3개의 스펙트로그램이 입력되는 것으로 도시하였지 만, 이러한 개수에 한정되는 것은 아니다. 복수 개의 레이어(202-1 ~ 202-4) 각각에 구비된 CNN 모델(710-1 ~ 710-4)은 입력된 복수 개의 스펙트로그램 각각에 대해서 2차원 CNN(합성곱 신경망, Convolutional Neural Networks)을 적용한다. 복수 개의 레이 어(202-1 ~ 202-4) 각각에 맥스 풀링 레이어가 구비되고, CNN 적용 결과에 맥스 풀링 레이어가 추가적으로 적용 될 수 있다. 더 나아가, 복수 개의 레이어(202-1 ~ 202-4) 각각에 구비되는 LSTM 모델(711-1 ~ 711-4)은 2차원 CNN이 적용 된 복수 개의 스펙트로그램에 대해서 LSTM(Long Short Term Memory)을 적용시킨다. 그리고 최종 분류 계층 이전에 4개의 다른 추출 수준의 다중 수준 기능은 각 수준 기능의 중요도를 모델링하기 위해 Softmax 활성화 기능이 있는 프로젝션 계층에서 얻은 가중치를 사용하여 재가중된다. 분류를 위한 마지막 특성은 다단계 특성의 가중 합이다. 이를 위하여, 복수 개의 레이어(202-1 ~ 202-4) 각각에서 LSTM이 적용된 결과(712-1 ~ 712-4)를 수신한 분류부 는, 결과(712-1 ~ 712-4)에 'concatenation'을 적용시켜 하나의 특징 벡터로 합친다. 분류부의 가중치 산출부는, 특징 벡터에 'fc-softmax'를 적용하여 가중치를 산출한다. 그 리고 분류부는 산출된 가중치를 특징 벡터에 적용하여 가중치 반영 특징 벡터를 생성하여 최종 정상/비정상 호흡을 분류시킨다. 이와 같은 분류 시, 상술한 완전 연결 계층 및 소프트맥스 레이어 가 적용될 수 있음은 자명할 것이다. 이하에서는, 본 발명의 제2 실시예에 대한 실험 결과를 설명한다. 도 8 및 도 9는 평가를 위한 데이터 세트의 통계를 도시한다. 실험에 사용한 데이터셋은 대한민국 서울 구로구에 소재한 \"우리아이들병원\" 의료진이 수집한 것이다. 데이터 세트의 각 호흡음은 정상 또는 비정상으로 레이블이 지정된다. 데이터 세트의 통계는 도 8의 Table 1에서 볼 수 있다. 각 소리 데이터에는 평균 길이가 2.5초인 하나의 호흡 주기가 포함되어 있다. 이 데이터 세트에서 분류기의 성능을 평가하기 위해 민감도, 특이도 및 점수를 포함하는 세 가지 평가 메트릭을 사용한다. 민감도(Se, Sensitivity)는 올바르게 분류된 비정상 샘플과 총 비정상 샘플 수 간의 비율로 계산된다. 동일한 방식으로 일반 샘플에 대해 특이성(Sp, specificity)이 계산된다. 최종 점수는 두 메트릭의 평균이다. 제안된 아키텍처에 대한 최상의 입력 표현을 얻기 위해 STFT(Short Time Fourier Transform), Mel 스펙트로그 램 및 MFCC(Mel-Frequency Cepstral Coefficient)를 포함하는 세 가지 다른 형태의 사운드 변환으로 실험을 수 행했다. 도 10의 Table 3에서 볼 수 있듯이 'Mel spectrogram'은 우리가 제안한 모델에 대한 적절한 입력 표현 임을 보여주는 최상의 성능을 얻는 다는 것을 확인할 수 있다. 도 10 및 도 11은 본 발명의 제2 실시예에 대한 실험 결과를 도시한다. 다른 추출 수준의 기능을 결합할 때 기능의 가중 합계 또는 평균을 사용하여 성능을 비교하기 위해 또 다른 실 험을 수행했다. 도 10의 Table 3에서와 같이 기능의 가중 합은 전반적으로 더 나은 성능을 보여준다. 민감도도 다소 높아서 이 연구에서 비정상 샘플을 정확하게 식별하는 것이 중요하다.그런 다음 최상의 모델의 성능을 'RespireNet'과 비교했다. 도 11의 표 4에서 볼 수 있듯이 본 발명의 제2 실시 예에서 제안한 모델(Proposed)은 민감도 측면에서 RespireNet을 5.1% 능가한다. 이는 다중 수준 특징 추출 아키 텍처가 0.90 이상의 높은 특이성 점수를 유지하면서 비정상적인 샘플을 인식하는 데 더 우수함을 보여준다. 최 종 점수는 제안한 방법이 전반적인 성능이 더 우수하고 RespireNet보다 1.2% 더 우수함을 보여준다. 본 발명의 제2 실시예에서는 호흡음 분류를 위한 다단계 특징 추출 메커니즘을 갖춘 CNN-LSTM 기반 모델을 제안 하였다. 병원 데이터셋에 대한 실험 결과 제안하는 방법이 최신 모델보다 성능이 우수하고 비정상 샘플 인식에 더 나은 민감도를 보인다는 것을 확인할 수 있다. 이상으로 본 발명에 따른 호흡이상음 식별 장치 및 제어 방법의 실시예를 설시하였으나 이는 적어도 하나의 실 시예로서 설명되는 것이며, 이에 의하여 본 발명의 기술적 사상과 그 구성 및 작용이 제한되지는 아니하는 것으 로, 본 발명의 기술적 사상의 범위가 도면 또는 도면을 참조한 설명에 의해 한정／제한되지는 아니하는 것이다. 또한 본 발명에서 제시된 발명의 개념과 실시예가 본 발명의 동일 목적을 수행하기 위하여 다른 구조로 수정하"}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "거나 설계하기 위한 기초로써 본 발명이 속하는 기술분야의 통상의 지식을 가진 자에 의해 사용되어질 수 있을"}
{"patent_id": "10-2023-0123687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "것인데, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자에 의한 수정 또는 변경된 등가 구조는 청구범위에 서 기술되는 본 발명의 기술적 범위에 구속되는 것으로서, 청구범위에서 기술한 발명의 사상이나 범위를 벗어나 지 않는 한도 내에서 다양한 변화, 치환 및 변경이 가능한 것이다."}
{"patent_id": "10-2023-0123687", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 호흡이상음 식별 장치의 블록도를 도시한다. 도 2는 본 발명의 제1 실시예에 따른 인공지능 모델의 개념도를 도시하는 도면이다. 도 3은 본 발명의 제1 실시예에 따른 호흡이상음 식별을 위한 인공지능 모델을 평가하기 위한 ICBHI 데이터 세 트의 통계를 도시한다.도 4는 평가에 사용되는 ICBHI 데이터 세트의 통계를 도시한다. 도 5는 입력 표현 간의 실험 결과를 비교하는 도면이다. 도 6은 본 발명의 제1 실시예와 \"RespireNet\"의 비교 결과를 도시한다. 도 7은 본 발명의 제2 실시예에 따른 인공지능 모델의 개념도를 도시하는 도면이다. 도 8 및 도 9는 평가를 위한 데이터 세트의 통계를 도시한다. 도 10 및 도 11은 본 발명의 제2 실시예에 대한 실험 결과를 도시한다."}
