{"patent_id": "10-2018-0119624", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0114537", "출원번호": "10-2018-0119624", "발명의 명칭": "자가 학습 로봇", "출원인": "엘지전자 주식회사", "발명자": "양원근"}}
{"patent_id": "10-2018-0119624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라 또는 마이크로부터 제1 데이터를 수신하는 데이터 수신부;내부 데이터 베이스에서 상기 제1 데이터에 맵핑되는 제1 행동 정보를 검색하는 매칭을 수행하는 데이터인식부;상기 매칭의 정확도를 산출하는 인식 결과 검증부;상기 정확도가 설정 레벨 이상인 경우, 상기 제1 행동 정보에 따라 동작하는 행동 명령부;상기 정확도가 상기 설정 레벨 미만인 경우, 데이터 요청 신호를 서버로 전송하는 서버 통신부; 및상기 서버로부터 상기 데이터 요청 신호에 응답하는 학습 데이터(learning data)를 수신하는 경우 상기 학습 데이터를 상기 데이터 베이스에 추가하는 인식 모델 갱신부를 포함하는 자가 학습 로봇."}
{"patent_id": "10-2018-0119624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인식 결과 검증부는상기 제1 행동 정보가 복수개인 경우 상기 정확도를 설정 레벨 미만으로 판단하는 자가 학습 로봇."}
{"patent_id": "10-2018-0119624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 인식 결과 검증부는기 설정된 영역 내에 존재하는 다른 자가 학습 로봇이 상기 제1 데이터에 대응하여 상기 제1 행동 정보와 상이한 행동 정보를 출력하는 경우 상기 정확도를 설정 레벨 미만으로 판단하는 자가 학습 로봇."}
{"patent_id": "10-2018-0119624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 데이터를 사용자 기기로 전송하고, 상기 제1 데이터에 응답하는 제2 행동 정보를 수신하는 통신부를더 포함하고,상기 인식 결과 검증부는상기 제1 행동 정보와 상기 제2 행동 정보가 동일한 경우 상기 정확도를 설정 레벨 이상으로 판단하고,상기 제1 행동 정보와 상기 제2 행동 정보가 상이한 경우 상기 정확도를 설정 레벨 미만으로 판단하는 자가 학습 로봇."}
{"patent_id": "10-2018-0119624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 통신부는상기 정확도가 상기 설정 레벨 미만인 경우, 상기 데이터를 사용자 기기로 전송하여 행동 대응 명령을 수신하는자가 학습 로봇."}
{"patent_id": "10-2018-0119624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,공개특허 10-2018-0114537-3-상기 학습 데이터는상기 서버가 상기 데이터로 상기 데이터 베이스의 업데이트가 가능한 것으로 판단한 경우, 상기 데이터에 대응하는 행동 정보를 포함하고,상기 서버가 상기 데이터로 상기 데이터 베이스의 업데이트가 불가능한 것으로 판단한 경우, 상기 데이터에 기초하여 추출된 추가 데이터 및 상기 추가 데이터에 대응하는 행동 정보를 포함하는 자가 학습 로봇."}
{"patent_id": "10-2018-0119624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 데이터 요청 신호를 전송하는 경우 상기 제1 데이터를 제2 데이터로 변환하는 데이터 변환부를 더 포함하는 자가 학습 로봇."}
{"patent_id": "10-2018-0119624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제2 데이터는적어도 하나의 오브젝트와 관련된 이미지 데이터 또는 음성 데이터와,상기 오브젝트와 상기 자가 학습 로봇 사이의 이격 거리, 상기 오브젝트를 인식한 위치 정보 및 상기 오브젝트를 인식할 때의 온도 정보 중 적어도 하나를 포함하는 환경 정보를 포함하는 자가 학습 로봇."}
{"patent_id": "10-2018-0119624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "서버; 및카메라 또는 마이크로부터 수신한 제1 데이터에 맵핑되는 제1 행동 정보를 내부 데이터 베이스에서 검색하는 매칭을 수행하고, 상기 매칭의 정확도가 설정 레벨 이상인 경우 상기 제1 행동 정보에 따라 동작하고, 상기 매칭의 정확도가 상기 설정 레벨 미만인 경우 상기 서버로 데이터 요청 신호를 전송하는 적어도 하나의 로봇을 포함하고, 상기 로봇은 상기 서버로부터 상기 데이터 요청 신호에 응답하는 학습 데이터(learning data)를 수신하는 경우상기 학습 데이터를 상기 데이터 베이스에 추가하는 로봇의 자가 학습 시스템."}
{"patent_id": "10-2018-0119624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 서버는소정 시간 동안 기 설정된 개수의 로봇으로부터 상기 데이터 요청 신호를 수신하는 경우, 상기 서버와 데이터를송수신하는 로봇으로 데이터 갱신 명령을 전송하는 로봇의 자가 학습 시스템."}
{"patent_id": "10-2018-0119624", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 자가 학습 로봇은 기 정해진 범위내에 위치한 사물과 관련된 비디오 데이터 또는 오디 오 데이터를 센싱하는 데이터 수신부, 데이터 수신부로부터 수신된 데이터와 자가 학습 로봇 내 데이터 베이스에 포함된 데이터를 매칭하는 데이터 인식부, 데이터 인식부의 매칭 결과를 출력하는 결과 출력부, 매칭 결과의 정 확도를 판단하는 인식 결과 검증부, 인식 결과 검증부의 판단 결과 매칭 결과의 정확도가 기 정해진 레벨 미만인 경우, 데이터 수신부로부터 수신된 데이터를 서버로 전송하는 서버 통신부 및 인식 결과 검증부의 판단 결과 매 칭 결과의 정확도가 기 정해진 레벨이상인 경우, 자가 학습 로봇이 기 설정된 사물 대응 행동을 수행하도록 하는 행동 명령부를 포함할 수 있다."}
{"patent_id": "10-2018-0119624", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자가 학습 로봇에 관한 것으로서, 기존에 인식되지 않은 사물에 대한 비디오 데이터 또는 오디오 데 이터를 인식한 로봇이 해당 사물에 대한 정보를 스스로 학습하거나 서버로부터 상기 사물에 대한 정보를 수신하 는 로봇 또는 시스템에 관한 것이다."}
{"patent_id": "10-2018-0119624", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "지능형 로봇은 가정 내에서 인간에게 다양한 서비스를 제공하고 정보화 시대의 사회적인 네트워크와 유기적으로 결합하고, 가전기기 등과의 원격제어가 가능한 인간친화적인 인터페이스 역할을 수행하고 있다. 이러한 미래 컴 퓨팅 환경과 지능형 서비스 로봇이 결합하면 인지 및 감성과 유비쿼터스 환경을 기반으로 한 미래형 로봇으로 발전하게 될 것이다. 이러한 로봇은 미래의 우리 생활 속에서 환경과 유기적으로 동작하고, 인간과 자연스러운상호작용을 통해서 지속적 관계를 갖고 성장하여, 인간의 동반자 역할을 할 수 있게 된다. 일반적으로 로봇은 산업용으로 개발되어 공장 자동화의 일 부분을 담당하여 왔다. 최근에는 로봇을 응용한 분야 가 더욱 확대되어, 의료용 로봇, 우주 항공 로봇 등이 개발되고, 일반 가정에서 사용할 수 있는 가정용 로봇도 만들어지고 있다. 가정용 로봇의 대표적인 예는 로봇 청소기로서, 일정 영역을 스스로 주행하면서 주변의 먼지 또는 이물질을 흡 입하여 청소하는 가전기기의 일종이다. 이러한 로봇 청소기는 일반적으로 충전 가능한 배터리를 구비하고, 주행 중 장애물을 피할 수 있는 장애물 센서를 구비하여 스스로 주행하며 청소할 수 있다. 다만, 이러한 가정용 로봇이 장애물을 인식한 후 해당 장애물에 대한 행동을 정확하게 수행하지 못할 경우 예상 하지 못하는 피해가 발생할 수 있다. 따라서, 가정에 사용자가 없는 경우에 스스로 사물에 대한 정보를 업데이 트하여 정확한 행동을 수행하도록 하는 시스템이 필요하다."}
{"patent_id": "10-2018-0119624", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 과제는, 일정 영역 내에서 움직이는 로봇이 새로운 사물을 발견할 경우 오동작하는 것을 방지하는 것이다. 본 발명의 다른 과제는, 로봇이 새로운 사물을 발견할 경우, 후속 행동을 하기 이전에 해당 사물이 무엇인지를 스스로 판단하여 적절한 행동을 하도록 하는 것이다. 본 발명의 또 다른 과제는, 로봇과 사용자의 디지털 디바이스 사이의 통신을 통하여 로봇이 직면한 문제점을 해 결하는 것이다."}
{"patent_id": "10-2018-0119624", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 자가 학습 로봇은 카메라 또는 마이크로부터 제1 데이터를 수신하는 데이터 수신부, 내부 데이터 베이스에서 제1 데이터에 맵핑되는 제1 행동 정보를 검색하는 매칭을 수행하는 데이터 인식부, 매 칭의 정확도를 산출하는 인식 결과 검증부, 정확도가 설정 레벨 이상인 경우, 제1 행동 정보에 따라 동작하는 행동 명령부, 정확도가 설정 레벨 미만인 경우, 데이터 요청 신호를 서버로 전송하는 서버 통신부 및 서버로부 터 데이터 요청 신호에 응답하는 학습 데이터(learning data)를 수신하는 경우 학습 데이터를 데이터 베이스에 추가하는 인식 모델 갱신부를 포함할 수 있다. 인식 결과 검증부는 제1 행동 정보가 복수개인 경우 정확도를 설정 레벨 미만으로 판단할 수 있다. 인식 결과 검증부는 기 설정된 영역 내에 존재하는 다른 자가 학습 로봇이 제1 데이터에 대응하여 제1 행동 정 보와 상이한 행동 정보를 출력하는 경우 정확도를 설정 레벨 미만으로 판단할 수 있다. 제1 데이터를 사용자 기기로 전송하고, 제1 데이터에 응답하는 제2 행동 정보를 수신하는 통신부를 더 포함하고, 인식 결과 검증부는 제1 행동 정보와 제2 행동 정보가 동일한 경우 정확도를 설정 레벨 이상으로 판 단하고, 제1 행동 정보와 제2 행동 정보가 상이한 경우 정확도를 설정 레벨 미만으로 판단할 수 있다. 통신부는 정확도가 설정 레벨 미만인 경우, 데이터를 사용자 기기로 전송하여 행동 대응 명령을 수신할 수 있다. 학습 데이터는 서버가 데이터로 데이터 베이스의 업데이트가 가능한 것으로 판단한 경우, 데이터에 대응하는 행 동 정보를 포함하고, 서버가 데이터로 데이터 베이스의 업데이트가 불가능한 것으로 판단한 경우, 데이터에 기 초하여 추출된 추가 데이터 및 추가 데이터에 대응하는 행동 정보를 포함할 수 있다. 데이터 요청 신호를 전송하는 경우 제1 데이터를 제2 데이터로 변환하는 데이터 변환부를 더 포함할 수 있다. 제2 데이터는 적어도 하나의 오브젝트와 관련된 이미지 데이터 또는 음성 데이터와, 오브젝트와 자가 학습 로봇 사이의 이격 거리, 오브젝트를 인식한 위치 정보 및 오브젝트를 인식할 때의 온도 정보 중 적어도 하나를 포함 하는 환경 정보를 포함할 수 있다. 본 발명의 실시 예에 따른 로봇의 자가 학습 시스템은 서버 및 카메라 또는 마이크로부터 수신한 제1 데이터에 맵핑되는 제1 행동 정보를 내부 데이터 베이스에서 검색하는 매칭을 수행하고, 매칭의 정확도가 설정 레벨 이상인 경우 제1 행동 정보에 따라 동작하고, 매칭의 정확도가 설정 레벨 미만인 경우 서버로 데이터 요청 신호를 전송하는 적어도 하나의 로봇을 포함하고, 로봇은 서버로부터 데이터 요청 신호에 응답하는 학습 데이터 (learning data)를 수신하는 경우 학습 데이터를 데이터 베이스에 추가할 수 있다. 서버는 소정 시간 동안 기 설정된 개수의 로봇으로부터 데이터 요청 신호를 수신하는 경우, 서버와 데이터를 송 수신하는 로봇으로 데이터 갱신 명령을 전송할 수 있다."}
{"patent_id": "10-2018-0119624", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 효과는 다음과 같다. 본 발명의 다양한 실시 예들 중 일 실시 예에 따르면, 일정 영역 내에서 움직이는 로봇이 새로 인식한 사물에 대하여 스스로 학습이 가능하도록 시스템을 구축하여, 새로운 사물을 발견할 경우의 오동작하는 것을 방지하는 기술적 효과가 있다. 본 발명의 다양한 실시 예들 중 다른 실시 예에 따르면, 사용자 입력 없이 로봇이 서버와 통신하여 해당 사물에 대하여 학습 및 사물 대응 행동을 스스로 업데이트하는 기술적 효과가 있다. 본 발명의 다양한 실시예들 중 또 다른 실시예에 따르면, 사용자로부터 부정적인 피드백을 기 정해진 횟수 이 상 수신하는 경우 등 사용자와의 통신을 통하여 사물 대응 행동을 업데이트하여 사물에 대하여 로봇이 적절한 행동을 하게 하는 장점이 있다."}
{"patent_id": "10-2018-0119624", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명과 관련된 실시 예에 대하여 도면을 참조하여 보다 상세하게 설명한다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 도 1은 본 발명의 일 실시예에 의한 로봇의 자가 학습 시스템을 설명하기 위한 블록도이다. 도 1에 도시된 바와 같이, 자가 학습 로0봇은 자가 학습을 위하여 사용자 기기와 통신하거나 서버와 통신을 수행할 수 있다. 본 발명의 일 실시예에 의한 자가 학습 로봇은 데이터 수신부, 데이터 인식부, 결과 출력부 , 인식 결과 검증부, 데이터 변환부, 통신부, 서버 통신부, 행동 명령부, 인식 모델 수신부 및 인식 모델 갱신부을 포함할 수 있다. 또한, 자가 학습 로봇이 통신을 수행하는 서버는 수신부, 데이터 역 변환부, 학습 데이터 관리부, 학습 데이터 수집부, 재학습 판단부, 인식 모델 재학습부 및 인식 모델 전송부를 포함할 수 있다. 도 1에 도시된 각 모듈 중 일부를 제거하거나 추가적인 모듈을 추가하더라도 자가 학습 로봇 및 서버를 이용한 자가 학습 로봇 시스템을 구현할 수 있으므로 도 1의 모듈에 한정되지 않는다. 자가 학습 로봇은 정해진 영역 내에서 움직이면서 적어도 하나 이상의 사물을 인식할 수 있다. 자가 학습 로봇은 사물의 입체적 형상을 센싱하는 3D 카메라 또는 기 정해진 레벨 이상의 오디오를 센싱하는 마이크 를 포함할 수 있다. 자가 학습 로봇은 3D 카메라 또는 마이크를 통해서 사물을 인식할 수 있다. 이하에서 는 카메라를 이용하여 사물의 외형을 촬상한 이미지 등의 비디오 데이터로 사물을 인식한 것을 가정하여 설명하 도록 하겠다. 자가 학습 로봇의 데이터 수신부은 3D 카메라가 센싱한 비디오 데이터 또는 마이크가 센싱한 오디오 데이터를 수신할 수 있다. 또한, 자가 학습 로봇의 데이터 인식부는 데이터 수신부로부터 수신 된 데이터와 자가 학습 로봇 내 데이터 베이스에 포함된 데이터를 매칭할 수 있다. 자가 학습 로봇의 데이터 베이스(미도시)에는 복수 개의 사물에 대한 비디오 데이터 또는 오디오 데이터와 해당 사물에 맵핑되는 적어도 하나 이상의 사물 대응 행동 정보가 저장되어 있을 수 있다. 자가 학습 로봇의 결과 출력부는 데이터 인식부의 매칭 결과를 출력할 수 있다. 결과 출력부 는 데이터 인식부의 매칭 결과 사물과 매칭되는 사물 정보 및 맵핑된 사물 대응 행동 정보가 존재하 는지 아닌지를 매칭 결과로서 출력할 수 있다. 자가 학습 로봇의 인식 결과 검증부는 결과 출력부로부터 전달받은 매칭 결과에 기초하여, 매칭 결과의 정확도를 판단할 수 있다. 우선, 자가 학습 로봇에 있어서 인식 결과 검증부는 데이터 인식부 의 인식이 성공인지 실패인지에 대한 기준을 설정할 수 있다. 예를 들어, 자가 학습 로봇이 특정 사 물을 인식하고 제1 사물 대응 행동을 수행한 후 사용자로부터 특정 사물에 대해서는 제1 사물 대응 행동이 아닌 제2 사물 대응 행동을 수행하라는 명령을 기 정해진 횟수 이상 수신하는 경우에는 자가 학습 로봇이 특정 사물에 대한 인식이 실패라고 판단할 수 있다. 또한, 자가 학습 로봇의 데이터 베이스에는 특정 사물을 인 식하는 경우에 제1 사물 대응 행동을 하도록 맵핑되어 있는 반면에, 실제로는 제2 사물 대응 행동을 수행하는 경우 제1 사물 대응 행동과 제2 사물 대응 행동이 다르므로 인식 결과 검증부는 이 경우에도 인식의 실패 로 판단할 수 있다. 또한, 자가 학습 로봇이 특정 사물을 인식한 후 하나가 아닌 복수 개의 사물 대응 행 동이 출력되는 경우, 인식 결과 검증부는 이 경우에도 인식의 실패로 판단할 수 있다. 또한, 일정한 영역 내에 복수 개의 자가 학습 로봇이 위치하고, 복수 개의 자가 학습 로봇들이 동일한 사물을 인식하였을 때 서로 다른 사물 대응 행동을 출력하는 경우에, 인식 결과 검증부는 이 경우에도 인식의 실패로 판단할 수 있다. 또한, 자가 학습 로봇의 인식 결과 검증부는 매칭 결과의 정확도를 수치로 출력할 수 있다. 예를 들 어, 인식 결과 검증부는 매칭 결과의 정확도가 80% 이상인 경우에 인식이 성공한 것으로 판단할 수 있다. 또는, 인식 결과 검증부는 매칭 결과의 정확도가 사용자가 설정한 정확도 값 이상인 경우에 인식이 성공한 것으로 판단할 수 있다. 자가 학습 로봇의 인식 결과 검증부의 판단 결과 매칭 결과의 정확도가 기 정해진 레벨 이상인 경우 에는, 행동 명령부가 자가 학습 로봇이 해당 사물에 맵핑된 기 설정된 사물 대응 행동을 수행하도록할 수 있다. 반면, 자가 학습 로봇의 인식 결과 검증부의 판단 결과 매칭 결과의 정확도가 기 정해진 레벨 미만인 경우에는, 통신부를 통해 사용자 기기에 해당 사물의 이미지가 포함된 데이터 등을 송부하고, 사용자로부 터 특정 사물 대응 행동 수행 명령을 수신할 수 있다. 또한, 자가 학습 로봇의 인식 결과 검증부의 판단 결과 매칭 결과의 정확도가 기 정해진 레벨 미만인 경우에는, 서버 통신부를 통해 서버와 통신을 수행하여 사용자 입력 없이 해당 사물에 대한 적절한 사물 대응 행동을 하도록 서버로부터 데이터를 수신할 수 있다. 이 경우, 자가 학습 로봇의 데이터 변환부는 데이터 수신부가 수신한 데이터를 사용자 기기 또 는 서버로의 송신을 위한 데이터로 변환할 수 있다. 데이터 변환부는 사생활 침해 방지 등을 고려하여 사 람의 얼굴 영상 등을 모자이크 처리하거나 크롭(crop)한 이미지로 가공하여 송신할 수 있다. 또한, 데이터 변환 부는 이미지의 유출 및 해킹 등을 방지하기 위하여 해당 데이터를 암호화하여 송신할 수 있다. 또한, 데이 터 변환부는 사물과의 거리, 온도, 위치 정보 등 자가 학습 로봇이 사물을 인식한 환경 등을 포함하 는 인식 실패와 관련된 정보를 함께 사용자 기기 또는 서버에 송신할 수 있다. 따라서, 데이터 변환부는 개인 정보가 삭제된 비디오 데이터 또는 오디오 데이터 및 인식 실패와 관련된 센싱 데이터 등을 사용자 기기 또는 서버에 송신할 수 있다. 본 발명의 일 실시예에 의한 자가 학습 로봇과 데이터를 송수신하는 서버는 변환된 데이터 또는 가공 된 데이터를 수신하는 수신부를 포함할 수 있다. 도 1에 도시된 바와 같이, 서버의 데이터 역 변환부는 수신부가 수신한 변환된 데이터 등을 역 변환할 수 있다. 서버의 데이터 역 변환부가 변환한 데이터는 학습 데이터 관리부에서 관리할 수 있다. 나아가, 학습 데이터 관리부는 복수 개의 자가 학습 로봇들로부터 다양한 사물에 대한 인식 데이터를 수집할 수 있 다. 또한, 학습 데이터 관리부는 복수 개의 자가 학습 로봇들로부터 수신한 데이터를 인식 데이터 타입별 또는 로봇 기기별로 분류하여 관리할 수 있다. 서버의 학습 데이터 수집부는 복수 개의 자가 학습 로봇들로부터 수신되는 인식 데이터만으로는 사물 정보를 결정하기 어렵다고 판단하는 경우, 다른 데이터 베이스로부터 해당 사물과 유사한 데이터를 복수 개 추 출할 수 있다. 예를 들어, 해당 사물과 유사한 이미지 또는 다른 데이터를 저장하고 있는 다른 자가 학습 로봇 에 데이터를 요청할 수 있다. 또한, 인터넷을 이용하여 해당 사물과 유사한 이미지들을 추출할 수 있다. 또한, 기 정해진 이미지 데이터 베이스에 액세스(access)하여 해당 사물과 유사한 이미지들을 추출할 수 있다. 서버의 재학습 판단부는 복수 개의 자가 학습 로봇들로부터 수집된 누적 데이터를 기반으로 자가 학 습 로봇들의 데이터 베이스를 갱신 또는 업데이트하여야 하는지를 판단할 수 있다. 이 경우 재학습 판단부(25 0)는, 기 정해진 시간 이내에 복수 개의 자가 학습 로봇들로부터 해당 사물에 대한 인식 실패 결과가 출력되는 경우에는 서버와 통신을 수행하는 모든 자가 학습 로봇들에 대하여 해당 사물에 대한 사물 정보 및 대응되 는 사물 대응 행동과 관련된 데이터를 갱신 또는 업데이트하도록 결정할 수 있다. 또한, 재학습 판단부는 수집된 인식 데이터를 클러스터링하였을 때, 특정 클러스터에 기 정해진 용량 이상의 인식 실패 데이터가 쌓이 는 경우, 서버와 통신을 수행하는 모든 자가 학습 로봇들에 대하여 해당 사물에 대한 사물 정보 및 대응되 는 사물 대응 행동과 관련된 데이터를 갱신 또는 업데이트하도록 결정할 수 있다. 또한, 재학습 판단부는 하나의 자가 학습 로봇으로부터 동일한 인식 실패 결과가 지속적으로 수신되는 경우에는 해당 자가 학습 로봇에 대해서만 해당 사물에 대한 사물 정보 및 대응되는 사물 대응 행동과 관련된 데이터를 갱신 또는 업데이트하도록 결정할 수 있다. 서버의 인식 모델 재학습부는 재학습 판단부에 의해서 자가 학습 로봇의 데이터 업데이트 가 결정되면, 갱신 또는 업데이트할 사물에 대한 사물 정보 및 대응되는 사물 대응 행동에 대한 데이터를 생성 및 가공할 수 있다. 서버의 인식 모델 전송부는 인식 모델 재학습부에서 생성 및 가공한 데이터를 자가 학습 로봇 에 송신할 수 있다. 자가 학습 로봇의 인식 모델 수신부는 서버의 인식 모델 전송부로부터 사물 정보 및 사물 대응 행동에 대한 데이터를 수신할 수 있다.자가 학습 로봇의 인식 모델 갱신부는 서버로부터 수신한 데이터를 이용하여 자가 학습 로봇 의 데이터 베이스를 갱신 또는 업데이트할 수 있다. 도 1에 도시된 바와 같이 설계하는 경우, 사용자의 입력 없이도 자가 학습 로봇이 스스로 사물에 대하여 적절한 행동을 수행 할 수 있기 때문에, 예상치 못한 자가 학습 로봇의 행동을 방지할 수 있다. 도 2는 본 발명의 일 실시예에 의한 자가 학습 로봇이 사물 인식에 실패하는 경우 자가 학습 하는 방법을 설명 하기 위한 도면이다. 도 2에 도시된 바와 같이, 본 발명의 일 실시예에 의한 자가 학습 로봇은 특정 사물을 인식하고, 데이터 수신부에서 인식 데이터를 수신할 수 있다. 그리고, 데이터 인식부는 데이터 수신부에서 수신한 인식 데이터와 자가 학습 로봇 내 데이터 베이스에 포함된 데이터를 매칭할 수 있다. 그리고, 결과 출력부 는 데이터 인식부의 매칭 결과를 출력할 수 있다. 그리고, 인식 결과 검증부는 결과 출력부 의 매칭 결과의 정확도를 판단할 수 있다. 인식 결과 검증부의 판단 결과 매칭 결과의 정확도가 기 정해진 레벨 이상인 경우, 행동 명령부로 하여금 자가 학습 로봇이 기 설정된 사물 대응을 수행하게 할 수 있다. 반면, 인식 결과 검증부의 판단 결과 매칭 결과의 정확도가 기 정해진 레벨 미만인 경우, 데이터 변 환부로 하여금 인식 데이터를 기 정해진 알고리즘에 따라 변환하게 하고, 서버 통신부로 하여금 변환 된 데이터를 서버에 송신하게 할 수 있다. 자가 학습 로봇의 인식 모델 수신부는 서버의 인식 모델 전송부로부터 사물 정보 및 사물 대응 행동에 대한 데이터를 수신할 수 있다. 그리고, 자가 학 습 로봇의 인식 모델 갱신부는 서버로부터 수신한 데이터를 이용하여 자가 학습 로봇의 데 이터 베이스를 갱신 또는 업데이트할 수 있다. 도 3은 본 발명의 일 실시예에 의한 서버가 복수 개의 자가 학습 로봇들로부터 인식 실패 데이터를 수신하는 일 예를 설명하기 위한 도면이다. 본 발명의 일 실시예에 의한 복수 개의 자가 학습 로봇들과 데이터를 송수신하는 서버의 수신부(21 0)는 는 변환된 데이터 또는 가공된 데이터를 수신할 수 있다. 그리고, 서버의 데이터 역 변환부는 수신부가 수신한 변환된 데이터 등을 역 변환할 수 있다. 그리고, 서버의 데이터 역 변환부가 변환한 데이터는 학습 데이터 관리부에서 관리할 수 있다. 그리고, 서버의 학습 데이터 수집부 는 복수 개의 자가 학습 로봇들로부터 수신되는 인식 데이터만으로는 사물 정보를 결정하기 어렵다고 판단하는 경우, 다른 데이터 베이스로부터 해당 사물과 유사한 데이터를 복수 개 추출할 수 있다. 그리고, 서버의 재학습 판단부는 복수 개의 자가 학습 로봇들로부터 수집된 누적 데이터를 기반으로 자가 학습 로봇들의 데이터 베이스를 갱신 또는 업데이트하여야 하는지를 판단할 수 있다. 이 경우 재학습 판단부는, 기 정해 진 시간 이내에 복수 개의 자가 학습 로봇들로부터 해당 사물에 대한 인식 실패 결과가 출력되는 경우에는 서버 와 통신을 수행하는 모든 자가 학습 로봇들에 대하여 해당 사물에 대한 사물 정보 및 대응되는 사물 대응 행동과 관련된 데이터를 갱신 또는 업데이트하도록 결정할 수 있다. 또한, 재학습 판단부는 수집된 인식 데이터를 클러스터링하였을 때, 특정 클러스터에 기 정해진 용량 이상의 인식 실패 데이터가 쌓이는 경우, 서버 와 통신을 수행하는 모든 자가 학습 로봇들에 대하여 해당 사물에 대한 사물 정보 및 대응되는 사물 대응 행동과 관련된 데이터를 갱신 또는 업데이트하도록 결정할 수 있다. 또한, 재학습 판단부는 하나의 자가 학습 로봇으로부터 동일한 인식 실패 결과가 지속적으로 수신되는 경우에는 해당 자가 학습 로봇에 대해서만 해당 사물에 대한 사물 정보 및 대응되는 사물 대응 행동과 관련된 데이터를 갱신 또는 업데이트하도 록 결정할 수 있다. 그리고, 서버의 인식 모델 재학습부는 재학습 판단부에 의해서 자가 학습 로봇의 데이터 업데이트가 결정되면, 갱신 또는 업데이트할 사물에 대한 사물 정보 및 대응되는 사물 대응 행동에 대한 데이터를 생성 및 가공할 수 있다. 그리고, 서버의 인식 모델 전송부는 인식 모델 재학 습부에서 생성 및 가공한 데이터를 자가 학습 로봇에 송신할 수 있다. 도 4는 본 발명의 일 실시예에 의한 자가 학습 로봇의 송신부 및 수신부가 로봇의 자가 학습을 수행하는 방법을 설명한 도면이다. 도 4에 도시된 바와 같이, 본 발명의 일 실시예에 의한 자가 학습 로봇은 송신부와 수신부로 구성될 수 있 다. 송신부에서는 우선 자가 학습 로봇이 특정 사물을 인식한 데이터를 입력 받고(S411), 입력 받은 데이 터를 인식할 수 있다(S412). 그리고, 입력 받은 데이터를 인식한 결과를 출력하고(S413), 출력 결과를 기초로 특정 사물을 정확하게 인식하였는지 아닌지를 판단할 수 있다(S414). 이 때 인식에 성공했다고 판단되는 경우에 는 송신부의 기능을 종료할 수 있다. 반면 인식에 실패하였다고 판단되는 경우 특정 사물에 대한 추가 정보 수 집을 결정할 수 있다(S415). 그리고, 인식한 데이터를 기 정해진 알고리즘에 따라 변환하고(S416), 변환된 데이터를 서버로 전송할 수 있다(S417). 또한, 본 발명의 일 실시예에 의한 자가 학습 로봇의 수신부는 서버로부터 갱신 모델을 수신하고 (S421), 갱신 모델에 기초하여 자가 학습 로봇의 데이터 베이스 전체를 갱신할지를 판단할 수 있다(S422). 판단 결과에 따라서, 자가 학습 로봇의 전체 데이터 베이스를 갱신할 수도 있고(S423), 데이터 베이스 내 에서 해당 사물과 관련된 데이터 부분만을 갱신할 수 있다(S424). 도 5는 본 발명의 일 실시예에 의한 서버가 자가 학습 로봇을 학습시키는 방법을 설명한 도면이다. 도 5에 도시된 바와 같이, 본 발명의 일 실시예에 의한 자가 학습 로봇과 통신을 수행하는 서버는 자 가 학습 로봇에서 변환한 데이터를 수신하고(S510), 변환된 데이터를 역 변환하고(S520), 역 변환된 데이 터를 저장하고(S530), 자가 학습 로봇의 데이터 베이스 갱신 조건을 결정할 수 있다(S540). 이 경우, 갱신 조건을 만족하는지를 판단하여(S550), 갱신이 필요한 경우 데이터 베이스 갱신에 필요한 데이터가 충분한지 여 부를 판단할 수 있다(S560). 판단 결과 데이터가 충분한 경우에는 재학습 데이터를 생성하고(S580), 생성한 재 학습 데이터를 자가 학습 로봇에 송신할 수 있다. 반면에 판단 결과 데이터가 불충분한 경우에는 추가 데 이터를 수집할 수 있다(S570). 도 6은 본 발명의 일 실시예에 의한 자가 학습 로봇이 인식 실패 후 데이터 베이스를 갱신하는 제1 실시예를 설 명하기 위한 도면이다. 도 6에 도시된 바와 같이, 자가 학습 로봇은 가정 내에서 이동할 수 있다. 이 때, 자가 학습 로봇이 벽난로를 보고 회피하지 않고 그대로 통과하는 경우, 인식 실패로 판단할 수 있다. 따라서, 자가 학습 로 봇은 벽난로를 촬영한 이미지를 서버로 송신하여 자가 학습을 위한 데이터 베이스 업데이트를 요청할 수 있다. 서버는 자가 학습 로봇이 촬영한 이미지만으로 데이터 베이스 업데이트가 가능하다 고 판단되는 경우, 벽난로 정보 및 벽난로에 대응하는 사물 대응 행동에 대한 데이터를 생성하여 자 가 학습 로봇에 송신할 수 있다. 반면에, 자가 학습 로봇이 촬영한 이미지만으로 데이터 베이스 업데 이트가 불가능하다고 판단되는 경우에는, 유사한 이미지(610, 620)들을 추출하여 벽난로 정보 및 벽난로 에 대응하는 사물 대응 행동에 대한 데이터를 생성하여 자가 학습 로봇에 송신할 수 있다. 벽난로 에 대응하는 사물 대응 행동은 회피 또는 다른 방향으로의 이동일 수 있다. 나아가, 데이터 베이스가 갱신 또는 업데이트된 자가 학습 로봇은 이후에 벽난로를 통과하지 않고 회피 또는 다른 방향으로 이동할 수 있다. 도 7은 본 발명의 일 실시예에 의한 자가 학습 로봇이 인식 실패 후 데이터 베이스를 갱신하는 제2 실시예를 설 명하기 위한 도면이다. 도 7에 도시된 바와 같이, 자가 학습 로봇은 가정 내에서 이동할 수 있다. 이 때, 자가 학습 로봇이 도자기를 보고 데이터 베이스 내의 유사한 이미지를 갖는 데이터를 검색하여 도자기를 쓰레기통(70 5)으로 인식할 수 있다. 따라서, 자가 학습 로봇은 쓰레기를 회수하여 도자기에 넣는 사물 대응 행동 을 수행할 수 있다. 이 경우 사용자가 자가 학습 로봇의 사물 대응 행동에 대하여 부정적인 피드백을 입력하는 경우, 자가 학습 로봇은 쓰레기를 도자기에 넣는 행동이 인식 실패로서 정의할 수 있다. 따 라서, 자가 학습 로봇은 도자기를 촬영한 이미지를 서버로 송신하여 자가 학습을 위한 데이터 베이스 업데이트를 요청할 수 있다. 서버는 자가 학습 로봇이 촬영한 이미지만으로 데이터 베이스 업 데이트가 가능하다고 판단되는 경우, 도자기 정보 및 도자기에 대응하는 사물 대응 행동에 대한 데이 터를 생성하여 자가 학습 로봇에 송신할 수 있다. 반면에, 자가 학습 로봇이 촬영한 이미지만으로 데 이터 베이스 업데이트가 불가능하다고 판단되는 경우에는, 유사한 이미지들을 추출하여 도자기 정보 및 도 자기에 대응하는 사물 대응 행동에 대한 데이터를 생성하여 자가 학습 로봇에 송신할 수 있다. 나아 가, 도 7에는 도시하지 않았으나 사용자가 직접 자가 학습 로봇의 데이터 베이스를 업그레이드 할 수 있다. 도자기에 대응하는 사물 대응 행동은 회피일 수 있다. 나아가, 데이터 베이스가 갱신 또는 업데이트 된 자가 학습 로봇은 이후에 도자기에 쓰레기를 넣지 않고 회피할 수 있다. 도 8은 본 발명의 일 실시예에 의한 자가 학습 로봇이 인식 실패 후 데이터 베이스를 갱신하는 제3 실시예를 설 명하기 위한 도면이다. 도 8에 도시된 바와 같이, 자가 학습 로봇은 가정 내에서 이동할 수 있다. 이 때, 자가 학습 로봇이 선풍기를 보고 데이터 베이스 내의 유사한 이미지를 갖는 데이터를 검색한 결과, 유사한 이미지가 발견되 지 않는 경우 자가 학습 로봇은 선풍기를 특정 사물로 정의하지 못할 수 있다. 이와 같이 자가 학습로봇이 특정 사물을 보고 어떠한 정의를 하지 못하는 경우에는 사물 대응 행동을 하지 않을 수 있다. 그리 고 이 경우에 자가 학습 로봇은 사물 대응 행동을 하지 않은 것을 인식 실패로서 정의할 수 있다. 따라서, 자가 학습 로봇은 선풍기를 촬영한 이미지를 서버로 송신하여 자가 학습을 위한 데이터 베이스 업데이트를 요청할 수 있다. 서버는 자가 학습 로봇이 촬영한 이미지만으로 데이터 베이스 업데이트 가 가능하다고 판단되는 경우, 선풍기 정보 및 선풍기에 대응하는 사물 대응 행동에 대한 데이터를 생성하여 자가 학습 로봇에 송신할 수 있다. 반면에, 자가 학습 로봇이 촬영한 이미지만으로 데이터 베이스 업데이트가 불가능하다고 판단되는 경우에는, 유사한 이미지들(810, 820, 830, 840)을 추출하여 선풍기 정보 및 선풍기에 대응하는 사물 대응 행동에 대한 데이터를 생성하여 자가 학습 로봇에 송신 할 수 있다. 데이터 베이스가 갱신 또는 업데이트된 자가 학습 로봇은 이후에 선풍기를 유사한 이미 지(810, 820, 830, 840)들과 동일한 선풍기로 정의할 수 있다. 또한, 자가 학습 로봇은 선풍기(80 0)로 정의내린 뒤에는 사용자의 명령에 따라 선풍기를 온/오프하는 사물 대응 행동도 수행할 수 있다. 도 9 내지 도 11은 본 발명의 일 실시예에 의한 자가 학습 로봇이 자가 학습을 수행하기 위해 사용하는 기술들 에 대하여 설명하기 위한 도면들이다. 도 9는 오토인코더(autoencoder, 900) 기술을 설명하기 위한 도면이다. 오토인코더 기술은 데이터를 부호 화하고 그것을 다시 복호화하는 구조로 구성되며, 부호화하고 복화하여 복원된 데이터가 원본 데이터와 차이가 발생하는데 그 차이를 이용하는 기술이다. 예를 들어, 기존에 학습된 사물에 대한 데이터를 입력으로 넣었을 경 우에는 이미 학습된 사물이므로 복원된 데이터와 원본 데이터의 차이가 극히 적을 수 있다. 반면에, 학습되지 않은 사물에 대한 데이터를 입력으로 넣었을 때는 학습하지 않은 사물이므로 데이터가 정확하게 복원되지 않으 므로 복원된 데이터와 원본 데이터의 차이가 클 수 있다. 따라서, 본 발명의 일 실시예에 의한 자가 학습 로봇 은 복원된 데이터와 원본 데이터 사이의 차이가 크고 작은지를 기준으로 해당 사물이 기 학습된 사물인지 아닌지를 판단할 수 있다. 도 10은 제로 샷 러닝(zero shot learning, 1000) 기술을 설명하기 위한 도면이다. 자가 학습 로봇은 제 로 샷 러닝 기술을 이용하여 이미지만으로 해당 사물이 어떠한 사물인지를 정의내릴 수 있다. 즉, 자가 학습 로봇은 제로 샷 러닝 기술을 이용하여 이미지만으로도 해당 사물이 기 학습된 사물인지를 판단 할 수 있다. 제로 샷 러닝 기술은 주로 단어 정보를 이용하게 된다. 즉, 이미지를 시각 정보(visual feature) 값으로 변환하고 이를 의미 정보 공간(Semantic feature space)로 맵핑하게 된다. 따라서, 단어를 이 용하여 의미 정보 공간으로 만들고 의미 정보 공간 내에서 이미지를 맵핑시켜 이미지가 의미 정보 공간에서 어 디에 위치하는지에 따라 이미지에 해당하는 단어를 출력할 수 있다. 도 11은 증분 학습(incremental learning, 1100) 기술을 설명하기 위한 도면이다. 자가 학습 로봇은 증분 학습 기술을 이용하여 새로운 데이터가 들어왔을 때 이전에 학습한 것을 삭제하지 않고 이전에 학습했던 데이터에 대한 접근 없이 새롭게 학습을 할 수 있다. 즉, 증분 학습 기술은 새로운 데이터에 대해 누적적 으로 학습할 수 있게 하는 기술이다. 따라서, 자가 학습 로봇은 증분 학습 기술을 이용하여 기존에 학습된 데이터들은 그대로 놔두면서 새롭게 인식한 사물에 대한 데이터만을 데이터 베이스에 누적적으로 추가하 면서 학습 데이터량을 계속해서 늘릴 수 있다. 도 12는 본 발명의 다른 일 실시예에 의한 행동을 학습하는 자가 학습 로봇의 구조를 도시한 블록도이다. 도 12에 도시된 바와 같이 본 발명의 다른 일 실시예에 의한 자가 학습 로봇은 무선랜을 통해 다른 로봇 의 행동 패턴이나 사용자의 학습 규칙을 입력 받아 이를 피지컬 링크를 통해 움직임 제어부로 전송하고, 그 움 직임제어부의 명령 신호에 따라 모터(1213-1~1213-N)의 구동을 제어하는 모터 제어부와 모터제어부 로부터 입력 되는 다른 로봇의 행동 패턴이나 사용자의 학습규칙을 발현한 후, 이를 터치 판넬 및 마이크 를 통해 입력되는 외부자극에 의해, 로봇의 움직임 패턴으로 결정하여 그에 따른 명령 신호를 상기 모터제어부 에 전송하는 움직임 제어부로 구성될 수 있다. 모터제어부는 다른 로봇의 행동패턴이나 사용자의 지시사항들을 받아 들이기 위한 무선랜(미도시), 외부 의 자극을 센싱하는 센서, 외부 이미지를 씨씨디를 통해 캡쳐하는 이미지 캡쳐, 센서 의 자극 및 이미지 캡쳐의 이미지를 입력 받아 이를 피지컬 링크를 통해 움직임 제어부로 전송하고, 움직임 전송부에서 전송되는 특정동작에 대한 명령신호를 디지탈 신호처리하여 그에 따른 모터 구동제어신호를 출력하는 디지탈신호처리부, 디지탈신호처리부의 모터 구동 제어 신호를 입력 받아 모터 구동 제어 신호에 해당되는 동작속도를 생성하기 위한 펄스폭 변조 신호를 출력함과 아울러 모터 구동 제 어 신호에 해당되는 특정동작의 위치를 지시하기 위한 위치신호를 출력하는 PWM제너레이터, PWM제너레이터의 펄스폭 변조 신호 및 위치 신호에 따라, 각기 해당 링크를 동작시키는 다수의 모터(1213-1~1213-N), 링크를 통해 현재 관절의 위치를 파악하여, 명령에 따른 동작의 오류를 검출하여 그 검출된 오류를 재조정하는 포텐셔미터로 구성될 수 있다. 움직임 제어부는, 마이크를 통해 음성 신호를 입력 받아 이를 코딩하는 오디오 코덱부, 운용 프로그램 및 응용프로그램이 저장되는 플래시메모리, 엘씨디 판넬과 일체형으로 이루어져, 외부의 자극을 입력 받은 터치 판넬, 오디오코덱부와 터치판넬을 통해 입력되는 음성신호와 외부자극을 저 장하는 램, 오디오 코덱부 및 터치판넬을 통해 입력되는 외부자극과 음성신호를 소정 신호처 리하여 그에 따라 로봇의 행동을 결정한후, 그 로봇의 행동에 대한 명령신호를 피지컬 링크를 통해 모터제어부 에 전송하는 마이크로프로세서로 구성될 수 있다. 피지컬 링크는 I/O버스나 USB, 또는 RS232-C 케 이블로 이루어 질 수 있다. 도 13 및 도 14는 본 발명의 다른 일 실시예에 의한 자가 학습 로봇의 행동 학습 방법을 설명하기 위한 도면들 이다. 도 13에 도시된 바와 같이, 자가 학습 로봇의 행동 학습 방법은 네트워크를 통해 다른 로봇의 행동패턴을 받아 들이는 제1 과정, 제1 과정의 행동패턴과 연관되는 행동들에 대한 행동선택 확률을 임시로 높여 해당 행동 을 발현하는 제2 과정, 사용자의 반응이 우호적인지를 판단하는 제3 과정, 제3 과정의 판단결과, 사용자의 반응 이 우호적이면 연관될 행동들에 대한 행동 선택 확률을 증가시키는 제4 과정으로 이루어질 수 있다. 예를 들어, 로봇은 내부 상태에 따라 행동을 선택할 수 있는 행동 선택 과정 (Behavior Selection)을 갖는데, 내부상태는 노여움, 즐거움, 놀라움등의 감정 (Emotion)과 식욕, 성욕등의 욕구(Motivation)으로 이루어질 수 있다. 행동 선택 과정은 마이크로프로세서에서 비주기적으로 이루어지고, 선택된 로봇의 동작정보는 로봇의 정 지자세를 특정한 시간 간격으로 나타낸 것으로 근사하는데, 이는 정화상을 연속으로 재생하여 동화상을 구현하 는 영화나 동화 (Animation)의 원리와 같을 수 있다. 단, 영화가 화상정보로 표현되듯이 로봇의 정지자세는 로 봇이 가지고 있는 모든 관절(Joint)의 현재 지시값으로 나타내는데, 회전관절은 현재 지시값이 각도 이고, 직동 관절은 현재 지시값이 변위가 될 수 있다. 이때, 로봇의 정지자세를 나타내는 모든 관절의 지시값을 프레임 (Frame)으로 정의하고, 프레임을 시계열(Time Series)로 작성한 것을 동작정보로 정의할 수 있다. 본 발명의 동 작을 설명하면, 우선 현재의 기계적 장치로 실행가능한 로봇의 행동들을 분석한후, 각 행동의 연결 비율을 기설 정하여 Commom-Sense Stereotype DB를 구현하는데, 그 Commom-Sense Stereotype DB는 임의의 행동간의 연결비 율을 조정하기 위해, 특정 항목을 수정하거나 추가한다. Commom-Sense Stereotype DB는, 무선랜이나 RS232C케이 블로 피씨로 연결되어, 사용자가 행동간의 연결비율을 조정하기 위해 내용을 교체할 수 있다. 예를 들어, 로봇의 행동중에 짖는 행동이나 땅을 파는 행동등은 강아지와 유사한 행동으로 묶을 수 있고, 경례 하는 행동이나 부동자세등은 군인과 유사한 행동으로 묶어 놓을 수 있다. 이때, 로봇은 네트워크를 통해 다른 로봇의 행동패턴을 받아들여 그 행동패턴과 연관되는 행동들에 대한 행동 선택 확률을 높여 해당 행동을 발현할 수 있다. 무선랜을 통해 다른 로봇의 행동패턴을 받아들여 이를 참조하여 로봇의 행동 선택 확률을 조정함으로 써, 다른 로봇의 행동패턴을 흉내낼 수 있다. 그 다음, 다른 로봇의 행동패턴을 사용자가 호의적으로 받아들이 는지를 판단하여 자신의 행동패턴으로 결정할지를 판단할 수 있다. 즉, 사용자에 의해, 피드백 외부입력이 있으면, 그 외부 입력이 사용자의 칭찬 또는 꾸중인지를 판별하여 사용 자의 호감도를 판단할 수 있다. 이때, 터치센서를 통한 사용자의 입력으로 칭찬 또는 꾸중을 판단하는데, 사용 자에 의해 피드백 받는 터치센서가 어느 부위에 있는지로 칭찬인지 꾸중인지를 구별하거나, 사용자에 의한 터치 스크린의 눌림 지속시간에 따라 칭찬인지 꾸중인지를 구별할 수 있다. 칭찬 또는 꾸중을 판단하는 다른 방법으로, 칭찬과 꾸중에 해당되는 단어를 저장한 단어 데이터 베이스와 사용 자의 음성입력을 비교하여 꾸중 또는 칭찬을 판단할 수 있다. 만약, 피드백된 외부의 입력이 사용자의 칭찬 또는 꾸중이면, 해당 행동 선택 확률을 증가 또는 감소시킬 수있 다다. 즉, 피드백된 외부의 입력이 사용자의 칭찬이면, 현재 저장되어 있는 관절 지시값의 시계열 데이터를 이 용하여 현재 로봇 행동을 인식한후, 그 인식된 로봇행동의 발현 확률을 특정값 만큼 증가시켜 다른 로봇의 행동 패턴을 자신의 행동패턴으로 학습하고, 피드백된 외부의 입력이 사용자의 꾸중이면, 현재 저장되어 있는 관절 지시값의 시계열 데이터를 이용하여 현재 로봇 행동을 인식한후, 그 인식된 로봇 행동의 발현 확률을 특정값 만 큼 감소시킬 수 있다. 만약, 사용자가 정한 규칙 사항이 무선랜을 통해 받아 들여지면 상술한 방법으로 행동 선 택 확률값을 조정하여 사용자의 규칙사항에 따른 행동을 보여주고, 이에 대해 사용자가 만족하는지를 칭찬 또는꾸중으로 인식하여 자신의 행동 패턴으로 받아들일지 결정한다. 여기서, 다른 로봇의 행동패턴과 연관된 행동들 이 있으면, 그 연관된 행동들에 대한 선택 확률을 증가 또는 감소시키는데, 칭찬과 연관된 행동의 경우에는 발 생 확률을 증가시키고, 꾸중과 연관된 행동의 경우에는 발생 확률을 감소시킬 수 있다. 보다 상세하게 도 14를 참조하여 설명하면, 행동선택과정은, Emotion Modeling부의 상태에 따라 각 동작들의 발 현 확률을 설정하고, 그 설정된 발현확률에 따라 수행할 동작을 결정하는데, 상기 Emotion Modeling부는 외부 입력과 로봇의 행동 수행상황을 종합하여 지속적으로 갱신될 수 있다. 이렇게, 로봇이 정상적으로 동작하고 있 을 때, 터치센서 또는 마이크를 통해 외부의 자극이 입력되면 이를 램에 저장하고, 피드백 프로세싱부는 그 입 력이 사람의 칭찬 또는 꾸중인지를 판단하는데, 만약, 사람의 칭찬 또는 꾸중이 아니라고 판단되면 램에 저장된 외부입력은 사용되지 않고, 계속하여 행동 선택과정을 수행할 수 있다. 반대로, 칭찬 또는 꾸중이라고 판단되면, 기저장되어 있는 관절 지시값의 시계열 데이터를 이용하여 현재 로봇의 행동이 무엇인지를 알아내어 그 행동의 발현확률을 칭찬 또는 꾸중에 맞게 특정값 만큼 증가 또는 감소시킨후, 그 행동의 발현확률을 저장할 수 있다. 이후, 마이크로프로세서는 칭찬 또는 꾸중의 피드백을 받은 로봇의 해당 행동과 연관된 행동들이 있는지를 Commom-Sense Stereotype DB를 이용하여 판단하는데, 관된 행동들이 있을 경우에는 해당 행동의 차후 발현 확률 을 칭찬 또는 꾸중에 맞게 증가 또는 감소시켜 저장한후, 상기 행동선택과정을 지속적으로 계속하는 자율모드로 복귀할 수 있다. 한편, 무선랜을 통해 다른 로봇의 행동패턴이 받아들여지면, 해당 행동의 발현 확률을 임시로 조정할 수 있다. 예를 들어, 현재 로봇의 행동 패턴은 장애물을 만났을때 무조건 왼쪽으로 피하는 방식이고, 새 롭게 무선랜을 통해 받아들여진 행동패턴은 장애물을 만났을때, 왼쪽,오른쪽을 둘러보고 장애물이 없는 쪽으로 피하는 방식이라고 가정하며, 로봇은 무선랜을 통해 들어온 방식인 좌우를 둘러보고 회피 방향을 정하는 일련의 행동 발현 확률을 임의로 높일 수 있다. 이렇게 높아진 확률에 의해서 새로운 방식이 선택되어 실행되었을 때, 이를 사용자가 칭찬해 주면 앞으로 장애 물을 발견했을때는 좌우를 둘러보고 방향을 선택하는 방식의 확률을 확정적으로 높여주게 될 수 있다. 또한,사 용자가 PC를 이용해 장애물이 있을 때는 360도 회전하면서 장애물이 없는 곳을 찾아서 그 방향으로 전진하라는 규칙을 만들어 전송하면, 상술한 방식과 같이 임의로 상기 규칙에 대한 행동발현 확률을 상향 조정하여 사용자 의 반응을 파악한 다음에 해당 행동의 차후 확률을 결정할 수 있다. 도 12 내지 도 14에서 설명한 행동 학습 방법을 이용하여, 자가 학습 로봇은 특정 사물에 대응하는 사물 대응 행동을 학습할 수 있다. 도 15 내지 도 21에서 설명하는 자가 학습 로봇은 일 예로서 로봇 청소기를 도시한 것이다. 도 15 내지 도 21에 대해서는 로봇 청소기를 기준으로 설명하나, 로봇 청소기가 아닌 기타 다른 로봇 장치들에 모두 적용 가능하다. 도 15는 본 발명의 또 다른 일 실시예에 의한 자가 학습 로봇의 일 부분을 도시한 사시도이고, 도 16은 본 발명 의 또 다른 일 실시예에 의한 자가 학습 로봇의 구성을 개략적으로 그린 블록도이다. 도 15 및 도 16을 참조하면, 또 다른 일 실시 예에 따른 자가 학습 로봇은, 외관을 형성하는 본체, 광 패턴 센서, 제어 유닛을 포함하여 구성될 수 있다. 광 패턴 센서는 본체의 전면에 구비되고, 광 패턴을 조사하고 패턴 영상을 출력한다. 도 16에 도시 한 바와 같이, 광 패턴 센서는, 본체의 전방으로 하나 이상의 십자형의 상기 광 패턴을 조사하는 광원 모듈과, 광 패턴이 조사된 영역의 패턴 영상을 촬영하는 카메라 모듈을 포함한다. 광원 모듈 은 레이저 다이오드(Laser Diode; LD), 발광다이오드(Light Emitting Diode; LED) 등을 포함한다. 광 패 턴 센서는 광원 모듈 이외에 필요에 따라 별도의 조명을 더 포함할 수 있다. 카메라 모듈은 광 패 턴 센서에 하나만 구비되거나, 둘 이상으로 구비될 수 있다. 카메라 모듈은 구조 광 카메라(Structured Light Camera)이고, 광 패턴 센서는 레이저 비전 센서(Laser Vision Sensor)를 포함한다. 광 패턴 센서는 광원 모듈의 전단에 연결되어 광원 모듈로부터 조사되는 광 패턴 중 일정 주파수만 통과하도록 하는 필터를 더 포함 할 수 있다. 광 패턴은 십자형 광 패턴이 하나 또는 그 이상의 조합일 수 있으나, 수직 패턴의 길이보다 수평 패턴의 길이가 더 길게 형성된 비대칭 십자형 광 패턴인 것이 좋다. 즉, 상기 광 패턴 센서는, 수직 패턴의 길이보다 수 평 패턴의 길이가 더 길게 형성된 비대칭 십자형 광 패턴을 조사한다. 수직 패턴과 수평 패턴의 길이를 동일하 게 하거나, 수직 패턴의 길이를 상대적으로 더 길게 할 수 있다. 그러나, 수평 패턴은 넓은 범위에 대하여 장애 물을 스캔할 수 있도록 하는 반면, 수직 패턴은 이동 로봇의 이동에 필요한 정도로만 설정하면 되므로, 수평 패턴의 길이보다 수직 패턴의 그것이다소 짧을 수 있다. 또, 수직 패턴 및 수평 패턴의 조합은 여러 개일 수 있 고, 하나의 수평 패턴의 복수의 수직 패턴이 결합할 수도 있다. 여기서, 광 패턴이 원뿔 모양으로 조사되는 경 우에, 각 패턴의 가장 긴 부분, 예를 들어 원의 지름이나 타원의 장축이 수평 패턴 및 수직 패턴의 길이가 될 수 있다. 도 16을 참조하면, 제어 유닛은, 패턴 영상을 영상 처리하여 상기 장애물을 인식하는 장애물 인식 모듈 을 포함할 수 있다. 장애물 인식 모듈은, 수평 패턴에 대한 패턴 영상을 이용하여 장애물의 유무뿐 만 아니라 장애물의 폭을 인식할 수 있다. 예를 들어 이동 로봇이 이동하면서 연속적으로 광 패턴을 조사한 다 음, 수평 패턴이 구부러지는 시각이나 정도 등에 따라 장애물의 폭을 인식할 수 있다. 또, 장애물 인식 모듈 은, 수평 패턴에 대한 패턴 영상으로부터 장애물의 높이도 인식할 수 있다. 예를 들어, 장애물이 존재하 지 아니하는 패턴 영상에서의 수평 패턴의 위치를 기억한 다음, 장애물에 의해 수평 패턴이 이동한 거리를 산출 하여 장애물의 높이도 인식할 수 있다. 다만, 수평 패턴만을 이용하는 경우, 인식할 수 있는 장애물의 높이에 한계가 있을 수 있고, 오인식의 여지가 있다. 따라서, 장애물 인식 모듈은 수직 패턴을 이용하거나, 수직 패턴 및 수평 패턴을 함께 이용하여 장애물의 높이를 더욱 정밀하게 인식할 수 있다. 도 17 내지 도 19는 본 발명의 또 다른 일 실시예에 의한 자가 학습 로봇이 장애물 검출 결과에 따라 수행하는 동작을 설명하기 위한 도면들이다. 도 17은 장애물이 일정 높이 이상의 다리를 가진 의자인 경우이다. 자가 학습 로봇은 다리와 다리 사이를 피하 여 이동할 수 있고, 다리가 일정 높이를 가지므로 의자 아래를 통과하여 이동할 수 있다. 도 18은 장애물이 낮 은 문턱인 경우이다. 자가 학습 로봇은, 광 패턴을 전방에 조사한 다음 문턱을 인식하고, 인식 결과, 통과할 수 있다고 판단하면, 문턱을 넘어서 이동할 수 있다. 도 19는 장애물이 침대 프레임인 경우이다. 자가 학습 로봇은, 역시 광 패턴 조사 후의 패턴 영상으로부터 침대 프레임을 인식하고, 인식 결과 통과하기에 높이가 너 무 낮은 것으로 판단하면, 침대 프레임을 우회하여 이동할 수 있다. 이에 따라 침대와 같은 가구나, 전자제품 등 적은 틈을 가진 장애물에 끼이는 사고를 방지할 수 있다. 자가 학습 로봇은, 주변을 촬영하여 영상 정보를 출력하는 영상 검출 유닛을 더 포함하여 구성될 수 있다. 여기 서, 제어 유닛은, 영상 검출 유닛으로부터 출력된 영상 정보를 이용하여 자가 학습 로봇의 위치를 인식하 는 위치 인식 모듈을 더 포함하여 구성될 수 있다. 또, 제어 유닛은 인식된 위치를 이용하여 주변 지도를 생성 하는 지도 생성 모듈을 더 포함할 수 있다. 도 20은 본 발명의 또 다른 일 실시예에 의한 자가 학습 로봇의 다른 구성을 개략적으로 그린 블록도이다. 도 20을 참조하면, 또 다른 실시 예에 따른 자가 학습 로봇은, 외관을 형성하는 본체, 구동 유닛, 광 패턴 센서 및 제어 유닛을 포함하여 구성될 수 있다. 광 패턴 센서는, 본체의 전면에 구비되고, 본체의 전방으로 하나 이상의 십자형의 광 패턴을 조사 하고 패턴 영상을 출력할 수 있다. 도 20을 참조하면, 광 패턴 센서는, 본체의 전방으로 하나 이상 의 십자형의 광 패턴을 조사하는 광원 모듈과 광 패턴이 조사된 영역의 패턴 영상을 촬영하는 카메라 모 듈을 포함할 수 있다. 또, 광 패턴 센서는, 패턴 영상을 소정 영상 처리하여 장애물을 검출하는 영 상 처리 모듈을 더 포함하여 구성될 수 있다. 즉, 제어 유닛에 장애물 인식 모듈의 형태로 구비될 수 있 으나, 광 패턴 센서에 장애물을 검출할 수 있는 영상 처리 모듈이 구비되도록 할 수 있다. 광 패턴은 십자형 광 패턴이 하나 또는 그 이상의 조합일 수 있으나, 수직 패턴의 길이보다 수평 패턴의 길이가 더 길게 형성된 비대칭 십자형 광 패턴인 것이 바람직하다. 즉, 광 패턴 센서는, 수직 패턴의 길이보다 수평 패턴의 길이가 더 길게 형성된 비대칭 십자형 광 패턴을 조사할 수 있다. 광원 모듈과 카메라 모듈 에 대한 설명은 전술한 설명에 갈음한다. 영상 처리 모듈은 카메라 모듈(들)이 획득한 영상을 소정 처리하여 장애물을 검출할 수 있다. 영상 처리 모듈은 영상으로부터 영역에 조사된 광 패턴의 모양, 면적, 변화 등을 이용하여 장애물을 검출할 수 있다. 영상 처리 모듈은 수직 패턴과 수평 패턴에 대한 패 턴 영상으로부터 장애물의 유무, 장애물의 크기, 폭, 높이 등을 검출할 수 있다. 다른 예로, 영상 처리 모듈은 일정 방향(예를 들어 x 방향)으로의 패턴을 추출한 다음, 이를 다른 축 방향으로 변환하고, 이를 이용하여 장애 물을 검출할 수 있다. 또 두 대의 카메라 모듈을 이용하는 경우, 영상 처리 모듈은 하나의 카메라 모듈이 촬영 한 영상으로부터 수직 성분만, 다른 카메라 모듈이 촬영한 영상으로부터 수평 성분만 추출할 수 있다. 그런 다 음, 영상 처리 모듈은 3차원 패턴을 생성하고 이를 이용하여 장애물을 검출하여 장애물의 크기, 모양 등의 장애물 정보를 제어 유닛에 출력할 수 있다. 광 패턴 센서는 광원 모듈의 전단에 연결되어 광원 모듈로부터 조사되 는 광 패턴 중 일정 주파수만 통과하도록 하는 필터를 더 포함할 수 있다. 제어 유닛은, 패턴 영상으로부 터 장애물을 인식하고, 인식 결과에 따라 구동 신호를 발생한다. 제어 유닛은, 패턴 영상을 영상 처리하 여 장애물을 인식하는 장애물 인식 모듈을 포함할 수 있다. 물론, 제어 유닛은 상기 영상 처리 모 듈로부터 검출된 장애물에 대한 정보를 직접 입력 받아 구동 신호를 발생할 수 있다. 이동 로봇은, 주변 을 촬영하여 영상 정보를 출력하는 영상 검출 유닛을 더 포함하여 구성될 수 있다. 여기서, 제어 유닛은, 영상 검출 유닛으로부터 출력된 영상 정보를 이용하여 이동 로봇의 위치를 인식하는 위치 인식 모듈을 더 포함 하여 구성될 수 있다. 또, 제어 유닛은, 인식된 위치를 이용하여 주변 지도를 생성하는 지도 생성 모듈을 더 포 함할 수 있다. 구동 유닛은, 본체의 하부에 설치된 하나 이상의 바퀴를 구동하는 휠 모터를 구비하고, 구동 신호 에 따라 상기 본체를 이동시킬 수 있다. 자가 학습 로봇은, 하부 양측에 이동 가능하도록 하는 좌, 우측 주 바 퀴를 구비할 수 있다. 주 바퀴의 양 측면에는 사용자의 파지가 용이하도록 손잡이가 설치될 수 있다. 휠 모터(Wheel Motor)는 각각 주 바퀴에 연결되어 주 바퀴가 회전하도록 하고, 휠 모터는 서로 독립적으로 작동하 며 양방향으로 회전이 가능하다. 또, 자가 학습 로봇은, 배면에 하나 이상의 보조 바퀴를 구비하여 본체를 지지 하고, 본체의 하면과 바닥면(floor) 사이의 마찰을 최소화하고 이동 로봇의 이동이 원활하도록 한다. 도 21은 본 발명의 또 다른 일 실시예에 의한 자가 학습 로봇의 제어 방법을 개략적으로 그린 플로우 차트이다. 도 21을 참조하면, 자가 학습 로봇은 이동하거나 정지 중에 전방으로 광 패턴을 조사한다(S2110). 이때, 전술한 바와 같이 광 패턴은 비대칭 십자형 광 패턴인 것이 바람직하다. 그런 다음, 자가 학습 로봇은, 광 패턴이 조사 된 영역에 대하여 패턴 영상을 촬영하여 획득한다(S2120). 패턴 영상을 이용하여, 자가 학습 로봇은, 장애물을 인식한다(S2130). 이때, 자가 학습 로봇은 마이컴 등 제어 유닛을 통해 패턴 영상을 소정 영상 처리하여 장애물 을 인식한다. 물론, 광 패턴 센서 자체에서 장애물을 인식 가능하도록 설계될 수 있다. 예를 들어, 자가 학습 로봇은 수평 패턴을 이용하여 장애 물의 유무, 장애물의 폭, 일정 높이 등을 인식하고, 수직 패턴을 이용하여 정확한 높이를 감지할 수 있다. 자가 학습 로봇은 장애물의 인식 결과를 근거로 장애물을 통과할 수 있는 지 여 부를 판단한다(S2140). 도 17에 도시한 바와 같이, 통과할 수 있는 장애물의 경우에, 자가 학습 로봇은 본체를 전진하여 장애물을 통과한다(S2141). 또, 도 18에 도시한 바와 같이, 넘어갈 수 있는 문턱의 경우에도, 자가 학 습 로봇은 본체를 전진하여 문턱을 넘어간다. 전진이 불가한 경우에, 자가 학습 로봇은 우회 가능한지 판단한다 (S2150). 도 19에 도시한 바와 같이, 장애물을 통과하기에 공간이 적은 경우, 자가 학습 로봇은 이를 우회한다 (S2161). 전진도 우회도 불가한 경우에, 자가 학습 로봇은 정지하거나 후퇴할 수 있다. 이러한 대응 알 고리즘은 사용자 또는 프로그래밍에 의해 달라질 수 있고, 자가 학습 로봇의 사양에 따라 학습 기능이 추가될 수 있다. 자가 학습 로봇은 주변 영상을 촬영하고(S2170), 주변 영상으로부터 특징점 등을 추출하여 특징점을 이용하여 자가 학습 로봇의 위치를 인식할 수 있다(S2180). 또, 인식된 위치를 이용하여, 자가 학습 로봇은 주 변 지도를 생성할 수 있다(S2190). 상기와 같이 설명된 자가 학습 로봇 및 로봇의 자가 학습 시스템은 상기 설명된 실시예들의 구성과 방법이 한정 되게 적용될 수 있는 것이 아니라, 상기 실시예들은 다양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또 는 일부가 선택적으로 조합되어 구성될 수도 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21"}
{"patent_id": "10-2018-0119624", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 의한 로봇의 자가 학습 시스템을 설명하기 위한 블록도이다. 도 2는 본 발명의 일 실시예에 의한 자가 학습 로봇이 사물 인식에 실패하는 경우 자가 학습 하는 방법을 설명 하기 위한 도면이다. 도 3은 본 발명의 일 실시예에 의한 서버가 복수 개의 자가 학습 로봇들로부터 인식 실패 데이터를 수신하는 일 예를 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에 의한 자가 학습 로봇의 송신부 및 수신부가 로봇의 자가 학습을 수행하는 방법을 설명한 도면이다. 도 5는 본 발명의 일 실시예에 의한 서버가 자가 학습 로봇을 학습시키는 방법을 설명한 도면이다. 도 6은 본 발명의 일 실시예에 의한 자가 학습 로봇이 인식 실패 후 데이터 베이스를 갱신하는 제1 실시예를 설 명하기 위한 도면이다. 도 7은 본 발명의 일 실시예에 의한 자가 학습 로봇이 인식 실패 후 데이터 베이스를 갱신하는 제2 실시예를 설 명하기 위한 도면이다. 도 8은 본 발명의 일 실시예에 의한 자가 학습 로봇이 인식 실패 후 데이터 베이스를 갱신하는 제3 실시예를 설 명하기 위한 도면이다. 도 9 내지 도 11은 본 발명의 일 실시예에 의한 자가 학습 로봇이 자가 학습을 수행하기 위해 사용하는 기술들 에 대하여 설명하기 위한 도면들이다. 도 12는 본 발명의 다른 일 실시예에 의한 자가 학습 로봇의 구조를 도시한 블록도이다. 도 13 및 도 14는 본 발명의 다른 일 실시예에 의한 자가 학습 로봇의 행동 학습 방법을 설명하기 위한 도면들 이다. 도 15는 본 발명의 또 다른 일 실시예에 의한 자가 학습 로봇의 일 부분을 도시한 사시도이다. 도 16은 본 발명의 또 다른 일 실시예에 의한 자가 학습 로봇의 구성을 개략적으로 그린 블록도이다. 도 17 내지 도 19는 본 발명의 또 다른 일 실시예에 의한 자가 학습 로봇이 장애물 검출 결과에 따라 수행하는 동작을 설명하기 위한 도면들이다. 도 20은 본 발명의 또 다른 일 실시예에 의한 자가 학습 로봇의 다른 구성을 개략적으로 그린 블록도이다.도 21은 본 발명의 또 다른 일 실시예에 의한 자가 학습 로봇의 제어 방법을 개략적으로 그린 플로우 차트이다."}
