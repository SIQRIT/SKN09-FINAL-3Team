{"patent_id": "10-2023-0128777", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0046058", "출원번호": "10-2023-0128777", "발명의 명칭": "인공지능을 이용한 가상 인물 및 배경 구현 시스템 및 그에 대한 방법", "출원인": "주식회사 아리아스튜디오", "발명자": "채수응"}}
{"patent_id": "10-2023-0128777", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능을 이용한 가상 인물 구현 시스템에 있어서,외부로부터 학습 데이터를 입력받는 입력 장치;상기 인공지능을 이용하여 상기 입력된 학습 데이터에 내포된 감정, 동작 및 언어를 분석하여 가상 인물에 적용되는 세계관 데이터를 생성하는 세계관 데이터 생성 장치;상기 세계관 데이터에 기초하여, 상기 입력된 학습 데이터에 대응하는 상기 가상 인물의 감정을 생성하는 감정생성 장치;상기 세계관 데이터에 기초하여, 상기 입력된 학습 데이터에 대응하는 상기 가상 인물의 동작을 생성하는 동작생성 장치;상기 생성된 감정 및 동작을 합성하는 제1 합성 장치;외부로부터 상기 가상 인물의 특성을 입력 받아, 상기 입력된 특성에 부합하는 가상 인물을 생성하는 가상 인물생성 장치;상기 생성된 가상 인물에 제1 합성 장치로부터 합성된 감정 및 동작을 합성하는 제2 합성 장치; 상기 제2 합성 장치에서 합성된 감정 및 동작에 기반하여 긴장도 벡터 값을 생성하고, 긴장도 벡터 값에 기반하여 백그라운드 그래픽 정보 및 오브제 그래픽 정보를 생성하는 배경 생성 장치; 및상기 제2 합성 장치 및 배경 생성 장치를 기반으로 생성된 동적 가상 인물을 제공하는 출력 장치를 포함하는 인공지능을 이용한 가상 인물 구현 시스템."}
{"patent_id": "10-2023-0128777", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 배경 생성 장치는,상기 백그라운드 그래픽 정보 및 상기 오브제 그래픽 정보를 기반으로 상기 세계관 데이터를 업데이트 하는 것을 특징으로 하는 인공지능을 이용한 가상 인물 구현 시스템."}
{"patent_id": "10-2023-0128777", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 배경 생성 장치는,상기 입력 장치로 입력되는 입력 데이터에 기반하여 상기 긴장도 벡터 값을 생성하는 것을 포함하는 인공지능을이용한 가상 인물 구현 시스템."}
{"patent_id": "10-2023-0128777", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 긴장도 벡터 값은,상기 입력 데이터의 단어 종류 및 문장 종류에 기반하여 긴장감 및 편안함을 값으로 하는 2차원 값인 것을 특징으로 하는 인공지능을 이용한 가상 인물 구현 시스템."}
{"patent_id": "10-2023-0128777", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,공개특허 10-2024-0046058-3-상기 배경 생성 장치는,상기 긴장도 벡터 값을 공간적으로 연속되는 하나의 장면에 대하여 할당하는 것을 특징으로 하는 인공지능을 이용한 가상 인물 구현 시스템."}
{"patent_id": "10-2023-0128777", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 배경 생성 장치는,상기 긴장도 벡터 값 및 복수의 컬러 세트들 중 하나의 컬러 세트에 기반하여 백그라운드 그래픽 정보를 조정하고, 상기 긴장도 벡터 값에 기반하여 복수의 오브제 세트들 중 하나의 오브제 세트를 선택하여 오브제 그래픽정보를 생성하는 것을 특징으로 하는 인공지능을 이용한 가상 인물 구현 시스템."}
{"patent_id": "10-2023-0128777", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 배경 생성 장치는,산출된 상기 긴장도 벡터 값이 제1 긴장도 벡터 기준 값 보다 높은 경우에 제1 컬러 세트에 기반하여 상기 백그라운드 그래픽 정보의 색상을 조절하고, 산출된 상기 긴장도 벡터 값이 제2 긴장도 벡터 기준 값 보다 높은 경우에 제1 오브제 세트를 선택하여 상기 오브제 그래픽 정보를 생성하는 것을 특징으로 하는 인공지능을 이용한가상 인물 구현 시스템."}
{"patent_id": "10-2023-0128777", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능을 이용한 가상 인물 구현 시스템에 있어서, 외부로부터 학습 데이터를 입력받는 입력 장치, 상기 인공 지능을 이용하여 상기 입력된 학습 데이터에 내포된 감정, 동작 및 언어를 분석하여 가상 인물에 적용되는 세계 관 데이터를 생성하는 세계관 데이터 생성 장치, 상기 세계관 데이터에 기초하여, 상기 입력된 학습 데이터에 대 (뒷면에 계속)"}
{"patent_id": "10-2023-0128777", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 기술적 사상은 인공지능을 이용한 가상 인물 구현 시스템 및 그데 대한 방법에 관한 것으로, 구체적 으로 입력되는 학습 데이터에 내포되어 있는 감정 및 동작을 분석하고, 분석된 감정 및 동작으로 가상 인물을 구현하는 가상 인물 구현 시스템 및 그 방법과 상기 방법을 실현시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체에 관한 것이다."}
{"patent_id": "10-2023-0128777", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간이나 가상 인물의 동작과 제스처, 음성이나 자연어 입력 문장을 통하여 기계적으로 컴퓨터가 인간이나 가상 인격체가 전달하고 싶은 감정을 분석한다는 것은 정말 난해한 문제이다. 최근 인공지능 기술의 발달로 인공지능을 이용한 자연어 처리 기술, 음성 처리 기술과 그래픽 처리 기술을 이용 한 가상 인물이 콘텐츠 시장에서 각광을 받고 있다. 이때, 이러한 가상 인물 기술에서 그래픽 처리 기술은 Style Transfer, StyleGAN, ObamaNet과 같은 GAN 기술의 발달로 버츄어 휴먼의 그래픽을 상당히 자연스럽게 서 비스할 수 있게 되었고, 음성 처리 기술은 Tacotron, Attention is all you need 등의 딥러닝 음성 합성 기술 의 발달로 가상 인물의 음성을 자연스럽게 서비스할 수 있게 되었다. 하지만, 가상 인물의 인터렉션과 관련된 기술은 그래픽 처리 기술이나 음성 처리 기술에 비해 그 진보가 미약한 상황이다."}
{"patent_id": "10-2023-0128777", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 사상은 인공지능을 이용한 가상 인물 구현 시스템 및 그데 대한 방법은 인공지능을 활용함으 로써 실시간으로 표정 및 동작 변화에 대응할 수 있는 가상 인물을 제공하는데 있다."}
{"patent_id": "10-2023-0128777", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "인공지능을 이용한 가상 인물 구현 시스템에 있어서, 외부로부터 학습 데이터를 입력받는 입력 장치, 상기 인공 지능을 이용하여 상기 입력된 학습 데이터에 내포된 감정, 동작 및 언어를 분석하여 가상 인물에 적용되는 세계 관 데이터를 생성하는 세계관 데이터 생성 장치, 상기 세계관 데이터에 기초하여, 상기 입력된 학습 데이터에대응하는 상기 가상 인물의 감정을 생성하는 감정 생성 장치, 상기 세계관 데이터에 기초하여, 상기 입력된 학 습 데이터에 대응하는 상기 가상 인물의 동작을 생성하는 동작 생성 장치, 상기 생성된 감정 및 동작을 합성하 는 제1 합성 장치, 외부로부터 상기 가상 인물의 특성을 입력 받아, 상기 입력된 특성에 부합하는 가상 인물을 생성하는 가상 인물 생성 장치, 상기 생성된 가상 인물에 제1 합성 장치로부터 합성된 감정 및 동작을 합성하는 제2 합성 장치, 상기 제2 합성 장치에서 합성된 감정 및 동작에 기반하여 긴장도 벡터 값을 생성하고, 긴장도 벡터 값에 기반하여 백그라운드 그래픽 정보 및 오브제 그래픽 정보를 생성하는 배경 생성 장치 및 상기 제2 합 성 장치 및 배경 생성 장치를 기반으로 생성된 동적 가상 인물을 제공하는 출력 장치를 포함할 수 있다. 또한, 상기 배경 생성 장치는, 상기 백그라운드 그래픽 정보 및 상기 오브제 그래픽 정보를 기반으로 상기 세계 관 데이터를 업데이트 하는 것을 특징으로 할 수 있다. 또한, 상기 배경 생성 장치는, 상기 입력 장치로 입력되는 입력 데이터에 기반하여 상기 긴장도 벡터 값을 생성 하는 것을 포함할 수 있다. 또한, 상기 긴장도 벡터 값은, 상기 입력 데이터의 단어 종류 및 문장 종류에 기반하여 긴장감 및 편안함을 값 으로 하는 2차원 값일 수 있다. 또한, 상기 배경 생성 장치는, 상기 긴장도 벡터 값을 공간적으로 연속되는 하나의 장면에 대하여 할당하는 것 을 특징으로 할 수 있다. 한편, 상기 배경 생성 장치는, 상기 긴장도 벡터 값 및 복수의 컬러 세트들 중 하나의 컬러 세트에 기반하여 백 그라운드 그래픽 정보를 조정하고, 상기 긴장도 벡터 값에 기반하여 복수의 오브제 세트들 중 하나의 오브제 세 트를 선택하여 오브제 그래픽 정보를 생성하는 것을 특징으로 할 수 있다. 또한, 상기 배경 생성 장치는, 산출된 상기 긴장도 벡터 값이 제1 긴장도 벡터 기준 값 보다 높은 경우에 제1 컬러 세트에 기반하여 상기 백그라운드 그래픽 정보의 색상을 조절하고, 산출된 상기 긴장도 벡터 값이 제2 긴 장도 벡터 기준 값 보다 높은 경우에 제1 오브제 세트를 선택하여 상기 오브제 그래픽 정보를 생성하는 것을 특 징으로 할 수 있다."}
{"patent_id": "10-2023-0128777", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 기술적 사상에 따른 인공지능을 이용한 가상 인물 구현 시스템 및 그에 대한 방법은 인공지능을 활용 함으로써 가상 인물이 실제 사람과 같이 표정 변화 또는 동작 변화를 수행할 수 있고, 실시간으로 표정 및 동작 변화에 대응할 수 있다."}
{"patent_id": "10-2023-0128777", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부된 도면에서, 동일하거나 대응하는 구성요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예들 의 설명에 있어서, 동일하거나 대응하는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나 구성요소 에 관한 기술이 생략되어도, 그러한 구성요소가 어떤 실시예에 포함되지 않는 것으로 의도되지는 않는다. 본 개시의 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 개시의 전체에서 어떤 부분이 어떤 구성요소를 '포함'한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 '모듈' 또는 '부'라는 용어는 소프트웨어 또는 하드웨어 구성요소를 의미하며, '모 듈' 또는 '부'는 어떤 역할들을 수행한다. 그렇지만 '모듈' 또는 '부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '모듈' 또는 '부'는 어드레싱 할 수 있는 저장 매체에 있도록 구성될 수 도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수 있다. 따라서, 일 예로서 '모듈' 또는 '부'는 소프트웨어 구성요 소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세 스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 모듈, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 또는 변수들 중 적어도 하나를 포함할 수 있다. 구성요소들과 '모듈' 또는 '부'들은 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '모듈' 또 는 '부'들로 결합되거나 추가적인 구성요소들과 '모듈' 또는 '부'들로 더 분리될 수 있다. 이하, 첨부한 도면을 참조하여 본 개시의 실시예에 대해 상세히 설명한다. 도 1은 본 개시의 예시적인 실시예에 따른 가상 인물 동작 구현 시스템을 나타내는 블록도이다. 도 1을 참조하면, 인공지능을 이용한 가상 인물 구현 시스템은 입력 장치, 세계관 데이터 생성 장치 , 감정 생성 장치, 동작 생성 장치, 제1 합성 장치, 가상 인물 생성 장치, 제2 합성 장치 및 출력 장치를 포함할 수 있다. 입력 장치는 외부로부터 학습 데이터를 입력 받을 수 있다. 학습 데이터는 동작 데이터 및 자연어 데이터 등을 포함할 수 있다. 도 1에는 도시하지 않았으나, 입력 장치는 동작 데이터 입력부 및 자연어 데이터 입 력부를 포함할 수 있다. 입력 장치는 학습 데이터를 입력 받고, 이를 세계관 데이터 생성 장치에 제 공할 수 있다. 여기서 학습 데이터란, 시나리오가 존재하는 영상물에 나타나는 컨텍스트(context) 정보 및 상기 컨텍스트 정보를 포함하는 동영상 데이터를 기반으로 생성된 데이터일 수 있다. 컨텍스트 정보에는 감정, 동작 및 언어에 대한 정보를 포함할 수 있다. 이로써, 가상 인물이 존재하게 될 컨텍스트(즉, 상황)를 새롭게 구성하 는 데이터일 수 있다. 예를 들어, 입력 장치는 동작 데이터만이 수신된 경우에는 뉴로퍼지(Neuro-Fuzzy) 추론을 통해 감정을 분 석할 수 있고, 감정 강도를 계산할 수 있다. 입력 장치는 동작 데이터 및 자연어 데이터가 동시에 수신된 경우에는 동작 데이터로 분석한 감정과 자연어 데이터를 이용해 분석한 감정을 상호 보정할 수 있다. 입력 장치 는 자연어 데이터만이 수신된 경우에는 자연어 데이터가 문서인가 문장인가를 판단할 수 있다. 문서인 경"}
{"patent_id": "10-2023-0128777", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "우에는 요약 과정을 통해 문장을 추출할 수 있고, 문장인 경우에는 곧바로 자연어를 분석할 수 있다. 세계관 데이터 생성 장치는 입력 장치로부터 학습 데이터를 제공받을 수 있다. 세계관 데이터 생성 장치는 인공지능을 이용하여 입력된 학습 데이터에 내포된 감정, 동작 및 언어 등을 분석하여 가상 인물에 게 적용될 세계관 데이터를 생성할 수 있다. 세계관 데이터 생성 장치의 구체적인 구성 및 기능에 대해서 는 이하 도 2 및 도 3을 참조하여 후술하도록 한다. 감정 생성 장치는 세계관 데이터에 기초하여 입력된 학습 데이터에 댕응하는 가상 인물의 감정을 생성할 수 있다. 감정 생성 장치는 세계관 데이터 생성 장치로부터 제공받은 세계관 데이터를 기초로 가상 인물의 감정을 생성할 수 있다. 감정 생성 장치는 자연어 데이터에 포함된 감정을 분석할 수 있고, 감정의 강도를 계산할 수 있다. 예를 들어, 감정 생성 장치는 자연어 데이터에 포함되어 있는 감정 표현에 대한 의미를 파악한 후, 문장에 내재된 감정을 분석할 수 있다. 감정 생성 장치는 감정을 분석하는 감정 분석부 및 감정의 강도를 계산하는 감정 강도 계산부를 포함할 수 있다. 동작 생성 장치는 세계관 데이터에 기초하여 입력된 학습 데이터에 대응하는 가상 인물의 동작을 생성할 수 있다. 동작 생성 장치는 세계관 데이터 생성 장치로부터 제공받은 세계관 데이터를 기초로 가상 인물의 동작을 생성할 수 있다. 동작 생성 장치는 동작 데이터에 포함된 동작을 분석할 수 있고, 분석된 동작 결과를 이용하여 자연어 데이터에 부합하는 동작을 생성할 수 있다. 예를 들어, 동작 생성 장치는 자연어 입력 문장에서 동작을 추출하는 동작 분석부와 추출된 동작을 바탕으로 자연어 입력 문장에 제스처와 동작을 할 당하는 동작 생성부를 포함할 수 있다. 동작 생성 장치의 구체적인 구성 및 기능에 대해서는 이하 도 4를 참조하여 후술하도록 한다. 제1 합성 장치는 감정 생성 장치에서 생성된 감정 및 동작 생성 장치에서 생성된 동작을 합성할 수 있다. 예를 들어, 제1 합성 장치는 문장을 음성으로 출력하거나 문자로 출력하면서 얼굴 표정, 동작,제스처 등으로 표현할 수 있고, 얼굴 표정, 동작, 제스처, 음성 등의 감정 강도를 조절할 수 있다. 가상 인물 생성 장치는 외부로부터 가상 인물의 특성을 수신함으로써, 수신된 특성에 부합하는 가상 인물 을 생성할 수 있다. 가상 인물의 특성은 얼굴, 신체 특성을 포함할 수 있다. 예를 들어, 가상 인물 생성 장치 는 가상 인물을 표현하기 위해서 가상 인물의 얼굴 특징 및 여러가지 신체적 특성(신체 사이즈)를 제대로 표현하는 기능을 할 수 있다. 제2 합성 장치는 가상 인물 생성 장치에서 생성된 가상 인물을 수신할 수 있고, 제1 합성 장치 에서 생성된 합성된 감정 및 동작을 수신할 수 있다. 제2 합성 장치는 가상 인물에 합성된 감정 및 동작을 합성할 수 있다. 예를 들어, 제2 합성 장치는 가상 인물에 세계관 데이터에 기초하여 생성된 감정 및 동작 을 합성하여 가상 인물이 실시간으로 움직이고 동작할 수 있게끔 한다. 가상 인물이 감정을 표현할 수 있고, 실 시간으로 얼굴 표정과 제스처, 동작 등을 변화시킬 수 있는 애니메이션 기능을 할 수 있다. 배경 생성 장치는 자연어 분석의 결과 생성된 의미 정보 등을 이용하여 배경 그래픽 세트를 실시간으로 변 동시킴으로써, 가상 인물과 배경 그래픽의 상호 연동이 가능하게 할 수 있다. 예를 들어, 배경 생성 장치 는 자연어 입력 정보를 이용하여 가상 인물의 얼굴표정, 제스처, 몸동작을 실시간으로 제어할 수 있다. 배경 생 성 장치는 언어 정보를 분석하여 배경 그래픽 세트를 실시간으로 변동함으로써, 가상 인물의 변화시킴으로 써, 가상 인물과 배경 그래픽의 상호 연동을 할 수 있다. 배경 생성 장치는 배경 분석을 할 수 있는데, 배 경 분석은 시간적 배경과 공간적 배경을 포함할 수 있다. 시간적 배경은 시간을 나타내는 숫자나 단어가 단독으 로 쓰일 때를 포함할 수 있고, 자연어 입력문장에서 공간적 배경 분석은 육하원칙의 구성요소를 추출해내는 것 에 해당할 수 있다. 본 개시의 예시적 실시예에 따르면, 배경 생성 장치는 제2 합성 장치에서 합성된 감정 및 동작에 기 반하여 긴장도 벡터 값을 생성하고, 긴장도 벡터 값에 기반하여 백그라운드 그래픽 정보 및 오브제 그래픽 정보 를 생성하며, 생성된 그래픽 정보를 이용하여 세계관 데이터를 업데이트할 수 있다. 벡터 값은 예컨대, C++ 환 경에서 std::vector와 같은 유클리디언 벡터 형태로 구현될 수 있다. 먼저, 배경 생성 장치는 서로 반대되는 두 개의 성질을 갖는 2차원의 긴장도 벡터 값을 생성할 수 있다. 예컨대, 두 개의 성질은 긴장감과 편안함을 포함할 수 있다. 배경 생성 장치는 제2 합성 장치가 합성 한 감정 및 동작을 유래한 입력 데이터(예컨대, 입력 장치가 입력받은 학습 데이터 또는 가상 인물에게 할당되 는 대사에 관한 데이터)의 단어 종류 및 문장 종류에 따라 긴장도 벡터 값을 생성할 수 있다. 예컨대, 합성된 감정 및 동작을 유래한 입력 데이터의 대사에 의문문 및 명령문의 빈도가 평서문 및 청유문 보다 높은 경우에 배경 생성 장치는 긴장도 벡터 값을 높일 수 있으며, 유사하게, 부정 어휘의 빈도가 긍정 어휘 보다 높은 경우에는 긴장도 벡터 값을 높일 수 있다. 배경 생성 장치는 시나리오에서 공간적으로 연속되는 하나의 장면에 대하여 긴장도 벡터 값을 할당할 수 있다. 예컨대, 배경 생성 장치는 지하 공간 및 공원에서 펼쳐지는 장면에 대해 각각 서로 다른 2차원 값을 갖는 제1 긴장도 벡터 값 및 제2 긴장도 벡터 값을 할당할 수 있다. 배경 생성 장치는 장면 마다 긴장도 벡터 값을 달리 할당하여 극의 분위기를 달리 전환할 수 있따. 배경 생성 장치는 긴장도 벡터 값에 기반하여 백그라운드 그래픽 정보 및 오브제 그래픽 정보를 생성할 수 있다. 여기서, 백그라운드 그래픽 정보란, 생성된 가상 인물이 상호작용할 수 없는 그래픽 정보를 의미하며 예 컨대 하늘에 대한 색채 및 형상 정보를 포함할 수 있고, 오브제 그래픽 정보란, 생성된 가상 인물이 상호작용할 수 있는 그래픽 정보를 의미하며 예컨대 의자에 대한 색채 및 형상 정보를 포함할 수 있다. 배경 생성 장치는 긴장도 벡터 값에 기반하여 복수의 컬러 세트들 중 하나의 컬러 세트에 기반하여 백그라 운드 그래픽 정보를 조정할 수 있다. 배경 생성 장치는 산출된 긴장도 벡터 값이 기설정된 제1 긴장도 벡 터 기준 값보다 높은 값을 갖는 경우, 채도가 낮은 제1 컬러 세트를 불러오고, 기존의 백그라운드 그래픽 정보 의 컬러들을 제1 컬러 세트의 색상 영역을 향하도록 조정할 수 있다. 예컨대, 백그라운드 그래픽 정보가 CMYK 컬러 코드로 구현된 경우, 배경 생성 장치는 각각 시안(C), 마젠타(M), 옐로(Y), 블랙(K)의 요소 컬러들의 값을 제1 컬러 세트(예컨대, 시안 값 5~10, 마젠타 값 2~5, 옐로 값 32~36, 블랙 값 21~23을 갖는 컬러들의 세 트)에 근접해지도록 조정할 수 있다. 이로써, 배경 생성 장치는 긴장도 벡터 값에 따라 어두운 분위기의 배경을 연출할 수 있다. 다시 말해, 배경 생성 장치는 백그라운드 그래픽 정보의 색채를 변화시킬 수 있다. 이에 한정되지는 않으며, 배경 생성 장치는 백그라운드 그래픽 정보의 형상(예컨대, 구름의 모양)도 변화시킬 수 있으나, 바람직하게는 색채 변화를 주로 수행할 수 있다.이와 반대로, 배경 생성 장치는 긴장도 벡터 값이 제1 긴장도 벡터 기준 값보다 낮은 경우에는, 제1 컬러 세트보다 채도가 높은 제2 컬러 세트를 불러올 수 있으며, 이에 기반하여 백그라운드 그래픽 정보를 조정할 수 있다. 한편, 배경 생성 장치는 긴장도 벡터 값에 기반하여 복수의 오브제 세트들 중 하나의 오브제 세트를 선택 하여 오브제 그래픽 정보를 생성할 수 있다. 예컨대, 사후 세계의 연출이 필요한 상황에서, 배경 생성 장치 는 긴장도 벡터 값이 제2 긴장도 벡터 기준 값보다 높은 경우에는, 천사 이미지를 포함하는 제1 오브제 세 트를 선택하여, 제1 오브제 세트에 포함된 그래픽 정보를 기반으로 오브제를 이미지를 생성할 수 있으며, 제2 긴장도 벡터 기준 값보다 낮은 경우에는, 악마 이미지를 포함하는 제2 오브제 세트를 선택하여, 제2 오브제 세 트에 포함된 그래픽 정보를 기반으로 오브제 이미지를 생성할 수 있다. 다시 말해, 배경 생성 장치는 특정 장면의 긴장도에 부합하는 오브제 이미지를 등장시킬 수 있다. 이어서, 배경 생성 장치는 합성된 감정 및 동작의 변화에 따라 기설정된 시간 간격 마다 백그라운드 그래 픽 정보 및 오브제 그래픽 정보를 변화시킬 수 있으며, 배경 생성 장치는 세계관 데이터 갱신 정보를 세계 관 데이터 생성 장치로 전송함으로써, 세계관 데이터 생성 장치가 세계관 데이터를 갱신하도록 제어 할 수 있다. 구체적으로, 배경 생성 장치는 백그라운드 그래픽 정보에 관한 컬러 세트에 태그된 정보(예컨대, 단계가 낮은 채도) 및 오브제 그래픽 정보에 관한 오브제 세트에 태그된 정보(예컨대, 지옥)에 기반하여 세계관 데이터 갱신을 요청하는 명령을 생성할 수 있으며, 생성된 갱신 명령에 기반하여 세계관 데이터 생성 장치는 감정 생성 장치 및 동작 생성 장치를 제어하여 감정 및 동작을 새로 생성할 수 있다. 출력 장치는 제2 합성 장치와 배경 생성 장치에 의해 생성된 최종 결과물을 음성 합성(TTS)을 이용하여 실시간 음성, 자연어 텍스트 출력, 애니메이션으로 2D나 3D의 가상환경에서 가상 인물로 하여금 자연 스럽게 감정을 표현하고 동작을 구현하도록 출력할 수 있다. 전술한 장치들(100 내지 800)은 각각 하드웨어 형태의 프로세서, RAM, ROM 및 I/O(Input/Output) 인터페이스를 포함하는 전자장치일 수 있으며, 또는 소프트웨어 형태의 모듈(예컨대, 복수의 인스트럭션들)로서 구현될 수도 있다. 즉, 본 개시의 가상 인물 구현 시스템에 의하면 가상 인물이 취할 수 있는 동작과 제스처, 음성이나 자연어 문장 입력에 대해서, 가상 인물 전달하고 싶은 감정을 분석하고, 그 분석된 감정을 바탕으로 가상 인물이 얼굴 표정, 동작이나 제스처를 동반한 음성과 자연어 텍스트 출력으로 완벽하게 재현할 수 있다. 도 2는 본 개시의 예시적인 실시예에 따른 세계관 데이터 생성 장치를 나타내는 블록도이다. 도 2를 참조하면, 세계관 데이터 생성 장치는 입력신호 처리 모듈, 인공지능 알고리즘 모듈 및 인공지능 관리 모듈을 포함할 수 있다. 입력신호 처리 모듈은 학습 데이터 종류에 맞춰 정해진 처리과정을 거쳐 인공지능에 적합한 입력을 생성할 수 있다. 입력신호 처리 모듈은 도 1의 입력 장치로부터 제공받은 학습 데이터의 종류에 따라 인공지 능에 적합한 입력을 생성할 수 있다. 입력신호 처리 모듈은 생성된 입력을 인공지능 알고리즘 모듈에 제공할 수 있다. 인공지능 알고리즘 모듈은 입력신호 처리 모듈로부터 입력을 제공받을 수 있다. 인공지능 알고리즘 모듈은 입력신호 처리 모듈에 입력된 신호로부터 인공지능 알고리즘을 통해 감정 및 동작을 추론할 수 있다. 인공지능 알고리즘 모듈은 감정 및 동작을 추론하기 위해서 뉴로퍼지 감정 추론 수단을 이용할 수 있다. 예를 들어, 인공지능 알고리즘 모듈은 Neural Network, HMM등 인공지능 알고리즘을 통해 입력신 호 처리 모듈에 입력된 신호로부터 감정 및 동작을 추론할 수 있다. 추론하는 감정의 종류는 필요에 따라 분류될 수 있으며, 각성/이완의 1차원적인 분류에서부터 증오, 애정, 질투 등의 고차원적인 분류에 이르기까지 다양화될 수 있다. 인공지능 알고리즘 모듈은 추론해야 할 감성의 종류에 따라 그 구조나 규모가 변할 수 있다. 인공지능 관리 모듈은 인공지능 알고리즘이 실제 구현화되는데 필요한 각종 파라미터들 및 상태 정보를 업 데이트 및/또는 관리할 수 있다. 예를 들어, 인공지능의 구현화는 Neural Network이나 HMM등 인공지능 알고리즘 에서 각 Node 혹은 State의 전이 확률과 같은 파라미터의 집합으로 표현될 수 있다. 인공지능 관리 모듈은 이러한 파라미터의 집합에 대한 저장 및 외부로의 전달을 수행할 수 있고, 이에 더하여 학습에 따른 인공지능알고리즘의 파라미터 업데이트에 관여할 수 있다. 도 3은 본 개시의 예시적인 실시예에 따른 인공지능 알고리즘 모듈을 나타내는 블록도이다. 도 3을 참조하면, 인공지능 알고리즘 모듈의 감정 및/또는 동작을 추론하여 세계관 데이터에 포함될 수 있는 감 정 및/또는 동작을 출력하는 방법에 대해 설명하도록 한다. 인공지능 알고리즘 모듈은 동작과 제스처, 얼굴 모양, 얼굴 색깔, 음성, 억양, 음색 등과 같은 감정 및 동 작을 추론하기 위해 뉴로퍼지 감정 추론 방법 또는 장치를 사용할 수 있다. 인공지능 알고리즘 모듈은 퍼지 추론 모듈 및 신경 회로망을 포함할 수 있다. 퍼지 추론 모듈 은 가상 인물 또는 인간의 감정을 퍼지 규칙 베이스에 저장되어 있는 퍼지 규칙에 의해서 감정과 감 정 강도를 추출할 수 있다. 신경 회로망은 퍼지 규칙으로 해결하지 못한 입력에 대해서 입력과 근사한 감 정을 생성할 수 있다. 신경 회로망은 퍼지 규칙을 학습하고 연결 강도를 조절한 후에 퍼지 규칙으로 해결 하지 못한 입력에 적당한 감정을 근사시킬 수 있고, 퍼지 추론 모듈을 보조해줄 수 있다. 신경 회로망 은 퍼지 규칙 베이스에 저장되어 있는 퍼지 규칙과 감정 벡터 값을 입력 받아 단위 신경망을 생성할 수 있고, 생성된 단위 신경망을 학습시키고, 학습된 유사 출력을 낼 수 있다. 즉, 인공지능 알고리즘 모듈은 동작이나 제스처(얼굴 표정, 손짓 등) 인식 등으로부터 분석된 결과를 입력 으로 하여 감정을 분석할 수 있다. 본 개시의 가상 인물 구현 시스템에 의하면 가상 인물이 취할 수 있는 동작과 제스처, 음성이나 자연어 문 장 입력에 대해서, 가상 인물 전달하고 싶은 감정을 분석하고, 그 분석된 감정을 바탕으로 가상 인물이 얼굴표 정, 동작이나 제스처를 동반한 음성과 자연어 텍스트 출력으로 완벽하게 재현할 수 있다. 도 4는 본 개시의 예시적인 실시예에 따른 동작 생성 장치를 나타내는 블록도이다. 도 4를 참조하면, 동작 생성 장치는 동작 분석부 및 동작 생성부를 포함할 수 있다. 동작 분석 부는 자연어 데이터를 대상으로 입력 문장에 맞는 동작을 생성하기 위해서, 입력 문장을 최소한의 단위로 나누어서 각 단위의 성격을 규명하는 역할을 하며, 이러한 역할은 데이터 베이스(DB)를 이용함으로써 달성될 수 있다. 동작 생성부는 동작 분석부에 의해서 생성된 XML 트리를 이용해서 각 노드에 적합한 동작을 제 시하는 동작 생성기와 생성된 다양한 동작의 충돌 문제를 해결하기 위한 동작 필터로 구성된다. 본 명세서에서, 입력 문장에서 동작과 제스처를 추출해 내는 과정을 거치는데 이러한 분석과정을 동작 분석이라 고 할 수 있다. 동작분석(Motion analysis)은 크게 제스처 분석(Gesture analysis)과 동작 분석(Action analysis)로 나눌 수 있다. 예를 들어, 제스처 분석은 얼굴표정(눈썹 모양, 눈 응시, 입술 동작 등), 손동작, 머리 동작 등으로 세분할 수 있고, 동작 분석은 걷기, 뛰기, 먹기, 오르기, 춤추기, 자기 등의 동작으로 세분할 수 있다. 도 5는 본 개시의 예시적인 실시예에 따른 가상 인물 생성 장치를 나타내는 블록도이다. 도 5를 참조하면, 가상 인물 생성 장치는 가상 인물의 신체 정보와 가상 인물의 상세 정보를 선택 받은 후, 데이터 베이스(DB)를 이용하여 가상 인물의 기본적인 얼굴 표정, 제스처, 동작 등을 각각의 얼굴 표정 DB, 제스처 DB, 동작 DB에서 선택하여 기본적인 가상 인물을 생성할 수 있다. 가상 인물 생성 장치는 가상 인물의 영상 정보에 해당하는 얼굴 표정, 제스처, 동작 등에 대한 데이터 베 이스(DB)를 미리 구축함으로써, 세계관 데이터에 일치하는 가상 인물 또는 개성 있는 가상 인물을 차별적으로 생성할 수 있다. 이와 달리, 가상 인물 생성 장치가 데이터 베이스(DB)를 이용하지 않는 경우에는, 가상 인물의 감정과 감정의 강도를 조절함으로써, 각각의 감정과 감정의 강도에 따른 얼굴 표정, 제스처, 동작에 대 한 영상을 데이터 베이스(DB)에서 가져온 후, 가상 인물의 얼굴 표정, 제스처, 동작을 일괄적으로 선택하고, 최 종적으로 기본적인 가상인격체를 생성할 수 있다. 도 6은 본 개시의 예시적인 실시예에 따른 제2 합성 장치를 나타내는 블록도이다. 도 6을 참조하면, 제2 합성 장치는 감정/동작 관리부, 언어 정보 관리부, 합성 필터 및 데 이터 베이스(DB)를 포함할 수 있다. 감정/동작 관리부는 얼굴 표정, 제스처와 동작은 가상 인물이 자연스럽게 동작할 수 있도록 관리할 수 있 다. 언어 정보 관리부는 최소 언어 정보 단위에 따른 얼굴 표정, 제스처, 동작 등에 언어 정보 데이터를저장 및/또는 관리할 수 있다. 합성 필터는 감정/동작 관리부 및 언어 정보 관리부에서 제공된 데이터를 합성할 수 있다. 합성 필터는 감정/동작 관리부 및 언어 정보 관리부에서 제공된 데이 터의 처리 순서의 충돌을 방지하기 위해 우선 순위에 따라 취사선택하여 합성할 수 있다. 제2 합성 장치는 가상 인물에 합성된 감정 및 동작을 합성할 수 있다. 예를 들어, 가상 인물 생성 장치 에 의해 입력되는 가상 인물의 얼굴과 신체 영상에 제2 합성 장치에서 계획한 소스 기술을 적용하여, 이를 기반으로 자연어 문장에 대해서 가상 인물의 얼굴표정과 제스처, 동작 정보를 복원할 수 있고, 시간이나 이벤트에 따라 변화는 연속된 정보에 대응하여 새로운 합성 영상을 생성할 수 있다. 본 개시의 실시예들은 다양한 컴퓨터로 구현되는 동작을 수행하기 위한 프로그램 명령을 포함하는 컴퓨터 판독 가능 매체를 포함할 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으 로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기 록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD 와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함될 수 있다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드 뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 본 개시의 가상 인물 구현 시스템에 의하면 가상 인물이 취할 수 있는 동작과 제스처, 음성이나 자연어 문 장 입력에 대해서, 가상 인물 전달하고 싶은 감정을 분석하고, 그 분석된 감정을 바탕으로 가상 인물이 얼굴표 정, 동작이나 제스처를 동반한 음성과 자연어 텍스트 출력으로 완벽하게 재현할 수 있다. 본 명세서에서 특정한 용어를 사용하여 실시예들을 설명되었으나, 이는 단지 본 개시의 기술적 사상을 설명하기 위한 목적에서 사용된 것이지 의미 한정이나 특허청구범위에 기재된 본 개시의 범위를 제한하기 위하여 사용된"}
{"patent_id": "10-2023-0128777", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "것은 아니다. 그러므로 본 기술분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서, 본 개시의 진정한 기술적 보호범위는 첨부된 특허청구범위의 기술적 사상에 의해 정해져야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2023-0128777", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 예시적인 실시예에 따른 가상 인물 동작 구현 시스템을 나타내는 블록도이다. 도 2는 본 개시의 예시적인 실시예에 따른 세계관 데이터 생성 장치를 나타내는 블록도이다. 도 3은 본 개시의 예시적인 실시예에 따른 인공지능 알고리즘 모듈을 나타내는 블록도이다. 도 4는 본 개시의 예시적인 실시예에 따른 동작 생성 장치를 나타내는 블록도이다. 도 5는 본 개시의 예시적인 실시예에 따른 가상 인물 생성 장치를 나타내는 블록도이다. 도 6은 본 개시의 예시적인 실시예에 따른 제2 합성 장치를 나타내는 블록도이다."}
