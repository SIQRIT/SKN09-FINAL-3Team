{"patent_id": "10-2017-0176004", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0074560", "출원번호": "10-2017-0176004", "발명의 명칭": "사물 의인화 및 인터랙션을 위한 방법 및 시스템", "출원인": "네이버랩스 주식회사", "발명자": "정유진"}}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 시스템에서 수행되는 사물 인터랙션 방법에 있어서,AR(Augmented Reality) 공간에서 특정된 사물에 페이스 마스크(face mask)를 부착하여 해당 사물에 대한 의인화캐릭터를 생성하는 단계; 및상기 의인화 캐릭터를 인터페이스로 하여 상기 사물과의 인터랙션(interaction)을 제공하는 단계를 포함하는 사물 인터랙션 방법."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 사물 인터랙션 방법은,전자 기기로부터 입력 또는 선택된 이미지의 페이스 모델링(face modeling)을 통해 해당 이미지로부터 상기 페이스 마스크를 생성하는 단계를 더 포함하는 사물 인터랙션 방법."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 페이스 마스크를 생성하는 단계는,상기 이미지로부터 얼굴 영역을 추출하여 추출된 얼굴 영역을 3D 오브젝트화하는 것을 특징으로 하는 사물 인터랙션 방법."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 생성하는 단계는,상기 사물에 특정 기업이나 상품에 특화된 페이스 마스크를 부착하는 단계를 포함하는 사물 인터랙션 방법."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 생성하는 단계는,상기 사물의 3D 정보를 바탕으로 상기 페이스 마스크가 해당 사물을 트래킹(tracking)하도록 구현하는 단계를 포함하는 사물 인터랙션 방법."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 생성하는 단계는,상기 페이스 마스크의 경계를 블렌딩(blending) 처리하는 단계공개특허 10-2019-0074560-3-를 포함하는 사물 인터랙션 방법."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 생성하는 단계는,상기 사물의 칼라값을 이용하여 상기 페이스 마스크의 경계를 블렌딩 처리하는 단계를 포함하는 사물 인터랙션 방법."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 제공하는 단계는,인공지능(AI) 대화 시스템과 연동하여 획득한 정보를 상기 의인화 캐릭터를 통해 출력하는 것을 특징으로 하는 사물 인터랙션 방법."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제공하는 단계는,별도의 그래픽 사용자 인터페이스를 이용하여 시각적인 정보를 함께 출력하는 것을 특징으로 하는 사물 인터랙션 방법."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 제공하는 단계는,주어진 감정 정보에 대응하여 상기 의인화 캐릭터의 표정을 변화시키거나 이펙트(effect)를 첨부하는 것을 특징으로 하는 사물 인터랙션 방법."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컴퓨터와 결합되어 제1항 내지 제10항 중 어느 한 항의 사물 인터랙션 방법을 컴퓨터에 실행시키기 위해 컴퓨터판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항 내지 제10항 중 어느 한 항의 사물 인터랙션 방법을 컴퓨터에 실행시키기 위한 프로그램이 기록되어 있는것을 특징으로 하는 컴퓨터에서 판독 가능한 기록매체."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨터 시스템에 있어서,메모리에 포함된 컴퓨터 판독 가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,전자 기기로부터 입력 또는 선택된 이미지의 페이스 모델링을 통해 해당 이미지로부터 페이스 마스크를 생성하는 마스크 생성부;AR 공간에서 특정된 사물에 상기 페이스 마스크를 부착하여 해당 사물에 대한 의인화 캐릭터를 생성하는 캐릭터공개특허 10-2019-0074560-4-생성부; 및상기 의인화 캐릭터를 인터페이스로 하여 상기 사물과의 인터랙션을 제공하는 인터랙션부를 포함하는 컴퓨터 시스템."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 마스크 생성부는,상기 이미지로부터 얼굴 영역을 추출하여 추출된 얼굴 영역을 3D 오브젝트화하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 캐릭터 생성부는,상기 사물의 3D 정보를 바탕으로 상기 페이스 마스크가 해당 사물을 트래킹하도록 구현하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 캐릭터 생성부는,상기 페이스 마스크의 경계를 블렌딩 처리하여 상기 사물에 부착하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 캐릭터 생성부는,상기 사물의 칼라값을 이용하여 상기 페이스 마스크의 경계를 블렌딩 처리하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 인터랙션부는,인공지능 대화 시스템과 연동하여 획득한 정보를 상기 의인화 캐릭터를 통해 출력하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 인터랙션부는,별도의 그래픽 사용자 인터페이스를 이용하여 시각적인 정보를 함께 출력하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2017-0176004", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2019-0074560-5-제18항에 있어서,상기 인터랙션부는,주어진 감정 정보에 대응하여 상기 의인화 캐릭터의 표정을 변화시키거나 이펙트를 첨부하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2017-0176004", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사물 의인화 및 인터랙션을 위한 방법 및 시스템을 제공한다. 사물 인터랙션 방법은, AR(Augmented Reality) 공 간에서 특정된 사물에 페이스 마스크(face mask)를 부착하여 해당 사물에 대한 의인화 캐릭터를 생성하는 단계; 및 상기 의인화 캐릭터를 인터페이스로 하여 상기 사물과의 인터랙션(interaction)을 제공하는 단계를 포함할 수 있다."}
{"patent_id": "10-2017-0176004", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 사물(object)을 캐릭터화하고 캐릭터화된 인터페이스를 통해 인터랙션(interaction)하는 기술에 관한 것이다."}
{"patent_id": "10-2017-0176004", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사물에 대한 3D 모델은 AR(Augmented Reality, 증강현실), 컴퓨터 게임이나 애니메이션 제작 등 다양한 분야에 서 수요가 증가하고 있다. 3D 모델은 숙련된 전문가와 전문 소프트웨어 툴을 이용하여 작성하거나 스캐너를 이용하여 제작하나, 최근에는 일반인도 쉽게 3D 모델을 생성할 수 있는 연구가 활발히 진행되고 있다. 예컨대, 한국등록특허공보 제10-1747951호(등록일 2017년 6월 9일)에는 멀티뷰 촬영법을 기반으로 3D 컴퓨터 그 래픽을 활용한 새로운 방식의 3D 휴먼 캐릭터 제작 방식을 제공하는 기술이 개시되어 있다."}
{"patent_id": "10-2017-0176004", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "사물을 의인화한 캐릭터를 인터페이스로 하여 해당 사물과 인터랙션할 수 있는 방법 및 시스템을 제공한다. 사물에 대한 의인화 캐릭터를 생성하여 인공지능(AI) 디지털 에이전트(digital agent)로 활용할 수 있는 방법 및 시스템을 제공한다."}
{"patent_id": "10-2017-0176004", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "컴퓨터 시스템에서 수행되는 사물 인터랙션 방법에 있어서, AR(Augmented Reality) 공간에서 특정된 사물에 페 이스 마스크(face mask)를 부착하여 해당 사물에 대한 의인화 캐릭터를 생성하는 단계; 및 상기 의인화 캐릭터 를 인터페이스로 하여 상기 사물과의 인터랙션(interaction)을 제공하는 단계를 포함하는 사물 인터랙션 방법을 제공한다. 일 측면에 따르면, 상기 사물 인터랙션 방법은, 전자 기기로부터 입력 또는 선택된 이미지의 페이스 모델링 (face modeling)을 통해 해당 이미지로부터 상기 페이스 마스크를 생성하는 단계를 더 포함할 수 있다. 다른 측면에 따르면, 상기 페이스 마스크를 생성하는 단계는, 상기 이미지로부터 얼굴 영역을 추출하여 추출된 얼굴 영역을 3D 오브젝트화할 수 있다. 또 다른 측면에 따르면, 상기 생성하는 단계는, 상기 사물에 특정 기업이나 상품에 특화된 페이스 마스크를 부 착하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 생성하는 단계는, 상기 사물의 3D 정보를 바탕으로 상기 페이스 마스크가 해당 사 물을 트래킹(tracking)하도록 구현하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 생성하는 단계는, 상기 페이스 마스크의 경계를 블렌딩(blending) 처리하는 단계 를 포함할 수 있다. 또 다른 측면에 따르면, 상기 생성하는 단계는, 상기 사물의 칼라값을 이용하여 상기 페이스 마스크의 경계를 블렌딩 처리하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 제공하는 단계는, 인공지능(AI) 대화 시스템과 연동하여 획득한 정보를 상기 의인 화 캐릭터를 통해 출력할 수 있다. 또 다른 측면에 따르면, 상기 제공하는 단계는, 별도의 그래픽 사용자 인터페이스를 이용하여 시각적인 정보를 함께 출력할 수 있다. 또 다른 측면에 따르면, 상기 제공하는 단계는, 주어진 감정 정보에 대응하여 상기 의인화 캐릭터의 표정을 변 화시키거나 이펙트(effect)를 첨부할 수 있다. 컴퓨터와 결합되어 상기 사물 인터랙션 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장 된 컴퓨터 프로그램을 제공한다. 상기 사물 인터랙션 방법을 컴퓨터에 실행시키기 위한 프로그램이 기록되어 있는 것을 특징으로 하는 컴퓨터에 서 판독 가능한 기록매체를 제공한다. 컴퓨터 시스템에 있어서, 메모리에 포함된 컴퓨터 판독 가능한 명령들을 실행하도록 구성된 적어도 하나의 프로 세서를 포함하고, 상기 적어도 하나의 프로세서는, 전자 기기로부터 입력 또는 선택된 이미지의 페이스 모델링 을 통해 해당 이미지로부터 페이스 마스크를 생성하는 마스크 생성부; AR 공간에서 특정된 사물에 상기 페이스 마스크를 부착하여 해당 사물에 대한 의인화 캐릭터를 생성하는 캐릭터 생성부; 및 상기 의인화 캐릭터를 인터 페이스로 하여 상기 사물과의 인터랙션을 제공하는 인터랙션부를 포함하는 컴퓨터 시스템을 제공한다."}
{"patent_id": "10-2017-0176004", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면, 사물을 의인화한 캐릭터를 인터페이스로 하여 해당 사물과 인터랙션할 수 있고 의인화 캐릭터를 다양한 디지털 에이전트로 활용할 수 있다."}
{"patent_id": "10-2017-0176004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 본 발명의 실시예들에 따른 사물 인터랙션 방법은 이후 설명될 전자 기기나 서버와 같은 컴퓨터 장치를 통해 수 행될 수 있다. 이때, 컴퓨터 장치에는 본 발명의 일실시예에 따른 컴퓨터 프로그램이 설치 및 구동될 수 있고, 컴퓨터 장치는 구동된 컴퓨터 프로그램의 제어에 따라 본 발명의 일실시예에 따른 사물 인터랙션 방법을 수행할 수 있다. 상술한 컴퓨터 프로그램은 컴퓨터 장치와 결합되어 사물 인터랙션 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장될 수 있다. 예를 들어, 서버는 AR(Augmented Reality, 증강현실) 서비스 를 통해 정보를 제공하는 정보 플랫폼 역할을 하며, 특히 사물을 캐릭터화하고 캐릭터화된 인터페이스를 통해 사물과의 인터랙션을 지원할 수 있다. 도 1은 본 발명의 일실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 1의 네트워크 환경은 복수의 전 자 기기들(110, 120, 130, 140), 복수의 서버들(150, 160) 및 네트워크를 포함하는 예를 나타내고 있다. 이러한 도 1은 발명의 설명을 위한 일례로 전자 기기의 수나 서버의 수가 도 1과 같이 한정되는 것은 아니다.복수의 전자 기기들(110, 120, 130, 140)은 컴퓨터 장치로 구현되는 고정형 단말이거나 이동형 단말일 수 있다. 복수의 전자 기기들(110, 120, 130, 140)의 예를 들면, 스마트폰(smart phone), 휴대폰, 내비게이션, 컴퓨터, 노트북, 디지털방송용 단말, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 태블릿 PC, 게임 콘솔(game console), 웨어러블 디바이스(wearable device), IoT(internet of things) 디바이스, VR(virtual reality) 디바이스, AR(augmented reality) 디바이스 등이 있다. 일례로 도 1에서는 전자 기기 1의 예로 스마트폰의 형상을 나타내고 있으나, 본 발명의 실시예들에서 전자 기기 1은 실질적으로 무 선 또는 유선 통신 방식을 이용하여 네트워크를 통해 다른 전자 기기들(120, 130, 140) 및/또는 서버(150, 160)와 통신할 수 있는 다양한 물리적인 컴퓨터 장치들 중 하나를 의미할 수 있다. 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망, 위성망 등)을 활용하는 통신 방식뿐만 아니라 기기들간의 근거리 무선 통신 역시 포함될 수 있 다. 예를 들어, 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네 트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포 함하는 네트워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 서버(150, 160) 각각은 복수의 전자 기기들(110, 120, 130, 140)과 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 예를 들어, 서버는 네트워크를 통해 접속한 복수의 전자 기기들(110, 120, 130, 140)로 제1 서비스를 제공 하는 시스템일 수 있으며, 서버 역시 네트워크를 통해 접속한 복수의 전자 기기들(110, 120, 130, 140)로 제2 서비스를 제공하는 시스템일 수 있다. 보다 구체적인 예로, 서버는 복수의 전자 기기들(110, 120, 130, 140)에 설치되어 구동되는 컴퓨터 프로그램으로서의 어플리케이션을 통해, 해당 어플리케이션이 목적 하는 서비스(일례로, AR 서비스 등)를 제1 서비스로서 복수의 전자 기기들(110, 120, 130, 140)로 제공할 수 있 다. 다른 예로, 서버는 상술한 어플리케이션의 설치 및 구동을 위한 파일을 복수의 전자 기기들(110, 120, 130, 140)로 배포하는 서비스를 제2 서비스로서 제공할 수 있다. 도 2는 본 발명의 일실시예에 있어서 전자 기기 및 서버의 내부 구성을 설명하기 위한 블록도이다. 도 2에서는 전자 기기에 대한 예로서 전자 기기 1, 그리고 서버의 내부 구성을 설명한다. 또한, 다른 전자 기기 들(120, 130, 140)이나 서버 역시 상술한 전자 기기 1 또는 서버와 동일한 또는 유사한 내부 구 성을 가질 수 있다. 전자 기기 1과 서버는 메모리(211, 221), 프로세서(212, 222), 통신 모듈(213, 223) 그리고 입출력 인터페이스(214, 224)를 포함할 수 있다. 메모리(211, 221)는 비-일시적인 컴퓨터 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory), 디스크 드라이브, SSD(solid state drive), 플래시 메모 리(flash memory) 등과 같은 비소멸성 대용량 저장 장치(permanent mass storage device)를 포함할 수 있다. 여기서 ROM, SSD, 플래시 메모리, 디스크 드라이브 등과 같은 비소멸성 대용량 저장 장치는 메모리(211, 221)와 는 구분되는 별도의 영구 저장 장치로서 전자 기기 1이나 서버에 포함될 수도 있다. 또한, 메모리 (211, 221)에는 운영체제와 적어도 하나의 프로그램 코드(일례로 전자 기기 1에 설치되어 구동되는 브라우 저나 특정 서비스의 제공을 위해 전자 기기 1에 설치된 어플리케이션 등을 위한 코드)가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 메모리(211, 221)와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판독 가능한 기록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드 라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록매체가 아닌 통신 모듈(213, 223)을 통해 메모리(211, 221)에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또는 어플리케이션의 설치 파일을 배포하는 파일 배포 시스템(일례로, 상술한 서버)이 네트워크를 통해 제공하는 파일들에 의해 설치되는 컴퓨터 프로 그램(일례로 상술한 어플리케이션)에 기반하여 메모리(211, 221)에 로딩될 수 있다. 프로세서(212, 222)는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하 도록 구성될 수 있다. 명령은 메모리(211, 221) 또는 통신 모듈(213, 223)에 의해 프로세서(212, 222)로 제공 될 수 있다. 예를 들어 프로세서(212, 222)는 메모리(211, 221)와 같은 기록 장치에 저장된 프로그램 코드에 따 라 수신되는 명령을 실행하도록 구성될 수 있다. 통신 모듈(213, 223)은 네트워크를 통해 전자 기기 1과 서버가 서로 통신하기 위한 기능을 제공 할 수 있으며, 전자 기기 1 및/또는 서버가 다른 전자 기기(일례로 전자 기기 2) 또는 다른 서 버(일례로 서버)와 통신하기 위한 기능을 제공할 수 있다. 일례로, 전자 기기 1의 프로세서가 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 생성한 요청이 통신 모듈의 제어에 따라 네 트워크를 통해 서버로 전달될 수 있다. 역으로, 서버의 프로세서의 제어에 따라 제공되는 제어 신호나 명령, 컨텐츠, 파일 등이 통신 모듈과 네트워크를 거쳐 전자 기기 1의 통신 모듈 을 통해 전자 기기 1로 수신될 수 있다. 예를 들어 통신 모듈을 통해 수신된 서버의 제어 신호나 명령, 컨텐츠, 파일 등은 프로세서나 메모리로 전달될 수 있고, 컨텐츠나 파일 등은 전자 기 기 1이 더 포함할 수 있는 저장 매체(상술한 영구 저장 장치)로 저장될 수 있다. 입출력 인터페이스는 입출력 장치와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 키보드, 마우스, 마이크로폰, 카메라 등의 장치를, 그리고 출력 장치는 디스플레이, 스피커, 햅틱 피드백 디바 이스(haptic feedback device) 등과 같은 장치를 포함할 수 있다. 다른 예로 입출력 인터페이스는 터치스 크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와의 인터페이스를 위한 수단일 수도 있다. 입출력 장치는 전자 기기 1과 하나의 장치로 구성될 수도 있다. 또한, 서버의 입출력 인터페이스(22 4)는 서버와 연결되거나 서버가 포함할 수 있는 입력 또는 출력을 위한 장치(미도시)와의 인터페이스 를 위한 수단일 수 있다. 보다 구체적인 예로, 전자 기기 1의 프로세서가 메모리에 로딩된 컴 퓨터 프로그램의 명령을 처리함에 있어서 서버나 전자 기기 2가 제공하는 데이터를 이용하여 구성되 는 서비스 화면이나 컨텐츠가 입출력 인터페이스를 통해 디스플레이에 표시될 수 있다. 또한, 다른 실시예들에서 전자 기기 1 및 서버는 도 2의 구성요소들보다 더 많은 구성요소들을 포함 할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 전자 기기 1은 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버(transceiver), GPS(Global Positioning System) 모듈, 카메라, 각종 센서, 데이터베이스 등과 같은 다른 구성요소들을 더 포함 할 수도 있다. 보다 구체적인 예로, 전자 기기 1이 스마트폰인 경우, 일반적으로 스마트폰이 포함하고 있 는 가속도 센서나 자이로 센서, 카메라 모듈, 각종 물리적인 버튼, 터치패널을 이용한 버튼, 입출력 포트, 진동 을 위한 진동기 등의 다양한 구성요소들이 전자 기기 1에 더 포함되도록 구현될 수 있다. 이하에서는 AR 기반의 사물 의인화 및 인터랙션을 위한 방법 및 시스템의 구체적인 실시예를 설명하기로 한다. AR 서비스에서 캐릭터는 공간 상에서 사용자 본인을 대신해주는 아바타(avatar) 역할은 물론이고, 정보를 전달 하고 사용자와 소통하는 디지털 에이전트로 활용되거나, 혹은 컨텐츠 시나리오에 등장하는 주요 인물이나 주인 공으로서 다양한 역할을 할 수 있다. 이러한 캐릭터는 3D 모델로 생성되는 것으로 주로 사람의 형태일 수도 있고 다양한 사물 템플릿(template)에 사 람 얼굴을 더한 형태로 구현되기도 한다. 그러나, 실제 3D 모델의 디지털 캐릭터를 생성하는 것은 매우 복잡하 고 시간이 많이 소요되는 일이다. 본 발명에서는 얼굴 사진을 3D로 모델링한 후 사물에 부착하여 캐릭터화하고 캐릭터화된 인터페이스를 통해 인 터랙션할 수 있는 방법을 제안한다. 도 3은 본 발명의 일실시예에 따른 서버의 프로세서가 포함할 수 있는 구성요소의 예를 도시한 블록도이고, 도 4는 본 발명의 일실시예에 따른 서버의 프로세서가 수행할 수 있는 방법의 예를 도시한 흐름도이다. 본 실시예에 따른 서버는 AR 서비스로 다양한 정보를 제공하는 정보 플랫폼 서비스를 제공할 수 있다. 다 시 말해, 서버는 클라이언트(client)인 복수의 전자 기기들(110, 120, 130, 140)을 대상으로 AR 컨텐츠를 제공하는 플랫폼 역할을 한다. 서버는 전자 기기들(110, 120, 130, 140) 상에 설치되는 어플리케이션과 연동하여 AR 기반의 사물 의인화 및 인터랙션을 지원하는 서비스를 제공할 수 있다. 도 4의 사물 인터랙션 방법을 수행하기 위해, 서버의 프로세서는 구성요소로서 도 3에 도시된 바와 같이, 마스크 생성부, 캐릭터 생성부, 및 인터랙션부를 포함할 수 있다. 실시예에 따라 프로세 서의 구성요소들은 선택적으로 프로세서에 포함되거나 제외될 수도 있다. 또한, 실시예에 따라 프로 세서의 구성요소들은 프로세서의 기능의 표현을 위해 분리 또는 병합될 수도 있다. 이러한 프로세서 및 프로세서의 구성요소들은 도 4의 사물 인터랙션 방법이 포함하는 단계들(S410 내 지 S440)을 수행하도록 서버를 제어할 수 있다. 예를 들어, 프로세서 및 프로세서의 구성요소 들은 메모리가 포함하는 운영체제의 코드와 적어도 하나의 프로그램의 코드에 따른 명령(instruction)을실행하도록 구현될 수 있다. 여기서, 프로세서의 구성요소들은 서버에 저장된 프로그램 코드가 제공하는 명령에 따라 프로세서 에 의해 수행되는 프로세서의 서로 다른 기능들(different functions)의 표현들일 수 있다. 예를 들 어, 서버가 페이스 마스크(face mask)를 생성하도록 상술한 명령에 따라 서버를 제어하는 프로세서 의 기능적 표현으로서 마스크 생성부가 이용될 수 있다. 단계(S410)에서 프로세서는 서버의 제어와 관련된 명령이 로딩된 메모리로부터 필요한 명령을 읽어들일 수 있다. 이 경우, 상기 읽어들인 명령은 프로세서가 이후 설명될 단계들(S420 내지 S440)을 실 행하도록 제어하기 위한 명령을 포함할 수 있다. 단계(S420)에서 마스크 생성부는 전자 기기 1의 사용자에 의해 지정된 이미지에 대한 페이스 모델링 (face modeling)을 통해 해당 이미지로부터 페이스 마스크를 생성할 수 있다. 모델링 대상이 되는 이미지로는 전자 기기 1로부터 수신된 이미지 또는 서버와 관련된 데이터베이스 상의 이미지 중에서 선택된 이미 지 등을 이용할 수 있고, 예를 들어 사용자나 지인, 혹은 유명인 등의 얼굴 사진, 특정 기업의 마스코트나 특정 상품 이미지 등이 포함될 수 있다. 마스크 생성부는 이미지에 포함된 얼굴을 3D로 모델링하여 페이스 마 스크를 생성할 수 있으며, 이때 모델링 방법은 영상 내 음영 정보의 점진적 변화를 이용하여 얼굴 모델을 생성 하는 음영 기반 모델링, 영상 내 정점, 능선, 면, 질량 등을 이용하여 얼굴 모델을 생성하는 솔리드 모델링 등 기 공지된 모델링 기법을 사용할 수 있다. 마스크 생성부는 모델링된 얼굴에서 이마, 눈썹, 눈, 코, 입, 귀 등을 포함한 얼굴 영역의 마스크를 추출하여 3D 오브젝트화할 수 있다. 단계(S430)에서 캐릭터 생성부는 AR 서비스 환경에서 특정된 사물에 단계(S420)에서 생성된 페이스 마스크 를 합성하여 해당 사물에 대한 의인화 캐릭터를 생성할 수 있다. 캐릭터 생성부는 AR 서비스 환경에서 전 자 기기 1의 카메라에 의해 포인팅된 특정 사물 또는 카메라 화면을 통해 전자 기기 1의 사용자가 선 택한 특정 사물에 페이스 마스크를 부착하여 해당 사물을 캐릭터화할 수 있다. 이때, 캐릭터 생성부는 페 이스 마스크를 특정 사물에 자연스럽게 얹을 수 있도록 마스크 영역의 경계를 블렌딩(blending) 처리할 수 있다. 캐릭터 생성부는 페이스 마스크의 자연스러운 렌더링을 위해 얼굴이나 사물의 대표 색상을 활용할 수 있다. 일례로, 캐릭터 생성부는 눈, 눈썹, 코, 입 영역을 제외한 영역에서 대표 색상을 추출한 후 해 당 색상을 캐릭터 피부색에 반영할 수 있다. 페이스 마스크를 이용한 아바타 생성 시 손이나 목과 같이 피부색 이 노출되는 부분을 자연스럽게 처리하기 위해서 추출된 대표 색상으로 아바타 피부색을 처리할 수 있다. 다른 예로, 캐릭터 생성부는 특정 사물에서 페이스 마스크가 합성될 영역 주변의 대표 색상을 추출한 후 해당 색상을 이용하여 마스크 영역의 경계를 블렌딩 처리할 수 있다. 다시 말해, 캐릭터 생성부는 특정 사물에 서 페이스 마스크와 합성되는 영역의 칼라값을 추출하여 마스크 영역의 경계에 대해 해당 사물의 칼라값을 이용 한 블렌딩을 수행할 수 있다. 즉, 캐릭터 생성부는 페이스 마스크와 사물의 경계를 자연스럽게 하기 위해 서 사물의 대표 색상을 페이스 마스크의 경계에 반영할 수 있다. 그리고, 캐릭터 생성부는 3D 트래킹 (tracking) 기술을 이용하여 특정 사물에 부착된 페이스 마스크가 해당 사물을 트래킹하도록 구현할 수 있다. 2D 기반 트래킹은 일정 거리 이상 오브젝트나 카메라가 움직이는 경우 트래킹을 실패하게 된다. X, Y, Z 축으 로 다양한 움직임에 대응하기 위해서는 3D 트래킹을 활용하는 것이 효과적이며, 3D 트래킹의 경우 일반적으로 CAD를 활용하여 3D 모델 정보를 얻을 수 있다. CAD를 활용하는 경우 대부분 트래킹 시작 포인트를 맞추는 작업 이 필요하다. CAD 대신 딥 러닝을 이용하여 다양한 뷰에 맞는 3D 모델 정보를 얻는 것 또한 가능하다. 전자 기기 1의 AR 서비스를 이용하는 환경에 따라, 예를 들어 모바일 기반의 모노 카메라(mono camera) 환경에 서는 딥러닝(deep learning)을 이용하여 미리 학습된 물체의 3D 정보를 바탕으로 대상 사물의 모션, 회전, 이동 등의 변화에 대응하여 캐릭터에 실재감을 더할 수 있다. 다시 말해, 서버는 사물에 대한 사전 학습을 통 해 사물 별로 3D 정보인 표준 모델을 구축할 수 있고, 캐릭터화하고자 하는 특정 사물에 대한 3D 표준 모델을 제공할 수 있다. 이에, 캐릭터 생성부는 사용자가 캐릭터화하고자 하는 특정 사물에 대해 사전에 학습된 3D 표준 모델을 획득하여 이를 바탕으로 캐릭터의 3D 트래킹을 구현할 수 있다. 또한, 전자 기기 1이 스 테레오(stereo)나 3D 센서 환경을 통해 AR 서비스를 이용하는 경우 캐릭터 생성부는 전자 기기 1이 직접 제공하는 3D 정보를 활용하여 캐릭터의 3D 트래킹을 구현할 수 있다. 단계(S440)에서 인터랙션부는 특정 사물을 페이스 마스크로 의인화한 캐릭터를 인터페이스로 하여 해당 사 물과의 인터랙션을 제공할 수 있다. 인터랙션부는 특정 사물에 페이스 마스크를 부착함으로써 캐릭터화된 인터페이스를 통해 인터랙션할 수 있다. 일례로, 인터랙션부는 인공지능(AI) 대화 시스템과 연동하여 특 정 사물을 통해 사용자와 커뮤니케이션하거나 날씨, 뉴스, 음악, 지도, 사진 등 다양한 정보를 제공할 수 있다. 인공지능 대화 시스템은 개인비서 시스템, 챗봇 플랫폼(chatbot platform), 인공지능(AI) 스피커 등에 적용되는것으로 사용자의 명령어에 대한 의도를 이해하고 그에 대응하는 정보를 제공할 수 있다. 예를 들어, 인터랙션 부는 전자 기기 1로부터 사용자의 발화에 따른 음성 입력 \"오늘 날씨\"를 수신하는 경우 수신된 음성 입력을 인식 및 분석하여 오늘의 날씨에 대한 정보를 획득하고 AR 공간 상에서 캐릭터화된 사물을 통해 상기 획 득한 정보를 \"오늘의 날씨는 ...\"와 같이 음성이나 텍스트 등으로 출력할 수 있다. 이때, 인터랙션부는 정보 제공 과정에서 별도의 팝업창(pop-up), 말풍선(word bubble), 툴팁(tooltip) 등을 이용하여 시각적인 (visual) 정보를 함께 제공할 수도 있다. 또한, 인터랙션부는 의인화 캐릭터로 구현된 페이스 마스크의 표정을 변화시켜 해당 사물과 사용자 간의 감정을 교류하고 표현할 수 있다. 인터랙션부는 3D 모델링을 통해 오브젝트화된 마스크의 얼굴 영역에 대 한 변형을 통해 캐릭터의 표정을 변화시킬 수 있고, 감정의 표현을 극대화하기 위해 의인화된 사물에 다양한 이 펙트(effect)를 첨부하는 것 또한 가능하다. 이펙트는 이미지 객체로 구성된 컨텐츠로서 AR 기반 영상에 합성 가능한 필터, 스티커나 이모지 등을 모두 포괄하여 의미할 수 있으며, 이는 고정된 형태의 객체는 물론, 플래시 나 애니메이션 등이 적용된 움직이는 이미지 객체로도 구현 가능하다. 이러한 이펙트는 감정 정보를 나타내는 것으로 감정 별로 사전 분류될 수 있으며, 다시 말해 복수 개의 감정(예컨대, 기쁨, 슬픔, 놀람, 고민, 괴로움, 불안, 공포, 혐오, 분노 등)이 사전에 정의되고 각 감정 별로 해당 감정을 나타내는 이펙트들이 그룹핑 되어 관 리될 수 있다. 인터랙션부는 감정 표현을 위하여 사용자로부터 수신된 음성 입력의 문장에서 감정 정보를 추출할 수 있다. 이때, 감정 정보는 감정 종류와 감정 강도(감정 정도)를 포함할 수 있다. 감정을 나타내는 용어, 즉 감정 용어들은 사전에 정해지며 소정 기준에 따라 복수 개의 감정 종류(예컨대, 기쁨, 슬픔, 놀람, 고 민, 괴로움, 불안, 공포, 혐오, 분노 등)로 분류되고 감정 용어의 강약에 따라 복수 개의 강도 등급(예컨대, 1~10)으로 분류될 수 있다. 감정 용어는 감정을 나타내는 특정 단어는 물론, 특정 단어를 포함한 구절이나 문 장 등을 포함할 수 있다. 예를 들어, '좋아해요'나 '괴롭지만요'와 같은 단어, 혹은 '너무너무 좋아해요'와 같 은 구절이나 문장 등이 감정 용어의 범주에 포함될 수 있다. 일례로, 인터랙션부는 사용자의 음성 입력에 따른 문장에서 형태소를 추출한 후 추출된 형태소에서 미리 정해진 감정 용어를 추출하여 추출된 감정 용어에 대응되는 감정 종류와 감정 강도를 분류할 수 있다. 음성 입력의 문장에 복수 개의 감정 용어가 포함된 경우 감정 용어가 속한 감정 종류와 감정 강도에 따라 가중치를 계산할 수 있고 이를 통해 문장의 감정 정보에 대한 감정 벡터를 계산하여 해당 문장을 대표하는 감정 정보를 추출할 수 있다. 상기한 감정 정보를 추출하는 기술 은 예시적인 것으로 이에 한정되는 것은 아니며, 이미 잘 알려진 다른 기술들을 이용하는 것 또한 가능하다. 따라서, 인터랙션부는 주어진 감정 정보, 예컨대 사용자의 음성 입력으로부터 인식된 감정 정보에 대응하 여 캐릭터의 표정을 변화시키거나 해당 감정의 이펙트를 노출할 수 있다. 상기한 바와 같이, 인터랙션부는 사물을 의인화한 캐릭터를 정보 제공을 위한 인공지능 디지털 에이전트로 활용할 수 있다. 도 5 내지 도 6은 본 발명의 일실시예에 있어서 페이스 마스크를 생성하는 과정을 설명하기 위한 예시 도면이다. 도 5를 참조하면, 마스크 생성부는 AR 서비스 화면에서 특정 사물(예컨대, 마카롱)에 대한 캐릭 터화 요청이 수신되는 경우 전자 기기 1의 사용자에게 의인화를 위한 인물 사진을 요청할 수 있다. 이후, 도 6에 도시한 바와 같이 마스크 생성부는 전자 기기 1로부터 인물 사진이 입력 또는 선택되면 인물 사진에서 이마, 눈썹, 눈, 코, 입, 귀 등을 포함한 얼굴 영역을 추출할 수 있고(S61), 추출된 얼굴 영영을 3D 오브젝트화하여 페이스 마스크를 생성할 수 있다(S62). 도 7 내지 도 8은 본 발명의 일실시예에 있어서 의인화 캐릭터를 생성하는 과정을 설명하기 위한 예시 도면이다. 캐릭터 생성부는 특정 사물과의 자연스러운 합성을 위해 도 7에 도시한 바와 같이 페이스 마스크의 경계를 블렌딩 처리할 수 있다. 이때, 캐릭터 생성부는 캐릭터화하고자 하는 사물의 색상 정보에 기초하 여 마스크 경계를 블렌딩 처리할 수 있으며, 예를 들어 도 5에서 캐릭터화를 요청한 사물이 노란색인 경우 페이스 마스크의 경계를 노란색으로 블렌딩할 수 있다. 도 8을 참조하면, 캐릭터 생성부는 AR 서비스 화면에서 선택된 특정 사물에 페이스 마스크(60 1)를 합성하여 해당 사물을 의인화한 캐릭터를 생성할 수 있다. 예를 들어, AR 서비스 환경에서 카 메라 화면에 포착된 마카롱을 선택하는 경우 마카롱에 페이스 마스크를 부착함으로써 마카롱을 의인화 캐 릭터로 만들 수 있다. 이때, 캐릭터 생성부는 사물에 해당되는 영역 내에서 정해진 비율과 위 치에 페이스 마스크를 부착할 수 있으며, 혹은 사물에 해당되는 영역 내에서 페이스 마스크를부착할 위치나 영역 크기를 사용자가 조정하는 것 또한 가능하다. 도 9 내지 도 10은 본 발명의 일실시예에 있어서 의인화 캐릭터를 이용한 인터랙션 과정을 설명하기 위한 예시 도면이다. 인터랙션부는 캐릭터화된 사물을 인터페이스로 하여 해당 사물과의 인터랙션을 제공할 수 있으며, 인공지 능 대화 시스템과 연동하여 의인화 캐릭터를 통해 전자 기기 1의 사용자에게 전달하고자 하는 정보를 청각 적 또는 시각적인 방법 등으로 출력할 수 있다. 도 9에 도시한 바와 같이, 인터랙션부는 의인화 캐릭터 를 통해 사용자에게 전달하고자 하는 정보(날씨, 뉴스, 음악, 지도, 사진 등)를 말풍선과 같은 그래픽 사 용자 인터페이스를 이용하여 전달할 수 있다. 또한, 도 10을 참조하면 인터랙션부는 의인화 캐릭터 의 주변에 다양한 이펙트 객체를 함께 노출할 수 있다. 이때, 이펙트 객체는 전자 기기 1의 사용자의 음성 명령에서 분석된 감정 정보, 혹은 사용자에게 전달하고자 하는 정보에 포함된 감정 정 보를 표현하는 객체로 활용될 수 있다. 이외에도, 인터랙션부는 사용자와의 커뮤니케이션 중 의인화 캐릭 터를 구성한 페이스 마스크의 표정을 변화시켜 감정을 표현하는 것 또한 가능하다. 예를 들어, 사용자의 감정이 '분노'로 인식되는 경우 의인화 캐릭터의 페이스 마스크 메시를 화난 표정으로 변화시키거나 의인 화 캐릭터의 주변에 화난 감정의 불꽃 이펙트를 첨부할 수 있다. AR 서비스 환경에서 특정 사물을 선택하여 해당 사물에 페이스 마스크를 부착함으로써 의인화 캐릭터를 생성할 수 있다. 상기한 예시 이외에도, 도 11에 도시한 바와 같이 AR 공간 상의 휴대폰에 페이스 마스크(110 2)를 부착하여 휴대폰을 의인화한 캐릭터를 만들거나, 세제에 페이스 마스크를 부착하 여 세제를 의인화한 캐릭터를 만드는 등 모든 사물을 캐릭터화할 수 있고, 어떤 사물이라도 3D 모 델의 마스크와 합성하여 캐릭터화하여 이를 정보 제공을 위한 휴대용 인터페이스(portable interface)로서 활용 할 수 있다. 인터랙션부는 페이스 마스크가 아닌 얼굴의 일부분(예컨대, 눈, 입 등), 혹은 특정 인터페이스 그래픽 등 을 이용하여 사물의 캐릭터화와 인터랙션을 지원할 수도 있다. 또한, 특정 기업이나 상품과 제휴하여 특화된 페이스를 제공할 수 있고 이를 통해 프로모션이나 바이럴(viral) 마케팅에 활용할 수 있다. 예를 들어, 치킨 페이스와 치킨 관련 대화를 특화하여 이를 바탕으로 사용자가 치킨을 의인화하여 컨텐츠를 만들고 공유할 수 있 다. 이때, 인터랙션이나 인터페이스를 프로모션이나 마케팅 용도에 맞게 특화할 수 있다. 이처럼 본 발명의 실시예들에 따르면, 사물을 의인화한 캐릭터를 인터페이스로 하여 해당 사물과 인터랙션할 수 있고 의인화 캐릭터를 다양한 디지털 에이전트로 활용할 수 있다. 사물을 의인화한 캐릭터를 이용함에 따라 사 물을 친근하게 만들어 어린이 교육용 등으로 활용할 수 있고, 특정 상품이나 브랜드의 바이럴 프로모션/홍보 등 에 유용하게 쓰일 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 프로세서, 콘트롤 러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2017-0176004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 컴퓨 터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분 산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다.실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 이때, 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수 개의 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트 워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같 은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 어플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어 를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다."}
{"patent_id": "10-2017-0176004", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2017-0176004", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 2는 본 발명의 일실시예에 있어서 전자 기기 및 서버의 내부 구성을 설명하기 위한 블록도이다. 도 3은 본 발명의 일실시예에 따른 서버의 프로세서가 포함할 수 있는 구성요소의 예를 도시한 블록도이다. 도 4는 본 발명의 일실시예에 따른 서버의 프로세서가 수행할 수 있는 방법의 예를 도시한 흐름도이다. 도 5 내지 도 6은 본 발명의 일실시예에 있어서 페이스 마스크를 생성하는 과정을 설명하기 위한 예시 도면이다. 도 7 내지 도 8은 본 발명의 일실시예에 있어서 의인화 캐릭터를 생성하는 과정을 설명하기 위한 예시 도면이다. 도 9 내지 도 10은 본 발명의 일실시예에 있어서 의인화 캐릭터를 이용한 인터랙션 과정을 설명하기 위한 예시 도면이다. 도 11은 본 발명의 일실시예에 있어서 의인화 캐릭터의 다른 예시들을 설명하기 위한 도면이다."}
