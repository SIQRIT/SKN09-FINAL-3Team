{"patent_id": "10-2019-0144022", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0057354", "출원번호": "10-2019-0144022", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "조종명"}}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "통신 인터페이스;디스플레이; 및상기 통신 인터페이스를 통해 소스 장치로부터 컨텐츠가 수신되면, 상기 수신된 컨텐츠의 특징 정보를 획득하여외부 서버로 전송하고,상기 외부 서버로부터 상기 특징 정보에 기초하여 획득된 상기 컨텐츠의 식별 정보를 수신하고, 상기 통신 인터페이스를 통해 상기 소스 장치로부터 수신된 신호에 따라 상기 디스플레이의 기설정된 모드가 턴온되면, 상기 기설정된 모드가 턴 온되는 제1 시점에 대한 정보를 획득하고,상기 제1 시점 이후 상기 기설정된 모드가 턴 오프되는 제2 시점에 대한 정보를 획득하고,상기 식별 정보, 상기 제1 시점에 대한 정보 및 상기 제2 시점에 대한 정보에 기초하여 상기 디스플레이를 통해디스플레이된 상기 컨텐츠에 대한 정보를 획득하는 프로세서;를 포함하는 전자 장치."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 식별 정보에 기초하여 상기 디스플레이를 통해 디스플레이된 상기 컨텐츠의 타이틀을 식별하고, 상기 제1시점 및 상기 제2 시점에 대한 정보에 기초하여 상기 식별된 컨텐츠의 재생 시간을 식별하는, 전자 장치."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,상기 외부 서버로부터 수신된 복수의 식별 정보 중 상기 제1 시점 및 상기 제2 시점 사이에서 획득된 특징 정보에 기초하여 상기 컨텐츠의 식별 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 소스 장치로부터 수신된 신호는, 상기 소스 장치에서 제공하는 컨텐츠의 타입에 기초하여 상기 전자 장치가 상기 기설정된 모드를 턴 온 또는 턴오프시키도록 하는 제어 정보를 포함하는, 전자 장치."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 기설정된 모드는,ALLM(Automatic Low-Latency Mode)인, 전자 장치."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 제어 정보는, 공개특허 10-2021-0057354-3-기설정된 버전 이상의 HDMI 규격을 지원하는 상기 전자 장치에 제공되는 정보인, 전자 장치."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 제어 정보는, 상기 컨텐츠의 타입이 게임 컨텐츠인 경우 상기 소스 장치로부터 제공되는 정보인, 전자 장치."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 특징 정보는,비디오 특징 정보 또는 오디오 특징 정보 중 적어도 하나를 포함하고,상기 프로세서는,상기 수신된 컨텐츠 중 현재 시청 중인 컨텐츠의 이미지를 기설정된 시간 간격으로 캡쳐하고, 상기 캡쳐된 이미지의 픽셀 값에 기초하여 상기 비디오 특징 정보를 획득하고,상기 현재 시청 중인 컨텐츠의 음향 신호의 주파수 정보를 기설정된 시간 간격으로 획득하고, 상기 획득된 주파수 정보에 기초하여 상기 오디오 특징 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 오디오 특징 정보는,상기 비디오 특징 정보에 기초하여 획득된 컨텐츠의 식별 정보가 복수인 경우, 상기 복수의 식별 정보 중 현재시청 중인 컨텐츠에 대응되는 식별 정보를 획득하기 위해 추가적으로 이용되는 정보인, 전자 장치."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 프로세서는,상기 기설정된 시간 간격으로 캡쳐된 복수의 이미지 중 최근에 캡쳐된 기설정된 개수의 이미지로부터 상기 비디오 특징 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "소스 장치로부터 컨텐츠가 수신되면, 상기 수신된 컨텐츠의 특징 정보를 획득하여 외부 서버로 전송하는 단계;상기 외부 서버로부터 상기 특징 정보에 기초하여 획득된 상기 컨텐츠의 식별 정보를 수신하는 단계;상기 소스 장치로부터 수신된 신호에 따라 상기 전자 장치의 기설정된 모드가 턴 온되면, 상기 기설정된 모드가턴 온되는 제1 시점에 대한 정보를 획득하는 단계; 상기 제1 시점 이후 상기 기설정된 모드가 턴 오프되는 제2 시점에 대한 정보를 획득하는 단계; 및상기 식별 정보, 상기 제1 시점에 대한 정보 및 상기 제2 시점에 대한 정보에 기초하여 디스플레이된 상기 컨텐츠에 대한 정보를 획득하는 단계;를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 컨텐츠에 대한 정보를 획득하는 단계는,상기 식별 정보에 기초하여 디스플레이된 상기 컨텐츠의 타이틀을 식별하고, 상기 제1 시점 및 상기 제2 시점에공개특허 10-2021-0057354-4-대한 정보에 기초하여 상기 식별된 컨텐츠의 재생 시간을 식별하는, 제어 방법."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 컨텐츠의 식별 정보를 수신하는 단계는,상기 외부 서버로부터 수신된 복수의 식별 정보 중 상기 제1 시점 및 상기 제2 시점 사이에서 획득된 특징 정보에 기초하여 상기 컨텐츠의 식별 정보를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 소스 장치로부터 수신된 신호는, 상기 소스 장치에서 제공하는 컨텐츠의 타입에 기초하여 상기 전자 장치가 상기 기설정된 모드를 턴 온 또는 턴오프시키도록 하는 제어 정보를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 기설정된 모드는,ALLM(Automatic Low-Latency Mode)인, 제어 방법."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 제어 정보는, 기설정된 버전 이상의 HDMI 규격을 지원하는 상기 전자 장치에 제공되는 정보인, 제어 방법."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 제어 정보는, 상기 컨텐츠의 타입이 게임 컨텐츠인 경우 상기 소스 장치로부터 제공되는 정보인, 제어 방법."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 특징 정보는,비디오 특징 정보 또는 오디오 특징 정보 중 적어도 하나를 포함하고,상기 특징 정보를 획득하여 외부 서버로 전송하는 단계는,상기 수신된 컨텐츠 중 현재 시청 중인 컨텐츠의 이미지를 기설정된 시간 간격으로 캡쳐하고, 상기 캡쳐된 이미지의 픽셀 값에 기초하여 상기 비디오 특징 정보를 획득하고,상기 현재 시청 중인 컨텐츠의 음향 신호의 주파수 정보를 기설정된 시간 간격으로 획득하고, 상기 획득된 주파수 정보에 기초하여 상기 오디오 특징 정보를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 오디오 특징 정보는,상기 비디오 특징 정보에 기초하여 획득된 컨텐츠의 식별 정보가 복수인 경우, 상기 복수의 식별 정보 중 현재공개특허 10-2021-0057354-5-시청 중인 컨텐츠에 대응되는 식별 정보를 획득하기 위해 추가적으로 이용되는 정보인, 제어 방법."}
{"patent_id": "10-2019-0144022", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서,상기 특징 정보를 획득하여 외부 서버로 전송하는 단계는,상기 기설정된 시간 간격으로 캡쳐된 복수의 이미지 중 최근에 캡쳐된 기설정된 개수의 이미지로부터 상기 비디오 특징 정보를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0144022", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 전자 장치는 통신 인터페이스, 디스플레이 및 통신 인터페이스를 통해 소스 장치로부터 컨텐츠가 수신되면, 수신된 컨텐츠의 특징 정보를 획득하여 서버로 전송하고, 서버로부터 특징 정보에 기초하여 획득된 컨텐츠의 식별 정보를 수신하고, 통신 인터페이스를 통해 소스 장치로부터 수신된 신호에 따라 디스플레 이의 기설정된 모드가 턴 온되면, 기설정된 모드가 턴 온되는 제1 시점에 대한 정보를 획득하고, 제1 시점 이후 기설정된 모드가 턴 오프되는 제2 시점에 대한 정보를 획득하고, 식별 정보, 제1 시점에 대한 정보 및 제2 시점 에 대한 정보에 기초하여 디스플레이를 통해 디스플레이된 컨텐츠에 대한 정보를 획득하는 프로세서를 포함한다."}
{"patent_id": "10-2019-0144022", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 디스플레이되는 컨텐츠에 대한 정보를 획득하는 전자 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0144022", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래에는 디스플레이되는 컨텐츠에 대한 정보를 획득하는 다양한 방법이 존재하였다. 다만, 종래의 기술은 대체 로 영화, 드라마와 같이 이미 정해진 프레임이 연속적으로 디스플레이되는 컨텐츠에 적용되는 기술이었다. 예를 들어, 현재 디스플레이되는 컨텐츠의 몇몇 프레임을 데이터 베이스에 저장된 프레임과 비교함에 따라 TV는 현재 디스플레이 중인 드라마 또는 영화의 제목을 인식할 수 있었다. 다만, 게임 컨텐츠의 경우 이미 정해진 프레임이 연속적으로 디스플레이되는 컨텐츠와 달리 사용자 조작에 따라 다양한 플레이 영상이 나올 수 있기 때문에 데이터 베이스에 저장된 프레임과 비교하여 컨텐츠를 특정하기는 어 려운 문제가 있다."}
{"patent_id": "10-2019-0144022", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 따른 것으로, 본 개시의 목적은, 현재 디스플레이 중인 컨텐츠의 타이틀 및 재생 시 간을 식별하는 전자 장치 그 제어 방법을 제공함에 있다."}
{"patent_id": "10-2019-0144022", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 전자 장치는, 통신 인터페이스, 디스플레이 및 상기 통신 인터페이스를 통해 소스 장치로부터 컨텐츠가 수신되면, 상기 수신된 컨텐츠의 특징 정보를 획득하여 외부 서버로 전송하고, 상기 외부 서버로부터 상기 특징 정보에 기초하여 획득된 상기 컨텐츠의 식별 정보를 수신하 고, 상기 통신 인터페이스를 통해 상기 소스 장치로부터 수신된 신호에 따라 상기 디스플레이의 기설정된 모드 가 턴 온되면, 상기 기설정된 모드가 턴 온되는 제1 시점에 대한 정보를 획득하고, 상기 제1 시점 이후 상기 기 설정된 모드가 턴 오프되는 제2 시점에 대한 정보를 획득하고, 상기 식별 정보, 상기 제1 시점에 대한 정보 및 상기 제2 시점에 대한 정보에 기초하여 상기 디스플레이를 통해 디스플레이된 상기 컨텐츠에 대한 정보를 획득 하는 프로세서를 포함한다. 상기 프로세서는 상기 식별 정보에 기초하여 상기 디스플레이를 통해 디스플레이된 상기 컨텐츠의 타이틀을 식 별하고, 상기 제1 시점 및 상기 제2 시점에 대한 정보에 기초하여 상기 식별된 컨텐츠의 재생 시간을 식별할 수 있다. 여기서, 상기 프로세서는 상기 외부 서버로부터 수신된 복수의 식별 정보 중 상기 제1 시점 및 상기 제2 시점 사이에서 획득된 특징 정보에 기초하여 상기 컨텐츠의 식별 정보를 획득할 수 있다. 상기 소스 장치로부터 수신된 신호는 상기 소스 장치에서 제공하는 컨텐츠의 타입에 기초하여 상기 전자 장치가 상기 기설정된 모드를 턴 온 또는 턴 오프시키도록 하는 제어 정보를 포함할 수 있다. 상기 기설정된 모드는 ALLM(Automatic Low-Latency Mode)일 수 있다. 여기서, 상기 제어 정보는 기설정된 버전 이상의 HDMI 규격을 지원하는 상기 전자 장치에 제공되는 정보일 수 있다. 상기 제어 정보는 상기 컨텐츠의 타입이 게임 컨텐츠인 경우 상기 소스 장치로부터 제공되는 정보일 수 있다. 상기 특징 정보는 비디오 특징 정보 또는 오디오 특징 정보 중 적어도 하나를 포함할 수 있다. 여기서, 상기 프로세서는 상기 수신된 컨텐츠 중 현재 시청 중인 컨텐츠의 이미지를 기설정된 시간 간격으로 캡 쳐하고, 상기 캡쳐된 이미지의 픽셀 값에 기초하여 상기 비디오 특징 정보를 획득하고, 상기 현재 시청 중인 컨 텐츠의 음향 신호의 주파수 정보를 기설정된 시간 간격으로 획득하고, 상기 획득된 주파수 정보에 기초하여 상 기 오디오 특징 정보를 획득할 수 있다. 여기서, 상기 오디오 특징 정보는 상기 비디오 특징 정보에 기초하여 획득된 컨텐츠의 식별 정보가 복수인 경우, 상기 복수의 식별 정보 중 현재 시청 중인 컨텐츠에 대응되는 식별 정보를 획득하기 위해 추가적으로 이 용되는 정보일 수 있다. 여기서, 상기 프로세서는 상기 기설정된 시간 간격으로 캡쳐된 복수의 이미지 중 최근에 캡쳐된 기설정된 개수 의 이미지로부터 상기 비디오 특징 정보를 획득할 수 있다. 한편, 상술한 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 제어 방법은, 소스 장치로부터 컨텐츠가 수신 되면, 상기 수신된 컨텐츠의 특징 정보를 획득하여 외부 서버로 전송하는 단계, 상기 외부 서버로부터 상기 특 징 정보에 기초하여 획득된 상기 컨텐츠의 식별 정보를 수신하는 단계, 상기 소스 장치로부터 수신된 신호에 따 라 상기 전자 장치의 기설정된 모드가 턴 온되면, 상기 기설정된 모드가 턴 온되는 제1 시점에 대한 정보를 획 득하는 단계, 상기 제1 시점 이후 상기 기설정된 모드가 턴 오프되는 제2 시점에 대한 정보를 획득하는 단계 및 상기 식별 정보, 상기 제1 시점에 대한 정보 및 상기 제2 시점에 대한 정보에 기초하여 디스플레이된 상기 컨텐 츠에 대한 정보를 획득하는 단계를 포함한다. 상기 컨텐츠에 대한 정보를 획득하는 단계는, 상기 식별 정보에 기초하여 디스플레이된 상기 컨텐츠의 타이틀을 식별하고, 상기 제1 시점 및 상기 제2 시점에 대한 정보에 기초하여 상기 식별된 컨텐츠의 재생 시간을 식별할 수 있다. 상기 컨텐츠의 식별 정보를 수신하는 단계는, 상기 외부 서버로부터 수신된 복수의 식별 정보 중 상기 제1 시점 및 상기 제2 시점 사이에서 획득된 특징 정보에 기초하여 상기 컨텐츠의 식별 정보를 획득할 수 있다. 상기 소스 장치로부터 수신된 신호는 상기 소스 장치에서 제공하는 컨텐츠의 타입에 기초하여 상기 전자 장치가 상기 기설정된 모드를 턴 온 또는 턴 오프시키도록 하는 제어 정보를 포함할 수 있다. 여기서, 상기 기설정된 모드는 ALLM(Automatic Low-Latency Mode)일 수 있다. 상기 제어 정보는 기설정된 버전 이상의 HDMI 규격을 지원하는 상기 전자 장치에 제공되는 정보일 수 있다. 상기 제어 정보는 상기 컨텐츠의 타입이 게임 컨텐츠인 경우 상기 소스 장치로부터 제공되는 정보일 수 있다. 상기 특징 정보는 비디오 특징 정보 또는 오디오 특징 정보 중 적어도 하나를 포함할 수 있다. 여기서, 상기 특징 정보를 획득하여 외부 서버로 전송하는 단계는, 상기 수신된 컨텐츠 중 현재 시청 중인 컨텐 츠의 이미지를 기설정된 시간 간격으로 캡쳐하고, 상기 캡쳐된 이미지의 픽셀 값에 기초하여 상기 비디오 특징 정보를 획득하고, 상기 현재 시청 중인 컨텐츠의 음향 신호의 주파수 정보를 기설정된 시간 간격으로 획득하고, 상기 획득된 주파수 정보에 기초하여 상기 오디오 특징 정보를 획득할 수 있다. 여기서, 상기 오디오 특징 정보는 상기 비디오 특징 정보에 기초하여 획득된 컨텐츠의 식별 정보가 복수인 경우, 상기 복수의 식별 정보 중 현재 시청 중인 컨텐츠에 대응되는 식별 정보를 획득하기 위해 추가적으로 이 용되는 정보일 수 있다. 상기 특징 정보를 획득하여 외부 서버로 전송하는 단계는, 상기 기설정된 시간 간격으로 캡쳐된 복수의 이미지 중 최근에 캡쳐된 기설정된 개수의 이미지로부터 상기 비디오 특징 정보를 획득할 수 있다."}
{"patent_id": "10-2019-0144022", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 개시의 다양한 실시 예에 따르면, 전자 장치는 현재 디스플레이 중인 컨텐츠의 타이틀을 식별할 수 있다.또한, 전자 장치를 통해 재생되는 컨텐츠가 게임 컨텐츠인 경우, 전자 장치는 사용자가 실제 플레이한 게임 컨 텐츠의 플레이 시간을 식별할 수 있다."}
{"patent_id": "10-2019-0144022", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 개시의 실시 예들은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정 하려는 것이 아니며, 개시된 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 실시 예들을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 요지를 흐릴 수 있다 고 판단되는 경우 그 상세한 설명을 생략한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. A 및/또는 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 명세서에서, 사용자라는 용어는 전자 장치(또는 전자 장치)를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 본 발명의 일 실시 예에 따른 전자 시스템의 구성을 개략적으로 설명하기 위한 도면이다. 도 1에 따르면 본 발명의 일 실시 예에 따른 전자 시스템은 전자 장치, 소스 장치 및 서버 를 포함한다. 전자 장치는 소스 장치로부터 영상 신호를 수신하고, 수신된 영상 신호에 포함된 컨텐츠를 디스플레 이하는 디스플레이 장치일 수 있다. 예를 들어, 전자 장치는 TV, 스마트 TV, 스마트폰, 태블릿 PC, 이동 전화기, 영상 전화기, 전자책 리더기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, PDA, PMP(portable multimedia player), MP3 플레이어, 의료기기, 카메라, 또는 웨어러블 장치 등 디스플레이를 구비하는 다양한 형태로 구현 될 수 있다. 소스 장치는 소스 영상 및 소스 영상과 관련된 정보가 포함된 신호를 전자 장치로 전송하는 장치일 수 있다. 예를 들어, 소스 장치는 게임 콘솔(예:XboxTM, PlayStationTM), 스마트폰, 태블릿 PC, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 웨어러블 장치, 셋탑 박스, USB와 같은 저장 장치 등 다양한 형태로 구현될 수 있다. 서버는 다양한 컨텐츠에 대한 정보를 저장 및 관리하는 장치이다. 예를 들어, 서버는 컨텐츠의 특징 정보를 생성하여 저장할 수 있다. 여기서, 특징 정보는 해당 컨텐츠를 다른 컨텐츠와 구별할 수 있도록 하는 고 유의 정보를 의미하며, 예를 들어, 비디오 신호에 기초하여 생성되는 비디오 특징 정보 및 오디오 신호에 기초 하여 생성되는 오디오 특징 정보를 포함할 수 있다. 이에 관하여는 하기에서 자세히 설명하도록 한다. 한편, 전자 장치는 현재 디스플레이되는 컨텐츠에 대한 정보가 존재하지 않는 경우, 현재 디스플레이되는 컨텐츠에 대한 특징 정보를 획득하여 서버로 전송하고, 서버는 수신된 특징 정보를 서버에 저장 된 정보와 비교하여 현재 전자 장치 상에 디스플레이되는 컨텐츠가 어떤 컨텐츠인지를 식별하고 식별 정보 를 전자 장치로 전송할 수 있다. 또한, 전자 장치는 소스 장치로부터 수신되는 신호에 포함된 정보에 기초하여 현재 디스플레이되는 컨텐츠의 재생 시간 정보를 획득할 수도 있다. 이와 같이, 전자 장치가 재생 중인 컨텐츠에 대한 정보를 획득하는 실시 예에 대해 하기에서 자세히 설명 하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 블록도이다. 도 2에 따르면, 전자 장치는 통신 인터페이스, 디스플레이 및 프로세서를 포함한다. 통신 인터페이스는 회로(circuitry)를 포함하며, 소스 장치 및 서버와 통신할 수 있는 구성이다. 통신 인터페이스는 유선 또는 무선 통신 방식에 기초하여 소스 장치 및 서버와 통신을 수행할 수 있다. 일 실시 예에 따라, 통신 인터페이스가 유선 통신 방식으로 외부와 통신하는 경우, 통신 인터페이스 는 전자 장치에 구비되는 포트로 구현될 수 있다. 특히, 통신 인터페이스는 HDMI 포트로 구현되어 소 스 장치와 통신할 수 있다. 이 경우, 소스 장치 또한 HDMI 포트를 구비할 수 있다. 이에 따라, 전자 장치 및 소스 장치는 각 HDMI 포트 및 이를 연결하는 HDMI(High Definition Multimedia Interface) 케이블을 통해 통신을 수행할 수 있다. 다만, 이에 한정되는 것은 아니며, LVDS(Low Voltage Differential Signals) 케이블, DVI(Digital Visual Interface) 케이블, D-SUB(D-subminiature) 케이블, VGA(VideoGraphics Array) 케이블, V-by-One 케이블 또는 광 케이블 등을 통해 통신 인터페이스는 소스 장치 와 통신을 수행할 수 있다. 다른 실시 예에 따라, 통신 인터페이스는 무선 통신을 통하여 소스 장치 및 서버와 통신을 수행 할 수 있다. 이 경우, 통신 인터페이스는 와이파이 모듈(미도시), 블루투스 모듈(미도시), IR(infrared) 모듈, LAN(Local Area Network) 모듈, 이더넷(Ethernet) 모듈 등을 포함할 수 있다. 여기서, 각 통신 모듈은 적어도 하나의 하드웨어 칩 형태로 구현될 수 있다. 무선 통신 모듈은 상술한 통신 방식 이외에 지그비 (zigbee), USB(Universal Serial Bus), MIPI CSI(Mobile Industry Processor Interface Camera Serial Interface), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation)등과 같은 다양한 무선 통신 규격에 따라 통신 을 수행하는 적어도 하나의 통신 칩을 포함할 수 있다. 다만 이는 일 실시 예에 불과하며 통신 인터페이스(11 0)는 다양한 통신 모듈 중 적어도 하나의 통신 모듈을 이용할 수 있다. 한편, 소스 장치와 통신을 수행하는 통신 인터페이스 및 서버와 통신을 수행하는 통신 인터페이스는 서로 다른 인터페이스로 구현될 수 있다. 예를 들어, 통신 인터페이스는 소스 장치와 통신을 수행하 는 제1 통신 인터페이스(110-1) 및 서버와 통신을 수행하는 제2 통신 인터페이스(110-2)를 포함할 수 있다. 이 경우, 제1 통신 인터페이스(110-1)는 유선 통신을 통하여 소스 장치와 통신하고, 제2 통신 인터 페이스(110-2)는 무선 통신을 통하여 서버와 통신할 수 있다. 특히, 제1 통신 인터페이스(110-1)는 HDMI 포트로 구현되는 것이 바람직하나, 이에 한정되는 것은 아니다. 제1 통신 인터페이스(110-1)는 소스 장치로부터 영상 신호를 수신할 수 있다. 여기서, 영상 신호는 컨텐츠 및 컨텐츠와 관련된 정보가 포함된 신호를 포함할 수 있다. 제2 통신 인터페이스(110-2)는 서버에 컨텐츠 의 특징 정보를 전송하고, 서버로부터 특징 정보에 기초하여 획득된 컨텐츠의 식별 정보를 수신할 수 있다. 이에 대해서는 하기에서 자세히 설명한다. 디스플레이는 소스 장치로부터 수신된 컨텐츠를 디스플레이하는 구성이다. 디스플레이는 LCD(liquid crystal display), OLED(organic light-emitting diode), LCoS(Liquid Crystal on Silicon), DLP(Digital Light Processing), QD(quantum dot) 디스플레이 패널, QLED(quantum dot light- emitting diodes), 마이크로 LED(micro light-emitting diode) 등과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 디스플레이는 터치패드와 상호 레이어 구조를 이루는 터치스크린 형태로 구현될 수 있다. 여기서, 터치스 크린은 터치 입력 위치 및 면적뿐만 아니라 터치 입력 압력까지도 검출할 수 있도록 구성될 수 있다. 프로세서는 메모리(미도시)와 전기적으로 연결되며, 전자 장치의 전반적인 동작을 제어한다. 본 개시의 일 실시 예에 따라, 프로세서는 통신 인터페이스를 통해 소스 장치로부터 컨텐츠를 수신할 수 있다. 경우에 따라, 전자 장치는 소스 장치로부터 컨텐츠에 대한 정보(예를 들어, 컨텐츠 의 타이틀, 타입, 재생 시간 등)를 수신할 수도 있으나, 본 개시에서는 소스 장치로부터 컨텐츠에 대한 명 시적인 정보를 수신하지 못하여 현재 재생 중인 또는 재생될 컨텐츠에 대한 정보의 획득이 필요한 경우를 상정 하여 설명하도록 한다. 프로세서는 소스 장치로부터 수신된 컨텐츠의 특징 정보를 획득하여 외부 서버로 전송할 수 있 다. 여기서, 특징 정보는 해당 컨텐츠를 다른 컨텐츠와 구별할 수 있는 컨텐츠의 고유 정보를 의미하며, 특징 정보는 비디오 특징 정보 또는 오디오 특징 정보 중 적어도 하나를 포함할 수 있다. 비디오 특징 정보는 오디오 정보가 포함되지 않은 비디오 신호로부터 추출된 정보이며, 비디오 핑거프린트(Video Fingerprint) 정보일 수 있다. 또한, 오디오 특징 정보는 오디오 신호로부터 추출된 정보이며, 오디오 핑거프린트(Audio Fingerprint) 정보일 수 있다. 구체적으로, 비디오 핑거프린트 정보는 비디오 신호에 포함된 일 프레임의 픽셀 값에 기초하여 생성된 문자열 정보일 수 있다. 이러한 문자열은 픽셀 위치에 따른 픽셀 값에 따라 변경되므로 동일한 프레임일 경우에만 동일 한 문자열이 생성될 수 있다. 따라서, 비디오 핑거프린트는 해당 프레임을 다른 프레임과 구별할 수 있는 특징 정보가 될 수 있다. 오디오 핑거프린트 정보는 오디오 신호의 일 구간에 포함된 음향 주파수 정보에 기초하여 생성된 문자열 정보일 수 있다. 이러한 문자열은 주파수 정보에 따라 변경되므로 동일한 음향 신호일 경우에만 동일한 문자열이 생성될 수 있다. 따라서, 오디오 핑거프린트 또한 해당 구간의 음향 주파수를 다른 음향 주파수와 구별할 수 있는 특징 정보가 될 수 있다. 프로세서는 소스 장치로부터 수신된 컨텐츠 중 현재 시청 중인 컨텐츠의 이미지를 기설정된 시간 간 격으로 캡쳐할 수 있다. 예를 들어, 프로세서는 디스플레이를 통해 디스플레이되는 컨텐츠의 프레임 을 500ms 간격으로 캡쳐할 수 있다. 이후, 프로세서는 캡쳐된 이미지의 픽셀 값에 기초하여 비디오 특징 정보를 획득할 수 있다. 구체적으로, 프로세서는 캡쳐된 이미지 즉, 캡쳐된 일 프레임 내의 전체 픽셀들을 n*m 개의 픽셀로 이루어 진 블록들로 구분할 수 있다. 이후, 프로세서는 구분된 블록들 중 일부 또는 전체 블록의 픽셀 값을 산출 할 수 있다. 프로세서는 산출된 픽셀 값에 대응되는 문자열을 생성하며, 생성된 문자열이 비디오 핑거프린 트가 될 수 있다. 프로세서는 이와 같은 방식으로 비디오 핑거프린트 즉, 비디오 특징 정보를 획득할 수 있다. 여기서, 프로세서는 기설정된 시간 간격으로 캡쳐된 복수의 이미지 중 최근에 캡쳐된 기설정된 개수의 이 미지로부터 비디오 특징 정보를 획득할 수 있다. 예를 들어, 기설정된 시간 간격으로 캡쳐된 모든 복수의 이미 지에서 비디오 특징 정보를 획득하여 서버로 전송하는 경우 현재 디스플레이 상에서 재생 중인 컨텐 츠에 대한 식별 정확도는 개선될 수 있으나, 프로세서의 연산 량이 불필요하게 증가할 수 있다. 따라서, 프로세서는 컨텐츠를 식별하기 위해 필요한 최소의 개수의 이미지로부터 비디오 특징 정보를 획득하며, 현 재 재생 중인 컨텐츠의 실시간성을 고려할 때 최근 캡쳐된 이미지로부터 비디오 특징 정보를 획득하는 것이 바 람직하다. 예를 들어, 기설정된 개수가 3개인 경우, 프로세서는 최근 3개의 캡쳐된 이미지에서만 비디오 특정 정보를 획득할 수 있다. 또한, 프로세서는 현재 시청 중인 컨텐츠의 음향 신호를 기설정된 시간 간격으로 획득할 수 있다. 예를 들 어, 프로세서는 스피커(미도시)를 통해 출력되는 컨텐츠의 음향 신호의 주파수 정보를 500ms 간격으로 획 득할 수 있다. 이후, 프로세서는 획득된 주파수 정보에 기초하여 오디오 특징 정보를 획득할 수 있다. 구 체적으로, 프로세서는 획득된 주파수 정보의 파형을 분석하고, 분석된 파형에 대응되는 문자열을 생성할 수 있다. 이와 같이 생성된 문자열이 오디오 핑거프린트가 될 수 있다. 프로세서는 비디오 특징 정보와 마 찬가지로, 기설정된 시간 간격으로 획득된 주파수 정보 중 최근에 획득된 기설정된 개수의 주파수 정보로부터 오디오 특징 정보를 획득할 수 있다. 한편, 오디오 특징 정보는 비디오 특징 정보에 기초하여 획득된 컨텐츠의 식별 정보가 복수인 경우, 복수의 식 별 정보 중 현재 시청 중인 컨텐츠에 대응되는 식별 정보를 획득하기 위해 추가적으로 이용되는 정보일 수 있다. 이에 대하여는 도 5 및 도 6에서 자세히 설명하도록 한다. 프로세서는 상술한 실시 예들에 의해 획득된 특징 정보를 서버로 전송할 수 있다. 일 예에 따라, 프로세서는 기설정된 시간 간격으로 특징 정보를 서버로 전송할 수 있는데, 여기서 기 설정된 시간 간격은 특징 정보를 획득하는 시간 간격과 동일할 수 있으나, 이에 한정되는 것은 아니며 특징 정 보를 획득하는 시간 간격과 다른 시간 간격으로 특징 정보를 서버로 전송할 수 있다. 다만 이에 한정되는 것은 아니며, 사용자로부터 컨텐츠 식별 요청이 입력되거나 서버로부터 특징 정보 전 송 요청 신호가 수신되는 경우, 프로세서는 획득된 특징 정보를 서버로 전송할 수 있다. 이후, 서버는 전자 장치로부터 전송된 특징 정보를 서버의 데이터 베이스에 저장된 특징 정보와 비교할 수 있다. 예를 들어, 전자 장치로부터 하나의 컨텐츠에 포함된 3개의 프레임에 대응되는 비디오 핑 거프린트 정보가 전송된 경우, 서버는 3개의 비디오 핑거프린트 정보를 포함하는 컨텐츠를 데이터 베이스 에서 검색할 수 있다. 일 예에 따르면, 서버는 3개의 비디오 핑거프린트 정보 중 적어도 하나를 포함하는 컨텐츠를 후보 컨텐츠로 식별할 수 있다. 이 경우, 식별된 후보 컨텐츠가 서로 다른 경우, 서버는 3개의 비디오 핑거프린트 정보 중 상대적으로 많은 수의 비디오 핑거프린트 정보가 일치하는 컨텐츠를 전자 장치(10 0)로부터 전송된 비디오 핑거프린트 정보에 대응되는 컨텐츠로 식별할 수 있다. 예를 들어, 서로 다른 영화 컨 텐츠라도 1편과 2편으로 구분되는 컨텐츠의 경우, 도입부 영상은 서로 동일할 수 있기 때문에 서버는 식별 된 복수의 후보 컨텐츠 중 상대적으로 많은 수의 비디오 핑거프린트 정보가 일치하는 컨텐츠를 전자 장치 로부터 전송된 특징 정보에 대응되는 컨텐츠로 식별할 수 있다. 이에 따라, 전자 장치가 전송한 비디오 핑 거프린트에 대응되는 컨텐츠 식별에 대한 정확도가 증가할 수 있다. 또한, 서버가 일 컨텐츠에 대한 모든 프레임의 비디오 핑거프린트를 저장하지 않을 수 있으므로, 서버 는 전자 장치로부터 전송된 비디오 핑거프린트와 모두 일치하는 컨텐츠를 발견하지 못할 수도 있다. 따라서, 서버는 우선 전자 장치로부터 전송된 복수의 비디오 핑거프린트 중 적어도 하나만 일치하는 경우를 검색하여 후보 컨텐츠로 식별할 수 있다. 이후의 과정은 상술한 바와 같이, 상대적으로 많은 수의 비디 오 핑거프린트 정보가 일치하는 컨텐츠를 전자 장치로부터 전송된 비디오 핑거프린트 정보에 대응되는 컨 텐츠로 식별될 수 있다. 다시 말해, 서버는 전자 장치로부터 전송된 특징 정보와 데이터 베이스에 저장된 정보를 비교하여 유 사도가 높은 컨텐츠를 식별할 수 있다. 서버는 식별된 컨텐츠에 대한 정보를 데이터 베이스로부터 획득하 여 획득된 컨텐츠의 식별 정보를 전자 장치로 전송할 수 있다. 여기서, 컨텐츠의 식별 정보는 컨텐츠의 타 이틀 정보, 타입 정보, 제작 연도 정보, 제작 국가 정보, 인물 정보 등을 포함할 수 있다. 이에, 프로세서는 서버로부터 특징 정보에 기초하여 획득된 컨텐츠의 식별 정보를 수신할 수 있다. 한편, 프로세서는 통신 인터페이스를 통해 소스 장치로부터 신호를 수신할 수 있다. 여기서, 신 호는 컨텐츠 및 제어 정보가 포함된 신호일 수 있다. 컨텐츠는 소스 장치가 제공하는 소스 영상이며, 제어 정보는 디스플레이의 설정 정보를 변경하는 커맨드 정보를 포함할 수 있다. 구체적으로, 소스 장치로부터 수신된 신호는 소스 장치에서 제공하는 컨텐츠의 타입에 기초하여 전자 장치가 기설정된 모드를 턴 온 또는 턴 오프시키도록 하는 제어 정보를 포함할 수 있다. 여기서, 컨텐츠의 타입이 게임 컨텐츠인 경우, 기설정된 모드는 ALLM(Automatic Low-Latency Mode)일 수 있다. ALLM 이란 입력에 따른 응답을 디스플레이 상에서 상대적으로 신속하게 표시하는 모드이다. 게임 컨텐츠는 영화, 드라마와 같은 컨텐츠에 비해 실시간 사용자 조작이 요구되는 컨텐츠이다. 이에 따라, 사용자 조작에 따른 응답이 디스플레이 상에 빠르게 반영될 필요가 있으며, 이를 위해서는 사용자 입력에 따른 응답 시간이 상대적으로 감소되어 야 한다. 따라서, 소스 장치는 전자 장치로 전송하는 컨텐츠가 게임 컨텐츠로 식별되는 경우, 전자 장치로 전송하는 신호에 ALLM을 턴 온시키는 제어 정보를 포함시킬 수 있다. 한편, 이와 같은 제어 정보는 기설정된 버전 이상의 HDMI 규격을 지원하는 전자 장치에 제공되는 정보일 수 있다. 예를 들어, 제어 정보는 HDMI 2.0 버전 이상의 규격을 지원하는 전자 장치에 제공될 수 있다. 이 경우, 전자 장치 및 소스 장치는 HDMI 2.0 포트를 구비할 수 있다. 다만, 이에 한정되는 것은 아니며, 전자 장치가 지원하는 버전이 HDMI 2.0 미만인 경우, 소스 장치로부터 제어 정보가 제공되더 라도 전자 장치에서 ALLM이 턴 온되지 않을 수 있다. 여기서, HDMI 2.0은 4K, 혹은 UHD(울트라 HD)로 불리는 초고해상도 환경에 최적화된 규격이다. HDMI 2.0에서 지 원하는 최대 대역폭은 18Gbps이며, 최대 4,096 x 2,160(2160p)의 해상도에서 60Hz로 부드럽게 구동하는 영상을 전송할 수 있게 되었다. HDMI 규격에는 VSDB(Vender Specific Data Block)라는 정보 블록이 포함되는데, VSDB는 Audio/Video Latency 정보, CEC Physical address 정보, Color bit 정보, 최고 TMDS 주파수 정보 등을 포함할 수 있다. 여기서, Color bit 정보는 컬러 정보를 의미하고, 최고 TMDS(Transition Minimized Differential Signaling)주파수 정 보는 해상도 정보를 의미한다. 소스 장치는 전자 장치로 전송하는 컨텐츠의 타입이 게임 컨텐츠로 식별된 경우 VSDB에 포함된 Latency 정보를 조정하는 ALLM(Automatic Low-Latency Mode) 제어 정보를 포함시킬 수 있다. 여기서, 각 버전의 HDMI 포트는 하위 호환성을 가지고 있다. 때문에 상위 규격의 소스 장치와 하위 규격의 전자 장치를 연결해 사용하거나 혹은 그 반대의 경우도 가능하다. 다만, 이 경우에는 양쪽 모두 하위 규격 에 해당하는 기능만 사용이 가능하다. 일 예로, 소스 장치가 HDMI 2.0을 지원하더라도 전자 장치가 HDMI 1.4 규격이라면 HDMI 1.4 기능만 이용할 수 있게 된다. 따라서, 전자 장치 상에서 ALLM이 턴 온 되기 위해서는 전자 장치 및 소스 장치의 최소 규격이 HDMI 2.0이어야 한다. 한편, 프로세서는 소스 장치로부터 수신된 신호에 따라 디스플레이의 기설정된 모드가 턴 온되 면, 기설정된 모드가 턴 온되는 제1 시점에 대한 정보를 획득할 수 있다. 구체적으로, 프로세서는 기설정 된 모드가 턴 온되는 제1 시점에 대한 정보를 메모리(미도시)에 저장할 수 있다. 또한, 프로세서는 제1 시점 이후 기설정된 모드가 턴 오프되는 제2 시점에 대한 정보를 획득할 수 있다. 구체적으로, 프로세서는 기설정된 모드가 턴 오프되는 제2 시점에 대한 정보를 메모리(미도시)에 저장할 수 있다.여기서, 기설정된 모드가 턴 온되는 제1 시점에 대한 정보 및 기설정된 모드가 턴 오프되는 제2 시점에 대한 정 보는, 일 예에 따르면, 해당 시점의 시간 정보일 수 있다. 예를 들어, 제1 시점에 대한 정보는 19년 10월 1일 16시 30분과 같이 제1 시점에서의 시간 정보일 수 있다. 다른 예에 따르면, 제1 시점에 대한 정보는 소요 시간 을 측정하는 스톱워치의 개념에서 시작 시점일 수 있다. 이 경우, 기설정된 모드가 턴 오프되는 제2 시점에 대 한 정보는 소요 시간 그 자체를 의미할 수 있다. 예를 들어, 제1 시점은 스톱워치가 시작되는 시점으로 0이며 제2 시점은 스톱워치가 종료되는 시점으로 일 예로 2시간 30분일 수 있다. 일 예에 따라, 기설정된 모드를 턴 오프시키는 제어 정보가 포함된 신호에 기초하여 기설정된 모드가 턴 오프될 수 있다. 다른 예에 따라, 제1 시점부터 기설정된 모드를 턴 온시키는 제어 정보가 포함된 신호가 주기적으로 소스 장치 로부터 전자 장치로 전송되며, 기설정된 모드를 턴 온시키는 제어 정보가 더 이상 전송되지 않는 경 우 기설정된 모드가 턴 오프될 수 있다. 이에 따라, 프로세서는 기설정된 모드가 턴 온되는 제1 시점에 대한 정보 및 기설정된 모드가 턴 오프되는 제2 시점에 대한 정보를 식별할 수 있다. 다시 말해, 프로세서는 기설정된 모드가 턴 온되어 있는 동안의 시간을 식별할 수 있다. 프로세서는 식별 정보, 제1 시점에 대한 정보 및 제2 시점에 대한 정보에 기초하여 디스플레이를 통 해 디스플레이된 컨텐츠에 대한 정보를 획득할 수 있다. 여기서, 컨텐츠에 대한 정보는 컨텐츠의 타이틀, 타입 또는 재생 시간 중 적어도 하나를 포함할 수 있다. 구체적으로, 프로세서는 식별 정보에 기초하여 디스플레이를 통해 디스플레이된 컨텐츠의 타이틀을 식별할 수 있다. 여기서, 식별 정보는 서버가 전자 장치로부터 수신된 특징 정보 및 서버에 저 장된 특징 정보를 비교하여 획득된 정보로서, 서버가 전자 장치로 전송한 정보일 수 있다. 프로세서 는 식별 정보에 기초하여 컨텐츠의 타이틀뿐만 아니라 타입 정보, 제작 연도 정보, 제작 국가 정보, 인물 정보 등을 식별할 수도 있다. 또한, 프로세서는 제1 시점에 대한 정보 및 제2 시점에 대한 정보에 기초하여 식별된 컨텐츠의 재생 시간 을 식별할 수 있다. 구체적으로, 프로세서는 식별 정보에 기초하여 식별된 컨텐츠가 제1 시점에 재생이 시 작되어 제2 시점에 재생이 종료되는 것으로 식별할 수 있다. 이에 따라, 프로세서는 컨텐츠가 총 재생된 시간 정보를 획득할 수 있다. 프로세서는 서버로부터 수신된 복수의 식별 정보 중 제1 시점 및 제2 시점 사이에서 획득된 특징 정 보에 기초하여 컨텐츠의 식별 정보를 획득할 수 있다. 예를 들어, 제1 시점 이전에 특징 정보가 획득되어 서버 로 전송되고, 서버로부터 수신된 식별 정보는 제1 시점 및 제2 시점 사이에 디스플레이를 통해 재생되는 컨텐츠가 아니므로, 프로세서는 제1 시점 및 제2 시점 사이에서 획득된 특징 정보에 기초한 컨텐 츠 만이 제1 시점 및 제2 시점 사이에서 재생되는 컨텐츠로 식별할 수 있다. 이에 대하여는 도 8에서 자세히 설 명하도록 한다. 한편, 프로세서는 현재 재생 중인 컨텐츠의 특징 정보를 획득하는 것으로 상술하였으나, 이에 한정되는 것 은 아니며 재생될 컨텐츠의 특징 정보를 획득하여 이에 대한 식별 정보를 서버로부터 수신할 수도 있다. 도 3은 전자 장치의 세부 구성을 설명하기 위한 블록도이다. 도 3에 따르면, 전자 장치는 통신 인터페이스, 디스플레이, 프로세서, 메모리, 오디 오 출력부 및 사용자 입력부를 포함한다. 도 3에 도시된 구성 중 도 2에 도시된 구성과 중복되는 부 분에 대해서는 자세한 설명을 생략하도록 한다. 프로세서는 메모리에 저장된 각종 프로그램을 이용하여 전자 장치의 동작을 전반적으로 제어한 다. 프로세서는 영상에 대응되는 그래픽 처리를 위한 그래픽 프로세서(Graphic Processing Unit, 132)를 포함할 수 있다. 프로세서는 코어(core, 미도시)와 GPU를 포함하는 SoC(System On Chip)로 구현될 수 있다. 프로세서는 싱글 코어, 듀얼 코어, 트리플 코어, 쿼드 코어 및 그 배수의 코어를 포함할 수 있다. 한편, 프로세서는 메인 CPU, GPU, NPU를 포함한다. 메인 CPU는 메모리에 액세스하여, 메모리에 저장된 O/S를 이용하여 부팅을 수행한다. 그리고, 메모리에 저장된 각종 프로그램, 컨텐츠 데이터 등을 이용하여 다양한 동작을 수행한다. 특히, 일 실시 예 에 따르면, 메인 CPU가 ROM에 저장된 명령어에 따라 메모리에 프로그램을 RAM에 복사하고, RAM에 액 세스하여 해당 프로그램을 실행시킬 수 있다. GPU는 그래픽처리를 위한 고성능의 처리장치에 해당할 수 있으며, 메모리를 빠르게 처리하고 바꾸어 화면 으로 출력할 프레임 버퍼 안의 영상 생성을 가속하도록 설계된, 전문화된 전자 회로일 수 있다. 또한, GPU(13 2)는 VPU(Visual Processing Unit)를 의미할 수 있다. NPU는 AI 칩셋(또는 AI 프로세서)에 해당할 수 있으며 AI 가속기(AI accelerator)일 수 있다. NPU는 딥뉴럴네트워크 수행에 최적환 된 프로세서 칩에 해당할 수 있다. 한편, NPU는 GPU를 대신하여 딥러 닝 모델을 실행하는 처리 장치에 해당할 수 있으며, NPU는 GPU와 함께 딥러닝 모델을 실행하는 처리 장치에 해당할 수도 있다. 메모리는 프로세서와 전기적으로 연결되며, 본 개시의 다양한 실시 예를 위해 필요한 데이터를 저장 할 수 있다. 메모리는 데이터 저장 용도에 따라 전자 장치에 임베디드된 메모리 형태로 구현되거나, 전자 장치 에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 전자 장치의 구동을 위한 데이터의 경우 전자 장치에 임베디드된 메모리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드된 메모리의 경우 휘 발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이 브(solid state drive(SSD)) 중 적어도 하나로 구현되고, 전자 장치에 탈부착이 가능한 메모리의 경우 메 모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini- SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결 가능한 외부 메 모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 일 실시 예에 따라, 메모리는 프로세서에 의해 획득된 특징 정보를 저장할 수 있다. 구체적으로, 메 모리는 비디오 핑거프린트 또는 오디오 핑거프린트 중 적어도 하나를 저장할 수 있다. 메모리는 제1 시점에 대한 정보 및 제2 시점에 대한 정보를 저장할 수 있다. 또한, 메모리는 특징 정 보가 획득된 시점에 대한 정보도 저장할 수 있다. 오디오 출력부는 비디오 신호에 대응되는 오디오 신호를 출력하기 위한 구성이다. 오디오 출력부는 스피커로 구현될 수 있으며, 경우에 따라 사운드 바와 같이 전자 장치 외부 구성으로 구현될 수도 있다. 사용자 입력부는 다양한 사용자 명령 및 정보를 입력 받기 위한 구성이다. 프로세서는 사용자 입력부 를 통해 입력된 사용자 명령에 대응되는 기능을 실행하거나, 사용자 입력부를 통해 입력된 정보를 메 모리에 저장할 수도 있다. 사용자 입력부는 사용자 명령을 음성 형태로 수신하기 위해 마이크(미도시)를 포함하거나, 사용자 명령을 터치로 입력 받기 위한 디스플레이로 구현될 수 있다. 또한, 사용자 입력부는 전자 장치를 제어하기 위한 별도의 제어 장치(미도시)로부터 사용자 명령 또 는 작업에 대한 정보가 포함된 신호를 입력 받을 수도 있다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치 및 서버 간 동작을 설명하기 위한 도면이다. 전자 장치는 신호 수신 모듈, 비디오 핑거프린트(VFP) 획득 모듈, 오디오 핑거프린트(AFP) 획득 모듈, HDMI 정보 처리 모듈 및 컨텐츠 정보 획득 모듈을 포함할 수 있다. 상술한 모듈들은 메모리에 저장되고 프 로세서의 제어에 따라 프로세서에 로딩되어 실행될 수 있다. 신호 수신 모듈은 소스 장치로부터 영상 신호를 수신할 수 있다. 영상 신호는 컨텐츠 및 컨텐츠와 관련된 제어 정보를 포함할 수 있다. 신호 수신 모듈은 소스 장치로부터 수신된 영상 신호를 비디오 신호와 오디 오 신호로 분리할 수 있다. 이후, 신호 수신 모듈은 비디오 신호를 비디오 핑거프린트 획득 모듈로 전송하고, 오디오 신호를 오디오 핑거프린트 획득 모듈로 전송하며, 제어 정보를 HDMI 정보 처리 모듈로 전송할 수 있다.비디오 핑거프린트 획득 모듈은 기설정된 시간 간격으로 비디오 신호로부터 비디오 핑거프린트를 획득할 수 있 다. 구체적으로, 비디오 핑거프린트 획득 모듈은 비디오 신호에 포함된 픽셀 값에 기초하여 문자열로 구성된 비 디오 핑거프린트를 획득할 수 있다. 획득된 비디오 핑거프린트 정보는 컨텐츠 정보 획득 모듈로 전송될 수 있다. 오디오 핑거프린트 획득 모듈은 기설정된 시간 간격으로 오디오 신호로부터 오디오 핑거프린트를 획득할 수 있 다. 구체적으로, 오디오 핑거프린트 획득 모듈은 오디오 신호에 포함된 음향 신호의 주파수 정보에 기초하여 문 자열로 구성된 오디오 핑거프린트를 획득할 수 있다. 획득된 오디오 핑거프린트 정보는 컨텐츠 정보 획득 모듈 로 전송될 수 있다. HDMI 정보 처리 모듈은 소스 장치로부터 기설정된 버전 이상의 HDMI 규격을 통해 전송된 제어 정보에 기초 하여 전자 장치에서 ALLM이 턴 온되는지를 모니터링할 수 있다. HDMI 정보 처리 모듈은 ALLM이 턴 온되는 제1 시점에 대한 정보를 컨텐츠 정보 획득 모듈로 전송할 수 있다. 또한, HDMI 정보 처리 모듈은 턴 온된 ALLM이 턴 오프되는지를 모니터링할 수 있다. HDMI 정보 처리 모듈은 제1 시점 이후 ALLM이 턴 오프되는 제2 시점에 대한 정보를 컨텐츠 정보 획득 모듈로 전송할 수 있다. 컨텐츠 정보 획득 모듈은 HDMI 정보 처리 모듈로부터 전송된 제1 시점에 대한 정보 및 제2 시점에 대한 정보를 메모리에 저장하고, 제1 시점부터 제2 시점 사이에 기설정된 타입의 컨텐츠가 재생된 것으로 식별할 수 있 다. 일 예로, 컨텐츠 정보 획득 모듈은 제1 시점부터 제2 시점 사이에 게임 컨텐츠가 재생된 것으로 식별할 수 있다. 한편, 컨텐츠 정보 획득 모듈은 비디오 핑거프린트 획득 모듈 및 오디오 핑거프린트 획득 모듈로부터 전송된 비 디오 핑거프린트 정보 및 오디오 핑거프린트 정보를 서버로 전송할 수 있다. 일 예에 따르면, 컨텐츠 정보 획득 모듈은 최근에 수신된 비디오 핑거프린트 정보 또는 오디오 핑거프린트 정보 중 적어도 하나를 서버 로 전송할 수 있다. 다만, 이에 한정되는 것은 아니며, 컨텐츠 정보 획득 모듈은 비디오 핑거프린트 획득 모듈 및 오디오 핑거프린트 획득 모듈로부터 전송된 모든 비디오 핑거프린트 정보 및 오디오 핑거프린트 정보를 서버 로 전송할 수도 있다. 신호 수신 모듈, 비디오 핑거프린트(VFP) 획득 모듈, 오디오 핑거프린트(AFP) 획득 모듈, HDMI 정보 처리 모듈 및 컨텐츠 정보 획득 모듈의 동작은 프로세서에서 수행되며, 상술한 모듈들을 프로세서로 통칭할 수 도 있다. 또한, 모듈의 이름 및 모듈의 종류는 예시일 뿐 다양한 이름 및 다양한 종류의 모듈로 구현될 수 있음 은 물론이다. 한편, 서버는 매칭 모듈, 인덱싱 모듈, 데이터베이스, 영상 입력 모듈을 포함할 수 있다. 서버는 전자 장치로부터 전송된 비디오 핑거프린트 또는 오디오 핑거프린트 중 적어도 하나에 기초하 여 전자 장치에서 재생되는 컨텐츠를 식별할 수 있다. 매칭 모듈은 전자 장치로부터 전송된 비디오 핑거프린트 또는 오디오 핑거프린트 중 적어도 하나와 매칭되 는 컨텐츠를 판단할 수 있다. 예를 들면, 매칭 모듈은 데이터베이스에 저장된 비디오 핑거프린트 정보 및 오디 오 핑거프린트 정보에 기초하여 전자 장치으로부터 전송된 비디오 핑거프린트 또는 오디오 핑거프린트 중 적어도 하나와 매칭되는 컨텐츠를 식별할 수 있다. 여기서, 매칭은 비디오 핑거프린트가 다른 비디오 핑거프린 트와 동일 또는 유사한 경우, 오디오 핑거프린트가 다른 오디오 핑거프린트와 동일 또는 유사한 경우를 의미할 수 있다. 데이터베이스는 적어도 하나의 컨텐츠에 대해 생성된 비디오 핑거프린트 또는 오디오 핑거프린트 중 적어도 하 나를 저장할 수 있다. 예를 들면, 데이터베이스는 게임 컨텐츠의 비디오 핑거프린트 또는 오디오 핑거프린트를 저장하거나 실시간 방송 서비스에 대해 생성된 비디오 핑거프린트 및 오디오 핑거프린트를 저장할 수 있다. 인덱싱 모듈은 비디오, 오디오 각각을 인덱싱할 수 있다. 인덱싱 모듈은 영상 입력 모듈을 통해 전송된 영상 신 호에 따른 비디오 신호를 기초로 비디오 핑거프린트를 생성할 수 있고, 전송된 영상 신호에 따른 오디오 신호를 기초로 오디오 핑거프린트를 생성할 수 있다. 여기서, 비디오 핑거프린트 생성 및 오디오 핑거프린트 생성은 비 디오 핑거프린트 추출 및 오디오 핑거프린트 추출을 의미할 수 있다. 인덱싱 모듈은 생성된 비디오 핑거프린트 및 오디오 핑거프린트 각각을 인덱싱하여 데이터베이스에 저장할 수 있다.영상 입력 모듈은 게임 컨텐츠 관련 신호 또는 방송 서비스 신호를 포함하는 컨텐츠 신호를 수신할 수 있다. 영 상 입력 모듈은 수신된 신호를 비디오 신호와 오디오 신호로 분리할 수 있다. 영상 입력 모듈은 분리된 비디오 신호 및 오디오 신호를 인덱싱 모듈에 전달할 수 있다. 한편, 게임 컨텐츠 관련 신호 또는 방송 서비스 신호는 소스 장치 또는 외부 장치(미도시)로부터 전송된 신호일 수 있다. 한편, 실시간 방송의 경우, 실시간 방송 서비스 신호는 전자 장치 보다 서버의 영상 입력 모듈에 먼 저 전송될 수 있다. 이에 따라, 방송 서비스 신호에 포함된 영상 신호로부터 비디오 핑거프린트 및 오디오 핑거 프린트가 전자 장치 보다 먼저 획득되어 데이터베이스에 저장될 수 있다. 이에 따라, 전자 장치로부 터 실시간 방송에 대한 컨텐츠 식별 요청이 수신되더라도 서버는 데이터베이스에 저장된 비디오 핑거프린 트 또는 오디오 핑거프린트 중 적어도 하나에 기초하여 실시간 방송에 대응되는 컨텐츠를 식별할 수 있다. 도 5는 본 개시의 일 실시 예에 따라 복수의 채널에서 동일한 비디오가 재생되는 경우 컨텐츠를 구별하는 동작 을 설명하기 위한 도면이다. 도 5와 같이, 복수의 채널에서 재생되는 컨텐츠의 비디오가 동일한 경우를 상정한다. 이 경우, 전자 장치 는 채널 5, 채널 7 및 채널 11로부터 획득된 비디오 핑거프린트 정보를 획득하여 서버로 전송할 수 있다. 서버는 전자 장치로부터 전송된 복수의 비디오 핑거프린트가 동일하므로 각 채널의 컨텐츠를 하나의 컨텐츠로 인식할 수 있다. 다만, 예를 들어, 채널 5, 채널 7 및 채널 11에서 재생 중인 컨텐츠가 축구 경기로 상정하면 각 컨텐츠가 재생 되는 채널 번호, 해설자 등이 달라 실제로는 다른 컨텐츠로 식별될 필요가 있다. 따라서, 이 경우 오디오 핑거 프린트 정보를 이용하여 컨텐츠를 좀 더 정확하게 식별하는 실시 예에 대해서는 하기의 도 6에서 자세히 설명하 도록 한다. 도 6은 본 개시의 일 실시 예에 따른 비디오 특징 정보 만으로 컨텐츠 식별이 안되는 경우 오디오 특징 정보를 이용하는 과정을 설명하기 위한 도면이다. 전자 장치는 서버로부터 컨텐츠에 대한 식별 정보를 수신할 수 있다(S610). 여기서, 서버로부터 수신된 식별 정보가 복수 개인 경우인지를 식별할 수 있다. 즉, 서버로부터 동일한 식별 정보가 복수 개 수신되었는지 여부를 식별할 수 있다. 서버로부터 하나의 식별 정보만이 수신된 경우(S620-N), 전자 장치 는 하나의 컨텐츠에 대한 식별 정보를 요청한 것으로 인식하여 해당 식별 정보로서 재생 중인 컨텐츠를 식 별할 수 있다(S630). 한편, 서버로부터 복수의 식별 정보가 수신되고 복수의 식별 정보가 동일한 경우(S620-N), 전자 장치(10 0)는 오디오 핑거프린트(AFP) 정보를 획득할 수 있다(S640). 오디오 핑거프린트 정보를 이용하여 복수의 식별 정보가 구분될 수 있기 때문이다. 전자 장치는 획득된 오디오 핑거프린트 정보를 서버로 전송할 수 있다. 예를 들어, 채널 5, 채널 7 및 채널 11에서 재생 중인 컨텐츠가 축구 경기로 상정하면, 채널 5, 채널 7 및 채널 11의 비디오 신호는 동일하 더라도 해설자는 서로 다를 수 있으므로 채널 5, 채널 7 및 채널 11의 오디오 신호는 상이할 수 있다. 따라서, 전자 장치는 각 채널의 오디오 핑거프린트 정보를 서버로 전송할 수 있다. 서버는 전자 장치로부터 전송된 복수의 오디오 핑거프린트 정보를 각각 데이터베이스에 저장된 정보 와 비교하여 서로 다른 컨텐츠 식별 정보를 획득할 수 있다. 예를 들어, 서버는 각 오디오 핑거프린트 정 보에 대응되는 방송사, 채널 번호, 인물 정보를 상이하게 획득하여 전자 장치로 전송할 수 있다. 전자 장치는 서버로부터 서로 다른 복수의 식별 정보를 수신(S660)하여 컨텐츠를 식별할 수 있다 (S670). 전자 장치가 비디오 핑거프린트에 대응되는 식별 정보를 서버로부터 수신한 이후 오디오 핑거프린트 정보를 서버로 전송하는 것으로 상술하였으나, 이에 한정되는 것은 아니며, 전자 장치는 채널 5, 채 널 7 및 채널 11에 대한 비디오 핑거프린트 및 오디오 핑거프린트를 함께 전송하고, 서버는 전자 장치 로부터 전송된 복수의 비디오 핑거프린트가 동일한 것으로 식별되면 오디오 핑거프린트를 이용하여 각 오 디오 핑거프린트 정보에 대응되는 서로 다른 컨텐츠 식별 정보를 획득하여 전자 장치로 전송할 수도 있다. 도 7은 본 개시의 일 실시 예에 따른 전자 장치, 소스 장치 및 서버의 시퀀스도이다. 소스 장치는 전자 장치로 전송할 컨텐츠의 타입을 식별하고(S705), 영상 신호를 전자 장치로 전 송할 수 있다(S710). 소스 장치는 전자 장치로 전송하는 컨텐츠가 게임 컨텐츠로 식별되는 경우, 전 자 장치로 전송하는 영상 신호에 ALLM을 턴 온시키는 제어 정보를 포함시킬 수 있다. 전자 장치는 소스 장치로부터 영상 신호를 수신할 수 있다(S715). 영상 신호에 포함된 제어 정보에 의해 기설정된 모드가 턴 온 되는지 여부를 식별할 수 있다(S720). 전자 장치는 기설정된 모드가 턴 온되 는 것으로 식별되면(S720-Y), 턴 온되는 제1 시점에 대한 정보를 저장할 수 있다. 또한, 전자 장치는 소스 장치로부터 영상 신호가 수신되면, 영상 신호에 포함된 컨텐츠를 비디오 신 호 및 오디오 신호로 분리하고, 비디오 신호 및 오디오 신호로부터 주기적으로 특징 정보를 획득할 수 있다 (S730). 구체적으로, 전자 장치는 비디오 신호로부터 비디오 핑거프린트 정보를 획득하고, 오디오 신호로 부터 오디오 핑거프린트 정보를 획득할 수 있다. 이후, 전자 장치는 컨텐츠에 대한 정보를 식별하기 위해 획득된 특징 정보를 서버로 전송할 수 있다 (S735). 한편, 서버는 전자 장치 보다 우선하여 소스 장치 또는 외부 장치로부터 영상 신호를 수신할 수 있다(S740). 서버는 영상 신호에 포함된 컨텐츠를 비디오 신호 및 오디오 신호로 분리하고 비디오 특징 정 보 및 오디오 특징 정보를 생성할 수 있다(S745). 생성된 특징 정보를 비디오 특징 정보 및 오디오 특징 정보로 구분하여 저장할 수 있다(S750). 이후, 전자 장치로부터 특징 정보가 전송되면(S735), 서버는 우선 전자 장치로부터 전송된 비디 오 특징 정보를 데이터베이스의 정보와 매칭(비교)할 수 있다(S755). 서버는 비디오 특징 정보에 기초하여 획득된 식별 정보가 복수 개인지 여부를 식별할 수 있다(S760). 식별 정보가 복수 개로 식별(S760-Y) 즉, 하나 의 컨텐츠로 식별되지 못한 경우 서버는 전자 장치로부터 전송된 오디오 특징 정보를 데이터베이스의 정보와 매칭(비교)할 수 있다(S765). 오디오 특징 정보까지 이용되는 복수의 식별 정보는 하나의 식별 정보로 식별될 것이며, 이에 따라 서버는 하나의 매칭된 컨텐츠를 식별하고 이에 대한 식별 정보를 획득할 수 있 다(S770). 이후, 서버는 매칭된 컨텐츠 식별 정보를 전자 장치로 전송할 수 있다(S775). 전자 장치는 기설정된 모드가 턴 오프되는 제2 시점 정보를 획득하고, 제2 시점 정보를 저장할 수 있다 (S780). 도 7 상에서는 S780의 단계가 서버로부터 식별 정보를 수신한 이후로 도시되었으나, 이는 일 예일 뿐 S780의 단계는 전자 장치에서 특징 정보를 획득하는 S730 단계 이후의 다양한 시점에서 수행될 수 있는 단계이다. 전자 장치는 서버로부터 수신된 식별 정보 및 저장된 제1 시점 및 제2 시점에 대한 정보에 기초하여 컨텐츠에 대한 정보를 획득할 수 있다(S785). 구체적으로, 전자 장치는 식별 정보에 기초하여 컨텐츠의 타입 및 타이틀을 식별할 수 있고, 제1 시점 및 제2 시점에 대한 정보에 기초하여 컨텐츠의 재생 시간 및 타입을 식별할 수 있다. 도 8은 본 개시의 일 실시 예에 따른 특징 정보의 획득 시점에 기초한 식별 정보를 설명하기 위한 도면이다. 전자 장치는 기설정된 모드가 턴 온되는 제1 시점부터 기설정된 모드가 턴 오프되는 제2 시점 사이에 특정 타입의 컨텐츠가 재생된 것으로 판단할 수 있다. 이 경우, 제1 시점부터 제2 시점 사이에 복수의 서로 다른 식 별 정보가 수신되는 경우, 전자 장치는 어떤 식별 정보에 대응되는 컨텐츠가 제1 시점 및 제2 시점 사이에 재생되었는지 식별할 필요가 있다. 예를 들어, 전자 장치가 제1 시점 이전인 t1 시점에 A 컨텐츠로부터 특징 정보를 획득하고, 획득된 특징 정보를 서버로 전송할 수 있다. 서버는 특징 정보에 기초하여 매칭되는 A 컨텐츠를 식별하고, A 컨텐 츠의 식별 정보를 전자 장치로 전송할 수 있다. 이에 전자 장치는 제1 시점 이후인 t2 시점에 서버 로부터 A 컨텐츠의 식별 정보를 수신하는 것으로 상정한다. 또한, 전자 장치가 제1 시점 이후인 t3 시점에 B 컨텐츠로부터 특징 정보를 획득하고, 획득된 특징 정보를 서버로 전송할 수 있다. 서버는 특징 정보에 기초하여 매칭되는 B 컨텐츠를 식별하고, B 컨텐츠의 식 별 정보를 전자 장치로 전송할 수 있다. 이에 전자 장치는 제2 시점 이전인 t4 시점에 서버로부 터 B 컨텐츠의 식별 정보를 수신하는 것으로 상정한다. 다시 말해, 전자 장치는 제1 시점부터 제2 시점 사이에 서버로부터 복수의 식별 정보를 수신할 수 있 다. 이 경우, 전자 장치는 서버로부터 수신된 복수의 식별 정보 중 제1 시점 및 제2 시점 사이에서획득된 특징 정보에 대응되는 식별 정보(t4 시점에 수신된 식별 정보)를 식별할 수 있다. 전자 장치는 t4 시점에 수신된 식별 정보에 대응되는 컨텐츠가 제1 시점부터 제2 시점 사이에 재생된 것으로, 컨텐츠 B의 재생 시간을 식별할 수 있다. 또한, B 컨텐츠의 식별 정보를 수신한 시점인 t4가 제2 시점 이후이더라도 B 컨텐츠의 특징 정보는 제1 시점 및 제2 시점 사이에서 획득되었으므로, 이 경우에도 전자 장치는 B 컨텐츠가 제1 시점부터 제2 시점 사이에 재생된 것으로 식별할 수 있다. 도 9는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 전자 장치는 소스 장치(200로부터 컨텐츠가 수신되면, 수신된 컨텐츠의 특징 정보를 획득하여 서버로 전송할 수 있다(S910). 여기서, 특징 정보는 비디오 특징 정보 또는 오디오 특징 정보 중 적어도 하나를 포함할 수 있다. 비디오 특징 정보는 비디오 핑거프린트로 구현되고, 오디오 특징 정보는 오디오 핑거프린트로 구현될 수 있다. 구체적으로, 전자 장치는 수신된 컨텐츠 중 현재 시청 중인 컨텐츠의 이미지를 기설정된 시간 간격으로 캡 쳐하고, 캡쳐된 이미지의 픽셀 값에 기초하여 비디오 특징 정보를 획득할 수 있다. 또한, 전자 장치는 현재 시청 중인 컨텐츠의 음향 신호의 주파수 정보를 기설정된 시간 간격으로 획득하고, 획득된 주파수 정보에 기초하여 오디오 특징 정보를 획득할 수 있다. 여기서, 오디오 특징 정보는 비디오 특징 정보에 기초하여 획득된 컨텐츠의 식별 정보가 복수인 경우, 복수의 식별 정보 중 현재 시청 중인 컨텐츠에 대응되는 식별 정보를 획득하기 위해 추가적으로 이용되는 정보일 수 있 다. 한편, 전자 장치는 기설정된 시간 간격으로 캡쳐된 복수의 이미지 중 최근에 캡쳐된 기설정된 개수의 이미 지로부터 비디오 특징 정보를 획득하여 서버로 전송할 수 있다. 전자 장치는 서버로부터 특징 정보에 기초하여 획득된 컨텐츠의 식별 정보를 수신할 수 있다(S920). 구체적으로, 전자 장치는 서버로부터 수신된 복수의 식별 정보 중 제1 시점 및 제2 시점 사이에서 획 득된 특징 정보에 기초하여 컨텐츠의 식별 정보를 획득할 수 있다. 전자 장치는 소스 장치로부터 수신된 신호에 따라 전자 장치의 기설정된 모드가 턴 온되면, 기 설정된 모드가 턴 온되는 제1 시점에 대한 정보를 획득할 수 있다(S930). 여기서, 소스 장치로부터 수신된 신호는 소스 장치에서 제공하는 컨텐츠의 타입에 기초하여 전자 장 치가 기설정된 모드를 턴 온 또는 턴 오프시키도록 하는 제어 정보를 포함할 수 있다. 제어 정보는 컨텐츠의 타입이 게임 컨텐츠인 경우 소스 장치로부터 제공되는 정보이며, 기설정된 모드는 ALLM(Automatic Low-Latency Mode)일 수 있다. 전자 장치는 제1 시점 이후 기설정된 모드가 턴 오프되는 제2 시점에 대한 정보를 획득할 수 있다(S940). 전자 장치는 획득된 식별 정보, 제1 시점에 대한 정보 및 제2 시점에 대한 정보에 기초하여 디스플레이된 컨텐츠에 대한 정보를 획득할 수 있다(S950). 구체적으로, 전자 장치는 식별 정보에 기초하여 디스플레이된 컨텐츠의 타이틀을 식별하고, 제1 시점 및 제2 시점에 대한 정보에 기초하여 식별된 컨텐츠의 재생 시간을 식별할 수 있다. 각 단계의 상세 동작에 대해서는 상술한 바 있으므로 자세한 설명은 생략하도록 한다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 어플리케이션 형태 로 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또 는 하드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치 중 적어도 하 나의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기 기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프로세 서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인 터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않 으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어 (hardware) 또는 이들의 조합을 이용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있 다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨 어 모듈들로 구현될 수 있다. 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 다양한 실시 예들에 따른 기기의 프로세싱 동작을 수행하기 위한 컴퓨터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium) 에 저장될 수 있 다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의해 실행되었 을 때 상술한 다양한 실시 예에 따른 기기에서의 처리 동작을 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2019-0144022", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2019-0144022", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 전자 시스템의 구성을 개략적으로 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 블록도이다. 도 3은 전자 장치의 세부 구성을 설명하기 위한 블록도이다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치 및 서버 간 동작을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따라 복수의 채널에서 동일한 비디오가 재생되는 경우를 설명하기 위한 도면이 다. 도 6은 본 개시의 일 실시 예에 따른 비디오 특징 정보 만으로 컨텐츠 식별이 안되는 경우 오디오 특징 정보를 이용하는 과정을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시 예에 따른 전자 장치, 소스 장치 및 서버의 시퀀스도이다. 도 8은 본 개시의 일 실시 예에 따른 특징 정보의 획득 시점에 기초한 식별 정보를 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
