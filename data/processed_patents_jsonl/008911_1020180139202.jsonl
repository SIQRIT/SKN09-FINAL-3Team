{"patent_id": "10-2018-0139202", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0055495", "출원번호": "10-2018-0139202", "발명의 명칭": "PTZ 카메라 자동제어를 위한 강화학습 모델 생성 방법", "출원인": "전자부품연구원", "발명자": "김동칠"}}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "PTZ 카메라 자동제어를 위한 강화학습 모델을 생성하는 방법으로서, 1) 강화학습을 수행하기 위해 객체 정보가 포함된 학습용 영상 데이터를 취득하고, 영상 내 객체의 위치 및 크기 정보를 분석하는 학습용 영상데이터 취득 및 분석 단계;2) PTZ 카메라 제어를 위해 PTZ 카메라의 액션값을 선택하는 단계;3) Pan Left, Pan Right, Tilt Up, Tilt Down, Zoom이 포함된 PTZ 카메라의 제어 방향을 추정해 리워드(Reward)를 계산하여, 상기 선택된 액션값을 이용하여 추정된 카메라 제어 방향으로 PTZ 카메라를 이동시키고,PTZ 카메라 이동 후 영상 내 객체의 위치 변화에 적응적으로 Reward를 부여하는 단계;4) 카메라의 액션 전,후 상태와 Reward가 포함된 데이터셋을 저장하는 단계;5) 저장 데이터셋의 개수가 사전 결정된 개수 이상인지 판단하는 단계;6) 저장된 데이터셋을 기반으로 강화학습 모델을 생성하는 단계를 포함하는 PTZ 카메라 자동제어를 위한 강화학습 모델 생성 방법."}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서, 상기 2) PTZ 카메라 제어를 위해 PTZ 카메라의 액션값을 선택하는 단계에서, 액션값 는 의 수학식을 통해 선택되되, 상수인 값이 사전에 전해진 임계값인 와 같거나 클 경우에는 액션값이 무작위로 선택되며, 그렇지 않은경우에는 현재 상태 와 학습되지 않은 강화학습 모델로 액션값이 선택되는 PTZ 카메라 자동제어를 위한 강화학습 모델 생성 방법."}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에서, 상기 3) PTZ 카메라의 제어 방향을 추정해 리워드(Reward)를 계산하는 단계에서, PTZ 카메라의 제어방향은 의 수학식으로 추정하여, 와 가보다 작을 때는 Zoom In을 카메라 제어 방향으로 추정하고, 그 외의 경우에는 Pan과 Tilt를 카메라 제어 방향으로 추정하되,여기서 는 현재 객체의 가로 위치와 취득한 영상의 가로 중심 거리의 차이를, 는 현재 객체의 세로위치와 취득한 영상의 세로 중심 거리의 차이를, 는 사전에 정해진 임계값 상수를 의미하는 PTZ 카메라 자동제어를 위한 강화학습 모델 생성 방법."}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에서, 상기 가 양수일 경우 Pan Right, 음수일 경우 Pan Left를 카메라 제어 방향으로 추정하고,가 양수일 경우 Tilt Down을, 음수일 경우 Tilt UP을 카메라 제어 방향으로 추정하는 PTZ 카메라 자동제어공개특허 10-2020-0055495-3-를 위한 강화학습 모델 생성 방법."}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에서, 상기 PTZ 카메라의 Pan과 Tilt에 관련해서 ,, 의 수학식을 이용하여 Reward rt를 계산하되, 여기서 는 카메라 움직임 이전 상태에서 객체의 위치와 화면 중심의 거리 차이고, 은 카메라 이동 후변한 객체의 위치와 화면 중심의 거리 차이며, 은 정규화 상수이고, τ1은 Pan과 Tilt의 목표 크기인 PTZ 카메라 자동제어를 위한 강화학습 모델 생성 방법."}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에서, 상기 PTZ 카메라의 Zoom에 관련해서 및의 수학식을 이용하여 Reward rt를 계산하되, 여기서 와 는 각각 카메라 이동 전,후에 대한 객체 크기 정보이고, 는 정규화 상수이고, 는를 반영하는 상수이고, 는 Zoom의 목표 크기인 PTZ 카메라 자동제어를 위한 강화학습 모델 생성 방법."}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에서, 4) 카메라의 액션 전,후 상태와 Reward가 포함된 데이터셋을 저장하는 단계에서, 저장되는 데이터셋은 카메라 이동 전 객체 상태정보, 액션값 추정 정보, Reward, 카메라 이동 후 객체 상태정보를 포함하는 PTZ카메라 자동제어를 위한 강화학습 모델 생성 방법."}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에서, 5) 저장 데이터셋의 개수가 사전 결정된 개수 이상인지 판단하는 단계에서, 사전 결정된 데이터셋개수는 3000개인 PTZ 카메라 자동제어를 위한 강화학습 모델 생성 방법."}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에서, 6) 저장된 데이터셋을 기반으로 강화학습 모델을 생성하는 단계는, 인공신경망을 이용해 현재 상태와 현재 액션값으로 딥 Q-러닝(deep Q-learning) 함수를 계산하여 PTZ 카메라 제어에 대한 현재 학습 목표를 설정하는 수단; 상기 현재 학습 목표 설정 단계의 수행 후에 Reward를 습득하는 단계와,상기 현재 액션값으로 실제 액션을 수행한 후 변경된 다음 단계의 상태와 새롭게 선택된 액션값을 이용하여 복사된 인공신경망을 통해 최대가 되는 딥 Q-러닝 함수값을 계산하고, 산출된 딥 Q-러닝 함수값을 가중치로 조절하고 상기 현재 학습 목표 설정 단계의 수행 후에 습득한 Reward를 결합하여 다음 단계 학습 목표를 설정하는단계를 포함하는 PTZ 카메라 자동제어를 위한 강화학습 모델 생성 방법."}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2020-0055495-4-제1항 내지 제9항 중 어느 한 항에 기재된 PTZ 카메라 자동제어에 사용되는 강화학습 모델로서, 입력층, 출력층, 및 은닉층을 포함하는 인공신경망;이 인공신경망의 가중치(weight)를 이용해 딥 Q-러닝(deep Q-learning) 함수를 계산하여 PTZ 카메라 제어에 대한 현재 학습 목표를 설정하는 수단; 상기 설정된 PTZ 카메라 제어에 대한 현재 학습 목표에 따라 실제의 PTZ 카메라 액션을 수행하여 PTZ 카메라 제어에 대한 다음 단계 학습 목표를 설정하는 수단; PTZ 카메라 제어에 대한 상기 현재 학습 목표와 다음 단계 학습 목표의 에러를 줄이도록 가중치를 갱신하여서PTZ 카메라 제어에 대해 강화학습을 수행하는 수단을 포함하는, PTZ 카메라 자동제어를 위한 강화학습 모델."}
{"patent_id": "10-2018-0139202", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에서, 상기 인공신경망에서 손실함수(Loss functioin)에는 mse(mean square error)가 사용되고, 활성화 함수(Activation function)는 은닉층에 대해서는 ReLU(Rectified Linear Unit) 함수가, 출력층에 대해서는 Linear 함수가 사용되고,학습률(Learning Rate)은 0.001로 설정되고,뱃치사이즈(Batch size)는 128로 설정된 PTZ 카메라 자동제어를 위한 강화학습 모델."}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 지능형 보안관제 시스템에서 사용되는 PTZ 카메라의 자동제어를 위해 효율적인 강화학습 모델을 생성 함으로써, 지능형 보안관제 시스템의 영상 관제 효율성을 향상시키는 강화학습 모델 생성 방법을 제안한다. 본 발명의 방법은 1) 강화학습을 수행하기 위해 객체 정보가 포함된 학습용 영상 데이터를 취득하고, 영상 내 객체 의 위치 및 크기 정보를 분석하는 학습용 영상데이터 취득 및 분석 단계; 2) PTZ 카메라 제어를 위해 PTZ 카메라 의 액션값을 선택하는 단계; 3) PTZ 카메라의 제어 방향을 추정해 리워드(Reward)를 계산하는 단계; 4) 카메라의 액션 전,후 상태와 Reward가 포함된 데이터셋을 저장하는 단계; 5) 저장 데이터셋의 개수가 사전 결정된 개수 이 상인지 판단하는 단계; 6) 저장된 데이터셋을 기반으로 강화학습 모델을 생성하는 단계를 포함한다."}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 지능형 보안 관제 시스템이 적용된 종합상황실 또는 CCTV 통합관제센터와 같은 환경에서의 영상관제 효율 향상을 위하여 PTZ 카메라 자동제어를 위한 강화학습 모델을 생성하는 방법, 그리고 이에 의해 생성된 강 화학습 모델에 관한 것이다. 본 발명은 2017년도 과학기술정보통신부 및 정보통신기술진흥센터의 정보통신·방송 연구개발 사업(과제고유번 호 2017-0-00250; 연구과제명: 엣지카메라 임베디드 시스템과 영상분석 시스템의 협업 강화학습 기반 지능형 국 방경계 감시 시스템 핵심 기술 개발)의 연구결과로서 수행되었다."}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재 많은 CCTV 통합관제센터가 구축되어 운영 중이며 여기에 많은 카메라가 연계되어 있다(2018년 현재 대한민 국내에 약 190개소 이상의 CCTV 통합관제센터가 운영중이며 약 40만 9000여대의 카메라가 사용되고 있음). 지속적인 CCTV 수요의 증가로 인해 지방정부 및 산업현장에서 CCTV 통합관제센터 구축 후 관제인력 부족으로 어 려움을 호소하고 있다. 이로 인해, 관제요원 1인당 수십 내지 수백 대의 카메라를 관제해야 하는 문제가 발생하 고 있고, 이는 관제 효율 하락의 주요 원인이 되고 있다. 또한 관제요원을 추가 배치시에는 많은 예산을 확보해 야 하는 문제가 발생한다. 최근 이러한 문제점을 완화하고 CCTV 통합관제센터의 관제 시스템 효율성을 높이기 위해 스마트 관제가 도입되 고 있다. 스마트 관제에는 영상 분석 서비스, 관제 요원의 관제 채널의 수 감소, 카메라의 우선순위 판단 등 여 러 기술이 적용된다. 그러나 위험상황 발생과 같은 이벤트 감지시에 카메라의 PTZ(pan, tilt, zoom)를 수동으로 제어해야 한다. 종래의 PTZ 카메라 제어 기술은 카메라 화면 중심에 객체를 위치시키기 위해 객체와 카메라 중심점의 거리의 차 이를 기반으로 카메라를 제어하고 있다. 그러나 이 방법은 객체 크기를 고려하지 않은 단순한 카메라 이동 방법 으로, 객체 추적 분야에만 적용할 수 있는 단점이 있다. 또한, 호모그래피를 이용한 PTZ 제어 방법은 객체 크기 를 고려하지만 객체와 카메라의 물리적 거리를 고려해 Zoom을 제어하기 때문에 Zoom 제어가 정확하지 않다."}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기 문제를 극복하기 위하여 지능형 보안관제 시스템에서 사용되는 PTZ 카메라의 자동제어를 위해 효율적인 강화학습 모델을 생성함으로써, 지능형 보안관제 시스템의 영상 관제 효율성을 향상시키는 강화학습 모델 생성 방법을 제안한다."}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따르면, 강화학습을 이용한 PTZ 카메라 자동제어를 위해 카메라 이동을 예측하고 상황에 적응적으로 Reward를 부여하는 강화학습 모델을 생성함으로써 지능형 보안 관제 시스템의 영상 관제를 효율적으로 수행할 수 있게 된다. 강화학습(reinforcement learning: RL)은 확률적 의사결정 문제를 푸는 기계학습의 새로운 방법론으로, 지도학 습(supervised learning)과 달리 보상 또는 리워드(reward) 함수가 주어져서 미래에 얻어질 리워드값들의 평균 을 최대로 하는 정책 함수를 찾는 기계학습 기법이다. 즉, 지도학습과 달리 목표값(target)은 리워드(reward)이 고 예측값은 정책(policy) 또는 액션(action)이다. 상기 과제를 해결하기 위한 한 측면에 따르면, PTZ 카메라 자동제어를 위한 강화학습 모델을 생성하는 방법이 제공된다. 이 방법은 1) 강화학습을 수행하기 위해 객체 정보가 포함된 학습용 영상 데이터를 취득하고, 영상 내 객체의 위치 및 크기 정보를 분석하는 학습용 영상데이터 취득 및 분석 단계; 2) PTZ 카메라 제어를 위해 PTZ 카메라의 액션값을 선택하는 단계; 3) Pan Left, Pan Right, Tilt Up, Tilt Down, Zoom이 포함된 PTZ 카메 라의 제어 방향을 추정해 리워드(Reward)를 계산하여, 상기 선택된 액션값을 이용하여 추정된 카메라 제어 방향 으로 PTZ 카메라를 이동시키고, PTZ 카메라 이동 후 영상 내 객체의 위치 변화에 적응적으로 Reward를 부여하는 단계; 4) 카메라의 액션 전,후 상태와 Reward가 포함된 데이터셋을 저장하는 단계; 5) 저장 데이터셋의 개수가 사전 결정된 개수 이상인지 판단하는 단계; 6) 저장된 데이터셋을 기반으로 강화학습 모델을 생성하는 단계를 포함한다. 또한, 상기 과제를 해결하기 위한 다른 측면에 따르면, 입력층, 출력층, 및 은닉층을 포함하는 인공신경망을 포 함하는 강화학습 모델이 제공된다. 이 강화학습 모델은, 상기 인공신경망의 가중치(weight)를 이용해 딥 Q-러닝 (deep Q-learning) 함수를 계산하여 PTZ 카메라 제어에 대한 현재 학습 목표를 설정하는 수단; 상기 설정된 PTZ 카메라 제어에 대한 현재 학습 목표에 따라 실제의 PTZ 카메라 액션을 수행하여 PTZ 카메라 제어에 대한 다음 단계 학습 목표를 설정하는 수단; PTZ 카메라 제어에 대한 상기 현재 학습 목표와 다음 단계 학습 목표의 에러 를 줄이도록 가중치를 갱신하여서 PTZ 카메라 제어에 대해 강화학습을 수행하는 수단을 포함한다. 이상에서 소개한 본 발명의 구성 및 작용은 차후에 도면과 함께 설명하는 구체적인 실시예를 통하여 더욱 명확 해질 것이다."}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 강화학습을 이용함으로써 객체의 위치와 크기에 최적화 된 PTZ 카메라 제어가 가능하며, 이 러한 강화학습 기반 PTZ 카메라 자동 제어에 의해 지능형 보안관제 시스템의 영상관제 효율성이 향상되고, 업무 부담이 감소될 수 있다."}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 기술되어 있는 실시 예를 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예에 한정되는 것이 아니라 서로 다 른 다양한 형태로 구현될 수 있는 것이며, 단지 본 실시예는 본 발명의 개시가 완전하도록 하여 본 발명이 속하"}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명의 기술적 범위는 청구항의 기재에 의해 정의된다. 한편, 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것이 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한 다(comprises)\" 또는 \"포함하는(comprising)\"은 언급된 구성요소, 단계, 동작 및/또는 소자 이외의 하나 이상의 다른 구성요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 이하, 본 발명의 바람직한 실시예를 첨부 도면을 참조하여 상세히 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가급적 동일한 부호를 부 여하고 또한 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있는 경우에는 그 상세한 설명을 생략한다. 도 1은 본 발명의 강화학습 모델에 사용된 인공신경망 구조를 나타낸다. 도 1에 나타낸 인공신경망은 입력층 (Innput layer)과 출력층(Output layer) 사이에 4개의 은닉층(Hidden layer)(30-1, 30-2, 30-3, 30- 4)을 갖고 있다. 도 2는 도 1의 인공신경망에 적용된 파라미터를 나타낸다. 도 2에서 각 파라미터에 대해 개략적으로 설명한다. - 최적화 기법(Optimizer)으로는 Adam을 사용하였다. 최적화는 신경망 모델의 학습과 그 결과에 따른 손실함수 의 값을 최소화하는 방향으로 하이퍼파라미터의 값을 찾는 것이며, 이러한 최적화를 위한 다양한 기법 중 하나 인 Adam 기법을 사용하였다. - 손실함수(Loss functioin)는 모델을 통해 생성된 결과값과 실제로 발생하기를 원했던 값 간의 차이를 계산하 는 함수로, 목적에 따라 여러 종류의 함수가 존재할 수 있는데, 이를 위해 많이 사용되는 mse(mean square error)를 본 발명에서도 사용하였다. mse는 추정한 값과 기대했던 값간의 차이를 측정하기 위해 에러 또는 편차 의 제곱의 평균을 측정한다. 제곱값을 이용하므로 에러에 따른 값 변화가 커서 추측의 정확성이 높아지는 장점 이 있다. - 활성화 함수(Activation function)는 신호를 입력받아 이를 적절한 처리를 하여 출력해주는 함수로서, 이를 통해 출력된 신호가 다음 단계에서 활성화되는지를 결정한다. 활성화 함수로, 은닉층에는 ReLU(Rectified Linear Unit) 함수를, 출력층에는 Linear 함수를 사용하였다. - 학습률(Learning Rate)은 한 번 학습할 때 얼마만큼 학습해야 하는지의 학습의 양을 의미하며 한 번의 학습량 으로 학습한 이후에 가중치 파라미터가 갱신된다. 학습률 값은 미리 0.01, 0.001과 같이 특정 값을 정해두어야 하며 일반적으로 이 값이 너무 크거나 작으면 적합한 지점으로 찾아가기가 어렵다. 신경망 학습에서는 보통 이 학습률 값을 변경하면서 올바르게 학습하고 있는지를 확인한다. 학습률이 너무 크면 큰 값을 출력하고, 너무 작 으면 거의 갱신되지 않고 학습이 끝나버린다. 본 발명에서는 0.001을 학습률로 설정하였다. - 뱃치사이즈(Batch size)는 한 번의 학습시 사용되는 데이터의 수를 의미하는 것으로 여기서는 128개로 설정하 였다. - 세대수(Epochs)는 전체 데이터에 대한 한 번의 학습수(forward 와 backward 포함)를 의미하는데, 본 발명에서 는 35로 설정하였다. - 리워드가 리턴(return)되는 단위 구간인 에피소드(Episode)는 1000으로 설정하였다. 이러한 인공신경망을 포함하는 강화학습 모델은, 이 인공신경망의 가중치(weight)를 이용해 딥 Q-러닝(deep Q- learning) 함수를 계산하여 PTZ 카메라 제어에 대한 현재 학습 목표를 설정한 후에 실제 PTZ 카메라 제어 액션 을 수행하여 PTZ 카메라 제어에 대한 다음 단계 학습 목표를 설정한다. PTZ 카메라 제어에 대한 현재 학습 목표 와 다음 단계 학습 목표의 에러를 줄이도록 가중치를 갱신하여서 PTZ 카메라 제어에 대해서 강화학습을 수행한 다. 강화학습 모델에 대해서는 추후에 다시 설명한다. 도 3은 본 발명에서 제안하는 지능형 영상 관제 시스템의 PTZ 카메라 자동제어를 위한 강화학습 모델 생성 방법 의 흐름도이다. 도 3을 참조하여 본 발명에 따른 PTZ 카메라 자동제어를 위한 강화학습 모델을 생성하는 방법에대해 설명한다. 110: 강화학습을 수행하기 위해 객체 정보가 포함된 학습용 영상 데이터를 취득하고, 영상 내 객체의 위치 및 크기 [x, y, w(width), h(height)] 정보를 분석하는 학습용 영상데이터 취득 및 분석 단계. 120: 110의 단계를 수행한 후, PTZ 카메라 제어를 위해 PTZ 카메라의 액션값을 선택하는 단계. 여기서 카메라의 액션값은 (0.02, 0.06, 0.1, 0.14, 0.18, 0.22, 0.26, 0.3)으로 정의하며, 정의된 액션값은 수학식 1을 통해 선택된다. PTZ 카메라의 액션값 는 수학식 1에서 값에 의해 무작위로 선택되거나, 학습되 지 않은 강화학습 모델로 액션값을 선택한다. 여기에서 는 1이며, 반복횟수 가 증가할수록 수학식 2의 제약 조건에 따라 값이 감소한다. 즉, 감소된 값이 임계값인 와 같거나 이보다 클 경우에만 액션값 를 무작위로 선택하며, 그렇지 않은 경우에는 현재 상태 와 학습되지 않은 강화학습 모델로 액션값을 선택한다. 수학식 2는 제약조건으로, 는 를 감소시키는 값이고, 은 값이 마이너스로 떨어지지 않게 하는 양 수 값이다. 수학식 1"}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2"}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "130: 이전 120 단계를 수행한 후, PTZ 카메라의 자동제어 방향을 추정해 리워드(Reward)를 계산하는 단계 화면의 중심 좌표와 객체의 현재 좌표를 수학식 3을 통해 분석하여 PTZ 카메라의 제어 방향(즉, Pan Left, Pan Right, Tilt Up, Tilt Down, Zoom)을 추정한다. 수학식 3"}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 는 현재 객체의 가로 위치와 취득한 영상의 가로 중심 거리의 차이를 나타내고, 는 현재 객체 의 세로 위치와 취득한 영상의 세로 중심 거리의 차이를 말한다. 또한 는 임계값 상수이고, 와 가 보다 작을 때 Zoom In을 카메라 제어 방향으로 추정한다. 그 외에는 Pan, Tilt를 수행하는데 가 양수일 경우 Pan Right, 음수일 경우 Pan Left를 이동 방향으로 추정하고, 가 양수일 경우 Tilt Down, 음수일 경우 Tilt UP으로 카메라 제어 방향을 추정한다. 이 단계에서는 앞의 단계 120에서 선택된 액션값을 이용하여 추정된 카메라 제어 방향으로 PTZ 카메라를 이동시 킨다. PTZ 카메라 이동 후 영상 내 객체의 위치 변화에 적응적으로 Reward를 부여한다. 이를 위해 먼저 Pan과 Tilt에 관한 PTZ 카메라 움직임 발생시 수학식 4, 5, 6을 이용하여 이동 방향 및 액션값 에 대응되는 Reward rt를 계산한다. 여기서 는 카메라 움직임 이전 상태에서 객체의 위치와 화면 중심의 거리 차이고, 은 카메라 이동 후 변한 객체의 위치와 화면 중심의 거리 차이다. 은 정규화 상수이고, τ 1은 Pan과 Tilt의 목표 크기이다. 수학식 4"}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 5"}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 6"}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "다음으로 수학식 7, 8을 이용하여 Zoom에 관한 Reward rt를 계산한다. 여기서 와 는 각각 카메라 이동 전,후에 대한 객체 크기 정보이고, 앞의 과 수학식 5, 6의 는 정규화 상수로 예컨대 각각 100, 10으로 설정가능하다. 그리고 는 를 반영하는 상수로 예컨대 1.2로 설정가능하며, 는 Zoom의 목표 크기로 예컨대 70으로 설정할 수 있다. 수학식 7"}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "수학식 8 이와 같이 수학식 4~8을 이용하여 Pan, Tilt, Zoom 이동이 각각 가로, 세로의 중심과 목표 크기에 가까워질 경 우 +Reward를 갖고 반대의 경우 -Reward를 갖기 때문에 이동값 및 방향에 대해 적응적으로 Reward를 부여할 수 있다. 140: 이전 130 단계를 수행한 후, 액션 전,후 상태와 Reward를 저장하는 단계. 저장할 액션 전,후 상태 및 Reward가 포함된 데이터셋은 11개의 세부 데이터로 구성되어 있으며 각 세부 데이터 항목은 다음과 같다. - 카메라 이동 전 객체 상태정보(x, y, width, height) - 액션값 추정 정보(0~7) - Reward - 카메라 이동 후 객체 상태정보(x, y, width, height) - 종료 Flag 150: 이전 140 단계를 수행한 후, 저장 데이터셋의 개수가 일정 개수 이상인지 판단하는 단계. 일 실시예에서는 강화학습에 사용할 목적으로 액션 전,후 상태와 Reward로 구성된 데이터셋 개수가 3000개 이상 인지 확인한다. 160: 이전 150 단계를 수행한 후, 저장된 데이터셋을 기반으로 강화학습 모델을 생성하는 단계. 강화학습 모델을 생성하기 위해 수학식 9를 사용한다. 수학식 9"}
{"patent_id": "10-2018-0139202", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "위 수학식 9는 강화학습시의 학습 목표 설정에 관한 수식으로서, 각 변수의 정의는 다음과 같다. : 반복 횟수, : 총 반복 횟수 : 현재 단계의 상태, : 다음 단계의 상태. 좀 더 구체적으로, 는 객체의 현재 좌표 및 크기이고, 은 120과 130 단계에서 추정된 액션값과 방향으로 PTZ 카메라를 이동시켰을 때의 객체의 좌표 및 크기이다 (객체의 좌표 및 크기 임). : 현재 단계의 액션값, : 다음 단계의 액션값 (본 발명에서 액션값은 (0.02, 0.06, 0.1, 0.14, 0.18, 0.22, 0.26, 0.3) 중 선택된 값) : 무작위성을 조절하는 가중치(Weight)(E-greedy 방법 사용) : 현재 단계의 Reward : 인공신경망의 Weight, : 복사된 인공신경망의 Weight : Deep Q-learning 함수 (Q값을 산출한다) 수학식 9에서 ①번 항은 인공신경망 를 이용해 PTZ 카메라의 현재 상태 와 현재 액션값 로 Q값(딥 Q- 러닝 함수값)을 계산한다(PTZ 카메라에 대한 현재 학습 목표 설정). ②번 항은 ①번 항에서 선택한 값으로 실제 PTZ 카메라 액션을 수행한 후 변경된 다음 단계의 PTZ 카메라 상태 와 새롭게 선택된 액션값 를 이용하여 복사된 인공신경망 을 통해 최대가 되는 Q값을 계산한다. 산출된 Q값은 가중치 로 조절하며, ① 번 항 수행 후에 습득한 Reward를 결합한다(PTZ 카메라에 대한 다음 단계 학습 목표 설정). ① 항과 ② 항의 에 러를 줄일 수 있는 인공신경망 를 학습함으로써 PTZ 카메라에 대한 강화학습이 수행된다. 이상에서, 본 발명의 바람직한 실시예를 통하여 본 발명의 구성을 상세히 설명하였으나, 본 발명이 속하는 기술 분야의 통상의 지식을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 본 명세서에 개시된 내용과는 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 이상에서 기술한 실시예 들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 본 발명의 보호범위는 상기 상세한 설명보다는 후술한 특허청구범위에 의하여 정해지며, 특허청구의 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태는 본 발명의 기술적 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2018-0139202", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 강화학습 모델의 인공신경망 구조 도 2는 도 1의 인공신경망에 적용된 파라미터 도 3은 본 발명에서 제안하는 지능형 영상 관제 시스템의 PTZ 카메라 자동제어를 위한 강화학습 모델 생성 방법 의 흐름도"}
