{"patent_id": "10-2018-0028194", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0109671", "출원번호": "10-2018-0028194", "발명의 명칭": "감정 공유를 위한 커플 로봇 및 이를 이용한 감정 공유 방법", "출원인": "이화여자대학교 산학협력단", "발명자": "류한영"}}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자들 간의 감정 공유를 위한 한 쌍으로 구성된 커플 로봇에 있어서,상기 커플 로봇은 제1 로봇 및 제2 로봇을 포함하고, 제1 로봇 및 제2 로봇은 각각,상기 사용자로부터 감지된 정보를 데이터로 변환하는 인터페이스부;상기 인터페이스부가 변환한 데이터를 기초로 상기 사용자의 감정상태를 판단하는 판단부;상기 사용자의 감정상태를 송수신하는 통신부; 및상기 감정상태에 대응하는 동작을 출력하는 출력부;를 포함하고,상기 커플 로봇은,상기 제1 로봇의 상기 판단부에서 판단한 제1 사용자의 감정상태를 상기 제2 로봇으로 송신하여, 상기 제2 로봇의 출력부에서 상기 제1 사용자의 감정상태에 대응하는 동작이 출력되는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 제1 사용자의 감정상태를 수신한 상기 제2 로봇은,상기 출력부가 상기 감정상태에 대응하는 상세정보를 제2 사용자에게 출력하고, 상기 인터페이스부가 상기 제2사용자로부터 감지된 피드백을 데이터로 변환하여, 상기 판단부가 상기 제2 사용자의 감정상태를 판단하고, 상기 통신부가 상기 제2 사용자의 감정상태를 상기 제1 로봇으로 송신하며,상기 제2 사용자의 감정상태를 수신한 상기 제1 로봇은,상기 제2 사용자의 감정상태에 대응하는 동작을 출력하는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 인터페이스부는,상기 사용자로부터 복수의 정보 또는 피드백을 감지하고,상기 판단부는,상기 감지된 정보 또는 피드백에 대응하는 동작의 출력에 대한 우선순위를 지정하며,상기 출력부는,상기 우선순위에 따라 상기 감지된 정보 또는 피드백에 대응하는 동작을 출력하는, 감정 공유를 위한 커플로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,공개특허 10-2019-0109671-3-상기 제2 로봇의 인터페이스부는,상기 제2 사용자로부터 상기 상세정보의 출력에 대한 요청을 감지하여, 상기 제2 로봇의 출력부로 전달하고,상기 출력에 대한 요청을 수신한 제2 로봇의 출력부는,상기 상세정보를 상기 제2 사용자에게 출력하는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 커플 로봇 한 쌍의 결합시 상기 제1 로봇의 상기 출력부와 상기 제2 로봇의 상기 출력부가 연결되어 동작,형상 디스플레이, 소리, 음성, 이모티콘, 디밍, 색변화, 텍스트, 영상 및 음악 중 적어도 하나를 포함하는 결합신호를 동시에 출력하는 출력단;을 형성하는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 사용자로부터 감지된 정보는,상기 사용자의 음성, 표정, 제스처, 체온, 혈압, 호흡수, 맥박, 외부로부터 감지되는 접촉, 주변온도, 텍스트,이모티콘, 그림, 영상, 음악 중 적어도 하나를 포함하고,상기 감정상태에 대응하는 동작은,형상 디스플레이, 소리, 음성, 이모티콘, 디밍, 색변화, 텍스트, 영상 및 음악 중 적어도 하나를 포함하는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 판단부는,상기 인터페이스부에 의해 상기 사용자로부터 감지된 정보 중 상기 사용자로부터 감지되는 접촉이 상기 데이터로 변환되는 경우, 상기 로봇에 접촉한 상기 사용자의 신체부위를 구분하는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 커플 로봇 한 쌍의 각 출력부는,상기 판단부에 의해 구분된 상기 사용자의 신체부위에 대응하여 기설정된 동작을 수행하는, 감정 공유를 위한커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 6 항에 있어서,상기 판단부는,상기 주변온도, 상기 사용자의 체온, 혈압, 호흡수, 및 맥박 중 적어도 하나를 기초로 상기 사용자의 건강상태를 판단하고공개특허 10-2019-0109671-4-상기 통신부는 상기 건강상태를 송수신하는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 사용자로부터 감지된 정보는,상기 사용자의 지문, 홍채 및 얼굴 중 적어도 하나의 인식정보를 더 포함하며,상기 판단부는,상기 인식정보를 기초로 상기 사용자를 인식하는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서,상기 커플 로봇 한 쌍은,결합시 기설정된 형상을 유지하도록 접촉단이 형성된 결합부;를 더 포함하고,상기 접촉단의 결합방식은,걸쇠식, 삽입식, 나사식, 자기식 및 접촉식 중 하나의 방식을 포함하는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 기설정된 형상은,삼각형(△), 하트형(♡), 아치형(∩), 사각형(□) 및 원형(○) 중 하나를 포함하는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 1 항에 있어서,상기 제1 로봇의 인터페이스부는,상기 제1 로봇과 상기 제1 사용자의 대화 정보를 기록한 공유카드를 상기 제1 로봇의 통신부로 전달하고,상기 제1 로봇의 통신부는,상기 공유카드를 상기 제2 로봇의 통신부로 송신하는, 감정 공유를 위한 커플 로봇."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "결합시 기설정된 형상을 형성하는 제1 로봇 및 제2 로봇을 포함하는 한 쌍으로 구성된 커플 로봇을 이용한 감정공유 방법에 있어서,상기 제1 로봇이 제1 사용자로부터 감지된 정보를 데이터로 변환하는 단계;상기 제1 로봇이 상기 데이터를 기초로 상기 제1 사용자의 감정상태를 판단하는 단계;상기 제1 로봇이 판단한 상기 제1 사용자의 감정상태를 상기 제2 로봇으로 송신하는 단계; 및공개특허 10-2019-0109671-5-상기 제2 로봇을 통해 상기 제1 로봇이 판단한 상기 제1 사용자의 감정상태에 대응하는 동작을 출력하는 단계;를 포함하는, 커플 로봇을 이용한 감정 공유 방법."}
{"patent_id": "10-2018-0028194", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 제1 로봇이 판단한 상기 제1 사용자의 감정상태를 상기 제2 로봇으로 송신하는 단계는,상기 제1 로봇과 상기 제1 사용자의 대화 정보를 기록한 공유카드를 송신하는, 커플 로봇을 이용한 감정 공유방법."}
{"patent_id": "10-2018-0028194", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사용자들 간의 감정 공유를 위한 한 쌍으로 구성된 커플 로봇에 있어서, 상기 커플 로봇은 제1 로봇 및 제2 로봇을 포함하고, 제1 로봇 및 제2 로봇은 각각 상기 사용자로부터 감지된 정보를 데이터로 변환하는 인 터페이스부; 상기 인터페이스부가 변환한 데이터를 기초로 상기 사용자의 감정상태를 판단하는 판단부; 상기 사 용자의 감정상태를 송수신하는 통신부; 및 상기 감정상태에 대응하는 동작을 출력하는 출력부;를 포함하고, 상기 커플 로봇은 상기 제1 로봇의 상기 판단부에서 판단한 제1 사용자의 감정상태를 상기 제2 로봇으로 송신하여, 상 기 제2 로봇의 출력부에서 상기 제1 사용자의 감정상태에 대응하는 동작이 출력된다."}
{"patent_id": "10-2018-0028194", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사용자들 간의 감정 공유를 위해 한 쌍의 로봇으로 구성된 커플 로봇 및 이를 이용한 감정 공유 방법 에 관한 것이다."}
{"patent_id": "10-2018-0028194", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자동 청소기 로봇과 같이 사용자의 편의를 향상시키기 위해 로봇의 개발이 진행되었으며, 다양한 형태의 로봇이 개발되고 있다. 최근에는, 클라우드 시스템과 로봇기술이 결합되어 개발되고 있으며, 그 예로 아마존의 Kiva가 있다. 아마존의 Kiva는 창고 관리형 로봇시스템으로, 다수의 로봇이 동일한 정보를 공유하며 창고 물류를 관리 하는 시스템이다. 또한, 인공지능 기술과 머신러닝 기술의 결합을 통해 발전된 형태의 로봇이 공급되고 있다. 특히, KT의 기가지 니, SKT NUGU와 같은 인공지능 스피커의 등장으로 1인 가구에 대한 로봇의 공급 및 수요가 확장되고 있으나, 이 러한 인공지능 스피커는 사용자와 스피커 간 1:1 교감만을 제공하고 있다. 이처럼 다양한 형태의 로봇이 개발되 고 있지만, 로봇 사용자의 감정을 타인에게 전달하기 위한 방법은 제한적이다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2016-0072956호"}
{"patent_id": "10-2018-0028194", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 목적은 종래의 통신수단이 음성, 텍스트 및 영상과 같은 제한적인 정보에 기초하여 통신하는 것을 보완하기 위해, 터치정보, 생체정보, 대화정보 등을 추가적으로 전달하고, 사용자 간에 감정을 공유하게 하는 커플 로봇을 제공하는데 있다. 또한, 본 발명의 다른 목적은 통신 기능뿐 아니라, 결합을 통해 새로운 형상을 구성하고, 결합신호를 출력하는 커플 로봇을 제공하는데 있다. 또한, 본 발명의 또 다른 목적은 입력된 정보의 전달뿐 아니라 이를 기초로 사용자의 감정을 분석하여 공유하는 감정 공유 방법을 제공하는데 있다."}
{"patent_id": "10-2018-0028194", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 사용자들 간의 감정 공유를 위한 한 쌍으로 구성된 커플 로봇에 있어서, 상기 커 플 로봇은 제1 로봇 및 제2 로봇을 포함하고, 제1 로봇 및 제2 로봇은 각각, 상기 사용자로부터 감지된 정보를 데이터로 변환하는 인터페이스부; 상기 인터페이스부가 변환한 데이터를 기초로 상기 사용자의 감정상태를 판단 하는 판단부; 상기 사용자의 감정상태를 송수신하는 통신부; 및 상기 감정상태에 대응하는 동작을 출력하는 출 력부;를 포함하고, 상기 커플 로봇은, 상기 제1 로봇의 상기 판단부에서 판단한 제1 사용자의 감정상태를 상기 제2 로봇으로 송신하여, 상기 제2 로봇의 출력부에서 상기 제1 사용자의 감정상태에 대응하는 동작이 출력된다. 또한, 상기 제1 사용자의 감정상태를 수신한 상기 제2 로봇은 상기 출력부가 상기 감정상태에 대응하는 상세정 보를 제2 사용자에게 출력하고, 상기 인터페이스부가 상기 제2 사용자로부터 감지된 피드백을 데이터로 변환하 여, 상기 판단부가 상기 제2 사용자의 감정상태를 판단하고, 상기 통신부가 상기 제2 사용자의 감정상태를 상기 제1 로봇으로 송신하며, 상기 제2 사용자의 감정상태를 수신한 상기 제1 로봇은 상기 제2 사용자의 감정상태에 대응하는 동작을 출력할 수 있다. 또한, 상기 인터페이스부는 상기 사용자로부터 복수의 정보 또는 피드백을 감지하고, 상기 판단부는 상기 감지 된 정보 또는 피드백에 대응하는 동작의 출력에 대한 우선순위를 지정하며, 상기 출력부는 상기 우선순위에 따 라 상기 감지된 정보 또는 피드백에 대응하는 동작을 출력할 수 있다. 또한, 상기 제2 로봇의 인터페이스부는 상기 제2 사용자로부터 상기 상세정보의 출력에 대한 요청을 감지하여, 상기 제2 로봇의 출력부로 전달하고, 상기 출력에 대한 요청을 수신한 제2 로봇의 출력부는 상기 상세정보를 상 기 제2 사용자에게 출력할 수 있다. 또한, 상기 커플 로봇은 상기 로봇 한 쌍의 결합시 제1 로봇의 상기 출력부와 제2 로봇의 상기 출력부가 연결되 어 동작, 형상 디스플레이, 소리, 음성, 이모티콘, 디밍, 색변화, 텍스트, 영상 및 음악 중 적어도 하나를 포함 하는 결합신호를 동시에 출력하는 출력단;을 형성할 수 있다. 또한, 상기 사용자로부터 감지된 정보는 상기 사용자의 음성, 표정, 제스처, 체온, 혈압, 호흡수, 맥박, 외부로 부터 감지되는 접촉, 주변온도, 텍스트, 이모티콘, 그림, 영상, 음악 중 적어도 하나를 포함하고, 상기 감정상 태에 대응하는 동작은 형상 디스플레이, 소리, 음성, 이모티콘, 디밍, 색변화, 텍스트, 영상 및 음악 중 적어도 하나를 포함할 수 있다. 또한, 상기 판단부는 상기 인터페이스부에 의해 상기 사용자로부터 감지된 정보 중 상기 사용자로부터 감지되는 접촉이 상기 데이터로 변환되는 경우, 상기 로봇에 접촉한 상기 사용자의 신체부위를 구분할 수 있다. 또한, 상기 한 쌍의 로봇의 각 출력부는 상기 판단부에 의해 구분된 상기 사용자의 신체부위에 대응하여 기설정 된 동작을 수행할 수 있다. 또한, 상기 판단부는 상기 주변온도, 상기 사용자의 체온, 혈압, 호흡수, 및 맥박 중 적어도 하나를 기초로 상 기 사용자의 건강상태를 판단하고, 상기 통신부는 상기 건강상태를 송수신할 수 있다. 또한, 상기 사용자로부터 감지된 정보는 상기 사용자의 지문, 홍채 및 얼굴 중 적어도 하나의 인식정보를 더 포 함하며, 상기 판단부는 상기 인식정보를 기초로 상기 사용자를 인식할 수 있다. 또한, 상기 커플 로봇 한 쌍은 결합시 기설정된 형상을 유지하도록 접촉단이 형성된 결합부;를 더 포함하고, 상 기 접촉단의 결합방식은 걸쇠식, 삽입식, 나사식, 자기식 및 접촉식 중 하나의 방식을 포함할 수 있다. 또한, 상기 기설정된 형상은 삼각형(△), 하트형(♡), 아치형(∩), 사각형(□) 및 원형(Ο) 중 하나를 포함할 수 있다. 또한, 상기 제1 로봇의 인터페이스부는 상기 제1 로봇과 사용자의 대화 정보를 기록한 공유카드를 상기 제1 로 봇의 통신부로 전달하고, 상기 제1 로봇의 통신부는 상기 공유카드를 상기 제2 로봇의 통신부로 송신할 수 있다. 또한, 본 발명의 다른 실시 예에 따른 결합시 기설정된 형상을 형성하는 제1 로봇 및 제2 로봇을 포함하는 한 쌍으로 구성된 커플 로봇을 이용한 감정 공유 방법은, 상기 제1 로봇이 사용자로부터 감지된 정보를 데이터로 변환하는 단계; 상기 제1 로봇이 상기 데이터를 기초로 상기 사용자의 감정상태를 판단하는 단계; 상기 제1 로봇이 판단한 상기 사용자의 감정상태를 상기 제2 로봇으로 송신하는 단계; 및 상기 제2 로봇을 통해 상기 제1 로봇이 판단한 사용자의 감정상태에 대응하는 동작을 출력하는 단계;를 포함한다. 또한, 상기 제1 로봇이 판단한 상기 사용자의 감정상태를 제2 로봇으로 송신하는 단계는 상기 제1 로봇과 상기 사용자의 대화 정보를 기록한 공유카드를 송신할 수 있다."}
{"patent_id": "10-2018-0028194", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 커플 로봇 및 감정 공유 방법은, 커플 로봇 중 제1 로봇을 통해 판단된 일 사용자의 감정상태와 함께 일 사용자로부터 입력된 정보를 커플 로봇 중 제2 로봇과 공유하여, 일 사용자의 감정상태를 타 사용자가 공감할 수 있다. 또한, 본 발명에 따른 커플 로봇은, 로봇 한 쌍의 결합부를 통해 용이하게 결합되어, 펜던트, 커플링과 같은 커 플 아이템 형태 등 제1 로봇의 형태와 다른 새로운 형태로 제공될 수 있다. 또한, 본 발명에 따른 커플 로봇은 제1 로봇의 사용자로부터 감지된 음성, 제스처, 체온, 혈압, 접촉 등을 데이 터로 변환하여 제1 로봇이 사용자의 감정을 판단하고, 이를 제2 로봇으로 전달함으로써 로봇 사용자간 송수신하 는 감정상태의 신뢰도를 향상시킬 수 있다. 나아가, 본 발명의 커플 로봇은 수요대상이 커플뿐만 아니라 노인 복지 분야, 원거리 상담 분야 등으로 확장될 수 있다."}
{"patent_id": "10-2018-0028194", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면들에 기재된 내용들을 참조하여 본 발명을 상세히 설명한다. 다만, 본 발명이 예시적 실시 예 들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일 참조부호는 실질적으로 동일한 기능을 수 행하는 부재를 나타낸다. 본 발명의 목적 및 효과는 하기의 설명에 의해서 자연스럽게 이해되거나 보다 분명해 질 수 있으며, 하기의 기 재만으로 본 발명의 목적 및 효과가 제한되는 것은 아니다. 또한, 본 발명을 설명함에 있어서 본 발명과 관련된 공지 기술에 대한 구체적인 설명이, 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 도 1은 본 발명의 일 실시 예에 따른 커플 로봇 중 제1 로봇의 측면사시도 및 정면도를 나타낸다. 도 2 는 본 발명의 일 실시 예에 따른 커플 로봇이 분리된 형태를 나타낸다. 도 3은 도 2의 커플 로봇이 결합 된 형태를 나타낸다. 도 1 내지 3을 참조하면, 본 발명의 일 실시 예에 따른 커플 로봇은 제1 로봇과 제2 로봇 한 쌍으로 구성될 수 있다. 제1 로봇과 제2 로봇은 각각 별도로 형성될 수 있으며, 결합시 각 형상과는 다른 새로 운 형상을 형성할 수 있다. 제1 로봇과 제2 로봇은 각기 다른 구성요소를 포함하거나 동일한 구성요소 를 포함할 수 있다. 커플 로봇 중 제1 로봇은 결합부, 인터페이스부, 판단부, 통신부 및 출력부 를 포함할 수 있다. 이와 별도로, 커플 로봇 중 제2 로봇은 결합부, 인터페이스부(미도시), 판단부 (미도시), 통신부(미도시) 및 출력부를 포함할 수 있다. 이하에서는, 커플 로봇 중 제1 로봇의 구 성을 중심으로 설명한다. 커플 로봇은 제1 로봇의 판단부에서 판단한 제1 사용자의 감정상태를 제2 로봇으로 송신하여, 제2 로봇의 출력부에서 제1 사용자의 감정상태에 대응하는 동작이 출력될 수 있다. 이를 통해, 커플 로봇은 사용자들 간의 감정을 공유하기 위한 매개체 역할을 수행할 수 있다. 또한, 제1 로봇 및 제2 로 봇은 각 로봇의 사용자와 교감할 수 있다. 커플 로봇 각각은 운반이 자유롭고 상호 작용하기 용이한 중 소형의 크기로 제공될 수 있다. 제1 로봇과 제2 로봇의 각 결합부(111, 131)는 제1 로봇과 제2 로봇이 결합할 경우, 기설정된 형상을 유지하도록 접촉단이 형성될 수 있다. 결합부(111, 131)는 접촉단의 결합방식에 따라 걸쇠식, 삽입식, 나사식, 자기식, 접촉식 중 하나의 방식으로 결합될 수 있다. 접촉식으로 결합되는 경우, 결합부(111, 131)는 접촉단의 형상에 따라 면접촉, 선접촉, 점접촉 등이 이루어질 수 있다. 인터페이스부는 사용자로부터 감지된 정보를 데이터로 변환할 수 있다. 인터페이스부는 제1 로봇 내부에 배치될 수 있다. 사용자로부터 감지된 정보는 사용자의 음성, 표정, 제스처, 체온, 혈압, 호흡수, 맥박, 외부로부터 감지되는 접촉, 주변온도, 텍스트, 이모티콘, 그림, 영상, 음악 중 적어도 하나를 포함할 수 있다. 인터페이스부는 해당 정보를 데이터화 하여 판단부 및 통신부로 전달할 수 있다. 판단부는 인터페이스부가 변환한 데이터를 기초로 사용자의 감정상태를 판단할 수 있다. 판단부(11 5)는 제1 로봇 내부에 배치될 수 있다. 판단부는 기쁨, 즐거움, 분노, 슬픔 등의 카테고리로 사용자의 감정상태를 분류할 수 있다. 판단부가 사용자의 감정상태를 판단하는 신뢰도는 데이터가 누적됨에 따라 향 상될 수 있다. 판단부는 판단한 감정상태를 통신부 및 출력부로 전달할 수 있다. 통신부는 사용자의 감정상태를 송수신 할 수 있다. 통신부는 제1 로봇 내부에 배치될 수 있다. 통신부는 인터페이스부에서 전달받은 데이터 및 판단부에서 전달받은 감정상태를 송수신할 수 있다. 즉, 제1 로봇의 통신부로부터 송신된 데이터 및 감정상태가 제2 로봇의 통신부에서 수신될 수 있다. 또한, 제2 로봇의 통신부는 데이터 및 감정상태를 제2 로봇의 출력부를 통해 출력할 수 있다. 제1 로봇과 제2 로봇의 각 출력부(119, 139)는 사용자의 감정상태에 대응하는 동작을 출력할 수 있다. 출력부(119, 139)는 각각 제1 로봇의 통신부 또는 제2 로봇의 통신부로부터 전달받은 감정상태에 대응하는 기설정된 동작을 출력할 수 있다. 감정상태에 대응하는 동작은 형상 디스플레이, 소리, 음성, 이모티 콘, 디밍, 색변화, 텍스트, 영상 및 음악 중 적어도 하나를 포함할 수 있다. 출력부(119, 139)는 사용자와 교감 하기 위해 기입력된 음성 또는 사용자가 설정한 성별 및 나이대에 해당하는 음성으로 단어 및 문장을 출력할 수있다. 출력부(119, 139)는 다양한 효과음을 출력하여 사용자에게 수행중인 기능을 알릴 수 있다. 도 3을 참조하면, 결합된 커플 로봇(1a)은 각 로봇의 결합부(111, 131)를 통해 결합되는 것을 확인할 수 있다. 결합된 커플 로봇(1a)은 각 로봇의 출력부(119, 139)가 연결되어 각 로봇의 출력부(119, 139)와 다른 새로운 형 태의 출력단을 형성할 수 있다. 결합된 커플 로봇(1a)의 출력단은 결합신호를 출력할 수 있다. 결합 신호는 동작, 형상 디스플레이, 소리, 음성, 이모티콘, 디밍, 색변화, 텍스트, 영상 및 음악 중 적어도 하나를 포함할 수 있다. 출력단은 제1 로봇의 출력부의 일부 영역과 제2 로봇의 출력부 일부 영역에서 출력되는 신호의 조합을 통해 결합신호가 생성될 수 있다. 도 3과 같이, 제1 로봇의 출력부가 하트 형상의 좌측부분을, 제2 로봇의 출력부가 하트 형상 의 우측 부분을 출력하고 이를 통해 출력단은 결합된 하트 형상(♡)을 출력할 수 있다. 출력단이 생 성하는 결합신호는 이에 제한되지 않으며 음성, 이모티콘, 표정, 형상, 색변화 등 다양한 형태로 출력될 수 있 다. 이는, 커플 로봇의 각 라이트(1191, 1391), 스크린(1193, 1393) 및 스피커(1195, 1395)중 적어도 하나 를 통해 출력될 수 있다. 또한, 결합한 커플 로봇(1a)은 최초 디자인된 형태에 따라 삼각형(△), 하트형(♡), 아치형(∩), 사각형(□) 및 원형(Ο)과 같은 다양한 형상을 나타낼 수 있다. 한편, 커플 로봇의 크기가 휴대에 제한되는 경우, 커플 로 봇을 축소한 미니어처 등을 추가로 제작하여 사용자가 용이하게 휴대할 수 있으며, 미니어처의 결합을 통해 다양한 형상을 구현할 수 있다. 도 4는 본 발명에 따른 커플 로봇의 스크린에서 출력가능한 화면을 나타낸다. 도 4를 참조하면, 스크린은 감정상태를 표현하는 특정 이모티콘, 사용자가 입력한 영상, 텍스트, 그림 등 을 출력할 수 있다. 상세하게, 하트모양 이모티콘은 기쁜 감정상태를, 번개모양 이모티콘은 화난 감정상태를, 물방울모양 이모티콘은 슬픈 감정상태를 나타내며, 폭죽모양 이모티콘은 즐거운 감정상태를 나타낼 수 있다. 또 한, 이모티콘과 동시에 눈과 입으로 표현된 간단한 표정이 동시에 출력되어 감정상태를 직관적으로 판단할 수 있다. 이처럼, 감정상태를 표현하는 화면이 스크린을 통해 출력되지만, 표현 가능한 이모티콘 및 감정상 태는 이에 제한되지 않는다. 도 5 및 도 6은 본 발명에 따른 커플 로봇이 사용자의 접촉에 대응하는 동작을 수행하는 예시를 나타낸다. 도 5 및 도 6과 같이 커플 로봇에는 다양한 신체접촉이 이루어질 수 있다. 이때, 접촉을 감지한 로봇의 인터 페이스부는 사용자로부터 감지된 접촉을 데이터로 변환시킬 수 있으며, 판단부는 해당 데이터를 기초 로 사용자가 접촉한 신체부위를 구분할 수 있다. 이때, 인터페이스부는 판단부의 정확한 신체부위 구 분을 위해 사용자의 영상을 데이터로 변환하여 판단부로 전달할 수 있다. 판단부는 구분한 사용자의 신체부위를 출력부 및 통신부로 전달할 수 있다. 이어서, 출력부는 판단부에 의해 구분된 사용자의 신체부위에 대응하여 기설정된 동작을 수행할 수 있다. 예를 들어, 제1 사용자가 제1 로봇에 입술을 접촉하는 경우, 제1 로봇은 입술이 접촉한 것을 판단하고 키스마크 및 색변화 등과 같이 사용자의 입술 접촉에 대응되는 동작을 출력할 수 있다. 또한, 제1 사용자가 제1 로봇을 손으로 쓰다듬는 경우, 제1 로봇은 손이 접촉한 영역을 판단하고 붉은 계통의 색변화 및 기쁜 이모티콘 등과 같이 제1 사용자의 쓰다듬는 접촉에 대응되는 동작을 출력할 수 있다. 또한, 제1 사용자가 제1 로봇을 발로 차거나 미는 경우, 제1 로봇은 제1 사용자의 발이 접촉한 것을 판단하고 어두운 계통의 색 변화 및 화난 이모티콘 등과 같이 부정적인 감정상태를 표현하는 동작을 출력할 수 있다. 각 예시들을 도 5 및 도 6을 참조하여 자세히 설명한다. 또한, 사용자로부터 감지된 정보가 사용자의 지문, 홍채 및 얼굴 중 적어도 하나의 인식정보를 포함하는 경우, 판단부는 인식정보를 기초로 사용자를 인식할 수 있다. 판단부에서 사용자를 인식하면, 스크린(119 3)을 통해 초기화면이 출력될 수 있다. 이후, 사용자는 스크린의 메뉴를 선택함으로써 커플 로봇을 사 용할 수 있다. 즉, 커플 로봇 각각은 로봇의 사용자를 인식하기 위한 수단이 마련될 수 있으며, 이를 통해 커플 로봇의 보안성이 향상될 수 있다. 도 5를 참조하면, 제1 사용자가 제1 로봇에 키스를 하는 경우를 나타낸다. 이때, 제1 로봇의 판단부 는 제1 사용자의 신체부위를 입술로 인식할 수 있고, 출력부는 입술모양의 형상을 출력할 수 있다. 또한, 제1 로봇의 출력부는 라이트를 통해 그라데이션 효과를 나타내는 색변화를 출력할 수 있 다. 상세하게, 접촉된 부분의 주변은 진하고 선명한 색을 출력하고, 접촉된 부분과 멀어질수록 연한 색을 출력 할 수 있다. 이러한 과정은 제1 로봇에서 발생할 수 있다. 또한, 통신부를 통해 감정상태가 제2 로봇의 통신부와 송수신될 수 있으며, 제2 로봇의 출력부를 통해 감정상태에 대응하는 동작이 출력될 수 있다. 도 6을 참조하면, 제1 사용자가 제1 로봇을 손으로 쓰다듬는 경우 라이트를 통해 그라데이션 효과를 나타내는 색변화를 출력할 수 있다. 상세하게, 제1 로봇의 판단부는 제1 사용자의 신체부위를 손으로 인식할 수 있고, 제1 로봇의 출력부는 손이 접촉된 부분은 진하고 선명한 색을 출력하고, 이외의 부분 은 연한 색을 출력할 수 있으며, 접촉이 옮겨짐에 따라 이러한 색변화가 유동적으로 출력될 수 있다. 또한, 스 크린을 통해 이모티콘 및 표정이 출력될 수 있다. 이를 통해, 사용자와 로봇은 상호 교감할 수 있다. 다른 예로, 제1 사용자가 제1 로봇을 발로 차거나 미는 경우에는, 찡그린 표정과 함께 라이트를 통해 어두운 색을 기초로한 색변화가 출력될 수 있다. 이처럼, 커플 로봇은 판단부를 통해 사용자 신체부위 및 접촉형태를 구분하고, 기설정된 출력을 출력부에서 나타냄으로써 사용자와 다양하게 교감할 수 있다. 또한, 다양한 접촉형태를 제2 로봇과 공유함으로써 관련된 감정상태를 전달할 수 있다. 한편, 제1 로봇 및 제2 로봇의 각 인터페이스부(113, 미도시)는 각 사용자로부터 복수의 정보를 감지할 수 있다. 상세하게, 제1 로봇의 인터페이스부는 제1 사용자의 음성과 손으로 쓰다듬는 정보를 함께 감 지할 수 있다. 유사하게, 제1 로봇의 인터페이스부는 제1 사용자로부터 키스와 손으로 쓰다듬는 정보를 함 께 감지할 수 있다. 이처럼 인터페이스부가 복수의 정보를 감지하는 경우, 판단부는 정보에 대응하는 동작의 출력에 대한 우선순위를 지정하여 통신부와 출력부로 전달할 수 있다. 특히, 복수의 정보에 일기, 로봇과의 대화 등의 상세정보가 포함되는 경우 판단부는 상세정보에 대응하는 동작의 출력에 대한 우선순위를 낮출 수 있다. 판단부에서 우선순위를 지정하는 기준은 정보가 감지된 시간, 감지된 정보의 종류, 정보가 변환된 데이터 의 크기, 사용자의 예약 설정 여부 등일 수 있으나 이에 제한되지 않는다. 이후 출력부는 우선순위에 따라 감지된 정보에 대응하는 동작을 출력할 수 있다. 이와 동일하게 제2 로봇은 제2 사용자로부터 복수의 정보 를 감지하고, 대응동작을 출력할 수 있다. 이처럼, 각 사용자는 복수의 정보에 대응하는 동작을 출력하는 로봇 과 교감할 수 있다. 또한, 제1 사용자로부터 복수의 정보를 감지한 경우, 제1 로봇의 통신부는 제2 로봇의 통신부(미 도시)로 우선순위를 송신할 수 있다. 이때, 제2 로봇의 출력부는 우선순위에 따라 제1 사용자의 감정 상태에 대응하는 동작을 출력할 수 있다. 다만, 복수의 정보에 일기, 로봇과의 대화 등의 상세정보가 포함되는 경우 제2 로봇의 출력부는 상세정보의 출력여부에 대한 요청을 출력하여, 인터페이스부(미도시)를 통 해 상세정보에 대한 출력 요청을 감지하고, 출력부는 상세정보를 출력할 수 있다. 제2 로봇은 제2 사용자로부터 제1 사용자의 감정상태에 대응하는 복수의 피드백을 감지할 수 있다. 복수의 피드백을 감지하는 과정은 전술한 복수의 정보를 감지하는 것과 동일하게 진행될 수 있다. 이후, 제2 로봇 은 피드백의 출력에 대한 우선순위를 지정하여 제2 로봇의 통신부(미도시), 출력부 및 제1 로봇으 로 송신할 수 있다. 제1 로봇은 제2 로봇으로부터 우선순위를 전달받아 복수의 피드백에 대응하는 동작 을 출력할 수 있다. 이처럼, 제1 사용자와 제2 사용자는 감지된 정보 및 이에 대응하는 피드백을 공유하고, 이 에 대응하여 출력되는 다양한 동작을 통해 상대방의 감정상태를 공유할 수 있다. 도 7은 본 발명에 따른 커플 로봇이 카메라를 통해 영상을 촬영하는 예시를 나타낸다. 도 7을 참조하면, 제1 사용자는 카메라를 통해 영상 또는 사진을 촬영할 수 있다. 인터페이스부는 영상 또는 사진을 데이터화 하여 통신부 및 판단부로 전달하고, 제1 로봇의 통신부는 제2 로봇의 통신부로 데이터를 송신할 수 있다. 또한, 제1 로봇의 판단부는 영상에 나타난 제1 사용자 의 표정, 제스처 등을 기초로 사용자의 감정상태를 파악할 수 있다. 제2 로봇은 해당 데이터에 대응하는 동 작을 출력부를 통해 출력할 수 있다. 이때, 제2 로봇의 출력부는 영상 또는 사진의 도착을 알리 는 알람메시지 또는 효과음 등을 포함하는 동작을 스피커를 통해 출력할 수 있다. 효과음은 단순 기계음, 제2 사용자의 녹음된 목소리, 인공음성 등을 포함하여 사용자의 설정에 따라 다양하게 출력될 수 있다. 상세하 게, 효과음은 데이터 수신을 알리는 문장을 포함한 안내음성으로 출력될 수 있으며, 비프음과 같은 단순한 기계 음으로 출력될 수 있다. 도 8은 본 발명에 따른 커플 로봇 한 쌍이 각 스크린을 통해 동일한 동작을 수행하는 것을 나타낸다. 도 8을 참조하면, 제1 로봇이 물방울모양 이모티콘을 출력하고, 이와 관련된 감정상태를 전달받은 제2 로봇 이 동일한 이모티콘을 출력하여 실시간으로 제1 사용자의 감정상태를 공유하는 것을 확인할 수 있다. 이처럼, 커플 로봇은 실시간으로 사용자의 감정상태를 공유할 수 있으며, 감지되는 정보에 따라 다양한 상태를 공유할 수 있다. 상세하게, 제1 로봇의 인터페이스부가 주변온도, 제1 사용자의 체온, 혈압, 호흡수, 및 맥박 중 적어 도 하나의 정보를 데이터로 변환하여 판단부로 전달한 경우, 판단부는 이를 기초로 제1 사용자의 건 강상태를 판단하여 통신부 및 출력부로 전달할 수 있다. 이처럼, 제1 로봇의 통신부는 제1 사용자의 감정상태뿐 아니라 건강상태를 제2 로봇의 통신부로 송신할 수 있다. 제2 로봇은 송신된 건강 상태를 알리는 동작을 출력부를 통해 출력할 수 있다. 이를 통해, 제2 로봇의 제2 사용자는 제1 로봇 의 제1 사용자의 건강상태를 파악할 수 있다. 도 9는 본 발명에 따른 커플 로봇 한 쌍의 공유카드를 통한 감정 공유 과정을 나타낸다. 공유카드는 제1 로봇과 제1 사용자의 대화정보를 기록한 데이터로 판단부가 제1 사용자의 감정상태를 판단하는 기초자료가 될 수 있으며, 제1 로봇 및 제2 로봇의 통신부를 통해 커플 로봇간 공유될 수 있다. 제2 로봇의 제2 사용자는 공유카드를 통해 상세한 감정상태를 판단할 수 있으며, 제1 로봇의 판 단부에 의한 감정상태의 판단이 잘못된 경우 공유카드를 통해 정확한 감정상태를 파악할 수 있다. 이후, 제2 로봇의 제2 사용자는 접촉정보, 영상정보 등과 같은 추가적인 정보를 입력하여 위로, 공감, 응원 등을 제1 로봇의 제1 사용자에게 전달할 수 있다. 일 예로, 공유카드를 통해 제1 사용자의 우울한 감정상태를 판단한 제2 사용자는 제2 로봇을 손으로 쓰다듬 을 수 있고, 이때 제2 로봇은 제2 사용자의 쓰다듬는 접촉에 대응하는 동작을 출력하는 동시에 제1 로봇 으로 제2 사용자의 접촉을 전달할 수 있다. 이를 통해, 제2 사용자의 접촉 정보가 전달되어 제1 사용자에게 위로의 감정이 공유될 수 있다. 이하, 커플 로봇을 이용한 감정 공유 방법에 대하여 상술하며, 전술한 커플 로봇과 중복된 내용은 생략하도 록 한다. 도 10은 본 발명의 다른 실시 예에 따른 커플 로봇을 이용한 감정 공유 방법의 순서도이다. 도 10을 참조하면, 감정 공유 방법은 데이터 변환 단계(S1), 감정상태 판단 단계(S3), 감정상태 송신 단계(S5) 및 대응동작 출력 단계(S7)를 포함할 수 있다. 데이터 변환 단계(S1)에서는 제1 로봇의 인터페이스부가 감지된 정보를 데이터로 변환시킬 수 있다. 데이터 변환 단계(S1)에서 변환된 데이터는 제1 로봇의 판단부로 전달되거나, 공유카드에 기록될 수 있다. 감정상태 판단 단계(S3)에서는 제1 로봇의 판단부가 데이터 변환 단계(S1)에서 전달된 데이터를 기초 로 제1 사용자의 감정상태를 판단할 수 있다. 또한, 감정상태 판단 단계(S3)에서 판단부는 누적된 데이터 와 감정상태를 학습하여 신뢰도 높은 감정상태를 산출해낼 수 있다. 산출된 감정상태는 제1 로봇의 통신부 와 출력부로 전달될 수 있다. 제1 로봇의 출력부는 전달된 감정상태에 대응하는 동작을 출 력하여 제1 사용자와 교감할 수 있다. 감정상태 송신 단계(S5)에서는 제1 로봇의 판단부에서 판단한 제1 사용자의 감정상태를 통신부가 제2 로봇의 통신부로 송신할 수 있다. 감정상태 송신 단계(S5)를 통해, 제2 사용자는 제1 사용자의 감정상 태를 공유할 수 있으며, 이때 감정상태의 기초가 되는 데이터를 함께 공유할 수 있다. 대응동작 출력 단계(S7)에서는 제2 로봇의 출력부가 제1 로봇의 제1 사용자의 감정상태에 대응하 는 동작을 출력할 수 있다. 제2 로봇의 제2 사용자는 해당 단계에서 제1 로봇의 판단부가 판단한 제1 사용자의 감정상태를 직관적으로 전달받을 수 있다. 상세하게, 제2 로봇의 제2 사용자는 이모티콘과 제 2 로봇의 표정을 통해 출력되는 이미지로 감정상태를 전달받을 수 있다. 또한, 제1 사용자의 접촉에 대응하 는 동작을 통해 감정상태를 전달받을 수 있다. 한편, 감정상태 송신 단계(S5)는 제1 로봇과 제1 사용자의 대화 정보를 기록한 공유카드를 더 송신할 수 있 다. 이를 통해, 대응동작 출력 단계(S7)에서 제2 사용자가 제1 사용자의 감정상태를 정확히 파악할 수 있다. 상 세하게, 제2 로봇의 제2 사용자는 출력부를 통한 동작뿐 아니라 공유카드에 기록되어 공유된 데이터를 확인할 수 있다. 이를 통해, 제1 로봇의 판단부에 의한 감정상태에 대한 판단이 정확하지 않은 경우에 도, 제2 사용자가 공유카드를 확인하여 정확한 감정상태를 정확하게 파악함으로써 제1 로봇의 제1 사용자와공감할 수 있다. 이처럼, 본 발명의 실시 예에 따른 커플 로봇 및 커플 로봇을 이용한 감정 공유 방법은 제1 사용자의 건강상 태, 감정상태, 접촉 등을 제2 사용자에게 전달하여 신뢰도 높은 커뮤니케이션 환경을 제공하는 이점이 있다. 이 러한 이점에 기초하여, 커플 로봇을 노인 복지 분야 또는 원거리 상담 분야 등에 적용할 수 있다. 도 11은 본 발명에 따른 커플 로봇을 이용한 감정 공유 방법 중 개인정보설정 시 수행되는 순서도를 나타낸다. 도 12 내지 14는 도 11이 수행되는 예들을 나타낸다. 도 11을 참조하면, 데이터 변환 단계(S1)는 연인간 애칭 설정(S111 내지 S113), 기념일 설정(S121 내지 S123), 커플 화면 설정(S131 내지 S133)를 포함할 수 있으며, 이는 예시들에 불과하며 이에 한정되지 않는다. 제1 로봇 의 제1 사용자는 각 정보를 제1 로봇으로 입력하여 제2 로봇으로 전달할 수 있다. 제2 로봇의 제2 사용자는 전달된 정보를 확인하여 출력여부를 결정할 수 있다. 각 예시들은 이하 도 12 내지 도 14를 참조 하여 자세히 설명한다. <실시 예1> 도 12를 참조하면, 도 11의 순서도 중 연인간 애칭 설정(S111 내지 S113)시 출력되는 화면을 확인할 수 있다. 애칭을 설정하는 방법은 도 12(a)에서 도 12(f)로 순서대로 진행될 수 있다. 도 12(a)는 사용자가 애칭 설정을 위해 스크린에 출력된 메뉴를 선택하는 것을 나타낸다. 도 12(b)는 제1 사용자가 제2 사용자의 애칭을 설정하여 저장하는 것을 나타낸다. 이후 도 12(c)와 같이 제2 로봇으로 공유 메시지가 발송되며, 도 12(d)와 같이 제2 로 봇의 제2 사용자는 공유 메시지를 확인하고 상대방의 애칭을 설정할 수 있다. 상호간 애칭에 대한 동의가 완료 되면 도 12(e)와 같이 설정된 애칭이 스크린을 통해 공개되며, 추후 감정상태, 메시지, 공유카드 등을 송수신하 는 경우 도 12(f)와 같이 설정된 애칭이 사용되어 스크린에 출력될 수 있다. <실시 예2> 도 13을 참조하면, 도 11의 순서도 중 연인간 기념일 설정(S121 내지 S123)시 출력되는 화면을 확인할 수 있다. 기념일을 설정하는 방법은 도 13(a)에서 도 13(h)의 순서대로 진행될 수 있다. 도 13(a)는 사용자가 애칭 설정 을 위해 스크린에 출력된 메뉴를 선택하는 것을 나타낸다. 도 13(b)와 같이 제1 로봇의 제1 사용자가 지정될 기 준날짜를 지정하면, 이후 도 13(c)와 같이 기념일 유형을 선택하는 화면이 출력되며, 지정된 기준날짜로부터 기 념일을 자동적으로 계산하여 출력된 화면이 도 13(d)와 같이 출력될 수 있다. 이후 제1 사용자는 기념일의 명칭, 기념일의 알람 설정 여부를 도 13(e) 및 13(f)와 같이 설정하여 기념일 설정을 마무리할 수 있다. 제1 사 용자는 도 13(g)의 화면이 출력되면 기념일 설정이 마무리된 것을 알 수 있으며, 커플 로봇은 기념일이 가까워 지면 기설정된 시기에 도 13(h)와 같은 화면을 포함하는 알람 동작을 출력하여, 사전에 각 사용자에게 기념일을 알릴 수 있다. <실시 예3> 도 14를 참조하면, 도 11의 순서도 중 커플화면 설정(S131 내지 S133) 시 출력되는 화면을 확인할 수 있다. 커 플화면을 설정하는 방법은 도 14(a)에서 도 14(f)로 순서대로 진행될 수 있다. 도 14(a)는 제1 사용자가 커플화 면 설정을 위해 스크린에 출력된 메뉴를 선택하는 것을 나타낸다. 도 14(b)는 제1 사용자가 사용할 사진을 선택 하는 것을 나타내며, 선택된 사진은 도 14(c)와 같이 편집화면에서 출력된다. 제1 사용자는 도 14(d) 및 도 14(e)와 같이 다양한 효과를 통해 사진을 꾸밀 수 있으며, 경우 도 14(f)와 같이 설정된 커플화면이 사용되어 스크린에 출력될 수 있다. 도 15는 본 발명에 따른 커플 로봇을 이용한 감정 공유 방법 중 일기를 통한 감정 공유 방법을 설명하기 위한 순서도이다. 도 16은 도 15를 설명하기 위한 예를 나타낸다. 도 15를 참조하면, 데이터 변환 단계(S1) 중 음성 인식 단계(S141 내지 S144)를 통해 제1 로봇은 제1 사용 자의 음성을 인식할 수 있다. 이후, 제1 로봇은 상황별 위로, 공감 등을 수행할 수 있다. 또한, 제1 사용자 의 음성, 텍스트를 통해 일기가 작성되면 감정상태 송신 단계(S5)를 통해 해당 정보를 공유카드에 기록하여 공 유카드를 제2 로봇과 공유할 수 있다. 제1 로봇의 판단부는 감정상태 판단 단계(S311 내지 312)를 수행함으로써 대화 내용을 분석하여 감정상태를 판단하고, 출력부에 감정상태에 대응하는 동작을 출력하도 록 전달할 수 있다. 또한, 감정상태를 통신부로 전달하여 제2 로봇과 공유할 수 있다. 본 예시는 이하 도 16을 참조하여 자세히 설명한다.<실시 예4> 도 16을 참조하여 도 15의 순서도를 상세히 설명한다. 도 16(a)는 제1 사용자의 음성을 인식하여 감정상태를 체 크하는 화면을 나타내며 이는 도 15의 음성 인식 단계(S141 내지 S144)에 해당될 수 있다. 이때, 제1 로봇의 판 단부는 제1 사용자 음성의 높낮이, 음색 등을 기초로 감정상태를 체크할 수 있다. 이후, 제1 사용자는 음성 또 는 텍스트를 통해 작성된 일기를 제1 로봇에 입력할 수 있다. 인터페이스부는 입력된 일기를 공유카드에 저장하 고 판단부로 전달할 수 있다. 판단부는 공유카드를 전달받아 제1 사용자의 감정상태를 상세히 판단하는 단계 (S311 및 S312)를 수행할 수 있다. 이때 제1 로봇은 도 16(b) 내지 도 16(e)와 같이 제1 사용자가 입력하는 정 보에 대응하는 일기 작성 시작 알림, 일기 작성 완료 알림, 대화 내용 분석 알림 및 공유카드로 일기 전송 알림 화면을 스크린을 통해 출력하여 현재 진행상태를 나타낼 수 있다. 이후, 통신부는 감정상태 송신 단계(S511 내 지 S513)를 수행함으로써 제2 로봇으로 공유카드 및 감정상태를 전달하고, 제2 로봇 출력부에 도 16(f)와 같이 새로운 일기가 업데이트된 알림 동작이 출력될 수 있다. 도 17은 본 발명에 따른 커플 로봇을 이용한 감정 공유 방법 중 스크린(1193, 1393)의 디스플레이를 통한 감정 공유 방법을 설명하기 위한 순서도이다. 도 18 내지 도 20은 도 17의 감정 공유 방법을 설명하기 위한 예들을 나타낸다. 도 17을 참조하면, 감정상태 송신 단계(S521 내지 S524)를 통해 상대방의 감정상태 및 공유카드를 전달받은 제2 로봇의 제2 사용자는 이에 대응하는 공감, 위로의 표현을 데이터 변환 단계(S8) 및 대응동작 출력 단계(S 9)를 통해 상대방에게 전달 할 수 있다. 데이터 변환 단계(S8)는 제스처 표현(S151 및 S152), 접촉 및 그림 등 의 표현을 포함할 수 있다. 이후 커플 로봇 각각은 대응동작 출력 단계(S9)를 수행하여 각각의 출력부(119, 139)에 대응동작을 출력(S721 및 S722)할 수 있다. 각 예시들은 이하 도 18 내지 도 20을 참조하여 자세히 설명 한다. <실시 예5> 도 18은 감정상태 송신 단계(S521 내지 S524)를 통해 우울한 마음을 전달하는 실시 예를 나타낸다. 도 18(a) 내 지 도 18(d)와 같이 제1 로봇의 출력부에 우울함이 출력되고, 입력된 정보가 공유카드에 저장되어 업데이트 된 것을 알리며, 공유카드의 확인을 요청하는 화면이 출력되는 과정을 통해 제1 로봇의 제1 사용자의 감정상태가 제2 로봇의 제2 사용자로 전달되며, 제2 사용자는 대응동작 출력 단계(S711 내지 S713)을 수행하는 제2 로봇을 통해 도 18(e)와 같이 공유카드의 내용을 확인하여 감정상태를 상세히 파악할 수 있다. 이후, 제2 사용자는 제2 로봇을 쓰다듬거나 토닥이는 접촉, 또는 제2 로봇을 안아주거나 제2 로봇에 키스하는 접촉 등을 입력할 수 있으 며, 제2 로봇은 데이터 변환 단계(S151 및 S152)를 통해 데이터를 변환할 수 있다. 이후, 도시되지 않았으나 감 정상태 판단 단계(S3) 및 감정상태 송신 단계(S5)를 수행함으로써 제1 사용자에게 공감, 위로, 응원 등을 전달 할 수 있다. 이때, 도 18(f)와 같이 제1 로봇의 스크린에는 공감, 위로, 응원 등에 대응하는 기설정된 동작이 출력될 수 있다. 이를 통해, 제1 사용자는 본인의 감정상태에 따른 상대방의 공감, 위로, 응원 등을 다양한 표 현방법으로 전달받을 수 있다. <실시 예6> 도 19 및 도 20은 그림을 통해 감정을 전달하는 예시를 나타낸다. 이는 도 17의 데이터 변환 단계(S151 및 S152) 이후 수행되는 대응동작 출력 단계(S721 및 S722)의 예시일 수 있다. 도 19(a) 내지 도 19(c)의 순서와 같이 제1 로봇의 제1 사용자는 그림메뉴를 선택하여, 원하는 그림을 그릴 수 있다. 완성된 그림은 메시지 형태 로 저장될 수 있으며, 각 로봇의 통신부를 통해 공유될 수 있으며, 도 19(d)와 같은 화면이 출력되어 메시지의 전달상태를 알릴 수 있다. 이후, 도 20(a) 및 도 20(b)와 같이 제2 로봇은 메시지를 수신하면 이를 알리는 동작 을 출력하여 제2 사용자에게 알릴 수 있으며, 제2 사용자는 수신된 메시지를 확인하여 상대방의 감정상태를 확 인할 수 있다. 도 21은 본 발명에 따른 커플 로봇을 이용한 감정 공유 방법 중 영상을 통한 감정 공유 방법을 설명하기 위한 순서도이다. 도 22 및 도 23은 도 21의 감정 공유 방법을 설명하기 위한 예를 나타낸다. 상세하게, 도 21은 제1 사용자가 설정한 기념일에 맞추어 영상을 통해 감정을 공유 하는 방법의 순서도이다. 기 입력된 기념일을 알리는 출력이 확인되면(S7) 제1 사용자는 제1 로봇에 녹화 명령을 입력하여, 제1 로봇이 데이터 변환 단계(S2)를 수행할 수 있다. 상세하게, 영상을 녹화하고 녹화된 영상을 확인 및 재촬영(S161 내지 S165)하고 선택된 영상의 제목을 설정하고 발송날짜를 지정하여 예약발송(S166 내지 S168) 할 수 있다. 이 후, 발송된 영상을 사용자에게 출력하기 위해 제2 로봇은 대응동작 출력 단계(S6)단계를 수행할 수 있으며, 해당 단계는 영상 메시지 수신 알림 단계(S731 및 S732)를 포함할 수 있다. <실시 예7> 도 22 및 도 23을 통해 도 21의 순서도를 상세히 설명한다. 도 22(a) 내지 도 22(d)는 도 21의 데이터 변환 단 계(S161 내지 S165)에서 제1 사용자가 영상의 촬영명령을 입력하고, 이후 촬영된 영상의 정보를 기입 및 확인함 에 따라 순차적인 진행상황을 출력하는 로봇의 스크린을 나타낸다. 도 22(e) 내지 도 22(h)는 도 21의 데이터 변환 단계(S166 내지 S168)에서 영상을 예약발송하기 위해 제1 사용자가 다양한 영상 목록의 상세정보를 확인하 고, 날짜를 지정하며, 지정된 날짜에 포함될 영상을 선택하여 예약발송을 하는 과정에 대응하여 스크린에서 출 력하는 화면을 순서대로 나열한 것이다. 이처럼, 커플 로봇은 감정상태 및 공유카드를 실시간으로 송수신할 뿐 아니라, 사용자의 설정에 따라 입력한 정보의 전달시기를 예약할 수 있다. 한편, 제2 로봇의 제2 사용자는 도 23(a) 및 도 23(b)의 화면을 출력하며 도 21의 대응동작 출력 단계(S731 및 S732)를 수행하는 제2 로봇을 통해 메시지가 수신된 것을 확인하고, 전달된 메시지를 확인할 수 있다. 이상의 설명 및 실시 예를 기초로 본 발명의 커플 로봇의 수행기능 및 기능별 출력형태를 정리한 [표 1]을 하기에 첨부한다. 다만, 본 발명의 커플 로봇의 수행가능한 기능 및 출력형태는 이에 제한되지 않는다. 표 1 기능 출력음 색변화 스크린 로봇이 음성으로 대화설정된 남성 또는 여성 목소리얼굴 표정 출력 사용자의 음성 입력 얼굴 표정 출력을 통한 사용 자 음성인식 확인 음성 인식 후 사용자의 감정상태 판단이모티콘, 표정 등의 동작 출 력 제2 로봇에게 감정전달전달완료 효과음 출력 판단된 감정상태에 대응된 동 작 출력 제1 로봇으로부터 감정 상태 수신수신완료 효과음 출력 수신된 감정상태에 대응된 동 작 출력 뽀뽀 전달 키스마크 출력 및 핑크색 그 라데이션 색변화 출력이모티콘, 표정 등의 동작 출 력 쓰다듬기 전달 그라데이션 색변화 출력 이모티콘, 부끄러운 표정 등 의 동작 출력 밀침, 충돌 전달 그라데이션 색변화 출력 이모티콘, 찡그린 표정 등의 동작 출력 그림 그리기 그림배경 출력 후 터치에 대 응되는 그림 출력 메시지 전달 문자, 그림 및 영상을 포함한 메시지 전달 및 수신완료 효과음 출력1) 수신시 메시지 형상 이모 티콘 출력 2) 확인시 메시지에 포함된 내용출력 기념일 알림 알림안내 음성 출력 기념일 이름, 일자 등의 정보 출력 영상녹화 촬영 시작 및 종료시 효 과음 출력녹화되는 영상, 저장된 영상 정보 등 출력 예약전송 예약완료 효과음 출력 예약일시 설정화면 출력 [표 1]에 나타난 바와 같이, 본 발명에 따른 커플 로봇은 사용자로부터 감지된 정보에 대응하도록 소리, 색 변화, 표정, 이모티콘 등을 포함하는 다양한 동작을 출력하여 사용자간 감정상태를 공유할 수 있다. 또한, 각 로봇(11, 13)이 판단한 감정상태와 함께 공유카드를 전송하여 각 사용자가 상대방의 정확한 감정을 판단할 수 있는 환경을 제공할 수 있다. 이처럼, 다양한 출력과 공유카드를 통해 판단하는 감정상태의 신뢰도가 향상됨에 따라 커플 로봇은 노인 복지분야, 의료 분야 등에 확대 적용될 수 있다.이상에서 대표적인 실시 예를 통하여 본 발명을 상세하게 설명하였으나, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자는 상술한 실시 예에 대 하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형이 가능함을 이해할 것이다. 그러므로 본 발명 의 권리 범위는 설명한 실시 예에 국한되어 정해져서는 안 되며, 후술하는 특허청구범위뿐만 아니라 특허청구범위와 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태에 의하여 정해져야 한다."}
{"patent_id": "10-2018-0028194", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 커플 로봇 중 제1 로봇의 측면사시도 및 정면도를 나타낸다. 도 2는 본 발명의 일 실시 예에 따른 커플 로봇이 분리된 형태를 나타낸다. 도 3은 도 2의 커플 로봇이 결합된 형태를 나타낸다. 도 4는 본 발명에 따른 커플 로봇의 스크린에서 출력가능한 화면을 나타낸다. 도 5 및 6은 본 발명에 따른 커플 로봇이 사용자의 접촉에 대응하는 동작을 수행하는 예시를 나타낸다. 도 7은 본 발명에 따른 커플 로봇이 카메라를 통해 영상을 촬영하는 예시를 나타낸다. 도 8은 본 발명에 따른 커플 로봇 한 쌍이 각 스크린을 통해 동일한 동작을 수행하는 것을 나타낸다. 도 9는 본 발명에 따른 커플 로봇 한 쌍의 공유카드를 통한 감정 공유 과정을 나타낸다. 도 10은 본 발명의 일 실시 예에 따른 커플 로봇을 이용한 감정 공유 방법의 순서도이다. 도 11은 본 발명에 따른 커플 로봇을 이용한 감정 공유 방법 중 개인정보 설정방법의 순서도를 나타낸다. 도 12 내지 14는 도 11이 수행되는 예들을 나타낸다. 도 15는 본 발명에 따른 커플 로봇을 이용한 감정 공유 방법 중 일기를 통한 감정 공유 방법을 설명하기 위한 순서도이다. 도 16은 도 15를 설명하기 위한 예를 나타낸다. 도 17은 본 발명에 따른 커플 로봇을 이용한 감정 공유 방법 중 스크린의 디스플레이를 통한 감정 공유 방법을 설명하기 위한 순서도이다. 도 18 내지 20은 도 17의 감정 공유 방법을 설명하기 위한 예들을 나타낸다. 도 21은 본 발명에 따른 커플 로봇을 이용한 감정 공유 방법 중 영상을 통한 감정 공유 방법을 설명하기 위한 순서도이다. 도 22 및 23은 도 21의 감정 공유 방법을 설명하기 위한 예를 나타낸다."}
