{"patent_id": "10-2022-0184420", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0102417", "출원번호": "10-2022-0184420", "발명의 명칭": "인공지능 모델의 학습을 위한 학습데이터의 불균형을 개선하는 방법 및 장치", "출원인": "재단법인대구경북과학기술원", "발명자": "이충희"}}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 모델의 학습을 위한 학습데이터의 불균형을 개선하는 방법으로서,제1 학습영상을 언더 샘플링하는 단계; 및상기 언더 샘플링의 결과를 반영하여 제2 학습영상을 오버 샘플링하는 단계;를 포함하고,상기 언더 샘플링하는 단계는,상기 제1 학습영상을 그룹으로 묶어 제1 학습그룹을 생성하는 단계;상기 제1 학습그룹을 하나씩 입력하여 제1 인공지능 모델을 학습시키고 제1 점수를 산출하는 단계;상기 제1 점수가 가장 높은 제1 학습그룹에 상기 제1 점수가 다음으로 높은 제1 학습그룹을 순서대로 하나씩 추가하여 상기 제1 인공지능 모델을 학습시키고 제2 점수를 산출하는 단계; 및상기 제2 점수가 미리 설정된 값에 해당하는 상기 제1 학습그룹을 언더 샘플링 학습그룹으로 선택하는 단계;를 포함하고,상기 오버 샘플링하는 단계는,상기 제2 학습영상에 데이터 증강 기법을 적용하여 제2 학습그룹을 생성하는 단계;상기 언더 샘플링 학습그룹, 상기 제2 학습영상 및 상기 제2 학습그룹을 입력하여 제2 인공지능 모델을 학습시키고 제3 점수를 산출하는 단계; 및상기 산출된 제3 점수가 가장 높은 제2 학습그룹을 오버 샘플링 학습그룹으로 선택하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 학습그룹을 생성하는 단계는,상기 제1 학습영상을 무작위로 섞고, 상기 제2 학습영상의 개수만큼 그룹으로 묶어 상기 제1 학습그룹을 생성하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 인공지능 모델을 학습시키고 제2 점수를 산출하는 단계는,모든 제1 학습그룹에 대하여 상기 제1 인공지능 모델을 학습시키는 과정을 반복하는, 방법."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,제1 인공지능 모델을 학습시키고 제2 점수를 산출하는 단계는,상기 제2 학습영상을 입력하여 상기 제1 인공지능 모델을 학습시키는 단계; 및공개특허 10-2024-0102417-3-상기 제1 인공지능 모델의 제2 점수를 그래프화하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제2 학습그룹을 생성하는 단계는,복수의 데이터 증강 기법들 중 하나를 선택하는 단계;상기 선택된 데이터 증강 기법의 파라메터 값을 조정하는 단계; 및상기 제2 학습영상에서 상기 복수의 데이터 증강 기법들의 개수로 나눈 만큼 무작위로 선택하고, 상기 파라메터값이 조정된 데이터 증강 기법을 적용하여 상기 제2 학습그룹을 생성하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제2 학습그룹을 생성하는 단계는,상기 복수의 데이터 증강 기법들 각각에 대하여 상기 파라메터 값을 조정하여 데이터 증강 기법을 적용하는 과정을 반복하는, 방법."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제2 인공지능 모델을 학습시키고 점수를 산출하는 단계는,상기 언더 샘플링 학습그룹을 입력하여 상기 제2 인공지능 모델을 학습시키는 단계;를 포함하는, 방법."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 오버 샘플링하는 단계는,상기 제2 인공지능 모델의 점수를 그래프화하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 메모리; 및적어도 하나의 프로세서;를 포함하고,상기 적어도 하나의 프로세서는,제1 학습영상을 언더 샘플링하고,상기 언더 샘플링의 결과를 반영하여 제2 학습영상을 오버 샘플링하고,상기 적어도 하나의 프로세서는,상기 제1 학습영상을 그룹으로 묶어 제1 학습그룹을 생성하고,상기 제1 학습그룹을 하나씩 입력하여 제1 인공지능 모델을 학습시키고 제1 점수를 산출하고,상기 제1 점수가 가장 높은 제1 학습그룹에 상기 제1 점수가 다음으로 높은 제1 학습그룹을 순서대로 하나씩 추공개특허 10-2024-0102417-4-가하여 상기 제1 인공지능 모델을 학습시키고 제2 점수를 산출하고,상기 제2 점수가 미리 설정된 값에 해당하는 상기 제1 학습그룹을 언더 샘플링 학습그룹으로 선택하고,상기 제2 학습영상에 데이터 증강 기법을 적용하여 제2 학습그룹을 생성하고,상기 언더 샘플링 학습그룹, 상기 제2 학습영상 및 상기 제2 학습그룹을 입력하여 제2 인공지능 모델을 학습시키고 제3 점수를 산출하고,상기 산출된 제3 점수가 가장 높은 제2 학습그룹을 오버 샘플링 학습그룹으로 선택하는, 장치."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 학습영상을 무작위로 섞고, 상기 제2 학습영상의 개수만큼 그룹으로 묶어 상기 제1 학습그룹을 생성하는, 장치."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 적어도 하나의 프로세서는,모든 제1 학습그룹에 대하여 상기 제1 인공지능 모델을 학습시키는 과정을 반복하는, 장치."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 적어도 하나의 프로세서는,상기 제2 학습영상을 입력하여 상기 제1 인공지능 모델을 학습시키고,상기 제1 인공지능 모델의 제2 점수를 그래프화하는, 장치."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 적어도 하나의 프로세서는,복수의 데이터 증강 기법들 중 하나를 선택하고,상기 선택된 데이터 증강 기법의 파라메터 값을 조정하고,상기 제2 학습영상에서 상기 복수의 데이터 증강 기법들의 개수로 나눈 만큼 무작위로 선택하고, 상기 파라메터값이 조정된 데이터 증강 기법을 적용하여 상기 제2 학습그룹을 생성하는, 장치."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 적어도 하나의 프로세서는,상기 복수의 데이터 증강 기법들 각각에 대하여 상기 파라메터 값을 조정하여 데이터 증강 기법을 적용하는 과정을 반복하는, 장치."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서,상기 적어도 하나의 프로세서는,상기 언더 샘플링 학습그룹을 입력하여 상기 제2 인공지능 모델을 학습시키는, 장치.공개특허 10-2024-0102417-5-청구항 16 제9항에 있어서,상기 적어도 하나의 프로세서는,상기 제2 인공지능 모델의 점수를 그래프화하는, 장치."}
{"patent_id": "10-2022-0184420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 측면에 따른 인공지능 모델의 학습을 위한 학습데이터의 불균형을 개선하는 방법은, 제1 학습영상을 언더 샘 플링하는 단계; 및 상기 언더 샘플링의 결과를 반영하여 제2 학습영상을 오버 샘플링하는 단계;를 포함하고, 상 기 언더 샘플링하는 단계는, 상기 제1 학습영상을 그룹으로 묶어 제1 학습그룹을 생성하는 단계; 상기 제1 학습 (뒷면에 계속)"}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델의 학습을 위한 학습데이터의 불균형을 개선하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인식기를 구성할 때, 멀티 인식기를 구성하는 것은 일반적이다. 그러나 응용분야에 따라서 클래스 간 학습데이 터 개수의 차이가 매우 많은 경우를 자주 접할 수 있다. 클래스 간 학습데이터 개수의 차이는 멀티 인식기의 성 능을 저하시키는 대표적인 원인중에 하나이다. 학습데이터가 적은 클래스는 학습 시 소외되어, 학습데이터가 많은 클래스 쪽으로 편향되어 학습되는 경우가 많 이 발생하기 때문에, 학습 시 클래스 간의 학습데이터의 개수를 적절히 맞추어 주는 것이 매우 중요하다. 학습데이터가 많은 클래스에서는 학습데이터의 개수를 감소시키고, 학습데이터가 적은 클래스에서는 데이터 증 강기법을 통하여 학습데이터의 개수를 증가시켜야 한다. 데이터 증강은 부족한 학습 데이터의 개수를 늘려 인공지능 학습의 안정성과 신뢰성을 높인다. 또한 다양한 특 성을 갖는 학습 데이터를 생성함으로써, 실제 필드에서의 일반화 성능을 개선하는 데 크게 기여한다. 하나의 원본 영상을 기반으로, 데이터 증강 기법을 이용하여 다양한 특성을 갖는 학습영상을 만들고, 이를 인공 지능 학습에 적용하는 종래의 기술에서 데이터 증강에 사용될 수 있는 기법은 노이즈 첨가, 콘트라스트 변화, 크롭핑, 회전, 생성 변화 등이 있다. 그러나 종래에는 학습데이터의 개수를 얼마나 감소시켜야 하는지, 또는 데이터 증강 기법을 사용하여 얼마나 효 율적으로 개수를 증가시켜야 하는지에 대한 명확한 기준이 없었다. 그러므로 주어진 학습데이터를 이용하여 다양하게 학습하고, 이를 통해서 출력되는 값을 기준으로 학습영상의 개수를 적절히 줄이는 과정이 필요하다. 또한, 데이터 증강기법을 통하여 적절히 증강시키는 과정이 요구된다."}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "종래에는 학습데이터 불균형시, 학습데이터의 개수를 얼마나 줄여야 하는지, 또는 데이터 증강기법을 사용하여 얼마나 효율적으로 개수를 증가시켜야 하는지에 대한 명확한 기준이 없었다. 이에 본 발명은 학습데이터 불균형시, 학습데이터를 효율적으로 증가시키거나 감소시키는 방법의 제안을 통해 인식 성능을 개선시키고자 한다. 이를 위해, 본 발명에서는 학습 데이터가 많은 클래스는 그룹핑을 통해, 학습 데이터가 적은 클래스는 데이터 증강기법을 이용하여 클래스 간 학습데이터 개수의 차이를 줄이는 방법을 제공 하고자 한다."}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 본 발명의 과제를 해결하기 위해, 본 발명의 일 실시예에 따른 인공지능 모델의 학습을 위한 학습데이터 의 불균형을 개선하는 방법은, 제1 학습영상을 언더 샘플링하는 단계; 및 상기 언더 샘플링의 결과를 반영하여제2 학습영상을 오버 샘플링하는 단계;를 포함하고, 상기 언더 샘플링하는 단계는, 상기 제1 학습영상을 그룹으 로 묶어 제1 학습그룹을 생성하는 단계; 상기 제1 학습그룹을 하나씩 입력하여 제1 인공지능 모델을 학습시키고 제1 점수를 산출하는 단계; 상기 제1 점수가 가장 높은 제1 학습그룹에 상기 제1 점수가 다음으로 높은 제1 학 습그룹을 순서대로 하나씩 추가하여 상기 제1 인공지능 모델을 학습시키고 제2 점수를 산출하는 단계; 및 상기 제2 점수가 미리 설정된 값에 해당하는 상기 제1 학습그룹을 언더 샘플링 학습그룹으로 선택하는 단계;를 포함 하고, 상기 오버 샘플링하는 단계는, 상기 제2 학습영상에 데이터 증강 기법을 적용하여 제2 학습그룹을 생성하 는 단계; 상기 언더 샘플링 학습그룹, 상기 제2 학습영상 및 상기 제2 학습그룹을 입력하여 제2 인공지능 모델 을 학습시키고 제3 점수를 산출하는 단계; 및 상기 산출된 제3 점수가 가장 높은 제2 학습그룹을 오버 샘플링 학습그룹으로 선택하는 단계;를 포함한다. 다른 측면에 따른 인공지능 모델의 학습을 위한 학습데이터의 불균형을 개선을 장치는, 적어도 하나의 메모리; 및 적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로세서는, 제1 학습영상을 언더 샘플링하고, 상 기 언더 샘플링의 결과를 반영하여 제2 학습영상을 오버 샘플링하고, 상기 적어도 하나의 프로세서는, 상기 제1 학습영상을 그룹으로 묶어 제1 학습그룹을 생성하고, 상기 제1 학습그룹을 하나씩 입력하여 제1 인공지능 모델 을 학습시키고 제1 점수를 산출하고, 상기 제1 점수가 가장 높은 제1 학습그룹에 상기 제1 점수가 다음으로 높 은 제1 학습그룹을 순서대로 하나씩 추가하여 상기 제1 인공지능 모델을 학습시키고 제2 점수를 산출하고, 상기 제2 점수가 미리 설정된 값에 해당하는 상기 제1 학습그룹을 언더 샘플링 학습그룹으로 선택하고, 상기 제2 학 습영상에 데이터 증강 기법을 적용하여 제2 학습그룹을 생성하고, 상기 언더 샘플링 학습그룹, 상기 제2 학습영 상 및 상기 제2 학습그룹을 입력하여 제2 인공지능 모델을 학습시키고 제3 점수를 산출하고, 상기 산출된 제3 점수가 가장 높은 제2 학습그룹을 오버 샘플링 학습그룹으로 선택하도록 인공지능 모델의 학습을 위한 학습데이 터의 불균형을 개선을 장치를 제어한다. 또 다른 측면에 따른 컴퓨터로 읽을 수 있는 기록매체는 상술한 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 기록매체를 포함한다."}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 학습데이터의 개수가 불균형하여 인식 성능이 저하될 때, 효율적이고 효과적인 학습데이터의 증감을 결정을 가능하게 한다. 또한, 학습데이터 개수의 불균형으로 인해 발생하는 편향적으로 학습되는 경우를 방지하여 멀티 인식기의 성능 개선을 가능하게 한다. 또한, 본 발명은 영상 인식에만 사용될 수 있는 것이 아니라, 음성데이터, 센서데이터 등 다양한 학습 데이터에 도 모두 적용이 가능해, 그 적용 범위가 매우 넓게 활용될 수 있다."}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시 예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시 예들로 한정되는 것이 아니라, 서로 다른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발"}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시예에서\" 또는 \"일 실시예에서\" 등의 어구는 반드시 모 두 동일한 실시예를 가리키는 것은 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표 현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동 작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이 나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기 술을 채용할 수 있다.\"매커니즘\", \"요소\", \"수단\" 및 \"구성\"등과 같은 용어는 넓게 사용될 수 있으며, 기계적이 고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 본 실시예들에서 사용되는 용어는 본 실시예들에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 부분에서 상세히 그 의미를 기재할 것이다. 따라서, 본 실시예들에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가 지는 의미와 본 실시예들 전반에 걸친 내용을 토대로 정의되어야 한다. 본 실시예들은 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있는 바, 일부 실시예들을 도면에 예시하 고 상세하게 설명하고자 한다. 그러나, 이는 본 실시예들을 특정한 개시형태에 대해 한정하려는 것이 아니며, 본 실시예들의 사상 및 기술범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한 다. 본 명세서에서 사용한 용어들은 단지 실시예들의 설명을 위해 사용된 것으로, 본 실시예들을 한정하려는 의 도가 아니다."}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 실시예들에 사용되는 용어들은 다르게 정의되지 않는 한, 본 실시예들이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미가 있다. 일반적으로 사용되는 사전에 정의되어 있는 것 과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 실시 예들에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않아야 한다.후술하는 본 발명에 대한 상세한 설명은, 본 발명이 실시될 수 있는 특정 실시예를 예시로서 도시하는 첨부 도 면을 참조한다. 이러한 실시예는 당업자가 본 발명을 실시할 수 있기에 충분하도록 상세히 설명된다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 본 명세서에 기재되 어 있는 특정 형상, 구조 및 특성은 본 발명의 정신과 범위를 벗어나지 않으면서 일 실시예로부터 다른 실시예 로 변경되어 구현될 수 있다. 또한, 각각의 실시예 내의 개별 구성요소의 위치 또는 배치도 본 발명의 정신과 범위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미 로서 행하여지는 것이 아니며, 본 발명의 범위는 특허청구범위의 청구항들이 청구하는 범위 및 그와 균등한 모 든 범위를 포괄하는 것으로 받아들여져야 한다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하거나 유 사한 구성요소를 나타낸다."}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이하에서는, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실시할 수 있도록 하 기 위하여, 본 발명의 여러 실시예에 관하여 첨부된 도면을 참조하여 상세히 설명하기로 한다. 도 1은 일 실시예에 따른 인공지능 모델의 학습을 위한 학습데이터의 불균형을 개선하는 장치의 일 예를 설명하 기 위한 도면이다. 도 1을 참조하면, 학습데이터의 불균형을 개선하는 장치(이하, '데이터 불균형 개선 장치'라 함)는 메모리 와 프로세서를 포함할 수 있다. 도 1에 도시된 데이터 불균형 개선 장치는 본 실시예들과 관련된 구성요소들만이 도시되어 있어, 도 1에"}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음은 당해 기술분야의 기술자에게 자명하 다. 따라서, 데이터 불균형 개선 장치는 도 1에 개시되지 않은 디스플레이 장치 및 사용자 입력을 수신하는 장 치(예: 키보드, 마우스 등)를 포함할 수 있고, 통신부를 포함할 수 있다. 예를 들어 데이터 불균형 개선 장치 는 노트북(notebook) PC, 데스크탑(desktop) PC, 랩탑(laptop), 태블릿 컴퓨터(tablet computer), 스마트 폰(Smart Phone)을 포함한 모바일 디바이스(Mobile Device), 서버 디바이스(Server Device), 임베디드 디바이 스(Embedded Device) 등의 다양한 종류의 디바이스들로 구현될 수 있다. 구체적인 예로서 인공지능을 이용한 음 성 인식, 영상 인식, 영상 분류 등을 수행하는 스마트폰, 태블릿 디바이스, AR(Augmented Reality) 디바이스, IoT(Internet of Things) 디바이스, 자율주행 자동차, 로보틱스, 의료기기 등에 해당될 수 있으나, 이에 제한되 지 않는다. 나아가서, 데이터 불균형 개선 장치는 위와 같은 디바이스에 탑재되는 전용 하드웨어 가속기 (HW accelerator)에 해당될 수 있고, 데이터 불균형 개선 장치는 인공지능 구동을 위한 전용 모듈인 NPU(neural processing unit), TPU(Tensor Processing Unit), Neural Engine 등과 같은 하드웨어 가속기일 수 있으나, 이에 제한되지 않는다. 또한 데이터 불균형 개선 장치는 사용자 인터페이스를 더 포함할 수 있다. 사용자 인터페이스는, 데이터 불균형 개선 장치를 제어하기 위한 데이터를 입력하는 수단을 의미할 수 있다. 예를 들어, 사용자 인터페 이스에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위 치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 메모리는 데이터 불균형 개선 장치내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 컴퓨터 로 판독이 가능한 기록매체를 포함할 수 있다. 예를 들어, 메모리는 데이터 불균형 개선 장치에서 처 리된 데이터들 및 처리될 데이터들을 저장할 수 있다. 또한, 메모리는 데이터 불균형 개선 장치에 의 해 구동될 애플리케이션(application)들, 드라이버(driver)들 등을 저장할 수 있다. 메모리는 휘발성 메모 리(volatile memory) 또는 비휘발성 메모리(nonvolatile memory) 중 적어도 하나를 포함할 수 있다. 휘발성 메 모리는 DRAM(dynamic random access memory), SRAM(static random access memory), SDRAM(synchronous dynamic random access memory), PRAM(phase-change random access memory), MRAM(magnetic random access memory), RRAM(resistive random access memory), FeRAM(ferroelectric random access memory)등을 포함할 수 있다. 비휘발성 메모리는 ROM(read-only memory), PROM(programmable read-only memory), EPROM(electrically programmable read-only memory), EEPROM(electrically erasable programmable read-only memory)등을 포함할 수 있다. 실시예에 있어서, 메모리는 자기 메모리, CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), 또는 Memory Stick을 포함할 수 있으 나, 이에 제한되지 않는다. 또한, 메모리는 운영체제(Operating System)와 적어도 하나의 프로그램 코드(도 2 내지 도 9를 참조하여 동작하는 프로세서가 수행하기 위한 코드)가 저장될 수 있다. 프로세서는 도 2 내지 도 9을 참조하여, 인공지능 모델의 학습을 위한 학습데이터의 불균형을 개선하는 데 이터 불균형 개선 장치를 실행하기 위한 전반적인 기능을 제어하는 역할을 할 수 있다. 예를 들어 프로세 서는 데이터 불균형 개선 장치내의 메모리에 저장된 소프트웨어(예: 프로그램)를 실행함으로써, 프로세서에 연결된 전자 장치의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행하여 데이터 불균형 개선 장치를 전반적으로 제어할 수 있다. 예를 들어 프로세서는 제1 학습영상을 언더 샘플링하고, 언더 샘플링의 결과를 반영하여 제2 학습영상을 오버 샘플링 할 수 있다. 예를 들어 프로세서는 제1 학습영상을 그룹으로 묶어 제1 학습그룹을 생성하고, 제1 학습그룹을 하나씩 입 력하여 제1 인공지능 모델을 학습시키고 제1 점수를 산출하고, 제1 점수가 가장 높은 제1 학습그룹에 제1 점수 가 다음으로 높은 제1 학습그룹을 순서대로 하나씩 추가하여 제1 인공지능 모델을 학습시키고 제2 점수를 산출 하고, 제2 점수가 미리 설정된 값에 해당하는 제1 학습그룹을 언더 샘플링 학습그룹으로 선택할 수 있다. 예를 들어 프로세서는 제2 학습영상에 데이터 증강 기법을 적용하여 제2 학습그룹을 생성하고, 언더 샘플 링 학습그룹, 제2 학습영상 및 제2 학습그룹을 입력하여 제2 인공지능 모델을 학습시키고 제3 점수를 산출하고, 산출된 제3 점수가 가장 높은 제2 학습그룹을 오버 샘플링 학습그룹으로 선택할 수 있다. 일 실시예에 따르면, 프로세서는 데이터 불균형 개선 장치 내에 구비된 중앙 처리 장치 (central processing unit; CPU), 그래픽 처리 장치(graphics processing unit; GPU), 어플리케이션 프로세서 (application processor; AP), 신경망 처리 장치(neural processing unit; NPU), 이미지 시그널 프로세서 (image signal processor; ISP), 센서 허브 프로세서(sensor hub processor) 또는 커뮤니케이션 프로세서 (communication processor; CP) 등으로 구현될 수 있으나, 이에 제한되지 않는다. 도 2는 일 실시예에 따른 인공지능 모델의 학습을 위한 학습데이터의 불균형을 개선하는 방법을 도시하기 위한 예시적인 도면이다. 도 2를 참조하면, 단계 200에서, 데이터 불균형 개선 장치는 제1 학습영상을 그룹으로 묶어 제1 학습그룹을 생 성할 수 있다. 예를 들어, 데이터 불균형 개선 장치는 도 1의 메모리와 프로세서를 포함하는 학습데이터의 불균형을 개선하는 장치일 수 있다. 예를 들어, 제1 학습영상은 이미지, 음성 데이터, 센서 데이터, 동영상 등이 될 수 있으나, 이에 제한되지 않는 다. 단계 210에서, 데이터 불균형 개선 장치는 제1 학습그룹을 하나씩 입력하여 제1 인공지능 모델을 학습시키고 제 1 점수를 산출할 수 있다. 제1 인공지능 모델은 사람 또는 동물 두뇌의 구조에 착안하여 구현된 컴퓨팅 시스템으로서, 하드웨어로 구현될 수도 있고, 소프트웨어로 구현될 수도 있다. 예를 들어, 제1 인공지능 모델은 기계 학습(machine learning)모델 중 하나일 수 있다. 제1 인공지능 모델은 입력층(Input layer)이 하나 이상의 은닉층(Hidden layer)을 거쳐 출 력층(Output layer)에 연결된 다층 신경망 형태일 수 있다. 또한, 제1 인공지능 모델은 입력층(Input layer)이 은닉층(Hidden layer)을 거치지 않고 직접 출력층(Output layer)에 연결된 단층 신경망 형태일 수 있다. 제1 점수는 정밀도(precision)와 재현율(recall)의 조화평균인 F1 score를 사용하여 산출될 수 있다. 예를 들어, 제1 인공지능 모델의 정밀도(precision)는 아래의 수학식 1에 따라 산출될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 1은 정밀도(precision)로, 인공지능 모델이 참(True)으로 예측한 데이터 중 실제로 참(True)인 데이터의 비율을 나타낸다. 이 때, TruePositives는 인공지능 모델이 참(True)이라고 예측하였고 실제로 참(True)인 경우 이며, FalsePositives는 인공지능 모델이 참(True)이라고 예측하였지만 실제로는 거짓(False)인 경우를 나타낼 수 있다. 예를 들어, 제1 인공지능 모델의 재현율(recall)은 아래의 수학식 2에 따라 산출될 수 있다. 수학식 2"}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 2는 재현율(recall)로, 실제로 참(True)인 데이터 중 제1 인공지능 모델이 참(True)으로 예측한 데이터 의 비율을 나타낸다. 이 때, TruePositives는 제1 인공지능 모델이 참(true)이라고 예측하였고 실제로 참(Tru e)인 경우이며, FalseNegatives는 제1 인공지능 모델이 거짓(False)이라고 예측하였지만, 실제로는 참(True)인 경우를 나타낼 수 있다. 예를 들어, 제1 인공지능 모델의 정밀도와 재현율의 조화평균은 아래의 수학식 3에 따라 산출될 수 있다. 수학식 3"}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 3은 정밀도(precision)과 재현율(recall)의 조화평균인 F1 score로, 정밀도(precision)과 재현율 (recall)이 어느 한 쪽으로 편중되지 않을 때 상대적으로 높은 값을 가질 수 있다. 단계 220에서, 데이터 불균형 개선 장치는 제1 점수가 가장 높은 제1 학습그룹에 제1 점수가 다음으로 높은 제1 학습그룹을 순서대로 하나씩 추가하여 제1 인공지능 모델을 학습시키고 제2 점수를 산출할 수 있다. 제2 점수는 정밀도(precision)와 재현율(recall)의 조화평균인 F1 score를 사용하여 산출될 수 있다. 예를 들어, 제1 인공지능 모델의 정밀도(precision)는 수학식 1에 따라 산출될 수 있고, 제1 인공지능 모델의 재현율 (recall)은 수학식 2에 따라 산출될 수 있고, 제1 인공지능 모델의 정밀도와 재현율의 조화평균은 수학식 3에 따라 산출될 수 있다. F1 score는 정밀도(precision)과 재현율(recall)이 어느 한 쪽으로 편중되지 않을 때 상대적으로 높은 값을 가 질 수 있다. 단계 230에서, 데이터 불균형 개선 장치는 제2 점수가 미리 설정된 값에 해당하는 제1 학습그룹을 언더 샘플링 학습그룹으로 선택할 수 있다. 미리 설정된 값은 사용자가 미리 설정한 값일 수 있고, 이하에서는 설명의 편의를 위하여 산출된 제2 점수 중 최대값의 70%가 되는 값을 미리 설정한 값으로 하여 설명하기로 하지만, 이에 제한되는 것은 아니다. 단계 240에서, 데이터 불균형 개선 장치는 제2 학습영상에 데이터 증강 기법을 적용하여 제2 학습그룹을 생성할 수 있다. 예를 들어, 제2 학습영상은 이미지, 음성 데이터, 센서 데이터, 동영상 등이 될 수 있으나, 이에 제한되지 않는 다. 예를 들어, 데이터 증강 기법은 노이즈 첨가, 콘트라스트(contrast) 변화, 크롭핑(cropping), 회전, 색상 변화 등이 될 수 있으나, 이에 제한되지 않는다. 하나의 학습영상에 데이터 증강 기법 중 하나를 적용할 수 있고, 두 가지 이상의 데이터 증강 기법을 적용하는 것도 가능하다. 또한, 적용되는 데이터 증강 기법의 순서는 제한되지 않는다. 단계 250에서, 데이터 불균형 개선 장치는 언더 샘플링 학습그룹, 제2 학습영상 및 제2 학습그룹을 입력하여 제 2 인공지능 모델을 학습시키고 제3 점수를 산출할 수 있다. 제2 인공지능 모델은 사람 또는 동물 두뇌의 구조에 착안하여 구현된 컴퓨팅 시스템으로서, 하드웨어로 구현될 수도 있고, 소프트웨어로 구현될 수도 있다. 예를 들어, 제2 인공지능 모델은 기계 학습(machine learning)모델 중 하나일 수 있다. 제2 인공지능 모델은 입력층(Input layer)이 하나 이상의 은닉층(Hidden layer)을 거쳐 출 력층(Output layer)에 연결된 다층 신경망 형태일 수 있다. 또한, 제2 인공지능 모델은 입력층(Input layer)이 은닉층(Hidden layer)을 거치지 않고 직접 출력층(Output layer)에 연결된 단층 신경망 형태일 수 있다. 또한, 제2 인공지능 모델은 제1 인공지능 모델과 동일할 수도, 상이할 수도 있다. 제3 점수는 정밀도(precision)와 재현율(recall)의 조화평균인 F1 score를 사용하여 산출될 수 있다. 예를 들어, 제2 인공지능 모델의 정밀도(precision)는 수학식 1에 따라 산출될 수 있고, 제2 인공지능 모델의 재현율 (recall)은 수학식 2에 따라 산출될 수 있고, 제2 인공지능 모델의 정밀도와 재현율의 조화평균은 수학식 3에 따라 산출될 수 있다. F1 score는 정밀도(precision)과 재현율(recall)이 어느 한 쪽으로 편중되지 않을 때 상대적으로 높은 값을 가 질 수 있다. 단계 260에서, 데이터 불균형 개선 장치는 단계 250에서 산출한 제3 점수 중 가장 높은 점수를 가진 제2 학습그 룹을 오버 샘플링 학습그룹으로 선택할 수 있다. 도 3은 일 실시예에 따른 데이터 감소가 필요한 학습영상을 그룹핑하고 내림차순으로 정렬하는 방법을 도시하기 위한 예시적인 흐름도이다. 도 3을 참조하면, 단계 300에서, 데이터 불균형 개선 장치는 제1 학습영상과 제2 학습영상을 수신할 수 있다. 예를 들어, 제1 학습영상은 이미지, 음성 데이터, 센서 데이터, 동영상 등이 될 수 있으나, 이에 제한되지 않는 다. 또한, 제1 학습영상의 개수는 설명의 편의를 위하여, 이하에서는 M개로 한다. 예를 들어, 제2 학습영상은 이미지, 음성 데이터, 센서 데이터, 동영상 등이 될 수 있으나, 이에 제한되지 않고, 제1 학습영상과 상이할 수 있다. 또한, 제2 학습영상의 개수는 설명의 편의를 위하여, 이하에서는 N개로 한다. 또한, M은 N보다 큰 숫자라고 가정하여 설명하기로 한다. 단계 310에서, 데이터 불균형 개선 장치는 제1 학습영상을 무작위로 섞을 수 있다. 단계 320에서, 데이터 불균형 개선 장치는 제1 학습영상을 그룹으로 묶어 제1 학습그룹을 생성할 수 있다. 제1 학습그룹 내 제1 학습영상의 개수는 N개가 될 수 있고, 제1 학습그룹은 M/N개가 생성될 수 있다. 이하에서 는 설명의 편의를 위하여 생성된 제1 학습그룹을 G1, G2, G3, ... , GM/N으로 한다. 단계 330에서, 데이터 불균형 개선 장치는 제1 학습그룹 중 하나와 제2 학습영상을 입력하여 제1 인공지능 모델 을 학습시킬 수 있다. 제1 인공지능 모델은 사람 또는 동물 두뇌의 구조에 착안하여 구현된 컴퓨팅 시스템으로서, 하드웨어로 구현될 수도 있고, 소프트웨어로 구현될 수도 있다. 예를 들어, 제1 인공지능 모델은 기계 학습(machine learning)모델 중 하나일 수 있다. 제1 인공지능 모델은 입력층(Input layer)이 하나 이상의 은닉층(Hidden layer)을 거쳐 출 력층(Output layer)에 연결된 다층 신경망 형태일 수 있다. 또한, 제1 인공지능 모델은 입력층(Input layer)이 은닉층(Hidden layer)을 거치지 않고 직접 출력층(Output layer)에 연결된 단층 신경망 형태일 수 있다. 단계 340에서, 데이터 불균형 개선 장치는 제1 인공지능 모델의 출력 결과를 이용한 제1 점수를 산출할 수 있다. 제1 점수는 정밀도(precision)와 재현율(recall)의 조화평균인 F1 score를 사용하여 산출될 수 있다. 예를 들어, 제1 인공지능 모델의 정밀도(precision)는 수학식 1에 따라 산출될 수 있고, 제1 인공지능 모델의 재현율 (recall)은 수학식 2에 따라 산출될 수 있고, 제1 인공지능 모델의 정밀도와 재현율의 조화평균은 수학식 3에 따라 산출될 수 있다. F1 score는 정밀도(precision)과 재현율(recall)이 어느 한 쪽으로 편중되지 않을 때 상대적으로 높은 값을 가 질 수 있다.예를 들어, 제1 점수는 각각의 F1 score가 클수록 더 높은 값이 될 수 있고, 각 F1 score 간의 차이가 적을수록 더 높은 값이 될 수 있어, 일 예에 따르면 제1 점수를 산출하는 계산식은 A+B+(A-B)2가 될 수 있다. 이때, A는 제1 인공지능 모델에 제1 학습그룹 중 하나를 입력했을 때 산출되는 F1 score가 될 수 있고, B는 제1 인공지능 모델에 제2 학습영상을 입력했을 때 산출되는 F1 score가 될 수 있다. 단계 350에서, 데이터 불균형 개선 장치는 모든 제1 학습그룹에 대하여 제1 인공지능 모델을 학습시켰는지 여부 를 확인할 수 있다. 데이터 불균형 개선 장치는 단계 320에서 생성된 모든 제1 학습그룹이 제1 인공지능 모델을 학습시키는 데 이용 될 때까지, 학습에 이용되지 않은 제1 학습그룹 중 하나와 제2 학습영상을 입력하여 제1 인공지능 모델을 학습 시키고 제1 점수를 산출하는 과정을 M/N번 반복할 수 있다. 단계 360에서, 모든 제1 학습그룹에 대하여 제1 인공지능 모델의 학습이 완료되면, 데이터 불균형 개선 장치는 제1 점수를 기준으로 제1 학습그룹을 점수가 높은 순에서 낮은 순으로 내림차순 정렬할 수 있다. 이하에서는 설 명의 편의를 위하여 G3, G1, G5, G7, ... 순으로 정렬된다고 가정하지만, 이에 제한되는 것은 아니다. 도 4는 일 실시예에 따른 언더 샘플링 학습그룹을 선정하는 방법을 도시하기 위한 예시적인 흐름도이다. 도 4를 참조하면, 단계 400에서, 데이터 불균형 개선 장치는 제1 점수가 가장 높은 제1 학습그룹과 제2 학습영 상을 입력하여 제1 인공지능 모델을 학습시킬 수 있다. 제1 점수는 도 3의 단계 340에서 산출된 제1 점수로, 정밀도(precision)와 재현율(recall)의 조화평균인 F1 score를 사용하여 산출될 수 있다. 제1 학습그룹은 도 3의 단계 320에서 생성된 제1 학습그룹일 수 있다. 예를 들어, 제2 학습영상은 이미지, 음성 데이터, 센서 데이터, 동영상 등이 될 수 있으나, 이에 제한되지 않는 다. 시스템으로서, 하드웨어로 구현될 수도 있고, 소프트웨어로 구현될 수도 있다. 예를 들어, 제1 인공지능 모델은 기계 학습(machine learning)모델 중 하나일 수 있다. 제1 인공지능 모델은 입력층(Input layer)이 하나 이상의 은닉층(Hidden layer)을 거쳐 출력층(Output layer)에 연결된 다층 신경망 형태일 수 있다. 또한, 제1 인공지능 모델은 입력층(Input layer)이 은닉층(Hidden layer)을 거치지 않고 직접 출력층(Output layer)에 연결된 단층 신경망 형태일 수 있다. 단계 410에서, 데이터 불균형 개선 장치는 제1 인공지능 모델의 출력 결과를 이용한 제2 점수를 산출할 수 있다. 제2 점수는 정밀도(precision)와 재현율(recall)의 조화평균인 F1 score를 사용하여 산출될 수 있다. 예를 들어, 제1 인공지능 모델의 정밀도(precision)는 수학식 1에 따라 산출될 수 있고, 제1 인공지능 모델의 재현율 (recall)은 수학식 2에 따라 산출될 수 있고, 제1 인공지능 모델의 정밀도와 재현율의 조화평균은 수학식 3에 따라 산출될 수 있다. F1 score는 정밀도(precision)과 재현율(recall)이 어느 한 쪽으로 편중되지 않을 때 상대적으로 높은 값을 가 질 수 있다. 예를 들어, 제2 점수는 각각의 F1 score가 클수록 더 높은 값이 될 수 있고, 각 F1 score 간의 차이가 적을수록 더 높은 값이 될 수 있어, 일 예에 따르면 제2 점수를 산출하는 계산식은 A+B+(A-B)2가 될 수 있다. 이때, A는 제1 인공지능 모델에 제1 점수가 가장 높은 제1 학습그룹(G3)을 입력했을 때 산출되는 F1 score가 될 수 있고, B는 제1 인공지능 모델에 제2 학습영상을 입력했을 때 산출되는 F1 score가 될 수 있다. 단계 420에서, 데이터 불균형 개선 장치는 제1 점수가 가장 높은 제1 학습그룹(G3)에 제1 점수가 다음으로 높은 제1 학습그룹(G1)을 추가하고, 제2 학습영상을 함께 입력하여 제1 인공지능 모델을 학습시킬 수 있다. 따라서, 제1 인공지능 모델의 학습에는 제1 점수가 가장 높은 제1 학습그룹(G3)과 제1 점수가 두번째로 높은 제 1 학습그룹(G1) 및 제2 학습영상이 이용될 수 있다. 단계 430에서, 데이터 불균형 개선 장치는 제1 인공지능의 출력 결과를 이용하여 제1 인공지능 모델의 제2 점수 를 산출할 수 있다. 제1 점수가 가장 높은 제1 학습그룹(G3)에 제1 점수가 다음으로 높은 제1 학습그룹(G1)을 추가하였기 때문에, 제 2 점수를 산출하는 계산식 A+B+(A-B)2에서, A는 제1 인공지능 모델에 제1 점수가 가장 높은 제1 학습그룹(G3)과 제1 점수가 두번째로 높은 제1 학습그룹(G1)을 함께 입력하였을 때 산출되는 F1 score일 수 있다. 단계 440에서, 데이터 불균형 개선 장치는 학습그룹별 제1 인공지능 모델의 제2 점수를 그래프화 할 수 있다. 예를 들어, 제1 점수가 가장 높은 제1 학습그룹(G3) 및 제2 학습영상을 입력하여 제1 인공지능을 학습시킨 것이 학습 1이 될 수 있다. 또한, 제1 점수가 가장 높은 제1 학습그룹(G3)에 제1 점수가 두번째로 높은 제1 학습그룹 (G1)을 추가하고, 제2 학습영상을 함께 입력하여 제1 인공지능을 학습시킨 것이 학습 2가 될 수 있다. 단계 450에서, 데이터 불균형 개선 장치는 제1 점수가 가장 높은 제1 학습그룹(G3)에 모든 제1 학습그룹이 추가 되고 제2 학습영상과 함께 입력되어 제1 인공지능을 학습시켰는지 여부를 확인할 수 있다. 모든 제1 학습그룹이 추가되어 제1 인공지능 학습에 이용될 때까지, 데이터 불균형 개선 장치는 학습에 이용되 지 않은 제1 학습그룹 중 점수가 가장 높은 제1 학습그룹을 추가하고 제2 학습영상과 함께 입력하여 제1 인공지 능 모델을 학습시키고 제2 점수를 산출하여 그래프화 하는 과정을 반복할 수 있다. 단계 460에서, 데이터 불균형 개선 장치는 제2 점수가 미리 설정된 값에 해당하는 제1 학습그룹을 언더 샘플링 학습그룹으로 선택할 수 있다. 미리 설정된 값은 사용자가 미리 설정한 값일 수 있고, 이하에서는 설명의 편의를 위하여 산출된 제2 점수 중 최대값의 70%가 되는 값을 미리 설정한 값으로 하여 설명하기로 하지만, 이에 제한되는 것은 아니다. 도 5a는 일 실시예에 따른 데이터 감소가 필요한 학습영상을 그룹핑하고 내림차순으로 정렬하는 방법을 설명하 기 위한 예시적인 도면이고, 도 5b는 일 실시예에 따른 데이터가 감소된 학습그룹 중에서 언더 샘플링 학습그룹 을 선정하는 방법을 설명하기 위한 예시적인 도면으로서, 이하에서는 도 5a 및 도 5b를 함께 참조하여 설명하기 로 한다. 데이터 불균형 개선 장치는 제1 학습영상과 제2 학습영상을 사용자로부터 수신할 수 있다. 예를 들어, 제1 학습영상은 이미지, 음성 데이터, 센서 데이터, 동영상 등이 될 수 있으나, 이에 제한되지 않는다. 또한, 제1 학습영상의 개수는 설명의 편의를 위하여, 이하에서는 M개로 한다. 예를 들어, 제2 학습영상은 이미지, 음성 데이터, 센서 데이터, 동영상 등이 될 수 있으나, 이에 제한되지 않고, 제1 학습영상과 상이할 수 있다. 또한, 제2 학습영상의 개수는 설명의 편의를 위하여, 이하에 서는 N개로 한다. 또한, M은 N보다 큰 숫자라고 가정하여 설명하기로 한다. 다음으로, 데이터 불균형 개선 장치는 제1 학습영상을 무작위로 섞고 그룹으로 묶어 제1 학습그룹 을 생성할 수 있다. 제1 학습그룹 내 제1 학습영상의 개수는 N개가 될 수 있고, 제1 학습그룹은 M/N개가 생성될 수 있다. 이하에서는 설명의 편의를 위하여 생성된 제1 학습그룹을 G1, G2, G3, ... , GM/N으로 한다. 다음으로, 데이터 불균형 개선 장치는 제1 학습그룹 중 하나와 제2 학습영상을 입력하여 제1 인공지 능 모델을 학습시킬 수 있다. 제1 인공지능 모델은 사람 또는 동물 두뇌의 구조에 착안하여 구현된 컴퓨팅 시스템으로서, 하드웨어로 구 현될 수도 있고, 소프트웨어로 구현될 수도 있다. 예를 들어, 제1 인공지능 모델은 기계 학습(machine learning)모델 중 하나일 수 있다. 제1 인공지능 모델은 입력층(Input layer)이 하나 이상의 은닉층 (Hidden layer)을 거쳐 출력층(Output layer)에 연결된 다층 신경망 형태일 수 있다. 또한, 제1 인공지능 모델 은 입력층(Input layer)이 은닉층(Hidden layer)을 거치지 않고 직접 출력층(Output layer)에 연결된 단 층 신경망 형태일 수 있다. 다음으로, 데이터 불균형 개선 장치는 제1 인공지능 모델의 출력 결과를 이용한 제1 점수를 산출할 수 있다. 제1 점수는 정밀도(precision)와 재현율(recall)의 조화평균인 F1 score를 사용하여 산출될 수 있다. 예를 들어, 제1 인공지능 모델의 정밀도(precision)는 수학식 1에 따라 산출될 수 있고, 제1 인공지능 모델 의 재현율(recall)은 수학식 2에 따라 산출될 수 있고, 제1 인공지능 모델의 정밀도와 재현율의 조화 평균은 수학식 3에 따라 산출될 수 있다. F1 score는 정밀도(precision)과 재현율(recall)이 어느 한 쪽으로 편중되지 않을 때 상대적으로 높은 값을 가 질 수 있다. 예를 들어, 제1 점수는 각각의 F1 score가 클수록 더 높은 값이 될 수 있고, 각 F1 score 간의 차이가 적을수록 더 높은 값이 될 수 있어, 일 예에 따르면 제1 점수를 산출하는 계산식은 A+B+(A-B)2가 될 수 있다. 이때, A는 제1 인공지능 모델에 제1 학습그룹 중 하나를 입력했을 때 산출되는 F1 score가 될 수 있고, B는 제1 인공지능 모델에 제2 학습영상을 입력했을 때 산출되는 F1 score가 될 수 있다. 데이터 불균형 개선 장치는 모든 제1 학습그룹이 제1 인공지능 모델을 학습시키는 데 이용될 때까지, 학습에 이용되지 않은 제1 학습그룹 중 하나와 제2 학습영상을 입력하여 제1 인공지능을 학습시키고, 출력 결과를 이용한 제1 점수를 산출하는 과정을 M/N번 반복할 수 있다. 모든 제1 학습그룹에 대하여 제1 인공지능 모델의 학습이 완료되면, 데이터 불균형 개선 장치는 제1 점수를 기준으로 제1 학습그룹을 점수가 높은 순에서 낮은 순으로 내림차순 정렬할 수 있다. 이하에 서는 설명의 편의를 위하여 G3, G1, G5, G7, ... 순으로 정렬된다고 가정하지만, 이에 제한되는 것은 아니다. 다음으로, 데이터 불균형 개선 장치는 제1 학습그룹 중 제1 점수가 가장 높은 제1 학습그룹(G3)과 제2 학 습영상을 입력하여 제1 인공지능을 학습시키고, 출력 결과를 이용한 제2 점수를 산출할 수 있다. 제2 점수는 정밀도(precision)와 재현율(recall)의 조화평균인 F1 score를 사용하여 산출될 수 있다. 예를 들어, 제1 인공지능 모델의 정밀도(precision)는 수학식 1에 따라 산출될 수 있고, 제1 인공지능 모델 의 재현율(recall)은 수학식 2에 따라 산출될 수 있고, 제1 인공지능 모델의 정밀도와 재현율의 조화 평균은 수학식 3에 따라 산출될 수 있다. F1 score는 정밀도(precision)과 재현율(recall)이 어느 한 쪽으로 편중되지 않을 때 상대적으로 높은 값을 가 질 수 있다. 예를 들어, 제2 점수는 각각의 F1 score가 클수록 더 높은 값이 될 수 있고, 각 F1 score 간의 차이가 적을수록 더 높은 값이 될 수 있어, 일 예에 따르면 제2 점수를 산출하는 계산식은 A+B+(A-B)2가 될 수 있다. 이때, A는 제1 인공지능 모델에 제1 점수가 가장 높은 제1 학습그룹(G3)을 입력했을 때 산출되는 F1 score가 될 수 있고, B는 제1 인공지능 모델에 제2 학습영상을 입력했을 때 산출되는 F1 score가 될 수 있다. 다음으로, 데이터 불균형 개선 장치는 제1 점수가 가장 높은 제1 학습그룹(G3)에 제1 점수가 다음으로 높은 제1 학습그룹(G1)을 추가하고, 제2 학습영상을 함께 입력하여 제1 인공지능 모델을 학습시키고, 출 력 결과를 이용한 제2 점수를 산출할 수 있다. 제1 점수가 가장 높은 제1 학습그룹(G3)에 제1 점수가 다음으로 높은 제1 학습그룹(G1)을 추가하였기 때문 에, 제2 점수를 산출하는 계산식 A+B+(A-B)2에서, A는 제1 인공지능 모델에 제1 점수가 가장 높은 제1 학 습그룹(G3)과 제1 점수가 두번째로 높은 제1 학습그룹(G1)을 함께 입력하였을 때 산출되는 F1 score일 수 있다. 데이터 불균형 개선 장치는 제1 점수가 가장 낮은 학습그룹을 추가하여 제1 인공지능 모델을 학습시킬 때까지, 정렬된 제1 학습그룹을 하나씩 순차대로 추가하여 제1 인공지능을 학습시키고 제2 점수를 산출 하는 과정을 반복할 수 있다. 도 6은 일 실시예에 따른 제2 점수를 이용하여 언더 샘플링 학습그룹을 선정하는 방법을 설명하기 위한 예시적 인 도면이다. 이하에서는 도 6을 참조하여, 도 5b에서 산출한 제2 점수를 그래프화한 일 예를 설명하기로 한다. 인공지능 모 델과 입력한 학습영상 및 학습그룹에 따라 그래프는 상이할 수 있다. 학습 1은 제1 점수가 가장 높은 제1 학습그룹 및 제2 학습영상을 입력하여 제1 인공지능을 학습시킨 것으로, 일 실시예에선 도 5a 및 도 5b에 따라 G3과 제2 학습영상을 입력한 것일 수 있다. 학습 2는 제1 점수가 가장 높은 제1 학습그룹에 제1 점수가 두번째로 높은 제1 학습그룹을 추가하고 제2 학습영 상과 함께 입력하여 제1 인공지능을 학습시킨 것으로, 일 실시예에선 도 5a 및 도 5b에 따라 G3과 G1 및 제2 학 습영상을 입력한 것일 수 있다. 학습 3은 제1 점수가 가장 높은 제1 학습그룹에 점수가 두번째로 높은 제1 학습그룹 및 제1 점수가 세번째로 높 은 제1 학습그룹을 추가하고 제2 학습영상과 함께 입력하여 제1 인공지능을 학습시킨 것으로, 일 실시예에선 도 5a 및 도 5b에 따라 G3, G1, G5 및 제2 학습영상을 입력한 것일 수 있다. Score_max는 산출된 제2 점수 중 가장 높은 점수이며, 일 실시예에선, 학습 3을 입력했을 때 산출된 제2 점수 가 Score_max가 될 수 있다. 언더 샘플링 학습그룹은 미리 설정된 값에 해당하는 점수를 가진 제1 학습그룹이 선정될 수 있고, 설명의 편의 를 위해 일 실시예에선, Score_max의 70%가 되는 값을 미리 설정된 값으로 하지만, 이에 제한되는 것은 아니다. 일 실시예에 따르면, Score_max의 70%가 되는 지점인 0.7*Score_max를 점수로 가진 학습은 학습 4이며, 학습 4는 제1 점수가 가장 높은 제1 학습그룹에 점수가 두번째로 높은 제1 학습그룹, 제1 점수가 세번째로 높은 제1 학습그룹 및 점수가 네번째로 높은 제1 학습그룹을 추가하고 제2 학습영상과 함께 입력하여 제1 인공지능을 학습시킨 것일 수 있다. 예를 들어, 일 실시예에선, 도 5a 및 도 5b에 따라 G3, G1, G5, G7 및 제2 학습영상을 입력한 것일 수 있다. 도 7은 일 실시예에 따른 데이터가 증강된 학습그룹 중에서 오버 샘플링 학습그룹을 선정하는 방법을 도시하기 위한 예시적인 흐름도이다. 도 7을 참조하면, 단계 700에서, 데이터 불균형 개선 장치는 데이터 증강 기법 중 하나를 선택할 수 있다. 예를 들어, 데이터 증강 기법은 노이즈 첨가, 콘트라스트(contrast) 변화, 크롭핑(cropping), 회전, 색상 변화, 확대, 축소 등이 될 수 있으나, 이에 제한되지 않는다. 하나의 학습영상에 데이터 증강 기법 중 하나를 적용할 수 있고, 두 가지 이상의 데이터 증강 기법을 적용하는 것도 가능하다. 또한, 적용되는 데이터 증강 기법의 순 서는 제한되지 않는다. 이하에서는 설명의 편의를 위하여, 일 실시예에서 사용할 데이터 증강 기법의 개수를 P개로 하여 설명하기로 한 다. 단계 710에서, 데이터 불균형 개선 장치는 데이터 증강 기법의 파라메터 값을 조정할 수 있다. 모든 데이터 증강 기법에는 학습 영상을 변화시키는 파라메터가 존재할 수 있다. 예를 들어, 데이터 증강 기법 중 노이즈 첨가에는 노이즈의 크기를 결정하는 노이즈 값이 파라메터가 될 수 있다. 또한, 콘트라스트 (contrast) 변화에는 감마 값이 파라메터가 될 수 있고, 크롭핑(cropping)에는 잘라내고 남은 이미지의 크기가 파라메터가 될 수 있고, 회전에는 회전 각도가 파라메터가 될 수 있고, 색상 변화에는 색상 변화값이 파라메터 가 될 수 있으나, 이에 제한되는 것은 아니다. 데이터 증강 기법의 파라메터 값의 변화는 데이터 증강 결과 생성된 데이터의 특성을 결정할 수 있고, 인공지능 학습모델의 인식 성능에 영향을 줄 수 있다. 즉, 파라메터 값의 변화가 적을수록 데이터 증강의 실제적인 효과 를 저해하여 인공지능 학습모델의 인식 성능이 개선되지 않을 수 있고, 파라메터 값의 변화가 클수록 학습 영상 과 다른 특성을 가지게 되어 인공지능 학습모델의 인식 성능을 저해할 수도 있다. 데이터 증강이 반복될수록, 파라메터의 변화 값을 크게 하기 위해, 일 예에 따르면 파라메터의 값을 산출하는 계산식은 0.05*D*i가 될 수 있다. 이때, D는 파라메터가 변할 수 있는 전체 범위이며, i는 반복 수행된 횟수일 수 있다. 단계 720에서, 데이터 불균형 개선 장치는 데이터 증강 당 생성할 영상의 개수를 (제2 학습영상의 개수/데이터 증강 기법의 개수)로 하여 제2 학습영상 내에서 무작위로 선택할 수 있다. 예를 들어, 제2 학습영상은 이미지, 음성 데이터, 센서 데이터, 동영상 등이 될 수 있으나, 이에 제한되지 않는 다. 이하에서는 설명의 편의를 위하여, 제2 학습영상의 개수를 N개로 하여 설명하기로 한다. 단계 730에서, 데이터 불균형 개선 장치는 단계 720에서 선택한 제2 학습영상에 단계 700에서 선택한 데이터 증 강 기법을 적용하여 데이터 증강 영상을 생성할 수 있다. 단계 720에서 N/P개를 선택했기 때문에, 생성되는 데이터 증강 영상은 N/P개가 될 수 있다. 단계 740에서, 데이터 불균형 개선 장치는 P개의 데이터 증강 기법을 모두 사용했는지 여부를 확인할 수 있다. 사용되지 않은 데이터 증강 기법이 있다면, 데이터 불균형 개선 장치는 사용되지 않은 데이터 증강 기법 중 하 나를 선택하여 데이터 증강 영상을 생성하는 과정(단계 700 내지 단계 730)을 반복할 수 있다. P개의 데이터 증강 기법이 모두 사용되었다면, 단계 750에서, 데이터 불균형 개선 장치는 총 N개의 데이터 증강 영상을 갖는 제2 학습그룹을 생성할 수 있다. 이하에서는 설명의 편의를 위하여 첫번째로 생성된 제2 학습그룹 을 A1이라 한다. 단계 760에서, 데이터 불균형 개선 장치는 언더 샘플링 학습그룹과 제2 학습영상 및 생성된 모든 제2 학습그룹 을 입력하여 제2 인공지능을 학습시킬 수 있다. 수 있다. 언더 샘플링 학습그룹은 도 4의 단계 460에서 선택된 언더 샘플링 학습그룹일 수 있다. 일 실시예에서, 제2 학습그룹은 하나만 생성되었기 때문에, 데이터 불균형 개선 장치는 언더 샘플링 학습그룹, 제2 학습영상 및 A1을 입력할 수 있다. 제2 인공지능 모델은 사람 또는 동물 두뇌의 구조에 착안하여 구현된 컴퓨팅 시스템으로서, 하드웨어로 구현될 수도 있고, 소프트웨어로 구현될 수도 있다. 예를 들어, 제2 인공지능 모델은 기계 학습(machine learning)모델 중 하나일 수 있다. 제2 인공지능 모델은 입력층(Input layer)이 하나 이상의 은닉층(Hidden layer)을 거쳐 출 력층(Output layer)에 연결된 다층 신경망 형태일 수 있다. 또한, 제2 인공지능 모델은 입력층(Input layer)이 은닉층(Hidden layer)을 거치지 않고 직접 출력층(Output layer)에 연결된 단층 신경망 형태일 수 있다. 또한, 제2 인공지능 모델은 도 3 및 도 4의 제1 인공지능 모델과 동일할 수도, 상이할 수도 있다. 단계 770에서, 데이터 불균형 개선 장치는 제2 인공지능 모델의 출력 결과를 이용한 제3 점수를 산출하고, 산출 된 점수를 그래프화 할 수 있다. 제3 점수는 정밀도(precision)와 재현율(recall)의 조화평균인 F1 score를 사용하여 산출될 수 있다. 예를 들어, 제2 인공지능 모델의 정밀도(precision)는 수학식 1에 따라 산출될 수 있고, 제2 인공지능 모델의 재현율 (recall)은 수학식 2에 따라 산출될 수 있고, 제2 인공지능 모델의 정밀도와 재현율의 조화평균은 수학식 3에 따라 산출될 수 있다. F1 score는 정밀도(precision)과 재현율(recall)이 어느 한 쪽으로 편중되지 않을 때 상대적으로 높은 값을 가 질 수 있다. 예를 들어, 제3 점수는 각각의 F1 score가 클수록 더 높은 값이 될 수 있고, 각 F1 score 간의 차이가 적을수록 더 높은 값이 될 수 있어, 일 예에 따르면 제3 점수를 산출하는 계산식은 A+B+(A-B)2가 될 수 있다. 이때, A는 제2 인공지능 모델에 언더 샘플링 학습그룹을 입력했을 때 산출되는 F1 score가 될 수 있고, B는 제2 인공지능 모델에 제2 학습영상 및 제2 학습그룹을 입력했을 때 산출되는 F1 score가 될 수 있다. 일 실시예에서, 제2 학 습그룹은 하나만 생성되었기 때문에 B는 제2 인공지능 모델에 제2 학습영상 및 A1을 입력했을 때 산출되는 F1 score일 수 있다. 단계 780에서, 데이터 불균형 개선 장치는 단계 770에서 산출된 제3 점수가 최대 점수인지 여부를 확인할 수 있 다. 산출된 제3 점수가 산출된 점수 중 최대 점수이면, 데이터 불균형 개선 장치는 단계 700 내지 단계 770을 반복 하여 N개의 영상을 갖는 제2 학습그룹(A2)을 생성하고 제3 점수를 산출할 수 있다. 이때, 데이터 불균형 개선 장치는 반복 수행된 횟수(i)에 1을 증가시켜 파라메터를 조정할 수 있고, 언더 샘플링 학습그룹과 제2 학습영상 및 A1, A2를 제2 인공지능에 입력하여 제3 점수를 산출할 수 있다. 데이터 불균형 개선 장치는 산출된 제3 점수가 최대값이 되지 않을 때까지 n번 반복하여 반복 수행된 횟수(i)는 n으로 하여 파라메터를 조정할 수 있고, 제 2 학습그룹(A3, A4, ... ,An)은 n개를 생성할 수 있다. 또한, 데이터 불균형 개선 장치는 제2 인공지능에 언더 샘플링 학습그룹과 제2 학습영상 및 A1, A2, A3, ... , An을 입력하여 제3 점수를 산출할 수 있다. 파라메터 값이 최대값인 D에 도달할 때까지 추가적인 학습이 필요하면, 파라메터를 산출하는 계산식을 (D/2)+{0.05*(D/2)*(i-j)}로 수정하여 추가 학습을 수행할 수 있다. 이때, j는 최대값인 D에 도달했을 때의 i값 이 될 수 있다. 산출된 제3 점수가 최대값이 되지 않으면, 단계 790에서, 데이터 불균형 개선 장치는 제3 점수의 값이 가장 높 은 제2 학습그룹을 오버 샘플링 학습그룹으로 선택할 수 있다. 도 8a는 일 실시예에 따른 데이터 증강이 필요한 학습영상에 데이터 증강 기법을 적용하는 방법을 설명하기 위 한 예시적인 도면이고, 도 8b는 일 실시예에 따른 데이터가 증강된 학습그룹을 생성하는 방법을 설명하기 위한 예시적인 도면으로서, 이하에서는 도 8a 및 도 8b를 함께 참조하여 설명하기로 한다. 데이터 불균형 개선 장치는 사용할 데이터 증강 기법의 종류를 결정할 수 있다. 예를 들어, 데이터 증강 기법은 노이즈 첨가, 콘트라스트(contrast) 변화, 크롭핑(cropping), 회전, 색상 변화, 확대, 축소 등이 될 수 있으나, 이에 제한되지 않는다. 하나의 학습영상에 데이터 증강 기법 중 하나를 적용할 수 있고, 두 가지 이상의 데이터 증강 기법을 적용하는 것도 가능하다. 또한, 적용되는 데이터 증강 기법의 순 서는 제한되지 않는다. 이하에서는 설명의 편의를 위하여, 일 실시예에서 사용할 데이터 증강 기법의 개수를 P개로 하여 설명하기로 한 다. 데이터 불균형 개선 장치는 사용할 데이터 증강 기법의 종류 중 하나를 선택하고, 선택한 데이터 증강 기 법의 파라메터의 값을 결정할 수 있다. 모든 데이터 증강 기법에는 학습 영상을 변화시키는 파라메터가 존재할 수 있다. 예를 들어, 데이터 증강 기법 중 노이즈 첨가에는 노이즈의 크기를 결정하는 노이즈 값이 파라메터가 될 수 있다. 또한, 콘트라스트 (contrast) 변화에는 감마 값이 파라메터가 될 수 있고, 크롭핑(cropping)에는 잘라내고 남은 이미지의 크기가 파라메터가 될 수 있고, 회전에는 회전 각도가 파라메터가 될 수 있고, 색상 변화에는 색상 변화값이 파라메터 가 될 수 있으나, 이에 제한되는 것은 아니다. 데이터 증강 기법의 파라메터 값의 변화는 데이터 증강 결과 생성된 데이터의 특성을 결정할 수 있고, 인공지능 학습모델의 인식 성능에 영향을 줄 수 있다. 즉, 파라메터 값의 변화가 적을수록 데이터 증강의 실제적인 효과 를 저해하여 인공지능 학습모델의 인식 성능이 개선되지 않을 수 있고, 파라메터 값의 변화가 클수록 학습 영상 과 다른 특성을 가지게 되어 인공지능 학습모델의 인식 성능을 저해할 수도 있다. 데이터 불균형 개선 장치는 N개의 제2 학습영상에서 N/P개를 무작위로 선택하여 N/P개의 데이터 증강 영상을 생성할 수 있다. 예를 들어, 제2 학습영상은 이미지, 음성 데이터, 센서 데이터, 동영상 등이 될 수 있으나, 이에 제한되지 않는다. 이하에서는 설명의 편의를 위하여, 제2 학습영상의 개수를 N개로 하여 설명하기로 한다. 데이터 불균형 개선 장치는 제2 학습영상에 사용하기로 결정한 데이터 증강 기법을 모두 적용하여 총 N개의 데이터 증강 영상을 갖는 제2 학습그룹을 생성할 수 있다. 이하에서는 설명의 편의를 위하여, 첫번 째로 생성된 제2 학습그룹을 A1이라 한다. 데이터 불균형 개선 장치는 언더 샘플링 학습그룹과 제2 학습영상 및 첫번째로 생성한 제2 학습영상 (A1)을 입력하여 제2 인공지능을 학습시킬 수 있다. 언더 샘플링 학습그룹은 도 5a 및 도 5b에서 선택된 언더 샘플링 학습그룹일 수 있고, 일 실시예에선, 도 6에 따라 G3, G1, G5, G7일 수 있다. 제2 인공지능 모델은 사람 또는 동물 두뇌의 구조에 착안하여 구현된 컴퓨팅 시스템으로서, 하드웨어로 구현될 수도 있고, 소프트웨어로 구현될 수도 있다. 예를 들어, 제2 인공지능 모델은 기계 학습(machine learning)모델 중 하나일 수 있다. 제2 인공지능 모델은 입력층(Input layer)이 하나 이상의 은닉층(Hidden layer)을 거쳐 출력층(Output layer)에 연결된 다층 신경망 형태일 수 있다. 또한, 제2 인공지능 모델은 입력층(Input layer)이 은닉층(Hidden layer)을 거치지 않고 직접 출력층(Output layer)에 연결된 단층 신경망 형태일 수 있다. 또한, 제2 인공지능 모델은 도 5a 및 도 5b의 제1 인공지능 모델과 동일할 수도, 상이할 수도 있다. 데이터 불균형 개선 장치는 제2 인공지능 모델의 출력 결과를 이용한 제3 점수를 산출할 수 있다. 제3 점수는 정밀도(precision)와 재현율(recall)의 조화평균인 F1 score를 사용하여 산출될 수 있다. 예를 들어, 제2 인공지능 모델의 정밀도(precision)는 수학식 1에 따라 산출될 수 있고, 제2 인공지능 모델의 재현율 (recall)은 수학식 2에 따라 산출될 수 있고, 제2 인공지능 모델의 정밀도와 재현율의 조화평균은 수학식 3에 따라 산출될 수 있다. F1 score는 정밀도(precision)과 재현율(recall)이 어느 한 쪽으로 편중되지 않을 때 상대적으로 높은 값을 가 질 수 있다. 예를 들어, 제3 점수는 각각의 F1 score가 클수록 더 높은 값이 될 수 있고, 각 F1 score 간의 차이가 적을수록 더 높은 값이 될 수 있어, 일 예에 따르면 제3 점수를 산출하는 계산식은 A+B+(A-B)2가 될 수 있다. 이때, A는 제2 인공지능 모델에 언더 샘플링 학습그룹을 입력했을 때 산출되는 F1 score가 될 수 있고, B는 제2 인공 지능 모델에 제2 학습영상 및 제2 학습그룹을 입력했을 때 산출되는 F1 score가 될 수 있다. 일 실시예에 서, 제2 학습그룹은 하나만 생성되었기 때문에 B는 제2 인공지능 모델에 제2 학습영상 및 A1을 입력 했을 때 산출되는 F1 score일 수 있다. 데이터 불균형 개선 장치는 산출된 제3 점수가 최대값이면, 제2 학습그룹을 생성하는 과정을 반복할 수 있고, 이때 생성된 제2 학습그룹은 설명의 편의를 위하여, A2, A3, ... , An으로 할 수 있다. 데이터 불균형 개선 장치는 언더 샘플링 학습그룹과 제2 학습영상 및 생성된 모든 제2 학습그룹(82 0)을 입력하여 제2 인공지능을 학습시키고 제3 점수를 산출할 수 있다. 제3 점수를 산출하는 계산식에서, B는 제2 인공지능 모델에 제2 학습영상 및 생성된 모든 제2 학습그룹 을 입력했을 때 산출되는 F1 score일 수 있다. 도 9는 일 실시예에 따른 제3 점수를 이용하여 오버 샘플링 학습그룹을 선정하는 방법을 설명하기 위한 예시적 인 도면이다. 이하에서는 도 9를 참조하여, 도 8a 및 도 8b에서 산출한 제3 점수를 그래프화한 일 예를 설명하기로 한다. 인 공지능 모델과 입력한 학습영상 및 학습그룹에 따라 그래프는 상이할 수 있다. 학습 1은 언더 샘플링 학습그룹과 제2 학습영상 및 첫번째로 생성된 제2 학습그룹을 입력하여 제2 인공지능을 학습시킨 것으로, 일 실시예에선 도 8a 및 도 8b에 따라 G3, G1, G5, G7과 제2 학습영상 및 A1을 입력한 것일 수 있다. 학습 2는 언더 샘플링 학습그룹과 제2 학습영상, 첫번째로 생성된 제2 학습그룹 및 두번째로 생성된 제2 학습그 룹을 입력하여 제2 인공지능을 학습시킨 것으로, 일 실시예에선 도 8a 및 도 8b에 따라 G3, G1, G5, G7과 제2 학 습영상, A1, A2을 입력한 것일 수 있다. Score_max는 산출된 제3 점수 중 가장 높은 점수이며, 일 실시예에선, 학습 4를 입력했을 때 산출된 제3 점수 가 Score_max가 될 수 있다. 또한, 가장 높은 점수가 산출될 때 사용된 제2 학습그룹은 오버 샘플링 학습 그룹으로 선택될 수 있다. 일 실시예에선, 학습 4에 사용된 제2 학습그룹 A1, A2, A3, A4가 오버 샘플링 학습그 룹으로 선택될 수 있다. 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같 은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 일 실시예에 따르면, 본 개시의 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2022-0184420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "전술한 본 명세서의 설명은 예시를 위한 것이며, 본 명세서의 내용이 속하는 기술분야의 통상의 지식을 가진 자 는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아 닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으 며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2022-0184420", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 인공지능 모델의 학습을 위한 학습데이터의 불균형을 개선하는 장치의 일 예를 설명하 기 위한 도면이다. 도 2는 일 실시예에 따른 인공지능 모델의 학습을 위한 학습데이터의 불균형을 개선하는 방법을 도시하기 위한 예시적인 도면이다. 도 3은 일 실시예에 따른 데이터 감소가 필요한 학습영상을 그룹핑하고 내림차순으로 정렬하는 방법을 도시하기 위한 예시적인 흐름도이다. 도 4는 일 실시예에 따른 언더 샘플링 학습그룹을 선정하는 방법을 도시하기 위한 예시적인 흐름도이다. 도 5a는 일 실시예에 따른 데이터 감소가 필요한 학습영상을 그룹핑하고 내림차순으로 정렬하는 방법을 설명하 기 위한 예시적인 도면이다. 도 5b는 일 실시예에 따른 데이터가 감소된 학습그룹 중에서 언더 샘플링 학습그룹을 선정하는 방법을 설명하기 위한 예시적인 도면이다. 도 6은 일 실시예에 따른 제2 점수를 이용하여 언더 샘플링 학습그룹을 선정하는 방법을 설명하기 위한 예시적 인 도면이다. 도 7은 일 실시예에 따른 데이터가 증강된 학습그룹 중에서 오버 샘플링 학습그룹을 선정하는 방법을 도시하기위한 예시적인 흐름도이다. 도 8a는 일 실시예에 따른 데이터 증강이 필요한 학습영상에 데이터 증강 기법을 적용하는 방법을 설명하기 위 한 예시적인 도면이다. 도 8b은 일 실시예에 따른 데이터가 증강된 학습그룹을 생성하는 방법을 설명하기 위한 예시적인 도면이다. 도 9는 일 실시예에 따른 제3 점수를 이용하여 오버 샘플링 학습그룹을 선정하는 방법을 설명하기 위한 예시적 인 도면이다."}
