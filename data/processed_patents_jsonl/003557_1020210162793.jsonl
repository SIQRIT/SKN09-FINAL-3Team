{"patent_id": "10-2021-0162793", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0126622", "출원번호": "10-2021-0162793", "발명의 명칭": "디바이스의 자세 추정 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "리우 지후아"}}
{"patent_id": "10-2021-0162793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디바이스의 자세 추정 방법에 있어서,키 프레임 세트에서 상기 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하는 단계;상기 현재 프레임과 상기 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이터 관련 정보를 획득하는 단계; 및상기 데이터 관련 정보를 기반으로 상기 디바이스의 자세를 획득하는 단계를 포함하는, 디바이스의 자세 추정방법."}
{"patent_id": "10-2021-0162793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 키 프레임 세트에서 상기 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하는 단계는,현재 프레임의 전역 특징을 추출하고, 상기 전역 특징을 기반으로 키 프레임 세트에서 현재 프레임의 유사 키프레임을 획득하는 단계;현재 프레임의 전역 특징을 추출하고, 상기 전역 특징을 기반으로 상기 키 프레임 세트 중 각 키 프레임과 현재프레임의 제1 유사도를 확정하는 단계; 상기 현재 프레임의 국소 특징을 추출하고, 상기 국소 특징을 기반으로 상기 제1 유사도를 업데이트하여, 상기키 프레임 세트 중 각 키 프레임과 현재 프레임의 제2 유사도를 획득하는 단계; 및 상기 유사 키 프레임을 기반으로 상기 현재 프레임의 유사 키 프레임을 획득하는 단계 중 어느 하나를포함하는, 디바이스의 자세 추정 방법."}
{"patent_id": "10-2021-0162793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 현재 프레임과 상기 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 상기 이미지 프레임 간의 데이터 관련 정보를 획득하는 단계는,현재 프레임에 대해 프레임 간 특징 매칭을 수행하여, 이미지 프레임 간의 제1 데이터 관련 정보를 획득하는 단계; 및상기 현재 프레임과 상기 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 상기 제1 데이터 관련 정보를 업데이트하여, 이미지 프레임 간의 제2 데이터 관련 정보를 획득하는 단계를 포함하는, 디바이스의 자세 추정 방법."}
{"patent_id": "10-2021-0162793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 현재 프레임과 상기 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 상기 제1 데이터 관련 정보를 업데이트하여, 이미지 프레임 간의 제2 데이터 관련 정보를 획득하는 단계는,현재 프레임에 대해 프레임 간 특징 매칭을 수행하여, 제1 데이터 관련 정보를 획득하는 단계, 상기 제1 데이터관련 정보는 각 이미지 프레임의 특징 간의 매칭 관계를 포함함;상기 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 각 이미지 프레임의 특징이 동일 특징인지 여부를 판단하는 단계;판단 결과를 기반으로 동일 특징을 합치는 단계; 및공개특허 10-2022-0126622-3-합친 특징을 기반으로, 상기 제1 데이터 관련 정보를 업데이트하여 제2 데이터 관련 정보를 획득하는 단계를 포함하는, 디바이스의 자세 추정 방법."}
{"patent_id": "10-2021-0162793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 이미지 특징 추출 모델을 채택하여 키 프레임 세트에서 상기 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하고,상기 이미지 특징 추출 모델은,제1 이미지 및 상기 제1 이미지를 회전 절첩한 제2 이미지를 획득하는 단계; 및제1 이미지와 제2 이미지를 기반으로, 이미지 특징 추출 모델에서 추출한 전역 특징과 국소 특징을 통해, 이미지 특징 추출 모델에 대해 공동 학습을 수행하여, 학습된 이미지 특징 추출 모델을 획득하는 단계를 통해 학습하여 획득되는, 디바이스의 자세 추정 방법."}
{"patent_id": "10-2021-0162793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 이미지 특징 추출 모델에서 추출한 전역 특징과 국소 특징을 통해, 이미지 특징 추출 모델에 대해 연합 학습을 수행하는 단계는,이미지 특징 추출 모델을 통해 제1 이미지의 국소 특징과 전역 특징을 획득하는 단계;타깃 모델을 통해 제2 이미지의 국소 특징을 획득하고, 상기 제2 이미지의 국소 특징에 대해 상기 회전 절첩에대응하는 공액 회전 절첩을 수행하는 단계;제1 이미지의 국소 특징과 공액 회전 절첩된 제2 이미지의 국소 특징을 기반으로 국소 특징쌍을 획득하는 단계;및상기 국소 특징쌍과 상기 전역 특징을 기반으로, 상기 이미지 특징 추출 모델의 파라미터를 업데이트하는 단계를 포함하는, 디바이스의 자세 추정 방법."}
{"patent_id": "10-2021-0162793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "디바이스의 자세 추정 장치에 있어서,키 프레임 세트에서 상기 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하도록 구성되는 제1 획득 모듈;상기 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이터 관련 정보를획득하도록 구성되는 제2 획득 모듈; 및상기 데이터 관련 정보를 기반으로 상기 디바이스의 자세를 획득하도록 구성되는 제3 획득 모듈을 포함하는, 디바이스의 자세 추정 장치."}
{"patent_id": "10-2021-0162793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "전자 디바이스에 있어서, 메모리와 프로세서를 포함하고,상기 메모리에는 컴퓨터 프로그램이 저장되고,상기 프로세서는 상기 컴퓨터 프로그램을 운행할 때, 제1항 내제 제6항 중 어느 한 항에 따른 방법을 실행하도록 구성되는, 전자 디바이스."}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 인공 지능"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것으로, 디바이스의 자세 추정 방법 및 관련 디바이스에 관한 것이다. 여 기에서 디바이스의 자세 추정 방법은 키 프레임 세트에서 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획 득하는 단계; 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이터 관련 정보를 획득하는 단계; 및 데이터 관련 정보를 기반으로 디바이스의 자세를 획득하는 단계를 포함한다. 상기 방 법의 실시는 자세 추정의 속도와 정밀도를 향상시키는 데 도움이 된다. 대 표 도 - 도1"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2022-0126622 CPC특허분류 G06T 7/11 (2017.01) G06V 10/10 (2022.01) G06V 10/40 (2022.01) 발명자 왕 창 중국 베이징 차오양 디스트릭트 타이양공 미들 로 드 넘버 12에이. 타이양공 빌딩 18층 김윤태 경기도 수원시 영통구 태장로82번길 32, 102동 1404호 (망포동, 동수원자이1차)마 쿠안 중국 베이징 차오양 디스트릭트 타이양공 미들 로 드 넘버 12에이. 타이양공 빌딩 18층명 세 서 청구범위 청구항 1 디바이스의 자세 추정 방법에 있어서, 키 프레임 세트에서 상기 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하는 단계; 상기 현재 프레임과 상기 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이터 관련 정 보를 획득하는 단계; 및 상기 데이터 관련 정보를 기반으로 상기 디바이스의 자세를 획득하는 단계를 포함하는, 디바이스의 자세 추정 방법. 청구항 2 제1항에 있어서, 상기 키 프레임 세트에서 상기 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하는 단계는, 현재 프레임의 전역 특징을 추출하고, 상기 전역 특징을 기반으로 키 프레임 세트에서 현재 프레임의 유사 키 프레임을 획득하는 단계; 현재 프레임의 전역 특징을 추출하고, 상기 전역 특징을 기반으로 상기 키 프레임 세트 중 각 키 프레임과 현재 프레임의 제1 유사도를 확정하는 단계; 상기 현재 프레임의 국소 특징을 추출하고, 상기 국소 특징을 기반으로 상기 제1 유사도를 업데이트하여, 상기 키 프레임 세트 중 각 키 프레임과 현재 프레임의 제2 유사도를 획득하는 단계; 및 상기 유사 키 프레임을 기반으로 상기 현재 프레임의 유사 키 프레임을 획득하는 단계 중 어느 하나를 포함하는, 디바이스의 자세 추정 방법. 청구항 3 제1항에 있어서, 상기 현재 프레임과 상기 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 상기 이미지 프레임 간의 데이터 관 련 정보를 획득하는 단계는, 현재 프레임에 대해 프레임 간 특징 매칭을 수행하여, 이미지 프레임 간의 제1 데이터 관련 정보를 획득하는 단 계; 및 상기 현재 프레임과 상기 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 상기 제1 데이터 관련 정보를 업데 이트하여, 이미지 프레임 간의 제2 데이터 관련 정보를 획득하는 단계를 포함하는, 디바이스의 자세 추정 방법. 청구항 4 제3항에 있어서, 상기 현재 프레임과 상기 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 상기 제1 데이터 관련 정보를 업데 이트하여, 이미지 프레임 간의 제2 데이터 관련 정보를 획득하는 단계는, 현재 프레임에 대해 프레임 간 특징 매칭을 수행하여, 제1 데이터 관련 정보를 획득하는 단계, 상기 제1 데이터 관련 정보는 각 이미지 프레임의 특징 간의 매칭 관계를 포함함; 상기 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 각 이미지 프레임의 특징이 동일 특징인 지 여부를 판단하는 단계; 판단 결과를 기반으로 동일 특징을 합치는 단계; 및합친 특징을 기반으로, 상기 제1 데이터 관련 정보를 업데이트하여 제2 데이터 관련 정보를 획득하는 단계를 포 함하는, 디바이스의 자세 추정 방법. 청구항 5 제1항에 있어서, 이미지 특징 추출 모델을 채택하여 키 프레임 세트에서 상기 디바이스가 수집한 현재 프레임의 유사 키 프레임 을 획득하고, 상기 이미지 특징 추출 모델은, 제1 이미지 및 상기 제1 이미지를 회전 절첩한 제2 이미지를 획득하는 단계; 및 제1 이미지와 제2 이미지를 기반으로, 이미지 특징 추출 모델에서 추출한 전역 특징과 국소 특징을 통해, 이미 지 특징 추출 모델에 대해 공동 학습을 수행하여, 학습된 이미지 특징 추출 모델을 획득하는 단계를 통해 학습 하여 획득되는, 디바이스의 자세 추정 방법. 청구항 6 제5항에 있어서, 상기 이미지 특징 추출 모델에서 추출한 전역 특징과 국소 특징을 통해, 이미지 특징 추출 모델에 대해 연합 학 습을 수행하는 단계는, 이미지 특징 추출 모델을 통해 제1 이미지의 국소 특징과 전역 특징을 획득하는 단계; 타깃 모델을 통해 제2 이미지의 국소 특징을 획득하고, 상기 제2 이미지의 국소 특징에 대해 상기 회전 절첩에 대응하는 공액 회전 절첩을 수행하는 단계; 제1 이미지의 국소 특징과 공액 회전 절첩된 제2 이미지의 국소 특징을 기반으로 국소 특징쌍을 획득하는 단계; 및 상기 국소 특징쌍과 상기 전역 특징을 기반으로, 상기 이미지 특징 추출 모델의 파라미터를 업데이트하는 단계 를 포함하는, 디바이스의 자세 추정 방법. 청구항 7 디바이스의 자세 추정 장치에 있어서, 키 프레임 세트에서 상기 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하도록 구성되는 제1 획득 모 듈; 상기 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이터 관련 정보를 획득하도록 구성되는 제2 획득 모듈; 및 상기 데이터 관련 정보를 기반으로 상기 디바이스의 자세를 획득하도록 구성되는 제3 획득 모듈을 포함하는, 디 바이스의 자세 추정 장치. 청구항 8 전자 디바이스에 있어서, 메모리와 프로세서를 포함하고, 상기 메모리에는 컴퓨터 프로그램이 저장되고, 상기 프로세서는 상기 컴퓨터 프로그램을 운행할 때, 제1항 내제 제6항 중 어느 한 항에 따른 방법을 실행하도 록 구성되는, 전자 디바이스. 발명의 설명 기 술 분 야본 개시는 인공 지능 기술 분야에 관한 것으로, 더욱 상세하게는 디바이스의 자세 추정 방법 및 장치에 관한 것 이다."}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능 기술이 발달함에 따라, 인공 지능 기술은 자율주행, 로봇 내비게이션, 증강현실 등 다양한 분야에서 중요하게 사용되고 있다. 이러한 분야에서 디바이스의 자세 추정은 일반적으로 SLAM(simultaneous localization and mapping, 동시 로컬화 및 매핑) 기술을 채택해 구현된다. SLAM 기술은 디바이스가 수집한 두 이미지 간의 데이터 연관성을 검색함으로써 디바이스의 자세를 추정할 수 있 다. 종래 기술에서, SLAM 기술은 일반적으로 광학 흐름법(optical flow method)과 특징점법(characteristic point method)을 통해 추적함으로써 두 이미지 간의 데이터 연관성을 확정한다. 그러나 상기 추적 방법은 특징점의 표 현 성능에 의해 제한되므로, 이미지 프레임 간의 데이터 연관성을 정확하게 검색할 수 없다. 이는 디바이스의 자세 추정에서 SLAM 기술의 안정성과 정확도에 영향을 미친다."}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 다양한 실시예들은 SLAM 기술의 안정성과 정확도를 확보할 수 있는 디바이스의 자세 추정 방법 및 장 치를 제공하고자 한다. 본 개시의 실시예들을 통해 해결하고자 하는 과제가 상술한 과제로 한정되는 것은 아니며, 언급되지 아니한 과"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "제들은 본 개시 및 첨부된 도면으로부터 실시예들이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제1 양상에 있어서, 본 개시의 디바이스의 자세 추정 방법은, 키 프레임 세트에서 디바이스가 수집한 현재 프레 임의 유사 키 프레임을 획득하는 단계; 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이터 관련 정보를 획득하는 단계; 및 데이터 관련 정보를 기반으로 상기 디바이스의 자세를 획득 하는 단계를 포함할 수 있다. 일 실시예에 있어서, 키 프레임 세트에서 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하는 단계는, 현재 프레임의 전역 특징(global feature)을 추출하고, 전역 특징을 기반으로 키 프레임 세트에서 현재 프레임 의 유사 키 프레임을 획득하는 단계; 현재 프레임의 전역 특징을 추출하고, 전역 특징을 기반으로 키 프레임 세 트 중 각 키 프레임과 현재 프레임의 제1 유사도를 확정하고; 현재 프레임의 국소 특징(local feature)을 추출 하고, 국소 특징을 기반으로 제1 유사도를 업데이트하여, 키 프레임 세트 중 각 키 프레임과 현재 프레임의 제2 유사도를 획득하고; 유사 키 프레임을 기반으로 현재 프레임의 유사 키 프레임을 획득하는 단계 중 어느 하나를 포함할 수 있다. 일 실시예에 있어서, 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이 터 관련 정보를 획득하는 단계는, 현재 프레임에 대해 프레임 간 특징 매칭을 수행하여, 이미지 프레임 간의 제 1 데이터 관련 정보를 획득하는 단계; 및 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 제1 데이터 관련 정보를 업데이트하여, 이미지 프레임 간의 제2 데이터 관련 정보를 획득하는 단계를 포함할 수 있 다. 다른 일 실시예에 있어서, 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 제1 데이터 관련 정 보를 업데이트하여, 이미지 프레임 간의 제2 데이터 관련 정보를 획득하는 단계는, 현재 프레임에 대해 프레임 간 특징 매칭을 수행하여, 제1 데이터 관련 정보를 획득하는 단계, 상기 제1 데이터 관련 정보는 각 이미지 프 레임의 특징 간의 매칭 관계를 포함함; 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 각 이 미지 프레임의 특징이 동일 특징인지 여부를 판단하는 단계; 상기 판단 결과를 기반으로 동일 특징을 합치는 단 계; 및 상기 합친 특징을 기반으로, 제1 데이터 관련 정보를 업데이트하여 제2 데이터 관련 정보를 획득하는 단 계를 포함할 수 있다.일 실시예에 있어서, 이미지 특징 추출 모델을 채택하여 키 프레임 세트에서 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득할 수 있다. 이미지 특징 추출 모델은, 제1 이미지 및 상기 제1 이미지를 회전 절첩한 제2 이미지를 획득하는 단계; 및 제1 이미지와 제2 이미지를 기반으로, 이미지 특징 추출 모델에서 추출한 전역 특징과 국소 특징을 통해, 이미지 특 징 추출 모델에 대해 공동 학습을 수행하여, 학습된 이미지 특징 추출 모델을 획득하는 단계를 통해 획득될 수 있다. 일 실시예에 있어서, 이미지 특징 추출 모델에서 추출한 전역 특징과 국소 특징을 통해, 이미지 특징 추출 모델 에 대해 공동 학습을 수행하는 단계는, 이미지 특징 추출 모델을 통해 제1 이미지의 국소 특징과 전역 특징을 획득하는 단계; 타깃 모델을 통해 제2 이미지의 국소 특징을 획득하고, 제2 이미지의 국소 특징에 대해 회전 절 첩에 대응하는 공액 회전 절첩을 수행하는 단계; 제1 이미지의 국소 특징과 공액 회전 절첩된 제2 이미지의 국 소 특징을 기반으로 국소 특징쌍을 획득하는 단계; 및 국소 특징쌍과 전역 특징을 기반으로, 이미지 특징 추출 모델의 파라미터를 업데이트하는 단계를 포함한다. 제2 양상에 있어서, 본 개시는 디바이스의 자세 추정 장치를 제공한다. 여기에는, 키 프레임 세트에서 디바이스 가 수집한 현재 프레임의 유사 키 프레임을 획득하도록 구성되는 제1 획득 모듈; 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이터 관련 정보를 획득하도록 구성되는 제2 획득 모듈; 및 상기 데이터 관련 정보를 기반으로 디바이스의 자세를 획득하도록 구성되는 제3 획득 모듈을 포함한다. 제3 양상에 있어서, 본 개시의 전자 디바이스는 메모리와 프로세서를 포함할수 있다. 메모리에는 컴퓨터 프로그 램이 저장될 수 있다. 프로세서는 컴퓨터 프로그램을 운행할 때, 본 개시의 실시예에서 제공하는 디바이스의 자 세 추정 방법을 실행하는 데 사용된다. 제4 양상에 있어서, 본 개시는 컴퓨터 판독 가능 저장 매체를 제공할 수 있다. 상기 저장 매체에는 컴퓨터 프로 그램이 저장된다. 컴퓨터 프로그램은 프로세서에 의해 운행될 때, 본 개시의 실시예에서 제공하는 디바이스의 자세 추정 방법을 실행한다."}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시는 디바이스의 자세 추정 방법을 제공한다. 디바이스에서 수집한 현재 프레임을 통해 키 프레임 세트에 서 유사 키 프레임을 검색한 후, 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로 이미지 프레임 간의 데이터 관련 정보를 획득하여, 상기 데이터 관련 정보를 기반으로 디바이스의 자세를 획득할 수 있다. 상 기 방법의 실시에 의하여, 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 통해 이미지 프레임 간의 데이 터 관련 정보를 정확하게 검색할 수 있다. 따라서, 본 개시의 디바이스의 자세 추정 방법은 이미지 프레임 추적 의 견고성을 개선하고 자세 추정의 정확도와 계산 속도를 향상시킬 수 있다. 다른 일 양상에 있어서, 본 개시에서 제공하는 디바이스의 자세 추정 방법은, 현재 프레임에서 추출한 전역 특 징 또는 추출한 전역 특징과 국소 특징을 이용하여 키 프레임 세트에서 현재 프레임의 유사 키 프레임을 획득할 수도 있다. 상기 방법은 전역 특징 또는 전역 특징과 국소 특징의 결합을 통해 이미지 검색을 수행하여, 특징 표현 성능을 효과적으로 향상시킬 수 있다. 이를 기반으로 현재 프레임에 대해 프레임 간 시퀀스 추적을 수행하 는 처리를 결합하면, 디바이스의 자세 추정의 정확도가 향상될 수 있다. 또 다른 일 양상에 있어서, 본 개시에서 제공하는 디바이스의 자세 추정 방법은, 이미지 특징 추출 모델을 채택 하여 키 프레임 세트에서 디바이스가 수집하는 현재 프레임의 유사 키 프레임을 획득할 수 있다. 여기에서 이미 지 특징 추출 모델은 학습 과정에서 전역 특징과 국소 특징에 대해 공동 학습을 수행하는 것이다. 상기 학습 방 식은 모델이 전역 특징과 국소 특징을 학습 추출하는 과정에서 상호 학습에서 성능을 향상시키고, 나아가 모델 이 추출한 전역 특징과 국소 특징의 표현 성능을 향상시킬 수 있다. 본 개시에서 제공하는 이미지 특징 추출 모델에 의해 추출된 전역 특징 및 국소 특징을 기반으로 이미지 검색을 수행하는 것도 이미지 검색의 정확도를 효과적으로 향상시킬 수 있다. 즉, 본 개시의 실시예들은 키 프레임 세 트에서 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하는 정확도를 향상시킬 수 있다. 또 다른 일 양상에 있어서, 본 개시에서 제공하는 이미지 특징 추출 모델의 학습 과정은, 제1 이미지만 있는 경 우 제1 이미지에 대해 회전 절첩 처리를 수행하여 제2 이미지를 획득함으로써, 전역 특징 학습의 제1 이미지를 획득할 수 있는 동시에, 제2 이미지를 기반으로 국소 특징 학습을 위한 쌍을 이루는 이미지 블록을 구축할 수도 있다(제1 이미지의 국소 특징과 공액 회전 절첩된 제2 이미지의 국소 특징을 기반으로 획득한 국소 특징쌍). 상기 학습 방법은 추가적인 학습 데이터 없이도 전역 특징 학습과 국소 특징 학습에 필요한 데이터를 구축할 수 있으며, 모델 학습 비용을 낮출 수 있다."}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 실시예들에서 사용되는 용어는 본 실시예들에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "용어들을 선택하였으나, 이는 당 기술분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 임의로 선정된 용어도 있으며, 이 경우 해당 실시예의 설명 부분에서 상 세히 그 의미를 기재할 것이다. 따라서, 본 실시예들에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어 가 가지는 의미와 본 실시예들의 전반에 걸친 내용을 토대로 정의되어야 한다. 실시예들에 대한 설명들에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 그 중간에 다른 구성요소를 사이에 두고 전기적으로 연결되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 포함한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것 이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 실시예들에서 사용되는 \"구성된다\" 또는 \"포함한다\" 등의 용어는 본 개시에 기재된 여러 구성 요소들, 또는 여러 단계들을 반드시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들 은 포함되지 않을 수도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한 다. 또한, 본 개시에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하 는데 사용할 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로만 사용된다."}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "하기 실시예들에 대한 설명은 권리범위를 제한하는 것으로 해석되지 말아야 하며, 해당 기술분야의 당업자가 용 이하게 유추할 수 있는 것은 실시예들의 권리범위에 속하는 것으로 해석되어야 할 것이다. 본 개시 실시예에서 제공하는 해결 방법에 대한 이해 및 설명을 돕기 위해, 이하에서는 먼저 본 개시에 언급된 관련 기술에 대해 설명한다. 인공 지능(Artificial Intelligence, AI)은 디지털 컴퓨터 또는 디지털 컴퓨터로 제어되는 기계를 이용하여 인 간 지능을 모방, 연장 및 확장하고, 환경을 인식하며, 지식을 습득하고, 지식을 사용하여 최상의 결과를 얻는이론, 방법, 기술 및 응용 시스템이다. 인공 지능 소프트웨어 기술에는 주로 컴퓨터 시각 기술, 언어 처리 기술, 자연어 처리 기술 및 머신 러닝/딥 러 닝 등 몇 가지 큰 방향이 포함된다. 본 개시의 실시예는 주로 컴퓨터 시각 기술에 관한 것이다. 그 중 본 개시에 언급된 디바이스의 자세 추정 기술에 있어서, 디바이스의 자세 추정의 구현은 일반적으로 SLAM(simultaneous localization and mapping, 동시 로컬화 및 매핑)에 의해 구현된다. SLAM을 처리하는 문제는 로봇을 미지의 환경 중 미지의 위치에 배치하고 로봇을 이동시키면서 단계적으로 해당 환경의 완전한 맵을 그릴 수 있는지 여부로 설명될 수 있다. 완전한 맵(a consistent map)은 장애물 없이 영역 내로 행진하여 진입할 수 있는 각 구석을 의미한다. 구체적으로, SLAM은 다양한 센서(예를 들어 라이다(LiDAR), 카메라(Camera), 관성 측정 장치(IMU), GPS(Global Positioning System), 깊이 센서(Kinect) 등)의 입력을 캡쳐함으로써, 실시간으로 자세를 추정하는 동시에 3차 원 장면 또는 맵을 구축할 수 있다. 이와 같은 SLAM 기술은 자율주행, 로봇 내비게이션, 증강현실 분야에서 널리 활용될 수 있다. 여기에서 카메라(Camera)는 보다 풍부한 질감 정보를 얻을 수 있으며, 거리, 건축물에 의한 차단 등에 영향을 받지 않기 때문에 SLAM 시스템에서 널리 사용될 수 있다. SLAM 기술에서 두 이미지(프레임 이미지일 수 있음) 간의 데이터 관련성이 검색되는데, 이는 SLAM 시스템 카메 라 추적의 정확도와 관련이 있으며, SLAM 시스템에서 추적의 견고성과도 관련이 있다. 관련 기술에 있어서, SLAM 시스템은 종래의 광학 흐름법과 특징점법을 통해 추적을 수행한다. SLAM 시스템에서 는 종종 특징점의 표현 성능에 의해 제한되어, 하나의 특징점의 장시간 추적(long term tracking)이 복수의 단 시간 추적(short term tracking)으로 분할되는 결과를 초래할 수 있다. 이 경우, 이미지 프레임 간의 데이터 관 련성을 정확하게 검색할 수 없어, SLAM 시스템의 안정성과 정확도에 영향을 미칠 수 있다. 상기 기술적 문제를 해결하기 위해, 본 개시는 디바이스의 자세 추정 방법을 제공한다. 본 개시의 실시예들에 따른 디바이스의 자세 추정 방법은 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 통해 이미지 프레임 간의 데이터 관련 정보를 정확하게 검색할 수 있다. 따라서, 본 개시의 실시예들에 따른 디바이스의 자세 추정 방법은 이미지 프레임 추적의 견고성을 개선하고, 자세 추정의 정확도와 계산 속도를 향상시키는 데 도움이 된 다. 또한 본 개시는 이미지 검색 기술을 SLAM 시스템에 적용하여 자세 추정의 정확도를 향상시킬 수 있다. 여기에서 이미지 검색 기술은 어느 두 이미지 간의 유사도를 계산함으로써 가장 유사한 이미지를 검색하는 것을 의미할 수 있다. 그러나 관련 기술에서 이미지 검색 기술은 종종 전역 특징만 이용해 검색하거나, 국소 특징을 이용해 기하 검증 을 수행할 수 있다. 이 때, 전역 특징만을 이용하는 이미지 검색 기술은 정확도가 비교적 낮고, 국소 특징을 이 용하는 이미지 검색 기술은 시간 복잡도가 비교적 높을 수 있다. 상기 기술적 문제를 해결하고, 전역 특징 또는 국소 특징의 표현 성능을 향상시키기 위해, 본 개시는 전역 특징 과 국소 특징의 공동 학습에 기반한 방법을 더 채택하여 획득한 이미지 특징 추출 모델에 의해 추출된 현재 프 레임 중의 전역 특징과 국소 특징을 학습함으로써, 키 프레임 세트 중 디바이스에 의해 수집된 현재 프레임의 유사 키 프레임을 획득하는 정확도를 향상시킬 수 있다. 또한 종래의 데이터 세트는 종종 이미지 레벨의 주석만 있어 전역 특징의 학습에만 사용할 수 있었다. 국소 특 징 대응 관계에 대한 주석이 있는 데이터 세트의 경우, 종종 주석 비용 및 데이터 획득의 난이도에 제한을 받아 데이터 세트가 종종 비교적 작을 수 있었다. 즉, 종래의 방법은 전역 특징과 국소 특징 공동 학습 시 데이터 세 트에 대한 요건을 해결할 수 없었다. 따라서, 데이터 세트의 각도 전환에서 기술적 과제를 해결하는 핵심은 국소 특징 학습에 사용할 수 있는 이미지 쌍을 어떻게 생성하는지에 있다. 여기에서 이미지쌍은 이미지쌍 간에 픽셀쌍 픽셀의 대응 관계가 존재하고, 이미지쌍 및 그에 대응하는 국소 특징쌍 간에 충분한 차이가 있다는 특징이 있다. 종래 기술에서 국소 특징의 학습의 경우 일반적으로 사전에 계산하여 획득한 이미지쌍을 사용하였다. 상기 기술적 문제를 해결하기 위해, 본 개시는 제안하는 이미지 특징 추출 모델의 학습 방법을 기반으로, 공액 랜덤 회전 절첩 알고리즘을 제공할 수 있다. 제공하는 공액 랜덤 회전 절첩 알고리즘은 이미지 레벨 주석이 있 는 데이터 세트 상에서, 전역 특징과 국소 특징 공동 학습에 필요한 전역 이미지와 국소 이미지 쌍을 동시에 제 공할 수 있다 이를 통해, 본 개시의 실시예들은 이미지 레벨 주석만 있는 데이터 세트 상에서 전역 특징과 국소 특징 공동 학습의 효율을 향상시킬 수 있다. 본 개시의 목적, 기술적 해결 방법 및 장점을 보다 명확하게 설명하기 위해, 이하에서는 구체적인 실시예와 첨 부 도면을 참고하여 본 출원의 각 선택적 실시 방식 및 본 개시의 실시예의 기술적 해결 방법으로 어떻게 상기 기술적 과제를 해결하는지 상세하게 설명한다. 이하에서는 몇 가지 구체적인 실시예를 서로 결합할 수 있으며, 동일 또는 유사한 개념이나 과정에 대해 특정 실시예에서 장황하게 설명하지 않기로 한다. 이하에서는 첨부 도면을 참고하여 본 개시의 실시예를 설명한다. 이하에서는 도 1, 도 2 및 도 3을 참고하여 디바이스의 자세 추정 방법을 설명한다. 일 실시예에 있어서, 도 1에 도시된 바와 같이, 본 개시의 실시예에서 제공하는 디바이스의 자세 추정 방법은 하기 단계 S101 내지 단계 S103을 포함할 수 있다. 단계 S101에서, 디바이스의 자세 추정 방법은 키 프레임 세트에서 디바이스가 수집한 현재 프레임의 유사 키 프 레임을 획득한다. 구체적으로, 디바이스는 카메라, 이동 촬영 디바이스 등일 수 있다. 카메라는 청소 로봇, 웨어러블 디바이스 등 과 같은 이동 디바이스 상에 장착할 수도 있다. 여기에서 디바이스가 수집하는 현재 프레임은 디바이스가 실시간 수집하는 이미지 데이터일 수 있다. 예를 들어, 현재 프레임은 청소 로봇이 이동하면서 촬영하는 이미지 데이터일 수 있다. 여기에서, 키 프레임 세트에서 자세 추정을 수행하는 히스토리 데이터가 생성하는 복수의 키 프레임을 포함할 수 있다. 키 프레임 세트는 SLAM 기술을 채택하여 구축할 수 있다. 구체적으로 키 프레임 세트는 다음 방식을 통해 구축 할 수 있다. 먼저 이미지 수집 디바이스의 입력 이미지(처리 과정은 현재 프레임과 이전 프레임으로 표현함)의 특징점을 수집 또는 추출할 수 있다. 다음으로, 현재 프레임과 이전 프레임 이미지 간에 추적된 특징점의 개수 가 업데이트되고, 키 프레임 세트에 포함된 키 프레임들이 업데이트될 수 있다. 선택적으로, 키 프레임 세트는 SLAM 시스템 중의 전역 맵(global map)(또는 '키 프레임 맵'이라고 지칭될 수 있 음)을 구성할 수 있다. 여기에서 도 4에 도시된 바와 같이, 키 프레임 세트 구축을 설명하기 전에, 먼저 입력 이미지의 특징점에 대한 추적을 구현하는 방법에 대해 설명한다. 구체적으로 하기 2가지 방법 중 어느 하나를 통해 수행할 수 있다. 방법 1. 현재 프레임과 이전 프레임(앞 프레임) 또는 참조 키 프레임 간의 특징점 매칭 기반의 추적: 입력 이미 지에 대해 ORB(Oriented FAST, 방향이 있는 FAST 키 포인트) 등 특징점과 대응하는 디스크립터(descriptor)를 추출하고, 이전 프레임 입력 이미지의 디스크립터와 비교하여 전후 두 프레임 간의 특징점 매칭 관계를 획득한 다. 여기에서 참조 키 프레임은 일반적으로 키 프레임 세트 중 타임 시퀀스 상에서 최신 키 프레임을 의미한다. 방법 2. 광학 흐름법 기반의 프레임 간 추적: 이전 프레임 이미지의 특징점을 통해, 광학 흐름법으로 현재 프레 임(입력 이미지 중 현재 처리 중인 이미지 프레임) 상에서 대응하는 특징점을 검색하고, 디스크립터를 통해 잘 못된 특징점 매칭을 선별하여 전후 두 프레임 간의 특징점 매칭 관계를 획득한다. 현재 프레임 상에서 획득한 매칭된 특징점이 설정된 임계값보다 적을 경우, 현재 프레임 중에서 키 포인트와 디 스크립터를 다시 추출한다. 여기에서 SLAM 시스템 처리에서, 특징점은 키 포인트와 디스크립터를 포함할 수 있다. 이 때, 키 포인트는 이미 지에서 특징점의 위치를 의미하며, 디스크립터는 키 포인트의 방향과 주변 픽셀 정보를 의미할 수 있다. 구체적으로, 전후 두 프레임 간의 추적 상태 비교를 통해, 현재 프레임을 키 프레임으로 사용할지 여부를 확정 한다. 현재 프레임을 키 프레임으로 사용할 경우 현재 이미지는 키 프레임 세트에 추가되어 후술하는 광속 조정 법(bundle adjustment), 및 루프 클로저 검출(loop closure detection)과 리포지셔닝 모듈(repositioning module)에 사용될 수 있다. 전후 두 프레임 간의 추적 상태를 판단할 때, 현재 프레임에서 추적된 특징점 개수 및 새로 추출된 특징점(현재 프레임 상에서 획득한 매칭된 특징점이 설정된 임계값보다 적은 경우, 현재 프레임에서 새로 추출한 특징점)의 개수를 비교하여, 추적한 특징점 개수가 주어진 수치 미만이거나 새로 추출한 특징점 개수가 주어진 수치를 초 과할 경우, 현재 프레임이 키 프레임 세트 중의 키 프레임으로 사용될 수 있다. 선택적으로, 키 프레임 세트에 포함된 키 프레임은 획득한 입력 데이터에 따라 실시간 업데이트될 수 있다. 현 재 프레임을 키 프레임으로 사용하는 경우, 현재 프레임을 키 프레임 세트에 저장한다. 구체적으로, 유사 키 프레임은 현재 프레임과 유사성을 갖는 키 프레임을 의미할 수 있다. 이는 현재 프레임을 기반으로 키 프레임 세트에서 이미지 검색을 수행하여, 유사도가 비교적 높은 키 프레임을 획득하여 현재 프레 임의 유사 키 프레임으로 사용할 수 있다. 유사 키 프레임은 한 프레임의 이미지 프레임에 한정되지 않으며 복 수 프레임의 이미지 프레임일 수도 있다. 단계 S102에서, 디바이스의 자세 추정 방법은 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이터 관련 정보를 획득할 수 있다. 구체적으로, 디바이스의 자세 추정 방법은 현재 프레임과 유사 키 프레임을 획득한 후, 현재 프레임과 각 유사 키 프레임의 특징을 각각 추출하고, 추출하여 획득한 특징을 기반으로 특징 매칭을 수행하여 현재 프레임과 유 사 키 프레임 간의 특징 매칭 관계를 확정할 수 있다. 선택적으로, 추출한 특징은 점, 선, 면 등의 특징일 수 있으며, 이에 한정되는 것은 아니다. 여기에서 특징점 추출 시, 추출한 키 포인트와 디스크립터를 포함되며. 이를 기반으로 특징 매칭은 키 포인트 매칭을 포함될 수 있다. 구체적으로, 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로 이미지 프레임 간의 데이터 관련 정보를 획득하는 경우, 각 이미지 프레임에서 동일한 특징을 기반으로 합칠 수 있으며, 합친 특징을 기반으로 이미지 프레임 간의 데이터 관련 정보를 확정할 수 있다. 단계 S103에서, 디바이스의 자세 추정 방법은 데이터 관련 정보를 기반으로 상기 디바이스의 자세를 획득할 수 있다. 구체적으로, 디바이스의 자세 추정 방법은 데이터 관련 정보를 획득한 후, 광속 조정법 등에 따라 데이터 관련 정보를 기반으로 디바이스의 자세를 계산하여 더욱 정확한 자세 결과를 획득할 수 있다. 이하에서는 도 2 및 도 3을 참고하여, 키 프레임 세트에서 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하는 구체적인 과정을 설명한다. 일 실시예에 있어서, 단계 S101의 키 프레임 세트에서 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득 하는 단계는 하기 단계 A1 및 단계 A2 중 어느 하나의 단계를 포함할 수 있다. 단계 A1: 현재 프레임의 전역 특징을 추출하고, 전역 특징을 기반으로 키 프레임 세트에서 현재 프레임의 유사 키 프레임을 획득할 수 있다. 구체적으로 현재 프레임의 전역 특징 추출을 통해 전역 추출에서 이미지 검색을 수행할 수 있다. 키 프레임 세트는 복수의 키 프레임을 포함할 수 있다. 단계 A1을 실시할 때, 전역 특징을 통해 현재 프레임과 키 프레임 세트 중 각 키 프레임의 유사도를 계산할 수 있으며, 계산된 유사도를 기반으로 유사도가 비교적 높 은 키 프레임을 현재 프레임의 유사 키 프레임으로 사용할 수 있다. 단계 A2: 현재 프레임의 전역 특징을 추출하고, 전역 특징을 기반으로 키 프레임 세트 중 각 키 프레임과 현재 프레임의 제1 유사도를 확정하고; 현재 프레임의 국소 특징을 추출하고, 국소 특징을 기반으로 제1 유사도를 업 데이트하여, 키 프레임 세트 중 각 키 프레임과 현재 프레임의 제2 유사도를 획득하고; 유사 키 프레임을 기반으로 현재 프레임의 유사 키 프레임을 획득할 수 있다. 여기에서 전역 특징을 기반으로 키 프레임 세트에서 각 키 프레임과 현재 프레임의 제1 유사도를 확정하는 과정 은 전역 특징을 기반으로 키 프레임 세트에서 이미지 검색의 과정을 수행하는 것으로 이해할 수 있다. 또한 키 프레임은 제1 유사도를 기반으로 순서 배열될 수도 있다. 여기에서 현재 프레임의 국소 특징을 추출하고 국소 특징을 기반으로 제1 유사도를 업데이트하여 키 프레임 세 트 중 각 키 프레임과 현재 프레임의 제2 유사도를 획득하는 과정은 국소 특징을 기반으로 제1 유사도에 대해 기하 검증을 수행하는 과정으로 이해할 수 있다. 선택적으로, 현재 프레임의 국소 특징점 주의력 점수를 추출하고, 나아가 국소 특징을 결합하여 제1 유사도에 대해 기하 검증을 수행할 수도 있다. 또한 기하 검증 결과를 기반으로 제1 유사도를 업데이트한 후 제2 유사도 를 획득할 수 있다. 여기에서 기하 검증의 과정은 하기 과정을 포함한다. 즉, 국소 디스크립터(국소 특징) 및 각 국소 디스크립터의 점수(국소 특징점 주의력 점수도를 통해 알 수 있음)를 추출하여 획득한 후, 점수가 가장 큰 복수의 국소 디스 크립터를 선택하고, 현재 프레임 상에서 이들의 위치를 통해 대응하는 인지 필드(perception field)의 중심을 계산하여 국소 디스크립터에 대응하는 특징점의 위치(키 포인트)로 사용한다. 상기 위치를 기반으로 현재 프레 임과 키 프레임의 유사도를 확정하며 제1 유사도를 업데이트한다. 여기에서 제2 유사도를 기반으로 현재 프레임의 유사 키 프레임을 획득할 때, 제2 유사도를 기반으로 유사도가 가장 높은 키 프레임을 취하여 유사 키 프레임(공통 뷰(common-view) 프레임이라고 칭하기도 함)으로 사용할 수 있다. 제2 유사도를 기반으로 각 키 프레임에 대해 유사도 내림차순 배열을 수행하고, 앞에 배열된 N프레임 키 프레임 을 유사 키 프레임으로 사용할 수도 있다. 여기에서 전역 특징은 이미지의 전체 속성을 의미할 수 있다. 일반적으로 전역 특징의 인지 필드는 전체 프레임 이미지일 수 있다. 전체 프레임 이미지는 하나의 벡터로 표시되고 빛 조사, 시야 변화 등에 대해 우수한 불변성 을 가지며 계산량이 적고 저장 공간이 작을 수 있다. 여기에서 국소 특징은 이미지 국소 영역으로부터 추출한 특징일 수 있다. 일반적으로 국소 특징의 인지 필드는 전체 프레임 이미지의 국소 영역일 수 있다. 이는 빛 조사, 시야 변화의 영향을 받기 쉬우나, 전체 프레임 이미 지가 국소 특징에서 기술될 경우, 국소 검증 가능성은 그에 대응하는 위치와 함께 기하 검증을 수행할 수 있으 며, 종종 비교적 강한 간섭 방지 능력을 가지고 표현 성능이 비교적 우수하나, 계산량이 많고 저장 공간이 클 수 있다. 구체적으로, 전역 특징을 기반으로 이미지 검색을 수행할 수 있다. 예를 들어 현재 프레임을 주어진 이미지로 사용하며, SLAM 시스템에서 이미 구축된 키 프레임 세트에 포함된 각 이미지 프레임(키 프레임)에서 주어진 이 미지와 유사도가 비교적 높은 이미지 프레임을 검색할 수 있다. 이를 기반으로 국소 특징과 국소 특징점 주의력 점수도를 기반으로 이미지 검색 과정 중 획득한 유사도에 대해 기하 검증을 수행할 수 있다. 따라서, 기하 검증의 결과를 기반으로 키 프레임 세트에서 유사도가 비교적 높은 몇몇 키 프레임을 유사 키 프 레임으로 취하고, 주어진 이미지(현재 프레임)와 유사 키 프레임 간의 매칭 관계를 기반으로 이미지 프레임 간 의 데이터 관련 정보를 확정할 수 있다. 이하에서는 도 2 및 도 3을 참고하여 어떻게 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로 이 미지 프레임 간의 데이터 관련 정보를 획득하는지에 대한 구체적인 과정을 설명한다. 일 실시예에 있어서, 단계 S102의 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레 임 간의 데이터 관련 정보를 획득하는 단계는 하기 단계 B1 및 B2를 포함할 수 있다. 단계 B1: 현재 프레임에 대해 프레임 간 특징 매칭을 수행하여, 이미지 프레임 간의 제1 데이터 관련 정보를 획 득할 수 있다. 여기에서 현재 프레임에 대해 프레임 간 특징 매칭을 수행하는 방법은 단계 S101에서 입력 이미지의 특징점 추 적 방법을 참고하여 구현할 수 있다. 예를 들어, 특징점 추적 방법은 현재 프레임과 이전 프레임(앞 프레임) 또는 참조 키 프레임 간의 특징점 매칭 기반의 추적 방법 또는 광학 흐름법의 프레임 간 추적 방법을 포함할 수 있다. 현재 프레임에 대해 프레임 간 특징 매칭을 수행한 후, 현재 프레임과 키 프레임 세트 중 키 프레임의 특징 매 칭 관계를 확정하고, 나아가 상기 특징 매칭 관계를 기반으로 이미지 프레임 간의 제1 데이터 관련 정보를 획득 할 수 있다. 구체적으로, 도 2 및 도 3에 도시된 바와 같이, 최신 입력된 복수의 프레임 간의 특징점 매칭 관계에 따라, 현 재 프레임과 키 프레임 세트 중 모든 키 프레임 간의 데이터 관련성을 구축할 수 있다. 광속 조정법을 통해 각 프레임에 대응하는 카메라 자세 및 특징점의 3D 좌표를 업데이트하고, 동시에 현재 프레 임의 디바이스 자세를 출력할 수도 있다. 단계 B2: 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 제1 데이터 관련 정보를 업데이트하 여, 이미지 프레임 간의 제2 데이터 관련 정보를 획득할 수 있다. 구체적으로, 도 2 및 도 3에 도시된 바와 같이, 단계 B1을 실행하는 과정에 있어서, 스레드(thread)를 통해 단 계 B2를 실행하고, 단계 B2를 통해 이미지 검색 기반의 비동기 추적 조작을 실행하여, 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 확정할 수 있다. 나아가, 상기 특징 매칭 관계를 기반으로 단계 B1 중 메인 프로 세스에서 프레임 간 시퀀스 추적을 실행하여 획득한 제1 데이터 관련 정보를 업데이트할 수 있다. 업데이트된 데이터 관련 정보는 이미지 프레임 간의 제2 데이터 관련 정보를 의미할 수 있다. 여기에서 특징 매칭 관계를 계산하는 과정은 다음 단계를 포함한다. 즉, 현재 프레임과 조회하여 획득한 유사 키 프레임 상의 특징점과 디스크립터를 추출하고, 각 특징점에 대응하는 깊이값을 통해 현재 프레임과 유사 키 프레임에 대응하는 3차원 점 클라우드를 획득할 수 있다. 3차원 점 클라우드, 대응하는 디바이스 자세와 디스크 립터를 통해 두 프레임 간의 특징점 매칭 관계를 계산할 수 있다. 선택적으로, 단계 B2에서 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 제1 데이터 관련 정 보를 업데이트하여, 이미지 프레임 간의 제2 데이터 관련 정보를 획득하는 단계는 하기 단계 C1 내지 C4를 포함 할 수 있다. 단계 C1: 현재 프레임에 대해 프레임 간 특징 매칭을 수행하여, 제1 데이터 관련 정보를 획득할 수 있다. 제1 데이터 관련 정보는 각 이미지 프레임의 특징 간의 매칭 관계를 포함할 수 있다. 단계 C2: 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 각 이미지 프레임의 특징이 동일 특 징인지 여부를 판단할 수 있다. 구체적으로, 현재 프레임과 각 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 두 이미지 프레임 상의 특징이 동일 특징인지 여부를 판단할 수 있다. 예를 들어, 현재 프레임 상의 특징 A와 유사 키 프레임 상의 특징 B가 두 프레임 간의 특징 매칭 관계를 통해 동일 특징으로 간주되면, 모든 이미지 프레임 상의 특징 A와 특징 B는 모두 동일 특징으로 간주될 수 있다. 단계 C3: 판단 결과를 기반으로 동일 특징을 합칠 수 있다. 구체적으로, 현재 프레임 상에서 하나의 특징과 유사 키 프레임 상에서 하나의 특징이 동일 특징에 속한다고 판 단되면, 상기 동일한 특징을 합쳐 각 분산 특징에 대한 추적 조작을 감소시킴으로써, 이미지 프레임 추적의 안 정성과 정확도를 향상시킬 수 있다. 구체적으로, 동일 특징을 합쳐 새로운 특징을 생성하는 동시에, 새로 생성된 특징은 원래의 이러한 동일하지 않 는 특징의 모든 정보를 포함하며, 이러한 원래 동일하지 않은 것으로 간주되는 리던던시(redundancy) 특징을 더 제거할 수 있다. 즉, 현재 프레임과 유사 키 프레임 상에서 추출하여 획득한 동일 특징은 합치고, 동일하지 않 은 특징은 제거함으로써, 이미지 프레임 추적의 안정성과 정확도를 향상시킬 수 있다. 단계 C4: 합친 특징을 기반으로, 제1 데이터 관련 정보를 업데이트하여 제2 데이터 관련 정보를 획득할 수 있다. 구체적으로, 단계 C4의 실행에는 하기 2가지 경우가 포함될 수 있다. 제1 경우: 도 2에 도시된 바와 같이, 합친 특징을 메인 프로세스에 피드백하고, 메인 프로세스 중 획득한 제1 데이터 관련 정보를 업데이트하여, 제2 데이터 관련 정보를 획득할 수 있다. 제2 경우: 도 3에 도시된 바와 같이, 합친 특징을 획득할 때, 메인 프로세스 중 준비된 제1 데이터 관련 정보를 획득하고, 스레드에서 제1 데이터 관련 정보에 대한 업데이트를 완료할 수 있다. 나아가 직접 제2 데이터 관련 정보를 메인 프로세스에 피드백하고, 메인 프로세스에서 직접 제2 데이터 관련 정보를 기반으로 디바이스의 자 세를 획득할 수 있다. 본 개시의 실시예에 있어서, 획득한 특징 매칭 관계에 따라, 2개의 매칭되는 특징에 대응하는 단시간 추적(또는 '단기 추적')을 하나의 장시간 추적(또는 '장기 추적')으로 복구하고(즉, 단계 C3에서 특징을 합치는 조작), 메 인 프로세스에 리턴하여 데이터 관련성을 추적할 수 있다. 메인 프로세스는 데이터 관련 정보를 업데이트할 수 있다. 여기에서 단시간 추적의 특징(현재 프레임과 유사 키 프레임 중 동일하지 않은 특징)이 동일 특징으로 다시 판단되어 장시간 추적의 특징으로 합쳐지기 때문에, 단시 간 추적의 특징은 리던던시 특징으로 간주되어 제거될 수 있다. 이를 기반으로 메인 프로세스는 다시 광속 조정 법에 따라 이미지 수집 디바이스 자세를 계산하고, 보다 정확한 자세 결과를 획득할 수 있다. 일 실시예에 있어서, 도 2 및 도 3에 도시된 바와 같이, 본 개시에서 제공하는 자세 추정 방법은 본 개시에서 제공하는 SLAM 시스템에 적용할 수 있다. 본 개시의 SLAM 시스템은 메인 프로세스에서 입력된 이미지에 대해 프 레임 간 시퀀스 추적을 수행할 수 있고, 스레드에서 이미지 검색 모델을 채택하여 입력 이미지에 대해 이미지 검색 기반의 비동기(non-coherent) 추적을 수행한다. 여기에서 이미지 검색 모델에는 하기 실시예에서 제공하는 이미지 특징 추출 모델이 포함되며, 상기 이미지 특징 추출 모델에서 입력된 이미지를 처리하여 전역 특징, 국 소 특징 및 국소 특징점 주의력 점수도를 획득할 수 있다. 스레드의 도입은 SLAM 시스템이 메인 프로세스의 영 향을 받지 않는 상황에서 유사도 키 프레임의 조회를 비동기로 수행하여, 장시간 추적의 특징을 복구하도록 할 수 있다. 따라서 SLAM 시스템의 정확도를 개선하는 동시에, 단시간 추적 기능을 제거하여 최적화 파라미터 수량 을 줄이고 계산 복잡도를 낮출 수 있다. 일 실시예에 있어서, 이미지 특징 추출 모델을 포함한 네트워크를 채택하여 현재 프레임의 유사 키 프레임을 획 득할 수 있다. 본 개시의 실시예에 있어서, 관련된 이미지 검색 기술 중 전역 특징에만 의존하여 수행하는 검색이 속도는 빠르 지만 정확도가 낮은 문제, 또는 국소 특징을 이용하여 수행하는 기하 검증이 정확도는 높지만 속도가 낮은 문제 를 해결하기 위해, 본 개시는 전역 특징과 국소 특징 공동 학습 방법을 제공한다(이미지 특징 추출 모델의 학습 방법). 이를 통해 이 둘이 모두 상호 간 학습에서 향상되고, 속도와 정확도 측면에서 모두 현재 최상의 성능에 도달할 수 있다. 상기 방법을 기반으로 학습하여 획득한 이미지 특징 추출 모델은 도 3에 도시된 스레드의 네트 워크에 적용할 수 있다. 이미지 검색 기술 중 언급한 이미지 특징의 추출, 이미지 특징 추출 모델의 학습에 있어서, 전역 특징 학습은 일반적으로 단일 이미지가 구성하는 데이터 세트만 필요하며, 국소 특징 학습은 쌍을 이루는 이미지 블록이 필 요할 수 있다. 따라서 국소 특징의 학습에는 어려움이 있을 수 있다. 하나의 네트워크 상에서 전역 특징과 국소 특징이 공동 학습을 수행할 수 있도록 만들기 위해서는, 네트워크 구 조 선택 및 데이터 생성의 문제를 해결해야 한다. 전역 특징 학습과 국소 특징 학습 입력이 상이한 점, 국소 특징을 구축하는 데이터 세트는 쌍을 이루는 이미지 블록을 필요로 하는 문제를 해결하기 위해, 본 개시는 공액 랜덤 회전 절첩 알고리즘(Conjugate Random RF: Conjugate Random Rotation Flip)을 제시한다. 본 개시는 이미지만 구성하는 데이터 세트에서, 입력 이미지에 대해 공액 랜덤 회전 절첩을 수행함으로써, 전역 특징 학습에 필요한 입력 이미지를 획득하는 동시에, 국소 특 징 학습을 위한 쌍을 이루는 이미지 블록도 구축할 수 있다. 또한, 본 개시는 추가적인 학습 데이터 필요 없이, 전역 특징 학습과 국소 특징 학습에 필요한 데이터 세트를 구축할 수 있다. 이하의 본 개시의 실시예에서 제공하는 이미지 특징 추출 모델의 학습 방법에 있어서, 이미지 특징 추출 모델은 도 5 및 도 6에 도시된 바와 같이, 학습 시 타깃 모델을 도입하였다. 이하에서는 본 개시에서 제공하는 학습 방 법의 각 단계를 설명하기 전에, 먼저 이미지 특징 추출 모델(딥 네트워크(deep network)일 수 있음)의 아키텍처 에 대해 설명한다. 구체적으로, 도 5에 도시된 바와 같이, 학습 시, 이미지 특징 추출 모델(온라인 모델, 또는 온라인 콘볼루션 신 경망이라 부르기도 함)에는 3개의 브랜치가 포함될 수 있다. 이는 각각 국소 특징 브랜치(Local Feature Branch), 전역 특징 브랜치(Global Feature Branch) 및 자체 감독 브랜치(Pixel-wised Self-Supervised Learning Branch, '자기 주도 감독 브랜치' 또는 '픽셀 와이즈드 자체 감독 학습 브랜치'로 지칭될 수 있음)이 다. 여기에서 국소 특징 브랜치는 제1 이미지(앵커 포인트 이미지로 칭하기도 함)를 처리하여 전역 특징을 획득 하는 데 사용될 수 있다. 국소 특징 브랜치는 제1 이미지를 처리하여 국소 특징점 주의력 점수도를 획득하는 데 사용될 수 있다. 자체 감독 브랜치는 도입한 타깃 모델(또는 타깃 콘볼루션 신경망으로도 칭함)과 결합하여 국 소 특징을 기반으로 추출한 국소 특징의 학습을 수행하는 데 사용될 수 있다. 선택적으로, 전역 특징 브랜치에서, 확장된 평균값 풀링층(GeM)과 화이트닝층을 채택하여 전역 특징 학습의 백 본망을 구성할 수 있다. 여기에서 화이트닝층은 학습 바이어스을 갖는 완전연결층이다. 본 개시의 실시예에 있어서, 특징도를 백본망의 출력으로 사용할 수 있다. 이를 기반으로 주어진 이미지, 전역 특징 g에 대해 전체 이미지를 하기 수학식 1과"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "같이 요약할 수 있다. 수학식 1"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "상기 수학식 1에 있어서, 는 특징도 D에서 하나의 특징의 위치(h, w)를 나타낸다. p는 GeM 풀 링층의 하이퍼파라미터이다. 선택적으로, 도 5에 도시된 바와 같이, 국소 특징 브랜치에서, 중간층의 출력을 잔차 네트워크(ResNet) 모델의 입력으로 사용할 수 있다. 이는 주의력 모듈(attention module)을 통해 추출한 국소 특징 중 어느 특징이 관심 있는 대상과 구분되는지 예측하는 것을 목적으로 한다. 주의력 모듈은 국소 특징도(L) 상에서 각 특징의 점수를 예측하고, 이에 대응하여 국소 특징점 주의력 점수를 출력할 수 있다. 이미지 특징 추출 모델의 학습 후, 이미지 검색의 추리 과정에서, 최고 주의력 점수를 갖는 국소 특징 및 이에 대응하는 인지 필드 중심만 선택하여 기하학적 검증을 위한 키 포인트 위치로 사용할 수 있다. 따라서 주의력 모듈은 대략적인 키 포인트 검출기로 간주될 수 있다. 학습 과정에서 주의력 모듈이 출력하는 주의력 점수도 A는 자체 감독 학습 브랜치 중 음성 샘플 큐(sample queue)의 업데이트를 지도하는 데 사용될 수 있다. 이에 대해서는 후술할 실시예에서 구체적으로 설명하도록 한 다. 선택적으로, 자체 감독 브랜치를 통해 전역 특징과 국소 특징을 하나의 모델에 통합할 수 있다. 자체 감독 브랜 치는 국소 특징의 성능을 개선하고, 기울기를 백본망에 역전파하여 전역 특징의 성능을 향상시킬 수 있다. 여기에서 도 5에 도시된 바와 같이, 자체 감독 브랜치는 온라인 콘볼루션 신경망과 타깃 콘볼루션 신경망으로 구축될 수 있다. 두 네트워크는 동일한 체계 구조를 공유하며 상이한 네트워크를 가질 수 있다. 온라인 콘볼루션 신경망과 타깃 콘볼루션 신경망은 인코더(encoder)와 프로젝션 헤드(projection head)를 포함 할 수 있다. 인코더는 최종 출력된 것이 국소 특징 L인 국소 특징 브랜치의 레이어(또는 '층')로 구성되고, 프 로젝션 헤드는 2개의 완전히 연결된 레이어으로 구성된 다층 퍼셉트론(multilayer perceptron, MLP)일 수 있다. 프로젝션 헤드는 특징 공간 중의 국소 특징 을 임베디드 공간에 투영하여 임베디드 특징 을 형성할 수 있다. 자체 감독 학습(또는 '자기 주도 학습')에서 주어진 이미지 I에 대해, 데이터 증강 모듈은 이미지 I로부터 조회 이미지(제1 이미지 또는 앵커 포인트 이미지로 칭하기도 함) Iq와 키 이미지(제2 이미지 또는 양성 샘플 이미지 로 칭하기도 함) Ik를 샘플링할 수 있다. 조회 이미지 Iq는 온라인 콘볼루션 신경망(온라인 모델)에 입력되고, 키 이미지 Ik는 타깃 콘볼루션 신경망(타깃 모델)에 입력될 수 있다. 이 때, 임베디드 특징 은 온 라인 모델의 출력을 나타내고, 임베디드 특징 은 타깃 모델의 출력을 나타낸다. 본 개시의 실시예는, , 를 각 특징도 중 위치(h, w)의 임베디드 특징으로 사용하며, 양성 샘플(positive) 국소 특징쌍 을 구축하여 자체 감독 학습에 사용할 수 있다. 구체적으로, 본 개시의 실시예는 신규한 데이터 증강 방법 공액 랜덤 회전 절첩 알고리즘을 제안하여 이미지쌍 (국소 특징쌍)의 구축을 구현할 수 있다. 여기에서 도 5에 도시된 바와 같이, 온라인 모델에서만 학습 과정에서 역전파를 통해 업데이트를 수행하고, 타 깃 모델은 모멘텀 업데이트 방법을 통해 온라인 모델의 도움 하에서 업데이트를 수행한다. 형식적으로, 온라인 모델 의 파라미터는 로 표현되고, 타깃 모델 의 파라미터는 로 표현될 수 있다. 파라미터 는 다음 관계 를 통해 업데이트될 수 있다. 여기에서 모멘텀 계수는 이 고, m=0은 온라인 모델과 타깃 모델이 동일한 파라미터를 공유함을 나타낼 수 있다. 그러나 국소 특징 Lq의 기 울기만 백본망에 역전파될 수 있다. 일 실시예에 있어서, 본 개시에서 제공하는 이미지 특징 추출 모델은 하기 방법을 통해 학습하여 획득한 것이다. 상기 방법은 하기 단계 D1 내지 D2를 포함할 수 있다. 단계 D1: 제1 이미지 및 제1 이미지를 회전 절첩한 제2 이미지를 획득할 수 있다. 구체적으로, 제1 이미지는 학습 이미지를 처리한 후 획득한 이미지일 수 있다. 학습 이미지에 대응하는 학습 데 이터 세트에서 각 이미지는 대응하는 이미지 레벨의 주석을 포함할 수 있다. 일 실시예에 있어서, 학습 이미지는 이미지 특징 추출 모델을 학습하기 위한 학습 샘플 데이터이며, 복수 개 이 미지, 또는 복수 개 프레임의 이미지를 포함할 수 있다. 여기에서 제1 이미지 앵커(Anchor)는 각 학습 이미지에 대해 리사이징(resizing) 처리를 수행하여 획득한 이미 지일 수 있다. 예를 들어, 리사이징 처리는 크롭핑(cropping), 스케일링(scaling) 등 처리 조작일 수 있다. 제2 이미지 positive는 각 제1 이미지에 대해 회전 절첩을 수행하여 획득한 이미지일 수 있다. 제1 이미지와 제 2 이미지는 일대일 대응 관계를 갖는다. 선택적으로, 제1 이미지와 제2 이미지를 획득한 후, 제1 이미지와 제2 이미지에 대해 데이터 증강을 수행할 수 도 있다. 데이터 증강은 랜덤 컬러 광도 변화, 랜덤 그레이 스케일 변화, 랜덤 가우시안 블러(Gaussian blur) 등을 포함할 수 있다. 이하에서는 학습 이미지를 기반으로 제1 이미지를 획득하는 구체적인 과정을 설명한다. 일 실시예에 있어서, 단계 D1에서 제1 이미지를 획득하는 단계는 하기 단계 D11 내지 D13을 포함할 수 있다. 단계 D11: 학습 이미지를 획득할 수 있다. 구체적으로, 학습 이미지는 이미지 특징 추출 모델 응용 장면을 기반으로 획득한 이미지 데이터일 수 있다. 예 를 들어 현재 청소 로봇에 적용할 경우, 학습 이미지는 다양한 가구 이미지일 수 있다. 단계 D12: 학습 이미지를 랜덤 크롭핑하여 크롭핑 이미지를 획득할 수 있다. 구체적으로, 단계 D11에서 획득한 학습 이미지의 크기가 단일하지 않은 점을 고려하여, 학습 이미지에 대해 랜 덤 크롭핑을 수행할 수 있다. 예를 들어 랜덤으로 400Х300의 크기 또는 224Х224의 크기에 따라 크롭핑을 실행 할 수 있다. 단계 D13: 소정의 이미지 크기를 기반으로 크롭핑 이미지를 재배치하여, 학습 이미지의 제1 이미지를 획득할 수 있다. 구체적으로, 재배치는 크롭핑 이미지에 대해 스케일링 처리를 수행하는 것으로 이해할 수 있다. 예를 들어, 상 이한 크기의 크롭핑 이미지를 소정의 이미지 크기에 따라 확대 또는 축소 처리를 수행한다. 확대 또는 축소 처 리는 등비율일 수 있으며, 압축된 것일 수도 있다. 이하에서는 도 8을 참고하여, 제1 이미지를 기반으로 회전 절첩 처리를 수행하여 제2 이미지를 획득하는 구체적 인 과정을 상세하게 설명한다. 일 실시예에 있어서, 단계 D1에서 제1 이미지에 대해 회전 절첩을 수행하여 제2 이미지를 획득하는 단계는 하기 단계 D111 내지 단계 D112 중 어느 하나의 단계를 포함할 수 있다. 단계 D111: 제1 이미지를 회전시켜, 랜덤 각도로 회전된 대응하는 제2 이미지를 획득할 수 있다. 구체적으로 도 8에 도시된 바와 같이, 랜덤 회전(Random Rotation)은 중심을 감싸며 이미지 또는 특징도를 회전 시키는 데 사용될 수 있다. 회전하는 시계방향 회전각도에 따라, 4개의 상이한 회전각도가 존재하며, 이는 각각 0°, 90°, 180°, 270°일 수 있다. 각종 유형에는 모두 하나의 대응하는 코드 0, 90, 180, 270이 있다. 각 코드에는 모두 하나의 공액 코드 0, 270, 180, 90이 있다. 여기에서 각종 유형에 대응하는 전환 공식은 (x, y), (w-1-y, x), (w-1-x, w-y), (y, w-1-x)일 수 있다. 이 때, w는 회전각도를 나타내며, x는 이미지에서 특징점의 횡축 방향 위치를 나타내고, y는 이미지에서 특징점의 종축 방향 위치를 나타낸다. 하나의 정방 행렬 또는 정사각 행렬(M)이 제공되면 회전 연산은 M을 M'로 변환하고, 공액 회전 연산은 M'를 원 래 행렬 M으로 변환할 수 있다. 단계 D112: 제1 이미지를 절첩하여, 랜덤축으로 절첩된 대응하는 제2 이미지를 획득할 수 있다. 구체적으로, 도 8에 도시된 바와 같이, 랜덤 플립(랜덤 절첩, Random Flip)은 플립 방향에 따라 이미지 또는 특 징도를 플립시키는 데 사용될 수 있다. 플립 방향에 따라 5가지의 상이한 플립이 있을 수 있다. 예를 들어, 무(none) 플립, 수평 플립, 수직 플립, 주 요 대각선 플립, 보조 대각선 플립이 있을 수 있다. 각 유형에는 모두 하나의 대응하는 코드 X, H, V, P, Q가 있다. 각 코드에는 모두 하나의 공액 코드 X, H, V, P, Q가 있다. 여기에서 각종 유형에 대응하는 전환 공식은 (x, y), (w-1-x, y), (x, w-1-y), (w-1-y, w-1-x), (y, x)일 수 있다. 여기에서 w는 플립각도를 나타내며, x는 이미지에서 특징점의 횡축 방향 위치를 나타내고, y는 이미지에 서 특징점의 종축 방향 위치를 나타낸다. 정방 행렬 또는 정사각 행렬(M)이 제공되면 플립 연산은 M을 M'로 변환하고, 그 공액 플립 연산은 M'를 원래 행 렬 M으로 변환할 수 있다. 일 실시예에 있어서, 랜덤 회전과 랜덤 절첩으로부터의 랜덤 조합에서, 총 12가지 랜덤 회전 절첩 알고리즘을 얻을 수 있다. 즉, 본 개시에서는 제1 이미지에 대해 랜덤 회전 또는 랜덤 절첩만 수행할 수 있도록 한정하지 않으며, 제1 이 미지에 대해 랜덤 회전 및 랜덤 절첩을 수행할 수 있다. 본 개시의 실시예에 있어서, 제1 이미지에 대해 랜덤 회전 절첩(랜덤 회전과 랜덤 절첩 중 적어도 하나를 포 함)을 수행하여 제2 이미지를 획득하며, 이는 학습 샘플의 다양성을 향상시키고 모델 학습 특징 표현의 성능을 향상시킬 수 있다. 단계 D2: 제1 이미지와 제2 이미지를 기반으로, 이미지 특징 추출 모델에서 추출한 전역 특징과 국소 특징을 통 해, 이미지 특징 추출 모델에 대해 공동 학습을 수행하여, 학습된 이미지 특징 추출 모델을 획득할 수 있다. 구체적으로, 하나의 이미지 특징 추출 모델을 채택하여 전역 특징과 국소 특징의 공동 학습을 수행한다. 학습된 이미지 특징 추출 모델은 전역 특징과 국소 특징을 동시에 추출할 수 있다. 공동 학습의 실시는 상호 학습 진행 에 도움이 되며, 전역 특징과 국소 특징의 표현 능력을 향상시킬 수 있다. 본 개시의 실시예에 있어서, 자체 감독 학습을 통해 전역 특징과 국소 특징 학습을 통합하는 방법을 제공하며, 이는 PULG(Unify Local Feature and Global Feature for Image Retrieval via Pixel-wised Self-Supervised Learning, 픽셀 와이즈드 자체 감독 학습 기반의 전역 특징과 국소 특징의 공동 학습) 방법이라고 지칭될 수 있 다. 전역 특징과 국소 특징의 추출은 하나의 모델에서 학습을 수행할 수 있으며, 상호 학습을 수행할 수 있다. 여기에서 본 개시에서 제안하는 PULG 방법은 국소 특징 상에서 자체 감독 학습을 보조 태스크로 사용할 수 있다. 이는 국소 특징의 표시를 개선하는 데에 목적이 있으며, 기울기를 백본망에 역전파하여 최종적으로 국소 특징의 학습으로부터 전역 특징의 이점을 얻을 수 있다. 일 실시예에 있어서, 단계 D2는 제1 이미지와 제2 이미지를 기반으로, 이미지 특징 추출 모델에서 추출한 전역 특징과 국소 특징을 통해, 이미지 특징 추출 모델에 대해 공동 학습을 수행하여, 학습된 이미지 특징 추출 모델 을 획득할 수 있는 것으로 이해할 수 있다. 구체적으로, 도 5 및 도 6에 도시된 바와 같이, 이미지 특징 추출 모델(온라인 모델로 칭하기도 함)은 학습 시 도입된 타깃(target) 모델을 더 결합하여 학습을 수행한다. 제1 이미지는 온라인 모델의 입력이고, 제2 이미지 는 타깃 모델의 입력일 수 있다. 즉, 이미지 특징 추출 모델을 입력한 학습 샘플 데이터에서 일대일 대응하는 제1 이미지와 제2 이미지를 각 회차 학습의 입력으로 사용한다. 구체적으로, 도 7에 도시된 바와 같이, 학습된 이미지 특징 추출 모델은 타깃 모델 매칭 처리가 필요 없다. 즉, 이미지를 입력한 후, 온라인 모델을 통해 전역 특징, 국소 특징 및 국소 특징점 주의력 점수도를 추출하여 획득 할 수 있다. 구체적으로, 단계 D2에서 이미지 특징 추출 모델에서 추출한 전역 특징과 국소 특징을 통해, 이미지 특징 추출 모델에 대해 공동 학습을 수행하는 단계는 하기 단계 E1 내지 단계 E4를 포함할 수 있다. 단계 E1: 이미지 특징 추출 모델을 통해 제1 이미지의 국소 특징과 전역 특징을 획득할 수 있다. 구체적으로, 온라인 콘볼루션 신경망(Online Convolutional Neural Networks, Online CNN)은 이미지 특징 추출 모델에 해당하며, 학습 과정에서 전역 특징 브랜치, 국소 특징 브랜치 및 자체 감독 브랜치에 걸쳐 있을 수 있 다(도 5에 도시). 전역 특징 브랜치의 경우, 제1 이미지는 온라인 콘볼루션 신경망 처리를 거쳐 전역 특징을 획득할 수 있다. 국소 특징 브랜치의 경우, 제1 이미지는 온라인 콘볼루션 신경망 처리를 거쳐 제1 이미지의 국소 특징도를 획득 한 후, 다층 퍼셉트론으로 구성되는 주의력 모델을 통해 국소 특징점 주의력 점수도를 생성하고, 국소 특징점 점수도와 제1 이미지의 국소 특징도를 가중합 풀링 처리하여 국소 집합 특징을 획득할 수 있다(손실 함수의 계 산에 적용 가능). 자체 감독 브랜치의 경우, 제1 이미지에 대한 온라인 콘볼루션 신경망 처리를 거쳐 제1 이미지의 국소 특징도를 획득할 수 있다. 상기 브랜치에서 다층 퍼셉트론이 더 구축되며, 제1 이미지의 국소 특징도는 다층 퍼셉트론을 통해 매핑을 수행하여 그 임베디드 특징을 획득할 수 있다. 단계 E2: 타깃 모델을 통해 제2 이미지의 국소 특징을 획득하고, 제2 이미지의 국소 특징에 대해 회전 절첩에 대응하는 공액 회전 절첩을 수행할 수 있다. 구체적으로, 타깃 콘볼루션 신경망(Target Convolutional Neural Networks, Target CNN)은 학습 과정에서 이미 지 특징 추출 모델의 학습을 돕기 위해 도입된 일부 네트워크 구조일 수 있다. 이는 학습 과정에서 자체 감독 브랜치에 적용될 수 있다(도 5에 도시). 자체 감독 브랜치의 경우, 제2 이미지에 대한 타깃 콘볼루션 신경망 처리를 거친 후 제2 이미지의 국소 특징도 를 획득할 수 있다. 상기 브랜치에서 다층 퍼셉트론이 더 구축될 수 있다. 제2 이미지의 국소 특징도는 다층 퍼 셉트론을 통해 매핑을 수행하여 그 임베디드 특징을 획득할 수 있다(제2 이미지의 국소 특징도). 구체적으로, 단계 D1에서 제1 이미지가 회전 절첩된 후 제2 이미지를 획득하는 처리에 상응하여, 단계 E2에서는 제2 이미지의 국소 특징에 대해 공액 회전 절첩 처리를 수행하여, 공액 회전 절첩된 제2 이미지의 국소 특징을획득할 수 있다. 여기에서 공액 회전 절첩 처리는 비랜덤 처리이다. 구체적으로 단계 D1에서 랜덤 회전 절첩 시 채택하는 방식에 따라 공액 처리를 수행할 수 있다. 예를 들어 랜덤 회전 절첩이 회전에 대응할 경우, 제2 이미지의 국소 특징에 대해 공액 회전을 수행할 수 있다. 이하에서는 도 8을 참고하여, 제2 이미지의 국소 특징을 기반으로 공액 회전 절첩 처리를 수행하여 공액 회전 절첩된 제2 이미지의 국소 특징을 획득하는 구체적인 과정에 대해 설명한다. 일 실시예에 있어서, 단계 E2에서 제2 이미지의 국소 특징에 대해 회전 절첩에 대응하는 공액 회전 절첩을 수행 하는 단계는, 제1 이미지에 대한 회전 절첩 처리를 기반으로, 제2 이미지의 국소 특징에 대해 공액 회전 절첩을 수행하여, 제1 이미지의 국소 특징과 일대일 대응하는 제2 국소 특징을 획득하는 단계를 포함할 수 있다. 구체적으로, 단계 D1에서 제1 이미지 상에서 실행하는 랜덤 회전 절첩(Random RF: Random Rotation Flip) 조작 의 경우, 본 실시예에서는 제2 이미지의 국소 특징 상에서 그에 대응하는 공액 랜덤 회전 절첩(Random RF)을 실 행한다(제2 이미지의 국소 특징이 소재한 특징도 상에서 실행하는 것으로 이해할 수 있음). 예를 들어, 랜덤 회전 절첩은 이미지 A를 이미지 B로 변환할 수 있으며, 그에 대응하는 공액 랜덤 회전 절첩은 이미지 B를 이미지 A로 되돌릴 수 있다. 단계 D1과 단계 E2의 조작은 조회 특징을 포함하는 국소 특징도(제1 이미지의 국소 특징이 소재한 특징도이며, 앵커 포인트 국소 특징도로 칭하기도 함)와 키값 특징을 포함하는 국소 특징도(제2 이미지의 국소 특징이 소재 한 특징도이며, 양성 샘플 국소 특징도로 칭하기도 함) 간의 픽셀 대 픽셀의 대응 관계를 확보할 수 있다. 또한 1회 크롭핑을 통해, 충분한 다양성을 포함하는 양성 샘플 국소 이미지쌍과 양성 샘플 국소 특징쌍을 획득 할 수 있다. 양성 샘플쌍 간의 다양성은 네트워크가 학습 과정에서 충분히 큰 차이를 생성하도록 보장할 수 있다. 이러한 차 이는 본 개시의 실시예에서 비교 오차 손실 함수를 사용하여 네트워크를 감독하여, 백본망이 더 나은 성능을 학 습할 수 있도록 할 수 있다. 단계 E3: 제1 이미지의 국소 특징과 공액 회전 절첩된 제2 이미지의 국소 특징을 기반으로 국소 특징쌍을 획득 할 수 있다. 구체적으로, 도 5에 도시된 바와 같이, 제1 이미지의 국소 특징과 제2 이미지의 국소 특징 간의 일대일 대응 관 계를 기반으로, 국소 특징쌍을 구성할 수 있다. 상기 국소 특징쌍은 이미지 특징 추출 모델 중 국소 특징의 학 습 과정에 적용할 수 있다. 즉, 본 개시의 실시예는 타깃 콘볼루션 신경망을 도입하여 제2 이미지의 국소 특징을 추출하고, 제1 이미지의 국소 특징과 제2 이미지의 국소 특징을 결합함으로써, 국소 특징을 학습 추출하는 학습 샘플 데이터(국소 특징 쌍)를 획득하여, 국소 특징 추출 학습을 위한 학습 샘플 데이터를 추가적으로 획득하는 비용을 감소시킬 수 있 다. 선택적으로, 국소 특징쌍을 기반으로 손실 함수의 계산을 수행하여 이미지 특징 추출 모델의 네트워크 파라미터 를 업데이트할 수 있다. 일 실시예에 있어서, 자체 감독 브랜치는 각각 온라인 모델이 출력하는 제1 이미지의 국소 특징도와 타깃 모델 이 출력하는 제2 이미지의 국소 특징도에 대해 다층 퍼셉트론을 채택하여 매핑을 수행하며, 각각 대응하는 임베 디드 특징을 획득할 수 있다(국소 특징으로 구현될 수 있음). 또한, 자체 감독 브랜치는 제1 이미지의 국소 특 징도와 제2 이미지의 국소 특징도 간의 대응 관계를 기반으로 일대일 대응하는 국소 특징쌍을 획득할 수도 있다. 단계 E4: 국소 특징쌍과 전역 특징을 기반으로, 이미지 특징 추출 모델의 파라미터를 업데이트할 수 있다. 구체적으로, 도 5에 도시된 바와 같이, 전역 특징 브랜치는 전역 특징을 기반으로 오차 함수의 계산을 수행한다. 국소 특징 브랜치는 국소 특징점 주의력 점수도를 기반으로 오차 함수의 계산을 수행할 수 있다. 자 체 감독 브랜치는 국소 특징쌍(구체적으로 제1 이미지의 국소 특징과 제2 이미지의 국소 특징을 결합하여 획득 하는 국소 특징쌍임)을 기반으로 오차 함수의 계산을 수행한다. 나아가 3개 오차를 기반으로 백홀을 수행하고, 네트워크 모델(온라인 모델과 타깃 모델)을 최적화할 수 있다. 여기에서 국소 특징 브랜치의 기울기(gradient)는 백본망으로 백홀되지 않는다. 본 개시에서 제시하는 공액 랜덤 회전 절첩 알고리즘은 각각 제1 이미지와 제2 이미지의 국소 특징에 적용되어 국소 특징쌍을 생성하며, 하나의 입력 이미지를 사용하여 국소 특징쌍을 생성할 수 있으므로, 국소 특징 학습에 필요한 국소 특징쌍 데이터를 추가로 획득할 필요가 없다. 구체적으로, 제시하는 공액 랜덤 회전 절첩 알고리즘을 통해, 이미지 레벨 주석만 있는 데이터 세트 상에서, 전 역 특징과 국소 특징 연합 학습에 필요한 전역 이미지와 국소 이미지쌍을 동시에 제공하여, 이미지 레벨 주석만 있는 데이터 세트 상에서 전역 특징과 국소 특징의 공동 학습을 구현할 수 있다. 도 5 및 도 7에서 알 수 있듯이, 본 개시의 실시예에서 제시하는 PLUG 모델은 콘볼루션 신경망 기반의 멀티태스 크 모델일 수 있다. 모델의 학습 과정에서 모델은 3개의 브랜치인 전역 특징 브랜치, 국소 특징 브랜치 및 자체 감독 학습 브랜치로 구성될 수 있다. 모델의 추리 과정에서 전역 특징 브랜치와 국소 특징 브랜치만 채택할 수 있다. 모델의 학습 과정에서 자체 감독 학습 브랜치의 도입은 전역 특징과 국소 특징의 표현 성능을 향상시키는 데 도 움이 된다. 이하에서는 전역 특징 및 국소 특징쌍을 기반으로 이미지 특징 추출 모델의 네트워크 파라미터를 업데이트하는 구체적인 과정에 대해 상세히 설명한다. 일 실시예에 있어서, 단계 E4에서 전역 특징 및 국소 특징쌍을 기반으로 이미지 특징 추출 모델의 네트워크 파 라미터를 업데이트하는 단계는 하기 단계 E41 내지 단계 E44를 포함할 수 있다. 단계 E41: 전역 특징을 기반으로 분류 태스크 상에서 교차 엔트로피 손실 함수를 통해 제1 손실값을 확정할 수 있다. 구체적으로, 획득한 각 학습 이미지는 실제 클래스 라벨을 휴대한다. 본 개시의 실시예는 전역 특징을 통해 분 류 태스크 상에서 학습 이미지에 대응하는 예측 클래스 라벨을 추정할 수 있으며, 실제 클래스 라벨과 예측 클 래스 라벨을 기반으로 교차 엔트로피 손실 함수를 통해 제1 손실값을 확정할 수 있다. 구체적으로, 전역 특징은 정규화 후 ArcFace 오차 함수를 통해 분류 태스크 상에서 교차 엔트로피 손실 함수를 통해 감독 학습을 수행하며, 교차 엔트로피 손실 함수를 채택하여 제1 손실값을 계산하며 이는 하기 수학식 2로 표시될 수 있다. 수학식 2"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기에서 은 전역 특징 g 정규화 처리 후의 결과이다. y는 하나의 one-hot 벡터이다(1비트 유효 코드). 는 전역 특징 가 이미지 분류 태스크의 제k류에 속함을 나타내며 오직 이다. 단계 E2: 국소 특징점 주의력 점수도를 기반으로 분류 태스크 상에서 교차 엔트로피 손실 함수를 통해 제2 손실 값을 확정할 수 있다. 구체적으로, 국소 특징 브랜치에서, 전역 특징 브랜치와 동일한 분류 태스크를 채택해 주의력 모듈을 학습할 수 있다. 선택적으로, 단계 E42에서 국소 특징점 주의력 점수도를 기반으로 분류 태스크 상에서 교차 엔트로피 손실 함수 를 통해 제2 손실값을 확정하는 단계는 하기 단계 E421 내지 단계 E422를 포함할 수 있다. 단계 E421: 제1 이미지의 국소 특징과 국소 특징점 주의력 점수도를 기반으로 가중합을 구하여 국소 집합 특징 을 획득할 수 있다. 구체적으로, 제1 이미지의 국소 특징도를 정규화한 후 국소 특징점의 주의력 점수도와 가중합을 구하며, 이는 하기 수학식 3으로 표시될 수 있다. 수학식 3"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기에서 은 정규화 후의 제1 이미지의 국소 특징도이고, A는 국소 특징점의 주의력 점수도이다. 단계 E22: 국소 집합 특징을 기반으로 분류 태스크 상에서 교차 엔트로피 손실 함수를 통해 제2 손실값을 확정 할 수 있다. 구체적으로, 분류 태스크에서 완전연결층(콘볼루션층 w와 바이어스 b) 및 교차 엔트로피 손실 함수를 통해 감독 학습을 수행하고, 국소 특징 브랜치의 손실은 표준의 softmax 활성화 함수의 교차 엔트로피 손실로 표시될 수 있다. 이는 수학식 4와 같이 표시된다. 수학식 4"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기에서 wi은 클래스 i의 분류기 가중이고, bi은 클래스 i의 바이어스이고, y는 하나의 one-hot 벡터(1비트 유 효 코드)이고, k는 분류 태스크 실제 클래스(groundtruth) 중 하나( )이다. 단계 E43: 국소 특징쌍을 기반으로 교차 엔트로피 손실 함수를 통해 제3 손실값을 확정할 수 있다. 구체적으로, 비모수(nonparametric) 분류기(예를 들어 데이터 세트 InstDest, MoCo 및 Mo-CoV2에 사용되는 분 류기)를 채택해 자체 감독 브랜치를 학습하며, 양성 샘플 국소 특징쌍(단계 E3에서 획득한 국소 특징쌍)과 음성 샘플 국소 특징쌍의 코사인 점수를 통해 완전연결층을 치환하여 분류기를 구축할 수 있다. 선택적으로, 단계 E43에서 국소 특징쌍을 기반으로 교차 엔트로피 손실 함수를 통해 제3 손실값을 확정하는 단 계는 하기 단계 E431을 포함할 수 있다. 단계 E431: 국소 특징쌍과 음성 샘플 국소 특징을 기반으로 교차 엔트로피 손실 함수를 통해 제3 손실값을 확정 할 수 잇다. 여기에서 국소 특징쌍은 제1 이미지의 국소 특징도 상의 앵커 포인트 국소 특징과 제2 양성 샘플 국소 특징도 상의 양성 샘플 국소 특징을 포함한다. 음성 샘플 국소 특징은 이전 회차 모델 학습 과정에서 국소 특징점 주의력 점수의 최댓값에 대응하는 양성 샘플 국소 특징을 포함한다. 구체적으로, 자체 감독 학습 브랜치의 손실 함수는 수학식 5로 표시될 수 있다. 수학식 5"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기에서 τ는 온도 하이퍼파라미터이고, , , 은 음성 샘플 큐 중의 제1 이미지의 국소 특징(앵커 포 인트 국소 특징이라고 칭하기도 함) eq, 제2 이미지의 국소 특징(양성 샘플 국소 특징이라고 칭하기도 함) ek, 음성 샘플 국소 특징 en의 정규환 임베디드 특징이다. 여기에서 음성 샘플 국소 특징은 이전 회차 학습 과정에서 유래될 수 있으며, 제1 이미지의 국소 특징점 주의력 점수도(A)의 최댓값을 획득하고, 그에 대응하는 제2 이미지의 국소 특징을 획득하며, 음성 샘플 큐에 이송하여, 다음 회차 학습 과정의 음성 샘플 en로 사용할 수 있다. 여기에서 음성 샘플 큐 길이는 고정값이며, 선입선출 방 식에 따라 큐를 업데이트할 수 있다. 단계 E44: 제1 손실값, 제2 손실값 및 제3 손실값을 기반으로 이미지 특징 추출 모델의 네트워크 파라미터를 업 데이트할 수 있다. 구체적으로, 전역 특징 손실 함수 Lg, 국소 특징점 주의력 손실 함수 Ll, 국소 특징 자체 감독 손실 함수 Lpssl을 가중합산을 통해 계산하여 총 손실값 L을 획득한 후 네트워크의 학습에 사용한다. 여기에서 가중계수는 β=1, γ=0.1이고, 총 손실값 L은 하기 수학식 6으로 표시된다. 수학식 6"}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "이하에서는 이미지 특징 추출 모델의 네트워크 파라미터에 대한 업데이트의 구체적인 과정을 설명한다. 일 실시예에 있어서, 단계 E44에서 제1 손실값, 제2 손실값 및 제3 손실값을 기반으로 이미지 특징 추출 모델의 네트워크 파라미터를 업데이트하는 단계는 하기 단계 E441 내지 단계 E442를 포함할 수 있다. 단계 E441: 제1 손실값, 제2 손실값 및 제3 손실값을 기반으로 온라인 콘볼루션 신경망의 네트워크 파라미터를 업데이트할 수 있다. 단계 E442: 온라인 콘볼루션 신경망의 네트워크 파라미터를 기반으로 타깃 콘볼루션 신경망의 네트워크 파라미 터를 업데이트할 수 있다. 선택적으로, 네트워크 파라미터 업데이트 시, 온라인 모델만 학습 과정에서 제1 손실값, 제2 손실값 및 제3 손 실값을 기반으로 기울기 역전파를 통해 업데이트를 수행할 수 있으며, 타깃 모델은 모멘텀 업데이트 방법을 통 해 온라인 모델의 도움 하에서 업데이트를 수행할 수 있다. 형식적으로, 온라인 모델 의 파라미터는 로 표현되고, 타깃 모델 의 파라미터는 로 표현된다. 파라미 터 는 다음 관계 를 통해 업데이트될 수 있다. 여기에서 모멘텀 계수는 이고, m=0은 온라인 모델과 타깃 모델이 동일한 파라미터를 공유함을 나타낸다. 그러나 국소 특징 Lq 의 기울기만 백본망에 역전파하며, 국소 집합 특징의 기울기는 백본망에 백홀되지 않는다. 선택적으로, 타깃 모델은 온라인 모델을 직접 채택할 수도 있으며, 이때 이 둘은 샴 네트워크(siamese networ k)를 구성하며, 동시에 학습 과정에서 업데이트될 수 있다. 일 실시예에 있어서, 도 7에 도시된 이미지 특징 추출 모델 중 입력 이미지에 대한 처리는 전역 특징과 국소 특 징을 출력할 수 있다. 특징 추출의 결과는 SLAM 시스템에 적용할 수 있으며, 이미지 검색 또는 이미지 인식 기 술에 적용할 수도 있다. 구체적으로, 본 개시의 실시예의 일 양상에 있어서, 디바이스로부터 획득한 이미지는 광학 흐름법 또는 특징점 매칭 알고리즘을 통해 프레임 간 매칭을 계산하고, 데이터 관련성을 구축하며, 국소 광속 조정법과 전역 광속 조정법을 통해 카메라 자세를 계산하여, SLAM 시스템의 동시 로컬화 및 매핑을 구현할 수 있다. 다른 일 양상에 있어서, 본 개시의 실시예에서 제시하는 전역 특징과 국소 특징 공동 학습 모델을 통해, 공액 랜던 회전 절첩 알고리즘에 의존하여, 전역 특징과 국소 특징의 표현 능력을 동시에 향상시키고, 이미지 검색 모델이 이미지만 있는 데이터 세트 상에서 추가적으로 쌍을 이루는 이미지 블록에 의존하지 않고, 전역 특징과 국소 특징을 동시 에 학습할 수 있다. 궁극적으로 관련 기술 중 전역 특징과 국소 특징 기반 기하 검증보다 더욱 우수한 결과를나타내며, 시간 복잡도 요건을 낮추고 자세 추정의 정확도를 향상시킬 수 있다. 본 개시의 실시예는 정확한 이미지 검색과 기하 검증 기반의 동시 로컬화 및 매핑 시스템(SLAM 시스템)을 제공 할 수 있다. 이미지 수집 디바이스로부터 캡쳐하여 획득한 이미지의 경우, 종래의 특징점 매칭법 또는 광학 흐 름법을 통해 추적한 후, 광속 조정법을 통해 디바이스의 자세를 계산할 수 있다. 또한 딥 러닝 모델을 통해 SLAM 시스템을 도와 장시간 추적을 구축하고, 디바이스로부터 캡쳐하여 획득한 현재 입력 이미지에 대해 SLAM 시스템이 선별한 키 프레임으로 구성한 키 프레임 세트 중 유사도가 비교적 높은 키 프레임을 선별하고, 현재 입력 이미지와 조회하여 획득한 키 프레임 간의 특징점 매칭 관계를 계산하여, 장시간 추적을 구축할 수 있다. 본 개시의 실시예는 전역 특징과 국소 특징 연합 학습의 딥 러닝 모델을 이용하여, 공액 랜덤 회전 절첩 알고리 즘을 통해, 국소 이미지 블록쌍이 추가적으로 생성되지 않은 상황에서, 관련 기술과 융합하여, 전역 특징과 국 소 특징을 동시에 최적화할 수 있다. 궁극적으로 전역 특징과 국소 특징 연합 최적화의 이미지 심층 특징 추출 방법이 심층 특징(deep feature)의 표현 능력을 향상시키고, SLAM 시스템이 더욱 정확한 유사 이미지를 찾도록 도와, 특징점의 장시간 추적을 구축하고, SLAM 시스템이 리던던시 특징점(단시간 추적에 대응하는 특징점)을 제 거하도록 할 수 있다. 그 중 특징점의 장시간 추적의 구축은 SLAM 시스템의 최적화 속도와 정밀도 향상에 도움 이 될 수 있다. 본 개시에서 제공하는 디바이스의 자세 추정 방법에 대응하여, 본 개시의 실시예는 디바이스의 자세 추정 장치 를 더 제공한다. 그 구조는 도 9에 도시된 바와 같다. 본 개시의 디바이스의 자세 추정 장치는 제1 획득 모듈, 제2 획득 모듈 및 제3 획득 모듈을 포함할 수 있다. 제1 획득 모듈은 키 프레임 세트에서 디바이스가 수집한 현재 프레임의 유사 키 프레임을 획득하도록 구성될 수 있다. 제2 획득 모 듈은 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이터 관련 정보를 획득하도록 구성될 수 있다. 제3 획득 모듈은 상기 데이터 관련 정보를 기반으로 디바이스의 자세 를 획득하도록 구성될 수 있다. 일 실시예에 있어서, 제1 획득 모듈이 키 프레임 세트에서 디바이스가 수집한 현재 프레임의 유사 키 프 레임을 획득하는 단계를 실행할 때, 현재 프레임의 전역 특징을 추출하고, 전역 특징을 기반으로 키 프레임 세트에서 현재 프레임의 유사 키 프레임 을 획득하는 단계; 현재 프레임의 전역 특징을 추출하고, 전역 특징을 기반으로 키 프레임 세트 중 각 키 프레임과 현재 프레임의 제1 유사도를 확정하고; 현재 프레임의 국소 특징을 추출하고, 국소 특징을 기반으로 제1 유사도를 업데이트하 여, 키 프레임 세트 중 각 키 프레임과 현재 프레임의 제2 유사도를 획득하고; 유사 키 프레임을 기반으로 현재 프레임의 유사 키 프레임을 획득하는 단계 중 어느 하나를 더 실행할 수 있다. 일 실시예에 있어서, 제2 획득 모듈은 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 이미지 프레임 간의 데이터 관련 정보를 획득하는 단계를 실행할 때, 현재 프레임에 대해 프레임간 특징 매칭을 수행하여, 이미지 프레임 간의 제1 데이터 관련 정보를 획득하는 단 계; 및 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 제1 데이터 관련 정보를 업데이트하여, 이미지 프레임 간의 제2 데이터 관련 정보를 획득하는 단계를 더 실행할 수 있다. 일 실시예에 있어서, 제2 획득 모듈은 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 제1 데이터 관련 정보를 업데이트하고, 이미지 프레임 간의 제2 데이터 관련 정보를 획득하는 단계를 실행할 때, 현재 프레임에 대해 프레임 간 특징 매칭을 수행하여, 제1 데이터 관련 정보를 획득하는 단계, 제1 데이터 관련 정보는 각 이미지 프레임의 특징 간의 매칭 관계를 포함함; 현재 프레임과 유사 키 프레임 간의 특징 매칭 관계를 기반으로, 각 이미지 프레임의 특징이 동일 특징인지 여 부를 판단하는 단계; 판단 결과를 기반으로 동일 특징을 합치는 단계; 및 합친 특징을 기반으로, 제1 데이터 관련 정보를 업데이트하여 제2 데이터 관련 정보를 획득하는 단계를 실행할 수 있다.일 실시예에 있어서, 제1 획득 모듈에서 이미지 특징 추출 모델을 채택하여 키 프레임 세트에서 디바이스 가 수집한 현재 프레임의 유사 키 프레임을 더 획득할 수 있다. 구체적으로, 이미지 특징 추출 모델은, 제1 이미지 및 제1 이미지를 회전 절첩하여 획득한 제2 이미지를 획득하는 단계; 및 제1 이미지와 제2 이미지를 기반으로, 이미지 특징 추출 모델이 추출한 전역 특징과 국소 특징을 통해, 이미지 특징 추출 모델에 대해 공동 학습을 수행하여, 학습된 이미지 특징 추출 모델을 획득할 수 있다. 일 실시예에 있어서, 이미지 특징 추출 모델이 추출한 전역 특징과 국소 특징을 통해, 이미지 특징 추출 모델에 대해 공동 학습을 수행하는 단계는, 이미지 특징 추출 모델을 통해 제1 이미지의 국소 특징과 전역 특징을 획득하는 단계; 타깃 모델을 통해 제2 이미지의 국소 특징을 획득하고, 제2 이미지의 국소 특징에 대해 회전 절첩에 대응하는 공액 회전 절첩을 수행하는 단계; 제1 이미지의 국소 특징과 공액 회전 절첩된 제2 이미지의 국소 특징을 기반으로 국소 특징쌍을 획득하는 단계; 및 국소 특징쌍과 전역 특징을 기반으로, 이미지 특징 추출 모델의 파라미터를 업데이트하는 단계를 포함할 수 있 다. 본 개시의 실시예의 장치는 본 개시의 실시예에서 제공하는 방법을 실행할 수 있다. 그 구현 원리는 서로 유사 하며, 본 개시의 실시예에 따른 장치 중의 각 모듈이 실행하는 동작은 본 개시의 각 실시예에 따른 방법 중의 단계와 서로 대응한다. 장치에서 각 모듈의 상세한 기능 설명은 구체적으로 앞서 설명한 대응하는 방법 중의 설 명을 참조할 수 있으므로, 여기에서 더 이상 설명하지 않는다. 본 개시는 전자 디바이스를 더 제공한다. 상기 전자 디바이스는 메모리와 프로세서를 포함한다. 여기에서 메모 리에는 컴퓨터 프로그램이 저장된다. 프로세서는 컴퓨터 프로그램을 운행할 때, 본 개시에서 어느 하나의 선택 적 실시예에서 제공하는 디바이스의 자세 추정 방법을 실행하는 데 사용된다. 본 개시는 컴퓨터 판독 가능 저장 매체를 더 제공한다. 상기 저장 매체에는 컴퓨터 프로그램이 저장된다. 컴퓨 터 프로그램은 프로세서에 의해 운행될 때, 본 개시에서 어느 하나의 선택적 실시예에서 제공하는 디바이스의 자세 추정 방법을 실행한다. 선택적 방안으로서, 도 10은 본 개시의 실시예에 적용된 전자 디바이스의 구조도를 도시하였다. 도 10에 도시된 바와 같이, 상기 전자 디바이스는 프로세서 및 메모리를 포함한다. 여기에서 프로세서와 메모리는 서로 연결된다. 예를 들어 버스를 통해 서로 연결될 수 있다. 선택적으로, 전자 디바이스는 송수신기를 더 포함할 수 있다. 실제 적용에서 송수신기는 하나로 제한되지 않는다. 상기 디바이스의 구조는 본 개시의 실시예에 한정되지 않는다. 프로세서는 중앙 처리 장치(Central Processing Unit, CPU), 범용 프로세서, 디지털 신호 프로세서 (Digital Signal Processor, DSP), 주문형 집적 회로(Application Specific Integrated Circuits, ASIC), 필 드 프로그래머블 게이트 어레이(Field-Programmable Gate Array, FPGA) 또는 기타 프로그래밍 가능 논리 장치, 트랜지스터 논리 장치, 하드웨어 부재 또는 기타 임의 조합일 수 있다. 이는 본 개시에 개시된 내용에 설명된 다양한 예시적인 논리 블록, 모듈 및 회로를 구현하거나 실행할 수 있다. 프로세서는 컴퓨팅 기능을 구현하는 조합일 수 있다. 예를 들어 하나 이상의 마이크로프로세서 조합, DSP 와 마이크로프로세서의 조합 등이 포함될 수 있다. 버스는 전술한 구성 요소 간의 정보 전달을 위한 경로를 포함할 수 있다. 버스는 주변 컴포넌트 상호접속 표준(Peripheral Component Interconnect, PCI) 버스 또는 확장 산업 표 준 구조(Extended Industry Standard Architecture, EISA) 버스 등일 수 있다. 버스는 어드레스 버스, 데이터 버스, 제어 버스 등으로 구분될 수 있다. 도 10에서는 표현의 편의를 위해 하나의 굵은 선만 사용하여 나타냈으나, 이는 하나의 버스 또는 한 유형의 버 스만 있음을 의미하지는 않는다. 메모리는 읽기 전용 메모리(Read Only Memory, ROM) 또는 정적 정보 및 명령을 저장할 수 있는 다른 유형 의 정적 저장 디바이스, 랜덤 액세스 메모리(Random Access Memory, RAM) 또는 정보 및 명령을 저장할 수 있는 다른 유형의 동적 저장 디바이스일 수 있다. 또한 전기적 소거 및 프로그램 가능 읽기 전용 기억 장치 (Electrically Erasable Programmable Read Only Memory, EEPROM), 읽기 전용 콤팩트 디스크(Compact Disc Read Only Memory, CD-ROM) 또는 기타 콤팩트 디스크 저장소, 광 디스크 저장소(압축 광 디스크, 레이저 디스크, 광 디스크, 디지털 범용 광 디스크, 블루레이 광 디스크 등 포함), 자기 디스크 저장 매체 또는 기타 자기 저장 디바이스, 또는 명령 또는 데이터 구조의 형태를 가진 원하는 프로그램 코드를 휴대하거나 저장하는 데 사용할 수 있으며 컴퓨터에서 액세스할 수 있는 기타 모든 매체일 수도 있으나, 이에 한정되지 않는다. 메모리는 본 개시의 방법을 실행하는 응용 프로그램 코드를 저장하는 데 사용되며, 프로세서에 의 해 실행이 제어될 수 있다. 프로세서는 메모리에 저장된 응용 프로그램 코드(컴퓨터 프로그램)를 실행하여 전술한 방법 실시예 중 어느 하나에 도시된 내용을 구현하는 데 사용될 수 있다. 본 개시에서 제공하는 실시예에 있어서, 전자 디바이스에서 실행하는 상기 디바이스의 자세 추정 방법은 인공 지능 모델을 사용하여 실행할 수 있다. 본 개시의 실시예에 따르면, 전자 디바이스에서 실행되는 상기 방법은 이미지 데이터 또는 비디오 데이터를 인 공 지능 모델의 입력 데이터로 이용하여 이미지 또는 이미지 내의 이미지 특징을 인식하는 출력 데이터를 획득 할 수 있다. 인공 지능 모델은 학습을 통해 획득할 수 있다. 여기에서 \"학습을 통해 획득한다\"는 것은 학습 알고리즘을 통해 복수의 학습 데이터를 이용하여 기본 인공 지능 모델을 학습함으로써 기대하는 특징(또는 목적)을 실행하도록 구성된 사전 정의 조작 규칙 또는 인공 지능 모델 을 획득하는 것을 의미한다. 인공 지능 모듈은 복수의 신경망 계층을 포함할 수 있다. 복수의 신경망 계층에서 각 층은 복수의 가중치를 포함하며, 이전 계층의 계산 결과와 복수의 가중치 간의 계산 을 통해 신경망 계산을 실행할 수 있다. 시각적 이해는 인간의 시각과 같이 사물을 인식하고 처리하는 기술이며, 예를 들어 대상 인식, 대상 추적, 이미 지 검색, 인간 인식, 장면 인식, 3D 재구성/로컬화 또는 이미지 증강이 포함될 수 있다. 본 개시에서 제공하는 디바이스의 자세 추정 장치는 AI 모델을 통해 복수 모듈 중의 적어도 하나의 모듈을 구현 할 수 있다. AI와 관련된 기능은 비휘발성 메모리, 휘발성 메모리 및 프로세서를 통해 수행할 수 있다. 상기 프로세서는 하나 이상의 프로세서를 포함할 수 있다. 여기에서 하나 이상의 프로세서는 범용 프로세서(예를 들어 중앙 처리 장치(CPU), 애플리케이션 프로세서(AP) 등), 또는 순수 그래픽 처리 유닛(예를 들어 그래픽 처리 유닛(GPU)), 시각 처리 유닛(VPU) 및/또는 AI 전용 프 로세서(예를 들어 신경 처리 유닛(NPU))일 수 있다. 상기 하나 이상의 프로세서는 비휘발성 메모리 및 휘발성 메모리에 저장된 사전 정의된 조작 규칙 또는 인공 지 능(AI) 모델에 따라 입력 데이터의 처리를 제어할 수 있다. 또한 하나 이상의 프로세서는 훈련 또는 학습을 통해 사전 정의된 조작 규칙 또는 인공 지능 모델을 제공한다. 여기에서, 학습에 의한 제공은 복수의 학습 데이터에 학습 알고리즘을 적용하여 사전 정의된 조작 규칙 또는 원 하는 특성을 갖는 AI 모델을 획득하는 것을 의미한다. 상기 학습은 실시예에 따른 AI를 실행하는 디바이스 자체에서 실행될 수 있고, 및/또는 별도의 서버/시스템에 의해 구현될 수 있다. 상기 AI 모델은 복수의 신경망 계층을 포함하여 구성될 수 있다. 각 층은 복수의 가중치를 가지며, 한 층의 계 산은 이전 층의 계산 결과와 현재 층의 복수의 가중치를 통해 실행한다. 신경망의 예로는 콘볼루션 신경망(Convolutional Neural Network, CNN), 딥신경망(Deep Neural Network, DNN), 순환신경망(Recurrent Neural Network, RNN), 제한된 볼츠만 머신(Restricted Boltzmann Machine, RBM), 심층 신뢰망(Deep Belief Network, DBN), 양방향 순환 딥신경망(Bidirectional Recurrent Deep Neural Network, BRDNN), 생성적 대립 신경망(Generative Adversarial Network, GAN) 및 딥 Q 네트워크(Deep Q Network)가 포함 되나 이에 한정되지 않는다. 학습 알고리즘은 복수의 학습 데이터를 이용하여 소정의 타깃 장치(예를 들어 로봇)를 학습시켜 타깃 장치가 확 정 또는 예측하도록 만들거나, 허용하거나, 제어하는 방법이다. 상기 학습 알고리즘의 예로는 감독 학습, 비감독 학습, 반감독 학습 또는 강화 학습이 포함되나 이에 한정되지 않는다. 첨부 도면의 흐름도 중 각 단계가 화살표로 표시된 순서대로 도시되었으나, 이러한 단계가 반드시 화살표로 표 시된 순서대로 실행되는 것은 아님을 이해해야 한다. 본원에 명시되지 않는 한, 이러한 단계의 실행은 엄격한 순서로 제한되지 않으며, 다른 순서로 실행될 수 있다. 또한 첨부 도면의 흐름도 중 적어도 일부 단계는 복수의 하위 단계 또는 복수의 방법을 포함할 수 있다. 이러한 하위 단계 또는 방법은 반드시 동시에 실행될 필요는 없으며 상이한 시간에 실행될 수 있다. 그 실행 순서도 반 드시 순차적으로 수행되어야 하는 것은 아니며 다른 단계 또는 다른 방법의 하위 단계 중 적어도 일부와 교대로 또는 교차로 수행할 수 있다."}
{"patent_id": "10-2021-0162793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "상기 내용은 본 개시의 바람직한 실시예일뿐이다. 본 기술분야에서 통상의 지식을 가진 자는 본 개시의 사상을 벗어나지 않고 일부를 개선 및 변경할 수 있으며, 이러한 개선 및 변경은 본 개시의 보호 범위에 속한다."}
{"patent_id": "10-2021-0162793", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시예에서 제공하는 디바이스의 자세 추정 방법의 흐름도이다. 도 2는 본 개시의 실시예에서 제공하는 이미지 검색 및 기하 검증(geometric verification) 기반의 디바이스의 자세 추정의 시스템 개략도이다. 도 3은 본 개시의 실시예에서 제공하는 이미지 검색의 비동기 추적을 기반으로 수행하는 디바이스의 자세 추정 조작의 흐름도이다. 도 4는 본 개시의 실시예에서 제공하는 광학 흐름법과 특징점법 기반의 프레임 간 특징 매칭 조작의 개략도이다. 도 5는 본 개시의 실시예에서 제공하는 전역 특징과 국소 특징 연합으로 최적화한 이미지 특징 추출 모델 학습 의 프레임 개략도이다. 도 6은 본 개시의 실시예에서 제공하는 공액 랜덤 회전 절첩 기반의 국소 특징 자체 감독 학습 네트워크의 개략 도이다. 도 7은 본 개시의 실시예에서 제공하는 전역 특징과 국소 특징 연합으로 최적화한 이미지 특징 추출 모델 학습 의 추론 개략도이다. 도 8은 랜덤 회전 절첩의 원리도이다. 도 9는 본 개시의 실시예에서 제공하는 디바이스의 자세 추정 장치의 구조도이다. 도 10은 본 개시의 실시예에서 제공하는 전자 디바이스의 구조도이다."}
