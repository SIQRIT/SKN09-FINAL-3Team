{"patent_id": "10-2020-7037419", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0076882", "출원번호": "10-2020-7037419", "발명의 명칭": "서비스형 함수", "출원인": "인텔 코포레이션", "발명자": "하기가트, 모하마드 알."}}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "향상된 서비스형 함수(FaaS)를 복수의 사용자에게 제공하기 위한 실행 가능한 컴퓨터 프로그래밍 명령어들의 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체로서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 컴퓨팅 시스템에 의해 실행될 때, 상기 컴퓨팅 시스템으로 하여금: 상기 복수의 사용자로부터 수신된 하나 이상의 이벤트에 응답하여 상기 컴퓨팅 시스템 내의 하나 이상의 아키텍처 서브시스템에서 복수의 함수를 실행하게 하고 - 상기 하나 이상의 아키텍처 서브시스템은 상기 복수의 함수에 대한 실행 환경의 추상화 및 상기 복수의 함수와 연관된 복수의 컨테이너를 나타냄 -;상기 컴퓨팅 시스템 내의 하나 이상의 소프트웨어 및 오케스트레이션 서브시스템에 의한 상기 복수의 함수의 실행을 용이하게 하기 위해 상기 컴퓨팅 시스템의 복수의 컴퓨팅 리소스를 할당하게 하며;상기 복수의 함수와 연관된 복수의 파라미터 및 상기 복수의 컴퓨팅 리소스와 연관된 복수의 파라미터를 분석하게 하고;상기 복수의 함수, 및 상기 복수의 함수 및 상기 복수의 컴퓨팅 리소스와 연관된 상기 복수의 파라미터에 대한분석을 상기 컴퓨팅 시스템 내의 하나 이상의 네트워킹 및 저장 서브시스템에 저장하게 하며 - 상기 복수의 함수 및 상기 복수의 파라미터에 대한 분석을 저장하기 위한 위치들은 상기 복수의 함수 및 대응하는 상기 복수의컴퓨팅 리소스 사이의 지역성을 향상시키고 함수 실행 레이턴시를 감소시키도록 선택됨 -;상기 컴퓨팅 시스템 내의 하나 이상의 보안 서브시스템에 의해 상기 복수의 함수의 실행을 보호하게 하는, 적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 상기 복수의 함수 중 하나 이상의 함수의 실행을 모니터링하게 하고;상기 컴퓨팅 시스템의 하나 이상의 컴퓨팅 리소스를 하나 이상의 공유 리소스로 파티셔닝하게 하며 - 상기 복수의 함수의 각각의 함수는 상기 하나 이상의 공유 리소스에 대한 액세스를 가짐 -;상기 복수의 함수를 실행하기 위한 하나 이상의 컴퓨팅 리소스를 할당하는 스케줄링을 제공하게 하고 - 상기 스케줄링은 상기 컴퓨팅 시스템에 의해 실행되는 함수들의 이력 기반 리소스 스케줄링에 적어도 기초하여 생성됨-;실행을 위해 상기 하나 이상의 함수의 데이터를 선택된 컴퓨팅 디바이스들로 리디렉션하게 하며;상기 하나 이상의 함수와 연관된 서비스 레벨 파라미터들에 따라 상기 복수의 함수 중 하나 이상의 함수를 선택하게 하고;실행을 위해 상기 선택된 하나 이상의 함수를 조합된 함수로 조합하게 하는,적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 상기 복수의 함수 중 제2 함수를 호출하기 위한 트리거 에이전트를 수신하게 하고 - 상기 제2 함수는 현재 실행중인 상기 복수의 함수 중의 함수 다음에 실행됨 -;공개특허 10-2021-0076882-3-상기 제2 함수 호출에 대한 준비 완료를 나타내는 피드백을 상기 트리거 에이전트에 제공하게 하며;상기 복수의 함수 중의 함수가 다중 테넌트 가속 함수인 것에 응답하여, 상기 함수의 하나 이상의 버전을 개시하게 하고;상기 복수의 함수의 실행과 연관된 실행 액션들 간의 동기화를 제공하게 하며 - 상기 실행 액션들은 상기 복수의 함수와 연관된 복수의 컴퓨팅 디바이스 및/또는 컨테이너 간에 분배됨 -;기준이 충족되는 것에 응답하여 상기 제2 함수 호출을 트리거하게 하는,적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 상기 복수의 함수 중 2개 이상의 함수 간에 공유된 정보를 식별하게 하고;실행을 위해 호출된 함수가 실행을 위해 상기 공유된 정보를 필요로 하는지를 분석하게 하며;상기 분석에 기초하여 상기 함수를 실행 환경으로 라우팅하게 하는,적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 함수의 초기 실행 동안 상기 함수를 분석하게 하고;상기 함수의 분석으로부터 생성된 사용량 데이터를 상기 함수의 후속 호출을 위한 메타데이터 파일로서 저장하게 하며 - 상기 함수의 각각의 호출은 상기 함수에 대한 적어도 하나의 메타데이터 파일을 생성함 -;하나 이상의 인자에 기초하여 상기 함수를 회수하게 하고 - 상기 하나 이상의 인자 각각은 상기 함수의 실행 상태를 나타내고, 상기 실행 상태는 상기 함수를 회수할지를 나타냄 -;상기 함수에 보안 정책을 적용하게 하는 - 상기 보안 정책은 상기 함수의 실행 환경과 연관되고, 상기 함수의하나 이상의 함수 세트는 동일한 보안 키로 인코딩됨 -,적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 상기 복수의 함수 중의 함수의 하나 이상의 컴퓨팅 리소스 요구를 식별하게 하고;상기 함수가 할당되는 컨테이너 내의 하나 이상의 식별된 컴퓨팅 리소스를 사전 예약하게 하며 - 각각의 식별된컴퓨팅 리소스는 리소스 디렉터리 식별(resource directory identification)을 가짐 -;상기 함수의 특정 워크로드들에 대한 비용 함수를 평가하기 위해 가속기를 적용하게 하고;데이터 전송 또는 통신 레이턴시를 감소시키도록 상기 사전 예약된 컴퓨팅 리소스들 사이의 데이터 전송과 통신링크들 및 상기 함수의 호출을 구성하게 하며;상기 함수의 실행과 연관된 하나 이상의 서비스 품질(QoS) 측정치를 모니터링하게 하는 - 적어도 하나의 QoS 측정치는 벡터에 의해 정의됨 -,적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2021-0076882-4-제6항에 있어서, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기 컴퓨팅 시스템으로 하여금: 상기 함수를 실행하는 런타임 시에 하나 이상의 이상을 탐지하게 하고 - 상기 이상은 상기 함수를 실행하는 상기 런타임에서 동적 프로파일링 능력들을 사용하여 탐지됨 -;상기 하나 이상의 이상의 탐지의 결과들을 적어도 하나의 성능 분석 툴에 보고하게 하며;상기 함수의 상기 동적 프로파일링 능력들에 기초하여 함수의 프로파일 매핑을 유지하게 하는실행 가능한 컴퓨터 프로그래밍 명령어들을 추가로 포함하는, 적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 리소스 특성들을 실행된 함수들과 연관시켜 상기 함수들의 각각의 실행 스테이지에서 상기 실행된 함수들의 수요 핑거프린트들을 생성하게 하고 - 상기 수요 핑거프린트들은 상기 함수들의 파라미터들 및 상기 함수들을 호출하는 적어도 하나의 테넌트와 연관되고, 상기 수요 핑거프린트들은 트레이닝된 시퀀스 분석 머신 러닝 모델의적용에 기초하여 생성됨 -;상기 함수들의 다수의 실행 스테이지에서 상이한 리소스들의 사용량에 대한 보고서들을 생성하게 하며;상기 생성된 보고서들에 기초하여 상기 함수들을 실행하기 위한 리소스들을 상기 함수들에 할당하게 하는,적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 필드 세트(set of fields)를 리턴하는 함수의 제1 호출 인스턴스에 의해 제1 호출을 탐지하게 하고;상기 필드 세트의 제1 서브세트를 식별하게 하며 - 상기 제1 서브세트는 상기 제1 호출 인스턴스와 연관됨 -;상기 제1 서브세트에 기초하여 제1 응답 객체의 제1 릴레이 아웃을 수행하게 하는 - 상기 제1 응답 객체의 릴레이 아웃은 상기 제1 응답 객체를 재정렬하거나 재구성함 -,적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 상기 복수의 함수 중의 함수에 대한 페이로드를 결정하게 하고;컴파일 시에, 상기 페이로드를 빌드하는 코드를 호출을 하기에 충분한 정보를 포함하는 포맷으로 호출 스택에두게 하며, 상기 함수는 상기 페이로드를 통해 로컬 인스턴스, 원격 인스턴스 또는 하드웨어로서 균일하게 호출가능한, 적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 상기 복수의 함수 중 제1 함수와 연관된 능력 정보가 제1 인증 포맷과 관련하여 유효한지를 결정하게 하고 - 상기 능력 정보 및 상기 제1 인증 포맷은 상기 제1 함수에 대응함 -;상기 능력 정보가 상기 제1 인증 포맷과 관련하여 유효한 경우 상기 능력 정보를 큐에 저장하게 하며;상기 복수의 함수 중 제2 함수에 대응하는 제2 인증 포맷에 따라 상기 능력 정보를 상기 제2 함수에 전송하게하는 - 상기 제1 함수 및 상기 제2 함수는 이식 가능(portable) 함수들이고, 이식 가능 함수는 이식 가능 아이공개특허 10-2021-0076882-5-덴티티를 가지며 로드 밸런서에 의해 상기 컴퓨팅 시스템 전체에 걸쳐 동적으로 이동 가능하고, 상기 능력 정보는 계층적인 인코딩된 인라인 능력들 및 사용자 레벨 인터럽트들을 포함함 -,적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 키 식별자를 제1 키에 매핑하게 하고 - 상기 제1 키는 제1 함수 및 상기 제1 키로 암호화되는 제1 메모리 영역과 연관됨 -;상기 제1 함수로부터 제2 함수로의 컨텍스트 전환을 탐지하게 하고;상기 컨텍스트 전환에 응답하여 상기 키 식별자를 제2 키에 매핑하게 하며,상기 제2 키는 상기 제2 함수 및 상기 제2 키로 암호화된 제2 메모리 영역과 연관되고,상기 제1 메모리 영역과 상기 제2 메모리 영역은 선형 어드레스 범위를 공유하며,상기 제1 키는 제1 타깃 도메인에 대한 키이고 상기 제2 키는 제2 타깃 도메인에 대한 키이며, 상기 제1 타깃도메인들 또는 상기 제2 타깃 도메인들 중 하나 이상은 신뢰 도메인의 하위 도메인인, 적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 상기 복수의 함수의 함수 세트와 관련하여 불충분한 수의 보호 키 식별자들을 탐지하게 하고;상기 불충분한 수의 보호 키 식별자들에 응답하여 호스트 컴퓨팅 디바이스에 페이지 테이블 엔트리를 업데이트하라고 지시하게 하며 - 상기 함수 세트는 관리 런타임 함수들로 제한됨 -;상기 함수 세트의 원자적 실행을 시행하게 하는,적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서, 상기 실행 가능한 컴퓨터 프로그래밍 명령어들은, 상기 컴퓨팅 시스템에 의해 실행될 때, 상기컴퓨팅 시스템으로 하여금: 소프트웨어 스레드가 하드웨어 논리 스레드에서 실행 중인지를 결정하게 하고;상기 소프트웨어 스레드가 상기 하드웨어 논리 스레드에서 실행 중일 때 태그를 레지스터로 스와핑하게 하며;상기 태그에 대한 캐시 용량 및 메모리 대역폭 중 적어도 하나를 설정하게 하는,적어도 하나의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "반도체 장치로서,하나 이상의 기판; 및상기 하나 이상의 기판에 결합된 로직을 포함하며, 상기 로직은 구성 가능한 로직 또는 고정 기능 하드웨어 로직 중 하나 이상으로 적어도 부분적으로 구현되고, 상기 로직은:복수의 사용자로부터 수신된 하나 이상의 이벤트에 응답하여 컴퓨팅 시스템 내의 하나 이상의 아키텍처 서브시스템에서 복수의 함수를 실행하고 - 상기 하나 이상의 아키텍처 서브시스템은 상기 복수의 함수에 대한 실행 환공개특허 10-2021-0076882-6-경의 추상화 및 상기 복수의 함수와 연관된 복수의 컨테이너를 나타냄 -;상기 컴퓨팅 시스템 내의 하나 이상의 소프트웨어 및 오케스트레이션 서브시스템에 의한 상기 복수의 함수의 실행을 용이하게 하기 위해 상기 컴퓨팅 시스템의 복수의 컴퓨팅 리소스를 할당하며;상기 복수의 함수와 연관된 복수의 파라미터 및 상기 복수의 컴퓨팅 리소스와 연관된 복수의 파라미터를 분석하고;상기 복수의 함수, 및 상기 복수의 함수 및 컴퓨팅 리소스와 연관된 상기 복수의 파라미터에 대한 분석을 상기컴퓨팅 시스템 내의 하나 이상의 네트워킹 및 저장 서브시스템에 저장하며 - 상기 복수의 함수 및 상기 복수의파라미터에 대한 분석을 저장하기 위한 위치들은 상기 복수의 함수 및 대응하는 상기 복수의 컴퓨팅 리소스 사이의 지역성을 향상시키고 함수 실행 레이턴시를 감소시키도록 선택됨 -;상기 컴퓨팅 시스템 내의 하나 이상의 보안 서브시스템에 의해 상기 복수의 함수의 실행을 보호하기 위해상기 하나 이상의 기판에 결합되는, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:상기 복수의 함수 중 하나 이상의 함수의 실행을 모니터링하고;상기 컴퓨팅 시스템의 하나 이상의 컴퓨팅 리소스를 하나 이상의 공유 리소스로 파티셔닝하며 - 상기 복수의 함수의 각각의 함수는 상기 하나 이상의 공유 리소스에 대한 액세스를 가짐 -;상기 복수의 함수를 실행하기 위한 하나 이상의 컴퓨팅 리소스를 할당하는 스케줄링을 제공하고 - 상기 스케줄링은 상기 컴퓨팅 시스템에 의해 실행되는 함수들의 이력 기반 리소스 스케줄링에 적어도 기초하여 생성됨 -;실행을 위해 상기 하나 이상의 함수의 데이터를 선택된 컴퓨팅 디바이스들로 리디렉션하며;상기 하나 이상의 함수와 연관된 서비스 레벨 파라미터들에 따라 상기 복수의 함수 중 하나 이상의 함수를 선택하고;실행을 위해 상기 선택된 하나 이상의 함수를 조합된 함수로 조합하는, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:상기 복수의 함수 중 제2 함수를 호출하기 위한 트리거 에이전트를 수신하고 - 상기 제2 함수는 현재 실행 중인상기 복수의 함수 중의 함수 다음에 실행됨 -;상기 제2 함수 호출에 대한 준비 완료를 나타내는 피드백을 상기 트리거 에이전트에 제공하며;상기 복수의 함수 중의 함수가 다중 테넌트 가속 함수인 것에 응답하여, 상기 함수의 하나 이상의 버전을 개시하고;상기 복수의 함수의 실행과 연관된 실행 액션들 간의 동기화를 제공하며 - 상기 실행 액션들은 상기 복수의 함수와 연관된 복수의 컴퓨팅 디바이스 및/또는 컨테이너 간에 분배됨 -;기준이 충족되는 것에 응답하여 상기 제2 함수 호출을 트리거하는, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:상기 복수의 함수 중 2개 이상의 함수 간에 공유된 정보를 식별하고;실행을 위해 호출된 함수가 실행을 위해 상기 공유된 정보를 필요로 하는지를 분석하며;상기 분석에 기초하여 상기 함수를 실행 환경으로 라우팅하는, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "공개특허 10-2021-0076882-7-제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:함수의 초기 실행 동안 상기 함수를 분석하고;상기 함수의 분석으로부터 생성된 사용량 데이터를 상기 함수의 후속 호출을 위한 메타데이터 파일로서 저장하며 - 상기 함수의 각각의 호출은 상기 함수에 대한 적어도 하나의 메타데이터 파일을 생성함 -;하나 이상의 인자에 기초하여 상기 함수를 회수하고 - 상기 하나 이상의 인자 각각은 상기 함수의 실행 상태를나타내고, 상기 실행 상태는 상기 함수를 회수할지를 나타냄 -;상기 함수에 보안 정책을 적용하는 - 상기 보안 정책은 상기 함수의 실행 환경과 연관되고, 상기 함수의 하나이상의 함수 세트는 동일한 보안 키로 인코딩됨 -, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:상기 복수의 함수 중의 함수의 하나 이상의 컴퓨팅 리소스 요구를 식별하고;상기 함수가 할당되는 컨테이너 내의 하나 이상의 식별된 컴퓨팅 리소스를 사전 예약하며 - 각각의 식별된 컴퓨팅 리소스는 리소스 디렉터리 식별을 가짐 -;상기 함수의 특정 워크로드들에 대한 비용 함수를 평가하기 위해 가속기를 적용하고;데이터 전송 또는 통신 레이턴시를 감소시키도록 상기 사전 예약된 컴퓨팅 리소스들 사이의 데이터 전송과 통신링크들 및 상기 함수의 호출을 구성하며;상기 함수의 실행과 연관된 하나 이상의 서비스 품질(QoS) 측정치를 모니터링하는 - 적어도 하나의 QoS 측정치는 벡터에 의해 정의됨 -, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:상기 함수를 실행하는 런타임 시에 하나 이상의 이상을 탐지하고 - 상기 이상은 상기 함수를 실행하는 상기 런타임에서 동적 프로파일링 능력들을 사용하여 탐지됨 -;상기 하나 이상의 이상의 탐지의 결과들을 적어도 하나의 성능 분석 툴에 보고하며;상기 함수의 상기 동적 프로파일링 능력들에 기초하여 함수의 프로파일 매핑을 유지하는, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:리소스 특성들을 실행된 함수들과 연관시켜 상기 함수들의 각각의 실행 스테이지에서 상기 실행된 함수들의 수요 핑거프린트들을 생성하고 - 상기 수요 핑거프린트들은 상기 함수들의 파라미터들 및 상기 함수들을 호출하는적어도 하나의 테넌트와 연관되고, 상기 수요 핑거프린트들은 트레이닝된 시퀀스 분석 머신 러닝 모델의 적용에기초하여 생성됨 -;상기 함수들의 다수의 실행 스테이지에서 상이한 리소스들의 사용량에 대한 보고서들을 생성하며;상기 생성된 보고서들에 기초하여 상기 함수들을 실행하기 위한 리소스들을 상기 함수들에 할당하는, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:필드 세트를 리턴하는 함수의 제1 호출 인스턴스에 의해 제1 호출을 탐지하고;상기 필드 세트의 제1 서브세트를 식별하며 - 상기 제1 서브세트는 상기 제1 호출 인스턴스와 연관됨 -;상기 제1 서브세트에 기초하여 제1 응답 객체의 제1 릴레이 아웃을 수행하는 - 상기 제1 응답 객체의 릴레이 아공개특허 10-2021-0076882-8-웃은 상기 제1 응답 객체를 재정렬하거나 재구성함 -, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:상기 복수의 함수 중의 함수에 대한 페이로드를 결정하고;컴파일 시에, 상기 페이로드를 빌드하는 코드를 호출을 하기에 충분한 정보를 포함하는 포맷으로 호출 스택에두게 하며, 상기 함수는 상기 페이로드를 통해 로컬 인스턴스, 원격 인스턴스 또는 하드웨어로서 균일하게 호출가능한, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:상기 복수의 함수 중 제1 함수와 연관된 능력 정보가 제1 인증 포맷과 관련하여 유효한지를 결정하고 - 상기 능력 정보 및 상기 제1 인증 포맷은 상기 제1 함수에 대응함 -;상기 능력 정보가 상기 제1 인증 포맷과 관련하여 유효한 경우 상기 능력 정보를 큐에 저장하며;상기 복수의 함수 중 제2 함수에 대응하는 제2 인증 포맷에 따라 상기 능력 정보를 상기 제2 함수에 전송하는 -상기 제1 함수 및 상기 제2 함수는 이식 가능 함수들이고, 이식 가능 함수는 이식 가능 아이덴티티를 가지며 로드 밸런서에 의해 상기 컴퓨팅 시스템 전체에 걸쳐 동적으로 이동 가능하고, 상기 능력 정보는 계층적인 인코딩된 인라인 능력들 및 사용자 레벨 인터럽트들을 포함함 -, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:키 식별자를 제1 키에 매핑하고 - 상기 제1 키는 제1 함수 및 상기 제1 키로 암호화되는 제1 메모리 영역과 연관됨 -;상기 제1 함수로부터 제2 함수로의 컨텍스트 전환을 탐지하고;상기 컨텍스트 전환에 응답하여 상기 키 식별자를 제2 키에 매핑하며,상기 제2 키는 상기 제2 함수 및 상기 제2 키로 암호화된 제2 메모리 영역과 연관되고,상기 제1 메모리 영역과 상기 제2 메모리 영역은 선형 어드레스 범위를 공유하며,상기 제1 키는 제1 타깃 도메인에 대한 키이고 상기 제2 키는 제2 타깃 도메인에 대한 키이며, 상기 제1 타깃도메인들 또는 상기 제2 타깃 도메인들 중 하나 이상은 신뢰 도메인의 하위 도메인인, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:상기 복수의 함수의 함수 세트와 관련하여 불충분한 수의 보호 키 식별자들을 탐지하고;상기 불충분한 수의 보호 키 식별자들에 응답하여 호스트 컴퓨팅 디바이스에 페이지 테이블 엔트리를 업데이트하라고 지시하며 - 상기 함수 세트는 관리 런타임 함수들로 제한됨 -;상기 함수 세트의 원자적 실행을 시행하는, 반도체 장치."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제15항에 있어서, 상기 하나 이상의 기판에 결합된 로직은:소프트웨어 스레드가 하드웨어 논리 스레드에서 실행 중인지를 결정하고;상기 소프트웨어 스레드가 상기 하드웨어 논리 스레드에서 실행 중일 때 태그를 레지스터로 스와핑하며;상기 태그에 대한 캐시 용량 및 메모리 대역폭 중 적어도 하나를 설정하는, 반도체 장치.공개특허 10-2021-0076882-9-청구항 29 시스템으로서,메모리; 및상기 메모리에 결합된 프로세서를 포함하며, 상기 프로세서는 복수의 사용자로부터 수신된 하나 이상의 이벤트에 응답하여 컴퓨팅 시스템 내의 하나 이상의 아키텍처 서브시스템에서 복수의 함수를 실행하고 - 상기 하나 이상의 아키텍처 서브시스템은 상기 복수의 함수에 대한 실행 환경의 추상화 및 상기 복수의 함수와 연관된 복수의 컨테이너를 나타냄 -;상기 컴퓨팅 시스템 내의 하나 이상의 소프트웨어 및 오케스트레이션 서브시스템에 의한 상기 복수의 함수의 실행을 용이하게 하기 위해 상기 컴퓨팅 시스템의 복수의 컴퓨팅 리소스를 할당하며;상기 복수의 함수와 연관된 복수의 파라미터 및 상기 복수의 컴퓨팅 리소스와 연관된 복수의 파라미터를 분석하고;상기 복수의 함수, 및 상기 복수의 함수 및 상기 복수의 컴퓨팅 리소스와 연관된 상기 복수의 파라미터에 대한분석을 상기 컴퓨팅 시스템 내의 하나 이상의 네트워킹 및 저장 서브시스템에 저장하며 - 상기 복수의 함수 및상기 복수의 파라미터에 대한 분석을 저장하기 위한 위치들은 상기 복수의 함수 및 대응하는 상기 복수의 컴퓨팅 리소스 사이의 지역성을 향상시키고 함수 실행 레이턴시를 감소시키도록 선택됨 -;상기 컴퓨팅 시스템 내의 하나 이상의 보안 서브시스템에 의해 상기 복수의 함수의 실행을 보호하는로직을 포함하는, 시스템."}
{"patent_id": "10-2020-7037419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "방법으로서,복수의 사용자로부터 수신된 하나 이상의 이벤트에 응답하여 컴퓨팅 시스템 내의 하나 이상의 아키텍처 서브시스템에서 복수의 함수를 실행하는 단계 - 상기 하나 이상의 아키텍처 서브시스템은 상기 복수의 함수에 대한 실행 환경의 추상화 및 상기 복수의 함수와 연관된 복수의 컨테이너를 나타냄 -;상기 컴퓨팅 시스템 내의 하나 이상의 소프트웨어 및 오케스트레이션 서브시스템에 의한 상기 복수의 함수의 실행을 용이하게 하기 위해 상기 컴퓨팅 시스템의 복수의 컴퓨팅 리소스를 할당하는 단계;상기 복수의 함수와 연관된 복수의 파라미터 및 상기 복수의 컴퓨팅 리소스와 연관된 복수의 파라미터를 분석하는 단계;상기 복수의 함수, 및 상기 복수의 함수 및 컴퓨팅 리소스와 연관된 상기 복수의 파라미터에 대한 분석을 상기컴퓨팅 시스템 내의 하나 이상의 네트워킹 및 저장 서브시스템에 저장하는 단계 - 상기 복수의 함수 및 상기 복수의 파라미터에 대한 분석을 저장하기 위한 위치들은 상기 복수의 함수 및 대응하는 상기 복수의 컴퓨팅 리소스 사이의 지역성을 향상시키고 함수 실행 레이턴시를 감소시키도록 선택됨 -; 및상기 컴퓨팅 시스템 내의 하나 이상의 보안 서브시스템에 의해 상기 복수의 함수의 실행을 보호하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-7037419", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "시스템, 장치 및 방법의 실시예는 사용자, 예를 들면, 컴퓨터 개발자 및 클라우드 서비스 제공자(CSP)에게 향상 된 서비스형 함수(FaaS)를 제공한다. 그러한 향상된 FaaS 서비스를 제공하도록 구성된 컴퓨팅 시스템은 하나 이 상의 제어 아키텍처 서브시스템, 소프트웨어 및 오케스트레이션 서브시스템, 네트워크 및 저장 서브시스템, 및 (뒷면에 계속)"}
{"patent_id": "10-2020-7037419", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원에 대한 상호 참조 본 출원은 2018년 11월 8일자로 출원된 PCT 예비 특허 출원 제PCT/CN2018/114602호에 대한 우선권의 이익을 주 장한다."}
{"patent_id": "10-2020-7037419", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "서비스형 함수(Function as a Service)(FaaS)는 전형적으로 소량의 시간 동안 코드 실행 요청을 수신 및 실행하 기 위해 클라우드 컴퓨팅 인프라스트럭처에서 단일 목적 애플리케이션 프로그래밍 인터페이스(application programming interface)(API) 엔드포인트를 프로비저닝하는 이벤트 지향 고확장성 컴퓨터 코드 실행 모델이다. 그러한 코드 실행 요청 및/또는 요청된 코드의 실행은 다양하게 그리고 통상적으로 람다(lambda), 함수 (function), 액션(action) 및/또는 완전 실행(run-to-completion) 프로시저라고 지칭된다. 본 출원에서, 용어 \"함수(Function)\" 및/또는 \"함수(function)\"는, 그러한 실행이 소프트웨어로서 진행되든, 하드웨어에서 진행되 는 액션으로서 진행되든, 또는 이들의 임의의 조합이든 상관없이, 이러한 코드 실행 요청들 중 임의의 것 및 이 러한 요청의 실행을 지칭할 수 있다. 즉, 용어 \"함수\" 및 \"함수\"는, 본 명세서에서 사용되는 바와 같이, 달리 명시적으로 언급되고 그리고/또는 문맥을 통해 달리 암시되지 않는 한, 일반적으로 FaaS 함수를 지칭할 수 있다. 따라서 FaaS는 클라우드 컴퓨팅의 진화에서의 한 단계로 간주될 수 있다. 때때로 \"서버리스 컴퓨팅\"이 라고도 지칭되는, FaaS는 소프트웨어 개발자가 고확장성 코드를 작성할 수 있게 하지만 코드 실행이 수반할 하 드웨어 또는 애플리케이션 소프트웨어 리소스를 프로비저닝하거나 다른 방식으로 미리 정의하는 데 필요한 비용, 시간 및 자금 없이도 가능하게 한다. FaaS는 또한 클라우드 서비스 제공자(CSP)가 더 나은 할당(예를 들 면, 빈 패킹(bin packing))으로 인해 리소스 사용량(resource usage)을 증가시키게 할 수 있다. 컴퓨트 스케일 단위는 비즈니스 로직에 대한 집중이 증가하고 클라우드 스택 구현에 대한 관심/제어가 감소함에 따라 시간이 지남에 따라 변하고 있다. FaaS는 CLR(Common Language Runtime) 및 실행 컨텍스트 라이프사이클 과 같은 런타임 환경을 추상화한다. 사용자, 예를 들면, 애플리케이션 개발자 및 CSP는 FaaS를 통해 상당한 가 치를 확보할 수 있다. 예를 들어, 개발자는 고수준 언어를 사용하여 함수 코드와 같은 애플리케이션을 빌드하 고 실행을 위해 함수 코드를 FaaS 플랫폼에 업로드한다. 개발자는 FaaS 플랫폼을 자체적으로 호스팅하지 않고 이를 단순히 사용하며 FaaS 플랫폼의 인프라스트럭처는 사용자에게 불투명하다. CSP의 경우에, CSP는 그의 서비스형 함수 포트폴리오를 주요 차별화 요소로서 사용할 수 있지만, 상당한 개선의 여지가 여전히 있다. 예를 들어, 작성되어 클라우드에 배포된 함수 코드가 해당 순간에 CSP 제공 함수와 불가 분적으로 링크되기 때문에 \"전유적 잠김(proprietary lock-in)\"에 대한 우려가 남아 있다. 이러한 전유적 잠김 은 애플리케이션이 특정 클라우드 환경에 최적화된다는 것을 의미한다. 따라서, CSP들 간에 함수를 이동시키는 것은 CSP 제공 함수들 중 일부가 다른 CSP에 의해 지원되지 않는 상황을 초래하는 것 이외에 애플리케이션의 성 능 및 응답을 희생시킬 수 있다. 도 2a는 컴퓨터 애플리케이션 개발자에 의해 업로드된 서버리스 함수 코드를 수신하고 대응하는 이벤트에 의해 트리거된 함수 코드를 실행하는 서비스형 함수를 제공하기 위한 일반화된 기존 서버리스 서비스 플랫 폼을 예시한다. 서버리스 함수 코드의 애플리케이션 개발자는 서버리스 함수 코드가 서버리스 서비스 플랫폼에서 호출 및/또는 실행될 때에만 대응하는 금액을 지불할 수 있다. 도 2a에 도시된 바와 같이, 서버리스 서비스 플랫폼은 서버리스 함수 코드를 수신하고 서버리스 함수 코드를 스토리 지에 저장하며 컨테이너와 같은 필요한 컴퓨터 리소스를 사용하여 서버리스 함수 코드의 실행을 스케줄링 하는 서버리스 서비스 관리자(203a)를 갖는다. 서버리스 서비스 플랫폼은 CSP 네트워크의 엔드포인트들 사이에서 서버리스 함수 코드를 실행하는 것과 연관된 하나 이상의 이벤트를 트리거 및 라우팅하기 위한 네트워킹 및 메시징 모듈(203b)을 또한 포함할 수 있다. 서버리스 서비스 플랫폼은 보안 및 액세스 관리 자(203c) 및 하나 이상의 스토리지 서비스(203d)를 또한 포함할 수 있다. 보안 및 액세스 관리자(203c)는 서버 리스 함수 코드를 실행할 때 보안을 제공하는 역할을 한다. 예를 들어, 보안 및 액세스 관리자(203c)는 서버리스 함수 코드를 실행하는 것과 연관된 다양한 컴퓨터 리소스 및/또는 특권에 대한 액세스를 검증할 수 있다. 스토리지 서비스(203d)는 객체 스토리지(예를 들면, Amazon AWS' Lambda의 S3), 키-값 데이터베이스 (예를 들면, Amazon's AWS 서비스의 DynamoDB) 및/또는 전문 백엔드 서비스를 제공하는 모바일 백엔드 데이터베 이스(예를 들면, Google Cloud Functions의 Cloud Firestore)를 포함할 수 있다. 스토리지 서비스(203d)는 또 한 빅 데이터 질의(예를 들면, AWS Athena 및 Google BigQuery) 및 빅 데이터 변환(예를 들면, AWS Glue 및 Google Cloud Dataflow)을 포함한 빅 데이터 서비스를 가능하게 할 수 있다. 서버리스 서비스 플랫폼은 서버리스 서비스 아키텍처(203e)(예를 들면, AWS Lambda의 아키텍처, Google CloudPlatform의 아키텍처, 및/또 는 Azure Functions의 아키텍처), 및 하드웨어 지원 가상 머신, CPU, GPU 및 가속기와 같은 하나 이상의 하드웨 어 관련 요소를 통해 서버리스 서비스를 가능하게 한다. 도 2a에 도시된 것과 같은 기존 FaaS 솔루션에는 문제가 있다. 예를 들어, 기존 FaaS 솔루션은 전형적으로 미 성숙한 개발자 툴 에코시스템을 제공한다. 게다가, 기존 FaaS 솔루션은 코드를 실행하는 것 이외에 필요한 실 행 환경을 준비하는 것을 포함하는 예측할 수 없고 비용이 많이 드는 콜드 스타트를 빈번히 요구하며, 이것은높고 가변적이며 예측할 수 없는 레이턴시를 야기한다. 온 더 플라이 비디오 인코딩 애플리케이션을 예로 들면, 객체 저장소를 사용할 수 있는 기존 솔루션은 너무 느려서 세분화된(fine-grained) 통신을 지원하지 못하 고 그리고/또는 서버리스 함수 코드가 실행되기 전에 긴 레이턴시를 겪는다. 게다가, 기존 FaaS 솔루션은 현재 제한된 제어 및 코드 실행 상태 관리의 어려움을 겪고 있다. 대규모의 머신 러닝 트레이닝을 예로 들면, 도 2a에 도시된 것과 같은, 기존 FaaS 솔루션은 고속 및/또는 공유 메모리의 부족 은 물론, 네트워킹 연결성에 대한 충분한 지원의 부족으로 인해 바람직한 고 확장성을 달성하는 데 어려움에 직 면해 있다. 추가적으로, FaaS는 추가 추상화 계층을 도입하며, 이는, 기존 FaaS 솔루션에 의해 하드웨어 이질성을 지원하기 위한 컴퓨터 아키텍처와 같은, 독특한 및/또는 새로운 인프라스트럭처 특징을 프로세서, 플랫폼, 또는 시스템에 서 노출시켜 실행하는 것을 더 어렵게 만든다. 환언하면, 기존 FaaS 솔루션은 소프트웨어 개발을 추상화할 수 있지만, 그러한 추상화는 소프트웨어 코드를 실행하기 위해 하드웨어 아키텍처를 효율적으로 활용하는 데 어려 움을 초래할 수 있다."}
{"patent_id": "10-2020-7037419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 실시예에 따른 FaaS 컴퓨팅 환경을 도시한다. 개발자는 하나 이상의 컴퓨터 함수를 표현하는 함수 코드 (본 명세서에서 \"컴퓨터 코드\"라고도 지칭됨)를 작성하고, 함수 코드는, 예를 들어, CSP 데이터 센터 내의 FaaS 플랫폼에 업로드된다. 예를 들어, 사용 사례 또는 사물 인터넷(IoT) 이벤트와 같은 트리 거는 FaaS 플랫폼에서 함수 코드의 실행을 개시한다. 함수의 코드가 실행되는 환경은 컨테이너 라고 지칭된다. 컨테이너는 프로세스, Docker 또는 Kubernetes 컨테이너, 가상 머신 등과 같은 임의의 격리 실 행 엔티티일 수 있다. 자체 가상 머신에서 실행되는 컨테이너는 가상 컨테이너라고 지칭된다. FaaS 플랫폼 , 그의 데이터 센터, 에지 환경, 및 CSP가 제어할 수 있는 IoT(모바일을 포함함) 디바이스를 포함하는 CSP 데이터 센터 내에서, 인프라스트럭처는 \"스핀 업(spin up)\"(예를 들면, 활성화 및/또는 할당)되고 수요에따라 스케일링된다. 함수 코드는 CSP의 물리적 인프라스트럭처/에지/IoT 디바이스 및 기본 가상화된 컨테 이너에서 실행된다. 마지막으로, 인프라스트럭처는 실행이 완료된 것에 대한 응답하여 \"스핀 다운(spin down)\"(예를 들면, 비활성화 및/또는 할당해제)된다. 아래에서 더 상세히 논의될 것인 바와 같이, 본 명세서에서 설명된 기술은, 이벤트에 응답하여 온 디맨드로 함 수 코드를 실행하는 것 및 컴퓨트 스케일 단위로서 함수 코드를 그의 대응하는 함수와 함께 배포하는 원자적 스 케일 단위에 기초하여 이벤트의 수에 따라 자동으로 스케일링하는 것과 같은, 향상된 FaaS 특징을 제공함으로써 전유적 잠김, 비용이 많이 드는 콜드 스타트, 레이턴시, 및 코드 실행 상태의 관리/제어에 대한 우려를 감소시 킨다. 본 명세서에서 설명된 기술은 광범위한 향상을 가능하게 하여, 다양한 플랫폼을 허용하고 그리고/또는 하드웨어에서 직접적으로 및 표준 라이브러리 또는 런타임을 통해 보안을 가능하게 함으로써 앞서 언급한 우려 를 더욱 감소시킨다. 추가적으로, 본 명세서에서 설명된 기술은 새로운 실리콘 특징을 노출 및 실행하는 것을 더 쉽도록 한다. 개발자가 CSP FaaS 플랫폼에 의해 지원되는 더 높은 수준의 언어를 사용하여 애플리케이션을 빌드할 수 있게 하는 것 및 운영, 최적화, 유연성, 및 스케일링을 단순화하는 것에 의해, 본 명세서에서 설명된 기술은 추가로 비전문가 개발자가 하드웨어에서 제공되는 가속 능력으로부터 투명하게 이득을 보는 강건하고 고 성능이며 안전한 FaaS 솔루션을 달성할 수 있게 한다. 본 명세서에서 설명된 기술은 코딩을 더욱 단순화시키고 CSP FaaS 플랫폼에 의한 컴퓨트에 대한 더 많은 수요를 유도할 수 있다. 도 2b는 본 명세서에 설명된 바와 같은 향상된 FaaS 시스템의 컴포넌트(200a 및 200b)의 예를 도시한 다. 도 2a에 도시된 것과 같은 기존 FaaS 서비스와 연관된 문제와 비교하여, 향상된 FaaS 시스템은 고 확 장성 및 세분화된(granular) 빌링을 제공하면서 최소한의 관리를 요구하는, 이벤트 지향 실행 환경에서의 효율 적인 함수 코드 실행과 같은, 수많은 향상을 제공한다. 예시된 예에서, 이벤트 지향 컴포넌트(200a)는 이벤트 에 응답하여 온 디맨드로 함수 코드가 실행되는 것을 보장하고, 최소 관리 컴포넌트(200b)는 FaaS 서비스 제공 자에 의해 사용자(예를 들면, 코드 개발자)로부터 멀리 떨어져서 함수 코드를 실행하는 것의 인프라스트럭처 관 리를 추상화하며, 고 확장성 컴포넌트(200c)는 이벤트(예를 들면, 사용자 이벤트 또는 IoT 관련 이벤트)의 수에 따라 자동으로 함수 코드 실행을 스케일링하고, 원자적 스케일 단위 컴포넌트(200d)는 컴퓨트 스케일 단위로서 컴퓨터 코드를 그의 대응하는 함수와 함께 배포하며, 세분화된 빌링 컴포넌트(200e)는 고객(예를 들면, 컴퓨터 코드 개발자)이 자신의 코드가 실행될 때에만 지불할 수 있게 하고, 고객은, 예를 들어, 100 밀리초 증분으로 빌링된다. 아래에서 더 상세히 논의될 것인 바와 같이, 향상된 FaaS 시스템은 다른 유리한 컴포넌트를 또 한 포함할 수 있다. 따라서 사용자 및 CSP는 향상된 FaaS 시스템을 통해 상당한 가치를 확보할 것이다. 사용자의 경우 향상된 FaaS 시스템에 의해 제공되는 가치는, 예를 들어, 관심 동작의 개발에 대한 집중의 증가, 출시 시간(time to market)(TTM)의 감소, 인프라스트럭처 관리의 감소, 및 총 소유 비용(total cost of ownership)(TCO)의 감 소를 포함한다. CSP의 경우, 향상된 FaaS 시스템에 의해 제공되는 가치는, 예를 들어, 고수익 서비스 채 택의 유도, 컴퓨트 단위당 더 많은 수익을 내는 것, 새로운 클라우드 워크로드를 가능하게 하는 것, 개선된 비 용 상각, 컴퓨팅 리소스 스케줄링의 탄력성, 및 다른 CSP와 경쟁할 수 있는 능력을 제공하는 것을 포함한다. 실시예에서, 향상된 FaaS 시스템의 5개의 컴포넌트가 있다. 제1 컴포넌트는 함수를 생성하고 함수의 컴퓨 터 코드를 실행하는 함수 포맷 컴포넌트이다. 함수 포맷 컴포넌트의 일 예는 도 3에 예시된 바와 같은 FaaS 실 행기(310, 324, 319, 315)(아래에서 논의됨)이다. 제2 컴포넌트는 이벤트 호출을 함수로 라우팅하는 이벤트 핸 들링 API 프록시 컴포넌트이다. 이벤트 핸들링 API 프록시의 일 예는 도 4의 사용자 인터페이스 핸들러 (아래에서 논의됨)이다. 제3 컴포넌트는 함수 코드 패키지를 수신, 저장 및 보호하는 함수 코드 스토리지이다. 함수 코드 스토리지의 일 예는 도 4의 네트워크, 스토리지, 및 메모리 관리자(아래에서 논의됨)이다. 제4 컴포넌트는, 함수 코드가 다운로드되고 컨테이너 또는 다른 격리 실행 대안에서 인스턴스화되는 함수 실행 환경 을 제공하는, FaaS 컨테이너이다. FaaS 컨테이너의 일 예는 도 4의 FaaS 아키텍처(아래에서 논의됨)이다. 실행 후에, 컨테이너는 새로운 함수를 위해 와이핑(또는 리셋, 재초기화 등)된다. 컨테이너는 보안 및 격리를 위해 종종 가상 머신(VM) 내에서 실행된다. 마지막 코어 컴포넌트는 함수 코드에 대한 컨테이너를 스핀 업(예 를 들면, \"콜드 부트\")함으로써 이용 가능한 컴퓨트 리소스 내에서의 컨테이너 배치를 최적화하는 함수/컨테이 너 오케스트레이션 컴포넌트이다. 함수/컨테이너 오케스트레이션 컴포넌트의 일 예는 도 4의 오케스트레이터 (아래에서 논의됨)이다. 함수가 최근에 실행된 경우, 새로운 함수가 이미 \"웜\"인 컨테이너에 배치될 수 있어, 인스턴스화 레이턴시를 감소시킬 수 있다. 웜 컨테이너는 함수를 실행하기 위해 최근에 사용된 컨테이너, 또는 함수 실행에 자주 사용되는 컨테이너일 수 있다. 함수가 완료된 후에 컨테이너를 해체하기보다 는, 향후 함수 실행을 위해 컨테이너가 유지될 수 있다. 따라서, 컨테이너가 빌드될 필요가 없고 함수의 즉각적인 실행을 위한 준비가 되어 있다는 점에서 컨테이너는 \"웜\"인 것으로 간주될 수 있다. 도 3은 향상된 FaaS 성능을 사용자/CSP에 제공하기 위한 FaaS 서버 구성을 도시한다. 예시된 예시에서, FaaS 서버 구성은 향상된 FaaS 기판 상에 FaaS 관리 로직을 포함하는 스마트 네트워크 인터페이 스 카드(NIC)를 포함한다. 일부 실시예에서, 스마트 네트워크 인터페이스 카드는 FaaS 서버 구성 의 제어 센터로서 기능한다. FaaS 서버 구성은 오케스트레이션된 방식으로 다수의 함수 세트를 실행 하도록 구성된 하나 이상의 컴퓨터 코드 실행 유닛을 포함한다. 다른 실시예에서, FaaS 관리 로직 및 향 상된 FaaS 기판은 베이스보드 관리 제어기(baseboard management controller)(BMC)에서, 프로세서에서, 프로세서에서 실행되는 소프트웨어 모듈에서, 특수 함수 로직에서, 및/또는 이들의 임의의 조합으로 다양하게 구현될 수 있다. 예시된 예에서, 하나 이상의 중앙 프로세싱 유닛(CPU)(308a 내지 308n)(예를 들면, 호스트 프 로세서)은 FaaS 실행기를 사용하여 제1 함수 세트를 실행하고, 하나 이상의 가속기(314a 내지 314n) (예를 들면, 고정 기능 하드웨어 로직)은 제2 함수 세트를 실행하며, 하나 이상의 FPGA(field programmable gate array)(318a 내지 318n)는 제3 함수 세트를 실행하고, 하나 이상의 GPU(graphics processing unit)(318a 내지 318n)는 제4 함수 세트를 실행한다. 따라서, 예시된 FaaS 서버 구성은, GPU(322a 내지 322n), FPGA(318a 내지 318n), 및 특수 가속기(314a 내지 314n)를 포함하는, 특수 실리콘에 의해 작동(power)된다. FaaS 서버 구성은 다수의 CPU(308a 내지 308n), GPU(322a 내지 322n), FPGA(318a 내지 318n), 및 다른 특수 가속기(314a 내지 314n)를 포함할 수 있다. 특수 가속기(314a 내지 314n)가 서로 상이한 유형일 수 있다는 점은 주목할 가치가 있다. 예를 들어, 특수 가 속기(314a 내지 314n) 각각은 특정 함수 또는 프리미티브를 가속시키기 위해 특별히 설계될 수 있다(예를 들면, 머신 러닝(ML) 모델의 트레이닝 동안의 행렬 곱셈을 위해 특별히 설계된 가속기, 더 효율적인 전력 및 에너지 소비를 위한 가속기, 및/또는 특정 계산 및 데이터의 더 나은 보안 및 프라이버시를 위한 가속기). 유사하게, FaaS 서버 구성의 CPU(308a 내지 308n)는 서로 상이한 아키텍처일 수 있다(예를 들면, 상이한 벤더에 의해 제조되고 상이한 회로도(schematic)는 물론 아키텍처를 가짐). 예를 들어, 일부 실시예에서, CPU(308a 내지 308n)는 인텔 아키텍처, ARM(advanced reduced instruction set computer machine) 프로세서, MIPS(microprocessor without interlocked pipelined stages) 프로세서, 및 RISC-V(reduced instruction set computer-V) 프로세서 중 몇몇의 조합일 수 있다. 일부 실시예에서, CPU(308a 내지 308n) 모두는 동일한 아키 텍처를 가질 수 있다(예를 들면, 모두 인텔 아키텍처일 수 있음). 유사하게, GPU(322a 내지 322n)는 동일한 아 키텍처일 수 있거나 또는 서로 상이한 아키텍처일 수 있다(예를 들면, 상이한 벤더에 의해 제조되고 상이한 회 로도를 가짐). 유사하게, FPGA(318a 내지 318n)는 동일한 아키텍처일 수 있거나 또는 서로 상이한 아키텍처일 수 있다(예를 들면, 상이한 벤더에 의해 제조되고 상이한 회로도를 가짐). 게다가, 특수 가속기(314a 내지 314n)는 동일한 아키텍처일 수 있거나 또는 서로 상이한 아키텍처일 수 있다(예를 들면, 상이한 벤더에 의해 제 조되고 상이한 회로도를 가짐). 더욱이, 실행 유닛, CPU(308a 내지 308n), GPU(322a 내지 322n), FPGA(318a 내지 318n), 및 특수 가속기(314a 내지 314n)는 디지털 설계 이외에 아날로그 설계를 활용할 수 있다. FaaS 워크로드는, 예를 들어, 워크로드의 더 미세한(예를 들면, 증가된) 세분성 면에서, 전통적인 워크로드와 상이한 특성을 가질 수 있다. 워크로드의 증가된 세분성은 가속기(314a 내지 314n) 및 FPGA(318a 내지 318n)와 같은 특수 실리콘을 이용하는 것을 더 쉽도록 할 수 있다. 다수의 함수 세트를 분리(disaggregating)함으로써, FaaS 서버 구성은 CSP가 각각의 워크로드(예를 들면, 트랜스코딩, 추론, 특수 동작 등)를 가속기(314a 내 지 314n), FPGA(318a 내지 318n), CPU(308a 내지 308n), GPU(322a 내지 322n) 등과 같은 최적의 실리콘과 매칭 시킬 수 있게 한다. 도 3에 설명된 FaaS 서버 구성과 같은 FaaS 특정 하드웨어는 FaaS 성능 및 더 많은 사용자 및 CSP에 의한 채택을 개선시킬 수 있다. 향상된 FaaS 솔루션은 기존 솔루션과 비교하여 개선된 실행 특성을 위해 높은 정도의 유연성과 이질성을 제공한다. FaaS 서버 구성은 예시된 것보다 더 많은 또는 더 적은 컴포넌트를 포함할 수 있다. 예를 들어, 일 예에 서, FaaS 서버 구성은 제1 CPU(308a)와 같은 하나의 CPU를 포함할 수 있다. 다른 예에서, FaaS 서버 구 성은 제1 FPGA(318a)와 같은 하나의 FPGA 및 CPU(308a)와 같은 하나의 CPU를 포함할 수 있다. 또 다른 예에서, FaaS 서버 구성은 제1 가속기(314a)를 포함하고 CPU(308a 내지 308n) 중 어느 것도 포함하지 않는 다. 또 다른 예에서, FaaS 서버 구성은 다수의 CPU(308a 내지 308n), 다수의 GPU(322a 내지 322n), FPGA(318a)와 같은 하나의 FPGA, 및 상이한 유형의 다수의 특수 가속기(314a 내지 314n)를 포함한다. 이제 도 4를 살펴보면, 향상된 FaaS 시스템의 실시예가 도시되어 있다. 예시된 시스템은 사용자 인 터페이스 핸들러, 오케스트레이터, FaaS 아키텍처, 네트워크, 스토리지, 메모리 관리자 및보안 관리자를 포함한다. 실시예에서, 시스템은, 컨테이너/함수 실행 환경을 제공하는, FaaS 아키텍 처를 사용하여 실행될 FaaS 함수 코드를 수신한다. 예시된 시스템은 또한 사용자의 컴퓨터 코 드, 예를 들어, FaaS 함수 코드를 실행하기 위한 사용자 요청과 같은 시스템에 의해 수신된 하나 이 상의 FaaS 이벤트를 탐지한다. FaaS 이벤트에 응답하여, 대응하는 함수 코드가 다운로드되고 컨테이 너 또는 시스템의 다른 격리 실행 대안에서 인스턴스화된다. 사용자 인터페이스 핸들러는 이벤트 호 출을 컴퓨터 코드의 대응하는 함수로 라우팅하는 이벤트 핸들링 API 프록시이다. 오케스트레이터는 함수 코드에 대한 컨테이너 또는 다른 실행 엔진을 스핀 업함으로써 이용 가능한 컴퓨팅 리소스 내에서 (예를 들면, 컨테이너, 가상 머신, 프로세스 등에 의한 것이든 상관없이) 함수의 실행을 최적화한다. 함수가 최근에 컨테이너에서 실행된 경우, 컨테이너는 \"웜\" 컨테이너로서 마킹된다. 오케스트레이터는 이미 \"웜\"인 컨테이너(더 일반적으로는, 준비된 실행 엔진)에 새로운 함수를 배치하여, 인스턴스화 레이턴시를 감소 시킬 수 있다. 용어 \"컨테이너\"는, 본 명세서에서 사용되는 바와 같이, 함수 코드와 같은 코드를 위한 임 의의 형태의 실행 엔진으로 간주될 수 있다. 컨테이너는 프로세스, 프로세스 그룹, 가상 머신, 프로세스 어드 레스 공간 내의 샌드박싱된 환경, 가상 머신 내의 프로세스 등일 수 있다. 네트워크, 스토리지, 및 메모리 관 리자는 함수 코드를 수신하고 저장할 수 있으며, 함수 코드는 보안 관리자에 의해 보호된 다. 일 예에서, 보안 관리자는 컨테이너가 보안 및 격리를 위해 VM 내에서 실행되도록 보장한다. 오케스트레이터는 원격 측정 관리자, 프로파일 관리자, 머신 러닝/인공 지능(ML/AI) 어드바이저 , 및 서비스 수준 협약/서비스 품질(SLA/QoS) 관리자와 같은 서브컴포넌트를 또한 포함할 수 있다. 오케스트레이터는, 예를 들어, 도 13a 내지 도 13c의 실시예와 관련하여 설명되는 함수의 리소스 요구 및/ 또는 수요 프로파일, 도 24a 및 도 24b의 실시예와 관련하여 설명되는 바와 같은 함수의 정적 및 동적 프로파일 정보, 및 도 40a 및 도 40b와 관련하여 아래에서 설명되는 바와 같은 동적 프로파일과 같은, 데이터를 프로파일 링할 수 있다. 게다가, 원격 측정 관리자는 도 13a 내지 도 13c의 실시예에서 설명되는 바와 같은, 예를 들어, 메트릭 데 이터(예를 들면, 시간에 따른 캐시 사용량)와 같은, 함수의 리소스 요구 및/또는 수요 프로파일, 도 7a 내지 도 7c의 실시예와 관련하여 논의되는 바와 같은 함수의 실행 동안 발생하는 백그라운드 성능 모니터링 및 특정 성 능 원격 측정, 도 22의 실시예와 관련하여 설명되는 바와 같은 대역외(out-of-band)(OOB) 원격 측정, 도 24a 및 도 24b의 실시예와 관련하여 설명되는 바와 같은 원격 측정 및 프로파일 정보, 및 도 36a 및 도 36b의 실시예와 관련하여 설명되는 바와 같은 원격 측정 정보를 모니터링 및 기록할 수 있다. 더욱이, SLA/QoS 관리자는 도 21a 내지 도 21d의 실시예와 관련하여 설명되는 바와 같은 어드레스 기반 QoS, 서비스 클래스, 페이지 레벨 QoS 및/또는 스레드 레벨 QoS는 물론, 도 39a 내지 도 39c와 관련하여 설명되는 바와 같은 QoS 준수 실행, QoS 매니페스트 벡터, QoS 혼합, 보안 벡터 및/또는 QoS 사양을 결정하는 데 이용될 수 있다. 오케스트레이터, 원격 측정 관리자, 프로파일 관리자, ML/AI 어드바이저, 및 SLA/QoS 관 리자가 본 명세서에서 설명된 실시예들 중 임의의 실시예를 실행하기 위해 다양한 방식으로 조합되고 이용 될 수 있음이 이해될 것이다. 더욱이, 원격 측정 관리자, 프로파일 관리자, ML/AI 어드바이저, 및 SLA/QoS 관리자의 서브세트만이 오케스트레이터의 일부인 오케스트레이터의 상이한 배열이 사용될 수 있다. 일부 실시예에서, 향상된 FaaS 시스템은, 원격 측정 관리자를 사용하여, 실행 중인 함수와 연관된 원 격 측정 정보를 수집한다. 원격 측정 정보는 해당 함수에 관한 프로파일 정보의 일부로서 사용될 수 있으며, 프로파일 관리자에 의해 저장된다. SLA/QoS 관리자는 함수의 향후 호출의 요구사항(예를 들면, 시간 및/또는 비용 제약)을 충족시키면서 효율성을 향상시키기 위해 함수 실행을 상이한 실행 유닛에 매핑하는 것에 대한 조언 및/또는 지시를 ML/AI Advisor로부터 구하는 것 이외에 프로파일 관리자의 프로파일 정보 를 질의할 수 있다. 일 실시예에서, ML/AI 어드바이저는 이전에 관측된 시나리오에 기초하여 이상 탐지를 실행하고 적절한 액션을 취하며 그리고/또는 SLA/QoS 어드바이저에 조언할 수 있다. 오케스트레이터는 실행을 위한 FaaS 함수를 효율적으로 배치할 수 있다. 오케스트레이터에 내장된 알고리즘적 및 규칙 기반 메커니즘에 추가하여, ML/AI 어드바이저는 함수를 스케줄링함에 있어서 오케스트 레이터를 안내할 수 있다. FaaS 시스템의 연속적인 동작으로 인해, 엄청난 양의 \"원격 측정\" 데이터 가 원격 측정 관리자에 의해 수집될 수 있다. 그러한 원격 측정 데이터는 다양한 범위의 시스템에서 그리 고 상이한 시간/위치에서 함수의 실행 특성을 캡처할 수 있다. 원격 측정 정보는 CPU 이용률, 메모리 소비, 캐 시 계층 거동, I/O 및 네트워킹 거동, 실행의 시간/위치, 전력/에너지 소비, 함수 및 그의 데이터의 보안/프라 이버시 측면(예를 들면, 보안 요구사항 및 악의적 공격 탐지), 함수를 호출하는 사용자 및 애플리케이션, 함수에 의해 사용되는 파라미터 및 데이터 등과 같은 어트리뷰트를 포함할 수 있다."}
{"patent_id": "10-2020-7037419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "프로파일 관리자는 (실시간으로는 물론 오프라인으로) 수집된 원격 측정 정보를 프로세싱하고 정보의 요약 을 생성하며 함수 실행 거동의 상관관계 및 역상관관계(anti-correlation)를 찾을 수 있다. 오케스트레이터 는 이어서, 시간, 노드, 가속기 사용량 등과 같은, 함수 배치의 측면을 결정하기 전에 프로파일 관리자 는 물론 ML/AI 어드바이저에 질의할 수 있다. 예를 들어, 오케스트레이터는 2개 이상의 CPU 집약적 함수를 동일한 프로세서에 동시에 스케줄링하는 것을 방지할 수 있다. 그 대신에, 오케스트레이터는 메모리를 많이 사용하는(memory-hungry) 함수(예를 들면, 많은 양의 메모리를 필요로 하거나 많은 수의 프로세서 캐시 미스를 갖는 함수, 또는 둘 모두인 함수)를 갖는 CPU 집약적 함수를 동일한 프로세서에 스케줄링할 수 있다. 게다가, 오케스트레이터는 다수의 I/O 집약적 함수를 동일한 시스템에 동시에 스케줄링하는 것 등을 방지할 수 있다. 따라서, 오케스트레이터는 FaaS 서버의 리소스 소비가 균형을 이루도록 보장할 수 있다. 게다가, 오케스트레이터에 내장된 그러한 규칙에 추가하여, ML/AI 어드바이저는 원격 측정 관리자 에 의해 수집되고 프로파일 관리자에 의해 프로세싱되는 엄청난 양의 과거 정보로부터 자동으로 학습 할 수 있다. 예를 들어, 프로파일 관리자에 의해 수집되고 빌드된 ML 모델은 실행을 위한 함수의 배치를 자동으로 결정하는 데 ML/AI 어드바이저를 도울 수 있다. 예로서, 정보는 프로파일 관리자에 의해 수집되고 프로세싱된 가능한 ML 모델을 포함할 수 있다. ML 모델은 동일한 시스템에서 동시에 실행되는 특정 함수 집합체가 비정상적으로 열악한 실행 특성(예를 들면, 이상, 고 레이턴시 실행 등)을 결과할 것임을 보여줄 수 있다. 오케스트레이터는 그의 제어 하에서 모든 서버 상에서 실행되는 함수 및 그의 상태를 결정 및 기록할 수 있다. 오케스트레이터는 또한, FaaS 서버들의 서브세트를 각각 담당하는, 분산 오케스트레이터들의 집합 체일 수 있다. 새로운 함수가 실행을 위해 배치될 때, 오케스트레이터는 ML/AI 어드바이저에 질의하고 함 수의 배치에 대한 지침을 구할 수 있다. 그와 같이, 오케스트레이터는 \"적응적\"일 수 있다. 원격 측정 데이터가 원격 측정 관리자에 의해 지 속적으로 수집됨에 따라, 향상된 FaaS 시스템은 함수 실행 거동에 관해 지속적으로 학습할 수 있다. 이 양태는 향상된 FaaS 시스템이 이전에 FaaS 시스템에 의해 이전에 분석되지 않은 새로운 함수에 관해 자동으로 학습할 수 있게 하는 것은 물론 단계 변화(phase shift)(예를 들면, 그 중에서도 CPU 사용량, 메모리 소비, I/O 동작, 및 네트워크 상호작용의 변화와 같은 함수 실행 거동의 갑작스런 및/또는 상당한 변화) 및 계 절적 영향에 관해 학습할 수 있게 한다. 계절적 영향은 시간에서의 발생 및 빈도가 함수 실행 및 실행 특성에 영향을 미치는 외부 이벤트를 포함할 수 있다. 예를 들어, 계절적 영향에 의해 영향을 받는 함수는, 러시아워 또는 국경일 동안 더 자주 실행될 수 있는 거리 교통에 의해 구동되는, 인터넷 가능 GPS를 포함할 수 있다. 다 른 예는 정규 근무 시간 후에 비디오 콘텐츠의 스트리밍 애플리케이션을 실행하는 것을 포함할 수 있다. 예를 들어, 향상된 FaaS 시스템은 특정 함수 그룹의 실행을 위한 호출 또는 특정 데이터 세트에 대한 액세스의 대폭 증가가 갑자기 있는 것을 자동으로 탐지할 수 있다. 그러한 정보는 이어서 실행을 위해 더 많은 FaaS 서 버를 셋업하는 것 또는 데이터 센터로부터 네트워크 에지로를 포함하여 데이터를 함수 실행 위치에 더 가깝게 이동시키는 것 및/또는 분리된 메모리 아키텍처를 갖는 플랫폼에 더 많은 메모리를 할당하는 것을 결과할 수 있 다. 도 5는 서브시스템을 포함하는 향상된 FaaS 시스템의 실시예를 도시한다. 예시된 예에서, FaaS 시스템 은 사용자 경험 서브시스템, 보안 서브시스템, 소프트웨어 서브시스템(506a 내지 506c) 및 하드웨어 서브시스템(508a 내지 508d)을 포함한다. 소프트웨어 서브시스템은 라이브러리(506a), 프 레임워크(506b), 플랫폼 및 오케스트레이션 모듈(506c) 등을 포함할 수 있다. 추가적으로, 예시된 하드웨어 서 브시스템은 CPU(508a), GPU(508b), 메모리 및 스토리지(508c), 네트워킹 컴포넌트(508d), 가속기(508e) (예를 들면, FPGA) 등을 포함한다. 향상된 FaaS 시스템은 실행될 FaaS 함수 코드를 수신하고 하나 이상의 연관된 FaaS 이벤트에 응답하여 함수 코드를 실행한다. 따라서 향상된 FaaS 시스템은 특징 수익화를 위한 기회를 창출함으로써 더 다양한 시장에 적합하다. 통신 서비스 제공자(Communications Service Provider)(CoSP)와 같은 소규모 서비스 제공자 및 에지 로케이션(edge location)를 소유하는 지역 CSP의 경우, FaaS는 차세대 엔드 투 엔드 애플리케이션 및 서비스에의 더 큰 참여의 기회를 나타낸다. 많은 차세대 애플리케이션 및 서비스는 애플리케이션 또는 서비스의 일부가 소비자 또는 기 업 근처에서 실행되거나 제공되는 것을 필요로 할 수 있다. 이러한 에지 사이트에서 소규모 함수 포트폴리오를호스팅하는 것은 모든 DevOps(development and operations) 툴, API, 및 하이퍼스케일 CSP로부터 이용가능한 것과 같은 서비스를 갖는 풍부한 PaaS(Platforms as a Service)를 제공하는 것보다 소규모 플레이어에게 훨씬 더 쉬운 작업이다. 향상된 FaaS 시스템은 컴퓨팅 리소스의 테넌시(tenancy), 스케일 및 이용률을 증가시킴으로써 기존 FaaS 아키텍처를 개선시키고 FaaS 파라미터를 확장시킨다. FaaS는 클라우드 기반 기술의 개발을 위한 디폴트 모드가 될 가능성이 있어, 개발자를 백엔드 인프라스트럭처 유지 관리로부터 해방시키고 프로그래밍을 소수가 아닌 다 수에게 개방할 수 있다. 이러한 방식으로, 향상된 FaaS 시스템은 개발자에게 완전히 새로운 작업 방식을 제공할 수 있는 잠재력을 가지고 있다. 예를 들어, 예시된 시스템은 FaaS 제공자 오퍼링을 보강 및 확장 하는 소프트웨어를 지원 및/또는 직접적으로 제공한다. FaaS 서비스 제공자는 더 나은 툴을 사용하여 FaaS 채 택에 대한 더 낮은 장벽으로부터 이득을 보는 반면 사용자는 시스템에 의해 제공되는 증가된 사용 용이성 을 경험한다. 본 명세서에서의 특정 예가 FaaS 함수와 관련하여 논의되지만, 개념은, 예를 들어, 비-FaaS 컨테이너, 데스크톱 애플리케이션 등과 같은 다른 유형의 소프트웨어 구획(software compartment)에 더 광범위하게 적용 가능하다. 향상된 FaaS 아키텍처 향상된 FaaS 시스템(예를 들면, 도 4 및 도 5에 예시된 FaaS 시스템)은 또한 하드웨어 특징을 직접적으로 제어 하기 위해 소프트웨어 함수 및/또는 가속 함수(예를 들면, FPGA 또는 다른 구성 가능한 로직)을 사용하기 위한 사용자 레벨 능력을 제공할 수 있다. 그러한 접근법은 SSD(solid-state drive) 블록 디바이스를 백업하는 특권 유지 기능, 가속기에 대한 관리 기능 등에 유리할 수 있다. 함수가 오래 지속되지 않는 완전 실행 태스크이기 때문에, 함수의 하드웨어 사용에 대한 하드웨어 기반 제어는 다른 계층의 플랫폼 소프트웨어(예를 들면, 그에게 는 함수가 사용자 레벨 소프트웨어의 임의의 다른 함수와 구별될 수 없음)에 그러한 액세스를 중재하도록 요구 하는 것보다 더 높은 효율성과 투명성을 제공한다. 도 6a는 리소스 할당 및 제어를 위한 향상된 FaaS 아키텍처를 도시한다. 예시된 아키텍처에서, 제1 함수(\"F1\")는 CPU 컨테이너 내에서 실행될 코드 및 보안 증명 토큰을 포함한다. 예시된 제1 함수는 또한 사용자 레벨 능력 세트, 예를 들어, 사용자 레벨 능력(614, 618, 622, 626) 세트를 정의 하는 메타데이터와 연관된다. 일 예에서, 사용자 레벨 능력 세트는 컨테이너 외부의 하나 이상의 특 징에 대응한다. 예를 들어, OS 내의 특징은 메모리 관리, 시스템 호출 등, 또는 이들의 임의의 조합 을 포함할 수 있다. 추가적으로, VMM(가상 머신 모니터, 예를 들면, 하이퍼바이저) 내의 특징은 메 모리 관리, 디바이스 관리, 네트워크 재구성, 네트워크 경로에 대한 액세스, 가상 소프트웨어 재구성 등, 또는 이들의 임의의 조합을 포함할 수 있다. 일 실시예에서, CPU 내의 특징은 RDT(resource director technology) 모니터 카운터, RDT 캐시 및 메모리 제어, 플랫폼 서비스 품질 모니터 카운터, 플랫폼 서비스 품질 캐시 및 메모리 제어, 하드웨어 성능 모니터링 카운터, DRAM의 더 직접적인 제어, 3D XPoint, 저장 디바이스 등, 또는 이들의 조합을 포함한다. 더욱이, 가속기(예를 들면, FPGA) 내의 특징은 하드웨어 재구성, 비트스트림(예를 들면, FPGA 구현 이미지), 디바이스 리셋 등, 또는 이들의 임의의 조합을 포함한다. 함수와 연관된 보안 증명 토큰은 위조하기 불가능하지는 않지만 어려울 수 있으며, 제1 함수의 활성화의 어떤 열거 가능한, 발견 가능한 또는 검증 가능한 어트리뷰트에 연계될 수 있다. 따라서, OS 내 의 검증 모듈 및/또는 VMM 내의 검증 모듈이 보안 증명 토큰이 유효하다고 결정하는 경우, 제1 함수은 (예를 들면, 사용자 레벨 능력에 대응하는) 특징(614, 618, 622, 626)을 사용하도록 허용된다. 제1 함수로부터 예시된 곡선 화살표는 제1 함수가 컨테이너 내부에서 및 컨테이너 외부에 서 할 수 있는 다양한 호출을 나타낸다. 일 예에서, 허가형(permissioned) 특징은 예약될 수 없거나 VMM, OS 또는 다른 소프트웨어 \"이그제큐티브(executive)\"(예를 들면, 하이퍼바이저 호스트, 게스트 OS)에 의한 제1 함수에의 노출이 다른 방식으로 방지될 수 없다. 실제로, 아키텍처는, 확장(expansion)이 정확 성 위반(예를 들면, 프로토콜 및/또는 신택스 에러) 또는 보안 위반을 야기하지 않는 한, 사용자 레벨 능력 세 트를 확장(expand)/확대(extend)할 수 있다. 확장은, 예를 들어, OS/VMM 카운터의 필터링된 뷰, \"어피니타이제 이션(affinitization)\"과 같은 OS/VMM 동작에 대한 맞춤형 제어(예를 들면, VM과 호스트 사이의 관계를 확립하 는 선호도 규칙(affinity rules)을 시행함) 또는 메모리 계층화를 위한 정책 힌팅(policy hinting)을 포함할 수 있다. 그렇지만, 보안 증명 토큰이 유효하지 않다고 결정되는 경우, 아키텍처는 사용자 레벨 능력의 제1 함수에 의한 사용을 방지하고 디폴트 특징을 사용한 실행을 계속한다. 따라서, 제1 함수는 컨테 이너를 우회하기 위해 컨테이너 외부의 특징을 직접적으로 호출(예를 들면, 그에 명령)할 수 있다.도 6a에 예시된 가속기는 별도의 함수가 가속기를 재구성할 수 있게 하는 하나 이상의 가상 인터페이 스(632a 내지 632c)를 또한 포함한다. 일 예에서, 제1 함수는 제1 가상 인터페이스(632a)를 통해 가 속기를 재구성하고, 제2 함수(“F2”)는 통해 제2 가상 인터페이스(632b)를 통해 가속기를 재구 성하며, 제3 함수(“F3”)는 제3 가상 인터페이스(632c)를 통해 가속기를 재구성한다. 따라서 가상 인터페이스는 도 6a에 예시된 아키텍처와 같은 FaaS 아키텍처에서 SR-IOV(single-root IO virtualization) 및/또는 sRIO(serial rapid IO)의 사용을 가능하게 한다. 이제 도 6b를 살펴보면, 도 6b는 도 6a에 도시된 것과 같은 향상된 FaaS 아키텍처를 사용하여 사용자 레벨 능력 을 관리하는 방법을 예시한다. 방법은 일반적으로, 예를 들어, 이미 논의된, 시스템(도 2), 시 스템(도 3), 시스템(도 4), 및/또는 시스템(도 5)과 같은 향상된 FaaS 시스템에서 구현될 수 있 다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머 신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어 에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 컨테이너 내에서 실행되는 함수와 연관된 보안 증명 토큰을 탐지하기 위해 제공된 다. 예를 들어, 오케스트레이터가 함수를 함수 호출자(function invoker)에게 송신할 때 오케스트레이터는 요 구된 보안 증명 토큰을 제공한다. 게다가, 호출자는 그러한 보안 증명 토큰의 레지스트리를 유지할 수 있으며 프레임워크 의존적이다. 보안 증명 토큰은 호출자 또는 오케스트레이터 중 어느 하나에 의해 미리, 예를 들어, 함수가 개발자 또는 함수의 소비자에 의해 오케스트레이터에 등록될 때, 생성될 수 있다. 블록에서 서명의 검증 또는 다른 적용 가능한 방법에 의해 보안 증명 토큰이 유효한지에 대한 결정이 이루 어질 수 있다. 만약 그렇다면, 블록은 사용자 레벨 능력 세트의 함수에 의한 사용(예를 들면, 직접 액세 스)을 허용하고, 여기서 사용자 레벨 능력 세트는 컨테이너 외부의 하나 이상의 특징에 대응한다. 능력 세트는, 예를 들어, 자체 모니터링, 가상 공간의 일부에 대한 제어, 일정 범위의 페이지에 대한 판독 보호에 대 한 제어, 일정 범위의 페이지에 대한 기입 보호에 대한 제어, 영구 메모리에 저장된 객체에 대한 네임스페이스 의 확립, 메모리 관리, 시스템 호출 관리, 디바이스 관리, 네트워크 구성, 네트워크 경로에 대한 액세스, 가상 소프트웨어 재구성 등을 포함할 수 있다. 더욱이, 특징은 호스트 프로세서(예를 들면, CPU) 특징, OS 특징, 가 상 머신(예를 들면, VMM) 특징, 가속기 특징 등일 수 있다. 게다가, 특징은, 인텔® RDT(Resource Director Technology)와 같은 특정 기술 또는 GPU, ASIC, PCIe Hub, FPGA 등에 구현된 유사한 기술을 사용하여, (프로세 서 공유, 캐시 공유, I/O 처리량 공유, 가속기 공유 등과 같은) FaaS 아키텍처의 다양한 컴포넌트에 대한 세분 화된 예약 또는 우선순위화를 포함할 수 있다. 추가적으로, 블록에서 사용자 레벨 능력 세트의 확장이 정확성 위반(예를 들면, 프로토콜 및/또는 신택스 에러) 또는 보안 위반을 야기하는지에 대한 결정이 이루어질 수 있다. 만약 그렇지 않다면, 예시된 블록 은 확장이 정확성 또는 보안 위반을 야기하지 않는다는 결정에 응답하여 확장을 수행한다. 블록에서 확장 이 정확성 또는 보안 위반을 야기할 것이라고 결정되는 경우, 방법은 종료된다. 블록에서 보안 증명 토큰이 유효하지 않다고 결정되는 경우, 블록은 사용자 레벨 능력 세트의 함수에 의한 사용을 방지한다. 이제 도 6c를 살펴보면, 도 6c는 도 6a에 도시된 것과 같은 향상된 FaaS 아키텍처를 사용하여 사용자 레벨 능력 을 관리하는 방법을 예시한다. 방법은 일반적으로, 예를 들어, 이미 논의된, 시스템(도 2), 시 스템(도 3), 시스템(도 4), 및/또는 시스템(도 5)과 같은 향상된 FaaS 시스템에서 구현될 수 있 다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머 신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어 에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 함수와 연관된 보안 증명 토큰이 서명의 검증 또는 다른 적용 가능한 방법에 의해 유효하다고 결정하는 것을 제공한다. 함수는 컨테이너 내에서 실행될 수 있다. 블록은 함수가 하나 이상 의 이용 불가능한 리소스 및/또는 특징을 사용하고 그리고/또는 이에 대한 액세스를 요구하는지를 결정한다. 예를 들어, 블록은 리소스 또는 능력이 사용자 레벨에서 이용 가능하지 않고 그리고/또는 컨테이너에 이용 가능하지 않을 때 리소스 또는 능력이 이용 불가능하다고 결정할 수 있다. 능력 소스는, 예를 들어, 자체 모니 터링, 가상 공간의 일부에 대한 제어, 일정 범위의 페이지에 대한 판독 보호에 대한 제어, 일정 범위의 페이지 에 대한 기입 보호에 대한 제어, 영구 메모리에 저장된 객체에 대한 네임스페이스의 확립, 메모리 관리, 시스템호출 관리, 디바이스 관리, 네트워크 구성, 네트워크 경로에 대한 액세스, 가상 소프트웨어 재구성 등을 포함할 수 있다. 리소스는 호스트 프로세서(예를 들면, CPU) 특징, OS 특징, 가상 머신(예를 들면, VMM) 특징, 가속기 특징 등일 수 있다. 게다가, 능력 및/또는 리소스는, 인텔® RDT(Resource Director Technology)와 같은 기술 또는 GPU, ASIC, PCIe Hub, FPGA 등에 구현된 유사한 기술을 사용하여, (프로세서 공유, 캐시 공유, I/O 처리량 공유, 가속기 공유 등과 같은) FaaS 아키텍처의 다양한 컴포넌트에 대한 세분화된 예약 또는 우선순위화를 포함 할 수 있다. 만약 그렇다면, 블록은 사용자 레벨 액세스가 필요한, 필요한 리소스 및/또는 능력을 열거한다. 일부 실 시예에서, 블록은 사용자 레벨 리소스 및/또는 능력 세트의 확장이 정확성 위반(예를 들면, 프로토콜 및/ 또는 신택스 에러) 또는 보안 위반을 야기하는지에 대한 검사를 추가로 포함할 수 있고, 그렇게 하는 임의의 리 소스 및/또는 능력을 열거하지 않는다. 블록은 열거된 리소스 및/또는 능력을 추가한다. 예를 들어, 블 록은 열거된 리소스 및/또는 능력을 함수의 컨테이너에 일시적으로 추가한다. 일시적인 추가는 함수의 지 속기간 동안 유지된다. 블록은 열거된 리소스 및/또는 능력에 대한 사용자 레벨 액세스를 가능하게 한다. 블록이 실행된 후에 또는 함수가 임의의 이용 불가능한 리소스 및/또는 함수를 사용하지 않는 경우, 예시 된 블록은 임의의 선택적인 추가 리소스 및/또는 능력이 인에이블되어야 하는지를 결정한다. 블록은 성능에 유익하거나 단순성을 향상시키는 선택적인 추가 리소스 및/또는 능력(예를 들면, 페이지를 핀 다운(pin down)하고 스레드를 어피니타이징(affinitize)하는 능력 등)을 나타내는 테이블을 조회한다. 만약 그렇다면, 블록은 선택적인 추가 리소스 및/또는 능력을 열거할 수 있다. 이미 위에서 설명된 바와 같이, 블록(67 4)은 특정의 선택적인 추가 리소스 및/또는 능력이 열거되고 사용자 레벨 액세스가 허용되는 경우 정확성 위반 (예를 들면, 프로토콜 및/또는 신택스 에러) 또는 보안 위반이 발생할 것인지를 결정하기 위해 추가로 검사를 실행한다. 특정의 선택적인 추가 리소스 및/또는 능력에 대해 보안 또는 정확성 위반이 발생하는 경우, 특정의 선택적인 추가 리소스 및/또는 능력이 열거되지 않는다. 그와 같이, 블록는 안전하고 안정적인 선택적인 추가 리소스 및/또는 능력만을 열거할 것이다. 즉, 보안 문제를 야기하지 않고 또한 시스템의 안정적인 기능에 대한 위험(예컨대, 데드록(deadlock), 라이브록(livelock), 스타베이션(starvation) 등)을 초래하지 않는 선택 적인 추가 리소스 및/또는 능력만이 열거될 것이다. 블록은 함수 실행의 지속기간 동안 안전하고 안정적 인 추가 리소스 및/또는 능력에 대한 사용자 레벨 액세스를 허용한다. 블록이 완료된 후에, 방법이 종료된다. 블록이 어떠한 추가의 능력 및 리소스도 인에이블되지 않는 다고 결정하는 경우, 방법은 종료된다. 방법(640 및 660)이 함께 수정 및 조합될 수 있다는 점은 주목할 가치가 있다. 예를 들어, 박스(664, 666, 668, 670, 672, 674, 676)는 박스(646, 648, 650) 중 하나 이상으로 대체될 수 있다. 추가 비고 및 예 예 601은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 컨테이너 내에서 실행되는 함수와 연 관된 보안 증명 토큰을 탐지하게 하고, 보안 증명 토큰이 유효한 경우 사용자 레벨 능력 세트의 함수에 의해 사 용을 허용하게 하며, 보안 증명 토큰이 유효하지 않은 경우 사용자 레벨 능력 세트의 함수에 의한 사용을 방지 하게 하게 하는 컴퓨터 실행 가능 프로그램 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체 를 포함하고, 여기서 사용자 레벨 능력 세트는 컨테이너 외부의 하나 이상의 특징에 대응한다. 예 602는 예 601의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 프로그램 명령어는, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 보안 증명 토큰이 유효한 경우 사용자 레벨 능력 세트의 적어도 하나의 확장을 수행하게 하고, 여기서 보안 증명 토큰은 정확성 위반 또는 보안 위반을 야기하지 않는 경우 유효하다. 예 603은 예 601의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 사용자 레벨 능력 세트는 자 체 모니터링, 가상 공간의 일부에 대한 제어, 일정 범위의 페이지에 대한 판독 보호에 대한 제어, 일정 범위의 페이지에 대한 기입 보호에 대한 제어, 영구 메모리에 저장된 객체에 대한 네임스페이스의 확립, 메모리 관리, 시스템 호출 관리, 디바이스 관리, 네트워크 재구성, 네트워크 경로에 대한 액세스, 및 가상 소프트웨어 재구성 을 포함하는 그룹으로부터 선택된다. 예 604는 예 601의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 하나 이상의 특징은 호스트 프로세서 특징, 운영 체제 특징, 가상 머신 특징 및 가속기 특징을 포함하는 그룹으로부터 선택된다. 도 7a는 다양한 vPMU(virtual power performance monitoring unit) 이벤트가 컨테이너 내에서의 함 수의 실행 동안 함수 또는 컨테이너 레벨에서 모니터링되는 FaaS 컴퓨트 노드를 도시한다. 이벤트는 네스팅된(nested) 모니터링을 가능하게 하는 아키텍처 인터페이스(예를 들면, 하드웨어 및/또는 소프트웨 어)를 통해 모니터링하도록 구성될 수 있다. 네스팅과 관련하여, 모니터링은 가상 머신 게스트에서, 베어 메탈 (bare metal) 운영 체제에서 또는 베어 메탈 컨테이너에서 행해질 수 있는 동일한 방식으로 컨테이너 내에서 또 는 심지어 함수 내에서 행해질 수 있다. 환언하면, 어떤 아키텍처 이벤트(예를 들면, 실행된 명령어의 수, 조 우된 캐시 미스의 횟수 등)를 측정하는 능력 또는 소프트웨어 이벤트 카운터(예컨대, 페이지 폴트의 횟수, 페이 지 인(page in) 또는 페이지 아웃(page out)된 페이지, 수신 또는 전송된 패킷의 수 등)를 샘플링하는 능력은 카운터가 판독되는 곳에 의존하지 않는다. 더욱이, 해당 판독치에 대한 해당 특정 레벨(예를 들면, 함수, 컨테 이너, 게스트 OS, 호스트 OS 등)의 기여도를 반영하는 판독치를 획득하기 위해 각각의 레벨에서 측정이 가능하 다. 예시된 예에서, 이벤트는 실행된 시간, IPC(instructions per cycle), 메모리 대역폭, 캐시 사용량, IOPs(I/O operations per second) 및 네트워크 대역폭을 포함하지만, 다른 이벤트가 또한 모니터링/수집될 수 있다. 모니터링될 이벤트의 프로그래밍은 시스템 소프트웨어 능력을 통해 통합될 수 있다. 일 예에서, 예를 들어, 컨테이너 및/또는 호스트 머신에 의해 제공되는 vPMU 드라이버는 이벤트의 통합을 수행한 다. 더 상세히 논의될 것인 바와 같이, 이벤트는 다양한 가상 PMU 카운터(예를 들면, 다른 카운터를 미러 링하는 \"섀도(shadow)\" 카운터)를 통해 추적될 수 있다. 예를 들어, 시간 t0에서, 컨테이너에서의 함수의 실행과 연관된 카운터 값의 제1 스냅숏이 생성 된다. 유사하게, 시간 tn에서 카운터 값의 제2 스냅숏이 생성될 수 있고, 시간 tn+1에서 카운터 값의 제3 스냅숏이 생성될 수 있으며, 이하 마찬가지이다. 카운터 값은 일반적으로 이벤트들 중 하나 이상을 정량화할 수 있으며, 여기서 스냅숏(706, 708, 710)은 새로운 명령어, 새로운 인터페이스 호출 등에 응답하여 생성될 수 있다. 스냅숏(706, 708, 710)을 하드웨어로 구현하는 것은 소프트웨어 오버헤드를 최소화할 수 있다. 스냅숏(706, 708, 710) 중 하나 이상은 소프트웨어 네스팅의 더 깊은 레벨에 있는 다른 이미 존재하는 스냅숏의 다른 부분을 미러링하는 섀도 스냅숏일 수 있다. 스냅숏(706, 708, 710) 및/또는 스냅숏들(706, 708, 710) 사이의 차이(예를 들면, 델타)는 vPMU 버퍼에 저장되며, vPMU 버퍼는 함수에 대한 스크래 치패드 영역(scratchpad area)으로서 동작할 수 있다. 예시된 예에서, vPMU 버퍼는 API 엔드포인트 (예를 들면, 하이퍼 텍스트 전송 프로토콜/HTTP 엔드포인트)를 통해 함수, 오케스트레이터 또는 노드 관리자 중 하나 이상에 노출된다. 따라서 예시된 솔루션은 각각의 함수 호출에 대해 제한된 메모리 리소스를 제공하는 FaaS 인프라스트럭처에서 용량 또는 대역폭 면에서 스타베이션을 방지하는 데 사용될 수 있다. 더 상세하게는 그리고 예로서, 함수(71 4)의 개발자는 스냅숏(706, 708, 710)을 통해 OS 메트릭, 메모리 캐시 및 메모리 액세스 통계치 등을 획득하도 록 vPMU를 프로그래밍함으로써 함수가 메모리 페이지 스와핑 또는 캐시 스레싱(cache thrashing)을 조우하 는지 및 얼마만큼 조우하는지를 모니터링할 수 있다. 추가적으로, 다수의 노드 레벨 vPMU가 분산된 vPMU로 구 성될 수 있다. 이제 도 7b를 살펴보면, 함수의 실행과 연관된 제1 메트릭 데이터(예를 들면, 원격 측정 스냅숏 및/ 또는 스냅숏들 사이의 차이)가 함수 및 컨테이너 소프트웨어에 제공되는 vPMU 버퍼가 도시되어 있다. 예시된 예에서, 컨테이너 소프트웨어는 제1 메트릭 데이터(예를 들면, 시간에 따른 캐시 사용 량)의 집계를 수행하고 집계에 기초하여 제2 메트릭 데이터를 생성한다. 추가적으로, 함수는 제1 메 트릭 데이터를 수집 및 프로세싱하여 제3 메트릭 데이터를 생성할 수 있다. 이제 도 7c를 살펴보면, 함수의 성능을 모니터링하는 방법이 도시되어 있다. 방법은 일반적으로, 예 를 들어, 이미 논의된, 시스템(도 2), 시스템(도 3), 시스템(도 4), 및/또는 시스템(도 5)과 같은 향상된 FaaS 시스템에서 구현될 수 있다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세 트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 실행의 제1 시점에서 컨테이너에서의 함수의 실행과 연관된 카운터 값의 제1 스냅 숏을 생성하기 위해 제공되며, 여기서 카운터 값의 제2 스냅숏은 블록에서 실행의 제2 시점에서 생성된다. 일 예에서, 블록은 제1 스냅숏, 제2 스냅숏 또는 제1 스냅숏과 제2 스냅숏 사이의 차이 중 하나 이상을 vPMU 버퍼에 저장한다. 추가적으로, vPMU 버퍼는 블록에서 API 엔드포인트를 통해 함수, 오케스트레이터또는 노드 관리자 중 하나 이상에 노출될 수 있다. 따라서 본 명세서에서 설명된 기술은 함수 개발자가, 백그라운드 성능 모니터링을 통해, 함수의 실행 동안 발생 하는 특정 성능 원격 측정을 구분(demarcate)하기 위해 컨테이너 또는 임의의 다른 실행 엔진과 협력하여 작업 할 수 있게 한다. 따라서, 이벤트 지향, 최소 관리, 고 확장성, 원자적 스케일 단위 및 세분화된 빌링 전부가 달성될 수 있다. 이는 추가로 수집된 스냅숏 데이터의 특권에 적절한 보기(privilege-appropriate view)를 허 용한다. 예를 들어, 함수 코드를 호스팅하는 컨테이너 소프트웨어 모듈은 개발자 제공 모듈에 가려져 있는 일 부 이벤트를 관측 및/또는 식별할 수 있다. 예를 들어, 상이한 아키텍처로 인해, 함수 코드가 개발자 제공 모 듈에서 호스팅될 때는 특정 경향을 나타내지 않을 수 있지만, 컨테이너 소프트웨어 모듈 내부에서 호스팅될 때 는 해당 특정 경향을 나타낼 수 있다. 따라서, 본 명세서에서의 기술은 개발자에 의해 직접적으로 액세스 가능 하지 않은 플랫폼에서(예를 들면, 개발자가 플랫폼에서 함수 코드를 개발 및/또는 디버그하지 않았음) 세분화된 성능 추적을 가능하게 한다. 일부 실시예에서, FaaS 시스템(예를 들면, 오케스트레이터 또는 스케줄러)은 더 효율적인 스케줄링 및 할당을 위해 수집된 스냅숏 데이터를 사용할 수 있다. 추가 비고 및 예 예 701은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 컨테이너 내에서의 함수의 실행과 연 관된 카운터 값의 제1 스냅숏을 생성하게 하고, 컨테이너 내에서의 함수의 실행과 연관된 카운터 값의 제2 스냅 숏을 생성하게 하며, 제1 스냅숏, 제2 스냅숏 또는 제1 스냅숏과 제2 스냅숏 사이의 차이 중 하나 이상을 vPMU(virtual performance monitoring unit) 버퍼에 저장하게 하는 실행 가능 프로그램 명령어 세트를 포함하 는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 702는 예 701의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 프로그램 명령어는, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 애플리케이션 프로그램 인터페이스(application program interface)(API) 엔드포인트를 통해 가상 PMU 버퍼를 함수, 오케스트레이터 또는 노드 관리자 중 하나 이상에 노출시키게 한다. 공유 메모리 예 일부 실시예는 유리하게도 코어 내(in-core) 메시지, 시스템 내(in-system) 메시지, 플랫폼 내(in-platform) 메시지 및/또는 머신 메시지 통신을 위한 버퍼 확장을 제공할 수 있다. HTTP를 통한 종래의 함수간(inter- function) 통신은 협업 함수가 동일한 코어, 동일한 시스템, 동일한 플랫폼 및/또는 공유 메모리를 갖는 임의의 실행 유닛에 공존하는 경우 필요한 것보다 많은 오버헤드를 수반할 수 있다. 일부 실시예는 2개의 협업 함수가 2개의 함수 사이에서 교환되는 데이터의 콘텐츠를 복사하기 위한 메모리 세그먼트를 공유할 수 있게 하기 위해 공유 메모리를 제공할 수 있다. 유리하게도, 일부 실시예는 OS 커널 및 다른 HTTP 계층을 우회함으로써 함수간 통신 오버헤드를 방지할 수 있다. 이제 도 8a를 살펴보면, 전자 프로세싱 시스템의 실시예는 프로세서, 프로세서에 통신 가능하게 결합된 메모리, 및 제1 과도 함수와 제1 과도 함수와 협업하는 제2 과도 함수 간에 메모리의 메모리 영역을 공유하기 위해 프로세서 및 메모리에 통신 가능하게 결합된 로직을 포함할 수 있다. 일 부 실시예에서, 로직은, 제1 과도 함수 및 제2 과도 함수와 같은, FaaS 플랫폼의 협업 과도 함수들 사이의 코어 내, 시스템 내, 플랫폼 내 및/또는 머신 메시지 통신을 위한 버퍼 확장을 제공하도록 추가로 구성될 수 있 다. 일부 실시예에서, 로직은 공유 메모리 영역을 사용하여 제1 과도 함수와 제2 과도 함수 사이에서 데 이터를 교환하도록 구성될 수 있다. 예를 들어, 로직은 교환된 데이터를 call 명령어 및 return 명령어 중 적어도 하나와 동기화시키도록 구성될 수 있다. 일부 실시예에서, 로직은, (예를 들면, 동일한 다이 상의) 프로세서, 메모리 등을 포함한, 다양한 컴포넌트에 위치되거나 그와 공존할 수 있다. 상기 프로세서, 메모리, 로직, 및 시스템의 다른 컴포넌트들 각각의 실시예는 하드웨어, 소프트웨어 또는 이들의 임의의 적합한 조합으로 구현될 수 있다. 예를 들어, 하드웨어 구현은, 예를 들어, PLA(programmable logic array), FPGA(field programmable gate array), CPLD(complex programmable logic device)와 같은 구성 가능한 로직, 또는, 예를 들어, ASIC(application specific integrated circuit), CMOS(complementary metal oxide semiconductor) 또는 TTL(transistor-transistor logic) 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 이들 컴포넌트의 전부 또는 일부는 하나 이상의 모듈에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM(random access memory), ROM(read only memory), PROM(programmable ROM),펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현 될 수 있다. 예를 들어, 컴포넌트의 동작을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언 어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 운영 체제(OS)에 적용 가능한/적절한 프로 그래밍 언어의 임의의 조합으로 작성될 수 있다. 예를 들어, 메모리, 영구 저장 매체, 또는 다른 메모리 는, 프로세서에 의해 실행될 때, 시스템으로 하여금 시스템의 하나 이상의 컴포넌트, 특징, 또 는 양태(예를 들면, 로직, 메모리 영역을 공유하는 것, 버퍼 확장을 제공하는 것, 데이터를 교환하는 것 등)를 구현하게 하는 명령어 세트를 저장할 수 있다. 적합한 프로세서의 실시예는 범용 프로세서, 특수 목적 프로세서, CPU, GPU, 제어기, 마이크로컨트롤러, 커널, 실행 유닛 등을 포함할 수 있다. 이제 도 8b를 살펴보면, 반도체 패키지 장치의 실시예는 하나 이상의 기판, 및 하나 이상의 기판 에 결합된 로직을 포함할 수 있으며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현된다. 하나 이상의 기판에 결합된 로직은 제1 과도 함 수와 제1 과도 함수와 협업하는 제2 과도 함수 간에 메모리 영역을 공유하도록 구성될 수 있다. 일부 실시예에 서, 로직은 FaaS 플랫폼의 협업 과도 함수들 사이의 코어 내, 시스템 내 및/또는 플랫폼 내 머신 메시지 통신을 위한 버퍼 확장을 제공하도록 추가로 구성될 수 있다. 일부 실시예에서, 로직은 공유 메모리 영역 을 사용하여 제1 과도 함수와 제2 과도 함수 사이에서 데이터를 교환하도록 구성될 수 있다. 예를 들어, 로직 은 교환된 데이터를 call 명령어 및 return 명령어 중 적어도 하나와 동기화시키도록 구성될 수 있다. 일 부 실시예에서, 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함할 수 있다. 로직 및 장치의 다른 컴포넌트의 실시예는, 적어도 부분적으로 하드웨어로 구현하는 것을 포함하여, 하드웨어, 소프트웨어, 또는 이들의 임의의 조합으로 구현될 수 있다. 예를 들어, 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어, 또는 이들의 임의의 조합을 포함할 수 있다. 추가적으로, 이들 컴 포넌트의 일부는 하나 이상의 모듈에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있 다. 예를 들어, 컴포넌트의 동작을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종 래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조 합으로 작성될 수 있다. 장치는 방법(도 8c)의 하나 이상의 양태, 또는 본 명세서에서 논의된 실시예들 중 임의의 실시예를 구현할 수 있다. 일부 실시예에서, 예시된 장치는 하나 이상의 기판(예를 들면, 실리콘, 사파이어, 갈륨 비화물) 및 기판(들)에 결합된 로직(예를 들면, 트랜지스터 어레이 및 다른 집적 회로/IC 컴포 넌트)을 포함할 수 있다. 로직은 적어도 부분적으로 구성 가능한 로직 또는 고정 기능 로직 하드웨어로 구현될 수 있다. 일 예에서, 로직은 기판(들) 내에 배치된(예를 들면, 매립된) 트랜지스터 채널 영 역을 포함할 수 있다. 따라서, 로직과 기판(들) 사이의 계면은 계단형 접합(abrupt junction)이 아 닐 수 있다. 로직은 또한 기판(들)의 초기 웨이퍼 상에 성장되는 에피택셜 층을 포함하는 것으로 간 주될 수 있다. 이제 도 8c를 살펴보면, 다수의 FaaS 함수 사이에서 메모리를 공유하는 방법의 실시예는 블록에서 제 1 과도 함수에 대한 메모리 영역을 할당하는 단계, 및 블록에서 제1 과도 함수와 제1 과도 함수와 협업하 는 제2 과도 함수 간에 메모리 영역을 공유하는 단계를 포함할 수 있다. 방법의 일부 실시예는 블록(83 3)에서 FaaS 플랫폼의 협업 과도 함수들 사이의 코어 내 머신 메시지 통신을 위한 버퍼 확장을 제공하는 단계를 추가로 포함할 수 있다. 방법의 일부 실시예는 블록에서 FaaS 플랫폼의 과도 함수들 사이의 노드 내 머신 메시지 통신을 위한 버퍼 확장을 제공할 수 있다. 방법은 블록에서 공유 메모리 영역을 사용하 여 제1 과도 함수와 제2 과도 함수 사이에서 데이터를 교환하는 단계를 또한 포함할 수 있다. 예를 들어, 방법 은 블록에서 교환된 데이터를 call 명령어 및 return 명령어 중 적어도 하나와 동기화시키는 단계를 포함할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능 한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어,또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴 퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작을 수 행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프로그래 밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하 여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 예를 들어, 방법은 아래의 예 814 내지 예 817과 관련하여 설명된 바와 같이 컴퓨터 판독 가능 매체 상에 구현될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API)를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가 적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 이제 도 8d를 살펴보면, 다수의 FaaS 함수 사이에서 메모리를 공유하는 방법의 실시예는 블록에서 제 1 과도 함수에 대한 메모리 영역을 할당하는 단계, 및 블록에서 제1 과도 함수와 제1 과도 함수와 협업하 는 제2 과도 함수 간에 메모리 영역을 공유하는 단계를 포함할 수 있다. 방법의 일부 실시예는 블록(87 6)에서 FaaS 플랫폼의 협업 과도 함수들 사이의 시스템 내 및/또는 플랫폼 내 머신 메시지 통신을 위한 버퍼 확 장을 제공하는 단계를 추가로 포함할 수 있다. 방법은 블록에서 공유 메모리 영역을 사용하여 제1 과도 함수와 제2 과도 함수 사이에서 데이터를 교환하는 단계를 또한 포함할 수 있다. 예를 들어, 방법은 블록에서 교환된 데이터를 call 명령어 및 return 명령어 중 적어도 하나와 동기화시키는 단계를 포함할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능 한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴 퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작을 수 행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프로그래 밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하 여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 예를 들어, 방법은 아래의 예 814 내지 예 817과 관련하여 설명된 바와 같이 컴퓨터 판독 가능 매체 상에 구현될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API)를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가 적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 일부 실시예에서, 방법에 설명된 바와 같이 동일한 머신에 있고 메모리 기반 전송을 사용하는 2개의 협업 함수 사이의 데이터의 전달은 통신을 수행하는 프로세스 또는 스레드가 커널에 들어가야 해야 하는 것을 요구하 지 않으며, 따라서 이들은 사용자의 애플리케이션으로부터의 데이터 교환을 달성할 수 있다. 게다가, 새로운 명령어는 필요한 데이터 교환을, 사용자 레벨에서 안전하게, 수행할 수 있다. 즉, 명령어가 (커널 특권보다 훨 씬 더 큰) 하드웨어 특권으로 동작하도록 설계될 수 있으며, 따라서 함수의 실행은 하나의 함수의 컨테이너로부 터 다른 함수의 컨테이너로 데이터를 복사하는 권한을 갖기 때문이다. 대안적으로, 실제 복사는 펌웨어에서 또 는 OS 내의 헬퍼 스레드(helper thread)에서 수행될 수 있지만, 펌웨어 또는 헬퍼 스레드를 활성화시키기 위해 커널 모드에서 함수를 송신 및 수신하는 것을 요구하지 않는 새로운 명령어에 의해 시작될 수 있다. 이제 도 8e를 살펴보면, 향상된 FaaS 시스템의 실시예는 2개의 협업 FaaS 함수(841 및 842)(예를 들면, 함 수 A 및 함수 B), 및 2개의 FaaS 함수(841 및 842) 간의 협업을 용이하게 하도록 구성될 수 있는 공유 메모리 를 포함할 수 있다. 일부 실시예는 유리하게도 FaaS 함수(841 및 842) 간의 머신 메시지/JSON 통신을 위한 버퍼/ISA 확장을 제공할 수 있다. 일부 FaaS 아키텍처는 HTTP를 통한 함수간 통신을 위해 JSON과 같은 표준 데이터 교환 포맷을 사용할 수 있다. 협업 FaaS 함수가 스케줄러에 의해 동일한 머신(예를 들면, 코어 또는 호 스트)에 공존할 때, 함수간 통신은 OS 커널 및 다른 HTTP 계층을 거칠 필요가 없다. 일부 실시예에서, 공유 메 모리는 2개의 함수(841, 842)가 2개의 함수(841, 842) 사이에서 교환되는 데이터의 콘텐츠를 복사하기 위 해 메모리 세그먼트를 공유하게 하는 것에 의해 통신 방식을 제공할 수 있다. 예를 들어, 피호출자 함수 (callee function)가 호출되기 직전에, 호출자 함수(caller function)에 의해 전달된 파라미터는 호출자로부터 공유 메모리로 복사될 수 있다. 피호출자가 리턴(return)된 후 응답/JSON 객체 콘텐츠가 공유 메모리로부터 호 출자로 복사될 수 있다. 동기화는 call 명령어 및 return 명령어를 통해 자연스럽게 발생할 수 있다. 이제 도 8f를 살펴보면, 함수 색인 버퍼(FLB)의 실시예는 2개의 협업 FaaS 함수(f 및 g)에 대한 엔트리를 포함할 수 있다. 통신이 공유 메모리(예를 들면, 또는 내부 버퍼)를 통해 발생해야 하는지 종래의 HTTP/커널 루트를 통해 발생해야 하는지는 호출자가 피호출자에 로컬/근접(예를 들면, 코어 내, 시스템 내, 플랫폼 내 및/ 또는 공유 메모리를 갖는 실행 유닛)인지를 검사하고 이어서 해당 검사의 값에 기초하여 분기하여 데이터를 패 킹/복사를 위한 적절한 코드를 실행함으로써 결정될 수 있다. 이 검사의 속도를 높이기 위해, FLB는 함께 공존하는 함수의 프로세스/람다 ID를 캐싱하는 데 사용될 수 있는 TLB(translation look-aside buffer)와 유사 한 하드웨어 구조를 포함할 수 있다. 함수가 페이지 테이블 엔트리와 유사하게 이동함에 따라 지역성 (locality) 정보가 업데이트될 수 있고 함수가 호스트로부터 제거될 때 캐시 내의 임의의 상주 엔트리(resident entry)가 무효화된다. 이제 도 8g를 살펴보면, 향상된 FaaS 시스템의 실시예는 2개 이상의 서버(863, 864, 865)와 통신하는 오케 스트레이터를 포함할 수 있다. 함수 코드(F1 내지 F9)는, F1, F4, F5, F6, 및 F8 간의 협업을 통해, 서 버(863, 864, 865) 간에 분산될 수 있다. F4, F5, 및 F6이 동일한 서버에 공존하기 때문에, 일부 실시예 는 유리하게도 F4, F5, 및 F6 간의 협업을 용이하게 하기 위해 서버 상의 공유 메모리를 활용할 수 있다. 일부 실시예는 더 나은 빈 패킹 및/또는 지역성 최적화를 위해 어떤 함수가 어떤 서버에서 실행되고 있는지의 그래프 기반 표현을 활용할 수 있다. 일부 실시예는 또한 교차 함수 통신 패턴의 그래프 기반 표현을 활용할 수 있다. 예를 들어, 노드들에 걸친 호출 체인(call chain)은 그래프 기반 표현으로서 공유될 수 있다. 일부 실시예에서, OS는 함수 호출 API를 함수에 노출시킬 수 있다. 예를 들어, API 프레임워크는 이용 가능한 경우 네트워크 통신 대신에 함수 호출을 위해 OS API를 사용할 수 있다. 유리하게도, API 프레임워크는 원격 호출을 위해 네트워크에 비해 더 효율적인 전송을 제공할 수 있다. 일부 실시예는 모든 함수를 전역적(globa l)이고 RDMA(remote direct memory access) 액세스 가능하게 만들기 위해 128 비트 어드레스를 활용함으로써 네트워크를 피할 수 있다. 시스템(도 8a), 장치(도 8b), 방법(도 8c), FaaS 시스템(도 8d), FLB(도 8e), 및/또 는 FaaS 시스템(도 8f)의 실시예 또는 양태/특징은 FaaS 플랫폼(도 1), 향상된 FaaS 시스템(도 2), FaaS 서버 아키텍처(도 3), 향상된 FaaS 시스템(도 4), 및/또는 향상된 FaaS 시스템(도 5)의 전부 또 는 일부로 대체되거나 그 내에 통합될 수 있다. 예를 들어, 다양한 실시예의 소프트웨어 컴포넌트(예를 들면, 함수 코드, 로직의 양태 등)는 FaaS 소프트웨어 서브시스템(도 5)에 통합될 수 있고, 다양한 실시예의 하 드웨어 컴포넌트(예를 들면, 공유 메모리, FLB, 로직의 양태 등)은 FaaS 하드웨어 서브시스템(도 5)에 통 합될 수 있다. 추가 비고 및 예 예 800은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 제1 과도 함수와 제1 과도 함수와 협 업하는 제2 과도 함수 간에 메모리의 메모리 영역을 공유하게 하고, 128 비트 어드레스를 활용하게 하며, 제1 및 제2 과도 함수에 대해 함수 호출 인터페이스를 노출시키게 하고, 제1 및 제2 과도 함수를 포함하는 그래프 기반 표현을 생성하게 하는 실행 가능 프로그램 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 801은 전자 프로세싱 시스템을 포함하고, 이 전자 프로세싱 시스템은 프로세서, 프로세서에 통신 가능하게 결합된 메모리, 및 제1 과도 함수와 제1 과도 함수와 협업하는 제2 과도 함수 간에 메모리의 메모리 영역을 공 유하기 위해 프로세서 및 메모리에 통신 가능하게 결합된 로직을 포함한다. 예 802는 예 801의 시스템을 포함하고, 여기서 로직은 추가로 서비스형 함수 플랫폼의 협업 과도 함수들 간의 머신 메시지 통신을 위한 버퍼 확장을 제공한다.예 803은 예 801 및 예 802 중 어느 한 예의 시스템을 포함하고, 여기서 로직은 추가로 공유 메모리 영역을 사 용하여 제1 과도 함수와 제2 과도 함수 사이에서 데이터를 교환한다. 예 804는 예 803의 시스템을 포함하고, 여기서 로직은 추가로 교환된 데이터를 call 명령어 및 return 명령어 중 적어도 하나와 동기화시킨다. 예 805는, 하나 이상의 기판 및 하나 이상의 기판에 결합된 로직을 포함하는, 반도체 패키지 장치를 포함하며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현되고, 로 직은 제1 과도 함수와 제1 과도 함수와 협업하는 제2 과도 함수 간에 메모리의 메모리 영역을 공유하기 위해 하 나 이상의 기판에 결합된다. 예 806은 예 805의 장치를 포함하고, 여기서 로직은 추가로 서비스형 함수 플랫폼의 협업 과도 함수들 간의 머 신 메시지 통신을 위한 버퍼 확장을 제공한다. 예 807은 예 805 및 예 806 중 어느 한 예의 장치를 포함하고, 여기서 로직은 추가로 공유 메모리 영역을 사용 하여 제1 과도 함수와 제2 과도 함수 사이에서 데이터를 교환한다. 예 808은 예 807의 장치를 포함하고, 여기서 로직은 추가로 교환된 데이터를 call 명령어 및 return 명령어 중 적어도 하나와 동기화시킨다. 예 809은 예 805 내지 예 808 중 어느 한 예의 장치를 포함하고, 여기서 하나 이상의 기판에 결합된 로직은 하 나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함한다. 예 810은 메모리를 공유하는 방법을 포함하고, 이 방법은 제1 과도 함수에 대한 메모리 영역을 할당하는 단계, 및 제1 과도 함수와 제1 과도 함수와 협업하는 제2 과도 함수 간에 메모리의 메모리 영역을 공유하는 단계를 포 함한다. 예 811은 예 810의 방법을 포함하며, 서비스형 함수 플랫폼의 협업 과도 함수들 간의 머신 메시지 통신을 위한 버퍼 확장을 제공하는 단계를 추가로 포함한다. 예 812는 예 810 및 예 811 중 어느 한 예의 방법을 포함하고, 공유 메모리 영역을 사용하여 제1 과도 함수와 제2 과도 함수 사이에서 데이터를 교환하는 단계를 추가로 포함한다. 예 813은 예 812의 방법을 포함하며, 교환된 데이터를 call 명령어 및 return 명령어 중 적어도 하나와 동기화 시키는 단계를 추가로 포함한다. 컨테이너 추측 실행 예 일부 실시예는 유리하게도 컨테이너 런 어헤드 추측 실행을 제공할 수 있다. 일부 함수는 긴 레이턴시/기동 (latency/startup)을 수반하며, 이는 실행을 느려지게 할 수 있다. 일부 실시예는 프로세서/코어 레벨에서 데 이터/명령어 스트림을 페치하고 또한 리소스를 예약 및/또는 재할당하기 위한 런 어헤드 실행 메커니즘을 제공 할 수 있다. 유리하게도, 일부 실시예는 런 어헤드 능력을 이용할 수 있는 함수에 대한 레이턴시/기동을 감소 시킬 수 있다. 제한이 아닌 설명으로서, 런 어헤드는 프로세서가 스톨링(stalling) 대신에 캐시 미스 사이클 동안 명령어를 (예를 들면, 추론적으로(speculatively)) 계속 실행할 수 있게 하는 기술을 의미할 수 있다. 추측 실행은 유휴 실행 리소스를 사용하여 명령어/캐시 미스가 달리 발생하기 전에 명령어/캐시 미스를 탐지하여 명령어 및 데이 터 스트림 프리페치를 생성하는 데 사용될 수 있다. 관리 가능한 비용은 레지스터 파일 상태를 보존하고 추측 저장이 메모리를 수정하는 것을 방지하기 위해 추측 실행 지원을 제공하는 것을 포함할 수 있다. 일부 FaaS 함수는 데이터베이스에 질의하는 것, 다른 FaaS 서비스를 호출하는 것 등과 같은 가변 길이(예를 들 면, 일부 긴) 레이턴시 동작의 차단을 수행하는 것으로부터 이익을 얻을 수 있다. 일부 실시예는 (예를 들면, 데이터베이스에 액세스하기 위한 대역폭을 예약하는 것, 잠재적으로 호출될 컨테이너/FaaS 함수를 워밍업하는 것, 컨테이너/FaaS 함수를 현재 함수에 근접하게 재배치하는 것 등과 같은) 프로세서/코어 레벨에서 데이터/명 령어 스트림을 페치하고 또한 리소스를 예약/재할당하기 위해 런 어헤드 실행 기술을 제공할 수 있다. FaaS 환경에서 그러한 능력을 가능하게 하기 위해, 일부 실시예는 프로세서 레벨에서 추측 실행을 지원하는 카 피 온 라이트(copy on write) 기술, 및 또한 (예를 들면, 외부 함수 호출, 데이터베이스 업데이트 등과 같은) 외부에서 보이는 동작을 리소스를 예약/재할당하기 위한 적절한 매칭하는 동작으로 대체하는 런타임 루틴을 제공할 수 있다. 일부 실시예는 함수에 키를 태깅하기 위해 다중 키 전체 메모리 암호화(multi-key total memory encryption)(MKTME)를 활용할 수 있다. 예를 들어, 일부 실시예는 MKTME를 사용하여 RDMA를 갖는 자유 추측 사 이드 채널(free speculation side channel)을 제공할 수 있다. 일부 실시예에서, 프로그래머는 런 어헤드 추측 실행을 수행할지 여부에 관한 힌트를 데이터 구조를 통해 표시할 수 있다. 일 실시예에서, 도 8a와 관련하여 설명된 것과 같은 전자 프로세싱 시스템은 FaaS 관련 정보를 페치하기 위해 런 어헤드(run ahead)하고, 페치된 FaaS 관련 정보에 기초하여 하나 이상의 가변 길이 레이턴시 동작을 차단하 도록 구성된다. 일부 실시예에서, 전자 프로세싱 시스템은 페치된 FaaS 관련 정보에 기초하여 리소스를 예약 및/또는 재할당하도록 추가로 구성될 수 있다. 추가적으로 또는 대안적으로, 전자 프로세싱 시스템은 리소스를 예약 및 재할당하는 것 중 하나 이상을 하기 위해 하나 이상의 외부에서 보이는 동작을 대응하는 매칭하는 동작 으로 대체하도록 추가로 구성될 수 있다. 일부 실시예에서, 로직, 프로세서, 메모리 등과 같은 다양한 컴포넌 트는 서로에(예를 들면, 동일한 다이에) 위치되거나 공존할 수 있다. 다른 실시예에서, 도 8b에 예시된 반도체 패키지 장치와 동일하거나 유사한 반도체 패키지 장치는 하나 이상의 기판, 및 하나 이상의 기판에 결합된 로직을 포함할 수 있으며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현된다. 하나 이상의 기판에 결합된 로직은 FaaS 관련 정 보를 페치하기 위해 런 어헤드하고, 페치된 FaaS 관련 정보에 기초하여 하나 이상의 가변 길이 레이턴시 동작을 차단하도록 구성될 수 있다. 일부 실시예에서, 로직은 페치된 FaaS 관련 정보에 기초하여 리소스를 예약 및/또 는 재할당하도록 추가로 구성될 수 있다. 추가적으로 또는 대안적으로, 로직은 리소스를 예약 및 재할당하는 것 중 하나 이상을 하기 위해 하나 이상의 외부에서 보이는 동작을 대응하는 매칭하는 동작으로 대체하도록 추 가로 구성될 수 있다. 일부 실시예에서, 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함할 수 있다. 이제 도 9a를 살펴보면, 서비스형 함수를 제공하는 방법의 실시예는 블록에서 FaaS 관련 정보를 페치 하기 위해 런 어헤드하는 단계, 및 블록에서 페치된 FaaS 관련 정보에 기초하여 하나 이상의 가변 길이 레 이턴시 동작을 차단하는 단계를 포함할 수 있다. 방법의 일부 실시예는 블록에서 페치된 FaaS 관련 정보에 기초하여 리소스를 예약 및/또는 재할당하는 단계를 추가로 포함할 수 있다. 추가적으로 또는 대안적으 로, 방법은 블록에서 리소스를 예약 및 재할당하는 것 중 하나 이상을 하기 위해 하나 이상의 외부에 서 보이는 동작을 대응하는 매칭하는 동작으로 대체하는 단계를 또한 포함할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능 한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴 퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작을 수 행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프로그래 밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하 여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 예를 들어, 방법은 아래의 예 931 내지 예 933과 관련하여 설명된 바와 같이 컴퓨터 판독 가능 매체 상에 구현될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API)를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가 적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 이제 도 9b를 살펴보면, 향상된 FaaS 시스템의 실시예는 리소스 관리자에 통신 가능하게 결합된 스트 림 페치 모듈을 포함할 수 있다. 스트림 페치 모듈은 실행될 함수의 FaaS 관련 정보를 페치하기 위 해 런 어헤드하는 기술을 포함할 수 있다. 리소스 관리자는 페치된 FaaS 관련 정보에 기초하여 하나 이상 의 가변 길이 레이턴시 동작을 차단하는 기술을 포함할 수 있다. 일부 실시예에서, 리소스 관리자는 페치 된 FaaS 관련 정보에 기초하여 리소스를 예약 및/또는 재할당하도록 추가로 구성될 수 있다. 추가적으로 또는 대안적으로, 리소스 관리자는 리소스를 예약 및 재할당하는 것 중 하나 이상을 하기 위해 하나 이상의 외부에서 보이는 동작을 대응하는 매칭하는 동작으로 대체하도록 추가로 구성될 수 있다. 시스템의 일부 실 시예는 유리하게도 (예를 들면, FaaS 환경에서) 컨테이너 런 어헤드 추측 실행을 제공할 수 있다. 이제 도 9c를 살펴보면, 향상된 FaaS 시스템의 실시예는 일부 FaaS 함수의 추측 실행을 포함할 수 있다. 사용자는 다수의 이미지, 예를 들면, img1.jpg 내지 imgN.jpg를 포함하는 웹 페이지를 디스플레이하 기 위해 브라우저를 사용할 수 있다. 사용자는 FaaS 시스템을 통해 이미지 회전 함수을 통해 웹 페이지의 하나 이상의 이미지를 회전시킬 수 있다. FaaS 시스템은 하나 이상의 이미지(예를 들면, img1.jpg 내지 imgN.jpg)를 회전시킬 가능성이 있는 사용자 의도를 결정할 수 있고 이미지를 하나 이상의 대안적인 배향으로 추론적으로 회전시킬 수 있다. 예를 들어, FaaS 시스템은 더 나은 사용자 경험 및/또 는 성능 메트릭을 위해 이미지 배향의 사용 패턴/시퀀스를 탐지하고 다양한 회전 함수를 사전에 론칭할 수 있다. 추측 실행은 사용자의 관점에서 이미지를 회전시키는 레이턴시를 크게 감소시킬 수 있다. 시스템, 장치, 방법(도 9a), FaaS 시스템(도 9b), 및/또는 FaaS 시스템(도 9c)의 실시예 또는 양태/특징은 FaaS 플랫폼(도 1), 향상된 FaaS 시스템(도 2), FaaS 서버 아키텍처(도 3), 향상 된 FaaS 시스템(도 4), 및/또는 향상된 FaaS 시스템(도 5)의 전부 또는 일부로 대체되거나 그 내에 통합될 수 있다. 예를 들어, 다양한 실시예의 소프트웨어 컴포넌트(예를 들면, 스트림 페처, 리소스 관리자, 함수 코드, 로직의 양태 등)는 FaaS 소프트웨어 서브시스템(도 5)에 통합될 수 있고, 다양한 실시예의 하드웨어 컴포 넌트(예를 들면, 다양한 큐/버퍼, 로직의 양태 등)은 FaaS 하드웨어 서브시스템(도 5)에 통합될 수 있다. 추가 비고 및 예 예 900은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 적어도 하나의 함수의 FaaS 관련 정보 를 페치하기 위해 런 어헤드하게 하고, 페치된 FaaS 관련 정보에 기초하여 하나 이상의 가변 길이 레이턴시 동 작을 차단하게 하며, 다중 키 전체 메모리 암호화를 사용하여 함수에 키를 태깅하게 하고, 이미지 관련 정보를 탐지하게 하며, 탐지된 이미지 관련 정보에 기초하여 이미지 동작을 사전에 론칭하게 하는 실행 가능 프로그램 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 901은 전자 프로세싱 시스템을 포함하고, 이 전자 프로세싱 시스템은 프로세서, 프로세서에 통신 가능하게 결합된 메모리, 및 적어도 하나의 함수의 FaaS 관련 정보를 페치하기 위해 런 어헤드하고, 페치된 FaaS 관련 정 보에 기초하여 하나 이상의 가변 길이 레이턴시 동작을 차단하기 위해 프로세서 및 메모리에 통신 가능하게 결 합된 로직을 포함한다. 예 902는 예 901의 시스템을 포함하고, 여기서 로직은 추가로 페치된 FaaS 관련 정보에 기초하여 리소스를 예약 및 재할당하는 것 중 하나 이상을 한다. 예 903은 예 901 및 예 902 중 어느 한 예의 시스템을 포함하고, 여기서 로직은 추가로 리소스를 예약 및 재할 당하는 것 중 하나 이상을 하기 위해 하나 이상의 외부에서 보이는 동작을 대응하는 매칭하는 동작으로 대체한 다. 예 904는, 하나 이상의 기판 및 하나 이상의 기판에 결합된 로직을 포함하는, 반도체 패키지 장치를 포함하며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현되고, 로 직은 적어도 하나의 함수의 FaaS 관련 정보를 페치하기 위해 런 어헤드하고, 페치된 FaaS 관련 정보에 기초하여 하나 이상의 가변 길이 레이턴시 동작을 차단하기 위해 하나 이상의 기판에 결합된다. 예 905는 예 904의 장치를 포함하고, 여기서 로직은 추가로 페치된 FaaS 관련 정보에 기초하여 리소스를 예약 및 재할당하는 것 중 하나 이상을 한다. 예 906은 예 904 및 예 905 중 어느 한 예의 장치를 포함하고, 여기서 로직은 추가로 리소스를 예약 및 재할당 하는 것 중 하나 이상을 하기 위해 하나 이상의 외부에서 보이는 동작을 대응하는 매칭하는 동작으로 대체한다. 예 907은 예 904 내지 예 906 중 어느 한 예의 장치를 포함하고, 여기서 하나 이상의 기판에 결합된 로직은 하 나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함한다. 예 908은 서비스형 함수를 제공하는 방법을 포함하고, 이 방법은 적어도 하나의 함수의 FaaS 관련 정보를 페치 하기 위해 런 어헤드하는 단계, 및 페치된 FaaS 관련 정보에 기초하여 하나 이상의 가변 길이 레이턴시 동작을 차단하는 단계를 포함한다. 예 909는 예 908의 방법을 포함하며, 페치된 FaaS 관련 정보에 기초하여 리소스를 예약 및 재할당하는 것 중 하 나 이상을 하는 단계를 추가로 포함한다. 예 910은 예 908 및 예 909 중 어느 한 예의 방법을 포함하고, 리소스를 예약 및 재할당하는 것 중 하나 이상을 하기 위해 하나 이상의 외부에서 보이는 동작을 대응하는 매칭하는 동작으로 대체하는 단계를 추가로 포함한다. 플랫폼 피드백, 다중 버전 함수, 및 비동기 함수 예 종래의 FaaS 호출은 함수를 호출하는 일부 최종 트리거를 포함하여, 다수의 트리거를 수반할 수 있다. 함수가 호출된 후에, 작업은 일부 컨테이너를 갖는 플랫폼으로 디스패치된다(예를 들면, 새로 시작됨, 워밍업됨, 기 타). 그러나 새로운 호출을 지원하는 데 사용되는 리소스가 너무 적을 수 있다. 누적된 레이턴시는 함수의 실 행을 지연시킬 수 있다. 종래의 트리거링 메커니즘은, 선행 작업(antecedent)으로부터 함수 호출로, 단방향으 로 흐르며, 이는 FaaS 시스템 자체의 능력과 외부 리소스 간에 최적화하는 것을 어렵게 만들 수 있다. 일부 FaaS 시스템에서, 가속 함수에 대한 시작 시간(startup time)은 함수를 실행하는 것의 레이턴시를 증가시킨다. 다른 문제는 FaaS 데이터/액션이 분리된 시스템들에 걸쳐 동기화하기 어려울 수 있다는 것이다. 완전 동기 액 션은 후속 함수를 호출하기 전에 호출 함수가 태스크의 완료를 기다리는 것을 필요로 한다. 호출 함수에 대한 리소스는 대기하느라 묶여 있다. 향상된 FaaS 시스템의 일부 실시예는 플랫폼이 다음 함수 호출을 위해 성숙되어(ripe) 있음을 나타내는, 함수를 실행하는 플랫폼으로부터의 피드백을 트리거링 메커니즘에 제공한다. 일부 실시예는 또한 필요한 리소스/조건 에 대한 사전 통지를 제공할 수 있으며, 일부 통지는 그러한 리소스가 이용 가능하거나 이용 가능할 것으로 예 상될 때 및 그러한 조건이 충족될 때 플랫폼으로부터 반환된다(예를 들면, 풀(pull) 대 푸시(push)). 일부 실 시예는 또한 가속 함수가 기동되는 동안 사용될 수 있는 가속 함수의 대안적인 형태를 제공함으로써 가속 함수 에 대한 시작 시간을 숨길 수 있다. 일부 실시예에서, 일부 함수는 서비스 체이닝을 지원하기 위해 비동기인 것으로 식별될 수 있다. 유리하게도, 일부 실시예는 리소스 스타베이션을 방지하고, 리소스의 더 나은 이용을 제공하며, 그리고/또는 함수 실행에서 더 적은 레이턴시(예를 들면, 또는 겉보기 레이턴시(apparent latency)) 를 경험할 수 있다. 예를 들어, 일부 실시예는 체이닝된 함수를 디스패치한 후에(예를 들면, 함수를 더 원자적 이고 더 모듈적(modular)으로 만든 후에) 호출 함수를 해제할 수 있다. 일 실시예에서, 도 8a와 관련하여 설명된 것과 동일하거나 유사한 전자 프로세싱 시스템은 프로세서, 프로세서 에 통신 가능하게 결합된 메모리, 및 후속 함수 호출에 대한 요청을 트리거 에이전트로부터 수신하고, 후속 함 수 호출에 대한 준비 완료(readiness)를 나타내는 피드백을 트리거 에이전트에 제공하기 위해 프로세서 및 메모 리에 통신 가능하게 결합된 로직을 포함할 수 있다. 대안적으로 또는 추가적으로, 로직은 가속 함수가 기동되 는 동안 사용될 수 있는 가속 함수의 하나 이상의 대안적인 형태를 제공하도록 구성될 수 있다. 대안적으로 또 는 추가적으로, 로직은 서비스 체인을 지원하기 위해 하나 이상의 함수를 비동기인 것으로 식별하도록 구성될 수 있다. 일부 실시예에서, 로직은, (예를 들면, 동일한 다이 상의) 프로세서, 메모리 등을 포함한, 다양한 컴 포넌트에 위치되거나 그와 공존할 수 있다. 다른 실시예에서, 도 8b와 관련하여 설명된 것과 동일하거나 유사한 반도체 패키지 장치는 하나 이상의 기판, 및 하나 이상의 기판에 결합된 로직을 포함할 수 있으며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨 어 로직 중 하나 이상에 적어도 부분적으로 구현된다. 하나 이상의 기판에 결합된 로직은 후속 함수 호출에 대 한 요청을 트리거 에이전트로부터 수신하고, 후속 함수 호출에 대한 준비 완료를 나타내는 피드백을 트리거 에 이전트에 제공하도록 구성될 수 있다. 대안적으로 또는 추가적으로, 로직은 가속 함수가 기동되는 동안 사용될 수 있는 가속 함수의 하나 이상의 대안적인 형태를 제공하도록 구성될 수 있다. 대안적으로 또는 추가적으로, 로직은 서비스 체인을 지원하기 위해 하나 이상의 함수를 비동기인 것으로 식별하도록 구성될 수 있다. 일부 실시예에서, 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함할 수 있다. 이제 도 10a를 살펴보면, 서비스형 함수를 제공하는 방법의 실시예는 블록에서 후속 함수 호출에 대한 요청을 트리거 에이전트로부터 수신하는 단계, 및 블록에서 후속 함수 호출에 대한 준비 완료를 나 타내는 피드백을 트리거 에이전트에 제공하는 단계를 포함할 수 있다. 대안적으로 또는 추가적으로, 방법 은 블록에서 가속 함수가 시작되는 동안 사용될 수 있는 가속 함수의 하나 이상의 대안적인 형태를 제공하는 단계를 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 블록에서 서비스 체인을 지원하기 위해 하나 이상의 함수를 비동기인 것으로 식별하는 단계를 포함할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 예를 들어, 방법은 아래의 예 1011 내지 예 1013과 관련하여 설명된 바와 같이 컴퓨터 판독 가능 매체 상 에 구현될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그 래밍 인터페이스(API)를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 플랫폼 피드백 예 이제 도 10b를 살펴보면, 향상된 FaaS 시스템의 실시예는 클라이언트에 (예를 들면, 유선으로 또는 무선으로) 통신 가능하게 결합된 FaaS 플랫폼을 포함할 수 있다. 일부 실시예는 유리하게도 FaaS 및/또 는 하드웨어 가속 FaaS(AFaaS) 액션을 플랫폼 이벤트 및 콜백을 조건으로 하기 위한 아키텍처 지원을 제공할 수 있다. 하드웨어 가속 FaaS 또는 AFaaS 액션은, 도 3에 도시된 FaaS 서버에서, FPGA, 가속기, GPU, SmartNIC 등 상에서 실행될 수 있는 것이다. 예를 들어, FaaS 플랫폼은 후속 함수 호출에 대 한 요청을 클라이언트로부터 수신하고, 후속 함수 호출에 대한 준비 완료를 나타내는 피드백을 클라이언 트에 제공하는 기술을 포함하는 플랫폼 관리자를 포함할 수 있다. 함수가 트리거(예를 들면, 호출)될 때, 예를 들어, DAEMON은 디스패치를 위해 성숙되지 않은(unripe) 조건에 의한 지연을 야기할 수 있다 (예를 들면, 더 나은 조건, QoS 고려사항 등을 위해 더 오래 대기함). 성숙되지 않은 조건은 또한 수요가 높을 수 있는 제한된 리소스 상황(예를 들면, 스토리지, 가속기 등)에 관련될 수 있고 따라서 리소스에 액세스하기 위한 큐가 있을 수 있다. 제약으로 인해, 함수는 시작될 때 너무 오래 걸릴 수 있으므로 결코 실행되지 않을 수 있다(예를 들면, 5분 후에 타임아웃). 일부 실시예는 플랫폼 모니터링(예를 들면, 플랫폼 호출자에 의해 실 행됨)을 제공하고 그리고/또는 함수를 세그먼트/단편(piece)으로 분할할 수 있다. 플랫폼 관리자는 이어 서 제한된 리소스에 대한 액세스를 필요로 하지 않는 함수의 단편을 실행하고, 데이터를 프리큐잉(pre-queue)하 며, 리소스를 모니터링하는 가상 함수를 시작하고, 준비될 때 나머지 단편을 실행할 수 있다. 함수가 세그먼트 로 분할된 경우, 클라이언트(예를 들면, 소비자)는 적절한 시간에 콜백을 실행하고 그리고/또는 리소스가 이용 가능해질 때까지 함수를 일시중지(pause)할 수 있다. 일부 실시예는 1) FaaS 액션의 플랫폼 및 능력 자각(enlightened) 제출 및 실행, 2) FaaS 액션의 조건 또는 이 벤트 피드백 기반, 저스트 인 타임(just-in-time) 실행을 포함한, 2개의 잠재적으로 독립적이지만 보완적인 능 력을 제공할 수 있다. 일부 실시예는 소비자(예를 들면, 클라이언트)가 플랫폼 제공자를 안내하고, 플랫 폼 제공자가 다양한 플랫폼, 네트워크 및 전력 조건에 기초하여 더 협업적이고 정보에 입각한 액션 실행을 달성 하기 위한 유연성을 제공할 수 있다. 이제 도 10c를 살펴보면, 향상된 FaaS 시스템의 실시예는 함수 세그먼터, 플랫폼 모니터, 함 수 콜백 모듈, 및 함수 일시중지 모듈을 포함할 수 있다. 예를 들어, 다양한 플랫폼 조건이 플랫 폼 모니터에 의해 모니터링될 수 있고, 액션을 수행하기 위한 리소스가 이용 가능하고 플랫폼이 다음에 설명되는 바와 같은 다양한 다른 미묘한 조건을 충족시킬 때, 액션의 실제 트리거링이 수행될 수 있다. 미묘한 플랫폼 조건의 예는 데이터와의 거리이다. 예를 들어, 데이터 세트가 하나의 머신 또는 스토리지 위치에 있고, 데이터 세트를 필요로 하는 함수가 상이한 머신에서 실행되며, 이 머신으로부터 데이터 세트에 대한 함수의 액 세스는 데이터 세트가 함수와 동일한 머신에 있는 경우보다 액세스를 훨씬 더 느리게 만드는 하나 이상의 네트 워크 또는 스토리지 링크를 통과해야 하는 경우(예를 들면, 상당한 수의 디스크 또는 네트워크 IO 동작을 필요 로 하는 경우), 그러한 미묘한 플랫폼 조건이 충족되지 않는다. 메타 스케줄러(meta-scheduler)는 이러한 \"데 이터와의 거리\" 조건을 충족시키기 위해 데이터 마이그레이션 동작을 개시할 수 있으며, 일단 충분한 데이터가 마이그레이션되면, 액션이 진행될 수 있다. 대안적으로, 함수가 데이터가 있는 곳(예를 들면, 원격 노드)에 더가깝게 푸시될 필요가 있는 경우, 미묘한 조건은 데이터 근처에 \"충분한 계산 리소스를 갖는 것\"으로 변경된다. 미묘한 조건의 다른 예는 비용이다. 예를 들어, (예를 들면, 함수를 트리거하기 위한 모든 다른 조건이 충족된 다고 가정할 때) 함수가 저비용으로 실행될 수 있는 경우에만 함수가 트리거되는 것이 바람직할 수 있다. 예를 들어, 함수가 최선의 처리를 제공받을 수 있고 어떤 자유롭지만 제한된 레이턴시 내에서 완료될 것으로 예상되 도록, 플랫폼이 전력, CPU 사이클, 메모리 대역폭 등에서 충분한 잉여 용량을 갖는 경우 이러할 수 있다. 환언 하면, 이 접근법은 함수의 트리거링 및/또는 실제 디스패치가 유효성, 효율성 및 심지어 보안에 대한 다양한 직 접적인 및 간접적인 척도의 충족을 조건으로 하는 것을 고려한다(예를 들면, 보안 기준의 예는, 보안을 위해 그 레이 리스트에 있는(gray-listed) 액션을 실행하는 것을 허용하기 위해, 민감한 서비스가 플랫폼에서 실행되고 있지 않은 것이다). AFaaS의 경우, 리소스 이용 가능성도 그러한 플랫폼 조건이 될 수 있고, AFaaS가 인공 지능(AI) 모델의 저 강도 백그라운드 트레이닝을 수행하는 데 사용되는 경우 특히 그렇다. 그렇게 함으로써, 특히 함수가 실행되는 조건 이 그 자체로 제2 트리거이기 때문에(예를 들면, 제1 트리거가 단지 \"모든 논리 상태 기반, 또는 시간 트리거형 프리커서가 만족되었다”는 취지일 수 있는 경우), 목표는, 함수의 더 결정적 실행(deterministic execution)을 달성하는 것일 수 있다. 사실상, 이 기술은 함수의 실행을 올바른 리소스의 이용 가능성 및 함수에 대한 예상 수요에 명시적이고 체계적으로 링크시킬 수 있다. 함수 콜백 모듈은 소비자(예를 들면, 또는 소비자의 프록시로서 역할하는 소프트웨어 에이전트)가 플랫폼 인프라스트럭처로부터의 피드백을 통해 소비자가 요청하는 정보를 수신 및 프로세싱할 때 FaaS 활동의 실제 제 출을 연계시키게 할 수 있다. 예를 들어, 콜백이 제어기에서 또는 호출자에서 소비자 프록시를 자연적으로 활 성화시키도록, 콜백 모듈은 항상 준비된(예를 들면, \"사전 트리거된\") 것으로 취급되는 특정 메타 함수를 활용할 수 있다. 이 프록시는, 적시에 그리고 적절한(just-the-right) 플랫폼 조건 하에서, 소비자가 디스패치 하려고 의도하는 함수의 필요한 트리거링을 제공한다. 유리하게도, FaaS 시스템에서의 모니터링 및/또는 콜백 기술의 일부 실시예는 자각 디스패치를 달성하기 위해, CSP에서 부족한 다른 리소스를 기다리면서 CSP의 묵인 하에 소비자가 일부 리소스를 사전 예약할 수 있는(예를 들면, 일부 리소스를 사전에 별도로 요청함으로써 이를 명시적으로 획득할 수 있는) 더 풍부한 협업을 달성하는 BYOC(bring your own capabilities) 접근법을 지원할 수 있다. 예를 들어, 일부 변환 서비스는 변환을 수행하 기 위해 FaaS를 호출하기 전에 자체 리소스로 모든 것을 준비할 수 있다. 딥 신경 네트워크(DNN)는 FaaS 플랫 폼에 비해 너무 클 수 있으며, 따라서 소비자는 CSP에서 자체 선불 리소스로 DNN 부분을 수행하고, 이어서 CSP 의 FaaS 플랫폼을 사용하여 의도한 함수의 나머지를 실행할 수 있다. 시스템, 장치, 방법(도 10a), FaaS 시스템(도 10b), 및/또는 FaaS 시스템(도 10c)의 실시예 또는 양태/특징은 FaaS 플랫폼(도 1), 향상된 FaaS 시스템(도 2), FaaS 서버 아키텍처(도 3), 향상된 FaaS 시스템(도 4), 및/또는 향상된 FaaS 시스템(도 5)의 전부 또는 일부로 대체되거나 그 내에 통합될 수 있다. 예를 들어, 다양한 실시예의 소프트웨어 컴포넌트(예를 들면, 플랫폼 관리자, 함수 세그먼터, 플랫폼 모니터, 콜백 특징, 일시중지 특징, 함수 코드, 로직의 양태 등)는 FaaS 소프트웨어 서브시스템(도 5)에 통합될 수 있고, 다양한 실시예의 하드웨어 컴포넌트(예를 들면, 다양한 큐/버퍼, 로직의 양태 등)은 FaaS 하드 웨어 서브시스템(도 5)에 통합될 수 있다. 다중 버전 함수 예 이제 도 11a를 살펴보면, 함수의 실시예는 인스턴스화를 위한 다수의 옵션(예를 들면, 옵션 1 내지 옵션 N)을 포함할 수 있다. 일부 실시예는 유리하게도 동일한 함수의 다수의 버전을 제공할 수 있고, 동일한 함수의 다수의 가속 버전을 추가로 제공할 수 있다. 동일한 함수의 다수의 가속 버전을 포함하여, 동일한 함수의 다수의 버전은 그의 인스턴스화에 필요한 시간 또는 리소스, 및 함수가 수행될 필요 가 있을 때 인스턴스화를 실행(execute) 또는 실행(run)하는 데 걸리는 시간이 서로 상이할 수 있다. 일부 실 시예는 이러한 다수의 버전을 단계적 방식으로(in a graduated manner) 개시되는 다수의 테넌트(tenant)로서 제 공한다. 일부 컨테이너(예를 들면, 가속기를 사용하거나 머신에 따라 코어가 달라지는 경우 코어를 활용하는 컨테이너)는 시작하는 데 시간이 좀 걸릴 수 있다. 소프트웨어 함수는 낮은 레이턴시의 시작을 제공하지만 더 긴 레이턴시의 실행을 제공할 수 있다. 하드웨어 함수는 긴 레이턴시의 시작을 제공하지만, 짧은 레이턴시의 실행을 제공할 수 있다. 일부 실시예에서, 함수은 다수의 옵션(예를 들면, 인스턴스화)을 포함할 수 있 으며, 그 중 하나가 다양한 인자(예를 들면, 호출자 요구사항, FaaS 플랫폼 조건 등)에 따라 실행을 위해 선택 될 수 있다.이제 도 11b를 살펴보면, 향상된 FaaS 시스템의 실시예는 함수 B의 다수의 버전을 가진 코드 블록 A를 지 원할 수 있다. 예를 들어, 코드 블록 A의 호출자는, 최소 가속기(minimalist accelerator) 버전(Bm), 고속 가 속기(high accelerator) 버전(Bh), 및 비-가속기 버전(Bs)을 포함한, 함수 B의 상이한 버전을 식별할 수 있다. 컨테이너가 가속기(예를 들면, 최소 가속기(Bm))에 대해 시작되는 경우, 일부 실시예는 함수 B의 각각의 버전을 컨테이너로 셔틀링할 수 있다. 일부 실시예는 함수 B의 새로운 도착의 횟수가 감소하는 것에 기초하여 가속 컨 테이너를 저하시킬 수 있다(예를 들면, 고속 가속기(Bh)를 해제하고 최소 버전(Bm)을 워밍업하거나, 또는 소프 트웨어/비-가속기 버전(Bs)으로 전환함). 일부 실시예는 다수의 함수 버전을 함수 B의 물리적 위치 근처에 있 도록 데이터의 프리페칭하는 것과 조합할 수 있다. 일부 실시예는 유리하게도 새로운 가속 함수를 론칭하는 시점에서 예상되는 사소하지 않은(non-trivial) 기동 레이턴시를 숨기는 방식으로 다중 테넌트 상황에서 가속 함수를 수행할 수 있다. 범용 CPU에서 실행되는 호출 자의 경우, 호출의 대상은 초기화기 또는 호스트 CPU 기반 코드가 코드 블록 A인 일부 함수에 대응할 수 있으며, 가속 함수는 함수 B에 대응할 수 있다. A가 제어를 받는 시점에서, B가 가속기에 이미 초기화되어 있 을 수 있거나, 또는 B가 가속기에 이미징될 필요가 있을 수 있다. 일반적으로, Bh의 초기화는 수 밀리초 내지 수십 밀리초가 걸릴 수 있다. 예를 들어, FPGA 리소스는 다수의 사 용 중인 활성 함수, 유휴 함수, 및 요청된(예를 들면, 큐잉된) 함수 사이에서 중재될 수 있다. Bh가 활성이 아 닌 경우, Bh를 위한 리소스를 할당하고, 가까운 또는 멀리 있는 메모리로부터 Bh에 대한 비트스트림을 페치하며, 이어서 비트스트림을 활성화(예를 들면, 론칭)시키는 데 얼마간의 시간이 걸릴 수 있다. 일단 활성 화되면, Bh에 대한 리소스가 감소되고 Bh가 회수(reclaim)되기 전에 Bh가 유지되는 많은 듀티 사이클에 걸쳐 Bh 를 기동시키는 비용을 상각하기 위해 Bh에 대한 비트스트림이 일정 시간 동안 활성으로 유지될 수 있다. 이러 한 레이턴시를 숨기기 위해, 일부 실시예는, 예를 들어, 2개의 추가적인 대안 형태(Bm 및 Bs)를 포함한 Bh의 다 수의 버전을 지원할 수 있으며, 여기서 Bm은 기동시키는 데 매우 적은 양의 시간이 걸리지만 실행하는 데 더 오 래 걸릴 수 있는 Bh의 최소 가속 버전에 대응할 수 있고(예를 들면, 루프를 공간에서 실행하지 않고 루프를 시 간에서 실행하기 때문임), 여기서 Bs는 B의 소프트웨어(예를 들면, CPU) 버전(예를 들면, Bh보다 훨씬 덜 전력 및 성능 효율적일 수 있지만 Bs가 웜이면 거의 즉각적으로 론칭될 수 있는 B의 비-가속 버전)에 대응할 수 있다. 이제 도 11c를 살펴보면, 서비스형 함수를 제공하는 방법의 실시예는 블록에서 함수의 완전 가속 (fully accelerated) 버전(예를 들면, 고속 가속기 하드웨어에서 동작하는 컨테이너에서 실행되는 함수)이 활성 인지를 결정하는 단계 및, 만약 그렇다면, 블록에서 완전 가속 버전을 사용하는 단계를 포함할 수 있다. 그렇지 않으면, 방법은 블록에서 함수의 부분 가속(partially accelerated) 버전(예를 들면, 최소 가속기 하드웨어에서 동작하는 컨테이너에서 실행되는 함수)이 활성인지를 결정하고, 만약 그렇다면, 블록 에서 부분 가속 버전을 사용할 수 있다. 그렇지 않으면, 방법은 블록에서 함수의 비-가속 버전을 사용할 수 있다. 고객 요구/플랫폼 조건에 따라, 방법은 블록에서 함수의 완전 버전 또는 부분 가속 버전을 추론적으로 론칭하는 단계(예를 들면, 그리고 해당 버전이 활성으로 될 때 해당 버전으로 전 환하는 단계)를 추가로 포함할 수 있다. 환언하면, Bh가 이미 활성이고(예를 들면, B의 가장 빠르고 가장 효율적인 실행임) Bh에 대한 셋업 시간이 없는 경우, 코드 블록 A는 Bh를 사용할 수 있고; 그렇지 않고, Bm이 이미 활성인 경우(예를 들면, 셋업 시간은 없지 만 실행 지속기간이 더 길어짐) A는 Bm을 사용할 수 있으며; 또는 Bh와 Bm 어느 것도 활성이 아닌 경우 A는 Bs 를 사용할 수 있으며, 그 후에 A는 Bm을 론칭하거나 Bh를 론칭하고, 이어서 원하는 레이턴시 성능 영역 전력 (latency-performance-area-power) 트레이드오프에 따라 론칭된 Bm 또는 B를 사용할 수 있다. 일부 실시예는 (예를 들면, 과거 프로파일링을 통해) 빈번한 것으로 알려진 해당가속 함수에 대해 Bm 버전을 먼 저 프리론칭(prelaunch)할 수 있다. 빈번하지 않은 가속 함수의 경우, 일부 실시예는 온 디맨드로 이러한 최소 버전을 론칭할 수 있지만, Bm 또는 Bs가 아직 론칭되지 않은 경우 처음에는 소프트웨어 버전(Bs)을 사용한다. Bs 또는 Bm에 대한 수요가 최근 시간 윈도에서 특정 임계치를 초과하는 경우, 일부 실시예는 가속 함수(Bh)를 론칭하고, Bh가 완전히 활성화될 때까지, B에 대한 요청에 대해 Bs 또는 Bm을 계속 사용할 수 있다. 일부 실시예는 또한 각각의 론칭된 B에 대한 이용률 및 비용 메트릭의 이동 윈도 평균을 수집할 수 있다. 수집 된 정보가 임계치 아래로 떨어지는 경우, 또는 다른 함수에 대한 수요가 상승하는 경우, 일부 실시예는 Bh의 회 수를 개시할 수 있고, Bm이 적격인 경우, Bh에 대한 리소스를 회수하지만 B를 수행하기 위한 새로운 요청에 응 답하여 그 대신에 Bm을 론칭할 수 있다. 반대로, B에 대한 수요가 아래로부터 임계치를 초과하는 경우, 일부실시예는 Bh의 론칭을 개시하고, Bh가 활성화된 후에 Bm이 활성인 경우 Bm을 회수할 수 있다. (예를 들면, Bs 또는 Bm의 이용률이 제각기 상승함에 따라) Bm 또는 Bh를 론칭하기 위한 임계치를 선택할 때, 그리고 (예를 들면, Bh 및 Bm의 이용률이 제각기 하강함에 따라) Bh 또는 Bm을 회수하기 위한 임계치를 선택할 때, 일부 실시예는 AFaaS 제어 서비스에 의해 동적으로 제공되는 서비스 수준 협약(SLA) 입력을 고려할 수 있다. SLA 입력이 제공되지 않는 경우, 이러한 임계치는 B에 대한 요청의 도착률(예를 들면, 도착률의 이동 윈 도 평균)에 기초하여 휴리스틱적으로 및 동적으로 설정될 수 있다. 일부 실시예는, 1) 얼마 동안 hB를 활성으로 유지할지를 결정하는 것 및 2) 과거 빈도 및 활성 이용의 지속기간 을 지침으로 사용하여 Bh의 향후 활성화가 촉진될 수 있도록 과거 정보를 축적하는 것의 두 가지 목표를 달성하 기 위해, 하드웨어에서의 Bh의 비용에 의해 정규화된 듀티 사이클(이용률)의 연속 모니터링을 활용할 수 있다. 함수의 Bs 버전로부터 Bm 버전으로 Bh 버전으로 전환하기 위한 임계치를 결정하기 위해 탐욕적 빈 패킹(greedy bin-packing) 휴리스틱스가 이용될 수 있다. 이러한 통계는 Bh에 대한 에필로그를 사용하여 업데이트될 수 있 으며, 코드 블록 A의 향후 활성화가 Bs, Bm 및 Bh 중에서 선택하는 데 사용하는 메모리 내 통계를 업데이트하는 데 사용될 수 있다. 함수(도 11a), FaaS 시스템(도 11b), 및/또는 방법(도 11c)의 실시예 또는 양태/특징은 FaaS 플랫폼(도 1), 향상된 FaaS 시스템(도 2), FaaS 서버 아키텍처(도 3), 향상된 FaaS 시스 템(도 4), 및/또는 향상된 FaaS 시스템(도 5)의 전부 또는 일부로 대체되거나 그 내에 통합될 수 있다. 예를 들어, 다양한 실시예의 소프트웨어 컴포넌트(예를 들면, 다중 버전 함수 코드, 로직의 양태 등)는 FaaS 소프트 웨어 서브시스템(도 5)에 통합될 수 있고, 다양한 실시예의 하드웨어 컴포넌트(예를 들면, 모니터링, 로직 의 양태 등)은 FaaS 하드웨어 서브시스템(도 5)에 통합될 수 있다. 비동기 함수 예 이제 도 12를 참조하면, 향상된 FaaS 시스템의 실시예는 이벤트 큐, 함수 큐, 트리거 큐 등을 포함하는 큐들을 갖는 스케줄러를 포함할 수 있다. 일부 실시예는 유리하게도 분산된 액션들 간의 효율적인 동기화를 제공할 수 있다. 체이닝된 함수들이 중개 액션에 의해 링크되는 것(예를 들면, 함수 X는 함수 Y에 의해 사용될 데이터를 저장하는 액션을 호출할 필요가 있음)은 여러 호출을 결과할 수 있다. 액션 X가 네트워크 또는 저장 동작 P 자체를 완료된 것으로 간주할 수 있기 전에 네트워크 또는 저장 동작 P를 수행할 필요가 있는 액션 X를 고려하고, 상기 동작 P를 통해 통신되거나 저장 영역에 채워진 데이터를 프로세싱 하는 다른 액션 Y를 트리거한다. 예를 들어, 종래의 FaaS 시스템에서, 액션 X는 네트워크 또는 저장 동작 P가 채우기(population)를 완료하기를 기다리고 이어서 액션 Y를 호출하거나 트리거해야 한다. 스케줄러는 빈둥빈둥 기다릴 필요가 있을 수 있고, 리소스는 대기 시간 동안 액션 X에 의해 사용된다. 향상된 FaaS 솔루션 의 일부 실시예는 유리하게도 액션 X로 하여금 네트워크 또는 저장 동작 P를 트리거하게 할 수 있고, 네트워크 또는 저장 동작 P의 완료가 액션 Y를 트리거하고 따라서 네트워크 또는 저장 동작 P가 완료되어 액션 X에 의해 소비되는 리소스를 해제하기 전에 액션 X가 폐기될 수 있도록, 네트워크 또는 저장 동작 P를 수정하게 할 수 있 다. 일부 실시예는 또한 루트(root)(예를 들면, 부모 함수)가 빈둥빈둥 기다릴 필요가 없기 때문에 더 흥미로 운 병렬 처리(예를 들면, 모듈식 설계)를 가능하게 할 수 있으며, 따라서 완료에 의해 트리거되는 다른 함수가 실행되기 시작할 수 있다. 일부 실시예는 하드웨어 큐 관리자(hardware queue manager)(HQM)에 의해 구현될 수 있다. 영속성(durability)을 위해 커밋되거나 가시성을 위해 통신되는 상태가 직렬화 가능한 동작 시퀀스에 의해 업데 이트되어야 한다는 요구사항을 충족시키는 것만을 위해서라도 많은 분산 액션이 동기화될 필요가 있다. 따라서, 예를 들어, 이러한 동작의 결과가 영속성 매체에 기록되거나 서드파티로부터 관측되는 방식으로 시간이 뒤로 이동한 것처럼 보이지 않아야 한다. 그렇지만, 일부 경우에, 분산 프로세스 시스템에서 취해지는 접근법 이 너무 보수적일 수 있다. 예를 들어, 이용되는 프로세스가 이미 데이터 병렬인 경우에도, 모든 에이전트가, 2 단계 잠금(two phase locking)에서와 같은, 장벽을 통과할 수 있다(예를 들면, 프로세스가 분리 데이터 파티 션(disjoint partitions of data)에 대해 동작함). 코디네이팅 노드 세트에 걸쳐 수행될 필요가 있는 저 레이 턴시 FaaS 액션의 경우, 그러한 오버헤드는 엄청나게 비용이 많이 들고 불필요한 지연을 도입한다. 지속성 또는 통신을 위해 상태가 업데이트되는 경우 실제 코디네이션의 일부 또는 대부분이 발생할 필요가 있을 수 있기 때문에, 향상된 FaaS 솔루션의 일부 실시예는, 임의의 주어진 범위의 데이터에 대한 업데이트가 전역적 으로 일관된 시간 순서로 수행되도록, (예를 들면, 저장 함수로서 또는 네트워크 함수로서) 통신 및 저장을 위 한 다양한 페이로드의 비동기 제출을 지원하도록 패브릭 및/또는 저장 인터페이스를 확장할 수 있다. 따라서,X가 공유 디스크에 있는 데이터 블록의 비동기 업데이트를 수행하고 X의 완료가 Y가 트리거하도록 2개의 동작 X 와 Y가 종속성 체이닝되어 있는 경우(예를 들면, Y가 X에 의해 이루어진 업데이트를 사용할 수 있거나(기입후 판독(read-after-write), 또는 RAW 종속성) 또는 덮어쓰기하는 경우(기입후 기입(write-after-write) 또는 WAW 종속성)), \"저장 FaaS 액션\"의 체이닝의 일부 실시예는 요구된 순서 종속성을 위반하는 것을 방지할 수 있다. 일부 실시예는 저장 액션 자체를 체이닝된 FaaS 액션으로서 추상화할 수 있다. 제한이 아닌 설명으로서, 함수가 공유 데이터에 대해 닫기후 열기(close-to-open) 또는 취득후 해제(acquire- to-release) 일관성 모델을 따를 수 있다는 점에서 분산 함수는 분산 프로세스와 상이할 수 있다(예를 들면, 함 수가 그의 유한 지속시간 또는 완전 실행 모델을 넘어서는 세션 상태를 전혀 알지 못할 수 있기 때문임). 액션 X의 완료를 알리고 액션 Y를 트리거하기 전에 액션 X가 액션 X 내에서 네트워크 또는 저장 동작 P를 동기적으로 수행해야 하는 것(예를 들면, [X, P] => Y로 표현됨) 대신에, 일부 실시예에서, 하나의 함수 X가 완료되고, 이 어서 체이닝된 액션 P(예를 들면, 저장, 네트워크 등)를 수행(예를 들면, 트리거)할 수 있고, P가 스케줄링되어 수행될 때, P의 완료가 함수 Y를 트리거할 수 있음을 지정할 수 있다(예를 들면, X => [P => Y]로 표현됨). 예를 들어, 함수 큐는 실행될 함수의 큐를 포함할 수 있다. 함수 Y(또는 함수 Y의 어떤 표시)는, 예를 들어, 제1 함수로서 함수 큐에 저장될 수 있다. 이벤트 큐는, \"제1 이벤트가 발생할 때(예를 들면, 네트워크 또는 저장 동작 P의 완료), 트리거 큐의 제1 트리거를 실행\"과 같은, 트리거를 실행하는 상이한 이벤트를 포함할 수 있다. 트리거 큐는 실행할 함수 큐의 하나 이상의 함수에 대한 다양한 트리거를 저장할 수 있다. 트리거 큐의 제1 트리거는 함수 큐로부터 제1 함수(예를 들면, 함수 Y)을 트리거하는 것을 포함할 수 있다. 따라서, 네트워크 또는 저장 동작 P가 완료될 때, 시스템은, 이벤트 큐 로부터, 제1 이벤트(예를 들면, 네트워크 또는 저장 동작 P의 완료)가 발생했다고 결정하여, 실행할 트리 거 큐로부터의 제1 트리거를 실행하게 할 수 있다. 제1 트리거는 이어서 함수 큐로부터의 하나 이 상의 함수(예를 들면, 함수 Y)가 실행되게 할 수 있다. 종래의 시퀀스 [X, P] => Y는 함수 X가 폐기(retire)되기 전에 업데이트 액션 P를 동기적으로 수행(예를 들면, P를 기다림)하는 것을 요구하며, 따라서 레이턴시를 증가시키고 잠재적으로 병목현상을 확장시킬 수 있다(예를 들면, X가 P를 수행하기 위해 다양한 잠금 및 리소스에 대해 경쟁할 필요가 있는 경우). Y 자체는 X에 관련될 수 있다. 예를 들어, Y는 X의 연속이며 P를 수행한 결과로서 그에 이용 가능하게 되는 일부 자격증명을 요구할 수 있다. 일 예로서, X는 어떤 카메라 피드를 프로세싱하는 이미지 프로세싱 태스크일 수 있고, P는 이미지 데 이터베이스를 업데이트하는 태스크일 수 있으며, Y는 최신 업데이트가 특정 타깃 객체 또는 패턴을 포함하는지 를 확인하기 위해 최신 업데이트를 프로세싱할 필요가 있는 태스크일 수 있다. 일부 실시예에서, 태스크 P는, X에 할당된 리소스가 P가 론칭된 후에 해제될 수 있도록, X에 대해 실행후 무시(fire-and-forget) 태스크로 간 주될 수 있다. 일부 실시예에서, 분산 시스템에서 그러한 동기화 및 코디네이션을 위해 잠금을 취득 및 해제하고 2 단계 트랜 잭션을 수행하는 것은 고성능 패브릭 및 저장 동작(예를 들면, 스마트 NIC, 스마트 디스크 등)을 위한 비동기 커맨드 큐잉 기술로 대체될 수 있다. 이것은 풀링된 스토리지 및 풀링된 메모리가 공유 플랫 액세스 패러다임 (shared, flat-access paradigm)에서 상이한 실행 엔진에 의해 사용될 수 있는 \"랙 스케일 설계(rack-scale- design)\" 또는 RSD 아키텍처에 특히 유용할 수 있으며, 따라서 하드웨어 기반 큐잉 메커니즘은 잠금, 조건 등에 대한 필요성을 방지할 수 있고 동시에 상위 레벨 소프트웨어 프로토콜(예를 들면, 리더-라이터 잠금(reader- writer lock) 관리, 데드록 탐지 및 해결 등)에 대한 필요성을 방지할 수 있다. 일부 실시예는 HQM 유사 기술 을 활용할 수 있다. 예를 들어, 태스크는 태스크의 실행을 관리하기 위해 HQM에 위임될 수 있다. 시스템(도 12)의 실시예 또는 양태/특징은 FaaS 플랫폼(도 1), 향상된 FaaS 시스템(도 2), FaaS 서버 아키텍처(도 3), 향상된 FaaS 시스템(도 4), 및/또는 향상된 FaaS 시스템(도 5)의 전부 또는 일 부로 대체되거나 그 내에 통합될 수 있다. 예를 들어, 다양한 실시예의 소프트웨어 컴포넌트(예를 들면, 스케 줄러, 함수 코드, 로직의 양태 등)는 FaaS 소프트웨어 서브시스템(도 5)에 통합될 수 있고, 다양한 실시예 의 하드웨어 컴포넌트(예를 들면, HQM, 로직의 양태 등)은 FaaS 하드웨어 서브시스템(도 5)에 통합될 수 있다. 추가 비고 및 예 예 1200은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 후속 함수 호출에 대한 요청을 트리 거 에이전트로부터 수신하게 하고, 후속 함수 호출에 대한 준비 완료를 나타내는 피드백을 트리거 에이전트에 제공하게 하며, 다중 테넌트 가속 함수의 단계적 다중 버전 개시를 제공하게 하고, 분산 액션들 간의 동기화를제공하게 하며, 기준이 충족될 때 후속 함수 호출을 트리거하게 하는 실행 가능 프로그램 명령어 세트를 포함하 는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 1201은 전자 프로세싱 시스템을 포함하고, 이 전자 프로세싱 시스템은 프로세서, 프로세서에 통신 가능하게 결합된 메모리, 및 후속 함수 호출에 대한 요청을 트리거 에이전트로부터 수신하고, 후속 함수 호출에 대한 준 비 완료를 나타내는 피드백을 트리거 에이전트에 제공하기 위해 프로세서 및 메모리에 통신 가능하게 결합된 로 직을 포함할 수 있다. 예 1202는 예 1201의 시스템을 포함하고, 여기서 로직은 추가로 가속 함수가 기동되는 동안 사용될 수 있는 가 속 함수의 하나 이상의 대안적인 형태를 제공한다. 예 1203은 예 1201 및 예 1202 중 어느 한 예의 시스템을 포함하고, 여기서 로직은 추가로 서비스 체인을 지원 하기 위해 하나 이상의 함수를 비동기인 것으로 식별한다. 예 1204는, 하나 이상의 기판 및 하나 이상의 기판에 결합된 로직을 포함하는, 반도체 패키지 장치를 포함하며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현되고, 하 나 이상의 기판에 결합된 로직은 후속 함수 호출에 대한 요청을 트리거 에이전트로부터 수신하고, 후속 함수 호 출에 대한 준비 완료를 나타내는 피드백을 트리거 에이전트에 제공한다. 예 1205는 예 1204의 장치를 포함하고, 여기서 로직은 추가로 가속 함수가 기동되는 동안 사용될 수 있는 가속 함수의 하나 이상의 대안적인 형태를 제공한다. 예 1206은 예 1204 및 예 1205 중 어느 한 예의 장치를 포함하고, 여기서 로직은 추가로 서비스 체인을 지원하 기 위해 하나 이상의 함수를 비동기인 것으로 식별한다. 예 1207은 예 1204 내지 예 1206 중 어느 한 예의 장치를 포함하고, 여기서 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함한다. 예 1208은 서비스형 함수를 제공하는 방법을 포함하고, 이 방법은 후속 함수 호출에 대한 요청을 트리거 에이전 트로부터 수신하는 단계, 및 후속 함수 호출에 대한 준비 완료를 나타내는 피드백을 트리거 에이전트에 제공하 는 단계를 포함한다. 예 1209는 예 1208의 방법을 포함하며, 가속 함수가 기동되는 동안 사용될 수 있는 가속 함수의 하나 이상의 대 안적인 형태를 제공하는 단계를 추가로 포함한다. 예 1210은 예 1208 및 예 1209 중 어느 한 예의 방법을 포함하고, 서비스 체인을 지원하기 위해 하나 이상의 함 수를 비동기인 것으로 식별하는 단계를 추가로 포함한다. FaaS를 위한 성능 향상된 컴퓨팅 아키텍처 서버리스 계산은 FaaS 함수 및 비-FaaS 함수가 동일한 컴퓨트 노드에서 실행될 수 있게 한다. 예를 들어, 하이 퍼스레딩과 유사하게 일반 클라우드 애플리케이션들(예를 들면, 비-FaaS 함수들) 사이의 간극(유휴 기간)에 많 은 수의 독립적인 FaaS 함수를 통합하는 것이 가능할 수 있다. 간극은, 어떤 경우에도, 일반 클라우드 애플리 케이션으로 채워지지 않는 갭일 수 있다. 하이퍼스레딩은, 추가 스레드와 함께, 코어당 하나의 스레드만으로 완전히 실행되지 않는 유휴 마이크로 아키텍처 리소스를 활용할 수 있다. 따라서, FaaS 함수 및 비-FaaS 함수는, 예를 들어, 동일한 컴퓨트 노드(예를 들면, 서버 또는 프로세서 코어)에 서 동시에 동작하도록 다중 테넌시로 통합될 수 있다. 그러한 다중 테넌시 상황에서, 클라우드 서비스 제공자 (CSP) 공동 테넌트(co-tenant)가 리소스(예를 들면, 대역폭, 디스크 I/O, CPU)를 독점하여 다른 공동 테넌트의 성능에 부정적인 영향을 미칠 수 있는 시끄러운 이웃 문제(noisy neighbor problem)가 존재할 수 있다. 예를 들어, 비-FaaS 함수는 FaaS 함수에 의해 항상 완전히 구독되지 않은 리소스 대역폭을 흡수할 수 있으며 그 반대 의 경우도 마찬가지이다. 이것은 공동 테넌트들에 걸쳐 불균일한 클라우드 네트워크 성능을 야기하고 실행할 FaaS 함수에 대한 레이턴시를 증가시키거나 비-FaaS 공동 테넌트의 성능을 감소시킨다. 현재 존재하는 솔루션 에서 가상 머신 또는 컨테이너 레벨에서 캐시 용량, 메모리 대역폭, 또는 프로세서 스케줄링 우선순위와 같은 리소스를 할당하거나 예약하는 다른 설계와 달리, 예를 들어, 프로세서 코어 레벨에서, 각각의 컴퓨트 노드 내 에서의 효율적이고 적응적이며 세분화되고 공정한 리소스 공유에 관한 한, 새로운 시끄러운 이웃 문제는 정성적 으로 고유할 수 있다. 아래에 설명된 실시예는 이러한 통합이 나타내는 훨씬 더 높은 레벨의 다중 테넌시 하에서 시끄러운 이웃 문제 를 방지하기 위해 각각의 FaaS 함수 및 비-FaaS 함수를 스케줄링할 수 있다. 그렇게 하는 것은 대기로 인한 레 이턴시를 감소시키나 안정화시킬 수 있고, 타임아웃 에러로 인한 함수의 실패를 감소시키고, 실행 성능의 가변 성을 제어할 수 있다. 게다가, 일부 실시예는 리소스 분배를 향상시킬 수 있다. 예를 들어, 함수의 실행을 향 상시키기 위해 특수 하드웨어 가속기를 갖는 노드에 함수가 제공될 수 있다. 일부 실시예는 우선순위화된 스케줄링에 의해 다수의 하드웨어 스레드 사이에서 코어 실행 리소스의 범위 할당 (scoped allocation)을 제공할 수 있다. 각각의 함수가 해당 함수가 가장 민감해 하는 적어도 해당 리소스를 공정하게 사용하도록, 우선순위화된 스케줄링은 공유 코어 상에서의 동시 멀티스레딩(simultaneous multithreading)(SMT) 실행(예를 들면, SMT4, SMT8 등)을 위해 충돌하지 않는 수요 프로파일을 사용하여 함수를 스케줄링한다. 그렇게 함으로써, 함수간 리소스 충돌 또는 시끄러운 이웃 문제가 방지될 수 있다. 따라서, 일 부 실시예는 SMT(예를 들면, SMT2, SMT4) 동안 코어 실행 리소스의 효율적이고 민첩한, 단기간의 미세 범위 할 당에 필요한 방법과 툴 및 피드백 메커니즘을 포함할 수 있다. 도 13a를 살펴보면, 리소스 경쟁을 감소시키는 FaaS를 위한 성능 향상된 컴퓨팅 아키텍처가 예시된다. 아래에 설명된 바와 같이, 서버는 제1 내지 제3 함수(1312, 1314, 1316)가 실행에 충분한 제1 내지 제3 리소스 할당(1326, 1328, 1330)을 가질 수 있게 하도록 제1 내지 제3 함수(1312, 1314, 1316)을 분배함으로써 리소스 경쟁을 감소시킬 수 있다. 게다가, 일부 실시예에서, 제1 내지 제3 컴퓨트 노드(1304a 내지 1304c)에서 실행 중인 제4 내지 제6 함수(1318, 1320, 1322)는 제1 내지 제3 함수(1312, 1314, 1316)에 의한 제1 내지 제3 리소스에 대한 액세스를 손상시키지 않는 제1 내지 제3 리소스의 할당량을 가질 수 있다. 초기에, 효율성 향상된 서버는 이벤트 기반 트리거링 디바이스 또는 단순히 트리거링 디바이스(1306, 1308, 1310)(예를 들면, 다양한 컴퓨팅 디바이스)로부터 제1 내지 제3 함수(1312, 1314, 1316)(예를 들면, FaaS 함수)에 대한 요청을 수신할 수 있다. 제1 내지 제3 함수(1312, 1314, 1316)에 대한 요청은 트리거링 디 바이스(1306, 1308, 1310)에서 동작하는 애플리케이션에 의해 호출될 수 있다. 서버는 제1 내지 제3 함 수(1312, 1314, 1316)의 민감한 리소스를 결정할 수 있다. 예를 들어, 제1 함수는 실행하기 위해 제1 리 소스에 대한 액세스를 요구할 수 있고, 제2 함수는 실행하기 위해 제2 리소스에 대한 액세스를 요구할 수 있으며, 제3 함수는 실행하기 위해 제3 리소스에 대한 액세스를 요구할 수 있다. 제1 내지 제3 리소스는 실행 동안 제1 내지 제3 함수(1312, 1314, 1316)에 의해 요구되는 임의의 유형의 컴퓨팅 리소스(예를 들면, 하 드웨어 리소스, 하드웨어 가속기, 대역폭, 산술 로직 유닛, 전력, 주파수 등)일 수 있으며, 서로 상이할 수 있 다. 서버는 제1 내지 제3 함수(1312, 1314, 1316) 각각이 실행에 민감한 적어도 제1 내지 제3 리소스를 공정 하게 사용하도록 하드웨어 리소스 할당을 지시할 수 있다. 상세하게는, 서버는 제1 내지 제3 함수(1312, 1314, 1316)가 리소스 경쟁 없이 제1 내지 제3 리소스에 액세스할 수 있도록 제1 내지 제3 함수(1312, 1314, 1316)를 다양한 타이밍에서 다양한 컴퓨트 노드(1304a 내지 1304c) 상에서 실행되도록 스케줄링할 수 있다. 예 를 들어, 리소스 경쟁을 방지하기 위해, 서버는 제1 함수가 실행에 충분한 제1 리소스 할당 을 갖도록 제1 함수를 제1 컴퓨트 노드(1304a)에 분배할 수 있다. 서버는 제2 함수가 실행 에 충분한 제2 리소스 할당을 갖도록 제2 함수를 제3 컴퓨트 노드(1304c)에 분배할 수 있다. 서버 는 제3 함수가 실행에 충분한 제3 리소스 할당을 갖도록 제3 함수를 제2 컴퓨트 노드 (1304b)에 분배할 수 있다. 실행 이전에, 서버는 제1 내지 제3 함수(1312, 1314, 1316)가 필요로 하는 제1 내지 제3 리소스를 추론적 으로 결정할 수 있다. 예를 들어, 서버는 연관된 구현(예를 들면, 소스 코드, 트랜스코드, 유사하거나 동일한 함수에 의한 과거 요구사항 등)을 분석함으로써 제1 내지 제3 함수(1312, 1314, 1316)의 민감한 리소스 를 결정할 수 있다. 따라서, 서버는 함수가 필요로 하는 요구된 리소스 할당 및/또는 함수가 필요로 하 는 리소스의 유형을 식별하고, 그러한 리소스를 민감한 리소스로서 라벨링할 수 있다. 리소스는 전력 소비, 펌 웨어 요구사항, 하드웨어 요구사항(예를 들면, 대역폭 요구사항, 가속기, CPU의 명령어 페치에서 이용 가능한 리소스의 수 또는 비율, TLB, BTB(Brach Target Buffer), 예약 스테이션, 산술 로직 유닛(ALU)과 같은 동작 포 트 등) 또는 클록 주파수 요구사항 중 하나 이상을 포함할 수 있다. 리소스는 또한 초과 할당에 대비해 예약될 수 있다 - 예를 들어, 상이한 다중 테넌트 조건들 하에서 성능의 가변성을 제어하기 위해, CPU 코어가 터보 실 행에 들어가는 것을 허용하지 않음 -. 일부 실시예에서, 서버는 제1 내지 제3 함수(1312, 1314, 1316) 각각이 필요로 하는 하나 이상의 리소스 할당이 임계치 초과인지를 결정할 수 있다. 만약 그렇다면, 서버는 하나 이상의 리소스를 민감한 리소스로서 라벨링할 수 있다. 임계치는 제1 내지 제3 컴퓨트 노드(1304a 내지 1304c)에서의 평균 과거 리소스 이용 가능성에 대응할 수 있다. 임계치는 또한 컴퓨트 노드(1304a 내지 1304c) 중 하나 이상 각각에서 현재 리소스 이용 가능성으로 설정될 수 있다. 서버는 추가로 리소스 충돌을 방지하기 위해 컴퓨트 노드(1304a 내지 1304c) 중 상이한 컴퓨트 노드 상 에서 및/또는 상이한 타이밍에서 실행되도록 추론적으로 결정된 제1 내지 제3 리소스에 기초하여 제1 내지 제3 함수(1312, 1314, 1316)를 스케줄링할 수 있다. 따라서, 서버는 레이턴시를 감소시키고 제1 내지 제3 함 수(1312, 1314, 1316)의 완료율을 향상시킬 수 있다. 예를 들어, 제1 함수는 메모리 대역폭 집약적 함수를 실행할 수 있으며, 따라서 제1 리소스(예를 들면, 민감한 리소스)는 고 대역폭 리소스이다. 제2 함수은 ALU 계산 집약적 함수를 실행할 수 있으며, 따라서 제2 리소스(예를 들면, 민감한 리소스)는 ALU 리소스일 수 있다. 제3 함수는 전력 집약적 동작을 포함할 수 있으며, 따라서 제3 리소스(예를 들면, 민감한 리소스)는 고전력일 수 있다. 위에서 언급된 바와 같이, 서버는 트리거링 디바이스(1306, 1308, 1310)로부터 제1 내지 제3 함수(1312, 1314, 1316)을 실행하라는 요청을 수신하고, 리소스 경쟁을 방지하기 위해 제1 내지 제3 함수(1312, 1314, 1316)를 컴퓨트 노드(1304a 내지 1304c) 중 다양한 컴퓨트 노드에 분배할 수 있다. 일부 실시예에서, 서버 는 컴퓨트 노드(1304a 내지 1304c)에서 실행 중인 제4 내지 제6 함수(1318, 1320, 1322)(예를 들면, 비- FaaS 함수)를 이미 스케줄링했을 수 있다. 서버는 제4 내지 제6 함수(1318, 1320, 1322)의 제1 내지 제 3 리소스 할당(1332, 1334, 1336)을 참조하여 제1 내지 제3 컴퓨트 노드(1304a 내지 1304c) 중 다양한 컴퓨트 노드에서 제4 내지 제6 함수(1318, 1320, 1322)에 의해 제1 내지 제3 리소스가 광범위하게 활용되고 있음을 식 별할 수 있다. 서버는 리소스 경쟁을 방지하기 위해 제1 함수를 제1 컴퓨트 노드(1304a)에 분배할 수 있다. 상세 하게는, 제1 함수가 필요로 하는 제1 리소스는 제6 함수가 필요로 하는 제3 리소스와 상이하며, 따 라서 제1 함수와 제6 함수 사이의 리소스 경쟁이 방지된다. 이와 달리, 제1 함수가 제3 컴 퓨트 노드(1304c)에 제공되었다면, 제1 및 제4 함수(1312, 1318) 둘 모두가 민감한 리소스인 제1 리소스를 필요 로 하기 때문에 리소스 경쟁이 존재할 수 있다. 위에서 설명된 바와 같이, 제1 및 제4 함수(1312, 1318)는 제1 리소스의 높은 할당을 요구하고, 높은 할당은 제 3 컴퓨트 노드(1304c)에서의 제1 리소스의 이용 가능성을 초과할 수 있다. 예를 들어, 비록 제1 함수가 제3 노드(1304c)에서 제한된 수량으로 제1 리소스에 액세스할 수 있지만, 제1 리소스가 제1 리소스 할당 에 의해 제4 함수에 이미 상당히 할당되었기 때문에 제1 함수는 실행을 완료하기 위해 제1 리소스 에 충분한 액세스를 가지지 못할 수 있다. 마찬가지로, 제3 함수는 제2 컴퓨트 노드(1304b)에 제공되고, 제2 함수는 제3 컴퓨트 노드(1304c)에 제공될 수 있다. 일부 실시예에서, 서버는 제6 함수가 제1 컴퓨트 노드(1304a)에서 제1 리소스를 활용하고 있다고 결정할 수 있다. 그러한 시나리오에서, 서버는 제1 함수가 실행을 완료하기 위해 제1 리소스에 충 분히 액세스할 수 있을지를 결정할 수 있다. 예를 들어, 제6 함수가 제1 리소스에 대한 액세스 및/또는 소량만을 할당받은 경우, 제1 함수는 실행을 용이하게 할 제1 리소스의 할당을 여전히 받을 수 있다. 따라서, 서버는 리소스의 이용 가능성에 기초하여 함수가 민감한 리소스에 액세스할 수 있는지를 결정할 수 있다. 예를 들어, 서버는 컴퓨트 노드에서의 총 이용 가능 할당을 결정하기 위해 아래의 방정식 1300 을 따를 수 있다: 총 이용 가능 할당 = 총 잠재적 할당 - 기존 할당(들) 방정식 1300 위의 방정식 1300에서, 총 잠재적 할당은 컴퓨트 노드에서의 민감한 리소스의 총 잠재적 할당이고, 기존 할당은, 예를 들어, 다른 함수에 대한, 컴퓨트 노드에서의 민감한 리소스의 현재 할당이다. 서버는 민감 한 리소스의 충분한 할당이 존재하는지를 결정하기 위해 아래의 방정식 1301을 따를 수 있다: 민감한 리소스 요구사항 ≤ 총 이용 가능 할당 방정식 1301 민감한 리소스 요구사항은 함수의 민감한 리소스 요구사항이다. 방정식 1301이 참이면, 충분한 할당이 존재한 다. 즉, 민감한 리소스 요구사항이 컴퓨트 노드에서의 민감한 리소스의 총 이용 가능 할당보다 작거나 같으면, 컴퓨트 노드에서 함수의 실행을 완료하기에 충분한 할당이 존재한다. 일부 실시예에서, 서버는 제4 내지 제6 함수(1318, 1320, 1322)에 대한 제1 내지 제3 리소스 할당(1332, 1334, 1336)을 감소시키고, 민감한 리소스가 균등하게 분배되도록 해당 제1 내지 제3 리소스를 제1 내지 제3 함 수(1312, 1314, 1316)에 할당한다. 예를 들어, 일부 실시예에서, 서버는 제1 컴퓨트 노드(1304a)보다는 제3 컴퓨트 노드(1304c)에 제1 함수를 분배할 수 있다. 제1 및 제4 함수(1312 및 1318) 둘 모두는 민감 한 리소스인 제1 리소스를 필요로 하며, 따라서 리소스 경쟁이 있을 수 있다. 리소스 경쟁을 감소시키기 위해, 서버는 제4 함수에 대한 제1 리소스 할당을 감소시키고 제1 함수에 대한 제1 리소스 할당을 증가시킬 수 있다. 그렇게 하는 것은 제4 함수와 제1 함수 사이의 제1 리소스의 균 등한 할당을 확립할 수 있다. 일부 실시예에서, 서버는 리소스 경쟁을 방지하도록 제1 내지 제3 함수(1312, 1314, 1316)의 타이밍을 스 케줄링할 수 있다. 예를 들어, 일부 실시예에서, 서버는 제1 함수를 제3 컴퓨트 노드(1304c)에 제 공할 수 있다. 언급된 바와 같이, 제1 함수 및 제4 함수 둘 모두는 민감한 리소스인 제1 리소스를 필요로 하며, 따라서 리소스 경쟁이 있을 수 있다. 리소스 경쟁을 방지하기 위해, 서버는 제4 함수 가 실행을 완료한 후에 제1 함수를 제3 컴퓨트 노드(1304c)에서 실행되도록 스케줄링할 수 있다. 그렇게 하는 것은 제1 함수와 제4 함수 사이의 제1 리소스에 대한 리소스 경쟁을 방지할 수 있다. 일부 실시예에서, 서버는 하드웨어 가속기 및/또는 FPGA가 함수(1312, 1314, 1316) 중 하나의 함수의 실 행을 향상시킬 수 있다고 결정할 수 있다. 서버는 함수(1312, 1314, 1316) 중 하나를 그에 따라 하드웨 어 가속기에 액세스할 수 있도록 스케줄링할 수 있다. 일부 실시예에서, 컴퓨트 노드(1304a 내지 1304c)는 프로세서 코어, 컴퓨팅 디바이스 또는 서버일 수 있다. 일 부 실시예에서, 트리거링 디바이스(1306, 1308, 1310)는 원격 서버(도시되지 않음)에서 실행 중인 애플리케이션 을 호출할 수 있고, 애플리케이션은 차례로 함수(1312, 1314, 1316)에 대한 요청을 서버에 제공한다. 일 부 실시예에서, 서버가 함수(1312, 1314, 1316)를 호출할 수 있다. 트리거링 디바이스(1306, 1308, 1310)는, 예를 들어, 랩톱, 모바일 디바이스, 서버, 데스크톱 등을 포함할 수 있다. 일부 실시예에서, 서버 는 제1 내지 제3 컴퓨트 노드(1304a 내지 1304c)를 포함할 수 있다. 게다가, 일부 실시예에서, 서버 는 위에서 설명된 양태를 구현하는 도 4의, 오케스트레이터와 같은, 향상된 FaaS 시스템을 포 함할 수 있다. 도 13b는 도 13a의 서버에 의해 구현될 수 있는 더 공정한 빈 패킹을 위한 향상된 스케줄링 프로세스 를 예시한다. 본 예에서, 함수 0 및 함수 1 각각에 대한 대역 1 및 대역 2는 할당된 하드웨어 리소스일 수 있다. 예를 들어, 대역 1은 하드웨어 가속기 리소스를 나타낼 수 있고 대역 2는 할당된 프로세서 코어 리소 스를 나타낼 수 있다. 예를 들어, 서버는, 함수 0과 함수 1이 동일한 컴퓨트 노드에서 동시에 동작하는 경우, 함수 0과 함수 1에 할당된 예측된 IPC(instruction-per-cycle) 리소스(1340, 1342)를 식별하기 위해 함 수 0과 함수 1을 추론적으로 분석할 수 있다. 함수 1은, 예를 들어, 비-FaaS 함수일 수 있고 함수 0은 FaaS 함 수일 수 있다. 언급된 바와 같이, 함수 1은 함수 0에 비해 부당하게 많은 양의 리소스(1340, 1342)(예를 들면, 할당된 하드웨어 리소스)를 할당받을 수 있다. 예를 들어, 함수 1이 함수 0보다 먼저 동작을 시작하는 경우, 함수 1은 불공정한 리소스 할당을 가질 수 있다. 따라서, 함수 0 및 함수 1의 스케줄링은 화살표로 예시된 바와 같이 더 공정한 빈 패킹을 위해 및/또는 상이한 시간에, 또는 상이한 노드에 스케줄링되도록 수정될 수 있고 그리고/또는 더 높은 IPC에 필요한 하드웨 어 리소스 간의 공정성(예를 들면, 동일한 양)을 확립하기 위해 하드웨어 리소스가 재분배될 수 있다. 따라서, 함수 0은 함수 1에 할당된 리소스(예를 들면, 할당된 하드웨어 리소스)의 양에 의해 달성된 것과 동일한 IPC를 달성하는 리소스(예를 들면, 할당된 하드웨어 리소스)의 양을 할당받을 수 있다. 예시되어 있지 않지만, 전력 및 주파수 할당이 또한 수정에 의해 함수 0과 함수 1 사이에 더 균등하게 할당될 수 있다. 도 13c는 CSP 환경에서 함수를 스케줄링하는 방법을 도시하고, 도 13a의 서버 및/또는 도 4의, 오 케스트레이터와 같은, 향상된 FaaS 시스템에 의해 실행될 수 있다. 방법은 하나 이상의 모듈 에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다.예를 들어, 방법에 도시된 동작을 수행하기 위한 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 등과 같 은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프 로그래밍 언어를 포함하여, 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 추가적으로, 로 직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴 포넌트를 포함할 수 있다. 예시된 프로세싱 블록은, 복수의 함수의 각각의 각자의 함수에 대해, 각자의 함수를 실행하는 데 필요한 하나 이상의 민감한 리소스를 결정하는 것을 포함할 수 있다. 예시된 프로세싱 블록은 함수들 중 제1 함 수의 하나 이상의 민감한 리소스와 함수들 중 제2 함수의 하나 이상의 민감한 리소스 사이의 리소스 충돌을 결 정하는 것을 포함할 수 있다. 예시된 프로세싱 블록은 리소스 충돌을 방지하도록 제1 함수 또는 제2 함 수 중 하나 이상을 스케줄링하는 것을 포함할 수 있다. 예를 들어, 예시된 프로세싱 블록은 동일한 노드 에서 완전히 비-중첩하는 시간에 실행되도록, 서로 상이한 노드에서 실행되도록 그리고/또는 공정성을 확립하고 서비스 품질을 유지하기 위해 리소스 할당을 하나의 함수로부터 다른 함수로 재분배하도록 제1 함수 또는 제2 함수 중 하나 이상을 스케줄링하는 것을 포함할 수 있다. 예시된 프로세싱 블록은 제각기 제1 및 제2 함 수에 대한 목표 성능 수율을 달성하기 위해 민감한 리소스들 중 하나 이상을 제1 및 제2 함수에 스케줄링하는 것을 포함할 수 있다. 예를 들어, 예시된 프로세싱 블록은 민감한 리소스를 제1 및 제2 함수에 할당하는 것을 포함할 수 있다. 예시되어 있지 않지만, 방법은 제1 함수의 하나 이상의 민감한 리소스와 함수들 중 제3 함수의 하나 이상의 민감한 리소스 사이의 리소스 충돌의 결여를 결정하는 것을 포함할 수 있다. 방법 은 리소스 충돌의 결여에 기초하여 중첩하는 시간에 동일한 노드에서 실행되도록 제1 및 제3 함수를 스케 줄링하는 것을 포함할 수 있다. 방법은 CSP 환경의 효율성 및 동작을 향상시킬 수 있다. 예를 들어, 방법은 레이턴시를 감소시키 고 함수의 완료율을 향상시킬 수 있다. 추가 비고 및 예 예 1300은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 복수의 함수의 각각의 각자의 함수에 대해, 각자의 함수를 실행하는 데 필요한 하나 이상의 민감한 리소스를 결정하게 하고, 복수의 함수 중 제1 함 수의 하나 이상의 민감한 리소스와 복수의 함수 중 제2 함수의 하나 이상의 민감한 리소스 사이의 리소스 충돌 을 결정하게 하며, 리소스 충돌을 방지하도록 제1 함수 또는 제2 함수 중 하나 이상을 스케줄링하게 하고, 상이 한 시간에 실행되도록 제1 함수 및 제2 함수를 스케줄링하게 하며, 상이한 컴퓨트 노드에서 실행되도록 제1 함 수 및 제2 함수를 스케줄링하게 하고, 제1 함수의 하나 이상의 민감한 리소스와 복수의 함수 중 제3 함수의 하 나 이상의 민감한 리소스 사이의 리소스 충돌의 결여를 결정하게 하며, 중첩하는 시간에 동일한 노드에서 실행 되도록 제1 함수 및 제3 함수를 스케줄링하게 하고, 제각기 제1 함수 및 제2 함수에 대한 목표 성능 수율을 달 성하기 위해 민감한 리소스들 중 하나 이상을 제1 함수 및 제2 함수에 스케줄링하게 하는 명령어 세트를 포함하 는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 1301은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 복수의 함수의 각각의 각자의 함수에 대해, 각자의 함수를 실행하는 데 필요한 하나 이상의 민감한 리소스를 결정하게 하고, 복수의 함수 중 제1 함 수의 하나 이상의 민감한 리소스와 복수의 함수 중 제2 함수의 하나 이상의 민감한 리소스 사이의 리소스 충돌 을 결정하게 하며, 리소스 충돌을 방지하도록 제1 함수 또는 제2 함수 중 하나 이상을 스케줄링하게 하는 명령 어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 1302는 예 1301의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 상이한 시간에 실행되도록 제1 함수 및 제2 함수를 스케줄링하게 하는 추가 명령 어 세트를 포함한다. 예 1303은 예 1301의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 상이한 컴퓨트 노드에서 실행되도록 제1 함수 및 제2 함수를 스케줄링하게 하는 추가 명령어 세트를 포함한다. 예 1304는 예 1301의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 제1 함수의 하나 이상의 민감한 리소스와 복수의 함수 중 제3 함수의 하나 이상의 민감한 리소스 사이의 리소스 충돌의 결여를 결정하게 하고, 중첩하는 시간에 동일한 노드에서 실행되도록 제1 함수 및 제3 함수를 스케줄링하게 하는 추가 명령어 세트를 포함한다. 예 1305는, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 복수의 함수의 각각의 각자의 함수에 대해, 각자의 함수를 실행하는 데 필요한 하나 이상의 민감한 리소스를 결정하게 하고, 복수의 함수 중 제1 함 수의 하나 이상의 민감한 리소스와 복수의 함수 중 제2 함수의 하나 이상의 민감한 리소스 사이의 리소스 충돌 을 결정하게 하며, 제각기 제1 함수 및 제2 함수에 대한 목표 성능 수율을 달성하기 위해 민감한 리소스들 중 하나 이상을 제1 함수 및 제2 함수에 스케줄링하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가 능 저장 매체를 포함한다. FaaS를 위한 향상된 함수 실행 도 14a 및 도 14b는 일부 실시예에 따른 향상된 함수 실행 시퀀스를 예시한다. 그러한 예는 도 13a의 서 버, 예를 들어, 제1 내지 제3 컴퓨트 노드(1304a 내지 1304c) 중 하나 이상 및/또는 도 4의, 오케스트레 이터와 같은, 향상된 FaaS 시스템에 의해 구현될 수 있다. 더 상세하게는, 함수 호출은 실행 할 함수를 요청할 수 있다. 함수 호출은 FaaS 컨텍스트에서 \"트리거\"라고도 지칭될 수 있다. 함 수는 서버리스 함수(예를 들면, 단일 FaaS 함수)일 수 있다. 함수는 어떤 순서로 실행 가능한 내 부 동작들의 집합체로 볼 수 있다. 동작은 전체 함수의 일부를 달성하는 함수 내의 모듈의 실행일 수 있 다. 예를 들어, 함수가 조건 세트에 따라 데이터베이스 테이블로부터 몇개의 튜플을 선택하고, 이어서 원하는 순서로 출력을 생성하기 위해 결과를 정렬(sort)하거나 정렬된 출력에서 추가로 하위 선택(subselect)할 필요가 있다고 가정한다. 그 예에서, 선택 및 정렬은 함수 내부에서의 두 가지 동작이다. 내부 동작은 \"펑크릿(funclet)\"이라고 지칭될 수 있다. 분해 절차는, 함수를 원자 단위로서 취급하고 제시된 바와 같이 함수를 실행하기보다는, 예 를 들어, 트랜스코드, 또는 함수의 코드 보디로부터 어느 모듈이 호출되는지의 정적 분석을 통해, 함수 를 일련의 펑크릿(1408a 내지 1408e)으로 분해할 수 있다. 분해 절차는 프로그래머에 의해, 클라 우드 서비스 제공자에 의해 지정될 수 있고, 그리고/또는 서드파티에 의해 저작된 최적화 툴 체인에 의해 구현 될 수 있다. 분해 절차 및 분해 절차의 동작은 프로그래머 또는 클라우드 서비스 제공자에 의해 제공되는 옵션, 힌트, 지시문(directive) 등에 의해 추가로 제어될 수 있다. 펑크릿(1408a 내지 1408c) 중 하 나 이상은 임의로 사용자에 의해 구현되고 절차에 지정될 수 있다. 함수와 달리, 펑크릿(1408a 내지 1408e)은 효율적인 계산 및 코디네이션을 위해 서로 간에 다양한 레벨의 상태를 공유할 수 있다. 개별 펑크릿 (1408a 내지 1408e)은 레이턴시를 감소시키고 리소스를 더 효율적으로 관리하기 위해 개별 스케줄링 및 실행 프 로세스를 거칠 수 있다. 상세하게는, 펑크릿(1408a 내지 1408e) 중 일부는 레이턴시를 감소시키기 위해 동시에 실행될 수 있다. 게다가, 펑크릿(1408a 내지 1408e) 중 특정 펑크릿이 실행하기 위해 특수 하드웨어(예 를 들면, 가속기 또는 FPGA) 또는 펌웨어와 같은 리소스를 필요로 하는 경우, 리소스 이용률(resource utilization) 및 스케줄링을 향상시키기 위해 특수 하드웨어가 이용 가능하게 될 때까지 펑크릿(1408a 내지 1408e) 중 해당 특정 펑크릿의 실행을 지연시키는 것이 가능할 수 있다. 예시된 바와 같이, 함수는 펑크릿(1408a 내지 1408e)으로 구성된 종속성 그래프로 분해될 수 있으 며, 여기서 종속성 그래프는 펑크릿(1408a 내지 1408e)의 실행 순서를 나타낸다. 종속성 그래프에 서, 펑크릿(1408a)이 먼저 실행될 수 있다. 펑크릿(1408b, 1408c)은 펑크릿(1408a)으로부터의 정보에 기초하여 실행될 수 있고, 동시에 실행될 수 있다. 펑크릿(1408d)은 펑크릿(1408b, 1408c) 이후에 2개의 펑크릿(1408b, 1408c)으로부터의 정보에 기초하여 동작할 수 있다. 펑크릿(1408e)은 펑크릿(1408d)으로부터의 정보에 기초하 여 펑크릿(1408d) 이후에 실행되고 함수의 실행을 완료할 수 있다. 스케줄링 및 실행 절차는 펑크릿(1408a 내지 1408e) 각각을 개별적으로 스케줄링하기 위해 종속성 그래프 에 기초하여 동작한다. 예를 들어, 종속성 그래프에 기초하여, 펑크릿(1408a 내지 1408e) 사이의 상호연결이 명확하다. 따라서, 스케줄링 및 실행 절차는 종속성 그래프의 종속성 상호연결에 기초 하여 펑크릿(1408a 내지 1408e)을 동시에(병렬로) 스케줄링할지 또는 순차적으로(연달아) 스케줄링할지를 결정 할 수 있다. 도 14b의 스케줄 그래프에 예시된 바와 같이, 펑크릿(1408a 내지 1408e)은 타이밍 T0과 타이밍 T4 사이의 다양한 시간 슬롯 동안 다양한 컴퓨트 노드(1412a 내지 1412c)에서 동작하도록 스케줄링 및 실행 절차에 의해 스케줄링될 수 있다. 펑크릿(1408a)은 시간 T0과 시간 T1 사이에 컴퓨트 노드(1412a)에서 실행되도록 스케줄링될 수 있다. 다른 펑크릿(1408b 내지 1408e)이 펑크릿(1408a)으로부터의 데이터를 필요로 하기 때문에, 다 른 펑크릿 중 어느 것도 시간 T0 내지 시간 T1 동안 실행될 수 없다. 펑크릿(1408a)이 실행을 완료한 후에, 펑크릿(1408b, 1408c) 둘 모두는 시간 T1과 시간 T2 사이에 컴퓨트 노드 (1412a, 1412b)에서 실행될 수 있다. 종속성 그래프에 예시된 바와 같이, 펑크릿(1408b, 1408c) 둘 모 두가 펑크릿(1408d, 1408e)이 아닌 펑크릿(1408a)으로부터의 정보만을 필요로 하기 때문에 펑크릿(1408b, 1408c)은 동시에 실행될 수 있다. 따라서, 스케줄 그래프에서, 펑크릿(1408b, 1408c)은 상이한 컴퓨트 노드(1412a, 1412b)에서 동시에 실행된다. 일부 실시예에서, 컴퓨트 노드(1412a 내지 1412c) 중 하나가 펑크릿 (1408b, 1408c) 둘 모두를 지원하기에 충분한 리소스를 갖는 경우, 펑크릿(1408b, 1408c) 둘 모두는 컴퓨트 노 드(1412a 내지 1412c) 중 하나에서 실행되도록 스케줄링될 수 있다. 펑크릿(1408b, 1408c)이 실행을 완료한 후에, 펑크릿(1408d)은 시간 T2 내지 시간 T3 동안 컴퓨트 노드(1412c) 에서 실행될 수 있다. 펑크릿(1408d)의 실행은 컴퓨트 노드(1412c)에서 발견되는 하드웨어 가속기 및/또는 FPGA를 통해 향상될 수 있다. 따라서, 스케줄링 및 실행 절차는, 하드웨어 리소스와 같은, 리소스가 펑 크릿(1408a 내지 1408e) 중 하나의 펑크릿의 실행을 향상시킬 수 있는지를 추가로 고려하고, 그에 따라 펑크릿 (1408a 내지 1408e) 중 하나를 스케줄링할 수 있다. 게다가, 종속성 그래프에 예시된 바와 같이, 펑크릿 (1408d)은 실행하기 위해 펑크릿(1408e)이 아니라 펑크릿(1408b, 1408c)으로부터의 데이터를 필요로 할 수 있으 며, 따라서 펑크릿(1408b, 1408c)이 실행을 완료한 후에 스케줄링된다. 펑크릿(1408d)이 실행을 완료한 후에, 펑크릿(1408e)은 시간 T3 내지 시간 T4 동안 컴퓨트 노드(1412c)에서 실 행될 수 있다. 리소스의 효율성은 펑크릿(1408e)이 컴퓨트 노드(1412c)에서 실행되게 하는 것에 의해 향상될 수 있다. 즉, 펑크릿(1408e)이 펑크릿(1408d)으로부터의 데이터를 필요로 할 수 있기 때문에, 펑크릿(1408e)은 컴퓨트 노드(1412a 내지 1412c) 사이의 데이터 전송을 최소화하고 메모리 및 캐시 사용량을 향상시키기 위해 펑 크릿(1408d)과 동일한 노드에서 실행되도록 스케줄링될 수 있다. 따라서, 스케줄링 및 실행 절차는 데이 터 전송을 최소화하고 펑크릿(1408a 내지 1408e)의 향상된 스케줄링을 통해 캐시 재사용을 향상시킴으로써 리소 스 사용량을 추가로 향상시킬 수 있다. 일부 실시예에서, 펑크릿(1408a 내지 1408e) 하나 이상은 펑크릿(1408a 내지 1408e)에 필요한 리소스가 이용 가 능해질 때 재생성된 상태로부터 나중에 실행될 수 있다. 예를 들어, 펑크릿(1408d)이 실행을 위해 하드웨어 가 속기를 필요로 한다고 가정한다. 펑크릿(1408d)은 하드웨어 가속기가 이용 가능하다는 식별에 응답하여 실행되 도록 스케줄링될 수 있다. 펑크릿(1408d)의 실행은 펑크릿(1408b, 1408c)이 실행을 완료하고 나서 일정 기간 후에 발생할 수 있다. 즉, 펑크릿(1408d)은 펑크릿(1408b, 1408c)이 실행을 완료하자마자 실행을 시작하도록 자동 트리거되지 않을 수 있다. 오히려, 펑크릿(1408d)은 펑크릿(1408b, 1408c)이 실행을 완료하는 것에 추가 하여 하드웨어 가속기가 이용 가능해질 때 실행되도록 스케줄링될 수 있다. 함수를 펑크릿(1408a 내지 1408e)으로 분할하는 것은 함수의 실패 가능성을 감소시킬 수 있다. 예 를 들어, 일부 실시예에서, 함수의 동작들 중 일부는, 위에서 언급된 펑크릿(1408d)과 같이, 특정 하드웨 어를 필요로 할 수 있다. 함수가 하드웨어를 기다려야 하는 경우, 함수가 미리 결정된 시간 제한 이전에 완료되지 않고 따라서 포기되는 타임아웃 실패가 발생할 수 있다. 함수를 일련의 개별 펑크릿(1408a 내지 1408e)으로 분할함으로써, 펑크릿(1408a 내지 1408e)이 리소스가 이용 가능할 때에만 동작하도록 개별적으로 스케줄링될 수 있기 때문에 그러한 타임아웃 실패가 더 잘 방지될 수 있다. 간단히 말하면, 함수는 리소스가 이용 가능할 때까지 펑크릿(1408a 내지 1408)을 개시하는 것 을 기다림으로써 펑크릿(1408a 내지 1408e) 사이에서 \"일시중지\"될 수 있다. 언급된 바와 같이, 펑크릿(1408 d)은, 실행을 시작하고 하드웨어 가속기가 이용 가능해지기를 기다리는 것보다는, 하드웨어 가속기가 이용 가능 해질 때 실행되도록 스케줄링될 수 있다. 게다가, 분해 절차와, 스케줄링 및 실행 절차는 함수의 세분성보다 더 미세한 세분성인 펑크 릿(1408a 내지 1408e) 레벨 세분성으로 리소스를 취득 및 해제함으로써 전반적인 실행을 향상시킬 기회를 제공 할 수 있다. 게다가, 특수 목적 하드웨어 가속기에서 가속될 수 있는 펑크릿(1408d)과 같은 펑크릿을 종래의 또는 CPU 기반 소프트웨어 실행에 더 적합한 것, 예를 들어, 펑크릿(1408a 내지 1408c 및 1408e)과 혼합하는 것 이 가능할 수 있다. 게다가, 실시예는, 종속성 그래프에 예시된 바와 같이, 순서와 함께 함수가 더 작은 펑크릿(1408a 내지 1408e)으로 분해되는 함수의 간단한 흐름 실행을 가능하게 한다. 스케줄링 및 실행 절차에서 구현된 스케줄링 스킴은, 펑크릿 순서를 유지하면서 기회주의적 스케줄링을 위해, 해당 리소스에 대한 다른 경 쟁하는 요구의 가용 리소스/실행 또는 우선순위를 모니터링할 수 있다. 더욱이, 개발자는 향상된 함수 실행 시 퀀스를 인식하지 못할 수 있다. 프로세스가 CSP 측에서 불투명하게 실행되므로 개발자가 하위 함수를 식 별할 필요가 없기 때문에 이것은 개발자 작업을 단순화할 수 있다. 위에서 설명된 바와 같이, 펑크릿(1408a 내지 1408e)은 종속성 그래프에 의해 기술된 순서 종속성에 따라 실행 플랫폼에 프로비저닝될 수 있다. 어드레스 공간 경계 내에서 또는 그에 걸쳐 동시 활동으로서 스케줄링될 수 있는 펑크릿(1408a 내지 1408e)에 대해 사용자 레벨 인터럽트(ULI), 하드웨어 큐 관리자, RAO(Remote Atomics) 등을 확장하는 기술을 사용하는 효율적인 논리 장벽 및 이벤트 코디네이션에 대한 지원을 포함하여, 종속성 그래프에서 올바른 순서 종속성을 보장하기 위한 아키텍처 지원이 제공될 수 있다. 펑크릿(1408a 내지 1408e)은 또한 위에서 설명된 바와 유사하게 실행되는 \"미니-펑크릿(mini-funclet)\"이라고 불리는 더 작은 단위로 분해될 수 있다. 향상된 함수 실행 시퀀스는 하나 이상의 하드웨어 큐 관리자에 의해 코디네이션될 수 있다. 다수의 하드 웨어 큐 관리자는 펑크릿(1408a 내지 1408e)을 스케줄링하고 큐잉할 수 있다. 하드웨어 큐 관리자는 상이한 노 드에 있을 수 있지만, 종속성 그래프의 실행 순서로 펑크릿(1408a 내지 1408e)의 큐를 유지하고 그에 따 라 스케줄링할 수 있다. 향상된 함수 실행 시퀀스는 추가로 위에서 언급된 바와 같이 도 13a의 서버에 의해 구현될 수 있지 만, 또는 서버와 협력하여, 도 4의, 오케스트레이터와 같은, 향상된 FaaS 시스템 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 도 구현될 수 있다. 예를 들어, 향상된 함수 실행 시퀀스에 도시된 동작을 수행하기 위한 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 등과 같은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 추가적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인 화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 예로서, 함수가 짧은 음성 파일을 분석하는 것을 포함한다고 가정한다. 짧은 음성 파일의 분석은, 음성 파일을 텍스트로 변환(전사)하는 것, 상이한 참가자가 말한 단어 및/또는 문장을 인식 및 분리하는 것, 및 전사를 화자 의 ID(identity)에 귀속시키는 것을 포함한, 펑크릿들(예를 들면, 구성 동작들)로 분해될 수 있다. 향상된 함 수 실행 시퀀스에 대해 위에서 설명된 바와 같이 함수를 분해함으로써, 펑크릿들 중 일부가 특정 양의 리 소스로 이용 가능한 양의 시간 내에 완료되도록, 함수의 부분 실행이 달성된다. 따라서, 함수를 펑크릿으로 분 해하는 것은 실행을 향상시키고, 리소스 사용량을 감소시키며 레이턴시를 감소시킬 수 있다. 도 14c는 CSP 환경에서 다수의 동작을 갖는 함수를 스케줄링하는 방법을 도시하며, 도 13a의 서버 에 의해 실행될 수 있지만, 또는 서버와 협력하여, 도 4의, 오케스트레이터와 같은, 향상된 FaaS 시 스템 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에 서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이 들의 임의의 조합으로도 구현될 수 있다. 예를 들어, 방법에 도시된 동작을 수행하기 위한 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 등과 같 은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프 로그래밍 언어를 포함하여, 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 추가적으로, 로 직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴 포넌트를 포함할 수 있다.예시된 프로세싱 블록은 함수의 동작들(예를 들면, 펑크릿들)을 결정할 수 있다. 예시된 프로세싱 블록 은 식별된 동작들에 따라 함수를 펑크릿들로 분할한다. 예를 들어, 각각의 펑크릿은 단일 동작을 포함할 수 있다. 다른 실시예에서, 동작들이 서로 관련되어 있는 경우(예를 들면, 유사한 데이터를 활용하거나 서로로 부터의 데이터를 필요로 함) 각각의 펑크릿은 여러 동작을 포함할 수 있다. 예시된 프로세싱 블록은 펑 크릿들의 순서를 결정하기 위해 정적 상호종속성 그래프를 생성할 수 있다. 예를 들어, 위에서 언급된 바와 같 이, 순서는 펑크릿(예를 들면, 동작)이 동시에 또는 순차적으로 실행될 수 있는지를 결정하는 것을 포함할 수 있다. 예시된 프로세싱 블록은 결정된 순서에 기초하여 펑크릿을 개별적으로 스케줄링할 수 있다. 예를 들어, 다른 펑크릿이 제1 펑크릿으로부터의 데이터에 의존하는 경우, 제1 펑크릿(예를 들면, 동작)이 다른 펑크 릿(예를 들면, 동작)보다 먼저 스케줄링될 수 있다. 예시된 프로세싱 블록은 추가로 제1 컴퓨트 노드에 서 실행되도록 제1 펑크릿을 스케줄링하고 제1 컴퓨트 노드와 상이한 제2 컴퓨트 노드에서 실행되도록 제2 펑크 릿을 스케줄링할 수 있다. 따라서, 제1 함수 및 제2 함수의 레이턴시를 감소시키기 위해 동시 스케줄링이 용이 하게 되거나 또는 상이한 하드웨어(예를 들면, 특수 하드웨어 및/또는 비-특수 하드웨어)의 사용이 용이하게 될 수 있다. 예시된 프로세싱 블록은 또한 제1 시간에 펑크릿들 중 제1 펑크릿을 스케줄링하고 제1 시간과 상이한 제2 시간에 펑크릿들 중 제2 펑크릿을 스케줄링할 수 있다. 따라서, 제1 펑크릿 및 제2 펑크릿의 순차적 실행이 구 현될 수 있다. 게다가, 예시된 프로세싱 블록은 리소스 할당(예를 들면, 특수 하드웨어 가속기 및/또는 FPGA)이 이용 가능하다는 식별 및 제1 펑크릿이 완료되었다는 식별 둘 모두에 응답하여 실행을 시작하도록 제2 펑크릿을 스케줄링할 수 있다. 그러한 실시예에서, 방법은 리소스 할당이 이용 가능할 때까지 제2 펑크 릿의 실행을 의도적으로 지연시키는 단계를 추가로 포함할 수 있다. 게다가, 제2 펑크릿은 제1 펑크릿으로부터 의 출력을 필요로 할 수 있다. 방법은 CSP 환경의 효율성 및 동작을 향상시킬 수 있다. 예를 들어, 방법은 레이턴시를 감소시키 고, 리소스 이용률을 향상시키며, 함수의 완료율을 향상시킬 수 있다. 추가 비고 및 예 예 1400은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 함수의 동작들을 결정하게 하고, 동 작들의 순서를 결정하게 하며, 결정된 순서에 기초하여 동작들을 개별적으로 스케줄링하게 하고, 제1 컴퓨트 노 드에서 실행되도록 동작들 중 제1 동작을 스케줄링하게 하고, 제2 컴퓨트 노드에서 실행되도록 동작들 중 제2 동작을 스케줄링하게 하며, 제1 시간에 제1 동작을 스케줄링하게 하고, 제1 시간과 상이한 제2 시간에 제2 동작 을 스케줄링하게 하며, 리소스 할당이 이용 가능하다는 식별 및 제1 동작이 완료되었다는 식별 둘 모두에 응답 하여 실행을 시작하도록 제2 동작을 스케줄링하게 하고, 리소스 할당이 이용 가능할 때까지 제2 동작의 실행을 지연시키게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함하며, 여기서 제2 동작은 제1 동작으로부터의 출력을 수신하는 것이다. 예 1401은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 함수의 동작들을 결정하게 하고, 동 작들의 순서를 결정하게 하며, 결정된 순서에 기초하여 동작들을 개별적으로 스케줄링하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 1402는 예 1401의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 컴퓨트 노드에서 실행되도록 동작들 중 제1 동작을 스케줄링하게 하고, 제2 컴퓨트 노드에서 실행되도록 동작들 중 제2 동작을 스케줄링하게 하는 추가 명령어 세트를 포함한다. 예 1403은 예 1401의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 시간에 동작들 중 제1 동작을 스케줄링하게 하고, 제1 시간과 상이한 제2 시간에 동작들 중 제2 동작을 스케줄링하게 하는 추가 명령어 세트를 포함한다. 예 1404는 예 1403의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 리소스 할당이 이용 가능하다는 식별 및 제1 동작이 완료되었다는 식별 둘 모두에 응답 하여 실행을 시작하도록 제2 동작을 스케줄링하게 하는 추가 명령어 세트를 포함한다. 예 1405는 예 1404의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 리소스 할당이 이용 가능할 때까지 제2 동작의 실행을 지연시키게 하는 추가 명령어 세 트를 포함한다.예 1406은 예 1403의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 제2 동작은 제1 동작으로부터의 출력을 수신하는 것이다. 예 1407은 예 1400의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 사용자 입력에 기초하여 동작들을 결정하게 하는 추가 명령어 세트를 포함한다. FaaS를 위한 향상된 메모리 할당 도 15a는 일부 실시예에 따른 성능 및 메모리 저장 향상된 컴퓨팅 아키텍처를 예시한다. 그러한 예는 도 13a의 서버, 예를 들어, 제1 내지 제3 컴퓨트 노드(1304a 내지 1304c) 중 하나 이상 및/또는 도 4의, 오 케스트레이터와 같은, 향상된 FaaS 시스템에 의해 구현될 수 있다. 성능 및 메모리 저장 향상된 컴퓨팅 아키텍처는 컨테이너 및 함수를 포함한다. 함수는 컨테 이너와 협력하여 동작할 수 있다. 예를 들어, 함수는 컨테이너에 로딩될 수 있다. 일부 실 시예에서, 함수는 다운로드되어 컨테이너에 인스턴스화될 수 있다. 플랫폼 운영 체제는 컨 테이너 및 함수를 호스팅하고, 컨테이너 및 함수에 대한 데이터를 저장하기 위해 메모 리와 협력하여 동작할 수 있다. 예시된 바와 같이, 플랫폼 운영 체제는 전용 컨테이너 메모리 목록 및 전용 함수 메모리 목록 을 포함할 수 있다. 전용 컨테이너 메모리 목록 및 전용 함수 메모리 목록은 함수 및 /또는 컨테이너에 전용인 메모리의 어드레스 범위를 식별해주는 데이터 구조, 어레이 또는 룩업 테 이블일 수 있다. 예를 들어, 전용 컨테이너 메모리 목록은 기본 컨테이너 메모리 공간(1520a 내지 1520c)을 식별해준다. 전용 함수 메모리 목록은 함수 메모리 공간(1522a, 1522b)을 식별해준다. 예시된 바와 같이, 메모리는 미할당된 메모리 공간도 포함할 수 있다. 메모리 할당 요청이 플랫폼 운영 체제에 의해 수신될 때, 플랫폼 운영 체제는 함수 또는 컨 테이너가 메모리 할당 요청을 발신하는지를 결정할 수 있다. 컨테이너가 메모리 할당 요청을 발신 하는 경우, 전용 컨테이너 메모리 목록에 기초하여 메모리 할당이 제공될 수 있다. 예를 들어, 메모리 할당은 전용 컨테이너 메모리 목록에 의해 식별된 메모리 범위의 할당일 수 있다. 따라서, 컨테이너 는 플랫폼 운영 체제로부터 수신된 메모리 할당에 기초하여 데이터를 기본 컨테이너 메모리 공간 (1520a 내지 1520c)에 저장 및 기입할 수 있다. 따라서, 컨테이너는 기본 컨테이너 메모리 공간(1520a 내지 1520c)을 통해 표준의 신뢰할 수 있는 메모리 부분으로 프로비저닝될 수 있다. 이와 달리, 함수가 메모리 할당 요청을 발신하는 경우, 전용 함수 메모리 목록에 기초하여 메모리 할당이 제공될 수 있다. 예를 들어, 메모리 할당은 전용 함수 메모리 목록에 의해 식별된 메모리 범위의 할당일 수 있다. 따라서, 함수는 데이터를 함수 메모리 공간(1522a, 1522b)에 저장 및 기입할 수 있다. 그와 같이, 컨테이너의 컨테이너 특정 데이터 및 함수에 의해서만 사용되는 함수 특정 데이터는 상 이한 기본 컨테이너 및 함수 메모리 공간(1520a 내지 1520c, 1522a, 1522b)에 저장될 수 있다. 컨테이너 특정 데이터는 많은 상이한 함수에 의해 재사용 가능할 수 있고 함수의 실행 동안 함수에 의해 변경되지 않을 수 있다. 일단 함수가, 예를 들어, 실행을 완료하는 것 또는 오류 발생(faulting)에 의해 종료되면, 함수 메모리 공간(1522a, 1522b)에 저장된 함수 특정 데이터가 와이핑(wipe)될 수 있다. 기본 컨테이너 메모리 공간(1520a 내지 1520c)에 저장된 컨테이너 특정 데이터는 함수가 실행을 완료할 때 와이핑되지 않을 수 있다. 그와 같이, 함수가 종료되고 더 이상 실행되지 않을 때에도, 컨테이너는 실행을 위해 다른 함수를 수신 할 준비가 된 세미-웜 상태(semi-warm state)로 유지된다. 따라서, 전체 컨테이너의 해체는 함수 가 종료될 때 와이핑되는 데이터의 제한에 의해 방지될 수 있다. 함수가 함수 메모리 공간(1522a, 1522b)에만 데이터를 저장하게 함으로써, 컨테이너의 상태로부터 함수에 의해 행해진 변경만이 제 거될 수 있으며, 이에 의해 컨테이너를 신뢰할 수 있는 코드가 기본 컨테이너 메모리 공간(1520a 내지 1520c)에 저장되어 있는 세미-웜 상태로 남겨둔다. 그와 같이, 데이터를 함수 특정 데이터와 컨테이너 특정 데 이터로 분할하고 그에 따라 저장함으로써, 보안을 향상시키고 고 레이턴시 콜드 컨테이너(cold container) 시작 을 감소시키기 위해 함수와 연관된 데이터의 삭제가 용이하게 될 수 있다. 상세하게는, 다양한 컨테이너 유형의 경우, 컨테이너를 종료 및 재시작하기 위한 오버헤드가 엄청날 수 있고 레이턴시를 증가시킬 수 있다. 예를 들어, 컨테이너가 신경 네트워크(예를 들면, 컨볼루션 신경 네트워크 또는 딥 신경 네트워크)에 대한 것인 경우, 컨테이너가 종료한 다음 다시 스핀 업하는 데 비용이 많이 들 수 있다. 이러한 이유는 신경 네트워크가 처리할 상당한 데이터 로드(예를 들면, 신경 가중치 및/또는 상수 값)를 포함하기 때문일 수 있다. 그러한 데이터 로드는, 데이터 로드가 상이한 함수에 의해 재사용될 수 있고 함수에 의해 변경될 수 없기 때문에, 컨테이너의 일부일 수 있다. 따라서, 함수에서 오류가 발생하는 경우, 컨테이너는 강제 종료되고 다시 스핀 업될 수 있으며, 이는 레이턴시를 증가시키고 효율 성을 감소시킨다. 컴퓨팅 아키텍처는 함수의 종료 프로세스를 향상시킬 수 있다. 예를 들어, 함수에서 오류가 발생하는 경우, 플랫폼 운영 체제는 종료되는 데이터의 범위를 제한할 수 있다. 즉, 함수 메모리 공간 (1522a, 1522b)에 저장된 데이터만이 와이핑 또는 할당해제될 수 있다. 따라서, 함수에 의해 행해진 변 경만이 컨테이너의 상태로부터 제거되고, 전체 컨테이너의 해체가 방지된다. 예시된 바와 같이, 플랫폼 운영 체제는 컨테이너에서 실행되는 함수를 위해 할당 및 사용되는 함수 메모리 공간 (1522a, 1522b) 및 컨테이너 자체를 위해 할당 및 사용되는 기본 컨테이너 메모리 공간(1520a 내지 1520c)을 포함하는 2개의 상이한 리소스 세트를 유지하는 능력을 컨테이너에 제공한다. 게다가, 함수가 종료된 후에 함수의 민감한 데이터가 와이핑되기 때문에 보안이 향상된다. 예를 들어, 함수에 특정적인 민감한 데이터는 함수 메모리 공간(1522a, 1522b)으로부터 와이핑될 수 있다. 플랫폼 운영 체제는 가상 머신 모니터(예시되지 않음)는 물론 컨테이너 또는 함수 중 하나 이상에 의해 사용되는 라이브러리와 협력하여 동작할 수 있다. 플랫폼 운영 체제, 가상 머신 모니터 및 라이브러리 중 하나 이상은 메모리 할당 호출(예를 들면, malloc, calloc 등)이 컨테이너의 일부인 것으 로 화이트 리스트에 있는(white listed) 코드 범위, 또는 컨테이너의 알려진 검증된 실행 보디로부터 유 래하는지를 결정하는 메커니즘을 구현할 수 있다. 메모리 할당 호출이 컨테이너의 화이트 리스트에 있는 코드 범위 또는 알려진 검증된 보디로부터 유래하는 경우, 메모리 할당 호출은 기본 컨테이너 메모리 공간 (1520a 내지 1520c)으로부터의 메모리 범위를 제공받는다. 그렇지 않으면, 기본적으로, 메모리 할당 호출은 함 수의 코드로부터 유래하는 것으로 가정되고 이어서 함수 메모리 공간(1522a, 1522b)으로부터의 메모리 범 위를 제공받는다. 전용 함수 메모리 범위는 \"임시(pro-tem)\" 범위로 간주될 수 있다. 예를 들어, 세그먼트화 위반의 결과로서, cleanup 또는 teardown 루프를 실행할 필요가 있는 경우, 기본 컨테이 너 메모리 공간(1520a 내지 1520c)를 해체하는 대신에, 함수의 함수 메모리 공간(1522a, 1522b)만이 해체 된다. 예를 들어, 전용 컨테이너 메모리 목록은 컨테이너에 의해 활용되는 모든 할당된 메모리 공 간의 목록을 포함할 수 있다. 마찬가지로, 전용 함수 메모리 목록은 함수에 의해 활용되는 모든 할당된 메모리 공간의 목록을 포함할 수 있다. 정리 동안, 컨테이너에 할당된 메모리 공간을 건드리지 않은 채로 남겨 두면서 함수에 할당된 메모리 공간은 해체 및 와이핑될 수 있다. 게다가, 임의의 유형의 메모리 할당 호출, 예를 들어, POSIX(Portable Operating System Interface Compliant Unix) 시스템 호출(예를 들면, mmap() 호출) 또는 동적 메모리 할당 호출(예를 들면, malloc, calloc 등)은 위 에서 설명된 바와 같이 식별되고 적절하게 지시될 수 있다. 예를 들어, mmap() 호출이 함수로부터 수신 되는 경우, 매핑을 위해 제공된 가상 메모리 범위는 전용 함수 메모리 목록에 기초하여 제공될 수 있다. 따라서, 전용 함수 메모리 목록은 가상 메모리 범위의 식별을 포함할 수 있다. 따라서, 해당 가상 메모 리 범위 및 임의의 관련 물리 메모리 범위만이 회수될 필요가 있을 수 있다. 게다가, 파일 디스크립터가 유사하게 취급될 수 있다. 예를 들어, \"open()\" 커맨드에 대해, 플랫폼 운영 체제 는 전용 컨테이너 메모리 목록 및 전용 함수 메모리 목록에서 2개의 상이한 파일 디스크립터 그룹을 유지할 수 있다. 전용 컨테이너 메모리 목록 및 관련 기본 컨테이너 메모리 공간(1520a 내지 1520c)의 파일 디스크립터는 비정상 조건 또는 함수의 종료 시에 종료되거나 닫힐 필요가 없다(그러나 재 개시, 재생성 또는 다시 열기(reopen) 및 재초기화될 필요가 있을 수 있음). 전용 함수 메모리 목록 및 관련 함수 메모리 공간(1522a, 1522b)의 파일 디스크립터는 함수의 비정상 조건 또는 종료 시에 항상 닫 힐 수 있다. 예를 들어, 불법적인 명령어 또는 세그먼트화 위반에 의해 야기된 트랩으로 인해, 함수가 종료될 때, 컨 테이너는 컨테이너 자체가 강제 종료되지 않고 함수에 대한 정리를 실행할 수 있다. 위에서 언급된 바와 같이, 플랫폼 운영 체제, 소프트웨어 라이브러리 및 가상 머신 모니터 중 하나 이상은 함수 의 해체를 용이하게 할 수 있다.일부 실시예에서, 플랫폼 운영 체제 및/또는 컨테이너는 함수 이외에 컨테이너를 해체 할 수 있다. 즉, 기본 컨테이너 메모리 공간(1520a 내지 1520c)은 컨테이너가 에러를 야기하는 것으로 식별될 때 와이핑될 수 있다. 예를 들어, 컨테이너의 화이트 리스트에 있는 보디 내부로부터 실행 중인 코드의 결과로서 종료 조건(예를 들면, 불법 명령어 오류)이 발생하는 경우, 함수 이외에 프로세스 또는 컨테이너가 해체되어야 한다. 일부 실시예에서, 컨테이너가 미리 결정된 양의 시간 동안 함수에 의해 사용되지 않은 상태로 유지되는 경우 컨테이너는 해체될 수 있다. 일부 실시예에서, 함수가 완료 이전에(예를 들면, 오류로 인해) 종료될 때, 컨테이너에 특별 진입 점이 정의될 수 있다. 진입점은, 함수가 해체되고 함수 메모리 공간(1522a, 1522b)이 할당해제된 후에, 실행이 벡터화되는 곳이다. 재진입점은 컨테이너가 웜 스타트(warm start) 동안 함수의 론칭을 수행하는 지점일 수 있다. 예를 들어, 재진입점은 컨테이너가 완전히 초기화되고 함수의 프로세싱을 시작할 준비가 된 론칭 지점일 수 있다. 이 재진입점에 대한 벡터화는 해당 론칭 지점에 대한 \"longjmp 호출\"과 동등 할 수 있다. 적절한 할당 및 할당해제를 용이하게 하기 위해 커맨드 또는 라이브러리 인터페이스에 다양한 조정이 이루어질 수 있다. 예를 들어, \"backtrace\" 커맨드는 일반적으로 다양한 할당의 출처를 결정하는 데 필요하지만; 이는 다양한 할당 및 \"열기 호출\"에 대한 2개의 상이한 진입점을 갖는 것에 의해 방지될 수 있다. 예를 들어, 하나 의 진입점은 화이트 리스트에 있는 코드에만 링크되고, 다른 진입점은 함수의 코드에 대한 기본값이다. \"mmap()\"(가상 범위를 제공해야 함), \"open()\"(파일 디스크립터, socket() 등을 할당함)과 같은 다른 유형의 프 로비저닝 호출에 대해서도 유사한 커맨드 분기(bifurcation)가 수행될 수 있다. 각각의 경우에, 화이트 리스트 에 있는 코드는 정상적인 방식으로 할당되는 코드와 링크되는 반면, 화이트 리스트에 있지 않은 코드는 전용 함 수 메모리 목록을 통해 함수 메모리 공간(1522a, 1522b)으로 리소스를 격리시키거나 또는 오류 시에 자동 으로 해제/자동으로 닫힐 필요가 있는 함수와 연관된 데이터로서 열린 파일 디스크립터, 소켓 등을 추적 하는 경로를 통과하는 것으로 가정될 수 있다. 따라서, 향상된 컴퓨팅 아키텍처는 컨테이너의 제한된 해체 및 콜드 컨테이너의 제한된 초기화를 포함하 여 여러 향상을 포함할 수 있으며, 이에 의해 비용을 감소시킬 수 있다. 더욱이, 향상된 컴퓨팅 아키텍처 는 더 적은 대역폭 및 전력이 컨테이너를 해체 및 재생성하기 위해 이용되기 때문에 리소스의 이용 효율 성을 향상시킬 수 있다. 게다가, 향상된 컴퓨팅 아키텍처는 세미-웜 상태로부터의 컨테이너의 더 빠른 기동 및 함수 종료 및 오류로부터의 더 적은 오버헤드로 인해 더 적은 레이턴시를 갖는다. 함수 메모리 공간 (1522a, 1522b)으로부터 함수 특정 데이터를 제거함으로써 보안이 또한 향상될 수 있다. 도 15b는 함수 및 컨테이너에 대한 메모리 할당 방법을 도시하며, 도 13a의 서버에 의해 실행될 수 있지만, 또는 서버와 협력하여, 도 4의 향상된 FaaS 시스템 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세 트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로도 구현될 수 있다. 예를 들어, 방법에 도시된 동작을 수행하기 위한 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 등과 같 은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프 로그래밍 언어를 포함하여, 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 추가적으로, 로 직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴 포넌트를 포함할 수 있다. 예시된 프로세싱 블록은 하나 이상의 컨테이너 메모리 공간을 컨테이너에 전용할 수 있다. 예시된 프로 세싱 블록은 하나 이상의 함수 메모리 공간을 컨테이너와 연관된 함수에 전용할 수 있다. 예시된 프로세 싱 블록은 메모리 할당 요청을 수신할 수 있다. 예시된 프로세싱 블록은 메모리 할당 요청이 컨테 이너 또는 함수로부터 유래하는지를 결정할 수 있다. 예시된 프로세싱 블록은 메모리 할당 요청이 컨테 이너 또는 함수로부터 유래하는지에 기초하여 하나 이상의 컨테이너 메모리 공간 또는 하나 이상의 함수 메모리 공간으로부터 메모리 할당을 제공할 수 있다. 예를 들어, 메모리 할당 요청이 컨테이너로부터 유래할 때, 메모 리 할당은 하나 이상의 컨테이너 메모리 공간으로부터 제공될 수 있다. 이와 달리, 메모리 할당 요청이 함수로 부터 유래할 때, 메모리 할당은 하나 이상의 함수 메모리 공간으로부터 제공될 수 있다.게다가, 컨테이너가 처리할 데이터만이 하나 이상의 컨테이너 메모리 공간에 저장될 수 있다. 더욱이, 함수 특 정 데이터는 하나 이상의 함수 메모리 공간에만 저장된다. 예시된 프로세싱 블록은, 함수가 종료되었다는 식별에 응답하여, 하나 이상의 컨테이너 메모리 공간으로 부터의 메모리의 할당해제 없이 하나 이상의 함수 메모리 공간으로부터 메모리를 할당해제할 수 있다. 예시되 어 있지는 않지만, 방법은 실행을 위해 다른 함수를 컨테이너에 로딩하는 단계를 추가로 포함할 수 있다. 따라 서, 방법은 컨테이너의 제한된 해체 및 콜드 컨테이너의 제한된 초기화를 포함하여 여러 향상을 포함할 수 있으며, 이에 의해 비용을 감소시킬 수 있다. 더욱이, 방법은 더 적은 대역폭 및 전력이 컨테이너를 해체 및 재생성하기 위해 이용되기 때문에 리소스의 이용 효율성을 향상시킬 수 있다. 더욱이, 방법은 세미-웜 상태로부터의 컨테이너의 더 빠른 기동 및 함수 종료 및 오류로부터의 더 적은 오버헤드로 인해 더 적 은 레이턴시를 가질 수 있다. 추가 비고 및 예 예 1500은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 하나 이상의 컨테이너 메모리 공간을 컨테이너에 할당하게 하고, 하나 이상의 함수 메모리 공간을 컨테이너와 연관된 함수에 전용하게 하며, 메모리 할당 요청을 수신하게 하고, 메모리 할당 요청이 컨테이너 또는 함수로부터 유래하는지를 결정하게 하며, 메모 리 할당 요청이 컨테이너로부터 유래할 때 하나 이상의 컨테이너 메모리 공간으로부터 메모리 할당을 제공하게 하고, 메모리 할당 요청이 함수로부터 유래할 때 하나 이상의 함수 메모리 공간으로부터 메모리 할당을 제공하 게 하며, 함수가 종료되었다는 식별에 응답하여, 하나 이상의 컨테이너 메모리 공간으로부터의 메모리의 할당해 제 없이 하나 이상의 함수 메모리 공간으로부터 메모리를 할당해제하게 하는 명령어 세트를 포함하는 적어도 하 나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 컨테이너가 처리할 데이터만이 하나 이상의 컨테이너 메모리 공간에 저장되고, 함수 특정 데이터는 하나 이상의 함수 메모리 공간에만 저장되며, 여기서 하나 이상의 컨테이 너 메모리 공간은 파일 디스크립터 또는 소켓 디스크립터 중 하나 이상을 저장한다. 예 1501은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 하나 이상의 컨테이너 메모리 공간을 컨테이너에 할당하게 하고, 하나 이상의 함수 메모리 공간을 컨테이너와 연관된 함수에 전용하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 1502는 예 1501의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 메모리 할당 요청을 수신하게 하고, 메모리 할당 요청이 컨테이너 또는 함수로부터 유 래하는지를 결정하게 하며, 메모리 할당 요청이 컨테이너 또는 함수로부터 유래하는지에 기초하여 하나 이상의 컨테이너 메모리 공간 또는 하나 이상의 함수 메모리 공간으로부터 메모리 할당을 제공하게 하는 추가 명령어 세트를 포함한다. 예 1503은 예 1502의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 메모리 할당 요청이 컨테이너로부터 유래할 때 하나 이상의 컨테이너 메모리 공간으로 부터 메모리 할당을 제공하게 하는 추가 명령어 세트를 포함한다. 예 1504는 예 1502의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 메모리 할당 요청이 함수로부터 유래할 때 하나 이상의 함수 메모리 공간으로부터 메모 리 할당을 제공하게 하는 추가 명령어 세트를 포함한다. 예 1505는 예 1501의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 컨테이너가 처리할 데이터만이 하나 이상의 컨테이너 메모리 공간에 저장되고, 함수 특정 데이터는 하나 이상의 함수 메모리 공간에만 저장된 다. 예 1506은 예 1501의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 함수가 종료되었다는 식별에 응답하여, 하나 이상의 컨테이너 메모리 공간으로부터의 메모리의 할당해제 없이 하나 이상의 함수 메모리 공간으로부터 메모리를 할당해제하게 하는 추가 명령어 세트 를 포함한다. 예 1507은 예 1506의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 하나 이상의 컨테이너 메모리 공간은 파일 디스크립터 또는 소켓 디스크립터 중 하나 이상을 저장한다. 웜 컨테이너 및 콜드 컨테이너에의 함수의 분배 함수는 웜 컨테이너와 콜드 컨테이너 사이에 랜덤한 분포를 가질 수 있다. 본 명세서에서 이미 설명된 바와 같 이, 콜드 컨테이너를 초기화하기 위한 레이턴시 시간은 사소하지 않을 수 있다. 그와 같이, 콜드 컨테이너는, 예를 들어, 프로비저닝되는 것에 의해 초기화되어야 하고, 이어서 함수가 실행되어야 하기 때문에, 콜드 컨테이 너에 분배된 함수는 더 높은 레이턴시를 가질 수 있다. 이와 달리, 콜드 컨테이너 초기화가 방지될 수 있기 때 문에, 웜 컨테이너에 분배된 함수는 더 낮은 레이턴시를 가질 수 있다. 콜드 컨테이너 초기화 레이턴시는 많은 초기화 단계 및 인자로 인해 야기될 수 있다. 하나의 인자 세트는 컨테 이너에 할당된 다양한 리소스(예를 들면, CPU 및 메모리)의 양을 제한하기 위해 리소스 ID(예를 들면, 프로세스 ID 및 파일 디스크립터) 및 제어 그룹에 대한 네임스페이스과 같은 OS 레벨 리소스를 할당 및 구성하는 것일 수 있다. Java와 같은 관리 언어에 대한 언어 런타임과 같은, 다른 인자 세트는 컨테이너의 내용을 초기화하는 것 일 수 있다. 함수를 시작하는 것 자체가 또한 추가 오버헤드를 부과한다. 웜 컨테이너는 웜 컨테이너 내에서 호스팅되는 함수를 호출하는 것의 레이턴시를 감소시키기 위해 이러한 단계들 중 몇개를 사전에 수행할 수 있다. 종래의 스케줄링은 함수를 분배할 때 콜드 컨테이너 초기화에 필요한 시간 또는 콜드 컨테이너 초기화를 최소화 하는 방법을 고려하지 않을 수 있다. 더욱이, 일부 스케줄링은 웜 컨테이너와 콜드 컨테이너 간의 비효율적인 함수 분배를 가질 수 있어, 더 높은 리소스 사용량 및 더 높은 레이턴시의 실행으로 이어질 수 있다. 이제 도 16a를 살펴보면, 함수 요청이 FaaS 시스템, 예를 들어, 도 4의 FaaS 시스템의 호출자 및 배 치 밸런서(batch balancer)에 의해 스케줄링되는 예가 도시되어 있다. 호출자 및 배치 밸런서 는 레이턴시를 감소시키고 리소스 이용률을 향상시키기 위해 배칭 기반 구현을 구현할 수 있다. 예를 들 어, 일부 실시예는 배칭 가능 함수의 실행을 각각 요청하는 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)을 식별할 수 있다. 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)은 함께 배칭될 수 있고, 배칭 가능 함수가 상이한 컨테이너가 아닌 동일한 컨테이너(1614a)에서 실행되도록 예측하여 스케줄링될 수 있다. 따라서 레이턴시를 감소시키고 더 적은 컨테이너를 이용하기 위해 배칭 가능 함수의 배칭 기반 실행에 의해 콜 드 컨테이너 초기화가 감소될 수 있다. 게다가, 호출자 및 배치 밸런서는 함수 요청과 연관된 특정 함수의 레이턴시 제약을 식별하고 레이 턴시 제약을 충족시키도록 함수 요청을 분배할 수 있다. 레이턴시 제약은 함수가 실행을 완료해야 하는 요청된 시간에 대응할 수 있다. 예를 들어, 더 짧은 레이턴시의 함수는 그룹 내의 모든 함수에 대한 레이턴시 제약 모두가 충족되도록 레이턴시 제약이 허용되고 정렬될 때 함께 그룹화될 수 있다. 상기 분석은 함수의 프 로그램 코드가 길이가 크게 변하는 특정 상황을 특히 향상시킬 수 있다. 하나의 그러한 상황은 느슨한 레이턴 시 제약(예를 들면, 긴 레이턴시 제약)을 갖는 긴 함수 및 엄격한 레이턴시 제약(예를 들면, 짧은 레이턴시 제 약)을 갖는 짧은 함수가 함께 스케줄링될 때일 수 있다. 짧은 함수를 먼저 스케줄링하는 것은 긴 함수와 짧은 함수의 레이턴시 제약 둘 모두가 충족될 수 있게 한다. 이와 달리, 긴 함수를 먼저 스케줄링하는 것은 짧은 함 수에 대한 레이턴시 요구사항이 충족되지 않게 한다. 일부 실시예에서, \"최단 마감 우선(earliest-deadline first)\" 스케줄링 정책은 실현 가능 스케줄을 생성하는 데 사용된다. 따라서, 가장 짧은 레이턴시 제약을 갖는 함수는 더 긴 레이턴시 제약을 갖는 함수보다 먼저 스 케줄링된다. 일부 실시예에서, \"최단 작업 우선(shortest job first)\" 및 구현(예를 들면, 라운드 로빈)과 같 은 대안적인 스케줄링 스킴이 사용될 수 있다. 예를 들어, 가장 짧은 함수는 더 긴 함수보다 먼저 실행되고, 라운드 로빈 방식으로 실행될 수 있다. 일부 실시예에서, \"최단 마감 우선\"과 \"최단 작업 우선\"의 하이브리드 모델이 채택될 수 있다. 예를 들어, \"최 단 작업 우선\" 정책은 가장 짧은 함수를 더 긴 함수보다 먼저 실행되도록 정렬할 수 있다. 시스템은 이어서 모 든 함수를 분석(예를 들면, 함수를 완료하는 데 필요한 타이밍을 예측하고 타이밍을 연관된 레이턴시 제약과 비 교)하여 모든 레이턴시 제약이 충족되는지를 예측할 수 있다. 만약 그렇다면, 시스템은 결정된 배열에 따라 함 수를 스케줄링할 수 있다. 함수들 중 일부의 레이턴시 제약이 충족되지 않을 경우, 시스템은 레이턴시 제약이 충족되지 않을 해당 함수가 레이턴시 제약이 충족되는 다른 함수보다 먼저 실행되도록 \"최단 마감 우선\" 정책에 기초하여 배열을 수정할 수 있다. 일 예로서, 이를테면 F1, F2, F3 및 F4가 해당 순서로 실행되도록 \"최단 작업 우선\" 정책에 따라 스케줄 링된다. F2 및 F3이 레이턴시 제약을 충족시키지 않는 것으로 식별되는 경우, 시스템은 F2, F3을 F1, F4보다 먼 저 실행되도록 이동시킬 수 있다. F2 또는 F3이 먼저 실행되는지를 결정하기 위해, 시스템은 \"최단 마감 우선\" 정책을 실행하고, F3 이 F2와 F3 중에 최단 마감을 갖고 F2보다 먼저 스케줄링되어야 한다고 결정할 수 있다. 따라서, 최종 순서는: F3, F2 , F1 및 F4과 비슷할 것이다. 일부 실시예에서, 다양한 원격 측정 소스(예를 들면, 이전 함수 실행의 시간을 측정한 타이머)로부터 수집된 것 과 같은 이력 정보는 각각의 함수에 대한 실행 시간을 추정하는 데 사용될 수 있으며, 이는 함수의 향후 호출의 스케줄링을 알리는 데 도움이 될 수 있다. 추가 세부사항에 대해서는, 도 24a 및 도 41a에 대한 논의를 참조한 다. 일부 실시예는 또한 배칭 가능 함수를 프로세싱하기 위해 콜드 컨테이너 초기화가 필요할 것인지를 결정할 수 있으며, 만약 그렇다면, 레이턴시 제약이 충족될 것인지를 식별할 때 콜드 컨테이너 초기화를 위한 레이턴시 시간을 고려할 수 있다. 따라서, 일부 실시예는 리소스 사용량을 감소시키기 위해 더 효과적인 함수 분배를 가지면서 콜드 컨테이너 초 기화를 제한할 수 있다. 예를 들어, 함수를 실행하기 위해 여러 새로운 콜드 컨테이너를 초기화하는 것보다, 동일한 컨테이너 내에서 여러 함수가 실행되게 하는 것이 더 리소스 효율적일 수 있다. 첫 번째 함수 외에, 배 칭된 함수가 직렬 실행 모델에서 선행하는 배칭된 함수가 완료되기를 기다려야 하고, 이는 전용 컨테이너 내의 함수가 임의의 다른 함수가 완료되기를 기다릴 필요가 없는 무한 병렬 처리 모델을 가정하는 것에 비해 레이턴 시를 증가시킬 수 있다. 이것에도 불구하고, 일단 병렬 처리에서의 제한이 고려되고 초기화 시간의 감소가 고 려되면, 배칭된 함수의 전체 레이턴시와 심지어 첫 번째 함수가 아닌 함수에 대한 레이턴시도 실제로 더 낮을 수 있다. 따라서, 일부 실시예는, 함수들이 함께 배칭되더라도, 향상된 웜 컨테이너 사용량으로 인해 더 낮은 레이턴시를 가질 수 있다. 단일 컨테이너에서의 다수의 배칭된 함수의 병렬 실행은 레이턴시를 추가로 감소시 킬 수 있다. 게다가, 위에서 언급된 바와 같이, 리소스 관리가 향상될 수 있다. 예를 들어, 웜 컨테이너는 특정 양의 유휴 시간 후에 해체될 수 있다. 유휴 시간은 웜 컨테이너가 어떠한 함수도 프로세싱하지 않는 시간일 수 있다. 본 명세서에 설명된 바와 같은 배칭 기반 구현을 통해 웜 컨테이너가 더 종종 이용되게 함으로써, 실시예는 웜 컨 테이너가 더 자주 사용되기 때문에 덜 빈번한 콜드 컨테이너 초기화 및 덜 빈번한 웜 컨테이너 해체를 나타낼 수 있다. 게다가, 일부 실시예는 리소스를 소비하는 동일한 컨테이너의 인스턴스가 더 적을 수 있다. 예를 들 어, 각각의 함수에 대해 컨테이너를 갖는 것보다는, 하나의 컨테이너가 여러 함수를 서비스할 수 있다. 따라서, 실시예는 효율성을 향상시키고 더 적은 리소스를 이용하여 비용을 감소시킨다. 따라서, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)이 갑작스럽고 드문 버스트로 발생하더라도, 콜드 컨테이너 페널티가 방 지될 수 있고 향상된 FaaS 시스템이 컨테이너의 빌드 및 해체에 대한 더 많은 제어를 할 수 있게 한다. 게다가, 로드 밸런싱 비용이 감소될 수 있다. 예를 들어, 오케스트레이터에 의해 각각의 함수를 개별적으로 스 케줄링하는 것은, 함수들의 배치(batch)를 함께 스케줄링하는 것과는 달리, 더 많은 계산 리소스를 필요로 할 수 있다. 더욱이, 메시징 오버헤드가 감소될 수 있지만, 각각의 함수 요청에 대해 개별 메시지가 송신되지 않 을 수 있기 때문에, 오히려 제1 내지 제N 배칭된 함수 요청(1608a 내지 1608n) 전부를 포함하는 배칭된 함수 요 청 메시지가 전송될 수 있다. 예에 예시된 바와 같이, 함수 요청은 FaaS 시스템, 예를 들어, 도 4의 FaaS 시스템의 호출자 및 배치 밸런서에 의해 스케줄링된다. 호출자 및 배치 밸런서는 오케스트레이터의 일부일 수 있거나, 또는 오케스트레이터와 협력하여 동작할 수 있다. 도 16a에 예시된 바와 같이, 이벤트 핸들링 API 프록시는 이벤트 호출을 함수 요청과 연관된 함수 로 라우팅할 수 있다. 1600의 예에서, API 프록시는, 예를 들어, API를 통해 함수 요청을 생성할 수 있다. 함수 요청은 호출자 및 배치 밸런서에 제공될 수 있다. 함수 요청 각각은 각자의 함수를 실행하라는 요청일 수 있다. 호출자 및 배치 밸런서는 함수 요청이 배칭될 수 있는지를 식별하기 위해 함수 요청을 분석 할 수 있다. 상세하게는, 호출자 및 배치 밸런서는 함수 요청의 함수가 컨테이너(1614a 내지 1614c)의 동일한 컨테이너에서 실행될 수 있는지를 결정할 수 있다. 강력한 레이턴시 제약이 없는 한 요청이 축적될 수 있으며, 이어서 요청이, 얼마만큼의 워크로드가 배치에 포함되는지에 따라, 이용 가능한 웜 컨테이너 로 또는 새로운 콜드 컨테이너로 배치로서 송신될 수 있다. 따라서, 그러한 임의적인 배칭 하에서, 액션이 트 리거될 때 액션의 로드 밸런싱, 호출, 및 실행 모두가 분리(예를 들면, 2-스테이지) 방식으로 수행된다. 컨테 이너(1614a 내지 1614c)의 동일한 컨테이너에서 실행될 수 있는 함수는 함께 배칭될 수 있다. 일부 실시예에서, 호출자 및 배치 밸런서는 동일한 함수가 함께 배칭 가능하다고 결정할 수 있다. 게다가, 호 출자 및 배치 밸런서는 동일하지 않은 함수가 컨테이너(1614a 내지 1614c) 중 동일한 컨테이너에서 실행될 수 있는 경우 해당 동일하지 않은 함수가 함께 배칭 가능하다고 결정할 수 있다. 호출자 및 배치 밸런서는 함수 요청으로부터 비-배칭 가능 함수 요청(1610, 1612)을 식별할 수 있 다. 비-배칭 가능 함수 요청(1610, 1612)은 다른 함수와 그룹화될 수 없는 비-배칭 가능 함수를 요청할 수 있 으며, 따라서 비-배칭 가능인 것으로 간주된다. 비-배칭 가능 함수 요청(1610, 1612)은 개별적으로 컨테이너 (1614b, 1614c)로 송신될 수 있다. 즉, 비-배칭 가능 함수는 개별 컨테이너(1614b, 1614c)에서 실행될 수 있다. 컨테이너(1614b, 1614c)는 웜 또는 콜드일 수 있으며, 가장 강력한 레이턴시 제약을 갖는 비-배칭 가능 함수 요청(1614b, 1614c) 중의 비-배칭 가능 함수 요청에 우선순위가 부여된다. 예시된 바와 같이, 호출자 및 배치 밸런서는 함수 요청으로부터 제1 내지 제N 배칭 가능 함수 요청 (1608a 내지 1608n)을 식별할 수 있다. 설명된 바와 같이, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n) 각각은 동일한 컨테이너 내에서 실행되도록 구성된 함수(\"배칭 가능 함수\"라고 지칭될 수 있음)를 호출 할 수 있다. 따라서, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)은 컨테이너(1614a)로 전송될 수 있 다. 배칭 가능 함수는 컨테이너(1614a) 내에서 실행될 수 있다. 제1 내지 제N 배칭 가능 함수 요청(1608a 내 지 1608n)은 1보다 큰 임의의 개수의 함수 요청을 포함할 수 있다. 일부 실시예에서, 컨테이너(1614a)가 그러한 동시 실행을 지원하기에 충분한 리소스를 가지고 있다면, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)과 연관된 배칭 가능 함수가 컨테이너(1614a)에서 동시에 실행될 수 있다. 예를 들어, 호출자 및 배치 밸런서는 배칭 가능 함수 각각의 리소스 요구사항을 결정할 수 있고, 컨테이너(1614a)가 모든 리소스 요구사항을 동시에 충족시키기에 충분한 리소스(예를 들면, CPU 및 메모리)에 액세스할 수 있는지를 결정할 수 있다. 만약 그렇다면, 동시 실행이 스케줄링될 수 있다. 만약 그렇지 않다면, 동시 실행이 지원되지 않을 수 있으며 배칭 가능 함수가 순차적으로(연달아) 실행될 수 있다. 일부 실시예에서, 호출자 및 배치 밸런서는 배칭 가능 함수의 보안 프로토콜을 결정할 수 있다. 보안 프 로토콜이 특정 배칭 가능 함수가 특정 보안 요구사항(예를 들면, 높은 보안)을 가짐을 나타내는 경우, 특정 배 칭 가능 함수는 컨테이너(1614a)에서의 비-동시 실행을 위해 스케줄링되고, 도 15a 및 도 15b 및 상기 관련 설 명과 관련하여 설명된 바와 같이, 컨테이너(1614a)의 데이터가 유지되는 동안 특정 배칭 가능 함수의 데이터만 이 제거되는, 컨테이너(1614a)의 제한된 해체를 실행할 수 있다. 일부 실시예에서, 배칭 가능 함수 중 일부는 동시에 실행될 수 있고, 배칭 가능 함수 중 다른 것은 순차적으로 실행될 수 있다. 일부 실시예에서, 컨테이너(1614a)는 배칭 가능 함수의 제1 그룹, 예를 들어, 컨테이너 (1614a)의 리소스에 의해 지원될 수 있는 최대 개수의 배칭 가능 함수를 실행할 수 있다. 제1 그룹이 실행을 완료한 후에, 배칭 가능 함수의 제2 그룹은, 예를 들어, 컨테이너(1614a)의 리소스에 의해 지원될 수 있는 최대 개수의 배칭 가능 함수를 실행하기 시작할 수 있다. 따라서, 호출자 및 배치 밸런서는 보안 프로토콜 및 함수의 리소스 요구사항에 대한 컨테이너(1614a)의 리소스 이용 가능성에 기초하여 컨테이너(1614a)에서 배칭 가능 함수의 하이브리드 직렬 및 병렬 실행을 스케줄링할 수 있다. 일부 실시예에서, 컨테이너(1614a)는 병렬로 실행되는 배칭 가능 함수를 분리하기 위해 파티셔닝된 작업 공간을 포함할 수 있다. 각각의 함수는 상이한 파티션에서 실행될 수 있다. 모든 파티션은 배칭 가능 함수 중 임의의 것에 의해 활용될 수 있는 공통 데이터에 액세스할 수 있다. 파티션은 함수에 특정한 데이터를 보존하기 위해 분리된 메모리 공간을 가질 수 있다. 따라서, 각각의 파티션은 함수에 의해 사용되는 공통 데이터에 액세스하 면서, 함수에 의해 생성된 데이터를 분리된 메모리 공간에 저장한다. 함수가 파티션에서의 실행을 완료한 후에, 대응하는 분리된 메모리 공간으로부터의 데이터가 (필요한 경우) 다른 데이터 스토리지에 저장되고, 분리 된 메모리 공간이 다른 함수를 위한 파티션을 준비하기 위해 와이핑된다. 그렇지만 공통 데이터는 실행 동안 함수에 의해 변경될 수 없으며, 컨테이너(1614a)에서 실행되는 각각의 함수에 의해 재사용 가능하다. 일부 실시예에서, 호출자 및 배치 밸런서는 함수 요청을 축적할 수 있다. 예를 들어, 함수 요청 각각이 상이한 시간에 호출자 및 배치 밸런서로 송신될 수 있다. 호출자 및 배치 밸런서는 함수 요청이 일정 시간 기간 동안 축적되도록 할 수 있다. 즉, 호출자 및 배치 밸런서는 함수 요 청이 수신될 때 함수 요청을 즉각 스케줄링하지 않을 수 있다. 오히려, 호출자 및 배치 밸런서 는 함수 요청을 스케줄링하기 전에 대기할 수 있다. 그렇게 하는 것은 호출자 및 배치 밸런서 가 다수의 잠재적으로 배칭 가능 함수 요청을 수신하고 이어서 함수 요청이 함께 배칭 가능 한지에 기초하여 이들을 스케줄링하도록 할 수 있다. 일부 실시예에서, 호출자 및 배치 밸런서는 함수 요청 각각의 레이턴시 제약을 결정하고 그에 따라 연관된 함수를 스케줄링할 수 있다. 예를 들어, 비-배칭 가능 함수 요청은 강력한 레이턴시 제약을 가질 수 있다. 즉, 비-배칭 가능 함수 요청은 연관된 레이턴시 제약으로 인해 대응하는 함수를 즉각 실행하도 록 스케줄링될 필요가 있을 수 있다. 레이턴시 제약은 수치 값 및/또는 절대 시간일 수 있다. 레이턴시 제약 은 비-배칭 가능 함수 요청의 연관된 함수가 짧은 시간 프레임 내에 완료될 필요가 있을 수 있음을 나타 낼 수 있다. 따라서, 비-배칭 가능 함수 요청은 웜 컨테이너일 수 있는 컨테이너(1614b) 내에서 실행되 도록 스케줄링될 수 있다. 일부 실시예에서, 함수 요청 중의 함수 요청의 레이턴시 제약이 비-배칭 가능 임계치를 충족시키면, 함수 요청은 적시적 실행을 보장하기 위해 비-배칭 가능으로 자동으로 분류될 수 있다. 예를 들어, 레이턴시 제약이 함수가 미리 결정된 양의 시간 내에 완료되어야 함을 나타내는 경우, 대응하는 함수 요청과 함께 배칭할 다른 배칭 가능 함수를 식별하는 일 없이 대응하는 함수 요청이 즉각 스케줄링될 수 있다. 일부 실시예에서, 호출자 및 배치 밸런서는 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n) 각각의 레이턴시 제약을 추가로 결정할 수 있다. 호출자 및 배치 밸런서는 지금까지 수신된 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)의 가장 강력한 레이턴시 제약에 기초하여 제1 내지 제N 배칭 가능 함수 요청 (1608a 내지 1608n)을 스케줄링하기 위해 대기할 수 있다. 예를 들어, 호출자 및 배치 밸런서는, 레이턴시 제약으로부터, 실행을 완료할 제1 내지 제N 배칭 가능 함 수 요청(1608a 내지 1608n)의 각각의 각자의 함수의 시간 프레임을 결정할 수 있다. 시간 프레임은 각자의 배 칭 가능 함수가 실행을 완료해야 하는 선호된 시간 윈도에 대응할 수 있다. 시간 프레임들 중의 가장 짧은 시 간 프레임이 결정될 수 있다. 호출자 및 배치 밸런서는 가장 짧은 시간 프레임을 충족시키기 위해 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)을 컨테이너(1614a)에 송신할 수 있다. 예를 들어, 호출자 및 배치 밸런서는 가장 짧은 시간 프레임을 갖는 함수가 가장 짧은 시간 프레임 내에 완료되도록 보장하기 위해 제1 시간에 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)을 컨테이너(1614a)로 송신할 수 있다. 그렇지만 호출자 및 배치 밸런서는 제1 시간에 도달할 때까지 함수 요청을 계속 수신하고 축적할 수 있다. 그와 같이, 호출자 및 배치 밸런서는 레이턴시 제약을 준수하기 위해 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)을 컨테이너(1614a)에 송신하기 전에 일정 시간 기간 동안 대기할 수 있다. 일부 실시예에서, 호출자 및 배치 밸런서는 레이턴시 제약을 준수하도록 특정 함수의 실행을 시작하는 타 이밍을 결정할 수 있다. 호출자 및 배치 밸런서는 특정 함수의 실행을 완료하는 데 필요한 총 예상 레이 턴시를 결정할 수 있다. 총 예상 레이턴시는 콜드 컨테이너를 초기화하는 데 필요한 시간, 호출자 및 배치 밸 런서가 함수 요청을 축적하는 데 이미 소비한 시간, 특정 함수 이전에 컨테이너에서 실행되도록 스 케줄링된 함수의 레이턴시, 통신 레이턴시 및/또는 컨테이너에서 실행을 완료하기 위한 특정 함수의 레이턴시를 포함할 수 있다. 이하의 방정식 1600은 총 예상 레이턴시와 허용 가능한 레이턴시의 비교에 기초하여 특정 함 수의 레이턴시 제약이 충족되는지를 결정하는 데 사용될 수 있다. Lwait + LCCL + LF + LC ≤ Laccept 방정식 1600 상기 방정식 1600에서, Lwait는 호출자 및 배치 밸런서가 특정 함수의 특정 함수 요청을 축적한 시간 기간 이다. 예를 들어, Lwait는 현재 시간과 특정 함수 요청이 수신된 시간 사이의 차이일 수 있다. LCCL은 콜드 컨테 이너를 초기화하는 데 필요한 시간이다. 웜 컨테이너가 사용 가능한 것으로 식별되는 경우, LCCL은 0으로 설정 될 수 있다. LF는 특정 함수 이전에 실행되도록 스케줄링된 각각의 함수의 예상 실행 레이턴시와 특정 함수가 실행을 완료하기 위해 예상되는 레이턴시의 합계이다. 따라서, LF는 총 함수 실행 레이턴시 추정일 수 있다. LC는 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)을 컨테이너(1614a)에 송신하기 위한 통신 레이턴시 이다. Laccept는 레이턴시 제약으로부터 결정될 수 있고, 특정 함수의 총 허용 가능 레이턴시일 수 있다. 예를 들어, Laccept는 서비스 제공자 또는 클라이언트에 의해 설정된 임계치일 수 있으며, 함수가 실행을 완료할 것으 로 예상되는 총 시간일 수 있다. 함수가 Laccept 이하의 레이턴시로 실행을 완료하는 경우, 함수는 적시에 완료 된 것으로 간주될 수 있다. 상기한 바가 참인 경우 또는 Laccept가 Lwait, LCCL, LC 및 LF의 합계보다 크거나 같은 경우 레이턴시 제약은 충족되는 것으로 간주될 수 있다. 일부 실시예에서, 호출자 및 배치 밸런서는 Laccept가 합계보다 미리 결정된 양만큼 더 큰 경우에만 레이턴시 제약이 충족된 것으로 간주할 수 있다.상기 방정식 1600에 기초하여, 호출자 및 배치 밸런서는 특정 함수의 실행을 시작하기 위한 시작 타이밍 을 결정할 수 있다. 호출자 및 배치 밸런서는 시작 타이밍을 충족시키기 위해 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)을 전송하기 위한 전송 시간을 추가로 결정할 수 있다. 예를 들어, 호출자 및 배 치 밸런서는, LCCL 및 LC와 같은, 정적 값을 결정하고, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)이 컨테이너(1614a)에 송신되는 타이밍(전송 시간) 및 컨테이너(1614a)에서의 배칭 가능 함수 실행의 순 서를 제어함으로써, Lwait 및 LF와 같은, 동적 레이턴시를 조정할 수 있다. 일부 실시예에서, 호출자 및 배치 밸런서는 특정 개수의 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)이 축적되는 것에 응답하여 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)을 컨테이너(1614a)에 송신할 수 있다. 예를 들어, 컨테이너(1614a)는 지원되는 개수의 함수의 동시 실행을 지원할 수 있다. 그와 같이, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)의 함수의 개수가 지원되는 개수에 도달할 때, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)이 실행을 시작하기 위해 컨테이너(1614a)에 송신될 수 있다. 일부 실시예에서, 함수는 컨테이너(1614a) 내의 독립적인 소프트웨어 스레드에서 동시에 동작할 수 있고, 따라 서 함수들이 병렬로 실행될 수 있다. 일부 실시예에서, 함수는 이용 가능한 스레드에서 시간 공유 모드로 실행 될 수 있다. 따라서, 상기 예에서, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)은 호출자 및 배치 밸런서에 의해 상이한 시간에 수신되고 축적될 수 있다. 호출자 및 배치 밸런서는 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)을 배치로서, 웜 또는 콜드일 수 있는, 컨테이너(1614a)에 송신할 수 있다. 호출자 및 배치 밸런서는 얼마만큼의 작업이 배치에 있을 수 있는지에 따라 그리고 연관된 레이턴시 제약을 충족시 키도록 배치를 스케줄링할 수 있다. 따라서, 그러한 배칭 스킴 하에서, 함수가 트리거될 때 함수의 로드 밸런 싱, 호출 및 실행이 분리(2-스테이지) 방식으로 수행될 수 있다. 일부 실시예에서, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)은 레이턴시 제약에 따라 호출자 및 배 치 밸런서에 의해 2개 이상의 그룹으로 분할될 수 있다. 예를 들어, 제1 내지 제N 배칭 가능 함수 요청 (1608a 내지 1608n)은 제1 그룹이 가장 강력한 레이턴시 제약을 갖고, 제2 그룹이 다음으로 가장 강력한 레이턴 시 제약을 가지며 이하 마찬가지이도록 분할될 수 있다. 레이턴시를 감소시키기 위해 2개 이상의 컨테이너에 의한 2개 이상의 그룹의 동시 실행이 이루어질 수 있다. 일부 실시예에서, 2개 이상의 그룹을 위한 충분한 웜 컨테이너가 없는 경우, 레이턴시 제약에 따라 웜 컨테이너 가 할당될 수 있다. 예를 들어, 가장 강력한 레이턴시 제약(실행을 위한 최단 시간 윈도)을 가진 그룹은 웜 컨 테이너에 송신될 수 있는 반면, 더 약한 레이턴시 제약(실행을 위한 더 긴 시간 윈도)을 가진 그룹은 콜드 컨테 이너에 송신될 수 있다. 예를 들어, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)으로부터 레이턴시 제약에 대한 식별이 이루어질 수 있다. 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)은, 실행을 완료 할 최단 시간 윈도를 갖는 함수가 웜 컨테이너에서 실행되도록, 레이턴시 제약에 따라 그룹화될 수 있다. 이와 달리, 실행을 완료할 더 긴 시간 윈도를 갖는 함수는 콜드 컨테이너에서 실행을 완료하도록 함께 그룹화될 수 있다. 일부 실시예에서, 그룹은 동일한 컨테이너(1614a)에서 연달아 실행되도록 스케줄링될 수 있다. 가장 강력한 레 이턴시 제약을 갖는 그룹은 더 약한 레이턴시 제약을 갖는 그룹보다 먼저 실행되도록 스케줄링될 수 있다. 게다가, 일부 실시예에서, 호출자 및 배치 밸런서는 함수의 배치를 스케줄링하기 위해 FaaS 인프라스트럭 처의 프런트 엔드로부터 백엔드로의 조대하게 나뉜(coarse-grained) 디스패치로서 동작할 수 있다. 예를 들어, 백엔드에서, 제1 내지 제N 배칭 가능 함수 요청(1608a 내지 1608n)은 연관된 함수가 정상적인 방식으로 실행되 는 컨테이너(1614a)에 제공될 수 있다. 이와 달리, FaaS의 상업적인 대량 사용은 개별 함수 요청 스케줄링 스 킴에 기초하여 로드 밸런싱, 컨테이너 할당, 및 전송 동작(모두 순수 오버헤드일 수 있음)을 수행하기 위해 더 많은 리소스를 필요로 할 수 있다. 더욱이, 본 명세서에서 설명된 배칭 기반 스케줄링 스킴은 웜 컨테이너에 대한 콜드 컨테이너의 비율을 자동으 로 감소시킬 수 있다. 상세하게는, 콜드 컨테이너는 배치 내의 제1 액션(예를 들면, 함수)에 대해서만 콜드이 고 배치 내의 나머지 액션에 대해서는 웜이다. 게다가, 함수를 수용하기 위해 더 적은 수의 콜드 컨테이너가 빌드되어, 웜 컨테이너에 대한 콜드 컨테이너의 비율을 감소시킨다. 위에서 언급된 바와 같이, 함수는 레이턴 시 제약에 기초하여 임계 지속기간 초과 동안 지연되지 않을 수 있으며, 해당 시점에서, 함수가 어느 배치 내에 있는지에 관계없이, 실행을 향해 푸시된다.이제 도 16b를 살펴보면, 반도체 패키지 장치의 실시예는 하나 이상의 기판, 및 하나 이상의 기판 에 결합된 로직을 포함할 수 있으며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨 어 로직 중 하나 이상에 적어도 부분적으로 구현된다. 하나 이상의 기판에 결합된 로직은 각자의 함수의 실행을 각각 요청하는 복수의 함수 요청을 수신하고 복수의 함수 요청 중에서 배칭 가능 함수 요청을 결 정하도록 구성될 수 있다. 일부 실시예에서, 로직은 배칭 가능 함수 요청을 동일한 컨테이너에 송신하도 록 구성될 수 있다. 예를 들어, 로직은 동일한 컨테이너가 웜이라고 결정하고, 컨테이너가 웜이라는 결 정에 응답하여, 배칭 가능 함수 요청이 동일한 컨테이너에 송신되어야 한다고 결정하도록 구성될 수 있다. 일 부 실시예에서, 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지 스터 채널 영역을 포함할 수 있다. 로직 및 장치의 다른 컴포넌트의 실시예는, 적어도 부분적으로 하드웨어로 구현하는 것을 포함하여, 하드웨어, 소프트웨어, 또는 이들의 임의의 조합으로 구현될 수 있다. 예를 들어, 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어, 또는 이들의 임의의 조합을 포함할 수 있다. 추가적으로, 이 들 컴포넌트의 일부는 하나 이상의 모듈에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌 웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언 어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어 의 임의의 조합으로 작성될 수 있다. 장치는 방법(1650, 1670 및 1690)(도 16c, 도 16d 및 도 16e)의 하나 이상의 양태, 또는 본 명세서에서 논의된 실시예들 중 임의의 실시예를 구현할 수 있다. 일부 실시예에서, 예시된 장치는 하나 이상의 기 판(예를 들면, 실리콘, 사파이어, 갈륨 비화물) 및 기판(들)에 결합된 로직(예를 들면, 트랜 지스터 어레이 및 다른 집적 회로/IC 컴포넌트)을 포함할 수 있다. 로직은 적어도 부분적으로 구성 가능 한 로직 또는 고정 기능 로직 하드웨어로 구현될 수 있다. 일 예에서, 로직은 기판(들) 내에 배치 된(예를 들면, 매립된) 트랜지스터 채널 영역을 포함할 수 있다. 따라서, 로직과 기판(들) 사이의 계면은 계단형 접합(abrupt junction)이 아닐 수 있다. 로직은 또한 기판(들)의 초기 웨이퍼 상에 성장되는 에피택셜 층을 포함하는 것으로 간주될 수 있다. 도 16c는 함수 요청을 배칭하는 방법을 도시하며, 도 13a의 서버에 의해 실행될 수 있지만, 또는 서버와 협력하여, 도 4의 향상된 FaaS 시스템 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨 어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들 어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로도 구현될 수 있다. 예를 들어, 방법에 도시된 동작을 수행하기 위한 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 등과 같 은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프 로그래밍 언어를 포함하여, 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 추가적으로, 로 직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴 포넌트를 포함할 수 있다. 예시된 프로세싱 블록은 각자의 함수의 실행을 각각 요청하는 복수의 함수 요청을 수신할 수 있다. 예시 된 프로세싱 블록은 복수의 함수 요청 중에서 배칭 가능 함수 요청들을 결정할 수 있다. 예시된 프로세 싱 블록은 배칭 가능 함수 요청을 동일한 컨테이너에 송신할 수 있다. 예시된 프로세싱 블록은 추 가로 동일한 컨테이너가 웜이라고 결정하고, 동일한 컨테이너가 웜인 것에 기초하여, 배칭 가능 함수 요청들이 동일한 컨테이너에 송신되어야 한다고 결정할 수 있다. 예시된 프로세싱 블록은 비-배칭 가능한 복수의 함수 요청 중에서 하나 이상의 비-배칭 가능 함수 요청을 결정할 수 있다. 예시된 프로세싱 블록은 하나 이상의 비-배칭 가능 함수 요청 각각을 상이한 컨테이너 에 송신할 수 있다. 도 16d는 2개 이상의 함수 요청을 배칭하는 방법을 도시하며, 도 13a의 서버에 의해 실행될 수 있 지만, 또는 서버와 협력하여, 도 4의 향상된 FaaS 시스템 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로도 구현될 수 있다. 예시된 프로세싱 블록은 제1 배칭 가능 함수 요청을 수신할 수 있다. 예시된 프로세싱 블록은 제1 배칭 가능 함수 요청이 배칭되어야 한다고 결정할 수 있다. 예시된 프로세싱 블록은 제2 배칭 가능 함수 요청이 수신될 때까지 대기할 수 있다. 즉, 제1 배칭 가능 함수 요청은 실행을 위해 컨테이너에 즉시 송신되지 않을 수 있고 그리고/또는 스케줄링되지 않을 수 있다. 오히려, 방법은 스케줄링 이전에 실행을 위해 함 수 요청을 함께 효과적으로 배칭하기 위해 다른 함수 요청이 수신되기를 기다릴 수 있다. 예시된 프로세싱 블 록은 제1 및 제2 배칭 가능 함수 요청들이 함께 배칭 가능하다고 결정할 수 있다. 예시된 프로세싱 블록 은 제1 및 제2 배칭 가능 함수 요청들의 하나 이상의 레이턴시 제약을 결정할 수 있다. 본 명세서에서 이미 설명된 바와 같이, 레이턴시 제약은 제1 및 제2 배칭 가능 함수 요청들에 의해 호출된 함수가 실행을 완료 해야 하는 요청된 시간을 반영할 수 있다. 예시된 프로세싱 블록은, 하나 이상의 레이턴시 제약에 기초 하여, 제1 및 제2 배칭 가능 함수 요청들을 동일한 컨테이너에 송신하기 위한 전송 시간을 결정할 수 있다. 상 세하게는, 전송 시간은 제1 및 제2 배칭 가능 함수 요청들이 하나 이상의 레이턴시 제약을 준수하거나 또는 요 청된 시간까지 실행을 완료하도록 보장할 수 있다. 예시된 프로세싱 블록은 전송 시간에 제1 및 제2 배 칭 가능 함수 요청들을 동일한 컨테이너에 송신할 수 있다. 일부 실시예에서, 예시된 프로세싱 블록(1680, 1682)은 예시된 프로세싱 블록(1674, 1676, 1678) 중 하나 이상 과 동시에 또는 그 이전에 발생할 수 있다. 예를 들어, 제1 배칭 가능 함수 요청의 레이턴시 제약은 블록 과 동시에 식별될 수 있다. 게다가, 예시된 프로세싱 블록은, 제1 배칭 가능 함수 요청의 레이턴 시 제약에 기초하여, 제1 배칭 가능 함수 요청이 긴급하지 않고 다른 함수 요청을 기다릴 수 있다고 결정할 수 있다. 더욱이, 예시된 프로세싱 블록은 제1 배칭 가능 함수 요청의 레이턴시 제약에 부합하는 시간 기간 동안 다른 함수를 기다릴 수 있다. 도 16e는 레이턴시 제약을 준수하기 위해 함수 요청을 스케줄링하는 방법을 도시하며, 도 13a의 서버 에 의해 실행될 수 있지만, 또는 서버와 협력하여, 도 4의 향상된 FaaS 시스템 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 도 구현될 수 있다. 예시된 프로세싱 블록은 함수 요청을 수신한다. 예를 들어, 오케스트레이터는 함수 요청을 수신하고 함 수 요청을 스케줄링할 수 있다. 예시된 프로세싱 블록은 함수 요청의 레이턴시 제약을 결정할 수 있다. 위에서 설명된 바와 같이, 레이턴시 제약은 함수 요청에 의해 호출된 함수에 대한 총 허용 가능 레이턴시를 반 영할 수 있다. 레이턴시 제약은 함수의 선호되는 완료 타이밍을 반영하는 수치 척도(예를 들면, 5 ms) 및/또는 절대 시간(예를 들면, 2:48 EST)일 수 있다. 일부 실시예에서, 레이턴시 제약은 다른 함수 요청에 의존할 수 있다. 예를 들어, 함수는 다른 함수로부터의 데이터에 대해 동작할 수 있으며, 따라서 레이턴시 제약은 함수가 다른 함수의 완료로부터 미리 결정된 양의 시간 내에 실행을 완료해야 한다는 것을 반영할 수 있다. 일부 실시 예에서 레이턴시 제약은 함수 요청의 함수가 배칭을 기다리지 않고 가능한 한 빨리 실행되어야 한다는 것을 반 영할 수 있다. 예시된 프로세싱 블록은 레이턴시 제약을 준수하기 위해 함수 요청을 컨테이너에 송신할 수 있다. 함수 요청은 다른 함수 요청과 함께 배칭될 수 있다. 따라서, 함수 요청 및 다른 함수 요청이 컨테이너에 송신될 수 있다. 일부 실시예에서, 함수 요청이 컨테이너를 공유할 수 없거나, 또는 레이턴시 제약이 배칭을 위한 시간을 허용하지 않는 경우 함수 요청은 배칭되지 않을 수 있다. 추가 비고 및 예 예 1600은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 각자의 함수의 실행을 각각 요청하는 복수의 함수 요청을 수신하게 하고, 복수의 함수 요청 중에서 복수의 배칭 가능 함수 요청을 결정하게 하며, 복 수의 배칭 가능 함수 요청 중 제1 배칭 가능 함수 요청을 수신하게 하고, 제1 배칭 가능 함수 요청이 배칭되어 야 한다고 결정하게 하며, 복수의 배칭 가능 함수 요청 중 제2 배칭 가능 함수 요청이 수신될 때까지 대기하게 하고, 제1 및 제2 배칭 가능 함수 요청들이 함께 배칭 가능하다고 결정하게 하며, 제1 및 제2 배칭 가능 함수요청들의 하나 이상의 레이턴시 제약을 결정하게 하고, 하나 이상의 레이턴시 제약에 기초하여, 제1 및 제2 배 칭 가능 함수 요청들을 동일한 컨테이너에 송신하기 위한 시간을 결정하게 하며, 결정된 시간에 복수의 배칭 가 능 함수 요청을 동일한 컨테이너에 송신하게 하고, 동일한 컨테이너가 웜이라고 결정하게 하며, 동일한 컨테이 너가 웜인 것에 기초하여 복수의 배칭 가능 함수 요청이 동일한 컨테이너에 송신되어야 한다고 결정하게 하고, 비-배칭 가능한 복수의 함수 요청 중에서 하나 이상의 비-배칭 가능 함수 요청을 결정하게 하며, 하나 이상의 비-배칭 가능 함수 요청 각각을 상이한 컨테이너에 송신하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨 터 판독 가능 매체를 포함하고, 여기서 배칭 가능 함수 요청의 함수는 직렬 스킴으로, 병렬 스킴으로 또는 하이 브리드 직렬 및 병렬 스킴으로 실행될 것이다. 예 1601은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 각자의 함수의 실행을 각각 요청하는 복수의 함수 요청을 수신하게 하고, 복수의 함수 요청 중에서 복수의 배칭 가능 함수 요청을 결정하게 하는 명 령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 1602는 예 1601의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 복수의 배칭 가능 함수 요청을 동일한 컨테이너에 송신하게 하는 추가 명령어 세트를 포함한다. 예 1603은 예 1602의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 동일한 컨테이너가 웜이라고 결정하게 하고, 동일한 컨테이너가 웜인 것에 기초하여 복 수의 배칭 가능 함수 요청이 동일한 컨테이너에 송신되어야 한다고 결정하게 하는 추가 명령어 세트를 포함한다. 예 1604는 예 1601의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 복수의 배칭 가능 함수 요청 중 제1 배칭 가능 함수 요청을 수신하게 하고, 제1 배칭 가능 함수 요청이 배칭되어야 한다고 결정하게 하며, 복수의 배칭 가능 함수 요청 중 제2 배칭 가능 함수 요청 이 수신될 때까지 대기하게 하고, 제1 및 제2 배칭 가능 함수 요청들이 함께 배칭 가능하다고 결정하게 하는 추 가 명령어 세트를 포함한다. 예 1605는 예 1604의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 및 제2 배칭 가능 함수 요청들의 하나 이상의 레이턴시 제약을 결정하게 하고, 하 나 이상의 레이턴시 제약에 기초하여, 제1 및 제2 배칭 가능 함수 요청들을 동일한 컨테이너에 송신하기 위한 시간을 결정하게 하며, 결정된 시간에 제1 및 제2 배칭 가능 함수 요청들을 동일한 컨테이너에 송신하게 하는 추가 명령어 세트를 포함한다. 예 1606은 예 1601의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 비-배칭 가능한 복수의 함수 요청 중에서 하나 이상의 비-배칭 가능 함수 요청을 결정 하게 하고, 하나 이상의 비-배칭 가능 함수 요청 각각을 상이한 컨테이너에 송신하게 하는 추가 명령어 세트를 포함한다. 예 1607은 예 1601의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 배칭 가능 함수 요청의 함수는 직렬 스킴으로, 병렬 스킴으로 또는 하이브리드 직렬 및 병렬 스킴으로 실행될 것이다. 리던던트 함수 구현 이제 도 17a를 살펴보면, 함수 요청이 FaaS 시스템, 예를 들어, 도 4의 FaaS 시스템의 오케스트레이 터에 의해 핸들링되는 리던던트 함수 구현의 예가 도시되어 있다. 일부 경우에, 함수가 많은 인자(예를 들면, 컴퓨트 노드의 충돌)으로 인해 타임아웃되어 결코 완료되지 않을 수 있다. 예를 들어, 트리거될 때, 원래 함수는 오케스트레이터가 컴퓨트 노드(1706c)를 식별하여 원 래 함수에 할당할 수 있는 일련의 동작(예를 들면, 인증, 인가, 프리론칭 리소스 이용 가능성 등)을 거칠 수 있다. 그렇지만 상이한 플랫폼은 고유한 특성(예를 들면, 가상화 계층 등) 및 원래 함수를 요청한 FaaS 서비스의 클라이언트에게 알려지지 않고 불투명할 수 있는 리소스를 가질 수 있다. 예를 들어, 원래 함수 는 적시적 실행을 용이하게 하기 위해 충분한 비가입 리소스를 갖는 컴퓨트 노드(1706a)의 웜 컨테이너에 서 실행되는 것을 알 수 있다. 다른 경우에, 원래 함수는 실행을 용이하게 하기에 충분한 리소스 없이 비지(busy) 플랫폼에서도 실행되는 컴퓨트 노드(1706a)의 콜드 컨테이너에서 실행될 수 있다. 더욱이, 원래 함 수는 성능이 또한 가변적인 다른 서비스를 추가로 소비할 수 있다. 그 결과, 원래 함수가 실제로실행되기 시작하여 실행을 완료하고, 또한 원래 함수가 적시에 완료될 것이라는 확신이 제한될 수 있다. 예를 들어, 원래 함수가 가용 리소스(예를 들면, 메모리에 대한 동적 제한)를 초과하는 경우 원래 함수 가 디스패치되지 않을 수 있다. 게다가, 원래 함수가 적시에 디스패치되지 않을 수 있거나, 또는 일단 디스패치되면, 원래 함수가 허용된 시간 제한 내에 실행을 완료할 것인지가 불분명할 수 있다. 일부 경우에, 원래 함수가 완료될 수 있지만, 여러 번의 직렬 재시도를 필요로 한다. 따라서, 원래 함수 가 최종적으로 완료될 때까지, 원래 함수는 연달아 여러 번 리스포닝(respawn)수 있다. 클라이언 트에서 그러한 직렬 재시도를 수행하는 것은 비용이 많이 들기도 하고 완료를 보장하기도 어려운데, 그 이유는 클라이언트가 성공 또는 실패를 결과하는 인자를 제어할 수 없기 때문이다. 성공적인 결과에 대해 테스트하고 재시도하는 것은 또한 요청자에서의 프로그래밍을 복잡하게 만든다. 일부 함수는 성공을 위한 높은 요구사항을 갖는 것으로 간주될 수 있으며, 따라서 미완료 또는 지연된 완료의 위험이 용인되지 않을 수 있다. 아래에서 논의되는 바와 같이, 오케스트레이터는 다수의 컴퓨트 노드 (1706a 내지 1706c)에 걸친 리던던트 함수 실행에 의해 미완료 또는 지연된 완료의 가능성을 완화시킬 수 있다. 예를 들어, 원래 함수의 리던던트 함수(1708a, 1708b)가 스포닝(spawn)되어 상이한 노드(1706a, 1706b) 에서 실행될 수 있다. 도 17a에 예시된 바와 같이, 이벤트 핸들링 API 프록시는 이벤트 호출을 함수로 라우팅할 수 있다. 1700 의 예에서, API 프록시는, 예를 들어, API를 통해 함수 요청을 생성할 수 있다. 함수 요청 호출 이 오케스트레이터에 제공될 수 있다. 함수 요청은 원래 함수를 실행하라는 요청일 수 있다. 오케스트레이터는 함수 요청을 분석할 수 있다. 상세하게는, 오케스트레이터는 리던던트 함수 실행을 제공할지를 결정할 수 있다. 그러한 결정은 원래 함수가 품질 임계치를 충족시키 는지에 기초할 수 있다. 품질 임계치는 사용자 요청(예를 들면, 토큰, 클래스 등), 서비스 품질(QoS) 메트릭, 또는 서비스 수준 협약에 기초할 수 있다. 도 17a의 예에서, 오케스트레이터는 원래 함수가 품질 임계치를 충족시키며, 따라서 원래 함수 의 미완료 또는 비적시적 완료의 가능성이 리던던트 함수 실행 스킴을 통해 완화되어야 한다고 결정할 수 있다. 리던던트 함수 실행 스킴은 리던던트 함수(1708a, 1708b)를 스포닝하는 것을 포함할 수 있다. 일 예에 서, 리던던트 함수(1708a, 1708b) 각각은 원래 함수의 동일한 사본일 수 있지만, 원래 함수의 구현 은 1708a, 1708b 등에서 느리지만 보장된 실행을 위해 임의로 특화(particularize)될 수 있다. 예를 들어, 이 것은 보장된 함수의 실행에 중요한 동적 리소스 이용의 이용 가능한 레벨에 기초한 예측적, 사전대응적 및 사후 대응적 대책을 포함한 상이한 반복 전략을 사용하여 달성될 수 있다. 예를 들어, 128 MB 함수가 256 MB의 RAM 으로 프로비저닝된 컨테이너에서 실행될 수 있다. 함수는 256 MiB의 RAM으로 프로비저닝된 컨테이너에서 실행 될 수 있다. 다른 예로서, 함수가 더 긴 타임아웃으로 실행될 수 있다. 예시된 바와 같이, 원래 함수 및 리던던트 함수(1708a, 1708b)가 상이한 컴퓨트 노드(1706a 내지 1706 c)에 제공될 수 있다. 따라서, 함수 타임 아웃 또는 미완료의 가능성이 완화될 수 있다. 그와 같이, 리던던트 함수(1708a, 1708b) 및 원래 함수 중 하나가 미리 결정된 양의 시간 내에 성공적으로 완료될 증가된 가능 성을 통해 신뢰성이 향상된다. 일단 원래 함수 및 리던던트 함수(1708a, 1708b) 중 하나가 실행을 완료하면, 오케스트레이터 또는 다른 메커니즘은 원래 함수 및 리던던트 함수(1708a 및 1708b) 중 완료되지 않은 것의 실행을 취소할 수 있다. 따라서, 리소스가 취소를 통해 효율적으로 관리될 수 있다. 일부 실시예에서, 함수 요청은 함수가 보장되어야 하는지를 지정하는 필드를 포함할 수 있다. 따라서, FaaS 아키텍처의, 클라이언트와 같은, 사용자는 언제 함수가 보장되어야 하는지를 지정할 수 있다. 일부 실시 예에서, 오케스트레이터는 보장되는 함수의 화이트리스트를 포함할 수 있고, 실행 동안 해당 함수의 다수 의 사본을 스포닝할 수 있다. 일부 실시예에서, 리던던트 함수(1708a, 1708b)는 원래 함수와의 비-중첩 실행을 가질 수 있다. 예를 들 어, 컴퓨트 노드(1706c)는 원래 함수의 실행에 대한 진행상황 보고서를 제공할 수 있다. 진행상황 보고 서는 완료된 동작의 개수, 원래 함수의 현재 실행된 코드 라인 등을 나타낼 수 있다. 진행상황 보고서가 원래 함수가 지연되거나 타임 아웃될 수 있음을 나타내는 경우, 오케스트레이터는 원래 함수(171 2)가 실행을 시작한 후의 시간에서 리던던트 함수(1708a, 1708b)를 스포닝할 수 있다. 일부 실시예에서, 오케스트레이터는 원래 함수의 실행에 필요할 수 있는 리소스 요구사항을 결정할 수 있다. 오케스트레이터는 리소스의 동적 이용의 이용 가능한 척도에 기초하여 리소스 요구사항을 결정 할 수 있다. 일부 실시예에서, 다양한 원격 측정 소스로부터, 예를 들면, 타이머, 함수 또는 디버그 로그, 및 성능 모니터로부터 수집된 것과 같은 이력 정보는, 나중에 향후 함수 호출의 스케줄링을 알리기 위해 사용될 수 있는, 각각의 함수에 대한 실행 시간 및/또는 리소스 요구사항을 추정하는 데 사용될 수 있다. 추가 세부사항 에 대해서는, 도 24a 및 도 41a에 대한 논의를 참조한다. 오케스트레이터는, 리소스 요구사항에 기초하 여, 리던던트 함수(1708a, 1708b)를 스포닝할지를 결정할 수 있다. 예를 들어, 리던던트 함수(1708a, 1708b)는 컴퓨트 노드(1706c)가 충분한 리소스를 결여할 수 있거나 또는 원래 함수의 실행을 완료하기 위한 리소스 요구사항을 충족시킬 수 없다는 식별에 응답하여 스포닝될 수 있다. 예를 들어, 당초 스케줄링되었을 때, 컴퓨 트 노드(1706c)는 원래 함수를 실행하기에 충분한 리소스를 가질 수 있다. 그렇지만, 컴퓨트 노드(1706c)가 리소스 면에서 열화되는 경우, 컴퓨트 노드(1706c)는 원래 함수를 실행 하기에 충분한 리소스를 결여할 수 있다. 예를 들어, 컴퓨트 노드가 과열로 인해 스로틀링할 필요가 있 거나, 또는 리소스의 재할당을 강제하는 더 새롭고 더 높은 우선순위의 함수가 컴퓨트 노드(1706c)에 할당되는 경우, 원래 함수의 실행을 위한 이용 가능한 리소스가 감소될 수 있다. 일부 실시예에서, 원래 함수 가 임계치를 초과하는 특정 양의 리소스를 필요로 할 것이고, 따라서 컴퓨트 노드(1706c)와 같은 특정 서 버에서 유지하기 어려울 수 있다는 식별이 이루어질 수 있다. 일부 실시예에서, 원래 함수 및 리던던트 함수(1708a 및 1708b) 각각은 동시에 실행을 시작하도록 오케스트레이터에 의해 스케줄링될 수 있다. 예 를 들어, 원래 함수 및 리던던트 함수(1708a, 1708b) 각각에 대해 거의 동시에 또는 가능한 한 빨리 실행 을 시작하기 위해, 원래 함수 및 리던던트 함수(1708a, 1708b)는 원래 함수가 품질 임계치를 충족 시킨다는 식별에 응답하여 실행되도록 스케줄링될 수 있다. 리던던트 함수(1708a 및 1708b) 및 원래 함수 는 중첩하는 실행 시간을 가질 수 있다. 일부 실시예에서, 리던던트 함수(1708a, 1708b)는 원래 함수가 실행을 완료하지 못하는 경우에만 실행되 도록 스케줄링될 수 있다. 예를 들어, 오케스트레이터는 원래 함수가 실행을 완료하지 못했고 품 질 임계치를 충족시킨다고 결정할 수 있다. 따라서, 오케스트레이터는 제2 미완료 발생을 완화시키기 위 해 원래 함수의 다수의 리던던트 사본이 리던던트 함수(1708a, 1708b)로서 스포닝되어야 한다고 결정할 수 있다. 게다가, API 프록시 또는 오케스트레이터는 지정된 파라미터에 기초하여 원래 함수의 중요성 을 식별할 수 있다. 어느 정도의 확실성을 획득하기 위해 상이한 함수에 대해 상이한 유형의 반복 전략을 지정 하는 지정된 파라미터는 관리자 또는 클라이언트에 의해 설정될 수 있다. 위에서 설명된 바와 같이, 그러한 전 략은 원래 함수의 실행에 필요한 리소스의 동적 활용의 이용 가능한 척도에 기초한 예측적, 사전대응적 및 사후대응적 대책을 포함할 수 있다. 일단 원래 함수가 실행되어 완료되면, 오케스트레이터는 리던던트 함수(1708a, 1708b)가 어떤 실행 스테이지에 있든 상관없이 리던던트 함수(1708a, 1708b)를 취소, 드 롭 또는 종료할 수 있으며, 따라서 불필요한 리소스 소비를 절감할 수 있다. 따라서, 오케스트레이터는 함수가 실패할 가능성을 완화시키고 함수가 적시에 실행될 것을 보장함으로써 FaaS 함수 구현을 향상시킬 수 있 다. 도 17b는 리던던트 FaaS 함수 구현 방법을 도시하며, 도 13a의 서버에 의해 실행될 수 있지만, 또 는 서버와 협력하여, 도 4의 향상된 FaaS 시스템 및/또는 도 17a의 오케스트레이터 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매 체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조 합으로도 구현될 수 있다. 예시된 프로세싱 블록은 원래 함수를 실행하기 위한 함수 요청 호출을 수신할 수 있다. 함수 요청 호출 은, 예를 들어, 애플리케이션 또는 사용자 디바이스로부터 유래할 수 있다. 예시된 프로세싱 블록은 원 래 함수가 품질 임계치를 충족시키는지를 결정할 수 있다. 만약 그렇지 않다면, 원래 함수만이 실행될 수 있다. 즉, 리던던트 함수가 스포닝되지 않을 수 있다. 그렇지만 만약 그렇다면, 예시된 프로세싱 블록 은 하나 이상의 리던던트 함수가 원래 함수와 함께 실행되어야 한다고 결정할 수 있다. 하나 이상의 리던던트 사본 각각은 원래 함수의 동일한 사본일 수 있다. 예시된 프로세싱 블록은 상이한 컴퓨트 노드에서 중첩 하는 시간에 원래 함수 및 하나 이상의 리던던트 사본을 실행하는 것을 포함할 수 있다. 게다가, 예시된 프로 세싱 블록은 제1 시간에서 원래 함수의 실행을 시작하는 것, 및 제1 시간 이후에 제2 시간에서 하나 이상 의 리던던트 사본의 실행을 시작하는 것을 추가로 포함할 수 있다. 일부 실시예에서, 원래 함수 및 하나 이상의 리던던트 사본은 비-중첩하는 시간에 실행될 수 있다. 일부 실시예에서, 하나 이상의 리던던트 사본은 원래 함수가 진행 임계치 또는 리소스 요구사항 중 하나 이상을 충족시키지 못한다는 식별에 응답하여 실행을 시작할 수 있다. 추가 비고 및 예 예 1700은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 원래 함수를 실행하기 위한 함수 요 청 호출을 수신하게 하고, 원래 함수가 품질 임계치를 충족시키는지를 결정하게 하며, 원래 함수가 품질 임계치 를 충족시키는 것에 응답하여, 원래 함수의 하나 이상의 리던던트 함수가 원래 함수와 함께 실행되어야 한다고 결정하게 하고 - 하나 이상의 리던던트 함수 각각은 원래 함수의 사본임 -, 원래 함수와 하나 이상의 리던던트 함수를 중첩하는 시간에 실행하게 하며, 원래 함수와 하나 이상의 리던던트 함수를 상이한 컴퓨트 노드에 실행 하게 하고, 제1 시간에서 원래 함수의 실행을 시작하게 하며, 제1 시간 이후의 제2 시간에서 하나 이상의 리던 던트 함수의 실행을 시작하게 하고, 원래 함수가 진행 임계치 또는 리소스 요구사항을 충족시키지 못한다는 식 별에 응답하여 하나 이상의 리던던트 함수의 실행을 시작하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨 터 판독 가능 매체를 포함한다. 예 1701은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 원래 함수를 실행하기 위한 함수 요 청 호출을 수신하게 하고, 원래 함수가 품질 임계치를 충족시키는지를 결정하게 하며, 원래 함수가 품질 임계치 를 충족시키는 것에 응답하여, 하나 이상의 리던던트 함수가 원래 함수와 함께 실행되어야 한다고 결정하게 하 는 - 하나 이상의 리던던트 함수 각각은 원래 함수의 사본임 - 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 1702는 예 1701의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 원래 함수와 하나 이상의 리던던트 함수를 중첩하는 시간에 실행하게 하는 추가 명령어 세트를 포함한다. 예 1703은 예 1701의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 원래 함수와 하나 이상의 리던던트 함수를 상이한 컴퓨트 노드에 실행하게 하는 추가 명령어 세트를 포함한다. 예 1704는 예 1701의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 시간에서 원래 함수의 실행을 시작하게 하고, 제1 시간 이후에 제2 시간에서 하나 이상의 리던던트 함수의 실행을 시작하게 하는 추가 명령어 세트를 포함한다. 예 1705는 예 1701의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 원래 함수가 진행 임계치 또는 리소스 요구사항을 충족시키지 못한다는 식별에 응답하 여 하나 이상의 리던던트 함수의 실행을 시작하게 하는 추가 명령어 세트를 포함한다. FaaS 및/또는 AFaaS 함수의 반복 실행 일부 태스크는 FaaS 및/또는 AFaaS 함수의 반복 실행을 트리거할 수 있다. 아래에서 FaaS가 참조되지만, AFaaS 함수가 유사하게 실행될 수 있음이 이해될 것이다. FaaS 함수는 상이한 공간 또는 관심 영역을 조사할 수 있다. 예를 들어, 입찰 매칭 태스크는 가장 유리한 조건 을 가진 제안을 찾기 위해 다양한 제안 조합을 탐색할 수 있다. 다양한 조합이 반복 FaaS 함수를 통해 탐색될 수 있다. 예로서, FaaS 함수는 입찰 매칭 프로세스를 실행하기 위해 반복적으로 반복할 필요가 있을 수 있다. 예를 들어, 제안의 조건이 입찰의 변경을 필요로 하거나 또는 다른 제안보다 비싸게 입찰(outbid)하는 것을 필 요로 하는 조항을 포함하는 경우, 하나 이상의 함수가 반복적으로 동작할 필요가 있을 수 있다. 다른 예로서, 인공 지능 지원 에지 서비스에서, 추론이 허용 가능한 위험 기준에 속하는 관련 신뢰도 메트릭을 가질 때까지 추론이 솔루션으로서 식별되지 않을 수 있다. 일부 경우에, 반복 태스크를 완료하기 위한 조건이 동적으로 지정될 가능성이 있기 때문에, 위에서 설명된 다양 한 동적 조건을 고려하기 위해 반복 제어를 동적으로 스크립팅 가능하거나 변경 가능하게 만드는 것에 의해 반 복 실행이 지원될 수 있다. 따라서, FaaS 함수는 특정 컨텍스트에서 동적 제어를 사용하여 반복적으로 동작한 다. 그렇지만 반복 FaaS 함수는 때때로 완료를 위해 동적 조건에 도달함이 없이 불필요하게 계속 동작할 수 있 다. 예를 들어, 상이한 FaaS 함수에 의해 각각 탐색되는, 2개의 검색 공간이 있다고 가정한다. 일정 양의 시 간 이후에, FaaS 함수들 중 하나가 실행 가능한 솔루션을 생성할 가능성이 없는 검색 서브공간을 탐색하고 있음이 분명해질 수 있다. 그러한 FaaS 함수가 불필요하게 동작하게 하는 것은 FaaS 함수가 실행 가능한 솔루션을 생성할 가능성이 더 높은 다른 FaaS 함수에 할당될 수 있는 리소스를 소비한다는 점에서 비효율적이다. 더욱이, FaaS 함수는 종료 조건(예를 들면, 실행 가능한 솔루션)에 도달하지 않을 수 있고 시간에 도달할 때까 지 계속 동작할 수 있다. 따라서, 레이턴시가 증가되고 리소스가 비효율적으로 할당된다. 검색 공간은 검색 스킴 또는 절차가 검색 기준을 충족시키는 가능한 솔루션 또는 답변을 탐색할 수 있는 솔루션 또는 답변의 실행 가능한 영역일 수 있다. 예를 들어, 검색 공간은 검색이 실행 가능한 것으로 간주될 수 있는 가능성, 파라미터, 알고리즘, 스킴, 값 또는 액세스 또는 시간 제약의 전체 모음을 기술하는 데 사용될 수 있다. 하나의 특정 예에서, 체스를 하는 슈퍼 컴퓨터의 경우, 검색 공간이 매우 클 수 있지만, 클라우드와 연 결해제된 랩톱 또는 태블릿에서 실행되는 프로그램의 경우, 검색 공간이 평가의 깊이, 평가 시간, 또는 평가할 대안의 무브(move)의 수 등에서 제약될 수 있다. 위에서는 검색 공간이 언급되지만, 아래에서는 \"솔루션 공 간\"이 언급되며, 여기서 검색 공간은 솔루션 공간의 예이다. 솔루션 공간은 솔루션이 식별되는 공간일 수 있다. 도 18a 및 도 18b를 살펴보면, FaaS 서비스에 대한 함수 생성 그래프를 생성하기 위해 향상된 스케줄러 가 제공된다. 향상된 스케줄러는 조건이 충족되는 것에 기초하여, 예를 들어, 솔루션 공간(예를 들면, 특정 탐색 세트)이 실행 가능한 솔루션을 생성할 가능성이 없을 확률에 기초하여 함수 생성 그래프(180 0)의 솔루션 공간에 대한 리소스 할당을 취소하거나 재우선순위화할 수 있다. 그렇게 하는 것은 리소스 할당을 향상시킬 수 있고 실행 가능하고 최적에 가까운 실행 가능한 솔루션 공간으로부터 솔루션을 찾는 타이밍을 감소 시킬 수 있다. 도 18a는 함수 생성 그래프를 예시한다. (도 18b에 도시된 바와 같은) 스케줄러는 함수 그래프 를 생성하고 충분히 가치있는 솔루션을 찾는 쪽으로 함수 그래프를 실행하기 위한 다양한 스케줄링, 취소 및 재우선순위화 메타-태스크를 구현하는 다양한 하드웨어 또는 소프트웨어 구현을 포함할 수 있다. 예를 들어, 스케줄러는 스레드 빌딩 블록을 사용하여 빌드된 분기 한정(branch and bound) 동작일 수 있거나; 또는 SQL 질의 최적화기 등일 수 있다. 태스크는 함수 A, 함수 B, 함수 C, 함수 D 및 함수 E를 스포닝할 수 있다. 함수 A, 함수 B, 함수 C, 함 수 D 및 함수 E는 이하의 설명에서 간결함을 위해 집합적으로 \"스포닝된 함수\"라고 지칭될 수 있다. 함수 생성 그래프는 스포닝된 함수가 병렬로 또는 직렬로 동작하는 스케줄의 데이터 표현이다. 스포닝된 함수는 이질적이지만 관련있는 함수일 수 있다. 함수 C는 실행하기 위해 함수 A로부터의 데이터에 의존할 수 있으며, 따라서 함수 A에 의존적이다. 그와 같이, 함수 A 및 함수 C는 함수 생성 그래프의 제1 분기로 간주될 수 있다. 마찬가지로, 함수 D는 실행하기 위해 함수 B로 부터의 데이터에 의존할 수 있고, 따라서 함수 B에 의존적이다. 함수 B 및 함수 D는 함수 생성 그 래프의 제3 분기로 간주될 수 있다. 함수 E는 동작하기 위해 다른 함수로부터의 데이터를 필요로 하지 않을 수 있다. 함수 E는 함수 생성 그래프의 제2 분기로 간주될 수 있다. 제 1, 제2 및 제3 분기(1814, 1816, 1818) 각각은 적어도 하나의 반복 함수를 포함할 수 있으며, 잠재적인 솔루션 또는 결과에 대한 별개의 솔루션 공간 및/또는 탐색 가능성으로 간주된다. 완료된 것으로 간주되기 위해, 태스 크는 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 하나로부터 가능한 최상의 솔루션 또는 결과만을 채택 할 수 있다. 예시된 바와 같이, 제1, 제2 및 제3 분기(1814, 1816, 1818)는 별개이지만 서로 관련될 수 있다. 즉, 제1, 제2 및 제3 분기(1814, 1816, 1818)는 상이한 검색 솔루션 공간 또는 반복 탐색 영역을 나타낼 수 있다. 제1, 제2 및 제3 분기(1814, 1816, 1818)는, 예를 들어, 실행하기 위해 정보를 공유하지 않음으로써 독립적으로 동작할 수 있으며, 따라서 별개인 것으로 간주될 수 있다. 그렇지만 제1, 제2 및 제3 분기(1814, 1816, 1818)는 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 하나가 그 자체 또는 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 다른 것의 우선순위해제 또는 취소를 야기할 수 있다는 점에서 관련될 수 있다. 예를 들어, 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 하나의 분기가 (우선순위해제 조건으로 간주될 수 있는) 취소 조건에 도달하는 경우, 스케줄러는 하나의 분기를 종료할 수 있다. 다른 예에서, 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 한 분기에 대한 리소스 할당은 스케줄러에 의해 그리고 우선순위해제 조건에 도달되는 것에 기초하여 수정될 수 있다. 예를 들어, 스케줄러가 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 하나의 분기가 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 다른 분기보다 상당히 더 적은 성공 확률을 갖는다는 것을 식별하는 경우, 우선순위해제 조건이 충족된 것으로 간주될 수 있다. 게다가, 스케줄 러는 하나의 분기에 대한 리소스 할당을 감소시키고 다른 분기에 대한 리소스 할당을 증가시킬 수 있다. 예를 들어, 각각의 솔루션 공간은 상이한 솔루션을 나타낼 수 있다. 솔루션 공간이 검색 크기가 좁아지거나 감 소함에 따라, 잠재적 솔루션의 개수가 그에 대응하여 감소하여, 한정된 양의 계산 노력 또는 시간 내에서 솔루 션이 달성될 수 있음을 의미한다. 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 하나의 분기가 반복을 통해 솔 루션 공간을 감소시키는 경우(솔루션에 대한 가능한 선택 사항을 좁히는 경우), 해당 하나의 분기는 성공 추세 를 보이고 있을 수 있다. 이와 달리, 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 다른 분기가 솔루션 공간을 증가시키거나(솔루션에 대한 가능한 선택 사항을 증가시키거나) 동일한 솔루션 공간 크기를 유지하는 경우, 다 른 분기는 실패 추세에 있을 수 있고 그리고/또는 현재 우선순위화된 탐색이 솔루션으로 이어질 가능성을 소진 한 후에 탐색할 대안 솔루션을 생성할 수 있다. 따라서 다른 분기는 실패 추세에 기초하여 우선순위해제 조건 에 도달할 수 있다. 일부 실시예에서, 솔루션 공간 크기(솔루션 선택 사항)의 비교는 우선순위해제 조건에 도 달하게 할 수 있다. 예를 들어, 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 하나의 분기의 하나의 솔루션 공 간이 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 다른 분기의 다른 솔루션 공간보다 반복을 통해 더 빠른 속도 로 감소한 경우, 다른 분기는 우선순위해제 조건을 충족시키는 것으로 간주될 수 있다. 특히, 위에서 설명된 바와 같이, 스포닝된 함수들 중 하나는 우선순위해제 조건에 도달할 수 있다. 우선순위해 제 조건은 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 하나 이상이 우선순위해제될 수 있음을 나타낼 수 있다. 우선순위해제된다는 것은 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 하나 이상이 태스크에 의해 처리되는 문 제에 대한 실행 가능한 솔루션을 생성할 가능성이 없는 영역 또는 공간을 탐색하는 것으로 간주되거나 또는 어 떤 다른 스포닝된 함수보다 더 많은 리소스 또는 시간을 필요로 할 가능성이 있다는 것을 의미할 수 있다. 스 케줄러가 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 하나의 분기를 우선순위해제하는 경우, 더 적은 리 소스가 하나의 분기에 할당될 수 있거나, 또는 하나의 분기가 하나의 분기를 포함하는 임의의 스포닝된 함수를 보류/종료/해제(unwind)하는 것에 의해 보류/종료/해제될 수 있다. 우선순위해제 조건은 스포닝된 함수들 중 하나가 종료 조건을 식별하고, 따라서 하나의 스포닝된 함수 또는 다른 스포닝된 함수의 종료를 결과할 때일 수 있다. 따라서, 태스크에 덜 중요하거나 관련이 없는 함수의 실행을 회피하는 것에 의해 효율적인 리소스 할당 이 달성될 수 있다. 예를 들어, 함수 D가 우선순위해제 조건에 도달한다고 가정한다. 제3 분기가 종료될 수 있으며, 이는 함수 D 및/또는 함수 B의 실행을 중지하는 것을 포함할 수 있다. 일부 실시예에서, 제3 분기 를 종료하기보다는 제3 분기에 대한 리소스 할당이 감소된다. 예를 들어, 함수 D 및/또는 함수 B에 대한 리소스 할당이 감소될 수 있다. 일부 실시예에서, 우선순위해제 조건은 함수 D에 의해 생성된 값, 함수 D에 의해 생성된 솔루션의 신뢰 구간, 함수 D에 의한 성공 가능성의 측정치, 함수 D가 잠 재적 솔루션에 접근하고 있는지 등을 통해 식별될 수 있다. 도 18b에 예시된 바와 같이, 향상된 FaaS 시스템은 스케줄러를 포함할 수 있다. 이미 설명된 바와 같이, 스케줄러는 도 18a의 함수 생성 그래프를 생성하고, 함수 그래프에 따라 스케줄링하며 스포닝된 함수를 그에 따라 취소할 수 있다. 상세하게는, 스케줄러는 스포닝된 함수의 실행을 함수 생성 그래프에 따라 스케줄링하고 모니터링 할 수 있다. 함수 A의 반복 실행, 함수 B의 반복 실행, 함수 C의 반복 실행, 함수 D(182 8)의 반복 실행 및 함수 E의 반복 실행은 제각기 도 18a의 함수 A, 함수 B, 함수 C, 함수 D 및 함수 E에 대응한다. 스케줄러는 함수 생성 그래프의 실행 동안 우선순위해제 조건(예를 들면, 종료 조건)을 식별하고, 우선순위해제 조건에 기초하여 실행을 중단 또는 보류할 수 있다. 예를 들어, 스케줄러는 스포닝된 함수 들 중 하나 이상을 종료 또는 보류하고 스포닝된 함수의 임의의 추가 함수 인스턴스화를 중단 및/또는 일시중지 할 수 있다. 스케줄러는 그렇게 하기 위해 하드웨어 큐 관리자 및 멀티캐스팅을 이용할 수 있다. 상세하게는, 함수 A의 반복 실행은, 함수 A의 반복인, FA1 내지 FAn을 포함한다. 함수 A의 반복 실행이 완료될 수 있고, 이어서 함수 C의 반복 실행이 시작될 수 있다. 마찬가지로, 함수 B 의 반복 실행이 완료될 수 있고, 함수 D의 반복 실행이 시작될 수 있다. 일부 실시예에서, 동시 실행이 수행될 수 있다. 예를 들어, 함수 A의 반복 실행이 함수 C의 반복 실행과 동시에 발생할 수 있다. 게다가, 함수 B의 반복 실행이 함수 D의 반복 실행과 동시적일 수 있다.함수 C의 반복 실행 동안, 스케줄러는 함수 C의 반복 실행을 종료하는 우선순위해제 조건을 식별할 수 있다. 그러한 우선순위해제 조건은 제1 분기, 특히 함수 C가 실행 가능한 솔루션을 생 성할 가능성이 없다는 식별을 포함할 수 있다. 따라서, 함수 C의 반복 실행은 하나의 반복 FC1에 대해서 만 실행된다. 함수 C의 반복 실행의 취소 또는 보류 이후에, 함수 C의 반복 실행에 할당된 리소스 는 다른 실행에 재할당될 수 있다. 예를 들어, 함수 E의 반복 실행은 증가된 리소스 할당을 가질 수 있 고 그리고/또는 함수 D의 반복 실행은 증가된 리소스 할당을 가질 수 있다. 일부 실시예에서, 함수 C의 반복 실행을 취소하기보다는, 스케줄러는 함수 C의 반복 실행의 리소스 할당을 감소시킬 수 있다. 일부 실시예에서, 스케줄러는 함수 C의 반복 실행으로부터 함수 E의 반복 실행 및/또는 함수 D의 반복 실행으로 리소스 할당을 재분배할 수 있다. 일부 실시예에 서, 리소스는, 스포닝된 함수들 중 하나 이상이 가장 큰 성공 기회, 및/또는 여전히 계속 실행되는 스포닝된 함 수들 중 다른 함수에 비해 더 큰 성공 기회를 가질 확률에 기초하여, 스포닝된 함수들 중 하나 이상에 재할당될 수 있다. 그렇게 하는 것은 함수 E의 반복 실행 및/또는 함수 D의 반복 실행의 레이턴시를 감소시 킬 수 있으며, 더욱이 태스크에 대한 솔루션을 식별하는 것의 레이턴시를 감소시킬 수 있다. 그렇지만 함수 C의 반복 실행의 레이턴시는 증가할 수 있지만, 함수 C의 반복 실행에 의해 제기된 더 낮은 성공 확률을 감안할 때 허용 가능한 트레이드 오프로 간주될 수 있다. 일부 실시예에서, 함수 C의 반복 실행은 재우선순위화될 수 있다. 예를 들어, 함수 C의 반복 실행 이 재개되고 그리고/또는 증가된 리소스 할당을 갖도록, 재우선순위화 조건이 충족되면 함수 C의 반복 실 행이 재우선순위화될 수 있다. 예를 들어, 재우선순위화 조건은 함수 C의 반복 실행이 스포닝된 함수들 중 다른 것보다 실행 가능한 결과를 생성할 가능성이 더 높다는 표시일 수 있다. 일부 실시예에서, 재우선순위 화 조건은 다른 스포닝된 함수, 예를 들어, 함수 D의 반복 실행이 감소된 성공 확률을 갖는다는 식별일 수 있다. 일부 실시예에서, 스포닝된 함수의 반복 실행이 상이한 노드 및/또는 컨테이너에서 발생한다. 예를 들어, 함수 A의 반복 실행이 상이한 노드 및/또는 상이한 컨테이너에서 발생할 수 있다. FA1은 제1 노드에 있는 제1 컨테이너에서 실행될 수 있는 반면, FAN은 제2 노드에 있는 제2 컨테이너에서 실행될 수 있다. 이미 설명된 바와 같이, 스케줄러는 위에서 설명된 바와 같이 스포닝된 함수를 종료하는 것 및/또는 덜 성공적인 솔루션 공간에 대한 리소스 할당을 감소시키는 것에 의해 레이턴시를 감소시키고 향상된 리소스 관리 를 가질 수 있다. 예를 들어, 리소스가 우선순위해제 조건 식별에 응답하여 효율적으로 할당해제된다. 반복 태스크를 완료하기 위한 조건이 동적으로 지정될 가능성이 있기 때문에, 반복 실행 제어는 동적으로 스크 립팅 가능하거나 변경 가능할 수 있다. 따라서, 스케줄러는 제1, 제2 및 제3 분기(1814, 1816, 1818), 특히 제1, 제2 및 제3 분기(1814, 1816, 1818)의 스포닝된 함수에 의해 표현되는 상이한 전략을 탐색할 수 있다. 제1, 제2 및 제3 분기(1814, 1816, 1818)는 동적 힌트, 최근의 관측된 패턴 및 패턴의 변화, 제약의 변 동 등에 따라 결정되는 상이한 검색 전략일 수 있다. 예를 들어, 스케줄러는 임의의 주어진 시간에 한정된 양의 시간 및 전력 버짓 내에서 최상의 추론을 식별 할 수 있다. 그렇게 하기 위해, 시간 윈도가 충분히 작거나 임계치를 충족시키지 못하는 경우, 및/또는 컴퓨트 버짓(compute budget)이 충분히 작거나 임계치를 충족시키지 못하는 경우 스케줄러는 저 정밀도 전략을 사용할 수 있다. 도 18b에 예시된 바와 같이 제1, 제2 및 제3 분기(1814, 1816, 1818)를 탐색한 후에, 스케줄 러는 위에서 설명된 제1 분기와 같은 솔루션 공간을 제거한 후에 향후 반복에 대해 더 높은 정밀도 를 사용할 수 있다. 따라서, 스케줄러는 제1, 제2 및 제3 분기(1814, 1816, 1818)를 통해 여러 병렬적인 저비용 검색을 개시할 수 있고 이어서 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 다른 것이 더 생산적인 결과 를 생성할 것이라는 식별에 응답하여 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 일부를 취소할 수 있다. 이 미 설명된 바와 같이, 제1, 제2 및 제3 분기(1814, 1816, 1818) 중 한 분기의 취소는 취소된 분기를 포함하는 스포닝된 함수(들)의 취소를 의미할 수 있다. 따라서, 스케줄러는 함수 A의 반복 실행, 함수 B의 반복 실행, 함수 C의 반복 실행, 함수 D의 반복 실행 및 함수 E의 반복 실행 중 우선순위해제된 것에 대한 리소스 할당을 효율적으 로 취소하거나 감소시킬 수 있다. 우선순위해제된다는 것은 우선순위해제된 반복 함수가 태스크에 의해 처리되 는 문제에 대한 실행 가능한 솔루션을 생성할 가능성이 없는 영역 또는 공간을 탐색하는 것으로 간주됨을 의미 할 수 있다. 예를 들어, 일부 실시예는 함수 A의 반복 실행, 함수 B의 반복 실행, 함수 C의반복 실행, 함수 D의 반복 실행 및 함수 E의 반복 실행의 그러한 동적 반복 론칭 및 취소에 대한 다양한 메타 프로그래밍 지원을 포함할 수 있다. 솔루션 서브공간이 일시적으로 우선순위해제되는 경우, 이를 탐색하는 데 소비되는 솔루션 공간의 리소스가, 예를 들어, 솔루션 서브공간이 재우선순위화될 때까지 데이터를 캐싱 계층 밖으로 이동시키는 것에 의해, 자동으로 할당해제될 수 있다. 게다가, 리소스가 덜 중요한 함수 또 는 작업으로부터 신속하게 할당해제되고 다른 더 높은 우선순위의 작업 또는 스포닝된 함수에 할당될 수 있도록, 스포닝된 함수의 취소가 자동으로 생성될 수 있다. 일부 예에서, 스포닝된 함수에서 하나의 반복으로부터의 데이터(및 이벤트)가 로컬로 발생할 수 있거나 그렇지 않을 수 있는 스포닝된 함수(또는 다른 스포닝된 함수)의 다른 반복으로 자동으로 이동될 수 있는 유연한 멀티 캐스팅 토폴로지가 구현된다. 따라서, 이 토폴로지는 효율적인 통신 전략이 스포닝된 함수를 취소하거나 재우 선순위화할 수 있게 한다. 게다가, 일부 실시예는 네트워크 함수 가상화 성능 수요를 충족시키기 위해 다양한 포인트-투-포인트 능력을 일 반화하는 향상된 멀티캐스팅 토폴로지를 가질 수 있다. 예를 들어, 일부 실시예는, 스포닝된 함수 및 태스크가 인프라스트럭처의 한 부분에서 스포닝되고 인프라스트럭처의 다른 부분에서 취소될 때, 통신 토폴로지가 낮은 통신 오버헤드로 적응하도록 유연한 멀티캐스팅 토폴로지를 구현할 수 있다. 예를 들어, 에지 컴퓨팅에서 요청 하는 모바일 클라이언트 또는 모바일 타깃(예를 들면, 기지국 또는 소비자 구내 장비)이 위치를 변경함에 따라, 일부 실시예는 대응하는 스포닝된 반복 함수를 재배포하기 위해 효율적인 방식으로 상이한 노드들, 컨테이너들 등 사이의 멀티캐스팅 배열을 수정할 수 있다. 예를 들어, 일부 실시예에서, 스케줄러는 모바일 클라이언트 및/또는 모바일 타깃의 위치를 식별할 수 있 다. 모바일 클라이언트 및/또는 모바일 타깃이 위치를 변경할 때, 스포닝된 함수의 반복 실행은 모바일 클라이 언트 및/또는 타깃으로부터 미리 결정된 거리 내에 유지되도록 상이한 컨테이너 및/또는 노드로 이동될 수 있다. 그렇게 하는 것은 통신 레이턴시를 감소시킬 수 있으며, 위에서 설명된 유연한 멀티캐스팅 인프라스트럭 처를 통해 달성될 수 있다. 게다가, 스케줄러가 스포닝된 함수의 실행, 리소스 할당, 및 취소를 제어할 수 있도록, 스케줄러는 컨테이너 및/또는 노드를 인식할 수 있다. 더욱이, 메타 프로그램을 실행하기 위 한 능력이, 하드웨어 큐 관리자(들)와 같은, 하드웨어로 추가로 이동될 수 있으며, 스포닝된 함수가 더 신속하 게 실행되고, 필요할 때, 효율적으로 취소될 수 있도록, 플랫폼 소프트웨어에 제공될 수 있다. 하드웨어 큐 관 리자의 실시예는, 요청된 동작이 적용 가능한 보안 정책을 위반하지 않고 수행될 수 있음을 확인한 후에 그리고, 임의로, 제1 요청 엔티티가 동작이 제2 엔티티에서 완료될 때까지 기다리도록 강제하지 않으면서, 복수 의 엔티티 중 제1 엔티티(예를 들면, 엔티티는 태스크, 프로세스, 컨테이너, 가상 머신 등일 수 있음)로부터 제 어 동작 또는 동작에 대한 데이터 이동 요청을 수신하고 복수의 엔티티 중 제2 엔티티(예를 들면, 다른 태스크, 다른 프로세스, 다른 컨테이너, 다른 가상 머신 등)에서 요청된 동작을 수행할 수 있는 플랫폼 하드웨어 특징이 다. 도 18c는 FaaS 함수 구현 방법을 도시하며, 도 13a의 서버에 의해 실행될 수 있지만, 또는 서버 와 협력하여, 도 4의 향상된 FaaS 시스템 및/또는 도 18b의 스케줄러, 또는 하나 이상의 모듈 에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로도 구현될 수 있 다. 예시된 프로세싱 블록은 실행되어야 하는 복수의 함수를 식별할 수 있다. 복수의 함수는 반복적으로 실 행될 수 있다. 예시된 프로세싱 블록은 우선순위해제 조건이 식별되는 것에 응답하여 복수의 함수 중 하 나 이상의 함수를 우선순위해제할 수 있다. 예를 들어, 예시된 프로세싱 블록은 우선순위해제 조건이 식 별되는 것에 응답하여 복수의 함수 중 하나 이상의 함수의 실행을 취소한다. 예시된 프로세싱 블록은 또 한 우선순위해제 조건이 식별되는 것에 응답하여 복수의 함수 중 하나 이상의 함수의 리소스 할당을 감소시킬 수 있다. 예시된 프로세싱 블록은 우선순위해제 조건이 식별되는 것에 응답하여 우선순위해제되지 않는 복수의 함수 중 하나 이상의 함수에 대한 리소스 할당을 증가시킬 수 있다. 방법은 덜 성공적인 솔루션 공간, 예를 들어, 복수의 함수 중 하나 이상의 함수에 대한 리소스 할당을 종 료 및/또는 감소시킴으로써 위에서 설명된 바와 같이 레이턴시를 감소시키고 향상된 리소스 관리를 가질 수 있 다. 예를 들어, 리소스는 예시된 프로세싱 블록과 관련하여 설명된 바와 같이 우선순위해제 조건의 식별 에 응답하여 효율적으로 할당해제된다.추가 비고 및 예 예 1800은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 실행되어야 하는 복수의 함수를 식별 하게 하고, 우선순위해제 조건이 식별되는 것에 응답하여 복수의 함수 중 하나 이상의 함수를 우선순위해제하게 하며, 우선순위해제 조건이 식별되는 것에 응답하여, 복수의 함수 중 하나 이상의 함수의 리소스 할당을 감소시 키게 하거나 또는 복수의 함수 중 하나 이상의 함수의 실행을 취소하게 하고, 우선순위해제되지 않는 복수의 함 수 중 하나 이상의 함수에 대한 리소스 할당을 증가시키게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 복수의 함수의 함수는 반복적으로 실행되어야 한다. 예 1801은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 실행되어야 하는 복수의 함수를 식별 하게 하고, 우선순위해제 조건이 식별되는 것에 응답하여 복수의 함수 중 하나 이상의 함수를 우선순위해제하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 1802는 예 1801의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 우선순위해제 조건이 식별되는 것에 응답하여 복수의 함수 중 하나 이상의 함수의 실행 을 취소하게 하는 추가 명령어 세트를 포함한다. 예 1803은 예 1802의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 우선순위해제 조건이 식별되는 것에 응답하여 복수의 함수 중 하나 이상의 함수의 리소 스 할당을 감소시키게 하는 추가 명령어 세트를 포함한다. 예 1804는 예 1801의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 복수의 함수의 함수는 반복적으 로 실행되어야 한다. 예 1805는 예 1801의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 우선순위해제되지 않는 복수의 함수 중 하나 이상의 함수에 대한 리소스 할당을 증가시 키게 하는 추가 명령어 세트를 포함한다. 공통 데이터 스토리지를 갖는 향상된 FaaS 아키텍처 FaaS 환경에서의 통신 레이턴시는 상당한 오버헤드를 제공할 수 있다. 예를 들어, 일부 FaaS 환경은 수천개의 함수를 포함할 수 있으며, 대응하는 데이터는 장기 저장 및/또는 실행을 위해 노드들 간에 전달된다. 더욱이 함수는 \"무상태(stateless)\"로 간주될 수 있다. 그와 같이, 데이터를 생성하는 함수의 실행 후에도 존속하는 데이터를 저장하는 것은 특정 문제를 야기할 수 있다. 일부 실시예는 향후 재사용을 위해 그러한 데이터를 캐 싱하는 것을 향상시킨다. 예를 들어, 노드일 수 있는 데이터베이스 서버를 고려한다. 노드(데이터베이스 서버)는 함수를 실행하는 실행 노드에 대해 원격일 수 있다. 데이터베이스 서버는 함수가 실행을 위해 활용할 수 있는 데이터를 저장할 수 있 다. 실행 노드로부터, 원격 데이터베이스 서버에 대한 데이터 액세스는 비용이 많이 들 수 있으며, 그와 같이 데이터가 실행 노드로 이동되거나 실행 노드에 근접해 있을 수 있다. 그러한 데이터 전송은, 특히 데이터의 성 질 및 크기에 따라, 고 레이턴시이고 리소스 집약적일 수 있다. 예를 들어, 왔다갔다하는 낭비적인 입/출력이 초래될 뿐만 아니라 데이터의 자연스러운 포맷이 보관중(at-rest) 코딩 포맷으로부터 사용중(in-use) 코딩 포맷 으로 그리고 그 반대로 수정될 수 있다. 따라서, 마샬링 비용이 증가되고 데이터에 대한 보관중 코딩 포맷과 사용중 코딩 포맷 간에 변경하기 위한 비용이 증가된다. 이제 도 19a를 살펴보면, 공통 데이터 스토리지를 갖는 향상된 FaaS 아키텍처가 예시된다. 예는 도 4의 향상된 FaaS 시스템을 포함할 수 있다. 일부 실시예는 하나 이상의 함수에 의한 재사용을 위해 데 이터를 저장하기 위해 공통 데이터 스토리지(임시 데이터 스토리지일 수 있음)의 활용을 통해 효율성을 향상시킬 수 있다. 예를 들어, 함수 F1은 다른 함수에 의해 사용될 공통 데이터를 생성할 수 있다. 공통 데이 터는 공통 데이터 스토리지에 저장될 수 있다. 함수 F1이 실행을 완료한 후에, 공통 데이터는 공통 데이 터 스토리지에 저장된 채로 있을 수 있다. 그 후에, 함수 F2와 같은 다른 함수가 실행을 시작하고 공통 데이터에 액세스할 수 있다. 예를 들어, 제1 함수 F1이 실행을 완료한 후에 함수 F2가 실행을 시작하는 경우, 함수 F2는, 공통 데이터 스토리지에 근접해 있고 그리고/또는 이를 포함하는 실행 노드와 같은, 노 드에 인스턴스화될 수 있다. 따라서, 공통 데이터는, 축출되지 않고, 공통 데이터 스토리지에 남아있을 수 있다. 또한 공통 데이터의 포맷은 보안 이유로 암호화될 수 있지만, 그렇지 않고 변경되지 않을 수 있다. 따라서, 상기 구현은 IO 전송 및 데이터 코딩 포맷 수정을 감소시켜, 레이턴시를 감소시키고 리소스 사용량을 향상시킬 수 있다. 제어 노드는, 프로세스에 의해 표시된 바와 같이, 시간 T0에서 함수 F1을 호출할 수 있다. 함수 F1 은 노드에서 실행될 수 있다. 노드는 로컬 데이터 스토리지와 통신할 수 있다. 일부 실시 예에서, 로컬 데이터 스토리지는 실행 노드의 일부일 수 있다. 일부 실시예에서, 로컬 데이터 스 토리지 및 실행 노드는 서버와 같은 동일한 컴퓨팅 디바이스의 일부이다. 예시된 바와 같이, 로컬 데이터 스토리지는, 공통 데이터 스토리지 및 특정 데이터 스토리지를 포함하는, 적어도 2개 의 데이터 스토리지 또는 파티션을 포함한다. 함수 F1이 실행 노드의 컨테이너에서 실행될 때 함수 F1은 데이터를 생성할 수 있다. 데이터 중 적어도 일부는 공통 데이터라고 지칭될 수 있다. 공통 데이터는 다른 함수에 의해 재사용될 수 있다. 예를 들어, 제 어 노드는, 도 18a의 함수 생성 그래프와 같은, 함수 생성 그래프를 생성할 수 있다. 일부 실시예 에서, 제어 노드의 동작은 프로그래머 또는 클라우드 서비스 제공자로부터 수신된 지시문에 의해 임의로 안내될 수 있다. 제어 노드는 함수 생성 그래프를 분석하여 함수의 상호 종속성, 예를 들어, 함수가 다 른 함수에 의해 생성된 데이터에 기초하여 동작해야 하는지를 결정할 수 있다. 제어 노드는 데이터가 공 통 데이터 스토리지 또는 특정 데이터 스토리지에 저장되는지를 제어할 수 있다. 일부 실시예에서, 데이터가 공통 데이터 스토리지 또는 특정 데이터 스토리지에 저장되는지에 대한 결정 은 프로그래머 또는 클라우드 서비스 제공자로부터의 추가 입력(예를 들면, 힌트, 지시문 등)의 영향을 받을 수 있고, 프로그래머 또는 클라우드 서비스 제공자는 때때로 이러한 입력(예를 들면, 힌트 또는 지시문)을 변경할 수 있다. 일부 실시예에서, 제어 노드는 함수 F2가 함수 F1에 의해 생성된 데이터를 소비할 것이라고 결정할 수 있 다. 따라서, 제어 노드는 함수 F1 에 의해 생성된 데이터의 적어도 일부가 공통 데이터라는 커맨드 또는 메시지를 실행 노드에 전달할 수 있다. 예를 들어, 함수 F1이 T0에서 호출될 때, 제어 노드는 함수 F1에 의해 생성된 데이터를 공통 데이터로서 저장하도록 실행 노드에 지시할 수 있다. 일부 실시예에서, 함수 F1의 데이터의 전부가 아니라, 함수 F1의 데이터의 서브세트(예를 들면, 최종 계산 또는 결론 데이터)만이 공통 데이터로 간주될 수 있다. 데이터의 서브세트는 함수 F2에 의해 사용 가능한 것으로 식별되는 데이터일 수 있다. 함수 F2에 의해 사용 가능하지 않은 것으로 식별된 다른 데이터는 폐기될 수 있다. 실행 노드는 함수 F1을 인스턴스화하고, 공통 데이터 스토리지로부터의 데이터 스토리지를 할당할 수 있다. 함수 F1은 따라서 프로세스에 의해 표시된 바와 같이 공통 데이터를 공통 데이터 스토리지 에 저장할 수 있다. 함수 F1이 실행을 완료한 후에, 공통 데이터를 제어 노드에 송신하기보다는, 공통 데이터는 공통 데이터 스토리지에 남아 있을 수 있다. 예를 들어, 공통 데이터를 공통 데이터 스토 리지로부터 즉각 제거하기보다는, 공통 데이터가 공통 데이터 스토리지에 저장된 채로 있을 수 있 다. 공통 데이터는 공통 데이터에 대한 생존 시간을 기술하는 생존 시간 정책을 제공받을 수 있다. 생존 시간은 다 른 함수가 공통 데이터에 액세스하는 것에 의해 연장될 수 있다. 생존 시간은, 새로운 함수가 공통 데이터에 액세스할 때마다, 고정된 양만큼(또는 과거 이력에 기초하여 정책 또는 휴리스틱스로부터 결정되는 바와 같은 가변 양만큼) 연장될 수 있다. 일부 실시예에서, 공통 데이터는 최대 생존 시간을 적용받을 수 있으며, 최대 생존 시간 이후에 공통 데이터는 적어도 공통 데이터 스토리지로부터 자동으로 축출되고, 추가로 로컬 데 이터 스토리지로부터 축출될 것이다. 함수 F1이 실행을 완료한 후에 공통 데이터가 액세스되지 않은 채 로 있는 경우, 생존 시간이 만료된 후에 그리고 생존 시간에 대한 어떠한 조정도 없이 공통 데이터가 제어 노드 로 축출될 수 있다. 로컬 데이터 스토리지 및/또는 실행 노드는 생존 시간 정책을 시행할 수 있다. 일부 실시예에서, 생존 시간 정책은 보안 요구사항에 대해 균형을 이룰 수 있다. 예를 들어, 로컬 데이터 스토 리지가 물리적 침입을 통해 쉽게 손상될 수 있는 에지 디바이스에 유지되는 경우, 생존 시간은 낮은 값으 로 설정될 수 있다. 게다가, 공통 데이터가 높은 보안 요구사항을 갖는 경우, 생존 시간은 낮은 값으로 설정될수 있다. 게다가, 함수 F1 및/또는 로컬 데이터 스토리지는 공통 데이터를 암호화할 수 있다. 그렇게 함으로써, 공 통 데이터가 인가된 함수에 의해서만 액세스될 수 있도록 보안이 향상될 수 있다. 함수 F1, 실행 노드, 및/또는 로컬 데이터 스토리지는 공통 데이터가 어디에 저장되어 있는지 및 공통 데이터가 암호화되어 있는지를 기술하는 디스크립터(고유 식별자 등)를 생성할 수 있다. 게다가, 보안 목 적으로 공통 데이터가 암호화된 경우, 디스크립터는 공통 데이터에 액세스하기 위한 복호화 프로토콜을 포함할 수 있다. 예를 들어, 디스크립터는 공통 데이터를 복호화하기 위한 복호화 키를 포함할 수 있다. 디스크립터 는 제어 노드에 제공될 수 있으며, 제어 노드는, 적절한 경우, 디스크립터를 다른 함수에 전달할 수 있다. 함수 F1이 실행을 완료한 후에, 제어 노드는, 프로세스에 의해 표시된 바와 같이, 시간 T2에서 함수 F2를 호출할 수 있다. 실행 노드는 함수 F2를 실행할 수 있다. 함수 F2는 함수 F1에 의해 저장된 공통 데이터의 디스크립터를 수신할 수 있다. 디스크립터는 공통 데이터의 위치는 물론 임의의 적절한 복호화 프로 토콜을 정확하게 기술할 수 있다. 함수 F2는, 프로세스에 의해 표시된 바와 같이, 공통 데이터 스토리지 에 저장된 공통 데이터에 액세스하고, 공통 데이터에 기초하여 실행될 수 있다. 따라서, 공통 데이터의 생존 시간이 증가될 수 있다. 액세스는 함수 F2가 공통 데이터를 판독하고, 새로운 공통 데이터를 공통 데이터 에 추가하며 그리고/또는 공통 데이터를 덮어쓰기할 수 있다는 것을 의미한다. 위에서 설명된 바와 같이, 공통 데이터가 액세스되기 때문에, 공통 데이터의 생존 시간은 미리 정의된 값만큼 연장된다. 일부 실시예에서, 생 존 시간 대신에 또는 그에 추가하여, 함수 F2가 그의 완료에 도달하지 않은 동안 공통 데이터의 조기 축출을 방 지하기 위해 기준 카운트가 사용될 수 있다. 함수 F2는 또한 함수 F2만이 사용할 특정 데이터를 생성할 수 있다. 특정 데이터는, 프로세스에 의해 표 시된 바와 같이, 특정 데이터 스토리지와 같은, 공통 데이터 스토리지와 별개의 파티션에 저장될 수 있다. 프로세스에 의해 예시된 바와 같이, 특정 데이터는 함수 F2가 실행을 완료할 때 특정 데이터 스토리지로부터 자동으로 축출될 수 있다. 프로세스에 의해 표시된 바와 같이, 함수 F2는 T1(T1의 호출 시간) 이후 그러나 함수 F3이 T2에서 호출되기 전의 시간에서 실행을 완료할 수 있다. 함수 F2에 의해 생성된 특정 데이터는, F2에 전용된 리소스가 회수될 때, 프로세스에 의해 표시된 바와 같이, 제어 노드로 자동으로 축출될 수 있다. 제어 노드 는 특정 데이터를 장기 스토리지에 저장함이 없이 특정 데이터를 포기할 수 있거나, 또는 특정 데이터를 데이터 베이스 노드에 저장할 수 있다. 그와 같이, 공통 데이터 스토리지는 함수 F1과 함수 F2 사이에서 데이터를 전달하기 위한 임시 스토리지를 제공할 수 있다. 그렇게 하는 것은 함수 F1에 의해 생성된 데이터를 공통 데이터 스토리지에 저장함으로 써 데이터베이스 액세스(판독/기입)를 데이터베이스 노드로 제한할 수 있다. 게다가, 도 19a에 예시된 향상된 FaaS 아키텍처는 로컬 데이터 스토리지와 제어 노드 사이에서 더 적은 데이터가 전달되기 때문에 향상된 리소스 관리 프로토콜을 가질 수 있고, 함수 F2의 레이턴시를 추가로 감소시킨다. 예를 들어, 감 소된 데이터 이동 및 입/출력 대역폭으로 인해, 함수 F2는 공통 데이터의 데이터 전송을 기다리지 않으면서 더 적은 오버헤드로 실행을 시작할 수 있다. 공통 데이터 스토리지는 함수 F2에 의한 액세스를 가능하게 하는 실행 노드의 로컬 페이지 캐시일 수 있다. 상세하게는, 함수 F2는 실행 노드에서 실행되고, 따라서 편리한 방식으로 실행 노드의 로컬 페이지 캐시에 액세스할 수 있다. 일부 실시예에서, 데이터 스토리지는 스토리지 캐시(파일 또는 블록 캐시), 임시 키 값 저장소 또는 페이지 캐시와 블록 캐시의 어떤 조합을 사용하는 문서 저장소 등일 수 있 다. 제어 노드는, 프로세스에 의해 예시된 바와 같이, 시간 T2에서 함수 F3을 호출할 수 있다. 함수 F3 이 실행 노드에서 실행을 시작하고 특정 데이터를 생성한다. 특정 데이터는 프로세스에 의해 특정데이터 스토리지에 저장될 수 있다. 함수 F3이 실행을 완료한 후에 또는 함수 F3에 대한 컨테이너가 해체 되거나 회수되는 경우, 특정 데이터는 프로세스에 의해 축출될 수 있고, 제어 노드에 의해 폐기되 거나 데이터베이스 노드에 저장될 수 있다. 함수 F3은 공통 데이터 스토리지에 저장된 공통 데이터에 액세스할 수 없다. 그와 같이, 공통 데이터의 생존 시간은 연장되지 않을 수 있고, 만료될 수 있다. 따라서, 프로세스는 함수 F2가 완료된 후 미리 결 정된 시간에 공통 데이터를 축출할 수 있다. 상세하게는, 공통 데이터는 공통 데이터 스토리지로부터 축 출되어 제어 노드로 송신될 수 있다. 제어 노드는 공통 데이터를 사용중 코딩 포맷으로부터 보관 중 코딩 포맷으로 수정하고, 이어서 프로세스에서 공통 데이터를 데이터베이스 노드에 저장할 수 있다. 데이터베이스 노드는 장기 스토리지일 수 있다. 공통 데이터는 또한 로컬 데이터 스토리지(190 6)에 의해 보관중 코딩 포맷으로 수정될 수 있다. 일부 실시예에서, 함수 F1, F2, F3에 의해 생성된 데이터는 데이터의 잠재적 재사용에 대한 참조 없이 공통 데이 터 스토리지에 저장될 수 있다. 따라서, 제어 노드는 함수 F1, F2, F3 중 어느 것이다른 함수 F1, F2, F3에 의해 사용될 수 있는 데이터를 생성할 수 있는지를 결정하기 위해 함수 그래프를 분석하지 않을 수 있 다. 오히려, 각각의 함수 F1, F2, F3은 생성된 데이터를 공통 데이터 스토리지에 저장할 수 있다. 데이 터는 위에서 설명된 바와 유사하게 취급될 수 있고, 대응하는 생존 시간이 만료된 후에 암호화되어 공통 데이터 스토리지로부터 축출될 수 있다. 도 19b는 하나 이상의 FaaS 함수에 의해 생성된 공통 데이터 스토리지를 사용하는 방법을 도시하며, 도 4 의 향상된 FaaS 시스템 및/또는 하나 이상의 모듈에 의해 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같 은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하 드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은, 제1 함수의 실행 동안, 함수와 연관된 제1 데이터를 데이터 스토리지에 저장할 수 있으며, 여기서 제1 데이터는 하나 이상의 다른 함수에 의해 사용될 것이다. 예를 들어, 제1 데이터는 데이 터 스토리지의 캐시에 저장될 수 있으며, 여기서 데이터 스토리지는 하나 이상의 다른 함수에 의해 액세스 가능 하다. 예시된 프로세싱 블록은, 제1 함수가 종료된 후에, 제1 함수의 제1 데이터를 데이터 스토리지에 유지할 수 있다. 예를 들어, 제1 함수가 실행을 완료했다는 식별에 응답하여 제1 데이터가 축출되지 않을 수 있다. 예시된 프로세싱 블록은, 제2 함수의 실행 동안, 제2 함수가 데이터 스토리지에 저장된 제1 데이 터에 액세스할 수 있게 할 수 있다. 예를 들어, 제2 함수는 제1 데이터의 위치를 나타내는 디스크립터, 및 제1 데이터에 액세스하는 데 필요한 임의의 보안 프로토콜을 수신할 수 있다. 데이터를 참조하는 디스크립터를 생 성하는 임의의 방법이 사용될 수 있다. 예를 들어, 디스크립터는 참조될 데이터가 특정 위치에 저장되어 있다 는 표시를 포함할 수 있고, 데이터가 저장될 때 (예를 들면, 메모리 제어기에 의해) 생성될 수 있다. 디스크립 터는 제1 데이터와 연관된 메타데이터의 위치를 추가로 포함하거나 표시할 수 있으며, 여기서 메타데이터는 제1 데이터가 암호화된 경우 제1 데이터를 복호화하기 위한 적용 가능한 복호화 키, 제1 데이터 핑거프린팅된 경우 제1 데이터를 검증하기 위한 적용 가능한 검증 코드, 제1 데이터가 압축된 경우 제1 데이터를 압축해제하기 위 한 압축해제 코드 등을 포함해야 한다. 따라서, 제1 및 제2 함수가 데이터 스토리지에 액세스하는 동안 제1 데 이터는 데이터 스토리지에 저장될 수 있다. 위에서 설명된 바와 같이, 그렇게 하는 것은 I/O 동작, 데이터 전 송 및 데이터 수정을 감소시킴으로써 레이턴시를 감소시키고 리소스 관리를 향상시킬 수 있다. 예시된 프로세싱 블록은 제1 데이터가 데이터 스토리지에서 액세스되지 않는 시간 기간을 결정할 수 있다. 예시된 프로세싱 블록은 시간 기간이 제1 데이터의 생존 시간 임계치를 충족시키는지를 결정할 수 있다. 만약 그렇지 않다면, 예시된 프로세싱 블록은 제1 데이터가 액세스되지 않는 시간 기간을 결정하 기 위해 반복될 수 있다. 생존 시간 임계치가 충족될 때, 예시된 프로세싱 블록은 제1 데이터를 데이터 스토리지로부터 축출할 수 있다. 제1 데이터의 축출은 제1 데이터가 저장된 메모리를 할당해제하는 것, 및/또 는 제1 데이터를 데이터 스토리지로부터 소거하는 것을 포함할 수 있다. 예시된 프로세싱 블록은 제1 데 이터를 제2 데이터 서버에 저장할 수 있다. 제2 데이터 서버는 장기 데이터베이스 저장 서버일 수 있다. 도 19c는 FaaS 보안 프로토콜을 구현 및 시행하는 방법을 도시하며, 도 4의 향상된 FaaS 시스템 및/ 또는 하나 이상의 모듈에 의해 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들 어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 제1 함수에 의해 생성된 데이터가 다른 함수에 의한 액세스를 위해 공통 데이터 스토리지에 저장될 것이라고 결정할 수 있다. 예시된 프로세싱 블록은 제1 함수가 실행을 완료한 후에 제1 데이터가 암호화되도록 제1 데이터를 암호화할 수 있다. 예시된 프로세싱 블록은 제2 함수가 제1 데 이터에 액세스할 수 있다고 결정할 수 있다. 예를 들어, 예시된 프로세싱 블록은 제2 함수의 보안 인가, 제2 함수 인스턴스화의 출처(예를 들면, 제2 함수의 실행을 요청하는 서버, 서비스 또는 클라이언트), 제2 함수 의 멀웨어 분석, 및/또는 제2 함수가 제1 데이터와 호환되는지를 식별할 수 있다. 예시된 프로세싱 블록(197 8)은 제2 함수가 제1 데이터에 액세스할 수 있게 하기 위해 제1 데이터를 복호화할 수 있다. 블록에서의 암호화 및/또는 블록에서의 복호화는 알려진 기술에 의해(예를 들면, 암호화 및 복호화 키를 통해), 향상 된 FaaS 시스템에서의 하드웨어 및/또는 소프트웨어를 사용하여 및/또는 하드웨어와 소프트웨어 방법의 조 합을 사용하여 수행될 수 있다. 따라서, 방법은 멀웨어 또는 서드파티가 데이터에 액세스할 가능성을 감 소시키기 위해 보안을 향상시킬 수 있다. 추가 비고 및 예 예 1900은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 제1 함수의 실행 동안, 제1 함수와 연관된 제1 데이터를 데이터 스토리지에 저장하게 하고 - 제1 데이터는 데이터 스토리지의 캐시에 저장되어야 함 -, 제1 함수가 종료된 후에, 제1 함수의 제1 데이터를 데이터 스토리지에 유지하게 하며, 제2 함수의 실행 동안, 제2 함수가 데이터 스토리지에 저장된 제1 데이터에 액세스할 수 있게 하고, 제1 데이터가 데이터 스토리 지에서 액세스되지 않는 시간 기간을 결정하게 하며, 시간 기간이 제1 데이터의 생존 시간 임계치를 충족시키는 지를 결정하게 하고, 시간 기간이 생존 시간 임계치를 충족시킬 때 제1 데이터를 데이터 스토리지로부터 축출하 게 하며, 시간 기간이 생존 시간 임계치를 충족시키는 것에 응답하여, 제1 데이터를 제2 데이터 서버에 저장하 게 하고, 디스크립터를 제2 함수에 전달하게 하며 - 디스크립터는 제1 데이터의 위치를 나타내고, 추가로 제1 데이터와 연관된 메타데이터의 위치를 나타내며, 메타데이터는 제1 데이터가 암호화된 경우 제1 데이터를 복호 화하기 위한 적용 가능한 복호화 키, 제1 데이터 핑거프린팅된 경우 제1 데이터를 검증하기 위한 적용 가능한 검증 코드, 또는 제1 데이터가 압축된 경우 제1 데이터를 압축해제하기 위한 압축 해제 코드 중 하나 이상을 포 함함 -, 제1 함수가 실행을 완료한 후에 제1 데이터가 암호화되도록 제1 데이터를 암호화하게 하고, 제2 함수가 제1 데이터에 액세스할 수 있게 하기 위해 제1 데이터를 복호화하게 하는 명령어 세트를 포함하는 적어도 하나 의 컴퓨터 판독 가능 매체를 포함한다. 예 1901은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 제1 함수의 실행 동안, 제1 함수와 연관된 제1 데이터를 데이터 스토리지에 저장하게 하고, 제1 함수가 종료된 후에, 제1 함수의 제1 데이터를 데 이터 스토리지에 유지하게 하며, 제2 함수의 실행 동안, 제2 함수가 데이터 스토리지에 저장된 제1 데이터에 액 세스할 수 있게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 1902는 예 1901의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 데이터가 데이터 스토리지에서 액세스되지 않는 시간 기간을 결정하게 하는 추가 명령어 세트를 포함할 수 있다. 예 1903은 예 1902의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 시간 기간이 제1 데이터의 생존 시간 임계치를 충족시키는지를 결정하게 하고, 시간 기 간이 생존 시간 임계치를 충족시킬 때 제1 데이터를 데이터 스토리지로부터 축출하게 하는 추가 명령어 세트를 포함한다. 예 1904는 예 1903의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 시간 기간이 생존 시간 임계치를 충족시키는 것에 응답하여, 제1 데이터를 제2 데이터 서버에 저장하게 하는 추가 명령어 세트를 포함한다. 예 1905는 예 1901의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 제1 데이터는 데이터 스토리지 의 캐시에 저장되어야 한다. 예 1906은 예 1901의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 디스크립터를 제2 함수에 전달하게 하는 추가 명령어 세트를 포함하며, 여기서 디스크립터는 제1 데이터의 위치를 나타내고, 추가로 제1 데이터와 연관된 메타데이터의 위치를 나타내며, 여기서 메 타데이터는 제1 데이터가 암호화된 경우 제1 데이터를 복호화하기 위한 적용 가능한 복호화 키, 제1 데이터 핑 거프린팅된 경우 제1 데이터를 검증하기 위한 적용 가능한 검증 코드, 또는 제1 데이터가 압축된 경우 제1 데이 터를 압축해제하기 위한 압축 해제 코드 중 하나 이상을 포함한다. 예 1907은 예 1901의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 함수가 실행을 완료한 후에 제1 데이터가 암호화되도록 제1 데이터를 암호화하게 하고, 제2 함수가 제1 데이터에 액세스할 수 있게 하기 위해 제1 데이터를 복호화하게 하는 추가 명령어 세트를 포함한다. 서비스형 함수 환경은 레이턴시와 리소스 오버헤드 간의 트레이드오프를 가질 수 있다. 콜드 컨테이너를 프로 비저닝하는 것은 대규모 고 레이턴시 데이터 전송은 물론, 데이터에 기초한 컨테이너의 구성을 포함할 수 있다. 따라서, 콜드 컨테이너를 프로비저닝하는 것은 고 레이턴시 동작일 수 있다. 이와 달리, 상기 데이터 전송 및 구성이 방지될 수 있기 때문에 웜 컨테이너를 유지하는 것은 저 레이턴시 동작일 수 있다. 웜 컨테이너를 유지 하는 것은 긴 시간 기간 동안 유휴인 채로 유지되고 상당한 메모리 풋프린트를 가지는 과도한 컴퓨트 리소스를 소비할 수 있다. 예를 들어, 웜 컨테이너는 함수가 실행되기를 기다리는 동안 이용되지 않고 유휴인 채로 유지 될 수 있다. 게다가, 웜 컨테이너는, 유휴인 채로 유지되고 그러한 함수를 기다리는 동안, 도착 함수를 실행할 상당한 리소스 할당을 가질 수 있다. 상이한 모드를 갖는 향상된 FaaS 서버 아키텍처 도 20a는 서버가 FaaS 관리 로직(2006a)을 포함하는 스마트 네트워크 인터페이스 카드(NIC)를 포함 하는 향상된 FaaS 서버 아키텍처를 도시한다. 다른 실시예에서, 로직(2006a)은 서버 아키텍처에서 하드웨어로서, 예를 들어, 프로세서에, 베이스보드 관리 제어기에, 가속기에, 및/또는 FPGA 등에 구현될 수 있 다. 서버는 FaaS 관리 로직(2006a)과 협력하여 및/또는 FaaS 관리 로직(2006a)과 조율하여 동작하는 FaaS 관리 로직(2006b)을 추가로 포함할 수 있다. FaaS 관리 로직(2006b)은 서버의 OS 드라이버 또는 스마트 미들웨어일 수 있다. FaaS 관리 로직(2006a, 2006b)은 FaaS 서버 아키텍처가 전용 FaaS 관련 데 이터/객체에 대해 더 많은 메모리 리소스를 사용함으로써 증가하는 FaaS 워크로드에 적응하도록 캐싱 정책의 변 경을 수행할 수 있다. 일부 실시예에서, 서버는 둘 다가 아니라 FaaS 관리 로직(2006a, 2006b) 중 하나 만을 포함할 수 있다. 따라서 예를 들어, FaaS 관리(2006b)만이 캐싱 정책을 변경하는 데 포함될 수 있다. 그 러한 변경은, 예를 들어, 범용 또는 특수 목적 프로세서에서 구현된 캐싱 정책을 제어하는 하나 이상의 구성 레 지스터를 프로그래밍하는 것에 의해 수행될 수 있다. 전용 캐싱은 페이지 캐시와 같은 소프트웨어 관리 리소스 에도 적용될 수 있으며; 따라서 운영 체제 및 런타임 소프트웨어는 물리 페이지 풀을 적어도 2개의 서브풀로 세 분화할 수 있다: 하나는 일반용이고 하나는 전용 FaaS 용이며, 시스템이 전용 FaaS 모드, 범용 모드 또는 하이 브리드 모드에서 동작해야 하는지에 따라 서브풀에 대해 상이한 크기를 갖는다. 그와 같이, 도 20a 내지 도 20d와 관련하여 사용되는 바와 같은 캐시는 소프트웨어 리소스 캐시 및 하드웨어 캐시 둘 모두를 포함할 수 있 다. 소프트웨어 리소스 캐시와 하드웨어 캐시 둘 모두가 기본 메모리에 대한 (직접적 또는 간접적) 액세스를 반영해야 한다는 점이 이해될 것이다. FaaS 관리 로직(2006a, 2006b)은, 전용 FaaS 모드, 범용 모드 및 하이브리드 FaaS 모드를 포함한, 3개 이상의 상이한 모드에서 서버를 동작시킬지를 결정할 수 있다. 도 20a에 예시된 실시예에서, 서버는 하이 브리드 FaaS 모드에 있다. 하이브리드 FaaS 모드에서는, 캐시(2008, 2010, 2012) 중 일부만이 전용 FaaS 모드 에 배치되는 반면, 나머지는 범용 모드에 배치된다. 전용 FaaS 모드에서, 캐시(2008, 2010, 2012) 각각은 FaaS 모드에 전용되어 있다. 캐시(2008, 2010, 2012)는 소프트웨어 리소스 캐시와 하드웨어 캐시 둘 모두를 포함할 수 있다. 서버 아키텍처는 플랫폼(예를 들면, 서버)에 대한 하이브리드 및 전용 FaaS 모드를 통해 레이턴시와 리소 스 고려사항의 균형을 맞출 수 있다. 하이브리드 FaaS 모드에서는, 하나 이상의 함수와 연관된 데이터 객체만 을 저장하기 위해, 전용 FaaS 캐시(2008, 2010)와 같은, 하나 이상의 캐시가 사용될 수 있다. 대안적으로, 전 용 FaaS 캐시(2008 또는 2010)는 하나 이상의 함수와 연관된 데이터 객체가 더 큰 캐시 레지던시(cache residency)를 부여받도록 \"소프트 우선순위\"를 구현할 수 있다. 그러한 캐시 레지던시 조정은, 예를 들어, 일 반 애플리케이션에 의해 캐싱된 것과 비교하여 FaaS 함수에 의해 캐싱된 데이터에 대해 상이한 에이징 정책을 이용하는 것을 통해 실행될 수 있다. 따라서, 일부 실시예에서, 전용 FaaS 캐시(2008, 2010)는 FaaS 데이터 객 체가 전용 FaaS 캐시(2008, 2010)에 저장될 가능성이 더 높도록 비-FaaS 데이터보다 FaaS 데이터 객체를 우선순위화할 수 있다. 일부 실시예에서, 전용 FaaS 캐시(2008, 2010)는 컨테이너를 구성하기 위해 데이터의 적어도 일부를 저장할 수 있다. 일부 실시예에서, 전용 FaaS 캐시(2008, 2010)는 컨테이너를 초기화하는 데 필요한 컨 테이너의 데이터를 저장하는 데 전용될 수 있다. 일부 실시예는, 상이한 노드들 사이의 데이터 전송이 방지될 수 있고 컨테이너 구성이 로컬로 캐싱된 데이터에 기초하여 시작될 수 있기 때문에, 콜드 컨테이너 초기화에 대한 레이턴시를 감소시킬 수 있다. 즉, 컨테이너 및 함수 초기화가 가속화될 수 있다. 아래에서 설명되는 바와 같이, 함수의 초기화는 컨테이너의 구성 및 컨테 이너에서 함수의 실행을 시작하는 것을 포함할 수 있다. 컨테이너의 초기화 및/또는 구성은 캐싱 가능할 수 있 는 함수 데이터 독립적 부분의 구성 및 캐싱 가능하지 않은 컨테이너의 추가적인 함수 데이터 특정적 부분의 구 성 둘 모두를 포함할 수 있다. 일부 실시예는 컨테이너에 대한 \"저스트 인 타임\" 접근법을 이용할 수 있다. 위에서 설명된 바와 같이, 컨테이 너의 시작 레이턴시가 감소된다. 필요한 경우, 함수의 레이턴시 요구사항을 충족시키기 위해 컨테이너가 전용 FaaS 캐시(2008, 2010) 내의 데이터로부터 \"저스트 인 타임으로\" 신속하게 재초기화될 수 있다. 따라서, 웜 컨 테이너(예를 들면, 함수를 실행하지 않고 함수를 기다리는 컨테이너)의 개수가 감소될 수 있기 때문에 웜 컨테 이너 사용을 감소시키기 위해 컨테이너 초기화에 대한 \"저스트 인 타임\" 접근법이 사용될 수 있다. 웜 컨테이너 사용을 감소시키는 것은 감소된 웜 컨테이너 리소스 풋프린트를 통해 리소스 할당을 향상시킬 수 있다. 예를 들어, 더 적거나 더 작은 웜 컨테이너가 대기 상태로 유지될 때, 리소스가 해제되고 함수를 실행하 는 활성 컨테이너(핫 컨테이너라고 지칭될 수 있음)에 전용될 수 있기 때문이다. 그와 같이, 더 많은 함수가 더 적은 리소스로 지원되고, 증가된 리소스 할당을 통해 더 빠르게 실행을 완료하며, 용인 가능한 레이턴시 요 구사항을 유지할 수 있다. 도 20a에 예시된 바와 같이, 서버는 3개의 캐시(2008, 2010, 2012)를 포함할 수 있다. 하이브리드 FaaS 모드에서, 캐시 중 2개(2008, 2010)는 전용 FaaS 캐시로서 동작할 수 있다. 전용 FaaS 캐시(2008, 2010)는 하 나 이상의 컨테이너를 빌드하기 위해 초기화 데이터를 저장할 수 있다. 하나 이상의 컨테이너는 서버에 서 로컬로 빌드될 수 있다. 따라서, 컨테이너를 프로비저닝하기 위해 모든 데이터를 원격 노드로부터 수신하기 보다는, 서버가 전용 FaaS 캐시(2008, 2010)에 액세스할 수 있다. 더욱이, 서버는 일부 함수에 대 해 웜 컨테이너를 유지할 필요가 없을 수 있으며, 이에 의해 웜 컨테이너에 대한 가속기, 메모리, FPGAS, 프로 세서 등과 같은 하드웨어 컴포넌트의 리소스 할당을 감소시킬 수 있다. 따라서, 서버는 더 많은 활성(핫) 컨테이너를 지원하고 향상된 리소스 할당 및 \"저스트 인 타임\" 컨테이너 초기화 접근법을 통해 함수 실행을 가속화할 수 있다. 일부 실시예에서, 전용 FaaS 캐시(2008, 2010)는 컨테이너를 개시하는 데 필요한 전체 데이터 세트의 일부만을 저장할 수 있다. 예를 들어, 서버는 컨테이너의 여러 상이한 컴포넌트를 순차적 순서로 빌드할 수 있다. 전용 FaaS 캐시(2008, 2010) 내의 초기화 데이터는 컨테이너의 시작 컴포넌트를 빌드하기 위한 데이터일 수 있 으며, 다른 후속 컴포넌트를 빌드하기 위한 데이터는 원격 노드로부터 서버로 전송된다. 그와 같이, 컨 테이너는 전용 FaaS 캐시(2008, 2010)에 저장된 초기화 데이터에 기초하여 빌드 프로세스의 시작 부분을 시작할 수 있다. 빌드 프로세스의 시작 부분과 동시에, 서버는 원격 노드로부터 빌드 프로세스의 후속 부분에 대한 데이터를 수신하고, 이어서 수신된 데이터에 기초하여 빌드 프로세스를 완료할 수 있다. 일부 실시예에서, 전용 FaaS 캐시(2008, 2010)는 함수와 연관된 데이터 객체만을 저장할 수 있으며, 이에 의해 함수 초기화를 가속화할 수 있다. 예를 들어, 전용 FaaS 캐시(2008, 2010)는 컨테이너에 대한 초기화 데이터만 을 저장할 수 있다. 범용 캐시와 같은 다른 캐시는 함수의 실행 동안 함수에 의해 생성된 데이터를 저장 할 수 있다. FaaS 관리(2006a, 2006b)는 언제 서버를 전용 FaaS 모드, 범용 모드 또는 하이브리드 FaaS 모드에서 동 작시켜야 하는지를 결정할 수 있다. 예를 들어, FaaS 관리(2006a, 2006b)는 전용 FaaS 모드 또는 하이브리드 FaaS 모드로 토글할지를 결정하기 위해 이력 데이터를 활용할 수 있다. 예를 들어, 이력 데이터는 서버 가 함수 유형을 여러 번 실행했음을 나타낼 수 있다. 상세하게는, FaaS 관리(2006a, 2006b)는 각각의 함수를 함수 유형으로 분류할 수 있다. 함수 각각이 동일한 컨테이너에서 실행 가능한 경우 함수는 동일한 함수 유형 으로 간주될 수 있다. FaaS 관리(2006a, 2006b)는 횟수를 미리 결정된 횟수와 비교하고, 횟수가 미리 결정된 횟수보다 크면 전용 FaaS 모드 또는 하이브리드 FaaS 모드가 관여되어야 한다고 결정할 수 있다. 일부 실시예에서, 이력 데이터는, 예를 들어, 이전 5 밀리초와 같은 시간 윈도 내에서 호출된 함수 유형만을 포 함할 수 있다. 서버의 모드에 대한 상기 결정을 주도하는 이력 데이터 외에도, 정책, 서비스 수준 협약 고려사항 및 오케스트레이터로부터의 명시적 지시가 전용 FaaS 캐시의 크기 및 양을 증가 또는 감소시키는 것에 대한 결정에 영향을 미칠 수 있다. 게다가, 스마트 NIC는 피어 머신 및/또는 캐시(2008, 2010, 2012)로 부터 캐싱된 FaaS 데이터를 페치하는 것에 관한 온-더-플라이 결정을 수행할 수 있다. 유사하게, FaaS 관리 로 직(2006a, 2006b)은 향상된 FaaS 시스템 및 CPU, 가속기, FPGA와 같은 요소에서 구현될 수 있으며, 피어 머신 및/또는 캐시(2008, 2010, 2012)로부터 캐싱된 FaaS 데이터를 페치하는 것에 관한 온-더- 플라이 결정을 수행할 수 있다. 이러한 방식으로, 소프트웨어는 일단의 인터네트워킹된 서버 중의 캐시 (2008, 2010, 2012)를 포함한 캐시에 FaaS 객체가 어떻게 분배되는지에 대해 알지 못할 수 있다. 위에서 언급된 바와 같이, 전용 FaaS 캐시(2008, 2010)는 하이브리드 모드에서 범용 캐시와 공존할 수 있 다. 따라서, 상기 예에서, 캐시 중 2개(2008, 2010)는 FaaS 캐시에 전용될 수 있으며 캐시는 범용 캐시 로서 활용된다. 따라서, 서버에서의 워크로드의 FaaS 부분이 증가할 때, 캐시(2008, 2010, 2012) 중의 전용 FaaS 캐시의 개수 및/또는 총 크기는 그에 따라 증가할 수 있다. 나중에, FaaS 부분이 감소할 때, 캐시 (2008, 2010, 2012) 중의 매우 작은 전용 FaaS 캐시가 계속 존재하거나 모든 캐시(2008, 2010, 2012)가 전부 FaaS 페이지, 파일 등을 캐싱하는 것과 비-FaaS 페이지, 파일 등을 캐싱하는 것 간의 구분 없이 범용 캐시로 된 다. 일부 실시예에서, FaaS 관리(2006a, 2006b)는 전용 FaaS 모드, 범용 모드 또는 하이브리드 FaaS 모드가 관여되 어야 하는지를 결정하기 위해 스케줄러로부터 메시지를 수신할 수 있다. 스케줄러는 서버에 대해 원격일 수 있으며, 예를 들어, 제어 노드에 있을 수 있다. 일부 실시예에서, 서버는 스케줄러 를 포함할 수 있다. 스케줄러는 이러한 결정을 주도하는 이력 데이터, 정책, 시스템 레벨 협약 고 려사항은 물론 오케스트레이터로부터의 명시적 지시에 기초하여 FaaS 관리(2006a, 2006b)에 전용 FaaS 모드, 하 이브리드 모드 또는 범용 모드로 진입하도록 지시할 수 있다. 일부 실시예에서, 스케줄러는 특정 컨테이너 데이터가 전용 FaaS 캐시(2008, 2010)에 저장되어야 한다고 FaaS 관리(2006a, 2006b)에 추가로 지시할 수 있다. 예를 들어, 스케줄러는 특정 컨테이너가 여러 함수 에 의해 활용되어야 한다고 결정할 수 있으며, 따라서 컨테이너에 대한 초기화 데이터가 함수에 의한 재사용을 위해 전용 FaaS 캐시(2008, 2010)에 저장되어야 한다는 것을 FaaS 관리(2006a, 2006b)에 지시할 수 있다. 더욱이, 스케줄러는 함수가 실행을 완료하는 것에 부분적으로 응답하여 하이브리드 FaaS 모드를 해제 (disengage)하고 범용 모드에 진입하도록 FaaS 관리(2006a, 2006b)에 지시할 수 있다. 예를 들어, 스케줄러 는 함수 제어 흐름 그래프로부터, 수집된 통계 및 스케줄러에 내장된 워크로드 예측 규칙으로부터, 전용 FaaS 캐시(2008, 2010) 내의 초기화 데이터가 실행을 완료한 함수에 의해 더 이상 활용되지 않을 것이라고 그리고/또는 수요가 많을 가능성이 더 적거나 없을 것이라고 결정할 수 있고, 따라서 FaaS 관리에 전용 FaaS 모드 또는 하이브리드 FaaS 모드를 해제하고 범용 모드 또는 하이브리드 FaaS 모드에 진입하도록 지시할 수 있다. 예를 들어, 과거 이력에 기초하여 예견될 수 있는 함수 제어 그래프에서의 나머지 함수는, 그의 성능 또는 효율성에 대한 상당한 위험 없이, 전용 FaaS 캐시(2008, 2010)에 저장된 초기화 데이터와 연관된 컨테이너 와 상이한 컨테이너에서 실행되도록 디스패치될 수 있다. 일단 하이브리드 FaaS 모드가 해제되면, 전용 FaaS 캐시(2008, 2010)는 재할당되어 범용 모드에서 범용 캐시로서 활용될 수 있다. 일부 실시예에서, 스케줄러 및/또는 FaaS 관리(2006a, 2006b)는 FaaS 서버 아키텍처의 부하를 식 별할 수 있다. 부하가 특정 임계치 초과인 경우, 효과적으로 리소스와 레이턴시 간의 균형을 이루기 위해 전용 FaaS 모드 또는 하이브리드 FaaS 모드가 관여될 수 있다. 부하가 임계치 아래로 저하되는 경우, 전용 FaaS 또 는 하이브리드 FaaS 모드가 해제될 수 있고, 하이브리드 FaaS 모드 또는 범용 모드가 이어서 관여될 수 있다. 예를 들어, 부하가 저하되는 경우, 전용 FaaS 모드가 하이브리드 FaaS 모드로 토글될 수 있으며, 부하가 더욱 저하되는 경우, 하이브리드 FaaS 모드가 범용 모드로 토글될 것이다. 부하는 현재 실행중인 함수, 데이터 액세 스, 통신 요청의 수, 및/또는 다른 척도를 통해 측정될 수 있다. 일부 실시예에서, 부하는 제어 흐름 그래프에 기초하여 스케줄러 및/또는 FaaS 관리(2006a, 2006b)에 의해 예측될 수 있다. 예를 들어, 스케줄러 는 제어 흐름 그래프 및/또는 한 유형의 함수의 활성화가 얼마나 자주 동일한 또는 다른 유형의 함수의 활성화로 이어졌는지에 대한 통계 분석에 기초하여 여러 함수가 동시에 동작할지를 예측할 수 있다. 일부 실시예에서, 서버는 서버가 충분히 많은 수의 FaaS 애플리케이션의 요청을 프로세싱하지 않을 것이라는 식별에 응답하여 하이브리드 FaaS 모드를 해제하고 범용 모드를 관여시킬 수 있다. 예를 들어, 스케 줄러가 서버가 더 이상 많은 수의 FaaS 애플리케이션 요청을 프로세싱할 필요가 없다고 결정하고서버에게 하이브리드 FaaS 모드를 종료하도록 지시할 수 있을 때. 일부 실시예에서, 서버는 전용 FaaS 캐시(2008, 2010)에서의 초기화 데이터의 생존 시간이 만료되었다는 식별에 응답하여 하이브리드 FaaS 모드를 해제하고 범용 모드를 관여시킬 수 있다. 예를 들어, FaaS 관리 (2006a, 2006b)는 초기화 데이터가 미사용이고 그리고/또는 컨테이너를 빌드하는 데 사용되지 않는 시간의 양을 결정하기 위해 카운터를 유지할 수 있다. FaaS 관리(2006a, 2006b)는 시간의 양이 생존 시간 임계치를 초과하 고 및/또는 충족시키는지를 결정할 수 있다. 시간의 양이 임계치를 초과하고 그리고/또는 충족시키는 경우, FaaS 관리(2006a, 2006b)는 자동으로 하이브리드 FaaS 모드를 해제하고 범용 모드를 관여시킬 수 있다. 상기 실시예 중 몇몇은 특정 조건(예를 들면, 생존 시간이 만료되었다는 식별, 부하 저하, 과거 제어 흐름 그래 프의 분석, 활성화 시퀀스 등)에 기초하여 전용 FaaS 모드 및/또는 하이브리드 FaaS 모드를 종료하는 것을 설명 한다. 일부 실시예에서, 하이브리드 FaaS 모드를 즉시 종료하기보다는, 전용 FaaS 캐시(2008, 2010) 내의 초기 화 데이터가 해제되고, 이어서 새로운 초기화 데이터로 대체될 수 있다. 예를 들어, 조건들 중 하나가 충족될 때, 스케줄러 및/또는 서버는 전용 FaaS 캐시(2008, 2010)에 상이한 초기화 데이터를 저장할지를 결정할 수 있다. 예를 들어, 스케줄러는, 제어 흐름 그래프로부터, 전용 FaaS 캐시(2008, 2010)에 저장된 초기화 데이터가 더 이상 관련성이 없다고 결정할 수 있다. 즉, 스케줄러는 초기화 데이터로부터 빌드된 제1 컨테이너가 더 이상 사용되지 않거나 드물게 사용될 것이라고 결정할 수 있다. 하이브리드 FaaS 모드를 즉시 종료하기보다 는, 스케줄러는 제어 흐름 그래프 및/또는 이력 데이터를 참조하고, 제2 컨테이너가 사용될 것인지를 결 정할 수 있다. 만약 그렇다면, 스케줄러는 FaaS 관리(2006a, 2006b)에게 제1 컨테이너에 대한 초기화 데 이터를 소거하고 제2 컨테이너에 대한 초기화 데이터를 전용 FaaS 캐시(2008, 2010)에 저장하도록 지시할 수 있 다. 그렇지만 스케줄러가 어떠한 다른 초기화 데이터도 전용 FaaS 캐시(2008, 2010)에 저장되어서는 안 된다고 결정하는 경우, 하이브리드 FaaS 모드가 종료될 수 있다. 일부 실시예들에서, 서버의 운영 체제는 서버 및/또는 스케줄러와 관련하여 위에서 설명된 바와 같이 언제 전용 FaaS 모드, 하이브리드 FaaS 모드, 범용 모드를 관여시키고 전용 FaaS 모드, 범용 모드를 종료할지를 결정할 수 있다. 일부 실시예에서, 전용 FaaS 캐시(2008, 2010)는 하드웨어 캐시일 수 있다. 일부 실시예에서, 전용 FaaS 캐시(2008, 2010)는 페이지 캐시를 포함하지만 이에 제한되지 않는 소프트웨어 캐시일 수 있다. 서버를 포함하는 실시예는 주어진 시간 프레임 내에서 서버에서 실행될 수 있는 함수의 개수를 증 가시킬 수 있다. 게다가, 함수를 실행하기 위한 실행 환경을 셋업하는 레이턴시(예를 들면, 시간)(시작 시간) 및 함수가 소비하는 메모리가 서버에서 실행될 수 있는 함수의 개수를 결정하는 인자일 수 있다. 위에서 설명된 바와 같이, 시작 시간을 감소시키기 위해 함수 실행을 위한 리소스를 메모리에 준비된 상태로 유지하는 것(예를 들면, 웜 컨테이너)이 활용될 수 있다. 잠재적인 증가된 메모리 풋프린트 및 웜 컨테이너의 리소스 할 당을 처리하기 위해, 일부 실시예는 시작 함수 및/또는 함수에 대한 컨테이너에 대한 리소스만을 저장하여 메모 리 풋프린트 및 메모리 할당을 감소시키기 위해 전용 FaaS 캐시(2008, 2010)를 격리시킬 수 있다. 따라서, 리 소스 경쟁이 감소되고, 함수의 시작 시간이 가속화된다. 서버가 FaaS 애플리케이션을 제공하는 데 사용 되지 않거나 상당한 부하가 없을 때 전용 FaaS 캐시(2008, 2010)가 적응적으로 해제될 수 있다. 도 20b는 서버가 도 20a와 관련하여 위에서 설명된 바와 같이 범용 모드에 있는 향상된 FaaS 서버 아키텍 처를 도시한다. 예시된 바와 같이, 3개의 캐시(2028, 2030, 2032)가 범용 모드에서 동작한다. 즉, 범용 캐시(2028, 2030, 2032)가 데이터 객체를 저장할 수 있지만, FaaS 관련 객체를 저장하는 데 전용되지 않을 수 있다. 범용 캐시(2028, 2030, 2032)가 FaaS 관련 객체를 저장하고 게다가 범용 데이터 객체를 저장하는 것이 여전히 가능할 수 있다. 일부 실시예에서, 도 20b에서의 FaaS 관리 로직(2026a)은 스마트 NIC에서 구현된다. 일부 실시예에서, 로직(2026a)은 대안적으로 서버 아키텍처에서 하드웨어로서, 예를 들어, 프로세서에, 베이스보드 관리 제 어기에, 가속기에, 및/또는 FPGA 등에 구현될 수 있다. 서버는 FaaS 관리 로직(2026a)과 협력하여 및/또 는 FaaS 관리 로직(2006a)과 조율하여 동작하는 FaaS 관리 로직(2026b)을 추가로 포함할 수 있다. FaaS 관리 (2026b)는 서버의 OS 드라이버 또는 스마트 미들웨어일 수 있다. FaaS 관리(2026a, 2026b)는 범용 모드, 하이브리드 모드 및 전용 FaaS 모드 사이에서 서버를 토글할 수 있다. 예를 들어, FaaS 관리 (2026a, 2026b)는 범용 모드와 전용 FaaS 모드 사이에서 토글하라는 지시를 스케줄러로부터 수신할 수 있 다. 서버가 하이브리드 모드로 토글될 때, 서버는 서버와 비슷하고 도 20a와 관련하여 위에서 설명된 것과 유사하게 동작할 수 있다. 서버가 전용 FaaS 모드로 토글될 때, 캐시(2028, 2030, 2032) 각각은 전용 FaaS 캐시로서 동작할 수 있다. 도 20c는 데이터 객체의 데이터 볼륨을 예시하는 그래프를 도시한다. 그래프는 다양한 데이터 객 체(X-축)와 데이터의 양(Y-축)의 관계를 예시한다. 핫 컨테이너는 현재 함수를 실행 중일 수 있다. 핫 컨테이 너 데이터 볼륨이 가장 크다. 웜 컨테이너는 현재 함수를 실행하지 않도록 유휴일 수 있다. 웜 컨테이 너 데이터 볼륨은 핫 컨테이너 데이터 볼륨보다 작다. 초기화 데이터는, 도 20a 및 도 20b와 관련 하여 위에서 설명된 바와 같이, 컨테이너를 개시하는 데 필요한 데이터일 수 있다. 초기화 데이터 볼륨 이 가장 적을 수 있다. 그와 같이, 웜 컨테이너 데이터 볼륨과 초기화 데이터 볼륨의 비교는 웜 컨테이너를 해체하는 것, 초기화 데이터를 하나 이상의 전용 캐시에 저장하는 것, 및 초기화 데이터로부 터 컨테이너를 재초기화하는 것에 의해 메모리 풋프린트 향상이 달성될 수 있다는 것을 예시한다. 일부 실시예에서, 초기화 데이터 볼륨에 의해 표현되는 초기화 데이터는 하나 초과의 컨테이너를 초기화 하는 데 공통인 데이터일 수 있다. 즉, 여러 컨테이너가 초기화 데이터로부터 개시될 수 있다. 그러한 공통성 은 데이터를 웜 컨테이너에 유지하는 대신에 초기화 데이터를 전용 캐시에 저장함으로써 달성되는 메모리 풋프 린트를 감소시킬 수 있다. 예를 들어, 컨테이너는 초기화 데이터로부터 개시될 수 있다. 이러한 컨테이너 각 각을 웜 컨테이너로서 유지하는 것은 여러 웜 컨테이너에 대한 오버헤드를 생성할 것이다. 오버헤드는 적어도 웜 컨테이너 데이터 볼륨을 웜 컨테이너의 개수와 곱한 것을 포함할 수 있다. 이와 달리, 해당 웜 컨테 이너 각각을 개시하기 위해 초기화 데이터의 하나의 사본만이 있으면 된다. 따라서, 웜 컨테이너를 유지하지 않고 오히려 초기화 데이터를 유지하는 것에 의해, 메모리 오버헤드가 상당히 감소된다. 도 20d는 향상된 함수 리소스 관리 방법을 도시하며, 도 20a 및 도 20b의 향상된 FaaS 서버 아키텍처 (2000, 2020), 및/또는 하나 이상의 모듈에 의해 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은, 예를 들어, FaaS 관리 로직(2006a 또는 2006b)에 의해, 서버에 대한 함수 모드 가 관여된 것으로 결정한다. 함수 모드는 위에서 설명된 바와 같이 전용 FaaS 모드 또는 하이브리드 FaaS 모드 일 수 있다. 서버는 복수의 캐시를 포함할 수 있다. 예시된 프로세싱 블록은, 함수 모드가 관여된 것에 응답하여, 복수의 캐시 중 하나 이상의 캐시를 초기화 데이터를 저장하기 위한 전용 서비스형 함수 캐시로서 활 용한다. 초기화 데이터는 함수의 실행을 개시하는 데 활용될 수 있다. 일부 실시예에서, 초기화 데이터는 함 수를 개시하기 위한 전체 데이터 세트의 일부일 뿐일 수 있다. 예시된 프로세싱 블록은 하나 이상의 전 용 서비스형 함수 캐시에 캐싱된 초기화 데이터에 기초하여 함수를 초기화할 수 있다. 예를 들어, 초기화 데이 터는 함수를 실행하기 위한 컨테이너를 빌드하는 데 활용될 수 있다. 예시된 프로세싱 블록은 웜 컨테이 너에 대한 감소된 수요, 감소된 함수 활성화 율 또는 감소된 예상 함수 활성화 중 하나 이상의 식별에 기초하여 함수 모드를 해제할 수 있다. 예시된 프로세싱 블록은 하나 이상의 캐시를 초기화 데이터에 전용되는 것으로부터 해제하고, 그리고/또는 범용 모드를 관여시킬 수 있다. 예를 들어, 하나 이상의 캐시는 서비스형 함 수 캐시로서 활용되기보다는 범용 캐시로서 활용될 수 있다. 방법은 위에서 설명된 바와 같이 리소스 이 용률을 향상시키고 함수의 레이턴시를 감소시킬 수 있다. 추가 비고 및 예 예 2000은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 컴퓨팅 디바이스에 대한 함수 모드가 관여되어 있다고 결정하게 하고 - 컴퓨팅 디바이스는 복수의 캐시를 포함함 -, 함수 모드가 관여된 것에 응답하 여, 복수의 캐시 중 하나 이상의 캐시를 초기화 데이터를 저장하기 위한 전용 서비스형 함수 캐시로서 활용하게 하며 - 초기화 데이터는 함수의 실행을 개시하는 데 활용되어야 하고, 초기화 데이터는 함수의 실행을 개시하기 위한 전체 데이터 세트의 일부일 뿐이며, 초기화 데이터는 함수를 실행하기 위한 컨테이너를 빌드하는 데 활용 됨 -, 하나 이상의 전용 서비스형 함수 캐시에 캐싱된 초기화 데이터에 기초하여 함수를 초기화하게 하며, 웜 컨테이너에 대한 감소된 수요, 감소된 함수 활성화 율 또는 감소된 예상 함수 활성화 중 하나 이상의 식별에 기 초하여 함수 모드를 해제하게 하고, 함수 모드가 해제되는 것에 응답하여, 하나 이상의 캐시를 초기화 데이터에 전용되는 것으로부터 해제하게 하며, 함수 모드가 해제되는 것에 응답하여, 하나 이상의 캐시를 범용 하드웨어 캐시로서 활용하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 2001은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 컴퓨팅 디바이스에 대한 함수 모드가 관여되어 있다고 결정하게 하고 - 컴퓨팅 디바이스는 복수의 캐시를 포함함 -, 함수 모드가 관여된 것에 응답하 여, 복수의 캐시 중 하나 이상의 캐시를 초기화 데이터를 저장하기 위한 전용 서비스형 함수 캐시로서 활용하게 하며 - 초기화 데이터는 함수의 실행을 개시하는 데 활용되어야 함 -, 하나 이상의 전용 서비스형 함수 캐시에 캐싱된 초기화 데이터에 기초하여 함수를 초기화하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 2002는 예 2001의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 초기화 데이터는 함수를 개시하 기 위한 전체 데이터 세트의 일부일 뿐이다. 예 2003은 예 2002의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 초기화 데이터는 함수를 실행하 기 위한 컨테이너를 빌드하는 데 활용되어야 한다. 예 2004는 예 2001의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 웜 컨테이너에 대한 감소된 수요, 감소된 함수 활성화 율 또는 감소된 예상 함수 활성 화 중 하나 이상의 식별에 기초하여 함수 모드를 해제하게 하는 추가 명령어 세트를 포함한다. 예 2005는 예 2004의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 함수 모드가 해제되는 것에 응답하여, 하나 이상의 캐시를 초기화 데이터에 전용되는 것으로부터 해제하게 하는 추가 명령어 세트를 포함한다. 예 2006은 예 2005의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 함수 모드가 해제되는 것에 응답하여, 하나 이상의 캐시를 범용 하드웨어 캐시로서 활 용하게 하는 추가 명령어 세트를 포함한다. 어드레스 공간 기반 QoS FaaS 환경에서, 애플리케이션, 스레드, 또는 가상 머신(VM)을 우선순위화할 수 있는 것이 중요하다. 어느 애플 리케이션 또는 VM이 높은/중간/낮은 우선순위인지를 소프트웨어(OS/VMM)로부터 하드웨어에 알려주는 기존 접근 법은 부정확하고 리소스 집약적이다. 애플리케이션, 스레드 및/또는 VM의 우선순위화하는 기존 솔루션의 예는 서비스 클래스(CLOS) 스레드 기반 인터 페이스이다. CLOS 스레드 기반 인터페이스가 편리할 수 있고, 현재 배포되어 있으며 널리 수용될 수 있지만, 이는 적어도 두 가지 단점, 즉 정밀도의 결여 - 플랫폼에서 각각의 캐시 라인이 어떻게 취급되어야 하는지 를 지정할 수 없는 것 -, 및 각각의 컨텍스트 스왑에서 CLOS를 스와핑하는 데 오버헤드가 있는 것을 겪을 수 있다. 향상된 FaaS 솔루션의 일부 예시적인 실시예는 어느 애플리케이션 또는 VM이 높은/중간/낮은 우선순 위인지를 나타내는 데 필요한 리소스와 관련하여 더 정확하고 비용이 더 적게 드는 기술적 솔루션을 제공할 수 있다. 향상된 FaaS 솔루션의 예시적인 실시예는 최종 레벨 캐시(LLC) 및 메모리 대역폭과 같은 공유 리소스가 애플리 케이션, VM 및 컨테이너에 의해 어떻게 사용되는지(예를 들면, RDT 또는 플랫폼 서비스 품질)에 대한 가시성 및 제어를 제공한다. 그러한 기술에 대한 확장은, 어드레스 공간의 특정 범위가 서비스 클래스(CLOS)로 태깅 되거나, 또는 개별 페이지가 페이지별 어트리뷰트를 추가하는 것을 통해 관리될 수 있는, 어드레스 기반 QoS를 가능하게 하도록 구축될 수 있다. 어드레스 공간 기반 QoS는 MTRR(memory type and range register)의 스타일에서의 어드레스 범위의 지정 또는 보호 키 유사 접근법을 통해 개발될 수 있으며, 여기서 범위는 베이스 및 한계(base and limit) 제어 레지스터(CR) 또는 모델 특정 레지스터(MSR)를 통해 지정된다. 그러한 경우에, 각각의 범위 레지스터가 태깅을 가능하기 위해 CLOS와 연관되어 있는 한, 기존 범위 레지스터가 재사용될 수 있 거나 또는 새로운 범위 레지스터가 도입될 수 있다. 일부 실시예에서, 태깅 및 필터링을 위해 다른 메커니즘이 사용될 수 있으며; 예를 들어, 소프트웨어는 범위-태그 테이블을 채울 수 있으며, 이는 프로세서, 메모리 제어 기에서의 하드웨어 메커니즘, 또는 다양한 DMA 가능 디바이스에 의한 어드레스 변환 서비스(ATS)에 의해 캐시로 가속화된다. CLOS는 스레드/앱/VM/컨테이너가 그룹화될 수 있는 소프트웨어 할당 태그일 수 있다. 이 태그는 소프트웨어 스 레드 또는 vCPU가 하드웨어 논리 스레드(예를 들면, 코어 상의 SMT(simultaneous multithreading) 스레드)에서 실행되기 시작할 때마다 MSR로 스와핑될 수 있다. 소프트웨어는 0개 이상의 스레드를 CLOS에 유연하게 할당할 수 있고, 이어서 LLC에서의 캐시 용량 또는 메모리 대역폭과 같은 플랫폼 리소스가 (다시 말하지만 우선순위화 요구를 충족시키기 위해 OS/VMM에 의해) 각각의 CLOS에 대해 설정될 수 있다. 그러한 할당은, 제각기, 도 4 및도 5에서의 FaaS 시스템(400 또는 500) 중 어느 하나를 통해 수행될 수 있다. 예시적인 구현예에서, 각각의 페이지 테이블 엔트리는 CLOS 태그를 사용하여 확장될 수 있다. CPU가 TLB(translation lookaside buffer) 미스 동안 페이지 테이블을 순회할 때, CLOS 어트리뷰트가 검색되고 사용 되며 TLB에 캐싱될 수 있다. 이것은, 액세스된 각각의 페이지 상의 각각의 라인에 대해, 이전에 가능했던 것보 다 더 세분화된 QoS 태깅을 가능하게 하기 위해 CLOS가 제공될 수 있다는 것을 의미한다. 스레드 기반 태깅이 오늘날 배포될 수 있고 서로 간에 FaaS 스레드를 우선순위화하는 동작을 할 수 있지만, 범 위 또는 어드레스 기반 태깅의 개념은 FaaS 스레드 내의 데이터가 또한 우선순위화될 수 있게 하고, 이는 FaaS 의 더 세분화된 성질과 더 잘 어울릴 수 있다. 또한 IOT, 산업 자동화, 모션 제어 및 실시간 컴퓨팅과 같은 다 른 용도에서 어드레스 기반 태깅의 기술적 장점이 있을 수 있으며, 여기서 키 메모리 범위는 캐시에서 우선순위 화되거나 \"의사 고정(pseudo-pinned)\"될 수 있어, 이에 의해 이전에 이용 가능했던 것보다 더 세분화된 제어를 가능하게 한다. 개발 프로세스 동안, 위에서 설명된 접근법은 툴체인에 통합될 수 있으며, 중요한 데이터는 링커 스크립트의 특 수 부분에 태깅될 수 있어, 어드레스 공간 기반 QoS가 우선순위화를 보장할 수 있게 한다. 유사하게, (캐시를 오염시킬 수 있는) 알려진 스트리밍 데이터는 우선순위해제될 수 있다. 따라서, 특수한 사용을 위해, 어드레스 공간 기반 QoS는 기존 스레드 기반 태깅 기술 위에 추가 이점을 제공할 수 있다. 일 실시예에서, 도 8a와 관련하여 설명된 것과 유사하거나 동일한 전자 프로세싱 시스템은 프로세서, 프로세서 에 통신 가능하게 결합된 메모리, 및 소프트웨어 또는 소프트웨어 스레드를 우선순위화하는 동작을 수행하기 위 해 프로세서 및 메모리에 통신 가능하게 결합된 로직을 포함할 수 있다. 일부 실시예에서, 로직은, (예를 들면, 동일한 다이 상의) 프로세서, 메모리 등을 포함한, 다양한 컴포넌트에 위치되거나 그와 공존할 수 있다. 다른 실시예에서, 도 8b와 관련하여 설명된 것과 유사하거나 동일한 반도체 패키지 장치는 하나 이상의 기판, 및 하나 이상의 기판에 결합된 로직을 포함할 수 있으며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨 어 로직 중 하나 이상에 적어도 부분적으로 구현된다. 하나 이상의 기판에 결합된 로직은 소프트웨어 또는 소 프트웨어 스레드를 우선순위화하는 동작을 수행하도록 구성될 수 있다. 일부 실시예에서, 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함할 수 있다. 이제 도 21a를 살펴보면, 이 도면은 일 실시예에 따른 소프트웨어 스레드를 우선순위화하는 방법을 예시 한다. 방법은, 블록에서, 소프트웨어 스레드가 하드웨어 논리 스레드에서 실행 중인지를 결정하는 동작을 포함한다. 블록에서, 소프트웨어 스레드가 하드웨어 논리 스레드(예를 들면, 프로세서 코어)에서 실행 중일 때 태그가 레지스터로 스와핑될 수 있다. 마지막으로, 블록에서, 각각의 태그에 대해 캐시 용 량 및 메모리 대역폭 중 하나 이상이 설정될 수 있다. 예시적인 실시예에 따르면, 캐시 용량 또는 메모리 대역 폭 중 하나 이상은 운영 체제 및/또는 가상 머신 관리자(VMM)에 의해 설정될 수 있다. 게다가, 예시적인 실시예에 따르면, 데이터 및 애플리케이션(들)은, 런타임 성능 표시자, 문제가 있는 메모리 영역 또는 구역에 기초하여, 및/또는 액세스 패턴에 기초하여 런타임 시에 상이한 성능 클래스로 동적으로 이동 될 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 페이지 레벨 QoS CPU의 성능은 저 레이턴시, 고 대역폭 메모리 액세스에 크게 의존한다. 최신 CPU 아키텍처는 DDR과 같은 외부 메모리 솔루션의 레이턴시 및 대역폭 제약을 감소시키기 위해 다수의 레벨의 캐시에 의존한다. 캐싱은 CPU의 전반적인 성능을 개선시키는 데 사용될 수 있으며, 캐시 QoS(캐시 할당 기술, CAT) 및 메모리 대역폭 할당 (MBA)(둘 모두 기존 특징임)과 같은 특징은 다중 코어 프로세서 내의 특정 코어에 대해 더 큰 성능을 보장하는 수단을 제공한다. CAT 및 MBA는 많은 환경에서 이점을 제공하지만, 스레드 레벨 태깅에 의존한다. 이것은 태 그가 적용된 후에(리소스 제어를 위한 서비스 클래스(CLOS), 또는 모니터링을 위한 리소스 모니터링 ID(RMID)), 이어서 스레드와 연관된 후속 활동이 제어 및/또는 모니터링된다는 것을 의미한다. 그렇지만, 스레드에 의해 액세스되는 데이터 어드레스에 민감하고 그리고/또는 그에 대응하는 방식으로 해당 스레드의 데이터 배치를 제 어하는 방법이 현재는 없다. 특정 어드레스에 대한 가장 중요한 캐시 미스가 성능 및 실행 지터에 상당한 영향 을 미칠 수 있는 실시간 또는 중요한 스레드에서, 이것은 스레드의 가장 중요한 데이터를 캐시에 유지하기 위해 튜닝 및 최적화하기 어려운 스레드를 결과할 수 있다. 실시간 환경에서, 이러한 캐시 미스는 최악의 실행 시간 을 고려할 때 가정되며, 따라서 최종적인 실시간 워크로드 완료 시간을 보장하는 프로그래머의 능력에 상당한 영향을 미친다. 예를 들어, 제1 코어인 코어 A가 100 μs마다 정기적으로 데이터 A(<1KB)를 소비하는 워크로드를 갖지만, 차례 로 전체 L3 캐시를 소비하는 스트림 프로세싱 동작도 수행하는 경우, 데이터 A가 L1, L2 및 L3 캐시는 물론 STLB(second-level TLB)에서의 TL 엔트리로부터 강제로 축출될 수 있다. 100 μs의 정규 비트 레이트(beat rate)로 데이터 A에 나중에 재액세스하는 이 패턴을 통해, 데이터 A에 대한 가상 어드레스를 변환하는 데 필요 한 페이지 워크를 포함하여 DDR로부터 메모리를 페치하는 것에 의해 예측불가능한 추가 레이턴시가 종종 부과될 수 있다(여기서 변환은 나중에 TLB/STLB 구조에 저장되지만, 나중에 스트리밍 워크로드 단계의 큰 작업 세트에 의해 강제 퇴출됨). 실시간 환경에서, 이 추가된 레이턴시는 사용 가능한 실행 사이클을 더욱 감소시켜, 최악 의 캐시 및 TLB 거동을 고려하기 위해 사이클 버짓이 패딩되어야 하기 때문에 총 이용 가능 성능의 70% 미만을 남길 수 있다. 10us 비트 레이트 정도로 더 엄격한 한계를 갖는 일부 경우에, 유효 성능은 50% 미만일 수 있다. 다른 예로서, 실행의 타임 슬라이싱을 통해 코어에서 워크로드를 혼합하는 것은 또한 캐시 및 STLB 압력 을 도입할 수 있다. 향상된 FaaS 및 실시간 솔루션의 예시적인 실시예는 캐시 계층구조가 불필요한 축출 및 비용이 많이 드는 페이 지 테이블 워크를 방지함으로써 캐시에서의 데이터 블록의 레지던시를 개선시키게 할 수 있다. 추가적으로, 예시적인 실시예에 따르면, CLOS 선택은 페이지 어트리뷰트에 첨부될 수 있고, 임계 경로 실행을 위한 캐시 라인 레지던시를 개선시키는 방법을 캐시 계층구조에 제공할 수 있다. 운영 체제에 의해 페이지 테 이블에 할당된 각각의 페이지는 페이지에 대한 선택된 CLOS를 정의할 수 있다. 메모리 로드/저장이 발생하고 데이터가 캐시로 가져와져야 할 때, 페이지 어트리뷰트는 CLOS가 사용할 수 있는 캐시 블록, 특히 공간을 만들 기 위해 데이터가 어느 방식으로 축출될 수 있는지를 나타낼 수 있다. 마찬가지로, STLB의 경우, 페이지 변환 이 판독될 때, 그것이 페이지 어트리뷰트에 의해 정의된 CLOS에 할당된 STLB의 특정 위치를 가질 수 있으며, 따 라서 TLB 엔트리의 레지던시를 개선시킨다. 달리 말하면, CLOS 태그는 중요한 데이터(위의 두 단락의 예에서 데이터 A)를 L1/L2/L3/등 레벨에 있는 캐시의 보호된 파티션 및/또는 STLB에 할당하는 데 사용될 수 있다. 보 호된 파티션에 이 데이터가 존재하는 것은 그 데이터가 축출될 가능성을 없애주며, 이는 필요할 때 데이터가 존 재하여, 메모리로부터 이 데이터를 페치할 필요가 있는 것에 의해 유발되는 실행 지터를 감소시킨다는 것을 의 미한다. 페이지 레벨 QoS는 각각의 데이터 블록을 개별적으로 처리할 수 있게 한다(이 용어는 또한 바이트, 캐시 라인 또는 페이지 레벨에서의 관리를 지칭할 수 있지만, 구현 효율성을 위해, 페이지 레벨이 통상적인 접근법일 수 있음). 명령어는 특정 어트리뷰트(예컨대, CLOS 태그)를 갖는 페이지에 매핑될 수 있으며, 임계 경로 실행의 경우에, 임계 경로 명령어는 특정 QoS 요구사항을 갖는 별개의 페이지를 가질 수 있다. 유사하게, 데이터의 경 우, 더 낮은 액세스 빈도를 갖는 임계 경로 아이템은 메모리 액세스 중단을 방지하는 특정 QoS 요구사항을 가질 수 있다. 원하는 QoS 태그(예를 들어, CLOS)를 페이지 어트리뷰트에 통합하는 것은 다양한 캐시 레벨에서 CAT 와 같은 캐시 제어 특징 및 STLB 파티셔닝 함수와의 더 나은 통합을 가능하게 할 수 있어, 결정적 레지던시 및 더 단순한 모델링이 최악의 실행 시간을 보장할 수 있게 한다. 위에서 설명된 접근법은 코어 레벨 QoS(전통적인 RDT)의 관련 솔루션과 상이할 수 있으며, 여기서 CLOS는 코어 내에 존재하는 모든 다운스트림 구조를 제어하는 레지스터를 통해 정의된다. 보안 위험으로 인해, CLOS는 전형 적으로 사용자 공간 애플리케이션에 이용 가능하지 않은 특권 레지스터를 통해 제어된다. 이러한 스레드 태깅 구현을 통해, 모든 메모리 동작에 대한 실행 동안 주어진 시간에 하나의 CLOS만이 태스크에 의해 사용될 수 있 다. 코어 레벨 QoS는 태스크 내의 모든 데이터가 동일하게 취급된다고 가정하기 때문에 더 문제가 될 수 있다 (그리고 코어 레벨 특징은 SMT의 경우에서와 같이 각각의 코어에 여러 스레드가 존재하는 경우 관리하기 더 어 렵다). 따라서 CLOS가 전환되고 데이터가 사용 전에 사전에 캐시로 \"프라이밍(prime)\"되는 \"의사 잠금(pseudo locking)\"과 같은 복잡한 특수 사용 흐름이 없는 경우, 태스크는 어떤 아이템이 L2 또는 STLB 캐시에서 특정 레 지던시 요구사항을 가질 것인지를 제어할 수 없다. 따라서, 그러한 복잡한 셋업 동작 및/또는 단계 없이, 스트 림 프로세싱 동작은 캐시 내의 모든 임계 경로 아이템을 축출할 수 있다. 게다가, 의사 잠금 솔루션은, 때때로 효과적이기는 하지만, 예상치 못한 마이크로아키텍처 거동에 의해 영향을 받을 수 있다는 점에서 \"취약\"하며, 이는 캐싱 거동을 둘러싼 보증을 구축하는 것을 매우 어렵게 만든다. 코어당 많은 통합된 태스크를 갖는 실행 환경도 문제를 일으킬 수 있다. 이 시나리오에서는, 성능에 영향을 미치지 않으면서 태스크당 상당한 양의 캐 시를 카브 아웃(carve out)하는 능력이 어려울 수 있다. 페이지 레벨 QoS는 일 예시적인 실시예에서 페이지 레벨에서 페이지 테이블 내의 엔트리에 CLOS 정의를 추가함 으로써 런타임 서비스 품질을 개선시키는 수단을 제공할 수 있다. 예상된 용도는 아래의 시나리오에서 설명될 수 있다. 예를 들어, 애플리케이션이 실행될 준비가 될 때, 운영 체제는 애플리케이션의 모든 바이너리 섹션을 메모리에 배치하기 위해 페이지를 할당할 수 있다. 바이너리의 각각의 세그먼트는 운영 체제에 보이는 어떤 수 단에 의해 CLOS로 태깅될 수 있으며 해당 CLOS에 의해 결정되고 태깅되는 할당된 페이지에 배치될 수 있다. 이 것은 애플리케이션의 상이한 세그먼트가 전체 서비스 품질을 개선시키기 위해 더 높거나 더 낮은 우선순위를 가 질 수 있게 하지만, 더 중요한 것은, 중요한 페이지에서의 중요한 데이터 조각에 대해, 그것이 훨씬 더 높은 확 률로 캐시/TLB에 보관될 수 있고 (이러한 데이터 영역을 캐시/TLB로 로드하기 위한 페이지 레벨 인터페이스를 통해) 더 간단한 인터페이스가 제공된다는 것이다. 페이지가 할당될 때, 각각의 페이지 엔트리는 페이지가 나타내는 메모리에 대한 CLOS를 정의하기 위해 추가 비 트와 함께 페이지 테이블에 추가될 수 있다. 런타임 시에, 페이지 엔트리는 가상 대 물리 어드레스 변환을 제 공하기 위해 CPU에 의해 검색될 수 있으며, 이 시점에서 CLOS는 자신이 액세스할 메모리에 대해 식별될 수 있다. CLOS가 캐시 계층구조가 어떻게 파티셔닝되는지를 정의할 수 있기 때문에, 메모리는 이어서 해당 CLOS에 대한 파티션에 의해 정의되는 공유 리소스(예컨대, 캐시 레벨의 STLB)의 영역으로 로드될 수 있다. 축출의 경 우에, 특정 캐시 파티션에 액세스할 수 있는 새로운 메모리 요청만이 캐시 파티션으로부터 아이템을 축출할 수 있다. 이것은 별개의 파티션에 있는 중요한 데이터가 축출로부터 보호될 수 있다는 것을 의미한다. 이것은 예 약된 파티션에 대해 캐시에 있는 아이템의 레지던시를 극적으로 개선시킬 수 있고, 따라서 다른(그리고 아마도 더 강력한) 의사 잠금 수단을 제공할 수 있다. 런타임 동안의 메모리 애플리케이션의 경우, 힙에 메모리를 할 당하기 위한 운영 체제 호출은 생성될 새로운 페이지 테이블 엔트리에 대해 선택된 CLOS를 추가로 제공받을 수 있다. 이제 도 21b 및 도 21c를 살펴보면, 이 2개의 도면은 향상된 FaaS 아키텍처에서 페이지 레벨 QoS를 제공하기 위 해 페이지 테이블에서의 태스크와 CLOS 간의 상호작용을 도시한다. 페이지 레벨 QoS는 프로그램의 세그먼트를 별개의 CLOS로 파티셔닝하여 특정 세그먼트 또는 세그먼트 내의 특정 데이터가 캐시/TLB에서 특별히 우선순위화 되거나 보호될 수 있게 함으로써 이점을 제공할 수 있다. 도 21b에서, 애플리케이션은, 각각이 특정 실 시간 결정적 요구사항을 갖는, 3개의 개별 태스크(예를 들면, 태스크 0, 태스크 1, 태스크 2)를 가질 수 있다. 이러한 태스크 각각은, (예를 들어, 다중 스레드 애플리케이션의 경우에서와 같이) 전역 프로세스 레벨 컨텍스 트를 여전히 공유하면서 실행 중에 특정 캐시 파티셔닝을 가능하게 하기 위해, 코드 및 데이터에 대한 자체 세 그먼트(.text 및 .bss)를 갖는다. 데이터 및 코드는 태스크 0에 관련되고, 데이터 및 코드 는 태스크 1에 관련되며, 데이터 및 코드는 태스크 2에 관련된다. 각각의 태스크의 코드 및 데이터는 특정 캐시 파티션을 목표로 하여, 실행 시간에 더 많은 결정성을 제공하고 더 엄격한 최악의 실행 시 간 계산을 가능하게 한다. 도 21b의 예시적인 실시예에 따르면, .bss 및 .text 세그먼트는 동일한 서비스 클래 스를 공유할 수 있지만, 이들은 메모리 크기 제약 및 요구되는 결정성의 정도에 기초하여 추가로 파티셔닝될 수 있다. 이제 도 21c를 살펴보면, 런타임 시에, 태스크 0은 CPU 코어 0 L2 및 L3 캐시의 파티션으로서 메모리 할당자 CLOS 3에 힙 데이터를 요청할 수 있다. 태스크 1은 또한 CPU 코어 1 L2 및 L3 캐시의 파티션으로서 CLOS 4에 힙 데이터를 요청한다. CPU 코어 0의 경우, 다음과 같이 그리고 도 21c에 도시된 바와 같이, 센서데이터에 대해 예시적인 타이트 루프(tight loop)가 실행될 수 있다: 1) 센서 데이터가 PCI-E DMA를 통해 L3/LLC에 배치된다. 예를 들어, Intel DDIO 특징은 메모리에 저장된 일부 데이터를 L3/LLC 캐시의 전용 영역에 캐싱한다. 2) 태스크 0은 입력 센서 데이터를 소비하여, 이를 CLOS 3 L2 캐시 파티션으로 스트리밍하면서 bss_clos_0 ds에 서 데이터도 업데이트한다. 3) 태스크 0은 bss_clos_2 내의 데이터를 통해 태스크 2에 대한 출력을 생성하고 단계 1로 루프백한다. CPU 코어 1의 경우, 태스크 1은 태스크 0 또는 태스크 2에 대한 데이터 상관성 없이 외부 인터럽트에 기초하여 태스크 0에 비동기적으로 실행될 수 있다. 실시간 결정성으로 인해, 태스크 1의 캐시에서의 레지던시가 중요할 수 있다. CPU 코어 1의 경우, 태스크 2는 다음과 같이 bss_clos_2로의 태스크 0의 출력과 등시적으로 정렬되어 실행할 수 있다: 1) bss_clos_2를 통해 Task 0으로부터의 출력을 판독한다. 2) CPU 코어 1 L2 및 L3 캐시 내의 CLOS 4를 사용하여 기입 출력 데이터를 생성한다. 3) PCI-E 상의 NIC는 L3로부터의 출력 데이터를 판독한다. 이제 도 21d를 살펴보면, 이 다이어그램은, 스레드 레벨 QoS가 CLOS를 정의하는 데 사용되는 것을 제외하고는, 도 21c에서와 유사한 시나리오를 예시한다. 첫째, CPU 코어 0의 관점에서 볼 때, 특별한 소프트웨어 기 반 기술 및 이를 지원하도록 특별히 튜닝된 캐시 계층구조 없이, 태스크 0만이 CPU 코어 0에서 실행되고 있기 때문에, 센서 데이터에서 스트리밍될 때 text_clos_0 또는 bss_clos_0의 레지던시를 증가시키기 위해 캐시 를 파티셔닝할 수단이 없을 수 있다. 이것은 캐시에서의 원하지 않는 축출을 강제하고, 추가 캐시 미스가 발생 할 때 전체적인 결정성을 감소시킬 수 있다. 다음으로 CPU 코어 1의 관점에서 볼 때, 태스크 1과 태스크 2 사이에 파티셔닝이 여전히 존재할 수 있지만, 힙 출력 데이터에 대한 스트리밍된 기입이 CLOS 2와 결합될 수 있다. 이것은 bss_clos_2 및 text_clos_2로의 원하지 않는 축출을 야기할 수 있으며, 센서 데이터(또는 이 경 우에 패킷)가 송신되도록 명령받은 타이밍과 NIC가 실제로 송출되는 시기 사이의 결정성을 추가로 감소시킨다. 환언하면, 캐시의 공유로 인해, 애플리케이션이 송신하라는 커맨드를 발행한 시간과 데이터가 실제로 유선을 통 해 송신되는 시간 사이에 비-결정적 레이턴시가 있다. 이 레이턴시는 PCIe 디바이스가 메모리로부터 데이터를 판독해야 할 것이고, 데이터가 캐싱될 수 있거나 그렇지 않을 수 있다는 사실로 인한 것이다. 궁극적으로 이러 한 캐싱 불확실성은 실행 시간에서의 비-결정 및 지터를 결과한다. 가장 큰 결정적 메모리 블록인 L3 캐시의 관점에서 볼 때, 힙 입력 및 출력 데이터가 중요한 코드 및 데 이터의 추가적인 축출을 유발할 수 있도록 세분성이 감소된다. L2 축출이 L3 캐시에 원하지 않는 레이턴 시를 추가하지만, 외부 메모리로부터 데이터를 페치해야 하는 것은 온다이 메모리 블록보다 상당히 더 많은 레 이턴시 및 지터를 추가할 수 있다. 페이지 레벨 QoS를 구현함으로써, 캐시에서의 데이터/명령어 레지던시에 기초하여 더 결정적인 모델이 개발될 수 있어, 더 엄격한 실시간 실행 제약 및 더 높은 코어 이용률을 가능하게 한다. 높은 중요도의 주요 FaaS 워 크로드의 경우, 이것은 상당한 발전이다. 추가 비고 및 예 예 2101은 소프트웨어 스레드가 하드웨어 논리 스레드에서 실행 중인지를 결정하는 단계, 소프트웨어 스레드가 하드웨어 논리 스레드에서 실행 중일 때 태그를 레지스터로 스와핑하는 단계, 및 각각에 대해 캐시 용량 및 메 모리 대역폭 중 적어도 하나를 설정하는 단계를 포함하는 방법을 포함한다. 예 2102는 예 2101의 방법을 포함하고, 여기서 태그는 페이지 테이블로부터의 서비스 클래스(CLOS) 태그이어야 한다. 예 2103은 예 2101의 방법을 포함하고, 여기서 캐시 용량 및 메모리 대역폭 중 적어도 하나는 운영 체제 및 가 상 머신 관리자 중 하나에 의해 설정된다. 통합된 동시 스레드의 수에 관계없이 예측 가능한 FaaS 처리량 및 공정성의 보장 예시적인 실시예에 따르면, 결정성과 공정성을 보장하는 하드웨어 또는 소프트웨어 솔루션이 FaaS 환경에서 제 공될 수 있다. 그러한 것은 빌링의 일관성, 정확성 및 공정성을 보장하도록 구현될 수 있다. FaaS 리소스의 관리 및 모니터링은 리소스 사용량에 대한 정확한 빌링을 보장하기 위해 일관성 있도록 설계되어 있다. FaaS 리소스 사용량의 평가에서의 공정성이 필요한데 그 이유는 FaaS 리소스가 사용될 때 테넌트가 비용을 지불 하고, 다른 테넌트의 스레드의 활동으로 인해 야기되는 하나의 테넌트의 스레드의 속도 저하가 동일한 워크로드 의 반복된 호출이 주어진 경우 런타임에서의 불공정성 또는 변동(따라서 빌링에서의 변동)을 야기할 수 있기 때 문이다. 따라서, CPU 스케줄링 퀀텀이 공정성을 보장하도록 조정될 수 있고; 빌링 통계는 주어진 CPU 시간 및 전반적인 공정성을 측정하는 데 사용될 수 있으며; 대역외(OOB) 원격 측정은 또한 현재 달성되고 있는 공정성의 정도를 이해하기 위해 애플리케이션을 모니터링하는 데 역할을 할 수 있다. 그렇지만, 아래에 설명된 바와 같 이, 제어가 중요하다. 예시적인 실시예에 따르면, 결정성 및 공정성을 보장하는 적어도 2가지 접근법이 있다: 1) 함수들 각각이 공유 리소스에 동등하게 액세스할 수 있도록 보장하기 위해 공유 리소스를 파티셔닝하는 것, 또는 2) a. 모니터링 및 제어 b. 동적 함수 리소스 제어 및 마이그레이션 동작을 수행하는 하드웨어 또는 소프트웨어 성능 관리 제어기를 구현하는 것. 도 22는 FaaS 환경에서 결정성 및 정확성을 제공하기 위한 예시적인 아키텍처를 예시한다. 도 22에서, 컴퓨팅 디바이스, 예를 들면, 성능 제어기는 바로 위 단락에서의 동작 \"a\" 및 동작 \"b\"를 수행할 수 있다. 컴퓨 팅 디바이스는 또한 이력 기반 리소스 스케줄링을 제공하고, 데이터를 호출을 위해 적절한 코어로 리디렉 션하며, 데이터 공유를 최대화하고 데이터 이동을 최소화하며, 서비스 수준 협약에 따라 함수를 번들링할 수 있 다. 컴퓨팅 디바이스의 위에서 설명된 동작은 소프트웨어를 통해서도 구현될 수 있다. 결정성 및 공정성을 보장하기 위해, 컴퓨팅 디바이스 또는 소프트웨어는, 특히 L2가 채워질 때, L2 캐시 가 상이한 코어(2220, 2230)에 의해 핸들링되도록 L2 캐시를 분할할 수 있다. 예시적인 실시예에 따르면, 컴퓨팅 디바이스는 코드를 데이터로부터 분할할 수 있다. 추가적으로, 함수 가 균형을 잘 이루도록, 예를 들어, 하나의 리소스가 백엔드 과중(back-end heavy)인 경우, 함수가 혼합되고 스 케줄러에 기초하여 상이한 코어 상에 매칭될 수 있도록 함수가 이동될 수 있다. 추가적으로, 컴퓨팅 디바이스 는 시간 리소스를 동적으로 재할당할 수 있다. 런타임은 도 22의 아키텍처에서 구현될 수 있거나 그렇지 않을 수 있다. 구현될 때, 함수는, 운영 체제 특정 호출을 피하기 위해, 인프라스트럭처로부터 서비스 및 명령어를 획득하기 위해 런타임을 호출할 수 있다. FaaS에 대한 빌링의 정확도 향상 빌링을 위한 소프트웨어 기반 시간 샘플링 접근법은 스큐 및 높은 오버헤드를 겪기 때문에 FaaS에 적합하지 않 을 수 있다. 빌링이 밀리초에 기초하는 경우, 컴퓨팅 리소스 사용량이 마이크로초 단위로 측정될 수 있도록 하 는 세분성이 필요하다. 데이터 센터에서 워크로드 시간스케일이 감소함에 따라, 세분화된 모니터링 및 빌링이 점점 더 중요해지고 있다. FaaS는 고객이 밀리초까지 빌링할 수 있게 하도록 설계되어 있으며, 이는 운영자에게 정확성을 보장하기 위해 마이크로초 레벨로 검증 가능한 빌링 정밀도를 유지할 것을 요구한다. 따라서 최소한의 오버헤드로 그러 한 빌링을 지원하는 하드웨어 기술이 필요하게 되며, 여러 기술이 아래에 설명되어 있다. 예시적인 실시예에 따르면, 낮은 오버헤드를 갖고 인프라스트럭처에 의해 주기적으로 빌링 통계의 온 디맨드 검 색을 가능하게 하는 빌링 관리 및 모니터링에 대한 하드웨어 접근법이 제공된다. 이 예시적인 실시예는 FaaS 함수의 컨텍스트 스왑 경로로부터 시간 어카운팅 오버헤드를 제거하여, 오버헤드 및 비용을 개선시킬 수 있다. VM에 대한 빌링을 예로 들면, 전통적으로 VM은 웹 기반 콘솔 또는 모바일 애플리케이션을 통해 관리될 수 있으 며 관리자에 의해 온-디맨드로 스핀 업 또는 스핀 다운될 수 있다. 그렇지만, 전형적으로 빌링은 분 단위로 관 리된다. 이러한 조대하게 나뉜 빌링은 인프라스트럭처의 비용이 저렴하고 고객이 관리하고 확인하기가 쉽다. 즉, 그러한 시스템에 대한 요구사항은 낮다(예를 들면, 기본적인 추적 및 시간 동기화된 인프라스트럭처, NTP와 같은 기존 프로토콜이 이 목적에 적합하다). FaaS에 요구되는 세분화된 빌링에서, VM의 경우에 위에서 설명된 조대하게 나뉜 빌링과 같은 전통적인 기술은 부적절할 수 있다. OS 시간 API의 소프트웨어 기반 시간 샘플링은 스큐를 겪으며, 높은 함수 호출/종료 비율은 시간 값을 수집하고 타임 스탬프 간의 차이를 계산하는 등을 위해 높은 오버헤드에 이를 수 있다. 이것은 운영자 비용 증가 및 런타임에 대해 고객이 프로파일링하는 것과 운영자가 보고하는 것 사이의 미스매치 가 능성을 초래할 수 있다. 시간 경과에 따라 누적된 불명확성 및 부정확성은 이러한 문제를 더욱 악화시킨다. 소프트웨어 솔루션과 달리, 하드웨어 접근법은 매우 낮은 오버헤드를 수반할 수 있으며, 인프라스트럭처에 의해 주기적으로 빌링 통계의 온-디맨드 검색을 가능하게 한다. 다음을 포함하지만 이에 제한되지 않는, 하드웨어 지원 FaaS 빌링이 시스템에서의 함수 또는 특정 스레드 및 그의 대응하는 활동을 고유하게 식별하기 위한 여러 태깅 기술 또는 솔루션이 가능하다. 1) 리소스 모니터링 ID(RMID) 기술 - OS/VMM이 RMID를 스왑할 때, RMID 리소스 추적 태그가 FaaS 함수를 추적 하는 데 사용될 수 있다. 각각의 함수(또는 각각의 테넌트)는 RMID를 할당받을 수 있으며, (세분화된 시간 기 반으로 또는 CPU 기준 클록 사이클 단위로) CPU에서의 RMID 시간을 추적하기 위해 새로운 CPU 하드웨어가 구축 또는 인에이블될 수 있다. 새로운 RMID별 이벤트 코드가 이어서 보고될 수 있거나 또는 리소스 사용량이 RMID 대 시간 사용량을 보고하는 새로운 MSR 또는 MMIO 블록을 통해 보고될 수 있다. 2) 프로세스 어드레스 공간 ID(PASID) 기술 - 예시적인 실시예에 따른 PASID는 PCIe gen 3 사양 부록의 일부로 도입된 20b 태그이다. PASID는 각각의 코어에 할당되고 SIOV(Scalable I/O Virtualization)와 같은 다른 특징 과 함께 사용될 수 있다. PASID당 사용된 CPU 시간을 추적하기 위해 새로운 하드웨어가 구축되거나 인에이블될 수 있기 때문에, 이것은 고유한 함수 계산 시간 사용량을 추적하는 매우 효율적인 방법일 수 있다(이 기술에서 는 위의 MMIO 기반 또는 MSR 기반과 유사한 구현 옵션이 이용 가능함). 각각의 PASID에 의해 소비되는 CPU 사 이클을 추적하기 위해 카운터의 추적 시스템을 추가하는 것은 이 접근법을 구현하는 중요한 부분일 것이다. 3) 논리 프로세서 ID(LPID) 기술 또는 스레드별 또는 코어별 논리 프로세서 ID, 스레드 또는 코어는 PASID 및 RMID와 유사하게 사용될 수 있으며, 유사하게 CPU 이용률을 추적하기 위해 인스턴스당 카운터가 추가될 수 있다. 이것은 OS/VMM이 각각의 컨텍스트 스왑에서 이러한 카운터를 판독할 가능성이 있을 것을 요구하거나, 소 프트웨어 대신에 이러한 결과를 집계하기 위해 하드웨어가 필요할 것이다. 4) 제어 레지스터 CR3 기반 기술 - 베이스 페이지 테이블 어드레스가 프로세스에 대한 기초를 형성하는 경우, 고유 제어 레지스터 CR3마다의 하드웨어 카운터에서 CPU 시간을 추적한다. CPU 이용률을 추적하기 위해 (예를 들어, 비용을 감소시키기 위해 가장 활동적인 CR3에 대해) CR3 고유 값당 소비된 시간 또는 사이클이 추적될 수 있다. 5) VM vCPU 기반 기술 - VM 가상 CPUID당 하드웨어 카운터를 할당하는 것(VT-x 아키텍처와 연관될 수 있음) - 그러한 카운터는 vCPU 각각에 대한 CPU 이용률을 추적할 수 있다(실제로는 가상화되지 않은 사례에 대한 이용률 을 추적하기 위해 위에서 설명된 다른 기술도 필요함). 6) RAO(Remote Atomics) 기반 기술 - RAO는 CPU 시간을 추적하는 데 사용될 수 있는 언코어에서의 로직을 구축 할 수 있다 - 예를 들어, 하드웨어에 의해 자동으로(또는 소프트웨어에 의해 명시적으로) 각각의 컨텍스트 스왑 에서 주어진 프로세스 ID/PASID/RMID 등에 대해 \"X 사이클만큼 증분\"을 추적 하드웨어에 송신하기 위해 게시된 RAO 명령어가 사용될 수 있다. 이것은 미래 세대의 서버 하드웨어로 시작하는 소프트웨어에서의 RAO 변수로 가 능할 수 있다. 언코어는 코어에 없지만, 고성능을 달성하기 위해 코어와 밀접하게 연결될 수 있는 마이크로프 로세서의 함수를 반영할 수 있다. 언코어는, 예를 들어, 캐싱, 메모리 제어기 액세스, (예를 들어, PCIe를 통 한) I/O 디바이스 액세스 등, 및 일반적으로 모든 함수를 하나로 묶는 고성능 상호연결과 같은 능력을 제공할 수 있다. 6) RAO(Remote Atomics) 기반 기술 - RAO는 CPU 시간을 추적하는 데 사용될 수 있는 언코어에서의 로직을 구축 할 수 있다 - 예를 들어, 하드웨어에 의해 자동으로(또는 소프트웨어에 의해 명시적으로) 각각의 컨텍스트 스왑 에서 주어진 프로세스 ID/PASID/RMID 등에 대해 \"X 사이클만큼 증분\"을 추적 하드웨어에 송신하기 위해 게시된 RAO 명령어가 사용될 수 있다. 이것은 Sapphire Rapids 서버로 시작하는 소프트웨어에서의 RAO 변수로 가능할 수 있다. 언코어는 코어에 없지만, 고성능을 달성하기 위해 코어와 밀접하게 연결될 수 있는 마이크로프로세서 의 함수를 반영할 수 있다. 상기 태깅 스킴 중 하나 이상에서, (예를 들어, 새로운 테넌트에 대해 PASID 또는 RMID를 재할당 및 재활용하기 위해) 온 디맨드로 카운터를 샘플링/판독하고 임의로 온 디맨드로 카운터를 클리어하는 메커니즘이 또한 필요할 수 있다. 예시적인 실시예에 따르면, 위에서 설명된 태그는 OS 또는 다른 하드웨어에 의해 할당될 수 있다.일 실시예에서, 도 8a와 관련하여 설명된 것과 유사하거나 동일한 전자 프로세싱 시스템은 프로세서, 프로세서 에 통신 가능하게 결합된 메모리, 및 리소스 사용량을 계산하는 동작을 수행하기 위해 프로세서 및 메모리에 통 신 가능하게 결합된 로직을 포함할 수 있다. 일부 실시예에서, 로직은, (예를 들면, 동일한 다이 상의) 프로세 서, 메모리 등을 포함한, 다양한 컴포넌트에 위치되거나 그와 공존할 수 있다. 다른 실시예에서, 도 8b와 관련하여 설명된 것과 유사하거나 동일한 반도체 패키지 장치는 하나 이상의 기판, 및 하나 이상의 기판에 결합된 로직을 포함할 수 있으며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨 어 로직 중 하나 이상에 적어도 부분적으로 구현된다. 하나 이상의 기판에 결합된 로직은 리소스 사용량을 계 산하는 동작을 수행하도록 구성될 수 있다. 일부 실시예에서, 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함할 수 있다. 이제 도 23을 참조하면, 이 도면은, 예시적인 실시예에 따른, 빌링 목적으로 리소스 사용량을 계산하는 방법 을 예시한다. 방법은, 블록에서, CPU 상에서의 리소스 모니터링 식별자(RMID) 시간을 추적 하는 동작을 포함한다. 블록에서, RMID 시간이 보고될 수 있다. 블록에서, 카운터 클리어 모듈은 온-디맨드로 카운터를 저장 및/또는 클리어하고 RMID를 재할당하도록 구성될 수 있다. 추가 비고 및 예 예 2301은 중앙 프로세싱 유닛, 리소스 모니터링 식별자(RMID)를 사용하여 전력 관리 유닛에서 파티셔닝하고 CPU 상에서의 리소스 모니터링 식별자(RMID) 시간을 추적하도록 구성된 리소스 모니터링 하드웨어 모듈, 및 RMID 시간을 보고하도록 구성된 코드 보고 하드웨어 모듈을 포함하는 장치를 포함한다. 예 2302는 예 2301의 장치를 포함하고, 여기서 하드웨어 이벤트를 카운트하기 위한 하드웨어 카운터는 RMID별로 할당되어야 한다. 예 2303은 예 2301의 장치를 포함하고, 카운터 클리어 모듈을 추가로 포함하며, 카운터 클리어 모듈은 온 디맨 드로 카운터를 클리어하고 RMID를 재할당하도록 구성되어야 한다. 지능형 원격 측정 기반 스케줄링 예 종래의 스케줄러/오케스트레이터는, 함수가 어떻게 거동하는지에 대한 피드백 없이, 이용 가능성에 기초하여 함 수를 분배한다. 도 5와 관련하여 위에서 설명된 것과 같은, 향상된 FaaS 솔루션의 일부 실시예는 함수가 실행 될 때의 거동에 대한 정보(예를 들어, 함수가 너무 많은 시간이 걸리는 것, 너무 많은 캐시를 사용하는 것 등) 를 수집하고, 수집된 정보에 기초하여 더 나은 스케줄링/오케스트레이션 결정을 할 수 있다. 예를 들어, 다양 한 하드웨어 아키텍처는 함수 거동에 관련된 유용한 정보를 제공할 수 있는 수많은 카운터를 제공할 수 있다. 일부 실시예는 (예를 들어, 모든 데이터 포인트 대신에) 함수 관련 정보의 통계를 수집할 수 있다. 예를 들어, 수집된 정보의 데이터베이스는 향후 라우팅 결정을 위해 스케줄러/오케스트레이터에 의해 유지 및 사용될 수 있 다. 유리하게는, 일부 실시예는 더 나은 분배 결정(들)을 할 수 있고, 더 나은 리소스 이용률을 제공할 수 있 으며 기타 등등이다. 이제 도 24a를 살펴보면, 분산 컴퓨팅 환경의 실시예는 하나 이상의 실행 환경(예를 들면, 플랫폼, 서버 등)과 통신 가능하게 결합된 서버를 포함할 수 있다. 일부 실시예에서, 서버는 향상된 FaaS 시스템이다. 서버는 함수를 실행 환경으로 스케줄링하고 라우팅하기 위한 오케스트레이터를 포함할 수 있다. 실행 환경은 함수의 실행에 관련된 정보를 수집하도록 구성될 수 있는 데이터 수집 모 듈에 통신 가능하게 결합될 수 있다. 데이터 수집 모듈은 수집된 정보를 (예를 들면, 개별적으로,"}
{"patent_id": "10-2020-7037419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "요약 형태로, 수집된 정보에 관련된 통계, 어떤 구조화된 데이터베이스 등으로) 저장할 수 있는 데이터 저장소 에 통신 가능하게 결합될 수 있다. 오케스트레이터는 저장된 데이터를 활용하여 함수를 어떻게 스 케줄링하고 라우팅할지에 대한 결정을 하기 위해 데이터 저장소에 통신 가능하게 결합될 수 있다. 일부 실시예에서, 오케스트레이션 및/또는 데이터 수집은 특정 사용량 레벨에 도달하는 함수에 대해서만 구현될 수 있다(예를 들어, 1000회 미만의 함수 인스턴스화는 수집된 데이터에 기초하여 오케스트레이션되지 않는 반면, 1000회 초과의 함수 인스턴스화는 데이터가 수집되고 수집된 데이터에 기초하여 오케스트레이션됨). 일부 실시 예에서, 함수가 잘 알려진 후에(예를 들면, 함수가 미리 정의된 임계 횟수에 걸쳐 실행된 후에) 수집이 중단될 수 있다. 상세하게는, 오케스트레이터는 함수를 실행할, 서버와 같은, 시스템으로 함수를 라우팅하고 스케줄 링한다. 오케스트레이터는 자유 사이클을 갖는 시스템 및/또는 서브시스템을 찾고 함수 실행을 이들로라우팅할 수 있다. 오케스트레이터의 일부 실시예는 더 효율적이고 더 경제적인 실행을 위해 함수의 이 전 실행으로부터의 원격 측정 정보를 사용하는 지능형 스케줄러를 제공할 수 있다. 일부 실시예에서, 오케스트 레이터는 비효율성(예를 들면, 높은 전력 소비, 예상보다 긴 레이턴시 등)을 식별하는 AI 및/또는 MI, 및 비효율성을 해결하기 위한 향상을 포함할 수 있다. AI 및/또는 MI는 서버 상의 함수의 스케줄링 및/또는 분배를 조정하고, 조정이 효과적인지를 결정할 수 있다(예를 들어, 함수의 배치를 실행하고 비효율성이 방지 또 는 감소되는지를 결정함). 만약 그렇다면, 오케스트레이터는 조정에 기초하여 다른 함수를 계속 스케줄 링 및/또는 분배할 수 있다. 그렇지 않으면, 오케스트레이터는 비효율성을 극복하기 위해 다른 세트의 조정을 시도하기 위해 또다시 AI 및/또는 MI를 이용할 수 있다. 원격 측정 정보는 호스트 시스템 상에서의 이 벤트에 대한 끊김 없는 통계 샘플링은 물론 함수의 정적 및 동적 프로파일 정보를 수집하기 위한 코드의 정적 또는 동적 구성을 포함한 다양한 방식으로 수집될 수 있다. 수집될 수 있는 이벤트 정보의 비제한적인 예는 데 이터/명령어 캐시 미스, 분기 예측 실패, 열 카운터, IPT, RDT 등과 같은 마이크로아키텍처 이벤트 정보를 포함 한다(예를 들면, 대역 내(CPU 상) 또는 CSME를 통한 대역외). 수집될 수 있는 다른 정보의 비제한적인 예는 함 수의 동적 호출 그래프, 기본 블록 카운트, API 호출 등을 포함한다. 수집된 정보는 함수에 대응하는 정적/동 적 프로파일 정보로서 구성될 수 있다. 오케스트레이터의 지능형 원격 측정 기반 스케줄러의 실시예는 함수를 함수 실행에 아주 적합한 또는 가 장 적합한 시스템 또는 시스템/서브시스템의 풀(예를 들면, 이용 가능한 리소스, 충분한 컴퓨트, 메모리, 스토"}
{"patent_id": "10-2020-7037419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "리지 등)로 동적으로 라우팅하기 위해 함수에 관해 수집된 정보(예를 들면, 정보의 요약)를 사용할 수 있다. 수집된 원격 측정 및 함수에 관한 프로파일 정보의 적합한 프리프로세싱으로, 지능형 스케줄러는 그의 제어 하 에 있는 시스템의 리소스의 이용 가능성을 신속하게 평가할 수 있다. 예를 들어, 스케줄러는 함수가 스케줄링 되기 위해 필요한 충분한 양의 캐시를 가지는 시스템 또는 시스템의 풀을 식별할 수 있다. 수집된 정보의 세분 성은 구현에 따라 다를 수 있지만, 지능형 스케줄러의 실시예는 함수에 의한 요구사항의 벡터를 이용 가능한 시 스템의 요구사항과 매칭시키는 문제를 해결할 수 있다. 스케줄러는 더 많은 함수가 실행될수록, 스케줄러가 함 수의 예측된 거동에 관한 더 정확한 정보를 가질 수 있다는 점에서 지능적인 것으로 간주될 수 있다. 원격 측정 기반 스케줄링의 일 예에서, 오케스트레이터의 지능형 스케줄러의 실시예는 실패를 예측하고 이를 방지할 수 있다. 예를 들어, 오케스트레이터의 지능형 스케줄러의 일부 실시예는 어떤 함수가 실행 되고 있었는지, 리소스 이용률 벡터(예를 들면, 전력 프로파일 등을 포함함) 등을 포함하는 충돌 시점에서의 서 버의 상태를 기록할 수 있다. 스케줄러는 잠재적으로 많은 실패 사례를 보고 시스템 상태를 빠르게 매칭 시키기 위해(예를 들면, 잠재적인 실패를 예측하기 위해) 딥 신경 네트워크(DNN)를 생성할 수 있다. 일부 실시예에서, 컴파일러는 향상된 컴파일 성능을 위해 프로파일 기반 최적화(profile guided optimization)(PGO) 또는 피드백 기반 최적화(feedback-directed optimization)(FDO)를 사용할 수 있다. 이것 은 인공 지능의 한 측면으로 간주될 수 있다. 이벤트가 트리거될 때 함수를 실행하기 위해 많은 노드가 이용 가능할 수 있다. 다양한 노드는 상이한 강점/능력을 가질 수 있으며 함수가 어디에서 실행되는지에 대해 실질 적이거나 완전한 유연성이 있을 수 있다. 오케스트레이터는 함수를 수신하고, 이를 실행을 위해 어떻게 라우팅할지를 결정한다. 일부 실시예에서, 함수가 실행될 때, 함수의 거동(예를 들어, 캐시 미스, 실행할 타이 밍 등)에 관한 정보가 오케스트레이터에 의해 수집될 수 있다. 일부 실시예는 프로그램 정보를 수집하기 위해 많은 카운터를 사용할 수 있고, 그리고/또는 함수가 데이터를 수집하도록 구성될 수 있다(예를 들어, 그리 고/또는 정보를 수집하기 위해 타이머가 사용될 수 있다). 구성은 또한 코드를 가속화하기 위해 코드를 수정하 는 것을 결과할 수 있다(예를 들면, 행렬 곱셈이 식별되고, 따라서 다음에 특정 서버 상의 하드웨어를 활용하도 록 코드를 구성함). 수집된 데이터는 컴파일러가 함수를 어디에서 실행할지의 프로파일 기반 최적화를 위해 활 용할 수 있는 함수에 대한 프로파일을 형성할 수 있다. 오케스트레이터의 일부 실시예는 함수가 미래에 JIT(just-in-time) 적응을 위해 분배될 때 풀인(pull i n)되는 리소스(예를 들어, ASIC, GPU, FPGA 등과 같은 하드웨어 구현을 포함한, 가속 함수)에 대한 인공 지능 의사 결정 능력을 변경하는 것을 또한 포함할 수 있다. 수집된 데이터는 데이터베이스 또는 데이터 저장소 와 같은 데이터 저장소에 저장되고 실행에서의 에러를 식별하기 위해 샘플링될 수 있다. 에러에 기초하 여, 오케스트레이터의 일부 실시예는 이상적인 리소스 할당 및 서버를 식별할 수 있다(예를 들면, 프로파 일이 함수가 대용량 캐시를 사용함을 나타내는 경우, 오케스트레이터는 에러를 방지하기 위해 대용량 캐 시 할당을 가진 서버로 함수를 라우팅할 수 있음). 오케스트레이터의 일부 실시예는 생성된 프로파일을 활용하여 프로파일 기반 최적화를 제공하고, 리소스의 선택을 최적화하기 위해 가능한 결과를 식별할 수 있다. 예를 들어, 오케스트레이터의 일부 실시예는 함수를 분석하고 캐시 사용을 최대화할 수 있다(예를 들면,비디오를 상이한 사용자에게 스트리밍하는 2개의 함수가 동일한 서버로 푸시될 수 있음). 이제 도 24b를 살펴보면, 서비스형 함수를 제공하는 방법의 실시예는, 블록에서, 실행된 함수에 관 련된 거동 관련 정보를 수집하는 단계, 및 블록에서, 수집된 거동 관련 정보에 기초하여 후속 함수 관리 결정을 하는 단계를 포함할 수 있다. 방법의 일부 실시예는, 블록에서, 수집된 거동 관련 정보에 관련된 통계를 결정하는 단계, 및, 블록에서, 결정된 통계에 기초하여 후속 함수 관리 결정을 하는 단계 를 추가로 포함할 수 있다. 예를 들어, 블록에서, 함수 관리 결정은 스케줄 결정 및 오케스트레이션 결 정 중 하나 이상을 포함할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 예를 들어, 방법은 아래의 예 2411 내지 예 2413과 관련하여 설명된 바와 같이 컴퓨터 판독 가능 매체 상 에 구현될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그 래밍 인터페이스(API)를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, FPGA 비트 스트림, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤 러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 추가 비고 및 예 예 2400은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 실행된 함수에 관련된 거동 관련 정 보를 수집하게 하고 - 거동 관련 정보는 대역 내 정보 및 대역 외 정보 중 하나 이상을 포함함 -, 수집된 거동 관련 정보에 기초하여 후속 저스트 인 타임(just-in-time) 함수 관리 결정을 하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 2401은 전자 프로세싱 시스템을 포함하고, 이 전자 프로세싱 시스템은 프로세서, 프로세서에 통신 가능하게 결합된 메모리, 및 프로세서에 의해 실행되는 함수에 관련된 거동 관련 정보를 수집하고, 수집된 거동 관련 정 보에 기초하여 후속 함수 관리 결정을 하기 위해 프로세서 및 메모리에 통신 가능하게 결합된 로직을 포함한다. 예 2402는 예 2401의 시스템을 포함하며, 여기서 로직은 추가로 수집된 거동 관련 정보에 관련된 통계를 결정하 고, 결정된 통계에 기초하여 후속 함수 관리 결정을 한다. 예 2403은 예 2401 및 예 2402 중 어느 한 예의 시스템을 포함하고, 여기서 함수 관리 결정은 스케줄 결정 및 오케스트레이션 결정 중 하나 이상을 포함한다. 예 2404는, 하나 이상의 기판 및 하나 이상의 기판에 결합된 로직을 포함하는, 반도체 패키지 장치를 포함하며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현되고, 로 직은 실행된 함수에 관련된 거동 관련 정보를 수집하고, 수집된 거동 관련 정보에 기초하여 후속 함수 관리 결 정을 하기 위해 하나 이상의 기판에 결합된다. 예 2405는 예 2404의 장치를 포함하며, 여기서 로직은 추가로 수집된 거동 관련 정보에 관련된 통계를 결정하고, 결정된 통계에 기초하여 후속 함수 관리 결정을 한다. 예 2406은 예 2404 및 예 2405 중 어느 한 예의 장치를 포함하고, 여기서 함수 관리 결정은 스케줄 결정 및 오 케스트레이션 결정 중 하나 이상을 포함한다. 예 2407은 예 2404 내지 예 2406 중 어느 한 예의 장치를 포함하고, 여기서 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함한다.예 2408은 서비스형 함수를 제공하는 방법을 포함하고, 이 방법은 실행된 함수에 관련된 거동 관련 정보를 수집 하는 단계, 및 수집된 거동 관련 정보에 기초하여 후속 함수 관리 결정을 하는 단계를 포함한다. 예 2409는 예 2408의 방법을 포함하며, 수집된 거동 관련 정보에 관련된 통계를 결정하는 단계, 및 결정된 통계 에 기초하여 후속 함수 관리 결정을 하는 단계를 추가로 포함한다. 예 2410은 예 2408 및 예 2409 중 어느 한 예의 방법을 포함하고, 여기서 함수 관리 결정은 스케줄 결정 및 오 케스트레이션 결정 중 하나 이상을 포함한다. 예 2411은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 실행된 함수에 관련된 거동 관련 정 보를 수집하게 하고, 수집된 거동 관련 정보에 기초하여 후속 함수 관리 결정을 하게 하는 명령어 세트를 포함 하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 2412는 예 2411의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 수집된 거동 관련 정보에 관련된 통계를 결정하게 하고, 결정된 통계에 기초하여 후속 함수 관리 결정을 하게 하는 추가 명령어 세트를 포함한다. 예 2413은 예 2411 및 예 2412 중 어느 한 예의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 함수 관리 결정은 스케줄 결정 및 오케스트레이션 결정 중 하나 이상을 포함한다. 메모리 재사용을 최대화하는 지능형 함수 스케줄링 예 도 4의 설명과 관련하여 위에서 설명된 것과 같은 향상된 FaaS 시스템의 일부 실시예는 유리하게도 메모리 재사 용을 최대화하는 지능형 함수 스케줄링을 제공할 수 있다. 메모리는 제한된 리소스이며 함수와 데이터는 메모 리에서의 공간을 차지한다. 일부 실시예는 동일한 언어 스택의 함수 인스턴스를 동일한 기본 시스템/머신/메모 리로 라우팅할 수 있다. JIT 생성 코드는 또한 중복될 수 있고 일부 실시예에서 중복 JIT 코드의 인스턴스는 동일한 기본 시스템/머신/메모리로 라우팅될 수 있다. 일부 실시예는 동일한 언어(예를 들면, JAVA, PYTHON 등)를 활용하는 함수를 동일한 머신 및/또는 물리 노드로 우선적으로 라우팅할 수 있다. 일부 실시예는 추가적 으로 또는 대안적으로, 공유 데이터(예를 들면, 맵 데이터)를 동일한 시스템/머신/메모리로 라우팅할 수 있다. 아래의 도 25a에서의 FaaS 시스템과 같은 향상된 FaaS 시스템의 실행 환경은 함수의 실행을 지원하기 위 해 공통 코드 라이브러리(예를 들면, DLL(dynamic link library)) 및/또는 공통 데이터(예를 들면, 데이터 세트, 데이터베이스, 맵 데이터 등)를 로딩할 수 있다. 그러한 공유 라이브러리는 비용이 많이 들고 그리고/또 는 많은 데이터를 가질 수 있다. 향상된 FaaS 시스템의 일부 실시예는 유리하게도 공유 라이브러리로부 터 이익을 얻기 위해 동일한 언어의 함수를 동일한 머신으로 라우팅할 수 있다. 일부 실시예에서, 공유 라이브 러리는 공유 함수의 상이한 인스턴스처럼 취급될 수 있다. 예를 들어, 일부 시스템에서, 동일한 함수의 컴파일 된 코드는 유사할 수 있다. 향상된 FaaS 시스템의 일부 실시예는 또한 공유 데이터(예를 들면, 2개의 함 수 둘 모두가 동일한 맵 데이터에 액세스할 수 있고, 일부 실시예는 2개의 함수를 동일한 머신에 라우팅할 수 있음) 및 리소스를 이용할 수 있다. 향상된 FaaS 시스템의 일부 실시예는 정확히 동일한 비트 스트링을 갖는 메모리 영역의 물리 메모리의 단 하나의 사본(예를 들어, 캐시 라인)을 사용함으로써 더 큰 메모리 대역폭 및 더 짧은 메모리 액세스 레이턴시를 가능하게 하는 메모리 재사용 기술을 포함할 수 있다. 예를 들어, 수천 개의 개별 캐시 라인 모두가 동일한 값 을 가질 때(예를 들면, 모든 비트가 0 또는 1 또는 0과 1의 임의의 순열일 때), 물리 메모리는 중복 영역의 하 나의 사본만을 저장할 것이다. 메모리 재사용 기술은 동일한 메모리 위치를 재사용하기 위해 해싱과 조합된 추 가 간접 참조(indirection)를 활용할 수 있다. 그렇지만, 영역들 중 하나가 변경될 때, 새로운 값에 대한 새로 운 영역이 생성될 수 있으며, 순열이 이미 존재하는 경우, 간접 참조 메커니즘은 수정된 영역을 해당 기존 저장 값에 매핑할 것이다. 메모리 재사용 기술의 이점은 데이터의 중복을 방지하기 위해 모든 비트의 공통 패턴이 0 또는 1인 것이다. 향상된 FaaS 시스템의 일부 실시예는 데이터 외에도 함수 코드에 대한 메모리 재사용 기술로부터 이익을 얻을 가능성을 증가시킬 수 있다. 추가적으로, FaaS 플랫폼에서의 함수는 종종 관리 런타임(managed runtime)(예를 들면, JavaScript, Python, Java, C # 등)에 있다. 이러한 플랫폼 각각은 동적으로 로딩 및 링크되는 DLL과 같은 다수의 공유 라이브러리 를 갖는다. 다수의 애플리케이션이 동일한 DLL을 사용할 때, OS는 전형적으로 메인 메모리에 하나의 DLL을 유 지하며 해당 DLL을 로딩하는 모든 앱에 대해 공유된다. 추가적으로, 이러한 관리 런타임의 대부분은 그의 고급 언어에 대한 코드를 동적으로 생성하는 JIT 컴파일러를 갖는다. 향상된 FaaS 시스템의 일부 실시예는 유리하게도 동일한 언어의 함수, 또는 이전에 라우팅된 함수와 유사하거나 동일한 추가 함수를 동일한 시스템 또 는 동일한 시스템 풀로 라우팅하기 위해 스케줄러/오케스트레이터, 예를 들면, 도 24b에 도시된 오케스트레이터 를 제공할 수 있다. 게다가, 동일한 데이터(예를 들면, 동일한 맵, 동일한 비디오 스트림 등)를 사용하 는 함수는 동일한 시스템 또는 동일한 시스템 풀로 라우팅될 수 있다. 유리하게도, 향상된 FaaS 시스템 의 일부 실시예는 이러한 상이한 함수가 (예를 들어, 정적 코드, DLL, JIT 생성 코드, JIT 생성 데이터 등의 면 에서) 코드/데이터의 많은 중복을 가질 가능성을 증가시킬 수 있다. 메모리 재사용 기술을 장비한 시스템은 일 부 실시예로부터 추가로 이익을 얻을 수 있는데, 그 이유는 메모리 재사용 기술이 실제로는 캐시 레벨을 포함하 여 매우 미세한 레벨로 각각의 중복 코드의 하나의 인스턴스만을 사용할 수 있기 때문이다. 유리하게도, 일부 실시예는 대역폭을 위한 메모리에 대한 압력을 감소시킬 수 있으며 함수/앱은 그들이 사용하는 코드의 더 빠른 액세스에 더하여 데이터를 위한 더 많은 메모리를 가질 수 있다. 일부 실시예에서, 향상된 FaaS 시스템의 시스템 소프트웨어는 캐시 라인 경계에 높은 메모리 재사용 가능 성을 갖는 코드 및 데이터 구조를 정렬하도록 구성될 수 있다. 추가적으로, 일부 데이터 구조의 테일에 0을 패 딩하는 것은 메모리 재사용 기술로부터 이익을 얻을 가능성을 추가로 증가시킬 수 있다. 또한, 함수/워크로드 의 \"기입 세트\"를 감소시키거나 제한하는 것은 기입이 메모리 재사용 기술의 스테이징 영역에 적합하도록 보장 하는 데 도움이 될 수 있으며 기입 세트가 성장하기 시작할 때 메모리 중복을 방지하는 것과 연관된 오버헤드의 감소를 결과할 수 있다. 이제 도 25a를 살펴보면, 향상된 FaaS 시스템은 함수 f 및 함수 g를 포함한 하나 이상의 과도 함수 및 함 수를 위한 하나 이상의 타깃 시스템을 포함할 수 있다. 각각의 함수 f 또는 g는 그의 상이한 데이터 및 코드 섹션(도 25a에서 상이하게 음영 처리된 영역으로 도시됨)과 연관된 상이한 메모리 영역을 가지고 있다. 지능형 오케스트레이터/스케줄러의 일부 실시예는 고도로 사용되는 중복 메모리 영역(데이터 및 코드 둘 모두) 을 동적으로 끊김없이 샘플링하고, 이를 실행 중인 함수와 연관시키며, 결과를 향후 스케줄링 시나리오에서 사 용할 수 있다. 예를 들어, 일부 실시예는 함수 f, g에서 공유 정보를 식별하고 함수 f, g를 동일한 타깃 시스템으로 라우팅할 수 있다(예를 들어, 타깃 시스템이 이미 로딩된 공유 정보를 가질 수 있기 때문임). 이제 도 25b를 살펴보면, 서비스형 함수를 제공하는 방법의 실시예는, 블록에서, 과도 함수에 대응 하는 공유 정보를 식별하는 단계, 및 블록에서, 식별된 공유 정보에 기초하여 과도 함수를 실행 환경으로 라우팅하는 단계를 포함할 수 있다. 예를 들어, 블록은 동일한 언어 및/또는 서로 유사한 함수를 갖는 함수를 식별하는 스케줄러 및/또는 오케스트레이터를 포함할 수 있으며, 따라서 동일한 기본 공통 데이터 세트 를 활용할 수 있다. 예를 들어, 동일한 데이터(예를 들면, 동일한 맵, 또는 동일한 비디오 스트리밍, 동일한 컴퓨터 언어 라이브러리 등)를 사용하는 함수는 동일한 기본 공통 데이터 세트(예를 들면, 공유 정보)를 활용하 는 것으로 식별될 수 있다. 식별된 함수는 동일한 시스템(예를 들면, 특정 노드) 또는 동일한 시스템 풀에서 실행되도록 스케줄링될 수 있다. 방법의 일부 실시예는, 블록에서, 이전에 라우팅된 과도 함수의 새로운 인스턴스를 식별하는 단계, 및, 블록에서, 새로운 인스턴스를 이전에 라우팅된 과도 함수와 동일한 실행 환경으로 라우팅하는 단계를 추가로 포함할 수 있다. 일부 실시예에서, 블록은 블록으로 확장될 수 있다. 예를 들어, 블록 에 의해 예시된 바와 같이, 공유 정보는 공유 코드, 공유 언어, 및 공유 데이터 중 하나 이상을 포함할 수 있고, 하나의 함수에 의해 생성되고 다른 함수에 의해 소비되는 과도 정보의 공유를 추가로 포함할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 도 25a에 설명된 FaaS 시스템과 같 은 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언 어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어 의 임의의 조합으로 작성될 수 있다. 예를 들어, 방법은 아래의 예 2511 내지 예 2513과 관련하여 설명된 바와 같이 컴퓨터 판독 가능 매체 상 에 구현될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그 래밍 인터페이스(API)를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 추가 비고 및 예 예 2501은 전자 프로세싱 시스템을 포함하고, 이 전자 프로세싱 시스템은 프로세서, 프로세서에 통신 가능하게 결합된 메모리, 및 과도 함수에 대응하는 공유 정보를 식별하고, 식별된 공유 정보에 기초하여 과도 함수를 실 행 환경으로 라우팅하기 위해 프로세서 및 메모리에 통신 가능하게 결합된 로직을 포함하고, 여기서 식별된 정 보는 적어도 다른 함수에 의해 공유된다. 예 2502는 예 2501의 시스템을 포함하며, 여기서 로직은 추가로 이전에 라우팅된 과도 함수의 새로운 인스턴스 를 식별하고, 새로운 인스턴스를 이전에 라우팅된 과도 함수와 동일한 실행 환경으로 라우팅한다. 예 2503은 예 2501 및 예 2502 중 어느 한 예의 시스템을 포함하고, 여기서 공유 정보는 공유 코드, 공유 언어, 및 공유 데이터 중 하나 이상을 포함한다. 예 2504는, 하나 이상의 기판 및 하나 이상의 기판에 결합된 로직을 포함하는, 반도체 패키지 장치를 포함하며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현되고, 로 직은 과도 함수에 대응하는 공유 정보를 식별하고, 식별된 공유 정보에 기초하여 과도 함수를 실행 환경으로 라 우팅하기 위해 하나 이상의 기판에 결합되며, 여기서 식별된 정보는 적어도 다른 함수에 의해 공유된다. 예 2505는 예 2504의 장치를 포함하며, 여기서 로직은 추가로 이전에 라우팅된 과도 함수의 새로운 인스턴스를 식별하고, 새로운 인스턴스를 이전에 라우팅된 과도 함수와 동일한 실행 환경으로 라우팅한다. 예 2506은 예 2504 및 예 2505 중 어느 한 예의 장치를 포함하고, 여기서 공유 정보는 공유 코드, 공유 언어, 및 공유 데이터 중 하나 이상을 포함한다. 예 2507은 예 2504 내지 예 2506 중 어느 한 예의 장치를 포함하고, 여기서 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함한다. 예 2508은 서비스형 함수를 제공하는 방법을 포함하고, 이 방법은 과도 함수에 대응하는 공유 정보를 식별하는 단계, 및 식별된 공유 정보에 기초하여 과도 함수를 실행 환경으로 라우팅하는 단계를 포함하고, 여기서 식별된 정보는 적어도 다른 함수에 의해 공유된다. 예 2509는 예 2508의 방법을 포함하며, 이전에 라우팅된 과도 함수의 새로운 인스턴스를 식별하는 단계, 및 새 로운 인스턴스를 이전에 라우팅된 과도 함수와 동일한 실행 환경으로 라우팅하는 단계를 추가로 포함한다. 예 2510은 예 2508 및 예 2509 중 어느 한 예의 방법을 포함하고, 여기서 공유 정보는 공유 코드, 공유 언어, 및 공유 데이터 중 하나 이상을 포함한다. 예 2511은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 과도 함수에 대응하는 공유 정보를 식별하게 하고, 식별된 공유 정보에 기초하여 과도 함수를 실행 환경으로 라우팅하게 하는 명령어 세트를 포함 하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 식별된 정보는 적어도 다른 함수에 의해 공유된다. 예 2512는 예 2511의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 이전에 라우팅된 과도 함수의 새로운 인스턴스를 식별하게 하고, 새로운 인스턴 스를 이전에 라우팅된 과도 함수와 동일한 실행 환경으로 라우팅하게 하는 추가 명령어 세트를 포함한다. 예 2513은 예 2511 및 예 2512 중 어느 한 예의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 공유 정보는 공유 코드, 공유 언어, 및 공유 데이터 중 하나 이상을 포함한다. 컨테이너 병합/분해 및 상태 집계 및 분할 예 도 4의 설명과 관련하여 위에서 설명된 것과 같은 향상된 FaaS 시스템의 일부 실시예는 유리하게도 컨테이너 병 합 및/또는 분해, 및/또는 상태 집계 및 분할을 제공할 수 있다. 함수가 종래에는, 함수 간의 관계를 분석하거나 고려하지 않고, 독립적인 실행 단위로 취급될 수 있으며, 이는 때때로 리소스가 최적화되지 않게 하거나 IO 오버헤드(예를 들면, 네트워크 및 로컬)를 증가시킬 수 있다. 향상된 FaaS 시스템의 일부 실시예는 유리하게도 함수 간의 관계를 정의하기 위해 함수 호출 그래프를 제공할 수 있다. 다수의 함수 호출을 피하기 위해 일부 관련 함수가 인라인으로 될 수 있다. 리소스/대역폭 소비를 줄이기 위해 일부 함수가 분해될 수 있다. 일부 실시예에서, 동적 호출 그래프는 런타임 분석에 기초하여 조정될 수 있다. 향상된 FaaS 시스템의 일부 실시예 는 상태의 동적 표현 및 탐색을 위한 데이터 온톨로지를 제공할 수 있다. 유리하게도, 향상된 FaaS 시스템의 일부 실시예는 더 나은 리소스 이용률, 더 낮은 IO 오버헤드 및/또는 증가된 대역폭을 제공할 수 있다. 일부 실시예는 필요하지 않은 경우 오버헤드를 생성하지 않을 수 있다. 일부 실시예에서, 개발자는 함수를 론칭하기 전에 함수가 얼마나 오랫동안 실행될 필요가 있는지를 식별할 수 있다. 이제 도 26a를 살펴보면, 서비스형 함수를 제공하는 방법의 실시예는, 블록에서, 하나 이상의 과도 함수에 대한, 함수들 간의 관계를 정의하는 함수 호출 그래프와 같은, 구성 관련 정보(organization-related information)를 제공하는 단계, 및 블록에서, 구성 관련 정보에 기초하여 하나 이상의 과도 함수의 실행 을 수정하는 단계를 포함할 수 있다. 방법의 일부 실시예는, 블록에서, 과도 함수들 중 하나 이상 을 하나 이상의 하위 함수로 분할하는 단계를 추가로 포함할 수 있다. 방법은, 블록에서, 과도 함 수들 및 하위 함수들 중 하나 이상을 병합하는 단계를 또한 포함할 수 있다. 예를 들어, 방법은, 블록 에서, 과도 함수들 및 하위 함수들 중 하나 이상의 실행 사이에서 상태 정보를 공유하는 단계를 포함할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 예를 들어, 방법은 아래의 예 2614 내지 예 2617과 관련하여 설명된 바와 같이 컴퓨터 판독 가능 매체 상 에 구현될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그 래밍 인터페이스(API)를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 효율적인 실행을 위한 컨테이너 병합/분해 예 이제 도 26b를 살펴보면, 함수 호출 그래프의 실시예는 과도 함수 f, g 및 h에 대한 구성 관련 정보를 제 공할 수 있다. 위에서 언급된 바와 같이, 종속적인 것으로 식별된 함수는, 함수 간의 하나 이상의 종속성으로 인해, 오버헤드 증가, 열악한 리소스 사용률 등을 유발할 수 있다. 도 26b에 도시된 예에서, 함수 g 및 h는 함 수 f에 의존한다(예를 들면, 함수 g 및 h는 실행을 위해 함수 f에 의해 생성된 적어도 하나의 출력을 필요로 한 다). 일부 실시예는 유리하게도 효율적인 함수 실행을 위해 (예를 들면, 하나의 함수가 언제 다른 함수으로 이 어지는지를 식별하기 위한 수단을 통해) 함수 호출 그래프와 같은 구성 관련 정보를 제공할 수 있다. 호출 그래프는 함수들 간의 호출 관계를 나타내는 제어 흐름 그래프에 대응할 수 있다. 가중된 호출 그래프에 서, (예를 들어, 호출자 함수에서 시작되고 피호출자 함수에서 끝나는) 각각의 아크는 해당 호출 호출(call invocation)의 빈도 및/또는 확률로 태깅될 수 있다. 호출 그래프는 정적으로 형성될 수 있고 이어서 동적으 로 미세 조정될 수 있다. 호출 그래프 내에 형성된 영역에 기초하여, 호출 및 데이터 통신의 오버헤드를 줄이 기 위해 특정 FaaS 함수가 병합될 수 있다. 예를 들어, 일부 실시예는, 특정 FaaS 함수가 2개 이상의 함수로 분할될 수 있도록, 인트라-FaaS 함수 제어 흐름 그래프를 호출 그래프에 통합할 수 있다. 이제 도 26c 내지 도 26e를 살펴보면, 예시적인 다이어그램은 함수 f가 2개의 하위 함수 f0 및 f1로 분할될 수 있는 방법을 도시하고(도 26c 참조), 이어서 함수 g는 2개의 하위 함수 사이에서 병합될 수 있다(도 26d 및 도26e 참조). 이러한 분해 및 병합 프로세스는 간결하고 및/또는 효율적인 동작 시퀀스를 형성하는 데 도움이 될 수 있다. 일부 실시예는 코어의 캐시 성능에 긍정적인 영향을 미칠 수 있으며 또한 동시에 다수의 FaaS 함수를 웜/라이브 상태로 유지하기 위해 스토리지 요구사항 및 오버헤드를 줄일 수 있다. 덜 자주 취해지는 제어 흐름 경로 및 호출 경로가, 콜드 경로가 실행되는 경우에 적절한 코드/호출(들)을 적절한 FaaS 함수에 삽입함으로써 프로비저닝될 필요가 여전히 있을 수 있다. 일부 실시예에서, 코드 생성은 명령어 레벨 병렬성(ILP)을 향상시키기 위한 슈퍼블록을 형성하기 위해 컴파일러 기술(예를 들면, 원래 람다로부터의 컴파일러/코드 생성기)을 적용할 수 있다. 슈퍼블록은 측면 입구를 갖지 않는 트레이스에 대응할 수 있다. 예를 들어, 제어는 상부로부터만 진입할 수 있지만 하나 이상의 출구 지점에 서 나갈 수 있다(예를 들면, 상부에 있는 단일 입구 그러나 다수의 출구). 일부 실시예에서, 프로파일 정보는 다수의 기본 블록을 포함하는 공통 경로로부터 슈퍼 블록을 빌드하는 데 사용될 수 있다. 일부 실시예는 인프라스트럭처에 의해(예를 들어, 스케줄링 이전에) 및/또는 런타임 시에 스케줄러에 의해 수행 될 수 있다. 일부 실시예는 또한 데이터의 공존을 활용할 수 있다. 예를 들어, 일부 실시예는, 데이터를 이동 시키기 위한 비용이 함수를 이동시키기 위한 비용보다 더 많기 때문에, 데이터를 함수로 전달하는 것이 아니라, 함수를 데이터로 전달할 수 있다. 일부 실시예는 인라인 기술을 활용할 수 있다. 예를 들어, 식별된 함수 2가 합리적인 확실성으로 함수 1에 의해 호출될 때, 일부 실시예는, 분리된 호출 대신에, 함수 2의 코드를 함수 1에 인라이닝할 수 있다(예를 들어, 도 26e 참조). 인라이닝 이후에, FaaS 시스템은 함수 2를 실행하거나, 스케줄 러를 가져오거나, 또는 함수를 다운로드하기 위해 외부로 나갈 필요가 없다. 그와 같이, 인라이닝은 향상된 FaaS 시스템의 효율성을 증가시키고 그리고/또는 오버헤드를 줄일 수 있다. 일부 실시예에서, 스케줄러는 인라 인 동작을 실행할 수 있다. 일부 실시예에서, 함수 1이 함수 2와 인라이닝되어 새로운 병합된 코드를 생성한 후에도, 원래 함수 1 및 함수 2 코드는 그럼에도 불구하고 여전히 저장된다(예를 들어, 제거되거나 삭제되지 않 음). 그렇게 함으로써, 원래 함수 1과 2가 서로 독립적으로 실행되도록 여전히 독립성을 유지한다. 예를 들어, 새로 병합된 코드를 실행할 때 에러가 발생하면, 인라이닝이 잘못 실행되었을 가능성이 있다. 그러한 경 우에, 원래 함수 1과 2는 여전히 유지되고, 분리된 함수 호출을 사용하여 인라이닝되지 않은 방식으로 서로 독 립적으로 실행될 수 있다. 향상된 FaaS 시스템의 일부 실시예는 추가적으로 또는 대안적으로 아웃라이닝(outlining) 기술을 활용할 수 있 다. 예를 들어, 일부 실시예는 실행될 가능성이 더 낮은 동일한 함수의 부분을 제거할 수 있다(예를 들어, 거 의 실행되지 않도록 if-else 문으로부터 else 문을 제거함). 제거된 부분은 별개의 프로그램/함수로서 구성될 수 있다. 아웃라이닝은 유리하게도 각각의 함수에 대해 더 작은 다운로드를 제공할 수 있다. 동적 프로파일링 은 코드에서 경로의 \"핫니스(hotness)\" 정보(예를 들어, 확률 또는 빈도)를 식별하고, 사용을 위해 향상된 FaaS 시스템에 핫니스 정보를 저장할 수 있다. 예를 들어, 동일한 함수의 상이한 경로가 식별될 수 있고, 이어서 경 로들 각각이 발생할 가능성을 결정하기 위해 핫니스 정보와 대조하여 참조될 수 있다. 임계치 초과의 관련 핫 니스 정보(예를 들면, 발생 확률 또는 빈도)를 갖는 경로가 유지된다. 임계치 초과인 핫니스 정보를 갖지 않는 다른 경로는 제거되고 별개의 프로그램/함수로서 배치된다. 하나의 특정 예에서, 함수는 \"if-else\"문을 가질 수 있다. 핫니스 정보는 \"if\"문이 100% 실행 확률을 갖는 반 면, \"else\"문이 10% 실행 확률을 가진다는 것을 나타낸다. 임계치가 30% 확률로 설정된 경우, 시스템은 \"if\"문 은 유지되어야 하지만 \"else\"문은 제거되고 별개의 함수 호출로서 배치되어야 한다고 결론을 내릴 수 있다. 그 렇지만, 핫니스 정보가 \"else\"문 확률이 40%라고 나타내는 경우, 시스템은 \"else\"문이 제거되지 않고 유지되어 야 한다고 결론을 내릴 수 있다. 임계치는 이용 가능한 하드웨어, 캐시 이용 가능성, 대역폭 이용 가능성, 함 수의 우선순위 정보(예를 들면, 함수가 높은 우선순위를 갖고 짧은 시간에 완료하는 것이 필수적인 경우, 함수 를 분해하지 않음) 등과 같은, 상이한 인자에 기초하여 동적으로 설정될 수 있다. 향상된 FaaS 시스템의 일부 실시예는 동일한 데이터에 대해 동작하는 함수(예를 들어, 그렇지 않았으면 관련이 없을 수 있음)를 식별하고 함수를 데이터와 동일한 위치에 둘 수 있다. 일부 실시예는 임의의 병합/분해를 수 행할지를 식별하기 위한 메트릭(예를 들어, 모든 함수에 대한 최소 5분 실행 시간)을 결정할 수 있다. 함수 재사용을 용이하게 하기 위한 상태 집계 및 분할 예 많은 FaaS 프레임워크는 \"순수\" 또는 무상태인 함수의 재사용이라는 개념을 지원할 수 있다. 따라서, 컨테이너 는 실용적인 목적으로 내부 상태가 일정하지만 들어오는 파라미터로서 새로운 입력을 제공받을 수 있는 함수에 대한 메모리 레이아웃으로 초기화될 수 있다. 그 무상태 함수는 이어서 출력(예를 들어, 다시 말하지만 함수의 상태의 일부가 아님)을 생성할 수 있다. 이러한 무상태가 항상 유익한 것은 아니다. 때때로 더 큰 인텐트(intent)는 (예를 들어, 해당 인텐트를 하나의 함수로부터 다른 함수로 데이터를 명시적으로 이동시켜야 하는 별개의 함수로 항상 분해하는 대신에) 공통 상태를 우연히 업데이트하는 다른 하위 모듈에 매핑되는 단일 컨테 이너에 의해 가장 잘 충족될 수 있다. 추가적으로, 필요한 함수들의 합집합이 너무 커서 단일 컨테이너에 들어 가지 않는 경우, 또는 컨테이너를 분해하는 것이 모듈성을 위해 바람직한 경우, 함수들의 체인에서 하나의 함수 로부터 다른 함수로의 필요한 출력 흐름은 많은 데이터 이동 및 메모리 관리 오버헤드를 추가한다. 이제 도 27a를 살펴보면, 향상된 FaaS 시스템의 실시예는 디스크립터와 같은 구성 관련 정보의 활 용을 통해 2개 이상의 하위 함수(예를 들면, 하위 함수 A 내지 하위 함수 N)에 의해 공유될 수 있는 메모 리를 포함할 수 있다. 향상된 FaaS 시스템의 일부 실시예는 유리하게도 컨테이너의 불필요한 단편 화의 오버헤드를 피하기 위한 기술을 제공할 수 있다. 예를 들어, 데이터 온톨로지는 상태의 동적 표현 및 탐 색을 제공할 수 있다. 예를 들어, 하나의 함수로부터 다른 함수로 출력으로서 논리적으로 전달되어야 하는 상 태의 총량은 디스크립터의 계층 구조로 분할되고 온톨로지를 사용하여 기술될 수 있다. 디스크립터의 계층구조 는 하위 함수들 간의 공유 온톨로지에 따라 소비 함수에서의 총 정보가 어떻게 집계되는지를 기술할 수 있다. 결과적으로, 이전 함수 X로부터 다음 함수 Y로 변경될 필요가 없는 상태 정보는 X로부터 Y로 전달되는 공통 디 스크립터 배후에 그대로 유지되며, 다른 모든 상태 정보는 Y에서 해당 공통 디스크립터 위의 오버레이(예를 들 면, 교체 또는 확장)로서 취급될 수 있다. 이러한 방식으로, 함수는 접근자(accessor) 기술로 액세스되는 데이 터에 대해 동작하도록 의도적으로 구성될 수 있으며, 이러한 접근자 기술은 디스크립터를 사용하기도 하고 필요 한 임의의 오버레이를 수행하기도 할 수 있으며, 따라서 각각의 하위 함수의 보디는 그 자체로 무상태로 유지된 다. 예를 들어, 일부 실시예는 하나의 메모리 영역으로부터 다른 메모리 영역으로 데이터를 이동시키는 일 없 이 \"데이터에 함수를 적용하는\" 개념을 따를 수 있다. 일부 실시예는 그 대신에 준비된 데이터에 대해 동작할 수 있지만 전달되는 디스크립터를 통해 간접적으로 동작할 수 있다. 도 27b는 궁극적으로 메모리 내의 객체 1 내지 객체 6을 참조하는 디스크립터 및 제1 및 제2 디스 크립터 그룹(2756, 2758)의 계층구조의 상세도를 도시한다. 디스크립터 및 디스크립터 그룹(2756 및 2758)의 계층구조는 프로그래머에 의해 명시적으로 정의될 수 있거나, 또는 메모리 내의 함수 및 객체에 대해 수행되는 데이터 흐름 분석에서 암시적으로 도달될 수 있으며, 여기서 그러한 데이터 흐름 분석은 프로그래머에 의해 명시적으로 개시되거나 또는 FaaS 시스템 자체에 의해 암시적으로 개시된다. 일부 실시예에 서, 프로그래머는 일부 객체를 명시적으로 지정하고 이들에 대한 디스크립터를 생성 및 사용하며 그를 계층구조 에 배치할 수 있는 반면, 다른 객체 및 그의 디스크립터는 파일 시스템, 심벌 테이블, 데이터베이스 등에서 객 체 명명 및 참조 메커니즘을 사용하여 계층구조로 구성될 수 있다. 이는 2개의 레벨의 디스크립터 전송을 도시 하지만, 계층구조 내의 상이한 레벨에서 다른 유형의 디스크립터 전송을 수행하는 것이 또한 가능하다. 제1 레 벨의 디스크립터 전송은 디스크립터를 포함한다. 디스크립터는, 하위 함수 B가 하위 함수 A에 의 해 이전에 액세스할 수 있었던 모든 객체에 액세스할 수 있도록, 하위 함수 A로부터 하위 함수 B로 최상위 레벨 디스크립터(예를 들면, 디스크립터 1)를 전송하는 것을 나타낸다. 예를 들어, 하위 함수 A가 실행을 완료한 후 에, 디스크립터 1이 하위 함수 B로 전달될 수 있다. 제2 레벨의 디스크립터 전송은 제1 및 제2 디스크립터 그 룹(2756, 2758)을 포함한다. 제1 및 제2 디스크립터 그룹(2756, 2758)은 제1 레벨의 디스크립터 전송을 통해 전송될 수 있는 새로운 최상위 레벨 디스크립터의 생성이다. 제1 및 제2 디스크립터 그룹(2756, 2758) 각각은 디스크립터 1로부터 참조되는 제2 레벨 디스크립터 2 내지 7의 절반만을 참조한다. 다양한 깊이의 다양한 디스 크립터 계층구조가 가능하다. 제1 레벨 디스크립터가 또한 제1 및 제2 디스크립터 그룹(2756, 2758) 중 상이한 그룹을 가리키도록 수정될 수 있다는 점에 주목할 가치가 있다. 추가 비고 및 예 예 2600은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 하나 이상의 과도 함수에 대한 구성 관련 정보를 제공하게 하고, 구성 관련 정보에 기초하여 하나 이상의 과도 함수의 실행을 수정하게 하며 - 수정 은 과도 함수들 중 하나 이상을 하나 이상의 하위 함수로 분할하는 것 및 병합하는 것 중 하나 이상을 포함할 수 있음 -, 과도 함수들 및 하위 함수들 중 하나 이상의 실행 사이에서 상태 정보를 공유하게 하고, 과도 함수 들 및 하위 함수들 중 하나 이상에 의해 활용되는 데이터와 공존하도록 과도 함수들 및 하위 함수들 중 하나 이 상을 이동시키게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 2601은 전자 프로세싱 시스템을 포함하고, 이 전자 프로세싱 시스템은 프로세서, 프로세서에 통신 가능하게 결합된 메모리, 및 하나 이상의 과도 함수에 대한 구성 관련 정보를 제공하고, 구성 관련 정보에 기초하여 하나 이상의 과도 함수의 실행을 수정하기 위해 프로세서 및 메모리에 통신 가능하게 결합된 로직을 포함한다.예 2602는 예 2601의 시스템을 포함하고, 여기서 로직은 추가로 과도 함수들 중 하나 이상을 하나 이상의 하위 함수로 분할한다. 예 2603은 예 2601 및 예 2602 중 어느 한 예의 시스템을 포함하고, 여기서 로직은 추가로 과도 함수들 및 하위 함수들 중 하나 이상을 병합한다. 예 2604는 예 2601 및 예 2602 중 어느 한 예의 시스템을 포함하고, 여기서 로직은 추가로 과도 함수들 및 하위 함수들 중 하나 이상의 실행 사이에서 상태 정보를 공유한다. 예 2605는, 하나 이상의 기판 및 하나 이상의 기판에 결합된 로직을 포함하는, 반도체 패키지 장치를 포함하며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현되고, 로 직은 하나 이상의 과도 함수에 대한 구성 관련 정보를 제공하고, 구성 관련 정보에 기초하여 하나 이상의 과도 함수의 실행을 수정하기 위해 하나 이상의 기판에 결합된다. 예 2606은 예 2605의 장치를 포함하고, 여기서 로직은 추가로 과도 함수들 중 하나 이상을 하나 이상의 하위 함 수로 분할한다. 예 2607은 예 2605 및 예 2606 중 어느 한 예의 장치를 포함하고, 여기서 로직은 추가로 과도 함수들 및 하위 함수들 중 하나 이상을 병합한다. 예 2608은 예 2605 및 예 2606 중 어느 한 예의 장치를 포함하고, 여기서 로직은 추가로 과도 함수들 및 하위 함수들 중 하나 이상의 실행 사이에서 상태 정보를 공유한다. 예 2609는 예 2605 내지 예 2608 중 어느 한 예의 장치를 포함하고, 여기서 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함한다. 예 2610은 서비스형 함수를 제공하는 방법을 포함하고, 이 방법은 하나 이상의 과도 함수에 대한 구성 관련 정 보를 제공하는 단계, 및 구성 관련 정보에 기초하여 하나 이상의 과도 함수의 실행을 수정하는 단계를 포함한다. 예 2611은 예 2610의 방법을 포함하며, 과도 함수들 중 하나 이상을 하나 이상의 하위 함수로 분할하는 단계를 추가로 포함한다. 예 2612는 예 2610 및 예 2611 중 어느 한 예의 방법을 포함하고, 과도 함수들 및 하위 함수들 중 하나 이상을 병합하는 단계를 추가로 포함한다. 예 2613은 예 2610 및 예 2611 중 어느 한 예의 방법을 포함하고, 과도 함수들 및 하위 함수들 중 하나 이상의 실행 사이에서 상태 정보를 공유하는 단계를 추가로 포함한다. 예 2614는, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 하나 이상의 과도 함수에 대한 구성 관련 정보를 제공하게 하고, 구성 관련 정보에 기초하여 하나 이상의 과도 함수의 실행을 수정하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 2615는 예 2611의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 과도 함수들 중 하나 이상을 하나 이상의 하위 함수로 분할하게 하는 추가 명령 어 세트를 포함한다. 예 2616은 예 2614 및 예 2615 중 어느 한 예의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 과도 함수들 및 하위 함수들 중 하나 이상을 병합하게 하는 추가 명령어 세트를 포함한다. 예 2617은 예 2614 및 예 2615 중 어느 한 예의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 과도 함수들 및 하위 함수들 중 하나 이상의 실행 사이 에서 상태 정보를 공유하게 하는 추가 명령어 세트를 포함한다. 컨테이너 값 해시 캐시 예 향상된 FaaS 시스템의 일부 실시예는 유리하게도 컨테이너 값 해시 캐시를 제공할 수 있다. 컨테이너 값은 컨 테이너에 저장될 수 있는 임의의 유형의 데이터(예를 들면, KV 저장소, 텍스트, 코드, 압축된 실행 가능 이미지, 함수 호출에 사용된 파라미터, 함수 실행으로부터의 결과 등)에 대응할 수 있다. 메모리는 제한된 리소스이며, 컨테이너 값은 메모리 공간을 차지한다. 일부 컨테이너 값은 많은 함수에 의해 사용될 수 있으며, 이러한 컨테이너 값을 로딩/재로딩하기 위해 IO 대역폭이 필요하다. 일부 실시예는 공유 컨테이너 값에 액세스 하는 데 필요한 메모리의 양을 줄이기 위해 해시 인덱스를 제공할 수 있다. 일부 실시예에서, 공유 컨테이너 값이 캐시에 로딩될 수 있다. 일부 실시예는 컨테이너 값을 재로딩하는 오버헤드를 피하기 위해 하나 이상의 컨테이너 값을 고정할 수 있다(예를 들어, 캐시/메모리에 지속적으로 유지될 컨테이너 값에 마킹함). 이제 도 28a를 살펴보면, 서비스형 함수를 제공하는 방법의 실시예는, 블록에서, 2개 이상의 과도 함수 사이에 공유된 해시 테이블에 공유 컨테이너 값을 저장하는 단계, 및 블록에서, 공유 해시 테이블에 저장된 공유 컨테이너 값을 해시 인덱스를 사용하여 액세스하는 단계를 포함할 수 있다. 방법의 일부 실 시예는, 블록에서, 공유 해시 테이블을 캐싱하는 단계를 추가로 포함할 수 있다. 방법은, 블록 에서, 공유 해시 테이블 내의 공유 컨테이너 값을 피닝(pinning)하는 단계를 또한 포함할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 예를 들어, 방법은 아래의 예 2811 내지 예 2813과 관련하여 설명된 바와 같이 컴퓨터 판독 가능 매체 상 에 구현될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그 래밍 인터페이스(API)를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 도 28b와 관련하여 아래에서 설명되는 것과 같은 향상된 FaaS 시스템의 일부 실시예는 유리하게도 컨테이 너 값 해시 캐시를 제공할 수 있다. 일부 다른 FaaS 시스템에서, 반복적인 상수는 함수들 간에 공유되지 않는 다. 일부 다른 FaaS 시스템에서, 함수가 값을 공유하지 않도록 함수가 상이하게 취급된다. 향상된 FaaS 시스 템의 일부 실시예는 유리하게도 컨테이너에 의해 이용되는 공유 상수를 저장하기 위해 해시 테이블을 제 공할 수 있다. 함수는 유리하게도 해시 테이블을 참조하며 이에 의해 그렇지 않았으면 공유 컨테이너 값(들)을 로딩하는 데 필요할 수 있는 IO 대역폭, 메모리 공간, 전력 이용, 컴퓨팅 리소스 등을 절감할 수 있다. 이제 도 28b를 살펴보면, 향상된 FaaS 시스템의 실시예는 하나 이상의 과도 함수에 의해 공유될 수 있는 해시 테이블을 포함할 수 있다. 해시 테이블은 대응하는 공유 컨테이너 상수 값(예를 들어, C1 내지 CN)을 리턴하도록 해시 값(예를 들어, H1 내지 HN)에 의해 인덱싱될 수 있다. 향상된 FaaS 시스템의 일부 실시예는 프로세스/람다/컨테이너가 시작될 때 채워질 수 있는 상수 값 캐시 를 제공할 수 있고 큰 상수 값(예를 들면, 고속 푸리에 변환(FFT), 신경 네트워크 필터 값 등을 계산하기 위한 트위들 인자(twiddle factor))을 별도의 캐시에 저장할 수 있다. 예를 들어, 64개의 상이한 double float 상 수(예를 들어, 각각 64 비트)의 경우, 일부 실시예는 이들에 액세스하기 위해 6 비트 인덱스(예를 들어, 64개의 상이한 상수를 인덱싱하기 위한 26개의 인덱스 값)를 사용할 수 있다. 이러한 값은 컴파일 시간 또는 로드 시간 (예를 들어, 워밍업된 신경 네트워크 컨테이너에 추론 람다를 주입할 때) 상수일 수 있다. 컴파일러/JIT/코드 생성기는 먼저 특수 저장 명령어를 사용하여 람다/컨테이너 초기화의 시작에서 상수 값을 상수 값 캐시에 로딩 할 수 있다. 이후에 상수 값에 대응하는 정규 로드는 상수 값 캐시에 대한 인덱스를 나타내는 특수 로드 명령 어로 대체될 수 있다. 향상된 FaaS 시스템의 일부 실시예는 유리하게도 로드의 더 컴팩트한 인코딩에 의 해 캐시 성능을 개선시킬 수 있다. 예를 들어, 메모리 참조를 위해 요구되는 특정 아키텍처 명령어 포맷의 일 부 필드(예를 들어, 어드레싱 모드를 지정하는 MOD 필드, 및 메모리 어드레스를 계산하기 위한 스케일, 인덱스 및 베이스를 지정하는 SIB 필드)는 상수 값 캐시에 대한 참조에 필요하지 않을 수 있다. 일부 실시예는 또한 MOB(memory ordering buffer) 엔트리를 해제하고, 상수 값 캐시로부터의 로드 명령어 판독을 위해 저장 전달(store forwarding) 등에 대해 검사할 요구사항을 제거할 수 있다. 향상된 FaaS 시스템의 일부 실시예는 또한 상수가 상수 값 캐시에 고정되고 킥아웃(kick out)되지 않을 것임을 보장할 수 있다. 예를 들어, CNN(convolutional neural network) 필터 값은 추론 중에 매우 자주 사용 될 수 있다. 필터 값은 일정할 수 있지만, 많은 수의 입/출력 채널은 CNN의 작업 세트를 캐시의 용량보다 훨씬 더 크게 만들 수 있다. 결과적으로, 필터 값은 캐시 내에 상주할 수 없으며 일부 다른 시스템에서는 여러 상이 한 함수 호출을 통해 메모리에서 매번 다시 가져와질 수 있으며, 이는 비용이 많이 들고 성능에 영향을 미칠 수 있다. 향상된 FaaS 시스템의 일부 실시예에서, 상수 값 캐시는 한 번 로딩되고 다수의 람다/프로세스(예 를 들어, 동일한 CNN 필터 값을 사용하는 다수의 추론 람다를 포함함) 간에 공유될 수 있으며, 이는 유리하게도 컴퓨트, 메모리 및/또는 IO 리소스를 절감할 수 있다. 추가 비고 및 예 예 2801은 전자 프로세싱 시스템을 포함하고, 이 전자 프로세싱 시스템은 프로세서, 프로세서에 통신 가능하게 결합된 메모리, 및 2개 이상의 과도 함수 사이에 공유된 해시 테이블에 공유 컨테이너 값을 저장하고, 공유 해 시 테이블에 저장된 공유 컨테이너 값을 해시 인덱스를 사용하여 액세스하기 위해 프로세서 및 메모리에 통신 가능하게 결합된 로직을 포함한다. 예 2802는 예 2801의 시스템을 포함하고, 여기서 로직은 추가로 공유 해시 테이블을 캐싱한다. 예 2803은 예 2801 및 예 2802 중 어느 한 예의 시스템을 포함하고, 여기서 로직은 추가로 공유 해시 테이블 내 의 공유 컨테이너 값을 피닝한다. 예 2804는, 하나 이상의 기판 및 하나 이상의 기판에 결합된 로직을 포함하는, 반도체 패키지 장치를 포함하며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현되고, 로 직은 2개 이상의 과도 함수 사이에 공유된 해시 테이블에 공유 컨테이너 값을 저장하고, 공유 해시 테이블에 저 장된 공유 컨테이너 값을 해시 인덱스를 사용하여 액세스하기 위해 하나 이상의 기판에 결합된다. 예 2805는 예 2804의 장치를 포함하고, 여기서 로직은 추가로 공유 해시 테이블을 캐싱한다. 예 2806은 예 2804 및 예 2805 중 어느 한 예의 장치를 포함하고, 여기서 로직은 추가로 공유 해시 테이블 내의 공유 컨테이너 값을 피닝한다. 예 2807은 예 2804 내지 예 2806 중 어느 한 예의 장치를 포함하고, 여기서 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함한다. 예 2808은 서비스형 함수를 제공하는 방법을 포함하고, 이 방법은 2개 이상의 과도 함수 사이에 공유된 해시 테 이블에 공유 컨테이너 값을 저장하는 단계, 및 공유 해시 테이블에 저장된 공유 컨테이너 값을 해시 인덱스를 사용하여 액세스하는 단계를 포함한다. 예 2809는 예 2808의 방법을 포함하며, 공유 해시 테이블을 캐싱하는 단계를 추가로 포함한다. 예 2810은 예 2808 및 예 2809 중 어느 한 예의 방법을 포함하고, 공유 해시 테이블 내의 공유 컨테이너 값을 피닝하는 단계를 추가로 포함한다. 예 2811은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 2개 이상의 과도 함수 사이에 공유된 해시 테이블에 공유 컨테이너 값을 저장하게 하고, 공유 해시 테이블에 저장된 공유 컨테이너 값을 해시 인덱스 를 사용하여 액세스하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 2812는 예 2811의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 공유 해시 테이블을 캐싱하게 하는 추가 명령어 세트를 포함한다. 예 2813은 예 2811 및 예 2812 중 어느 한 예의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 공유 해시 테이블 내의 공유 컨테이너 값을 고정하게 하 는 추가 명령어 세트를 포함한다. 역/실행취소 컨테이너 예 향상된 FaaS 시스템의 일부 실시예는 유리하게도 역/실행취소 컨테이너를 제공할 수 있다. FaaS 시스템에서, 취소 요청 또는 충돌은 일부 리소스를 불확정 상태로 남길 수 있다. 일부 실시예에서, 충돌/취소 요청에 의해 영향을 받는 리소스를 정리하기 위해 역/실행취소 함수가 등록될 수 있다. 일부 실시예는 더 나은 리소스 이용률 및/또는 더 적은 불확정 상태를 제공할 수 있다. 이제 도 29a를 살펴보면, 서비스형 함수를 제공하는 방법의 실시예는, 블록에서, 과도 함수가 관련 정리 함수를 갖는지를 결정하는 단계, 및 블록에서, 과도 함수가 인터럽트되는 경우 관련 정리 함수를 실 행하는 단계를 포함할 수 있다. 방법의 일부 실시예는, 블록에서, 정리 함수를 자동으로 생성하는 단계를 추가로 포함할 수 있다. 방법은, 블록에서, 정리 함수를 자동으로 등록하는 단계를 또한 포함할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 예를 들어, 방법은 아래의 예 2911 내지 예 2913과 관련하여 설명된 바와 같이 컴퓨터 판독 가능 매체 상 에 구현될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그 래밍 인터페이스(API)를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 일부 FaaS 시스템은 무상태로 간주될 수 있다. \"무상태\" FaaS 시스템의 예는 FaaS 시스템에 의해 실행중인 함 수의 모니터링된 상태가 없다는 것이다. 시스템 또는 함수가 충돌하면, 기록된 상태가 없기 때문에 문제가 발 생할 수 있다. 예를 들어, 함수가 일부 데이터를 수정하고 이어서 충돌하는 경우, 시스템은 함수를 어디에서 가져올지 또는 계속하여 함수를 종결하고 정리하며 다시 시작할지를 결정하지 못할 수 있다(예를 들어, FaaS 시 스템은 어떤 데이터를 실행취소할지를 알지 못함). 도 29b에 도시된 것과 같은 향상된 FaaS 시스템의 일 부 실시예는 유리하게도 원래 함수에 대한 역으로서 손상을 실행취소하는 특수 함수(예를 들어, 상보적이거나 동일한 함수에 포함됨)을 제공할 수 있다. 이제 도 29b를 살펴보면, 향상된 FaaS 시스템의 실시예는 완료 이전에 중단될 수 있는 함수 f(x)를 호출 할 수 있다. 예를 들어, 그러한 중단은 함수의 취소, 함수 f(x)의 충돌, FaaS 시스템의 충돌, 필요한 리 소스의 손실 등에 대응할 수 있다. FaaS 시스템은 함수 f(x)의 중단으로 인해 야기되는 하나 이상의 문 제를 해결하기 위해 정리 함수 f-1(x)를 호출할 수 있다. 예를 들어, 함수 f-1(x)는 실행취소 함수, 역 함수 (inverse function), 역 함수(reverse function) 등으로 간주될 수 있다. 전통적인 FaaS 함수, 예를 들면, Amazon Web Services(AWS) LambdaTM은 무상태로 간주되며, 이는 외부에서 보이 는 부작용을 가질 수 있다. 예를 들어, 람다 함수는 데이터베이스 엔트리를 업데이트하거나 외부에서 보이는 어떤 다른 부작용을 자체적으로 가질 수 있는 다른 람다 함수를 호출할 수 있다. 예를 들어, 아이템 배달에 대 한 주문은 일련의 FaaS 함수/람다 함수를 호출할 수 있다. 주문이 임의의 시점에서 취소되면, 취소 요청이 전 파될 필요가 있으며 특정 업데이트/액션이 실행취소될 필요가 있을 수 있다. 향상된 FaaS 시스템의 일부 실시예는 부작용 등을 실행취소하기 위해 JSON 객체와 같은 원래 파라미터로 동일한 체인을 호출함으로써 실행 취소 함수를 수행할 수 있다. 향상된 FaaS 시스템의 일부 실시예는 부작용을 정리하기 위해 실제 람다 대신에 호출될 FaaS 함수/람다 함수의 역/실행취소 버전을 등록할 수 있으며, 실행취소 람다 함수는 애플리케이션 개발자에 의해 제공될 수 있 거나 또는 코드 생성기에 의해 자동으로 생성될 수 있다. 예를 들어, 실행취소 람다 함수는 실행취소 로깅의 조합을 포함할 수 있으며, (예를 들어, 멤버 객체를 삭제하기 위한 C ++ 소멸자 호출과 유사한) 상향식, 모듈식 방식으로 역방향 슬라이스 생성을 활용할 수 있다.추가 비고 및 예 예 2901은 전자 프로세싱 시스템을 포함하고, 이 전자 프로세싱 시스템은 프로세서, 프로세서에 통신 가능하게 결합된 메모리, 및 과도 함수가 관련 정리 함수를 갖는지를 결정하고, 과도 함수가 인터럽트되는 경우 관련 정 리 함수를 실행하기 위해 프로세서 및 메모리에 통신 가능하게 결합된 로직을 포함한다. 예 2902는 예 2901의 시스템을 포함하고, 여기서 로직은 추가로 정리 함수를 등록한다. 예 2903은 예 2901 및 예 2902 중 어느 한 예의 시스템을 포함하고, 여기서 로직은 추가로 정리 함수를 자동으 로 생성한다. 예 2904. 반도체 패키지 장치로서, 하나 이상의 기판, 및 하나 이상의 기판에 결합된 로직을 포함하며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현되고, 로직은 과 도 함수가 관련 정리 함수를 갖는지를 결정하고, 과도 함수가 인터럽트되는 경우 관련 정리 함수를 실행하기 위 해 하나 이상의 기판에 결합된다. 예 2905는 예 2904의 장치를 포함하고, 여기서 로직은 추가로 정리 함수를 등록한다. 예 2906은 예 2904 및 예 2905 중 어느 한 예의 장치를 포함하고, 여기서 로직은 추가로 정리 함수를 자동으로 생성한다. 예 2907은 예 2904 내지 예 2906 중 어느 한 예의 장치를 포함하고, 여기서 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함한다. 예 2908. 서비스형 함수를 제공하는 방법으로서, 과도 함수가 관련 정리 함수를 갖는지를 결정하는 단계, 및 과도 함수가 인터럽트되는 경우 관련 정리 함수를 실행하는 단계를 포함한다. 예 2909는 예 2908의 방법을 포함하며, 정리 함수를 등록하는 단계를 추가로 포함한다. 예 2910은 예 2908 및 예 2909 중 어느 한 예의 방법을 포함하고, 정리 함수를 자동으로 생성하는 단계를 추가 로 포함한다. 예 2911. 적어도 하나의 컴퓨터 판독 가능 저장 매체로서, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이 스로 하여금 과도 함수가 관련 정리 함수를 갖는지를 결정하게 하고, 과도 함수가 인터럽트되는 경우 관련 정리 함수를 실행하게 하는 명령어 세트를 포함한다. 예 2912는 예 2911의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 정리 함수를 등록하게 하는 추가 명령어 세트를 포함한다. 예 2913은 예 2911 및 예 2912 중 어느 한 예의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 정리 함수를 자동으로 생성하게 하는 추가 명령어 세트 를 포함한다. 컨테이너 연속 전달 스타일 예 도 4에 도시된 것과 같은 향상된 FaaS 시스템의 일부 실시예는 유리하게도 컨테이너에 대한 연속 전달 스타일을 제공할 수 있다. FaaS 함수는 독립적인 실행 단위이며 상이한 FaaS 함수가 어떤 관계(예를 들면, 함수 간 데이 터 전달)를 가질 때 추가 오버헤드가 발생할 수 있다. 향상된 FaaS 시스템의 일부 실시예는 함수 호출 간에 정 보를 핸드 오프(hand off)하기 위한 패스 다운(pass down) 능력을 제공할 수 있다. 일부 실시예에서, 조건부 함수 호출은 패스 다운 데이터의 일부일 수 있다. 유리하게도, 일부 실시예는 더 나은 리소스 이용률, 감소된 IO 대역폭, 및/또는 더 빠른 실행을 제공할 수 있다. 이제 도 30a를 살펴보면, 서비스형 함수를 제공하는 방법의 실시예는, 블록에서, 과도 함수의 파라 미터로서 연속 함수를 포함하는 과도 함수를 실행하는 단계, 및 블록에서, 과도 함수로부터 연속 함수를 실행하는 단계를 포함할 수 있다. 방법의 일부 실시예는, 블록에서, 연속 함수에 대한 코드, 컨텍 스트, 및 데이터 중 하나 이상을 재귀적으로 패스 다운하는 단계를 추가로 포함할 수 있다. 예를 들어, 방법 은, 블록에서, 연속 함수의 일부로서 복구 코드를 패스 다운하는 단계를 포함할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 예를 들어, 방법은 아래의 예 3011 내지 예 3013과 관련하여 설명된 바와 같이 컴퓨터 판독 가능 매체 상 에 구현될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그 래밍 인터페이스(API)를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트를 포함할 수 있다. 일부 FaaS 시스템에서, 함수는 독립적인 기능 유닛이며, 상이한 위임 전술이 성능에 영향을 미칠 수 있기 때문 에, 상이한 함수 간에 위임 문제가 발생할 수 있다. 도 30b에 도시된 바와 같은 향상된 FaaS 시스템의 일부 실시예는 유리하게도 함수 실행 성능을 개선시키기 위해 람다 함수 또는 다른 함수와 같은 연속 함수를 다 른 피호출자 함수에 전달할 수 있다. 이것은 다수의 함수에 걸쳐 \"멱등성(idempotency)\"을 시행하는 메커니즘 으로 간주될 수 있으며, 멱등 함수를 실행하는 것이 더 성능이 좋을 수 있다. 다른 함수의 임의의 인터리빙된 실행 없이 함수가 몇 번 호출되는지에 관계없이 함수의 모든 인스턴스가 실행을 완료한 후에 함수에 의해 액세 스된 시스템 상태 및/또는 기본 데이터가 동일한 값을 갖는 경우 부작용이 있는 함수는 멱등성이 있는 것으로 간주될 수 있다. 함수는 처음에는 부작용이 없는 것으로 간주될 수 있지만, 함수가 외부적으로 공유된 리소스 (예를 들어, 데이터베이스 및/또는 데이터 구조)를 수정하여, 이에 의해 부작용을 결과하는 사용 사례가 있다. 함수 호출의 비동기적 성질을 고려하여, 본 명세서에서 논의된 접근법은 변경 동작(예를 들어, 데이터베이스 및 /또는 데이터 구조와 같은 외부적으로 공유된 리소스를 수정하는 함수)의 실행을 호출 체인 내의 마지막 함수에 위임한다. 이제 도 30b를 살펴보면, 향상된 FaaS 시스템의 실시예는 함수 f가 함수 g를 호출하기 위해 데이터 및 코 드를 패스 다운할 수 있고, 함수 g가 함수 h를 호출하기 위해 데이터 및 코드를 패스 다운할 수 있으며 이하 마 찬가지일 수 있는 재귀적 함수 호출을 포함할 수 있다. 즉, 각각의 연속 함수는 부모 함수의 현재 함수 상태로 업데이트되고, 이어서 연속 함수의 현재 함수 상태를 자식 함수로 추가로 패스 다운한다. 따라서 예시된 예에 서, 함수 f는 현재 함수 상태 데이터(cont_f)를 함수 g에 패스 다운한다. 즉, \"cont_f\"는 함수 g를 호출하고 함수 f의 현재 함수 상태로 간주된다. 함수 g는 함수 f의 현재 함수 상태를 수신하고 함수 상태를 \"cont_f. g.\"로 업데이트하며 이는 또한 함수 h를 호출하며 이하 마찬가지이다. 따라서, 호출은 또한 리버스 엔지니어링 및/또는 디버깅이 가능하도록 함수 상태의 명확한 대응을 유지하는 역할을 한다. 향상된 FaaS 시스템의 일부 실시예는 코드, 데이터, 컨텍스트 등을 피호출자 함수에 패스 다운할 수 있는 기술/능력을 함수 호출에 추가할 수 있다. 피호출자 함수는 이어서 코드, 데이터, 컨텍스트 등을 재귀적으로 패스 다운할 수 있다. 예를 들어, 함수 g는 함수 g에 데이터를 전달하는 함수 f의 피호출자이고; 함수 h는 함 수 h에 데이터를 전달한 함수 g의 피호출자이다. 향상된 FaaS 시스템의 일부 실시예는 유리하게도 특정 요구사항이 충족될 때까지 특정 동작(예를 들어, 외부에서 보이는 부작용이 있는 액션)의 지연된 실행을 가능하 게 할 수 있다. 향상된 FaaS 시스템의 일부 실시예는 또한 함수 상태의 상기 대응을 통해 함수 호출 체 인 동안 특정 예외/조건이 발생하는 경우 패스 다운 복구/롤백 코드가 실행될 수 있게 할 수 있다. 유리하게도, 향상된 FaaS 시스템의 일부 실시예는 탄력적인 솔루션을 구현하고 적절한/효율적인 예외 핸 들링을 가능하게 하는 데 도움이 될 수 있다. 향상된 FaaS 시스템의 일부 실시예는 컨텍스트 및 데이터 구조가 프로토콜 버퍼와 같은 표준 데이터 교환 포맷으로 전달될 수 있는 연속 전달 스타일을 지원할 수 있다. 실행될 코드는 람다 함수에 캡슐화될 수 있으며, 람다 어드레스/ID도 컨텍스트와 함께 전달될 수 있다. 일부 실시예에서, 람다 코드의 복구/지연된 부 작용은 원래 람다로부터 컴파일러/코드 생성기에 의해 추출될 수 있다. 추가 비고 및 예 예 3001은 전자 프로세싱 시스템을 포함하고, 이 전자 프로세싱 시스템은 프로세서, 프로세서에 통신 가능하게 결합된 메모리, 및 과도 함수의 파라미터로서 연속 함수를 포함하는 과도 함수를 실행하고, 과도 함수로부터 연 속 함수를 실행하기 위해 프로세서 및 메모리에 통신 가능하게 결합된 로직을 포함한다. 예 3002는 예 3001의 시스템을 포함하고, 여기서 로직은 추가로 연속 함수에 대한 코드, 컨텍스트, 및 데이터 중 하나 이상을 재귀적으로 패스 다운한다. 예 3003은 예 3001 및 예 3002 중 어느 한 예의 시스템을 포함하고, 여기서 로직은 추가로 연속 함수의 일부로 서 복구 코드를 패스 다운한다. 예 3004는, 하나 이상의 기판 및 하나 이상의 기판에 결합된 로직을 포함하는, 반도체 패키지 장치를 포함하며, 여기서 로직은 구성 가능한 로직 및 고정 기능 하드웨어 로직 중 하나 이상에 적어도 부분적으로 구현되고, 로 직은 과도 함수의 파라미터로서 연속 함수를 포함하는 과도 함수를 실행하고, 과도 함수로부터 연속 함수를 실 행하기 위해 하나 이상의 기판에 결합된다. 예 3005는 예 3004의 장치를 포함하고, 여기서 로직은 추가로 연속 함수에 대한 코드, 컨텍스트, 및 데이터 중 하나 이상을 재귀적으로 패스 다운한다. 예 3006은 예 3004 및 예 3005 중 어느 한 예의 장치를 포함하고, 여기서 로직은 추가로 연속 함수의 일부로서 복구 코드를 패스 다운한다. 예 3007은 예 3004 내지 예 3006 중 어느 한 예의 장치를 포함하고, 여기서 하나 이상의 기판에 결합된 로직은 하나 이상의 기판 내에 배치되는 트랜지스터 채널 영역을 포함한다. 예 3008. 서비스형 함수를 제공하는 방법으로서, 과도 함수의 파라미터로서 연속 함수를 포함하는 과도 함수를 실행하는 단계, 및 과도 함수로부터 연속 함수를 실행하는 단계를 포함한다. 예 3009는 예 3008의 방법을 포함하며, 연속 함수에 대한 코드, 컨텍스트, 및 데이터 중 하나 이상을 재귀적으 로 패스 다운하는 단계를 추가로 포함한다. 예 3010은 예 3008 및 예 3009 중 어느 한 예의 방법을 포함하고, 연속 함수의 일부로서 복구 코드를 패스 다운 하는 단계를 추가로 포함한다. 예 3011. 적어도 하나의 컴퓨터 판독 가능 저장 매체로서, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이 스로 하여금 과도 함수의 파라미터로서 연속 함수를 포함하는 과도 함수를 실행하게 하고, 과도 함수로부터 연 속 함수를 실행하게 하는 명령어 세트를 포함한다. 예 3012는 예 3011의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 연속 함수에 대한 코드, 컨텍스트, 및 데이터 중 하나 이상을 재귀적으로 패스 다운하게 하는 추가 명령어 세트를 포함한다. 예 3013은 예 3011 및 예 3012 중 어느 한 예의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 연속 함수의 일부로서 복구 코드를 패스 다운하게 하는 추가 명령어 세트를 포함한다. 편리한 컨테이너 구성 및 캐시 관리 예 FaaS 시스템은 주기적인 이벤트 및 랜덤한 이벤트를 갖는 이벤트 기반 모델일 수 있다. 그와 같이, 함수가 실 행 중에 이용할 데이터 세트(예를 들어, 데이터 객체)를 포함하는 동일하거나 유사한 컨테이너를 동일한 함수 및/또는 함수가 이용하는 상황이 일반적으로 발생한다. 함수는 짧은 시간 기간 내에 여러 번 실행될 수 있다. 일부 아키텍처에서, 웜 컨테이너 접근법을 통해 컨테이너가 재사용될 수 있는 일부 경우를 제외하고는 함수 실 행마다 새로운 컨테이너가 사용될 수 있다. 웜 컨테이너를 유지하는 것은 리소스를 불필요하게 소비할 수 있다. 예를 들어, 웜 컨테이너는 함수가 실행되기를 기다리는 동안 유휴인 채로 유지될 수 있다. 유휴 시간은 비생산적일 수 있다. 더욱이, 컨테이너 재사용 또는 공유는 컨테이너에 특정적일 수 있고 모든 상황에 적용 가 능한 것은 아닐 수 있다. 이와 달리, 웜 컨테이너는 해체될 수 있으며, 함수가 호출될 때 콜드 컨테이너가 시작될 수 있다. 컨테이너를 빌드, 개시 또는 시작하는 것은, 네임스페이스 및 제어 그룹을 구성하는 것, 네트워크를 셋업하는 것, 및 실행 환경을 셋업하는 것과 같은, 여러 스테이지를 포함할 수 있다. 실행 환경은 사용자 데이터 및 기타 요구사항을포함할 수 있다. 일부 다른 요구사항은 다양한 키, CPU/메모리/디스크 용량 예약 또는 우선순위, 데이터베이스, 데이터 세트, 키 값 저장소, 변환 사전, 리소스 사용 크레딧 등을 포함할 수 있다. 다른 요구사 항의 추가 예는 한 번 열리고 이어서 재사용을 위해 캐싱되며 그리고/또는 실행 파일의 분해된 이미지를 캐싱한 신경 네트워크, 파일 또는 네트워크 디스크립터를 또한 포함할 수 있다. 위에서 설명된 바와 같이, 컨테이너 시작 시간(콜드 컨테이너 시작)은 사소하지 않은 레이턴시를 갖고 리소스를 소비한다. 컨테이너 시작 시간은 FaaS 성능에 영향을 미칠 수 있으며, 시작 시간의 감소는 바람직하다. 이제 도 31a를 참조하면, 웜 컨테이너를 이용하지 않으면서 그리고/또는 컨테이너를 빌드하는 데 필요한 모든 데이터를 저장하지도 않으면서 컨테이너가 편리한 방식으로 재빌드될 수 있는 FaaS 예가 예시된다. 예 의 향상된 FaaS 아키텍처는 캐시, 캐시 제어기, 보유 정책 관리자 및 시작 타이머 를 포함할 수 있다. 캐시, 캐시 제어기, 보유 정책 관리자 및 시작 타이머는 동일한 컴퓨트 노드(예를 들어, 컴퓨팅 디바이스, 서버, 모바일 디바이스 등)의 일부일 수 있다. 아래에서 더 상세히 설명되는 바와 같이, 향상된 FaaS 아키텍처는 컨테이너의 서브세트를 식별하고 컨테이너 전체를 회수하 거나 해체하기보다는 서브세트를 저장할 수 있다. 서브세트는 작업 세트라고 불릴 수 있다. 그렇게 함으로써, 리소스 소비를 감소시키기 위해 웜 컨테이너가 해체될 수 있으며, 레이턴시를 줄이기 위해 필요할 때 컨테이너 가 신속하게 재빌드될 수 있다. 따라서, 컨테이너의 리소스는 작업 세트라고 지칭될 수 있다. 따라서, 컨테이너의 덜 활성인 부분이 제거될 수 있게 하면서 \"핫\" 활성 작업 세트는 캐시에 이미 저장되어 있을 수 있다. 예를 들어, 공유 작업 세트는 함수들 간에 공유되는 세트일 수 있으며, 가중치, 상수, 공식, 공통 데이터(예를 들어, 이름, 이미지, 맵 등)의 데이터베이스, 사용자 데이터, 다양한 키, CPU/메모리/디스크 용량 예약 또는 우선순위, 데이터 세트, 키 값 저 장소, 변환 사전, 리소스 사용 크레딧, 한 번 열리고 이어서 재사용을 위해 캐싱되며 그리고/또는 실행 파일의 분해된 이미지를 캐싱한 신경 네트워크, 파일 또는 네트워크 디스크립터를 포함할 수 있다. 그러한 작업 세트 는 캐시에 보관되고, 작업 세트에 대한 액세스를 허용하기 위해, FaaS 아키텍처에 의해 관리될 수 있다. 각각의 작업 세트는 함수가 작업 세트에 액세스할 때마다 확장되는 생존 시간을 할당받을 수 있다. 작업 세트 는 데이터의 사용 빈도(아래에서 설명됨)는 물론 작업 세트 없이 컨테이너를 개시하기 위한 시작 시간의 측정치 및 생존 시간에 기초하여 캐시로부터 축출될 수 있다. 예를 들어, 작업 세트가 큰 사용 빈도를 갖는 경 우, 셋업 시간이 짧더라도 해당 작업 세트는 유지될 수 있다. 예시된 바와 같이, 캐시는 2개의 작업 세트: C 작업 세트(데이터 객체라고도 지칭될 수 있음) 및 C 작업 세트(데이터 객체라고도 지칭될 수 있음)를 저장하는 캐시 공간을 포함한다. C은 제1 컨테이너 에 대한 약어이고 C는 제2 컨테이너에 대한 약어이다. 제1 및 제2 컨테이너는 실행 중에 함수가 활용하는 데이터 세트를 포함할 수 있다. C 작업 세트는 제1 컨테이너에 대한 작업 세트이고, C는 제2 컨테이너에 대한 작업 세트이다. 이 예에서, 제1 및 제2 컨테이너 둘 모두는 해체되었으며 비활성(예를 들어, 빌드되지 않 음)이다. 제1 및 제2 컨테이너가 해체될 때, C 및 C 작업 세트는 호출되는 경우 제1 및 제2 컨테이너를 신속하게 빌드하기 위해 캐시 공간에 유지된다. 즉, C 작업 세트는 제1 컨테이너를 빌드하는 데 사용 될 수 있고, C 작업 세트는 제2 컨테이너를 빌드하는 데 사용될 수 있다. 따라서, 캐시 공간에 C 및 C 작업 세트를 유지하는 것은 제1 또는 제2 컨테이너에서의 함수의 후속 실행을 가속화할 수 있다. 즉, 제1 및 제2 컨테이너는 C 및 C 작업 세트에 적어도 부분적으로 기초하여 재빌드될 수 있다. 일부 실시예에서, C 및 C 작업 세트는 제각기 제1 및 제2 컨테이너를 빌드하기 위한 모든 데이터를 포함할 수 있다. 일부 실시예에서, C 및 C 작업 세트는 제각기 제1 및 제2 컨테이너를 빌 드하기 위한 데이터의 서브세트만을 포함할 수 있다. 예를 들어, 일부 데이터는 여러 상이한 컨테이너에 공통 일 수 있다. 그러한 데이터는 C 및 C 작업 세트로 저장될 수 있으며, 그와 같이, C 및 C 작업 세 트 각각은 여러 상이한 컨테이너를 빌드하는 데 사용될 수 있다. 일부 실시예에서, C 및 C 작업 세트는 제각기 제1 및 제2 컨테이너를 빌드하기 시작하기 위한 데이터 객체를 포함할 수 있으며, 나머지 데이터 객체는 제1 및 제2 함수가 빌드될 때 도착하는 제1 및 제2 컨테이너를 빌드한다. 일부 실시예에서, 제1 또는 제2 컨테이너는 함수의 실행을 지원하기 위해 추가 데이터를 필요로 할 수 있다. 즉, 완전히 빌드된 제1 또는 제2 컨테이너는 함수의 요구사항에 따라 함수를 지원하지 못할 수 있다. 따라서, 제1 또는 제2 컨테이너는 추가 데이터를 포함하도록 그리고 수정된 제1 또는 제2 컨테이너가 함수를 지원할 수 있도록 빌드 및 수정될 수 있다. 추가 데이터는 데이터 소스(예를 들어, 다른 컴퓨트 노드, 데이터베이스 서버 등)로부터 수신될 수 있다. C 및 C 작업 세트의 크기와 제1 및 제2 컨테이너 시작 시간은 상이한 함수에대해 상이하고, 제1 컨테이너와 제2 컨테이너가 실행을 용이하게 하기 위해 추가 데이터로 보강되어야 하는 경 우에 특히 그렇다. 일부 축출 정책은 사용 빈도 및 새로운 데이터가 저장되어야 하는지에 거의 전적으로 기초할 수 있다. FaaS 환 경에서, 컨테이너 시작 시간(함수 시작 시간과 동등할 수 있음)은 사소하지 않으며, 따라서 축출 동안 고려될 필요가 있을 수 있다. 따라서, 3100의 예는 시작 시간을 고려하고 컨테이너 시작을 향상시키기 위해 C 및 C 작업 세트에 대한 향상된 축출 정책을 갖는다. 예시된 바와 같이, 시작 타이머가 제공된다. 시작 타이머는 제1 및 제2 컨테이너의 시작 시간을 측정하고, 측정된 시작 시간(예를 들면, 빌드 시간)을 테이블에 T 및 T로서 저장할 수 있다. 예를 들어, 빌드 시간 T은 제1 컨테이너를 빌드하기 위한 시간 측정이다(초기 실행). 제1 컨테이너가 함수의 실 행을 시작할 수 있을 때 제1 컨테이너는 완전히 빌드된 것으로 간주될 수 있다. 유사하게, 빌드 시간 T(초 기 실행)는 제2 컨테이너를 빌드하기 위한 시간 측정이다. 제2 컨테이너가 함수의 실행을 시작할 수 있을 때 제2 컨테이너는 완전히 빌드된 것으로 간주될 수 있다. 테이블은 빌드되는 각각의 컨테이너의 작업 세트 및 그의 빌드 시간을 저장하는 데이터 구조일 수 있다. 향상된 캐시 제어기는 캐시로부터의 축출을 제어할 수 있다. 캐시 제어기는 테이블에 액세스하거나, 또는 테이블에 저장된 정보를 포함하는 메시지를 시작 타이머로부터 수신할 수 있다. 캐시 제어기는 캐시로부터의 축출을 결정할 때 빌드 시간 T 및 T를 이용할 수 있다. 따라서, 캐시 제어기는 C 작업 세트 또는 C 작업 세트를 축출할지를 결정할 때 제1 및 제2 컨테이 너의 빌드 시간 T 및 T를 이용할 수 있다. 예를 들어, 캐시 제어기는 축출 정책 관리자를 포함할 수 있다. 축출 정책 관리자는 빌드 시간 T 및 T에 기초하여 상이한 가중 수식을 생성하고, 그러한 값을 테이블에 저장할 수 있다. 예 를 들어, 축출 정책 관리자는 C 작업 세트에 대한 제1 가중 수식을 빌드할 수 있다. 제1 가중 수식은 가중 함수 F(T)를 포함할 수 있다. F(T)는 빌드 시간 T을 입력으로서 받고 빌드 시간 T으로부터 도출된 값을 출력하는 함수일 수 있다. 마찬가지로, C 작업 세트에 대해 제2 가중 수식이 생성된다. 제2 가중 수식은 함수 F(T)를 포함할 수 있다. 함수 F(T)는 빌드 시간 T를 입력으로서 받고 빌드 시간 T로부터 도출된 값을 출력하는 함수일 수 있다. 표는 제1 및 제2 가중 수식을 저장한다. 제1 및 제2 가중 수식 둘 모두는 추가적인 값도 포함할 수 있다. 예를 들어, 제1 가중 수식은, C 작업 세트 의 액세스 AC의 빈도에 기초하는 다른 함수일 수 있는, 함수 K(1, AC)를 포함할 수 있다. 예를 들어, 함 수 K은 출력을 생성하기 위해, C 작업 세트의 AC 액세스의 횟수를 입력으로서 받을 수 있다. 마찬가 지로, 함수 K는 출력을 생성하기 위해, C 작업 세트의 AC 액세스의 횟수를 입력으로서 받을 수 있다. 제1 및 제2 가중 수식은 다른 값도 포함할 수 있다. 제1 및 제2 가중 수식은 상기 함수들의 합계일 수 있다. 축출 정책 관리자는 C 작업 세트 또는 C 작업 세트를 캐시로부터 축출할지를 결정하기 위해 제1 및 제2 가중 수식을 참조할 수 있다. 예를 들어, 축출 정책 관리자는 제1 가중 수식의 총 계산인 제 1 최종 값, 및 제2 가중 수식의 총 계산인 제2 최종 값을 결정할 수 있다. 제1 및 제2 최종 값은 축출 정책 관 리자의 테이블에 저장될 수 있다. 축출 정책 관리자는 제1 최종 값과 제2 최종 값을 비교하 여 C 및 C 작업 세트를 축출할지를 결정할 수 있다. 따라서, 축출 정책 관리자는 빌드 시간 T 과 T를 서로 비교하고 그리고/또는 C 및 C 작업 세트에 대한 액세스 AC와 AC의 횟수를 비교한다. 예로서, 제1 및 제2 최종 값은 제각기 제1 및 제2 컨테이너의 시작 시간, 및 제각기 C 및 C 작업 세트에 대한 데이터 액세스 AC 및 AC의 횟수에 비례할 수 있다. 따라서, 제1 최종 값이 제2 최종 값보다 크면, C 작업 세트보다 C 작업 세트가 더 많이 액세스될 수 있고, 그리고/또는 제1 컨테이너는 제2 컨테이너에 비해 더 높은 시작 시간을 가질 수 있다. 따라서, C 작업 세트를 축출하는 것은 C 작업 세트를 축출하는 것에 비해 더 큰 전체 지연 시간을 결과할 것이다. 그와 같이, 축출 정책 관리자는 제1 및 제2 최종 값 에 기초하여 C 작업 세트를 축출할 수 있다. 따라서, 축출 정책 관리자는 가장 작은 최종 값과 연관 된 작업 세트를 축출할 수 있다. 캐시 제어기는 보유 정책 관리자를 또한 포함할 수 있다. 보유 정책 관리자는 C 및 C 작업 세트에 대한 생존 시간을 결정하기 위해 상이한 가중 수식을 생성할 수 있다. 생존 시간은 표에 저 장될 수 있다. 예를 들어, 보유 정책 관리자는 제1 컨테이너에 대한 제3 가중 수식을 빌드할 수 있다.제3 가중 수식은 빌드 시간 T로부터 도출된 값을 출력하기 위해 빌드 시간 T 및 함수 L을 입력으로서 받는 함수인 함수 G(T)를 포함할 수 있다. 마찬가지로, 제2 컨테이너에 대해 제4 가중 수식이 생성된다. 제4 가중 수식은 빌드 시간 T로부터 도출된 값을 출력하기 위해 함수 G(T), 또는 빌드 시간 T를 입력 으로서 받는 함수는 물론 함수 L를 포함할 수 있다. 제3 및 제4 가중 수식은, 제각기 상수 및/또는 C 및 C 작업 세트에 대한 데이터 액세스의 횟수와 같은, 다른 값도 포함할 수 있다. 제3 가중 수식으로부터 도출 된 값은 C 작업 세트에 대한 생존 시간일 수 있고, 제4 가중 수식으로부터 도출된 값은 C 작업 세트에 대 한 생존 시간일 수 있다. 표는 제3 및 제4 가중 수식을 보여준다. 일부 실시예에서, 보유 정책 관리자는 작업 세트에 대한 \"생존 시간\"만을 결정한다. 따라서, 보유 정책 관리자는 본질적으로 축출 정책 관리자가 생존 시간에만 기초하지 않는 우선순위화된 축출에 관해 더 많은 정보에 입각한 결정을 내릴 수 있게 한다. 일부 실시예에서, 보유 정책 관리자의 결과는 더 많 은 정보에 입각한 축출 결정을 내리기 위해 축출 정책 관리자에 의해 사용될 수 있으며, 제1 및 제2 가중 수식에서의 인자이다. 그러한 실시예에서, 보유 정책 관리자는 캐시로부터 데이터를 축출하지 않 을 수 있지만, 그러한 결정을 축출 정책 관리자에게 맡길 수 있다. 일부 실시예에서, 보유 정책 관리자 및 축출 정책 관리자는 필요에 따라 C 및 C 작업 세트를 제거하기 위해 서로 독립적으로 동작할 수 있다. 예를 들어, 축출 정책 관리자는 캐시가 가득 차 고 다른 FaaS 함수를 위해 더 많은 자유 공간이 필요하다는 결정에 응답하여 데이터를 축출하도록 트리거될 수 있다. 축출 정책 관리자는 이어서 C 작업 세트 또는 C 작업 세트가 위에서 설명된 바와 같이 축출 되어야 하는지를 결정할 수 있다. 보유 정책 관리자는 단순히 생존 시간이 언제 만료되는지를 식별하고 캐시 내의 자유 공간의 양에 관계없이 대응하는 C 또는 C 작업 세트를 축출할 수 있다. 즉, 축출 정책 관리자는 캐시에 더 많은 자유 공간이 필요하다는 식별에 의해 작업 세트를 제거하도록 트리 거될 수 있는 반면, 보유 정책 관리자는 그러한 식별에 의해 트리거되지 않을 수 있다. 일부 실시예에서, 각각의 작업 세트 C 및(C2)는 별개의 타이머를 가질 수 있다. 계산된 생존 시간 값이 타 이머와 비교할 수 있다. 작업 세트 C 및 C 중 하나의 작업 세트에 대한 타이머들 중 하나의 타이머가 하 나의 작업 세트에 대한 생존 시간을 충족시킬 때, 해당 하나의 작업 세트는 축출될 수 있다. 예를 들어, 카운 터에 의해 카운트되고 보유 정책 관리자에 의해 식별된 바와 같이, 대응하는 생존 시간이 타임 아웃될 때, C 작업 세트 또는 C 작업 세트가 축출될 수 있다. C 또는 C 작업 세트가 액세스될 때마다 타 이머가 리셋될 수 있다. 예를 들어, C 작업 세트가 액세스되는 경우, C 작업 세트에 대한 타이머가 리셋 된다. 이와 달리, C 작업 세트 타이머는 C가 액세스되지 않았으므로 리셋되지 않을 수 있다. 타이머는 또한 자동으로 리셋되고 그리고/또는 리소스를 해제하거나 선택된 요청 카테고리에 높은 우선순위를 부여할 필 요성의 식별에 응답하여 관리적으로 리셋될 수 있다. 일부 실시예에서, 타이머는 리셋되지 않을 수 있고 생존 시간은 최대 생존 시간을 나타낸다. 캐시는 하드웨어 캐시(예를 들어, LLC, TLB) 또는 소프트웨어 객체 캐시(예를 들어, Java 영속 객체 캐시)일 수 있다. 캐시는, 예를 들어, 페이지 캐시일 수 있다. 게다가, 캐시 제어기는 여러 캐시 또는 캐시 레벨을 제어할 수 있다. 더욱이, 축출 이벤트는 들어오는 데이터를 위한 저장 공간의 부족에 의해 트리거될 수 있고, 캐시 제어기에 의해 모니터링될 수 있다. 예로서, 제1 컨테이너는 이미지 인식을 위한 제1 함수를 실행할 수 있고, 제2 컨테이너는 이미지 회전을 위한 제2 함수를 실행할 수 있다. 제1 함수에 대한 이미지 인식 시작은 제1 컨테이너의 신경 네트워크를 초기화하는 것을 수반할 수 있다. 따라서, 제1 컨테이너의 빌드 시간 T은 제2 컨테이너의 빌드 시간 T보다 상당히 더 높을 수 있다. 이미지 인식의 메모리 풋프린트가 더 높을 수 있으며, 컨테이너를 재사용을 위해 생존 상태 로 유지하는 것은 많은 비용이 들 수 있다. 게다가, 이미지 인식의 실행 빈도는 이미지 회전 함수보다 낮을 수 있다. 따라서, 제1 컨테이너의 데이터에 대한 액세스 횟수는 제2 컨테이너보다 낮을 수 있다. 그럼에도 불구 하고, 성능 관점에서 볼 때, 빌드 시간 T이 빌드 시간 T보다 상당히 더 길기 때문에, 축출 정책 관리자 는 C 작업 세트(이미지 인식 컨테이너)를 축출하고 C 작업 세트(이미지 회전 컨테이너)를 축출하는 것이 유익하지 않다고 결정할 수 있다. 더욱이, C 작업 세트를 유지하는 것은 제2 컨테이너 시작을 향상시 킬 수 있는데, 그 이유는 C 작업 세트로부터의 데이터가 제1 및 제2 컨테이너 둘 모두에 공통인 것으로 식별 되고 제2 컨테이너의 빌드 동안 이용될 수 있기 때문이다. 따라서, 축출 정책 관리자는 캐시 축출 정책 에서 시작 시간을 고려할 수 있다. 프로세스는 들어오는 C 작업 세트를 수용하기 위해 C 작업 세트를 축출할 수 있다. C 작업 세 트는 제3 컨테이너를 빌드하기 위한 데이터일 수 있으며, C 및 C 작업 세트와 관련하여 위에서 설명된 것 과 유사한 데이터를 포함할 수 있다. 도 31b는 도 31a에 예시된 시나리오의 연속일 수 있다. 도 31b에 예시된 바와 같이, C 데이터 세트 및 관련 데이터는 캐시 공간, 테이블, 테이블 및 테이 블로부터 소거된다. 캐시 공간, 테이블, 테이블 및 테이블은 위에서 설명된 대 응하는 데이터와 유사할 수 있는 제3 컨테이너 및 C 작업 세트에 대한 데이터를 저장한다. 도 31c는 향상된 캐시 축출 방법을 도시하며, 도 31a 및 도 31b의 향상된 FaaS 서버 아키텍처, 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매 체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조 합으로 구현될 수 있다. 예를 들어, 방법에 도시된 동작을 수행하기 위한 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 등과 같 은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프 로그래밍 언어를 포함하여, 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 추가적으로, 로 직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴 포넌트를 포함할 수 있다. 예시된 프로세싱 블록은 함수의 초기 실행 동안 시작 시간을 측정할 수 있다. 초기 실행은 함수를 실행 하기 위한 컨테이너를 빌드하는 것만을 포함할 수 있다. 예를 들어, 시작 시간은 컨테이너 빌드의 시작으로부 터 컨테이너가 빌드되고 함수를 실행할 준비가 될 때까지만 측정될 수 있다. 예시된 프로세싱 블록은 시 작 시간에 기초하여 하나 이상의 가중치를 생성할 수 있다. 하나 이상의 가중치는 시작 시간에 비례할 수 있다. 예시된 프로세싱 블록은 데이터를 축출하기 위해 하나 이상의 가중치를 이용할 수 있다. 예를 들 어, 하나 이상의 가중치는 캐시에서 컨테이너의 작업 세트의 유용성을 나타내는 최종 값을 계산하고 최종 값에 기초하여 데이터를 축출하기 위해 가중 알고리즘 및/또는 스킴에서 사용될 수 있다. 예를 들어, 최종 값이 다 른 최종 값(본 명세서에서 설명된 것과 유사하게 계산됨)보다 큰 경우, 작업 세트가 캐시로부터 축출되지 않을 수 있으며, 다른 최종 값에 대응하는 상이한 작업 세트가 축출될 수 있다. 따라서, 방법은 캐시 축출을 향상시킬 수 있다. 도 31d는 향상된 캐시 축출 방법을 도시하며, 도 31a 및 도 31b의 향상된 FaaS 서버 아키텍처, 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매 체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조 합으로 구현될 수 있다. 예를 들어, 방법에 도시된 동작을 수행하기 위한 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 등과 같 은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프 로그래밍 언어를 포함하여, 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 추가적으로, 로 직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴 포넌트를 포함할 수 있다. 예시된 프로세싱 블록은 제1 컨테이너에 대한 제1 셋업 시간을 측정할 수 있다. 제1 컨테이너가 셋업(예 를 들면, 빌드)된 후에 제1 함수가 제1 컨테이너에서 실행될 수 있다. 제1 셋업 시간은 제1 컨테이너의 하나 이상의 네임스페이스 및 제1 컨테이너의 하나 이상의 제어 그룹을 구성하는 것은 물론 실행 환경을 셋업하는 시 간일 수 있다. 예시된 프로세싱 블록은 제2 컨테이너에 대한 제2 셋업 시간을 측정할 수 있다. 제2 컨 테이너가 셋업(예를 들어, 빌드)된 후에 제2 함수가 제2 컨테이너에서 실행될 수 있다. 제2 셋업 시간은 제2 컨테이너의 하나 이상의 네임스페이스 및 제2 컨테이너의 하나 이상의 제어 그룹은 물론, 실행 환경을 구성하는 시간일 수 있다. 제2 함수는 제1 함수와 상이할 수 있으며, 제1 컨테이너와 제2 컨테이너는 서로 상이할 수 있 다. 예시된 프로세싱 블록은 제1 데이터 세트의 제1 사용(예를 들어, 액세스) 빈도를 측정할 수 있다. 제1 데이터 세트는 제1 컨테이너를 빌드하기 위한 데이터일 수 있다. 예시된 프로세싱 블록은 제2 데이터 세 트의 제2 사용(예를 들어, 액세스) 빈도를 측정할 수 있다. 제2 데이터 세트는 제2 컨테이너를 빌드하기 위한 데이터일 수 있다. 액세스는 판독 및/또는 기입을 의미할 수 있다. 예시된 프로세싱 블록은 제1 셋업 시간과 제2 셋업 시간의 비교에 기초하여 데이터 객체들을 캐시로부터 축출할 수 있다. 게다가, 예시된 프로세싱 블록은 제1 사용 빈도 측정치와 제2 사용 빈도 측정치의 비교 에 기초하여 데이터 객체를 캐시로부터 축출할 수 있다. 데이터 객체는 제2 셋업 시간이 제1 셋업 시간보다 클 때 제1 컨테이너와 연관될 수 있다. 예를 들어, 제1 셋업 시간은 제2 셋업 시간보다 작을 수 있고, 제1 사용 빈도는 한계량(marginal amount)만큼 제2 사용 빈도보다 클 수 있다. 제1 사용 빈도가 더 높음에도 불구하고, 제1 셋업 시간이 제2 셋업 시간보다 작기 때문에 제1 컨테이너의 데이터 객체(예를 들면, 제1 데이터 세트)가 축출될 수 있다. 데이터 객체는 제1 컨테이너를 개시하는 제1 데이터 세트일 수 있거나 또는 이를 포함할 수 있다. 일부 실시예에서, 제1 사용 빈도가 제2 사용 빈도보다 충분히 큰 정도만큼 큰 경우, 제2 셋업 시간이 제1 셋업 시간보다 크더라도, 제1 컨테이너의 데이터 객체보다는, 제2 컨테이너와 관련된 데이터 객체(예를 들면, 제2 데 이터 세트)가 축출될 수 있다. 예를 들어, 제1 사용 빈도가 제2 사용 빈도보다 미리 결정된 양만큼 더 크거나 어떤 비보다 큰 경우, 제2 컨테이너와 연관된 데이터 객체가 축출될 수 있다. 일부 실시예에서, 데이터 객체 (예를 들어, 데이터 세트)의 사용 빈도가 특정 임계치 아래로 떨어지는 경우, 데이터 객체는 시작 시간을 고려 하지 않고 축출될 수 있다. 따라서, 방법은 캐시 축출을 향상시키고 함수 실행의 레이턴시를 감소시킬 수 있다. 도 31e는 향상된 캐시 축출 방법을 도시하며, 도 31a 및 도 31b의 향상된 FaaS 서버 아키텍처, 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매 체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조 합으로 구현될 수 있다. 예를 들어, 방법에 도시된 동작을 수행하기 위한 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 등과 같 은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프 로그래밍 언어를 포함하여, 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 추가적으로, 로 직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴 포넌트를 포함할 수 있다. 예시된 프로세싱 블록은 제1 컨테이너에 대한 제1 셋업 시간을 측정할 수 있다. 논의된 바와 같이, 제1 셋업 시간은 제1 컨테이너를 빌드하는 시간일 수 있다. 예시된 프로세싱 블록은 제2 컨테이너에 대한 제 2 셋업 시간을 측정할 수 있다. 논의된 바와 같이, 제2 셋업 시간은 제2 컨테이너를 빌드하는 시간일 수 있다. 예시된 프로세싱 블록은 제1 셋업 시간에 기초하여 제1 컨테이너의 데이터 객체들에 대한 생존 시간을 결 정할 수 있다. 데이터 객체는 캐시에 저장될 수 있다. 예시된 프로세싱 블록은 추가로 제2 셋업 시간에 기초하여 제2 컨테이너의 데이터 객체들에 대한 생존 시간을 결정할 수 있다. 제2 컨테이너의 데이터 객체는 캐시에 저장될 수 있다. 예시되어 있지 않지만, 생존 시간이 만료되는 경우 제1 객체 및 제2 객체가 축출될 수 있다. 추가 비고 및 예 예 3100은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 제1 컨테이너에 대한 제1 셋업 시간 을 측정하게 하고 - 제1 함수는 제1 컨테이너에서 실행되고, 제1 셋업 시간은 제1 컨테이너의 하나 이상의 네임 스페이스 및 제1 컨테이너의 하나 이상의 제어 그룹을 구성하는 시간임 -, 제2 컨테이너에 대한 제2 셋업 시간 을 측정하게 하며 - 제2 함수는 제2 컨테이너에서 실행되고 제2 함수는 제1 함수와 상이하며, 제2 셋업 시간은 제2 컨테이너의 하나 이상의 네임스페이스 및 제2 컨테이너의 하나 이상의 제어 그룹을 구성하는 시간임 -, 제1 셋업 시간과 제2 셋업 시간의 비교, 및 제1 데이터 세트의 사용 빈도와 제2 데이터 세트의 사용 빈도의 비교에 기초하여 데이터 객체들을 캐시로부터 축출하게 하는 - 제1 데이터 세트는 제1 컨테이너를 빌드하는 데 이용되 고, 추가로 제2 데이터 세트는 제2 컨테이너를 빌드하는 데 사용되며, 추가로 데이터 객체들은 제1 데이터 세트 를 포함함 - 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다.예 3101은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 제1 컨테이너에 대한 제1 셋업 시간 을 측정하게 하고 - 제1 함수는 제1 컨테이너에서 실행됨 -, 제2 컨테이너에 대한 제2 셋업 시간을 측정하게 하 며 - 제2 함수는 제2 컨테이너에서 실행되고 제2 함수는 제1 함수와 상이함 -, 제1 셋업 시간과 제2 셋업 시간 의 비교에 기초하여 데이터 객체들을 캐시로부터 축출하게 하는 - 데이터 객체들을 제1 컨테이너와 연관됨 - 명 령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 3102는 예 3101의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 제1 셋업 시간은 제2 셋업 시간 보다 크다. 예 3103은 예 3102의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 제1 셋업 시간은 제1 컨테이너 의 하나 이상의 네임스페이스 및 제1 컨테이너의 하나 이상의 제어 그룹을 구성하는 시간이고, 제2 셋업 시간은 제2 컨테이너의 하나 이상의 네임스페이스 및 제2 컨테이너의 하나 이상의 제어 그룹을 구성하는 시간이다. 예 3104는 예 3102의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 컨테이너의 사용 빈도에 기초하여 데이터 객체들을 캐시로부터 축출하게 하는 추가 명령어 세트를 포함한다. 예 3105는 예 3102의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 데이터 세트의 사용 빈도와 제2 데이터 세트의 사용 빈도의 비교에 기초하여 데이 터 객체들을 캐시로부터 축출하게 하는 - 제1 데이터 세트는 제1 컨테이너를 빌드하는 데 이용되고, 추가로 제2 데이터 세트는 제2 컨테이너를 빌드하는 데 사용되며, 추가로 데이터 객체들은 제1 데이터 세트를 포함함 - 추 가 명령어 세트를 포함한다. 예 3106은 예 3102의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 셋업 시간에 기초하여 제1 컨테이너의 데이터 객체들에 대한 생존 시간을 결정하게 하고, 제2 셋업 시간에 기초하여 제2 컨테이너의 데이터 객체들에 대한 생존 시간을 결정하게 하는 추가 명령어 세트를 포함한다. 예 3106은 예 3100의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 데이터 객체들은 제1 컨테이너 를 개시하기 위한 데이터를 포함한다. 향상된 FaaS 함수 배포 예 본 명세서에서 이미 설명된 바와 같이, 일부 함수는 실행 중에 데이터 세트에 의존할 수 있다. 데이터 세트는 컨테이너에 포함될 수 있으며, 따라서 적절한 데이터 세트에 액세스하기 위해 함수가 적절한 컨테이너에 제공될 수 있다. 일부 데이터는, 예컨대, 하둡(Hadoop) 환경에서, 크고 그리고/또는 분산될 수 있다. 그와 같이, 데 이터 세트를 함수로 이동시키는 것은 비효율적이고 그리고/또는 총 환경 비용(TCE)을 증가시킬 수 있다. 즉, 함수가 터치하거나 수정할 수 있는 데이터(예를 들면, 그의 메모리 또는 스토리지 또는 네트워크 풋프린트)는 액션이 완료되는 레이턴시 및 서비스 제공자에 의해 제공되는 계산 리소스의 효율적인 사용과 상당한 관계가 있 을 수 있다. 일부 함수 및 데이터 세트는 특수 컴퓨팅(예를 들면, 하드웨어 가속기)이 없어도 증가된 TCE를 가 질 수 있다. 그와 같이, 도 32a의 3200의 예에서, 오케스트레이터는 FaaS 인프라스트럭처를 분석하여 제1 노드 및 제2 노드 중에서 함수 F1에 대한 데이터 세트에 대한 최저 레이턴시 전송을 갖는 노드를 식별할 수 있 다. 오케스트레이터는 데이터 이동 및 데이터 이동 비용에 기초하여 함수 F1을 스케줄링할 수 있다. 예 를 들어, 비용 분석기는 제1 및 제2 노드(3208, 3216) 각각에서 함수 F1의 총 실행 비용을 결정할 수 있 다. 총 비용은 데이터 이동 비용과 실행 비용의 합계일 수 있다. 총 비용은 레이턴시 측정치, 실행 시간 측정 치, 리소스 측정치, 보안 채널 확립, 암호화/복호화 또는 압축/압축해제 레이턴시 측정치, 네트워크 홉, 대역폭 및 버퍼링 추정치 등을 추가로 포함할 수 있다. 예를 들어, 오케스트레이터는 함수 F1의 실행과 연관된 데이터 객체(들) 및 데이터 객체의 지역성을 결정할 수 있다. 오케스트레이터는 선호된 리소스 이용률에 기초하여 함수 F1 및 데이터 객체의 분배를 오케스트레이션할 수 있다. 그와 같이, 오케스트레이터는 리 소스를 해제하고, 총 실행 비용을 감소시키며, 더 낮은 IO 대역폭 및 더 낮은 레이턴시의 함수 실행을 가질 수 있다. 도 31a 및 도 31b의 실시예와 유사하게, 제1 노드는 데이터 객체를 C 작업 세트에 저장하는 캐시 를 포함한다. 간결성을 위해, 유사한 컴포넌트에 대한 유사한 설명은 생략될 것이다. 예를 들어, 도 32a의 캐시 제어기, 캐시 및 시작 타이머는 도 31a의 캐시 제어기, 캐시 및 시 작 타이머와 유사하게 동작할 수 있다. 마찬가지로, 제2 노드는 도 31a 및 도 31b의 실시예와 유 사하게 동작할 수 있다. 이해되는 바와 같이, C은 제1 컨테이너에 대한 약어이다. C 작업 세트는 제1 컨테이너에 대한 작업 세트 이다. 이 예에서, 제1 컨테이너는 해체되어 비활성(빌드되지 않음)이다. 제1 컨테이너가 해체될 때, C 작 업 세트는 제1 컨테이너를 신속하게 빌드하기 위해 캐시에 유지된다. 즉, C 작업 세트는 제1 컨테이 너를 빌드하는 데 사용될 수 있다. 오케스트레이터는 함수 F1이 특정 컨테이너에서 실행될 수 있는지를 결정할 수 있다. 예를 들어, 함수 분석기는 함수 F1의 함수 구조로부터 임의적 필드(예를 들면, 메타데이터)의 특성을 결정할 수 있다. 도 33a 및 도 33b 및 관련 설명은 함수 구조를 더 상세히 논의한다. 메타데이터는 함수 F1과 데이터 모니커의 연 관성을 기술한다. 데이터 모니커는 데이터 세트 구조의 아이덴티티의 대략적인 표현일 수 있다. 모니커는 함 수의 다양한 범용 고유 식별자, 함수의 호출자, 함수의 특정 파라미터, 함수와 연관된 파일 시스템 경로 이름, 예를 들어, Spark에서의 RDD(Resilient Distributed Dataset) 계보, 함수에 의해 액세스되는 관계형 데이터베 이스에서의 테이블 스페이스 범위 등을 통해 세트 함수(set function)(예를 들어, 블룸 필터(Bloom Filter)) 및 /또는 모니커 구성 API에 의해 구성될 수 있다. 따라서, 함수 분석기는 모니커를 도출하기 위해 모니커 구성 API와 상호작용할 수 있고 그리고/또는 세트 함수를 포함할 수 있다. 일부 실시예에서, 함수 분석기 는 모니커 구성 API를 포함할 수 있다. 추가 세부사항은 도 33a 및 도 33b와 관련하여 아래에서 설명된 다. 모니커는 함수 F1이 실행 중에 필요로 할 수 있는 리소스(예를 들면, 가속기, 데이터, 가중 수식, 하드웨어 요 구사항 등)의 이름에 대한 간결한 표현 또는 설명일 수 있다. 모니커는 특정 데이터 세트가 실행 동안 함수 F1 에 의해 활용될 수 있음을 나타낼 수 있다. 그러한 특정 데이터 세트는 F1 데이터 세트라고 지칭될 수 있다. 함수 분석기는 메타데이터에 기초하여 모니커를 결정할 수 있고, 함수 F1은 컨테이너가 F1 데이터 세트의 적어도 일부는 물론 실행 동안 필요하게 될 수 있는 다른 리소스를 포함할 수 있는지를 결정하기 위해 모니커와 소프트 친화성(soft affinity)을 갖는 컨테이너의 유형을 결정할 수 있다. 제1 및 제2 노드(3208, 3216)는 임 의의 저장된 작업 세트(예를 들어, C 작업 세트)를 오케스트레이터에 알릴 수 있다. 오케스트레이터 는 C 작업 세트가 모니커에 대해 소프트 친화성을 갖는 컨테이너를 빌드할 수 있는지를 결정할 수 있 다. 일부 실시예에서, 오케스트레이터는 C 작업 세트가 F1 데이터 세트의 적어도 일부를 포함하는지 를 결정할 수 있다. 따라서, 오케스트레이터는 함수 F1과 데이터 세트 간의 연관성을 정의하며, 이 연관성은 함수 F1이 실행 동안 필요로 할 가능성이 가장 많은 데이터의 로컬 웜 사본을 소유할 가능성이 가장 높은 컨테이너(예를 들면, 아래에서 설명되는 바와 같은 제1 컨테이너)를 향해 함수 F1을 유인함으로써 스토리지, 캐시 및 통신 효율적인 스케줄링을 안내하는 잠재 상태로서 역할한다. 더욱이, 상기 향상은 서버리스 추상화를 위반하지 않고 달성될 수 있다. 더 상세하게는, 본 예에서, 함수 분석기는 제1 컨테이너가 함수 F1이 실행 동안 활용할 F1 데이터 세트의 적어도 일부를 포함한다고 결정할 수 있다. 오케스트레이터는 제1 노드가, 위에서 설명된 바와 같 이 제1 컨테이너를 빌드하는데 사용될 수 있는, C 작업 세트를 포함한다고 결정할 수 있다. 그와 같이, 오 케스트레이터는 제1 노드가 F1 데이터 세트의 적어도 일부를 포함할 수 있음을 식별하고, 함수를 제 1 노드로 조종(steer)할 수 있다. 예를 들어, 빌드 이전에, 오케스트레이터는, 캐시에 저장 된 바와 같은, C 작업 세트를 F1 데이터 세트와 비교하여 저장된 C 작업 세트가 F1 데이터 세트의 적어도 일부를 포함한다고 결정할 수 있다. 이와 달리, 제2 노드는 어떠한 관련 데이터 객체도 포함하지 않을 수 있다. 제2 노드가 일부 작업 세트(예시되지 않음)를 포함할 수 있지만, 해당 작업 세트는 F1 데이터 세트의 실행과 연관된 데이터를 포함하지 않으므로 생략되어 있다.비용 분석기는 함수 F1을 실행하기 위한 제1 노드 및 제2 노드의 총 비용을 결정할 수 있다. 총 비용은 예상된 비용, 예측된 추정치, 조건부 레이턴시 및/또는 추정된 레이턴시일 수 있으며, 예상된 또는 추정된 비용 및 레이턴시는 제1 노드와 제2 노드 사이의 데이터 전송 비용 및 레이턴시를 포함한다. 총계는 레 이턴시 측정치, 실행 시간 측정치, 리소스 측정치, 보안 채널 확립, 암호화/복호화 또는 압축/압축해제 레이턴 시 측정치, 네트워크 홉, 대역폭 및 버퍼링 추정치 등을 추가로 포함할 수 있다. 제1 노드의 총 비용은 제1 노드에서 컨테이너(예를 들어, 추가된 데이터를 갖는 제1 컨테이너 또는 제1 컨테이너의 수정된 버전)를 빌드하고 제1 노드에서 함수 F1를 실행하기 위한 비용을 나타낼 수 있다. 제2 노드의 총 비용은 제2 노드에서 함수 F1을 실행하기 위한 컨테이너를 빌드하고 제2 노드에서 함수 F1을 실행하 기 위한 비용을 나타낼 수 있다. 함수 F1을 제1 노드 또는 제2 노드로 송신할지를 결정하기 위해 총 비용이 비교될 수 있다. 더 상세하게는, 비용 분석기는 함수 F1을 실행하기 위한 제1 및 제2 노드(3208, 3216) 각각의 총 비용을 결정할 수 있다. 총 비용은 제1 및 제2 노드(3208, 3218) 각각에 대해 결정될 수 있으며, 통신 비용(예를 들어, 컨테이너를 빌드하기 위해 전송될 필요가 있는 데이터의 볼륨, 데이터에 대한 근접성 등), 컨테이너의 빌 드 비용, 실행 레이턴시 비용(예를 들어, 가속기가 필요한지) 등에 기초할 수 있다. 예를 들어, 제1 및 제2 노드(3208, 3216) 중 한 노드가 함수 F1의 실행을 용이하게 하는 가속기를 포함하고 그 리고/또는 함수 F1을 지원하기에 충분한 리소스를 포함하는 경우, 실행 레이턴시 비용이 감소될 수 있다. 함수 F1을 지원할 리소스가 부족하거나 또는 가속기가 노드에 의해 지원되지 않는 경우 실행 비용이 증가될 수 있다. 오케스트레이터는 함수 F1을 총 비용의 비교에 기초하여 제1 및 제2 노드(3208, 3216) 중 한 노드, 또는 가장 낮은 총 비용을 갖는 제1 및 제2 노드(3208, 3216) 중 한 노드에 할당할 수 있다. 예를 들어, 제2 노드는 제1 노드에 비해 함수 F1을 실행하기 위해 더 높은 레이턴시(예를 들어, 더 높은 레이턴시 비용)을 제공할 수 있다. 상세하게는, 제2 노드는 함수 F1에 대한 컨테이너를 빌드하기 위한 모든 데이터를 수신한 다음에 컨테이너를 빌드할 필요가 있을 수 있다. 이와 달리, 제1 노드는 캐 시에 로컬로 저장된 C 작업 세트로부터 제1 컨테이너를 신속하게 빌드하고 필요한 경우 추가 데이터로 제1 컨테이너를 수정할 수 있으며, 이에 의해 제2 노드에 의해 제공되는 통신 레이턴시 비용의 적어도 일 부를 피할 수 있다. 따라서, F1 데이터 세트와 C 작업 세트 사이의 중첩으로 인해, 제1 노드의 통신 레이턴시는 제2 노드에 비해 감소될 수 있고, 이에 의해 제1 노드에 대한 전체 비용을 감소시킬 수 있다. 결과적으로, 제1 노드에서 함수 F1을 실행하기 위한 총 비용은 제2 노드에서 함수 F1을 실행 하기 위한 총 비용보다 적을 수 있다. 일부 실시예에서, C 작업 세트는 F1 데이터 세트의 일부만 포함할 수 있고, 나머지 데이터는 제1 컨테이너의 구성 이전 또는 구성 동안 제1 노드에 도착한다. 그러한 실시예에서, 비용 분석기는 제1 노드 에서 함수 F1을 실행하기 위한 총 비용의 일부로서 나머지 데이터를 전송하기 위한 비용을 포함할 수 있 다. 제1 노드가 나머지 데이터를 수신한 후에, 제1 컨테이너는 함수 F1을 실행하기 위해 나머지 데이터 로 보강될 수 있다. 본 예에서, 오케스트레이터는 함수 F1이 제1 노드에서 실행되기 위한 총 비용이 제2 노드에 서 함수 F1을 실행하기 위한 총 비용보다 적다고 결정할 수 있다. 프로세스는 함수 F1을 분배할 수 있다. 상세하게는, 오케스트레이터는 F1 함수를 제1 노드에 제공할 수 있다. 도 32b에 예시된 바와 같이, 제1 노드는 캐시에 저장된 C 작업 세트에 기초하여 제1 노드에 컨테이너 C(예를 들 어, 제1 컨테이너)를 빌드한다. 일부 실시예에서, 컨테이너 C는 함수 F1의 실행을 용이하게 하기 위해 C 작업 세트에 포함되지 않은 추가 데이터로 보강될 수 있다. 함수 F1은 이어서 실행을 시작할 수 있다. 예를 들어, 제1 노드는 함수 F1이 실행 동안 활용하는 일부 데이터를 수신할 수 있고, 컨테이너 C를 빌드하는 동안 해당 데이터를 컨테이너 C에 추가할 수 있다.도 32c를 살펴보면, 예가 예시된다. 간결함을 위해, 도 32a, 도 32b에 예시된 것과 유사한 컴포넌트는 여기서 반복되지 않을 것이다. 그렇지만, 대응하는 컴포넌트가 서로 유사하게 동작할 수 있음이 이해될 것이다. 예에서, 함수 F2는 오케스트레이터에 의해 할당된다. 상기 실시예와 유사하게, 제1 노드는 함수 F2를 실행할 제1 컨테이너를 구성하기 위한 C 작업 세트를 포함하는 반면, 제2 노드는 그러한 작 업 세트를 포함하지 않는다. 함수 분석기는 함수 F2를 분석하여 F2 데이터 세트를 결정할 수 있다. 오케스트레이터는 C 작업 세트가 F2 데이터 세트의 제1 부분만을 포함한다고 결정할 수 있다. 그와 같이, F2 데이터 세트의 제2 부분이 제1 노드에서 함수 F2를 실행하기 위해 제1 노드로 전송되어야 한다. 제2 노드는 어떠한 관 련 작업 세트도 포함하지 않을 수 있으며, 따라서 함수 F2를 실행하기 위해 제2 노드에 새로운 컨테이너 가 빌드될 필요가 있을 것이다. 비용 분석기는 제1 노드 및 제2 노드의 총 비용을 결정할 수 있다. 제1 노드에 대한 총 비용은 F2 데이터 세트의 제2 부분을 제1 노드에 전송하기 위한 비용을 포함할 수 있다. 제1 노드 는 F2 데이터 세트의 제2 부분을 제1 노드에 전송하는 데이터 소스로부터 멀리 떨어져 있을 수 있 다. 데이터 소스는 다른 노드일 수 있으며, F2 데이터 세트의 제2 부분을 갖는 제1 노드에 가장 가까운 노드일 수 있다. 따라서 비용 분석기는 F2 데이터 세트의 제2 부분을 전송하기 위한 통신 비용이 높고 제1 노드에 대한 총 비용이 그에 대응하여 높다고 결정할 수 있다. 제2 노드에 대한 총 비용은 제1 컨테이너를 빌드하기 위한 모든 빌드 데이터를 수신하기 위한 비용일 수 있다. 그렇지만 이러한 본 예에서, 제2 노드는 데이터 소스에 근접하게 배치될 수 있다. 데이터 소스는 모든 빌드 데이터를 포함할 수 있으며, 빌드 데이터를 제2 노드에 전송할 수 있다. 그와 같이, 제2 노드 의 통신 비용은 제1 노드의 통신 비용보다 상당히 더 낮을 수 있다. 통신 비용 간의 상당한 차이 로 인해, 제2 노드는 어떠한 작업 세트도 존재하지 않더라도 더 낮은 전체 비용을 가질 수 있다. 즉, 오 케스트레이터는, 제2 노드가 어떠한 작업 세트도 갖지 않음에도 불구하고, 제2 노드의 저하 된 데이터 전송 비용으로 인해 제2 노드에서 함수 F2를 실행하는 것이 더 효율적(더 낮은 레이턴시)이라 고 결정할 수 있다. 따라서, 오케스트레이터는, 데이터 소스로부터 더 멀리 떨어진 노드(심지어 관련 작 업 세트를 가짐)에 컨테이너를 빌드하기보다는, 레이턴시 비용을 줄이기 위해 데이터 소스에 더 가까운 노드에 컨테이너를 빌드할 수 있다. 프로세스에서, 오케스트레이터는 함수 F2를 분배할 수 있다. 도 32c의 예의 연속인 도 32d 에 예시된 바와 같이, 함수 F2는 제2 노드에 제공된다. 컨테이너는 데이터 소스로부터 수신된 데 이터에 기초하여 함수 F2를 실행하도록 빌드될 수 있다. 따라서, 도 32a 내지 도 32d의 상기 실시예는 액션이 실행되는 하드웨어 또는 그의 실행 동안 참조할 수 있는 데이터의 물리적 위치에 대해 그렇지 않았으면 알지 못하는 액션을 실행하기 위해 향상된 방식으로 데이터를 향 해 계산을 푸시할 수 있다. 실시예는 함수를 실행하기 위한 레이턴시를 감소시킬 수 있고 더욱이 리소스 이용 률을 감소시킬 수 있다. 도 32e는 향상된 함수 배포 방법을 도시하며, 도 32a 내지 도 32d의 향상된 FaaS 서버 아키텍처, 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매 체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조 합으로 구현될 수 있다. 예를 들어, 방법에 도시된 동작을 수행하기 위한 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 등과 같 은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프 로그래밍 언어를 포함하여, 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 추가적으로, 로 직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴 포넌트를 포함할 수 있다. 예시된 프로세싱 블록은 실행될 함수를 식별할 수 있다. 예시된 프로세싱 블록은 함수가 실행 동 안 활용할 데이터 세트를 결정할 수 있다. 예시된 프로세싱 블록은 제1 작업 세트가 데이터 세트의 적어 도 일부를 포함하는지를 결정할 수 있다. 제1 작업 세트는 제1 컨테이너를 시작하기 위한 리소스를 포함할 수 있다. 게다가, 제1 작업 세트는 제1 노드에 저장될 수 있다. 예를 들어, 제1 작업 세트는 제1 노드의 하드웨 어 및/또는 소프트웨어 캐시에 저장될 수 있다. 예시된 프로세싱 블록은 제1 노드에서 제1 함수를 실행하기 위한 제1 총 비용을 계산할 수 있다. 제1 총 비용 계산은 제1 작업 세트가 데이터 세트의 일부를 포함하는지에 기초할 수 있다. 예로서, 예시된 프로세싱 블록은 제1 작업 세트가 데이터 세트의 제1 부분만을 포함한다고 결정할 수 있다. 그러한 실시예에서, 예시된 프로세싱 블록은 데이터 세트의 제2 부분을 제1 노드에 전송하기 위한 전송 비용(제1 총 전송 비 용이라고 지칭될 수 있음)을 결정할 수 있고, 전송 비용을 제1 총 비용에 포함시킬 수 있다. 예를 들어, 예시 된 프로세싱 블록은 제1 총 비용이 제1 컨테이너를 빌드하기 위한 비용 및 전송 비용을 포함한다고 결정 할 수 있다. 예시된 프로세싱 블록은 제2 노드에 있는 제2 컨테이너에서 제1 함수를 실행하기 위한 제2 총 비용을 계 산할 수 있다. 제2 총 비용은 제2 노드에서 제2 컨테이너를 빌드하기 위해 데이터를 전송하기 위한 데이터 전 송 비용 및 제2 컨테이너를 빌드하기 위한 비용을 포함할 수 있다. 제2 컨테이너는 콜드 컨테이너일 수 있다. 예시된 프로세싱 블록은 제1 총 비용 및 제2 총 비용의 계산에 기초하여 제1 노드 또는 제2 노드에서 함 수를 실행할지를 결정할 수 있다. 예로서, 예시된 프로세싱 블록은 제1 노드에서 제1 컨테이너를 시작할 지를 결정할 수 있고, 제1 작업 세트가 데이터 세트의 적어도 일부를 포함하는지에 기초하여 제1 노드에 있는 제1 컨테이너에서 함수를 실행할 수 있다. 예시된 프로세싱 블록은 제1 총 비용이 제2 총 비용보다 적을 때 제1 노드에서 제1 컨테이너를 빌드하고, 제1 노드에 있는 제1 컨테이너에서 함수를 실행할 수 있다. 이와 달리, 제2 총 비용이 제1 총 비용보다 적을 때 제2 컨테이너가 제2 노드에 빌드될 수 있고, 함수가 제2 노드에 있는 제2 컨테이너에서 실행될 수 있다. 추가 비고 및 예 예 3200은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 실행될 함수를 식별하게 하고, 함수 가 실행 동안 활용할 데이터 세트를 결정하게 하며, 제1 작업 세트가 데이터 세트의 적어도 제1 부분만을 포함 한다고 결정하게 하고 - 제1 작업 세트는 제1 컨테이너를 시작하기 위한 리소스를 포함하고, 제1 작업 세트는 제1 노드에 저장되며, 제1 작업 세트는 제1 노드의 캐시에 저장됨 -, 데이터 세트의 제2 부분을 제1 노드에 전 송하기 위한 전송 비용을 결정하게 하며, 제1 노드에서 함수를 실행하기 위한 제1 총 비용을 결정하게 하고 - 제1 총 비용은 제1 컨테이너를 빌드하기 위한 비용 및 전송 비용을 포함함 -, 제2 노드에 있는 제2 컨테이너에 서 함수를 실행하기 위한 제2 총 비용을 결정하게 하고 - 제2 총 비용은 제2 노드에서 제2 컨테이너를 빌드하기 위해 데이터를 전송하기 위한 데이터 전송 비용 및 제2 컨테이너를 빌드하기 위한 비용을 포함함 -, 제2 총 비 용이 제1 총 비용보다 적을 때 제2 노드에서 제2 컨테이너를 빌드하고, 제2 노드에 있는 제2 컨테이너에서 함수 를 실행하게 하며, 제1 총 비용이 제2 총 비용보다 적을 때 제1 노드에서 제1 컨테이너를 빌드하고, 제1 노드에 있는 제1 컨테이너에서 함수를 실행하게 하는 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 3201은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 실행될 함수를 식별하게 하고, 함수 가 실행 동안 활용할 데이터 세트를 결정하게 하며, 제1 작업 세트가 데이터 세트의 적어도 일부를 포함하는지 를 결정하게 하고 - 제1 작업 세트는 제1 컨테이너를 시작하기 위한 리소스를 포함하고, 제1 작업 세트는 제1 노드에 저장됨 -, 제1 작업 세트가 데이터 세트의 적어도 일부를 포함하는지에 기초하여 제1 노드에 있는 제1 컨테이너에서 함수를 실행하기 위해 제1 노드에서 제1 컨테이너를 시작할지를 결정하게 하는 명령어 세트를 포 함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 3202는 예 3201의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 제1 작업 세트는 제1 노드의 캐 시에 저장된다. 예 3203은 예 3201의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 작업 세트가 데이터 세트의 제1 부분만을 포함한다고 결정하게 하고, 데이터 세트의 제2 부분을 제1 노드에 전송하기 위한 전송 비용을 결정하게 하는 추가 명령어 세트를 포함한다. 예 3204는 예 3203의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제1 노드에서 함수를 실행하기 위한 제1 총 비용을 결정하게 하고 - 제1 총 비용은 제1 컨테이너를 빌드하기 위한 비용 및 전송 비용을 포함함 -, 제2 노드에 있는 제2 컨테이너에서 함수를 실행하기 위한 제2 총 비용을 결정하게 하는 - 제2 총 비용은 제2 노드에서 제2 컨테이너를 빌드하기 위해 데이터를 전송 하기 위한 데이터 전송 비용 및 제2 컨테이너를 빌드하기 위한 비용을 포함함 - 추가 명령어 세트를 포함한다. 예 3205는 예 3204의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 제2 컨테이너는 콜드 컨테이너 이다. 예 3206는 예 3204의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 컴퓨팅 디바이스에 의해 실행될 때, 컴 퓨팅 디바이스로 하여금 제2 총 비용이 제1 총 비용보다 적을 때 제2 노드에서 제2 컨테이너를 빌드하고, 제2 노드에 있는 제2 컨테이너에서 함수를 실행하게 하며, 제1 총 비용이 제2 총 비용보다 적을 때 제1 노드에서 제 1 컨테이너를 빌드하고, 제1 노드에 있는 제1 컨테이너에서 함수를 실행하게 하는 추가 명령어 세트를 포함한다. 향상된 FaaS 함수 구조 예 도 33a는 함수의 함수 구조를 예시한다. 도 32a 내지 도 32d의 실시예와 관련하여 논의된 바와 같이, 함 수 구조는 함수를 실행하기에 적합한 모드를 결정하기 위해 이용될 수 있다. 도 33a에서, 함수 구조 는 데이터 모니커와의 연관을 기술하는 임의적 필드를 포함한다. 함수 구조 필드는 그 안에 포함된 메타 데이터를 식별하기 위해 판독될 수 있으며, 메타데이터에 기초하여 모니커와 연관될 수 있다. 데이터 모니커는 함수 구조의 아이덴티티의 대략적인 표현일 수 있다. 모니커는 함수의 다양한 범용 고유 식별자, 함수의 호출자, 함수의 특정 파라미터, 함수와 연관된 파일 시스템 경로 이름, 예를 들어, Spark에서의 RDD(Resilient Distributed Dataset) 계보, 함수에 의해 액세스되는 관계형 데이터베이스에서의 테이블 스페이스 범위 등을 통 해 세트 함수(예를 들어, 블룸 필터) 및/또는 모니커 구성 API에 의해 함수 구조로부터 구성될 수 있다. 함수 구조에 기인하는 함수는 함수 구조로부터 도출되는 해당 모니커와 소프트 친화성에서 연관된 컨테이 너에서 실행되도록 제공될 수 있다. 따라서, 모니커는 리소스 및 레이턴시를 감소시키기 위해 함수를 효과적으 로 할당하는 데 사용될 수 있다. 데이터 세트 구조는 여러 필드를 포함한다. 필드의 어트리뷰트는 함수 생성 시에 생성될 수 있는 것은 물론 함 수 실행 및 캐시/메모리 스래싱(thrashing) 레벨에 따라 동적으로 업데이트될 수 있다. 함수 구조로부터 수집되는, 함수 실행 동안 터치된 데이터에 기초하여, 함수 구조와 연관된 함수는 데이터의 웜 사본을 소 유할 가능성이 있는 컨테이너에 할당될 수 있어, 이에 의해 데이터 이동을 감소시키고 스래싱 가능성을 감소시 킬 수 있다. 호출자 필드는 함수 호출의 소스(예를 들어, 클라이언트, 컴퓨팅 디바이스, 지리적 영역 등)를 식별하는 데 사용될 수 있다. 호출자 모니커는 소스의 아이덴티티, 위치 및/또는 디바이스를 기술하기 위해 호출자 필드 로부터 결정될 수 있다. 인수들 필드는 함수의 인수를 식별하는 데 사용될 수 있다. 인수는 함수 유형, 기본 데이터 요구사항 등 을 결정하는 데 사용될 수 있다. 예를 들어, 인수에 대한 입력 데이터가 식별될 수 있고, 특정 언어 라이브러 리 및/또는 데이터 요구사항에 대한 액세스가 식별될 수 있다. 더욱이, 특정 유형의 인수는 특정 하드웨어 활 용을 통해 향상될 수 있다. 그와 같이, 함수의 컴퓨터 언어, 데이터 요구사항, 하드웨어 요구사항(예를 들어, 가속기, 메모리 공간, 프로세서 속도) 등을 기술하기 위해 인수들 필드로부터 유형 모니커가 결정될 수 있다. 함수의 다른 어트리뷰트를 식별하기 위해 기타 필드가 사용될 수 있다. 예를 들어, 기타 필드는 실행을 위한 지리적 위치, 클라이언트의 위치 등을 식별하는 데 사용될 수 있다. 다른 모니커는 클라이언트의 지리적 위치 및 위치 등을 기술하기 위해 기타 필드로부터 결정될 수 있다. 다른 모니커는 클라이언트의 지리적 위치에 근접한 또는 데이터가 궁극적으로 전송될 노드를 향해 함수를 조종하는 데 사용될 수 있다. 파일 시스템 경로는 함수의 경로를 결정하는 데 사용될 수 있다. 예를 들어, 파일 시스템 경로는 함수의 출력을 저장할 위치를 식별하는 데 사용될 수 있다. 경로 모니커는 출력을 저장할 위치를 기술하기 위 해 파일 시스템 경로로부터 결정될 수 있다. 경로 모니커는 출력을 저장할 위치에 근접한 노드를 향해함수를 조종하는 데 사용될 수 있다. 데이터베이스 테이블스페이스 범위는 콤팩트한 식별 및 함수의 데이터 세트와 연관시키는 데 있어서의 후 속 사용을 위해 데이터베이스에서의 \"튜플\" 세트의 논리 아이덴티티를 기술하는 데 사용될 수 있다. 범위 모니 커는 다양한 필드 내의 값 또는 어트리뷰트가 범위 최소 값 내지 범위 최대 값 내에 속하는 데이터의 논리 범위 를 기술하기 위해 데이터베이스 테이블 스페이스 범위로부터 결정될 수 있다. 이는 데이터 내의 필드에 의해 충족되는 다양한 제약에 기초하여 함수에서 사용되는 데이터의 범위를 콤팩트하게 기술하는 데 사용될 수 있다. 도 33b는 도 33b에 도시된 바와 같은 향상된 함수 구조로부터의 모니커 식별 방법을 도시하며, 도 32a 내 지 도 32d의 향상된 오케스트레이터(3202, 3242), 및/또는 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래 시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예를 들어, 방법에 도시된 동작을 수행하기 위한 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 등과 같 은 객체 지향 프로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프 로그래밍 언어를 포함하여, 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 추가적으로, 로 직 명령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴 포넌트를 포함할 수 있다. 예시된 프로세싱 블록은 함수와 연관된 함수 구조의 필드들을 식별할 수 있다. 예시된 프로세싱 블록 은 필드들로부터 메타데이터를 결정할 수 있다. 예시된 프로세싱 블록은 필드들로부터 하나 이상의 모니커를 결정할 수 있으며, 여기서 모니커들은 함수 가 실행 동안 활용해야 하는 하나 이상의 리소스를 나타낸다. 예를 들어, 하나 이상의 리소스는 함수가 실행 동안 활용해야 하는 데이터를 포함할 수 있다. 하나 이상의 리소스는 함수의 하드웨어 리소스 요구사항을 추가 로 포함할 수 있다. 하나 이상의 리소스는 함수가 실행 동안 활용해야 하는 하드웨어 가속기를 추가로 포함할 수 있다. 더욱이, 하나 이상의 모니커는 함수를 실행하기 위한 지리적 영역을 나타낼 수 있다. 게다가, 하나 이상의 모니커는 함수의 유형(예를 들면, 이미지 인식 또는 이미지 회전)을 나타낼 수 있다. 위에서 설명된 바 와 같이, 하나 이상의 리소스 및 함수의 유형은 적절한 노드에 함수를 할당하고 효율성을 증가시키면서 레이턴 시를 감소시키기 위해 활용될 수 있다. 추가 비고 및 예 예 3300은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 함수와 연관된 함수 구조의 필드들을 식별하게 하고, 필드들로부터 메타데이터를 결정하게 하며, 메타데이터로부터 하나 이상의 모니커를 결정하게 하는 - 모니커들은 함수가 실행 동안 활용해야 하는 하나 이상의 리소스를 나타내고, 하나 이상의 리소스는 함 수가 실행 동안 활용해야 하는 데이터, 함수의 하드웨어 리소스 요구사항, 함수가 실행 동안 활용해야 하는 하 드웨어 가속기를 포함하며, 하나 이상의 모니커는 함수를 실행할 지리적 영역 및 함수의 유형을 나타냄 - 명령 어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 3301은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 함수와 연관된 함수 구조의 필드들을 식별하게 하고, 필드들로부터 메타데이터를 결정하게 하며, 메타데이터로부터 하나 이상의 모니커를 결정하게 하는 - 모니커들은 함수가 실행 동안 활용해야 하는 하나 이상의 리소스를 나타냄 - 명령어 세트를 포함하는 적 어도 하나의 컴퓨터 판독 가능 매체를 포함한다. 예 3302는 예 3301의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 하나 이상의 리소스는 함수가 실행 동안 활용해야 하는 데이터를 포함한다. 예 3303은 예 3301의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 하나 이상의 리소스는 함수의 하드웨어 리소스 요구사항을 포함한다. 예 3304는 예 3301의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 하나 이상의 리소스는 함수가 실행 동안 활용해야 하는 하드웨어 가속기를 포함한다.예 3305는 예 3301의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 하나 이상의 모니커는 함수를 실행하기 위한 지리적 영역을 나타낸다. 예 3306은 예 3301의 적어도 하나의 컴퓨터 판독 가능 매체를 포함하고, 여기서 하나 이상의 모니커는 함수의 유형을 나타낸다. 동적 배치 및 프리페치 예 현재 기존 솔루션의 경우, FaaS 함수는 함수 실행의 각각의 스테이지에서 최적으로 배치되지 않는다. 예를 들 어, 실행의 FPGA(field-programmable gate array) 버전과 소프트웨어(메모리) 버전 간에 데이터를 리플로 (reflow)하는 것의 리소스 비용이 많이 들 수 있다. 종종 인프라스트럭처는 임의의 주어진 때에 원하는 수(및 유형)의 함수 컨테이너를 빠른 재사용을 위해 이용 가능하도록 유지하기에 충분한 메모리를 갖지 않을 수 있다. 이제 도 34a를 살펴보면, 예시적인 실시예에 따르면, 함수 호출의 빈도에 기초하여 함수를 프리페치하기 위해 호출 그래프가 사용되는 예가 도시된다. 사용자 인터페이스 핸들러는 FaaS 함수 실행을 최적화하기 위한 요청을 수신하고, 차례로, 호출 그래프를 생성할 수 있다. 호출 그래프는 함수들 간의 호출 관계를 나타낼 수 있다. 예시된 예에서, 오케스트레이터는 호출 그래프에서의 함수 호출의 표시된 빈도에 기초하여, 다음에 호출될 가능성이 가장 높은 함수를 프리페치할 수 있다. 프리페치된 함수는 임시 스토리지에 로딩되어 초기화될 수 있다. 예시된 예에서, 프리페치된 함수는 서버의 캐시에 일시적으로 저장될 수 있다. 오케스트레이터는 호출될 가능성이 가장 낮은 함수를 해제하기 위해 서버에 대한 커맨드를 발행할 수 있다. 도 34b는 실시예에 따른 FaaS 함수의 실행을 향상시키기 위한 방법을 예시한다. 방법의 블록에서, 함수 활성화들(\"호출들\")의 빈도를 나타내는 호출 그래프가 생성될 수 있다. 호출 그래프는 함수들 사이의 호 출 관계를 나타내는 제어 흐름 그래프일 수 있다. 가중 호출 그래프에서, 각각의 아크 - 프리커서(조상 함수 (antecedent function))에서 시작되고 하나 이상의 후손 함수(successor function)에서 끝남 - 는 후손의 호출 의 빈도(예를 들면, 해당 프리커서가 해당 후손으로 이어질 확률)로 태깅될 수 있다. 제어 흐름 그래프가 프로 시저들 사이의 호출-리턴(call-return) 관계(및 네스팅)를 갖는 경우, 함수에 대한 호출 그래프가 다른 함수의 실행을 야기하는 조건을 실행하고 점진적으로 트리거하는 다양한 함수의 그래픽 표시이며, 보통 후자의 함수는 전자의 함수에 의해 생성되는 데이터 및 결과를 소비하거나 그에 액세스한다는 점을 제외하고, 호출 그래프는 제어 흐름 그래프와 유사할 수 있다. 예시적인 실시예에 따르면, 현재 함수 F가 실행 중이고 함수 G가 실행되 도록 할 것이라는 지식은 G가 \"프리페치\"될 수 있음 - 그의 구성이 시작될 수 있고, 그의 데이터가 배치/매핑될 수 있는 것 등 - 을 의미한다. 호출 그래프 상의 가중치는 확률 - F가 G의 실행을 야기할 가능성을 나타냄 - 을 나타낼 수 있다. 호출 그래프는 정적으로 형성될 수 있고 이어서 동적으로 미세 조정될 수 있다. 블록에서, 호출 그래프 에 표시된 함수 호출의 빈도에 기초하여 다음에 호출될 가능성이 가장 많은 함수가 프리페치될 수 있다. 즉, 프리페치된 함수는, 프리커서 함수가 이를 활성화시킬 때 함수가 실행될 준비가 되도록, 임시 저장소에 로드되 어 초기화될 수 있다. 블록에서, 호출 그래프의 각각의 단계/영역에서 호출될 가능성이 가장 적은 FaaS 함수는 리소스를 해제하기 위해 언로딩될 수 있다. 종래의 프로그램에서의 일반 프로시저 호출 시퀀스와 유사하게, 하나의 \"호출자\" 함수는 원격 프로시저 호출로 직접적으로 다른 \"피호출자\" 함수를 임의로 호출할 수 있다(이어서 피호출자에 대한 원격 프로시저 호출이 완료 되었다는 표시를 수신하기 위해 대기함). 위에서 언급된 아크는 후손 함수의 수행과 연관된 비용으로 추가로 보강될 수 있다 - FaaS의 경우, 이것은 파라미터 및 결과를 전달하는 비용을 포함할 수 있다 -. 예를 들어, JSON(JavaScript Object Notation) 객체의 오버헤드는, 바이트 단위의 크기 및 피호출자 함수와 호출자 함수를 호스팅하는 2개의 지점 간의 통신 대역폭을 고려하여, 통신될 수 있다. 호출의 빈도, 각각의 호스트에서 이용 가능한 리소스, 호출 오버헤드, 제공되는 가격/우선순위 계층등에 기초하여, 각각의 스테이지에서 FaaS 함수에 대한 최적의 배치가 계산될 수 있다. 스테이지는 동적일 수 있다. 즉, 어떤 함수 F가 활성화될 때마다, 함수 F의 활성화는 어떤 다른 함수 G의 활성화를 결과할 수 있으며, 일반적으로 G는 상이한 어딘가에서 수행될 수 있 다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트 를 포함할 수 있다. 추가 비고 및 예 예 3401은 함수들 간의 호출 관계를 나타내는 호출 그래프를 형성하는 단계 - 호출 그래프는 후손 활성화에 대 한 프리커서의 빈도 또는 가능성을 표시함 -, 호출 그래프에 의해 표시된 함수 호출의 빈도에 기초하여, 가장 가능성이 많은 다음 함수가 호출될 때 이미 실행될 준비가 되어 있도록 가장 가능성이 많은 다음 함수를 프리페 치하는 단계, 및 적어도 하나의 가장 가능성이 적은 다음 함수를 언로딩하는 단계를 포함하는 방법을 포함한다. 예 3402는 예 3401의 방법을 포함하며, 호출 그래프가 호출의 빈도를 나타내는 아크를 이용하는 단계를 추가로 포함한다. 예 3403은 예 3402의 방법을 포함하며, 함수 호출의 상기 빈도/확률에 기초하여 각각의 호스트에서 이용 가능한 리소스를 계산하는 단계를 추가로 포함한다. 예 3404. 예 3401의 방법으로서, 여기서 함수 호출은 기존 애플리케이션과 역호환된다. 예 3405. 예 3401의 방법으로서, 여기서 메모리 무결성 프로토콜이 메모리에서 데이터 버전을 식별하는 데 사 용된다. 예 3406은 함수들 간의 호출 관계를 나타내는 호출 그래프를 형성하는 단계 - 호출 그래프는 함수 호출의 빈도 를 표시함 -, 호출 그래프에 의해 표시된 함수 호출의 빈도에 기초하여, 가장 가능성이 많은 다음 함수가 호출 될 때 이미 실행될 준비가 되어 있도록 가장 가능성이 많은 다음 함수를 프리페치하는 단계, 적어도 하나의 가 장 가능성이 적은 다음 함수를 언로딩하는 단계, 호출 그래프에서 아크를 이용하는 단계 - 아크는 호출 빈도를 나타냄 -, 및 함수 호출의 빈도에 기초하여 각각의 호스트에서 이용 가능한 리소스를 계산하는 단계를 포함하는 방법을 포함하고, 여기서 함수 호출은 기존 애플리케이션과 역호환되고, 여기서 메모리 무결성 프로토콜이 메모 리에서 데이터 버전을 식별하는 데 사용된다. 다중 테넌트 함수의 단계적 다중 버전 개시 예 바로 위에 설명된 예시적인 실시예는 이전 이력에 기초하여 - 예를 들어, 제2 함수 자체뿐만 아니라 그 프리커 서 체인의 서브세트에 기초하여 - 함수의 체인 C: {F(i) ... F(ii) ... F(iii) ...F(n)}에서의 제2 함수 \" B\"로 확장될 수 있다. 환언하면, 함수의 소프트웨어 기반, 최소 가속 또는 가속 버전을 론칭할지 여부를 선택 할 때, 예시적인 실시예는 함수 B의 사용 이력뿐만 아니라 B에 선행하는 체인 내의 프리커서 함수 Bp의 사용 이 력을 고려할 수 있다. 도 35a는 함수 B의 선행 함수 Bp를 도시하는 블록 다이어그램이며, 여기서 현재 실행 중인 함수의 선행 함수 Bp는 프리페치 및 호출될 다음 함수를 결정하는 데 사용될 수 있 다. 이 실시예의 예시적인 이점은 (다수의 경쟁자 간에) 제한된 가속 리소스들의 사용을 균형을 이루게 하는 것과 동시에, 실행의 하드웨어(예를 들어, FPGA) 버전과 소프트웨어(메모리) 버전 사이에서 데이터를 리플로하는 것 의 비용을 최소화하는 것을 포함한다. 실제로, 이 실시예는, 데이터의 리플로가 최소화되도록, 전체 버전을 활 성화시키는 것보다 가속 함수의 최소 버전의 체인을 활성화시키는 것을 가능하게 할 수 있다. 예시적인 실시예에 따르면, 1의 체인 깊이: Bp -> B가 있을 수 있고, 여기서 Bp는, 위에서 설명된 바와 같이, 함수 B에 선행하는 함수를 나타낸다. 이 실시예에 따르면, 함수 Bp는 함수 B의 즉각적인 프리커서이고, x 및 y는, 제각기, 함수 B의 전체 버전에 대 한 론칭 임계치 및 회수 임계치일 수 있다. 유사하게, u 및 v는, 제각기, Bp의 전체 버전에 대한 론칭 임계치 및 회수 임계치일 수 있다. 함수의 생존 시간이 만료된 경우, 또는 실행되는 채로 유지하기 위한 그의 가중 척 도와 같은 다른 고려사항이 어떤 임계치 아래로 떨어진 경우, 함수의 리소스가 '회수'된다. 반대 방향으로, 론 칭 임계치와 관련하여, 일반적으로 캐싱되지 않거나 프리페치되지 않는 함수가 사용 증가의 징후를 보이는 경우, 사용이 증가함에 따라, 해당 함수를 캐싱되고 어쩌면 프리페치된 채로 유지하는 것이 매력적으로 된다. 따라서, 예시적인 실시예에 따르면, 함수의 프리커서 함수가 현재 실행 중이고 빈도가 증가하는 경우, 프리커서 함수는 함수 B가 프리페칭되는 것에 대한 적격성(eligibility)이 론칭 임계치를 초과하게 할 수 있다. 예시적 인 실시예에 따르면, 각자의 함수에 대한 회수 임계치는 론칭 임계치보다 낮을 수 있다. 또한, 원하는 하드웨어 또는 소프트웨어 조건이 충족되도록 보장하기 위해, u가 저하될 때는 x가 작은 양 z(결 합 기여도(coupling contribution))만큼 저하될 수 있고, v가 상승될 때는 y가 작은 양 z만큼 상승될 수 있다. 그러한 수정은 x, y 및 |x - y| 모두가 다양한 최대/최소 규칙을 위반하지 않는 값을 취하도록 제약된다; 다른 예시적인 실시예에 따르면, u와 v가 변경되도록 허용되지 않지만, x와 y가 변경될 수 있는 경우, 가상 값 u' 및 v'(u 및 v에 대한 섀도 값(shadow value))가 계산될 수 있으며, 결합 기여도 z가, 제각기, 계산된 값 u' 및 v'에 기초하여 x 및 y에 적용될 수 있다. 예시적인 실시예에 따르면, Bp의 리소스 이용률을 억제할 필요가 있기 때문에, 예를 들어, 값 'u' 및 'v'는 변경되도록 허용되지 않을 수 있지만; Bp로의 도착률의 업틱(uptic k)이 있는 경우, 업틱은 하방으로(B로의 도착률이 증가할 것이기 때문임) x에 영향을 미칠 수 있으며, 유사하게 y는 상방으로(B에 대한 회수율을 감소시키기 위해) 영향을 받을 수 있다. 위에서 설명된 실시예는, 추이적으로, 체인 깊이 > 1로 일반화하는 데 사용될 수 있다. 일반적으로, 결합 기여 도(z)를 계산할 때 하나 이상의 파라미터가 있을 수 있다 - 예를 들어, 리소스 제약된 환경에서, 함수 B 및 그 의 프리커서에 대한 수요가 떨어질 때(따라서 B가 더 빨리 회수될 수 있음) 주어진 가속 함수 B에 대해 가변 양 의 생존 시간 증가가 적용될 수 있고; 유사하게, 전체 수요가 낮을 때 또는 SLA 요구사항이 엄격할 때, B의 프 리커서에서의 관측에 기초하여, 함수 B를 론칭하는 것에 대한 더 강한 긍정적 편향이 있을 수 있고 B를 회수하 는 것에 대한 더 강한 부정적 편향이 있을 수 있다. 이제 도 35b를 참조하면, 예시적인 실시예에 따르면, 방법의 블록에서, 함수 A가 론칭될 수 있다. 블록에서, 함수 A에 선행하는 프리커서 함수들 B가 식별될 수 있다. 블록에서, 프리커서 함수들 B 및 함수 A의 사용 이력에 기초하여 함수 A의 가속 버전을 론칭할지가 결정될 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트 를 포함할 수 있다. 추가 비고 및 예 예 3501은 함수를 론칭하는 단계, 함수에 선행하는 프리커서 함수들을 식별하는 단계, 함수에 선행하는 프리커 서 함수들 및 함수의 사용 이력에 기초하여 함수의 가속 버전을 론칭할지를 결정하는 단계, 및 함수 및 프리커 서 함수들을 리포지토리에 저장하는 단계를 포함하는 방법을 포함한다.예 3502는 예 3501의 방법을 포함하며, 메시지 인증 코드(MAC)를 사용하여 메모리에서 함수 버전을 식별하는 단 계를 추가로 포함한다. 예 3503은 예 3501의 방법을 포함하며, 컨테이너가 원격 프로시저 호출(RPC)을 가로채기하여 이를 로컬로 제공 하는 단계를 추가로 포함하며, 여기서 함수는 기존 애플리케이션에 투명하고 역호환되어야 한다. 예 3503은 예 3501의 방법을 포함하며, 함수에 관련된 데이터를 프리페치하는 단계를 추가로 포함한다. 예 3504는 함수를 론칭하는 단계, 함수에 선행하는 프리커서 함수들을 식별하는 단계, 함수에 선행하는 프리커 서 함수들 및 함수의 사용 이력에 기초하여 함수의 가속 버전을 론칭할지를 결정하는 단계, 메시지 인증 코드 (MAC)를 사용하여 메모리에서 함수 버전을 식별하는 단계, 컨테이너를 통해, 원격 프로시저 호출(RPC)을 가로채 기하여 이를 로컬로 제공하는 단계 - 함수는 기존 애플리케이션에 투명하고 역호환되어야 함 -, 함수에 관련된 데이터를 프리페치하는 단계, 및 함수 및 프리커서 함수들을 리포지토리에 저장하는 단계를 포함하는 방법을 포 함한다. 적응적 회수율 예 이제 도 36a를 살펴보면, 다른 예시적인 실시예에 따르면, 도 36a는 함수가 실행될 확률에 따라 컨테이너의 웜 상태를 유지하는 예를 도시한다. 상세하게는, 컨테이너에서 함수 X를 완료(실행)할 때, 컨테이너 에서 다른 함수 Y가 실행될 확률 P가 있다. 예를 들어, 비디오 감시 애플리케이션에서, 함 수 X는 미디어 트랜스코딩 함수일 수 있고 함수 Y는 탐지 및 조대하게 나뉜 매칭 함수(예를 들면, 비디오 스트림이 사람 또는 사람의 일부를 보여주는지를 결정하는 함수)일 수 있거나; 또는 함수 X는 조 대하게 나뉜 매칭 함수일 수 있는 반면 함수 Y는 인식 함수(예를 들면, 비디오에서 탐지된 임의의 사람이 또한 데이터베이스에서 알려진 사람 - 예를 들면, 친구 또는 가족 구성원, 낯선 사람 등 - 인지를 결정하는 함 수)일 수 있다. 이 확률 P은 일정할 수 있지만, 프로세싱 시간 및 다른 시간적으로 또는 공간적으로 상 관성이 있는 인자에 기초하여, 일반적으로 가변적이다. 오케스트레이터의 확률 평가기는 함수 Y에 대한 컨테이너를 웜으로 유지하는 결정을 생성할 수 있는데, 이는 그러한 확률 P의 동적 평가에 의존할 수 있으며; 또는 더 일반적으로, 유형 Y의 함수에 대한 컨테이너 회수율은 이 확률 P에 따라 달라질 수 있다. 확률 P의 최근 평가 및 과거 평가 둘 모두에 기초하여 회수율 및 결정을 적응시킴으로써, 최근 정보에 적응적이기도 하고 장기 정보와 관련 하여 로드 밸런싱되기도 하는 전체 목표가 달성될 수 있다. 바로 위의 예시적인 솔루션은 함수 호출 그래프 - 또는 서비스 메시 - 로 일반화될 수 있으며, (i) 회수 시간이 적응적으로 변화될 수 있을 뿐만 아니라 (ii) 다수의 그래프 에지에 걸친 확률 흐름에 대한 더 긴 범위의 평가 가 활성화 시간(워밍업) 시간이 사소하지 않은 해당 함수를 미리 활성화시키는 데 사용될 수 있도록 가속 함수 로 추가로 일반화될 수 있다. 일 실시예에서, 확률 그래프 모델(PGM)은 하나 이상의 상호의존적 함수의 확률 흐름을 인수 분해하기 위한 범용 프레임워크로서 사용될 수 있다. PGM 인수 분해 기술 및 라이브러리는 각각의 함수 Y의 동적 확률을 그 의 프리커서 함수 X에 대한 그의 종속성에 기초하여 획득하고, 함수 X의 동적 확률을 함수 X(365 5)의 프리커서에 기초하여 획득하는 데 사용될 수 있다. 더 간단하지만 실행 가능한 단순화는 약한 확률 흐름 을 제거하고(예를 들어, 약한 상관성이 있는 함수를 상호 독립적인 것으로 취급함), 그러한 그래프를 희소하게 만들며, 이어서 확률적 프로그래밍 언어(예를 들어, FIGARO)로 작성된 PGM 솔버를 적용하는 것일 수 있다. 다 른 구현예는 검색 엔진 페이지 순위 스킴을 가중치(사전에 자체적으로 추정되거나 동적으로 추론될 수 있음)에 의해 함수의 인기도를 그의 프리커서 또는 선조의 인기도에 관련시키는 단순화된 형태로서 사용하는 것, 및 이 용 가능한 데이터에 기초하여 상이한 함수가 얼마나 자주 실행될 가능성이 있는지를 추정하는 반복 페이지 순위 솔루션을 사용하는 것이다. 그러한 접근법은, 웜 컨테이너 또는 생존 시간(TTL) 파라미터의 개수를 제어하기 위해 하드 코딩된 상수 또는 간단한 휴리스틱스를 사용하는 대신에, 가속 또는 전통적인(CPU 소프트웨어 기반) 함수 실현을 위한 민첩한 리 소스 할당을 가능하게 할 수 있다. 대안적으로, 이 예시적인 실시예는 다른 실현과 함께 작동할 수 있고, 상기 확률 흐름 기술을 사용하여, 수집된 원격 측정의 주기적 평가에 기초하여 컨테이너 또는 그 TTL의 개수에 걸쳐 그러한 구성 설정을 조정하는 데 사용될 수 있다. 게다가, 전체 최적화 문제 자체는 리소스 요구사항에 의해 정규화된 더 높은 확률 활성화의 처리량을 최대화함으로써 문제의 리소스 제약된 처리량을 최대화하려고 시도하 는 빈 패킹 문제를 가질 수 있다.이제 도 36b를 살펴보면, 실시예에 따른 웜 컨테이너로부터 FaaS 함수를 실행하는 방법이 예시되어 있다. 방법 의 블록에서, 함수 A가 론칭될 수 있다. 블록에서, 후속 함수가 실행될 확률의 동적 평가에 기초하여 함수 A의 후속 함수를 실행하기 위한 컴퓨팅 컨테이너의 준비 상태(readiness)(예를 들어, 웜 상태)가 유지된다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트 를 포함할 수 있다. 추가 비고 및 예 예 3601은 함수를 실행하는 단계, 함수의 실행에 후속하여, 후속 함수가 실행될 확률의 동적 평가에 기초하여 후속 함수를 실행하기 위한 컨테이너의 준비 상태를 유지하는 단계를 포함하는 방법을 포함한다. 예 3602는 함수를 실행하는 단계, 함수의 실행에 후속하여, 후속 함수가 실행될 확률의 동적 평가에 기초하여 후속 함수를 실행하기 위한 컨테이너의 준비 상태를 유지하는 단계, 함수 로직이 아니라 함수 데이터만을 클리 어시키는 단계, 별도의 함수에 별도의 키가 할당될 때 MKTME(multi-key total memory encryption) 키를 결정하 는 단계, 및 관리 런타임이 아니라 사용자 프로그램만을 회수하는 단계를 포함하는 방법을 포함한다. 적응적 메모리 계층화 예 함수가 덜 사용되게 될 때, 함수가 차지하는 용량의 양이 감소될 수 있다. 종종 인프라스트럭처는 임의의 주어 진 때에 원하는 수(및 유형)의 함수 컨테이너를 빠른 재사용을 위해 이용 가능하도록 유지하기에 충분한 메모리 를 갖지 않을 수 있다. 도 4에 도시된 것과 같은 향상된 FaaS 시스템의 예시적인 실시예에 따르면, 함수가 고성능 메모리 계층에 그의 데이터 또는 코드를 가져야 하는지를 결정할 때 함수의 크기와 사용 빈도 둘 모두가 고려될 수 있다. 다른 실 시예에서, 이것은 사용량에 기초할 수 있다: 덜 사용되는 함수를 완전히 회수하는 대신에 (3DXP 메모리와 같은) 하위 성능 계층에 생존 상태로 유지. 메모리에서의 계층화를 갖는 향상된 FaaS 시스템의 일 실시예에 따르면, 메모리에서의 계층화는 크기 및 사용량 둘 모두에 적응적으로 될 수 있다. 즉, 크기가 크면, 함수가 자주 사용 되더라도, 3DXP와 같이 멀리 떨어진 계층에 배치될 수 있다. 사용량이 적은 경우에도, 함수가 멀리 떨어진 계 층에 배치될 수 있다. 게다가, 함수가 더 멀리 있는 계층에 있는 경우, 함수는, 이미 더 적은 리소스를 사용하 고 있기 때문에, 그에 대응하여 더 긴 생존 시간을 제공받아야 한다. 다른 실시예에서, MCDRAM/HBM 또는 DDR 계층에서와 같이 성능에 중요한 메모리 용량을 초과 구독 (oversubscribe)하지 않고 전체적으로 더 높은 웜 컨테이너 속도를 달성하기 위해 다수의 실제 또는 가상화된 메모리 계층의 사용이 설명되었을 수 있다. 도 37a에 도시된 바와 같은 본 예시적인 실시예에서, 동일한 접근 법이 함수 내에서도 함수 체인에 대해서도 적용될 수 있다. 1. 함수 내: 첫째, 종종 함수가 다중 계층 메모리에서의 성능 계층(예를 들면, MCDRAM/HBM, DRAM)에서 이용 가능한 용량의 양에 비해 너무 클 수 있다는 점을 고려한다 - 예를 들어, Amazon Lambda는 컨테이너당 400MB의 제한을 부과하는데, 이는 많은 토폴로지의 공개 버전에는 충분히 크지만 MKL-DNN(Math Kernel Library for Deep Neural Learning Networks)에는 너무 작을 수 있다 -.그 양태가 도 37a 및 도 37b에 예시되어 있는, 본 예시적인 실시예에 따르면, 함수는 크기 및 사용량 둘 모두에 따라 세그먼트화될 수 있으며, 따라서: 1a. DRAM 배치를 할당받기에는 너무 큰 함수는 외부 메모리 계층에 사전 할당될 수 있고(도 37a); 1b. 전체적인 과거 사용 빈도가 높지만 이미 현재 일시중지 비율 임계치를 초과한 함수는 즉각 회수되는 대신 에 외부 메모리 계층에 잔존될 수 있으며; 이들은 거기에서 더 오랜 지속기간 동안 에이징될 수 있다. 일시중 지 비율 임계치는 사실상 가장 최근의 사용 이후의 함수의 컨테이너에 대한 생존 시간일 수 있다. 해당 시간에 걸쳐 어떠한 요청도 도착하지 않는 경우, 해당 리소스 - 주로 메모리 - 가 해제되도록 함수가 제거될 수 있다. 사용 통계 및 메모리 페이지 액세스 프로파일링에 따라, 시간이 지남에 따라, 더 핫한 페이지 세트는 MCDRAM/HBM/DDR 예약 범위에 반영될 수 있다 - 함수의 동적 코드 풋프린트가 너무 커서 그 일부가 임시로 성능 계층 할당되는 것으로부터 이익을 얻을 수 없지 않는 한 -. 2. 함수의 체인에 걸쳐: 바로 위에 설명된 실시예는 함수 체인으로 확장될 수 있으며, 따라서: 2a. 도 37b에 예시된 바와 같이, 함수의 체인(또는 웹)에서 함수 X(i)의 조상 함수 또는 종속 함 수가 - 상위 계층 할당 메모리에서든 하위 계층 할당 메모리에서든 간에 관계없이 - 활성화된 경우, X (i)를 재활용하는(예를 들어, X(i)를 호스팅하는 컨테이너를 해체하는) 대신에, X(i)는 해당 조상 및/또는 종속 함수의 연속에 근거하여 외부 계층 배치를 제공받을 수 있다. 이러한 적응적 메모리 계층화 접근법이 구현될 수 있는데, 그 이유는 실행의 레이턴시가 메모리가 메모리의 외 부 계층에 있는 비-콜드 컨테이너의 성능 저하보다 콜드 론칭(cold launch)에 훨씬 더 민감하기 때문이다. 게 다가, 이 접근법은, 가까운 계층에 충분한 자유 용량이 있을 때, 먼 계층에 유지되는 그러한 활성 컨테이너의 임시 승격을 배제하지 않는다. 도 37a의 발명 개념은 함수 내의 상이한 객체에 적용될 수 있다. 예시적인 실시예에서, 소프트웨어는 함수가 함수의 데이터의 어떤 부분을 가까이 둘 것인지 그리고 어떤 부분을 그렇게 하지 않을 것인지에 대해 더 많이 알 수 있다. 따라서, 예를 들어, 자바 너서리(Java nursery)(새로운 객체(young object) 영역)에 통상적으로 할당될 수 있는 객체의 경우, 객체가 더 오랜 지속기간 동안 사용될 가능성이 있는 것으로 알려진 경우, 객체는 다른 어떤 곳에 - 예를 들면, 성능이 떨어지는 메모리 계층에 - 할당될 수 있다. 즉, 큰 함수의 전체 함수 보 디를 외부 계층에 배치하는 대신에, 비-너서리 메모리가 어차피 조만간 회수될 수 있기 때문에, 큰 함수의 비- 너서리 부분이 외부 계층에 배치될 수 있다. 예시적인 실시예에 따르면, 도 37a 또는 도 37b에 도시된 외부 계층이, 예를 들어, 하드웨어 키 메커니즘에 의 해 보호되지 않기 때문에, 프라이버시 공격으로부터 보호되지 않을 수 있는 경우가 있을 수 있다. 따라서 그 경우에, 솔루션은 소프트웨어로 암호화된 외부 계층에 함수의 보디를 유지하고, 이어서 해당 함수가 활성화될 필요가 있을 때 그를 복호화하여, 함수 보디를 HW 보호가 적용되는 메모리 계층에 배치하는 것이다. 그러한 암 호화-복호화를 위해, 키는 함수와 연관될 수 있고, 여기서 키는 HW 보호 메모리 내에서 보호되며, 해당 키는 소 프트웨어 기반 암호화-복호화 방법에서 사용될 수 있다. 함수의 보디 및 상태를 복호화하는 것은, 특히 그의 크기가 큰 경우, 처음부터 재구성하는 것보다 저렴할 수 있다. 이제 도 37c를 살펴보면, 실시예에 따른 함수를 적응적으로 메모리 계층화하는 방법이 예시된다. 방법의 블록에서, 함수 A가 론칭될 수 있다. 블록에서, 함수 A의 크기 및 사용 빈도가 결정된다. 블록 에서, 함수 A가 자주 사용되는지가 결정된다. 블록에서, 함수 A가 자주 사용되는 것으로 결정되는 경우, 블록에서, 함수 A가 크기가 큰지가 결정된다. 함수 A가 크기가 큰 경우, 블록에서, 함수 A 가 멀리 있는 메모리 계층에 배치된다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트 를 포함할 수 있다. 추가 비고 및 예 예 3701은 함수를 실행하는 단계, 함수의 크기 및 사용 빈도를 결정하는 단계, 및 함수가 자주 사용되고 크기가 큰 경우, 함수를 멀리 있는 메모리 계층에 배치하는 단계를 포함하는 방법을 포함한다. 예 3702는 예 3701의 방법을 포함하며, 암호화를 사용하여 메모리 계층구조에서 함수를 이동시키는 단계를 추가 로 포함한다. 예 3703은 예 3701의 방법을 포함하고, 캐시를 사용하여 함수들 사이에서 통신하는 단계를 포함한다. 예 3704는 함수를 실행하는 단계, 함수의 크기 및 사용 빈도를 결정하는 단계, 함수가 자주 사용되고 크기가 큰 경우, 함수를 멀리 있는 메모리 계층에 배치하는 단계, 암호화를 사용하여 메모리 계층구조에서 함수를 이동시 키는 단계, 및 캐시를 사용하여 함수들 사이에서 통신하는 단계를 포함하는 방법을 포함한다. 빠른 클래스 로딩 예 CSP는 일반적으로 FaaS를 위한 유연한 스케줄링 메커니즘/모듈을 활용할 수 있다. FaaS를 위한 관리 런타임 컨 테이너를 로딩하고 해체하는 것은 비용이 많이 들 수 있는데, 그 이유는 그러한 것이다른 목적(예를 들어, 활 성 함수의 프로세싱, 새로운 함수의 분배 및 스케줄링, 임의의 다른 유형의 수익 창출 목적 등)에 사용될 수 있 는 귀중한 CPU 시간을 소비할 수 있기 때문이다. 따라서, 컨테이너를 로딩하고 해체하는 것은 효율성을 감소시 키고 전력 사용을 증가시킬 수 있다. 이 문제는 Java와 같은 정적 유형 관리 런타임 언어에서 특히 심각할 수 있는데, 그 이유는, 예를 들어, JVM(java virtual machine)과 같은 관리 런타임 시스템이, 예를 들어, 간단한 \"Hello World\" 프로그램을 실행하기 위해서조차도 전체 기본 클래스 라이브러리 세트를 로딩할 필요가 있을 수 있기 때문이다. 이것은 종래의 데이터 센터 사용에는 문제가 아닐 수 있지만, 그러한 것이 FaaS에는 비용이 많 이 든다. 오래 실행되는 애플리케이션 또는 지속적인 마이크로서비스와 달리, FaaS 실행에 대한 요청의 애드혹, 버스티, 및 예측 불가능한 도착률은 QoS 기대치를 달성하기 어렵게 만든다 - QoS 기대치 자체가 함수마다 다른 경우 특 히 그렇다 -. 예시적인 실시예에 따르면, 도 38a의 블록 다이어그램에 예시된 바와 같이, 워크로드 기반 클래스 로딩 최적화 모듈이 제공되며, 여기서 사용된 클래스만이 최적화된 클래스 로더에 의해 로딩된다. 이 모듈은 빠른 관리 런 타임 로드 시간을 가능하게 한다. 도 38a에서, 클래스 사용량 데이터는 커스텀 관리 런타임 시스템 클래스 로더(예를 들어, 커스텀 자바 가상 머신)를 통해 획득될 수 있으며, 여기서: 커스텀 관리 런타임 시스템 클래스 로더의 분석기 는 FaaS 서비스의 함수의 첫 번째 실행 동안 호출될 수 있다. 일부 실시예에서, 분석기는 첫 번째 실행 이후에 발생하는 함수의 실행 동안 호출될 수 있다. 클래스 종속성 그래프, 클래스, 메서드 및 변수 초기 화, 오프셋 계산, 탈가상화(de-virtualization), JNI 함수를 JAVA 네이티브 메서드에 바인딩하는 것에 관련된 데이터와 같은 사용량 데이터는 나중에 클라우드 함수를 호출하기 위해 메타데이터 파일로서 저장할 수 있다. 워크로드 입력은 FaaS 함수에 대한 입력 및/또는 값을 포함할 수 있다. - 커스텀 관리 런타임 시스템 클래스 로더는 해당 함수의 모든 후속 실행을 위해 특정 FaaS 함수와 연관 된 메타데이터 파일을 메타데이터 파일 로더를 통해 로딩할 수 있다. - 클래스 사용량 데이터, 워크로드 입력(예를 들어, 특정 FaaS 함수에 대한 입력) 및 FaaS 머신 러 닝 프레임워크로부터의 데이터를 포함한 상이한 데이터 소스로 인해 단일 FaaS 함수에 대해 다수의 메타 데이터 파일이 확립될 수 있다. FaaS 머신 러닝 프레임워크에 의해 생성된 머신 러닝 알고리즘 및/또는 스킴은 위에서 설명된 비효율성을 감소 및/또는 제거하기 위해 커스텀 관리 런타임 시스템 클래스 로더의추가 향상을 위해 사용될 수 있다. 향상(예를 들어, 가속기 사용, 특정 노드 사용, 실행 타이밍 등)은 커스텀 관리 리소스 시스템 클래스 로더에 제공되고 메타데이터 파일 로더로서 저장될 수 있다. 더욱이, FaaS 머신 러닝 프레임워크는 함수에 대한 향상이 성공적인지에 기초하여 수정될 수 있다. 예를 들어, 향상은 함수의 향후 실행에 대한 수정을 포함할 수 있다. 수정이 어떤 방식으로든 효율성을 증가시키는 경우 (감소된 전력, 더 낮은 레이턴시, 감소된 리소스 사용량 등), 수정은 성공한 것으로 간주될 수 있으며 FaaS 머 신 러닝 프레임워크는 함수의 향후 호출에서는 물론 다른 함수에 대해서도 유사한 그러한 수정을 시도할 수 있다. 수정이 성공하지 못한 경우, FaaS 머신 러닝 프레임워크는 수정을 롤백하고 이러한 수정을 다 른 함수에 적용하지 않을 수 있다. 예시적인 실시예에 따른 FaaS 머신 러닝 프레임워크는 함수의 이력으로부터 개발된 시간순 피드백과 동시 에 그리고 독립적으로 발생하는 많은 수의 함수 활성화로부터 다이제스트(digest)된 클라우드 스케일 피드백 둘 모두의 연속적인 적용을 용이하게 할 수 있다. 이러한 방식으로, 이는 군중 학습(crowd learning)과 조합된 지 속 학습의 한 형태이다. FaaS 머신 러닝 프레임워크는 실제 클래스 사용량 데이터, 워크로드 입력 및 메타데이터 파일 로더로부터의 메타데이터 및 분석기로부터의 데이터에 기초하여 트레이 닝할 수 있다. 이제 도 38b를 살펴보면, 예시적인 실시예에 따르면, 방법의 블록에서, FaaS 서비스의 함수의 초기 실행 동안 분석기 함수가 호출될 수 있다. 블록에서, 사용량 데이터가 함수의 후속 실행을 위해 메타데 이터 파일로서 저장될 수 있다. 블록에서, 메타데이터 파일이 함수의 후속 호출들을 위해 로딩될 수 있 다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트 를 포함할 수 있다. 이제 도 38c를 살펴보면, 예시적인 실시예에 따르면, 방법의 블록에서, FaaS 서비스의 함수의 초기 실행 동안 분석기 함수가 호출될 수 있다. 블록에서, 머신 러닝 프레임워크가 트레이닝될 수 있다. 일 부 실시예에서, 머신 러닝 프레임워크는 커스텀 관리 런타임 시스템 클래스 로더에 의해 저장된 메타데이터, 클 래스 사용량 데이터 및 함수와 연관된 워크로드 입력에 기초하여 트레이닝될 수 있다. 일부 실시예에서, FaaS 제공자는 주어진 언어 및/또는 런타임에 대한 표준 라이브러리 및 런타임 시스템과 상이 하고 그리고/또는 커스텀 제작될 수 있는 FaaS 배포 패키지에 특정 런타임 시스템 및/또는 라이브러리를 포함하 도록 개발자에게 요청할 수 있다. 일부 실시예에서, 제안된 런타임 시스템 및/또는 라이브러리는 FaaS 제공자 에 의해 또는 서드파티에 의해 제공될 수 있다. 일부 실시예에서, 커스텀 런타임 시스템은 개발자 또는 사용자 에게 함수의 실행 특성에 관한 추가 정보(예를 들면, 그 중에서도, 실행 시간, 실행된 명령문의 수, 코드 커버 리지, 전력/에너지 소비, 할당된 메모리의 양, 발생한 예외의 수, 또는 잘못 예측된 분기 명령어, OS 페이지 폴 트, 및 데이터/명령어 캐시 미스의 수를 포함하여 코드 실행과 연관된 마이크로 아키텍처 이벤트에 관한 원격 측정 데이터와 같은 코드 실행 특성에 관한 프로파일 정보)를 제공할 수 있다. 일부 실시예에서, 커스텀 런타 임의 사용은 표준 런타임에 비해 더 짧은 또는 더 긴 실행 시간을 결과할 수 있다. 특히, 지능형 커스텀 런타 임 시스템에서, 지능형 런타임이 함수의 전형적인 거동에 관해 학습하고 더 빠른 성능을 추측하고 확인하는 것 과 같은 프리프로세싱 및/또는 예상 기술을 사용할 수 있으므로, 시간이 지남에 따라 동일한 코드의 실행이 개선될 수 있다. 그러한 실시예에서, 동일한 코드를 실행하는 비용은 시간이 지남에 따라 더 저렴해질 수 있으며, 이러한 변화는 런타임 및/또는 라이브러리의 커스터마이제이션을 통해 개발자 또는 사용자에 의해 관측 가능할 수 있다. 따라서, 지능형 런타임은 함수의 실행 환경을 커스터마이징할 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트 를 포함할 수 있다. 추가 비고 및 예 예 3801은 FaaS 서비스의 함수의 초기 실행 동안 분석기 함수를 호출하는 단계, 함수의 후속 호출을 위해 사용 량 데이터를 메타데이터 파일로서 저장하는 단계, 및 함수의 후속 호출을 위해 메타데이터 파일을 로딩하는 단 계를 포함하는 방법을 포함하고, 여기서 다수의 메타데이터 파일은 단일 함수에 대응한다. 예 3802는 예 3801에 따른 방법이며, 실행 환경에 기초하여 함수를 회수하는 단계를 추가로 포함한다. 예 3803은 예 3802에 따른 방법이며, 실행 환경에서 보안 정책을 구현하는 단계를 추가로 포함한다. 예 3804는 예 3801에 따른 방법이며, 여기서 일부 함수 세트는 동일한 MKTME 키로 인코딩되어야 한다. 예 3805는 FaaS 서비스의 함수의 초기 실행 동안 분석기 함수를 호출하는 단계, 함수의 후속 호출을 위해 사용 량 데이터를 메타데이터 파일로서 저장하는 단계, 함수의 후속 호출을 위해 메타데이터 파일을 로딩하는 단계, 실행 환경에 기초하여 함수를 회수하는 단계, 및 실행 환경에서 보안 정책을 구현하는 단계를 포함하는 방법을 포함하고, 여기서 다수의 메타데이터 파일은 단일 함수에 대응하고, 여기서 일부 함수 세트는 동일한 MKTME 키 로 인코딩되어야 한다. 함수 리소싱 예 FaaS 활성화에서의 주요 과제 중 하나는 효율성을 극대화하고 QoS 준수 실행을 폭넓게 변화시키면서 민첩한 리 소스 밸런싱이다. 오래 실행되는 애플리케이션 또는 지속적인 마이크로서비스와 달리, FaaS 실행에 대한 요청 의 애드혹, 버스티, 및 예측 불가능한 도착률은 QoS 기대치를 달성하기 어렵게 만든다 - QoS 기대치 자체가 함 수마다 다른 경우 특히 그렇다 -. 컨테이너에 대해 다른 기술(예를 들어, RDT 기술)을 사용하여 필요한 리소스를 사전 예약하고 이어서 해당 컨테 이너를 요구가 사전에 알려지지 않은 어떤 함수에 할당하는 것은 어려울 수 있다. 따라서, 도 4에 도시된 바와 같은 향상된 FaaS 시스템의 실시예는 함수가 할당되는 컨테이너에 대해 사전 예약되어야 하는 함수의 리소스 요 구(예를 들어, 캐시 용량이 얼마인지, 메모리 BW가 얼마인지 등)를 식별하기 위해 제공된다. 이 정보를 캡처하 기 위해, 시간순 및 클라우드 전체(cloud-wide) 이력 메커니즘 둘 모두가 사용되며, 이에 의해 이전에 실행된 함수가 무엇을 필요로 하는지를 알 수 있고; 그리고 이어서 해당 정보가 향상된 FaaS 시스템에 의해 RDT 파라미 터를 설정하는 데 사용될 수 있다. 예시적인 실시예에 따르면, 도 39a에 예시된 바와 같이, FaaS 프레임워크는 함수의 이력로부터 개 발된 시간순 피드백 및 동시에 그리고 독립적으로 발생하는 함수의 많은 수의 활성화로부터 개발되 는 클라우드 스케일(수평) 피드백 둘 모두의 연속적인 적용을 용이하게 한다. 이러한 방식으로, 이는 함수의 런타임 시에 구현될 수 있는 군중 학습과 조합된 지속 학습의 한 형태이다. 이제 도 39b를 살펴보면, 예시적인 실시예에 따르면, 각각의 함수 유형에 대해 이하의 컴포넌트/양태가 제공될 수 있다: 1. QoS 매니페스트 벡터 - {레이턴시, 처리량, 변동성, 이용률, 비용 등}의 다차원 공간에서의 벡터로서 요망되는 특정 QoS 혼합을 기술하며, 각각의 QoS 벡터가 단위 구체 Q 내부의 값을 취하도록 공통 기준으로 정규 화되며, 여기서 데이터는 데이터 간의 관계가 크기 또는 스케일 불변일 수 있도록 표현된다. 2. 리소스 비용 함수의 대응하는 리소스 비용 벡터 {CPU 사이클, 메모리 BW, IO BW, ... 등}, 비용 함 수(예를 들어, 코드의 루틴)가 단위 구체 C 내부의 값을 취하도록 공통(머신 중립적) 기준으로 유사하게 정규화 된다. 도 38a의 커스텀 관리 런타임 시스템 클래스 로더는 적어도 리소스 비용 벡터의 컴포넌트를 생성 할 수 있다. 예를 들어, 메타데이터 파일 로더는 FaaS 함수에 기초하여 벡터를 식별할 수 있다. 3. 벡터 Q를 C 내의 벡터 세트에 매핑하는 다중 값 만족도 함수 벡터 G = {g1, g2, ... gN} - 예를 들 어, 여기서 Q로부터 C로의 다수의 상이한 벡터 g1(Q), g2(Q), ... gN(Q)는 주어진 벡터 Q를 충족시킨다. 4. C와 Q 둘 모두는 기본 연속 도메인의 이산화된 버전일 수 있다. 또한, 검색할 만족스러운 리소스 할당의 제한된 수의 변형이 있도록, 각각의 G는 N에서의 상한으로 제한될 수 있다. 5. 이용 가능한 리소스 서브세트 또는 동등하게 시간상 주어진 에포크에서 C에서의 이용 가능한 벡터 서브세트 를 기술하는 가용성 벡터. 6. QoS에 관련된 보안 벡터. 만족도 함수 벡터 G는 원하는 또는 지정된 QoS가 평가된 리소스 지출에 의해 충족될 수 있는 로컬 이력을 적용하는 것으로부터 반복적으로 트레이닝(또는 학습)될 수 있다. 리소스 지출은 주어진 함수에 대해 각각의 호스트 또는 컨테이너 내에서 런타임 시에 원격 측정을 통해 이용 가능할 수 있다. 추가적으로, 이는 또한 클 라우드 내의 다른 호스트들 또는 컨테이너들로부터 트레이닝되는 만족도 함수들을 혼합하여 업데이트될 수 있다. 이 혼합은, 로컬 이력이 다른 호스트로부터의 일시적 입력보다 더 큰 가중치를 부여받도록, 가중될 수 있지만; 이러한 가중치는 진화 학습을 달성하기 위해 의도적으로 변경될 수 있다. 시간이 지남에 따라, 이 솔 루션은, 예를 들어, 머신 또는 소프트웨어 거동의 과도적 이상 및 수요의 본질적인 변화로 인한 순간적인 변동 에 탄력적인 리소스 할당의 지속적인 발전을 가능하게 할 수 있다. 특히, 만족도 함수들을 혼합하는 것은 이들 을 클라우드 스케일 학습으로 일반화하면서 (최적의 만족도 벡터를 선택하기 위해) 빈 패킹 휴리스틱스를 적용 하는 것을 결과할 수 있다. 또한, 예시적인 실시예에 따르면, 특정 워크로드에 대한 호스트 함수를 평가하기 위해 전술한 벡터에 관련된 원 격 측정을 집계하도록 메타 언어 가속기가 구현될 수 있다. 원하는 QoS에 대한 QoS 사양(예를 들어, 매니페스 트)이 있을 수 있으며, 사양은 테넌트(예를 들어, 데이터베이스 시스템, 이미지 프로세싱 서비스 등과 같은, 함 수가 서비스되는 소프트웨어 구현)에 관한 데이터를 포함할 수 있다. 테넌트에 관한 그러한 데이터를 자동으로 축적하고 프로세싱하는 방법이 있을 수 있다. 일부 경우에, 서비스(예를 들면, 데이터베이스)가 - 예를 들어, 자신이 표준 방식으로 동작하고 있지 않을 때 - 자신의 메트릭이 무시되어야 한다고 표시할 수 있다. 예시적인 실시예에 따르면, 동일한 함수 요청이 서비스되고 있는 여러 단계를 거칠 때 시간을 축적하는 엔드 투 엔드 레이턴시가 일부 함수 요청을 통해 추적될 수 있다. 레이턴시 SLA가 수 밀리초(ms) 레이턴시를 요구하는 경우 함수가 로컬로 유지될 수 있다. 예시적인 실시예는 일부 임계 레이턴시 미만으로 유지하는 것을 보장할 수 있고 그러한 임계 레이턴시를 보장할 수 있는 링크의 구성을 제공할 수 있다. 이제 도 39c를 살펴보면, 실시예에 따른 적절한 리소스를 사전 예약하기 위한 방법이 예시된다. 방법의 블록에서, 함수의 리소스 요구들이 식별될 수 있다. 블록에서, 함수가 할당되는 컨테이너 내의 리 소스들이 식별된 리소스 요구들에 기초하여 사전 예약될 수 있다. 블록에서, 식별된 리소스 요구들에 기 초하여 RDT 파라미터들이 설정될 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트 를 포함할 수 있다. 추가 비고 및 예 예 3901은 함수의 리소스 요구들을 식별하는 단계, 식별된 리소스 요구들에 기초하여, 함수가 할당되는 컨테이 너 내의 리소스들을 사전 예약하는 단계, 및 식별된 리소스 요구들에 기초하여 RDT 파라미터들을 설정하는 단계 를 포함하는 방법을 포함한다. 예 3902는 예 3901에 따른 방법이며, 함수의 워크로드에 대한 비용 함수를 평가하기 위해 가속기를 호출하는 단 계를 추가로 포함한다. 예 3903은 예 3901에 따른 방법이며, 최소 레이턴시를 보장하도록 링크들을 구성하는 단계를 추가로 포함한다. 예 3904는 예 3901에 따른 방법이며, 적어도 하나의 벡터를 사용하여 QoS를 보안하는 단계를 추가로 포함한다. 예 3905는 함수의 리소스 요구들을 식별하는 단계, 식별된 리소스 요구들에 기초하여, 함수가 할당되는 컨테이 너 내의 리소스들을 사전 예약하는 단계, 식별된 리소스 요구들에 기초하여 RDT 파라미터들을 설정하는 단계, 특정 워크로드에 대한 비용 함수를 평가하기 위해 가속기를 호출하는 단계, 최소 레이턴시를 보장하도록 링크들 을 구성하는 단계, 및 적어도 하나의 벡터를 사용하여 QoS를 보안하는 단계를 포함하는 방법을 포함한다. 향상된 경량 프로파일 기반 최적화(PGO) 예 코드 최적화는 서버리스 실행에 중요할 수 있는데, 특히 최적화되지 않은 코드는 비대해진 레이턴시 및 풋프린 트를 초래하며, 이는 FaaS 패러다임에서 곧바로 비용으로 이어지기 때문이다. 서버리스 아키텍처에서의 대부분 의 코드는 node.js, 파이썬(python) 등과 같은 동적 언어로 되어 있을 수 있다. PGO는 더 큰 유형 특화 컴파일 러 영역을 생성하기 위한 중요한 단서를 제공하며 따라서 유형 검사 및 스택 레지스터로부터 메모리로 값을 스 필링(spilling)하는 것을 최소화할 수 있지만, 서버리스 컴퓨팅에서의 그의 사용은 이를 수집, 분석 및 적용하 는 것의 CPU 오버헤드 및 결과적인 레이턴시 세금(latency tax)에 의해 제한될 수 있다. 함수를 실행하는 비용이 밀리초 단위로 측정되는 실행 시간 및 사용된 메모리에 의존하기 때문에, 레이턴시 및 코드 풋프린트를 감소시키는 것이 FaaS 환경에서 매우 중요하게 된다. 향상된 PGO 방법에서는, 함수 소스 코드 가 먼저 컴파일되고, 실행 동안, 동적 프로파일이 생성될 수 있다. 프로파일은 다양한 최적화를 수행하고 향후 함수 실행을 위해 코드 성능을 개선시키는 데 사용될 수 있다. 함수의 향후 실행이 얼마나 잘 수행될 것인지 또는 특정 함수의 향후 실행이 실제로 수행될 것인지를 알려지지 않았기 때문에 프로파일은 함수의 향후 실행에 유용할 수 있다. 이 프로세스는 시간이 많이 걸릴 수 있으며, 이 예시적인 실시예는 FaaS 함수에 대한 하드웨 어 지원을 사용하여 전술한 프로파일 생성을 가속화할 수 있다. 예를 들어, 마지막 분기 레코드 또는 다른 하 드웨어는 위에서 언급된 동적 프로파일을 생성하도록 구현될 수 있다. 동적 프로파일의 생성은 또한, 부분적으 로, 소프트웨어 또는 소프트웨어-하드웨어 조합을 사용하여 생성될 수 있다. 향상된 PGO 방법의 또 다른 실시예에 따르면, 함수 성능을 저하시키는 저레벨 머신 관련 병목 현상이 식별될 수 있다. FaaS 실행 환경에서, 함수의 후속 실행이 상이한 시스템에서 있을 수 있기 때문에, 저레벨 머신 종속성 을 이해하는 것이 매우 유용할 수 있다. 마지막으로, 향상된 PGO 방법의 또 다른 예시적인 실시예에 따르면, (예를 들면, 이미지 프로세싱 함수에서의) 어레이 연산을 벡터화하는 것, 분기 재조종을 최소화하는 것, 및 더 빠른 캐시에 맞게 코드를 압축하는 것과 같 은 향상된 PGO 방법을 사용하는 새로운 최적화가 함수 레이턴시를 감소시키기 위해 추가될 수 있다. 향상된 PGO 방법의 다양한 실시예는 FaaS 런타임에서 동적 프로파일링 능력을 사용하여 이상을 탐지하는 것을 가능하게 한다. 일반적으로, 이상 탐지는 비정상 이벤트를 식별하는 프로세스이다. FaaS 실행 환경의 맥락에 서, 예시적인 이상 이벤트는 불법 명령어 오류, 메모리 영역에 대한 액세스 금지, 미숙하거나 예기치 않은 함수 종료를 포함한다. 이상 이벤트를 탐지할 때, 향상된 PGO 방법은 탐지를 추가 분석을 위해 향상된 FaaS 시스템 의 성능 분석 툴에 보고한다. 이상 이벤트는, 예를 들어, 함수가 특정 파일이 이용 가능할 것으로 예상하지만 해당 파일이 실제로는 이용 가능하지 않은 것일 수 있다. 이제 도 40a를 살펴보면, 예시적인 실시예에 따르면, 코드 최적화에 관련된 위에서 설명된 과제를 해결하 기 위해 3개의 대별 카테고리를 포함하는 도 4에 도시된 것과 같은 향상된 FaaS 시스템의 여러 향상이 있을 수 있다: 1. 제1 카테고리는 하드웨어 지원 코드와 JIT에 자동으로 노출되는 코드 둘 모두의 컬렉션에 관련된다. 2. 제2 카테고리는 코드 실행에 영향을 미치는 주요 문제를 식별하는 것을 더 쉽도록 할 수 있으며, 예를 들면, 머신마다 달라지는, 머신 성능 데이터 간의 저레벨 차이를 추상화한다. 즉, 특정 머신 상에서 일 부 함수가 실행 중이고 느리게 실행되는 경우, 머신 성능 데이터에 관련된 그러한 정보는 느린 것이 최적화될 필요가 있는 함수에서의 어떤 약점으로 인한 것이 아니라 머신이 바람직한 빈도로 실행되지 않는 것으로 인한 것임을 나타낼 수 있다. 3. 제3 카테고리는 기존 FaaS 솔루션의 다수의 최적화 또는 향상을 포함한다: - 가장 작은 동적 캐시 및 TLB 풋프린트로의 코드 압축 - 분기 재조종(branch re-steering) 최소화 - 어레이 연산 벡터화 TLB는 컴퓨터 시스템의 메모리에 대한 어드레스 변환 정보를 캐싱하기 위한 성능에 중요한 구조이다. 높은 비 율의 TLB 미스는 시스템 및 함수 성능에 대가가 크다. 향상된 FaaS 시스템의 실시예는, 예를 들어, CPU 코어들 간의 스트라이디드(strided) 액세스 패턴에 관한 정보를 통신하고 (TLB 미스가 데이터가 프리페치되는 것만을 느려지게 하도록 - 그러나 이는 실제 실행의 속도에는 영향을 주지 않음) 프리페처를 사용하여 향후 참조를 예 측함으로써, TLB 미스가 감소될 수 있거나 또는 TLB 미스 페널티가 감소될 수 있는 방식으로 코드를 컴파일할 수 있다. 유사하게, 향상된 FaaS 시스템의 실시예는 컴파일된 코드가 더 작은 동적 페이지 풋프린트에 수용될 수 있도록 코드 컴파일을 최적화한다(따라서 프로세서 캐시에서 코드가 소비하는 공간을 감소시킴). 유사하게, 자주 액세 스되는 정적 데이터가 공존하도록, 코드에 의해 터치되는 임의의 정적 데이터도 압축된다. 예를 들어, 향상된 FaaS 시스템의 실시예는 상이한 컴파일러 옵션 및 수집된 캐시 통계 하에서 함수의 실행 이력을 분석하여, 낮은 시간적 지역성을 갖는 코드의 해당 컴파일된 부분(예를 들면, 해당 코드 모듈)을 선택하고 - L1 명령어 캐시 히 트를 개선시키기 위해 - 이를 코드의 나머지 부분과 상이한, 함수의 어드레스 공간의 부분에 배치하며; 유사하 게 더 자주 액세스되거나 동시에 액세스되는 다양한 데이터 객체를 모음으로써, L1 데이터 캐시 히트가 개선될 수 있다. 그러한 압축은 또한 동시에 액세스되는 (명령어 및 데이터 페이지에 대한) 가상 어드레스의 평균 개 수를 감소시킴으로써, 향상된 FaaS 시스템에서 TLB 히트율이 개선된다. 분기 재조종은 명령어 페처가 이전에 잘못된 분기 목적지로 간 경우 명령어 페처를 올바른 목적지로 리디렉션하 는 프로세스를 지칭한다. 예를 들어, BTB(Brach Target Buffer)는, 이전에 본 분기를 룩업하기 위해 향상된 FaaS 시스템에 의해 사용될 수 있는, 캐시 유사 구조이다. BTB에 의해 제공되는 현재 프로그램 카운터의 어떤 개수의 비트는 잠재적 분기에 관한 정보를 포함한다. 잠재적 분기의 추측이 틀릴 때, 명령어 페처는 잘못된 분 기 목적지로 갈 것이고; 일단 그러한 잘못된 분기 목적지가 발견되면, 명령어 페처는 올바른 목적지로 재조종될 필요가 있다. 향상된 FaaS 시스템을 사용하여, 그러한 분기 재조종이 최소화될 수 있다. 컴파일러는 분기 재 조종을 감소시키기 위해 많은 상이한 기술을 사용할 수 있으며; 일 예에서, 자주 취해진 분기가 BTB가 취해지는 것으로 예측하기 더 쉽도록(일반적으로 후방 분기가 전방 분기보다 취해지는 것으로 예측하기 더 쉬움), 컴파일 러는 분기의 방향을 변경할 수 있으며; 다른 예에서, 컴파일러는, 평가된 프로파일 정보에 기초하여, 예측 힌트 를 분기 명령어에서의 프리픽스로서 사용할 수 있다. 향상된 FaaS 시스템의 실시예는 어레이 연산의 벡터화를 통해 함수 실행을 추가로 최적화할 수 있다. 예를 들 어, 향상된 FaaS 시스템의 실시예는 벡터화 컴파일러를 이용하여 루프 연산을 벡터 연산들의 시퀀스로 변환할 수 있다. 그러한 벡터화/변환은, 함수 실행의 성능이 개선되도록, 향상된 FaaS 시스템이 한 번에 다수의 피연산자 쌍에 대해 하나의 연산을 프로세싱할 수 있게 한다. RDT, SGX 및 3DXP와 같은 정보 아키텍처(IA) 고유성을 통해 저스트 인 타임 QoS, 보안 및 지속성을 가능하게 하 는 것과 같은 제1 카테고리에 의해 추출되고 제2 향상 카테고리에 의해 변환되는 실행 특성은 또한 직교 값 (orthogonal value)을 도출하는 데 사용될 수 있다. 이제 도 40b를 참조하면, 예시적인 실시예에 따라, 방법의 블록에서, 함수 소스 코드가 컴파일될 수 있다. 블록에서, 컴파일된 소스 코드의 실행 동안, 함수에 관련된 동적 프로파일이 생성될 수 있다. 블록에서, 생성된 동적 프로파일에 기초한 새로운 최적화가 함수 레이턴시를 감소시키도록 생성될 수 있 다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트 를 포함할 수 있다. 추가 비고 및 예 예 4001은 함수의 소스 코드를 컴파일하는 단계, 컴파일된 소스 코드의 실행 동안, 함수에 관련된 동적 프로파 일을 생성하는 단계, 및 함수 레이턴시를 감소시키도록 생성된 동적 프로파일에 기초한 새로운 최적화를 생성하 는 단계를 포함하는 방법을 포함한다. 예 4002는 예 4001에 따른 방법이며, FaaS 런타임에서 동적 프로파일링 능력을 사용하여 이상을 탐지하는 단계 를 추가로 포함한다. 예 4003은 예 4002에 따른 방법이며, 탐지의 결과를 성능 분석 툴에 보고하는 단계를 추가로 포함한다. 예 4004는 예 4001에 따른 방법이며, 오케스트레이터를 통해, 프로파일 매핑을 유지하는 단계를 추가로 포함한 다. 예 4005는 함수의 리소스 요구들을 식별하는 단계, 식별된 리소스 요구들에 기초하여, 함수가 할당되는 컨테이 너 내의 리소스들을 사전 예약하는 단계, 식별된 리소스 요구들에 기초하여 RDT 파라미터들을 설정하는 단계, 특정 워크로드에 대한 비용 함수를 평가하기 위해 가속기를 호출하는 단계, 최소 레이턴시를 보장하도록 링크들 을 구성하는 단계, 적어도 하나의 벡터를 사용하여 QoS를 보안하는 단계, FaaS 런타임에서 동적 프로파일링 능 력을 사용하여 이상을 탐지하는 단계, 탐지의 결과를 성능 분석 툴에 보고하는 단계, 오케스트레이터를 통해, 프로파일 매핑을 유지하는 단계를 포함하는 방법을 포함한다. 시간순 핑거프린트 예 함수는 그의 실행 동안 상이한 특성을 나타낼 수 있으며 CPU, 메모리, 네트워크 등과 같은 리소스를 상이한 비 율로 사용할 수 있다. 이러한 특성을 이해하고 이를 (함수의 수요 핑거프린트로서) 함수와 연관시키는 것은 효 율적인 리소스 할당 및 스케줄링에 중요하다. 예시적인 수요 핑거프린트가 도 41d에 도시되어 있다. 그렇지만, 상당한 사전 실험 없이는 수요 핑거프린트가 쉽게 획득될 수 없다 - 많은 함수가 며칠, 몇 주, 몇 달 에 걸쳐 여러 번 실행될 수 있다 -. 도 4에 도시된 것과 같은 향상된 FaaS 시스템의 예시적인 실시예에 따르면, 함수 실행의 다양한 스테이지에서 상이한 리소스의 사용에 대한 상세 보고서를 자동으로 생성하고 다수의 실행에 걸쳐 그에 기초하여 수요 핑거프 린트를 생성하는 프로세스가 제공된다. 일부 리소스(예를 들면, CPU)는 함수의 시작에서 과중하게 사용될 수 있고, 일부 다른 리소스(예를 들면, 메모리, 캐시)는 후반부 동안 과중하게 사용될 수 있다. 하나의 함수가 결 국 다른 함수도 호출할 수 있다. 그러한 상세 보고서는 함수 연대기(FUNCTION CHRONICLE)라고 불릴 수 있다. 따라서, 도 41a에 도시된 바와 같이, 시간이 지남에 따라, 함수의 각각의 실행에서, 함수의 다양한 성능, 전력 및 스케일링 특성 또는 감도가 획득될 수 있고, 풍부한 이력이 성숙한 수요 핑거프린트(DEMAND FINGERPRINT)로 축적된다. 도 41b에 예시된 바와 같이, 수요 핑거프린트 정보는 CSP의 오케스트레이터 또는 서버에서 구현될 수 있는 리소스 관리자를 통해 효율적인 리소스 관리를 위해 함수를 스케줄링하고 함수에 리소스를 할당 하는 데 사용될 수 있다. 수요 핑거프린트는 함수 호출 체인, 발신하는 호출자(특정 클라이언트) 및 함수 호출 의 특정 파라미터 값과 연관될 수 있다. 도 41b에 도시된 예시적인 실시예에 따르면, 수요 핑거프린트는 함수 생성 시에 생성될 수 있고 메모리 요구사 항 및 타임아웃과 같은 함수 파라미터에 관한 세부 사항만을 포함할 수 있다. 함수 실행 동안, 다양한 리소스 소비(예를 들면, CPU, 메모리)가 기록될 수 있다. 함수 실행의 종료 시에, 함수가 CPU/메모리/네트워크 집약적 이라는 것 또는 CPU/메모리 집약적인, 함수가 실행될 때의 특정 스테이지와 같은 상이한 리소스 사용 패턴이 추 론될 수 있다. 다수의 함수 실행의 경우, 수요 핑거프린트가 증가하고 함수의 리소스 사용 패턴에 관한 더 많 은 (정확한) 정보가 획득될 수 있다. 이 수요 핑거프린트는 함수의 추가 실행을 위한 리소스 스케줄링에 사용 될 수 있다. 함수 체이닝의 경우에, 리소스 관리자는 체이닝된 함수의 수요 핑거프린트에 기초하여 리소 스(CPU, 메모리)를 할당함으로써 체이닝된 함수를 실행하기 위한 리소스를 사전에 준비할 수 있다. 이제 도 41c를 살펴보면, 예시적인 실시예에 따라, 방법의 블록에서, 각각의 실행 스테이지에서 실 행된 함수들의 수요 핑거프린트들을 생성하기 위해 리소스 특성들이 실행된 함수들과 연관될 수 있다. 블록 에서, 오케스트레이터(미도시)는, 예를 들어, 함수들의 다수의 실행 스테이지에서 상이한 리소스들의 사 용량에 대한 상세 보고서들을 생성할 수 있다. 블록에서, 함수들의 실행이 스케줄링될 수 있고, 생성된 보고서들에 기초하여 리소스들이 함수들에 할당될 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨 어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트 를 포함할 수 있다. 추가 비고 및 예 예 4101은 각각의 실행 스테이지에서 실행된 함수의 수요 핑거프린트를 생성하기 위해 리소스 특성을 실행된 함 수와 연관시키는 단계, 오케스트레이터를 통해, 함수의 다수의 실행 스테이지에서 상이한 리소스의 사용량에 대 한 상세 보고서를 생성하는 단계, 함수의 실행을 스케줄링하는 단계, 및 생성된 보고서에 기초하여 리소스를 함 수에 할당하는 단계를 포함하는 방법을 포함한다. 예 4102는 예 4101에 따른 방법이며, 함수의 파라미터 및 함수를 호출하는 테넌트와 관련하여 수요 핑거프린트 를 생성하는 단계를 추가로 포함한다. 예 4103은 예 4101에 따른 방법이며, 수요 핑거프린트를 생성하기 위해 시퀀스 분석 머신 러닝 모델을 구현하는 단계를 추가로 포함한다.예 4104는 각각의 실행 스테이지에서 실행된 함수의 수요 핑거프린트를 생성하기 위해 리소스 특성을 실행된 함 수와 연관시키는 단계, 오케스트레이터를 통해, 함수의 다수의 실행 스테이지에서 상이한 리소스의 사용량에 대 한 상세 보고서를 생성하는 단계, 함수의 실행을 스케줄링하는 단계, 생성된 보고서에 기초하여 리소스를 함수 에 할당하는 단계, 함수의 파라미터 및 함수를 호출하는 테넌트와 관련하여 수요 핑거프린트를 생성하는 단계, 및 수요 핑거프린트를 생성하기 위해 시퀀스 분석 머신 러닝 모델을 구현하는 단계를 포함하는 방법을 포함한다. 딥 프로파일링을 자동화하기 위한 프레임워크 방법 및 수단 함수와 함수가 실행되는 관련 실행 엔진(예컨대, 컨테이너 및/또는 호스팅 수단)의 상호 불투명성은 그의 실행 을 프로파일링, 디버깅, 감사 및 최적화하는 데 상당한 과제를 도입한다. 도 4에 도시된 것과 같은 향상된 FaaS 시스템의 예시적인 실시예는 함수의 성능 추적을 단순화하고 이 정보를 실행 엔진으로부터 획득된 정보와 통합하기 위한 방법들을 제공하며, 이 방법들 중 일부는 하드웨어 지원일 수 있다. 이 통합에서는, 원하는 레 벨의 실행 엔진 투명성을 달성하기 위해 호스팅 엔진/컨테이너 또는 플랫폼의 세부 사항이 공개되지 않도록 적 합하게 보호될 수 있으며, 함수의 아키텍처 중립적 거동이 디버깅, 튜닝 및 감사 목적을 위해 프로파일링, 트레 이싱, 및 타임 라이닝(time line)될 수 있다. 이제 도 42a를 살펴보면, 향상된 FaaS 프레임워크는 함수 클라이언트가 불투명 마커(예를 들면, 인 덱스 또는 데이터 핸들)와 함께 시간 또는 이벤트 분절 트레이스를 획득할 수 있는 가상 프로파일링 API 를 포함한다. 시간 또는 이벤트 분절 트레이스는 트레이스 수집 중에 발생한 이벤트(예를 들면, 인터럽트 또는 다른 신호, 타임아웃, 페이지 폴트 등) 및, 함수의 실행으로 시작하여, 세분화된 시간 단위로 이벤트가 발생한 때로 주석 첨부될 수 있다. 함수 클라이언트와 실행 서비스 제공자 사이에 협상된 투명성 정도에 따라 실행 환경으로부터 다양한 정규화된 집계 척도를 획득하기 위해 불투명 마커가 실행 엔진 에 제공될 수 있다. 불투명 마커는 참조자가 참조된 객체의 콘텐츠 또는 구조에 대한 어떠한 액세 스를 갖지 않고도 정보 객체를 참조하는 것을 가능하게 할 수 있다. 불투명 마커는 인프라스트럭처 레벨에 있고 따라서 (열등한 특권 레벨에서 실행되는) 실행 함수에 이용 가능하지 않을 수 있는 다양한 통계를 적절한 특권이 있는 툴이 수신하기 위한 방법을 제공할 수 있다. 이러한 방식으로, 플랫폼 레벨 이벤트 또는 통계는 적절하게 필터링되거나 일부 참조 단위에 매핑되고 이어서 트레이스 에 블렌딩될 수 있다. 예를 들어, 불투명 마커는 나중에 \"CPU가 시간 0x12345에서 터보 주파수 G에 들어 감\" 또는 \"열 트립으로 인해 시간 0x56789에 메모리 에러가 탐지 및 정정됨\" 등으로 변환될 수 있다. 일반적으로 시스템 내의 모든 것에 관해 가장 세밀한 상세 레벨로 알 필요가 없을 수 있기 때문에, 시스템 및 함수의 거동을 함께 분석 및 특성화하기 위해 집계 척도가 획득될 수 있다. 예를 들어, 페이지 폴트가 평균 빈 도 X에서 발생했다는 것 또는 시스템이 열 이벤트를 경험했거나 또는 함수가 실행되는 시간 기간 동안 어떠한 열 이벤트도 경험하지 않았다는 것을 아는 것으로 충분할 수 있다. 전체 측정 트레인을 획득하는 것이 예시적 인 실시예에 따라 수행될 수 있지만, 일부 경우에는 그러한 것이 너무 드러나기도 하고 나중에 저장하고 분석하 기에는 너무 비용이 많이 들 수도 있다. 함수 실행 엔진으로부터 획득된 집계 척도는 획득된 집계 척도 의 개선된 분석 성능을 위해 추가로 정규화될 수 있다. 정규화된 집계 척도는 스왑 사용량과 같은 소프 트웨어 메트릭 및 L1 캐시 미스와 같은 하드웨어 메트릭을 포함할 수 있다. 가상 프로파일링은 런타임 시에 발생할 수 있으며 함수를 실행하는 컨테이너에 의해 수행될 수 있다. 생성된 트레이스는 함수의 실행 동안의 하드웨어 및 소프트웨어 메트릭의 집합체를 포함하며 함수 실행 또는 함수 체이 닝 동안 발생하는 상이한 이벤트에 기초하여 분류될 수도 있다. 불투명 마커는 컨테이너 계층, 가상 머 신 계층 또는 하드웨어 계층에 의해 생성될 수 있다. 임의적인 하드웨어 확장은 함수 내로부터 추상화되었지만 민첩한 자체 특성화를 위한 가상 전원 관리 유닛(PMU) 능력에 대한 직접적인 액세스를 제공한다. 이제 도 42b를 참조하면, 예시적인 실시예에 따라, 방법의 블록에서, 함수는 불투명 마커와 함께 시간 또는 이벤트-분절 트레이스(time or event-punctuated trace)를 획득할 수 있다. 블록에서, 불투 명 마커가 실행 환경으로부터 집계 척도를 획득하기 위해, 함수를 실행하는 컨테이너와 같은, 함수의 실행 엔진 에 제시될 수 있다. 블록에서, 함수는 가상 PMU에 대한 직접적인 액세스를 제공받을 수 있다. 방법의 실시예는, 예를 들어, 본 명세서에서 설명된 것과 같은, 시스템, 장치, 컴퓨터, 디바이스 등에서 구현될 수 있다. 더 상세하게는, 방법의 하드웨어 구현은, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가 능한 로직, 또는, 예를 들어, ASIC, CMOS, 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어, 또는 이들의 임의의 조합을 포함할 수 있다. 대안적으로 또는 추가적으로, 방법은 하나 이상의 모듈 에서 프로세서 또는 컴퓨팅 디바이스에 의해 실행될 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또 는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서 구현될 수 있다. 예를 들어, 컴포넌트의 동작 을 수행하기 위한 컴퓨터 프로그램 코드는, PYTHON, PERL, JAVA, SMALLTALK, C++, C# 등과 같은 객체 지향 프 로그래밍 언어 및 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어를 포함하여, 하나 이상의 OS에 적용 가능한/적절한 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 방법의 실시예 또는 부분은 펌웨어, 애플리케이션(예를 들어, 애플리케이션 프로그래밍 인터페이스(API) 를 통해), 또는 운영 체제(OS) 상에서 실행되는 드라이버 소프트웨어로 구현될 수 있다. 추가적으로, 로직 명 령어는 어셈블러 명령어, ISA(instruction set architecture) 명령어, 머신 명령어, 머신 종속 명령어, 마이크 로코드, 상태 설정 데이터, 집적 회로에 대한 구성 데이터, 전자 회로를 개인화하는 상태 정보 및/또는 하드웨 어(예를 들면, 호스트 프로세서, 중앙 프로세싱 유닛/CPU, 마이크로컨트롤러 등)에 고유한 다른 구조 컴포넌트 를 포함할 수 있다. 추가 비고 및 예 예 4201은, 함수를 통해, 함수 및 불투명 마커의 시간 또는 이벤트 분절 트레이스를 획득하는 단계, 불투명 마 커를 함수와 연관된 실행 엔진에 제시하여 실행 엔진으로부터 함수에 관한 정보를 획득하는 단계, 및 하나 이상 의 하드웨어 컴포넌트에 대한 직접적인 액세스를 함수에 제공하는 단계를 포함하는 방법을 포함하며, 여기서 불 투명 마커는 데이터 객체의 내용 또는 구조에 대한 어떠한 액세스도 없이 데이터 객체를 참조한다. 예 4202는 예 4201의 방법을 포함하며, 신뢰할 수 있는 엔티티에 공급되어야 하는 서명된 데이터를 엔클레이브 에 저장하는 단계를 추가로 포함한다. 예 4203은 예 4201의 방법을 포함하며, 불투명 마커와 관련하여 캡처된 시스템 원격 측정을 암호화하는 단계를 추가로 포함하고, 여기서 암호화는 앱 특정 설정을 사용하여 수행된다. 예 4204는 예 4201의 방법을 포함하며, 애플리케이션이 실행 환경과 무관하게 프로파일링 포인트를 결정하기 위 한 API를 생성하는 단계를 추가로 포함한다. 예 4205는 예 4201의 방법을 포함하며, 함수로부터 특권을 분리시키고 데이터를 프로파일링하는 단계를 추가로 포함한다. 예 4206은 예 4201의 방법을 포함하며, 탭/토큰을 삽입하기 위해 안전 포인트를 관리하는 단계를 추가로 포함한 다. 예 4207은, 함수를 통해, 함수 및 불투명 마커의 시간 또는 이벤트 분절 트레이스를 획득하는 단계, 불투명 마 커를 실행 엔진에 제시하여 실행 엔진으로부터 정보를 획득하는 단계, 가상 전력 관리 유닛에 대한 직접적인 액 세스를 함수에 제공하는 단계, 신뢰할 수 있는 엔티티에 공급되어야 하는 서명된 데이터를 엔클레이브에 저장하 는 단계, 캡처된 페이지를 앱 특정 설정을 사용하여 암호화하는 단계, 애플리케이션이 실행 환경과 무관하게 프 로파일링 포인트를 결정하기 위한 API를 생성하는 단계, 함수로부터 특권을 분리시키고 데이터를 프로파일링하 는 단계, 및 탭/토큰을 삽입하기 위해 안전 포인트를 관리하는 단계를 포함하는 방법을 포함한다. 함수 실행을 위한 서버 선택 이제 도 43a를 살펴보면, 세션 상태 관리가 향상된 FaaS 시스템의 사용자 인터페이스 핸들러(예를 들어, API 게이트웨이와 같은 API 프록시)에 의해 핸들링되는 예가 도시되어 있다. 예시된 예에서, 사용자 인터페이 스 핸들러는 함수 컨텍스트 식별자(ID)를 포함하는 토큰(예를 들어, 데이터 \"모니커\")을 생 성한다. 함수 컨텍스트 ID는 함수를 실행하기 위해 들어오는 요청과 연관된 함수의 컨텍스트 를 고유하게 식별해준다. 더 상세하게는, 함수는 데이터 세트 구조의 아이덴티티의 대략적인 표현으로서 컨텍스트를 기술하는 임의적 필드에 기인할 수 있다. 일 예에서, 토큰은, 예를 들어, 다양한 UUID(universally unique ID)에 걸쳐 적용되는 세트 함수(예를 들어, 블룸 필터), 요청의 소스(예를 들 면, 애플리케이션 정의 함수 매핑 솔루션의 함수의 호출자), 함수의 특정 파라미터, 파일 시스템 경로 이름, (예를 들면, APACHE SPARK에서의) RDD(resilient distributed dataset) 계보, 관계형 데이터베이스의 테이블스 페이스 범위 등을 사용하는 사용자 인터페이스 핸들러의 모니커 구성 API에 의해 구성된다. 예시된 예에서, 오케스트레이터는 토큰(및 더 상세히 논의될 잠재적으로 다른 인자)에 기초하여 서 버 위치를 선택하고 함수 호출과 함께 토큰을 선택된 서버 위치로 전송한다. 예시된 예에서, 함수호출 및 토큰은 컨텍스트를 포함하는 로컬 캐시를 포함하는 제1 서버로 전송되 며, 여기서 컨텍스트는 함수에 의한 상태 데이터(예를 들어, 퍼미션, 인증 상태, 트랜잭션 관련 데이터 등)의 검색을 용이하게 한다. 따라서 예시된 솔루션은 계산이 함수 실행 중에 사용되는 데이터를 향해 푸시될 수 있게 한다. 이와 관련하여, 컨텍스트가 로컬로 캐싱되기 때문에(예를 들어, 함수 특정 친화성이 시행 될 때 온 디맨드로 동일한 상태를 갖는 함수 프로세싱 요청이 생성되는 경우) 상태 데이터의 더 효율적인 검색 이 달성된다. 서버 위치가 추가 인자에 기초하여 선택될 수 있다. 예를 들어, 제1 서버, 제2 서버, 제3 서버 등의 상대적 위치 비용(예를 들어, 위치에 대한 데이터 전송/대역폭, 위치에 데이터를 저장하는 것 및/ 또는 위치에서 데이터를 프로세싱하는 비용)이 다른 곳에서의 함수 호출 및 토큰의 전송에 영향을 미칠 수 있다. 또 다른 예에서, 오케스트레이터는 서비스 품질(QoS) 요구사항(예를 들어, 신뢰성, 프로 세싱 속도 등)에 기초하여 서버 위치를 선택한다. 그러한 경우에, 제2 서버가 QoS 요구사항을 충족시킬 수 있고 제1 서버가 QoS 요구사항을 충족시킬 수 없다면, 함수 호출 및 토큰이 제2 서버 로 전송될 수 있다. 또 다른 예에서, 오케스트레이터는 함수의 이전 실행의 해시 결과에 기초하여 서버 위치를 선택한다. 더 상세하게는, DataID2 = hash(fn(DataID1)인 경우 fx(DataID2)가 호출될 때, 오케스트레이터는 DataID2 또는 함수 fx()를 이동할 것인지를 결정할 수 있다. 서버 위치는 또한 데이터가 스트리밍되는(예를 들면, 2차 또는 3차 프로세싱을 통해 소비되는) 노드일 수 있다. 추가 예에서, 서버 위치는 함수, 요청 소스 및/또는 함수 호출 트리(즉, 스케줄링되는 함수를 포함하는 호출 시 퀀스)와 연관된 이력(예를 들면, 시간/시간 이력)에 기초하여 선택된다. 예시된 솔루션은, 함수 호출이 요청에 응답하여 온 디맨드로 생성되는 한, 이벤트 지향으로 FaaS 시스템을 향상시킨다. 추가적으로, 예시된 솔루션은, 서버 위치의 선택이 사용자로부터 추상화되기 때문에, 최 소한의 관리로 FaaS 시스템을 향상시킨다. 더욱이, 함수 호출이 요청의 횟수에 따라 자동으로 확 장되기 때문에 FaaS 시스템이 고 확장성으로 향상된다. 추가적으로, 예시된 솔루션은, 함수가 컴퓨트 스케일 단위인 한, 원자 스케일 단위로 FaaS 시스템을 향상시킨다. 예시된 솔루션은 또한 고객이 함수 호출이 실행될 때만 비용을 지불할 수 있게 하며, 따라서 FaaS 시스템에 세분화된 빌링을 제공한다. 추가적으로, 예시 된 솔루션은 컨텍스트를 데이터베이스에 유지할 필요성을 감소시키며, 이는 그렇지 않았으면 컨텍스트 의 검색을 덜 효율적으로 만들 것이다. 이제 도 43b를 살펴보면, 함수 호출을 관리하는 방법이 도시되어 있다. 방법은 일반적으로, 예를 들어, 이미 논의된, 시스템(도 2), 시스템(도 3) 및/또는 시스템(도 4)과 같은 향상된 FaaS 시 스템에서 구현될 수 있다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래 시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 함수를 실행하기 위해 들어오는 요청과 연관된 함수의 컨텍스트를 고유하게 식별 해주는 토큰을 생성하는 것을 제공한다. 들어오는 요청은, 예를 들어, IoT 이벤트 및/또는 사용자에 의해 개발 된 함수를 실행하기 위한 사용자 요청과 같은 FaaS 이벤트와 같은, 트리거일 수 있다. 일 예에서, 블록 은 이미 논의된, 예를 들어, 사용자 인터페이스 핸들러(도 43a)와 같은, 사용자 인터페이스 핸들러에 의 해 수행된다. 블록에서, 토큰에 기초하여 서버 위치가 선택되고, 여기서 예시된 블록은 선택된 서 버 위치에서 함수를 호출한다. 예시된 예에서, 컨텍스트는 함수에 의한 상태 데이터의 검색을 용이하게 한다 (예를 들어, 함수는 컨텍스트로부터 상태 데이터를 검색한다). 블록 및 블록은 이미 논의된, 예를 들어, 오케스트레이터(도 43a)과 같은, 오케스트레이터에 의해 수행될 수 있다. 따라서 예시된 방법 은 이벤트 지향, 최소 관리, 고 확장성, 원자 스케일 단위 및 세분화된 빌링 면에서 FaaS 시스템을 향상 시킨다. 추가적으로, 예시된 방법은 별도의 데이터베이스에서 컨텍스트를 유지하고 매번 그에 액세스할 필요를 감소시키며, 이는 원격 액세스의 추가 레이턴시로 인해 훨씬 덜 효율적일 것이다. 도 43c는 함수 호출을 관리하는 더 상세한 방법을 도시한다. 방법은 일반적으로, 예를 들어, 이미 논의된, 시스템(도 2), 시스템(도 3) 및/또는 시스템(도 4)과 같은 향상된 FaaS 시스템에서 구현될 수 있다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등 과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로 직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 함수를 실행하기 위해 들어오는 요청과 연관된 함수의 컨텍스트를 고유하게 식별 해주는 토큰을 생성하는 것을 제공한다. 들어오는 요청은, 예를 들어, IoT 이벤트 및/또는 FaaS 이벤트와 같은 트리거일 수 있다. 일 예에서, 블록은 이미 논의된, 예를 들어, 사용자 인터페이스 핸들러(도 43a)와 같은, 사용자 인터페이스 핸들러에 의해 수행된다. 블록에서 함수와 연관된 시간 이력, 요청 소 스, 함수 호출 트리, 위치 비용, QoS 요구사항, 또는 함수의 이전 실행의 해시 결과 중 하나 이상 및 토큰에 기 초하여 서버 위치가 선택된다. 예시된 예에서, 서버 위치는 컨텍스트를 포함하는 로컬 캐시 또는 함수를 실행 하기 위한 성능, QoS 요구사항, 또는 데이터 친화성을 최대화하는 위치를 포함하도록 선택된다. 서버 위치는 또한 데이터가 스트리밍되는(예를 들면, 2차 또는 3차 프로세싱을 통해 소비되는) 노드일 수 있다. 블록은 선택된 서버 위치에서 함수를 호출하며, 여기서 컨텍스트는 함수에 의한 상태 데이터의 검색을 용 이하게 한다. 블록에서 선택된 서버 위치는 함수와 연관된 시간 이력에 저장된다. 따라서, 시간 이력은 함수에 대한 향후 서버 위치 결정을 하는 데 사용될 수 있다. 일 예에서, 블록들(4334, 4336 및 4338)은 이미 논의된, 예를 들어, 오케스트레이터(도 43a)과 같은, 오케스트레이터에 의해 수행된다. 따라서 예시된 방법은 이벤트 지향, 최소 관리, 고 확장성, 원자 스케일 단위 및 세분화된 빌링 면에서 FaaS 시스템을 향상시킨다. 도 43d는 요청 소스에 기초하여 함수 호출의 위치가 선택되는 FaaS 시스템을 도시한다. 더 상세하게는, 제1 클라이언트(\"클라이언트 1\")는 특정 함수를 실행하라는 제1 요청(\"요청 A\")을 FaaS 시스템 에 발행한다. 제1 클라이언트는 또한 동일한 함수를 실행하라는 제2 요청(\"요청 B\")을 FaaS 시스템에 발행할 수 있다. 추가적으로, 제2 클라이언트(\"클라이언트 2\")는, 예시된 예에서, 함수 를 실행하라는 제3 요청(\"요청 C\")을 FaaS 시스템에 발행한다. 그러한 경우에, FaaS 시스템 은 컨텍스트 및/또는 상태 데이터를 이동시킬 가능성을 감소시키기 위해 요청 A 호출 및 요청 B 호 출을, 예를 들어, 제i 서버(\"서버 i\")와 같은 공통 서버에 송신할 수 있다. 이와 달리, 예시된 FaaS 시스템은, 제3 요청이 제2 클라이언트(예를 들어, 상이한 요청 소스)로부터의 것이기 때문에, 요청 C 호출을 제j 서버(\"서버 j\")에 송신한다. 도 43e는 함수 호출 트리에 기초하여 함수 호출의 위치가 선택되는 FaaS 시스템을 도시한다. 더 상세하 게는, 제1 함수 호출 트리(\"함수 호출 트리 1\") 및 제2 함수 호출 트리(\"함수 호출 트리 2\")가 FaaS 시스템에 발행된다. 그러한 경우에, FaaS 시스템은, 제1 함수 호출 트리와 연관된 컨 텍스트 및/또는 상태 데이터를 이동시킬 가능성을 감소시키기 위해, 제1 함수 호출 트리에 대응하는 제1 호출 세트를 제i 서버에 송신할 수 있다. 유사하게, 예시된 FaaS 시스템은, 제2 함수 호출 트리와 연관된 컨텍스트 및/또는 상태 데이터를 이동시킬 가능성을 감소시키기 위해, 제2 호출 세트 를 제j 서버에 송신한다. 추가 비고 및 예 예 4301은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 함수를 실행하기 위해 들어오는 요청 과 연관된 함수의 컨텍스트를 고유하게 식별해주는 토큰을 생성하게 하고; 함수와 연관된 시간 이력, 요청 소스, 함수 호출 트리, 위치 비용, QoS(Quality of Service) 요구사항, 또는 함수의 이전 실행의 해시 결과 중 하나 이상 및 토큰에 기초하여 서버 위치를 선택하게 하며 - 서버 위치는 컨텍스트를 포함하는 로컬 캐시를 포 함하도록 선택됨 -; 선택된 서버 위치에서 함수를 호출하게 하고 - 컨텍스트는 함수에 의한 상태 데이터의 검색 을 용이하게 함 -; 선택한 서버 위치를 시간 이력에 저장하게 하는 실행 가능 프로그램 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 4302는 예 4301의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 서버 위치는 데이터가 스 트리밍되는 노드이도록 선택된다. 교차 도메인 호출 전송 예 교차 도메인 제어 전송 - 대부분 원격 프로시저 호출(RPC)로부터 종종 발생함 - 은 분산된 애플리케이션 및 서 비스에서 빈번하고 그의 높은 비용은 관련 컨텍스트 전환, (예를 들면, 수퍼바이저/하이퍼바이저의 제어 하에서의) 교차 스택 복사 및 보안 제어 전송으로 인한 것일 수 있다. RPC는 클라이언트-서버 또는 피어-투-피어 상 호작용을 구축하기 위한 핵심 메커니즘이었다. 그렇지만, 효율적인 RPC 구현이 FaaS 환경에서는 어려울 수 있 다. 실제로, 다른 문제(예를 들면, 보다 경량의 국한을 통한 효율적인 격리, 서비스 수준 협약/SLA 지원 등)가 해결됨에 따라 효율적인 교차 도메인 제어 전송의 중요성이 커질 수 있다. RPC 상호작용 동안, 호출자는 (a) 그의 사용자 공간으로부터 커널 공간으로 이동할 수 있고, 여기서 (b) 다양한 능력의 유효성의 검증 이후, (c) 호출 파라미터/데이터가 마샬링되며 (d) 적절한 전송 메커니즘을 통해 피호출 자에게 메시징된다. 측정은 최적화된 gRPC(GOOGLE RPC) 구현에서의 제어 평면 오버헤드가 사이클의 90% 이상을 차지한다는 것을 보여준다. 일 예에서, 예를 들어, NFF-Go 프로젝트(예를 들면, github.com/intel-go/nff- go)와 같은 클라우드 네이티브 데이터 평면(예를 들어, 사용자 트래픽을 전달하는 네트워크의 일부) 연구는 효 율적인 RPC가 네트워크 함수 가상화에 중요할 수 있음을 입증했다(예를 들면, 초당 수억 개의 요청, 패킷당 ~ 1 개의 요청이 가능함). 동시에, 데이터 평면 프로세싱에 FaaS 패러다임을 적용하려는 시도는 OS, 플랫폼 및 하 드웨어 가속에 액세스하기 위한 통합 메커니즘은 물론, 특정 프레임워크에 대한 종속성을 피하기 위한(예를 들 면, AMAZON LAMBDATM, OPENWHISKTM, GCP/GOOGLE CLOUD PLATFORMTM, 및 NFF-GoTM와 같은, 상이한 클라우드 환경에 서 동일한 방식으로 함수 호출을 수행하기 위한) 함수 대 함수 체이닝에 대한 필요성을 노출했을 수 있다. 상기 프로세스(a) 내지 (d)에 수반된 동작은 상이한 도메인에 걸쳐 수행되는 보일러 플레이트 코드 시퀀스 (boiler-plate code sequence)를 포함할 수 있으며, 이는 동작을 계산 비용이 많이 들게 만드는 감독 개입을 수 반한다. 실제로, 유사한 오버헤드가 피호출자 측 및 결과 리턴 경로에 적용된다. 다른 하드웨어 특징이 (예를 들면, 연속적인 하드웨어 기술 세대에서) 더 빨라짐에 따라, 이러한 오버헤드는 비례적으로 \"파이\"의 더 큰 부 분이 된다. 최근에 개발된 명령어가 상기 \"매크로\" 또는 쿠키 커터(cookie-cutter) 동작의 하드웨어 구현을 용이하게 할 수 있지만, 개선의 여지가 남아 있다. 예를 들어, 제어 전송을 효율적으로 만드는 데 초점을 맞춘 기본 메커니즘 이 없으면 더 빈번한 컨텍스트 전환, 교차 스택 복사, 전송 보안 및/또는 감독 개입과 연관된 더 많은 비용을 결과할 수 있다. 더 상세히 논의될 것인 바와 같이, 가상 하드웨어 스레드 및 URI(uniform resource identifier) 호출 명령어는 교차 도메인 제어 전송의 효율성을 증가시키기 위해 사용될 수 있다. 이제 도 44a를 살펴보면, 제1 도메인 내의 호출자(예를 들어, 호출자)가 제2 도메인에서의 호출을 \"가상적으로 기다리는\" 함수를 호출하는 교차 도메인 환경이 도시된다. 일반적으로, 제2 도메인 내의 코어는 모니터 로직(예를 들어, 로직 명령어, 구성 가능 로직, 고정 기능 하드웨어 로직 등, 또는 이들의 임의의 조합) 및, 예를 들어, 가상 하드웨어 스레드와 같은 복수의 가상 하드웨어 스레드 (VHTR)를 포함할 수 있다. 가상 하드웨어 스레드는 일반적으로 다수의 스레드 또는 가상 네트워크 함수 (VNF) 간에 코어 리소스 및 사이클을 세분화하기 위해 스케줄링 하드웨어에 의해 사용되는 스레드 스케줄링 구 조일 수 있다. 소프트웨어 및 운영 체제 관점에서, VHTR은 일반 CPU 코어와 유사하다. 일부 실시예에서, VHTR 은 스레드에 고정되고 스케줄링 및 실행을 지원하기 위해 다수의 함수와 연관된다. 일부 실시예에서, 하드웨어 스케줄러는 VHTR들 사이의 CPU 슬라이싱을 적응시킨다. 예를 들어, 100개 이상의 VHTR이 2개의 프로세싱 코어 의 CPU 사이클을 공유하도록 스케줄링될 수 있다. 따라서, 충분한 스토리지가 있는 한, 수천 개의 VHTR이 스레 드에 할당되고 고정될 수 있다. 예시된 예에서, 가상 하드웨어 스레드는 실행 및 폴링이 보류되는 일시중지 상태(\"P\"상태)에 배치된다. 가상 하드웨어 스레드가 P 상태에서 대기하는 동안, 이는 프로세서 사이클을 수신하지도 않고 폴링하지도 않는다. 호출자가 (예를 들어, CALLURI2 명령어를 통해) 호출된 함수의 하나 이상의 호출 파라미터를, 예를 들어, 큐 또는 피호출 당사자에 의해 모니터링되는 다른 위치와 같은 모니터링된 위치에 인큐잉할 때, 예시된 호출자는 (예를 들어, WAIT 커맨드를 통해) 로컬 가상 하드웨어 스레드를 P 상태에 진 입하게 한다. 추가적으로, 모니터 로직은 큐에서 호출 파라미터(들)의 존재를 탐지할 수 있다. 큐에서의 호출 파라미터(들)의 존재는, 예를 들어, 사용자 레벨 인터럽트(예를 들면, UMONITOR/UMWAIT), 메모리 트리거(예를 들면, MONITOR/MWAIT), 마킹된 캐시 라인에 대한 로드 또는 저장의 TSX(transactional synchronization extension) 메커니즘 생성 표시, HLT(halt) 명령어 및 경량 ISR(interrupt service routine) 과 결합된 IPI(inter-processor interrupt), 역방향 호환 폴링 루프 등과 같은 기존 마이크로아키텍처 능력을 통해 탐지될 수 있다. 일 예에서, 모니터 로직은, 대기 상태에 있는 코어를 선택하고 함수의 어드레스, 호출 파라미터(들)에 대 한 포인터, 및 결과의 향후 리턴에 사용될 수 있는 요청을 식별해주는 토큰을 전달함으로써 선택된 코어의 실행을 트리거하는, 하드웨어 스케줄러의 일부이다. 대기 중인 코어가 없는 경우, HW 스케줄러는 각각의 코어에 대 한 태스크의 큐(예를 들면, 하드웨어 큐 관리자/HQM)를 지원하거나 또는 파라미터 전송 및 큐(예를 들면, 코어 가 P 상태에서 대기 중인지를 보고하는 것)를 지원하는 UMONITOR/UMWAIT의 확장된 시맨틱을 사용할 수 있다. 따라서, 호출 파라미터(들)가 큐에 있는 것에 응답하여, 모니터 로직은 가상 하드웨어 스레드 를 실행 상태(\"E\" 상태)에 배치한다. 예시된 예에서, 가상 하드웨어 스레드는, 예를 들어, 큐 또는 호출 당사자에 의해 모니터링되는 다른 위치와 같은 모니터링된 위치에서 호출된 함수의 하나 이상 의 결과를 인큐잉한다. 모니터 로직(예를 들어, 로직 명령어, 구성 가능 로직, 고정 기능 하드웨어 로직 등, 또는 이들의 임의의 조합)은 큐에서 결과(들)의 존재를 탐지할 수 있다. 큐에서의 결과(들)의 존재는, 예를 들어, 사용자 레벨 인터럽트, 메모리 트리거, 마킹된 캐시 라인에 대한 로드 또는 저장의 TSX 메 커니즘 생성 표시, HLT 명령어 및 경량 ISR과 결합된 IPI, 역방향 호환 폴링 루프 등과 같은 기존 마이크로아키 텍처 능력을 통해 탐지될 수 있다. 결과(들)가 큐에 있는 것에 응답하여, 예시된 모니터 로직은, 가상 하드웨어 스레드가 결과(들)를 소비하고 추가 동작을 수행할 수 있도록, 가상 하드웨어 스레드 를 실행 상태에 배치한다. 이제 도 44b를 살펴보면, 원격 프로시저 피호출자를 동작시키는 방법이 도시되어 있다. 방법은 일 반적으로, 예를 들어, 이미 논의된, 시스템(도 2), 시스템(도 3) 및/또는 시스템(도 4)과 같은 향상된 FaaS 시스템에서 구현될 수 있다. 일 실시예에서, 방법은 이미 논의된, 예를 들어, 제2 도메인 (도 44a)과 같은, 피호출 당사자 도메인에서 구현된다. 더 상세하게는, 방법은 하나 이상의 모듈 에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 가상 하드웨어 스레드를 실행 및 폴링이 일시중지되는 일시중지 상태에 두는 것 을 제공한다. 예시된 예에서, 가상 하드웨어 스레드는 호출된 함수와 연관되고 호출된 함수는 원격 프로시저이 다. 블록에서, 호출된 함수의 하나 이상의 호출 파라미터가 모니터링된 위치에 있는지에 대한 결정이 이 루어질 수 있다. 그렇지 않다면, 예시된 방법은 블록을 반복한다. 일단 호출 파라미터(들)가 탐 지된 것으로 결정되면, 블록은, 호출 파라미터(들)가 모니터링된 위치에 있는 것에 응답하여, 가상 하드 웨어 스레드를 실행 상태에 두는 것을 제공한다. 도 44c는 원격 프로시저 호출자를 동작시키는 방법을 도시한다. 방법은 일반적으로, 예를 들어, 이미 논의된, 시스템(도 2), 시스템(도 3) 및/또는 시스템(도 4)과 같은 향상된 FaaS 시스템에 서 구현될 수 있다. 일 실시예에서, 방법은 이미 논의된, 예를 들어, 제1 도메인(도 44a)과 같은, 호출 당사자 도메인에서 구현된다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨 어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들 어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 가상 하드웨어 스레드를 실행 및 폴링이 일시중지되는 일시중지 상태에 두는 것 을 제공한다. 예시된 예에서, 가상 하드웨어 스레드는 호출된 함수의 호출자와 연관되고 호출된 함수는 원격 프로시저이다. 블록에서, 호출된 함수의 하나 이상의 결과가 모니터링된 위치에 있는지에 대한 결정이 이루어질 수 있다. 그렇지 않다면, 예시된 방법은 블록을 반복한다. 일단 결과(들)가 탐지된 것으로 결정되면, 블록은, 결과(들)가 모니터링된 위치에 있는 것에 응답하여, 가상 하드웨어 스레드를 실 행 상태에 두는 것을 제공한다. 추가 비고 및 예 예 4401은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 가상 하드웨어 스레드를 실행 및 폴 링이 일시중지되는 일시중지 상태에 두게 하고 - 가상 하드웨어 스레드는 호출된 함수와 연관되고 호출된 함수 는 원격 프로시저임 -, 호출된 함수의 하나 이상의 호출 파라미터를 모니터링된 위치에서 탐지하게 하며, 하나 이상의 호출 파라미터가 모니터링된 위치에 있는 것에 응답하여, 가상 하드웨어 스레드를 실행 상태에 두게 하 는 실행 가능 프로그램 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 4402는, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 가상 하드웨어 스레드를 실행 및 폴 링이 일시중지되는 일시중지 상태에 두게 하고 - 가상 하드웨어 스레드는 호출된 함수의 호출자와 연관되고 호출된 함수는 원격 프로시저임 -, 호출된 함수의 하나 이상의 결과를 모니터링된 위치에서 탐지하게 하며, 하나 이상의 결과가 제2 위치에 있는 것에 응답하여, 제2 가상 하드웨어 스레드를 실행 상태에 두게 하는 실행 가능 프로그램 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 이기종 데이터 흐름 통합 예 도 45a는 패킷이 네트워크 경계를 통과하고 네트워크 스택이 일반적으로 여러 계층(예를 들면, L7 - 애플 리케이션 계층, L4 - 전송 계층, L3 - 네트워크 계층, L2 - 데이터 링크 계층 등)을 포함하는 FaaS 아키텍처 를 도시한다. 예를 들어, 하나 이상의 데이터 링크(예를 들어, 개방형 시스템 상호연결/OSI 모델의 계층 L2) 함수는 WAN(wide area network)의 인접 네트워크 노드들 사이의 또는 동일한 LAN(local area network) 세그먼트 상의 노드들 사이의 데이터 전송을 용이하게 한다. 추가적으로, 하나 이상의 네트워크(예를 들어, OSI 모델의 계층 L3) 함수는 패킷 포워딩을 핸들링할 수 있고 하나 이상의 전송(예를 들어, OSI 모 델의 계층 L4) 함수는 애플리케이션을 위한 호스트 대 호스트 통신 서비스를 제공한다. 일 예에서, API 게이트웨이는, 예를 들어, 제1 애플리케이션 계층(예를 들면, OSI 모델의 L7) 함수 (4504a), 제1 데이터 평면 함수(4504b)(예를 들어, 웹 함수), 제2 데이터 평면 함수(4504c)(예를 들어, 프록시 함수), 제2 애플리케이션 계층 함수(4504d) 등과 같은 다양한 함수(4504a 내지 4504d)로부터의 원격 프로 시저 호출(RPC)을 가로채기한다. HTTP(Hypertext Transfer Protocol)를 지원하는 예시된 API 게이트웨이 는 또한 하나 이상의 인프라스트럭처 함수로부터의 RPC를 가로채기한다. 가속 RPC(A-RPC) 호출자 는 가로채기된 RPC와 연관된 네트워크 함수의 인스턴스화를 수행할 수 있다. 예를 들어, API 게이트웨이 는 제1 애플리케이션 계층 함수(4504a)로부터의 RPC를 가로채기할 수 있으며, 여기서 가로채기된 RPC가 제2 애플리케이션 계층 함수(4504d)과 연관되면, 호출자는 제2 애플리케이션 계층 함수(4504d)를 인스턴스화한 다. 특히, RPC는 RPC의 패킷화 이전에 가로채기되고, 인스턴스화는 네트워크 스택의 전송 계층 및/또는 네트워크 계 층을 우회한다. 따라서, 예시된 솔루션은 전체 네트워크 스택을 통과할 필요가 없는 새로운 ABI(application binary interface)를 제공한다. 인스턴스화는 또한 하나 이상의 암호화 동작, 하나 이상의 호출자-타깃 핸드셰 이크 메시지 등을 우회할 수 있다. 따라서, 예시된 API 게이트웨이, 함수 및 호출자는 더 효율적인 인스턴스화 및 라우팅을 가능하게 하는 FaaS 함수 대 함수 가속 로직을 구성한다. 예시된 함수 및 다양한 이벤트 소스(예를 들어, 상태 및 구성 데이터베이스)는 하나 이상의 제어 평면 함수에 의해 지원된다. 추가로, 이벤트 소스는 네트워크 경계, 데이터 링크 함수 (들), 인터넷 프로토콜(IP) 로직(예를 들어, IPv4, IPv6), 전송 제어 프로토콜(TCP) 로직, TCP 메시지를 API 게이트웨이와 교환하는 보안 소켓 계층(SSL) 로직, UDP(User Datagram Protocol) 로직, 및 DNS(Domain Name Server) 로직 - 예시된 예에서 이들 모두는 가속됨 - 에 컨 텍스트 데이터를 제공할 수 있다. 예시된 아키텍처는 ARP(Address Resolution Protocol) 로직을 또한 포함한다. 일 예에서, 네트워크 경계, 데이터 링크 함수(들), IP 로직, TCP 로직 , SSL 로직, 및 API 게이트웨이는 FaaS API-게이트웨이 가속 로직이다. 제1 애플리케이션 계층 함수(4504a) 및 제2 애플리케이션 계층 함수(4504d)는 REST(Representational State Transfer), gRPC, A-RPC 등을 통해 호출 가능하다. 예를 들어, API 게이트웨이에 도달하기 전에 프로세 싱될 BGP(Border Gateway Protocol)와 같은 레거시 스타일 프로토콜을 포함하는 패킷에 대해 추가 경로가 제공될 수 있다. 레거시 스타일 프로토콜은 다른 함수의 일부 구성에 영향을 미칠 수 있다. 예를 들어, BGP는 일부 IP 함수에서 차례로 사용되는 라우팅 테이블을 업데이트하는 데 사용될 수 있다. 따라서, 예시된 추가 경 로는, 적절한 경우, API 게이트웨이의 기능이 단지 몇 개의 프로토콜로 제한될 수 있게 한다. 실 제로, 추가 경로는 REST 및 gRPC 호출을 핸들링할 수 있으며, API 게이트웨이는 A-RPC 호출(네트워 크 스택의 하위 레벨 없이, 그의 재순환, 예를 들어, F1 => F2 => F3 등을 포함함)만을 책임지고 있다. 따라서 예시된 아키텍처는 완전한 L2 내지 L7 네트워크 스택 및 L7 애플리케이션 함수의 구현을 통합하고, API 게이트웨이를 자체 상의 인프라스트럭처(또는 런타임) 함수로서 노출함으로써 다양한 단축키를 가능하게 한다. 예시된 아키텍처는 또한 커널 네트워크 스택을 통과하기 위해 그렇지 않았으면 호출을 필요로 할 수 있는, NGINX와 같은, 상이하게 설계된 애플리케이션과 연관된 성능 문제를 제거한다. 도 45b는 FaaS 서비스를 위한 런타임 프레임워크를 동작시키는 방법을 도시한다. 방법은 일반적 으로, 예를 들어, 이미 논의된, 시스템(도 2), 시스템(도 3) 및/또는 시스템(도 4)과 같은 향상 된 FaaS 시스템에서 구현될 수 있다. 일 실시예에서, 방법은 이미 논의된, 예를 들어, FaaS 아키텍처(도 45a)과 같은, FaaS 아키텍처에서 구현된다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령 어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기 술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 RPC의 패킷화 이전에 네트워크 스택의 애플리케이션 계층에서 제1 네트워크 함수 로부터의 RPC를 가로채기하는 것을 제공한다. 블록은 (예를 들면, 애플리케이션 계층에서) RPC와 연관된 제2 네트워크 함수의 인스턴스화를 수행할 수 있으며, 여기서 인스턴스화는 네트워크 스택의 전송 계층 또는 네 트워크 스택의 네트워크 계층 중 하나 이상을 우회한다. 일 예에서, 인스턴스화는 또한 하나 이상의 암호화 동 작 및/또는 하나 이상의 호출자-타깃 핸드셰이크 메시지를 우회한다. 추가 비고 및 예 예 4501은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 원격 프로시저 호출의 패킷화 이전에 네트워크 스택의 애플리케이션 계층에서 제1 네트워크 함수로부터의 원격 프로시저 호출을 가로채기하게 하고, 원격 프로시저 호출과 연관된 제2 네트워크 함수의 인스턴스화를 수행하게 하는 실행 가능 프로그램 명령어 세 트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 인스턴스화는 네트워크 스택의 전송 계층 또는 네트워크 스택의 네트워크 계층 중 하나 이상을 우회한다. 예 4502는 예 4501의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 인스턴스화는 하나 이상의 암호화 동작 및/또는 하나 이상의 호출자-타깃 핸드셰이크 메시지를 우회한다. 응답 객체 조정 예 일 예에서, FaaS 아키텍처는 표준 데이터 교환 포맷을 사용하여 함수 간에 파라미터 및 인수를 전달하고, 그러 한 포맷으로 직렬화되는 호출 요청 응답을 수신하는 등을 하며, 통상적으로 사용되는 포맷은 경량이고 쉽게 판 독/파싱될 수 있는 JSON(JavaScript Object Notation)이다. 함수의 상이한 호출 인스턴스는 응답 객체의 상이 한 필드를 사용할 수 있으며, 여기서 응답 객체는 JSON 객체의 형태로 직렬화되고 리턴될 수 있다. 예를 들어, 함수 \"funcGetItems\"는 아이템들 - 각각은 필드들의 상세 리스트를 포함함 - 의 리스트를 리턴할 수 있다. funcGetItems(){ //retrieve items from, e.g., database itemsRet = ... return itemsRet; } funcGetItems에 의해 리턴되는 샘플 JSON 응답: { \"items\": [ { \"item_id\": \"CCA\", \"estimated_at\": 1461612017, \"expires_at\": 1461612617, \"start_time\": 1461618000, \"end_time\": 1461621600, \"fee\": 4.34, \"currency_code\": \"USD\", \"ready_by_time\": 1461617260 }, { \"item_id\": \"CVOWF\", \"estimated_at\": 1461612017, \"expires_at\": 1461612617, \"start_time\": 1461621600, \"end_time\": 1461625200, \"fee\": 4.34, \"currency_code\": \"USD\", \"ready_by_time\": 1461620860 }, { \"item_id\": \"Y2UyND\", \"estimated_at\": 1461612017, \"expires_at\": 1461612617, \"start_time\": 1461625200, \"end_time\": 1461628800, \"fee\": 4.34, \"currency_code\": \"USD\", \"ready_by_time\": 1461624460 } ] } 함수 \"funcA\" 및 \"funcB\" 각각이 \"funcGetItems\"를 호출하지만, 이들 각각이 각각의 아이템의 몇 개의 필드만을 사용하는 시나리오가 조우될 수 있다. funcA() { response = lambda.invoke(funcGetItems) all = response[\"items\"] for item in all: process(item[\"item_id\"], item[\"fee\"]) } funcB() { response = lambda.invoke(funcGetItems) all = response[\"items\"] for item in all: process(item[\"item_id\"], item[\"start_time\"]) } 본 명세서에서 설명된 기술은 각각의 호출자의 요구사항/서명에 따라 조정될 직렬화된 응답(또는 파라미터) 객 체를 조정한다. 예를 들어, \"funcB\"에 대한 리턴된 응답은 이하의 JSON 객체 - 필요한/적절한 데이터 필드만포함함 - 로 압축될 수 있다. { \"items\": [ { \"item_id\": \"CCA\", \"start_time\": 1461618000, }, { \"item_id\": \"CVOWF\", \"start_time\": 1461621600, }, { \"item_id\": \"Y2UyND\", \"start_time\": 1461625200, } ] } 예를 들어, 도 46a는 함수가 데이터 필드 세트(예를 들어, \"item_id\"부터 \"ready_by_time\"까지)를 리턴할 수 있음을 보여준다. 함수의 제1 호출 인스턴스(예를 들어, \"funcA\"의 람다/익명 호출자) 에 의한 제1 호출이 탐지되면, 필드 세트의 제1 서브세트(예를 들면, \"item_id\" 및 \"fee\"만)가 식 별될 수 있으며, 여기서 제1 서브세트는 제1 호출 인스턴스와 관련된다. 더욱이, 제1 응답 객체 (예를 들면, JSON 객체)의 제1 릴레이 아웃(relayout)(예를 들면, 재구성, 재정렬)이 제1 서브세트 에 기초하여 수행될 수 있다. 더 상세히 논의될 것인 바와 같이, 제1 릴레이 아웃은 제1 서브세트(460 6)만을 포함하도록 제1 응답 객체를 필터링할 수 있고, 필드 세트 내의 나머지 필드 이전에 제1 서 브세트를 열거하도록 제1 응답 객체를 재정렬하는 등을 할 수 있다. 유사하게, 함수의 제2 호출 인스턴스(예를 들어, \"funcB\"의 람다/익명 호출자)에 의한 제2 호출이 탐지되면, 필드 세트의 제2 서브세트(예를 들면, \"item_id\" 및 “start_time”만)가 식별될 수 있 으며, 여기서 제2 서브세트는 제2 호출 인스턴스와 관련된다. 더욱이, 제2 응답 객체(예를 들면, JSON 객체)의 제2 릴레이 아웃이 제2 서브세트에 기초하여 수행될 수 있다. 다시 말하면, 제2 릴 레이 아웃은 제2 서브세트만을 포함하도록 제2 응답 객체를 필터링할 수 있고, 필드 세트 내 의 나머지 필드 이전에 제2 서브세트를 열거하도록 제2 응답 객체를 재정렬하는 등을 할 수 있다. 따라서 향상된 FaaS 시스템에 의해 제공되는 예시된 솔루션은 응답 객체(4612, 4614)를 압축하고, 더 효율적인 네트워킹/대역폭 사용, 더 적은 프로세싱 오버헤드, 향상된 성능, 최소화된 관리 및 더 큰 확장성을 가능하게 한다. 일 실시예에서, 압축 메커니즘은 응답이 다시 송신되기 전에 각각의 호출자 익명 함수(예를 들어, 함수 리터럴, 람다 추상화, 람다 표현식)에 대한 관련 필드의 수집으로서 구현될 수 있다. 하나의 예에서, 관련 데이터 필드 의 레이블/오프셋은 각각의 호출자에 대해 등록된다 - 그리고 피호출자 람다에 인접한 소프트웨어/하드웨어 구 조에 추가로 캐싱될 수 있음 -. 예를 들어, 룩업 테이블은 원시 결과에 적용될 필터를 검색하기 위해 호출자 ID/IP/어드레스에 의해 인덱싱될 수 있다. 필터는 상기 예와 유사한 몇 개의 관심 필드를 선택할 수 있다. 추 가적으로, 필터는 관심 필드를 먼저 열거/표시하고 나머지 필드/데이터를 나중에 배치하도록 응답/JSON 객체를 재포맷팅할 수 있다. 논의를 용이하게 하기 위해 본 명세서에서 JSON 압축이 사용되지만, 예를 들어, gRPC 바 이너리 인코딩과 같은 메시지 파라미터의 다른 인코딩도 사용될 수 있다. 일 예에서, 필터 코드(예를 들어, 메소드 스터브, 람다)는 호출자 구현(예를 들어, 서명, 메서드 스터브)의 일 부로서 제공된다. 필터 코드는 또한 컴파일러/런타임 툴에 의해 도출될 수 있다. 일 실시예에서, 원시 결과를 다시 송신하기 이전의 원시 결과의 필터링은 return 명령어를 실행하기 전에 점프 테이블(예를 들어, 각각의 호 출자에 맞게 조정된 압축/릴레이 아웃을 수행하는 코드로의 간접 점프)을 통해 구현된다. 게다가, ISA(instruction set architecture) 및 하드웨어 지원은 간접 점프의 타깃을 캐싱하거나(예를 들면, 변환 색인버퍼/TLB 캐시와 유사함) 간접 점프의 타깃을 예측하기 위해(예를 들면, 분기 타깃 버퍼/BTB와 유사함) 개발될 수 있다. 이제 도 46b를 살펴보면, 응답 객체를 호출 인스턴스에 맞춤화하는 방법이 도시되어 있다. 방법은 일반적으로, 예를 들어, 이미 논의된, 시스템(도 2), 시스템(도 3) 및/또는 시스템(도 4)과 같 은 향상된 FaaS 시스템에서 구현될 수 있다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 필드 세트를 리턴하는 함수의 제1 호출 인스턴스에 의해 제1 호출을 탐지한다. 블록에서 필드 세트의 제1 서브세트가 식별될 수 있으며, 여기서 제1 서브세트는 제1 호출 인스턴스와 관 련되어 있다. 추가적으로, 블록은 제1 서브세트에 기초하여 제1 응답 객체의 제1 릴레이 아웃을 수행한 다. 일 예에서, 블록은 제1 서브세트만을 포함하도록 제1 응답 객체를 필터링하는 것을 포함한다. 블록 은 필드 세트 내의 나머지 필드 이전에 제1 서브세트를 열거하기 위해 제1 응답 객체를 재정렬하는 것을 또한 포함할 수 있다. 다른 릴레이 아웃 기술이 또한 사용될 수 있다. 일 예에서, 블록에서 함수의 제2 호출 인스턴스에 의한 제2 호출이 탐지된다. 블록에서 데이터 필 드 세트의 제2 서브세트가 식별되며, 여기서 제2 서브세트는 제2 호출 인스턴스와 관련되어 있다. 예시된 블록 은 제2 서브세트에 기초하여 제2 응답 객체의 제2 릴레이 아웃을 수행하며, 여기서 제2 릴레이 아웃은 제 1 릴레이 아웃과 상이하다. 블록은 제2 서브세트만을 포함하도록 제2 응답 객체를 필터링하는 것, 필드 세트 내의 나머지 필드 이전에 제2 서브세트를 열거하도록 제2 응답 객체를 재정렬하는 것 등을 포함할 수 있다. 따라서, 예시된 방법은 응답 객체를 압축하고, 더 효율적인 네트워킹/대역폭 사용, 더 적은 프로 세싱 오버헤드, 향상된 성능, 최소화된 관리 및 더 큰 확장성을 가능하게 한다. 추가 비고 및 예 예 4601은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 필드 세트를 리턴하는 함수의 제1 호 출 인스턴스에 의해 제1 호출을 탐지하게 하고, 필드 세트의 제1 서브세트를 식별하게 하며 - 제1 서브세트는 제1 호출 인스턴스와 관련됨 -, 제1 서브세트에 기초하여 제1 응답 객체의 제1 릴레이 아웃을 수행하게 하는 실 행 가능 프로그램 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 예 4602는 예 4601의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 제1 릴레이 아웃은 제1 서 브세트만을 포함하도록 제1 응답 객체를 필터링한다. 예 4603은 예 4601의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 제1 릴레이 아웃은 필드 세트 내의 나머지 필드 이전에 제1 서브세트를 열거하도록 제1 응답 객체를 재정렬한다. 예 4604는 예 4601의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 명령어는, 실행될 때, 컴 퓨팅 디바이스로 하여금 함수의 제2 호출 인스턴스에 의한 제2 호출을 탐지하게 하고, 필드 세트의 제2 서브세 트를 식별하게 하며 - 제2 서브세트는 제2 호출 인스턴스와 관련됨 -, 제2 서브세트에 기초하여 제2 응답 객체 의 제2 릴레이 아웃을 수행하게 하며, 여기서 제2 릴레이 아웃은 제1 릴레이 아웃과 상이하다. 파라미터 마샬링 예 파라미터 마샬링은 객체의 메모리 표현을 다른 소프트웨어 애플리케이션으로의 저장 또는 전송에 적합한 다른 포맷으로 변환하는 것을 포함한다. 따라서 마샬링은 객체를 직렬화된 형태로 변환함으로써 원격 객체 간의 통 신을 용이하게 한다. FaaS 프레임워크에서의 RPC에 대한 파라미터의 마샬링은 급격한 양의 데이터가 전송되는 것으로 인해 병목 현상 문제에 직면할 수 있다. 텍스트 인코딩(예를 들면, JSON을 사용한 REST) 또는 이진 인 코딩(예를 들면, GRPS, FLATBUFFERS, APACHE THRIFT)이 함수 파라미터를 전달하는 데 사용되는지에 관계없이, \"와이어\" 상의 데이터가 메모리 내의 데이터와 상이하게 포맷팅되기 때문에 병목 현상 문제가 지속될 수 있으며, 영구 직렬화/역직렬화가 있다. 도 47a는 컴파일러가 함수에 대한 페이로드(예를 들어, \"실행 준비된(ready-to-execute)\" 데이터 어레이)를 결정하고, 컴파일 시에, 페이로드를 호출 스택에 배치하는 시나리오를 도시한다. 더 상 세히 논의될 것인 바와 같이, 함수는 (예를 들어, 로컬 플랫폼 상의) 하나 이상의 로컬 인스턴스 또는 (예를 들어, 원격 플랫폼 상의) 하나 이상의 원격 인스턴스로서 페이로드를 통해 균일하게 호출 가능하다. 런타임 시에 (예를 들어, 컴파일 시에 알려지지 않은 다양한 조건에 기초하여) 함수가 원격 플랫폼 상 에서 호출되어야 한다고 결정되면, 예시된 페이로드는 원격 플랫폼 상의 호출 스택으로 전송되며, 여기서 일반 RPC 핸들러가 인스턴스(들)를 호출하는 데 사용된다. 일 예에서, 페이로드는 하나 이 상의 파라미터 값, 페이로드의 크기, 및 함수의 식별자를 포함한다. 따라서, 예시된 솔루션은 함수 파라 미터의 비효율적인 마샬링과 연관된 병목 현상을 제거한다. 따라서, 향상된 성능, 최소 관리, 및 더 큰 확장성 이 달성될 수 있다. 더 상세하게는, \"전송 준비된(ready-to-wire)\" 포맷은 호출의 스터브 측 부분에 대한 스택이 RPC 전송 메 커니즘을 사용하여 이를 전송하는 데 또는 이를 하드웨어에 전달하는 데 필요한 모든 세부 사항을 포함하는 함 수 호출에 대한 ABI(application binary interface)의 일부로서 사용될 수 있다. 따라서, 스택은 페이 로드가 실행 준비된 데이터 어레이로서 배치되어 타깃의 호출에 대해 준비되는 곳이다. 따라서, 타깃이 원격이고 비공유 메모리 전송 메커니즘을 통해 호출될 필요가 있는 경우, 이는 로컬 플랫폼의 스택에 이 미 조립된 페이로드로 직접 호출된다. 원격 플랫폼(예를 들어, 수신기/타깃 측)에서, 역 동작은 유사하게 호출을 위한 스택을 셋업한다(예를 들 어, 프로토콜 프로세싱 및 데이터 언패킹을 단일 동작으로 축소(collapse)함). 따라서, 타깃이 유선으로 페이 로드를 전송할 필요 없이 호출될 수 있는 원격 프로시저인 경우, 스택은 공유 메모리에 구축될 수 있으며 RPC는 매우 경량이다 - 로컬 함수 호출과 매칭하더라도, 모든 인수가 원격 호출을 디스패치하는 데 사용되는 스 택과 함께 공유 메모리에 있는 경우 -. 마샬링이 단순히 파라미터 값(예를 들면, 인수)을 스택 프레임에 복사하는 것을 수반하는 의도적으로 간단한 예 로 원리가 아래에 설명되어 있다. 핵심 원리가 더 복잡한 인수에 대해 동일하게 유지된다. 런타임 시에, 구성에 따라, 예를 들어, test(int a, short b)와 같은 함수가 로컬 호출로서 또는 원격 네트워크 호스트 상에서의 원격 호출로서 디스패치될 수 있다. 이 결정은 컴파일 시에 알려지지 않은 다양한 조건에 근 거할 수 있다. 그러한 경우에, 종래의 런타임은 다음과 같은 호출을 수행할 수 있다(이중 슬래시 \"//\" 뒤에 코 드 주석이 있음): if (__local_call_to_test()) { test(a, b); // compiler generates code placing a and b on stack or registers, as // follows- // stack.a=a; // stack.b=b; // call test } // use regular ABI, a and b would be on stack and/or registers else { // client-side stub for test(a, b) ... // construct the message for sending struct m_test m = malloc (sizeof (struct m_test)) ; m->a = a; m->b = b; m->header = ... xxx ...; // perform the invocation via-transport _RPC_CALL_(\"test\", m); // the target host will reverse the above operations, and then invoke test(a, b) at the target. } 이와 달리, 본 명세서에서 설명된 기술은 컴파일러를 통해 다음과 같은 통합 및 단순화를 수행한다. 컴 파일러는, test(a, b) 호출에 대해, 다음을 생성한다: stack.header = test_specific_header; // identification of 'test' function, // such as a 32- or 64- bit ID that may be an index in vtable for this function stack.a=a; stack.b=b; stack.epilogue=test_specific_epilogue; // contains size of frame, and may // be, something else in addition. // Size of frame/payload enables generic RPC implementation call [test]; // indirect call using vtable (virtual method table) 더욱이, 호출이 원격 IPC(inter-process communication) 호출인 경우, 일반 RPC 핸들러가 다음을 수행할 수 있 다: #define _SES sizeof (stack.epilogue) // make a call to the function // as defined in the header, using stack content as payload, and size of payload send(stack.header.id,&stack-_SES_,_SES_); 여기서 SES는 스택 에필로그 크기(예를 들면, 코드 명확성을 위해 사용되는 매크로 대체물)를 지칭한다. 이미 언급된 바와 같이, 페이로드는 호출된 함수의 식별(identification), 페이로드의 크기 및 파라미터의 값을 포함 할 수 있다(예를 들어, 그렇지 않았으면 교차 도메인 호출을 방해할 임의의 포인터/참조를 피함). 도 47b는 로컬 호출이 로컬 시스템에서 실행되는 것과 동일한 방식으로 원격 호출이 그의 스택 상에 디스패치를 위해 배열되는 상위 레벨 아키텍처를 도시한다. 이제 도 47c를 살펴보면, 함수 파라미터를 마샬링하는 방법이 도시되어 있다. 방법은 일반적으로, 예를 들어, 이미 논의된, 시스템(도 2), 시스템(도 3) 및/또는 시스템(도 4)과 같은 향상된 FaaS 시스템에서 구현될 수 있다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술 을 사용하는 고정 기능 로직 하드웨어에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 함수에 대한 페이로드를 결정하는 것을 제공한다. 일 예에서, 페이로드는 하나 이상의 파라미터 값, 페이로드의 크기, 및 함수의 식별자를 포함한다. 블록은, 컴파일 시에, 페이로드를 호출 스택에 두고, 여기서 함수는 페이로드를 통해 로컬 인스턴스 또는 원격 인스턴스로서 균일하게 호출 가능 하다. 추가적으로, 블록은, 런타임에서, 함수를 로컬 인스턴스로서 호출할지 또는 페이로드를 원격 플랫 폼에 전송할지를 결정할 수 있다. 따라서, 예시된 방법은 함수 파라미터의 비효율적인 마샬링과 연관된 병목 현상을 제거한다. 따라서, 향상된 성능, 최소 관리, 및 더 큰 확장성이 달성될 수 있다. 따라서 더 효율적인 데이터 마샬링은 임의적인 비트 순서(MSB/LSB) 및 유형 트랜스코딩을 사용하는 데이터 구조 의 스캐터/개더(scatter/gather)를 수반할 수 있다. 임의적 비트 순서화와 관련하여, 일부 구현예에서(예를 들 면, 이기종 아키텍처 간에, 말하자면, INTEL <-> MIPS 또는 ARM 간에 호출이 수행될 때), 다중 바이트 유형(예 를 들면, 32 비트 정수 또는 부동 소수점)에서의 바이트의 순서를 지정하는 것이 중요할 수 있다. 예를 들어, 32 비트 정수 0x12345678은 다음과 같은 바이트 시퀀스로 인코딩될 수 있다: LSB(최하위 바이트/비트 먼저)의 경우 0x78, 0x56, 0x34, 0x12 또는 MSB(최상위 바이트/비트 먼저)의 경우 0x12, 0x34, 0x56, 0x78. 따라서, 수신기는 로드 시에 순서를 반대로 할 필요가 있을 수 있으며, 이는 많은 아키텍처에서 특수 명령어로 수행된다. 이 기술은 또한 CPU 기반 파라미터 전달과 원격 호출 또는 가속기 오프로드에 의해 핸들링되는 호출 간에 변환하기 위해 함수 허브를 사용할 수 있다. 따라서, 작업이 발생하는 타깃이 호출자에게는 프로세스 로 컬 호출과 똑같이 보인다. 추가 비고 및 예 예 4701은, 컴퓨팅 디바이스에 의해 실행될 때, 컴퓨팅 디바이스로 하여금 함수에 대한 페이로드를 결정하게 하 고, 컴파일 시에, 페이로드를 빌드하는 코드를 호출을 하기에 충분한 정보를 포함하는 포맷으로 호출 스택에 두 게 하는 실행 가능 프로그램 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 함수는 페이로드를 통해 로컬 인스턴스, 원격 인스턴스 또는 하드웨어로서 균일하게 호출 가능하다. 예 4702는 예 4701의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 페이로드는 하나 이상의 파라미터 값, 페이로드의 크기 및 함수의 식별자를 포함한다. 예 4703은 예 4701의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 명령어는, 실행될 때, 컴 퓨팅 디바이스로 하여금, 런타임에서, 함수를 로컬 인스턴스로서 호출할지 또는 페이로드를 원격 플랫폼에 전송 할지를 결정하게 한다. 능력 전달 예 FaaS 시스템의 동작 동안, 함수(예를 들면, 소스 함수)의 능력은 종종, 로컬(예를 들면, 소스 함수와 메모리 영 역을 공유함) 또는 원격(예를 들면, 목적지 함수와 메모리 영역을 공유하지 않음)일 수 있는, 다른 함수(예를 들면, 목적지 함수)에 전달된다. 함수가 상대적으로 비특권(예를 들면, 특권 링 3)인 경우, 보안 대책은 함수 들 간에 전달되는 능력이 합법적이도록 보장하기에 적절하다. 더 상세히 논의될 것인 바와 같이, 도 4에 도시 된 것과 같은 향상된 FaaS 시스템에 의해 이용되는 향상된 기술은 복잡한 소프트웨어 아키텍처에서 함수 능력을 생성하기 위해 신뢰할 수 있는 소프트웨어 런타임의 개발 또는 삽입에 대한 임의의 필요성을 줄이는 데 사용된 다. 더욱이, 이 기술은 공유 메모리 설정에서 HTTP 메시지를 전송하는 것 및 데이터를 복사하는 것과 연관된 오버헤드를 제거한다. 도 48a는 제1 함수(소스 함수 \"f3\")가 제2 함수(목적지 함수 \"f4\")의 호출/호출과 관련하여 신뢰할 수 있는 큐 관리자에 능력 정보를 송신하는 시나리오를 도시한다. 예시된 예에서, 신뢰할 수 있는 큐 관리자는 제1 인증 포맷에 대해 능력 정보가 유효한지(예를 들어, 진정인지)를 결정하고, 여기서 능력 정보 및 제1 인증 포맷은 제1 함수에 대응한다. 일 실시예에서, 제1 인증 포맷 은 제1 함수에 의해 인식되고 신뢰할 수 있는 큐 관리자가 제1 함수에 할당된 제1 키 (도시되지 않음)를 사용하여 능력 정보가 유효한지를 결정하는 것을 수반한다. 더 상세하게는, 신뢰할 수 있는 큐 관리자는 제1 키를 능력 정보에 임베딩된 MAC(message authentication code)와 비교할 수 있다. 대안적으로, 능력 정보는 능력 정보를 손상시키는 것이 공격자에게 예측 가능하고 사용 가능한 기능을 제공하지 않는 방식으로 암호화될 수 있다. 신뢰할 수 있는 큐 관리자가 능력 정보가 제1 인증 포맷에 대해 유효하다고 결정하면, 신뢰 할 수 있는 큐 관리자는 능력 정보를 신뢰할 수 있는 큐(도시되지 않음)에 저장(예를 들어, 인큐잉)한다. 예시된 신뢰할 수 있는 큐 관리자는 또한 제2 함수에 대응하는 제2 인증 포맷에 따라 능력 정보를 생성하여 제2 함수에 송신한다. 일 실시예에서, 제2 인증 포맷은 제2 함수에 의해 인식되고 제2 함수에 할당된 제2 키(도시되지 않음)를 사용하여 능력 정보를 인증하는 것을 수반한다. 일 실시예에서, 인증은 제2 키를 사용하여 MAC를 재계산하고 그 결과를 능력 정보에 임베딩된 MAC와 비교하는 것을 포함한다. 따라서, 제1 인증 포맷은 전형적으로 제2 인증 포맷과 상이하다. 신뢰할 수 있는 큐 관리자를 하드웨어 큐 관리자(HQM)로서 구현하는 것은 신뢰할 수 있는 소프트웨어 런 타임이 복잡한 소프트웨어 아키텍처에서 능력 정보(4802, 4803)를 생성할 필요가 없게 한다. 더욱이, 신뢰할 수 있는 큐 관리자는 (예를 들어, HTTP 포맷 또는 f3으로부터 f4로 전송될 수 있는 임의의 다른 포맷으로) 메시지를 전송하는 것 및 공유 메모리 설정에서 데이터를 복사하는 것과 연관된 오버헤드를 제거한다. 함수(4800, 4806)는, 로드 밸런서가 FaaS 시스템 전체에 걸쳐 함수(4800, 4806)를 동적으로 이동시 키는 한, 이식 가능 함수(예를 들어, 이식 가능 아이덴티티를 가짐)일 수 있다. 도 48b는 이미 논의된 능력 정보(4802, 4803)(도 48a)를 쉽게 대체할 수 있는 EIC(encoded inline capability) 정보(4812a 내지 4812c)를 도시한다. 예시된 예에서, EIC 정보는 MAC(4812a), 경계 정보(4812b) 및 포인터(4812c)를 포함한다. 일 예에서, MAC(4812a)는 경계 정보(4812b)에 기초한 키잉된 단방향 해시 함수 에 의해 생성된 태그이며, MAC(4812a)를 생성하는 데 사용되는 비밀 키는 보호된 영역에(예를 들면, 호스트 프 로세서 상에) 위치된다. 따라서, MAC(4812a)는 EIC 정보가 명시된 송신자로부터 왔으며 변경되지 않았음 을 확인하는 데 사용된다. 따라서, 예시된 MAC(4812a)는 또한 비밀 키를 소유한 검증자가 EIC 정보에 대 한 임의의 변경을 탐지할 수 있게 함으로써 EIC 정보의 무결성 및 진정성 둘 모두를 보호한다. 일 예에 서, 포인터(4812c)는 경계 정보(4812b)에 의해 정의된 메모리 영역을 참조한다. 따라서, 함수에 의해 메모리액세스가 시도될 때, MAC(4812a)는 액세스에서 사용되는 포인터가 적법이고 경계 정보(4812b)에 의해 정의된 메 모리 영역 내에 있음을 확인하기 위해 검사된다. 일 실시예에서, EIC 정보는 계층적인 인코딩된 인라인 능력을 포함한다. 예를 들어, 복합 EIC는 EIC의 서브그룹을 포함할 수 있으며, 이는 차례로 다중 레벨 계층구조에서의 가상(예를 들어, 멀티캐스팅) 채널에 대 응한다. 추가적으로, EIC 정보는 능력으로서 사용자 레벨 인터럽트(ULI)를 포함할 수 있고, PASID(process address space identifier)는 EIC 정보와 함께 인큐잉될 수 있다. 도 48c는 이미 논의된 신뢰할 수 있는 큐 관리자(도 48a)를 쉽게 대체할 수 있는 하드웨어 큐 관리자 를 도시한다. 예시된 예에서, 하드웨어 큐 관리자는 큐 세트를 유지하고, 여기서 각각의 큐 는 특정 함수 또는 함수 세트에 대한 능력 정보를 보유한다. 따라서 예시된 솔루션은 인큐잉된 능력의 하드웨어 관리를 사용하여 가상 채널을 시행한다. 시스템 레벨 특권(예를 들어, 링 3보다 더 많은 특권이 있음)을 갖는 하드웨어 큐 관리자는 또한 (예를 들어, 다른 플랫폼/머신에서의 에지를 통해) 원격 하드웨 어 큐 관리자와 키 정보를 교환할 수 있다. 일 실시예에서, 하드웨어 큐 관리자는 또한, 예 를 들어, 능력을 인증하는 데 사용되는 키, 각각의 함수에 대한 개인 데이터 영역의 경계를 나타내는 범위 레지 스터 등과 같은 다른 컨텍스트 정보를 업데이트하는 것을 책임지고 있다. 따라서 하드웨어 큐 관리자는 링 3에 상주하고 함수 능력을 생성하기 위해 신뢰할 수 있는 소프트웨어 런타임으로서 작용하는 종래의 루트 보 호 도메인(PD)에 비해 효율성 개선을 나타낸다. 예를 들어, 일부 종래의 루트 PD는 프로세스 내의 모든 메모리에 액세스할 수 있는 비특권 소프트웨어(예를 들어, CPU의 링 3에 또는 프로세서 상의 다른 비특권 모드 에 있음)로서 구현될 수 있다. 이 소프트웨어는 개인 데이터 영역 경계 레지스터를 초기화하는 것, 능력 인증 키 레지스터를 초기화하는 것, 및 특정 비-루트 PD가 액세스하도록 인가된 공유 데이터 영역 내의 메모리 영역 을 참조하는 인코딩된 인라인 능력을 생성하는 것 - 이는 효율성을 저하시킴 - 을 책임지고 있다. 일 예에서, 본 실시예의 하드웨어 큐 관리자는 상이한 함수의 호출로 인해 컨텍스트 전환이 발생하려고 할 때를 탐지 하는 호스트 프로세서(예를 들어, CPU)에 위치된다. 도 48d는 하드웨어 큐 관리자를 동작시키는 방법을 도시한다. 방법은 일반적으로 이미 논의된, 예 를 들어, 신뢰할 수 있는 큐 관리자(도 48a) 및/또는 하드웨어 큐 관리자(도 48c)와 같은, 큐 관리 자에 의해 구현될 수 있다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래 시 메모리 등과 같은 비-일시적 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술 을 사용하는 고정 기능 하드웨어 로직에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 능력 정보가 제1 인증 포맷과 관련하여 유효한 것/진정한 것인지를 결정하며, 여 기서 능력 정보 및 제1 인증 포맷은 제1 함수에 대응한다. 일 예에서, 블록은 제1 함수와 연관된 제1 키 를 사용하여 능력 정보가 유효한지를 결정한다. 만약 그렇다면, 블록은 능력 정보를 신뢰할 수 있는 큐 에 저장(예를 들면, 인큐잉)한다. 일 예에서, 능력 정보는 계층적인 인코딩된 인라인 능력을 포함한다. 블록에서 제2 함수에 대응하는 제2 인증 포맷에 따라 능력 정보가 제2 함수에 전송된다. 일 실시예에서, 제2 인증 포맷은 제2 함수으로의 전송 동안 능력 정보를 보호 및 인증하기 위해 제2 함수와 연관된 제2 키의 사 용을 지정한다. 예에서, 제1 함수와 제2 함수는 이식 가능 함수이다. 따라서, 예시된 방법은 복잡한 소 프트웨어 아키텍처에서 함수 능력을 생성하기 위해 신뢰할 수 있는 소프트웨어 런타임에 대한 임의의 요구를 감 소시킨다. 더욱이, 이 기술은 공유 메모리 설정에서 메시지를 전송하는 것 및 데이터를 복사하는 것과 연관된 오버헤드를 제거한다. 도 48e는 실시예에 따른 능력을 인큐잉하는 방법을 도시한다. 방법은 일반적으로 이미 논의된, 예 를 들어, 신뢰할 수 있는 큐 관리자(도 48a) 및/또는 하드웨어 큐 관리자(도 48c)와 같은, 큐 관리 자에 의해 구현될 수 있다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래 시 메모리 등과 같은 비-일시적 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술 을 사용하는 고정 기능 하드웨어 로직에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 송신될 능력은 물론 의도된 목적지를 지정하는 새로운 명령어(예를 들면, ENQCAP)을 사용하여 능력을 인큐잉하라는 하나 이상의 서비스 요청을 탐지한다. 예를 들어, 목적지는 전역적으 로 또는 로컬로 고유한 서비스 ID로서 지정될 수 있다. 예시된 블록에서, ENQCAP는 제공된 능력을 인증 하기 위해 현재 능력 인증 키를 사용한다. 인증이 성공하는 경우, ENQCAP 블록은 능력으로부터 경계 및포인터 정보를 추출한다. ENQCAP 블록은 이어서 추출된 정보에 적절한 목적지 큐를 식별한다. 예를 들 어, 이 절차는 서비스 ID를 서비스를 호스팅하도록 할당된 프로세서의 ID로 변환하는 것을 수반할 수 있다. 각 각의 서비스는 하나 이상의 프로세서로 잠금될 수 있거나, 또는 시스템 내의 임의의 프로세서에서 서비스를 호 출하는 것이 가능할 수 있다. 상이한 시스템 내의 프로세서에서 서비스를 자동으로 호출하는 것조차도 가능할 수 있다. 그러한 호출은 능력에 의해 참조되는 데이터를 목적지 시스템에 복사하는 것을 요구할 것이다. 이는 또한 서비스에 대한 코드를 목적지 시스템에 복사하는 것을 요구할 수 있다. 목적지 시스템과 통신하기 위한 네트워크 프로토콜이 요구될 수 있다. 예를 들어, 운영 체제는 상이한 시스템 들에 있는 하드웨어 큐 관리자 인스턴스들 간의 연결성을 확립하는 것을 담당할 수 있다. 그러면 하드웨어 큐 관리자가 서로 통신할 수 있다. 예시된 블록은 목적지 서비스 ID와 함께 포인터 및 경계 정보를 목적지 큐에 인큐잉한다. 블록에서 서비스 실행이 이어서 계속될 수 있다. 블록에서 제공된 능력이 진정 한 것이 아닌 것으로 결정되는 경우, 예시된 블록에서 예외가 생성된다. 도 48f는 실시예에 따른 능력을 디큐잉하는 방법을 도시한다. 방법은 일반적으로 이미 논의된, 예 를 들어, 신뢰할 수 있는 큐 관리자(도 48a) 및/또는 하드웨어 큐 관리자(도 48c)와 같은, 큐 관리 자에 의해 구현될 수 있다. 더 상세하게는, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래 시 메모리 등과 같은 비-일시적 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술 을 사용하는 고정 기능 하드웨어 로직에서, 또는 이들의 임의의 조합으로 구현될 수 있다. 예시된 프로세싱 블록은 포인터 및 경계 정보는 물론 목적지 서비스 ID를 디큐잉하라는 요청을 탐지한다. 블록에서 목적지 서비스가 현재 로딩되어 있는지에 대한 결정이 이루어질 수 있다. 만약 그렇지 않다면, 블록은 목적지 서비스에 대한 코드 및 데이터를 로딩하고 개인 데이터 영역을 할당한다. 추가적으로, 블 록에서, 목적지 서비스에 대한 개인 데이터 영역을 커버하도록 개인 데이터 영역 경계 레지스터가 초기화 된다. 일 실시예에서, 블록은 랜덤하게 생성된 데이터로 능력 인증 키 레지스터를 초기화한다. 인증 키 레지스터 내의 키는 인코딩된(예를 들면, 암호화 된) 인라인 능력 및/또는 메시지에서 MAC을 생성할 때 입력으 로서 사용된다. 비-루트 PD는 키를 판독하거나 키에 액세스할 수 없기 때문에, 키의 사용은 비-루트 PD가 위조 능력을 갖지 못하도록 하는 데 도움을 준다. 예시된 블록은 디큐잉된 포인터 및 경계 정보를 표현하는 인코딩된 인라인 능력을 생성하고 생성된 EIC를, 목적지 서비스가 액세스할 수 있도록, 레지스터에 저장한다. 블록은 제어를 목적지 서비스로 이전한다. 블록에서 목적지 서비스가 현재 로딩되어 있다고 결정 되는 경우, 방법은 블록을 우회할 수 있다. 추가 비고 및 예 예 4801은, 하나 이상의 기판 및 하나 이상의 기판에 결합된 로직을 포함하는, 반도체 장치를 포함하며, 여기서 로직은 적어도 부분적으로 구성 가능한 로직 또는 고정 기능 하드웨어 로직으로 구현되고, 로직은 능력 정보가 제1 인증 포맷과 관련하여 유효한지를 결정하고 - 능력 정보 및 제1 인증 포맷은 제1 함수에 대응함 -, 능력 정 보가 제1 인증 포맷과 관련하여 유효한 경우 능력 정보를 큐에 저장하며, 제2 함수에 대응하는 제2 인증 포맷에 따라 능력 정보를 제2 함수에 전송하기 위해 하나 이상의 기판에 결합되며, 여기서 제1 함수 및 제2 함수는 이 식 가능 함수이고, 여기서 능력 정보는 계층적인 인코딩된 인라인 능력 및 사용자 레벨 인터럽트를 포함한다. 예 4802는, 하나 이상의 기판 및 하나 이상의 기판에 결합된 로직을 포함하는, 반도체 장치를 포함하며, 여기서 로직은 적어도 부분적으로 구성 가능한 로직 또는 고정 기능 하드웨어 로직으로 구현되고, 로직은 디큐잉된 포 인터 및 경계 정보 및 실행될 함수와 연관된 목적지 서비스 ID를 결정하고, 목적지 서비스가 현재 로딩되지 않 은 것에 응답하여, 식별된 목적지 서비스에 대한 함수와 연관된 코드 및 데이터를 로딩하고 함수를 실행하기 위 한 개인 데이터 영역를 할당하며, 제어를 식별된 목적지 서비스로 이전하기 위해 하나 이상의 기판에 결합되며, 여기서 함수를 실행하기 위한 개인 데이터 영역을 할당하는 것은 목적지 서비스에 대한 개인 데이터 영역을 커 버하도록 하나 이상의 개인 데이터 영역 경계 레지스터를 초기화하는 것, 랜덤하게 생성된 데이터로 능력 인증 키 레지스터를 초기화하는 것, 디큐잉된 포인터 및 경계 정보를 표현하는 인코딩된 인라인 능력을 생성하는 것, 및 목적지 서비스에 의해 액세스 가능하도록 인코딩된 인라인 능력을 레지스터에 저장하는 것을 포함한다. 인트라 어드레스 공간 구획화 예 TME(Total Memory Encryption)는 단일 키로 플랫폼의 전체 메모리(예를 들면, 다양한 캐시 레벨)를 암호화할 수 있다. TME는 BIOS 구성 및/또는 다른 소프트웨어를 통해 인에이블될 수 있으며, 메모리 내의 모든 데이터(예를들면, 고객 자격 증명, 암호화 키 및 다른 IP 또는 개인 정보)가 외부 메모리 버스 상에서 암호화되도록 보장하 는 데 도움이 될 수 있다. 따라서, 애플리케이션 및/또는 CPU가 메모리에 데이터를 요청하면, 데이터가 암호화 되고 이어서 나중에 전송 후에 복호화될 수 있다. 메모리 암호화에 사용되는 암호화 키는 CPU 및/또는 신뢰할 수 있는 플랫폼 관리자 내의 강화된(hardened) 난수 생성기를 사용하여 생성될 수 있다. 일부 실시예에서, 키는 소프트웨어에 절대로 노출되지 않을 수 있으며, 이 에 의해 악의적인 데이터 도난 및/또는 키 사용의 교차 오염의 가능성을 감소시킨다. 다른 실시예에서, 소프트 웨어는 키 ID를 통해 키에 액세스할 수 있다. 메모리 내의 및 외부 메모리 버스 상의 데이터는 암호화될 수 있으며, 전형적인 스토리지 암호화와 유사하게, CPU 내부에 있는 동안 및/또는 TPM(Trusted Platform Manager)에 의해 평문으로 복호화된다. 이것은 TME를 사 용하여 메모리를 보호하면서 기존 소프트웨어가 수정되지 않고 실행될 수 있게 한다. TME는, 메모리의 다른 부 분(예를 들어, 다른 물리 어드레스 범위)을 암호화되지 않은 상태로 두면서, 메모리의 일부(예를 들어, 특정 물 리 어드레스 범위)만을 암호화하도록 조정될 수 있다. TME 가능 시스템에서 실행되는 소프트웨어는 TME에 의해 암호화되지 않도록 구성된 메모리의 암호화되지 않은 부분에 대한 완전 가시성을 갖기 위해 CPU 내의 구성 레지 스터를 판독할 수 있다. MK-TME(Multi-Key TME)는 메모리의 일부(예를 들면, 페이지 및/또는 물리 어드레스 범위)에 대해서만 특정 키의 사용을 지정하는 능력을 제공하기 위해 다수의 암호화 키를 지원하도록 TME를 확장한다. MK-TME는 로컬로 생성 된 키(예를 들면, TPM 생성 키 및/또는 CPU 생성 키) 및/또는 서드파티 키(예를 들면, 원격 위치에서 오프-플랫 폼으로 생성된 테넌트 제공 키)를 허용하여, 고객에게 완전한 유연성을 제공한다. 그와 같이, 메모리는 다수의 암호화 키에 따라 암호화될 수 있다. 따라서 제1 어드레스 범위는 제1 키에 따라 암호화될 수 있고, 제2 어드 레스 범위는 제2 키에 따라 암호화될 수 있다. MK-TME는 가상 머신(VM) 및 컨테이너가 별개의 암호화 키를 사용하여 메모리에서 서로 암호적으로 격리될 수 있 게 한다. 다중 테넌트 클라우드 환경에서, 그러한 격리는 민감한 데이터가 고객에 의해 프로세싱되고 있을 때 유리하다. VM 및 컨테이너는 특정 상황 하에서 개별 키를 공유하도록 인가되어, 스케일 및 유연성을 더욱 확장시킨다. 예 를 들어, 제1 FaaS 함수가 제2 FaaS 함수를 호출하면, 제1 함수와 제2 함수 둘 모두가 동일한 데이터에 액세스 하도록 허용될 수 있다. 다른 예에서, 동일한 고객이 2개의 함수를 호출할 수 있으며, 하나의 함수는 데이터를 생성하고 다른 함수는 생성된 데이터를 소비한다. 2개의 함수는 위에서 설명된 바와 같이 키를 공유하도록 허 용될 수 있다. 따라서, MK-TME는 각각의 함수에 할당된 메모리 영역을 상이한 암호화 키로 암호화함으로써 함수를 서로 격리/ 구획화하는 데 사용될 수 있다. 그러한 접근법은 별개의 페이지 테이블을 갖는 별개의 선형 어드레스 공간에 함수를 할당할 임의의 필요성을 감소시키며, 그렇지 않았으면 OS 커널을 호출하는 것, 페이지 테이블을 전환하 는 것, 및 변환 색인 버퍼(TLB, 가상 메모리 대 물리 메모리의 최근 변환을 저장함)를 다시 채우는 것의 오버헤 드를 초래할 것이다. 아래의 설명이 키를 통해 데이터에 액세스하는 함수와 관련하여 설명되지만, 함수가 데이 터를 복호화하기 위해 기본 하드웨어(예를 들어, CPU 또는 TPM)와 협력하여 동작할 수 있음이 이해될 수 있다. 예를 들어, 함수는 CPU 및/또는 프로세서가 메모리로부터 데이터를 검색하고 데이터를 복호화하며, 이에 의해 함수가 데이터에 액세스할 수 있게 하는 방식으로 실행될 수 있다. 도 49a는 키 식별자(ID) 세트(4900a 내지 4900d)와 공유 선형 어드레스 범위에서 메모리 영역을 암호화하 는 데 사용되는 암호화 키 세트(4902a 내지 4902f) 간의 매핑을 도시한다. 예시된 예에서, 제1 키 ID(4900a)는 제1 키(4902a) 및 제2 키(4902b)에 할당되고, 제2 키 ID(4900b)는 제3 키(4902c)에 매핑되며, 제3 키 ID(4900c)는 제4 키(4902d) 및 제5 키(4902e)에 매핑되고, 제4 키 ID(4900d)는 제6 키(4902f)에 매핑된다. 따라서 예시된 매핑은 키 ID가 키에 걸쳐 재사용될 수 있게 한다. 예를 들어, 제1 키(4902a)에 대 응하는 함수가 종료되거나, 제1 키(4902a)로 암호화된 메모리 영역이 다른 방식으로 해제되면, 제1 키 ID(4900a)는 페이지 테이블을 전환하지 않고 제2 키(4902b)에 자동으로 재할당될 수 있다. 도 49b는 키 ID(kID) 다중화가 개인 영역에 대한 키 및 키 ID로 제한되지 않는 단일 어드레스 공간의 예 를 도시한다. 예시된 예에서, kID1은 함수 f1과 f3 둘 모두에서 k7에 매핑되고, kID2는 함수 f2에서 k9에 매핑 되며, kID3은 함수 f4에서 k9에 매핑된다. 이러한 후자의 두 매핑은 단일 기본 키가 다수의 키 ID로부터 매핑 될 수 있음을 예시하며, 이는 도 49a에서 반드시 분명한 것은 아니다.도 49c는 제1 함수가 제4 키(4902d)로 암호화된 제1 메모리 영역을 사용(예를 들어, 그로부터 판독 및/또는 그에 기입)하는 예를 도시한다. 예시된 예에서, 제3 키 ID(4900c)는 처음에 제4 키(4902d)에 할당된다. 제1 함수로부터 제2 함수으로의 컨텍스트 전환이 발생할 때, 제3 키 ID(4900c)는 제2 함수와 연관된 제2 메모리 영역을 암호화하는 데 사용되는 제5 키(4902e)에 자동으로 재할당된다. 특히 주목할 점은, 제1 메모리 영역 및 제2 메모리 영역이 공유 선형 어드레스 범위에 위치 된다는 것이다. 따라서, 예시된 솔루션은 OS 커널을 호출하는 것, 페이지 테이블을 전환하는 것, 및 가상 메모 리로부터 물리 메모리로의 변환을 사용하여 TLB를 다시 채우는 것의 오버헤드를 제거한다. 예시된 메모리 영역 (4906, 4910)은 또한 공유 메모리 영역을 암호화하는 데 사용되는 키(제각기, \"k9\" 및 \"k7\")에 따라 암호화될 수 있다. 더 상세하게는, 공유 메모리를 통해 통신할 필요가 있는 함수는 공유 메모리의 대응하는 영역을 암호화하는 데 사용되는 키에 대한 액세스를 공유해야 한다. 예를 들어, 함수 f1 및 f3이 공유 메모리 영역을 통해 통 신할 필요가 있는 경우, 해당 영역은 k7을 사용하여 암호화될 수 있으며 각각의 함수에서의 어떤 키 ID는 k7에 매핑될 수 있다. 키 ID는 양쪽 함수에서 동일할 수 있거나 또는 상이할 수 있다. 중요한 것은 양쪽 함수가 k7 을 사용할 수 있다는 것이다. 그렇지만, 키 ID가 물리 어드레스 비트를 통해 전달될 수 있기 때문에, 양쪽 함 수가 동일한 키 ID를 사용하도록 하는 것에는 어떤 장점이 있을 수 있다. 키 ID를 공유하는 것은 f1과 f2 간에 공유되는 메모리 영역을 커버하는 단일 선형 대 물리 어드레스 매핑만을 갖는 것을 간단하게 만든다. 그러한 접근법은 상이한 키 ID를 지원하기 위해 해당 영역을 커버하는 다수의 선형 대 물리 어드레스 매핑에 비해 TLB 오버헤드를 감소시킨다. 예를 들어, 키 ID를 다른 키에 매핑되도록 전환하는 새로운 유형의 명령어가 정의될 수 있다. 해당 명령어 유 형은 특정 코드 범위 내에서만 사용 가능하도록 제한될 수 있다(예를 들면, 범위 레지스터를 사용하여 정의됨). 해당 범위는 루트 PD 코드에 해당하도록 구성될 수 있다. 해당 명령어는 특권 소프트웨어(예를 들면, OS 또는 VMM) 및/또는 하드웨어(예를 들면, CPU 또는 TPM)에 의해 구성된 키의 리포지토리로부터 키를 선택하는 것을 허 용할 수 있다. 대안적으로, 해당 명령어는 소프트웨어 제공 키를 특권 소프트웨어에 알려져 있고 비특권 소프 트웨어로부터 액세스 가능하지 않은 위치에 있는 구조에 기록할 수 있다. 프로세서는 해당 구조로부터 각각의 함수에 대한 현재 키 ID 대 키 매핑을 검색하도록 구성될 수 있다. 예를 들어, 이것은 새로운 함수가 호출될 때마다 발생할 수 있거나, 또는 루트 PD는 프로세서로 하여금 메모리 내 구조의 내용에 기초하여 그의 내부 상 태를 업데이트하게 하는 명령어를 호출할 수 있다. 대안적으로, 단일 가상 어드레스 또는 가상 어드레스 범위를 매핑하는 것을 책임지고 있는 리프 페이지 테이블 엔트리 또는 엔트리들 내의 키 ID를 변경하는 명령어가 정의될 수 있다. 각각의 함수가 다수의 키 ID를 사용하여 메모리에 액세스할 수 있는 것은 명백하다. 각각의 메모리 액세스에 대한 적절한 키 ID를 선택하기 위해, 함수는 각각의 가상 메모리 어드레스에 태그 값을 지정할 수 있으며 해당 태그 값은 물리 메모리 어드레스에 있는 해당 키 ID에 매핑될 수 있다. 예를 들어, 도 49f는 가상 어드레스 와 물리 어드레스 간을 매핑하는 TLB/페이지 미스 핸들러를 예시한다. TLB/페이지 미스 핸 들러는 프로세서의 일부일 수 있다. 가상 어드레스의 태그 값은 어떤 방식으로든 \"키 ID\" 값에 매 핑될 수 있는 물리 어드레스와 같은 선형 어드레스 비트의 슬라이스 내의 값을 참조하는 데 사용된다. \"키 ID\"는, 예를 들어, 키 ID와 대조하여 참조되는 룩업 테이블을 통해, 어떤 방식으로든 키에 매핑될 수 있는 물리 어드레스 비트의 슬라이스 내의 값을 참조하는 데 사용된다. 페이지 테이블 엔트리는 물리 어드레스를 지 정할 수 있다. 예시된 실시예에서, TLB/페이지 미스 핸들러는 가상 어드레스를 물리 어드레스 로 변환하고, 태그 값을 변환하는 것 외에 변환 동안 태그 값을 무시할 수 있다. 태그 값은 이어서 가상 어드레스로부터 추출되어 물리 어드레스에 삽입될 수 있다. 따라서, 프로세서는 태그를 지정하는 가상 어드레스 비트의 슬라이스를 추출하여, 도 49f에 도시된 바와 같이, 키 ID를 지정하는 물리 어드레스의 슬 라이스에 삽입할 수 있다. 도 49e를 또다시 참조하면, 루트 PD에 대한 개인 데이터 영역은 적대적 함수가 그의 평문 콘텐츠에 액세스하는 것을 방지하기 위해 별개의 키를 사용하여 암호화될 수 있다. 함수 내에서 사용 가능한 어떠한 키 ID도 해당 키에 매핑되지 않는다. 각각의 함수에 대한 코드 및 루트 PD는 별개의 키를 사용하여 암호화될 수 있으며 키 ID 대 키 매핑은 각각의 함수에 그 자신의 개인 코드 영역에 대해 사용되는 키에 대한 액세스만을 부여하는 것에 의해 (예를 들면, 함수 들 간에 직접적으로 또는 함수로부터 루트 PD 내의 비인가 진입점으로의) 비인가 제어 흐름 이전을 방지하는 데도움을 주도록 구성될 수 있다. 코드 내의 제1 위치로의 점프를 통해 코드 내의 제2 위치에 도달하는 프로세스 를 포함할 수 있는 트램펄린(trampoline)이 이용될 수 있다. 루트 PD와 함수 간에 제어를 이전할 때 키 ID 대 키 매핑을 업데이트하는 트램펄린 코드 섹션은 모든 함수 및 루트 PD로부터 액세스 가능한 키 ID로부터 매핑되 는 키를 사용하여 암호화될 수 있다. 대안적으로, 각각의 함수가 트램펄린 코드를 포함하여 해당 함수의 컨텍 스트에서 실행되는 코드 전부를 암호화하기 위해 단일 키만 사용하면 되도록, 이 트램펄린 코드 섹션이 각각의 함수에 대해 복제될 수 있다. 대안적으로, 모든 함수 및 루트 PD에 대한 코드가 단일 공유 키를 사용하여 암호화할 수 있으며, 비인가 제어 흐름 이전을 방지하기 위해 다양한 제어 흐름 무결성 시행 메커니즘이 적용될 수 있다. 예를 들어, 16/024,547 은 일부 가능한 메커니즘을 설명한다. 도 49d는 루트 보호 도메인(PD, 예를 들어, 호스트 프로세서/CPU에 위치된 사용자 공간 신뢰 모니터), 복 수의 서비스별 개인 데이터 영역, 및 다수의 통신 버퍼를 갖는 공유 데이터 영역을 포함하는 단일 어드레스 공간을 도시한다. 예시된 예에서, 각각의 서비스별 개인 데이터 영역은 상이한 키(예를 들면, k*)를 사용하여 암호화된다. 일 실시예에서, 루트 PD는 커널을 호출하는 것의 오버헤드를 피하기 위해 함수들 사이를 전환할 때 매핑 업데이트를 수행한다. 따라서, 예시된 루트 PD는 키 ID 재할당의 빈도를 최소화하기 위해 상이한 키 ID를 상이한 키에 할당한다. 더 상세하게는, 루트 PD는 목적지 키 ID가 이미 목적지 함수에 대한 키에 매핑된 경우 현재 함수와 상이한 키 ID를 가진 함수로 전환될 수 있다. 일부 키 ID는 공유 메모리 통신을 구현하기 위해 다수의 함수로부터 액세스 가능할 수 있다. 도 49e는 키 ID 매핑을 업데이트하는 방법을 도시한다. 방법은 일반적으로 이미 논의된, 예를 들 어, 루트 PD(도 49d)와 같은, 루트 PD에 의해 구현될 수 있다. 더 상세하게는, 방법은 하나 이상 의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 비-일시적 머신 또는 컴퓨터 판독 가능 저장 매 체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 하드웨어 로직에서, 또는 이들의 임의의 조 합으로 구현될 수 있다. 예시된 프로세싱 블록은 키 식별자를 제1 키에 매핑하는 것을 제공하며, 여기서 제1 키는 제1 함수 및 제 1 키로 암호화된 제1 메모리 영역과 연관된다. 블록에서 제1 함수로부터 제2 함수로의 컨텍스트 전환이 탐지된다. 추가적으로, 예시된 블록은 컨텍스트 전환에 응답하여 키 식별자를 제2 키에 매핑하고, 여기 서 제2 키는 제2 함수 및 제2 키로 암호화된 제2 메모리 영역과 연관된다. 실시예에서, 제1 메모리 영역과 제2 메모리 영역은 선형 어드레스 범위를 공유한다. 따라서 예시된 방법은 OS 커널을 호출하는 것, 페이지 테이블을 전환하는 것, 및 가상 메모리로부터 물리 메모리로의 변환을 사용하여 TLB를 다시 채우는 것의 오버헤 드를 제거한다. 추가적으로, 제1 키는 제1 타깃 도메인에 대한 대칭 키일 수 있고 제2 키는 제2 타깃 도메인에 대한 대칭 키일 수 있다. 일 예에서, 제1 타깃 도메인 및/또는 제2 타깃 도메인은 신뢰 도메인의 하위 도메인이다. 그러한 경 우에, 암호화 키(\"트위크 키(tweak key)\"라고도 지칭될 수 있음)에 추가적인 \"트위크\" 값이 상이한 암호화 입력 이 각각의 하위 도메인에 대해 지정될 수 있게 하는 트위크 가능(tweakable) 암호(예를 들면, 일반 키 및 평문 또는 암호문 입력에 추가적인 트위크)와 함께 사용될 수 있다. 트위크 키를 사용하는 것은 각각의 하위 도메인 에 대해 완전히 상이한 키를 지정하는 것보다 종종 더 효율적이다. 트위크 키는, 추가적인 키가 하드웨어에 유 지되는 비용 없이, 신뢰 도메인 내에서 효과적으로 유지되는 별도의 하위 신뢰 도메인을 허용할 수 있다. 하위 도메인은 항상 \"외부\" 신뢰 도메인의 컨텍스트에서 실행되고 2개의 하위 도메인은 메모리 어드레스 공간에서 상 호 배타적이기 때문에, 트위크는 트위크 키를 생성하기 위해 기본 신뢰 도메인 키와 함께 사용될 때 추가적인 의사 랜덤성을 제공한다. 추가적으로, 신뢰 도메인이 파괴될 때, 트위크 키들 중 임의의 것에 대한 액세스 권 한을 제거함으로써 모든 하위 도메인 내용도 효과적으로 스크러빙하는 기능을 제공하는 기본 키가 파괴된다. 루트 PD로 하여금 함수를 호출하기 전에 함수로부터 하나씩 액세스 가능할 수 있는 임의의 키 ID로부터 해당 키 를 언매핑하도록 함으로써 함수가 사용하도록 인가되지 않은 키에 액세스하는 것이 방지될 수 있다. 그렇지만, 이는 불필요한 성능 오버헤드를 도입할 수 있다. 더 효율적인 대안은 어드레스 태그를 키 ID에 매핑하는 테이 블을 지원하고 그러한 테이블들 간의 전환을 위한 효율적인 동작을 지원하는 것이다. 이는 가상 메모리 어드레 스를 물리 메모리 어드레스에 매핑하는 페이지 테이블과 유사하다. 많은 수의 함수를 지원하는 데 유익할 것인 바와 같이, 키 매핑 테이블이 메모리에 저장되는 경우, 태그로부터 TKLB(tag to key ID lookaside buffer) 내 의 키 ID로의 매핑을 캐싱하는 것도 유익할 수 있으며, TKLB는 가상-물리 어드레스 매핑을 캐싱하는 데 사용되는 TLB(translation lookaside buffer)와 유사하다. 상이한 어드레스 공간들 간에 전환할 때 플러시할 필요성 을 최소화하기 위해 TLB 엔트리가 어드레스 공간 식별자(ASID)로 태깅될 수 있는 방법과 유사하게, TKLB 엔트리 도 구획 ID로 태깅될 수 있다. 예를 들어, 구획 ID는 루트 PD로부터만 액세스 가능한 레지스터에 저장될 수 있 다. 태그 대 키 ID 매핑 테이블에 대안적으로 또는 그에 추가적으로, 특정 태그 값 또는 키 ID에 대한 함수에 의한 액세스를 차단하는 메커니즘/절차가 정의될 수 있다. 예를 들어, 비트 마스크는 루트 PD로부터만 액세스 가능 한 레지스터 또는 메모리 내 비트맵에 저장될 수 있다. 루트 PD는 각각의 함수를 호출하기 전에, 함수가 사용 하도록 인가된 태그 또는 키 ID를 표시하도록, 해당 태그 마스크 구조를 업데이트할 수 있다. 예를 들어, 태그 마스크 구조의 세트된 비트는 해당 비트 위치에 대응하는 특정 태그 또는 키 ID가 함수에 의해 사용되도록 인가 되어 있음을 나타낼 수 있다. 코드 페치 및 데이터 액세스를 규제하기 위해(예를 들면, 실행 전용 메모리 퍼미 션을 시행하기 위해) 별도의 태그 마스크 구조가 정의될 수 있다. 데이터 액세스는 심지어 판독, 기입 등으로 더 세분화될 수 있으며, 각각의 액세스 유형에 대해 별도의 태그 마스크 구조가 정의된다. 페이지 테이블 엔트리 내의 태그 값을 변경하라는 명령어의 호출은 또한, 새로운 함수가 원래 태그 값과 새로운 태그 값 둘 모두를 사용하게 인가되도록 보장하기 위해, 태그 마스크 구조와 대조하여 검사될 수 있다. 명령어 는 어느 태그 마스크 구조가 검사되어야 하는지에 대한 지정자(specifier)를 받을 수 있거나, 또는 그 모두가 병렬로 검사될 수 있다. 성능 오버헤드를 추가로 감소시키기 위해, 함수가 지정된 태그에 대한 액세스를 드롭시킬 수 있게 하는 것이 유 익할 수 있다. 예를 들어, 태그 마스크 구조에서 비트 클리어만을 지원하는 명령어가 정의될 수 있다. 이 접 근법은 함수가 하위 구획을 호출하기 전에 특정 태그에 대한 액세스를 드롭시켜 해당 하위 구획이 드롭된 태그 와 연관된 메모리 영역에 액세스하는 것을 방지함으로써 해당 하위 구획을 효과적으로 샌드박싱할 수 있게 할 수 있다. 하위 구획이 해당 태그 자체에 대한 액세스를 다시 인에이블시키는 것이 방지될 것이다. 루트 PD는 태그 마스크 구조에 의해 현재 차단되어 있는 태그 값에 대한 액세스를 다시 추가하기 위해 호출될 수 있다. 대안적으로, 각각의 게이트를 통과할 때 적용될 태그 마스크 구조 값을 사용하여 호출 게이트가 확장 될 수 있다. 태그 값에 대한 액세스를 드롭시키는 기능은 JIT(Just-In-Time) 컴파일러에서 실행 전용 메모리 퍼미션을 시행 하는 데 유용할 수 있는데, 그 이유는 JIT가 코드를 메모리에 기입하고 이어서 대응하는 태그를 코드 태그 마스 크 구조에서는 여전히 인에이블된 상태로 두면서 데이터 태그 마스크 구조로부터는 드롭시킬 수 있기 때문이다. 게다가, 하드웨어는 비-루트 보호 도메인 내의 실행 가능 메모리에 대한 기입을 방지하는 정책을 임의로 시행할 수 있다. 모든 태그 값 또는 특정 태그 값 중 어느 하나에 대해 인에이블될 때, 이는 이 정책이 인에이블되어 있는 태그 값들 중 하나를 사용하여 명령어를 페치할 때 데이터 기입 태그 마스크 구조 및 코드 페치 태그 마스 크 구조 둘 모두를 검사할 수 있다. 이는 페치 태그 마스크 구조가 대응하는 태그에 대한 액세스를 차단하는 경우 또는 데이터 기입 태그 마스크 구조가 대응하는 태그에 대한 액세스를 허용하는 경우 페치를 차단할 수 있 다. 태그를 지정하기 위해 가상 어드레스 비트를 포기하는 것이 일부 애플리케이션에서 바람직하지 않을 수 있다. 대안적으로, 각각의 메모리 액세스의 유효 세그먼트가 태그 또는 키 ID를 선택하는 데 사용될 수 있다. 예를 들어, 코드 페치는 코드 세그먼트(CS)와 연관된 태그를 사용할 수 있고, 일반 데이터 액세스는 데이터 세그먼트 (DS)와 연관된 태그를 사용할 것이며, 스택 액세스는 스택 세그먼트와 연관된 태그를 사용할 것이다. 태그 연 관은 유효 세그먼트(예를 들면, CS 대 DS), 관련 세그먼트 셀렉터 값, 또는 세그먼트 레지스터 내에 포함된 다 른 정보(예를 들면, 세그먼트 디스크립터 테이블 엔트리로부터 로딩됨)에만 기초할 수 있다. 세그먼트 대 태그 연관은 레지스터 또는 메모리 내 테이블에 저장할 수 있다. 연관 데이터는 특권 소프트웨어로부터만 또는 인가 된 비특권 소프트웨어로부터도 업데이트 가능할 수 있다. 예를 들어, 해당 연관을 업데이트하는 명령어가 정의 될 수 있으며, 그의 사용은 루트 PD의 코드 범위로 제한될 수 있다. 추가 비고 및 예 예 4901은, 컴퓨팅 시스템에 의해 실행될 때, 컴퓨팅 시스템으로 하여금 키 식별자를 제1 키에 매핑하게 하고 - 제1 키는 제1 함수 및 제1 키로 암호화되는 제1 메모리 영역과 연관됨 -, 제1 함수로부터 제2 함수로의 컨텍스 트 전환을 탐지하게 하며, 컨텍스트 전환에 응답하여 키 식별자를 제2 키에 매핑하게 하는 - 제2 키는 제2 함수 및 제2 키로 암호화된 제2 메모리 영역과 연관됨 - 실행 가능 프로그램 명령어 세트를 포함하는 적어도 하나의컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 제1 메모리 영역과 제2 메모리 영역은 동일한 어드레스 공간에 있으며, 여기서 제1 키는 제1 타깃 도메인에 대한 키이고 제2 키는 제2 타깃 도메인에 대한 키이며, 여기서 제1 타깃 도메인 또는 제2 타깃 도메인 중 하나 이상은 신뢰 도메인의 하위 도메인이다. 비특권 보호 키 업데이트 예 도 50a는 다수의 함수에 대해 액세스 퍼미션이 지정될 수 있게 하는 다수의 서비스 보호 도메인(5000a 내 지 5000n)을 도시한다. 더 상세하게는, 예시된 도메인은 보호 키 레지스터(PKR, 도시되지 않음) 내의 다 수의 \"슬라이스\"에 대응하며, 각각의 슬라이스는 페이지(예를 들어, 메모리 영역)에 대한 모든 액세스를 디스에 이블시키는 비트 및 페이지에 대한 기입을 디스에이블시키는 비트를 포함한다. 루트 보호 도메인(PD)(예 를 들어, 신뢰할 수 있는 사용자 공간 모니터)은 일반적으로 실행을 위해 함수를 스케줄링하고 각각의 스케줄링 된 함수를 도메인들 중 하나(예를 들면, 보호 키 레지스터 내의 슬라이스들 중 하나)에 할당한다. 따라 서, 루트 PD는 제1 함수를 제1 도메인(5000a)(예를 들면, PKR 내의 제1 슬라이스)에 할당하고, 제2 함수 를 제2 도메인(5000b)(예를 들면, PKR 내의 제2 슬라이스)에, 기타 등등으로 할당할 수 있다. 일부 함수는 다 수의 슬라이스에 대한 액세스를 할당받을 수 있다(예를 들어, 슬라이스들 중 하나가 다수의 함수 간에 공유되는 메모리 영역에 대한 액세스를 규제하는 경우). 예시된 루트 PD는 또한 보호 키 ID를 스케줄링된 함수에 할당하며, 여기서 각각의 보호 키 ID는 함수가 액세스할 페이지를 암호화하는 데 사용되는 암호화 키에 매핑된다. 루트 PD가 실행을 위해 함수를 스케 줄링할 때, 루트 PD는 보호 키 ID가 함수에 할당될 수 있는지를 결정한다. 이와 관련하여, 함수의 개수 는 보호 키 ID의 개수(예를 들어, 예시된 예에서 \"n\")보다 클 수 있다. 함수에 할당될 수 있는 이용 가능한 보 호 키가 없는 경우, 모든 함수의 세트에 대해 보호 키 ID의 개수가 충분하지 않다. 그러한 경우에, 예시된 루 트 PD는 호스트 프로세서(예를 들어, CPU, 도시되지 않음)에 업데이트 명령어를 발행한다. 업데이 트 명령어는 새로운 보호 키 ID(PKIDnew)로 계층적 페이지 테이블 내의 엔트리를 업데이트하 도록 호스트 프로세서에 지시한다. 이와 관련하여, 업데이트 명령어는 새로운 보호 키 ID는 물론 페이지 의 선형 어드레스에 대해 어떤 값을 사용할지를 표시할 수 있다. 따라서, 호스트 프로세서는 계층적 페이지 테 이블에서 엔트리를 (예를 들어, 페이지 워크를 통해) 찾기 위해 선형 어드레스를 사용할 수 있다. 페이지 테이블 내의 엔트리는 비특권 컴포넌트에 의한 직접적인 수정으로부터 보호되는 특권 데이터 구조 이다. 따라서 예시된 접근법은 보호 키 ID 정보만이 수정되도록 허용한다. 일 실시예에서, 업데이트 명령어는 또한 페이징 구조 캐시를 클리어하도록 호스트 프로세서에 지시한다. 그러한 접근법은 오래되어 쓸모없는 보호 키 ID 값이 페이징 구조 캐시로부터 제거되도록 보장한다. 추가적으 로, 업데이트 명령어는, 이미 언급된 바와 같이, 가상 메모리 어드레스 대 물리 메모리 어드레스의 최근 변환을 저장하는 TLB(도시되지 않음)를 클리어하도록 호스트 프로세서에 지시할 수 있다. 따라서 예시된 솔루 션은 새로운 보호 키 ID로 페이지 테이블을 업데이트할 때 OS 커널을 호출할 필요가 없게 한다. 업데이트 명령어에 대한 액세스를 제한함으로써 다른 보안 문제가 해결될 수 있다. 일 예에서, 함수는 관리 런타임 함수로 제한된다. 일반적으로, 관리 런타임 환경은, 예를 들어, HTML5(Hypertext Markup Language 5, 예를 들면, HTML5 Editor's Draft 8 May 2012, W3C), Dalvik(ANDROID Open Handset Alliance/OHA), ART(ANDROID Runtime, OHA), C#(예를 들면, C# 5.0, MICROSOFT Corp., August 15, 2012), .NET(예를 들면, .NET Framework 4.5, MICROSOFT Corp., October 17, 2013), Ruby(예를 들면, Ruby 2.1.0, Y. Matsumoto, December 25, 2013), Perl(예를 들면, Perl 5.18.2, Perl.org, January 7, 2014), Python(예를 들 면, Python 3.3.3, Python Software Foundation, November 19, 2013), JAVA(예를 들면, JAVA Standard Edition 7 Update 51, ORACLE Corp., January 14, 2014) 등과 같은 고수준 솔루션일 수 있다. 따라서, 함수가 관리 런타임 환경에 의해 저스트 인 타임(JIT)으로 해석되거나 호출되기 때문에 보안이 향상된다. 추가적으로, 함수의 원자적 실행이 시행될 수 있다. 따라서 그러한 접근법은 자체 스레드를 조작하는 애플리케 이션(예를 들면, 데이터베이스, JAVA 및/또는 가비지 컬렉션 애플리케이션)에서 발생할 수 있는 동작 중의 스레 드의 보류로부터 보호한다. 업데이트 명령어에 대한 액세스를 제한하는 다른 접근법은 신뢰할 수 없는 코드를 스캔하여 해당 코드가 업데이트 명령어를 포함하지 않음을 확인하는 것, 루트 PD를 포함하는 지정된 영역 외부에서 업데 이트 명령어를 실행하려는 임의의 시도를 차단하는 것 등을 포함한다. 도 50b는 보호 키 ID를 업데이트하는 방법을 도시한다. 방법은 일반적으로 이미 논의된, 예를 들 어, 루트 PD(도 50a)와 같은, 루트 PD에 의해 구현될 수 있다. 더 상세하게는, 방법은 하나 이상 의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 비-일시적 머신 또는 컴퓨터 판독 가능 저장 매 체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 하드웨어 로직에서, 또는 이들의 임의의 조 합으로 구현될 수 있다. 예시된 프로세싱 블록은 함수 세트와 관련하여 불충분한 수의 보호 키 ID를 탐지하는 것을 제공한다. 블 록은, 불충분한 수의 보호 키 ID에 응답하여, 예를 들어, 호스트 프로세서와 같은 프로세서에 새로운 보 호 키 ID로 페이지 테이블 엔트리를 업데이트하도록 지시한다. 따라서 블록은 새로운 보호 키 ID 및 선 형 어드레스를 표시하는 업데이트 명령어를 발행하는 것을 포함할 수 있으며, 여기서 프로세서는 선형 어드레스 에 기초하여 계층적 페이지 테이블의 페이지 워크(page walk)를 수행한다. 예시된 블록은 또한 (예를 들 어, 업데이트 명령어를 통해) 프로세서에 페이징 구조 캐시 및 TLB를 클리어하도록 지시한다. 일 예에서, 함수 세트는 업데이트 명령어에 대한 비인가 액세스를 제한하기 위해 관리 런타임 함수로 제한된다. 일 실시예에서, 블록은 또한 각각의 서비스가 하나 초과의 페이지를 가질 가능성이 있기 때문에 특정 서비스에 할당된 모 든 페이지에 대한 페이지 테이블 엔트리(PTE)를 업데이트한다. 블록은 또한 함수의 원자적 실행을 시행 하는 것, 신뢰할 수 없는 코드를 스캔하여 업데이트 명령어를 포함하지 않음을 확인하는 것, 루트 PD를 포함하 는 지정된 영역 외부에서 업데이트 명령어를 실행하려는 임의의 시도를 차단하는 것 등을 포함할 수 있다. 따 라서 예시된 방법은 페이지 테이블 엔트리를 업데이트할 때 OS 커널을 호출할 필요가 없다. 추가 비고 및 예 예 5001은, 컴퓨팅 시스템에 의해 실행될 때, 컴퓨팅 시스템으로 하여금 함수 세트와 관련하여 불충분한 수의 보호 키 식별자를 탐지하게 하고, 불충분한 수의 보호 키 식별자에 응답하여 호스트 프로세서에 페이지 테이블 엔트리를 업데이트하라고 지시하게 하며 - 함수 세트는 관리 런타임 함수로 제한됨 -, 함수 세트의 원자적 실행 을 시행하게 하는 실행 가능 프로그램 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포 함한다. 예 5002는 예 5001의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 실행 가능 프로그램 명령 어는, 실행될 때, 추가로 컴퓨팅 시스템으로 하여금 호스트 프로세서에 페이징 구조 캐시를 클리어하도록 지시 하게 한다. 예 5003은 예 5001의 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함하고, 여기서 실행 가능 프로그램 명령 어는, 실행될 때, 컴퓨팅 시스템으로 하여금 호스트 프로세서에 변환 색인 버퍼를 클리어하도록 지시하게 한다. 비특권 페이지 테이블 퍼미션 업데이트 예 도 51a는 샌드박스(예를 들어, 코드 격리 툴로서 동작하는 규칙 세트)를 포함하는 프로세스를 도시 하며, 여기서 샌드박스는, 예를 들어, 사용자 모드 브로커(예를 들어, 사용자 공간 구획 관리자)와 같은 비특권 컴포넌트를, 예를 들어, 논리 어드레스 공간의 논리 블록 어드레스 및 물리 어드레스 공간 내의 물리 페이지와 같은 \"샌드박싱된\" 리소스에 액세스하지 못하도록 제한한다. 사용자 모 드 샌드박싱은 소프트웨어 지향 액세스 제어를 통해 종래 방식으로 시행될 수 있다. 예시된 예에서, 명령어 세 트 아키텍처 페이지 테이블(ISA-PT)은 논리 어드레스 공간을 물리 어드레스 공간에 매핑하고, CPU의 페이지 미스 핸들러(PMH)는 페이지 어드레스 변환이 TLB를 미스할 때(도시되지 않 음) 어드레스 변환을 수행한다. 하드웨어로 소프트웨어 기반 액세스 제어를 강화하는 것은 다중 테넌트 워크로 드가 논리 어드레스 공간을 공유하고 CPU가 추측 실행을 사용하는 OOO(out-of-order) 프로세서일 때 발생할 수 있는 \"부채널 공격\"과 관련하여 특히 유리할 수 있다. 비순차(out-of-order) 프로세싱과 관련하여, CPU는 특정 명령어를 완료하고, 다른 명령어를, 나중에 허용되지 않는 것으로 밝혀지더라도, 수행하기 시작하며, 따라서 해당 명령어들 중 어느 것도 실제 회수에 적격이 아닐 것이다. 따라서, 허용되지 않는 명령어의 결과 중 어느 것도 실제로는 임의의 변수를 수정하지 않는다. 부채 널 공격 위험은 공격자가 금지된 것으로 알고 있는 그러한 신중하게 구성된 동작으로부터 결과하는 성능 효과를 관측하는 형태로 올 수 있다. 따라서, 심지어 공격자가 위치 X에 액세스할 수 없지만, OOO로 인해 일시적으로 충분히 진행하여 위치 X에 있는 몇 비트로부터(예를 들면, *X & 0x0F를 사용하여) 값 V를 구성할 수 있는 경우, 공격자는, 예를 들어, R[V]와 같은 어떤 다른 허용 범위에 액세스할 수 있다. R[V]에 대한 액세스는, 공격자가 V의 상이한 가능한 값에서의 R[...]에 대한 액세스가 레이턴시를 검사함으로써 캐시 히트 또는 미스를 야기하는지를 검사할 수 있을 때, 나중에 성능 차이를 유발한다. 이러한 방식으로, 공격자는 실제로 해당 콘텐츠를 직 접 보도록 허용되지 않으면서 한 번에 몇 비트씩 위치 X에 있는 콘텐츠에 관해 학습한다. FaaS 워크로드는 하드웨어를 통해 시행되는 더 세분화된 액세스 제어로부터도 이득을 얻을 수 있는 다중 테넌트 워크로드의 서버 형태일 수 있다. 더 상세하게는, FaaS는 하드웨어가 더 세분화된 메모리 객체 레벨에서 액세 스 제어를 제공하는 것으로부터 이익을 얻을 수 있으며 여기서 종래의 하드웨어는 4096 바이트(4KB) 레벨(예를 들면, 페이지 레벨)로 메모리 퍼미션을 제한할 수 있다. 예시된 솔루션은 하드웨어로 시행되는 하위 페이지 퍼미션 모델을 제공하고, OS가 퍼미션 관리 및 업데이 트를 세밀한 세분성으로 사용자 모드 브로커에 위임할 수 있게 한다. 따라서, 다중 테넌트 워크로드는 동일한 논리 어드레스 공간에서 실행될 수 있으며 사용자 모드 브로커는 구획 퍼미션을 관리한다. 그렇지만 특히 주목할 점은 OS가 선형 어드레스 공간 대 물리 어드레스 공간의 매핑을 계속 제어한다는 것이다. 일반적으로, 보호 키는 논리 어드레스 공간이 프로세스 내의 복수의 하위 도메인(예를 들어, 16개 의 하위 도메인)에 걸쳐 희박한 방식으로 파티셔닝될 수 있게 한다. 종래의 보호 키는 페이지에 대한 RW(read/write) 퍼미션이 도메인마다 표현될 수 있게 하고, 시스템 호출을 하지 않고 도메인들 간의 빠른 전환 을 가능하게 한다. 예시된 예에서, 하위 페이지 퍼미션 테이블(SPPT)은 하위 페이지의 레벨(예를 들어, 4KB 페이지의 경우 128 바이트 세분성)에서 퍼미션을 지정하고, 사용자 모드 브로커에 노출된다. 예시된 사용자 모드 브로커는 SPPT와 관련하여 RWX(read/write/execute) 특권을 갖는다. 일 예에서, 사용자 모드 브 로커는 물리 어드레스 공간 내의 하위 페이지와 관련하여 하위 페이지 퍼미션을 감소시킬 수 있지 만(예를 들어, RW 액세스를 판독 전용 액세스로 다운그레이드함), 하위 페이지 퍼미션을 증가시키는 능력은 없 다(예를 들면, 판독 전용 액세스를 판독/기입 액세스로 업그레이드함). 따라서 SPPT를 통해 물리 어드레스 공간 내의 각각의 물리 페이지(또는 가상화된 환경에서의 게스트 물리 어드레스/GPA)에 대해 하위 페이지 퍼미션이 시행된다. 실시예에서, SPPT는 물리 페이지 를 퍼미션의 비트 벡터에 매핑하고, 여기서 각각의 비트는 하위 페이지 영역에 대한 기입 퍼미션에 대응 한다. EPT(extended page table) 페이지 엔트리가 특정 4KB 매핑에 대해 하위 페이지 퍼미션이 인에이블된다는 것을 지정할 때에만 CPU에 의해 SPPT를 워킹하기보다는, 예시된 솔루션은 페이지 워크를 1) ISA- PT 페이지 워크를 완료하는 것, 논리 블록 어드레스를 물리 페이지의 어드레스로 변환하는 것, 및 이어서 물리 페이지의 어드레스를 사용하여 SPPT를 워킹하는 것으로 변경한다. 따라서, 하 위 페이지 퍼미션이, EPT를 인에이블시키기 위해 VMM(virtual machine monitor)을 필요로 하지 않으면서, ISA- PT에 의해 인에이블/트리거된다. 추가적으로, SPPT는 사용자 모드 브로커에 대해 OS에 의해 생성되는 ISA-PT에서의 적 절한 매핑에 의해 사용자 모드 브로커에 노출된다. 여전히 OS에 의해 제어되는, 페이지에 대한 논 리 블록 어드레스 대 물리 어드레스 매핑이 아니라, 이러한 매핑은 사용자 모드 브로커가 퍼미션을 자유 롭게 수정할 수 있도록 허용한다. 더욱이, 새로운 명령어는 사용자 모드 브로커에 의해 SPPT를 무효화하는 데 사용될 수 있으며, 여 기서 새로운 명령어는 캐싱된 퍼미션을 플러시한다. 그러한 접근법은 퍼미션이 감소될 때 특히 유용하다. 프 로세스 컨텍스트 전환 시에 사용자 모드 브로커가 CPU들에 걸쳐 마이그레이션되는 경우 임의의 캐싱된 퍼 미션도 플러시될 수 있다. 일 예에서, 하위 페이지 퍼미션은 보안 도메인마다 고수준 프로그램 언어에 노출된 다. 추가적으로, 호출 스택 영역은 호출된 함수를 호출자 함수로부터 격리시키기 위해(예를 들면, 상대적으로 낮은 특권을 가진 호출된 함수로부터의 역 스택(reverse stack) 공격을 방지하기 위해) 사용될 수 있다. 도 51b는 하위 페이지 퍼미션을 제어하는 방법을 도시한다. 방법은 일반적으로 이미 논의된, 예를 들어, OS(도 51a)와 같은, OS에 의해 구현될 수 있다. 실시예에서, 방법은 하나 이상의 모듈에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 비-일시적 머신 또는 컴퓨터 판독 가능 저장 매체에 저장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 하드웨어 로직에서, 또는 이들의 임의의 조합으로 구현된다. 예시된 프로세싱 블록은 비특권 컴포넌트(예를 들면, 사용자 모드 브로커)가 복수의 함수에 의해 공유되 는 논리 어드레스 공간과 물리 어드레스 공간 사이의 매핑을 수정하는 것을 방지하는 것을 제공한다. 블록에서 비특권 컴포넌트는 물리 어드레스 공간과 관련하여 하위 페이지 퍼미션을 감소시키도록 허용된다. 일 예에서, 블록은 하위 페이지 퍼미션을 보안 도메인 기반으로 고수준 프로그램 언어에 노출시킨다. 이 와 관련하여, 하위 페이지 퍼미션은 태그 또는 주석으로 특정 보안 도메인에 노출될 수 있다. 실시예에서, 블록은 호출 스택 영역을 통해 복수의 함수 내의 호출된 함수를 복수의 함수 내의 호출자 함 수로부터 격리시킨다. 따라서 블록은 호출된 함수가 호출자 함수보다 낮은 특권에 있는 역 스택 공격으 로부터 보호한다. 블록(5130, 5132, 5134, 5136)은 비-순차적으로 및/또는 임의의 적절한 순서로 수행될 수 있 는 독립적인 동작이다. 추가 비고 및 예 예 5101은, 컴퓨팅 시스템에 의해 실행될 때, 컴퓨팅 시스템으로 하여금 비특권 컴포넌트가 복수의 함수에 의해 공유되는 논리 어드레스 공간과 물리 어드레스 공간 사이의 매핑을 수정하는 것을 방지하게 하고, 비특권 컴포 넌트가 물리 어드레스 공간과 관련하여 하위 페이지 퍼미션을 감소시키도록 허용하게 하며, 하위 페이지 퍼미션 을 보안 도메인 기반으로 고수준 프로그램 언어에 노출시키게 하고, 호출 스택 영역을 통해 복수의 함수 내의 호출된 함수를 복수의 함수 내의 호출자 함수로부터 격리시키게 하는 실행 가능 프로그램 명령어 세트를 포함하 는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 특권 박탈 모드 예 하드웨어 이용률 및 전반적인 비즈니스 효율성을 개선시키는 것은 통상적으로 테넌트들 간에 하드웨어 컴퓨팅 리소스를 공유함으로써 달성되며, 예는 클라우드 컴퓨팅, FaaS 등이다. 이러한 공유는 보안 및 프라이버시를 유지하기 위해 액션을 구분하고 교차 테넌트 워크로드 상호작용을 방지하는 프로세스를 필요로 할 수 있다. 따 라서, 구분된 액션은 사전 제한될(예를 들면, 국한될) 필요가 있는 임의의 것을 지칭한다 - 일반적으로 이 국한 은, 예를 들어, 샌드박스, VM(virtual machine) 등과 같은 어떤 종류의 격리를 통해 \"에워싸인(hemmed in)\" 코 드에 적용된다. VM, 프로세스, (예를 들면, \"컨테이너\"에 대한) 네임스페이스 및 관리 런타임이 국한 문제를 해결할 수 있지만, 시작 시간, 호출 성능 및/또는 메모리 오버헤드와 관련하여 상당한 개선의 여지가 있어, 적용 가능성 및 배포의 밀도를 제한한다. NFV(Network Functions Virtualization)와 같은 일부 애플리케이션은 나노초 내지 마이크로초 범위의 레이턴시 를 요구할 수 있는 반면, 종래의 FaaS 구현은 콜드 스타트 컨테이너를 호출할 때 수십 밀리초 정도의 레이턴시 를 유발할 수 있다. 전형적으로 그러한 애플리케이션에서 사용되는 폴 모드(poll-mode)는 다른 일련의 문제 - 격리와 연관된 밀도 및 메모리 오버헤드 - 가 있다. 실제로, VM 및 컨테이너는 상대적으로 많은 양의 메모리 - 수 MB 내지 수 GB - 를 여전히 사용할 수 있다. 따라서, 서버 상에서의 인스턴스의 양은 전형적으로 제한된다. 더욱이, 폴 모드 실행은 초과 구독의 경우 잘 작동하지 않을 수 있다. 이와 달리, 완전 실행 접근법은 전형적 으로 (예를 들면, 함수 호출들 사이의 공유 메모리 공간으로 인해) 단일 애플리케이션 내에서만 적용 가능하거 나, 또는 양호한 격리를 갖는 FaaS 모델에 매핑되는 경우, 높은 레이턴시를 가질 것이다. 극단적인 경우에, 모든 애플리케이션이 로컬로도 원격으로도 실행되는 함수(예를 들면, OS, 플랫폼 및 인프라스 트럭처 서비스를 포함함)로 분해될 때, 성능에 대한 수요는 서버당 초당 수억 개의 호출에 도달할 수 있다 - 어 떤 것은 종래에 네이티브 코드 및 CALL 명령어를 통해서만 도달 가능함 -. 특권 박탈 모드라고 지칭되는 최근 개발된 기술은 다수의 메모리 \"세그먼트\"로 구성된 어드레스 공간을 공유하 면서 샌드박싱된 환경에서 함수를 실행하는 프레임워크를 제공한다. 샌드박싱은 함수가 세그먼트를 변경하는 것을 방지하고, 코드 세그먼트에 의해 정의되는 샌드박스 내로 국한되도록 제어 이전을 제한한다. LDT(local descriptor table)는 메모리 세그먼트 디스크립터를 포함하는 메모리 테이블이다. 각각의 세그먼트 디스크립터 는 셀렉터(예를 들면, 인덱스) 및, 예를 들어, 베이스 어드레스, 크기, 액세스 특권 등과 같은 다양한 속성을 포함한다. 메모리 세그먼트를 참조하기 위해, 함수는 셀렉터를 세그먼트 레지스터에 로딩하고, 이는 디스크립 터 속성이 LDT로부터 호스트 프로세서로 전송되게 한다. LDT에 대한 후속 수정은 일반적으로, 세그먼트 레지스 터가 재로딩되지 않는 한, 효과적이지 않다. 특권 박탈 모드 접근법은 수정된 세그먼트 디스크립터의 사용에 의존하며, 여기서 베이스 어드레스는 범위의 하한으로서 취급된다. 그렇지만 이용 가능한 세그먼트 디스크립터 의 개수가 제한되어 있기 때문에, LDT에 대한 동적 업데이트가 필요할 수 있다. 추가적으로, 낮은 개수의 세그 먼트 레지스터는 제한된 수의 메모리 범위만이 사용되게 할 수 있어, 모든 파라미터 및 결과를 연속 메모리 영역에 배치하도록 호출자를 압박한다. 본 명세서에 설명된 기술은 특권 박탈 모드를, 예를 들어, EIC(encoded inline capability) 정보와 같은 능력 정보로 확장하고 어드레스 공간을 공유하면서 다수의 메모리 영역의 사용을 가능하게 한다. 더 상세하게는, 특 권 박탈 모드의 구성은 메모리 액세스에 대한 EIC 시맨틱스를 시행하고, 스택 액세스를 커버하는 EIC에 대한 ABI(application binary interface)를 정의하며, 특권 박탈된 코드로부터의 시스템/외부 호출의 핸들링을 정의 하도록 구현된다. 도 52a는 공유 메모리(예를 들어, 메모리 세그먼트)에 액세스하려고 시도하는 함수에 대한 특권 박탈 모드 경로 를 도시한다. 예시된 예에서, EIC 정보(5202a 내지 5202c)의 하나 이상의 능력 제약(예를 들어, 시맨틱스)이 시도된 메모리 액세스에 대해 시행된다. EIC 정보는 MAC(5202a), 경계 정보(5202b) 및 포인 터(5202c)를 포함한다. 일 예에서, MAC(5202a)는 경계 정보(5202b)에 기초한 키잉된 단방향 해시 함수에 의해 생성된 태그이며, MAC(5202a)를 생성하는 데 사용되는 비밀 키는 보호된 영역에(예를 들면, 호스트 프로세서 상 에) 위치된다. 따라서, MAC(5202a)는 EIC 정보가 명시된 송신자로부터 왔으며 변경되지 않았음을 확인하 는 데 사용된다. 따라서, 예시된 MAC(5202a)는 또한 비밀 키를 소유한 검증자가 EIC 정보에 대한 임의의 변경을 탐지할 수 있게 함으로써 EIC 정보의 무결성 및 진정성 둘 모두를 보호한다. 일 예에서, 포인터 (5202c)는 경계 정보(5202b)에 의해 정의된 메모리 영역을 참조한다. 따라서, 특권 박탈된 함수에 의해 메모리 액세스가 시도될 때, MAC(5202a)는 액세스에서 사용되는 포인터가 적법이고 경계 정보(5202b)에 의해 정의된 메 모리 영역 내에 있음을 확인하기 위해 검사된다. 일 예에서, 세그먼트 디스크립터는 또한 스택 액세스를 커버하는 EIC에 대한 ABI를 정의하고 특권 박탈된 코드 로부터의 시스템/외부 호출의 핸들링을 정의하도록 수정된다. ABI는 호출자 및 피호출자가 특정 거동 임무를 따르는 호출 규약이다. 본 명세서에서 사용된 바와 같이, ABI는 피호출자의 세그먼트 레지스터 또는 능력이 어 떻게 로딩되는지 및 호출에서 호출자의 세그먼트 레지스터 또는 능력이 어떻게 언로딩되는지를 지정한다. 유사 하게, ABI는 피호출자가 완료되고 호출자가 피호출자가 완료된 시점으로부터 재개할 필요가 있는 경우 각자의 로딩/언로딩이 역으로 수행되는 방식을 지정한다. 일 실시예에서, ABI는 포인터에 대해 단일 비트 필드를 포함 하는 일반 포인터와 구별하기 위해 메모리에 대한 모든 참조가 EIC로서 전달되고 특정 이진 포맷(예를 들면, 비 트 필드- MAC/경계/포인터로 구성됨)으로 피호출자의 스택에 배치되는 것을 말한다. 예시된 예에서, 특권 모드 경로는 EIC 정보의 능력 제약을 우회한다. 도 52b는 하위 페이지 퍼미션을 제어하는 방법을 도시한다. 실시예에서, 방법은 하나 이상의 모듈 에서 RAM, ROM, PROM, 펌웨어, 플래시 메모리 등과 같은 비-일시적 머신 또는 컴퓨터 판독 가능 저장 매체에 저 장된 로직 명령어 세트로서, 예를 들어, PLA, FPGA, CPLD와 같은 구성 가능한 로직에서, 예를 들어, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 사용하는 고정 기능 하드웨어 로직에서, 또는 이들의 임의의 조합으로 구현 된다. 예시된 프로세싱 블록은 함수의 호출을 탐지하고, 여기서 블록에서 함수가 특권 박탈 모드에서 호 출되는지에 대한 결정이 이루어진다. 이미 언급된 바와 같이, 특권 박탈 모드는 다수의 메모리 세그먼트로 구 성된 어드레스 공간을 공유하면서 샌드박싱된 환경에서 함수를 실행하는 프레임워크를 제공할 수 있다. 함수가 특권 박탈 모드에서 호출되는 것에 응답하여, 예시된 블록은 공유 메모리 공간에 액세스하려는 함수에 의 한 시도에 대해 하나 이상의 능력 제약을 시행한다. 일 예에서, 블록은, 메모리 액세스를 위해 EIC 시맨 틱스를 시행하는 것 외에도, 스택 액세스를 커버하는 EIC에 대한 ABI를 정의하는 것 및 특권 박탈된 코드로부터 의 시스템/외부 호출의 핸들링을 정의하는 것을 포함한다. 따라서 예시된 방법은 서버당 초당 매우 많은 수의 호출을 포함하는 FaaS 시스템에서 제한된 수의 이용 가능한 세그먼트 디스크립터 및 적은 수의 세그먼트 레지스 터에 대한 문제를 해결한다. 코드 세그먼트 디스크립터 및 코드 세그먼트 레지스터는 각각의 디스크립터를 로딩할 때 EIC 인증 키 레지스터 에 자동으로 로딩되는 능력 인증 키를 저장하도록 확장될 수 있다. 대안적으로, 코드 세그먼트 셀렉터는 EIC 인증 스킴 및/또는 알고리즘에 대한 입력으로서(예를 들어, MAC 생성 절차에 대한 다른 입력과 연결되거나 암호 트위크로서) 사용될 수 있다. 대안적으로, EIC 인증 스킴 및/또는 알고리즘에 대한 능력 인증 키 또는 다른 입력은 다른 세그먼트 레지스터 (예를 들면, 데이터 세그먼트/DS, 추가 세그먼트/ES, 일반 세그먼트(FS, GS) 또는 스택 세그먼트/SS)로부터 도 출될 수 있다.추가 비고 및 예 예 5201은, 컴퓨팅 시스템에 의해 실행될 때, 컴퓨팅 시스템으로 하여금 함수의 호출을 탐지하게 하고, 함수가 특권 박탈 모드에서 호출되는 것으로 결정하게 하며, 함수가 특권 박탈 모드에서 호출되는 것에 응답하여, 공유 메모리 공간에 액세스하려는 함수에 의한 시도에 대해 하나 이상의 능력 제약을 시행하게 하는 실행 가능 프로 그램 명령어 세트를 포함하는 적어도 하나의 컴퓨터 판독 가능 저장 매체를 포함한다. 용어 \"결합된\"은 본 명세서에서 문제의 컴포넌트들 사이의, 직접적인 또는 간접적인, 임의의 유형의 관계를 지 칭하는 데 사용될 수 있고, 전기적, 기계적, 유체, 광학적, 전자기적, 전기기계적 또는 다른 연결에 적용될 수 있다. 그에 부가하여, 용어 \"제1\", \"제2\" 등은 본 명세서에서 논의를 용이하게 하기 위해서만 사용될 수 있으 며, 달리 언급되지 않는 한 특정의 시간적 또는 연대기적 의미를 지니지 않는다. 본 출원에서 그리고 청구항에서 사용되는 바와 같이, 용어 “~ 중 하나 이상”에 의해 연결(join)되는 항목들의 리스트는 열거된 용어들의 임의의 조합을 의미할 수 있다. 예를 들어, 문구 \"A, B 또는 C 중 하나 이상\"은 A; B; C; A 및 B; A 및 C; B 및 C; 또는 A, B 및 C를 의미할 수 있다. 본 기술 분야의 통상의 기술자는 전술한 설명으로부터 실시예의 광범위한 기술이 다양한 형태로 구현될 수 있음 을 이해할 것이다. 따라서, 실시예가 그의 특정 예와 관련하여 설명되었지만, 다른 수정이 도면, 명세서 및 이 하의 청구범위를 살펴볼 때 숙련된 실무자에게 명백해질 것이기 때문에, 실시예의 진정한 범위가 그렇게 제한되 어서는 안된다. 이해될 것인 바와 같이, 본 명세서에서 사용되는 바와 같은 컴퓨터 및/또는 컴퓨팅 디바이스는 CPU, GPU, FPGA, ASIC 등을 포함하고 이에 제한되지 않는 다양한 회로를 포함할 수 있다.도면 도면1 도면2a 도면2b 도면3 도면4 도면5 도면6a 도면6b 도면6c 도면7a 도면7b 도면7c 도면8a 도면8b 도면8c 도면8d 도면8e 도면8f 도면8g 도면9a 도면9b 도면9c 도면10a 도면10b 도면10c 도면11a 도면11b 도면11c 도면12 도면13a 도면13b 도면13c 도면14a 도면14b 도면14c 도면15a 도면15b 도면16a 도면16b 도면16c 도면16d 도면16e 도면17a 도면17b 도면18a 도면18b 도면18c 도면19a 도면19b 도면19c 도면20a 도면20b 도면20c 도면20d 도면21a 도면21b 도면21c 도면21d 도면22 도면23 도면24a 도면24b 도면25a 도면25b 도면26a 도면26b 도면26c 도면26d 도면26e 도면27a 도면27b 도면28a 도면28b 도면29a 도면29b 도면30a 도면30b 도면31a 도면31b 도면31c 도면31d 도면31e 도면32a 도면32b 도면32c 도면32d 도면32e 도면33a 도면33b 도면34a 도면34b 도면35a 도면35b 도면36a 도면36b 도면37a 도면37b 도면37c 도면38a 도면38b 도면38c 도면39a 도면39b 도면39c 도면40a 도면40b 도면41a 도면41b 도면41c 도면41d 도면42a 도면42b 도면43a 도면43b 도면43c 도면43d 도면43e 도면44a 도면44b 도면44c 도면45a 도면45b 도면46a 도면46b 도면47a 도면47b 도면47c 도면48a 도면48b 도면48c 도면48d 도면48e 도면48f 도면49a 도면49b 도면49c 도면49d 도면49e 도면49f 도면50a 도면50b 도면51a 도면51b 도면52a 도면52b"}
{"patent_id": "10-2020-7037419", "section": "도면", "subsection": "도면설명", "item": 1, "content": "실시예의 다양한 장점이 이하의 명세서 및 첨부된 청구항을 읽고 이하의 도면을 참조함으로써 본 기술 분야의 통상의 기술자에게 명백해질 것이다. 도 1은 실시예에 따른 FaaS 컴퓨팅 환경의 예의 예시이다; 도 2a는 일반화된 기존 서버리스 서비스의 예를 예시한다; 도 2b는 실시예에 따른 FaaS 시스템 컴포넌트 세트의 예의 블록 다이어그램이다; 도 3은 실시예에 따른 FaaS 서버 구성의 예의 블록 다이어그램이다; 도 4는 실시예에 따른 향상된 FaaS 시스템의 예의 블록 다이어그램이다; 도 5는 실시예에 따른 향상된 FaaS 시스템의 서브시스템의 예의 블록 다이어그램이다; 도 6a는 실시예에 따른 리소스 할당 및 제어를 위한 향상된 FaaS 아키텍처의 예의 블록 다이어그램이다; 도 6b는 실시예에 따른 향상된 FaaS 아키텍처를 사용하여 사용자 레벨 능력을 관리하는 것의 플로차트이다; 도 6c는 실시예에 따른 향상된 FaaS 아키텍처를 사용하여 사용자 레벨 능력을 관리하는 것의 플로차트이다; 도 7a는 실시예에 따른 컨테이너에서 다양한 vPMU(virtual power performance monitoring unit) 이벤트를 모니 터링하기 위한 예시적인 FaaS 컴퓨트 노드의 블록 다이어그램이다; 도 7b는 실시예에 따른 vPMU 버퍼의 예의 블록 다이어그램이다; 도 7c는 실시예에 따른 함수의 성능을 모니터링하는 방법의 예의 플로차트이다; 도 8a는 실시예에 따른 전자 프로세싱 시스템의 예의 블록 다이어그램이다; 도 8b는 실시예에 따른 반도체 패키지 장치의 예의 블록 다이어그램이다; 도 8c는 실시예에 따른 다수의 FaaS 함수 사이에서 메모리를 공유하는 예의 플로차트이다; 도 8d는 실시예에 따른 다수의 FaaS 함수 사이에서 메모리를 공유하는 예의 플로차트이다; 도 8e는 실시예에 따른 다수의 FaaS 함수 사이에서 메모리 공유를 제공하는 FaaS 시스템의 다른 예의 블록 다이 어그램이다; 도 8f는 실시예에 따른 2개의 FaaS 함수 사이의 통신을 용이하게 하기 위한 함수 색인 버퍼(function look- aside buffer)의 다른 예의 블록 다이어그램이다; 도 8g는 실시예에 따른 분산된 FaaS 함수를 오케스트레이션하기 위한 FaaS 시스템의 다른 예의 블록 다이어그램 이다; 도 9a는 실시예에 따른 서비스형 함수의 컨테이너 런 어헤드 추측 실행(container run ahead speculative execution)을 제공하는 방법의 예의 플로차트이다;도 9b는 실시예에 따른 컨테이너 런 어헤드 추측 실행을 지원하는 FaaS 시스템의 다른 예의 블록 다이어그램이 다; 도 9c는 실시예에 따른 이미지 회전 함수의 컨테이너 런 어헤드 추측 실행을 지원하는 FaaS 시스템의 다른 예의 블록 다이어그램이다; 도 10a는 실시예에 따른 피드백 지원을 갖는 서비스형 함수를 제공하는 방법의 다른 예의 플로차트이다; 도 10b는 실시예에 따른 피드백 지원을 갖는 FaaS 시스템의 다른 예의 블록 다이어그램이다; 도 10c는 실시예에 따른 피드백 지원을 갖는 FaaS 시스템의 다른 예의 블록 다이어그램이다; 도 11a는 실시예에 따른 인스턴스화를 위한 다수의 옵션을 갖는 함수의 예의 예시적인 다이어그램이다; 도 11b는 실시예에 따른 인스턴스화를 위한 다수의 옵션을 갖는 함수를 지원하는 FaaS 시스템의 다른 예의 블록 다이어그램이다; 도 11c는 실시예에 따른 인스턴스화를 위한 다수의 옵션을 갖는 함수에 대한 서비스형 함수를 제공하는 방법의 다른 예의 플로차트이다; 도 12는 실시예에 따른 스케줄러를 갖는 FaaS 시스템의 다른 예의 블록 다이어그램이다; 도 13a는 실시예에 따른 FaaS 서버 아키텍처의 예의 블록 다이어그램이다; 도 13b는 실시예에 따른 향상된 FaaS 스케줄링 프로세스의 예이다; 도 13c는 실시예에 따른 함수의 플로차트이다; 도 14a 및 도 14b는 실시예에 따른 향상된 함수 실행 시퀀스의 예이다; 도 14c는 실시예에 따른 다수의 동작을 갖는 함수를 스케줄링하는 것의 플로차트이다; 도 15a는 실시예에 따른 FaaS를 위한 메모리 스토리지 향상된 컴퓨팅 아키텍처의 예의 블록 다이어그램이다; 도 15b는 실시예에 따른 FaaS 플랫폼의 컨테이너 및 함수에 대한 메모리 할당의 플로차트이다; 도 16a는 실시예에 따른 함수 실행을 위한 배칭된(batched) 함수 요청의 예이다; 도 16b는 실시예에 따른 반도체 패키지 장치의 예의 예시이다; 도 16c는 실시예에 따른 함수 요청을 배칭(batching)하는 것의 플로차트이다; 도 16d는 실시예에 따른 2개 이상의 함수 요청을 배칭하는 것의 플로차트이다; 도 16e는 실시예에 따른 함수 요청을 스케줄링하는 것의 플로차트이다; 도 17a는 실시예에 따른 리던던트 함수 구현의 예이다; 도 17b는 실시예에 따른 리던던트 함수 구현의 플로차트이다; 도 18a는 실시예에 따른 FaaS에 대한 스케줄러를 표현하는 함수 생성 그래프를 예시한다; 도 18b는 실시예에 따른 스케줄러를 갖는 향상된 FaaS 시스템을 예시한다; 도 18c는 실시예에 따른 FaaS 함수 구현의 플로차트이다; 도 19a는 실시예에 따른 공통 데이터 스토리지를 갖는 향상된 FaaS 아키텍처의 예이다; 도 19b는 실시예에 따른 예시적인 FaaS 데이터 저장의 플로차트이다; 도 19c는 실시예에 따른 FaaS 보안 프로토콜을 구현하고 시행하는 예시적인 방법의 플로차트이다; 도 20a는 실시예에 따른 전용 FaaS 캐시를 갖는 향상된 FaaS 서버 아키텍처의 예의 블록 다이어그램이다; 도 20b는 실시예에 따른 범용 캐시를 갖는 향상된 FaaS 서버 아키텍처의 예의 블록 다이어그램이다; 도 20c는 실시예에 따른 데이터 객체의 데이터 볼륨을 예시하는 그래프의 예이다; 도 20d는 실시예에 따른 예시적인 향상된 함수 리소스 관리의 플로차트이다;도 21a는 실시예에 따른 소프트웨어 스레드를 우선순위화하는 방법의 예이다; 도 21b 및 도 21c는 예시적인 실시예에 따른 향상된 FaaS 아키텍처에서 페이지 레벨 QoS를 제공하기 위한 페이 지 테이블에서 태스크와 서비스 클래스(CLOS) 사이의 상호작용을 예시한다; 도 21d는 예시적인 실시예에 따른 페이지 레벨 QoS에 관련된 다른 아키텍처를 예시한다; 도 22는 실시예에 따른 FaaS 서비스와 관련하여 결정성(determinism) 및 정확성(accuracy)을 제공하기 위한 예 시적인 아키텍처를 예시한다; 도 23은 실시예에 따른 과금 목적으로 리소스 사용량을 계산하는 방법의 예이다; 도 24a는 실시예에 따른 분산 컴퓨팅 환경의 예의 블록 다이어그램이다; 도 24b는 실시예에 따른 서비스형 함수를 제공하는 다른 예의 플로차트이다; 도 25a는 실시예에 따른 다수의 함수 사이에서 메모리 재사용을 가능하게 하는 FaaS 시스템의 예의 블록 다이어 그램이다; 도 25b는 실시예에 따른 서비스형 함수를 제공하는 방법의 다른 예의 플로차트이다; 도 26a는 실시예에 따른 서비스형 함수를 제공하는 다른 예의 플로차트이다; 도 26b는 실시예에 따른 함수 호출 그래프의 예시적인 다이어그램이다; 도 26c는 실시예에 따른 함수를 분할하는 것의 예시적인 다이어그램이다; 도 26d는 실시예에 따른 함수 호출 그래프의 다른 예시적인 다이어그램이다; 도 26e는 실시예에 따른 함수들을 병합하는 것의 예시적인 다이어그램이다; 도 27a는 실시예에 따른 다수의 함수에 의해 공유되는 메모리를 갖는 향상된 FaaS 시스템의 다른 예의 블록 다 이어그램이다; 도 27b는 실시예에 따른 다수의 함수에 의해 공유되는 메모리를 갖는 향상된 FaaS 시스템의 다른 예의 블록 다 이어그램이다; 도 28a는 실시예에 따른 서비스형 함수를 제공하는 것의 플로차트이다; 도 28b는 실시예에 따른 FaaS 시스템의 다른 예의 블록 다이어그램이다; 도 29a는 실시예에 따른 컨테이너 반전 특징을 지원하는 서비스형 함수를 제공하는 것의 플로차트이다; 도 29b는 실시예에 따른 컨테이너 반전 특징을 지원하는 FaaS 시스템의 예의 블록 다이어그램이다; 도 30a는 실시예에 따른 개선된 함수 실행 성능을 위한 연속 애플리케이션(continuation application)을 갖는 서비스형 함수를 제공하는 것의 플로차트이다; 도 30b는 실시예에 따른 개선된 함수 실행 성능을 위한 연속 애플리케이션을 갖는 FaaS 시스템의 예의 블록 다 이어그램이다; 도 31a 및 도 31b는 실시예에 따른 FaaS에 대한 향상된 컨테이너 구성 및 캐시 관리의 예이다; 도 31c는 실시예에 따른 예시적인 캐시 축출의 플로차트이다; 도 31d는 실시예에 따른 다른 예시적인 캐시 축출의 플로차트이다; 도 31e는 실시예에 따른 캐싱된 데이터 객체에 대한 생존 시간(time-to-live)을 결정하는 것의 플로차트이다; 도 32a 및 도 32b는 실시예에 따른 향상된 함수 분배의 예이다; 도 32c 및 도 32d는 실시예에 따른 향상된 함수 분배의 예이다; 도 32e는 실시예에 따른 함수 분배의 플로차트이다; 도 33a는 실시예에 따른 FaaS의 함수의 향상된 함수 구조의 예이다; 도 33b는 실시예에 따른 향상된 함수 구조로부터의 모니커 식별의 플로차트이다;도 34a는 실시예에 따른 함수 호출의 빈도에 따라 호출 그래프를 사용하여 함수를 프리페칭하는 것의 예의 예시 이다; 도 34b는 실시예에 따른 FaaS 함수의 실행을 향상시키기 위한 방법의 예이다; 도 35a는 실시예에 따른 현재 함수의 선행 함수를 예시하는 블록 다이어그램이다; 도 35b는 실시예에 따른 프리커서 함수에 기초하여 FaaS 함수를 실행하는 방법의 예이다; 도 36a는 실시예에 따른 함수가 실행될 확률에 기초하여 컨테이너의 웜 상태(warmth)를 유지하는 것의 예를 예 시한다; 도 36b는 실시예에 따른 웜 컨테이너(warm container)로부터 FaaS 함수를 실행하는 방법의 예이다; 도 37a는 실시예에 따른 크기에 기초한 적응적 메모리 계층화(adaptive memory tiering)를 예시하는 블록 다이 어그램이다; 도 37b는 실시예에 따른 사용량에 기초한 적응적 메모리 계층화를 예시하는 블록 다이어그램이다; 도 37c는 실시예에 따른 함수를 적응적으로 메모리 계층화하는 방법의 예이다; 도 38a는 실시예에 따른 FaaS에 대한 고속 클래스 로딩을 위한 환경을 예시한다; 도 38b는 실시예에 따른 향상된 FaaS 컴퓨팅 환경에서 함수를 실행하는 방법의 예이다; 도 38c는 실시예에 따른 향상된 FaaS 컴퓨팅 환경에서 함수를 실행하는 방법의 예이다; 도 39a는 실시예에 따른 시간순 및 클라우드 스케일(수평) 피드백 둘 모두의 연속적인 적용을 용이하게 하는 FaaS 환경을 예시한다; 도 39b는 실시예에 따른 각각의 함수 유형의 상이한 벡터를 예시한다; 도 39c는 실시예에 따른 적절한 리소스를 사전 예약하는 방법의 예이다; 도 40a는 실시예에 따른 코드 최적화에 관련된 상이한 특성을 예시한다; 도 40b는 실시예에 따른 향상된 FaaS 컴퓨팅에서 함수를 실행하는 방법의 예이다; 도 41a는 실시예에 따른 수요 핑거프린트와 함수 실행 사이의 관계를 보여주는 그래프이다; 도 41b는 실시예에 따른 리소스 관리자의 동작을 예시한다; 도 41c는 실시예에 따른 수요 핑거프린트를 사용하는 효율적인 FaaS 리소스 관리 방법의 예이다; 도 41d는 실시예에 따른 수요 핑거프린트의 예이다; 도 42a는 실시예에 따른 함수 클라이언트와 함수 실행 엔진 사이의 통신의 예이다; 도 42b는 실시예에 따른 불투명 마커를 사용하여 FaaS 함수를 실행하는 방법의 예이다; 도 43a는 실시예에 따른 함수의 컨텍스트를 고유하게 식별해주는 토큰에 기초한 서버 위치 선택의 예의 예시이 다; 도 43b는 실시예에 따른 함수 호출을 관리하는 것의 플로차트이다; 도 43c는 실시예에 따른 함수 호출을 관리하는 상세한 방법의 플로차트이다; 도 43d는 함수 호출의 위치가 요청 소스에 기초하여 선택되는 FaaS 시스템의 예의 블록 다이어그램이다; 도 43e는 함수 호출의 위치가 함수 호출 트리에 기초하여 선택되는 FaaS 시스템의 예의 블록 다이어그램이다; 도 44a는 실시예에 따른 교차 도메인 제어 전환(cross-domain control transfer)의 예의 블록 다이어그램이다; 도 44b는 실시예에 따른 원격 프로시저 피호출자(callee)를 동작시키는 것의 플로차트이다; 도 44c는 실시예에 따른 원격 프로시저 호출자(caller)를 동작시키는 것의 플로차트이다; 도 45a는 실시예에 따른 애플리케이션 계층 함수가 데이터 평면 함수와 공존하는 FaaS 아키텍처의 예의 블록 다이어그램이다; 도 45b는 실시예에 따른 런타임 프레임워크를 동작시키는 것의 플로차트이다; 도 46a는 실시예에 따른 맞춤형 응답 객체 솔루션의 예의 예시이다; 도 46b는 실시예에 따른 응답 객체를 호출 인스턴스에 맞춤화하는 것의 플로차트이다; 도 47a는 실시예에 따른 파라미터 마샬링 솔루션의 예의 예시이다; 도 47b는 실시예에 따른 플랫폼들에 걸쳐 함수를 균일하게 호출하는 하이 레벨 아키텍처의 예의 다이어그램이다; 도 47c는 실시예에 따른 함수 파라미터를 마샬링하는 것의 플로차트이다; 도 48a는 실시예에 따른 함수들 사이의 능력 정보의 전송의 예의 블록 다이어그램이다; 도 48b는 실시예에 따른 인코딩된 인라인 능력(encoded inline capability)(EIC) 정보의 예의 블록 다이어그램 이다; 도 48c는 실시예에 따른 하드웨어 큐 관리자의 예의 블록 다이어그램이다; 도 48d는 실시예에 따른 하드웨어 큐 관리자를 동작시키는 것의 플로차트이다; 도 48e는 실시예에 따른 능력을 인큐잉(enqueueing)하는 것의 플로차트이다; 도 48f는 실시예에 따른 능력을 디큐잉(dequeuing)하는 것의 플로차트이다; 도 49a는 실시예에 따른 키 식별자와 키 사이의 매핑의 예의 예시이다; 도 49b는 실시예에 따른 단일 어드레스 공간의 예의 블록 다이어그램이다; 도 49c는 실시예에 따른 컨텍스트 전환(context switch)의 예의 블록 다이어그램이다. 도 49d는 실시예에 따른 키 식별자 맵 업데이트의 예의 블록 다이어그램이다; 도 49e는 실시예에 따른 키 식별자 매핑을 업데이트하는 것의 플로차트이다; 도 49f는 가상 어드레스와 물리적 어드레스 사이를 매핑하는 변환 색인 버퍼(translation look-aside buffer)/ 페이지 미스 핸들러(page miss handler)의 예의 블록 다이어그램이다; 도 50a는 실시예에 따른 보호 키 식별자 업데이트 명령어의 예의 블록 다이어그램이다; 도 50b는 실시예에 따른 보호 키 식별자를 업데이트하는 것의 플로차트이다; 도 51a는 실시예에 따른 하위 페이지 퍼미션을 수정하도록 허용되는 비특권 컴포넌트의 예의 블록 다이어그램이 다; 도 51b는 실시예에 따른 하위 페이지 퍼미션을 제어하는 것의 플로차트이다; 도 52a는 실시예에 따른 능력 정보 제약을 포함하는 특권 박탈 모드 경로(deprivileged mode path)의 예의 예시 이다; 도 52b는 실시예에 따른 메모리 액세스를 제어하는 것의 플로차트이다."}
