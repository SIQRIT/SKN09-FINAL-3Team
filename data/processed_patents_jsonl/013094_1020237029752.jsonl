{"patent_id": "10-2023-7029752", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0145096", "출원번호": "10-2023-7029752", "발명의 명칭": "신경망 기반 픽처 프로세싱에서의 보조 정보의 독립적 위치결정", "출원인": "후아웨이 테크놀러지 컴퍼니 리미티드", "발명자": "솔로비예프 티모페이 미카일로비치"}}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 스테이지(i+r) 및 제2 스테이지(i)를 포함하는 2개 이상의 스테이지(K 내지 0)를 포함하는 신경망(1786)을이용하여 비트스트림(1772)으로부터의 하나 이상의 픽처의 특징 데이터를 프로세싱하기 위한 방법으로서,상기 비트스트림(1772)에 기초하여 제1 데이터(1760)를 획득하는 단계,상기 신경망(1786)을 이용하여 상기 제1 데이터(1760)를 프로세싱하는 단계 - 상기 프로세싱하는 단계는, 상기신경망의 상기 제2 스테이지로부터, 상기 신경망(1786)에 의해 이전에 프로세싱된 데이터에 기초하는 제2 데이터(1765)를 획득하는 것, 상기 신경망의 상기 제1 스테이지에 대한 입력을 생성하기 위하여 상기 제1 데이터(1760)를 상기 제2 데이터(1765)와 함께 이용하는 것을 포함하고, 상기 제1 스테이지(i+r)는 신경망(1765)의 특징 데이터 프로세싱에서 상기 제2 스테이지(i)에 선행함 -;상기 프로세싱의 결과(1702)를 출력하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 데이터(1760)는 상기 신경망(1786)의 상기 특징 데이터 프로세싱에서 상기 제1 스테이지 및 상기 제2스테이지에 선행하거나 상기 제1 스테이지와 동일한 상기 신경망(1786)의 제3 스테이지에서 획득되는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 데이터(1760)는 예측 오차를 나타내고, 상기 제2 데이터(1765)는 예측을 나타내는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 예측은,- 상기 제2 스테이지에서 상기 신경망(1786)에 의해 출력된 특징 데이터인 참조 특징 데이터를 획득하는 것,- 비트스트림(1790)에 기초하여, 상기 참조 특징 데이터에 관련된 모션 정보 또는 공간적 정보를 포함하는 예측정보를 획득하는 것,- 상기 참조 특징 데이터 및 상기 예측 정보에 기초하여 상기 예측을 생성하는 것에 의해 획득되는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 예측 오차는 상기 신경망(1786)으로 현재 픽처를 프로세싱함으로써 획득되고,상기 예측 정보는 모션 정보이고, 상기 참조 특징 데이터는 디코딩 순서에서 상기 현재 픽처에 선행하는 픽처를나타내는 픽처 데이터의 상기 신경망(1786) 프로세싱에 의해 생성되는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항 내지 제5항 중 어느 한 항에 있어서,공개특허 10-2023-0145096-3-상기 제1 데이터를 상기 제2 데이터(1765)와 함께 이용하는 것은, 상기 예측 또는 리스케일링된(re-scaled) 예측과, 상기 예측 오차 또는 리스케일링된 예측 오차와의 엘리먼트별(element-wise) 가산을 포함하는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항 또는 제6항에 있어서,상기 모션 정보는 모션 벡터를 포함하는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 제2 스테이지는 상기 신경망(1786)의 출력인, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제2항 내지 제8항 중 어느 한 항에 있어서,상기 제1 스테이지는 상기 신경망(1786)의 입력인, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 또는 제2항에 있어서,상기 제1 스테이지는 상기 신경망(1786)의 입력이고,상기 제1 데이터는 엔트로피 인코딩된 데이터이고,상기 제2 스테이지는 상기 신경망(1786)의 출력 스테이지와는 상이한 스테이지이고,상기 제2 데이터는 상기 제2 스테이지의 상기 특징 데이터에 관련된 확률 모델 데이터인, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제2 데이터는 상기 제1 데이터의 엔트로피 디코딩(entropy decoding)을 위한 확률 모델 데이터인, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항 내지 제11항 중 어느 한 항에 있어서,상기 제1 스테이지 및/또는 상기 제2 스테이지의 위치는 상기 신경망(1786) 내에서 구성가능하고,상기 방법은 하나 이상의 픽처 코딩 파라미터에 기초하여 수집 조건에 따라 상기 제1 스테이지 및/또는 상기 제2 스테이지의 위치를 구성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항 내지 제12항 중 어느 한 항에 있어서,상기 방법은, 상기 비트스트림(1772)으로부터, 상기 제1 스테이지 및/또는 상기 제2 스테이지를 특정하는 스테이지 선택 지시자를 파싱하는 단계를 더 포함하고,상기 신경망(1786) 내에서의 상기 제1 스테이지 및 상기 제2 스테이지의 위치는 파싱된 스테이지 선택 지시자에따라 구성되는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "비트스트림(1772)을 생성하기 위하여, 제1 스테이지 및 제2 스테이지를 포함하는 2개 이상의 스테이지를 포함하는 신경망(1706)을 이용하여 적어도 하나의 픽처를 프로세싱하기 위한 방법으로서,상기 신경망(1706)으로 상기 적어도 하나의 픽처를 프로세싱하는 단계 - 상기 프로세싱하는 단계는, 상기 적어도 하나의 픽처에 기초하여 제1 데이터(1760)를 획득하는 것, 상기 프로세싱의 상기 제2 스테이지에서 제2 데이공개특허 10-2023-0145096-4-터(1765)를 획득하되, 상기 제2 데이터(1765)는 상기 신경망(1706)에 의해 이전에 프로세싱된 데이터에 기초하는 것, 상기 신경망(1706)의 상기 제1 스테이지에서의 입력을 생성하기 위하여 상기 제1 데이터(1760)를 상기제2 데이터(1765)와 함께 이용하는 것을 포함하고, 상기 제1 스테이지는 상기 신경망(1706)의 특징 데이터 프로세싱에서 상기 제2 스테이지에 선행함 -;상기 프로세싱에 의해 획득된 특징 데이터를 상기 비트스트림(1772) 내로 포함하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제1 데이터(1760)는 상기 신경망(1706)의 상기 특징 데이터 프로세싱에서 상기 제1 스테이지 및 상기 제2스테이지에 선행하거나 상기 제1 스테이지와 동일한 상기 신경망(1706)의 제3 스테이지에서 획득되는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 제1 데이터(1760)는 예측 오차를 나타내고, 상기 제2 데이터(1765)는 예측을 나타내는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 예측은,- 상기 제2 스테이지에서 상기 신경망(1706)에 의해 출력된 특징 데이터인 참조 특징 데이터를 획득하는 것,- 상기 적어도 하나의 픽처에 기초하여, 상기 참조 특징 데이터에 관련된 모션 정보 또는 공간적 정보를 포함하는 예측 정보를 획득하는 것,- 상기 참조 특징 데이터 및 상기 예측 정보에 기초하여 상기 예측을 생성하는 것, 및- 획득된 예측 정보를 비트스트림(1790) 내로 삽입하는 것에 의해 획득되는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 예측 오차는 상기 신경망(1706)으로 현재 픽처를 프로세싱함으로써 획득되고,상기 예측 정보는 모션 정보이고, 상기 참조 특징 데이터는 디코딩 순서에서 상기 현재 픽처에 선행하는 픽처를나타내는 픽처 데이터의 상기 신경망(1706) 프로세싱에 의해 생성되는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항 내지 제18항 중 어느 한 항에 있어서,상기 제1 데이터(1760)를 상기 제2 데이터(1765)와 함께 이용하는 것은, 상기 제1 데이터(1760) 또는 리스케일링된 제1 데이터(1760)로부터 상기 예측 또는 리스케일링된 예측의 엘리먼트별 감산을 포함하는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항 또는 제19항에 있어서,상기 모션 정보는 모션 벡터를 포함하는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제14항 내지 제20항 중 어느 한 항에 있어서,공개특허 10-2023-0145096-5-상기 제2 스테이지는 재구성된 픽처 데이터를 나타내는 디코딩 신경망(1706)의 출력인, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제15항 내지 제21항 중 어느 한 항에 있어서,상기 제1 스테이지는 상기 신경망(1706)의 출력인, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제14항 또는 제15항에 있어서,상기 제1 스테이지는 상기 신경망(1706)의 출력이고,상기 제1 데이터는 엔트로피 인코딩되어야 할 프로세싱된 데이터이고,상기 제2 스테이지는 상기 신경망(1706)의 입력 스테이지와는 상이한 스테이지이고,상기 제2 데이터는 상기 제2 스테이지의 상기 특징 데이터에 관련된 확률 모델 데이터인, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서,상기 제2 데이터는 상기 제1 데이터의 엔트로피 인코딩(entropy encoding)을 위한 확률 모델 데이터인, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제1항 내지 제24항 중 어느 한 항에 있어서,상기 제1 스테이지 및/또는 상기 제2 스테이지의 위치는 상기 신경망(1706) 내에서 구성가능하고,상기 방법은 하나 이상의 픽처 코딩 파라미터에 기초하여 수집 조건에 따라 상기 제1 스테이지 및/또는 상기 제2 스테이지의 위치를 구성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제1항 내지 제25항 중 어느 한 항에 있어서,상기 방법은, 상기 제1 스테이지 및/또는 상기 제2 스테이지를 특정하는 스테이지 선택 지시자를 결정하고 상기스테이지 선택 지시자를 상기 비트스트림(1772) 내로 포함하는 단계를 더 포함하고,상기 신경망(1706) 내에서의 상기 제1 스테이지 및 상기 제2 스테이지의 위치는 결정된 스테이지 선택 지시자에따라 구성되는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제26항에 있어서,상기 스테이지 선택 지시자의 결정은 레이트(rate), 왜곡(distortion), 레이턴시(latency), 정확도(accuracy),및 복잡도(complexity) 중의 하나 이상을 포함하는 비용 함수(cost function)에 따라 수행된 최적화 절차에 기초하는, 방법."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "컴퓨터-판독가능 비-일시적 매체(540) 상에 저장되고 코드 명령을 포함하는 컴퓨터 프로그램(510)으로서,상기 코드 명령은, 하나 이상의 프로세서 상에서 실행될 때, 상기 하나 이상의 프로세서로 하여금, 제1항 내지제27항 중 어느 한 항에 따른 상기 방법을 수행하게 하는, 컴퓨터 프로그램(510)."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제1 스테이지 및 제2 스테이지를 포함하는 2개 이상의 스테이지를 포함하는 신경망(1786)을 이용하여 비트스트림(1772)으로부터의 하나 이상의 픽처의 특징 데이터를 프로세싱하기 위한 장치로서,공개특허 10-2023-0145096-6-프로세싱 회로부를 포함하고, 상기 프로세싱 회로부는,상기 비트스트림(1772)에 기초하여 제1 데이터(1760)를 획득하고,상기 신경망(1786)을 이용하여 상기 제1 데이터(1760)를 프로세싱하고 - 상기 프로세싱하는 것은, 상기 신경망(1786)의 상기 제2 스테이지로부터, 상기 신경망(1786)에 의해 이전에 프로세싱된 데이터에 기초하는 제2 데이터(1765)를 획득하는 것, 상기 신경망(1786)의 상기 제1 스테이지에 대한 입력을 생성하기 위하여 상기 제1 데이터(1760)를 상기 제2 데이터(1765)와 함께 이용하는 것을 포함하고, 상기 제1 스테이지는 상기 신경망(1786)의 특징 데이터 프로세싱에서 상기 제2 스테이지에 선행함 -;상기 프로세싱의 결과를 출력하도록구성되는, 장치."}
{"patent_id": "10-2023-7029752", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "비트스트림(1772)을 생성하기 위하여, 제1 스테이지 및 제2 스테이지를 포함하는 2개 이상의 스테이지를 포함하는 신경망(1706)을 이용하여 적어도 하나의 픽처를 프로세싱하기 위한 장치로서,프로세싱 회로부를 포함하고, 상기 프로세싱 회로부는,상기 신경망(1706)으로 상기 적어도 하나의 픽처를 프로세싱하고 - 상기 프로세싱하는 것은, 상기 적어도 하나의 픽처에 기초하여 제1 데이터(1760)를 획득하는 것, 상기 프로세싱의 상기 제2 스테이지에서 제2 데이터(1765)를 획득하되, 상기 제2 데이터(1765)는 상기 신경망(1706)에 의해 이전에 프로세싱된 데이터에 기초하는것, 상기 신경망(1706)의 상기 제1 스테이지에서의 입력을 생성하기 위하여 상기 제1 데이터(1760)를 상기 제2데이터(1765)와 함께 이용하는 것을 포함하고, 상기 제1 스테이지는 상기 신경망(1706)의 특징 데이터 프로세싱에서 상기 제2 스테이지에 선행함 -,상기 프로세싱에 의해 획득된 특징 데이터를 상기 비트스트림(1772) 내로 포함하도록구성되는, 장치."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이 출원은 2개 이상의 계층을 갖는 신경망을 이용하여 픽처 데이터 또는 픽처 특징 데이터의 프로세싱을 위한 방 법 및 장치를 제공한다. 본 개시내용은 인공 지능(AI)-기반 비디오 또는 픽처 압축 기술의 분야에서, 그리고 특 히, 신경망-기반 비디오 압축 기술의 분야에 적용될 수 있다. 일부 실시예에 따르면, 2개의 종류의 데이터는 신 경망에 의한 프로세싱을 포함하는 프로세싱 동안에 조합된다. 2개의 종류의 데이터는 네트워크에 의한 프로세싱 의 상이한 스테이지로부터 획득된다. 장점의 일부는 더 양호한 인코딩/디코딩 성능을 추가로 초래할 수 있는 신 경망 아키텍처의 더 큰 확장가능성 및 더 유연한 설계를 포함할 수 있다."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 인공 지능(AI : artificial intelligence)-기반 비디오 또는 픽처 압축 기술의 분야, 특히, 비트스트림을 생성하기 위하여 픽처 특징 데이터를 프로세싱하거나, 신경망(neural network)을 이용하여 픽처 특징 데이터를 비트스트림으로 디코딩하도록 프로세싱하기 위한 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "비디오 코딩(비디오 인코딩 및 디코딩)은 광범위한 디지털 비디오 애플리케이션, 예를 들어, 브로드캐스트 디지 털 TV, 인터넷 및 모바일 네트워크 상에서의 비디오 송신, 비디오 채팅과 같은 실시간 대화 애플리케이션, 비디 오 회의, DVD 및 블루-레이(Blu-ray) 디스크, 비디오 컨텐츠(video content) 취득 및 편집 시스템, 및 보안 애 플리케이션의 캠코더에서 이용된다. 심지어 상대적으로 짧은 비디오를 묘사하기 위하여 필요한 비디오 데이터의 양은 상당할 수 있고, 이것은 데이 터가 제한된 대역폭 용량으로 통신 네트워크에 걸쳐 스트리밍되어야 하거나 또는 이와 다르게 통신되어야 할 때 에 어려움으로 귀착될 수 있다. 따라서, 비디오 데이터는 일반적으로, 현대판 전기통신 네트워크에 걸쳐 통신되 기 전에 압축된다. 메모리 자원이 제한될 수 있으므로, 비디오의 크기는 또한, 비디오가 저장 디바이스 상에서 저장될 때에 쟁점이 될 수 있다. 비디오 압축 디바이스는 송신 또는 저장 이전에 비디오 데이터를 코딩하기 위 하여 출발지(source)에서 소프트웨어 및/또는 하드웨어를 종종 이용하고, 이에 의해, 디지털 비디오 픽처를 나 타내기 위하여 필요한 데이터의 수량을 감소시킨다. 압축된 데이터는 그 다음으로, 비디오 데이터를 디코딩하는 비디오 압축해제 디바이스에 의해 목적지(destination)에서 수신된다. 제한된 네트워크 자원 및 더 높은 비디오 품질의 점점 더 증가하는 수요로, 픽처 품질에 있어서 희생을 거의 또는 전혀 가지지 않으면서 압축 비율을 개선시키는 개선된 압축 및 압축해제 기법이 바람직하다. 최근, 심층 학습(deep learning)은 픽처 및 비디오 인코딩 및 디코딩의 분야에서 인기를 얻고 있다. 이 출원은, 신경망의 구성가능성을 개선시킬 수 있고, 이에 의해, 더 높은 효율을 달성할 수 있는 방법 및 장치 를 제공한다. 상기한 그리고 다른 목적은 독립항의 발명 요지에 의해 달성된다. 추가의 구현 형태는 종속항, 설명, 및 도면으 로부터 분명하다. 특정한 실시예는 첨부된 독립항에서 개략적으로 서술되고, 다른 실시예는 종속항에서 개략적으로 서술된다. 제1 측면에 따르면, 본 개시내용은 제1 스테이지(stage) 및 제2 스테이지를 포함하는 2개 이상의 스테이지를 포 함하는 신경망을 이용하여 비트스트림으로부터의 하나 이상의 픽처의 특징 데이터를 프로세싱하기 위한 방법에 관한 것이다. 방법은 비트스트림에 기초하여 제1 데이터를 획득하는 단계, 신경망을 이용하여 제1 데이터를 프 로세싱하는 단계, 및 프로세싱의 결과를 출력하는 단계를 포함한다. 프로세싱하는 단계는, 신경망의 제2 스테이 지로부터, 신경망에 의해 이전에 프로세싱된 데이터에 기초하는 제2 데이터를 획득하는 단계; 및 신경망의 제1 스테이지에 대한 입력을 생성하기 위하여 제1 데이터를 제2 데이터와 함께 이용하는 단계를 포함하고, 여기서, 제1 스테이지는 신경망의 특징 데이터 프로세싱에서 제2 스테이지에 선행한다. 하나의 스테이지에서 함께 이용되는 2개의 종류의 데이터의 획득 - 데이터의 종류 중의 적어도 하나의 종류의 획득은 또 다른 스테이지 상에서 수행됨 - 은 신경망 아키텍처의 유연성(flexibility)을 추가로 증가시키고, 감 소된 복잡도 또는 레이턴시 또는 레이트의 측면에서의 더 높은 효율, 또는 더 높은 품질로 귀착될 수 있다. 가능한 구현예에서, 제1 데이터는 신경망의 특징 데이터 프로세싱에서 제1 스테이지 및 제2 스테이지에 선행하 거나 제1 스테이지와 동일한 신경망의 제3 스테이지에서 획득된다. 상이한 스테이지로부터 제1 데이터 및 제2 데이터를 획득하는 것은 효율을 추가로 개선시킬 수 있다. 가능한 구현예에서, 제1 데이터는 예측 오차를 나타내고, 제2 데이터는 예측을 나타낸다. 본 개시내용은 예측 오차 및 예측 신호에 용이하게 적용가능하다. 이것이 조합되는 해상도(resolution)와는 상 이한 해상도로 이것 중의 적어도 하나를 획득함으로써, 복잡도, 비트스트림 길이 뿐만 아니라, 레이턴시가 절약 될 수 있다. 또한, 픽처 코딩에서는, 공간적 및 시간적 도메인에서 높은 상관(correlation)이 있으므로, 예측은 신경망을 이용하여 디코딩(및 인코딩)의 성능을 개선시킬 수 있는 보조 데이터이다. 또한, 예측을 제공하기 위"}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "하여 매우 효율적일 수 있는, 본 기술분야로부터 공지된 많은 접근법이 있다. 가능한 구현예에서는, 상기 제2 스테이지에서 신경망에 의해 출력된 특징 데이터인 참조 특징 데이터를 획득하 는 것, 비트스트림에 기초하여, 참조 특징 데이터에 관련된 모션 정보(motion information) 또는 공간적 정보를 포함하는 예측 정보를 획득하는 것, 및 참조 특징 데이터 및 예측 정보에 기초하여 예측을 생성하는 것에 의해 예측이 획득된다. 이 구현예는 예측 품질을 추가로 개선시키도록 도울 수 있는 추가적인 예측 정보의 도움으로 예측을 획득하는 예이다. 가능한 구현예에서, 예측 오차는 신경망으로 현재 픽처를 프로세싱함으로써 획득된다. 예측 정보는 모션 정보이 고, 참조 특징 데이터는 디코딩 순서에서 현재 픽처에 선행하는 픽처를 나타내는 픽처 데이터의 신경망 프로세 싱에 의해 생성된다. 시간적 예측은 전형적으로, 공간적 예측 또는 오직 무손실성 코딩보다 더 효율적이다. 따라서, 위에서 언급된 신경망 아키텍처는 디코딩(뿐만 아니라 인코딩)의 성능을 추가로 개선시킬 수 있다. 가능한 구현예에서, 제1 데이터를 제2 데이터와 함께 이용하는 것은 예측 또는 리스케일링된(re-scaled) 예측과, 예측 오차 또는 리스케일링된 예측 오차와의 엘리먼트별(element-wise) 가산을 포함한다. 이러한 조합은 특히, 픽처 또는 픽처 특징 데이터, 예측, 및 잔차를 다루기 위하여 관련될 수 있다. 가능한 구현예에서, 모션 정보는 모션 벡터(motion vector)를 포함한다. 모션 벡터는 모션 정보를 지시하기 위한 효율적인 수단이고, 본 명세서에서 설명된 실시예에 있어서 용이하게 적용될 수 있는 그 획득 및 시그널링을 위한 많은 이용가능한 접근법이 있다. 가능한 구현예에서, 상기 제2 스테이지는 신경망의 출력이다. 신경망의 출력은 (디코딩 측에서의) 재구성된 픽처이다. 이 스테이지로부터 제2 데이터를 획득하는 것은 전체 해상도를 제공하고, 이것은 품질을 개선시킬 수 있다. 가능한 구현예에서, 제1 스테이지는 신경망의 입력이다. 디코딩 측에서의 신경망의 입력은 인코딩된 비트스트림이다. 본 개시내용의 실시예는 병목 특징 데이터 (bottleneck feature data)의 디코딩을 위하여 효과적으로 적용될 수 있다. 가능한 구현예에서, 제1 스테이지는 신경망의 입력이고; 제1 데이터는 엔트로피 인코딩된 데이터이고; 제2 스테 이지는 신경망의 출력 스테이지와는 상이한 스테이지이고; 제2 데이터는 제2 스테이지의 특징 데이터에 관련된 확률 모델 데이터이다. 예를 들어, 제2 데이터는 제1 데이터의 엔트로피 디코딩(entropy decoding)을 위한 확률 모델 데이터(probability model data)이다. 확률 모델 데이터의 수집은 비트스트림 크기의 추가의 감소를 가능하게 할 수 있다. 상이한 스테이지로부터 확 률 모델 데이터를 취득하는 것은 성능과 복잡도 사이의 더 양호한 절충을 위한 유연한 아키텍처를 제공할 수 있 다. 가능한 구현예에서, 제1 스테이지 및/또는 제2 스테이지의 위치는 신경망 내에서 구성가능하고, 방법은 하나 이 상의 픽처 코딩 파라미터에 기초하여 수집 조건에 따라 제1 스테이지 및/또는 제2 스테이지의 위치를 구성하는 단계를 포함한다. 신경망 내에서 제1 스테이지 및 제2 스테이지의 위치를 구성할 가능성은 추가적인 유연성을 제공한다. 그것은 동적 신경망 아키텍처 변경을 가능하게 할 수 있다. 이러한 유연성은 수집 조건에 기초하여 더 양호한 적응으로 귀결될 수 있고, 더 효율적인 인코딩 및/또는 디코딩을 초래할 수 있다. 수집 조건은 제2 데이터 및/또는 제1 데이터가 특정한 프로세싱 스테이지로 입력되도록 하기 위하여 이행되어야 할 조건 또는 전제조건이다. 수집 조건은 어떤 위치에 대한 보조 정보를 수집할 것인지 또는 그렇지 않은지 여 부를 결정하기 위한 일부 픽처 특성 또는 픽처 특징 특성과 임계치와의 비교를 포함할 수 있다. 픽처 특성 또는 픽처 특징 특성은 인코더 및 디코더에 알려질 수 있어서, 이로써 추가적인 시그널링이 요구되지 않는다. 대안적 으로 또는 추가적으로, 보조 정보가 사전구성된 위치에 대하여 수집되어야 하는지 또는 그렇지 않은지 여부의 지시자를 설정하는 것에 의하여, 수집 조건은 인코딩 측에 의해 구성될 수 있다. 지시자는 디코더에서 이용가능 한 비트스트림 내에서 제공될 수 있다. 특히, 방법은 비트스트림으로부터, 상기 제1 스테이지 및/또는 상기 제2 스테이지를 특정하는 스테이지 선택 지 시자를 파싱하는 단계를 더 포함하고, 여기서, 신경망 내에서의 제1 스테이지 및 제2 스테이지의 위치는 파싱된 스테이지 선택 지시자에 따라 구성된다. 제2 측면에 따르면, 본 발명은 비트스트림을 생성하기 위하여, 제1 스테이지 및 제2 스테이지를 포함하는 2개 이상의 스테이지를 포함하는 신경망을 이용하여 적어도 하나의 픽처를 프로세싱하기 위한 방법에 관한 것이고, 방법은 신경망으로 적어도 하나의 픽처를 프로세싱하는 단계를 포함한다. 프로세싱하는 단계는, 적어도 하나의 픽처에 기초하여 제1 데이터를 획득하는 단계, 및 프로세싱의 상기 제2 스테이지에서 제2 데이터를 획득하는 단 계 - 제2 데이터는 신경망에 의해 이전에 프로세싱된 데이터에 기초함 -, 및 신경망의 상기 제1 스테이지에서의 입력을 생성하기 위하여 제1 데이터를 제2 데이터와 함께 이용하는 단계를 포함하고, 여기서, 제1 스테이지는 신경망의 특징 데이터 프로세싱에서 제2 스테이지에 선행한다. 방법은 프로세싱에 의해 획득된 특징 데이터를 비트스트림 내로 삽입하는 단계를 더 포함한다. 본 개시내용의 인코딩 파트는 디코딩 파트에 대하여 위에서 언급된 것과 동일한 장점을 제공할 수 있다. 인코더 는 비트스트림을 준비하고, 비트스트림을 디코더에 제공하여, 이로써 디코더는 희망된 품질 및 애플리케이션을 고려하여 데이터를 디코딩하거나 재구성할 수 있다. 중복성(redundancy)을 회피하기 위하여, 대응하는 디코딩 프로세싱 청구항에 대하여 제공된 장점은 유사한 방식 으로 인코딩에 대하여 적용된다. 가능한 구현예에서, 제1 데이터는, 신경망의 특징 데이터 프로세싱에서 상기 제1 스테이지 및 상기 제2 스테이 지에 선행하거나, 상기 제1 스테이지와 동일한 신경망의 제3 스테이지에서 획득된다. 가능한 구현예에서, 제1 데이터는 예측 오차를 나타내고, 제2 데이터는 예측을 나타낸다. 가능한 구현예에서는, 상기 제2 스테이지에서 신경망에 의해 출력된 특징 데이터인 참조 특징 데이터를 획득하 는 것, 적어도 하나의 픽처에 기초하여, 참조 특징 데이터에 관련된 모션 정보 또는 공간적 정보를 포함하는 예 측 정보를 획득하는 것, 참조 특징 데이터 및 예측 정보에 기초하여 예측을 생성하는 것, 및 획득된 예측 정보 를 비트스트림 내로 삽입하는 것에 의해 예측이 획득된다. 가능한 구현예에서, 예측 오차는 신경망으로 현재 픽처를 프로세싱함으로써 획득되고; 예측 정보는 모션 정보이 고, 참조 특징 데이터는 디코딩 순서에서 현재 픽처에 선행하는 픽처를 나타내는 픽처 데이터의 신경망 프로세 싱에 의해 생성된다. 가능한 구현예에서, 제1 데이터를 제2 데이터와 함께 이용하는 것은 제1 데이터 또는 리스케일링된 제1 데이터 로부터 예측 또는 리스케일링된 예측의 엘리먼트별 감산을 포함한다. 가능한 구현예에서, 모션 정보는 모션 벡터를 포함한다. 가능한 구현예에서, 상기 제2 스테이지는 재구성된 픽처 데이터를 나타내는 디코딩 신경망의 출력이다. 가능한 구현예에서, 상기 제1 스테이지는 신경망의 출력이다. 가능한 구현예에서, 제1 스테이지는 신경망의 출력이고; 제1 데이터는 엔트로피 인코딩되어야 할 프로세싱된 데 이터이고; 제2 스테이지는 신경망의 입력 스테이지와는 상이한 스테이지이고; 제2 데이터는 제2 스테이지의 특 징 데이터에 관련된 확률 모델 데이터이다. 가능한 구현예에서, 제2 데이터는 제1 데이터의 엔트로피 인코딩(entropy encoding)을 위한 확률 모델 데이터이 다. 가능한 구현예에서, 상기 제1 스테이지 및/또는 상기 제2 스테이지의 위치는 신경망 내에서 구성가능하고, 방법 은 하나 이상의 픽처 코딩 파라미터에 기초하여 수집 조건에 따라 상기 제1 스테이지 및/또는 상기 제2 스테이 지의 위치를 구성하는 단계를 포함한다. 가능한 구현예에서, 방법은 상기 제1 스테이지 및/또는 상기 제2 스테이지를 특정하는 스테이지 선택 지시자를 결정하고 이를 비트스트림 내로 포함하는 단계를 더 포함하고, 여기서, 신경망 내에서의 제1 스테이지 및 제2 스테이지의 위치는 결정된 스테이지 선택 지시자에 따라 구성된다. 가능한 구현예에서, 스테이지 선택 지시자의 결정은 레이트(rate), 왜곡(distortion), 레이턴시(latency), 정확 도(accuracy), 및 복잡도(complexity) 중의 하나 이상을 포함하는 비용 함수(cost function)에 따라 수행된 최 적화 절차에 기초한다. 비용 함수에 기초한 스테이지(들)의 결정은 신경망의 적응 및 희망된 요건에 대한 결과를 개선시킬 수 있다. 따 라서, 이러한 최적화는 성능을 개선시킬 수 있다. 그렇게 획득된 스테이지(들) 위치를 지시하는 것과 조합하여, 유연성이 추가로 개선된다. 제3 측면에 따르면, 본 개시내용은 제1 스테이지 및 제2 스테이지를 포함하는 2개 이상의 스테이지를 포함하는 신경망을 이용하여 비트스트림으로부터의 하나 이상의 픽처의 특징 데이터를 프로세싱하기 위한 장치에 관한 것 이고, 장치는 프로세싱 회로부를 포함한다. 프로세싱 회로부는, 비트스트림에 기초하여 제1 데이터를 획득하고, 신경망을 이용하여 제1 데이터를 프로세싱하고, 프로세싱의 결과를 출력하도록 구성된다. 프로세싱하는 것은, 신경망의 제2 스테이지로부터, 신경망에 의해 이전에 프로세싱된 데이터에 기초하는 제2 데이터를 획득하는 것; 및 신경망의 제1 스테이지에 대한 입력을 생성하기 위하여 제1 데이터를 제2 데이터와 함께 이용하는 것을 포함 하고, 여기서, 제1 스테이지는 신경망의 특징 데이터 프로세싱에서 제2 스테이지에 선행한다. 본 개시내용의 유리한 효과에 대해서는, 제1 측면의 설명을 참조한다. 세부사항은 본 명세서에서 다시 설명되지 않는다. 디코딩 장치는 제1 측면에서의 방법 예에서의 액션을 구현하는 기능을 가진다. 기능은 하드웨어에 의해 구현될 수 있거나, 대응하는 소프트웨어를 실행하는 하드웨어에 의해 구현될 수 있다. 하드웨어 또는 소프트웨 어는 상기한 기능에 대응하는 하나 이상의 모듈을 포함한다. 가능한 구현예에서, 디코딩 장치는 비트스트림에 기초하여 제1 데이터를 획득하기 위한 비트스트림 디코딩 모듈; 및 위에서 언급된 프로세싱 및 출력을 수행하도 록 구성된 신경망 모듈을 포함한다. 이 모듈은 제1 측면에서의 방법 예에서의 대응하는 기능을 수행할 수 있다.세부사항에 대해서는, 방법 예에서의 상세한 설명을 참조한다. 세부사항은 본 명세서에서 다시 설명되지 않는다. 제4 측면에 따르면, 본 개시내용은 비트스트림을 생성하기 위하여, 제1 스테이지 및 제2 스테이지를 포함하는 2 개 이상의 스테이지를 포함하는 신경망을 이용하여 적어도 하나의 픽처를 프로세싱하기 위한 장치에 관한 것이 고, 장치는 프로세싱 회로부를 포함한다. 프로세싱 회로부는 신경망으로 적어도 하나의 픽처를 프로세싱하도록 구성된다. 프로세싱하는 것은, 적어도 하나의 픽처에 기초하여 제1 데이터를 획득하는 것, 프로세싱의 상기 제2 스테이지에서 제2 데이터를 획득하는 단계 - 제2 데이터는 신경망에 의해 이전에 프로세싱된 데이터에 기초함 -, 및 신경망의 상기 제1 스테이지에서의 입력을 생성하기 위하여 제1 데이터를 제2 데이터와 함께 이용하는 것 을 포함하고, 여기서, 제1 스테이지는 신경망의 특징 데이터 프로세싱에서 제2 스테이지에 선행한다. 방법은 프 로세싱에 의해 획득된 특징 데이터를 비트스트림 내로 포함하는 단계를 더 포함한다. 본 발명의 유리한 효과에 대해서는, 제2 측면의 설명을 참조한다. 세부사항은 본 명세서에서 다시 설명되지 않 는다. 인코딩 장치는 제2 측면에서의 방법 예에서의 액션을 구현하는 기능을 가진다. 기능은 하드웨어에 의해 구현될 수 있거나, 대응하는 소프트웨어를 실행하는 하드웨어에 의해 구현될 수 있다. 하드웨어 또는 소프트웨 어는 상기한 기능에 대응하는 하나 이상의 모듈을 포함한다. 가능한 구현예에서, 인코딩 장치는 위에서 언급된 프로세싱을 수행하도록 구성된 신경망 모듈; 및 신경망에 의해 픽처를 프로세싱하여 획득된 데이터를 비트스트 림 내로 삽입하고 비트스트림을 출력하도록 구성된 비트스트림 출력 모듈을 포함한다. 이 모듈은 제2 측면에서 의 방법 예에서의 대응하는 기능을 수행할 수 있다. 세부사항에 대해서는, 방법 예에서의 상세한 설명을 참조한 다. 세부사항은 본 명세서에서 다시 설명되지 않는다. 본 발명의 제1 측면에 따른 방법은 본 발명의 제3 측면에 따른 장치에 의해 수행될 수 있다. 본 발명의 제1 측 면에 따른 방법의 다른 특징 및 구현예는 본 발명의 제3 측면에 따른 장치의 기능성 및 구현예에 직접적으로 종 속된다. 본 발명의 제2 측면에 따른 방법은 본 발명의 제4 측면에 따른 장치에 의해 수행될 수 있다. 본 발명의 제2 측 면에 따른 방법의 다른 특징 및 구현예는 본 발명의 제4 측면에 따른 장치의 기능성 및 구현예에 직접적으로 종 속된다. 제5 측면에 따르면, 본 발명은 프로세서 및 메모리를 포함하는 비디오 스트림 디코딩 장치에 관한 것이다. 메모 리는, 프로세서로 하여금, 제1 측면에 따른 방법을 수행하게 하는 명령을 저장한다. 제6 측면에 따르면, 본 발명은 프로세서 및 메모리를 포함하는 비디오 스트림 인코딩 장치에 관한 것이다. 메모 리는, 프로세서로 하여금, 제2 측면에 따른 방법을 수행하게 하는 명령을 저장한다. 제7 측면에 따르면, 실행될 때, 하나 이상의 프로세서로 하여금, 비디오 데이터를 인코딩하게 하는 명령을 저장 한 컴퓨터-판독가능 저장 매체가 제안된다. 명령은, 하나 이상의 프로세서로 하여금, 제1 또는 제2 측면, 또는 제1 또는 제2 측면의 임의의 가능한 실시예에 따른 방법을 수행하게 한다. 제8 측면에 따르면, 본 발명은 컴퓨터 상에서 실행될 때, 제1 또는 제2 측면, 또는 제1 또는 제2 측면의 임의의 가능한 실시예에 따른 방법을 수행하기 위한 프로그램 코드를 포함하는 컴퓨터 프로그램 제품에 관한 것이다. 하나 이상의 실시예의 세부사항은 첨부 도면 및 이하의 설명에서 기재된다. 다른 특징, 목적, 및 장점은 설명, 도면, 및 청구항으로부터 분명할 것이다."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이 출원의 실시예는 AI-기반 비디오 픽처 압축 기술을 제공하고, 특히, 신경망-기반 비디오 압축 기술을 제공한 다. 비디오 코딩은 전형적으로, 픽처의 시퀀스(sequence)의 프로세싱을 지칭하고, 여기서, 픽처의 시퀀스는 비디오 또는 비디오 시퀀스를 형성한다. 비디오 코딩의 분야에서, 용어 \"픽처(picture)\", \"프레임(frame)\", 및 이미지 (image)\"는 동의어로서 이용될 수 있다. 비디오 코딩(또는 일반적으로 코딩)은 2개의 파트인 비디오 코딩 및 비 디오 디코딩을 포함한다. 비디오 인코딩은 출발지 측에서 수행되고, 전형적으로, (더 효율적인 저장 및/또는 송 신을 위하여) 비디오 픽처를 표현하기 위해 요구된 데이터의 양을 감소시키기 위하여 원래의 비디오 픽처를 (예 를 들어, 압축에 의해) 프로세싱하는 것을 포함한다. 비디오 디코딩은 목적지 측에서 수행되고, 전형적으로, 비 디오 픽처를 재구성하기 위하여 인코더의 프로세싱과 비교한 역 프로세싱(inverse processing)을 포함한다. 비 디오 픽처(또는 일반적으로 픽처)의 \"코딩\"을 지칭하는 실시예는 비디오 픽처 또는 개개의 비디오 시퀀스의 \"인 코딩\" 또는 \"디코딩\"에 관련되는 것으로 이해될 것이다. 인코딩 파트 및 디코딩 파트의 조합은 또한, CODEC(인 코딩 및 디코딩)으로서 지칭된다. 무손실성 비디오 코딩의 경우에, 원래의 비디오 픽처가 재구성될 수 있다. 다시 말해서, (저장 또는 송신 동안 에 송신 손실 또는 다른 데이터 손실이 발생하지 않는 것으로 가정하면) 재구성된 비디오 픽처는 원래의 비디오 픽처와 동일한 품질을 가진다. 손실성 비디오 코딩의 경우에, 비디오 픽처를 나타내기 위하여 요구된 데이터의 양을 감소시키기 위하여, 예를 들어, 양자화를 통해 추가의 압축이 수행되고, 비디오 픽처는 디코더 측 상에서 완전히 재구성되지 않을 수 있다. 다시 말해서, 재구성된 비디오 픽처의 품질은 원래의 비디오 픽처의 품질보다 낮거나 열악하다. 몇몇 H.26x 비디오 코딩 표준(예컨대, H.261, H.263, H.264, H.265, H.266)은 \"손실성 하이브리드 비디오 코딩\"을 위하여 이용된다(즉, 샘플 도메인에서의 공간적 및 시간적 예측은 변환 도메인에서 양자화를 적용하기 위한 2D 변환 코딩과 조합됨). 비디오 시퀀스의 각각의 픽처는 전형적으로, 비-중첩하는 블록의 세트로 파티셔 닝(partition)되고, 코딩은 전형적으로 블록 레벨에서 수행된다. 구체적으로 말하면, 인코더 측에서, 비디오는 통상적으로, 블록(비디오 블록) 레벨에서 프로세싱되고, 즉, 인코딩된다. 예를 들어, 예측 블록은 공간적(인트 라-픽처) 예측 및 시간적(인터-픽처) 예측을 통해 생성되고, 예측 블록은 잔차 블록을 획득하기 위하여 현재 블 록(프로세싱되고 있거나 프로세싱되어야 할 블록)으로부터 감산(subtract)되고, 잔차 블록은 송신(압축)되어야 하는 데이터의 양을 감소시키기 위하여 변환 도메인에서 변환되고 양자화된다. 디코더 측에서, 인코더에 대한 역 프로세싱 파트는 표현을 위한 현재 블록을 재구성하기 위하여 인코딩된 블록 또는 압축된 블록에 적용된다. 또한, 인코더는 디코더 프로세싱 루프를 복제하여, 둘 모두가 후속 블록을 프로세싱, 즉, 코딩하기 위한 동일한 예측(예를 들어, 인트라 및 인터 예측) 및/또는 재구성을 생성한다. 본 개시내용은 픽처 데이터의 인코딩 및 디코딩의 목적을 위하여 신경망을 이용하여 픽처 데이터를 프로세싱하 는 것에 관한 것이다. 이러한 인코딩 및 디코딩은 여전히, 위에서 언급된 표준의 프레임워크로부터 알려진 일부 컴포넌트를 지칭하거나 포함할 수 있다. 이하에서는, 본 명세서에서 이용된 일부 용어가 간략하게 도입된다. 픽처 크기: 픽처의 폭 또는 높이 또는 폭-높이 쌍을 지칭한다. 이미지의 폭 및 높이는 통상적으로, 루마 샘플의 수로 측정된다. 다운샘플링: 다운샘플링은 이산 입력 신호(discrete input signal)의 샘플링 레이트가 감소되는 프로세스이다. 예를 들어, 입력 신호가 h 및 w의 크기를 가지는 이미지이고, 다운샘플링의 출력이 h2 및 w2인 경우에, 다음 중 의 적어도 하나가 유효하다: - h2<h - w2<w 하나의 예시적인 구현예에서, 다운샘플링은 각각의 m 번째 샘플만을 유지하고, 입력 신호(예컨대, 이미지)의 나 머지를 폐기하는 것으로서 구현될 수 있다. 그러나, 다운샘플링은 컨볼루션(convolution) 또는 다른 필터링 등 에 의한 것과 같은 다른 수단에 의해 수행될 수 있다. 업샘플링: 업샘플링은 이산 입력 신호의 샘플링 레이트가 증가되는 프로세스이다. 예를 들어, 입력 이미지가 h 및 w의 크기를 가지고, 다운샘플링의 출력이 h2 및 w2인 경우에, 다음 중의 적어도 하나가 유효하다: - h<h2 - w<w2 리샘플링(resampling): 다운샘플링 및 업샘플링 프로세스는 둘 모두 리샘플링의 예이다. 리샘플링은 입력 신호 의 샘플링 레이트(샘플링 간격)가 변경되는 프로세스이다. 샘플링 비율: 픽처 크기가 리샘플링 프로세스(업- 또는 다운-샘플링) 동안에 변경되는 경우에, 출력 및 입력 픽 처 크기는 샘플링 비율로 칭해진다. 샘플링 비율은 수평 및 수직 차원에 대하여 상이할 수 있다. 보간 필터링(interpolation filtering): 업샘플링 또는 다운샘플링 프로세스 동안에, 필터링은 리샘플링된 신호 의 정확도를 개선시키고 에일리어싱 영향(aliasing affect)을 감소시키기 위하여 적용될 수 있다. 보간 필터는 통상적으로, 리샘플링 위치 주위의 샘플 위치에서의 샘플 값의 가중화된 조합을 포함한다. 그것은 다음으로서 구현될 수 있다:"}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, f()는 리샘플링된 신호이고, 은 리샘플링된 이미지 내의 좌표이고, C(k)는 보간 필터 계수이고, s(x,y)는 입력 신호의 샘플이다. 합산 동작은 근처에 있는 (x,y)에 대하여 수행된다. 크롭핑(cropping): 디지털 이미지의 외부 에지를 트리밍하여 제거함. 크롭핑은 이미지를 (샘플의 수에 있어서) 더 작게 하고 및/또는 이미지의 종횡비(aspect ratio)(폭에 대한 길이)를 변경하기 위하여 이용될 수 있다. 패딩(padding): 패딩은 예컨대, 사전정의되는 샘플 값을 이용하는 것, 또는 이미지 내의 위치의 샘플 값을 이용 하는 것 등에 의해, (통상적으로, 이미지의 경계에서) 새로운 샘플을 생성함으로써 이미지의 크기를 증가시키는 것을 지칭한다. 리사이징(resizing): 리사이징은 입력 이미지의 크기가 변경되는 일반적인 용어이다. 그것은 패딩 또는 크롭핑 의 방법 중의 하나를 이용하여 행해질 수 있다. 또는, 그것은 리샘플링에 의해 행해질 수 있다. 정수 제산(integer division): 정수 제산은 분수 파트(나머지)가 폐기되는 제산이다. 컨볼루션: 컨볼루션은 다음의 일반적인 수학식에 의해 주어진다. 이하의 f()는 입력 신호로서 정의될 수 있고, g()는 필터로서 정의될 수 있다."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이 컨볼루션은 이산 컨볼루션(discrete convolution)이고, n 및 m은 샘플 인덱스 및 이에 따라 정수이다. 인덱 스 n 및 m의 범위는 신호 크기(차원) 및 필터 크기에 종속될 수 있다. 일반적으로, 이론적으로는, 그것은 마이 너스 무한대로부터 무한대까지의 범위일 수 있다. NN 모듈: 신경망 모듈, 신경망의 컴포넌트. 그것은 신경망 내의 계층 또는 서브-네트워크일 수 있다. 신경망은 하나 이상의 NN 모듈의 시퀀스이다. 파이프라인 내에서의 위치(스테이지): 신경망일 수 있거나 신경망을 포함할 수 있는 프로세싱 네트워크 내의 프 로세싱 파이프라인 내에서의 위치를 특정함. 네트워크 내에서의 위치는 예컨대, 위치에 선행하는 NN 모듈(또는 계층)의 수에 의해 특정될 수 있다. 파이프라인의 i 번째 위치에서 변환을 적용하는 것은, 변환을 i 번째 NN 모 듈의 출력에 적용하고 변환의 결과를 (i+1) 번째 NN 모듈의 입력으로서 이용하는 것을 의미한다. 파이프라인의 0 번째 위치에서 변환을 적용하는 것은, 변환을 NN의 입력에 적용하는 것으로서 해독된다. 파이프라인의 K 번째위치에서 변환을 적용하는 것은, 변환을 NN의 출력에 적용하는 것으로서 해독된다. 잠재 공간: 신경망 프로세싱의 중간 단계인 잠재 공간 표현은 입력 계층 또는 은닉된 계층(들)의 출력을 포함하 고, 이것은 통상적으로 관측되도록 지원되지 않는다. 손실성 NN 모듈: 손실성 NN 모듈에 의해 프로세싱된 정보는 정보 손실로 귀착되고, 손실성 모듈은 그 프로세싱 된 정보가 반전가능하지 않게 한다. 무손실성 NN 모듈: 무손실성 NN 모듈에 의해 프로세싱된 정보는 정보 손실 없음으로 귀착되고, 무손실성 프로세 싱은 그 프로세싱된 정보가 반전가능하게 한다. 병목(bottleneck): 무손실성 코딩 모듈에 입력될 수 있는 잠재 공간 텐서(latent space tensor). 용어 병목은 채널 크기가 통상적으로 선행 스테이지보다 작다는 사실에 관련된다. NN 계층: 입력 데이터에 대해 하나의 프로세싱 동작을 수행하는 신경망의 프로세싱 단계. 가변적 오토-인코더(VAE : Variational Auto-Encoder) 예시적인 심층 학습 기반 이미지 및 비디오 압축 알고리즘은 가변적 오토-인코더(VAE) 프레임워크, 예컨대, Z. Cui, J. Wang, B. Bai, T. Guo, Y. Feng, \"G-VAE: A Continuously Variable Rate Deep Image Compression Framework(연속적인 가변적 레이트 심층 이미지 압축 프레임워크)\"(arXiv preprint arXiv:2003.02012, 2020)을 따른다. 도 1은 VAE 프레임워크를 예시한다. VAE 프레임워크는 비선형 변환 코딩 모델로서 고려될 수 있다. 네트워크의 인코더 측에서, 인코더는 함수 y = f (x)를 통해 이미지 x를 잠재 표현으로 맵핑한다. 인코더는 신경망을 포 함할 수 있거나 신경망으로 구성될 수 있다. 양자화기는 잠재 표현을 희망된 비트길이 및/또는 정밀도의 이 산 값인 y_hat = Q(y)로 변환한다. 양자화된 신호(잠재 공간) y_hat는 산술 인코더(arithmetic encoder)를 의미하는 AE로서 나타내어진 산술 코딩을 이용하여 비트스트림(비트스트림1) 내로 포함된다. 네트워크의 디코더 측에서, 인코딩된 잠재 공간은 산술 디코더(AD : arithmetic decoder)에 의해 비트스트림 으로부터 디코딩된다. 디코더는 AD로부터 출력되는 양자화된 잠재 표현을 디코딩된 이미지인 x_hat = g(y_hat)로 변환한다. 디코더는 신경망을 포함할 수 있거나 신경망으로 구성될 수 있다. 도 1에서, 2개의 서브네트워크(subnetwork)는 서로에 연접(concatenate)된다. 제1 네트워크는 위에서 언급된 프 로세싱 유닛(1(인코더), 2(양자화기), 4(디코더), 5(AE), 및 6(AD))을 포함한다. 적어도 유닛(1, 2, 및 4) 은 오토-인코더/디코더 또는 간단하게 인코더/디코더 네트워크로 칭해진다. 제2 서브네트워크는 적어도 유닛(3 및 7)을 포함하고, 하이퍼(hyper) 인코더/디코더 또는 컨텍스트 모델러 (context modeler)로 칭해진다. 특히, 제2 서브네트워크는 AE 및 AD에 대한 확률 모델(컨텍스트)을 모델 링한다. 엔트로피 모델, 또는 이 경우에, 하이퍼 인코더는 무손실성 엔트로피 소스 코딩(lossless entropy source coding)으로 달성가능한 최소 레이트에 근접하기 위하여 양자화된 신호 y_hat의 분포 z를 추정한다. 추 정된 분포는 비트스트림 내에 디코더 측으로 전달될 수 있는 부 정보를 나타내는 양자화된 확률 모델 z_hat을 획득하기 위하여 양자화기에 의해 양자화된다. 그렇게 행하기 위하여, 산술 인코더인 AE는 확률 모델을 비트스트림2로 인코딩할 수 있다. 비트스트림2는 비트스트림1과 함께 디코더 측으로 전달될 수 있고, 또한, 인 코더에 제공될 수 있다. 특히, AE 및 AD에 제공되도록 하기 위하여, 양자화된 확률 모델 z_hat는 AD 에 의해 산술적으로 디코딩되고, 그 다음으로, 하이퍼 디코더로 디코딩되고 AD 및 AE로 삽입된다. 도 1은 단일 도면에서 인코더 및 디코더를 도시한다. 다른 한편으로, 인코더 및 디코더는 별도로 작동할 수 있 으므로, 도 2 및 도 3은 인코더 및 디코더를 별도로 도시한다. 다시 말해서, 인코더는 비트스트림1 및 비트스트 림2를 생성할 수 있다. 디코더는 스토리지(storage)로부터, 또는 채널 등을 통해 이러한 비트스트림을 수신할 수 있고, 인코더와의 임의의 추가의 통신 없이 이러한 비트스트림을 디코딩할 수 있다. 인코더 및 디코더 엘리 먼트의 위의 설명은 도 2 및 도 3에 대하여 또한 적용된다. 심층 학습 기반 이미지/비디오 압축 시스템의 대다수는 신호를 2진 숫자(비트)로 변환하기 전에 신호의 차원성 (dimensionality)을 감소시킨다. VAE 프레임워크에서는, 예를 들어, 비-선형 변환인 인코더가 입력 이미지 x를 y로 맵핑하고, 여기서, y는 x보다 작은 폭 및 높이를 가진다. y는 더 작은 폭 및 높이, 이 때문에, 더 작은 크기를 가지므로, 신호의 차원은 감소 되고, 이 때문에, 신호 y를 압축하는 것이 더 용이하다.압축의 일반적인 원리는 도 4에서 예시된다. 입력 이미지 x는 인코더의 입력인 입력 데이터에 대응한다. 변환된 신호 y는, 입력 신호보다 작은 차원성을 가지고, 이에 따라, 병목으로서 또한 지칭되는 잠재 공간에 대응한다. 전형적으로, 채널의 차원성은 인코더-디코더 파이프라인 내에서의 이 프로세싱 위치에서 가장 작다. 도 4에서의 원(circle)의 각각의 열은 인코더 또는 디코더의 프로세싱 체인 내의 계층을 나타낸다. 각각의 계층 내의 원의 수는 그 계층에서의 신호의 크기 또는 차원성을 지시한다. 인코더의 출력 및 디코더의 입력인 잠재 공간은 압축 된 데이터 y를 나타낸다. 디코더 측에서, 잠재 공간 신호 y(인코딩된 이미지)는 디코더 신경망에 의해 프로세싱 되어, 입력 데이터 x와 동일한 차원성을 가질 수 있지만, 특히, 손실성 프로세싱이 적용되었을 경우에 입력 데 이터 x와 상이할 수 있는 재구성된 데이터 x_hat를 획득할 때까지, 채널의 차원을 확장하는 것을 초래한다. 디 코더 계층에 의해 프로세싱된 채널의 차원은 전형적으로, 병목 데이터 y 차원보다 높다. 다시 말해서, 통상적으 로, 인코딩 동작은 입력 신호의 크기에서의 감소에 대응하는 반면, 디코딩 동작은 이미지의 원래의 크기의 재구 성, 이에 따라, 명칭 병목에 대응한다. 위에서 언급된 바와 같이, 신호 크기의 감소는 다운-샘플링 또는 리스케일링(rescaling)에 의해 달성될 수 있다. 신호 크기에서의 감소는 통상적으로, 즉시가 아니라, 프로세싱 계층의 체인을 따라 단계적으로 발생한다. 예를 들어, 입력 이미지 x가 h 및 w(높이 및 폭을 지시함)의 차원을 가지고, 잠재 공간 y가 차원 h/16 및 w/16 을 가지는 경우에, 크기의 감소는 인코딩 동안에 4개의 계층에서 발생할 수 있고, 여기서, 각각의 계층은 각각 의 차원에서 2의 계수만큼 신호의 크기를 감소시킨다. 공지된 심층 학습 기반 비디오/이미지 압축 방법은 전형적으로, 다수의 다운샘플링 계층을 채용한다. 예시적인 VAE는 도 5에서 도시되어 있고, 51 내지 56으로 마킹되는 6개의 다운샘플링 계층을 사용한다. 다운샘플링을 포 함하는 계층은 계층 설명에서의 하향 화살표로 지시된다. 계층 설명 \"Conv Nx5x5/2↓\"는, 계층이 N개의 채널을 갖는 컨볼루션 계층(\"ConV\")이고, 컨볼루션 커널(convolution kernel)은 크기에 있어서 5x5 샘플인 것을 의미한 다. \"2↓\"는 2의 계수를 갖는 다운샘플링이 이 계층에서 수행된다는 것을 의미한다. 2의 계수에 의한 다운샘플 링은 입력 신호의 차원 중의 하나가 출력에서 절반만큼 감소되는 것으로 귀착된다. 도 5에서, 2↓는 입력 이미 지의 폭 및 높이의 둘 모두는 2의 계수만큼 감소된다는 것을 지시한다. 하나의 차원에서 크기를 절반으로 하는 6개의 다운샘플링 계층이 있으므로, 입력 이미지 x의 폭 및 높이가 w 및 h에 의해 주어지는 경우에, 출력 신호 z_hat는 각각 w/64 및 h/64인 폭 및 높이를 가진다. 제1 서브네트워크에서, 일부 컨볼루션 계층은 인코드 측에서의 일반화된 분할적 정규화(GDN : generalized divisive normalization) 및 디코더 측에서의 역 GDN(IGDN : inverse GDN)에 선행한다. 제2 서브네트워크에서, 적용된 활성화 함수는 정류된 선형 유닛(ReLU : rectified linear unit)이다. 본 개시내용은 이러한 구현예로 제한되지는 않고, 일반적으로, 다른 활성화 함수가 GDN 또는 ReLu 대신에 이용될 수 있다는 것이 주목된다. 도 5에서의 네트워크 아키텍처는 하이퍼 프라이어 모델(hyper prior model)을 포함한다. 좌측 측부(ga, gs)는 이미지 오토인코더 아키텍처를 도시하고, 우측 측부(ha, hs)는 도 1 내지 도 3을 참조하여 위에서 설명된 바와 같은 하이퍼 프라이어를 구현하는 오토인코더에 대응한다. 모델은 분석 및 합성 변환 ga 및 gs를 위한 유사한 아 키텍처를 이용한다. Q는 양자화를 나타내고, AE, AD는 또한, 위에서 설명된 도 1 내지 도 3에서와 같이, 각각 산술 인코더 및 산술 디코더를 나타낸다. 인코더는 입력 이미지 x가 ga를 거치게 하여, 공간적으로 변동되는 표 준 편차를 갖는 잠재 표현 y를 산출한다."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "결과는 ha로 공급되어, z에서의 표준 편차의 분포를 요약한다. z은 그 다음으로, 부 정보로서 양자화되고, 압축 되고, 송신된다. 인코더는 산술 코딩(AE : arithmetic coding)을 위하여 확률 값(또는 주파수 값)을 획득하기 위하여 이용되는 표준 편차의 공간적 분포인 를 추정하기 위하여 양자화된 벡터 z_hat을 이용하고, 이를 이용하여 양자화된 잠재 표현 y_hat을 압축하고 송신한다. 디코더는 먼저, 압축된 신호로부터 z_hat를 복 원한다. 그것은 그 다음으로, y_hat을 마찬가지로 성공적으로 본원하기 위하여 올바른 확률 추정치를 제공하는 y_hat을 획득하기 위하여 hs를 이용한다. 그것은 그 다음으로, 재구성된 이미지를 획득하기 위하여 y_hat을 gs로 공급한다. 디코더는 업샘플링 계층(57 내지 59, 및 510 내지 512)을 포함한다. 추가의 계층은, 컨볼루션 계층으로서 구현되지만, 업샘플링을 수신된 입력에 제공하지 않는 입력의 프로세싱 순서에서 업샘플링 계층(411 및 411) 사 이에 제공된다. 대응하는 컨볼루션 계층 \"conv Mx3x3/1\"은 또한, 디코더에 대하여 도시되어 있다. 이러한 계층 은 입력의 크기를 변경하는 것이 아니라 특정 특성을 변경하는 입력에 대한 동작을 수행하기 위하여 NN에서 제공될 수 있다. 그러나, 이러한 계층이 제공된다는 것은 필요하지 않다. 디코더를 통해 비트스트림2의 프로세싱 순서에서 보여질 때, 업샘플링 계층은 역방향 순서로, 즉, 업샘플링 계 층으로부터 업샘플링 계층으로 작동된다. 각각의 업샘플링 계층은 2의 업샘플링 비율을 갖는 업샘플링 을 제공하기 위하여 여기에서 도시되어 있고, 이것은 ↑에 의해 지시된다. 물론, 모든 업샘플링 계층이 동일한 업샘플링 비율을 가진다는 것이 반드시 그렇지는 않고, 또한, 3, 4, 8 등과 같은 다른 업샘플링 비율이 이용될 수 있다. 계층(57 내지 512)은 컨볼루션 계층(conv)으로서 구현된다. 구체적으로, 이것은 인코더의 입력에 역인 입력에 대한 동작을 제공하도로 의도될 수 있으므로, 업샘플링 계층은 디컨볼루션 동작(deconvolution operation)을 수신된 입력에 적용할 수 있어서, 그 크기는 업샘플링 비율에 대응하는 계수만큼 증가된다. 그러 나, 본 개시내용은 일반적으로 디컨볼루션으로 제한되지는 않고, 업샘플링은 2개의 이웃하는 샘플 사이의 쌍선 형 보간(bilinear interpolation)에 의한 것, 또는 최근접 이웃 샘플 복사(bilinear interpolation)에 의한 것 등과 같은 임의의 다른 방식으로 수행될 수 있다. 도 6은 심층 학습 기반 픽처(스틸 또는 비디오) 코덱의 일반적인 도면을 예시하고, 보조 정보는 제1 계층 후에 적용된다. 심층 학습 아키텍처는 조건적 오토-인코더 및 하이퍼 프라이어를 포함하는 임의의 아키텍처일 수 있 다. 조건적 VAE는, 보조 정보로서 본 명세서에서 지칭된 추가적인 정보를 수집함으로써 네트워크가 조절되는 것 을 의미한다. 이러한 보조 정보는 특징 데이터와 함께, NN의 하나 이상의 계층에 의해 프로세싱된다. 예를 들어, 픽처 인코더의 입력은 복수의 채널에서 제공될 수 있는 이미지이다. 도 6의 예시적인 표현은 픽처 코딩에서의 통상적인 접근법 중의 하나가 그러한 바와 같이, (예컨대, YUV 컬러 공간 등에서) 휘도(luminance) 및 2개의 서브샘플링된 색차(chrominance)를 갖는 3개의 컬러 채널을 도시한다. 일반적으로, 더 많은 채널(예컨 대, 백색(white)과 같은 추가적인 컬러, 또는 심도(depth) 또는 다른 특징, 예컨대, 모션(motion) 등) 또는 더 적은 채널(예컨대, 오직 하나의 그레이-스케일(gray-scale) 채널, 흑색-백색(black-white), 또는 컬러-팔레트 (color-palette) 등)이 있을 수 있다. 입력 픽처 채널은 입력 텐서 x 내로 배열되고, 인코더 신경망(600 A)으로 입력된다. 인코더 신경망(600A)은 예컨대, 일부 스트라이드(stride)를 갖거나 갖지 않는 컨볼루션, sigmoid, ReLU, 또는 GDN 등과 같은 비선형 활성화, 텐서의 차원을 변경하지 않는 일부 마스킹된 컨볼루션 (masked convolution) 등에 의해 구현될 수 있는 다운샘플링 계층을 포함할 수 있는 복수의 계층 또는 계층 스 테이지를 포함할 수 있다. 계층은 또한, 엔트로피 인코딩 또는 다른 프로세싱 계층을 포함할 수 있다는 것이 주 목된다. 입력 신호 X는 일부 비선형 동작(NonLinAct) 및 마스킹된 컨볼루션(MaskConv)과 함께, 컨볼루션(\"conv\") 및 다 운샘플링(\"↓\")을 포함하는 하나 이상의 계층에 의해 프로세싱될 수 있다. 인코더는 2개 이상의 계층을 포함하 고, 잠재 공간 내의 압축된 정보를 하나 이상의 비트스트림(\" \")(620 및/또는 630) 내로 기입할 수 있다. 예를 들어, 비트스트림 중의 하나(예컨대, 비트스트림)는 비트스트림1에 대응할 수 있고, 다른 하나(예컨 대, 비트스트림)는 도 1 내지 도 3에서 도시된 비트스트림2에 대응할 수 있다. 도 6에서, 스테이지 또는 계층은 다운사이징(프로세싱 방향에서 더 좁음)으로서 예시된다. 그러나, 이것은 예시 목적을 위한 것이고, 일 반적으로, 네트워크는 또한, 텐서 크기를 수정하지 않는 계층(들), 및/또는 심지어 텐서 크기를 증가시키는 계 층(들)을 포함할 수 있다. 계층 1 후에는, 보조 정보의 수집이 수행될 수 있다. 수집기는 보조 정보 를 수집할 수 있고, 그것을 계층 1의 출력 데이터와 조합할 수 있다. 조합된 정보는 그 다음으로, 추가의 프로 세싱을 위하여 계층 2에 입력된다. 이에 대응하여, 네트워크의 디코더 파트(600B)는 하나 이상의 비트스트림(620 및/또는 630)을 파싱하고, (디)컨 볼루션, 업샘플링(\"↑\"), 비선형 동작, 및 마스크 컨볼루션과 같은 하나 이상의 계층으로 신호를 재구성한다. 이 예시적인 디코더 네트워크(600B)는 인코더 네트워크(600A)에 대칭적이다(이것은 일반적으로 필연적이지 않음). 수집기는 보조 정보를 수집하고, 수집된 보조 정보와 마지막 하나 전의 계층의 출력과의 조합을 마 지막 디코딩 계층(인코더의 계층 1에 대칭적임)에 적용한다. 마지막 계층에 의한 프로세싱 후에, 출력 텐서, 예 컨대, 이 예에서는, 재구성된 픽처가 획득된다. 인코딩/디코딩 파이프라인 내에서의 보조 정보 픽처 코덱에서, 보조 정보는 인코더 및 디코더를 용이하게 하기 위하여 이용될 수 있다. 이 보조 정보는, 인코 딩된 또는 디코딩된 텐서와 함께, 코딩(인코딩 및/또는 디코딩) 파이프라인 내의 특정 하나 이상의 위치에서 적 용될 수 있다. 도 6의 예에서, 보조 정보는 제1 계층 후에 프로세싱된 신호를 인코딩하고 디코딩하는 것을 돕기 위하여 이용된다. 네트워크 아키텍처는 (픽처 인코딩 및 디코딩과 같은) 어떤 애플리케이션을 위하여 주로 사전 -정의되고 고정되므로, 이 보조 정보의 적용은 전형적으로, 도 6에서의 수집 블록(610 및 650)에 의해 도시된바와 같이, 프로세싱 파이프라인 내에서의 어떤 고정된 위치에 결부된다. 신경망에서 적용된 파라미터(예컨대, 가중치)는 통상적으로 사전-훈련된다(예컨대, 인코딩 및/또는 디코딩 전에 제공됨). 그러므로, 보조 정보를 적 용하는 가중치 및 위치가 미리 결정되기 때문에, 신경망의 아키텍처가 미리 결정된다. 이것은 네트워크의 유연 성, 및 인코딩된 또는 디코딩된 컨텐츠의 상이한 파라미터 및 특성에 대한 그 적응을 제한할 수 있다. 보조 정보에 대한 가능한 예는 입력 신호 x의 도메인에서 적용된 인터-예측된 프레임(예측)이다. 인접한 프레임 의 컨텐츠는 통상적으로 완전히 변경되지 않으므로, 인터-예측은 비디오 내의 이웃하는 프레임과 현재 프레임 사이의 시간적 중복성을 활용한다. 그 대신에, 컨텐츠는 통상적으로, 프레임을 가로질러서 조금 이동할 것이다. 그러므로, 인터-예측은 2개의 피스(piece)의 정보, 즉, 참조 픽처로서의 하나 이상의 인접한 프레임 및 모션 정 보(예컨대, 모션 벡터(들))를 요구한다. 인터-예측은 이 2개를 입력으로서 취하고, 현재 프레임에 대한 예측을 생성하기 위하여 모션 보상을 적용한다. 또 다른 형태의 예측은 하나의 프레임(픽처) 내의(내부의) 인트라 예측이다. 인트라 예측은 프레임의 내부의 공 간적 중복성을 활용한다. 프레임의 내부의 영역이 주어지면, 통상적으로, 영역의 동일한 값이 상관된다. 그러므 로, 인트라 예측은 동일한 프레임 내의 현재 위치에서 샘플의 값을 예측하기 위하여 프레임의 재구성된 이웃하 는 샘플을 이용한다. 도 7에서, 보조 정보로서의 예측의 시각적 예가 제공된다. 상부-좌측 이미지는 공통 테스트 시퀀스 BasketballDrill로부터의 예측 프레임이다. 예측은 입력 신호 x와 동일한 도메인에서, 즉, 이 예에서의 NN 입력 픽처 도메인에서 수행된다. 휘도 프레임의 원래의 폭 및 높이는 각각 W 및 H로 나타내어진다. 하부-좌측 코너에서 위치된 더 작은 프레임은 동일한 예측 프레임이지만, 하나의 채널 및 2의 다운샘플링을 갖는 하 나의 컨볼루션 계층 conv(1, ↓2) 후에 있다. 그러므로, 폭 및 높이의 둘 모두는 원래의 해상도의 절반, 즉, W/2 및 H/2이다. 우측 측부 상에는, 각각의 컨볼루션 계층에 대하여 2x의 다운샘플링을 갖는 N개의 컨볼루션 계 층 후의 잠재 공간 도메인에서의 예측의 예가 도시되어 있다. 그러므로, 이제는 예측의 폭 및 높이가 2N 더 작다. 도면은 다운샘플링된 프레임의 그리드(grid)이고, 여기서, 그리드 크기는 채널의 수 K에 의해 결 정된다. 여기서, 총 K = 13 * 11 = 143개의 채널이 있다. 다시 말해서, 모자이크 픽처는 K개의 채널 갖는 n개의 컨볼루션 계층 N * conv(K, ↓2) 후의 잠재 공간 도메인에서의 보조 정보(여기에서는, 예측)를 도시한다. 도 8은 다양한 프레임의 특성을 캡처하기 위하여 기존의 블록-기반 비디오 코덱(HEVC) 및 심층 학습의 둘 모두 를 채용하는 조합된 접근법을 도시하고, [Lu, Z. Ma, L. Xu, D. Wang, \"Tests on Decomposition, Compression, Synthesis (DCS)-based Technology(분해, 압축, 합성(DCS)-기반 기술에 대한 테스트)\", 원격회의에 의한 JVET- U0096, Joint Video Experts Team(공동 비디오 전문가 팀)(JVET) 21 번째 회의, 2021년 1월 6-15일]를 따른다. 예측과 같은 보조 정보는 코딩 파이프라인 내의 다수의 위치에서 채용된다. 도 8에서의 코딩 파이프라인은 3개 의 스테이지: 분해(decomposition), 압축(compression), 및 합성(synthesis)으로 분할될 수 있다. 도면에서, ↓는 다운-샘플링을 의미하고, ↑는 업-샘플링을 의미하고, E 및 D는 HEVC 비디오 인코더 및 디코더를 각각 나 타낸다. STF는 픽처의 그룹(GOP : group of pictures) 내의 인트라-예측된 프레임인 공간적 텍스처 프레임 (Spatial Texture Frame)을 나타낸다. TMF는 GOP 내의 인터-예측된 프레임인 시간적 텍스처 프레임(Temporal Texture Frame)을 나타낸다. HEVC 인코더 및 디코더의 예측 및 잔차 코딩은 HEVC 비디오 코덱 파이프라인 내의 정적(고정된) 장소에서 위치된다. 도 8에서, 입력 GOP는 먼저, 분해 스테이지에서 2개의 카테고리 STF 및 TMF로 분류된다. TMF 내의 모션 정보는 대략적 세분화도(coarse granularity)로 캡처될 수 있고, 그러므로, 이것은 인코딩되기 전에 다운-샘플링되고, 으로서 나타내어진다(즉, TMF에 대한 저-해상도 입력). 비교에 의해, STF는 표기 (즉, STF에 대한 원래의 고-해상도 입력)을 갖는 원래의 높은 해상도에서 인코딩된다. STF 및 다운-샘플링된 TMF의 둘 모두는 제2 압축 스테이지에서 기존의 HEVC 코덱을 이용하여 인코딩되고, 여기서, HEVC의 인코더 및 디코더는 각각 E 및 D로 라 벨 붙여진 박스에 의해 표현된다. TMF를 인코딩할 때, 그 참조 픽처는 (STF에 대한 재구성된 다운-샘플링된 저-해상도 신호)로서 나타내어진, STF의 재구성된 신호의 다운-샘플링된 버전이다. STF 및 TMF의 인코딩된 정보 는 비트스트림(들) 내로 기입된다. 나중에, 이것은 파싱되고, HEVC 디코더에 의해 STF 및 TMF를 재구성하기 위 하여 이용된다. 다시, TMF를 디코딩할 때, 그 참조 프레임은 STF의 다운-샘플링된 버전 이다. 압축 스테이지 의 출력은 각각 및 으로서 나타내어진, STF 및 TMF의 재구성된 신호이다.합성 스테이지에서, 재구성된 STF 및 TMF는 그 태생적 해상도에서 고-충실도(high-fidelity) 비디오를 생성하기 위하여 이용된다. 모션 보상 네트워크(모션 보상으로서 나타내어짐)는 먼저, 이웃하는 TMF를 가로질러서 정보를 어그리게이팅함으로써 현재 TMF의 시간적으로 평활하고 공간적으로 세분화된 모션 표현()을 생성하기 위하여 사용된다. 그 다음으로, STF로 나타내어진, 디코딩되고 업샘플링된 TMF()와 함께, 모션 보상 네트워크에 의 해 생성된 시간적 모션 특징 뿐만 아니라, 그 리-샘플링된 버전은 공간적 세부사항 및 시간적 평활도 (smoothness)의 둘 모두를 갖는 고-충실도 프레임 복원을 위한 교차-해상도 정보를 학습하고 전송하기 위하여 비-로컬 텍스처 전송 네트워크(non-local texture transfer network)로 공급된다. 하이브리드 코딩 파이프라인 은 모션 보상 네트워크에 의해 생성된 시간적 모션 특징, HEVC 인코더 및 디코더(그것은 도 8에서 도시되지 않 지만, 이것은 블록 E 및 D에서 이용됨)에서 이용된 예측 및 잔차 정보와 같은, 코덱 내의 상이한 위치에서의 보 조 정보를 이용한다. 그러나, 보조 정보는 코딩 파이프라인 내의 고정된 위치에서 적용된다. 이러한 구현예는 이미지 및 비디오 시퀀스의 특성을 효과적으로 적응시키지 못할 수 있고, 이 때문에, 차선의 코딩 결과로 귀착될 수 있다. 원래의 신호로부터 예측된 신호를 감산함으로써 획득된 잔차 신호(또한, 예측 오차 신호 또는 잔차 신호로서 지 칭됨)는 또한, 보조 정보로서 이용될 수 있다. 본 개시내용의 일부 실시예에서, 예측 및 잔차 신호는 입력 신호 x에 대해 동일한 도메인 뿐만 아니라, 인코더 파트(600A)의 프로세싱 순서에서의 하나 또는 몇몇 계층 후의 도 메인, 또는 이에 대응하여, 디코더 파트(600B)의 프로세싱 순서에서의 하나 또는 몇몇 계층 전의 도메인에서 발 생할 수 있다. 기존에는, 인코더 및/또는 디코더 내의 인코딩된 및/또는 디코딩된 텐서로 이 보조 정보를 사용 하는 위치는 고정된다. 그러나, 개념에 따라, 그리고 특히, 입력 픽처의 특성에 따라, 보조 정보는 코딩 파이프라인 내의 사전-설계된 고정된 위치에서 양호하게 수행되지 않을 수 있다. 그러므로, 코딩 파이프라인 내의 고정된 위치에서의 보조 정 보를 사용하는 것은 차선의 코딩 결과를 초래할 수 있다. 따라서, 입력 특성에 기초하여 상이한 위치에서 조건 적으로 이 보조 정보를 적용하는 적응적 해결책이 바람직할 수 있다. 수집 조건에 기초한 보조 정보 입력 위치의 선택 실시예에 따르면, 신경망을 이용하여 비트스트림으로부터 픽처 특징 데이터를 프로세싱하기 위한 방법이 제공된 다. 신경망은 계층으로서 이하에서 또한 지칭된 복수(즉, 2개 이상)의 신경망 계층을 포함한다. 이러한 신경망 (900B)은 도 9에서 예시된다. 용어 픽처 특징 데이터는 인코더 측에서의 픽처 프로세싱에 의해 획득된 임의의 잠재 공간 데이터를 지칭한다. 다시 말해서, 픽처 특징 데이터는 인코딩 프로세싱의 출력일 수 있다. 방법은 비트스트림에 기초하여 픽처 특징 데이터를 획득하는 것을 포함한다. 예를 들어, 픽처 특징 데이터 는 직접적으로 파싱될 수 있거나, 비트스트림으로부터 파싱되고 디코딩될 수 있다. 또한, 픽처 특징 데이터는 일부 프로세싱에 의해 디코딩된 데이터에 기초하여 획득될 수 있다. 방법은 신경망(900B)을 이용하여 픽처 특징 데이터를 프로세싱하는 것을 더 포함한다. 신경망 내에서의 하나 이상의 사전구성된 위치의 각각에 대하여, 프 로세싱하는 것은 다음을 포함한다: a) 수집 조건(910_1, 910_2, 910_3)에 기초하여, (특징 데이터 프로세싱 방향에서 사전구성된 위치를 따르는) 상기 사전구성된 위치에서 복수의 신경망 계층 중의 하나에 의한 프로세싱을 위한 보조 데이터를 수집 (960_1, 960_2, 960_3)할 것인지 또는 그렇지 않은지 여부를 결정함, b) 보조 데이터가 수집되어야 하는 것으로 결정되는 경우에, 상기 사전구성된 위치에서의 계층에 의한 프 로세싱은 보조 데이터에 기초함. 사전구성된 위치는 (동일한) 보조 정보의 수집이 가능한, 신경망 내에서의 위치이다. 오직 하나의 이러한 위치 또는 2개 이상(또는 심지어 모든) 이러한 위치가 있을 수 있다. 도 9에서는, 3개의 사전구성된 위치, 즉, 수집 (960_1, 960_2, 960_3)의 위치가 있다. 위에서 언급된 바와 같이, 네트워크 내에서의 위치는 예컨대, 픽처 특징 데이터의 프로세싱의 순서에서 위치에 선행하는 NN 모듈(여기서는, 계층)의 수에 의해 특정될 수 있다. 사전구 성된 위치는 신경망 네트워크의 일부로서 고정될 수 있다. 여전히, 보조 데이터가 하나 이상의 계층으로 입력되 는 것을 가능하게 하거나 금지함으로써, 유연성이 개선될 수 있다. 그럼에도 불구하고, 본 개시내용은 고정된 위치로 제한되지는 않는다. 대안적으로, 사전구성된 위치는 직접적으로 또는 간접적으로 비트스트림 내로 또한 포함된 부 정보에 의해 구성가능할 수 있다. 여기서, 직접적인 구성은 실제적인 위치를 시그널링할 수 있는 반 면, 간접적인 구성은 인코더 및 디코더에서 알려진 동일한 규칙에 기초하여, 그리고 (예컨대, 비트스트림으로부터의) 예컨대, 인코딩 파라미터의 값에 기초하여 수행될 수 있다. 보조 데이터가 어떤 계층에 의한 프로세싱을 위하여 수집되지 않아야 하는 것으로 결정될 때, 어떤 계층에 의한 프로세싱은 보조 데이터에 기초하지 않는다. 도 6에서의 예시적인 아키텍처에서, 보조 데이터가 도 6의 예에서 입력되는 위치는 고정되어, 제1 계층 후에 위치된다. 대조적으로, 도 9에서는, 상기 보조 정보가 신경망 내의 다수의 잠재적인 위치로 삽입될 수 있다. 이것은 신경망을 가로지르는 조건(물음표 마크 원으로서 라벨 붙여 짐)(910_1, 910_2, 및 910_3)에 의해 제어된 수집 유닛(960_1, 960_2, 및 960_3)에 의해 지시된다. 유사한 프로세싱은 인코더 측에서 수행된다. 인코딩 측 방법은 비트스트림을 생성하기 위하여 복수의 신경 망 계층을 포함하는 신경망(900A)으로 픽처를 프로세싱하기 위하여 제공된다. 방법은 신경망(900A)을 이용 하여 픽처를 프로세싱하는 것을 포함한다. 프로세싱하는 것은 신경망 내에서의 하나 이상의 사전구성된 위 치의 각각에 대하여: 수집 조건(910_1, 910_2, 및 910_3)에 기초하여, 상기 사전구성된 위치에서의 계층에 의한 프로세싱을 위한 보조 데이터를 (예컨대, 개개의 수집기(920_1, 920_2, 및 920_3)에 의해) 수집할 것인지 또는 그렇지 않은지 여부를 결정하는 것, 및 보조 데이터가 수집되어야 하는 것으로 결정되는 경우에, 상기 사 전구성된 위치에서의 계층에 의한 프로세싱이 보조 데이터에 기초한다는 것을 포함한다. 방법은 신경망에 의해 픽처를 프로세싱하여 획득된 데이터를 비트스트림 내로 삽입하는 것을 더 포함한다. 도 9에서 알 수 있는 바와 같이, 확률 모델 파라미터를 무손실성 인코딩에 제공하기 위한 하이퍼 프라이어 서브-네트워크가 적 용되는 경우에 제공될 수 있는 추가적인 비트스트림(또는 비트스트림 부분)이 있을 수 있다. 이러한 방식으로, 보조 정보를 적용하는 위치는 비디오 시퀀스 내의 이미지 또는 프레임의 컨텐츠 및/또는 특성 에 따라 동적으로 변경될 수 있다. 따라서, 보조 정보 및 대응하는 수집 파라미터를 적용하는 것은 상이한 위치 에서 발생할 수 있으므로, 본 구성가능한 신경망은 동적 아키텍처를 가진다. 본 명세서에서의 용어 수집 조건은, 예컨대, 이행될 때, 수집기가 보조 정보를 수집할 것인지 또는 그렇지 않은지 여부가 결정되는 요건을 지칭한다. 요건은 개개의 수집 유닛(960_1, 960_2, 및 960_3)(및 개개의 인코더 측 수집 유닛(920_1, 920_2, 및 920_3))에 대하여 상이할 수 있다. 이러한 결정은 보조 정보가 입력되는 위치의 선택과 동일한 효과를 가진다. 요건의 설계에 의해, 그것은 보조 정보가 사전구성된 위치로부터의 오직 하나에 대하여 선택되는 것일 수 있다. 이것은 예를 들어, 개개의 수집기에 대한 상호 배타적 요건(수집 조건)을 제공 함으로써 달성될 수 있다. 다시 말해서, 결정 단계에서 수집 조건을 적용하는 결과로서, 보조 데이터는 하나 이 상의 사전구성된 위치 중의 단 하나에 대하여 수집되어야 한다. 그러나, 위에서 언급된 예는 본 개시내용을 제한하기 위한 것이 아니다. 도 9에서 알 수 있는 바와 같이, 사전 구성된 위치에서 수집될 수 있는 하나의 피스 또는 유형의 보조 정보가 있다. 일부 예시적인 구현예에서, 결정 단계에서 수집 조건을 적용하는 결과로서, 동일한 보조 데이터는 상기 사전구성된 위치 중의 하나 초과에 대하여 수집되어야 한다. 보조 정보를 수집하는 것에 관한 위에서 설명된 접근법은 하나 초과의 유형의 보조 정 보에 적용될 수 있다. 그 다음으로, 보조 정보 유형의 각각에 대하여, 수집 위치(들)는 사전구성된 위치의 세트 로부터 결정될 수 있다. 사전구성된 위치의 세트는 상이한 유형의 보조 정보에 대하여 상이할 수 있다는 것이 주목된다. 그러나, 세트는 일부 유형의 보조 정보에 대하여 중첩할 수 있거나 심지어 동일할 수 있다. 예를 들 어, 보조 정보는 예측 신호, 예측 오차 신호, 확률 모델 등일 수 있다. 이것 중의 일부는 대응하는 위치에서의 동일하거나 중첩하는 스테이지에 적용가능할 수 있고, 예컨대, 예측 신호 또는 예측 오차 신호는 함께 이용될 수 있다. 보조 정보 유형의 일부는 상이한 스테이지, 예컨대, 잠재 공간 신호를 엔트로피 인코딩하기 위한 확률 모델에 적용가능할 수 있다. 신호를 본 명세서에서 지칭할 때, 의미하는 것은 주로, 인코딩 네트워크에 대한 입력 픽처 또는 디코딩 네트워 크에 대한 입력 픽처 특징 데이터, 또는 임의의 스테이지의 잠재 공간, 또는 보조 정보를 나타내는 데이터 등과 같은 이산 신호이다. 위에서 언급된 바와 같이, 신경망의 상이한 계층은 상이한 크기를 갖는 특징 텐서를 프로세싱할 수 있다. 픽처 프로세싱에서, 특징 텐서는 통상적으로, 도 7을 참조하여 이미 논의된 바와 같이, 3개의 차원, 즉, 채널의 폭, 높이, 및 수를 가진다. 폭 및 높이를 갖는 특징 픽처는 채널에 대응하는 것으로서 고려될 수 있다. 따라서, 파 이프라인의 다수의 스테이지에서 동일한 보조 정보의 (선택가능한) 수집을 지원하기 위하여, 일부 리사이징 또 는 리스케일링이 구현될 수 있다. 예를 들어, 예시적인 구현예에서, 상기 사전구성된 위치 중의 하나 초과는 사 전구성된다. 보조 데이터는 상기 사전구성된 위치 중의 2개 이상에서 계층에 의해 프로세싱된 입력 채널의 차원 을 정합하기 위하여 크기에 있어서 확장가능하다. 따라서, 이 예시적인 구현예에서, 결정 단계에서 수집 조건을 적용하는 결과로서, 보조 정보(데이터)는 (i) 수집될 수 있거나, (ii) 상기 사전구성된 위치 중의 단 하나에 대하여 수집되고 스케일링될 수 있다. 이것은 사전구성된 위치 중에서, 보조 정보가 수집되는 단 하나를 선택하는 것, 및 (필요한 경우에) 보조 정보를, 그것이 입력되어야 할 계층에 의해 프로세싱된 해상도에 적응시키는 것과 동등하다. 그러나, 본 개시내용은 적어도 하나의 위치에서 보조 정보를 항상 적용하도록 제한되지는 않는다. 그 적용의 결과로서, 보조 정보는 일부 픽처에 대한 사전구성된 정보 중의 임의의 사전구성된 정보에서의 수집이 아니도록 수집 조건을 설계하는 것이 상상가능하다. 다시 말해서, (iii) 보조 정보를 수집하지 않는 제3 가능성 이 구현될 수 있다. 본 명세서에서 설명된 실시예는 보조 정보의 확장가능한 수집에 초점을 맞춘다. 그러나, 이러한 선택가능한 수 집과는 별도로, 신경망 아키텍처는 기존의 조건적 VAE 프레임워크에서의 경우와 같이, 어떤 유형의 보조 정보가 (수집 조건을 이행하는 것과 같은 전제조건에 대한 종속성 없이) 항상 수집되는 하나 이상의 수집 스테이지를 제공할 수 있다. 이 실시예는 보조 정보를 적용하는 위치가 수집 조건에 따라 적응적으로 변경되는 것을 허용한다. 본 개시내용은 VAE와 같은 특정한 NN 프레임워크로 제한되지는 않는다는 것이 주목된다. 또한, 개시내용은 이미 지 또는 비디오 압축으로 한정되지 않고, 객체 검출, 객체 인식, 또는 분류 시스템 뿐만 아니라, 일반적으로, 픽처가 인간 시각 목적을 위하여 재구성되어야 하는 인간 시각 시스템(human vision system), 또는 세그먼트화 맵(segmentation map), 심도 맵(depth map), 객체 분류, 객체 검출 등과 같은 바람직한 출력을 도출하기 위하여 적당한, 픽처가 반드시 재구성되는 것이 아니라 픽처 특징이 프로세싱되는 머신 시각 시스템(machine vision system)을 포함하는 임의의 픽처 프로세싱 시스템에 적용될 수 있다. 도 10은 수집 조건이 비트스트림으로부터 획득된 픽처 특성 또는 픽처 특징 데이터 특성에 기초하는 예시적인 시스템을 도시한다. 도 10의 신경망은 입력 픽처를 프로세싱하고, 프로세싱된 픽처를 출력한다. 예를 들어, 픽처 특성 또는 픽처 특징 데이터 특성은 해상도를 포함한다. 수집 조건은 해상도와 사전구성된 해 상도 임계치와의 비교를 포함한다. 예를 들어, 픽처 해상도가 사전구성된 임계치를 초과하는 경우에, 보조 데이 터는 사전구성된 위치 중에서 제1 위치에 대하여 수집되어야 한다. 다른 한편으로, 픽처 해상도가 사전구성된 임계치를 초과하지 않는 경우에, 보조 데이터는 제1 위치와는 상이한, 사전구성된 위치 중의 제2 위치에 대하여 수집되어야 한다. 임계치는 신경망 네트워크의 설계의 일부로서 경험적으로 정의될 수 있거나, 대응하는 파라미 터를 비트스트림 내로 포함함으로써 훈련될 수 있고 및/또는 구성가능할 수 있다. 해상도에 기초한 조건에 추가적으로 또는 대안적으로, 예시적인 실시예에서, 픽처는 비디오 픽처이고, 픽처 특 성은 픽처 유형을 포함한다. 수집 조건은 픽처 유형이 시간적으로 예측된 픽처 유형 또는 공간적으로 예측된 픽 처 유형인지 여부를 결정하는 것을 포함한다. 공간적으로 예측된 픽처는 오직 그 자신의 픽처 내의 샘플을 이용 하여 예측된다. 이 경우에, 다른 픽처로부터의 샘플은 이용되지 않는다. 시간적으로 예측된 픽처는 다른 픽처 상의 샘플에 기초하여 시간적으로 예측된 일부 영역을 포함해야 한다. 그러나, 그것은 또한, 공간적 예측을 이 용하는, 즉, 그 자신의 픽처 내의 샘플을 이용하는 일부 영역을 포함할 수 있다. 픽처 유형 및 픽처 해상도의 둘 모두 또는 다른 픽처 특성은 인코더 및 디코더의 둘 모두에 알려져서, 이로써 이러한 두 측은 임의의 추가적인 부 정보를 요구하지 않으면서 동일한 방식으로 작동할 수 있다. 도 10에서, 제1 프로세싱 계층은 인코더(1010A) 내의 다운샘플링 계층, 및 디코더(1010B) 내의 업샘플링 계층이다. 이 예에서의 다운샘플링 및 업샘플링은 프레임의 폭 및 높이의 둘 모두에서 2의 계수만큼이다. 예측과 같은 보조 정보는 하나 초과의 위치: 인코더의 제1 계층 및 디코더의 대응하는 계 층의 전 및 후에서 잠재적으로 적용될 수 있다. 인코더 측에서는, 이 예에서, 수집 유닛이 2개의 입력 신호: 인코딩되어야 할 원래의 프레임의 전체 크기 에서의 하나, 및 원래의 프레임의 다운샘플링된 버전에 대응하는, 원래의 프레임 크기(전체 크기)의 1/4 크기에 서의 다른 하나의 가중화된 합이다. 예를 들어, (1, 0)의 가중치 쌍은, (가중화 계수 0에 의해 지시된) 1/4 크기가 아니라, (가중화 계수 1에 의해 지시된) 전체 크기에서의 보조 정보를 이용하는 인코딩을 지시하는 반면, (0, 1)의 가중치 쌍은 전체 크기가 아 니라 1/4 크기에서의 보조 정보를 이용하는 인코딩을 나타낸다. 이러한 방식으로, 보조 정보를 적용하는 위치는 신경망에서 구성가능하게 될 수 있다. 보조 정보가 어디에서 이용되는지를 제어하기 위한 조건은 예를 들어, 원 래의 프레임의 프레임 크기(해상도), 및/또는 프레임 유형일 수 있다. 예를 들어, 조건은 프레임 크기가 4K 해상도 이상인지 여부, 및 프레임 유형이 인터 프레임인지 여부일 수 있다. 예시적인 구현예에서, 조건이 참(true)일 때, (0, 1)의 가중치 쌍이 이용되므로, 이 입력 프레임은 보조 정보를 이용하여 1/4 크기에서 인코딩된다. 다른 프레임은 보조 정보를 이용하여 그 원래의 해상도에서 인코딩 된다. 보조 정보를 적용하는 위치는 프레임 유형 및/또는 프레임 크기에 기초하여 프레임 레벨에서 동적으로 변 경될 수 있다. 다시 말해서, 도 10에서는, 수집 유닛(및 대응하게도 디코더에서는 1060)이 단지 가중화된 합인 예가 도 시되어 있다. 가중치는 위에서 설명된 바와 같은 값 (1, 0) 또는 (0, 1)을 가질 수 있다. 가중치 (1, 0)은 전체 크기 픽처가 인코딩된다는 것을 의미하고, 가중치 (0, 1)은 코딩이 2에 의해 다운샘플링된 신호에 대응하는, 1/4 크기의 신호에 대하여 수행된다는 것을 의미한다. 이 예에서의 수집 조건은, 비디오가 4K 이상의 해 상도를 가지고, 동시에, 고려 중인 프레임이 시간적으로 예측된 프레임인지 또는 그렇지 않은지 여부이다. 그러 나, 위에서 주목된 바와 같이, 본 개시내용은 이러한 조합된 수집 조건으로 제한되지는 않는다. 오히려, 임계치 해상도는 오직, 해상도가 어떤 값을 초과하거나 해상도의 어떤 세트에 속하는지 또는 그렇지 않은지 여부일 수 있다. 대안적으로, 해상도를 고려하지 않으면서, 프레임 유형은 오직 평가된 조건일 수 있다. 별도로 또는 조합 하여 이용되어야 할 다른 조건을 수반하는 추가의 예가 가능하다. 예를 들어, 예측 모드, (예컨대, 모션 세기 또는 유형을 도출하기 위한) 모션 정보 등과 같은 코딩 파라미터는 수집 조건에서 적용될 수 있다. 위에서 설명된 예시적인 실시예에서의 신경망의 구성가능성은 컨텐츠 적응적 조 건에 기초하여 특정 장소에서 보조 정보를 온/오프로 스위칭함으로써 달성된다. 컨텐츠는 도 10의 예에서 도시 된 바와 같은 프레임 크기 및 프레임 유형과 같은 이미지의 직접적인 특성을 포함할 수 있다. 그러나, 특성은 또한, 주어진 영역에서의 샘플 값의 히스토그램(histogram)과 같은, 컨텐츠의 간접적인 특성일 수 있다. 컨텐츠 의 세분화도는 또한, 변경가능할 수 있다. 예를 들어, 보조 정보의 위치를 결정하는 조건은 프레임 레벨, 블록 레벨, 또는 픽처의 그룹의 레벨 또는 임의의 양의 픽처에서 업데이트될 수 있다. 다시 말해서, 일부 실시예에서, 신경망은 비디오 픽처의 프로세싱을 수행하도록 훈련된다. 상기 사전구성된 위치에서의 계층에 의 한 프로세싱을 위한 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여부의 결정은 미리 결정된 수의 비디오 픽처마다 수행되고, 여기서, 미리 결정된 수의 비디오 픽처는 하나 이상이다. 조건은 마찬가지로 상이한 형태를 가질 수 있다. 그것은 이하에서 설명되는 바와 같이, 디코더에서의 파싱된 플 래그로부터 결정될 수 있다. 인코더에서, 플래그 값은 일부 RDO 계산에 기초하여 또는 다른 비용 함수에 기초하 여 결정될 수 있다. 조건은 명시적으로 시그널링되는 것이 아니라, 비디오 시퀀스 내의 이미지/프레임의 다른 정보에 의해 결정되는 것이 또한 가능하다. 보조 정보를 적용하기 위한 유연한 위치의 이점 중의 하나는, 그것이 픽처 또는 프레임을 적응적으로 인코딩하 고 디코딩할 수 있고, 이 때문에, 더 양호한 성능으로 귀착될 수 있다는 것이다. 더 양호한 성능은 동일한 품질 에서의 결과적인 비트스트림의 더 낮은 레이트 또는 그 반대(동일한 레이트에서의 더 높은 품질)를 포함 할 수 있다. 실시예에 따르면, 방법은 방법은 디코더 측에서, 하나 이상의 사전구성된 위치에 대하여, 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여부를 특정하는 지시를 비트스트림으로부터 획득하는 단계를 포함한다. 하나 이상 의 사전구성된 위치의 각각에 대한 수집 조건은 다음과 같다: - 지시가 상기 사전구성된 위치에 대하여, 보조 데이터가 수집되는 것으로 특정하는 경우에, 결정은 긍정적임; 및 - 지시가 상기 사전구성된 위치에 대하여, 보조 데이터가 수집되지 않아야 하는 것으로 특정하는 경우에, 결정 은 부정적임. 지시는, 비트스트림 신택스에 의해 지원되고, 어떤 위치에서 어떤 보조 정보를 수집할 것인지 또는 그렇지 않은 지 여부를 직접적으로 지시하는 플래그일 수 있다. 대안적으로, 지시는 그 신택스에 따라 비트스트림 내에 직접 적으로 포함될 수 있고, 보조 정보가 수집되어야 하는 사전구성된 위치 중에서 단 하나를 특정할 수 있다. 지시 자는 또한, 보조 정보가 사전구성된 위치 중의 임의의 것에서 수집되지 않아야 하는 것으로 지시하는 값을 취하 도록 설계될 수 있다. 이 실시예에서, 수집 조건은 지시자를 평가하는 것에 기초한다. 위에서 언급된 실시예는 보조 정보를 참조하여 설명되었다. 일반적으로, 보조 정보(또는 보조 데이터)는 출력을 생성하기 위하여 신경망에 의해 프로세싱된 픽처 특징 데이터에 대한 일부 (보충적) 정보를 제공한다. 도 11에 서 또한 도시되는 특정한 예에서, 보조 데이터는, (예컨대, 인코더에 대한 입력 픽처 도메인에서의) 픽처의 예 측이거나, (예컨대, 인코더에 대한 입력 픽처 도메인 이외의 것에서의) 신경망의 계층 중의 하나 이상에 의한프로세싱 후의 픽처 특징 데이터의 예측인 예측 데이터를 포함한다. 도 11에서 도시된 바와 같이, 일부 예시적인 구현예에서, 보조 데이터는, 예측 데이터, 및 예측 데이터와 조합 되어야 할 보충적 데이터의 결합된 쌍이다. 여기에서의 용어 \"결합된(coupled)\"은 예측 및 보충적 데이터가 동 일한 파이프라인 위치(스테이지)로부터 취해진다는 사실을 지칭한다. 보충적 데이터는 예를 들어, 특정 경우에 예측 잔차(예측된 픽처와 픽처의 예측 사이의 차이)일 수 있는 예측 오차 데이터(예측 오차를 나타내는 데이 터)일 수 있다. 예측 및 잔차 신호는 도 11에서 도시된 바와 같이, 신경망 내의 제로, 하나, 또는 몇몇 계층 후 에 획득될 수 있다. i 번째 위치에서 보조 정보를 적용하는 것은, 파이프라인 내의 i 번째 위치에서 변환을 위 한 보조 정보를 이용하는 것을 의미한다. 여기에서의 변환은 계층에 의해 수행된 일반적인 변환, 또는 네트워크 의 프로세싱 단계(계층)로서 수행된 실제적인 주파수 도메인 변환, 예컨대, 푸리엔 변환(Fourier transformation)(예컨대, 고속 푸리에 변환(FFT : fast Fourier transformation) 또는 이산 코사인 변환(DCT : Discrete Cosine Transformation) 또는 그 정수 버전 등)과 같은 직교 변환(orthogonal transformation)일 수 있다. 위에서 언급된 바와 같이, 일반적으로, 보조 정보는, 수집 위치에 따라, 인코더 측 입력 신호 또는 코딩 파이프라인 내의 잠재 공간 표현과 동일한 크기를 가질 수 있는 텐서이다. 일반적으로, 예측 및 잔차 신호를 적용할 수 있는 위치의 수는 N+1이다. 이것은 디코더 측에서 입력 신호(NN에 대한 입력) 및 인코더에서 출력 신호를 나타내는 위치 0 뿐만 아니라, N개의 추가의 위치 1 내지 N에 대응한다. 사전구성된 위치는 반드시 각각의 계층 후에 제공되지는 않는다는 것이 주목된다. 도 11은 보조 정보가 예측 및 잔차 신호인 예를 도시한다. 이것은 몇몇 위치에서 수집될 수 있고, 이것은 신경망의 인코더 파트(1100A) 및 디 코더 파트(1100B)에서 수집 유닛을 몇 회 제공함으로써 예시된다. 도 11의 예에서, 이 위치 중의 단 하나는 인코딩 및 디코딩 동안에 예측 신호 및 잔차 신호를 적용하고 있다. 다시 말해서, 보조 정보를 적용하는 위치는 중복되는 것이 아니라, 오히려, 코딩 파이프라인에서 변경된다. 수 집 스테이지는 예측 신호(predi)를 보조 정보로서 수집하는 것, 및 (디코더 프로세싱의 방향에서 계산된) i 번째 위치의 픽처 특징 데이터로부터 예측을 감산함으로써 잔차(resii)를 계산하는 것을 포함 한다. 잔차는 그 다음으로, 비트스트림에서 인코딩된다. 따라서, 예컨대, 모션 보상 프로세싱 또는 인트 라-예측 프로세싱 등을 포함할 수 있는 프로세싱에 의해 획득되는 예측에 잔차를 가산함으로써, 잔차가 디코더(1100B)에서 수집될 수 있다. 인코더 측에서, 방법은 하나 이상의 사전구성된 위치에 대하여, 레이트, 왜곡, 정확도, 레이턴시, 또는 복잡도 중의 적어도 하나를 포함하는 비용 함수의 최적화에 기초하여 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여부를 선택하는 단계를 더 포함할 수 있다. 다시 말해서, 위치는 RDO 또는 유사한 접근법에 의해 결정될 수 있 다. 예를 들어, 인코더 측 상에서는, 보조 정보가 적용되는, 파이프라인 내의 스테이지에 대한 판정이 멀티-패 스(multi-pass) 인코딩에 의해 수행될 수 있다. 하나의 예에서, 보조 정보를 적용하는 것은 위에서 언급된 바와 같은 하나의 위치에서만 허용된다. 이 경우에, i=0, 1, 2, .., N개의 사전구성된 위치에 대한 인코더는 파이프 라인의 i 번째 위치에서 보조 정보를 적용하도록 시도하고, 각각의 변형에 대한 왜곡 및 레이트를 획득한다. 그 다음으로, 정의된 레이트/왜곡 비율에 대한 최상의 변형(위치)이 선택된다. 또 다른 예에서, 보조 정보를 적용하는 것이 파이프라인 내의 임의의 하나 이상의 위치에서 가능한 경우에, 길 이 (N+1)의 각각의 불리언 벡터(Boolean vector)에 대한 인코더는 이 불리언 벡터에서의 위치에 대응하는 위치 에서 보조 정보를 적용하도록 시도하므로, 2N+1 개의 변형이 시도된다. 검색 공간은 일부 선험적 지식(a-priori knowledge)이 고려되는 경우에 감소될 수 있다. 불리언 벡터는 각각의 위치 i에 대하여, 보조 정보가 그 위치에 서 수집되는지 또는 그렇지 않은지 여부를 지시한다. 그러나, 본 개시내용은 보조 정보로서의 예측 및 예측 잔차로 제한되지는 않는다. 오히려, 보조 데이터는 디코 딩 프로세싱에서의 방향성을 가능하게 하는 일종의 안내 데이터로서 적용된다. 다시 말해서, 보조 데이터는 일 부 보충적 정보에 의해 프로세싱을 조절한다. 일반적으로, 보조 데이터는 생성형(generative) 네트워크를 돕기 위한 라벨(label) 또는 다른 데이터일 수 있다. 본 개시내용에서, 예측 및 잔차 신호의 의미는 약간 일반화되고, 즉, 예측 및 잔차 신호가 입력 신호 x의 동일 한 도메인에서 생성되는 HEVC와 같은 기존의 코덱과 달리, 본 명세서에서의 예측 및 잔차 신호는 도 11에서 도 시된 바와 같이, 신경망 내의 하나 또는 몇몇 계층 후의 신호를 지시할 수 있다. 도 11의 실시예에서는, 예측 및 잔차 신호가 결합되고, 즉, 공동-위치된 예측 신호 predi 및 잔차 신호 resii는 수집 조건이 충족될 때에 동시에 이네이블되거나 디세이블된다. 그러나, 예측 데이터 및 보충적 데이터가 네트워크 내의 상호 상이한 위치에서의 계층에 의해 프로세싱된 데이 터의 차원을 가지는 실시예가 있다. 다시 말해서, 이것은 상이한 스테이지로부터 수집된다. 예측의 (선택된) 수 집 위치 및 잔차의 (선택된) 수집 위치는 상이할 수 있다. 이러한 접근법의 일부 실시예는 섹션 \"신경망의 상이 한 스테이지로부터의 데이터의 조합(Combining data from different processing stages of the neural network)\"에서 이하에 설명될 것이고, 본 명세서에서 설명된 바와 같은 수집 위치를 변경하는 것과 조합될 수 있다. 도 12는 일부 실험적 데이터를 도시한다. 실험에서, 네트워크 구성은 입력 신호의 분석에 기초하여 선택될 수 있다. 이 분석은 주파수 도메인에서 행해진다. 2 차원 고속 푸리에 변환(참조. https://www.mathworks.com/help/matlab/ref/fft2.html)에 대응하는 변환 FFT2가 스펙트럼 분석을 수행하기 위 한 변환 툴(transform tool)로서 이용되는 예가 도 12에서 주어진다. 주어진 이미지에 대하여, 통상의 기술자는 2x의 다운샘플링을 갖는 네트워크 계층 전 또는 후의 FFT2 변환에 의해 도입된 스펙트럼 변경을 예측(또는 측정)할 수 있다. 현저한 신호 에너지가 보존되는 경우에, 아마도, 원래의 픽처와 재구성된 픽처 사이의 오차는 무시가능하므로, 보조 신호를 더 낮은-해상도 표현에 적용하는 것이 유리하다. 도 12는 다음의 분석 스테이지를 도시한다. 스테이지 (a)는 입력(원래의) 픽처를 도시한다. 여기서에서의 실험은 2개의 상이한 픽처((a) 참조, 상부 및 하부)에 대하여 수행되었다. 스테이지 (b)는 FFT2가 원래의 이미지에 적용되는 경우에 FFT2 결과를 도 시한다. 스테이지 (c)는 FFT2가 2만큼의 다운샘플링 후의 원래의 픽처에 적용될 때의 FFT2 결과를 도시한다. 스 테이지 (d)는 서브샘플링된 신호에 기초하여 재구성된 이미지를 도시한다. 스테이지 (e)는 재구성된 이미지에 적용된 FFT2를 도시한다. 스테이지 (f)는 재구성된 이미지와 원래의 이미지 사이의 차이를 도시한다. 스테이지 (g)는 차이 이미지의 FFT2를 도시한다. 알 수 있는 바와 같이, 도 12에서의 상부 상의 이미지는 더 적은 고-주 파수 컴포넌트를 가진다. 재구성된 프레임은 우선, 다운-샘플링된 해상도에서 보조 신호를 적용하고, 그 다음으 로, 업샘플링을 수행함으로써 획득된다. 이러한 리샘플링은 신호 컨텐츠에 대한 영향을 거의 가지지 않는다. 대 조적으로, 고-주파수 에너지의 손실은 더 많은 고-주파수 컴포넌트가 관찰되는 하부에서의 이미지에 대한 픽처 세부사항 및 주파수 컴포넌트의 둘 모두에서 명백하다. 이 관찰은 다른 변환에 대해서도 마찬가지로 유효할 가 능성이 있다. 전반적으로, 네트워크는 이러한 방식으로 적응적으로 구성되어, 이로써 보조 신호는 적절한 해상 도를 갖는 컨볼루션 계층에 적용되고, 여기서, 입력 신호의 스펙트럼 에너지는 충분하게 보존된다. 수집 조건은 FFT2, 또는 일부 스펙트럼 정보를 제공할 수 있는 또 다른 변환에 기초한다는 것이 상상가능하다. 예를 들어, 스펙트럼 분포의 일부 통계적 파라미터는 보조 정보가 어느 위치에서 수집되어야 하는지에 대해 정의하도록 임 계화(threshold)될 수 있다. 본 개시내용은 예측 신호 및 잔차 신호를 보조 정보로서 제공하는 것으로 제한되지는 않는다는 것이 주목된다. 또 다른 예시적인 가능성은 무손실성 압축에서의 보조 정보의 적용이다. 따라서, 보조 정보가 적용될 수 있는 잠재적인 위치는 신호가 무손실성으로 프로세싱될 수 있는 위치를 포함한 다. 도 13에서 도시된 바와 같이, 신경망은 신호 y_hat이 위에서 도 1 내지 도 3을 참조하여 설명된 바와 같이 디코더로부터 무손실성으로 복원될 수 있는 서브-네트(sub-net)를 포함할 수 있다. 실시예에 따르면, 신호 y- hat를 획득한 후에 수집 유닛이 있고, 여기서, 보조 정보는 신경망에서 나중에 적용될 수 있다. 다시 말해서, 실시예에서, 신경망은 적어도 하나의 계층을 갖는 무손실성 디코딩을 위한 서브-네트워크를 포함 하고, 보조 정보는 무손실성 디코딩을 위한 상기 서브-네트워크로 입력된다. 수집 조건은 이에 따라, 엔 트로피 코딩(VAE 프레임워크에 대하여 위에서 설명된 바와 같은 인코딩 및 디코딩)을 위한 확률 모델이 무손실 성 코딩 서브-네트로부터의 보조 정보로서 제공되는지 또는 그렇지 않은지 여부를 제어할 수 있다. 보조 정보가 제공되지 않아야 하는 경우에, 확률 모델은 예컨대, 디폴트 확률 분포(default probability distribution)에 의해, 또는 비트스트림 시그널링 등에 의해 결정될 수 있다. 한편으로 서브-네트에 의해 야기된 복잡도 및 레이 턴시, 및 결과적인 비트스트림 크기를 감소시키는 것에 대한 서브-네트의 기여를 고려하여, 수집 조건은 비용 함수 등에 기초한 최적화에 기초할 수 있다. 대안적으로, 수집 조건은 이전에 코딩된 데이터의 통계, 예컨대, 그 분산(variance)에 기초할 수 있다. 거의 정지되거나 느리게 변경되는 경우에, 서브-네트로부터의 보조 정보 의 적용이 필요하지 않을 수 있다. 일반적으로, 신경망은 스틸 픽처 디코딩, 비디오 픽처 디코딩, 스틸 픽처 필터링, 비디오 픽처 필터링, 및 객체 검출, 객체 인식, 또는 객체 분류를 포함하는 머신 시각 프로세싱 중의 적어도 하나를 수행하도록 훈련될 수 있 다.위에서 언급된 인코딩 및/또는 디코딩은 제1 보조 데이터 및 제2 보조 데이터를 포함하는 복수의 보조 데이터의 각각에 대하여 수행될 수 있고, 여기서, 제1 보조 데이터는 하나 이상의 사전구성된 위치의 제1 세트와 연관되 고, 제2 보조 데이터는 하나 이상의 사전구성된 위치의 제2 세트와 연관된다. 다시 말해서, 본 개시내용은 동일 한 네트워크에서 상이한 유형의 보조 데이터에 적용될 수 있다. 예를 들어, 제1 보조 데이터는 예측 및 잔차 신 호이고, 제2 보조 데이터는 무손실성 코딩을 위한 확률 모델이다. 일부 실시예에서, 하나 이상의 사전구성된 위 치의 제1 세트 및 하나 이상의 사전구성된 위치의 제2 세트는 적어도 하나의 사전구성된 위치를 공유한다. 그러 나, 이것은 오직 예시적이고, 일부 경우에는, 세트가 임의의 사전구성된 위치를 반드시 공유하지는 않는다. 이 것은 예를 들어, 제1 데이터로서의 예측/잔차 및 제2 데이터로서의 확률 모델의 예에서도 마찬가지일 수 있다. 도 9에서 도시된 바와 같이, 구성가능한 조건적 오토-인코더 신경망은 예시적인 실시예로서 제공되었다. 이 아 키텍처 내에서, 예측 및/또는 잔차와 같은 보조 정보를 적용하는 위치는 조건에 기초하여 적응적으로 결정될 수 있다. 그러므로, 신경망의 아키텍처는 비디오 시퀀스 내의 이미지 또는 프레임의 특성에 따라 동적으로 변경될 수 있다. 일반적으로, 본 개시내용의 실시예는 신경망 기반 픽처 코덱을 동적으로 구성가능하게 하는 접근법을 제공하고, 여기서, 코딩 파이프라인에서 보조 정보를 적용하는 위치가 조건에 종속된다. 보조 정보는 예측 및 잔차 신호의 결합된 쌍일 수 있다. 쌍을 이룬 예측 및 잔차 신호는 입력 신호 x에 대한 동일한 도메인 또는 신경망의 하나 이상의 계층에 의한 프로세싱 후의 도메인의 어느 하나에서 위치될 수 있다. 보조 정보를 적용하는 위치는 변경 가능하고, 이것은 수집 조건에 기초하여 신경망 내의 잠재적인 위치 중에서 배타적으로 하나의 특정 위치에서 보조 정보를 이용함으로써 달성될 수 있다. 이러한 수집 조건은 컨텐츠 적응적 방식으로 보조 정보를 적용하는 위치를 제어하고, 즉, 조건은 입력 신호(픽처)의 하나 이상의 특성에 기초하여 결정될 수 있다. 또한, 보조 정 보를 적용하는 위치를 제어하는 조건은 현장에서(on the fly) 업데이트될 수 있고, 예컨대, 비디오 시퀀스를 인 코딩할 때, 조건은 (프레임 내의) 블록 레벨에서, 또는 프레임 레벨에서, 또는 프레임-그룹(group-of-frame) 레 벨에서 업데이트될 수 있다. 보조 정보를 적용하는 잠재적인 위치 중의 하나는 도 13에서 도시된 바와 같이, 신 호가 무손실성으로 코딩되는 위치이다. 위치 변경은 2개 이상의 독립적인 보조 신호에 적용될 수 있다. 2개의 독립적인 보조 신호 A1 및 A2가 주어지는 경우에는, 각각 A1 및 A2를 적용하는 잠재적인 위치의 2개의 대응하는 세트가 있어야 한다. 잠재적인 위치의 이 2개의 세트가 S1 및 S2인 것으로 추정하면, S1 및 S2에서의 위치는 한 정되지 않고, 즉, 이것은 중첩될 수 있거나 그렇지 않을 수 있다. 동일 사항은 2개 초과의 독립적인 보조 신호 에 적용된다. 실시예는 주로 방법의 측면에서 설명되었다. 그러나, 본 개시내용은 그것으로 제한되지는 않는다. 오히려, 본 발명은 또한, 복수의 신경망 계층을 포함하는 신경망을 이용하여 비트스트림으로부터의 픽처 특징 데이터를 프 로세싱하기 위한 장치에 관한 것이다. 장치는 비트스트림으로부터 픽처 특징 데이터를 획득하고; 신경망을 이용 하여 픽처 특징 데이터를 프로세싱하도록 구성된 프로세싱 회로부를 포함하고, 여기서, 신경망 내에서의 하나 이상의 사전구성된 위치의 각각에 대하여, 프로세싱하는 것은, 수집 조건에 기초하여, 상기 사전구성된 위치에 서의 복수의 신경망 계층 중의 하나에 의한 프로세싱을 위한 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여부를 결정하는 것, 및 보조 데이터가 수집되어야 하는 것으로 결정되는 경우에, 상기 사전구성된 위치에서의 계층에 의한 프로세싱이 보조 데이터에 기초한다는 것을 포함한다. 프로세싱 회로부는 도 26 내지 도 29를 참조 하여 상세하게 설명되는 바와 같이, 예컨대, 대응하는 소프트웨어에 의해 구성된 하나 이상의 프로세서일 수 있 다. 유사하게, 본 발명은 비트스트림을 생성하기 위하여 복수의 신경망 계층을 포함하는 신경망으로 픽처를 프로세 싱하기 위한 장치에 관한 것이고, 장치는 다음을 포함한다. 프로세싱 회로부는, 신경망으로 픽처를 프로세싱하 도록 구성되고 - 프로세싱하는 것은 신경망 내에서의 하나 이상의 사전구성된 위치의 각각에 대하여, 수집 조건 에 기초하여, 상기 사전구성된 위치에서의 계층에 의한 프로세싱을 위한 보조 데이터를 수집할 것인지 또는 그 렇지 않은지 여부를 결정하는 것, 및 보조 데이터가 수집되어야 하는 것으로 결정되는 경우에, 상기 사전구성된 위치에서의 계층에 의한 프로세싱이 보조 데이터에 기초한다는 것을 포함함 -; 신경망에 의해 픽처를 프로세싱 하여 획득된 데이터를 비트스트림 내로 삽입하도록 구성된다. 프로세싱 회로부는 도 26 내지 도 29를 참조하여 상세하게 설명되는 바와 같이, 예컨대, 대응하는 소프트웨어에 의해 구성된 하나 이상의 프로세서일 수 있다. 신경망의 상이한 프로세싱 스테이지로부터의 데이터의 조합 도 14는 픽처 데이터의 프로세싱을 위한 신경망, 및 특히, 인코더 측 및 디코더 측에 적용된 번호부여된 계층의 아키텍처를 예시하는 블록도이다. 입력 픽처는 입력 데이터 텐서로 스택(stack)되고, 인코더 측의 신경망(1400A)으로 입력된다. 도면에서 알 수 있는 바와 같이, 인코더-측 네트워크(1400A)는 1부터 K까지 번호부여되 는 복수의 캐스케이딩된 프로세싱 계층(또는 계층의 블록)을 포함한다. 스테이지는 여기서, 프로세싱된 특징 텐 서의 스테이지를 나타낸다. 병목에서의 신경망의 출력에 대응하는 마지막(K 번째) 스테이지까지, 입력 데이터 텐서는 0 번째 스테이지에 대응하고, 계층 1로 입력 데이터 텐서를 프로세싱한 후의 특징 텐서는 1 번째 스테이 지에 대응하는 등과 같다. 여기에서의 출력은 비트스트림을 형성하기 위하여 (예컨대, 위에서 예시된 바 와 같은 산술 인코더에 의해) 인코딩될 수 있는 병목 특징 텐서(또한, 출력 또는 잠재 공간 텐서 또는 출력 특 징 데이터로서 지칭됨)에 대응한다. 디코딩 측 네트워크(1400B)는 K부터 1까지 번호부여되는 복수의 캐스케이딩된 프로세싱 계층(또는 계층의 블 록)을 포함한다. 이 예에서, 본 명세서에서의 프로세싱 계층(또는 계층의 블록)은 설명의 단순화를 위하여 인코 더 측에서의 개개의 프로세싱 계층(또는 계층의 블록)에 대응한다. 일반적으로, 인코더 측 네트워크 및 디코더 측 네트워크는 반드시 엄격하게 대칭적일 필요가 없다는 것이 주목되고, 이것은 두 네트워크가 동일한 수의 계 층을 가지는 것을 요구하지 않지만, 동일한 수의 계층을 여전히 가질 수 있다는 것을 의미한다. 특정한 아키텍 처는 이것이 전개되는 작업에 종속될 수 있다. 심지어 동일한 작업(예컨대, 비디오/이미지 코딩)에 대하여, NN 의 구조가 상이할 수 있다. 그럼에도 불구하고, 인코더 측에서의 다운샘플링 계층의 수는 대부분의 경우에 디코 더 측에서의 업샘플링 계층의 수이다. 디코딩 측 네트워크의 출력은 이 예에서, 재구성된 픽처이다. 그러나, 일반적으로, 디코딩 측의 출력은 인간 관측을 위하여 재구성된 픽처일 필요가 없다. 그것은 컴퓨터 시각 프로세싱 등과 같은 컴퓨터 프로세싱을 위한 특징 데이터 또는 이러한 컴퓨터 프로세싱의 결과일 수 있다. 도 15는 파이프라인의 동일한 스테이지에서의 픽처 데이터의 인코딩 및 디코딩을 위하여 예측 및 예측 잔차를 이용하는 신경망에서의 프로세싱 및 데이터 흐름을 더 상세하게 도시한다. 특히, 이 예측 및 잔차는 파이프라인 의 동일한 스테이지, 즉, 0 번째 스테이지에서 이용된다. 이것은 위에서 설명된 바와 같은 위에서 언급된 보조 정보 입력 위치 선택의 고정된 배열 또는 결과일 수 있다. 이 예에서는, 도 11을 참조하여 설명된 네트워크가 더 상세하게 도시되어 있다. 도 15는 현재 픽처, 즉, 시간 인스턴스 t+1에서의 프레임을 프로세싱하는 인코딩 및 디코딩 네트워크를 하부 파트 상에서 도시한다. 네트워크는 기본적으로, 도 14를 참조하여 설명 된 네트워크(1400A 및 1400B)에 대응한다. 그러나, 인코더 측 및 디코더 측에서의 스테이지 0에서는, (유사하게 는, 도 11에서 도시된 바와 같이) 보조 정보가 수집된다(1560, 1565). 인코더 측에서의 수집된 정보는 예측 신호이다. 예측 신호는 (수집기에 대응하는) 부분 내의 0 번째 스테 이지에서의 입력 픽처 데이터(입력 텐서)와 조합된다. 즉, 입력 텐서와 예측 사이의 엘리먼트별 차이가 계산되 고, 추가로 인코딩되는, 즉, 네트워크의 인코딩 측으로 프로세싱되고 비트스트림 내로 삽입되는 잔 차가 획득된다. 엘리먼트별 차이는 데이터의 공통적인 이용 또는 조합을 구현하는 오직 하나의 예시적인 가능성 인 것이 주목된다. 일반적으로, 조합은 상이한 방식으로 수행될 수 있다. 예를 들어, 2개의 조합된 종류의 데이 터가 상이한 해상도 또는 차원을 가지는 경우에, 조합은 리스케일링을 추가로 수반할 수 있다. 신경망 아키텍처 및 네트워크의 훈련에 따라서는, 일반적으로, 연접 등과 같은 다른 종류의 조합이 이용될 수 있다. 따라서, 일 부 예가 가산 또는 감산을 지시하는 도면에서 제공되더라도, 본 개시내용은 이러한 동작으로 제한되지는 않는다. 오히려, 도 21 및 도 22을 참조하여 추가로 설명되는 바와 같이, 이것은 데이터의 일반적인 조합을 지 시할 수 있다. 디코더 측은 계층 K 내지 1로 비트스트림로부터의 잠재 공간 데이터를 프로세싱한다. 0 번째 스테이지에 서의 결과적인 데이터(디코더 측에서의 1 번째 계층 또는 계층 블록의 출력)는 디코딩된 잔차이다. 이것은 1565 로서 나타내어진 유닛에서 수집된 예측과 조합된다. 여기에서의 수집은 예측 및 디코딩된 잔차의 조합을 포함한 다. 여기에서의 조합은 디코딩된 잔차 텐서 및 예측의 엘리먼트별 합이다. 여기에서의 예측은 수집 유닛(1560 및 1565)에서 엘리먼트별 프로세싱을 수행하기 위하여 잔차 신호와 동일한 크기(차원)를 가진다는 것이 주목된 다. 위에서 언급된 바와 같이, 본 명세서에서 도시된 엘리먼트별 합은 오직 2개의 신호(데이터의 종류)의 예시 적인 조합이다. 일반적으로, 조합은 상이하게 수행될 수 있고, 연접 또는 텐서를 함께 스택하는 것 및/또는 리 스케일링 등을 의미할 수 있다. 도 15의 상부 파트는 현재 필처의 프로세싱을 위하여 수집되는 예측이 어떻게 획득되는지를 도시한다. 특 히, 예측은 (시간 인스턴트 t에서의) 이전 픽처에 대한 동일한 네트워크에 의해 생성된 참조 프레임(참조 데이 터)에 기초하여, 그리고 아마도, (시간 인스턴트 t+1에서의) 현재 픽처의 비트스트림에서 제공될 수 있는 모션 정보와 같은 추가의 데이터에 기초하여 획득된다. 네트워크의 인코딩 파트에 의한 t-번째(선행하는) 픽처의 신경망 프로세싱은 현재 픽처에 대하여 위에서 설명된 바와 같은 유사한 프로세싱을 포함한 다. t = 0인 경우에는, 통상적으로, 이전에 코딩된 프레임이 없다. 따라서, 현재(t=0) 프레임의 디코딩된 샘플 만이 예측으로서 이용될 수 있다. 예를 들어, 인트라 예측이 적용될 수 있다. 대안적으로, 이러한 프레임은 상 이한 방식으로, 예컨대, 오직 무손실성 코딩 등에 의해 인코딩될 수 있다. 네트워크의 인코딩 파트에 의한 t 번째 (선행하는) 픽처의 신경망 프로세싱은 추가의 프로세싱, 즉, 인코 더 측에서의 모션 추정 및 디코더 측에서의 모션 보상을 위한 (디코딩된 잔차를 이전에 획득된 참 조 프레임에 가산함으로써 0 번째 스테이지에서 생성된) 참조 프레임의 제공을 포함한다. 모션 추정에서, (시간 인스턴트 t에서 디코딩된) 참조 픽처와 (t+1에서의) 현재 픽처 사이의 모션이 추정 된다. 모션은 그 다음으로, 모션 정보에 의해 표현되고, 비트스트림 내로 삽입된다. 또한, 추정된 모션은 모션 보상에서 이용된다. 모션 보상은 임의의 널리 공지된 접근법에 따라 수행된다. 모션 정보는 픽처의 어떤 부분에 대한 전체 광학 흐름 또는 서브샘플링된(그리고 아마도 무손실성 또는 손실성 코딩에 의해 추가로 인코딩된) 광학 흐름을 포함한다. 일반적으로, 모션 정보는 참조 픽처로부터 예측을 생성하는 것을 가능하게 한 다. 모션 정보는 참조 픽처로부터의 어느 샘플 값이 각각의 샘플 값 또는 예측 픽처에 기여하는지(그리고 어떻 게 기여하는지)를 특정한다. 모션 보상은 잔차 신호(예측 오차)를 생성하기 위하여 수집 유닛에서 그 후에 수집되는 예측 픽처를 생성한다. 디코더 측에서는, 모션 정보가 비트스트림으로부터 디코딩된다. 현재 픽처의 디코딩 동안에, 모션 보상 은 인코더 측에서의 모션 보상에 대하여 설명된 것과 동일한 방식으로, 이전 픽처의 디코딩의 0 번 째 스테이지로부터의 참조 픽처에 기초하여, 그리고 모션 정보에 기초하여 예측 픽처를 생성한다. 도 15는 신호 흐름을 주로 도시한다는 것이 주목된다. 실제적으로, 버퍼링(buffering)은 일부 스테이지에서 수 행될 수 있고, 예를 들어, 참조 픽처는 인코더 및 디코더 측에서 참조 픽처 버퍼 내에 저장될 수 있다. 예측 픽 처는 위에서 설명된 바와 같은 하나의 참조 픽처를 이용하여 생성될 수 있다. 그러나, 본 개시내용은 이러한 프 로세싱으로 제한되지는 않고, 예측 픽처는 하나 초과의 예측 픽처를 이용하여 생성될 수 있다. 최신 기술은 2개 의 참조 픽처(양방향-예측), 예컨대, 디스플레이 순서에서 현재 픽처에 선행하는 픽처 및 디스플레이 순서에서 현재 픽처에 후행하는 픽처(양방향성 예측)를 이용하는 다양한 접근법을 제공한다. 시간 인스턴스 t 및 t+1은 프로세싱된 픽처의 단위로 측정된다는 것이 추가로 주목된다. 그러나, 이것은 또한, 오직 예시적이다. 본 개시 내용은 바로 선행하는 픽처를 참조로서 이용하는 것으로 제한되지는 않는다. 특히, 시간적 확장가능성 (scalability)을 위하여, 디스플레이 순서에서 현재 픽처에 선행하거나 후행하고 있는(그러나, 인코딩 및 디코 딩 순서에서 현재 픽처에 선행하는) 참조 픽처가 이용될 수 있다. 비트스트림(1590 및 1572)은 하나의 비트스트 림으로 멀티플렉싱될 수 있다. 도 16은 잔차와 동일한 스테이지에서의 예측의 수집을 예시하므로, 도 16은 도 16와 유사하지만, 예측 및 잔차 의 수집은 스테이지 1에서 수행된다. 따라서, 예측은 입력 신호 도메인에서 수행될 필요가 없다. 이 경우에, 그 것은 1 번째 스테이지의 잠재 공간 도메인에서 수행된다. 여기에서의 1 번째 스테이지는 제1 계층 또는 계층의 블록으로 (시간 인스턴트 t+1에서의) 현재 입력 픽처를 프로세싱한 후의 스테이지이다. 특히, 1 번 째 계층은 다운샘플링을 포함할 수 있고, 이 경우에, 잠재 공간에서의 예측의 취급은 예컨대, 복잡도 및 레이턴시의 측면에서 증가된 효율을 제공할 수 있다. 도 16에서 알 수 있는 바와 같이, 잔차는 예컨대, 1 번째 계층의 출력으로부터 예측 텐서를 감산(일반적으로 조합)함으로써 수집기 유닛에서 획득된다. 이 경우의 1 번째 계층의 출력은 예측 텐서와 동일한 크기의 서브샘플링된(그리고 아마도 추가로 프로세싱된, 예컨대, 필터링된) 입력 픽처 텐서일 수 있고; 예측 텐서는 이전 픽처의 디코더 파이프라인의 1 번 째 스테이지로부터 획득된 참조 프레임에 기초하여 획득된다(네트워크). 대응하는 모션 정보는 그 다음으 로 또한, 잔차 비트스트림과 멀티플렉싱될 수 있는 비트스트림에서 전달되어야 할 더 적은 데이터 로 귀착될 수 있다. 디코더 측에서, 수집은 또한, 대응하는 스테이지(여기서, 1 번째 스테이지, 예컨대, 디코딩 프로세싱 순서에서 제1 계층 또는 계층의 블록에 의한 프로세싱에 선행하는 스테이지)에서 수행된다. 수 집은 또한, 도 15에서와 같이, 1 번째 스테이지의 잠재 공간 내의 예측 신호 및 디코딩된 잔차의 조합(이 경우 의 엘리먼트별 합)을 포함한다."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "본 기술분야에서의 통상의 기술자에게 명확한 바와 같이, 도 15 및 도 16 후에, 예측 신호 수집은 2 내지 k 중 의 스테이지 중의 임의의 스테이지에서 수행될 수 있다. 특히, 계층(또는 계층의 블록)이 서브샘플링을 포함하 는 경우에, 스테이지가 더 높을수록, 예측은 덜 정밀하게 될 수 있다. 다른 한편으로, 스테이지가 증가함에 따 라, 생성된 비트스트림의 레이트 뿐만 아니라, 복잡도 및 레이턴시도 감소할 수 있다. 따라서, 낮은 비트레이트/품질 코딩을 위하여, 위에서 언급된 스테이지를 더 이후에(더 큰 스테이지 인덱스에 대응함) 가지는 것이 유익 할 수 있는 반면, 높은 비트레이트/품질을 위하여, 위에서 언급된 스테이지를 더 이전에(더 작은 스테이지 인덱 스에 대응함) 가지는 것이 유익할 수 있다. 예측/잔차 수집의 스테이지를 독립적으로 선택할 가능성으로, 네트 워크 동작은 개선될 수 있다. 또한, 도 1 내지 도 13을 참조하여 설명된 위의 실시예 및 예에서 설명된 바와 같 이, 스테이지 선택은 컨텐츠 특성(예컨대, 스펙트럼)에 따라 적응적으로 수행될 수 있다. 도 15 및 도 16은 예측 및 잔차가 프로세싱의 동일한 스테이지(이 예에서 0 번째 또는 1 번째)로부터 획득되는 예를 예시한다. 그러나, 본 개시내용의 실시예에 따르면, 이것은 반드시 그렇지는 않다. 상이한 스테이지로부터 예측 및 잔차를 획득하는 것이 유리할 수 있다. 도 17은 예측이 i 번째 스테이지 내에서 획득되고 잔차 코딩이 NN 파이프라인의 (i+r) 번째 스테이지에서 수행 되는 예시적인 실시예를 도시한다. 이러한 실시예에 따르면, 신경망을 이용하여 비트스트림(아마도 또한, 1790)으로부터 하나 이상의 픽처의 특징 데이터를 프로세싱하기 위한 방법이 제공된다. 신경망은 제1 스테이지 및 제2 스테이지를 포함하는 2개 이상의 스테이지(K 내지 1)를 포함한다. 여기에서의 상기 \"제1\" 스테이지 및 상기 \"제2\" 스테이지는 스테이 지 K 내지 1 중의 임의의 것이고, 용어 \"제1\" 및 \"제2\"는 스테이지 번호에 대한 플레이스홀더(placehoder)로서 채용된다. 방법은 비트스트림에 기초하여 제1 데이터를 획득하는 것, 및 신경망을 이용하여 제1 데이터를 프로세싱 하는 것을 포함한다. 예를 들어, 도 17에서의 제1 데이터는, 비트스트림으로부터 디코딩되는, 아마도 또 한, 하나 이상의 계층(들)에 의해 프로세싱되는 잔차이다. 도 17에서, 제1 데이터는 비트스트림으로부터 디코딩되고 계층 K 내지 i+r+1에 의해 프로세싱되는 잔차이다. 다시 말해서, 잔차는 디코딩 파이프라인의 (i+r) 번째 스테이지에서 이용된다. 일반적으로, 제1 데이터는 하나 이상의 계층에 의해 반드시 프로세싱되지는 않고, 그것은 비트스트림으로부터 직접적으로 엔트로피 코딩된 특징 데이터일 수 있다는 것이 주목된다. 더 이후에 논의되는 바와 같이, 본 개시 내용은 또한, 엔트로피 인코딩/디코딩에 적용될 수 있다. 신경망을 이용하는 프로세싱은 다음을 포함한다: - 신경망의 제2 스테이지로부터, 신경망에 의해 이전에 프로세싱된 데이터에 기초하는 제2 데이터 를 획득하는 것; 및 - 신경망의 제1 스테이지에 대한 입력을 생성하기 위하여 제1 데이터를 제2 데이터와 함께 이용하는 것 - 제1 스테이지는 신경망의 특징 데이터 프로세싱에서 제2 스테이지에 선행함(도 17의 예에서의 네트워크 디코딩 파트 에서의 프로세싱 순서, 즉, 스테이지 K로부터 스테이지 0까지의 순서) -; 여기에서의 용어 \"이전에\"는 이전 프레임 또는 이전 블록(인트라) 등을 의미한다. 방법은 프로세싱의 결 과(예컨대, 재구성된 픽처 또는 픽처 특징 데이터)를 출력하는 것을 더 포함한다. 일반적으로, 본 실시예는 상 기 제1 스테이지 및 상기 제2 스테이지가 상이할 때마다 적용가능하다. 그러나, 도 1 내지 도 16을 참조하여 설 명된 실시예를 참조하여 도시된 바와 같이, 상기 제1 및 상기 제2 스테이지는 또한, 동일한 스테이지일 수 있다. 이 예에서의 제2 데이터는 예측 프레임일 수 있다. 제2 데이터를 획득하는 것은 참조 프레임 및 모션 정보를 획 득하는 것을 포함할 수 있다. 그러나, 일반적으로 참조 프레임 또는 일반적으로 참조 데이터는 예측으로서 직접 적으로 획득될 수 있다(예컨대, 모션이 시그널링되지 않는 경우, 또는 인트라 예측 또는 또 다른 유형의 예측이 이용되는 경우). 도 17은 픽처(프레임) 레벨 상에서의 프로세싱을 도시한다는 것이 주목된다. 그러나, 본 개시 내용은 그것으로 제한되지는 않고, 일반적으로, 픽처 부분은 인코딩/디코딩될 수 있다. 도 17의 예에서, 제1 스테이지는 디코딩 파이프라인의 (i+r) 번째 스테이지이고, 제2 스테이지는 디코딩 파이프 라인의 i 번째 스테이지이다. 예시적인 구현예에서, 상기 제1 데이터(예컨대, 잔차)는 신경망의 특징 데이터 프로세싱에서 상기 제1 스테이지 및 상기 제2 스테이지에 선행하거나 상기 제1 스테이지와 동일한 신경망의 제3 스테이지에서 획득된다. 다시 말 해서, 제1 데이터는 제1 데이터가 제2 데이터와 조합되는 스테이지와는 상이한 스테이지에서 획득될 수 있다. 이것은 일부 신경망 아키텍처에 대하여 유익할 수 있고, 일종의 스킵 접속(skip connection)에 대응할 수 있다. K 번째로부터 (i+r+1) 번째까지의 계층은 디코딩된 잔차 신호를 프리프로세싱하기 위하여 이용될 수 있고, 그것을 (i+1)로부터 (i+r)까지의 계층으로 프로세싱된 제2 데이터와 동일한 특징 공간으로 변환할 수 있다. 기본적 으로, 계층 (i+1) 내지 (i+r) 및 K 내지 (i+r+1)은 도 17에서 도시된 예시적인 구현예에서 제1 데이터 및 제2 데이터를 동일한 특징 공간(동일한 도메인)으로 변환하기 위하여 이용된다. 프로세싱된 제1 데이터 및 프로세싱 된 제2 데이터가 동일한 도메인 내에 있자마자, 이것은 도 21 내지 도 22에서 도시된 바와 같이 조합될 수 있다. 도 17에서, 제1 데이터는 예측 오차(예측 잔차)를 나타내고, 제2 데이터는 예측을 나타낸다. 특히, 예측은 다음 에 의해 획득된다: - 상기 제2 스테이지에서 신경망에 의해 출력된 특징 데이터인 참조 특징 데이터를 획득하는 것. i 번째 스테이 지의 일반적인 경우에, 참조 데이터는 픽처 도메인 내에 있는 것이 아니라 잠재 공간 도메인 내에 있으므로, 그 것은 여기에서 일반적으로, \"참조 특징 데이터\"로서 지칭된다. 0 번째 스테이지의 참조 특징은 도 15를 참조하 여 이미 논의된 바와 같이, 참조 픽처이다. - 비트스트림에 기초하여, (동일한 스테이지 또는 상이한 스테이지 상에서) 참조 특징 데이터에 관련된 모션 정 보 또는 공간적 정보를 포함하는 예측 정보를 획득하는 것. 본 명세서에서의 관계는, 예측 정보가 네트워크의 인코딩 파트에서 참조 특징 데이터에 대해 결정되었다는 사실에 의해 주어진다. 도 17에서, 비트스트림 내로 포함된 모션 정보는 인코더 측에서 계층 1 내지 i에 의해 프로세싱된 참조 특징 데이터와 특징 데이터 사 이의 모션에 대한 모션 추정을 수행함으로써 획득된다. 예컨대, 모션 정보를 생성하기 위하여 텐서 내로 스택된 입력 픽처 데이터를 이용하고, 그 다음으로, 그것을 다운샘플링하는 등을 행하여, 다른 예시적인 구현예"}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "가 가능하다. 본 기술분야에서의 통상의 기술자에게 명확한 바와 같이, 리스케일링 또는 리사이징은 필요한 경 우에 적용될 수 있다. - 참조 특징 데이터 및 예측 정보에 기초하여 예측을 생성하는 것. 도 17에서, 예측의 생성은 도 15를 참조하여 위에서 설명된 바와 같이 모션 보상에 의해 수행된다. 따라서, 제2 데이터는 모션 보상의 출력에 대응하는 예측 이다. 도 17에서, 예측 오차는 신경망으로 현재 픽처를 프로세싱함으로써 획득된다. 예측 정보는 모션 정보이고, 참조 특징 데이터는 디코딩 순서에서 현재 픽처에 선행하는 픽처를 나타내는 픽처 데이터의 신경망 프로세싱에 의해, 그리고 아마도 모션 추정을 추가로 적용함으로써 생성된다. 또한, 위에서 언급된 바와 같이, 디코딩 순서는 반 드시 디스플레이 순서가 아니고; 예측은 하나 초과의 참조에 기초할 수 있다. 전술한 제1 데이터를 제2 데이터와 함께 이용하는 것은 예측 또는 리스케일링된(re-scaled) 예측과, 예측 오차 또는 리스케일링된 예측 오차와의 엘리먼트별 가산을 포함한다. 예측 데이터의 이러한 리스케일링은 도 17에서 도시되어 있어서, (예를 들어, 컨볼루션 계층일 수 있는) 계층 i+1 내지 i+r에 의해 예컨대, 프로세싱 내에 포 함된다. 위에서 언급된 바와 같이, 엘리먼트별 가산은 연접 또는 다른 동작 또는 일련의 동작과 같은 상이한 종 류의 조합에 의해 대체될 수 있다. 본 개시내용은 보조 데이터가 예측인 것으로 제한되지는 않는다는 것이 주목된다. 이하에서 설명되는 바와 같이, 일부 실시예에서, 보조 (제2) 데이터는 하이퍼 프라이어로서의 상이한 (서브-) 네트워크로부터 획득될 수 있고, 신경망의 디코딩 측의 입력에서 잠재 공간 특징 데이터를 생성하기 위하여 0 번째 스테이지 상에서 인코 딩된 데이터와 함께 이용될 수 있다. 이러한 경우에, 함께 이용하는 것은 확률 모델 정보를 예컨대, 픽처 특징 데이터의 산술 디코딩에 적용하는 것을 지칭한다. 도 17에서, 모션 정보는 모션 벡터를 포함한다. 그러나, 본 개시내용은 모션 추정 및 보상의 임의의 특정한 방 식으로 제한되지는 않는다. 따라서, 일반적으로, 모션 정보는 모션 벡터로 제한되지는 않는다. 오히려, 그것은 아핀 변환 파라미터(affine transformation parameter)를 포함할 수 있다. 모션 벡터에 추가적으로, 모션 정보 는 (비-규칙적 모션 필드 샘플링(non-regular motion field sampling)의 경우에) 샘플링된 모션 벡터에 대한 위치를 포함할 수 있다. 도 18은 도 17의 더 일반적인 실시예의 특정 경우이다. 특히, 도 18에서, 상기 제2 스테이지는 (디코더) 신경망 의 출력, 즉, 0 번째 스테이지이다. 다시 말해서, 참조 프레임은 도 15에서 또한 이미 도시된 바와 같이, 디코 딩 프로세싱의 0 번째 스테이지로부터 취해진다. 이 경우의 0 번째 스테이지는 이전 픽처(시간 인스턴트 t)의 프로세싱의 스테이지인 것이 주목된다. 그러나, 이 예에서는, 네트워크 아키텍처가 현재 픽처 또는 픽처 특징 데이터(시간 인스턴트 t+1)의 프로세싱에 대하여, 그리고 이전 픽처 또는 픽처 특징 데이터(시간 인스턴트 t)에 대하여 변경되지 않는 것으로 가정된다.도 18에서, 상기 제1 스테이지(위에서 언급된 제3 스테이지와 동일함)는 K이고, 즉, 잔차는 파이프라인의 K 번 째 스테이지에서 (인코더에서) 계산되고 (디코더에서) 이용된다. 그러나, 본 개시내용은 이것으로 제한되지는 않고, 상기 제1 스테이지는 특히, 이하에서 더 상세하게 설명되는 바와 같이, 무손실성 코딩에 관련되는 실시예 의 경우에, 디코더 측에서 신경망의 입력일 수 있다. 도 19는 참조 픽처(및 따라서, 또한 예측)가 파이프라인의 스테이지 1에서 획득되고, 즉, 상기 제2 스테이지가 디코딩 파이프라인의 스테이지 1인 또 다른 예를 도시한다. 이것은 도 16에 대응한다. 잔차를 계산하고 이용하 기 위한 상기 제1 스테이지는 위에서 설명된 도 18에서와 같이, 인코딩 및 디코딩 파이프라인의 스테이지 K를 유지한다. 또 다른 예는 도 20에서 도시되어 있다. 도 20에서, 참조 프레임을 획득하기 위한 상기 제2 스테이지는 도 16 및 도 19에서와 같이 스테이지 1이다. 그러나, 잔차를 계산하고 이용하기 위한 상기 제1 스테이지는 인코딩 뿐 만 아니라 디코딩 파이프라인의 스테이지 (K-1)이다. 다시 말해서, 인코딩 측에서, 잔차를 획득한 후에(제1 데 이터 및 제2 데이터를 조합한 후에), 프로세싱된 데이터를 비트스트림 내로 삽입하기 전에, 조합된 데이 터는 신경망의 하나 이상의 계층에 의해 프로세싱될 수 있다. 이 예시적인 프로세싱 파이프라인 뿐만 아 니라, 도 17 내지 도 19의 예에서, 예측(제2 데이터에 대응함)은 또한, 인코딩 측에서 신경망의 하나 이상의 계 층에 의해 프로세싱될 수 있다. 이에 대응하여, 디코딩 측에서, 스테이지 K-1에서 추가의 프로세싱된 예 측을 조합하기 전에, 비트스트림으로부터의 데이터는 하나(도 20에서, 계층 K) 이상의 계층에 의해 프로 세싱될 수 있다. 또한, 예측은 디코딩 측에서 신경망의 하나 이상의 계층에 의해 프로세싱될 수 있다. 위 에서 언급된 바와 같이, 그 조합 전의 제1 데이터 및 제2 데이터의 프로세싱은 공통 크기(해상도)에 대한 그 적 응을 포함할 수 있지만, 이것으로 제한되지는 않는다. 위의 예는 대칭적 인코딩 및 디코딩 파이프라인, 및 인코딩 및 디코딩 파이프라인 내의 대응하는 스테이지에서 의 예측의 대칭적 수집을 도시한다. 이것은 반드시 그렇지 않다는 것이 주목된다. 리스케일링 및 리사이징의 가 능성으로, 비대칭적 해결책이 상상가능하다. 도 15 내지 도 20은 잔차를 획득하거나 픽처 (특징) 데이터를 획득하기 위하여 예측이 적용되는 특정한 예시적 인 실시예를 설명하였다. 예시적으로, 인코딩 측에서는, 잔차를 획득하기 위하여, 예측 데이터(제2 데이터)가 신경망에 대한 (그리고 아마도 일부 계층에 의해 프로세싱된) 픽처 (특징) 데이터 입력으로부터 감산되었다. 감 산은 엘리먼트별로 행해졌다. 유사하게, 디코딩 측에서, 잔차는 예측과 엘리먼트별로 조합되었다. 이러한 접근 법이 도 21에서 예시되어 있다. 도 21에서는, 예측된 블록과 원래의 블록 사이의 차이가 엘리먼트별로 결정되고, 비트스트림 내로 포함된다. (또한, 본 개시내용에서 잔차로서 또는 예측 오차로서 나타내어지는) 차 이는 그 다음으로, 디코더 측에서 비트스트림으로부터 획득되고, 재구성된 블록을 획득하기 위하여 예측 블록에 추가된다. 이 예는 단지 개략적이고, 블록은 직접적으로 픽처 데이터 또는 픽처 특징 데이터를 나타낼 수 있다. 그러나, 일부 실시예에서, 원래의 블록 및 예측 블록의 직접적인 조합 및/또는 잔차 블록 및 예측 블록의 조합 은 항상 가능한 블록별로 되어 있지는 않다. 예를 들어, 위에서 논의된 바와 같이, 예측, 입력 (원래의) 데이터, 및 잔차는 상이한 크기(해상도)를 가질 수 있다. 따라서, 도 22는 인코더 및 디코더에서의 일반화된 조 합을 도시한다. 예를 들어, 인코더에서, 잔차의 획득은 원래의 데이터 및 예측 데이터 중의 적어도 하나의 업샘 플링 또는 다운샘플링을 포함할 수 있다. 유사하게, 디코딩 측에서, 예측에 대한 잔차의 적용은 잔차 및/또는 예측 등의 리스케일링/리사이징을 포함할 수 있다. 하나의 예에서, 입력 (원래의) 데이터는 예측 데이터와 스택 되므로, 채널의 수는 원래의 데이터 채널 및 예측 데이터 채널의 수의 이 되었고; 이러한 조합된 데이터는 (아 마도 다운샘플링 또는 스트라이드형 컨볼루션(strided convolution)으로) 하나 이상의 컨볼루션 계층에 의해 추 가로 프로세싱되고, 결과는 잔차이다. 디코더 측에서, 잔차의 적용은 다음의 방식으로 수행된다: 잔차는 예측 데이터와 스택되고, 그 다음으로, (아마도, 다운샘플링 또는 스트라이드형 컨볼루션으로) 하나 이상의 컨볼루션 계층에 의해 프로세싱되고, 이러한 프로세싱의 결과는 재구성된 데이터이다(그것이 잠재 공간일 때, 하나 초과 의 채널을 가질 수 있음). 인코더 측에서, 원래 및 예측 데이터가 상이한 크기(해상도)를 가지는 경우에, 리스 케일링/리사이징은 채널을 스택하기 전에 적용될 수 있다. 디코더 측에서, 잔차 및 예측 데이터가 상이한 크기 (해상도)를 가지는 경우에, 리스케일링/리사이징은 채널을 스택하기 전에 적용될 수 있다. 또한, 약간의 컨볼루 션 계층은 조합 전에 예측 및/또는 예측 오차를 프리프로세싱하기 위하여 이용될 수 있다. 일반적으로, 이러한 종류의 프리프로세싱은 예측 및 예측 오차에 대하여 상이할 수 있다. 이하에서, 무손실성 인코딩 및 디코딩에서의 적용에 관한 실시예가 제공된다. 일반적으로, 제1 데이터는 오토인 코더의 인코딩 파트 후에 획득될 수 있고, 산술 코딩 전에 추가로 양자화될 수 있다. 이 경우에, 엔트로피 모델로서 제2 데이터를 갖는 이러한 실시예는 무손실성 코딩에 선행하는 손실성 코딩에 대하여 여전히 작동할 수 있 다. 따라서, 상기 제1 스테이지는 신경망의 입력이다. 제1 데이터는 엔트로피 인코딩된 데이터이다. 제2 데이터는 제2 스테이지의 특징 데이터에 관련된 확률 모델 데이터이다. 예를 들어, 상기 제2 데이터는 제1 데이터의 엔트 로피 디코딩을 위한 확률 모델 데이터이다. 이 예시적인 구현예에서, 제2 데이터는 제1 데이터 내의 심볼(symbol)의 확률의 예측을 행하기 위하여 이용되고, 이것은 산술 코딩을 실질적으로 개선시킬 수 있다. 기술적 효과는 신호로부터 예측을 감산하는 것, 및 예컨대, 제로(zero)에 근접한 차이(잔차)를 인코딩하는 것과 필적한다. 산술 코딩에 의해 인코딩되는 심볼이 (유리한 실제적인 실시예 중의 하나인) 오토인코더의 인코딩 파트의 양자화된 출력인 경우에, 손실성 코딩이 구 현된다. 심볼이 (이미 정수이고 산술 코딩에 의해 인코딩될 수 있는) 원시 이미지 샘플(raw image sample)인 경 우에, 무손실성 코딩이 구현된다. 이 실시예는 도 14를 참조하여 설명된 실시예의 확장이다. 도 14에서, 확률 모델은 0 번째 스테이지에서의 특징 데이터에 기초하여 결정되고, (산술 인코딩 및 산술 디코딩을 위한) 인코딩 및 디코딩의 0 번째 스테이지에서 적용된다. 그러나, 이것은 일반적으로 그렇게 되어야 하는 것은 아니다. 오히려, 확률 모델 정보에 대응하는 제 2 데이터는 예컨대, 0보다 큰 스테이지로부터의 잠재 공간의 픽처 특징 데이터에 기초하여, 예컨대, 하이퍼 프 라이어 서브 네트워크를 적용함으로써 획득될 수 있다. 일반적으로, 선행하는 예 또는 실시예 중의 임의의 것에서, 상기 제1 스테이지 및/또는 제2 스테이지의 위치는 구성가능할 수 있다. 예를 들어, 제1 스테이지 및/또는 제2 스테이지의 위치는 신경망 내에서 구성가능하고, 인 코딩 측 및/또는 디코딩 측에서의 프로세싱 방법은 하나 이상의 픽처 코딩 파라미터에 기초하여 수집 조건에 따 라 제1 스테이지 및/또는 제2 스테이지의 위치를 구성하는 것을 포함한다. 다시 말해서, 수집 조건에 기초하여 수집 위치를 선택하기 위한 접근법은 상기 제1 및/또는 제2 스테이지에 적용될 수 있다. 수집 조건은 인코더 및 디코더의 둘 모두에 의해 이용가능한 파라미터(정보)에 기초할 수 있다. 대안적으로 또는 추가적으로, 수집 조건은 인코더에서 수행되고 디코더로 시그널링된 선택에 종속될 수 있다. 예를 들어, 디코딩 방법은 비트스트림으로부터, 상기 제1 스테이지 및/또는 상기 제2 스테이지를 특정하는 스테 이지 선택 지시자를 파싱하는 것을 포함할 수 있다. 신경망 내에서의 제1 스테이지 및 제2 스테이지의 위치는 파싱된 스테이지 선택 지시자에 따라 구성된다. 인코딩 측에서는, 스테이지 선택 지시가 생성되고 비트스트림 내로 삽입된다. 위에서 설명된 바와 같이, 인코더는 레이트, 왜곡, 복잡도, 레이턴시, 정확도 등을 포함하는 비 용 함수에 기초한 일부 최적화에 기초하여 어떤 스테이지를 선택하도록 판정할 수 있다. 대안적으로, 손실된 정 보의 양과 같은 다른 접근법(예컨대, 위에서 설명된 FFT2 분석)이 적용될 수 있다."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "요약하면, 본 개시내용은 신경망 기반 이미지/비디오 코덱 또는 일반적인 픽처 프로세싱을 동적으로 구성가능하 게 할 수 있는 일부 실시예를 제공하고, 여기서, 코딩 파이프라인에서 보조 정보를 적용하는 위치는 조건에 종 속될 수 있다. 추가의 또는 대안적인 개선은, 참조 프레임에서의 일부 파이프라인 스테이지에서 획득된 보조 정 보가 현재 프레임에 대한 다른 파이프라인 스테이지에서 이용될 수 있는 아키텍처로부터 기인할 수 있다. 예측 및 잔차 보조 정보에 대한 이러한 방식의 예는 도 17을 참조하여 논의되었다. 예를 들어, 참조 프레임 측에서의 파이프라인의 i 번째 스테이지로부터 획득된 예측은 후속 r개의 NN 모듈에 의해 추가로 프로세싱될 수 있고, 잔 차 계산을 위하여, 현재 프레임에 대한 파이프라인의 (i+r) 번째 스테이지 내에서 이용될 수 있다. 이 경우에, 잔차는 NN 모듈 i+1, i+2,..i+r에 의해 프로세싱된 예측과 NN 모듈 1,..,i+r에 의해 프로세싱된 현재 프레임 사 이에서 계산된다. 그 다음으로, 잔차는 NN 모듈 (i+r+1), .., K에 의해 추가로 프로세싱된다. (인코더 측에서의) K 번째 모듈의 출력은 병목이고, 비트스트림에서 시그널링된다. 디코더 측에서는, 동일한 방식이 적 요되고: 예측은 NN 모듈 i+1, i+2,..i+r에 의해 프로세싱되고; 비트스트림으로부터 획득된 잔차는 모듈 K, .., (i+r+1)에 의해 프로세싱된다. 그 다음으로, 예측 및 잔차로부터 획득된 조합된 신호는 모듈 (i+r), .., 1에 의 해 프로세싱된다. 위에서 설명된 바와 같이, 하나의 스테이지 선택을 위하여, 인코더 측 상에서는, 보조 정보가 적용되는, 파이프 라인 내의 스테이지에 대한 판정이 멀티-패스 인코딩에 의해 수행될 수 있다. 하나의 예에서, 보조 정보를 적용 하는 것은 하나의 위치에서만 허용된다. 이 경우에, k=0,1,2,..,K에 대한 인코더는 파이프라인의 k 번째 위치에 서 보조 정보를 적용하도록 시도하고, 각각의 변형에 대한 왜곡 및 레이트를 획득한다. 그 다음으로, 정의된 레 이트/왜곡 비율에 대한 최상의 변형이 선택된다. 또 다른 예에서, 보조 정보를 적용하는 것이 파이프라인 내의 모든 위치에서 가능한 경우에, 길이 (K+1)의 각각의 불리언 벡터에 대한 인코더는 이 불리언 벡터에서의 위치에대응하는 위치에서 보조 정보를 적용하도록 시도하므로, 2K+1 개의 변형이 시도된다. 2개 이상의 스테이지가 선택될 가능성의 맥락 내에서, i 및 r의 모든 조합이 시도될 수 있다. 다음의 조건은 충 족되어야 한다: . 보조 정보 적용을 위한 모든 가능한 위치의 시도를 회피하고, 이에 따라, 인 코더 복잡도를 감소시키기 위하여, 철저한 검색(exhaustive search) 대신에, 경험적 방법(heuristic method)이 이용될 수 있다. 예를 들어, 위에서 설명된 (예컨대, FFT2를 이용하는) 스펙트럼 분석이 이용될 수 있다. 도 15 내지 도 20에서 도시된 예시적인 구현예 내에서, 예측은 오직 한번 계산되고, 잔차는 오직 한번 적용된다. 일반적으로, 코딩(인코딩 및/또는 디코딩) 방식은 (예컨대, 상이한 NN 계층에 의한 프로세싱을 위한)"}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "상이한 스테이지에서의 하나 초과의 예측 획득/잔차 적용 블록을 포함할 수 있다. 요약하면, 위에서 언급된 실 시예에서, 보조 정보는 예측 신호 및/또는 잔차 신호를 포함할 수 있다. 예측 신호는 이전에 코딩된 프레임의 i 번째 파이프라인 위치로부터 획득되고, 잔차 신호는 현재 프레임 프로세싱 동안에 k 번째 파이프라인 위치에서 적용된다. 일부 실시예에서, i 및 k는 서로 상이하다. 값 i 및 k는 미리 결정될 수 있고, 예컨대, 신경망 아키 텍처 내에서 고정될 수 있거나, 신경망 아키텍처 내에서 구성가능할 수 있다. 예를 들어, 값 i 및 k는 인코더 및 디코더 측 상에서 도출된 조건에 종속된다. 대안적으로 또는 추가적으로, 값 i 및 k는 비트스트림으로부터 파싱된 신택스 엘리먼트에 기초하여 결정된다. 일부 실시예에서, k는 i+r이고, 여기서, r은 제로 이상이다. 이러한 예는 도 17에서 일반적인 방식으로 도시되 어 있다. 도 20은 i=1, i+r=K-1에 대한 방식을 예시하고, 여기서, K는 인코더 파이프라인 내에서의 NN 모듈의 수이다. 모듈은 블록으로서 나타내어질 수 있고, 하나 이상의 계층을 포함할 수 있다. 가능한 구현예에서, i는 0이고, 즉, 예측은 신호 도메인(파이프라인 내에서의 0 번째 위치)에서 수행된다. 일부 다른 가능한 구현예에서, i+r은 K이고, 여기서, K는 인코더 파이프라인 내에서의 NN 모듈의 수이다. 잔차 코딩은 병목에서, 즉, 파이프라인 내에서의 K 번째 위치에서 수행된다. 도 18은 i=0, i+r=K에 대한 방식을 도시한다. 도 19는 i=1, 및 i+r=K에 대한 방식을 도시한다. 위의 예 중의 임의의 예에서, 예측 신호는 이전에 코딩된 프레임(들)의 p 번째 파이프라인 위치로부터의 정보 및 추가적으로 시그널링된 정보에 기초하여 계산될 수 있다. 예를 들어, 추가적으로 시그널링된 정보는 모션 정 보를 포함한다. 예를 들어, 잔차 신호는 2개의 입력: 예측 신호 및 파이프라인 내에서의 k 번째 NN 모듈의 출력 을 갖는 모듈에 의해 계산된다. 일부 실시예에서, 잔차 신호는 예측 신호와 파이프라인 내에서의 k 번째 NN 모 듈의 출력 사이의 차이로서 계산된다. 또한, 잔차 신호의 적용은 2개의 입력: 잔차 신호 및 예측 신호를 갖는 모듈에 의해 수행된다. 최종적으로, 잔차 신호의 적용은 잔차 신호를 예측 신호에 가산함으로써 수행된다."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 9, "content": "도 23 내지 도 25는 프로세싱 파이프라인의 일부 가능한 아키텍처를 요약한다. 도 23은 원래의 픽처, 예측, 및 잔차가 신호 도메인 내에, 즉, 인코딩 신경망에 의한 프로세싱을 위한 0 번째 스테이지 내에 있는 예를 도시한다. 원래의 픽처 및 예측은 획득된 잔차로 조합된다. 잔차는 하이퍼 프라이어를 포함하는 VAE로 인코딩된다. 결과는 코딩된 잔차 및 아마도 일부 부 정보를 포함하는 비트스트림이다. 디코더 측은 비트스트림을 입력한다. 디코더는 여기서, 재구성된 잔차를 출력하는 하이퍼 프라이어를 갖는 VAE이다. 재 구성된 잔차는 재구성된 픽처를 획득하기 위하여 예측 신호와 조합될 수 있다. 재구성된 픽처는 예컨대, 거리 척도(distance measure), 예컨대, 객관적 또는 지각적 품질 메트릭을 적용함으로써 원래의 픽처와 추가로 비교 될 수 있다. 도 24는 원래의 픽처, 예측, 및 잔차가 잠재 공간 도메인 내에, 즉, 인코딩 신경망에 의한 프로세싱을 위한 1 번째 스테이지 내에 있는 예를 도시한다. 이 경우에, 원래의 픽처 및 예측은 VAE 인코더의 하나 이상의 계층에 의해 먼저 프로세싱되고, 그 다음으로, 잠재 공간 도메인에서 잔차를 획득하도록 조합된다. 이것은 하이퍼 프라 이어 인코더에 의해 인코딩되고, 이에 따라, 비트스트림이 생성된다. 비트스트림은 재구성된 잠재 공간 잔차를 획득하기 위하여 하이퍼 프라이어 디코더에 의해 디코딩될 수 있다. 재구성된 잠재 공간 잔차는 잠재 공간 도메 인에서 (또한 잠재 공간 도메인에서의) 예측과 조합되고, 이에 따라, 재구성된 픽처를 획득하기 위하여 VAE 디 코더에 입력되는 재구성된 픽처 특징 텐서가 획득된다. 재구성된 픽처는 예컨대, 거리 척도, 예컨대, 객관적 또 는 지각적 품질 메트릭을 적용함으로써 원래의 픽처와 추가로 비교될 수 있다. 도 25는, 원래의 픽처가 VAE 인코더에 의해 인코딩되고, 그 다음으로, 인코딩된 픽처를 이전 프레임의 잠재 공 간으로부터 획득된 예측과 감산(또는 조합)함으로써 잠재 공간에서 획득되는 예를 도시한다. 잔차는 하이퍼 프 라이어 인코더로 비트스트림 내로 인코딩된다. 비트스트림은 하이퍼프라이어 디코더에 의해 디코딩될 수 있고, 이에 따라, 잠재 공간에서 재구성된 잔차가 획득될 수 있다. 이것은 이전 프레임의 잠재 공간으로부터 획득된예측과 조합되고, 이러한 방식으로, 잠재 공간 내의 재구성된 픽처 특징 텐서가 획득된다. VAE 디코더로 획득되 는 재구성된 픽처 특징 텐서를 변환함으로써, 재구성된 픽처가 획득된다. 재구성된 픽처는 예컨대, 거리 척도, 예컨대, 객관적 또는 지각적 품질 메트릭을 적용함으로써 원래의 픽처와 추가로 비교될 수 있다. 이 3개의 아키텍처 중의 임의의 것은 위에서 설명된 바와 같은 실시예 및 예시적인 구현예를 채용하는 것에 기 초가 될 수 있다. 이 아키텍처는 VAE 인코더 및 디코더를 포함하였다. 그러나, 일반적으로, 개시내용은 하이퍼 프라이어를 갖는 VAE로 제한되지는 않는다. 산술 코딩을 위한 심볼 확률 추정의 다른 접근법이 마찬가지로 적용 될 수 있다. 예를 들어, 컨텍스트 기반 접근법이 이용될 수 있다. 이 경우에, 이전에 디코딩된 샘플에 대한 정 보는 심볼 확률 추정 NN에 의해 추가적으로 이용된다. 컨텍스트 접근법에 의한 확률 추정 NN의 예가 도 13에서 도시되어 있다. 일부 실시예의 개요 이 출원은 2개 이상의 계층을 갖는 신경망을 이용하여 픽처 데이터 또는 픽처 특징 데이터의 프로세싱을 위한 방법 및 장치를 제공한다. 본 개시내용은 인공 지능(AI)-기반 비디오 또는 픽처 압축 기술의 분야에서, 그리고 특히, 신경망-기반 비디오 압축 기술의 분야에 적용될 수 있다. 일부 실시예에 따르면, 보조 정보가 프로세싱을 위하여 입력될 수 있는, 신경망 내에서의 위치는 수집 조건에 기초하여 선택가능하다. 수집 조건은 일부 전제조 건이 이해되는지 여부를 평가할 수 있다. 장점의 일부는 신경망 구성가능성에서의 증가된 유연성의 효과로 인한 레이트 및/또는 개시내용의 측면에서의 더 양호한 성능을 포함할 수 있다. 제1 측면에 따르면, 본 개시내용은 복수의 신경망 계층을 포함하는 신경망을 이용하여 비트스트림으로부터의 픽 처 특징 데이터를 프로세싱하기 위한 방법에 관한 것이다. 방법은, 비트스트림으로부터 픽처 특징 데이터를 획 득하는 것; 및 신경망을 이용하여 픽처 특징 데이터를 프로세싱하는 것을 포함하고, 여기서, 신경망 내에서의 하나 이상의 사전구성된 위치의 각각에 대하여, 프로세싱은, 수집 조건에 기초하여, 상기 사전구성된 위치에서 의 복수의 신경망 계층 중의 하나에 의한 프로세싱을 위한 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여 부를 결정하는 것, 및 보조 데이터가 수집되어야 하는 것으로 결정되는 경우에, 상기 사전구성된 위치에서의 계 층에 의한 프로세싱이 보조 데이터에 기초한다는 것을 포함한다. 사전구성된 위치는 보조 정보가 수집될 수 있는, 신경망 내에서의 위치이다. 보조 정보가 실제적으로 특정한 사 전구성된 위치에서 수집되는지 또는 그렇지 않은지 여부는 위에서 언급된 결정 단계에서 결정된다. 용어 \"위 치\"는 신경망 내에서의 노드를 지칭한다. 노드는 계층(또는 신경망의 아키텍처에 따라, 계층 또는 모듈의 블 록)으로 입력되고 및/또는 계층으로부터 출력되는 특징 텐서에 대응한다. 특히, 그것은 프로세싱 방향에서 위치 에 선행하는 신경망 계층의 수에 의해 특정될 수 있다. 보조 정보는 신경망에 추가된 픽처 데이터 또는 픽처 특징 데이터에 관련된 임의의 정보이다. 이러한 정보는 프 로세싱을 추가로 개선시키기 위하여 신경망으로 입력될 수 있다. 보조 정보의 일부 특정한 예는 이하의 예시적 인 구현예에서 제공된다. 수집 조건은 보조 데이터가 특정한 사전구성된 위치로 입력되도록 하기 위하여 이행되어야 할 조건 또는 전제조 건이다. 수집 조건은 어떤 위치에 대한 보조 정보를 수집할 것인지 또는 그렇지 않은지 여부를 결정하기 위한 일부 픽처 특성 또는 픽처 특징 특성과 임계치와의 비교를 포함할 수 있다. 픽처 특성 또는 픽처 특징 특성은 인코더 및 디코더에 알려질 수 있어서, 이로써 추가적인 시그널링이 요구되지 않는다. 대안적으로 또는 추가적 으로, 보조 정보가 사전구성된 위치에 대하여 수집되어야 하는지 또는 그렇지 않은지 여부의 지시자를 설정하는 것에 의하여, 수집 조건은 인코딩 측에 의해 구성될 수 있다. 지시자는 디코더에서 이용가능한 비트스트림 내에 서 제공될 수 있다. 보조 정보를 신경망으로 입력하는 위치를 구성하는 것은 더 높은 유연성의 효과를 가지고, 동적 신경망 아키텍 처 변경을 가능하게 한다. 이러한 유연성은 수집 조건에 기초하여 더 양호한 적응으로 귀결될 수 있고, 더 효율 적인 인코딩 및/또는 디코딩을 초래할 수 있다. 가능한 구현예에서, 결정에서 수집 조건을 적용하는 결과로서, 상기 보조 데이터는 하나 이상의 사전구성된 위 치 중의 단 하나에 대하여 수집되어야 한다. 이러한 구현예는 특정한 보조 정보에 대하여, 보조 정보가 수집되어야 하는, 신경망 내의 위치를 선택하는 것과 유사한 효과를 제공한다. 이것은 프로세싱 시간 또는 복잡도 및/또는 레이트 또는 왜곡을 포함할 수 있는 코딩 효율과 같은 일부 기준에 따라 가장 적당할 수 있는 그 위치로 보조를 제공하는 것을 가능하게 한다.가능한 대안적인 구현예에서, 결정에서 수집 조건을 적용하는 결과로서, 상기 보조 데이터는 상기 사전구성된 위치 중의 하나 초과에 대하여 수집되어야 한다. 상기한 구현예에 대해 대안적인 이러한 구현예는, 보조 정보로부터 이익을 얻을 수 있는 임의의 계층 상에서 보 조 정보가 이용가능하다는 것을 보장할 수 있다. 그것은 네트워크의 구성가능성 및 이에 따라 유연성을 추가로 증가시킬 수 있다. 가능한 구현예에서는, 상기 사전구성된 위치 중의 하나 초과가 있고(상기 프로세싱은 2개 이상의 사전구성된 위 치에 대하여 수행됨); 보조 데이터는 상기 사전구성된 위치 중의 2개 이상에서의 계층에 의해 프로세싱된 입력 채널의 차원과 정합하도록 크기에 있어서 확장가능하고; 결정에서 수집 조건을 적용하는 결과로서, 상기 보조 데이터가 i) 수집되거나, ii) 상기 사전구성된 위치 중의 단 하나에 대하여 수집되고 스케일링된다. 따라서, 보조 데이터는 특징 데이터와의 그 조합을 가능하게 하도록 적절하게 스케일링될 수 있다. 이러한 스케 일링은 상이한 스테이지 또는 소스로부터 나올 수 있는 매우 다양한 보조 정보의 제공을 가능하게 한다. 가능한 구현예에서, 수집 조건은 비트스트림으로부터 획득된 픽처 특성 또는 픽처 특징 데이터 특성에 기초한다. 이 구현예는 신경망의 컨텐츠 적응을 가능하게 하고, 신경망에 의해 수행된 인코딩 또는 디코딩 또는 다른 프로 세싱의 성능을 개선시킬 수 있다. 가능한 구현예에서, 픽처 특성 또는 픽처 특징 데이터 특성은 해상도를 포함하고; 수집 조건은 해상도와 사전구 성된 해상도 임계치와의 비교를 포함한다. 해상도는, 추가로 다운샘플링되거나 또는 이와 다르게 손실성으로 프로세싱될 때, 품질이 열화하게 할 수 있는 상세한 특징의 레벨에 영향을 주므로, 해상도는 적당한 판정 기초이다. 가능한 구현예에서, 픽처는 비디오 픽처이고, 픽처 특성은 픽처 유형을 포함하고; 수집 조건은 픽처 유형이 시 간적으로 예측된 픽처 유형인지 또는 공간적으로 예측된 픽처 유형인지 여부를 결정하는 것을 포함한다. 픽처 유형은 예측의 품질에 영향을 주므로, 픽처 유형은 적당한 판정 기초이다. 또한, 인트라 픽처는 또한, 시 간적 예측에 대한 참조로서 인트라-코딩된 픽처를 전형적으로 이용하는 인터 픽처에 영향에 줄 수 있으므로, 더 높은 품질로 인트라 픽처를 인코딩하는 것이 바람직할 수 있다. 예시적인 구현예에 따르면, 방법은 비트스트림으로부터, 하나 이상의 사전구성된 위치에 대하여, 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여부를 특정하는 지시를 획득하는 것을 더 포함하고, 하나 이상의 사전구성 된 위치의 각각에 대한 수집 조건은 다음과 같고: 지시가 상기 사전구성된 위치에 대하여, 보조 데이터가 수집 되어야 하는 것으로 특정하는 경우에, 결정은 긍정적이고; 지시가 상기 사전구성된 위치에 대하여, 보조 데이터 가 수집되지 않아야 하는 것으로 특정하는 경우에, 결정은 부정적이다. 수집 조건(들)의 명시적 시그널링은 구성가능성을 추가로 증가시키고, 사전정의된 수집 조건(들)이 그것을 포착 할 수 없더라도, 픽처의 컨텐츠에 대한 더 근접한 적응을 가능하게 한다. 가능한 구현예에서, 보조 데이터는 출력을 생성하기 위하여 신경망에 의해 프로세싱된 픽처 특징 데이터에 대한 정보를 제공한다. 픽처 특징 데이터에 대한 추가적인 정보의 제공은 재구성 프로세싱 및/또는 다른 종류의 프로세싱을 개선시킬 수 있다. 프로세싱 유형에 기초하여, 상이한 보조 정보가 관련될 수 있고 적용될 수 있다. 가능한 구현예에서, 보조 데이터는 신경망의 계층 중의 하나 이상에 의한 프로세싱 후의 픽처의 예측 또는 픽처 특징 데이터의 예측인 예측 데이터를 포함한다. 움직이는 픽처(비디오) 코딩 효율은 인접한 픽처로부터의 시간적 상관을 제거하는 것에 고도로 종속될 수 있다. 따라서, 제공 또는 예측 데이터 또는 예측 오차 데이터는 신경망 프로세싱을 개선시킬 수 있다. 가능한 구현예에서, 보조 데이터는, 예측 데이터, 및 예측 데이터와 조합되어야 할 보충적 데이터의 결합된 쌍 이다. 동일한 도메인에서 예측 및 예측 오차를 수집하는 것은 수집 스테이지 선택의 상대적으로 간단하고 효과적인 방 식을 제공할 수 있다.가능한 구현예에서, 예측 데이터 및 보충적 데이터는 신경망 내의 상호 상이한 위치에서의 계층에 의해 프로세 싱된 데이터의 차원을 가진다. 다시 말해서, 예측은 예측 잔차 또는 다른 보충적 정보가 제공되는 스테이지와는 상이한 스테이지에서 제공될 수 있다. 따라서, 컨텐츠에 대한 더 양호한 적응에 의한 효율이 달성될 수 있다. 가능한 구현예에서, 신경망은 적어도 하나의 계층을 갖는 무손실성 디코딩을 위한 서브-네트워크를 포함하고, 보조 정보는 무손실성 디코딩을 위한 상기 서브-네트워크로 입력된다. 하이퍼 프라이어를 갖는 가변적 오토-인코더는 최근에 채용되었고, 하이퍼 프라이어의 (수집 조건에 기초한) 조 건적 수집에 의해 효율적으로 지원될 수 있다. 일부 경우에, 그것은 서브-네트워크가 확률 모델 파라미터를 도 출하기 위하여 이용되는 경우에 유익할 수 있다(더 간결한 비트스트림을 초래함). 다른 경우에, 그것은 디폴트 또는 컨텍스트 기반 확률 모델이 이미 양호하게 작동하는 경우에는 연산적으로 너무 비쌀 수 있다. 가능한 구현예에서, 신경망은 스틸 픽처 디코딩, 비디오 픽처 디코딩, 스틸 픽처 필터링, 비디오 픽처 필터링, 및 객체 검출, 객체 인식, 또는 객체 분류를 포함하는 머신 시각 프로세싱 중의 적어도 하나를 수행하도록 훈련 된다. 이 구현예는 유연한 보조 정보 위치(및 아마도 또한 해상도)로부터 이익을 얻을 수 있는 많은 중요한 애플리케 이션에 대하여 본 명세서에서 설명된 방법의 전개를 가능하게 한다. 실시예에서, 방법은 제1 보조 데이터 및 제2 보조 데이터를 포함하는 복수의 보조 데이터의 각각에 대하여 수행 되고, 여기서, 제1 보조 데이터는 하나 이상의 사전구성된 위치의 제1 세트와 연관되고, 제2 보조 데이터는 하 나 이상의 사전구성된 위치의 제2 세트와 연관된다. 이것은 예컨대, 상이한 위치에서 자연적으로 채용될 예측 관련된 보조 정보 및 무손실성 코딩 관련된 보조 정보 와 같이, 보조 정보가 오히려 상이하더라도, 신경망이 하나 초과의 유형의 보조 정보를 효율적으로 수집하는 것 을 가능하게 한다. 가능한 구현예에서, 하나 이상의 사전구성된 위치의 제1 세트 및 하나 이상의 사전구성된 위치의 제2 세트는 적 어도 하나의 사전구성된 위치를 공유한다. 이것은 일부 애플리케이션에 대하여 적당할 수 있는 예시적인 구현예이다. 예를 들어, 예측 및 예측 오차의 경 우에, 모든 사전구성된 위치가 공유될 수 있다. 가능한 구현예에서, 신경망은 비디오 픽처의 프로세싱을 수행하도록 훈련되고; 상기 사전구성된 위치에서의 계 층에 의한 프로세싱을 위한 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여부를 결정하는 것은 미리 결정 된 수의 비디오 픽처마다 수행되고, 여기서, 미리 결정된 수의 비디오 픽처는 하나 이상이다. 수집 위치 적응을 위한 일부 세분화도를 설정하는 것은, 그것이 더 적은 복잡도 및 일부 실시예에서는 더 적은 시그널링 오버헤드(signaling overhead)를 수반할 수 있으므로 효율에 기여할 수 있다. 제2 측면에 따르면, 본 발명은 비트스트림을 생성하기 위하여 복수의 신경망 계층을 포함하는 신경망으로 픽처 를 프로세싱하기 위한 방법에 관한 것이다. 방법은 신경망으로 픽처를 프로세싱하는 것을 포함한다. 프로세싱하 는 것은 신경망 내에서의 하나 이상의 사전구성된 위치의 각각에 대하여: 수집 조건에 기초하여, 상기 사전구성 된 위치에서의 계층에 의한 프로세싱을 위한 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여부를 결정하는 것, 및 보조 데이터가 수집되어야 하는 것으로 결정되는 경우에, 상기 사전구성된 위치에서의 계층에 의한 프로 세싱이 보조 데이터에 기초한다는 것을 포함한다. 방법은 신경망에 의해 픽처를 프로세싱하여 획득된 데이터를 비트스트림 내로 삽입하는 것을 더 포함한다. 본 개시내용의 인코딩 파트는 디코딩 파트에 대하여 위에서 언급된 것과 동일한 장점을 제공할 수 있다. 인코더 는 비트스트림을 준비하고, 비트스트림을 디코더에 제공하여, 이로써 디코더는 희망된 품질 및 애플리케이션을 고려하여 데이터를 디코딩하거나 재구성할 수 있다. 중복성(redundancy)을 회피하기 위하여, 대응하는 디코딩 프로세싱 청구항에 대하여 제공된 장점은 유사한 방식 으로 인코딩에 대하여 적용된다. 가능한 구현예에서, 결정에서 수집 조건을 적용하는 결과로서, 상기 보조 데이터는 하나 이상의 사전구성된 위 치 중의 단 하나에 대하여 수집되어야 한다.가능한 구현예에서, 결정에서 수집 조건을 적용하는 결과로서, 상기 보조 데이터는 상기 사전구성된 위치 중의 하나 초과에 대하여 수집되어야 한다. 가능한 구현예에서는, 상기 사전구성된 위치 중의 하나 초과가 있고(상기 프로세싱은 2개 이상의 사전구성된 위 치에 대하여 수행됨); 보조 데이터는 상기 사전구성된 위치 중의 2개 이상에서의 계층에 의해 프로세싱된 입력 채널의 차원과 정합하도록 크기에 있어서 확장가능하고; 결정에서 수집 조건을 적용하는 결과로서, 상기 보조 데이터가 i) 수집되거나, ii) 상기 사전구성된 위치 중의 단 하나에 대하여 수집되고 스케일링된다. 가능한 구현예에서, 수집 조건은 비트스트림 내로 포함되는 픽처 특성 또는 픽처 특징 데이터 특성에 기초한다. 가능한 구현예에서, 픽처 특성 또는 픽처 특징 데이터 특성은 해상도를 포함하고; 수집 조건은 해상도와 사전구 성된 해상도 임계치와의 비교를 포함한다. 가능한 구현예에서, 픽처는 비디오 픽처이고, 픽처 특성은 픽처 유형을 포함하고; 수집 조건은 픽처 유형이 시 간적으로 예측된 픽처 유형인지 또는 공간적으로 예측된 픽처 유형인지 여부를 결정하는 것을 포함한다. 일부 실시예에서, 방법은 하나 이상의 사전구성된 위치에 대하여, 보조 데이터를 수집할 것인지 또는 그렇지 않 은지 여부를 특정하는 지시를 생성하는 것, 및 지시를 비트스트림 내로 포함하는 것을 더 포함한다. 예시적인 구현예에 따르면, 방법은 하나 이상의 사전구성된 위치에 대하여, 레이트, 왜곡, 정확도, 속력, 또는 복잡도 중의 적어도 하나를 포함하는 비용 함수의 최적화에 기초하여 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여부를 선택하는 단계를 더 포함한다. 비용 함수에 기초한 수집하기 위한 위치의 결정은 신경망의 적응 및 희망된 요건에 대한 결과를 개선시킬 수 있 다. 따라서, 이러한 최적화는 성능을 개선시킬 수 있다. 그렇게 획득된 수집 위치를 지시하는 것과 조합하여, 유연성이 추가로 개선된다. 가능한 구현예에서, 보조 데이터는 출력을 생성하기 위하여 신경망에 의해 프로세싱된 픽처 특징 데이터에 대한 정보를 제공한다. 가능한 구현예에서, 보조 데이터는 신경망의 계층 중의 하나 이상에 의한 프로세싱 후의 픽처의 예측 또는 픽처 특징 데이터의 예측인 예측 데이터를 포함한다. 가능한 구현예에서, 보조 데이터는, 예측 데이터, 및 예측 데이터와 조합되어야 할 보충적 데이터의 결합된 쌍 이다. 가능한 구현예에서, 예측 데이터 및 보충적 데이터는 신경망 내의 상호 상이한 위치에서의 계층에 의해 프로세 싱된 데이터의 차원을 가진다. 가능한 구현예에서, 신경망은 적어도 하나의 계층을 갖는 무손실성 디코딩을 위한 서브-네트워크를 포함하고, 보조 정보는 무손실성 디코딩을 위한 상기 서브-네트워크로 입력된다. 가능한 구현예에서, 신경망은 스틸 픽처 디코딩, 비디오 픽처 디코딩, 스틸 픽처 필터링, 비디오 픽처 필터링, 및 객체 검출, 객체 인식, 또는 객체 분류를 포함하는 머신 시각 프로세싱 중의 적어도 하나를 수행하도록 훈련 된다. 예시적인 구현예에 따르면, 방법은 제1 보조 데이터 및 제2 보조 데이터를 포함하는 복수의 보조 데이터의 각각 에 대하여 수행되고, 여기서, 제1 보조 데이터는 하나 이상의 사전구성된 위치의 제1 세트와 연관되고, 제2 보 조 데이터는 하나 이상의 사전구성된 위치의 제2 세트와 연관된다. 가능한 구현예에서, 하나 이상의 사전구성된 위치의 제1 세트 및 하나 이상의 사전구성된 위치의 제2 세트는 적 어도 하나의 사전구성된 위치를 공유한다. 가능한 구현예에서, 신경망은 비디오 픽처의 프로세싱을 수행하도록 훈련되고; 상기 사전구성된 위치에서의 계 층에 의한 프로세싱을 위한 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여부를 결정하는 것은 미리 결정 된 수의 비디오 픽처마다 수행되고, 여기서, 미리 결정된 수의 비디오 픽처는 하나 이상이다. 제3 측면에 따르면, 본 발명은 복수의 신경망 계층을 포함하는 신경망을 이용하여 비트스트림으로부터의 픽처 특징 데이터를 프로세싱하기 위한 장치에 관한 것이다. 장치는, 비트스트림으로부터 픽처 특징 데이터를 획득하 고; 신경망을 이용하여 픽처 특징 데이터를 프로세싱하도록 구성된 프로세싱 회로부를 포함하고, 여기서, 신경망 내에서의 하나 이상의 사전구성된 위치의 각각에 대하여, 다음과 같다. 프로세싱하는 것은, 수집 조건에 기 초하여, 상기 사전구성된 위치에서의 복수의 신경망 계층 중의 하나에 의한 프로세싱을 위한 보조 데이터를 수 집할 것인지 또는 그렇지 않은지 여부를 결정하는 것, 및 보조 데이터가 수집되어야 하는 것으로 결정되는 경우 에, 상기 사전구성된 위치에서의 계층에 의한 프로세싱이 보조 데이터에 기초한다는 것을 포함한다. 본 개시내용의 유리한 효과에 대해서는, 제1 측면의 설명을 참조한다. 세부사항은 본 명세서에서 다시 설명되지 않는다. 디코딩 장치는 제1 측면에서의 방법 예에서의 액션을 구현하는 기능을 가진다. 기능은 하드웨어에 의해 구현될 수 있거나, 대응하는 소프트웨어를 실행하는 하드웨어에 의해 구현될 수 있다. 하드웨어 또는 소프트웨 어는 상기한 기능에 대응하는 하나 이상의 모듈을 포함한다. 가능한 구현예에서, 디코딩 장치는 비트스트림으로 부터 픽처 특징 데이터를 획득하도록 구성된 특징 데이터 입력 모듈; 및 위에서 언급된 프로세싱을 수행하도록 구성된 신경망 모듈을 포함한다. 이 모듈은 제1 측면에서 방법 예에서의 대응하는 기능을 수행할 수 있다. 세부 사항에 대해서는, 방법 예에서의 상세한 설명을 참조한다. 세부사항은 본 명세서에서 다시 설명되지 않는다. 제4 측면에 따르면, 본 발명은 비트스트림을 생성하기 위하여 복수의 신경망 계층을 포함하는 신경망으로 픽처 를 프로세싱하기 위한 장치에 관한 것이다. 장치는, 신경망으로 픽처를 프로세싱하고 - 프로세싱하는 것은 신경 망 내에서의 하나 이상의 사전구성된 위치의 각각에 대하여, 수집 조건에 기초하여, 상기 사전구성된 위치에서 의 계층에 의한 프로세싱을 위한 보조 데이터를 수집할 것인지 또는 그렇지 않은지 여부를 결정하는 것, 및 보 조 데이터가 수집되어야 하는 것으로 결정되는 경우에, 상기 사전구성된 위치에서의 계층에 의한 프로세싱이 보 조 데이터에 기초한다는 것을 포함함 -; 신경망에 의해 픽처를 프로세싱하여 획득된 데이터를 비트스트림 내로 삽입하도록 구성된 프로세싱 회로부를 포함한다. 본 발명의 유리한 효과에 대해서는, 제2 측면의 설명을 참조한다. 세부사항은 본 명세서에서 다시 설명되지 않 는다. 인코딩 장치는 제2 측면에서의 방법 예에서의 액션을 구현하는 기능을 가진다. 기능은 하드웨어에 의해 구현될 수 있거나, 대응하는 소프트웨어를 실행하는 하드웨어에 의해 구현될 수 있다. 하드웨어 또는 소프트웨 어는 상기한 기능에 대응하는 하나 이상의 모듈을 포함한다. 가능한 구현예에서, 인코딩 장치는 위에서 언급된 프로세싱을 수행하도록 구성된 신경망 모듈; 및 신경망에 의해 픽처를 프로세싱하여 획득된 데이터를 비트스트 림 내로 삽입하고 비트스트림을 출력하도록 구성된 비트스트림 출력 모듈을 포함한다. 이 모듈은 제2 측면에서 의 방법 예에서의 대응하는 기능을 수행할 수 있다. 세부사항에 대해서는, 방법 예에서의 상세한 설명을 참조한 다. 세부사항은 본 명세서에서 다시 설명되지 않는다. 본 발명의 제1 측면에 따른 방법은 본 발명의 제3 측면에 따른 장치에 의해 수행될 수 있다. 본 발명의 제1 측 면에 따른 방법의 다른 특징 및 구현예는 본 발명의 제3 측면에 따른 장치의 기능성 및 구현예에 직접적으로 종 속된다. 본 발명의 제2 측면에 따른 방법은 본 발명의 제4 측면에 따른 장치에 의해 수행될 수 있다. 본 발명의 제2 측 면에 따른 방법의 다른 특징 및 구현예는 본 발명의 제4 측면에 따른 장치의 기능성 및 구현예에 직접적으로 종 속된다. 제5 측면에 따르면, 본 발명은 프로세서 및 메모리를 포함하는 비디오 스트림 디코딩 장치에 관한 것이다. 메모 리는, 프로세서로 하여금, 제1 측면에 따른 방법을 수행하게 하는 명령을 저장한다. 제6 측면에 따르면, 본 발명은 프로세서 및 메모리를 포함하는 비디오 스트림 인코딩 장치에 관한 것이다. 메모 리는, 프로세서로 하여금, 제2 측면에 따른 방법을 수행하게 하는 명령을 저장한다. 제7 측면에 따르면, 실행될 때, 하나 이상의 프로세서로 하여금, 비디오 데이터를 인코딩하게 하는 명령을 저장 한 컴퓨터-판독가능 저장 매체가 제안된다. 명령은, 하나 이상의 프로세서로 하여금, 제1 또는 제2 측면, 또는 제1 또는 제2 측면의 임의의 가능한 실시예에 따른 방법을 수행하게 한다. 제8 측면에 따르면, 본 발명은 컴퓨터 상에서 실행될 때, 제1 또는 제2 측면, 또는 제1 또는 제2 측면의 임의의 가능한 실시예에 따른 방법을 수행하기 위한 프로그램 코드를 포함하는 컴퓨터 프로그램 제품에 관한 것이다. 소프트웨어 및 하드웨어에 의한 구현예 비디오 코딩 시스템의 다음의 실시예에서, 비디오 인코더 및 비디오 디코더는 도 26 내지 도 27에 기초하여 설명된다. 도 26은 예시적인 코딩 시스템, 예를 들어, 이 출원의 기법을 사용할 수 있는 비디오 코딩 시스템(또는 줄여서 코딩 시스템)을 예시하는 개략적인 블록도이다. 비디오 코딩 시스템의 비디오 인코더(또는줄여서 인코더) 및 비디오 디코더(또는 줄여서 디코더)는 이 출원에서 설명된 다양한 예에 따라 기 법을 수행하도록 구성될 수 있는 디바이스의 예를 나타낸다. 비디오 인코더 및 비디오 디코더는 위의 실시예 및 예에서 설명된 바와 같은 신경망을 이용하여(이를 포함하거나 이것인 것으로) 구현될 수 있다. 시스 템의 나머지 파트는 신경망에 의해 구현될 수 있지만, 신경망에 의해 구현될 필요가 있는 것은 아니다. 도 26에서 도시된 바와 같이, 코딩 시스템은 인코딩된 픽처 데이터를 예를 들어, 인코딩된 픽처 데이터 를 디코딩하기 위하여 목적지 디바이스에 제공하도록 구성된 출발지 디바이스를 포함한다. 출발지 디바이스는 인코더를 포함하고, 추가적으로, 즉, 임의적으로, 픽처 소스(picture source), 프리-프로세서(pre-processor)(또는 프리-프로세싱 유닛), 예를 들어, 픽처 프리-프로세서, 및 통신 인 터페이스 또는 통신 유닛을 포함할 수 있다. 픽처 소스는 임의의 유형의 픽처 캡처 디바이스, 예를 들어, 실세계 픽처를 캡처하기 위한 카메라, 및/또는 임의의 유형의 픽처 생성 디바이스, 예를 들어, 컴퓨터 애니메이팅된 픽처를 생성하기 위한 컴퓨터-그래픽 프로 세서, 또는 실세계 픽처, 컴퓨터 생성된 픽처(예를 들어, 스크린 컨텐츠, 가상 현실(VR : virtual reality) 픽 처), 및/또는 그 임의의 조합(예를 들어, 증강 현실(AR : augmented reality) 픽처)을 획득하고 및/또는 제공하 기 위한 임의의 유형의 다른 디바이스를 포함할 수 있거나 이러한 디바이스일 수 있다. 픽처 소스는 전술한 픽 처 중의 임의의 픽처를 저장하는 임의의 유형의 메모리 또는 스토리지(storage)일 수 있다. 프리-프로세서 및 프리-프로세싱 유닛에 의해 수행된 프로세싱과 구분하여, 픽처 또는 픽처 데이터(1 7)는 또한, 원시 픽처(raw picture) 또는 원시 픽처 데이터(raw picture data)로 지칭될 수 있다. 프리-프로세서는 (원시) 픽처 데이터를 수신하고, 프리-프로세싱된 픽처 또는 프리-프로세싱된 픽 처 데이터를 획득하기 위하여 픽처 데이터에 대해 프리-프로세싱을 수행하도록 구성된다. 프리-프로세 서에 의해 수행된 프리-프로세싱은, 예를 들어, 트리밍(trimming), (예를 들어, RGB로부터 YCbCr로의) 컬러 포맷 변환, 컬러 정정(color correction), 또는 잡음-제거(de-noising)를 포함할 수 있다. 프리-프로세싱 유닛 은 임의적인 컴포넌트일 수 있다는 것이 이해될 수 있다. 프리-프로세싱 유닛은 임의적인 컴포넌트일 수 있다는 것이 이해될 수 있다. 비디오 인코더는 프리-프로세싱된 픽처 데이터를 수신하고 인코딩된 픽처 데이터를 제공하도록 구 성된다(추가의 세부사항은 위의 1 내지 25에서 설명됨). 출발지 디바이스의 통신 인터페이스는 인코딩된 픽처 데이터를 수신하고, 저장 또는 직접적인 재구 성을 위하여, 인코딩된 픽처 데이터(또는 그 임의의 추가의 프로세싱된 버전(version))를 통신 채널 상 에서 또 다른 디바이스, 예를 들어, 목적지 디바이스 또는 임의의 다른 디바이스로 송신하도록 구성될 수 있다. 목적지 디바이스는 디코더(예를 들어, 비디오 디코더)를 포함하고, 추가적으로, 즉, 임의적으로, 통신 인터페이스 또는 통신 유닛, 포스트-프로세서(post-processor)(또는 포스트-프로세싱 유닛), 및 디스플레이 디바이스를 포함할 수 있다. 목적지 디바이스의 통신 인터페이스는 예를 들어, 출발지 디바이스로부터 직접적으로, 또는 임의의 다른 소스, 예를 들어, 저장 디바이스, 예를 들어, 인코딩된 픽처 데이터 저장 디바이스로부터 인코딩된 픽처 데이터(또는 그 임의의 추가의 프로세싱된 버전)를 수신하고, 인코딩된 픽처 데이터를 디코더에 제 공하도록 구성된다. 통신 인터페이스 및 통신 인터페이스는 출발지 디바이스와 목적지 디바이스 사이의 직접 통신 링크, 예를 들어, 직접 유선 또는 무선 접속을 통해, 또는 임의의 유형의 네트워크, 예를 들어, 유선 또는 무선 네트워크 또는 그 임의의 조합, 또는 임의의 유형의 사설 및 공공 네트워크, 또는 그 임의의 유형의 조합을 통 해, 인코딩된 픽처 데이터 또는 인코딩된 데이터를 송신하거나 수신하도록 구성될 수 있다. 통신 인터페이스는 예를 들어, 인코딩된 픽처 데이터를 적절한 포맷, 예를 들어, 패킷(packet)으로 패 키징하고, 및/또는 통신 링크 또는 통신 네트워크 상에서의 송신을 위한 임의의 유형의 송신 인코딩 또는 프로 세싱을 이용하여 인코딩된 픽처 데이터를 프로세싱하도록 구성될 수 있다. 통신 인터페이스의 대응부를 형성하는 통신 인터페이스는 예를 들어, 송신된 데이터를 수신하고, 인코 딩된 픽처 데이터를 획득하기 위하여 임의의 유형의 대응하는 송신 디코딩 또는 프로세싱 및/또는 디-패키징(de-packaging)을 이용하여 송신 데이터를 프로세싱하도록 구성될 수 있다. 통신 인터페이스 및 통신 인터페이스의 둘 모두는 출발지 디바이스로부터 목적지 디바이스로 가리키는 도 26에서의 통신 채널에 대한 화살표에 의해 지시된 바와 같은 단방향 통신 인터페이스, 또는 양 방향 통신 인터페이스로서 구성될 수 있고, 통신 링크 및/또는 데이터 송신, 예를 들어, 인코딩된 픽처 데이터 송신에 관련된 임의의 다른 정보를 수신확인(acknowledge)하고 교환하기 위하여, 예컨대, 메시지를 전송하고 수 신하도록, 예를 들어, 접속을 셋업(set up)하도록 구성될 수 있다. 비디오 디코더(또는 디코더)는 인코딩된 픽처 데이터를 수신하고 디코딩된 픽처 데이터 또는 디코 딩된 픽처를 제공하도록 구성된다(추가의 세부사항은 예를 들어, 도 1 내지 도 25에 기초하여 위에서 설명 됨). 목적지 디바이스의 포스트-프로세서는 포스트-프로세싱된 픽처 데이터, 예를 들어, 포스트-프로세 싱된 픽처를 획득하기 위하여, 디코딩된 픽처 데이터(또한 재구성된 픽처 데이터로 칭해짐), 예를 들어, 디코딩된 픽처를 포스트-프로세싱하도록 구성된다. 포스트-프로세싱 유닛에 의해 수행된 포스트- 프로세싱은, 예를 들어, (예를 들어, YCbCr로부터 RGB로의) , 컬러 포맷 변환, 컬러 정정, 트리밍, 또는 리-샘 플링(re-sampling), 또는 예를 들어, 디스플레이 디바이스에 의한 디스플레이를 위하여, 예를 들어, 디코딩 된 픽처 데이터를 준비하기 위한 임의의 다른 프로세싱을 포함할 수 있다. 목적지 디바이스의 디스플레이 디바이스는 픽처를 예를 들어, 사용자 또는 뷰어(viewer)에게 디스플레 이하기 위한 포스트-프로세싱된 픽처 데이터를 수신하도록 구성된다. 디스플레이 디바이스는 재구성된 픽처를 표현하기 위한 임의의 유형의 디스플레이, 예를 들어, 통합된 또는 외부의 디스플레이 또는 모니터일 수 있거나 이러한 디스플레이 또는 모니터를 포함할 수 있다. 예를 들어, 디스플레이는 액정 디스플레이(liquid crystal display, LCD), 유기 발광 다이오드(organic light emitting diode, OLED) 디스플레이, 플라즈마 디스 플레이, 프로젝터(projector), 마이크로 LED 디스플레이, 액정 온 실리콘(liquid crystal on silicon, LCoS), 디지털 광 프로세서(digital light processor, DLP), 또는 임의의 유형의 다른 디스플레이를 포함할 수 있다. 코딩 시스템은 훈련 엔진을 더 포함한다. 훈련 엔진은 입력 픽처, 픽처 영역, 또는 픽처 블록을 프 로세싱하기 위하여 인코더(특히, 인코더 내의 신경망 모듈) 또는 디코더(특히, 디코더 내의 신 경망 모듈)를 훈련하도록 구성된다. 위에서 설명된 실시예 및 예는 신경망 프로세싱 픽처(때때로, 프레임으로서 지칭됨)에 대하여 설명되었다는 것이 주목된다. 그러나, 본 개시내용은 또한, 임의의 다른 세분화도에 적용가능 하고: 전체 픽처의 부분(영역)은 인코딩 및 디코딩 동안에 픽처로서 취급될 수 있다. 신경망 기반 실시예는 사전-훈련된 네트워크를 채용할 수 있으므로, 훈련 엔진은 본 개시내용의 시스템에서 제 공될 필요가 없다는 것이 주목된다. 훈련 데이터는 데이터베이스(도시되지 않음) 내에 저장될 수 있다. 훈련 엔진은 타깃 모델을 획득하기 위하 여 훈련 데이터에 기초하여 훈련을 수행한다(예를 들어, 타깃 모델은 객체 인식, 객체 분류, 픽처 세그먼트화, 또는 픽처 인코딩 및 재구성 등을 위하여 이용된 신경망일 수 있음). 훈련 데이터의 소스는 이 출원의 이 실시 예에서 제한되지 않는다는 것이 주목되어야 한다. 예를 들어, 훈련 데이터는 모델 훈련을 수행하기 위하여 클라 우드 또는 또 다른 장소로부터 획득될 수 있다. 훈련 엔진에 의한 훈련을 통해 획득된 타깃 모델은 코딩 시스템(10 및 40)에 적용될 수 있고, 예를 들어, 도 26에서 도시된 출발지 디바이스(예를 들어, 인코더) 또는 목적지 디바이스(예를 들어, 디코더 )에 적용될 수 있다. 훈련 엔진은 클라우드 상에서의 훈련을 통해 타깃 모델을 획득할 수 있고, 코딩 시스템은 클라우드로부터 타깃 모델을 다운로딩하고 타깃 모델을 이용한다. 대안적으로, 훈련 엔진은 클라우드 상에서의 훈련을 통해 타깃 모델을 획득할 수 있고, 타깃 모델을 이용할 수 있고, 코딩 시스템은 클라우드로부터 프로세싱 결과를 직접적으로 획득한다. 도 26은 출발지 디바이스 및 목적지 디바이스를 별도의 디바이스로서 도시하지만, 디바이스의 실시예는 또한, 둘 모두 또는 둘 모두의 기능성인, 출발지 디바이스 또는 대응하는 기능성, 및 목적지 디바이스 또는 대응하는 기능성을 포함할 수 있다. 이러한 실시예에서, 출발지 디바이스 또는 대응하는 기능성, 및 목적지 디바이스 또는 대응하는 기능성은 동일한 하드웨어 및/또는 소프트웨어를 이용하여, 또는 별도의 하 드웨어 및/또는 소프트웨어 또는 그 임의의 조합에 의해 구현될 수 있다. 설명에 기초하여 통상의 기술자에게 분명한 바와 같이, 도 26에서 도시된 바와 같은 상이한 유닛의 기능성 또는 출발지 디바이스 및/또는 목적지 디바이스 내에서의 기능성의 존재 및 (정확한) 분할은 실제적인 디바이스 및 애플리케이션에 따라 변동될 수 있다. 인코더(예를 들어, 비디오 인코더) 또는 디코더(예를 들어, 디코더) 또는 인코더 및 디코 더의 둘 모두는, 하나 이상의 마이크로프로세서, 디지털 신호 프로세서(digital signal processor, DSP), 애플리케이션-특정 집적 회로(application-specific integrated circuit, ASIC), 필드-프로그래밍가능 게이트 어레이(field-programmable gate array, FPGA), 개별 로직, 하드웨어, 비디오 코딩 전용, 또는 그 임의의 조합 과 같은, 도 27에서 도시된 바와 같은 프로세싱 회로를 통해 구현될 수 있다. 인코더는 인코더에 대하 여 논의된 바와 같은 다양한 모듈 및/또는 본 명세서에서 설명된 임의의 다른 인코더 시스템 또는 서브시스템을 구체화하기 위하여 프로세싱 회로를 통해 구현될 수 있다. 디코더는 디코더에 대하여 논의된 바와 같은 다양한 모듈 및/또는 본 명세서에서 설명된 임의의 다른 디코더 시스템 또는 서브시스템을 구체화하기 위 하여 프로세싱 회로를 통해 구현될 수 있다. 프로세싱 회로는 더 이후에 논의된 바와 같은 다양한 동작을 수행하도록 구성될 수 있다. 도 29에서 도시된 바와 같이, 기법이 부분적으로 소프트웨어로 구현될 경우에, 디 바이스는 소프트웨어를 위한 명령을 적당한 비-일시적(non-transitory) 컴퓨터-판독가능 저장 매체 내에 저장할 수 있고, 본 발명의 기법을 수행하기 위하여 하나 이상의 프로세서를 이용하여 명령을 하드웨어로 실행할 수 있 다. 비디오 인코더 및 비디오 디코더의 어느 하나는 예를 들어, 도 27에서 도시된 바와 같이, 단일 디 바이스 내의 조합된 인코더/디코더(encoder/decoder, CODEC)의 부분으로서 통합될 수 있다. 출발지 디바이스 및 목적지 디바이스는 임의의 유형의 핸드헬드(handheld) 또는 정지식 디바이스, 예를 들어, 노트북 또는 랩톱 컴퓨터, 모바일 전화, 스마트 폰, 태블릿 또는 태블릿 컴퓨터, 카메라, 데스크톱 컴퓨 터, 셋톱 박스(set-top box), 텔레비전, 디스플레이 디바이스, 디지털 미디어 플레이어, 비디오 게이밍 콘솔 (video gaming console), (컨텐츠 서비스 서버 또는 컨텐츠 전달 서버와 같은) 비디오 스트리밍 디바이스, 브로 드캐스트 수신기 디바이스, 브로드캐스트 송신기 디바이스 등을 포함하는 광범위한 디바이스 중의 임의의 디바 이스를 포함할 수 있고, 오퍼레이팅 시스템(operating system)을 이용하지 않을 수 있거나 임의의 유형의 오퍼 레이팅 시스템을 이용할 수 있다. 일부 경우에는, 출발지 디바이스 및 목적지 디바이스가 무선 통신을 위하여 구비될 수 있다. 그러므로, 출발지 디바이스 및 목적지 디바이스는 무선 통신 디바이스일 수 있 다. 일부 경우에는, 도 26에서 예시된 비디오 코딩 시스템이 단지 예이고, 본 출원의 기법은 인코딩 및 디코딩 디바이스 사이의 임의의 데이터 통신을 반드시 포함하지는 않는 비디오 코딩 설정(예를 들어, 비디오 인코딩 또 는 비디오 디코딩)에 적용할 수 있다. 다른 예에서, 데이터는 로컬 메모리로부터 인출(retrieve)되고, 네트워크 상에서 스트리밍되는 등과 같다. 비디오 인코딩 디바이스는 데이터를 인코딩하고 인코딩된 데이터를 메모리 내 로 저장할 수 있고, 및/또는 비디오 디코딩 디바이스는 메모리로부터 데이터를 인출하고 데이터를 디코딩할 수 있다. 일부 예에서, 인코딩 및 디코딩은, 서로 통신하지 않지만, 간단하게 데이터를 메모리로 인코딩하고 및/또 는 메모리로부터 데이터를 인출하고 데이터를 디코딩하는 디바이스에 의해 수행된다. 도 27은 예시적인 실시예에 따른, 인코더 및/또는 디코더를 포함하는 비디오 코딩 시스템의 예의 예시적인 도면이다. 비디오 코딩 시스템은 이미징 디바이스, 비디오 인코더, 비디오 디코더(및 /또는 프로세싱 회로에 의해 구현된 비디오 인코더/디코더), 안테나, 하나 이상의 프로세서, 하나 이상의 메모리, 및/또는 디스플레이 디바이스를 포함할 수 있다. 도 27에서 도시된 바와 같이, 이미징 디바이스, 안테나, 프로세싱 회로, 비디오 인코더, 비디 오 디코더, 프로세서, 메모리, 및/또는 디스플레이 디바이스는 서로 통신할 수 있다. 비디오 코딩 시스템은 상이한 예에서 오직 비디오 인코더 또는 오직 비디오 디코더를 포함할 수 있다. 일부 예에서, 안테나는 비디오 데이터의 인코딩된 비트스트림을 송신하거나 수신하도록 구성될 수 있다. 추 가로, 일부 예에서, 디스플레이 디바이스는 비디오 데이터를 제시하도록 구성될 수 있다. 프로세싱 회로 는 애플리케이션-특정 집적 회로(application-specific integrated circuit, ASIC) 로직, 그래픽 프로세서, 범용 프로세서 등을 포함할 수 있다. 비디오 코딩 시스템은 또한, 임의적인 프로세서를 포함 할 수 있다. 임의적인 프로세서는 애플리케이션-특정 집적 회로(application-specific integrated circuit, ASIC) 로직, 그래픽 프로세서, 범용 프로세서 등을 유사하게 포함할 수 있다. 추가적으로, 메모리(4 4)는 임의의 유형의 메모리, 예를 들어, 휘발성 메모리(예를 들어, 정적 랜덤 액세스 메모리(static random access memory, SRAM) 또는 동적 랜덤 액세스 메모리(dynamic random access memory, DRAM)) 또는 비휘발성 메 모리(예를 들어, 플래시 메모리)일 수 있다. 비-제한적인 예에서, 메모리는 캐시 메모리에 의해 구현될 수 있다. 다른 예에서, 로직 회로 및/또는 프로세싱 회로는 픽처 버퍼를 구현하기 위한 메모리(예를 들어,캐시)를 포함할 수 있다. 일부 예에서, 로직 회로를 이용함으로써 구현된 비디오 인코더는 (예를 들어, 프로세싱 회로 또는 메모 리)에 의해 구현되는) 픽처 버퍼 및 (예를 들어, 프로세싱 회로에 의해 구현되는) 그래픽 프로세싱 유 닛을 포함할 수 있다. 그래픽 프로세싱 유닛은 픽처 버퍼에 통신가능하게 결합될 수 있다. 그래픽 프로세싱 유 닛은 본 명세서에서 설명된 바와 같은 다양한 기능적 모듈을 구체화하기 위하여 로직 회로부를 통해 구현된 바와 같은 비디오 인코더를 포함할 수 있다. 로직 회로는 이 명세서에서 설명된 다양한 동작을 수행하도록 구성될 수 있다. 일부 예에서, 디코더는 이 명세서에서 설명된 디코더 및/또는 임의의 다른 디코더 시스템 또는 서브시 스템을 참조하여 설명되는 다양한 모듈을 구현하기 위하여, 로직 회로에 의해 유사한 방식으로 구현될 수 있다. 일부 예에서, 로직 회로를 이용함으로써 구현된 디코더는 (프로세싱 회로 또는 메모리)에 의 해 구현되는) 픽처 버퍼 및 (예를 들어, 프로세싱 회로에 의해 구현되는) 그래픽 프로세싱 유닛을 포함할 수 있다. 그래픽 프로세싱 유닛은 픽처 버퍼에 통신가능하게 결합될 수 있다. 그래픽 프로세싱 유닛은 본 명세 서에서 설명된 다양한 모듈을 구체화하기 위하여 로직 회로부를 통해 구현된 바와 같은 비디오 인코더 를 포함할 수 있다. 일부 예에서, 안테나는 비디오 데이터의 인코딩된 비트스트림을 수신하도록 구성될 수 있다. 설명된 바와 같이, 인코딩된 비트스트림은 이 명세서에서 설명된 비디오 프레임 코딩에 관련된 데이터, 지시자, 인덱스 값, 모드 선택 데이터 등, 예를 들어, 코딩 파티셔닝에 관련된 데이터(예를 들어, 변환 계수 또는 양자화된 변환 계 수, (설명된 바와 같은) 임의적인 지시자, 및/또는 코딩 파티셔닝을 정의하는 데이터)를 포함할 수 있다. 비디 오 코딩 시스템은, 안테나에 결합되며 인코딩된 비트스트림을 디코딩하도록 구성되는 디코더를 더 포함할 수 있다. 디스플레이 디바이스는 비디오 프레임을 제시하도록 구성된다. 이 출원의 이 실시예에서, 인코더를 참조하여 설명된 예에 대하여, 디코더는 역 프로세스를 수행하도록 구성될 수 있다는 것이 이해되어야 한다. 시그널링 신택스 엘리먼트에 관하여, 디코더는 이러한 신택스 엘 리먼트를 수신하고 파싱하고, 이에 대응하여, 관련된 비디오 데이터를 디코딩하도록 구성될 수 있다. 일부 예에 서, 인코더는 신택스 엘리먼트를 인코딩된 비디오 비트스트림으로 엔트로피 인코딩할 수 있다. 이러한 예에 서, 비디오 디코더는 이러한 신택스 엘리먼트를 파싱할 수 있고, 이에 따라, 연관된 비디오 데이터를 디코 딩할 수 있다. 도 28은 개시내용의 실시예에 따른 비디오 코딩 디바이스의 개략도이다. 비디오 코딩 디바이스는 본 명세서에서 설명된 바와 같은 개시된 실시예를 구현하기 위하여 적당하다. 실시예에서, 비디오 코딩 디바이스 는 도 26의 비디오 디코더와 같은 디코더, 또는 도 26의 비디오 인코더와 같은 인코더일 수 있다. 위에서 언급된 바와 같이, 본 명세서에서의 픽처(비디오) 인코더 및 디코더를 지칭할 때, 그것은 반드시, 인간 뷰어를 위한 재구성을 포함하는 픽처 데이터 인코딩 및 디코딩을 제공하는 인코더 및 디코더인 것은 아니다. 오 히려, 인코더는 비트스트림을 제공할 수 있고, 디코더는 컴퓨터 시각 작업에서 이용되어야 할 픽처 데이터 또는 픽처 특징 데이터를 디코딩할 수 있다. 비디오 코딩 디바이스는 데이터를 수신하기 위한 유입 포트(또는 입력 포트) 및 수신기 유닛 (receiver unit, Rx); 데이터를 프로세싱하기 위한 프로세서, 로직 유닛, 또는 중앙 프로세싱 유닛 (central processing unit, CPU); 데이터를 송신하기 위한 송신기 유닛(transmitter unit, Tx) 및 유출 포트; 및 데이터를 저장하기 위한 메모리를 포함한다. 비디오 코딩 디바이스는 또한, 광학 또는 전기 신호의 유출 또는 유입을 위하여 유입 포트, 수신기 유닛, 송신기 유닛, 및 유출 포 트에 결합된 광학-대-전기(optical-to-electrical, OE) 컴포넌트 및 전기-대-광학(electrical-to- optical, EO) 컴포넌트를 포함할 수 있다. 프로세서는 하드웨어 및 소프트웨어에 의해 구현된다. 프로세서는 하나 이상의 CPU 칩, 코어(예를 들 어, 멀티-코어 프로세서), FPGA, ASIC, 및 DSP로서 구현될 수 있다. 프로세서는 유입 포트, 수신기 유닛, 송신기 유닛, 유출 포트, 및 메모리와 통신한다. 프로세서는 코딩 모듈 (예를 들어, 신경망(NN : neural network)-기반 코딩 모듈)을 포함한다. 코딩 모듈은 위에서 설명되 는 개시된 실시예를 구현한다. 예를 들어, 코딩 모듈은 다양한 코딩 동작을 구현하거나, 프로세싱하거나, 준비하거나, 제공한다. 그러므로, 인코딩/디코딩 모듈의 포함은 비디오 코딩 디바이스의 기능에 대한 상당한 개선을 제공하고, 상이한 상태로의 비디오 코딩 디바이스의 스위칭에 영향을 준다. 대안적으로, 코 딩 모듈은 메모리 내에 저장되고 프로세서에 의해 실행된 명령으로서 구현된다.메모리는 하나 이상의 디스크, 테이프 드라이브, 및 솔리드-스테이트 드라이브를 포함하고, 이러한 프로그 램이 실행을 위하여 선택될 때에 프로그램을 저장하고, 프로그램 실행 동안에 판독되는 명령 및 데이터를 저장 하기 위하여, 오버플로우 데이터 저장 디바이스로서 이용될 수 있다. 메모리는 휘발성 및/또는 비휘발성일 수 있고, 판독-전용 메모리(read-only memory, ROM), 랜덤 액세스 메모리(random access memory, RAM), 3진 컨 텐츠-어드레싱가능 메모리(ternary content-addressable memory, TCAM), 및/또는 정적 랜덤-액세스 메모리 (static random-access memory, SRAM)일 수 있다. 도 29는 예시적인 실시예에 따른, 도 26에서의 출발지 디바이스 및 목적지 디바이스의 어느 하나 또는 둘 모두로서 이용될 수 있는 장치의 단순화된 블록도이다. 장치 내의 프로세서는 중앙 프로세싱 유닛일 수 있다. 대안적으로, 프로세서는 지금-현존하거나 이후에 개발된, 정보를 조작할 수 있거나 프로세싱할 수 있는 임의의 다른 유형의 디바이스 또는 다수의 디바이 스일 수 있다. 개시된 구현예는 도시된 바와 같은 단일 프로세서, 예를 들어, 프로세서로 실시될 수 있지 만, 속력 및 효율에서의 장점은 하나 초과의 프로세서를 이용하여 달성될 수 있다. 장치 내의 메모리는 구현예에서 판독-전용 메모리(read-only memory, ROM) 디바이스 또는 랜덤 액세 스 메모리(random access memory, RAM) 디바이스일 수 있다. 임의의 다른 적당한 유형의 저장 디바이스가 메모 리로서 이용될 수 있다. 메모리는 버스를 이용하여 프로세서에 의해 액세스되는 코드 및 데이터를 포함할 수 있다. 메모리는 오퍼레이팅 시스템(operating system) 및 애플리케이션 프 로그램을 더 포함할 수 있고, 여기서, 애플리케이션 프로그램은 프로세서가 여기에서 설명된 방 법을 수행하는 것을 허용하는 적어도 하나의 프로그램을 포함한다. 예를 들어, 애플리케이션 프로그램은, 여기에서 설명된 방법을 수행하는 비디오 코딩 애플리케이션을 더 포함하는 애플리케이션 1 내지 N을 포함할 수 있다. 장치는 또한, 디스플레이와 같은 하나 이상의 출력 디바이스를 포함할 수 있다. 디스플레이는 하나의 예에서, 디스플레이를, 터치 입력을 감지하도록 동작가능한 터치 감지 엘리먼트와 조합하는 터치 감지 디스플레이일 수 있다. 디스플레이는 버스를 통해 프로세서에 결합될 수 있다. 단일 버스로서 여기에서 도시되지만, 장치의 버스는 다수의 버스로 구성될 수 있다. 추가로, 보조 스 토리지는 장치의 다른 컴포넌트에 직접적으로 결합될 수 있거나 네트워크를 통해 액세스될 수 있고, 메모리 카드와 같은 단일 통합된 유닛, 또는 다수의 메모리 카드와 같은 다수의 유닛을 포함할 수 있다. 장치 는 이에 따라, 널리 다양한 구성으로 구현될 수 있다. 이 출원의 실시예는 신경망의 적용에 관한 것이다. 이해의 용이함을 위하여, 다음은 이 출원의 실시예에서 이용"}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "된 일부 명사 또는 용어를 먼저 설명한다. 명사 또는 용어는 또한, 본 발명의 내용의 일부로서 이용된다. 신경망 신경망(neural Network, NN)은 머신 학습 모델이다. 신경망은 뉴런(neuron)을 포함할 수 있다. 뉴런은 xs 및 1 의 절편(intercept)을 입력으로서 이용하는 연산 유닛일 수 있고, 여기서, 연산 유닛의 출력은 다음과 같을 수 있고: (1-1) 여기서, s = 1, 2, ..., 또는 n이고, n은 1 초과인 자연수이고, Ws는 xs의 가중치이고, b는 뉴런의 바이어스 (bias)이다. f는 뉴런의 활성화 함수(activation function)이고, 활성화 함수는 비-선형 특징을 신경망 내로 도 입하기 위하여 이용되어, 뉴런 내의 입력 신호를 출력 신호로 변환한다. 활성화 함수의 출력 신호는 다음 컨볼 루션 계층의 입력으로서 이용될 수 있다. 활성화 함수는 시그모이드 함수(sigmoid function)일 수 있다. 신경망 은 많은 단일 뉴런을 함께 접속함으로써 형성된 네트워크이다. 구체적으로 말하면, 뉴런의 출력은 또 다른 뉴런 의 입력일 수 있다. 각각의 뉴런의 입력은 국소적 수용성 필드(local receptive field)의 특징을 추출하기 위하 여 이전 계층의 국소적 수용성 필드에 접속될 수 있다. 국소적 수용성 필드는 몇몇 뉴런을 포함하는 영역일 수 있다. 심층 신경망 멀티-계층 신경망으로서 또한 지칭된 심층 신경망(deep neural network, DNN)은 많은 은닉된 계층을 가지는 신 경망으로서 이해될 수 있다. 본 명세서에서의 \"많은\"은 특수한 측정 표준을 가지지는 않는다. DNN은 상이한 계 층의 위치에 기초하여 분할되고, DNN 내의 신경망은 3개의 유형: 입력 계층, 은닉된 계층, 및 출력 계층으로 분 할될 수 있다. 일반적으로, 첫 번째 계층은 입력 계층이고, 마지막 계층은 출력 계층이고, 중간 계층은 은닉된 계층이다. 계층은 완전히 접속된다. 구체적으로 말하면, i 번째 계층에서의 임의의 뉴런은 (i+1) 번째 계층에서 의 임의의 뉴런에 확실히 접속된다. DNN은 복잡한 것으로 보이지만, DNN은 실제적으로, 각각의 계층에서의 작동 의 측면에서 복잡하지 않고, 다음의 선형 관계 표현으로서 간단하게 표현된다: , 여기서, 는 입력 벡터이고, 는 출력 벡터이고, 는 바이어스 벡터(bias vector)이고, 는 가중치 행렬(또한, 계수로서 지칭됨)이고, 는 활성화 함수이다. 각각의 계층에서, 출력 벡터 는 입력 벡터 에 대해 이러한 간단한 동작을 수행함으로써 획득된다. DNN 내에 많은 계층이 있으므로, 또한, 많은 계수 및 바이어스 벡터 가 있다. DNN에서의 이 파라미터의 정의는 다음과 같다: 계수 는 예로서 이용된다. 3-계층 DNN에서는, 제 2 계층에서의 제4 뉴런으로부터 제3 계층에서의 제2 뉴런으로의 선형 계수가 으로서 정의되는 것으로 가정 된다. 윗첨자(superscript) 3은 계수 가 위치되는 계층을 나타내고, 아랫첨자(subscript)는 출력 제3-계층 인덱스 2 및 입력 제2-계층 인덱스 4에 대응한다. 결론적으로, (L-1) 번째 계층에서의 k 번째 뉴런으로부터 L 번째 계층에서의 j 번째 뉴런으로의 계수는 로서 정의된다. 입력 계층에서 파라미터 가 없다는 것이 주목되어야 한다. 심층 신경망에서, 더 많은 은닉된 계층은 네트워크가 실세계에서의 복잡한 경우를 더 많이 설 명할 수 있게 한다. 이론적으로, 더 큰 수량의 파라미터를 갖는 모델은 더 높은 복잡도 및 더 큰 \"용량 (capacity)\"을 지시하고, 모델이 더 복잡한 학습 작업을 완료할 수 있다는 것을 지시한다. 심층 신경망을 훈련 시키는 것은 가중치 행렬(weight matrix)을 학습시키는 프로세스이고, 훈련의 최종적인 목적은 훈련된 심층 신 경망의 모든 계층의 가중치 행렬(많은 계층에서 벡터 에 의해 형성된 가중치 행렬)을 획득하기 위한 것이다. 컨볼루션 신경망 컨볼루션 신경망(convolutional neuron network, CNN)은 컨볼루션 구조를 갖는 심층 신경망이고, 심층 학습 (deep learning) 아키텍처이다. 심층 학습 아키텍처에서, 멀티-계층 학습은 머신 학습 알고리즘(machine learning algorithm)을 이용함으로써 상이한 추상 레벨(abstract level)에서 수행된다. 심층 학습 아키텍처로서, CNN은 피드-포워드(feed-forward) 인공 신경망(artificial neural network)이다. 피드-포워드 인공 신경망 내의 뉴런은 뉴런으로의 픽처 입력에 응답할 수 있다. 컨볼루션 신경망은 컨볼루션 계층 및 풀링 계층(pooling layer)에 의해 구성된 특징 추출기(feature extractor)를 포함한다. 특징 추출기는 필터로서 간주 될 수 있다. 컨볼루션 프로세스는 입력 이미지 또는 컨볼루션 특징 평면(특징 맵)에 대해 컨볼루션을 수행하기 위하여 훈련가능한 필터를 이용하는 것으로서 간주될 수 있다. 컨볼루션 계층은, 컨볼루션 신경망 내에 있고, 컨볼루션 프로세싱이 입력 신호에 대해 수행되는 뉴런 계층이다. 컨볼루션 계층은 복수의 컨볼루션 연산자(convolution operator)를 포함할 수 있다. 컨볼루션 연산자는 또 한, 커널(kernel)로서 지칭된다. 이미지 프로세싱에서, 컨볼루션 연산자는 입력 이미지 행렬로부터 특정 정보를 추출하는 필터로서 기능한다. 컨볼루션 연산자는 필수적으로, 가중치 행렬일 수 있고, 가중치 행렬은 통상적으 로 사전정의된다. 이미지에 대해 컨볼루션 동작을 수행하는 프로세스에서, 가중치 행렬은 통상적으로, 입력 이 미지 상의 수평 방향에서 하나의 픽셀(또는, 스트라이드(stride)의 값에 따라서는 2개의 픽셀)의 세분화도 레벨 로 픽셀을 프로세싱하여, 이미지로부터 특정 특징을 추출한다. 가중치 행렬의 크기는 픽처의 크기에 관련되어야 한다. 가중치 행렬의 심도 차원(depth dimension)은 입력 픽처의 심도 차원과 동일한 것이 주목되어야 한다. 컨 볼루션 동작 동안에, 가중치 행렬은 입력 픽처의 전체 심도로 확장된다. 그러므로, 단일 심도 차원의 컨볼루션 출력은 단일 가중치 행렬과의 컨볼루션을 통해 생성된다. 그러나, 대부분의 경우에, 단일 가중치 행렬이 이용되 는 것이 아니라, 동일한 크기(행 x 열)를 갖는 복수의 가중치 행렬, 즉, 복수의 동일-유형 행렬이 적용된다. 가 중치 행렬의 출력은 컨볼루션 픽처의 심도 차원을 형성하기 위하여 스택된다. 본 명세서에서의 차원은 상기한 \"복수\"에 기초하여 결정되는 것으로서 이해될 수 있다. 상이한 가중치 행렬은 픽처로부터 상이한 특징을 추출 하기 위하여 이용될 수 있다. 예를 들어, 하나의 가중치 행렬은 픽처의 에지 정보(edge information)를 추출하기 위하여 이용되고, 또 다른 가중치 행렬은 픽처의 특정 컬러(color)를 추출하기 위하여 이용되고, 추가의 가 중치 행렬은 픽처 내의 불필요한 잡음을 블러링(blur)하기 위하여 이용된다. 복수의 가중치 행렬의 크기(행 x 열)는 동일하다. 동일한 크기를 갖는 복수의 가중치 행렬로부터 추출된 특징 맵의 크기는 또한 동일하고, 그 다 음으로, 동일한 크기를 갖는 복수의 추출된 특징 맵은 컨볼루션 동작의 출력을 형성하기 위하여 조합된다. 이 가중치 행렬에서의 가중치 값은 실제적인 애플리케이션에서의 대용량 훈련을 통해 획득될 필요가 있다. 훈련을 통해 획득된 가중치 값을 이용함으로써 형성된 각각의 가중치 행렬은 입력 이미지로부터 정보를 추출하기 위하 여 이용될 수 있어서, 컨볼루션 신경망이 올바른 예측을 수행하는 것을 가능하게 할 수 있다. 컨볼루션 신경망 이 복수의 컨볼루션 계층을 가질 때, 상대적으로 큰 수량의 일반적인 특징은 통상적으로, 초기 컨볼루션 계층에 서 추출된다. 일반적인 특징은 또한, 낮은-레벨 특징(low-level feature)으로서 지칭될 수 있다. 컨볼루션 신경 망의 심도가 증가함에 따라, 후속 컨볼루션 계층에서 추출된 특징은 더 복잡하고, 예를 들어, 높은-레벨 시맨틱 특징(high-level semantic feature)이다. 더 높은-레벨 시맨틱을 갖는 특징은 해결-대상 문제에 더 많이 적용가 능하다. 훈련 파라미터의 수량은 종종 감소될 필요가 있다. 그러므로, 풀링 계층은 종종, 컨볼루션 계층 후에 주기적으 로 도입될 필요가 있다. 하나의 컨볼루션 계층은 하나의 풀링 계층에 선행할 수 있거나, 복수의 컨볼루션 계층 이 하나 이상의 풀링 계층에 선행할 수 있다. 픽처 프로세싱 동안에, 풀링 계층은 픽처의 공간 크기를 감소시키 기 위하여 오직 이용된다. 풀링 계층은 평균 풀링 연산자 및/또는 최대 풀링 연산자를 포함할 수 있어서, 상대 적으로 작은 크기를 갖는 픽처를 획득하기 위하여 입력 픽처에 대해 샘플링을 수행할 수 있다. 평균 풀링 연산 자는 특정 범위에서 픽처 내의 픽셀 값을 계산하기 위하여 이용될 수 있어서, 평균 값을 생성할 수 있다. 평균 값은 평균 풀링 결과로서 이용된다. 최대 풀링 연산자는 특정 범위에서 최대 값을 갖는 픽셀을 최대 풀링 결과 로서 선택하기 위하여 이용될 수 있다. 추가적으로, 컨볼루션 계층에서의 가중치 행렬의 크기가 픽처 크기에 관 련될 필요가 있다는 것과 유사하게, 풀링 계층에서의 연산자는 또한, 픽처 크기에 관련될 필요가 있다. 풀링 계 층으로부터의 프로세싱된 픽처 출력의 크기는 풀링 계층으로의 픽처 입력의 크기 미만일 수 있다. 풀링 계층으 로부터의 픽처 출력 내의 각각의 픽셀은 풀링 계층으로의 픽처 입력의 대응하는 서브-영역의 평균 값 또는 최대 값을 나타낸다. 컨볼루션 계층/풀링 계층에서 수행된 프로세싱 후에, 컨볼루션 신경망은 요구된 출력 정보를 출력하도록 준비되 지 않는데, 그 이유는 위에서 설명된 바와 같이, 컨볼루션 계층/풀링 계층에서는, 특징만이 추출되고, 입력 이 미지로부터 기인하는 파라미터는 감소되기 때문이다. 그러나, 최종적인 출력 정보(요구된 클래스 정보(class information) 또는 다른 관련된 정보)를 생성하기 위하여, 컨볼루션 신경망은 하나의 요구된 클래스 또는 요구 된 클래스의 그룹의 출력을 생성하기 위하여 신경망 계층을 이용할 필요가 있다. 그러므로, 컨볼루션 신경망 계 층은 복수의 은닉된 계층을 포함할 수 있다. 복수의 은닉된 계층 내에 포함된 파라미터는 특정 태스크 유형의 관련된 훈련 데이터에 기초한 사전-훈련(pre-training)을 통해 획득될 수 있다. 예를 들어, 태스크 유형은 이미 지 인식, 이미지 분류, 및 수퍼-해상도(super-resolution) 이미지 재구성을 포함할 수 있다. 임의적으로, 신경망 계층에서, 복수의 은닉된 계층은 전체 컨볼루션 신경망의 출력 계층에 선행한다. 출력 계층 은 카테고리 교차 엔트로피(categorical cross entropy)와 유사한 손실 함수를 가지고, 손실 함수는 구체적으로, 예측 오차를 계산하기 위하여 이용된다. 일단 전체 컨볼루션 신경망의 순방향 전파(forward propagation)가 완료되면, 역방향 전파(backward propagation)는 위에서 언급된 각각의 계층의 가중치 값 및 편차를 업데이트하기 시작하여, 컨볼루션 신경망의 손실, 및 출력 계층을 이용하는 것에 의한 컨볼루션 신경망 에 의한 결과 출력과 이상적인 결과 사이의 오차를 감소시킨다. 순환 신경망 순환 신경망(recurrent neural network, RNN)은 시퀀스 데이터를 프로세싱하기 위하여 이용된다. 기존의 신경망 모델에서는, 입력 계층으로부터 은닉된 계층까지, 그 다음으로, 출력 계층까지, 계층은 완전히 접속되고, 각각 의 계층에서의 노드는 접속되지 않는다. 이러한 공통적인 신경망은 많은 상이한 문제를 해결하지만, 많은 다른 문제를 여전히 해결할 수 없다. 예를 들어, 문장 내의 단어가 예측되어야 하는 경우에, 이전 단어가 통상적으로 이용될 필요가 있는데, 그 이유는 문장 내의 인접한 단어가 독립적이지 않기 때문이다. RNN이 순환 신경망으로 서 지칭되는 이유는, 시퀀스의 현재 출력이 또한, 시퀀스의 이전 출력에 관련된다는 것이다. 특정 표현 형태는, 네트워크가 이전 정보를 기억하고 이전 정보를 현재 출력의 계산에 적용한다는 것이다. 구체적으로 말하면, 은 닉된 계층에서의 노드는 접속되고, 은닉된 계층의 입력은 입력 계층의 출력을 포함할 뿐만 아니라, 이전 순간에 서의 은닉된 계층의 출력을 포함한다. 이론적으로, RNN은 임의의 길이의 시퀀스 데이터를 프로세싱할 수 있다. RNN에 대한 훈련은 기존의 CNN 또는 DNN에 대한 훈련과 동일하다. 오차 역방향 전파 알고리즘이 또한 이용되지만, 차이가 있다: RNN이 확장되는 경우에, RNN의 W와 같은 파라미터가 공유된다. 이것은 상기한 예에서 설명된 기존의 신경망과는 상이하다. 추가적으로, 경도 하강 알고리즘의 이용 동안에, 각각의 단계에서의 출력은 현재 단계에서의 네트워크 뿐만 아니라, 몇몇 이전 단계에서의 네트워크 스테이터스에 종속된다. 학습 알고리즘은 시 간을 통한 역방향 전파(backward propagation through time, BPTT) 알고리즘으로서 지칭된다. 컨볼루션 신경망이 있는데, 순환 신경망이 왜 요구되는가? 이유는 간단하다. 컨볼루션 신경망에서는, 엘리먼트 가 서로에 독립적이고, 입력 및 출력이 또한, 개 및 고양이와 같이 독립적인 것으로 가정된다. 그러나, 실세계 에서는, 많은 엘리먼트가 상호접속된다. 예를 들어, 주식은 시간에 따라 변화한다. 또 다른 예를 들어, 개인이 말한다: 나는 여행을 좋아하고, 나의 가장 좋아하는 장소는 Yunnan이다. 나는 기회가 있을 경우에 갈 것이다. 여기서, 사람들은 개인이 \"Yunnan\"에 갈 것이라는 것을 알아야 한다. 그 이유는 사람들이 문맥의 컨텐츠에 기초 하여 답변을 도출할 수 있다는 것이다. 그러나, 머신이 어떻게 이것을 행할 수 있을까? RNN이 등장한다. RNN은 머신이 인간과 같이 기억할 수 있게 하도록 의도된다. 그러므로, RNN의 출력은 현재 입력 정보 및 이력적 기억 된 정보에 종속될 필요가 있다. 재귀적 잔차 컨볼루션 신경망(recursive residual convolutional neuron network, RR-CNN) 인공 신경망(artificial neural network, ANN) 손실 함수 심층 신경망을 훈련시키는 프로세스에서는, 심층 신경망의 출력이 실제적으로 예상되는 예측된 값에 가능한 한 근접한 것으로 예상되기 때문에, 현재 네트워크의 예측된 값, 및 실제적으로 예상되는 타깃 값은 비교될 수 있 고, 그 다음으로, 신경망의 각각의 계층의 가중치 벡터는 예측된 값과 타깃 값 사이의 차이에 기초하여 업데이 트된다(확실히, 제1 업데이트 전에 초기화 프로세스가 통상적으로 있고, 구체적으로 말하면, 파라미터는 심층 신경망의 모든 계층에 대하여 사전구성됨). 예를 들어, 네트워크의 예측된 값이 큰 경우에, 가중치 벡터는 예측 된 값을 감소시키도록 조절되고, 심층 신경망이 실제적으로 예상되는 타깃 값, 또는 실제적으로 예상되는 타깃 값에 매우 근접한 값을 예측할 수 있을 때까지, 조절이 계속적으로 수행된다. 그러므로, \"비교를 통해, 예측된 값과 타깃 값 사이의 차이를 어떻게 획득할 것인지\"는 사전정의될 필요가 있다. 이것은 손실 함수(loss function) 또는 목적 함수(objective function)이다. 손실 함수 및 목적 함수는 예측된 값과 타깃 값 사이의 차 이를 측정하기 위하여 이용된 중요한 수학식이다. 손실 함수는 예로서 이용된다. 손실 함수의 더 높은 출력 값 (손실)은 더 큰 차이를 지시한다. 그러므로, 심층 신경망의 훈련은 손실을 가능한 한 많이 최소화하는 프로세스 이다. 역방향 전파 알고리즘 컨볼루션 신경망은 오차 역방향 전파(backward propagation, BP) 알고리즘에 따라 훈련 프로세스에서 초기 수퍼 -해상도 모델에서의 파라미터의 값을 정정할 수 있어서, 이로써 수퍼-해상도 모델을 재구성하는 오차 손실이 더 작아진다. 구체적으로, 입력 신호는 오차 손실이 출력에서 발생할 때까지 순방향으로 전송되고, 초기 수퍼-해상 도 모델에서의 파라미터는 역방향 전파 오차 손실 정보에 기초하여 업데이트되어, 오차 손실이 수렴하게 된다. 역방향 전파 알고리즘은 최적 수퍼-해상도 모델의, 가중치 행렬과 같은 파라미터를 획득하도록 의도된 오차-손 실-중심형 역방향 전파 모션이다. 생성형 대립적 네트워크 생성형 대립적 네트워크(generative adversarial networks, GAN)는 심층 학습 모델이다. 모델은 적어도 2개의 모듈: 생성형 모델(generative model) 및 판별형 모델(discriminative model)을 포함한다. 2개의 모듈은 더 양 호한 출력을 생성하기 위하여 서로로부터 학습한다. 생성형 모델 및 판별형 모델의 둘 모두는 신경망일 수 있고, 구체적으로, 심층 신경망 또는 컨볼루션 신경망일 수 있다. GAN의 기본적인 원리는 다음과 같다: 픽처를 생성하기 위한 GAN을 예로서 이용하면, 2개의 네트워크가 있는 것으로 가정된다: G(생성기) 및 D(판별기). G는 픽처를 생성하기 위한 네트워크이다. G는 랜덤 잡음 z를 수신하고, 잡음을 이용함으로써 픽처를 생성하고, 여기 서, 픽처는 G(z)로서 나타내어진다. D는 픽처가 \"실제\"인지 여부를 결정하기 위하여 이용된 판별기 네트워크이 다. D의 입력 파라미터는 x이고, x는 픽처를 나타내고, 출력 D(x)는 x가 실제 픽처일 확률을 나타낸다. D(x)의 값이 1인 경우에, 그것은 픽처가 100 % 실제인 것을 지시한다. D(x)의 값이 0인 경우에, 그것은 픽처가 실제일 수 없다는 것을 지시한다. 생성형 대립적 네트워크를 훈련시키는 프로세스에서, 생성형 네트워크 G의 목적은 판 별형 네트워크 D를 기만하기 위하여 가능한 한 실제인 픽처를 생성하는 것이고, 판별형 네트워크 D의 목적은 G 에 의해 생성된 픽처와 실제 픽처 사이를 가능한 한 많이 구별하는 것이다. 이러한 방식으로, 동적 \"게이밍\" 프로세스, 구체적으로 말하면, \"생성형 대립적 네트워크\"에서의 \"대립\"은 G와 D 사이에 존재한다. 최종적인 게이 밍 결과는, 이상적인 상태에서, G가 실제 픽처로부터 어렵게 구별되어야 하는 픽처 G(z)를 생성할 수 있고, D가 G에 의해 생성된 픽처가 실제인지, 구체적으로 말하면, D(G(z))=0.5인지 여부를 결정하는 것이 어렵다. 이러한 방식으로, 우수한 생성형 모델 G가 획득되고, 픽처를 생성하기 위하여 이용될 수 있다."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "본 기술분야에서의 통상의 기술자는, 다양한 예시적인 논리적 블록을 참조하여 설명된 기능, 및 이 명세서에서 개시되고 설명된 알고리즘 단계는 하드웨어, 소프트웨어, 펌웨어, 또는 그 임의의 조합에 의해 구현될 수 있다 는 것을 이해할 수 있다. 소프트웨어에 의해 구현되는 경우에, 예시적인 논리적 블록, 모듈, 및 단계를 참조하 여 설명된 기능은 하나 이상의 명령 또는 코드로서, 컴퓨터-판독가능 매체 내에 저장될 수 있거나 컴퓨터-판독 가능 매체 상에서 송신될 수 있고, 하드웨어-기반 프로세싱 유닛에 의해 실행될 수 있다. 컴퓨터-판독가능 매체 는, 데이터 저장 매체와 같은 유형의 매체에 대응하는 컴퓨터-판독가능 저장 매체를 포함할 수 있거나, (예를 들어, 통신 프로토콜에 따라) 하나의 장소로부터 또 다른 곳으로의 컴퓨터 프로그램의 송신을 용이하게 하는 임 의의 통신 매체를 포함할 수 있다. 이러한 방식으로, 컴퓨터-판독가능 매체는 일반적으로 다음에 대응할 수 있 다: 비-일시적 유형의 컴퓨터-판독가능 저장 매체, 또는 신호 또는 캐리어와 같은 통신 매체. 데이터 저장 매체는 이 출원에서 설명된 기술을 구현하기 위한 명령, 코드, 및/또는 데이터 구조를 인출하기 위하여 하 나 이상의 컴퓨터 또는 하나 이상의 프로세서에 의해 액세스될 수 있는 임의의 이용가능 매체일 수 있다. 컴퓨 터 프로그램 제품은 컴퓨터-판독가능 매체를 포함할 수 있다. 제한이 아니라 예로서, 이러한 컴퓨터-판독가능 저장 매체는 RAM, ROM, EEPROM, CD-ROM, 또는 또 다른 컴팩트 디스크 저장 장치, 자기 디스크 저장 장치 또는 또 다른 자기 저장 장치, 플래시 메모리, 또는 명령 또는 데이 터 구조의 형태로 희망된 프로그램 코드를 저장하기 위하여 이용될 수 있으며 컴퓨터에 의해 액세스될 수 있는 임의의 다른 매체를 포함할 수 있다. 추가적으로, 임의의 접속은 컴퓨터-판독가능 매체로서 적절하게 지칭된다. 예를 들어, 명령이 동축 케이블, 광섬유, 연선(twisted pair), 디지털 가입자 회선(digital subscriber line, DSL), 또는 무선 기술 예컨대, 적외선, 무선, 또는 마이크로파를 통해 웹사이트, 서버, 또는 또 다른 원격 소스 로부터 송신되는 경우에, 동축 케이블, 광섬유, 연선, DSL, 또는 무선 기술 예컨대, 적외선, 무선, 또는 마이크 로파가 매체의 정의 내에 포함된다. 그러나, 컴퓨터-판독가능 저장 매체 및 데이터 저장 매체는 접속, 캐리어, 신호, 또는 다른 일시적 매체를 포함하는 것이 아니라, 실제적으로, 비-일시적 유형의 저장 매체를 의미한다는 것이 이해되어야 한다. 이 명세서에서 이용된 디스크(disk) 및 디스크(disc)는 컴팩트 디스크(compact disc, CD), 레이저 디스크(laser disc), 광학 디스크(optical disc), 디지털 다기능 디스크(digital versatile disc, DVD), 및 블루-레이 디스크(Blu-ray disc)를 포함한다. 디스크(disk)는 통상적으로, 데이터를 자기적으로 재현 하는 반면, 디스크(disc)는 레이저를 이용함으로써 데이터를 광학적으로 재현한다. 상기한 항목의 조합은 또한, 컴퓨터-판독가능 매체의 범위 내에 포함되어야 한다. 명령은 하나 이상의 디지털 신호 프로세서(digital signal processor, DSP), 범용 마이크로프로세서, 애플리케 이션-특정 집적 회로(application-specific integrated circuit, ASIC), 필드 프로그래밍가능 게이트 어레이 (field programmable gate array, FPGA), 또는 다른 등가적인 집적된 또는 개별 로직 회로와 같은 하나 이상의 프로세서에 의해 실행될 수 있다. 그러므로, 이 명세서에서 이용된 용어 \"프로세서\"는 상기한 구조, 또는 이 명 세서에서 설명된 기술을 구현하기 위하여 적당한 임의의 다른 구조 중의 임의의 것일 수 있다. 추가적으로, 일 부 측면에서, 이 명세서에서 설명된 예시적인 논리적 블록, 모듈, 및 단계를 참조하여 설명된 기능은 인코딩 및 디코딩을 위하여 구성된 전용 하드웨어 및/또는 소프트웨어 모듈 내에서 제공될 수 있거나, 조합된 코덱 내로 통합될 수 있다. 추가적으로, 기술은 하나 이상의 회로 또는 로직 엘리먼트에서 모두 구현될 수 있다. 이 출원에서의 기술은 무선 핸드셋, 집적 회로(integrated circuit, IC), 또는 IC의 세트(예를 들어, 칩셋)를 포함하는 다양한 장치 또는 디바이스에서 구현될 수 있다. 다양한 컴포넌트, 모듈, 또는 유닛은 개시된 기술을 구현하도록 구성된 장치의 기능적 측면을 강조하기 위하여 이 출원에서 설명되지만, 상이한 하드웨어 유닛에 의 해 반드시 구현되지는 않는다. 실제적으로, 위에서 설명된 바와 같이, 다양한 유닛은 적절한 소프트웨어 및/또 는 펌웨어와 조합하여 코덱 하드웨어로 조합될 수 있거나, (위에서 설명된 하나 이상의 프로세서를 포함하는) 상호 동작가능한 하드웨어 유닛에 의해 제공될 수 있다. 상기한 설명은 이 출원의 단지 특정 구현의 예이지만, 이 출원의 보호 범위를 제한하도록 의도되지는 않는다."}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "이 출원에서 개시된 기술적 범위 내에서 본 기술분야에서의 통상의 기술자에 의해 용이하게 도출된 임의의 변형 또는 대체는 이 출원의 보호 범위 내에 속할 것이다. 그러므로, 이 출원의 보호 범위는 청구항의 보호 범위가"}
{"patent_id": "10-2023-7029752", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "대상이 될 것이다.요약하면, 본 개시내용은 2개 이상의 계층을 갖는 신경망을 이용하여 픽처 데이터 또는 픽처 특징 데이터의 프 로세싱을 위한 방법 및 장치를 제공한다. 본 개시내용은 인공 지능(AI)-기반 비디오 또는 픽처 압축 기술의 분 야에서, 그리고 특히, 신경망-기반 비디오 압축 기술의 분야에 적용될 수 있다. 일부 실시예에 따르면, 2개의 종류의 데이터는 신경망에 의한 프로세싱을 포함하는 프로세싱 동안에 조합된다. 2개의 종류의 데이터는 네트워 크에 의한 프로세싱의 상이한 스테이지로부터 획득된다. 장점의 일부는 더 양호한 인코딩/디코딩 성능을 추가로 초래할 수 있는 신경망 아키텍처의 더 큰 확장가능성 및 더 유연한 설계를 포함할 수 있다."}
{"patent_id": "10-2023-7029752", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하에서, 본 발명의 실시예는 첨부된 도면 및 그림을 참조하여 더 상세하게 설명된다: 도 1은 하이퍼 프라이어 모델(hyper prior model)을 포함하는 인코더 및 디코더 측을 위한 예시적인 네트워크 아키텍처를 예시하는 블록도이다. 도 2는 하이퍼 프라이어 모델을 포함하는 인코더 측을 위한 일반적인 네트워크 아키텍처를 예시하는 블록도이다. 도 3은 하이퍼 프라이어 모델을 포함하는 디코더 측을 위한 일반적인 네트워크 아키텍처를 예시하는 블록도이다. 도 4는 신경망에 기초한 인코더 및 디코더의 일반적인 방식을 예시하는 개략도이다.도 5는 예시적인 자동-변량(auto-variate) 인코더 및 디코더를 예시하는 블록도이다. 도 6은 인코딩 및 디코딩 신경망의 사전정의된 스테이지 상에서의 보조 정보의 적용을 예시하는 일반적인 블록 도이다. 도 7은 다운샘플링을 포함하는 하나의 프로세싱 계층에 의한 프로세싱 후와, 다운샘플링을 포함하는 N개의 계층 후의, 신호 도메인에서의 예측 신호의 시각화(visualization)이다. 도 8은 심층 학습(deep learning) 기간 접근법과 조합하는 기존의 블록-기반 코덱(codec)을 갖는 예시적인 비디 오 코딩 파이프라인을 예시하는 블록도이다. 도 9는 보조 정보를 수집하기 위한 다수의 선택가능한 위치를 갖는 예시적인 구성가능한 조건적 오토-인코더 (auto-encoder)를 예시하는 블록도이다. 도 10은 보조 정보를 수집하기 위한 하나의 선택가능한 위치를 갖는 예시적인 구성가능한 조건적 오토-인코더를 예시하는 블록도이다. 도 11은 예측 정보 뿐만 아니라 잔차 정보를 보조 정보로서 수집하기 위한 복수의 수집 기회(위치)를 포함하는 예시적인 신경망 프로세싱을 예시하는 블록도이다. 도 12는 상이한 특성을 갖는 2개의 예시적인 픽처를 다운샘플링하고 재구성하기 위한 성능의 비교를 예시하는 개략도이다. 도 13은 확률 모델의 지시를 보조 정보로서 입력하는 목적을 위한 구성가능한 수집 유닛의 애플리케이션을 예시 하는 블록도이다. 도 14는 예시적인 번호부여된 프로세싱 스테이지(또는 계층)를 갖는 인코딩 측 및 디코딩 측 신경망을 예시하는 블록도이다. 도 15는 파이프라인의 0 번째 위치에서의 예측 및 잔차의 둘 모두를 갖는 인코딩 측 및 디코딩 측 신경망을 예 시하는 블록도이다. 도 16은 파이프라인의 1 번째 위치에서의 예측 및 잔차의 둘 모두를 갖는 인코딩 측 및 디코딩 측 신경망을 예 시하는 블록도이다. 도 17은 파이프라인의 i 번째 스테이지에서의 예측 및 (i+r) 번째 스테이지에서의 잔차를 갖는 인코딩 측 및 디 코딩 측 신경망을 예시하는 블록도이다. 도 18은 파이프라인의 0 번째 스테이지에서의 예측 및 K 번째 스테이지에서의 잔차를 갖는 인코딩 측 및 디코딩 측 신경망을 예시하는 블록도이다. 도 19는 파이프라인의 1 번째 스테이지에서의 예측 및 K 번째 스테이지에서의 잔차를 갖는 인코딩 측 및 디코딩 측 신경망을 예시하는 블록도이다. 도 20은 파이프라인의 1 번째 스테이지에서의 예측 및 (K-1) 번째 스테이지에서의 잔차를 갖는 인코딩 측 및 디 코딩 측 신경망을 예시하는 블록도이다. 도 21은 제1 예시적인 구현예에 따른 잔차 및 예측의 가능한 취급을 예시하는 블록도이다. 도 22는 제2 예시적인 구현예에 따른 잔차 및 예측의 가능한 취급을 예시하는 블록도이다. 도 23은 신호 도메인에서 예측 및 잔차를 취급하는 예시적인 개괄적 아키텍처를 예시하는 블록도이다. 도 24는 잠재 공간(latent space)에서 예측 및 잔차를 취급하는 예시적인 개괄적 아키텍처를 예시하는 블록도이 다. 도 25는 잠재 공간에서 예측 및 잔차를 취급하는 예시적인 개괄적 아키텍처를 예시하는 블록도이지만, 예측의 잠재 공간은 선행 픽처의 프로세싱으로부터의 것이다. 도 26은 본 발명의 실시예를 구현하도록 구성된 비디오 코딩 시스템의 예를 도시하는 블록도이고, 여기서, 시스 템은 비디오 픽처를 인코딩하거나 디코딩하기 위하여 신경망을 이용한다. 도 27은 본 발명의 실시예를 구현하도록 구성된 비디오 코딩 시스템의 또 다른 예를 도시하는 블록도이고, 여기서, 비디오 인코더 및/또는 비디오 디코더는 비디오 픽처를 인코딩하거나 디코딩하기 위하여 신경망을 이용한다. 도 28은 본 발명의 실시예를 구현하도록 구성된 비디오 코딩 장치를 예시하는 블록도이다. 도 29는 본 발명의 실시예를 구현하도록 구성된 비디오 코딩 장치를 예시하는 블록도이다."}
