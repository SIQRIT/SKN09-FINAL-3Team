{"patent_id": "10-2022-0091556", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0014639", "출원번호": "10-2022-0091556", "발명의 명칭": "스마트 팩토리의 행동개선 솔루션을 제공하는 장치 및 방법", "출원인": "주식회사 아임토리", "발명자": "남기환"}}
{"patent_id": "10-2022-0091556", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "공정라인에 설치된 로봇 팔의 상태 및 동작을 센싱하여 상기 로봇 팔의 동작을 제어하여 스마트 팩토리의 행동개선 솔루션을 제공하는 장치에 있어서,상기 장치는,상기 로봇 팔을 촬영하여 영상 데이터를 획득하는 촬영부;상기 로봇 팔의 상태를 감지하여 센싱 분석 데이터를 생성하는 센싱부;상기 영상 데이터를 입력받고, 상기 영상 데이터를 기초로 이미지 분석 데이터를 출력하는 사전처리부;상기 센싱 분석 데이터 및 상기 이미지 분석 데이터를 입력받고, 학습 데이터를 출력하는 멀티모달부;상기 학습 데이터를 입력받고, 다층 신경망(Multiple Neural Network)을 이용하여 상기 학습 데이터를 정답 데이터와 비교하여 비교 결과를 출력하는 학습부; 및상기 비교 결과를 기초로 상기 로봇 팔의 동작을 제어하는 제어부;를 포함하되, 상기 제어부는,상기 공정라인에서 생산되는 복수의 제품 각각의 불량 여부를 판별하고,상기 복수의 제품 중 불량으로 판별되는 제품에 대하여, 상기 공정라인에 설치된 상기 로봇 팔의 이상 동작 발생 여부와의 상관관계를 판단하여 상관점수를 출력하는,장치."}
{"patent_id": "10-2022-0091556", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,[수학식]상기 제어부는 상기 수학식을 이용하여 상기 상관점수를 출력하고,상기 수학식에서, %D는 특정 시간 구간에서의 불량률, n(dP)는 공정라인의 불량 제품 개수, n(P)는 공정라인의생산 제품 총 개수, t_err은 로봇 팔에서 특정 이상 동작이 발생한 시기, △t_c는 시간 구간 상수를 의미하고,상기 제어부는 상기 불량률과 미리 설정된 제1 임계값의 차에 비례하여 상기 특정 이상 동작에 대해 높은 상관점수를 부여하는,장치."}
{"patent_id": "10-2022-0091556", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제어부는,상기 상관점수가 미리 설정된 제2 임계값을 초과하는 경우, 상기 로봇 팔의 동작 모드를 제1 동작 모드에서 제2동작 모드로 변경하는,공개특허 10-2024-0014639-3-장치."}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예들은 로봇 팔의 이상 동작을 센싱하는 방법을 제공한다. 실시예들에 의해 제공되는 로봇 팔의 이상 동작 센싱 방법은, 촬영부에 의해, 상기 로봇 팔을 촬영하여 영상 데이터를 획득하고, 센싱부에 의해, 상기 로봇 팔의 상태를 감지하여 센싱 분석 데이터를 생성하고, 사전처리부에 의해, 상기 영상 데이터를 입력받고, 상기 영상 데 (뒷면에 계속)"}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예들은 스마트 팩토리의 행동개선 솔루션을 제공하는 장치 및 방법에 관한 것으로, 보다 구체적 으로는 스마트 팩토리의 로봇 팔의 작동을 센싱하여 이상 동작 발생을 감지하고, 인공지능을 이용하여 로봇 팔 의 이상 동작과 불량률의 관계를 추적하여, 로봇 팔의 행동 개선 솔루션을 제공하는 장치 및 방법에 대한 것이다."}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스마트 팩토리는 제품의 설계 및 제조 단계에서 정보 통신 기술(Information and Communications Technology; ICT)을 이용하여 제품의 생산성 및 품질을 향상시키도록 디지털 자동화 솔루션이 적용된 공정이다. 스마트 팩토리의 각 공정라인에는 로봇 팔 등의 생산 장비가 설치되며, 로봇 팔을 제어하는 전자 장치를 통해 각 공정라인의 생산 과정을 관리한다. 또한, 스마트 팩토리에서 생산되는 제품에 고유 바코드를 부여하여, 언제 어떠한 공정라인에서 생산되었는지를 기록하고, 이를 통해 공정별 작업시간 데이터를 생성하여 생산 과정을 관 리한다. 그런데, 스마트 팩토리 각 공정라인에 설치된 로봇 팔이 지시된 사항을 수행하기 위해 작동하는 과정에서 다양 한 환경 요인으로 인해 로봇 팔의 비정상적인 움직임이 발생할 수 있다. 예를 들면, 로봇 팔에는 제품의 생산 공정 중 일부 요소행동에 대한 지시만이 프로그래밍되는 것이 일반적인데, 이 경우 해당 요소행동을 달성하는 과정에서 다른 요소행동과의 간섭으로 비정상적인 움직임이 발생할 수 있다. 일반적으로 프로그래밍에 따라 로봇 팔이 작동하는 과정은 매우 빠르고, 비정상적인 움직임이 발생한다고 하더 라도 그 오차가 크지 않은 경우에는 육안으로 식별하는 것이 거의 불가능하다. 또한, 비정상적인 움직임이 발생 하는 빈도는 일정하지 않으므로, 로봇 팔을 정밀하게 센싱하여 비정상적인 움직임의 발생 여부를 확인할 수 있 는 기술의 필요성이 요구되고 있다."}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "위에서 설명한 배경기술은 발명자가 본원의 개시 내용을 도출하는 과정에서 보유하거나 습득한 것으로서, 반드 시 본 출원 전에 일반 공중에 공개된 공지기술이라고 할 수는 없다."}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예들은, 상술한 문제점을 해결하기 위한 스마트 팩토리의 행동개선 솔루션을 제공하는 장치 및 방법을 제공 한다. 실시예들에서 이루고자 하는 기술적 과제들은 이상에서 언급한 사항들로 제한되지 않으며, 언급하지 않은 또 다"}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "른 기술적 과제들은 이하 설명할 다양한 실시예들로부터 당해 기술분야에서 통상의 지식을 가진 자에 의해 고려 될 수 있다."}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 스마트팩토리의 행동개선 솔루션을 제공하는 장치는, 상기 로봇 팔을 촬영하여 영 상 데이터를 획득하는 촬영부; 상기 로봇 팔의 상태를 감지하여 센싱 분석 데이터를 생성하는 센싱부; 상기 영 상 데이터를 입력받고, 상기 영상 데이터를 기초로 이미지 분석 데이터를 출력하는 사전처리부; 상기 센싱 분석 데이터 및 상기 이미지 분석 데이터를 입력받고, 학습 데이터를 출력하는 멀티모달부; 상기 학습 데이터를 입력 받고, 다층 신경망(Multiple Neural Network)을 이용하여 상기 학습 데이터를 정답 데이터와 비교하여 비교 결 과를 출력하는 학습부; 및 상기 비교 결과를 기초로 상기 로봇 팔의 동작을 제어하는 제어부;를 포함하되, 상기 제어부는, 상기 공정라인에서 생산되는 복수의 제품 각각의 불량 여부를 판별하고, 상기 복수의 제품 중 불량으 로 판별되는 제품에 대하여, 상기 공정라인에 설치된 상기 로봇 팔의 이상 동작 발생 여부와의 상관관계를 판단 하여 상관점수를 출력할 수 있다.일 실시예에서, [수학식]"}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "상기 제어부는 상기 수학식을 이용하여 상기 상관점수를 출력하고, 상기 수학식에서, %D는 특정 시간 구간에서 의 불량률, n(dP)는 공정라인의 불량 제품 개수, n(P)는 공정라인의 생산 제품 총 개수, t_err은 로봇 팔에서 특정 이상 동작이 발생한 시기, △t_c는 시간 구간 상수를 의미하고, 상기 제어부는 상기 불량률과 미리 설정된 제1 임계값의 차에 비례하여 상기 특정 이상 동작에 대해 높은 상관점수를 부여할 수 있다. 일 실시예에서, 상기 제어부는, 상기 상관점수가 미리 설정된 제2 임계값을 초과하는 경우, 상기 로봇 팔의 동 작 모드를 제1 동작 모드에서 제2 동작 모드로 변경할 수 있다."}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 이미지 분석 데이터와 센싱 분석 데이터를 복합적으로 연산하여 로봇 팔의 이상 동작 발생 여부를 정밀하게 감지할 수 있다. 실시예들로부터 얻을 수 있는 효과들은 이상에서 언급된 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효"}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "과들은 이하의 상세한 설명을 기반으로 당해 기술분야에서 통상의 지식을 가진 자에게 명확하게 도출되고 이해 될 수 있다."}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 실시예들은 실시예들의 구성요소들과 특징들을 소정 형태로 결합한 것들이다. 각 구성요소 또는 특징은 별도의 명시적 언급이 없는 한 선택적인 것으로 고려될 수 있다. 각 구성요소 또는 특징은 다른 구성요소나 특 징과 결합되지 않은 형태로 실시될 수 있다. 또한, 일부 구성요소들 및/또는 특징들을 결합하여 다양한 실시예 들을 구성할 수도 있다. 다양한 실시예들에서 설명되는 동작들의 순서는 변경될 수 있다. 어느 실시예의 일부구성이나 특징은 다른 실시예에 포함될 수 있고, 또는 다른 실시예의 대응하는 구성 또는 특징과 교체될 수 있 다. 도면에 대한 설명에서, 다양한 실시예들의 요지를 흐릴 수 있는 절차 또는 단계 등은 기술하지 않았으며, 당해"}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자의 수준에서 이해할 수 있을 정도의 절차 또는 단계는 또한 기술하지 아니 하였다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함(comprising 또는 including)\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미 한다. 또한, 명세서에 기재된 \"...부\", \"...기\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, \"일(a 또는 an)\", \"하나(one)\", \"그(the)\" 및 유사 관련어는 다양한 실시예들을 기술하는 문맥에 있어서(특히, 이하의 청구항의 문맥에서) 본 명세서에 달리 지시되거나 문맥에 의해 분명하게 반박되지 않는 한, 단수 및 복 수 모두를 포함하는 의미로 사용될 수 있다. 이하, 다양한 실시예들에 따른 실시 형태를 첨부된 도면을 참조하여 상세하게 설명한다. 첨부된 도면과 함께 이 하에 개시될 상세한 설명은 다양한 실시예들의 예시적인 실시형태를 설명하고자 하는 것이며, 유일한 실시형태 를 나타내고자 하는 것이 아니다. 또한, 다양한 실시예들에서 사용되는 특정(特定) 용어들은 다양한 실시예들의 이해를 돕기 위해서 제공된 것이 며, 이러한 특정 용어의 사용은 다양한 실시예들의 기술적 사상을 벗어나지 않는 범위에서 다른 형태로 변경될 수 있다. 도 1은 로봇 팔을 이용한 스마트 팩토리 공정 환경을 개략적으로 나타내는 도면이다. 스마트 팩토리는 제품의 설계 및 제조 단계에서 정보 통신 기술(Information and Communications Technology; ICT)을 이용하여 제품의 생산성 및 품질을 향상시키도록 디지털 자동화 솔루션이 적용된 공정을 의미한다. 도 1을 참조하면, 스마트 팩토리 공정 환경은 전자 장치, 로봇 팔, 스마트 팩토리 제어 장치를 포함할 수 있다. 비록 도 1에는 하나의 공정라인만이 도시되었으나, 본 발명의 일 실시예에 따른 스마트 팩토리 는 복수의 공정라인을 포함할 수 있다. 스마트 팩토리의 각 공정라인에는 로봇 팔이 설치될 수 있다. 로봇 팔은 스마트 팩토리 제어 장치에 의해 제어될 수 있다. 이를 위해, 스마트 팩토리 제어 장치는 로봇 팔의 작동 상태 또는 로봇 팔 외부의 환경 상태를 감지할 수 있다. 스마트 팩토리 제어 장치 는 로봇 팔의 작동 상태 또는 로봇 팔 외부의 환경 상태를 기초로 로봇 팔의 동작을 제어 할 수 있다. 또한, 스마트 팩토리 제어 장치는 전자 장치와 데이터 또는 신호를 주고받을 수 있다. 일 실시예에서, 스마트 팩토리 제어 장치가 로봇 팔을 제어하기 위해 필요한 연산은 전자 장치 에서 이루어질 수 있다. 즉, 스마트 팩토리 제어 장치가 로봇 팔의 작동 상태 또는 로봇 팔 외 부의 환경 상태를 감지하여 이상 작동 여부를 판단하는 경우, 스마트 팩토리 제어 장치는 후술할 로봇 팔 의 이미지 분석 데이터, 로봇 팔의 센싱 분석 데이터를 전자 장치에 송신하고, 전자 장치 로부터 연산 결과를 수신하여 이를 기초로 이상 작동 여부를 판단할 수 있다. 또한, 스마트 팩토리 제어 장치는 생산된 제품의 불량 여부를 판별할 수 있다. 스마트 팩토리 제어 장치 는 생산된 제품의 불량 여부를 판별하여, 제품의 불량률을 산출할 수 있다. 스마트 팩토리 제어 장치(30 0)는 스마트 팩토리의 복수의 공정라인에 설치된 각각의 로봇 팔 중에서 불량 제품의 생산에 관여한 로봇 팔을 추적할 수 있다. 도 2는 본 발명의 일 실시예에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 2를 참조하면, 네트워크 환경에서 전자 장치는 네트워크를 통하여 스마트 팩토리 제어 장치 와 통신할 수 있다. 일 실시예에서, 전자 장치는 프로세서, 메모리, 센서 모듈, 카메라 모듈, 통신 모듈 , 안테나 모듈을 포함할 수 있다. 다른 실시예에서, 전자 장치에는, 이 구성요소들 중 적어도 하나가 생략되거나, 하나 이상의 다른 구성요소가 추가될 수 있다. 다른 실시예에서, 이 구성요소들 중 일부들은 하나의 구성요소로 통합될 수 있다. 프로세서는, 예를 들면, 소프트웨어를 실행하여 프로세서에 연결된 전자 장치의 적어도 하나의 다른 구성요소를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 일 실시예에서, 데이터 처 리 또는 연산의 적어도 일부로서, 프로세서는 다른 구성요소로부터 수신된 명령 또는 데이터를 휘발성 메 모리에 저장하고, 휘발성 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 비휘발성 메 모리에 저장할 수 있다. 일 실시예에서, 프로세서는 메인 프로세서(예를 들면, 중앙 처리 장치 또는 어플리케이션 프로세서) 또는 이와는 독립적으로 또는 함께 운영 가능한 보조 프로세서(예를 들면, 그래픽 처리 장치, 신경망 처리 장치(NPU: neural processing unit), 센서 허브 프로세서)를 포함할 수 있다. 예를 들어, 전자 장치가 메인 프로세서 및 보조 프로세서를 포함하는 경우, 보조 프로세서(11 2)는 메인 프로세서보다 저전력을 사용하거나, 지정된 기능에 특화되도록 설정될 수 있다. 보조 프로세서 는 메인 프로세서와 별개로, 또는 그 일부로서 구현될 수 있다. 프로세서는 로봇 팔의 이미지 분석 데이터와, 로봇 팔의 센싱 분석 데이터를 기초로 학습 데이 터를 생성할 수 있다. 프로세서 학습 모델을 이용하여 로봇 팔의 이상 작동 여부를 감지할 수 있다. 프로세서는 학습 모델을 이용하여 로봇 팔의 이상 작동 여부를 감지할 수 있다. 학습 모델은, 입력 레이어, 하나 이상의 히든 레이어 및 출력 레이어를 포함할 수 있다. 학습 데이터는 입력 레이어에 입력되어 하 나 이상의 히든 레이어 및 출력 레이어를 통과하여 출력 벡터를 출력하고, 출력 벡터는 상기 출력 레이어에 연 결된 손실함수 레이어에 입력될 수 있다. 손실함수 레이어는 출력 벡터와 각각의 학습 데이터에 대한 정답 벡터 를 비교하는 손실 함수를 이용하여 손실값을 출력할 수 있다. 학습 모델의 파라미터는 손실값이 작아지는 방향 으로 학습될 수 있다. 보조 프로세서는, 예를 들면, 메인 프로세서가 인액티브 상태에 있는 동안 메인 프로세서를 대 신하여, 또는 메인 프로세서가 액티브 상태에 있는 동안 메인 프로세서와 함께, 전자 장치의 구 성요소들 중 적어도 하나의 구성요소와 관련된 기능 또는 상태들의 적어도 일부를 제어할 수 있다. 일 실시예에 서, 보조 프로세서는 기능적으로 관련 있는 다른 구성요소의 일부로서 구현될 수 있다. 일 실시예에서, 보조 프로세서가 신경망 처리 장치인 경우, 보조 프로세서는 인공지능 모델의 처리에 특화된 하드웨어 구조를 포함할 수 있다. 인공지능 모델은 기계 학습을 통해 생성될 수 있다. 이러한 학습은, 예를 들어, 인공지능 모델이 수행되는 전자 장치 자체에서 수행될 수 있고, 별도의 서버를 통해 수행될 수 도 있다. 학습 알고리즘은, 예를 들어, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준 지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경망(DNN: deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 하드웨어 구조 이외에, 추가적으로 또는 대체적으로, 소프트웨어 구조를 포 함할 수 있다. 메모리는, 전자 장치의 적어도 하나의 구성요소에 의해 사용되는 다양한 데이터를 저장할 수 있다. 데이터는, 예를 들어, 소프트웨어 및, 이와 관련된 명령에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있 다. 메모리는, 휘발성 메모리 또는 비휘발성 메모리를 포함할 수 있다. 메모리는 후술할 로봇 팔의 이미지 분석 데이터와, 로봇 팔의 센싱 분석 데이터를 저장할 수 있다. 통신 모듈은 전자 장치와 외부 전자 장치 간의 유선 통신 채널 또는 무선 통신 채널의 수립, 및 수립 된 통신 채널을 통한 통신 수행을 지원할 수 있다. 통신 모듈은 프로세서와 독립적으로 운영되고, 유 선 통신 또는 무선 통신을 지원하는 하나 이상의 커뮤니케이션 프로세서를 포함할 수 있다. 일 실시예에서, 통 신 모듈은 무선 통신 모듈 또는 유선 통신 모듈을 포함할 수 있다. 이들 통신 모듈 중 해당하는 통신 모듈 은 네트워크를 통하여 스마트 팩토리 제어 장치와 통신할 수 있다. 이런 여러 종류의 통신 모듈들은 하나의 구성요소로 통합되거나, 또는 서로 별도의 복수의 구성요소들로 구현될 수 있다. 무선 통신 모듈은 4G 네트워크 이후의 5G 네트워크 및 차세대 통신 기술, 예를 들어, NR 접속 기술(new radio access technology)을 지원할 수 있다. NR 접속 기술은 고용량 데이터의 고속 전송(eMBB(enhanced mobilebroadband)), 단말 전력 최소화와 다수 단말의 접속(mMTC(massive machine type communications)), 또는 고신 뢰도와 저지연(URLLC(ultra-reliable and low-latency communications))을 지원할 수 있다. 무선 통신 모듈은, 예를 들어, 높은 데이터 전송률 달성을 위해, 고주파 대역을 지원할 수 있다. 무선 통신 모듈은 고주파 대역에 서의 성능 확보를 위한 다양한 기술들, 예를 들어, 빔포밍(beamforming), 거대 배열 다중 입출력(massive MIMO(multiple-input and multiple-output)), 전차원 다중입출력(FD-MIMO: full dimensional MIMO), 어레이 안 테나(array antenna), 아날로그 빔형성(analog beam-forming), 또는 대규모 안테나(large scale antenna)와 같 은 기술들을 지원할 수 있다. 무선 통신 모듈은 전자 장치, 외부 전자 장치 또는 네트워크 시스템에 규정 되는 다양한 요구사항을 지원할 수 있다. 일 실시예에서, 무선 통신 모듈은 eMBB 실현을 위한 Peak data rate, mMTC 실현을 위한 손실 Coverage 또는 URLLC 실현을 위한 U-plane latency를 지원할 수 있다. 안테나 모듈은 신호 또는 전력을 외부 전자 장치로 송신하거나 외부로부터 수신할 수 있다. 일 실시예에서, 안테나 모듈은 서브스트레이트 위에 형성된 도전체 또는 도전성 패턴으로 이루어진 방사체를 포함하는 안테나를 포함할 수 있다. 일 실시예에서, 안테나 모듈은 복수의 안테나들을 포함할 수 있다. 이 경우, 네트워크와 같은 통신 네트워크에서 사용되는 통신 방식에 적합한 적어도 하나의 안테나가, 예를 들 면, 통신 모듈에 의하여 상기 복수의 안테나들로부터 선택될 수 있다. 신호 또는 전력은 상기 선택된 적어 도 하나의 안테나를 통하여 통신 모듈과 외부 전자 장치 간에 송신되거나 수신될 수 있다. 일 실시예에서, 명령 또는 데이터는 네트워크에 연결된 스마트 팩토리 제어 장치간에 송신 또는 수신 될 수 있다. 스마트 팩토리 제어 장치는 전자 장치와 동일한 또는 다른 종류의 장치일 수 있다. 일 실시예에서, 전자 장치에서 실행되는 동작들의 전부 또는 일부는 스마트 팩토리 제어 장치에서 실행 될 수 있다. 예를 들면, 전자 장치가 어떤 기능이나 서비스를 자동으로, 또는 사용자 또는 다른 장치로부터의 요청에 반응하여 수행해야 할 경우에, 전자 장치는 기능 또는 서비스를 자체적으로 실행시키는 대신에 또는 추가 적으로, 하나 이상의 외부 전자 장치들에게 그 기능 또는 그 서비스의 적어도 일부를 수행하라고 요청할 수 있 다. 상기 요청을 수신한 하나 이상의 외부 전자 장치들은 요청된 기능 또는 서비스의 적어도 일부, 또는 상기 요청과 관련된 추가 기능 또는 서비스를 실행하고, 그 실행의 결과를 전자 장치로 전달할 수 있다. 전자 장치는 상기 결과를, 그대로 또는 추가적으로 처리하여, 상기 요청에 대한 응답의 적어도 일부로서 제공할 수 있다. 이를 위하여, 예를 들면, 클라우드 컴퓨팅, 분산 컴퓨팅, 모바일 에지 컴퓨팅(MEC: mobile edge computing), 또는 클라이언트-서버 컴퓨팅 기술이 이용될 수 있다. 전자 장치는, 예를 들어, 분산 컴퓨팅 또는 모바일 에지 컴퓨팅을 이용하여 초저지연 서비스를 제공할 수 있다. 다른 실시예에서, 스마트 팩토리 제어 장치는 IoT(internet of things) 기기를 포함할 수 있다. 일 실시예 에서, 스마트 팩토리 제어 장치는 네트워크 내에 포함될 수 있다. 전자 장치는 5G 통신 기술 및 IoT 관련 기술을 기반으로 지능형 서비스(스마트 팩토리)에 적용될 수 있다. 전자 장치는 하드웨어적으로는 통상적인 웹 서버(Web Server) 또는 왑 서버(WAP Server)와 동일한 구성을 가질 수 있다. 그러나, 소프트웨어적으로는, C, C++, Java, Visual Basic, Visual C 등 여하한 언어를 통하여 구현되어 여러 가지 기능을 하는 프로그램 모듈(Module)을 포함할 수 있다. 또한, 전자 장치는 일반적으로 인터넷과 같은 개방형 컴퓨터 네트워크를 통하여 불특정 다수 클라이언트 및/또는 다른 서버와 연결되어 있고, 클라이언트 또는 다른 서버의 작업수행 요청을 접수하고 그에 대한 작업 결과를 도출하여 제공하는 컴퓨터 시스 템 및 그를 위하여 설치되어 있는 컴퓨터 소프트웨어(서버 프로그램)를 뜻하는 것이다. 또한, 전자 장치는, 전술한 서버 프로그램 이외에도, 전자 장치 상에서 동작하는 일련의 응용 프로그램 (Application Program)과 경우에 따라서는 내부 또는 외부에 구축되어 있는 각종 데이터베이스(DB: Database, 이하 \"DB\"라 한다)를 포함하는 넓은 개념으로 이해되어야 할 것이다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조 또는 전자 장 치와 스마트 팩토리 제어 장치를 연결하는 망(Network)을 의미한다. 네트워크는 인터넷 (Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 3G, 4G, LTE, 5G, Wi-Fi 등이 포함되나 이에 한정되지는 않는다. 네트 워크는 LAN, WAN 등의 폐쇄형 네트워크일 수도 있으나, 인터넷(Internet)과 같은 개방형인 것이 바람 직하다. 인터넷은 TCP/IP 프로토콜 및 그 상위계층에 존재하는 여러 서비스, 즉 HTTP(HyperText Transfer Protocol), Telnet, FTP(File Transfer Protocol), DNS(Domain Name System), SMTP(Simple Mail Transfer Protocol), SNMP(Simple Network Management Protocol), NFS(Network File Service), NIS(NetworkInformation Service)를 제공하는 전 세계적인 개방형 컴퓨터 네트워크 구조를 의미한다. 데이터베이스는 데이터베이스 관리 프로그램(DBMS)을 이용하여 컴퓨터 시스템의 저장공간(하드디스크 또는 메모 리)에 구현된 일반적인 데이터구조를 가질 수 가질 수 있다. 데이터베이스는 데이터의 검색(추출), 삭제, 편집, 추가 등을 자유롭게 행할 수 있는 데이터 저장형태를 가질 수 있다. 데이터베이스는 오라클(Oracle), 인포믹스 (Infomix), 사이베이스(Sybase), DB2와 같은 관계형 데이타베이스 관리 시스템(RDBMS)이나, 겜스톤(Gemston), 오리온(Orion), O2 등과 같은 객체 지향 데이타베이스 관리 시스템(OODBMS) 및 엑셀론(Excelon), 타미노 (Tamino), 세카이주(Sekaiju) 등의 XML 전용 데이터베이스(XML Native Database)를 이용하여 본 개시의 일 실 시예의 목적에 맞게 구현될 수 있고, 자신의 기능을 달성하기 위하여 적당한 필드(Field) 또는 엘리먼트들을 가 질 수 있다. 도 3은 도 1의 로봇 팔을 설명하기 위한 도면이다. 도 3을 참조하면, 로봇 팔은 복수의 조인트로 연결되는 복수의 암과, 핸드부, 및 지지부를 포함 할 수 있다. 지지부는 제1 조인트를 포함할 수 있다. 제1 조인트는 제1 마크를 포함할 수 있다. 제1 마크는 제1 조인트의 표면에 표시될 수 있다. 제1 마크는 제1 조인트의 제1 방향(x) 표면에 표시될 수 있다. 제1 암의 일단은 제1 조인트에 연결되고, 제1 암의 타단은 제2 조인트에 연결될 수 있다. 즉, 제1 조인트는 제1 암의 일단과 지지부를 연결할 수 있다. 제2 조인트는 제2 마크를 포 함할 수 있다. 제2 마크는 제2 조인트의 표면에 표시될 수 있다. 제2 마크는 제2 조인트의 제1 방향 (x) 표면에 표시될 수 있다. 또한, 제2 암의 일단은 제2 조인트에 연결되고, 제2 암의 타단은 제3 조인트에 연결될 수 있다. 즉, 제2 조인트는 제1 암의 타단과 제2 암의 일단을 연결할 수 있다. 마찬가지로, 제3 암의 일단은 제3 조인트에 연결되고, 제3 암의 타단은 제4 조인트 에 연결될 수 있다. 즉, 제3 조인트는 제2 암의 타단과 제3 암의 일단을 연결할 수 있다. 제3 조인트는 제3 마크를 포함할 수 있다. 제3 마크는 제3 조인트의 표면에 표시될 수 있다. 제3 마 크는 제3 조인트의 제1 방향(x) 표면에 표시될 수 있다. 제4 암의 일단은 제4 조인트에 연결되 고, 제4 암의 타단은 핸드부에 연결될 수 있다. 로봇 팔의 핸드부는 집게 형상으로 이루어질 수 있다. 즉, 핸드부는 후술할 제어부의 제어를 기 초로(예를 들면, 제어 신호 또는 전기 신호를 기초로) 물건을 잡거나, 또는 물건을 놓도록 기능할 수 있다. 로봇 팔은 제어부의 제어를 기초로 하여 제1 내지 제4 조인트(221, 222, 223, 224)를 동작시킬 수 있다. 로봇 팔은 제어부의 제어를 기초로, 제1 내지 제4 조인트(221, 222, 223, 224)를 움직여 핸드부의 위 치를 움직일 수 있다. 또한 로봇 팔은 제어부의 제어를 기초로 핸드부의 그랩(grab) 동작을 제어할 수 있다. 로봇 팔의 제1 조인트는, 제어부의 제어에 따라, 지지부에 대하여 제1 암을 회전 이동시킬 수 있다. 로봇 팔의 제2 조인트는, 제어부의 제어에 따라 제1 방향(x)을 축으로 하여, 제1 암에 대 하여 제2 암을 회전 이동시킬 수 있다. 여기서, 제1 방향(x)은 지지부에 대한 제1 암의 회전 이 동 축 방향(z)과 수직일 수 있다. 로봇 팔의 제3 조인트는, 제어부의 제어에 따라 제2 암에 대하여 제3 암을 회전 이동시킬 수 있다. 일 실시예에서, 제3 조인트가 제2 암에 대하여 제3 암을 회전 이동시키는 경우, 회전 축은 제1 방향(x)과 상이할 수 있다. 다른 실시예에서, 제3 조인트가 제2 암에 대하여 제3 암을 회전 이동시키는 경우, 회전 축은 제1 방향(x)과 동일할 수 있다. 로봇 팔의 제4 조인트는, 제어부의 제어에 따라 제3 암에 대하여 제4 암을 회전 이동시킬 수 있다. 도 4는 본 발명의 일 실시예에 따른 스마트 팩토리 제어 장치의 구성을 설명하기 위한 블록도이다. 도 4를 참조하면, 스마트 팩토리 제어 장치는 촬영부, 센싱부, 사전처리부, 학습부, 멀티모달부, 제어부를 포함할 수 있다. 촬영부는 복수의 카메라를 포함할 수 있다. 복수의 카메라는 제1 카메라, 제2 카메라, 제3 카메 라를 포함할 수 있다. 도 1에 도시된 바와 같이, 제1 카메라, 제2 카메라, 제3 카메라는 각각 서로 다른 방향에서 로봇 팔을 촬영하도록 설치될 수 있다. 복수의 카메라 각각은 로봇 팔의 정 지 영상 및 동영상을 촬영할 수 있다. 일 실시예에서, 복수의 카메라 각각은 하나 이상의 렌즈들, 이미지 센서 들, 이미지 시그널 프로세서들, 또는 플래시들을 포함할 수 있다. 비록 도 4에는 촬영부가 3개의 카메라를 포함하는 것으로 도시되었으나, 본 발명의 실시예가 이에 제한되는 것은 아니다. 필요에 따라, 촬영부는 4 개 이상의 카메라를 포함할 수도 있고, 또는 2개 이하의 카메라를 포함할 수도 있다. 그러나 서로 다른 각도에 서의 로봇 팔의 영상 데이터를 획득하기 위해, 촬영부는 3개 이상의 카메라를 포함하는 것이 바람직 하다. 촬영부에 포함된 복수의 카메라 각각은 로봇 팔의 정지 상태 또는 작동 상태를 촬영하여 영상 데이터 (img_raw)를 생성할 수 있다. 영상 데이터(img_raw)는 로봇 팔의 정지 상태 또는 작동 상태가 광학적으로 기록된 데이터를 의미할 수 있다. 일 실시예에서, 촬영부는 제1 카메라, 제1 카메라와 다른 방 향에서 로봇 팔을 촬영하도록 설치된 제2 카메라, 제1 카메라 및 제2 카메라와 다른 방향 에서 로봇 팔을 촬영하도록 설치된 제3 카메라를 포함할 수 있다. 제1 카메라는 로봇 팔을 촬영하여 제1 영상 데이터(img_raw1)를 생성할 수 있다. 제2 카메라는 로봇 팔을 촬영하여 제2 영상 데이터(img_raw2)를 생성할 수 있다. 제3 카메라는 로봇 팔을 촬영하여 제3 영상 데이터(img_raw3)를 생성할 수 있다. 각각의 영상 데이터는 영상 촬영 시기에 대응하는 시간 정보, 로봇 팔과 카메라가 이루는 각도 및 거리에 대응하는 위치 정보를 포함하는 메타데이터를 포함할 수 있다. 메타데이터는 IPTC (International Press Telecommunications Council), XMP (Extensible Metadata Platform from Adobe), EXIF(Exchangeable Image File Format) 등의 포맷으로 저장될 수 있다. 센싱부는 로봇 팔의 작동 상태(예를 들면, 전력 또는 온도), 또는 로봇 팔 외부의 환경 상태를 감지하고, 감지된 상태에 대응하는 전기 신호 또는 데이터 값을 생성할 수 있다. 센싱부는 복수의 센서를 포함할 수 있다. 예를 들면, 센싱부는 제스처 센서, 자이로 센서, 기압 센서, 마그네틱 센서, 가속도 센서, 그립 센서, 근접 센서, 컬러 센서, IR(infrared) 센서, 생체 센서, 온도 센서, 습도 센서, 또는 조도 센 서를 포함할 수 있다. 센싱부에 포함된 복수의 센서 각각은 로봇 팔의 작동 상태 또는 로봇 팔 외부의 환경 상태를 감지할 수 있다. 도 4에 도시된 바와 같이, 복수의 센서의 개수는 다양할 수 있다. 필요에 따라, 센싱부는 3개 이상의 센서를 포함할 수 있다. 이 경우, 센싱부에 포함된 복수의 센서 각각은 서로 다른 방식을 이용하여 로봇 팔의 작동 상태 또는 로봇 팔 외부의 환경 상태를 감지할 수 있다. 또는, 복수의 센서 중 일부는 동일한 방식을 이용하여 로봇 팔의 작동 상태 또는 로봇 팔 외부의 환 경 상태를 감지하고, 다른 일부는 각각 서로 상이한 방식을 이용하여 로봇 팔의 작동 상태 또는 로봇 팔 외부의 환경 상태를 감지할 수 있다. 센싱부에 포함된 복수의 센서 각각은 로봇 팔의 작동 상태 또는 로봇 팔 외부의 환경 상태를 감 지하여 센싱 데이터(sens_raw)를 생성할 수 있다. 일 실시예에서, 복수의 센서는 로봇 팔의 온도를 감지하 는 제1 센서, 로봇 팔의 진동을 감지하는 제2 센서를 포함할 수 있다. 제1 센서는 로봇 팔 의 온도가 임계값 이상인 경우, 제1 센싱 데이터(sens_raw1)를 생성할 수 있다. 제2 센서는 로봇 팔 의 특정 부분(예를 들면, 제2 조인트)의 진동을 감지하여, 진동으로 인한 특정 부분의 변위가 임계값 이상인 경우 제2 센싱 데이터(sens_raw2)를 생성할 수 있다. 센싱부는 각각의 센서로부터 획득된 복수의 센싱 데이터를 기초로 센싱 분석 데이터(d_sens)를 생성할 수 있다. 센싱부는 각각의 센싱 데이터에 포함된 노이즈를 제거하고, 미리 정해진 수치에 따라 각각의 센싱 데이터에 포함된 센싱 값을 변환하여, 센싱 분석 데이터(d_sens)를 생성할 수 있다. 일 실시예에서, 센싱 분석 데이터(d_sens)는 제1 센싱 데이터(sens_raw1), 제2 센싱 데이터(sens_raw2)를 포함할 수 있다. 사전처리부는 촬영부에 전기적으로 연결될 수 있다. 사전처리부는 촬영부로부터 복수의 영 상 데이터를 수신할 수 있다. 사전처리부는 각각의 영상 데이터를 사전처리(preprocessing)하여 영상 분석 데이터를 생성할 수 있다. 일 실시예에서, 사전처리부는 각각의 영상 데이터에 포함된 메타데이터를 참고하여 영상 데이터로부터 이 미지를 추출할 수 있다. 사전처리부는 제1 카메라에 의해 촬영된 제1 영상 데이터(img_raw1)를 기초 로, 제1 시각에 제1 카메라에 의해 촬영된 제1 이미지를 추출할 수 있다. 또한, 사전처리부는 제1 영상 데이터(img_raw1)를 기초로 제1 시각에 후속하는 제2 시각에 제1 카메라에 의해 촬영된 제2 이미지를 추출할 수 있다. 이 경우, 제1 시각과 제2 시각의 시간 간격은 로봇 팔의 작동 주기와 동일할 수 있다. 즉, 로봇 팔이 일정한 주기에 따라 상태가 변화하는 경우, 제1 시각의 로봇 팔의 상태(외부 형태)와 제2 시각의 로봇 팔의 상태는 동일할 수 있다. 일 실시예에서, 사전처리부는 제1 이미지의 제1 특정 영역을 기초로 제1 특징점(P1)을 설정할 수 있다. 제 1 특정 영역은, 예를 들면, 로봇 팔의 제1 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제1 특징점(P1)은 제1 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 또한, 제1 특정 영역과 물 리적으로 분리된 제2 특정 영역을 설정하고, 제2 특정 영역을 기초로, 제1 특징점(P1)과 물리적으로 분리된 제2 특징점(P2)을 설정할 수 있다. 예를 들면, 제2 특정 영역은 로봇 팔의 제2 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제2 특징점(P2)은 제2 조인트의 중심에 대응하는 점일 수 있다. 사전처리부 는 제1 특징점(P1)과 제2 특징점(P2)을 기초로 제1 벡터(V1)를 생성할 수 있다. 마찬가지로, 사전처리부 는 제1 특정 영역 및 제2 특정 영역과 물리적으로 분리된 제3 특정 영역을 설정하고, 제3 특정 영역을 기 초로, 제1 특징점(P1) 및 제2 특징점(P2)과 물리적으로 분리된 제3 특징점(P3)을 설정할 수 있다. 예를 들면, 제3 특정 영역은 로봇 팔의 제3 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제3 특징점(P 3)은 제3 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 제2 특징점(P2) 및 제3 특징점(P3) 을 기초로 제2 벡터(V2)를 생성할 수 있다. 다른 실시예에서, 사전처리부는 제1 이미지 및 로봇 팔의 제1 마크를 기초로 제1 특징점(P1)을 설정 할 수 있다. 여기서, 제1 마크는 로봇 팔의 제1 조인트의 표면에 표시된 마크일 수 있다. 일 실시예 에서, 제1 마크는 로봇 팔의 제1 조인트의 제1 방향(x) 표면의 중심에 표시된 마크일 수 있다. 또한, 사전처리부는 제1 이미지 및 로봇 팔의 제2 마크를 기초로 제2 특징점(P2)을 설정할 수 있다. 마찬가 지로, 사전처리부는 제1 이미지 및 로봇 팔의 제3 마크를 기초로 제3 특징점(P3)을 설정할 수 있다. 제2 마크 및 제3 마크는 각각 로봇 팔의 제2 조인트 및 제3 조인트의 표면에 표시된 마크일 수 있다. 일 실시예에서, 제2 마크 및 제3 마크는 각각 로봇 팔의 제2 조인트 및 제3 조인트의 제1 방향(x) 표면의 중심에 표시된 마크일 수 있다. 사전처리부는 제1 특징점(P1) 및 제2 특징점(P2)에 의해 결정되는 제1 벡터(V1)와, 제2 특징점(P2) 및 제3 특징점(P3)에 의해 결정되는 제2 벡터(V2)를 생성할 수 있다. 학습부는 복수의 이미지 내에 포함된 객체를 식별하기 위한 기준을 학습할 수 있다. 예를 들어, 학습부 는 이상 작동이 발생한 로봇 팔의 이미지를 식별하기 위해 학습 모델을 학습시킬 수 있다. 구체 적으로, 학습부는 로봇 팔의 이미지에 포함된 복수의 특정 영역, 또는 복수의 특징점 및 이를 기초로 결정되는 벡터를 기초로 로봇 팔의 이상 작동 발생 여부를 판단하기 위해 학습 모델을 학습시킬 수 있다. 학습부는 복수의 로봇 팔 이미지 중에서, 정상 동작하는 로봇 팔 이미지를 결정하기 위해 학습 모델의 파라미터를 학습시킬 수 있다. 예를 들면, 학습부는 복수의 로봇 팔 이미지의 특정 영역을 기초로, 정상 동작하는 로봇 팔 이 미지의 특정 영역을 결정하고, 결정된 로봇 팔 이미지의 특정 영역과 상이한 특정 영역을 포함하는 로봇 팔 이미지를 이상 동작이 발생한 로봇 팔 이미지로 분류할 수 있다. 또한, 학습부는 결정된 로 봇 팔 이미지의 특정 영역과 동일하거나 유사한 특정 영역을 포함하는 로봇 팔 이미지를 정상 동작하 는 로봇 팔 이미지로 분류할 수 있다. 학습부는 적어도 하나의 하드웨어 칩 형태로 제작되어 디바이스에 탑재될 수 있다. 예를 들어, 학습부 는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기 존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작 되어 전술한 각종 디바이스에 탑재될 수도 있다. 이 경우, 학습부는 하나의 디바이스에 탑재될 수도 있으며, 또는 별개의 디바이스에 탑재될 수도 있다. 한 편, 학습부는 소프트웨어 모듈로 구현될 수 있다. 학습부가 소프트웨어 모듈(또는, 인스트럭션 (instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능 한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 어플리케이션에 의해 제공 될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 어플리케이션에 의해 제공될 수 있다. 학습부는 학습 모델과 학습 모델에 연결된 손실함수 모델을 포함할 수 있다. 일 실시예에서, 학습부는 학습 모델을 이용하여 학습 데이터를 기초로 로봇 팔의 이상 작동 여 부를 판단할 수 있다. 이를 위해, 학습 모델은 입력 레이어, 하나 이상의 히든 레이어 및 출력 레이어를 포함할 수 있다. 학습 모델은 학습 과정을 통해 로봇 팔의 이상 작동 여부를 정확하게 판단하도록 미 리 학습될 수 있다. 이를 위하여, 학습 과정에서 이미지 분석 데이터에 관한 복수의 학습 데이터는 학습 모델 의 입력 레이어에 입력되어 하나 이상의 히든 레이어 및 출력 레이어를 통과하여 출력 벡터가 출력될 수 있다. 손실함수 모델은 손실함수 레이어를 포함할 수 있다. 출력 벡터는 출력 레이어에 연결된 손실함수 모델 의 손실함수 레이어에 입력될 수 있다. 손실함수 레이어는 출력 벡터와 각각의 학습 데이터에 대한 정답 벡터를 비교하는 손실 함수를 이용하여 손실값을 출력할 수 있다. 학습 모델의 파라미터는 손실값이 작아지는 방향으로 학습될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "일 실시예에서, 손실함수 레이어는, [수학식 1]을 이용하여 손실값을 계산할 수 있다. [수학식 1]에서, FL은 손 실값, α는 손실함수의 웨이트 파라미터, γ는 손실함수의 포커싱 파라미터, p_t는 출력 벡터를 의미할 수 있다. 수학식 2"}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "다른 실시예에서, 손실함수 레이어는 [수학식 2]를 따라 손실값을 계산할 수 있다. [수학식 2]에서, N은 복수의 학습 데이터의 수, n은 학습 데이터를 식별하는 자연수, k는 n번째 학습 데이터의 값을 식별하는 자연수, nk는 n번째 학습 데이터의 k번째 값을 의미하고, t는 정답 데이터를 의미하고, y는 출력 벡터를 의미하고, E는 손실 값을 의미할 수 있다. 수학식 3"}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "또 다른 실시예에서, 손실함수 레이어는 [수학식 3]을 따라 손실값을 계산할 수 있다. [수학식 3]에서, n은 클 래스 별 학습 데이터의 수, y와 j는 클래스를 나타내는 식별자, C는 상수값, M은 클래스의 개수, x_y는 학습 데 이터가 클래스 y에 속할 확률값, x_j는 학습 데이터가 클래스 j에 속할 확률값, L은 손실값을 의미할 수 있다. 멀티모달부는, 센싱부로부터 센싱 분석 데이터(d_sens)를 제공받고, 사전처리부로부터 이미지 분석 데이터(d_img)를 제공받고, 센싱 분석 데이터(d_sens)와 이미지 분석 데이터(d_img)를 기초로 로봇 팔 의 이상 작동 발생 여부를 판단할 수 있다. 일 실시예에서, 멀티모달부는 제1 벡터(V1)와 제3 벡터(V3)의 유사도를 기초로 제1 이상 신호를 생성할 수 있다. 일 실시예에서, 멀티모달부는 제1 시각에 선행하는 제3 시각의 제1 이미지 상의 제1 특징점의 위치와, 제1 시각에 후속하고 제2 시각에 선행하는 제4 시각의 제1 이미지 상의 제1 특징점의 위치를 기초로 제1 이상 신호 를 생성할 수 있다. 일 실시예에서, 멀티모달부는 Cosine Similarity, Jaccard similarity, Euclidean distance, Levenshtein distance 중 어느 하나를 이용하여 제1 벡터와 제3 벡터의 유사도를 계산할 수 있다. 그러나 이는 예시적인 것 이고, 본 발명의 실시예는 이에 제한되지 않는다. 멀티모달부가 로봇 팔의 이상 작동 발생 여부를 판단하는 방법에 관하여는 상세히 후술한다. 제어부는 센싱 분석 데이터 및 이미지 분석 데이터를 기초로 로봇 팔의 동작을 제어할 수 있다. 일 실시예에서, 제어부는 스마트 팩토리의 각 공정라인에서 생산되는 복수의 제품 각각의 불량 여부를 판 별할 수 있다. 이를 위해, 스마트 팩토리의 각 공정라인에서 생산되는 복수의 제품 각각은, 고유 바코드가 부여 될 수 있다. 고유 바코드는, 해당 제품의 제품 고유 식별 코드, 제품 생산 시기, 제품이 생산된 공정라인에 대 응하는 정보를 포함할 수 있다. 제어부는 스마트 팩토리의 각 공정라인에서 생산되는 복수의 제품에 대해 품질 검사를 통해 불량 제품을 판별할 수 있다. 제어부는 복수의 제품 중 불량으로 판별되는 제품에 대하여, 스마트 팩토리의 공정라인에 설치된 로봇 팔 의 이상 동작 발생 여부와의 상관관계를 판단하여 상관점수를 출력할 수 있다. 이를 위해, 제어부는 복수의 제품 각각에 포함된 고유 바코드를 기초로, 제품의 생산 시기 및 생산된 공정라인의 정보를 분석하고, 불량으로 판별된 제품에 대응하는 공정라인의 로봇 팔을 특정할 수 있다. 제어부는 로봇 팔의 이상 동작 발생 여부를 확인하고, 불량 제품과 로봇 팔의 이상 동작 발생 여부의 상관관계를 판단할 수 있 다. 제어부는 상관점수가 미리 설정된 임계치를 초과하는 경우, 로봇 팔의 동작 모드를 변경할 수 있다. 제어부는 불량 제품의 발생 여부와 로봇 팔의 이상 동작 발생 여부의 상관관계를 판단하기 위해, 복 수의 이상 신호 발생 기록을 참고할 수 있다. 제어부는 로봇 팔의 이상 신호가 발생한 경우, 해당 이 상 신호가 발생한 시점으로부터 일정 시간 구간 동안, 해당 로봇 팔이 설치된 공정라인에서 생산된 제품의 불량 여부를 기초로, 로봇 팔의 이상 신호 발생 여부와 불량 제품의 발생 여부와의 상관관계를 판단하여 상관점수를 출력할 수 있다. 수학식 4"}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "일 실시예에서, 제어부는 [수학식 4]를 이용하여 상관점수를 출력할 수 있다. [수학식 4]에서, %D는 특정 시간 구간에서의 불량률, n(dP)는 공정라인의 불량 제품 개수, n(P)는 공정라인의 생산 제품 총 개수, t_err은 로봇 팔에서 특정 이상 동작이 발생한 시기, △t_c는 시간 구간 상수를 의미할 수 있다. 즉, 제어부는 특 정 공정라인에 설치된 로봇 팔의 이상 동작 발생 시기로부터 일정 시간 구간 내의 생산 제품의 불량률을 기초로, 로봇 팔의 이상 신호 발생 여부와 불량 제품의 발생 여부와의 상관관계를 판단하여 상관점수를 출 력할 수 있다. 일 실시예에서, 제어부는 불량률(%D)과 미리 설정된 임계값의 차에 비례하여 상기 특정 이 상 동작에 대해 높은 상관점수를 부여할 수 있다. 일 실시예에서, 제어부는 상관점수가 미리 설정된 임계값을 초과하는 경우, 로봇 팔의 동작 모드를 제1 동작 모드에서 제2 동작 모드로 변경할 수 있다. 여기서, 제1 동작 모드는 일반 생산 모드일 수 있고, 제2 동작 모드는 비상 정지 모드일 수 있다. 다음으로, 도 5a 내지 도 8을 참조하여, 로봇 팔의 동작을 설명한다. 도 5a 및 도 5b는 본 발명의 로봇 팔의 제1 상태를 나타내는 예시적인 도면이다. 도 6은 본 발명의 로봇 팔의 제2 상태를 나타내는 예시적인 도면이다. 도 7 및 8은 로봇 팔의 동작을 설명하기 위한 도면이 다. 이하의 로봇 팔의 동작 설명은 예시적인 것으로, 본 발명의 기술적 사상을 해치지 않는 한, 이하의 설명은 본 발명의 다양한 실시예에 따라 다르게 이해될 수 있다. 도 5a는 제1 시각(t1)에서 도 1에 도시된 제1 카메라에 의해 촬영된 제1 상태(S1)의 로봇 팔을 도시 한 도면이다. 제1 시각(t1) 이후, 제어부의 제어에 의해, 로봇 팔의 제2 조인트는 제1 암 에 대하여 제2 암을 제1 방향(x)을 축으로 시계방향으로 회전 이동시킬 수 있다. 이 경우, 제3 조인트 는 제3 암이 지지부와 이루는 각도가 유지되도록 제3 암을 제2 암에 대하여 회전 이 동시킬 수 있다. 제1 구분 동작(SM1) 이후, 도 6은 제2 시각(t2)에서 도 1에 도시된 제1 카메라에 의해 촬 영된 제2 상태(S2)의 로봇 팔을 도시한 도면이다. 로봇 팔이 제1 상태(S1)에서 제2 상태(S2)로 변화 하는데 걸리는 시간은 제1 시각(t1)과 제2 시각(t2)의 시간 간격과 같다. 로봇 팔의 작동 주기가 T인 경우, 로봇 팔이 제1 상태(S1)에서 제2 상태(S2)로 변화하는데 걸리는 시간은 T/k(k는 하나의 동작을 구성 하는 구분 동작의 수)일 수 있다. 즉, 도 8을 참조하면, 로봇 팔의 작동 주기가 T인 경우, 로봇 팔이 제1 상태(S1)에서 제2 상태(S2)로 변화하는데 걸리는 시간은 T/4일 수 있다. 로봇 팔의 동작은 제어부에 의해 제어될 수 있다. 로봇 팔은 미리 설정된 스마트 팩토리 제어 프로그램에 따라, 일정한 주기로 같은 동작을 반복할 수 있다. 일 실시예에서, 로봇 팔의 동작은 복수의 구분 동작으로 구성될 수 있다. 예를 들면, 도 7에 도시된 바와 같이, 로봇 팔의 제1 동작(M1)은, 제1 구분 동작(SM1), 제2 구분 동작 (SM2), 제3 구분 동작(SM3), 제4 구분 동작(SM4)으로 구성될 수 있다. 제1 구분 동작(SM1)은 로봇 팔의 상태를 제1 상태(S1)에서 제2 상태(S2)로 변경시키는 동작을 의미할 수 있다. 제2 구분 동작(SM2)은 로봇 팔 의 상태를 제2 상태(S2)에서 제3 상태(S3)로 변경시키는 동작을 의미할 수 있다. 마찬가지로, 제3 구분 동 작(SM3)은 로봇 팔의 상태를 제3 상태(S3)에서 제4 상태(S4)로 변경시키는 동작을 의미할 수 있다. 마지막 으로, 제4 구분 동작(SM4)은 로봇 팔의 상태를 제4 상태(S4)에서 다시 초기의 제1 상태(S1)로 변경시키는 동작을 의미할 수 있다. 즉, 로봇 팔은 제1 내지 제4 구분 동작에 따라, 제1 내지 제4 상태가 일정한 주기 로 반복되며 작동할 수 있다. 도 8을 참조하면, 시간의 흐름에 따라, 로봇 팔은 제1 구분 동작(SM1), 제2 구분 동작(SM2), 제3 구분 동 작(SM3), 제4 구분 동작(SM4), 제1 구분 동작(SM1)쪋 순서로 작동할 수 있다. 이 경우, 각각의 구분 동작 간 시 간 간격은 동일할 수 있다. 즉, 로봇 팔의 제1 동작의 주기를 T라고 할 경우, 로봇 팔의 제1 동작과 제2 동작의 간격, 로봇 팔의 제2 동작과 제3 동작의 간격, 로봇 팔의 제3 동작과 제4 동작의 간격, 로봇 팔의 제4 동작과 제1 동작의 간격은 각각 동일할 수 있다. 도 5a는 도 1에 도시된 제1 카메라에 의해 촬영된 정상 동작하는 로봇 팔의 제1 상태를 도시한 도면 이다. 도 5b는 도 1에 도시된 제1 카메라에 의해 촬영된 이상 동작이 발생한 로봇 팔의 제1 상태를 도시한 도면이다. 이하에서, 제1 이미지는 도 5a에 도시된 로봇 팔의 이미지를 의미하고, 제2 이미지는 도 5b에 도시된 로봇 팔의 이미지를 의미한다. 사전처리부는 제1 이미지의 제1 특정 영역을 기초로 제1 특징점(P1)을 설정할 수 있다. 제1 특정 영역은, 예를 들면, 로봇 팔의 제1 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제1 특징점(P1)은 제 1 이미지 상의 제1 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 또한, 제1 이미지의 제1 특정 영역과 물리적으로 분리된 제2 특정 영역을 설정하고, 제2 특정 영역을 기초로, 제1 이미지 상의 제1 특징 점(P1)과 물리적으로 분리된 제2 특징점(P2)을 설정할 수 있다. 예를 들면, 제2 특정 영역은 로봇 팔의 제 2 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제2 특징점(P2)은 제1 이미지 상의 제2 조인트 의 중심에 대응하는 점일 수 있다. 사전처리부는 제1 특징점(P1)과 제2 특징점(P2)을 기초로 제1 벡 터(V1)를 생성할 수 있다. 또한, 사전처리부는 제1 이미지의 제1 특정 영역 및 제2 특정 영역과 물리적으 로 분리된 제3 특정 영역을 설정하고, 제3 특정 영역을 기초로, 제1 특징점(P1) 및 제2 특징점(P2)과 물리적으 로 분리된 제1 이미지 상의 제3 특징점(P3)을 설정할 수 있다. 예를 들면, 제3 특정 영역은 로봇 팔의 제3조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제3 특징점(P3)은 제1 이미지 상의 제3 조인트 의 중심에 대응하는 점일 수 있다. 사전처리부는 제2 특징점(P2) 및 제3 특징점(P3)을 기초로 제2 벡터 (V2)를 생성할 수 있다. 마찬가지로, 사전처리부는 제2 이미지의 제1 특정 영역을 기초로 제4 특징점(P1')을 설정할 수 있다. 제1 특정 영역은, 예를 들면, 로봇 팔의 제1 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제4 특 징점(P1')은 제2 이미지 상의 제1 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 또한, 제2 이미지의 제1 특정 영역과 물리적으로 분리된 제2 특정 영역을 설정하고, 제2 특정 영역을 기초로, 제2 이미지 상의 제4 특징점(P1')과 물리적으로 분리된 제5 특징점(P2')을 설정할 수 있다. 예를 들면, 제2 특정 영역은 로 봇 팔의 제2 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제5 특징점(P2')은 제2 이미지 상 의 제2 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 제4 특징점(P1')과 제5 특징점(P2')을 기초로 제3 벡터(V1')를 생성할 수 있다. 또한, 사전처리부는 제2 이미지의 제1 특정 영역 및 제2 특정 영 역과 물리적으로 분리된 제3 특정 영역을 설정하고, 제3 특정 영역을 기초로, 제4 특징점(P1') 및 제5 특징점 (P2')과 물리적으로 분리된 제2 이미지 상의 제6 특징점(P3')을 설정할 수 있다. 예를 들면, 제3 특정 영역은 로봇 팔의 제3 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제6 특징점(P3')은 제2 이미지 상의 제3 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 제5 특징점(P2') 및 제6 특징점 (P3')을 기초로 제4 벡터(V2')를 생성할 수 있다. 만약 로봇 팔이 정상적으로 작동하는 경우, 도 7에 도시된 작동 과정 동안, 로봇 팔의 각 상태(예를 들면, 도5a에 도시된 제1 상태)를 촬영한 이미지는 동일하여야 한다. 즉, 로봇 팔이 정상적으로 작동하는 경우, 도 5a와 도 5b는 동일한 이미지이어야 한다. 그러나, 로봇 팔이 정상적으로 작동하지 않는 경우, 도 5a와 도 5b는 일치하지 않을 수 있다. 즉, 제1 내지 제3 특징점(P1, P2, P3)은 각각 제4 내지 제6 특징점(P1', P2', P3')과 동일하지 않을 수 있다. 또한, 제1 벡터(V1) 및 제2 벡터(V2)는 각각 제3 벡터(V1') 및 제4 벡터 (V2')와 동일하지 않을 수 있다. 예를 들면, 스마트 팩토리 공정라인의 환경 변화에 따라 로봇 팔에 진동 이 발생하여 로봇 팔의 제1 상태가 일정하게 유지되지 않을 수 있다. 이에 따라, 제1 시각(t1), 제5 시각 (t5), 제9 시각에 제1 카메라에 의해 촬영된 로봇 팔의 상태는 동일하지 않을 수 있다. 다양한 요인 에 따라, 이러한 로봇 팔의 비정상 동작은 미세할 수 있고, 육안으로 식별하기 어려울 수 있다. 이를 자동 으로 확인하고 로봇 팔의 작동을 제어하기 위해 본 발명의 다양한 실시예가 제안된다. 도 9는 본 발명의 일 실시예에 따른 스마트 팩토리 제어 장치의 동작을 설명하기 위한 흐름도이다. 도 9를 참조하면, S910 단계에서, 촬영부에 의해, 로봇 팔을 촬영하여 영상 데이터를 획득할 수 있다. 촬영부에 포함된 복수의 카메라 각각은 로봇 팔의 정지 상태 또는 작동 상태를 촬영하여 영상 데이터(img_raw)를 생성할 수 있다. 각각의 영상 데이터는 영상 촬영 시기에 대응하는 시간 정보, 로봇 팔(20 0)과 카메라가 이루는 각도 및 거리에 대응하는 위치 정보를 포함하는 메타데이터를 포함할 수 있다. 이어, S920 단계에서, 센싱부에 의해, 로봇 팔의 상태를 감지하여 센싱 분석 데이터를 생성할 수 있 다. 센싱부는 로봇 팔의 작동 상태(예를 들면, 전력 또는 온도), 또는 로봇 팔 외부의 환경 상 태를 감지하고, 감지된 상태에 대응하는 전기 신호 또는 데이터 값을 생성할 수 있다. 센싱부는 복수의 센 서를 포함할 수 있다. 예를 들면, 센싱부는 제스처 센서, 자이로 센서, 기압 센서, 마그네틱 센서, 가속도 센서, 그립 센서, 근접 센서, 컬러 센서, IR(infrared) 센서, 생체 센서, 온도 센서, 습도 센서, 또는 조도 센 서를 포함할 수 있다. 센싱부에 포함된 복수의 센서 각각은 로봇 팔의 작동 상태 또는 로봇 팔 외부의 환경 상태를 감지할 수 있다. 센싱부에 포함된 복수의 센서 각각은 로봇 팔의 작동 상태 또는 로봇 팔 외부의 환경 상태를 감지하여 센싱 데이터(sens_raw)를 생성할 수 있다. 센싱부는 각각의 센 서로부터 획득된 복수의 센싱 데이터를 기초로 센싱 분석 데이터(d_sens)를 생성할 수 있다. 센싱부는 각 각의 센싱 데이터에 포함된 노이즈를 제거하고, 미리 정해진 수치에 따라 각각의 센싱 데이터에 포함된 센싱 값 을 변환하여, 센싱 분석 데이터(d_sens)를 생성할 수 있다. S930 단계에서, 사전처리부에 의해, 영상 데이터를 기초로 이미지 분석 데이터를 출력할 수 있다. 사전처 리부는 각각의 영상 데이터에 포함된 메타데이터를 참고하여 영상 데이터로부터 이미지를 추출할 수 있다. 사전처리부는 제1 카메라에 의해 촬영된 제1 영상 데이터(img_raw1)를 기초로, 제1 시각에 제1 카메 라에 의해 촬영된 제1 이미지를 추출할 수 있다. 또한, 사전처리부는 제1 영상 데이터(img_raw1)를 기초로 제1 시각에 후속하는 제2 시각에 제1 카메라에 의해 촬영된 제2 이미지를 추출할 수 있다. 이경우, 제1 시각과 제2 시각의 시간 간격은 로봇 팔의 작동 주기와 동일할 수 있다. 즉, 로봇 팔이 일 정한 주기에 따라 상태가 변화하는 경우, 제1 시각의 로봇 팔의 상태(외부 형태)와 제2 시각의 로봇 팔 의 상태는 동일할 수 있다. S940 단계에서, 멀티모달부에 의해, 센싱 분석 데이터 및 이미지 분석 데이터를 입력받고 이를 기초로 학 습 데이터를 출력할 수 있다. 멀티모달부는, 센싱부로부터 센싱 분석 데이터(d_sens)를 제공받고, 사 전처리부로부터 이미지 분석 데이터(d_img)를 제공받고, 센싱 분석 데이터(d_sens)와 이미지 분석 데이터 (d_img)를 기초로 로봇 팔의 이상 작동 발생 여부를 판단할 수 있다. S950 단계에서, 학습부에 의해, 학습 데이터를 입력받고, 다층 신경망(Multiple Neural Network)을 이용 하여 학습 데이터를 정답 데이터와 비교하여 비교 결과를 출력할 수 있다. 학습부는 복수의 이미지 내에 포함된 객체를 식별하기 위한 기준을 학습할 수 있다. 예를 들어, 학습부는 이상 작동이 발생한 로봇 팔 의 이미지를 식별하기 위해 학습 모델을 학습시킬 수 있다. 구체적으로, 학습부는 로봇 팔(20 0)의 이미지에 포함된 복수의 특정 영역, 또는 복수의 특징점 및 이를 기초로 결정되는 벡터를 기초로 로봇 팔 의 이상 작동 발생 여부를 판단하기 위해 학습 모델을 학습시킬 수 있다. 학습부는 복수의 로봇 팔 이미지 중에서, 정상 동작하는 로봇 팔 이미지를 결정하기 위해 학습 모델의 파라미터를 학 습시킬 수 있다. 도 10은 본 발명의 일 실시예에 따른 로봇 팔의 행동개선 솔루션 제공 방법을 설명하기 위한 흐름도이다. 도 10을 참조하면, 먼저, 사전처리부는 영상 데이터에 포함된 메타데이터를 참고하여 영상 데이터로부터 복수의 이미지를 추출할 수 있다(S1010). 여기서, 복수의 이미지는, 특정 카메라에 의해 복수의 시각에서 촬영 된 로봇 팔의 이미지를 의미할 수 있다. 예를 들면, 복수의 이미지는, 제1 시각에 제1 카메라에 의해 촬영된 로봇 팔의 이미지와, 제1 시각으로부터 제1 시간 간격만큼 후속하는 제2 시각에 제1 카메라에 의해 촬영된 로봇 팔의 이미지와, 제2 시각으로부터 제1 시간 간격만큼 후속하는 제3 시각에 제1 카메라 에 의해 촬영된 로봇 팔의 이미지를 포함할 수 있다. 여기서, 제1 시간 간격은 로봇 팔의 작동 주기 (T)와 동일할 수 있다. 일 실시예에서, 사전처리부는 제1 영상 데이터(img_raw1)를 기초로, 제1 시각(t1)에 제1 카메라에 의 해 촬영된 제1 상태(S1)의 로봇 팔을 제1 이미지(도 5a)로서 추출할 수 있다. 또한, 사전처리부는 제 1 시각(t1)에 후속하는 제5 시각(t5)에 제1 카메라에 의해 촬영된 제1 상태(S1)의 로봇 팔을 제2 이 미지(도 5b)로서 추출할 수 있다. 이 경우, 도 8을 참조하면, 제1 시각(t1)과 제5 시각(t5)의 시간 간격은 로봇 팔의 작동 주기(T)와 동일할 수 있다. 다음으로, 사전처리부는 복수의 이미지 각각에 대하여 복수의 특정 영역을 설정하고, 복수의 특정 영역을 기초로 복수의 특징점을 설정하고, 복수의 특징점을 기초로 하나 이상의 벡터를 생성하고, 복수의 이미지와 각 각의 특정 영역, 특징점, 및 벡터를 기초로 학습 데이터를 생성할 수 있다(S1020). 일 실시예에서, 사전처리부는 제1 이미지의 제1 특정 영역을 기초로 제1 특징점(P1)을 설정할 수 있다. 제 1 특정 영역은, 예를 들면, 로봇 팔의 제1 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제1 특징점(P1)은 제1 이미지 상의 제1 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 또한, 제1 이미지의 제1 특정 영역과 물리적으로 분리된 제2 특정 영역을 설정하고, 제2 특정 영역을 기초로, 제1 이미지 상의 제1 특징점(P1)과 물리적으로 분리된 제2 특징점(P2)을 설정할 수 있다. 예를 들면, 제2 특정 영역은 로봇 팔의 제2 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제2 특징점(P2)은 제1 이미지 상의 제 2 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 제1 특징점(P1)과 제2 특징점(P2)을 기초로 제1 벡터(V1)를 생성할 수 있다. 또한, 사전처리부는 제1 이미지의 제1 특정 영역 및 제2 특정 영역과 물 리적으로 분리된 제3 특정 영역을 설정하고, 제3 특정 영역을 기초로, 제1 특징점(P1) 및 제2 특징점(P2)과 물 리적으로 분리된 제1 이미지 상의 제3 특징점(P3)을 설정할 수 있다. 예를 들면, 제3 특정 영역은 로봇 팔(20 0)의 제3 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제3 특징점(P3)은 제1 이미지 상의 제3 조 인트의 중심에 대응하는 점일 수 있다. 사전처리부는 제2 특징점(P2) 및 제3 특징점(P3)을 기초로 제 2 벡터(V2)를 생성할 수 있다. 마찬가지로, 사전처리부는 제2 이미지의 제1 특정 영역을 기초로 제4 특징점(P1')을 설정할 수 있다. 제1 특정 영역은, 예를 들면, 로봇 팔의 제1 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제4 특징점(P1')은 제2 이미지 상의 제1 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 또한, 제2 이미지의 제1 특정 영역과 물리적으로 분리된 제2 특정 영역을 설정하고, 제2 특정 영역을 기초로, 제2 이미지 상의 제4 특징점(P1')과 물리적으로 분리된 제5 특징점(P2')을 설정할 수 있다. 예를 들면, 제2 특정 영역은 로 봇 팔의 제2 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제5 특징점(P2')은 제2 이미지 상 의 제2 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 제4 특징점(P1')과 제5 특징점(P2')을 기초로 제3 벡터(V1')를 생성할 수 있다. 또한, 사전처리부는 제2 이미지의 제1 특정 영역 및 제2 특정 영 역과 물리적으로 분리된 제3 특정 영역을 설정하고, 제3 특정 영역을 기초로, 제4 특징점(P1') 및 제5 특징점 (P2')과 물리적으로 분리된 제2 이미지 상의 제6 특징점(P3')을 설정할 수 있다. 예를 들면, 제3 특정 영역은 로봇 팔의 제3 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제6 특징점(P3')은 제2 이미지 상의 제3 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 제5 특징점(P2') 및 제6 특징점 (P3')을 기초로 제4 벡터(V2')를 생성할 수 있다. 사전처리부는 복수의 이미지와, 각각의 이미지에 포함된 복수의 특정 영역, 복수의 특징점, 및 하나 이상 의 벡터를 기초로 학습 데이터를 생성할 수 있다. 즉, 학습 데이터는 특정한 영역 및 포인트가 지정된 복수의 이미지 데이터일 수 있다. 다음으로, 학습부의 학습 모델은 학습 데이터를 입력받고, 학습 데이터를 정답 데이터와 비교하여 비 교 결과를 출력할 수 있다(S1030). 먼저, 학습부의 학습 모델의 입력 레이어는 학습 데이터를 입력받을 수 있다. 학습 데이터는 로봇 팔 의 이미지에 포함된 복수의 특정 영역, 또는 복수의 특징점 및 이를 기초로 결정되는 벡터에 대응하는 정 보를 포함할 수 있다. 학습 모델은 학습 데이터에 포함된 복수의 로봇 팔 이미지를 기초로, 정상 동 작하는 로봇 팔 이미지를 식별하기 위해 미리 학습될 수 있다. 정답 데이터는, 정상 동작하는 복수의 로봇 팔 이미지를 포함할 수 있다. 정상 동작하는 복수의 로봇 팔 이미지 각각은 복수의 특정 영역을 포함할 수 있다. 각각의 특정 영역은 특징점을 포함할 수 있고, 각각 의 특징점을 기초로 하나 이상의 정답 벡터가 결정될 수 있다. 학습 모델은 학습 데이터와 정답 데이터를 비교하여 비교 결과를 출력할 수 있다. 학습부는 정답 데 이터로 결정된 로봇 팔 이미지의 특정 영역과 상이한 특정 영역을 포함하는 로봇 팔 이미지를 이상 동작이 발생한 로봇 팔 이미지로 분류할 수 있다. 또한, 학습부는 정답 데이터로 결정된 로봇 팔 이미지의 특정 영역과 동일하거나 유사한 특정 영역을 포함하는 로봇 팔 이미지를 정상 동작하는 로 봇 팔 이미지로 분류할 수 있다. 일 실시예에서, 학습부는 학습 모델을 이용하여 학습 데이터를 기초로 로봇 팔의 이상 작동 여 부를 판단할 수 있다. 이를 위해, 학습 모델은 입력 레이어, 하나 이상의 히든 레이어 및 출력 레이어를 포함할 수 있다. 학습 모델은 학습 과정을 통해 로봇 팔의 이상 작동 여부를 정확하게 판단하도록 미 리 학습될 수 있다. 이를 위하여, 학습 과정에서 이미지 분석 데이터에 관한 복수의 학습 데이터는 학습 모델 의 입력 레이어에 입력되어 하나 이상의 히든 레이어 및 출력 레이어를 통과하여 출력 벡터가 출력될 수 있다. 다음으로, 학습부의 손실함수 모델은 출력 벡터를 입력받고, 손실함수를 이용하여 손실값을 출력할 수 있다(S1040). 일 실시예에서, 출력 벡터는 출력 레이어에 연결된 손실함수 모델의 손실함수 레이어에 입력될 수 있다. 손실함수 레이어는 출력 벡터와 각각의 학습 데이터에 대한 정답 벡터를 비교하는 손실 함수를 이용하여 손실값 을 출력할 수 있다. 다음으로, 제어부는 손실값을 기초로 학습부의 학습 모델의 파라미터를 변경하고, 로봇 팔(20 0)의 작동을 제어할 수 있다(S1050). 학습 모델의 파라미터는 손실값이 작아지는 방향으로 학습될 수 있다. 즉, 제어부는 손실값을 기초로 학습부를 제어할 수 있다. 또한, 제어부는 로봇 팔의 이상 동작 발생 여부를 판단하고, 이를 기초로 로봇 팔의 동작을 제어할 수 있다. 전술한 바와 같이, 본 발명의 일 실시예에 따른 로봇 팔의 행동개선 솔루션은, 로봇 팔을 촬영하여 이미지 데이 터를 획득하고, 이를 뉴럴 네트워크를 이용하여 학습시켜 이미지 데이터 중 정상 동작하는 로봇 팔 이미지와 오 작동하는 로봇 팔 이미지를 식별할 수 있다. 이를 통해 로봇 팔에 이상 동작이 발생한 경우, 이를 자동으로 제어하여 스마트 팩토리의 공정라인을 원활하게 관리할 수 있다. 도 11은 본 발명의 일 실시예에 따른 사전처리부의 이미지 데이터 처리 방법을 설명하기 위한 흐름도이다. 도 11을 참조하면, 먼저, S1110에서, 사전처리부는 제1 영상 데이터(img_raw1)를 기초로, 제1 시각(t1)에 제1 카메라에 의해 촬영된 제1 상태(S1)의 로봇 팔을 제1 이미지(도 5a)로서 추출할 수 있다. 또한, 사전처리부는 제1 시각(t1)에 후속하는 제5 시각(t5)에 제1 카메라에 의해 촬영된 제1 상태(S1)의 로 봇 팔을 제2 이미지(도 5b)로서 추출할 수 있다. 이 경우, 도 8을 참조하면, 제1 시각(t1)과 제5 시각(t 5)의 시간 간격은 로봇 팔의 작동 주기(T)와 동일할 수 있다. 다음으로, S1120에서, 사전처리부는 제1 이미지의 제1 특정 영역을 기초로 제1 특징점을 설정하고, 상기 제1 이미지의 제2 특정 영역을 기초로 상기 제1 특징점과 물리적으로 분리된 제2 특징점을 설정하고, 상기 제1 특징점과 상기 제2 특징점을 기초로 제1 벡터를 생성할 수 있다. 사전처리부는 제1 이미지의 제1 특정 영 역을 기초로 제1 특징점(P1)을 설정할 수 있다. 제1 특정 영역은, 예를 들면, 로봇 팔의 제1 조인트 에 대응하는 이미지 영역일 수 있다. 이 경우, 제1 특징점(P1)은 제1 이미지 상의 제1 조인트의 중심에 대 응하는 점일 수 있다. 사전처리부는 또한, 제1 이미지의 제1 특정 영역과 물리적으로 분리된 제2 특정 영 역을 설정하고, 제2 특정 영역을 기초로, 제1 이미지 상의 제1 특징점(P1)과 물리적으로 분리된 제2 특징점(P 2)을 설정할 수 있다. 예를 들면, 제2 특정 영역은 로봇 팔의 제2 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제2 특징점(P2)은 제1 이미지 상의 제2 조인트의 중심에 대응하는 점일 수 있다. 사전 처리부는 제1 특징점(P1)과 제2 특징점(P2)을 기초로 제1 벡터(V1)를 생성할 수 있다. 다음으로, S1130에서, 사전처리부는 제2 이미지의 제1 특정 영역을 기초로 제4 특징점(P1')을 설정할 수 있다. 제1 특정 영역은, 예를 들면, 로봇 팔의 제1 조인트에 대응하는 이미지 영역일 수 있다. 이 경 우, 제4 특징점(P1')은 제2 이미지 상의 제1 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 또한, 제2 이미지의 제1 특정 영역과 물리적으로 분리된 제2 특정 영역을 설정하고, 제2 특정 영역을 기초로, 제2 이미지 상의 제4 특징점(P1')과 물리적으로 분리된 제5 특징점(P2')을 설정할 수 있다. 예를 들면, 제2 특 정 영역은 로봇 팔의 제2 조인트에 대응하는 이미지 영역일 수 있다. 이 경우, 제5 특징점(P2')은 제 2 이미지 상의 제2 조인트의 중심에 대응하는 점일 수 있다. 사전처리부는 제4 특징점(P1')과 제5 특 징점(P2')을 기초로 제3 벡터(V1')를 생성할 수 있다. 다음으로, S1140에서, 멀티모달부는 제1 벡터와 제3 벡터의 유사도를 기초로 로봇 팔의 이상 작동 여 부를 판단할 수 있다. 일 실시예에서, 멀티모달부는 제1 벡터(V1)와 제3 벡터(V1')의 유사도를 기초로 제1 이상 신호를 생성할 수 있다. 일 실시예에서, 멀티모달부는 Cosine Similarity, Jaccard similarity, Euclidean distance, Levenshtein distance 중 어느 하나를 이용하여 제1 벡터와 제3 벡터의 유사도를 계산할 수 있다. 그러나 이는 예시적인 것이고, 본 발명의 실시예는 이에 제한되지 않는다. 일 실시예에서, 멀티모달부는 제1 벡터와 제3 벡터의 유사도가 미리 설정된 임계값 이하인 경우, 로봇 팔 의 제1 이상 신호를 생성할 수 있다. 제어부는 멀티모달부로부터 제1 이상 신호를 수신하는 경 우, 제1 이상 신호를 기초로 로봇 팔의 동작을 제어할 수 있다. 전술한 바와 같이, 본 발명의 일 실시예에 따른 이미지 데이터 처리 방법은 로봇 팔을 촬영하여 획득한 영상 데 이터를 기초로 이미지 데이터를 추출하고, 정상 데이터와 용이하게 비교할 수 있도록 이미지 데이터를 가공할 수 있다. 도 12는 본 발명의 다른 실시예에 따른 사전처리부의 이미지 데이터 처리 방법을 설명하기 위한 흐름도이다. 도 12를 참조하면, 먼저, S1210에서, 사전처리부는 제1 영상 데이터(img_raw1)를 기초로, 제1 시각(t1)에 제1 카메라에 의해 촬영된 제1 마크가 표시된 제1 상태(S1)의 로봇 팔을 제1 이미지(도 5a)로서 추출 할 수 있다. 또한, 사전처리부는 제1 시각(t1)에 후속하는 제5 시각(t5)에 제1 카메라에 의해 촬영된 제2 마크가 표시된 제1 상태(S1)의 로봇 팔을 제2 이미지(도 5b)로서 추출할 수 있다. 이 경우, 도 8을 참 조하면, 제1 시각(t1)과 제5 시각(t5)의 시간 간격은 로봇 팔의 작동 주기(T)와 동일할 수 있다. 다음으로, S1220에서, 사전처리부는 제1 이미지의 제1 마크를 기초로 제1 특징점을 설정하고, 상기 제1 이 미지의 제2 마크를 기초로 상기 제1 특징점과 물리적으로 분리된 제2 특징점을 설정하고, 상기 제1 특징점과 상기 제2 특징점을 기초로 제1 벡터를 생성할 수 있다. 이 경우, 제1 특징점(P1)은 제1 이미지 상의 제1 마크에 대응하는 점일 수 있다. 또한, 제2 특징점(P2)은 제1 이미지 상의 제2 마크에 대응하는 점일 수 있다. 사전처리 부는 제1 특징점(P1)과 제2 특징점(P2)을 기초로 제1 벡터(V1)를 생성할 수 있다. 다음으로, S1230에서, 사전처리부는 제2 이미지의 제1 마크를 기초로 제1 특징점을 설정하고, 상기 제2 이 미지의 제2 마크를 기초로 상기 제1 특징점과 물리적으로 분리된 제2 특징점을 설정하고, 상기 제1 특징점과 상 기 제2 특징점을 기초로 제3 벡터(V1')를 생성할 수 있다. 이 경우, 제1 특징점(P1)은 제2 이미지 상의 제1 마 크에 대응하는 점일 수 있다. 또한, 제2 특징점(P2)은 제2 이미지 상의 제2 마크에 대응하는 점일 수 있다. 사 전처리부는 제1 특징점(P1)과 제2 특징점(P2)을 기초로 제3 벡터(V1')를 생성할 수 있다. 다음으로, S1240에서, 멀티모달부는 제1 벡터와 제3 벡터의 유사도를 기초로 로봇 팔의 이상 작동 여 부를 판단할 수 있다. 일 실시예에서, 멀티모달부는 제1 벡터(V1)와 제3 벡터(V1')의 유사도를 기초로 제1 이상 신호를 생성할 수 있다. 일 실시예에서, 멀티모달부는 Cosine Similarity, Jaccard similarity, Euclidean distance, Levenshtein distance 중 어느 하나를 이용하여 제1 벡터와 제3 벡터의 유사도를 계산할 수 있다. 그러나 이는 예시적인 것이고, 본 발명의 실시예는 이에 제한되지 않는다. 일 실시예에서, 멀티모달부는 제1 벡터와 제3 벡터의 유사도가 미리 설정된 임계값 이하인 경우, 로봇 팔 의 제1 이상 신호를 생성할 수 있다. 제어부는 멀티모달부로부터 제1 이상 신호를 수신하는 경 우, 제1 이상 신호를 기초로 로봇 팔의 동작을 제어할 수 있다. 일 실시예에서, 사전처리부는 제1 시각(t1)에 후속하고 제5 시각(t5)에 선행하는 제4 시각(t4)의 제3 이미 지와, 제5 시각(t5)에 후속하는 제6 시각(t6)의 제4 이미지를 추출할 수 있다. 사전처리부는 제3 이미지와 제4 이미지에 대해서, 도 11의 S1110 내지 S1130 단계를 수행할 수 있다. 멀티모달부는 제3 이미지와 제4 이미지에 대해서 생성된 각각의 벡터를 기초로, 로봇 팔의 이상 동작 발생 여부를 확인할 수 있다. 또는, 사전처리부는 제3 이미지와 제4 이미지에 대해서, 도 12의 S1210 내지 S1230 단계를 수행할 수 있다. 멀티 모달부는 제3 이미지와 제4 이미지에 대해서 생성된 각각의 벡터를 기초로, 로봇 팔의 이상 동작 발 생 여부를 확인할 수 있다. 전술한 바와 같이, 본 발명의 일 실시예에 따른 이미지 데이터 처리 방법은 로봇 팔을 촬영하여 획득한 영상 데 이터를 기초로 이미지 데이터를 추출하고, 정상 데이터와 용이하게 비교할 수 있도록 이미지 데이터를 가공할 수 있다. 또한 로봇 팔의 이상 동작 발생 여부가 확인되는 특정 상태 전/후의 상태를 참고하여, 로봇 팔의 이상 동작 발생 여부 판단의 정확도를 높일 수 있다. 도 13은 본 발명의 일 실시예에 따른 멀티모달부의 이상 동작 센싱 방법을 설명하기 위한 흐름도이다. 도 13을 참조하면, 먼저 S1310 단계에서, 멀티모달부는 제1 센싱 분석 데이터의 제1 임계값 초과 여부에 기초하여 제1 피드백 신호를 생성할 수 있다. S1320 단계에서, 멀티모달부는 제2 센싱 분석 데이터의 제2 임계값 초과 여부에 기초하여 제2 피드백 신호 를 생성할 수 있다. 일 실시예에서, 멀티모달부는 제1 피드백 신호 및 제2 피드백 신호를 기초로 로봇 팔의 이상 신호를 생성할 수 있다. S1330 단계에서, 멀티모달부는 이미지 분석 데이터에 포함된 제1 벡터와 제2 벡터의 유사도 값의 제3 임계 값 초과 여부에 기초하여 네거티브 신호를 생성할 수 있다. S1330 단계에서, 멀티모달부는 제1 피드백 신호, 제2 피드백 신호를 논리곱한 후, 네거티브 신호와 배타적 논리합하여 로봇 팔의 이상 신호를 생성할 수 있다. 전술한 바와 같이, 본 발명의 일 실시예에 따른 로봇 팔의 이상 동작 센싱 방법은, 복수의 센서에 의해 획득된 센싱 분석 데이터와, 카메라에 의해 획득된 이미지 분석 데이터를 모두 이용하여 로봇 팔에 이상 동작이 발생하 였는지를 정확하게 판단할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터 를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로"}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2022-0091556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5a 도면5b 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13"}
{"patent_id": "10-2022-0091556", "section": "도면", "subsection": "도면설명", "item": 1, "content": "실시예들에 대한 이해를 돕기 위해 상세한 설명의 일부로 포함된, 첨부 도면은 다양한 실시예들을 제공하고, 상 세한 설명과 함께 다양한 실시예들의 기술적 특징을 설명한다. 도 1은 로봇 팔을 이용한 스마트 팩토리 공정 환경을 개략적으로 나타내는 도면이다. 도 2는 본 발명의 일 실시예에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 3은 도 1의 로봇 팔을 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에 따른 스마트 팩토리 제어 장치의 구성을 설명하기 위한 블록도이다. 도 5a 및 도 5b는 본 발명의 로봇 팔의 제1 상태를 나타내는 예시적인 도면이다. 도 6은 본 발명의 로봇 팔의 제2 상태를 나타내는 예시적인 도면이다. 도 7은 로봇 팔의 동작을 설명하기 위한 도면이다. 도 8은 로봇 팔의 동작을 설명하기 위한 도면이다. 도 9는 본 발명의 일 실시예에 따른 스마트 팩토리 제어 장치의 동작을 설명하기 위한 흐름도이다. 도 10은 본 발명의 일 실시예에 따른 로봇 팔의 행동개선 솔루션 제공 방법을 설명하기 위한 흐름도이다. 도 11은 본 발명의 일 실시예에 따른 사전처리부의 이미지 데이터 처리 방법을 설명하기 위한 흐름도이다. 도 12는 본 발명의 다른 실시예에 따른 사전처리부의 이미지 데이터 처리 방법을 설명하기 위한 흐름도이다. 도 13은 본 발명의 일 실시예에 따른 멀티모달부의 이상 동작 센싱 방법을 설명하기 위한 흐름도이다."}
