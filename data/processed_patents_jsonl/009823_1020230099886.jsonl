{"patent_id": "10-2023-0099886", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0019210", "출원번호": "10-2023-0099886", "발명의 명칭": "이동 로봇 및 이동 로봇의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "류민우"}}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "본체(10);상기 본체에 마련되는 복수의 휠(20a, 20b, 20c, 20d);상기 본체에 마련되어 잔디를 커팅하는 블레이드(40);상기 본체의 전방을 향한 시야를 갖고 영상을 생성하는 광학 센서(S);사용자 입력을 획득하고, 이동 로봇의 동작에 관한 정보를 제공하는 사용자 인터페이스(70);상기 휠, 상기 블레이드, 상기 광학 센서 및 상기 사용자 인터페이스를 제어하는 제어부(200);를 포함하고,상기 제어부(200)는상기 본체가 이동하는 동안 획득되는 상기 영상에서 복수의 객체를 식별하고,상기 식별된 복수의 객체 중 미리 정해진 시간 동안 검출되는 객체를 오염물로 결정하고,상기 오염물의 특징과 상기 영상 내 상기 오염물의 위치에 기초하여 상기 광학 센서의 오염도를 결정하고,상기 광학 센서의 오염도에 대응하는 정보를 상기 사용자 인터페이스를 통해 제공하고,상기 광학 센서의 오염도에 기초하여 이동 로봇의 동작 모드를 결정하는 이동 로봇."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제어부는상기 광학 센서의 오염도가 임계 레벨보다 낮은 것에 기초하여, 상기 사용자 인터페이스를 통해 상기 광학 센서의 오염 발생을 알리기 위한 오염 알림을 제공하고, 상기 이동 로봇의 동작 모드를 정상 모드로 결정하는 이동로봇."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제어부는상기 광학 센서의 오염도가 임계 레벨보다 높거나 같은 것에 기초하여, 상기 사용자 인터페이스를 통해 주행의위험을 알리기 위한 위험 알림을 제공하고, 상기 이동 로봇의 동작 모드를 대기 모드 또는 클리닝 모드로 결정하는 이동 로봇."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제어부는상기 사용자 인터페이스를 통해 입력되는 동작 지속 명령에 기초하여, 상기 이동 로봇의 동작 모드를 상기 대기모드 또는 상기 클리닝 모드에서 정상 모드로 변경하고, 상기 임계 레벨을 상기 결정된 광학 센서의 오염도보다높게 변경하는 이동 로봇."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,공개특허 10-2025-0019210-3-상기 제어부는상기 영상에서 상기 오염물로 결정된 상기 객체가 식별되지 않는 것에 기초하여, 상기 사용자 인터페이스를 통해 오염 제거 알림을 제공하고, 상기 이동 로봇의 동작 모드를 정상 모드로 결정하는 이동 로봇."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제어부는미리 정해진 기준선에 기초하여 상기 영상을 복수의 영역으로 나누고,상기 복수의 영역 중 상기 오염물이 위치하는 영역에 따라 상기 광학 센서의 오염도를 다르게 결정하는 이동 로봇."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 제어부는상기 영상의 중앙 영역에 가장 큰 제1 가중치를 적용하고,상기 영상의 좌측 영역과 우측 영역에 상기 제1 가중치보다 작은 제2 가중치를 적용하고,상기 영상의 상부 영역과 하부 영역에 상기 제2 가중치보다 작은 제3 가중치를 적용하며,상기 오염물이 위치하는 영역의 가중치가 클수록, 상기 광학 센서의 오염도를 높게 결정하는 이동 로봇."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 오염물의 특징은상기 오염물의 크기 및 상기 오염물의 투명도 중 적어도 하나를 포함하고,상기 제어부는상기 오염물의 크기가 클수록 또는 상기 오염물의 투명도가 낮을수록, 상기 광학 센서의 오염도를 높게 결정하는 이동 로봇."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 광학 센서는컬러 영상을 생성하는 제1 광학 센서; 및대상까지의 거리 정보를 포함하는 깊이 영상을 생성하는 제2 광학 센서;를 포함하고,상기 제어부는상기 제1 광학 센서의 상기 컬러 영상과 상기 제2 광학 센서의 상기 깊이 영상 모두에서 상기 객체가 동일하게검출되는 것에 기초하여, 상기 객체를 오염물이 아닌 외부 물체로 결정하는 이동 로봇."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 제어부는상기 광학 센서의 오염도에 대응하는 시각 정보 또는 청각 정보 중 적어도 하나를 상기 사용자 인터페이스를 통해 제공하는 이동 로봇.공개특허 10-2025-0019210-4-청구항 11 제1항에 있어서,외부 장치와 통신하는 통신부;를 더 포함하고,상기 제어부는사용자 기기에서 상기 광학 센서의 오염도에 대응하는 상기 정보가 표시되도록, 상기 정보를 상기 통신부를 통해 상기 사용자 기기로 전송하는 이동 로봇."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "본체, 상기 본체에 마련되어 잔디를 커팅하는 블레이드, 상기 본체의 전방을 향한 시야를 갖고 영상을 생성하는광학 센서 및 사용자 인터페이스를 포함하는 이동 로봇의 제어 방법에 있어서,상기 이동 로봇이 이동하는 동안 광학 센서에 의해 획득되는 영상에서 복수의 객체를 검출하고;상기 복수의 객체 중 미리 정해진 시간 동안 검출되는 객체를 오염물로 결정하고;상기 오염물의 특징과 상기 영상 내 상기 오염물의 위치에 기초하여 상기 광학 센서의 오염도를 결정하고;상기 광학 센서의 오염도에 대응하는 정보를 상기 사용자 인터페이스를 통해 제공하고;상기 광학 센서의 오염도에 기초하여 상기 이동 로봇의 동작 모드를 결정하는 것;을 포함하는 이동 로봇의 제어방법."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 광학 센서의 오염도가 임계 레벨보다 낮은 것에 기초하여,상기 광학 센서의 오염도에 대응하는 정보는 상기 광학 센서의 오염 발생을 알리기 위한 오염 알림으로 제공되고, 상기 이동 로봇의 동작 모드는 정상 모드로 결정되는, 이동 로봇의 제어 방법."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 광학 센서의 오염도가 임계 레벨보다 높거나 같은 것에 기초하여,상기 광학 센서의 오염도에 대응하는 정보는 주행의 위험을 알리기 위한 위험 알림으로 제공되고, 상기 이동 로봇의 동작 모드는 대기 모드 또는 클리닝 모드로 결정되는, 이동 로봇의 제어 방법."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 사용자 인터페이스를 통해 입력되는 동작 지속 명령에 기초하여, 상기 이동 로봇의 동작 모드를 상기 대기모드 또는 상기 클리닝 모드에서 정상 모드로 변경하고, 상기 임계 레벨을 상기 결정된 광학 센서의 오염도보다높게 변경하는 것;을 더 포함하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 영상에서 상기 오염물로 결정된 상기 객체가 식별되지 않는 것에 기초하여, 상기 광학 센서의 오염도에 대응하는 정보는 오염 제거 알림으로 제공되고, 상기 이동 로봇의 동작 모드는 정상 모드로 결정되는, 이동 로봇의 제어 방법."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,공개특허 10-2025-0019210-5-상기 광학 센서의 오염도를 결정하는 것은,미리 정해진 기준선에 기초하여 상기 영상을 복수의 영역으로 나누고;상기 복수의 영역 중 상기 객체가 위치하는 영역에 따라 상기 광학 센서의 오염도를 다르게 결정하는 것;을 포함하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 광학 센서의 오염도를 결정하는 것은,상기 영상의 중앙 영역에 가장 큰 제1 가중치를 적용하고;상기 영상의 좌측 영역과 우측 영역에 상기 제1 가중치보다 작은 제2 가중치를 적용하고;상기 영상의 상부 영역과 하부 영역에 상기 제2 가중치보다 작은 제3 가중치를 적용하며;상기 오염물이 위치하는 영역의 가중치가 클수록, 상기 광학 센서의 오염도를 높게 결정하는 것;을 포함하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서, 상기 오염물의 특징은상기 오염물의 크기 및 상기 오염물의 투명도 중 적어도 하나를 포함하고,상기 광학 센서의 오염도를 결정하는 것은,상기 오염물의 크기가 클수록 또는 상기 오염물의 투명도가 낮을수록, 상기 광학 센서의 오염도를 높게 결정하는 것;을 포함하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2023-0099886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항에 있어서,상기 광학 센서는컬러 영상을 생성하는 제1 광학 센서; 및대상까지의 거리 정보를 포함하는 깊이 영상을 생성하는 제2 광학 센서;를 포함하고,상기 제1 광학 센서의 상기 컬러 영상과 상기 제2 광학 센서의 상기 깊이 영상 모두에서 상기 객체가 동일하게검출되는 것에 기초하여, 상기 객체를 오염물이 아닌 외부 물체로 결정하는 것;을 더 포함하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2023-0099886", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "개시된 이동 로봇은 본체, 상기 본체에 마련되는 복수의 휠, 상기 본체에 마련되어 잔디를 커팅하는 블레이드, 상기 본체의 전방을 향한 시야를 갖고 영상을 생성하는 광학 센서, 사용자 입력을 획득하고 이동 로봇의 동작에 관한 정보를 제공하는 사용자 인터페이스, 및 제어부를 포함한다. 상기 제어부는 상기 본체가 이동하는 동안 획 득되는 상기 영상에서 복수의 객체를 식별하고, 상기 식별된 복수의 객체 중 미리 정해진 시간 동안 검출되는 객 체를 오염물로 결정하고, 상기 오염물의 특징과 상기 영상 내 상기 오염물의 위치에 기초하여 상기 광학 센서의 오염도를 결정하고, 상기 광학 센서의 오염도에 대응하는 정보를 상기 사용자 인터페이스를 통해 제공하고, 상기 광학 센서의 오염도에 기초하여 이동 로봇의 동작 모드를 결정한다."}
{"patent_id": "10-2023-0099886", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 발명은 작업 영역을 이동하면서 작업 영역의 잔디를 커팅하고 잔디 관리가 완료되면 충전 스테이션에 도 킹하는 이동 로봇 및 이동 로봇의 제어 방법에 관한 것이다."}
{"patent_id": "10-2023-0099886", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 산업용으로 개발되어 공장 자동화의 일 부분을 담당하여 왔다. 최근에는 로봇을 응용한 분야가 더욱 확 대되어, 의료용 로봇, 우주 항공 로봇 및 서비스용 로봇 등이 개발되었고, 일반 가정에서 사용할 수 있는 가정 용 로봇도 개발되었다. 이러한 로봇 중에서 자력으로 주행이 가능한 로봇을 이동 로봇이라고 한다. 이동 로봇의 대표적 예로, 가정의 야외 환경이나, 골프장 및 운동장에서 잔디를 깎고 다듬을 수 있는 잔디 깎이 로봇이 있다. 이동 로봇은 휠과 블레이드를 포함하고, 휠을 회전시켜 작업 영역을 주행하면서 블레이드를 회전시켜 잔디의 윗부분을 커팅할 수 있다. 이와 같이 야외에서 사용되는 이동 로봇은, 실내에서 사용되는 이동 로봇과 달리, 외부의 환경 요인으로 인한 이동 로봇의 오염과 물리적 손상에 취약하다. 예를 들면, 이동 로봇에 포함된 광학 센서가 쉽게 오염될 수 있다. 광학 센서가 오염되면 이동 로봇이 전방의 물체를 잘못 식별하거나 장애물을 식별할 수 없게 될 수 있으 며, 그에 따라 이동 로봇이 잘못 동작할 수 있다. 개시된 발명은 외부 환경에 노출되는 광학 센서의 오염을 감지할 수 있고, 광학 센서에 오염에 대응하는 적절한 조치를 취할 수 있는 이동 로봇, 이동 로봇의 제어 방법 및 시스템을 제공한다. 일 실시예에 따른 이동 로봇은, 본체, 상기 본체에 마련되는 복수의 휠, 상기 본체에 마련되어 잔디를 커팅하는 블레이드, 상기 본체의 전방을 향한 시야를 갖고 영상을 생성하는 광학 센서, 사용자 입력을 획득하고 이동 로 봇의 동작에 관한 정보를 제공하는 사용자 인터페이스, 및 제어부를 포함한다. 상기 제어부는 상기 본체가 이동 하는 동안 획득되는 상기 영상에서 복수의 객체를 식별할 수 있다. 상기 제어부는 상기 식별된 복수의 객체 중 미리 정해진 시간 동안 검출되는 객체를 오염물로 결정할 수 있다. 상기 제어부는 상기 오염물의 특징과 상기 영상 내 상기 오염물의 위치에 기초하여 상기 광학 센서의 오염도를 결정할 수 있다. 상기 제어부는 상기 광학 센서의 오염도에 대응하는 정보를 상기 사용자 인터페이스를 통해 제공할 수 있다. 상기 제어부는 상기 광학 센 서의 오염도에 기초하여 이동 로봇의 동작 모드를 결정할 수 있다. 일 실시예에 따른 이동 로봇의 제어 방법은, 상기 이동 로봇이 이동하는 동안 광학 센서에 의해 획득되는 영상 에서 복수의 객체를 검출하고; 상기 복수의 객체 중 미리 정해진 시간 동안 지속적으로 검출되는 객체를 오염물 로 결정하고; 상기 오염물의 특징과 상기 영상 내 상기 오염물의 위치에 기초하여 상기 광학 센서의 오염도를 결정하고; 상기 광학 센서의 오염도에 대응하는 정보를 상기 사용자 인터페이스를 통해 제공하고; 상기 광학 센 서의 오염도에 기초하여 상기 이동 로봇의 동작 모드를 결정하는 것;을 포함한다. 일 실시예에 따른 시스템은, 시스템은 이동 로봇, 서버 및 충전 스테이션을 포함할 수 있다. 시스 템은 사용자 기기를 더 포함할 수 있다. 개시된 이동 로봇, 이동 로봇의 제어 방법 및 시스템은, 외부 환경에 노출되는 광학 센서의 오염을 감지할 수 있고, 광학 센서에 오염에 대응하는 적절한 조치를 취할 수 있다. 따라서 광학 센서의 오염에 따른 이동 로봇의 잘못된 동작과 사고가 예방될 수 있다."}
{"patent_id": "10-2023-0099886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 문서의 다양한 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한 정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 아이템 한 개 또는 복 수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제1\", \"제2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하 기 위해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제1) 구성요소가 다른(예: 제2) 구성요소에, \"기능적으로\" 또는 \"통신적으로\"라는 용어와 함께 또는 이런 용어 없이, \"커플드\" 또는 \"커넥티드\"라고 언급된 경우, 그것은 어떤 구성요소가 다른 구성요소에 직접적 으로(예: 유선으로), 무선으로, 또는 제3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. “포함하다” 또는 \"가지다\"등의 용어는 본 문서에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는다. 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\", \"지지\" 또는 \"접촉\"되어 있다고 할 때, 이는 구성요소들이 직접적으로 연결, 결합, 지지 또는 접촉되는 경우 뿐 아니라, 제3 구성요소를 통하여 간접적으로 연결, 결합, 지지 또는 접촉되는 경우를 포함한다. 어떤 구성요소가 다른 구성요소 \"상에\" 위치하고 있다고 할 때, 이는 어떤 구성요소가 다른 구성요소에 접해 있 는 경우 뿐 아니라 두 구성요소 사이에 또 다른 구성요소가 존재하는 경우도 포함한다. “및/또는\"이라는 용어는 복수의 관련된 기재된 구성요소들의 조합 또는 복수의 관련된 기재된 구성요소들 중의 어느 구성요소를 포함한다. 이하 첨부된 도면들을 참고하여 본 발명의 작용 원리 및 실시예에 대해 설명한다. 도 1은 일 실시예에 따른 이동 로봇을 포함하는 시스템을 도시한다. 도 1을 참조하면, 일 실시예에 따른 시스템은 이동 로봇, 사용자 기기, 서버 및 충전 스테이션 을 포함할 수 있다. 이동 로봇은, 사용자 기기, 서버 또는 충전 스테이션과 통신할 수 있는 통신 모듈, 사용자 입력을 수신하거나 사용자에게 정보를 출력하는 사용자 인터페이스, 이동 로봇의 동작을 제어하는 적어도 하나의 프 로세서 및 이동 로봇의 동작을 제어하기 위한 프로그램이 저장된 적어도 하나의 메모리를 포함할 수 있다. 서버는 이동 로봇, 다른 서버, 사용자 기기 또는 충전 스테이션과 통신할 수 있는 통신 모듈을 포 함할 수 있다. 서버는 이동 로봇, 다른 서버, 사용자 기기 또는 충전 스테이션로부터 수신된 데이 터를 처리할 수 있는 적어도 하나의 프로세서 및 데이터를 처리하기 위한 프로그램 또는 처리된 데이터를 저장 할 수 있는 적어도 하나의 메모리를 포함할 수 있다. 서버는 워크스테이션(workstation), 클라우드(cloud), 데이터 드라이브(data drive), 데이터 스테이션(data station) 등 다양한 컴퓨팅 디바이스로 구현될 수 있다. 서버는 기능, 기능의 세부 구성 또는 데이터 등을 기준으로 물리적 또는 논리적으로 구분된 하나 이상의 서버로 구현될 수 있으며, 각 서버 간의 통신을 통해 데이터를 송수신하고 송수신된 데이터를 처리할 수 있다. 서버는 사용자 계정을 관리하고, 사용자 계정에 결부시켜 이동 로봇을 등록하고, 등록된 이동 로봇을 관리하거나 제어하는 등의 기능을 수행할 수 있다. 예를 들어, 사용자는 사용자 기기를 통해 서버에 접속 하여, 사용자 계정을 생성할 수 있다. 사용자 계정은 사용자에 의해 설정된 아이디와 비밀번호에 의해 식별될 수 있다. 서버는 정해진 절차에 따라 이동 로봇을 사용자 계정에 등록할 수 있다. 예를 들어, 서버는 이동 로봇의 식별 정보(예: 시리얼 넘버 또는 맥 주소(MAC address) 등)를 사용자 계정에 연결하여, 이동 로 봇을 등록, 관리, 제어할 수 있다. 사용자 기기는 이동 로봇, 서버 또는 충전 스테이션과 통신할 수 있는 통신 모듈을 포함할 수 있다. 사용자 기기는 사용자 입력을 수신하거나 사용자에게 정보를 출력하는 사용자 인터페이스를 포함할 수 있다. 사용자 기기는 사용자 기기의 동작을 제어하는 적어도 하나의 프로세서 및 사용자 기기의 동작 을 제어하기 위한 프로그램이 저장된 적어도 하나의 메모리를 포함할 수 있다. 사용자 기기는 사용자가 휴대하거나, 사용자의 가정 또는 사무실 등에 배치될 수 있다. 사용자 기기는 퍼 스널 컴퓨터(personal computer), 단말기(terminal), 휴대폰(portable telephone), 스마트 폰(smart phone), 휴대 장치(handheld device), 착용 장치(wearable device), 디스플레이 장치 등을 포함할 수 있으나, 이에 한 정되는 것은 아니다. 사용자 기기의 메모리에는 이동 로봇을 제어하기 위한 프로그램, 즉 어플리케이션이 저장될 수 있다. 어 플리케이션은 사용자 기기에 설치된 상태로 판매되거나, 외부 서버로부터 다운로드 받아 설치될 수 있다. 사용자가 사용자 기기에 설치된 어플리케이션을 실행함으로써 서버에 접속하여 사용자 계정을 생성하고, 로그인된 사용자 계정을 기반으로 서버와 통신을 수행하여 이동 로봇을 등록할 수 있다. 예를 들어, 사용자 기기에 설치된 어플리케이션에서 안내하는 절차에 따라 이동 로봇이 서버에 접속될 수 있도록 이동 로봇을 조작하면, 서버에서 해당 사용자 계정에 이동 로봇의 식별 정보(예: 시리얼 넘 버 또는 맥 주소(MAC address) 등)를 등재함으로써, 사용자 계정에 이동 로봇을 등록할 수 있다. 사용자는 사용자 기기에 설치된 어플리케이션을 이용하여 이동 로봇을 제어할 수 있다. 예를 들어, 사용 자가 사용자 기기에 설치된 어플리케이션으로 사용자 계정에 로그인하면, 사용자 계정에 등록된 이동 로봇 이 나타나고, 이동 로봇에 대한 제어 명령을 입력하면 서버를 통해 이동 로봇에 제어 명령을 전달 할 수 있다. 네트워크는 유선 네트워크와 무선 네트워크를 모두 포함할 수 있다. 유선 네트워크는 케이블 네트워크 또는 전 화 네트워크 등을 포함하며, 무선 네트워크는 전파를 통하여 신호를 송수신하는 모든 네트워크를 포함할 수 있 다. 유선 네트워크와 무선 네트워크는 서로 연결될 수 있다. 네트워크는 인터넷 등의 광역 네트워크(wide area network, WAN)와 접속 중계기(Access Point, AP)를 중심으로 형성된 지역 네트워크(local area network, LAN), 접속 중계기(AP)를 통하지 않는 근거리 무선 네트워크를 포함 할 수 있다. 근거리 무선 네트워크는 블루투스(Bluetooth쪠, IEEE 802.15.1), 지그비(Zigbee, IEEE 802.15.4), 와이파이 다이렉트(Wi-Fi Direct), NFC(Near Field Communication), 지-웨이브(Z-Wave) 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 접속 중계기(AP)는 이동 로봇, 사용자 기기 또는 충전 스테이션을 서버가 연결된 광역 네트워크 (WAN)에 연결시킬 수 있다. 이동 로봇, 사용자 기기 또는 충전 스테이션은 광역 네트워크(WAN)를 통해 서버에 연결될 수 있다. 접속 중계기(AP)는 와이파이(Wi-Fi쪠, IEEE 802.11), 블루투스(Bluetooth쪠, IEEE 802.15.1), 지그비(Zigbee, IEEE 802.15.4) 등의 무선 통신을 이용하여 이동 로봇, 사용자 기기 또는 충전 스테이션과 통신하고, 유선 통신을 이용하여 광역 네트워크(WAN)에 접속할 수 있으나, 이에 한정되는 것은 아니다. 다양한 실시예에 따라, 이동 로봇은 접속 중계기(AP)를 통하지 않고 사용자 기기, 서버 또는 충전 스 테이션과 직접 연결될 수도 있다. 이동 로봇은 원거리 무선 네트워크 또는 근거리 무선 네트워크를 통해 사용자 기기, 서버 또는 충전 스테이션과 연결될 수 있다. 예를 들어, 이동 로봇은 근거리 무선 네트워크(예: 와이파이 다이렉트)를 통해 사용자 기기와 연결될 수 있다. 또 다른 예로, 이동 로봇은 원거리 무선 네트워크(예: 셀룰러 통신 모듈)를 이용하여 광역 네트워크(WAN)를 통해 사용자 기기, 서버 또는 충전 스테이션과 연결될 수 있다. 또 다른 예로, 이동 로봇은 유선 통신을 이용하여 광역 네트워크(WAN)에 접속하고, 광역 네트워크(WAN)를 통 해 사용자 기기, 서버 또는 충전 스테이션과 연결될 수 있다. 이동 로봇이 유선 통신을 이용하여 광역 네트워크(WAN)에 접속할 수 있는 경우, 접속 중계기로서 동작할 수도 있다. 이동 로봇은 네트워크를 통하여 동작 또는 상태에 관한 정보를 사용자 기기, 서버 또는 충전 스테이션 에 전송할 수 있다. 예를 들어, 이동 로봇은 서버로부터 요청이 수신되는 경우, 이동 로봇에서 특 정 이벤트가 발생한 경우, 또는 주기적으로 또는 실시간으로 동작 또는 상태에 관한 정보를 사용자 기기, 서 버 또는 충전 스테이션에 전송할 수 있다. 서버는 이동 로봇으로부터 동작 또는 상태에 관한 정보가 수신되면 저장되어 있던 이동 로봇의 동작 또는 상태에 관한 정보를 업데이트하고, 네트워크를 통하여 사용자 기기에 이동 로봇의 동작 및 상태에 관한 업데이트된 정보를 전송할 수 있다. 여기서, 정보의 업데이트란 기존 정보에 새로운 정보를 추가하는 동작, 기존 정보를 새로운 정보로 대체하는 동작 등 기존 정보가 변경되는 다양한 동작을 포함할 수 있다. 이동 로봇은 사용자 기기, 서버 또는 충전 스테이션으로부터 다양한 정보를 획득하고, 획득된 정보 를 사용자에게 제공할 수 있다. 예를 들어, 이동 로봇은 서버로부터 이동 로봇의 기능과 관련된 정보, 다양한 환경 정보(예를 들어, 날씨, 온도, 습도 등)의 정보를 획득하고, 사용자 인터페이스를 통해 획득된 정보 를 출력할 수 있다. 이동 로봇은 사용자 기기, 서버 또는 충전 스테이션로부터 수신되는 제어 명령에 따라 동작할 수 있다. 예를 들어, 이동 로봇은 사용자 입력이 없더라도 서버의 제어 명령에 따라 동작할 수 있도록 사용 자의 사전 승인을 획득한 경우, 이동 로봇은 서버로부터 수신되는 제어 명령에 따라 동작할 수 있다. 여 기서, 서버로부터 수신되는 제어 명령은 사용자가 사용자 기기를 통해 입력한 제어 명령 또는 기 설정된 조건에 기초한 제어 명령 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 사용자 기기는 통신 모듈을 통해 사용자에 관한 정보를 이동 로봇, 서버 또는 충전 스테이션에 전 송할 수 있다. 예를 들어, 사용자 기기는 사용자의 위치, 사용자의 건강 상태, 사용자의 취향, 사용자의 일 정 등에 관한 정보를 서버에 전송할 수 있다. 사용자 기기는 사용자의 사전 승인에 따라 사용자에 관한 정보를 서버에 전송할 수 있다. 이동 로봇, 사용자 기기, 서버 또는 충전 스테이션은 인공 지능 등의 기술을 이용하여 제어 명령을 결정할 수 있다. 예를 들어, 서버는 이동 로봇의 동작 또는 상태에 관한 정보와 사용자 기기의 사용자 에 관한 정보를 인공지능 기술을 이용하여 처리하고, 처리 결과에 기초하여 이동 로봇 또는 사용자 기기 에 처리 결과 또는 제어 명령을 전송할 수 있다. 이동 로봇은 자율 주행이 가능한 로봇을 포함할 수 있다. 이하에서 이동 로봇은 잔디를 커팅하기 위한 로 봇으로 예시된다. 도 2는 일 실시예에 따른 시스템에 포함된 이동 로봇, 충전 스테이션 및 비콘을 도시한다. 도 2를 참조하면, 이동 로봇은 잔디밭을 이동할 수 있다. 잔디밭은 이동 로봇의 작업 영역(P)이라 할 수 있다. 작업 영역(P)의 각 경계 영역에는 비콘과 충전 스테이션이 배치될 수 있다. 일 실시예에 따른 시스 템은 비콘을 더 포함할 수 있다. 작업 영역은 복수의 비콘 및 충전 스테이션에 의해 다각형의 형상으로 형성될 수 있다. 예를 들어, 도시 된 바와 같이, 3개의 비콘 및 충전 스테이션에 의해 작업 영역(P)은 사각 형상으로 형성될 수 있다. 다른 예로, 4개의 비콘 및 충전 스테이션에 의해 작업 영역(P)은 오각 형상으로 형성될 수 있다. 이처럼, 작업 영역은 다양한 형상일 수 있고, 작업 영역의 형상은 비콘의 개수에 의해 달라질 수 있다. 이동 로봇은 복수의 비콘 및 충전 스테이션과 통신을 수행할 수 있다. 이동 로봇은 복수의 비콘 중 적어도 하나로부터 신호를 수신할 수 있고, 복수의 비콘 중 적어도 하나에 신호를 전송할 수 있다. 이동 로봇은 충전 스테이션으로부터 신호를 수신할 수 있고, 충전 스테이션에 신호를 전송할 수 있다. 적어도 하나의 비콘이 생성하는 신호는 초광대역(UWB: Ultra Wideband) 통신 신호일 수 있으며, 적어도 하나 의 비콘이 이동 로봇에 송신하는 신호에는 적어도 하나의 비콘의 위치 정보가 포함되어 있을 수 있다. 충전 스테이션이 생성하는 신호는 초광대역(UWB: Ultra Wideband) 통신 신호일 수 있다. 충전 스테이션이이동 로봇에 송신하는 신호에는 충전 스테이션의 위치 정보가 포함되어 있을 수 있다. 복수의 비콘은 서로 통신을 수행할 수 있고 충전 스테이션과도 통신을 수행할 수 있다. 각 비콘과 충 전 스테이션은 서로 간 상대 좌표를 획득할 수 있고, 이동 로봇과의 UWB 통신 거리를 측정할 수 있다. 각 비콘 및 충전 스테이션은 상대 좌표계 내에서 이동 로봇의 위치를 삼각 측량법을 통해 획득할 수 있다. 이동 로봇은 복수의 지점 각각에 배치된 비콘에서 트리거 된 신호의 방향 및 신호의 전송 거리를 측정할 수 있으며, 측정한 신호의 방향 및 거리에 기초하여 작업 영역(P) 내에서의 이동 로봇의 현재 위치 정보를 획득할 수 있다. 또한, 이동 로봇은 충전 스테이션에서 트리거 된 신호의 방향 및 신호의 전송 거리를 측 정할 수 있으며, 측정한 신호의 방향 및 거리에 기초하여 작업 영역(P) 내에서의 이동 로봇의 현재 위치 정 보를 획득할 수도 있다. 이동 로봇은 이동 로봇의 현재 위치 정보를 획득하는 별도의 위치 센서를 포함할 수 있다. 예를 들면, 위 치 센서는 GPS(Global Positioning System) 수신기를 포함할 수 있다. 이동 로봇은 충전 스테이션과 비콘으로부터 전송되는 신호에 기초하여 작업 영역(P)의 경계를 설정할 수 있다. 충전 스테이션도 작업 영역(P)의 경계를 설정할 수 있다. 이동 로봇은 설정된 작업 영역(P) 내 에서 주행할 수 있다. 도 3은 일 실시예에 따른 이동 로봇의 사시도이다. 도 4는 일 실시예에 따른 이동 로봇의 아래에서 바라본 평면 도이다. 도 5는 도 3에 도시된 이동 로봇을 상하 방향으로 자른 단면의 일 예를 도시한다. 전방, 후방, 상방, 하방, 좌측 및 우측과 같은 용어는 이동 로봇의 전진 이동 방향을 기준으로 정의되는 것 이며, 이 용어에 의하여 각 구성요소의 형상 및 위치가 제한되는 것은 아니다. 또한, 방향을 지칭하는 표현은 본 발명이 명확하게 이해될 수 있도록 사용되는 것이며, 각 방향은 다르게 정의될 수도 있다. 도 3, 도 4 및 도 5를 참조하면, 이동 로봇은 본체와, 지면과 수평인 축을 중심으로 회전 가능하게 마련 되고 본체를 이동시키는 복수의 휠(20a, 20b, 20c, 20d)을 포함할 수 있다. 본체는 외형을 형성하는 케 이스를 포함할 수 있다. 복수의 휠(20a, 20b, 20c, 20d)은 제1 구동 휠(20a), 제2 구동 휠(20b), 제1 보조 휠 (20c) 및 제2 보조 휠(20d)을 포함할 수 있다. 제1 구동 휠(20a)은 본체의 우측 후방에 마련될 수 있다. 제2 구동 휠(20b)은 본체의 좌측 후방에 마련 될 수 있다. 제1 보조 휠(20c)은 본체의 우측 전방에 마련될 수 있다. 제2 보조 휠(20d)은 본체의 우측 전방에 마련될 수 있다. 제1 구동 휠(20a)은 제1 휠 모터(30a)와 연결된다. 제1 휠 모터(30a)는 제1 구동 휠(20a)을 회전시키기 위한 회 전력을 생성할 수 있다. 제2 구동 휠(20b)은 제2 휠 모터(30b)와 연결된다. 제2 휠 모터(30b)는 제2 구동 휠 (20b)을 회전시키기 위한 회전력을 생성할 수 있다. 제1 휠 모터(30a)와 제2 휠 모터(30b) 각각의 회전 속도에 따라 제1 구동 휠(20a)과 제2 구동 휠(20b) 각각의 회전 속도가 조절될 수 있다. 본체의 전방에는 광학 센서(S)가 마련될 수 있다. 광학 센서(S)는 본체의 전방을 향한 시야(Field Of View, FOV)를 갖고 영상을 생성할 수 있다. 광학 센서(S)의 위치는 본체의 전방으로 한정되지 않는다. 광학 센서(S)는 이동 로봇의 주변을 촬영할 수 있는 다양한 위치에 마련될 수 있다. 광학 센서(S)는 본체의 측방 및/또는 후방에 마련될 수도 있다. 광학 센서(S)는 외부로부터 입사되는 광을 수집하여 영상 데이터를 생성하는 다양한 센서를 포함할 수 있다. 예 를 들면, 광학 센서(S)는 컬러 영상을 생성하는 제1 광학 센서(S1) 및 대상까지의 거리 정보를 포함하는 깊이 영상을 생성하는 제2 광학 센서(S2) 중 적어도 하나를 포함할 수 있다. 제1 광학 센서(S1)는 가시광선을 수집하여 컬러 영상을 생성하는 RGB 카메라를 포함할 수 있다. 제2 광학 센서 (S2)는 양안 카메라 또는 스테레오 카메라를 포함할 수 있다. 제2 광학 센서(S2)는 양안의 차이(Disparity)를 이용하여 대상까지의 깊이 정보를 획득할 수 있다. 제2 광학 센서(S2)는 양안을 갖는 적외선 카메라를 포함할 수 있다. 제1 광학 센서(S1)의 제1 시야(FOV)와 제2 광학 센서(S2)의 제2 시야는 상이할 수 있다. 광학 센서(S)는 예시된 것으로 한정되지 않는다. 예를 들면, 광학 센서(S)는 라이다(Light detection and Ranging, Lidar) 센서, ToF(Time-of-Flight) 센서, RGB-D 카메라와 같은 다양한 센서를 포함할 수 있다. 본체의 상면 일부에는 사용자 인터페이스가 마련될 수 있다. 도 2에서는 사용자 인터페이스가 본체 의 후방 상면에 마련되는 것으로 예시되어 있으나, 이에 한정되지 않는다. 사용자 인터페이스는 사용자 입력을 획득할 수 있다. 사용자 인터페이스는 이동 로봇의 동작에 관한 다양한 정보를 제공할 수 있다. 후술되는 바와 같이, 사용자 인터페이스는 디스플레이, 스피커, 인디케이터 및 입력부를 포함할 수 있다. 이동 로봇은 잔디를 커팅하는 블레이드를 포함할 수 있다. 블레이드는 원형의 팬 형상으로 마련될 수 있다. 블레이드는 본체의 하부에 마련될 수 있고, 지면과 수직인 축을 중심으로 회전할 수 있다. 블 레이드는 블레이드 모터(40a)와 연결된다. 블레이드 모터(40a)는 블레이드를 회전시키기 위한 회전력을 생성할 수 있다. 블레이드 모터(40a)의 회전축은 휠 모터의 회전축과 수직일 수 있다. 블레이드는 본체의 상하 방향을 따라 이동할 수 있다. 블레이드는 지면(GND)으로부터 이격될 수 있 다. 블레이드가 상하 방향으로 이동함에 따라 지면(GND)과 블레이드 간 간격이 조절될 수 있다. 블레이 드의 상하 이동에 따라 잘려지는 잔디의 높이가 조절될 수 있다. 본체의 전면에는 배터리의 충전에 사용되는 충전 단자가 마련될 수 있다. 이동 로봇의 충전 단 자는 충전 스테이션의 충전기와 연결될 수 있다. 이동 로봇이 충전 스테이션에 도킹 되면, 충전 단자는 충전 스테이션의 충전기와 전기적으로 연결될 수 있고, 충전기로부터 공급되는 전력에 의해 이동 로봇의 배터리가 충전될 수 있다. 배터리는 이동 로봇에 포함된 다양한 전자 부품에 전력을 공급할 수 있다. 도 6은 일 실시예에 따른 충전 스테이션을 더 상세히 도시한다. 도 7은 일 실시예에 따른 충전 스테이션의 제어 블록도이다. 도 6과 도 7을 참조하면, 충전 스테이션은 통신 모듈(4c)과 충전기를 포함할 수 있다. 또한, 충전 스테 이션은 브러시, 팬 및 히터 중 적어도 하나를 더 포함할 수 있다. 충전 스테이션의 제어 부는 프로세서와 메모리를 포함할 수 있다. 충전 스테이션은 통신 모듈(4c)을 통해 이동 로봇, 사용자 기기및/또는 비콘과 통신할 수 있다. 통 신 모듈(4c)은 다양한 무선 통신을 수행하기 위한 통신 회로를 포함할 수 있다. 예를 들면, 통신 모듈(4c)은 초 광대역 통신을 지원할 수 있다. 충전 스테이션은 하우징(4a)과, 하우징(4a)을 지지하는 지지대(4b)를 포함할 수 있다. 지지대(4b)는 이동 로 봇이 충전 스테이션에 도킹할 때 이동 로봇의 이동 경로를 제공할 수 있다. 이동 로봇은 지지대 (4b)를 따라 이동함으로써 정확한 충전 위치에 도달할 수 있다. 충전 스테이션은 이동 로봇의 배터리를 충전하기 위한 전력을 공급할 수 있다. 충전 스테이션은 상용 전원에 연결될 수 있고, 상용 전원으로부터 전력을 공급받으며, 공급된 전력의 변환을 수행한 후 변환된 전력을 이동 로봇에 제공할 수 있다. 이동 로봇이 충전 스테이션에 도킹 되면, 충전 스테이션은 상 용 전원을 이동 로봇의 배터리의 충전을 위한 전력으로 변환할 수 있다. 충전 스테이션은 이동 로봇의 광학 센서(S)에 부착된 오염물을 제거하기 위한 구조를 포함할 수 있다. 예 를 들면, 충전 스테이션은 이동 로봇의 도킹이 완료됨에 따라 이동 로봇의 광학 센서(S)에 접촉하게 되는 브러시를 포함할 수 있다. 충전 스테이션은 브러시를 회전시킬 수 있다. 회전하는 브러시 는 광학 센서(S)와 접촉하는 부분에 마찰력을 제공하고, 마찰력에 의해 광학 센서(S)에 부착된 오염물이 제거될 수 있다. 또한, 충전 스테이션은 바람을 생성하는 팬과 열을 생성하는 히터를 포함할 수 있다. 팬의 회전에 따라 생성되는 바람이 광학 센서(S)에 부착된 오염물을 제거할 수 있다. 히터에 의해 생성되는 열 도 광학 센서(S)에 부착된 오염물 제거에 도움이 될 수 있다. 팬과 히터가 함께 동작하면 이동 로봇 의 광학 센서(S)에 열풍이 공급될 수 있다. 도시되어 있지 않으나, 충전 스테이션의 하우징(4a)에는 이동 로봇의 도킹에 사용되는 마커가 마련될 수 있다. 마커는 이동 로봇의 광학 센서(S)의 오염을 판단하는데 사용될 수도 있다. 마커는 다양한 패턴(예를 들면, 격자 패턴, 체스 보드 패턴)을 가질 수 있다. 이동 로봇의 광학 센서(S)는 충전 스테이션의 마커를 촬영할 수 있다. 이동 로봇은 광학 센서(S)의 시야에 마커가 들어오면, 마커를 향해 이동할 수 있다. 광학 센서(S)에 의해 생성된 영상에서 마커가 불완전하게 식별되는 경우, 이동 로봇은 광학 센서(S)가 오염 된 것으로 판단할 수 있다. 또한, 이동 로봇은 광학 센서(S)에 의해 생성된 영상에서 식별되는 마커의 크기와 형상에 따라 광학 센서(S)의 오염도를 결정할 수도 있다. 광학 센서(S)의 오염도를 결정함에 있어서, 후술되 는 방법과 함께 충전 스테이션의 마커를 이용함으로써 오염도가 더 정확하게 판단될 수 있다. 충전 스테이션의 제어부는 충전 스테이션의 동작을 제어할 수 있다. 충전 스테이션의 프로세서 는 메모리에 저장된 데이터를 이용하여 충전 스테이션의 동작과 관련된 제어를 수행할 수 있다. 제어부는 이동 로봇과의 도킹을 위해 통신 모듈(4c)을 제어할 수 있다. 제어부는 이동 로봇에 포함된 배터리를 충전하기 위해 충전기를 제어할 수 있다. 제어부는 이동 로봇과 비콘으로 부터 전송되는 신호를 처리하여 작업 영역(P)의 경계를 설정할 수 있다. 또한, 제어부는 이동 로봇의 광학 센서(S)에 존재하는 오염물을 제거하기 위해 브러시, 팬 및 히터 중 적어도 하나를 동작시 킬 수 있다. 충전 스테이션의 구성요소는 예시된 것으로 제한되지 않는다. 설명된 구성요소들 중 일부가 생략되거나 다른 구성요소가 추가될 수도 있다. 또한, 충전 스테이션에 포함되는 구성요소의 배치 구조는 도면에 도시된 것으 로 제한되지 않는다. 도 8은 일 실시예에 따른 이동 로봇의 제어 블록도이다. 도 8을 참조하면, 이동 로봇은 휠 모터, 블레이드 모터(40a), 광학 센서(S), 배터리, 사용자 인터페 이스 및 제어부를 포함할 수 있다. 또한, 이동 로봇은 통신부를 더 포함할 수 있다. 이동 로봇 은 움직임 센서와 위치 센서를 추가적으로 포함할 수 있다. 제어부는 이동 로봇의 구성요소들을 제어할 수 있다. 제어부는 프로세서와 메모리를 포 함할 수 있다. 프로세서는 하드웨어로서, 논리 회로와 연산 회로를 포함할 수 있다. 프로세서는 이동 로봇의 동작을 위해 메모리에 저장된 프로그램, 인스트럭션 및/또는 데이터를 이용하여 전기적으로 연 결된 이동 로봇의 구성요소들을 제어할 수 있다. 제어부는 콘덴서, 인덕터 및 저항 소자와 같은 회로 소자를 포함하는 제어 회로로 구현될 수 있다. 프로세서와 메모리는 별도의 칩으로 구현되거나, 단일 의 칩으로 구현될 수 있다. 또한, 제어부는 복수의 프로세서와 복수의 메모리를 포함할 수 있다. 메모리는 이동 로봇의 동작을 위한 프로그램, 어플리케이션 및/또는 데이터를 저장할 수 있고, 프로세 서에 의해 생성되는 데이터를 저장할 수 있다. 메모리는 데이터를 장기간 저장하기 위한 롬(Read Only Memory), 플래시 메모리와 같은 비휘발성 메모리를 포함할 수 있다. 메모리는 데이터를 일시적으로 기억하기 위한 S-램(Static Random Access Memory, S-RAM), D-램(Dynamic Random Access Memory)과 같은 휘발 성 메모리를 포함할 수 있다. 휠 모터는 구동 휠(20a, 20b)을 회전시킬 수 있다. 휠 모터는 제1 휠 모터(30a)와 제2 휠 모터(30b)를 포함할 수 있다. 제1 휠 모터(30a)는 제1 구동 휠(20a)과 연결되고, 제1 휠 모터(30a)의 회전에 따라 제1 구동 휠(20a)이 회전할 수 있다. 제2 휠 모터(30b)는 제2 구동 휠(20b)과 연결되고, 제2 휠 모터(30b)의 회전에 따라 제2 구동 휠(20b)이 회전할 수 있다. 제1 구동 휠(20a)과 제2 구동 휠(20b)이 회전함으로써 이동 로봇이 주 행할 수 있다. 블레이드 모터(40a)는 블레이드와 연결될 수 있다. 블레이드 모터(40a)의 회전에 따라 블레이드가 회전 할 수 있다. 블레이드의 회전에 의해 지면으로부터 솟아난 잔디가 잘릴 수 있다. 블레이드 모터(40a)의 구 동축은 상하 방향으로 움직일 수 있다. 블레이드 모터(40a)의 구동축이 상하 방향으로 이동함으로써, 지면으로 부터 블레이드의 높이가 조절될 수 있고, 잘려지는 잔디의 높이가 달라질 수 있다. 광학 센서(S)는 본체의 전방을 향한 시야(Field Of View, FOV)를 갖고 영상을 생성할 수 있다. 영상은 미리 정해진 주기마다 획득된 복수의 이미지 프레임을 포함할 수 있다. 즉, 복수의 이미지 프레임이 시계열적으로 나 열됨으로써 동영상이 생성될 수 있다. 광학 센서(S)는 외부로부터 입사되는 광을 수집하여 영상을 생성할 수 있 다. 광학 센서(S)는 생성한 영상에 대응하는 영상 데이터 및/또는 영상 신호를 제어부에 전송할 수 있다. 예를 들면, 광학 센서(S)는 제1 광학 센서(S1) 및 제2 광학 센서(S2) 중 적어도 하나를 포함할 수 있다. 제1 광 학 센서(S1)는 가시광선을 수집하여 컬러 영상을 생성할 수 있다. 제1 광학 센서(S1)는 렌즈와 이미지 센서를 포함할 수 있다. 제2 광학 센서(S2)는 대상까지의 거리 정보를 포함하는 깊이 영상을 생성할 수 있다. 제2 광학 센서(S2)는 양안을 갖는 적외선 카메라를 포함할 수 있다. 제2 광학 센서(S2)는 2개의 렌즈와 2개의 이미지 센 서를 포함할 수 있다. 다시 말해, 제2 광학 센서(S2)는 좌안 카메라와 우안 카메라를 포함할 수 있다. 제2 광학 센서(S2)는 흑백 영상을 생성할 수 있다.본체에 제1 광학 센서(S1) 및 제2 광학 센서(S2)가 모두 마련되는 경우, 제1 광학 센서(S1)와 제2 광학 센 서(S2)는 하나의 모듈로 제공되거나 별개의 모듈로 제공될 수 있다. 제어부는 광학 센서(S)에 의해 획득된 영상에 기초하여 이동 로봇의 주행을 제어할 수 있다. 제어부 는 광학 센서(S)에 의해 획득된 영상을 분석하여 영상에 포함된 다양한 객체를 식별할 수 있다. 제어부 는 메모리 또는 서버로부터 획득되는 인공지능모델을 이용하여 영상으로부터 객체을 식별할 수 있 고, 객체의 특징을 식별할 수 있다. 예를 들면, 제어부는 영상으로부터 객체의 크기, 형상, 밝기, 선명도, 투명도, 위치 및/또는 색상을 식별할 수 있다. 또한, 제어부는 영상에 포함된 깊이 정보를 이용하여 객체 까지의 거리와 객체의 높이를 추정할 수 있다. 제어부는 영상 처리를 통해 이동 로봇의 주행 경로 상에 존재하는 장애물을 식별할 수 있고, 장애물을 회피하기 위해 휠 모터를 제어할 수 있다. 배터리는 이동 로봇에 포함된 다양한 전자 부품에 전력을 공급할 수 있다. 예를 들면, 배터리는 휠 모터, 블레이드 모터(40a), 광학 센서(S), 사용자 인터페이스, 통신부, 움직임 센서, 위치 센 서 및 제어부 각각에 전력을 공급할 수 있다. 배터리로부터 공급되는 전력은 제어부에 의해 변환된 후 각 전자 부품에 공급될 수도 있다. 이동 로봇이 충전 스테이션에 도킹하면, 배터리는 충전 스테이션의 충전기로부터 제공되는 충전 전력에 의해 충전될 수 있다. 사용자 인터페이스는 사용자 입력을 획득할 수 있다. 사용자 인터페이스는 이동 로봇의 동작에 관한 다양한 정보를 제공할 수 있다. 사용자 인터페이스는 디스플레이, 스피커, 인디케이터 및 입력 부를 포함할 수 있다. 디스플레이는 이동 로봇의 동작과 관련된 정보를 표시할 수 있다. 디스플레이는 사용자가 입력한 정 보 또는 사용자에게 제공되는 정보를 다양한 화면으로 표시할 수 있다. 디스플레이는 이동 로봇의 동작 과 관련된 정보를 이미지 또는 텍스트 중 적어도 하나로 표시할 수 있다. 예를 들면, 디스플레이는 광학 센 서(S)의 오염에 관한 이미지 또는 텍스트 중 적어도 하나를 표시할 수 있다. 디스플레이는 배터리 정보를 표시할 수 있다. 또한, 디스플레이는 이동 로봇의 제어를 가능하게 하는 그래픽 사용자 인터페이스(GUI, Graphic User Interface)를 표시할 수 있다. 즉, 디스플레이는 아이콘(Icon)과 같은 UI 엘리먼트(User Interface Element)를 표시할 수 있다. 디스플레이는 다양한 종류의 디스플레이 패널로 제공될 수 있다. 예를 들어, 디스플레이는 액정 디스플 레이 패널(Liquid Crystal Display Panel, LCD Panel), 발광 다이오드 패널(Light Emitting Diode Panel, LED Panel), 유기 발광 다이오드 패널(Organic Light Emitting Diode Panel, OLED Panel), 또는 마이크로 LED 패널 을 포함할 수 있다. 디스플레이는 입력 장치의 역할도 수행하는 터치 디스플레이를 포함할 수 있다. 스피커는 사용자가 입력한 정보 또는 사용자에게 제공되는 정보를 다양한 음향으로 출력할 수 있다. 예를 들면, 제어부는 이동 로봇의 동작 상태와 광학 센서(S)의 오염에 관한 다양한 사운드를 출력하도록 스 피커를 제어할 수 있다. 광학 센서(S)가 오염된 경우, 광학 센서(S)의 오염을 알리는 음성 메시지, 알림음 또는 경고음이 스피커를 통해 출력될 수 있다. 인디케이터는 이동 로봇의 다양한 상태를 알리기 위한 상태 표시등이다. 인디케이터는 다양한 색상 의 LED를 포함할 수 있다. 이동 로봇의 동작에 관한 특정 이벤트가 발생하는 경우, 특정 이벤트에 대응하는 적어도 하나의 인디케이터가 발광할 수 있다. 예를 들면, 광학 센서(S)의 오염이 발생한 경우, 광학 센서 (S)의 오염을 알리기 위해 인디케이터가 발광할 수 있다. 사용자는 발광하는 인디케이터를 통해 이동 로봇의 현재 상태를 쉽게 확인할 수 있다. 입력부는 사용자 입력을 획득할 수 있다. 사용자 입력은 다양한 명령을 포함할 수 있다. 예를 들면, 입력부 는, 전원 온 명령, 전원 오프 명령, 동작 시작 명령, 동작 중지 명령, 동작 지속 명령, 센서 청소 명령, 충 전 명령을 획득할 수 있다. 사용자 입력은 사용자 기기로부터 획득될 수도 있다. 입력부는 사용자 입력 에 대응하는 전기적 신호(전압 또는 전류)를 제어부로 전송할 수 있다. 입력부는 다양한 버튼 및/또는 다이얼을 포함할 수 있다. 예를 들면, 입력부는 이동 로봇의 전원을 온 또는 오프 하기 위한 전원 버튼, 잔디 커팅 동작을 시작 또는 정지하기 위한 시작/정지 버튼, 이동 로봇 을 충전 스테이션에 도킹시키기 위한 도킹 버튼 중 적어도 하나를 포함할 수 있다. 버튼은 물리 버튼 또는 터치 버튼으로 마련될 수 있다. 디스플레이와 입력부는 별개의 장치로 마련되거나 하나의 장치(예를 들면, 터치 디스플레이)로 마련될 수 있다. 제어부는 디스플레이, 입력부 또는 사용자 기기 중 적어도 하나를 통해 수신되는 명령을 처리 하여 이동 로봇의 동작을 제어할 수 있다. 통신부는 네트워크를 통해 사용자 기기 또는 서버 중 적어도 하나와 연결을 수행할 수 있다. 또한, 통신부는 비콘과 통신할 수 있다. 제어부는 통신부를 통해 사용자 기기 또는 서버로부터 다양한 정보, 다양한 신호 및/또는 다양한 데이터를 획득할 수 있다. 예를 들면, 통신부는 사용자 기기 로부터 원격 제어 신호를 수신할 수 있다. 제어부는 통신부를 통해 서버로부터 영상을 분석하는데 사용되는 인공지능모델을 획득할 수 있다. 또한, 제어부는 사용자 기기에서 광학 센서(S)의 오염도에 대응하는 정보가 표시되도록, 해당 정보를 통신부를 통해 사용자 기기로 전송할 수 있다. 통신부는 다양한 통신 회로를 포함할 수 있다. 통신부는 무선 통신 회로 및/또는 유선 통신 회로를 포 함할 수 있다. 무선 통신 회로는, 무선 LAN(wireless local area network), 홈 RF(Home Radio Frequency), 적 외선 통신, UWB(Ultra-wide band) 통신, 와이파이, 블루투스, 지그비(Zigbee), 원거리 무선 네트워크(예: 셀룰 러 통신)와 같은 다양한 무선 통신을 지원할 수 있다. 제어부는 초광대역 통신 기반의 SLAM(Simultaneous localization and mapping)을 이용하여 이동 로봇 의 현재 위치를 식별할 수 있다. 즉, 제어부는 이동 로봇이 작업 영역(P)을 주행하는 동안 SLAM(Simultaneous Localization And Mapping) 알고리즘을 이용하여 작업 영역(P)의 맵을 생성할 수 있고, 작 업 영역(P) 내 이동 로봇의 위치를 식별할 수 있다. 움직임 센서는 휠의 회전 속도를 검출하는 휠 센서, 본체의 자세 변화를 검출하는 자이로 센서 및 이동 로봇의 가속도, 속도 및 방향을 검출하기 위한 관성 센서(IMU: Inertial Measurement Unit) 중 적어도 하나 를 포함할 수 있다. 이외에도 이동 로봇의 움직임을 감지할 수 있는 다양한 센서가 마련될 수 있다. 제어부 는 움직임 센서로부터 전송되는 신호에 기초하여 이동 로봇의 움직임을 식별할 수 있다. 위치 센서는 이동 로봇의 위치 정보를 획득할 수 있다. 예를 들면, 위치 센서는 GPS(Global Positioning System) 수신기를 포함할 수 있다. 위치 센서는 이동 로봇의 위치 정보를 포함하는 전기적 신호를 제어부에 전송할 수 있다. 제어부는 위치 센서에 의해 획득되는 위치 정보의 변화에 기 초하여 이동 로봇의 움직임을 식별할 수도 있다. 이동 로봇의 구성요소는 전술된 것으로 제한되지 않는다. 이동 로봇은 전술된 구성요소들 외에도 다양한 구성요소들을 더 포함할 수 있으며, 전술된 구성요소들 중 일부가 생략되는 것도 가능하다. 전술된 이동 로봇의 광학 센서(S)는 이동 로봇의 외부로 노출되기 때문에, 외부 물체에 의해 오염될 수 있다. 광학 센서(S)가 오염되면 이동 로봇이 전방의 물체를 잘못 식별하거나 장애물을 식별할 수 없게 될 수 있으며, 그에 따라 이동 로봇이 잘못 동작하거나 장애물과 충돌하는 사고가 발생할 수 있다. 잔디를 깎는 블 레이드는 날카롭기 때문에 이동 로봇의 사고가 발생하는 경우 사용자에도 피해를 입을 수 있다. 따라서 광학 센서(S)의 오염을 감지하고, 오염에 적절한 조치를 취하는 것이 필요하다. 제어부는 광학 센서(S)로부터 영상, 영상 데이터 및/또는 영상 신호를 획득할 수 있다. 제어부는 광 학 센서(S)에 의해 획득되는 영상에서 객체를 식별할 수 있다. 제어부는 본체가 이동하는 동안 획득되 는 영상에서 복수의 객체를 식별할 수 있다. 제어부는 식별된 복수의 객체 중 미리 정해진 시간(예: 10초) 동안 검출되는 객체를 오염물로 결정할 수 있다. 영상에서 식별되는 복수의 객체 중 적어도 하나가 오염물로 결 정될 수 있다. 객체를 오염물로 판단하기 위한 미리 정해진 시간은 설계에 따라 다양한 값으로 정해질 수 있다. 다시 말해, 제어부는 본체가 주행하는 도중에 획득되는 영상에서 미리 정해진 시간 동안 계속 검출되 는 객체를 오염물로 판단할 수 있다. 즉, 본체의 이동에도 불구하고 영상에서 특징 변화가 상대적으로 적은 객체가 오염물로 판단될 수 있다. 오염물은 광학 센서(S)에 부착된 상태로 이동 로봇과 함께 움직이게 되므 로, 이동 로봇이 움직이더라도 영상에서 오염물에 대응하는 객체의 특징은 거의 변화하지 않는다. 이동 로봇 이 이동하면, 영상에서 주변 환경에 실제로 존재하는 객체의 특징 변화는 상대적으로 커지는 반면에, 영상에 서 오염물의 특징 변화는 거의 없거나 상대적으로 적게 된다. 즉, 광학 센서(S)의 시야의 적어도 일부가 오염물 에 의해 가려지면, 영상의 적어도 일부 영역의 변화가 영상의 다른 영역의 변화에 비해 상대적으로 적게 된다. 예를 들면, 제어부는 본체가 이동하는 도중에 영상에서 검출되는 객체의 크기 또는 객체의 형상이 미 리 정해진 시간 동안 일정한 것에 기초하여 해당 객체를 오염물로 결정할 수 있다. 즉, 이동 로봇이 이동하더라도 영상에서 오염물에 해당하는 객체의 크기나 형상은 거의 일정하게 유지될 수 있다. 영상의 적어도 일부 영역의 크기 또는 형상이 본체의 이동에도 불구하고 일정하게 유지된다면, 상기 적어도 일부 영역에 오염물 이 위치하는 것으로 판단될 수 있다. 제어부는 본체가 이동하는 도중에 영상에서 객체의 밝기가 미리 정해진 시간 동안 미리 정해진 임계 밝기보다 작게 유지되는 것에 기초하여 객체를 오염물로 결정할 수 있다. 오염물은 광학 센서(S)의 렌즈를 적어 도 일부분 가리게 되므로, 영상에서 오염물이 위치하는 적어도 일부 영역의 밝기는 다른 영역의 밝기보다 낮게 검출될 수 있다. 제어부는 본체가 이동하는 도중에 영상에서 객체의 선명도가 미리 정해진 시간 동안 미리 정해진 임계 선명도보다 작게 유지되는 것에 기초하여 객체를 오염물로 결정할 수 있다. 광학 센서(S)에 오염물이 부착되어 있는 경우, 광학 센서(S)에 의해 생성되는 영상의 전체 영역 중 오염물이 위치하는 영역이 아웃 포커싱 될 수 있다. 따라서, 영상에서 오염물 부분의 선명도가 상대적으로 작게 검출될 수 있다. 또한, 제어부는 본체가 이동하는 도중에 이동 로봇의 현재 위치로부터 객체까지의 거리가 미리 정 해진 시간 동안 미리 정해진 임계 거리보다 작게 유지되는 것에 기초하여 객체를 오염물로 결정할 수 있다. 이 동 로봇의 현재 위치로부터 객체까지의 거리는 영상에 포함된 깊이 정보로부터 획득될 수 있다. 광학 센서(S)가 양안 카메라인 경우, 좌안 렌즈와 우안 렌즈 중 어느 하나에 오염물이 존재하면 양안차 매칭이 실패하여 대상까지의 거리가 무작위 값으로 출력될 수 있다. 제어부는 본체가 이동하는 동안 양안 카 메라에 의해 획득되는 영상 내 객체까지의 거리가 반복해서 무작위 값으로 출력되는 것에 기초하여 해당 객체를 오염물로 결정할 수 있다. 한편, 이동 로봇에는 서로 다른 2개 이상의 광학 센서(S)가 마련될 수 있다. 예를 들면, 전술된 바와 같이, 이동 로봇은 컬러 영상(제1 영상)을 생성하는 제1 광학 센서(S1)와, 대상까지의 거리 정보를 포함하는 깊이 영상(제2 영상)을 생성하는 제2 광학 센서(S2)를 포함할 수 있다. 제어부는 제1 광학 센서(S1)의 제1 영상 과 제2 광학 센서(S2)의 제2 영상을 정합할 수 있고, 제1 영상에 포함된 객체와 제2 영상에 포함된 객체를 비교 할 수 있다. 제어부는 제1 영상에서 검출되는 객체(제1 객체)와 제2 영상에서 검출되는 객체(제2 객체)가 동일한 것인지 또는 다른 것인지 판단할 수 있다. 제어부는 제1 광학 센서(S1)의 제1 영상과 제2 광학 센서(S2)의 제2 영상 모두에서 객체가 동일하게 검출 되는 것에 기초하여, 객체를 오염물이 아닌 외부 물체로 결정할 수 있다. 예를 들면, 제1 광학 센서(S1)의 제1 영상에 포함된 어떤 객체가 오염물로 결정되었더라도, 그 객체가 제2 광학 센서(S2)의 제2 영상에서도 동일하게 검출된다면, 그 객체는 오염물이 아니라 다른 외부 물체일 확률이 높다. 이와 같이, 서로 다른 광학 센서에 의 해 획득된 영상들을 비교함으로써 오염물 결정의 정확도가 향상될 수 있다. 제어부는 오염물의 특징과 영상 내 오염물의 위치에 기초하여 광학 센서(S)의 오염도를 결정할 수 있다. 제어부는 미리 정해진 기준선에 기초하여 영상을 복수의 영역으로 나눌 수 있다. 제어부는 영상의 복 수의 영역 중 오염물로 결정된 객체가 위치하는 영역에 따라 광학 센서(S)의 오염도를 다르게 결정할 수 있다. 복수의 영역은 설계에 따라 다양하게 설정될 수 있다. 예를 들면, 제어부는 광학 센서(S)에 의해 획득된 영상의 전체 영역을 중앙 영역, 좌측 영역, 우측 영역, 상부 영역 및 하부 영역으로 구분할 수 있다. 제어부는 영상의 중앙 영역에 가장 큰 제1 가중치를 적용할 수 있다. 제어부는 영상의 좌측 영역과 우측 영역에 제1 가중치보다 작은 제2 가중치를 적용할 수 있다. 제어부는 영상의 상부 영역과 하부 영역에 제2 가중치보다 작은 제3 가중치를 적용할 수 있다. 제어부 는 객체가 위치하는 영역의 가중치가 클수록, 광학 센서(S)의 오염도를 높게 결정할 수 있다. 일반적으로, 광학 센서(S)의 시야(FOV)는 이동 로봇의 크기보다 큰 넓이를 갖는 영역을 볼 수 있도록 설계된 다. 영상의 중앙 영역의 넓이는 이동 로봇의 크기에 대응하도록 설정될 수 있다. 광학 센서(S)는 이동 로봇 의 전방을 촬영하고, 이동 로봇은 주행 경로를 따라 전방으로 이동한다. 광학 센서(S)에 의해 획득된 영 상의 영역들 중 이동 로봇의 주행에 큰 영향을 미치는 영역은 중앙 영역일 수 있다. 광학 센서(S)에 의해 획 득된 영상의 중앙 영역에서 검출되는 물체는 이동 로봇의 주행 경로 상에 있는 물체에 해당하기 때문에, 영 상의 중앙 영역에서 검출되는 물체가 무엇인지에 따라 이동 로봇의 동작이 달라진다. 따라서 영상의 복수의 영역들 중 중앙 영역이 가장 중요하게 처리되어야 하므로, 중앙 영역에 가장 큰 가중치가 부여될 수 있다. 다시 말해, 영상의 복수의 영역들 중 이동 로봇의 직진 주행에 가장 큰 영향을 미치는 영역은 중앙 영역일 수 있다. 또한, 이동 로봇이 좌방향 또는 우방향으로 주행 방향의 변경이 필요한 경우에는, 영상의 좌측 영역 또는 우측 영역에서 어떤 물체가 검출되는지에 따라 이동 로봇의 동작이 달라진다. 반면에, 영상의 상부 영역에서 검출되는 물체는 실제로 이동 로봇의 위에 존재할 수 있고, 영상의 하부 영역에서 검출되는 물체는 이동 로봇의 하면보다 아래에 존재할 수 있다. 즉, 영상의 상부 영역 또는 영상의 하부 영역에서 검출되는 물체는 이동 로봇의 주행에 영향을 미치지 않을 수 있다. 따라서 영상의 좌측 영역과 우측 영역이 영상의 상 부 영역과 하부 영역보다 중요하게 처리될 필요가 있다. 제어부는 영상 내에서 오염물이 위치하는 영역 뿐만 아니라 오염물의 특징을 함께 고려하여 광학 센서(S) 의 오염도를 결정할 수 있다. 예를 들면, 오염물의 특징은 오염물의 크기 또는 오염물의 투명도 중 적어도 하나 를 포함할 수 있다. 제어부는 오염물의 크기가 클수록, 광학 센서(S)의 오염도를 높게 결정할 수 있다. 오 염물의 크기가 클수록 광학 센서(S)의 시야(FOV)를 많이 가리게 되므로, 오염도가 높게 결정될 수 있다. 제어부 는 오염물의 투명도가 낮을수록, 광학 센서(S)의 오염도를 높게 결정할 수 있다. 오염물이 불투명할수록 빛이 오염물을 투과할 수 없으므로 오염물이 위치하는 영상의 적어도 일부 영역이 어둡게 된다. 또한, 제어부는 오염물의 밝기가 낮을수록, 광학 센서(S)의 오염도를 높게 결정할 수 있다. 제어부는 오염물의 선명도가 낮을수록, 광학 센서(S)의 오염도를 높게 결정할 수 있다. 영상에서 오염물로 결정되는 객체가 복수 개일 수도 있다. 제어부는 영상 내에서 복수의 오염물 각각이 위 치하는 영역의 가중치와 복수의 오염물 각각의 특징을 모두 고려하여 광학 센서(S)의 오염도를 결정할 수 있다. 이동 로봇의 제어부는 광학 센서(S)의 오염도에 대응하는 정보를 사용자 인터페이스 또는 사용자 기기 중 적어도 하나를 통해 제공할 수 있다. 광학 센서(S)의 오염도에 대응하는 정보는 시각 정보 또는 청 각 정보 중 적어도 하나를 포함할 수 있다. 시각 정보는 사용자 인터페이스의 디스플레이와 인디케이터 를 통해 제공될 수 있다. 청각 정보는 사용자 인터페이스의 스피커를 통해 제공될 수 있다. 제어부는 광학 센서(S)의 오염도에 기초하여 이동 로봇의 동작 모드를 결정할 수 있다. 이동 로봇의 동작 모드는 정상 모드, 대기 모드 또는 클리닝 모드로 결정될 수 있다. 정상 모드는 이동 로봇이 잔디 커팅 작업을 정상적으로 수행하도록 설정될 수 있다. 대기 모드는 이동 로봇이 잔디 커팅 작업을 중지하고 대기하 도록 설정될 수 있다. 클리닝 모드는 이동 로봇이 잔디 커팅 작업을 중지하고 충전 스테이션으로 복귀하 도록 설정될 수 있다. 예를 들면, 제어부는 광학 센서(S)의 오염도가 임계 레벨보다 낮은 것에 기초하여, 사용자 인터페이스 또는 사용자 기기 중 적어도 하나를 통해 광학 센서(S)의 오염 발생을 알리기 위한 오염 알림을 제공하고, 이동 로봇의 동작 모드를 정상 모드로 결정할 수 있다. 임계 레벨은 설계에 따라 다양하게 설정될 수 있다. 광학 센서(S)의 오염도가 임계 레벨보다 낮은 경우, 이동 로봇이 정상적으로 주행하는데 문제되지 않을 수 있다. 따라서 이동 로봇은 사용자에게 광학 센서(S)의 오염이 발생한 사실을 알리고, 잔디를 커팅하기 위한 주행을 계속할 수 있다. 광학 센서(S)의 오염도가 임계 레벨보다 낮은 경우, 제어부는 광학 센서(S)의 오염도에 따라 이동 로봇 의 주행 속도를 조절하기 위해 휠 모터를 제어할 수 있다. 제어부는 광학 센서(S)의 오염도가 높을 수록 이동 로봇의 주행 속도를 감소시킬 수 있다. 광학 센서(S)의 오염도가 임계 레벨보다 높거나 같은 경우, 이동 로봇이 전방에 위치하는 다른 물체를 식별 하지 못해 주행 경로를 비정상적으로 이탈하거나 다른 물체와 충돌할 수 있다. 제어부는 광학 센서(S)의 오염도가 임계 레벨보다 높거나 같은 것에 기초하여, 사용자 인터페이스 또는 사용자 기기 중 적어도 하 나를 통해 주행의 위험을 알리기 위한 위험 알림을 제공하고, 이동 로봇의 동작 모드를 대기 모드 또는 클리 닝 모드로 결정할 수 있다. 이동 로봇은 휠 모터와 블레이드 모터(40a)의 동작을 정지시켜 주행을 정지하고 대기 모드로 진입할 수 있다. 이동 로봇이 대기 모드로 진입하면, 제어부는 광학 센서(S)로부터 오염물이 제거될 때까지 대기 모드를 유지할 수 있다. 사용자는 직접 광학 센서(S)에서 오염물을 제거하거나 이동 로봇을 충전 스테이션 에 도킹시킬 수 있다. 충전 스테이션은 이동 로봇이 도킹되면 광학 센서(S)의 청소를 수행할 수 있다. 이동 로봇의 제어부는 클리닝 모드로 진입함에 따라 충전 스테이션으로 복귀를 결정할 수 있다. 즉, 클리닝 모드로 진입하면 제어부는 블레이트 모터(40a)의 동작을 정지시키고, 이동 로봇을 충전 스테이 션으로 이동시키기 위해 휠 모터를 제어할 수 있다. 광학 센서(S)의 오염으로 인해 이동 로봇이 충전 스테이션으로 복귀하는 도중에 사고가 발생할 수도 있다. 제어부는 이동 로봇과 충전 스테이션의 도킹이 완료될 때까지, 사용자 인터페이스 또는 사용자 기기 중 적어도 하나를 통해 이동 로봇의 복귀에 관한 알림을 제공할 수 있다. 제어부는 미리 정해진 주기마다 광학 센서(S)에 의해 획득되는 영상을 분석하여 광학 센서(S)의 오염 여부 를 판단할 수 있다. 제어부는 영상에서 오염물로 결정된 객체가 식별되지 않으면, 광학 센서(S)의 오염이 제거된 것으로 판단할 수 있다. 제어부는 영상에서 오염물로 결정된 객체가 식별되지 않는 것에 기초하여, 사용자 인터페이스 또는 사용자 기기 중 적어도 하나를 통해 오염 제거 알림을 제공하고, 이동 로봇의 동작 모드를 정상 모드로 결정할 수 있다. 이와 같이, 개시된 이동 로봇은 광학 센서(S)에 오염에 대응하는 적절한 조치를 함으로써 광학 센서(S)의 오 염으로 인한 이동 로봇의 잘못된 동작과 사고를 예방할 수 있다. 한편, 광학 센서(S)의 오염에도 불구하고 사용자는 이동 로봇이 계속 잔디 커팅 작업을 수행하기를 원할 수 있다. 이동 로봇이 대기 모드 또는 클리닝 모드로 진입한 후 사용자 인터페이스 또는 사용자 기기를 통해 동작 지속 명령이 입력될 수 있다. 제어부는 동작 지속 명령을 획득함에 기초하여 이동 로봇의 동 작 모드를 대기 모드 또는 클리닝 모드에서 정상 모드로 변경할 수 있다. 또한, 동작 지속 명령에 따라, 제어부 는 오염도에 관한 임계 레벨을 광학 센서(S)의 현재 오염도보다 높게 변경할 수 있다. 따라서 추후에는 광 학 센서(S)의 오염도가 현재 오염도에 대응하더라도 위험 알림이 제공되지 않고, 이동 로봇이 대기 모드 또 는 클리닝 모드로 진입하지 않을 수 있다. 도 9는 일 실시예에 따른 제1 광학 센서에 의해 획득된 영상을 보여준다. 도 10은 일 실시예에 따른 제2 광학 센서에 의해 획득된 영상을 보여준다. 도 9를 참조하면, 제1 광학 센서(S1)는 제1 영상(IM1)을 획득할 수 있다. 제1 광학 센서(S1)의 미리 정해진 제1 시야(FOV)와 제1 광학 센서(S1)에 포함된 제1 이미지 센서의 크기에 따라, 제1 영상(IM1)은 제1 가로폭(W1)과 제1 높이(H1)를 가질 수 있다. 예를 들면, 제1 영상(IM1)은 세로가 긴 직사각형 프레임을 가질 수 있다. 도 10을 참조하면, 제2 광학 센서(S2)는 제2 영상(IM2)을 획득할 수 있다. 제2 광학 센서(S2)의 미리 정해진 제 2 시야(FOV)와 제2 광학 센서(S2)에 포함된 제2 이미지 센서의 크기에 따라, 제2 영상(IM2)은 제2 가로폭(W2)과 제2 높이(H2)를 가질 수 있다. 예를 들면, 제2 영상(IM2)은 가로가 긴 직사각형 프레임을 가질 수 있다. 이동 로봇의 제어부는 제1 광학 센서(S1)의 제1 영상(IM1)과 제2 광학 센서(S2)의 제2 영상(IM2)을 정 합할 수 있고, 제1 영상(IM1)에 포함된 객체와 제2 영상(IM2)에 포함된 객체를 비교할 수 있다. 제어부는 제1 영상(IM1)과 제2 영상(IM2)을 정합하기 위해, 영상의 일부를 잘라내는 크롭 처리 및 영상의 리스케일링 처 리 중 적어도 하나를 수행할 수 있다. 예를 들면, 제2 영상(IM2)의 제2 가로폭(W2)은 제1 영상(IM1)의 제1 가로 폭(W1)보다 크고, 제2 영상(IM2)의 제2 높이(H2)는 제1 영상(IM1)의 제1 높이(H1)보다 작을 수 있다. 제어부 는 제1 영상(IM1)의 제1 가로폭(W1)에 대응하는 제2 영상(IM2)의 일부 영역을 크롭하고, 제1 영상(IM1)과 정합할 수 있다. 제어부는 제1 영상(IM1)에서 검출되는 객체(제1 객체)와 제2 영상(IM2)에서 검출되는 객 체(제2 객체)가 동일한 것인지 또는 다른 것인지 판단할 수 있다. 제어부는 이동 로봇이 이동하는 동안 제1 영상(IM1)과 제2 영상(IM2) 각각에서 특징 변화가 없거나 특 징 변화가 상대적으로 적은 객체를 검출할 수 있다. 예를 들면, 이동 로봇의 이동에도 불구하고, 제1 영상 (IM1)에서 OB1과 O1으로 표시된 객체의 특징 변화가 없는 것으로 검출될 수 있다. 따라서 제어부는 제1 영 상(IM1)에서 검출된 OB1과 O1을 모두 오염물로 결정할 수 있다. 그런데, 제어부는 제2 영상(IM2)에서도 제1 영상(IM1)의 O1에 대응하는 객체를 검출할 수 있다. 이 경우, 제어부는 O1으로 표시된 객체를 오염물이 아닌 외부 물체로 결정할 수 있다. 이동 로봇으로부터 먼 곳 에 위치하는 객체(예를 들면, 영상의 소실점 부근에 있는 객체)는, 이동 로봇이 이동하더라도 영상에서 상대 적으로 적은 변화를 보일 수 있다. 이러한 객체를 오염물로 결정하면 오염물 판단에 관한 신뢰도가 하락한다. 서로 다른 광학 센서에 의해 획득된 영상들을 비교함으로써 오염물 판단의 정확도가 향상될 수 있다. 도 11은 광학 센서에 의해 생성된 영상을 복수의 영역으로 나눈 예를 보여준다. 도 11을 참조하면, 이동 로봇의 제어부는 광학 센서(S)에 의해 획득된 영상(IM)을 복수의 영역(RC, RL, RR, RU, RL)으로 나눌 수 있다. 도 11의 영상(IM)은 도 10의 제2 영상(IM2)에 대응할 수 있다. 제어부는 미리 정해진 기준선(L1, L2, L3, L4)에 기초하여 영상(IM)을 복수의 영역으로 나눌 수 있다. 예 를 들면, 좌측 세로선(L1), 우측 세로선(L2), 상부 가로선(L3)과 하부 가로선(L4)에 의해, 영상(IM)은 중앙 영역(RC), 좌측 영역(RL), 우측 영역(RR), 상부 영역(RU) 및 하부 영역(RL)으로 구분될 수 있다. 도 11에 도시된 바와 같이, 영상(IM)의 상부 영역(RU)에 위치한 객체OB2가 오염물로 결정되고, 영상(IM)의 중앙 영역(RC)에 위치한 객체OB3이 오염물로 결정될 수 있다. 제어부는 중앙 영역(RC)의 가중치, 상부 영역(R U)의 가중치, 객체OB2의 특징 및 객체OB3의 특징에 기초하여 광학 센서(S)의 오염도를 결정할 수 있다. 상부 영 역(RU)의 가중치가 상대적으로 작고, 객체OB2의 크기도 상대적으로 작기 때문에, 광학 센서(S)의 오염도 결정에 있어서 객체OB2는 무시될 수도 있다. 그러나 중앙 영역(RC)의 가중치는 가장 크고, 중앙 영역(RC)에 위치한 객체OB2의 크기도 상대적으로 크기 때문 에, 광학 센서(S)의 오염도는 임계 레벨보다 높은 것으로 결정될 수 있다. 이 경우 이동 로봇은 사용자 인터 페이스 또는 사용자 기기 중 적어도 하나를 통해 주행의 위험을 알리기 위한 위험 알림을 제공할 수 있 다. 또한, 이동 로봇은 동작 모드가 대기 모드 또는 클리닝 모드로 변경될 수 있다. 도 11은 광학 센서(S)의 오염도를 결정하는 방법을 설명하는 하나의 예에 불과하다. 광학 센서(S)의 오염도는 다양한 상황에 따라 다양하게 결정될 수 있다. 도 12는 일 실시예에 따른 이동 로봇의 사용자 인터페이스 또는 사용자 기기를 통해 제공되는 정보의 일 예를 도시한다. 도 13은 일 실시예에 따른 이동 로봇의 사용자 인터페이스 또는 사용자 기기를 통해 제공되는 정보의 다른 예를 도시한다. 도 12에 도시된 제1 화면과 도 13에 도시된 제2 화면은 이동 로봇의 디스플레이 또는 사용 자 기기를 통해 표시될 수 있다. 도 12와 도 13을 참조하면, 제1 화면과 제2 화면에는, 광학 센 서(S)의 오염 정보와 그에 대응하는 작업 정보를 표시하는 알림 박스(N1) 및 광학 센서(S)에 의해 획득된 영상 을 표시하는 이미지 박스(N2)가 포함될 수 있다. 이미지 박스(N2)에는 오염물을 포함하는 영상이 표시될 수 있 다. 광학 센서(S)의 오염도가 임계 레벨보다 낮은 경우, 제1 화면에 나타난 바와 같이, 알림 박스(N1)에는 광 학 센서(S)의 오염 발생과 이동 로봇의 정상 동작을 알리기 위한 오염 알림이 표시될 수 있다. 예를 들면, 오염 알림은 \"센서의 오염이 감지되었습니다. 작업을 지속하지만 센서 클리닝이 필요할 수 있습니다.\"와 같은 텍스트 메시지로 제공될 수 있다. 광학 센서(S)의 오염도가 임계 레벨보다 높거나 같은 경우, 제2 화면에 나타난 바와 같이, 알림 박스(N 1)에는 주행의 위험과 이동 로봇이 동작을 정지하고 대기 모드로 진입한 것을 알리기 위한 위험 알림이 표시 될 수 있다. 예를 들면, 위험 알림은 \"센서의 오염이 감지되었습니다. 위험 상황이 발생할 수 있으므로, 작업을 긴급 중지하였습니다.\"와 같은 텍스트 메시지로 제공될 수 있다. 또한, 제1 화면과 제2 화면에는, 이동 로봇의 동작 지속 명령을 입력하기 위한 작업 지속 버튼 (B1), 이동 로봇의 동작 중지 명령을 입력하기 위한 작업 중단 버튼(B2) 및 센서 청소 명령을 입력하기 위한 센서 클리닝 버튼(B3)이 포함될 수 있다. 이동 로봇이 대기 모드 또는 클리닝 모드로 진입한 후 작업 지속 버튼(B1)을 통한 사용자 입력(예를 들면, 터치 입력)이 획득되면, 이동 로봇의 제어부는 이동 로봇의 동작 모드를 정상 모드로 변경할 수 있 다. 작업 지속 버튼(B1)을 통한 사용자 입력에 따라 이동 로봇의 동작 모드가 강제로 정상 모드로 변경되는 경우, 충돌 또는 이상 주행에 관한 경고가 작업 지속 버튼(B1)에 표시될 수 있다. 이동 로봇이 정상 모드로 동작하는 중에 작업 중단 버튼(B2)을 통한 사용자 입력이 획득되면, 제어부는 이동 로봇의 동작 모드를 대기 모드로 결정할 수 있다. 제어부는 센서 클리닝 버튼(B3)을 통한 사용자 입력이 획득되면, 이동 로봇의 동작 모드를 클리닝 모드로 결정할 수 있다. 이동 로봇이 클리닝 모드로 진입하면, 이동 로봇의 복귀에 관한 알림이 센서 클리닝 버튼(B3)에 표시될 수 있다. 도 12와 도 13에서 예시된 것 외에도 다양한 정보가 이동 로봇의 사용자 인터페이스와 사용자 기기를 통해 제공될 수 있다. 예를 들면, 광학 센서(S)의 오염이 제거된 경우, 알림 박스(N1)에 오염 제거 알림이 표시 될 수 있다. 도 14는 일 실시예에 따른 이동 로봇의 제어 방법을 설명하는 순서도이다. 도 14를 참조하면, 이동 로봇의 제어부는 이동 로봇이 주행하는 동안 광학 센서(S)로부터 영상을 획 득할 수 있다. 제어부는 영상에서 복수의 객체를 식별할 수 있고, 식별된 복수의 객체 중 미리 정해진 시간 동안 검출되는 객체를 오염물로 결정할 수 있다. 제어부는 오염물의 특징과 영상 내 오염물 의 위치에 기초하여 광학 센서(S)의 오염도를 결정할 수 있다. 제어부는 광학 센서(S)의 오염도에 대응하는 정보를 사용자 인터페이스를 통해 제공할 수 있다. 광학 센서(S)의 오염도에 대응하는 정보는 시각 정보 또는 청각 정보 중 적어도 하나를 포함할 수 있다. 시각 정보는 디스플레이를 통해 표시되는 이미지, 텍스트 및 그래픽 엘리먼트 중 적어도 하나를 포함할 수 있다. 또한, 시각 정보는 인디케이터의 색상을 포함할 수 있다. 청각 정보는 스피커를 통해 제공되는 음향과 음성 중 적어도 하나를 포함할 수 있다. 제어부는 사용자 기기에서 광학 센서(S)의 오염도에 대응하는 정보가 출력되도록, 정보를 사용자 기기로 전송할 수 있다. 제어부는 광학 센서(S)의 오염도에 기초하여 이동 로봇의 동작 모드를 결정할 수 있다. 이동 로 봇의 동작 모드는 정상 모드, 대기 모드 또는 클리닝 모드로 결정될 수 있다. 제어부는 결정된 동작 모 드에 따라 이동 로봇을 제어할 수 있다. 도 15는 도 14에서 설명된 광학 센서의 오염도를 결정하는 방법을 더 상세히 설명하는 순서도이다. 도 15를 참조하면, 영상 내 객체의 위치에 따른 광학 센서(S)의 오염도를 결정하기 위해, 이동 로봇의 제어 부는 미리 정해진 기준선에 기초하여 영상을 복수의 영역으로 나눌 수 있다. 예를 들면, 제어부 는 광학 센서(S)에 의해 획득된 영상의 전체 영역을 중앙 영역, 좌측 영역, 우측 영역, 상부 영역 및 하부 영역으로 구분할 수 있다. 제어부는 영상의 복수의 영역 중 오염물로 결정되는 객체가 위치하는 영역에 따 라 광학 센서(S)의 오염도를 다르게 결정할 수 있다. 제어부는 영상의 복수의 영역 각각에 가중치를 적용할 수 있다. 제어부는 영상의 중앙 영역에 가장 큰 제1 가중치를 적용할 수 있다. 제어부는 영상의 좌측 영역과 우측 영역에 제1 가중치보다 작은 제 2 가중치를 적용할 수 있다. 제어부는 영상의 상부 영역과 하부 영역에 제2 가중치보다 작은 제3 가중치를 적용할 수 있다. 제어부는 오염물이 위치하는 영역의 가중치 및 오염물의 특징에 기초하여 광학 센서(S)의 오염도를 결정할 수 있다. 제어부는 오염물이 위치하는 영역의 가중치가 클수록, 광학 센서(S)의 오염도를 높게 결정 할 수 있다. 광학 센서(S)의 오염도를 결정하기 위해 고려되는 오염물의 특징은 객체의 크기 또는 객체의 투명 도 중 적어도 하나를 포함할 수 있다. 제어부는 오염물의 크기가 클수록, 광학 센서(S)의 오염도를 높게 결정할 수 있다. 제어부는 오염물의 투명도가 낮을수록, 광학 센서(S)의 오염도를 높게 결정할 수 있다. 또한, 제어부는 오염물의 밝기가 낮을수록, 광학 센서(S)의 오염도를 높게 결정할 수 있다. 제어부는 오염물의 선명도가 낮을수록, 광학 센서(S)의 오염도를 높게 결정할 수 있다. 영상에서 오염물로 결정되는 객체가 복수 개일 수도 있다. 제어부는 영상 내에서 복수의 오염물 각각이 위 치하는 영역의 가중치와 복수의 오염물 각각의 특징을 모두 고려하여 광학 센서(S)의 오염도를 결정할 수 있다. 도 16은 도 14에서 설명된 광학 센서의 오염도에 따른 이동 로봇의 동작을 더 상세히 설명하는 순서도이다. 도 16을 참조하면, 이동 로봇의 제어부는 광학 센서(S)의 오염도가 임계 레벨보다 낮은지, 임계 레벨보 다 높은지 또는 임계 레벨과 같은지를 판단할 수 있다. 제어부는 광학 센서(S)의 오염도가 임계 레벨보다 낮은 것에 기초하여, 사용자 인터페이스 또는 사용 자 기기 중 적어도 하나를 통해 광학 센서(S)의 오염 발생을 알리기 위한 오염 알림을 제공하고, 이동 로봇의 동작 모드를 정상 모드로 결정할 수 있다. 제어부는 광학 센서(S)의 오염도가 임계 레벨보다 높거나 같은 것에 기초하여, 사용자 인터페이스 또 는 사용자 기기 중 적어도 하나를 통해 주행의 위험을 알리기 위한 위험 알림을 제공하고, 이동 로봇 의 동작 모드를 대기 모드 또는 클리닝 모드로 결정할 수 있다. 이동 로봇이 대기 모드 또는 클리닝 모드로 진입한 후, 제어부는, 사용자 인터페이스 또는 사용자 기기를 통해 동작 지속 명령을 획득되면, 이동 로봇의 동작 모드를 정상 모드로 변경할 수 있다. 또한, 제어부는 오염도에 관한 임계 레벨을 업데이트 할 수 있다. 즉, 제어부는 오염도에 관한 임계 레벨을 광학 센서(S)의 현재 오염도보다 높게 변경할 수 있다. 제어부는 광학 센서(S)의 영상에서 오염물이 제거되었는지를 식별할 수 있다. 제어부는 영상에 서 오염물로 결정된 객체가 식별되지 않으면, 광학 센서(S)의 오염이 제거된 것으로 판단할 수 있다. 제어부는 영상에서 오염물이 식별되지 않는 것에 기초하여, 사용자 인터페이스 또는 사용자 기기 중 적어 도 하나를 통해 오염 제거 알림을 제공하고, 이동 로봇의 동작 모드를 정상 모드로 결정할 수 있다. 따라 서 이동 로봇은 정상 모드로 동작할 수 있다. 도 17은 도 14에서 설명된 영상 내 오염물을 결정하는 방법에 관한 추가 실시예를 설명한다. 전술된 바와 같이, 이동 로봇에는 서로 다른 2개 이상의 광학 센서(S)가 마련될 수 있다. 예를 들면, 이동 로봇은 제1 영상을 생성하는 제1 광학 센서(S1)와, 제2 영상을 생성하는 제2 광학 센서(S2)를 포함할 수 있 다. 도 17을 참조하면, 이동 로봇의 제어부는 이동 로봇이 이동하는 동안 제1 광학 센서(S1)로부터 제1 영상을 획득할 수 있고, 제2 광학 센서(S2)로부터 제2 영상을 획득할 수 있다. 제어부는 제1 광학 센서(S1)의 제1 영상에서 미리 정해진 시간 동안 검출되는 객체를 오염물로 결정할 수 있다. 제어부는 제1 광학 센서(S1)의 제1 영상과 제2 광학 센서(S2)의 제2 영상을 정합할 수 있고, 제1 영상에 포함된 객체와 제2 영상에 포함된 객체를 비교할 수 있다. 제어부는 제1 영상에서 오염물로 결정된 객체가 제2 광학 센서(S2)의 제2 영상에서도 동일하게 검출되는지 판단할 수 있다. 제어부는 제1 영상에서 오염물로 결정된 객체가 제2 영상에서도 검출되는 것에 기초하여, 제1 영상에서 오 염물로 결정된 객체를 오염물이 아닌 외부 물체로 결정할 수 있다. 제1 영상에서 오염물로 결정된 객체가 제2 영상에서 검출되지 않으면, 제어부는 제1 광학 센서(S1)에 오염이 발생한 것으로 결정할 수 있고, 제1 광학 센서(S1)의 오염도를 결정할 수 있다. 일 실시예에 따른 이동 로봇은 본체, 상기 본체에 마련되는 복수의 휠(20a, 20b, 20c, 20d), 상기 본체에 마련되어 잔디를 커팅하는 블레이드, 상기 본체의 전방을 향한 시야를 갖고 영상을 생성하는 광학 센서(S), 사용자 입력을 획득하고 이동 로봇의 동작에 관한 정보를 제공하는 사용자 인터페이스, 및 제어부를 포함한다. 상기 제어부는 상기 본체가 이동하는 동안 획득되는 상기 영상에서 복수의 객체를 식별할 수 있 다. 상기 제어부는 상기 식별된 복수의 객체 중 미리 정해진 시간 동안 검출되는 객체를 오염물로 결정할 수 있다. 상기 제어부는 상기 오염물의 특징과 상기 영상 내 상기 오염물의 위치에 기초하여 상기 광학 센 서의 오염도를 결정할 수 있다. 상기 제어부는 상기 광학 센서의 오염도에 대응하는 정보를 상기 사용자 인터페이스를 통해 제공할 수 있다. 상기 제어부는 상기 광학 센서의 오염도에 기초하여 이동 로봇의 동작 모드를 결정할 수 있다. 상기 제어부는 상기 광학 센서의 오염도가 임계 레벨보다 낮은 것에 기초하여, 상기 사용자 인터페이스를 통해 상기 광학 센서의 오염 발생을 알리기 위한 오염 알림을 제공하고, 상기 이동 로봇의 동작 모드를 정상 모드로 결정할 수 있다. 상기 제어부는 상기 광학 센서의 오염도가 임계 레벨보다 높거나 같은 것에 기초하여, 상기 사용자 인터페이스 를 통해 주행의 위험을 알리기 위한 위험 알림을 제공하고, 상기 이동 로봇의 동작 모드를 대기 모드 또는 클리 닝 모드로 결정할 수 있다. 상기 제어부는 상기 사용자 인터페이스를 통해 입력되는 동작 지속 명령에 기초하여, 상기 이동 로봇의 동작 모 드를 상기 대기 모드 또는 상기 클리닝 모드에서 정상 모드로 변경하고, 상기 임계 레벨을 상기 결정된 광학 센 서의 오염도보다 높게 변경할 수 있다. 상기 제어부는 상기 영상에서 상기 오염물로 결정된 상기 객체가 식별되지 않는 것에 기초하여, 상기 사용자 인 터페이스를 통해 오염 제거 알림을 제공하고, 상기 이동 로봇의 동작 모드를 정상 모드로 결정할 수 있다. 상기 제어부는 미리 정해진 기준선에 기초하여 상기 영상을 복수의 영역으로 나누고, 상기 복수의 영역 중 상기 오염물이 위치하는 영역에 따라 상기 광학 센서의 오염도를 다르게 결정할 수 있다. 상기 제어부는 상기 영상의 중앙 영역에 가장 큰 제1 가중치를 적용하고, 상기 영상의 좌측 영역과 우측 영역에 상기 제1 가중치보다 작은 제2 가중치를 적용하고, 상기 영상의 상부 영역과 하부 영역에 상기 제2 가중치보다 작은 제3 가중치를 적용하며, 상기 오염물이 위치하는 영역의 가중치가 클수록, 상기 광학 센서의 오염도를 높 게 결정할 수 있다. 상기 오염물의 특징은 상기 오염물의 크기 및 상기 오염물의 투명도 중 적어도 하나를 포함하고, 상기 제어부는 상기 오염물의 크기가 클수록 또는 상기 오염물의 투명도가 낮을수록, 상기 광학 센서의 오염도를 높게 결정할수 있다. 상기 광학 센서는 컬러 영상을 생성하는 제1 광학 센서; 및 대상까지의 거리 정보를 포함하는 깊이 영상을 생성 하는 제2 광학 센서;를 포함할 수 있다. 상기 제어부는 상기 제1 광학 센서의 상기 컬러 영상과 상기 제2 광학 센서의 상기 깊이 영상 모두에서 상기 객체가 동일하게 검출되는 것에 기초하여, 상기 객체를 오염물이 아닌 외 부 물체로 결정할 수 있다. 상기 제어부는 상기 광학 센서의 오염도에 대응하는 시각 정보 또는 청각 정보 중 적어도 하나를 상기 사용자 인터페이스를 통해 제공할 수 있다. 상기 이동 로봇은 외부 장치와 통신하는 통신부;를 더 포함할 수 있다. 상기 제어부는 사용자 기기에서 상기 광 학 센서의 오염도에 대응하는 상기 정보가 표시되도록, 상기 정보를 상기 통신부를 통해 상기 사용자 기기로 전 송할 수 있다. 일 실시예에 따른 이동 로봇의 제어 방법은, 상기 이동 로봇이 이동하는 동안 광학 센서에 의해 획득되는 영상 에서 복수의 객체를 검출하고; 상기 복수의 객체 중 미리 정해진 시간 동안 검출되는 객체를 오염물로 결정하고; 상기 오염물의 특징과 상기 영상 내 상기 오염물의 위치에 기초하여 상기 광학 센서의 오염도를 결정 하고; 상기 광학 센서의 오염도에 대응하는 정보를 상기 사용자 인터페이스를 통해 제공하고; 상기 광학 센서의 오염도에 기초하여 상기 이동 로봇의 동작 모드를 결정하는 것;을 포함한다. 상기 광학 센서의 오염도가 임계 레벨보다 낮은 것에 기초하여, 상기 광학 센서의 오염도에 대응하는 정보는 상 기 광학 센서의 오염 발생을 알리기 위한 오염 알림으로 제공되고, 상기 이동 로봇의 동작 모드는 정상 모드로 결정될 수 있다. 상기 광학 센서의 오염도가 임계 레벨보다 높거나 같은 것에 기초하여, 상기 광학 센서의 오염도에 대응하는 정 보는 주행의 위험을 알리기 위한 위험 알림으로 제공되고, 상기 이동 로봇의 동작 모드는 대기 모드 또는 클리 닝 모드로 결정될 수 있다. 상기 이동 로봇의 제어 방법은, 상기 사용자 인터페이스를 통해 입력되는 동작 지속 명령에 기초하여, 상기 이 동 로봇의 동작 모드를 상기 대기 모드 또는 상기 클리닝 모드에서 정상 모드로 변경하고, 상기 임계 레벨을 상 기 결정된 광학 센서의 오염도보다 높게 변경하는 것;을 더 포함할 수 있다. 상기 영상에서 상기 오염물로 결정된 상기 객체가 식별되지 않는 것에 기초하여, 상기 광학 센서의 오염도에 대 응하는 정보는 오염 제거 알림으로 제공되고, 상기 이동 로봇의 동작 모드는 정상 모드로 결정될 수 있다. 상기 광학 센서의 오염도를 결정하는 것은, 미리 정해진 기준선에 기초하여 상기 영상을 복수의 영역으로 나누 고; 상기 복수의 영역 중 상기 객체가 위치하는 영역에 따라 상기 광학 센서의 오염도를 다르게 결정하는 것;을 포함할 수 있다. 상기 광학 센서의 오염도를 결정하는 것은, 상기 영상의 중앙 영역에 가장 큰 제1 가중치를 적용하고; 상기 영 상의 좌측 영역과 우측 영역에 상기 제1 가중치보다 작은 제2 가중치를 적용하고; 상기 영상의 상부 영역과 하 부 영역에 상기 제2 가중치보다 작은 제3 가중치를 적용하며; 상기 오염물이 위치하는 영역의 가중치가 클수록, 상기 광학 센서의 오염도를 높게 결정하는 것;을 포함할 수 있다. 상기 오염물의 특징은 상기 오염물의 크기 및 상기 오염물의 투명도 중 적어도 하나를 포함하고, 상기 광학 센 서의 오염도를 결정하는 것은, 상기 오염물의 크기가 클수록 또는 상기 오염물의 투명도가 낮을수록, 상기 광학 센서의 오염도를 높게 결정하는 것;을 포함할 수 있다. 상기 광학 센서는 컬러 영상을 생성하는 제1 광학 센서; 및 대상까지의 거리 정보를 포함하는 깊이 영상을 생성 하는 제2 광학 센서;를 포함할 수 있다. 상기 이동 로봇의 제어 방법은, 상기 제1 광학 센서의 상기 컬러 영상 과 상기 제2 광학 센서의 상기 깊이 영상 모두에서 상기 객체가 동일하게 검출되는 것에 기초하여, 상기 객체를 오염물이 아닌 외부 물체로 결정하는 것;을 더 포함할 수 있다. 전술된 바와 같이, 개시된 이동 로봇, 이동 로봇의 제어 방법 및 시스템은, 외부 환경에 노출되는 광학 센서의 오염을 감지할 수 있고, 광학 센서에 오염에 대응하는 적절한 조치를 취할 수 있다. 따라서 광학 센서의 오염에 따른 이동 로봇의 잘못된 동작과 사고가 예방될 수 있다. 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 저장매체의 형태로 구현될 수 있다. 명령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된실시예들의 동작을 수행할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일 시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2023-0099886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 발명이 속하는 기술분야에서 통상 의 지식을 가진 자는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 발명이 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2023-0099886", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 이동 로봇을 포함하는 시스템을 도시한다. 도 2는 일 실시예에 따른 시스템에 포함된 이동 로봇, 충전 스테이션 및 비콘을 도시한다. 도 3은 일 실시예에 따른 이동 로봇의 사시도이다. 도 4는 일 실시예에 따른 이동 로봇의 아래에서 바라본 평면도이다. 도 5는 도 3에 도시된 이동 로봇을 상하 방향으로 자른 단면의 일 예를 도시한다. 도 6은 일 실시예에 따른 충전 스테이션을 더 상세히 도시한다. 도 7은 일 실시예에 따른 충전 스테이션의 제어 블록도이다. 도 8은 일 실시예에 따른 이동 로봇의 제어 블록도이다. 도 9는 일 실시예에 따른 제1 광학 센서에 의해 획득된 영상을 보여준다. 도 10은 일 실시예에 따른 제2 광학 센서에 의해 획득된 영상을 보여준다. 도 11은 광학 센서에 의해 생성된 영상을 복수의 영역으로 나눈 예를 보여준다. 도 12는 일 실시예에 따른 이동 로봇의 사용자 인터페이스 또는 사용자 기기를 통해 제공되는 정보의 일 예를 도시한다. 도 13은 일 실시예에 따른 이동 로봇의 사용자 인터페이스 또는 사용자 기기를 통해 제공되는 정보의 다른 예를도시한다. 도 14는 일 실시예에 따른 이동 로봇의 제어 방법을 설명하는 순서도이다. 도 15는 도 14에서 설명된 광학 센서의 오염도를 결정하는 방법을 더 상세히 설명하는 순서도이다. 도 16은 도 14에서 설명된 광학 센서의 오염도에 따른 이동 로봇의 동작을 더 상세히 설명하는 순서도이다. 도 17은 도 14에서 설명된 영상 내 오염물을 추정하는 방법에 관한 추가 실시예를 설명한다."}
