{"patent_id": "10-2023-0114742", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0032216", "출원번호": "10-2023-0114742", "발명의 명칭": "모낭충에 대한 정보 제공 방법 및 이를 이용한 모낭충에 대한 정보 제공용 디바이스", "출원인": "연세대학교 산학협력단", "발명자": "김제민"}}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "모낭충 예측 장치의 프로세서에 의해 수행되는 모낭충에 대한 정보 제공 방법으로서,개체의 얼굴 영상을 수신하는 단계;얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐(feature)를 추출하도록 학습된 제 1 예측 모델에 상기 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐를 추출하는 단계;상기 제 1 피쳐로부터 중요 영역 맵(saliency map)을 생성하는 단계;상기 중요 영역 맵으로부터 얼굴 내 관심 영역들을 한 개 이상의 패치(patch)로 획득하는 단계;한 개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐를 추출하도록 학습된 제 2 예측 모델에 상기 한개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐를 추출하는 단계, 및제 1 피쳐 및 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 학습된 제 3 예측 모델에 상기 제 1 피쳐 및 상기 제 2 피쳐를 입력으로 하여 상기 개체에 대한 모낭충의 최종 밀도 확률을 예측하는단계;를 포함하는, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 수신하는 단계 후에,수신된 상기 얼굴 영상으로부터 얼굴 내 랜드마크를 비식별화하는 단계를 더 포함하는, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제4항에 있어서,상기 비식별화 하는 단계는, 수신된 상기 얼굴 영상으로부터 얼굴 내 해부학적 구조에 대한 좌표를 추출하고,추출된 상기 좌표에 기초하여 얼굴 내 랜드마크를 비식별화하는 단계를 포함하는, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 제 1 피쳐를 추출하는 단계 후에,제 1 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습된 제 1 예측 모델에 상기 제1 피쳐를 입력으로 하여 상기 개체에 대한 모낭충의 제 1 밀도 확률을 예측하는 단계를 더 포함하는, 모낭충에대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 제 1 밀도 확률은,상기 얼굴 영상에 대한 전역 예측값(global prediction)인, 모낭충에 대한 정보 제공 방법. 공개특허 10-2025-0032216-3-청구항 6 제 1항에 있어서, 상기 제 2 피쳐를 추출하는 단계 후에,제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습된 제 2 예측 모델에 상기 제2 피쳐를 입력으로 하여 상기 개체에 대한 모낭충의 제 2 밀도 확률을 예측하는 단계를 더 포함하는, 모낭충에대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 제 2 밀도 확률은,상기 패치 영상에 대한 국소 예측값(local prediction)인, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항에 있어서,상기 수신하는 단계는,개체의 임상 정보를 수신하는 단계를 더 포함하고,상기 수신하는 단계 후에,임상정보를 입력으로 하여 모낭충의 피쳐를 추출하도록 학습된 제 4 예측 모델에상기 임상 정보를 입력으로 하여 모낭충에 대한 제 3 피쳐를 추출하는 단계를 더 포함하는, 모낭충에 대한 정보제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 제 3 예측 모델은,제 1 피쳐, 제 2 피쳐 및 제 3 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습되고,상기 최종 밀도 확률을 예측하는 단계는,상기 제 3 예측 모델에 상기 제 1 피쳐, 상기 제 2 피쳐 및 상기 제 3 피쳐를 입력으로 하여 상기 개체에 대한모낭충의 최종 밀도 확률을 예측하는 단계;를 포함하는, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8항에 있어서,상기 임상 정보에 기초하여 특성 중요도를 출력하는 단계를 더 포함하는, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1항에 있어서,상기 최종 밀도 확률을 예측하는 단계의 제 1 피쳐는,풀링(pooling)된 벡터(vector)값인, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1항에 있어서,공개특허 10-2025-0032216-4-상기 최종 밀도 확률을 예측하는 단계의 제 2 피쳐는,어탠션 스코어가 적용된 벡터 값(attention-weighted representation Z vector)인, 모낭충에 대한 정보 제공방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,상기 제 2 피쳐를 추출하는 단계는,추출된 상기 제 2 피쳐에 어탠션 스코어(attention score)를 적용하는 단계를 더 포함하는, 모낭충에 대한 정보제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 어탠션 스코어를 적용하는 단계는,상기 한 개 이상의 패치들이 하나의 배치(batch)로 1개 이상의 FC 레이어에 입력되는 단계;상기 FC 레이어로부터 출력된 로짓(logit)에 기초하여 어탠션 스코어(attention score)를 출력하는 단계, 및출력된 상기 어탠션 스코어를 상기 제 2 피쳐에 곱해주는 단계를 포함하는, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 1항에 있어서,상기 제 1 예측 모델은,상기 얼굴 영상을 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된모델인, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 1항에 있어서,상기 제 2 예측 모델은,상기 패치를 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델인, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 1항에 있어서,상기 제 3 예측 모델은,상기 제 1 피쳐 및 상기 제 2 피쳐를 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델인, 모낭충에 대한 정보 제공 방법."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 15항 내지 제 17항 중 어느 한 항에 있어서,상기 분류 0은,1 cm2 당 모낭충의 마릿수가 0 이상 내지 5 미만이고,상기 분류 1은, 1 cm2 당 모낭충의 마릿수가 5 이상인, 모낭충에 대한 정보 제공 방법. 공개특허 10-2025-0032216-5-청구항 19 개체의 얼굴 영상을 수신하도록 구성된 통신부, 및상기 통신부와 통신하도록 연결된 프로세서를 포함하고,상기 프로세서는,얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐(feature)를 추출하도록 학습된 제 1 예측 모델에 상기 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐를 추출하고,상기 제 1 피쳐로부터 중요 영역 맵(saliency map)을 생성하고,상기 중요 영역 맵으로부터 얼굴 내 관심 영역들을 한 개 이상의 패치(patch)로 획득하고,한 개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐를 추출하도록 학습된 제 2 예측 모델에 상기 한개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐를 추출하고,제 1 피쳐 및 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 학습된 제 3 예측 모델에 상기 제 1 피쳐 및 상기 제 2 피쳐를 입력으로 하여 상기 개체에 대한 모낭충의 최종 밀도 확률을 예측하도록 구성된, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19항에 있어서,상기 프로세서는,수신된 상기 얼굴 영상으로부터 얼굴 내 랜드마크를 비식별화하도록 더 구성된, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 20항에 있어서,상기 프로세서는,수신된 상기 얼굴 영상으로부터 얼굴 내 해부학적 구조에 대한 좌표를 추출하고,추출된 상기 좌표에 기초하여 얼굴 내 랜드마크를 비식별화하도록 구성된, 모낭충에 대한 정보 제공용디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 19항에 있어서, 상기 프로세서는, 상기 제 1 피쳐를 추출한 후에,제 1 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습된 제 1 예측 모델에 상기 제1 피쳐를 입력으로 하여 상기 개체에 대한 모낭충의 제 1 밀도 확률을 예측하도록 더 구성된, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 18항에 있어서,상기 제 1 밀도 확률은,상기 얼굴 영상에 대한 전역 예측값(global prediction)인, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제 19항에 있어서,공개특허 10-2025-0032216-6-상기 프로세서는,상기 제 2 피쳐를 추출하는 단계 후에,제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습된 제 2 예측 모델에 상기 제2 피쳐를 입력으로 하여 상기 개체에 대한 모낭충의 제 2 밀도 확률을 예측하도록 더 구성된, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제 24항에 있어서,상기 제 2 밀도 확률은,상기 패치 영상에 대한 국소 예측값(global prediction)인, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제 19항에 있어서,상기 통신부는,개체의 임상 정보를 수신하도록 더 구성되고,상기 프로세서는,임상정보를 입력으로 하여 모낭충의 피쳐를 추출하도록 학습된 제 4 예측 모델에 상기 임상 정보를 입력으로 하여 모낭충에 대한 제 3 피쳐를 추출하도록 더 구성된, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제 26항에 있어서,상기 제 3 예측 모델은,제 1 피쳐, 제 2 피쳐 및 제 3 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습되고,상기 프로세서는,상기 제 3 예측 모델에,상기 제 1 피쳐, 상기 제 2 피쳐 및 상기 제 3 피쳐를 입력으로 하여 상기 개체에 대한 모낭충의 최종 밀도 확률을 예측하도록 구성된, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제 26항에 있어서,상기 프로세서는,상기 임상 정보에 기초하여 특성 중요도를 출력하도록 더 구성된, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제 19항에 있어서,상기 제 3 예측 모델에 입력되는 상기 제 1 피쳐는,풀링(pooling)된 벡터(vector)값인, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제 19항에 있어서,상기 제 3 예측 모델에 입력되는 상기 제 2 피쳐는,공개특허 10-2025-0032216-7-어탠션 스코어가 적용된 벡터 값(attention-weighted representation Z vector)인, 모낭충에 대한 정보 제공용디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제 30항에 있어서,상기 프로세서는,추출된 상기 제 2 피쳐에 어탠션 스코어(attention score)를 적용하도록 더 구성되는, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제 31항에 있어서,상기 프로세서는,상기 한 개 이상의 패치들이 하나의 배치(batch)로 1개 이상의 FC 레이어에 입력되고,상기 FC 레이어로부터 출력된 로짓(logit)에 기초하여 어탠션 스코어(attention score)가 출력되고,출력된 상기 어탠션 스코어를 상기 제 2 피쳐에 곱해주도록 더 구성된, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제 19항에 있어서,상기 제 1 예측 모델은,상기 얼굴 영상을 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된모델인, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제 19항에 있어서,상기 제 2 예측 모델은,상기 패치를 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델인, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제 19항에 있어서,상기 제 3 예측 모델은,상기 제 1 피쳐 및 상기 제 2 피쳐를 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델인, 모낭충에 대한 정보 제공용 디바이스."}
{"patent_id": "10-2023-0114742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제 33항 내지 제 35항 중 어느 한 항에 있어서,상기 분류 0은,1 cm2 당 모낭충의 마릿수가 0 이상 내지 5 미만이고,상기 분류 1은, 1 cm2 당 모낭충의 마릿수가 5 이상인, 모낭충에 대한 정보 제공용 디바이스. 공개특허 10-2025-0032216-8-"}
{"patent_id": "10-2023-0114742", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 모낭충 예측 장치의 프로세서에 의해 수행되는 모낭충에 대한 정보 제공 방법으로서, 개체의 얼굴 영상을 수신하는 단계; 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐(feature)를 추출하도록 학습된 제 1 예측 모델에 상기 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐를 추출하는 단계; 상기 제 1 (뒷면에 계속)"}
{"patent_id": "10-2023-0114742", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 모낭충에 대한 정보 제공 방법 및 이를 이용한 디바이스에 관한 것이다."}
{"patent_id": "10-2023-0114742", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "데모덱스 종 (Demodex species) 즉, 모낭충은 인체 피부 특히, 털피지샘 구조에서 주로 발견되는 마이크로바이 옴으로서, 아종으로 Demodex folliculorum 과 Demodex brevis가 있다. 이러한, 모낭충은 신생아를 제외한 모 든 연령의 모낭에서 관찰되며, 특히, 30대 이상의 성인의 경우 모낭충이 대부분 관찰되는 것으로 나타난다. 모낭충에 의한 피부병변은 주로 얼굴에서 구진(papule), 농포(pustule) 그리고 모공각화증(follicular keratosis)을 동반한 염증성 병변으로 나타나며, 데모덱스 종은 염증성 피부질환인 주사(rosacea)의 주요 악화 인자로 작용하는 것으로 알려져 있다. 하지만 모낭충에 의한 병인은 그 존재 자체 보다 개체수의 변화에 의해 유발된다. 보다 구체적으로, 모낭충이 정상 성인 피부에서 1cm2 당 10 마리 이상 발견될 경우, 모낭충의 충체나 대사산물로 인하여 숙주의 면역반응을 변화시켜, 털피지샘 누두(infundibulum) 구조의 증식 및 과각화를 일으켜 모낭 폐쇄를 초래할 수 있다. 이러한 모낭충에 의하여 발생되는 피부질환 중 주사(Rosacea)는 약 10 %의 인구에서 발생하는 흔한 피부질환으 로, 주로 코와 뺨 같은 얼굴의 중앙 부위에 혈관 확장, 구진 및 농포가 발생하는 것이 특징인 만성질환이다. 주사 환자수는 2017년 대한피부과학회에서 시행한 빅데이터 분석 결과, 2000년대 이후 매년 약 20 % 씩 증가하 는 것으로 나타나고 있으며, 주사의 주요 병인으로 모낭충이 주목되고 있다. 보다 구체적으로, 모낭충에 의한 피부 면역반응 조절이상이 주사환자에서 보고되고 있으며, 선행 연구에서는 모 낭충 개체 수의 증가에 따라 TLR2 매개 염증성 사이토카인 (IL-1, IL-6, IL-8 및 LL-37)이 증가하는 것으로 나 타났으며, 주사의 신경 혈관성 증상 발현과 관련된 TRPV 수용체 발현 또한, 증가한 것으로 나타났다. 나아가, 모낭충의 과증식은 주사 외에도 염증성 모낭염, 지루성 피부염 등 안면 홍반을 동반하는 다른 질환에도 발견된다. 모낭충의 과증식은 주사 및 접촉성 피부염을 동시에 가진 환자군에서 더 흔하게 발견되며 특정 항원 (니켈 금속)과도 연관된 것으로 나타난다. 전술한 바와 같이, 모낭충은 광범위한 피부질환의 원인이 됨에 따라, 모낭충의 확인은 홍반을 호소하는 환자의 감별 진단 및 치료 방향 선택에 중요할 수 있으며, 이에, 모낭충을 정확하게 진단 및 확인할 수 있는 방법 개발 이 요구되고 있는 실정이다. 발명의 배경이 되는 기술은 본 발명에 대한 이해를 보다 용이하게 하기 위해 작성되었다. 발명의 배경이 되는 기술에 기재된 사항들이 선행기술로 존재한다고 인정하는 것으로 이해되어서는 안 된다."}
{"patent_id": "10-2023-0114742", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "현재, 모낭충의 측정 방법으로는 고식적인 펀치 생검(punch biopsy), SSSB(standardized skin surface biopsy) 및 압출법 등이 있으나, 이들은 모두 침습적인 생검 방법이다. 이러한, 생검을 통한 분석 방법은 검사자의 고 도의 훈련이 요구되며, 검사자의 숙련도에 의존적임에 따라 검사자 또는 측정 시기 마다 일관적인 결과 값이 도 출되지 않을 수 있다. 즉, 이러한 종래의 모낭충에 대한 측정 및 평가 방법은 검사자의 주관적인 직관이나 경험에 근거하기 때문에, 객관적이거나 일관적이지 않을 수 있으며, 환자들에게 침습적인 생검에 대한 부담이 가중될 수 있다. 이에, 모낭충의 측정 방법은 검사 접근성 자체가 어려움에 따라 실제 임상 환경에서 직접적으로 이용되지 못하 고 있는 실정이며, 극소수의 대형병원에서만 모낭충에 대한 측정이 이루어지고 있다. 한편, 피부 진단에 있어, U-net과 같은 인공 지능 기술 기반의 정보 제공 시스템이 다수 적용되고 있다. 그러 나, 모낭충과 관련된 피부 진단의 경우, 모낭충을 진단 및 측정할 수 있는 의료 기관이 제한되어 있으며, 이에 따라, 모낭충의 진단 및 측정이 인공 지능 기술 적용에 제한적이었다. 나아가, 종래의 피부 진단 방법의 경우,얼굴 피부 영상의 종류에 따라 재현성이 떨어지는 한계가 있다. 이에, 본 발명의 발명자들은 모낭충에 대한 측정(확인) 및 평가에 있어, 얼굴 내 특정 영역을 세분화하여 확인 할 경우, 보다 일관적인 결과를 가질 수 있다는 것을 주목하였다. 즉, 본 발명의 발명자들은 얼굴 내 영역이 패턴으로 세분화되어 단위 예측이 수행될 경우, 다양한 피부 병변 예측에 있어 인공 지능이 보다 효과적으로 학 습될 수 있다는 것을 인지하였다. 나아가, 본 발명의 발명자들은 얼굴 내 특정 영역 즉, 모낭충이 분포되어 있을 것으로 예측되는 관심 영역이 인 공 지능에 의하여 보다 정확하게 세분화될 수 있다는 것을 발견하였다. 보다 구체적으로, 본 발명의 발명자들은 알고리즘(모델)에 의하여, 병변 영역이 전체 영역(global) 및 특정 부 분 영역(local)으로 세분화되어 학습 및 예측될 경우, 개체(환자)의 모낭충에 대한 밀도를 높은 정확도로 예측 할 수 있다는 인지하였다. 더욱이, 본 발명자들은 약 지도 학습(Weakly Supervised Learning)을 이용할 경우, 특정 부분 영역을 세분화하 기 위한 관심 영역(ROI) 패치가 모델에 의하여 자동적으로 추출될 수 있다는 것을 발견하였다. 결국, 본 발명의 발명자들은, 얼굴 영상을 입력으로 하는 모델(알고리즘), 얼굴 영상 내에서 주요 관심 부분만 을 강조한 영상을 자동으로 탐색하여 패치로 추출하고, 이를 다시 입력으로 하는 모델(알고리즘) 및 임상 데이 터를 입력으로 하는 모델(알고리즘)이 결합된 앙상블 (Ensemble) 모델을 포함함으로써, 보다 높은 정확도를 가 지는 모낭충에 대한 밀도 예측 시스템을 개발하였다. 나아가, 본 발명의 발명자들은 얼굴 영상 내에서 주요 관심 영역이 해부학적 구조에 기반하여 선택되지 않고, 인공 지능에 의하여 자동으로 선택되어 제시될 경우, 보다 높은 정확도로 모낭충에 대한 밀도 및 분포를 예측할 수 있다는 것을 발견하였다. 따라서, 본 발명이 해결하고자 하는 과제는 얼굴 영상, 패치, 임상 정보 각각을 입력으로 하는 각각의 예측 모 델을 이용하여 1차적으로 모낭충에 대한 밀도 확률을 예측하고, 각각의 예측 모델로부터 도출된 데이터를 합쳐 다시 학습하는 최종 예측 모델을 이용하여 높은 정확도의 최종 밀도 확률을 제공하도록 구성된 모낭충에 대한 정보 제공 방법 및 이에 기초한 디바이스를 제공하는 것이다. 본 발명의 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재 로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0114742", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 바와 같은 과제를 해결하기 위하여 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법이 제공된 다. 본 정보 제공 방법은, 개체의 얼굴 영상을 수신하는 단계; 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐(feature)를 추출하도록 학습된 제 1 예측 모델에 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐를 추출하는 단계; 제 1 피쳐로부터 중요 영역 맵(saliency map)을 생성하는 단계; 중요 영역 맵으로부터 얼굴 내 관심 영역들을 한 개 이상의 패치(patch)로 획득하는 단계; 한 개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐를 추출하도록 학습된 제 2 예측 모델에 한 개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐 를 추출하는 단계, 및 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 학습된 제 3 예측 모델에 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 최종 밀도 확률을 예 측하는 단계;를 포함한다. 본 발명의 특징에 따르면, 수신하는 단계 후에, 수신된 얼굴 영상으로부터 얼굴 내 랜드마크를 비식별화하는 단 계를 더 포함할 수 있다. 본 발명의 다른 특징에 따르면, 비식별화 하는 단계는, 수신된 얼굴 영상으로부터 얼굴 내 해부학적 구조에 대 한 좌표를 추출하고, 추출된 좌표에 기초하여 얼굴 내 랜드마크를 비식별화하는 단계를 포함할 수 있다. 본 발명의 또 다른 특징에 따르면, 제 1 피쳐를 추출하는 단계 후에, 제 1 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습된 제 1 예측 모델에 제 1 피쳐를 입력으로 하여 개체에 대한 모낭충 의 제 1 밀도 확률을 예측하는 단계를 더 포함할 수 있다. 본 발명의 또 다른 특징에 따르면, 제 1 밀도 확률은, 얼굴 영상에 대한 전역 예측값(global prediction)일 수 있다. 본 발명의 또 다른 특징에 따르면, 제 2 피쳐를 추출하는 단계 후에, 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습된 제 2 예측 모델에 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충 의 제 2 밀도 확률을 예측하는 단계를 더 포함할 수 있다. 본 발명의 또 다른 특징에 따르면, 제 2 밀도 확률은, 패치 영상에 대한 국소 예측값(local prediction)일 수 있다. 본 발명의 또 다른 특징에 따르면, 수신하는 단계는, 개체의 임상 정보를 수신하는 단계를 더 포함하고, 수신하 는 단계 후에, 임상정보를 입력으로 하여 모낭충의 피쳐를 추출하도록 학습된 제 4 예측 모델에 임상 정보를 입 력으로 하여 모낭충에 대한 제 3 피쳐를 추출하는 단계를 더 포함할 수 있다. 본 발명의 또 다른 특징에 따르면, 제 3 예측 모델은, 제 1 피쳐, 제 2 피쳐 및 제 3 피쳐를 입력으로 하여 개 체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습되고, 최종 밀도 확률을 예측하는 단계는, 제 3 예측 모델 에 제 1 피쳐, 제 2 피쳐 및 제 3 피쳐를 입력으로 하여 개체에 대한 모낭충의 최종 밀도 확률을 예측하는 단계;를 포함할 수 있다. 본 발명의 또 다른 특징에 따르면, 임상 정보에 기초하여 특성 중요도를 출력하는 단계를 더 포함할 수 있다. 본 발명의 또 다른 특징에 따르면, 최종 밀도 확률을 예측하는 단계의 제 1 피쳐는, 풀링(pooling)된 벡터 (vector)값일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 최종 밀도 확률을 예측하는 단계의 제 2 피쳐는, 어탠션 스코어가 적용된 벡 터 값(attention-weighted representation Z vector) 값일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 제 2 피쳐를 추출하는 단계는, 추출된 제 2 피쳐에 어탠션 스코어(attention score)를 적용하는 단계를 더 포함할 수 있다. 본 발명의 또 다른 특징에 따르면, 어탠션 스코어를 적용하는 단계는, 한 개 이상의 패치들이 하나의 배치 (batch)로 1개 이상의 FC 레이어에 입력되는 단계; FC 레이어로부터 출력된 로짓(logit)에 기초하여 어탠션 스 코어(attention score)를 출력하는 단계, 및 출력된 어탠션 스코어를 제 2 피쳐에 곱해주는 단계를 포함할 수 있다. 본 발명의 또 다른 특징에 따르면, 제 1 예측 모델은, 얼굴 영상을 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 제 2 예측 모델은, 패치를 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 제 3 예측 모델은, 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 분류 0은, 1 cm2 당 모낭충의 마릿수가 0 이상 내지 5 미만이고, 분류 1은, 1 cm2 당 모낭충의 마릿수가 5 이상일 수 있으나, 이에 제한되는 것은 아니다. 전술한 바와 같은 다른 과제를 해결하기 위하여 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공용 디바이 스가 제공된다. 본 발명의 모낭충에 대한 정보 제공용 디바이스는, 개체의 얼굴 영상을 수신하도록 구성된 통 신부, 및 통신부와 통신하도록 연결된 프로세서를 포함하고, 프로세서는, 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐(feature)를 추출하도록 학습된 제 1 예측 모델에 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐를 추출하고, 제 1 피쳐로부터 중요 영역 맵(saliency map)을 생성하고, 중요 영역 맵으로부터 얼굴 내 관심 영역들을 한 개 이상의 패치(patch)로 획득하고, 한 개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐를 추출하도록 학습된 제 2 예측 모델에 한 개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐를 추 출하고, 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 학습된 제 3 예측 모델에 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 최종 밀도 확률을 예측하도록 구성 될 수 있다. 본 발명의 특징에 따르면, 프로세서는, 수신된 얼굴 영상으로부터 얼굴 내 랜드마크를 비식별화하도록 더 구성 될 수 있다. 본 발명의 다른 특징에 따르면, 프로세서는, 수신된 얼굴 영상으로부터 얼굴 내 해부학적 구조에 대한 좌표를 추출하고, 추출된 좌표에 기초하여 얼굴 내 랜드마크를 비식별화하도록 구성될 수 있다. 본 발명의 또 다른 특징에 따르면, 프로세서는, 제 1 피쳐를 추출한 후에, 제 1 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습된 제 1 예측 모델에 제 1 피쳐를 입력으로 하여 개체에 대한 모 낭충의 제 1 밀도 확률을 예측하도록 더 구성될 수 있다. 본 발명의 또 다른 특징에 따르면, 제 1 밀도 확률은, 얼굴 영상에 대한 전역 예측값(global prediction)일 수 있다. 본 발명의 또 다른 특징에 따르면, 프로세서는, 제 2 피쳐를 추출하는 단계 후에, 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습된 제 2 예측 모델에 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 제 2 밀도 확률을 예측하도록 더 구성될 수 있다. 본 발명의 또 다른 특징에 따르면, 제 2 밀도 확률은, 패치 영상에 대한 국소 예측값(global prediction)일 수 있다. 본 발명의 또 다른 특징에 따르면, 통신부는, 개체의 임상 정보를 수신하도록 더 구성되고, 프로세서는, 임상정 보를 입력으로 하여 모낭충의 피쳐를 추출하도록 학습된 제 4 예측 모델에 임상 정보를 입력으로 하여 모낭충에 대한 제 3 피쳐를 추출하도록 더 구성될 수 있다. 본 발명의 또 다른 특징에 따르면, 제 3 예측 모델은, 제 1 피쳐, 제 2 피쳐 및 제 3 피쳐를 입력으로 하여 개 체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습되고, 프로세서는, 제 3 예측 모델에, 제 1 피쳐, 제 2 피 쳐 및 제 3 피쳐를 입력으로 하여 개체에 대한 모낭충의 최종 밀도 확률을 예측하도록 구성될 수 있다. 본 발명의 또 다른 특징에 따르면, 프로세서는, 임상 정보에 기초하여 특성 중요도를 출력하도록 더 구성될 수 있다. 본 발명의 또 다른 특징에 따르면, 제 3 예측 모델에 입력되는 제 1 피쳐는, 풀링(pooling)된 벡터(vector)값일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 제 3 예측 모델에 입력되는 제 2 피쳐는, 어탠션 스코어가 적용된 벡터 값 (attention-weighted representation Z vector)일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 프로세서는, 추출된 제 2 피쳐에 어탠션 스코어(attention score)를 적용하 도록 더 구성될 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 프로세서는, 한 개 이상의 패치들이 하나의 배치(batch)로 1개 이상의 FC 레 이어에 입력되고, FC 레이어로부터 출력된 로짓(logit)에 기초하여 어탠션 스코어(attention score)가 출력되고, 출력된 어탠션 스코어를 제 2 피쳐에 곱해주도록 더 구성될 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 제 1 예측 모델은, 얼굴 영상을 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 제 2 예측 모델은, 패치를 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 제 3 예측 모델은, 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 또 다른 특징에 따르면, 분류 0은, 1 cm2 당 모낭충의 마릿수가 0 이상 내지 5 미만이고, 분류 1은, 1 cm2 당 모낭충의 마릿수가 5 이상일 수 있으나, 이에 제한되는 것은 아니다. 실시예의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2023-0114742", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은, 비침습적으로 모낭충에 대한 진단 및 예측을 객관적으로 빠르게 수행할 수 있음에 따라, 생검에 따 른 환자의 심리적 비용적 부담을 감소시킬 수 있으며, 나아가, 실제 임상 실무에 있어서 의료진의 워크 플로우 를 향상시킬 수 있다. 더 나아가, 의료진은 결과에 따른 적절한 치료 방법을 빠르게 선택할 수 있어, 본 발명 의 주사를 포함하는 모낭충에 의한 피부 질환 치료 예후에 긍적적인 치료 결과를 기여할 수 있는 효과가 있다.나아가, 본 발명은 비식별화 방법을 포함함에 따라, 개인에 대한 초상 및 신상 정보가 안전하게 보호될 수 있다. 더욱이, 본 발명은 비식별화된 얼굴 영상 및 패치 영상을 제공함으로써, 관심 영역 이외의 다른 영역으로부터의 간섭이 최소화될 수 있으며, 관심 영역 내 모낭충에 대하여 보다 정확한 밀도 및 분포를 예측할 수 있다. 더 나아가, 본 발명은 얼굴 전체 및 얼굴 영역 각각에 대한 모낭충에 대한 밀도 확률을 예측함으로써, 보다 세 밀하게 모낭충에 대한 밀도 확률을 예측할 수 있을 뿐만 아니라, 모낭충에 대한 얼굴 내 분포를 확인 및 예측할 수 있다. 더 나아가, 본 발명은 모든 데이터를 학습 및 평가에 이용될 수 있는 교차 검증이 수행됨에 따라, 데이터의 편 중을 방지할 수 있으며, 소수의 데이터로도 높은 정확도를 가질 수 있으며, 이에 따라, 높은 신뢰도의 모낭충의 밀도 확률을 예측할 수 있다. 더 나아가, 본 발명은 얼굴 영상에 대한 중요 영역 맵(saliency map) 포함함에 따라, 모낭충의 밀도 확률에 있 어, 얼굴 내 영역에 대한 각 기여도 즉, 병변의 분포를 보다 쉽게 가시적으로 확인할 수 있다. 더 나아가, 임상정보에 기초하여 특성 중요도를 출력하는 단계를 더 포함함에 따라, 모낭충의 밀도 확률에 미치 는 개체의 임상정보에 대한 기여도를 보다 쉽게 가시적으로 확인할 수 있다. 본 발명에 따른 효과는 이상에서 예시된 내용에 의해 제한되지 않으며, 더욱 다양한 효과들이 본 명세서 내에 포함되어 있다."}
{"patent_id": "10-2023-0114742", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하"}
{"patent_id": "10-2023-0114742", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조부 호가 사용될 수 있다. 본 문서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 문서에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\" 등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하 나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 문서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 예를 들면, 제1 사용자 기기와 제2 사용자 기기는, 순서 또는 중요도와 무관하게, 서로 다른 사용자 기기를 나타낼 수 있다. 예를 들면, 본 문서에 기재된 권리범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 바꾸어 명명될 수 있다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 문서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~ 를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 디바이스\"라는 표현은, 그 디 바이스가 다른 디바이스 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된)프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로 세서), 또는 메모리 디바이스에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수 행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 문서에서 사용된 용어들은 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다른 실시예의 범위를 한정 하려는 의도가 아닐 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할"}
{"patent_id": "10-2023-0114742", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 문서에 기재된 기술분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 문서에 사용된 용어 들 중 일반적인 사전에 정의된 용어들은, 관련 기술의 문맥상 가지는 의미와 동일 또는 유사한 의미로 해석될 수 있으며, 본 문서에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 경우에 따라서, 본 문서에서 정의된 용어일지라도 본 문서의 실시 예들을 배제하도록 해석될 수 없다. 본 발명의 여러 실시예들의 각각 특징들이 부분적으로 또는 전체적으로 서로 결합 또는 조합 가능하며, 당업자 가 충분히 이해할 수 있듯이 기술적으로 다양한 연동 및 구동이 가능하며, 각 실시예들이 서로에 대하여 독립적 으로 실시 가능할 수도 있고 연관 관계로 함께 실시 가능할 수도 있다. 본 명세서의 해석의 명확함을 위해, 이하에서는 본 명세서에서 사용되는 용어들을 정의하기로 한다. 본 명세서에서 사용되는 용어, \"개체\"는 모낭충을 예측하고자 하는 모든 대상을 의미할 수 있다. 예를 들어, 개체는, 모낭충에 의한 피부질환 의심 개체일 수도 있다. 이때, 본 명세서 내에 개시된 개체는, 인간을 제외한 모든 포유 동물일 수 있으나, 이에 제한되는 것은 아니다. 본 명세서에서 사용되는 용어, \"얼굴 영상\"은, 영상 진단 디바이스로부터 획득된 안면 영상을 의미할 수 있다. 이때, 얼굴 영상은 개체의 안면 영역을 포함하는 의료 영상일 수 있다. 한편, 얼굴 영상은, 복수 개의 컷으로 구성된 동영상일 수 있다. 이때, 동영상은 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 따라 동영상의 프레임 각각에 대하여 얼굴 즉, 개체의 안면 영역 및 모낭충에 대한 분포, 모낭충에 대한 밀도가 결정 및 예측될 수 있다. 이하에서는 도 1a 내지 1d를 참조하여, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공용 디바이스에 기 초한 모낭충에 대한 정보 제공 시스템을 설명한다. 도 1a는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공용 디바이스에 기초한 모낭충에 대한 정보 제공 시스템을 예시적으로 도시한 것이다. 먼저, 도 1a를 참조하면, 모낭충에 대한 정보 제공 시스템은, 개체에 대한 얼굴 영상을 기초로 모낭충과 관련된 정보를 제공하도록 구성된 시스템일 수 있다. 이때, 모낭충에 대한 정보 제공 시스템은, 개체의 얼굴 즉, 안면부를 포함하는 영상을 기초하여 개체에 대한 모낭충의 밀도 확률, 모낭충에 대한 분포 확률, 피부 치료 방법을 결정하도록 구성된 모낭충에 대한 정보 제공용 디바이스, 모낭충에 대한 정보를 수신하는 의 료진 디바이스 및 사용자 디바이스로 구성될 수 있다. 이때, 모낭충에 대한 정보 제공용 디바이스, 모낭충에 대한 정보를 수신하는 의료진 디바이스 및 사 용자 디바이스는 유무선통신을 통해 다양한 정보를 송수신할 수 있다. 보다 구체적으로, 모낭충에 대한 정보 제공용 디바이스, 의료진 디바이스 및 사용자 디바이스는 케이블로 직접 연결되어 송수신되는 유선을 통하여 통신할 수 있으나, 바람직하게는 케이블이 생략되어 송수신 되는 무선으로 통신할 수 있다. 이에, 모낭충에 대한 정보 제공용 디바이스, 의료진 디바이스 및 사용자 디바이스는 무선 통신 을 위하여 네트워크(network)에 연결되어 있을 수 있으며, 네트워크는 LAN(Local Area Network) 및 WAN(Wide Area Network)등의 폐쇄형 네트워크일 수 있고, 인터넷(Internet)과 같은 개방형 네트워크일 수도 있으며, 블루 투스(Bluetooth), NFC(Near Field Communication), RFID(Radio-Frequency Identification), Wi-Fi 및/또는 지 그비(Zigbee) 등과 같은 근거리 무선 통신일 수 있으나, 이에 제한되는 것은 아니다. 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공용 디바이스는 사용자 디바이스로부터 제공된 개체의 얼굴 영상을 기초로 모낭충의 밀도 확률 및/또는 모낭충에 대한 분포 확률을 예측하고, 개체에 대한 피 부 치료 방법을 결정하기 위해 다양한 연산을 수행하는 범용 컴퓨터, 랩탑, 및/또는 데이터 서버 등을 포함할 수 있다. 보다 구체적으로, 도 1b를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공용 디바이스의 구성 을 나타낸 블록도가 도시된다. 모낭충에 대한 정보 제공용 디바이스는 통신 인터페이스, 메모리 , I/O 인터페이스 및 프로세서를 포함할 수 있으며, 각 구성은 하나 이상의 통신 버스 또는 신 호 라인을 통해 서로 통신할 수 있다. 통신 인터페이스는 통신부를 의미할 수 있으며, 유/무선 통신 네트워크를 통해 의료진 디바이스 및 사용자 디바이스와 연결되어 데이터를 주고받을 수 있다. 예를 들어, 통신 인터페이스는 사용자 디바이스로 개체에 대한 얼굴 영상을 실시간으로 수신할 수 있다. 다른 예를 들어, 통신 인터페이스(11 0)는 의료진 디바이스로부터 모낭충에 대한 데이터를 송신할 수 있다. 한편, 이러한 데이터의 송수신을 가능하게 하는 통신 인터페이스는 유선 통신 포트 및 무선 회로 를 포함하며, 여기서 유선 통신 포트는 하나 이상의 유선 인터페이스, 예를 들어, 이더넷, 범용 직렬 버스(USB), 파이어 와이어 등을 포함할 수 있다. 또한, 무선 회로는 RF 신호 또는 광학 신호를 통해 외부 디바이스와 데이터를 송수신할 수 있다. 아울러, 무선 통신은 복수의 통신 표준, 프로토콜 및 기술, 예컨대GSM, EDGE, CDMA, TDMA, 블루투스, Wi-Fi, VoIP, Wi-MAX, 또는 임의의 기타 적합한 통신 프로토콜 중 적어도 하나를 사용할 수 있다. 메모리는 모낭충에 대한 정보 제공용 디바이스에서 사용되고, 도출되는 다양한 데이터를 저장할 수 있다. 예를 들어, 메모리는 개체에 대한 얼굴 영상, 개체에 대한 임상정보, 얼굴 영상 및 임상정보로부터 도출되는 모낭충에 대한 밀도 확률, 모낭충에 대한 분포 확률, 얼굴 영상으로부터 도출된 Grad-CAM 데이터, Grad-CAM에 기초한 시각화 영상, 특성 중요도 등과 같은 다양한 데이터를 저장할 수 있다. 또한, 메모리는 제 1 예측 모델, 제 2 예측 모델, 제 3 예측 모델 및 제 4 예측 모델을 저장할 수 있으며, 전술한 예측 모델로부터 추출 또는 생성(예측)된 다양한 데이터 또한 저장할 수 있다. 예를 들어, 메모리(12 0)는 제 1 예측 모델로부터 추출된 제 1 피쳐, 제 2 예측모델로부터 추출된 제 2 피쳐, 제 3 예측 모델로부터 추출된 최종 밀도 확률 및 제 4 예측 모델로부터 추출된 제 3 피쳐를 포함할 수 있으나, 이에 제한되는 것은 아 니다. 나아가, 메모리는 전술한 예측 모델로부터 도출된 데이터뿐만 아니라, 제 1 피쳐로부터 생성된 중요 영역 맵(saliency map) 및 얼굴 영상 또는 중요 영역 맵으로부터 획득된 얼굴 내 관심 영역들에 대한 패치(patch) 등 을 더 포함할 수 있으나, 이에 제한되는 것은 아니다. 다양한 실시예에서, 메모리는 각종 데이터, 명령 및 정보를 저장할 수 있는 휘발성 또는 비휘발성 기록 매 체를 포함할 수 있다. 예를 들어, 메모리는 플래시 메모리 타입, 하드디스크 타입, 멀티미디어 카드 마이 크로 타입, 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램, SRAM, 롬, EEPROM, PROM, 네트워크 저장 스토리지, 클라우드, 블록체인 데이터베이스 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 다양한 실시예에서, 메모리는 운영 체제, 통신 모듈, 사용자 인터페이스 모듈 및 하나 이 상의 애플리케이션 중 적어도 하나의 구성을 저장할 수 있다. 운영 체제(예. LINUX, UNIX, MAC OS, WINDOWS, VxWorks 등의 내장형 운영 체제)는 일반적인 시스템 작업 (예. 메모리 관리, 저장 디바이스 제어, 전력 관리 등)를 제어하고 관리하기 위한 다양한 소프트웨어 컴포넌트 및 드라이버를 포함할 수 있으며, 다양한 하드웨어, 펌웨어, 및 소프트웨어 컴포넌트 간의 통신을 지원할 수 있 다. 통신 모듈은 통신 인터페이스를 통해 다른 디바이스와 통신을 지원할 수 있다. 통신 모듈은 통 신 인터페이스의 유선 통신 포트 또는 무선 회로에 의해 수신되는 데이터를 처리하기 위한 다양 한 소프트웨어 구성 요소들을 포함할 수 있다. 사용자 인터페이스 모듈은 I/O 인터페이스를 통해 키보드, 터치 스크린, 키보드, 마우스, 마이크 등 으로부터 사용자의 요청 또는 입력을 수신하고, 디스플레이 상에 사용자 인터페이스를 제공할 수 있다. 애플리케이션은 하나 이상의 프로세서에 의해 실행되도록 구성되는 프로그램 또는 모듈을 포함할 수 있다. 여기서, 모낭충에 대한 정보를 제공하기 위한 애플리케이션은 서버 팜(server farm) 상에서 구현될 수 있 다. I/O 인터페이스는 모낭충에 대한 정보 제공용 디바이스의 입출력 디바이스(미도시), 예컨대 디스플레 이, 키보드, 터치 스크린 및 마이크 중 적어도 하나를 사용자 인터페이스 모듈과 연결할 수 있다. I/O 인 터페이스는 사용자 인터페이스 모듈과 함께 사용자 입력(예. 음성 입력, 키보드 입력, 터치 입력 등)을 수신하고, 수신된 입력에 따른 명령을 처리할 수 있다. 프로세서는 통신 인터페이스, 메모리 및 I/O 인터페이스와 연결되어 모낭충에 대한 정보 제공용 디바이스의 전반적인 동작을 제어할 수 있으며, 메모리에 저장된 애플리케이션 또는 프로그램 을 통해 모낭충에 대한 정보를 추출하기 위한 다양한 명령들을 수행할 수 있다. 프로세서는 CPU(Central Processing Unit)나 AP(Application Processor)와 같은 연산 장치에 해당할 수 있다. 또한, 프로세서는 다양한 연산 장치가 통합된 SoC(System on Chip)와 같은 통합 칩(Integrated Chip (IC))의 형태로 구현될 수 있다. 또는 프로세서는 NPU(Neural Processing Unit)과 같이 인공 신경망 모델을 계산하기 위한 모듈을 포함할 수 있다. 다시 도 1a를 참조하면, 모낭충에 대한 정보 제공용 디바이스는 사용자 디바이스로부터 얼굴 영상을 수신하고, 수신된 얼굴 영상으로부터 모낭충의 밀도 확률, 모낭충에 대한 분포 확률 및 피부 치료 방법을 의료진 디바이스로 제공할 수 있다. 이와 같이 모낭충에 대한 정보 제공용 디바이스로부터 제공되는 데이터는 의료진 디바이스에 설치된 웹 브라우저를 통해 웹 페이지로 제공되거나, 어플리케이션, 또는 프로그램 형태로 제공될 수 있다. 다양한 실 시예에서 이러한 데이터는 클라이언트-서버 환경에서 플랫폼에 포함되는 형태로 제공될 수 있다. 의료진 디바이스는 개체의 모낭충에 대한 정보 제공을 요청하고 정보 데이터를 나타내기 위한 사용자 인터 페이스를 제공하는 전자 디바이스로서, 스마트폰, 태블릿 PC (Personal Computer), 노트북 및/또는 PC 등 중 적 어도 하나를 포함할 수 있다. 보다 구체적으로, 도 1c를 참조하면, 본 발명의 일 실시예에 따른 의료진 디바이스의 구성에 대한 블록도가 도 시된다. 의료진 디바이스는 메모리 인터페이스, 하나 이상의 프로세서 및 주변 인터페이스 를 포함할 수 있다. 의료진 디바이스 내의 다양한 컴포넌트들은 하나 이상의 통신 버스 또는 신호 라인에 의해 연결될 수 있다. 메모리 인터페이스는 메모리에 연결되어 프로세서로 다양한 데이터를 전할 수 있다. 여기서, 메 모리는 플래시 메모리 타입, 하드디스크 타입, 멀티미디어 카드 마이크로 타입, 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램, SRAM, 롬, EEPROM, PROM, 네트워크 저장 스토리지, 클라우드, 블록체인 데이 터베이스 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 다양한 실시예에서, 메모리는 운영 체제, 통신 모듈, 그래픽 사용자 인터페이스 모듈 (GUI), 센서 처리 모듈, 전화 모듈 및 애플리케이션 모듈 중 적어도 하나 이상을 저장할 수 있다. 구체적으로, 운영 체제는 기본 시스템 서비스를 처리하기 위한 명령어 및 하드웨어 작업들을 수 행하기 위한 명령어를 포함할 수 있다. 통신 모듈은 다른 하나 이상의 디바이스, 컴퓨터 및 서버 중 적어 도 하나와 통신할 수 있다. 그래픽 사용자 인터페이스 모듈(GUI)은 그래픽 사용자 인터페이스를 처리할 수 있다. 센서 처리 모듈은 센서 관련 기능(예를 들어, 하나 이상의 마이크를 이용하여 수신된 음성 입력을 처리함)을 처리할 수 있다. 전화 모듈은 전화 관련 기능을 처리할 수 있다. 애플리케이션 모듈 은 사용자 애플리케이션의 다양한 기능들, 예컨대 전자 메시징, 웹 브라우징, 미디어 처리, 탐색, 이미징, 기타 프로세스 기능을 수행할 수 있다. 아울러, 의료진 디바이스는 메모리에 어느 한 종류의 서비스와 연관된 하나 이상의 소프트웨어 애플 리케이션(256-1, 256-2)을 저장할 수 있다. 이때, 어플리케이션(256-1)은 의료진 디바이스에 모낭충에 대 한 정보를 제공할 수 있다. 다양한 실시예에서, 메모리는 디지털 어시스턴트 클라이언트 모듈(이하, DA 클라이언트 모듈)을 저장 할 수 있으며, 그에 따라 디지털 어시스턴트의 클라이언트 측의 기능을 수행하기 위한 명령어 및 다양한 사용자 데이터(예. 사용자 맞춤형 어휘 데이터, 선호도 데이터, 사용자의 전자 주소록, 할 일 목록, 기타 리스트 등과 같은 기타 데이터)를 저장할 수 있다. 한편, DA 클라이언트 모듈은 의료진 디바이스에 구비된 다양한 사용자 인터페이스(예. I/O 서브시스 템)를 통해 사용자의 음성 입력, 텍스트 입력, 터치 입력 및/또는 제스처 입력을 획득할 수 있다. 또한, DA 클라이언트 모듈은 시청각적, 촉각적 형태의 데이터를 출력할 수 있다. 예를 들어, DA 클라이언 트 모듈은 음성, 소리, 알림, 텍스트 메시지, 메뉴, 그래픽, 비디오, 애니메이션 및 진동 중 적어도 둘 하 나 이상의 조합으로 이루어진 데이터를 출력할 수 있다. 아울러, DA 클라이언트 모듈은 통신 서브시스템 을 이용하여 디지털 어시스턴트 서버(미도시)와 통신할 수 있다. 다양한 실시예에서, DA 클라이언트 모듈은 사용자 입력과 연관된 상황(context)을 구성하기 위하여 다양한 센서, 서브시스템 및 주변 디바이스로부터 의료진 디바이스의 주변 환경에 대한 추가 정보를 수집할 수 있 다. 예를 들어, DA 클라이언트 모듈은 사용자 입력과 함께 상황 정보를 디지털 어시스턴트 서버에 제공하 여 사용자의 의도를 추론할 수 있다. 여기서, 사용자 입력에 동반될 수 있는 상황 정보는 센서 정보, 예를 들어, 광(lighting), 주변 소음, 주변 온도, 주변 환경의 이미지, 비디오 등을 포함할 수 있다. 다른 예를 들 어, 상황 정보는 의료진 디바이스의 물리적 상태(예. 디바이스 배향, 디바이스 위치, 디바이스 온도, 전력 레벨, 속도, 가속도, 모션 패턴, 셀룰러 신호 강도 등)을 포함할 수 있다. 또 다른 예를 들어, 상황 정보는 의 료진 디바이스의 소프트웨어 상태에 관련된 정보(예. 의료진 디바이스에서 실행 중인 프로세스, 설치 된 프로그램, 과거 및 현재 네트워크 활동성, 백그라운드 서비스, 오류 로그, 리소스 사용 등)를 포함할 수 있다. 다양한 실시예에서, 메모리는 추가 또는 삭제된 명령어를 포함할 수 있으며, 나아가 의료진 디바이스(20 0)도 도 1c에 도시된 구성 외에 추가 구성을 포함하거나, 일부 구성을 제외할 수도 있다. 프로세서는 의료진 디바이스의 전반적인 동작을 제어할 수 있으며, 메모리에 저장된 어플리케이 션 또는 프로그램을 구동하여 모낭충에 대한 다양한 정보 인터페이스를 구현하기 위한 다양한 명령들을 수행할 수 있다. 프로세서는 CPU(Central Processing Unit)나 AP(Application Processor)와 같은 연산 장치에 해당할 수 있다. 또한, 프로세서는 NPU(Neural Processing Unit)과 같은 다양한 연산 장치가 통합된 SoC(System on Chip)와 같은 통합 칩(Integrated Chip (IC))의 형태로 구현될 수 있다. 주변 인터페이스는 다양한 센서, 서브 시스템 및 주변 디바이스와 연결되어, 의료진 디바이스가 다양 한 기능을 수행할 수 있도록 데이터를 제공해 줄 수 있다. 여기서, 의료진 디바이스가 어떠한 기능을 수 행한다는 것은 프로세서에 의해 수행되는 것으로 이해될 수 있다. 주변 인터페이스는 모션 센서, 조명 센서(광 센서) 및 근접 센서로부터 데이터를 제공받을 수 있으며, 이를 통해, 의료진 디바이스는 배향, 광, 및 근접 감지 기능 등을 수행할 수 있다. 다른 예를 들어, 주변 인터페이스는 기타 센서들(포지셔닝 시스템-GPS 수신기, 온도 센서, 생체인식 센서)로부 터 데이터를 제공받을 수 있으며, 이를 통해 의료진 디바이스가 기타 센서들과 관련된 기능들을 수행 할 수 있다. 다양한 실시예에서, 의료진 디바이스는 주변 인터페이스와 연결된 카메라 서브시스템 및 이와 연결된 광학 센서를 포함할 수 있으며, 이를 통해 의료진 디바이스는 사진 촬영 및 비디오 클립 녹화 등의 다양한 촬영 기능을 수행할 수 있다. 다양한 실시예에서, 의료진 디바이스는 주변 인터페이스와 연결된 통신 서브 시스템을 포함할 수 있다. 통신 서브 시스템은 하나 이상의 유/무선 네트워크로 구성되며, 다양한 통신 포트, 무선 주파수 송수신기, 광학 송수신기를 포함할 수 있다. 다양한 실시예에서, 의료진 디바이스는 주변 인터페이스와 연결된 오디오 서브 시스템을 포함하 며, 이러한 오디오 서브 시스템은 하나 이상의 스피커 및 하나 이상의 마이크를 포함함으로써, 의료진 디바이스는 음성 작동형 기능, 예컨대 음성 인식, 음성 복제, 디지털 녹음, 및 전화 기능 등을 수 행할 수 있다. 다양한 실시예에서, 의료진 디바이스는 주변 인터페이스와 연결된 I/O 서브시스템을 포함할 수 있다. 예를 들어, I/O 서브시스템은 터치 스크린 제어기를 통해 의료진 디바이스에 포함된 터 치 스크린을 제어할 수 있다. 일 예로서, 터치 스크린 제어기는 정전용량형, 저항형, 적외형, 표면 탄성파 기술, 근접 센서 어레이 등과 같은 복수의 터치 감지 기술 중 어느 하나의 기술을 사용하여 사용자의 접 촉 및 움직임 또는 접촉 및 움직임의 중단을 검출할 수 있다. 다른 예를 들어, I/O 서브시스템은 기타 입 력 제어기(들)를 통해 의료진 디바이스에 포함된 기타 입력/제어 디바이스를 제어할 수 있다. 일 예로서, 기타 입력 제어기(들)은 하나 이상의 버튼, 로커 스위치(rocker switches), 썸 휠(thumb- wheel), 적외선 포트, USB 포트 및 스타일러스 등과 같은 포인터 디바이스를 제어할 수 있다. 다시 도 1a를 참조하면, 결국 의료진 디바이스는 전술한 바와 같은 구성을 포함함에 따라, 모낭충에 대한 정보 제공용 디바이스로부터 모낭충의 밀도 확률, 모낭충에 대한 분포 확률 및 개체에 대한 피부 치료 방 법 등 다양한 모낭충에 대한 정보를 제공받을 수 있다. 한편, 사용자 디바이스는 앞서 도 1c에서 전술한 의료진 디바이스와 동일한 구성을 포함할 수 있다. 이에, 사용자 디바이스는 주변 인터페이스와 연결된 카메라 서브시스템 및 이와 연결된 광학 센서를 포함 할 수 있으며, 이를 통해 사용자의 얼굴 영상을 촬영하고, 이를 모낭충에 대한 정보 제공용 디바이스 및/또는 의료진 디바이스에게 제공할 수 있다. 보다 구체적으로, 도 1d를 참조하면, 본 발명의 일 실시예에 따른 사용자 디바이스에 대한 개략도가 도시된다. 사용자 디바이스는 사용자의 얼굴이 영상으로 촬영될 수 있도록 인터페이스 화면이 구성될 수 있다. 나아가, 사용자 디바이스는 사용자의 얼굴 영상 뿐만 아니라, 사용자의 정보 및 질병에 대한 증상이 사용자에 의하여 입력될 수 있도록 인터페이스 화면이 구성될 수 있다. 이에, 모낭충에 대한 정보 제공용 디바이스는 사용자 디바이스로부터 사용자의 상태를 보다 손쉽게 획득 및 확인할 수 있다. 또한, 사용자 디바이스는 전술한 의료진 디바이스와 동일한 구성을 포함함에 따라, 의료진 디바이스 와 동일하게 모낭충에 대한 정보 제공용 디바이스로부터 수신된 모낭충의 밀도 확률, 모낭충에 대한 분포 확률 및 개체에 대한 피부 치료 방법 등을 수신하고, 수신된 데이터들이 인터페이스 화면을 통하여 표시되어 사용자에게 제공될 수 있다. 다시 도 1a를 참조하면, 사용자 디바이스는 모낭충에 대한 정보 제공용 디바이스에게 얼굴 영상(31 0)을 제공할 수 있는 모든 디바이스를 의미할 수 있다. 이에, 사용자 디바이스는 전술한 바와 같이 스마 트폰, 태블릿 PC (Personal Computer), 노트북 및/또는 PC 등을 포함할 수 있으나, 이에 제한되는 것은 아니며, 미리 저장된 얼굴 영상을 제공할 수 있는 범용 컴퓨터 및/또는 데이터 서버 등을 더 포함할 수 있다. 결국, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공용 디바이스에 기초한 모낭충에 대한 정보 제공 시 스템은 모낭충에 대한 정보 제공용 디바이스, 의료진 디바이스 및 사용자 디바이스를 포함함에 따라, 사용자 디바이스로부터 개체(사용자)에 대한 얼굴 영상을 수신하고, 모낭충에 대한 정보 제공 용 디바이스로부터 수신된 얼굴 영상을 기초로 개체에 대한 모낭충에 대한 밀도 확률, 모낭충에 대한 분포 확률 및 개체에 대한 피부 치료 방법 등에 대한 다양한 정보(데이터)를 예측 및 결정하고, 모낭충에 대한 정보 제공용 디바이스로부터 도출된 모낭충에 대한 다양한 정보(데이터)를 의료진 디바이스 및/또는 사용자 디바이스에게 제공할 수 있다. 그러나, 제한되지 않고, 수신된 얼굴 영상을 기초로 개체에 대 한 모낭충에 대한 밀도 확률, 모낭충에 대한 분포 확률 및 개체에 대한 피부 치료 방법 등에 대한 다양한 정보 (데이터)를 예측 및 결정하는 동작은 의료진 디바이스 또는 사용자 디바이스에서 수행될 수도 있다. 이하에서는, 도 2를 참조하여, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법의 절차를 설명한다. 이때, 설명의 편의를 위하여, 도 3a 내지 9을 참조하여 설명한다. 도 2는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 대한 흐름도이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은, 개체의 얼굴 영상을 수신하는 단계(S210), 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐(feature)를 추출하도록 학습된 제 1 예측 모 델에 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐를 추출하는 단계(S220), 제 1 피쳐로부터 중요 영역 맵(saliency map)을 생성하는 단계(S230), 중요 영역 맵으로부터 얼굴 내 관심 영역들을 한 개 이상의 패치 (patch)로 획득하는 단계(S240), 한 개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐를 추출하도록 학 습된 제 2 예측 모델에 한 개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐를 추출하는 단계(S250) 및 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 학습된 제 3 예측 모델 에 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 최종 밀도 확률을 예측하는 단계(S260)를 포 함할 수 있다, 먼저, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 개체의 얼굴 영상을 수신하는 단계(S210)를 포함할 수 있으며, 개체의 얼굴 영상을 수신하는 단계(S210)에서 개체의 얼굴 영상은 모낭충에 의한 질환 의심 개체에 대한 얼굴 영상을 의미할 수 있다. 또한, 개체의 얼굴 영상은 개체의 상부 영역을 포함하며, 바람직하 게는 목 이상의 안면 영역을 포함하는 영상을 의미할 수 있다. 나아가, 개체의 얼굴 영상을 수신하는 단계(S210)에서는 개체 즉, 사용자의 디바이스로부터 촬영된 얼굴 영상이 수신될 수 있으나, 이에 제한되는 것은 아니며, 범용 컴퓨터, 랩탑, 및/또는 데이터 서버 등에 미리 저장되어 있는 개체의 얼굴 영역이 포함된 영상이 수신될 수 있다. 더 나아가, 개체의 얼굴 영상을 수신하는 단계(S210)에서는 개체의 얼굴 영상뿐만 아니라, 개체의 임상정보를 수신하는 단계를 더 포함할 수 있다. 보다 구체적으로, 개체의 얼굴 영상을 수신하는 단계(S210)에서는 개체의 얼굴 내 병변과 관련된 임상정보를 수신할 수 있으며, 이러한 임상정보는 의료 기관 내 저장된 데이터 및/또는 개체(사용자)의 디바이스 내 문답을 통하여 획득된 데이터를 포함할 수 있으나, 이에 제한되는 것은 아니며, 개체와 얼굴 내 병변과 관련된 다양한 데이터를 모두 포함할 수 있다. 나아가, 임상정보는 성별, 나이, 기저질환, serum eosinophil count, total IgE 및 ECP 등을 포함하는 알레르 기 마커(allergy marker), 가려움증, 간헐적 홍조, 열감, 건조감 및 부종 등을 포함하는 증상 등을 포함할 수 있으나, 이에 제한되는 것은 아니며, 임상정보(연속형 변수인 나이 및/또는 알레르기 마커)는 평균을 0, 분산을 1로 표준화되어, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용될 수 있다. 그 다음, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 수신하는 단계(S210) 후에, 수신된 얼굴 영상으로부터 얼굴 내 랜드마크를 비 식별화하는 단계를 더 포함할 수 있다. 보다 구체적으로, 도 3a를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 따른 비식별 화 과정에 대한 개략도가 도시된다. 먼저, 수신된 얼굴 영상은 자동으로 좌표가 설정되고, 설정된 좌표에 기초하여 얼굴 영역이 탐지되고, 탐지된 얼굴 영역을 기초로 수신된 얼굴 영상 중 안면 부분만이 확대되도록 크로핑(cropping)되고, 크로핑된 영 상 내 얼굴 내 랜드마크가 비식별화 될 수 있다. 나아가, 비식별화가 되는 랜드마크의 기준이 되는 영역은 좌표에 기초하여 설정될 수 있다. 보다 구체적으로, 도 3b를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 따른 비식별 화 과정에서의 좌표에 대한 개략도가 도시된다. 수신된 얼굴 영상은 얼굴 내 해부학적 구조에 기초하여 얼굴 라인, 눈썹, 코 및 입 등의 좌표가 설정되고, 설정된 좌표에 기초하여 얼굴 내 랜드마크가 가려짐으로써, 개체가 비식별화 될 수 있다. 이때, 얼굴 내 랜드마크는 눈 및/또는 입을 포함할 수 있으나, 이에 제한되는 것은 아니며, 얼굴 내 다양한 영역이 포 함될 수 있다. 나아가, 비식별화 방법은 블라인드 또는 모자이크로 수행될 수 있으나, 이에 제한되는 것은 아니며, 개인의 초 상 및 신상 정보가 보호될 수 있는 방법은 모두 포함될 수 있다. 이에, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 비식별화 방법에 의하여, 개인에 대한 초상 및 신상 정보가 안전하게 보호될 수 있다. 더욱이, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 비식별화된 영상을 제공함으로써, 모낭충 이 존재할 것으로 예측되는 관심 영역 이외의 다른 영역으로부터의 간섭이 최소화될 수 있으며, 관심 영역 내 모낭충에 대하여 보다 정확한 밀도 및 분포를 예측할 수 있다. 따라서, 다시 도 2를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 전술한 도 3a 및 3b의 과정을 포함함에 따라, 개체의 얼굴 영상을 수신하는 단계(S210) 후에, 수신된 상기 얼굴 영상으로부터 얼 굴 내 랜드마크를 비식별화 하는 단계를 더 포함할 수 있으며, 이때, 비식별화 하는 단계는, 수신된 상기 얼굴 영상으로부터 얼굴 내 해부학적 구조에 대한 좌표를 추출하고, 추출된 상기 좌표에 기초하여 얼굴 내 랜드마크 를 비식별화하는 단계를 포함할 수 있다. 그 다음, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 제 1 예측 모델에 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐(feature)를 추출하는 단계(S220)를 포함할 수 있으며, 제 1 피쳐를 추출하는 단 계(S220)에서 제 1 예측 모델은, 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐를 추출하도록 학습된 모 델일 수 있다. 보다 구체적으로, 도 4를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 제 1 예측 모델에 대한 학습 및 추론 과정에 대한 예시도가 도시된다. 먼저, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 제 1 예측 모델은 글로벌 모듈 (global module)에 포함될 수 있으며, 글로벌 모듈은 얼굴 영상이 제 1 예측 모델에 입력되어 제 1 피 쳐가 추출되고, 추출된 제 1 피쳐에 컨볼루션 레이어(Convolution Layer, 1x1 conv.) 및 시그모이드 (sigmoid) 함수가 순차적으로 수행됨으로써 중요 영역 맵이 생성되고, 생성된 중요 영역 맵에 fagg 레 이어가 적용되어 제 1 밀도 확률(global prediction)이 예측되는 과정을 포함할 수 있다. 즉, 제 1 예측 모델은 제 1 피쳐의 추출뿐만 아니라, 중요 영역 맵(saliency map) 및 제 1 밀도 확률을 생성(예측)할 수 있다.보다 구체적으로, 얼굴 영상은 (2944, 1920, 3) 픽셀로 조정되고, -1 내지 1 사이의 값으로 정규화될 수 있 으나, 이에 제한되는 것은 아니며, 다양한 크기의 픽셀로 조정될 수 있다. 이때, 얼굴 영상은 얼굴 내 랜 드마크가 비식별화된 영상일 수 있으나, 이에 제한되는 것은 아니며, 의료진 디바이스, 사용자 디바이스 및 의 료 기관 DB 등으로부터 수신되어 비식별화되지 않은 얼굴 영상 또한 포함될 수 있다. 그 다음, 조정된 얼굴 영상은 제 1 예측 모델에 입력될 수 있으며, 이에, 제 1 피쳐(feature maps, 31)가 추출될 수 있다. 나아가, 추출된 제 1 피쳐는 풀링이 수행된 벡터 값으로써, 후술될 제 3 예측 모델 에 이용될 수 있다. 이때, 제 1 예측 모델은 ResNet, XGBoost 및 MLP 중 적어도 하나에 기반한 모델일 수 있으나, 이에 제한되 는 것은 아니며, EfficientNet, AlexNet, GoogLeNet, SENet, GPipe, SqueezeNet, MobileNets, ShuffleNets, ResNet, DenseNet, U-net 및 VGG-Net 모델 및 전술한 모델 중 적어도 두 개 이상의 조합으로 구성된 앙상블 (Ensemble) 모델 중 적어도 하나의 모델일 수 있다. 그러나, 바람직하게 얼굴 영상을 입력으로 하는 제 1 예측 모델은 이미지넷이 전이 학습(ImageNet transfer learning) 된 합성곱 신경망(convolutional neural network, CNN)으로 ResNet 18 및/또는 DenseNet일 수 있다. 즉, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은, 전이 학습된 ResNet 18 및/또는 DenseNet의 제 1 예측 모델을 포함함으로써, 적은 얼굴 영상 데이터에서도 높은 예측력을 가질 수 있게 충분히 학습될 수 있다. 이에, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 학습 데이터의 양에 한계를 극복 할 수 있다. 그 다음, 글로벌 모듈에서 추출된 제 1 피쳐에 컨볼루션 레이어(Convolution Layer, 1x1 conv.) 및 시그모 이드(sigmoid) 함수가 적용되어 중요 영역 맵(saliency map, 33)을 생성(출력)할 수 있다. 나아가, 1x1 크기의 컨볼루션 레이어는 제 1 피쳐를 1 채널로 축소한 것으로 도시되었으나, 이에 제한되는 것은 아니며, 클래스(class) 개수에 따라 사용자가 원하는 다양한 채널(channel)이 도출되도록 설정될 수 있다. 그러나, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서는 모낭충이 있을 것으로 예측되는 클래 스(positive class)만을 출력하기 위하여, 1 채널이 가장 바람직할 수 있다. 즉, 1x1 크기의 컨볼루션 레이어 (1x1 conv layer)는 원하는 개수의 채널로 조절할 수 있는 레이어일 수 있다. 이에, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 글로벌 모듈에서 컨볼루션 레이어의 출력된 결과에 기초하여, 모낭충이 집중되어 있을 것으로 예측되는 영역에 대한 시각화 데이터인 중요 영역 맵을 제 1 피쳐로부터 생성할 수 있다. 이때, 중요 영역 맵은 결과 값이 큰 부분을 이미지 상에 표현하는 시각화 방법 모델을 의미하며, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서는 saliency map이 이용되었으나, 이에 제한되는 것은 아니 며, 특징 맵(feature map)에 가중치(weight)를 곱하여, 히트 맵(heat map)으로 출력하는 시각화 방법 모델인 Grad-cam이 적용될 수 있으며, Grad-cam에서의 가중치(weight)는 미분값(각 특징 맵의 원소가 특정 class에 주 는 영향력)이 이용될 수 있다. 그 다음, 중요 영역 맵에 평균 풀링(average pooling)을 위한 fagg 레이어가 적용되어 제 1 밀도 확률 즉, 얼굴 전체 영역에 대한 모낭충의 밀도 확률인 전역 예측값(global prediction)이 예측될 수 있다. 보다 구체적으로, 중요 영역 맵은 1 채널(num_classes)임에 따라, 글로벌 모듈에서는 차원 축소를 위한 풀 링(pooling)만이 수행되어 중요 영역 맵에 대한 데이터가 1차원으로 평탄화(flatten)될 수 있다. 이때, 풀 링을 위한 fagg 레이어는 중요 영역 맵을 이미지 레벨 클래스 예측(image level class prediction)으로 변 환시킬 수 있는 함수로써, GAP(global average pooling) 또는 GMP(global max pooling)가 이용될 수 있으나, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공방법은 top t % average pooling(t=hyperparameter)이 바 람직할 수 있다. 이에, 글로벌 모듈에서 제 1 예측 모델은 얼굴 영상을 입력으로 하여 분류 0(class 0) 및 분류 1(class 1) 에 대한 확률을 예측하도록 학습된 모델일 수 있으며, 제 1 밀도 확률인 전역 예측값(global prediction)은 얼 굴 영상으로부터 도출된 개체의 모낭충에 대한 밀도 예측 값을 의미할 수 있으며, 분류 0(class 0) 및 분류 1(class 1)에 대한 확률로 예측되어 표시될 수 있다. 예를 들어, 분류 0(class 0)은 1 cm2 당 모낭충의 마릿수가 0 이상 내지 5 미만이고, 분류 1(class 1)은 1 cm2 당 모낭충의 마릿수가 5 이상일 수 있으나, 이에 제한되는 것은 아니다. 나아가, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서의 제 1 예측 모델은 전술된 분류 0(class 0) 및 분류 1(class 1)과 같이 이진 분류(binary classification)로 예측 결과를 나타낼 수 있으나, 이에 제한되는 것은 아니며, 다중 분류(multi classification)로 2개 이상의 출력값을 가질 수 있다. 결국, 다시 도 2를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 전술한 도 4에서의 과정을 포함함에 따라, 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐(feature)를 추출하도록 학습된 제 1 예측 모델에 얼굴 영상을 입력으로 하여 모낭충에 대한 제 1 피쳐를 추출하는 단계(S220) 및 제 1 피쳐로부터 중요 영역 맵(saliency map)을 생성하는 단계(S230)를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 제 1 피쳐를 추출하는 단계 후에, 제 1 피 쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습된 제 1 예측 모델에 제 1 피쳐를 입 력으로 하여 상기 개체에 대한 모낭충의 제 1 밀도 확률을 예측하는 단계를 더 포함할 수 있다. 즉, 제 1 피쳐를 추출하는 단계(S220), 중요 영역 맵을 생성하는 단계(S230) 및 제 1 밀도 확률을 예측하는 단 계는 제 1 예측 모델을 포함하는 하나의 글로벌 모듈(global module) 내에서 수행될 수 있으나, 이에 제한되는 것은 아니다. 그 다음, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 중요 영역 맵으로부터 얼굴 내 관심 영 역들을 한 개 이상의 패치(patch)로 획득하는 단계(S240)를 포함할 수 있으며, 패치는 중요 영역 맵에 기초한 검색 알고리즘에 따라 획득될 수 있다. 보다 구체적으로, 도 5를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 패치 획득 과정에 대한 예시도가 도시된다. 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 패치는 중요 영역 맵에서 관 심 영역이 검색(retrieve ROI)되고, 검색된 관심 영역에 기초하여 패치 맵(patch map, 35)이 생성되고, 생성된 패치 맵에서의 위치 정보 데이터에 기초하여 얼굴 영상으로부터 획득될 수 있다. 이때, 패치 획득 과정에서 이용되는 중요 영역 맵은 광역 모듈(global module)에서 생성된 중요 영역 맵일 수 있으나, 이에 제한되는 것은 아니다. 즉, 얼굴 영상 또는 중요 영역 맵으로부터 얼굴 내 관심 영역들을 한 개 이상의 패치로 획득될 수 있다. 나아가, 관심 영역 검색(retrieve ROI)에 의하여 획득된 패치 위치(patch location) 정보(6, )를 이용하여 원 본 얼굴 영상으로부터 R, G, B (Red, Green, Blue 색 조합으로 나타낸 3 채널 컬러 이미지) 채널 별로 패치 (N, 18, 256, 256)가 획득될 수 있다. 이러한, 패치 획득 과정은 패치 검색 알고리즘에 의하여 수행될 수 있으며, 패치 검색 알고리즘은 고정된 사이 즈의 윈도우가 이동하면서 윈도우 내에 있는 데이터를 판별하는 알고리즘을 의미할 수 있다. 즉, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 패치 검색 알고리즘은 슬라이딩 윈도우(sliding window) 알고리즘으로써, (256, 256, 3) 크기의 슬라이딩 윈도우가 중요 영역 맵 또는 얼굴 영상을 이 동하면서, 값의 합이 가장 큰 ROI(region of interest)를 포착하고, 해당 좌표에 대한 데이터를 크롭(crop)하여, 패치로 획득(추출)할 수 있다. 이에, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 패치의 크기는 슬라이딩 윈 도우 크기인 (256, 256, 3)일 수 있으나, 이에 제한되는 것은 아니며, 사용자에 의하여 다양한 크기로 설정될 수 있다. 나아가, 패치의 개수는 개체의 얼굴 영상 및/또는 중요 영역 맵에서의 ROI에 따라 다양할 수 있으나, 본 발 명의 일 실시예에서는 1 내지 10개일 수 있으나, 이에 제한되는 것은 아니며, 바람직한 패치의 개수는 6개 일 수 있다. 결국, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서의 패치는 얼굴의 해부학적 구조에 기 초하여 기 설정된 영역의 패치가 아닌, 머신러닝(인공지능)에 의하여 모낭충이 분포되어 있을 것으로 예측되는 영역이 자동으로 선택되어 획득된 패치를 의미할 수 있다. 따라서, 패치는 개체마다 획득되는 위치 및 개수가 상이할 수 있으며, 본 발명의 일 실시예에 따른 모낭충 에 대한 정보 제공 방법은 모낭충이 분포되어 있을 것으로 예측되는 영역의 패치만을 이용함에 따라, 보다 정확 한 모낭충에 대한 밀도 확률을 예측할 수 있다. 다시, 도 2를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 제 2 예측 모델에 한 개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐를 추출하는 단계(S250)를 포함할 수 있다. 보다 구체적으로, 도 6a을 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 제 2 예측 모델에 대한 학습 및 추론 과정에 대한 예시도가 도시된다. 먼저, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 제 2 예측 모델은 로컬 모듈(local module)에 포함될 수 있으며, 로컬 모듈은 얼굴 영상 및/또는 중요 영역 맵으로부터 획득된 패치가 제 2 예측 모델에 입력되어 제 2 피쳐가 추출되고, 추출된 제 2 피쳐에 어탠션(attention)이 적용 되고, 어탠션이 적용된 제 2 피쳐에 fc 레이어(Fully Connected Layer, fc layer) 및 소프트맥스 (softmax) 함수가 순차적으로 수행됨으로써 제 2 밀도 확률(local prediction)이 추출(예측)되는 과정을 포함할 수 있다. 즉, 제 2 예측 모델은 제 2 피쳐 뿐만 아니라, 제 2 밀도 확률을 생성(예측)할 수 있다. 보다 구체적으로, (256, 256, 3) 크기의 패치(patches, 15)는 제 2 예측 모델에 입력될 수 있으며, 이에 (n, 6, 512) 크기의 제 2 피쳐(feature maps, 41)가 추출될 수 있다. 이때, 패치는 앞서 도 5에서의 과정 에 획득된 패치일 수 있음에 따라, R, G, B 채널에 따른 패치(N, 18, 256, 256)일 수 있다. 그 다음, 패치는 제 2 예측 모델에 입력되기 전, reshape 함수가 적용되어 (N*6, 3, 256, 256)으로 형 태 및 구조(행 및 열)가 변경될 수 있다. 즉, 제 2 예측 모델에 입력되는 한 개 이상의 패치는 R, G, B 정보를 포함하는 6개의 패치로써, 일렬의 배치(batch) 형태로 입력될 수 있다. 이때, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 제 2 예측 모델에 입력되는 패치의 개수는 6개인 것으로 나타나나, 이에 제한되는 것은 아니며, 개체에 따라 획득되는 패치가 다를 수 있음에 따라, 입력되는 패치의 개수는 개체마다 다를 수 있거나, 사용자에 의하여 자유롭게 설정될 수 있다. 나아가, 제 2 예측 모델은 제 1 예측 모델과 마찬가지로, ResNet, XGBoost 및 MLP 중 적어도 하나에 기반한 모델일 수 있으나, 이에 제한되는 것은 아니며, EfficientNet, AlexNet, GoogLeNet, SENet, GPipe, SqueezeNet, MobileNets, ShuffleNets, ResNet, DenseNet, U-net 및 VGG-Net 모델 및 전술한 모델 중 적어도 두 개 이상의 조합으로 구성된 앙상블(Ensemble) 모델 중 적어도 하나의 모델일 수 있다. 그러나, 바람직하게 패치을 입력으로 하는 제 2 예측 모델은 이미지넷이 전이 학습(ImageNet transfer learning) 된 합성곱 신경망(convolutional neural network, CNN)으로 ResNet 18 및/또는 DenseNet일 수 있다. 즉, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은, 전이 학습된 ResNet 18 및/또는 DenseNet의 제 2 예측 모델을 포함함으로써, 적은 패치 데이터에서도 높은 예측력을 가질 수 있게 충분히 학습될 수 있 다. 이에, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 학습 데이터의 양에 한계를 극복할 수 있다. 그 다음, 제 2 피쳐는 어탠션 모듈(attention module)에 의하여 도출된 어탠션 스코어(attention score)가 적용될 수 있다. 보다 구체적으로, 도 6b를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 어탠션 모 듈의 구성을 나타내는 블록도이다. 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서의 어탠션 모듈은 제 2 예측 모델이 하나 이상의 패치 중 어느 패치에 집중하여 학습하였는지를 나타내는 어탠션 스코어(attention score)를 도출(계산)할 수 있 는 모듈로써, 3개의 fc 레이어(fully connected layer) 및 3개의 활성 함수(activation)를 포함할 수 있으나, 이에 제한되는 것은 아니다. 이때, 활성 함수는 비선형성을 증가시켜 복잡한 패턴의 인식 효율을 향상시킬 수 있는 함수로써, 시그모이드 (sigmoid), 탄젠트(hyperbolic tangent, tanh) 및 소프트맥스(softmax)를 포함한 것으로 나타나나, 이에 제한 되는 것은 아니며, 출력의 효율을 위하여 데이터의 비선형성을 증가시키거나 데이터를 압축하여 나타낼 수 있는 다양한 함수는 모두 포함되어, 본 발명의 어탠션 모듈에서 이용될 수 있다.나아가, 활성 함수의 순서 및 배치 또한, 시그모이드(sigmoid), 탄젠트(hyperbolic tangent, tanh) 및 소프트 맥스(softmax) 순으로 제한되는 것은 아니며, 사용자에 의하여 자유롭게 설정될 수 있으나, 시그모이드 (sigmoid) 또는 탄젠트(hyperbolic tangent, tanh)가 먼저 배치되어 fc 레이어의 뉴런을 활성화하고, 소프트맥 스(softmax)가 마지막에 배치되어 어탠션을 계산하는 것이 가장 바람직할 수 있다. 이에, 제 2 피쳐는 어탠션 모듈에 입력되어 6개의 로짓(logit)으로 출력되며, 출력된 로짓에 소프트맥스의 출력 값(softmax output)을 곱하여 각 패치에 대한 어탠션 스코어(attention score=prob, Probability)가 도출(출력)할 수 있다. 다시 도 6a를 참조하면, 전술한 도 6b의 과정으로 도출된 어탠션 스코어는 각 패치마다 도출(출력)될 수 있으며, 도출된 어탠션 스코어는 제 2 피쳐에 곱하여 이용될 수 있다. 이에, 제 2 피쳐는 어탠션 스코 어가 적용된 출력 벡터 값(attention-weighted representation Z vector)으로 출력될 수 있다. 이때, 어탠션 스코어가 적용된 출력 벡터 값(attention-weighted representation Z vector)은 후술될 제 3 예측 모델에 입력 데이터로 이용될 수 있다. 그 다음, 출력된 벡터 값은 fc 레이어에 입력되어 각 패치를 라벨로 분류될 수 있으며, fc 레이어에 의해 출력 된 분류 값은 다시 소프트맥스(softmax) 함수가 적용되어 클래스가 분류될 수 있다. 즉, 로컬 모듈에서는 분류기(classifier)인 fc 레이어 및 소프트맥스를 포함함에 따라, 출력된 벡터 값이 제 2 밀도 확률인 국소 예 측값(local prediction)으로 예측될 수 있다. 이때, fc 레이어에 의해 출력된 분류 값 또한, 후술될 제 3 예측 모델에 입력 데이터로 이용될 수 있다. 이에, 로컬 모듈에서 제 2 예측 모델은 패치를 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델일 수 있으며, 제 2 밀도 확률인 국소 예측값(local prediction)은 패치에 각각 에 대한 예측 값이 아닌 패치로부터 도출된 개체의 모낭충에 대한 밀도 예측 값을 의미할 수 있으며, 분류 0(class 0) 및 분류 1(class 1)에 대한 확률로 예측되어 표시될 수 있다. 예를 들어, 분류 0은 1 cm2 당 모낭충의 마릿수가 0 이상 내지 5 미만이고, 1 cm2 당 모낭충의 마릿수가 5 이상 일 수 있으나, 이에 제한되는 것은 아니다. 나아가, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서의 제 2 예측 모델은 전술된 분류 0(class 0) 및 분류 1(class 1)과 같이 이진 분류(binary classification)로 예측 결과를 나타낼 수 있으나, 이에 제한되는 것은 아니며, 다중 분류(multi classification)로 2개 이상의 출력값을 가질 수 있다. 결국, 다시 도 2를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 전술한 도 6a 및 6b 에서의 과정을 포함함에 따라, 제 2 예측 모델에 한 개 이상의 패치를 입력으로 하여 모낭충에 대한 제 2 피쳐 를 추출하는 단계(S250)를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 제 2 피쳐를 추출하는 단계 후에, 제 2 피 쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습된 제 2 예측 모델에 제 2 피쳐를 입 력으로 하여 개체에 대한 모낭충의 제 2 밀도 확률을 예측하는 단계를 더 포함할 수 있다. 즉, 제 2 피쳐를 추출하는 단계(S250) 및 제 2 밀도 확률을 예측하는 단계는 제 2 예측 모델을 포함하는 하나의 로컬 모듈(local module) 내에서 수행될 수 있으나, 이에 제한되는 것은 아니다. 그 다음, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 제 3 예측 모델에 제 1 피쳐 및 제 2 피 쳐를 입력으로 하여 개체에 대한 모낭충1 최종 밀도 확률을 예측하는 단계(S260)를 포함할 수 있으며, 최종 밀 도 확률을 예측하는 단계(S260)에서 제 3 예측 모델은, 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 학습된 모델일 수 있다. 보다 구체적으로, 도 7을 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법의 전체 학습 및 추론 과정에 대한 예시도가 도시된다. 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 제 1 피쳐를 추출할 수 있는 제 1 예측 모델 을 포함하는 글로벌 모듈(global module), 제 2 피쳐를 추출할 수 있는 제 2 예측 모델을 포함하는 로컬 모듈(local module), 최종 밀도 확률(fusion prediction, 51)을 추출(예측)할 수 있는 제 3 예측 모델 을 포함하는 퓨전 모듈(fusion module) 및 제 3 피쳐를 추출할 수 있는 제 4 예측 모델을 포함하는 임상정보 모듈(clinical data module)을 포함할 수 있다. 먼저, 퓨전 모듈(fusion module)에서 제 3 예측 모델은 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 개체의 모낭충의 밀도 확률을 예측할 수 있으나, 이에 제한되는 것은 아니다. 이때, 제 3 예측 모델에 입력되는 제 1 피쳐는 차원 축소를 위하여 풀링(pooling)이 적용된 벡터 (vector) 값을 의미할 수 있으며, ( , 512)의 크기의 벡터일 수 있다. 보다 구체적으로, 제 1 피쳐로 부터 풀링된 벡터 값은 제 1 예측 모델로부터 추출된 제 1 피쳐에서 각각의 피쳐 맵의 최대값을 추출하 여 연결된 활성화 계층의 벡터 값을 의미할 수 있다. 즉, 제 1 피쳐에 적용된 풀링은 글로벌 최대 풀링 (global max pooling)을 의미할 수 있으나, 이에 제한되는 것은 아니다. 나아가, 제 3 예측 모델에 입력되는 제 2 피쳐는 어탠션(attention)이 적용된 출력 벡터 값 (attention-weighted representation Z vector, 43)을 의미할 수 있으며, ( , 512)의 크기의 벡터일 수 있다. 이에, 제 1 피쳐에 대한 풀링(pooling)이 적용된 벡터(vector) 값 및 제 2 피쳐에 대한 어탠션 (attention)가 적용된 출력 벡터 값은 콘캣(concat) 함수에 의해 하나의 벡터로 합쳐지고, 합쳐진 벡터는 분류기인 fc 레이어(fully connected layer) 및 소프트맥스(softmax)에 학습되어 최종 밀도 확률(fusion prediction, 51)로 출력(예측)될 수 있다. 즉, 제 3 예측 모델은 콘캣(concat) 함수, fc 레이어(fully connected layer) 및 소프트맥스(softmax)를 포함하는 모델을 의미할 수 있으나, 이에 제한되는 것은 아니다. 나아가, 퓨전 모듈에서 제 3 예측 모델은 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 분류 0(class 0) 및 분류 1(class 1)에 대한 확률을 예측하도록 학습된 모델일 수 있으며, 최종 밀도 확률은 얼 개체의 모낭 충에 대한 최종 밀도 예측 값을 의미할 수 있으며, 분류 0(class 0) 및 분류 1(class 1)에 대한 확률로 예측되 어 표시될 수 있다. 예를 들어, 분류 0은 1 cm2 당 모낭충의 마릿수가 0 이상 내지 5 미만이고, 1 cm2 당 모낭충의 마릿수가 5 이상 일 수 있으나, 이에 제한되는 것은 아니다. 나아가, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서의 제 3 예측 모델은 전술된 분류 0(class 0) 및 분류 1(class 1)과 같이 이진 분류(binary classification)로 예측 결과를 나타낼 수 있으나, 이에 제한되는 것은 아니며, 다중 분류(multi classification)로 2개 이상의 출력값을 가질 수 있다. 한편, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 임상정보 모듈(clinical data module)을 더 포함할 수 있다. 보다 구체적으로, 임상정보 모듈은 제 4 예측 모델을 포함할 수 있으며, 제 4 예측 모델 은 임상정보(clinical features, 16)로부터 제 3 피쳐를 추출할 수 있다. 이때, 임상정보는 의료진 디바이스, 사용자 디바이스 및 의료 기관 DB 등으로부터 수신될 수 있으며, 수신 된 임상정보는 (12, 1) 크기로 조정 및 정규화되어 임상 피쳐(clinical features, 16)로 이용될 수 있다. 나아가, 제 4 예측 모델은 ResNet, XGBoost 및 MLP 중 적어도 하나에 기반한 모델일 수 있으나, 이에 제한 되는 것은 아니며, EfficientNet, AlexNet, GoogLeNet, SENet, GPipe, SqueezeNet, MobileNets, ShuffleNets, ResNet, DenseNet, U-net 및 VGG-Net 모델 및 전술한 모델 중 적어도 두 개 이상의 조합으로 구성된 앙상블 (Ensemble) 모델 중 적어도 하나의 모델일 수 있다. 그러나, 바람직하게 임상정보를 입력으로 하는 제 4 예측 모델은 다층 퍼셉트론(Multi layer perceptron, MLP), 랜덤 포레스트(Random Forest) 및 XGBoost 중 적어도 하나일 수 있다. 임상정보 모듈에서 제 4 예측 모델에 의하여 임상정보(clinical features, 16)로부터 제 3 피쳐가 추출 될 수 있으며, 추출된 제 3 피쳐는 제 1 피쳐 및 제 2 피쳐와 함께, 콘캣(concat) 함수에 의해 하 나의 벡터로 합쳐지고, 제 3 예측 모델에 입력되어 개체의 밀도 확률을 예측할 수 있다. 이때, 제 3 피쳐의 크기는 ( , 32)일 수 있으며, 제 1 피쳐, 제 2 피쳐 및 제 3 피쳐가 하나로 합 쳐진 벡터의 크기는 ( , 1056)일 수 있다. 이에, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 제 3 피쳐가 추가로 더 입력되어 이용 됨으로써, 개체의 모낭충에 대한 예측 정확도 및 신뢰도가 더욱 향상될 수 있다. 한편, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 포함된 다양한 학습 절차는 교차 검증 (cross validation) 방법으로 모델을 일반화시킬 수 있다. 나아가, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서의 손실(loss)는 binary cross entropy 손실 함수가 적용되어 도출된 개별 손실 값을 모두 더한 다음, 하기의 [수학식 1]에 적용되어 구할 수 있다. 수학식 1"}
{"patent_id": "10-2023-0114742", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "BCE( : 제 1 밀도확률에 대한 손실함수 BCE( : 제 2 밀도확률에 대한 손실함수 BCE( : 최종 밀도 확률에 대한 손실함수 : 모델 일반화를 위한 정규화(regularization) 수식 이때, 전술한 [수학식 1]은 글로벌 모듈, 로컬 모듈 및 퓨전 모듈에서 획득되는 손실 함수를 모두 포함함에 따 라, 제 1 피쳐, 제 2 피쳐 및 제 3 피쳐 모두에 대한 학습이 가능할 수 있다. 더 나아가, 손실함수에 패널티와 같은 중요 영역 맵 평균 값 을 더함으로써, 일반화된 모델을 얻을 수 있으 며, 이는 필수적이지 않으며, 사용자에 의하여 자유롭게 설정될 수 있다. 더 나아가, 제 4 예측 모델은 임상정보에 기초하여 임상 정보에 대한 특성 중요도가 SHAP로 제공될 수 있다. 보다 구체적으로, 도 8을 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 SHAP 결과에 대한 예시도가 도시된다. 제 4 예측 모델은 임상정보를 입력으로 임상정보가 출력값(모낭충에 대한 밀도 확률)에 미치는 영 향(feature importance)을 SHAP(Shapley Additive exPlanations) 값(value)으로 도시되어 출력될 수 있다. 이에, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 임상정보에 기초하여 특성 중요도를 출력하 는 단계를 더 포함함에 따라, 모낭충의 밀도 확률에 미치는 개체의 임상정보에 대한 기여도를 보다 쉽게 가시적 으로 확인할 수 있다. 결국, 다시 도 2를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 전술한 도 7 및 8에 서의 과정을 포함함에 따라, 제 3 예측 모델에 제 1 피쳐 및 제 2 피쳐를 입력으로 하여 상기 개체에 대한 모낭 충의 최종 밀도 확률을 예측하는 단계(S260)를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 임상 정보를 이용함에 따라, 개체의 임상 정보를 수신하는 단계를 더 포함할 수 있다. 나아가, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 임상정보를 수신하는 단계 후에, 임상정 보를 입력으로 하여 모낭충의 피쳐를 추출하도록 학습된 제 4 예측 모델에 임상 정보를 입력으로 하여 모낭충에 대한 제 3 피쳐를 추출하는 단계를 더 포함할 수 있다. 이에, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 제 3 예측 모델은 제 1 피쳐, 제 2 피쳐 및 제 3 피쳐를 입력으로 하여 개체에 대한 모낭충의 밀도 확률을 예측하도록 더 학습될 수 있으며, 최종 밀도 확률을 예측하는 단계(S260)는 전술한 제 3 예측 모델에 제 1 피쳐, 제 2 피쳐 및 제 3 피쳐를 입력으로 하여 상기 개체에 대한 모낭충의 최종 밀도 확률을 예측하는 단계를 포함할 수 있다. 또한, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 임상정보에 기초하여 특성 중요도를 출력하 는 단계를 더 포함할 수 있다. 그 다음, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 예측된 최종 밀도 확률에 기초하여 치료 가이드 라인을 제공하는 단계를 더 포함할 수 있다. 보다 구체적으로, 도 9를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 대한 최종 모 낭충의 밀도 확률에 대한 예시도가 도시된다.본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 제 3 예측 모델을 통하여 모낭충에 대한 최종 밀도 확률을 예측할 수 있다. 즉, 예측된 개체의 모낭충에 대한 최종 밀도 확률은 분류 0(class 0) 및 분류 1(class 1)의 확률로 출력될 수 있으며, 각각의 분류 마다 치료 가이드 라인이 함께 표시되어 제공될 수 있다. 이때, 가이드 라인은 피부, 연조직 감염 항생제 사용 지침, 임상 진료 지침 등을 포함하는 국내외 질환 가이드 라인이 포함될 수 있으나, 이에 제한되는 것은 아니며, 온오프라인으로 공개된 치료 가이드 라인은 모두 포함될 수 있다. 예를 들어, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 예측 확률이 분류 1(class 1)인 경 우, 항생제(항기생충 국소도포제)에 대한 사용 또는 경구 항기생충제 복용을 권고를 제공할 수 있으며, 이와 더 불어, 주사(rosacea) 질환 가이드 라인에 기초하여 관련 생활 습관 개선 등을 추가로 제공할 수 있다. 이상의 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 따라, 본 발명은 비침습적으로 모낭충에 대한 진단 및 예측을 객관적으로 빠르게 수행할 수 있음에 따라, 생검에 따른 환자의 심리적 비용적 부담을 감 소시킬 수 있으며, 나아가, 실제 임상 실무에 있어서 의료진의 워크 플로우를 향상시킬 수 있다. 더 나아가, 의료진은 결과에 따른 적절한 치료 방법을 빠르게 선택할 수 있어, 본 발명의 주사를 포함하는 모낭충에 의한 피부 질환 치료 예후에 긍적적인 치료 결과를 기여할 수 있는 효과가 있다. 평가 : 본 발명의 다양한 실시예에 이용되는 예측 모델에 대한 평가 이하에서는, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 예측 모델에 대한 평과 결과에 대하여 설명하도록 한다. 도 10은 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법으로 도출된 다양한 이미지 결과가 도시된다. 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 얼굴 영상(input image)을 입력으로 제 1 피쳐에 기초하여 생성된 중요 영역 맵(saliency map), 중요 영역 맵에서의 관심 영역이 검색(retrieve ROI)되어 표시된 패치 맵(patch map), 패치 맵에 기초하여 획득된 패치(patches)가 생성(획득)될 수 있다. 이때, 중요 영역 맵 (saliency map) 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 해부학적 구조에 기준하여 기 설정된 영역만을 추 출하는 방법이 아닌, 머신러닝(인공지능)에 의하여 모낭충이 분포되어 있을 것으로 예측되는 영역이 자동으로 선택되어 표시 및 제시될 수 있음에 따라, 중요 영역 맵(saliency map) 및 패치 맵(patch map)에서의 표시되는 관심 영역과 관심 영역으로부터 획득되는 패치의 위치가 개체마다 다를 수 있다. 이에, 도 10을 참조하면, 개체마다 입력되는 얼굴 영상(input image)이 상이함에 따라, 중요 영역 맵(saliency map) 및 패치 맵(patch map)에서의 표시되는 관심 영역과 관심 영역으로부터 획득되는 패치가 상이한 것으로 나 타난다. 나아가, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 어탠션 모듈에 의하여 각 패치에 대한 어 탠션 스코어(attention score)를 도출(계산)할 수 있다. 이에, 패치 각각에 대한 어탠션 스코어는 패치 상에서 의 피부 상태에 따라 상이하게 도출된 것으로 나타난다. 즉, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법은 개체의 피부 상태에 따라, 개별에게 특화된 모낭충에 대한 피부 상태 및 관련 정보를 제공할 수 있으며, 이에, 본 발명은 높은 정확도로 모낭충에 대한 밀 도 및 분포를 예측할 수 있다. 도 11a 및 11b는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 다양한 예측 모델에 대한 평과 결과이다. 이때, 본 발명의 다양한 실시예에 포함된 예측 모델들은 임상에서 수집된 1,024명의 환자에 대한 안면 이미지 및 임상정보를 기초로 학습되었으며, 학습된 환자 데이터는 분류 0(class 0)으로써 769명 및 분류 1(class 1)으 로써 255명의 데이터가 이용되었다. 또한, 학습 데이터(train data) 및 테스트 데이터(test data)의 비율은 9: 1 로, 학습 데이터는 924개(0:719, 1:205)가 이용되었으며, 테스트 데이터는 100개(0:50, 1:50)가 이용되었 다. 또한, 제 1 예측 모델 및 제 2 예측 모델은 입력되는 데이터가 얼굴 영상 및 패치인 이미지 데이터임에 따 라, ResNet18이 사용되었으며, 제 4 예측 모델은 입력되는 데이터가 임상정보(clinical data)임에 따라, MLP가 사용되었으며, 제 3 예측 모델은 입력되는 데이터가 벡터 값임에 따라, 이를 하나로 합치고, 분류할 수 있는 콘 캣(concat) 함수, fc 레이어(fully connected layer) 및 소프트맥스(softmax)를 포함하는 모델이 사용되었으나, 이의 평가 결과는 해당 모델에 한정되어 해석되어서는 아니된다. 나아가, 각각의 폴드(fold)는 입력되는 데이터를 학습 세트(Training Set/Train) 및 검증 세트(Validation Set/Valid)로 분리한 뒤, 이를 여 러 번 반복하여 병렬로 학습하는 교차 검증(Cross validation)하여 합쳐진 데이터 세트로서, 학습 세트(train) : 검증 세트(valid) : 테스트 세트(test)의 비율은 8 : 2 : 1일 수 있으나, 잉 제한되는 것은 아니다. 먼저, 도 11a의 (a)를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 이미 지 베이스 모델(image based model)에 대한 평가 결과가 도시되며, 이미지 베이스 모델은 얼굴 영상 및 패치와 같은 이미지 데이터를 입력으로 하는 제 1 예측 모델 및 제 2 예측 모델을 포함할 수 있다. 이미지 베이스 모델(image based model)의 검증 예측 값(valid)에 대한 정확도(accuracy) 및 AUC는 fold 1인 경우, 0.775 및 0.8523인 것으로 나타나며, fold 2인 경우, 0.8 및 0.8355인 것으로 나타나며, fold 3인 경우, 0.65 및 0.7031 인 것으로 나타나며, fold 4인 경우, 0.775 및 0.8517 인 것으로 나타나며, fold 5인 경우, 0.7875 및 0.8634 인 것으로 나타나며, fold 6인 경우, 0.7375 및 0.8462 인 것으로 나타나며, fold 7인 경우, 0.85 및 0.8703 인 것으로 나타나며, fold 8인 경우, 0.6875 및 0.7987 인 것으로 나타나며, fold 9인 경우, 0.8125 및 0.8410 인 것으로 나타나며, fold 10인 경우, 0.725 및 0.789 인 것으로 나타난다. 즉, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 이미지 베이스 모델(image based model)의 검증 예측 값에 대한 정확도(accuracy) 및 AUC는 0.65 및 0.7031 이상인 것으로 나타남에 따라, 보통 (normal) 이상의 예측력을 가진다는 것을 의미할 수 있다. 나아가, 이미지 베이스 모델(image based model)의 테스트 예측 값(test)에 대한 정확도(accuracy) 및 AUC는 fold 1인 경우, 0.64 및 0.7286 인 것으로 나타나며, fold 2인 경우, 0.675 및 0.762 인 것으로 나타나며, fold 3인 경우, 0.695 및 0.7453 인 것으로 나타나며, fold 4인 경우, 0.665 및 0.7288 인 것으로 나타나며, fold 5인 경우, 0.69 및 0.7517 인 것으로 나타나며, fold 6인 경우, 0.635 및 0.7399 인 것으로 나타나며, fold 7인 경우, 0.65 및 0.7867 인 것으로 나타나며, fold 8인 경우, 0.665 및 0.7597 인 것으로 나타나며, fold 9인 경우, 0.655 및 0.769 인 것으로 나타나며, fold 10인 경우, 0.66 및 0.7637 인 것으로 나타난다. 즉, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 이미지 베이스 모델(image based model)의 테스트 예측 값에 대한 정확도(accuracy) 및 AUC는 0.635 및 0.7453 이상인 것으로 나타남에 따라, 보통(normal) 이상의 예측력을 가진다는 것을 의미할 수 있다. 그 다음, 도 11a의 (b)를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 임상정보 베이스 모델(clinical data based model)에 대한 평가 결과가 도시되며, 임상정보 베이스 모델은 임상 정보 데이터를 입력으로 하는 제 4 예측 모델을 포함할 수 있다. 임상정보 베이스 모델(clinical data based model)의 검증 예측 값(valid)에 대한 정확도(accuracy) 및 AUC는 fold 1인 경우, 0.7875 및 0.8441 인 것으로 나타나며, fold 2인 경우, 0.725 및 0.8243 인 것으로 나타나며, fold 3인 경우, 0.725 및 0.7703 인 것으로 나타나며, fold 4인 경우, 0.8 및 0.8697 인 것으로 나타나며, fold 5인 경우, 0.7125 및 0.7641 인 것으로 나타나며, fold 6인 경우, 0.7875 및 0.93 인 것으로 나타나며, fold 7인 경우, 0.775 및 0.9048 인 것으로 나타나며, fold 8인 경우, 0.775 및 0.9048 인 것으로 나타나며, fold 9인 경우, 0.7875 및 0.9199 인 것으로 나타나며, fold 10인 경우, 0.8 및 0.9037 인 것으로 나타난다. 즉, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 임상정보 베이스 모델(clinical data based model)의 검증 예측 값에 대한 정확도(accuracy) 및 AUC는 0.725 및 0.7641 이상인 것으로 나타남 에 따라, 보통(normal) 이상의 예측력을 가진다는 것을 의미할 수 있다. 나아가, 임상정보 베이스 모델(clinical data based model)의 테스트 예측 값(test)에 대한 정확도(accuracy) 및 AUC는 fold 1인 경우, 0.665 및 0.783 인 것으로 나타나며, fold 2인 경우, 0.735 및 0.7972 인 것으로 나 타나며, fold 3인 경우, 0.745 및 0.7873 인 것으로 나타나며, fold 4인 경우, 0.705 및 0.7913 인 것으로 나 타나며, fold 5인 경우, 0.67 및 0.7582 인 것으로 나타나며, fold 6인 경우, 0.7 및 0.7898 인 것으로 나타나 며, fold 7인 경우, 0.635 및 0.781 인 것으로 나타나며, fold 8인 경우, 0.755 및 0.7908 인 것으로나타나며, fold 9인 경우, 0.675 및 0.786 인 것으로 나타나며, fold 10인 경우, 0.675 및 0.7956 인 것으로 나타난다. 즉, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 임상정보 베이스 모델(clinical data based model)의 테스트 예측 값에 대한 정확도(accuracy) 및 AUC는 0.635 및 0.7582 이상인 것으로 나타 남에 따라, 보통(normal) 이상의 예측력을 가진다는 것을 의미할 수 있다. 결국, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이미지 베이스 모델(image based model) 및 임상정보 베이스 모델(clinical data based model)은 모낭충에 대한 최종 밀도를 예측 전부터 1차적으로도 보통이상의 높은 정확도로 모낭충에 대한 밀도 및 분포를 예측할 수 있다. 그 다음, 도 11b를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 결합 모 델(conbined model) 및 본 발명에서 이용되는 모델들의 최종 평균에 대한 평가 결과가 도시되며, 결합 모델은 제 1 예측 모델, 제 2 예측 모델 및 제 4 예측 모델로부터 도출된 벡터 값을 입력으로 하는 제 3 예측 모델을 포함할 수 있다. 먼저, 도 11b의 (a)를 참조하면, 결합 모델(conbined model)의 검증 예측 값(valid)에 대한 정확도(accuracy) 및 AUC는 fold 1인 경우, 0.7875 및 0.8145 인 것으로 나타나며, fold 2인 경우, 0.75 및 0.8047 인 것으로 나 타나며, fold 3인 경우, 0.775 및 0.7383 인 것으로 나타나며, fold 4인 경우, 0.8125 및 0.9015 인 것으로 나 타나며, fold 5인 경우, 0.8 및 0.7764 인 것으로 나타나며, fold 6인 경우, 0.75 및 0.8318 인 것으로 나타나 며, fold 7인 경우, 0.8125 및 0.8528 인 것으로 나타나며, fold 8인 경우, 0.6875 및 0.8574 인 것으로 나타 나며, fold 9인 경우, 0.8375 및 0.8593 인 것으로 나타나며, fold 10인 경우, 0.7375 및 0.8862 인 것으로 나 타난다. 즉, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 결합 모델(conbined model)의 검 증 예측 값에 대한 정확도(accuracy) 및 AUC는 0.6875 및 0.7383 이상인 것으로 나타남에 따라, 보통(normal) 이상의 예측력을 가진다는 것을 의미할 수 있다. 나아가, 결합 모델(conbined model)의 테스트 예측 값(test)에 대한 정확도(accuracy) 및 AUC는 fold 1인 경우, 0.708 및 0.8185 인 것으로 나타나며, fold 2인 경우, 0.74 및 0.8016 인 것으로 나타나며, fold 3인 경우, 0.675 및 0.745 인 것으로 나타나며, fold 4인 경우, 0.735 및 0.8162 인 것으로 나타나며, fold 5인 경우, 0.65 및 0.7783 인 것으로 나타나며, fold 6인 경우, 0.73 및 0.7961 인 것으로 나타나며, fold 7인 경우, 0.68 및 0.7973 인 것으로 나타나며, fold 8인 경우, 0.685 및 0.7669 인 것으로 나타나며, fold 9인 경우, 0.615 및 0.8182 인 것으로 나타나며, fold 10인 경우, 0.74 및 0.8092 인 것으로 나타난다. 즉, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 결합 모델(conbined model)의 테 스트 예측 값에 대한 정확도(accuracy) 및 AUC는 0.615 및 0.745 이상인 것으로 나타남에 따라, 보통(normal) 이상의 예측력을 가진다는 것을 의미할 수 있다. 결국, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 결합 모델(conbined model)은 최종적으로 개체의 모낭충에 대하여 높은 정확도로 모낭충에 대한 밀도 및 분포를 예측(분류)하는 것으로 나타 난다. 결과적으로, 도 11b의 (b)를 참조하면, 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되 는 모델에서 10개 폴드(fold)의 성능에 대한 평균(average) 값이 도시되며, 이미지 베이스 모델(image based model)에서 10 폴드의 테스트 예측 값에 대한 정확도(accuracy) 및 AUC는 0.663 및 0.75354 인 것으로 나타나 며, 임상정보 베이스 모델(clinical data based model)에서 10 폴드의 테스트 예측 값에 대한 정확도 (accuracy) 및 AUC는 0.696 및 0.78602 인 것으로 나타나며, 결합 모델(conbined model)에서 10 폴드의 테스트 예측 값에 대한 정확도(accuracy) 및 AUC는 0.6955 및 0.79473 인 것으로 나타난다. 즉, 본 발명에서 이용되는 모델은 모두 보통(normal) 이상의 우수한 예측력을 가진다는 것을 의미할 수 있다.결 국, 본 발명의 다양한 실시예에 따른 밀도 예측 모델은 높은 정확도로 모낭충에 대한 밀도 및 분포를 예측할 수 있음에 따라, 실제 임상에서 생검(biopsy)을 대신하여 모낭충에 대한 진단 시스템에 적용 가능할 수 있다. 이상 첨부된 도면을 참조하여 본 발명의 실시 예들을 더욱 상세하게 설명하였으나, 본 발명은 반드시 이러한 실 시 예로 국한되는 것은 아니고, 본 발명의 기술사상을 벗어나지 않는 범위 내에서 다양하게 변형 실시될 수 있다. 따라서, 본 발명에 개시된 실시 예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시 예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 그러므로, 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 본 발명의 보호 범 위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권 리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0114742", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공용 디바이스에 기초한 모낭충에 대한 정보 제공 시스템을 예시적으로 도시한 것이다. 도 1b는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공용 디바이스의 구성을 나타낸 블록도이다. 도 1c는 본 발명의 일 실시예에 따른 의료진 디바이스의 구성에 대한 블록도이다. 도 1d는 본 발명의 일 실시예에 따른 사용자 디바이스에 대한 개략도이다. 도 2는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 대한 흐름도이다. 도 3a는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 따른 비식별화 과정에 대한 개략도이다. 도 3b는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 따른 비식별화 과정에서의 좌표에 대한 개략도이다. 도 4는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 제 1 예측 모델에 대한 학습 및 추론 과 정에 대한 예시도이다. 도 5는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 패치 획득 과정에 대한 예시도이다. 도 6a는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 제 2 예측 모델에 대한 학습 및 추론 과정에 대한 예시도이다. 도 6b는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 어탠션 스코어 모듈의 구성을 나타내는 블록도이다. 도 7은 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법의 전체 학습 및 추론 과정에 대한 예시도이 다. 도 8은 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 SHAP 결과에 대한 예시도이다. 도 9는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에 대한 최종 모낭충의 밀도 확률에 대한 예 시도이다. 도 10은 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법으로 도출된 다양한 이미지 결과이다. 도 11a 및 11b는 본 발명의 일 실시예에 따른 모낭충에 대한 정보 제공 방법에서 이용되는 다양한 예측 모델에대한 평과 결과이다."}
