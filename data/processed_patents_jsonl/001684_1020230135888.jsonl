{"patent_id": "10-2023-0135888", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0052739", "출원번호": "10-2023-0135888", "발명의 명칭": "가상 아바타 기반의 가상 회의 시스템 및 그것의 동작 방법", "출원인": "주식회사 에이아이파크", "발명자": "박철민"}}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치에 의해 수행되는 가상 회의 시스템의 동작 방법에 있어서,제1 사용자의 아바타를 생성 또는 설정하는 단계;상기 제1 사용자가 제공한 송신 데이터와 상기 아바타에 기초하여 가상 아바타 영상을 생성하는 단계; 및상기 가상 아바타 영상을 이용하여 가상 회의 서비스를 제공하는 단계를 포함하는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 아바타는,3차원 애니메이션 형태를 갖는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 아바타 영상을 생성하는 단계는,상기 송신 데이터를 기초로 제2 사용자가 원하는 언어의 음성을 생성하는 단계; 및상기 아바타와 상기 음성을 기초로, 상기 아바타가 상기 음성을 발화하는 상가 가상 아바타 영상을 생성하는 단계를 포함하는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 송신 데이터는 음성 데이터를 포함하고,상기 음성을 생성하는 단계는,상기 음성 데이터를 STT 모델을 통해 제1 언어의 제1 텍스트로 변환하고,상기 제1 텍스트를 기계 번역 모델을 통해 제2 언어의 제2 텍스트로 변환하고,상기 제2 텍스트를 다중언어 TTS 모델에 입력하여 상기 음성을 생성하는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 송신 데이터는 텍스트 데이터를 포함하고,상기 음성을 생성하는 단계는,상기 텍스트 데이터를 기계 번역 모델을 통해 제2 언어의 제2 텍스트로 변환하고,공개특허 10-2025-0052739-3-상기 제2 텍스트를 다중언어 TTS 모델에 입력하여 상기 음성을 생성하는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,가상 비서를 통한 가상 회의 어시스턴스(assistance) 서비스를 제공하는 단계를 더 포함하는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 가상 회의 어시스턴스 서비스는,가상 회의의 회의 내용을 요약하여 데이터베이스에 저장하는 회의 내용 요약 기능을 포함하는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서,상기 가상 회의 어시스턴스 서비스는,사용자가 가상 회의 중 입력한 이미지 및 영상을 기초로, 설명이 부가된 이미지 및 영상을 제공하는 자료 요약기능을 포함하는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6 항에 있어서,상기 가상 회의 어시스턴스 서비스는,가상 회의와 관련된 정보를 데이터베이스로부터 검색하고, 검색된 정보를 가공하여 가상 회의 참가자들에게 제공하는 자료 검색 기능을 포함하는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "프로세서;상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 로드(load)하는 메모리; 및상기 컴퓨터 프로그램을 저장하는 스토리지를 포함하되,상기 컴퓨터 프로그램은,제1 사용자의 아바타를 생성 또는 설정하는 동작,상기 제1 사용자가 제공한 송신 데이터와 상기 아바타에 기초하여 가상 아바타 영상을 생성하는 동작, 및상기 가상 아바타 영상을 이용하여 가상 회의 서비스를 제공하는 동작을 수행하기 위한 인스트럭션들을 포함하는,가상 회의 시스템."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,공개특허 10-2025-0052739-4-상기 아바타 영상을 생성하는 동작은,상기 송신 데이터를 기초로 제2 사용자가 원하는 언어의 음성을 생성하는 동작, 및상기 아바타와 상기 음성을 기초로, 상기 아바타가 상기 음성을 발화하는 상가 가상 아바타 영상을 생성하는 동작을 포함하는,가상 회의 시스템."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 송신 데이터는 음성 데이터를 포함하고,상기 음성을 생성하는 동작은,상기 음성 데이터를 STT 모델을 통해 제1 언어의 제1 텍스트로 변환하고,상기 제1 텍스트를 기계 번역 모델을 통해 제2 언어의 제2 텍스트로 변환하고,상기 제2 텍스트를 다중언어 TTS 모델에 입력하여 상기 음성을 생성하는,가상 회의 시스템."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 컴퓨터 프로그램은,가상 비서를 통한 가상 회의 어시스턴스(assistance) 서비스를 제공하는 동작을 수행하기 위한 인스트럭션들을더 포함하는,가상 회의 시스템."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 가상 회의 어시스턴스 서비스는,가상 회의의 회의 내용을 요약하여 데이터베이스에 저장하는 회의 내용 요약 기능을 포함하는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13 항에 있어서,상기 가상 회의 어시스턴스 서비스는,사용자가 가상 회의 중 입력한 이미지 및 영상을 기초로, 설명이 부가된 이미지 및 영상을 제공하는 자료 요약기능을 포함하는,가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13 항에 있어서,상기 가상 회의 어시스턴스 서비스는,가상 회의와 관련된 정보를 데이터베이스로부터 검색하고, 검색된 정보를 가공하여 가상 회의 참가자들에게 제공하는 자료 검색 기능을 포함하는,공개특허 10-2025-0052739-5-가상 회의 시스템의 동작 방법."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "가상 아바타 기반의 가상 회의 시스템 및 그것의 동작 방법이 제공된다. 본 발명의 일 실시 예에 따른 가상 회의 시스템의 동작 방법은 컴퓨팅 장치에 의해 수행되고, 제1 사용자의 아바타를 생성 또는 설정하는 단계, 상기 제1 사용자가 제공한 송신 데이터와 상기 아바타에 기초하여 가상 아바타 영상을 생성하는 단계, 및 상기 가상 아바 타 영상을 이용하여 가상 회의 서비스를 제공하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 가상 아바타 기반의 가상 회의 시스템 및 그것의 동작 방법에 관한 것으로, 더욱 구체적으로는, 아바 타를 기반으로 음성 및 텍스트 기반의 가상 회의 서비스를 제공하고 가상 비서를 통해 가상 회의의 편의성을 향 상시키는 아바타 기반의 가상 회의 시스템 및 그것의 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근의 기술 발전으로 다양한 온라인 회의 도구와 플랫폼이 개발되고 있다. 그러나, 여전히 대부분의 플랫폼에 서는 실제 사용자의 모습이나 목소리만을 중심으로 회의가 이루어지는 실정이다. 일부 플랫폼에서는 텍스트 기 반의 채팅 기능을 제공하지만, 이러한 기능들은 참가자들의 실제 의도나 감정을 전달하기 어려운 한계가 있다. 또한, 기존의 회의 도구는 중요한 내용을 기록하거나 웹에서 필요한 자료를 자동으로 검색하고 제공하는 기능을 포함하고 있지 않다. 한편, 풍성한 가상 회의 서비스를 제공하기 위해, 여러 인공지능 기반 기술이 이용될 수 있다. 예를 들어, 인공 지능을 기반으로 문장 및 텍스트를 음성인 스피치로 변환하는 Text To Speech(이하, TTS라 함) 기술, 또는 발화 하는 음성에 따라 가상 인물 또는 캐릭터의 입 모양을 변화시키는 Speech To Face (이하, STF라 함) 기술이 가 상 회의 서비스에 활용될 수 잇다. 본 발명에서는 인공지능 기반의 TTS 기술 및 STF 기술을 활용한 가상 아바타 기반의 가상 회의 시스템을 제안하 고자 한다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들을 통해 해결하고자 하는 기술적 과제는, 참가자들이 선택한 아바타를 통해 회의 내용을 음 성 또는 텍스트 입력만으로 효과적으로 전달하면서, 아바타가 해당 내용에 따라 자연스럽게 의사소통 할 수 있 는 가상 아바타 기반의 가상 회의 시스템 및 그것의 동작 방법을 제공하는 것이다. 본 발명의 실시예들을 통해 해결하고자 하는 다른 기술적 과제는, 가상 비서 기능을 포함하여 회의 중 발생하는 중요한 내용을 자동으로 기록하고, 필요한 자료를 웹에서 검색하여 회의 참가자들에게 제공하는 기능을 통해 회 의의 효율성과 생산성을 높일 수 있는 가상 아바타 기반의 가상 회의 시스템 및 그것의 동작 방법을 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적"}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "과제들은 아래의 기재로부터 본 발명의 기술분야에서의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 바와 같은 과제를 해결하기 위한 본 발명의 실시 예에 따른 가상 회의 시스템의 동작 방법은, 컴퓨팅 장 치에 의해 수행되고, 제1 사용자의 아바타를 생성 또는 설정하는 단계, 상기 제1 사용자가 제공한 송신 데이터 와 상기 아바타에 기초하여 가상 아바타 영상을 생성하는 단계, 및 상기 가상 아바타 영상을 이용하여 가상 회 의 서비스를 제공하는 단계를 포함할 수 있다. 일 실시예로서, 상기 아바타는 3차원 애니메이션 형태를 가질 수 있다. 일 실시예로서, 상기 아바타 영상을 생성하는 단계는, 상기 송신 데이터를 기초로 제2 사용자가 원하는 언어의 음성을 생성하는 단계 및 상기 아바타와 상기 음성을 기초로 상기 아바타가 상기 음성을 발화하는 상가 가상 아 바타 영상을 생성하는 단계를 포함할 수 있다. 일 실시예로서, 상기 송신 데이터는 음성 데이터를 포함하고, 상기 음성을 생성하는 단계는, 상기 음성 데이터 를 STT 모델을 통해 제1 언어의 제1 텍스트로 변환하고, 상기 제1 텍스트를 기계 번역 모델을 통해 제2 언어의제2 텍스트로 변환하고, 상기 제2 텍스트를 다중언어 TTS 모델에 입력하여 상기 음성을 생성할 수 있다. 일 실시예로서, 상기 송신 데이터는 텍스트 데이터를 포함하고, 상기 음성을 생성하는 단계는, 상기 텍스트 데 이터를 기계 번역 모델을 통해 제2 언어의 제2 텍스트로 변환하고, 상기 제2 텍스트를 다중언어 TTS 모델에 입 력하여 상기 음성을 생성할 수 있다. 일 실시예로서, 가상 비서를 통한 가상 회의 어시스턴스(assistance) 서비스를 제공하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "일 실시예로서, 상기 가상 회의 어시스턴스 서비스는 가상 회의의 회의 내용을 요약하여 데이터베이스에 저장하"}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "는 회의 내용 요약 기능을 포함할 수 있다. 일 실시예로서, 상기 가상 회의 어시스턴스 서비스는 사용자가 가상 회의 중 입력한 이미지 및 영상을 기초로,"}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "설명이 부가된 이미지 및 영상을 제공하는 자료 요약 기능을 포함할 수 있다. 일 실시예로서, 상기 가상 회의 어시스턴스 서비스는 가상 회의와 관련된 정보를 데이터베이스로부터 검색하고, 검색된 정보를 가공하여 가상 회의 참가자들에게 제공하는 자료 검색 기능을 포함할 수 있다. 상기한 바와 같은 과제를 해결하기 위한 본 발명의 실시 예에 따른 가상 회의 시스템은, 프로세서, 상기 프로세 서에 의해 실행되는 컴퓨터 프로그램을 로드(load)하는 메모리, 및 상기 컴퓨터 프로그램을 저장하는 스토리지 를 포함하되, 상기 컴퓨터 프로그램은, 제1 사용자의 아바타를 생성 또는 설정하는 동작, 상기 제1 사용자가 제 공한 송신 데이터와 상기 아바타에 기초하여 가상 아바타 영상을 생성하는 동작, 및 상기 가상 아바타 영상을 이용하여 가상 회의 서비스를 제공하는 동작을 수행하기 위한 인스트럭션들을 포함할 수 있다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 본 발명의 다양한 실시 예들에 따르면, 참가자들이 선택한 아바타를 통해 회의 내용을 음성 또는 텍스트 입력만으로 효과적으로 전달하면서, 아바타가 해당 내용에 따라 자연스럽게 의사소통 할 수 있는 가상 아바타 기반의 가상 회의 시스템 및 그것의 동작 방법이 제공된다. 또한, 상기한 가상 회의 시스템을 통해, 회의 참여자는 자신만의 선택한 아바타를 통해 개성화된 표현을 할 수 있으며, 카메라가 없어서 음성이나 텍스트로만 하는 경우와 같이 제한된 상황에서 의사소통을 하는 경우에도 가 상 아바타가 전달하고자 하는 내용을 효과적으로 전달해주고, 화자와 청자가 언어가 달라도 쉽게 의사소통이 가 능할 수 있다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "또한, 가상 비서의 기능을 통해 회의 중 발생하는 내용을 기록하고, 중요한 내용을 자동으로 요약할 수 있으며, 가상 회의 중 필요한 정보나 자료를 웹에서 즉시 검색하여 참가자들에게 제공함으로써, 회의의 효율성과 생산성 을 크게 향상시킬 수 있게 된다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명한다. 본 발명의 이점 및 특징, 그리고 그것들 을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러 나 본 발명의 기술적 사상은 이하의 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으"}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "며, 단지 이하의 실시예들은 본 발명의 기술적 사상을 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명의 기술적 사상은 청구 항의 범주에 의해 정의될 뿐이다. 각 도면의 구성요소들에 참조부호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시 되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명을 설명함에 있어, 관련 된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세 한 설명은 생략한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있다. 또 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니 다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 또한, 본 발명의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질 이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성 요소 사이에 또 다른 구성 요소가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 도 1은 본 발명의 실시 예에 따른 전체 시스템을 개략적으로 도시한 개념도이다. 도 1을 참조하면, 본 발명의 실시 예에 가상 회의 시스템은 아바타 생성부, 아바타 조절부, 가 상 비서, 및 데이터베이스를 포함한다. 아바타 생성부는 사용자가 개인 아바타를 만들고 설정하기 위한 도구를 제공하는 구성이다. 아바타 생성부 에 의해 생성된 아바타는 3D 애니메이션 데이터의 형태로 구성될 수 있다. 일 실시예로서, 상기 아바타의 모양은 실사에 가까운 모습, 만화 캐릭터 등 다양한 외형을 가질 수 있으며 특정 제약에 국한되지 않는다. 아바타 조절부는 가상 회의에서 송신자로부터 다양한 정보를 입력받고, 그에 따라 아바타를 조절(또는, 생 성)하여 수신자에게 전달한다. 예를 들어, 송신자가 음성 또는 텍스트를 입력한 경우, 아바타 조절부는 송신자가 설정한 아바타, 입력된 음성 데이터 또는 텍스트 데이터를 기초로, 수신자가 원하는 언어로 말하는 아바타를 생성하여 출력한다. 일 실시예로서, 수신자가 수신하는 정보는 아바타, 음성, 자막, 또는 기타 유형의 정보를 포함할 수 있다. 도 2를 참조하면, 송신자가 음성 데이터를 보낸 경우의 예시적인 동작 흐름도가 도시되어 있다. 송신자가 보낸 음성 데이터는 먼저 기계 번역되고, 번역된 텍스트는 다중언어 TTS 모델로 처리되어 수신자가 원하는 언어의 음 성으로 변환된다. 그리고, 변환된 음성은 송신자가 설정한 아바타와 합성되어, 음성과 싱크가 맞는 아바타 영상 으로 수신자에게 출력된다. 일 실시예로서, 상기 음성 데이터는 기계 번역을 위해 먼저 STT 모델을 통해 텍스트로 변환된 후 기계 번역 모 델에 입력될 수 있다. 일 실시예로서, 상기 번역된 텍스트는 다중언어 TTS 모델에 제공되는 동시에, 별도의 자막으로도 출력될 수 있 다. 일 실시예로서, 상기 음성 데이터가 수신자가 원하는 언어와 언어 종류가 동일한 경우, 기계 번역 모델을 이용 한 번역 과정은 생략될 수 있다. 도 3을 참조하면, 송신자가 텍스트 데이터를 보낸 경우의 예시적인 동작 흐름도가 도시되어 있다. 송신자가 보 낸 텍스트 데이터는 먼저 기계 번역되고, 번역된 텍스트는 다중언어 TTS 모델로 처리되어 수신자가 원하는 언어 의 음성으로 변환된다. 그리고, 변환된 음성은 송신자가 설정한 아바타와 합성되어, 음성과 싱크가 맞는 아바타 영상으로 수신자에게 출력된다. 일 실시예로서, 상기 번역된 텍스트는 다중언어 TTS 모델에 제공되는 동시에, 별도의 자막으로도 출력될 수 있 다. 일 실시예로서, 상기 텍스트 데이터가 수신자가 원하는 언어와 언어 종류가 동일한 경우, 기계 번역 모델을 이 용한 번역 과정은 생략될 수 있다. 가상 비서는 가상 회의 서비스의 편의성을 높여주기 위한 구성으로, 가상 회의의 효율성과 생산성을 향상 시키는 다양한 기능을 구비한다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "일 실시예로서, 가상 비서가 제공하는 다양한 기능은 회의 내용 요약 기능, 자료 요약 기능, 및/또는 자료 검색 기능을 포함할 수 있다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 4, "content": "도 4는 도 1에 도시된 가상 비서를 통해 제공되는 가상 비서 서비스 중 회의 내용 요약 기능을 설명하기 위한 도면이다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 5, "content": "도 4를 참조하면, 가상 비서는 회의 진행시 참여자의 대화(음성, 텍스트)를 요약하여 이를 저장할 수"}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "있다. 또한, 가상 비서는 회의 참여 전에는 이전 회의(동일한 주제의 회의)의 요약본을 제공하여 회의 참"}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "가자에게 내용을 상기시키는 역할도 할 수 있다. 또한, 가상 비서는 회의 이후에는 회의 결과를 요약된 형 태로 공유하는 역할도 할 수 있다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "도 은 도 1에 도시된 가상 비서를 통해 제공되는 가상 비서 서비스 중 자료 요약 기능을 설명하기 위한 도면이 다. 도 5를 참조하면, 가상 비서는 사용자가 회의 전, 회의 중, 회의 이후에 입력한 이미지와 영상을 그대로 기록할 뿐만 아니라 “이미지 캡셔닝 (AI)”, “영상 캡셔닝 (AI)” 모듈로 나온 텍스트 데이터를 함께 저장할 수 있다. 이는 사용자가 회의 내용을 검색을 효율적으로 할 수 있고, 송신자가 보낸 내용을 수신자가 쉽게 이해 할 수 있도록 돕는다. 도 6은 도 1에 도시된 가상 비서를 통해 제공되는 가상 비서 서비스 중 자료 검색 기능을 설명하기 위한 도면이 다. 도 6을 참조하면, 가상 비서는 가상 회의 중 회의와 관련된 내용을 가상 회의 참여자들에게 제공하기 위해, 상가 내용과 관련된 정보들을 데이터베이스에서 검색한다. 이때, 검색되는 정보에는 이전 회의"}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "내용, 참가자가 입력한 내용, 요약본 등 다양한 정보가 포함될 수 있다. 또한, 가상 비서는 외부 데이터베이스의 활용을 위해 다른 검색 서비스를 API로 호출하여 필요한 정보를 외부에서도 빠르게 찾아줄 수도 있다. 일 실시예로서, 이를 위해 사용자가 가상 비서에게 입력하는 데이터의 형태는 텍스트나 음성으로 국한하지 않는다. 예를 들어, 사용자가 입력하는 데이터는 이미지와 텍스트가 결합된 데이터(예를 들어, \"이 이미지로 설 명했던 추가 자료를 보여줘\"와 같은 인스트럭션을 입력), 영상과 텍스트가 결합된 데이터(예를 들어, \"15초에 등장한 인물에 대해서 알려줘\"와 같은 인스트럭션 입력) 등 다양한 데이터의 형태를 조합하여 제시할 수 있다. 데이터베이스는 가상 회의 서비스의 제공을 위한 다양한 정보를 저장한다. 일 실시예로서, 데이터베이스는 가상 회의와 관련하여 사용자가 입력한 모든 정보, 가상 비서가 가공 한 정보, 및/또는 가상 회의 참가자에 대한 정보 등 다양한 정보를 저장할 수 있다. 데이터베이스에 저장되는 데이터의 형식은 텍스트, 음성, 이미지, 영상 등 다양한 형태가 가능하며, 이는 검색이 쉬운 형태로 저장될 수 있다. 한편, 일 실시예로서 가상 회의 시스템은, 본 발명의 실시 예에 따른 서비스 제공을 위해, 외부의 사용자 단말(미도시) 과 유/무선 네트워크를 통해 연결될 수 있으며, 상호간 통신을 수행할 수 있다. 여기서 상기 각 네트워크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 개인 근거리 무선통신(Personal Area Network; PAN), 이동 통신 망(mobile radiocommunication network) 또는 위성 통신망 등과 같은 모든 종류의 유/무선 네트워크로 구현될수 있다. 그리고, 사용자 단말은, 가상 회의 시스템를 통해 제공되는 영상, 음성, 또는 텍스트 등을 제공받는 단말 장치이거나, 가상 회의 시스템이 가상 회의 서비스를 복수의 다른 단말에 중계하는 플랫폼 서버일 수 있다. 사용자 단말이 단말 장치인 경우, 사용자 단말은 휴대폰, 스마트 폰(smart phone), 스마트 패드(smart pad), PDA(Personal Digital Assistants), 또는 태블릿 PC(Tablet PC)일 수 있다. 이러한 시스템 구성을 통해, 가상 회의 시스템는, 가상 아바타 기반의 가상 회의 서비스를 제공하며, 가상 아바타 영상의 처리 속도와 립싱크 정확도 향상, 헤드 모션 적용, 화질 향상 등을 위한 다양한 처리부들을 더 구비할 수 있는 바, 이에 대하여는 도 7에서 보다 구체적으로 설명하기로 한다. 도 7은 도 1에 도시된 가상 회의 시스템을 주요 기능 블록 단위로 설명하기 위한 블록도이다. 도 7을 참조하면, 본 발명의 실시 예에 따른 가상 회의 시스템는, 다국어 글로벌 영상 커뮤니케이션 서비 스부, 문자 입력 기반 실시간 AI 아바타 생성부, 고화질 데이터 처리 기반 립싱크 영상 생성부, 비학습 인물 대 응 AI 아바타 생성부, 음성 내 감정 분석 기반 얼굴영상 구성부, 음성의 입 모양 동기화 기반 립싱크 영상 처리 부, 음성 기반 립싱크 3D 얼굴 데이터 처리부, 감정 분석 기반 표정 및 머리 움직임 제어부, 단기 음성 데이터 학습 처리부, 학습 기반 감정 연출 음성 처리부, 오디오북 제작 서비스부, 화자 얼굴-음성 매칭 데이터 수집 자 동화부, 감정 기반 텍스트-음성 매칭 데이터 수집 자동화부를 포함한다. 먼저, 다국어 글로벌 영상 커뮤니케이션 서비스부는, 사용자 단말에서 입력된 문자에 대응하여, 다국어 음 성과 발화영상에 기초한 가상 회의 영상 정보를 실시간으로 생성하여, 사용자 단말로 제공하는 데이터 서 비스를 처리한다. 이에 따라, 다국어 글로벌 영상 커뮤니케이션 서비스부는, 사용자가 문자만 입력하면, 본 발명의 실시 예에 따 른 다국어 글로벌 영상 커뮤니케이션 가상 회의 영상을 실시간으로 생성하여, 문자만으로 글로벌 영상소통이 가 능하게 하는 어플리케이션을 제공할 수 있으며, 이는 글로벌 영상소통의 수요가 증가하면서 실시간 소통이 가능 하지만 언어장벽의 한계가 발생되는 문제점을 해결할 수 있다. 예를 들어, 종래기술의 경우,현재 실시간 영상소통을 위해, 마이크와 카메라를 이용하여 비대면 소통 기술을 제 공하는데, 언어적 장벽은 늘 존재하고, 마이크와 카메라 장치가 필요하다는 시스템적인 한계가 존재한다. 이에 따라, 본 발명의 실시 예에 따른 다국어 글로벌 영상 커뮤니케이션 서비스부는, 사용자 단말에서 번 역할 언어를 선택 후 모국어를 문자로 입력하면, 번역 음성을 발화하는 아바타 영상이 출력되는 서비스를 제공 할 수 있다. 또한, 본 발명의 실시 예에 따른 다국어 글로벌 영상 커뮤니케이션 서비스부는, 전술한 인공지능 학습 모델 및 엔진 처리를 통해, 다국어 음성과 실시간 생성이 가능한 립싱크 영상을 포함하는 가상 회의 서비스를 사용자 단 말로 제공할 수 있다. 이에 따라, 카메라와 마이크 없어도 글로벌 영상 소통이 가능한 서비스를 제공할 수 있으며, 본 발명의 실시 예 에 따른 다국어 글로벌 영상 커뮤니케이션 서비스부는, 번역 기능과 음성 출력 기능 및 아바타 생성 기능을 조 합함에 따라, 마이크와 카메라 장비 없이도 글로벌 소통이 가능한 서비스를 제공할 수 있다. 이러한 본 발명의 실시 예에 따른 다국어 글로벌 영상 커뮤니케이션 서비스부의 처리에 따라, 음성으로 소통이 어려운 장애인의 경우에도, 문자만 입력하면 본인의 의사를 시청각으로 표현할 수 있어 원활한 의사소통이 가능 하게 할 수 있으며, 언어장벽이 존재하는 글로벌 환경에 있어서, 다국어 말하기가 힘든 상황에서 문자 입력만으 로 다국어 소통이 가능하게 하므로, 민족과 문화 간의 소통장벽을 해소할 수 있게 된다. 한편, 문자 입력 기반 실시간 AI 아바타 생성부는, 사용자 단말로부터의 문자 입력에 대응하여, 실시간으 로 출력되는 AI 휴먼 아바타를 생성하며, 상기 AI 휴먼 아바타의 스피치 영상 데이터를 사용자 단말로 제 공하는 프로세스를 처리할 수 있다. 보다 구체적으로, 본 발명의 실시 예에 따른 문자 입력 기반 실시간 AI 아바타 생성부는, AI 아나운서 제작 시, 영상 출력에 소요되는 시간으로 인한 한계를 극복하기 위한 것으로, 사용자 단말로부터 문자만 입력되면, 음성과 발화영상이 매칭된 가상 회의 영상이 실시간으로 사용자 단말에서 출력되도록 하는 기능을 제공하 며, 이는 문자만으로 영상 소통 및 가상 회의 영상 제작이 가능하게 하는 서비스를 구현한다.예를 들어, 종래기술의 AI 아나운서 기술들이 실험적으로 제안되고 있으나, 이는 단일 화자의 8시간 내외 음성 과 얼굴데이터를 인공지능신경망으로 학습하여, 문자입력시 학습된 아나운서의 음성과 얼굴이 영상으로 출력되 는 기술로서, 고화질-저효율의 모델을 사용하기 때문에, 10초 정도의 짧은 영상 출력에도 1분 이상의 장시간 렌 더링 시간이 발생하는 문제점이 있다. 이에 따라, 본 발명의 실시 예에 따른 문자 입력 기반 실시간 AI 아바타 생성부는, 문자 입력 후 적어도 1초 이 내의 렌더링 시간을 보장하는 립싱크 영상 출력 모듈을 포함할 수 있으며, 생성 알고리즘의 구조 최적화를 통한 실시간 영상 출력을 제공할 수 있다. 이러한 본 발명의 실시 예에 따른 문자 입력 기반 실시간 AI 아바타 생성부는 모델 경량화 기법을 활용하여, 실 시간 생성이 가능한 립싱크 영상생성 모델을 구축할 수 있다. 예를 들어, 도 3에 도시된 바와 같은 딥러닝 모델 최적화 프로세스를 통해 Parameter pruning and quantization, Knowledge distillation 등을 활용한 모델 최적 화를 구현할 수 있다. 이에 따라, 문자 입력 기반 실시간 AI 아바타 생성부는, 음성으로 소통이 어려운 장애인의 경우에도, 문자만 입 력하면 본인의 의사를 시청각으로 표현할 수 있어 원활한 의사소통이 가능하게 하며, 언어장벽이 존재하는 글로 벌 환경에 있어서, 다국어 말하기가 힘든 상황에서 문자 입력만으로 다국어 소통이 가능하게 하므로, 언어가 다 른 사람 간의 소통장벽을 해소할 수 있는 차이점이 있다. 한편, 본 발명의 실시 예에 따른 고화질 데이터 처리 기반 립싱크 영상 생성부는, 고화질 데이터를 기반으로 한 고화질 립싱크 영상을 생성하여, 사용자 단말로 제공하는 서비스 데이터 처리를 수행한다. 여기서, 본 발명의 실시 예에 다른 고화질 데이터 처리 기반 립싱크 영상 생성부는, 디스플레이 기술의 발달로 인해, 대형 컨시어지를 활용한 AI 휴먼의 활용이 확대를 고려하여 안출된 것으로, 종래기술에 따른 국내 AI아나 운서의 출력영상들이 HD(720p)이하의 얼굴 영상을 통해 데이터를 수집 및 가공해 활용하고 있어 발생되는 화질 문제를 해결하기 위한 것이다. 고화질 데이터 처리 기반 립싱크 영상 생성부는 저화질 데이터를 활용해 온 기술 적 한계를 극복하고, AI 가상 회의 영상의 화질 문제가 상용화의 진입장벽이 되는 문제점을 해결한다. 이를 위해, 본 발명의 실시 예에 따른 고화질 데이터 처리 기반 립싱크 영상 생성부는, 발화영상의 고화질 데이 터셋을 구축하며, 데이터 수집 자동화 시스템으로 고화질 데이터셋 확보하고, 특히 입모양과 치아 부분의 선명 도를 위한 고도화 생성 프로세스를 수행할 수 있다. 예를 들어, 고화질 데이터 처리 기반 립싱크 영상 생성부는, Face super resolution, StyleGAN3 등 고화질의 얼굴을 생성하는 최신 GAN 모델을 활용하여 고화질 데이터 처리 기반 립싱크 영상 생성을 수행할 수 있다. 이에 따라, 고화질 데이터 처리 기반 립싱크 영상 생성부는, 고화질로 화질이 개선된 드라마, 영화 등 고화질이 필요한 서비스를 통해 고화질 가상 회의 영상을 제공할 수 있으며, 이는 화질 개선에 따른 영상제작 활용도 증 가와 영상제작 시간과 비용을 획기적으로 절감하게 한다. 한편, 비학습 인물 대응 AI 아바타 생성부는, 비학습 인물의 음성과 영상이 출력되는 AI 휴먼 가상 회의를 생성 하여 사용자 단말로 출력하는 기능을 수행한다. 통상적으로 영상 제작 시, 촬영에 소요되는 시간과 비용, 에너지 등에서 낭비적 요소가 발생하고 있는 바, 본 발명의 실시 예에 따른 비학습 인물 대응 AI 아바타 생성부는, 사용자 단말로부터 비학습 인물 정보 및 문 자만 입력하면 음성과 영상이 결합된 비학습 인물 대응 AI 아바타를 생성 및 제공함에 따라, 사용자가 별도의 촬영 공간이 없어도 영상제작을 쉽게 할 수 있게 한다. 즉, 종래기술을 예를 들면 현재 AI 아나운서 기술은 단일화자의 수시간(8시간 내외) 음성과 얼굴데이터를 인공 지능 신경망으로 학습하여, 문자 입력시 학습된 아나운서의 음성과 얼굴이 영상으로 출력되는 기술이 제안되고 있으나, 단일화자의 8시간 이상의 영상데이터를 필요로 하기 때문에 학습데이터 수집에서부터 가공, 출력까지의 비용과 시간이 상당히 많은 부분 차지한다. 이로 인해 인물 영상 제작의 어려움을 해결하지 못하고 AI아나운서 제작에 대한 진입장벽이 발생한다. 또한 단일화자의 영상데이터를 학습한 모델이기 때문에 다른 화자의 음성과 동기화 되지 못하는 한계가 있다. 이에 따라, 본 발명의 실시 예에 따른 비학습 인물 대응 AI 아바타 생성부는, 불특정 화자의 음성과 불특정 인 물의 영상을 자유롭게 동기화할 수 있도록, 학습데이터를 통해 비학습된 영상데이터의 입모양 생성이 가능한 일 반화된 생성 엔진을 인공지능 신경망 학습을 통해 구축하고, 이에 기초한 비학습 인물 대응 AI 아바타를 생성하여, 이에 기초한 가상 회의 영상을 사용자 단말로 제공할 수 있다. 일 실시예로서, 본 발명의 실시 예에 따른 비학습 인물 대응 AI 아바타 생성부는, 음성 정보를 임베딩하여 스피 치 피처(음성의 다양한 정보로서, 피치, 톤, 볼륨 등을 함축적으로 표현하는 정보)를 추출하는 스피치 인코더와, 얼굴의 정보를 임베딩하여 페이스 피처(얼굴 이미지의 고차원 정보를 함축적으로 표현하는 정보)를 추출하는 이미지 인코더와, 상기 스피치 피처를 통해 입모양을 예측하고, 페이스 피처 기반 얼굴을 생성하는 디 코더와, 상기 스피치 피처 및 상기 페이스 피처간 유사도를 측정하여 립싱키의 정확도를 판별하는 립싱크 판별 기를 포함할 수 있다. 또한, 비학습 인물 대응 AI 아바타 생성부는, 언어별 제한 없이 음성과 맞는 입모양 생성을 처리할 수 있으며, 이를 위해, 언어별 입모양 특성을 학습할 수 있는 언어별 맞춤형 립싱크 엔진을 구비할 수 있다. 이에 따라, 비학습 인물 대응 AI 아바타 생성부는, 영상소통 환경의 혁신과 함께 영상제작에 필요한 시간과 자 원의 낭비가 해소되어 영상제작의 진입장벽이 낮아지고 제작인력의 시간이 더욱 효과적으로 사용될 수 있도록 한하며, 음성과 얼굴 영상의 자유로운 동기화를 통해 언어제약이 없는 가상 회의 영상을 생성하여 사용자 단말 로 제공할 수 있다. 한편, 음성 내 감정 분석 기반 얼굴영상 구성부는 음성 내 감정을 분석해 표정이 변화하는 가상 회의 영상을 생 성하여, 사용자 단말로 출력한다. 음성 내 감정 분석 기반 얼굴영상 구성부는, 디지털 휴먼의 수요 증가로 다양한 활동 영역에 등장하고 있는 상 황에서 더욱 친근감 있는 디지털 휴먼에 대한 필요성에 의해 안출된 것으로, 가상 회의 영상에 포함된 디지털 휴먼의 음성과 표정을 자연스럽게 나타낼 수 있는 서비스를 제공할 수 있다. 예를 들어, 종래기술의 디지털 휴먼은 기 학습된 영상데이터의 사람의 모습을 영상으로 생성하는 기술로 학습데 이터를 기반으로 얼굴과 표정을 출력하는 바, 무표정한 얼굴로 영상데이터 상에 포함된 제스쳐만 출력되는 상황 이다. 이에 따라 친근감이 떨어지고 사용성이 떨어진다는 한계가 발생하고 있다. 한편, 본 발명의 실시 예에 따른 음성 내 감정 분석 기반 얼굴영상 구성부는, 음성 신호에 있는 감정을 분석하 며, 감정 분석 결과에 따라 가상 회의 영상의 감정 컨트롤이 가능한 학습 모델을 구축할 수 있다. 이를 위해, 음성 내 감정 분석 기반 얼굴영상 구성부는, audio encoder에서 출력된 speech features를 통해 입모양을 학습 하고, expression encoder에서 출력된 expression features를 통해 감정이 있는 표정을 학습하여 학습 모델을 구축할 수 있다. 음성 내 감정 분석 기반 얼굴영상 구성부의 구동에 따라, 음성 신호의 발음만 고려한 종래의 모델보다 자연스러 운 표정이 있는 영상 생성 가능해지며, 이는 감정 표현이 필요한 예술 문화 콘텐츠에도 디지털 휴먼 도입을 가 능하게 한다. 또한, 음성 내 감정 분석 기반 얼굴영상 구성부는 다양한 감정을 표현할 수 있는 디지털 휴먼을 사용자 단말 로 제공하며, 이는 사용자와 친근감을 형성하고 감정교류까지 체감할 수 있는 인간친화적 디지털 휴먼 산 업을 구축할 수 있도록 한다. 그리고, 음성의 입 모양 동기화 기반 립싱크 영상 처리부는, 음성에 따라 입모양이 일치하는 립싱크 영상생성 모델을 구축할 수 있다. 보다 구체적으로, 음성의 입 모양 동기화 기반 립싱크 영상 처리부는, AI 아나운서의 수요 증가와 함께 관련 기 술에 대한 기대감이 높아지고 이에 더욱 자연스러운 립싱크 기술이 요구되는 상황에서 안출된 것으로, 사용자 단말로부터의 문자가 입력되면, 음성과 발화영상이 정확하게 일치되어 출력되는 가상 회의 생성 모델을 학 습 기반으로 구축할 수 있다. 예를 들어, 종래기술의 AI 아나운서 기술은 단일화자의 8시간 내외 음성과 얼굴데이터를 인공지능신경망으로 학 습하여, 문자입력시 학습된 아나운서의 음성과 얼굴이 영상으로 출력되는 기술로서, 비학습한 다른 언어를 입력 하면 립싱크가 불일치하는 문제가 발생할 수 있다. 본 발명의 실시 예에 따른 음성의 입 모양 동기화 기반 립싱크 영상 처리부는, 다국어 언어 인식에 따른 다국어 언어 립싱크 영상 생성을 위한 학습 모델을 구축할 수 있다. 이를 위해, 음성의 입 모양 동기화 기반 립싱크 영 상 처리부는, 데이터셋 수집 후, 언어를 고려한 lip sync discriminator 학습을 처리할 수 있다. 그리고, 음성의 입 모양 동기화 기반 립싱크 영상 처리부는, 언어별 정확도가 높은 립싱크 영상 생성 모델을 구 축하기 위해, lower half visual features와 audio features 의 similarity 계산을 통해 sync 를 판별하는 처 리를 수행할 수 있다. 이에 따라, 음성의 입 모양 동기화 기반 립싱크 영상 처리부는, 언어별 부자연스러운 입모양을 해소할 수 있어 글로벌 아바타 영상 소통에 도움을 줄 수 있으며, 언어에 따른 정확한 입모양 영상을 제공하여, 언어교육 영상 으로도 활용할 수 있는 가상 회의 영상 서비스를 사용자 단말로 제공할 수 있다. 그리고, 음성 기반 립싱크 3D 얼굴 데이터 처리부는, 음성에 따라 립싱크 하는 3D 얼굴을 생성하는 프로세스를 수행한다. 이는 메타버스 산업의 발달로 인해 3D 기술 기반의 다양한 메타휴먼이 등장함에 따라 안출된 것으로, 음성 기반 립싱크 3D 얼굴 데이터 처리부는, 3D 환경에서도 원활한 음성 립싱크가 가능한 얼굴 생성 모델을 구현할 수 있 다. 즉, 종래에는 3D 얼굴제작과 음성 립싱크 제작 환경이 모셥캡쳐 기반의 기술을 활용하고 있으나, 이는 고비용의 개발 비용과 환경이 필요하므로 진입장벽이 높고 제작기간이 상당하며, 또한 자연스러운 입모양 연출이 어려워 이질감을 주고 있는 상황이기 때문에, 음성 기반 립싱크 3D 얼굴 데이터 처리부는 이를 해결하기 위한 3D 얼굴 생성 프로세스를 처리할 수 있다. 보다 구체적으로, 본 발명의 실시 예에 따른 음성 기반 립싱크 3D 얼굴 데이터 처리부는, 3D 메쉬 데이터를 학 습데이터셋으로 활용해 음성과 3D 데이터 동기화 학습 수행할 수 있다. 이를 위해, 음성 기반 립싱크 3D 얼굴 데이터 처리부는, 3D template mesh를 입력하여 움직이는 mesh 출력할 수 있다. 그리고, 음성 기반 립싱크 3D 얼굴 데이터 처리부는, 임의의 neutral face mesh 데이터와, 오디오 정보를 기반 으로, 립싱크 생성 모델을 구축할 수 있다. 또한, 음성 기반 립싱크 3D 얼굴 데이터 처리부는, audio encoder로 speech signal을 임베딩하여, 오디오 기반 으로 하는 3D 얼굴 데이터 생성 처리를 수행할 수 있다. 이에 따라, 음성 기반 립싱크 3D 얼굴 데이터 처리부는, 2D 영상환경 뿐 아니라 3D 기반의 메타버스 환경에서도 다양하게 활용할 수 있는 가상 회의 서비스를 사용자 단말로 제공할 수 있으며, 이는 고가의 모션캡쳐 장 비가 없어도 3D 아바타의 표정을 컨트롤 할 수 있는 환경을 제공할 수 있다. 한편, 감정 분석 기반 표정 및 머리 움직임 제어부는, 음성 내 감정을 분석해 표정 변화와 머리 움직임이 가능 한 얼굴영상 생성을 수행하고, 이에 기초한 가상 회의 서비스 정보를 구성하여 사용자 단말로 제공할 수 있다. 감정 분석 기반 표정 및 머리 움직임 제어부는, 디지털 휴먼의 수요 증가로 다양한 활동 영역에 등장하고 있는 상황에서 더욱 자연스러운 디지털 휴먼에 대한 필요성에 의해 안출된 것으로, 디지털 휴먼의 음성과 고개를 자 연스럽게 연출할 수 있는 기능을 제공할 수 있다. 종래기술의 디지털 휴먼은 기 학습된 영상데이터의 사람의 모습을 영상으로 생성하는 기술로 학습데이터를 기반 으로 얼굴과 표정을 출력하는 바, 학습된 영상데이터 상에 포함된 뻣뻣한 자세와 녹화된 제스쳐만 출력되는 상 황이며, 이에 따라 부자연스러움이 발생하고 사용성이 떨어진다는 한계가 발생하고 있다. 본 발명의 실시 예에 따른 감정 분석 기반 표정 및 머리 움직임 제어부는, audio-to-animation generator 기술 을 이용하여, 오디오와 얼굴로부터 mouth parameter, eyebrow parameter, head parameter를 추출하며, head pose를 예측하는 모듈을 구비하여, head motion 제어를 수행할 수 있다. 이에 따라, 감정 분석 기반 표정 및 머리 움직임 제어부는, 음성에 따른 자연스러운 head pose를 예측하고 생성 하는 head motion의 제어를 처리한다. 특히, 감정 분석 기반 표정 및 머리 움직임 제어부는, 이미지이거나 head motion이 정적인 영상에 대하여도, 음 성 신호에 따라 자연스러운 head motion을 생성한 가상 회의가 제작되도록 처리할 수 있으며, 이에 따른 다양한 서비스로의 확장이 가능하게 된다. 한편, 단기 음성 데이터 학습 처리부는, 단기(예를 들어, 10분 이내)의 음성데이터만로도 학습 가능한 음성생성 학습 처리를 수행한다. 통상적으로 AI 성우에 대한 수요가 높아짐에 따라 자신의 목소리를 AI 성우로 만들고자 하는 수요도 증가하고 있으나, 종래기술의 TTS 기술만으로는 단일화자의 8시간 내외의 음성데이터를 학습해야 자연스러운 AI 성우 모 델이 완성되는 기술이어서, AI 성우를 개발하기 위해서는 고품질의 방대한 음성데이터가 필요해 기술 개발의 진 입장벽이 발생한다. 이에 따라, 본 발명의 실시 예에 따른 단기 음성 데이터 학습 처리부는, 문자만 입력하면 음성이 출력되는 Text to speech(TTS) 기능을 위한 학습 데이터를 10분 이내의 적은 데이터로 학습 가능하도록 하는 단기 음성 데이터 학습 프로세스를 제공할 수 있다. 보다 구체적으로, 본 발명의 실시 예에 따른 단기 음성 데이터 학습 처리부는, 10분 정도의 적은 단기 음성데이 터만으로 학습이 가능한 음성합성 모델을 구축하기 위해, speaker encoder를 통해 오디오로부터 화자 정보를 추 출해 End-to-end 딥러닝을 수행할 수 있다. 또한, 단기 음성 데이터 학습 처리부는, 대량의 데이터를 학습한 기존 basemodel을 활용하여, TTS 학습 효율화 시스템을 구축하며, 소량의 개인 화자데이터만으로도 model adaptation 을 일치시키는 모델을 구축할 수 있다. 이에 따라, 단기 음성 데이터 학습 처리부는, 적은 음성 데이터로 AI 성우를 개발할 수 있어, TTS 개인화 서비 스가 가능하게 되며, AI 성우 기술의 비약적인 발전과 AI 성우 산업의 비약적인 확장을 가져올 수 있다. 한편, 학습 기반 감정 연출 음성 처리부는, 감정을 자유자재로 표현할 수 있는 음성생성 엔진을 인공지능 신경 망 학습 기반으로 구축할 수 있다. 학습 기반 감정 연출 음성 처리부는, AI 성우에 대한 수요가 높아짐에 따라 다양한 감정을 표현하는 AI 성우를 사용하고자 하는 수요도 증가하여 안출된 것으로, 사용자 단말로부터 문자가 입력되면 음성이 출력되는 Text to speech(TTS) 기능에 있어서, 다양한 감정들이 표현될 수 있도록 하는 감정 연출 처리를 수행한다. 종래기술의 경우 문자와 동기화 된 음성데이터를 학습하는 기술로서 일관된 음성 컨디션만을 학습하고 출력하기 때문에 다양한 음성 표현에 있어서 한계가 발생하는 문제점이 있다. 본 발명의 실시 예에 따른 학습 기반 감정 연출 음성 처리부는, Speech Emotion Recognition을 통해 음성의 감 정을 분류한 데이터 학습 처리를 수행하며, 음성데이터의 감정 분류를 진행하고 분류된 음성의 특징을 인공지능 이 학습하는 학습 프로세스를 수행하여, 학습 기반 감정 연출 음성 처리부 위한 학습 모델을 구축할 수 있다. 여기서, 학습 기반 감정 연출 음성 처리부는, 다양한 감정(기쁨, 슬픔, 화남 등)을 생성할 수 있는 모델을 구축 할 수 있으며, 이는 분류된 감정데이터의 음성 특징을 학습하고 생성할 수 있는 모델로 구성될 수 있다. 이에 따라, 학습 기반 감정 연출 음성 처리부는, 감정 연출이 가능한 TTS 모델을 통해 드라마, 영화, 소설 오디 오북 등 다양한 문화 컨텐츠에 사용 가능한 가상 회의 정보를 구성하여 사용자 단말로 제공할 수 있다. 또 한, 학습 기반 감정 연출 음성 처리부 구동에 따라 부자연스러운 AI 성우의 음성을 다양한 감정을 섞어 연출할 수 있어 AI 성우 산업의 확장을 기대할 수 있게 된다. 오디오북 제작 서비스부는, 오디오북 제작 서비스 제공을 자동화함에 따라, 오디오북 제작기간을 단축시킬 수 있다. 오디오북 제작 서비스부는, AI 성우의 기술력이 높아짐에 따라 빠른 시간 안에 다량의 오디오북을 만들고자 하 는 수요도 증가하여 안출된 것으로, 기존의 TTS기술을 개선하여, 대량의 오디오북을 신속히 제작하는 서비스 기 능을 제공한다. 예를 들어, 종래기술의 오디오북의 경우 사람인 성우가 대본을 낭독하는 방식으로 녹음하고 제작하며, 대본 낭 독의 시간이 많이 소요되므로 제작기간이 길고 제작역량에 한계가 있다. 이를 극복하기 위해, 본 발명의 실시 예에 따른 오디오북 제작 서비스부는, AI 성우를 활용한 오디오북 제작 시 스템을 구성하여, 대본 정보을 입력하면 AI 성우 음성이 파일로 즉시 출력하는 프로세스를 수행할 수 있다. 또 한, 오디오북 제작 서비스부는, 사용자 단말에서 다양한 감정연출 입력이 가능한 유저 인터페이스를 구성 하여 사용자 단말로 제공할 수 있다. 또한, 오디오북 제작 서비스부는, 감정과 화자를 적절하게 연출할 수 있는 AI 성우 학습 모델 및 시스템을 구성 하고, 이에 기초한 자동화된 가상 회의 기반의 오디오북 제작 서비스를 사용자 단말로 제공할 수 있다. 이에 따라, 오디오북의 대량 생산이 가능해지므로 기존 오디오북 시장의 확장을 기대할 수 있으며, AI 성우 기 술의 도입으로 오디오북 제작환경을 획기적으로 개선할 수 있다.한편, 화자 얼굴-음성 매칭 데이터 수집 자동화부는, 화자의 얼굴-음성 매칭 데이터를 수집, 가공함에 있어서, 인공지능 알고리즘 기반의 자동화 프로세스에 의한 STF 학습 데이터베이스를 효율적이고 신속하게 구축하게 한 다. 종래기술의 경우 수작업으로 얼굴-음성 매칭 데이터 수집 및 가공함에 의한 시간과 비용이 과도하게 소요되는 문제점이 있다. 이에 반해, 본 발명의 실시 예에 따른 화자 얼굴-음성 매칭 데이터 수집 자동화부는, 웹사이트의 영상을 수집하 는 웹 크롤러인 영상 크롤링 엔진과, 수집된 영상의 비디오와 음성의 퀄리티를 평가(No-Reference Video Quality Assessments, No-Reference Audio Quality Assessments)하고 일정 기준을 넘는 경우만 저장하는 영상 퀄리티 평가 분석부와, 영상의 프레임 단위로 얼굴이 있는지 여부를 판단하는 딥러닝 기반의 얼굴 인식부와, 입 력된 오디오에서 화자별로 오디오를 분리하는 딥러닝 기반의 화자 분리부와, 하나의 오디오를 화자별로 분리하 는 딥러닝 모델을 사용하여 화자별 음성을 확보하는 음성 강화부와, 오디오와 얼굴이 있는 시간 구간을 매칭하 는 시점 매칭부와, 영상에서 말하는 사람의 얼굴을 찾는 딥러닝 기반의 화자 식별부를 포함한다. 이에 따라, 화자 얼굴-음성 매칭 데이터 수집 자동화부는, 인공지능 알고리즘을 이용하여 데이터 수집 과정을 자동화하여 화자의 얼굴과 음성이 매칭된 데이터를 다량으로 빠르게 수집할 수 있게 된다. 한편, 감정 기반 텍스트-음성 매칭 데이터 수집 자동화부는, 감정 기반의 텍스트-음성 매칭 데이터를 수집, 가 공하기 위한 인공지능 알고리즘 기반의 자동화 시스템을 구성한다. 종래기술의 경우 수작업으로 텍스트-음성 매칭 데이터 수집 및 가공함에 의한 시간과 비용이 과도하게 소요되는 문제점이 있다. 그러나, 본 발명의 실시 예에 따른 감정 기반 텍스트-음성 매칭 데이터 수집 자동화부는, 웹 크롤러로 오디오를 자동으로 크롤링하여 데이터를 확보하는 오디오 크롤링 엔진과, No-Reference Audio Quality Assessments을 통 해 고음질 오디오만 확보하는 오디오 평가 알고리즘 처리부와, 하나의 오디오를 화자별로 분리하는 딥러닝 모델 을 사용하여 화자별 음성을 확보하는 Speaker Diarization 엔진 처리부와, 노이즈가 포함된 음성 신호에서 노이 즈는 제거하고 음성은 보존하는 Speech enhancement 처리부와, 음성을 텍스트로 변환해주는 딥러닝 모델 사용하 여 음성에 맞는 텍스트를 라벨링한 데이터를 확보하는 Speech To Text 처리부와, 오디오의 감정을 분류하는 Speech Emotion Recognition 처리부와, 화자를 인식하되, 기존 데이터에 없는 화자일 경우 화자 정보를 추가하 고, 있는 경우 해당 화자 id로 저장하는 Speaker identification 처리부를 포함한다. 이에 따르면, 감정 기반 텍스트-음성 매칭 데이터 수집 자동화부의 구동에 따라, 인공지능 알고리즘을 이용하여 데이터 수집 과정을 자동화하여 화자의 얼굴과 음성이 매칭된 데이터를 다량으로 빠르게 수집할 수 있는 장점이 있다. 지금까지 설명한 본 발명의 실시 예들에 따르면, 참가자들이 선택한 아바타를 통해 회의 내용을 음성 또는 텍스 트 입력만으로 효과적으로 전달하면서, 아바타가 해당 내용에 따라 자연스럽게 의사소통 할 수 있는 가상 아바 타 기반의 가상 회의 시스템 및 그것의 동작 방법이 제공된다. 또한, 상기한 가상 회의 시스템을 통해, 회의 참여자는 자신만의 선택한 아바타를 통해 개성화된 표현을 할 수 있으며, 카메라가 없어서 음성이나 텍스트로만 하는 경우와 같이 제한된 상황에서 의사소통을 하는 경우에도 가 상 아바타가 전달하고자 하는 내용을 효과적으로 전달해주고, 화자와 청자가 언어가 달라도 쉽게 의사소통이 가 능할 수 있다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "또한, 가상 비서의 기능을 통해 회의 중 발생하는 내용을 기록하고, 중요한 내용을 자동으로 요약할 수 있으며, 가상 회의 중 필요한 정보나 자료를 웹에서 즉시 검색하여 참가자들에게 제공함으로써, 회의의 효율성과 생산성 을 크게 향상시킬 수 있게 된다. 이하에서는, 도 8을 참조하여 본 발명의 다양한 실시예에서 설명된 방법들이 구현되는 예시적인 컴퓨팅 장치 에 대하여 설명하도록 한다. 예를 들어, 도 8의 컴퓨팅 장치는 도 1의 가상 회의 시스템일 수 있다. 도 8는 컴퓨팅 장치를 나타내는 예시적인 하드웨어 구성도이다. 도 8에 도시된 바와 같이, 컴퓨팅 장치는 하나 이상의 프로세서, 버스, 통신 인터페이스, 프로세서에 의하여 수행되는 컴퓨터 프로그램을 로드(load)하는 메모리와, 컴퓨터 프로그램를 저장하는 스토리지를 포함할 수 있다. 다만, 도 8에는 본 발명의 실시예와 관련 있는 구성요소들"}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "만이 도시되어 있다. 따라서, 본 발명이 속한 기술분야의 통상의 기술자라면 도 8에 도시된 구성요소들 외에 다 른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발명의 기술 분야에 잘 알려진 임의의 형태의 프로세서 중 적어도 하나를 포함하여 구성될 수 있다. 또 한, 프로세서는 본 발명의 다양한 실시예들에 따른 방법/동작을 실행하기 위한 적어도 하나의 애플리케이 션 또는 프로그램에 대한 연산을 수행할 수 있다. 컴퓨팅 장치는 하나 이상의 프로세서를 구비할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 발명의 다양한 실시예들에 따른 방법/동작들을 실행하기 위하여 스토리지로부터 하나 이상의 프로그램을 로드(load) 할 수 있다. 메 모리의 예시는 RAM이 될 수 있으나, 이에 한정되는 것은 아니다. 버스는 컴퓨팅 장치의 구성 요소 간 통신 기능을 제공한다. 버스는 주소 버스(Address Bus), 데 이터 버스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 컴퓨팅 장치의 유무선 인터넷 통신을 지원한다. 통신 인터페이스는 인터넷 통신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 발명의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 스토리지는 하나 이상의 컴퓨터 프로그램을 비임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 지휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알 려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 본 발명의 다양한 실시예들에 따른 방법/동작들이 구현된 하나 이상의 인스트럭션 (Instruction)들을 포함할 수 있다. 예를 들어, 컴퓨터 프로그램은 제1 사용자의 아바타를 생성 또는 설정하는 동작, 상기 제1 사용자가 제공 한 송신 데이터와 상기 아바타에 기초하여 가상 아바타 영상을 생성하는 동작, 및 상기 가상 아바타 영상을 이 용하여 가상 회의 서비스를 제공하는 동작을 수행하기 위한 인스트럭션들을 포함할 수 있다. 컴퓨터 프로그램이 메모리에 로드 되면, 프로세서는 상기 하나 이상의 인스트럭션들을 실행시킴 으로써 본 발명의 다양한 실시예들에 따른 방법/동작들을 수행할 수 있다. 지금까지 설명된 본 발명의 기술적 사상은 컴퓨터가 읽을 수 있는 매체 상에 컴퓨터가 읽을 수 있는 코드로 구 현될 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체는, 예를 들어 이동형 기록 매체(CD, DVD, 블루레이 디스 크, USB 저장 장치, 이동식 하드 디스크)이거나, 고정식 기록 매체(ROM, RAM, 컴퓨터 구비 형 하드 디스크)일 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체에 기록된 상기 컴퓨터 프로그램은 인터넷 등의 네트워크를 통 하여 다른 컴퓨팅 장치에 전송되어 상기 다른 컴퓨팅 장치에 설치될 수 있고, 이로써 상기 다른 컴퓨팅 장치에 서 사용될 수 있다."}
{"patent_id": "10-2023-0135888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 본 발명이 다른 구체적인 형태로도 실시될 수 있다는 것을 이해할 수 있다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로 이해해야만 한다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명에 의해 정의되는 기술적 사상의 권리범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2023-0135888", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 가상 회의 시스템을 나타내는 블록도이다. 도 2는 송신자가 음성 데이터를 보낸 경우의 가상 회의 시스템의 동작 방법을 나타내는 도면이다. 도 3은 송신자가 텍스트 데이터를 보낸 경우의 가상 회의 시스템의 동작 방법을 나타내는 도면이다."}
{"patent_id": "10-2023-0135888", "section": "도면", "subsection": "도면설명", "item": 2, "content": "도 4는 도 1에 도시된 가상 비서를 통해 제공되는 가상 비서 서비스 중 회의 내용 요약 기능을 설명하기 위한 도면이다."}
{"patent_id": "10-2023-0135888", "section": "도면", "subsection": "도면설명", "item": 3, "content": "도 5은 도 1에 도시된 가상 비서를 통해 제공되는 가상 비서 서비스 중 자료 요약 기능을 설명하기 위한 도면이 다. 도 6은 도 1에 도시된 가상 비서를 통해 제공되는 가상 비서 서비스 중 자료 검색 기능을 설명하기 위한 도면이 다. 도 7은 도 1에 도시된 가상 회의 시스템을 주요 기능 블록 단위로 설명하기 위한 블록도이다. 도 8은 본 발명의 다양한 실시예들을 구현하기 위해 사용되는 컴퓨팅 장치의 하드웨어 구성을 예시적으로 나타 내는 블록도이다."}
