{"patent_id": "10-2021-0133809", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0050671", "출원번호": "10-2021-0133809", "발명의 명칭": "인공지능의 학습을 위한 언어 데이터셋 증강 방법 및 장치", "출원인": "주식회사 리니토", "발명자": "남지순"}}
{"patent_id": "10-2021-0133809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "AI 학습을 위한 데이터베이스 생성 장치에 의해 수행되는 방법에 있어서,적어도 하나의 도메인에 대한 텍스트를 포함하는 데이터를 획득하는 단계;상기 데이터를 전처리하는 단계;상기 전처리된 데이터에 대해 어휘소(lexeme) 및 문법소(morpheme) 분석 및 데이터 각각이 나타내는(expressing) 감성 정보를 기초로 태그를 태깅하는(tagging) 단계; 및상기 태그에 기초하여 단일 토큰 단위의 사전 정보 및 둘 이상의 다단어 토큰 단위의 패턴 정보를 포함하는 이중 구조의 데이터베이스를 생성하는 단계를 포함하는, AI 학습을 위한 데이터베이스 생성 방법."}
{"patent_id": "10-2021-0133809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 데이터를 획득하는 단계는,상기 적어도 하나의 도메인의 유형에 따라 데이터 수집 카테고리를 생성하는 단계;상기 데이터 수집 카테고리에 기초하여 데이터를 수집하는 단계; 및상기 수집된 데이터에 대응되는 메타데이터를 확인하는 단계를 포함하는, AI 학습을 위한 데이터베이스 생성 방법."}
{"patent_id": "10-2021-0133809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 데이터를 전처리하는 단계는,상기 데이터에 포함된 오류를 정정하는 단계 - 상기 오류는 띄어쓰기 오류 및 오기를 적어도 하나 포함함-;상기 데이터에 포함된 노이즈를 제거하는 단계 - 상기 노이즈는 이모티콘, 기 설정된 단위 이상의 반복 텍스트,특수문자 및 부호 중 적어도 하나를 포함함 -; 및상기 데이터에서 문장 분리를 나타내는 표시자(indicator)를 삽입하는 단계를 포함하는, AI 학습을 위한 데이터베이스 생성 방법."}
{"patent_id": "10-2021-0133809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 태깅하는 단계는,상기 전처리된 데이터에 대해 상기 어휘소 및 문법소 분석을 기초로 제1 태그를 태깅하는 단계;상기 제1 태그에 기초하여, 상기 전처리된 데이터의 단일 토큰이 나타내는 극성 감성 정보, 심리 감성 정보 및지시하는(indicating) 개체 정보를 분석하여 제2 태그를 태깅하는 단계; 상기 제1 태그에 기초하여, 상기 전처리된 데이터의 둘 이상의 토큰이 결합된 다단어 토큰의 결합 패턴을 분석하여 제3 태그를 태깅하는 단계; 및상기 제2 태그 및 제3 태그 중 적어도 하나에 대해 상기 적어도 하나의 도메인 별로 분류하여 제4 태그를 태깅하는 단계를 포함하는, AI 학습을 위한 데이터베이스 생성 방법.공개특허 10-2023-0050671-3-청구항 5 제4항에 있어서,상기 제1 태그를 태깅하는 단계는,상기 어휘소를 분석하는 단계; 및상기 문법소를 분석하는 단계를 포함하고,상기 어휘소를 분석하는 단계는,어휘 데이터베이스를 기초로 상기 전처리된 데이터에 포함된 적어도 하나의 어휘소를 획득하는 단계;상기 적어도 하나의 어휘소에 품사 및 활용 정보를 태깅하는 단계;상기 품사 및 활용 정보를 기초로 상기 적어도 하나의 어휘소의 어간 변이형을 확인하고 컴파일하는 단계; 및상기 활용 정보를 기초로 상기 적어도 하나의 어휘소에 대한 결합 형태소 구성 정보 및 결합 제약 정보를 확인하는 단계를 포함하는, AI 학습을 위한 데이터베이스 생성 방법."}
{"patent_id": "10-2021-0133809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 문법소를 분석하는 단계는,상기 결합 문법소 구성 정보를 기초로 상기 적어도 하나의 어휘소 각각에 결합되는 적어도 하나의 문법소를 확인하는 단계;상기 적어도 하나의 문법소 각각의 구성 원소에 대한 선형 그래프를 생성하는 단계;상기 선형 그래프의 각 노드에 대하여 속성 값을 태깅하는 단계 - 상기 속성은 상기 선형 그래프의 각 노드에대응되는 문법소의 의미, 문법 및 담화 정보를 적어도 하나 포함함 -; 및상기 선형 그래프에 대한 태그 정보를 기초로 상기 적어도 하나의 어휘소의 어간 변이형에 대해 결합 가능한 문법소 정보를 출력하는 모델을 생성하는 단계를 포함하는, AI 학습을 위한 데이터베이스 생성 방법."}
{"patent_id": "10-2021-0133809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 이중 구조의 데이터베이스는,상기 제2 태그 및 상기 제2 태그에 대한 제4 태그가 태깅된 데이터를 포함하는 제1 데이터베이스; 및 상기 제3 태그 및 상기 제3 태그에 대한 제4 태그가 태깅된 데이터를 포함하는 제2 데이터베이스를 포함하는,AI 학습을 위한 데이터베이스 생성 방법."}
{"patent_id": "10-2021-0133809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 적어도 하나의 도메인에 대한 텍스트를 포함하는 데이터를 반복적으로 획득하는 단계; 및상기 반복적으로 획득된 데이터를 기초로 상기 데이터베이스를 업데이트하는 단계를 더 포함하는, AI 학습을 위한 데이터베이스 생성 방법."}
{"patent_id": "10-2021-0133809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "컴퓨터와 결합되어, 제1항 내지 제8항 중 어느 하나의 항의 AI 학습을 위한 데이터베이스 생성 방법을 실행시키기 위하여 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0133809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2023-0050671-4-AI 학습을 위한 데이터베이스 생성 장치에 있어서,통신부;저장부; 및제어부를 포함하고,상기 제어부는,상기 통신부 및 상기 저장부 중 적어도 하나를 통해, 적어도 하나의 도메인에 대한 텍스트를 포함하는 데이터를획득하고,상기 데이터를 전처리하고,상기 전처리된 데이터에 대해 어휘소 및 문법소 분석 및 데이터 각각이 나타내는 감성 정보를 기초로 태그를 태깅하고,상기 태그에 기초하여 단일 토큰 단위의 사전 정보 및 둘 이상의 다단어 토큰 단위의 패턴 정보를 포함하는 이중 구조의 데이터베이스를 생성하는, AI 학습을 위한 데이터베이스 생성 장치."}
{"patent_id": "10-2021-0133809", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "AI 학습을 위한 데이터베이스 생성 방법을 제공한다. 상기 방법은, 적어도 하나의 도메인에 대한 텍스트를 포함 하는 데이터를 획득하는 단계; 상기 데이터를 전처리하는 단계; 상기 전처리된 데이터에 대해 어휘소(lexeme) 및 문법소(morpheme) 분석 및 데이터 각각이 나타내는(expressing) 감성 정보를 기초로 태그를 태깅하는(tagging) 단계; 및 상기 태그에 기초하여 단일 토큰 단위의 사전 정보 및 둘 이상의 다단어 토큰 단위의 패턴 정보를 포함 하는 이중 구조의 데이터베이스를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0133809", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능(AI) 학습을 위한 데이터베이스 생성 방법 및 장치에 관한 것이다. 특히, 본 발명은 어휘 사 전과 패턴 문법에 기초하여 머신러닝을 위한 학습 데이터를 반자동으로 증강하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2021-0133809", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술 분야에서 인간의 언어에 대한 처리 기술은 가장 중요한 핵심 기술 중 하나이다. 한편, 빠르게 향 상되는 다양한 머신러닝 방법론을 한국어 처리 분야에 적용하기 위해서는 한국어에 특화된 양질의 대용량 언어 학습데이터가 반드시 필요하다. 이때 학습데이터에는 각 응용분야에서 요구되는 특정 유형의 언어정보가 함께 제공되어야 한다. 특히, 소셜미디어에서 사용자가 생성하는 텍스트에 대해 평가대상과 자질표현, 감성표현 등에 대한 신뢰할 수 있는 주석(또는 태그) 정보가 부착된 학습 데이터의 제공이 필요하다. 이러한 주석 정보가 부착 된 학습 데이터의 제공은 소셜미디어 사용자 생성문 텍스트에 대한 자질기반 감성분석(Feature-Based Sentiment Analysis, FBSA) 모델 개발에 있어 시스템의 성능을 좌우하는 핵심 열쇠가 된다. 그러나, 학습 데이터에서 제공하는 언어 정보가 단순한 형태인 경우, 이를 시스템에서 자동으로 수집하거나 획 득하는 것이 가능하지만, 일련의 의미적인 또는 비규칙적인 언어표현 정보가 주석 되어야 하는 경우에는 시스템 에서 자동으로 수집하는 것이 용이하지 않다. 이때 아마존 미케니컬 터크(Mechanical Turk)와 같은 클라우드소 싱 방법으로 익명의 작업자 그룹을 통해 이를 수행하는 접근법이 사용될 수 있다. 그러나, 이러한 수동 접근법 은 기계에 의한 자동 접근법의 한계를 넘어설 수는 있으나, 작업자의 숙련도와 전문지식 보유의 문제 등으로 인 해 심화된 작업을 기대하기 어려운 경우가 많아, 상대적으로 낮은 수준의 주석 작업에 집중되는 경향을 보인다. 또한, 작업에 소요되는 시간과 비용으로 인해 대규모의 양질의 학습 데이터를 생성하는 것에 한계가 있다. 본 발명에서는 이상에서 논의한 양질의 학습 데이터를 수동으로 구축하는 과정의 문제점을 해결하기 위해, 사전 과 같은 어휘 데이터베이스와 다단어 패턴 문법 기술에 기반하여, 반자동으로 데이터를 증강하는 방법론을 제시 한다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허번호 제10-1887415호, 2018.08.06"}
{"patent_id": "10-2021-0133809", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2021-0133809", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 어휘 데이터베이스와 다단어 패턴 문법에 기초하여, 머신러닝 언어 모델 개 발을 위한 학습 데이터를 반자동으로 증강하는 방법(Semi-automatic Symbolic Propagation, SSP)을 제공하는 것이다. 특히, 본 발명은 자질기반 감성분석에 필요한 학습 데이터를 생성하는 방법을 제공할 수 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0133809", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 일 면에 따른 AI 학습을 위한 데이터베이스 생성 방법은 적어도 하나의 도메인에 대한 텍스트를 포함하는 데이터를 획득하는 단계; 상기 데이터를 전처리하는 단계; 상기 전처리된 데 이터에 대해 어휘소(lexeme) 및 문법소(morpheme) 분석 및 데이터 각각이 나타내는(expressing) 감성 정보를 기 초로 태그를 태깅하는(tagging) 단계; 및 상기 태그에 기초하여 단일 토큰 단위의 사전 정보 및 둘 이상의 다단 어 토큰 단위의 패턴 정보를 포함하는 이중 구조의 데이터베이스를 생성하는 단계를 포함한다. 또한, 본 발명의 일 면에 따른 AI 학습을 위한 데이터베이스 생성 장치에 있는 통신부; 저장부; 및 제어부를 포 함하고, 상기 제어부는, 상기 통신부 및 상기 저장부 중 적어도 하나를 통해, 적어도 하나의 도메인에 대한 텍 스트를 포함하는 데이터를 획득하고, 상기 데이터를 전처리하고, 상기 전처리된 데이터에 대해 어휘소 및 문법 소 분석 및 데이터 각각이 나타내는 감성 정보를 기초로 태그를 태깅하고, 상기 태그에 기초하여 단일 토큰 단 위의 사전 정보 및 둘 이상의 다단어 토큰 단위의 패턴 정보를 포함하는 이중 구조의 데이터베이스를 생성할 수 있다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2021-0133809", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 면에 따르면, 어휘 데이터베이스와 다단어 패턴 문법에 기초하여 머신러닝 언어 모델 개발을 위한 학습 데이터를 반자동으로 증강하는 방법(SSP)과 그 장치를 제공할 수 있다. 또한, 본 발명의 일 면에 따르면, 감성 분석 및 의도 분석, AI 어시스턴트와 챗봇 다이얼로그 등과 같은 응용 영역의 언어 모델을 개발하는 데에 중요한 언어 자원을 반자동으로 증강하여 제공할 수 있다."}
{"patent_id": "10-2021-0133809", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0133809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 자질기반 감성분석을 위한 언어 정보 주석 작업이 사람의 개입없이 수행되기 위해서는, 몇가지 언어처리 관련 제반 기술이 선결되어야 한다. 우선, 인터넷 및 모바일 소셜미디어 플랫폼을 통해 사용자들이 생성하는 빅데이 터 텍스트에서 관찰되는 비정형적 표현들에 대해 일련의 전처리 과정을 수행하기 위해 언어 자원 및 처리 기술 이 요구된다. 사용자 생성문(User-Generated Text, UGT)에는 의도적 또는 비의도적 띄어쓰기나 맞춤법 오류 등 의 문제가 빈번하게 발생하기 때문에, 이에 대한 전처리 과정 없이는 자동 주석을 위한 언어 자원 구축이 제대 로 진행되기 어렵기 때문이다. 둘째로, 한국어 특유의 형태적 복합 구성에 대한 정교한 분석 기술이 필요하다. 예를 들어, 용언의 어간에 결합하는 다양한 활용 어미들의 경우 화자의 의지나 요청, 희망 등의 주관적 감정 및 의견 표현이 드러나는 경우가 빈번하기 때문에, 기존의 단순 토크나이저(tokenizer)나 레마타이저(lemmatizer) 와 같은 기술력만으로는 이러한 요소들에 대한 감성분석 주석이 자동으로 수행되기 어렵기 때문이다. 셋째로, 사용자 생성문에서는 단일어로 실현되는 감성 표현에 대한 인식만으로는 올바른 자질기반 감성분석을 수행하기 어려운 경우가 빈번하기 때문에, 여러 단위로 분리되어 있지만 실제로는 하나의 의미 단위로 인식되어야 하는 유형을 분석해야 하며, 이를 위해 구/절 단위 언어 정보에 대한 데이터베이스가 필요하다. 이러한 복합 구절에 대한 언어 자원의 구성은 간단한 규칙으로 예측되지 않으므로 상당한 고도의 언어 이해 기술이 축적되어야 한다. 본 발명에서는 상기 지적한 기존의 한계점을 극복할 수 있도록 디자인된 데이터베이스와 패턴문법을 기반으로 하여, 반자동으로 대용량 학습 데이터가 증강될 수 있는 방법 및 장치를 제시한다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 도 1은 본 발명의 일 실시 예에 따른 AI 학습을 위한 데이터베이스 생성 방법을 나타낸 흐름도이다. 단계 S110에서 적어도 하나의 도메인에 대한 텍스트를 포함하는 데이터를 획득할 수 있다. 일 실시 예에 따르면, 데이터를 획득하기 위해, 적어도 하나의 도메인의 유형에 따라 데이터 수집 카테고리를 생성하고, 데이 터 수집 카테고리에 기초하여 데이터를 수집하고, 수집된 데이터에 대응되는 메타데이터를 확인할 수 있다. 또한, 메타데이터와 수집된 데이터를 별도의 데이터베이스에 저장할 수 있다. 단계 S120에서 데이터를 전처리할 수 있다. 일 실시 예에 따르면, 데이터에 포함된 오류를 정정하고, 데이터에 포함된 노이즈를 삭제하고, 데이터에서 문장 분리를 나타내는 표시자를 삽입함으로써, 데이터를 전처리할 수 있 다. 일 실시 예에 따르면, 오류 정정은 띄어쓰기 오류를 교정하거나, 타이핑 오기를 정정하는 것을 포함할 수 있다. 또한, 노이즈 삭제는 이모티콘, 반복되는 텍스트, 특수문자, 및 부호 중 적어도 하나를 삭제하는 것을 포 함할 수 있다. 그리고, 표시자를 삽입하는 것은 데이터를 단문 구조 형식을 분할하기 위한 구분자 부호를 삽입 하는 것을 포함할 수 있다. 단계 S130에서 전처리된 데이터에 대해 어휘소(lexeme) 및 문법소(morpheme) 분석 및 데이터 각각이 나타내는 (expressing) 감성 정보를 기초로 태그를 태깅(tagging)할 수 있다. 일 실시 예에 따르면, 태깅하는 것은 단계 S120에서 전처리된 데이터에 대해 어휘소 및 문법소 분석을 기초로 제1 태그를 태깅하고, 제1 태그에 기초하여 전처리된 데이터의 단일 토큰이 나타내는 극성 감성 정보, 심리 감성 정보 및 지시하는(indicating) 개체 정보 를 분석하여 제2 태그를 태깅하고, 제1 태그에 기초하여 전처리된 데이터의 둘 이상의 토큰이 결합된 다단어 시 퀀스의 결합 패턴을 분석하여 제3 태그를 태깅하고, 제2 태그 및 제3 태그 중 적어도 하나에 대해 적어도 하나 의 도메인 별로 분류하여 제4 태그를 태깅하는 것을 포함할 수 있다. 일 실시 예에 따르면, 단계 S130에서 제1 태그를 태깅하는 것은 전처리된 데이터에 대해 어휘소를 분석하고, 문 법소를 분석하는 것을 포함할 수 있다. 이때 어휘소를 분석하는 것은 어휘 데이터베이스를 기초로 전처리된 데 이터에 포함된 적어도 하나의 어휘소를 획득하고, 적어도 하나의 어휘소에 품사 및 활용 정보를 태깅하고, 품사 및 활용 정보를 기초로 적어도 하나의 어휘소의 어간 변이형을 확인하고 컴파일하며, 활용 정보를 기초로 적어 도 하나의 어휘소에 대한 결합 문법소 구성 정보 및 결합 제약 정보를 확인하는 것을 포함할 수 있다. 또한, 문 법소를 분석하는 것은 결합 문법소 구성 정보를 기초로 적어도 하나의 표제어 각각에 결합되는 적어도 하나의 문법소를 확인하고, 적어도 하나의 문법소 각각의 구성 원소에 대한 선형 그래프를 생성하고, 선형 그래프의 각 노드에 대하여 속성 값을 태깅하고, 선형 그래프에 대한 태그 정보를 기초로 적어도 하나의 어휘소의 어간 변이 형에 대해 결합 가능한 문법소 정보를 출력하는 모델을 생성하는 것을 포함할 수 있다. 이떄 각 노드에 대한 속 성은 선형 그래프의 각 노드에 대응되는 문법소의 의미, 문법 및 담화 정보를 적어도 하나 포함할 수 있다. 단계 S140에서 태그에 기초하여 단일 토큰 단위의 사전 정보 및 둘 이상의 다단어 토큰 단위의 패턴 정보를 포 함하는 이중 구조의 데이터베이스를 생성할 수 있다. 일 실시 예에 따르면, 이중 구조의 데이터베이스는 제2 태 그 및 제2 태그에 대한 제4 태그가 태깅된 데이터를 포함하는 제1 데이터베이스 및 제3 태그 및 제3 태그에 대 한 제4 태그가 태깅된 데이터를 포함하는 제2 데이터베이스를 포함할 수 있다. 즉, 제1 데이터베이스는 단일 토 큰 단위의 사전 정보에 기초한 태그가 태깅된 데이터에 대한 데이터베이스이고, 제2 데이터베이스는 둘 이상의 다단어 토큰 단위의 패턴 정보에 기초한 태그가 태깅된 데이터에 대한 데이터베이스이다. 일 실시 예에 따르면, 전술한 단계 S110 내지 S140은 반복적으로 수행되어 데이터베이스가 지속적으로 업데이트 되도록 할 수 있다. 이하의 도면들을 참조로 하여 각 단계의 구성을 보다 자세히 살펴보기로 한다. 도 2는 본 발명의 일 실시 예에 따른 AI 학습을 위한 데이터베이스 생성 방법을 나타낸 상세 흐름도이다. 도 2를 참조하면, 데이터 유형 분류 테이블에 기초하여 데이터의 수집과 저장이 수행될 수 있다(S210). 예 를 들어, 소셜미디어 카테고리 분류테이블(Social media Category Classification, SCC)에 기초하여 소셜미디 어 사용자 생성문 데이터를 수집되고 이에 대한 유형별 데이터 저장 작업이 수행될 수 있다. 일 실시 예에 따르 면, 데이터 수집 이전에 데이터 유형 분류 설계 과정이 추가적으로 수행될 수 있다. 다음으로, 전처리 문법 테이블에 기초하여 수집된 데이터에 대한 노이즈 제거 및 전처리가 수행될 수 있다 (S220). 구체적으로, 소셜미디어 텍스트의 비정규성의 특징을 해결하기 위하여 전처리 문법 테이블 (Preprocessing Grammar Table, PGT)이 적용되어, 수집된 텍스트의 노이즈를 제거하고 전처리하는 과정이 진행 될 수 있다. 일 실시 예에 따르면, 전처리가 수행된 이후, 어휘소(lexeme) 사전 및 활용후치사 변환(transducer) 사전 을 기초로 어휘소 및 문법소 분석이 수행될 수 있다(S230). 예를 들어, 어휘소 사전과 활용후치사 문법소 사전 으로 구성된 활용형 사전이 적용되어, 수집된 텍스트의 형태소 분석과 표제어 분석(lemmatizing)이 수행될 수 있다. 이와 더불어, 범용 어휘 사전을 기초로 극성 감성, 심리 감성 및 개체 정보를 태깅할 수 있다 (S240). 구체적으로, 전자 사전과 같은 범용 어휘 사전에 수록되는 표제어에 대한 형태 정보, 술어 별 논항 구조 정보, 의미 온톨로지 정보 등을 토대로 하여, FBSA에서 필요로 하는 극성 감성(POL) 정보, 심리 감성(PSY) 정보, 및 도메인/개체명 정보를 이용하여, 수집된 데이터에 포함된 토큰들에 대한 감성 지식 정보를 자동으로 태깅할 수 있다. 또한, 데이터가 나타내는 대상에 대한 개체명과 자질어, 감성 단일어 토큰(Simple Sentiment Expressions, SSE) 등이 자동으로 태깅될 수 있다. 다음으로, 범용 패턴 문법 사전을 기초로 복합 명사구, 감성 시퀀스 및 구/절 단위 표현 정보가 태깅될 수 있다(S250). 구체적으로, 범용 다단어 패턴 문법 테이블을 통해 복합 구성 및 다단어(Multi-Word Expression, MWE) 감성 표현 시퀀스 정보, 극성 전환어에 의한 극성 정보, 정보 부사어가 적용된 극성 등급 정보 등을 나타 낼 수 있다. 그리고 이러한 정보를 토대로 수집된 데이터에 대하여 복합 감성 시퀀스(Multi-word Sentiment Expressions, MSE) 및 복합어, 구/절 단위 표현, 관용 표현, 극성 전환된 표현, 극성 강화/약화된 표현 등에 대 한 태깅을 자동으로 수행할 수 있다. 일 실시 예에 따르면, 도메인 사전 및 도메인 문법에 기초하여 도메인 지식을 태깅할 수 있다(S260). 구체 적으로, 도메인 사전 및 도메인 문법은 범용 어휘 사전 및 범용 패턴 문법 사전과 같은 범용 언 어 자원과 동일한 프레임에 기반하여 도메인 특화 서브 자원이 적용될 수 있다. 도메인 특화 서브 자원은 도메 인 지식을 기초로 하는 어휘 사전과 다단어 패턴 문법으로 구성되며, 이를 범용 언어 자원에 전달하여 궁극적으 로 해당 도메인의 평가대상어(t), 평가자질어(f), 감성표현(se)의 원소쌍을 태깅할 수 있다. 단계 S210 내지 S260이 진행된 후, FBSA용 이중구조 데이터베이스가 생성될 수 있다. 데이터베이스는 토큰 단위 사전 정보가 태그된 데이터를 포함하는 제1 데이터베이스와 구/절 단위 패턴 정보가 태그된 데 이터를 포함하는 제2 데이터베이스를 포함할 수 있다. 일 실시 예에 따르면, 사전 기반 주석 레이어 (DICTIONARY-LAYER)에서 토큰 단위 사전 정보가 자동으로 태깅되어 제1 데이터베이스에 저장될 수 있고, 구 단위 주석 레이어(PHRASE-LAYER)에서 구/절 단위 패턴 정보가 자동으로 태깅되어 제2 데이터베이스에 저장될 수 있다. 이러한 과정을 통해 대용량의 학습데이터가 데이터베이스내에서 증강될 수 있다. 본 개시에서, 데이터베이스는 AI 학습을 위한 데이터 생성 장치에 포함된 각 기능부에 유선 통신, 무선 통 신, 데이터 직접 제공 등의 방식으로 각종 요청사항 정보(또는 데이터)를 제공될 수 있다. 예를 들어, AI 학습 을 위한 데이터 생성 장치는 동축 케이블, 유선 랜(LAN; Local Area Network)(예컨대, 이더넷(Ethernet)) 등 유선 네트워크 방식으로 각종 요청사항 정보(또는 데이터)를 자신에 포함된 각 기능부에 제공함으로써 AI 학습 을 위한 데이터 생성 방법을 수행할 수 있다. 예를 들어, AI 학습을 위한 데이터 생성 장치는 이동통신 표준 통 신방식에 따라 구축된 이동 통신망 상에서 패킷의 형태로 요청사항 정보 제공할 수 있다. 예를 들어, 데이터베 이스는 이동식 디스크 등의 저장 매체를 통해 AI 학습을 위한 데이터 생성 장치에 물리적으로 이식될 수 있다. 데이터베이스는 AI 학습을 위한 데이터 생성 장치의 다양한 기능을 지원하는 로컬 저장 매체일 수 있다. 데이터베이스는 AI 학습을 위한 데이터 생성 장치에서 구동될 수 있는 응용 프로그램, 동작을 위한 데이터 들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 장치로부터 다운로드 될 수 있다. 응용 프로그램은, 데이터베이스에 저장되고, AI 학습을 위한 데이터 생성 장치 상에 설치되어, AI 학습을 위한 데이터 생성 장치의 프로세서(미도시)에 의하여 동작(또는 기능)을 수행하도록 구동 될 수 있다. 데이터베이스는 DDR SDRAM(Double Data Rate Synchronous Dynamic Random Access Memory), LPDDR(Low Power Double Data Rate) SDRAM, GDDR(Graphics Double Data Rate) SDRAM, RDRAM(Rambus Dynamic Random Access Memory), DDR2 SDRAM, DDR3 SDRAM, DDR4 SDRAM 등과 같은 동적 랜덤 액세스 메모리(Dynamic Random Access Memory, DRAM)일 수 있다. 그러나, 본 개시의 실시 예들은 이에 국한될 필요가 없다. 예시적인 실시 예에서, 데이터베이스는 AI 학습 을 위한 데이터 생성 장치에 공급되는 전원이 차단되더라도 데이터들이 남아있어야 하며, 변동사항을 반영할 수 있도록 쓰기 가능한 비휘발성 메모리(Non-Volatile Memory)로 구비될 수 있다. 그러나, 이에 한정되지 않고, 데 이터베이스는 플래시 메모리(Flash Memory) 또는 EPROM 또는 EEPROM, ReRAM(resistive RAM)과 같은 저항 형 메모리 셀들, PRAM(phase change RAM), MRAM(magnetic RAM), MRAM(Spin-Transfer Torgue MRAM), Conductive bridging RAM(CBRAM), FeRAM(Ferroelectric RAM), 및 다른 다양한 종류의 메모리가 적용될 수 있다. 또는, 데이터베이스는 임베디드 멀티미디어 카드(embedded multimedia card, eMMC), 유니버셜 플래 시 스토리지(universal flash storage, UFS), 또는 CF(Compact Flash), SD(Secure Digital), Micro-SD(Micro Secure Digital), Mini-SD(Mini Secure Digital), xD(extreme Digital) 또는 메모리 스틱(Memory Stick) 등다양한 종류의 장치로 구현될 수 있다. 본 개시에서 설명의 편의를 위해 하나의 데이터베이스에 모든 인스 트럭션 정보가 저장되는 것으로 설명하고 있으나, 이에 한정되는 것은 아니며, 데이터베이스는 복수의 메 모리들을 구비할 수 있다. 도 3은 본 발명의 일 실시 예에 따라 수집된 소셜미디어 텍스트를 유형 별로 분류하여 저장하는 방법을 나타낸 흐름도이다. 소셜미디어 텍스트는 다양한 유형의 사회관계망 플랫폼을 통해 각 사용자들이 직접 업로드하는 텍스트 형식의 데이터로, 이러한 사용자 생성문(UGT)은 객관적 사실과 정보를 담고 있는 뉴스 기사와 달리, 주관적 의견이나 판단, 감정, 추론, 주장 등의 주관적 메시지를 전달할 수 있다. 예를 들어, 소셜미디어 텍스트가 상품의 구매 후 작성되는 후기글인지, 또는 블로그 및 카페 동호회에서 회원들 간에 공유되는 특정 영역의 경험 공유글인지, 영화나 콘서트 등의 문화 체험에 대한 감상글인지, 호텔이나 숙박 등의 체험 정보글인지, 트위터나 페이스북에 업로드되는 개인적 의견글인지, 또는 신문기사 등의 정치 사회적 이슈에 대한 댓글로 작성되는 글인지에 따라 그 양상이 다르게 나타날 수 있다. 이러한 소셜미디어 텍스트는 현대의 빅데이터 기반 언어처리 연구 영역에서 가장 중요한 데이터 원천이 되기 때 문에, 다양한 머신러닝, 딥러닝 시스템에서 이러한 소셜미디어 텍스트를 분석하기 위해서 개인들의 감정 및 오 피니언을 분석하는 감성분석(Sentiment Analysis) 또는 오피니언 마이닝(Opinion Mining) 연구 기술이 요구된다. 도 3을 참조하면, 먼저, 소셜미디어 텍스트에 대한 도메인 유형 분류가 진행될 수 있다(S310). 도메인은 적어도 하나 있을 수 있으며, 소셜미디어 텍스트가 생성되는 영역에 대한 속성을 나타낼 수 있다. 예를 들어, 상품 구매 후기글에 대한 도메인의 경우, 평가 대상(예를 들어, 브랜드명, 특정 상품명)이 텍스트 내에 명시적 으로 나타나지 않을 수 있다. 이러한 도메인에서의 평가대상(TARGET)은 후기글들이 작성되는 색션의 메타데이터 로 주어지기 때문에 작성자들은 이러한 평가 대상 어휘를 반복하지 않고, 이에 대한 평가 내용을 곧바로 작성할 수 있기 때문이다. 반면, 정치기사에 대한 댓글과 같은 도메인에서 텍스트는 작성자들의 긍정 또는 부정의 평가 에 대한 평가대상이 텍스트 내에 명시적으로 나타날 수 있다. 이 경우, 평가 대상이 되는 정치가를 지지 또는 반대하는 입장에 따라, 평가 대상의 개체명이 욕설이나 특정 접두사 등을 통해 변형된 형태로 표현될 수 있다. 본 발명의 일 실시 예에 따르면, 사용자 생성문을 수집 데이터로 하는 경우, 어떠한 유형의 소셜미디어를 대상 으로 하는가가 먼저 고려될 수 있으며, 이때 수집되는 대상의 속성에 따라 어떠한 방식의 하위 범주화가 이루어 져야 하는지 결정될 수 있다. 따라서, 수집되는 데이터의 비균형성과 편중성의 문제를 해결하기 위하여, 소셜미 디어 카테고리 분류 테이블(Social Media Category Classification, SCC)을 기초로 각 소셜미디어의 카테 고리가 쇼핑몰 후기글인가, 정치댓글과 같은 사회이슈 관련 텍스트인가로 구별할 수 있다. 구체적으로, 소셜미 디어 카테고리 분류 테이블을 통해 각 도메인 별 하위 분류가 세분화될 수 있다. 예를 들어, 쇼핑몰 후기 글의 경우, 어떠한 유형의 아이템인가에 따라 텍스트가 하위 분류될 수 있다. 일 실시 예에 따르면, 소셜미디어 카테고리 분류 테이블은 소셜미디어의 도메인별 대분류, 중분류, 소분류 방식의 계층구조(taxonomy) 로 구조화될 수 있으며, 이를 토대로 사용자 생성문의 대표성 (representativeness)과 균형성(balance)의 속성을 유지할 수 있다. 예를 들어, 특정 소셜미디어 플랫폼에서 의 류 관련 후기글 도메인의 텍스트를 수집할 때, 여성 원피스 후기글의 비중이 90%를 차지하게 된다면, ‘부츠컷 이 맘에 든다’와 같은 바지에 대한 긍정 감성 표현은 수집되지 않을 수 있다. 이것은 실제 판매되는 바지 아이 템의 수가 적거나, 바지 구매자의 수가 적어서, 전체적으로 바지 아이템에 대한 후기글의 비중이 축소되어서 생 기는 문제와는 달리, 수집된 데이터의 비균형성의 문제에서 비롯된 현상일 수 있다. 따라서, 도메인 별 하위 분 류 체계가 적용되면, 사용자 생성문의 대표성과 균형성의 속성을 유지하는데 보다 효과적일 수 있다. 소셜미디어 카테고리 분류 테이블을 통해 각 도메인 별 하위 분류가 수행된 이후, 웹크롤러(web crawler) 를 이용해 대상 데이터가 수집될 수 있다(S320). 그리고, 수집되는 데이터는 가용한 모든 메타데이터와 함께 테 이블 파일 형식으로 저장될 수 있다(S330). 도 4는 본 발명의 일 실시 예에 따른 데이터 전처리 모듈을 나타낸 도면이다. 도 4를 참조하면, 데이터 전처리 모듈은 수집된 데이터의 노이즈 및 비정형 부분을 처리하기 위한 전처리 문법 테이블(PGT)의 모듈별 유형을 포함한다. 구체적으로, 데이터 전처리 모듈은 치환 모듈, 제거 모 듈 및 삽입 모듈을 포함할 수 있다. 도 3에서 상술한 사용자 생성문의 형식적 측면을 보면, 기존 출판물이나 교과서, 신문기사 등과 같이 정형화된 문서들과 달리, 사용자 생성문은 개인들이 직접 업로드하는 텍스트이므로, 맞춤법이나 띄어쓰기, 오타, 신조어 등의 오류나 의도적인 변형이 빈번히 등장하는 비정형 문서의 성격을 보일 수 있다. 플랫폼에 따라서는 글자수 의 제한이 있어 이를 피하기 위해 띄어쓰기가 누락되는 현상이 빈번하게 관찰될 수 있으며, 이러한 현상은 기존 의 언어 자원을 이용하여 자동 형태소 분석을 하는 경우, 분석 성능을 저하시킬 수 있다. 따라서, 사용자 생성 문을 수집 데이터로 할때 관찰되는 노이즈(noise) 및 비정형 현상을 처리하기 위해 별도의 전처리 문법 테이블 이 적용될 수 있다. 치환 모듈은 데이터에 포함된 오류를 치환하여 정정할 수 있다. 구체적으로, 치환 모듈은 고빈도 띄 어쓰기 오류와 입력 오타 유형 등을 검출하여, 오류를 정상 표현으로 치환하는 패턴을 기록하는 패턴 치환 (pattern replace) 방식으로 테이블을 구성할 수 있다. 그리고, 테이블을 수집 데이터에 적용하여 오류를 정정 할 수 있다. 일 실시 예에 따르면, 오류 정정 과정에서 처리되지 않은 오류 유형들에 대하여는 휴리스틱 교정법 이 별도로 적용될 수 있다. 제거 모듈은 데이터에 포함된 노이즈를 제거할 수 있다. 일 실시 예에 따르면, 텍스트 데이터에 포함된 노 이즈에는 이모티콘, 반복 텍스트, 특수문자 및 부호 등이 포함될 수 있다. 제거 모듈은 이모티콘이나 긴 반복 유형의 정규화를 위한 부분 소거 및 특수문자, 부호 등의 노이즈 등을 제거하기 위한 테이블을 구성하여 수집 데이터에 적용할 수 있다. 삽입 모듈은 입력 텍스트를 단문 구조 형식으로 분할하기 위해 문장 분리(SENTENCE SPLIT)를 나타내는 표 시자를 삽입할 수 있다. 일 실시 예에 따르면 표시자는 입력 텍스트 내부에 존재하는 종결부호 구두점 (punctuation mark)의 우측에 삽입될 수 있다. 종결부호 구두점이 존재하지 않는 경우에는 단문 구조 분리 알고 리즘을 적용하여 표시자를 삽입할 수 있다. 도 5는 본 발명의 일 실시 예에 따른 전처리된 데이터를 어휘소 및 문법소 모듈들을 통해 분석하는 방법을 나타 낸 흐름도이다. 어휘소 모듈 및 문법소 모듈은 자연어처리(NLP) 모듈의 일부로서 동작을 수행할 수 있다. 본 개시에 서, 자연어처리 모듈은 사용자로부터 입력된 요청사항, 또는 전처리 데이터에 대한 자연어 처리를 하도록 구성 될 수 있다. 자연어는 사용자가 일상에서 사용하는 언어이다. 자연어처리 모듈은 기계가 자연어를 해독하고 분 석하여 변환하도록 구성된다. 예시적 실시 예에서, 자연어처리 모듈은 사용자로부터 수신한 문언 텍스트를 데이 터화 하여 분류할 수 있다. 즉, 자연어처리 모듈은 사용자가 입력한 문장 또는 단어를 임베딩하여 n차원의 벡터 형식으로 나타나는 데이터(사용자로부터 수신한, 요청사항)로 변환할 수 있다. 이하에서 임베딩된 사용자가 입 력한 문장 또는 단어를 요청사항, 또는 요청사항 정보라고 칭한다. 자연어 처리는 본 개시에 선행 문헌으로 기 재된 문헌을 참조하여 당 기술 분야에서 통상의 지식을 가진 사람이 용이하게 실시 가능하므로 자세한 설명은 생략한다. 그렇다고, 본 개시에서 자연어 처리를 선행 문헌의 내용으로 한정하는 것은 아니며, 당 기술 분야에 서 통상의 지식을 가진 사람이 실시할 수 있는 범위는 본 개시에 포함된다. 상술한 언어 모델을 사용하면 자연 어를 분류하고 특징을 추출하여 벡터화 하는 것이 가능하다. 자연어처리 모듈은 사용자의 요청사항에 대한 자연어 처리를 하도록 구성된다. 자연어처리 모듈은 인공 신경망 (Artificial Neural Network, ANN)을 포함하는 학습 모델을 학습시킨 언어 모델일 수 있다. 예를 들어, 자연어 처리 모듈은 구글(Google Inc.)의 BERT((Bidirectional Encoder Representation from Transformers), 및 이를 응용한 모델), GPT((Generative Pre-Training), 및 이를 응용한 모델, 예컨대 GPT-1, GPT-2, GPT-3 등), XLNET, RoBERTa, ALBERT 등의 NLP 네트워크 모델을 포함하고, 해당 모델을 디플로이(deploy)해 동작할 수 있다. 예컨대, 자연어처리 모듈은 트랜스포머 기반의 모델을 구축하고 자연어처리 애플리케이션에 적용될 수 있 다. 도 5를 참조하면, 어휘소 및 문법소 분석 방법에는 어휘소 모듈과 문법소 모듈이 사용될 수 있다. 일 실시 예에 따르면, 어휘소(lexeme) 모듈을 이용하여 전처리된 데이터에 대해 어휘 사전을 참조하여 어휘소 표제어(또는 레마, lemma) 엔트리(entry)를 적용할 수 있다(S511). 그리고, 어휘소 표제어 별로 품사(POS) 및 활용(inflection) 정보 태그를 부착할 수 있다(S512). 또한, 품사 및 활용 정보 태그에 기초하여 어휘소 표제어 별로 활용 분류하고, 어휘소 활용 분류 별로 어간 변이형을 확인하여, 어간 변이형을 시스템이 읽을 수 있는 바 이너리 파일로 컴파일할 수 있다(S513). 다음으로, 어휘소 활용 분류 별로 결합되는 활용 어미 복합 구성의 순 서 및 제약 관계를 확인할 수 있다(S514). 일 실시 예에 따르면, 어휘소(lexeme) 모듈을 통해 데이터에 결합될 수 있는 활용 어미의 구성 순서와 제 약 관계를 확인한 후, 문법소(morpheme) 모듈을 통해 활용 어미의 복합 구성 순서를 구성하는 문법소를 확 인할 수 있다(S521). 그리고 문법소의 결합 관계를 선형 그래프로 나타낼 수 있다(S522). 다음으로, 문법소를 구성하는 구성 원소들의 의미, 문법 및 담화 정보에 대하여 분류하여 태그를 부착할 수 있다(S523). 또한, 선형 그래프로 표상되는 구성 원소들의 결합 및 태그를 유한 상태 그래프로 구현하여 문법소 분석을 완료할 수 있다 (S524). 최종적으로, 어휘소 모듈을 통해 분석된 어휘소의 어간 변이형과, 문법소 모듈을 통해 분석 된 문법소 원소결합 모듈을 연동하여 그래프 문법을 생성할 수 있다(S530). 보다 구체적으로, 어휘소 레마 사전과 활용후치사/문법소 변환(transducer) 사전을 적용하여, 수집된 텍스트의 토큰 내부의 형태소를 분석하고, 활용형 토큰들의 레마를 할당할 수 있다. 이를 위해, 먼저 어휘소 모듈을 통해 어휘소의 레마 엔트리를 적용할 수 있다. 이 엔트리 부류는 기존의 인쇄 사전 및 디지털 사전의 표제어, 실제 신문기사 및 다양한 학술문서, 소셜미디어 등 사용자 생성문 등에 출현하는 어휘 부류를 토대로 구성될 수 있다. 본 발명의 일 실시 예에 따르면, 기존 사전에는 높은 생산성을 가진 접두사나 접미사에 의한 파생어 부류 가 체계적으로 수록되어 있지 않기 때문에, 원소조합(atom combination) 방법론에 기반하여 표제어의 재현율 (recall)을 체계적으로 보완할 수 있다. 다음으로, 어휘소 표제어 별 품사 및 활용 정보에 대한 분류 태그를 부 착할 수 있다. 이 단계에서는 각 표제어의 품사 정보를 대분류, 중분류 방식으로 계층화하여 부여하고, 이에 기 반한 활용 클라스 정보를 숫자로 태깅할 수 있다. 다음으로, 어휘소의 활용 클라스 별 어간 변이형을 바이너리 파일로 컴파일할 수 있다. 이 단계에서는 명사 (NOUN)와 부사(ADVERB) 범주가 조사(후치사)와 결합하여 단일 토큰을 구성하는 형태를 생성 또는 인식하기 위해 어휘소 어근의 변이형을 기술하고, 또한 동사(VERB)와 형용사(ADJECTIVE) 범주가 어미(후치사)와 결합하여 하나 의 단일 토큰을 구성하는 형태를 생성 또는 인식하기 위해 어휘소의 어간의 변이형을 기술할 수 있다. 특히 후 자의 경우 소위 불규칙용언이라 일컬어지는 일련의 어간 변이형이 각 용언 어휘소에 맞게 기술될 수 있다. 예를 들어, 형용사 ‘곱다’의 경우 ‘곱+고’, ‘고오+ㅏ(고와)’, ‘고우+니’와 같이 어간이 3가지 유형으로 변이 가 발생할 수 있다. 상기와 같이 각 표제어 별로 어간 변이형이 기술되면, 어휘소 전체에 대한 어간 변이형 사 전이 바이너리 파일 형식으로 컴파일될 수 있다. 마지막으로, 어휘소 모듈에서 어휘소의 활용 클라스 별로 결합되는 활용 어미(문법소)의 복합 구성 순서 및 제약 관계가 확인될 수 있다. 이와 관련하여 도 6을 참조로 자세히 살펴보기로 한다. 도 6은 본 발명의 일 실시 예에 따른 어휘소의 어간 변이형을 예시적으로 나타낸 도면이다. 일 실시 예에 따르면, 어휘소의 어간 변이형에 따라 결합 가능한 활용 어미 그룹이 달라질 수 있다. 도 6을 참 조하면, 어휘소 '곱다'에 대해 가능한 3 가지의 변이형을 확인할 수 있다. 3가지 변이형에는 '곱', '고오' 및 '고우'가 있으며, 이때 결합되는 활용 어미 그룹은 EOMI_05_1, EOMI_05_2 및 EOMI_05_3이 있을 수 있다. 각각의 활용 어미 그룹에는 각 어간 변이형과 결합 가능한 활용어미 요소들이 포함될 수 있다. 이때 활용 어미들은 여러 개가 중첩될 수 있으므로, 이들 사이의 내적 제약관계가 설정될 수도 있다. 다시 도 5로 돌아와서, 문법소 모듈을 통해 어휘소의 활용 클라스 별로 결합되는 활용 어미들의 복합구성 (complex sequence)의 결합 순서 및 제약 관계를 확인할 수 있다. 앞서 도 6에서 EOMI_05_1, EOMI_05_2, EOMI_05_3 등으로 분할된 활용 어미 그룹들에 실현되는 문법소 원소(atom)에 대해 이들 사이의 결합 제약 관계 가 문법소 모듈을 통해 기술될 수 있다. 예를 들어, 과거 시제를 표현하는 형태소 {-었}과 주어 높임을 표 현하는 형태소 {-시} 사이의 결합 관계에서 {-시}+{-었}의 순서로 실현되어야 하는 제약 관계가 기술될 수 있다. 본 발명의 일 실시 예에 따라, 어간 뒤에 실현되는 일련의 활용 어미(문법소)들의 결합 관계가 빠짐없이 기술될 수 있다. 다음으로, 문법소 모듈을 통해 문법소의 결합 관계가 선형 그래프(linear graph) 형식으로 표상될 수 있다. 선형 그래프는 방향성 비순환그래프(Directed Acyclic Graph, DAG) 형식으로 표상되어, 실제 텍스트 처리 시에 유한 상태 변환기(Finite-State Transducer, FST)로 기능할 수 있다. 이 그래프 셋은 각 활용 클라스 별 어간 변이형에 결합하는 활용어미 셋의 개수만큼 구축될 수 있으며, 이때 어휘소의 모든 표제어 변이형들은 이 단계의 복합 활용형 그래프셋 각각에 할당될 수 있다. 다음으로, 문법소 모듈에서 문법소를 구성하는 성분들의 의미, 문법 및 담화 정보가 분류 태그로 부착될 수 있다. 가령 ‘과거/현재’ 등의 시제나 시상, 높임법 등의 문법소, ‘목적/원인/시간’ 등의 의미 기능을 표 현하는 연결형 어미의 기능, ‘질문/명령’ 등의 담화적 기능을 담당하는 종결형 어미 등의 분류 정보가 문법소 의 구성 성분에 태깅될 수 있다. 그리고, 선형 그래프에서의 구성 성분들의 결합 관계와 관련 태그가 유한 상태변환기(FST)로 구현될 수 있다. 유한 상태 변환기 에서는 기술된 문법소 그래프의 최종 단계(final state)까지 의 경로를 통해 입력문(input) 시퀀스에 각각 할당되어 있는 출력문(output)의 문법소 정보를 연쇄적으로 추적 할 수 있다. 예시적인 실시 예에서, 어휘소 모듈 및 문법소 모듈, 또는 이들을 포함하는 자연어처리 모듈은 하나 의 프로세서(미도시)로 구현되거나, 하나의 프로세서의 지원을 받는 별도의 처리 단위로 구현될 수 있다. 프로 세서는 범용 프로세서, 전용 프로세서 또는 애플리케이션 프로세서(application processor) 등으로 구현될 수 있다. 예시적인 실시 예에서, 프로세서는 아날로그 신호를 디지털로 변환해 고속 처리할 수 있는 DSP(Digital Signal Processor), MCU(Micro Controller Unit), 또는 발광 장치에서 필요한 연산을 지원하는 전용 논리 회로 (예컨대, FPGA(Field Programmable Gate Array), ASICs(Application Specific Integrated Circuits) 등)를 포 함하는 연산 프로세서(예를 들어, CPU(Central Processing Unit), GPU(Graphic Processing Unit), AP(Application Processor) 등)로 구현될 수 있으나 이에 제한되지 않는다. 예시적인 실시 예에서, 어휘소 모듈 및 문법소 모듈, 또는 이들을 포함하는 자연어처리 모듈은 인공 지능 장치에 포함될 수 있다. 인공 지능 장치는, 본 개시에서, 대량의 학습 데이터를 통해 인공 신경망 (Artificial Neural Network, ANN)을 포함하는 학습 모델을 학습시켜 인공 신경망 내부의 파라미터를 최적화하 고, 학습된 학습 모델을 이용하여 시스템의 동작에 관여하는 모델을 의미할 수 있다. 일 실시 예에서 인공 지 능 장치는 MRC(Machine Reading Comprehension)를 통해 학습될 수 있다. 일 실시 예에서, 인공 지능 장치에 사 용되는 인공 신경망 모델은 합성곱 신경망(Convolutional Neural Network, CNN), 심층 신경망(Deep Neural Network, DNN), 순환 신경망(Recurrent Neural Network, RNN), 제한적 볼츠만 머신(Restricted Boltzmann Machine, RBM), 심층 신뢰 신경망(Deep Belief Network, DBN), 양방향 순환 신경망(Bidirectional Recurrent Deep Neural Network, BRDNN) 또는 심층 Q-네트워크(Deep Q-Networks) 등 중 적어도 어느 하나 또는 이들의 조 합이 있으나, 전술한 예에 한정되지 않는다. 도 7은 본 발명의 일 실시 예에 따른 유한 상태 변환 그래프를 나타낸 도면이다. 도 7의 입력 노드 각각의 하단에는 각 입력 값과 대응되는 태그 정보가 출력문의 형태로(예를 들어, 703) 표시 될 수 있다. 도 7을 참조하면, 형용사(ADJECTIVE)의 활용 클라스가 {AS05} 클라스 부류이고(예: '곱다'), 이때 3가지 어간 변이형 중, 2번째 유형인 '고오'가 실현되는 경우({AS05_2}), 결합 가능한 활용 어미 성분들은 단일 원의 노드로 표현될 수 있다. 여기서 이중원으로 표시된 노드는 유한 상태 변환 그래프의 최종 단계 를 나타내며, 도 7의 유한 상태 변환 그래프에서 최종 생성될 수 있는 복합 문법소 연쇄는 '-ㅏ/-ㅏ서/-ㅤㅏㅆ 는데/-ㅤㅏㅆ는데요/-ㅤㅏㅆ었는데/-ㅤㅏㅆ었는데요/-ㅤㅏㅆ었어/-ㅤㅏㅆ었어씩얌/-ㅤㅏㅆ었지'의 9가지가 될 수 있다. 다시 도 5로 돌아와서, 이상과 같은 방식으로 어휘소 모듈과 문법소 모듈이 구성되면, 어휘소의 어간 변이형과 문법소의 변환 모듈을 연동하는 결합 그래프(linking graph) 문법이 생성될 수 있다. 이에 따라, 텍스 트 데이터가 입력되면 결합 그래프 문법이 호출되어, 특수문자, 로마자, 숫자 등을 포함하는 문자열에 대한 처 리를 위해 별도 구축된 사전과 함께 텍스트 분석이 수행될 수 있다. 또한, 본 발명의 일 실시 예에 따르면, 이 상의 과정을 통해 사용자 생성문 텍스트에 대한 형태소 분석 및 활용형 레마/활용 어미 정보에 대한 태그가 부 착되는 작업이 수행될 수 있다. 도 8은 본 발명의 일 실시 예에 따른 전처리된 데이터를 감성 정보를 기초로 태깅하는 방법을 나타낸 흐름도이 다. 일 실시 예에 따르면, 범용 사전에 수록된 지식 정보를 활용하여 형태소가 분석된 레마에 대한 감성 정보와 개 체명 분류 정보 등을 태깅하고, 평가 대상 개체명(n)과 평가자질어(f), 감성 단일어토큰(s)을 주석할 수 있다. 지식베이스 사전에는 품사 및 활용 정보 외에도, 형태 정보와 술어별 논항구조에 대한 정보, 의미 온톨로지 정 보가 포함될 수 있다. 특히, 지식베이스 사전에는 극성 감성(POL) 정보, 심리 감성(PSY) 정보 및 도메인/개체명 정보 등이 포함될 수 있다. 이러한 일련의 정보들이 사전의 레마 표제어에 {+}와 같은 일련의 구분자 (separator)로 연결되어 내장될 수 있으며, 이를 통해 실제 텍스트 데이터 분석 시에 해당 어휘소에 관련된 정 보들이 반환될 수 있다. 도 8을 참조하면, 극성 감성(POL) 정보는 긍정과 부정의 극성(polarity)을 나타낼 수 있으며, '강한긍정 (SP), 긍정(PO), 약한긍정(WP), 중립(NE), 약한부정(WN), 부정(NG), 강한부정(SN)'의 7가지의 카테고리로 분류 될 수 있다. 심리 감성(PSY) 정보는 기존의 심리학적 분류 이론에 기반하여 '사랑(LO), 기쁨(JO), 소망(WI), 슬픔(SA), 수치(SH), 후회(RE), 고통(PA), 분노(AN), 공포(FE), 질투(JE), 복수(VE), 증오(HA)' 등 18가 지 유형의 카테고리로 분류될 수 있다. 심리 감성 정보는 극성 감성 분류에서 제공하지 못하는 인간의 심 리 상태에 대해서 보다 상세한 분류 정보를 제공할 수 있다. 개체명(named entity) 분류 정보는 '인물성/ 공간성/시간성/사물성'의 4가지로 대분류될 수 있다. 그리고 개체명 분류 정보는 각각 다음과 같이 하위 분류되어 전체 11가지의 카테고리를 구성할 수 있다. 예를 들어, 인물성은 '특정 개인(PERSON)', '일반 개인 (HUMAN)', '집단 조직(ORGANIZATION)'의 3가지로 하위 분류될 수 있고, 공간성은 '자연적 공간(GEOGRAPHY)', '인공적 공간(LOCATION)'의 2가지로 하위 분류될 수 있고, 시간성은 '사건표현(EVENT)'과 '시간표현(TIME)'의 2가지로 하위 분류될 수 있으며, 사물성은 '특정 고유 구체물(PRODUCT)'와 '그외 이동 가능한 구체물(THING)', '그외 고정되어 이동이 불가한 구체물(CONCRETE)', 그리고 '개념 추상적 대상(CREATION)'의 4가지로 하위 분류 될 수 있다. 이와 같은 개체명 분류는 대상 텍스트의 도메인이 무엇인가에 따라 그 양상이 다르게 나타날 수 있으며, 그 유 형별 비중과 어휘분포도 상이하게 나타날 수 있다. 또한, 개체명 분류는 일반적으로 평가의 대상(TARGET)이나 평가자 주체(OPINION HOLDER)로 실현될 수 있으며, 앞서 살핀 극성 감성어 또는 심리 감성어 분류와 분포적인 제약 관계를 형성할 수 있다. 도 9는 본 발명의 일 실시 예에 따라 전처리된 데이터의 다단어 유형의 결합 패턴을 분석하여 태깅하는 방법을 나타낸 도면이다. 도 9를 참조하면, 범용 패턴문법 지식 정보를 적용하여 감성 시퀀스 및 복합어, 구 단위 표현, 관용 표현, 극성 전환된 표현, 극성 강화/약화된 표현 등을 태깅할 수 있다. 패턴 문법으로 표상되는 지식 정보는 '복합명사구 ' 및 '다단어(Multi-Word Expression, MWE) 술어 감성 표현 시퀀스 정보', '극성 전환어(Polarity- Shifting Device, PSD) 적용된 극성 전환 술어구 정보', 그리고 '정도부사어(Intensifier, INT) 적용된 극성 등급 포함 술어구 정보' 등을 포함할 수 있다. 앞서 도 8에서 도시한 감성 표현들이 모두 지식베이스 사전에 단일 표제어로 등재되는 단일어휘 부류였다면, 도 9에서는 둘 이상의 다단어(MWE)로 실현되는 감성 시퀀스들이 패턴 문법을 통해 기술될 수 있다. 예를 들어, '좋 다/나쁘다'와 같은 단일어 표현 외에 '맘에 들다', '자꾸 손이 가다'와 같은 '명사+술어구' 유형의 MWE 감성표 현 부류가 기술될 수 있으며, 그 외의 복합 명사구나 복합 용언도 같은 방식으로 기술될 수 있다. 일 실시 예에 따르면, 이와 같이 패턴 문법으로 기술되는 시퀀스는 일련의 문법적 장치가 포함된 구(phrase)나 절(clause)과 같은 통사적 연쇄도 포함할 수 있다. 예를 들어, '맘에 들지 않다'와 같이 '않다'라는 부정소(부 정 조동사)가 극성 전환어(PSD)로 출현하여 극성이 전환되는 경우나, '너무 좋다'와 같이 강화 정도부사(INT)의 삽입에 의해 극성의 정도성이 전환되는 경우 등이 포함될 수 있다. 이와 관련하여 도 10을 참조로 상세하게 살 펴보기로 한다. 도 10은 본 발명의 일 실시 예에 따라 입력 데이터에 패턴 문법을 적용하는 방법을 나타낸 도면이다. 도 10을 참조하면, 입력문 \"맘에 들지 않았어요\"에 패턴 문법이 적용되면 출력문이 획득될 수 있다. '맘에 들다'는 다단어 감성 표현(SE_MWE)으로서, 긍정(POSITIVE)의 극성을 표현할 수 있다. 이 서술어 가, 극성 전환 장치(Polarity-Shifting Device, PSD)의 일환으로 부정의 보조용언 '않다'를 수반하면 (PSD=NEGATOR), 전체 극성(POLARITY)은 '약한부정(Weakly Negative, WN)'[-0.5]의 값으로 표현될 수 있다. 상 기의 과정은 그래프로 표상된 패턴 문법에 정의된 태그 정보를 토대로 진행될 수 있으며, 이상의 태그 정 보가 대상 텍스트에 통합(MERGE)됨으로써, 해당 정보가 주석된 문장이 출력문으로 생성될 수 있다. 일 실시 예에 따르면, 상기와 같이 패턴 문법 프레임을 통해, 앞서 단일 어휘 수준에서는 기술하기 어려웠던 시 퀀스 및 구, 절 등에 대한 효과적인 기술이 가능하게 된다. 이러한 분류 정보는 후술하게 될 도 12의 2-LAYER 학습데이터 생성에 적용될 수 있다. 도 11은 본 발명의 일 실시 예에 따라 태그 정보를 도메인 별로 분류하여 태깅하는 방법을 나타낸 도면이다. 도 11을 참조하면, 범용의 지식베이스 사전과 패턴 문법을 기초로 태깅된 정보들과 더불어, 실제 분석 대 상이 되는 사용자 생성문의 도메인 속성에 특화된 서브 자원(sub-recources)을 이용하여 도메인 텍스트의 태그를 추가할 수 있다. 도메인 서브 자원은 도메인 지식베이스 사전과 도메인 다단어 패턴 문법으로서, 상술한 범용 지식베이스 사전 및 범용 패턴 문법과 동일한 프레임으로 구현될 수 있다. 예를 들어, 코스메틱 쇼핑몰 후기글에 대한 태그 데이터를 구축한다면, 해당 도메인에 특화된 연관 어휘류(예: 발색력, 지속력 등) 및 해당 도메인에 특화된 감성 시 퀀스 부류(예: (화장이) 들뜨지 않다(+)) 등이 각각 도메인 사전과 도메인 문법에 기술될 수 있고, 이를 토대로 정보 전체가 대상 텍스트에 태깅될 수 있다. 도 11에서 도시한 바와 같이, 범용 지식베이스 사전과 패턴 문법이 각 도메인 별 서브 자원과 분리되어 제어되 는 모듈 방식을 적용하게 되면, 도메인의 유형이 달라지는 경우, 범용의 메인 언어 자원은 공통으로 적용되고 해당 도메인의 서브 자원만 치환될 수 있으므로 언어 자원의 관리, 유지 및 적용이 보다 효율적으로 이루어질 수 있다. 일 실시 예에 따르면, 개체명 부류 중에서 특히 확장성이 높은 지역명이나 인명, 기관명, 또는 상품명이나 브랜 드명 등과 같은 유형이 도메인 서브 자원으로 별도로 추가 및 관리될 수 있으며, 이 경우 이러한 서브 자원의 규모는 더 큰 규모로 확장될 수 있다. 일 실시 예에 따르면, 도메인 패턴 문법을 구성하는 도메인 서브 자원의 경우는, 상술한 바와 같이 다른 도메인에서는 감성 표현의 의미 기능을 갖지 못하나, 해당 도메인에서 특화된 의미를 갖는 유형들이 적절하게 태깅될 수 있다. 예를 들어, 코스메틱 상품구매 후기글에서 '가루가 날리지 않아요'(+)와 같은 텍스트는 도메인 특화된 긍정의 극성 표현을 나타낼 수 있다. 이러한 표현들은 범용의 언어 자원에서 기술되지 않고 {COSMETICS} 도메인 자원에서 기술됨으로써, 불필요한 중의적 분석을 억제하고 다양한 다단어 시퀀스들을 적절하게 분석할 수 있게 하는 장치를 제공할 수 있다. 도 12는 본 발명의 일 실시 예에 따른 이중 구조의 데이터베이스를 나타낸 도면이다. 도 12를 참조하면, 이전의 단계에서 생성된 태그 정보들을 기초로 2-LAYER 자질기반 감성분석(FBSA)용 학습 데 이터를 증강하는 과정을 확인할 수 있다. 일 실시 예에 따르면, 범용 지식베이스 사전 및 도메인 서브 사전에 수록된 단일 토큰 기반 지식 정보를 적용한 태그 정보는 {DICTIONARY-LAYER} 정보로 저장될 수 있다. 범용 다단어 패턴 문법 및 도메인 서브 문법으로 표상되는 지식 정보를 적용한 태그 정보는 {PHRASE-LAYER} 정보로 저장될 수 있다. {PHRASE-LAYER} 정보는 복합어/구/절 단위의 시퀀스를 나타내는 범용 정보 및 도메인 특화된 다단 어 표현들을 태깅한 결과를 표함할 수 있다. 본 발명의 일 실시 예에 따르면, 자질기반 감성분석(FBSA)을 위한 학습 데이터를 구성하는 데에 있어서, 이상과 같이 범용/도메인 지식베이스 사전과 범용/도메인 패턴 문법 프레임을 통해 필요한 언어 정보들이 기술되면, 이 를 기반으로 2-LAYER 자질기반 감성분석용 학습데이터가 증강될 수 있다. 도 12에서 기술된 언어 자원은 방향성 그래프(directed graph) 형식으로 나타내는 패턴 문법으로 호출될 수 있으며, 그 전체가 유한 상태 변환(FST) 그래프로 컴파일될 수 있다. 그리고 이상의 과정으로 컴파일된 언어 자원이 대상 데이터에 적용되면, 2-LAYER 태그가 부착된 학습 데이터가 생성될 수 있다. 이와 관련하여 도 13의 예시를 참조하여 상세히 살펴보기로 한다. 도 13은 본 발명의 일 실시 예에 따른 이중 구조의 데이터베이스를 이용하여 사람의 개입 없이 입력 데이터를 태깅하는 방법을 나타낸 도면이다. 도 13을 참조하면, 입력문 \"랑콤 파데는 들뜨지 않아요\"에 대해, 언어 자원이 유한 상태 변환(FST) 그래 프로 컴파일 되어 적용되면, 출력문이 생성될 수 있다. 출력문에는 DICTIONARY-LAYER의 태그들이 다음과 같이 부착될 수 있다. DICTIONARY-LAYER의 태그의 예: - <ENTITY=BRAND> </ENTITY> - <ENYTITY=PRODUCT> </ENTITY> - <SE=NEGATIVE> </SE> - <PSD=NEGATOR> </PSD> 그리고, 출력문에는 PHRASE-LAYER의 태그들이 다음과 같이 부착될 수 있다. PHRASE-LAYER의 태그의 예: - <TARGET=MWE> </TARGET> - <POLARITY=WEAKLY_POSITIVE> </POLARITY> 상기의 예에서, '파데'와 같은 상품 타입에 대한 구어체 표현은 <ENTITY_NORM>과 같은 방식으로 패턴 문법에 기 술될 수 있다. 따라서, 실제로 긴 음절수로 구성되거나 외래어 전사표기(transliteration) 형태로 실현되는 상 품명/상품타입 등에 사용자들이 여러 변이형을 사용하는 경우, <ENTITY_NORM>을 통해 이에 대한 정규화된 값을 할당할 수 있다. 예를 들어, '파데'에 대해 다음과 같은 여러 변이형이 있을 수 있으며, 이들에는 {파운데이 션}이라는 정규화된 값이 <ENTITY_NORM=파운데이션>이라는 형식의 태그로 부착될 수 있다. <ENTITY_NORM=파운데이션>의 변이형들의 예: - 파운데이션 - 파데 - 파운데이숀 - 화운데이션 상기 예에서는 자질어(FEATURE) 성분이 명시적으로 실현되지 않았으나, 서술어에 따라서는 미출현한 자질어 성 분이 암시적으로 유추될 수도 있다. 도 13에서 예시한 {COSMETICS} 도메인에서는, '들뜨지 않다'라는 술어는 긍 정(POSITIVE) 극성을 갖는 감성 표현으로서, {발색력}이라는 자질에 대한 감성 표현임이 함축되어 있다. 이러한 속성을 기반으로, 도메인 특화 패턴 문법에서는 '들뜨지 않다'라는 긍정 다단어 술어구에 대해 비명시적 자질 (IMPLICIT FEATURE) 정보를 <IMPLICIT_FEATURE=발색력>과 같은 방식으로 부여할 수 있다. 그리고 이상의 과정 을 통해 최종적으로 감성 분석 원소쌍이 획득될 수 있다. 본 발명의 반자동 데이터 증강(Semi-automatic Symbolic Propagation, SSP) 방법은, 이상과 같이 기존의 관련 분야 기술로는 체계적으로 처리하지 못헀던 감성 다단어 표현을 패턴 문법으로 기술하는 접근법을 적용함으로써, 기존 방법론의 한계를 넘어서는 의미를 가진다. 본 발명에서 핵심이 되는 언어 정보 유형은 단일 토큰 사전 유형과 다단어 패턴 문법 유형으로 나뉠 수 있으며, 이는 다시 범용의 언어 자원과 도메인 특화 서브 자원으로 분리되어, 궁극적으로 대상 텍스트 태그에 통합적으 로 적용되어 자원 이용의 효율성이 극대화될 수 있다. 그리고 본 발명은 상기의 과정을 통해 사람의 개입없이 자질기반 감성분석용 학습데이터를 무한 증식시킬 수 있으며, 이를 자질기반 감성분석용 모델 개발을 위한 머신 러닝 시스템에 제공할 수 있다. 도 14는 본 발명의 일 실시 예에 따른 AI 학습을 위한 데이터베이스 생성 장치를 도식화한 블록도이다. 본 발명의 데이터베이스 생성 장치는 통신부, 저장부 및 제어부를 포함할 수 있다. 도 14는 본 발명의 데이터베이스 생성 장치에 대해 예시적인 구성요소를 나타낸 것이고, 실시 예의 구현을 위해 기타 다른 구성요소들이 추가적으로 사용될 수 있다. 통신부는 네트워크를 통하여 외부의 전자 장치와 통신할 수 있다. 데이터베이스 생성 장치는 통신 부를 통해 데이터를 수신하고, 범용 지식베이스 사전 등 다양한 언어 자원에 관한 데이터에 접근할 수 있 다. 저장부는 수집된 데이터를 저장하고, 분류된 데이터를 저장하며, 태그 정보가 매핑된 데이터를 저장할 수 있다. 특히 저장부는 자질기반 감성분석을 위한 학습에 관련된 데이터를 저장할 수 있다. 일 실시 예에 따르면, 저장부는 본 발명의 이중 구조 데이터베이스를 포함할 수 있다. 제어부는 데이터베이스 생성 장치의 동작을 제어하기 위한 것으로서, 통신부및 저장부(142 0)를 제어할 수 있다. 일 실시 예에 따르면, 제어부는 통신부 및 저장부 중 적어도 하나를 통해, 적어도 하나의 도메인에 대한 텍스트를 포함하는 데이터를 획득할 수 있다. 그리고, 제어부는 데이 터를 전처리하고, 전처리된 데이터에 대해 어휘소 및 문법소 분석 및 데이터 각각이 나타내는 감성 정보를 기초 로 태그를 태깅할 수 있다. 또한, 제어부는 태그에 기초하여 단일 토큰 단위의 사전 정보 및 둘 이상의 다단어 토큰 단위의 패턴 정보를 포함하는 이중 구조의 데이터베이스를 생성할 수 있다. 데이터베이스 생성 장치는 이상의 구성요소들을 통해 본 발명에 기술된 모든 실시 예를 실시할 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다."}
{"patent_id": "10-2021-0133809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2021-0133809", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 AI 학습을 위한 데이터베이스 생성 방법을 나타낸 흐름도이다. 도 2는 본 발명의 일 실시 예에 따른 AI 학습을 위한 데이터베이스 생성 방법을 나타낸 상세 흐름도이다. 도 3은 본 발명의 일 실시 예에 따라 수집된 소셜미디어 텍스트를 유형 별로 분류하여 저장하는 방법을 나타낸 흐름도이다. 도 4는 본 발명의 일 실시 예에 따른 데이터 전처리 모듈을 나타낸 도면이다. 도 5는 본 발명의 일 실시 예에 따른 전처리된 데이터를 어휘소 및 문법소 분석하는 방법을 나타낸 흐름도이다. 도 6은 본 발명의 일 실시 예에 따른 어휘소의 어간 변이형을 예시적으로 나타낸 도면이다. 도 7은 본 발명의 일 실시 예에 따른 유한 상태 변환 그래프를 나타낸 도면이다. 도 8은 본 발명의 일 실시 예에 따른 전처리된 데이터를 감성 정보를 기초로 태깅하는 방법을 나타낸 흐름도이 다. 도 9는 본 발명의 일 실시 예에 따라 전처리된 데이터의 다단어 유형의 결합 패턴을 분석하여 태깅하는 방법을 나타낸 도면이다.도 10은 본 발명의 일 실시 예에 따라 입력 데이터에 패턴 문법을 적용하는 방법을 나타낸 도면이다. 도 11은 본 발명의 일 실시 예에 따라 태그 정보를 도메인 별로 분류하여 태깅하는 방법을 나타낸 도면이다. 도 12는 본 발명의 일 실시 예에 다른 이중 구조의 데이터베이스를 나타낸 도면이다. 도 13은 본 발명의 일 실시 예에 따른 이중 구조의 데이터베이스를 이용하여 사람의 개입 없이 입력 데이터를 태깅하는 방법을 나타낸 도면이다. 도 14는 본 발명의 일 실시 예에 따른 AI 학습을 위한 데이터베이스 생성 장치를 도식화한 블록도이다."}
