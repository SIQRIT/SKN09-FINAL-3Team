{"patent_id": "10-2021-0187467", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0097710", "출원번호": "10-2021-0187467", "발명의 명칭": "훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치 및 방법", "출원인": "큐에라소프트", "발명자": "정대영"}}
{"patent_id": "10-2021-0187467", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "다양한 출처와 장르로부터 수집된 코퍼스를 이용하여 N개의 언어 모델을 사전-학습(pre-training)시키는 사전학습 모듈;미리 정해진 데이터셋(dataset)을 이용하여 상기 언어 모델을 미세-조정(fine-tuning)하는 미세 조정 모듈; 및상기 사전 학습 모듈과 상기 미세 조정 모듈에 의해 생성된 의사결정 시뮬레이션 모델을 이용하여 의사결정을추론하는 추론 모듈;을 포함하고,다양한 출처와 장르로부터 수집된 상기 코퍼스로부터 N개의 상기 언어 모델을 학습하고, 상기 각각의 언어모델이 앙상블 알고리즘에 의거하여 의사결정을 추론하는 것을 특징으로 하는,훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치."}
{"patent_id": "10-2021-0187467", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "사전 학습 모듈이, 다양한 출처와 장르로부터 수집된 코퍼스를 이용하여 N개의 언어 모델을 사전-학습(pre-training)시키는 사전 학습 단계;미세 조정 모듈이, 미리 정해진 데이터셋(dataset)을 이용하여 상기 BERT 모델 또는 상기 GPT-3 모델을 미세-조정(fine-tuning)하는 미세 조정 단계; 및추론 모듈이, 상기 사전 학습 모듈과 상기 미세 조정 모듈에 의해 생성된 의사결정 시뮬레이션 모델을 이용하여의사결정을 추론하는 추론 단계;를 포함하고,다양한 출처와 장르로부터 수집된 상기 코퍼스로부터 N개의 상기 언어 모델을 학습하고, 상기 각각의 언어모델이 앙상블 알고리즘에 의거하여 의사결정을 추론하는 것을 특징으로 하는,훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 방법."}
{"patent_id": "10-2021-0187467", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치에 관한 것이다. 이를 위하여, 다양한 출처와 장르로부터 수집된 코퍼스를 이용하여 N개의 언어 모델을 사전-학습(pre-training)시키는 사전 학습 모듈; 미리 정해진 데이터셋(dataset)을 이용하여 언어 모델을 미세-조정(fine-tuning)하는 미세 조정 모듈; 및 사전 학습 모듈과 미세 조정 모듈에 의해 생성된 의사결정 시뮬레이션 모델을 이용하여 의사결정을 추론하는 추론 모듈;을 제공할 수 있다."}
{"patent_id": "10-2021-0187467", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0187467", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능을 이용한 자연어 처리(NLP)에서 가장 화제가 되고 있는 플랫폼으로는 Google의 양방향 언어 모델 BERT(Bidirectional Encoder Representations from Transformers model), OpenAI의 단방향 언어모델 GPT- 3(Generative Pre-Training 3) 등을 뽑을 수 있다. 특히 GPT-3의 경우에는 2020년 6월에 arXiv를 통해 공개된 모델로서, 4,990억개의 데이터셋 중에서 가중치 샘플링하여 3,000억개로 구성된 데이터세트로 pre-trained 되었 으며 1,750억개의 매개변수를 가지고 있어 2019년 초에 공개된 GPT-2에 비해 2배 이상 큰 규모의 모델이다. GPT-3 출시 전 가장 큰 언어 모델은 2020년 2월에 선보인 마이크로소프트의 튜링 NLG로 GPT-3보다 용량이 10배 적다. GPT-3가 수행가능한 작업으로는 각종 언어 관련 문제풀이, 랜덤 글짓기, 간단한 사칙연산, 번역, 주어진문장에 따른 간단한 웹 코딩이 가능하다."}
{"patent_id": "10-2021-0187467", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "선행기술문헌 특허문헌 (특허문헌 0001) 미국 공개특허 2021-0192140 A1, CONTROLLABLE GROUNDED TEXT GENERATION, Microsoft Technology Licensing, LLC"}
{"patent_id": "10-2021-0187467", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치를 제공하는 데에 있다."}
{"patent_id": "10-2021-0187467", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이하 본 발명의 목적을 달성하기 위한 구체적 수단에 대하여 설명한다. 본 발명의 목적은, 다양한 출처와 장르로부터 수집된 코퍼스를 이용하여 N개의 언어 모델을 사전-학습(pre- training)시키는 사전 학습 모듈; 미리 정해진 데이터셋(dataset)을 이용하여 상기 언어 모델을 미세-조정 (fine-tuning)하는 미세 조정 모듈; 및 상기 사전 학습 모듈과 상기 미세 조정 모듈에 의해 생성된 의사결정 시 뮬레이션 모델을 이용하여 의사결정을 추론하는 추론 모듈;을 포함하고, 다양한 출처와 장르로부터 수집된 상기 코퍼스로부터 N개의 상기 언어 모델을 학습하고, 상기 각각의 언어모델이 앙상블 알고리즘에 의거하여 의사결정 을 추론하는 것을 특징으로 하는, 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치를 제공하여 달성될 수 있다. 본 발명의 다른 목적은, 사전 학습 모듈이, 다양한 출처와 장르로부터 수집된 코퍼스를 이용하여 N개의 언어 모 델을 사전-학습(pre-training)시키는 사전 학습 단계; 미세 조정 모듈이, 미리 정해진 데이터셋(dataset)을 이 용하여 상기 BERT 모델 또는 상기 GPT-3 모델을 미세-조정(fine-tuning)하는 미세 조정 단계; 및 추론 모듈이, 상기 사전 학습 모듈과 상기 미세 조정 모듈에 의해 생성된 의사결정 시뮬레이션 모델을 이용하여 의사결정을 추론하는 추론 단계; 를 포함하고, 다양한 출처와 장르로부터 수집된 상기 코퍼스로부터 N개의 상기 언어 모델 을 학습하고, 상기 각각의 언어모델이 앙상블 알고리즘에 의거하여 의사결정을 추론하는 것을 특징으로 하는, 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 방법을 제공하여 달성될 수 있다."}
{"patent_id": "10-2021-0187467", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같이, 본 발명에 의하면 이하와 같은 효과가 있다. 첫째, 본 발명의 일실시예에 따르면, 다양한 출처와 장르를 포괄하는 분류 알고리즘을 생성할 수 있게 되는 효 과가 발생된다."}
{"patent_id": "10-2021-0187467", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작원리를 상세하게 설명함에 있 어서 관련된 공지기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 특정 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 특정 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 제1 또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하려는 목적으 로만, 예컨대 본 발명의 개념에 따른 권리 범위로부터 벗어나지 않은 채, 제1 구성 요소는 제2 구성 요소로 명 명될 수 있고 유사하게 제2 구성 요소는 제1 구성 요소로도 명명될 수 있다. 어떤 구성 요소가 다른 구성 요소 에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성 요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성 요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성 요소가 다른 구성 요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는 중간에 다른 구성 요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성 요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어 야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로서, 본 발명을 한정하려는 의 도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 본 명세서에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구 성 요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적 으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 본 명세서에 첨부된 도면들을 참조하여 본 발명의 실시 예들을 상세히 설명한다. 그러나, 특허출원의 범 위가 이러한 실시 예들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치 도 1은 본 발명의 일 실시예에 따른 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치의 기능 블럭도이고, 도 2는 도 1에 도시된 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치에 의해 생성된 의사 결정 시뮬레이션 모델을 도시한다. 본 발명의 일실시예에 따른 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치는 사전 학습 모듈 , 미세 조정 모듈 및 저장 모듈을 포함한다. 실시예에 따라, 의사결정 시뮬레이션 장치는 테스트 모듈 및/또는 추론 모듈을 더 포함할 수도 있다. 의사결정 시뮬레이션 장치는 특정 text 를 입력받아 기설정된 class를 분류하는 모델, 즉 의사결정 시뮬레이션 모델을 생성하고, 생성된 의사결정 시뮬 레이션 모델을 이용하여 특정 text를 분류하여 의사결정 시뮬레이션을 수행할 수 있다. 예컨대, 의사결정 시뮬레이션 장치는 BERT(Bidirectional Encoder Representations from Transformers model) 모델 또는 GPT- 3(Generative Pre-Training 3) 등의 인공신경망 기반 NLP 모델을 학습시킴으로써 의사결정 시뮬레이션 모델을 생성할 수 있다. 의사결정 시뮬레이션 장치는 적어도 하나의 프로세서를 이용하여 구현될 수 있으며, 여기서, 프로세서는 중 앙 처리 장치(CPU, Central Processing Unit), 마이크로 컨트롤러 유닛(MCU, Micro Controller Unit), 애플리 케이션 프로세서(AP, Application Processor), 마이컴(Micom, Micro Processor), 전자 제어 유닛(ECU, Electronic Controlling Unit) 및/또는 각종 연산 처리 및 제어 신호의 생성이 가능한 다른 전자 장치 등을 포 함할 수 있다. 이들 장치는, 예를 들어, 하나 또는 둘 이상의 반도체 칩 및 관련 부품을 이용하여 구현될 수 있 다. 일 실시예에 의하면, 프로세서는 저장 모듈에 저장된 적어도 하나의 애플리케이션(소프트웨어, 프로그 램이나 앱 등으로 표현 가능하다)을 구동시켜, 미리 정의된 연산, 판단, 처리 및/또는 제어 동작 등을 수행할 수도 있다. 여기서, 저장 모듈에 저장된 애플리케이션은, 설계자에 의해 직접 작성되어 저장 모듈에 입력 및 저장된 것일 수도 있고, 또는 유선 또는 무선 통신 네트워크를 통해 접속 가능한 전자 소프트웨어 유통 망을 통하여 획득 또는 갱신된 것일 수도 있다. 또한, 의사결정 시뮬레이션 장치는 이와 같은 프로세서가 하나 이상 설치된 적어도 하나의 정보 처리 장치 를 이용하여 구현될 수도 있으며, 전자 정보 처리 장치는 데스크톱 컴퓨터, Lap top 컴퓨터, 서버용 컴퓨터, 스 마트폰, 태블릿 PC, 스마트 시계, 내비게이션 장치, 휴대용 게임기, 헤드 마운티드 디스플레이(HMD, Head Mounted Display) 장치, 인공지능 음향 재생 장치, 디지털 텔레비전, 가전기기, 기계 장치 및/또는 전자적으로 정보의 연산/처리 및 이와 관련된 제어가 가능하고 에너지 관리를 위해 특별히 제작된 적어도 하나의 장치를 포 함할 수 있다. 사전 학습 모듈(110, 프리 트레이닝부라고 칭할 수도 있음)은 제1 데이터를 이용하여 의사결정 시뮬레이션 모델, 예를 들어 BERT 모델/GPT-3 모델을 사전-학습(pre-training)시킬 수 있다. 설명의 편의를 위하여 의사결 정 시뮬레이션 모델에 대해 BERT 모델을 기준으로 설명하자면, 사전 학습 모듈에 의한 사전-학습의 결과로, BERT 모델의 문맥(context) 이해력을 향상시키고 자연어 처리 프로세스(natural language processing, NLP)를 향상시킬 수 있다. 구체적으로, BERT 모델은 MLM(masked language model)과 다음 문장 예측기(next sentence predictor)를 포함하는 비지도 예측 태스크(unsupervised prediction task)를 이용하여 프리-트레이 닝을 수행한다. MLM은 우선 문맥(context)을 이해하고 단어들(words)을 예측한다. 이를 위해, 사전 학습 모듈 은 BERT에 입력되는 단어들(word piece) 또는 문장으로부터 일정 확률(예컨대, 15%)로 몇몇 토큰들 (tokens)을 랜덤하게 마스크(mask)할 수 있다. 입력은 주위 단어들(surrounding words)의 문맥에 기초하여 마스 크된 단어를 예측하기 위해 트랜스포머 구조(Transformer structure)에 포함된다. 이와 같은 과정을 통하여, BERT 모델은 문맥을 보다 정확하게 이해할 수 있다. 다음 문장 예측기는 문장들 간의 관계를 식별하기 위한 것 이다. 이러한 태스크는 QA(Question Answering)나 NLI(Natural Language Inference)와 같은 언어 이해 태스크 를 위해 중요하다. BERT는 말뭉치(corpus) 내의 두 문장을 오리지널 문장과 결합하는 이진화된 다음 문장 예측 태스크(binarized next sentence prediction task)를 포함한다. 이러한 모델은 BERT의 NLP 태스크에서의 성능 을 향상시킬 수 있다. BERT 모델에서 사용된 데이터는 Book Corpus로부터의 800M 단어들과 Wikipedia로부터의 2,500M 단어들을 포함한다. 위 데이터를 제1 데이터라 칭할 수 있다. 실시예에 따라, 사전 학습 모듈은 제n 데이터를 이용하여 N개의 BERT 모델을 사전-학습시킬 수도 있다. 예 컨대, 제n 데이터는 다양한 출처와 장르로부터 수집된 코퍼스를 포함할 수 있다. 다양한 출처와 장르로부터 수 집된 코퍼스를 이용하여 N개의 언어 모델이 사전 학습될 수 있다. 제n 데이터를 이용한 추가적인 사전-학습을 통해 BERT 모델의 의사결정 시뮬레이션 성능을 향상시킬 수 있다. 제n 데이터는 Environment-action 쌍으로 구 성된 text를 의미할 수 있다. 이전의 자연어 처리(NLP) 태스크에서 BERT의 프리-트레이닝은 좋은 성능을 보인다. 그러나, BERT 모델이 사용하는 데이터는 Wikipedia로부터 획득된 일반적인 데이터의 2,500M 단어들과 Book Corpus로부터의 800M 단어들에 기초한다. 이러한 데이터는 방대한 분야의 정보를 포함하고 있으나, 개별적 인 도메인(individual domain)에서의 구체적인 정보는 부족한 상태이다. 이러한 문제점에 착안하여, 본 발명에 서는 의사결정 시뮬레이션 기능을 향상시키기 위해 프리-트레이닝 단계에서 다양한 출처와 장르로부터 수집된 코퍼스를 새로운 데이터로서 추가하였고, 이에 대응되는 N개의 언어 모델을 사전 학습하였다. 미세 조정 모듈(120, 파인 튜닝부라고 칭할 수도 있음)은 BERT 모델을 미세-조정(Fine-tuning)함으로써 의사결 정 시뮬레이션 모델을 생성할 수 있다. 미세-조정 단계에서는 의사결정 시뮬레이션에 관련된 학습 데이터를 사 용할 수 있다. 여기서, 학습 데이터는 Environment와 Action의 쌍으로 구성되어 있으며, 각 Environment- action 쌍의 분류 라벨(class label)을 포함할 수 있다. 여기서, 분류 라벨이라 함은 Environment-action 쌍으 로 이루어진 데이터의 분류로서, 복수의 class를 포함할 수 있다. 예컨대, 복수의 class는 매수, 매도, 보유 등 과 같은 의사결정에 대한 class로 구성될 수 있다. 이때, BERT 모델에서, Environment를 n개의 그룹으로 분류하기 위해 WCE(Weighted Cross Entropy, 가중된 크로 스 엔트로피 또는 가중치가 적용된 크로스 엔트로피)가 사용될 수 있다. 테스트 모듈은 테스트 데이터를 이용하여 학습된 의사결정 시뮬레이션 모델을 테스트하는 모듈이다. 여기 서, 테스트 데이터는 Environment와 Action의 쌍으로 구성되어 있으며, 의사결정 시뮬레이션 모델을 평가하기 위해 분류 라벨을 포함하지 않는다. 예를 들어, 학습 데이터 및 테스트 데이터로 총 n개의 Environment-Action 쌍이 사용될 수 있다. 추론 모듈은 Environment-action 쌍으로 구성된 분류 대상 text를 입력받고, 생성된 분류 모델에 분류 대 상 text를 입력함으로써 분류 대상 text를 분류할 수 있다. 즉, 추론 모듈은 분류 대상 text에 따라 어떤 의사결정(action)을 취하여야 하는지 여부를 판단할 수 있다. 예컨대, 분류 대상 text가 '매도'로 분류된 경우, 추론 모듈은 분류 대상 text를 매도라는 의사결정으로 판단할 수 있다. 저장 모듈에는 의사결정 시뮬레이션 모델을 생성하기 위해 사용하는 데이터, 의사결정 시뮬레이션 모델의 생성 중에 생성되는 데이터, 의사결정 시뮬레이션 모델을 테스트하기 위한 데이터, 생성된 의사결정 시뮬레이션 모델, 분류 대상 text, 분류의 결과 등이 저장될 수 있다. 이상에서 설명된 장치는 하드웨어 구성 요소, 소프트웨어 구성 요소, 및/또는 하드웨어 구성 요소 및 소프트웨 어 구성 요소의 집합으로 구현될 수 있다. 예를 들어, 실시 예들에서 설명된 장치 및 구성 요소는, 예를 들어, 프로세서, 콘트롤러, ALU(Arithmetic Logic Unit), 디지털 신호 프로세서(Digital Signal Processor), 마이크 로컴퓨터, FPA(Field Programmable array), PLU(Programmable Logic Unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(Operation System, OS) 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응 답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사 용되는 것으로 설명된 경우도 있지만, 해당 기술 분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처 리 요소(Processing Element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (Parallel Processor)와 같은, 다른 처리 구성(Processing Configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(Computer Program), 코드(Code), 명령 (Instruction), 또는 이들 중 하나 이상 의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (Collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성 요소(Component), 물리적 장치, 가상 장치(Virtual Equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(Signal Wave)에 영구적으로, 또는 일시적으로 구체화(Embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시 예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시 예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(Magnetic Media), CD- ROM, DVD와 같은 광기록 매체(Optical Media), 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체 (Magneto-optical Media), 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계 어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상 기된 하드웨어 장치는 실시 예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상에서 설명한 바와 같이, 본 발명이 속하는 기술 분야의 통상의 기술자는 본 발명이 그 기술적 사상이나 필 수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 상술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범 위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함하는 것으로 해석되어야 한다. 본 명세서 내에 기술된 특징들 및 장점들은 모두를 포함하지 않으며, 특히 많은 추가적인 특징들 및 장점들이 도면들, 명세서, 및 청구항들을 고려하여 당업자에게 명백해질 것이다. 더욱이, 본 명세서에 사용된 언어는 주 로 읽기 쉽도록 그리고 교시의 목적으로 선택되었고, 본 발명의 주제를 묘사하거나 제한하기 위해 선택되지 않 을 수도 있다는 것을 주의해야 한다. 본 발명의 실시예들의 상기한 설명은 예시의 목적으로 제시되었다. 이는 개시된 정확한 형태로 본 발명을 제한 하거나, 빠뜨리는 것 없이 만들려고 의도한 것이 아니다. 당업자는 상기한 개시에 비추어 많은 수정 및 변형이 가능하다는 것을 이해할 수 있다. 그러므로 본 발명의 범위는 상세한 설명에 의해 한정되지 않고, 이를 기반으로 하는 출원의 임의의 청구항들에 의해 한정된다. 따라서, 본 발명의 실시예들의 개시는 예시적인 것이며, 이하의 청구항에 기재된 본 발명의 범 위를 제한하는 것은 아니다."}
{"patent_id": "10-2021-0187467", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 발명의 상세한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어 해석되어서는 아니 된다. 도 1은 본 발명의 일 실시예에 따른 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치의 기능 블럭도, 도 2는 도 1에 도시된 훈련된 다중 언어모델을 통한 의사결정 시뮬레이션 장치에 의해 생성된 의사결정 시뮬레 이션 모델이다."}
