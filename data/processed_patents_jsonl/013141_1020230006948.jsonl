{"patent_id": "10-2023-0006948", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0114612", "출원번호": "10-2023-0006948", "발명의 명칭": "사용자 입력에 기반하여 이미지를 생성하는 장치", "출원인": "엔에이치엔 주식회사", "발명자": "이상현"}}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지에 포함될 오브젝트들의 레이아웃과 연관된 레이아웃 토큰들을 갖는 입력을 수신할 때마다, 벡터값들을출력하도록 구성되는 제 1 트랜스포머 디코더;널(null) 값을 갖는 비교 토큰들을 갖는 입력을 수신할 때마다, 비교 벡터값들을 출력하도록 구성되는 제 2 트랜스포머 디코더;상기 벡터값들 및 상기 비교 벡터값들에 기반하여 이미지 토큰을 생성하도록 구성되는 이미지 토큰 생성기; 및상기 이미지 토큰 생성기에 의해 생성되어 누적된 이미지 토큰들을 디토큰화하여 이미지를 생성하도록 구성되는이미지 디코더를 포함하는 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 비교 토큰들의 개수는 상기 레이아웃 토큰들의 개수와 동일한 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 레이아웃 토큰들은 상기 오브젝트들에 각각 대응하는 클래스들과 연관되는 제 1 레이아웃 토큰들을 포함하고,상기 비교 토큰들은 상기 제 1 레이아웃 토큰들과 동일한 개수의 제 1 비교 토큰들을 포함하는 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 레이아웃 토큰들은 상기 오브젝트들에 각각 대응하는 포지션들과 연관되는 제 2 레이아웃 토큰들을 포함하고,상기 비교 토큰들은 상기 제 2 레이아웃 토큰들과 동일한 개수의 제 2 비교 토큰들을 포함하는 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 레이아웃 토큰들은 상기 오브젝트들에 각각 대응하는 포지션들과 연관되고,상기 비교 토큰들의 개수는 상기 레이아웃 토큰들과 동일한 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,사용자 입력에 따라 획득된 텍스트 데이터를 토큰화하여 텍스트 토큰들을 생성하도록 구성되는 텍스트 인코더를더 포함하고,제 1 트랜스포머 디코더는 상기 레이아웃 토큰들과 함께 상기 텍스트 토큰들을 포함하는 상기 입력을 수신하여상기 벡터값들을 출력하도록 구성되고,상기 제 2 트랜스포머 디코더는 상기 비교 토큰들과 함께 상기 텍스트 토큰들을 포함하는 상기 입력을 수신하여공개특허 10-2024-0114612-3-상기 비교 벡터값들을 출력하도록 구성되는 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 이미지 토큰 생성기는 상기 벡터값들에 제 1 가중치를 부여하고, 상기 비교 벡터값들에 제 2 가중치를 부여하고, 상기 가중된 벡터값들과 상기 가중된 비교 벡터값들에 기반하여 상기 이미지 토큰을 생성하도록 구성되는 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 제 1 가중치는 상기 제 2 가중치보다 큰 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서,상기 제 1 가중치는 양수이고 상기 제 2 가중치는 음수인 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "사용자 입력에 따라 획득된 텍스트 데이터를 토큰화하여 텍스트 토큰들을 생성하도록 구성되는 텍스트 인코더;상기 텍스트 토큰들 및 이미지에 포함될 오브젝트들의 레이아웃과 연관된 레이아웃 토큰들을 갖는 제 1 입력 매트릭스를 수신할 때마다, 벡터값들을 출력하도록 구성되는 제 1 트랜스포머 디코더;상기 텍스트 토큰들 및 상기 제 1 입력 매트릭스에서의 상기 레이아웃 토큰들의 위치들과 동일한 위치들에서 비교 토큰들을 갖는 제 2 입력 매트릭스를 수신할 때마다, 비교 벡터값들을 출력하도록 구성되는 제 2 트랜스포머디코더;상기 벡터값들 및 상기 비교 벡터값들에 기반하여 이미지 토큰을 생성하도록 구성되는 이미지 토큰 생성기; 및상기 이미지 토큰 생성기에 의해 생성되어 누적된 이미지 토큰들을 디토큰화하여 이미지를 생성하도록 구성되는이미지 디코더를 포함하며,상기 비교 토큰들은 널(null) 값을 갖는 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 제 1 트랜스포머 디코더는 상기 제 1 입력 매트릭스가 상기 텍스트 토큰들 및 상기 레이아웃 토큰들을 포함할 때 제 1 출력값들을 상기 벡터값들로서 생성하고,상기 제 2 트랜스포머 디코더는 상기 제 2 입력 매트릭스가 상기 텍스트 토큰들 및 상기 비교 토큰들을 포함할때 제 2 출력값들을 상기 비교 벡터값들로서 생성하고,상기 이미지 토큰 생성기는 상기 제 1 출력값들 및 상기 제 2 출력값들에 기반하여 상기 이미지 토큰들 중 제 1이미지 토큰을 생성하는 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 제 1 트랜스포머 디코더는 상기 제 1 입력 매트릭스가 상기 텍스트 토큰들, 상기 레이아웃 토큰들, 및 상기 제 1 이미지 토큰을 포함할 때 제 3 출력값들을 상기 벡터값들로서 생성하고,상기 제 2 트랜스포머 디코더는 상기 제 2 입력 매트릭스가 상기 텍스트 토큰들, 상기 비교 토큰들, 및 상기 제1 이미지 토큰을 포함할 때 제 4 출력값들을 상기 비교 벡터값들로서 생성하고,상기 이미지 토큰 생성기는 상기 제 3 출력값들 및 상기 제 4 출력값들에 기반하여 상기 이미지 토큰들 중 제 2공개특허 10-2024-0114612-4-이미지 토큰을 생성하는 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 제 1 트랜스포머 디코더는 상기 제 1 입력 매트릭스가 상기 텍스트 토큰들, 상기 레이아웃 토큰들, 그리고상기 제 1 및 제 2 이미지 토큰들을 포함할 때 제 5 출력값들을 상기 벡터값들로서 생성하고,상기 제 2 트랜스포머 디코더는 상기 제 2 입력 매트릭스가 상기 텍스트 토큰들, 상기 비교 토큰들, 그리고 상기 제 1 및 제 2 이미지 토큰들을 포함할 때 제 6 출력값들을 상기 비교 벡터값들로서 생성하고,상기 이미지 토큰 생성기는 상기 제 5 출력값들 및 상기 제 6 출력값들에 기반하여 상기 이미지 토큰들 중 제 3이미지 토큰을 생성하는 이미지 생성 장치."}
{"patent_id": "10-2023-0006948", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이미지 생성 장치는, 이미지에 포함될 오브젝트들의 레이아웃과 연관된 레이아웃 토큰들을 갖는 입력을 수신할 때마다, 벡터값들을 출력하도록 구성되는 제 1 트랜스포머 디코더, 널(null) 값을 갖는 비교 토큰들을 갖는 입력 을 수신할 때마다 비교 벡터값들을 출력하도록 구성되는 제 2 트랜스포머 디코더, 벡터값들 및 비교 벡터값들에 기반하여 이미지 토큰을 생성하도록 구성되는 이미지 토큰 생성기, 그리고 이미지 토큰 생성기에 의해 생성되어 누적된 이미지 토큰들을 디토큰화하여 이미지를 생성하도록 구성되는 이미지 디코더를 포함한다."}
{"patent_id": "10-2023-0006948", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 전자 장치에 관한 것으로, 좀 더 구체적으로는 사용자 입력에 기반하여 이미지를 생성하는 장치에 관 한 것이다."}
{"patent_id": "10-2023-0006948", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "과거에는 창작이 전문가의 영역으로 오랜 기간 동안 지속되어 왔으나, 정보 통신 기술의 발전, 통신 성능의 향 상, 컨텐츠 소비 문화의 변화 등으로 인해 점차 개인의 영역으로 확대되고 있는 추세이다. 또한 다양한 소셜 네 트워크 서비스(Social Network Service, SNS) 플랫폼들이 확산되면서, 과거와 달리 개인이 창작물을 전시할 수 있는 공간이 확대되었다. 예를 들면, 개인은 SNS 플랫폼을 통해 블로그, 방송 등을 통해 창작물을 대중에게 쉽 게 공개할 수 있다. 컨텐츠를 제작을 위해, 개인은 아이디어 개발, 스케치, 편집 등 모든 과정을 직접 수행하고 있다. 만약 개인이 아이디어의 개발 이후의 과정들을 수행하는 데에 미숙하다면 그 과정들을 전문 편집기를 사용할 수 있는 전문가 에게 맡겨야 하며, 이러한 경우 개인은 상당한 비용을 지불해야 한다. 설사 개인이 전문 편집기를 사용할 수 있 다 하더라도, 해당 과정들을 수행하는 데에 상당한 시간이 소요될 수 있다. 위 기재된 내용은 오직 본 발명의 기술적 사상들에 대한 배경 기술의 이해를 돕기 위한 것이며, 따라서 그것은 본 발명의 기술 분야의 당업자에게 알려진 선행 기술에 해당하는 내용으로 이해될 수 없다."}
{"patent_id": "10-2023-0006948", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시 예들은 향상된 신뢰성으로 이미지를 자동적으로 생성할 수 있는 장치를 제공하기 위한 것이다."}
{"patent_id": "10-2023-0006948", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 이미지 생성 장치는, 이미지에 포함될 오브젝트들의 레이아웃과 연관된 레이아웃 토 큰들을 갖는 입력을 수신할 때마다, 벡터값들을 출력하도록 구성되는 제 1 트랜스포머 디코더; 널(null) 값을 갖는 비교 토큰들을 갖는 입력을 수신할 때마다, 비교 벡터값들을 출력하도록 구성되는 제 2 트랜스포머 디코더; 상기 벡터값들 및 상기 비교 벡터값들에 기반하여 이미지 토큰을 생성하도록 구성되는 이미지 토큰 생 성기; 및 상기 이미지 토큰 생성기에 의해 생성되어 누적된 이미지 토큰들을 디토큰화하여 이미지를 생성하도록 구성되는 이미지 디코더를 포함한다. 상기 비교 토큰들의 개수는 상기 레이아웃 토큰들의 개수와 동일할 수 있다. 상기 레이아웃 토큰들은 상기 오브젝트들에 각각 대응하는 클래스들과 연관되는 제 1 레이아웃 토큰들을 포함할 수 있고, 상기 비교 토큰들은 상기 제 1 레이아웃 토큰들과 동일한 개수의 제 1 비교 토큰들을 포함할 수 있다. 상기 레이아웃 토큰들은 상기 오브젝트들에 각각 대응하는 포지션들과 연관되는 제 2 레이아웃 토큰들을 포함할 수 있고, 상기 비교 토큰들은 상기 제 2 레이아웃 토큰들과 동일한 개수의 제 2 비교 토큰들을 포함할 수 있다.상기 레이아웃 토큰들은 상기 오브젝트들에 각각 대응하는 포지션들과 연관될 수 있고, 상기 비교 토큰들의 개 수는 상기 레이아웃 토큰들과 동일할 수 있다. 상기 이미지 생성 장치는 사용자 입력에 따라 획득된 텍스트 데이터를 토큰화하여 텍스트 토큰들을 생성하도록 구성되는 텍스트 인코더를 더 포함할 수 있다. 이때, 제 1 트랜스포머 디코더는 상기 레이아웃 토큰들과 함께 상기 텍스트 토큰들을 포함하는 상기 입력을 수신하여 상기 벡터값들을 출력하도록 구성될 수 있다. 제 2 트랜 스포머 디코더는 상기 비교 토큰들과 함께 상기 텍스트 토큰들을 포함하는 상기 입력을 수신하여 상기 비교 벡 터값들을 출력하도록 구성될 수 있다. 상기 이미지 토큰 생성기는 상기 벡터값들에 제 1 가중치를 부여하고, 상기 비교 벡터값들에 제 2 가중치를 부 여하고, 상기 가중된 벡터값들과 상기 가중된 비교 벡터값들에 기반하여 상기 이미지 토큰을 생성하도록 구성될 수 있다. 상기 제 1 가중치는 상기 제 2 가중치보다 클 수 있다. 상기 제 1 가중치는 양수이고 상기 제 2 가중치는 음수일 수 있다. 본 발명의 다른 실시 예에 따른 이미지 생성 장치는, 사용자 입력에 따라 획득된 텍스트 데이터를 토큰화하여 텍스트 토큰들을 생성하도록 구성되는 텍스트 인코더; 상기 텍스트 토큰들 및 이미지에 포함될 오브젝트들의 레 이아웃과 연관된 레이아웃 토큰들을 갖는 제 1 입력 매트릭스를 수신할 때마다, 벡터값들을 출력하도록 구성되 는 제 1 트랜스포머 디코더; 상기 텍스트 토큰들 및 상기 제 1 입력 매트릭스에서의 상기 레이아웃 토큰들의 위 치들과 동일한 위치들에서 비교 토큰들을 갖는 제 2 입력 매트릭스를 수신할 때마다, 비교 벡터값들을 출력하도 록 구성되는 제 2 트랜스포머 디코더; 상기 벡터값들 및 상기 비교 벡터값들에 기반하여 이미지 토큰을 생성하 도록 구성되는 이미지 토큰 생성기; 및 상기 이미지 토큰 생성기에 의해 생성되어 누적된 이미지 토큰들을 디토 큰화하여 이미지를 생성하도록 구성되는 이미지 디코더를 포함하며, 상기 비교 토큰들은 널 값을 갖는다. 상기 제 1 트랜스포머 디코더는 상기 제 1 입력 매트릭스가 상기 텍스트 토큰들 및 상기 레이아웃 토큰들을 포 함할 때 제 1 출력값들을 상기 벡터값들로서 생성할 수 있고, 상기 제 2 트랜스포머 디코더는 상기 제 2 입력 매트릭스가 상기 텍스트 토큰들 및 상기 비교 토큰들을 포함할 때 제 2 출력값들을 상기 비교 벡터값들로서 생 성할 수 있고, 상기 이미지 토큰 생성기는 상기 제 1 출력값들 및 상기 제 2 출력값들에 기반하여 상기 이미지 토큰들 중 제 1 이미지 토큰을 생성할 수 있다. 상기 제 1 트랜스포머 디코더는 상기 제 1 입력 매트릭스가 상기 텍스트 토큰들, 상기 레이아웃 토큰들, 및 상 기 제 1 이미지 토큰을 포함할 때 제 3 출력값들을 상기 벡터값들로서 생성할 수 있고, 상기 제 2 트랜스포머 디코더는 상기 제 2 입력 매트릭스가 상기 텍스트 토큰들, 상기 비교 토큰들, 및 상기 제 1 이미지 토큰을 포함 할 때 제 4 출력값들을 상기 비교 벡터값들로서 생성할 수 있고, 상기 이미지 토큰 생성기는 상기 제 3 출력값 들 및 상기 제 4 출력값들에 기반하여 상기 이미지 토큰들 중 제 2 이미지 토큰을 생성할 수 있다. 상기 제 1 트랜스포머 디코더는 상기 제 1 입력 매트릭스가 상기 텍스트 토큰들, 상기 레이아웃 토큰들, 그리고 상기 제 1 및 제 2 이미지 토큰들을 포함할 때 제 5 출력값들을 상기 벡터값들로서 생성할 수 있고, 상기 제 2 트랜스포머 디코더는 상기 제 2 입력 매트릭스가 상기 텍스트 토큰들, 상기 비교 토큰들, 그리고 상기 제 1 및 제 2 이미지 토큰들을 포함할 때 제 6 출력값들을 상기 비교 벡터값들로서 생성할 수 있고, 상기 이미지 토큰 생성기는 상기 제 5 출력값들 및 상기 제 6 출력값들에 기반하여 상기 이미지 토큰들 중 제 3 이미지 토큰을 생 성할 수 있다."}
{"patent_id": "10-2023-0006948", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예들에 따르면, 향상된 신뢰성으로 이미지를 자동적으로 생성할 수 있는 장치가 제공될 수 있다. 예를 들면, 이미지 생성 장치는 이미지에 포함될 오브젝트들의 레이아웃에 대한 사용자의 의도에 부합하 는 이미지를 생성할 수 있다. 실시 예들에 따른 효과는 이상에서 예시된 내용에 의해 제한되지 않으며, 더욱 다양한 효과들이 본 명세서 내에 포함되어 있다."}
{"patent_id": "10-2023-0006948", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 바람직한 실시 예를 첨부한 도면을 참조하여 상세히 설명한다. 하기의 설명에서는 본 발 명에 따른 동작을 이해하는데 필요한 부분만이 설명되며 그 이외 부분의 설명은 본 발명의 요지를 모호하지 않 도록 하기 위해 생략될 것이라는 것을 유의하여야 한다. 또한 본 발명은 여기에서 설명되는 실시 예에 한정되지"}
{"patent_id": "10-2023-0006948", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "않고 다른 형태로 구체화될 수도 있다. 단지, 여기에서 설명되는 실시 예는 본 발명이 속하는 기술분야에서 통 상의 지식을 가진 자에게 본 발명의 기술적 사상을 용이하게 실시할 수 있을 정도로 상세히 설명하기 위하여 제 공되는 것이다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 여기에서 사용된 용 어는 특정한 실시 예들을 설명하기 위한 것이며 본 발명을 한정하기 위한 것이 아니다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. \"X, Y, 및 Z 중 적어도 어느 하나\", 그리고 \"X, Y, 및 Z로 구성된 그룹으로부터 선택된 적어도 어느 하나\"는 X 하나, Y 하나, Z 하나, 또는 X, Y, 및 Z 중 둘 또는 그 이상의 어떤 조합 (예를 들면, XYZ, XYY, YZ, ZZ) 으로 해석될 수 있다. 여기에서, \"및/또는\"은 해 당 구성들 중 하나 또는 그 이상의 모든 조합을 포함한다. 여기에서, 제 1, 제 2 등과 같은 용어가 다양한 구성 요소들을 설명하기 위해 사용될 수 있지만, 이러한 구성 요소들은 이러한 용어들에 한정되지 않는다. 이러한 용어들은 하나의 구성 요소를 다른 구성 요소와 구별하기 위해 사용된다. 따라서, 제 1 구성 요소는 여기에 개시된 바를 벗어나지 않는 범위 내에서 제 2 구성 요소를 칭 할 수 있다. 도 1은 이미지 생성 장치를 보여주는 블록도이다. 도 1을 참조하면, 이미지 생성 장치는 사용자 입력(UI)을 수신한다. 사용자 입력(UI)에 따라, 예를 들면 \"The elephant is walking around in the park\"와 같은 텍스트 데이터가 정의될 수 있다. 예를 들면, 키보드, 터치 스크린 등과 같은 사용자 입력 장치를 통해 사용자 입력(UI)이 수신될 수 있다. 이미지 생성 장치는 텍스트 데이터와 연관된 이미지(IMG)를 출력하도록 구성된다. 좀 더 구체적으로, 이미 지 생성 장치는 텍스트 데이터를 자동적으로 이미지화하도록 구성되는 텍스트 이미지 변환(text to image translation) 모델을 포함할 수 있다. 예를 들면, 이미지 생성 장치는 텍스트 데이터의 요소들(예를 들면, elephant, walking 등)로부터 텍스트 토큰들을 생성하도록 구성되는 텍스트 인코더, 텍스트 토큰들에 기반하여 이미지 토큰들을 생성하도록 구성되는 텍스트 이미지 변환 모델, 그리고 이미지 토큰들에 기반하여 이미지(IM G)를 생성하도록 구성되는 이미지 디코더를 포함할 수 있다. 도 2는 도 1의 이미지 생성 장치의 실시 예를 보여주는 블록도이다. 도 2를 참조하면, 이미지 생성 장치는 텍스트 인코더(210, text encoder), 버퍼 메모리, 트랜스포머 디코더(230, transformer decoder), 및 이미지 벡터 양자화기(240, image vector quantizer)를 포함할 수 있다. 텍스트 인코더는 텍스트 데이터(TD)를 수신하도록 구성된다. 예를 들면, 사용자 인터페이스가 제공되고, 사용자 인터페이스는 사용자로부터 사용자 입력을 수신하고 수신된 사용자 입력을 텍스트 데이터(TD)로서 텍스 트 인코더에 제공할 수 있다. 예를 들면, 텍스트 데이터(TD)는 \"The elephant is walking around in the park\"일 수 있다. 텍스트 인코더는 텍스트 데이터(TD)에 대응하는 텍스트 토큰 세트(TTS)을 생성하도록 구성될 수 있다. 텍 스트 토큰 세트(TTS)는 텍스트 데이터(TD), 예를 들면 \"The elephant is walking around in the park\"의 요소 들 및/또는 특징들이 벡터화된 제 1 내지 제 m 텍스트 토큰들(TT1~TTm)을 포함할 수 있다. 실시 예들에서, 텍스트 인코더는 텍스트 데이터(TD)를 인코딩(혹은 토큰화)하도록 구성되는 바이트 페어 인코더(byte pair encoder)를 포함할 수 있다. 실시 예들에서, 텍스트 데이터를 인코딩하여 양자화된 벡터값들 을 생성하도록 구성되는 인코더, 그리고 양자화된 벡터값들을 디코딩하여 텍스트 데이터를 생성하도록 구성되는 디코더를 포함하는 텍스트 벡터 양자화기가 제공될 수 있으며, 이러한 경우 텍스트 벡터 양자화기의 인코더가 텍스트 인코더로서 제공될 수 있다. 해당 인코더는 텍스트 데이터(TD)를 양자화하여 벡터값들을 출력할 수 있으며, 양자화된 벡터값들은 제 1 내지 제 m 텍스트 토큰들(TT1~TTm)로서 제공될 수 있다. 텍스트 인코더는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm)을 버퍼 메모리에 저장할 수 있다. 버퍼 메모리는 텍스트 인코더, 트랜스포머 디코더, 및 이미지 벡터 양자화기에 연결될 수 있다. 버퍼 메모리는 텍스트 인코더, 트랜스포머 디코더, 및 이미지 벡터 양자화기에 의해 액세스될 수 있으며, 그들의 워킹 메모리로서 기능할 수 있다. 실시 예들에서, 버퍼 메모리는 DRAM(Dynamic random access memory), SRAM(Static Random Access Memory) 등과 같은 저장 매체들을 포함하여 데이터를 저장할 수 있다. 트랜스포머 디코더는 버퍼 메모리에 연결된다. 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토 큰들(TT1~TTm)에 따라 다음의 데이터 토큰을 예측(혹은 생성)하도록 구성될 수 있다. 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm) 및 예측된 데이터 토큰에 따라 그 다음의 데이터 토큰을 예측할 수 있 다. 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm) 및 예측된 데이터 토큰들에 따라 그 다 음의 데이터 토큰을 예측하는 동작을 반복함으로써, 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 생성할 수 있다. 트랜스포머 디코더은 제 1 내지 제 m 텍스트 토큰들(TT1~TTm)을 입력으로 수신하여 제 1 레이아웃 토큰 (LT1)을 생성할 수 있다. 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm) 및 생성된 제 1 레 이아웃 토큰(LT1)을 입력으로 수신하여 다음 레이아웃 토큰(LT2)을 생성할 수 있다. 이와 같은 방식으로, 트랜 스포머 디코더는 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)을 순차적으로 생성할 수 있다. 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)은 그것들이 디코딩(혹은 디토큰화)될 때 이미지(IMG)에 포함될 오브젝트들의 레이아 웃을 나타내는 레이아웃 데이터로 변환되는 데이터일 수 있다. 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm) 및 제 1 내지 제 n 레이아웃 토큰들 (LT1~LTn)을 입력으로 수신하여 제 1 이미지 토큰(IT1)을 생성할 수 있다. 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm), 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn), 및 생성된 제 1 이미지 토큰(IT1)을 입력으로 수신하여 다음 이미지 토큰(IT2)을 생성할 수 있다. 이와 같은 방식으로, 트랜스포머 디코더는 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 순차적으로 생성할 수 있다. 제 1 내지 제 q 이미지 토큰들(IT1~IT q)은 그것들이 디코딩(혹은 디토큰화)될 때 이미지(IMG)로 변환되는 데이터일 수 있다. 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm)에 뒤따르는 제 1 내지 제 n 레이아웃 토큰들 (LT1~LTn), 및 제 1 내지 제 q 이미지 토큰들(IT1~ITq)의 데이터 매트릭스(혹은 스트링)을 도 2에 도시된 순서 대로 순차적으로 예측하도록 학습된 인공지능 머신을 포함할 수 있다. 실시 예들에서, 트랜스포머 디코더 는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm)에 따라 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)을 순차적으로 예 측하도록 학습될 수 있다. 또한, 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm) 및 제 1 내 지 제 n 레이아웃 토큰들(LT1~LTn)에 따라 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 순차적으로 예측하도록 학 습될 수 있다. 트랜스포머 디코더가 제 1 내지 제 m 텍스트 토큰들(TT1~TTm)로부터 바로 이미지 토큰들을 예측하도록 구성된다 면, 이미지 토큰들은 상대적으로 낮은 신뢰성을 가질 수 있다. 예를 들면, 이미지 토큰들을 디코딩하여 생성된 이미지는 사용자가 원하는 이미지가 아닐 수 있다. 반면, 본 발명의 실시 예예 따른 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm)로부터 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)을 순차적으로 예측하 고, 이후 제 1 내지 제 m 텍스트 토큰들(TT1~TTm) 및 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)로부터 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 순차적으로 예측하도록 사전에 학습된다. 이에 따라, 트랜스포머 디코더 는 상대적으로 높은 신뢰성을 갖는 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 제공할 수 있다. 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 디코딩하여 생성된 이미지(IMG)는 상대적으로 높은 확률로 사용자가 원하는 이 미지일 수 있다. 이미지 벡터 양자화기는 버퍼 메모리에 연결된다. 이미지 벡터 양자화기는 이 분야에 알려진 이 미지 인코더(IEN)와 이미지 디코더(IDE)를 포함할 수 있다. 이미지 인코더(IEN)는 이미지(혹은 이미지 데이터) 를 인코딩(혹은 토큰화)하여 양자화된 벡터값들을 생성하도록 구성될 수 있다. 이미지 디코더(IDE)는 양자화된 벡터값들을 디코딩(혹은 디토큰화)하여 이미지(IMG)를 생성하도록 구성될 수 있다. 이미지 벡터 양자화기는 이미지 디코더(IDE)를 이용하여 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 디코딩 할 수 있다. 이미지 디코더(IDE)는 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 양자화된 벡터값들로서 획득하고, 획득된 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 디코딩하여 이미지(IMG)를 생성하도록 구성될 수 있다. 실시 예에서, 이미지 인코더(IEN)는 사용되지 않을 수 있다. 도 3은 도 2의 트랜스포머 디코더의 실시 예를 보여주는 블록도이다. 도 3을 참조하면, 트랜스포머 디코더는 인공지능 모델 및 인공지능 프로세서를 포함할 수 있다. 인공지능 모델은 입력 데이터 토큰들(IDT)을 입력하면 출력 데이터 토큰(ODT)을 출력하도록 사전에 학습될 수 있다. 여기에서, 입력 데이터 토큰들(IDT)은 제 1 내지 제 m 텍스트 토큰들(TT1~TTm) 및 이전에 생성된 출력 데이터 토큰들을 포함할 수 있다. 예를 들면, 입력 데이터 토큰들(IDT)은 제 1 내지 제 m 텍스트 토큰들 (TT1~TTm), 그리고 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn) 및 제 1 내지 제 q 이미지 토큰들(IT1~ITq) 중 직전까지 생성된 출력 데이터 토큰들을 포함할 수 있다. 출력 데이터 토큰(ODT)은 직전까지 생성된 출력 데이터 토큰들 다음의 데이터 토큰일 수 있다. 이와 같이, 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들 (TT1~TTm)에 따라, 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn), 및 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 순차적으로 생성하도록 사전에 학습될 수 있다. 실시 예들에서, 인공지능 모델은 하나 또는 그 이상의 뉴럴 네트워크들(L1, L2, ... , L_k-1, L_k)을 포함 할 수 있다. 뉴럴 네트워크들(L1, L2, ... , L_k-1, L_k)은 입력 데이터 토큰들(IDT)로서 텍스트 토큰들, 그리고 출력 데이 터 토큰들(ODT)로서 레이아웃 토큰들을 포함하는 제 1 학습 데이터를 사전에 학습할 수 있다. 또한, 뉴럴 네트 워크들(L1, L2, ... , L_k-1, L_k)은 입력 데이터 토큰들(IDT)로서 텍스트 토큰들 및 레이아웃 토큰들, 그리고 출력 데이터 토큰들(ODT)로서 이미지 토큰들을 포함하는 제 2 학습 데이터를 사전에 학습할 수 있다. 인공지능 프로세서는 인공지능 모델을 제어하도록 구성된다. 인공지능 프로세서는 데이터 학습 부(321, data learning unit) 및 데이터 처리부(322, data processing unit)를 포함할 수 있다. 데이터 학습부 는 학습 데이터, 예를 들면 위 설명된 제 1 학습 데이터 및 제 2 학습 데이터를 이용하여, 입력 데이터 토 큰들(IDT)이 인공지능 모델에 입력되면 해당 출력 데이터 토큰(ODT)이 출력되도록 인공지능 모델을 학습시킬 수 있다. 데이터 처리부는 학습된 인공지능 모델에 입력 데이터 토큰들(IDT)을 입력함으로 써 출력 데이터 토큰(ODT)을 획득할 수 있다. 실시 예들에서, 인공지능 모델 및 인공지능 프로세서는 프로세서 및 메모리로 구현될 수 있다. 프로 세서는 싱글 코어, 듀얼 코어, 쿼드 코어 등과 같이 하나 또는 그 이상의 코어들을 포함할 수 있다. 프로세서는 프로그램 및/또는 명령어들을 메모리에 로드하고, 로드된 프로그램 및/또는 명령어들을 실행함으로써 인공지능 모델 및 인공지능 프로세서 각각을 제공할 수 있다. 도 4는 도 1의 이미지 생성 장치의 다른 실시 예를 보여주는 블록도이다. 도 4를 참조하면, 이미지 생성 장치는 텍스트 인코더, 버퍼 메모리, 트랜스포머 디코더, 이미지 벡터 양자화기, 및 레이아웃 벡터 양자화기(450, custom data generator)를 포함할 수 있다. 텍스트 인코더, 버퍼 메모리, 트랜스포머 디코더, 및 이미지 벡터 양자화기는 도 2를 참조 하여 설명된 텍스트 인코더, 버퍼 메모리, 트랜스포머 디코더, 및 이미지 벡터 양자화기와 각각 마찬가지로 구성된다. 이하, 중복되는 설명은 생략된다. 레이아웃 벡터 양자화기는 레이아웃 데이터(LD)를 수신할 수 있다. 레이아웃 벡터 양자화기는 레이아 웃 데이터(LD)를 인코딩(혹은 토큰화)하여 레이아웃 토큰 세트(LTS) 중 적어도 일부를 생성하도록 구성될 수 있다. 레이아웃 데이터(LD)은 이미지(IMG)에 포함될 오브젝트들의 레이아웃과 연관된 정보를 포함할 수 있다. 실시 예 들에서, 레이아웃 데이터(LD)는 이미지(IMG)에 포함될 오브젝트들의 클래스(class)들을 나타내는 정보를 포함할 수 있다. 여기에서, 클래스는 해당 오브젝트의 종류(예를 들면, 코끼리, 나무, 하늘, 지면 등)를 나타내는 데이 터일 수 있다. 실시 예들에서, 레이아웃 데이터(LD)는 이미지(IMG)에 포함될 오브젝트들의 포지션(position)들 을 나타내는 정보를 포함할 수 있다. 여기에서, 포지션은 각 오브젝트가 이미지(IMG) 상에서 위치하는 영역을 나타내는 데이터일 수 있다. 레이아웃 데이터(LD)는 사용자 입력으로부터 획득될 수 있다. 예를 들면, 사용자 인터페이스를 통해 사용자로부 터 사용자 입력이 수신될 수 있으며, 이때 사용자 입력은 레이아웃 데이터(LD)를 포함할 수 있다. 예를 들면, 사용자 입력은 이미지(IMG)에 포함될 오브젝트들의 클래스(class)들에 대한 정보를 포함할 수 있다. 예를 들면, 사용자 입력은 이미지(IMG)에 포함될 오브젝트들의 포지션(position)들에 대한 정보를 더 포함할 수 있다. 레이아웃 벡터 양자화기는 이 분야에 알려진 레이아웃 인코더(LEN) 및 레이아웃 디코더(LDE)를 포함할 수 있다. 레이아웃 인코더(LEN)는 레이아웃 데이터(LD)를 인코딩(혹은 토큰화)하여 양자화된 벡터값들을 생성하도 록 구성될 수 있다. 레이아웃 디코더(LDE)는 양자화된 벡터값들을 디코딩(혹은 디토큰화)하여 레이아웃 데이터 (LD)를 생성하도록 구성될 수 있다. 레이아웃 벡터 양자화기는 레이아웃 인코더(LEN)를 이용하여 레이아웃 데이터(LD)를 인코딩함으로써 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)을 생성할 수 있다. 좀 더 구체적으로, 레이아웃 인코더(LEN)는 레이아웃 데이터(LD)를 인코딩하여 양자화된 벡터값들을 생성하고, 생성된 양자화된 벡터값들을 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)로서 제공할 수 있다. 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn) 중 일부는 이미지(IMG)에 포함될 오브젝트들의 클래스들과 연관될 수 있다. 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn) 중 다른 일부는 이미지(IMG)에 포함될 오브젝트들의 포지션들 과 연관될 수 있다. 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)은 레이아웃 토큰 세트(LTS)를 형성할 수 있다. 이와 같은, 사용자 입력으로부터 레이아웃 데이터(LD)를 생성하고 레이아웃 데이터(LD)로부터 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)을 생성하는 동작들에 대해서는 특허출원번호 10-2022-0187535의 명세서와 도면이 여 기에 참조될 수 있다. 위 설명된 바와 같이 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)은, 트랜스포머 디코더에 의해 예측되는 대 신, 사용자로부터 제공된 레이아웃 데이터(LD)에 기반하여 생성될 수 있다. 이에 따라, 제 1 내지 제 q 이미지 토큰들(IT1~ITq)은 사용자의 의도를 더 잘 반영할 수 있으며, 그에 기반하여 생성되는 이미지(IMG)도 사용자의 의도를 더 잘 반영할 수 있다. 따라서, 더 높은 신뢰성의 이미지(IMG)가 제공될 수 있다. 도 5는 본 발명의 실시 예에 따른 이미지 생성 장치를 보여주는 블록도이다. 도 6은 도 5의 이미지 토큰 생성기 에 의해 처리되는 데이터를 개념적으로 보여주는 도면이다. 도 7은 도 5의 이미지 벡터 양자화기 및 그 입력과 출력을 개념적으로 보여주는 블록도이다. 도 5를 참조하면, 이미지 생성 장치는 텍스트 인코더(510, text encoder), 패더(515, padder), 제 1 내지 제 3 버퍼 메모리들(521, 522, 523), 제 1 트랜스포머 디코더(531, first transformer decoder), 제 2 트랜스 포머 디코더(532, second transformer decoder), 이미지 벡터 양자화기(540, image vector quantizer), 및 이 미지 토큰 생성기(550, image token generator)를 포함할 수 있다. 텍스트 인코더는 텍스트 데이터(TD)를 수신하고, 수신된 텍스트 데이터(TD)에 대응하는 텍스트 토큰 세트 (TTS)를 생성하도록 구성된다. 텍스트 토큰 세트(TTS)는 텍스트 데이터(TD), 예를 들면 \"The elephant is walking around in the park\"의 요소들 및/또는 특징들이 벡터화된 제 1 내지 제 m 텍스트 토큰들(TT1~TTm)을 포함할 수 있다. 생성된 제 1 내지 제 m 텍스트 토큰들(TT1~TTm)은 제 1 및 제 2 버퍼 메모리들(521, 522) 각각 에 저장될 수 있다. 텍스트 인코더는 도 2의 텍스트 인코더와 마찬가지로 구성될 수 있다. 제 1 버퍼 메모리는 텍스트 인코더, 제 1 트랜스포머 디코더, 및 이미지 토큰 생성기에 의 해 액세스될 수 있으며, 그들의 워킹 메모리로서 기능할 수 있다. 제 2 버퍼 메모리는 텍스트 인코더 , 패더, 제 2 트랜스포머 디코더, 및 이미지 토큰 생성기에 의해 액세스될 수 있으며, 그 들의 워킹 메모리로서 기능할 수 있다. 실시 예들에서, 제 1 및 제 2 버퍼 메모리들(521, 522) 각각은 DRAM(Dynamic random access memory), SRAM(Static Random Access Memory) 등과 같은 저장 매체들을 포함하여데이터를 저장할 수 있다. 제 1 버퍼 메모리는 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)을 포함하는 레이아웃 토큰 세트(LTS)를 저 장할 수 있다. 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)은 그것들이 디코딩(혹은 디토큰화)될 때 이미지(IMG) 에 포함될 오브젝트들의 레이아웃(예를 들면, 클래스들 및/또는 포지션들)을 나타내는 레이아웃 데이터로 변환 되는 데이터일 수 있다. 실시 예들에서, 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)은 도 2를 참조하여 설명된 바와 같이 제 1 트랜스포 머 디코더에 의해 생성될 수 있다. 실시 예들에서, 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)은 도 4를 참 조하여 설명된 바와 같이 사용자에 의해 제공된 레이아웃 데이터(LD)에 기반하여 생성될 수 있다. 제 1 트랜스포머 디코더는 제 1 버퍼 메모리에 연결된다. 제 1 트랜스포머 디코더는 제 1 버퍼 메모리에 저장된 데이터 토큰들의 매트릭스를 입력으로 수신하여 제 1 벡터값들(V1)을 생성할 수 있다. 예 를 들면, 제 1 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm) 및 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)을 입력으로 수신하여 제 1 벡터값들(V1)을 출력할 수 있다. 만약 적어도 하나의 이미지 토큰 (예를 들면, IT1)이 이미 생성되었다면, 제 1 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토큰들 (TT1~TTm), 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn), 및 생성된 적어도 하나의 이미지 토큰을 입력으로 수신 하여 제 1 벡터값들(V1)을 생성할 수 있다. 제 1 벡터값들(V1)은 제 1 내지 제 m 벡터값들(V11~V1m)을 포함할 수 있다. 만약 제 1 트랜스포머 디코더가 도 2의 실시 예에 적용된다면, 제 1 트랜스포머 디코더는 제 1 벡터값들(V1)에 기반하여 이미지 토큰을 생성하여 생성된 이미지 토큰을 제 1 버퍼 메모리에 업데이 트할 것이다. 반면, 본 실시 예에서는 제 1 트랜스포머 디코더는 이미지 토큰 생성기가 액세스할 수 있는 제 3 버퍼 메모리에 제 1 벡터값들(V1)을 저장한다. 실시 예들에서, 도 2 혹은 도 4의 트랜스포머 디코더가 제 1 트랜스포머 디코더로서 제공될 수 있다. 패더는 제 2 버퍼 메모리에 널(null) 값을 갖는 비교 토큰들(NL)로 구성된 널 데이터(ND)를 기입(혹 은 패딩)하도록 구성된다. 제 1 버퍼 메모리에 저장된 데이터와 다르게, 제 2 버퍼 메모리에는 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)의 개수와 동일한 개수의 비교 토큰들(NL)이 기입될 수 있다. 다시 말해, 텍스트 토큰 세트(TTS)와 널 데이터(ND)로 구성된 제 2 버퍼 메모리의 데이터 매트릭스(혹은 스트링)는, 텍스트 토큰 세트(TTS)과 레이아웃 토큰 세트(LTS)로 구성된 제 1 버퍼 메모리의 데이터 매트릭스(혹은 스 트링)에서의 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)의 위치들과 동일한 위치들에서 비교 토큰들(NL)을 포함 할 수 있다. 제 2 트랜스포머 디코더는 제 2 버퍼 메모리에 연결된다. 제 2 트랜스포머 디코더는 제 1 트랜 스포머 디코더와 상이한 데이터 토큰들을 수신하는 점을 제외하면 제 1 트랜스포머 디코더와 마찬가 지로 구성된다. 실시 예들에서, 도 2 혹은 도 4의 트랜스포머 디코더가 제 2 트랜스포머 디코더로서 제공될 수 있다. 제 2 트랜스포머 디코더는 제 2 버퍼 메모리에 저장된 데이터 토큰들의 매트릭스를 입력으로 수신하 여 제 2 벡터값들(V2)을 생성할 수 있다. 예를 들면, 제 2 트랜스포머 디코더는 제 1 내지 제 m 텍스트 토 큰들(TT1~TTm) 및 비교 토큰들(NL)을 입력으로 수신하여 제 2 벡터값들(V2)을 출력할 수 있다. 만약 적어도 하 나의 이미지 토큰(예를 들면, IT1)이 이미 생성되었다면, 제 2 트랜스포머 디코더는 제 1 내지 제 m 텍스 트 토큰들(TT1~TTm), 비교 토큰들(NL), 및 생성된 적어도 하나의 이미지 토큰을 입력으로 수신하여 제 2 벡터값 들(V2)을 생성할 수 있다. 제 2 벡터값들(V2)은 제 1 벡터값들(V1)의 제 1 내지 제 m 벡터값들(V11~V1m)과 동일 한 개수의 제 1 내지 제 m 벡터값들(V21~V2m)을 포함할 수 있다. 제 2 트랜스포머 디코더는 제 2 벡터값들 (V2)을 비교 벡터값들로서 제 3 버퍼 메모리에 저장할 수 있다. 이미지 토큰 생성기는 제 1 벡터값들(V1) 및 제 2 벡터값들(V2)에 기반하여 제 k 이미지 토큰을 생성하고 (k는 1보다 크거나 같은 정수), 생성된 이미지 토큰을 제 1 및 제 2 버퍼 메모리들(521, 522) 각각에 저장하도 록 구성된다. 도 5에서, 이미지 토큰 생성기가 제 1 이미지 토큰(IT1)을 생성하는 것이 예시된다. 이와 같 이, 이미지 토큰 생성기는 제 1 벡터값들(V1) 및 제 2 벡터값들(V2)이 갱신될 때마다 각 이미지 토큰을 순 차적으로 생성할 수 있다. 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)은 널 값을 갖는 비교 토큰들(NL)과 비교할 때 상대적으로 높은 확률 로 이미지(IMG)에 포함될 오브젝트들의 레이아웃(예를 들면, 클래스들 및/또는 포지션들)에 대한 사용자의 의도 (intention)를 반영할 수 있다. 예를 들면, 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)은 학습된 인공지능 머신을 포함하는 제 1 트랜스포머 디코더에 의해 생성되거나, 도 4를 참조하여 설명된 바와 같이 사용자에 의 해 제공된 레이아웃 데이터(LD)에 의해 생성될 수 있으며, 이는 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn)이 상 대적으로 높은 확률로 사용자가 원하는 레이아웃에 부합함을 의미한다. 반면, 널 값을 갖는 비교 토큰들(NL)은 사용자의 의도를 실질적으로 반영하지 않는다. 이미지 토큰 생성기는 비교 토큰들(NL)에 따라 생성된 제 2 벡터값들(V2)을 이용하여, 제 1 내지 제 n 레 이아웃 토큰들(LT1~LTn)에 따라 생성된 제 1 벡터값들(V1)을 사용자의 레이아웃에 대한 의도가 더 반영되는 방 향으로 이동시킴으로써, 새로운 벡터값들(예를 들면 도 6의 V3)을 생성할 수 있다. 이미지 토큰 생성기는 생성된 벡터값들에 기반하여 이미지 토큰을 생성할 수 있다. 제 1 벡터값들(V1)과 제 2 벡터값들(V2) 사이의 차 이를 참조하여, 제 1 벡터값들(V1)이 사용자의 레이아웃에 대한 의도를 더 반영하는 방향으로 이동되어 새로운 벡터값들을 생성하는 것으로 이해될 수 있다. 이에 따라 생성되는 이미지 토큰들은 사용자의 레이아웃에 대한 의도를 더 반영할 수 있으며, 이는 이미지 토큰들에 따라 생성되는 이미지(IMG)도 사용자의 레이아웃에 대한 의 도를 상대적으로 높은 신뢰성으로 반영함을 의미할 수 있다. 도 6을 참조하면, 제 1 벡터값들(V1)의 제 1 내지 제 m 벡터값들(V11~V1m)은 제 1 가중치(W1)만큼 가중될 수 있 으며, 이에 따라 가중된 제 1 내지 제 m 벡터값들(V11'~V1m')이 생성될 수 있다. 제 2 벡터값들(V2)의 제 1 내 지 제 m 벡터값들(V21~V2m)은 제 2 가중치(W2)만큼 가중될 수 있으며, 이에 따라 가중된 제 1 내지 제 m 벡터값 들(V21'~V2m')이 생성될 수 있다. 가중된 제 1 내지 제 m 벡터값들(V11'~V1m')은 가중된 제 1 내지 제 m 벡터값들(V21'~V2m')과 각각 더해질 수 있으며, 이에 따라 제 1 내지 제 m 벡터값들(V31~V3m)을 포함하는 제 3 벡터값들(V3)이 생성될 수 있다. 제 1 가중치(W1)는 제 2 가중치(W2)보다 클 수 있다. 실시 예들에서, 제 1 가중치(W1)는 양수이고 제 2 가중치 (W2)는 음수일 수 있다. 이와 같이, 제 1 벡터값들(V1)을 제 2 벡터값들(V2)과 비교하여 사용자의 의도가 더 반 영되는 방향으로 이동시킴으로써, 제 3 벡터값들(V3)이 생성될 수 있다. 이어서, 제 3 벡터값들(V3)의 제 1 내지 제 m 벡터값들(V31~V3m)에 따라 제 1 내지 제 m 이미지 토큰 확률들 (ITP1~ITPm)을 생성할 수 있다. 예를 들면, 제 1 내지 제 m 벡터값들(V31~V3m)에 소프트맥스(softmax) 함수가 적용되어 제 1 내지 제 m 이미지 토큰 확률들(ITP1~ITPm)을 얻을 수 있으며, 제 1 내지 제 m 이미지 토큰 확률 들(ITP1~ITPm)은 확률 분포로 이해될 수 있다. 마지막으로, 제 1 내지 제 m 이미지 토큰 확률들(ITP1~ITPm)로부터 샘플링이 수행되어 제 k 이미지 토큰(ITk)을 생성할 수 있다. 실시 예들에서, 제 1 내지 제 m 이미지 토큰 확률들(ITP1~ITPm)가 나타내는 확률 분포에 따라 제 1 내지 제 m 이미지 토큰 확률들(ITP1~ITPm) 중 어느 하나가 선택될 수 있으며, 그 중 선택된 이미지 토큰 확률의 순서가 제 k 이미지 토큰(ITk)의 값으로서 결정될 수 있다. 다시 도 5를 참조하면, 이미지 벡터 양자화기는 제 1 버퍼 메모리에 연결된다. 이미지 벡터 양자화기 는 이미지 인코더(IEN)와 이미지 디코더(IDE)를 포함할 수 있다. 이미지 벡터 양자화기는 도 2의 이 미지 벡터 양자화기와 마찬가지로 구성될 수 있다. 도 5를 참조하여 설명된 이미지 생성 장치의 동작들에 따라, 제 1 및 제 2 버퍼 메모리들(521, 522) 각각 에 제 1 내지 제 q 이미지 토큰들(IT1~ITq)이 누적될 수 있다. 도 5와 함께 도 7을 참조하면, 제 1 버퍼 메모리 에 누적된 제 1 내지 제 q 이미지 토큰들(IT1~ITq)이 개념적으로 도시되어 있다. 이미지 벡터 양자화기 는 이미지 디코더(IDE)를 이용하여 제 1 내지 제 q 이미지 토큰들(IT1~ITq)을 디코딩하여 이미지(IMG)를 생성할 수 있다. 도 5 및 도 7에서 이미지 벡터 양자화기는 제 1 버퍼 메모리의 제 1 내지 제 q 이미 지 토큰들(IT1~ITq)에 액세스하는 것으로 도시된다. 그러나, 실시 예들은 여기에 한정되지 않으며, 이미지 벡터 양자화기는 제 2 버퍼 메모리에 누적된 제 1 내지 제 q 이미지 토큰들(IT1~ITq)에 액세스할 수도 있 다. 도 5에서, 제 1 내지 제 3 버퍼 메모리들(521~523)은 서로 분리된 구성 요소들로 도시되어 있으나, 실시 예들은 여기에 한정되지 않는다. 예를 들면, 제 1 내지 제 3 버퍼 메모리들(521~523) 중 적어도 2 이상은 물리적 및/또 는 논리적으로 통합된 메모리로서 제공될 수 있다. 본 발명의 실시 예에 따르면, 제 1 내지 제 n 레이아웃 토큰들(LT1~LTn) 및 그것들에 대응하는 비교 토큰들(N L)을 이용하여 각 이미지 토큰이 생성될 수 있다. 이에 따라, 그러한 이미지 토큰들에 기반하여 생성된 이미지 (IMG)는 이미지에 포함될 오브젝트들의 레이아웃에 대한 사용자의 의도를 상대적으로 높은 신뢰성으로 반영할수 있다. 도 8은 도 5의 레이아웃 토큰 세트의 실시 예를 개념적으로 보여주는 도면이다. 도 8을 참조하면, 레이아웃 토큰 세트(LTS)는 제 1 레이아웃 토큰 세트(LTS1)와 제 2 레이아웃 토큰 세트(LTS 2)를 포함할 수 있다. 제 1 레이아웃 토큰 세트(LTS1)는 제 1 내지 제 x 레이아웃 토큰들(LT1~LTx, x는 n보다 작은 양의 정수)을 포함 할 수 있다. 제 1 내지 제 x 레이아웃 토큰들(LT1~LTx)은 이미지(IMG)에 포함될 오브젝트들의 클래스들과 연관 될 수 있다. 예를 들면, 제 1 내지 제 x 레이아웃 토큰들(LT1~LTx)은 디코딩될 때 이미지(IMG)에 포함될 오브젝 트들의 클래스들을 나타내는 데이터로 변환될 수 있다. 제 2 레이아웃 토큰 세트(LTS2)는 제 x+1 내지 제 n 레이아웃 토큰들(LTx+1~LTn)을 포함할 수 있다. 제 x+1 내 지 제 n 레이아웃 토큰들(LTx+1~LTn)은 이미지(IMG)에 포함될 오브젝트들의 포지션들과 연관될 수 있다. 예를 들면, 제 x+1 내지 제 n 레이아웃 토큰들(LTx+1~LTn)은 디코딩될 때 이미지(IMG)에 포함될 오브젝트들의 포지션 들을 나타내는 데이터로 변환될 수 있다. 도 9는 도 5의 이미지 생성 장치의 다른 실시 예를 보여주는 블록도이다. 도 9를 참조하면, 이미지 생성 장치는 패더, 제 1 및 제 2 버퍼 메모리들(521, 522), 제 1 및 제 2 트랜스포머 디코더들(531, 532), 이미지 벡터 양자화기, 및 이미지 토큰 생성기를 포함할 수 있다. 이미지 생성 장치는 도 5의 이미지 생성 장치와 같이 텍스트 인코더 및 제 3 버퍼 메모리를 더 포함 할 수 있으나, 명확 및 간결한 설명을 위해 생략된다. 제 1 및 제 2 버퍼 메모리들(521, 522), 제 1 및 제 2 트랜스포머 디코더들(531, 532), 이미지 벡터 양자화기 , 및 이미지 토큰 생성기는 각각 도 5를 참조하여 설명된 바와 마찬가지로 구성된다. 이하, 중복되는 설명은 생략된다. 패더는 제 2 버퍼 메모리 내 데이터 매트릭스 중 제 1 레이아웃 토큰 세트(LTS1)에 대응하는 위치들 에 비교 토큰들(NL)을 기입(혹은 패딩)할 수 있다. 기입된 비교 토큰들(NL)은 널 데이터(ND')를 구성할 수 있다. 제 2 버퍼 메모리 내 데이터 매트릭스는 제 2 레이아웃 토큰 세트(LTS2)를 포함할 수 있다. 이에 따 라, 제 2 버퍼 메모리 내 데이터 매트릭스는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm), 비교 토큰들(NL), 및 제 2 레이아웃 토큰 세트(LTS2)를 저장할 수 있다. 제 1 버퍼 메모리 내 데이터 매트릭스는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm), 제 1 레이아웃 토큰 세 트(LTS1), 및 제 2 레이아웃 토큰 세트(LTS2)를 저장할 수 있다. 이후, 제 1 및 제 2 트랜스포머 디코더들(531, 532)과 이미지 토큰 생성기는 이미지 토큰을 생성할 수 있 다. 이와 같이, 제 1 레이아웃 토큰 세트(LTS1) 및 그것에 대응하는 비교 토큰들(NL)을 이용하여 이미지 토큰이 생 성될 수 있다. 이에 따라, 그러한 이미지 토큰들에 기반하여 생성된 이미지(IMG)는 오브젝트들의 클래스들에 대 한 사용자의 의도를 상대적으로 높은 신뢰성으로 반영할 수 있다. 도 10은 도 5의 이미지 생성 장치의 또 다른 실시 예를 보여주는 블록도이다. 도 10을 참조하면, 이미지 생성 장치는 패더, 제 1 및 제 2 버퍼 메모리들(521, 522), 제 1 및 제 2 트랜스포머 디코더들(531, 532), 이미지 벡터 양자화기, 및 이미지 토큰 생성기를 포함할 수 있다. 이미지 생성 장치는 도 5의 이미지 생성 장치와 같이 텍스트 인코더 및 제 3 버퍼 메모리(52 3)를 더 포함할 수 있으나, 명확 및 간결한 설명을 위해 생략된다. 제 1 및 제 2 버퍼 메모리들(521, 522), 제 1 및 제 2 트랜스포머 디코더들(531, 532), 이미지 벡터 양자화기 , 및 이미지 토큰 생성기는 각각 도 5를 참조하여 설명된 바와 마찬가지로 구성된다. 이하, 중복되는 설명은 생략된다. 패더는 제 2 버퍼 메모리 내 데이터 매트릭스 중 제 2 레이아웃 토큰 세트(LTS2)에 대응하는 위치들 에 비교 토큰들(NL)을 기입할 수 있다. 기입된 비교 토큰들(NL)은 널 데이터(ND'')를 구성할 수 있다. 제 2 버 퍼 메모리 내 데이터 매트릭스는 제 1 레이아웃 토큰 세트(LTS1)를 포함할 수 있다. 이에 따라, 제 2 버퍼 메모리 내 데이터 매트릭스는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm), 제 1 레이아웃 토큰 세트(LTS1),및 비교 토큰들(NL)을 저장할 수 있다. 제 1 버퍼 메모리 내 데이터 매트릭스는 제 1 내지 제 m 텍스트 토큰들(TT1~TTm), 제 1 레이아웃 토큰 세 트(LTS1), 및 제 2 레이아웃 토큰 세트(LTS2)를 저장할 수 있다. 이후, 제 1 및 제 2 트랜스포머 디코더들(531, 532)과 이미지 토큰 생성기는 이미지 토큰을 생성할 수 있 다. 이와 같이, 제 2 레이아웃 토큰 세트(LTS2) 및 그것에 대응하는 비교 토큰들(NL)을 이용하여 이미지 토큰이 생 성될 수 있다. 이에 따라, 그러한 이미지 토큰들에 기반하여 생성된 이미지(IMG)는 오브젝트들의 포지션들에 대 한 사용자의 의도를 상대적으로 높은 신뢰성으로 반영할 수 있다. 비록 특정 실시 예들 및 적용 예들이 여기에 설명되었으나, 다른 실시 예들 및 변형들이 위 기재로부터 도출될 수 있다. 따라서, 본 발명의 사상은 이러한 실시 예들에 한정되지 않으며, 아래 기재된 특허청구범위, 다양한 자명한 변형들, 그리고 균등물들에까지 미친다."}
{"patent_id": "10-2023-0006948", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 이미지 생성 장치를 보여주는 블록도이다. 도 2는 도 1의 이미지 생성 장치의 실시 예를 보여주는 블록도이다. 도 3은 도 2의 트랜스포머 디코더의 실시 예를 보여주는 블록도이다. 도 4는 도 1의 이미지 생성 장치의 다른 실시 예를 보여주는 블록도이다. 도 5는 본 발명의 실시 예에 따른 이미지 생성 장치를 보여주는 블록도이다. 도 6은 도 5의 이미지 토큰 생성기에 의해 처리되는 데이터를 개념적으로 보여주는 도면이다. 도 7은 도 5의 이미지 벡터 양자화기 및 그 입력과 출력을 개념적으로 보여주는 블록도이다. 도 8은 도 5의 레이아웃 토큰 세트의 실시 예를 개념적으로 보여주는 도면이다. 도 9는 도 5의 이미지 생성 장치의 다른 실시 예를 보여주는 블록도이다. 도 10은 도 5의 이미지 생성 장치의 또 다른 실시 예를 보여주는 블록도이다."}
