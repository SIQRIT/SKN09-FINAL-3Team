{"patent_id": "10-2017-0170919", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0070432", "출원번호": "10-2017-0170919", "발명의 명칭": "영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 방법 및 진단 시스템", "출원인": "(주)엔텔스", "발명자": "심재희"}}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "클라이언트 장치가 피부 색상을 나타내는 색상값으로 구성되는 제1 영상 및 피부 온도를 나타내는 색상값으로구성되는 제2 영상을 포함하는 사용자의 얼굴 영상을 전송하는 단계;서비스 서버가 수신한 상기 얼굴 영상을 분석 서버에 전송하는 단계;상기 분석 서버가 사전에 마련된 신경망 모델에 상기 얼굴 영상을 입력하여 생성되는 진단 데이터를 전송하는단계;상기 서비스 서버가 상기 진단 데이터를 상기 클라이언트 장치에 전송하는 단계; 및상기 서비스 서버가 상기 진단 데이터를 병원 서버에 전송하는 단계를 포함하되,상기 클라이언트 장치는 거울층 및 상기 거울층 배면에서 가이드 이미지를 출력하는 디스플레이 장치, 상기 거울층 전면 방향에 위치하면서 상기 가이드 이미지 내에 정합되는 얼굴에 대한 제1 영상을 촬영하는 제1 카메라장치, 상기 거울층 전면 방향에 위치하면서 상기 가이드 이미지 내에 정합되는 얼굴에 대한 온도를 나타내는 제2 영상을 촬영하는 제2 카메라 장치 및 상기 영상을 네트워크로 전송하는 통신 장치를 포함하고, 상기 제2 카메라 장치는 적외선 카메라이고,상기 신경망 모델은 상기 얼굴 영상에서 복수의 얼굴 영역을 추출하는 제1 신경망 모델 및 상기 복수의 얼굴 영역에 대하여 색상 및 온도 중 적어도 하나에 대한 값을 매개 변수로 갖고 상기 정보를 출력하는 제2 신경망 모델을 포함하고,상기 제2 신경망 모델은 상기 복수의 영역 각각에 대하여 별개의 모델을 포함하고, 상기 분석 서버는 상기 별개의 모델이 각각 출력하는 결과값에 서로 다른 가중치를 부여하여 상기 진단 데이터를 생성하는 영상 데이터를분석하는 인공 지능을 이용한 질병 진단 방법."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "클라이언트 장치가 사용자의 얼굴 영상을 전송하는 단계;서비스 서버가 수신한 상기 얼굴 영상을 분석 서버에 전송하는 단계;상기 분석 서버가 사전에 마련된 신경망 모델에 상기 얼굴 영상을 입력하여 생성되는 상기 사용자에 대한 진단데이터를 전송하는 단계;상기 서비스 서버가 상기 진단 데이터를 상기 클라이언트 장치에 전송하는 단계; 및상기 서비스 서버가 상기 진단 데이터를 병원 서버에 전송하는 단계를 포함하되,상기 신경만 모델은 복수의 얼굴 영역별 색상 및 복수의 얼굴 영역별 온도 중 적어도 하나를 입력으로 삼아, 사용자의 건강 상태에 대한 정보를 출력하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 방법."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 클라이언트 장치는 화면에 가이드 이미지를 출력하고, 일반 카메라 및 적외선 카메라 중 적어도 하나로 상기 가이드 이미지 내에 위치하는 객체에 대한 영상을 획득하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 방법."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 얼굴 영상은 피부 색상을 나타내는 색상값으로 구성되는 제1 영상 및 피부 온도를 나타내는 색상값으로 구공개특허 10-2019-0070432-3-성되는 제2 영상을 포함하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 방법."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 신경망 모델은 상기 얼굴 영상에서 복수의 얼굴 영역을 추출하는 제1 신경망 모델 및 상기 복수의 얼굴 영역에 대하여 색상 및 온도 중 적어도 하나에 대한 값을 매개 변수로 갖고 상기 정보를 출력하는 제2 신경망 모델을 포함하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 방법."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제2 신경망 모델은 상기 복수의 영역 각각에 대하여 별개의 모델을 포함하고, 상기 분석 서버는 상기 별개의 모델이 각각 출력하는 결과값에 서로 다른 가중치를 부여하여 상기 진단데이터를 생성하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 방법."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 제2 신경망 모델은 상기 복수의 영역 각각에 대하여 별개의 모델을 포함하고, 상기 분석 서버는 상기 별개의 모델이 각각 출력하는 결과값 중 가장 많은 동일한 결과값을 상기 진단 데이터로 마련하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 방법."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서,상기 클라이언트 장치는 거울층 및 상기 거울층 배면에서 영상을 출력하는 디스플레이 장치;상기 거울층 전면 방향의 영상을 획득하는 카메라 장치; 및상기 영상을 네트워크로 전송하는 통신 장치를 포함하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단방법."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "카메라로 사용자의 얼굴 영상을 획득하여 전송하는 클라이언트 장치;상기 클라이언트 장치의 요청을 수신하고, 상기 얼굴 영상을 송신하고, 상기 얼굴 영상에 대한 분석 결과를 클라이언트 장치에 전달하는 서비스 서버; 및사전에 마련된 신경망 모델에 상기 얼굴 영상을 입력하여 생성되는 상기 사용자에 대한 진단 데이터를 전송하는분석 서버를 포함하되,상기 신경만 모델은 복수의 얼굴 영역별 색상 및 복수의 얼굴 영역별 온도 중 적어도 하나를 입력으로 삼아, 사용자의 건강 상태에 대한 정보를 출력하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 시스템."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 클라이언트 장치는 거울층 및 상기 거울층 배면에서 상기 분석 결과를 출력하는 디스플레이 장치;상기 거울층 전면 방향의 영상을 획득하는 카메라 장치; 상기 거울층 전면 방향의 온도 영상을 획득하는 적외선 카메라 장치; 및상기 영상을 송신하고, 상기 분석 결과를 수신하는 통신 장치를 포함하는 영상 데이터를 분석하는 인공 지능을공개특허 10-2019-0070432-4-이용한 질병 진단 시스템."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 클라이언트 장치는 상기 분석 결과를 병원 서버에 전달하는 영상 데이터를 분석하는 인공 지능을 이용한질병 진단 시스템."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 얼굴 영상은 피부 색상을 나타내는 색상값으로 구성되는 제1 영상 및 피부 온도를 나타내는 색상값으로 구성되는 제2 영상을 포함하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 시스템."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 신경망 모델은 상기 얼굴 영상에서 복수의 얼굴 영역을 추출하는 제1 신경망 모델 및 상기 복수의 얼굴 영역에 대하여 색상 및 온도 중 적어도 하나에 대한 값을 매개 변수로 갖고 상기 정보를 출력하는 제2 신경망 모델을 포함하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 시스템."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제2 신경망 모델은 상기 복수의 영역 각각에 대하여 별개의 모델을 포함하고, 상기 분석 서버는 상기 별개의 모델이 각각 출력하는 결과값에 서로 다른 가중치를 부여하여 상기 진단데이터를 생성하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 시스템."}
{"patent_id": "10-2017-0170919", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 제2 신경망 모델은 상기 복수의 영역 각각에 대하여 별개의 모델을 포함하고, 상기 분석 서버는 상기 별개의 모델이 각각 출력하는 결과값 중 가장 많은 동일한 결과값을 상기 진단 데이터로 마련하는 영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 시스템."}
{"patent_id": "10-2017-0170919", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 방법은 클라이언트 장치가 사용자의 얼굴 영상을 전송하 는 단계, 서비스 서버가 수신한 상기 얼굴 영상을 분석 서버에 전송하는 단계, 상기 분석 서버가 사전에 마련된 신경망 모델에 상기 얼굴 영상을 입력하여 생성되는 상기 사용자에 대한 진단 데이터를 전송하는 단계, 상기 서 비스 서버가 상기 진단 데이터를 상기 클라이언트 장치에 전송하는 단계 및 상기 서비스 서버가 상기 진단 데이 터를 병원 서버에 전송하는 단계를 포함한다. 상기 신경만 모델은 복수의 얼굴 영역별 색상 및 복수의 얼굴 영역 별 온도 중 적어도 하나를 입력으로 삼아, 사용자의 건강 상태에 대한 정보를 출력한다."}
{"patent_id": "10-2017-0170919", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하 설명하는 기술은 얼굴 영상을 이용하여 질병을 진단하는 기법 에 관한 것이다."}
{"patent_id": "10-2017-0170919", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 빅데이터 분석 내지 인공 지능을 접목한 다양한 기법에 대한 연구가 진행되고 있다. 질병 진단 분야에서도 컴퓨터를 활용하여 환자의 검사 결과를 분석하는 기법도 연구되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1740464호"}
{"patent_id": "10-2017-0170919", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이하 설명하는 기술은 사용자의 얼굴 영상을 이용하여 사용자의 건강 상태 내지 질병을 진단하는 방법을 제공하 고자 한다."}
{"patent_id": "10-2017-0170919", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "영상 데이터를 분석하는 인공 지능을 이용한 질병 진단 방법은 클라이언트 장치가 사용자의 얼굴 영상을 전송하 는 단계, 서비스 서버가 수신한 상기 얼굴 영상을 분석 서버에 전송하는 단계, 상기 분석 서버가 사전에 마련된 신경망 모델에 상기 얼굴 영상을 입력하여 생성되는 상기 사용자에 대한 진단 데이터를 전송하는 단계, 상기 서 비스 서버가 상기 진단 데이터를 상기 클라이언트 장치에 전송하는 단계 및 상기 서비스 서버가 상기 진단 데이 터를 병원 서버에 전송하는 단계를 포함한다. 상기 신경만 모델은 복수의 얼굴 영역별 색상 및 복수의 얼굴 영 역별 온도 중 적어도 하나를 입력으로 삼아, 사용자의 건강 상태에 대한 정보를 출력한다."}
{"patent_id": "10-2017-0170919", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이하 설명하는 기술은 사용자가 이용하는 스마트 기기 등과 같은 장치로 획득한 얼굴 영상을 인공신경망을 이용 하여 분석하여 즉각적으로 건강 상태 내지 질병 가능성에 대한 정보를 제공한다. 이하 설명하는 기술은 사용자 가 자신의 건강 강태를 수시로 점검 가능하게 하고, 필요한 경우 병원에 관련 정보를 제공하여 건강 관리에 만 전을 기하게 한다."}
{"patent_id": "10-2017-0170919", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시례를 가질 수 있는 바, 특정 실시례들을 도면 에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 이하 설명하는 기술을 특정한 실시 형태에 대해 한정하려 는 것이 아니며, 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하 는 것으로 이해되어야 한다. 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 해당 구성요소들은 상기 용어 들에 의해 한정되지는 않으며, 단지 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예 를 들어, 이하 설명하는 기술의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 본 명세서에서 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함 하는 것으로 이해되어야 하고, \"포함한다\" 등의 용어는 설시된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요 소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의 해 전담되어 수행될 수도 있음은 물론이다.또, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기 재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 이하 설명하는 기술은 사용자의 얼굴 영상을 이용하여 해당 사용자의 건강 상태를 확인하는 기법에 관한 것이다. 이하 설명하는 기술은 얼굴 영상을 인공 지능 기법으로 분석하여 건강 상태 내지 질병 여부를 분석하는 기법이다. 사용자의 건강이나 질병과 관련된 정보를 이하 진단 정보라고 명명한다. 진단 정보는 다양한 유형의 정보로 구성될 수 있다. 진단 정보는 얼굴의 피부 상태에 대한 정보를 포함할 수 있다. 예컨대, 진단 정보 는 피부의 유분 정도, 피부의 수분 정도, 피부의 노화 정도, 피부의 주름 상태, 피부의 색상 변화 정도 등에 대 한 정보를 포함할 수 있다. 진단 정보는 다른 신체 부위의 건강 상태에 대한 정보를 포함할 수 있다. 얼굴 의 색상 및/또는 온도를 기준으로 추정가능한 신체 부위의 건강 상태를 의미한다. 예컨대, 진단 정보는 소화 기 관의 장애, 혈액 순환 장애, 호흡기 관련 장애, 알러지 반응, 눈병 등에 대한 정보를 포함할 수 있다. 나아 가 진단 정보는 사용자의 머리 부위를 기준으로 측정되는 모발 상태, 탈모 진행 상태 등에 대한 정보를 포함할 수 도 있다. 도 1은 인공 지능을 이용한 질병 진단 시스템의 구성을 도시한 예이다. 질병 진단 시스템은 클라이언 트 장치, 서비스 서버 및 분석 서버를 포함한다. 클라이언트 장치는 사용자가 사용하는 장치이다. 클라이언트 장치는 스마트 기기, PC 등과 같은 장치 일 수 있다. 클라이언트 장치는 기본적으로 사용자의 얼굴 영상을 획득하고, 얼굴 영상을 다른 객체에 전 송한다. 따라서 클라이언트 장치는 사용자 얼굴 영상을 획득할 수 있는 카메라를 포함한다. 클라이언트 장 치는 특정한 애플리케이션을 구동하여 서비스를 수행할 수 있다. 이 경우 클라이언트 장치가 애플리 케이션을 구동하면 서비스 서버에 접속하고, 필요한 경우 로그인을 수행하면 이후 얼굴 영상 촬영 등이 진 행 될 수 있다. 서비스 서버는 얼굴 영상을 이용한 진단 정보 제공에 대한 전반적인 서비스를 제공한다. 서비스 서버(12 0)는 접속한 클라이언트 장치를 인증할 수 있다. 서비스 서버는 클라이언트 장치에 얼굴 영상 촬영을 요청하는 명령을 전달할 수 있다. 요청에 따라 사용자가 클라이언트 장치에서 얼굴 영상을 촬영하 면, 서비스 서버는 클라이언트 장치로부터 얼굴 영상을 전송받는다. 서비스 서버는 분석 서버 로 얼굴 영상을 전송하고, 분석 서버로부터 분석 결과에 해당하는 진단 정보를 수신한다. 서비스 서 버는 진단 정보를 클라이언트 장치에 전송할 수 있다. 서비스 서버는 진단 정보를 일정하게 가 공하여 클라이언트 장치에 전송할 수 있다. 예컨대, 서비스 서버는 진단 정보를 시각화하거나, 자신 이 보유한 통계적 자료와 비교한 데이터를 생성하여 클라이언트 장치에 전송할 수 있다. 서비스 서버(12 0)는 진단 정보를 병원 서버에 전송할 수도 있다. 병원 서버는 해당 사용자에 대한 의료 서비스를 제공하는 병원이 관리하는 서버에 해당한다. 서비스 서버 는 특정 사용자와 매칭되는 병원 서버에 대한 정보를 사전에 보유한다고 가정한다. 병원 서버는 사용자에 대한 공적 의료 서비스를 제공하는 기관이 관리하는 서버일 수도 있다. 분석 서버는 인공 신경망을 이용하여 얼굴 영상을 분석한다. 분석 서버는 사전에 훈련한 인공 신경망 을 보유한다고 전제한다. 분석 서버는 별도의 분석 모델 DB에 인공 신경망을 보유하고 관리할 수도 있다. 인공 신경망을 활용한 분석 과정에 대해서는 후술한다. 도 2는 클라이언트 장치에 대한 예이다. 도 2(A)는 클라이언트 장치에 대한 예이다. 도 2(A)는 스마트 기 기와 같은 클라이언트 장치에 대한 예이다. 스마트 기기는 내장한 카메라를 이용하여 사용자의 얼굴 영상 을 획득할 수 있다. 후술하겠지만, 클라이언트 장치는 얼굴의 온도를 추정하기 위하여 적외선 카메라 같은 장치를 포함할 수도 있다. 도 2(B)는 클라이언트 장치에 대한 예이다. 도 2(B)는 거울을 포함하는 구조물에 설치된 클라이언트 장치 에 대한 예이다. 클라이언트 장치는 거울층과 거울층 배면에 위치한 디스플레이층을 포함한다. 디스플레이층는 LED, OLED 또는 LCD 등과 같은 방식의 디스플레이 패널을 포함한다. 거울층은 반투명한 거울(half-silvered mirror)이다. 반투명한 거울이기 때문에 거울층의 배면에 있는 디스 플레이층에서 출력되는 영상이 전면에 있는 사용자에게 출력될 수 있다. 클라이언트 장치는 일반 영 상을 촬영하는 제1 카메라과 적외선 영상을 촬영하는 제2 카메라를 포함할 수 있다. 클라이언트 장치 는 화장대, 욕실의 거울, 화장실의 거울 등과 같은 구조물 형태일 수 있다. 도 3은 클라이언트 장치의 구성에 대한 예이다. 클라이언트 장치는 전술한 클라이언트 장치 또 는 클라이언트 장치에 해당한다. 도 3은 클라이언트 장치 또는 클라이언트 장치에 대한 구성을 도시한 예이다. 클라이언트 장치는 입력장치, 제1 카메라, 제2 카메라, 연산장치, 저 장장치, 출력장치 및 통신장치를 포함한다. 입력장치는 기본적으로 사용자로부터 일정한 명령이나 정보를 입력받은 장치이다. 입력장치는 키보드, 마우스, 터치 입력 장치, 음성 입력 장치 등으로 구현될 수 있다. 입력장치는 얼굴 영상을 이용한 질병 진단을 위한 애플리케이션을 실행하는 명령, 영상 촬영 명령, 진단 정보 요청 명령, 진단 정보를 병원 서 버에 전달하라는 명령 등을 입력받을 수 있다. 제1카메라는 사용자의 얼굴 영상을 획득하는 장치이다. 제1카메라는 영상의 각 픽셀에 대한 색상 종 류와 색상의 정도(레벨)를 나타내는 정보를 생성한다. 제1카메라는 일반적인 카메라 장치 내지 카메라 센 서에 해당한다. 제2카메라는 촬영한 객체의 온도를 나타내는 영상을 생성한다. 예컨대, 제2카메라는 적외선 카메라일 수 있다. 제2카메라는 촬영 대상(얼굴 영역)에 대하여 각 부위별 온도를 나타내는 정보를 생성한다. 저장장치는 각종 프로그램 및 데이터를 저장하는 객체이다. 저장장치는 하드디스크 및/또는 비휘발성 메모리로 구현될 수 있다. 저장장치는 질병 진단을 위한 애플리케이션, 카메라(310, 320)가 획득한 영상, 서비스 서버에서 전달받은 진단 정보 등을 저장할 수 있다. 연산장치는 AP(Application process) 또는 CPU 등과 같은 장치를 의미한다. 연산장치는 주어진 명령 에 따라 특정 연산을 수행한다. 연산장치는 저장장치에 저장된 애플리케이션을 실행하면서 관련된 연 산이나 작업을 수행한다. 연산장치는 촬영한 영상 또는 특정한 명령을 통신장치에 전달하거나, 진단 정보를 출력장치에 출력하게 하는 제어를 할 수도 있다. 출력장치는 일정한 정보를 출력하는 장치이다. 출력장치는 기본적으로 디스플레이 장치로 구현될 수 있다. 출력장치는 영상 촬영을 위한 정보, 애플리케이션 구동을 위한 인터페이스, 진단 결과 등을 출력할 수 있다. 통신장치는 입력된 명령 및/또는 촬영된 영상을 서비스 서버에 전달한다. 또한 통신장치는 서비 스 서버로부터 진단 정보 또는 진단 정보를 일정하게 가공한 데이터를 수신할 수 있다. 도 4는 클라이언트 장치의 화면에 대한 예이다. 클라이언트 장치의 화면은 클라이언트 장치 또 는 클라이언트 장치의 화면에 대한 예이다. 클라이언트 장치는 화면에 얼굴 영상 촬영을 위하여 바람 직한 얼굴 위치를 나타내는 가이드 구역을 표시할 수 있다. 가이드 구역을 이용하는 경우 분석 서버 가 얼굴 영역을 별도로 식별하지 않아도 된다. 분석 서버는 영상의 특정 부분이 특정한 얼굴 영역이 라고 인식할 수 있다. 여기서 얼굴 영역은 코, 눈, 볼, 이마 등과 같이 얼굴을 구성하는 특정한 영역 중 어느 하나를 의미한다. 클라이언트 장치는 화면의 특정 구역에 진단 결과를 출력할 수도 있다. 화면에 출력되는 진단 결과는 분석 서버가 전달한 진단 정보 또는 진단 정보를 가공한 정보일 수 있다. 클라이언트 장치는 화면 은 일정한 인터페이스를 출력할 수 있다. 도 4는 진단 결과를 병원 서버에 전송하는 버튼 메뉴를 예시로 표시하였다. 도 5는 클라이언트 장치의 화면에 대한 다른 예이다. 클라이언트 장치는 화면의 특정 구역에 분 석 결과에 대한 그래프 자료 및 통계 자료를 출력할 수 있다. 그래프 자료 등은 서비스 서버가 가공한 데 이터일 수 있다. 경우에 따라서는 클라이언트 장치가 자신이 보유한 이전 진단 정보를 이용하여 일정한 통계적자료를 화면에 출력할 수도 있다. 클라이언트 장치는 화면의 특정 구역에 진단 정보 및 사용자에 대 한 권고 사항을 출력할 수도 있다. 이제 분석 서버에서 얼굴 영상을 이용하여 진단 정보를 생성하기 위하여 이용하는 인공 신경망 모델을 설 명한다. 인공 신경망은 다양한 형태의 신경망일 수 있다. 예컨대, 인공 신경망은 FNN(Feedforward neural network), CNN(Convolutional neural network) 등과 같은 형태로 구현될 수 있다. 나아가 분석 서버는 반 드시 인공 신경망 모델을 사용하여야 하는 것은 아니며, 다양한 기계 학습 모델을 사용할 수도 있다. 다만 이하 설명의 편의를 위하여 영상 처리에서 많이 사용되는 CNN을 기준으로 설명한다. 도 6은 영상 데이터를 분석하는 인공신경망에 대한 예이다. 도 6은 예시적으로 컨볼루션 계층(Convolution Layer) 및 풀링 계층(Pooling Layer)을 각각 2개 갖는 형태를 도시하였다. 컨볼루션 계층과 풀링 계층은 개수는 구현하는 방식에 따라 다양할 수 있다. 컨볼루션 계층과 풀링 계층은 영상에서 특징을 추출하는 구성에 해당하 고, 완전 연결 계층(Fully connected Layer)는 추출한 특징에 기반하여 일정한 분류를 수행하는 구성이다. 컨볼루션 계층은 입력 영상에 대하여 필터 뱅크를 적용하여 일정한 특징값을 추출하는 계층이다. 컨볼루션 계층 의 파라미터(parameter)들은 일련의 학습가능한 필터들로 이뤄져 있다. 각 필터는 가로/세로 차원으로는 작지만 깊이 (depth) 차원으로는 전체 깊이를 아우른다. 포워드 패스 (forward pass) 때에는 각 필터를 입력 볼륨의 가 로/세로 차원으로 이동(convolution) 시키며 2차원의 액티베이션 맵 (activation map)을 생성한다. 필터를 입력 위로 이동 시킬 때, 필터와 입력의 요소들 사이의 내적 연산 (dot product)이 이뤄진다. 신경망은 입력의 특정 위치의 특정 패턴에 대해 반응하는 (activate) 필터를 학습한다. 액티베이션 맵 (activation map)을 깊이 (depth) 차원을 따라 쌓은 것이 곧 출력 볼륨이 된다. 그러므로 출력 볼륨의 각 요소들은 입력의 작은 영역만을 취급하고, 같은 액티베이션 맵 내의 뉴런들은 같은 모수들을 공유한다. 도 6에 도시한 바와 같이 영상과 같은 고차원 입력을 다룰 때에는, 현재 레이어의 한 뉴런을 이전 볼륨의 모든 뉴런들과 연결하는 것이 비효율적이다. 따라서 레이어의 각 뉴런을 입력 볼륨의 로컬한 영역(local region)에만 연결한다. 풀링 계층(Max-Pooling Layer 또는 Subsampling Layer)은 입력 영상에 대하여 지역적으로 최대값을 추출하여 2D 이미지로 맵핑하는 계층이다. CNN은 컨볼루션 계층들 중간중간에 주기적으로 풀링 계층을 포함한다. 풀링 계 층은 네트워크의 파라미터의 개수나 연산량을 줄이기 위해 공간의 크기를 줄인다. 예컨대, 풀링 계층은 서브 샘 플 윈도우에서 가장 큰 값만을 선택하여 이후 샘플의 크기를 줄일 수 있다. 컨볼루션 계층과 풀링 계층 과정을 반복하면 입력 영상을 대표할 수 있는 특징을 얻을 수 있다. 이러한 특징을 학습하여 일정한 결과를 출력한다. 완전 연결 계층은 복수 계층망의 표준적인 계층으로 입력 벡터와 가중치 값 의 선형결합이 수행된다. 분류는 입출력간의 이미지 오차를 최소화하는 방향으로 학습을 반복한다. 분석 서버이 사용하는 인공 신경망을 학습하는 예를 설명한다. 분석 서버는 도 6과 같은 하나의 CNN 을 이용할 수 있다. 인공 신경망은 얼굴 영상의 색상을 입력으로 사용할 수 있다. 인공 신경망은 기본적으로 얼굴 영역을 구성 하는 각 픽셀값을 기준으로 특징을 추출하여 학습할 수 있다. 일반 영상을 제1 영상이라고 명명한다. 일반 영상 이란 일반적인 칼라 영상을 의미한다. 인공 신경망은 나아가 얼굴의 온도를 입력으로 사용할 수 있다. 전술한 바와 같이 클라이언트 장치(110, 200)는 일반 영상과 함께 적외선 영상을 생성할 수 있다. 이 경우 인공 신경망은 동일한 얼굴 영역의 온도를 나 타내는 적외선 영상에서 특징을 추출하여 학습할 수 있다. 적외선 영상을 제2 영상이라고 명명한다. 인공 신경망은 얼굴에 대한 제1 영상 및 제2 영상을 동시에 입력받아 학습할 수 있다. 몇 가지 구현 가능한 방법들이 있다. (i) 하나는 제1 영상과 제2 영상을 결합(예컨대, add 연산)하여 결합된 영상을 기준으로 특징값 을 찾고 학습하는 방법이다. (ii) 다른 하나는 제1 영상과 제2 영상에서 각각 특징값을 찾고, 특징값을 결합하 여 완전 연결 계층에서 분류하도록 학습하는 방법이다. 한편 얼굴 영상을 복수의 얼굴 영역(눈, 코, 입, 이마, 뺨 등)으로 구분될 수 있다. 이러한 구분은 별다른 영상 처리 없이 도 4와 같은 가이드 구역을 활용하여 영상의 특정 부분을 해당 영역이라고 가정하고 처리할 수 있다.이 경우 다음과 같은 구현이 가능하다. 인공 신경망은 서로 다른 얼굴 영역에 대하여 각 노드에 서로 다른 파라미터를 적용하여 특징값을 추출할 수 있다. 인공 신경망은 서로 다른 얼굴 영역에 대한 특징값에 대하 여 각 얼굴 영역 별로 분류기를 사전에 학습할 수 있다. 즉, 현재 추출된 특징값이 제1 특정 영역에서 추출된 것이라면, 제1 분류기를 사용하여 영상을 분석하는 것이다. 도 7은 영상 데이터를 분석하는 인공신경망에 대한 다른 예이다. 도 7은 CNN을 계층적으로 구성한 예이다. 도 7 의 CNN은 제1 계층 CNN과 제2 계층 CNN으로 구성된다. 제1 계층 CNN은 입력되는 영상에서 특정한 얼굴 영역을 분류한다. 제1 계층 CNN은 입력 영상에서 얼 굴을 인식하는 기법을 활용하여 입력 영상에서 전체 얼굴 영역을 추출하고, 추출한 전체 얼굴 영역에서 각 얼굴 영역(코, 눈, 뺨 등)을 식별한다. 제2 계층 CNN은 다양한 방법으로 구현될 수 있다. 제2 계층 CNN은 얼굴 영역에 따라서 서로 다른 파라미터나 가중치를 부여한 노드를 활용하여 특징을 추출할 수 있다. 이 경우 제2 계층 CNN은 하나의 CNN으로 구현된다. 또 도 7에 도시한 바와 같이 각 얼굴 영역 별로 서로 다른 CNN을 사전에 마련할 수 있다. 예컨대, 제2 계층 CNN은 얼굴 영역 A 전용으로 구성된 CNN이고, 제2 계층 CNN은 얼굴 영역 B 전용으로 구성된 CNN이다. 설명의 편의를 위해 제2 계층 CNN과 제2 계층 CNN만을 예로 설명한다. 제2 계층 CNN은 더 많은 수의 CNN을 포함할 수도 있다. 제2 계층 CNN 및 제2 계층 CNN은 각각 얼굴 영역 A와 얼굴 영역 B만을 입력으로 받는다. 이 경우 제2 계층 CNN 및 제2 계층 CNN은 얼굴 영역 전체가 아닌 일부를 사용하는 것이다. 제2 계층 CNN 및 제2 계층 CNN은 각각 입력된 영상을 기준으로 특징값을 추출하고, 추출한 특징값에 따라 학습하여 완전 연 결 계층을 마련한다. 즉 제2 계층 CNN 및 제2 계층 CNN은 서로 동일한 값(진단 정보)을 출력할 수도 있고, 서로 다른 값을 출력할 수도 있다. 분석 서버는 복수의 제2 계층 CNN에서 출력하는 진단 정보 중 가장 많은 동일한 값을 갖는 진단 정보를 최 종적인 진단 정보로 선택할 수 있다. 또는 분석 서버는 복수의 제2 계층 CNN 각각이 출력하는 값에 서로 다른 가중치를 부여하여 합산한 결과값을 최종적인 진단 정보로 선택할 수도 있다. 경우에 따라서는 복수의 복 수의 제2 계층 CNN이 출력하는 값을 다른 기계 학습 모델로 학습하여 최종적인 진단 정보를 추출할 수도 있다. 분석 서버는 도 6 내지 도 7에서 설명한 바와 같이 학습한 CNN을 활용하여 입력 영상을 분석하고, 분석 결 과(진단 정보)를 서비스 서버에 전달한다. 본 실시례 및 본 명세서에 첨부된 도면은 전술한 기술에 포함되는 기술적 사상의 일부를 명확하게 나타내고 있 는 것에 불과하며, 전술한 기술의 명세서 및 도면에 포함된 기술적 사상의 범위 내에서 당업자가 용이하게 유추 할 수 있는 변형 예와 구체적인 실시례는 모두 전술한 기술의 권리범위에 포함되는 것이 자명하다고 할 것이다."}
{"patent_id": "10-2017-0170919", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 인공 지능을 이용한 질병 진단 시스템의 구성을 도시한 예이다. 도 2는 클라이언트 장치에 대한 예이다. 도 3은 클라이언트 장치의 구성에 대한 예이다. 도 4는 클라이언트 장치의 화면에 대한 예이다. 도 5는 클라이언트 장치의 화면에 대한 다른 예이다. 도 6은 영상 데이터를 분석하는 인공신경망에 대한 예이다. 도 7은 영상 데이터를 분석하는 인공신경망에 대한 다른 예이다."}
