{"patent_id": "10-2023-0129822", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0046450", "출원번호": "10-2023-0129822", "발명의 명칭": "악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템", "출원인": "(주)노바코스", "발명자": "임광현"}}
{"patent_id": "10-2023-0129822", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "레이더 신호를 감지 영역으로 투사하고 감지영역의 객체로부터 반사된 신호를 레이더 검지 데이터로 출력하는레이더;상기 레이더로부터 출력되는 레이더 검지 데이터로부터 객체를 검지하고, 객체 검지시 영상 획득을 제어하며,획득한 영상으로부터 인공지능 영상 분석모델을 이용하여 객체를 분류하고, 레이더 검지 데이터의 데이터셋과영상 데이터의 데이터셋을 매칭시켜 레이더와 영상의 객체를 판단하는 레이더-영상 이중화 제어기;상기 레이더-영상 이중화 제어기의 제어에 따라 촬영하여 획득한 영상을 상기 레이더-영상 이중화 제어기로 전송하는 영상 센서; 및학습용 수집 데이터를 기초로 생성된 모델을 학습하여 학습 모델을 최적화하고, 최적화한 인공지능 영상 분석모델을 상기 레이더-영상 이중화 제어기에 업데이트하는 인공지능 학습서버를 포함하는 것을 특징으로 하는 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템."}
{"patent_id": "10-2023-0129822", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에서, 상기 레이더-영상 이중화 제어기로부터 전송된 레이더 및 영상 분석 결과를 기초로 객체 인식 데이터를 제공해주는 엣지 플랫폼 서버를 포함하는 것을 특징으로 하는 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템."}
{"patent_id": "10-2023-0129822", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에서, 상기 레이더-영상 이중화 제어기는,상기 레이더로부터 출력되는 레이더 검지 데이터로부터 객체를 검지하고, 객체 검지 시 영상 획득을 제어하며,레이더 검지 데이터의 데이터셋과 영상 데이터의 데이터셋을 매칭시켜 레이더와 영상의 객체를 판단하는 메인제어부;상기 메인 제어부로부터 영상 분석 요청 시 영상 센서를 통해 영상을 획득하고, 획득한 영상으로부터 인공지능영상 분석모델을 이용하여 객체를 분류하는 인공지능 분석부를 포함하는 것을 특징으로 하는 악천후 조건에서자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템."}
{"patent_id": "10-2023-0129822", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에서, 상기 메인 제어부는 레이더에서 검출된 객체의 검출 시간 정보를 상기 인공지능 분석부에 제공하고 영상 분석을 요청하는 것을 특징으로 하는 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상융복합시스템."}
{"patent_id": "10-2023-0129822", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 3에서, 상기 메인 제어부는,상기 레이더로부터 출력되는 레이더 검지 데이터로부터 객체 분석 알고리즘으로 객체를 검지하는 레이더 객체검지부;상기 레이더 객체 검지부에서 객체 검출 시 인공지능 분석부에 영상 분석을 요청하고, 상기 인공지능 분석부를공개특허 10-2025-0046450-3-통해 전달되는 영상 분석 결과를 수신하는 서버 통신 모듈;상기 레이더 객체 검지부를 통해 검지된 객체 정보의 데이터셋과 상기 서버 통신모듈을 통해 전달되는 영상 정보의 데이터셋을 매칭시켜 병합하는 데이터 병합부;상기 데이터 병합부를 통해 생성된 레이더 및 영상 객체 정보를 엣지 플랫폼 서버에 전송하는 엣지 서버 통신부를 포함하는 것을 특징으로 하는 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템."}
{"patent_id": "10-2023-0129822", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 3에서, 상기 인공지능 분석부는,인공지능 영상 분석모델을 이용하여 영상 센서로부터 획득한 영상으로부터 객체를 분류하는 영상 객체 분류부;상기 영상 객체 분류부에서 분류한 객체 정보를 상기 메인 제어부에 전달하는 클라이언트 통신모듈;수집한 영상 데이터를 학습 데이터로 인공지능 학습서버에 전송하며, 상기 인공지능 학습서버로부터 전송된 인공지능 영상 분석모델로 상기 영상 객체 분류부의 인공지능 영상 분석모델을 업데이트하는 학습 서버 통신부를포함하는 것을 특징으로 하는 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템."}
{"patent_id": "10-2023-0129822", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에서, 상기 학습 서버 통신부는,수집한 영상 데이터에서 프레임 단위로 이미지를 추출하여 학습에 필요한 동적, 정적 객체의 이미지로 제공하는것을 특징으로 하는 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템."}
{"patent_id": "10-2023-0129822", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에서, 상기 인공지능 학습서버는,학습 데이터를 수집하는 학습 데이터 수집부;수집된 영상 이미지를 JPG 형태로 변환하고, 변환된 이미지를 탐지할 객체별로 Object ID를 지정하는 작업을 통해 객체의 영역을 지정하여 이미지 데이터를 라벨링하고, 라벨링된 이미지 데이터를 XML 형태의 포맷으로 저장하는 이미지 라벨링 및 어노테이션부; 및상기 이미지 라벨링 및 어노테이션부를 통해 제공되는 이미지 데이터를 데이터셋으로 하여 미리 생성된 인공지능 영상 분석모델을 학습하고, 학습 결과를 기초로 인공지능 영상 분석모델을 최적화하는 모델 생성부를 포함하는 것을 특징으로 하는 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템."}
{"patent_id": "10-2023-0129822", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "레이더 장비와 카메라 장비에서 수집할 수 있는 데이터셋을 구성하고, 하나의 장비에서 레이더와 영상의 데이터 셋을 매칭하여 표적을 정확하게 인식하도록 하여, 악천후 상황에서도 Level 4 자율주행이 안전하게 이루어지도록 한 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템에 관한 것으로서, 레이더 신호 (뒷면에 계속)"}
{"patent_id": "10-2023-0129822", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템에 관한 것으로, 특히 레이더 장비와 카메라 장비에서 수집할 수 있는 데이터셋을 구성하고, 하나의 장비에서 레이더와 영상의 데이터 셋을 매칭하여 표적을 정확하게 인식하도록 하여, 악천후 상황에서도 Level 4 자율주행이 안전하게 이루어지도 록 한 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템에 관한 것이다."}
{"patent_id": "10-2023-0129822", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 자율주행차의 객체 인식, 도로의 교통을 감시하기 위해 레이더와 영상 장비(예를 들어, 카메라, 비 전 센서, 기타)를 활용하여 객체를 인식하는 기술이 점차 증가하고 있다. 자율주행차는 레이더(Radar), 라이다(Lidar), 스테레오 카메라(Stereo Camera), 초음파 센서(Ultrasonic) 등 다양한 센서가 필요하다. 주지한 바와 같이 객체를 인식하기 위해서, 레이더와 카메라 장비가 많이 사용되는 데, 카메라는 2차원 영상을 도출하고, 레이더는 3차원 위치, 속도 등을 도출할 수 있어, 객체 인식에 많이 활용된다. 레이더 센서는 200m 이내의 인지 가능 거리의 한계로 다양한 도로 교통 환경에 대처하여 안전 솔루션을 제공하 는데 한계가 있다. 특히, 기상 악천후에는 센서 인지 가능 거리가 더욱 축소될 수 있고, 비신호 교차로, 사각지대, 보행자 상충 구간과 같이 단순한 인지뿐만 아니라 복잡한 의사결정을 요구하는 구간에서는 교통 인프라와 협업 없이는 안전 한 정보 제공 한계가 있다. 한편, 자율주행 자동차 개발 및 상용화를 위해, 주행안전도 확보가 가장 중요한 시점에서 이를 위해 전방 및 주 행 차량 주변에 존재하는 다양한 정적/동적 차량의 인식과 검출 성능을 고도화 및 최적화하기 위한 AI, 빅데이 터 기반 알고리즘 개발 등이 연구되고 있다. 하기의 선행기술 1 내지 선행기술 5는 밀리미터 레이더 관련 선행된 연구이다. 선행기술 1은 차량에 적용된 레이더가 FMCW 레이더 방식으로서, 거리 및 전송된 신호와 수신된 신호 사이의 주 파수 차이를 추정하여 대상의 속도를 측정하는 방식이므로, 정확한 주파수 추정은 FMCW 레이더 시스템에서 매우 중요함을 알 수 있다. 선행기술 2를 살펴보면, 레이더 센서를 이용하여 거리를 측정할 경우, 표준편차를 이용한 방법보다는 평균값 필 터를 이용하는 방법이 객체 탐지의 정확도가 높음을 알 수 있다. 선행기술 3은 LFM(Linear Frequency Modulation) 레이더에 대해 높은 정확도로 표적 속도를 측정하는 새로운 방 법을 제안한다. 선행기술 4는 도로 사용자의 행동을 추가로 탐색하고, 안전 위험 및 혼잡 형성의 역학을 추적하여, 보다 미시적 이지만 포괄적인 방식으로 사고 영향을 평가하는 데 효율적임을 알 수 있다. 선행기술 5는 비인가 60GHz 밀리미터파 대역 애플리케이션용으로 설계된 소형 마이크로스트립 패치 안테나를 제 시하여, 단거리 고속 통신을 위한 60GHz 무선 애플리케이션에 적합함을 증명하였다. 아울러 하기의 선행기술 6 내지 선행기술 10은 레이더와 영상을 이용하여 객체를 탐색하는 선행 연구이다. 선행기술 6은 비전 영상과 레이다 영상을 매핑하여 비전 영상에서 목표물의 위치를 구함으로써, 목표물이 위치 한 관심 영역을 정확하게 찾을 수 있도록 제안된 기술이다. 선행기술 7은 호모그래피 행렬(homography matrix)을 사용하여 동기화된 영상 객체 및 레이더 객체를 정합함으 로써 객체 검출의 정확도를 현저히 높였다. 선행기술 8은 물체를 정확하게 감지하고 분류하기 위해, 서로 다른 이기종 데이터를 융합하여 보완적인 이점을 얻을 필요가 있다는 것을 제안하였다. 선행기술 9는 최적 측정 속성을 택하여 현지화 정확도를 개선하는 동시에 적응형 감쇠 기능과 손실 태그를 도입 하여 대상 궤적의 연속성을 보장한다. 선행기술 10은 레이더 대상의 위치와 속도뿐만 아니라 계산된 클래스 점수도 고려하는 클러스터링 단계를 통해 개체 제안을 생성한다. 이와 같이 레이더와 카메라의 고유한 장점을 활용하여 동일한 차량으로 인식하기 위한 연구 사례들이 많이 있지 만, 딥러닝 영상 처리 기술을 이용하지 않거나, 레이더의 성능상의 문제로 짧은 거리만 동일한 표적으로 감지하 고 있는 한계가 있다. 따라서 레이더 장비와 영상 장비에서 수집할 수 있는 데이터셋을 구성하고, 데이터셋의 오차를 계산하여 동일한 표적으로 인식하는 융합 기반 객체 인식 방법이 필요하다. 선행기술문헌 특허문헌(특허문헌 0001) (선행문헌 1) Kyung-Woo Yoo, Seung-Hyun Kong, “Application and Analysis of 1D FRI (Finite Rate of Innovation) Super-resolution Technique in FMCW Radar”, Transactions of the Korean Society of Automotive Engineers, Vol. 22, No. 7, pp. 31-39, Nov 2014. (특허문헌 0002) (선행문헌 2) Si-Woong Jang, Dong-Hun Jung, “Design and Implementation of a Distance Measurement System using Radar Sensor”, Journal of the Korea Institute of Information and Communication Engineering, Vol. 22, No. 7, pp. 1009-1014, July 2018. (특허문헌 0003) (선행문헌 3) Zuoning Dai, Xinggan Zhang, Yechao Bai, “A method of high accuracy velocity measurement for LFM radar”, 2015 IEEE International Conference on Wireless Communications & Signal Processing (WCSP), pp. 1-4, Oct 2015. (특허문헌 0004) (선행문헌 4) Junhua Wang, Ting Fu, Jiangtian Xue, Chengmin Li, Hao Song, Wenxiang Xu, Qiangqiang Shangguan, “Realtime wide-area vehicle trajectory tracking using millimeter-wave radar sensors and the open TJRD TS dataset”, International Journal of Transportation Science and Technology, Mar 2022. (특허문헌 0005) (선행문헌 5) Alam, M. S., Islam, M. T., Misran, N., Mandeep, J. S. “A wideband microstrip patch antenna for 60GHz wireless applications”, Elektronika ir Elektrotechnika, Vol. 19, No. 9, pp. 65-70, Nov 2013. (특허문헌 0006) (선행문헌 6) Mi-Ryong Park, Su-In Lee, “Target matching method for vehicle radar target list and vision image”, ETRI(Electronics and Telecommunications Research Institute) Patent, 2017-0023531. Feb 2017. (특허문헌 0007) (선행문헌 7) Gwang-Seop Kim, Seung-Pyo Cho, “Traffic Information Management System Using Camera and Radar”, Inc. HuNS(Human & Solutions) Patent, 2014-0166072, Nov 2014. (특허문헌 0008) (선행문헌 8) Zhangjing Wang, Xianhan Miao, Zhen Huang, Haoran Luo, “Research of Target Detection and Classification Techniques Using Millimeter-Wave Radar and Vision Sensors”, Remote Sensing, Vol. 13, No. 6, pp. 1064, March 2021. (특허문헌 0009) (선행문헌 9) Jie Bai, Sen Li, Han Zhang, Libo Huang, Ping Wang, “Robust Target Detection and Tracking Algorithm Based on Roadside Radar and Camera”, Sensors, Vol. 21, No. 4, pp. 1116, Feb 2021. (특허문헌 0010) (선행문헌 10) Andras Palffy, Jiaao Dong, Julian F. P. Kooij, Dariu M. Garvrila, “CNN Based Road User Detection Using the 3D Radar Cube”, IEEE Robotics and Automation Letters, Vol. 5, No. 2, pp. 1263-1270, Jan 2020."}
{"patent_id": "10-2023-0129822", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서 본 발명은 상기와 같은 종래 자율주행 차량에서 객체 검출을 위해 레이더를 이용할 경우 인지 가능 거리 의 한계로 다양한 도로 교통 환경에 대처하여 안전솔루션을 제공하는 것이 어렵다는 문제와 딥러닝 영상 처리 기술을 이용하지 않아 발생하는 악천후 시 영상 객체 분류/인식 정확도가 저하되는 문제를 해결하기 위해서 제 안된 것으로서, 레이더 장비와 카메라 장비에서 수집할 수 있는 데이터셋을 구성하고, 하나의 장비에서 레이더 와 영상의 데이터셋을 매칭하여 표적을 정확하게 인식하도록 하여, 악천후 상황에서도 Level 4 자율주행이 안전 하게 이루어지도록 한 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템 및 방법을 제공하는 데 그 목적이 있다."}
{"patent_id": "10-2023-0129822", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 바와 같은 목적을 달성하기 위하여, 본 발명에 따른 \"악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템\"은,레이더 신호를 감지 영역으로 투사하고 감지영역의 객체로부터 반사된 신호를 레이더 검지 데이터로 출력하는 레이더; 상기 레이더로부터 출력되는 레이더 검지 데이터로부터 객체를 검지하고, 객체 검지시 영상 획득을 제어하며, 획득한 영상으로부터 인공지능 영상 분석모델을 이용하여 객체를 분류하고, 레이더 검지 데이터의 데이터셋과 영상 데이터의 데이터셋을 매칭시켜 레이더와 영상의 객체를 판단하는 레이더-영상 이중화 제어기; 상기 레이더-영상 이중화 제어기의 제어에 따라 촬영하여 획득한 영상을 상기 레이더-영상 이중화 제어기로 전 송하는 영상 센서; 학습용 수집 데이터를 기초로 생성된 모델을 학습하여 학습 모델을 최적화하고, 최적화한 인공지능 영상 분석모 델을 상기 레이더-영상 이중화 제어기에 업데이트하는 인공지능 학습서버를 포함하는 것을 특징으로 한다. 또한, 본 발명에 따른 \"악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템\"은, 상기 레이더-영상 이중화 제어기로부터 전송된 레이더 및 영상 분석 결과를 기초로 객체 인식 데이터를 제공해 주는 엣지 플랫폼 서버를 포함하는 것을 특징으로 한다. 상기에서 레이더-영상 이중화 제어기는, 상기 레이더로부터 출력되는 레이더 검지 데이터로부터 객체를 검지하고, 객체 검지 시 영상 획득을 제어하며, 레이더 검지 데이터의 데이터셋과 영상 데이터의 데이터셋을 매칭시켜 레이더와 영상의 객체를 판단하는 메인 제어부; 상기 메인 제어부로부터 영상 분석 요청 시 영상 센서를 통해 영상을 획득하고, 획득한 영상으로부터 인공지능 영상 분석모델을 이용하여 객체를 분류하는 인공지능 분석부를 포함하는 것을 특징으로 한다. 상기에서 메인 제어부는 레이더에서 검출된 객체의 검출 시간 정보를 상기 인공지능 분석부에 제공하고 영상 분 석을 요청하는 것을 특징으로 한다. 상기에서 메인 제어부는, 상기 레이더로부터 출력되는 레이더 검지 데이터로부터 객체 분석 알고리즘으로 객체를 검지하는 레이더 객체 검지부; 상기 레이더 객체 검지부에서 객체 검출 시 인공지능 분석부에 영상 분석을 요청하고, 상기 인공지능 분석부를 통해 전달되는 영상 분석 결과를 수신하는 서버 통신 모듈; 상기 레이더 객체 검지부를 통해 검지된 객체 정보의 데이터셋과 상기 서버 통신모듈을 통해 전달되는 영상 정 보의 데이터셋을 매칭시켜 병합하는 데이터 병합부; 상기 데이터 병합부를 통해 생성된 레이더 및 영상 객체 정보를 엣지 플랫폼 서버에 전송하는 엣지 서버 통신부 를 포함하는 것을 특징으로 한다. 상기에서 레이더 객체 검지부는, 수신한 레이더 감지 신호에서 사용자가 지정한 관심 영역(ROI) 외에 검지된 포인트를 제거하여 객체 탐지에 방 해되는 고스트 타깃을 제거하는 포인트 클라우딩 태깅(Point Cloud Tagging) 단계; 상기 포인트 클라우딩 태깅을 통해 전달되는 레이더 검지 데이터로부터 칼만 필터를 이용한 예측 표현식을 이용 하여 위치, 속도 및 가속도를 추정하는 예측(Predict) 단계; 객체 주위의 게이트를 생성하여 상기 추정된 위치, 속도 및 가속도 추정치에 대하여 개별적인 평가를 통해 평가 점수가 가장 높은 트랙에 포인트를 할당하는 병합(Associate) 단계; 상기 병합 단계를 통해 위치, 속도 및 가속도 추정치가 설정된 임계값 내에 속하는지를 확인하여 추적 인스턴스 를 생성하는 클러스터링(Clustering) 단계; 클러스터링 단계에서 생성된 추적 인스턴스가 트랙에 병합되면 트랙 중심 및 해당 공분산 행렬 추정 값이 새롭 게 병합된 측정값을 기반으로 각 트랙에 대해 업데이트를 수행하는 갱신(Update) 단계; 상기 세트의 포인트 수와 평균 속도가 해당 임계 값을 초과하는지 확인하는 존재유무(Presence) 단계; 이벤트의 수명 주기를 통해 트랙의 상태를 변경하거나 트랙 할당을 해제하는 유지(Maintenance) 단계를 포함할 수 있다. 상기에서 인공지능 분석부는, 인공지능 영상 분석모델을 이용하여 영상 센서로부터 획득한 영상으로부터 객체를 분류하는 영상 객체 분류부; 상기 영상 객체 분류부에서 분류한 객체 정보를 상기 메인 제어부에 전달하는 클라이언트 통신모듈; 수집한 영상 데이터를 학습 데이터로 인공지능 학습서버에 전송하며, 상기 인공지능 학습서버로부터 전송된 인 공지능 영상 분석모델로 상기 영상 객체 분류부의 인공지능 영상 분석모델을 업데이트하는 학습 서버 통신부를 포함하는 것을 특징으로 한다. 상기에서 학습 서버 통신부는, 수집한 영상 데이터에서 프레임 단위로 이미지를 추출하여 학습에 필요한 동적, 정적 객체의 이미지로 제공하는 것을 특징으로 한다. 상기에서 인공지능 학습서버는, 학습 데이터를 수집하는 학습 데이터 수집부; 수집된 영상 이미지를 JPG 형태로 변환하고, 변환된 이미지를 탐지할 객체별로 Object ID를 지정하는 작업을 통 해 객체의 영역을 지정하여 이미지 데이터를 라벨링하고, 라벨링된 이미지 데이터를 XML 형태의 포맷으로 저장 하는 이미지 라벨링 및 어노테이션부; 상기 이미지 라벨링 및 어노테이션부를 통해 제공되는 이미지 데이터를 데이터셋으로 하여 미리 생성된 인공지 능 영상 분석모델을 학습하고, 학습 결과를 기초로 인공지능 영상 분석모델을 최적화하는 모델 생성부를 포함하 는 것을 특징으로 한다."}
{"patent_id": "10-2023-0129822", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 레이더 장비와 카메라 장비에서 수집할 수 있는 데이터셋을 구성하고, 하나의 장비에서 레이 더와 영상의 데이터셋을 매칭하여 표적을 정확하게 인식하도록 하여, 악천후 상황에서도 Level 4 자율주행이 안 전하게 이루어지도록 도모해주는 효과가 있다. 또한, 본 발명에 따르면 하나의 장비에서 레이더와 영상의 데이터셋을 매칭시킴으로써 시스템 구현을 단순화할 수 있는 장점도 있다. 또한, 본 발명에 따르면 레이더를 통해 획득할 수 있는 객체 추적 데이터를 통해 보행자의 이동 특성을 분석하 고, 객체 추적 중 사라지거나 이상 패턴을 보이는 돌발 상황에 대비할 수 있도록 도모해주는 효과도 있다."}
{"patent_id": "10-2023-0129822", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 본 발명의 바람직한 실시 예에 따른 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복 합시스템을 첨부된 도면을 참조하여 상세하게 설명한다. 이하에서 설명되는 본 발명에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정해서 해석되어서는 안 되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념으로 적절하게 정의할 수 있 다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시 예와 도면에 도시된 구성은 본 발명의 바람직한 실시 예에 불과할 뿐이고, 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원 시점에서 이들을 대체할 수 있는 다양한 균등물과 변형 예들이 있을 수 있음을 이해하여야 한다. 도 1은 본 발명의 바람직한 실시 예에 따른 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융 복합시스템의 구성도로서, 레이더, 영상 센서, 레이더-영상 이중화 제어기, 인공지능 학습서버 및 엣지 플랫폼 서버를 포함할 수 있다. 레이더는 레이더 신호를 감지 영역으로 투사하고 감지영역의 객체로부터 반사된 신호를 레이더 검지 데이 터로 레이더-영상 이중화 제어기에 전달해주는 역할을 한다. 다양한 레이더를 이용할 수 있으며, 본 발명에서는 밀리미터 웨이브 레이더를 이용하는 것을 실시 예로 설명한다. 영상 센서는 상기 레이더-영상 이중화 제어기의 제어에 따라 촬영하여 획득한 영상을 상기 레이더-영 상 이중화 제어기로 전송하는 역할을 한다. 이러한 영상 센서는 CCTV, 스테레오 카메라, 비전 센서 등 다양한 영상 장비로 구현할 수 있다. 레이더-영상 이중화 제어기는 상기 레이더로부터 출력되는 레이더 검지 데이터로부터 객체를 검지하 고, 객체 검지시 영상 획득을 제어하며, 획득한 영상으로부터 인공지능 영상 분석모델을 이용하여 객체를 분류 하고, 레이더 검지 데이터의 데이터셋과 영상 데이터의 데이터셋을 매칭시켜 레이더와 영상의 객체를 판단하는 역할을 한다. 이러한 레이더-영상 이중화 제어기는 상기 레이더로부터 출력되는 레이더 검지 데이터로부터 객체를 검지하고, 객체 검지 시 영상 획득을 제어하며, 레이더 검지 데이터의 데이터셋과 영상 데이터의 데이터셋을 매 칭시켜 레이더와 영상의 객체를 판단하는 메인 제어부, 상기 메인 제어부로부터 영상 분석 요청 시 영상 센서를 통해 영상을 획득하고, 획득한 영상으로부터 인공지능 영상 분석모델을 이용하여 객체를 분류 하는 인공지능 분석부를 포함할 수 있다. 상기 메인 제어부는 상기 레이더에서 검출된 객체의 검출 시간 정보를 상기 인공지능 분석부에 제공하고 영상 분석을 요청할 수 있다. 이러한 메인 제어부는 상기 레이더로부터 출력되는 레이더 검지 데이터로부터 객체 분석 알고리즘으 로 객체를 검지하는 레이더 객체 검지부, 상기 레이더 객체 검지부에서 객체 검출 시 인공지능 분석 부에 영상 분석을 요청하고, 상기 인공지능 분석부를 통해 전달되는 영상 분석 결과를 수신하는 서버 통신 모듈, 상기 레이더 객체 검지부를 통해 검지된 객체 정보의 데이터셋과 상기 서버 통신 모듈 을 통해 전달되는 영상 정보의 데이터셋을 매칭시켜 병합하는 데이터 병합부, 상기 데이터 병합부 를 통해 생성된 레이더 및 영상 객체 정보를 엣지 플랫폼 서버에 전송하는 엣지 서버 통신부를포함할 수 있다. 상기 인공지능 분석부는 인공지능 영상 분석모델을 이용하여 영상 센서로부터 획득한 영상으로부터 객체를 분류하는 영상 객체 분류부, 상기 영상 객체 분류부에서 분류한 객체 정보를 상기 메인 제어 부에 전달하는 클라이언트 통신모듈, 수집한 영상 데이터를 학습 데이터로 인공지능 학습서버에 전송하며, 상기 인공지능 학습서버로부터 전송된 인공지능 영상 분석모델로 상기 영상 객체 분류부의 인공지능 영상 분석모델을 업데이트하는 학습 서버 통신부를 포함할 수 있다. 상기 학습 서버 통신부는 수집한 영상 데이터에서 프레임 단위로 이미지를 추출하여 학습에 필요한 동적, 정적 객체의 이미지로 제공할 수 있다. 인공지능 학습서버는 학습용 수집 데이터를 기초로 생성된 모델을 학습하여 학습 모델을 최적화하고, 최적 화한 인공지능 영상 분석모델을 상기 레이더-영상 이중화 제어기에 업데이트하는 역할을 한다. 이러한 인공지능 학습서버는 학습 데이터를 수집하는 학습 데이터 수집부, 수집된 영상 이미지를 JPG 형태로 변환하고, 변환된 이미지를 탐지할 객체별로 Object ID를 지정하는 작업을 통해 객체의 영역을 지정하여 이미지 데이터를 라벨링하고, 라벨링된 이미지 데이터를 XML 형태의 포맷으로 저장하는 이미지 라벨링 및 어노 테이션부, 상기 이미지 라벨링 및 어노테이션부를 통해 제공되는 이미지 데이터를 데이터셋으로 하여 미리 생성된 인공지능 영상 분석모델을 학습하고, 학습 결과를 기초로 인공지능 영상 분석모델을 최적화하는 모 델 생성부, 상기 레이더-영상 이중화 제어기와 통신을 통해 수집 데이터를 수신하고, 인공지능 영상 분석모델을 전송하는 통신모듈을 포함할 수 있다. 엣지 플랫폼 서버는 상기 레이더-영상 이중화 제어기로부터 전송된 레이더 및 영상 분석 결과를 기초 로 객체 인식 데이터를 제공해주는 역할을 한다. 이와 같이 구성된 본 발명의 바람직한 실시 예에 따른 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더 와 영상 융복합시스템의 동작을 첨부한 도면을 참조하여 구체적으로 설명하면 다음과 같다. 먼저, 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템이 동작을 시작하면, 레이더 는 레이더 신호를 감지 영역(사용자가 설정한 영역(ROI)으로 투사하고 감지영역의 객체로부터 반사된 신호 를 레이더 검지 데이터로 레이더-영상 이중화 제어기에 전달한다. 상기 레이더-영상 이중화 제어기는 상기 레이더로부터 출력되는 레이더 검지 데이터로부터 객체를 검 지한다. 예컨대, 메인 제어부의 레이더 객체 검지부에서 상기 레이더로부터 출력되는 레이더 검지 데이 터로부터 객체 분석 알고리즘으로 객체를 검지한다. 레이더 객체 검지부에서 수신한 레이더 검지 데이터(데이터)로부터 객체를 분석하고 군집(클러스터링)할 수 있는 알고리즘으로 DBSCAN(Denisity-Based Spatial Clustering of Applications with Noise)을 사용한다. 레이더 검지 데이터로부터 추출되는 객체 데이터들의 구성은 도 2와 같으며, 상기 레이더 객체 검지부는 상기 DBSCAN 알고리즘으로 이용하여 수신한 레이더 객체 데이터로부터 객체를 분석한다. 여기서 ID는 차량의 고유 순번, x는 레이더 기기 기준 2차원 형태의 좌표에서 차량이 탐지된 X 좌표 위치 값, y 는 레이더 기기 기준 2차원 형태의 좌표에서 차량이 탐지된 Y 좌표 위치 값, v는 레이더 기기 기준 2차원 형태 의 좌표에서 차량이 탐지된 속도 값 등을 나타낸다. 예컨대, 도 3에 도시한 바와 같이, 밀리미터 웨이브 레이더 검지 데이터를 수신하면, 레이더 객체 데이터 구성 으로부터 개별 객체 위치/속도를 분석한다(S101). 이어, 데이터 분류(클러스터링)를 통해 군집 처리를 한다 (S102). 여기서 군집에 속하지 않는 데이터는 노이즈로 처리하고 폐기 처리를 한다(S103). DBSCAN은 밀도 기반의 클러스터링 기법으로 점이 세밀하게 몰려 있어서 밀도가 높은 부분을 클러스터링하는 방 식이며, 어느 점을 기준으로 반경 e 내에 점이 n 개 이상 있으면 하나의 군집으로 인식하는 방식으로 점을 중심 으로 epsilon 반경 내에 minPts 이상수의 점이 있으면 그 점을 중심으로 군집이 되고, 그 점을 core point라고 하며, Core point가 서로 다른 core point 군집의 일부가 되면 그 군집을 서로 연결되어 있다고 하고 하나의 군 집으로 연결을 한다. 군집에는 속하지만, 스스로 core point가 안 되는 점을 border point라고 하고, 주로 클러 스터의 외곽을 이루는 점이 되며, 어느 클러스터에도 속하지 않는 점은 Noise point으로 처리한다.DBSCAN 알고리즘을 사용하는 이유는 크게 3가지로, 1) 클러스터의 수를 정하지 않아도 되기 때문에 군집의 수를 정하지 않아도 밀도 중심으로 군집을 나누어 클러스터링하며, 다른 클러스터링 알고리즘과 다르게 군집의 수를 미리 지정하지 않는다. 2) 레이더의 객체 검지 데이터 중 난반사 등 장애물에 의한 노이즈가 발생하는 경우가 있으며, 이러한 경우 노이즈에 ID 값이 부여되어 고스트 차량이 발생할 수 있기에 일부 노이즈 제거가 가능하고, 레이더에서 검지된 신호를 객체로 인식하는 과정에 검지된 포인트 반경 n개 이상의 데이터를 검지하 며, 노이즈의 경우 검지된 포인트의 수가 적어 군집화되지 못하여 노이즈는 제거된다. 3) 다른 클러스터링 알고 리즘들에 비해 처리 속도가 빠른 장점이 있다. 상기와 같이 군집화된 데이터를 정렬한 후, 군집화된 데이터를 처리한다(S104 - S105). 이어, 레이더 검지 데이터가 입력된 시간을 기준으로 객체 추적 한계 시간의 초과 유무를 확인하여, 한계시간이 초과된 데이터를 데이터 리스트에서 제거하고, 추적 한계시간 이내의 데이터만 레이더 객체 리스트로 생성하여 예상 위치를 추정한다(S106 - S108). 예상 위치를 추정한 결과 데이터와 이미 군집화된 데이터를 비교하여 결과 데이터가 군집화된 데이터와 유사한 지를 확인하여 결과 데이터가 군집화된 데이터와 유사하지 않을 경우, 리스트에서 새로운 ID를 부여하여 객체 정보로 추가하며, 군집화된 데이터와 유사한 데이터가 존재하면 레이더 객체 리스트의 데이터를 갱신하고, 이를 화면에 출력한다(S109 - S111). 이렇게 생성되는 객체 정보가 데이터 병합부에 전달됨과 동시에 서버 통신 모듈로 전달된다. 도 4는 상기와 같은 객체 분석 알고리즘의 모듈별 시나리오 예시이다. 상기 레이더 객체 검지부는 수신한 레이더 감지 신호에서 사용자가 지정한 관심 영역(ROI) 외에 검지된 포 인트를 제거하여 객체 탐지에 방해되는 고스트 타깃을 제거하는 포인트 클라우딩 태깅(Point Cloud Tagging)을 수행한다. 즉, 사용자가 지정한 관심 영역(ROI)을 벗어나는 탐지된 점(Point)은 적절하게 태깅한 다음, 다음 단계 프로세 싱을 위해 무시하며, 이와 같은 사용자 지정 Boundary는 관심 영역을 정의하고 일반적으로 ROI 영역 크기를 설 정한다. 이렇게 지정한 영역 외에 검지된 포인트를 무시하면 객체 탐지에 방해가 되는 Ghost 타깃을 제거하는 데 도움이 되며, 레이더 Low level processing 단계에서 처리되어 시리얼 포트 또는 이더넷 포트로 전송된다. 다음으로, 포인트 클라우딩 태깅을 통해 전달되는 레이더 검지 데이터로부터 칼만 필터를 이용한 예측 표현식을 이용하여 위치, 속도 및 가속도를 추정하는 예측(Predict)을 수행한다. 즉, 칼만 필터를 이용한 예측 표현식을 이용하며, 예측에 대한 입력은 좌표의 위치, 속도 및 가속도(즉, 상태 벡터)와 추적된 개체의 해당 상태 공분산 행렬이며, 예측 표현식을 기반으로 새로운 위치, 속도 및 가속도(즉, 선험적 상태 벡터) 및 공분산 행렬이 각 대상에 대해 추정된다. 다음으로, 객체 주위의 게이트를 생성하여 상기 추정된 위치, 속도 및 가속도 추정치에 대하여 개별적인 평가를 통해 평가점수가 가장 높은 트랙에 포인트를 할당하는 병합(Associate) 과정을 수행한다. 즉, 각 객체 주위에 게이트가 생성되고, Mahalanobis Distance(어떤 값이 얼마나 발생하기 힘든 값인지, 또는 얼마나 이상한 값인지를 수치화하는 한 방법, 평균과의 거리가 표준편차의 몇 배인지를 나타내는 값)는 각 측정 지점과 각 대상/트랙 사이에서 계산되어 포인트가 트랙의 게이트 내에 있으면 평가점수가 할당된다. 각 포인트 는 게이트에 적합한 각 트랙에 대한 점수가 부여되며, 마지막으로 평가점수가 가장 높은 트랙에 포인트가 할당 되고, 각 포인트는 단일 트랙에만 연결된다. 다음으로, 병합 단계를 통해 위치, 속도 및 가속도 추정치가 설정된 임계값 내에 속하는지를 확인하여 추적 인 스턴스를 생성하는 클러스터링(Clustering) 과정을 수행한다. 즉, 병합 과정에서 기존 트랙과 연결되지 않은 모든 포인트는 할당 단계를 거치게 되고, 기능적으로 할당은 클 러스터링과 유사하며, 할당 단계에서 임의의 측정 지점이 먼저 선행 측정으로 선택되고 클러스터/후보 집합의 초기화에 사용되어 각 측정이 클러스터의 사용자 구성 가능한 속도 및 거리 임계값 내에 속하는지 확인한다. 측 정이 테스트를 통과하면 클러스터에 추가되고 객체 중심이 다시 계산된다. 모든 측정 포인트에 대해 이 작업이 완료되면 클러스터에 대해 몇 가지 추가 자격 기준이 확인된다. 이러한 테스트에는 클러스터가 최소 포인트 수 를 초과하는지, 평균 속도가 속도 임계값을 초과하는지, 클러스터의 포인트가 결합된 SNR(Signal-to-Noise Ratio)이 충분히 큰 값인지 확인하며, 이와 같은 SNR 기준을 통과하면 새로운 추적 인스턴스가 생성되고 클러스터의 관련 포인트가 추적기를 초기화하는 데 사용되어 최소 기준을 통과하지 못한 클러스터는 무시된다. 다음으로, 클러스터링 단계에서 생성된 추적 인스턴스가 트랙에 병합되면 트랙 중심 및 해당 공분산 행렬 추정 값이 새롭게 병합된 측정값을 기반으로 각 트랙에 대해 업데이트를 수행하는 갱신(Update) 과정을 수행한다. 즉, 새 측정값이 트랙에 병합되면 트랙 중심 및 해당 공분산 행렬 추정 값이 새롭게 병합된 측정값을 기반으로 각 트랙에 대해 업데이트한다. 또한, 이 단계에서 그룹 트랙 분산 행렬과 그룹 공분산 행렬도 같이 계산된다. 그룹 공분산 행렬은 이후 병합 단계에서 사용되어 각 트랙 주위에 게이트를 형성한다. 다음으로, 세트의 포인트 수와 평균 속도가 해당 임계 값을 초과하는지 확인하는 존재 유무(Presence) 과정을 수행한다. 즉, 객체 존재 유무 감지는 점유 영역 내에 대상이 있는지 확인하는 단계로 초기 탐지와 해당 지점에서 알고 있 는 표적을 결합하며, 초기 감지 표시의 경우 할당(Clustering) 프로세스에서 생성된 후보 세트를 재사용하고, 점유 임계 값, 즉 세트의 포인트 수와 평균 속도가 해당 임계 값을 초과하는지 확인한다. 마지막으로, 이벤트의 수명 주기를 통해 트랙의 상태를 변경하거나 트랙 할당을 해제하는 유지(Maintenance) 과 정을 수행한다. 즉, 각 트랙은 이벤트의 수명 주기를 통해 전환되어 트랙이 DETECT, ACTIVE 또는 FREE 상태일 때 유지 관리 단 계에서 트랙의 상태가 변경되거나 트랙 할당이 해제된다. 상기와 같이 레이더 객체 검지부에 의해 객체가 감지되면 서버 통신 모듈은 인공지능 분석부에 영상 분석을 요청한다. 예컨대, 인공지능 분석부는 영상 분석이 요청되면, 영상 객체 분류부에서 영상 센서를 통해 영 상을 획득하도록 하고, 획득한 영상으로부터 인공지능 영상 분석모델을 이용하여 객체를 분류한다. 여기서 레이더-영상 이중화 제어기와 엣지 플랫폼 서버는 TCP/IP 프로토콜로 통신하며, Closed API로 연동한다. 아울러 레이더-영상 이중화 제어기와 영상 센서 간의 통신은 TCP/IP 방식의 패킷 통신을 하며, 레이더-영상 이중화 제어기는 서버 모드(server mode)로 동작하고, 영상 센서는 클라이언트 모 드(Client mode)로 동작한다. 레이더-영상 이중화 제어기와 영상 센서 구조에서 레이더-영상 이중화 제어기는 레이더에서 검 출된 객체의 정보(검출시간)전송하고, Passive 영상 센서는 영상에서 객체 위치 중심(화면중심)에서 식별된 정 보를 전송하며, Scheduling 영상센서는 자체 카메라 위치 순환 중 검출된 객체의 정보를 전송하며, 전체적인 레 이더-영상 이중화 제어기와 영상 센서 간의 통신 흐름은 도 5와 같다. 프로토콜의 패킷에서 전송되는 메시지 프레임은 고정 길이를 가지는 헤더 부와 헤더 내의 명령어 코드에 따라 가변길이를 가지는 데이터부, 고정 길이를 가지는 종료부로 구성되고, 모든 패킷에 걸쳐 바이트 정렬은(Network Ordering: Little-Endian)을 따라야 하며, 패킷을 구성하는 각 필드들에 대한 데이터형과 그 길이를 표시함에 따른 표기법은 도 6과 같이 정의한다. 또한, 정수형 숫자로 표시되는 것이 일반적이며, 가변길이를 표현할 경우 에는 [N]으로 타입코드를 표기하고, N 바이트 길이를 자니는 필드로 정리한다. 레이더-영상 이중화 제어기와 영상센서 간의 명령 코드별 DATA 필드 패킷 구성은 제어기 시스템 정보 전송 및 시간 동기화 요청을 통해 수행되며, 레이더-영상 이중화 제어기와 영상센서의 시간을 동기화 하고 시스템 설정 정보를 송/수신하는 명령어는 Connect 후 첫 번째로 송/수신(임의의 시점에서도 가능)한다. 수신된 ID 들을 가지고 송/수신에 활용한다. 레이더와 카메라를 융합한 레이더-영상 이중화 제어기에서 레 이더의 데이터가 전송되고, PTZ 카메라(영상 센서)에서 검지 영역을 설정하며, 이벤트가 발생하는 등 전체적인 시나리오 흐름은 도 7과 같다. 예컨대, 레이더 정보 및 차선 정보 등에 대한 시스템 설정 값을 로딩하고(S201), 주기적으로(50ms) 레이더 검지 데이터를 수신하여 객체가 검지되지 않으면 설정값을 재입력한다(S202 - S203). 이와는 달리 레이더 검지 데이터 검지를 통해 객체가 검출되면, 검출된 객체로부터 객체 위치 정보를 취득하고, 객체 위치와 설정된 차선의 위치 값을 비교하여 객체 위치가 설정된 차선의 위치와 동일하면, 객체 최소 이동거 리를 산출한다(S204 - S206). 즉, 객체 이동거리가 최소 이동거리 설정 값보다 크면 객체 최소 이동거리 값을 출력한다. 아울러 상기 검출된 객체로부터 객체 크기 정보를 취득하고, 객체 속도 정보를 취득한다(S207 - S208). 이어 취득한 객체 속도 정보를 기초로 객체 속도의 변화를 확인한다(S209). 여기서 객체의 속도 변화 확인은 객체 속도변화와 이미 설정된 최대 속도변화 설정 값을 비교하는 방법으로 확인할 수 있다. 이어, 상기 객 체 최소 이동거리와 객체 크기 정보 및 객체 속도 정보 및 객체 속도 변환 정보를 객체(교통)정보로 등록한다 (S210). 이와 같이 레이더를 이용하여 객체 정보가 검출되면, 상황별 이벤트를 판단하고(S211), Exception Zone 구간을 확인하여, Exception Zone 설정 구간이면 관심 영역인지를 확인한다(S212 - S213). 이 확인 결과 관심 영역의 이벤트이면 위험상황 이벤트를 생성하고, 위험상황 이벤트 CCTV 녹화를 처리하여 이벤트에 대응하도록 하며, 이벤트 생성 정보를 엣지 플랫폼 서버에 전송한다(S214 - S217). 한편, 영상 획득 요청을 수신한 영상 센서는 촬영을 통해 영상을 획득하고, 획득한 영상을 상기 레이더-영 상 이중화 제어기의 영상 객체 분류부에 전달한다. 상기 인공지능 분석부의 영상 객체 분류부는 분석 모델인 인공지능 영상 분석모델(딥러닝 학습 모 델)을 이용하여 영상 센서로부터 획득한 영상으로부터 객체를 분류한다. 영상으로부터 객체를 분류하는 인공지능 영상 분석모델은 인공지능 학습서버를 통해 업데이트된다. 상기 인공지능 학습서버는 학습용 수집 데이터를 기초로 생성된 모델을 학습하여 학습 모델(인공지능 영상 분석모델)을 최적화하고, 최적화한 인공지능 영상 분석모델을 상기 레이더-영상 이중화 제어기에 업데이트 한다. 예컨대, 인공지능 학습서버는 학습 데이터 수집부에서 학습 데이터(영상 이미지)를 수집하여 상기 라 벨링 및 어노테이션부에 전달한다. 학습 데이터는 영상 이미지에서 프레임 단위로 추출되는 이미지로서, 학습에 필요한 동적, 정적 객체의 이미지 일 수 있다. 즉, Python 프로그래밍 언어 기반 영상 처리 라이브러리 중 OpenCV를 활용하여 수집된 영상 데이터 에서 프레임(Default: 30fps) 단위로 추출된 영상 이미지일 수 있다. 상기 라벨링 및 어노테이션부는 수집된 영상 이미지를 JPG 형태로 변환하고, 변환된 이미지를 탐지할 객체 별로 Object ID를 지정하는 작업을 통해 객체의 영역을 지정하여 이미지 데이터를 라벨링하고, 라벨링된 이미지 데이터를 XML 형태의 포맷으로 저장한다. 여기서 이미지 라벨링 도구로 Object Detection 학습을 위해 영상에서 Bounding Box를 지정하여 라벨링을 수행 하고, Bounding Box 정보들을 XML 형태의 포맷으로 저장한다. Python 및 Pyqt 기반의 프로그램을 이용할 수 있 다. 어노테이션 파일 저장 방식은 Object Detection Dataset 중 하나인 PASCAL VOC 포맷을 사용할 수 있다. XML 파일 안에는 수많은 태그(Tag) 들이 존재하지만, Object Detection 모델을 학습하기 위해 사용되는 태그들 은 정해져 있다. 모델 생성부는 상기 이미지 라벨링 및 어노테이션부를 통해 제공되는 이미지 데이터를 데이터셋으로 하여 미리 생성된 인공지능 영상 분석모델을 학습하고, 학습 결과를 기초로 인공지능 영상 분석모델을 최적화한 다. 이렇게 최적화된 인공지능 영상 분석모델은 통신모듈을 통해 상기 레이더-영상 이중화 제어기로 전송 된다. 상기 영상 객체 분류부에서 상기 최적화된 인공지능 영상 분석모델을 통해 영상으로부터 객체를 분석한 영 상 분석 결과(영상 데이터셋)는 클라이언트 통신모듈을 통해 메인 제어부에 전달된다. 상기 메인 제어부의 서버 통신 모듈은 수신한 영상 분석 결과를 데이터 병합부에 전달한다. 상기 데이터 병합부는 상기 레이더 객체 검지부를 통해 검지된 객체 정보의 데이터셋과 상기 서버 통 신 모듈을 통해 전달되는 영상 정보의 데이터셋을 매칭시켜 레이더와 영상의 객체를 정확하게 판단한다. 즉, 양자의 데이터셋의 오차를 계산하여 동일한 표적으로 인식한다. 엣지 서버 통신부는 상기 데이터 병합부를 통해 생성된 레이더 및 영상 객체 정보를 엣지 플랫폼 서 버에 전송한다. 엣지 플랫폼 서버는 상기 레이더-영상 이중화 제어기로부터 전송된 레이더 및 영상 분석 결과를 기초 로 객체 인식 데이터를 제공해준다. 레이더와 영상 센서를 융합한 레이더-영상 이중화 제어기의 객체 정보 리스트가 에지 플랫폼 서버로 전송될 때 검지 영역이 단일 레이더 검지 영역을 초과하는 경우는 레이더 네트워크(Radar Network)를 통해 구성된다. Radar Network는 복수의 레이더 간 시간 동기를 조정하는 제어기(NPTMaster)로 구성되는 네트워크로 다수 의 레이더가 동일한 타이밍으로 동작, 검지 영역 내의 객체를 연속적으로 추적한다. 통합 감지 알고리즘이 적용 되어 검지 영역을 통합한 가상 맵을 구성하여 객체 위치를 매핑하고, 최대/최소 검지 거리(음영 지역) 고려하여 레이더 설치 높이를 결정하며, NTP Master-Slave 통신은 유선 이더넷을 통해 구성된다. Radar Network로 검지 영역을 구성할 때 시간 동기되는 모습과 전체적인 구조 모습은 도 8과 같다. 딥러닝 기반 영상 처리를 통한 교통 객체 분류 및 인지 최적화를 위하여 자율주행 관련 AI 영상데이터 수집이 필요하며, 이를 활용하여 1차적으로 AI 학습모델을 구현하고 지속적으로 현장시험을 통하여 실제 영상을 수집하 고, 실제 도로 환경/상황 및 악천후 기후에도 영상 객체 분류/인식 정확도를 점진적으로 개선할 수 있다. 본 발명자는 본 발명에 의해 제안된 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스 템의 성능을 평가하였다. 도 9는 본 발명에 의해 제안된 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템의 성능 평가를 위한 테스트 계획이다. 아울러 성능 테스트를 위해 구현된 밀리미터 웨이브 레이더 객체 검지 프로그램의 사용자 인터페이스(UI)는 도 10과 같다. 도 10의 설명은 소괄호를 이용하여 그림 내에 표현된 파란색 박스에 맞춰 설명한다. ① Radar 연결은 장치 관리 자에서 확인한 포트 번호에 맞춰 설정하는 부분으로 Data Port(Standard COM Port), CFG Port(Enhanced COM Port)로 구성되어 있다. ② 섹션 탐색 데이터 출력 및 설정은 박스 안에 설정된 범위 안의 객체가 있는지 확인 하고, 설정 범위 변경은 [min ~ max]의 형식으로 작성 후 버튼을 설정할 수 있다. ③ 분석 데이터 출력 화면의 차선 변경은 왼쪽부터 최대 4개의 차선을 설정할 수 있고, 그려진 차선 일부를 선택하여 Remove 버튼을 눌러 제 거할 수 있으며, 선택된 차선의 라인을 추가는 Add 버튼을 누른 후 분석 데이터 화면 위에 마우스로 시작점과 끝점을 클릭할 수 있다. ④ 검지 된 차량 수 측정은 레이더에서 검지된 차량의 개수를 실시간을 표현하는 화면 이다. ⑤ 레이더가 검지한 데이터의 원본을 출력하는 화면이며, ⑥ 검지 된 데이터를 가공한 후 출력하는 화면 이다. ⑦ 카메라 연결로 연결 가능한 카메라 주소(RTSP 주소)를 작성하며 시작 버튼을 누를 수 있으며, ⑧ 연결 된 카메라의 영상이 출력되는 화면이고, ⑨ 검지 된 객체의 정보가 표시되는 표이다. 구현된 밀리미터 웨이브 레이더 객체 검지 프로그램을 통해 테스트한 결과는 도11a 및 도 11b와 같다. 도 11a는 강우 상황에서 테스트한 레이더의 결과이고, 도 11b는 안개 상황에서 테스트한 레이더의 결과이다. 양 호한 기상 상황과 짙은 안개 속에서는 일반적인 레이더 성능과 같이 최고 범위까지 차량의 검지가 가능하다는 것을 확인하였고, 짙은 안개(시계 5미터)는 밀리미터 웨이브 레이더에 큰 영향이 없다는 사실을 확인했다. 강우 속에서는 일반적인 상황보다 검지 범위가 절반으로 줄어든다는 것을 확인하였으며, 악천후 속에서 레이더 검지 성능 향상을 위해 CFAR 파라미터 튜닝이 필요한 결과를 인지했다. 밀리미터 웨이브 레이더의 거리 및 속도 정확도를 시험한 결과는 도 12와 같다. 거리 정확도 시험은 거리 측정기를 사용하여 10m 간격으로 라바콘을 설치하여 비교하였고, 공인인증을 취득한 SMS사 레이더(SMS-45T)로 측정한 값과 비교했다. 속도 정확도 시험은 스피드건으로 측정한 값과 비교하며, 공인 인증을 취득한 SMS사 레이더(SMS-45T)로 측정한 값과 비교했다. 정확도 계산 공식은 다음 [수학식 1]과 같다. 수학식 1"}
{"patent_id": "10-2023-0129822", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 변수 a는 밀리미터 웨이브 레이더가 탐지한 거리와 속도 값이며, b는 SMS사 레이더가 탐지한 거리 및 속도이며, n은 정확도 측정을 위해 수행한 전체 횟수를 의미한다. 위의 [수학식 1] 에서 실제 차량 대수와 거리 는 카메라 영상을 사용하여 테스트를 진행하였고, 차량을 대상으로 100회 실시하여 정확도를 평가했다. 평가 결 과 인증 레이더 SMS-T45 대비 전체 거리 정확도는 92.26%, 전체 속도 정확도는 97.75%를 달성했다. 딥러닝 기반 레이더와 영상 이중화 센싱 파일럿 시스템 테스트는 SOC 실증 센터에서 진행되었으며, 테스트 시험 구성도는 도 13과 같다. 악천후(강우, 안개) 날씨 환경에서 객체 검지 및 객체 분류 정확도 시험을 시행하였으 며, 시험 결과로 1차 시험에서는 레이더 연동 및 CCTV 제어 성능 확인, 관련 소프트웨어 검증 및 추가 개선 필요 확인했다. 도 14는 이중화 센싱 파일럿 시스템에 사용된 소프트웨어의 초기 모습을 보인 것이다. 도 15a 및 도 15b는 2차 시험을 통해 수행된 이중화 제어기 소프트웨어의 개선된 모습을 보여준다. 시험 방법은 CCTV 영상 추적(Preset) 거리 설정 수정 및 세밀화 테스트를 수행하고, CCTV Zoom In/Out에 따른 객체 분류 오 검지 발생(객체 크기)을 확인했다. 시험 결과로는 레이더, 이중화 제어기(AI 분석 모듈) 간의 통신 확인 및 이 벤트 정보 수집 및 표출 확인했으며, 이중화 시스템 영상 분석 시 필요기능을 정의하고, CCTV Preset별 ROI 영 역 설정, 레이더 객체 정보와 영상 ROI 간의 데이터 맵핑과 같은 개선사항을 인지했다. 도 16은 3차 시험을 수행한 필드 테스트 구성 모습을 보여주고, 도 17은 엣지 플랫폼까지의 통신 시간(성능) 테 스트를 수행한 결과를 보여주며, 도 18a 및 도 18b는 레이더와 실영상 이중화 제어기 간 수정된 프로토콜을 적 용하여 통신이 되는지 확인한 모습을 보여준다. 엣지 플랫폼까지의 통신 테스트 결과는 전송시간에서 11ms를 기록했고, 통신 데이터 신뢰도는 100%를 기록하여 무리 없이 통신 가능한 결과를 이루어 냈다. 또한, 레이더와 실영상 이중화 제어기에서 수정이 필요한 프로토콜 에 대해서는 수정된 프로토콜을 적용하여 테스트를 수행하여 엣지 플랫폼 통신과 동일하게 무리 없이 통신 가능 하다는 결과를 확인했다. 이상 상술한 본 발명에 따르면, 개선된 밀리미터 웨이브 레이더는 악천후 상황(강우, 안개)에서 정상적으로 보 행자를 탐지하는 결과를 이루어 냈고, 전체 거리정확도는 92.26%, 전체 속도 정확도는 97.75%를 달성했다. 또한, 구현된 레이더와 실영상 이중화 센싱 파일럿 시스템은 총 3번의 실험을 수행했으며, 실험을 점차 수행하 면서 필요한 소프트웨어의 특정 기능 및 통신 프로토콜의 수정이 필요한 개선사항을 도출했다. 마지막 시험에서 는 이를 전부 적용하여 엣지 플랫폼까지 전송 시간을 11ms를 기록하며, 통신 데이터 신뢰도는 100%를 기록하여 통신 상태에 대한 검증을 마치게 되었다. 이상 본 발명자에 의해서 이루어진 발명을 상기 실시 예에 따라 구체적으로 설명하였지만, 본 발명은 상기 실시"}
{"patent_id": "10-2023-0129822", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "예에 한정되는 것은 아니고 그 요지를 이탈하지 않는 범위에서 여러 가지로 변경 가능한 것은 이 기술분야에서 통상의 지식을 가진 자에게 자명하다."}
{"patent_id": "10-2023-0129822", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 악천후 조건에서 자율주행을 위한 인공지능 기반 레이더와 영상 융복합시스템의 구성도 이고, 도 2는 도 1의 레이더 객체 데이터 구성도이고, 도 3은 본 발명에서 레이더 검지 데이터로부터 객체를 탐색하는 알고리즘 흐름도이고, 도 4는 본 발명에서 레이더 검지 데이터로부터 객체를 탐색하는 시나리오 구성도이며, 도 5는 본 발명에서 레이더-영상 이중화 제어기와 영상 센서 간의 통신 프로토콜이며, 도 6은 본 발명에서 통신 프로토콜의 패킷에서 사용되는 필드 타입 종류 예시표이며, 도 7은 본 발명에서 레이더-영상 이중화 제어기의 데이터 전송 흐름도이며, 도 8은 본 발명에서 레이더 네트워크로 구성된 검지 영역 예시이며, 도 9는 본 발명에서 성능평가를 위한 테스트 계획표이며, 도 10은 본 발명에 적용되는 밀리미터 웨이브 레이더 객체 검지 프로그램의 유저 인터페이스이며,도 11a 및 도 11b는 본 발명에서 밀리미터 웨이브 레이더 날씨 환경 테스트 결과 예시이며, 도 12는 본 발명에서 밀리미터 웨이브 레이더 거리 및 속도 테스트 결과이며, 도 13은 이중화 센싱 파일럿 시스템 테스트 구성도이며, 도 14는 이중화 제어기 소프트웨어의 초기 모습 예시이며, 도 15a 및 도 15b는 레이더의 실영상 연동을 통한 인공지능 기반 객체 인식 결과이며, 도 16은 필드 테스트 구성 예시이며, 도 17은 데이터 전송시간(성능) 테스트 결과이며, 도 18a 및 도 15b는 객체 ID 및 속도 프로토콜 수정 및 테스트 결과이다."}
