{"patent_id": "10-2022-0118520", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0039770", "출원번호": "10-2022-0118520", "발명의 명칭": "전이 학습을 이용한 영상 처리 방법 및 사전 학습 서버", "출원인": "한국전자기술연구원", "발명자": "신사임"}}
{"patent_id": "10-2022-0118520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치에 의해 수행되는 영상 처리 방법에 있어서, 외부 장치로부터 영상을 수집하는 단계;상기 영상으로부터 2차원 또는 3차원 스켈레톤 정보를 추출한 전처리 데이터를 생성하는 단계;상기 전처리 데이터로부터 객체의 몸체로부터 복수의 관절로의 어텐션, 상기 복수의 관절 각각으로부터 상기 몸체로의 어텐션, 및 사람과 사람 간의 어텐션을 적용하여 N개의 트랜스포머 블록을 포함하는 제1 인공지능 모델을 사전 학습시키는 단계; 및상기 제1 인공지능 모델의 사전 학습 결과로 결정된 파라미터들이 전이되면, 상기 파라미터들이 기초하여 상기N개의 트랜스포머 블록을 포함하는 제2 인공지능 모델로 상기 외부 장치로부터 수신한 영상으로부터 액션을 인식하는 방법을 학습하는 단계;를 포함하고, 상기 N은 2 이상의 자연수인,영상 처리 방법."}
{"patent_id": "10-2022-0118520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 인공지능 모델을 사전 학습시키는 단계는, 상기 N개의 트랜스포머 블록 중 n번째 트랜스포머 블록이, 이전 블록의 출력의 각 프레임에 대응하는 포지셔널임베딩 텐서의 슬라이스를 적용하고 제1 계층 정규화하는 단계;상기 n번째 트랜스포머 블록이, 상기 제1 계층 정규화한 결과에 공간적 멀티헤드 어텐션(MHA, MultiHeadAttention)을 적용하는 단계; 및상기 n번째 트랜스포머 블록이, 상기 공간적 MHA를 적용한 결과에 상기 이전 블록의 출력의 각 프레임에 대응하는 포지셔널 임베딩 텐서의 슬라이스를 적용한 것을 더하여 제1 결과를 도출하는 단계를 포함하고, 상기 n은 2 이상, N 이하의 자연수인,영상 처리 방법."}
{"patent_id": "10-2022-0118520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,각 프레임에 응하는 상기 제1 결과가 적층된 포즈 시퀀스 행렬에 상기 포지셔널 임베딩 텐서의 차원이 변경된행렬을 적용하고 제2 계층 정규화 하는 단계;상기 제2 계층 정규화한 결과에 시간적 MHA를 적용하는 단계; 및상기 시간적 MHA를 적용한 결과에 상기 포즈 시퀀스 행렬에 상기 포지셔널 임베딩 텐서의 차원이 변경된 행렬을적용한 것을 더하여 제2 결과를 도출하는 단계공개특허 10-2024-0039770-3-를 더 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-0118520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제2 결과를 제3 계층 정규화하는 단계;상기 제3 계층 정규화한 결과에 다중 퍼셉트론(MLP, Multi-Layer Perceptron)을 적용하는 단계; 및상기 MLP를 적용한 결과에 상기 제2 결과를 더하여 제3 결과를 도출하는 단계를 더 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-0118520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 N개의 트랜스포머 블록 중 N번째 블록이, 상기 영상에 따른 입력 모션 시퀀스에 대한 모션 시퀀스 표현을도출하는 단계를 더 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-0118520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "프로세서;메모리; 및상기 메모리에 로드 되고, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 포함하되,상기 컴퓨터 프로그램은, 외부 장치로부터 영상을 수집하는 명령어;상기 영상으로부터 2차원 또는 3차원 스켈레톤 정보를 추출한 전처리 데이터를 생성하는 명령어;상기 전처리 데이터로부터 객체의 몸체로부터 복수의 관절로의 어텐션, 상기 복수의 관절 각각으로부터 상기 몸체로의 어텐션, 및 사람과 사람 간의 어텐션을 적용하여 N개의 트랜스포머 블록을 포함하는 제1 인공지능 모델을 사전 학습시키는 명령어; 및상기 제1 인공지능 모델의 사전 학습 결과로 결정된 파라미터들이 전이되면, 상기 파라미터들이 기초하여 상기N개의 트랜스포머 블록을 포함하는 제2 인공지능 모델로 상기 외부 장치로부터 수신한 영상으로부터 액션을 인식하는 방법을 학습하는 명령어를 포함하고, 상기 N은 2 이상의 자연수인,사전 학습 서버."}
{"patent_id": "10-2022-0118520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2024-0039770-4-프로그램 코드를 저장하는 메모리에 결합된 프로세서를 포함하는 서버에 있어서,상기 프로세서는, 레이블이 지정되지 않은 입력 모션 시퀀스를 사용하여 인공지능 모델을 비지도 학습시키고, 상기 인공지능 모델은, 객체의 몸체로부터 복수의 관절로의 어텐션, 상기 복수의 관절 각각으로부터 상기 몸체로의 어텐션, 및 사람과사람 간의 어텐션을 적용하는 N개의 트랜스포머 블록을 포함하며, 상기 N개의 트랜스포머 블록 각각은, 각 프레임 내에서 객체의 관절 간 정보, 관절-바디 간 정보, 바디-바디간 정보를 융합하고, 융합한 공간적 종속성을 어텐션 연산에 의해 학습하는 공간적 MHA 모듈; 및상기 공간적 MHA 모듈에 의해 집계된 포즈 특징을 이용하여 시퀀스 전반에 걸친 시간적 종속성을 어텐션 연산에의해 학습하는 시간적 MHA 모듈을 포함하며, 상기 N은 2 이상의 자연수인,사전 학습 서버."}
{"patent_id": "10-2022-0118520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 N개의 트랜스포머 블록 중 n번째 트랜스포머 블록 각각은, 이전 블록의 출력의 각 프레임에 대응하는 포지셔널 임베딩 텐서의 슬라이스를 적용한 결과를 제1 계층 정규화하고, 상기 공간적 MHA 모듈은,상기 제1 계층 정규화한 결과에 공간적 MHA를 적용하며, 상기 n은 2 이상, N 이하의 자연수인,사전 학습 서버."}
{"patent_id": "10-2022-0118520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,n번째 트랜스포머 블록 각각은, 공간적 MHA를 적용한 결과에 상기 이전 블록의 출력의 각 프레임에 대응하는 포지셔널 임베딩 텐서의 슬라이스를 적용한 결과를 더하여 제1 결과를 도출하고, 각 프레임에 응하는 상기 제1 결과가 적층된 포즈 시퀀스 행렬에 상기 포지셔널 임베딩 텐서의 차원이 변경된 행렬을 적용하고 제2 계층 정규화하며, 상기 시간적 MHA 모듈은,상기 제2 계층 정규화한 결과에 시간적 MHA를 적용하는,사전 학습 서버."}
{"patent_id": "10-2022-0118520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,공개특허 10-2024-0039770-5-n번째 트랜스포머 블록 각각은, 상기 시간적 MHA를 적용한 결과에 상기 포즈 시퀀스 행렬에 상기 포지셔널 임베딩 텐서의 차원이 변경된 행렬을적용한 것을 더하여 제2 결과를 도출하고, 상기 제2 결과를 제3 계층 정규화하며, 상기 제3 계층 정규화한 결과에 다중 퍼셉트론(MLP, Multi-Layer Perceptron)을 적용하고, 상기 MLP를 적용한 결과에 상기 제2 결과를 더하여 제3 결과를 도출하는, 사전 학습 서버."}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상 처리 방법은, 컴퓨팅 장치에 의해 수행되는 영상 처리 방법에 있어서, 외부 장치로부터 영상을 수집하는 단 계, 상기 영상으로부터 2차원 또는 3차원 스켈레톤 정보를 추출한 전처리 데이터를 생성하는 단계, 상기 전처리 데이터로부터 객체의 몸체로부터 복수의 관절로의 어텐션, 상기 복수의 관절 각각으로부터 상기 몸체로의 어텐션, 및 사람과 사람 간의 어텐션을 적용하여 N개의 트랜스포머 블록을 포함하는 제1 인공지능 모델을 사전 학습시키는 단계, 및 상기 제1 인공지능 모델의 사전 학습 결과로 결정된 파라미터들이 전이되면, 상기 파라미터 들이 기초하여 상기 N개의 트랜스포머 블록을 포함하는 제2 인공지능 모델로 상기 외부 장치로부터 수신한 영상 으로부터 액션을 인식하는 방법을 학습하는 단계를 포함하고, 상기 N은 2 이상의 자연수이다."}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 전이 학습을 이용한 영상 처리 방법 및 사전 학습 서버에 관한 것이다. 보다 구체적으로, 본 발명은 전이 학습을 이용하여 라벨이 없는 영상 데이터를 처리하는 방법 및 그 서버에 관한 것이다."}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기반의 영상 분석 기술에서, 기존에는 각각의 목적에 맞는 모델과 목적 각각에 필요한 다량의 데이터 를 별도로 구축하여 학습하여야 하는 문제가 있었다. 다만, 영상 분석, 탐지, 예측 등 영상 처리 기술은 시각 지능 분야 중 활용도가 가장 높지만, 프라이버시 등의 문제로 인해 다량의 데이터를 확보하는 데 어려움이 있다. 또한 스켈레톤 기반의 동작 인식에 있어서, 지도학습의 비용, 시간 등의 한계를 피하기 위하여 최근에는 사전 학습에 대한 비지도 학습 기술 개발에 집중하고 있다. 선행기술문헌 특허문헌"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 상기와 같은 문제점을 해결하기 위한 것으로, 다양한 목적에 적용할 수 있는 하나의 범용 인 공지능 모델을 제공하는 방법 및 그 장치를 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과 제들은 아래의 기재로부터 본 발명의 기술 분야에서의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위하여 본 발명의 실시예에 따르면, 영상 처리 방법은, 컴퓨팅 장치에 의해 수행 되는 영상 처리 방법에 있어서, 외부 장치로부터 영상을 수집하는 단계, 상기 영상으로부터 2차원 또는 3차원 스켈레톤 정보를 추출한 전처리 데이터를 생성하는 단계, 상기 전처리 데이터로부터 객체의 몸체로부터 복수의 관절로의 어텐션, 상기 복수의 관절 각각으로부터 상기 몸체로의 어텐션, 및 사람과 사람 간의 어텐션을 적용하 여 N개의 트랜스포머 블록을 포함하는 제1 인공지능 모델을 사전 학습시키는 단계, 및 상기 제1 인공지능 모델 의 사전 학습 결과로 결정된 파라미터들이 전이되면, 상기 파라미터들이 기초하여 상기 N개의 트랜스포머 블록 을 포함하는 제2 인공지능 모델로 상기 외부 장치로부터 수신한 영상으로부터 액션을 인식하는 방법을 학습하는 단계를 포함하고, 상기 N은 2 이상의 자연수이다. 상기 제1 인공지능 모델을 사전 학습시키는 단계는, 상기 N개의 트랜스포머 블록 중 n번째 트랜스포머 블록이, 이전 블록의 출력의 각 프레임에 대응하는 포지셔널 임베딩 텐서의 슬라이스를 적용하고 제1 계층 정규화하는 단계, 상기 n번째 트랜스포머 블록이, 상기 제1 계층 정규화한 결과에 공간적 멀티헤드 어텐션(MHA, MultiHead Attention)을 적용하는 단계, 및 상기 n번째 트랜스포머 블록이, 상기 공간적 MHA를 적용한 결과에 상기 이전 블록의 출력의 각 프레임에 대응하는 포지셔널 임베딩 텐서의 슬라이스를 적용한 것을 더하여 제1 결과를 도출 하는 단계를 포함할 수 있고, 상기 n은 2 이상, N 이하의 자연수이다. 각 프레임에 응하는 상기 제1 결과가 적층된 포즈 시퀀스 행렬에 상기 포지셔널 임베딩 텐서의 차원이 변경된 행렬을 적용하고 제2 계층 정규화 하는 단계, 상기 제2 계층 정규화한 결과에 시간적 MHA를 적용하는 단계, 및 상기 시간적 MHA를 적용한 결과에 상기 포즈 시퀀스 행렬에 상기 포지셔널 임베딩 텐서의 차원이 변경된 행렬을 적용한 것을 더하여 제2 결과를 도출하는 단계를 더 포함할 수 있다. 상기 제2 결과를 제3 계층 정규화하는 단계, 상기 제3 계층 정규화한 결과에 다중 퍼셉트론(MLP, Multi-Layer Perceptron)을 적용하는 단계, 및 상기 MLP를 적용한 결과에 상기 제2 결과를 더하여 제3 결과를 도출하는 단계 를 더 포함할 수 있다. 상기 N개의 트랜스포머 블록 중 N번째 블록이, 상기 영상에 따른 입력 모션 시퀀스에 대한 모션 시퀀스 표현을 도출하는 단계를 더 포함할 수 있다. 본 발명의 다른 실시예에 따르면, 사전 학습 서버는, 프로세서, 메모리, 및 상기 메모리에 로드 되고, 상기 프 로세서에 의해 실행되는 컴퓨터 프로그램을 포함하되, 상기 컴퓨터 프로그램은, 외부 장치로부터 영상을 수집하 는 명령어, 상기 영상으로부터 2차원 또는 3차원 스켈레톤 정보를 추출한 전처리 데이터를 생성하는 명령어, 상 기 전처리 데이터로부터 객체의 몸체로부터 복수의 관절로의 어텐션, 상기 복수의 관절 각각으로부터 상기 몸체 로의 어텐션, 및 사람과 사람 간의 어텐션을 적용하여 N개의 트랜스포머 블록을 포함하는 제1 인공지능 모델을 사전 학습시키는 명령어, 및 사전 학습 된 상기 제1 인공지능 모델의 파라미터 및 가중치가 전이되면, 상기 파 라미터 및 가중치를 사용한 제2 인공지능 모델로 상기 외부 장치로부터 수신한 영상으로부터 액션을 인식하는 명령어를 포함하고, 상기 N은 2 이상의 자연수이다. 본 발명의 또 다른 실시예에 따르면, 사전 학습 서버는, 프로그램 코드를 저장하는 메모리에 결합된 프로세서를 포함하는 서버에 있어서, 상기 프로세서는, 레이블이 지정되지 않은 입력 모션 시퀀스를 사용하여 인공지능 모 델을 비지도 학습시키고, 상기 인공지능 모델은, 객체의 몸체로부터 복수의 관절로의 어텐션, 상기 복수의 관절 각각으로부터 상기 몸체로의 어텐션, 및 사람과 사람 간의 어텐션을 적용하는 N개의 트랜스포머 블록을 포함하 며, 상기 N개의 트랜스포머 블록 각각은, 각 프레임 내에서 객체의 관절 간 정보, 관절-바디 간 정보, 바디-바 디간 정보를 융합하고, 융합한 공간적 종속성을 어텐션 연산에 의해 학습하는 공간적 MHA 모듈 및 상기 공간적 MHA 모듈에 의해 집계된 포즈 특징을 이용하여 시퀀스 전반에 걸친 시간적 종속성을 어텐션 연산에 의해 학습하 는 시간적 MHA 모듈을 포함하며, 상기 N은 2 이상의 자연수이다. 상기 N개의 트랜스포머 블록 중 n번째 트랜스포머 블록 각각은, 이전 블록의 출력의 각 프레임에 대응하는 포지 셔널 임베딩 텐서의 슬라이스를 적용한 결과를 제1 계층 정규화하고, 상기 공간적 MHA 모듈은, 상기 제1 계층 정규화한 결과에 공간적 MHA를 적용할 수 있고, 상기 n은 2 이상, N 이하의 자연수이다. n번째 트랜스포머 블록 각각은, 공간적 MHA를 적용한 결과에 상기 이전 블록의 출력의 각 프레임에 대응하는 포 지셔널 임베딩 텐서의 슬라이스를 적용한 결과를 더하여 제1 결과를 도출하고, 각 프레임에 응하는 상기 제1 결 과가 적층된 포즈 시퀀스 행렬에 상기 포지셔널 임베딩 텐서의 차원이 변경된 행렬을 적용하고 제2 계층 정규화 하며, 상기 시간적 MHA 모듈은, 상기 제2 계층 정규화한 결과에 시간적 MHA를 적용할 수 있다. n번째 트랜스포머 블록 각각은, 상기 시간적 MHA를 적용한 결과에 상기 포즈 시퀀스 행렬에 상기 포지셔널 임베 딩 텐서의 차원이 변경된 행렬을 적용한 것을 더하여 제2 결과를 도출하고, 상기 제2 결과를 제3 계층 정규화하 며, 상기 제3 계층 정규화한 결과에 다중 퍼셉트론(MLP, Multi-Layer Perceptron)을 적용하고, 상기 MLP를 적 용한 결과에 상기 제2 결과를 더하여 제3 결과를 도출할 수 있다."}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은, 하나의 범용 모델로 다양한 목적의 분야에 적용할 수 있다. 또한 본 발명은, 하나의 범용 모델을 이용하므로, 소량의 데이터만으로 각 목적에 따른 전이 학습을 할 수 있다."}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 본 발명의 기술 분야에서의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 취지를 벗어나지 않는 한도에서 다양하게 변경하여 실시할 수 있고, 하나 이상의 실시 예를 가질 수"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "있다. 그리고 본 발명에서 “발명을 실시하기 위한 구체적인 내용” 및 “도면” 등에 기재한 실시 예는, 본 발 명을 구체적으로 설명하기 위한 예시이며, 본 발명의 권리 범위를 제한하거나 한정하는 것은 아니다. 따라서, 본 발명이 속하는 기술 분야의 통상의 지식을 가진 자가, 본 발명의 “발명을 실시하기 위한 구체적인 내용” 및 “도면” 등으로부터 용이하게 유추할 수 있는 것은, 본 발명의 범위에 속하는 것으로 해석할 수 있 다. 또한, 도면에 표시한 각 구성 요소들의 크기와 형태는, 실시 예의 설명을 위해 과장되어 표현한 것 일 수 있으 며, 실제로 실시되는 발명의 크기와 형태를 한정하는 것은 아니다. 본 발명의 명세서에서 사용되는 용어를 특별히 정의하지 않는 이상, 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 일반적으로 이해하는 것과 동일한 의미를 가질 수 있다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 명 세에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한 (suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것 만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 부 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 명세의 다양한 실시 예들에 따른 전자 장치는, 적어도 하나의 서버로 구현될 수 있으나, 이는 일 실시 예에 불과할 뿐, 사용자단말 장치 또는 가전 제품으로 구현될 수 있다. 본 개시에 따른 인공지능 모델은, 복수의 신경망 레이어들로 구 성될 수 있다. 각 레이어는 복수의 가중치(weight values)를 갖고 있으며, 이전(previous) 레이어의 연산 결과 와 복수의 가중치의 연산을 통해 레이어의 연산을 수행한다. 신경망의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트 워크 (Deep Q-Networks)이 있으며, 본 개 시에서의 신경망은 명시한 경우를 제외하고 전술한 예에 한정되지 않 는다. 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨대, 로봇)을 훈련시켜 소정의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 방법이다. 학습 알고리즘의 예로는, 지도형 학습 (supervised learning), 비지도형 학습(unsupervised learning), 준 지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으며, 본 개시에서의 학습 알고리즘은 명시한 경우를 제외하고 전 술한 예에 한정되지 않는다 이하, 도면을 참조하여 본 발명의 실시 예를 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 영상 처리 시스템을 도식적으로 도시한 도면이다. 일 실시예에 따른 영상 처리 시스템은, 사전 학습 서버 및 전이 학습 서버를 포함할 수 있다. 사전 학습 서버 및 전이 학습 서버는 통신을 통해 서로 신호를 주고받을 수 있다. 사전 학습 서버는, 외 부 장치로부터 데이터를 송수신할 수 있다. 사전 학습 서버는, 외부 장치로부터 수신한 영상 데이터를 이용하여 인공지능 모델을 학습시킬 수 있다. 일 실시예에 따른 인공지능 모델은, 영상 데이터로부터 객체의 모션(동작) 특성을 추출하는 방법을 할 수 있다. 여기서 사전 학습 모델이 학습하는 것은, 전이 학습 서버가 학습시키는 것과 구분하기 위해 사전 학습(pre- train)이라 한다. 여기서 객체는, 영상 데이터에 포함된 사람, 동물, 물체 등 영상 처리 시스템이 모션 특성 을 처리하고자 하는 대상을 의미한다. 사전 학습 서버는, 사전 학습된 인공지능 모델을, 전이 학습 서버에 전달할 수 있다. 전이 학습 서버 는, 사전 학습된 인공지능 모델을 이용한 모델을 통해 복수의 태스크(tasks) 각각에 적용할 수 있다. 사전 학습 서버는, 스켈레톤 기반으로 객체의 모션을 인식할 수 있다. 인공지능 모델은, 트랜스포머 (Transformer) 기반의 구조를 사용하여 구현될 수 있다. 도 2는 도 1의 사전 학습 서버의 세부 구성을 도식적으로 나타낸 블록도이다. 사전 학습 서버는, 메모리, 프로세서를 포함할 수 있다. 메모리는, 사전 학습 서버의 적어도 하나의 다른 구성요소에 관계된 적어도 하나의 프로그램을 실행하기 위한 명령어(instruction)들 또는 데이터를 저장할 수 있다. 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드 디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모리는 프로세서 에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 본 개시에서 메모리라는 용어는 메모리, 프로세서 내 롬(미도시), 램(미도시) 또는 전자 장치에 장 착되는 메모리 카드(미도 시)(예를 들어, micro SD 카드, 메모리 스틱)를 포함할 수 있다. 특히, 메모리는 인공지능 에이전트를 수행하기 위한 프로그램을 저장할 수 있다. 이때, 인공지능 에이전트는 사전 학습 서버 에 대한 다양한 서비스를 제공하기 위한 개인화된 프로그램이다. 본 개시에 따른 인공 지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 프 로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 프로세서는 메모리에 저장된 명령 어들을 실행할 수 있다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발명의 기술 분야에 잘 알려진 임의의 형 태의 프로세서를 포함하여 구성될 수 있다. 또한, 프로세서는 본 발명의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프로그램에 대한 연산을 수행할 수 있다. 도 2에서는 프로세서를 하나인 것으로 도시하였으나, 발명이 이에 한정되지 않고 프로세서는 복수의 프로세서를 포함할 수 있다. 프로세서는 용어에 한정되지 않고 CPU, AP 등과 같은 범용 프로세서, GPU. VPU 등과 같은 그래픽 전용 프 로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 다수의 학습 데 이터들에 학습 알고리즘을 적용함으로써, 원하는 특성의 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 인공지능 모델의 학습은 본 개 시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 사전 학습 서버는, 외부 장치로부터 영상 데이터를 수집하는 수집부 및 수집부로부터 수신한 영상 데이터를 전처리하는 전처리부를 포함할 수 있다. 통신부는, 전이 학습 서버 및 외부 장치 각각과 통신하여 데이터나 신호를 주고 받을 수 있다. 프로세서는, 레이블이 지정되지 않은 모션 시퀀스를 사용하여 인공지능 모델을 비지도 학습시킬 수 있다. 일 실시예에서는, 글로벌-로컬 어텐션 및 사람(person)-사람(person) 어텐션이 가능한 매커니즘과 이를 이용한 사전 훈련 방법을 제공한다. 프로세서는, 인공지능 모델의 사전 훈련 방법에서, 로컬 및 글로벌 어텐션을 효과적으로 모델링하여 다운 스트림(downstream) 동작 인식 작업에 적합한 입력 모션 시퀀스의 표현을 생성하도록 GL-트랜스포머를 훈련할 수 있다. 프로세서는, 입력 데이터에서 글로벌 병진(global translation)을 분리하고, 두 명의 사람 사이 에 어텐션이 가능하도록 시퀀스를 배치할 수 있다. 전이 학습 서버는, 사전 학습된 인공지능 모델이 전이되면, 사전 학습된 인공지능 모델을 이용하여 다양한 다운스트림 태스크들을 수행할 수 있다. 도 3a 및 도 3b는, 일 실시예에 따른 영상 처리 시스템의 프레임워크를 설명하기 위한 구성도이다. 도 3a은 사 전 학습 서버가 비지도 사전 학습하는 인공지능 모델을 나타내고, 도 3b는 전이 학습 서버가 다운 스트림 태스크에 사용하는 인공지능 모델을 나타낸다. 사전 학습 서버는, 레이블이 지정되지 않은 모션 시퀀스를 사용하여 트랜스포머 기반의 모델인 인공지능 모 델을 사전 훈련한다. 사전 훈련 결과 인공지능 모델은, 액션 인식에 요구되는 적절한 모션 표현을 생 성할 수 있다. GL-트랜스포머에서 출력된 데이터는, 시간 축에서 모션 시퀀스 표현에 대한 평균적인 풀링 이 적용된 이후, 선형 분류기에 전달될 수 있다. 선형 분류기는, GL-트랜스포머의 뒤에 연결 된다. 도 3a를 참조하면, 인공지능 모델은, 글로벌 및 로컬 어텐션을 사용한 트랜스포머(GL-Transformer, Global-Local-Transformer) 모델로 구현될 수 있다. 인공지능 모델은, GL-트랜스포머 계층, 포즈 변위 크기 예측 계층(Pose Displacement Magnitude Prediction Layer), 및 포즈 변위 방향 예측 계층 (Pose Displacement Direction Prediction Layer)을 포함할 수 있다. 인공지능 모델은, GL-트랜스 포머 계층을 통해 영상의 글로벌(Global) 및 로컬(Local) 어텐션을 모두 학습하여 스켈레톤의 관절 (joint) 역학을 모두 포착할 수 있다. 다운스트림 태스크에서, 전이 학습 서버는 사전 학습된 인공지능 모델을 이용한 인공지능 모델을 통해 액션 인식(action recognition)할 수 있다. 사전 학습 서버가 인공지능 모델을 사전 학습시키면, 사전 학습된 인공지능 모델 및 인공지능 모델의 파라미터가 통신부를 통해 전이 학습 서버 에 전이될 수 있다. 전이 학습 서버는 인공지능 모델을 이용하여 다양한 태스크에 활용할 수 있다. 전 이 학습 서버가 이용하는 GL-트랜스포머 계층은 학습된 GL-트랜스포머 계층과 동일하지만, 이하, 설 명의 편의를 위해 GL-트랜스포머 계층로 한다. 도 3b를 참조하면, 인공지능 모델은, GL-트랜스포머 계층 및 선형 분류기(Linear Classifier)를 포함할 수 있다. 도 3b에서는, 인공지능 모델이 선형 분류기를 하나 포함하는 것으로 도시하였으나, 발명이 이에 한정되는 것은 아니고 선형 분류기는, 적어도 하나의 레이어를 포함할 수 있다. 적어도 하나의 레이어는, CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), GNN(Graph Neural Network) 등 다양한 형태의 네트워크로 구현될 수 있다. 도 4a 및 도 4b는, 일 실시예에 따른 인공지능 모델의 아키텍쳐를 도식적으로 도시한 블록도이다. 도 3a의 인공지능 모델은, 도 4a의 인공지능 모델로 구현할 수 있다. 사전 학습 서버는, 인공지 능 모델을 사전 학습시킬 수 있다. 도 4a를 참조하면, 인공지능 모델은, 글로벌 병진 임베딩 계층(Global Translation Embedding Layer), 관절 임베딩 계층(Joint Embedding Layer), 훈련 가능한 포지셔널 임베딩(Trainablepositional Embedding), N개의 GL-트랜스포머 블록(GL-Transformer Block), 다층 퍼셉트론(MLP, Multi-Layer Perceptron), 모션 시퀀스 표현(Motion Sequence Representation), 및 예측 계층 (Prediction Layer)으로 구성될 수 있다. 여기서 N은 2 이상의 자연수이다. 도 4b를 참조하면, N개의 GL-트랜스포머 블록 각각은, 공간적(spatial) 멀티헤드 어텐션(MHA, MultiHead Attention) 모듈 및 시간적(temporal) MHA 모듈을 포함할 수 있다. 공간적 MHA 모듈 및 시간적 MHA 모듈 각각은 N개의 GL-트랜스포머 블록 각각에 대응된다. 여기서 예측 계층은, 출력 값에 적합한 결과를 내기 위해 task-specific하게 학습될 수 있다. 예측 계층 은 복수의 레이어를 포함할 수 있다. 도 4b의 N개의 GL-트랜스포머 블록은, 도 3a의 GL-트랜스포머 에 대응될 수 있고, 도 4a의 예측 계층은, 도 3a의 포즈 변위 크기 예측 계층 및 포즈 변위 방향 예측 계층를 포함할 수 있다. 예측 계층은, 사전 학습 서버가 사전 학습할 때 사용되고, 다운스트림(Downstream)에 대응하는 전이 학습 서버에서는 제거될 수 있다. 일 실시예는 다양한 태스크에 적용될 수 있는 범용적인 모델을 만들기 위 한 것이다. 따라서 사전 학습 서버는 예측 계층를 포함하는 인공지능 모델을 사전 학습시키고, 사전 학습이 완료된 후 전이 학습 서버는, 예측 계층 대신 도 3b의 선형 분류기를 포함하는 인 공지능 모델을 학습시킨다. N개의 GL-트랜스포머 블록 각각은, 공간적 MHA 모듈 및 시간적 MHA 모듈을 포함한다. 이하, N개의 GL-트랜 스포머 블록 각각에 대응되는 공간적 MHA 모듈 및 시간적 MHA 모듈 각각의 공통된 동작 및 특징을 공간적 MHA 모듈 및 시간적 MHA 모듈로 설명한다. N개의 GL-트랜스포머 블록 각각은, 객체의 몸체로부터 복수의 관절로의 어텐션, 상기 복수의 관절 각각으 로부터 상기 몸체로의 어텐션, 및 사람과 사람 간의 어텐션을 적용할 수 있다. 공간적 MHA 모듈은, 각 프 레임 내에서 객체의 관절 간 정보, 관절-바디 간 정보, 바디-바디간 정보를 융합하고, 융합한 공간적 종속성을 어텐션 연산에 의해 학습할 수 있다. 시간적 MHA 모듈은, 공간적 MHA 모듈에 의해 집계된 포즈 특징을 이용하여 시퀀스 전반에 걸친 시 간적 종속성을 어텐션 연산에 의해 학습할 수 있다. 이하에서, 인공지능 모델에 입력되는 입력 모션 시퀀스를 참조하여 인공지능 모델의 아키텍처를 설명 한다. 공간적 MHA 모듈은, 글로벌 몸체 모션과 로컬 관절 동작을 분리된 입력 몸체(body) 모션을 사용하여, 세 가지 유형의 어텐션을 수행할 수 있다. 하나는 로컬(관절 간) 어텐션, 다른 하나는 글로벌(몸체)로부터 로컬(관 절)으로의 어텐션, 및/또는 로컬(관절)로부터 글로벌(몸체)으로의 어텐션, 그리고 나머지 하나는 글로벌(사람) 으로부터 글로벌(사람)으로의 어텐션이다. 이하, 입력 모션 시퀀스는 입력 몸체 모션의 시퀀스인 것으로 한다. 시간적 MHA 모듈은, 모든 사람의 시퀀스에 대한 두 프레임 간의 글로벌 및 로컬 어텐션을 수행할 수 있다. 이처럼 글로벌 및 로컬 어텐션 매커니즘은, N개의 GL-트랜스포머 블록 각각의 공간적 MHA 및 시간적 MHA 모두에 서 구현될 수 있다. 인공지능 모델에 입력되는 입력 모션 시퀀스는, 몸체의 글로벌 병진 모션(Global Translational Motion) 및 몸체 관절의 로컬 모션 두 개의 유형의 정보로 표현될 수 있다. 글로벌 병진 모션은, 몸체의 중심 관절의 궤 적으로 표현되고, 로컬 모션은, 중심 관절로부터 몸체의 관절의 상대적인 움직임으로 표현될 수 있다. 여기서 중심 관절은, 각 데이터셋에 정의될 수 있다. 예를 들어, NTU 데이터셋[28, 19]은, 척추 관절을 중심 관절로 표 현한다. 이하, 도 5를 참조하여, 영상 처리 시스템이 사전 학습을 통해 영상 처리하는 방법을 설명한다. 도 5는 일 실시예에 따른 영상 처리 방법의 순서도이다. 도 5를 참조하면, 수집부는, 외부 장치로부터 영상을 수집할 수 있다(S1). 외부 장치는, 소정의 영 역을 촬영하여 소정 영역에 대한 영상을 생성하는 촬영 장치일 수 있다. 영상은, RGB로 구성된 영상일 수 있다.수집부는, 촬영된 영상을 수신하여 전처리부에 전달할 수 있다. 전처리부는, 수집한 영상을 전처리하여 전처리 데이터를 생성할 수 있다(S2). 전처리부는, 영상으로 부터 2차원 또는 3차원 스켈레톤 정보를 추출할 수 있다. 스켈레톤 추출은, 기존에 존재하는 스켈레톤 추출 알 고리즘에 의해 구현될 수 있다. 전처리 데이터는, 텐서 X로 구현될 수 있다. 텐서 X는, 영상에 포함된 객체의 각 관절에 대한 3차원 위치 정보를 포함한다. 프로세서는, 전처리 데이터를 학습 데이터로 사용하여 인공지능 모델을 학습시킬 수 있다(S3). 프로 세서는, 객체의 글로벌(몸체)로부터 로컬(관절)으로의 어텐션, 로컬(관절)로부터 글로벌(몸체)으로의 어텐 션, 및 글로벌(사람)과 글로벌(사람) 간의 어텐션을 적용한 트랜스포머 기반의 모델을 이용한 인공지능 모델 을 학습시킬 수 있다. 따라서 원래의 3D 스켈레톤 모션 시퀀스는, 텐서 로 표현될 수 있다. 여기서 는 t(t는 자연수)번째 프레임에서의 스켈레톤의 포즈(pose)를 나타내는 행렬이다. 포즈 행렬 는, (k는 자연수)로 정의될 수 있고, 여기서 은, k번째 관절에 대응하는 3차원 벡터를 나타낸다. k번째 관절에서의 상대적인(Relative) 포지션 은,"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이다. 여기서 는 중심 관절의 좌표를 나타낸다. Relative 관절 포지션을 사용하여, 로컬 모션의 t번째 프레임은 행렬 Rx로 표현될 수 있다."}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 은 삭제되고, K-1 차원의 행렬로 다시 인덱싱될 수 있다."}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "글로벌 병진 모션의 t번째 프레임은 벡터를 사용하여 계산될 수 있다. 도 4를 참조하면, 하기 [수학식 1]과 같이 와 는 D차원 임베딩 벡터로 투영될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, , 이고, , 각각은 글로벌 병진 임베딩 계층 및 관절 임베딩 계층 각각에서 훈련 가능한 가중치와 바이어스를 나타낸다. 2 이상의 사람 사이의 상호 작용을 포함하는 액션 데이터셋의 경우, 벡터 와 행렬 각각은, 와 으로 나타낼 수 있다. 여기서, p는, 사람의 인덱스를 나타낸다. 유사하게, 임베딩 벡터들은 각각 와 으로 나타낼 수 있다. 이하, 시퀀스에서 여러 사람들 간의 상호 작용을 고려하는 방법을 설명한다. 인공지능 모델은, 시퀀스의 순서 정보를 포함하는 포지셔널 임베딩 행렬의 개념을 확장하여, 훈련 가능한 공간적-시간적 포지셔널 임베딩 텐서 M을 도입하여 훈련 데이터로부터 시간적 프레임 및 공간적 관절 모두의 시 간 정보를 학습할 수 있다. 여기서, 이다. PK는, P명의 사람의 관절 지수에 대한 차원이고, D는 임베딩 벡터들의 차원이며, 와 에서의 차원(D)과 동일하다. 관절 순서 정보는, 관절이 몸체의 어느 부분에 속하는 지 알기 전까지 각각의 관절의 위치가 의미 없다는 점에 서, 문장이나 이미지의 경우 보다 스켈레톤 모션 시퀀스에서 더욱 중요한 역할을 할 수 있다. 또한 프레임 순서 도 액션을 감지하는 데 중요한 역할을 할 수 있다. 따라서 인공지능 모델는, N개의 GL-트랜스포머 블록 각각에서 명시적으로 관절 순서 정보를 사용하는 타이트(tight) 포지셔널 임베딩 방법을 수행하도록 할 수 있다. 기존의 트랜스포머 기반의 모델들은, 첫번째 트랜스포머 블록 전에 포지셔널 임베딩을 한 번 적용한다. 이와 대 조적으로, 일 실시예에 따른 인공지능 모델은, 모든 블록의 입력 텐서에 포지셔널 임베딩을 적용한다. 도 4b를 참조하면, N개의 GL-트랜스포머 블록 각각에서, 포지셔널 임베딩이 공간적 MHA 모듈과 시간 적 MHA 모듈 각각에 적용된다. 이하, 인공지능 모델이 스켈레톤 모션 시퀀스 내 관절들 사이의 로컬 역학을 포착하고, 이와 함께 글로벌 의미(semantic) 정보를 추출하는 글로벌 및 로컬 어텐션 매커니즘을 구성하는 동작을 설명한다. 글로벌 및 로컬 어텐션(GLA, Global and Local Attention)은, 공간적 MHA 모듈 및 시간적 MHA 모듈 모두에서 구현된다. 공간적 MHA 모듈은 각 프레임 내에서 공간적 정보를 융합할 수 있다. 구체적으로 공간적 MHA 모듈 은 관절 간(local) 정보, 관절-body 간(local-global) 정보, 및 body-body(person-to-person) 간 정보를 융합 한다. 공간적 MHA 모듈은, 각 프레임 내에서 융합한 공간적 종속성을 학습할 수 있다. 공간적 MHA 모듈 에서, 각 사람의 와 에 대응하는 특징들 간의 어텐션 연산에 의해 글로벌(몸체)로부터 로컬(관절) 으로의, 또는 로컬(관절)로부터 글로벌(몸체)으로의 종속성이 학습된다. 마찬가지로, 글로벌(사람)과 글로벌(사람) 간의 종속성은 여러 사람들의 특징 사이의 어텐션에 의해 학습된다. 여기서 이고, P는 사람의 수이다. 시간적 MHA 모듈은 시퀀스의 다양한 시간대에 대한 정보를 융합할 수 있다. 시간적 MHA 모듈은, 공 간적 MHA 모듈에 의해 집계된 포즈 특징을 이용하여 시퀀스 전반에 걸친 시간적 종속성을 어텐션 연산에 의해 학습할 수 있다. 시간적 MHA 모듈은, 원거리 프레임들로부터 전신(whole-body) 모션 정보를 학습할 뿐 아니라, 인접한 프 레임들로부터 로컬 관절 역학을 학습할 수 있다. n번째 블록의 t번째 프레임에 대응하는 공간적 MHA 모듈의 입력 포즈 특성은, 으로 나타낼 수 있다. 도 4a 및 도 4b를 참조하면, 첫 번째 블록에서, 하기 [수학식 2] 및 [수학식 3]과 같이 여러 사람의 임베딩이 공간적 어텐션 축을 따라 연결된다. 수학식 2"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 3"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서 t는 1 이상 T이하의 자연수이고, T는 입력 시퀀스의 프레임 개수이며, ||는 연결 연산(Concatenation operation)을 나타낸다. 이하, 도 6를 참조하여 n은 2 이상, N 이하의 자연수인 경우, n번째 GL-트랜스포머 블록이 입력으로부터 출력을 생성하는 동작을 설명한다. 도 6는 도 5의 S3 단계의 세부 순서도이다. 이전 블록의 출력( )을 입력 받으면, n번째 GL-트랜스포머 블록은 이전 블록의 출력의 각 프레임( )에 대응하는 포지셔널 임베딩 텐서 M의 t번째 슬라이스( )를 적용한 결과( )를 계층 정규화한다 ( ). n번째 GL-트랜스포머 블록의 공간적 MHA 모듈은 계층 정규화 결과에 공간적 MHA를 적용한 다( ). n번째 GL-트랜스포머 블록은, 공간적 MHA를 적용한 결과 ( )에 이전 블록의 출력의 각 프레임( )에 대응하는 포지셔널 임베딩 텐서 M의 t번째 슬라이스( )를 적용한 결과( )를 더한 제1 결과( )를 도출할 수 있다(S31). n이 2 이상인 경우, n번째 블록의 공간적 MHA 모듈은 이전 블록의 출력 을 입력 받는다. 공간적 MHA 모듈은, 포즈 기능을 하기의 [수학식 4] 와 같이 업데이트한다. 수학식 4"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서 는 포지셔널 임베딩 텐서 M의 t번째 슬라이스이고, LN()은, 계층 정규화 연산자를 나타낸다. 공간적 MHA에서, 포지셔널 임베딩 행렬에서의 MHA 개념을 사용할 수 있다. 이하, 단순화를 위 해, 를 로 표현하여 설명한다. 먼저, 는, 하기의 [수학식 5]와 같이 쿼리 Q, 키 K, 값 V을 갖는 행렬 Q에 투영(Projection)될 수 있다. 수학식 5"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서 는 투영에 대한 가중치 행렬이고, 투영 차원은 d로 나타낼 수 있다. 인공지능 모 델은, 사전 학습을 통해 각각을 결정할 수 있다. 인공지능 모델의 어텐션 매커니즘은, 하기의 [수학식 6]과 같이 표현될 수 있다. 수학식 6"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "여기서 는 쿼리 Q에서 키 K에 대하여 각각의 투영된 관절 벡터의 내적 유사성을 나타낸다. 높은 유사성에 대해 높은 어텐션 가중치가 적용된다. MHA에서, i번째 head는 다른 가중치 행렬 과 하기의 [수학 식 7]과 같은 다른 헤드들의 가중치 행렬들로 [수학식 6]의 어텐션 매커니즘을 수행한다. 수학식 7"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "여기서, i는 1 이상 h 이하의 자연수이고, 연쇄적인 는 하기의 [수학식 8]로 집계된 포즈 특징들에 투영되며, 여기서 는 투영 행렬이다. 인공지능 모델은, 사전 학습을 통해 각각을 결정할 수 있다. 수학식 8"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "n번째 블록에서 시간적 MHA를 수행하기 위해, t번째 프레임 를 로 포즈 특징을 백터화 한다. 그리고, 벡터화된 포즈 특징들은 포즈 특징 시퀀스 행렬 을 형성하기 위해 적층 된다. 시간적 MHA 모듈에서, [수학식 8]과 동일한 MHA 매커니즘이 사용되지만, 다른 가중치 행렬이 적용 된다. 각 프레임에 대한 n번째 GL-트랜스포머 블록은 제1 결과( )가 적층된 포즈 시퀀스 행렬( )에 포지셔널 임베 딩 텐서 M의 차원이 변경된 행렬( )를 적용한 결과( )를 계층 정규화한다( ). n번째 GL-트 랜스포머 블록의 시간적 MHA 모듈은 계층 정규화 결과에 시간적 MHA를 적용한다 ( ). n번째 GL-트랜스포머 블록은, 하기의 [수학식 9]와 같이 공간적 MHA를 적용 한 결과( )에 포즈 시퀀스 행렬( )에 포지셔널 임베딩 텐서 M의 차원이 변경된 행렬( )를 적용한 결과( )를 더한 제2 결과( )를 도출할 수 있다(S32). 수학식 9"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "여기서, 은, 포지셔널 임베딩 텐서 의 차원이 변경되는 경우의 행렬이다. n번째 GL-트랜스포머 블록은 제2 결과( )를 계층 정규화한다( ). n번째 GL-트랜스포머 블록은 계층 정 규화 결과에 MLP를 적용하고( ), MLP를 적용한 결과( )에 제2 결과( )를 더한 제3 결과( )를 도출할 수 있다(S33). 여기서 제3 결과( )는, 최종적으로 n번째 GL-트랜스포머 블록의 출력이 된 다. n번째 GL 트랜스포머( )의 출력 포즈 시퀀스 특징은 하기의 [수학식 10]과 같이 MLP를 통해 획득될 수 있다. 수학식 10"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "인공지능 모델은, 사전 학습을 통해 MLP의 파라미터들 각각을 결정할 수 있다. N개의 GL-트랜스포머 블록 각각에서 상술한 S31 내지 S33 단계가 수행된다. 일 실시예에서는, 임베딩 텐서 M을 트랜스포머 블록 중 첫번째 블록에만 적용하는 것에 지나지 않고, N개의 GL-트랜스포머 블록 각각에 적용하였다. N번째 GL-트랜스포머 블록은, 하기의 [수학식 11]과 같이 N번째 제3 결과( )에 2 계층 MLP을 적용하여 입력 모션 시퀀스 X에 대한 최종적인 모션 시퀀스 표현 F를 도출할 수 있다. 수학식 11"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "모션 시퀀스 표현 F는, 예측 계층에 입력되어 task-specific한 결과로 출력될 수 있다. 이하, 자연스러운 속도 모션 시퀀스에 대한 Masked 어텐션을 설명한다. 자연스러운 속도의 모션 시퀀스를 처리하기 위해 일 실시예에서는 프레임 전체에서 자연스러운 관절 역학을 학 습하고, 다양한 동작에서 속도 특성을 포착할 수 있도록 어텐션 마스크를 사용한다. 이를 위해 최대 시퀀스 길 이를 정의하고, 원래 시퀀스의 길이가 최대 시퀀스 길이보다 짧으면, 나머지 프레임은 패딩 더미(Padding Dummy) 토큰으로 채운다. 인공지능 모델은, 패딩 더미 토큰들은 해당 토근에 해당하는 손실을 제외하기 때문에 임의의 숫자로 설정 된다. 더미 값에서 어텐션을 배제하기 위하여 행렬의 패딩 더미 토큰에 해당하는 열을 마스킹한다. 예를 들어, 인공지능 모델은, 패딩 더미 토큰에 해당하는 열을 마이너스 무한대로 설정할 수 있다. 이하, 인공지능 모델이 길이가 긴 시퀀스에 걸쳐 글로벌 어텐션을 학습하는 방법을 설명한다. 사전 훈련을 위해 다중 간격 자세 변위 예측(MPDP, multi-interval pose displacement prediction) 전략을 사 용한다. 인공지능 모델은, MPDP를 통해 여러 태스크들로 훈련되어 동시에 다른 간격에 걸쳐 다양한 포즈의 변위를 예측할 수 있다. 여기서 다양한 포즈의 변위로는, 모든 관절의 각도 및 이동 거리일 수 있다. 인공지능 모델은 적은 간격에서 로컬 어텐션을 학습하고, 큰 간격에서 글로벌 어텐션을 학습한다. 인공지 능 모델은, 프레임 전반에 걸쳐 자연스러운 관절 역학을 학습하기 위해 고정된 길이로 샘플링된 시퀀스 대 신 자연스러운 속도의 모션 시퀀스를 적용할 수 있다. 또한 인공지능 모델은, 학습 가능한 공간적 포지셔 널 임베딩 및 시간적 포지셔널 임베딩을 적용하여 각 GL-트랜스포머 블록들에 반복적으로 적용하여 모든 블록의 순서 정보를 사용할 수 있다. 모든 블록의 순서 정보는, 모션 시퀀스에서 매우 중요한 정보이다.특정 프레임에서 관절의 순간 속도는 인접 프레임에서 쉽게 얻을 수 있으므로 모델이 넓은 범위(long-range)의 글로벌 어텐션이 아닌 로컬 어텐션을 학습하도록 안내하지만, 프로세서는 이러한 한계를 극복하기 위해 인 공지능 모델이 지역적 어텐션 뿐만 아니라 글로벌 어텐션도 효과적으로 학습할 수 있도록 한다. 도 7은, 객체의 움직임을 설명하기 위한 다중 프레임 간격의 예시도이다. 도 7를 참조하면, 인공지능 모델은, 다중 프레임 간격 t-N, ... , t-n, ..., t을 선택할 수 있다. GL-트 랜스포머 계층은, t번째 프레임과 (t-n)번째 프레임 간의 포즈 변위의 방향과 크기를 예측하는 방법을 학 습할 수 있다. 상대적인 관절 변위를 나타내는 로컬 모션은 글로벌 모션의 도움으로 예측될 수 있고, 글로벌 모 션도 로컬 모션의 도움으로 예측될 수 있다. 추가적으로, 한 사람의 움직임을 예측할 때, 다른 사람의 움직임도 고려된다. 도 8a는 도 7의 객체의 중심 관절의 변위 및 k번째 관절의 변위를 설명하기 위한 예시도이다. 도 8b는 도 7의 객체의 변위의 방향과 크기를 설명하기 위한 예시도이다. 도 8a 및 도 8b에는, 도 7에 도시된 객체의 포즈 변위를 화살표로 도시하였다. 포즈 변위 크기 예측 계층 및 포즈 변위 방향 예측 계층 각각의 분류 태스크는, softmax가 적용된 선형 분류기를 사용하여 구현될 수 있다. 인공지능 모델은, 각각의 간격에 대한 방향 및 크기를 모두 예측 하도록 학습될 수 있다. 간격 n에 대한 t번째 프레임의 예측은 하기의 [수학식 12]와 같이 표현될 수 있다. 수학식 12"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "여기서, 는 모션 시퀀스 표현 F의 t번째 슬라이스이다. 이며, 여기서 이다. 또한 는 각 각 글로벌 병진 벡터에서 예측된 방향 클래스 벡터와 k번째 관절 벡터에서 예측된 방향 클래스 벡터를 나타내고, k는 1 이상 K-1 이하의 자연수이다. 는, 방향 클래스의 개수를 나타낸다. 이며, 여기서 이다. 또한 는 각 각 글로벌 병진 벡터에서 예측된 크기 클래스 백터와 k번째 관절 벡터에서 예측된 크기 클래스 벡터를 나타내고, k는 1 이상 K-1 이하의 자연수이다. 는, 크기 클래스의 개수를 나타낸다 는, 간격 n에 대한 학습 가능한 가중치 및 편향(bias)이다. 사전 학습 서버는, 인공지능 모델의 파라미터들을 학습하기 위하여, 간격 n과 p번째 사람에 대한 t번 째 프레임에서의 방향 과 크기 의 실측 클래스를 하기의 [수학식 13] 및 [수학식 14]와 같이 정의할 수 있다.수학식 13"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "수학식 14"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "여기서, (t-n)번째 프레임의 정보가 없기 때문에, t≤n에서, 이고, 으로 세팅할 수 있다. class(A)는, A의 클래스 레이블 벡터를 나타내며, 여기서 크기는 클래스 중 하나로 양자화되고, 방향은 =27 클래스 중 하나로 지정됩니다. 여기서, 27개 클래스는, 각 x축, y축, z축 방향 각각에 대한 +, -, 움직임이 없음의 세 가지 클래스를 포함한 것이다. 예측 계층은, [PAD] 토큰을 제외하고 모든 구간 및 프레임에서 분류 손실을 계산할 수 있다. [PAD] 토큰은, 딥러닝 모델에서, 입력 대상의 길이를 같게 맞춰주는 padding하는 특수 토큰이다. 총 손실은, 하기의 [수학식 15]와 같이 정의될 수 있다. 수학식 15"}
{"patent_id": "10-2022-0118520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "여기서, 방향 손실 및 크기 손실 은, 및 의 각 구성 요소를 훈련하기 위한 교 차 엔트로피 손실의 가중치 합을 나타낸다. 또한 및 각각은 및 각각의 가중치를 나타낸다. 이처럼 인공지능 모델은, 상기 동작을 통해 사전 학습될 수 있다. 인공지능 모델은, 글로벌 및 로컬 어텐션을 학습하여, 시퀀스의 글로벌 컨텍스트와 로컬 역학을 효과적으로 포착한다. 일 실시예에서 인공지능 모 델은 비지도 학습 방식에서 구현될 수 있으나, 지도 학습 방식에서도 다운스트림 동작 인식 작업에서 뛰어난 성 능을 보여준다. 인공지능 모델이 사전 학습에서 결정한 파라미터들은, 다운스트림 태스크에 사용될 수 있 도록 전이 학습 서버에 전달될 수 있다. 사전 학습에서 결정한 파라미터들은, [수학식 1] 내지 [수학식 1 1]의 파라미터들 및 [수학식 1] 내지 [수학식 11]을 통해 사전 학습하여 결정한 가중치들을 포함할 수 있다. 사전 학습에서 결정한 파라미터들이 전이되면, 전이 학습 서버는, 사전 학습에서 결정한 파라미터들이 적용 된 인공지능 모델을 적용할 수 있다. 상술한 바와 같이, 인공지능 모델은, 사전 학습된 GL-트랜스포 머 계층 및 적어도 하나의 새로운 예측 레이어를 포함할 수 있다. 인공지능 모델은, 인공지능 모델 중 [수학식 12]를 통해 결정된 예측 계층()을 제외하고, 새롭게 추가되는 적어도 하나의 레이어를 학습할수 있다. 전이 학습 서버는 인공지능 모델을 이용하여 객체의 행동을 다루는 다양한 다운스트림 태스 크를 수행할 수 있다. 인공지능 모델을 다양한 태스크에 활용하기 위하여, 전이 학습 서버는, 인공지능 모델에 포함된 레이어들을 각 태스크 별로 달리 결정할 수 있다. 전이 학습 서버는 개별 태스크에 대해 세부 학습을 진행 하기 위해, 사전 학습된 인공지능 모델의 사전 학습에서 결정한 파라미터들에 기초하여 인공지능 모델 을 학습할 수 있다. 인공지능 모델은, 비디오 이해에 관한 다양한 태스크에 적용될 수 있다. 전이 학 습 서버는, 인공지능 모델의 사전 학습에서 결정한 파라미터들을 그대로 고정한 채 사용하여 학습할 수 있다. 전이 학습 서버는, 액션 분류, 이상 행동 탐지, 이벤트 구간 탐색 등 다양한 태스크에 인공지능 모델 을 활용할 수 있다. 인공지능 모델은, 다운스트림 태스크가 액션 분류인 제1 인공지능 모델(101_1), 다운 스트림 태스크가 이상 행동 탐지인 제2 인공지능 모델(101_2), 및 다운스트림 태스크가 이벤트 구간 탐색인 제3 인공지능 모델(101_3) 중 적어도 하나를 포함할 수 있다. 제1 인공지능 모델(101_1), 제2 인공지능 모델 (101_2), 및 제3 인공지능 모델(101_3)은 예시적인 것이고, 발명은 이에 한정되지 않는다. 인공지능 모델 은, GL-트랜스포머 계층 및 적어도 하나의 새로운 계층을 포함하여 영상으로부터 객체의 행동을 다루는 다양한 다운스트림 태스크를 수행하는 모델 중 하나일 수 있다. 인공지능 모델에 포함되는 적어도 하나의 새로운 계층은, 액션 인식에 맞추어 학습될 수 있다. 인공지능 모델(101_1)은, GL-트랜스포머 계층 및 적어도 하나의 새로운 제1 계층을 포함할 수 있다. 전 이 학습 서버는, 액션의 종류가 추정되도록 인공지능 모델(101_1)을 학습시킬 수 있다. 인공지능 모델 (101_2)은, GL-트랜스포머 계층 및 적어도 하나의 새로운 제2 계층을 포함할 수 있다. 전이 학습 서버 는, 영상에 포함된 객체의 행동이 이상 행동인지, 아니면 정상 행동인지 둘 중에 하나로 추정되도록 인공지 능 모델(101_2)을 학습시킬 수 있다. 인공지능 모델(101_3)은, GL-트랜스포머 계층 및 적어도 하나의 새 로운 제3 계층을 포함할 수 있다. 전이 학습 서버는, 영상 중 각 시간 구간에 대한 액션 종류가 라벨링 되 어 있는 경우, 해당 영상을 포함하는 데이터로 인공지능 모델(101_3)을 학습시켜, 영상을 학습된 인공지능 모델 에 입력하면 이벤트가 발행한 구간과 해당 구간의 액션 종류가 출력될 수 있다. 또는 전이 학습 서버는, 인공지능 모델의 사전 학습에서 결정한 파라미터들을 고정하지 않고, 학습의 초기 값으로 사용하여 학습할 수 있다. 전이 학습 서버가 사용할 데이터 량이 매우 적거나, 적은 연산 만으 로 빠르게 인공지능 모델을 업데이트하기 위하여 인공지능 모델의 사전 학습에서 결정한 파라미터들 도 변경될 수 있도록 학습할 수 있다. 전이 학습 서버는, 학습된 인공지능 모델에 영상 데이터를 입력하여 개별 태스크를 추론할 수 있다. 도 1에 도시하지 않았지만, 전이 학습 서버는, 프로세서 및 프로세서에 의해 수행되는 컴퓨터 프로그램을 로드하는 메모리, 및 컴퓨터 프로그램을 저장하는 스토리지를 포함할 수 있다. 메모리 및 전이 학습 서버 의 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리 및 전이 학습 서버의 메모리는 본 발명의 실시예들에 따른 방법을 실행하기 위하여 스토리지로부터 하나 이상의 프로그램을 로드 할 수 있다. 메모리 및 전이 학습 서버의 메모리는 RAM 과 같은 휘발성 메모리로 구현될 수 있을 것이나, 본 발명 의 기술적 범위가 이에 한정되는 것은 아니다. 메모리 및 전이 학습 서버의 스토리지는 상기 하나 이상의 프로그램과 각종 데이터를 비임시적으로 저 장할 수 있다. 메모리 및 전이 학습 서버의 스토리지는 는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메 모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 사전 학습 서버 및 전이 학습 서버 각각의 컴퓨터 프로그램은 메모리에 로드 될 때 프로세서로 하여금 본 발명의 다양한 실시예에 따른 방법/동작을 수행하도록 하는 하나 이상의 명령어를 포함할 수 있다. 즉, 프로세서는 상기 하나 이상의 명령어를 실행함으로써, 본 명의 다양한 실시예에 따른 방법/동작들을 수행할 수 있다. 상술한 본 발명의 실시예들은 다양한 수단을 통해 구현될 수 있다. 예를 들어, 본 발명의 실시예들은 하드웨어, 펌웨어(firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 프로세서, 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 펌웨어나 소프트웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 이상에서 설명된 기능 또는 동작 들을 수행하는 모듈, 절차 또는 함수 등의 형태로 구현될 수 있다. 소프트웨어 코드는 메모리 유닛에 저장되어 프로세서에 의해 구동될 수 있다. 상기 메모리 유닛은 상기 프로세서 내부 또는 외부에 위치하여, 이미 공지된 다양한 수단에 의해 상기 프로세서와 데이터를 주고받을 수 있다. 이상을 통해 본 발명의 실시 예에 대하여 설명하였지만, 본 발명은 상기 실시 예에 한정되지 않고, 본 발명의 취지를 벗어나지 않고 효과를 저해하지 않는 한, 발명의 상세한 설명 및 첨부한 도면의 범위 안에서 다양하게 변경하여 실시할 수 있다. 또한 그러한 실시 예가 본 발명의 범위에 속하는 것은 당연하다."}
{"patent_id": "10-2022-0118520", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 영상 처리 시스템을 도식적으로 도시한 도면이다. 도 2는 도 1의 사전 학습 서버의 세부 구성을 도식적으로 나타낸 블록도이다. 도 3a 및 도 3b는, 일 실시예에 따른 영상 처리 시스템의 프레임워크를 설명하기 위한 구성도이다. 도 4a 및 도 4b는, 일 실시예에 따른 인공지능 모델의 아키텍쳐를 도식적으로 도시한 블록도이다. 도 5는 일 실시예에 따른 영상 처리 방법의 순서도이다. 도 6는 도 5의 S3 단계의 세부 순서도이다. 도 7은 객체의 움직임을 설명하기 위한 다중 프레임 간격의 예시도이다. 도 8a는 도 7의 객체의 중심 관절의 변위 및 k번째 관절의 변위를 설명하기 위한 예시도이다. 도 8b는 도 7의 객체의 변위의 방향과 크기를 설명하기 위한 예시도이다."}
