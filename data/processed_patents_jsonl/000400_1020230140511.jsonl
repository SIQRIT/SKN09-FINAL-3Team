{"patent_id": "10-2023-0140511", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0056609", "출원번호": "10-2023-0140511", "발명의 명칭": "신경망 모델의 온-디바이스 학습을 위한 가중치 업데이트 장치 및 방법", "출원인": "경북대학교 산학협력단", "발명자": "박대진"}}
{"patent_id": "10-2023-0140511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "신경망 모델의 온-디바이스 학습을 위한 가중치 업데이트 장치에서의 가중치 업데이트 방법으로서,상기 신경망 모델의 가중치 행렬(matrix)을 열(column) 단위로 분할하여 플래시 메모리(Flash Memory)의 각 페이지(page)에 매핑시켜 저장하는 단계;상기 신경망 모델의 학습에 따른 업데이트가 필요한 가중치 열을 선별하는 단계;상기 선별된 가중치 열에 대응하는 상기 플래시 메모리의 페이지를 SRAM(Static Random Access Memory)에 복사하여 가중치를 업데이트하고 상기 플래시 메모리의 페이지에 재쓰기(rewrite) 작업을 수행하는 단계;를 포함하는, 가중치 업데이트 방법."}
{"patent_id": "10-2023-0140511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 가중치 열을 선별하는 단계는,상기 신경망 모델의 학습에 따라 발생하는, 현재 시점의 기울기(gradient) 평균 벡터와 이전 시점의 기울기 평균 벡터를 산출하는 단계;상기 현재 시점의 기울기 평균 벡터와 상기 이전 시점의 기울기 평균 벡터 간의 변화량을 계산하는 단계; 및상기 계산된 변화량과 미리 정해진 임계 값을 기반으로 상기 플래시 메모리에 저장된 가중치 행렬에서 상기 업데이트할 가중치 열을 선별하는 단계;를 포함함을 특징으로 하는, 가중치 업데이트 방법."}
{"patent_id": "10-2023-0140511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 기울기 평균 벡터는 상기 신경망 모델의 은닉(hidden) 계층에서 발생된 오차(error) 벡터와 상기 신경망모델의 입력 계층 활성화 함수의 결과 벡터의 곱으로 산출됨을 특징으로 하는, 가중치 업데이트 방법."}
{"patent_id": "10-2023-0140511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 선별된 가중치 열은 상기 변화량이 상기 임계 값을 초과하는 열인 것을 특징으로 하는, 가중치 업데이트방법."}
{"patent_id": "10-2023-0140511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 임계 값은 상기 신경망 모델의 학습 과정에서 입력되는 각 이미지 픽셀에 전파되는 기울기 변화량을 고려하여 결정됨을 특징으로 하는, 가중치 업데이트 방법.공개특허 10-2025-0056609-3-청구항 6 신경망 모델의 온-디바이스 학습을 위한 가중치 업데이트 장치로서,상기 신경망 모델의 가중치를 페이지(page) 단위로 저장하는 플래시 메모리(Flash Memory);상기 플래시 메모리에 저장된 가중치를 복사하여 가중치를 업데이트하는 SRAM(Static Random Access Memory);및상기 가중치의 행렬(matrix)을 열(column) 단위로 분할하여 플래시 메모리의 각 페이지에 매핑시키는 링커(Linker);를 포함하고,상기 가중치 업데이트 장치는 상기 신경망 모델의 학습에 따른 업데이트가 필요한 가중치 열을 선별하고, 상기선별된 가중치 열에 대응하는 상기 플래시 메모리의 페이지만을 상기 SRAM에 복사하여 가중치의 일부만을 업데이트하도록 제어하는, 가중치 업데이트 장치."}
{"patent_id": "10-2023-0140511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 선별된 가중치 열은, 상기 신경망 모델의 학습에 따라 발생하는, 현재 시점의 기울기(gradient) 평균 벡터와 이전 시점의 기울기 평균 벡터 간의 변화량과 미리 정해진 임계 값을 기반으로 선별된 것임을 특징으로하는, 가중치 업데이트 장치."}
{"patent_id": "10-2023-0140511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 기울기 평균 벡터는 상기 신경망 모델의 은닉(hidden) 계층에서 발생된 오차(error) 벡터와 상기 신경망모델의 입력 계층 활성화 함수의 결과 벡터의 곱으로 산출됨을 특징으로 하는, 가중치 업데이트 장치."}
{"patent_id": "10-2023-0140511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 선별된 가중치 열은 상기 기울기 변화량이 상기 임계 값을 초과하는 열인 것을 특징으로 하는, 가중치 업데이트 장치."}
{"patent_id": "10-2023-0140511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 임계 값은 상기 신경망 모델의 학습 과정에서 입력되는 각 이미지 픽셀에 전파되는 기울기 변화량을 고려하여 결정됨을 특징으로 하는, 가중치 업데이트 장치."}
{"patent_id": "10-2023-0140511", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 신경망 모델의 온-디바이스 학습을 위한 가중치 업데이트 장치에서의 가중치 업데이트 방법에 대한 것으로, 상기 신경망 모델의 가중치 행렬(matrix)을 열(column) 단위로 분할하여 플래시 메모리(Flash Memory)의 각 페이지(page)에 매핑시켜 저장하고, 상기 신경망 모델의 학습에 따른 업데이트가 필요한 가중치 열을 선별하 고, 상기 선별된 가중치 열에 대응하는 상기 플래시 메모리의 페이지를 SRAM(Static Random Access Memory)에 복사하여 가중치를 업데이트하고 상기 플래시 메모리의 페이지에 재쓰기(rewrite) 작업을 수행한다."}
{"patent_id": "10-2023-0140511", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 신경망 모델의 온-디바이스 학습을 위한 가중치(weight) 업데이트 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0140511", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능(AI: Artificial Intelligence) 신경망의 학습을 서버가 아닌 로컬에서 수행하는 엣지(edge) 디바 이스에 대한 관심이 높아지는 가운데, 온-디바이스 학습이 가능한 엣지 디바이스에 대한 연구가 활발히 진행중 에 있다. 이러한 엣지 디바이스는 온-디바이스 학습을 위해 마이크로 컨트롤러 유닛(MCU: Micro Controller Unit)을 사용 하는 것이 일반적인데, MCU의 메모리인 SRAM(Static Random Access Memory)과 플래시 메모리(Flash Memory)는 각각 다음과 같은 장단점을 갖는다. 즉 SRAM은 빠른 접속(access) 속도를 가지며 데이터에 대한 읽기(read)/쓰 기(write) 작업이 빠른 반면 비용이 높아 용량이 작다는 단점이 있고, 플래시 메모리는 대용량 데이터를 저장하 고 영구 데이터를 보관하는데 적합한 반면 쓰기 작업을 수행하는데 있어 제약이 많다는 단점이 있다. 한편, 온-디바이스 학습을 위해서는 플래시 메모리에 저장된 매개변수, 일례로 가중치를 업데이트하는 것이 필 수적이나, 플래시 메모리는 앞서 설명한 바와 같이 쓰기 작업을 수행하는데 있어 많은 제약이 따른다. 특히 플 래시 메모리에서 데이터를 삭제하려면 높은 전압이 필요하고 상당한 비용이 소요되며 데이터를 쓰기 위해서는 크기에 관계없이 해당 페이지를 먼저 삭제 후 데이터를 써야 한다. 또한 플래시 메모리의 접근 오버헤드를 줄 이기 위해 부분적으로 가중치 업데이트를 수행할 수도 있으나 이 경우 온-디바이스 학습의 추론 정확도가 낮아 지는 문제점이 있다. 따라서 이러한 온-디바이스 학습의 추론 정확도에 대한 손실은 최소화하며 학습에 필요한 가중치를 최소한의 메 모리만 사용하여 업데이트하는 방안에 대한 연구가 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허공보 제10-2505946호"}
{"patent_id": "10-2023-0140511", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제를 해결하기 위해 안출된 것으로, 본 발명의 목적은 신경망 모델의 온-디바이스 학 습을 위한 가중치 업데이트 장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2023-0140511", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 신경망 모델의 온-디바이스 학습을 위한 가중치 업데이 트 장치에서의 가중치 업데이트 방법은, 상기 신경망 모델의 가중치 행렬(matrix)을 열(column) 단위로 분할하 여 플래시 메모리(Flash Memory)의 각 페이지(page)에 매핑시켜 저장하는 단계; 상기 신경망 모델의 학습에 따 른 업데이트가 필요한 가중치 열을 선별하는 단계; 상기 선별된 가중치 열에 대응하는 상기 플래시 메모리의 페 이지를 SRAM(Static Random Access Memory)에 복사하여 가중치를 업데이트하고 상기 플래시 메모리의 페이지에 재쓰기(rewrite) 작업을 수행하는 단계;를 포함한다. 상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 신경망 모델의 온-디바이스 학습을 위한 가중치 업데이 트 장치는, 상기 신경망 모델의 가중치를 페이지(page) 단위로 저장하는 플래시 메모리(Flash Memory); 상기 플 래시 메모리에 저장된 가중치를 복사하여 가중치를 업데이트하는 SRAM(Static Random Access Memory); 및 상기 가중치의 행렬(matrix)을 열(column) 단위로 분할하여 플래시 메모리의 각 페이지에 매핑시키는 링커(Linker); 를 포함하고, 상기 가중치 업데이트 장치는 상기 신경망 모델의 학습에 따른 업데이트가 필요한 가중치 열을 선 별하고, 상기 선별된 가중치 열에 대응하는 상기 플래시 메모리의 페이지만을 상기 SRAM에 복사하여 가중치의 일부만을 업데이트하도록 제어한다."}
{"patent_id": "10-2023-0140511", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 본 발명의 일측면에 따르면, 신경망 모델의 온-디바이스 학습을 위한 가중치 업데이트 장치 및 방법을 제공함으로써, 온-디바이스 학습의 추론 정확도를 유지하고 상대적으로 비용이 많이 드는 SRAM의 사용량을 최소 화할 수 있다."}
{"patent_id": "10-2023-0140511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명이 실시될 수 있는 특정 실시예를 예시로서 도시하는 첨부 도 면을 참조한다. 이들 실시예는 당업자가 본 발명을 실시할 수 있기에 충분하도록 상세히 설명된다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있 는 특정 형상, 구조 및 특성은 일 실시예와 관련하여 본 발명의 정신 및 범위를 벗어나지 않으면서 다른 실시예 로 구현될 수 있다. 또한, 각각의 개시된 실시예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 정신 및 범 위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미로 서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모든 범위와 더불어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하거 나 유사한 기능을 지칭한다. 본 발명에 따른 구성요소들은 물리적인 구분이 아니라 기능적인 구분에 의해서 정의되는 구성요소들로써 각각이 수행하는 기능들에 의해서 정의될 수 있다. 각각의 구성요소들은 하드웨어 또는 각각의 기능을 수행하는 프로그 램 코드 및 프로세싱 유닛으로 구현될 수 있을 것이며, 두 개 이상의 구성요소의 기능이 하나의 구성요소에 포 함되어 구현될 수도 있을 것이다. 따라서 이하의 실시예에서 구성요소에 부여되는 명칭은 각각의 구성요소를 물 리적으로 구분하기 위한 것이 아니라 각각의 구성요소가 수행되는 대표적인 기능을 암시하기 위해서 부여된 것 이며, 구성요소의 명칭에 의해서 본 발명의 기술적 사상이 한정되지 않는 것임에 유의하여야 한다. 이하에서는 도면들을 참조하여 본 발명의 바람직한 실시예들을 보다 상세하게 설명하기로 한다. 도 1은 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 장치의 내부 구조를 나타낸 도면이 다. 도시된 가중치 업데이트 장치는 코어(Core), 플래시 메모리(Flash Memory), SRAM 및 온- 칩 버스를 포함하고, 상기 코어, 플래시 메모리, SRAM 각각은 상기 온-칩 버스에 연 결된다. 여기서 상기 가중치 업데이트 장치는 MCU일 수 있다. 상기 코어는 온-디바이스 학습을 위한 신경망(Neural Network) 모델의 학습 프로그램을 수행하고, 상기 신 경망 모델로부터 생성되는 신경망 모델 가중치를 온-칩 메모리, 즉 플래시 메모리와 SRAM에 저 장한다. 그러나 플래시 메모리는 대용량 데이터를 저장하고 영구 데이터를 보관하는데 적합한 반면 쓰기 작업을 수 행하는데 있어 페이지 단위로 수행해야만 하는 제약이 있다. 즉 플래시 메모리에 데이터를 저장하려면 페 이지 단위로 삭제한 후 저장해야만 한다. 또한 SRAM은 읽기/쓰기 작업은 자유로우나 비용이 높아 용량이 작다는 단점이 있다.따라서 후술할 본 발명의 실시예에서는 신경망 모델 학습의 추론 정확도에 대한 손실을 최소화하면서 최소한의 메모리를 사용하여 신경망 모델 가중치의 일부만을 업데이트하는 방안에 대하여 설명하도록 한다. 먼저 본 발명의 실시예에 따른 가중치 업데이트 방법은 신경망 모델의 학습 프로그램 컴파일 단계에서 링커를 통해 신경망 모델 가중치를 플래시 메모리에 페이지 단위로 저장하는 과정을 포함한다. 이하에서는 도 2를 통해 링커가 신경망 모델 가중치를 플래시 메모리에 페이지 단위로 저장하는 동작에 대하여 보다 상세히 설명하도록 한다. 도 2는 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 장치에 포함되는 링커의 매핑 동작 의 예를 나타낸 도면이다. 도시된 링커(Linker)는 신경망 모델의 가중치, 일례로 가중치 행렬(weight matrix)이 입력되면, 상기 가중치 행렬을 열(column) 단위로 분할하여 플래시 메모리의 각 페이지에 매핑시킨다. 이때 링커 는 또 다른 입력인 링커스크립트(Linkerscript)를 참조하여 상기 가중치 행렬을 분할한다. 상기 열 단위로 분할된 가중치 행렬은 상기 링커를 통해 플래시 메모리의 각 페이지에 매핑되어 저장 된다. 즉 플래시 메모리의 시작 주소부터 점유하는 페이지에 순차적으로 매핑되어 저장된다. 신경망 모델의 학습 과정에서 SRAM의 용량으로 인해 오버플로우(overflow)된 가중치 매개변수들은 플래시 메모 리에 저장된다. SRAM에 저장된 데이터는 읽기/쓰기에 대한 접근이 자유로우므로 학습 과정 중의 가중치 업데이 트는 비용이 적게 드는 반면, 플래시 메모리에 저장된 데이터를 수정하기 위해서는 데이터가 존재하는 주소에 대응하는 페이지 전체를 삭제해야만 하므로 학습 과정 중의 가중치 업데이트에 제약이 있다. 뿐만 아니라 플래시 메모리에는 신경망 모델의 학습 프로그램 코드와 데이터(즉, 가중치)가 함께 저장되므로, 이러한 데이터 수정을 위한 임의의 페이지 삭제가 코드 실행에 영향을 미칠 수 있다. 따라서 본 발명의 실시예 에서는 선별된 일부 가중치에 대해서만 업데이트하기 위해 입력 계층의 가중치 행렬을 각 플래시 메모리 페이지에 열 단위로 저장한다. 도 2에서는 가중치 행렬이 링커를 통해 플래시 메모리의 시작 주소와 끝 주소가 각각 _start_A, _end_A인 섹션(Section) A에 저장되는 과정을 하나의 예로써 나타낸 것이다. 여기서 링커는 런타임 (runtime) 동안 가중치가 저장된 섹션에 접근하기 위해 플래시 메모리를 구성하는 페이지들의시작 주소를 관리 하는 배열을 참조하고, 컴파일러의 _attribute_ 키워드를 사용하여 입력 계층의 가중치 행렬을 구성하는 열들 각각을 하나의 페이지에 매핑시킨다. 본 발명의 실시예에서는 이러한 링커의 매핑 동작을 통해 플래시 메모리에 저장된 가중치 행렬의 열 을 수정할 수 있으며, 입력 이미지로부터 가중치 업데이트가 필요한 픽셀을 결정하는 것이 가능한 경우 그 픽셀 과 연관된 가중치만을 부분적으로 업데이트할 수 있다. 도 3은 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 알고리즘의 예를 나타낸 도면이다. 도시된 알고리즘(Algorithm) 1은 플래시 메모리의 페이지들 중 업데이트가 필요한 페이지가 결정되면, 업데이트 가 필요한 페이지에 저장된 가중치만을 부분적으로 업데이트하는 과정을 나타낸 것이다. 플래시 메모리의 페이지들 중 i번째 페이지, 즉 pageup[i]에 저장된 가중치에 대해 업데이트가 필요한 경 우,(line 7) pageup[i], 즉 pageup[i]에 저장된 가중치를 SRAM에 복사하여 가중치를 업데이트하고,(lines 8-9) pageup[i]에 저장된 가중치를 상기 SRAM을 통해 업데이트된 가중치로 대체한다.(line 10) 즉 pageup[i]에 재쓰기 (rewrite) 작업을 수행하여 상기 SRAM을 통해 업데이트된 가중치를 저장한다. 이와 같이 플래시 메모리에 저장된 가중치의 일부만을 업데이트하기 위해서는 신경망 모델 학습의 추론 정확도 에 대한 손실을 최소화하고 메모리 사용률이 최적화되도록 가중치를 선별하는 것이 매우 중요하다. 이하에서는 도 4를 통해 도 3의 알고리즘 1에서 업데이트가 필요한 페이지를 결정하는 과정, 즉 플래시 메모리 에 저장된 가중치 행렬에서 업데이트가 필요한 가중치 열을 선별하는 과정에 대하여 보다 상세히 설명하도록 한 다. 도 4는 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치를 선별하여 업데이트하는 동작의 예를 나타낸 도면이다. 본 발명의 실시예에 따른 가중치 업데이트 장치는 업데이트가 필요한 가중치 열을 선별하는데 사용되는 기울기 평균 벡터 간의 변화량 Δavg_grad를 다음과 같은 절차에 따라 계산한다. 즉 가중치 업데이트 장치는 신경망 모델의 은닉 계층에서 발생된 오차 벡터(error2)와 상기 신경망 모델의 입력 계층 활성화 함수의 결과 벡터(a1)의 곱으로, 신경망 모델의 학습에 따라 발생되는 현재 시점 t에 대한 기울기 평균 벡터 avg_grad [t]와, 이전 시점 t-1에 대한 기울기 평균 벡터 avg_grad [t-1]을 산출한다. 여기서 l1은 상기 입력 계층의 크기를 나타내고, l2는 상기 은닉 계층의 크기를 나타낸다. 오차 벡터(error2)와 활성화 함수의 결과 벡터(a1)의 곱셈은 l2 x l1 크기의 기울기 행렬을 생성하고, 활성화 함 수의 결과 벡터(a1)의 n번째 원소(element)와 오차 벡터(error2)를 MAC(Multiply-Accumulate) 연산하고 l2로 나 누어 시간 t에 대한 기울기 평균 벡터 avg_grad[t]를 계산한다. 그런 다음 가중치 업데이트 장치는 상기 계산한 t에 대한 기울기 평균 벡터 avg_grad[t]를 t-1에 대한 기울기 평균 벡터 avg_grad[t-1]과 비교하여 하기 수학식 1과 같이 기울기 평균 벡터 간의 변화량 Δavg_grad[t]를 계 산한다. 수학식 1"}
{"patent_id": "10-2023-0140511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1을 통해 기울기 평균 벡터의 변화량 Δavg_grad[t]를 계산한 가중치 업데이트 장치는 상기 계산한 Δ avg_grad[t]와 미리 정해진 임계 값 TH를 기반으로 플래시 메모리에 저장된 가중치 행렬에서 업데이트가 필요한 가중치 열을 선별한다. 이때 가중치 업데이트 장치는 상기 계산한 Δavg_grad[t]가 임계 값 TH을 초과하는 열에 대하여 상기 업데이트가 필요한 가중치 열로 선별한다. 종래의 완전 연결(FC: Fully Connected) 계층 역전파(backpropagation)는 기울기 행렬 계산을 위해 l1 x l2 크 기의 런타임 메모리를 필요로 하였으나, 본 발명의 실시예에 따른 가중치를 업데이트 방법은 시간 t에서 Δavg grad[t-1]을 저장하기 위한 메모리만을 필요로 하므로 런타임 메모리 사용량을 l1 x N 으로 감소시킨다. 여기서 N은 가중치 행렬 중 임계 값 TH를 초과하여 업데이트 대상으로 선택된 열의 수를 나타낸다. 또한 본 발명의 실시예에 따른 가중치 업데이트 방법은 Δavg_grad와 임계값 TH의 비교를 기반으로 Δavg_grad 와 선별된 가중치 열 업데이트를 연산하는 과정에서 제자리(in-place) 연산을 통해 런타임 메모리 사용량을 최 소화한다. 여기서 상기 메모리 사용량(Memory Usage)은 하기 수학식 2와 같이 계산될 수 있다. 수학식 2"}
{"patent_id": "10-2023-0140511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이후 가중치 업데이트 장치는 도 3에서 설명한 바와 같이, 플래시 메모리에 저장된 가중치 행렬에서 선별된 가 중치 열에 대응하는 페이지를 SRAM에 복사하여 가중치를 업데이트하고, 상기 플래시 메모리의 페이지 재쓰기 작 업을 수행하여 상기 SRAM을 통해 업데이트된 가중치 열을 저장한다. 이하에서는 도 5를 통해 업데이트할 가중치 열 선별 시 적용되는 임계 값을 결정하는 방법에 대하여 보다 상세 히 설명하도록 한다. 도 5는 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 방법에서 적용되는 임계 값을 결정 하는 예를 나타낸 그래프이다.본 발명의 실시예에 따른 가중치 업데이트 방법은 선별된 가중치만 부분적으로 업데이트하므로 훈련 비용을 감 소시킬 수는 있지만 추론 정확도 또한 감소될 우려가 있다. 따라서 추론 정확도를 유지하면서 업데이트할 가중치를 선별하기 위해, 본 발명의 실시예에서는 각 입력 이미지 픽셀에 전파되는 기울기 변화량을 고려하여 가중치 열 선별 시 적용되는 임계 값을 결정한다. 도 5(a)는 28 x 28 MNIST 데이터셋을 이용한 FC 모델 트레이닝 과정 중 각 트레이닝 단계에서 은닉 계층에서 784개의 평탄화된(attened) 입력 이미지 특징(feature)에 전파된 평균 기울기와 이전 단계의 평균 기울기 사이 의 차이 Δavg_grad를 나타낸 것이다. 도 5(a)에서 확인할 수 있는 바와 같이, 입력 이미지 특징의 Δavg_grad는 실제 MNIST 데이터 세트에 번호가 기 록된 이미지 중심에 해당하는 전체 입력 이미지 특징 위치에 걸쳐 높게 형성됨을 알 수 있다. 도 5(b)는 우세한(dominant) Δavg_grad 전파 픽셀을 필터링하기 위해 임계 값 TH를 정의할 때 Δavg_grad가 임계 값 TH보다 큰 특징 인덱스의 비율을 나타낸 것이다. 이와 같이 본 발명에서는 Δavg_grad가 임계 값 TH보다 큰 입력 이미지 특징 인덱스에 대응한 가중치에 대해서 만 부분적으로 업데이트하는 기법을 제안한다. 임계 값 TH가 작을수록 부분적으로 업데이트할 커버리지가 커지 며, TH = 0.0005일 때 전체 특징 차원(dimension)에 대한 비율은 24.5%이며, 이 경우 사용된 임계 값 TH는 도 5(a)에 나타낸 바와 같이 0.0005, 0.001, 0.005, 0.01, 0.015, 0.02가 됨을 알 수 있다. 도 6은 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 장치의 가중치 업데이트 방법을 나 타낸 순서도이다. 가중치 업데이트 장치는 신경망 모델의 가중치 행렬을 열 단위로 분할하고,(S601) 분할된 가중치 열을 플래시 메모리의 각 페이지에 매핑시켜 저장한다.(S603) 그런 다음 가중치 업데이트 장치는 S603에서 저장한 가중치 행렬에서 신경망 모델의 학습에 따른 업데이트가 필 요한 가중치 열을 선별하고,(S605) S605에서 선별된 가중치 열에 대응하는 플래시 메모리의 페이지를 SRAM에 복 사하여 가중치를 업데이트한다.(S607) 이후 가중치 업데이트 장치는 상기 플래시 메모리의 페이지에 재쓰기 작업을 수행하여, S607에서 SRAM을 통해 업데이트한 가중치를 상기 플래시 메모리의 페이지에 저장한다. 위와 같은 본 발명의 신경망 모델의 온-디바이스 학습을 위한 가중치 업데이트 방법은 다양한 컴퓨터 구성요소 를 통하여 수행될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로그램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM, DVD 와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨 어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사 용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치는 본 발명에 따른 처 리를 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상에서는 본 발명의 다양한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시예에 한정"}
{"patent_id": "10-2023-0140511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야에서 통상 의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사 상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2023-0140511", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 장치의 내부 구조를 나타낸 도면, 도 2는 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 장치에 포함되는 링커의 매핑 동작 의 예를 나타낸 도면, 도 3은 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 알고리즘의 예를 나타낸 도면, 도 4는 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 동작의 예를 나타낸 도면, 도 5는 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 방법에서 적용되는 임계 값을 결정 하는 예를 나타낸 그래프, 그리고, 도 6은 본 발명의 실시예에 따른 온-디바이스 학습을 위한 가중치 업데이트 장치의 가중치 업데이트 방 법을 나타낸 순서도."}
