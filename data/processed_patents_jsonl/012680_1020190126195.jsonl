{"patent_id": "10-2019-0126195", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0122606", "출원번호": "10-2019-0126195", "발명의 명칭": "차량 내 객체 모니터링 장치 및 방법", "출원인": "엘지전자 주식회사", "발명자": "김현규"}}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 영상 및 제2 영상을 이용하여 차량 내 객체를 모니터링하는 장치로서,상기 차량 내 제1 카메라에 의해 생성된 제1 영상 및 상기 차량 내 제2 카메라에 의해 생성된 제2 영상을 수신하는 인터페이스; 및상기 제1 영상 및 상기 제2 영상 각각에 객체가 존재하는 것으로 판단되면, 상기 제1 영상으로부터 상기 객체에대한 제1 특징 정보를 추출하고, 상기 제2 영상으로부터 상기 객체에 대한 제2 특징 정보를 추출하며, 상기 제1특징 정보 및 상기 제2 특징 정보에 기초하여, 상기 객체의 상태를 인식하는 프로세서를 포함하는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 카메라는, 초음파 센서를 이용하여 상기 제1 영상으로서, 초음파 영상을 생성하고,상기 제2 카메라는, RGB(Red, Green, Blue) 센서 또는 IR(Infrared Radiation) 센서를 이용하여, 상기 제2 영상으로서, RGB 영상 또는 IR 영상을 생성하는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 제1 영상 및 상기 제2 영상에, 객체 종류 예측 알고리즘을 각각 적용하여 상기 객체의 종류를 예측하고,상기 제1 영상 및 상기 제2 영상과 함께 상기 예측된 객체의 종류에, 객체의 영역 추정 알고리즘을 각각 적용하여 상기 객체의 가변영역을 추정하며, 상기 추정된 객체의 가변영역에 객체의 특징 추출 알고리즘을 각각 적용하여, 상기 제1 특징 정보 및 상기 제2 특징 정보를 추출하는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 객체 종류 예측 알고리즘은,수집된 제1 영상 및 제2 영상 중 적어도 하나의 영상에서 객체의 종류를 인식하도록 훈련된 신경망 모델이고,상기 객체의 영역 추정 알고리즘은,상기 객체의 종류에 기초하여, 상기 영상에서 상기 객체에 대응하는 가변영역을 설정하도록 훈련된 신경망 모델이며,상기 객체의 특징 추출 알고리즘은,상기 영상의 종류 및 상기 객체의 종류가 분류되는 카테고리에 기초하여, 상기 객체에 대응하는 가변영역에서상기 제1 특징 정보 또는 상기 제2 특징 정보 중 어느 하나의 특징 정보를 인식하도록 훈련된 신경망 모델인,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2019-0122606-3-제1항에 있어서,상기 객체의 종류가 움직임이 가능한 능동적 객체로 분류되는 경우,상기 프로세서는,상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 이목구비에 대한 제1 지점을추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 이목구비에 대한 제2 지점을 추출하며,상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지점에 대응하는 영상으로 대체시켜, 상기 객체의 상태를 인식하는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는,주행하는 상기 차량 내 상기 객체의 종류가 운전자일 경우,상기 객체의 상태로서 인식된 운전자의 시선이 설정된 범위를 설정된 시간 동안 벗어나면, 사고 위험 경고를 발생하는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 프로세서는,주행하는 상기 차량 내 상기 객체의 종류가 운전자이고, 상기 운전자의 시선이 상기 차량 내 디스플레이를 향하는지의 여부 및 상기 운전자의 머리가 향하는 방향에 기초하여, 상기 디스플레이의 백라이트 전원을 제어하는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 객체의 종류가 움직임이 불가능한 수동적 객체로 분류되는 경우,상기 프로세서는,상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 고유정보에 대한 제1 지점을추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 고유정보에 대한 제2 지점을 추출하며,상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지점에 대응하는 영상으로 대체시켜, 상기 객체의 상태를 인식하는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 객체에서의 고유정보는 상표명인,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,공개특허 10-2019-0122606-4-상기 인터페이스는,상기 제1 카메라 및 상기 제2 카메라로부터 설정된 주기 마다 각각 상기 제1 영상 및 상기 제2 영상을수신하고,상기 프로세서는,상기 주기적으로 수신되는 제1 영상 및 제2 영상에 기초하여, 상기 차량 내 설정된 공간에 위치하는 객체가 상기 공간의 외부로 이동하는 것으로 확인되면, 상기 이동된 객체의 상태를 인식하는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 프로세서는,상기 공간에 배치된 객체가 종류별로 설정된 기준에 미달하는 경우,미달된 종류에 해당하는 객체의 식별정보를 상기 차량을 기준으로 설정된 거리 내에 위치하는 상점 내 상점 단말로 제공하고, 상기 차량에 설치된 드론으로 하여금, 상기 상점으로 이동하여, 상기 객체의 식별정보에 대응하는 상품을 획득하여 상기 차량에 공급하도록 하는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는,상기 드론의 배터리 용량을 확인하고, 상기 배터리 용량에 기초하여 상기 상점에 대한 상기 드론의 왕복이 가능한 경우, 상기 드론을 상기 상점으로 이동시키는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 프로세서는,상기 차량의 주행 속도 및 상기 드론의 왕복 시간 중 적어도 하나에 기초하여, 상기 차량이 주행하는 경로에 포함되는 상점을 선택하고, 상기 선택된 상점 내 상점 단말로 상기 객체의 식별정보를 제공하는,차량 내 객체 모니터링 장치."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1 영상 및 제2 영상을 이용하여 차량 내 객체를 모니터링하는 방법으로서,상기 차량 내 제1 카메라에 의해 생성된 제1 영상 및 상기 차량 내 제2 카메라에 의해 생성된 제2 영상을 수신하는 단계; 및상기 제1 영상 및 상기 제2 영상 각각에 객체가 존재하는 것으로 판단되면, 상기 제1 영상으로부터 상기 객체에대한 제1 특징 정보를 추출하고, 상기 제2 영상으로부터 상기 객체에 대한 제2 특징 정보를 추출하며, 상기 제1특징 정보 및 상기 제2 특징 정보에 기초하여, 상기 객체의 상태를 인식하는 단계를 포함하는,차량 내 객체 모니터링 방법."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,공개특허 10-2019-0122606-5-상기 제1 카메라는, 초음파 센서를 이용하여 상기 제1 영상으로서, 초음파 영상을 생성하고,상기 제2 카메라는, RGB 센서 또는 IR 센서를 이용하여, 상기 제2 영상으로서, RGB 영상 또는 IR 영상을 생성하는,차량 내 객체 모니터링 방법."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 객체의 상태를 인식하는 단계는,상기 제1 영상 및 상기 제2 영상에, 객체 종류 예측 알고리즘을 각각 적용하여 상기 객체의 종류를 예측하는 단계;상기 제1 영상 및 상기 제2 영상과, 함께 상기 예측된 객체의 종류에 객체의 영역 추정 알고리즘을 각각 적용하여 상기 객체의 가변영역을 추정하는 단계; 및상기 추정된 객체의 가변영역에 객체의 특징 추출 알고리즘을 각각 적용하여, 상기 제1 특징 정보 및 상기 제2특징 정보를 추출하는 단계를 포함하는,차량 내 객체 모니터링 방법."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 객체의 상태를 인식하는 단계는,상기 객체의 종류가 움직임이 가능한 능동적 객체로 분류되는 경우,상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 이목구비에 대한 제1 지점을추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 이목구비에 대한 제2 지점을 추출하는단계; 및상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지점에 대응하는 영상으로 대체시켜, 상기 객체의 상태를 인식하는 단계를 포함하는,차량 내 객체 모니터링 방법."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서,상기 객체의 상태를 인식하는 단계는,상기 객체의 종류가 움직임이 불가능한 수동적 객체로 분류되는 경우,상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 고유정보에 대한 제1 지점을추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 고유정보에 대한 제2 지점을 추출하는단계; 및상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지점에 대응하는 영상으로 대체시켜, 상기 객체의 상태를 인식하는 단계를 포함하는,차량 내 객체 모니터링 방법."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제14항에 있어서,상기 객체의 상태를 인식하는 단계는,상기 주기적으로 수신되는 제1 영상 및 제2 영상에 기초하여, 상기 차량 내 설정된 공간에 위치하는 객체가 상공개특허 10-2019-0122606-6-기 공간의 외부로 이동하는 것으로 확인되면, 상기 이동된 객체의 상태를 인식하는 단계를 포함하는,차량 내 객체 모니터링 방법."}
{"patent_id": "10-2019-0126195", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 차량 내 객체 모니터링 방법은,상기 객체의 상태를 인식하는 단계 이후,상기 공간에 배치된 객체가 종류별로 설정된 기준에 미달하는 경우,미달된 종류에 해당하는 객체의 식별정보를 상기 차량을 기준으로 설정된 거리 내에 위치하는 상점 내 상점 단말로 제공하는 단계; 및상기 차량에 설치된 드론으로 하여금, 상기 상점으로 이동하여, 상기 객체의 식별정보에 대응하는 상품을 획득하여 상기 차량에 공급하도록 하는 단계를 더 포함하는,차량 내 객체 모니터링 방법."}
{"patent_id": "10-2019-0126195", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 지능 알고리즘을 통해, 상이한 종류의 영상으로부터 객체의 상태를 인지하는 차량 내 객체 모니터링 장치 및 방법이 개시된다. 차량 내 객체 모니터링 장치는 제1 영상 및 제2 영상을 이용하여 차량 내 객체를 모니터링 하는 장치로서, 상기 차량 내 제1 카메라에 의해 생성된 제1 영상 및 상기 차량 내 제2 카메라에 의해 생성된 제 2 영상을 수신하는 인터페이스와, 상기 제1 영상 및 상기 제2 영상 각각에 객체가 존재하는 것으로 판단되면, 상 기 제1 영상으로부터 상기 객체에 대한 제1 특징 정보를 추출하고, 상기 제2 영상으로부터 상기 객체에 대한 제2 특징 정보를 추출하며, 상기 제1 특징 정보 및 상기 제2 특징 정보에 기초하여, 상기 객체의 상태를 인식하는 프 로세서를 포함할 수 있다."}
{"patent_id": "10-2019-0126195", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 다양한 센서를 이용하여 생성된 상이한 종류의 영상에 기초하여, 영상 내 객체의 상태를 정확히 인식 하는 차량 내 객체 모니터링 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0126195", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "주변 상황에 대한 영상을 얻기 위해서 다양한 카메라가 이용되고 있다. 예컨대, 초음파 센서를 이용한 초음파 카메라, RGB(Red, Green, Blue) 센서를 이용한 RGB 카메라, IR(Infrared Radiation) 센서를 이용한 IR 카메라 등이 활용되고 있다. 그러나, 초음파 카메라는 센서는 투명한 물체, 액체, 반사도가 매우 높은 표면 또는 금속 표면을 감지할 때 유 용하나, 영상 내 객체의 상세한 부분(예컨대, 사람일 경우 이목구비, 물건일 경우 상표명 등)을 파악하기가 어 렵다. 반면, RGB 카메라 및 IR 카메라는 객체에 강한 빛이 비춰지는 경우, 객체에 대한 영상을 정확하게 획득하기 어 려울 수 있고, 상기 영상에 뎁스(depth) 정보가 포함되지 않음에 따라, 상기 영상 내 객체의 거리(또는 위치)를 파악하기가 어렵다. 한편, 선행기술에는 다양한 종류의 영상(예컨대, 가시광선 영상, 적외선 영상 및 밀리미터파 영상)을 합성하는 방법을 개시하고 있으나, 다양한 종류의 영상 중 두 개의 영상을, 사용자의 선택, 시간 또는 날씨에 따라 합성 할 뿐, 영상 내 객체의 상태를 보다 정확하게 파악할 수는 없다. 따라서, 다양한 센서를 이용하여, 어떠한 환경에서도 객체의 상태를 정확하게 인지할 수 있는 기술이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 선행기술: 한국 공개특허공보 제10-2009-0079658호"}
{"patent_id": "10-2019-0126195", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일실시예는, 카메라에서 다양한 센서(예컨대, 초음파 센서, RGB 센서, IR 센서)를 이용하여 상이한 종류의 영상이 생성되면, 상이한 종류의 영상 내 일부 영역을 합성하여, 환경 변화(예컨대, 객체에 강한 빛이 비춰질 때, 객체의 소재를 특정 센서가 감지하기 어려운 환경 등)에 영향을 받지 않고, 영상 내 객체의 상태를 용이하게 인식하는 것을 목적으로 한다. 본 발명의 일실시예는, 차량 내 제1 카메라에 의해 생성된 제1 영상 및 차량 내 제2 카메라에 의해 생성된 제2 영상 각각에, 객체가 존재하는 것으로 판단되면, 상기 제1 영상으로부터 상기 객체에 대한 제1 특징 정보를 추 출하고, 상기 제2 영상으로부터 상기 객체에 대한 제2 특징 정보를 추출하며, 상기 제1 특징 정보 및 상기 제2 특징 정보에 기초하여, 제1 영상과 제2 영상의 각각의 일부를 매칭시킴으로써, 상기 객체의 상태를 정확하게 인 식하는 것을 목적으로 한다. 본 발명의 일실시예는, 제1 영상으로부터 객체의 위치를 추출 함으로써, 공간 상에서 상기 객체의 위치를 인지 할 수 있게 하는 것을 목적으로 한다. 본 발명의 일실시예는, 제1 영상 및 제2 영상에 기초하여, 주행하는 차량 내 객체의 종류가 운전자로 예측되고, 운전자의 상태에 기초하여 사고 위험이 발생할 것으로 판단되면, 사고 위험 경고를 발생하여 사고를 미연에 방 지하거나, 또는 운전자의 상태에 기초하여 차량 내 디스플레이의 백라이트 전원을 제어 함으로써, 배터리 소모 를 절약할 수 있게 하는 것을 목적으로 한다. 또한, 본 발명의 일실시예는, 제1 영상 및 제2 영상에 기초하여, 차량 내 설정된 공간에 위치하는 객체가 상기 공간의 외부로 이동하는 것으로 확인되면, 상기 이동한 객체의 상태를 인식하여 상기 공간에 존재하는 상품의 수량을 관리할 수 있게 하는 것을 목적으로 한다."}
{"patent_id": "10-2019-0126195", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일실시예는, 제1 영상 및 제2 영상을 이용하여 차량 내 객체를 모니터링하는 장치로서, 상기 차량 내 제1 카메라에 의해 생성된 제1 영상 및 상기 차량 내 제2 카메라에 의해 생성된 제2 영상을 수신하는 인터페이 스와, 상기 제1 영상 및 상기 제2 영상 각각에 객체가 존재하는 것으로 판단되면, 상기 제1 영상으로부터 상기 객체에 대한 제1 특징 정보를 추출하고, 상기 제2 영상으로부터 상기 객체에 대한 제2 특징 정보를 추출하며, 상기 제1 특징 정보 및 상기 제2 특징 정보에 기초하여, 상기 객체의 상태를 인식하는 프로세서를 포함하는, 차 량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 상기 제1 카메라가, 초음파 센서를 이용하여 상기 제1 영상으로서, 초음파 영상을 생성 하고, 상기 제2 카메라가, RGB(Red, Green, Blue) 센서 또는 IR(Infrared Radiation) 센서를 이용하여, 상기 제2 영상으로서, RGB 영상 또는 IR 영상을 생성하는, 차량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 상기 프로세서가, 상기 제1 영상 및 상기 제2 영상에, 객체 종류 예측 알고리즘을 각각 적용하여 상기 객체의 종류를 예측하고, 상기 제1 영상 및 상기 제2 영상과 함께 상기 예측된 객체의 종류에, 객체의 영역 추정 알고리즘을 각각 적용하여 상기 객체의 가변영역을 추정하며, 상기 추정된 객체의 가변영역에 객체의 특징 추출 알고리즘을 각각 적용하여, 상기 제1 특징 정보 및 상기 제2 특징 정보를 추출하는, 차량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 상기 객체 종류 예측 알고리즘이, 수집된 제1 영상 및 제2 영상 중 적어도 하나의 영상 에서 객체의 종류를 인식하도록 훈련된 신경망 모델이고, 상기 객체의 영역 추정 알고리즘이, 상기 객체의 종류 에 기초하여, 상기 영상에서 상기 객체에 대응하는 가변영역을 설정하도록 훈련된 신경망 모델이며, 상기 객체 의 특징 추출 알고리즘이, 상기 영상의 종류 및 상기 객체의 종류가 분류되는 카테고리에 기초하여, 상기 객체 에 대응하는 가변영역에서 상기 제1 특징 정보 또는 상기 제2 특징 정보 중 어느 하나의 특징 정보를 인식하도 록 훈련된 신경망 모델인, 차량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 상기 객체의 종류가 움직임이 가능한 능동적 객체로 분류되는 경우, 상기 프로세서가, 상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 이목구비에 대한 제1 지점을 추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 이목구비에 대한 제2 지점을 추출하며, 상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지점에 대응하는 영상으로 대 체시켜, 상기 객체의 상태를 인식하는, 차량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 상기 프로세서가, 주행하는 상기 차량 내 상기 객체의 종류가 운전자일 경우, 상기 객체 의 상태로서 인식된 운전자의 시선이 설정된 범위를 설정된 시간 동안 벗어나면, 사고 위험 경고를 발생하는, 차량 내 객체 모니터링 장치일 수 있다.본 발명의 일실시예는, 상기 프로세서가, 주행하는 상기 차량 내 상기 객체의 종류가 운전자이고, 상기 운전자 의 시선이 상기 차량 내 디스플레이를 향하는지의 여부 및 상기 운전자자의 머리가 향하는 방향에 기초하여, 상 기 디스플레이의 백라이트 전원을 제어하는, 차량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 상기 객체의 종류가 움직임이 불가능한 수동적 객체로 분류되는 경우, 상기 프로세서가, 상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 고유정보에 대한 제1 지점을 추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 고유정보에 대한 제2 지점을 추출하며, 상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지점에 대응하는 영상으로 대 체시켜, 상기 객체의 상태를 인식하는, 차량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 상기 객체에서의 고유정보는 상표명인, 차량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 상기 인터페이스가, 상기 제1 카메라 및 상기 제2 카메라로부터 설정된 주기 마다 각각 상기 제1 영상 및 상기 제2 영상을 수신하고, 상기 프로세서가, 상기 주기적으로 수신되는 제1 영상 및 제2 영 상에 기초하여, 상기 차량 내 설정된 공간에 위치하는 객체가 상기 공간의 외부로 이동하는 것으로 확인되면, 상기 이동된 객체의 상태를 인식하는, 차량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 상기 프로세서가, 상기 공간에 배치된 객체가 종류별로 설정된 기준에 미달하는 경우, 미달된 종류에 해당하는 객체의 식별정보를 상기 차량을 기준으로 설정된 거리 내에 위치하는 상점 내 상점 단 말로 제공하고, 상기 차량에 설치된 드론으로 하여금, 상기 상점으로 이동하여, 상기 객체의 식별정보에 대응하 는 상품을 획득하여 상기 차량에 공급하도록 하는, 차량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 상기 프로세서가, 상기 드론의 배터리 용량을 확인하고, 상기 배터리 용량에 기초하여 상기 상점에 대한 상기 드론의 왕복이 가능한 경우, 상기 드론을 상기 상점으로 이동시키는, 차량 내 객체 모니 터링 장치일 수 있다. 본 발명의 일실시예는, 상기 프로세서가, 상기 차량의 주행 속도 및 상기 드론의 왕복 시간 중 적어도 하나에 기초하여, 상기 차량이 주행하는 경로에 포함되는 상점을 선택하고, 상기 선택된 상점 내 상점 단말로 상기 객 체의 식별정보를 제공하는, 차량 내 객체 모니터링 장치일 수 있다. 본 발명의 일실시예는, 제1 영상 및 제2 영상을 이용하여 차량 내 객체를 모니터링하는 방법으로서, 상기 차량 내 제1 카메라에 의해 생성된 제1 영상 및 상기 차량 내 제2 카메라에 의해 생성된 제2 영상을 수신하는 단계와, 상기 제1 영상 및 상기 제2 영상 각각에 객체가 존재하는 것으로 판단되면, 상기 제1 영상으로부터 상 기 객체에 대한 제1 특징 정보를 추출하고, 상기 제2 영상으로부터 상기 객체에 대한 제2 특징 정보를 추출하며, 상기 제1 특징 정보 및 상기 제2 특징 정보에 기초하여, 상기 객체의 상태를 인식하는 단계를 포함하 는, 차량 내 객체 모니터링 방법일 수 있다. 본 발명의 일실시예는, 상기 제1 카메라가, 초음파 센서를 이용하여 상기 제1 영상으로서, 초음파 영상을 생성 하고, 상기 제2 카메라가, RGB 센서 또는 IR 센서를 이용하여, 상기 제2 영상으로서, RGB 영상 또는 IR 영상을 생성하는, 차량 내 객체 모니터링 방법일 수 있다. 본 발명의 일실시예는, 상기 객체의 상태를 인식하는 단계가, 상기 제1 영상 및 상기 제2 영상에, 객체 종류 예 측 알고리즘을 각각 적용하여 상기 객체의 종류를 예측하는 단계와, 상기 제1 영상 및 상기 제2 영상과 함께 상 기 예측된 객체의 종류에, 객체의 영역 추정 알고리즘을 각각 적용하여 상기 객체의 가변영역을 추정하는 단계 와, 상기 추정된 객체의 가변영역에 객체의 특징 추출 알고리즘을 각각 적용하여, 상기 제1 특징 정보 및 상기 제2 특징 정보를 추출하는 단계를 포함하는, 차량 내 객체 모니터링 방법일 수 있다. 본 발명의 일실시예는, 상기 객체의 상태를 인식하는 단계가, 상기 객체의 종류가 움직임이 가능한 능동적 객체 로 분류되는 경우, 상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 이목구비 에 대한 제1 지점을 추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 이목구비에 대한 제 2 지점을 추출하는 단계와, 상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지 점에 대응하는 영상으로 대체시켜, 상기 객체의 상태를 인식하는 단계를 포함하는, 차량 내 객체 모니터링 방법 일 수 있다. 본 발명의 일실시예는, 상기 객체의 상태를 인식하는 단계가, 상기 객체의 종류가 움직임이 불가능한 수동적 객 체로 분류되는 경우, 상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 고유정 보에 대한 제1 지점을 추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 고유정보에 대한제2 지점을 추출하는 단계와, 상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지점에 대응하는 영상으로 대체시켜, 상기 객체의 상태를 인식하는 단계를 포함하는, 차량 내 객체 모니터링 방 법일 수 있다. 본 발명의 일실시예는, 상기 객체의 상태를 인식하는 단계가, 상기 주기적으로 수신되는 제1 영상 및 제2 영상 에 기초하여, 상기 차량 내 설정된 공간에 위치하는 객체가 상기 공간의 외부로 이동하는 것으로 확인되면, 상 기 이동된 객체의 상태를 인식하는 단계를 포함하는, 차량 내 객체 모니터링 방법일 수 있다. 본 발명의 일실시예는, 상기 객체의 상태를 인식하는 단계 이후, 상기 공간에 배치된 객체가 종류별로 설정된 기준에 미달하는 경우, 미달된 종류에 해당하는 객체의 식별정보를 상기 차량을 기준으로 설정된 거리 내에 위 치하는 상점 내 상점 단말로 제공하는 단계와, 상기 차량에 설치된 드론으로 하여금, 상기 상점으로 이동하여, 상기 객체의 식별정보에 대응하는 상품을 획득하여 상기 차량에 공급하도록 하는 단계를 더 포함하는, 차량 내 객체 모니터링 방법일 수 있다. 이 외에도, 본 발명을 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램이 저장된 컴퓨터로 판독 가능한 기록매체가 더 제공될 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2019-0126195", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 카메라에서 다양한 센서(예컨대, 초음파 센서, RGB 센서, IR 센서)를 이용하여 상이한 종류 의 영상이 생성되면, 상이한 종류의 영상 내 일부 영역을 합성하여, 환경 변화(예컨대, 객체에 강한 빛이 비춰 질 때, 객체의 소재를 특정 센서가 감지하기 어려운 환경 등)에 영향을 받지 않고, 영상 내 객체의 상태를 용이 하게 인식할 수 있다. 본 발명에 따르면, 차량 내 제1 카메라에 의해 생성된 제1 영상 및 차량 내 제2 카메라에 의해 생성된 제2 영상 각각에, 객체가 존재하는 것으로 판단되면, 상기 제1 영상으로부터 상기 객체에 대한 제1 특징 정보를 추출하고, 상기 제2 영상으로부터 상기 객체에 대한 제2 특징 정보를 추출하며, 상기 제1 특징 정보 및 상기 제 2 특징 정보에 기초하여, 제1 영상과 제2 영상의 각각의 일부를 매칭시킴으로써, 상기 객체의 상태를 정확하게 인식할 수 있다. 본 발명에 의하면, 제1 영상으로부터 객체의 위치를 추출 함으로써, 공간 상에서 상기 객체의 위치를 인지할 수 있다. 본 발명에 따르면, 제1 영상 및 제2 영상에 기초하여, 주행하는 차량 내 객체의 종류가 운전자로 예측되고, 운 전자의 상태에 기초하여 사고 위험이 발생할 것으로 판단되면, 사고 위험 경고를 발생하여 사고를 미연에 방지 하거나, 또는 운전자의 상태에 기초하여 차량 내 디스플레이의 백라이트 전원을 제어 함으로써, 배터리 소모를 절약할 수 있게 한다. 또한, 본 발명에 의하면, 제1 영상 및 제2 영상에 기초하여, 차량 내 설정된 공간에 위치하는 객체가 상기 공간 의 외부로 이동하는 것으로 확인되면, 상기 이동한 객체의 상태를 인식하여 상기 공간에 존재하는 상품의 수량 을 관리할 수 있게 한다."}
{"patent_id": "10-2019-0126195", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수개의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 명세서에서 기술되는 차량은, 동력원으로서 엔진을 구비하는 내연기관 차량, 동력원으로서 엔진과 전기 모터 를 구비하는 하이브리드 차량, 동력원으로서 전기 모터를 구비하는 전기 차량 등을 모두 포함하는 개념일 수 있 다. 도 1은 본 발명의 실시예에 따른 차량 내 객체 모니터링 장치가 적용되는 차량을 도시한 도면이다. 도 1을 참조하면, 차량 내 객체 모니터링 장치가 적용되는 차량에는, 상이한 종류의 제1 카메라 및 제2 카메라가 설치될 수 있으며, 1개 이상의 위치(예컨대, 차량 내 앞좌석의 상측, 뒷자석의 상측)에 제1 및 제2 카메라가 설치될 수 있다. 여기서, 제1 카메라는 예컨대, 초음파 센서를 이용하여 초음파 영상을 생성하는 초음파 카메라일 수 있다. 또한, 제2 카메라는 RGB(Red, Green, Blue) 센서를 이용하여 RGB 영상을 생성하는 RGB 카메라, IR(Infrared Radiation) 센서를 이용하여 IR 영상을 생성하는 IR 카메라 및 TOF(Time of Flight) 센서를 이용하여, TOF 영상을 생성하는 TOF 카메라 중 어느 하나의 카메라일 수 있다. 상기 초음파 영상은 뎁스 정보를 포함하는 제1 영상일 수 있으며, RGB 영상, IR 영상 및 TOF 영상은 뎁스 정보 를 포함하지 않은 제2 영상일 수 있다. 본 발명의 실시예에 따른 차량 내 객체 모니터링 장치는 차량의 내부에 탑재되어, 차량의 내부를 촬 영하는 제1 카메라 및 제2 카메라로부터 제1 영상 및 제2 영상을 각각 수신할 수 있으며, 제1 영상 및 제2 영상에 기초하여, 차량의 내부를 모니터링할 수 있다. 예컨대, 차량 내 객체 모니터링 장치는 제1 영상 및 제2 영상으로부터 차량 내 객체를 식별할 수 있으며, 객체 식별 결과에 기초하여, 다양한 기능(예컨대, 차량 의 사고위험 경고발생, 차량 내 디스플레이 전원 제어, 차량 내 스낵바 상품 관리 등)을 제공할 수 있다. 도 2는 본 발명의 실시예에 따른 차량 내 객체 모니터링 장치가 적용되는 시스템을 도시한 블록도이다. 도 2를 참조하면, 차량 내 객체 모니터링 장치가 적용되는 시스템은 차량에 포함될 수 있으며, 통신 부, 제어부, 사용자 인터페이스부, 오브젝트 검출부, 운전 조작부, 차량 구동부 , 운행부, 센싱부, 저장부 및 차량 내 객체 모니터링 장치를 포함할 수 있다. 실시예에 따라 차량 내 객체 모니터링 장치가 적용되는 시스템은, 도 2에 도시되고 이하 설명되는 구성 요소 외 에 다른 구성요소를 포함하거나, 도 2에 도시되고 이하 설명되는 구성요소 중 일부를 포함하지 않을 수 있다. 차량은 주행 상황에 따라 자율 주행 모드에서 매뉴얼 모드로 전환되거나 매뉴얼 모드에서 자율 주행 모드 로 전환될 수 있다. 여기서, 주행 상황은 통신부에 의해 수신된 정보, 오브젝트 검출부에 의해 검출 된 외부 오브젝트 정보 및 내비게이션 모듈에 의해 획득된 내비게이션 정보 중 적어도 어느 하나에 의해 판단될 수 있다. 차량은 사용자 인터페이스부를 통하여 수신되는 사용자 입력에 따라 자율 주행 모드에서 매뉴얼 모드 로 전환되거나 매뉴얼 모드에서 자율 주행 모드로 전환될 수 있다. 차량이 자율 주행 모드로 운행되는 경우, 차량은 주행, 출차, 주차 동작을 제어하는 운행부의 제어에 따라 운행될 수 있다. 한편, 차량이 매뉴얼 모드로 운행되는 경우, 차량은 운전자의 기계적 운전 조작을 통한 입력에 의해 운행될 수 있다. 통신부는, 외부 장치와 통신을 수행하기 위한 모듈이다. 여기서, 외부 장치는, 사용자 단말기, 타 차량 또 는 서버일 수 있다. 통신부는, 통신을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 통신부는, 근거리 통신(Short range communication), GPS 신호 수신, V2X 통신, 광통신, 방송 송수신 및 ITS(Intelligent Transport Systems) 통신 기능을 수행할 수 있다. 실시예에 따라, 통신부는, 설명되는 기능 외에 다른 기능을 더 지원하거나, 설명되는 기능 중 일부를 지원 하지 않을 수 있다. 통신부는, 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless- Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 근 거리 통신을 지원할 수 있다. 통신부는, 근거리 무선 통신망(Wireless Area Networks)을 형성하여, 차량과 적어도 하나의 외부 장 치 사이의 근거리 통신을 수행할 수 있다. 통신부는, 차량의 위치 정보를 획득하기 위한 GPS(Global Positioning System) 모듈 또는 DGPS(Differential Global Positioning System) 모듈을 포함할 수 있다. 통신부는, 차량과 서버(V2I: Vehicle to Infra), 타 차량(V2V: Vehicle to Vehicle) 또는 보행자 (V2P: Vehicle to Pedestrian)와의 무선 통신을 지원하는 모듈, 즉, V2X 통신 모듈을 포함할 수 있다. V2X 통 신 모듈은, 인프라와의 통신(V2I), 차량간 통신(V2V), 보행자와의 통신(V2P) 프로토콜이 구현 가능한 RF 회로를포함할 수 있다. 통신부는, V2X 통신 모듈을 통하여, 타 차량이 송신하는 위험 정보 방송 신호를 수신할 수 있고, 위험 정 보 질의 신호를 송신하고 그에 대한 응답으로 위험 정보 응답 신호를 수신할 수 있다. 통신부는, 광을 매개로 외부 디바이스와 통신을 수행하기 위한 광통신 모듈을 포함할 수 있다. 광통신 모 듈은, 전기 신호를 광 신호로 전환하여 외부에 발신하는 광발신 모듈 및 수신된 광 신호를 전기 신호로 전환하 는 광수신 모듈을 포함할 수 있다. 실시예에 따라, 광발신 모듈은, 차량에 포함된 램프와 일체화되게 형성될 수 있다. 통신부는, 방송 채널을 통해, 외부의 방송 관리 서버로부터 방송 신호를 수신하거나, 방송 관리 서버에 방 송 신호를 송출하기 위한 방송 통신 모듈을 포함할 수 있다. 방송 채널은, 위성 채널, 지상파 채널을 포함할 수 있다. 방송 신호는, TV 방송 신호, 라디오 방송 신호, 데이터 방송 신호를 포함할 수 있다. 통신부는, 교통 시스템과 정보, 데이터 또는 신호를 교환하는 ITS 통신 모듈을 포함할 수 있다. ITS 통신 모듈은, 교통 시스템에 획득한 정보, 데이터를 제공할 수 있다. ITS 통신 모듈은, 교통 시스템으로부터, 정보, 데이터 또는 신호를 제공받을 수 있다. 예를 들면, ITS 통신 모듈은, 교통 시스템으로부터 도로 교통 정보를 수 신하여, 제어부에 제공할 수 있다. 예를 들면, ITS 통신 모듈은, 교통 시스템으로부터 제어 신호를 수신하 여 제어부 또는 차량 내부에 구비된 프로세서에 제공할 수 있다. 실시예에 따라, 통신부의 각 모듈은 통신부 내에 구비된 별도의 프로세서에 의해 전반적인 동작이 제 어될 수 있다. 통신부는, 복수개의 프로세서를 포함하거나, 프로세서를 포함하지 않을 수도 있다. 통신부 에 프로세서가 포함되지 않는 경우, 통신부는, 차량 내 다른 장치의 프로세서 또는 제어부(20 2)의 제어에 따라, 동작될 수 있다. 통신부는, 사용자 인터페이스부와 함께 차량용 디스플레이 장치를 구현할 수 있다. 이 경우, 차량용 디스플레이 장치는, 텔레매틱스(telematics) 장치 또는 AVN(Audio Video Navigation) 장치로 명명될 수 있다. 도 3은 5G 통신 시스템에서 자율 주행 차량과 5G 네트워크의 기본동작의 일 예를 나타낸 도면이다. 통신부는, 차량이 자율 주행 모드로 운행되는 경우, 특정 정보를 5G 네트워크로 전송할 수 있다(S1). 이 때, 특정 정보는 자율 주행 관련 정보를 포함할 수 있다. 자율 주행 관련 정보는, 차량의 주행 제어와 직접적으로 관련된 정보일 수 있다. 예를 들어, 자율 주행 관련 정보는 차량 주변의 오브젝트를 지시하는 오브젝트 데이터, 맵 데이터(map data), 차량 상태 데이터, 차량 위치 데이터 및 드라이빙 플랜 데이터(driving plan data) 중 하나 이상을 포함할 수 있다. 자율 주행 관련 정보는 자율 주행에 필요한 서비스 정보 등을 더 포함할 수 있다. 예를 들어, 특정 정보는, 사 용자 인터페이스부를 통해 입력된 목적지와 차량의 안정 등급에 관한 정보를 포함할 수 있다. 또한, 5G 네트워크는 차량의 원격 제어 여부를 결정할 수 있다(S2). 여기서, 5G 네트워크는 자율 주행 관련 원격 제어를 수행하는 서버 또는 모듈을 포함할 수 있다. 또한, 5G 네트워크는 원격 제어와 관련된 정보(또는 신호)를 자율 주행 차량으로 전송할 수 있다(S3). 전술한 바와 같이, 원격 제어와 관련된 정보는 자율 주행 차량에 직접적으로 적용되는 신호일 수도 있고, 나아 가 자율 주행에 필요한 서비스 정보를 더 포함할 수 있다. 본 발명의 일 실시예에서 자율 주행 차량은, 5G 네트 워크에 연결된 서버를 통해 주행 경로 상에서 선택된 구간별 보험과 위험 구간 정보 등의 서비스 정보를 수신함 으로써, 자율 주행과 관련된 서비스를 제공할 수 있다. 차량은 통신망을 통해 외부 서버에 연결되고, 자율 주행 기술을 이용하여 운전자 개입 없이 미리 설정된 경로를 따라 이동 가능하다. 이하의 실시예에서, 사용자는 운전자, 탑승자 또는 사용자 단말기의 소유자로 해석될 수 있다. 차량이 자율 주행 모드로 주행 중인 경우에, 주변 위험 요소들을 실시간 센싱하는 능력에 따라 사고 발생 유형 및 빈도가 크게 달라질 수 있다. 목적지까지의 경로는 날씨, 지형 특성, 교통 혼잡도 등 다양한 원인에 의해 위험 수준이 서로 다른 구간들을 포함할 수 있다.본 발명의 자율 주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Inteligence) 모듈, 드론(Unmanned Aerial Vehicle, UAV), 로봇, 증강 현실(Augmented Reality, AR) 장치, 가상 현실(virtual reality, VR), 5G 서비스와 관련된 장치 등과 연계 혹은 융복합될 수 있다. 예를 들어, 차량은 자율 주행 중에 차량에 포함된 적어도 하나의 인공지능 모듈, 로봇과 연계되어 동 작할 수 있다. 예를 들어, 차량은, 적어도 하나의 로봇(robot)과 상호 작용할 수 있다. 로봇은, 자력으로 주행이 가능한 이동 로봇(Autonomous Mobile Robot, AMR)일 수 있다. 이동 로봇은, 스스로 이동이 가능하여 이동이 자유롭고, 주행 중 장애물 등을 피하기 위한 다수의 센서가 구비되어 장애물을 피해 주행할 수 있다. 이동 로봇은, 비행 장치를 구비하는 비행형 로봇(예를 들면, 드론)일 수 있다. 이동 로봇은, 적어도 하나의 바퀴를 구비하고, 바퀴 의 회전을 통해 이동되는 바퀴형 로봇일 수 있다. 이동 로봇은, 적어도 하나의 다리를 구비하고, 다리를 이용해 이동되는 다리식 로봇일 수 있다. 로봇은 차량 사용자의 편의를 보완하는 장치로 기능할 수 있다. 예를 들면, 로봇은, 차량에 적재된 짐을 사용자의 최종 목적지까지 이동하는 기능을 수행할 수 있다. 예를 들면, 로봇은, 차량에서 하차한 사용자 에게 최종 목적지까지 길을 안내하는 기능을 수행할 수 있다. 예를 들면, 로봇은, 차량에서 하차한 사용자 를 최종 목적지까지 수송하는 기능을 수행할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 통신 장치를 통해, 로봇과 통신을 수행할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇에 차량에 포함되는 적어도 하나의 전자 장치에서 처리 한 데이터를 제공할 수 있다. 예를 들면, 차량에 포함되는 적어도 하나의 전자 장치는, 차량 주변의 오브 젝트를 지시하는 오브젝트 데이터, HD 맵 데이터(map data), 차량 상태 데이터, 차량 위치 데이터 및 드라이빙 플랜 데이터(driving plan data) 중 적어도 어느 하나를 로봇에 제공할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇으로부터, 로봇에서 처리된 데이터를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇에서 생성된 센싱 데이터, 오브젝트 데이터, 로봇 상태 데이터, 로봇 위치 데이터 및 로봇의 이동 플랜 데이터 중 적어도 어느 하나를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇으로부터 수신된 데이터에 더 기초하여, 제어 신호를 생 성할 수 있다. 예를 들면, 차량에 포함되는 적어도 하나의 전자 장치는, 오브젝트 검출 장치에 생성된 오브젝 트에 대한 정보와 로봇에 의해 생성된 오브젝트에 대한 정보를 비교하고, 비교 결과에 기초하여, 제어 신호를 생성할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 차량의 이동 경로와 로봇의 이동 경로간의 간섭이 발생되지 않도록, 제어 신호를 생성할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능(artificial intelligence, AI)을 구현하는 소프트 웨어 모듈 또는 하드웨어 모듈(이하, 인공 지능 모듈)을 포함할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 획득되는 데이터를 인공 지능 모듈에 입력(input)하고, 인공 지능 모듈에서 출력(output)되는 데이터를 이용할 수 있다. 인공 지능 모듈은, 적어도 하나의 인공 신경망(artificial neural network, ANN)을 이용하여, 입력되는 데이터 에 대한 기계 학습(machine learning)을 수행할 수 있다. 인공 지능 모듈은, 입력되는 데이터에 대한 기계 학습 을 통해, 드라이빙 플랜 데이터를 출력할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능 모듈에서 출력되는 데이터에 기초하여, 제어 신호 를 생성할 수 있다. 실시예에 따라, 차량에 포함되는 적어도 하나의 전자 장치는, 통신 장치를 통해, 외부 장치로부터, 인공 지능에 의해 처리된 데이터를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능에 의해 처리된 데이터에 기초하여, 제어 신호를 생성할 수 있다. 인공 지능(artificial intelligence, AI)은 인간의 지능으로 할 수 있는 사고, 학습, 자기계발 등을 컴퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보기술의 한 분야로, 컴퓨터가 인간의 지능적인 행동을 모방할 수 있도록 하는 것을 의미한다. 또한, 인공지능은 그 자체로 존재하는 것이 아니라, 컴퓨터 과학의 다른 분야와 직간접으로 많은 관련을 맺고 있다. 특히 현대에는 정보기술의 여러 분야에서 인공지능적 요소를 도입하여, 그 분야의 문제 풀이에 활용하려는 시도가 매우 활발하게 이루어지고 있다. 제어부는, ASICs (Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 프로세서(Processors), 제어기(Controllers), 마이크로 컨트롤러(Micro-controllers), 마이크로 프로세서(Microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 사용자 인터페이스부는, 차량과 차량 이용자와의 소통을 위한 것으로, 이용자의 입력 신호를 수신하 고, 수신된 입력 신호를 제어부로 전달하며, 제어부의 제어에 의해 이용자에게 차량이 보유하는 정보를 제공할 수 있다. 사용자 인터페이스부는, 입력 모듈, 내부 카메라, 생체 감지 모듈 및 출력 모듈을 포함할 수 있으나 이에 한정되지 않는다. 입력 모듈은, 사용자로부터 정보를 입력 받기 위한 것으로, 입력 모듈에서 수집한 데이터는, 제어부에 의 해 분석되어, 사용자의 제어 명령으로 처리될 수 있다. 입력 모듈은, 사용자로부터 차량의 목적지를 입력받아 제어부로 제공할 수 있다. 입력 모듈은, 사용자의 입력에 따라 오브젝트 검출부의 복수개의 센서 모듈 중 적어도 하나의 센서 모듈을 지정하여 비활성화하는 신호를 제어부로 입력할 수 있다. 입력 모듈은, 차량 내부에 배치될 수 있다. 예를 들면, 입력 모듈은, 스티어링 휠(Steering wheel)의 일 영역, 인스투루먼트 패널(Instrument panel)의 일 영역, 시트(Seat)의 일 영역, 각 필러(Pillar)의 일 영역, 도어 (Door)의 일 영역, 센타 콘솔(Center console)의 일 영역, 헤드 라이닝(Head lining)의 일 영역, 썬바이저(Sun visor)의 일 영역, 윈드 쉴드(Windshield)의 일 영역 또는 윈도우(Window)의 일 영역 등에 배치될 수 있다. 출력 모듈은, 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것이다. 출력 모듈은, 음향 또는 이미 지를 출력할 수 있다. 출력 모듈은, 디스플레이 모듈, 음향 출력 모듈 및 햅틱 출력 모듈 중 적어도 어느 하나를 포함할 수 있다. 디스플레이 모듈은, 다양한 정보에 대응되는 그래픽 객체를 표시할 수 있다. 디스플레이 모듈은 액정 디스플레이(Liquid Crystal Display, LCD), 박막 트랜지스터 액정 디스플레이(Thin Film Transistor Liquid Crystal Display, TFT LCD), 유기 발광 다이오드(Organic Light-Emitting Diode, OLED), 플렉서블 디스플레이(Flexible display), 삼차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할 수 있다. 디스플레이 모듈은 터치 입력 모듈과 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구 현할 수 있다. 디스플레이 모듈은 HUD(Head Up Display)로 구현될 수 있다. 디스플레이 모듈이 HUD로 구현되는 경우, 디스플레 이 모듈은 투사 모듈을 구비하여 윈드 쉴드 또는 윈도우에 투사되는 이미지를 통해 정보를 출력할 수 있다. 디스플레이 모듈은, 투명 디스플레이를 포함할 수 있다. 투명 디스플레이는 윈드 쉴드 또는 윈도우에 부착될 수 있다. 투명 디스플레이는 소정의 투명도를 가지면서, 소정의 화면을 표시할 수 있다. 투명 디스플레이는, 투명도를 가 지기 위해, 투명 디스플레이는 투명 TFEL(Thin Film Elecroluminescent), 투명 OLED(Organic Light-Emitting Diode), 투명 LCD(Liquid Crystal Display), 투과형 투명디스플레이, 투명 LED(Light Emitting Diode) 디스플 레이 중 적어도 하나를 포함할 수 있다. 투명 디스플레이의 투명도는 조절될 수 있다. 사용자 인터페이스부는, 복수개의 디스플레이 모듈을 포함할 수 있다. 디스플레이 모듈은, 스티어링 휠의 일 영역, 인스투루먼트 패널의 일 영역, 시트의 일 영역, 각 필러의 일 영역, 도어의 일 영역, 센타 콘솔의 일 영역, 헤드 라이닝의 일 영역, 썬 바이저의 일 영역에 배치되거나, 윈드 쉴드의 일영역, 윈도우의 일영역에 구현될 수 있다. 음향 출력 모듈은, 제어부로부터 제공되는 전기 신호를 오디오 신호로 변환하여 출력할 수 있다. 이를 위 해, 음향 출력 모듈은, 하나 이상의 스피커를 포함할 수 있다. 햅틱 출력 모듈은, 촉각적인 출력을 발생시킨다. 예를 들면, 햅틱 출력 모듈은, 스티어링 휠, 안전 벨트, 시트 를 진동시켜, 사용자가 출력을 인지할 수 있게 동작할 수 있다. 오브젝트 검출부는, 차량 외부에 위치하는 오브젝트를 검출하기 위한 것으로, 센싱 데이터에 기초하 여 오브젝트 정보를 생성하고, 생성된 오브젝트 정보를 제어부로 전달할 수 있다. 이때, 오브젝트는 차량 의 운행과 관련된 다양한 물체, 예를 들면, 차선, 타 차량, 보행자, 이륜차, 교통 신호, 빛, 도로, 구조물, 과속 방지턱, 지형물, 동물 등을 포함할 수 있다. 오브젝트 검출부는, 복수개의 센서 모듈로서, 복수개의 촬상부로서의 카메라 모듈, 라이다(LIDAR: Light Imaging Detection and Ranging), 초음파 센서, 레이다(RADAR: Radio Detection and Ranging) 및 적외선 센서를 포함할 수 있다. 오브젝트 검출부는, 복수개의 센서 모듈을 통하여 차량 주변의 환경 정보를 센싱할 수 있다. 실시예에 따라, 오브젝트 검출부는, 설명되는 구성 요소 외에 다른 구성 요소를 더 포함하거나, 설명되는 구성 요소 중 일부를 포함하지 않을 수 있다. 레이다는, 전자파 송신 모듈, 수신 모듈을 포함할 수 있다. 레이다는 전파 발사 원리상 펄스 레이다(Pulse Radar) 방식 또는 연속파 레이다(Continuous Wave Radar) 방식으로 구현될 수 있다. 레이다는 연속파 레이다 방 식 중에서 신호 파형에 따라 FMCW(Frequency Modulated Continuous Wave)방식 또는 FSK(Frequency Shift Keyong) 방식으로 구현될 수 있다. 레이다는 전자파를 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브 젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 레이다는, 차량의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배 치될 수 있다. 라이다는, 레이저 송신 모듈, 수신 모듈을 포함할 수 있다. 라이다는, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식으로 구현될 수 있다. 라이다는, 구동식 또는 비구동식으로 구현될 수 있다. 구동식으로 구현되는 경우, 라이다는, 모터에 의해 회전되며, 차량 주변의 오브젝트를 검출할 수 있고, 비 구동식으로 구현되는 경우, 라이다는, 광 스티어링에 의해, 차량을 기준으로 소정 범위 내에 위치하는 오 브젝트를 검출할 수 있다. 차량은 복수개의 비구동식 라이다를 포함할 수 있다. 라이다는, 레이저 광 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 라이다는, 차량의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배 치될 수 있다. 촬상부는, 차량 외부 이미지를 획득하기 위해, 차량의 외부의 적절한 곳, 예를 들면, 차량의 전방, 후방, 우측 사이드 미러, 좌측 사이드 미러에 위치할 수 있다. 촬상부는, 모노 카메라일 수 있으나, 이에 한정되지 않으며, 스테레오 카메라, AVM(Around View Monitoring) 카메라 또는 360도 카메라일 수 있다. 촬상부는, 차량 전방의 이미지를 획득하기 위해, 차량의 실내에서, 프런트 윈드 쉴드에 근접하게 배치될 수 있 다. 또는, 촬상부는, 프런트 범퍼 또는 라디에이터 그릴 주변에 배치될 수 있다. 촬상부는, 차량 후방의 이미지를 획득하기 위해, 차량의 실내에서, 리어 글라스에 근접하게 배치될 수 있다. 또 는, 촬상부는, 리어 범퍼, 트렁크 또는 테일 게이트 주변에 배치될 수 있다. 촬상부는, 차량 측방의 이미지를 획득하기 위해, 차량의 실내에서 사이드 윈도우 중 적어도 어느 하나에 근접하 게 배치될 수 있다. 또한, 촬상부는 휀더 또는 도어 주변에 배치될 수 있다. 촬상부는, 획득된 이미지를 제어부에 제공할 수 있다. 초음파 센서는, 초음파 송신 모듈, 수신 모듈을 포함할 수 있다. 초음파 센서는, 초음파를 기초로 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 초음파 센서는, 차량의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치 에 배치될 수 있다.적외선 센서는, 적외선 송신 모듈, 수신 모듈을 포함할 수 있다. 적외선 센서는, 적외선 광을 기초로 오브젝트 를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 적외선 센서는, 차량의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치 에 배치될 수 있다. 제어부는, 오브젝트 검출부의 각 모듈의 전반적인 동작을 제어할 수 있다. 제어부는, 레이다, 라이다, 초음파 센서 및 적외선 센서에 의해 센싱된 데이터와 기 저장된 데이터를 비교 하여, 오브젝트를 검출하거나 분류할 수 있다. 제어부는, 획득된 이미지에 기초하여, 오브젝트를 검출하고, 트래킹할 수 있다. 제어부는, 이미지 처 리 알고리즘을 통해, 오브젝트와의 거리 산출, 오브젝트와의 상대 속도 산출 등의 동작을 수행할 수 있다. 예를 들면, 제어부는, 획득된 이미지에서, 시간에 따른 오브젝트 크기의 변화를 기초로, 오브젝트와의 거 리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 제어부는, 핀홀(pin hole) 모델, 노면 프로파일링 등을 통해, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 제어부는, 송신된 전자파가 오브젝트에 반사되어 되돌아오는 반사 전자파에 기초하여, 오브젝트를 검출하 고, 트래킹할 수 있다. 제어부는, 전자파에 기초하여, 오브젝트와의 거리 산출, 오브젝트와의 상대 속도 산출 등의 동작을 수행할 수 있다. 제어부는, 송신된 레이저가 오브젝트에 반사되어 되돌아오는 반사 레이저 광에 기초하여, 오브젝트를 검출 하고, 트래킹할 수 있다. 제어부는, 레이저 광에 기초하여, 오브젝트와의 거리 산출, 오브젝트와의 상대 속도 산출 등의 동작을 수행할 수 있다. 제어부는, 송신된 초음파가 오브젝트에 반사되어 되돌아오는 반사 초음파에 기초하여, 오브젝트를 검출하 고, 트래킹할 수 있다. 제어부는, 초음파에 기초하여, 오브젝트와의 거리 산출, 오브젝트와의 상대 속도 산출 등의 동작을 수행할 수 있다. 제어부는, 송신된 적외선 광이 오브젝트에 반사되어 되돌아오는 반사 적외선 광에 기초하여, 오브젝트를 검출하고, 트래킹할 수 있다. 제어부는, 적외선 광에 기초하여, 오브젝트와의 거리 산출, 오브젝트와의 상 대 속도 산출 등의 동작을 수행할 수 있다. 실시예에 따라, 오브젝트 검출부는, 제어부와 별도의 프로세서를 내부에 포함할 수 있다. 또한, 레이 다, 라이다, 초음파 센서 및 적외선 센서 각각 개별적으로 프로세서를 포함할 수 있다. 오브젝트 검출부에 프로세서가 포함된 경우, 오브젝트 검출부는, 제어부의 제어를 받는 프로세 서의 제어에 따라, 동작될 수 있다. 운전 조작부는, 운전을 위한 사용자 입력을 수신할 수 있다. 메뉴얼 모드인 경우, 차량은, 운전 조작 부에 의해 제공되는 신호에 기초하여 운행될 수 있다. 차량 구동부는, 차량내 각종 장치의 구동을 전기적으로 제어할 수 있다. 차량 구동부는, 차량 내 파워 트레인, 샤시, 도어/윈도우, 안전 장치, 램프 및 공조기의 구동을 전기적으로 제어할 수 있다. 운행부는, 차량의 각종 운행을 제어할 수 있다. 운행부는, 자율 주행 모드에서 동작될 수 있다. 운행부는, 주행 모듈, 출차 모듈 및 주차 모듈을 포함할 수 있다. 실시예에 따라, 운행부는, 설명되는 구성 요소 외에 다른 구성 요소를 더 포함하거나, 설명되는 구성 요소 중 일부를 포함하지 않을 수 있다. 운행부는, 제어부의 제어를 받는 프로세서를 포함할 수 있다. 운행부의 각 모듈은, 각각 개별적 으로 프로세서를 포함할 수 있다. 실시예에 따라, 운행부가 소프트웨어적으로 구현되는 경우, 제어부의 하위 개념일 수도 있다. 주행 모듈은, 차량의 주행을 수행할 수 있다. 주행 모듈은, 오브젝트 검출부로부터 오브젝트 정보를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량의 주행을 수행할 수 있다. 주행 모듈은, 통신부를 통해, 외부 디바이스로부터 신호를 제공받아, 차량 구동 모듈에 제어 신호를 제공 하여, 차량의 주행을 수행할 수 있다. 출차 모듈은, 차량의 출차를 수행할 수 있다. 출차 모듈은, 내비게이션 모듈로부터 내비게이션 정보를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차 량의 출차를 수행할 수 있다. 출차 모듈은, 오브젝트 검출부로부터 오브젝트 정보를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량의 출차를 수행할 수 있다. 출차 모듈은, 통신부를 통해, 외부 디바이스로부터 신호를 제공받아, 차량 구동 모듈에 제어 신호를 제공 하여, 차량의 출차를 수행할 수 있다. 주차 모듈은, 차량의 주차를 수행할 수 있다. 주차 모듈은, 내비게이션 모듈로부터 내비게이션 정보를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차 량의 주차를 수행할 수 있다. 주차 모듈은, 오브젝트 검출부로부터 오브젝트 정보를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량의 주차를 수행할 수 있다. 주차 모듈은, 통신부를 통해, 외부 디바이스로부터 신호를 제공받아, 차량 구동 모듈에 제어 신호를 제공 하여, 차량의 주차를 수행할 수 있다. 내비게이션 모듈은, 제어부에 내비게이션 정보를 제공할 수 있다. 내비게이션 정보는, 맵(map) 정보, 설정 된 목적지 정보, 목적지 설정 따른 경로 정보, 경로 상의 다양한 오브젝트에 대한 정보, 차선 정보 및 차량의 현재 위치 정보 중 적어도 어느 하나를 포함할 수 있다. 내비게이션 모듈은, 차량이 진입한 주차장의 주차장 지도를 제어부에 제공할 수 있다. 제어부는, 차량이 주차장에 진입한 경우, 내비게이션 모듈로부터 주차장 지도를 제공받고, 산출된 이 동 경로 및 고정 식별 정보를 제공된 주차장 지도에 투영하여 지도 데이터를 생성할 수 있다. 내비게이션 모듈은, 메모리를 포함할 수 있다. 메모리는 내비게이션 정보를 저장할 수 있다. 내비게이션 정보는 통신부를 통해 수신된 정보에 의하여 갱신될 수 있다. 내비게이션 모듈은, 내장 프로세서에 의해 제어될 수도 있고, 외부 신호, 예를 들면, 제어부로부터 제어 신호를 입력 받아 동작할 수 있으나 이에 한정되지 않는다. 운행부의 주행 모듈은, 내비게이션 모듈로부터 내비게이션 정보를 제공받아, 차량 구동 모듈에 제어 신호 를 제공하여, 차량의 주행을 수행할 수 있다. 센싱부는, 차량에 장착된 센서를 이용하여 차량의 상태를 센싱, 즉, 차량의 상태에 관한 신호를 감지하고, 감지된 신호에 따라 차량의 이동 경로 정보를 획득할 수 있다. 센싱부는, 획득된 이동 경로 정보를 제어부에 제공할 수 있다. 센싱부는, 자세 센서(예를 들면, 요 센서(yaw sensor), 롤 센서(roll sensor), 피치 센서(pitch sensor)), 충돌 센서, 휠 센서(wheel sensor), 속도 센서, 경사 센서, 중량 감지 센서, 헤딩 센서(heading sensor), 자이로 센서(gyro sensor), 포지션 모듈(position module), 차량 전진/후진 센서, 배터리 센서, 연료 센서, 타이어 센서, 핸들 회전에 의한 스티어링 센서, 차량 내부 온도 센서, 차량 내부 습도 센서, 초음파 센서, 조도 센서, 가속 페달 포지션 센서, 브레이크 페달 포지션 센서, 등을 포함할 수 있다. 센싱부는, 차량 자세 정보, 차량 충돌 정보, 차량 방향 정보, 차량 위치 정보(GPS 정보), 차량 각도 정보, 차량 속도 정보, 차량 가속도 정보, 차량 기울기 정보, 차량 전진/후진 정보, 배터리 정보, 연료 정보, 타이어 정보, 차량 램프 정보, 차량 내부 온도 정보, 차량 내부 습도 정보, 스티어링 휠 회전 각도, 차량 외부 조도, 가속 페달에 가해지는 압력, 브레이크 페달에 가해지는 압력 등에 대한 센싱 신호를 획득할 수 있다. 센싱부는, 그 외, 가속페달센서, 압력센서, 엔진 회전 속도 센서(engine speed sensor), 공기 유량 센서 (AFS), 흡기 온도 센서(ATS), 수온 센서(WTS), 스로틀 위치 센서(TPS), TDC 센서, 크랭크각 센서(CAS), 등을더 포함할 수 있다. 센싱부는, 센싱 데이터를 기초로, 차량 상태 정보를 생성할 수 있다. 차량 상태 정보는, 차량 내부에 구비 된 각종 센서에서 감지된 데이터를 기초로 생성된 정보일 수 있다. 차량 상태 정보는, 차량의 자세 정보, 차량의 속도 정보, 차량의 기울기 정보, 차량의 중량 정보, 차량의 방향 정보, 차량의 배터리 정보, 차량의 연료 정보, 차량의 타이어 공기압 정보, 차량의 스티어링 정보, 차량 실내 온도 정보, 차량 실내 습도 정보, 페달 포지션 정보 및 차량 엔진 온도 정보 등을 포함할 수 있다. 저장부는, 제어부와 전기적으로 연결된다. 저장부는 차량 내 객체 모니터링 장치 각 부에 대한 기본 데이터, 차량 내 객체 모니터링 장치 각 부의 동작 제어를 위한 제어 데이터, 입출력되는 데이터를 저장할 수 있다. 저장부는, 하드웨어적으로, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이브 등과 같은 다양한 저장기기 일 수 있다. 저장부는 제어부의 처리 또는 제어를 위한 프로그램 등, 차량 전반의 동 작을 위한 다양한 데이터, 특히, 운전자 성향 정보를 저장할 수 있다. 이때, 저장부는, 제어부와 일 체형으로 형성되거나, 제어부의 하위 구성 요소로 구현될 수 있다. 차량 내 객체 모니터링 장치는 차량의 내부를 촬영하는 제1 카메라 및 제2 카메라로부터 제1 영상 및 제2 영상을 각각 수신할 수 있으며, 제1 영상 및 제2 영상에 기초하여, 차량의 내부를 모니터링할 수 있다. 이러한 차량 내 객체 모니터링 장치는 인터페이스, 프로세서 및 메모리를 포함할 수 있으며, 이후 도 4를 참조하 여 상세하게 설명하도록 한다. 여기서, 인터페이스는 통신부에 포함될 수 있고, 프로세서는 제어부에 포함될 수 있으며, 메모리는 저장부에 포함될 수도 있다. 도 4는 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치의 구성을 도시한 도면이다. 도 4를 참조하면, 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치는 제1 영상 및 제2 영상을 이용 하여 차량 내 객체를 모니터링하는 장치로서, 인터페이스, 프로세서 및 메모리를 포함할 수 있 다. 인터페이스는 상기 차량 내 제1 카메라에 의해 생성된 제1 영상 및 상기 차량 내 제2 카메라에 의해 생성 된 제2 영상을 수신할 수 있다. 여기서, 제1 카메라 및 제2 카메라는 동일한 위치(예컨대, 차량 내 동일한 위치)에 설치되어, 동일한 주변환경 또는 동일한 객체에 대한 영상을 생성할 수 있으며, 다양한 센서를 구비한 하나의 카메라로 구성될 수도 있다. 또한, 제1 카메라 및 제2 카메라는 차량 내 객체 모니터링 장치 외부 에 존재할 수 있으나, 이에 한정되지 않고, 차량 내 객체 모니터링 장치 내부에 존재할 수 있다. 또한, 제1 영상 및 제2 영상은 동일한 해상도를 가질 수 있다. 이때, 제1 영상은 설정된 기준점(예컨대, 제1 카메라, 또는 제1 카메라 내 센서)을 기준으로 객체(또는, 주변환 경)가 이격되는 거리에 기초하여 픽셀의 색상이 상이하게 생성되는 영상으로서, 예컨대, 뎁스 정보(예컨대, 픽 셀별 거리 정보)를 포함하는 뎁스(depth) 영상일 수 있다. 반면, 제2 영상은 예컨대, 뎁스 정보를 포함하지 않 는 비뎁스(non-depth) 영상일 수 있다. 또한, 예를 들어, 제1 영상은 3차원 영상이고, 제2 영상은 2차원 영상일 수 있다. 상기 제1 카메라는 예컨대, 초음파 센서를 이용하여 상기 제1 영상으로서, 초음파 영상을 생성할 수 있다. 상기 초음파 센서는 투명한 물체, 액체, 반사도가 매우 높은 표면 또는 금속 표면을 감지할 때 유용할 수 있다. 또한, 상기 제2 카메라는 예컨대, RGB(Red, Green, Blue) 센서 또는 IR(Infrared Radiation) 센서를 이용하여, 상기 제2 영상으로서, RGB 영상 또는 IR 영상을 생성할 수 있다. 상기 IR 센서는 면/가죽 소재, 어두운 환경에 서 감지할 때 유용할 수 있다. 또한, 인터페이스는 상기 제1 카메라 및 상기 제2 카메라로부터 설정된 주기 마다 각각 상기 제1 영상 및 상기 제2 영상을 수신할 수 있다. 프로세서는 ⅰ)학습 단계에서, 차량 내 객체 모니터링 장치 내 프로세서는 객체 종류 예측 알고리즘, 객체 의 영역 추정 알고리즘 및 객체의 특징 추출 알고리즘을 생성하여 메모리에 저장할 수 있다. 구체적으로, 프로세서는 인터페이스를 통해 수집된 복수의 제1 영상(또는, 제2 영상)에서 객체의 종 류(예컨대, 사람, 동물, 음료, 스낵 등)를 인식하도록 신경망 모델을 훈련시켜, 상기 객체 종류 예측 알고리즘을 생성할 수 있다. 프로세서는 상기 객체의 종류에 기초하여, 제1 영상(또는, 제2 영상)에서 상기 객체에 대응하는 가변영역을 설정하도록 신경망 모델을 훈련시켜, 상기 객체의 영역 추정 알고리즘을 생성할 수 있다. 또한, 프로세서는 영상의 종류(예컨대, 제1 영상, 제2 영상) 및 상기 객체의 종류가 분류되는 카테고리(예 컨대, 능동적 객체, 수동적 객체)에 기초하여, 제1 영상과 연관된 제1 특징 정보 또는 제2 영상과 연관된 제2 특징 정보를 인식하도록 신경망 모델을 훈련시켜, 상기 객체의 특징 추출 알고리즘을 생성할 수 있다. 한편, 프로세서는 상기 객체 종류 예측 알고리즘, 상기 객체의 영역 추정 알고리즘 및 상기 객체의 특징 추출 알고리즘을 하나의 알고리즘으로 생성할 수도 있다. 이후, 프로세서는 ⅱ)추론 단계에서, 인터페이스를 통해, 상기 제1 카메라에 의해 생성된 제1 영상 및 상기 제2 카메라에 의해 생성된 제2 영상이 수신되면, 상기 제1 영상 및 상기 제2 영상 각각에 객체가 존재 하는지를 판단할 수 있다. 프로세서는 상기 제1 영상 및 상기 제2 영상 각각에 객체가 존재하는 것으로 판 단되면(즉, 객체가 추출되는 경우), 상기 제1 영상으로부터 상기 객체에 대한 제1 특징 정보를 추출하고, 상기 제2 영상으로부터 상기 객체에 대한 제2 특징 정보를 추출하며, 상기 제1 특징 정보 및 상기 제2 특징 정보에 기초하여, 상기 객체의 상태를 인식할 수 있다. 여기서, 객체의 상태는 예컨대, 객체의 형태, 객체의 상세정보 (예컨대, 사람일 경우 이목구비, 객체가 상품일 경우 상표명)를 포함할 수 있으며, 객체의 위치 또한 더 포함할 수 있다. 이때, 프로세서는 상기 제1 영상 및 상기 제2 영상에, 메모리 내 객체 종류 예측 알고리즘을 각각 적 용하여 상기 객체의 종류(예컨대, 사람, 동물, 음료, 스낵 등)를 예측하고, 상기 제1 영상 및 상기 제2 영상과 함께 상기 예측된 객체의 종류에, 메모리 내 객체의 영역 추정 알고리즘을 각각 적용하여 상기 객체의 가 변영역(즉, 객체에 대응하는 영역)을 추정할 수 있다. 프로세서는 상기 추정된 객체의 가변영역에 메모리 내 객체의 특징 추출 알고리즘을 각각 적용하여, 상기 제1 특징 정보 및 상기 제2 특징 정보를 추출할 수 있다. 여기서, 상기 객체 종류 예측 알고리즘은 수집된 제1 영상 및 제2 영상 중 적어도 하나의 영상에서 객체 의 종류를 인식하도록 훈련된 신경망 모델이고, 상기 객체의 영역 추정 알고리즘은 상기 객체의 종류에 기초하 여, 상기 영상에서 상기 객체에 대응하는 가변영역을 설정하도록 훈련된 신경망 모델일 수 있다. 또한, 상기 객 체의 특징 추출 알고리즘은, 상기 영상의 종류(예컨대, 제1 영상, 제2 영상) 및 상기 객체의 종류가 분류되는 카테고리(예컨대, 능동적 객체, 수동적 객체)에 기초하여, 상기 객체에 대응하는 가변영역에서 상기 제1 영상과 연관된 제1 특징 정보 또는 상기 제2 영상과 연관된 제2 특징 정보를 인식하도록 훈련된 신경망 모델일 수 있다. 프로세서는 상기 객체의 종류가 움직임이 가능한 능동적 객체(예컨대, 사람, 동물)로 분류되는 경우, 상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 이목구비에 대한 제1 지점(즉, 픽 셀 위치)을 추출할 수 있다. 이때, 프로세서는 예컨대, 골격화(Skeletonization) 정보를 이용할 수 있으며, 골격화 정보에 기초하여, 객체의 형태 및 상기 객체에서의 이목구비에 대한 제1 지점(즉, 픽셀 위치)을 추출할 수 있다. 프로세서는 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 이목구비에 대한 제2 지점(즉, 픽 셀 위치)을 추출할 수 있다. 이후, 프로세서는 상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지점에 대응하는 영상으로 대체시켜, 상기 객체의 상태를 인식할 수 있다. 이때, 프로세 서는 상기 제1 특징 정보로서, 상기 객체의 위치를 더 추출하고, 상기 객체의 상태로서, 상기 객체의 위치 를 더 인식할 수 있다. 예컨대, 프로세서는 제1 영상 및 제2 영상에 기초하여, 주행하는 상기 차량 내 상기 객체의 종류가 운전자 일 경우, 상기 객체의 상태로서 인식된 운전자의 시선이 설정된 범위(예컨대, 눈동자가 주행 시야, 또는 설정된 좌우 각도, 상하 각도)를 설정된 제1 시간 동안 벗어나거나 또는 설정된 제1 시간 동안 눈을 감고 있으면(예컨 대, 졸음 운전으로 판단할 수 있음), 사고 위험 경고를 발생할 수 있다. 다른 일례로서, 프로세서는 상기 제1 영상과 상기 제2 영상으로부터 객체의 상태로서, 운전자가 소지하는 휴대 단말(예컨대, 스마트폰, 태블릿 PC)의 상태를 더 인식할 수 있으며, 운전자의 시선이 휴대 단말로 설정된 제2 시간(제1 시간과 상이할 수 있음) 동안 향하는 경우, 사고 위험 경고를 발생 함으로써, 운전자가 휴대 단말 에 집중하지 않고, 차량 운전에 집중할 수 있게 한다. 또한, 프로세서는 제1 영상 및 제2 영상에 기초하여, 주행하는 상기 차량 내 상기 객체의 종류가 운전자이 고, 상기 객체의 상태로서 인식된 운전자의 시선이 상기 차량 내 디스플레이를 향하는지의 여부 및 상기 운전자의 머리가 향하는 방향(또한, 운전자의 고개가 꺽이는지의 여부)에 기초하여, 상기 디스플레이의 백라이트 전원 을 제어할 수 있다. 구체적으로, 프로세서는 운전자의 시선이 예컨대, 차량 내 디스플레이로 향하고, 운전자의 머리가 아래로 숙여진 경우(또는, 운전자의 고개가 설정된 각도 이상 꺽인 경우), 디스플레이의 백라이트 전원을 온(ON)시킬 수 있다. 반면, 차량 내 객체 모니터링 장치는 운전자의 시선이 예컨대, 디스플레이로 향하지 않고, 운전자의 머리가 아래로 숙여지지 않은(또는, 운전자의 고개가 설정된 각도 이상 꺽이지 않은 경우, 정면을 바라보는 경 우), 디스플레이의 백라이트 전원을 오프(OFF)시킬 수 있다. 프로세서는 상기 객체의 종류가 움직임이 불가능한 수동적 객체(예컨대, 음료, 스낵, 휴대 단말)로 분류되 는 경우, 상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 고유정보(예컨대, 상표명)에 대한 제1 지점(즉, 픽셀 위치)을 추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에 서의 고유정보에 대한 제2 지점을 추출할 수 있다. 이후, 프로세서는 상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지점(즉, 픽셀 위치)에 대응하는 영상으로 대체시켜, 상기 객체의 상태를 인식할 수 있다. 이때, 프로세서는 상기 제1 특징 정보로서, 상기 객체의 위치를 더 추출하고, 상 기 객체의 상태로서, 상기 객체의 위치를 더 인식할 수 있다. 한편, 제1 영상 내 객체와 제2 영상 내 객체 합성시, 프로세서는 상기 제1 영상 내 상기 제1 지점과, 상기 제2 영상 내 상기 제2 지점을 픽셀 대 픽셀로 매칭시켜, 제1 지점에 대응하는 영상을, 제2 지점에 대응하는 영 상으로 대체시킴으로써, 영상 전체를 픽셀 대 픽셀로 매칭시키는 것이 아니라, 영상의 중요한 일부 영역을 픽셀 대 픽셀로 매칭시킴으로써, 객체의 상태를 보다 신속하고 간편하게 인식할 수 있다. 프로세서는 상기 객체의 종류에 대한 카테고리(즉, 능동적 객체 또는 수동적 객체) 분류시, 메모리에 기저장된 객체의 종류별 카테고리 분류표 또는 분류 알고리즘(즉, 객체의 종류에 기초하여, 능동적 객체 또는 수동적 객체로 분류하도록 훈련된 신경망 모델)을 이용할 수 있다. 또한, 프로세서는 상기 주기적으로 수신되는 제1 영상 및 제2 영상에 기초하여, 상기 차량 내 설정된 공간 (예컨대, 스낵바)에 위치하는 객체가 상기 공간의 외부로 이동하는 것으로 확인되면, 상기 이동된 객체의 상태 (예컨대, 'C' 음료(레몬맛))를 인식할 수 있다. 프로세서는 상기 공간에 배치된 객체가 종류(예컨대, 콜라, 사이다, 'A' 과자, 'B' 과자, 'C' 음료(레몬맛))별로 설정된 기준에 미달하는 경우, 미달된 종류에 해당하는 객체의 식별정보를 상기 차량을 기준 으로 설정된 거리 내에 위치하는 상점 내 상점 단말로 제공하고, 상기 차량에 설치된 드론으로 하여금, 상기 상 점으로 이동하여, 상기 객체의 식별정보에 대응하는 상품을 획득하여 상기 차량에 공급하도록 한다. 이로써, 프 로세서는 차량 내 설정된 공간(예컨대, 스낵바)에 배치된 상품의 수량을 일정하게 유지시켜, 탑승자로 하 여금 상기 공간 내 상품을 불편함 없이, 사용할 수 있게 한다. 한편, 프로세서는 상기 드론의 배터리 용량을 확인하고, 상기 배터리 용량에 기초하여 상기 상점에 대한 상기 드론의 왕복이 가능한 경우, 상기 드론을 상기 상점으로 이동시킴으로써, 드론이 배터리가 부족하지 않고, 안전하게 차량으로 복귀할 수 있게 한다. 프로세서는 상기 차량의 주행 속도 및 상기 드론의 왕복 시간 중 적어도 하나에 기초하여, 상기 차량이 주 행하는 경로에 포함되는 상점을 선택하고, 상기 선택된 상점 내 상점 단말로 상기 객체의 식별정보를 제공할 수 있다. 이에 따라, 프로세서는 차량이 주행하는 경로에서의 위치와 상점에서 복귀하는 드론의 위치가 설정 된 거리 이내를 만족하도록 하여, 드론의 이동 거리를 최소화시킬 수 있다. 메모리는 객체의 상태를 인식할 때 활용되는, 객체 종류 예측 알고리즘, 객체의 영역 추정 알고리즘 및 객 체의 특징 추출 알고리즘이 저장될 수 있다. 메모리는 프로세서가 처리하는 데이터를 일시적 또는 영구적으로 저장하는 기능을 수행할 수 있다. 여기서, 메모리는 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체(flash storage medi a)를 포함할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 이러한 메모리는 내장 메모리 및/ 또는 외장 메모리를 포함할 수 있으며, DRAM, SRAM, 또는 SDRAM 등과 같은 휘발성 메모리, OTPROM(one time programmable ROM), PROM, EPROM, EEPROM, mask ROM, flash ROM, NAND 플래시 메모리, 또는 NOR 플래시 메모리 등과 같은 비휘발성 메모리, SSD. CF(compact flash) 카드, SD 카드, Micro-SD 카드, Mini-SD 카드, Xd 카드, 또는 메모리 스틱(memory stick) 등과 같은 플래시 드라이브, 또는 HDD와 같은 저장 장치를 포함할 수 있다.도 5는 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 객체가 능동적 객체일 때, 객체의 상태를 인식하는 일례를 설명하기 위한 도면이다. 도 5를 참조하면, 차량 내 객체 모니터링 장치는 제1 카메라(예컨대, 초음파 카메라)로부터 수신된 제1 영상 에 객체 종류 예측 알고리즘을 적용하여, 객체의 종류(예컨대, 사람)를 예측하고, 상기 제1 영상 및 상기 제2 영상과, 함께 상기 예측된 객체의 종류에 객체의 영역 추정 알고리즘을 적용하여, 상기 객체의 가변영역 을 추정하며, 객체의 가변영역에 객체의 특징 추출 알고리즘을 적용하여, 제1 특징 정보를 추출 할 수 있다. 이때, 차량 내 객체 모니터링 장치는 객체의 종류가 '사람'으로 예측됨에 따라, 객체의 종류를, 움 직임이 가능한 능동적 객체로 분류하고, 제1 특징 정보로서, 제1 영상 내 객체의 형태 및 객체에서의 이목구비에 대한 제1 지점(픽셀 위치)를 추출할 수 있다. 또한, 차량 내 객체 모니터링 장치는 제2 카메라(예컨대, RGB 카메라, IR 카메라)로부터 수신된 제2 영상 에 객체 종류 예측 알고리즘을 적용하여, 객체의 종류(예컨대, 사람)를 예측하고, 상기 제1 영상 및 상기 제2 영상과, 함께 상기 예측된 객체의 종류에 객체의 영역 추정 알고리즘을 적용하여 상기 객체의 가변영역을 추정하며, 상기 추정된 객체의 가변영역에 객체의 특징 추출 알고리즘을 적용하여, 제2 특징 정보를 추출 할 수 있다. 이때, 차량 내 객체 모니터링 장치는 객체의 종류가 '사람'으로 예측됨에 따라, 객체의 종류를, 움 직임이 가능한 능동적 객체로 분류하고, 제2 특징 정보로서, 제2 영상 내 상기 객체에서의 이목구비 에 대한 제2 지점을 추출할 수 있다. 차량 내 객체 모니터링 장치는 상기 객체에 대한 제1 특징 정보 및 제2 특징 정보에 기초하여, 상기 객체의 상태를 인식할 수 있다. 구체적으로, 차량 내 객체 모니터링 장치는 제1 영상 내 제1 지점에 대응하는 영상을, 제2 영상 내 제2 지점에 대응하는 영상으로 대체시켜, 객체의 상태를 인식할 수 있 다. 도 6은 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 객체가 수동적 객체일 때, 객체의 상태를 인식하는 일례를 설명하기 위한 도면이다. 도 6을 참조하면, 차량 내 객체 모니터링 장치는 제1 카메라(예컨대, 초음파 카메라)로부터 수신된 제1 영상 에 객체 종류 예측 알고리즘을 적용하여, 객체의 종류(예컨대, 과자, 음료)를 예측하고, 상기 제1 영상 및 상기 제2 영상과, 함께 상기 예측된 객체의 종류에 객체의 영역 추정 알고리즘을 적용하여, 상기 객체의 가변영 역을 추정하며, 객체의 가변영역에 객체의 특징 추출 알고리즘을 적용하여, 제1 특징 정보를 추 출할 수 있다. 이때, 차량 내 객체 모니터링 장치는 객체의 종류가 '과자, 음료'으로 예측됨에 따라, 객체의 종 류를, 움직임이 불가능한 수동적 객체로 분류하고, 제1 특징 정보로서, 제1 영상 내 객체의 형태 및 객체에서의 고유정보('A' 과자, 'B' 과자, 'C' 음료)에 대한 제1 지점(픽셀 위치)를 추출할 수 있다. 또한, 차량 내 객체 모니터링 장치는 제2 카메라(예컨대, RGB 카메라, IR 카메라)로부터 수신된 제2 영상 에 객체 종류 예측 알고리즘을 적용하여, 객체의 종류(예컨대, 과자, 음료)를 예측하고, 상기 제1 영상 및 상기 제2 영상과, 함께 상기 예측된 객체의 종류에 객체의 영역 추정 알고리즘을 적용하여 상기 객체의 가변영역 을 추정하며, 상기 추정된 객체의 가변영역에 객체의 특징 추출 알고리즘을 적용하여, 제2 특징 정보(61 3)를 추출할 수 있다. 이때, 차량 내 객체 모니터링 장치는 객체의 종류가 '과자, 음료'으로 예측됨에 따라, 객 체의 종류를, 움직임이 가능한 능동적 객체로 분류하고, 제2 특징 정보로서, 제2 영상 내 상기 객체 에서의 이목구비에 대한 제2 지점을 추출할 수 있다. 차량 내 객체 모니터링 장치는 상기 객체에 대한 제1 특징 정보 및 제2 특징 정보에 기초하여, 상기 객체의 상태를 인식할 수 있다. 구체적으로, 차량 내 객체 모니터링 장치는 제1 영상 내 제1 지점에 대응하는 영상을, 제2 영상 내 제2 지점에 대응하는 영상으로 대체시켜, 객체의 상태를 인식할 수 있 다. 도 7은 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 운전자의 상태를 모니터링하여, 사고위험을 방지하는 일례를 설명하기 위한 도면이다. 도 7을 참조하면, 차량 내 객체 모니터링 장치는 주행하는 초음파 카메라 및 RGB 카메라(또는, IR 카메라)로부 터 제1 영상과 제2 영상을 각각 수신하고, 수신된 제1 영상과 제2 영상에 기초하여, DSM(Driver Status Monitoring)을 수행할 수 있다. 차량 내 객체 모니터링 장치는 상기 제1 영상과 상기 제2 영상으로부터 객체의 상태로서, 운전자의 상태를 인식 할 수 있다. 이때, 차량 내 객체 모니터링 장치는 운전자의 시선이 설정된 범위(예컨대, 운전자의 눈동자 가 주행 시야)를 설정된 제1 시간(예컨대, 5초) 동안 벗어나면, 사고 위험 경고를 발생 함으로써, 교통사고를 미연에 방지할 수 있게 한다. 이때, 차량 내 객체 모니터링 장치는 상기 제1 영상과 상기 제2 영상으로부터 객체의 상태로서, 운전자가 소지 하는 휴대 단말을 더 인식할 수 있으며, 운전자의 시선이 휴대 단말로 제2 시간(제1 시간 보다 작을 수 있으며, 예컨대, 3초) 동안 향하는 경우, 사고 위험 경고를 발생 함으로써, 운전자가 휴대 단말에 집중하지 않고, 차량 운전에 집중할 수 있게 한다. 도 8 및 도 9는 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 운전자의 상태를 모니터링하여, 차 량 내 컴포넌트의 전원을 제어하는 일례를 설명하기 위한 도면이다. 도 8 및 도 9를 참조하면, 차량 내 객체 모니터링 장치는 운전자의 상태를 모니터링하여, 차량 내 컴포넌트(예 컨대, 디스플레이)의 전원을 제어할 수 있다. 이때, 차량 내 객체 모니터링 장치는 운전자의 시선이 차량 내 디 스플레이를 향하는지의 여부 및 상기 운전자의 머리가 향하는 방향에 기초하여, 차량 내 컴포넌트(예컨대, 디스 플레이)의 전원을 제어할 수 있다. 구체적으로, 차량 내 객체 모니터링 장치는 주행하는 초음파 카메라 및 RGB 카메라(또는, IR 카메라)로부터 제1 영상과 제2 영상을 각각 수신할 수 있다. 차량 내 객체 모니터링 장치는 상기 제1 영상과 상기 제2 영상으로부터 객체의 상태로서, 운전자의 상태를 인식할 수 있다. 이때, 차량 내 객체 모니터링 장치는 운전자의 시선이 예컨대, 디스플레이로 향하고, 운전자의 머리가 아래로 숙여진 경우(또는, 운전자의 고개가 설정된 각도 이상 꺽인 경우), 디스 플레이의 백라이트 전원을 온(ON)시킬 수 있다. 반면, 차량 내 객체 모니터링 장치는 운전자의 시선 이 예컨대, 디스플레이로 향하지 않고, 운전자의 머리가 아래로 숙여지지 않은(또는, 운전자의 고개 가 설정된 각도 이상 꺽이지 않은 경우, 정면을 바라보는 경우), 디스플레이의 백라이트 전원을 오프(OF F)시킬 수 있다. 즉, 차량 내 객체 모니터링 장치는 상이한 종류의 영상을 이용하여, 운전자의 상태를 정확하게 인식할 수 있으며, 운전자가 차량 내 디스플레이를 이용할 동안에만, 디스플레이의 백라이트 전원을 온시킴으로써, 배터리 소모를 절약할 수 있게 한다. 도 10은 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 차량 내 설정된 공간에 존재하는 상품의 상태를 인지하는 일례를 설명하기 위한 도면이다. 도 10을 참조하면, 차량 내 객체 모니터링 장치는 차량 내 초음파 카메라 및 RGB 카메라(또는, IR 카메라)로부터 설정된 주기 마다 각각 제1 영상과 제2 영상을 수신할 수 있다. 차량 내 객체 모니터링 장치는 상기 주기적으로 수신되는 제1 영상 및 제2 영상에 기초하여, 상기 차량 내 스낵 바에 위치하는 객체가 스낵바의 외부로 이동하는 것으로 확인되면, 상기 이동된 객체의 상태를 인 식할 수 있다. 예컨대, 차량 내 객체 모니터링 장치는 탑승자가 스낵바에 위치하는 상품을 꺼냄에 따라, 제1 영상 및 제 2 영상에 기초하여, 스낵바에 위치하는 객체가 스낵바의 외부로 이동하는 것으로 확인되면, 상기 이동된 객체의 상태로서, 'C' 음료(레몬맛)을 인식할 수 있다. 도 11은 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 차량 내 설정된 공간에 존재하는 상품의 상태를 인지하는 다른 일례를 설명하기 위한 도면이다. 도 11을 참조하면, 차량 내 객체 모니터링 장치는 차량 내 초음파 카메라 및 RGB 카메라(또는, IR 카메라)로부터 설정된 주기 마다 각각 제1 영상과 제2 영상을 수신할 수 있다. 차량 내 객체 모니터링 장치는 상기 주기적으로 수신되는 제1 영상 및 제2 영상에 기초하여, 상기 차량 내 스낵 바에 위치하는 객체가 스낵바의 외부로 이동하는 것으로 확인되면, 상기 이동된 객체의 상태를 인 식할 수 있다. 예컨대, 차량 내 객체 모니터링 장치는 탑승자가 스낵바에 위치하는 상품을 꺼냄에 따라, 제1 영상 및 제 2 영상에 기초하여, 스낵바에 위치하는 객체가 스낵바의 외부로 이동하는 것으로 확인되면, 상기 이동된 객체의 상태로서, 'A' 과자을 인식할 수 있다. 도 12 내지 도 15는 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 차량 내 설정된 공간에 존재하 는 상품의 수량을 관리하는 일례를 설명하기 위한 도면이다. 도 12 내지 도 15를 참조하면, 차량 내 객체 모니터링 장치는 차량 내 초음파 카메라 및 RGB 카메라(또는, IR 카메라)로부터 설정된 주기 마다 각각 제1 영상과 제2 영상을 수신할 수 있다. 차량 내 객체 모니터링 장치는 상기 주기적으로 수신되는 제1 영상 및 제2 영상에 기초하여, 상기 차량 내 스낵 바에 위치하는 객체가 스낵바의 외부로 이동하는 것으로 확인되면, 상기 이동된 객체의 상태를 인식할 수 있다. 이때, 차량 내 객체 모니터링 장치는 상기 공간에 배치된 객체가 종류(예컨대, 콜라, 사이다, 'A' 과자, 'B' 과 자, 'C' 음료(레몬맛))별로 설정된 기준에 미달하는 경우, 미달된 객체를 다시 스낵바에 채울 수 있다. 이때, 차량 내 객체 모니터링 장치는 차량의 상부에 설치된 드론을 이용하여, 미달된 객체에 해당하는 상 품을 차량(또는, 차량 내 스낵바)에 공급할 수 있다. 구체적으로, 차량 내 객체 모니터링 장치는 예컨대, 상기 차량에 설치된 드론(1201-2)으로 하여금, 상점 으로 이동시키는 한편, 미달된 종류에 해당하는 객체(예컨대, 'A' 과자, 'C' 음료(레몬맛))의 식별정보를 상점 내 상점 단말로 제공할 수 있다. 차량 내 객체 모니터링 장치는 드론(1201-2)으로 하여금, 상기 객체의 식별정보에 대응하는 상품(1402, 1403)을 상점에서 획득하여, 상기 차량(또는, 차량 내 스낵바)에 공급하 도록 하고, 차량에 설치된 위치에 안착시킬 수 있다. 상점은 상기 차량을 기준으로 설정된 거리 내에 위치하는 상점이거나, 또는 차량이 주행하는 경로에 포함 되는 상점일 수 있다. 한편, 차량 내 객체 모니터링 장치는 차량에 설치된 드론의 배터리 용량이 설정된 배터리 용량 이상이 되 도록 드론의 배터리를 충전시켜, 드론이 언제든지 상품을 배달할 수 있게 하는 환경을 마련할 수 있다. 도 16은 본 발명의 일실시예에 따른 차량 내 객체 모니터링 방법을 나타내는 흐름도이다. 여기서, 차량 내 객체 모니터링 방법을 구현하는 차량 내 객체 모니터링 장치는 객체 종류 예측 알고리즘, 객체의 영역 추정 알고리즘 및 객체의 특징 추출 알고리즘을 생성하여 메모리에 저장할 수 있다. 상기 객체 종류 예측 알고리즘은, 수집된 제1 영상 및 제2 영상 중 적어도 하나의 영상에서 객체의 종류를 인식 하도록 훈련된 신경망 모델이고, 상기 객체의 영역 추정 알고리즘은, 상기 객체의 종류에 기초하여, 상기 영상 에서 상기 객체에 대응하는 가변영역을 설정하도록 훈련된 신경망 모델이다. 또한, 상기 객체의 특징 추출 알고 리즘은, 상기 영상의 종류 및 상기 객체의 종류가 분류되는 카테고리에 기초하여, 상기 객체에 대응하는 가변영 역에서 제1 특징 정보 또는 제2 특징 정보 중 어느 하나의 특징 정보를 인식하도록 훈련된 신경망 모델일 수 있 다. 도 16을 참조하면, 단계 S1601에서, 차량 내 객체 모니터링 장치는 상기 차량 내 제1 카메라에 의해 생성된 제1 영상 및 상기 차량 내 제2 카메라에 의해 생성된 제2 영상을 수신할 수 있다. 이때, 상기 제1 카메라는 초음파 센서를 이용하여 상기 제1 영상으로서, 초음파 영상을 생성하고, 상기 제2 카메라는, RGB 센서 또는 IR 센서를 이용하여 상기 제2 영상으로서, RGB 영상 또는 IR 영상을 생성할 수 있다. 단계 S1602에서, 차량 내 객체 모니터링 장치는 상기 제1 영상 및 상기 제2 영상 각각에 객체가 존재하는지를 판단하고, 상기 판단 결과, 상기 제1 영상 및 상기 제2 영상 각각에 객체가 존재하는 것으로 판단되면, 단계S1603에서, 상기 제1 영상 및 상기 제2 영상에, 객체 종류 예측 알고리즘을 각각 적용하여 상기 객체의 종류를 예측할 수 있다. 단계 S1604에서, 차량 내 객체 모니터링 장치는 예측된 객체의 종류가 능동적 객체 또는 수동적 객체로 분류되 는지를 확인하고, 확인 결과, 객체의 종류가 능동적 객체로 분류되는 경우, 단계 S1605에서, 상기 제1 영상 및 상기 제2 영상으로부터 능동적 객체에 기초한 제1 특징 정보 및 제2 특징 정보를 추출할 수 있다. 구체적으로, 차량 내 객체 모니터링 장치는 상기 제1 영상 및 상기 제2 영상과, 함께 상기 예측된 객체의 종류에 객체의 영 역 추정 알고리즘을 각각 적용하여 상기 객체의 가변영역을 추정할 수 있다. 차량 내 객체 모니터링 장치는 상 기 추정된 객체의 가변영역에 객체의 특징 추출 알고리즘을 각각 적용하여, 상기 제1 특징 정보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 이목구비에 대한 제1 지점을 추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 이목구비에 대한 제2 지점을 추출할 수 있다. 상기 확인 결과, 객체의 종류가 수동적 객체로 분류되는 경우, 단계 S1606에서, 차량 내 객체 모니터링 장치는 상기 제1 영상 및 상기 제2 영상으로부터 수동적 객체에 기초한 제1 특징 정보 및 제2 특징 정보를 추출할 수 있다. 구체적으로, 차량 내 객체 모니터링 장치는 상기 제1 영상 및 상기 제2 영상과, 함께 상기 예측된 객체의 종류에 객체의 영역 추정 알고리즘을 각각 적용하여 상기 객체의 가변영역을 추정할 수 있다. 차량 내 객체 모 니터링 장치는 상기 추정된 객체의 가변영역에 객체의 특징 추출 알고리즘을 각각 적용하여, 상기 제1 특징 정 보로서, 상기 제1 영상 내 상기 객체의 형태 및 상기 객체에서의 고유정보에 대한 제1 지점을 추출하고, 상기 제2 특징 정보로서, 상기 제2 영상 내 상기 객체에서의 고유정보에 대한 제2 지점을 추출할 수 있다. S1607에서, 차량 내 객체 모니터링 장치는 제1 특징 정보 및 제2 특징 정보에 기초하여, 상기 객체의 상태를 인 식할 수 있다. 이때, 차량 내 객체 모니터링 장치는 상기 제1 영상 내 상기 제1 지점에 대응하는 영상을, 상기 제2 영상 내 상기 제2 지점에 대응하는 영상으로 대체시켜, 상기 객체의 상태를 인식할 수 있다. 단계 S1604에서, 차량 내 객체 모니터링 장치는 상기 추정된 객체의 가변영역에 객체의 특징 추출 알고리즘을 각각 적용하여, 상기 제1 특징 정보 및 상기 제2 특징 정보를 추출할 수 있다. 이후, 차량 내 객체 모니터링 장치는 주행하는 상기 차량 내 상기 객체의 종류가 운전자일 경우, 상기 객체의 상태로서 인식된 운전자의 시선이 설정된 범위를 설정된 시간 동안 벗어나면, 사고 위험 경고를 발생하여, 교통 사고를 방지할 수 있게 한다. 또한, 차량 내 객체 모니터링 장치는 주행하는 상기 차량 내 상기 객체의 종류가 운전자이고, 상기 운전자의 시 선이 상기 차량 내 디스플레이를 향하는지의 여부 및 상기 운전자의 머리가 향하는 방향에 기초하여, 상기 디스 플레이의 백라이트 전원을 제어할 수 있다. 한편, 차량 내 객체 모니터링 장치는 상기 제1 카메라 및 상기 제2 카메라로부터 설정된 주기 마다 각각 상기 제1 영상 및 상기 제2 영상을 수신할 수 있으며, 상기 주기적으로 수신되는 제1 영상 및 제2 영상에 기초하여, 상기 차량 내 설정된 공간에 위치하는 객체가 상기 공간의 외부로 이동하는 것으로 확인되면, 상기 이동된 객체 의 상태를 인식할 수 있다. 차량 내 객체 모니터링 장치는 상기 공간에 배치된 객체가 종류별로 설정된 기준에 미달하는 경우, 미달된 종류 에 해당하는 객체의 식별정보를 상기 차량을 기준으로 설정된 거리 내에 위치하는 상점 내 상점 단말로 제공하 고, 상기 차량에 설치된 드론으로 하여금, 상기 상점으로 이동하여, 상기 객체의 식별정보에 대응하는 상품을 획득하여 상기 차량에 공급하도록 한다. 이때, 차량 내 객체 모니터링 장치는 상기 드론의 배터리 용량을 확인 하고, 상기 배터리 용량에 기초하여 상기 상점에 대한 상기 드론의 왕복이 가능한 경우, 상기 드론을 상기 상점 으로 이동시킬 수 있다. 또한, 차량 내 객체 모니터링 장치는 상기 차량의 주행 속도 및 상기 드론의 왕복 시간 중 적어도 하나에 기초 하여, 상기 차량이 주행하는 경로에 포함되는 상점을 선택하고, 상기 선택된 상점 내 상점 단말로 상기 객체의 식별정보를 제공할 수 있다. 이상 설명된 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 \"상기\"의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하 는 각 개별적인 값을 기재한 것과 같다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물 의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2019-0126195", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 차량 내 객체 모니터링 장치가 적용되는 차량을 도시한 도면이다. 도 2는 본 발명의 실시예에 따른 차량 내 객체 모니터링 장치가 적용되는 시스템을 도시한 블록도이다. 도 3은 5G 통신 시스템에서 자율 주행 차량과 5G 네트워크의 기본동작의 일 예를 나타낸 도면이다. 도 4는 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치의 구성을 도시한 도면이다. 도 5는 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 객체가 능동적 객체일 때, 객체의 상태를 인식하는 일례를 설명하기 위한 도면이다. 도 6은 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 객체가 수동적 객체일 때, 객체의 상태를 인식하는 일례를 설명하기 위한 도면이다.도 7은 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 운전자의 상태를 모니터링하여, 사고위험을 방지하는 일례를 설명하기 위한 도면이다. 도 8 및 도 9는 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 운전자의 상태를 모니터링하여, 차 량 내 컴포넌트의 전원을 제어하는 일례를 설명하기 위한 도면이다. 도 10은 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 차량 내 설정된 공간에 존재하는 상품의 상태를 인지하는 일례를 설명하기 위한 도면이다. 도 11은 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 차량 내 설정된 공간에 존재하는 상품의 상태를 인지하는 다른 일례를 설명하기 위한 도면이다. 도 12 내지 도 15는 본 발명의 일실시예에 따른 차량 내 객체 모니터링 장치에서 차량 내 설정된 공간에 존재하 는 상품의 수량을 관리하는 일례를 설명하기 위한 도면이다. 도 16은 본 발명의 일실시예에 따른 차량 내 객체 모니터링 방법을 나타내는 흐름도이다."}
