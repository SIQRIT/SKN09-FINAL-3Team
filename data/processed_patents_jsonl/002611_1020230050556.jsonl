{"patent_id": "10-2023-0050556", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0154228", "출원번호": "10-2023-0050556", "발명의 명칭": "인공지능 분석 엔진에 의한 기계 학습 데이터셋 제작 방법", "출원인": "주식회사 세명소프트", "발명자": "황바울"}}
{"patent_id": "10-2023-0050556", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "시맨틱 세그멘테이션(Semantic segmentation))을 통해 의류 영상을 여러 상품으로 pixel단위로 분리해 내는 단계; 및시맨틱 세그멘테이션 이후 각 상품 단위로 본래 이미지를 잘라내는 기법인 이미지 크롭핑(image cropping)을 적용하여 이를 속성인식(Attribute Recognition) 엔진에 추론(inference) 하는 단계;를 포함하고,상기 시맨틱 세그멘테이션은사진에 있는 모든 픽셀을 미리 정해둔 클래스(class) 단위로 분류하는 것이며, 상기 속성인식(AttributeRecognition)은 패션에 대한 이미지(image) 한 장을 입력으로 받고 그 이미지(image)에 대해서 포함하고 있는의류에 대한 속성을 파악하는 작업이며, 속성(Attribute)의 종류로는 색상, 소재, 패턴, 또는 길이의 특징이며,세그멘테이션(segmentation)작업의 효율을 높이 위해 반자동 세그멘테이션(segmentation)기법으로서, 초기 AI기반의 세그멘테이션(segmentation) 영상의 윤곽(contour) 정보를 배경(background)과 전경(foreground)의 시드(seed)로 활용하여 그랩컷(grabcut)을 실시하여 기존의 세그멘테이션(segmentation) 품질을 향상시킨 뒤, 이를 기반으로 자동으로 꼭지점(vertex) 생성을 통해 다각형(polygon)을 가공해주는 것을 특징으로 하는 인공지능분석 엔진에 의한 기계 학습 데이터셋 제작 방법."}
{"patent_id": "10-2023-0050556", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 AI 기반 패션 분석 엔진에 의한 인공지능 데이터셋 제작 방법에 관한 것으로, Semantic segmentation 을 통해 의류 영상을 여러 상품으로 pixel단위로 분리해 내는 단계; Semantic segmentation 이후 각 상품 단위 로 본래 이미지를 잘라내는 기법(image cropping)을 적용하여 이를 Attribute Recognition 엔진에 inference 하 는 단계;를 포함하는 것으로 본 발명은 세그먼테이션(segmentation) 엔진을 학습하기 위해 기존에는 사람이 작업 했던 polygon data 가공 단계에 반자동(semi-auto) 세그먼테이션(segmentation)을 도입하여 작업시간을 단축시 키며, 데이터수집의 효율을 높여 가격 경쟁력을 확보하는 현저한 효과가 있다."}
{"patent_id": "10-2023-0050556", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 AI 기반 분석 엔진에 의한 기계 학습 데이터셋 제작 방법에 관한 것으로, 보다 상세하게는 세그먼테 이션(segmentation) 엔진을 학습하기 위해 기존에는 사람이 작업했던 polygon data 가공 단계에 반자동(semi- auto) 세그먼테이션(segmentation)을 도입하여 작업시간을 단축시키며, 데이터수집의 효율을 높여 가격경쟁력을 확보하는 AI 기반 패션 분석 엔진에 의한 기계 학습 데이터셋 제작 방법에 관한 것이다."}
{"patent_id": "10-2023-0050556", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 고객이나 본인의 패션을 분석하는데 있어서, 인공지능이 많이 사용되고 있는 추세이며, 종래특허기 술의 일례로서 공개특허공보 공개번호 10-2019-0078222호에는 서버가 사용자에게 제1 패션 상품에 기초하여 제2 패션 상품을 추천하는 방법에 있어서, 전자 장치로부터 상기 제1 패션 상품의 이미지 데이터를 수신하는 단계와 상기 제1 패션 상품의 이미지 데이터를 기 설정된 벡터 공간 상의 특정 위치에 매핑하는 단계와, 상기 제1 패션 상품의 상기 이미지 데이터에 대응되는 제1 벡터를 획득하는 단계와, 상기 획득된 제1 벡터 및 패션 상품의 적 어도 하나의 카테고리 벡터를 이용하여, 제2 벡터를 산출하는 단계와, 상기 산출된 제2 벡터에 기초하여, 제2 패션 상품의 이미지 데이터를 획득하는 단계; 및 상기 획득된 제2 패션 상품의 이미지 데이터를 상기 전자 장치 로 송신하는 단계를 포함하는, 서버의 패션 상품 추천 방법이 공개되어 있다. 또한 등록특허공보 등록번호 10-1913750호에는 사용자 단말기의 패션추천 요청에 따라, 입력되는 사용자의 치수 를 포함하는 신체특징과 관련된 데이터인 생체정보 및 상기 사용자가 보유한 패션 아이템과 관련된 데이터인 아 이템 정보에 기초하여 상기 사용자에 대한 제1패션추천정보를 생성하는 코디네이션 서버와, 상기 코디네이션 서 버에 축적된 상기 제1 패션추천정보 및 외부에서 수집된 복수의 샘플데이터에 기초하여 학습절차를 수행하고, 학습결과에 대응하는 제2 패션추천정보를 생성하는 학습 서버와, 사용자가 보유한 아이템에 대한 판매, 양도 및 교환절차를 수행하는 마켓 서버를 포함하고, 상기 코디네이션 서버는, 상기 사용자 단말기로부터 상기 생체정보 및 아이템 정보를 포함하는 데이터를 수신하고, 상기 사용자 단말에 상기 제1 또는 제2 패션추천정보를 제공하 는 단말기 연동부; 및 상기 생체정보 및 아이템 정보를 스타일리스트 단말기에 제공하여 상기 사용자에 대한 패 션추천을 요청하고, 요청에 대한 응답을 수신하여 상기 제1 패션추천정보를 생성하고, 상기 제1 패션추천정보에 반영되는 색상환표 및 부가정보를 입력받는 패턴 매칭부를 포함하고, 상기 학습 서버는, 상기 제1 패션추천정보와, 좋고 나쁨정도가 분류된 정보인 복수의 샘플데이터를 수집하여 상기 제2 패션추천정보의 생성을 위한 로우 데이터를 생성하는 데이터 수집부를 포함하는 패션 코디네이션 시스템이 공개되어 있다. 그러나 상기 종래기술들은 AI 기반 패션 분석시 polygon data 가공 단계에서 작업시간이 길며, 데이터수집의 효 율이 낮아 가격경쟁력이 떨어지는 단점이 있었다."}
{"patent_id": "10-2023-0050556", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서 본 발명은 상기와 같은 문제점을 해결하고자 안출된 것으로, 세그먼테이션(segmentation) 엔진을 학습하 기 위해 기존에는 사람이 작업했던 polygon data 가공 단계에 반자동(semi-auto) 세그먼테이션(segmentation) 을 도입하여 작업시간을 단축시키며, 데이터수집의 효율을 높여 가격경쟁력을 확보하는 AI 기반 분석 엔진에 의 한 기계 학습 데이터셋 제작 방법을 제공하고자 하는 것이다."}
{"patent_id": "10-2023-0050556", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 AI 기반 패션 분석 엔진에 의한 인공지능 데이터셋 제작 방법에 관한 것으로, 시멘틱 세그먼테이션 (Semantic segmentation)을 통해 의류 영상을 여러 상품으로 pixel단위로 분리해 내는 단계와, Semantic segmentation 이후 각 상품 단위로 본래 이미지를 잘라내는 기법(image cropping)을 적용하여 이를 Attribute Recognition 엔진에 inference 하는 단계;를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0050556", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "따라서 본 발명은 세그먼테이션(segmentation) 엔진을 학습하기 위해 기존에는 사람이 작업했던 polygon data 가공 단계에 반자동(semi-auto) 세그먼테이션(segmentation)을 도입하여 작업시간을 단축시키며, 데이터수집의 효율을 높여 가격경쟁력을 확보하는 현저한 효과가 있다."}
{"patent_id": "10-2023-0050556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명과 본 발명의 실시에 의해 달성되는 기술적 과제는 다음에서 설명하는 본 발명의 바람직한 실시예들에 의하여 보다 명확해질 것이다. 다음의 실시예들은 단지 본 발명을 설명하기 위하여 예시된 것에 불과하며, 본발명의 범위를 제한하기 위한 것은 아니다. 도 1은 본 발명의 AI 엔진 기본 흐름도이고, 도 2는 본 발명의labrlme_작업 예시사진이고, 도 3은 본 발명의 Clip Polygon 기능 적용전 이미지이고, 도 4는 본 발명의 Clip Polygon기능 적용 전 이미지이고, 도 5는 본 발 명의 Clip Polygon기능 적용 후 이미지이고, 도 6은 본 발명의 Semantic segmentation과 Instance segmentation의 차이를 표시한 이미지이다. 도 1 내지 도 6을 참조하면, 본 발명은 AI 기반 패션 분석 엔진에 의한 인공지능 데이터셋 제작 방법에 관한 것으로, Semantic segmentation을 통해 의류 영상을 여러 상품으로 pixel단위로 분리해 내는 단계와, Semantic segmentation 이후 각 상품 단위로 본래 이미지를 잘라내는 기법(image cropping)을 적용하여 이를 Attribute Recognition 엔진에 inference 하는 단계로 구성된다. 또한, 상기 Semantic segmentation은 사진에 있는 모든 픽셀을 미리 정해둔 class 단위로 분류하는 것이고, 상 기 Attribute recognition은 패션에 대한 image 한 장을 입력으로 받고 그 image에 대해서 포함하고 있는 의류 에 대한 속성을 파악하는 작업이며, Attribute의 종류로는 색상, 소재, 패턴, 또는 길이의 특징들인 것이다. 또한, 상기 세그먼테이션(segmentation)작업의 효율을 높이 위해 반자동 세그먼테이션(segmentation)기법으로서, 초기 AI 기반의 세그먼테이션(segmentation) 영상의 contour 정보를 background과 foreground의 seed로 활용하여 grabcut을 실시하여 기존의 세그먼테이션(segmentation) 품질을 향상시킨 뒤, 이를 기반으로 자동으로 vertex 생성을 통해 polygon을 가공해주는 것을 특징으로 한다. 이어서 본 발명을 첨부도면에 의해 상세히 설명하면 다음과 같다. 본 발명의 AI 기반 패션 분석 엔진은 이미지 속 패션을 약 130개의 속성값으로 분석해낼 수 있다. 엔진의 전반적인 처리 흐름은 다음과 같다. 우선 Semantic segmentation을 통해 의류 영상을 7종류의 상품 (shirts blouse, coat, jacket, pants, leggings stocking, one-piece, skirt)으로 pixel단위로 분리해 낸다. Semantic segmentation 이후 각 상품 단위로 본래 이미지를 잘라내는 기법(image cropping)을 적용하여 이를 Attribute Recognition 엔진에 inference 한다. Semantic segmentation, Attribute Recognition 작업을 수행하기 위해 Deep learning network를 사용하였다. 네트워크를 교사 학습(supervised learning) 하기 위해 필요한 학습 Data를 가공하였고, 학습 Data를 가공하는 방식은 기본적으로 사람이 직접 제작하는 수동 방식인데 이는 인건비 측면에서 매우 비효율적인 면이 있다. 따라서, 자동화 혹은 반자동화를 최대한 적용하여 소수의 사람이 한 번에 많은 작업을 효율적으로 수행할 수 있 도록 하는 것이 매우 중요하다. 본 발명에서는 세그먼테이션(segmentation) 엔진을 학습하기 위해 기존에는 사람이 작업했던 polygon data 가공 단계에 반자동(semi-auto) 세그먼테이션(segmentation)을 도입하여 완전 수동에 비해 약 40%가량 작업시간을 단 축시킬 수 있다. 첫 번째로 Semantic segmentation 구현방법에 대해 설명하면 다음과 같다. 표 1 NO. 기능명 개발 내용 비고 1OPEN 프로그램 실행 방법 개선 2Histroy 작업 내용 기록, 뒤로가기 기능 개발 3Draw Outline 드로잉 라벨링 도구 개발 4Label Color 동일 Labels 동일 색상으로 자동 지정 기능 개발 5Combine Polygons 선택 영역 병합 기능 개발 6Clip Polygon 교차 영역 제외 기능 개발 7Create Rectangle 점 추가/삭제 기능 추가 8Edit Image Option 이미지 대비, 밝기 조절 기능 개발 9Demi-Auto Detection(AI)AI 인식 라벨링 도구 개발 10Hand 이미지 창 이동 도구 개발 11Magnet 마그넷 라벨링 도구 개발 12Brush 브러쉬 라벨링 도구 개발 13Super Pixel 픽셀 인식 라벨링 도구 개발상기 표 1은 semantic segmentation 기능 개발 목록표로서, Semantic Image segmentation의 궁극적인 목적은 사진에 있는 모든 픽셀을 미리 정해둔 class 단위로 분류하는 것이다. 예를 들어, 1장의 이미지의 크기가 (200 x 200) 이며, 100장의 이미지에 대한 인공지능 엔진을 만든다면, 400,0000 (40만개)개의 모든 픽셀의 대한 예측 을 한다. 그러므로, LABELME 프로그램으로 데이터 수집을 할때 영역 실수 하나하나가 Critical 하다. 도 2의 예시 이미지와 같이 영역을 얼마나 미세하게 하지만 실수 없이 작업하는게 매우 중요하다. 데이터를 수 집하는 작업자가 실수를 하였을때 그 작업자가 누구인지, 잘못된 부분을 바로 수정 할 수 있어야 한다. 도 4의 이미지와 같이 여러 객체를 작업을 할때 최대한 Boundary를 지키되 겹치는 부분이 없어야 한다. 겹치는 부분을 그 부분의 교차 영역만 제외 할 수 있는 기능이다. Clip Polygon 기능을 적용전과 적용후의 차이를 확 인할 수 있다. 인공지능 엔진을 생각하면, 적용전과 적용후의 Data Quality 차이는 매우 크다. 픽셀 하나하나 Dot 좌표를 수정 하는 것 보다 Clip Polygon 기능을 사용하면 오류를 수정하는데 있어서 매우 효율 적이다. Semantic segmentation은 Computer vision 분야에서 가장 핵심적인 분야 중에 하나로 단순히 사진을 보고 분류 하는 것에 그치지 않고 그 장면을 완벽하게 이해해야 하는 높은 수준의 문제이다. 자율주행에서부터 사람 인식까지 적용분야가 무궁무진 하다. 이 분야는 다른 Computer vision 문제들과 마찬가 지로 Deep Convolution Neural Network (깊은 신경망)을 적용해서 많은 발전을 이루었다. Semantic Image segmentation의 궁극적인 목적은 사진에 있는 모든 픽셀을 미리 정해둔 class 단위로 분류하는 것이다. 이미지 에 있는 모든 픽셀에 대한 예측을 하는 것이기 때문에 dense prediction이라고도 불리며, instance segmentation과 다르게 같은 class의 instance를 구별하지 않는다는 것이 특징이다. 도 6에 도시된 사진처럼 같은 class에 속하는 object(사람이 5명)가 있을 때 사람을 따로 분류하지 않고, 그 픽 셀 자체가 어떤 class에 속하는지에만 관심이 있다. 본 발명에서는 7가지 라벨(shirts blouse, coat, jacket, pants, leggings stocking, one-piece, skirt)에 대 해 세그먼테이션(segmentation)을 수행하였다. 두번째로 Attribute recognition 구현 방법에 대해 설명하면 다음과 같다. Attribute recognition구현방법은 'Flag' {} 값이 비어있다는거를 알 수 있다. 기존의 세그먼테이션(segmentation)와 Auto 세그먼테이션(segmentation) 픽셀 좌표 데이터만 가지고는 Attribute Recognition 인공지능 엔진을 개발 할 수 없다. 더 나아가 이미지마다 Label(shirtblouse, pants, skirt, coat) 등 각 이미지마다 존재하는게 다르므로, 해당 이미지에 Label과 그에 맞는 Attribute를 수집하여야 한다(MAGNET 기능). Magnet 기능을 추가하여, 데이터를 수집을 하면 위 이미지와 같이 Flag 안에 Attribute데이터가 들어가 있는걸 확인 할 수 있다. 중요한 점은, 해당 Label과 Attribute가 연결이 되어 있어야 하며, 그렇게 연결이 되어있음을 확인할 수 있다. Pixel 단위 Classification인 세그먼테이션(segmentation)와 달리 해당 Label의 이미지 전체에 대한 Classification이다. Attribute recognition은 패션에 대한 image 한 장을 입력으로 받고 그 image에 대해서 포함하고 있는 의류에 대한 속성을 파악하는 작업이며, Attribute의 종류로는 색상, 소재, 패턴, 길이 등 다수의 특징들이 될 수 있다. 이러한 작업은 기존 image recognition에서 수행하던 image classification 작업과 유사하다고 할 수 있 으며, 본 발명에서는 image classification 작업에 용이한 network 중에서 resnet과 efficientnet을 기반으로 작업을 진행하였다. 의류의 속성 카테고리가 18가지 종류다 되기 때문에 각 network의 특성에 맞게 세부적으로 tuning 하는 작업을 진행하였다. 세번째로 Auto 세그먼테이션(segmentation) 에 대해 설명하면 다음과 같다. 세그먼테이션(segmentation) Engine을 학습하기 위해서는 original image와 segmented image가 쌍으로 필요하 다. 따라서, original image를 세그먼테이션(segmentation)해야하는 작업을 수행해야 하는데, 이 부분은 컴퓨터가 자동으로 하기 어려운 부분이라, 일반적으로 사람이 직접 수행한다. 작업을 효율적으로 수행할 수 있도록 보 조하는 software들이 많은데, 본 발명에서는 MIT(Massachusetts Institute of Technology) 컴퓨터 과학 및 인 공지능 연구소에서 데이터 가공 용으로 만들 수 있도록 개발한 \"Labelme\" 프로그램을 사용한다. \"Labelme\" 프로그램에서는 세그먼테이션(segmentation)을 하려고 하는 피사체의 경계 부분에 대해 마우스 클릭 을 통해 점(vertex)을 생성하며, 이러한 점들의 집합으로 피사체에 대한 polygon을 생성하게 된다. 문제는 image내 피사체의 형상이 복잡할수록 polygon의 vertex 수가 많아질 수밖에 없고 이는 곧 작업 시간과 연결되기 때문에 작업의 효율이 매우 떨어지게 된다. image를 눈으로 보면서 하는 세그먼테이션(segmentation) 작업을 숙 련자가 수행한다고 한다고 해도 하나의 image를 처리하는데 3분 이상 소요된다. 따라서 많은 양의 데이터에 대 한 세그먼테이션(segmentation) 작업을 수행한다면 많은 비용이 요구될 수 밖에 없다. 세그먼테이션 (segmentation) 작업의 효율성을 높이기 위해, 본 발명에서는 반자동 세그먼테이션(segmentation) 기법을 제안 한다. 반자동 세그먼테이션(segmentation)은 초기 AI 기반의 세그먼테이션(segmentation) 영상의 contour 정보 를 background과 foreground의 seed로 활용하여 grabcut을 실시하여 기존의 세그먼테이션(segmentation) 품질 을 향상시킨 뒤, 이를 기반으로 자동으로 vertex 생성을 통해 polygon을 가공해주는 기능을 제안한다. GrabCut 알고리즘은 이미지에서 배경이 아닌 전경에 해당하는 이미지를 추출해 내는 방법이다. 이미지에서 한 번에 전경을 추출해 내는 것이 아닌 여러 단계를 거쳐 전경을 추출한다. 이 단계는 크게 2가지 단계로 진행되는 데, 첫번째는 이미지에서 전경이 포함되는 영역을 사각형으로 대략적으로 지정한다. 단, 이때 지정한 사각형 영 역 안에는 전경이 모두 포함되야 한다. 그리고 두번째는 첫번째에서 얻어진 전경 이미지의 내용 중 포함되어진 배경 부분은 어디인지, 누락된 전경 부분은 어디인지를 seed를 통해 마킹하면 이를 이용해 다시 전경 이미지를 새롭게 추출한다. 이러한 원리를 이용하여 각 Label에 대해 섬세한 세그먼테이션(segmentation)을 적용할 수 있 고, 이를 통해 사람의 작업 효율을 끌어올릴 수 있다. 이미지 를 불러와 픽셀값 하나하나가 들어있는 배열을 생성한다. 픽셀값이 들어있는 배열을 이용해 배경과 객체를 구분하기 위해 필터를 적용한다. 외곽선 검출에서는 findContours 사용한다. 이미지를 이진화 처리 한후 필터를 적용한뒤 경계 그룹을 찾고 이미 지에서 연속된 점과 색깔을 분석한 등고선 형태 를 이용해 사물의 형태(shape)를 탐지하고 사물(object)을 탐지 한다. 어두운 영역이나 밝은 영역의 주변을 물체와 동일하게 만들어 Blur 처리와 비슷한 효과를 준다. Maskclose 와 maskfianl 을 넣어 외곽선을 찾는다. 객체의 외곽선의 x, y 좌표값의 최대값을 가져와 가로 세로폭을 가져온다 4개의 좌표를 가져와 실수형을 정수형으로 변경한뒤 최적화된 직선을 추출한다. 거리 함수 fitLine 을 사용했다. 직선거리를 구해서 최적화된 Boung box 의 영역 과 객체 의 외곽선을 그린다. Bounding box 의 영역이 좁고 정확할수록 객체의 속성을 좀더 정확하게 구분 할 수 있다. 단색 배경이 아닌 풍 경, 햇빛 등등 많은 요소들에 의해서 bounding box 의 영역이 부정확해지기 때문에 학습된 Model 을 통해서 좀 더 정확한 영역을 구분 하도록 한다. 학습된 모델을 통해 분리된 영역의 속성을 자동으로 인식 후 알려준다."}
{"patent_id": "10-2023-0050556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상에서 본 발명은 도면에 도시된 일 실시예를 참고로 설명되었으나, 본 기술분야의 통상의 지식을 가진 자라 면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15"}
{"patent_id": "10-2023-0050556", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 AI 엔진 기본 흐름도, 도 2는 본 발명의labrlme_작업 예시사진, 도 3은 본 발명의 Clip Polygon 기능 적용전 이미지, 도 4는 본 발명의 Clip Polygon기능 적용 전 이미지, 도 5는 본 발명의 Clip Polygon기능 적용 후 이미지, 도 6은 본 발명의 Semantic segmentation과 Instance segmentation의 차이를 표시한 이미지, 도 7은 본 발명의 Deeplab V3+ 알고리즘 흐름도, 도 8은 본 발명의 Semantic segmentation 결과 이미지, 도 9는 본 발명의 MAGNET 기능 적용 전 데이터 (Json)형태, 도 10은 본 발명의 Auto 세그먼테이션(segmentation) 구현 방법도, 도 11은 본 발명의 Auto 세그먼테이션(segmentation) 구현 방법 흐름도, 도 12는 본 발명의 Auto 세그먼테이션(segmentation) 구현 이미지, 도 13은 본 발명의 Auto 세그먼테이션(segmentation) 구현수식도, 도 14는 본 발명의 label Auto Detection도, 도 15는 본 발명의 label Auto Detection 시료측정도이다."}
