{"patent_id": "10-2021-0011926", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0108668", "출원번호": "10-2021-0011926", "발명의 명칭": "동영상 분석 방법", "출원인": "오지큐 주식회사", "발명자": "최장원"}}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "운영서버를 통해 방법에 있어서, 지정된 컨텐츠관리매체에 저장된 동영상 컨텐츠를 지정된 프레임 단위로 분석하여 기 설정된 T(T≥1)개의 객체카테고리 중 적어도 한 객체 카테고리에 속한 객체를 포함하는 M(M≥1)개의 객체를 인식하는 제1 단계; 상기 인식된 M개의 객체를 상기 설정된 객체 카테고리에 따라 분류하여 동일한 객체 카테고리에 속한 m(1≤m≤M)개의 객체를 포함한 상태를 유지하는 프레임 구간을 포함하는 N(N≥1)개의 프레임 구간을 인식하는 제2 단계;및상기 인식된 N개의 프레임 구간 정보와 각각의 프레임 구간에 포함된 각각의 m개의 객체가 속한 적어도 하나의객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 생성하여 지정된저장매체에 저장하는 제3 단계;를 포함하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,동영상 컨텐츠의 프레임을 분석하여 인식 가능한 각 객체에 대한 객체 정보와 각 객체가 속한 적어도 하나의 객체 카테고리를 포함하는 T(T≥1)개의 객체 카테고리 정보를 저장하는 단계를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, 상기 객체 정보는, 각 객체의 고유한 객체 명칭 정보와 각 객체에 부여된 적어도 하나의 객체 태그 정보 중 적어도 하나의 정보를포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서, 상기 객체 정보는, 각 객체를 인식하기 위한 각 객체의 관측된 특징에 대응하는 객체 별 객체 특징 정보를 더 포함하여 이루어지는것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3항에 있어서, 상기 객체 정보는, 각 객체의 관측된 특징을 통해 인식된 각 객체를 식별하는 객체 식별 정보를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항 또는 제 2항에 있어서, 공개특허 10-2022-0108668-3-상기 객체 카테고리는, 기 설정된 분류 기준에 대응하는 계층 구조를 포함하며, 상기 객체는, 상기 계층 구조의 객체 카테고리 중 적어도 한 계층의 객체 카테고리에 포함되는 것을 특징으로하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 2항에 있어서, 상기 객체 정보에 대응하는 객체의 관측된 특징에 대응하는 입력 정보와 상기 객체 정보에 대응하는 객체의 관측된 결과에 대응하는 출력 정보를 지정된 인공지능모듈에 대입하여 상기 객체 정보에 대응하는 객체를 인식하는 객체 인식을 학습시키는 단계를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서, 상기 제1 단계는, 상기 객체 인식을 학습한 인공지능모듈을 통해 상기 동영상 컨텐츠를 지정된 프레임 단위로 분석하여 지정된 객체를 인식하는 단계를 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서, 상기 제1 단계는, 상기 동영상 컨텐츠에 포함된 각 장면전환 프레임 사이의 장면 구간을 식별하는 단계; 상기 식별된 각 장면 구간에 포함된 복수의 프레임 중 적어도 하나의 인식 대상 프레임에 대응하는 인식 대상프레임 이미지를 선정하는 단계; 상기 객체 인식을 학습한 인공지능모듈에 상기 선정된 인식 대상 프레임 이미지의 관측된 특징을 대입하여 지정된 객체를 인식하는 단계;를 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서, 상기 인식 대상 프레임은, 각 장면 구간의 첫번째 프레임, 각 장면 구간의 첫번째 프레임에서 지정된 프레임 수만큼 이후로 이동한 프레임, 각 장면 구간의 가운데 프레임, 각 장면 구간의 첫번째 프레임에서 지정된 프레임 수만큼 전후로 이동한 프레임, 각 장면 구간의 마지막 프레임, 각 장면 구간의 마지막 프레임에서 지정된 프레임 수만큼 이전으로 이동한 프레임, 각 장면 구간을 기 설정된 프레임 수 단위 또는 재생시간 단위로 분할하여 선별된 프레임, 각 장면 구간에 포함된 프레임 중 모션블러(Motion Blur)가 없거나 가장 적은 프레임, 각 장면 구간에 포함된 프레임 중 카메라워킹(Cameraworking)이 없거나 가장 적은 프레임 중 적어도 하나 또는둘 이상의 조합에 대응하는 프레임을 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2022-0108668-4-제 1항에 있어서, 등록자 단말을 통해 동영상 컨텐츠를 등록받아 지정된 컨텐츠관리매체에 저장하는 단계를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서, 등록자 단말을 통해 동영상 컨텐츠를 등록 시, 상기 등록자 단말을 통해 상기 등록되는 동영상 컨텐츠에 포함된 객체와 관련된 적어도 하나의 동영상 태그 정보를 등록받는 단계; 및상기 동영상 컨텐츠와 상기 등록된 동영상 태그 정보를 연계하여 상기 컨텐츠관리매체에 저장하는 단계;를 더포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서, 상기 제1 단계는, 상기 등록된 동영상 태그 정보에 대응하는 객체를 인식하는 단계를 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11항에 있어서, 등록자 단말을 통해 동영상 컨텐츠를 등록 시, 상기 등록자 단말을 통해 상기 등록되는 동영상 컨텐츠를 설명하는 동영상 설명 정보를 등록받는 단계; 및상기 동영상 컨텐츠와 상기 등록된 동영상 설명 정보를 연계하여 상기 컨텐츠관리매체에 저장하는 단계;를 더포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14항에 있어서, 상기 제1 단계는, 상기 등록된 동영상 설명 정보에 포함된 단어를 근거로 상기 동영상 컨텐츠에 포함된 객체와 관련된 객체 관련태그 정보를 추출하는 단계; 및상기 추출된 객체 관련 태그 정보에 대응하는 객체를 인식하는 단계를 포함하여 이루어지는 것을 특징으로 하는동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 1항에 있어서, 상기 m개의 객체는, 동일한 객체를 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2022-0108668-5-제 1항에 있어서, 상기 m개의 객체는, 동일한 객체 카테고리에 속한 서로 다른 둘 이상의 객체를 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 1항에 있어서, 상기 프레임 구간은, 각 장면 구간과는 별개 또는 독립적으로 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 근거로 구분되는 구간을 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 1항 또는 제 18항에 있어서, 상기 프레임 구간은, 특정 장면 구간 중 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 유지하는 일부 장면 구간,동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 유지하는 복수의 장면 구간의 조합 구간, 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 유지하는 적어도 하나의 장면 구간과 일부 장면 구간의 조합 구간 중 적어도 하나의 구간을 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 1항에 있어서, 상기 N개의 프레임 구간 정보는, 각 프레임 구간에 포함된 객체가 속한 객체 카테고리에 따라 적어도 일부 중첩된 구간을 포함하여 이루어지는것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 1항에 있어서, 상기 객체 분석 정보는, 각각의 프레임 구간에서 인식된 m개의 객체에 대한 객체 정보를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 21항에 있어서, 상기 객체 분석 정보는, 상기 객체 정보에 대응하는 객체가 포함된 적어도 하나의 객체 별 프레임 구간 정보를 더 포함하여 이루어지는것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 1항에 있어서, 상기 제2 단계는, 각각의 프레임 구간에 포함된 인식 대상 프레임을 통해 지정된 객체를 인식하는 과정 중에 산출된 인식 대상 프레임 별 객체 매칭율 정보를 확인하는 단계를 더 포함하며, 상기 객체 분석 정보는, 상기 인식 대상 프레임 별 객체 매칭율 정보를 더 포함하여 이루어지는 것을 특징으로하는 동영상 분석 방법.공개특허 10-2022-0108668-6-청구항 24 제 1항에 있어서, 사용자 단말을 통해 지정된 동영상 컨텐츠에 포함된 객체를 분석한 객체 분석 정보를 요청하는 정보를 수신하는단계; 및상기 사용자 단말로 상기 동영상 컨텐츠의 객체 분석 정보를 제공하는 단계;를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제 1항에 있어서, 사용자 단말을 통해 적어도 하나의 동영상 컨텐츠에 포함된 객체 카테고리 정보의 검색을 요청하는 검색 요청정보를 수신하는 단계; 지정된 저장매체에 저장된 적어도 하나의 객체 분석 정보를 근거로 상기 검색 요청 정보에 대응하는 검색 대상객체 카테고리 정보를 포함하는 동영상 컨텐츠를 식별하는 동영상 정보와 상기 식별된 동영상 컨텐츠의 프레임구간 중 상기 검색 대상 객체 카테고리 정보를 포함하는 i(i≥1)개의 프레임 구간 정보를 포함하는 검색 결과정보를 생성하는 단계; 상기 사용자 단말로 상기 검색 결과 정보를 제공하는 단계;를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제 25항에 있어서, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구간 정보에 대응하는프레임 구간 내의 지정된 프레임 구간을 분할하는 i개의 프레임 분할 구간 정보를 생성하는 단계; 및상기 생성된 i개의 프레임 분할 구간 정보에 대응하는 i개의 짧은 동영상 컨텐츠를 상기 사용자 단말로 제공하기 위한 i개의 짧은 동영상 컨텐츠 정보를 생성하여 상기 검색 결과 정보에 포함시키는 단계;를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제 25항에 있어서, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구간 정보에 대응하는i개의 대표 이미지를 생성하는 단계; 및상기 생성된 i개의 대표 이미지를 상기 검색 결과 정보에 포함시키는 단계;를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제 1항에 있어서, 상기 객체 분석 정보에 각 프레임 구간에서 인식된 객체에 대응하는 객체 정보가 포함된 경우, 사용자 단말을 통해 적어도 하나의 동영상 컨텐츠에 포함된 객체의 검색을 요청하는 검색 요청 정보를 수신하는공개특허 10-2022-0108668-7-단계; 지정된 저장매체에 저장된 적어도 하나의 객체 분석 정보를 근거로 상기 검색 요청 정보에 대응하는 검색 대상객체를 포함하는 동영상 컨텐츠를 식별하는 동영상 정보와 상기 식별된 동영상 컨텐츠의 프레임 구간 중 상기검색 대상 객체를 포함하는 i(i≥1)개의 프레임 구간 정보를 포함하는 검색 결과 정보를 생성하는 단계; 상기 사용자 단말로 상기 검색 결과 정보를 제공하는 단계;를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제 28항에 있어서, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구간 정보에 대응하는프레임 구간 내의 지정된 프레임 구간을 분할하는 i개의 프레임 분할 구간 정보를 생성하는 단계; 및상기 생성된 i개의 프레임 분할 구간 정보에 대응하는 i개의 짧은 동영상 컨텐츠를 상기 사용자 단말로 제공하기 위한 i개의 짧은 동영상 컨텐츠 정보를 생성하여 상기 검색 결과 정보에 포함시키는 단계;를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제 28항에 있어서, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구간 정보에 대응하는i개의 대표 이미지를 생성하는 단계; 및상기 생성된 i개의 대표 이미지를 상기 검색 결과 정보에 포함시키는 단계;를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제 26항 또는 제 29항에 있어서, 상기 프레임 분할 구간 정보는, 상기 검색 결과 정보에 포함된 프레임 구간 정보와 동일한 구간 정보를 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제 26항 또는 제 29항에 있어서, 상기 프레임 분할 구간 정보는, 상기 검색 결과 정보에 포함된 프레임 구간 정보가 기 설정된 최대 프레임 분할 크기보다 큰 경우, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보를포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제 26항 또는 제 29항에 있어서, 상기 프레임 분할 구간 정보는, 상기 검색 결과 정보에 포함된 프레임 구간 정보가 기 설정된 최대 프레임 분할 크기보다 큰 경우, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보를포함하면서,공개특허 10-2022-0108668-8-상기 검색 결과 정보에 포함된 프레임 구간 정보의 첫번째 프레임부터 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보, 상기 검색 결과 정보에 포함된 프레임 구간 정보의 첫번째 프레임에서 지정된 프레임 수만큼 이후로 이동한 프레임부터 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 모션블러(Motion Blur)가 없거나 기 설정된 기준 값 이내이면서 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 카메라워킹(Cameraworking)이 없거나 기 설정된 기준 값 이내이면서 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보 중 적어도 하나 또는 둘 이상의 조합에 대응하는 구간 정보를 더 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제 26항 또는 제 29항에 있어서, 상기 프레임 분할 구간 정보는, 상기 검색 결과 정보에 인식 대상 프레임 별 객체 매칭율 정보가 포함된 경우, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 상기 프레임 분할 크기와 같거나 작은 범위의 구간을 포함하면서, 기 설정된 순위 내의 객체 매칭율 정보에 대응하는 인식 대상 프레임을 포함하는 구간 정보를 포함하여이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제 26항 또는 제 29항에 있어서, 상기 짧은 동영상 컨텐츠 정보는, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 프레임 분할 구간 정보에 대응하는 프레임 구간을 선택적으로사용자 단말로 제공하여 재생하기 위한 구간 재생 정보를 포함하여 이루어지는 것을 특징으로 하는 동영상 분석방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제 26항 또는 제 29항에 있어서, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 프레임 분할 구간 정보에 대응하는 프레임 구간을 선택적으로추출하여 짧은 동영상 컨텐츠를 생성하는 단계를 더 포함하며, 상기 짧은 동영상 컨텐츠 정보는, 상기 생성된 짧은 동영상 컨텐츠를 사용자 단말로 제공하여 재생하기 위한 동영상 재생 정보를 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "제 27항 또는 제30항에 있어서, 상기 대표 이미지는, 상기 검색 결과 정보에 포함된 각 프레임 구간의 첫번째 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간의 첫번째 프레임에서 지정된 프레임 수만큼 이후로 이동한 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간의 가운데 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간의 첫번째 프레임에서 지정된 프레임 수만큼 전후로 이동한 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간의 마지막 프레임 이미지, 공개특허 10-2022-0108668-9-상기 검색 결과 정보에 포함된 각 프레임 구간의 마지막 프레임에서 지정된 프레임 수만큼 이전으로 이동한 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간에 포함된 프레임 중 모션블러(Motion Blur)가 없거나 가장 적은프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간에 포함된 프레임 중 카메라워킹(Cameraworking)이 없거나 가장적은 프레임 이미지 중 적어도 하나 또는 둘 이상의 조합에 대응하는 프레임 이미지를 포함하여 이루어지는 것을 특징으로 하는 동영상 분석 방법."}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 동영상 분석 방법에 관한 것으로서, 본 발명에 따른 운영서버를 통해 실행되는 동영상 분석 방법은, 지정된 컨텐츠관리매체에 저장된 동영상 컨텐츠를 지정된 프레임 단위로 분석하여 기 설정된 T(T≥1)개의 객체 카테고리 중 적어도 한 객체 카테고리에 속한 객체를 포함하는 M(M≥1)개의 객체를 인식하는 제1 단계와, 상기 인식된 M개의 객체를 상기 설정된 객체 카테고리에 따라 분류하여 동일한 객체 카테고리에 속한 m(1≤m≤M)개의 객체를 포함한 상태를 유지하는 프레임 구간을 포함하는 N(N≥1)개의 프레임 구간을 인식하는 제2 단계와, 상기 인식된 N개의 프레임 구간 정보와 각각의 프레임 구간에 포함된 각각의 m개의 객체가 속한 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 생성하여 지정된 저장매 체에 저장하는 제3 단계를 포함한다."}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 동영상 분석 방법에 관한 것이다. 보다 상세하게는 운영서버에서 지정된 컨텐츠관리매체에 저장된 동 영상 컨텐츠를 지정된 프레임 단위로 분석하여 기 설정된 T(T≥1)개의 객체 카테고리 중 적어도 한 객체 카테고 리에 속한 객체를 포함하는 M(M≥1)개의 객체를 인식하고, 상기 인식된 M개의 객체를 상기 설정된 객체 카테고 리에 따라 분류하여 동일한 객체 카테고리에 속한 m(1≤m≤M)개의 객체를 포함한 상태를 유지하는 프레임 구간 을 포함하는 N(N≥1)개의 프레임 구간을 인식한 후, 상기 인식된 N개의 프레임 구간 정보와 각각의 프레임 구간 에 포함된 각각의 m개의 객체가 속한 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 생성하여 지정된 저장매체에 저장하는 방법에 관한 것이다."}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인터넷과 정보 기술의 발달로 인해 다양한 형태의 영상 컨텐츠가 등장했고, 특히 최근 들어 1인 미디어, 브이로 그 등의 영상 컨텐츠가 급속하게 늘고 있는 추세이다. 이러한 영상 컨텐츠가 증가함에 따라 사용자가 보다 편리하게 다양한 형태의 편집이 가능하도록 하는 동영상 분 석 기술이 필요한 시점이다. 대한민국 공개특허공보 제2011-0020158호, '메타데이터 태깅 시스템, 이미지 검색 방법, 디바이스 및 이에 적용 되는 제스처 태깅방법'에서는 이미지를 분석하여 시각정보와 장소정보를 추출하는 기술이 개시되어 있으나, 태 깅이 이미지 내 시각정보로 한정되는 등 사용자 기반의 최적의 편집 환경을 제공하기 어렵다."}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해소하기 위한 본 발명의 목적은, 지정된 컨텐츠관리매체에 저장된 동영상 컨텐츠를 지정 된 프레임 단위로 분석하여 기 설정된 T(T≥1)개의 객체 카테고리 중 적어도 한 객체 카테고리에 속한 객체를 포함하는 M(M≥1)개의 객체를 인식하고, 상기 인식된 M개의 객체를 상기 설정된 객체 카테고리에 따라 분류하여 동일한 객체 카테고리에 속한 m(1≤m≤M)개의 객체를 포함한 상태를 유지하는 프레임 구간을 포함하는 N(N≥1) 개의 프레임 구간을 인식한 후, 상기 인식된 N개의 프레임 구간 정보와 각각의 프레임 구간에 포함된 각각의 m 개의 객체가 속한 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객 체 분석 정보를 생성하여 지정된 저장매체에 저장하는 동영상 분석 방법을 제공함에 있다."}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 운영서버를 통해 실행되는 동영상 분석 방법은, 지정된 컨텐츠관리매체에 저장된 동영상 컨텐츠 를 지정된 프레임 단위로 분석하여 기 설정된 T(T≥1)개의 객체 카테고리 중 적어도 한 객체 카테고리에 속한 객체를 포함하는 M(M≥1)개의 객체를 인식하는 제1 단계와, 상기 인식된 M개의 객체를 상기 설정된 객체 카테고 리에 따라 분류하여 동일한 객체 카테고리에 속한 m(1≤m≤M)개의 객체를 포함한 상태를 유지하는 프레임 구간 을 포함하는 N(N≥1)개의 프레임 구간을 인식하는 제2 단계와, 상기 인식된 N개의 프레임 구간 정보와 각각의 프레임 구간에 포함된 각각의 m개의 객체가 속한 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 생성하여 지정된 저장매체에 저장하는 제3 단계를 포함하여 구성될 수 있다. 본 발명에 따른 동영상 분석 방법은, 동영상 컨텐츠의 프레임을 분석하여 인식 가능한 각 객체에 대한 객체 정 보와 각 객체가 속한 적어도 하나의 객체 카테고리를 포함하는 T(T≥1)개의 객체 카테고리 정보를 저장하는 단 계를 더 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 객체 정보는, 각 객체의 고유한 객체 명칭 정보와 각 객체에 부여된 적어도 하나의 객 체 태그 정보 중 적어도 하나의 정보를 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 객체 정보는, 각 객체를 인식하기 위한 각 객체의 관측된 특징에 대응하는 객체 별 객 체 특징 정보를 더 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 객체 정보는, 각 객체의 관측된 특징을 통해 인식된 각 객체를 식별하는 객체 식별 정 보를 더 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 객체 카테고리는, 기 설정된 분류 기준에 대응하는 계층 구조를 포함하며, 상기 객체는, 상기 계층 구조의 객체 카테고리 중 적어도 한 계층의 객체 카테고리에 포함될 수 있다. 본 발명에 따르면, 상기 객체 정보에 대응하는 객체의 관측된 특징에 대응하는 입력 정보와 상기 객체 정보에 대응하는 객체의 관측된 결과에 대응하는 출력 정보를 지정된 인공지능모듈에 대입하여 상기 객체 정보에 대응 하는 객체를 인식하는 객체 인식을 학습시키는 단계를 더 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 제1 단계는, 상기 객체 인식을 학습한 인공지능모듈을 통해 상기 동영상 컨텐츠를 지정 된 프레임 단위로 분석하여 지정된 객체를 인식하는 단계를 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 제1 단계는, 상기 동영상 컨텐츠에 포함된 각 장면전환 프레임 사이의 장면 구간을 식 별하는 단계와, 상기 식별된 각 장면 구간에 포함된 복수의 프레임 중 적어도 하나의 인식 대상 프레임에 대응 하는 인식 대상 프레임 이미지를 선정하는 단계와, 상기 객체 인식을 학습한 인공지능모듈에 상기 선정된 인식 대상 프레임 이미지의 관측된 특징을 대입하여 지정된 객체를 인식하는 단계를 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 인식 대상 프레임은, 각 장면 구간의 첫번째 프레임, 각 장면 구간의 첫번째 프레임에 서 지정된 프레임 수만큼 이후로 이동한 프레임, 각 장면 구간의 가운데 프레임, 각 장면 구간의 첫번째 프레임 에서 지정된 프레임 수만큼 전후로 이동한 프레임, 각 장면 구간의 마지막 프레임, 각 장면 구간의 마지막 프레 임에서 지정된 프레임 수만큼 이전으로 이동한 프레임, 각 장면 구간을 기 설정된 프레임 수 단위 또는 재생시 간 단위로 분할하여 선별된 프레임, 각 장면 구간에 포함된 프레임 중 모션블러(Motion Blur)가 없거나 가장 적 은 프레임, 각 장면 구간에 포함된 프레임 중 카메라워킹(Cameraworking)이 없거나 가장 적은 프레임 중 적어도 하나 또는 둘 이상의 조합에 대응하는 프레임을 포함하여 이루어질 수 있다.본 발명에 따른 동영상 분석 방법은, 등록자 단말을 통해 동영상 컨텐츠를 등록받아 지정된 컨텐츠관리매체에 저장하는 단계를 더 포함하여 이루어질 수 있다. 본 발명에 따르면, 등록자 단말을 통해 동영상 컨텐츠를 등록 시, 상기 등록자 단말을 통해 상기 등록되는 동영 상 컨텐츠에 포함된 객체와 관련된 적어도 하나의 동영상 태그 정보를 등록받는 단계와, 상기 동영상 컨텐츠와 상기 등록된 동영상 태그 정보를 연계하여 상기 컨텐츠관리매체에 저장하는 단계를 더 포함하여 이루어질 수 있 다. 본 발명에 따르면, 상기 제1 단계는, 상기 등록된 동영상 태그 정보에 대응하는 객체를 인식하는 단계를 포함하 여 이루어질 수 있다. 본 발명에 따르면, 등록자 단말을 통해 동영상 컨텐츠를 등록 시, 상기 등록자 단말을 통해 상기 등록되는 동영 상 컨텐츠를 설명하는 동영상 설명 정보를 등록받는 단계와, 상기 동영상 컨텐츠와 상기 등록된 동영상 설명 정 보를 연계하여 상기 컨텐츠관리매체에 저장하는 단계를 더 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 제1 단계는, 상기 등록된 동영상 설명 정보에 포함된 단어를 근거로 상기 동영상 컨텐 츠에 포함된 객체와 관련된 객체 관련 태그 정보를 추출하는 단계와, 상기 추출된 객체 관련 태그 정보에 대응 하는 객체를 인식하는 단계를 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 m개의 객체는, 동일한 객체를 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 m개의 객체는, 동일한 객체 카테고리에 속한 서로 다른 둘 이상의 객체를 포함하여 이 루어질 수 있다. 본 발명에 따르면, 상기 프레임 구간은, 각 장면 구간과는 별개 또는 독립적으로 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 근거로 구분되는 구간을 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 프레임 구간은, 특정 장면 구간 중 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 유지하는 일부 장면 구간, 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 유지하는 복수의 장면 구간의 조합 구간, 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 유지하는 적어도 하나의 장 면 구간과 일부 장면 구간의 조합 구간 중 적어도 하나의 구간을 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 N개의 프레임 구간 정보는, 각 프레임 구간에 포함된 객체가 속한 객체 카테고리에 따 라 적어도 일부 중첩된 구간을 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 객체 분석 정보는, 각각의 프레임 구간에서 인식된 m개의 객체에 대한 객체 정보를 더 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 객체 분석 정보는, 상기 객체 정보에 대응하는 객체가 포함된 적어도 하나의 객체 별 프레임 구간 정보를 더 포함하여 이루어질 수 있다.본 발명에 따르면, 상기 제2 단계는, 각각의 프레임 구간에 포함된 인식 대상 프레임을 통해 지정된 객체를 인 식하는 과정 중에 산출된 인식 대상 프레임 별 객체 매칭율 정보를 확인하는 단계를 더 포함하며, 상기 객체 분 석 정보는, 상기 인식 대상 프레임 별 객체 매칭율 정보를 더 포함하여 이루어질 수 있다. 본 발명에 따른 동영상 분석 방법은, 사용자 단말을 통해 지정된 동영상 컨텐츠에 포함된 객체를 분석한 객체 분석 정보를 요청하는 정보를 수신하는 단계와, 상기 사용자 단말로 상기 동영상 컨텐츠의 객체 분석 정보를 제 공하는 단계를 더 포함하여 이루어질 수 있다. 본 발명에 따른 동영상 분석 방법은, 사용자 단말을 통해 적어도 하나의 동영상 컨텐츠에 포함된 객체 카테고리 정보의 검색을 요청하는 검색 요청 정보를 수신하는 단계와, 지정된 저장매체에 저장된 적어도 하나의 객체 분 석 정보를 근거로 상기 검색 요청 정보에 대응하는 검색 대상 객체 카테고리 정보를 포함하는 동영상 컨텐츠를 식별하는 동영상 정보와 상기 식별된 동영상 컨텐츠의 프레임 구간 중 상기 검색 대상 객체 카테고리 정보를 포 함하는 i(i≥1)개의 프레임 구간 정보를 포함하는 검색 결과 정보를 생성하는 단계와, 상기 사용자 단말로 상기 검색 결과 정보를 제공하는 단계를 더 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구 간 정보에 대응하는 프레임 구간 내의 지정된 프레임 구간을 분할하는 i개의 프레임 분할 구간 정보를 생성하는 단계와, 상기 생성된 i개의 프레임 분할 구간 정보에 대응하는 i개의 짧은 동영상 컨텐츠를 상기 사용자 단말로 제공하기 위한 i개의 짧은 동영상 컨텐츠 정보를 생성하여 상기 검색 결과 정보에 포함시키는 단계를 더 포함하 여 이루어질 수 있다. 본 발명에 따르면, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구 간 정보에 대응하는 i개의 대표 이미지를 생성하는 단계와, 상기 생성된 i개의 대표 이미지를 상기 검색 결과 정보에 포함시키는 단계를 더 포함하여 이루어질 수 있다. 본 발명에 따른 동영상 분석 방법은, 상기 객체 분석 정보에 각 프레임 구간에서 인식된 객체에 대응하는 객체 정보가 포함된 경우, 사용자 단말을 통해 적어도 하나의 동영상 컨텐츠에 포함된 객체의 검색을 요청하는 검색 요청 정보를 수신하는 단계와, 지정된 저장매체에 저장된 적어도 하나의 객체 분석 정보를 근거로 상기 검색 요 청 정보에 대응하는 검색 대상 객체를 포함하는 동영상 컨텐츠를 식별하는 동영상 정보와 상기 식별된 동영상 컨텐츠의 프레임 구간 중 상기 검색 대상 객체를 포함하는 i(i≥1)개의 프레임 구간 정보를 포함하는 검색 결과 정보를 생성하는 단계와, 상기 사용자 단말로 상기 검색 결과 정보를 제공하는 단계를 더 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구 간 정보에 대응하는 프레임 구간 내의 지정된 프레임 구간을 분할하는 i개의 프레임 분할 구간 정보를 생성하는 단계와, 상기 생성된 i개의 프레임 분할 구간 정보에 대응하는 i개의 짧은 동영상 컨텐츠를 상기 사용자 단말로 제공하기 위한 i개의 짧은 동영상 컨텐츠 정보를 생성하여 상기 검색 결과 정보에 포함시키는 단계를 더 포함하 여 이루어질 수 있다. 본 발명에 따르면, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구 간 정보에 대응하는 i개의 대표 이미지를 생성하는 단계와, 상기 생성된 i개의 대표 이미지를 상기 검색 결과 정보에 포함시키는 단계를 더 포함하여 이루어질 수 있다.본 발명에 따르면, 상기 프레임 분할 구간 정보는, 상기 검색 결과 정보에 포함된 프레임 구간 정보와 동일한 구간 정보를 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 프레임 분할 구간 정보는, 상기 검색 결과 정보에 포함된 프레임 구간 정보가 기 설정 된 최대 프레임 분할 크기보다 큰 경우, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보를 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 프레임 분할 구간 정보는, 상기 검색 결과 정보에 포함된 프레임 구간 정보가 기 설정 된 최대 프레임 분할 크기보다 큰 경우, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보를 포함하면서, 상기 검색 결과 정보에 포함된 프레임 구간 정보의 첫번째 프레임부터 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보, 상기 검색 결과 정보에 포함된 프레임 구 간 정보의 첫번째 프레임에서 지정된 프레임 수만큼 이후로 이동한 프레임부터 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 모션블러(Motion Blur)가 없거나 기 설정된 기준 값 이내이면서 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 카메라워킹(Cameraworking)이 없거나 기 설정된 기준 값 이내이면서 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보 중 적어도 하나 또는 둘 이상의 조합에 대응하는 구간 정보를 더 포 함하여 이루어질 수 있다. 본 발명에 따르면, 상기 프레임 분할 구간 정보는, 상기 검색 결과 정보에 인식 대상 프레임 별 객체 매칭율 정 보가 포함된 경우, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 상기 프레임 분할 크기와 같거나 작은 범위의 구간을 포함하면서, 기 설정된 순위 내의 객체 매칭율 정보에 대응하는 인식 대상 프레임을 포함하는 구 간 정보를 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 짧은 동영상 컨텐츠 정보는, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 프레임 분할 구간 정보에 대응하는 프레임 구간을 선택적으로 사용자 단말로 제공하여 재생하기 위한 구간 재생 정보를 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 프레임 분할 구간 정보에 대응하는 프레임 구간을 선택적으로 추출하여 짧은 동영상 컨텐츠를 생성하는 단계를 더 포함하며, 상기 짧은 동영상 컨텐츠 정 보는, 상기 생성된 짧은 동영상 컨텐츠를 사용자 단말로 제공하여 재생하기 위한 동영상 재생 정보를 포함하여 이루어질 수 있다. 본 발명에 따르면, 상기 대표 이미지는, 상기 검색 결과 정보에 포함된 각 프레임 구간의 첫번째 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간의 첫번째 프레임에서 지정된 프레임 수만큼 이후로 이동 한 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간의 가운데 프레임 이미지, 상기 검색 결과 정 보에 포함된 각 프레임 구간의 첫번째 프레임에서 지정된 프레임 수만큼 전후로 이동한 프레임 이미지, 상기 검 색 결과 정보에 포함된 각 프레임 구간의 마지막 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간 의 마지막 프레임에서 지정된 프레임 수만큼 이전으로 이동한 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간에 포함된 프레임 중 모션블러(Motion Blur)가 없거나 가장 적은 프레임 이미지, 상기 검색 결과 정 보에 포함된 각 프레임 구간에 포함된 프레임 중 카메라워킹(Cameraworking)이 없거나 가장 적은 프레임 이미지 중 적어도 하나 또는 둘 이상의 조합에 대응하는 프레임 이미지를 포함하여 이루어질 수 있다."}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 사용자가 개인의 동영상을 다양한 용도로 편집하기에 앞서, 편집 및 기획의 자유도와 편의성 을 부여하기 위해 해당 동영상을 프레임 태그 기반으로 분석하여 제공하는 이점이 있다. 또한, 분석 결과를 이용해 특정 구간을 태그를 통해 검색할 수 있게 서비스를 제공하고, 해당 프레임의 쇼트 동 영상에 대한 편집을 용이하도록 구간별 자동 분할해주고 다운로드가 가능한 이점이 있다."}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면과 설명을 참조하여 본 발명의 바람직한 실시예에 대한 동작 원리를 상세히 설명한다. 다만, 하기에 도시되는 도면과 후술되는 설명은 본 발명의 특징을 효과적으로 설명하기 위한 여러 가지 방법 중에서 바람직한 실시 방법에 대한 것이며, 본 발명이 하기의 도면과 설명만으로 한정되는 것은 아니다. 즉, 하기의 실시예는 본 발명의 수 많은 실시예 중에 바람직한 합집합 형태의 실시예 예에 해당하며, 하기의 실 시예에서 특정 구성(또는 단계)를 생략하는 실시예, 또는 특정 구성(또는 단계)에 구현된 기능을 특정 구성(또 는 단계)로 분할하는 실시예, 또는 둘 이상의 구성(또는 단계)에 구현된 기능을 어느 하나의 구성(또는 단계)에 통합하는 실시예, 특정 구성(또는 단계)의 동작 순서를 교체하는 실시예 등은, 하기의 실시예에서 별도로 언급 하지 않더라도 모두 본 발명의 권리범위에 속함을 명백하게 밝혀두는 바이다. 따라서 하기의 실시예를 기준으로 부분집합 또는 여집합에 해당하는 다양한 실시예들이 본 발명의 출원일을 소급받아 분할될 수 있음을 분명하게 명기하는 바이다. 또한, 하기에서 본 발명을 설명함에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지 를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로써, 이는 환자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 발명에서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 결과적으로, 본 발명의 기술적 사상은 청구범위에 의해 결정되며, 이하 실시예는 진보적인 본 발명의 기술적 사"}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상을 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 효율적으로 설명하기 위한 일 수단일 뿐이다. 도면1은 본 발명의 실시 방법에 따른 동영상을 분석하는 시스템 구성을 도시한 도면이다. 보다 상세하게 본 도면1은 지정된 컨텐츠관리매체에 저장된 동영상 컨텐츠를 지정된 프레임 단위로 분석하여 기 설정된 T(T≥1)개의 객체 카테고리 중 적어도 한 객체 카테고리에 속한 객체를 포함하는 M(M≥1)개의 객체를 인 식하고, 상기 인식된 M개의 객체를 상기 설정된 객체 카테고리에 따라 분류하여 동일한 객체 카테고리에 속한 m(1≤m≤M)개의 객체를 포함한 상태를 유지하는 프레임 구간을 포함하는 N(N≥1)개의 프레임 구간을 인식한 후, 상기 인식된 N개의 프레임 구간 정보와 각각의 프레임 구간에 포함된 각각의 m개의 객체가 속한 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 생성하여 지정된"}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "저장매체에 저장하기 위한 시스템의 구성을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면1을 참조 및/또는 변형하여 상기 시스템의 구성에 대한 다양한 실시 방법(예컨대, 일부 구성부 가 생략되거나, 또는 세분화되거나, 또는 합쳐진 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되 는 모든 실시 방법을 포함하여 이루어지며, 본 도면1에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아 니한다. 본 발명의 시스템은, 운영서버와 통신하며, 상기 운영서버에 접속하여 지정된 컨텐츠관리매체에 등록할 동영상 컨텐츠를 상기 운영서버를 통해 등록하는 기능과, 상기 동영상 컨텐츠를 등록 시 상기 등록 하는 동영상 컨텐츠에 포함된 객체와 관련된 적어도 하나의 동영상 태그 정보를 상기 운영서버에 등록하는 기능과, 상기 동영상 컨텐츠를 등록 시 상기 등록하는 동영상 컨텐츠를 설명하는 동영상 설명 정보를 상기 운영 서버에 등록하는 기능 중 하나 이상의 기능을 구비하는 등록자 단말과, 운영서버와 통신하며, 상기 운영서버에 접속하여 지정된 동영상 컨텐츠에 포함된 객체를 분석한 객체 분석 정보를 요청하는 정보 를 상기 운영서버로 전송하는 기능과, 적어도 하나의 동영상 컨텐츠에 포함된 객체 카테고리 정보의 검색 을 요청하는 검색 요청 정보를 상기 운영서버로 전송하는 기능과, 상기 운영서버로부터 상기 객체 카 테고리 정보의 검색을 요청하는 검색 요청 정보에 대응하여 생성된 검색 결과 정보를 제공받는 기능과, 상기 운 영서버로부터 상기 검색 요청 정보에 대응하여 생성된 i개의 프레임 분할 구간 정보에 대응하는 i개의 짧 은 동영상 컨텐츠를 제공받는 기능 중 하나 이상의 기능을 구비하는 사용자 단말과, 상기 운영서버와 통신하며 상기 운영서버가 상기 등록자 단말로부터 등록받는 동영상 컨텐츠를 저장하는 컨텐츠관리매 체와, 지정된 컨텐츠관리매체에 저장된 동영상 컨텐츠를 지정된 프레임 단위로 분석하여 기 설정된 T(T≥1)개의 객체 카테고리 중 적어도 한 객체 카테고리에 속한 객체를 포함하는 M(M≥1)개의 객체를 인식하는 기능과, 상기 인식된 M개의 객체를 상기 설정된 객체 카테고리에 따라 분류하여 동일한 객체 카테고리에 속한 m(1≤m≤M)개의 객체를 포함한 상태를 유지하는 프레임 구간을 포함하는 N(N≥1)개의 프레임 구간을 인식하는 기능과, 상기 인식된 N개의 프레임 구간 정보와 각각의 프레임 구간에 포함된 각각의 m개의 객체가 속한 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 생성하여 지정된 저장매체에 저장하는 기능을 수행하는 운영서버를 포함하여 이루어질 수 있다. 상기 등록자 단말은 상기 운영서버와 연동하며, 상기 운영서버에 접속하여 지정된 컨텐츠관리매 체에 등록할 동영상 컨텐츠를 상기 운영서버를 통해 등록하는 등록자가 이용하는 컴퓨터 장치의 총칭 으로서, 유선망에 연결된 컴퓨터, 노트북 등의 유선단말과, 무선망에 연결된 휴대폰, 스마트폰, 태블릿PC, 노트 북 등의 무선단말을 중 적어도 하나를 포함한다. 바람직하게, 상기 등록자는 상기 등록자 단말을 통해 상 기 운영서버에 접속하여 상기 등록자에 대한 식별 및 등록자 인증을 수행할 수 있으며, 상기 등록자 단말 은 상기 운영서버에 접속하여 지정된 컨텐츠관리매체에 등록할 동영상 컨텐츠를 상기 운영서버 를 통해 등록하는 기능과, 상기 동영상 컨텐츠를 등록 시 상기 등록하는 동영상 컨텐츠에 포함된 객체와 관련된 적어도 하나의 동영상 태그 정보를 상기 운영서버에 등록하는 기능과, 상기 동영상 컨텐츠를 등록 시 상기 등록하는 동영상 컨텐츠를 설명하는 동영상 설명 정보를 상기 운영서버에 등록하는 기능 중 하나 이상의 기능을 포함하며, 실시 방법에 따라 상기 기능을 위해 지정된 적어도 하나 이상의 절차를 수행하는 프로 그램이나 앱(Application)이 설치될 수 있으며, 이 중 일부의 구성은 웹 방식을 통해 구현될 수도 있다. 이하, 별도의 언급이 없더라도 상기 등록자 단말을 주체로 하여 설명하는 기능은 상기 등록자 단말에 설치 된 프로그램(또는 앱)이나 웹 방식을 통해 구현되는 것임을 명백하게 밝혀두는 바이다. 상기 사용자 단말은 상기 운영서버와 연동하며, 상기 운영서버에 접속하여 지정된 동영상 컨텐 츠에 포함된 객체를 분석한 객체 분석 정보를 요청하는 정보를 상기 운영서버로 전송하는 사용자가 이용하는 컴퓨터 장치의 총칭으로서, 유선망에 연결된 컴퓨터, 노트북 등의 유선단말과, 무선망에 연결된 휴대폰, 스 마트폰, 태블릿PC, 노트북 등의 무선단말을 중 적어도 하나를 포함한다. 바람직하게, 상기 사용자 단말은 상기 운영서버에 접속하여 지정된 동영상 컨텐츠에 포함된 객체를 분석한 객체 분석 정보를 요청하는 정보 를 상기 운영서버로 전송하는 기능과, 적어도 하나의 동영상 컨텐츠에 포함된 객체 카테고리 정보의 검색 을 요청하는 검색 요청 정보를 상기 운영서버로 전송하는 기능과, 상기 운영서버로부터 상기 객체 카 테고리 정보의 검색을 요청하는 검색 요청 정보에 대응하여 생성된 검색 결과 정보를 제공받는 기능과, 상기 운 영서버로부터 상기 검색 요청 정보에 대응하여 생성된 i개의 프레임 분할 구간 정보에 대응하는 i개의 짧 은 동영상 컨텐츠를 제공받는 기능 중 하나 이상의 기능을 포함하며, 실시 방법에 따라 상기 기능을 위해 지정 된 적어도 하나 이상의 절차를 수행하는 프로그램이나 앱(Application)이 설치될 수 있으며, 이 중 일부의 구성 은 웹 방식을 통해 구현될 수도 있다. 이하, 별도의 언급이 없더라도 상기 사용자 단말을 주체로 하여 설 명하는 기능은 상기 사용자 단말에 설치된 프로그램(또는 앱)이나 웹 방식을 통해 구현되는 것임을 명백하 게 밝혀두는 바이다. 도면1을 참조하면, 상기 운영서버는 동영상 컨텐츠를 분석하여 기 설정된 객체 카테고리에 속한 객체를 포 함하는 객체를 인식하는 객체 인식부와, 상기 인식된 M개의 객체를 분류하여 동일한 객체 카테고리에 속한 m(1≤m≤M)개의 객체를 포함한 상태를 유지하는 프레임 구간을 인식하는 구간 인식부와, 상기 인식된 N개 의 프레임 구간 정보와 각각의 프레임 구간에 포함된 각각의 m개의 객체가 속한 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 생성하는 정보 생성부와, 상기 생성된 객체 분석 정보를 저장하는 정보 저장부를 포함하여 구성될 수 있다. 한편 본 도면1의 실시예는 편의상 상기 운영서버를 하나의 서버 형태로 도시하였으나, 상기 운영서버를 구현하는 실시예가 이에 의해 한정되는 것은 아니며, 상기 운영서 버는 둘 이상의 서버 조합 또는 서버 시스템 형태로 구현되거나 기 구축된 서버에 탑재되는 소프트웨어 형 태로 구현될 수 있으며, 본 발명은 이러한 모든 실시예를 포함한다. 상기 객체 인식부는 지정된 컨텐츠관리매체에 저장된 동영상 컨텐츠를 지정된 프레임 단위로 분석하 여 기 설정된 T(T≥1)개의 객체 카테고리 중 적어도 한 객체 카테고리에 속한 객체를 포함하는 M(M≥1)개의 객 체를 인식한다. 본 발명의 실시 방법에 따르면, 상기 객체 인식부는 상기 객체 정보에 포함된 각 객체 별 객체 특징 정보 를 통해 상기 동영상 컨텐츠를 지정된 프레임 단위로 분석하여 지정된 객체를 인식할 수 있다. 또한, 본 발명의 실시 방법에 따르면, 상기 객체 인식부는 상기 동영상 컨텐츠에 포함된 각 장면전환 프레 임 사이의 장면 구간을 식별하고, 상기 식별된 각 장면 구간에 포함된 복수의 프레임 중 적어도 하나의 인식 대 상 프레임에 대응하는 인식 대상 프레임 이미지를 선정한 후, 상기 객체 정보에 포함된 객체 별 객체 특징 정보 를 통해 상기 선정된 인식 대상 프레임 이미지를 분석하여 지정된 객체를 인식할 수 있다. 예컨대, 상기 장면 구간은 전통적인 의미의 장면 구간(예: 카메라의 촬영 대상이나 배경이 변경되지 않고 유지되는 구간이나 카메 라의 뷰포인트가 변경되지 않고 유지되는 구간)을 의미하며, 상기 장면 구간은 등록자에 의해 입력/선택될 수도 있고, 자동으로 인식될 수도 있다. 여기서, 상기 인식 대상 프레임은, 각 장면 구간의 첫번째 프레임, 각 장면 구간의 첫번째 프레임에서 지정된 프레임 수만큼 이후로 이동한 프레임, 각 장면 구간의 가운데 프레임, 각 장면 구간의 첫번째 프레임에서 지정 된 프레임 수만큼 전후로 이동한 프레임, 각 장면 구간의 마지막 프레임, 각 장면 구간의 마지막 프레임에서 지 정된 프레임 수만큼 이전으로 이동한 프레임, 각 장면 구간을 기 설정된 프레임 수 단위 또는 재생시간 단위로 분할하여 선별된 프레임, 각 장면 구간에 포함된 프레임 중 모션블러(Motion Blur)가 없거나 가장 적은 프레임, 각 장면 구간에 포함된 프레임 중 카메라워킹(Cameraworking)이 없거나 가장 적은 프레임 중 적어도 하나 또는 둘 이상의 조합에 대응하는 프레임을 포함할 수 있다.상기 객체 카테고리는 기 설정된 분류 기준에 대응하는 계층 구조를 포함하며, 상기 객체는 상기 계층 구조의 객체 카테고리 중 적어도 한 계층의 객체 카테고리에 포함될 수 있다. 예컨대, \"손흥민\"이라는 객체는, 사람 > 남자 > 운동선수 등의 계층적 객체 카테고리에 속할 수 있다. 본 발명의 실시 방법에 따르면, 상기 객체 인식부는 등록자 단말을 통해 동영상 컨텐츠와 동영상 태 그 정보가 등록된 경우, 상기 등록된 동영상 태그 정보에 대응하는 객체를 인식할 수 있다. 예컨대, 등록자가 해당 동영상에는 어떤 객체가 있을 것이라고 동영상 태그 정보를 통해 알려주었으므로, 가능하면 등록자가 알려 준 객체를 인식하는 것이 바람직하다. 한편, 본 발명의 실시 방법에 따르면, 상기 객체 인식부는 등록자 단말을 통해 동영상 컨텐츠를 설명 하는 동영상 설명 정보가 더 등록된 경우, 상기 등록된 동영상 설명 정보에 포함된 단어를 근거로 상기 동영상 컨텐츠에 포함된 객체와 관련된 객체 관련 태그 정보를 추출하고, 상기 추출된 객체 관련 태그 정보에 대응하는 객체를 인식할 수 있다. 상기 구간 인식부는 상기 객체 인식부를 통해 인식된 M개의 객체를 상기 설정된 객체 카테고리에 따 라 분류하여 동일한 객체 카테고리에 속한 m(1≤m≤M)개의 객체를 포함한 상태를 유지하는 프레임 구간을 포함 하는 N(N≥1)개의 프레임 구간을 인식한다. 여기서, 상기 m개의 객체는 동일한 객체를 포함할 수 있다. 또한, 상기 m개의 객체는 동일한 객체 카테고리에 속한 서로 다른 둘 이상의 객체를 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 프레임 구간은, 각 장면 구간과는 별개 또는 독립적으로 동일한 객체 카테 고리에 속한 m개의 객체를 포함한 상태를 근거로 구분되는 구간을 포함할 수 있다. 여기서, 상기 프레임 구간은 카메라의 촬영 대상이나 배경이 변경되지 않고 유지되는 구간이나 카메라의 뷰포인트가 변경되지 않고 유지되는 전통적 의미의 구간과는 달리 독립적으로 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 유지하는 구간을 의미한다. 예컨대, \"남자\"라는 객체 카테고리에 속한 객체의 경우 제1 장면의 10초 경과 시점부터 남자이 등장하고, 제 2 장면에 남자과 남자가 등장하고, 제3 장면의 15초 경과 시점까지 남자가 등장할 경우, 장면 구간은 3개이지만, 상기 프레임 구간은 제1 장면의 10초 경과 시점부터 제2 장면을 거쳐 제3 장면의 15초 경과 시점까 지 하나의 프레임 구간으로 포함될 수 있다. 또한 상기 프레임 구간은 특정 장면 구간 중 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 유지하 는 일부 장면 구간, 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 유지하는 복수의 장면 구간의 조 합 구간, 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 유지하는 적어도 하나의 장면 구간과 일부 장면 구간의 조합 구간 중 적어도 하나의 구간을 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 구간 인식부는 각각의 프레임 구간에 포함된 인식 대상 프레임을 통 해 지정된 객체를 인식하는 과정 중에 산출된 인식 대상 프레임 별 객체 매칭율 정보를 확인할 수 있다. 상기 정보 생성부는 상기 구간 인식부를 통해 인식된 N개의 프레임 구간 정보와 각각의 프레임 구간 에 포함된 각각의 m개의 객체가 속한 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 생성한다.여기서, 상기 프레임 구간 정보는 프레임 구간의 시작 프레임 번호와 종료 프레임 번호, 프레임 구간의 재생 시 작 시간과 재생 종료 시간 중 적어도 하나를 포함할 수 있다. 또한, 상기 N개의 프레임 구간 정보는 각 프레임 구간에 포함된 객체가 속한 객체 카테고리에 따라 적어도 일부 중첩된 구간을 포함할 수 있다. 예컨대, 재생시간 10초~20초까지 \"구름\"이라는 객체 카테고리가 포함되고, 재생 시간 15초~30초까지 \"남자\"라는 객체 카테고리가 포함된 경우, 재생시간 15초~20초는 \"구름\"이라는 객체 카테고 리와 \"남자\"라는 객체 카테고리가 중첩된 구간이 될 수 있다. 본 발명의 실시 방법에 따르면, 상기 객체 분석 정보는 각각의 프레임 구간에서 인식된 m개의 객체에 대한 객체 정보를 더 포함할 수 있다. 예컨대, 상기 객체 분석 정보는, 기본적으로 \"사람\", \"남자\", \"운동선수\"와 같은 객 체 카테고리 정보가 포함되지만, 추가적으로 각 프레임 구간에 실제 포함된 \"손흥민\", \"박지성\" 등과 같은 객체 정보도 포함될 수 있다. 본 발명의 실시 방법에 따르면, 상기 객체 분석 정보는 상기 객체 정보에 대응하는 객체가 포함된 적어도 하나 의 객체 별 프레임 구간 정보를 더 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 구간 인식부에서 각각의 프레임 구간에 포함된 인식 대상 프레임을 통해 지정된 객체를 인식하는 과정 중에 산출된 인식 대상 프레임 별 객체 매칭율 정보가 확인되는 경우, 상기 객체 분석 정보는, 상기 인식 대상 프레임 별 객체 매칭율 정보를 더 포함할 수 있다. 상기 정보 저장부는 상기 정보 생성부를 통해 생성된 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 지정된 저장매체에 저장한다. 본 발명의 실시 방법에 따르면, 상기 정보 저장부는 상기 객체 인식부를 통해 동영상 컨텐츠를 지정 된 프레임 단위로 분석하여 기 설정된 T(T≥1)개의 객체 카테고리 중 적어도 한 객체 카테고리에 속한 객체를 포함하는 M(M≥1)개의 객체를 인식하기 위해, 동영상 컨텐츠의 프레임을 분석하여 인식 가능한 각 객체에 대한 객체 정보와 각 객체가 속한 적어도 하나의 객체 카테고리를 포함하는 T(T≥1)개의 객체 카테고리 정보를 저장 할 수 있다. 여기서, 상기 객체 정보는 각 객체의 고유한 객체 명칭 정보와 각 객체에 부여된 적어도 하나의 객체 태그 정보 중 적어도 하나의 정보를 포함할 수 있다. 또한, 상기 객체 정보는 각 객체를 인식하기 위한 각 객체의 관측된 특징에 대응하는 객체 별 객체 특징 정보를 더 포함할 수 있다. 또한, 상기 객체 정보는 각 객체의 관측된 특징을 통해 인식된 각 객체를 식별하는 객체 식별 정보를 더 포함할 수 있다. 한편, 본 발명의 실시 방법에 따르면, 상기 정보 저장부는 등록자 단말을 통해 동영상 컨텐츠를 등록 받아 지정된 컨텐츠관리매체에 저장할 수 있다.상기 정보 저장부는 등록자 단말을 통해 동영상 컨텐츠를 등록 시, 상기 등록자 단말을 통해 상 기 등록되는 동영상 컨텐츠에 포함된 객체와 관련된 적어도 하나의 동영상 태그 정보를 등록받고, 상기 동영상 컨텐츠와 상기 등록된 동영상 태그 정보를 연계하여 상기 컨텐츠관리매체에 저장할 수 있다. 예컨대, 상기 등록자 단말을 동영상 등록 시 상기 등록자 단말을 통해 등록되는 동영상 태그 정보는 등록자가 직접 단말에 입력하여 등록하는 것으로, 등록자가 해당 동영상에는 어떤 객체가 포함되어 있다고 알려줄 수 있다. 한편, 본 발명의 실시 방법에 따르면, 상기 정보 저장부는, 상기 등록자 단말을 통해 등록된 동영상 컨텐츠와 상기 등록된 동영상 컨텐츠에 대응하는 동영상 태그 정보가 연계되어 상기 컨텐츠관리매체에 저 장된 경우, 등록자 단말을 통해 동영상 컨텐츠를 등록 시, 상기 등록자 단말을 통해 상기 등록되는 동영상 컨텐츠를 설명하는 동영상 설명 정보를 등록받고, 상기 동영상 컨텐츠와 상기 등록된 동영상 설명 정보 를 연계하여 상기 컨텐츠관리매체에 저장할 수 있다. 한편, 도면1을 참조하면, 상기 운영서버는 상기 객체 정보에 대응하는 객체의 관측된 특징에 대응하는 입 력 정보와 상기 객체 정보에 대응하는 객체의 관측된 결과에 대응하는 출력 정보를 지정된 인공지능모듈에 대입 하여 상기 객체 정보에 대응하는 객체를 인식하는 객체 인식을 학습시키는 객체인식 학습부를 더 포함하여 구성될 수 있다. 이 경우, 상기 객체 인식부는 상기 객체 인식을 학습한 인공지능모듈을 통해 상기 동영상 컨텐츠를 지정된 프레임 단위로 분석하여 지정된 객체를 인식할 수 있다. 또한, 상기 객체 인식부는 상기 동영상 컨텐츠에 포함된 각 장면전환 프레임 사이의 장면 구간을 식별하고, 상기 식별된 각 장면 구간에 포함된 복수의 프레임 중 적어도 하나의 인식 대상 프레임에 대응하는 인식 대상 프레임 이미지를 선정한 후, 상기 객체 인식을 학습한 인공지능모듈에 상기 선정된 인식 대상 프레임 이미지의 관측된 특징을 대입하여 지정된 객체를 인식할 수 있다. 여기서, 상기 인식 대상 프레임은, 각 장면 구간의 첫번째 프레임, 각 장면 구간의 첫번째 프레임에서 지정된 프레임 수만큼 이후로 이동한 프레임, 각 장면 구간의 가운데 프레임, 각 장면 구간의 첫번째 프레임에서 지정 된 프레임 수만큼 전후로 이동한 프레임, 각 장면 구간의 마지막 프레임, 각 장면 구간의 마지막 프레임에서 지 정된 프레임 수만큼 이전으로 이동한 프레임, 각 장면 구간을 기 설정된 프레임 수 단위 또는 재생시간 단위로 분할하여 선별된 프레임, 각 장면 구간에 포함된 프레임 중 모션블러(Motion Blur)가 없거나 가장 적은 프레임, 각 장면 구간에 포함된 프레임 중 카메라워킹(Cameraworking)이 없거나 가장 적은 프레임 중 적어도 하나 또는 둘 이상의 조합에 대응하는 프레임을 포함할 수 있다. 한편, 도면1을 참조하면, 상기 운영서버는 사용자 단말을 통해 지정된 동영상 컨텐츠에 포함된 객체 를 분석한 객체 분석 정보를 요청하는 정보를 수신하고, 상기 사용자 단말로 상기 동영상 컨텐츠의 객체 분석 정보를 제공하는 결과 제공부를 더 포함하여 구성될 수 있다. 본 발명의 실시 방법에 따르면, 상기 결과 제공부는 사용자 단말을 통해 적어도 하나의 동영상 컨텐 츠에 포함된 객체 카테고리 정보의 검색을 요청하는 검색 요청 정보를 수신하고, 지정된 저장매체에 저장된 적 어도 하나의 객체 분석 정보를 근거로 상기 검색 요청 정보에 대응하는 검색 대상 객체 카테고리 정보를 포함하 는 동영상 컨텐츠를 식별하는 동영상 정보와 상기 식별된 동영상 컨텐츠의 프레임 구간 중 상기 검색 대상 객체 카테고리 정보를 포함하는 i(i≥1)개의 프레임 구간 정보를 포함하는 검색 결과 정보를 생성한 후, 상기 사용자 단말로 상기 검색 결과 정보를 제공할 수 있다. 예컨대, 상기 사용자 단말을 통해 \"남자\"라는 객체 카테고 리 정보를 검색하는 경우, \"남자\"라는 객체 카테고리 정보를 포함하는 프레임 구간 정보를 검색 결과 정보에 포함시킬 수 있다. 여기서, 상기 결과 제공부는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i 개의 프레임 구간 정보에 대응하는 프레임 구간 내의 지정된 프레임 구간을 분할하는 i개의 프레임 분할 구간 정보를 생성하고, 상기 생성된 i개의 프레임 분할 구간 정보에 대응하는 i개의 짧은 동영상 컨텐츠를 상기 사용 자 단말로 제공하기 위한 i개의 짧은 동영상 컨텐츠 정보를 생성하여 상기 검색 결과 정보에 포함시킬 수 있다. 또한, 상기 결과 제공부는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개 의 프레임 구간 정보에 대응하는 i개의 대표 이미지를 생성하고, 상기 생성된 i개의 대표 이미지를 상기 검색 결과 정보에 포함시킬 수 있다. 한편, 본 발명의 다른 실시 방법에 따르면, 상기 결과 제공부는 상기 객체 분석 정보에 각 프레임 구간에 서 인식된 객체에 대응하는 객체 정보가 포함된 경우, 사용자 단말을 통해 적어도 하나의 동영상 컨텐츠에 포함된 객체의 검색을 요청하는 검색 요청 정보를 수신하고, 지정된 저장매체에 저장된 적어도 하나의 객체 분 석 정보를 근거로 상기 검색 요청 정보에 대응하는 검색 대상 객체를 포함하는 동영상 컨텐츠를 식별하는 동영 상 정보와 상기 식별된 동영상 컨텐츠의 프레임 구간 중 상기 검색 대상 객체를 포함하는 i(i≥1)개의 프레임 구간 정보를 포함하는 검색 결과 정보를 생성한 후, 상기 사용자 단말로 상기 검색 결과 정보를 제공할 수 있다. 여기서, 상기 결과 제공부는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i 개의 프레임 구간 정보에 대응하는 프레임 구간 내의 지정된 프레임 구간을 분할하는 i개의 프레임 분할 구간 정보를 생성하고, 상기 생성된 i개의 프레임 분할 구간 정보에 대응하는 i개의 짧은 동영상 컨텐츠를 상기 사용 자 단말로 제공하기 위한 i개의 짧은 동영상 컨텐츠 정보를 생성하여 상기 검색 결과 정보에 포함시킬 수 있다. 또한, 상기 결과 제공부는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개 의 프레임 구간 정보에 대응하는 i개의 대표 이미지를 생성하고, 상기 생성된 i개의 대표 이미지를 상기 검색 결과 정보에 포함시킬 수 있다. 여기서, 상기 프레임 분할 구간 정보는 상기 검색 결과 정보에 포함된 프레임 구간 정보와 동일한 구간 정보를 포함할 수 있다. 또한, 상기 프레임 분할 구간 정보는 상기 검색 결과 정보에 포함된 프레임 구간 정보가 기 설정된 최대 프레임 분할 크기보다 큰 경우, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보를 포함할 수 있다. 또한, 상기 프레임 분할 구간 정보는 상기 검색 결과 정보에 포함된 프레임 구간 정보가 기 설정된 최대 프레임 분할 크기보다 큰 경우, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보를 포함하면서, 상기 검색 결과 정보에 포함된 프레임 구간 정보의 첫번째 프레임부터 상 기 프레임 분할 크기와 같거나 작은 범위의 구간 정보, 상기 검색 결과 정보에 포함된 프레임 구간 정보의 첫번 째 프레임에서 지정된 프레임 수만큼 이후로 이동한 프레임부터 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 모션블러(Motion Blur)가 없거나 기 설정된 기 준 값 이내이면서 상기 프레임 분할 크기와 같거나 작은 범위의 구간 정보, 상기 검색 결과 정보에 포함된 프레 임 구간 정보 중 카메라워킹(Cameraworking)이 없거나 기 설정된 기준 값 이내이면서 상기 프레임 분할 크기와같거나 작은 범위의 구간 정보 중 적어도 하나 또는 둘 이상의 조합에 대응하는 구간 정보를 더 포함할 수 있다. 또한, 상기 프레임 분할 구간 정보는 상기 검색 결과 정보에 인식 대상 프레임 별 객체 매칭율 정보가 포함된 경우, 상기 검색 결과 정보에 포함된 프레임 구간 정보 중 상기 프레임 분할 크기와 같거나 작은 범위의 구간을 포함하면서, 기 설정된 순위 내의 객체 매칭율 정보에 대응하는 인식 대상 프레임을 포함하는 구간 정보를 포함 할 수 있다. 본 발명의 실시 방법에 따르면, 상기 짧은 동영상 컨텐츠 정보는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상 기 프레임 분할 구간 정보에 대응하는 프레임 구간을 선택적으로 사용자 단말로 제공하여 재생하기 위한 구간 재생 정보를 포함할 수 있다. 또한, 상기 결과 제공부는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 프레임 분할 구간 정보에 대응 하는 프레임 구간을 선택적으로 추출하여 짧은 동영상 컨텐츠를 생성할 수 있으며, 상기 짧은 동영상 컨텐츠 정 보는, 상기 생성된 짧은 동영상 컨텐츠를 사용자 단말로 제공하여 재생하기 위한 동영상 재생 정보를 포함 할 수 있다. 여기서 상기 짧은 동영상 컨텐츠는 지정된 컨텐츠관리매체에 저장될 수 있으며 상기 동영상 재생 정보는 짧은 동영상 컨텐츠의 URL 정보를 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 대표 이미지는 상기 검색 결과 정보에 포함된 각 프레임 구간의 첫번째 프 레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간의 첫번째 프레임에서 지정된 프레임 수만큼 이후로 이동한 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간의 가운데 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간의 첫번째 프레임에서 지정된 프레임 수만큼 전후로 이동한 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간의 마지막 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구 간의 마지막 프레임에서 지정된 프레임 수만큼 이전으로 이동한 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간에 포함된 프레임 중 모션블러(Motion Blur)가 없거나 가장 적은 프레임 이미지, 상기 검색 결과 정보에 포함된 각 프레임 구간에 포함된 프레임 중 카메라워킹(Cameraworking)이 없거나 가장 적은 프레임 이미 지 중 적어도 하나 또는 둘 이상의 조합에 대응하는 프레임 이미지를 포함할 수 있다. 한편, 본 발명의 실시 방법에 따르면, 상기 결과 제공부는 사용자 단말을 통해 적어도 하나의 동영상 컨텐츠에 포함된 객체의 검색을 요청하는 검색 요청 정보를 수신하고, 상기 검색 요청 정보에 대응하는 객체가 속한 적어도 하나의 객체 카테고리 중 검색 대상 객체 카테고리 정보를 결정하여, 지정된 저장매체에 저장된 적 어도 하나의 객체 분석 정보를 근거로 상기 검색 대상 객체 카테고리 정보를 포함하는 동영상 컨텐츠를 식별하 는 동영상 정보와 상기 식별된 동영상 컨텐츠의 프레임 구간 중 상기 검색 대상 객체 카테고리 정보를 포함하는 i(i≥1)개의 프레임 구간 정보를 포함하는 검색 결과 정보를 생성한 후, 상기 사용자 단말로 상기 검색 결 과 정보를 제공할 수 있다. 여기서, 상기 검색 대상 객체 카테고리 정보는, 객체 카테고리의 계층 구조 상에서 상기 객체가 속한 최하층 계 층의 객체 카테고리 정보를 포함할 수 있다. 예컨대, 상기 사용자 단말을 통해 \"손흥민\"을 검색하는 경우, 손흥민이 속한 \"사람\" > \"남자\" > \"운동선수\"의 객체 카테고리의 계층 구조 중 최하층인 \"운동선수\"에 해당하는 객체 카테고리를 검색 대상 객체 카테고리 정보로 결정하고, \"운동선수\"라는 객체 카테고리 정보를 포함하는 프 레임 구간 정보를 검색 결과 정보에 포함시킬 수 있다. 도면2는 본 발명의 실시 방법에 따라 동영상 컨텐츠에 포함된 객체를 인식하는 과정을 도시한 도면이다. 보다 상세하게 본 도면2는 상기 도면1에 도시된 운영서버에서 동영상 컨텐츠의 프레임을 분석하여 인식 가 능한 각 객체에 대한 객체 정보와 각 객체가 속한 적어도 하나의 객체 카테고리를 포함하는 T(T≥1)개의 객체 카테고리 정보를 저장하고, 지정된 인공지능모듈을 이용하여 객체 인식을 학습시킨 후, 지정된 컨텐츠관리매체 에 저장된 동영상 컨텐츠에 포함된 객체를 인식하는 과정에서 상기 객체 인식을 학습한 인공지능모듈을 통"}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "해 지정된 객체를 인식하는 과정을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면2를 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루 어지며, 본 도면2에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면2를 참조하면, 상기 운영서버는 동영상 컨텐츠의 프레임을 분석하여 인식 가능한 각 객체에 대한 객체 정보와 각 객체가 속한 적어도 하나의 객체 카테고리를 포함하는 T(T≥1)개의 객체 카테고리 정보를 저장한다 . 여기서, 상기 객체 정보는 각 객체의 고유한 객체 명칭 정보와 각 객체에 부여된 적어도 하나의 객체 태 그 정보 중 적어도 하나의 정보를 포함할 수 있다. 또한, 상기 객체 정보는 각 객체를 인식하기 위한 각 객체의 관측된 특징에 대응하는 객체 별 객체 특징 정보를 더 포함할 수 있다. 또한, 상기 객체 정보는 각 객체의 관측 된 특징을 통해 인식된 각 객체를 식별하는 객체 식별 정보를 더 포함할 수 있다. 여기서, 상기 객체 카테고리는 기 설정된 분류 기준에 대응하는 계층 구조를 포함하며, 상기 객체는 상기 계층 구조의 객체 카테고리 중 적어도 한 계층의 객체 카테고리에 포함되는 것이 바람직하다. 한편, 상기 운영서버는 상기 객체 정보에 대응하는 객체의 관측된 특징에 대응하는 입력 정보와 상기 객체 정보에 대응하는 객체의 관측된 결과에 대응하는 출력 정보를 지정된 인공지능모듈에 대입하고, 상기 객체 정보에 대응하는 객체를 인식하는 객체 인식을 학습시킨다. 이후, 상기 운영서버는 상기 동영상 컨텐츠에 포함된 각 장면전환 프레임 사이의 장면 구간을 식별하고 , 상기 식별된 각 장면 구간에 포함된 복수의 프레임 중 적어도 하나의 인식 대상 프레임에 대응하는 인식 대상 프레임 이미지를 선정한다. 그리고, 상기 운영서버는 상기 객체 인식을 학습한 인공지능모듈에 상기 선정된 인식 대상 프레임 이미지 의 관측된 특징을 대입하여 지정된 객체를 인식한다. 여기서, 상기 인식 대상 프레임은 각 장면 구간의 첫 번째 프레임, 각 장면 구간의 첫번째 프레임에서 지정된 프레임 수만큼 이후로 이동한 프레임, 각 장면 구간의 가운데 프레임, 각 장면 구간의 첫번째 프레임에서 지정된 프레임 수만큼 전후로 이동한 프레임, 각 장면 구간 의 마지막 프레임, 각 장면 구간의 마지막 프레임에서 지정된 프레임 수만큼 이전으로 이동한 프레임, 각 장면 구간을 기 설정된 프레임 수 단위 또는 재생시간 단위로 분할하여 선별된 프레임, 각 장면 구간에 포함된 프레 임 중 모션블러(Motion Blur)가 없거나 가장 적은 프레임, 각 장면 구간에 포함된 프레임 중 카메라워킹 (Cameraworking)이 없거나 가장 적은 프레임 중 적어도 하나 또는 둘 이상의 조합에 대응하는 프레임을 포함할 수 있다. 도면3은 본 발명의 다른 실시 방법에 따라 동영상 컨텐츠에 포함된 객체를 인식하는 과정을 도시한 도면이다. 보다 상세하게 본 도면3은 상기 도면1에 도시된 운영서버에서 등록자 단말을 통해 동영상 컨텐츠를 등록받아 지정된 컨텐츠관리매체에 저장하는 과정에서, 상기 동영상 컨텐츠에 포함된 객체와 관련된 동영 상 태그 정보를 함께 저장하여, 상기 영상 태그 정보를 이용하여 객체를 인식하는 과정을 도시한 것으로서, 본"}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면3을 참조 및/또는 변형하여 상기 과정에 대한 다 양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면3에 도시된 실시 방법만으로 그 기술적특징이 한정되지 아니한다. 도면3을 참조하면, 운영서버는 등록자 단말을 통해 동영상 컨텐츠를 등록받아 지정된 컨텐츠관리매체 에 저장한다. 그리고, 상기 운영서버는 상기 등록자 단말을 통해 동영상 컨텐츠를 등록 시, 상기 등록자 단말(14 0)을 통해 상기 등록되는 동영상 컨텐츠에 포함된 객체와 관련된 적어도 하나의 동영상 태그 정보를 등록받고 , 상기 동영상 컨텐츠와 상기 등록된 동영상 태그 정보를 연계하여 상기 컨텐츠관리매체에 저장한다 . 이후, 상기 운영서버는 상기 등록된 동영상 태그 정보에 대응하는 객체를 인식한다. 도면4는 본 발명의 또 다른 실시 방법에 따라 동영상 컨텐츠에 포함된 객체를 인식하는 과정을 도시한 도면이다. 보다 상세하게 본 도면4는 상기 도면1에 도시된 운영서버에서 등록자 단말을 통해 동영상 컨텐츠를 등록받아 지정된 컨텐츠관리매체에 저장하는 과정에서, 상기 동영상 컨텐츠를 설명하는 동영상 설명 정보 를 함께 저장하여, 상기 동영상 설명 정보에 포함된 단어를 근거로 상기 동영상 컨텐츠에 포함된 객체와 관련된 객체 관련 태그 정보를 추출하고 이를 이용하여 객체를 인식하는 과정을 도시한 것으로서, 본 발명이 속한 기술 분야에서 통상의 지식을 가진 자라면, 본 도면4를 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법 (예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면4에 도시된 실시 방법만으로 그 기술적 특징이 한정되 지 아니한다. 도면4를 참조하면, 상기 운영서버는 등록자 단말을 통해 동영상 컨텐츠를 등록받아 지정된 컨텐츠관 리매체에 저장한다. 이 때, 상기 운영서버는 상기 등록자 단말을 통해 상기 등록되는 동영상 컨텐츠를 설명하는 동영상 설명 정보를 등록받고, 상기 동영상 컨텐츠와 상기 등록된 동영상 설명 정보를 연계하여 상기 컨텐츠관리 매체에 저장한다. 이후 상기 운영서버는 상기 등록된 동영상 설명 정보에 포함된 단어를 근거로 상기 동영상 컨텐츠에 포함 된 객체와 관련된 객체 관련 태그 정보를 추출하고, 상기 추출된 객체 관련 태그 정보에 대응하는 객체를 인식한다. 도면5는 본 발명의 실시 방법에 따라 동영상 컨텐츠에 포함된 객체를 인식하는 과정을 도시한 도면이다. 보다 상세하게 본 도면5는 상기 도면2 내지 도면4의 과정을 통해 동영상 컨텐츠에 포함된 객체가 인식된 이후, 운영서버에서 상기 인식된 객체를 포함한 상태를 유지하는 프레임 구간을 인식하고, 상기 인식된 프레임 구간 정보와 각각의 프레임 구간에 포함된 각각의 객체가 속한 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 생성하여 지정된 저장매체에 저장한 후, 사용자 단말"}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "로 제공하는 과정을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면5를 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면5에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면5를 참조하면, 상기 운영서버는 상기 도면2 내지 도면4의 과정을 통해 동영상 컨텐츠에 포함된 M(M≥ 1)개의 객체가 인식된 이후, 상기 인식된 M개의 객체를 상기 설정된 객체 카테고리에 따라 분류하여 동일한 객 체 카테고리에 속한 m(1≤m≤M)개의 객체를 포함한 상태를 유지하는 프레임 구간을 포함하는 N(N≥1)개의 프레 임 구간을 인식한다. 여기서, 상기 m개의 객체는 동일한 객체를 포함할 수 있다. 또한, 상기 m개의 객체는 동일한 객체 카테고리에 속한 서로 다른 둘 이상의 객체를 포함할 수 있다. 또한, 상기 프레임 구간은 각 장면 구간과는 별개 또는 독립적으로 동일한 객체 카테고리에 속한 m개의 객체를 포함한 상태를 근거로 구분되는 구간을 포함할 수 있다. 한편, 상기 운영서버는 상기 인식된 N개의 프레임 구간 정보와 각각의 프레임 구간에 포함된 각각의 m개의 객체가 속한 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분 석 정보를 생성하고, 상기 생성된 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보를 지정 된 저장매체에 저장한다. 여기서, 상기 프레임 구간 정보는 프레임 구간의 시작 프레임 번호와 종료 프레임 번호, 프레임 구간의 재생 시 작 시간과 재생 종료 시간 중 적어도 하나를 포함할 수 있다. 또한, 상기 N개의 프레임 구간 정보는 각 프레임 구간에 포함된 객체가 속한 객체 카테고리에 따라 적어도 일부 중첩된 구간을 포함할 수 있다. 또한, 상기 객체 분석 정보는 각각의 프레임 구간에서 인식된 m개의 객체에 대한 객체 정보를 더 포함하거나, 상기 객체 정보에 대응하는 객체가 포함된 적어도 하나의 객체 별 프레임 구간 정보를 더 포함할 수 있다. 한편, 상기 객체 분석 정보가 지정된 저장매체에 저장된 이후, 상기 운영서버는 사용자 단말을 통해 지정된 동영상 컨텐츠에 포함된 객체를 분석한 객체 분석 정보를 요청하는 정보를 수신하고, 상기 사용자 단말로 상기 동영상 컨텐츠의 객체 분석 정보를 제공한다. 여기서 상기 객체 분석 정보는 엑셀 파일 형태로 제공될 수 있다. 도면6은 본 발명의 실시 방법에 따라 사용자 단말에서 객체 카테고리 정보의 검색을 요청하여 검색 결과 정보를 제공하는 과정을 도시한 도면이다. 보다 상세하게 본 도면6은 상기 도면5의 과정을 통해 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보가 생성되어 지정된 저장매체에 저장된 이후, 운영서버에서 사용자 단말의 객체 카테고리 정보 검색 요청에 따라 검색 결과 정보를 상기 사용자 단말로 제공하는"}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "과정을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면6을 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방 법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면6에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면6을 참조하면, 상기 운영서버는 사용자 단말을 통해 적어도 하나의 동영상 컨텐츠에 포함된 객체 카테고리 정보의 검색을 요청하는 검색 요청 정보를 수신하면, 지정된 저장매체에 저장된 적어도 하나의 객체 분석 정보를 근거로 상기 검색 요청 정보에 대응하는 검색 대상 객체 카테고리 정보를 포함하는 동영상 컨 텐츠를 식별하는 동영상 정보와 상기 식별된 동영상 컨텐츠의 프레임 구간 중 상기 검색 대상 객체 카테고리 정 보를 포함하는 i(i≥1)개의 프레임 구간 정보를 포함하는 검색 결과 정보를 생성한다. 그리고, 상기 운영서버는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구간 정보에 대응하는 프레임 구간 내의 지정된 프레임 구간을 분할하는 i개의 프레임 분할 구간 정보를 생성하고, 상기 생성된 i개의 프레임 분할 구간 정보에 대응하는 i개의 짧은 동영상 컨텐츠를 상기 사용자 단말로 제공하기 위한 i개의 짧은 동영상 컨텐츠 정보를 생성하여 상기 검색 결과 정보에 포함시킨다. 또한, 상기 운영서버는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구간 정보에 대응하는 i개의 대표 이미지를 생성하고, 상기 생성된 i개의 대표 이미지를 상기 검색 결과 정보에 포함시킨 후, 상기 사용자 단말로 상기 검색 결과 정보를 제공한다. 도면7은 본 발명의 실시 방법에 따라 사용자 단말에서 객체 검색을 요청하여 검색 결과 정보를 제공하는 과정을 도시한 도면이다. 보다 상세하게 본 도면7은 상기 도면5의 과정을 통해 적어도 하나의 객체 카테고리에 대응하는 프레임 구간 별 객체 카테고리 정보를 포함하는 객체 분석 정보가 생성되어 지정된 저장매체에 저장된 이후, 운영서버에서 사용자 단말의 객체 검색 요청 시, 상기 객체 분석 정보에 각 프레임 구간에서 인식된 객체에 대응하는 객 체 정보가 포함된 경우, 객체 분석 정보를 근거로 검색 결과 정보를 생성하여 상기 사용자 단말로 제공하"}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "는 과정을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면7을 참조 및/또 는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방 법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면7에 도 시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면7을 참조하면, 상기 운영서버는 사용자 단말을 통해 적어도 하나의 동영상 컨텐츠에 포함된 객체 의 검색을 요청하는 검색 요청 정보를 수신하면, 상기 객체 분석 정보에 각 프레임 구간에서 인식된 객체 에 대응하는 객체 정보가 포함되어 있는지 확인한다. 만약, 상기 객체 분석 정보에 각 프레임 구간에서 인식된 객체에 대응하는 객체 정보가 포함되어 있다면, 상기 운영서버는 지정된 저장매체에 저장된 적어도 하나의 객체 분석 정보를 근거로 상기 검색 요청 정보에 대 응하는 검색 대상 객체를 포함하는 동영상 컨텐츠를 식별하는 동영상 정보와 상기 식별된 동영상 컨텐츠의 프레 임 구간 중 상기 검색 대상 객체를 포함하는 i(i≥1)개의 프레임 구간 정보를 포함하는 검색 결과 정보를 생성 한다. 그리고, 상기 운영서버는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구간 정보에 대응하는 프레임 구간 내의 지정된 프레임 구간을 분할하는 i개의 프레임 분할 구간 정보를 생성하고, 상기 생성된 i개의 프레임 분할 구간 정보에 대응하는 i개의 짧은 동영상 컨텐츠를 상기 사용자 단말로 제공하기 위한 i개의 짧은 동영상 컨텐츠 정보를 생성하여 상기 검색 결과 정보에 포함시킨다.여기서, 상기 짧은 동영상 컨텐츠 정보는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 프레임 분할 구간 정 보에 대응하는 프레임 구간을 선택적으로 사용자 단말로 제공하여 재생하기 위한 구간 재생 정보를 포함할 수 있다. 또한, 상기 운영서버는 상기 동영상 컨텐츠의 전체 프레임 구간 중 상기 검색 결과 정보에 포함된 i개의 프레임 구간 정보에 대응하는 i개의 대표 이미지를 생성하고, 상기 생성된 i개의 대표 이미지를 상기 검색 결과 정보에 포함시킨 후, 상기 사용자 단말로 상기 검색 결과 정보를 제공한다. 도면8은 본 발명의 다른 실시 방법에 따라 사용자 단말에서 객체 검색을 요청하여 검색 결과 정보를 제공하는 과정을 도시한 도면이다. 보다 상세하게 본 도면8은 상기 도면7의 과정에서 사용자 단말에서 객체를 검색 요청했는데, 객체 분석 정 보에 객체 정보가 포함되지 않은 경우, 검색 요청 정보에 대응하는 객체가 속한 적어도 하나의 객체 카테고리 중 검색 대상 객체 카테고리 정보를 결정한 후, 검색 결과 정보를 생성하여 상기 사용자 단말로 제공하는"}
{"patent_id": "10-2021-0011926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "과정을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면8을 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방 법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면8에 도 시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면8을 참조하면, 상기 도면7의 과정을 통해 상기 운영서버는 사용자 단말을 통해 적어도 하나의 동 영상 컨텐츠에 포함된 객체의 검색을 요청하는 검색 요청 정보를 수신한 후, 상기 객체 분석 정보에 각 프레임 구간에서 인식된 객체에 대응하는 객체 정보가 포함되어 있지 않는 경우, 상기 운영서버는 상기 검색 요청 정보에 대응하는 객체가 속한 적어도 하나의 객체 카테고리 중 검색 대상 객체 카테고리 정보를 결정한다. 그리고, 상기 운영서버는 지정된 저장매체에 저장된 적어도 하나의 객체 분석 정보를 근거로 상기 검색 대 상 객체 카테고리 정보를 포함하는 동영상 컨텐츠를 식별하는 동영상 정보와 상기 식별된 동영상 컨텐츠의 프레 임 구간 중 상기 검색 대상 객체 카테고리 정보를 포함하는 i(i≥1)개의 프레임 구간 정보를 포함하는 검색 결 과 정보를 생성하고, 상기 사용자 단말로 상기 검색 결과 정보를 제공한다. 여기서, 상기 검색 대상 객체 카테고리 정보는 객체 카테고리의 계층 구조 상에서 상기 객체가 속한 최하층 계 층의 객체 카테고리 정보를 포함할 수 있다."}
{"patent_id": "10-2021-0011926", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 방법에 따른 동영상을 분석하는 시스템 구성을 도시한 도면이다. 도 2는 본 발명의 실시 방법에 따라 동영상 컨텐츠에 포함된 객체를 인식하는 과정을 도시한 도면이다. 도 3은 본 발명의 다른 실시 방법에 따라 동영상 컨텐츠에 포함된 객체를 인식하는 과정을 도시한 도면이다. 도 4는 본 발명의 또 다른 실시 방법에 따라 동영상 컨텐츠에 포함된 객체를 인식하는 과정을 도시한 도면이다. 도 5는 본 발명의 실시 방법에 따라 동영상 컨텐츠에 포함된 객체를 인식하는 과정을 도시한 도면이다. 도 6은 본 발명의 실시 방법에 따라 사용자 단말에서 객체 카테고리 정보의 검색을 요청하여 검색 결과 정보를 제공하는 과정을 도시한 도면이다. 도 7은 본 발명의 실시 방법에 따라 사용자 단말에서 객체 검색을 요청하여 검색 결과 정보를 제공하는 과정을 도시한 도면이다. 도 8은 본 발명의 다른 실시 방법에 따라 사용자 단말에서 객체 검색을 요청하여 검색 결과 정보를 제공하는 과 정을 도시한 도면이다."}
