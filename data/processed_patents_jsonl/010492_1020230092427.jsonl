{"patent_id": "10-2023-0092427", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0012331", "출원번호": "10-2023-0092427", "발명의 명칭": "혼합현실 기반 초음파 영상 출력 시스템 및 방법", "출원인": "사회복지법인 삼성생명공익재단", "발명자": "김도균"}}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "피검자의 초음파 영상 및 생체신호를 수신하는 데이터 수신부;상기 초음파 영상을 특정 객체에 정합하여 제1 MR(Mixed-reality) 콘텐츠를 생성하는 제1 콘텐츠 생성부; 상기 생체신호를 일정 공간에 정합하여 제2 MR 콘텐츠를 생성하는 제2 콘텐츠 생성부; 및상기 제1 콘텐츠 생성부 또는 상기 제2 콘텐츠 생성부에서 생성된 MR 콘텐츠를 디스플레이하는 출력기기;를 포함하고,상기 제1 콘텐츠 생성부는,상기 출력기기에 구비된 카메라를 통해 초음파 진단기기의 프로브 형상을 인식하고, 상기 프로브 형상의 움직임을 감지하여 상기 제1 MR 콘텐츠의 출력 위치를 변경하는 것을 특징으로 하는 혼합현실 기반 초음파 영상 출력시스템."}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 병변 영역이 주석 처리된 초음파 영상 데이터 세트로 학습된 인공지능을 이용하여 상기 초음파 영상에서 병변영역을 검출하는 병변 검출부를 더 포함하는 것을 특징으로 하는 혼합현실 기반 초음파 영상 출력 시스템."}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 콘텐츠 생성부는,상기 병변 검출부가 검출한 병변 영역이 다른 영역과 구분되도록 상기 제1 MR 콘텐츠를 변경하는 것을 특징으로하는 혼합현실 기반 초음파 영상 출력 시스템."}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1 콘텐츠 생성부는,상기 초음파 영상을 통해 바늘이 상기 병변 영역을 접촉한 것이 확인되면, 상기 병변 영역이 다른 영역과 구분되지 않도록 상기 MR 콘텐츠를 변경하는 것을 특징으로 하는 혼합현실 기반 초음파 영상 출력 시스템."}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,동일한 시점에 측정된 초음파 영상과 생체신호가 출력되고, 동일한 시점에 검출된 병변 영역이 표출될 수 있도록 상기 초음파 영상, 상기 생체신호 및 상기 병변 영역을 동기화시키는 동기화부를 더 포함하는 것을 특징으로하는 혼합현실 기반 초음파 영상 출력 시스템."}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 동기화부는,상기 병변 검출부에서 검출한 병변 영역이 기설정된 기준 값보다 작은 경우 상기 초음파 영상, 상기 생체신호및 상기 병변 영역 중 가장 지연된 신호를 기준으로 동기화시키는 지연 동기화 모듈; 및공개특허 10-2025-0012331-3-상기 병변 검출부에서 검출한 병변 영역이 기설정된 기준 값보다 큰 경우 상기 초음파 영상, 상기 생체신호 및상기 병변 영역 중 가장 앞선 신호를 기준으로 동기화시키는 예측 동기화 모듈;을 포함하는 것을 특징으로 하는 혼합현실 기반 초음파 영상 출력 시스템."}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 예측 동기화 모듈은,보외법(extrapolation)을 이용하여, 가장 앞선 신호에 다른 신호를 동기화시키는 것을 특징으로 하는 혼합현실기반 초음파 영상 출력 시스템."}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 출력기기는,착용자의 전방방향을 촬영하는 제1 카메라와 착용자의 안면을 촬영하는 제2 카메라를 포함하고, 상기 제1 카메라는,초음파 진단기기의 프로브 형상을 인식하고,상기 제2 카메라는,착용자의 시선방향을 추적하는 것을 특징으로 하는 혼합현실 기반 초음파 영상 출력 시스템."}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 출력기기는,상기 제2 카메라에서 추적한 착용자의 시선방향을 따라 상기 제2 MR 콘텐츠를 디스플레이하는 것을 특징으로 하는 혼합현실 기반 초음파 영상 출력 시스템."}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 출력기기는,상기 제2 카메라가 촬영한 착용자의 눈 또는 눈동자의 움직임에 의해 제어되는 것을 특징으로 하는 혼합현실 기반 초음파 영상 출력 시스템."}
{"patent_id": "10-2023-0092427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "피검자의 초음파 영상 및 생체신호를 수신하는 데이터 수신단계;상기 초음파 영상을 특정 객체에 정합하여 제1 MR(Mixed-reality) 콘텐츠를 생성하는 제1 콘텐츠 생성단계; 상기 생체신호를 일정 공간에 정합하여 제2 MR 콘텐츠를 생성하는 제2 콘텐츠 생성단계; 그리고상기 제1 콘텐츠 생성단계 또는 상기 제2 콘텐츠 생성단계에서 생성된 MR 콘텐츠를 출력기기에 디스플레이하는단계;를 포함하고,상기 제1 콘텐츠 생성단계는,상기 출력기기에 구비된 카메라를 통해 초음파 진단기기의 프로브 형상을 인식하고, 상기 프로브 형상의 움직임을 감지하여 상기 제1 MR 콘텐츠의 출력 위치를 변경하는 것을 특징으로 하는 혼합현실 기반 초음파 영상 출력방법.공개특허 10-2025-0012331-4-"}
{"patent_id": "10-2023-0092427", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 피검자의 초음파 영상 및 생체신호를 수신하는 데이터 수신부; 상기 초음파 영상을 특정 객체에 정합 하여 제1 MR(Mixed-reality) 콘텐츠를 생성하는 제1 콘텐츠 생성부; 상기 생체신호를 일정 공간에 정합하여 제2 MR 콘텐츠를 생성하는 제2 콘텐츠 생성부; 및 상기 제1 콘텐츠 생성부 또는 상기 제2 콘텐츠 생성부에서 생성된 MR 콘텐츠를 디스플레이하는 출력기기;를 포함하고, 상기 제1 콘텐츠 생성부는, 상기 출력기기에 구비된 카메라 를 통해 초음파 진단기기의 프로브 형상을 인식하고, 상기 프로브 형상의 움직임을 감지하여 상기 제1 MR 콘텐츠 의 출력 위치를 변경하는 것을 일 특징으로 한다."}
{"patent_id": "10-2023-0092427", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 혼합현실 기반 초음파 영상 출력 시스템 및 방법에 관한 것으로서, 특히 AR 또는 VR 방식으로 디스플 레이하는 기기를 이용하여 초음파 영상을 검사 부위 상에 정렬(align)하여 출력하는 혼합현실 기반 초음파 영상 출력 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0092427", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "초음파(Ultrasound)는 인간의 가청음역보다 높은 범위인 20,000Hz 이상의 주파수를 가진 음파를 지칭하며, 이러 한 초음파를 이용하여 인체 내부 장기나 뼈, 근육조직, 혈액 등 다양한 경계면에서 음파의 확산, 반사, 흡수 및 산란을 통해 생성된 수신 차이를 영상으로 구현한 것을 초음파 영상(ultrasonography)이라고 한다. 초음파 유도 생검(US-guided biopsy)은 초음파 검사 유도 하에 체외에서 가는 바늘을 종괴나 국소 병변에 삽입 하여 조직 표본을 얻는 검사이다. 초음파 유도 생검은 바늘이 병변을 정확하게 찌를 수 있게 도움을 줄 수 있어 정확도를 높이고 위음성을 줄일 수 있다. 이에 따라, 초음파 유도 생검은 임상에서 널리 활용되고 있다. 초음파 유도 고주파 열 치료(US-guided RF ablatio)는 초음파 검사 화면을 보면서 종양에 바늘 형태의 전극을 삽입한 후 전류를 흘려 보냄으로써 발생하는 열을 이용하여 종양을 태워 치료하는 방법이다. 초음파 유도 고주 파 열 치료는 CT(Computerized Tomography), MRI(Magnetic Resonance Imaging) 영상 대비 실시간 유도를 통해 빠르고 정확하게 암 종양 내부에 전극을 삽입하여 치료할 수 있다는 이점을 갖고 있다. 초음파 유도 생검은 시술자가 초음파 프로브를 장시간 움켜쥔 채 수시로 고개를 돌려 초음파 영상과 생검 부위 를 대조하고 확인해야 하므로, 높은 피로도를 유발할 수 있다. 초음파 유도 생검은 초음파 모니터와 생검 부위 를 동시에 볼 수 없어 시술 난이도가 높고, 높은 전문성과 기술을 요구하여 숙련된 전문가만이 수행할 수 있다. 또한, 실제 검사 환경에서, 환자의 침대, 수술장의 수많은 장비 등으로 인해 초음파 장비를 멀리 떨어진 공간에 두고 검사를 수행하는 경우가 빈번하여, 초음파 유도 생검에 장애가 될 수 있다. 초음파 유도 고주파 열 치료는 암 종양의 조기 발견에 따라, 치료할 종양의 크기는 점차 작아지고, 초음파 영상 으로 종양의 위치 확인이 어려워짐에 따라, 시술 시간이 길어질 수 있다. 초음파 유도 고주파 열 치료는 치료 중에는 고도의 집중력을 발휘하여 시술에 몰입하므로, 환자의 혈압, 심박수, 산소 포화도와 같은 신체 위험 징 후를 적시에 모니터링하기 어렵다. 따라서, 위와 같은 초음파 유도 생검과 초음파 유도 고주파 열 치료의 한계점을 해결하기 위한 혼합현실 기반 초음파 영상 출력 시스템 및 방법이 요구되고 있는 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 일본공개특허 제2022-507622호"}
{"patent_id": "10-2023-0092427", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 시술자가 착용할 수 있는 출력기기를 통해 생검 부위와 초음파를 동시에 볼 수 있게 하고, 생검 부위 에 초음파 영상과 병변 부위를 겹쳐볼 수 있게 하는 것을 일 목적으로 한다. 또한, 본 발명은 신체 위험 신호를 시술자가 착용할 수 있는 출력기기를 통해 착용자의 시선방향에 표시하고자 한다. 또한, 본 발명은 출력되는 정보의 신뢰성을 확보하기 위해 입력되는 신호들을 동기화하고자 한다. 또한, 본 발명은 시술자의 상황을 고려하여 터치 없이 장비를 제어할 수 있는 환경을 제공하고자 한다."}
{"patent_id": "10-2023-0092427", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위하여 본 발명은, 피검자의 초음파 영상 및 생체신호를 수신하는 데이터 수신부; 상기 초음파 영상을 특정 객체에 정합하여 제1 MR(Mixed-reality) 콘텐츠를 생성하는 제1 콘텐츠 생성부; 상기 생체 신호를 일정 공간에 정합하여 제2 MR 콘텐츠를 생성하는 제2 콘텐츠 생성부; 및 상기 제1 콘텐츠 생성부 또는 상기 제2 콘텐츠 생성부에서 생성된 MR 콘텐츠를 디스플레이하는 출력기기;를 포함하고, 상기 제1 콘텐츠 생성 부는, 상기 출력기기에 구비된 카메라를 통해 초음파 진단기기의 프로브 형상을 인식하고, 상기 프로브 형상의 움직임을 감지하여 상기 제1 MR 콘텐츠의 출력 위치를 변경하는 것을 일 특징으로 한다. 바람직하게는, 병변 영역이 주석 처리된 초음파 영상 데이터 세트로 학습된 인공지능을 이용하여 상기 초음파 영상에서 병변 영역을 검출하는 병변 검출부를 더 포함할 수 있다. 바람직하게는, 상기 제1 콘텐츠 생성부는, 상기 병변 검출부가 검출한 병변 영역이 다른 영역과 구분되도록 상 기 제1 MR 콘텐츠를 변경할 수 있다. 바람직하게는, 상기 제1 콘텐츠 생성부는, 상기 초음파 영상을 통해 바늘이 상기 병변 영역을 접촉한 것이 확인 되면, 상기 병변 영역이 다른 영역과 구분되지 않도록 상기 MR 콘텐츠를 변경할 수 있다. 바람직하게는, 동일한 시점에 측정된 초음파 영상과 생체신호가 출력되고, 동일한 시점에 검출된 병변 영역이 표출될 수 있도록 상기 초음파 영상, 상기 생체신호 및 상기 병변 영역을 동기화시키는 동기화부를 더 포함할 수 있다. 바람직하게는, 상기 동기화부는, 상기 병변 검출부에서 검출한 병변 영역이 기설정된 기준 값보다 작은 경우 상 기 초음파 영상, 상기 생체신호 및 상기 병변 영역 중 가장 지연된 신호를 기준으로 동기화시키는 지연 동기화 모듈; 및 상기 병변 검출부에서 검출한 병변 영역이 기설정된 기준 값보다 큰 경우 상기 초음파 영상, 상기 생 체신호 및 상기 병변 영역 중 가장 앞선 신호를 기준으로 동기화시키는 예측 동기화 모듈;을 포함할 수 있다. 바람직하게는, 상기 예측 동기화 모듈은, 보외법(extrapolation)을 이용하여, 가장 앞선 신호에 다른 신호를 동 기화시킬 수 있다. 바람직하게는, 상기 출력기기는, 착용자의 전방방향을 촬영하는 제1 카메라와 착용자의 안면을 촬영하는 제2 카 메라를 포함하고, 상기 제1 카메라는, 초음파 진단기기의 프로브 형상을 인식하고, 상기 제2 카메라는, 착용자 의 시선방향을 추적할 수 있다. 바람직하게는, 상기 출력기기는, 상기 제2 카메라에서 추적한 착용자의 시선방향을 따라 상기 제2 MR 콘텐츠를 디스플레이할 수 있다. 바람직하게는, 상기 출력기기는, 상기 제2 카메라가 촬영한 착용자의 눈 또는 눈동자의 움직임에 의해 제어될 수 있다. 또한 본 발명은, 피검자의 초음파 영상 및 생체신호를 수신하는 데이터 수신단계; 상기 초음파 영상을 특정 객 체에 정합하여 제1 MR(Mixed-reality) 콘텐츠를 생성하는 제1 콘텐츠 생성단계; 상기 생체신호를 일정 공간에 정합하여 제2 MR 콘텐츠를 생성하는 제2 콘텐츠 생성단계; 그리고 상기 제1 콘텐츠 생성단계 또는 상기 제2 콘 텐츠 생성단계에서 생성된 MR 콘텐츠를 출력기기에 디스플레이하는 단계;를 포함하고, 상기 제1 콘텐츠 생성단 계는, 상기 출력기기에 구비된 카메라를 통해 초음파 진단기기의 프로브 형상을 인식하고, 상기 프로브 형상의 움직임을 감지하여 상기 제1 MR 콘텐츠의 출력 위치를 변경하는 것을 다른 특징으로 한다."}
{"patent_id": "10-2023-0092427", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 생검 부위와 초음파를 동시에 볼 수 있게 하여 시술자의 피로도를 저감시킬 수 있고, 생검 부위에 초 음파 영상과 병변 부위를 겹쳐볼 수 있게 하여 정확성과 안정성을 높일 수 있다는 이점이 있다. 또한, 본 발명은, 신체 위험 신호를 시술자가 착용할 수 있는 출력기기를 통해 시선방향에 표시하여 환자의 안 전을 확보할 수 있다는 이점이 있다. 또한, 본 발명은 입력되는 신호들을 동기화하여 출력되는 정보의 신뢰성을 확보하고, 다른 부위에 바늘이 삽입 되는 것을 방지할 수 있다는 이점이 있다. 또한, 본 발명은 터치 없이 장비를 제어할 수 있는 환경을 제공하여 시술자의 자유도를 높일 수 있다."}
{"patent_id": "10-2023-0092427", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면들에 기재된 내용들을 참조하여 본 발명을 상세히 설명한다. 다만, 본 발명이 예시적 실시 예 들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일 참조부호는 실질적으로 동일한 기능을 수 행하는 부재를 나타낸다. 본 발명의 목적 및 효과는 하기의 설명에 의해서 자연스럽게 이해되거나 보다 분명해질 수 있으며, 하기의 기재 만으로 본 발명의 목적 및 효과가 제한되는 것은 아니다. 또한, 본 발명을 설명함에 있어서 본 발명과 관련된 공지 기술에 대한 구체적인 설명이, 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 본 발명에서 사용하는 용어는 단지 특정한 실시예들을 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의 도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 발명의 설명에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부분품 또 는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성 요소는 제2 구성 요소로 명명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 갖는다. 일반적 으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 발명에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미 로 해석되지 않는다. 구성 요소를 해석함에 있어서, 별도의 명시적 기재가 없더라도 오차 범위를 포함하는 것으로 해석한다. 시간 관 계에 대한 설명일 경우, 예를 들어, '~후에', '~에 이어서', '~다음에', '~전에' 등으로 시간 적 선후관계가 설 명되는 경우, '바로' 또는 '직접'이 사용되지 않는 이상 연속적이지 않은 경우도 포함한다. 이하, 첨부한 도면들을 참조하여 본 발명의 기술적 구성을 상세하게 설명한다. 도 1은 본 발명의 실시예에 따른 혼합현실 기반 초음파 영상 출력 시스템의 구성도를 나타낸다. 도 1을 참 조하면, 혼합현실 기반 초음파 영상 출력 시스템은 데이터 수신부, 제1 콘텐츠 생성부, 제2 콘텐츠 생성부, 병변 검출부, 동기화부, 및 출력기기를 포함할 수 있다. 혼합현실 기반 초음파 영상 출력 시스템은 생검 부위와 초음파를 동시에 볼 수 있게 하여 시술자의 피로도 를 저감시킬 수 있고, 생검 부위에 초음파 영상과 병변 부위를 겹쳐볼 수 있게 하여 정확성과 안정성을 높일 수 있다. 혼합현실 기반 초음파 영상 출력 시스템은 AR/VR/MR 기기 또는 글래스(glass) 등을 통해 초음파 영 상과 함께 피검자의 생체신호를 출력할 수 있다. 혼합현실 기반 초음파 영상 출력 시스템은 생체신호 등을 분석하여 도출된 신체 위험 신호를 시술자가 즉각 인지할 수 있도록 시술자가 착용한 출력기기(AR/VR/MR 기기 또는 글래스 등)를 통해 시술자의 시선방향에 표시하여 환자의 안전을 확보할 수 있다. 혼합현실 기반 초음파 영상 출력 시스템은 입력되는 신호들을 동기화하여 출력되는 정보의 신뢰성을 확보 하고, 각각 다른 시점의 신호들이 출력되어 다른 부위에 바늘이 삽입되는 것을 방지할 수 있다는 이점이 있다. 혼합현실 기반 초음파 영상 출력 시스템은 터치 없이 장비를 제어할 수 있는 환경을 제공하여 시술자의 자 유도를 높일 수 있다. 혼합현실 기반 초음파 영상 출력 시스템은 스마트폰 테더링 방식과 Stand-alone 방식으로 제공될 수 있다. 도 2는 본 발명의 실시예에 따른 stand-alone 방식의 혼합현실 기반 초음파 영상 출력 시스템 구성을 나타낸다. 도 2를 참조하면, 혼합현실 기반 초음파 영상 출력 시스템은 별도의 사용자 단말(스마트 폰, 노트북 등) 없이 독립적으로 구동될 수 있다. stand-alone 방식은 혼합현실 구현에 필요한 컴퓨팅 연산을 출력기기 자 체에서 수행할 수 있다. stand-alone 방식은 사용자 단말을 들고 다닐 필요가 없기 때문에 편리한 사용성에 강 점이 있다. 구체적으로, stand-alone 방식은 초음파 기기 및 생체신호 기기를 이용하여 피검자의 초음파 영상 및 생체신호 를 측정한 후 이를 의료기기 데이터 처리 서버로 전송할 수 있다. 여기에서 의료기기 데이터 처리 서버는 본 발 명의 데이터 수신부를 의미할 수 있다. 의료기기 데이터 처리 서버는 환자 생체신호 변화정보와 초음파 영 상을 AI 분석 서버(모듈)와 출력기기에 제공할 수 있다. AI 분석 서버는 AI 분석 결과를 출력할 수 있으며, 이때 AI 분석은 병변 검출을 의미할 수 있다. 즉, AI 분석 서버는 본 발명의 병변 검출부를 의미할 수 있다. AI 분석 서버는 AI 분석 결과를 인터넷을 통해 MR HMD(Head Mounted Display) 또는 글래스에 제공할 수 있다. MR HMD 또는 글래스는 의료기기 데이터 처리 서버로부터 환자 생체신호 변화정보와 초음파 영상을 인터넷을 통 해 전송받을 수 있으며, 전송받은 데이터를 이용하여 초음파 영상을 특정 객체에 정합하여 제1 MR(Mixed- reality) 콘텐츠를 생성하고, 생체신호를 일정 공간에 정합하여 제2 MR 콘텐츠를 생성할 수 있다. 즉, stand- alone 방식은 제1 콘텐츠 생성부와 제2 콘텐츠 생성부가 출력기기 내에 포함될 수 있다. 도 3은 본 발명의 실시예에 따른 스마트폰 테더링 방식의 혼합현실 기반 초음파 영상 출력 시스템 구성을 나타 낸다. 도 3을 참조하면, 혼합현실 기반 초음파 영상 출력 시스템은 스마트 폰에 연결되어 구동될 수 있다. 스마트폰 테더링 방식은 출력기기 자체에서 혼합현실 구현에 필요한 컴퓨팅 연산을 수행하지 않고 스마트 폰에서 수행될 수 있다. 스마트폰 테더링 방식은 출력기기 내부에 컴퓨팅을 위한 프로세서, 배터리가 없어 가볍고 발열이 적은 강점이 있다. 구체적으로, 스마트폰 테더링 방식은 환자 생체신호 변화정보, 초음파 영상, 및 AI 분석 결과를 인터넷을 통해 스마트폰으로 전송받을 수 있으며, 스마트 폰은 전송받은 데이터를 이용하여 초음파 영상을 특정 객체에 정합하 여 제1 MR(Mixed-reality) 콘텐츠를 생성하고, 생체신호를 일정 공간에 정합하여 제2 MR 콘텐츠를 생성할 수 있 다. 즉, 스마트폰 테더링 방식은 제1 콘텐츠 생성부와 제2 콘텐츠 생성부가 출력기기 내에 포함 되지 않을 수 있다. 데이터 수신부는 피검자의 초음파 영상 및 생체신호를 수신할 수 있다. 데이터 수신부는 초음파 진단 기기 및 생체신호 측정기기와 유선 또는 무선으로 연결되어 실시간으로 초음파 영상 및 생체신호를 수신할 수 있다. 데이터 수신부는 수신된 초음파 영상과 생체신호를 제1 콘텐츠 생성부, 제2 콘텐츠 생성부 , 또는 병변 검출부에 전송할 수 있다. 데이터 수신부는 무선으로 다른 구성과 연결시 CDMA(Code Division Multiple Access), WCDMA(Wideband CDMA), LTE(Long Term Evolution) 또는 wifi 등의 광 의의 이동통신망을 이용할 수 있다. 데이터 수신부는 무선으로 다른 구성과 연결시 블루투스 등의 근거리 무선통신을 이용할 수 있다. 제1 콘텐츠 생성부는 초음파 영상을 특정 객체에 정합하여 제1 MR(Mixed-reality) 콘텐츠를 생성할 수 있 다. 여기에서, 특정 객체란 초음파 영상이 측정하고자 하는 위치의 해부학적 구조에 1:1로 직접 중첩될 수 있는 신체 부위를 의미할 수 있다. 제1 콘텐츠 생성부는 초음파 진단기기, 데이터 수신부, 또는 출력기기와 상호작용하며 제1 MR 콘텐츠를 보정할 수 있다. 즉, 제1 콘텐츠 생성부는 초음파 진단기기의 프로브의 형상, 시술자의 눈과 출 력기기 사이의 거리 등을 통해 초음파 영상을 특정 객체에 정확히 정합될 수 있도록 제1 MR 콘텐츠를 보정 할 수 있다. 종래에는 초음파 진단기기의 프로브에 부착된 추적패턴(마커, QR 코드 등)을 분석하여 초음파 영상이 정합될 위 치를 계산하였다. 그러나, 실제 초음파 영상을 이용하여 생검 또는 치료를 진행하는데 있어서, 시술자는 필요한 초음파 영상을 정확히 획득하기 위하여 프로브를 지속적으로 움직이게 된다. 이때, 프로브에 부착된 추적패턴은 변형되거나 보이지 않을 수 있다. 기술적으로 추적패턴이 30도만 기울어지거나 회전하여도, 카메라가 추적패턴 을 인식하지 못한다. 이와 같이 추적패턴을 이용하여 정합될 위치를 계산하는 것에는 한계가 있다. 따라서, 본 발명의 실시예에 따른 제1 콘텐츠 생성부는 출력기기에 구비된 카메라를 통해 초음파 진단기기의 프로브 형상을 인식하고, 프로브 형상의 움직임을 감지하여 제1 MR 콘텐츠의 출력 위치를 변경할 수 있다. 제1 콘텐츠 생성부는 인식된 프로브 형상을 통해 프로브의 전면이 향하는 방향으로 제1 MR 콘텐츠가 출력 되게 할 수 있으며, 바람직하게는 프로브와 피검자의 신체가 닿는 부분을 기준으로 하여 프로브의 전면 방향을 향하여 초음파 영상이 측정하고자 하는 위치의 해부학적 구조에 1:1로 직접 중첩되도록 제1 MR 콘텐츠의 출력 위치를 변경할 수 있다. 초음파 기기는 프로브와 수직되는 일직선 방향으로 초음파를 출력하여 반사된 신호를 영상화하는 것이므로, 프 로브와 수직된 방향의 신체부분이 영상화된 것을 초음파 영상이라 한다. 따라서, 초음파 영상이 측정하고자 하 는 위치의 해부학적 구조에 1:1로 직접 중첩되도록 제1 MR 콘텐츠를 출력한다는 것의 의미는 초음파로 만들어내 는 영상이 프로브 아래에 실제로 물리적으로 위치하고 있다고 느끼도록 출력기기를 통해 구현하겠다는 것이다. 도 4는 본 발명의 실시예에 따른 출력기기에 출력되는 MR 콘텐츠의 크기와 프로브 각도의 관계를 설명하기 위한 그림을 나타낸다. 도 4의 (a)를 참조하면, 프로브가 피검자의 신체에 수직으로 초음파를 출력할 때, 시술자의 AR 안경 내 출력되는 초음파 영상 영역을 확인할 수 있다. 시술자가 AR 안경을 착용하고 있다면, AR 안경을 착 용한 시술자의 눈의 위치에서 프로브 아래에 있는 측정 영역이 어떻게 보일지를 계산하여 AR 안경에 출력한다. 따라서, 측정하고자 하는 위치의 해부학적 구조에 1:1로 직접 중첩되도록 MR 영상을 시술자에게 출력하면 신체 내부에 있는 실제 병변의 3차원 위치를 정확하게 알 수 있어 해당 위치에 정확히 바늘을 삽입할 수 있게 된다. 시술자의 눈에 프로브 아래에 있는 측정 영역이 어떻게 보일지에 대한 계산을 통해 AR 안경에 출력되는 초음파 영상의 크기가 정해질 수 있다. 도 4의 (b)를 참조하면, 프로브가 피검자의 신체와 둔각을 이룬 상태에서 초음파를 출력할 때, 시술자의 AR 안 경 내 디스플레이되는 초음파 영상 영역을 확인할 수 있다. 이 경우 프로브 아래에 있는 측정 영역을 바라보는 시선 각도가 프로브가 피검자의 신체에 수직으로 초음파를 출력할 때보다 커지게 되고, 이에 따라 AR 안경 내 디스플레이되는 초음파 영상 영역의 크기도 커지게 된다. 도 4의 (c)를 참조하면, 프로브가 피검자의 신체와 예각을 이룬 상태에서 초음파를 출력할 때, 시술자의 AR 안 경 내 디스플레이되는 초음파 영상 영역을 확인할 수 있다. 이 경우 프로브 아래이 있는 측정 영역을 바라보는 시선 각도가 프로브가 피검자의 신체에 수직으로 초음파를 출력할 때보다 작아지게 되고, 이에 따라 AR 안경 내 디스플레이되는 초음파 영상 영역의 크기도 작아지게 된다. 도 4의 (a) 내지 (c)를 통해 살펴본 것처럼, 프로브의 각도, 시술자와 프로브 사이의 거리 등 시술자가 착용한 출력기기와 프로브의 위치관계에 의해서 출력 기기에 디스플레이되는 초음파 영상의 크기는 달라질 수 있다. 다 만, 디스플레이되는 초음파 영상의 크기가 과도하게 작아질 경우에는 시술자가 초음파 영상을 보며 시술하는데 어려움이 있을 수 있다. 이를 해결하기 위해, 도 4의 (d)와 같이 출력기기 내 디스플레이되는 초음파 영상 영역 의 크기가 일정 이하인 경우 출력기기 내에 별도의 초음파 영상을 디스플레이할 수 있다. 따라서, 시술자는 출 력기기와 프로브의 위치관계에 따라 초음파 영상이 과도하게 작게 디스플레이되는 경우에도 별도로 디스플레이 된 초음파 영상을 통해 안전하게 시술을 진행할 수 있다. 또한, 시술자의 제어에 따라 AR 디스플레이의 특정 영 역에 별도의 초음파 영상을 디스플레이할 수도 있다. 제1 콘텐츠 생성부는 추적패턴을 감지하는 방식으로 초음파 영상이 증강될 위치를 결정하는 것이 아니라 프로브의 형상을 통해 결정하는 것이므로, 시술 중 프로브의 움직임에도 신뢰성 있는 초음파 영상을 출력할 수 있다. 추적패턴을 사용하는 종래 기술의 경우에는 프로브 등에 추적패턴이 부착되어 있어야 MR HMD 또는 글래스를 통 해 초음파 영상을 증강시킬 수 있었다. 본 발명의 실시예에 따른 혼합현실 기반 초음파 영상 출력 시스템 은 추적패턴을 이용하지 않고 프로브의 형상을 이용하므로, 별도의 설치 없이도 모듈화된 장비만을 구비하면 기 존의 초음파 진단기기에도 적용될 수 있다. 제1 콘텐츠 생성부는 병변 검출부가 검출한 병변 영역이 다른 영역과 구분되도록 제1 MR 콘텐츠를 변 경할 수 있다. 시술자는 초음파 영상에서 병변을 구분할 수 있으나, 병변 영역과 병변 영역 이외의 다른 영역을 구분하는 것은 매우 어렵다. 따라서, 현재는 시술자의 능력에 따라 병변 검출 여부가 결정된다. 제1 콘텐츠 생 성부는 병변 검출부가 검출한 병변 영역의 외각선을 강조하거나, 병변 영역 내부의 색을 달리하는 방 식으로 강조할 수 있다. 제1 콘텐츠 생성부는 사용자의 설정에 따라 병변 내부를 확인하고 싶은 경우에는 검출한 병변 영역의 외각선을 강조할 수 있다. 제1 콘텐츠 생성부는 사용자의 설정에 따라 병변의 크기가 확인하고 싶은 경우에는 병변 영역 내부의 색을 달리하는 방식으로 병변 영역을 강조할 수 있다. 제1 콘텐츠 생성부는 초음파 영상을 통해 바늘이 병변 영역을 접촉한 것이 확인되면, 병변 영역이 다른 영 역과 구분되지 않도록 MR 콘텐츠를 변경할 수 있다. 시술자가 병변 영역을 구분하였다고 하여도, 병변 조직을 취득하거나 병변을 치료하기 위해 병변 영역에 바늘을 정확하게 찌르는 것은 매우 어려운 기술이다. 따라서, 제 1 콘텐츠 생성부는 병변 영역을 바늘이 정확히 찌른 경우 강조되었던 병변 영역을 다른 영역과 동일하게 복구시킴으로써 시술자에게 시각적으로 병변 영역에 접촉했음을 알릴 수 있다. 제2 콘텐츠 생성부는 생체신호를 일정 공간에 정합하여 제2 MR 콘텐츠를 생성할 수 있다. 여기에서, 일정 공간은 시술자가 초음파 영상에 집중하며 생검 또는 치료하는 중에도 출력된 생체신호를 확인할 수 있는 공간을 의미한다. 바람직하게는, 시술자의 우측 또는 좌측 눈동자의 시선 방향을 의미할 수 있다. 생체신호는 심전도 (electrocardiogram, ECG), 뇌전도(electroencephalogram, EEG), 근전도(electromyogram, EMG), 피부전도도 (galvanic skin response, GSR), 피부온도(skin temperature, SKT), 맥파(photoplethysmography, PPG), 맥박 (pulse rate, PR), 혈압(blood pressure), 산소포화도 등을 포함할 수 있다. 제2 콘텐츠 생성부는 생체신호가 기준치를 벗어나는 경우 피검자에게 위험상황이 발생했다고 판단하여 시 술자에게 경고 또는 알림을 줄 수 있다. 제2 콘텐츠 생성부는 생체신호 이상 발생시 생체신호가 출력되는 화면을 깜빡이거나 적색 점멸이 발생하도록 제2 MR 콘텐츠를 변경할 수 있다. 도 5는 본 발명의 실시예에 따른 병변 검출부의 구성도를 나타낸다. 도 5를 참조하면, 병변 검출부는 입력부, 전처리부, 학습부, 병변 예측부, 및 후처리부를 포함할 수 있다. 병변 검출부는 병변 영역이 주석 처리된 초음파 영상 데이터 세트로 학습된 인공지능을 이용하여 초음파 영상에서 병변 영역을 검출할 수 있다. 구체적으로, 병변 검출부는 Semantic segmentation 모델을 이용하 여 초음파 영상에서 병변 영역을 검출할 수 있다. Semantic segmentation 모델은 디지털 이미지를 여러 개의 픽 셀 집합으로 나누는 과정으로, 분할을 통해 이미지의 표현을 해석하기 쉬운 것으로 단순화하여 변환할 수 있다. 병변 검출부는 Semantic segmentation 모델로 CNN 기반 모델을 이용할 수 있다. 입력부는 정상군과 환자군의 초음파 영상을 학습, 테스트, 또는 실제 병변 검출을 위해 입력받을 수 있다. 입력부는 데이터 수신부로부터 초음파 영상을 수신할 수 있다. 입력부는 수신된 초음파 영상을 전처리부로 전송할 수 있다. 전처리부는 입력부로부터 수신된 초음파 영상을 학습 또는 검출에 유리하도록 전처리할 수 있다. 전 처리부는 픽셀값을 정규화하는 방식의 전처리를 수행할 수 있다. 전처리부는 인공신경망에 입력되도 록 수신받은 초음파 영상의 사이즈와 해상도를 조정하는 전처리를 수행할 수 있다. 학습에 사용되는 초음파 영 상은 환자의 개인정보를 포함할 수 있어 보안 및 개인정보 유출의 문제가 발생할 수 있다. 따라서, 본 발명에 따른 전처리부는 초음파 영상 및 메타데이터 내의 환자정보를 비식별화하는 전처리를 수행할 수 있다. 학습부는 전처리되고 병변 영역이 주석 처리된 초음파 영상을 이용하여 인공지능을 학습시킬 수 있다. 여 기에서 학습시키는 인공지능은 CNN 기반 또는 SOTA 아키텍처 기반의 Semantic segmentation 모델일 수 있다. 컨볼루션 뉴럴 네트워크 (convolutional neural network; CNN)는 동물의 시각 피질의 구성에서 영감을 받아, 이미지와 같은 격자 패턴을 갖는 데이터를 처리하기 위한 딥 러닝 모델의 일종이다. 컨볼루션 뉴럴 네트워크는일반적으로 컨볼루션 레이어, 풀링 레이어 및 풀리 커넥티드 레이어 (fully connected layer)를 포함할 수 있다. 컨볼루션 레이어 및 풀링 레이어는 신경망 내에 반복적으로 존재할 수 있으며, 입력 데이터는 이러한 레 이어 계층을 통해 출력으로 변환될 수 있다. 컨볼루션은 레이어는 특징 추출을 위해서 커널 (또는 마스크)를 이 용하여, 커널의 각 요소와 입력 값 간의 요소별 곱은 각각의 위치에서 계산되고 합산되어 출력 값을 얻게되며, 이를 특징 맵 (feature map)이라 지칭한다. 이러한 절차는 임의의 수의 특징 맵을 형성하기 위해 여러 커널을 적용하며 반복될 수 있다. 컨볼루션 뉴럴 네트워크에서 컨볼루션 및 풀링 레이어는 특징 추출을 수행하는 반면, 풀리 커넥티드 레이어는 추출된 특징을 분류하는 동작 등의 최종 출력에 매핑한다. 컨볼루션 뉴럴 네트워크는 등의 뉴럴 네트워크는 출력 오류를 최소화하는 방향으로 학습될 수 있다. 입력 레이 어에서 출력 레이어로부터 값을 추출하는 순전파과정과 별개로, 뉴럴 네트워크 내에서는 입력된 학습데이터 및 이에 대한 뉴럴 네트워크의 출력값 사이의 오류를 계산하고 이러한 오류를 줄이기 위해 각각의 레이어의 노드들 에 대한 가중치를 업데이트 하는 역전파 (backpropagation)가 일어나게 된다. 컨볼루션 뉴럴 네트워크에서 학습"}
{"patent_id": "10-2023-0092427", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "시키는 과정은 주어진 학습데이터를 기반으로, 가장 오류가 적은 출력값을 추출하는 커널을 찾는 과정으로 요약 될 수 있다. 커널은 컨볼루션 레이어의 훈련과정에서 자동으로 학습되는 유일한 매개변수이다. 반면, 컨볼루션 뉴럴 네트워크에서 커널의 크기, 커널의 수, 패딩 등은 훈련 과정을 시작하기 전에 설정해야하는 하이퍼 파라미 터이며, 따라서, 커널의 크기, 커널의 수, 컨볼루션 레이어 및 풀링 레이어의 숫자에 따라서 각기 다른 컨볼루 션 뉴럴 네트워크 모델로 구분될 수 있다. 병변 예측부는 학습부에서 학습된 인공지능을 이용하여 피검자의 초음파 영상으로부터 병변 영역을 예측하고 검출할 수 있다. 후처리부는 병변 예측부에서 검출된 병변 영역이 다른 영역과 구분되도록 하는 후처리를 수행할 수 있다. 이는 전술한 제1 콘텐츠 생성부에서 수행되는 기능과 동일하다. 도 6은 본 발명의 실시예에 따른 병변 검출부가 인공지능을 이용하여 병변을 검출하는 프로세스를 나타낸 다. 도 6을 참조하면, 병변 검출부는 초음파 영상을 수신한 후 CNN(Convolutional Neural Network)에 입 력한 후 고성능 Semantic segmentation 모델에 입력하여 병변 예측 영역과 다른 영역이 구분되는 바이너리 마스 크를 획득할 수 있다. 이후 병변 검출부는 병변 예측 영역 중 병변 영역을 선별할 수 있다. 도 7은 본 발명의 실시예에 따른 동기화부의 구성도를 나타낸다. 도 7을 참조하면, 동기화부는 지연 동기화 모듈과 예측 동기화 모듈를 포함할 수 있다. 동기화부는 동일한 시점에 측정된 초음파 영상과 생체신호가 출력되고, 동일한 시점에 검출된 병변 영역이 표출될 수 있도록 초음파 영상, 생체신호 및 병변 영역을 동기화시킬 수 있다. 동기화부는 시술자가 동일 한 시점의 정보를 기준으로 생검 및 치료를 수행할 수 있도록 하는 중요한 역할을 수한다. 만약, 초음파 영상과 병변 영역이 각각 다른 시점에 측정된 것이라면, 시술자를 디스플레이된 병변 영역에 병변이 있을 것으로 기대 하고 있으나 실제로는 다른 시점의 병변 영역으로 해당 위치에 병변이 없을 수도 있다. 이와 같이, 각 신호들의 동기화가 필요한 이유는 초음파 영상, 생체신호, 또는 병변 영역이 구성되거나 검출되 거나 전송되는데 소요되는 시간이 각각 다르기 때문이다. 동기화부는 출력기기를 통해 시술자에게 디 스플레이되는 초음파 영상, 생체신호, 또는 병변 영역을 동일한 시점에 측정된 것으로 동기화시켜 안정성과 신 뢰성을 확보할 수 있다. 도 8은 본 발명의 실시예에 따른 지연 동기화 모듈의 동기화 방식을 설명하기 위한 그림을 나타낸다. 도 8을 참 조하면, 지연 동기화 모듈은 병변 검출부에서 검출한 병변 영역이 기설정된 기준 값보다 작은 경우 초음파 영상, 생체신호 및 병변 영역 중 가장 지연된 신호를 기준으로 동기화시킬 수 있다. 구체적으로 살펴보면, 병변 영역, 초음파 영상, 및 생체신호는 각각 T1, T2, T3만큼 지연되어 신호가 도달될 수 있다(T1>T2>T3). 이때, 가장 지연시간이 긴 병변 영역을 기준으로 동기화를 하게 되면 동기화 기준 시점에 이미 측정된 값들이 존재하므로 동기화에 용이하다. 즉, 초음파 영상은 Tp2 만큼 이전 시점의 신호를 출력하고, 생체 신호는 Tp3 만큼 이전 시점의 신호를 출력함으로써 병변 영역과 동기화할 수 있다. 이러한 동기화 방식은 이미 측정된 값들이 존재하므로 신뢰도와 정확도가 높다는 이점이 있으나, 지연시간이 길다는 단점이 있다. 도 9는 본 발명의 실시예에 따른 예측 동기화 모듈의 동기화 방식을 설명하기 위한 그림을 나타낸다. 도 9 를 참조하면, 예측 동기화 모듈은 병변 검출부에서 검출한 병변 영역이 기설정된 기준 값보다 큰 경 우 초음파 영상, 생체신호 및 병변 영역 중 가장 앞선 신호를 기준으로 동기화시킬 수 있다. 구체적으로 살펴보면, 가장 지연시간이 짧은 생체신호를 기준으로 동기화를 하게 되면 동기화 기준 시점에 병변 영역과 초음파 영상은 도달한 데이터가 없다는 문제가 생긴다. 따라서 예측 동기화 모듈은 보외법 (extrapolation)을 이용하여, 가장 앞선 신호에 다른 신호를 동기화시킬 수 있다. 보외법이란 얻을 수 있는 자 료가 한정되어 있어, 그 이상의 한계를 넘는 값을 얻고자 할 때 쓰는 방법을 의미한다. 다른 실시예로, 예측 동 기화 모듈은 인공지능을 이용하여 가장 앞선 신호의 시점까지의 데이터를 예측할 수 있다. 즉, 예측 동기화 모듈은 Tf1 만큼 앞선 시점의 신호를 예측하여 병변 영역을 출력하고, Tf2 만큼 앞선 시 점의 신호를 예측하여 초음파 영상을 출력함으로써 생체신호와 동기화할 수 있다. 이러한 동기화 방식은 가장 짧은 지연시간에 동기화하므로 지연시간이 짧다는 장점이 있으나, 아직 측정되지 않은 값들을 예측하여 출력하 므로 신뢰도와 정확도가 떨어진다는 단점이 있다. 따라서, 본 발명의 실시예에 따른 혼합현실 기반 초음파 영상 출력 시스템은 검출된 병변이 작은 경우에는 정확도가 높은 지연 동기화 모듈을 사용하고, 검출된 병변이 큰 경우에는 지연 시간이 짧은 예측 동기화 모듈을 사용할 수 있다. 지연 동기화 모듈과 예측 동기화 모듈은 사용자에 설정에 따라 선택될 수도 있다. 도 10은 본 발명의 실시예에 따른 출력기기를 통해 디스플레이되는 화면을 나타낸다. 도 10을 참조하면, 출력기기는 제1 콘텐츠 생성부 또는 제2 콘텐츠 생성부에서 생성된 MR 콘텐츠를 디스플레이할 수 있다. 출력기기는 시술자가 착용할 수 있는 기기일 수 있다. 출력기기는 제1 MR 콘텐츠와 제2 MR 콘텐츠를 증강시키는 방식으로 디스플레이할 수 있도록 AR/VR/MR 기기, 글래스, 또는 HMD일 수 있다. 출력기기는 내부에 혼합현실 구현에 필요한 컴퓨팅 연산을 할 수 있도 록 프로세서 및 배터리를 포함할 수 있다. 출력기기는 경량화를 위해 컴퓨팅 연산을 할 수 있도록 프로세 서 및 배터리를 포함하지 않을 수 있다. 출력기기는 착용자의 전방방향을 촬영하는 제1 카메라와 착용자의 안면을 촬영하는 제2 카메라를 포함할 수 있다. 제1 카메라는 초음파 진단기기의 프로브 형상을 인식하고, 제2 카메라는 착용자의 시선방향을 추적할 수 있다. 제1 카메라는 전술한 제1 콘텐츠 생성부에서 프로브 형상을 인식하는데 사용될 수 있다. 출력기기는 제2 카메라에서 추적한 착용자의 시선방향을 따라 제2 MR 콘텐츠를 디스플레이할 수 있다. 전 술한 바와 같이, 제2 MR 콘텐츠는 생체신호로 구성될 수 있으며, 생체신호는 시술자가 초음파 영상에 집중하는 상황에서도 상태를 파악될 수 있어야 한다. 따라서, 출력기기는 제2 카메라를 이용하여 착용자의 좌측 또 는 우측 눈동자의 시선방향을 감지하여, 해당 시선방향 근처에 제2 MR 콘텐츠를 디스플레이할 수 있다. 출력기기는 제2 카메라가 촬영한 착용자의 눈 또는 눈동자의 움직임에 의해 제어할 수 있다. 시술자는 초 음파 진단을 위해 한손에는 초음파 프로브를 파지하고 다른 한손에는 생검 또는 치료를 위해 바늘을 파지하게 된다. 따라서, 시술자는 출력기기를 제어하기 위해서는 파지한 프로브 또는 바늘을 내려놓거나, 보조자에 게 요청해야만 하는데, 시술자가 출력기기를 빈번하게 제어하거나 응급상황이 발생하여 출력기기를 신속하게 제어해야 하는 경우 제어하는데 한계점이 존재한다. 따라서, 출력기기는 착용자의 눈의 깜빡임, 눈동자의 움직임에 의해 제어됨으로써, 시술자에게 높은 자유도를 제공할 수 있다. 여기에서, 제어는 UI 변경, 제1 MR 콘텐츠 또는 제2 MR 콘텐츠의 온/오프 등을 의미할 수 있다. 본 발명의 다른 실시예인 혼합현실 기반 초음파 영상 출력 방법은 데이터 수신단계, 제1 콘텐츠 생성단계, 제2 콘텐츠 생성단계, 병변 검출단계, 동기화 단계, 및 디스플레이하는 단계를 포함할 수 있다. 데이터 수신단계는 초음파 진단기기와 생체신호 측정기기로부터 피검자의 초음파 영상 및 생체신호를 수신할 수 있다. 데이터 수신단계는 전술한 데이터 수신부에서 수행되는 동작을 의미한다. 제1 콘텐츠 생성단계는 초음파 영상을 특정 객체에 정합하여 제1 MR(Mixed-reality) 콘텐츠를 생성할 수 있다. 제1 콘텐츠 생성단계는 출력기기에 구비된 카메라를 통해 초음파 진단기기의 프로브 형상을 인식하고, 상기 프 로브 형상의 움직임을 감지하여 상기 제1 MR 콘텐츠의 출력 위치를 변경할 수 있다. 제1 콘텐츠 생성단계는 전 술한 제1 콘텐츠 생성부에서 수행되는 동작을 의미한다. 제2 콘텐츠 생성단계는 생체신호를 일정 공간에 정합하여 제2 MR 콘텐츠를 생성할 수 있다. 제2 콘텐츠 생성단 계는 전술한 제2 콘텐츠 생성부에서 수행되는 동작을 의미한다. 병변 검출단계는 병변 영역이 주석 처리된 초음파 영상 데이터 세트로 학습된 인공지능을 이용하여 초음파 영상 에서 병변 영역을 검출할 수 있다. 병변 검출단계는 전술한 병변 검출부에서 수행되는 동작을 의미한다. 동기화 단계는 동일한 시점에 측정된 초음파 영상과 생체신호가 출력되고, 동일한 시점에 검출된 병변 영역이 표출될 수 있도록 초음파 영상, 생체신호 및 병변 영역을 동기화시킬 수 있다. 동기화 단계는 전술한 동기화부 에서 수행되는 동작을 의미한다. 디스플레이하는 단계는 제1 콘텐츠 생성단계 또는 상기 제2 콘텐츠 생성단계에서 생성된 MR 콘텐츠를 출력기기 에 디스플레이할 수 있다. 디스플레이하는 단계는 전술한 출력기기에서 수행되는 동작을 의미한다. 이상에서 대표적인 실시예를 통하여 본 발명을 상세하게 설명하였으나, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자는 상술한 실시예에 대하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형이 가능 함을 이해할 것이다. 그러므로 본 발명의 권리 범위는 설명한 실시예에 국한되어 정해져서는 안 되며, 후술하는 특허청구범위뿐만 아니라 특허청구범위와 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태에 의하여 정 해져야 한다."}
{"patent_id": "10-2023-0092427", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 혼합현실 기반 초음파 영상 출력 시스템의 구성도를 나타낸다. 도 2는 본 발명의 실시예에 따른 stand-alone 방식의 혼합현실 기반 초음파 영상 출력 시스템 구성을 나타낸다. 도 3은 본 발명의 실시예에 따른 스마트폰 테더링 방식의 혼합현실 기반 초음파 영상 출력 시스템 구성을 나타 낸다. 도 4는 본 발명의 실시예에 따른 출력기기에 출력되는 MR 콘텐츠의 크기와 프로브 각도의 관계를 설명하기 위한 그림을 나타낸다. 도 5는 본 발명의 실시예에 따른 병변 검출부의 구성도를 나타낸다. 도 6은 본 발명의 실시예에 따른 병변 검출부가 인공지능을 이용하여 병변을 검출하는 프로세스를 나타낸다. 도 7은 본 발명의 실시예에 따른 동기화부의 구성도를 나타낸다. 도 8은 본 발명의 실시예에 따른 지연 동기화 모듈의 동기화 방식을 설명하기 위한 그림을 나타낸다. 도 9는 본 발명의 실시예에 따른 예측 동기화 모듈의 동기화 방식을 설명하기 위한 그림을 나타낸다. 도 10은 본 발명의 실시예에 따른 출력기기를 통해 디스플레이되는 화면을 나타낸다."}
