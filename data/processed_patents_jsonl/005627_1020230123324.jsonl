{"patent_id": "10-2023-0123324", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0040364", "출원번호": "10-2023-0123324", "발명의 명칭": "사용자-기기 간 인터랙션을 제공하는 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "박봉길"}}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 동작 방법에 있어서,복수의 기기들의 상태 관련 정보 및 상기 복수의 기기들의 이벤트에 대응하는 미디어 관련 정보를 상기 복수의기기들에게 요청하는 단계;제1 사용자 입력에 기초하여, 상기 복수의 기기들 중에서 선택된 기기에 대응하는 상기 상태 관련 정보 및 상기미디어 관련 정보 중 적어도 하나를 출력하는 단계;제2 사용자 입력에 대응하는 신호를 상기 선택된 기기로 전송하는 단계; 및상기 선택된 기기로부터 수신된 상기 제2 사용자 입력에 대응하는 응답을 출력하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 방법은,상기 복수의 기기들에 대응하는 아바타들 중 적어도 하나를 화면에 표시하는 단계; 및상기 아바타들 중에서, 상기 제1 사용자 입력에 대응하는 기기의 아바타에 관련된 정보를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 방법은,상기 복수의 기기들에 대응하는 아바타들의 미디어 관련 정보를 상기 복수의 기기들로부터 획득하는 단계를 더포함하는, 방법."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항 내지 제3항 중 어느 한 항에 있어서,상기 상태 관련 정보 및 상기 미디어 관련 정보 중 적어도 하나를 출력하는 단계는,상기 상태 관련 정보 및 상기 미디어 관련 정보 중 적어도 하나를 상기 제1 사용자 입력에 대응하는 기기의 아바타와 함께 상기 화면에 표시하는 것인, 방법."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항 내지 제4항 중 어느 한 항에 있어서,상기 방법은,상기 사용자에 대응하는 이미지를 획득하는 단계; 및상기 이미지에 기초하여 상기 화면에 대한 상기 사용자의 시선에 대응하는 아바타를 식별하는 단계를 더 포함하공개특허 10-2025-0040364-3-는, 방법."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 방법은,상기 시선에 대응하는 상기 아바타가 식별되면, 상기 식별된 아바타가 다른 아바타와 구별되도록 표시하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항 내지 제6항 중 어느 한 항에 있어서,상기 방법은,복수의 기기들의 위치 정보를 획득하는 단계; 및상기 위치 정보에 기초하여, 상기 복수의 기기들에 대응하는 아바타들이 상기 화면에 표시될 위치들을 변경하여표시하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항 내지 제7항 중 어느 한 항에 있어서,상기 방법은,화면 컨텍스트 정보를 획득하는 단계를 더 포함하고,상기 복수의 기기들에 대응하는 아바타들 중 적어도 하나를 화면에 표시하는 단계는,상기 화면 컨텍스트 정보에 기초하여, 상기 아바타들의 크기 및 위치 중 적어도 하나를 변경하여 표시하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제2항 내지 제7항 중 어느 한 항에 있어서,상기 복수의 기기들에 대응하는 아바타들 중 적어도 하나를 화면에 표시하는 단계는,상기 아바타들의 크기 및 위치에 기초하여 화면 레이아웃을 변경하여 표시하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 방법은,상기 선택된 기기를 동작시키기 위한 제어 명령을 상기 선택된 기기로 전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치에 있어서,공개특허 10-2025-0040364-4-통신 인터페이스;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 하나 이상의 프로세서를 포함하고,상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,복수의 기기들의 상태 관련 정보 및 상기 복수의 기기들의 이벤트에 대응하는 미디어 관련 정보를 상기 복수의기기들에게 요청하고,제1 사용자 입력에 기초하여, 상기 복수의 기기들 중에서 선택된 기기에 대응하는 상기 상태 관련 정보 및 상기미디어 관련 정보 중 적어도 하나를 출력하고,제2 사용자 입력에 대응하는 신호를 상기 선택된 기기로 전송하고,상기 선택된 기기로부터 수신된 상기 제2 사용자 입력에 대응하는 응답을 출력하는, 전자 장치."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 전자 장치는, 디스플레이를 더 포함하고,상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 복수의 기기들에 대응하는 아바타들 중 적어도 하나를 상기 디스플레이의 화면에 표시하도록 상기 디스플레이를 제어하고,상기 아바타들 중에서, 상기 제1 사용자 입력에 대응하는 기기의 아바타에 관련된 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 복수의 기기들에 대응하는 아바타들의 미디어 관련 정보를 상기 복수의 기기들로부터 획득하는, 전자장치."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항 내지 제13항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 디스플레이를 제어하여, 상기 상태 관련 정보 및 상기 미디어 관련 정보 중 적어도 하나를 상기 제1 사용자 입력에 대응하는 기기의 아바타와 함께 상기 화면에 표시하는, 전자 장치."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항 내지 제14항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자에 대응하는 이미지를 획득하고,공개특허 10-2025-0040364-5-상기 이미지에 기초하여 상기 화면에 대한 상기 사용자의 시선에 대응하는 아바타를 식별하는, 전자 장치."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 시선에 대응하는 상기 아바타가 식별되면, 상기 식별된 아바타가 다른 아바타와 구별되도록 변경하고,상기 디스플레이를 제어하여, 상기 다른 아바타와 구별되도록 변경된 아바타를 상기 화면에 표시하는, 전자 장치."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항 내지 제16항 중 어느 한항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,복수의 기기들의 위치 정보를 획득하고,상기 위치 정보에 기초하여, 상기 복수의 기기들에 대응하는 아바타들이 상기 화면에 표시될 위치들을변경하고,상기 디스플레이를 제어하여, 상기 위치들이 변경된 아바타들을 상기 화면에 표시하는, 전자 장치."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항 내지 제17항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,화면 컨텍스트 정보를 획득하고,상기 화면 컨텍스트 정보에 기초하여, 상기 아바타들의 크기 및 위치 중 적어도 하나를 변경하고,상기 디스플레이를 제어하여, 상기 크기 및 위치 중 적어도 하나가 변경된 아바타를 상기 화면에 표시하는 전자 장치."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항 내지 제17항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 아바타들의 크기 및 위치에 기초하여 화면 레이아웃을 변경하고,상기 디스플레이를 제어하여, 상기 변경된 화면 레이아웃을 상기 화면에 표시하는, 전자 장치."}
{"patent_id": "10-2023-0123324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2023-0123324", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자-기기 간 인터랙션을 제공하는 방법이 제공된다. 상기 방법은, 복수의 기기들의 상태 관련 정보 및 상기 복수의 기기들의 이벤트에 대응하는 미디어 관련 정보를 상기 복수의 기기들에게 요청하는 단계; 제1 사용자 입 력에 기초하여, 상기 복수의 기기들 중에서 선택된 기기에 대응하는 상기 상태 관련 정보 및 상기 미디어 관련 정보 중 적어도 하나를 출력하는 단계; 제2 사용자 입력에 대응하는 신호를 상기 선택된 기기로 전송하는 단계; 및 상기 선택된 기기로부터 수신된 상기 제2 사용자 입력에 대응하는 응답을 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0123324", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는, 복수의 기기들과 사용자간의 인터랙션을 제공하는 방법 및 전자 장치에 관한 것이다."}
{"patent_id": "10-2023-0123324", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 기술의 발전에 따라 다양한 타입의 디바이스들에 인공지능이 적용되고 있다. 예를 들어, 생성형 인공지능 이 탑재된 지능형 디바이스는 종래보다 다양하고 많은 시청각 정보를 생성할 수 있다. 지능형 디바이스에서 생 성되는 시각적 정보는 디스플레이를 통해 사용자에게 제공 되어 사용자에게 풍부한 디바이스 사용 경험을 제공 하며, 디바이스 사용 편의를 개선할 수 있다. 그러나, 각 지능형 디바이스는 그 목적과 크기에 따라 다양한 형태로 제작되고, 디바이스의 설치 장소에도 제약 이 존재한다. 이에 따라, 각 지능형 디바이스마다 별도의 디스플레이를 탑재하는 것은 부적절할 수 있다. 본 개 시는 상기한 것에 착안하여, 사용자가 지능형 디바이스들과 인터랙션 할 수 있는 새로운 기술에 관하여 개시한 다."}
{"patent_id": "10-2023-0123324", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 전자 장치가 사용자-기기 간 인터랙션을 제공하는 방법이 제공될 수 있다. 상기 방법은, 복수의 기기들의 상태 관련 정보 및 상기 복수의 기기들의 이벤트에 대응하는 미디어 관련 정보를 상기 복수의 기기들에게 요청하는 단계를 포함할 수 있다. 상기 방법은, 제1 사용자 입력에 기초하여, 상기 복수의 기기들 중에서 선택된 기기에 대응하는 상기 상태 관련 정보 및 상기 미디어 관련 정보 중 적어도 하나를 출력 하는 단계를 포함할 수 있다. 상기 방법은, 제2 사용자 입력에 대응하는 신호를 상기 선택된 기기로 전송하는 단계를 포함할 수 있다. 상기 방법은, 상기 선택된 기기로부터 수신된 상기 제2 사용자 입력에 대응하는 응답을 출력하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 사용자-기기 간 인터랙션을 제공하는 전자 장치가 제공될 수 있다. 상기 전자 장 치는, 통신 인터페이스; 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 메모리에 저장된 상기 하나 이상 의 인스트럭션을 실행하는 하나 이상의 프로세서를 포함할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 복수의 기기들의 상태 관련 정보 및 상기 복수의 기기들의 이벤트에 대응하 는 미디어 관련 정보를 상기 복수의 기기들에게 요청할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상 의 인스트럭션을 실행함으로써, 제1 사용자 입력에 기초하여, 상기 복수의 기기들 중에서 선택된 기기에 대응하 는 상기 상태 관련 정보 및 상기 미디어 관련 정보 중 적어도 하나를 출력할 수 있다. 상기 하나 이상의 프로세 서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 제2 사용자 입력에 대응하는 신호를 상기 선택된 기기로 전송할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 선택된 기 기로부터 수신된 상기 제2 사용자 입력에 대응하는 응답을 출력할 수 있다. 본 개시의 일 측면에 따르면, 전자 장치가 사용자-기기 간 인터랙션을 제공하는, 전술 및 후술하는 방법들 중 어느 하나를 실행시키기 위한 프로그램이 기록된 컴퓨터 판독 가능 기록매체를 제공할 수 있다."}
{"patent_id": "10-2023-0123324", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에 서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 시스템을 설명하기 위한 도면이다. 도 1을 참조하면, 일 실시예에 따른 전자 장치는 사용자가 복수의 기기들과 인터랙션 하도록 하는 인터랙션 허브 기능을 제공할 수 있다. 일 실시예에서, 전자 장치는 디스플레이를 포함하거나, 디스플레이와 연결 가능한 다양한 타입의 디바이 스들을 포함할 수 있다. 예를 들어, 전자 장치는 디스플레이를 포함하는, TV, 스마트 모니터, 태블릿 PC, 랩톱, 디지털 사이니지(Digital Signage), 대형 디스플레이, 360도 프로젝터 등을 포함할 수 있다. 또는, 전자 장치는 디스플레이와 연결 가능한 셋탑박스, 데스크탑 PC 등을 포함할 수 있으나, 이에 한정되는 것은 아 니다. 일 실시예에서, 기기들은 사용자의 공간 내 위치하는 다양한 타입의 디바이스들을 포함할 수 있다. 기기들 은 예를 들어, 세탁기, 건조기, 청소기, 로봇 청소기, 에어컨, 의류 관리기, 공기 청정기, 식기 세척기 등 다양한 홈 가전들을 포함할 수 있으나, 이에 한정되는 것은 아니다. 복수의 기기들 및 전자 장치는 동일한 네트워크에 연결된 상태일 수 있다. 예를 들어, 복수의 기기들 및 전자 장치는 홈 와이파이 에 연결되어, 서로간에 데이터를 송수신할 수 있다. 일 실시예에서, 전자 장치는 디스플레이를 통해 사용자가 복수의 기기들과 인터랙션하는 데 편의를 제공 가능한 다양한 미디어를 표시할 수 있다. 예를 들어, 전자 장치는 복수의 기기들 각 각에 대응하는 아바타들을 디스플레이에 표시할 수 있다. 일 실시예에서, 사용자는 전자 장치를 이용하여 기기들을 관리하고, 제어할 수 있다. 전자 장 치는 사용자 입력을 수신하고, 수신된 사용자 입력에 기초하여 복수의 기기들에게 정보를 요청하거 나, 복수의 기기들을 제어할 수 있다. 전자 장치가 사용자와 복수의 기기들 간에 인터랙션을 제공하는 구체적인 동작들에 대하여, 후 술하는 도면들과 그에 대한 설명을 통해 더 상세하게 기술하기로 한다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도 면이다. 동작 S210에서, 전자 장치는 복수의 기기들의 상태 관련 정보 및 복수의 기기들의 이벤트에 대응하는 미 디어 관련 정보를 요청한다. 일 실시예에서, 전자 장치는 사용자가 복수의 기기들과 인터랙션 하도록 하는 인터랙션 허브 기능을 제공 할 수 있다. 전자 장치는 복수의 기기들로부터, 사용자-기기 간 인터랙션을 위한 정보를 획득할 수 있다. 인터랙션을 위한 정보는, 복수의 기기들의 상태 관련 정보 및 상기 복수의 기기들의 이벤트들에 대응하는 미디 어 관련 정보를 포함할 수 있다. 기기의 상태 관련 정보는 예를 들어, 전원 온/오프 상태, 대기 중 상태, 절전 운용 중인 상태, 저전력 운용 중인 상태, 일반 운용 중인 상태 등, 기기의 현재 작동 상태를 나타내는 데이터를 포함할 수 있으나, 이에 한정되는 것은 아니다. 기기의 이벤트는 기기에서 발생하는 다양한 상황 및/또는 동작 을 포함하며, 사전 정의된 것일 수 있다. 예를 들어, 이벤트는 기기의 상태 변화, 사용자 입력 수신, 시간 경과, 알림 발생 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 기기의 이벤트에 대응하는 미디어 관련 정보는, 기기에서 발생하는 이벤트를 시각/청각 등의 방법을 이용하여 사용자에게 전달하기 위한 다양한 미디어 관련 정보를 포함할 수 있다. 미디어 관련 정보는 예를 들어, 이미지, 비디오, 오디오, 텍스트 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 또한, 미디어 관련 정보는 기기에 대응하는 아바타의 이미지 및/또는 동영 상을 포함할 수 있다. 인터랙션을 위한 정보에 대한 구체적인 설명은 도 3에 대한 설명에서 더 기술될 것이다.전자 장치는 인터랙션을 위한 정보를 다양한 방식으로 획득할 수 있다. 예를 들어, 전자 장치는 인 터랙션을 위한 정보를 복수의 기기들에게 요청할 수 있다. 또는, 전자 장치의 요청이 없더라도, 전자 장 치와 통신 연결된 기기로부터 인터랙션을 위한 정보가 주기적으로 또는 비주기적으로 전자 장치로 수신될 수도 있다. 동작 S220에서, 전자 장치는 제1 사용자 입력에 기초하여 복수의 기기들 중에서 선택된 기기에 대응하는 상태 관련 정보 및 미디어 관련 정보 중 적어도 하나를 출력한다. 본 개시에서, \"제1\" 및 \"제2\" 등 사용자 입력의 서수는, 서로 다른 시점에 입력되는 사용자 입력을 구별하기 위 한 것일 뿐, 사용자 입력의 목적, 기능 등을 한정하기 위한 것은 아니다.전자 장치는 복수의 기기들 중 사용자 입력에 대응하는 기기를 식별하고, 식별된 기기를 선택하여 사용자와 기기가 인터랙션할 수 있도록 하는 환경을 제공할 수 있다. 전자 장치는 제1 사용자 입력을 수신할 수 있다. 제1 사용자 입력은 사용자가 전자 장치를 이용하 여 기기와 인터랙션하기 위해 전자 장치로 입력하는 것일 수 있다. 인터랙션은 예를 들어, 사용자가 기기 를 호출(예를 들어, 웨이크 업 명령)하는 것일 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 사용자 입력은 다양한 형태일 수 있다. 예를 들어, 사용자 입력은 음성 입력일 수 있다. 이 경 우, 전자 장치는 마이크를 포함하거나, 전자 장치에 포함되는 입출력 인터페이스에 연결된 마이크 를 통해 음성 입력을 수신할 수 있다. 예를 들어, 사용자 입력은 시선 입력일 수 있다. 이 경우, 전자 장치 는 카메라 및/또는 시선 추적 센서를 포함하여 사용자의 시선을 추적하여 시선 입력을 획득할 수 있다. 또는, 전자 장치에 포함되는 입출력 인터페이스에 연결된 카메라 및/또는 시선 추적 센서를 통해 시선 입 력이 수신될 수 있다. 또 다른 다양한 형태의 사용자 입력을 예로 들면, 사용자 입력은 터치 입력, 사용자의 또 다른 디바이스(예를 들어, 모바일 폰, 리모콘 등)를 통한 입력을 포함할 수도 있으며, 전술한 예시들에 한정되 는 것은 아니다. 일 실시예에서, 전자 장치는 기기에 대응하는 아바타를 시각적으로 출력할 수 있다. 이 경우, 전자 장치 는 아바타를 시각적으로 출력하기 위한 디스플레이를 포함할 수 있다. 또는, 전자 장치에 포함되는 입출력 인터페이스에 연결된 디스플레이를 통해 아바타가 시각적으로 출력될 수 있다. 즉, 기기의 아바타가 전 자 장치의 화면에 표시되고, 사용자가 아바타를 보면서 사용자 입력을 입력함으로써 사용자-기기 간 인터 랙션이 시작될 수도 있다. 전자 장치는 기기의 아바타를 표시하여 사용자가 기기와 인터랙션을 할 때 보 다 몰입도 있는 인터랙션을 제공할 수 있다. 전자 장치는, 제1 사용자 입력에 기초하여 복수의 기기들 중에서 제1 사용자 입력에 대응하는 기기를 선 택할 수 있다. 전자 장치는 선택된 기기에 대응하는 상태 관련 정보 및 미디어 관련 정보 중 적어도 하나를 출력할 수 있다. 일 실시예에서, 전자 장치는 선택된 기기의 상태 관련 정보를 출력할 수 있다. 예를 들어, 전자 장치 는 사용자가 호출한 기기가 전원 온/오프 상태인지, 대기 중 상태인지, 운용 중인 상태인지 여부 등을 나 타내는 상태 관련 정보를 시각적 및/또는 청각적 형태로 출력할 수 있다. 일 실시예에서, 전자 장치는 선택된 기기의 이벤트에 대응하는 미디어 관련 정보를 출력할 수 있다. 예를 들어, 전자 장치는 기기를 호출하는 사용자 입력을 수신한 것에 대응하여, 기기의 호출 이벤트에 대응하 는 이미지, 비디오, 텍스트 등을 시각적으로 출력하거나, 기기의 호출 이벤트에 대응하는 오디오를 청각적으로 출력할 수 있다. 일 실시예에서, 전자 장치는 선택된 기기의 상태 관련 정보 및 선택된 기기의 이벤트에 대응하는 미디어 관련 정보를 동시에 출력할 수 있다. 예를 들어, 사용자가 기기를 호출하는 경우, 기기의 상태 관련 정보 및 기 기의 호출 이벤트에 대응하는 미디어 관련 정보가 함께 출력될 수 있다. 일 실시예에서, 전자 장치는 기기에 대응하는 아바타를 시각적으로 출력할 수 있다. 이 경우, 기기의 아 바타는 전술한 상태 관련 정보 및/또는 미디어 관련 정보와 함께 표시될 수 있다. 전자 장치는 상태 관련 정보 및/또는 미디어 관련 정보를 전자 장치에 포함되는 디스플레이를 이용 하여 시각적으로 출력할 수 있다. 또는, 전자 장치에 포함되는 입출력 인터페이스에 연결된 디스플레이를통해 상태 관련 정보 및/또는 미디어 관련 정보가 시각적으로 출력될 수도 있다. 전자 장치는 상태 관련 정보 및/또는 미디어 관련 정보를 청각적으로 출력하기 위한 스피커를 포함할 수 있다. 또는, 전자 장치에 포함되는 입출력 인터페이스에 연결된 스피커를 통해 상태 관련 정보 및/또는 미디어 관련 정보가 청각적으로 출력될 수도 있다. 동작 S230에서, 전자 장치는 제2 사용자 입력에 대응하는 신호를 선택된 기기로 전송한다. 전자 장치 는 제2 사용자 입력을 선택된 기기로 전송하는 것에 대응하여, 제2 사용자 입력에 대한 응답을 선택된 기 기로부터 수신할 수 있다. 본 개시에서, 사용자 입력의 서수 \"제1\" 및 \"제2\"는, 서로 다른 시점에 입력되는 사용자 입력을 구별하기 위한 것일 뿐, 사용자 입력의 목적, 기능 등을 한정하기 위한 것은 아니다. 일 실시예에서, 전자 장치는 제2 사용자 입력을 획득할 수 있다. 사용자 입력은 다양한 형태의 입력일 수 있으며, 이는 동작 S220의 설명에서 전술하였으므로 반복되는 설명은 생략한다. 제2 사용자 입력은 기기와 인터랙션하기 위한 사용자가 다양한 목적을 갖는 것일 수 있다. 예를 들어, 기기가 비활성화 상태인 경우, 사용자 입력은 웨이크 업 명령일 수 있다. 전자 장치는 웨이크 업 명령을 기기로 전송하고, 기기가 활성화되었다는 응답을 기기로부터 수신할 수 있다. 예를 들어, 기기가 대기 상태인 경우, 사용자 입력은 특정 기능을 실행하도록 하는 제어 명령일 수 있다. 전자 장치는 제어 명령을 기기로 전송하고, 기기가 제어 명령에 따라 동작을 시작하였다는 응답을 기기로부터 수신할 수 있다. 동작 S240에서, 전자 장치는 기기로부터 수신된 제2 사용자 입력에 대응하는 응답을 출력한다. 전자 장치는 기기로부터 수신된 응답의 시각적 출력 또는 청각적 출력을 통해, 제2 사용자 입력에 대한 기기의 응답이 전자 장치를 통해서 제공되도록 할 수 있다. 즉, 전자 장치는 사용자-기기 간 인터 랙션을 제공할 수 있다. 도 3은 본 개시의 일 실시예에 따른 전자 장치가 기기로부터 획득하는 인터랙션을 위한 정보를 설명하기 위한 도면이다. 도 3을 참조하면, 전자 장치는 기기로부터 사용자-기기 간 인터랙션을 위한 정보를 획득할 수 있다. 인터 랙션을 위한 정보는 기기의 상태 관련 정보 및 기기의 이벤트들에 대응하는 미디어 관련 정보를 포함할 수 있다. 전자 장치는 인터랙션을 위한 정보를 복수의 기기들에게 요청할 수 있다. 또는, 전자 장치의 요청 이 없더라도, 전자 장치와 통신 연결된 기기로부터 인터랙션을 위한 정보가 주기적으로 또는 비주기적으 로 전자 장치로 수신될 수도 있다. 이하에서, 설명의 편의를 위해 인터랙션을 위한 정보를 \"인터랙션 정 보\"라고 지칭하기로 한다. 예를 들어, 전자 장치는 기기들 중 하나인 로봇 청소기의 인터랙션 정보를 획득할 수 있다. 로 봇 청소기의 인터랙션 정보는 다양한 타입의 데이터가 포함될 수 있다. 예를 들어, 로봇 청소기(31 0)의 상태 관련 정보는, 절전 모드를 나타내는 데이터(Boolean 데이터 타입), 그 외 다른 상태(예를 들어, 작업 중인 상태(Busy), 알림 있음 상태, 알림 없음 상태)를 나타내는 데이터(Enumeration 데이터 타입)를 포함할 수 있다. 또한 예를 들어, 로봇 청소기의 이벤트에 대응하는 미디어 관련 정보는, 전자 장치의 슬립 상 태 진입 이벤트에 대응하는 비디오, 전자 장치의 웨이크 업 이벤트에 대응하는 비디오(mp4 데이터 타입) 를 포함할 수 있다. 일 실시예에서, 인터랙션 정보는 사용자-기기 간 인터랙션을 위해 이용 가능한 부가 데이터를 포함할 수 있다. 예를 들어, 사용자를 촬영한 동영상의 전송 허용 여부, 기기의 별명, 기기의 식별 정보 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 한편, 도 3에 도시된 것 및 전술한 설명의 데이터 타입(예를 들어, Bool, Enum, mp4 등)은 설명의 편의를 위한 예시일 뿐, 각 데이터 요소의 데이터 타입을 한정하기 위한 것은 아니다. 전술한 예시에 따라, 전자 장치는 로봇 청소기의 인터랙션 정보를 로봇 청소기로부터 획득하고, 냉장고의 인터랙션 정보를 냉장고로부터 획득할 수 있다. 같은 방식으로, 전자 장치는 전자 장치와 통신 연결 가능한 모든 기기들로부터 인터랙션 정보를 획득할 수 있다. 일 실시예에서, 인터랙션 정보에 포함되는 항목의 속성 값은 사용자 입력에 의해 변경될 수 있다. 예를 들어, 인터랙션 정보의 부가 데이터에 포함되는 \"사용자를 촬영한 동영상의 전송 허용 여부\"는 사용자 입력에 의해 허 용 또는 허용하지 않음으로 변경될 수 있다. 전자 장치는 각각의 기기별로 획득된 인터랙션 정보를 각각 의 기기마다 구별하여 관리할 수 있다. 예를 들어, 특정 디바이스에 대해 \"사용자를 촬영한 동영상의 전송 허용 여부\"가 허용하지 않음으로 변경되는 경우, 전자 장치는 해당 디바이스에 대한 인터랙션 정보만을 변경할 수 있다. 도 4는 본 개의 일 실시예에 따른 전자 장치가 복수의 클라이언트들에 대응하는 아바타를 표시하는 동작을 설명 하기 위한 도면이다. 일 실시예에서, 전자 장치는 복수의 기기들에 대응하는 아바타들 중 적어도 하나를 전자 장치의 화 면에 표시할 수 있다. 예를 들어, 도 4를 참조하면, 전자 장치는 기기들인 로봇 청소기, 냉장고 , 및 공기 청정기 중에서 냉장고의 아바타 및 공기 청정기의 아바타를 화면에 표시할 수 있다. 또는, 도 4에 도시된 것과 달리, 전자 장치는 로봇 청소기, 냉장고, 및 공기 청정기 모두의 아바타들을 화면에 표시할 수도 있다. 전자 장치의 화면에 표시되는 기기의 아바타는 다양한 기 설정된 규칙에 기초하여 결정될 수 있다. 예를 들어, 최근 사용자와 인터랙션한 기기의 아바타가 우 선적으로 표시되거나, 사용자와 가장 많이 인터랙션한 기기의 아바타가 우선적으로 표시될 수 있고, 모든 기기 의 아바타들이 표시될 수도 있다. 한편, 전자 장치의 화면에 표시되지 않은 기기의 아바타일지라도, 사용자 입력(예를 들어, 호출 명령)이 있는 경우 사용자 입력에 대응하는 기기의 아바타가 표시될 수 있다. 예를 들어, 사용자가 로봇 청소기를 호출하는 경우, 전자 장치는 데이터베이스에서 로봇 청소기의 아바타를 검색할 수 있다. 로봇 청소 기의 아바타가 검색되면, 로봇 청소기의 아바타에 관련된 정보를 획득할 수 있다. 전자 장치는 로봇 청소기의 아바타를 화면에 표시할 수 있다. 일 실시예에서, 기기들에 대응하는 아바타들의 미디어 관련 정보는 기기들 각각으로부터 획득될 수 있다. 예를 들어, 전자 장치는 냉장고로부터 냉장고의 아바타를 나타내는 미디어 관련 정보(예를 들 어, 이미지, 동영상 등)를 수신하고, 수신된 냉장고의 아바타를 렌더링할 수 있다. 일 실시예에서, 기기에 대응하는 아바타는 전자 장치에서 생성될 수 있다. 예를 들어, 전자 장치는 기기로부터 아바타 생성을 위한 메타데이터(예를 들어, 기기의 종류, 색상, 스타일, 등)을 수신하고, 메타데이 터에 기초하여 기기에 대응하는 아바타를 생성할 수 있다. 구체적으로, 전자 장치는 공기 청정기로 부터 공기 청정기의 아바타 생성을 위한 메타 데이터를 수신하고, 수신된 메타 데이터에 기초하여 공기 청 정기의 아바타를 생성하고, 렌더링할 수 있다. 일 실시예에서, 전자 장치는 임의의 아바타를 기기에 할당할 수 있다. 예를 들어, 전자 장치는 복 수의 아바타들의 데이터를 포함하는 아바타 데이터베이스에서 임의의 아바타를 선택하거나, 복수의 아바타들을 조합하여 임의의 아바타를 생성하고, 기기에 할당할 수 있다. 구체적으로, 전자 장치는 아바타 데이터베 이스 내 데이터에 기초하여 냉장고의 아바타를 생성하고, 렌더링할 수 있다. 일 실시예에서, 기기의 아바타는 기기의 상태 관련 정보 및/또는 기기의 이벤트에 대응하는 미디어 관련 정보가 출력될 때, 함께 표시될 수 있다. 또는, 기기의 아바타가 전자 장치의 화면에 표시되고, 사용자가 아바타 를 보면서 사용자 입력을 입력함으로써 사용자-기기 간 인터랙션이 시작될 수도 있다. 일 실시예에서, 전자 장치에서 표시되는 아바타는 사용자가 기기와 인터랙션함에 따라 컨텍스트에 맞게 변화되며 표시될 수 있다. 예를 들어, 사용자가 기기를 호출하는 경우, 사용자의 호출에 응답하는 애니메이션 효과가 아바타에 적용될 수 있다. 또는, 사용자의 호출에 응답하는 자연어 응답이 텍스트로 표시될 수 있으며, 오디오로 출력될 수도 있다. 전자 장치가 사용자에게 아바타를 이용한 인터랙션을 제공하는 경우, 아바타의 인터랙션 행동(예를 들어, 애니메이션 효과, 오디오 출력, 텍스트 출력)을 출력하기 위한 데이터는 기기로부터 수신될 수 있다. 또는, 전 자 장치가 기기로부터 획득한 인터랙션 정보를 이용하여, 아바타의 인터랙션 행동을 출력하기 위한 데이 터를 생성할 수도 있다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 아바타를 이용하여 사용자-기기 간 인터랙션을 제공하는 동작 을 설명하기 위한 도면이다. 도 5를 설명함에 있어서, 복수의 기기들의 아바타들 중에서 냉장고의 아바타가 선택되어 사용자와 인 터랙션 하는 것을 예시로 설명한다. 도 5를 참조하면, 전자 장치는 선택된 기기인 냉장고의 아바타를 표시할 수 있다. 이 경우, 전 자 장치는 냉장고의 아바타를 통해 사용자-냉장고 간 인터랙션을 제공할 수 있다. 예를 들어, 사용자가 냉장고를 호출하는 경우, 전자 장치의 화면에서 표시 중인 냉장고의 아바타가 손을 흔들어 사용자의 호출에 응답할 수 있다. 일 실시예에서, 전자 장치는 냉장고의 아바타와 함께 냉장고의 인터랙션 정보를 표시할 수 있다. 인터랙션 정보는 냉장고의 상태 관련 정보, 냉장고의 이벤트에 대응하는 미디어 관련 정보를 포 함할 수 있으나, 이에 한정되는 것은 아니다. 구체적으로 예를 들면, 도 5에 도시된 것과 같이 전자 장치는 냉장고 내 현재 보관 중인 식품들의 상태 관련 정보를 화면에 표시할 수 있다. 또한, 도 5에는 도시되지 않았으나, 전자 장치는 냉장고의 다양한 상태(예를 들어, 냉장실 온도, 냉 동실 온도, 동작 상태(예를 들어, 야채 보관 모드, 육류 보관 모드 등)를 나타내는 상태 관련 정보를 출력할 수 있다. 또한, 도 5에는 도시되지 않았으나, 전자 장치는 냉장고의 다양한 이벤트에 대응하는 미디어 관련 정보를 출력할 수 있다. 예를 들어, 전자 장치는 기 정의된 이벤트인 냉장고에 보관된 식품의 유통 기한의 임박을 알리는 이미지, 비디오, 텍스트 및 오디오 등을 출력할 수 있다. 일 실시예에서, 전자 장치는 사용자 입력을 수신하고, 사용자 입력에 대한 기기의 응답을 전자 장치 를 통해 출력할 수도 있다. 예를 들어, 전자 장치는 냉장고의 동작 상태를 변경(예를 들어, 야채 보관 모드에서 육류 보관 모드로 변경)하는 사용자 입력을 수신하고, 냉장고의 동작 상태를 변경하기 위한 제어 명령을 냉장고로 전송할 수 있다. 전자 장치는 냉장고의 동작 상태 변경을 알리는 응답을 냉장고로부터 수신하고 출력할 수 있다. 또 다른 예에서, 전자 장치는 유통기한이 임박한 식 품을 알려달라는 사용자 입력을 수신하고, 냉장고에게 식품 유통기한 데이터를 요청할 수 있다. 전자 장치 는 냉장고에 보관된 유통기한 임박 식품을 알리는 응답을 냉장고로부터 수신하고 출력할 수 있 다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 기기와 데이터를 송수신하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 클라이언트와 데이터를 송수신할 수 있다. 예를 들어, 도 6을 참조하면, 전자 장치는 냉장고의 아바타를 화면에 표시할 수 있다. 이 경우, 전자 장치의 화면에 표시되는 아바타의 미디어 관련 정보는 냉장고로부터 수신된 것일 수 있다. 아바타의 미디어 관련 정보는 아바타의 이미지, 동영상 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 사용자 데이터를 기기로 전송할 수 있다. 사용자 데이터는 사용자 가 기기와 인터랙션하기 위해 전자 장치에 입력한 사용자 입력에 대응할 수 있다. 예를 들어, 전자 장치 는 사용자 데이터를 냉장고로 전송할 수 있다. 사용자 입력에 의한 사용자 데이터는 다양 한 방식으로 획득될 수 있다. 사용자 입력은 예를 들어, 카메라를 통해 사용자를 촬영하여 획득되는, 사용 자에 대응하는 이미지/동영상일 수 있고, 마이크를 통해 획득되는 음성일 수 있다. 일 실시예에서, 미디어 관련 정보는 사용자 데이터에 대한 응답일 수 있다. 예를 들어, 사용자 데이 터가 냉장고를 호출하는 사용자 입력인 경우, 냉장고로부터 수신되는 미디어 관련 정보는 호출 이벤트에 대하여 아바타가 응답(예를 들어, 손 흔들기 등)하는 동영상일 수 있다. 또는, 사용자 데이 터가 사용자의 제스처를 포함하는 동영상인 경우, 냉장고로부터 수신되는 미디어 관련 정보는 제스처 유형에 대응하여 아바타가 응답하는 동영상일 수 있다. 전자 장치는, 냉장고로부터 아 바타의 미디어 관련 정보가 수신되면, 수신된 미디어 관련 정보를 렌더링하여 화면에 표시할 수 있다. 일 실시예에서, 전자 장치는 권한 설정을 위한 사용자 입력에 기초하여 기기로 전송되는 데이터의 권한 허용 범위를 설정할 수 있다. 예를 들어, 사용자가 자신을 촬영한 동영상이 기기로 전송되는 것을 원하지 않는 경우, 사용자는 동영상 전송을 허용하지 않도록 하는 설정을 입력할 수 있다. 전자 장치는 이 경우, 기기 로 사용자 데이터를 전송할 때, 사용자를 촬영한 동영상은 전송되지 않도록 할 수 있다. 즉, 전자 장치 는 사용자가 개인 정보를 보호를 위한 데이터 전송 범위를 설정하도록 할 수 있다. 도 7a는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도면이다. 전자 장치는 복수의 기기들에 대응하는 아바타들 중 적어도 하나를 화면에 표시할 수 있다. 예를 들어, 도 7a를 참조하면, 전자 장치는 제1 기기에 대응하는 제1 아바타 및 제2 기기에 대응하는 제2 아바 타를 화면에 표시할 수 있다. 일 실시예에서, 전자 장치는 사용자 입력을 수신할 수 있다. 사용자 입력은 시선 입력, 음성 입력, 제스 처 입력, 터치 입력, 사용자의 또 다른 디바이스(예를 들어, 모바일 폰, 리모콘 등)를 통한 입력을 포함할 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 사용자 입력에 기초하여 복수의 기기들 중 하나를 선택 할 수 있다. 전자 장치는 사용자의 시선에 대응하는 아바타를 식별할 수 있다. 예를 들어, 전자 장치 는 제1 아바타를 바라보는 사용자의 시선 입력에 기초하여 복수의 기기들 중에서 제1 아바타에 대응하는 제1 기기를 선택할 수 있다. 일 실시예에서, 전자 장치는 카메라 및/또는 시선 추적 센서를 이용하여 시선 입력을 획득할 수 있 다. 카메라 및/또는 시선 추적 센서는 전자 장치에 포함되거나, 전자 장치에 포함되는 입출력 인터페이스를 통해 연결될 수 있다. 전자 장치는 카메라를 이용하여 사용자에 대응하는 이미지들을 획득하고, 이미지들에 기초하여 화면에 대한 사용자의 시선 위치를 결정할 수 있다. 예를 들어, 전자 장치 는 이미지들로부터 눈동자를 검출하고, 눈동자의 위치를 기초로 사용자의 시선 위치를 화면에 매핑할 수 있다. 또는, 전자 장치는 시선 추적 센서를 이용하여 사용자의 눈동자나 동공의 이미지를 검출하거나, 근 적외선 등의 광이 각막에서 반사되는 반사광의 방향 또는 광량을 검출함으로써 사용자의 시선 방향을 획득하고, 시선 방향에 기초하여 화면에 대한 사용자의 시선 위치를 결정할 수 있다. 시선 위치는 전자 장치의 화면 에 대한 좌표 (x, y)일 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 시선 위치에 대응하는 아바 타를 결정하고, 결정된 아바타에 대응하는 기기를 식별할 수 있다. 일 실시예에서, 전자 장치는 마이크를 이용하여 음성 입력을 획득할 수 있다. 마이크는 전자 장치에 포함되거나, 전자 장치에 포함되는 입출력 인터페이스를 통해 연결될 수 있다. 전자 장치 는 마이크를 이용하여 사용자의 음성 입력을 획득할 수 있다. 이 경우, 마이크를 통해 입력되 는 음성 신호는 디지털 신호로 변환되어 전자 장치의 프로세서에 의해 처리될 수 있다. 전자 장치 는 예를 들어, 사용자의 음성 입력에 자동 음성 인식(Automatic Speech Recognition; ASR)을 적용하여 음성을 텍스트를 변환하고, 자연어 처리(Natural Language Processing; NLP) 모델을 이용하여 텍스트를 처리 및 분석할 수 있다. 또한, 전자 장치는 자연어 이해(Natural Language Understanding; NLU) 모델을 이용하여 텍스 트의 의미, 의도 등을 분석할 수도 있다. 전술한 자동 음성 인식, 자연어 처리, 자연어 이해 등을 포함하는 음 성 처리는 전자 장치에서 수행될 수 있으며, 음성 처리를 위한 별도의 외부 장치(예를 들어, 서버)에서 수행될 수도 있다. 한편, 음성 입력은 사용자의 또 다른 디바이스(예를 들어, 모바일 폰, 리모콘 등)를 통해 획 득될 수도 있다. 예를 들어, 전자 장치는 전자 장치와 블루투스 통신 연결된 리모콘으로부터, 디지 털 신호로 변환된 음성 데이터를 획득할 수 있다. 또 다른 예로, 전자 장치는 전자 장치와 와이파 이 통신 연결된 스마트폰으로부터, 디지털 신호로 변환된 음성 데이터를 획득할 수 있다. 일 실시예에서, 전자 장치는 터치 스크린 및/또는 터치 패드를 이용하여 터치 입력을 획득할 수 있다. 이 경우, 터치 스크린(터치 패널)이 전자 장치에 포함되거나, 터치 패드가 전자 장치에 포함되는 입출 력 인터페이스를 통해 연결될 수 있다. 일 실시예에서, 전자 장치는 사용자의 또 다른 디바이스(예를 들어, 모바일 폰, 리모콘 등)를 통한 다양 한 사용자 입력을 수신할 수 있다. 예를 들어, 전자 장치는 전자 장치와 통신 연결된 사용자의 모 바일 폰, 태블릿 PC 등으로부터, 터치 입력, 음성 입력 등의 사용자 입력을 수신할 수 있다. 이 경우, 사용자는 모바일 폰에 설치된 전자 장치를 제어하기 위한 애플리케이션을 통해 전자 장치에 사용자 입력을 제공할 수 있다. 또는, 전자 장치는 전자 장치를 제어 가능한 리모콘으로부터 음성 입력, 터치 입 력, 버튼 입력 등의 사용자 입력을 수신할 수도 있다.전자 장치는 사용자 입력에 대응하는 기기가 식별되면, 식별된 기기와 사용자 간의 인터랙션을 제공할 수 있다. 이 경우, 전자 장치는 기기에 대응하는 아바타를 화면에 표시하고, 아바타를 통해 사용자가 기기와 소통하고, 사용자가 기기를 제어할 수 있도록 함으로써, 직관적인 인터랙션 경험을 사용자에게 제공하는 인터랙 션 허브의 역할을 할 수 있다. 도 7b는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 복수의 기기들의 아바타들을 표시할 수 있다. 도 7b를 설명함에 있어서, 복 수의 기기들 중 하나가 사용자에 의해 선택된 경우를 예시로 설명한다. 일 실시예에서, 전자 장치는 사용자 입력에 기초하여 선택된 아바타를 다른 아바타와 구별되도록 출력할 수 있다. 예를 들어, 전자 장치는 선택된 아바타를 변경하여 선택된 아바타가 다른 아바타와 시각적으로 다르게 표시할 수 있다. 예를 들어, 도 7b를 참조하면, 전자 장치는 화면에 표시된 제1 아바타 및 제2 아바타 중에서, 사용자의 시선 위치에 대응하는 아바타가 제1 아바타인 것을 결정할 수 있다. 이 경우, 전자 장치는 사용자의 시선 위치에 대응하는 제1 아바타가 결정된 것에 기초하여, 제1 아바타 를 시각적으로 다르게 표시할 수 있다. 이하, 도 7b의 동작을 설명함에 있어서 사용자 입력(예를 들어, 시 선 입력)에 의해 제1 아바타가 선택된 경우를 예시로 하여 설명한다. 일 실시예에서, 전자 장치는 선택된 아바타의 표시를 변경하기 위해 소정의 데이터 처리 및 변환을 수행 하여 아바타 정보를 변경할 수 있다. 전자 장치는 변경된 아바타 정보를 이용하여 렌더링 업데이트를 수 행할 수 있다. 예를 들어, 전자 장치는 렌더링을 업데이트하여 아바타의 확대, 축소, 이동, 애니메이션 효과 등의 변경사항을 적용할 수 있다. 일 실시예에서, 전자 장치는 도 7b에 도시된 것과 같이 선택된 아바타를 다른 아바타들보다 크게 표시할 수 있다. 예를 들어, 전자 장치는 사용자 입력에 대응하는 제1 아바타를 화면에 크게 표시하고, 제2 아바타는 화면에 작게 표시할 수 있다. 한편, 전자 장치가 선택된 아바타를 시각적으로 다르게 표시하는 방법은 전술한 예시에 한정되는 것은 아 니다. 예를 들어, 전자 장치는 제1 아바타를 밝게 표시하고, 제2 아바타를 어둡게 표시할 수 있다. 또는, 전자 장치는 제1 아바타를 컬러로 표시하고, 제2 아바타를 흑백으로 표시할 수 있 다. 또는, 전자 장치는 제1 아바타에 움직이는 상태의 애니메이션 효과를 적용하여 표시하고, 제2 아바타는 정지된 상태로 표시할 수도 있다. 즉, 전자 장치는 전술한 예시들을 포함하여 아바타의 하 나 이상의 속성을 변경함으로써, 사용자에 의해 선택된 아바타가 강조되어 표시되도록 할 수 있다. 전자 장치는 사용자에 의해 선택된 아바타를 시각적으로 다르게 표시함으로써, 복수의 아바타들 중에서 어떠한 아바타가 현재 활성화되어 사용자와 인터랙션 중인지, 즉, 복수의 기기들 중 어떠한 기기가 사용자의 명 령을 듣고 있는지를 사용자가 직관적으로 인식할 수 있도록 할 수 있다. 도 7c는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 공간 내 사용자의 위치에 기초하여 전자 장치의 화면에 표시되는 아바 타를 변경할 수 있다. 전자 장치는 공간 내 사용자의 위치를 결정할 수 있다. 예를 들어, 전자 장치는 카메라를 이 용하여 사용자 및 사용자의 공간을 촬영한 이미지들을 획득할 수 있다. 전자 장치는 공간 내 사용자 위치 를 검출하기 위한 다양한 알고리즘을 적용할 수 있다. 예를 들어, 전자 장치는 사용자의 얼굴을 검출하고, 얼굴 추적, 시선 추적을 위한 알고리즘을 이용함으로써 전자 장치의 화면을 바라보는 사용자의 얼굴 위치를 결정하고, 공간 내에서 이동하는 사용자의 위치를 추적할 수 있다. 전자 장치는 공간 내 사용자의 위치가 결정되는 것에 기초하여, 전자 장치의 화면에 표시되는 아바 타가 사용자를 바라보도록 렌더링할 수 있다. 또한, 전자 장치는 공간 내 사용자의 위치가 변경되는 것에 기초하여, 전자 장치의 화면에 표시되는 아바타가 변경된 위치의 사용자를 바라보도록 렌더링할 수 있다. 예를 들어, 사용자가 전자 장치의 왼쪽 측면에 서서 전자 장치를 이용하는 경우, 전자 장치 는 화면에 표시되는 제1 아바타가 왼쪽에 서있는 사용자를 바라보도록 할 수 있다. 또한, 사용자가 오른쪽 측면으로 이동하는 경우, 전자 장치는 사용자의 위치 변화를 추적하고, 화면에 표시되는 제1 아바타 계속해서 사용자를 바라보도록 표시할 수 있다. 전자 장치는 사용자의 위치 변경에 따라 아바타의 표시를 변경하기 위해 소정의 데이터 처리 및 변환을 수행하여 아바타 정보를 변경할 수 있다. 전자 장치는 변경된 아바타 정보를 이용하여 렌더링 업데이트를 수행할 수 있다. 예를 들어, 전자 장치는 렌더링을 업데이트하여 아바타의 확대, 축소, 이동, 애니메이션 효과 등의 변경사항을 적용할 수 있다. 즉, 전자 장치는 사용자의 위치 변경에 대응하여 아바타의 표시를 변경함으로써, 사용자에게 보다 몰입감 있는 인터랙션을 제공할 수 있다. 도 7d는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 사용자 입력에 기초하여 복수의 기기들 중 하나를 선택하고, 선택된 기기에 대응하는 상태 관련 정보 및 미디어 관련 정보 중 적어도 하나를 출력할 수 있다. 예를 들어, 전자 장치는 사용자로부터 시선 입력을 수신할 수 있다. 기기가 사용자의 시선 입력을 수신하 는 경우, 기기는 시선 입력 이벤트에 대응하여 상태 정보 및 시선 입력 이벤트에 대응하는 미디어 관련 정보 중 적어도 하나를 표시할 수 있다. 구체적으로, 사용자가 제1 아바타를 바라보는 경우, 전자 장치는 사용자의 시선 위치가 제1 아바타 의 위치에 대응하는 것으로 결정하고, 제1 아바타에 대응하는 제1 기기를 선택할 수 있다. 이 경우, 제1 기기의 상태는 알림 있음 상태일 수 있다. 전자 장치는 제1 기기의 시선 입력 이벤트에 대응하는 미 디어를 제1 아바타를 이용하여 출력할 수 있다. 예를 들어, 전자 장치는 제1 기기에서 현재 알림이 있으니, 알림을 확인해 달라는 적극적인 행동을 하는 애니메이션 효과(예를 들어, 손 흔들기, 점프하기 등)를 제1 아바타에 적용할 수 있다. 또는, 전자 장치는 제1 기기의 상태를 제1 아바타를 이용하여 출력할 수 있다. 예를 들어, 전자 장치는 제1 기기가 알림이 있는 상태라는 것을 제1 아바타와 함께 시각적/청각적으로 출력할 수 있다. 기기의 알림은 기기의 기능 및 동작과 관련하여 사용자에게 제공되는 다양 한 알림들을 포함할 수 있다. 예를 들어, 냉장고 내 보관 식품의 유통기한이 임박하였음을 알리는 알림, 세탁기 에서 세탁이 완료되었음을 알리는 알림, 오븐에서 조리가 완료되었음을 알리는 알림 등이 포함될 수 있으나, 이 에 한정되는 것은 아니다. 또 다른 예시로, 사용자가 제2 아바타를 바라보는 경우, 전자 장치는 사용자의 시선 위치가 제2 아 바타의 위치에 대응하는 것으로 결정하고, 제2 아바타에 대응하는 제2 기기를 선택할 수 있다. 이 경 우, 제2 기기의 상태는 알림 없음 상태일 수 있다. 전자 장치는 제2 기기의 시선 입력 이벤트에 대응하는 미디어를 제2 아바타를 이용하여 출력할 수 있다. 예를 들어, 전자 장치는 제2 기기에 현재 알림이 없으니, 관심 받고 싶지 않은 소극적인 행동을 하는 애니메이션 효과(예를 들어, 시선 회피하기, 곤란한 표정 짓기 등)를 제2 아바타에 적용할 수 있다. 또는, 전자 장치는 제2 기기의 상태를 제2 아바타를 이용하여 출력할 수 있다. 예를 들어, 전자 장치는 제2 기기가 알림이 없는 상태라는 것을 제2 아바타 와 함께 시각적/청각적으로 출력할 수 있다. 도 8a는 본 개시의 일 실시예에 따른 전자 장치가 기기들의 위치를 획득하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 사용자의 공간(예를 들어, 집)의 공간 맵을 획득할 수 있다. 공간 맵 은 사용자의 현실 공간을 맵 데이터로 구현한 것일 수 있다. 공간 맵은 다양한 방식으로 획득될 수 있다. 예를 들어, 공간 맵은 인터넷 등에 공지된 퍼블릭 공간 맵에 대하여, 사용자가 공간 내 기기들을 맵핑한 것일 수 있다. 또는, 공간 맵은 사용자에 의해 촬영/생성 된 것이거나, 사용자의 또 다른 전자 장치(예를 들어, 로봇 청소기 등)에 의해 생성된 것일 수 있다. 일 실시예에서, 공간 맵은 사용자의 공간의 레이아웃(예를 들어, 기둥, 벽 등) 정보를 포함할 수 있다. 또 한, 공간 맵 기기 정보(기기의 종류, 위치 등)를 포함할 수 있다. 일 실시예에서, 전자 장치는 기기들의 위치 정보에 기초하여, 기기들에 대응하는 아바타들의 위치를 변경 하여 표시할 수 있다. 전자 장치는 공간 맵을 획득하여 기기들의 위치 정보를 획득하고, 기기들의 위치 정보에 기초하여 기기들에 대응하는 아바타들을 화면에 표시할 수 있다. 예를 들어, 공간 내에서 전자 장치의 왼쪽에는 공 기 청정기가 위치하고, 전자 장치의 오른쪽에는 에어컨이 위치할 수 있다. 이 경우, 전자 장치 는 공기 청정기 및 에어컨의 위치 정보를 식별한 것에 기초하여, 전자 장치의 화면 왼쪽에 공기 청정기의 아바타를 표시하고, 전자 장치의 화면 오른쪽에 에어컨의 아바타를 표시할 수 있다. 전자 장치는 전자 장치를 중심으로 기기들의 상대적인 위치 관계를 반영하여 기기들의 아바타들을 표시할 수 있다. 예를 들어, 전자 장치는 전자 장치로부터 기기가 위치하는 방향에 기초하여, 전자 장치의 화면에 표시될 기기의 아바타의 위치를 결정할 수 있다. 또는, 전자 장치는 전자 장치 로부터 기기까지의 거리에 기초하여, 전자 장치의 화면에 표시될 기기의 아바타의 크기를 결정할 수 있다. 또는, 전자 장치는 공간 레이아웃에 기초하여, 전자 장치 기기의 아바타의 표시 여부를 결정할 수도 있다. 예를 들어, 전자 장치는 공간 내 특정 레이아웃 내(예를 들어, 안방, 거실 등)에 위치 하는 기기들의 아바타들만을 표시할 수 있다. 도 8b는 본 개시의 일 실시예에 따른 전자 장치가 기기들의 위치를 획득하는 동작을 설명하기 위한 도면이다. 전자 장치는 공간 내 존재하는 기기들의 위치를 직접적으로 식별할 수 있다. 또한, 전자 장치는 공 간 내 존재하는 기기들로부터 위치에 관련된 정보를 획득할 수도 있다. 일 실시예에서, 전자 장치는 카메라를 이용하여 전자 장치가 위치한 공간을 촬영할 수 있다. 전자 장치는 공간을 촬영한 이미지들을 획득하고, 이미지들로부터 공간 내 존재하는 기기들을 검출할 수 있다. 예를 들어, 전자 장치는 공간을 촬영한 이미지로부터 공기 청정기를 검출하고, 공기 청정기 의 위치 정보를 획득할 수 있다. 전자 장치는 기기가 검출되면, 전자 장치로부터 기기까지의 상대적 위치를 계산할 수 있다. 이 경우, 깊이 추정을 위한 인공지능 알고리즘 등이 이용될 수 있으나, 이에 한 정되는 것은 아니다. 한편, 전자 장치는 객체의 3차원 정보를 분석하고 공간 내 객체의 위치를 식별하기 위해, 카메라외 하나 이상의 센서를 더 이용할 수 있다. 예를 들어, 전자 장치는 깊이 추정 및 3차 원 스캔을 위한 RGB-깊이(RGB-D) 센서, ToF(Time of Flight) 센서, 빛 탐지 및 범위 측정(Light Detection And Ranging; LiDAR) 센서, 전파 탐지 및 범위 측정(Radio Detection And Ranging; RADAR) 센서 등을 더 이용할 수 도 있다. 일 실시예에서, 전자 장치는 기기로부터 기기의 위치에 관한 정보를 획득할 수 있다. 예를 들어, 전자 장 치는 공간 내 존재하는 기기 중 하나인 로봇 청소기로부터, 라이다 맵을 생성할 수 있다. 라이 다 맵은 로봇 청소기가 공간 내를 이동하면서 공간을 촬영하고 생성한 공간 맵일 수 있다. 이 경우, 라이다 맵에 공간 내 존재하는 기기들의 위치 정보가 포함될 수 있다. 예를 들어, 사용자 입력에 의해 라 이다 맵에 공간 내 기기들의 위치가 마킹될 수 있다. 또는, 로봇 청소기에 내장된 카메라를 통해 로 봇 청소기가 공간 내 기기들을 검출하고, 기기들의 위치를 마킹할 수도 있다. 전자 장치는 기기들의 위치 정보를 포함하는 라이다 맵을 기기로부터 획득할 수 있다. 전자 장치는 공간 내 기기들의 위치 정보를 획득하고, 전자 장치를 중심으로 기기들의 상대적인 위 치 관계를 반영하여 기기들의 아바타들을 표시할 수 있다. 예를 들어, 전자 장치는 기기들의 위치 정보에 기초하여, 기기들에 대응하는 아바타들이 표시될 속성(아바타 위치, 아바타 크기 등)을 결정할 수 있다. 도 9a는 본 개시의 일 실시예에 따른 전자 장치가 기기의 아바타를 표시하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 화면 컨텍스트 정보를 획득할 수 있다. 전자 장치는 화면에 표시된 이 미지, 비디오, 텍스트 등을 분석할 수 있다. 예를 들어, 전자 장치는 화면에 표시 중인 적어도 하나의 객 체, 로고, 아이콘, 텍스트 등을 검출할 수 있다. 이 경우, 전자 장치는 인공지능 모델인 검출 모델을 이 용할 수 있다. 검출 모델은 이미지를 입력 받아 객체 등을 나타내는 정보를 출력하는 심층 신경망 모델일 수 있 다. 예를 들어, 검출 모델은 이미지를 입력 받아 검출된 객체 등을 나타내는 바운딩 박스를 출력할 수 있다. 검 출 모델은 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍 처 및 알고리즘의 변형을 통해 구현될 수 있다. 검출 모델은 예를 들어, Convolutional neural networks (CNNs)을 기반으로 하는 Faster R-CNN, Mask R-CNN, You Only Look Once(YOLO), Single Shot Detector(SSD) 등으로 구현될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 검출된 객체, 로고, 아이콘, 텍스트 등을 인식할 수 있다. 이 경우, 전자 장치는 인공 지능 모델인 인식 모델을 이용할 수 있다. 인식 모델은 이미지를 입력 받아 객체 클래스 레이블(들)을 나타내는 정보를 출력하는 심층 신경망 모델일 수 있다. 예를 들어, 인식 모델은, 객체를 잘라낸 이미지를 입력 받아 하 나 이상의 객체 클래스 레이블(예를 들어, \"아이콘\", \"사람\" 등) 및 신뢰도 스코어를 출력할 수 있다. 객체 인 식 모델은 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 객체 인식 모델은 예를 들어, Convolutional neural networks (CNNs)을 기반으로 하는 ResNet, Inception Networks, VGG Networks, DenseNet 등으로 구현될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 화면 내 객체, 로고, 아이콘, 텍스트 등을 검출 및 인식하여, 현재 표시 중인 화면의 상황 또는 맥락을 나타내는 화면 컨텍스트 정보를 획득할 수 있다. 전자 장치는 화면 컨텍스트 정보에 기초하 여, 아바타들의 크기 및 위치 중 적어도 하나를 변경하여 표시할 수 있다. 전자 장치는 화면 컨텍스트 정 보에 기초하여, 아바타들의 크기 및 위치 중 적어도 하나를 결정할 수 있다. 일 실시예에서, 전자 장치는 전자 장치가 동작하는 도중 사용자-기기 간 인터랙션을 위한 사용자 입력을 수신하면, 사용자 입력에 대응하는 기기를 결정할 수 있다. 전자 장치는 사용자 입력에 대응하는 기기가 결정되면, 기기에 대응하는 아바타를 화면에 표시할 수 있다. 이 경우, 전자 장치는 화면 컨텍스 트 정보에 기초하여 아바타가 표시될 위치, 아바타가 표시될 크기 등을 결정할 수 있다. 예를 들어, 제1 화면을 참조하면, 전자 장치는 홈 화면을 표시 중인 상태일 수 있다. 전자 장치 는 홈 화면에 표시된 애플리케이션 아이콘, 이미지(미리보기 썸네일), 메뉴 아이콘 등을 분석하고, 홈 화 면에서 기기의 아바타를 표시 가능한 영역을 결정할 수 있다. 전자 장치는 제1 화면에 도시된 것과 같이, 홈 화면에 표시된 애플리케이션 아이콘, 이미지(미리보기 썸네일), 메뉴 아이콘 등의 크기 및 위치에 기 초하여, 아바타의 크기 및 위치 중 적어도 하나를 결정할 수 있다. 이에 따라, 전자 장치는 사용자가 전 자 장치의 화면에 표시되는 아바타를 통해 기기와 인터랙션 할 수 있도록 하면서도, 전자 장치에서 제공하는 원래의 기능(예를 들어, 홈 화면 기능)도 이용 가능하도록 할 수 있다. 또 다른 예를 들어, 제2 화면을 참조하면, 전자 장치는 설정 메뉴 화면을 표시 중인 상태일 수 있다. 전자 장치는 설정 메뉴 화면에 표시된 아이콘, 텍스트 등을 분석하고, 설정 메뉴 화면에서 기기의 아바타를 표시 가능한 영역을 결정할 수 있다. 전자 장치는 제2 화면에 도시된 것과 같이, 설정 메 뉴 화면에 표시된 애플리케이션 아이콘, 미리보기 썸네일, 메뉴 아이콘 등의 크기 및 위치에 기초하여, 아바타 의 크기 및 위치 중 적어도 하나를 결정할 수 있다. 이에 따라, 전자 장치는 사용자가 전자 장치의 화면에 표시되는 아바타를 통해 기기와 인터랙션 할 수 있도록 하면서도, 전자 장치에서 제공하는 원래의 기능(예를 들어, 설정 화면 기능)도 이용 가능하도록 할 수 있다. 한편, 일 실시예에 따른 전자 장치는 아바타의 크기 및 위치를 먼저 결정하고, 결정된 아바타의 크기 및 위치에 기초하여 화면 레이아웃을 변경할 수 있다. 예를 들어, 전자 장치는 아바타의 크기 및 위치에 기 초하여, 화면에 표시되는 아이콘, 로고, 텍스트, 이미지들의 크기, 위치, 배치, 구조 등을 변경할 수 있다. 도 9b는 본 개시의 일 실시예에 따른 전자 장치가 기기의 아바타를 표시하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 화면 컨텍스트 정보에 기초하여 복수의 기기들에 대응하는 아바타들이 화면 에 표시될 위치들을 결정할 수 있다. 예를 들어, 전자 장치가 화면에 콘텐츠를 표시 중인 상황에서, 사용자-기기 간 인터랙션을 위한 사용자 입력이 수신될 수 있다. 이 경우, 전자 장치는 사용자-기기 간 인터랙션을 제공하기 위해 복수의 기기들에 대응하는 아바타들을 화면에 표시할 수 있다. 예를 들어, 전자 장치 는 제1 기기의 제1 아바타 및 제2 기기의 제2 아바타를 화면에 표시할 수 있다. 일 실시예에서, 전자 장치는 화면 컨텍스트 정보에 기초하여 콘텐츠와 제1 아바타 및 제2 아바 타가 겹치지 않도록 아바타가 표시될 위치를 결정할 수 있다. 즉, 전자 장치는 콘텐츠에 대응 하는 미디어 관련 정보에 제1 아바타 및 제2 아바타에 대응하는 미디어 관련 정보를 오버레이하여 표 시할 수 있다. 전자 장치는 화면 컨텍스트를 이용하여 아바타가 표시될 위치를 결정함으로서, 사용자가 전자 장치(200 0)에서 표시되는 컨텐츠를 계속 시청하면서도 기기와 인터랙션 할 수 있는 환경을 제공할 수 있다. 도 9c는 본 개시의 일 실시예에 따른 전자 장치가 기기의 아바타를 표시하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 기기에 대응하는 아바타를 표시할 때, 전자 장치에서 표시 중인 콘텐 츠를 변경할 수 있다. 예를 들면, 전자 장치에서 콘텐츠가 표시 중인 상황에서, 사용자가 전자 장치를 통해 기기와 인터 랙션을 수행하고자 할 수 있다. 구체적으로, 사용자는 기기를 호출하는 사용자 입력을 전자 장치로 입력 할 수 있다. 이 경우, 전자 장치는 사용자-기기간 인터랙션을 제공하기 위해 기기의 아바타를 화면에 표시할 수 있다. 일 실시예에서, 전자 장치는 도 9c에 도시된 것과 같이, 제1 아바타를 메인 화면에 표시하고, 전자 장치에서 표시 중이던 콘텐츠를 pip화면에 표시할 수 있다. 또는, 전자 장치는 제1 아바타를 화면에 표시하고, 전자 장치에서 표시 중이던 콘텐츠는 백그 라운드 프로세스에서 계속 재생되거나, 일시 정지된 상태로 대기하도록 할 수도 있다. 한편, 지금까지 기술된 전자 장치가 기기에 대응하는 아바타를 화면에 표시하는 다양한 예시들은, 각각이 독립 배타적인 것은 아니다. 전자 장치는 전술한 방법들의 다양한 조합을 이용하여 기기의 아바타를 화면 에 표시할 수 있고, 표시된 아바타를 통해 사용자-기기 간 인터랙션을 제공할 수 있다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 기기의 아바타를 표시하는 동작을 설명하기 위한 도면이다. 도 10을 참조하면, 일 실시예에 따른 전자 장치는 전자 장치가 일반적으로 동작 중인 상태(예를 들 어, 미디어 콘텐츠를 재생 동작 중인 상태) 외에 다른 동작 상태일 때에, 복수의 기기들의 아바타들을 표시할 수 있다. 예를 들어, 전자 장치는 전자 장치가 휴식 상태일 때, 적어도 하나의 아바타를 표시할 수 있다. 휴 식 상태란, 전자 장치가 전력 관리 등을 위해 동작하는 상태를 말하며, 예를 들어, 호출 명령에 의해 웨 이크 업 될 수 있는 절전 상태, 최소한의 전력 자원만을 사용하며 켜진 상태로 유지되는 Always On 상태 등을 포함할 수 있다. 이하에서, 전자 장치가 일반적으로 동작 중인 상태 외에 다른 방식으로 동작하는 상태를 휴식 상태를 예 시로 하여 설명한다. 다만, 다른 방식의 동작 상태의 종류는 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 휴식 상태일 때 동작되는 기능(예를 들어, 화면 보호기 기능)을 실행하고, 전자 장치의 화면에 복수의 기기들의 아바타들을 표시할 수 있다. 예를 들어, 제1 화면과 같이, 전자 장치는 전자 장치가 휴식 상태일 때 복수의 기기들에 대 응하는 아바타들을 표시할 수 있다. 이 경우, 사용자가 기기를 호출하거나, 전자 장치를 호출하면 전자 장치가 깨어날 수 있다. 전자 장치는 기기를 호출하는 사용자 입력이 수신되면, 복수의 기기들에 대응하는 아바타들 중에서 사용자 입력에 대응하는 아바타를 검색하고, 아바타에 관련된 정보를 표시할 수 있다. 전자 장치는 검색된 아바타를 표시할 수 있다. 전자 장치는 검색된 아바타를 통해 사용자가 기기와 인터랙션 하도록 할 수 있다. 일 실시예에서, 전자 장치가 휴식 상태에서 동작 중일 때 사용자가 기기를 호출하는 경우, 사용자-기기 간 인터랙션만을 수행하도록 최적화된 상태로 동작할 수 있다. 예를 들어, 제2 화면과 같이, 전자 장치가 휴식 상태에서 동작 중일 때, 사용자가 기기를 호출하는 경우, 전자 장치는 인터랙션 최적화 모드로 진입할 수 있다. 인터랙션 최적화 모드는, 전자 장치의 원래의 기능(예를 들어, 미디어 콘텐츠 재생 등)은 활성화하지 않고, 전자 장치가 사용자-기기 간 인터랙 션을 제공하기 위한 기능만을 활성화한 것일 수 있다. 예를 들어, 전자 장치는 전자 장치의 화면 중 일부만을 활성화하여 기기의 아바타를 표시할 수 있다. 다만, 인터랙션 최적화 모드의 기능은 전술한 예시에 한정되는 것은 아니다. 도 11a는 본 개시의 일 실시예에 따른 전자 장치가 기기와 데이터를 송수신하는 동작을 설명하기 위한 도면이다. 전자 장치는 기기인 로봇 청소기로부터 인터랙션을 위한 정보를 수신할 수 있다. 인터랙션을 위한 정보는 기기의 상태 관련 정보 및 기기의 이벤트에 대응하는 미디어 관련 정보를 포함할 수 있다. 일 실시예에서, 전자 장치는 기기에게 인터랙션을 위한 정보를 요청할 수 있다. 예를 들어, 전자 장치 는 사용자 입력 또는 기 설정된 주기에 기초하여 기기에게 인터랙션을 위한 정보를 요청할 수 있다. 전자 장치는 인터랙션을 위한 정보를 데이터베이스에 저장할 수 있다. 일 실시예에서, 기기가 기 설정된 이벤트 발생에 기초하여 전자 장치에게 인터랙션을 위한 정보를 전송할 수도 있다. 전자 장치는 기 설정된 이벤트가 발생한 기기로부터 인터랙션을 위한 정보를 수신하고, 전자 장치의 데이터베이스에 저장할 수 있다.예를 들어, 로봇 청소기가 절전 상태인 경우, 전자 장치는 로봇 청소기가 절전 상태에 있다 는 것을 사용자에게 표시할 수 있어야하고, 사용자가 전자 장치를 통해 로봇 청소기를 호출하는 경 우 로봇 청소기는 절전 상태에서 깨어나 사용자와 상호작용 할 수 있어야 한다. 전자 장치는 로봇 청소기로부터 인터랙션을 위한 정보를 수신할 수 있다. 예를 들어, 전자 장치 는 로봇 청소기로부터 로봇 청소기가 절전 상태에 진입함을 통지 받을 수 있다. 또한, 전자 장치 는 로봇 청소기로부터 로봇 청소기가 절전 상태임을 표시할 수 있는 미디어 관련 정보(예를 들어, Sleep.mp4)를 수신할 수 있다. 또한, 전자 장치는 로봇 청소기로부터 로봇 청소기가 절전 상태에서 깨어남을 표시할 수 있는 미디어 관련 정보(예를 들어, Wake up.mp4)를 수신할 수 있다. 전자 장 치는 로봇 청소기로부터 수신된 인터랙션을 위한 정보를 데이터베이스에 저장할 수 있다. 도 11b는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 와 데이터를 송수신하는 동작을 설명하기 위 한 도면이다. 일 실시예에서, 전자 장치는 데이터베이스에 저장된 인터랙션을 위한 정보를 이용하여 사용자와 기 기 간의 인터랙션을 제공할 수 있다. 일 실시예에서, 전자 장치는 사용자로부터 로봇 청소기를 호출하는 사용자 입력(예를 들어, 제1 사 용자 입력)을 수신할 수 있다. 전자 장치는 사용자 입력에 기초하여, 로봇 청소기와 사용자 간의 인터랙션을 제공할 수 있다. 예를 들어, 전자 장치는 데이터베이스에 저장된 데이터로부터 로봇 청 소기의 상태를 확인할 수 있다. 전자 장치는 로봇 청소기의 현재 상태가 절전 상태임을 확인 하고, 절전 상태임을 표시할 수 있는 미디어 관련 정보(예를 들어, Sleep.mp4)를 데이터 베이스에서 불러 올 수 있다. 전자 장치는 로봇 청소기가 절전 상태임을 나타내는 미디어 관련 정보를 화면에 표시 할 수 있다. 전자 장치는 사용자로부터 절전 상태인 로봇 청소기를 깨우려는 사용자 입력(예를 들어, 제2 사용 자 입력)을 수신할 수 있다. 전자 장치는 사용자 입력에 기초하여, 로봇 청소기와 사용자 간의 인 터랙션을 제공할 수 있다. 예를 들어, 전자 장치는 로봇 청소기가 절전 상태에서 깨어남을 표시할 수 있는 미디어 관련 정보(예를 들어, Wake up.mp4)를 데이터 베이스에서 불러올 수 있다. 또한, 전자 장 치는, 로봇 청소기를 활성화하기 위한 웨이크 업 명령을 로봇 청소기에게 전송할 수 있다. 전자 장치는 로봇 청소기가 깨어났음을 나타내는 미디어 관련 정보를 화면에 표시할 수 있다. 일 실시예에서, 전자 장치는 기기에 대응하는 아바타의 미디어 관련 정보를 기기로부터 획득할 수 있다. 예를 들어, 전자 장치는 로봇 청소기로부터 로봇 청소기에 대응하는 아바타의 미디어 관련 정보를 수신할 수 있다. 수신된 로봇 청소기의 아바타는 전자 장치의 화면에서 표시될 수 있다. 도 12는 본 개시의 일 실시예에 따른 전자 장치가 또 다른 전자 장치와 데이터를 송수신하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 공간 내 하나 이상일 수 있다. 예를 들어, 공간 내 제1 전자 장치(2000-1) 및 제2 전자 장치(2000-2)가 존재할 수 있다. 이하, 제1 전자 장치(2000-1)의 사용자는 제1 사용자로 지칭하고, 제2 전자 장치(2000-2)의 사용자는 제2 사용자로 지칭한다. 제1 전자 장치(2000-1)는 제1 사용자로부터 사용자 입력을 수신할 수 있다. 예를 들어, 제1 사용자는 제2 전자 장치(2000-2)를 호출하는 사용자 입력을 제1 전자 장치(2000-1)에 입력할 수 있다. 이 경우, 제1 전자 장치 (2000-1)는 제2 전자 장치(2000-2)의 아바타를 제1 전자 장치(2000-1)의 화면에 표시할 수 있다. 구체적으로 예를 들면, 제1 전자 장치(2000-1)를 이용하는 제1 사용자가 제2 전자 장치(2000-2)에서 현재 어떤 콘텐츠가 재생되고 있는지 궁금해할 수 있다. 이 경우, 제1 사용자는 현재 제2 전자 장치(2000-2)에서 어떤 콘 텐츠가 재생 중인지 문의하는 사용자 입력을 제1 전자 장치(2000-1)에게 입력할 수 있다. 제1 전자 장치(2000-1)는, 제1 사용자의 사용자 입력이 수신되는 것에 기초하여 사용자 입력에 대응하는 요청 (예를 들어, 현재 재생 중인 콘텐츠 문의)을 제2 전자 장치(2000-2)에게 전달할 수 있다. 제2 전자 장치(2000-2)는 제1 전자 장치(2000-1)로부터 사용자 입력에 대응하는 요청이 수신되는 것에 기초하여, 제2 전자 장치(2000-2)의 제2 사용자에게 제1 전자 장치(2000-1)로부터 수신된 요청을 전달할 수 있 다. 예를 들어, 제2 전자 장치(2000-2)는 지금 무슨 컨텐츠를 보고 있는 지 문의하는 요청이 제1 전자 장치(2000-1)로부터 수신되었을 제2 사용자에게 알리고, 제2 사용자가 응답을 제공하도록 할 수 있다. 제2 사용자가 제1 전자 장치(2000-1)로부터의 요청을 수락하는 경우, 제2 전자 장치(2000-2)는 사용자 입력에 대응하는 응답을 제1 전자 장치(2000-1)에게 제공할 수 있다. 예를 들어, 제2 전자 장치(2000-2)는 제2 전자 장 치(2000-2)의 화면을 복제한 미디어 관련 정보를 제1 전자 장치(2000-1)에게 전송할 수 있다. 제1 전자 장치(2000-1)는 제2 전자 장치(2000-2)로부터 수신된 미디어 콘텐츠를 화면에 표시할 수 있다. 일 실시예에서, 제1 사용자가 제1 전자 장치(2000-1)를 이용하여 특정 기기와 인터랙션 중일 때, 제2 사용자가 제2 전자 장치(2000-2)를 이용하여 동일한 기기와 인터랙션하고자 할 수 있다. 이 경우, 기기는 제1 전자 장치 (2000-1)를 통해 현재 인터랙션을 하고 있는 중이므로, 제2 전자 장치(2000-2)에게는 현재 상태가 바쁨 상태임 을 전송할 수 있다. 이에 따라, 제2 전자 장치(2000-2)에서는 기기의 상태가 바쁨 상태로 표시될 수 있다. 도 13은 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 일 실시예에서, 전자 장치는 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 통신 인터페이스는 통신 회로를 포함할 수 있다. 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜 (Wireless LAN), 와이파이(Wi-Fi), 블루투스(Bluetooth), 지그비(ZigBee), WFD(Wi-Fi Direct), 적외선 통신 (IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로 (Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Alliances, WiGig) 및 RF 통신을 포함하 는 데이터 통신 방식 중 적어도 하나를 이용할 수 있다. 통신 인터페이스는 전술한 통신 방식들을 구현하 기 위한 복수의 모듈들(예를 들어, 와이파이 모듈, 블루투스 모듈 등)을 포함하도록 구현될 수 있다. 통신 인터페이스는 전자 장치의 동작을 수행하기 위한 데이터를 기기들과 송수신할 수 있다. 예를 들어, 전자 장치는 통신 인터페이스를 통해 전자 장치가 사용자-기기 간 인터랙션을 제공하 기 위해 사용하는 다양한 데이터(예를 들어, 사용자 입력, 상태 관련 정보, 미디어 관련 정보 등)를 기기들과 송수신할 수 있다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 메모리는 하나 이상일 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작 들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 ROM(Read-only memory)(예를 들어, PROM(Programmable read-only memory), EPROM(Erasable programmable read-only memory), EEPROM(Electrically erasable programmable read-only memory)), 플래시 메모리(Flash memory)(예를 들어, 메모리 카드, SSD(Solid-state drive)) 및 아날로그 기록 타입(예를 들어, HDD(Hard disk drive), 자기테이프, 광학 디스크)와 같은 비휘발성 메모리 및, RAM(random-access memory)(예 를 들어, DRAM(Dynamic random-access memory), SRAM(Static random-access memory))과 같은 휘발성 메모리를 포함할 수 있다. 메모리는 전자 장치가 사용자-기기 간 인터랙션을 제공하기 위해 동작하도록 하는 데이터, 인스트 럭션들 및 프로그램들을 저장할 수 있다. 예를 들어, 메모리는 데이터베이스를 포함할 수 있다. 데 이터 베이스에는 복수의 기기들로부터 수신되는 데이터들이 저장될 수 있다. 또한, 사용자 입력 처리 모 듈, 기기 관리 모듈이 저장될 수 있다. 프로세서는 전자 장치의 전반적인 동작들을 제어할 수 있다. 예를 들어, 프로세서는 메모리 에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행함으로써, 전자 장치가 사용자- 기기 간 인터랙션을 제공하기 위한 전반적인 동작들을 제어할 수 있다. 프로세서는 하나 이상일 수 있다. 프로세서는 전자 장치의 전술했던 동작들이 수행되도록 할 수 있다. 예를 들어, 프로세서는 사용자 입력 처리 모듈을 이용하여 다양한 타입의 사용자 입력을 처리할 수 있다. 사용자 입력 처리 모듈은 예를 들어, 사용자의 시선을 추적하여 시선 입력을 획득하거나, 사용자의 음성을 분석하여 음성 입력을 획득할 수 있다. 또한, 사용자 입력 처리 모듈은, 제스처 입력, 터치 입력, 사용자의 또 다른 디바이스(예를 들어, 모바일 폰, 리모콘 등)를 통한 입력 등, 다양한 타입의 사용자 입력을 처리할 수 있다. 사용자 입력 처리 모듈의 동작에 관련된 전자 장치의 동작들은, 이전의 도면들에 서 상세하게 기술하였으므로 반복되는 설명은 생략한다.예를 들어, 프로세서는 기기 관리 모듈을 이용하여 복수의 기기들을 관리할 수 있다. 기기 관리 모 듈은 예를 들어, 기기에게 인터랙션을 위한 정보를 요청하고, 수신된 데이터를 데이터베이스에 저 장할 수 있다. 또는, 기기 관리 모듈은 기기에게 전송될 사용자 입력을 관리하거나, 기기를 제어하기 위 한 제어 명령을 관리하고, 기기로부터 수신되는 다양한 데이터를 관리할 수 있다. 기기 관리 모듈의 동작 에 관련된 전자 장치의 동작들은, 이전의 도면들에서 상세하게 기술하였으므로 반복되는 설명은 생략한다. 한편, 전술한 메모리에 저장된 모듈들은, 설명의 편의를 위한 것이며 반드시 이에 한정되는 것은 아니다. 전술한 실시예를 구현하기 위해 다른 모듈이 추가될 수 있으며, 전술한 모듈들 중 일부의 모듈들은 하나의 모듈 로 구현되거나, 전술한 모듈들 중 어느 한 모델은 복수의 모듈들로 분리되어 구현될 수도 있다. 일 실시예에서, 하나 이상의 프로세서는 CPU (Central Processing Unit), GPU (Graphics Processing Unit), APU (Accelerated Processing Unit), MIC (Many Integrated Core), DSP (Digital Signal Processor), 및 NPU (Neural Processing Unit) 중 적어도 하나를 포함할 수 있다. 하나 이상의 프로세서는, 하나 이 상의 전자부품을 포함하는 집적된 시스템 온 칩(SoC) 형태로 구현될 수 있다. 하나 이상의 프로세서 각각 은 별개의 하드웨어(H/W)로 구현될 수도 있다. 본 개시의 일 실시예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 프로세서에 의 해 수행될 수도 있고, 복수의 프로세서에 의해 수행될 수도 있다. 예를 들어, 일 실시예에 따른 방법에 의해 제1 동작, 제2 동작, 제3 동작이 수행될 때, 제1 동작, 제2 동작, 및 제3 동작 모두 제1 프로세서에 의해 수행될 수도 있고, 제1 동작 및 제2 동작은 제1 프로세서(예를 들어, 범용 프로세서)에 의해 수행되고 제3 동작 은 제2 프로세서(예를 들어, 인공지능 전용 프로세서)에 의해 수행될 수도 있다. 여기서, 제2 프로세서의 예시 는 인공지능 전용 프로세서일 수 있으며, 인공지능 전용 프로세서는, 인공지능 모델의 훈련/추론을 위한 연산들 이 수행될 수도 있다. 그러나, 본 개시의 실시예들이 이에 한정되는 것은 아니다. 본 개시에 따른 하나 이상의 프로세서는 싱글 코어 프로세서(single-core processor)로 구현될 수도 있고, 멀티 코어 프로세서(multi-core processor)로 구현될 수도 있다. 본 개시의 일 실시예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 코어에 의해 수행될 수도 있고, 하나 이상의 프로세서에 포함된 복수의 코어에 의해 수행될 수도 있다. 한편, 도 13에는 도시되지 않았으나, 전자 장치는 전술한 실시예에서 기술된 동작들을 수행하기 위해 추 가적인 구성들을 더 포함할 수 있다. 예를 들어, 전자 장치는 디스플레이, 카메라, 마이크, 입력/출력 인 터페이스 등을 더 포함할 수 있다. 도 14는 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 일 실시예에서, 전자 장치는 통신 인터페이스, 메모리, 프로세서, 디스플레이, 카메라, 비디오 처리 모듈, 오디오 처리 모듈, 전원 모듈, 입력/출력 인터페이스 를 포함할 수 있다. 도 14의 통신 인터페이스, 메모리 및 프로세서는, 도 13의 통신 인터페이스, 메모리 및 프로세서에 각각 대응하므로, 반복되는 설명은 생략한다. 디스플레이는 프로세서의 제어에 의해 전자 장치의 화면에 영상 신호를 출력할 수 있다. 예 를 들어, 전자 장치는 기기에 대응하는 아바타 및 사용자-기기 간 인터랙션을 위한 미디어 콘텐트를 디스 플레이를 통해 출력할 수 있다. 카메라는 공간 및/또는 객체, 사용자를 촬영하여 비디오 및/또는 이미지를 획득할 수 있다. 카메라(250 0)는 하나 이상일 수 있다. 카메라는 예를 들어, RGB 카메라, 깊이 카메라, 적외선 카메라 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 카메라를 이용하여 전자 장치를 이용하 는 사용자의 이미지들을 획득할 수 있다. 획득된 이미지들은 사용자의 시선 위치를 결정하는 데 이용될 수 있다. 전자 장치는 카메라를 공간 내 위치하는 기기들의 이미지들을 획득할 수 있다. 획득된 기기 들의 이미지들은 기기들의 공간 내 위치를 결정하는 데 이용될 수 있다. 카메라의 구체적인 종류 및 세부 기능은 통상의 기술자가 명확하게 추론할 수 있으므로, 설명을 생략한다. 비디오 처리 모듈은 전자 장치가 재생하는 비디오 데이터에 대한 처리를 수행한다. 비디오 처리 모 듈에서는 비디오 데이터에 대한 디코딩, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 해상도 변환, 렌더링 등과 같은 다양한 이미지 처리를 수행할 수 있다. 디스플레이는, 프로세서에서 처리된 영상 신호, 데이터 신호, OSD 신호, 제어 신호 등을 변환하여 구동 신호를 생성하고, 구동 신호에 따라 영상을 표시 할 수 있다. 오디오 처리 모듈은 오디오 데이터에 대한 처리를 수행한다. 오디오 처리 모듈에서는 오디오 데이 터에 대한 디코딩이나 증폭, 노이즈 필터링 등과 같은 다양한 처리가 수행될 수 있다. 전원 모듈은 프로세서의 제어에 의해 전자 장치 내부의 구성 요소들로 외부의 전원 소스에서 부터 입력되는 전원을 공급한다. 또한, 전원 모듈은 프로세서의 제어에 의해 전자 장치 내부 에 위치하는 하나 또는 둘 이상의 배터리(미도시)에서부터 출력되는 전원을 내부의 구성 요소들에게 공급할 수 있다. 입력/출력 인터페이스는 전자 장치의 외부에서부터 입력/출력을 처리한다. 비디오(예를 들어, 동영 상 등), 오디오(예를 들어, 음성, 음악 등) 및 부가 정보(예를 들어, EPG 등) 등을 수신한다. 입력/출력 인터페 이스는 USB(Universal Serial Bus), HDMI (High-Definition Multimedia Interface), MHL(Mobile High- Definition Link),DP(Display Port), 썬더볼트(Thunderbolt), VGA(Video Graphics Array) 포트, RGB 포트, D- SUB(D-subminiature), DVI(Digital Visual Interface), 컴포넌트 잭(component jack), PC 포트(PC port), 오 디오 잭 중 어느 하나를 포함할 수 있다. 즉, 입력/출력 인터페이스는 전술한 입력/출력 방식들을 구현하 기 위한 복수의 모듈들(예를 들어, USB 포트, HDMI 포트 등)을 포함하도록 구현될 수 있다. 전자 장치는 입력/출력 인터페이스를 통해 디스플레이, 카메라, 마이크, 스피커, 터치 패드 등의 외부 장치들과 연결 될 수 있다. 본 개시는, 사용자가 복수의 기기들과 인터랙션 할 수 있도록 하기 위해, 인터랙션 편의를 제공하는 인터랙션 허브 역할을 수행하는 전자 장치 및 그 동작 방법을 제시한다. 본 개시에서 이루고자 하는 기술적 과제는, 이상 에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 본 명세서의 기재로부터 본 발명"}
{"patent_id": "10-2023-0123324", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다. 본 개시의 일 측면에 따르면, 전자 장치가 사용자-클라이언트 간 인터랙션을 제공하는 방법이 제공될 수 있다. 상기 방법은, 복수의 기기들의 상태 관련 정보 및 상기 복수의 기기들의 이벤트에 대응하는 미디어 관련 정보를 상기 복수의 기기들에게 요청하는 단계를 포함할 수 있다. 상기 방법은, 제1 사용자 입력에 기초하여, 상기 복수의 기기들 중에서 선택된 기기에 대응하는 상기 상태 관련 정보 및 상기 미디어 관련 정보 중 적어도 하나를 출력하는 단계를 포함할 수 있다. 상기 방법은, 제2 사용자 입력에 대응하는 신호를 상기 선택된 기기로 전송하는 단계를 포함할 수 있다. 상기 방법은, 상기 선택된 기기로부터 수신된 상기 제2 사용자 입력에 대응하는 응답을 출력하는 단계를 포함할 수 있다. 상기 방법은, 상기 복수의 기기들에 대응하는 아바타들 중 적어도 하나를 화면에 표시하는 단계를 포함할 수 있 다. 상기 방법은, 상기 아바타들 중에서, 상기 제1 사용자 입력에 대응하는 기기의 아바타에 관련된 정보를 획득하 는 단계를 포함할 수 있다. 상기 방법은, 상기 복수의 기기들에 대응하는 아바타들의 미디어 관련 정보를 상기 복수의 기기들로부터 획득하 는 단계를 포함할 수 있다. 상기 상태 관련 정보 및 상기 미디어 관련 정보 중 적어도 하나를 출력하는 단계는, 상기 상태 관련 정보 및 상 기 미디어 관련 정보 중 적어도 하나를 상기 제1 사용자 입력에 대응하는 기기의 아바타와 함께 상기 화면에 표 시하는 것일 수 있다. 상기 방법은, 상기 사용자에 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 이미지에 기초하여 상기 화면에 대한 상기 사용자의 시선에 대응하는 아바타를 식별하는 단 계를 포함할 수 있다. 상기 방법은, 상기 시선에 대응하는 상기 아바타가 식별되면, 상기 식별된 아바타가 다른 아바타와 구별되도록 표시하는 단계를 포함할 수 있다.상기 방법은, 복수의 기기들의 위치 정보를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 위치 정보에 기초하여, 상기 복수의 기기들에 대응하는 아바타들이 상기 화면에 표시될 위치 들을 변경하여 표시하는 단계를 포함할 수 있다. 상기 방법은, 화면 컨텍스트 정보를 획득하는 단계를 포함할 수 있다. 상기 복수의 기기들에 대응하는 아바타들 중 적어도 하나를 화면에 표시하는 단계는, 상기 화면 컨텍스트 정보 에 기초하여, 상기 아바타들의 크기 및 위치 중 적어도 하나를 변경하여 표시하는 단계를 포함할 수 있다. 상기 복수의 기기들에 대응하는 아바타들 중 적어도 하나를 화면에 표시하는 단계는, 상기 아바타들의 크기 및 위치에 기초하여 화면 레이아웃을 변경하여 표시하는 단계를 포함할 수 있다. 상기 방법은, 상기 선택된 기기를 동작시키기 위한 제어 명령을 상기 선택된 기기로 전송하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 사용자-클라이언트 간 인터랙션을 제공하는 전자 장치가 제공될 수 있다. 상기 전자 장치는, 통신 인터페이스; 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 메모리에 저장된 상 기 하나 이상의 인스트럭션을 실행하는 하나 이상의 프로세서를 포함할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 복수의 기기들의 상태 관련 정보 및 상기 복수의 기기들의 이벤트에 대응하는 미디어 관련 정보를 상기 복수의 기기들에게 요청할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 제1 사용자 입력에 기초하여, 상 기 복수의 기기들 중에서 선택된 기기에 대응하는 상기 상태 관련 정보 및 상기 미디어 관련 정보 중 적어도 하 나를 출력할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 제2 사용자 입력에 대응하는 신호 를 상기 선택된 기기로 전송할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 선택된 기기로부터 수신된 상기 제2 사용자 입력에 대응하는 응답을 출력할 수 있다. 상기 전자 장치는, 디스플레이를 더 포함할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 복수의 기기들에 대응하는 아바타들 중 적어도 하나를 상기 디스플레이의 화면에 표시하도록 상기 디스플레이를 제어할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 아바타들 중에서, 상기 제1 사용자 입력에 대응하는 기기의 아바타에 관련된 정보를 획득할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 복수의 기기들에 대응하는 아바타들의 미디어 관련 정보를 상기 복수의 기기들로부터 획득할 수 있다. 상기 하나 이상의 프로세서는, 상기 디스플레이를 제어하여, 상기 하나 이상의 인스트럭션을 실행함으로써, 상 기 상태 관련 정보 및 상기 미디어 관련 정보 중 적어도 하나를 상기 제1 사용자 입력에 대응하는 기기의 아바 타와 함께 상기 화면에 표시할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 사용자에 대응하는 이미지를 획득할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 이미지에 기초하여 상기 화 면에 대한 상기 사용자의 시선에 대응하는 아바타를 식별할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 시선에 대응하는 상기 아바 타가 식별되면, 상기 식별된 아바타가 다른 아바타와 구별되도록 변경할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 디스플레이를 제어하여, 상 기 다른 아바타와 구별되도록 변경된 아바타를 상기 화면에 표시할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 복수의 기기들의 위치 정보를 획 득할 수 있다.상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 위치 정보에 기초하여, 상기 복수의 기기들에 대응하는 아바타들이 상기 화면에 표시될 위치들을 변경할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 디스플레이를 제어하여, 상 기 위치들이 변경된 아바타들을 상기 화면에 표시할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 화면 컨텍스트 정보를 획득할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 화면 컨텍스트 정보에 기초 하여, 상기 아바타들의 크기 및 위치 중 적어도 하나를 변경할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 디스플레이를 제어하여, 상 기 크기 및 위치 중 적어도 하나가 변경된 아바타를 상기 화면에 표시할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 아바타들의 크기 및 위치에 기초하여 화면 레이아웃을 변경할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 디스플레이를 제어하여, 상 기 변경된 화면 레이아웃을 상기 화면에 표시할 수 있다. 상기 하나 이상의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 선택된 기기를 동작시키기 위한 제어 명령을 상기 선택된 기기로 전송할 수 있다. 한편, 본 개시의 실시예들은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어 를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨 터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가 능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2023-0123324", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7a 도면7b 도면7c 도면7d 도면8a 도면8b 도면9a 도면9b 도면9c 도면10 도면11a 도면11b 도면12 도면13 도면14"}
{"patent_id": "10-2023-0123324", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 시스템을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도 면이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치가 기기로부터 획득하는 인터랙션을 위한 정보를 설명하기 위한 도면이다. 도 4는 본 개의 일 실시예에 따른 전자 장치가 복수의 클라이언트들에 대응하는 아바타를 표시하는 동작을 설명 하기 위한 도면이다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 아바타를 이용하여 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 기기와 데이터를 송수신하는 동작을 설명하기 위한 도면이다. 도 7a는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도면이다. 도 7b는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도면이다. 도 7c는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도면이다. 도 7d는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 인터랙션을 제공하는 동작을 설명하기 위한 도면이다. 도 8a는 본 개시의 일 실시예에 따른 전자 장치가 기기들의 위치를 획득하는 동작을 설명하기 위한 도면이다. 도 8b는 본 개시의 일 실시예에 따른 전자 장치가 기기들의 위치를 획득하는 동작을 설명하기 위한 도면이다. 도 9a는 본 개시의 일 실시예에 따른 전자 장치가 기기의 아바타를 표시하는 동작을 설명하기 위한 도면이다. 도 9b는 본 개시의 일 실시예에 따른 전자 장치가 기기의 아바타를 표시하는 동작을 설명하기 위한 도면이다. 도 9c는 본 개시의 일 실시예에 따른 전자 장치가 기기의 아바타를 표시하는 동작을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 기기의 아바타를 표시하는 동작을 설명하기 위한 도면이다. 도 11a는 본 개시의 일 실시예에 따른 전자 장치가 기기와 데이터를 송수신하는 동작을 설명하기 위한 도면이다. 도 11b는 본 개시의 일 실시예에 따른 전자 장치가 사용자-기기 간 와 데이터를 송수신하는 동작을 설명하기 위 한 도면이다. 도 12는 본 개시의 일 실시예에 따른 전자 장치가 또 다른 전자 장치와 데이터를 송수신하는 동작을 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 14는 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다."}
