{"patent_id": "10-2022-0073499", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0172834", "출원번호": "10-2022-0073499", "발명의 명칭": "다중 교통 표지를 사용한 센서 캘리브레이션 장치 및 방법", "출원인": "엘아이지넥스원 주식회사", "발명자": "명현"}}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "센서 캘리브레이션 방법에 있어서,영상 센서를 통해 제1 교통 표지를 촬영하여 2차원 이미지를 획득하는 단계;라이다 센서를 통해 상기 제1 교통 표지에 무선 신호를 송수신하여 3차원 포인트 클라우드를 획득하는 단계;상기 2차원 이미지로부터 교통 표지 추출 모델을 이용하여 교통 표지 영역을 추출하는 단계;상기 3차원 포인트 클라우드로부터 상기 3차원 교통 표지 데이터를 인식하고 2차원 교통 표지 데이터로 변환하는 단계;상기 교통 표지 영역에서 추출한 제1 코너 데이터, 상기 2차원 교통 표지 데이터에서 추출한 제2 코너 데이터,상기 제2 코너 데이터를 3차원 공간에 투영한 제3 코너 데이터, 상기 제2 코너 데이터를 2차원 평면에 투영한제4 코너 데이터를 이용하여 상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 단계를 포함하는 센서 캘리브레이션 방법."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 교통 표지 영역을 추출하는 단계는,상기 교통 표지 추출 모델로 네트워크의 최종 출력단에서 경계박스 위치 찾기와 클래스 분류가 동시에 이뤄지는모델을 구축하고,실시간 획득된 상기 2차원 이미지의 사이즈를 조정하여 상기 교통 표지 추출 모델에 입력하여 특징을 추출한 후박스 형태의 후보 영역을 추출하고,상기 박스 형태의 후보 영역에서 에지 감지 및 색상 임계치를 이용하여 상기 교통 표지 영역을 추출하는 것을특징으로 하는 센서 캘리브레이션 방법."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 2차원 교통 표지 데이터로 변환하는 단계는,상기 라이더 센서를 중심으로 하는 전역 좌표계에서 상기 3차원 포인트 클라우드를 기준 임계치까지 축적하고,상기 축적된 3차원 포인트 클라우드를 기준 복셀 그리드에 따라 샘플링하여 복셀화를 수행하고,상기 복셀화된 3차원 포인트 클라우드를 기준 세기에 따라 필터링하고,상기 필터링된 3차원 포인트 클라우드를 기준 근접 거리에 따라 클러스터링하고,상기 클러스터링된 3차원 포인트 클라우드에 무작위 샘플 데이터의 최대 지지를 받는 모델을 선택하는 영상 처리 방식 및 평면 투영 방식을 적용하여 2차원 평면에 피팅하는 것을 특징으로 하는 센서 캘리브레이션 방법."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 단계는,상기 제1 코너 데이터에 따른 모서리의 기울기 및 상기 제3 코너 데이터에 따른 모서리의 기울기를 비교하여 상기 3차원 공간에서 상기 제1 교통 표지에 대한 제1 법선 벡터를 산출하고,공개특허 10-2023-0172834-3-상기 제1 교통 표지에 대한 상기 제1 법선 벡터 및 제2 교통 표지에 대한 제2 법선 벡터를 비교하여 상기 영상센서의 회전 교정값을 추정하는 것을 특징으로 하는 센서 캘리브레이션 방법."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 단계는,상기 제1 코너 데이터 및 상기 제4 코너 데이터를 비교하여 상기 제1 교통 표지에 대한 상기 영상 센서의 제1위치 데이터를 산출하고,상기 제1 교통 표지에 대한 상기 영상 센서의 제1 위치 데이터 및 제2 교통 표지에 대한 상기 영상 센서의 제2위치 데이터를 비교하여 상기 영상 센서의 위치 교정값을 추정하는 것을 특징으로 하는 센서 캘리브레이션방법."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 단계 이후에상기 영상 센서 및 상기 라이다 센서가 제3 교통 표지를 검출하면, 상기 제1 교통 표지 및 제2 교통 표지를 기반으로 추정한 상기 영상 센서의 교정값을 상기 제2 교통 표지 및 상기 제3 교통 표지를 기반으로 다시 추정하여 상기 교정값을 업데이트하는 단계를 포함하는 것을 특징으로 하는 센서 캘리브레이션 방법."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "프로세서를 포함하는 센서 캘리브레이션 장치에 있어서,상기 프로세서는,영상 센서를 통해 제1 교통 표지를 촬영하여 획득한 2차원 이미지를 수신하고,라이다 센서를 통해 상기 제1 교통 표지에 무선 신호를 송수신하여 획득한 3차원 포인트 클라우드를 수신하고,상기 2차원 이미지로부터 교통 표지 추출 모델을 이용하여 교통 표지 영역을 추출하고,상기 3차원 포인트 클라우드로부터 상기 3차원 교통 표지 데이터를 인식하고 2차원 교통 표지 데이터로 변환하고,상기 교통 표지 영역에서 추출한 제1 코너 데이터, 상기 2차원 교통 표지 데이터에서 추출한 제2 코너 데이터,상기 제2 코너 데이터를 3차원 공간에 투영한 제3 코너 데이터, 상기 제2 코너 데이터를 2차원 평면에 투영한제4 코너 데이터를 이용하여 상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 것을 특징으로 하는센서 캘리브레이션 장치."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는,상기 교통 표지 추출 모델로 네트워크의 최종 출력단에서 경계박스 위치 찾기와 클래스 분류가 동시에 이뤄지는모델을 구축하고,실시간 획득된 상기 2차원 이미지의 사이즈를 조정하여 상기 교통 표지 추출 모델에 입력하여 특징을 추출한 후박스 형태의 후보을 추출하고,상기 박스 형태의 후보 영역에서 에지 감지 및 색상 임계치를 이용하여 상기 교통 표지 영역을 추출하는 것을특징으로 하는 센서 캘리브레이션 장치."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2023-0172834-4-제7항에 있어서,상기 프로세서는,상기 라이더 센서를 중심으로 하는 전역 좌표계에서 상기 3차원 포인트 클라우드를 기준 임계치까지 축적하고,상기 축적된 3차원 포인트 클라우드를 기준 복셀 그리드에 따라 샘플링하여 복셀화를 수행하고,상기 복셀화된 3차원 포인트 클라우드를 기준 세기에 따라 필터링하고,상기 필터링된 3차원 포인트 클라우드를 기준 근접 거리에 따라 클러스터링하고,상기 클러스터링된 3차원 포인트 클라우드에 무작위 샘플 데이터의 최대 지지를 받는 모델을 선택하는 영상 처리 방식 및 평면 투영 방식을 적용하여 2차원 평면에 피팅하여, 상기 2차원 교통 표지 데이터로 변환하는 것을특징으로 하는 센서 캘리브레이션 장치."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 프로세서는,상기 제1 코너 데이터에 따른 모서리의 기울기 및 상기 제3 코너 데이터에 따른 모서리의 기울기를 비교하여 상기 3차원 공간에서 상기 제1 교통 표지에 대한 제1 법선 벡터를 산출하고,상기 제1 교통 표지에 대한 상기 제1 법선 벡터 및 제2 교통 표지에 대한 제2 법선 벡터를 비교하여 상기 영상센서의 회전 교정값을 추정하는 것을 특징으로 하는 센서 캘리브레이션 장치."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 프로세서는,상기 제1 코너 데이터 및 상기 제4 코너 데이터를 비교하여 상기 제1 교통 표지에 대한 상기 영상 센서의 제1위치 데이터를 산출하고,상기 제1 교통 표지에 대한 상기 영상 센서의 제1 위치 데이터 및 제2 교통 표지에 대한 상기 영상 센서의 제2위치 데이터를 비교하여 상기 영상 센서의 위치 교정값을 추정하는 것을 특징으로 하는 센서 캘리브레이션장치."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,상기 프로세서는,상기 영상 센서 및 상기 라이다 센서가 제3 교통 표지를 검출하면, 상기 제1 교통 표지 및 제2 교통 표지를 기반으로 추정한 상기 영상 센서의 교정값을 상기 제2 교통 표지 및 상기 제3 교통 표지를 기반으로 다시 추정하여 상기 교정값을 업데이트하는 것을 특징으로 하는 센서 캘리브레이션 장치."}
{"patent_id": "10-2022-0073499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "이동체에 있어서,제1 교통 표지를 촬영하여 2차원 이미지를 획득하는 영상 센서;상기 제1 교통 표지에 무선 신호를 송수신하여 3차원 포인트 클라우드를 획득하는 라이다 센서;상기 영상 센서 및 상기 라이다 센서에 연결되어 상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는센서 캘리브레이션 장치; 및상기 센서 캘리브레이션 장치의 출력 결과를 기반으로 이동 계획을 갱신하고 이동을 수행하는 주행 수단을 포함하며,공개특허 10-2023-0172834-5-상기 센서 캘리브레이션 장치는,상기 2차원 이미지로부터 교통 표지 추출 모델을 이용하여 교통 표지 영역을 추출하고,상기 3차원 포인트 클라우드로부터 상기 3차원 교통 표지 데이터를 인식하고 2차원 교통 표지 데이터로 변환하고,상기 교통 표지 영역에서 추출한 제1 코너 데이터, 상기 2차원 교통 표지 데이터에서 추출한 제2 코너 데이터,상기 제2 코너 데이터를 3차원 공간에 투영한 제3 코너 데이터, 상기 제2 코너 데이터를 2차원 평면에 투영한제4 코너 데이터를 이용하여 상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 것을 특징으로 하는이동체."}
{"patent_id": "10-2022-0073499", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 실시예들은 도로를 이동 중인 자율 주행 차량 또는 지상 이동 로봇에서 주변 물체 인식에 필수적인 라이다 센 서 및 영상 센서의 정밀한 캘리브레이션을 교통 표지판을 사용하여 추정 및 업데이트하며, 별도의 캘리브레이션 보드를 사용할 필요 없고 주행 중에 계산 가능한 방법으로 손쉽게 정밀한 센서 융합 결과를 확인하고, 초기 센서 위치 데이터 없이 초기값을 추정하고 캘리브레이션 값을 업데이트할 수 있는 센서 캘리브레이션 장치 및 방법을 제공한다."}
{"patent_id": "10-2022-0073499", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명이 속하는 기술 분야는 다중 교통 표지를 사용하여 라이다 센서를 기반으로 영상 센서를 캘리브레이션 하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0073499", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 실시예에 대한 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아니다. 자율 주행 차량에서 카메라와 라이다를 같이 사용하고 있고, 도로와 인도를 포함한 다양한 환경을 오가는 배송 로봇에서도 카메라와 라이다를 모두 사용하고 있다. 이종 센서 간의 정밀한 융합을 위해서는 정밀한 외부 캘리 브레이션 값 추정이 필수적이고 중요하다. 대부분의 기술은 매번 별도의 캘리브레이션 보드로 캘리브레이션을 진행해야 하는 어려움이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허공보 제10-2021-0078439호 (2021.06.28)"}
{"patent_id": "10-2022-0073499", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들은 도로를 이동 중인 자율 주행 차량 또는 지상 이동 로봇에서 주변 물체 인식에 필수적인 라이다 센서 및 영상 센서의 정밀한 캘리브레이션을 교통 표지판을 사용하여 추정 및 업데이트하며, 별도의 캘 리브레이션 보드를 사용할 필요 없고 주행 중에 계산 가능한 방법으로 손쉽게 정밀한 센서 융합 결과를 확인하 고, 초기 센서 위치 데이터 없이 초기값을 추정하고 캘리브레이션 값을 업데이트하는데 주된 목적이 있다. 본 발명의 명시되지 않은 또 다른 목적들은 하기의 상세한 설명 및 그 효과로부터 용이하게 추론할 수 있는 범 위 내에서 추가적으로 고려될 수 있다."}
{"patent_id": "10-2022-0073499", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 실시예의 일 측면에 의하면 센서 캘리브레이션 방법에 있어서, 영상 센서를 통해 제1 교통 표지를 촬영하여 2차원 이미지를 획득하는 단계; 라이다 센서를 통해 상기 제1 교통 표지에 무선 신호를 송수신하여 3차원 포인 트 클라우드를 획득하는 단계; 상기 2차원 이미지로부터 교통 표지 추출 모델을 이용하여 교통 표지 영역을 추 출하는 단계; 상기 3차원 포인트 클라우드로부터 상기 3차원 교통 표지 데이터를 인식하고 2차원 교통 표지 데 이터로 변환하는 단계; 상기 교통 표지 영역에서 추출한 제1 코너 데이터, 상기 2차원 교통 표지 데이터에서 추 출한 제2 코너 데이터, 상기 제2 코너 데이터를 3차원 공간에 투영한 제3 코너 데이터, 상기 제2 코너 데이터를 2차원 평면에 투영한 제4 코너 데이터를 이용하여 상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하 는 단계를 포함하는 센서 캘리브레이션 방법을 제공한다.상기 교통 표지 영역을 추출하는 단계는, 상기 교통 표지 추출 모델로 네트워크의 최종 출력단에서 경계박스 위 치 찾기와 클래스 분류가 동시에 이뤄지는 모델을 구축하고, 실시간 획득된 상기 2차원 이미지의 사이즈를 조정 하여 상기 교통 표지 추출 모델에 입력하여 특징을 추출한 후 박스 형태의 후보 영역을 추출하고, 상기 박스 형 태의 후보 영역에서 에지 감지 및 색상 임계치를 이용하여 상기 교통 표지 영역을 추출할 수 있다. 상기 2차원 교통 표지 데이터로 변환하는 단계는, 상기 라이더 센서를 중심으로 하는 전역 좌표계에서 상기 3차 원 포인트 클라우드를 기준 임계치까지 축적하고, 상기 축적된 3차원 포인트 클라우드를 기준 복셀 그리드에 따 라 샘플링하여 복셀화를 수행하고, 상기 복셀화된 3차원 포인트 클라우드를 기준 세기에 따라 필터링하고, 상기 필터링된 3차원 포인트 클라우드를 기준 근접 거리에 따라 클러스터링하고, 상기 클러스터링된 3차원 포인트 클 라우드에 무작위 샘플 데이터의 최대 지지를 받는 모델을 선택하는 영상 처리 방식 및 평면 투영 방식을 적용하 여 2차원 평면에 피팅할 수 있다. 상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 단계는, 상기 제1 코너 데이터에 따른 모서리의 기울기 및 상기 제3 코너 데이터에 따른 모서리의 기울기를 비교하여 상기 3차원 공간에서 상기 제1 교통 표지 에 대한 제1 법선 벡터를 산출하고, 상기 제1 교통 표지에 대한 상기 제1 법선 벡터 및 제2 교통 표지에 대한 제2 법선 벡터를 비교하여 상기 영상 센서의 회전 교정값을 추정할 수 있다. 상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 단계는, 상기 제1 코너 데이터 및 상기 제4 코너 데이터를 비교하여 상기 제1 교통 표지에 대한 상기 영상 센서의 제1 위치 데이터를 산출하고, 상기 제1 교통 표지에 대한 상기 영상 센서의 제1 위치 데이터 및 제2 교통 표지에 대한 상기 영상 센서의 제2 위치 데이터를 비교하여 상기 영상 센서의 위치 교정값을 추정할 수 있다. 상기 센서 캘리브레이션 방법은, 상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 단계 이후에, 상기 영상 센서 및 상기 라이다 센서가 제3 교통 표지를 검출하면, 상기 제1 교통 표지 및 제2 교통 표지를 기 반으로 추정한 상기 영상 센서의 교정값을 상기 제2 교통 표지 및 상기 제3 교통 표지를 기반으로 다시 추정하 여 상기 교정값을 업데이트하는 단계를 포함할 수 있다. 본 실시예의 다른 측면에 의하면 프로세서를 포함하는 센서 캘리브레이션 장치에 있어서, 상기 프로세서는, 영 상 센서를 통해 제1 교통 표지를 촬영하여 획득한 2차원 이미지를 수신하고, 라이다 센서를 통해 상기 제1 교통 표지에 무선 신호를 송수신하여 획득한 3차원 포인트 클라우드를 수신하고, 상기 2차원 이미지로부터 교통 표지 추출 모델을 이용하여 교통 표지 영역을 추출하고, 상기 3차원 포인트 클라우드로부터 상기 3차원 교통 표지 데 이터를 인식하고 2차원 교통 표지 데이터로 변환하고, 상기 교통 표지 영역에서 추출한 제1 코너 데이터, 상기 2차원 교통 표지 데이터에서 추출한 제2 코너 데이터, 상기 제2 코너 데이터를 3차원 공간에 투영한 제3 코너 데이터, 상기 제2 코너 데이터를 2차원 평면에 투영한 제4 코너 데이터를 이용하여 상기 라이다 센서 기반한 상 기 영상 센서의 교정값을 추정하는 것을 특징으로 하는 센서 캘리브레이션 장치를 제공한다. 본 실시예의 또 다른 측면에 의하면 이동체에 있어서, 제1 교통 표지를 촬영하여 2차원 이미지를 획득하는 영상 센서; 상기 제1 교통 표지에 무선 신호를 송수신하여 3차원 포인트 클라우드를 획득하는 라이다 센서; 상기 영 상 센서 및 상기 라이다 센서에 연결되어 상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 센서 캘리브레이션 장치; 및 상기 센서 캘리브레이션 장치의 출력 결과를 기반으로 이동 계획을 갱신하고 이동을 수 행하는 주행 수단을 포함하며, 상기 센서 캘리브레이션 장치는, 상기 2차원 이미지로부터 교통 표지 추출 모델 을 이용하여 교통 표지 영역을 추출하고, 상기 3차원 포인트 클라우드로부터 상기 3차원 교통 표지 데이터를 인 식하고 2차원 교통 표지 데이터로 변환하고, 상기 교통 표지 영역에서 추출한 제1 코너 데이터, 상기 2차원 교 통 표지 데이터에서 추출한 제2 코너 데이터, 상기 제2 코너 데이터를 3차원 공간에 투영한 제3 코너 데이터, 상기 제2 코너 데이터를 2차원 평면에 투영한 제4 코너 데이터를 이용하여 상기 라이다 센서 기반한 상기 영상 센서의 교정값을 추정하는 것을 특징으로 하는 이동체를 제공한다."}
{"patent_id": "10-2022-0073499", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이 본 발명의 실시예들에 의하면, 도로를 이동 중인 자율 주행 차량 또는 지상 이동 로 봇에서 주변 물체 인식에 필수적인 라이다 센서 및 영상 센서의 정밀한 캘리브레이션을 교통 표지판을 사용하여 추정 및 업데이트하며, 별도의 캘리브레이션 보드를 사용할 필요 없고 주행 중에 계산 가능한 방법으로 손쉽게 정밀한 센서 융합 결과를 확인하고, 초기 센서 위치 데이터 없이 초기값을 추정하고 캘리브레이션 값을 업데이 트할 수 있는 효과가 있다. 또한, 기존 시스템의 변경을 최소화하면서, 새로운 인공지능 시스템을 탑재할 수 있다. 왜냐하면, 통제명령(T C)과 상태정보(TM)가 유통되는 외부 인터페이스를 기반으로 기존 시스템과 인공지능 시스템이 통합되기 때문이 다. 타 구성품의 내부나 인터페이스(전기적 인터페이스와 논리적 인터페이스) 변경이 필요하지 않다. 기존의 시 스템을 변경없이 재사용하기 때문에 인증 및 시험의 소요가 상대적으로 적고, 안정성을 확보할 수 있다. 인공지 능 시스템 내부를 모듈형으로 구성하여, 향후의 성능개량, 유지보수를 할 수 있다. 여기에서 명시적으로 언급되지 않은 효과라 하더라도, 본 발명의 기술적 특징에 의해 기대되는 이하의 명세서에 서 기재된 효과 및 그 잠정적인 효과는 본 발명의 명세서에 기재된 것과 같이 취급된다."}
{"patent_id": "10-2022-0073499", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명을 설명함에 있어서 관련된 공지기능에 대하여 이 분야의 기술자에게 자명한 사항으로서 본 발명 의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하고, 본 발명의 일부 실시예들 을 예시적인 도면을 통해 상세하게 설명한다. 영상 센서(예컨대, 카메라)와 라이다 센서는 자율 주행 차량을 비롯한 다양한 종류의 로봇이 주변 환경을 인식 하도록 지원한다. 영상 센서는 라이다 센서가 제공하는 깊이 정보가 없고, 라이다 센서는 영상 센서가 제공하는 색상, 질감 및 모양 정보가 없기 때문에 두 가지 감지 방식을 결합한 시스템은 각각의 장점을 사용하여 서로의 단점을 보완할 수 있다. 주면 물체 인식, SLAM을 포함한 매핑 및 위치 인식을 보다 정확하고 다양한 상황에서 성능을 유지하기 위해서는 두 센서의 정밀한 융합이 필요하다. 외적 요인에 의해 운행 중 또는 유지 관리 중에 미세하게 센서 시스템의 위치와 자세가 변할 수 있다. 정밀한 다중 센서 융합을 위해서는 센서 간의 정밀한 외 부 교정이 필요하다. 영상 센서(예컨대, 카메라)와 라이다 센서 간의 캘리브레이션은 대상 기반 유형 및 대상 없는 유형으로 구분된 다. 대상 기반 접근 방식은 보드를 이용한 방식으로 다각형 평면 보드, 상자, 바둑판 패턴 또는 단순한 인쇄된 원과 같이 지정된 크기를 갖는 특수 보정 대상을 사용한다. 대상 없는(Target-less) 방식은 자연 환경을 직접 관찰하여 대응 계산을 위한 특징을 추출하므로 특수하게 설치하거나 특수 제작한 보정 대상이 필요하지 않다. 타겟을 사용하지 않는 방식은 운행 중 주변 환경 특징을 사용한다. 이러한 방법의 정확도는 일반적으로 주변 환 경 특징을 특징을 감지하는 것이 상당히 어렵기 때문에 대상 기반의 방식보다 낮다. 초기에 정밀하게 캘리브레 이션된 시스템이라도 도로의 진동과 외부의 요인으로 인해 센서 간의 위치 정보에 오차가 생길 수 있고 유지 보 수를 위해 손쉬우면서도 정밀한 재보정이 필수적이다. 본 실시예는 복잡한 오프라인 재보정 프로세스를 피하기 위해 모든 도시 환경에서 활용 가능한 라이다 및 영상 센서의 정밀한 자동 캘리브레이션을 제공하며, 움직이는 차량에서 다중 교통 표지를 사용하는 영상 센서와 라이 다 센서에 대한 외부 보정 알고리즘을 제공한다. 본 실시예는 영상 센서와 라이다 센서를 사용하여 교통 표지판을 정확하게 추출하고, 추출된 표지판의 법선 벡 터를 사용하여 두 센서의 정확한 외부 캘리브레이션을 추정한다.도 1은 본 발명의 일 실시예에 따른 이동체를 예시한 블록도이다. 이동체는 영상 센서, 라이다 센서, 센서 캘리브레이션 장치, 주행 수단을 포함한다. 이동체 는 일반 자동차, 자율 주행차, 이동 로봇 등을 포함하는 개념이다. 영상 센서 및 라이다 센서는 이동체의 전방 상단에 장착될 수 있으며, 측면이나 후방에도 장착될 수 있 다. 영상 센서 및 라이다 센서는 대부분의 자율 주행 차량에서 사용하는 위치에 설치될 수 있다. 영상 센서는 주변환경을 촬영하여 2차원 이미지를 획득한다. 라이다 센서는 주변환경에 무선 신호를 송수신하여 3차원 포인트 클라우드를 획득한다. 센서 캘리브레이션 장치는 2차원 이미지로부터 교통 표지 추출 모델을 이용하여 교통 표지 영역을 추출하 고, 3차원 포인트 클라우드로부터 3차원 교통 표지 데이터를 인식하고 2차원 교통 표지 데이터로 변환한다. 센서 캘리브레이션 장치는 교통 표지 영역에서 추출한 제1 코너 데이터, 2차원 교통 표지 데이터에서 추출 한 제2 코너 데이터, 제2 코너 데이터를 3차원 공간에 투영한 제3 코너 데이터, 제2 코너 데이터를 2차원 평면 에 투영한 제4 코너 데이터를 이용하여 라이다 센서 기반한 영상 센서의 교정값을 추정한다. 주행 수단은 센서 캘리브레이션 장치의 출력 결과를 기반으로 이동 계획을 갱신하고 이동을 수행한다. 주 행 수단은 바퀴, 로봇 다리, 체인, 선로 등을 통해 이동 가능하도록 구현된 장치이다. 산출된 주행 경로를 따라 자동으로 이동시키거나 조작 등을 통해 수동으로 이동시킬 수도 있다. 도 2는 본 발명의 다른 실시예에 따른 센서 캘리브레이션 장치를 예시한 블록도이다. 센서 캘리브레이션 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능한 저장매체 및 통신 버스 를 포함한다. 프로세서는 센서 캘리브레이션 장치로 동작하도록 제어할 수 있다. 예컨대, 프로세서는 컴퓨터 판독 가능한 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있다. 하나 이상의 프로그램들은 하 나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 컴퓨터 실행 가능 명령어는 프로세서에 의해 실 행되는 경우 센서 캘리브레이션 장치로 하여금 예시적인 실시예에 따른 동작들을 수행하도록 구성될 수 있 다. 컴퓨터 판독 가능한 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이 터 및/또는 다른 적합한 형태의 정보는 입출력 인터페이스나 통신 인터페이스를 통해서도 주어질 수 있다. 컴퓨터 판독 가능한 저장 매체에 저장된 프로그램은 프로세서에 의해 실행 가능한 명령어 의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능한 저장 매체는 메모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 센서 캘리브레이션 장치에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능한 저장 매체를 포함하여 센서 캘리브레이션 장치(11 0)의 다른 다양한 컴포넌트들을 상호 연결한다. 센서 캘리브레이션 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출 력 인터페이스 및 하나 이상의 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치(미도시)는 입출력 인터페이스를 통해 센서 캘 리브레이션 장치의 다른 컴포넌트들에 연결될 수 있다. 프로세서는 영상 센서를 통해 제1 교통 표지를 촬영하여 획득한 2차원 이미지를 수신하고, 라이다 센서를 통해 제1 교통 표지에 무선 신호를 송수신하여 획득한 3차원 포인트 클라우드를 수신하고, 2차원 이미지로부터 교통 표지 추출 모델을 이용하여 교통 표지 영역을 추출하고, 3차원 포인트 클라우드로부터 3차원 교통 표지 데이터 를 인식하고 2차원 교통 표지 데이터로 변환한다. 프로세서는 교통 표지 영역에서 추출한 제1 코너 데이터, 2차원 교통 표지 데이터에서 추출한 제2 코너 데이터, 제2 코너 데이터를 3차원 공간에 투영한 제3 코너 데이터, 제2 코너 데이터를 2차원 평면에 투영한 제4 코너 데 이터를 이용하여 라이다 센서 기반한 영상 센서의 교정값을 추정한다.프로세서는 교통 표지 추출 모델로 네트워크의 최종 출력단에서 경계박스 위치 찾기와 클래스 분류가 동시에 이 뤄지는 모델을 구축하고, 실시간 획득된 2차원 이미지의 사이즈를 조정하여 교통 표지 추출 모델에 입력하여 특 징을 추출한 후 박스 형태의 후보을 추출하고, 박스 형태의 후보 영역에서 에지 감지 및 색상 임계치를 이용하 여 교통 표지 영역을 추출한다. 프로세서는 라이더 센서를 중심으로 하는 전역 좌표계에서 3차원 포인트 클라우드를 기준 임계치까지 축적하고, 축적된 3차원 포인트 클라우드를 기준 복셀 그리드에 따라 샘플링하여 복셀화를 수행하고, 복셀화된 3차원 포인 트 클라우드를 기준 세기에 따라 필터링하고, 필터링된 3차원 포인트 클라우드를 기준 근접 거리에 따라 클러스 터링하고, 클러스터링된 3차원 포인트 클라우드에 무작위 샘플 데이터의 최대 지지를 받는 모델을 선택하는 영 상 처리 방식 및 평면 투영 방식을 적용하여 2차원 평면에 피팅하여, 2차원 교통 표지 데이터로 변환한다. 프로세서는 제1 코너 데이터에 따른 모서리의 기울기 및 제3 코너 데이터에 따른 모서리의 기울기를 비교하여 3 차원 공간에서 제1 교통 표지에 대한 제1 법선 벡터를 산출하고, 제1 교통 표지에 대한 제1 법선 벡터 및 제2 교통 표지에 대한 제2 법선 벡터를 비교하여 영상 센서의 회전 교정값을 추정한다. 프로세서는 제1 코너 데이터 및 제4 코너 데이터를 비교하여 제1 교통 표지에 대한 영상 센서의 제1 위치 데이 터를 산출하고, 제1 교통 표지에 대한 영상 센서의 제1 위치 데이터 및 제2 교통 표지에 대한 영상 센서의 제2 위치 데이터를 비교하여 영상 센서의 위치(시프트) 교정값을 추정한다. 프로세서는 영상 센서 및 라이다 센서가 제3 교통 표지를 검출하면, 제1 교통 표지 및 제2 교통 표지를 기반으 로 추정한 영상 센서의 교정값을 제2 교통 표지 및 제3 교통 표지를 기반으로 다시 추정하여 교정값을 업데이트 한다. 센서 캘리브레이션 장치는 순차적인 교통 표지들에 관한 데이터를 기록한다. 센서 캘리브레이션 장치는 교정값, 처리 시간, 지도 상의 위치, 순서 등을 기록한다. 표지판과 표지판 간의 시간 간격이 제1 시간 간격을 초과하면 캘리브레이션 업데이트 타이밍이 되었음을 나타내는 제1 유형 메시지를 출력한다. 표지판과 표지판 간의 시간 간격이 제2 시간 간격 이내이면 캘리브레이션 업데이트를 생략할 수 있음을 나타내는 제2 유형 메시지를 출력한 다. 센서 캘리브레이션 장치는 제1 유형 메시지 및 제2 유형 메시지를 지도에 기록하고 동일 지역을 주행하던 중에 교정값의 오차 패턴을 파악하여, 오차 패턴이 일정 범위를 초과하면 제1 유형 메시지 및 제2 유형 메시지 에 매칭하는 표지판들을 기준으로 교정값에 기준이 되는 표지판을 변경할 수 있다. 도 3은 본 발명의 다른 실시예에 따른 센서 캘리브레이션 방법을 예시한 블록도이다. 센서 캘리브레이션 방법은 센서 캘리브레이션 장치에 의해 수행될 수 있다. 단계 S310에서는 영상 센서를 통해 제1 교통 표지를 촬영하여 2차원 이미지를 획득하는 단계를 수행한다. 단계 S320에서는 라이다 센서를 통해 제1 교통 표지에 무선 신호를 송수신하여 3차원 포인트 클라우드를 획득하 는 단계를 수행한다. 단계 S330에서는 2차원 이미지로부터 교통 표지 추출 모델을 이용하여 교통 표지 영역을 추출하는 단계를 수행 한다. 단계 S340에서는 3차원 포인트 클라우드로부터 3차원 교통 표지 데이터를 인식하고 2차원 교통 표지 데이터로 변환하는 단계를 수행한다. 단계 S350에서는 교통 표지 영역에서 추출한 제1 코너 데이터, 2차원 교통 표지 데이터에서 추출한 제2 코너 데 이터, 제2 코너 데이터를 3차원 공간에 투영한 제3 코너 데이터, 제2 코너 데이터를 2차원 평면에 투영한 제4 코너 데이터를 이용하여 라이다 센서 기반한 영상 센서의 교정값을 추정하는 단계를 수행한다. 단계 S360에서는 라이다 센서 기반한 영상 센서의 교정값을 추정하는 단계 이후에, 영상 센서 및 라이다 센서가 제3 교통 표지를 검출하면, 제1 교통 표지 및 제2 교통 표지를 기반으로 추정한 영상 센서의 교정값을 제2 교통 표지 및 제3 교통 표지를 기반으로 다시 추정하여 교정값을 업데이트하는 단계를 수행할 수 있다. 도 4는 본 발명의 다른 실시예에 따른 센서 캘리브레이션 방법에서 각 센서를 통해 교통 표지 데이터를 획득하 는 것을 예시한 도면이다. 영상 센서(예컨대, 카메라)와 라이다 센서에서 교통 표지판의 2D 이미지와 3D 포인트 클라우드 데이터를 취득한 다. 주행 중에 근접한 교통 표지판에 대한 여러 개의 2차원 영상들, 축적된 3D 포인트 클라우드 데이터를획득한다. 다양한 포즈에서 여러 교통 표지 데이터를 수집한다. 실시간 획득을 위하여 입력되는 이미지의 사이 즈를 조정하여 사용한다. 각 센서에서 획득한 데이터에서 표지판을 추출한다. 이미지와 포인트 클라우드에서 교 통 표지판을 감지하고 분할한다. 분할된 결과의 평면과 모서리의 법선 벡터를 사용하여 외부 보정 행렬을 추정 한다. 도 5 및 도 6은 본 발명의 다른 실시예에 따른 센서 캘리브레이션 방법에서 영상 센서를 통해 획득한 2차원 이 미지로부터 교통 표지 영역을 추출하는 것을 예시한 도면이다. 교통 표지 영역을 추출하는 단계는, 교통 표지 추출 모델로 네트워크의 최종 출력단에서 경계박스 위치 찾기와 클래스 분류가 동시에 이뤄지는 모델을 구축하는 단계(S410), 실시간 획득된 2차원 이미지의 사이즈를 조정하여 교통 표지 추출 모델에 입력하여 특징을 추출한 후 박스 형태의 후보 영역을 추출하는 단계(S420), 박스 형태의 후보 영역에서 에지 감지 및 색상 임계치를 이용하여 교통 표지 영역을 추출하는 단계(S430)를 포함할 수 있다. 교통 표지 영역을 추출하는 단계에서 실시간 획득된 영상을 사이즈를 조정(resize)하여 알고리즘에 실시간 활용 가능하도록 입력 데이터 크기를 조정한 후 신경망 모델을 사용하여 박스 형태로 표지판을 추출한다. 박스 형태 로 추출된 표지판에서 표지판 영역을 분할하며, Canny edge 감지, 색상임계값 활용하여 표지판 영역을 분할할 수 있다. 기존 사물 인식 네트워크(예컨대, YOLO 네트워크)를 재학습시켜 교통 표지 인식 네트워크를 구축할 수 있다. YOLO 네트워크의 최종 출력단에서 경계박스 위치 찾기와 클래스 분류가 동시에 이뤄진다. 출력 데이터는 바운더 리 박스 위치와 클래스에 관한 두 개의 유형이며, 크기가 상이한 바운더리 박스를 여러 개 생성하고 객체가 있 다고 판단되는 박스를 선별한다. 복수의 그리드로 분할된 영역에서 클래스를 분류하고, 바운더리 박스에 존재하 는 객체의 클래스를 매칭한다. 네트워크 모델은 특징을 추출하고 특징을 데이터 가공 처리한다. 네트워크 모델은 다수의 레이어가 네트워크로 연결되며 히든 레이어를 포함한다. 레이어는 파라미터를 포함할 수 있고, 레이어의 파라미터는 학습가능한 필터 집합을 포함한다. 파라미터는 노드 간의 가중치 및/또는 바이어스를 포함한다. 모델은 손실 함수를 최소화하도 록 파라미터를 학습한다. 도 7 및 도 8은 본 발명의 다른 실시예에 따른 센서 캘리브레이션 방법에서 라이다 센서를 통해 획득한 3차원 포인트 클라우드로부터 교통 표지 데이터로 변환하는 것을 예시한 도면이다. 2차원 교통 표지 데이터로 변환하는 단계는, 라이더 센서를 중심으로 하는 전역 좌표계에서 3차원 포인트 클라 우드를 기준 임계치까지 축적하는 단계(S510), 축적된 3차원 포인트 클라우드를 기준 복셀 그리드에 따라 샘플 링하여 복셀화를 수행하는 단계(S520), 복셀화된 3차원 포인트 클라우드를 기준 세기에 따라 필터링하는 단계 (S530), 필터링된 3차원 포인트 클라우드를 기준 근접 거리에 따라 클러스터링하는 단계(S540), 클러스터링된 3 차원 포인트 클라우드에 무작위 샘플 데이터의 최대 지지를 받는 모델을 선택하는 영상 처리 방식 및 평면 투영 방식을 적용하여 2차원 평면에 피팅하는 단계(S550)를 포함할 수 있다. 라이다 포인트 클라우드에서 교통 표지 추출하는 단계에서 포인트 클라우드에서 데이터 후보군을 추출하기 위해 서는 데이터 축적, 복셀화, 강도(intensity) 필터링, 유클리드 클러스터링, 평면 피팅 순서대로 이루어진다. 라 이다 데이터의 누적 및 복셀화를 수행한다. 이때, 라이다 센서의 데이터는 라이다를 중심으로 획득하기 때문에 전역 좌표로 변환되어 축적된다. 이와 같이 라이다 데이터가 일정 임계값만큼 누적되면 일정 크기의 복셀을 통 해 복셀화가 수행된다. 다음으로 강도 필터링을 수행한다. 표지판은 도로 위의 일반 물체에 비해 반사율이 현저 히 높은 특징이 있기 때문에 세기 필터링을 통해 포인트 클라우드 데이터를 추출하는 방법으로 매우 효과적이다. 주변 환경에 따라 라이다 데이터의 세기가 달라지므로 라이다 데이터의 세기 값은 상위 0.15% 이내 로 필터링 과정에서 특정 값을 설정하여 임계값 설정을 통해 추출할 수 있으며, 변화하는 상황에 따라 강인하게 표지판이 추출되도록 가변적으로 설정할 수 있다. 그 다음 유클리드 클러스터링 방법을 사용하여 포인트 클러스 터를 클러스터링한다. 마지막으로 포인트 클라우드를 동일한 평면에 배치하기 위해 RANSAC(RANdom SAmple Consensus) 평면 피팅 알고리즘을 이용하여 3차원 상에서 표지판에 해당하는 평면을 찾고 클러스터링된 포인트 클라우드를 해당 평면에 투영한다. 도 9 내지 도 11은 본 발명의 다른 실시예에 따른 센서 캘리브레이션 방법에서 라이다 센서 기반한 영상 센서의 교정값을 추정하는 것을 예시한 도면이다. 라이다 센서 기반한 영상 센서의 교정값을 추정하는 단계는, 제1 코너 데이터에 따른 모서리의 기울기 및 제3 코너 데이터에 따른 모서리의 기울기를 비교하여 3차원 공간에서 제1 교통 표지에 대한 제1 법선 벡터를 산출하는 단계(S610), 제1 교통 표지에 대한 제1 법선 벡터 및 제2 교통 표지에 대한 제2 법선 벡터를 비교하여 영상 센서의 회전 교정값을 추정하는 단계(S620)를 포함한다. 라이다 센서 기반한 영상 센서의 교정값을 추정하는 단계는, 제1 코너 데이터 및 제4 코너 데이터를 비교하여 제1 교통 표지에 대한 영상 센서의 제1 위치 데이터를 산출하는 단계(S710), 제1 교통 표지에 대한 영상 센서의 제1 위치 데이터 및 제2 교통 표지에 대한 영상 센서의 제2 위치 데이터를 비교하여 영상 센서의 위치 교정값을 추정하는 단계(S720)를 포함한다. 센서 캘리브레이션 방법에서 교정값으로 외부 교정 행렬을 추정하며, N개의 표지판 이미지 뷰를 가지고 있기 때 문에 N개의 3D 교통 표지판 코너를 찾을 수 있다. 표지판에 대한 영상 정보와 포인트 클라우드를 이용하여 표 지판 코너를 결정한다. 코너 추출에는 2D 이미지 상에서 코너 추출에 이용되는 해리스 코너 검출(Harris corner detection) 방법을 사용할 수 있다. 포인트 클라우드로 추출한 표지판의 꼭지점을 라이다 센서를 원점으로 하는 글로벌 3차원 좌표계로 나타낸다. 카메라로 추출한 표지판의 꼭지점들을 연결한 각 모서리의 기울기와 3차원에 서의 라이다로 추출한 실제 꼭지점들을 연결한 각 모서리의 기울기를 비교하여 카메라의 3차원 공간에서의 법선 벡터를 추정하고 추정치를 다른 표지판에서 추출된 법선벡터들과 비교하여 3차원 공간에서 카메라 회전을 추정 한다. 포인트 클라우드에서 추출한 모서리점을 카메라 평면에 투영하여 표지판 위치와 크기를 비교하여 카메라의 이동 을 추정한다. 이 과정에서도 다른 표지판 결과를 사용하여 카메라 위치 조정한다. 새로운 표지판이 검출되어 캘리브레이션에 활용될 때마다 라이다 기준 카메라의 3차원 공간에서의 회전 및 이동 결과값이 업데이트된다. 도 12는 본 발명의 실시예들을 캘리브레이션 보드를 사용하여 오차를 확인하는 것을 예시한 도면이다. 정확성을 테스트 하기 위해 색상화된 누적 포인트 클라우드를 사용하여 평가하였고, 위치가 다른 알려진 캘리브 레이션 보드를 사용하여 오차를 확인하였고, 복수의 좌측 교통표지판과 복수의 우측 교통표지판을 사용하였다. 본 실시예는 교통 표지를 활용한 라이다와 카메라 간 캘리브레이션 방법으로 주행한 데이터를 통하여 자동으로 센서 캘리브레이션을 업데이트를 진행하며, 라이다 및 카메라에서 모두 정밀하게 인식 가능한 교통 표지를 사용 함으로써 캘리브레이션 보드를 사용하는 결과만큼 정밀한 결과를 확인할 수 있다. 센서 캘리브레이션 장치는 하드웨어, 펌웨어, 소프트웨어 또는 이들의 조합에 의해 로직회로 내에서 구현될 수 있고, 범용 또는 특정 목적 컴퓨터를 이용하여 구현될 수도 있다. 장치는 고정배선형(Hardwired) 기기, 필드 프 로그램 가능한 게이트 어레이(Field Programmable Gate Array, FPGA), 주문형 반도체(Application Specific Integrated Circuit, ASIC) 등을 이용하여 구현될 수 있다. 또한, 장치는 하나 이상의 프로세서 및 컨트롤러를 포함한 시스템온칩(System on Chip, SoC)으로 구현될 수 있다. 센서 캘리브레이션 장치는 하드웨어적 요소가 마련된 컴퓨팅 디바이스 또는 서버에 소프트웨어, 하드웨어, 또는 이들의 조합하는 형태로 탑재될 수 있다. 컴퓨팅 디바이스 또는 서버는 각종 기기 또는 유무선 통신망과 통신을 수행하기 위한 통신 모뎀 등의 통신장치, 프로그램을 실행하기 위한 데이터를 저장하는 메모리, 프로그램을 실 행하여 연산 및 명령하기 위한 마이크로프로세서 등을 전부 또는 일부 포함한 다양한 장치를 의미할 수 있다. 도 3, 도 5, 도 7, 도 9, 도 10에서는 각각의 과정을 순차적으로 실행하는 것으로 기재하고 있으나 이는 예시적 으로 설명한 것에 불과하고, 이 분야의 기술자라면 본 발명의 실시예의 본질적인 특성에서 벗어나지 않는 범위 에서 도 3, 도 5, 도 7, 도 9, 도 10에 기재된 순서를 변경하여 실행하거나 또는 하나 이상의 과정을 병렬적으 로 실행하거나 다른 과정을 추가하는 것으로 다양하게 수정 및 변형하여 적용 가능할 것이다. 본 실시예들에 따른 동작은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨 터 판독 가능한 매체에 기록될 수 있다. 컴퓨터 판독 가능한 매체는 실행을 위해 프로세서에 명령어를 제공하는 데 참여한 임의의 매체를 나타낸다. 컴퓨터 판독 가능한 매체는 프로그램 명령, 데이터 파일, 데이터 구조 또는 이들의 조합을 포함할 수 있다. 예를 들면, 자기 매체, 광기록 매체, 메모리 등이 있을 수 있다. 컴퓨터 프로그 램은 네트워크로 연결된 컴퓨터 시스템 상에 분산되어 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 본 실시예를 구현하기 위한 기능적인(Functional) 프로그램, 코드, 및 코드 세그먼트들은 본"}
{"patent_id": "10-2022-0073499", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "실시예가 속하는 기술분야의 프로그래머들에 의해 용이하게 추론될 수 있을 것이다. 본 실시예들은 본 실시예의 기술 사상을 설명하기 위한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상 의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0073499", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 이동체를 예시한 블록도이다. 도 2는 본 발명의 다른 실시예에 따른 센서 캘리브레이션 장치를 예시한 블록도이다. 도 3은 본 발명의 다른 실시예에 따른 센서 캘리브레이션 방법을 예시한 블록도이다. 도 4는 본 발명의 다른 실시예에 따른 센서 캘리브레이션 방법에서 각 센서를 통해 교통 표지 데이터를 획득하 는 것을 예시한 도면이다. 도 5 및 도 6은 본 발명의 다른 실시예에 따른 센서 캘리브레이션 방법에서 영상 센서를 통해 획득한 2차원 이 미지로부터 교통 표지 영역을 추출하는 것을 예시한 도면이다. 도 7 및 도 8은 본 발명의 다른 실시예에 따른 센서 캘리브레이션 방법에서 라이다 센서를 통해 획득한 3차원 포인트 클라우드로부터 교통 표지 데이터로 변환하는 것을 예시한 도면이다. 도 9 내지 도 11은 본 발명의 다른 실시예에 따른 센서 캘리브레이션 방법에서 라이다 센서 기반한 영상 센서의 교정값을 추정하는 것을 예시한 도면이다. 도 12는 본 발명의 실시예들을 캘리브레이션 보드를 사용하여 오차를 확인하는 것을 예시한 도면이다."}
