{"patent_id": "10-2023-0091298", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0010984", "출원번호": "10-2023-0091298", "발명의 명칭": "주행영상속의 객체 검출 방법 및 그 장치", "출원인": "포티투닷 주식회사", "발명자": "조명훈"}}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상을 수신하고, 상기 수신된 영상의 프레임별로 포함된 객체를 검출하는 단계;상기 수신된 영상의 제1프레임 및 상기 제1프레임의 다음 프레임인 제2프레임에서 검출된 객체를 비교하는단계;상기 비교한 결과를 기초로 상기 제1프레임에서 검출되었다가 상기 제2프레임에서 미검출된 객체의 존부를 파악하는 단계; 및상기 파악된 결과를 기초로 상기 제2프레임에서의 객체 검출 결과를 보정하는 단계를 포함하는, 주행영상속의객체 검출 방법."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 영상은,자동차의 주행 중에 획득된 영상인, 주행영상속의 객체 검출 방법."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 영상은,주행 중에 일시적으로 정차하고 있는 자동차의 카메라를 통해 촬영된 영상인, 주행영상속의 객체 검출 방법."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 객체 검출 결과를 보정하는 단계는,상기 파악된 결과에, 상기 제1프레임 및 상기 제2프레임에서 상기 영상을 촬영한 카메라의 촬영방향을 기초로상기 제2프레임에서의 객체 검출 결과를 보정하는, 주행영상속의 객체 검출 방법."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 검출된 객체를 비교하는 단계는,상기 제1프레임 및 상기 제2프레임에서의 검출된 객체를 비교하기 위하여, 픽셀단위로 계산하는 Cross-correlation을 이용하는, 주행영상속의 객체 검출 방법."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 검출된 객체를 비교하는 단계는,상기 제1프레임의 가로중앙선의 상단의 적어도 일부를 크로핑(cropping)하고, 상기 크로핑된 상단만을비교하는, 주행영상속의 객체 검출 방법."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2025-0010984-3-제1항에 있어서,상기 객체 검출 결과를 보정하는 단계는,상기 파악된 결과에 따라 상기 제2프레임에서 미검출된 객체가 존재하고, 그 객체가 정지특성을 갖는 물체이면,상기 제2프레임에서의 객체 검출 결과를 보정하는, 주행영상속의 객체 검출 방법."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제8항에 있어서,상기 정지특성을 갖는 물체는, 신호등, 간판 및 신호표지판 중 어느 하나인, 주행영상속의 객체 검출 방법."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 영상은, 주행 중에 일시적으로 정차하고 있는 자동차의 카메라를 통해 촬영된 영상이고,상기 정지특성은,상기 자동차에 장착된 GPS 또는 가속도센서에 의해서 탐지되는, 주행영상속의 객체 검출 방법."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 객체를 검출하는 단계는,상기 검출된 객체의 외곽선에 마진(margin)을 부가한 확장된 외곽선을 설정하고, 확장된 외곽선이 설정된 객체별로 비교하여 객체별로 정지여부를 파악하는, 주행영상속의 객체 검출 방법."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 따른 방법을 실행시키기 위한 프로그램을 저장하고 있는 컴퓨터 판독가능한 기록매체."}
{"patent_id": "10-2023-0091298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써, 연산을 수행하는 프로세서를 포함하고,상기 프로세서는,영상을 수신하고, 상기 수신된 영상의 프레임별로 포함된 객체를 검출하고,상기 수신된 영상의 제1프레임 및 상기 제1프레임의 다음 프레임인 제2프레임에서 검출된 객체를 비교하고,상기 비교한 결과를 기초로 상기 제1프레임에서 검출되었다가 상기 제2프레임에서 미검출된 객체의 존부를 파악하고,상기 파악된 결과를 기초로 상기 제2프레임에서의 객체 검출 결과를 보정하는, 주행영상속의 객체 검출 장치."}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는, 영상을 수신하고, 상기 수신된 영상의 프레임별로 포함된 객체를 검출하는 단계; 상기 수신된 영상의 제1프레임 및 상기 제1프레임의 다음 프레임인 제2프레임에서 검출된 객체를 비교하는 단계; 상기 비교한 결과를 기초로 상기 제1프레임에서 검출되었다가 상기 제2프레임에서 미검출된 객체의 존부를 파악하는 단계; 및 상기 파악된 결과를 기초로 상기 제2프레임에서의 객체 검출 결과를 보정하는 단계를 포함하는, 주행영 상속의 객체 검출 방법을 개시한다."}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상에 포함된 객체를 검출하는 알고리즘을 개선하기 위한 방법에 관한 것으로서, 보다 구체적으로는, 도로에서 주행 중에 획득된 주행영상에서 객체를 검출하는 객체 검출도를 대폭 향상시킬 수 있는 방법 및 그 방법을 구현하기 위한 장치에 관한 것이다."}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보통신 기술과 차량 산업의 융합으로 인해 빠르게 차량의 스마트화가 진행되고 있다. 스마트화로 인해, 차량 은 단순한 기계적 장치에서 스마트카로 진화하고 있으며, 특히, 스마트카의 핵심기술로 자율 주행(self- driving)이 주목 받고 있다. 자율 주행이란, 운전자가 핸들과 가속페달, 브레이크 등을 조작하지 않아도 차량에 탑재된 자율 주행 모듈이 차량의 주행상태를 능동적으로 제어함으로써, 차량 스스로 목적지까지 찾아가는 기술 이다. 자율주행 자동차의 안전한 자율주행을 위해서, 자율 주행 과정에서 차량이 보행자나 다른 차량을 정확하게 검출 하고, 검출된 객체와의 거리를 산출하는 방법에 대한 연구가 다양하게 이루어지고 있으나, 차량이 주행 중에 도 로 상에 출현가능한 객체 특성은 사실상 무한에 가깝고, 자율주행 자동차에 탑재되는 모듈의 프로세싱 능력에 한계가 존재하여, 도로 상에 있는 객체를 완벽하게 검출할 수 있는 방법은 현재 알려져 있지 않다. 카메라를 통한 객체 검출 및 거리추정의 경우, 실제 3차원 세계의 객체를 2차원 이미지에 투영하였기 때문에 거 리에 대한 정보가 많이 손실된다. 특히, 보행자 위치 계산에 많이 사용되는 특징들(보행자의 키나 지면에 닿아 있는 점)의 편차가 크기 때문에 오차가 크다. 레이더(RADAR)를 통한 객체 검출 및 거리추정의 경우, 레이더가 운용하는 전파 특성상 객체를 빠르게 파악하고 분류하는 능력이 떨어지기 때문에, 보행자인지 또는 차량인지에 대한 판단이 어렵고, 특히, 도로상에 있는 보행 자나 이륜차(자전거나 오토바이)의 경우 신호세기가 작기 때문에 검출결과가 더욱 더 안 좋은 경향이 있다. 최근에는 라이다(LiDAR)를 이용한 객체 검출 및 거리 추정 기술이 상대적으로 높은 정확도를 갖고 있어서 각광 받고 있으나, 고출력 레이저는 위험성이 있어서 라이다는 출력을 낮춘 레이저를 기반으로 동작할 수 밖에 없고, 레이더가 사용하는 전파와는 다르게 레이저는 주변 환경의 영향을 크게 받고, 라이다 센서의 지나치게 높은 비 용이 한계점으로 지적된다. 한편, 도로를 주행하는 도중에 촬영된 주행영상에서 거리나 크기 특성으로 인해서, 매우 작은 크기로 촬영되어 영상에 담기는 객체들이 있을 수 있다. 예를 들어, 신체가 작은 어린이, 카메라로부터 멀리 떨어져서 작게 보이 는 신호등과 같은 객체들은, 안전한 자율주행을 위해서 학습모델에 의해 필수적이고 선제적으로 학습되어야 하 는 객체들이지만, 그 객체들에 대한 검출도가 낮은 한계점이 있다. 종래의 딥러닝 기반 모델을 이용한 객체 검출 방법은, 수신된 영상의 사이즈(해상도)를 객체 검출 장치(object detector)에서 지원하는 사이즈에 맞춰서 변경하고, 변경된 영상을 객체 검출 장치에 입력함으로써 예측 결과를 얻고, 예측 결과를 최초 수신된 영상의 해상도에 맞게 재변환하는 프로세스로 진행되는 것이 일반적이다. 특히, 객체 검출 장치에서 주로 사용되는 영상의 해상도는 640*640 또는 1280*1280이며, 과도한 GPU메모리가 필요하고 학습시간이 지나치게 길어지는 문제로 인해서, 앞서 설명한 해상도보다 더 큰 사이즈의 영상은 객체 검출 장치 의 입력 영상으로 사용되지 않았다. 그러나, 자동차에 탑재되는 카메라 모듈의 스펙이 나날이 향상됨에 따라서, 카메라로부터 수신되는 영상의 해상도는 1280*1280보다 훨씬 더 클 수 밖에 없고, 큰 해상도의 영상이 객체 검 출 장치에 입력되기 위해서 변환되면서, 영상속에 작은 크기로 촬영된 객체들에 대한 검출도(검출률)가 낮아지 는 문제가 있다."}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-2438114호 (2022.08.25)"}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는, 주행영상속에서 객체를 검출하는 방법 및 그 방법을 구현하기 위한 장치를 제공하는 데에 있다."}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 방법은, 영상을 수신하고, 상기 수신된 영상의 프레임별로 포함된 객체를 검출하는 단계; 상기 수신된 영상의 제1프레임 및 상기 제1프레임의 다음 프레임인 제2프레임에서 검출된 객체를 비교하는 단계; 상기 비교한 결과를 기초로 상기 제1프레임에서 검출되었다가 상 기 제2프레임에서 미검출된 객체의 존부를 파악하는 단계; 및 상기 파악된 결과를 기초로 상기 제2프레임에서의 객체 검출 결과를 보정하는 단계를 포함한다. 상기 방법에 있어서, 상기 영상은, 자동차의 주행 중에 획득된 영상일 수 있다. 상기 방법에 있어서, 상기 영상은, 주행 중에 일시적으로 정차하고 있는 자동차의 카메라를 통해 촬영된 영상일 수 있다. 상기 방법에 있어서, 상기 객체 검출 결과를 보정하는 단계는, 상기 파악된 결과에, 상기 제1프레임 및 상기 제 2프레임에서 상기 영상을 촬영한 카메라의 촬영방향을 기초로 상기 제2프레임에서의 객체 검출 결과를 보정할 수 있다. 상기 방법에 있어서, 상기 검출된 객체를 비교하는 단계는, 상기 제1프레임 및 상기 제2프레임에서의 검출된 객 체를 비교하기 위하여, 픽셀단위로 계산하는 Cross-correlation을 이용할 수 있다. 상기 방법에 있어서, 상기 검출된 객체를 비교하는 단계는, 상기 제1프레임의 가로중앙선의 상단의 적어도 일부 를 크로핑(cropping)하고, 상기 크로핑된 상단만을 비교할 수 있다. 상기 방법에 있어서, 상기 객체 검출 결과를 보정하는 단계는, 상기 파악된 결과에 따라 상기 제2프레임에서 미 검출된 객체가 존재하고, 그 객체가 정지특성을 갖는 물체이면, 상기 제2프레임에서의 객체 검출 결과를 보정할 수 있다. 상기 방법에 있어서, 상기 정지특성을 갖는 물체는, 신호등, 간판 및 신호표지판 중 어느 하나일 수 있다. 상기 방법에 있어서, 상기 영상은, 주행 중에 일시적으로 정차하고 있는 자동차의 카메라를 통해 촬영된 영상이 고, 상기 정지특성은, 상기 자동차에 장착된 GPS 또는 가속도센서에 의해서 탐지될 수 있다. 상기 방법에 있어서, 상기 객체를 검출하는 단계는, 상기 객체가 정지특성을 갖는 물체라면, 상기 검출된 객체 의 외곽선에 마진(margin)을 부가한 확장된 외곽선을 설정하고, 확장된 외곽선이 설정된 객체별로 비교하여 객 체별로 정지여부를 파악할 수 있다. 상기 기술적 과제를 해결하기 위한 본 발명의 다른 일 실시예에 따른 장치는, 적어도 하나의 프로그램이 저장된 메모리; 및 상기 적어도 하나의 프로그램을 실행함으로써, 연산을 수행하는 프로세서를 포함하고, 상기 프로세 서는, 영상을 수신하고, 상기 수신된 영상의 프레임별로 포함된 객체를 검출하고, 상기 수신된 영상의 제1프레 임 및 상기 제1프레임의 다음 프레임인 제2프레임에서의 검출된 객체를 비교하고, 상기 비교한 결과를 기초로 상기 제1프레임에서 검출되었다가 상기 제2프레임에서 미검출된 객체의 존부를 파악하고, 상기 파악된 결과를 기초로 상기 제2프레임에서의 객체 검출 결과를 보정한다. 본 발명의 일 실시예는 상기 방법을 실행시키기 위한 프로그램을 저장하고 있는 컴퓨터 판독가능한 기록매체를 제공할 수 있다."}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 주행영상속에서 정지특성을 갖는 신호등, 신호표지판, 간판과 같은 객체에 대한 검출능력이 대폭 향상될 수 있다."}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도면에 예시하"}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "고 상세한 설명에 상세하게 설명하고자 한다. 본 발명의 효과 및 특징, 그리고 그것들을 달성하는 방법은 도면 과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 다양한 형태로 구현될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 실시 예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동 일하거나 대응하는 구성 요소는 동일한 도면부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 실시 예에서, 제1, 제2 등의 용어는 한정적인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별 하는 목적으로 사용되었다. 이하의 실시 예에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 실시 예에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 또는 구성요소가 존재함을 의 미하는 것이고, 하나 이상의 다른 특징을 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 어떤 실시 예가 달리 구현 가능한 경우에 특정한 공정 순서는 설명되는 순서와 다르게 수행될 수도 있다. 예를 들어, 연속하여 설명되는 두 공정이 실질적으로 동시에 수행될 수도 있고, 설명되는 순서와 반대의 순서로 진행 될 수 있다. 도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 자율 주행 장치는, 차량에 장착되어 자율주행 자동차를 구현 할 수 있다. 자율주행 자동차에 장착되는 자율 주행 장치는, 주변의 상황 정보를 수집하기 위한 다양한 센 서들을 포함할 수 있다. 일례로, 자율 주행 장치는 자율주행 자동차의 전면에 장착된 이미지 센서 및/또는 이벤트 센서를 통해, 전방에서 운행 중인 선행 차량의 움직임을 감지할 수 있다. 자율 주행 장치는 자율주 행 자동차의 전면은 물론, 옆 차로에서 운행중인 다른 주행 차량과, 자율주행 자동차 주변의 보행 자 등을 감지하기 위한 센서들을 더 포함할 수 있다. 자율주행 자동차 주변의 상황 정보를 수집하기 위한 센서들 중 적어도 하나는, 도 1에 도시한 바와 같이 소정의 화각(FoV)을 가질 수 있다. 일례로, 자율주행 자동차의 전면에 장착된 센서가 도 1에 도시한 바와 같은 화 각(FoV)을 갖는 경우에, 센서의 중앙에서 검출되는 정보가 상대적으로 높은 중요도를 가질 수 있다. 이는, 센서 의 중앙에서 검출되는 정보에, 선행 차량의 움직임에 대응하는 정보가 대부분 포함되어 있기 때문일 수 있 다. 자율 주행 장치는, 자율주행 자동차의 센서들이 수집한 정보를 실시간으로 처리하여 자율주행 자동차의 움직임을 제어하는 한편, 센서들이 수집한 정보 중에 적어도 일부는 메모리 장치에 저장할 수 있다. 도 2를 참조하면, 자율 주행 장치는 센서부, 프로세서, 메모리 시스템, 및 차체 제어 모듈 등을 포함할 수 있다. 센서부는 복수의 센서들(42-45)을 포함하며, 복수의 센서들(42-45)은 이미지 센서, 이벤트 센서, 조도 센서, GPS 장치, 가속도 센서 등을 포함할 수 있다. 센서들(42-45)이 수집한 데이터는 프로세서로 전달될 수 있다. 프로세서는 센서들(42-45)이 수집한 데 이터를 메모리 시스템에 저장하고, 센서들(42-45)이 수집한 데이터에 기초하여 차체 제어 모듈을 제어하여 차량의 움직임을 결정할 수 있다. 메모리 시스템은 둘 이상의 메모리 장치들과, 메모리 장치들을 제어 하기 위한 시스템 컨트롤러를 포함할 수 있다. 메모리 장치들 각각은 하나의 반도체 칩으로 제공될 수 있다. 메모리 시스템의 시스템 컨트롤러 외에, 메모리 시스템에 포함되는 메모리 장치들 각각은 메모리 컨트 롤러를 포함할 수 있으며, 메모리 컨트롤러는 신경망과 같은 인공지능(AI) 연산 회로를 포함할 수 있다. 메모리 컨트롤러는 센서들(42-45) 또는 프로세서로부터 수신한 데이터에 소정의 가중치를 부여하여 연산 데이터를 생성하고, 연산 데이터를 메모리 칩에 저장할 수 있다. 도 3은 자율 주행 장치가 탑재된 자율주행 자동차의 센서가 획득한 영상 데이터의 예시를 나타낸 도면이다. 도 3을 참조하면, 영상 데이터는 자율주행 자동차의 전면에 장착된 센서가 획득한 데이터일 수 있다. 따라서 영상 데이터에는 자율주행 자동차의 전면부, 자율주행 자동차과 같은 차로의 선행 차량, 자율주행 자동차 주변의 주행 차량 및 비관심영역 등이 포함될 수 있다. 도 3에 도시한 실시예에 따른 영상 데이터에서, 자율주행 자동차의 전면부와 비관심영역이 나타나 는 영역의 데이터는 자율주행 자동차의 운행에 영향을 미칠 가능성이 거의 없는 데이터일 수 있다. 다시 말해, 자율주행 자동차의 전면부와 비관심영역은 상대적으로 낮은 중요도를 갖는 데이터로 간주될 수 있다. 반면, 선행 차량과의 거리, 및 주행 차량의 차로 변경 움직임 등은 자율주행 자동차의 안전한 운행에 있어서 매우 중요한 요소일 수 있다. 따라서, 영상 데이터에서 선행 차량 및 주행 차량 등이 포함 되는 영역의 데이터는 자율주행 자동차의 운행에 있어서 상대적으로 높은 중요도를 가질 수 있다. 자율 주행 장치의 메모리 장치는, 센서로부터 수신한 영상 데이터의 영역별로 가중치를 다르게 부여하여 저 장할 수 있다. 일례로, 선행 차량과 주행 차량 등이 포함되는 영역의 데이터에는 높은 가중치를 부여하 고, 자율주행 자동차의 전면부와 비관심영역이 나타나는 영역의 데이터에는 낮은 가중치를 부여할 수 있다. 도 4a 및 도 4b는 일 실시예에 따른 차량 외부를 촬영하는 카메라와 관련된 도면이다. 카메라는 차량에 탑재되어 차량의 외부를 촬영할 수 있다. 카메라는 차량의 전방, 측방, 후방 등을 촬영할 수 있다. 본 발명에 따른 장치는 카메라에서 촬영된 복수의 영상을 획득할 수 있다. 카메라에서 촬영된 복수의 영 상에는 복수의 객체가 포함될 수 있다. 객체에 관한 정보는 객체 종류 정보 및 객체 속성 정보를 포함한다. 여기에서, 객체 종류 정보는 객체의 종류를 나타내는 인덱스 정보이며, 큰 범위인 그룹과 세부 범위인 클래스로 구성된다. 그리고, 객체 속성 정보는 객체 의 현재 상태에 대한 속성 정보를 나타내는 것이며, 움직임 정보, 회전 정보, 교통 정보, 색상 정보, 및 가시성 정보 등을 포함한다. 일 실시예에서, 객체 종류 정보에 포함되는 그룹 및 클래스는 아래의 표 1과 같을 수 있으나, 이에 제한되지 않 는다. 표 1"}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "움직임 정보는 객체의 움직임 정보를 표현하며 정차, 주차, 이동 등으로 정의될 수 있다. 차량의 경우 정차, 주 차, 이동이 객체 속성 정보로 결정될 수 있고, 보행자의 경우 이동, 정지, 알 수 없음이 객체 속성 정보로 결정 될 수 있고, 신호등과 같이 움직일 수 없는 객체의 경우 디폴트 값인 정지로 객체 속성 정보가 결정될 수 있다.회전 정보는 객체의 회전 정보를 표현하며 정면, 후면, 수평(horizontal), 수직(vertical), 측면 등으로 정 의될 수 있다. 차량의 경우 정면, 후면, 측면으로 객체 속성 정보가 정해질 수 있고, 가로 또는 세로 방향의 신 호등은 각각 수평 또는 수직으로 객체 속성 정보가 정해질 수 있다. 교통 정보는 객체의 교통정보를 의미하며, 교통표지판의 지시, 주의, 규제, 보조 표지 등으로 정의될 수 있다. 색상 정보는 객체의 색상 정보를 의미하며 객체의 색상, 신호등 및 교통표지판의 색상을 표현할 수 있다. 도 4a를 참조하면, 객체는 보행자일 수 있다. 이미지는 소정의 크기를 가질 수 있다. 복수의 이미지 에는 동일한 객체가 포함될 수 있으나, 차량이 도로를 따라 주행함에 따라 차량과 객체의 상대 적 위치는 계속 변하고, 또한 객체도 시간에 따라 이동을 함으로써, 이에 따라 동일한 객체라도 각 이미지 내에서의 위치가 달라지게 된다. 각 이미지에서 동일한 객체가 어떤 것인지 결정하기 위해 이미지 전체를 이용하는 경우, 데이터 전송량 및 연산 량이 상당히 커지게 된다. 이에 따라, 차량에 탑재되는 장치에서 엣지 컴퓨팅을 통해 처리되기 어렵고, 실시간 분석 또한 어렵다. 도 4b를 참조하면, 이미지에 포함된 바운딩 박스가 도시된다. 바운딩 박스(Bounding box)는 객체 (object)에 대한 메타데이터로서, 바운딩 박스 정보에는 객체 종류 정보(그룹, 클래스 등), 이미지 상의 위치 정보, 크기 정보 등이 포함될 수 있다. 도 4b를 참조하면, 바운딩 박스 정보는 해당 객체가 보행자 클래스에 해당한다는 정보와, 객체의 좌 측 상단 꼭지점이 이미지 상의 (x, y) 에 위치한다는 정보, 객체의 크기가 w x h 라는 정보, 그리고 객체 가 이동 중이라는 현재 상태 정보(즉, 움직임 정보)를 포함할 수 있다. 도 5는 일 실시예에 따른 객체 검출 방법을 설명하는 개략도이다. 객체 검출 장치는 카메라로부터 획득된 동영상을 프레임별로 분리하여 복수의 프레임을 획득할 수 있다. 복수의 프레임은 이전 프레임 및 현재 프레임을 포함할 수 있다. 객체 검출 장치는 이전 프레임에서 제1 보행자 객체를 검출할 수 있다. 일 실시예에서, 객체 검출 장치는 프레임을 동일한 크기의 그리드로 나누고, 각 그리드에 대해 그리드 중앙을 중심으로 미리 정의된 형태로 지정된 경계박스의 개수를 예측하며 이를 기반으로 신뢰도를 계산할 수 있다. 객 체 검출 장치는 프레임에 객체가 포함되어 있는지, 또는, 배경만 단독으로 있는지 여부를 결정하고, 높은 객체 신뢰도를 갖는 위치를 선택하여 객체 카테고리를 결정함으로써 결과적으로 객체를 검출할 수 있다. 다만, 본 개 시에서 객체를 검출하는 방법은 이에 제한되지 않는다. 객체 검출 장치는 이전 프레임에서 검출된 제1 보행자 객체의 제1 위치 정보를 획득할 수 있다. 도 4a 및 도 4b에서 상술한 바와 같이, 제1 위치 정보는 이전 프레임 상의 제1 보행자 객체에 대응하는 바운딩 박스의 어느 하나의 꼭지점(예를 들어, 좌측 상단 꼭지점) 좌표 정보 및 가로, 세로 길이 정보를 포함할 수 있다. 또한, 객체 검출 장치는 현재 프레임에서 검출된 제2 보행자 객체의 제2 위치 정보를 획득할 수 있다. 객체 검출 장치는 이전 프레임에서 검출된 제1 보행자 객체의 제1 위치 정보, 및 현재 프레임에 서 검출된 제2 보행자 객체의 제2 위치 정보 간의 유사도를 산출할 수 있다. 도 5를 참조하면, 제1 위치 정보 및 제2 위치 정보를 이용하여, 객체 검출 장치는 제1 보행자 객체 및 제2 보행자 객체간의 교집합 및 합집합을 산출할 수 있다. 객체 검출 장치는 합집합 영역 대비 교집합 영역의 값을 산출하고, 산출된 값이 임계값 이상인 경우, 제1 보행자 객체 및 제2 보행자 객체가 동일한 보 행자 객체인 것으로 결정할 수 있다. 그러나, 객체 간의 동일성을 판별하는 방법은 상술한 방법으로 제한되지 않는다. 도 6은 도 4a, 도 4b 및 도 5에서 설명한 객체 검출 장치의 동작 특성 및 한계점을 설명하기 위한 도면이다. 본 발명에 따른 방법에서 사용되는 객체 검출 장치는 딥러닝(deep learning)을 기반으로 하며, CNN(Convolutional neural network)을 사용하기에, 영상에서 검출되는 객체들의 주변의 변화에 많은 영향을 받 는 특성을 갖는다. 즉, 검출하려고 하는 객체가 여러 프레임에 걸쳐서 위치가 전혀 변하지 않는 정지특성의 물체라고 하더라도, 그 객체의 주변의 움직이는 사물들에 의해서 오검출이 유발되어, 이전 프레임에서 계속 검출 되어 왔던 정지특성의 객체가 특정 시점부터 검출되지 않는 경우가 발생될 수 있다. 도 6은 위와 같은 문제점이 생기는 원인을 CNN연산 특성에 기반하여 도식적으로 나타내는 도면이다. 도 6을 참 조하면, 컨볼루션(convolution)이 적용되는 원본 영상의 최초 프레임의 규격은 224*224 픽셀의 해상도를 갖는데, 컨볼루션이 누적적으로 적용되면서, 영상의 정보를 포함하는 프레임의 규격은 1*1까지 작아지게 되고, 이 과정에서 정지특성을 갖는 일부 객체에 대한 오검출현상이 발생되는 것을, 이 분야의 통상의 지식을 가진 자 는 이해할 것이다. 본 발명에 따르면, 도 6과 같이, 정지특성을 갖는 일부 객체에 대해서 오검출현상이 발생되 는 것을 방지할 수 있게 되어, 객체 검출 장치의 전반적인 객체 검출 성능을 향상시킬 수 있다. 도 7은 본 발명에 따른 객체 검출 방법에서 사용되는 트래킹 알고리즘의 일 예를 흐름도로 나타낸 도면이다. 먼저, 객체 검출 장치는 주행 중에 획득된 제1영상에서 제1객체를 인식할 수 있다(S710). 여기서, 객체 검출 장 치가 제1영상에서 제1객체를 인식했다는 것은, 제1영상을 구성하는 프레임들 중 어느 한 프레임에서 제1객체를 인식하여 제1객체에 대한 크기 및 종류(class)에 대한 정보를 파악한 것을 의미한다. 이어서, 객체 검출 장치는 제1영상(제1프레임)에서 제1객체가 소정기간 사라졌다가 재출현하는지 여부를 감지할 수 있다(S730). 여기서, 소정기간은 적어도 하나 이상의 프레임에 대한 시간범위 값일 수 있다. 수집된 제1영상의 프레임레이트 가 30frames/초라면, 소정기간은 0초에서 1/30초에 해당하는 시간범위 값일 수 있다. 다른 예로서, 소정기간은 1프레임 내지 3프레임에 대한 시간범위 값일 수 있다. 여기서, 소정기간이 1프레임에 대한 시간범위 값일 때에는, i번째 프레임까지 트래킹되던 제1객체가 i+1번째 프레임에 소실되었다가 i+2번째 프레임에서 재출현하면, 제1객체는 소정기간 사라진 것으로 간주될 수 있다. 또한, 소정기간이 3프레임에 대한 시간범위 값일 때에는, i번째 프레임에 트래킹되던 제1객체가 i+1번째 프레임에 소실되었다가 i+4번째 프레임에 서 재출현하면, 제1객체는 소정기간(i+1, i+2, i+3, 총 3프레임)동안 사라진 것으로 간주될 수 있다. 객체 검출 장치는 제1객체가 재출현한 것을 감지한 것을 기초로 하여, 제1객체에 대한 학습데이터를 산출할 수 있다(S750). 또한, 객체 검출 장치는 제1객체가 재출현한 것을 감지한 것을 기초로 하여, 소정기간 제1객체가 사라져서 인식되지 않았다고 판단되었던 이전 프레임들에 제1객체가 인식된 것으로 간주할 수 있다. 예를 들어, 도 8에서 i번째 프레임, i+1번째 프레임에서 제1객체가 인식되었고 i+2번째 프레임에서 제1객체가 사라졌다가, i+3번째 프레임에서 제1객체가 다시 인식되었다면, 객체 검출 장치로는 여전히 i+2번째 프레임의 제1객체를 인식할 수 없지만, i+2번째 프레임에도 i번째 프레임, i+1번째 프레임, i+3번째 프레임에서 인식된 제1객체가 있는 것으로 간주된다. 제1객체가 사라진 후에 재출현하지 않지 않거나, 재출현하더라도 소정기간이 경과한 이후에 재출현하는 경우, 객체 검출 장치는 조건을 만족하지 못한 것으로 간주하고, 기존에 누적되어 있던 제1객체에 대한 트래킹정보를 삭제하고, 제1객체에 대한 학습데이터를 산출하지 않는다. 특히, 제1객체가 사라진 후에 소정기간보다 더 긴 시 간이 경과한 후에 재출현한 경우는, 인식모델이 인식성능의 한계로 제1객체를 인식하지 못한 것이 아니라, 다른 객체에 의해서 제1객체가 차폐되어 인식하지 못했을 가능성이 높으므로, 학습데이터를 산출할 조건이 만족된 것으로 볼 수 없다. 단계 S750에서 학습데이터는 제1객체의 크기, 위치, 분류코드(class), 제1객체가 최초에 인식된 후에 소정기간 사라졌다가 재출현한 이력(history)에 대한 정보, 제1객체의 신뢰도(confidence)에 대한 정보 중 적어도 하나 이상을 포함할 수 있다. 객체 검출 장치는, 단계 S750에서 산출한 학습데이터에 기반한 정보로, 주행 중에 획득된 영상에서 객체를 검출 하는 자율주행 자동차의 객체 검출 장치가 학습되도록 제어할 수 있다(S770). 도 7에서 설명한 트래킹 알고리즘은 칼만 필터(Kalman Filter) 기반의 SORT(Simple Online and Realtime Tracking)알고리즘으로 구현될 수 있으나, 이에 제한되지 않는다. 특히, 칼만 필터를 기반으로 하는 트래킹 알 고리즘은 2D 바운딩 박스에 대해서 정상적으로 동작하는 특성을 갖고, 트래킹 알고리즘을 수행한 결과정보도 객 체별로 대응되는 2D 바운딩 박스로 제공하는 특성을 갖고 있으며, 본 발명에서 설명한 트래킹 알고리즘도 동일 한 특성을 가질 수 있다. 도 8은 도 7에서 설명한 트래킹 알고리즘을 도식적으로 설명한 도면이다. 도 8을 참조하면, 총 4개의 프레임이 도시되어 있으며, 각 프레임별로 최소 하나 이상의 객체가 프레임의 특정 위치에 위치하고 있다. 보다 구체적으로, 도 8에서 i번째 프레임, i+1번째 프레임, i+3번째 프레임에는 상단과 하단에 각각 객체가 존재하는 것이 인식되었으나, i+2번째 프레임에서는 하단의 객체가 일시적으로 소실되어 상 단에만 객체가 존재하는 것으로 인식된 것을 알 수 있다. 본 실시예에 따른 객체 검출 장치는 도 8처럼 특정한 객체에 대해서 트래킹(tracking)이 이루어지고 있는 과정 에서 갑자기 특정 프레임에서 객체의 소실이 발생되었다가, 짧은 시간내에 객체가 인식된 경우를 Weakness Point로 간주하여 인식모델을 학습시킬 학습데이터로 변환시키거나, i+2번째 프레임의 하단의 객체가 존재하는 것으로 간주하고 그에 따라서, i+2번째 프레임의 하단의 객체를 주변의 배경이나 다른 객체들과 구별하기 위한 외곽선(2D 바운딩 박스 등)을 생성할 수 있다. 즉, 본 실시예는, 트래킹이 정상적으로 이루어진 객체가 특정 프레임에서 소실되었다가 재출현했다면, 자율주행 자동차의 객체 인식 장치의 성능한계가 발생한 것으로서, 해당 객체가 소실되었다고 판단된 프레임에 객체가 존 재하는 것으로 간주하여 그 프레임에 객체를 구별하기 위한 외곽선을 생성하고, 해당 객체 인식 장치에 대한 추 가학습을 통해서 객체 인식 성능을 향상시키기 위한 실시예로 이해될 수 있다. 도 7 및 도 8을 통해서 설명한 트래킹(tracking) 기반의 객체 검출 장치의 객체 검출 프로세스를 구현하기 위해 서 채택되는 하이퍼 파라미터(hyper parameter)에는 여러 가지가 있을 수 있다. 예를 들어, 하이퍼 파라미터에 포함되는 제1파라미터는 몇 프레임동안 연속적으로 객체를 검출하는 경우 트래킹을 시작할지에 대한 파라미터이 고, 제2파라미터는 몇 프레임동안 소실되었다가 재출현할 경우, 트래킹을 유지할 지에 대한 파라미터일 수 있다. 제1파라미터 및 제2파라미터를 제대로 조절하지 않으면, 트래킹을 시작한 객체를 쉽게 놓치게 되거나, 객 체가 이미 사라진 경우에도 객체에 대한 외곽선(2D 바운딩 박스)을 생성하게 되어 전체적인 객체 검출 성능이 하락할 수 있다. 위와 같이, 객체 인식률 향상 장치의 제1파라미터 및 제2파라미터의 변경은 트래킹 알고리즘의 성능에 있어서 트레이드-오프(trade-off)의 특성을 갖고 있으므로, 기존의 트래킹 알고리즘을 적절하게 보완하 기 위한 기술이 필요하며, 본 발명의 일 실시예는 트래킹 알고리즘을 보완하기 위한 기술을 구현할 수 있다. 도 9는 본 발명에 따른 객체 검출 방법의 일 예를 흐름도로 나타낸 도면이다. 도 9에 따른 방법은, 본 발명에 따른 객체 검출 장치에 의해 구현될 수 있으며, 객체 검출 장치를 구성하는 하 위 모듈의 기능에 대해서는 후술하기로 한다. 이하에서, 객체 검출 모듈(object detector)은 종래에 알려진 모 듈로서, 영상을 입력으로 받아서 딥러닝 기반으로 영상속에 있는 객체를 검출하는 기능을 수행하는 모듈 (module)을 의미하고, 객체 검출 장치(object detecting apparatus)는 객체 검출 모듈을 물리적 또는 논리적으 로 포함하고, 객체 검출 모듈이 검출한 객체들에 대한 정보를 추가적으로 가공하거나 보정하여 최종적으로 객체 검출 성능을 극대화한 본 발명에 따른 장치인 것으로 간주한다. 객체 검출 장치는 영상을 객체 검출 대상으로서 수신할 수 있다(S910). 단계 S910에서 객체 검출 장치가 수신하는 영상은 카메라가 장착된 자동차가 도로(차도)를 주행하면서 촬영할 때 그 카메라에 의해 생성된 영상으로서, 1920*1280 픽셀로 이루어진 영상일 수 있으나 이에 한정되지 않는다. 즉, 자동차에 장착되어 있는 카메라의 성능에 따라서, 제1영상은 Full HD급인 1920*1080보다 더 높은 해상도인 QHD(2560*1440)나 UHD(3840*2160)급의 해상도의 영상이 수신될 수도 있다. 특히, 객체 검출 장치에 수신되는 영상은 단순히 주행 중에 촬영된 영상이 아니라, 주행 중에 일시적으로 정차 하고 있는 상황에서 자동차의 카메라를 통해 촬영되어 생성된 영상일 수 있다. 본 실시예에 따라서 수신된 영상 은 카메라가 장착된 자동차가 일시적으로 정차하고 있는 특성상, 카메라의 촬영 방향 및 각도는 그대로 유지되 어, 정지 중인 물체는 영상내에서 계속 동일한 위치를 유지하고 있는 반면, 움직이는 물체의 위치는 영상의 각 프레임마다 달라지게 된다. 이어서, 객체 검출 장치는 수신된 영상을 객체 검출 모듈(object detector)의 입력데이터로 가공하여 영상속에 있는 객체를 1차적으로 검출하고(S920), 도 7 및 도 8에서 설명한 트래킹 알고리즘을 적용하여(S930), 영상속에 있는 객체를 2차적으로 검출한 후, 단계 S920 및 S930에서 검출한 결과를 통합(association)할 수 있다(S940). 예를 들어, 단계 S920에서 제1프레임, 제2프레임, 제4프레임에서 제1객체가 검출되고, 단계 S930를 통해서, 제3 프레임에서 제1객체가 추가적으로 검출된 것으로 간주되었다면, 단계 S940에서는 제1프레임 내지 제4프레임 모 두에서 제1객체가 검출된 것으로 처리될 수 있다. 이때, 단계 S930을 수행하면서, 프레임별로 객체를 트래킹하고 객체별로 외곽선(2D 바운딩 박스 또는 큐보이드 등)이 생성되었다면, 이때 생성된 정보들은 객체 검출 프로세스의 이력정보(history information)로서, 데이터 베이스에 저장될 수 있다(S960). 객체 검출 장치는 단계 S940의 결과를 프레임별로 분석하여, 검출되었다가 일정한 시점부터 갑자기 검출되지 않 는 객체가 있는지 여부를 판단하고(S950), 그 객체가 정지특성의 물체인지 판단하고(S970), 그 객체가 정지특성 의 물체라고 판단된 경우, 데이터베이스에 저장되어 있는 이력정보를 갱신(update)할 수 있다(S980). 단계 S970에서 정지특성의 물체로 판단되는 객체에는 신호등, 신호 표지판, 간판 등이 포함될 수 있으나, 이에 한정되지 않는다. 또한, 단계 S950에서 검출되지 않는 객체가 있었으나, 그 객체가 정지특성의 물체가 아니라 이동하는 특성을 갖 는 물체인 경우, 도 7 및 도 8에서 설명한 트래킹 알고리즘에 의해서 계속 트래킹되는 물체가 아닌 이상, 그 객 체에 대한 트래킹은 종료되고, 검출된 객체로서의 지위가 상실되도록 데이터베이스의 이력정보가 갱신될 수 있 다. 보다 구체적으로, 객체 검출 장치가 단계 S980에서 수행하는 '객체의 검출이력정보 갱신 프로세스'는 다음과 같 이 이루어질 수 있다. 먼저, 객체 검출 장치는 한번 검출되었다가 일정한 시점부터 갑자기 검출되지 않는 객체 가 정지특성의 물체라면, 정지특성의 물체가 검출되고 있다가 검출되지 않기 시작한 시점의 프레임에서 정지특 성의 물체가 검출된 것으로 이력정보를 갱신할 수 있다. 예를 들어, 정지특성의 물체로 클래스가 분류된 객체가 검출된 프레임의 번호가 1, 2, 3, 6번이고, 4, 5번에서는 그 객체가 검출되지 않았다면, 4, 5번 프레임에서도 객체가 검출된 것으로 간주하고 이력정보가 갱신될 수 있다. 이때, 정지특성을 갖는 객체가 4, 5번 프레임에서 검출되지 않는 이유는 다양할 수 있다. 일 예로서, 정지특성 의 객체가 이동하는 다른 물체에 의해 가려져서 특정 프레임에서 촬영되지 않은 경우가 있을 수도 있다. 또한, 다른 예로서, 정지특성의 객체가 다른 물체에 의해 차폐되지 않고 특정 프레임에서 육안을 통해서 식별이 가능할 정도로 촬영되었더라도, 객체로서 검출되지 않을 수도 있다. 도 6에서 설명한 것처럼, 프레임별로 객체 를 검출하는 프로세스에서 컨볼루션 기법이 반복적으로 사용되는데, 이 과정에서, 영상의 규격(사이즈)이 지속 적으로 작아지고, 주변 배경을 구성하는 사물들의 움직임, 밝기상태(조도, 광도), 색 배치 등 다양한 요인에 의 해서, 객체 검출 프로세스가 정상적으로 동작하지 않을 수 있으며, 그런 경우, 당연히 검출되어야 하는 정지특 성의 객체가 객체 검출 장치에 의해서 검출되지 않을 수도 있다. 결국, 본 발명에 따른 객체 검출 장치는 도 9에서 설명한 프로세스를 통해서, 정지특성을 갖는 객체가 4, 5번 프레임에서 검출되지 않았을 때, 검출된 것으로 이력정보를 갱신하여, 최종적으로는 1~6번 프레임 모두에서 객 체가 검출된 것으로 판단할 수 있다. 도 10은 정지특성을 갖는 객체가 특정한 프레임에서 객체로서 검출되지 않는 과정을 설명하기 위한 도면이다. 도 10의 (a) 내지 (e)는 객체 검출 장치가 수신한 영상에서 5개의 프레임을 순차적으로 나열한 것으로서, 도 10 의 (a)에 도시된 프레임이 i번째 프레임이라면, 도 10의 (e)에 도시된 프레임이 i+4번째 프레임일 수 있다. 도 10에 도시된 5개의 프레임이 서로 다른 시각에 대한 프레임이라는 것은, 각 프레임에 모두 촬영된 자동차가 계 속 이동하면서 위치가 달라지는 것을 보면 알 수 있다. 먼저, 도 10의 (a)에서는 1번 신호등, 2번 신호등, 6번 신호등이 객체로서 검출되어 있고, 도 10의 (b)에서도 1 번 신호등, 2번 신호등, 6번 신호등은 객체로서 계속 검출된 채로 유지된다. 도 10의 (a) 및 (b)에 도시된 결과 에 의해서, 1번 신호등, 2번 신호등, 6번 신호등은 트래킹 알고리즘에 의해서 트래킹되고 있다고 간주한다. 한편, 도 10의 (c)에서는 1번 신호등 및 2번 신호등만 객체로서 검출되었으며, 6번 신호등은 검출되지 않았다. 그리고, 도 10의 (c)에서 검출되지 않기 시작한 6번 신호등은 도 10의 (d) 및 도 10의 (e)에서도 계속 검출되지 않았다. 도 10의 (c) 내지 도 10의 (e)에서, 6번 신호등은 어떠한 물체에 의해서 차폐되지 않아서 정상적으로 촬영되었음에도 1번 신호등 및 2호 신호등과 다르게 객체로서 검출되지 않았으며, 본 발명에 따른 객체 검출 장 치는, 6번 신호등이 검출되지 않기 시작한 최초 프레임인 도 10의 (c)의 프레임을 그 직전 시점의 프레임과 비 교하는 방식으로 6번 신호등이 갑자기 검출되지 않기 시작한 객체라는 것을 파악할 수 있게 된다. 이하에서는, 도 10의 (c)와 같이, 객체로서 검출되고 있던 객체가 갑자기 미검출되기 시작하는 프레임을 '제2프 레임', 도 10의 (b)와 같이, 제2프레임의 바로 직전 시점이어서 제2프레임에서는 검출되고 있지 않은 객체가 마 지막으로 검출된 프레임을 '제1프레임'이라고 각각 약칭하기로 한다.도 11은 전술한 제1프레임 및 제2프레임을 비교하는 일 실시예를 설명하기 위한 도면이다. 객체 검출 장치는 도 10의 (b) 및 도 10의 (c)에 도시된 제1프레임 및 제2프레임 전체를 비교하여 미검출되는 객체를 탐지할 수 있으나, 실시예에 따라서, 도 11의 (a)의 상단영역(1110a) 및 도 11의 (b)의 상단영역(1110 b)을 비교함으로써, 미검출되는 객체를 탐지할 수도 있다. 도 11에 도시된 것처럼, 객체 검출 장치는, 제1프레임 및 제2프레임의 가로중앙선의 상단의 적어도 일부를 크로 핑(cropping)하고, 크로핑된 상단만을 비교함으로써, 연산량을 대폭 줄일 수 있을 뿐만 아니라 더 정확한 비교 결과를 획득할 수 있다. 본 발명에서 정지특성을 갖는 물체(객체)에는 신호등, 신호표지판, 간판 등이 포함되는 데, 정지특성을 갖는 물체는 통상적으로 높은 위치에 있고, 낮은 위치에는 보행자와 차량들의 이동이 많으므로, 프레임의 하단에 있는 정보들은 프레임간의 정지특성의 객체의 유무를 판단하기 위한 비교를 할 때에는 불필요 한 정보가 될 수 있다. 제1프레임 및 제2프레임의 가로중앙선 상단의 영역 일부는 크로핑된 후에 특징 벡터(feature vector)로 임베딩 (embedding)된 후, 다양한 방식을 통해 비교될 수 있다. 일 예로서, 객체 검출 장치는, 제1프레임 및 제2프레임의 크로핑된 영역을 픽셀단위로 하여, Cross-correlation 을 이용하여 비교할 수 있다. 다른 예로서, 객체 검출 장치는, L1, L2디스턴스(L1, L2 distance)방법을 통해서, 제1프레임 및 제2프레임의 크 로핑된 영역을 비교할 수도 있다. L1, L2 디스턴스 방법은 기계학습모델에서 사용되는 행렬데이터 처리 방식으 로서, L1디스턴스는 맨하튼 거리(The Manhattan distance), L2거리는 유클리디언 디스턴스(Euclidean distance)을 각각 의미한다. 그 외의 다른 예로서, 객체 검출 장치는, 연산량을 최소화하기 위해서, 제1프레임 및 제2프레임의 가로중앙선의 상단을 크로핑한 결과를 재차 리사이징(resizing)하여 비교할 수도 있다. 도 12는 본 발명에서 객체의 외곽선에 마진을 적용하여 검출하는 실시예를 설명하기 위한 도면이다. 본 발명에 따른 객체 검출 장치는, 주행 중에 자동차에 설치된 카메라가 촬영한 영상을 획득하고, 영상을 구성 하는 여러 프레임 중에서, 자동차가 일시적으로 정차하고 있는 도중에 촬영된 프레임에서는 마진(margin)을 부 가한, 확장된 외곽선을 검출된 객체마다 설정할 수 있다. 도 12의 (a)를 참조하여 설명하면, 기존 방식에 따른, 도 12의 (a)에는 총 5개의 신호등이 객체로서 검출되었고, 객체 검출 장치는 검출된 신호등별로 제1외곽선(1210A), 제2외곽선(1210B), 제3외곽선(1210C), 제4 외곽선(1210D), 제5외곽선(1210E)을 생성하여, 검출된 객체라는 표시를 할 수 있다. 도 12의 (a)와 같이 기존방 식에 의할 경우, 객체 검출 장치는 각 프레임의 전체 또는 상단 전체별로 비교하므로, 기울어진 도로나 날아가 는 새와 같은 물체가 있을 경우, 정지되어 있는 객체를 잘못 판단할 가능성이 있다. 한편, 본 발명에 따른, 객체 검출 장치는 도 12의 (a) 및 (b)에 도시된 것처럼, 제1확장외곽선(1210A'), 제2확 장외곽선(1210B'), 제3확장외곽선(1210C'), 제4확장외곽선(1210D'), 제5확장외곽선(1210E')을 생성하여, 확장외 곽선별 객체를 비교함으로써, 각 객체에 대해서 개별적으로 정지 여부를 확인하고, 확장된 외곽선별로 동일하여 정지상태라고 판단된 상태에서, 미검출까지 되었다면, 미검출 객체로 인지하고 후속적으로 인식된 객체로 보정 할 수 있다. 위와 같은 방식으로, 본 발명의 일 실시예에 따르면, 확장된 외곽선을 사용하지 않을 경우에 비교 적 작은 크기의 영역을 비교하게 되어 객체 검출 성능이 떨어지는 기존의 문제점을 개선할 수 있게 된다. 여기 서, 외곽선의 확장비율은 수학적, 경험적, 실험적으로 결정된 값이 하이퍼 파라미터(hyper parameter)로서 이용 될 수 있다. 도 12에서 객체 검출 장치가 자동차가 정차하고 있는지 여부를 판단하기 위한 방법의 다른 일 예로서, 객체 검 출 장치는 자동차의 GPS좌표변화 또는 차량에 탑재되어 있는 가속도 센서 등을 참고할 수도 있다. 도 13은 도 7 내지 도 12를 통해 설명한 본 발명의 일 실시예에 따른 방법을 흐름도로 나타낸 도면이다. 이하에서, 이미 설명한 내용과 중복되는 설명은 생략하기로 한다. 객체 검출 장치는, 영상을 수신하고, 수신된 영상의 프레임별로 포함된 객체를 검출할 수 있다(S1310). 객체 검출 장치는 수신된 영상의 제1프레임 및 제1프레임의 다음 프레임인 제2프레임에서의 검출된 객체를 비교 할 수 있다(S1330).객체 검출 장치는, 단계 S1330에서 비교한 결과를 기초로 제1프레임에서 검출되었다가 제2프레임에서 미검출된 객체의 존부를 파악할 수 있다(S1350). 객체 검출 장치는, 파악된 결과를 기초로 제2프레임에서의 객체 검출 결과를 보정할 수 있다(S1370). 단계 S1370에서 객체 검출 결과를 보정한다는 의미는, 도 7 내지 도 10을 통해서 설명한 것처럼, 이력정보를 갱신하 여, 객체가 검출되지 않았던 프레임에서 그 객체가 검출된 것으로 처리하는 것을 의미한다. 도 14는 일 실시예에 따른 객체 검출 장치의 블록도이다. 도 14를 참조하면, 객체 검출 장치는 통신부, 프로세서 및 DB를 포함할 수 있다. 도 14의 객체 검출 장치에는 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 14에 도시된 구성"}
{"patent_id": "10-2023-0091298", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 당해 기술분야의 통상의 기술자라면 이해할 수 있다. 통신부는 외부 서버 또는 외부 장치와 유선/무선 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부(미도시), 이동 통신부(미도시) 및 방송 수신부(미도시) 중 적 어도 하나를 포함할 수 있다. DB는 객체 검출 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있다. DB는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플 래시 메모리를 포함할 수 있다. 프로세서는 객체 검출 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 DB에 저장된 프로그램들을 실행함으로써, 입력부(미도시), 디스플레이(미도시), 통신부, DB 등을 전반적 으로 제어할 수 있다. 프로세서는, DB에 저장된 프로그램들을 실행함으로써, 객체 검출 장치(140 0)의 동작을 제어할 수 있다. 프로세서는 도 6 내지 도 13에서 상술한 객체 검출 장치의 동작 중 적어도 일부를 제어할 수 있다. 일 예로서, 프로세서는 영상을 수신하고, 수신된 영상의 프레임별로 포함된 객체를 검출하고, 수신된 영 상의 제1프레임 및 제1프레임의 다음 프레임인 제2프레임에서의 검출된 객체를 비교하고, 비교한 결과를 기초로 제1프레임에서 검출되었다가 제2프레임에서 미검출된 객체의 존부를 파악하고, 파악된 결과를 기초로 제2프레임 에서의 객체 검출 결과를 보정할 수 있다. 프로세서는 ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 본 발명에 따르면, 정지특성을 갖는 객체 또는 자동차가 주행 중에 정차한 상태에서 촬영된 영상에서 객체를 검 출하는 정확도가 대폭 향상될 수 있다. 이상 설명된 본 발명에 따른 실시 예는 컴퓨터상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명에서 설명하는 특정 실행들은 일 실시 예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아 니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 상기 시스템들의 다른 기능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재들 은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가 능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “필 수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소 가 아닐 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 “상기”의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복 수 모두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하 는 각 개별적인 값을 기재한 것과 같다. 마지막으로, 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하 게 순서를 기재하거나 반하는 기재가 없다면, 상기 단계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계 들의 기재 순서에 따라 본 발명이 한정되는 것은 아니다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이 상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다."}
{"patent_id": "10-2023-0091298", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 4a 및 도 4b는 일 실시예에 따른 차량 외부를 촬영하는 카메라와 관련된 도면이다. 도 5는 일 실시예에 따른 객체 검출 방법을 설명하는 개략도이다. 도 6은 도 4a, 도 4b 및 도 5에서 설명한 객체 검출 장치의 동작 특성 및 한계점을 설명하기 위한 도면이다.도 7은 본 발명에 따른 객체 검출 방법에서 사용되는 트래킹 알고리즘의 일 예를 흐름도로 나타낸 도면이다. 도 8은 도 7에서 설명한 트래킹 알고리즘을 도식적으로 설명한 도면이다. 도 9는 본 발명에 따른 객체 검출 방법의 일 예를 흐름도로 나타낸 도면이다. 도 10은 정지특성을 갖는 객체가 특정한 프레임에서 객체로서 검출되지 않는 과정을 설명하기 위한 도면이다. 도 11은 전술한 제1프레임 및 제2프레임을 비교하는 일 실시예를 설명하기 위한 도면이다. 도 12는 본 발명에서 객체의 외곽선에 마진을 적용하여 검출하는 실시예를 설명하기 위한 도면이다. 도 13은 도 6 내지 도 12를 통해 설명한 본 발명의 일 실시예에 따른 방법을 흐름도로 나타낸 도면이다. 도 14는 일 실시예에 따른 객체 검출 장치의 블록도이다."}
