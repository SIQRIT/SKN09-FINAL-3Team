{"patent_id": "10-2022-0112115", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0071053", "출원번호": "10-2022-0112115", "발명의 명칭": "메타버스 및 인공지능에 기반한 인적성 분석 방법", "출원인": "배영식", "발명자": "배영식"}}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인적성 분석 시스템에서 수행되는 메타버스 및 인공지능에 기반한 인적성 분석 방법은,사용자의 음성 정보, 시각 정보 및 바이오 정보 중 적어도 하나를 취득하는 단계;상기 음성 정보, 시각 정보 및 바이오 정보 중 적어도 하나를 이용하여 상기 사용자의 인적성을 분석하는 단계;상기 사용자의 인적성 분석 결과를 포함하는 사용자별 데이터를 생성하는 단계; 및상기 사용자별 데이터를 이용하여 상기 사용자의 아바타를 생성하는 단계를 포함하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 사용자의 인적성을 분석하는 단계는,상기 음성 정보를 분석하는 단계;상기 음성 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계; 및상기 예측에 기초하여 상기 사용자의 인적성을 추천하는 단계를 포함하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 음성 정보를 분석하는 단계는,상기 음성 정보에서 소음을 제거하고 상기 음성 정보를 정규화하는 단계;상기 음성 정보에 기초하여 시간의 축(timeline)으로 마킹 가능한 음성 데이터를 생성하는 단계; 및상기 음성 정보에 기초하여 속도(tempo), 휴지구간(idle time), 음색(tone) 및 크기(volume) 중 적어도 하나를포함하는 음성 스타일을 생성하는 단계를 포함하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 음성 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는,상기 음성 데이터에 기초하여 상기 사용자의 인적성을 예측하되,상기 음성 데이터를 입력으로 하여, 인적성 종류별로 분류된 학습용 음성 데이터에 의해 학습된 제1 엔진에 의해 상기 사용자의 인적성을 예측하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 음성 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는,상기 음성 스타일에 기초하여 상기 사용자의 인적성을 예측하되,공개특허 10-2023-0071053-3-판독이 용이한 특정 부분에 대한 상기 음성 스타일의 평균치를 입력으로 하여, 인적성 종류별로 분류된 학습용음성 스타일에 의해 학습된 제2 엔진에 의해 상기 사용자의 인적성을 예측하는, 메타버스 및 인공지능에 기반한인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 음성 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는,상기 음성 스타일에 기초하여 상기 사용자의 인적성을 예측하되,일정 시간간격으로 마킹된 상기 음성 스타일을 입력으로 하여, 마킹별 데이터 또는 마킹 구간의 연속 패턴 데이터에 의해 학습된 제3 엔진에 의해 상기 사용자의 인적성을 예측하는, 메타버스 및 인공지능에 기반한 인적성분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항에 있어서,상기 음성 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는,상기 음성 데이터 및 상기 음성 스타일에 기초하여 상기 사용자의 인적성을 예측하되,상기 음성 데이터에 기초하여 예측한 결과 및 상기 음성 스타일에 기초하여 예측한 결과를 통계 처리하여 상기사용자의 인적성을 예측하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 사용자의 인적성을 분석하는 단계는,상기 시각 정보를 분석하는 단계;상기 시각 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계; 및상기 예측에 기초하여 상기 사용자의 인적성을 추천하는 단계를 포함하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 시각 정보를 분석하는 단계는,상기 시각 정보에서 상기 사용자의 얼굴을 인식하고 상기 사용자의 얼굴을 추출하는 단계;상기 시각 정보에 기초하여 특정 영상의 한 장면 또는 상기 특정 영상 전체로서 시간의 축(timeline)으로 마킹가능한 얼굴 데이터를 생성하는 단계; 및상기 시각 정보에 기초하여 얼굴의 모양 및 크기, 눈의 모양 및 위치, 코의 모양 및 위치, 입의 모양 및 위치,귀의 모양 및 위치, 눈썹의 모양 및 위치, 표정, 및 헤어스타일 중 적어도 하나를 포함하는 얼굴 스타일을 생성하는 단계를 포함하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 시각 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는,상기 얼굴 데이터에 기초하여 상기 사용자의 인적성을 예측하되,공개특허 10-2023-0071053-4-상기 얼굴 데이터를 입력으로 하여, 인적성 종류별로 분류된 학습용 얼굴 데이터에 의해 학습된 제4 엔진에 의해 상기 사용자의 인적성을 예측하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 시각 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는,상기 얼굴 스타일에 기초하여 상기 사용자의 인적성을 예측하되,판독이 용이한 상기 특정 영상의 한 장면의 상기 얼굴 스타일에 기초하여 생성한 2D 또는 3D 얼굴 패턴을 입력으로 하여, 인적성 종류별로 분류된 학습용 얼굴 스타일에 의해 학습된 제5 엔진에 의해 상기 사용자의 인적성을 예측하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 시각 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는,상기 얼굴 스타일에 기초하여 상기 사용자의 인적성을 예측하되,상기 특정 영상의 전체에 대하여 시간별로 마킹된 상기 얼굴 스타일에 기초하여 생성한 2D 또는 3D 얼굴 패턴을입력으로 하여, 인적성 종류별로 분류된 학습용 얼굴 스타일에 의해 학습된 제6 엔진에 의해 상기 사용자의 인적성을 예측하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 시각 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는,상기 얼굴 데이터 및 상기 얼굴 스타일에 기초하여 상기 사용자의 인적성을 예측하되,상기 얼굴 데이터에 기초하여 예측한 결과 및 상기 얼굴 스타일에 기초하여 예측한 결과를 통계 처리하여 상기사용자의 인적성을 예측하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서,메타버스 내에서 상기 생성된 아바타의 행동, 대화, 말 또는 글을 반영하여 상기 사용자의 인적성 분석 결과를포함하는 사용자별 데이터를 실시간으로 또는 주기적으로 업데이트하는 단계를 더 포함하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서,멀티모달 행동 패턴 관점에서, 메타버스 내에서 상기 생성된 아바타가 사용하는 말, 대화 또는 글과 아바타의행동-상기 행동은 상기 아바타의 손, 머리, 시선의 움직임을 포함함-을 함께 고려하여 상기 아바타를 사용하는사용자의 관심분야 및 성향 중 적어도 하나를 분석하하는 단계를 더 포함하는, 메타버스 및 인공지능에 기반한인적성 분석 방법."}
{"patent_id": "10-2022-0112115", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자의 음성 정보 및 시각 정보 중 적어도 하나를 취득하는 단계와, 상기 음성 정보 및 상기 시각 정보 및 바 이오 정보 중 적어도 하나를 이용하여 상기 사용자의 인적성을 분석하는 단계와, 상기 사용자의 인적성 분석 결 과를 포함하는 사용자별 데이터를 생성하는 단계와, 상기 사용자별 데이터를 이용하여 상기 사용자의 아바타를 생성하는 단계를 포함하는, 메타버스 및 인공지능에 기반한 인적성 분석 방법이 제공된다."}
{"patent_id": "10-2022-0112115", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인적성 분석 방법에 관한 것으로서, 보다 상세하게는 메타버스 및 인공지능에 기반한 인적성 분석 방 법에 관한 것이다."}
{"patent_id": "10-2022-0112115", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "메타버스(metaverse)는 가상, 초월을 의미하는 '메타(meta)'와 세계, 우주를 의미하는 '유니버스(universe)'의 합성어로서, 3차원에서 실제 생활과 법적으로 인정되는 활동인 직업, 금융, 학습 등이 연결된 가상 세계를 뜻한 다. 즉, 메타버스는 가상현실(VR)보다 한 단계 더 진화한 개념으로, 아바타를 활용해 단지 게임이나 가상현실을 즐기는 데 그치지 않고, 실제 현실과 같은 사회문화적 활동을 할 수 있다는 특징이 있다. 비영리 기술 연구 단체인 ASF(Acceleration Studies Foundation)는 메타버스를 증강현실(augmented reality), 라이프로깅(life logging), 거울세계(mirror worlds) 및 가상세계(virtual worlds)의 네 가지 유형으로 분류한 다. 증강현실은 현실공간에 2D 또는 3D로 표현한 가상의 겹쳐 보이는 물체를 통해 상호작용하는 환경을 의미한다. 사람들에게서 가상세계에 대한 거부감을 줄이고, 몰입감을 높이는 특징을 지닌다. 사용자가 단말기 카메라로 현 재는 유적만 남은 흔적을 촬영하면 디지털로 구축된 과거의 건물이 사용자 단말기에 중첩해 보이는 장면이 증강 현실의 일례이다. 라이프로깅은 사물과 사람에 대한 일상적인 경험과 정보를 캡처하고 저장하고 묘사하는 기술이다. 사용자는 일 상생활에서 일어나는 모든 순간을 텍스트, 영상, 사운드 등으로 캡처하고 그 내용을 서버에 저장하여 정리하고, 다른 사용자들과 공유가 가능하다. 센서가 부착된 스포츠 웨어를 네트워크 연결이 가능한 MP3 플레이어와 연동 하여 달린 거리, 소비 칼로리, 선곡 음악 등의 정보를 저장하고 공유하는 등의 행위가 일상기록의 예시이다. 거울세계는 실제세계를 가능한 한 사실적으로, 있는 그대로 반영하되 정보적으로 확장된 가상세계를 말한다. 대 표적인 예로 구글 어스(Google Earth)를 들 수 있다. 구글 어스는 세계 전역의 위성사진을 모조리 수집하여 일 정 주기로 사진을 업데이트하면서 시시각각 변화하는 현실세계의 모습을 그대로 반영하고 있다. 기술의 발전이 계속될수록 현실이 반영된 거울세계는 점점 현실세계에 근접해갈 것이며, 이는 향후 가상현실의 커다란 몰입적 요소가 된다. 이 같은 거울세계 사용자는 가상세계를 열람함으로써 현실세계에 대한 정보를 얻게 된다. 가상세계는 현실과 유사하거나 혹은 완전히 다른 대안적 세계를 디지털 데이터로 구축한 것이다. 가상세계에서 사용자들은 아바타를 통해 현실세계의 경제적, 사회적 활동과 유사한 활동을 한다는 특징이 있다. 가상세계는 가장 친숙한 형태의 메타버스로서, 온라인 롤플레잉 게임에서부터 샌드박스(SANDBOX), 제페토(ZEPETO), 로블록 스(Roblox)와 같은 생활형 가상세계에 이르기까지 3차원 컴퓨터 그래픽 환경에서 구현되는 커뮤니티를 총칭하는 개념이다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개특허공보 제10-2019-0108523호(2019.09.24.)"}
{"patent_id": "10-2022-0112115", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인적성 검사는 실제 현실에서 사람을 대상으로 실시하고 있어 참여자가 직접 대면하여 진행하지 않으면 쉽게 검 사를 실시하기가 어렵다. 따라서 메타버스에 기반하여 상대적으로 간단하게 인적성 검사를 실시할 수 있는 방법 이 필요하다. 본 발명의 목적은 사용자의 음성 정보 및/또는 시각 정보를 취득하고 인공지능을 이용하여 사용자의 인적성을 분석하여 사용자별 데이터를 생성하며, 사용자별 데이터를 이용하여 메타버스 내에서 활동하는 사용자의 아바타 를 생성할 수 있는 메타버스 및 인공지능에 기반한 인적성 분석 방법을 제공하는 것이다. 본 발명의 다른 목적은 초기 사용자별 데이터를 이용하여 생성한 아바타의 메타버스에서의 말 또는 행동에 따라 실시간으로 인적성을 업데이트할 수 있는 메타버스 및 인공지능에 기반한 인적성 분석 방법을 제공하는 것이다. 본 발명의 또 다른 목적은 사용자의 인적성이 반영된 아바타를 통해 진로, 학습, 커뮤니케이션, 기업의 인사/채 용, 여행 추천, 제품 추천 등 다양한 분야에서 활용할 수 있는 메타버스 및 인공지능에 기반한 인적성 분석 방법을 제공하는 것이다. 다만, 본 발명의 해결하고자 하는 과제는 이에 한정되는 것이 아니며, 본 발명의 사상 및 영역으로부터 벗어나 지 않는 범위에서 다양하게 확장될 수 있을 것이다."}
{"patent_id": "10-2022-0112115", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 인적성 분석 시스템에서 수행되는 메타버스 및 인공지능에 기반한 인적성 분석 방 법은, 사용자의 음성 정보, 시각 정보 및 뇌파, DNA 등의 바이오 정보 중 적어도 하나를 취득하는 단계와, 상기 음성 정보, 시각 정보 중 및 뇌파, DNA 등의 바이오 정보 중 적어도 하나를 이용하여 상기 사용자의 인적성을 분석하는 단계와, 상기 사용자의 인적성 분석 결과를 포함하는 사용자별 데이터를 생성하는 단계와, 상기 사용 자별 데이터를 이용하여 상기 사용자의 아바타를 생성하는 단계를 포함한다. 상기 사용자의 인적성을 분석하는 단계는, 상기 음성 정보를 분석하는 단계와, 상기 음성 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계와, 상기 예측에 기초하여 상기 사용자의 인적성을 추천하는 단 계를 포함할 수 있다. 상기 음성 정보를 분석하는 단계는, 상기 음성 정보에서 소음을 제거하고 상기 음성 정보를 정규화하는 단계와, 상기 음성 정보에 기초하여 시간의 축(timeline)으로 마킹 가능한 음성 데이터를 생성하는 단계와, 상기 음성 정보에 기초하여 속도(tempo), 휴지구간(idle time), 음색(tone) 및 크기(volume) 중 적어도 하나를 포함하는 음성 스타일을 생성하는 단계를 포함할 수 있다. 상기 음성 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는, 상기 음성 데이터에 기초하 여 상기 사용자의 인적성을 예측하되, 상기 음성 데이터를 입력으로 하여, 인적성 종류별로 분류된 학습용 음성 데이터에 의해 학습된 제1 엔진에 의해 상기 사용자의 인적성을 예측할 수 있다. 상기 음성 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는, 상기 음성 스타일에 기초하 여 상기 사용자의 인적성을 예측하되, 판독이 용이한 특정 부분에 대한 상기 음성 스타일의 평균치를 입력으로 하여, 인적성 종류별로 분류된 학습용 음성 스타일에 의해 학습된 제2 엔진에 의해 상기 사용자의 인적성을 예 측할 수 있다. 상기 음성 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는, 상기 음성 스타일에 기초하 여 상기 사용자의 인적성을 예측하되, 일정 시간간격으로 마킹된 상기 음성 스타일을 입력으로 하여, 마킹별 데 이터 또는 마킹 구간의 연속 패턴 데이터에 의해 학습된 제3 엔진에 의해 상기 사용자의 인적성을 예측할 수 있 다. 상기 음성 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는, 상기 음성 데이터 및 상기 음성 스타일에 기초하여 상기 사용자의 인적성을 예측하되, 상기 음성 데이터에 기초하여 예측한 결과 및 상기 음성 스타일에 기초하여 예측한 결과를 통계 처리하여 상기 사용자의 인적성을 예측할 수 있다. 상기 사용자의 인적성을 분석하는 단계는, 상기 시각 정보를 분석하는 단계와, 상기 시각 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계와, 상기 예측에 기초하여 상기 사용자의 인적성을 추천하는 단 계를 포함할 수 있다. 상기 시각 정보를 분석하는 단계는, 상기 시각 정보에서 상기 사용자의 얼굴을 인식하고 상기 사용자의 얼굴을 추출하는 단계와, 상기 시각 정보에 기초하여 특정 영상의 한 장면 또는 상기 특정 영상 전체로서 시간의 축 (timeline)으로 마킹 가능한 얼굴 데이터를 생성하는 단계와, 상기 시각 정보에 기초하여 얼굴의 모양 및 크기, 눈의 모양 및 위치, 코의 모양 및 위치, 입의 모양 및 위치, 귀의 모양 및 위치, 눈썹의 모양 및 위치, 표정, 및 헤어스타일 중 적어도 하나를 포함하는 얼굴 스타일을 생성하는 단계를 포함할 수 있다. 상기 시각 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는, 상기 얼굴 데이터에 기초하 여 상기 사용자의 인적성을 예측하되, 상기 얼굴 데이터를 입력으로 하여, 인적성 종류별로 분류된 학습용 얼굴 데이터에 의해 학습된 제4 엔진에 의해 상기 사용자의 인적성을 예측할 수 있다. 상기 시각 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는, 상기 얼굴 스타일에 기초하 여 상기 사용자의 인적성을 예측하되, 판독이 용이한 상기 특정 영상의 한 장면의 상기 얼굴 스타일에 기초하여 생성한 2D 또는 3D 얼굴 패턴을 입력으로 하여, 인적성 종류별로 분류된 학습용 얼굴 스타일에 의해 학습된 제5 엔진에 의해 상기 사용자의 인적성을 예측할 수 있다.상기 시각 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는, 상기 얼굴 스타일에 기초하 여 상기 사용자의 인적성을 예측하되, 상기 특정 영상의 전체에 대하여 시간별로 마킹된 상기 얼굴 스타일에 기 초하여 생성한 2D 또는 3D 얼굴 패턴을 입력으로 하여, 인적성 종류별로 분류된 학습용 얼굴 스타일에 의해 학 습된 제6 엔진에 의해 상기 사용자의 인적성을 예측할 수 있다. 상기 시각 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는, 상기 얼굴 데이터 및 상기 얼굴 스타일에 기초하여 상기 사용자의 인적성을 예측하되, 상기 얼굴 데이터에 기초하여 예측한 결과 및 상기 얼굴 스타일에 기초하여 예측한 결과를 통계 처리하여 상기 사용자의 인적성을 예측할 수 있다. 상기 사용자의 인적성을 분석하는 단계는, 상기 바이오 정보를 분석하는 단계와, 상기 바이오 정보의 분석 결과 에 기초하여 상기 사용자의 인적성을 예측하는 단계와, 상기 예측에 기초하여 상기 사용자의 인적성을 추천하는 단계를 포함할 수 있다. 상기 바이오 정보를 분석하는 단계는, 시각, 청각, 미각, 촉각 및 후각 중적어도 하나의 다양한 자극에서 반응 하는 뇌파를 특정 시간 동안 취득하여 분석하는 뇌파 분석 단계, DNA 요소별 구조별 특징이 분석된 데이터 정보 맵과 비교하여 고유한 DNA 정보를 분석 하는 DNA 정보 분석 단계를 포함하는 바이오 정보 분석을 포함할 수 있 다. 상기 바이오 정보의 분석 결과에 기초하여 상기 사용자의 인적성을 예측하는 단계는. 축적된 바이오 분석을 통 한 예측 되는 결과들과 비교 분석한 인적성을 예측한 단계를 포함할 수 있다. 상기 인적성 예측에 기초하여 상기 사용자의 인적성을 추천하는 단계는, 하나 이상의 분석을 통해 예측된 인적 성 결과치를 단일 또는 통합 분석을 통해서 최종 추천 인적성을 안내하고 아바타 생성시 적용할 것인지 묻는 단 계를 포함할 수 있다. 상기 메타버스 및 인공지능에 기반한 인적성 분석 방법은 메타버스 내에서 상기 생성된 아바타의 행동, 대화, 말 또는 글을 반영하여 상기 사용자의 인적성 분석 결과를 포함하는 사용자별 데이터를 실시간으로 또는 주기적으로 업데이트하는 단계를 더 포함할수 있다. 상기 메타버스 및 인공지능에 기반한 인적성 분석 방법은 멀티모달 행동 패턴 관점에서, 메타버스 내에서 상기 생성된 아바타가 사용하는 말, 대화 또는 글과 아바타의 행동-상기 행동은 상기 아바타의 손, 머리, 시선의 움 직임을 포함함-을 함께 고려하여 상기 아바타를 사용하는 사용자의 관심분야 및 성향 중 적어도 하나를 분석하 하는 단계를 더 포함할 수 있다. 생성 된 아바타는 인공지능 성질을 가질 수 있으며 사용자 접속 없이도 능동적으로 활동 가능하며 다른 아바타 와 상호작용하여 운영 될 수 있다. 또한 조건에 따라서 다른 곳으로 이동 될 수 있고 복제 될 수 있으며 다양한 실험이나 메타버스(가상화, 디지털트윈화) 구성에 활용 될 수 있다."}
{"patent_id": "10-2022-0112115", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 기술은 다음의 효과를 가질 수 있다. 다만, 특정 실시예가 다음의 효과를 전부 포함하여야 한다거나 다 음의 효과만을 포함하여야 한다는 의미는 아니므로, 개시된 기술의 권리범위는 이에 의하여 제한되는 것으로 이 해되어서는 아니 될 것이다. 전술한 본 발명의 실시예들에 따른 메타버스 및 인공지능에 기반한 인적성 분석 방법에 따르면, 사용자의 음성 정보 및/또는 시각 정보를 취득하고 인공지능을 이용하여 사용자의 인적성을 분석하여 사용자별 데이터를 생성 하며, 사용자별 데이터를 이용하여 메타버스 내에서 활동하는 사용자의 아바타를 생성할 수 있다. 전술한 본 발명의 실시예들에 따른 메타버스 및 인공지능에 기반한 인적성 분석 방법에 따르면, 초기 사용자별 데이터를 이용하여 생성한 아바타의 메타버스에서의 말 또는 행동에 따라 실시간으로 인적성을 업데이트할 수 있다. 전술한 본 발명의 실시예들에 따른 메타버스 및 인공지능에 기반한 인적성 분석 방법에 따르면, 사용자의 인적 성이 반영된 아바타를 인적성 분석을 위한 인공지능의 학습, 커뮤니케이션 서비스 제공, 기업의 채용과정 등 다 양한 분야에서 활용할 수 있다."}
{"patent_id": "10-2022-0112115", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술범위에 포함 되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는 데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 본 발명의 권리범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함한다. 본 출원에서, \"포함하 다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합 한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이"}
{"patent_id": "10-2022-0112115", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다."}
{"patent_id": "10-2022-0112115", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이하에서는 첨부된 도면을 참조하여 본 발명의 바람직한 실시예를 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 사람이 본 발명을 쉽게 실시할 수 있도록 명확하고 상세하게 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 인적성 분석 시스템에서 수행되는 메타버스 및 인공지능에 기반한 인적성 분석 방법의 순서도이다. 도 1을 참조하면, 인적성 분석 시스템에서는, 단계 S110에서, 음성 정보 및 시각 정보 중 적어도 하나를 취득한 다. 음성 정보는 온톨로지(자연어 기계학습) 기반의 음성인식 기술에 의해 취득될 수 있으며, 시각 정보는 사용 자의 글씨체, 사용자가 들고 있는 객체에 표시된 모델명 등의 텍스트 정보, 사용자의 생김새, 표정, 평상시와 힘든 활동을 했을 때의 외형 변화 등의 얼굴 정보, 사용자의 제스처 정보, 사용자가 있고 있는 옷 등의 객체 정 보 등 시각에 의해 판단할 수 있는 정보를 제한 없이 포함할 수 있다. 상기 취득하는 단계에서는 음성 정보 및 시각 정보 이외에 적절한 센서를 활용하여 획득할 수 있는 뇌파, DNA 등 바이오 정보를 포함한 다양한 정보가 더 이용될 수도 있다. 주고 받는 대화, 기록 정보 및 패턴 등도 분석 및 학습 정보로 이용될 수 있다. 인적성 분석 시스템에서는, 단계 S130에서, 사용자의 인적성에 대한 간이 선별 단계로서, 상기 음성 정보, 상기 시각 정보 및 상기 바이오 정보 중 적어도 하나를 이용하여 사용자의 인적성을 분석한다. 구체적으로, 사용자의 음성 정보, 시각 정보 및 바이오 정보 중 적어도 하나를 분석하고, 분석된 데이터를 이용하여 사용자의 인적성 을 1차로 분석할 수 있다. 상기 바이오 정보의 분석은 시각, 청각, 미각, 촉각, 및 후각 중 적어도 하나의 자극 에서 반응하는 뇌파를 특정 시간 동안 취득하여 뇌파 분석을 수행할 수 있다. 또한, 상기 바이오 정보의 분석은DNA 요소별 구조별 특징이 분석된 데이터 정보 맵과 비교하여 고유한 DNA 정보를 분석할 수 있다. 상기 바이오 정보의 경우, 축적된 바이오 분석을 통한 예측 되는 결과들과 비교 분석하여 사용자의 인적성을 예측할 수 있다. 인적성 분석 시스템에서는, 단계 S130에서 1차 분석된 사용자의 인적성은 1차 인적성 데이터이며, 이에 기초하 여 사용자의 인적성을 추천할 수 있다. 예를 들어, 1차 인적성 데이터를 생성하는 경우에는 인공지능 학습을 통 해 관상학적인 측면에서 사용자의 직업이나 인적성을 분석할 수 있다. 즉, 사용자의 얼굴이나 목소리에 대하여 학습된 인공지능을 이용하여 사용자의 음성이나 얼굴 정보에 대하여 사용자의 직업이 대통령 또는 운동선수라고 분석할 수 있으며, 또한 인적성에 대한 1차 인적성 데이터가 분석될 수 있다. 이러한 1차 인적성 데이터는 추후 사용자의 아바타의 행동이나 말에 따라 업데이트되어 2차 인적성 데이터가 생성 될 수 있다. 인적성 분석 시스템에서는, 단계 S150에서, 상기 간이 선별 단계에서의 사용자의 인적성 분석 결과를 포함하는 사용자별 데이터(user data)를 생성한다. 사용자별 데이터는 예를 들어, 사용자의 아이디(ID), 패스워드, 인적 성 분석 결과 데이터를 포함할 수 있다. 사용자별 데이터는 사용자의 음성 데이터, 얼굴 이미지 데이터 자체를 포함한다기 보다는 사용자의 음성 또는 얼굴 이미지를 분석한 데이터를 포함할 수 있다. 여기서의 사용자별 데이터는 아바타의 행동이나 말에 기초하여 분석되어 얻어지는 2차 인적성 데이터 생성 이전 단계에서 임시적으로 취득한 사용자의 사용자 개인별 데이터이다.여기서 상기 사용자별 데이터는 시간축으로 업 데이트될 수 있다. 예를들어, 사용자의 인적성에 대한 간이 선별 단계에서 사용자의 목소리 또는 얼굴등 관상학 적인 측면에서 분석된 데이터를 이후에 시간축으로 인적성 데이터를 계속 갱신하면서 업데이트될 수 있다. 인적성 분석 시스템에서는, 단계 S170에서, 사용자별 데이터를 이용하여 사용자의 아바타를 생성한다. 사용자별 데이터에 따라 아바타의 외형이나 옷차림 등이 결정될 수 있으며, 사용자는 생성된 아바타를 통해 메타버스 내 에서 생활할 수 있다. 인적성 분석 시스템에서는, 단계 S190에서, 상기 아바타를 이용하여 실시간으로 사용자의 인적성을 분석하고, 인공지능을 학습시킨다. 즉, 단계 S130에서 인공지능에 의해 분석된 사용자의 인적성은 고정된 것이 아니다. 최 소의 음성 정보 및/또는 시각 정보에 의해 사용자의 인적성을 간이 선별하여 초기 데이터를 생성하고, 이후 메 타버스 내에서 사용자의 아바타의 행동이나 말을 반영하여 사용자의 인적성 데이터가 실시간으로 또는 주기적으 로 업데이트 될 수 있다. 아바타의 행동을 반영하는 예로서, 아바타가 특정 장소로 이동하는데 뛰어가는지 또는 걸어가는지의 행동에 따 라 사용자의 인적성 데이터가 업데이트 될 수 있다. 또는, 아바타가 특정 장소로 이동하는데 특정장소로 직선 경로를 통해 이동하는지 또는 우회 경로를 통해 우회하여 이동하는지의 행동에 따라 사용자의 인적성 데이터가 업데이트 될 수 있다. 아바타의 말을 반영하는 예로서, 아바타가 사용하는 말, 대화 또는 글에서 주긱적 또는 반복적으로 사용되는 단 어(주어, 목적어, 부사, 조사, 동사)를 중복성 검사를 통해 추출후 아바타를 사용하는 사용자의 관심분야, 성향 을 분석할 수 있다. 멀티모달 행동 패턴 관점에서, 아바타가 사용하는 말, 대화 또는 글과 아바타의 행동(손, 머리, 시선의 움직 임)을 함께 고려하여 아바타를 사용하는 사용자의 관심분야, 성향을 분석할 수 있다. 예를 들어, 아바타가 사용 하는 특정 단어에서 아바타의 손 또는 머리를 흔들거나 더 활발히 움직이는 경우, 아바타의 시선이 가상 공간내 에서 특정 위치 또는 특정한 대상으로 이동하는지, 시선이 멈추는지, 특정 행동의 지속시간등을 고려하여 아바 타를 사용하는 사용자의 관심분야, 성향등을 분석할 수 있다. 한편, 사용자의 행동이나 말이 아닌 아바타의 행동이나 말을 이용하여 인적성 데이터를 업데이트 하는 것이므로, 사용자는 본인의 실제 인적성을 알고 싶은 경우 메타버스 내에서 본인이 실제로 행동 또는 말하는 것 과 동일하게 행동 또는 말할 수 있다. 반면, 사용자가 원하는 인적성을 갖는 아바타를 생성하기 위해 사용자는 본인이 평소에 행동 또는 말하는 것과 다르게 메타버스 내에서 행동 또는 말할 수 있으며, 이를 반영하여 사용 자가 원하는 인적성으로 업데이트 될 수 있다. 분석된 사용자별 데이터 또는 사용자의 아바타를 통해 메타버스 내에서 사용자와 비슷한 인적성을 가진 다른 사 용자와 매칭시키거나 사용자와 반대의 인적성을 가진 다른 사용자와 매칭시키는 등의 방법을 통해 커뮤니케이션 서비스를 제공할 수 있다. 또한, 분석된 사용자별 데이터 또는 사용자의 아바타를 통해 기업의 채용과정의 일부로서 인적성 검사를 실시할 수도 있다. 예컨대, 기업에서 업무 환경을 설정하고, 해당 설정에 따라 메타버스를 구성한 뒤 사용자의 아바타 가 기업이 설정한 업무 환경에 잘 적응하면서 업무를 수행할 수 있는지 검사할 수 있다. 예를들어, 사용자의 아 바타가 근무하는 기업의 업무 환경을 넓은 공간에서 좁은 공간(예: 사람이 북적이는 공간 또는 빛이 안들어오는 공간)으로 업무 공간 설정을 변경한 경우, 사용자의 업무 진척도가 떨어지는지를 검사할 수 있다. 또는, 개발자 의 직무를 가진 사용자의 아바타에게 개발부서가 아닌 영업부서로 기업의 소속부서를 변경한 경우, 사용자의 업 무 적응 정도를 검사할 수 있다. 또한, 예를 들어, 신규 채용 예정자에 대하여, 신규 채용 예정자의 인적성이 반영된 인공지능화된 아바타가 가 상 업무 환경에서 어떻게 활동하는지를 시뮬레이션하여 채용시의 효과를 검증해볼 수 있다. 또한, 예를 들어, 신규 채용 예정자에 대하여, 기업내 부서별로 메타버스에서 신규 채용 예정자의 아바타가 업 무를 수행시 인사 고과 차원에서 업무성과를 평가함으로써 채용시의 효과를 검증해볼 수 있다. 또한, 예를 들어, 기업내 신규 프로젝트를 수행하기 위한 가상의 팀에 기업내 이미 채용된 인력 또는 신규 채용 예정자의 아바타를 넣어 메타버스 공간에서 신규 프로젝트를 수행해보도록 하여 어떤 시너지 효과가 나는지 프 로젝트의 효과를 검증해 볼 수 있다. 현실에서 인적성 검사를 받거나 채용과정이 진행되는 경우와 비교하여 사용자가 직접 검사를 받으러 다니지 않 아도 되므로 효율적인 인적성 검사 또는 채용과정이 이루어질 수 있고, 따라서 기업의 입장에서 ESG(Environmental, Social and Governance) 경영에 기여할 수 있다. 아바타를 생성할 때 분석된 사용자별 데이터가 반영되지만, 사용자별 데이터 자체를 타인에게 공개할지 여부는 사용자의 선택에 의해 결정될 수 있다. 본 발명의 일 실시예에 따른 인적성 분석 방법은 사용자(즉, 사람)의 인적성을 분석하는 것뿐만 아니라 동물이 나 사물의 적성을 분석하는 데 사용될 수도 있다. 전술한 단계 S130, S150, S170 및 S190은 인적성 분석 시스템의 인공지능 엔진에 의해 수행될 수 있으며, 상세 한 동작은 도 2 내지 도 6을 참조하여 후술하기로 한다. 도 2는 본 발명의 일 실시예에 따른 아바타를 생성하기 위한 전체적인 과정을 개략적으로 도시한다. 본 발명의 일 실시예에 따른 인적성 분석 방법은 메타버스 인적성 솔루션으로서 사용자에게 서비스 될 수 있다. 메타버스 인적성 솔루션은 온라인 기반으로 사용자가 실시간으로 접속하면 인적성 분석 서비스를 제공할 수도 있으며, 온라인 접속이 불가능한 경우에는 기존에 저장된 데이터에 기초하여 오프라인으로 인적성 분석 서비스 를 제공할 수도 있다. 추후 오프라인 데이터는 온라인 데이터와 동기화되어 오프라인에서 분석된 결과를 온라인 에 반영할 수도 있다. 메타버스는 현실 세계를 복사한 가상 세계일 수 있으며, 현실과 동일하게 작동하는 디지털 트윈일 수도 있다. 또한 현실을 그대로 반영한 것이 아닌 특수한 목적 또는 상상에 의해 만들어진 세계일 수도 있다. 사용자는 HMD(Head Mounted Display) 등의 VR 장비를 통해 메타버스 공간에 접속하거나 스마트폰, PC 등의 애플 리케이션 또는 브라우저를 통해 메타버스 공간에 접속하는 등 다양한 방법으로 메타버스 공간에 접속할 수 있다. 도 2에 도시된 바와 같이, 사용자가 메타버스 공간에 접속하여 로그인(Login)하면 아바타 생성을 위한 등록 과 정을 진행한다. 등록 과정은 기본 모드(Basic Mode)와 전문가 모드(Expert Mode)로 구성 될 수 있으며, 기본 모드는 음성 정보 및/또는 얼굴 정보를 이용하여 간이 인적성 선별에 의해 아바타를 생성하는 것이고, 전문가 모드는 정밀검사로서 스트롱검사, MLST 학습전략검사, MBTI, 에니어그 램 성격유형검사, 바이오 정보 분석(뇌파 , DNA) 등 다양한 검사에 의해 인적성을 보다 정밀하게 분석하는 것이다. 전문가 모드는 선택 사항으로서 사용자의 선택에 따라 수행 여부가 결정될 수 있다. 인적성 분석은 인공지능 엔진에 의해 수행될 수 있다. 기본 모드에서는 음성 정보 및/또는 얼굴 정보를 분석하고(211, 213), 인공지능 프로세스에 의 해 인적성을 분석하며(231, 233, 235), 그 결과로서 사용자의 인적성을 추천하고, 아바타를 추천한다 . 구체적인 설명은 후술한다. 전문가 모드에서는 전문가 인적성 프로세스에 의해 인적성을 분석하거나, 실제 인적성 검사를 통해 인적성을 분석하며, 그 결과에 따라 인적성을 추천하고, 아바타를 추천한다. 구체적인 설명은 후술한다. 즉, 인공지능 엔진은 음성 정보 및/또는 얼굴 정보를 이용하여 사용자의 인적성을 분석한 후 아 바타를 추천한다. 사용자는 인공지능 엔진에 의해 추천된 아바타를 그대로 자신의 아바타로 사용할 수도 있고, 커스터마이징 할 수도 있다. 아바타가 생성되면, 사용자는 메타버스 세계에 입장하여 자신의 아바타로 메타버스에서 생활하게 된다. 도 3은 본 발명의 일 실시예에 따른 음성 정보를 분석하는 과정을 도시한다. 도 3을 참조하면, 먼저, 음성 정보에서 소음을 제거하고(Noise cancel) 정규화한다(Normalize)(211-1). 즉, 취득된 음성 정보에서 사용자의 음성 이외에 나머지 소리를 없애고 음성 구간을 최대 크기로 보정한다. 다음으로, 음성 정보에 기초하여 시간의 축(timeline)으로 마킹 가능한 음성 데이터(Voice Data)(211-3)를 생성한다. 음성 데이터는 인적성 예측용 입력 데이터로서 전체 음성의 길이를 기준으로 시간의 축으로 마킹 가 능한 데이터를 제공할 수 있으며, 음성 정보의 특정 영역의 일부분 또는 음성 정보의 전체 영역일 수 있다. 상기 시간의 축(timeline)상으로 마킹 가능한 음성 데이터(Voice Data)(211-3)는 예를 들어, 사용자가 말 을 빠르게 하는 구간인지, 말을 느리게 하는 구간인지, 또는 말을 강조하는 구간인지를 음성 패턴 인식을 통해 구분하는데 사용될 수 있다. 상기 시간의 축(timeline)으로 마킹 가능한 음성 데이터(Voice Data)(211-3)는 어 느 시점에 어떤 음성 패턴에 해당되는지를 수작업이 아닌 자동으로 분석되어 마킹될 수 있다. 말을 빠르게 하다 가 천천히 말하는 경우를 말을 강조하는 구간으로 판단할 수 있다. 또는 말을 빠르게 하다가 천천히 말하는 경 우에도 말을 강조하는 구간이 아닐수 있으므로 사용자의 억양 또는 톤이 올라가는지 여부 또는 사용자의 시선등 도 함께 고려하여 사용자가 말을 강조하는 구간인지를 판단할 수 있다. 멀티모달 관점에서, 시간의 축(timeline)상의 특정 구간에서, 사용자의 말 뿐만 아니라 사용자의 손 동작 유무, 시선의 위치등과 같은 행동 데이터를 함께 시간의 축(timeline)으로 마킹할 수 있다. 다음으로, 음성 정보에 기초하여 말하는 속도(voice tempo), 말 중간의 휴지구간(voice idle time), 음색 (tone) 및 크기(volume) 중 적어도 하나를 포함하는 음성 스타일(Voice Style)(211-5)을 생성한다. 음성 스타 일은 인적성 예측용 입력 데이터 또는 시간의 축으로 마킹한 형태의 인적성 예측용 입력 데이터일 수 있다. 도 4는 본 발명의 일 실시예에 따른 음성 정보를 이용하여 인적성을 분석하는 과정을 도시한다. 도 4를 참조하면, 인적성의 예측(231-3)은 음성 데이터(211-3) 및 음성 스타일(211-5) 중 적어도 하나에 기초하 여 수행될 수 있으며, 머신러닝 (또는 딥러닝) 엔진(231-5)을 통해 인적성을 예측하고(231-3) 실시간으로 학습 할 수 있다. 음성 인적성 데이터세트(231-7)는 음성 데이터(211-3)에 따라 인적성이 분류된 데이터 및 음성 스 타일에 따라 인적성이 분류된 데이터 중 적어도 하나를 포함한다. 음성 데이터(211-3)에 기초하여 사용자의 인적성을 예측(231-3)하는 경우, 음성 데이터(211-3)를 입력으로 하여, 인적성 종류별로 분류된 학습용 음성 데이터에 의해 학습된 제1 엔진에 의해 사용자의 인적성을 예측할 수 있다(231-3). 예를 들어, 인적성 종류별로 유사도를 측정하고 유사도가 높은 인적성을 사용자에게 추천할 인 적성 결과로서 예측할 수 있다. 음성 데이터(211-3)에 기초하여 예측된 사용자의 인적성을 사용자게게 추천 하고, 예측된 사용자의 인적성에 상응하는 아바타를 추천한다. 음성 스타일(211-5)에 기초하여 사용자의 인적성을 예측(231-3)하는 경우, 판독이 용이한 특정 부분에 대한 음 성 스타일(211-5)의 평균치를 입력으로 하여, 인적성 종류별로 분류된 학습용 음성 스타일(211-5)에 의해 학습 된 제2 엔진에 의해 사용자의 인적성을 예측할 수 있다(231-3). 예를 들어, 인적성 종류별로 유사도를 측정하고 유사도가 높은 인적성을 사용자에게 추천할 인적성 결과로서 예측할 수 있다. 음성 스타일(211-5)에 기초하여 예측된 사용자의 인적성을 사용자게게 추천하고, 예측된 사용자의 인적성에 상응하는 아바타를 추천한다 . 다른 방식으로서, 음성 스타일(211-5)에 기초하여 사용자의 인적성(231-3)을 예측하는 경우, 일정 시간간격으로 마킹된 음성 스타일(211-5)을 입력으로 하여, 마킹별 데이터 또는 마킹 구간의 연속 패턴 데이터에 의해 학습된 제3 엔진에 의해 상기 사용자의 인적성을 예측할 수 있다(231-3). 예를 들어, 인적성 종류별로 유사도를 측정하 고 전체 마킹의 측정값을 통계화하거나 연속 패턴 분류를 사용자에게 추천할 인적성 결과로서 예측할 수 있다. 음성 데이터(211-3) 및 음성 스타일(211-5) 모두에 기초하여 사용자의 인적성을 예측(231-3)하는 경우, 전술한 제1 엔진에 의해 예측한 결과 및 제2 엔진에 의해 예측한 결과를 통계 처리하여 최종적으로 사용자에게 추천할 인적성을 예측하거나, 제1 엔진에 의해 예측한 결과 및 제3 엔진에 의해 예측한 결과를 통계 처리하여 최종적으 로 사용자에게 추천할 인적성을 예측할 수 있다. 도 5는 본 발명의 일 실시예에 따른 시각 정보를 분석하는 과정을 도시한다. 도 5를 참조하면, 먼저, 시각 정보에서 사용자의 얼굴을 인식하고(Face recognition) 사용자의 얼굴 을 추출한다(Crop). 시각 정보에 두 사람 이상이 있는 경우 대상자를 제외한 다른 사람은 삭제할 수 있으며, 얼 굴이 아닌 부분도 삭제할 수 있다. 다음으로, 시각 정보에 기초하여 특정 영상의 한 장면(Still) 또는 특정 영상 전체(Video)로서 시간의 축 (timeline)으로 마킹 가능한 얼굴 데이터(Face Data)(213-3)를 생성한다. 다음으로, 시각 정보에 기초하여 얼굴의 모양 및 크기(Face Shape/Size), 눈의 모양 및 위치(Eyes Shape/pts), 코의 모양 및 위치(Nose Shape/pts), 입의 모양 및 위치(Mouth Shape/pts), 귀의 모양 및 위치(Ears Shape/pts), 눈썹의 모양 및 위치(Eyebrows Shape/pts), 표정(Facial Expression), 및 헤어스타일(Hair Shape) 중 적어도 하나를 포함하는 얼굴 스타일(Face Style)(213-5)을 생성한다. 이외에도, 얼굴 스타일은 안경, 피어 싱, 수염 등의 별도로 인식한 정보를 더 포함할 수 있다. 얼굴 스타일은 인적성 예측용 입력 데이터 또는 시간 의 축으로 마킹한 형태의 인적성 예측용 입력 데이터일 수 있다. 도 6은 본 발명의 일 실시예에 따른 시각 정보를 이용하여 인적성을 분석하는 과정을 도시한다. 도 6을 참조하면, 인적성의 예측은 얼굴 데이터(213-3) 및 얼굴 스타일(213-5) 중 적어도 하나에 기초하여 수행 될 수 있으며, 머신러닝 (또는 딥러닝) 엔진(233-5)을 통해 인적성을 예측하고 실시간으로 학습할 수 있다(233- 3). 얼굴 인적성 데이터세트(233-7)는 얼굴 데이터(213-3)에 따라 인적성이 분류된 데이터 및 음성 스타일(211- 5)에 인적성이 분류된 데이터 중 적어도 하나를 포함한다. 얼굴 데이터(213-3)에 기초하여 사용자의 인적성을 예측(233-3)하는 경우, 얼굴 데이터(213-3)를 입력으로 하여, 인적성 종류별로 분류된 학습용 얼굴 데이터에 의해 학습된 제4 엔진에 의해 사용자의 인적성을 예측할 수 있으며, 예를 들어, 인적성 종류별로 유사도를 측정하고 유사도가 높은 인적성을 사용자에게 추천할 인적성 결과로서 예측할 수 있다. 얼굴 데이터(213-3)에 기초하여 예측된 사용자의 인적성을 사용자게게 추천하고, 예측된 사용자의 인적성에 상응하는 아바타를 추천한다. 얼굴 스타일(213-5)에 기초하여 사용자의 인적성을 예측(233-3)하는 경우, 판독이 용이한 특정 영상의 한 장면 의 얼굴 스타일에 기초하여 생성한 2D 또는 3D 얼굴 패턴을 입력으로 하여, 인적성 종류별로 분류된 학습용 얼 굴 스타일에 의해 학습된 제5 엔진에 의해 사용자의 인적성을 예측할 수 있다(233-3). 예를 들어, 인적성 종류 별로 유사도를 측정하고 유사도가 높은 인적성을 사용자에게 추천할 인적성 결과로서 예측할 수 있다. 얼굴 스 타일(213-5)에 기초하여 예측된 사용자의 인적성을 사용자게게 추천하고, 예측된 사용자의 인적성에 상응 하는 아바타를 추천한다. 다른 방식으로서, 얼굴 스타일(213-5)에 시초하여 사용자의 인적성을 예측(233-3)하는 경우, 특정 영상의 전체 에 대하여 시간별로 마킹된 얼굴 스타일에 기초하여 생성한 2D 또는 3D 얼굴 패턴을 입력으로 하여, 인적성 종 류별로 분류된 학습용 얼굴 스타일에 의해 학습된 제6 엔진에 의해 사용자의 인적성을 예측할 수 있다(233-3). 예를 들어, 마킹별 유사도를 측정하고 최종 통계화하여 사용자에게 추천할 인적성 결과를 예측할 수 있다. 얼굴 데이터(213-3) 및 얼굴 스타일(213-5) 모두에 기초하여 사용자의 인적성을 예측(233-3)하는 경우, 전술한 제4 엔진에 의해 예측한 결과 및 제5 엔진에 의해 예측한 결과를 통계 처리하여 최종적으로 사용자에게 추천할 인적성을 예측하거나, 제4 엔진에 의해 예측한 결과 및 제6 엔진에 의해 예측한 결과를 통계 처리하여 최종적으 로 사용자에게 추천할 인적성을 예측할 수 있다. 이상에서 도면 및 실시예를 참조하여 설명하였지만, 본 발명의 보호범위가 상기 도면 또는 실시예에 의해 한정 되는 것을 의미하지는 않으며 해당 기술 분야의 숙련된 당업자는 하기의 청구범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 부호의 설명200: 인공지능 엔진"}
{"patent_id": "10-2022-0112115", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 메타버스 및 인공지능에 기반한 인적성 분석 방법의 순서도이다. 도 2는 본 발명의 일 실시예에 따른 아바타를 생성하기 위한 전체적인 과정을 개략적으로 도시한다. 도 3은 본 발명의 일 실시예에 따른 음성 정보를 분석하는 과정을 도시한다. 도 4는 본 발명의 일 실시예에 따른 음성 정보를 이용하여 인적성을 분석하는 과정을 도시한다. 도 5는 본 발명의 일 실시예에 따른 시각 정보를 분석하는 과정을 도시한다. 도 6은 본 발명의 일 실시예에 따른 시각 정보를 이용하여 인적성을 분석하는 과정을 도시한다."}
