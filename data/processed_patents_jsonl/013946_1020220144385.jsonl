{"patent_id": "10-2022-0144385", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0062639", "출원번호": "10-2022-0144385", "발명의 명칭": "전자 장치 및 그의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "이가희"}}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상에 대한 태그를 생성하는 전자 장치에 있어서,디스플레이,메모리,적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,태그를 생성하기 위한 영상을 획득하고,상기 획득된 영상에 기초하여, 상기 영상과 관련된 정보를 획득하고,상기 디스플레이를 통해 표시되는 상기 영상 상에 감지된 제1 터치 제스처에 기초하여, 상기 영상과 관련된 정보 중 상기 제1 터치 제스처와 대응되는 영역을 판단하고, 상기 판단된 영역에 대한 영상과 관련된 정보를 식별하고,상기 식별된 영상과 관련된 정보에 기초하여, 상기 영상에 대한 태그(Tag)를 생성하는 전자 장치."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적어도 하나의 프로세서는,상기 영상에 기초하여 상기 영상에 포함된 적어도 하나의 객체 영역을 구별하고,상기 객체 영역에 대응되는 객체를 식별하고,상기 객체에 기초하여 영상과 관련된 정보를 획득하는 전자 장치."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 적어도 하나의 프로세서는,상기 판단된 제1 터치 제스처와 대응되는 영역을 포함하는 적어도 하나의 객체 영역을 획득하고,상기 적어도 하나의 객체 영역과 대응되는 상기 식별된 객체에 기초하여 상기 터치 제스처와 대응되는 영역에대한 영상과 관련된 정보를 식별하는 전자 장치."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 적어도 하나의 프로세서는,상기 디스플레이를 통해 표시되는 영상 상에 상기 태그를 제1 터치 제스처와 대응되는 영역에 표시하고,제1 터치 제스처와 대응되는 영역을 포함하는 적어도 하나의 객체 영역에서 제2 터치 제스처를 식별하고,상기 제2 터치 제스처에 기초하여 상기 태그를 변경하거나 상기 영상에 대한 태그를 추가하는 전자 장치."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,공개특허 10-2024-0062639-3-상기 적어도 하나의 프로세서는,상기 태그에 기초하여 상기 태그와 관련된 장소를 추천하고,상기 추천된 장소와 사용자의 위치 사이의 거리가 기설정된 거리 이하인지여부를 판단하고,상기 거리가 상기 기설정된 거리 이하이면, 상기 추천한 장소를 디스플레이에 표시하는 전자 장치."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,카메라를 더 포함하고,상기 적어도 하나의 프로세서는,카메라를 통해 획득된 영상을 기초로, 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 포함된 영상이 촬영되는지 판단하고,상기 사용자의 패션, 상기 사용자의 메이크업 및 상기 사용자의 헤어스타일이 촬영될 위치를 디스플레이에 표시하고,상기 사용자의 입력에 기초하여 상기 영상을 획득하는 전자 장치."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 영상과 관련된 정보는 패션과 관련된 정보, 메이크업과 관련된 정보및 헤어스타일과 관련된 정보를 포함하고,상기 적어도 하나의 프로세서는,상기 사용자의 패션, 상기 사용자의 메이크업 및 상기 사용자의 헤어스타일이 포함된 영상이 획득되면, 상기 패션과 관련된 정보, 상기 메이크업과 관련된 정보 및 상기 헤어스타일과 관련된 정보를 판단하고,상기 패션과 관련된 정보와 대응되는 복수의 제1 태그, 상기 메이크업과 관련된 정보와 대응되는 복수의 제2 태그 및 상기 헤어스타일과 관련된 정보와 대응되는 복수의 제3 태그를 생성하는 전자 장치."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 터치 제스처와 대응되는 영역에 대한 영상과 관련된 정보가 상기 메이크업과 관련된 정보이면, 상기복수의 제2 태그와 대응되는 상기 복수의 제1 태그 중 적어도 하나의 태그를 포함하는 복수의 제1 영상 및 상기복수의 제2 태그와 대응되는 상기 복수의 제3 태그 중 적어도 하나의 태그를 포함하는 복수의 제2 영상을 획득하고,상기 복수의 제1 태그, 상기 복수의 제1 영상 및 상기 복수의 제2 영상에 기초하여 상기 패션의 매칭률 및 상기헤어스타일의 매칭률을 판단하는 전자 장치."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 적어도 하나의 프로세서는,상기 복수의 제1 태그, 상기 복수의 제1 영상 및 상기 복수의 제2 영상에 기초하여 상기 패션의 빈도수 및 상기헤어스타일의 빈도수를 산출하고,상기 패션의 빈도수가 기설정된 기준 이상이면, 상기 패션의 매칭률을 낮게 판단하고,상기 헤어스타일의 빈도수가 기설정된 기준 이상이면, 상기 헤어스타일의 매칭률을 낮게 판단하는 전자 장치.공개특허 10-2024-0062639-4-청구항 10 제8항에 있어서,상기 적어도 하나의 프로세서는,상기 패션의 매칭률이 기설정된 비율 이하인 경우, 상기 제2 태그와 대응되는 상기 복수의 제1 태그 중 적어도하나의 태그를 포함하는 상기 기저장된 영상을 획득하고,상기 획득된 기저장된 영상 중 높은 매칭률이 판단되는 영상을 기초로 패션을 추천하는 전자 장치."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상에 대한 태그를 생성하는 전자 장치의 제어 방법에 있어서,태그를 생성하기 위한 영상을 획득하는 단계;상기 획득된 영상에 기초하여, 상기 영상과 관련된 정보를 획득하는 단계;상기 디스플레이를 통해 표시되는 상기 영상 상에 감지된 제1 터치 제스처에 기초하여, 상기 영상과 관련된 정보 중 상기 제1 터치 제스처와 대응되는 영역을 판단하는 단계;상기 판단된 영역에 대한 영상과 관련된 정보를 식별하는 단계; 및상기 식별된 영상과 관련된 정보에 기초하여, 상기 영상에 대한 태그(Tag)를 생성하는 단계를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 영상과 관련된 정보를 획득하는 단계는,상기 영상에 기초하여 상기 영상에 포함된 적어도 하나의 객체 영역을 구별하는 단계;상기 적어도 하나의 객체 영역에 대응되는 객체를 식별하는 단계; 및상기 객체에 기초하여 영상과 관련된 정보를 획득하는 단계를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 판단된 영역에 대한 영상과 관련된 정보를 식별하는 단계는,상기 판단된 제1 터치 제스처와 대응되는 영역을 포함하는 상기 적어도 하나의 객체 영역을 획득하는 단계; 및상기 적어도 하나의 객체 영역과 대응되는 상기 식별된 객체에 기초하여 상기 터치 제스처와 대응되는 영역에대한 영상과 관련된 정보를 식별하는 단계를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 디스플레이를 통해 표시되는 영상 상에 상기 태그를 제1 터치 제스처와 대응되는 영역에 표시하는 단계;제1 터치 제스처와 대응되는 영역을 포함하는 적어도 하나의 객체 영역에서 제2 터치 제스처를 식별하는 단계;및상기 제2 터치 제스처에 기초하여 상기 태그를 변경하거나 상기 영상에 대한 태그를 추가하는 단계를 포함하는전자 장치의 제어 방법."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,공개특허 10-2024-0062639-5-상기 태그에 기초하여 상기 태그와 관련된 장소를 추천하는 단계;상기 추천된 장소와 사용자의 위치 사이의 거리가 기설정된 거리 이하인지여부를 판단하는 단계; 및상기 거리가 상기 기설정된 거리 이하이면, 상기 추천한 장소를 디스플레이에 표시하는 단계를 포함하는 전자장치의 제어 방법."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 태그를 생성하기 위한 영상을 획득하는 단계는,카메라를 통해 획득된 영상을 기초로, 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 포함된 영상이 촬영되는지 판단하는 단계;상기 사용자의 패션, 상기 사용자의 메이크업 및 상기 사용자의 헤어스타일이 촬영될 위치를 디스플레이에 표시하는 단계; 및상기 사용자의 입력에 기초하여 상기 영상을 획득하는 단계를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 영상과 관련된 정보는 패션과 관련된 정보, 메이크업과 관련된 정보및 헤어스타일과 관련된 정보를 포함하고,상기 사용자의 패션, 상기 사용자의 메이크업 및 상기 사용자의 헤어스타일이 포함된 영상이 획득되면, 상기 패션과 관련된 정보, 상기 메이크업과 관련된 정보 및 상기 헤어스타일과 관련된 정보를 판단하는 단계; 및상기 패션과 관련된 정보와 대응되는 복수의 제1 태그, 상기 메이크업과 관련된 정보와 대응되는 복수의 제2 태그 및 상기 헤어스타일과 관련된 정보와 대응되는 복수의 제3 태그를 생성하는 단계를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 제1 터치 제스처와 대응되는 영역에 대한 영상과 관련된 정보가 상기 메이크업과 관련된 정보이면, 상기복수의 제2 태그와 대응되는 상기 복수의 제1 태그 중 적어도 하나의 태그를 포함하는 복수의 제1 영상 및 상기복수의 제2 태그와 대응되는 상기 복수의 제3 태그 중 적어도 하나의 태그를 포함하는 복수의 제2 영상을 획득하는 단계; 및상기 복수의 제1 태그, 상기 복수의 제1 영상 및 상기 복수의 제2 영상에 기초하여 상기 패션의 매칭률 및 상기헤어스타일의 매칭률을 판단하는 단계를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 복수의 제1 태그, 상기 복수의 제1 영상 및 상기 복수의 제2 영상에 기초하여 상기 패션의 빈도수 및 상기헤어스타일의 빈도수를 산출하는 단계;상기 패션의 빈도수가 기설정된 기준 이상이면, 상기 패션의 매칭률을 낮게 판단하는 단계; 및상기 헤어스타일의 빈도수가 기설정된 기준 이상이면, 상기 헤어스타일의 매칭률을 낮게 판단하는 단계를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0144385", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서,상기 패션의 매칭률이 기설정된 비율 이하인 경우, 상기 제2 태그와 대응되는 상기 복수의 제1 태그 중 적어도공개특허 10-2024-0062639-6-하나의 태그를 포함하는 상기 기저장된 영상을 획득하는 단계; 및상기 획득된 기저장된 영상 중 높은 매칭률이 판단되는 영상을 기초로 패션을 추천하는 단계를 포함하는 전자장치의 제어 방법."}
{"patent_id": "10-2022-0144385", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 본개시에 따른 영상에 대한 태그를 생성하는 전자 장치는 디스플레이, 메모리 및 태그를 생성하기 위한 영상을 획득하고, 획득된 영상에 기초하여, 영상과 관련된 정보를 획득하고, 디스플레이를 통해 표시되는 영상 상에 감지된 제1 터치 제스처에 기초하여, 영상과 관련된 정보 중 제1 터치 제스처와 대응되는 영 역을 판단하고, 판단된 영역에 대한 영상과 관련된 정보를 식별하고, 식별된 영상과 관련된 정보에 기초하여, 영 상에 대한 태그(Tag)를 생성하는 적어도 하나의 프로세서를 포함한다."}
{"patent_id": "10-2022-0144385", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 영상을 획득하고, 획득된 영상에 기초하여 영상에 대한 태그를 생성하는 전자 장치에 관한 것이다."}
{"patent_id": "10-2022-0144385", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상에 대한 태그를 생성하는 전자 장치는 컴퓨터, 스마트폰, 태블릿 PC, 노트북 등 다양하게 적용되어 이용될 수 있다. 특히, 전자 장치는 디스플레이에 표시된 영상을 캡쳐하거나, 카메라를 통해 영상을 촬영하여 영상을 획득할 수 있다. 전자 장치는 획득한 영상에 대해 캡쳐하거나 촬영한 사용자의 의도를 반영할 수 있는 태그를 디스플레이에 표시하도록 제어할 수 있다."}
{"patent_id": "10-2022-0144385", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른 영상에 대한 태그를 생성하는 전자 장치에 있어서, 디스플레이, 메모리, 적어도 하 나의 프로세서를 포함한다. 상기 적어도 하나의 프로세서는, 태그를 생성하기 위한 영상을 획득하고, 상기 획득 된 영상에 기초하여, 상기 영상과 관련된 정보를 획득하고, 상기 디스플레이를 통해 표시되는 상기 영상 상에 감지된 제1 터치 제스처에 기초하여, 상기 영상과 관련된 정보 중 상기 제1 터치 제스처와 대응되는 영역을 판 단하고, 상기 판단된 영역에 대한 영상과 관련된 정보를 식별하고, 상기 식별된 영상과 관련된 정보에 기초하여, 상기 영상에 대한 태그(Tag)를 생성한다. 본 개시의 일 실시예에 따른 영상에 대한 태그를 생성하는 전자 장치의 제어 방법에 있어서, 태그를 생성하기 위한 영상을 획득하는 단계; 상기 획득된 영상에 기초하여, 상기 영상과 관련된 정보를 획득하는 단계; 상기 디 스플레이를 통해 표시되는 상기 영상 상에 감지된 제1 터치 제스처에 기초하여, 상기 영상과 관련된 정보 중 상 기 제1 터치 제스처와 대응되는 영역을 판단하는 단계; 상기 판단된 영역에 대한 영상과 관련된 정보를 식별하 는 단계; 및 상기 식별된 영상과 관련된 정보에 기초하여, 상기 영상에 대한 태그(Tag)를 생성하는 단계를 포함 한다. 본 개시의 일 실시예에 따른 영상에 대한 태그를 생성하는 전자 장치의 제어 방법을 실행하기 위한 프로그램을 저장하는 컴퓨터 판독 가능한 기록매체에 있어서, 태그를 생성하기 위한 영상을 획득하는 단계; 상기 획득된 영 상에 기초하여, 상기 영상과 관련된 정보를 획득하는 단계; 상기 디스플레이를 통해 표시되는 상기 영상 상에 감지된 제1 터치 제스처에 기초하여, 상기 영상과 관련된 정보 중 상기 제1 터치 제스처와 대응되는 영역을 판 단하는 단계; 상기 판단된 영역에 대한 영상과 관련된 정보를 식별하는 단계; 및 상기 식별된 영상과 관련된 정 보에 기초하여, 상기 영상에 대한 태그(Tag)를 생성하는 단계를 포함한다."}
{"patent_id": "10-2022-0144385", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 실시 예들은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도면에 예 시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정하려는 것 이 아니며, 본 개시의 실시 예의 다양한 변경(modifications), 균등물(equivalents), 및/또는 대체물 (alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유 사한 참조 부호가 사용될 수 있다. 본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그에 대한 상세한 설명은 생략한다. 덧붙여, 하기 실시 예는 여러 가지 다른 형태로 변형될 수 있으며, 본 개시의 기술적 사상의 범위가 하기 실시 예에 한정되는 것은 아니다. 오히려, 이들 실시 예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본 개시의 기술적 사상을 완전하게 전달하기 위하여 제공되는 것이다. 본 개시에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 권리범위를 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직 접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트 웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 실시 예에 있어서 '모듈' 혹은 '부'는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 '모듈' 혹은 복수의 '부'는 특정 한 하드웨어로 구현될 필요가 있는 '모듈' 혹은 '부'를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하 나의 프로세서로 구현될 수 있다. 한편, 도면에서의 다양한 요소와 영역은 개략적으로 그려진 것이다. 따라서, 본 발명의 기술적 사상은 첨부한 도면에 그려진 상대적인 크기나 간격에 의해 제한되지 않는다. 이하에서는 첨부한 도면을 참고하여 본 개시에 따른 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 도면이다. 도 1을 참조하면, 전자 장치는 영상을 디스플레이에 표시할 수 있다. 구체적으로, 전자 장치는 사용자 입력에 의해 디스플레이에 표시된 영상을 캡쳐하거나, 카메라에 의해 촬영하여 획득된 영상을 디스 플레이에 표시할 수 있다. 디스플레이에 표시된 영상에서 사용자에게 유용한 정보가 포함된 경우, 전 자 장치는 사용자 입력에 의해 디스플레이에 표시된 영상을 캡쳐할 수 있다. 또는, 책 기타 인쇄된 문서에서 사용자에게 유용한 정보가 포함된 경우, 전자 장치는 사용자 입력에 의해 인쇄된 문서에 개시된 정보를 촬영할 수 있다. 이와 같이 획득된 영상은 메모리에 저장하여 보관되는데, 영상의 보관 기간이 오래될수록, 사용자는 영상을 획 득한 의도 또는 목적을 잊어버리는 경우가 많아 유용한 정보를 활용하기 어렵게 된다는 문제가 있다. 영상을 획 득한 의도 또는 목적을 반영하여 태그를 생성하지 않고 영상에 포함된 객체를 인식하여 인식된 모든 객체에 대 한 태그를 생성하는 경우, 영상을 획득한 의도 또는 목적이 불분명하게 된다는 문제가 있다. 또한 획득한 영상 에 대한 태그를 사람의 손으로 작성하게 되는 경우, 시간과 비용이 발생할 수 있는 문제가 있다. 이러한 문제는 영상을 획득한 의도 또는 목적이 반영될 수 있는 태그를 생성하여 해결될 수 있다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 2를 참조하면, 전자 장치는 디스플레이, 메모리 및 적어도 하나의 프로세서를 포함한다. 그러나, 도 2에 도시된 전자 장치의 구성은 일 실시예에 불과할 뿐, 다른 구성이 추가되거나 일 부 구성이 생략될 수 있음은 물론이다. 디스플레이는 다양한 정보를 디스플레이할 수 있다. 특히, 디스플레이는 영상 자체뿐 아니라, 영상과 관련된 정보를 디스플레이할 수 있다. 또한, 디스플레이는 영상에서 생성된 태그와 태그로부터 추천된 컨 텐츠를 디스플레이할 수 있다. 이와 같은 디스플레이는 LCD(Liquid Crystal Display) 패널, OLED(Organic Light Emitting Diodes) 패널, AM-OLED(Active-Matrix Organic Light-Emitting Diode), LcoS(Liquid Crystal on Silicon), QLED(Quantum dot Light-Emitting Diode) 및 DLP(Digital Light Processing), PDP(Plasma Display Panel) 패널, 무기 LED 패널, 마이크로 LED 패널 등 다양한 종류의 디스플레이 패널을 포함할 수 있으 나, 이에 한정되는 것은 아니다. 한편, 디스플레이는 터치 패널과 함께 터치스크린을 구성할 수도 있으며, 플렉서블(flexible) 패널로 이루어질 수도 있다. 메모리는 장치의 구성요소들의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 전자 장치의 구성요소와 관련된 인스트럭션 또는 데이터를 저장할 수 있다. 특히, 메모리는 카메라에 의해 촬영하거나 디스플레이 영상을 캡쳐하여 획득된 영상을 저장할 수 있다. 그리고, 획득된 영상으로부 터 태그를 생성하고, 태그와 관련된 컨텐츠를 추천하기 위하여, 메모리는 도 3에 도시된 바와 같이, 영상 획득 모듈, 영상 정보 획득 모듈, 터치 제스처 판단 모듈, 영상 정보 식별 모듈, 영상 태 그 생성 모듈, 컨텐츠 추천 모듈 및 매칭률 판단 모듈을 포함할 수 있다. 이와 같은 메모리 는, 예를 들어, 주기억장치 및 보조기억장치 중 적어도 하나를 포함할 수 있다. 주기억장치는 롬(ROM) 및/ 또는 램(RAM)과 같은 반도체 저장 매체를 이용하여 구현된 것일 수 있다. 롬은, 예를 들어, 통상적인 롬, 이피 롬(EPROM), 이이피롬(EEPROM) 및/또는 마스크롬(MASK-ROM) 등을 포함할 수 있다. 램은 예를 들어, 디램(DRAM) 및/또는 에스램(SRAM) 등을 포함할 수 있다. 보조기억장치는, 플래시 메모리 장치, SD(Secure Digital) 카드, 솔리드 스테이트 드라이브(SSD, Solid State Drive), 하드 디스크 드라이브(HDD, Hard Disc Drive), 자기 드럼, 컴팩트 디스크(CD), 디브이디(DVD) 또는 레이저 디스크 등과 같은 광 기록 매체(optical media), 자기테 이프, 광자기 디스크 및/또는 플로피 디스크 등과 같이 데이터를 영구적 또는 반영구적으로 저장 가능한 적어도 하나의 저장 매체를 이용하여 구현될 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 적어도 하나의 인스트럭션에 따라 전자 장치를 제어 할 수 있다. 특히, 적어도 하나의 프로세서는 태그를 생성하기 위한 영상을 획득할 수 있다. 그리고, 적어 도 하나의 프로세서는 획득된 영상에 기초하여, 영상과 관련된 정보를 획득할 수 있다. 이후, 디스플레이 를 통해 표시되는 영상 상에 감지된 제1 터치 제스처에 기초하여, 영상과 관련된 정보 중 제1 터치 제스처와 대 응되는 영역을 판단할 수 있다. 그리고, 적어도 하나의 프로세서는 판단된 영역에 대한 영상과 관련된 정 보를 식별하고, 식별된 영상과 관련된 정보에 기초하여 영상에 대한 태그(Tag)를 생성할 수 있다. 구체적으로, 적어도 하나의 프로세서는 영상에 기초하여 영상에 포함된 적어도 하나의 객체 영역을 구별하 고, 객체 영역에 대응되는 객체를 식별할 수 있다. 그리고, 객체에 기초하여 영상과 관련된 정보를 획득할 수 있다. 또한, 적어도 하나의 프로세서는 판단된 제1 터치 제스처와 대응되는 영역을 포함하는 적어도 하나의 객체 영역을 획득할 수 있다. 그리고, 적어도 하나의 프로세서는 적어도 하나의 객체 영역과 대응되는 식별된 객체에 기초하여 판단된 영역에 대한 영상과 관련된 정보를 식별할 수 있다. 그리고, 적어도 하나의 프로세서는 디스플레이를 통해 표시되는 영상 상에 태그를 제1 터치 제스처와 대응되는 영역에 표시할 수 있다. 여기에서, 적어도 하나의 프로세서는 제1 터치 제스처와 대응되는 영역 을 포함하는 적어도 하나의 객체 영역에서 제2 터치 제스처를 식별하고, 제2 터치 제스처에 기초하여 태그를 변 경하거나 영상에 대한 태그를 추가하는 방식으로 태그를 수정할 수 있다. 또한, 적어도 하나의 프로세서는, 태그와 관련된 장소를 추천할 수 있다. 그리고, 적어도 하나의 프로세서 는 추천된 장소와 사용자의 위치 사이의 거리가 기설정된 거리 이하인지여부를 판단하고, 거리가 기설정된 거리 이하이면, 추천한 장소를 디스플레이에 표시할 수 있다. 전자 장치는 카메라를 더 포함할 수 있다. 이때, 적어도 하나의 프로세서는 카메라를 통해 획득된 영 상을 기초로, 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 포함된 영상이 촬영되는지 판단할 수 있다. 적어도 하나의 프로세서는 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 촬영될 위치를 디스플레이에 표시하여 사용자에게 가이드를 제공할 수 있다. 그리고, 적어도 하나의 프로세서는 사용자의 입력에 기초하여 영상을 획득할 수 있다. 그리고, 영상과 관련된 정보는 패션과 관련된 정보, 메이크업과 관련된 정보및 헤어스타일과 관련된 정보를 포 함할 수 있다. 여기에서, 적어도 하나의 프로세서는 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어 스타일이 포함된 영상이 획득되면, 패션과 관련된 정보, 메이크업과 관련된 정보 및 헤어스타일과 관련된 정보 를 판단할 수 있다. 또한, 적어도 하나의 프로세서는 패션과 관련된 정보와 대응되는 복수의 제1 태그, 메이크업과 관련된 정 보와 대응되는 복수의 제2 태그 및 헤어스타일과 관련된 정보와 대응되는 복수의 제3 태그를 생성할 수 있다. 한편, 적어도 하나의 프로세서는 제1 터치 제스처와 대응되는 영역에 대한 영상과 관련된 정보가 메이크업 과 관련된 정보이면, 복수의 제2 태그와 대응되는 복수의 제1 태그 중 적어도 하나의 태그를 포함하는 복수의 제1 영상을 획득할 수 있다. 그리고, 적어도 하나의 프로세서는 복수의 제2 태그와 대응되는 복수의 제3 태그 중 적어도 하나의 태그를 포함하는 복수의 제2 영상을 획득할 수 있다. 그리고, 적어도 하나의 프로세서 는 복수의 제1 태그, 복수의 제1 영상 및 복수의 제2 영상에 기초하여 패션의 매칭률 및 헤어스타일의 매 칭률을 판단할 수 있다. 또한, 적어도 하나의 프로세서는 복수의 제1 태그, 복수의 제1 영상 및 복수의 제2 영상에 기초하여 패션 의 빈도수 및 헤어스타일의 빈도수를 산출할 수 있다. 그리고, 적어도 하나의 프로세서는 패션의 빈도수가 기설정된 기준 이상이면, 패션의 매칭률을 낮게 판단하고, 헤어스타일의 빈도수가 기설정된 기준 이상이면, 헤 어스타일의 매칭률을 낮게 판단할 수 있다. 적어도 하나의 프로세서가 복수의 구성을 통해 태그를 생성하고, 컨텐츠를 추천하는 방법에 대해서는 도 3 을 참조하여 상세히 설명하기로 한다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 태그를 생성하여 컨텐츠를 추천하는 구성을 도시한 블록도이 다. 도 3을 참조하면, 영상 획득 모듈은 태그를 생성하기 위한 영상을 획득할 수 있다. 구체적으로, 영상 획득 모듈은 디스플레이에 표시된 화면을 캡쳐하기 위한 사용자 입력을 수신하여 디스플레이에 표시 된 화면을 메모리에 저장하는 방식으로 영상을 획득할 수 있다. 또한, 영상 획득 모듈은 카메라를 통해 디스플레이에 표시된 화면을 촬영하기 위한 사용자 입력을 수신하여 디스플레이에 표시된 화면을 메모리에 저장하는 방식으로 영상을 획득할 수 있다. 영상 정보 획득 모듈은 획득된 영상에서 객체의 종류를 포함하고 있는지 식별하여 영상과 관련된 정보를 획득할 수 있다. 구체적으로, 영상 정보 획득 모듈은 영상에 포함된 적어도 하나의 객체 영역을 구별할 수 있다. 즉, 객체의 종류가 식별되기 이전에, 영상 정보 획득 모듈은 영상에서 포함된 구별되는 객체들이 영 상에서 차지하는 영역에 대해 우선 판단할 수 있다. 예를 들어, 도 4에 도시된 바와 같이, 영상 정보 획득 모듈은 객체 영역으로 크게 제1 영역 및 제1 영역과 구분되는 제2 영역으로 구별할 수 있다. 여기에서, 영상 정보 획득 모듈은 이미지 영역 에 포함된 적어도 하나의 객체 영역(411, 412, 413, 414)을 구별할 수 있다. 그리고, 영상 정보 획득 모듈은 객체 영역에 대응되는 객체를 식별할 수 있다. 구체적으로, 영상 정보 획 득 모듈은 구별된 객체 영역에 대해 각각 객체의 종류를 식별할 수 있다. 즉, 영상 정보 획득 모듈은 인공지능(AI)또는 컴퓨터 비전 알고리즘을 이용하여 객체 영역에 대응되는 객체를 식별할 수 있다. 예를 들어, 도 5에 도시된 바와 같이, 영상 정보 획득 모듈은 제1 영역을 이미지가 포함된 이미지 영 역으로 식별하고, 제2 영역을 텍스트가 포함된 텍스트 영역으로 식별할 수 있다. 여기에서, 영 상 정보 획득 모듈은 분류 알고리즘, 인공지능(AI)등을 통해 이미지 영역에서 헤어, 얼굴, 바디, 배 경이 식별된 경우, 이미지 영역에 포함된 적어도 하나의 객체 영역(411, 412, 413, 414) 각각을 헤어 영역 , 얼굴 영역, 바디 영역 및 배경 영역으로 식별할 수 있다. 또한, 영상 정보 획득 모듈 은 텍스트 영역에 포함된 텍스트를 키워드 단위(예로, '빌드펌', '어깨길이', '긴머리', '얼굴 형'등)로 식별할 수 있다. 영상 정보 획득 모듈은 식별된 객체에 기초하여 태그를 생성하기 위한 식별된 객체에 대한 카테고리별 태 그 셋을 생성할 수 있다. 여기에서 태그 셋은 식별된 객체의 카테고리에 포함될 수 있는 복수의 태그의 집합이 다. 예를 들어 헤어 카테고리의 태그 셋은 긴머리, 애쉬 카키, 씨컬 펌 등의 태그가 포함될 수 있다. 도 5에서 이미지 영역에서 헤어 영역, 얼굴 영역, 바디 영역 및 배경 영역이 식별된 경우, 영상 정보 획득 모듈은 헤어 카테고리의 태그 셋, 메이크업 카테고리의 태그 셋, 패션 카테고리의 태그 셋, 장소 카테고리의 태그 셋을 생성할 수 있다. 이와 같은 태그 셋은 식별된 객체로부터 생성되거나, 메 모리에 저장되어 이용될 수 있다. 이와 같이, 영상 정보 획득 모듈은 객체 영역, 식별된 객체의 종류 및 카테고리 태그 셋을 영상과 관련된 정보로서 획득할 수 있다. 또한 이와 같이 생성된 카테고리 태그 셋이 복수인 경우, 연관된 카테고리 태그 셋에 포함된 태그가 생성된 영 상이 동시에 디스플레이에 표시될 수 있다. 예를 들어, 패션 카테고리 태그 셋에 포함된 '봄캠핑룩'태그가 생성된 영상 및 구매 카테고리 태그 셋에 포함된 '캠핑의자' 태그가 생성된 영상이 동시에 디스플레이에 표시될 수 있다. 또한 이와 같이 생성된 카테고리 태그 셋은 통신 인터페이스를 통해 다른 사용자와 공유될 수 있다. 이와 같은 패션 카테고리 태그셋, 구매 카테고리 태그셋 등은 영상과 관련된 정보 예시로, 이에 한정하지 않으 며, 식별된 객체의 카테고리에 따라 카테고리 태그 셋이 생성될 수 있다. 터치 제스처 판단 모듈은 디스플레이를 통해 수신된 사용자의 터치 제스처의 종류를 우선 판단할 수 있다. 즉, 터치 제스처 판단 모듈은 터치 제스처로 탭(Tap), 롱 프레스(Long press), 스와이프(Swipe) 등 터치 제스처의 종류를 판단할 수 있다. 그리고, 터치 제스터 판단 모듈은 터치 제스터가 이루어지는 영역 을 판단할 수 있다. 구체적으로, 터치 제스처 판단 모듈은 터치 제스처가 이루어지는 디스플레이상의 좌표를 획득하여 터치 제스터가 이루어지는 영역을 판단할 수 있다. 또한, 터치 제스처 판단 모듈은 터치 제스처가 이루어지는 디스플레이상의 좌표를 획득하여 폐곡선이 그려지는지 판단할 수 있다. 터치 제스처 에 의해 디스플레이상에 폐곡선이 그려지는 것이 판단되면, 폐곡선 내의 영상 정보에 기초하여 영상 태그 가 생성될 수 있다. 영상 정보 식별 모듈은 터치 제스처와 대응되는 영역을 포함하는 적어도 하나의 객체 영역을 획득할 수 있 다. 즉, 영상 정보 식별 모듈은 디스플레이에 표시된 영상 상에 입력되는 터치 제스처가 입력되는 영 역을 판단하고, 터치 제스처가 입력되는 영역이 포함되는 적어도 하나의 객체 영역을 판단할 수 있다. 일 예로,영상 정보 식별 모듈은 사용자로부터 입력된 제1 터치 제스처는 롱 프레스로 판단할 수 있다. 이러한 경우, 영상 정보 식별 모듈은 롱 프레스된 영역과 대응되는 영역은 헤어 영역에 포함됨을 판단하여, 객체 영역으로 헤어 영역영역을 획득할 수 있다. 또한, 영상 정보 식별 모듈은 적어도 하나의 객체 영역과 대응되는 식별된 객체에 기초하여 터치 제스처와 대응되는 영역에 대한 영상과 관련된 정보를 식별할 수 있다. 여기에서, 영상과 관련된 정보는 객체 영역, 식별 된 객체의 종류 및 카테고리 태그 셋 중 적어도 하나에 해당될 수 있다. 일 예로, 영상 정보 식별 모듈은 헤어 영역과 대응되는 객체는 '헤어'에 해당되므로, '헤어'와 관련된 정보를 식별할 수 있다. 즉, 영상 정 보 식별 모듈은 헤어 영역을 식별하여 해당 영역을 태그를 표시할 영역을 획득할 수 있다. 또한, 영 상 정보 식별 모듈은 '헤어'와 관련된 태그를 생성하여 헤어 카테고리 태그 셋에 포함시킬 수 있도록 '헤 어'를 식별하여 영상에서의 헤어 스타일, 헤어 색상, 헤어 길이, 펌의 종류, 헤어의 상태 등과 관련된 정보를 획득할 수 있다. 영상 태그 생성 모듈은 식별된 영상과 관련된 정보에 기초하여, 영상에 대한 태그를 생성할 수 있다. 즉, 영상 태그 생성 모듈은 터치 제스처와 대응되는 영역에 대응되는 객체에 대한 정보 등을 활용하여 태그를 생성할 수 있다. 또한, 영상 태그 생성 모듈은 태그를 생성할 영역에 대한 정보를 활용하여 디스플레이 를 통해 표시되는 영상 상에 태그를 표시할 수 있다. 일 예로, 도 6을 참조하면, 영상 태그 생성 모듈은 제1 터치 제스처와 대응되는 객체 영역은 헤어 영 역으로 판단하여, 헤어 영역내에 태그를 생성할 수 있다. 또한, 영상 태그 생성 모듈은 생성된 태그는 헤어 카테고리의 태그 셋에 포함됨을 디스플레이에 표시할 수 있다. 그리고, 영상 태그 생성 모듈은 헤어 스타일, 헤어 색상, 헤어 길이 등의 관한 정보를 기초로 앞머리, 애쉬 브라운, 빌 드펌 및 중단발을 태그로 생성할 수 있다. 이와 같이 생성한 태그(601, 602, 603, 604)에 대해, 영상 태그 생성 모듈은 디스플레이에 표시할 수 있다. 다른 예로, 도 7a를 참조할 때, 터치 제스처와 대응되는 영역이 패션 영역으로 판단된 경우, 영상 태그 생성 모 듈은 패션 카테고리 태그셋을 영상과 관련된 정보로 식별할 수 있다. 따라서 영상 태그 생성 모듈은 영상 상에 패션과 관련된 태그로, '반묶음, 고데기' 태그, '맨투맨, 캐주얼, 그레이' 태그, '숏팬츠, 캐주얼, 레드'태그, '볼캡, 레드' 태그를 디스플레이에 표시할 수 있다. 영상 태그 생성 모듈은 제1 터치 제스처와 대응되는 영역을 포함하는 적어도 하나의 객체 영역에서 제2 터 치 제스처를 식별할 수 있다. 이 때, 영상 태그 생성 모듈은 제2 터치 제스처에 기초하여 태그를 변경하거 나 영상에 대한 태그를 추가할 수 있다. 일 예로, 도 7b를 참조할 때, 사용자로부터 입력된 제2 터치 제스처 가 식별되면, 영상 태그 생성 모듈은 패션 카테고리 태그 셋에 포함될 수 있는 태그를 추가하고, 이를 표시할 수 있다. 이와 같이 영상 태그 생성 모듈은 제2 터치 제스처에 기초하여 태그를 추가하거나 태그를 변경할 수 있다. 예를 들어, '숏팬츠, 캐주얼, 레드' 태그에 대하여 제2 터치 제스처가 입력되면, 영상 태그 생성 모 듈은 '숏팬츠, 캐주얼, 레드' 태그 중 '캐주얼'을 삭제하거나, '오버핏'으로 변경할 수 있다. 영상 태그 생성 모듈은 제2 터치 제스처에 기초하여 디스플레이에 표시된 카테고리 태그 셋을 다른 카테고리 태그 셋으로 변경할 수 있다. 도 8a를 참조하면, 제1 터치 제스처와 대응되는 영역에 대해 패션 카테 고리 태그가 디스플레이에 표시된 후, 영상 태그 생성 모듈은 제2 터치 제스처의 스와이프 방향에 따 라 장소 카테고리 태그 셋으로 변경하거나, 컨텍스트 카테고리 태그 셋으로 변경할 수 있다. 도 8b를 참조할 때, 2 터치 제스처가 오른쪽 방향의 스와이프이면, 영상 태그 생성 모듈은 컨텍스트 카테고리 태그 셋에 포함된 '바람많이부는날, 구름많은날, 햇살가끔'태그, '자연스러운포즈' 태그 및 '야외 나들이, 4월말, 친구들이랑'태그을 디스플레이에 표시할 수 있다. 컨텐츠 추천 모듈은 생성된 태그에 기초하여 태그와 관련된 컨텐츠를 추천할 수 있다. 컨텐츠 추천 모듈 은 메모리에 저장된 데이터에 기초하여 생성된 태그와 관련된 컨텐츠를 추천할 수 있다. 또는, 컨텐 츠 추천 모듈은 통신 인터페이스를 통해 서버로부터 수신된 데이터에 기초하여 태그와 관련된 컨텐츠를 추 천할 수 있다. 구체적으로, 컨텐츠 추천 모듈은 생성된 태그와 사용자와 관련된 정보를 서버에 전송하고, 사용자와 관련된 정보와 태그에 기초해 추천 컨텐츠를 서버로부터 수신해 태그와 관련된 컨텐츠를 추천할 수 있 다. 여기에서, 사용자와 관련된 정보는 사용자의 위치, 사용자의 성별, 사용자의 관심사 등이 포함될 수 있다. 태그와 관련된 컨텐츠 추천은 생성된 태그가 속한 카테고리에 따라 장소에 대한 추천, 제품 구매처에 대한추천, 사진 촬영하기 위한 포즈에 대한 추천 등이 포함될 수 있다. 일 예로, 생성된 태그가 '앞머리'에 해당하여, 헤어 카테고리 태그셋에 포함된 경우, 컨텐츠 추천 모듈은 앞머리와 관련된 장소를 추천할 수 있다. 즉, 컨텐츠 추천 모듈은 앞머리와 관련된 유명한 미용실을 추천 하거나, 앞머리와 관련되 헤어 제품을 파는 곳을 추천할 수 있다. 여기에서, 컨텐츠 추천 모듈은 추천된 장소와 사용자의 위치 사이의 거리가 기설정된 거리 이하인지 판단 할 수 있다. 그리고, 컨텐츠 추천 모듈은 거리가 기설정된 거리 이하이면, 추천한 장소를 디스플레이(11 0)에 표시할 수 있다. 즉, 앞머리와 관련된 미용실과 사용자의 위치 사이의 거리가 기설정된 거리 이하일 때, 컨텐츠 추천 모듈은 앞머리와 관련하여 추천한 장소가 근처에 있음을 디스플레이에 표시할 수 있다. 이러한 추천과 관련된 개시는 일 예에 해당하며, 이에 한정되지 않는다. 도 9 내지 10은 본 개시의 일 실시 예에 따른 태그를 생성하는 다른 실시 예를 설명하기 위한 도면이다. 도 9를 참조할 때, 터치 제스처 판단 모듈은 제1 터치 제스처에 대응되는 영역은 텍스트 영역으로 판 단할 수 있다. 이러한 경우, 영상 정보 식별 모듈은 이미지 영역에 포함된 객체와 텍스트 영역에 포함된 키워드에 기초하여 이미지 영역에 포함된 객체에 대한 구매 카테고리 태그 셋을 영상과 관련된 정보로 생성할 수 있다. 그리고, 영상 태그 생성 모듈은 텍스트 영역에서 추출한 키워드를 기준으로 제품명, 브랜드명 등 을 태그로 생성할 수 있다. 컨텐츠 추천 모듈은 이와 같은 태그와 그 카테고리를 기초로 해당 제품을 구매 할 수 있는 구매처를 추천할 수 있다. 도 10을 참조할 때, 터치 제스처 판단 모듈은 제1 터치 제스처에 대응되는 영역은 폐곡선 내의 영역 으로 판단할 수 있다. 이러한 경우, 영상 정보 식별 모듈은 이미지 영역에 포함된 객체에 기초하여 촬영 카테고리 태그 셋을 영상과 관련된 정보로 생성할 수 있다. 그리고, 영상 태그 생성 모듈은 '노을' 태그, '한강공원' 태그, '서있는뒷모습' 태그, '한쪽허리손' 태그 및 '허벅지위로' 태그를 생성할 수 있다. 컨텐츠 추 천 모듈은 이와 같은 태그에 기초해 '노을진 한강 공원'에 대한 위치에 대한 정보 및 시간에 대한 정보를 추천할 수 있다. 다른 예로, 터치 제스처 판단 모듈은 제1 터치 제스처에 대응되는 영역은 텍스트 영역으로 판단할 수 있다. 이러한 경우, 영상 정보 식별 모듈은 이미지 영역에 포함된 객체와 텍스트 영역에 포함된 키워드에 기초하여 이미지 영역에 포함된 객체가 음식으로 식별하여, 음식에 대한 장소 카테고리 태그 셋을 영상과 관련 된 정보로 생성할 수 있다. 그리고, 영상 태그 생성 모듈은 텍스트 영역에서 추출한 키워드를 기준으로 음 식점의 위치, 음식점의 명칭 등을 태그로 생성할 수 있다. 컨텐츠 추천 모듈은 이와 같은 태그와 그 카테 고리를 기초로 해당 음식을 판매하는 식당을 추천할 수 있다. 다른 예로, 터치 제스처 판단 모듈은 제1 터치 제스처에 대응되는 영역이 이미지 영역에 해당한다고 판단 한 경우에도, 이미지에 포함된 객체가 사람이 없고, 텍스트만 포함된 경우, 이미지에 포함된 텍스트로 태그가 생성될 수 있다. 즉, 영상 정보 식별 모듈은 이미지 영역에 포함된 텍스트를 식별하고, 해당 텍스트에 포 함된 키워드에 기초하여 장소 카테고리 태그 셋을 영상과 관련된 정보로 생성할 수 있다. 그리고, 영상 태그 생 성 모듈은 텍스트 영역에서 추출한 키워드를 기준으로 음식장의 위치, 음식장의 명칭 등을 태그로 생성할 수 있다. 컨텐츠 추천 모듈은 이와 같은 태그와 그 카테고리를 기초로 해당 음식을 판매하는 식당을 추천 할 수 있다. 매칭률 판단 모듈은 카메라를 통해 획득된 영상을 기초로, 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일 각각의 매칭되는 정도를 판단할 수 있다. 구체적으로, 매칭률 판단 모듈은 카메라를 통해 획득 된 영상을 기초로, 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 포함된 영상이 촬영되는지 판 단할 수 있다. 여기에서, 매칭률 판단 모듈은 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 촬영될 위치 를 디스플레이에 표시할 수 있다. 즉, 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 정확 하게 촬영할 수 있도록 가이드가 제공된다는 것이다. 그리고, 매칭률 판단 모듈은 사용자 입력에 기초하여 영상을 획득할 수 있다. 즉, 획득된 영상은 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 포함된다. 일 예로, 도 11a를 참조하면, 카메라를 통해 획득된 영상에 사용자의 패션, 사용자의 메이크업 및 사용자의 헤 어스타일 중 적어도 하나가 포함된 경우, 매칭률 판단 모듈은 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 포함된 영상이 촬영되는지 판단할 수 있다. 도 11b를 참조하면, 사용자의 메이크업 및 사용자의 헤어스타일이 정확하게 촬영할 수 있도록 가이드가 제공되 기 위해, 매칭률 판단 모듈은 사용자의 패션이 촬영될 위치(1113, 1114, 1115), 사용자의 메이크업 및 사용자의 헤어스타일이 촬영될 위치를 디스플레이에 표시할 수 있다. 이에 더하여 사용자의 악세 서리가 촬영될 위치를 추가적으로 디스플레이에 표시할 수 있다. 이와 같이 사용자의 패션이 촬영될 위치 (1113, 1114, 1115), 사용자의 메이크업 및 사용자의 헤어스타일이 촬영될 위치에 사용자가 위치해 있고, 사용자 입력에 따른 영상이 촬영된 경우, 매칭률 판단 모듈은 영상을 획득할 수 있다. 그리고, 매칭률 판단 모듈은 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 포함된 영상이 획득되면, 패션과 관련된 정보, 메이크업과 관련된 정보 및 헤어스타일과 관련된 정보를 판단할 수 있다. 즉 패 션과 관련된 정보에는 착용된 상의의 종류, 착용된 하의의 종류 및 메고있는 가방의 종류 등에 대한 정보가 포 함될 수 있다. 그리고, 메이크업 과 관련된 정보에는 메이크업의 색상, 진항 정도, 입술 색상 등에 대한 정보가 포함될 수 있다. 그리고, 헤어스타일과 관련된 정보에는 헤어의 길이, 헤어의 두께, 헤어가 풍성한 정도, 헤어 의 색상 등에 대한 정보가 포함될 수 있다. 매칭률 판단 모듈은 패션에 대한 정보를 상술한 패션 카테고리 태그 셋의 형태로 판단할 수 있고, 메이크업에 대한 정보를 메이크업 카테고리 태그 셋의 형태로 판단할 수 있 고, 헤어스타일에 대한 정보는 헤어스타일 카테고리 태그 셋의 형태로 판단할 수 있다. 그리고, 매칭률 판단 모듈은 패션과 관련된 정보와 대응되는 복수의 제1 태그, 메이크업과 관련된 정보와 대응되는 복수의 제2 태그 및 헤어스타일과 관련된 정보와 대응되는 복수의 제3 태그를 생성할 수 있다. 일 예로, 도 12를 참조하면, 매칭률 판단 모듈은 패션과 관련된 정보와 대응되는 복수의 제1 태그(1231, 1232)로 'slim, black, tight, jean, camera bag, small, cross bag, white, price level medium' 등을 생성 할 수 있다. 그리고, 매칭률 판단 모듈은 메이크업과 관련된 정보와 대응되는 복수의 제2 태그로 'cool, oily, no makeup makeup, pink lip'을 생성할 수 있다. 그리고, 매칭률 판단 모듈은 헤어 스타일에 대한 정보에 대응되는 복수의 제3 태그로 'wave, natural, black, medium long'을 생성할 수 있다. 다음으로, 매칭률 판단 모듈은 제1 터치 제스처와 대응되는 영역에 대한 영상과 관련된 정보가 메이크업과 관련된 정보이면, 복수의 제2 태그와 대응되는 복수의 제1 태그 중 하나의 태그를 포함하는 복수의 제1 영상을 획득할 수 있다. 여기에서 복수의 제2 태그와 대응되는 복수의 제1 태그는 특정한 영상에서 복수의 제1 태그가 생성될 때, 동일한 영상에서 복수의 제2 태그가 함께 생성된 태그이다. 그리고, 매칭률 판단 모듈은 제1 터치 제스처와 대응되는 영역에 대한 영상과 관련된 정보가 메이크업과 관련된 정보이면, 복수의 제2 태그와 대응되는 복수의 제3 태그 중 적어도 하나의 태그를 포함하는 복수의 제2 영상을 획득할 수 있다. 여기에서 복수의 제2 태그와 대응되는 복수의 제3 태그는 특정한 영상에서 복수의 제3 태그가 생성될 때, 동일한 영상에서 복수의 제2 태그가 함께 생성된 태그이다. 일 예로, 도 13a를 참조하면, 제1 터치 제스처와 대응되는 영역에 대한 영상과 관련된 정보가 메이크업과 관련된 경우, 매칭률 판단 모듈은 메이크업과 관련된 복수의 제2 태그가 생성될 때 함께 생성된 패 션과 관련된 제1 태그(1231, 1232)를 복수의 제2 태그와 대응되는 복수의 제1 태그로 판단할 수 있다. 그리고, 매칭률 판단 모듈은 메이크업과 관련된 복수의 제2 태그가 생성될 때 함께 생성된 헤어와 관련된 제 3 태그를 복수의 제2 태그와 대응되는 복수의 제3 태그로 판단할 수 있다. 여기에서, 복수의 제1 영상 및 복수의 제2 영상은 사용자에 의해 촬영되어 태그가 생성된 영상에 해당된다. 즉, 복수의 제1 영상 및 복수의 제2 영상은 사용자의 패션, 사용자의 헤어, 사용자의 메이크업이 포함된 영상이고, 패션과 관련된 태그, 헤어와 관련된 태그, 메이크업과 관련된 태그가 포함된 영상에 해당한다. 매칭률 판단 모듈은 복수의 제1 태그, 복수의 제1 영상 및 복수의 제2 영상에 기초하여 패션의 매칭률 및 헤어스타일의 매칭률을 판단할 수 있다. 즉, 매칭률 판단 모듈은 복수의 제1 태그와 복수의 제1 영상에 기 초하여 패션의 매칭률을 판단할 수 있고, 복수의 제1 태그와 복수의 제2 영상에 기초하여 헤어스타일의 매칭률 을 판단할 수 있다. 패션의 매칭률은 복수의 제2 태그와 대응되는 복수의 제1 태그를 포함하는 영상의 수를 전 체 영상의 수로 나눈 비율에 기초하여 계산될 수 있다. 또한 헤어스타일의 매칭률은 복수의 제2 태그와 대응되 는 복수의 제3 태그를 포함하는 영상의 수를 전체 영상의 수로 나눈 비율에 기초하여 계산될 수 있다. 또한, 복수의 제1 영상과 복수의 제2 영상에 대한 평가를 반영하여 이를 함께 고려해 매칭률을 판단할 수 있다. 일 예로, SNS에 업로된 사진에 대하여, 타 사용자들의 호감도 표시(예로, 좋아요, 슬퍼요, 화나요 등)를 반영하여 매칭률이 판단될 수 있다. 한편, 매칭률 판단 모듈은 복수의 제1 태그, 복수의 제1 영상 및 복수의 제2 영상에 기초하여 패션의 빈도 수 및 헤어스타일의 빈도수를 산출할 수 있다. 그리고, 매칭률 판단 모듈은 패션의 빈도수가 기설정된 기 준 이상이면, 패션의 매칭률을 낮게 판단하고, 헤어스타일의 빈도수가 기설정된 기준 이상이면 헤어스타일의 매 칭률을 낮게 판단할 수 있다. 반면, 매칭률 판단 모듈은 패션의 빈도수가 기설정된 기준 이하이면, 패션의 매칭률을 높게 판단하고, 헤어스타일의 빈도수가 기설정된 기준 이하이면 헤어스타일의 매칭률을 높게 판단할 수 있다. 이와 같이 매칭률에 대한 예로, 도 13b를 참조하면, 제1 터치 제스처와 대응되는 영역에 대한 영상과 관 련된 정보가 메이크업과 관련된 정보에 해당하여, 패션의 매칭률(1312, 1313, 1314) 및 헤어스타일의 매칭률 이 판단된 경우, 매칭률 판단 모듈은 디스플레이에 표시할 수 있다. 이 때, 컨텐츠 추천 모듈은 패션의 매칭률과 헤어스타일의 매칭률이 기설정된 비율 이하인지 판단할 수 있 다. 예로, 컨텐츠 추천 모듈은 패션의 매칭률이 기설정된 비율 이하인 경우, 제2 태그와 대응되는 복수의 제1 태그 중 적어도 하나의 태그를 포함하는 기저장된 영상을 획득할 수 있다. 그리고, 컨텐츠 추천 모듈 은 획득된 기저장된 영상 중 높은 매칭률이 판단되는 영상을 기초로 패션을 추천할 수 있다. 여기에서, 헤어스타일의 매칭률이 기설정된 비율 이하인 경우, 컨텐츠 추천 모듈은 제2 태그와 대응되는 복수의 제3 태그 중 적어도 하나의 태그를 포함하는 기저장된 영상을 획득할 수 있다. 그리고, 컨텐츠 추천 모 듈은 획득된 기저장된 영상 중 높은 매칭률이 판단되는 영상을 기초로 헤어스타일을 추천할 수 있다. 일 예로, 도 13b를 참조하면, 패션 중 하의의 매칭률이 3%에 해당하여, 기설정된 비율 이하인 경우, 컨텐 츠 추천 모듈은 복수의 제2 태그와 대응되는 복수의 제1 태그 중 적어도 하나의 태그를 포함 하는 기저장된 영상을 획득할 수 있다. 그리고, 컨텐츠 추천 모듈은 획득된 기저장된 영상 중 높은 매칭률 이 판단되는 영상을 기초로 하의를 추천할 수 있다. 상술한 예시는 제1 터치와 대응되는 영역에 관한 정보가 메이크업인 경우로, 예시적인 설명에 해당하여 이에 한 정되지 않으며, 제1 터치와 대응되는 영역에 관한 정보가 패션, 헤어스타일, 악세서리 등 다양하게 적용 될 수 있다. 한편, 컨텐츠 추천 모듈은 사용자가 자주 가는 장소의 위치와 연령별 선호하는 패션, 헤어스타일, 메이크 업 정보를 기초로 사용자의 패션, 사용자의 헤어스타일, 사용자의 메이크업 등을 추천 할 수 있다. 예를 들어, 사용자가 자주가는 장소가 한강 공원인 경우, 사용자의 연령이 선호하는 패션, 헤어스타일, 메이크업 정보를 획 득하고, 이를 기초로 한강공원에서의 패션, 헤어스타일, 메이크업을 추천할 수 있다. 한편, 매칭률 판단 모듈에서 서로 다른 사용자 사이에서의 패션의 매칭률, 헤어스타일의 매칭률 및 메이크 업의 매칭률을 판단할 수 있다. 이와 같이 서로 다른 사용자 사이에서의 매칭률이 계산되면, 컨텐츠 추천 모듈 은 서로 다른 사용자 사이의 패션의 매칭률, 헤어스타일의 매칭률 및 메이크업의 매칭률 중 적어도 하나가 기설정된 기준 이하인지 여부를 판단할 수 있다. 이와 같이 컨텐츠 추천 모듈은 기설정된 기준 이하의 패 션, 헤어스타일 및 메이크업 중 적어도 하나에 대해 변경할 부분을 추천할 수 있다. 상술한 영상 획득 모듈, 영상정보 획득 모듈, 터치 제스처 판단 모듈, 영상 정보 식별 모듈 , 영상 태그 생성 모듈, 컨텐츠 추천 모듈 및 매칭률 판단 모듈은 인공지능(AI) 모델에 기 초하여 각각의 동작이 수행될 수 있다. 도 14는 본 개시의 일 실시 예에 따른 전자 장치의 세부 구성을 설명하기 위한 블록도이다. 도 14를 참조하면, 전자 장치은 디스플레이, 메모리, 적어도 하나의 프로세서, 적어도 하 나의 센서, 카메라, 입력 인터페이스, 스피커 및 통신 인터페이스가 포함될 수 있다. 이하에서는 도 2에서의 설명과 중복되는 부분에 대한 자세한 설명은 생략하기로 한다. 적어도 하나의 센서은 전자 장치의 작동 상태(예: 전력 또는 온도), 또는 외부의 환경 상태(예: 사용 자 상태)를 감지하고, 감지된 상태에 대응하는 전기 신호 또는 데이터 값을 생성할 수 있다. 즉, 적어도 하나의 센서는 전자 장치의 사용자와 관련된 다양한 정보를 획득할 수 있다. 특히, 카메라는 정지 영상 및 동영상을 촬영할 수 있다. 일 실시 예에 따르면, 카메라는 하나 이상의 렌즈, 이미지 센서, 이미지 시그널 프로세서, 또는 플래시를 포함할 수 있다. 여기에서, 카메라는 사용자 의 패션, 사용자의 메이크업 및 사용자의 헤어스타일을 촬영할 수 있다. 입력 인터페이스는 회로를 포함하며, 전자 장치에서 지원하는 각종 기능을 설정 또는 선택하기 위한 사용자 명령을 입력받을 수 있다. 이를 위해, 입력 인터페이스는 복수의 버튼을 포함할 수 있고, 디스플레 이의 기능을 동시에 수행할 수 있는 터치 스크린으로 구현될 수도 있다. 이 경우, 적어도 하나의 프로세서는 입력 인터페이스를 통해 입력된 사용자 명령에 기초하여 전자 장 치의 동작을 제어할 수 있다. 예를 들어, 적어도 하나의 프로세서는 입력 인터페이스를 통해 입 력된 전자 장치의 온/오프 명령, 전자 장치의 기능의 온/오프 명령 등에 기초하여, 전자 장치를 제어할 수 있다. 스피커는 오디오를 출력할 수 있다. 구체적으로, 적어도 하나의 프로세서는 전자 장치 의 동작 과 관련된 다양한 알림음 또는 음성 안내 메시지를 스피커를 통해 출력할 수 있다. 특히, 스피커는 사용자에게 태그에 기초하여 추천된 장소에 관한 안내 메시지를 사용자에게 출력하거나, 매칭률이 높은 패션, 헤어스타일, 메이크업, 악세서리 등에 관한 안내 메시지를 출력할 수 있다. 통신 인터페이스는, 무선 통신 인터페이스, 유선 통신 인터페이스 또는 입력 인터페이스를 포함할 수 있다. 무선 통신 인터페이스는, 무선 통신 기술이나 이동 통신 기술을 이용하여 각종 외부 장치와 통신을 수행 할 수 있다. 이러한 무선 통신 기술로는, 예를 들어, 블루투스(Bluetooth), 저전력 블루투스(Bluetooth Low Energy), 캔(CAN) 통신, 와이 파이(Wi-Fi), 와이파이 다이렉트(Wi-Fi Direct), 초광대역 통신(UWB, ultrawide band), 지그비(zigbee), 적외선 통신(IrDA, infrared Data Association) 또는 엔에프씨(NFC, Near Field Communication) 등이 포함될 수 있으며, 이동 통신 기술 로는, 3GPP, 와이맥스(Wi-Max), LTE(Long Term Evolution), 5G 등이 포함될 수 있다. 무선 통신 인터페이스는 전자기파를 외부로 송신하거나 또는 외부에서 전 달된 전자기파를 수신할 수 있는 안테나, 통신 칩 및 기판 등을 이용하여 구현될 수 있다. 특히, 통신 인터페이 스를 통해 타 사용자의 호감도 표시를 수신하고, 이를 고려해 매칭률이 판단될 수 있다. 도 15는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 도 15를 참조하면, 영상에 대한 태그를 생성하는 전자 장치의 제어 방법은 태그를 생성하기 위한 영상을 획득할 수 있다(S1501). 그리고, 획득된 영상에 기초하여, 영상과 관련된 정보를 획득할 수 있다(S1502). 이후, 디스플레이를 통해 표시되는 영상 상에 감지된 제1 터치 제스처에 기초하여, 영상과 관련된 정보 중 제1 터치 제스처와 대응되는 영역을 판단할 수 있다(S1503). 다음으로, 판단된 영역과 대응되는 영상과 관련된 정보를 식별할 수 있다(S1504) 그리고, 식별된 영상과 관련된 정보에 기초하여, 영상에 대한 태그(Tag)를 생성할 수 있다(S1505). S1502단계는, 영상에 기초하여 영상에 포함된 적어도 하나의 객체 영역을 구별할 수 있다. 그리고, 적어도 하나의 객체 영역에 대응되는 객체를 식별할 수 있다. 그리고, 객체에 기초하여 영상과 관련된 정보를 획득할 수 있다. S1504단계는, 판단된 제1 터치 제스처와 대응되는 영역을 포함하는 적어도 하나의 객체 영역을 획득할 수 있다. 그리고, 적어도 하나의 객체 영역과 대응되는 식별된 객체에 기초하여 터치 제스처와 대응되는 영역에 대한 영 상과 관련된 정보를 식별할 수 있다. 또한, 디스플레이를 통해 표시되는 영상 상에 태그를 제1 터치 제스처와 대응되는 영역에 표시할 수 있다. 여기에서, 제1 터치 제스처와 대응되는 영역을 포함하는 적어도 하나의 객체 영역에서 제2 터치 제스처를 식별 할 수 있다. 그리고, 2 터치 제스처에 기초하여 태그를 변경하거나 영상에 대한 태그를 추가할 수 있다. 한편, 태그에 기초하여 태그와 관련된 장소를 추천할 수 있다. 그리고, 추천된 장소와 사용자의 위치 사이의 거리가 기설정된 거리 이하인지 여부를 판단할 수 있다. 이후, 거리가 기설정된 거리 이하이면, 추천한 장소를 디스플레이에 표시할 수 있다. 한편, S1501단계는, 카메라를 통해 획득된 영상을 기초로, 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어 스타일이 포함된 영상이 촬영되는지 판단할 수 있다. 그리고, 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 촬영될 위치를 디스플레이에 표시할 수 있다. 또한, 사용자의 입력에 기초하여 영상을 획득할 수 있다. 여기에서, 영상과 관련된 정보는 패션과 관련된 정보, 메이크업과 관련된 정보및 헤어스타일과 관련된 정보를 포함할 수 있다. 그리고, 사용자의 패션, 사용자의 메이크업 및 사용자의 헤어스타일이 포함된 영상이 획득되면, 패션과 관련된 정보, 메이크업과 관련된 정보 및 헤어스타일과 관련된 정보를 판단할 수 있다. 이후, 패션과 관련된 정보와 대응되는 복수의 제1 태그, 메이크업과 관련된 정보와 대응되는 복수의 제2 태그 및 헤어스타일과 관련된 정보와 대응되는 복수의 제3 태그를 생성할 수 있다. 그리고, 제1 터치 제스처와 대응되는 영역에 대한 영상과 관련된 정보가 메이크업과 관련된 정보이면, 복수의 제2 태그와 대응되는 복수의 제1 태그 중 적어도 하나의 태그를 포함하는 복수의 제1 영상 및 복수의 제2 태그 와 대응되는 복수의 제3 태그 중 적어도 하나의 태그를 포함하는 복수의 제2 영상을 획득할 수 있다. 그리고, 복수의 제1 태그, 복수의 제1 영상 및 복수의 제2 영상에 기초하여 패션의 매칭률 및 헤어스타일의 매 칭률을 판단할 수 있다. 한편, 복수의 제1 태그, 복수의 제1 영상 및 복수의 제2 영상에 기초하여 패션의 빈도수 및 헤어스타일의 빈도 수를 산출할 수 있다. 여기에서, 패션의 빈도수가 기설정된 기준 이상이면, 패션의 매칭률을 낮게 판단할 수 있다. 또한, 헤어스타일의 빈도수가 기설정된 기준 이상이면, 헤어스타일의 매칭률을 낮게 판단할 수 있다. 그리고, 패션의 매칭률이 기설정된 비율 이하인 경우, 제2 태그와 대응되는 복수의 제1 태그 중 적어도 하나의 태그를 포함하는 기저장된 영상을 획득할 수 있다. 그리고, 획득된 기저장된 영상 중 높은 매칭률이 판단되는 영상을 기초로 패션을 추천할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 전자 장치의 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU(Central Processing Unit), GPU(Graphic Processing Unit), NPU(Neural Processing Unit) 중 적어도 하나를 포함할 수 있으나 전술한 프로세서의 예시에 한정되지 않는다. CPU는 일반 연산뿐만 아니라 인공지능 연산을 수행할 수 있는 범용 프로세서로서, 다계층 캐시(Cache) 구조를 통해 복잡한 프로그램을 효율적으로 실행할 수 있다. CPU는 순차적인 계산을 통해 이전 계산 결과와 다음 계산 결과의 유기적인 연계가 가능하도록 하는 직렬 처리 방식에 유리하다. 범용 프로세서는 전술한 CPU로 명시한 경 우를 제외하고 전술한 예에 한정되지 않는다. GPU는 그래픽 처리에 이용되는 부동 소수점 연산 등과 같은 대량 연산을 위한 프로세서로서, 코어를 대량으로 집적하여 대규모 연산을 병렬로 수행할 수 있다. 특히, GPU는 CPU에 비해 컨볼루션(Convolution) 연산 등과 같 은 병렬 처리 방식에 유리할 수 있다. 또한, GPU는 CPU의 기능을 보완하기 위한 보조 프로세서(co-processor)로 이용될 수 있다. 대량 연산을 위한 프로세서는 전술한 GPU로 명시한 경우를 제외하고 전술한 예에 한정되지 않 는다. NPU는 인공 신경망을 이용한 인공지능 연산에 특화된 프로세서로서, 인공 신경망을 구성하는 각 레이어를 하드 웨어(예로, 실리콘)로 구현할 수 있다. 이때, NPU는 업체의 요구 사양에 따라 특화되어 설계되므로, CPU나 GPU 에 비해 자유도가 낮으나, 업체가 요구하기 위한 인공지능 연산을 효율적으로 처리할 수 있다. 한편, 인공지능 연산에 특화된 프로세서로, NPU 는 TPU(Tensor Processing Unit), IPU(Intelligence Processing Unit), VPU(Vision processing unit) 등과 같은 다양한 형태로 구현 될 수 있다. 인공 지능 프로세서는 전술한 NPU로명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 또한, 하나 또는 복수의 프로세서는 SoC(System on Chip)으로 구현될 수 있다. 이때, SoC에는 하나 또는 복수 의 프로세서 이외에 메모리, 및 프로세서와 메모리 사이의 데이터 통신을 위한 버스(Bus)등과 같은 네트워크 인 터페이스를 더 포함할 수 있다. 전자 장치에 포함된 SoC(System on Chip)에 복수의 프로세서가 포함된 경우, 전자 장치는 복수의 프로세서 중 일부 프로세서를 이용하여 인공지능과 관련된 연산(예를 들어, 인공지능 모델의 학습(learning)이나 추론 (inference)에 관련된 연산)을 수행할 수 있다. 예를 들어, 전자 장치는 복수의 프로세서 중 컨볼루션 연산, 행 렬 곱 연산 등과 같은 인공지능 연산에 특화된 GPU, NPU, VPU, TPU, 하드웨어 가속기 중 적어도 하나를 이용하 여 인공지능과 관련된 연산을 수행할 수 있다. 다만, 이는 일 실시예에 불과할 뿐, CPU 등과 범용 프로세서를 이용하여 인공지능과 관련된 연산을 처리할 수 있음은 물론이다. 또한, 전자 장치는 하나의 프로세서에 포함된 멀티 코어(예를 들어, 듀얼 코어, 쿼드 코어 등)를 이용하여 인공 지능과 관련된 기능에 대한 연산을 수행할 수 있다. 특히, 전자 장치는 프로세서에 포함된 멀티 코어를 이용하 여 병렬적으로 컨볼루션 연산, 행렬 곱 연산 등과 같은 인공 지능 연산을 수행할 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 기정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 다수의 학습 데이터들에 학습 알고리즘을 적용함으로써, 원하는 특성 의 기정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 적어도 하나의 레이어는 적어도 하나의 가중치 (weight values)dd을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 적어도 하나의 정의된 연산을 통해 레 이어의 연산을 수행한다. 신경망의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks), Transformer가 있으며, 본 개시에서의 신경망은 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨대, 로봇)을 훈련시켜 소정의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 방법이다. 학습 알고리즘의 예로는, 지도형 학습 (supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또 는 강화 학습(reinforcement learning)이 있으며, 본 개시에서의 학습 알고리즘은 명시한 경우를 제외하고 전술 한 예에 한정되지 않는다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기 기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 기기를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프 리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구 적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시 예에 따르면, 본 문서에 개시된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치 들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스 토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시 적으로 생성될 수 있다.이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2022-0144385", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형 실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2022-0144385", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 도면, 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 도시한 블록도, 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 태그를 생성하여 컨텐츠를 추천하는 구성을 도시한 블록도, 도 4 내지 6은 본 개시의 일 실시 예에 따른 태그를 생성하는 실시예를 설명하기 위한 도면, 도 7 내지 8은 본 개시의 일 실시 예에 따른 태그를 수정하는 실시예를 설명하기 위한 도면,도 9 내지 10은 본 개시의 일 실시 예에 따른 태그를 생성하는 다른 실시예를 설명하기 위한 도면, 도 11 내지 13은 본 개시의 일 실시 예에 따른 매칭률을 설명하기 위한 도면, 도 14는 본 개시의 일 실시 예에 따른 전자 장치의 세부 구성을 설명하기 위한 블록도, 도 15는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
