{"patent_id": "10-2023-0032849", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0001021", "출원번호": "10-2023-0032849", "발명의 명칭": "이미지 렌더링 방법, 장치, 전자 설비 및 저장 매체", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "리우 싱"}}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지 렌더링 방법으로서,환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이미지를 얻는 단계;타겟 물체의 NeRF(Neural Radiance Field)에 기반하여, 타겟 물체 모델 및 타겟 시점에서의 타겟 물체 이미지를결정하는 단계;상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는 단계를 포함하는 것을 특징으로 하는 이미지 렌더링 방법."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는 단계는,상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 법선 방향을 결정하는 단계;타겟 시점, 환경 광 및 상기 타겟 정점의 법선 방향에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지를 얻는 단계; 조도가 조절된 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링 하는 단계를 포함하는 것을 특징으로 하는 이미지 렌더링 방법."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 타겟 시점, 환경 광 및 상기 타겟 정점의 법선 방향에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지를 얻는 단계는,타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 정점의 법선 방향을 변환하여, 변환된 타겟 정점의 법선방향을 얻는 단계;환경 광 및 변환된 타겟 정점의 법선 방향에 따라 타겟 정점의 명암도를 결정하는 단계;상기 타겟 정점의 명암도에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체이미지를 얻는 단계를 포함하는 것을 특징으로 하는 이미지 렌더링 방법."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는 단계는,상기 타겟 시점과 상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 깊이 정보를 결정하는 단계;상기 타겟 정점의 깊이 정보에 따라 타겟 물체와 환경 물체 간의 차폐 관계를 결정하는 단계;상기 차폐 관계에 따라 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는 단계를 포함하는 것을 특징으로 하는 이미지 렌더링 방법."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0001021-3-제4항에 있어서,상기 타겟 시점과 상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 깊이 정보를 결정하는 단계는,타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 물체 모델을 변환하여 변환된 타겟 물체 모델을 얻는단계;타겟 시점의 카메라 투영 매트릭스를 사용하여 변환된 타겟 물체 모델을 투영하여 타겟 물체 모델의 타겟 정점의 깊이 정보를 얻는 단계를 포함하는 것을 특징으로 하는 이미지 렌더링 방법."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 타겟 정점의 깊이 정보에 따라 타겟 물체와 환경 물체 간의 차폐 관계를 결정하는 단계는,타겟 물체 모델의 각 픽셀에서의 타겟 정점의 깊이 정보와 대응하는 픽셀에서의 환경 물체의 깊이 정보를 비교하는 단계;상기 타겟 정점의 깊이 정보가 상기 환경 물체의 깊이 정보보다 작으면, 상기 타겟 정점이 해당 픽셀에서의 환경 물체에 차폐되지 않도록 상기 차폐 관계를 결정하는 단계를 포함하는 것을 특징으로 하는 이미지 렌더링 방법."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 타겟 물체의 NeRF에 기반하여, 타겟 물체 모델 및 타겟 시점에서의 타겟 물체 이미지를 결정하는 단계는,상기 타겟 물체의 NeRF로부터 타겟 물체의 점군 모델을 얻고, 상기 타겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모델을 얻는 단계;상기 타겟 물체의 NeRF에 기반하여, 타겟 시점의 모델 뷰 매트릭스 및 카메라 투영 매트릭스를 사용하여 타겟시점에서의 타겟 물체 이미지를 얻는 단계를 포함하는 것을 특징으로 하는 이미지 렌더링 방법."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 타겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모델을 얻는 단계는,마칭 큐브(Marching Cube) 알고리즘에 기반하여 상기 타겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모델을 얻는 단계를 포함하는 것을 특징으로 하는 이미지 렌더링 방법."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 타겟 물체의 NeRF는,수집 시점에서 타겟 물체에 대해 데이터를 수집하여 타겟 물체의 2차원 이미지 및 타겟 물체의 3차원 점군을 얻고;상기 타겟 물체의 2차원 이미지 및 상기 타겟 물체의 3차원 점군을 융합하여 타겟 물체의 융합 이미지를 얻고;상기 타겟 물체의 융합 이미지 및 상기 수집 시점에 따라 상기 타겟 물체의 NeRF를 결정하는 방식에 의해 결정되는 것을 특징으로 하는 이미지 렌더링 방법."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2024-0001021-4-이미지 렌더링 장치로서,환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이미지를 얻는데 사용되는 환경 물체 모듈;타겟 물체의 NeRF에 기반하여, 타겟 물체 모델 및 타겟 시점에서의 타겟 물체 이미지를 결정하는데 사용되는 타겟 물체 모듈; 상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는데 사용되는 융합 렌더링 모듈을 포함하는 것을 특징으로 하는 이미지 렌더링 장치."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 융합 렌더링 모듈은,상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 법선 방향을 결정하는데 사용되는 타겟 법선 유닛;타겟 시점, 환경 광 및 상기 타겟 정점의 법선 방향에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지를 얻는데 사용되는 조도 조절 유닛;조도가 조절된 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는데 사용되는 조도 렌더링 유닛을 포함하는 것을 특징으로 하는 이미지 렌더링 장치."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 조도 조절 유닛은,타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 정점의 법선 방향을 변환하여 변환된 타겟 정점의 법선 방향을 얻는데 사용되는데 사용되는 법선 변환 서브 유닛;환경 광과 변환된 타겟 정점의 법선 방향에 따라 타겟 정점의 명암도를 결정하는데 사용되는 명암도 서브 유닛;상기 타겟 정점의 명암도에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체이미지를 얻는데 사용되는 조도 조절 서브 유닛을 포함하는 것을 특징으로 하는 이미지 렌더링 장치."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 융합 렌더링 모듈은,상기 타겟 시점과 상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 깊이 정보를 결정하는데 사용되는깊이 정보 유닛;상기 타겟 정점의 깊이 정보에 따라 타겟 물체와 환경 물체 간의 차폐 관계를 결정하는데 사용되는 차폐 관계유닛;상기 차폐 관계에 따라 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는데 사용되는 차폐 렌더링 유닛을 포함하는 것을 특징으로 하는 이미지 렌더링 장치."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 깊이 정보 유닛은,공개특허 10-2024-0001021-5-타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 물체 모델을 변환하여 변환된 타겟 물체 모델을 얻는데 사용되는 모델 변환 서브 유닛;타겟 시점의 카메라 투영 매트릭스를 이용하여 변환된 타겟 물체 모델을 투영하여 타겟 물체 모델의 타겟 정점의 깊이 정보를 얻는데 사용되는 깊이 정보 서브 유닛을 포함하는 것을 특징으로 하는 이미지 렌더링 장치."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 차폐 관계 유닛은,타겟 물체 모델의 각 픽셀에서의 타겟 정점의 깊이 정보와 대응하는 픽셀에서의 환경 물체의 깊이 정보를 비교하는데 사용하는 깊이 비교 서브 유닛;상기 타겟 정점의 깊이 정보가 상기 환경 물체의 깊이 정보보다 작은 경우, 상기 타겟 정점이 해당 픽셀에서의환경 물체에 차폐되지 않도록 상기 차폐 관계를 결정하는데 사용되는 차폐 관계 서브 유닛을 포함하는 것을 특징으로 하는 이미지 렌더링 장치."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항 또는 제15항 중 어느 한 항에 있어서,상기 타겟 물체 모듈은,상기 타겟 물체의 NeRF로부터 타겟 물체의 점군 모델을 얻고, 상기 타겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모델을 얻는데 사용되는 타겟 모델 유닛;상기 타겟 물체의 NeRF를 기반으로 타겟 시점의 모델 뷰 매트릭스와 카메라 투영 매트릭스를 사용하여 타겟 시점에서의 타겟 물체 이미지를 결정하는데 사용되는 타겟 이미지 유닛을 포함하는 것을 특징으로 하는 이미지 렌더링 장치."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "상기 타겟 모델 유닛은 구체적으로,마칭 큐브 알고리즘에 기반하여, 상기 타겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모델을 얻는데 사용되는 것을 특징으로 하는 이미지 렌더링 장치."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항 또는 제15항 중 어느 한 항에 있어서,상기 이미지 렌더링 장치는 래디언스 필드 결정 모듈을 더 포함하되, 상기 래디언스 필드 결정 모듈은,수집 시점에서 타겟 물체에 대해 데이터를 수집하여 타겟 물체의 2차원 이미지와 타겟 물체의 3차원 점군을 얻는데 사용되는 데이터 수집 유닛;상기 타겟 물체의 2차원 이미지와 상기 타겟 물체의 3차원 점군을 융합하여 타겟 물체의 융합 이미지를 얻는데사용되는 데이터 융합 유닛;상 기 타겟 물체의 융합 이미지 및 상기 수집 시점에 따라 상기 타겟 물체의 NeRF를 결정하는데 사용되는 래디언스 필드 결정 유닛을 포함하는 것을 특징으로 하는 이미지 렌더링 장치."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "전자 설비로서,적어도 하나의 프로세서; 및공개특허 10-2024-0001021-6-상기 적어도 하나의 프로세서와 통신적으로 연결되는 메모리를 포함하되, 상기 메모리는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령을 저장하고, 상기 명령은상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제6항 중 어느 한항에 따른 이미지 렌더링 방법을 수행하도록 하는 것을 특징으로 하는 전자 설비."}
{"patent_id": "10-2023-0032849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체로서,상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제6항 중 어느 한 항에 따른 이미지 렌더링 방법을 수행하도록하는 것을 특징으로 하는 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 이미지 렌더링 방법, 장치, 설비 및 컴퓨터 저장 매체를 제공하고, 이는 지능"}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것으로"}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "서, 구체적으로 증강현실(AR), 가상현실(VR), 컴퓨터 비전, 딥 러닝 등 기술분야에 관한 것으로, 가상 이미지 및 메타버스와 같은 시나리오에 적용된다. 해당 방법은 환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이 미지를 얻는 단계; 타겟 물체의 NeRF에 기반하여, 타겟 물체 모델 및 타겟 시점에서의 타겟 물체 이미지를 결정 하는 단계; 상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하 는 단계를 포함한다. 상기 기술방안을 통해 이미지 렌더링 품질을 향상시킬 수 있다. 대 표 도 - 도1a"}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 3, "content": "공개특허10-2024-0001021 CPC특허분류 G06T 15/005 (2013.01) G06T 15/04 (2013.01) G06T 15/08 (2013.01) G06T 15/30 (2013.01) G06T 15/405 (2013.01) 발명자 장 옌 중국 베이징 100085 하이디엔 샹디 10번가 넘버 10 바이두 캠퍼스 2층 자오 첸 중국 베이징 100085 하이디엔 샹디 10번가 넘버 10 바이두 캠퍼스 2층 쑨 하오 중국 베이징 100085 하이디엔 샹디 10번가 넘버 10 바이두 캠퍼스 2층 리우 징투오 중국 베이징 100085 하이디엔 샹디 10번가 넘버 10 바이두 캠퍼스 2층딩 얼루이 중국 베이징 100085 하이디엔 샹디 10번가 넘버 10 바이두 캠퍼스 2층 우 티엔 중국 베이징 100085 하이디엔 샹디 10번가 넘버 10 바이두 캠퍼스 2층 왕 하이펑 중국 베이징 100085 하이디엔 샹디 10번가 넘버 10 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 이미지 렌더링 방법으로서, 환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이미지를 얻는 단계; 타겟 물체의 NeRF(Neural Radiance Field)에 기반하여, 타겟 물체 모델 및 타겟 시점에서의 타겟 물체 이미지를 결정하는 단계; 상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는 단계 를 포함하는 것을 특징으로 하는 이미지 렌더링 방법. 청구항 2 제1항에 있어서, 상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는 단계는, 상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 법선 방향을 결정하는 단계; 타겟 시점, 환경 광 및 상기 타겟 정점의 법선 방향에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하 여 조도가 조절된 타겟 물체 이미지를 얻는 단계; 조도가 조절된 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링 하는 단계 를 포함하는 것을 특징으로 하는 이미지 렌더링 방법. 청구항 3 제2항에 있어서, 상기 타겟 시점, 환경 광 및 상기 타겟 정점의 법선 방향에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수 행하여 조도가 조절된 타겟 물체 이미지를 얻는 단계는, 타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 정점의 법선 방향을 변환하여, 변환된 타겟 정점의 법선 방향을 얻는 단계; 환경 광 및 변환된 타겟 정점의 법선 방향에 따라 타겟 정점의 명암도를 결정하는 단계; 상기 타겟 정점의 명암도에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지를 얻는 단계 를 포함하는 것을 특징으로 하는 이미지 렌더링 방법. 청구항 4 제1항에 있어서, 상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는 단계는, 상기 타겟 시점과 상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 깊이 정보를 결정하는 단계; 상기 타겟 정점의 깊이 정보에 따라 타겟 물체와 환경 물체 간의 차폐 관계를 결정하는 단계; 상기 차폐 관계에 따라 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는 단계 를 포함하는 것을 특징으로 하는 이미지 렌더링 방법. 청구항 5 제4항에 있어서, 상기 타겟 시점과 상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 깊이 정보를 결정하는 단계는, 타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 물체 모델을 변환하여 변환된 타겟 물체 모델을 얻는 단계; 타겟 시점의 카메라 투영 매트릭스를 사용하여 변환된 타겟 물체 모델을 투영하여 타겟 물체 모델의 타겟 정점 의 깊이 정보를 얻는 단계 를 포함하는 것을 특징으로 하는 이미지 렌더링 방법. 청구항 6 제4항에 있어서, 상기 타겟 정점의 깊이 정보에 따라 타겟 물체와 환경 물체 간의 차폐 관계를 결정하는 단계는, 타겟 물체 모델의 각 픽셀에서의 타겟 정점의 깊이 정보와 대응하는 픽셀에서의 환경 물체의 깊이 정보를 비교 하는 단계; 상기 타겟 정점의 깊이 정보가 상기 환경 물체의 깊이 정보보다 작으면, 상기 타겟 정점이 해당 픽셀에서의 환 경 물체에 차폐되지 않도록 상기 차폐 관계를 결정하는 단계 를 포함하는 것을 특징으로 하는 이미지 렌더링 방법. 청구항 7 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 타겟 물체의 NeRF에 기반하여, 타겟 물체 모델 및 타겟 시점에서의 타겟 물체 이미지를 결정하는 단계는, 상기 타겟 물체의 NeRF로부터 타겟 물체의 점군 모델을 얻고, 상기 타겟 물체의 점군 모델을 처리하여 타겟 물 체의 그리드 모델을 얻는 단계; 상기 타겟 물체의 NeRF에 기반하여, 타겟 시점의 모델 뷰 매트릭스 및 카메라 투영 매트릭스를 사용하여 타겟 시점에서의 타겟 물체 이미지를 얻는 단계 를 포함하는 것을 특징으로 하는 이미지 렌더링 방법. 청구항 8 제7항에 있어서, 상기 타겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모델을 얻는 단계는, 마칭 큐브(Marching Cube) 알고리즘에 기반하여 상기 타겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모 델을 얻는 단계를 포함하는 것을 특징으로 하는 이미지 렌더링 방법. 청구항 9 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 타겟 물체의 NeRF는, 수집 시점에서 타겟 물체에 대해 데이터를 수집하여 타겟 물체의 2차원 이미지 및 타겟 물체의 3차원 점군을 얻 고; 상기 타겟 물체의 2차원 이미지 및 상기 타겟 물체의 3차원 점군을 융합하여 타겟 물체의 융합 이미지를 얻고; 상기 타겟 물체의 융합 이미지 및 상기 수집 시점에 따라 상기 타겟 물체의 NeRF를 결정하는 방식 에 의해 결정되는 것을 특징으로 하는 이미지 렌더링 방법. 청구항 10 이미지 렌더링 장치로서, 환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이미지를 얻는데 사용되는 환경 물체 모듈; 타겟 물체의 NeRF에 기반하여, 타겟 물체 모델 및 타겟 시점에서의 타겟 물체 이미지를 결정하는데 사용되는 타 겟 물체 모듈; 상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는데 사용 되는 융합 렌더링 모듈 을 포함하는 것을 특징으로 하는 이미지 렌더링 장치. 청구항 11 제10항에 있어서, 상기 융합 렌더링 모듈은, 상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 법선 방향을 결정하는데 사용되는 타겟 법선 유닛; 타겟 시점, 환경 광 및 상기 타겟 정점의 법선 방향에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하 여 조도가 조절된 타겟 물체 이미지를 얻는데 사용되는 조도 조절 유닛; 조도가 조절된 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는데 사용되는 조도 렌더링 유닛 을 포함하는 것을 특징으로 하는 이미지 렌더링 장치. 청구항 12 제11항에 있어서, 상기 조도 조절 유닛은, 타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 정점의 법선 방향을 변환하여 변환된 타겟 정점의 법선 방 향을 얻는데 사용되는데 사용되는 법선 변환 서브 유닛; 환경 광과 변환된 타겟 정점의 법선 방향에 따라 타겟 정점의 명암도를 결정하는데 사용되는 명암도 서브 유닛; 상기 타겟 정점의 명암도에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지를 얻는데 사용되는 조도 조절 서브 유닛 을 포함하는 것을 특징으로 하는 이미지 렌더링 장치. 청구항 13 제10항에 있어서, 상기 융합 렌더링 모듈은, 상기 타겟 시점과 상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 깊이 정보를 결정하는데 사용되는 깊이 정보 유닛; 상기 타겟 정점의 깊이 정보에 따라 타겟 물체와 환경 물체 간의 차폐 관계를 결정하는데 사용되는 차폐 관계 유닛; 상기 차폐 관계에 따라 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는데 사용되는 차 폐 렌더링 유닛 을 포함하는 것을 특징으로 하는 이미지 렌더링 장치. 청구항 14 제13항에 있어서, 상기 깊이 정보 유닛은,타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 물체 모델을 변환하여 변환된 타겟 물체 모델을 얻는데 사 용되는 모델 변환 서브 유닛; 타겟 시점의 카메라 투영 매트릭스를 이용하여 변환된 타겟 물체 모델을 투영하여 타겟 물체 모델의 타겟 정점 의 깊이 정보를 얻는데 사용되는 깊이 정보 서브 유닛 을 포함하는 것을 특징으로 하는 이미지 렌더링 장치. 청구항 15 제13항에 있어서, 상기 차폐 관계 유닛은, 타겟 물체 모델의 각 픽셀에서의 타겟 정점의 깊이 정보와 대응하는 픽셀에서의 환경 물체의 깊이 정보를 비교 하는데 사용하는 깊이 비교 서브 유닛; 상기 타겟 정점의 깊이 정보가 상기 환경 물체의 깊이 정보보다 작은 경우, 상기 타겟 정점이 해당 픽셀에서의 환경 물체에 차폐되지 않도록 상기 차폐 관계를 결정하는데 사용되는 차폐 관계 서브 유닛 을 포함하는 것을 특징으로 하는 이미지 렌더링 장치. 청구항 16 제10항 또는 제15항 중 어느 한 항에 있어서, 상기 타겟 물체 모듈은, 상기 타겟 물체의 NeRF로부터 타겟 물체의 점군 모델을 얻고, 상기 타겟 물체의 점군 모델을 처리하여 타겟 물 체의 그리드 모델을 얻는데 사용되는 타겟 모델 유닛; 상기 타겟 물체의 NeRF를 기반으로 타겟 시점의 모델 뷰 매트릭스와 카메라 투영 매트릭스를 사용하여 타겟 시 점에서의 타겟 물체 이미지를 결정하는데 사용되는 타겟 이미지 유닛 을 포함하는 것을 특징으로 하는 이미지 렌더링 장치. 청구항 17 상기 타겟 모델 유닛은 구체적으로, 마칭 큐브 알고리즘에 기반하여, 상기 타겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모델을 얻는데 사 용되는 것을 특징으로 하는 이미지 렌더링 장치. 청구항 18 제10항 또는 제15항 중 어느 한 항에 있어서, 상기 이미지 렌더링 장치는 래디언스 필드 결정 모듈을 더 포함하되, 상기 래디언스 필드 결정 모듈은, 수집 시점에서 타겟 물체에 대해 데이터를 수집하여 타겟 물체의 2차원 이미지와 타겟 물체의 3차원 점군을 얻 는데 사용되는 데이터 수집 유닛; 상기 타겟 물체의 2차원 이미지와 상기 타겟 물체의 3차원 점군을 융합하여 타겟 물체의 융합 이미지를 얻는데 사용되는 데이터 융합 유닛; 상 기 타겟 물체의 융합 이미지 및 상기 수집 시점에 따라 상기 타겟 물체의 NeRF를 결정하는데 사용되는 래디 언스 필드 결정 유닛 을 포함하는 것을 특징으로 하는 이미지 렌더링 장치. 청구항 19 전자 설비로서, 적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신적으로 연결되는 메모리 를 포함하되, 상기 메모리는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령을 저장하고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제6항 중 어느 한 항에 따른 이미지 렌더링 방법을 수행하도록 하는 것을 특징으로 하는 전자 설비. 청구항 20 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제6항 중 어느 한 항에 따른 이미지 렌더링 방법을 수행하도록 하는 것을 특징으로 하는 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체. 발명의 설명 기 술 분 야"}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 4, "content": "본 개시는 컴퓨터 기술분야, 특히 인공 지능 기술분야에 관한 것으로서, 구체적으로 증강현실(AR), 가상현실"}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 5, "content": "(VR), 컴퓨터 비전, 딥 러닝 등 기술분야에 관한 것으로, 가상 이미지 및 메타버스와 같은 시나리오에 적용된다. 구체적으로 이미지 렌더링 방법, 장치, 전자 설비 및 컴퓨터 판독 가능 저장 매체에 관한 것이다."}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터 그래픽스(Computer Graphics: CG)는 수학적 알고리즘을 사용하여 2차원 또는 3차원 그래픽을 컴퓨터 디 스플레이의 그리드 형태로 변환하는 과학이다. CG 렌더링 파이프라인은 디스플레이 칩 내부의 그래픽 처리 신호 가 서로 독립된 병렬 처리 유닛이며, 3차원 공간의 물체 모델을 2차원 평면의 물체 이미지로 변환하는데 사용된 다. CG 렌더링 파이프라인의 렌더링 품질을 향상시키는 것은 업계에서 중요한 문제이다."}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 이미지 렌더링 방법, 장치, 전자 설비 및 저장 매체를 제공한다."}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 이미지 렌더링 방법을 제공하며, 상기 방법은, 환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이미지를 얻는 단계; 타겟 물체의 뉴럴 래디언스 필드(Neural Radiance Field: NeRF)에 기반하여, 타겟 물체 모델 및 타겟 시점에서 의 타겟 물체 이미지를 결정하는 단계; 상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는 단계를 포함한다. 본 개시의 다른 측면에 따르면, 이미지 렌더링 장치를 제공하며, 상기 장치는, 환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이미지를 얻는데 사용되는 환경 물체 모듈; 타겟 물체의 NeRF에 기반하여, 타겟 물체 모델 및 타겟 시점에서의 타겟 물체 이미지를 결정하는데 사용되는 타 겟 물체 모듈; 상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는데 사용 되는 융합 렌더링 모듈을 포함한다. 본 개시의 또 다른 측면에 따르면, 전자 설비를 제공하며, 상기 전자 설비는, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신적으로 연결되는 메모리를 포함하되, 여기서, 상기 메모리는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령을 저장하고, 상기 명령은 상기 적어도 하 나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 본 개시의 임의의 실시예에서 제공하는 이미지 렌더링 방법을 실행할 수 있도록 한다. 본 개시의 또 다른 측면에 따르면, 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체를 제공 하고, 여기서, 상기 컴퓨터 명령은 상기 컴퓨터가 본 개시의 임의의 실시예에서 제공하는 이미지 렌더링 방법을 실행하도록 한다."}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 기술에 따르면, 이미지 렌더링 품질을 향상시킬 수 있다. 본 부분에 설명된 내용은 본 개시의 실시예의 핵심 또는 중요한 특징을 표시하려는 목적이 아니며, 본 개시의 범위를 한정하지 않음을 이해해야 한다. 본 개시의 다른 특징은 다음의 설명으로부터 쉽게 이해될 것이다."}
{"patent_id": "10-2023-0032849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1a는 본 개시의 실시예에서 제공하는 이미지 렌더링 방법의 흐름도이다. 해당 방법은 뉴럴 렌더링 결과를 CG 렌더링 파이프라인에 응용하는 경우에 적용될 수 있다. 해당 방법은 이미지 렌더링 장치에 의해 실행될 수 있고, 해당 장치는 하드웨어 및/또는 소프트웨어로 구현될 수 있으며, 전자 설비에 집성될 수 있다. 도 1a에 도 시된 바와 같이, 본 실시예의 이미지 렌더링 방법은 다음의 단계를 포함할 수 있다. 단계(S101), 환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이미지를 얻는다; 단계(S102), 타겟 물체의 뉴럴 래디언스 필드(Neural Radiance Field: NeRF)에 기반하여, 타겟 물체 모델 및 타겟 관점에서의 타겟 물체 이미지를 결정한다; 단계(S103), 상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링 한다. 여기서, 환경 물체 모델은 3차원 모델링 소프트웨어를 통해 환경 물체를 모델링하여 얻을 수 있는 환경 물체의 3차원 모델을 의미한다. 본 개시의 실시예는 3차원 모델링 소프트웨어를 구체적으로 한정하지 않으며, 예를 들 어 Unity 3D 3차원 모델일 수 있다. 또한, 환경 물체에 대해 구체적으로 한정하지 않는다. 본 개시의 실시예에서, CG 렌더링 파이프라인을 통해 환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 의 이미지를 획득한다. 도 1b를 참조하면, CG 렌더링 파이프라인은 환경 물체 모델의 환경 정점 데이터를 입력 으로 하여, 모델 변환, 정점 쉐이딩, 클리핑, 투영 변환과 같은 기하학적 단계 및 단편 탐색(traversal), 단편 쉐이딩, 딥 버퍼 쓰기, 단편별 작업과 같은 래스터화(rasterization) 단계를 통해 타겟 시점에서의 환경 물체 이미지를 획득하여 환경 물체의 렌더링 결과로 한다. 본 개시의 실시예에서, 타겟 물체의 NeRF는 타겟 물체의 이미지와 이미지의 수집 시점에 따라 미리 훈련하여 획 득할 수 있고, NeRF의 입력은 타겟 물체의 공간적 위치와 이미지의 수집 시점일 수 있으며, 이미지의 색상을 네 트워크의 정답값(ground truth)으로 하여 훈련하고, NeRF는 볼륨 밀도(volume, 즉, density)와 타겟 물체의 공 간 포인트 색상을 출력할 수 있다. 예시적으로, 완전 연결된 네트워크(MLP) 및 볼륨 렌더링을 사용하여 타겟 물 체의 이미지로부터 타겟 물체의 기하학 및 모양을 재구성한다. 여기서, 타겟 물체의 이미지는 타겟 물체를 수집 하여 얻을 수 있다. 여기서, 타겟 물체 모델은 타겟 물체의 3차원 모델로서 타겟 물체의 NeRF에서 얻을 수 있다. 타겟 물체의 이미 지는 타겟 물체의 2차원 이미지이며 타겟 시점을 타겟 물체의 NeRF의 입력으로 하여 타겟 시점에서의 타겟 물체 의 이미지를 얻을 수 있다. 타겟 물체의 이미지와 환경 물체의 이미지의 크기는 같다. 예시적으로, 타겟 물체 모델을 사용하여 타겟 물체의 타겟 시점에서의 렌더링 파라미터를 결정하고, 타겟 물체의 렌더링 파라미터를 사 용하여 타겟 물체 이미지를 융합하여 환경 물체 이미지에 렌더링하여, 타겟 물체와 환경 물체의 융합 렌더링 이 미지를 얻을 수 있다. 여기서, 렌더링 파라미터는 타겟 물체 중 타겟 정점의 명암도, 타겟 정점의 깊이 정보 등 일 수 있다. 상응하게, 타겟 물체 중 타겟 정점의 명암도, 깊이 정보 등을 사용하여 타겟 물체 이미지를 융합하 여 환경 물체 이미지에 렌더링할 수 있으며, 즉, 타겟 물체 이미지와 환경 물체 이미지를 맵핑하여 융합 렌더링 이미지에 타겟 물체뿐만 아니라 환경 물체도 포함되도록 한다. 타겟 물체의 NeRF를 통해 타겟 물체 모델과 타겟 시점에서의 타겟 물체 이미지를 결정하면 3차원 모델 재구성 및 시각화 파이프라인의 높은 비용과 결과가 현실적이지 않은 문제를 해결할 수 있을 뿐만 아니라 NeRF의 낮은 비용, 높은 안정성, 높은 품질 등 장점을 최대한 활용하여 고정밀도의 타겟 물체 이미지를 얻을 수 있다. 또한, 타겟 물체 모델에 따라 타겟 물체의 타겟 시점에서의 렌더링 파라미터를 결정하고 렌더링 파라미터를 사용하여 타겟 물체 이미지를 융합하여 환경 물체 이미지에 렌더링함으로써 타겟 물체 이미지와 환경 물체 이미지 간의 렌더링 일관성을 향상시킬 수 있어 융합 렌더링 이미지의 렌더링 품질을 향상시킬 수 있다. 본 개시의 실시예에서 제공하는 기술방안은 타겟 물체의 NeRF에 기반하여 타겟 물체 모델과 타겟 시점에서의 타 겟 물체 이미지를 결정하고, 타겟 물체 모델에 따라 타겟 시점에서의 타겟 물체의 렌더링 파라미터를 결정하며, 렌더링 파라미터를 사용하여 타겟 물체 이미지를 융합하여 환경 물체 이미지에 렌더링함으로써 타겟 물체의 NeRF를 CG 렌더링 파이프라인에 적용하여 CG 렌더링 파이프라인이 NeRF의 낮은 비용, 높은 안정성, 높은 품질 등 장점을 최대한 활용할 수 있도록 하고, 또한 타겟 물체 이미지와 환경 물체 이미지 간의 렌더링 일관성을 향 상시킬 수 있어 융합 렌더링 이미지의 렌더링 품질을 향상시킬 수 있다. 여기서, 환경 정점 데이터에는 환경 정점의 좌표, 색상, 법선, 텍스처 좌표 등이 포함될 수 있다. 도 1b를 참조 하면, 모델 변환 과정에서 타겟 시점의 모델 뷰 매트릭스를 결정하고 환경 정점의 좌표에 타겟 시점을 왼쪽으로 곱한 모델 뷰 매트릭스를 통해 환경 정점을 타겟 시점의 뷰잉 프러스텀(viewing frustum) 공간에 매핑한다. 뷰 잉 프러스텀 공간의 물체는 모두 타겟 시점의 카메라에 의해 관찰되며, 타겟 시점을 조절하여 뷰잉 프러스텀 공 간에서의 환경 물체의 위치를 정확하게 제어할 수 있다. 여기서 타겟 시점의 모델 뷰 매트릭스는 타겟 시점의 뷰 매트릭스를 역변환하고 모델 매트릭스와 곱하여 얻을 수 있다. 모델 매트릭스는 모델 좌표계에서 세계 좌표 계로 변환한 매트릭스이고, 타겟 시점의 뷰 매트릭스는 세계 좌표계에서 타겟 시점의 카메라 좌표계로의 변환이 며, 뷰 매트릭스의 역변환을 통해 타겟 시점의 카메라 좌표계를 세계 좌표계의 원점으로 이동시킨다. 도 1b를 참조하면, 정점 쉐이딩 과정에서 환경 정점의 법선 방향과 환경 광선에 따라 환경 정점의 색상을 결정 한다. 여기서, 환경 정점의 정점 법선 방향은 CG 렌더링 파이프라인에 알려진 정보로 입력할 수 있으며, 예를 들어 환경 정점이 속한 삼각형의 두 변을 사용하여 외적을 계산하여 환경 정점의 정점 법선 방향을 얻고, 삼각 형의 각 환경 정점의 정점 법선 방향을 평균하여 삼각형의 법선 방향으로 사용할 수 있다. 환경 광선은 CG 렌더 링 엔진의 환경 맵핑과 광원에 의해 제공될 수 있다. 클리핑 과정에서 타겟 시점의 뷰잉 프러스텀 공간 외부에 위치한 환경 정점을 삭제하고, 삭제 후 타겟 물체의 경계를 매끄럽게 처리한다. 투영 변환 과정에서 클리핑 및 쉐이딩된 환경의 정점에 타겟 시점을 왼쪽으로 곱한 카메라 투영 매트릭스를 통해 환경 물체를 카메라의 이미징 평면에 투시 투영하여 환경 물체가 근접하면 커지고 멀어지면 작아지는 인간의 시각적 특성에 부합하도록 한다. 여기서, 카메라 투영 매트릭스는 타겟 시점의 뷰잉 프러스텀 공간, 즉, 뷰잉 프러스텀 공간의 상평면, 하평면, 좌평면, 우평면, 원평면, 근평면에 따라 결정된다. 도 1b를 참조하면, 래스터화 단계에서 환경 정점 간의 삼각 관계에 따라 카메라 투영으로 변환된 환경 정점은 삼각 패치(즉, 단편)를 구성하고 모든 삼각 패치를 탐색하며 환경 광에 따라 삼각 패치를 쉐이딩하고 예를 들어, 환경 정점의 색상에 따라 보간할 수 있다. 설명해야 할 것은, 본 개시의 실시예는 단편 쉐이딩 방법을 구 체적으로 한정하지 않으며, 예를 들어 환경 광선과 삼각 패치의 법선 방향에 따라 삼각 패치의 색상을 계산하여보다 정밀한 렌더링 효과를 얻을 수도 있다. 래스터화 단계에서 딥 버퍼 처리를 수행할 수도 있다. 환경 정점의 좌표와 카메라 위치에 따라 환경 정점에서 카메라의 광심이 위치한 평면까지의 유클리드 거리를 결정하여 환경 정점의 깊이로 하고, 환경 정점의 깊이는 환경 정점이 속한 삼각 패치의 깊이와 일치할 수 있다. CG 렌더링 엔진은 각 삼각 패치의 깊이에 따라 서로 다 른 삼각 패치 간의 전후 차폐 관계를 결정할 수 있으며, 서로 다른 삼각 패치 간의 전후 차폐 관계에 따라 환경 물체의 이미지를 단편별로 출력하여 환경 물체의 렌더링 결과로 할 수 있다. 선택적 실시형태에서 상기 타겟 물체의 NeRF는 다음의 방식에 의해 결정된다: 수집 시점에서 타겟 물체의 데이 터를 수집하여 타겟 물체의 2차원 이미지와 타겟 물체의 3차원 점군(point cloud)을 얻고; 상기 타겟 물체의 2 차원 이미지와 상기 타겟 물체의 3차원 점군을 융합하여 타겟 물체의 융합 이미지를 얻으며; 상기 타겟 물체의 융합 이미지 및 수집 시점에 따라 상기 타겟 물체의 NeRF를 결정한다. 본 방안에서는 수집 시점에서 카메라와 레이저 레이더를 이용하여 타겟 물체의 데이터를 수집하여 타겟 물체의 2차원 이미지와 타겟 물체의 3차원 점군을 얻을 수 있으며; 타겟 물체의 2차원 이미지와 타겟 물체의 3차원 점 군을 융합하여 타겟 물체의 융합 이미지를 얻을 수 있어 융합 이미지가 2차원 이미지의 텍스처 정보뿐만 아니라 점군 데이터의 깊이 정보, 기하학적 정보도 가질 수 있도록 한다. 타겟 물체의 융합 이미지 중의 색상을 네트워 크 정답값으로 하여 타겟 물체의 NeRF를 훈련시킬 수 있다. 타겟 물체의 융합 이미지 및 대응하는 수집 시점을 사용하여 타겟 물체의 NeRF를 훈련시킴으로써 NeRF의 품질을 더욱 향상시킬 수 있다. 설명해야 할 것은, 타겟 물체의 융합 이미지가 더 넓은 시점을 커버하도록 카메라는 다양한 높이에서 시야 중심을 중심으로 촬영할 수 있다. 후속 알고리즘이 카메라 위치를 더 잘 예측하기 위해 수집 중 카메라를 회전시키지 않도록 하고; 카메라 를 회전시켜야 할 경우 천천히 회전하면서 앞뒤로 이동하는 방식으로 인접한 프레임 간의 시야 일치율을 높인다. 또한, NeRF의 최적화 알고리즘을 통해 렌더링 정확도를 향상시킬 수 있으며; 뉴럴 렌더링의 속도 향상 기술을 사용하여 실시간 신경 그래픽스(Instant Neural Graphics Primitives, Instant-NGP) 기술과 같은 NeRF 의 훈련 시간과 예측 시간을 크게 줄일 수 있다. 도 2는 본 개시의 실시예에서 제공하는 다른 이미지 렌더링 방법의 흐름도이다. 본 실시예는 상기 실시예의 기 초상에 타겟 물체 이미지에 대해 조도 조절 최적화를 수행한 것이다. 도 2를 참조하면, 본 실시예의 이미지 렌 더링 방법은 다음 단계를 포함할 수 있다. S201, 환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이미지를 얻는다; S202, 타겟 물체의 NeRF에 기반하여 타겟 물체 모델과 타겟 시점에서의 타겟 물체 이미지를 결정한다; S203, 상기 타겟 물체 모델에 따라 타겟 물체 모델에서 타겟 정점의 법선 방향을 결정한다; S204, 타겟 시점, 환경 광 및 상기 타겟 정점의 법선 방향에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지를 얻는다; S205, 조도가 조절된 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링한다. 여기서, 환경 광은 환경 물체의 환경 광이며, CG 렌더링 엔진의 환경 맵핑과 광원에 의해 제공된다. 예시적으로, 타겟 시점에 따라 타겟 정점의 법선 방향을 변환하여 변환된 타겟 정점의 법선 방향을 얻고, 변환 된 타겟 정점의 법선 방향을 환경 물체의 시점과 일치시키고 모두 타겟 시점 아래에 있도록 할 수 있다. 또한, 환경 광 및 변환된 타겟 정점의 주변광과 법선 방향에 따라 타겟 물체 이미지에 대해 조도 조절을 수행하고, 조 도가 조절된 타겟 물체 이미지를 융합하여 환경 물체 이미지에 렌더링하여 융합 렌더링 이미지를 얻는다. 타겟 물체의 조도를 조절함으로써 조도가 조절된 타겟 물체 이미지도 환경 광의 작용 하에 위치하도록 하며, 즉, 환 경 물체 이미지와 조도가 조절된 타겟 물체 이미지가 동일한 환경 광선 하에 위치하여 환경 물체 이미지와 조도 가 조절된 타겟 물체 이미지 사이의 광선 일관성을 향상시킨다. 선택적 실시형태에서 상기 타겟 시점, 환경 광 및 상기 타겟 정점의 법선 방향에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지를 얻는 단계는, 타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 정점의 법선 방향을 변환하여 변환된 타겟 정점의 법선 방향을 얻는 단계; 환경 광 및 변환 된 타겟 정점의 법선 방향에 따라 타겟 정점의 명암도를 결정하는 단계; 상기 타겟 정점의 명암도에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지를 얻는 단계를 포함한다. 여기서, 타겟 시점의 모델 뷰 매트릭스는 타겟 시점의 뷰 매트릭스를 역변환하고 모델 매트릭스와 곱하여 얻을 수 있다. 모델 매트릭스는 모델 좌표계에서 세계 좌표계로 변환한 매트릭스이고, 타겟 시점의 뷰 매트릭스는 세계 좌표계에서 타겟 시점의 카메라 좌표계로의 변환이며, 뷰 매트릭스의 역변환을 통해 타겟 시점의 카메라 좌 표계를 세계 좌표계의 원점으로 이동시킨다. 예시적으로, 타겟 정점의 법선 방향을 타겟 시점의 모델 뷰 매트릭스에 왼쪽으로 곱하여 변환된 타겟 정점의 법 선 방향을 얻는다. 또한 변환된 타겟 정점의 법선 방향에 환경 광을 작용하여 환경 광의 작용 하의 타겟 정점의 명암도를 얻으며, 예를 들어 환경 광선 방향과 변환된 타겟 정점의 법선 방향을 곱하여 타겟 정점의 명암도를 얻을 수 있으며, 타겟 정점의 명암도를 이용하여 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지를 얻을 수 있다. 예시적으로, 타겟 정점의 명암도와 타겟 물체 이미지의 타겟 정점의 픽셀 값 을 곱하여 조도가 조절된 타겟 물체 이미지를 얻는다. 조도가 조절된 타겟 물체 이미지와 환경 물체가 동일한 환경 광 아래에 있도록 제어함으로써 타겟 물체 이미지와 환경 물체 이미지 간의 렌더링 일관성이 향상된다. 본 개시의 실시예에서 제공하는 기술방안은 타겟 정점의 법선 방향을 타겟 시점 아래로 변환하고, 환경 광과 변 환된 타겟 정점의 법선 방향에 따라 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지와 환경 물체 이미지가 동일한 환경 광 아래에 위치하도록 함으로써, 타겟 물체 이미지와 환경 물체 이미 지 사이의 렌더링 일관성을 더욱 향상시켜 융합 렌더링 이미지의 렌더링 품질을 향상시킨다. 선택적인 실시형태에서, 상기 타겟 물체의 NeRF에 기반하여 타겟 물체 모델과 타겟 시점에서의 타겟 물체 이미 지를 결정하는 단계는, 상기 타겟 물체의 NeRF로부터 타겟 물체의 점군 모델을 얻고, 상기 타겟 물체의 점군 모 델을 처리하여 타겟 물체의 그리드 모델을 얻는 단계; 상기 타겟 물체의 NeRF에 기반하여, 타겟 시점의 모델 뷰 매트릭스와 카메라 투영 매트릭스를 사용하여 타겟 시점에서의 타겟 물체 이미지를 결정하는 단계를 포함한다. 여기서, 타겟 물체의 NeRF는 타겟 물체의 점군 모델을 출력할 수 있으며, 타겟 물체의 점군 모델을 처리하여 타 겟 물체의 그리드 모델을 얻을 수 있다. 선택적으로, 마칭 큐브(Marching Cube) 알고리즘을 기반으로 상기 타겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모델을 얻어 3차원 타겟 물체 모델로 한다. 여기서, 타겟 물 체의 그리드 모델은 그리드 정점과 그리드 면으로 구성되며 그리드 모델 데이터에는 그리드 정점의 정점 좌표와 그리드 면의 패치 관계가 포함된다. 구체적으로, 타겟 물체의 점군 모델의 정점 좌표에 따라 3차원 복셀 공간에 서 복셀 좌표의 유향 거리장을 결정할 수 있으며; 마칭 큐브 알고리즘을 기반으로 복셀 좌표의 유향 거리장에 따라 타겟 물체의 그리드 모델을 추출할 수 있다. 타겟 물체의 점군 모델에 따라 타겟 물체의 그리드 모델을 결 정함으로써 그리드 모델의 후속 처리를 용이하게 한다. 상응하게, 상기 타겟 물체 모델에 따라 타겟 물체 모델 에서 타겟 정점의 법선 방향을 결정하는 단계는, 타겟 물체의 그리드 모델에서 타겟 정점이 속한 삼각형의 두 변을 사용하여 외적을 계산하여 타겟 정점의 법선 방향을 얻는 단계를 포함할 수 있다. 또한 설명해야 할 것은, 타겟 물체의 NeRF는 타겟 정점의 법선 방향도 출력할 수 있다. 여기서, 타겟 시점의 카메라 투영 매트릭스는 타겟 물체를 카메라의 이미징 평면에 투영하여 타겟 물체가 근접 하면 커지고 멀어지면 작아지는 인간의 시각적 특성에 부합하도록 한다. 카메라 투영 매트릭스는 타겟 시점의 뷰잉 프러스텀 공간, 즉, 뷰잉 프러스텀 공간의 상평면, 하평면, 좌평면, 우평면, 원평면, 근평면에 따라 결정 된다. 구체적으로, 타겟 시점의 모델 뷰 매트릭스와 카메라 투영 매트릭스를 타겟 물체의 NeRF에 입력하고 뉴럴 렌더링을 통해 타겟 시점에서의 타겟 물체 이미지, 즉, 타겟 시점에서의 타겟 물체 렌더링 이미지를 얻는다. 타 겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모델을 얻어 3차원 타겟 물체 모델로 하여 타겟 물체 모델 의 타겟 정점 수를 단순화하고 타겟 물체 모델의 후속 계산량을 줄일 수 있을 뿐만 아니라 타겟 물체 모델의 정 확성을 향상시킬 수 있으며, 타겟 물체 모델을 사용하여 타겟 정점의 법선 방향을 결정하며, 또한 타겟 정점의 법선 방향의 정확성을 향상시킬 수 있다. 타겟 시점의 모델 뷰 매트릭스와 카메라 투영 매트릭스를 사용하여 타 겟 물체 이미지를 얻음으로써 타겟 물체 이미지와 환경 물체 이미지가 모두 타겟 시점 아래에 있도록 할 수 있 어 양자의 시점 일관성을 유지할 수 있다. 도 3a는 본 개시의 실시예에서 제공하는 또 다른 이미지 렌더링 방법의 흐름도이다. 본 실시예는 상기 실시예의 기초상에 제기한 선택적인 방안이다. 도 3a를 참조하면, 본 실시예의 이미지 렌더링 방법은 다음 단계를 포함할 수 있다. S301, 환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이미지를 얻는다; S302, 타겟 물체의 NeRF에 기반하여 타겟 물체 모델과 타겟 시점에서의 타겟 물체 이미지를 얻는다; S303, 상기 타겟 시점과 상기 타겟 물체 모델에 따라, 타겟 물체 모델의 타겟 정점의 깊이 정보를 결정한다. S304, 상기 타겟 정점의 깊이 정보에 따라 타겟 물체와 환경 물체 사이의 차폐 관계를 결정한다; S305, 상기 차폐 관계에 따라 상기 타겟 물체의 이미지를 융합하여 상기 환경 물체 이미지에 렌더링한다. 여기서, 타겟 물체 모델에서 타겟 정점의 깊이 정보는 타겟 정점에서 카메라의 이미징 평면까지의 유클리드 거 리이다. 예시적으로, 타겟 시점의 카메라 투영 매트릭스를 사용하여 타겟 물체 모델을 투영 변환하여 z축 방향 에서의 타겟 정점 거리를 얻어 타겟 정점의 깊이 정보로 할 수 있다. 또한, 픽셀별로 타겟 정점의 깊이 정보를 딥 버퍼(depth buffer)에 다시 쓸 수 있으며, CG 렌더링 파이프라인은 타겟 정점의 깊이 정보와 이미 이 픽셀에 저장된 환경 물체의 깊이 정보를 비교하여 비교 결과에 따라 타겟 정점의 차폐 관계를 결정한다. 선택적으로, 상기 타겟 정점의 깊이 정보에 따라 타겟 물체와 환경 물체 사이의 차폐 관계를 결정하는 단계는, 타겟 물체 모델의 각 픽셀에서의 타겟 정점의 깊이 정보와 해당 픽셀에서의 환경 물체의 깊이 정보를 비교하는 단계; 상기 타겟 정점의 깊이 정보가 상기 환경 물체의 깊이 정보보다 작으면, 상기 타겟 정점을 차폐하지 않는 단계를 포함한다. 각 픽셀에 대해 해당 픽셀의 타겟 정점의 깊이 정보가 환경 물체의 깊이 정보보다 작으면 타겟 정점을 차폐하지 않고, 환경 물체의 픽셀 값 대신 타겟 정점의 픽셀 값을 사용하며, 그렇지 않으면 해당 픽셀의 타겟 정점은 환 경 물체에 의해 차폐되고 해당 픽셀의 타겟 정점의 픽셀 값은 폐기된다. 타겟 물체 모델에서 타겟 정점의 깊이 정보를 결정하고, 타겟 정점의 깊이 정보에 따라 타겟 정점과 환경 물체 간의 차폐 관계를 결정하고, 차폐 관계 에 따라 픽셀별로 다시 써서 타겟 물체와 환경 물체의 전체 렌더링 결과를 얻음으로써 타겟 물체와 환경 물체 간의 차폐 관계를 정확하게 반영하여 융합 렌더링 품질을 더욱 향상시킬 수 있다. 선택적 실시형태에서 상기 타겟 시점과 상기 타겟 물체 모델에 따라, 타겟 물체 모델의 타겟 정점의 깊이 정보 를 결정하는 단계는, 타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 물체 모델을 변환하여 변환된 타겟 물체 모델을 얻는 단계; 타겟 물체 모델의 카메라 투영 매트릭스를 사용하여 변환된 타겟 물체 모델을 투영하여 타겟 물체 모델의 타겟 정점 깊이 정보를 얻는 단계를 포함한다. 여기서, 타겟 시점의 모델 뷰 매트릭스는 타겟 시점의 뷰 매트릭스를 역변환하고 모델 매트릭스와 곱하여 얻을 수 있다. 타겟 시점의 카메라 투영 매트릭스는 타겟 물체를 카메라의 이미징 평면에 투영하는데 사용된다. 구체 적으로, 타겟 물체 모델의 타겟 정점 좌표에 타겟 시점의 모델 뷰 매트릭스를 왼쪽으로 곱하여 타겟 시점에서의 타겟 물체 모델을 얻는다. 타겟 시점의 카메라 투영 매트릭스를 사용하여 타겟 물체 모델에 대해 투시 투영 변 환을 수행하여 타겟 물체 모델에서 타겟 정점의 깊이 정보를 얻는다. 모델 변환을 통해 타겟 물체 모델을 타겟 시점으로 변환하고 타겟 시점에서의 타겟 물체 모델을 기반으로 타겟 정점의 깊이 정보를 결정함으로써 깊이 정 보의 정확성을 향상시켜 전체 렌더링 결과의 정확도를 높일 수 있다. 설명해야 할 것은, 본 개시의 실시예는 타겟 물체 이미지에 대해 조도 조절을 수행할 뿐만 아니라, 타겟 물체 모델에 따라 조도가 조절된 타겟 물체 이미지와 환경 물체 이미지 간의 차폐 관계를 결정할 수 있으며, 또한 차 폐 관계에 따라 깊이 다시 쓰기 및 픽셀 다시 쓰기를 수행하여 타겟 물체 이미지와 환경 물체 이미지를 포함하 는 융합 렌더링 이미지를 얻을 수 있다. 즉, 융합 렌더링 이미지의 타겟 물체 이미지와 환경 물체 이미지는 동 일한 환경 광 아래에 있을 뿐만 아니라 타겟 물체 이미지와 환경 물체 이미지 간의 차폐 관계를 정확하게 반영 한다. 도 3b를 참조하면, CG 렌더링 라인은 타겟 시점의 모델 뷰 매트릭스를 이용하여 환경 물체 모델의 환경 정점 데 이터를 모델 변환하고, 환경 광을 통해 환경 정점을 쉐이딩하여 타겟 시점의 뷰잉 프러스텀 공간 이외의 환경 정점을 클리핑하고, 타겟 시점의 카메라 투영 매트릭스를 이용하여 쉐이딩, 클리핑된 환경 정점을 투시 투영 변 환하며; 래스터화 단계에서 환경 물체 모델의 단편을 탐색하여 환경 광에 따라 단편을 쉐이딩하고, 딥 버퍼를 통해 환경 정점의 가시성을 결정하고, 단편별로 작업하여 환경 물체 이미지를 출력한다. 도 3b를 참조하면, 타겟 물체의 공간적 위치, 타겟 물체를 수집하여 획득한 이미지 및 타겟 물체의 수집 위치에 따라 NeRF 훈련을 수행하여 타겟 물체의 NeRF를 얻는다. 타겟 시점의 모델 뷰 매트릭스와 카메라 투영 매트릭스 를 NeRF에 입력하여 타겟 시점에서의 타겟 물체 이미지를 얻고; NeRF를 기반으로 타겟 물체 모델과 타겟 물체 모델의 타겟 정점의 법선 방향도 결정한다. 타겟 시점의 모델 뷰 매트릭스를 이용하여 타겟 물체 모델과 타겟 정점의 법선 방향을 타겟 시점으로 변환하여 변환된 타겟 물체 모델과 변환된 타겟 정점의 법선 방향을 얻고; CG 렌더링 파이프라인의 환경 광을 변환된 타 겟 정점의 법선 방향에 작용하여 타겟 정점의 명암도를 얻고, 타겟 정점의 명암도와 타겟 물체 이미지를 곱하여 조도가 조절된 타겟 물체 이미지를 얻으며; 타겟 시점의 카메라 투영 매트릭스를 사용하여 변환된 타겟 물체 모 델의 투시 투영 변환을 수행하여 타겟 정점의 깊이 정보를 얻고 타겟 정점의 깊이 정보에 따라 깊이 다시 쓰기를 수행한다. 픽셀별로 깊이 다시 쓰기를 수행함으로써 타겟 정점과 환경 물체 사이의 차폐 관계를 얻고 차폐 관계에 따라 조도가 조절된 타겟 물체 이미지에 대해 픽셀별로 다시 쓰기를 수행하여 환경 물체 및 타겟 물체를 포함하는 융합 렌더링 이미지를 얻는다. 본 개시의 실시예에서 제공하는 기술방안은 타겟 물체 모델에 따라 뉴럴 렌더링 필드에서 출력되는 타겟 물체 이미지에 대해 조도 조절을 수행하고, 또한 타겟 정점과 환경 물체 사이의 차폐 관계를 결정함으로써, 조도 조 절 결과와 차폐 관계에 따라 타겟 물체와 환경 물체의 융합 렌더링 이미지를 획득하고, 뉴럴 렌더링 기술을 CG 렌더링 파이프라인에 창조적으로 도입하여 뉴럴 렌더링 결과를 CG 렌더링 파이프라인에 원활하게 연결할 수 있 도록 하여 더 나은 융합 렌더링 결과를 얻는다. 즉, 뉴럴 렌더링과 CG 렌더링 파이프라인을 융합 렌더링하는 새 로운 형태의 렌더링 증강 기술 경로를 제안하여 전통적인 특수효과 생산라인에 새로운 활력을 불어넣을 수 있다. 도 4는 본 개시의 실시예에서 제공하는 이미지 렌더링 장치의 구조 개략도이다. 본 실시예는 뉴럴 렌더링 결과 를 CG 렌더링 파이프라인에 적용하는 경우에 적용된다. 해당 장치는 소프트웨어 및/또는 하드웨어 방식으로 구 현될 수 있으며 사용자 단말 장치에 집성될 수 있다. 도 4에 도시된 바와 같이, 본 실시예의 이미지 렌더링 장 치는: 환경 물체 모델을 렌더링하여 타겟 시점에서의 환경 물체 이미지를 얻는데 사용되는 환경 물체 모듈; 타겟 물체의 NeRF에 기반하여, 타겟 물체 모델 및 타겟 시점에서의 타겟 물체 이미지를 결정하는데 사용되는 타 겟 물체 모듈; 상기 타겟 물체 모델에 따라, 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는데 사용 되는 융합 렌더링 모듈을 포함할 수 있다. 선택적인 실시형태에서, 상기 융합 렌더링 모듈은: 상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 법선 방향을 결정하는데 사용되는 타겟 법선 유닛; 타겟 시점, 환경 광 및 상기 타겟 정점의 법선 방향에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하 여 조도가 조절된 타겟 물체 이미지를 얻는데 사용되는 조도 조절 유닛; 조도가 조절된 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는데 사용되는 조도 렌더링 유닛 을 포함한다. 선택적인 실시형태에서, 상기 조도 조절 유닛은: 타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 정점의 법선 방향을 변환하여 변환된 타겟 정점의 법선 방 향을 얻는데 사용되는데 사용되는 법선 변환 서브 유닛; 환경 광과 변환된 타겟 정점의 법선 방향에 따라 타겟 정점의 명암도를 결정하는데 사용되는 명암도 서브 유닛; 상기 타겟 정점의 명암도에 따라 상기 타겟 물체 이미지에 대해 조도 조절을 수행하여 조도가 조절된 타겟 물체 이미지를 얻는데 사용되는 조도 조절 서브 유닛을 포함한다. 선택적인 실시형태에서, 상기 융합 렌더링 모듈은: 상기 타겟 시점과 상기 타겟 물체 모델에 따라 타겟 물체 모델의 타겟 정점의 깊이 정보를 결정하는데 사용되는 깊이 정보 유닛; 상기 타겟 정점의 깊이 정보에 따라 타겟 물체와 환경 물체 간의 차폐 관계를 결정하는데 사용되는 차폐 관계 유닛; 상기 차폐 관계에 따라 상기 타겟 물체 이미지를 융합하여 상기 환경 물체 이미지에 렌더링하는데 사용되는 차 폐 렌더링 유닛을 포함한다. 선택적인 실시형태에서, 상기 깊이 정보 유닛은: 타겟 시점의 모델 뷰 매트릭스를 사용하여 상기 타겟 물체 모델을 변환하여 변환된 타겟 물체 모델을 얻는데 사 용되는 모델 변환 서브 유닛; 타겟 시점의 카메라 투영 매트릭스를 이용하여 변환된 타겟 물체 모델을 투영하여 타겟 물체 모델의 타겟 정점 의 깊이 정보를 얻는데 사용되는 깊이 정보 서브 유닛을 포함한다. 선택적 실시형태에서, 상기 차폐 관계 유닛은: 타겟 물체 모델의 각 픽셀에서의 타겟 정점의 깊이 정보와 해당 픽셀에서의 환경 물체의 깊이 정보를 비교하는 데 사용하는 깊이 비교 서브 유닛; 상기 타겟 정점의 깊이 정보가 상기 환경 물체의 깊이 정보보다 작은 경우 상기 타겟 정점을 차폐하지 않는데 사용되는 차폐 관계 서브 유닛을 포함한다. 선택적 실시형태에서, 상기 타겟 물체 모듈은: 상기 타겟 물체의 NeRF로부터 타겟 물체의 점군 모델을 얻고, 상기 타겟 물체의 점군 모델을 처리하여 타겟 물 체의 그리드 모델을 얻는데 사용되는 타겟 모델 유닛; 상기 타겟 물체의 NeRF를 기반으로 타겟 시점의 모델 뷰 매트릭스와 카메라 투영 매트릭스를 사용하여 타겟 시 점에서의 타겟 물체 이미지를 결정하는데 사용되는 타겟 이미지 유닛을 포함한다. 선택적 실시형태에서, 상기 타겟 모델 유닛은 구체적으로: 마칭 큐브 알고리즘에 기반하여, 상기 타겟 물체의 점군 모델을 처리하여 타겟 물체의 그리드 모델을 얻는데 사 용된다. 선택적 실시형태에서, 해당 이미지 렌더링 장치는 래디언스 필드 결정 모듈을 더 포함하되, 상기 래디언스 필드 결정 모듈은: 수집 시점에서 타겟 물체에 대해 데이터를 수집하여 타겟 물체의 2차원 이미지와 타겟 물체의 3차원 점군을 얻 는데 사용되는 데이터 수집 유닛; 상기 타겟 물체의 2차원 이미지와 상기 타겟 물체의 3차원 점군을 융합하여 타겟 물체의 융합 이미지를 얻는데 사용되는 데이터 융합 유닛; 상기 타겟 물체의 융합 이미지 및 수집 시점에 따라 상기 타겟 물체의 NeRF를 결정하는데 사용되는 래디언스 필 드 결정 유닛을 포함한다. 본 개시의 기술방안은 뉴럴 렌더링 필드를 기반으로 타겟 물체 모델을 결정하고, 타겟 물체 모델에 따라 뉴럴 렌더링 필드에서 출력되는 타겟 물체 이미지에 대해 조도 조절을 수행하며, 또한 타겟 정점과 환경 물체 간의 차폐 관계를 결정하고, 조도 조절 결과와 차폐 관계에 따라 타겟 물체와 환경 물체의 융합 렌더링 이미지를 얻 음으로써, 뉴럴 렌더링과 CG 렌더링 파이프라인을 융합 렌더링하는 새로운 렌더링 증강 기술 경로를 창의적으로 제안하여 강력한 뉴럴 렌더링 기술을 직접 생산력으로 전환하여 전통적인 특수 효과 생산라인에 새로운 활력을 불어넣을 수 있다. 본 개시의 기술방안에 관련된 사용자 개인정보의 획득, 저장 및 응용 등은, 모두 관련 법률법규의 규정에 부합 되며, 공서양속을 위반하지 않는다. 본 개시의 실시예에 따르면, 본 개시는 전자 설비, 판독 가능한 저장 매체 및 컴퓨터 프로그램 제품을 더 제공 한다. 도 5는 본 개시의 실시예의 이미지 렌더링 방법을 구현하기 위한 전자 설비의 블록도이다. 도 5는 본 개시의 실 시예의 예시를 구현할 수 있는 전자 설비의 예시적인 블록도를 도시한다. 전자 설비는 각종 형태의 디지털 컴퓨터, 예를 들어, 랩톱 컴퓨터, 데스크톱 컴퓨터, 워크테이블, 개인용 정보 단말기, 서버, 블레이드 서버, 대 형 컴퓨터 및 기타 적합한 컴퓨터를 의미한다. 전자 설비는 각종 형태의 모바일 장치를 표시할 수 있으며, 예를 들어, 개인 디지털 처리, 셀 폰, 스마트 폰, 웨어러블 설비 및 기타 유사한 컴퓨팅 장치를 표시할 수 있다. 본 문에서 설명된 컴포넌트, 이들의 연결과 관계 및 이들의 기능은 단지 예시적인 것일 뿐, 본 문에서 기술 및/또 는 요구되는 본 개시의 실현을 제한하려는 의도가 아니다. 도 5에 도시된 바와 같이, 전자 설비는 컴퓨팅 유닛을 포함하되, 이는 판독 전용 메모리(ROM)에 저장된 컴퓨터 프로그램 또는 저장 유닛으로부터 랜덤 액세스 메모리(RAM)에 로딩되는 컴퓨터 프로그 램에 따라, 각종 적합한 동작 및 처리를 수행할 수 있다. RAM에는 전자 설비의 조작에 필요한 각종 프로그램 및 데이터가 저장될 수도 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스를 통해 서로 연결된다. 입력/출력(I/O) 인터페이스도 버스에 연결된다. 전자 설비 중의 복수의 컴포넌트는 I/O 인터페이스에 연결되고, 해당 컴포넌트는 키패드, 마우스 등 과 같은 입력 유닛; 각종 유형의 표시장치, 스피커 등과 같은 출력 유닛; 자기디스크, 광디스크 등과 같은 저장 유닛; 및 네트워크 인터페이스 카드, 모뎀, 무선통신 트랜시버 등과 같은 통신 유닛을 포 함한다. 통신 유닛은 전자 설비가 인터넷과 같은 컴퓨터 네트워크 및/또는 각종 전기 통신망을 통해 기타 설비와 정보/데이터를 교환하는 것을 허용한다. 컴퓨팅 유닛은 처리 및 컴퓨팅 능력을 갖는 각종 범용 및/또는 전용 처리 컴포넌트일 수 있다. 컴퓨팅 유 닛의 일부 예시는 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 각종 전용 인공 지능(AI) 컴퓨팅 칩, 기 계 러닝 모델 알고리즘을 수행하는 각종 컴퓨팅 유닛, 디지털 신호 프로세서(DSP) 및 임의의 적합한 프로세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만, 이에 한정되지 않는다. 컴퓨팅 유닛은 위에서 설명한 각각 의 방법 및 처리를 수행하고, 예를 들어, 이미지 렌더링 방법을 수행한다. 예를 들어, 일부 실시예에서, 이미지 렌더링 방법은 컴퓨터 소프트웨어 프로그램으로 구현될 수 있고, 이는 저장 유닛과 같은 기계 판독 가능 매체에 유형적으로 포함된다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전체는 ROM 및/또는 통신 유 닛에 의해 전자 설비에 로딩 및/또는 장착될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되어 컴퓨 팅 유닛에 의해 실행되는 경우, 위에서 설명한 이미지 렌더링 방법의 하나 이상의 단계를 수행할 수 있다. 대안적으로, 기타 실시예에서, 컴퓨팅 유닛은 기타 임의의 적합한 방식(예를 들어, 펌웨어를 통해)을 통해 이미지 렌더링 방법을 수행하도록 구성될 수 있다. 본문에서 설명하는 시스템 및 기술의 각종 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로 그래머블 게이트 어레이 (FPGA), 주문형 집적 회로 (ASIC), 특정 용도 표준 제품(ASSP), 시스템 온칩(SOC), 복 합 프로그래밍 로직 설비(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합으로 구현될 수 있 다. 이와 같은 각종 실시형태는 하나 또는 복수의 컴퓨터 프로그램에서 실시되는 것을 포함할 수 있고, 해당 하 나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능한 프로세서를 포함하는 프로그램 가능한 시스 템에서 실행 및/또는 해석(interpretating)될 수 있으며, 해당 프로그램 가능한 프로세서는 전용 또는 범용 프 로그램 가능한 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신할 수 있으며, 데이터 및 명령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치 및 상 기 적어도 하나의 출력 장치로 전송한다. 본 개시의 방법을 실시하기 위한 프로그램 코드는 하나 이상의 프로그래밍 언어의 임의의 조합을 사용하여 작성 될 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 기타 프로그램 가능한 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공되어, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행되면, 흐름도 및/또 는 블록도에 규정된 기능/조작이 실시될 수 있도록 한다. 프로그램 코드는 전체가 기계에서 실행되거나, 일부가 기계에서 실행되고, 독립적인 소프트웨어 패키지로서 일부가 기계에서 실행되고 일부가 원격 기계에서 실행되거 나, 전부가 원격 기계 또는 서버에서 실행될 수 있다. 본 개시의 전문에서, 기계 판독 가능 매체는 유형 매체(tangible medium)일 수 있고, 이는 명령 실행 시스템, 장치 또는 설비에 의해 사용되거나, 명령 실행 시스템, 장치 또는 설비와 결합하여 사용되는 프로그램을 포함하 거나 저장할 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 설비, 또는 상 기 내용의 임의의 적합한 조합을 포함할 수 있지만 이에 한정되지 않는다. 기계 판독 가능 저장 매체의 보다 구 체적인 예시는 하나 이상의 와이어에 기반한 전기적 연결, 휴대용 컴퓨터 디스크, 하드디스크, 랜덤 액세스 메 모리(RAM), 판독 전용 메모리(ROM), 소거 및 프로그램 가능한 판독 전용 메모리(EPROM 또는 플래시 메모리), 광 섬유, 휴대용 콤팩트 디스크 판독 전용 메모리(CD-ROM), 광학 저장 설비, 자기 저장 설비 또는 상기 내용의 임 의의 적합한 조합을 포함한다. 사용자와의 상호 작용을 제공하기 위해, 여기서 설명된 시스템 및 기술을 컴퓨터에서 실시할 수 있고, 해당 컴 퓨터는 사용자에게 정보를 표시하기 위한 표시장치(예를 들어, CRT(음극선관) 또는 LCD(액정 표시장치) 모니 터), 키보드 및 방향지시 장치(예를 들어, 마우스 또는 트랙볼)를 구비하며, 사용자는 해당 키보드 및 해당 방 향지시 장치를 통해 컴퓨터에 입력을 제공할 수 있다. 기타 유형의 장치는 사용자와의 상호 작용을 제공할 수도 있고, 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 센싱 피드백(예를 들어, 시각 피드백, 청각 피 드백 또는 촉각 피드백)일 수 있으며, 임의의 형태(사운드 입력, 음성 입력 또는 촉각 입력)로 사용자로부터의 입력을 수신할 수 있다.여기서 설명된 시스템 및 기술은 백엔드 컴포넌트(back-end component)를 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버), 또는 미들웨어 컴포넌트(middleware component)를 포함하는 컴퓨팅 시스템(예를 들어, 애플리케 이션 서버), 또는 프런트엔드 컴포넌트(front-end component)를 포함하는 컴퓨팅 시스템(예를 들어, 그래픽 사 용자 인터페이스 또는 웹브라우저를 구비하는 사용자 컴퓨터, 사용자는 해당 그래픽 사용자 인터페이스 또는 해 당 웹브라우저를 통해 여기서 설명된 시스템 및 기술의 실시형태와 상호 작용할 수 있음), 또는 이러한 백엔드 컴포넌트, 미들웨어 컴포넌트, 또는 프런트엔드 컴포넌트를 포함하는 임의의 조합의 컴퓨팅 시스템에서 실시될 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)으로 시스템의 컴포넌트를 서 로 연결할 수 있다. 통신 네트워크의 예시는 근거리 통신망(LAN), 광역 통신망(WAN), 블록체인 네트워크 및 인 터넷을 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 으며, 통상적으로 통신 네트워크를 통해 상호 작용을 수행한다. 클라이언트와 서버의 관계는 상응하는 컴퓨터에 서 실행되고 서로 클라이언트-서버 관계를 갖는 컴퓨터 프로그램에 의해 발생된다. 서버는 클라우드 서버일 수 있으며, 클라우드 컴퓨팅 서버 또는 클라우드 호스트라고도 하며, 클라우드 서버는 클라우드 컴퓨팅 서비스 체 계 중의 하나의 호스트 제품으로, 종래의 물리적 호스트 및 VPS 서비스에 존재하는 관리 난이도가 크고, 비즈니 스 확장성이 약한 결함을 해결한다. 인공 지능은 컴퓨터가 사람의 특정 사유 과정과 지능 행위(예를 들어 학습, 추론, 사고, 계획 등)를 시뮬레이션 하는 학과이며, 하드웨어 층면의 기술도 있고 소프트웨어 층면의 기술도 있다. 인공 지능 하드웨어 기술은 일반 적으로 예를 들어 센서, 전용 인공 지능 칩, 클라우드 컴퓨팅, 분산저장, 빅데이터 처리 등의 기술을 포함하고; 인공 지능 소프트웨어 기술은 주로 컴퓨터 비전 기술, 음성 인식 기술, 자연어 처리 기술 및 기계 학습/딥 러닝 기술, 빅데이터 처리 기술, 지식 그래프 기술 등 몇개의 주요 방향을 포함한다. 클라우드 계산(cloud computing)은 네트워크를 통해 탄력적 확장 가능한 공유 물리적 또는 가상 리소스 풀에 접 속하고, 리소스에는 서버, 운영 시스템, 네트워크, 소프트웨어, 애플리케이션 및 저장 설비 등을 포함할 수 있 으며, 필요 및 셀프 서비스의 방식에 따라 리소스에 대해 부서 및 관리할 수 있는 기술을 의미한다. 클라우드 계산 기술을 통해, 인공 지능, 블록체인 등 기술 응용, 모델 훈련을 위해, 효율적이고 강대한 데이터 처리 능력 을 제공할 수 있다. 상술한 각종 형태의 프로세스를 사용하여, 단계의 순서재배정, 추가 또는 삭제를 수행할 수 있음을 이해해야 한 다. 예를 들어, 본 개시에 기재된 각 단계는 병렬로 수행될 수 있거나 순차적으로 수행될 수 있거나 서로 다른 순서로 수행될 수도 있으며, 본 개시에서 개시한 기술방안이 희망하는 결과를 구현할 수 있기만 하면, 본 문에 서는 이에 대해 한정하지 않는다. 상기 구체적인 실시형태는 본 개시의 보호 범위를 한정하지 않는다. 본 분야의 당업자는 설계 요구 및 기타 요 소에 따라 다양한 수정, 조합, 부분 조합 및 대체가 가능함을 이해할 수 있을 것이다. 본 개시의 사상 및 원칙 내에서 이루어진 수정, 등가적 대체 및 개선 등은 모두 본 개시의 보호범위 내에 포함되어야 한다.도면 도면1a 도면1b 도면2 도면3a 도면3b 도면4 도면5"}
{"patent_id": "10-2023-0032849", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면은 본 방안을 더 잘 이해하기 위해 사용된 것으로, 본 개시를 제한하지 않는다. 여기서, 도 1a는 본 개시의 실시예에서 제공하는 이미지 렌더링 방법의 흐름도이다. 도 1b는 관련기술의 CG 렌더링 파이프라인의 개략도이다. 도 2는 본 개시의 실시예에서 제공하는 다른 이미지 렌더링 방법의 흐름도이다. 도 3a는 본 개시의 실시예에서 제공하는 또 다른 이미지 렌더링 방법의 흐름도이다. 도 3b는 본 개시의 실시예에서 제공하는 뉴럴 렌더링 및 CG 렌더링 파이프라인에 의해 융합 렌더링을 수행하는 개략도이다. 도 4는 본 개시의 실시예에서 제공하는 이미지 렌더링 장치의 구조 개략도이다. 도 5는 본 개시의 실시예의 이미지 렌더링 방법을 구현하기 위한 전자 설비의 블록도이다."}
