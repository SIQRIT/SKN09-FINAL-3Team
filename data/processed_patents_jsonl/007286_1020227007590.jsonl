{"patent_id": "10-2022-7007590", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0054317", "출원번호": "10-2022-7007590", "발명의 명칭": "시냅스 재사용이 가능한 인공 지능 하드웨어", "출원인": "인터내셔널 비지네스 머신즈 코포레이션", "발명자": "로이, 수브라지트"}}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "회로에 있어서, 상기 회로는:복수의 인공 뉴런들;복수의 인공 시냅스들 - 상기 복수의 인공 시냅스들의 각각은 상기 복수의 인공 뉴런들 중 대응하는 하나와 연관됨 -;복수의 가변 이득 증폭기들 - 상기 복수의 가변 이득 증폭기들의 각각은 상기 복수의 인공 뉴런들 중 대응하는하나와 연관됨 -;대응하는 가변 이득 증폭기 및 대응하는 인공 시냅스를 통해 복수의 입력 소스들 중 적어도 하나를 상기 복수의인공 뉴런들의 각각에 연결하도록 구성된, 라우터; 및주어진 시간 동안 스파이크를 전송하는 입력 소스의 신원(identity) 및 시간 분할 스키마에 기초하여 상기 복수의 가변 이득 증폭기들의 각각에 대한 이득을 세트 하도록 구성된, 이득 구성 컨트롤러를 포함하는회로."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 복수의 인공 뉴런들 중 주어진 인공 뉴런에 연결된 다수의 입력 소스들은 상기 시간 분할 스키마 및 상기 복수의 입력 소스로부터의 스파이크 전송 속도에 기초하는회로."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 라우터 및 상기 이득 구성 컨트롤러는 상기 복수의 인공 뉴런들 중 제1 인공 뉴런이, 제1이득에서, 상기 복수의 입력 소스들 중 제1 입력 소스로부터 제1 스파이크를 수신하도록 허용하고 그리고 상기복수의 인공 뉴런들 중 제2 인공 뉴런이, 상기 제1 이득과 독립적으로 세트된 제2 이득에서, 상기 복수의 입력소스들 중 제1 입력 소스로부터 상기 제1 스파이크를 수신하도록 허용하는회로."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 라우터 및 상기 이득 구성 컨트롤러는 상기 복수의 인공 뉴런들 중 제1 인공 뉴런이, 제1시간 동안, 상기 복수의 입력 소스들 중 제1 입력 소스로부터 제1 스파이크를 수신하도록 허용하고 그리고 상기복수의 인공 뉴런들 중 제2 인공 뉴런이, 상기 제1 시간에, 상기 복수의 입력 소스들 중 제2 입력 소스로부터제2 스파이크를 수신하도록 허용하는회로."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 복수의 입력 소스들 중 제1 입력 소스는, 제1 전송 속도에서, 스파이크들을 전송하고, 상기 복수의 입력 소스들 중 제2 입력 소스는, 상기 제1 전송 속도와 다른, 제2 전송 속도에서, 스파이크들을 전송하는 회로."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 라우터는 상기 복수의 입력 소스들로부터 입력 스파이크들을 수신 및 저장하도록 구성된공개특허 10-2022-0054317-3-레지스터를 포함하고, 상기 시간 분할 스키마에 기초하여 상기 레지스터로부터 상기 입력 스파이크들을 재전송하는회로."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 라우터 및 상기 이득 구성 컨트롤러는 공유 클록 신호를 통해 컨트롤되는 회로."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 복수의 가변 이득 증폭기들의 각각은 대응하는 인공 뉴런에 상대적인 대응하는 하나의 인공 시냅스의 업스트림에 위치하는 회로."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 복수의 인공 뉴런들, 상기 복수의 인공 시냅스들, 상기 복수의 가변 이득 증폭기들, 상기라우터, 및 상기 이득 구성 컨트롤러는 단일 집적 회로에 정의되는 회로."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "방법에 있어서, 상기 방법은:스파이크 신경망(SNN)에서 뉴런들을 훈련하는 단계;상기 훈련에 기초하여, 입력 소스들에 대한 시간 분할 스키마를 상기 뉴런들에 할당하는 단계;상기 훈련에 기초하여, 상기 뉴런들에 대한 이득을 상기 시간 분할 스키마에서 할당하는 단계;상기 입력 소스들로부터 입력들을 수신하는 단계;상기 할당된 이득들 및 주어진 입력이 수신되는 주어진 입력 소스에 기초하여, 주어진 뉴런에 대한 주어진 이득을 세트 하는 단계; 그리고상기 이득에 따라 상기 주어진 입력을 상기 주어진 뉴런으로 전송하는 단계를 포함하는방법."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 주어진 이득을 세트 하는 단계는:상기 주어진 입력이 수신된 주어진 입력 소스의 신원(ID)에 기초하여 상기 주어진 이득을 세트 하는 단계를 더포함하는방법."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 뉴런들 중 제1 뉴런은 상기 입력 소스들 중 제1 입력 소스로부터 제1 입력을, 제1 이득에서, 수신하고, 상기 뉴런들 중 제2 뉴런은 상기 제1 입력을, 상기 제1 이득과 다른 제2 이득에서, 수신하는방법."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 뉴런들 중 제1 뉴런은 상기 입력 소스들 중 제1 입력 소스로부터 제1 입력을, 제1 시간에, 수신하고 상기 뉴런들 중 제2 뉴런은 상기 입력 소스들 중 제2 입력 소스로부터 제2 입력을, 제1 시간에,수신하는 방법. 공개특허 10-2022-0054317-4-청구항 14 제10항에 있어서, 상기 방법은:상기 수신된 입력들을 레지스터에 상기 시간 분할 스키마에서의 대응 시간까지 저장하는 단계를 더 포함하는방법."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 주어진 이득을 세트 하는 단계는:상기 주어진 입력이 수신된 주어진 입력 소스와 연관되는 대응 시간에 기초하여 상기 주어진 이득을 세트 하는단계를 더 포함하는방법."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 방법은:상기 입력 소스들 중 하나의 입력 소스로부터 2개의 입력 스파이크들을 수신하는 것에 응답하여, 상기 하나의입력 소스로부터 2개의 입력 스파이크들 중 먼저 수신된 입력 스파이크를 드롭하는 단계를 더 포함하는방법."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서, 상기 방법은:상기 뉴런들 중 하나의 뉴런으로의 전송을 위해 하나의 시간 분할 동안 적어도 2개의 입력 스파이크들을 수신하는 것에 응답하여, 상기 적어도 2개의 입력 스파이크들을 충돌시키는 단계(colliding)를 더 포함하는방법."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "시스템에 있어서, 상기 시스템은:가변 이득 증폭기를 포함하는 신호 경로;상기 신호 경로를 통해 복수의 입력 소스들에 연결된 인공 뉴런; 및상기 복수의 입력 소스 중 어느 입력 소스가 상기 인공 뉴런으로 입력 스파이크를 전송하는지에 기초하여 가변이득 증폭기에서 이득을 세트 하도록 구성된 이득 구성 컨트롤러를 포함하는 시스템."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 시스템은:상기 복수의 입력 소스들에 연결되고, 상기 복수의 입력 소스들 중 하나의 입력 소스를, 한 번에, 상기 인공 뉴런에, 상기 신호 경로를 통해, 연결하도록 구성된 라우터를 더 포함하는 시스템."}
{"patent_id": "10-2022-7007590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서, 상기 시스템은:상기 이득 구성 컨트롤러 및 상기 복수의 입력 소스들에 연결된 라우터를 더 포함하고, 상기 라우터는 상기 복수의 입력 소스들 중 어느 입력 소스가 상기 입력 스파이크를 전송하고 있는지를 상기 이득 구성 컨트롤러에 식별하도록 구성된공개특허 10-2022-0054317-5-시스템."}
{"patent_id": "10-2022-7007590", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "시냅스 재사용이 가능한 인공 지능 하드웨어 시냅스 재사용은 복수의 인공 뉴런들이 대응하는 복수의 인공 시냅스들 및 가변 이득 증폭기들과 연관되도록 하 여, 이에 의해서 각 입력 소스에 대한 전용 경로들을 갖는 뉴런들 보다 더 적은 공간과 더 적은 구현할 컴포넌트 들 및 더 적은 운영전력을 사용할 수 있게 한다. 신호 충돌의 가능성을 줄이고 입력 스파이크들의 독립적인 컨트 롤 및 해석을 허용하기 위해, 라우터는, 주어진 시간 동안 스파이크를 전송하는 입력 소스의 신원(ID) 및 시간 분할 스키마에 기초하여 복수의 가변 이득 증폭기들의 각각에 대한 이득을 세트 하도록 구성된 이득 구성 컨트롤 러와 함께, 입력 소스들을 복수의 인공 뉴런들의 각각에 연결하도록 구성된다."}
{"patent_id": "10-2022-7007590", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "인공 신경망들(ANN)은 뇌의 구조를 본뜬 하드웨어 및 소프트웨어를 사용하여 자연적인 뇌의 학습 및 인 식 능력을 시뮬레이션하기 위해 인공 지능 애플리케이션들에 사용된다. 신경망에서 다양한 알고리즘은 뉴런들이 라고 하는 일련의 연결된 유닛들 또는 노드들을 통한 패턴 인식을 통해 다양한 작업들을 수행하도록 \"가르쳐질\" 수 있다. 이들 뉴런들은 시냅스들이고 하는 연결들을 통해 신경망 내의 다른 뉴런들과 입력 및 출력을 내부적으 로 공유한다. 신경망이 훈련됨에 따라 다양한 뉴런들은 이러한 시냅스들을 통해 다양한 다른 뉴런들로부터 수신 되는 다양한 입력들에 대해 서로 다른 가중치들을 제공하도록 훈련된다."}
{"patent_id": "10-2022-7007590", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스파이킹 신경망들(SNN들)은 2개의 뉴런들 사이에 정보를 전달하기 위해 주어진 시냅스를 따라 정보의 \"스파이크들(spikes)\" 또는 시간적 동작 전위들(timed action potentials)의 사용을 통해 생물학적 신경망(즉, 동물의 뇌)의 행동을 모델링하는 3세대 ANN이다. SNN들은 인공 지능을 모델링하는 데 더 생물학적 사실적(bio-realistic)으로 간주되며 이전 세대의 ANN들보다 계산 면에서 더 강력하며, 한편 매우 큰 규모 집적 (VLSI) 회로 같은 하드웨어에 집적될 때 잡음에 강한, 저-전력, 저-전압 구현들을 제공한다."}
{"patent_id": "10-2022-7007590", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "하드웨어에서 SNN을 모델링할 때, 이전 세대 ANN들과 비교하여 SNN의 풍부한 비-선형 다이나믹스를 실현 하기 위해 제작자들은 종종 더 많은 트랜지스터를 사용해야 하며(S자형 뉴런 또는 퍼셉트론 기반 ANN들과 비교 하여), 이는 SNN을 나타내는 데 필요한 총 메모리의 증가 및 그러한 하드웨어 구현들의 전력 소비에서 대응하는 증가로 이어질 수 있다. 일반적으로 시냅스들의 수가 SNN에서 뉴런들의 수보다 많기 때문에, SNN들은 구현하기 위해 많은 수의 하드웨어 컴포넌트들(예: 트랜지스터)이 필요할 수 있으며 해당 하드웨어 컴포넌트들을 패턴화 하고 배치하기 위해 칩에 대응하는 큰 양의 공간이 필요로 한다. 컴포넌트들을 수용하기 위한 더 큰 공간 요구 사항 외에도, 추가 컴포넌트들은 SNN의 복잡성이 확장됨에 따라 운영하는 데 더 많은 전력이 필요하는데, 이는 SNN을 구현하는데 부피가 크고, 제조하기도 어려우며, 전력 소모가 많은 회로로 이어진다."}
{"patent_id": "10-2022-7007590", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따라, 회로가 제공되고, 상기 회로는: 복수의 인공 뉴런들; 복수의 인공 시냅스 들 - 상기 복수의 인공 시냅스들의 각각은 상기 복수의 인공 뉴런들 중 대응하는 하나와 연관됨 -; 복수의 가변 이득 증폭기들 - 상기 복수의 가변 이득 증폭기들의 각각은 상기 복수의 인공 뉴런들 중 대응하는 하나와 연관 됨 -; 대응하는 가변 이득 증폭기 및 대응하는 인공 시냅스를 통해 복수의 입력 소스들 중 적어도 하나를 상기 복수의 인공 뉴런들의 각각에 연결하도록 구성된, 라우터; 및 주어진 시간 동안 스파이크를 전송하는 입력 소스 의 신원(identity) 및 시간 분할 스키마에 기초하여 상기 복수의 가변 이득 증폭기들의 각각에 대한 이득을 세 트 하도록 구성된, 이득 구성 컨트롤러를 포함하며, 이에 의해서 상기 입력 소스들과 그 안에 정의된 뉴런들 간 의 다수의 전용 경로들을 포함하는 회로들 보다 더 적은 공간, 구현하는데 더 적은 컴포넌트들, 작동하는데 더 적은 전력을 사용하게 한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 회로와 결합하여, 상기 복수의 인공 뉴런들 중 주어진 인공 뉴런에 연결된 다수의 입력 소스들은 상기 시간 분할 스키마 및 상기 복수의 입력 소스로부터의 스 파이크 전송 속도에 기초하며, 이는 바람직하게도 공유 전송 경로상에서 신호 충돌들의 가능성을 감소시킨다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 회로와 결합하여, 상기 라우터 및 상기 이득 구 성 컨트롤러는 상기 복수의 인공 뉴런들 중 제1 인공 뉴런이, 제1 이득에서, 상기 복수의 입력 소스들 중 제1 입력 소스로부터 제1 스파이크를 수신하도록 허용하고 그리고 상기 복수의 인공 뉴런들 중 제2 인공 뉴런이, 상 기 제1 이득과 독립적으로 세트된 제2 이득에서, 상기 복수의 입력 소스들 중 제1 입력 소스로부터 상기 제1 스 파이크를 수신하도록 허용하며, 이는 바람직하게도 서로 다른 뉴런들이 서로로부터 독립적으로 입력소스의 효과를 해석하도록 한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 회로와 결합하여, 상기 라우터 및 상기 이득 구 성 컨트롤러는 상기 복수의 인공 뉴런들 중 제1 인공 뉴런이, 제1 시간 동안, 상기 복수의 입력 소스들 중 제1 입력 소스로부터 제1 스파이크를 수신하도록 허용하고 그리고 상기 복수의 인공 뉴런들 중 제2 인공 뉴런이, 상 기 제1 시간에, 상기 복수의 입력 소스들 중 제2 입력 소스로부터 제2 스파이크를 수신하도록 허용하며, 이는 바람직하게도 서로 다른 신호 소스들로부터 서로 다른 뉴런들에 의한 독립적인 신호 수신을 허용한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 회로와 결합하여, 상기 복수의 입력 소스들 중 제1 입력 소스는, 제1 전송 속도에서, 스파이크들을 전송하고, 상기 복수의 입력 소스들 중 제2 입력 소스는, 상기 제1 전송 속도와 다른, 제2 전송 속도에서, 스파이크들을 전송하며, 이는 바람직하게도 상기 회로가 독립 적으로 작동되는 소스들로부터 입력들을 수신하도록 한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 회로와 결합하여, 상기 라우터는 상기 복수의 입력 소스들로부터 입력 스파이크들을 수신 및 저장하도록 구성된 레지스터를 포함하고, 상기 시간 분할 스키마 에 기초하여 상기 레지스터로부터 상기 입력 스파이크들을 재전송하며, 이는 바람직하게도 공유 전송 경로상에 서 신호 충돌들의 가능성을 감소시킨다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 회로와 결합하여, 상기 라우터 및 상기 이득 구 성 컨트롤러는 공유 클록 신호를 통해 컨트롤되며, 이는 바람직하게도 상기 라우터 및 상기 이득 구성 컨트롤러 의 작동들을 정렬한다(align). 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 회로와 결합하여, 복수의 가변 이득 증폭기들의 각각은 대응하는 인공 뉴런에 상대적인 대응하는 하나의 인공 시냅스의 업스트림에 위치하며, 이는 바람직하게 도 상기 시냅스가 상기 입력이 수신되는 소스에 기초하여 입력을 해석하는 방법을 컨트롤한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 회로와 결합하여, 상기 복수의 인공 뉴런들, 상 기 복수의 인공 시냅스들, 상기 복수의 가변 이득 증폭기들, 상기 라우터, 및 상기 이득 구성 컨트롤러는 단일 집적 회로에 정의되며, 이는 바람직하게도 신호 지연들을 감소시키고 상기 회로에 의해서 제공되는 공간 사용에 서 더 완전한 이점을 누릴 수 있게 해 준다. 본 발명의 일 실시 예에 따라, 방법을 제공하고, 상기 방법은: 스파이크 신경망(SNN)에서 뉴런들을 훈련 하는 단계; 상기 훈련에 기초하여, 입력 소스들에 대한 시간 분할 스키마를 상기 뉴런들에 할당하는 단계; 상기 훈련에 기초하여, 상기 뉴런들에 대한 이득을 상기 시간 분할 스키마에서 할당하는 단계; 상기 입력 소스들로부 터 입력들을 수신하는 단계; 상기 할당된 이득들 및 주어진 입력이 수신되는 주어진 입력 소스에 기초하여, 주 어진 뉴런에 대한 주어진 이득을 세트 하는 단계; 그리고 상기 이득에 따라 상기 주어진 입력을 상기 주어진 뉴 런으로 전송하는 단계를 포함하며, 이에 의해서 그 안에 정의된 뉴런을 위한 입력 소스들에 대해 여러 전용 경 로들을 포함하는 회로들 보다 더 적은 공간, 구현하는데 더 적은 컴포넌트들, 작동하는데 더 적은 전력을 사용 하는 하나 또는 그 이상의 입력 소스들을 위한 공유된 전송 경로들을 사용하는 뉴런들을 포함하는 회로를 작동 시킨다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 방법과 결합하여, 상기 주어진 이득을 세트 하 는 단계는: 상기 주어진 입력이 수신된 주어진 입력 소스의 신원(ID)에 기초하여 상기 주어진 이득을 세트 하는 단계를 더 포함하며, 이는 바람직하게도, 공유 전송 경로를 사용하는 동안, 상기 레이닝(the raining)에 기초하 여, 상기 뉴런들이 서로 다른 가중치들을 신호들에 적용하도록 한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 방법과 결합하여, 상기 뉴런들 중 제1 뉴런은 상기 입력 소스들 중 제1 입력 소스로부터 제1 입력을, 제1 이득에서, 수신하고, 상기 뉴런들 중 제2 뉴런은 상 기 제1 입력을, 상기 제1 이득과 다른 제2 이득에서, 수신하며, 이는 바람직하게도, 서로 다른 뉴런들이 서로로 부터 독립적으로 입력소스의 효과를 해석하도록 한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 방법과 결합하여, 상기 뉴런들 중 제1 뉴런은 상기 입력 소스들 중 제1 입력 소스로부터 제1 입력을, 제1 시간에, 수신하고 상기 뉴런들 중 제2 뉴런은 상기 입력 소스들 중 제2 입력 소스로부터 제2 입력을, 제1 시간에, 수신하며, 이는 바람직하게도, 서로 다른 신호 소스들로부터 서로 다른 뉴런들에 의한 독립적인 신호 수신을 허용한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 방법과 결합하여, 상기 방법은: 상기 수신된 입 력들을 레지스터에 상기 시간 분할 스키마에서의 대응 시간까지 저장하는 단계를 더 포함하며, 이는 바람직하게 도, 상기 공유 전송 경로를 위해 시간-기반 멀티플렉싱 스키마를 사용할 수 있게 한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 방법과 결합하여, 상기 주어진 이득을 세트 하 는 단계는: 상기 주어진 입력이 수신된 주어진 입력 소스와 연관되는 대응 시간에 기초하여 상기 주어진 이득을 세트 하는 단계를 더 포함하며, 이는 바람직하게도, 상기 공유 전송 경로를 위해 시간-기반 멀티플렉싱 스키마 를 사용할 수 있게 한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 방법과 결합하여, 상기 방법은: 상기 입력 소스 들 중 하나의 입력 소스로부터 2개의 입력 스파이크들을 수신하는 것에 응답하여, 상기 하나의 입력 소스로부터 2개의 입력 스파이크들 중 먼저 수신된 입력 스파이크를 드롭하는 단계를 더 포함하며, 이는 바람직하게도, 상 기 공유 전송 경로를 상의 신호 충돌들의 효과 또는 빈도를 감소시킬 수 있게 한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 방법과 결합하여, 상기 방법은: 상기 뉴런들 중 하나의 뉴런으로의 전송을 위해 하나의 시간 분할 동안 적어도 2개의 입력 스파이크들을 수신하는 것에 응답하 여, 상기 적어도 2개의 입력 스파이크들을 충돌시키는 단계(colliding)를 더 포함하며, 이는 바람직하게도, 소 프트웨어의 컨트롤 하드웨어를 더 적게 요구하고 대신에 SNN의 견고함에 의지하여 신호 충돌들을 무시하거나 또 는 보상할 수 있게 한다. 본 발명의 일 실시 예에 따라, 시스템을 제공하고, 상기 시스템은: 가변 이득 증폭기를 포함하는 신호 경로; 상기 신호 경로를 통해 복수의 입력 소스들에 연결된 인공 뉴런; 및 상기 복수의 입력 소스 중 어느 입력 소스가 상기 인공 뉴런으로 입력 스파이크를 전송하는지에 기초하여 가변 이득 증폭기에서 이득을 세트 하도록 구성된 이득 구성 컨트롤러를 포함하며, 이는 바람직하게도 상기 뉴런이 공유 전송 경로들 통해 다수의 소스들 로부터 다수의 입력들을 수신할 수 있게 하고 이에 의해서 여러 전용 경로들을 사용하는 뉴런들 보다 더 적은 공간, 구현하는데 더 적은 컴포넌트들, 작동하는데 더 적은 전력을 사용하게 한다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 시스템과 결합하여, 상기 시스템은: 상기 복수 의 입력 소스들에 연결되고, 상기 복수의 입력 소스들 중 하나의 입력 소스를, 한 번에, 상기 인공 뉴런에, 상 기 신호 경로를 통해, 연결하도록 구성된 라우터를 더 포함하며, 이는 바람직하게도 공유 전송 경로상에서 신호 충돌들의 가능성을 감소시킨다. 일부 실시 예들에서, 위에서 또는 아래에서 기술된 모든 시스템과 결합하여, 상기 시스템은: 상기 이득 구성 컨트롤러 및 상기 복수의 입력 소스들에 연결된 라우터를 더 포함하고, 상기 라우터는 상기 복수의 입력 소스들 중 어느 입력 소스가 상기 입력 스파이크를 전송하고 있는지를 상기 이득 구성 컨트롤러에 식별하도록 구성되며, 이는 바람직하게도 어느 입력 스파이크들이 어느 뉴런들로 라우트될 지와 상기 뉴런 및 송기 입력 소 스의 신원에 기초하여 이들 입력 스파이크들이 이득들을 컨트롤한다."}
{"patent_id": "10-2022-7007590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다수의 입력들을 뉴런으로 보내기 위한 시냅스들을 재사용함으로써 감소된 메모리 사용 및 칩 면적을 갖는 하드웨어로 스파이킹 신경망(Spiking Neural Network: SNN)의 구현을 제공한다. 각 뉴런이 최대 X 개의 입력들을 수신하도록 X개의 시냅스들을 제공하는 대신, 시냅스 재사용을 통해 뉴런은 X개보다 적은 수의 시냅스들을 사용하여 X개의 입력들을 수신할 수 있다. 다양한 실시 예들에서, 스파이크들이 뉴런에 의해 수신되 는 시기 및 방법을 조절하기 위해 시간 분할 멀티플렉싱(Time Division Multiplexing: TDM)을 사용하여 시냅스 의 전송 경로를 공유하는 최대 X개의 입력들을 수신하도록 뉴런들에는 단일 입력 시냅스가 각각 제공된다. 따라 서 하드웨어로 구현되는 시냅스들의 수를 감소시킴으로써 공간 요구 사항들, 제작에 필요한 컴포넌트들의 수, 및 이들 컴포넌트들을 구동하는 데 필요한 전력을 감소시킬 수 있다. 도 1은 본 발명의 실시 예들에 따라, n개의 입력 소스들(120a-n)(일반적으로, 입력 소스)로부터 입 력들을 수신하는 예시적인 뉴런을 도시한다. 뉴런의 예시적인 회로는 도 4a 및 도 4b와 관련하여 더 상세히 논의되지만, 다른 회로도 다양한 실시 예들에서 사용될 수 있다. 입력 소스는 인공 신경망(Artificial Neural Network: ANN)의 앞선 계층(an earlier layer) 내의 뉴런일 수 있으며, 상기 뉴런은 ANN으로의 데이터 입력을 위한 직접 피드(a direct feed)(예를 들어, 상기 뉴런이 ANN의 제1 계층 내에 있을 때)이거나 또는 ANN의 동일 또는 나중 계층(a later layer) 내의 다른 뉴런으로부터의 피드백 입력일 수 있다. 뉴런은 입력 소스로부터 다양한 데이터를 수신하 고, 상기 다양한 데이터는 연관된 입력 소스의 활동 전위(the action potential)가 만족될 때 SNN에서 \"스 파이크\"로서 수신된다. 차례로, 이들 입력들은 출력 스파이크를 \"발사(fire)\"할 때를 결정하기 위해 뉴런 에 의해 처리되며, 한편 이들 입력들은SNN의 출력으로서 또는 SNN의 다른 뉴런에 대한 입력으로서 전송될 수 있다. SNN에서, 뉴런은 (반드시) 모든 잠재적 시간 간격에서 출력을 생성하지(produce) 않는다. 대신에, 뉴런은 이전에 제공된 입력에 기초하여 출력 스파이크를 생성할 것인지를 결정한다. 이들 입력들은 뉴런 이 다운스트림 소비를 위한 출력 스파이크를 내보낼 수 있도록 뉴런의 활동 전위를 극복하기 위해 주 어진 시간 기간 내에 입력들의 충분한 수 및/또는 강도가 수신될 필요가 있도록 시간이 지남에 따라 감쇄될 수 있다. 따라서, 다른 뉴런들을 포함하는 입력 소스들로부터 수신될 수 있는, 주어진 뉴런은, 이 들 다른 뉴런들로부터의 활동 전위들이 만족되는 시기에 따른 다양한 시간들에서 수신된다. 뉴런은 입력 소스들로부터 다른 시간들에 전송된 입력을 수용할 수 있고, 입력 소스들은 모든 잠재적 시간 간격에서 뉴런에 신호를 (반드시) 전송하지는 않기 때문에, 뉴런은 서로 다른 시간 들에서 입력 소스들과 뉴런들 사이의 공유 경로를 통해 여러 입력들을 수신할 수 있다. 입력 소스들 로부터 뉴런으로 입력들을 제공하기 위해 하나(또는 적어도 몇개)의 신호 경로를 사용함으로써, 각 입력 소스와 뉴런 사이에 제공된 전용 신호 경로들을 사용하는 구현들과 비교하여, 더 적은 하드웨어, 더 적은 전력 및 더 적은 공간이 뉴런을 정의하는 집적 회로 상에서 사용될 수 있다. 예를 들어, 10개의 입력 소스들로부터 입력들을 수신하도록 구성된 10개의 뉴런들을 갖는 집적 회로상에서, 만일 전용 신호 경로들이 사용된다면, 100개의 신호 경로들이 구현되어야 할 필요가 있는데, 이는 오직 10개의 신호 경로들만 필요한 본 발명과 비교된다. 도 2는, m개의 뉴런들(110a-m)의 각각을 위한 하나의 대응하는 시냅스(210a-m)(일반적으로, 시냅스 )를 통해 최대 n개의 입력 소스들(120a-n)로부터 입력을 수신하도록 최대 m개의 뉴런들(110a-m)을 관리하 기 위한, 본 발명의 실시 예들에 따른, 예시적인 집적 회로 레이아웃을 도시한다. 시냅스의 예시적인 회로는 도 5a 및 5b와 관련하여 더 상세히 논의되며, 다른 회로도 다양한 실시 예들에서 사용될 수 있다. SNN에서, 한 계층의 모든 뉴런이 다음 계층의 모든 뉴런에 반드시 연결되는 것은 아니며, 대 신에 라우터가 포함되어 특정 입력 소스들을 특정 뉴런들에 링크한다. 라우터로부터 뉴런 들(110a-m)로 인도하는 각 신호 경로들 상에 대응하는 가변 이득 증폭기(250a-m)(일반적으로 증폭기) 및 시냅스(210a-m)이 포함된다. 다양한 실시 예들에서, 증폭기들 및 시냅스들은 예시된 순서로 또는 역 순으로(예를 들어, 시냅스 업스트림으로 또는 연관된 증폭기로부터 다운스트림으로) 대응하는 신호 경로 상에 포함될 수 있다. 다양한 실시 들예에서, 어떤 입력 소스들 및 뉴런들이 링크 될 것인지를 식별하고, SNN 훈련의 모든 반복 후에 조정될 수 있는, SNN의 훈련 단계에 기초하여, 라우터는 입력 소스 들(120a-n) 중 하나 또는 그 이상을 뉴런들(110a-m) 중 하나 또는 그 이상에 링크 또는 연결하도록 구성된다. 일부 실시 예들에서, SNN의 구성에 기초하여, 모든 뉴런들이 모든 입력 소스들로부터 입력들 을 수신하는 것은 아니지만, 라우터는 임의의 특정 입력 소스를 임의의 특정 뉴런에 연결할 수 있고, 하나의 신호 경로를 통해 하나 또는 그 이상의 입력 소스들 하나의 뉴런에 연결할 수 있다. 예 를 들어, 시간 t1에 제1 입력 소스(120a) 및 제2 입력 소스(120b) 둘 모두는 각각의 제1 스파이크 및 제2 스파 이크를 전송할 수 있다. 이 예에서, 라우터는 제1 뉴런(110a)을 제1 입력 소스(120a)에 연결하고, 제2 뉴 런(110b)을 제2 입력 소스(120b)에 연결하지만, 제1 뉴런(110a)을 제2 입력 소스(120b)에 또는 제2 뉴런(110 b)을 제1 입력 소스(120a)에 연결하지는 않는다. 따라서, 라우터는 다수의 뉴런들(110a)이 스파이크들의 충돌 없이 이질적인 입력 소스들(disparate inputs sources)로부터 스파이크들을 수신하는 것을 허용한다. 반대로, 만일 라우터가 위의 예에서 제1 뉴런(110a)을 제1 입력 소스(120a) 및 제2 입력 소스(120b)에 링 크했다면, 두 개의 스파이크들은 충돌할 것이며, 그리고 제1 뉴런(110a)은 입력이 어디로부터 수신되었는 지와 그러한 입력을 어떻게 처리해야 하는 지에 관한 정의를 잃어버릴 수 있다. 그러나, 다양한 다른 입력 소스들 이 서로 동시에 스파이크들을 전송하는 것이 예측되지(또는 허용되지) 않았을 때 또는 그렇지 않다면 전송 된 스파이크들이 충돌하는 것을 피하기 위해 시간-분리되었을(time-separated) 때, 라우터는 이들 다른 입 력 소스들을 제1 뉴런(110a)에 연결할 수 있다. 예를 들어, 라우터는 제1 뉴런(110a)을 n개의 서로 다른 입력 소스들(120a-n)에 연결할 수 있는데, 각각이 시간 기간의 개별 시간 분할 내에서 전송하도록 제한될 때, 라우터가 시간 분할 재전송을 위해 스파이크들을 캐시 할 때, 등이다. 다양한 실시 예들에서, 라우터는 다양한 입력 소스들이 다양한 시간들에서 다양한 뉴런들 에 링크되는 방식을 변경하기 위해 클록 신호에 따라 구동된다. 예를 들어, 시간 t0에서 라우터(22 0)는 제1 입력 소스(120a)를 제1 뉴런(110a) 및 제2 뉴런(110b)에 연결할 수 있지만, 제3 뉴런(110c)에는 연결 할 수 없다. 그후 시간 t1에서 라우터는 제2 입력 소스(120b)를 제1 뉴런(110a), 제2 뉴런(110b) 및 제3 뉴런(110c)에 연결할 수 있다. 그러한 실시 예들에서, 라우터는 여러 입력 소스들이 서로 다른 시간 들에서 각각의 개별 뉴런에 연결될 수 있지만, 주어진 뉴런에 하나 이상의 입력 소스들이 연결 되는 일은 결코 없음을 보장한다. 또한, 라우터는 주어진 시간에 입력을 수신할 수 있는 뉴런들을 변 경할 수 있다. 따라서 라우터는 개별의 입력 소스들로부터 할당된 시간 창 외부에서 생성된 스파이크 들이 주어진 뉴런을 위한 공유 신호 경로를 통해 충돌하는 것을 방지하기 위해 시간 분할 스키마에 따라 다양한 뉴런들과 입력 소스들 사이의 연결들을 설정하거나 끊을 수 있다. 일부 실시 예들에서, 라우터는 모든 입력 소스들(120a-n)로부터 입력 스파이크들을 수신하고 입력 스파이크들이 수신된 입력 소스를 식별한 후 상기 입력 스파이크들을 모든 뉴런들(110a-m)에 재전송한다. 입력 소스의 신원(identity)에 기초하여, 각 뉴런(110a-m)은 상기 입력 소스에 대해 독립적으로 튜닝 된 이득(입력 스파이크를 차단하거나 또는 그렇지 않으면 수신 임계 값 아래로 떨어지게 하는 이득들 - 효과적 으로 뉴런이 입력 스파이크를 수신하지 않도록 하는 이득들을 포함)에 따라 입력 스파이크를 수신한다. 독 립적으로 튜닝된 이득들은 SNN의 훈련 또는 학습 단계 동안 다양한 입력 소스들로부터의 입력 스파이크들 에 대해 뉴런들에 의해 학습된 가중치들에 기초한다. 다양한 실시 예들에서, 라우터는 시간 분할 스키마 내의 지정된 시간 분할에서 뉴런으로의 전 송을 위해 입력 소스들로부터 수신된 스파이크들을 수신하고 유지하는 선택적 레지스터를 포함한다. 예를 들어, 1초의 기간을 사용하는 시간 분할 스키마에서, 레지스터는 상기 1초 기간에 수신된 임의의 입 력을 홀드 하고 그 기간 내에 지정된 시간 분할에서 저장된 스파이크를 전송할 수 있다. 레지스터는 개별 입력 소스로부터 수신된 스파이크를 홀드 한 다음, 링크된 뉴런들로 재-전송하기 위해 각 입력 소스 를 위한 개별 메모리 유닛들을 포함할 수 있다. 일부 실시 들예에서, 레지스터는 클록 신호에 따라 구동되어, 메모리에 저장된 스파이크들을 재전송할지를 시기를 결정하며, 이 시기에 레지스터는 메모 리가 스파이크를 포함하게(또는 포함하지 않게) 하도록, 연관된 입력 소스가 다른 스파이크를 그 다음 기 간(the next time peried)에 전송하는지에 기초하여, 메모리를 클리어하거나 제로 아웃한다. 추가로, 레지스터는 다수의 입력 소스들로부터의 신호 경로들을 통한 충돌을 피하는 데 도움 이 될 수 있다. 예를 들어, 만일 2개(또는 그 이상)의 입력 스파이크들이 개별의(separate) 입력 소스들로 부터 동시에 시간 t0에서 수신된다면, 각 스파이크는 각 입력 소스와 연관된 레지스터 의 개별 섹션 들에 홀드 되어(held) 개별 시간들에(at separate times)(예를 들어, 제1 입력 스파이크는 시간 t1에, 제2 입력 스파이크는 시간 t2에) 목적지 뉴런으로 재전송 될 수 있다. 다른 예에서, 만일 2개(또는 그 이상)의 입력 스파이크들이 개별의(separate) 입력 소스들로부터 동시에 시간t0에서 수신된다면, 하나의 스파이크는 수 신 시간t0에 목적지 뉴런으로 재-전송되거나 전송되도록 허용될 수 있지만, 다른 입력 스파이크(들)는 나중에 재전송을 하기 위해 레지스터에 홀드 된다. 일부 실시예에서, 레지스터는 신호 경로에 증폭된 스파이크를 제공하기 위해 하나의 입력 소스로부터 일정 기간 동안 수신된 다수의 신호들을 결합할 수 있 다. 예를 들어, 만일 개별 스파이크들이 입력 소스들로부터 X의 진폭으로 전송되고 하나의 입력 소스(12 0)가 상기 기간 내에 두 개의 스파이크들을 전송한다면, 레지스터는 입력 소스와 연관된 다음 시간 분할에서 2X의 값을 갖는 스파이크를 홀드 하고 재-전송할 수 있다. 이득 구성 컨트롤러는 개별 가변 이득 증폭기들(250a-m)이 시간 분할 스키마에 기초하여 주어진 시 간에 연관된 신호 경로에 적용하는 이득을 컨트롤한다. 일부 실시 예들에서, 예를 들어, 제1 증폭기(250a)는 시간 tx에서 X의 이득을, 시간 tx+1에서 Y의 이득 을, 시간 tx+2에서 Z의 이득을 적용하고, 3개 시간 분할들(예를 들어, 시간 t2x에서 X, 시간 t2x+1에서 Y, 시간 t2x+2에서 Z) 패턴을 모두 반복할 수 있다. 제2 내지 제m의 증폭기들(250-m)도 대응하는 뉴런들이 SNN에서 훈련된 방법에 기초하여 제1 증폭기(250a)와 독립적으로 다양한 이득들을 적용한다. 클록 신호는 이득 구 성 컨트롤러를 구동하여 시간 분할 스키마 내의 서로 다른 시간 분할들에서 증폭기들(250a-m)에 적용된 이 득들을 변경한다. 라우터가 클록 신호를 수신하는 다양한 실시 예들에서, 라우터 및 이득 구성 컨트롤러는 동일한 클록 신호에 의해 구동되므로, 따라서 이득들 및 입력 스파이크들이 서로 동기화 되어 수신되고 증폭되는 것을 보장한다. 일부 실시 예들에서, 클록 신호, 및 확장하여 이득 구성 컨트롤러(및 선택적으로 라우터 )는 라우터와 뉴런들 사이의 신호 경로의 시가 분할 멀티플렉싱을 컨트롤한다. 시간 분할 멀티 플렉싱은 SNN의 특성을 이용하는데, SNN의 특성은 스파이크들이 입력 소스로부터 드물게(infrequently) 수 신된다는 것이고; 입력 소스는 일정한 신호를 보내지 않고, 오히려 일단 활동 전위가 충족되면 스파이크를 생성하고 그렇지 않으면 다음 활동 전위가 충족될 때까지 정지 상태(quiescent)가 된다는 것이다. 따라서, 이득 구성 컨트롤러는 클록 신호에 따라 하나의 신호 경로에 적용된 개별 이득을 관리함으로써 뉴런들이 여러 입력 소스들과 공유되는 시냅스를 정의하는 한 세트의 하드웨어를 재사용할 수 있고 대응하는 학습된 가중치를 상기 입력 소스를 위해 적용을 할 수 있음을 보장한다. 일부 실시 예들에서, 라우터는 스파이크가 수신되는 입력 소스의 신원에 기초하여 클록 신호 를 생성하며, 이는 이득 구성 컨트롤러(및 확장하여 증폭기)를 임의로 분할된 시간 분할 멀티플 렉싱 방식으로 컨트롤 한다. 예를 들어, 매 X 밀리초(ms)마다 새로운 시간 분할에 들어가는 대신에, 라우터 는 입력 스파이크가 제1 입력 소스(120a)로부터 수신될 때 증폭기에 대한 이득을 제1 입력 소스 (120a)에 연관된 이득에 세트 하도록 이득 구성 컨트롤러에 신호를 보낼 수 있다. 유사하게, 입력 스파이 크가 제2 입력 소스(120b)로부터 수신된다고 결정하는 것에 응답하여, 이득 구성 컨트롤러는 연관된 증폭 기의 이득을 제2 입력 소스(120b)에 연관된 이득에 세트 한다. 따라서, 상기 신호 경로들은 수신된 입력 스파이크들에 기초하여 멀티플렉스 되고, 서로 다른 입력 소스들을 위한 서로 다른 시간들에서 시냅스 하 드웨어(예를 들어, 증폭기들, 시냅스들, 및 트레이스들)를 재사용하도록 구성된다. 도 3a 내지 도 3e는 본 발명의 실시 예들에 따른, 다양한 시간들에서의 다양한 스파이크 전송들(300a- e)을 예시한다. 이득 구성 컨트롤러는, 뉴런들과 함께 SNN의 학습 단계의 일부로서, 훈련되어, 연관 된 입력 소스를 위해 대응하는 뉴런에 대해 시냅스가 수행하는 훈련된 가중치를 반영하기 위해, 증폭기의 이득을 고유하게 세트 한다. 예를 들어, 도 3a의 제1 증폭기(250a)의 제1 스파이크 전송(300a)을 살펴본다. 도 3a에서, 제1 스파이크 는 제1 입력 소스(120a)로부터 시간 t1에 수신되고, 제1 증폭기(250a)는 제1 이득을 제1 스파이크에 적용하여 3의 진폭에서 제1 스파이크를 출력한다. 유사하게, 증폭기는, 스파이크가 수신되는 입력 소스 에 대한 연관된 이득을 반영하기 위해, 시간 t2에서 제2 입력 소스(120b)로부터의 제2 스파이크를, 시간 t3에서 제3 입력 소스(120c)로부터의 제3 스파이크를, 시간 t4에서 제4 입력 소스(120d) 로부터의 제 4 스파이크를 증폭한다. 도시된 바와 같이, 증폭기는 제2 스파이크를 2의 진폭을 갖도록, 제3 스파이크를 4의 진폭을 갖도록, 제4 스파이크를 3의 진폭을 갖도록 증폭한다. 증폭기는 주어진 입력 소스와 연관되는 시간(예를 들어, 클록 신호 구동 이득 구성 컨트롤러에 의해 컨트롤되는)에 기 초하거나, 또는 입력 소스의 신원(예를 들어, 라우터에서 결정되는)에 기초하여 연관된 이득들을 위 해 세트 될 수 있다. 예시된 바와 같이, 제1 증폭기(250a)는 여러 다른 가중치들을 적용할 수 있지만, 학습된 가중치가 동일한 때(예를 들어, 제1 스파이크 및 제4 스파이크), 서로 다른 입력 소스들에 대해 / 서로 다른 시간들에서 동일한 가중치를 적용할 수 있다. 도 3b는 도 3a에 예시된 제1 스파이크 전송들(300a)과 동일한 시간들 t1-t4에서 증폭될 수 있는, 제2 증 폭기(250b)에 대한 제2 스파이크 전송들(300b)을 예시한다. 제2 증폭기(250b)는 제1 증폭기(250a)와 다른 시냅 스 및 뉴런 (즉, 제1 시냅스(210a) 및 제1 뉴런(110a)가 아닌 제2 시냅스(210b) 및 제2 뉴런(110 b))과 연관되어 있기 때문에, 제2 증폭기(250b)는 독립적으로 컨트롤되어, 제2 뉴런(110b)을 위해 학습된 이득 들을 입력 스파이크들에 적용한다. 따라서, 동일한 입력 소스들로부터 스파이크들를 수신함에도 불구하고, 그들에 적용된 이득들은, 도 3a 및 3b의 제1 스파이크(330a), 제2 스파이크(330b), 및 제3 스파이크(330c)의 서 로 다른 진폭들에 의해 표시된 바와 같이, 다를 수 있다. 그러나, SNN의 훈련은, 예를 들어, 각각의 제4 스파이 크에 대해 둘 다 3의 진폭을 가져온, 도 3a 및 3b의 제4 입력 소스(120d)로부터 스파이크들에 적용된 이득 들과 같이, 서로 다른 증폭기들에서 동일한 입력 소스에 대해 동일한 이득을 부여할 수 있다. 도 3c는 도 3a에 도시된 제1 스파이크 전송(300a)과 동일한 시간들 t1-t4에서 증폭될 수 있는, 제3 증폭 기(250c)에 대한 제3 스파이크 전송(300c)을 도시한다. 다양한 실시 예들에서, 증폭기(250c)는 하나 또는 그 이 상의 입력 소스들을 위해 연관된 시냅스에 대한 수신 임계값 아래의 이득으로 튜닝될 수 있다. 예를 들어, 제3 증폭기(250c)는 시간 t1에서의 제1 시간 분할에 대해서 또는 제1 입력 소스(120a)에 대해서 이 득을 적용하지 않거나 또는 진폭 1의 수신 임계값 아래의 이득을 적용하도록 훈련된다. 따라서, 제3 뉴런 (110c)은 제1 스파이크의 진폭이 수신 임계값보다 작기 때문에 효과적으로 제1 스파이크를 수신 하지 않는다. 도 3d는 도 3a에 예시된 제1 스파이크 전송들(300a)과 동일한 시간들 t1-t4에서 증폭될 수 있는, 제4 증 폭기(250d)에 대한 제4 스파이크 전송들(300d)을 도시한다. 다양한 실시 예들에서, 라우터는 서로 다른 입 력 소스들(및 그에 관한 다른 수들)을 서로 다른 시냅스들에 동시에 링크할 수 있다. 예를 들어, 제4 시냅스(210d)(제4 증폭기(250d) 및 제4 뉴런(110d)에 대응하는)는, 도 3a에 예시된 제1 시냅스(210a)와 같이, 제1 입력 소스(120a), 제2 입력 소스(120b) 및 제3 입력 소스(120c)에 링크된다. 그러나, 도 3a의 제1 시냅스 (210a)는 또한 제4 입력 소스(120d)에도 링크되지만, 반면, 제4 시냅스(210d)는 링크되지 않는다. 유사하게, 제 4 시냅스(210d)는 제5 입력 소스(120e)에 링크되지만, 반면 제1 시냅스(210a)는 링크되지 않는다. 따라서, 시간 t4에서, 제1 시냅스(210a) 및 제4 시냅스(210d)는 예시된 예들에서 서로 다른 입력 소스들로부터 입력들을 수신한다. 도 3e는 제5 증폭기(250e)에 대한 제5 스파이크 전송들(300e)을 도시하며, 이는 도 3a에 예시된 제1 스 파이크 전송들(300a)과 동일한 시간들 t1-t4에 걸쳐 증폭될 수 있지만, 다른 속도로 증폭될 수 있다. 예를 들어, 제5 증폭기(250e)는 도 3a의 제1 증폭기(250a)와 유사하게 제1 내지 제4 입력 소스들(120a-d)로부터 입력 스파이크들을 수신하고 증폭할 수 있지만, 또한 제 1 내지 제 4 입력 스파이크들과 다른 속도 또는 주파수(310- 340)에서 수신된 제6 입력 소스(120f)로부터의 입력 스파이크들도 수신하고 증폭할 수 있다. 도시된 바와 같이, 제5 증폭기(250e)는 제5 입력 스파이크 및 제6 입력 스파이크 모두가 동일한 입력 소스(즉, 제6 입력 소스(120f))로부터 수신되기 때문에 이들 모두에 대해 동일한 이득(2의 진폭을 위한)을 적용한다. 제6 입 력 소스(120f)는 예시된 다른 입력 소스들과 다른 속도로 입력 스파이크들을 생성하는데, 이 것은 라우터 및 이득 구성 컨트롤러가 연관된 시간에 연관된 이득을 적용하고 제5 뉴런(110e)를 위해 단일 입력 신호 경로 상에서의 충돌들을 피하도록 처리하게 한다. 본 발명의 실시 예들에 따라, 도 4a는 인공 뉴런(400a)(일반적으로, 인공 뉴런)에 대한 하나의 회 로를 예시하고, 도 4b는 뉴런으로서 사용될 수 있는, 인공 뉴런(400b)에 대한 다른 회로를 예시한다. 이해 되는 바와 같이, 도 4a 및 4b에 예시된 인공 뉴런들이외의 다른 회로가 본 발명의 다양한 실시 예들에서 뉴런으로서 사용될 수 있고; 인공 뉴런은 뉴런으로 사용하기에 적합한 회로 컴포넌트들 및 구성 들의 비제한적인 예들로서 제공된다. 도 4a에서, 제1 트랜지스터(410a)(일반적으로, 트랜지스터) 및 제2 트랜지스터(410b)(둘 모두 p-채 널로 예시됨)는 전류 미러를 정의하고, 활성화 전위가 만족될 때 인공 뉴런(400a)에 대한 출력을 생성하는 제4 트랜지스터(410d) 및 제5 트랜지스터(410e)로부터 형성된 인버터에 연결된 제3 트랜지스터(410c)로부터 피드백 을 수신한다. 제6 트랜지스터(410f)(각 게이트에서 인에이블 전압(EN)이 공급됨)는 시간에 따라 대응하는 시냅 스로부터의 다양한 입력 스파이크들을 더하기 위해 합산 트랜지스터로서 제공된다. 또한, 제7 트랜지스터 (410g)(각 게이트에서 누설 전압 VL이 공급됨) 및 커패시터는 합산된 입력의 레벨이 시간이 지남에 따라 감쇄하도록 시간이 지남에 따라 입력 스파이크들로부터 합산된 전압을 \"누설\"하도록 제공된다. 바람직하게도, 누출은 뉴런이 입력이 수신되었다는 것을 \"잊게(forget)\" 하여 출력 스파이크를 내보낼지를 결정할 때 입 력들이 수신되는 강도 및/또는 주파수 모두가 고려될 수 있게 한다. 바람직하게도, 피드백은 일단 출력 스파이크가 생성되면 뉴런이 \"리세트\"되게 하여, 후속 출력 스파이크를 생성하기 위해 충분한 강도 및/또는 주파 수의 새로운 세트의 입력 스파이크들을 요구하게 한다. 도 4b에서, 인공 뉴런(400b)은 전류 미러 회로, 합산 회로 및 인버터 회로를 포함한다. 전류 미러 회로 는 서로의 게이트들에 연결된 제1 트랜지스터(410a) 및 제2 트랜지스터(410b)(둘 모두 p-채널로 예시됨)를 포함 한다. 제1 및 제2 트랜지스터(410a, 410b)의 드레인은 대응하는 시냅스로부터의 입력에 연결된다. 제3 트 랜지스터(410c)(n-채널로 예시됨)는 시간이 지남에 따라 수신된 대응하는 시냅스로부터의 입력 스파이크들 을 더하기 위해 풀-업 트랜지스터로 제공된다. 제4 트랜지스터(410d) (p-채널로 예시됨) 및 제5 트랜지스터 (410e)(n-채널로 예시됨)는, 활성화 전위가 만족될 때 인공 뉴런(400a)에 대한 출력을 생성하는, 인버터를 형성 한다. 바람직하게도, 누설 및 피드백 회로를 포함하는 뉴런에 비해, 인공 뉴런(400b)은 더 적은 회로 컴포 넌트를 필요로 하고(따라서 더 적은 제조 공간 및 작동 전력을 필요로 하고) 시간 독립적이며; 따라서 일정 기 간 동안 입력들을 \"잊을\" 수 있는 \"누설\" 뉴런과 비교하여 출력 스파이크를 생성하기 위해 더 긴 기간 동 안 입력 수신기를 사용할 수 있다. 본 발명의 실시예에 따라, 도 5a는 인공 시냅스(500a)(일반적으로, 인공 시냅스)에 대한 하나의 회 로를 예시하고, 도 5b는 시냅스로서 사용될 수 있는 인공 시냅스(500b)의 다른 회로를 예시한다. 이해되는 바와 같이, 도 5a 및 5b에 예시된 인공 시냅스 이외의 다른 회로가 본 발명의 다양한 실시 예들에서 시냅 스로서 사용될 수 있고; 인공 시냅스는 회로 컴포넌트 및 시냅스로 사용하기에 적합한 구성의 비제한적인 예로서 제공된다. 도 5a에서, 제1 트랜지스터(410a)는 라우터 또는 대응하는 증폭기로부터의 입력 Vin에 대응하 는 게이트에서 연결되고, 제1 트랜지스터(410a)의 소스는 접지에 연결된다. 제2 트랜지스터(410b)의 소스는 제1 트랜지스터(410a)의 드레인에 연결되고, 가중치 입력(Vw)은 제2 트랜지스터(410b)의 게이트에 연결되며, 인공 시냅스(500a)를 통해 스파이크를 전송하도록 라우트된/스케줄된 입력 소스에 따라 변화할 수 있다. 제3 트 랜지스터(410c) 및 제4 트랜지스터(410d)의 각 소스들은 제2 트랜지스터 (410b)의 드레인에 연결된다. 제3 트랜 지스터(410c)의 게이트는 인공 시냅스(500a)를 위한 임계 레벨에 대한 임계 전압 Vthr 입력에 연결되고, 제3 트 랜지스터(410c)의 소스는 콜렉터 전압 Vcc를 전달하는 레일(a rail)에 연결된다. 제4 트랜지스터(410d)의 게이 트는 커패시터를 통해 콜렉터 전압(Vcc)을 전달하는 레일에 연결된다. 제5 트랜지스터(410e)는 대응하는 소스 및 드레인에 의해 콜렉터 전압(Vcc)을 전달하는 레일 및 제4 트랜지스터 (410d)의 드레인에 각각 연결되고, 게이트에서 전압 Vtau에 연결된다. 인공 시냅스(500a)로부터의 출력은 제4 및 제5 트랜지스터(410d, e)의 드레인과 노드를 공유하고, 인공 시냅스(500a)의 활동 전위가 입력 Vin에 의해 충족되는 것에 응답하여 대 응 뉴런에 입력을 전달한다. 도 5b에서, 제1 트랜지스터(410a)는 라우터 또는 대응하는 증폭기로부터의 입력 Vin에 대응하 는 게이트에서 연결되고, 제1 트랜지스터(410a)의 소스는 접지에 연결된다. 또한, 제1 트랜지스터(410a)의 본체 (body)는 가중치 입력(Vw)에 연결되는데, 이는 인공 시냅스(500b)의 활동 전위가 입력 Vin에 의해서 충족되는 것에 응답하여 인공 시냅스(500b)를 통해 스파이크를 전송하도록 라우트 된/스케줄 된 입력 소스에 따라 변화할 수 있다. 제2 트랜지스터(410b) 및 제3 트랜지스터(410c)의 드레인들은 대응 뉴런에 대한 입력으로 연결된 레일에 연결된다. 제2 및 제3 트랜지스터들(410b, c)의 게이트들은 상보적 부호 입력들(complementary sign inputs)(예를 들어, 각각 sign 및 )에 연결된다. 제2 및 제3 트랜지스터들(410b, c)의 소스들은 모두 제1 트랜지스터의 드레인에 연결된다. 도 6은 본 발명의 실시 예들에 따라, 시냅스들을 재사용할 때 사용하기 위한 가변 이득들을 할당하 기 위한 방법의 플로차트이다. 방법은 블록에서 시작하며, 여기서 오퍼레이터는 하나 또는 그 이상의 입력 소스들로부터 입력 스파이크들을 전달하는 데 재사용되는 하나의 대응하는 시냅스로부터 입력을 각각 수신하는 여러 뉴런들을 포함하는 SNN을 훈련한다. SNN은 다양한 머신 러닝 모델에 따라 각 뉴런이 어떤 가중치들을 각 입력 소스에 할당해야 하는 지를 결정하기 위해 여러 번 반복들을 통해 훈련될 수 있다. 블록에서, 오퍼레이터는 훈련 동안 뉴런에 의해 다양한 입력 소스들에 할당된 가중치들 을 재사용 가능한 시냅스들을 포함하는 신호 경로들 상의 증폭기들에서 사용하기 위한 이득들로 변환 한다. 블록에서, 오퍼레이터는 다양한 입력 소스들로부터 재사용 가능한 시냅스들을 통해 전달 될 입력 스파이크들에 대해 시간 분할 스키마를 할당한다. 일부 실시 예들에서, 시간 분할 스키마는, 입력 소스들(예를 들어, 라우터의 레지스터에 서)로부터 수신된 신호들이 뉴런들로 재-전송되고 증폭기들이 블록 별로 할당된 대응하는 이득 들에 세트 되는 동안, 실제 시간들을 할당한다. 그러한 실시 예들에서, 이득 구성 컨트롤러 및 라우터 는 공유 클록 신호에 의해 컨트롤되어, 레지스터에 저장된 주어진 입력 소스로부터 스파이 크들을 언제 전송할 것인지 그리고 다양한 증폭기들을 어떤 이득에 세트 할 것인지를 시간 및/또는 대응하 는 입력 소스의 신원에 기초하여 결정한다. 일부 실시 예들에서, 시간 분할 스키마는 스파이크 및 스파이크가 수신되는 입력 소스의 신원을 수 신하는 것에 응답하여 작동한다(operate). 그러한 실시 예들에서, 라우터는 입력 스파이크가 수신되는 입 력 소스의 신원을 이득 구성 컨트롤러에 표시하고, 이득 구성 컨트롤러는 그 신원에 따라 증폭 기들의 이득들을 세트 한다. 따라서 증폭기들의 이득들은 후속 입력 스파이크가 수신될 때까지 세트 된 상태로 유지될 수 있으며, 이때 라우터는 증폭기에 의해 적용된 이득을 업데이트하는, 이득 구성 컨트롤러에 대한 새로운 입력 소스를 식별한다. 라우터에 의해 이득 구성 컨트롤러에 표시 된 입력 소스의 신원은 또한 이득 구성 컨트롤러가 증폭기가 세트 되는 이득들을 변경할 때 클 록 신호가 신호를 보내는데 사용될 수도 있다. 블록에서, 오퍼레이터는 트레이닝에 기초하여 시간 분할 스키마애서 이득들을 할당한다. 다양한 실 시 예들에서, 특정 입력 소스로부터 입력 스파이크를 수신하는 것에 응답하여 특정 증폭기들에 적용 될 이득들은 이득 구성 컨트롤러의 룩업 테이블 또는 다른 논리 구조에 저장된다. 그 다음 방법은 종 료될 수 있다. . 도 7은 본 발명의 실시 예들에 따라, 시냅스를 재사용할 때 사용하기 위해 가변 이득들을 적용하기 위한 방법의 플로차트이다. 방법은, 라우터가 특정 입력 소스로부터 입력 스파이크를 수신하는, 블록에서 시작한다. 라우터는 각 입력 소스 및 각 뉴런에 연결되지만, 입력 소스들을 뉴런들에 선택적으로 링크할 수 있다. (즉, 모든 뉴런이 모든 입력 소스에 반드시 연결되는 것 은 아니다). 일부 실시 예들에서, 라우터는 클록 신호에 기초하여 입력 소스가 뉴런에 연 결되는 것을 순환한다. 선택적으로, 블록에서, 만일 라우터는 레지스터 또는 다른 캐싱 디바이스를 포함할 수 있다면, 이는 입력 스파이크가 시간 분할 스키마에 따라 미리 정의된 시간에 목적지 뉴런으로 전달되는 것 을 보장하거나 또는 입력 스파이크가 각 개별 뉴런에 의해서 사용되는 공유 입력 경로들 위에서 다른 입력 스파이크와 충돌하지 않는 것을 보장하기 위해서이다. 만일 포함하지 않는다면, 라우터는 레지스터에 입력 스파이크를 저장하지 않고 신호 경로들을 통해 입력 스파이크를 뉴런에 전달할 수 있으며, 방법(70 0)은 블록을 수행하지 않고 블록으로 진행한다. 블록에서, 이득 구성 컨트롤러는 입력 스파이크를 뉴런들에 전송하는 입력 소스에 기초하여 증폭기들에서 이득들을 조정한다. 다양한 실시 예들에서, 이득 구성 컨트롤러는 각 뉴런 이 하나의 입력 소스로부터의 입력 스파이크들에 할당하는 학습된 가중치에 기초하여 제2 증폭기 (250b)(제2 뉴런(110b)에 대응)의 이득으로부터 독립적으로 제1 증폭기(250a)(제1 뉴런(110a)에 대응)의 이득을 세트 한다. 일부 실시 예들에서, 이득 구성 컨트롤러가 제2 증폭기(250b)(제2 뉴런(110b)에 대응)의 이득 으로부터 독립적으로 제1 증폭기(250a)(제1 뉴런(110a)에 대응)의 이득을, 라우터가 제1 입력 소스(120a) 를 제1 뉴런(110a)에 제2 입력 소스(120b)를 제2 뉴런(110b)에 링크하는 것에 기초하여, 세트 할 때, 연관된 가 중치들이 각각 링크된 입력 소스들에 이들 뉴런들에 의해서 할당된다. 따라서, 여러 입력 소스들은 변화하는 가중치들이 입력 스파이크들에 적용되는 상황에서 주어진 뉴런에 단일 경로를 통해 연결될 수 있 으며, 그 결과 주어진 뉴런을 포함하는 신경망을 나타내는 데 필요한 하드웨어의 양을 감소시킬 수 있다. 블록에서, 입력 스파이크는 목적지 뉴런(들)에 전송된다. 입력 스파이크는 라우터로부터 각 목적지 뉴런으로 이동(travel)하는데, 상기 뉴런에 대응하는 증폭기 및 시냅스를 포함 하는 공유 신호 경로를 통해 이동한다. 증폭기는 학습된 이득을 입력 스파이크에 적용하고, 시냅스는 입력 스파이크를 차단할지 또는 계속해서 대응하는 뉴런으로 전달할지를 결정한다. 그런 다음 방법은 종료될 수 있다. 도 8은 본 발명의 실시 예들에 따른 집적 회로를 제조하기 위한 방법의 플로차트이다. 방법의 블록들은 도 8에 세트 된 순서로 제시되어 있지만, 당업자는 회로 제조는 주어진 층에 서로 다른 컴포넌트들의 여러 부분들을 형성할 수 있는 추가 공정으로 베이스 또는 기판 층으로부터 회로의 컴포넌트들을 패턴하고 증착 하는 단계가 종종 층들에서 수행된다는 것을 이해할 것이다. 제조 프로세스는 또한 공동들(voids) 또는 추가 재 료가 나중의 추가 단계에서 증착되는 영역들을 정의하기 위해 재료를 제거하기 위한 에칭 또는 제거 단계들 (ablative steps)을 포함할 수 있다. 따라서, 방법의 엘리멘트들은 적어도 부분적으로 병렬로 수행되고 어 떤 엘리멘트는 처음/마지막으로 수행되지 않는 것으로 이해될 수 있다. 블록에서, 제작자는 라우터를 패턴 한다. 라우터는 하나 또는 그 이상의 입력 소스들 을 칩 상에 정의된 하나 또는 그 이상의 뉴런들에 연결한다(예를 들어, 블록 별로). 다양한 실 시 예들에서, 제작자는 칩 상에 정의된 다른 뉴런들로서 입력 소스들을 패턴 하거나, 또는 라우터 에 입력되고 이에 의해서 칩 상의 뉴런들에 전송될 오프-칩 뉴런들 또는 데이터 소스들을 위한 트레이스들(traces)을 패턴 할 수 있다. 블록에서, 제작자는 뉴런들을 패턴 한다. 뉴런들은 하나 또는 그 이상의 트랜지스터들을 포함하고, 저항기들, 커패시터들 및 인덕터들을 포함할 수 있으며, 일정 기간이 지남에 따라 이전 입력을 소멸 시키거나 \"잊는\"기능을 갖는 메모리를 포함하는, 회로에서 SNN의 알고리즘 또는 논리 연산을 나타내기 위해서이 다. 뉴런들 각각은 출력 포트를 포함하고, 그 출력포트를 통해서 뉴런에 의해 구현된 논리 연산이 만 족될 때 출력 스파이크가 전송된다. 다양한 실시 예들에서, 뉴런들은 입력 소스들로서 동일하거나 다 른 칩 상의 다른 뉴런들에 링크된다. 블록에서, 제작자는, 증폭기들 및 시냅스들을 포함하는, 라우터와 뉴런들 사 이의 신호 경로들을 패턴 한다. 각각의 뉴런은, 대응하는 증폭기 및 하나의 시냅스를 포함하는, 하나의 신호 경로와 연관된다. 다양한 실시 예들에서, 시냅스는 증폭기의 업스트림에 위치하지만(즉, 증폭기보다 대응하는 뉴런에서 더 멀리 떨어진), 다른 실시 예들에서 시냅스는 증폭기의 다운스트림(즉, 증폭기보다 대응하는 뉴런에 더 가까운)에 위치한다. 증폭기는 이득 구성 컨트 롤러로부터의 컨트롤 신호에 기초하여 가변 이득을 제공하도록 컨트롤 가능하다. 각각의 시냅스는 적 어도 하나의 트랜지스터를 포함하고 임계값으로 구성되며, 이는 시냅스에 의해 수신된 입력 스파이크가 임 계값을 충족한다는 것에 응답하여 대응하는 뉴런으로 전달되는 출력을 내보내기(produce)위함이다. 블록에서, 제작자는 이득 구성 컨트롤러를 패턴 한다. 다양한 실시 예들에서, 이득 구성 컨트 롤러는 증폭기들, 하나 또는 그 이상의 클록 신호용 생성기 및 라우터에 연결되는 논리 컨트롤 유닛 또는 마이크로프로세서이다. 다양한 실시 예들에서, 제작자는 컨트롤 로직을 이득 구성 컨트롤러의 메모리(예를 들어, 전기적으로 지울 수 있는 프로그래머블 읽기 전용 메모리(EEPROM))에 인코딩하여 각 증폭기 를 어떤 조건들(예를 들어, SNN의 시간 분할 스키마 및 훈련에 기초한) 아래로 세트 하기 위해 이득을 컨 트롤한다. 제작자는 단일 칩 또는 다른 VLSI(Very Large Scale Integrated) 회로들에서 블록(810-840)을 수행하거 나, 또는 별도의 칩들에서 블록들(810-840) 중 하나 또는 그 이상을 수행하고 상기 별도의 칩들을 함께 연결하 여 회로를 형성할 수 있다. 예를 들어, 제작자는 이득 설정 컨트롤러를 다른 컴포넌트들로부터 별도로 제 작하고(또는 제2 제작자를 사용하여), 이득 구성 컨트롤러를 다른 컴포넌트들과 통합함으로써 블록을 수행할 수 있다. 본 발명의 다양한 실시 예들에 대한 설명은 예시의 목적으로 제공되는 것이며, 개시된 실시 예들이 전부 라거나 이들에 한정하려는 의도가 있는 것은 아니다. 많은 수정들 및 변형들이 기술된 실시 예들의 범위와 정신 을 벗어남이 없이 이 기술 분야에서 통상의 지식을 가진 자들에게 명백할 것이다. 여기서 사용된 용어들은 본 발명의 실시 예들의 원리들, 시장에서 발견된 기술들에 대한 실제 응용 또는 기술적 개선을 잘 설명하기 위해서, 또는 이 기술 분야에서 통상의 지식을 가진 자들이 여기서 기술된 실시 예들을 이해할 수 있도록 하기 위해, 선택되고 기술되었다. 다음에서, 본 발명에 제시된 실시 예들을 참조한다. 그러나, 본 발명의 범위는 설명된 특정 실시예들에 제한되지 않는다. 대신에, 다른 실시 예들과 관련되든 아니든, 다음의 특징들 및 엘리멘트들의 모든 조합은 고 려된 실시 예들을 구현하고 실행하도록 고려된다. 또한, 여기서 개시된 실시 예들이 다른 가능한 솔루션들 또는 종래 기술들에 비해 이점을 달성할 수 있지만, 특정 이점이 주어진 실시 예에 의해 달성되는지 여부는 본 발명 의 범위를 제한하지 않는다. 따라서, 다음 실시 예들, 특징들, 구현들 및 이점들은 단지 예시적이며 청구범위 (들)에서 명시적으로 인용된 경우를 제외하고는 첨부된 청구범위의 엘리멘트들 또는 제한들로 간주되지 않는다.마찬가지로, \"발명\"에 대한 참조가 여기에 공개된 독창적인 주제의 일반화로 해석되어서는 안 되며 청구범위에 서 명시적으로 인용된 경우를 제외하고는 첨부된 청구범위의 엘리멘트들 또는 제한들로 간주되지 않는다. 본 발명의 실시 예들은 전체 하드웨어 실시예, 전체 소프트웨어 실시예(펌웨어, 상주 소프트웨어, 마이 크로코드 등 포함) 또는 소프트웨어 및 하드웨어 특징들을 결합한 실시 예의 형태를 취할 수 있고, 여기에서 하 드웨어는 모두 일반적으로 \"회로\", \"모듈\" 또는 \"시스템\"으로 참조된다. 본 발명은 시스템, 방법, 및/또는 컴퓨터 프로그램 제품이 될 수 있다. 컴퓨터 프로그램 제품은 컴퓨터 판독 가능 스토리지 매체(또는 미디어)를 포함할 수 있으며, 이 매체 상에 프로세서가 본 발명의 실시 예들을 수행하도록 하는 컴퓨터 판독 가능 프로그램 명령들을 갖는다. 상기 컴퓨터 판독 가능 스토리지 매체는 명령 실행 장치에 의해 사용될 명령들을 유지 및 저장할 수 있 는 유형의(tangible) 디바이스일 수 있다. 상기 컴퓨터 판독 가능 스토리지 매체는, 예를 들면, 전자 스토리지 디바이스, 자기 스토리지 디바이스, 광 스토리지 디바이스, 전자기 스토리지 디바이스, 반도체 스토리지 디바이 스, 또는 전술한 것들의 모든 적절한 조합일 수 있으며, 그러나 이에 한정되지는 않는다. 컴퓨터 판독 가능 스 토리지 매체의 더 구체적인 예들의 비포괄적인 목록에는 다음이 포함될 수 있다: 휴대용 컴퓨터 디스켓, 하드 디스크, 랜덤 액세스 메모리(RAM), 판독-전용 메모리(ROM), 소거 및 프로그램가능 판독-전용 메모리(EPROM 또는 플래시 메모리), 정적 랜덤 액세스 메모리(SRAM), 휴대용 컴팩트 디스크 판독-전용 메모리(CD-ROM), 디지털 다 용도 디스크(DVD), 메모리 스틱, 플로피 디스크, 천공-카드들 또는 명령들이 기록된 홈에 있는 융기된 구조들 같이 기계적으로 인코드 된 장치, 및 전술한 것들의 모든 적절한 조합. 본 명세서에서 사용될 때, 컴퓨터 판독 가능 스토리지 매체는 무선 전파들이나 다른 자유롭게 전파되는 전자기파들, 도파관이나 기타 전송 매체(예를 들어, 광섬유 케이블을 통해 전달되는 광 펄스들)를 통해 전파되는 전자기파들, 또는 선(wire)을 통해 전송되는 전기 신호들 같이 그 자체로 일시적인(transitory) 신호들로 해석되지는 않는다. 여기서 기술되는 컴퓨터 판독 가능 명령들은, 예를 들어, 인터넷, 근거리 네트웍, 광역 네트웍 및/또는 무선 네트웍 등의 네트웍을 통해 컴퓨터 판독 가능 스토리지 매체로부터 각각 컴퓨팅/처리 디바이스들로 또는 외부 스토리지 디바이스로부터 외부 컴퓨터로 다운로드 될 수 있다. 상기 네트웍은 구리 전송 케이블들, 광 전 송 섬유들, 무선 전송, 라우터들, 방화벽들, 스위치들, 게이트웨이 컴퓨터들 및/또는 엣지 서버들을 포함할 수 있다. 각 컴퓨팅/처리 장치 내 네트웍 어댑터 카드 또는 네트웍 인터페이스는 상기 네트웍으로부터 컴퓨터 판독 가능 프로그램 명령들을 수신하고 그 컴퓨터 판독 가능 프로그램 명령들을 각각의 컴퓨팅/처리 디바이스 내의 컴퓨터 판독 가능 스토리지 매체에 저장하기 위해 전송한다. 본 발명의 연산들을 실행하기 위한 컴퓨터 판독 가능 프로그램 명령들은 Smalltalk, C++ 또는 그와 유사 언어 등의 객체 지향 프로그래밍 언어와 \"C\" 프로그래밍 언어 또는 그와 유사한 프로그래밍 언어 등의 종래의 절차적 프로그래밍 언어들을 포함하여, 하나 또는 그 이상의 프로그래밍 언어들을 조합하여 작성된(written) 어 셈블러 명령들, 명령-세트-아키텍처(ISA) 명령들, 머신 명령들, 머신 종속 명령들, 마이크로코드, 펌웨어 명령 들, 상태-셋팅 데이터, 집적회로를 위한 구성 데이터, 또는 소스 코드나 목적 코드일 수 있다. 상기 컴퓨터 판 독 가능 프로그램 명령들은 전적으로 사용자의 컴퓨터상에서, 부분적으로 사용자의 컴퓨터상에서, 독립형 (stand-alone) 소프트웨어 패키지로서, 부분적으로 사용자의 컴퓨터상에서 그리고 부분적으로 원격 컴퓨터상에 서 또는 전적으로 원격 컴퓨터나 서버상에서 실행될 수 있다. 위에서 마지막의 경우에, 원격 컴퓨터는 근거리 네트웍(LAN) 또는 광역 네트웍(WAN)을 포함한 모든 종류의 네트웍을 통해서 사용자의 컴퓨터에 접속될 수 있고, 또는 이 접속은 (예를 들어, 인터넷 서비스 제공자를 이용한 인터넷을 통해서) 외부 컴퓨터에 이루어질 수도 있 다. 일부 실시 예들에서, 예를 들어 프로그램 가능 로직 회로, 필드-프로그램 가능 게이트 어레이들(FPGA), 또 는 프로그램 가능 로직 어레이들(PLA)을 포함한 전자 회로는 본 발명의 실시 예들을 수행하기 위해 전자 회로를 맞춤화하도록 상기 컴퓨터 판독 가능 프로그램 명령들의 상태 정보를 활용하여 상기 컴퓨터 판독 가능 프로그램 명령들을 실행할 수 있다. 본 발명의 특징들이 본 발명의 실시 예들에 따른 방법들, 장치들(시스템들), 및 컴퓨터 프로그램 제품들 의 플로 차트 예시도들 및/또는 블록도들을 참조하여 기술된다. 플로 차트 예시도들 및/또는 블록도들의 각 블 록과 플로 차트 예시도들 및/또는 블록도들 내 블록들의 조합들은 컴퓨터 판독 가능 프로그램 명령들에 의해 구 현될 수 있다는 것을 이해할 수 있을 것이다. 이들 컴퓨터 판독 가능 프로그램 명령들은 범용 컴퓨터, 특수목적용 컴퓨터, 또는 기타 프로그램가능 데 이터 처리 장치의 프로세서에 제공되어 머신(machine)을 생성하고, 그렇게 하여 그 명령들이 상기 컴퓨터 또는 기타 프로그램가능 데이터 처리 장치의 프로세서를 통해서 실행되어, 상기 플로 차트 및/또는 블록도의 블록 또는 블록들에 명시된 기능들/동작들을 구현하기 위한 수단을 생성할 수 있다. 이들 컴퓨터 판독 가능 프로그램 명령들은 또한 컴퓨터 판독 가능 스토리지 매체에 저장될 수 있으며, 컴퓨터, 프로그램가능 데이터 처리 장치 및/또는 기타 디바이스들에 지시하여 명령들이 저장된 상기 컴퓨터 판독 가능 스토리지 매체가 상기 플로 차트 및/또는 블록도의 블록 또는 블록들에 명시된 기능/동작의 특징들을 구현하는 명령들을 포함하는 제조품(an article of manufacture)을 포함하도록 특정한 방식으로 기능하게 할 수 있다. 상기 컴퓨터 판독 가능 프로그램 명령들은 또한 컴퓨터, 기타 프로그램가능 데이터 처리 장치, 또는 다 른 디바이스에 로드 되어, 상기 컴퓨터, 기타 프로그램가능 장치 또는 다른 디바이스에서 일련의 동작 단계들이 수행되게 하여 컴퓨터 구현 프로세스를 생성하며, 그렇게 하여 상기 컴퓨터, 기타 프로그램가능 장치, 또는 다 른 디바이스 상에서 실행되는 명령들이 플로 차트 및/또는 블록도의 블록 또는 블록들에 명시된 기능들/동작들 을 구현할 수 있다. 도면들 내 플로 차트 및 블록도들은 본 발명의 여러 실시 예들에 따른 시스템들, 방법들 및 컴퓨터 프로 그램 제품들의 가능한 구현들의 아키텍처, 기능(functionality), 및 연산(operation)을 예시한다. 이와 관련하 여, 상기 플로 차트 또는 블록도들 내 각 블록은 상기 명시된 논리적 기능(들)을 구현하기 위한 하나 또는 그 이상의 실행 가능한 명령들을 포함한 모듈, 세그먼트 또는 명령들의 일부분을 나타낼 수 있다. 일부 다른 실시 예들에서, 상기 블록에 언급되는 기능들은 도면들에 언급된 순서와 다르게 일어날 수도 있다. 예를 들면, 연속 으로 도시된 두 개의 블록들은 실제로는 사실상 동시에 실행될 수도 있고, 또는 이 두 블록들은 때때로 관련된 기능에 따라서는 역순으로 실행될 수도 있다. 블록도들 및/또는 플로 차트 예시도의 각 블록, 및 블록도들 및/ 또는 플로 차트 예시도 내 블록들의 조합들은 특수목적용 하드웨어 및 컴퓨터 명령들의 명시된 기능들 또는 동 작들, 또는 이들의 조합들을 수행하는 특수목적용 하드웨어-기반 시스템들에 의해 구현될 수 있다는 것에 또한 주목해야 한다. 전술한 내용은 본 발명의 실시예에 관한 것이지만, 본 발명의 기본 범위를 벗어나지 않고 본 발명의 다 른 및 추가 실시예가 고안될 수 있고, 그 범위는 다음의 청구범위에 의해 결정된다."}
{"patent_id": "10-2022-7007590", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예들에 따라, 여러 입력 소스들로부터 입력들을 수신하는 예시적인 뉴런을 도시 한다. 도 2는 본 발명의 실시 예들에 따라, 뉴런들의 각각에 대한 하나의 대응하는 시냅스를 통해 여러 입력 소스들로부터 입력들을 수신하도록 여러 뉴런들을 관리하기 위한 예시적인 집적 회로 레이아웃을 도시한다. 도 3a 내지 도 3e는 본 발명의 실시 예들에 따라, 다양한 시간들에서의 다양한 스파이크 전송들을 예시 한다. 도 4a 및 도 4b는 본 발명의 실시 예들에 따라, 인공 뉴런들을 위한 회로들을 도시한다. 도 5a 및 5b는 본 발명의 실시 예들에 따라, 인공 시냅스들을 위한 회로들을 예시한다. 도 6은 본 발명의 실시 예들에 따라, 시냅스들을 재사용할 때 사용하기 위한 가변 이득들을 할당하기 위 한 방법의 플로차트이다. 도 7은 본 발명의 실시 예들에 따라, 시냅스들을 재사용할 때 사용하기 위한 가변 이득들을 적용하기 위 한 방법의 플로차트이다. 도 8은 본 발명의 실시 예들에 따라, 집적 회로를 제조하기 위한 방법의 플로차트이다."}
