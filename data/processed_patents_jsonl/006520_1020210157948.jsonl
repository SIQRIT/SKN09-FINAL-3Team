{"patent_id": "10-2021-0157948", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0071913", "출원번호": "10-2021-0157948", "발명의 명칭": "인공지능 판별 모델과 3차원 모델링 기반의 위장 질환 진단 장치 및 방법", "출원인": "연세대학교 원주산학협력단", "발명자": "김희만"}}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "위장을 촬영한 영상을 획득하는 영상 처리부; 상기 영상을 기초로 상기 위장의 3차원 모델을 생성하는 모델링부; 위장의 질환 정보를 판별하는 머신러닝 기반의 판별 모델에 상기 영상을 입력하여 상기 영상에 포함된 질환 정보를 판별하는 영상 분석부; 및상기 3차원 모델에 상기 판별된 질환 정보를 표시하는 진단부를 포함하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 영상은, 기 설정된 지점의 위장을 특정한 복수 개의 프레임을 포함하고, 상기 모델링부는, 소정의 3차원 모델링 알고리즘을 기초로 상기 복수의 프레임으로부터 상기 위장의 모양 또는 구조를 반영하는상기 3차원 모델을 생성하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 소정의 3차원 모델링 알고리즘은, SfSM(Shape from Shading and Motion) 또는 SfM(Structure from Motion) 알고리즘을 포함하는,위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 모델링부는, SfSM(Shape from Shading and Motion) 및 SfM(Structure from Motion) 알고리즘을 기초로 각각의 모델을 추출하고, 상기 각각의 모델을 조합하여 상기 3차원 모델을 생성하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,공개특허 10-2023-0071913-3-상기 모델링부는, 상기 각각의 모델을 조합하여 생성된 3차원 모델에 SfSM(Shape from Shading and Motion) 및 SfM(Structurefrom Motion) 알고리즘을 재적용하여 상기 3차원 모델의 표면 이미지를 개선하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 영상 분석부는, 위장을 촬영한 영상의 프레임에 질환의 위치 및 질환의 정보에 대한 클래스가 레이블링된 학습 데이터를 이용하여 소정의 이미지 판별 알고리즘을 기초로 학습시킨 상기 판별 모델을 생성하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 소정의 이미지 판별 알고리즘은, Inception ResNet V2 또는 DenseNet을 포함하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 영상 분석부는, 상기 학습 데이터를 소정 비율에 따라 훈련 세트(training set)과 테스트 세트(test set)로 분배하고 K-foldCross Validation 알고리즘을 기초로 상기 판별 모델의 정확도를 개선하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 질환의 위치는, 질환의 위치 및 면적을 특정하는 바운딩 박스를 기초로 레이블링되는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 질환의 정보는, 적어도 장상피화생 또는 위축성 위염을 포함하는 질환의 종류를 특정하는 제1 클래스; 및공개특허 10-2023-0071913-4-적어도 질환의 진행 속도 또는 위암 가능성을 포함하는 질환의 위험도를 특정하는 제2 클래스를 포함하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 진단부는, 상기 3차원 모델에 상기 판별된 질환의 위치, 면적, 종류 및 위험도를 표시하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 진단부는, 상기 위장을 촬영한 환자의 데이터베이스와 연동하여 상기 환자의 개인 검진 정보를 연동하여 표시하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 개인 검진 정보는, 개인별 검진 기간 및 검진 횟수를 포함하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 진단부는, 상기 판별된 질환의 면적이 상기 3차원 모델의 표면적에서 차지하는 비율을 계산하여 표시하는, 위장 질환 진단 장치."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "위장 질환 진단 장치가 수행하는 위장 질환 진단 방법에 있어서,위장을 촬영한 영상을 획득하는 단계;상기 영상을 기초로 상기 위장의 3차원 모델을 생성하는 단계;위장의 질환 정보를 판별하는 머신러닝 기반의 판별 모델에 상기 영상을 입력하여 상기 영상에 포함된 질환 정보를 판별하는 단계; 및상기 3차원 모델에 상기 판별된 질환 정보를 표시하는 단계를 포함하는, 공개특허 10-2023-0071913-5-위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 영상은, 기 설정된 지점의 위장을 특정한 복수 개의 프레임을 포함하고, 상기 3차원 모델을 생성하는 단계는, 소정의 3차원 모델링 알고리즘을 기초로 상기 복수의 프레임으로부터 상기 위장의 모양 또는 구조를 반영하는상기 3차원 모델을 생성하는 단계를 포함하는, 위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 소정의 3차원 모델링 알고리즘은, SfSM(Shape from Shading and Motion) 또는 SfM(Structure from Motion) 알고리즘을 포함하는,위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 3차원 모델을 생성하는 단계는, SfSM(Shape from Shading and Motion) 및 SfM(Structure from Motion) 알고리즘을 기초로 각각의 모델을 추출하고, 상기 각각의 모델을 조합하여 상기 3차원 모델을 생성하는 단계를 포함하는, 위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 3차원 모델을 생성하는 단계는, 상기 각각의 모델을 조합하여 생성된 3차원 모델에 SfSM(Shape from Shading and Motion) 및 SfM(Structurefrom Motion) 알고리즘을 재적용하여 상기 3차원 모델의 표면 이미지를 개선하는 단계를 포함하는, 위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서,상기 판별하는 단계는,위장을 촬영한 영상의 프레임에 질환의 위치 및 질환의 정보에 대한 클래스가 레이블링된 학습 데이터를 이용하여 소정의 이미지 판별 알고리즘을 기초로 학습시킨 상기 판별 모델을 생성하는 단계를 포함하는, 공개특허 10-2023-0071913-6-위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 소정의 이미지 판별 알고리즘은, Inception ResNet V2 또는 DenseNet을 포함하는, 위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서,상기 판별하는 단계는,상기 학습 데이터를 소정 비율에 따라 훈련 세트(training set)과 테스트 세트(test set)로 분배하고 K-foldCross Validation 알고리즘을 기초로 상기 판별 모델의 정확도를 개선하는 단계를 포함하는, 위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제20항에 있어서,상기 질환의 위치는, 질환의 위치 및 면적을 특정하는 바운딩 박스를 기초로 레이블링되는, 위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제20항에 있어서,상기 질환의 정보는, 적어도 장상피화생 또는 위축성 위염을 포함하는 질환의 종류를 특정하는 제1 클래스; 및적어도 질환의 진행 속도 또는 위암 가능성을 포함하는 질환의 위험도를 특정하는 제2 클래스를 포함하는, 위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제15항에 있어서,상기 표시하는 단계는,상기 3차원 모델에 상기 판별된 질환의 위치, 면적, 종류 및 위험도를 표시하는 단계를 포함하는,위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "공개특허 10-2023-0071913-7-제25항에 있어서,상기 표시하는 단계는,상기 위장을 촬영한 환자의 데이터베이스와 연동하여 상기 환자의 개인 검진 정보를 연동하여 표시하는 단계를포함하는, 위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제26항에 있어서,상기 개인 검진 정보는, 개인별 검진 기간 및 검진 횟수를 포함하는, 위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제25항에 있어서,상기 표시하는 단계는,상기 판별된 질환의 면적이 상기 3차원 모델의 표면적에서 차지하는 비율을 계산하여 표시하는 단계를포함하는,위장 질환 진단 방법."}
{"patent_id": "10-2021-0157948", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제15항 내지 제28항 중 어느 한 항에 기재된 방법에 따른 각각의 단계를 수행하는 명령어를 포함하는 프로그램이 기록된 컴퓨터 판독 가능 기록매체."}
{"patent_id": "10-2021-0157948", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 위장 질환 진단 장치는 위장을 촬영한 영상을 획득하는 영상 처리부; 상기 영상을 기초로 상기 위장의 3차원 모델을 생성하는 모델링부; 위장의 질환 정보를 판별하는 머신러닝 기반의 판별 모델에 상기 영상 을 입력하여 상기 영상에 포함된 질환 정보를 판별하는 영상 분석부; 및 상기 3차원 모델에 상기 판별된 질환 정 보를 표시하는 진단부를 포함할 수 있다."}
{"patent_id": "10-2021-0157948", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 판별 모델과 3차원 모델링 기반의 위장 질환 진단 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0157948", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "위암은 한국을 포함한 동아시아 국가에서 발병률이 매우 높은 암이지만, 수술적 절차 및 이를 보조하는 화학적 항암 치료법뿐만 아니라 조기 진단 방법에 대해서도 많은 진전을 이뤄왔다. 그럼에도, 위암은 여전히 세계적으 로 성별을 불문하고 암으로 인한 사망 원인 중 매우 높은 순위를 차지하고 있으며, 위암 발병 및 종양 진행의 근본이 되는 정확한 기전은 아직 완전히 밝혀진 바가 없다. 한편, 지금까지 연구된 바에 따르면 위축성 위염과 장상피화생은 위암으로 이어질 수 있는 위험 인자이기 때문 에, 현재는 의사가 직접 내시경 영상을 육안으로 확인하고 분석하여 이러한 위장 질환을 진단하고 있으나, 이에 대한 자동적인 분석과 정량적인 데이터 생성은 적극적으로 이뤄지지 않고 있는 실정이다. 따라서, 위축성 위염과 장상피화생에 대한 자동화된 분석과 정량적인 데이터 생성을 통해 개개인의 맞춤형 위암 위험도를 분석하고, 개개인의 위험도에 따른 맞춤형 정기 검진을 제공할 수 있는 기술이 요구된다.선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개특허공보 제10-2012-0114895호: 내시경 장치 및 상기 내시경 장치의 영상 획득 방법"}
{"patent_id": "10-2021-0157948", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예가 해결하고자 하는 과제는 인공지능 판별 모델을 기초로 내시경 영상으로부터 위축성 위염과 장상피화생 등의 위장 질환 정보를 진단하고, 내시경 영상으로부터 위장의 모양과 구조를 3차원으로 모델링한 3 차원 모델에 질환 정보를 표시한 데이터를 생성하는 기법을 통해, 위축성 위염 및 장상피화생 등과 같은 위장 질환의 진행 속도와 위험도를 직관적으로 제시하면서 정량화할 수 있는 기술을 제공하는 것이다. 다만, 본 발명의 실시예가 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 이하 에서 설명할 내용으로부터 통상의 기술자에게 자명한 범위 내에서 다양한 기술적 과제가 도출될 수 있다."}
{"patent_id": "10-2021-0157948", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 위장 질환 진단 장치는 위장을 촬영한 영상을 획득하는 영상 처리부; 상기 영상을 기초로 상 기 위장의 3차원 모델을 생성하는 모델링부; 위장의 질환 정보를 판별하는 머신러닝 기반의 판별 모델에 상기 영상을 입력하여 상기 영상에 포함된 질환 정보를 판별하는 영상 분석부; 및 상기 3차원 모델에 상기 판별된 질 환 정보를 표시하는 진단부를 포함할 수 있다. 또한, 상기 영상은 기 설정된 지점의 위장을 특정한 복수 개의 프레임을 포함하고, 상기 모델링부는 소정의 3차 원 모델링 알고리즘을 기초로 상기 복수의 프레임으로부터 상기 위장의 모양 또는 구조를 반영하는 상기 3차원 모델을 생성할 수 있다. 또한, 상기 소정의 3차원 모델링 알고리즘은 SfSM(Shape from Shading and Motion) 또는 SfM(Structure from Motion) 알고리즘을 포함할 수 있다. 또한, 상기 모델링부는 SfSM(Shape from Shading and Motion) 및 SfM(Structure from Motion) 알고리즘을 기초 로 각각의 모델을 추출하고, 상기 각각의 모델을 조합하여 상기 3차원 모델을 생성할 수 있다. 또한, 상기 모델링부는 상기 각각의 모델을 조합하여 생성된 3차원 모델에 SfSM(Shape from Shading and Motion) 및 SfM(Structure from Motion) 알고리즘을 재적용하여 상기 3차원 모델의 표면 이미지를 개선할 수 있다. 또한, 상기 영상 분석부는 위장을 촬영한 영상의 프레임에 질환의 위치 및 질환의 정보에 대한 클래스가 레이블 링된 학습 데이터를 이용하여 소정의 이미지 판별 알고리즘을 기초로 학습시킨 상기 판별 모델을 생성할 수 있 다. 또한, 상기 소정의 이미지 판별 알고리즘은 Inception ResNet V2 또는 DenseNet을 포함할 수 있다. 또한, 상기 영상 분석부는 상기 학습 데이터를 소정 비율에 따라 훈련 세트(training set)과 테스트 세트(test set)로 분배하고 K-fold Cross Validation 알고리즘을 기초로 상기 판별 모델의 정확도를 개선할 수 있다. 또한, 상기 질환의 위치는 질환의 위치 및 면적을 특정하는 바운딩 박스를 기초로 레이블링될 수 있다. 또한, 상기 질환의 정보는 적어도 장상피화생 또는 위축성 위염을 포함하는 질환의 종류를 특정하는 제1 클래스; 및 적어도 질환의 진행 속도 또는 위암 가능성을 포함하는 질환의 위험도를 특정하는 제2 클래스를 포 함할 수 있다. 또한, 상기 진단부는 상기 3차원 모델에 상기 판별된 질환의 위치, 면적, 종류 및 위험도를 표시할 수 있다. 또한, 상기 진단부는 상기 위장을 촬영한 환자의 데이터베이스와 연동하여 상기 환자의 개인 검진 정보를 연동 하여 표시할 수 있다. 또한, 상기 개인 검진 정보는 개인별 검진 기간 및 검진 횟수를 포함할 수 있다. 또한, 상기 진단부는 상기 판별된 질환의 면적이 상기 3차원 모델의 표면적에서 차지하는 비율을 계산하여 표시 할 수 있다. 일 실시예에 따른 위장 질환 진단 장치가 수행하는 위장 질환 진단 방법은 위장을 촬영한 영상을 획득하는 단계; 상기 영상을 기초로 상기 위장의 3차원 모델을 생성하는 단계; 위장의 질환 정보를 판별하는 머신러닝 기 반의 판별 모델에 상기 영상을 입력하여 상기 영상에 포함된 질환 정보를 판별하는 단계; 및 상기 3차원 모델에 상기 판별된 질환 정보를 표시하는 단계를 포함할 수 있다. 또한, 상기 영상은 기 설정된 지점의 위장을 특정한 복수 개의 프레임을 포함하고 상기 3차원 모델을 생성하는 단계는 소정의 3차원 모델링 알고리즘을 기초로 상기 복수의 프레임으로부터 상기 위장의 모양 또는 구조를 반 영하는 상기 3차원 모델을 생성하는 단계를 포함할 수 있다. 또한, 상기 소정의 3차원 모델링 알고리즘은 SfSM(Shape from Shading and Motion) 또는 SfM(Structure from Motion) 알고리즘을 포함할 수 있다. 또한, 상기 3차원 모델을 생성하는 단계는 SfSM(Shape from Shading and Motion) 및 SfM(Structure from Motion) 알고리즘을 기초로 각각의 모델을 추출하고, 상기 각각의 모델을 조합하여 상기 3차원 모델을 생성하는 단계를 포함할 수 있다. 또한, 상기 3차원 모델을 생성하는 단계는 상기 각각의 모델을 조합하여 생성된 3차원 모델에 SfSM(Shape from Shading and Motion) 및 SfM(Structure from Motion) 알고리즘을 재적용하여 상기 3차원 모델의 표면 이미지를 개선하는 단계를 포함할 수 있다. 또한, 상기 판별하는 단계는 위장을 촬영한 영상의 프레임에 질환의 위치 및 질환의 정보에 대한 클래스가 레이 블링된 학습 데이터를 이용하여 소정의 이미지 판별 알고리즘을 기초로 학습시킨 상기 판별 모델을 생성하는 단 계를 포함할 수 있다. 또한, 상기 소정의 이미지 판별 알고리즘은 Inception ResNet V2 또는 DenseNet을 포함할 수 있다. 또한, 상기 판별하는 단계는 상기 학습 데이터를 소정 비율에 따라 훈련 세트(training set)과 테스트 세트 (test set)로 분배하고 K-fold Cross Validation 알고리즘을 기초로 상기 판별 모델의 정확도를 개선하는 단계 를 포함할 수 있다. 또한, 상기 질환의 위치는 질환의 위치 및 면적을 특정하는 바운딩 박스를 기초로 레이블링될 수 있다. 또한, 상기 질환의 정보는 적어도 장상피화생 또는 위축성 위염을 포함하는 질환의 종류를 특정하는 제1 클래스; 및 적어도 질환의 진행 속도 또는 위암 가능성을 포함하는 질환의 위험도를 특정하는 제2 클래스를 포 함할 수 있다. 또한, 상기 표시하는 단계는 상기 3차원 모델에 상기 판별된 질환의 위치, 면적, 종류 및 위험도를 표시하는 단 계를 포함할 수 있다. 또한, 상기 표시하는 단계는 상기 위장을 촬영한 환자의 데이터베이스와 연동하여 상기 환자의 개인 검진 정보 를 연동하여 표시하는 단계를 포함할 수 있다. 또한, 상기 개인 검진 정보는 개인별 검진 기간 및 검진 횟수를 포함할 수 있다. 또한, 상기 표시하는 단계는 상기 판별된 질환의 면적이 상기 3차원 모델의 표면적에서 차지하는 비율을 계산하 여 표시하는 단계를 포함할 수 있다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2021-0157948", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 위암의 위험도를 판별하고 이러한 질환 정보를 직관적으로 나타냄과 동시에, 개인 별 검진 검사의 기간과 횟수를 제시함으로써, 위암의 조기 발견율을 증가시키고 불필요한 검진 검사를 줄일 수 있다. 또한, 기존 내시경 시스템의 영상을 사용하여 연동할 수 있으므로 모든 내시경 시스템에 적용이 가능하여, 위암의 예방과 조기 발견에 큰 도움이 될 수 있다. 본 발명의 실시예에 대한 효과는 이상에서 언급한 효과들로 제한되지 않으며, 이하에서 설명할 내용으로부터 통 상의 기술자에게 자명한 범위 내에서 다양한 효과들이 포함될 수 있다."}
{"patent_id": "10-2021-0157948", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적과 기술적 구성 및 그에 따른 작용 효과에 관한 자세한 사항은 본 발명의 명세서에 첨부된 도면 에 의거한 이하의 상세한 설명에 의해 보다 명확하게 이해될 것이다. 첨부된 도면을 참조하여 본 발명에 따른 실시예를 상세하게 설명한다. 본 명세서에서 개시되는 실시예들은 본 발명의 범위를 한정하는 것으로 해석되거나 이용되지 않아야 할 것이다. 이 분야의 통상의 기술자에게 본 명세서의 실시예를 포함한 설명은 다양한 응용을 갖는다는 것이 당연하다. 따 라서, 본 발명의 상세한 설명에 기재된 임의의 실시예들은 본 발명을 보다 잘 설명하기 위한 예시적인 것이며 본 발명의 범위가 실시예들로 한정되는 것을 의도하지 않는다. 도면에 표시되고 아래에 설명되는 기능 블록들은 가능한 구현의 예들일 뿐이다. 다른 구현들에서는 상세한 설명 의 사상 및 범위를 벗어나지 않는 범위에서 다른 기능 블록들이 사용될 수 있다. 또한, 본 발명의 하나 이상의 기능 블록이 개별 블록들로 표시되지만, 본 발명의 기능 블록들 중 하나 이상은 동일 기능을 실행하는 다양한 하드웨어 및 소프트웨어 구성들의 조합일 수 있다. 또한, 어떤 구성요소들을 포함한다는 표현은 개방형의 표현으로서 해당 구성요소들이 존재하는 것을 단순히 지 칭할 뿐이며, 추가적인 구성요소들을 배제하는 것으로 이해되어서는 안 된다. 나아가 어떤 구성요소가 다른 구성요소에 연결되어 있다거나 접속되어 있다고 언급될 때에는, 그 다른 구성요소 에 직접적으로 연결 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 한다. 이하에서는 도면들을 참조하여 본 발명의 실시예들에 대해 설명하도록 한다. 도 1은 일 실시예에 따른 인공지능 판별 모델과 3차원 모델링 기반의 위장 질환 진단 장치(이하, \"진단 장 치\"로 지칭)의 구성을 도시한 도면이다. 도 1의 진단 장치는 영상 처리부, 모델링부, 영상 분석부 및 진단부를 포함할 수 있 다. 진단 장치는 데이터 및 명령어를 저장하는 메모리와, 하나 이상의 프로세서에 의해 전반적인 동작이 수행될 수 있고, 하나 이상의 프로세서는 도 1에 포함된 기능 블록들이 후술할 동작들을 수행하도록 제어할 수있다. 다만, 도 1의 진단 장치의 구성 요소에 대한 설명은 일 실시예에 불과하므로, 도 1에 의해 본 발명 의 기술적 사상이 한정 해석되는 것은 아니다. 이하에서는, 도 2 내지 도 7을 참조하여 진단 장치의 각 구 성 요소의 동작에 대해 설명할 것이며, 보다 자세한 동작에 대해서는 도 8 및 도 10을 참조하여 구체적으로 설 명하도록 한다. 영상 처리부는 위장을 촬영한 영상을 외부 장치로부터 획득할 수 있다. 예를 들어, 영상 처리부는 내 시경 장치가 위장을 촬영한 영상을 획득하거나, 병원의 데이터베이스로부터 위장을 촬영한 영상을 획득할 수 있 다. 도 2는 일 실시예에 따라 위장을 촬영한 영상으로부터 기 설정된 지점의 위장을 특정한 복수 개의 프레임을 추 출하는 예시도이다. 도 2를 참조하면, 영상 처리부는 위장을 촬영한 영상으로부터 기 설정된 지점의 위장을 특정한 복수 개의 프레임을 추출할 수 있다. 일 예로, 영상 처리부는 소정의 각도에서 특정 지점의 위장이 촬영된 영상의 프 레임을 특정하고 해당 프레임에 지점 정보(ex. 도 2a 내지 도 2f)를 매핑하여 저장할 수 있다. 모델링부는 획득된 영상(ex. 프레임)을 이용하여 3차원 모델링 알고리즘을 기초로 획득된 영상의 위장 모 양 또는 구조를 반영하는 3차원 모델을 생성할 수 있다. 도 3은 일 실시예에 따라 위장을 촬영한 영상을 기초로 위장의 3차원 모델을 생성한 예시도이다. 도 3을 참조하면, 모델링부는 획득된 영상의 프레임에 매핑된 지점 정보를 조합하여 위장의 구조 또는 모 양을 생성하는 3차원 모델링 알고리즘을 기초로 위장의 3차원 모델을 생성할 수 있다. 모델링부의 구체적 동작은 이후 도 8 및 도 9와 함께 후술하기로 한다. 영상 분석부는 위장의 질환 정보를 판별하는 머신러닝 기반의 판별 모델에 영상(ex. 프레임)을 입력하여 영상에 포함된 질환 정보를 판별할 수 있다. 도 4 및 도 5는 일 실시예에 따라 위장을 촬영한 영상에 포함된 질환 정보를 판별한 예시도이다. 도 4 및 도 5를 참조하면, 영상 분석부는 머신러닝 기반의 판별 모델을 이용하여 프레임에 포함된 질환의 위치, 면적, 종류(ex. 장상피화생 또는 위축성 위염), 위험도(ex. 질환의 진행 속도 또는 위암 가능성)를 판별 할 수 있다. 영상 분석부의 구체적 동작은 이후 도 8 및 10과 함께 후술하기로 한다. 진단부는 모델링부가 생성한 3차원 모델에 영상 분석부가 판별된 질환 정보를 표시할 수 있다. 도 6 및 도 7는 일 실시예에 따라 위장을 촬영한 영상으로부터 생성한 3차원 모델에 질환 정보를 표시한 예시도 이다. 도 6 및 도 7를 참조하면, 진단부는 3차원 모델에 판별된 질환의 위치, 면적, 종류 및 위험도를 표시할 수 있고, 3차원 모델에 질환 정보가 표시된 데이터를 정량적으로 저장할 수 있다. 일 예로, 진단부는 판별된 질환의 면적이 3차원 모델의 표면적에서 차지하는 비율을 계산하여 3차원 모델에 표시할 수 있다. 일 예로, 진 단부는 위장을 촬영한 환자의 기록을 저장하는 데이터베이스로부터 검색된 개인 검진 정보를 3차원 모델에 추가로 표시하여 출력할 수 있다. 일 예로, 개인 검진 정보는 개인별 검진 기간 및 검진 횟수를 포함할 수 있다. 도 8은 일 실시예에 따른 진단 장치가 수행하는 진단 방법의 동작 단계를 도시한 흐름도이다. 도 8에 따른 방법의 각 단계는 도 1을 통해 설명된 진단 장치에 의해 수행될 수 있으며, 각 단계를 설명하면 다음과 같 다. S1010 단계에서, 영상 처리부는 내시경 영상을 획득할 수 있다. 예를 들어, 영상 처리부는 내시경 장 치가 위장을 실시간으로 촬영한 내시경 영상을 획득하거나, 병원의 데이터베이스와 연동되어 기 저장된 내시경 영상을 획득할 수 있다. S1011 단계에서, 영상 처리부는 내시경 영상으로부터 프레임 이미지를 추출할 수 있다. 영상 처리부 는 내시경 영상으로부터 기 설정된 지점의 위장을 특정한 복수 개의 프레임 이미지를 추출할 수 있다. S1020 단계에서, 모델링부는 영상의 프레임을 조합하여 위장의 구조 또는 모양을 생성하는 3차원 모델링 알고리즘을 기초로 위장의 3차원 모델을 생성할 수 있다. 모델링부는 서로 다른 3차원 모델링 알고리즘을 사용하여 생성된 각 모델을 조합하여 3차원 모델을 생성할 수 있다. 모델링부가 3차원 모델을 생성하는 구체적 동작은 도 9와 함께 후술하기로 한다. S1030 단계에서, 영상 분석부는 위장의 질환 정보를 판별하는 머신러닝 기반의 판별 모델에 추출된 프레임 이미지를 입력하여 내시경 영상에 포함된 위장의 질환 정보를 판별할 수 있다. 영상 분석부는 위장을 촬영 한 영상의 프레임에 질환의 위치 및 질환의 정보에 대한 클래스가 레이블링된 학습 데이터를 이용하여 소정의 이미지 판별 알고리즘을 기초로 판별 모델을 생성할 수 있고, 생성된 판별 모델을 저장할 수 있다. 영상 분석부 가 판별 모델을 생성하는 구체적 동작은 도 10과 함께 후술하기로 한다. S1040 단계에서, 진단부는 S1020 단계에서 생성된 3차원 모델에 S1030 단계에서 판별된 질환 정보를 표시 하여 출력 및 저장할 수 있다. S1041 단계에서, 진단부는 위장을 촬영한 환자의 기록을 저장하는 데이터베이스로부터 검색된 개인 검진 정보를 3차원 모델에 추가로 표시하여 출력할 수 있다. 상술한 도 8의 흐름도에 따른 방법은 일 실시예에 불과하므로 도 8에 의해 본 발명의 사상이 한정 해석되는 것 은 아니며, 도 8에 도시된 방법의 각 단계는 경우에 따라 도면과 그 순서를 달리하여 수행될 수 있다. 도 8의 내용 중 도 1 내지 7과 중복되는 내용에 대해서는 설명을 생략한다. 도 9는 일 실시예에 따라 위장을 촬영한 영상으로부터 3차원 모델을 생성하는 동작의 단계를 도시한 흐름도이다. 도 9에 따른 방법의 각 단계는 도 1을 통해 설명된 진단 장치에 의해 수행될 수 있으며, 각 단계를 설명하면 다음과 같다. S1021 단계에서, 영상 처리부는 내시경 영상을 획득할 수 있다. 예를 들어, 영상 처리부는 내시경 장 치가 위장을 실시간으로 촬영한 내시경 영상을 획득하거나, 병원의 데이터베이스와 연동되어 기 저장된 내시경 영상을 획득할 수 있다. S1022 단계에서, 영상 처리부는 내시경 영상으로부터 프레임 이미지를 추출할 수 있다. 영상 처리부 는 내시경 영상으로부터 기 설정된 지점의 위장을 특정한 복수 개의 프레임 이미지를 추출할 수 있다. S1023 단계에서, 모델링부는 SfSM(Shape from Shading and Motion)알고리즘을 기초로 복수의 프레임으로 부터 위장의 모양 또는 구조를 반영하는 SfSM 모델을 생성할 수 있다. SfSM은 openCV(Open Source Computer Vision)의 프로그래밍 라이브러리에 포함된 3차원 모델링 오픈소스 알고리즘이다. 예를 들어, SfSM은 명암 (shading)과 움직임(motion)을 이용한 모양 추출 방식으로써, 복수의 프레임으로부터 위장의 모양 또는 구조를 반영하는 SfSM 모델을 생성할 수 있다. S1024 단계에서, 모델링부는 SfM(Structure from Motion) 알고리즘을 기초로 복수의 프레임으로부터 위장 의 모양 또는 구조를 반영하는 SfM 모델을 생성할 수 있다. SfM(Structure from Motion)은 openCV(Open Source Computer Vision)의 프로그래밍 라이브러리에 포함된 3차원 모델링 오픈소스 알고리즘이다. 예를 들어, SfM은 움직임(motion)을 이용한 모양 추출 방식으로써, 복수의 프레임으로부터 위장의 모양 또는 구조를 반영하는 SfM 모델을 생성할 수 있다. S1025 단계에서, 모델링부는 S1023 단계에서 생성된 SfSM 모델과, S1024 단계에서 생성된 SfM 모델을 조합 한 프로토타입 모델을 생성할 수 있다. S1026 단계에서, 모델링부는 S1025 단계에서 생성된 프로토타입 모델에 SfSM 알고리즘 및 SfM 알고리즘을 재적용하여 표면 이미지가 개선된 3차원 모델을 생성할 수 있다. S1027 단계에서, 모델링부는 생성된 3차원 모델을 저장할 수 있다. 상술한 도 9의 흐름도에 따른 방법은 일 실시예에 불과하므로 도 9에 의해 본 발명의 사상이 한정 해석되는 것 은 아니며, 도 9에 도시된 방법의 각 단계는 경우에 따라 도면과 그 순서를 달리하여 수행될 수 있다. 도 9의 내용 중 도 1 내지 8과 중복되는 내용에 대해서는 설명을 생략한다. 도 10은 일 실시예에 따라 위장을 촬영한 영상으로부터 질환 정보를 판별하는 판별 모델을 생성하는 동작의 단 계를 도시한 흐름도이다. 도 10에 따른 방법의 각 단계는 도 1을 통해 설명된 진단 장치에 의해 수행될 수 있으며, 각 단계를 설명하면 다음과 같다. S1031 단계에서, 영상 처리부는 위장을 촬영한 내시경 영상 및 상기 영상에 대한 질환 정보 기록이 저장된 데이터베이스와 연동될 수 있다. 예를 들어, 데이터베이스는 저장 공간을 포함하는 하드웨어 모듈일 수 있고,클라우드 방식으로 데이터를 송수신할 수 있는 서버일 수 있다. S1032 단계에서, 영상 처리부는 데이터베이스의 내시경 영상을 획득할 수 있다. S1033 단계에서, 영상 처리부는 내시경 영상으로부터 프레임 이미지를 추출할 수 있다. 영상 처리부 는 내시경 영상으로부터 기 설정된 지점의 위장을 특정한 복수 개의 프레임 이미지를 추출할 수 있다. S1034 단계에서, 영상 분석부는 내시경 영상에 대한 질환 정보 기록 중 후술할 판별 모델의 학습 클래스로 사용할 질환 정보를 추출할 수 있다. 예를 들어, 학습의 클래스는 질환 정보(ex. 장상피화생, 위축성 위염 등) 또는 질환의 위험도(ex. 질환의 진행 속도, 위암 가능성 등)를 포함할 수 있다. S1035 단계에서, 영상 분석부는 S1033 단계에서 추출한 프레임에, S1034 단계에서 질환의 위치 및 질환의 정보에 대한 클래스를 레이블링할 수 있다. 예를 들어, 영상 분석부는, 추출된 프레임에 포함된 질환의 위 치에 바운딩 박스를 생성하여 질환의 위치 및 면적을 특정하는 클래스를 레이블링 할 수 있고, 해당 바운딩 박 스에 질환 정보를 특정하는 제1 클래스 및 질환의 위험도를 특정하는 제2 클래스를 레이블링 할 수 있다. S1036 단계에서, 영상 분석부는 위장을 촬영한 영상의 프레임에 질환의 위치 및 질환의 정보에 대한 클래 스가 레이블링된 학습 데이터를 이용하여 Inception ResNet V2 또는 DenseNet 알고리즘을 기초로 판별 모델을 학습시킬 수 있다. S1037 단계에서, 영상 분석부는 S1035 단계에서 생성된 학습 데이터를 소정 비율에 따라 훈련 세트 (training set)과 테스트 세트(test set)로 분배하고 K-fold Cross Validation 알고리즘을 함으로써, 판별 모 델의 최적화 작업을 수행하여 판별 모델의 정확도를 개선시킬 수 있다. S1038 단계에서, 영상 분석부는 생성된 판별 모델을 저장할 수 있다. 상술한 도 10의 흐름도에 따른 방법은 일 실시예에 불과하므로 도 10에 의해 본 발명의 사상이 한정 해석되는 것은 아니며, 도 10에 도시된 방법의 각 단계는 경우에 따라 도면과 그 순서를 달리하여 수행될 수 있다. 도 10 의 내용 중 도 1 내지 9와 중복되는 내용에 대해서는 설명을 생략한다. 상술한 실시예에 따르면, 위암의 위험도를 판별하고 이러한 질환 정보를 직관적으로 나타냄과 동시에, 개인별 검진 검사의 기간과 횟수를 제시함으로써, 위암의 조기 발견율을 증가시키고 불필요한 검진 검사를 줄일 수 있 다. 또한, 기존 내시경 시스템의 영상을 사용하여 연동할 수 있으므로 모든 내시경 시스템에 적용이 가능하여, 위암의 예방과 조기 발견에 큰 도움이 될 수 있다. 상술한 본 발명의 실시예들은 다양한 수단을 통해 구현될 수 있다. 예를 들어, 본 발명의 실시예들은 하드웨어, 펌웨어(firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 프로세서, 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 펌웨어나 소프트웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 이상에서 설명된 기능 또는 동작 들을 수행하는 모듈, 절차 또는 함수 등의 형태로 구현될 수 있다. 소프트웨어 코드는 메모리 유닛에 저장되어 프로세서에 의해 구동될 수 있다. 상기 메모리 유닛은 상기 프로세서 내부 또는 외부에 위치하여, 이미 공지된 다양한 수단에 의해 상기 프로세서와 데이터를 주고받을 수 있다."}
{"patent_id": "10-2021-0157948", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이와 같이, 본 발명이 속하는 기술분야의 당업자는 본 발명이 그 기술적 사상이나 필수적 특징을 변경하지 않고 서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범위는 상기 상세한 설 명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 등가개념으로 부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2021-0157948", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 인공지능 기반의 위장 질환 진단 장치의 구성을 도시한 도면이다. 도 2a 내지 도 2f는 일 실시예에 따라 위장을 촬영한 영상으로부터 기 설정된 지점의 위장을 특정한 복수 개의 프레임을 추출하는 예시도이다. 도 3은 일 실시예에 따라 위장을 촬영한 영상을 기초로 위장의 3차원 모델을 생성한 예시도이다. 도 4 및 도 5는 일 실시예에 따라 위장을 촬영한 영상에 포함된 질환 정보를 판별한 예시도이다. 도 6 및 도 7는 일 실시예에 따라 위장을 촬영한 영상으로부터 생성한 3차원 모델에 질환 정보를 표시한 예시도 이다. 도 8은 일 실시예에 따른 진단 장치가 수행하는 진단 방법의 동작 단계를 도시한 흐름도이다. 도 9는 일 실시예에 따라 위장을 촬영한 영상으로부터 3차원 모델을 생성하는 동작의 단계를 도시한 흐름도이다. 도 10은 일 실시예에 따라 위장을 촬영한 영상으로부터 질환 정보를 판별하는 판별 모델을 생성하는 동작의 단 계를 도시한 흐름도이다."}
