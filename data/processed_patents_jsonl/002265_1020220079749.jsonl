{"patent_id": "10-2022-0079749", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0002497", "출원번호": "10-2022-0079749", "발명의 명칭": "인공지능 모델 운용 방법, 장치 및 기록 매체", "출원인": "엘지이노텍 주식회사", "발명자": "오승근"}}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 모델을 학습하는 동안 시계열적으로 획득한 n개의 모델 정보 각각에 상응하는 n개의 블록 데이터를 생성하는 단계;상기 생성된 n개의 블록 데이터를 스토리지에 시계열적인 블록체인 기반 분산 원장으로 저장하는 단계;상기 n개의 블록 데이터 중 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우,상기 저장된 (n-1)개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라미터를 획득하는 단계; 및상기 특정 블록 데이터의 상기 획득된 모델 파라미터를 바탕으로 상기 인공지능 모델을 재학습하는 단계;를 포함하는,인공지능 모델 운용 방법."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 특정 블록 데이터의 상기 획득된 모델 파라미터를 바탕으로 상기 인공지능 모델을 재학습하여 획득된 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터를 상기 시계열적인 블록체인 기반 분산 원장에 상기 제n 블록데이터 다음으로 저장하는 단계;를 포함하는,인공지능 모델 운용 방법."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 제n 블록 데이터의 모델 성능을 시계열적인 역산으로 상기 스토리지에 저장된 블록 데이터들 각각의 모델 성능과 비교하는단계; 및비교 결과, 상기 제n 블록 데이터의 모델 성능보다 큰 모델 성능을 포함하는 상기 특정 블록 데이터에서 모델파라미터를 획득하는 단계;를 포함하는,인공지능 모델 운용 방법."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 제n 블록 데이터의 모델 성능을 시계열적인 역산으로 상기 스토리지에 저장된 블록 데이터들 각각의 모델 성능과 비교하는단계;비교 결과, 상기 제n 블록 데이터의 모델 성능과 상기 특정 블록 데이터의 모델 성능이 동일하지만, 상기 제n블록 데이터의 파리미터의 값과 상기 특정 블록 데이터의 모델 파라미터 값이 상이한 경우, 상기 제n 블록 데이터의 파리미터의 값과 상기 특정 블록 데이터의 모델 파라미터 값 각각을 바탕으로 상기 인공지능 모델을 재학습하여 획득된 제1 및 제2 모델 성능 중에서 더 큰 모델 성능을 포함하는 모델 정보를 제(n+1) 모델 정보로 결정하는 단계; 및상기 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터를 상기 시계열적인 블록체인 기반 분산 원장에 상기제n 블록 데이터 다음으로 저장하는 단계;를 포함하는,인공지능 모델 운용 방법.공개특허 10-2024-0002497-3-청구항 5 제1항에 있어서,상기 상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 기 설정된 구간 범위에 해당하는 블록 데이터들 각각의 모델 성능의 크기를 기준으로 해당 블록 데이터들을 정렬하는 단계;및상기 정렬된 블록 데이터들 중에서 가장 큰 모델 성능을 포함하는 블록 데이터에서 모델 파라미터를 획득하는단계;를 포함하는,인공지능 모델 운용 방법."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,질의로부터 복수의 키워드를 추출하는 단계;상기 추출된 복수의 키워드를 기 설정된 레벨들로 분류하는 단계; 및상기 분류된 레벨들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐색하는 단계;를 포함하는,인공지능 모델 운용 방법."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 기 설정된 레벨들은,범주 영역 키워드들을 포함하는 제1 레벨; 및주제 영역 키워드들을 포함하는 제2 레벨;을 포함하는,인공지능 모델 운용 방법."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제1 레벨로 분류된 키워드들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐색하는 단계;및원하는 인공지능 모델이 탐색되지 않는 경우, 상기 제2 레벨로 분류된 키워드들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐색하는 단계;를 포함하는,인공지능 모델 운용 방법."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 n개의 모델 정보를 시각화하는 단계;를 포함하는,인공지능 모델 운용 방법."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 블록체인은 하이퍼레저 패브릭 블록체인을 포함하는,인공지능 모델 운용 방법."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2024-0002497-4-인공지능 모델을 포함하는 스토리지; 및적어도 하나 이상의 프로세서;를 포함하고,상기 프로세서는,상기 인공지능 모델을 학습하는 동안 시계열적으로 획득한 n개의 모델 정보 각각에 상응하는 n개의 블록 데이터를 생성하고,상기 생성된 n개의 블록 데이터를 상기 스토리지에 시계열적인 블록체인 기반 분산 원장으로 저장하고,상기 n개의 블록 데이터 중 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우,상기 저장된 (n-1)개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라미터를 획득하며,상기 특정 블록 데이터의 상기 획득된 모델 파라미터를 바탕으로 상기 인공지능 모델을 재학습하는,인공지능 모델 운용 장치."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는,상기 특정 블록 데이터의 상기 획득된 모델 파라미터를 바탕으로 상기 인공지능 모델을 재학습하여 획득된 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터를 상기 시계열적인 블록체인 기반 분산 원장에 상기 제n 블록데이터 다음으로 저장하는,인공지능 모델 운용 장치."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 프로세서는,상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 제n 블록 데이터의 모델 성능을 시계열적인 역산으로 상기 스토리지에 저장된 블록 데이터들 각각의 모델 성능과 비교하며,비교 결과, 상기 제n 블록 데이터의 모델 성능보다 큰 모델 성능을 포함하는 상기 특정 블록 데이터에서 모델파라미터를 획득하는,인공지능 모델 운용 장치."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 프로세서는,상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 제n 블록 데이터의 모델 성능을 시계열적인 역산으로 상기 스토리지에 저장된 블록 데이터들 각각의 모델 성능과 비교하고,비교 결과, 상기 제n 블록 데이터의 모델 성능과 상기 특정 블록 데이터의 모델 성능이 동일하지만, 상기 제n블록 데이터의 파리미터의 값과 상기 특정 블록 데이터의 모델 파라미터 값이 상이한 경우, 상기 제n 블록 데이터의 파리미터의 값과 상기 특정 블록 데이터의 모델 파라미터 값 각각을 바탕으로 상기 인공지능 모델을 재학습하여 획득된 제1 및 제2 모델 성능 중에서 더 큰 모델 성능을 포함하는 모델 정보를 (n+1) 모델 정보로 결정하고,상기 (n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터를 상기 시계열적인 블록체인 기반 분산 원장에 상기 제n블록 데이터 다음으로 저장하는,인공지능 모델 운용 장치.공개특허 10-2024-0002497-5-청구항 15 제11항에 있어서,상기 프로세서는,상기 상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 기 설정된 구간 범위에 해당하는 블록 데이터들 각각의 모델 성능의 크기를 기준으로 해당 블록 데이터들을 정렬하며,상기 정렬된 블록 데이터들 중에서 가장 큰 모델 성능을 포함하는 블록 데이터에서 모델 파라미터를 획득하는,인공지능 모델 운용 장치."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 프로세서는,질의로부터 복수의 키워드를 추출하고,상기 추출된 복수의 키워드를 기 설정된 레벨들로 분류하며,상기 분류된 레벨들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐색하는,인공지능 모델 운용 장치."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 기 설정된 레벨들은,범주 영역 키워드들을 포함하는 제1 레벨; 및주제 영역 키워드들을 포함하는 제2 레벨;을 포함하는,인공지능 모델 운용 장치."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 프로세서는,상기 제1 레벨로 분류된 키워드들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐색하고,원하는 인공지능 모델이 탐색되지 않는 경우, 상기 제2 레벨로 분류된 키워드들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐색하는,인공지능 모델 운용 장치."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 프로세서는,상기 n개의 모델 정보를 시각화하는,인공지능 모델 운용 장치."}
{"patent_id": "10-2022-0079749", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "명령들을 수행하기 위한 프로그램이 기록된 비 일시적 컴퓨터로 읽을 수 있는 기록 매체에 있어서,인공지능 모델을 학습하는 동안 시계열적으로 획득한 n개의 모델 정보 각각에 상응하는 n개의 블록 데이터를 생공개특허 10-2024-0002497-6-성하는 단계;상기 생성된 n개의 블록 데이터를 스토리지에 시계열적인 블록체인 기반 분산 원장으로 저장하는 단계;상기 n개의 블록 데이터 중 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우,상기 저장된 (n-1)개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라미터를 획득하는 단계; 및상기 특정 블록 데이터의 상기 획득된 모델 파라미터를 바탕으로 상기 인공지능 모델을 재학습하는 단계;를 포함하는,기록 매체."}
{"patent_id": "10-2022-0079749", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "방법은 인공지능 모델을 학습하는 동안 시계열적으로 획득한 n개의 모델 정보 각각에 상응하는 n개의 블록 데이 터를 생성하고, 상기 생성된 n개의 블록 데이터를 스토리지에 시계열적인 블록체인 기반 분산 원장으로 저장하고, n개의 블록 데이터 중 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경 우, 상기 저장된 (n-1)개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라미터를 획득하며, 특정 블록 데 이터의 모델 파라미터를 바탕으로 인공지능 모델을 재학습한다."}
{"patent_id": "10-2022-0079749", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "실시예는 인공지능 모델을 구축, 배포 및 운용할 수 있는 방법, 장치 및 기록 매체에 관한 것이다."}
{"patent_id": "10-2022-0079749", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어, 수많은 기업에서 MLOps(Machine Learning Operations)을 도입하고 있다. 하지만, MLOps의 도입시, 데이터 수집, 분석 및 검증이나 러싱 머닝 모델의 학습, 학습된 러싱 머닝 모델의 배 포, 배포된 러싱 머닝 모델의 운용 등에서 여러가지 난제가 발생하여, 머신 러닝 모델의 도입에 많은 어려움을 겪고 있다. 즉, 기업 내에서 데이터 분석을 위한 전문 인력의 부족, 다양한 주체 간의 협업 결여나 기술 괴리, 산출물(product)의 공유 환경 결여 등으로 인해, 러싱 머닝 제품이 개발되더라도 내재화에 한계가 있다. 한편, 러싱 머닝 모델이 제품화되어 배포되는 경우, 실시간으로 신규 데이터를 이용하여 러싱 머닝 모델이 학습 되어 결과값이 출력된다. 예컨대, 러싱 머닝 모델이 학습될 때마다 모델 파라미터가 변경되어 최적의 결과값이 출력된다. 즉, 러싱 머닝 모델의 성능이 저하되는 경우, 성능이 저하된 원인을 분석하여 모델 파라미터를 재조 정한 후 러싱 머닝 모델을 학습하여 최적의 결과값을 산출한다. 이러한 경우, 원인 분석을 통해 모델 파라미터 를 재조정하는데 많은 시간과 비용이 발생되는 문제가 있다. 한편, 최근 들어, 기업이 갖고 있는 기밀 정보를 탈취하기 위해 다양한 해킹이 시도되고 있어, 기업 또한 기밀 정보의 탈취를 막기 위해 노력하고 있다. 또한, 다양한 구성원들 중 특수한 구성원들에 한해 기밀 정보에 접근 하도록 접근 권한이 엄격하게 관리될 필요가 있다. 하지만, 기업이 다양한 네트워크에 연결되어 있어, 언제든지 해킹에 공격당할 상황에 놓여 있는 것이 현실이다. 따라서, 데이터의 해킹 방지와 더불어 위조나 변조 방지 또 한 구성원들에 대한 엄격한 접근 권한 부여를 위한 보안 기술 개발이 절실히 요구되고 있다."}
{"patent_id": "10-2022-0079749", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예는 전술한 문제 및 다른 문제를 해결하는 것을 목적으로 한다. 실시예의 다른 목적은 인공지능(AI) 모델의 최적 성능 관리가 가능한 인공지능 모델 운용 방법, 장치 및 기록 매체를 제공하는 것이다. 또한 실시예의 또 다른 목적은 하이퍼레저 패브릭(hyperledger fabric)을 이용하여 보안성을 강화하고 위조나 변조를 방지할 수 있는 인공지능 모델 운용 방법, 장치 및 기록 매체를 제공하는 것이다. 실시예의 또 다른 목적은 탐색 기능을 이용하여 신규 AI 모델을 신속히 개발할 수 있는 인공지능 모델 운용 방 법, 장치 및 기록 매체를 제공하는 것이다."}
{"patent_id": "10-2022-0079749", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 또는 다른 목적을 달성하기 위해 실시예의 제1 측면에 따르면, 인공지능 모델 운용 방법은, 인공지능 모델을 학습하는 동안 시계열적으로 획득한 n개의 모델 정보 각각에 상응하는 n개의 블록 데이터를 생 성하는 단계; 상기 생성된 n개의 블록 데이터를 스토리지에 시계열적인 블록체인 기반 분산 원장으로 저장하는 단계; 상기 n개의 블록 데이터 중 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 저장된 (n-1)개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라미터를 획득하는 단계; 및 상기 특정 블록 데이터의 상기 획득된 모델 파라미터를 바탕으로 상기 인공지능 모델을 재학습하는 단계;를 포 함한다. 상기 방법은, 상기 특정 블록 데이터의 상기 획득된 모델 파라미터를 바탕으로 상기 인공지능 모델을 재학습하 여 획득된 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터를 상기 시계열적인 블록체인 기반 분산 원장에 상기 제n 블록 데이터 다음으로 저장하는 단계;를 포함할 수 있다. 상기 방법은, 상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 제n 블록 데이터의 모델 성능을 시계열적인 역산으로 상기 스토리지에 저장된 블록 데이터들 각각의 모델 성능 과 비교하는 단계; 및 비교 결과, 상기 제n 블록 데이터의 모델 성능보다 큰 모델 성능을 포함하는 상기 특정 블록 데이터에서 모델 파라미터를 획득하는 단계;를 포함할 수 있다. 상기 방법은, 상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 제n 블록 데 이터의 모델 성능을 시계열적인 역산으로 상기 스토리지에 저장된 블록 데이터들 각각의 모델 성능과 비교하는 단계; 비교 결과, 상기 제n 블록 데이터의 모델 성능과 상기 특정 블록 데이터의 모델 성능이 동일하지만, 상기 제n 블록 데이터의 파리미터의 값과 상기 특정 블록 데이터의 모델 파라미터 값이 상이한 경우, 상기 제n 블록 데이 터의 파리미터의 값과 상기 특정 블록 데이터의 모델 파라미터 값 각각을 바탕으로 상기 인공지능 모델을 재학 습하여 획득된 제1 및 제2 모델 성능 중에서 더 큰 모델 성능을 포함하는 모델 정보를 제(n+1) 모델 정보로 결 정하는 단계; 및 상기 제(n+1) 모델 정보에 상응하는 (n+1) 블록 데이터를 상기 시계열적인 블록체인 기반 분산 원장에 상기 제n 블록 데이터 다음으로 저장하는 단계;를 포함할 수 있다. 상기 방법은, 상기 상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 기 설정된 구간 범위에 해당하는 블록 데이터들 각각의 모델 성능의 크기를 기준으로 해당 블록 데이터들을 정 렬하는 단계; 및 상기 정렬된 블록 데이터들 중에서 가장 큰 모델 성능을 포함하는 블록 데이터에서 모델 파라 미터를 획득하는 단계;를 포함할 수 있다. 상기 방법은, 질의로부터 복수의 키워드를 추출하는 단계; 상기 추출된 복수의 키워드를 기 설정된 레벨들로 분 류하는 단계; 및 상기 분류된 레벨들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐색하는 단 계;를 포함할 수 있다. 상기 기 설정된 레벨들은, 범주 영역 키워드들을 포함하는 제1 레벨; 및 주제 영역 키워드들을 포함하는 제2 레 벨;을 포함할 수 있다. 상기 방법은, 상기 제1 레벨로 분류된 키워드들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐 색하는 단계; 및 원하는 인공지능 모델이 탐색되지 않는 경우, 상기 제2 레벨로 분류된 키워드들을 바탕으로 상 기 스토리지에 저장된 복수의 인공지능 모델을 탐색하는 단계;를 포함할 수 있다. 상기 방법은, 상기 n개의 모델 정보를 시각화하는 단계;를 포함할 수 있다. 상기 블록체인은 하이퍼레저 패브릭 블록체인을 포함할 수 있다. 상기 또는 다른 목적을 달성하기 위해 실시예의 제2 측면에 따르면, 인공지능 모델 운용 장치는, 인공지능 모델을 포함하는 스토리지; 및 적어도 하나 이상의 프로세서;를 포함하고,상기 프로세서는, 상기 인공지능 모델을 학습하는 동안 시계열적으로 획득한 n개의 모델 정보 각각에 상응하는 n개의 블록 데이터 를 생성하고, 상기 생성된 n개의 블록 데이터를 상기 스토리지에 시계열적인 블록체인 기반 분산 원장으로 저장하고, 상기 n개의 블록 데이터 중 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 저장된 (n-1)개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라미터를 획득하며, 상기 특정 블록 데이터의 상기 획득된 모델 파라미터를 바탕으로 상기 인공지능 모델을 재학습한다. 상기 프로세서는, 상기 특정 블록 데이터의 상기 획득된 모델 파라미터를 바탕으로 상기 인공지능 모델을 재학 습하여 획득된 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터를 상기 시계열적인 블록체인 기반 분산 원장 에 상기 제n 블록 데이터 다음으로 저장할 수 있다. 상기 프로세서는, 상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 제n 블록 데이터의 모델 성능을 시계열적인 역산으로 상기 스토리지에 저장된 블록 데이터들 각각의 모델 성능과 비교하며, 비교 결과, 상기 제n 블록 데이터의 모델 성능보다 큰 모델 성능을 포함하는 상기 특정 블록 데이터에서 모델 파라미터를 획득할 수 있다. 상기 프로세서는, 상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 제n 블록 데 이터의 모델 성능을 시계열적인 역산으로 상기 스토리지에 저장된 블록 데이터들 각각의 모델 성능과 비교하고, 비교 결과, 상기 제n 블록 데이터의 모델 성능과 상기 특정 블록 데이터의 모델 성능이 동일하지만, 상기 제n 블록 데이터의 파리미터의 값과 상기 특정 블록 데이터의 모델 파라미터 값이 상이한 경우, 상기 제n 블록 데이 터의 파리미터의 값과 상기 특정 블록 데이터의 모델 파라미터 값 각각을 바탕으로 상기 인공지능 모델을 재학 습하여 획득된 제1 및 제2 모델 성능 중에서 더 큰 모델 성능을 포함하는 모델 정보를 제(n+1) 모델 정보로 결 정하고, 상기 제(n+1) 모델 정보에 상응하는 (n+1) 블록 데이터를 상기 시계열적인 블록체인 기반 분산 원장에 상기 제n 블록 데이터 다음으로 저장할 수 있다. 상기 프로세서는, 상기 상기 제n 블록 데이터의 모델 성능이 상기 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 기 설정된 구간 범위에 해당하는 블록 데이터들 각각의 모델 성능의 크기를 기준으로 해당 블록 데이터들 을 정렬하며, 상기 정렬된 블록 데이터들 중에서 가장 큰 모델 성능을 포함하는 블록 데이터에서 모델 파라미터 를 획득할 수 있다. 상기 프로세서는, 질의로부터 복수의 키워드를 추출하고, 상기 추출된 복수의 키워드를 기 설정된 레벨들로 분 류하며, 상기 분류된 레벨들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐색할 수 있다. 상기 기 설정된 레벨들은, 범주 영역 키워드들을 포함하는 제1 레벨; 및 주제 영역 키워드들을 포함하는 제2 레 벨;을 포함할 수 있다. 상기 프로세서는, 상기 제1 레벨로 분류된 키워드들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델 을 탐색하고, 원하는 인공지능 모델이 탐색되지 않는 경우, 상기 제2 레벨로 분류된 키워드들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐색할 수 있다. 상기 프로세서는, 상기 n개의 모델 정보를 시각화할 수 있다. 상기 또는 다른 목적을 달성하기 위해 실시예의 제3 측면에 따르면, 명령들을 수행하기 위한 프로그램이 기록된 비 일시적 컴퓨터로 읽을 수 있는 기록 매체는, 인공지능 모델을 학습하는 동안 시계열적으로 획득한 n개의 모델 정보 각각에 상응하는 n개의 블록 데이터를 생 성하는 단계; 상기 생성된 n개의 블록 데이터를 스토리지에 시계열적인 블록체인 기반 분산 원장으로 저장하는 단계; 상기 n개의 블록 데이터 중 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 상기 저장된 (n-1)개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라미터를 획득하는 단계; 및 상기 특정 블록 데이터의 상기 획득된 모델 파라미터를 바탕으로 상기 인공지능 모델을 재학습하는 단계;를 포 함한다."}
{"patent_id": "10-2022-0079749", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예는 MLOps에서 인공지능 모델을 학습하는 동안, 인공지능 모델의 성능이 항상 최적으로 유지되도록 할 수 있다. 예컨대, 인공지능 모델의 성능이 저하되는 경우, 이전에 학습시마다 저장된 블록체인 기반, 구체적으로 하이퍼레저 패브릭 기반 블록 데이터들 중에서 인공지능 성능이 우수했을 때의 모델 파라미터를 호출하여, 즉 롤백(roll-back)하여, 해당 모델 파라미터를 바탕으로 인공지능 모델을 학습함으로써, 모델 성능의 저하를 방지 할 수 있다. 실시예는 MLOps에서 인공지능 모델과 관련된 데이터나 정보를 블록체인 기반으로 저장함으로써, 해당 데이터나 정보의 접근 권한을 엄격히 관리하며 위조나 변조를 방지할 수 있다. 실시예는 질의에 포함된 키워드의 중요도에 따라 분류된 레벨을 바탕으로 탐색을 수행함으로써, 다양한 유저에 게 가장 적절한 응답이나 정보를 제공할 수 있다. 실시예의 적용 가능성의 추가적인 범위는 이하의 상세한 설명으로부터 명백해질 것이다. 그러나 실시예의 사상 및 범위 내에서 다양한 변경 및 수정은 당업자에게 명확하게 이해될 수 있으므로, 상세한 설명 및 바람직한 실 시예와 같은 특정 실시예는 단지 예시로 주어진 것으로 이해되어야 한다."}
{"patent_id": "10-2022-0079749", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 인공지능은 인공적인 지능 또는 이를 만들 수 있는 방법론을 연구하는 분야를 의미한다. 인공지능은 머신 러닝 (기계 학습, Machine Learning)과 딥 러닝(Deep Learning)을 포함할 수 있다. 머신 러닝은 데이터를 구문 분석하고, 해당 데이터를 통해 학습한 후, 정보를 바탕으로 결정을 내리기 위해 상 기 학습된 내용을 적용하는 알고리즘을 말한다. 또한, 머신 러닝은 어떠한 작업에 대하여 꾸준한 경험을 통해 그 작업에 대한 성능을 높이는 알고리즘으로 정의하기도 한다. 딥 러닝은 머신 러닝의 하위 개념으로써, 인간이 결론을 내리는 방식과 유사한 논리 구조를 사용하여 데이터를 지속적으로 분석하도록 설계된다. 이를 달성하기 위해 딥 러닝 애플리케이션은 인공 신경망이라는 계층화된 알 고리즘 구조를 사용한다. 인공 신경망의 설계는 인간 두뇌의 생물학적 신경망에서 영감을 얻어, 표준 머신 러닝 모델보다 훨씬 더 뛰어난 학습 프로세스를 제공할 수 있다. 실시예에서는 인공지능, 머신 러닝, 딥 러닝을 구분하지 않으며, 이하의 설명에서 특별한 기재가 없다면, 인공 지능을 의미할 수 있다. 인공 신경망(ANN: Artificial Neural Network)은 머신 러닝에서 사용되는 모델로써, 시냅스의 결합으로 네트워 크를 형성한 인공 뉴런(노드)들로 구성되는, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 인공 신경 망은 다른 레이어의 뉴런들 사이의 연결 패턴, 모델 파라미터를 갱신하는 학습 과정, 출력값을 생성하는 활성화 함수(Activation Function)에 의해 정의될 수 있다. 인공 신경망은 입력층(Input Layer), 출력층(Output Layer), 그리고 선택적으로 하나 이상의 은닉층(Hidden Layer)를 포함할 수 있다. 각 층은 하나 이상의 뉴런을 포함하고, 인공 신경망은 뉴런과 뉴런을 연결하는 시냅 스를 포함할 수 있다. 인공 신경망에서 각 뉴런은 시냅스를 통해 입력되는 입력 신호들, 가중치, 편향에 대한 활성 함수의 함숫값을 출력할 수 있다. 모델 파라미터는 학습을 통해 결정되는 파라미터를 의미하며, 시냅스 연결의 가중치와 뉴런의 편향 등이 포함된 다. 그리고, 하이퍼파라미터는 머신 러닝 알고리즘에서 학습 전에 설정되어야 하는 파라미터를 의미하며, 학습 률(Learning Rate), 반복 횟수, 미니 배치 크기, 초기화 함수 등이 포함된다. 인공 신경망의 학습의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함수 는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표로 이용될 수 있다. 머신 러닝은 학습 방식에 따라 지도 학습(Supervised Learning), 비지도 학습(Unsupervised Learning), 강화 학습(Reinforcement Learning)으로 분류할 수 있다.지도 학습은 학습 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시키는 방법을 의미하며, 레이블이란 학습 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 비지도 학습은 학습 데이터에 대한 레이블이 주어지지 않는 상태에서 인공 신경망을 학습시키 는 방법을 의미할 수 있다. 강화 학습은 어떤 환경 안에서 정의된 에이전트가 각 상태에서 누적 보상을 최대화 하는 행동 혹은 행동 순서를 선택하도록 학습시키는 학습 방법을 의미할 수 있다. 인공 신경망 중에서 복수의 은닉층을 포함하는 심층 신경망(DNN: Deep Neural Network)으로 구현되는 머신 러닝 을 딥 러닝(심층 학습, Deep Learning)이라 부르기도 하며, 딥 러닝은 머신 러닝의 일부이다. 이하에서, 머신 러닝은 딥 러닝을 포함하는 의미로 사용된다. 도 1a은 본 발명의 일 실시 예에 따른 AI 장치를 나타낸다. AI 장치는 예컨대, 머신러싱과 같은 인공지능을 이용하여 학습할 수 있는 모델을 구축하고, 상기 구축된 모델을 기 수집된 데이터를 이용하여 학습한 후, 상기 학습된 모델을 현장에서 이용할 수 있도록 배포하고, 상 기 배포된 모델을 현장에 적용하여 새로 생성된 데이터를 이용하여 학습하고 해당 모델을 운영하는 모든 절차를 수행하는 장치일 수 있다. 도 1a 을 참조하면, AI 장치는 통신부, 입력부, 러닝 프로세서, 센싱부, 출력부 , 메모리 및 프로세서 등을 포함할 수 있다. 통신부는 유무선 통신 기술을 이용하여 다른 AI 장치나 AI 서버(도 1b의200) 등의 외부 장치들과 데이터를 송수신할 수 있다. 예컨대, 통신부는 외부 장치들과 센서 정보, 사용자 입력, 학습 모델, 제어 신호 등을 송수신할 수 있다. 이때, 통신부가 이용하는 통신 기술에는 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), 5G, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블 루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), ZigBee, NFC(Near Field Communication) 등이 있다. 입력부는 다양한 종류의 데이터를 획득할 수 있다. 이때, 입력부는 영상 신호 입력을 위한 카메라, 오디오 신호를 수신하기 위한 마이크로폰, 사용자로부터 정보를 입력 받기 위한 사용자 입력부 등을 포함할 수 있다. 여기서, 카메라나 마이크로폰을 센서로 취급하여, 카메라나 마이크로폰으로부터 획득한 신호를 센싱 데이터 또는 센서 정보라고 할 수도 있다. 입력부는 모델 학습을 위한 학습 데이터 및 학습 모델을 이용하여 출력을 획득할 때 사용될 입력 데이터 등을 획득할 수 있다. 입력부는 가공되지 않은 입력 데이터를 획득할 수도 있으며, 이 경우 프로세서 또는 러닝 프로세서는 입력 데이터에 대하여 전처리로써 입력 특징점(input feature)을 추출할 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망으로 구성된 모델을 학습시킬 수 있다. 여기서, 학습 된 인공 신경망을 학습 모델이라 칭할 수 있다. 학습 모델은 학습 데이터가 아닌 새로운 입력 데이터에 대하여 결과 값을 추론해 내는데 사용될 수 있고, 추론된 값은 어떠한 동작을 수행하기 위한 판단의 기초로 이용될 수 있다. 이때, 러닝 프로세서는 AI 서버(도 1b의 200)의 러닝 프로세서과 함께 AI 프로세싱을 수행할 수 있다. 이때, 러닝 프로세서는 AI 장치에 통합되거나 구현된 메모리를 포함할 수 있다. 또는, 러닝 프로세서 는 메모리, AI 장치에 직접 결합된 외부 메모리 또는 외부 장치에서 유지되는 메모리를 사용하 여 구현될 수도 있다. 센싱부는 다양한 센서들을 이용하여 AI 장치 내부 정보, AI 장치의 주변 환경 정보 및 사용자 정보 중 적어도 하나를 획득할 수 있다. 이때, 센싱부에 포함되는 센서에는 근접 센서, 조도 센서, 가속도 센서, 자기 센서, 자이로 센서, 관성 센 서, RGB 센서, IR 센서, 지문 인식 센서, 초음파 센서, 광 센서, 마이크로폰, 라이다, 레이더 등이 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시킬 수 있다. 이때, 출력부에는 시각 정보를 출력하는 디스플레이부, 청각 정보를 출력하는 스피커, 촉각 정보를 출력하 는 햅틱 모듈 등이 포함될 수 있다. 메모리는 AI 장치의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 예컨대, 메모리는 입력 부에서 획득한 입력 데이터, 학습 데이터, 학습 모델, 학습 히스토리 등을 저장할 수 있다. 프로세서는 데이터 분석 알고리즘 또는 머신 러닝 알고리즘을 사용하여 결정되거나 생성된 정보에 기초하 여, AI 장치의 적어도 하나의 실행 가능한 동작을 결정할 수 있다. 그리고, 프로세서는 AI 장치(10 0)의 구성 요소들을 제어하여 결정된 동작을 수행할 수 있다. 이를 위해, 프로세서는 러닝 프로세서 또는 메모리의 데이터를 요청, 검색, 수신 또는 활용할 수 있고, 상기 적어도 하나의 실행 가능한 동작 중 예측되는 동작이나, 바람직한 것으로 판단되는 동작을 실행 하도록 AI 장치의 구성 요소들을 제어할 수 있다. 이때, 프로세서는 결정된 동작을 수행하기 위하여 외부 장치의 연계가 필요한 경우, 해당 외부 장치를 제 어하기 위한 제어 신호를 생성하고, 생성한 제어 신호를 해당 외부 장치에 전송할 수 있다. 프로세서는 사용자 입력에 대하여 의도 정보를 획득하고, 획득한 의도 정보에 기초하여 사용자의 요구 사 항을 결정할 수 있다. 프로세서는 AI 장치의 동작 내용이나 동작에 대한 사용자의 피드백 등을 포함하는 이력 정보를 수집 하여 메모리 또는 러닝 프로세서에 저장하거나, AI 서버 등의 외부 장치에 전송할 수 있다. 수 집된 이력 정보는 학습 모델을 갱신하는데 이용될 수 있다. 프로세서는 메모리에 저장된 응용 프로그램을 구동하기 위하여, AI 장치의 구성 요소들 중 적어 도 일부를 제어할 수 있다. 나아가, 프로세서는 상기 응용 프로그램의 구동을 위하여, AI 장치에 포 함된 구성 요소들 중 둘 이상을 서로 조합하여 동작시킬 수 있다. 도 1b는 본 발명의 일 실시 예에 따른 AI 서버를 나타낸다. 도 1b를 참조하면, AI 서버는 머신 러닝 알고리즘을 이용하여 인공 신경망을 학습시키거나 학습된 인공 신 경망을 이용하는 장치를 의미할 수 있다. 여기서, AI 서버는 복수의 서버들로 구성되어 분산 처리를 수행 할 수도 있고, 5G 네트워크로 정의될 수 있다. 이때, AI 서버는 AI 장치의 일부의 구성으로 포함되어, AI 프로세싱 중 적어도 일부를 함께 수행할 수도 있다. AI 서버는 통신부, 메모리, 러닝 프로세서 및 프로세서 등을 포함할 수 있다. 통신부는 AI 장치 등의 외부 장치와 데이터를 송수신할 수 있다. 메모리는 모델 저장부를 포함할 수 있다. 모델 저장부는 러닝 프로세서을 통하여 학습 중 인 또는 학습된 모델(또는 인공 신경망, 231a)을 저장할 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망(231a)을 학습시킬 수 있다. 학습 모델은 인공 신경 망의 AI 서버에 탑재된 상태에서 이용되거나, AI 장치 등의 외부 장치에 탑재되어 이용될 수도 있다. 학습 모델은 하드웨어, 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 학습 모델의 일부 또는 전부가 소프트웨어로 구현되는 경우 학습 모델을 구성하는 하나 이상의 명령어(instruction)는 메모리 에 저장될 수 있다. 프로세서는 학습 모델을 이용하여 새로운 입력 데이터에 대하여 결과 값을 추론하고, 추론한 결과 값에 기 초한 응답이나 제어 명령을 생성할 수 있다. 이하에서 설명될 실시예와 관련된 개념이나 용어를 설명한다. MLOps는 기업에서 머신러닝(ML: Machine Learning)이나 딥 러닝(DL: Deep Learning)을 포함하는 인공지능(AI: Artificial Intelligence)을 이용하여 모델을 생성하고, 상기 생성된 모델을 학습하고, 상기 학습된 모델을 배 포하고 운영하는 전반적인 절차나 시스템을 의미할 수 있다. MLOps는 나중에 도 2를 참조하여 설명한다.블록체인은 비즈니스 네트워크에서 트랜잭션을 기록하고 자산을 추적하는 프로세스를 효율화하는 불변의 공유 원장을 의미한다. 하이퍼레저 패브릭은 블록체인의 일종으로서, 블록체인 솔루션과 응용 프로그램을 개발하기 위한 모듈형 아키텍 처 플랫폼을 의미한다. 리눅스재단이 주도하여 설립한 하이퍼레저(Hyperledger)의 프로젝트 중 하나로서, 다 양한 기술 운영위원회와 여러 조직의 유지 관리자에 의해 관리된다. 하이퍼레저 패브릭은 허가받은 사용자만 참 여할 수 있는 허가형 블록체인(permissioned blockchain)으로서, 프라이빗 블록체인의 일종이다. 하이퍼레저 패브릭은 도 3을 참조하여 설명한다. 실시예는 MLOps에서 인공지능 모델을 학습하는 동안, 인공지능 모델의 성능이 항상 최적으로 유지되도록 할 수 있다. 예컨대, 인공지능 모델의 성능이 저하되는 경우, 이전에 학습시마다 저장된 블록체인 기반, 구체적으로 하이퍼레저 패브릭 기반 블록 데이터 중에서 인공지능 성능이 우수했을 때의 모델 파라미터를 호출하여, 즉 롤 백(roll-back)하여, 해당 모델 파라미터를 바탕으로 인공지능 모델을 학습함으로써, 모델 성능의 저하를 방지할 수 있다. 실시예는 MLOps에서 인공지능 모델과 관련된 데이터나 정보를 블록체인 기반으로 저장함으로써, 해당 데이터나 정보의 접근 권한을 엄격히 관리하며 위조나 변조를 방지할 수 있다. 실시예는 질의에 포함된 키워드의 중요도에 따라 분류된 레벨을 바탕으로 탐색을 수행함으로써, 다양한 유저에 게 가장 적절한 응답이나 정보를 제공할 수 있다. 이러한 기술적 장점을 갖는 다양한 실시예들을 도 2 내지 도 17을 참조하여 설명한다. 도 2는 실시예에 따른 MLOps을 설명하는 도면이다. 도 2에 도시한 바와 같이, MLOps에서 프로젝트를 진행하기 위해 디자인 단계(S1), 모델 개발 단계(S2) 및 운용 단계(S3)의 순서로 진행된다. 디자인 단계(S1)는 해당 기업에서 요구하는 바를 기준으로 문제를 정의하는 단계이다. 예컨대, 어떠한 데이터가 필요한지, 어떠한 머신러닝이나 딥러닝 기술이 중요하게 적용할지 등이 정의될 수 있다. 이러한 문제 정의를 통 해 모델이 생성될 수 있다. 모델 개발 단계(S2)는 디자인한 실험을 수행하기 위한 개발 단계이다. 기업에서 사용할 수 있도록 제품의 안정 성을 충분히 검증(verify)해야 하므로, 다양한 실험이 수행될 수 있다. 또한, 모델 개발 단계(S2)에서 상기 생 성된 모델이 학습될 수 있다. 운용 단계(S3)는 상기 개발된 모델을 최종 사용자에게 서비스하기 위한 단계이다. 즉, 상기 개발된 모델을 어느 곳에 배포할 지에 따라 배포 방식이 달라질 수 있다. 즉, 상기 개발된 모델이 웹, 스마트폰, 컴퓨터 등에 배포 될 때 그 배포 방식이 달라질 수 있다. 또한, 운용 단계(S3)에서 상기 배포된 모델이 지속적으로 모니터링되고 관리될 수 있다. 보다 상세한 설명은 기 공지된 MLOps 관련 자료들로부터 용이하게 이해될 수 있다. 도 3 및 도 4를 참고하여 하이퍼레저 패브릭 아키텍쳐를 설명한다. 먼저 하이퍼레저 패브릭 관련 중요 용어를 설명한다. 채널은 하이퍼레저 패브릭 블록체인만에 고유한 것으로서, 네트워크로서 구성 요소 간 그룹을 나워 트랜잭션을 수행해야 할 때 사용될 수 있다. 즉, 채널은 트랜잭션의 접근 권한을 그룹별로 설정하고 관리하는 중요한 프라 이빗 블록체인 기술 요소이다. 조직(Organization)은 조직 별로 피어 노드 관리 및 권한 부여 보증 정책 등을 수행하며, 네트워크 참여자의 접 근 권한도 관리할 수 있다. 피어 노드(peer node)는 블록체인 네트워크를 유지하고, 트랜잭션(transaction) 제안 및 응답을 처리하며, 분산 원장(distributed ledger)과 체인코드(chaincode)를 관리하고 저장하는 역할을 수행할 수 있다. 피오 노드는 종 류에 따라 endorsing, committing, anchor, ordering servicing node가 있다. 분산원장은 현재 상태를 나타내는 월드 스테이트와 원장의 생성 시점부터 현재까지의 기록을 저장하는 복수의 블록 데이터를 포함할 수 있다. 복수의 데이터는 블록체인 기반으로 저장될 수 있다. 월드 스테이트(world state)는 하이퍼레저 패드릭 원장의 일종으로, 체인 트랜잭션 로그(log)에 포함된 모든 키 (key)들의 최신 값들을 표현할 수 있다. 체인코드는 원장에 블록 데이터를 추가하거나 조회하는 일종의 프로그램이다. 체인코드는 Java, Go, js 로 로직 을 구현 할 수 있으며, 블록체인에 접근하는 외부 프로그램의 요청에 대해 계약서의 요건과 비교 검증하여 이상 이 없는 경우 실행 결과를 원장에 기록하도록 동작한다. 체인코드는 전체 트랜잭션 로그를 순회하며 키의 최신 값에 대한 직접적인 접근을 제공하기 때문에, 월드 스테 이트를 통해서 트래잭션 제안을 실행한다. 월드 스테이트는 키 값들이 수정될 때마다 변화한다. 각 피어 노드는 유효한 트랜잭션을 처리한 후 처리 된 블록 데이터의 값을 월드 스테이트의 분산원장에 저장할 수 있다. 예컨대, 월드 스테이트는 이터베이스로 구축되어, 사용자들이 데이터를 저장하고 읽어올 때 여러가지 기능을 활 용할 수 있다. 사용자 관리(Membership Service)는 인증과 인가를 관리하는 CA(Certification Authority) 서버를 통해 블록체 인 네트워크에 접근 자격이 부여되고, 각 사용자는 공인인증서와 같은 인증서를 발급받게 된다. 해당 인증서가 폐기 또는 변조될 경우에는 블록체인 네트워크에 접근 할 수 없다. 따라서, 블록체인에 블록 데이터를 새로 추 가하는 경우에 해당 사용자의 전자서명이 블록 데이터에 함께 기록이 되기 때문에, 누가 어떤 블록을 추가 하였 는지 추적도 가능할 수 있다. 또한, 채널과 정책등을 설정하여, 블록체인 참여자들 간의 프라이버시(Privacy)를 강화할 수 있다. 한편, 하나의 채널에 하나의 원장이 존재하며, 채널 안에 속한 피어 노드들은 동일한 원장의 복사본을 가진다. 도 3은 실시예에 따른 하이퍼레저 패브릭 아키텍처에서의 처리 흐름을 도시한다. 도 4는 실시예에 따른 하이퍼 레저 패브릭의 구체적인 동작을 도시한다. 도 3 및 도 4에 도시한 바와 같이, 클라이언트 어플리케이션(A)는 블록체인 네트워크(N)에 접속하여, 트랜잭션 을 요청하거나 블록 데이터를 수신할 수 있다. 즉, 클라이언트 어플리케이션(A)은 피어 노드(P1)에 연결하고(S11), 트랜잭션을 생성하여 상기 생성된 트랜잭션 을 피어 노드(P1)로 전송할 수 있다(S12). 즉, 클라이언트 어플리케이션(A)은 피어 노드(P1)에게 거래 제안을 할 수 있다. 클라이언트 어플리케이션(A)은 클라이언트 단말이나 클라이언트 노드로 불릴 수 있다. 피어 노드(P1)에는 거래 제안에 대해 승인을 해 줄 수 있는 보증 정책(endorsement policy)이 정의될 수 있다. 피어 노드(P1)는 거래 제안에 대하여 체인코드(S1)를 확인할 수 있다(S13). 피어 노드(P1)는 거래 제안을 받으면, 그 거래 제안이 거래 형식에 맞게 내용이 잘 채워져 있는지, 이전에 제출 된 적이 있는 거래 제안인지, MSP(Membership Service Provider)를 통해서 서명이 유효한지, 거래 제안을 한 클라이언트 어플리케이션(A)이 권한이 있는지 등을 확인할 수 있다. 이러한 확인 후, 피어 노드(P1)는 거래 제안을 인자로 받아서 체인코드(S1)를 실행할 수 있다. 월드 스테이트 데이터베이스의 값에 체인코드(S1)가 실행되며, 결과 값으로 RWSet(read/write set)을 반환할 수 있다. 체인코드(S1)는 제안 응답(proposal response)를 업데이트할 수 있다(S14). 피어 노드(P1)는 제안 응답을 클라이언트 어플리케이션(A)으로 전송할 수 있다(S15). 클라이언트 어플리케이션(A)은 해당 거래를 오더러(O1)으로 전송할 수 있다(S16). 오더러(O1)는 합의 알고리즘에 의거해서 블록 데이터를 생성하고, 상기 생성된 블록 데이터를 피어 노드(P1)로 전송할 수 있다(S17) 해당 거래에는 RWSet, 피어 노드(P1)의 서명, 채널 식별자(ID) 등이 포함될 수 있다. 오더러(O1)는 이들 정보들 을 바탕으로 블록 데이터를 생성할 수 있다. 피어 노드(P1)는 블록 데이터를 이용하여 원장(또는 분산 원장)(L1)을 업데이트할 수 있다(S18). 피어 노드(P1)는 블록 데이터 내의 거래들 각각이 보증 정책을 준수하였는지, 월드 스테이트의 RWSet 버전과 동 일한지 등을 확인할 수 있다. 검사 과정이 끝나면, 해당 블록 데이터 내의 거래에는 valid/invalid 값이 태그될 수 있다. 이후, 최종 검증을 마친 블록 데이터가 해당 채널 내의 원장(L1)에 블록체인 형태로 저장될 수 있다. 아울러, 유효한 거래인 경우, RWSet이 월드 스테이트에 기록될 수 있다. 피어 노드(P1)는 이벤트를 클라이언트 어플리케이션(A)으로 전송할 수 있다(S19). 이하에서 설명되는 모델은 머신러닝이나 딥러닝과 같은 인공지능을 이용하여 구축된 인공지능 모델일 수 있다. 도 5는 실시예에 따른 장치를 도시한다. 도 5를 참조하면, 실시예에 따른 장치는 프로세서, 스토리지 및 블록체인 엔진을 포함할 수 있 다. 프로세서 및 스토리지 각각은 도 1a에 도시된 프로세서이나 도 1b에 도시된 프로세서일 수 있다. 또한, 스토리지는 도 1a에 도시된 메모리나 도 1b에 도시된 메모리일 수 있다. 프로세서는 클라우드 기반 네트워크를 통해 스토리지에 접속하여, 데이터나 정보를 스토리지에 저장하거나 스토리지으로부터 데이터나 정보를 불러올 수 있다. 기업은 복수의 사업장(210, 220, 230)을 가질 수 있다. 이들 사업장(210, 220, 230)은 물리적으로 이격되어 있 을 수도 있고, 서로 상이한 제품을 생산할 수도 있지만, 이에 대해서는 한정하지 않는다. 복수의 사업장(210, 220, 230)은 자체적으로 데이터베이스(211, 221, 231)를 구축하여, 자체적으로 획득되는 데 이터나 정보가 데이터베이스(211, 221, 231)에 저장될 수 있다. 기업, 예컨대 본사에서는 기업 전체 측면에서 중요한 데이터나 정보를 한군데에 모아 저장할 필요성이 있다. 이 를 위해 스토리지가 구비될 수 있다. 하지만, 각 사업장(210, 220, 230)의 데이터베이스(211, 221, 231) 에 포함된 모든 데이터나 정보가 스토리지에 저장되는 경우, 스토리지의 용량 초과나 관리 측면에서 의 비용 증가 등으로 인해 비효율적이다. 따라서, 각 사업장(210, 220, 230)의 데이터베이스(211, 221, 231)에 포함된 모든 데이터나 정보 중에서 의미있 는 데이터나 정보가 추출되어 스토리지에 저장될 수 있다. 스토리지는 스토리지에 저장된 데이터나 별로도 수집된 데이터를 훈련 데이터로 하여 학습된 적어도 하나 이상의 모델을 포함할 수 있다. 이들 적어도 하나 이상의 모델은 각 사업장(210, 220, 230)에 사용하기 위 해 각 사업장(210, 220, 230)의 관리자(관리자#1 내지 관리자#4)에 의해 구축될 수 있다. 블록체인 엔진은 하이퍼레저 패브릭 블록체인 기반으로 거래가 이루어지도록 하는 역할을 할 수 있다. 블 록체인 엔진은 도 3 및 도 4에 설명된 거래가 이루어지도록 할 수 있다. 블록체인 엔진은 서로 데이터를 공유하기 위해 허가된 관리자들로 구분된 그룹들(410, 420)이 각 채널 (CH1, CH2)에 정의될 수 있다. 예컨대, 제1 채널(CH1)은 제1 사업장, 제2 사업장 및 제3 사업장이나 이들 사업장들(210 내지 230) 각각을 관리하는 관리자들(관리자#1 내지 관리자#3)을 제1 그룹으로서 포함할 수 있다. 예컨대, 제2 채널(CH2)은 제4 사업장이나 그 관리자를 제2 그룹으로서 포함할 수 있다. 이러한 경우, 제2 채널(CH2)의 제2 그룹에 속한 관리자는 제2 채널(CH2)에 접근이 불가할 수 있다. 각 관리자가 어느 채널 채널(CH1, CH2)을 이용하는 그룹(410, 420)에 포함될지는 도 4에 도시된 MSP나 CA에 의 해 결정될 수 있다. 각 채널(CH1, CH2)에 속한 관리자는 해당 채널(CH1, CH2)에만 접근이 가능하여, 해당 채널(CH1, CH2)에 분산 원 장(430, 440)에 저장된 데이터나 정보, 즉 블록체인 기반 복수의 블록 데이터를 이용할 수 있다. 각 관리자는 자신에게 허가된 채널 채널(CH1, CH2)을 통해 프로세서에 접근할 수 있다. 예컨대, 제1 분산 원장은 제1 채널(CH1)을 구성하는 제1 그룹에 포함된 관리자들(관리자#1 내지 관리자#3)만이 접근이가능할 수 있다. 예컨대, 제2 분산 원장은 제2 채널(CH2)을 구성하는 제2 그룹에 포함된 관리자(관리 자#1, 관리자#4)만이 접근이 가능할 수 있다. 제1 관리자(관리자#1)은 제1 채널(CH1) 및 제2 채널(CH2)에 허가 권한을 부여받은 자로서, 제1 및 제2 채널(CH1, CH2)을 통해 제1 및 제2 분산 원장(430, 440) 모두에 접근 가능 할 수 있다. 마스터 관리자가 이들 관리자들(관리자#1 내지 관리자#4) 각각이 어떤 채널에 허가 권한을 부여할 지를 결정하고 관리할 수 있다. 예컨대, 도 5에서 관리자들(관리자#1 내지 관리자#4)는 도 4에 도시된 멤버이고, 마스터 관리자는 도 4에 도시된 관리자일 수 있다. 프로세서는 모델 성능 관리 모듈, 모델 성능 모니터링 모듈 및 모델 탐색 모듈을 포함할 수 있다. 모델 성능 관리 모듈과 모델 성능 모니터링 모듈은 예컨대, MLOps에서 훈련 데이터에 의한 학습으로 학습된 모델이 배치되어 운용될 때, 그 운용시에 상기 학습된 모델의 성능이 항상 최적으로 유지되도록 관리하 고 모니터링하는 역할을 할 수 있다. 모델 성능 관리 모듈은 스토리지에 저장된 복수의 모델 중에서 특정 모델을 지속적으로 학습하는 경 우, 모델 성능이 저하될 때 모델 성능이 모델 성능을 높여 모델 성능을 항상 최적으로 유지할 수 있다. 특정 모 델이 학습될 때마다 모델 정보가 획득되어, 분산 원장에 블록체인 기반으로 블록 데이터로서 스토리지에 저장될 수 있다. 모델 성능 모니터링 모듈은 스토리지에 저장된 특정 모델에 대한 복수의 블록 데이터를 바탕으로 시 각화를 수행하여, 시각화된 영상을 특정 모델을 운용하는 관리자에게 제공할 수 있다. 해당 관리자는 시각화된 영상을 통해 특정 모델의 모델 성능을 모니터링할 수 있다. 모델 탐색 모듈은 미리 구축되어 스토리지에 저장된 복수의 모델 중에서 각 관리자(관리자 #1 내지 관리자#4)나 개발자가 새로운 모델을 개발하기 위해 참고할만한 모델을 탐색할 때 사용할 수 있다. 이하 도 6 내지 도 17을 참조하여 실시예를 구현하는 다양한 방법을 설명한다. [모델 성능 관리 방법] 도 6은 실시예에 따른 장치에서 모델 성능을 관리하는 방법을 설명하는 순서도이다. 도 5 및 도 6을 참조하면, 프로세서는 인공지능 모델을 학습할 수 있다(S1110). 프로세서는 스토리지에 저장된 복수의 인공지능 모델 중에서 특정 인공지능 모델을 독출하여, 해당 인공지능 모델을 학습할 수 있다. 인공지능 모델의 학습은 해당 인공지능 모델을 운용하는 관리자의 요청이나 기 설정된 지침에 의해 수행될 수 있다. 해당 관리자가 속한 사업장에서 해당 인공지능 모델과 관련된 데이터들이 생성될 수 있다. 이 데이터들을 입력 하여 하여 해당 인공지능 모델이 학습되어 결과값이 출력될 수 있다. 예컨대, 결과값은 불량 예측율, 고장율, 잔존 수명 시간 등일 수 있지만, 이에 대해서는 한정하지 않는다. 인공지능 모델이 학습될 때마다 모델 정보가 획득될 수 있다. 프로세서는 인공지능 모델이 n번 학습되었는지를 확인하고(S1120), 인공지능 모델이 학습될 때마다 모델 정보를 획득할 수 있다(S1130). 프로세서는 블록체인 엔진을 통해 모델 정보에 상응하는 블록 데이터를 생성할 수 있다(S1140). 프로세서는 블록 데이터를 블록체인 기반 분산 원장에 저장할 수 있다(S1150). 분산 원장에 스토리지(30 0)에 구비될 수 있다. 도 11에 도시한 바와 같이, 제1 클라이언트 어플리케이션은 제1 피어 노드와의 거래를 통해 제1 분산 원장을 생성하거나 제1 분산 원장에 접근할 수 있다. 제2 클라이언트 어플리케이션은 제2 피어 노드 와의 거래를 통해 제1 분산 원장과 제2 분산 원장을 생성하거나 제1 분산 원장 및 제2 분산 원장에 접근할 수 있다. 사용자 1 및 사용자 2는 도 5에 도시된 제1 관리자 내지 제4 관리자(관리자#1 내지 관리자#4)일 수 있다. 사용 자 1 및 사용자 2는 기 허가의 정도에 따라 생성된 채널 채널(CH1, CH2) 내에 구비된 분산 원장에 접근 가능할 뿐 그 외 채널에 구비된 분산 원장에는 접근이 차단될 수 있다. 예컨대, 제1 분산 원장은 제1 인공지능 모델의 학습시마다 획득된 모델 정보들 각각에 상응하는 블록 데이터들 을 블록체인으로 저장할 수 있다. 예컨대, 제2 분산 원장은 제2 인공지능 모델의 학습시마다 획득된 모델 정보 들 각각에 상응하는 블록 데이터들을 블록체인으로 저장할 수 있다. 한편, 인공지능 모델이 n번 학습되는 경우, 분산 원장의 블록체인에 제1 블록 데이터부터 제n 블록 데이터가 시 계열적인 순서로 연결될 수 있다. 도 12에 도시한 바와 같이, 블록체인으로서 복수의 블록 데이터(B_1 내지 B_(n+1))이 서로 연결될 수 있다. 복 수의 블록 데이터(B_1 내지 B_(n+1))은 시계열적인 순서로 서로 연결될 수 있다. 예컨대, 제2 블록 데이터(B_ 2)는 제1 블로 데이터(B_1)에 연결되고, 제3 블록 데이터(B_3)은 제2 블록 데이터(B_2)에 연결될 수 있다. 이들 복수의 블록 데이터(B_1 내지 B_(n+1))은 스토리지에 구비된 분산 원장에 저장될 수 있다. 실시예에서, 블록체인은 하이퍼레저 패브릭 블록체인을 포함할 수 있다. 다시 도 5 및 도 6을 참조하면, 프로세서는 인공지능 모델의 성능이 저하되는지를 결정할 수 있다(S1160). 도 13에 도시한 바와 같이, 스토리지에 저장된 각 블록 데이터(Block 1 내지 Block 9)는 도 13에 도시한 바와 같이, 모델 성능을 나타내는 모델 정확도를 포함할 수 있다. 모델 정확도는 인공지능 모델에서 출력된 결 과값의 정확도를 의미할 수 있지만, 이에 대해서는 한정하지 않는다. 한편, 각 블록 데이터(Block 1 내지 Block 9)는 모델 정확도 이외에, 블록 데이터(Block 1 내지 Block 9)의 식 별자, 해당 인공지능 모델의 적용 사업부, 해당 인공지능 모델명, 클래스, 적용 알고리즘, 모델 파라미터, 모델 실행횟수, 모델 유지보수자, 학습데이터의 수집 구간, 즉 수집 시작일 및 수집 종료일 등을 포함할 수 있다. 해당 수집 구간 동안 수집된 학습데이터를 이용하여 인공지능 모델이 학습되어 결과값이 출력될 수 있다. 도 13에는 수집 구간이 1개월이지만, 15일, 2개월 3개월 등으로 달리할 수도 있다. 모델 정확도는 인공지능 모델에 입력되는 데이터의 질(quality), 모델 파라미터, 주변 환경 등에 따라 달라질 수 있다. 프로세서는 현재의 블록 데이터(Block 10)의 모델 정확도를 이전 블록 데이터들(Block 1 내지 Block 9) 각 각의 모델 정확도와 비교함으로써, 인공지능 모델의 성능 저하 여부를 판단할 수 있다. 프로세서는 인공지능 모델의 성능이 저하된 경우, 특정 블록 데이터에 포함된 모델 파라미터를 획득할 수 있다(S1170). 프로세서는 상기 획득된 모델 파라미터를 바탕으로 인공 지능 모델을 재학습함으로써, 모델 성능을 향상시 킬 수 있다(S1180). 특정 블록 데이터는 이전 블록 데이터들(Block 1 내지 Block 9) 중 하나의 블록 데이터로서, 현재의 블록 데이 터의 모델 정확도보다 큰 정확도를 가질 수 있다. 도 7은 실시예에 따른 장치에서 스토리지에 저장된 n개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라미터를 이용하여 모델 성능 관리하는 방법을 설명하는 순서도이다. 도 7은 도 6의 S1160 내지 S1180을 보다 구체화한 것이다. 도 5 및 도 7을 참조하면, 프로세서는 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보 다 작은지를 결정할 수 있다(S1210). 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 프로세서는 (n-1)개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라미터를 획득할 수 있다(S1220). 프로세서는 특정 블록 데이터의 모델 파라미터를 바탕으로 인공지능 모델을 재학습할 수 있다(S1230). 이 러한 재학습에 의해 인공지능 모델의 성능이 향상될 수 있다. 프로세서는 재학습에 의해 제(n+1) 모델 정보를 획득할 수 있다(S1240). 프로세서는 상기 획득된 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터를 분산 원장에 저장할 수 있 다(S1250). 제(n+1) 블록 데이터는 스토리지에 블록체인의 제n 블록 데이터 다음으로 저장될 수 있다. 제(n+1) 블록 데이터는 블록체인의 제n 블록 데이터에 연결될 수 있다. 한편, 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 큰 경우, 프로세서는 제n 모 델 정보에 상응하는 제n 블록 데이터를 분산 원장에 제(n-1) 블록 데이터 다음으로 저장할 수 있다(S1260). 도 3 및 도 4에 도시된 바와 같이, 일련의 과정을 거쳐, 제n 모델 정보에 상응하는 제n 블록 데이터가 생성되어, 상기 생성된 제n 블록 데이터가 분산 원장에 블록체인으로서 저장될 수 있다. 한편, 모델의 성능 저하를 야기했던 제n 블록 데이터가 삭제되고, 제(n+1) 블록 데이터가 제n 블록 데이터로서 블록체인의 제(n-1) 블록 데이터에 연결된 상태로 스토리지에 저장될 수도 있다. 한편, 이상에서는 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, n개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라미터가 획득될 수 있다. 이러한 경우, 인공지능 모델의 학습시 현재 모델 성능이 직전 모델 성능보다 작을 때마다 인공지능 모델의 재학습이 수행되어야 하므로, 모델 성능 관 리가 어렵고 비용이 많이 들 수 있다. 따라서, 제n 블록 데이터의 모델 성능과 제(n-1) 블록 데이터의 모델 성능 간의 차이값이 임계치보다 큰 경우에 한해, 인공지능 모델의 재학습이 수행될 수 있다. 예컨대, 제n 블록 데이터의 모델 성능이 85이고 제(n-1) 블록 데이터의 모델 성능이 88이며, 임계값이 5인 경우, 제n 블록 데이터의 모델 성능과 제(n-1) 블록 데이터의 모델 성능 간의 차이값, 즉 3이 임계값이 5보다 작으므로, 인공지능 모델의 재학습은 수행되지 않고 n 블록 데이터가 분산 원장에 저장될 수 있다. 예컨대, 예컨대, 제n 블록 데이터의 모델 성능이 85이고 제(n-1) 블록 데이터의 모델 성능이 93이며, 임계값이 5인 경우, 제n 블록 데이터의 모델 성능과 제(n-1) 블록 데이터의 모델 성능 간의 차이값, 즉 8이 임계값이 5보 다 크므로, 인공지능 모델의 재학습이 수행되고, 이러한 재학습에 의해 획득된 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터가 분산 원장에 저장될 수 있다. 도 8은 실시예에 따른 장치에서 현재 모델 성능을 스토리지에 저장된 n개의 블록 데이터 각각의 모델 성능 과 비교하여 모델 성능 관리하는 방법을 설명하는 제1 순서도이다. 도 5 및 도 8을 참조하면, 프로세서는 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보 다 작은지를 결정한다(S1310). 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 프로세서는 제n 블록 데 이터의 모델 성능을 시계열적인 역산으로 스토리지에 저장된 블록 데이터들 각각의 모델 성능과 비교할 수 있다(S1320). 스토리지에 저장된 블록 데이터들은 제1 블록 데이터 내지 제(n-1) 블록 데이터일 수 있다. 프로세서는 스토리지에 저장된 블록 데이터들 중 제n 블록 데이터의 모델 성능보다 큰 모델 성능을 포함하는 특정 블록 데이터에서 모델 파라미터를 획득할 수 있다(S1330). 프로세서는 특정 블록 데이터의 모델 파라미터를 바탕으로 인공지능 모델을 재학습할 수 있다(S1340). 이 러한 재학습에 의해 인공지능 모델의 성능이 향상될 수 있다. 프로세서는 재학습에 의해 제(n+1) 모델 정보를 획득할 수 있다(S1350). 프로세서는 상기 획득된 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터를 분산 원장에 저장할 수 있 다(S1360). 한편, 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 큰 경우, 프로세서는 제n 모 델 정보에 상응하는 제n 블록 데이터를 분산 원장에 제(n-1) 블록 데이터 다음으로 저장할 수 있다(S1370).도 13은 하이퍼레저 패브릭 블록체인 기반으로 구성되어 스토리지에 저장된 블록 데이터들의 일 예시도이 다. 도 13에 도시한 바와 같이, 현재 블록 데이터(Block 10)의 모델 성능, 즉 모델 정확도가 직전 블록 데이터 (Block 9)의 모델 성능, 즉 모델 정확도와 비교될 수 있다. 도면에서 제1 블록 데이터(Block 1) 내지 제9 블록 데이터(Block 9)는 스토리지에 블록체인 형태로 분산 원장에 저장될 수 있다. 비교 결과, 제9 블록 데이터(Block 9)의 모델 정확도가 현재 블록 데이터(Block 10)의 모델 정확도보다 크므로, 제9 블록 데이터(Block 9)의 모델 파라미터(C=1.0)이 호출될 수 있다. 이와 같이, 이전 블록 데이터 (Block 1 내지 Block 9) 중 특정 블록 데이터의 모델 파라미터를 호출하는 것을 롤백(roll-back)이라 부를 수 있다. 상기 호출된 모델 파라미터 값인 1.0을 바탕으로 인공지능 모델이 재학습됨으로써, 현재 블록 데이터(Block 1 0)의 모델 성능보다 큰 모델 성능이 확보될 수 있다. 도 9는 실시예에 따른 장치에서 현재 모델 성능과 비교된 블록 데이터의 모델 성능이 동일하지만, 모델 파라미 터가 상이한 경우에 모델 성능 관리하는 방법을 설명하는 순서도이다. 도 5 및 도 9를 참조하면, 프로세서는 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보 다 작은지를 결정한다(S1410). 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 프로세서는 제n 블록 데 이터의 모델 성능을 시계열적인 역산으로 스토리지에 저장된 블록 데이터들 각각의 모델 성능과 비교할 수 있다(S1420). 스토리지에 저장된 블록 데이터들은 제1 블록 데이터 내지 제(n-1) 블록 데이터일 수 있다. 프로세서는 제n 블록 데이터의 모델 성능이 특정 블록 데이터의 모델 성능과 일치하는지를 확인할 수 있다 (S1430). 제n 블록 데이터의 모델 성능이 특정 블록 데이터의 모델 성능과 일치하는 경우, 프로세서는 제n 블록 데 이터의 모델 파라미터가 특정 블록 데이터의 모델 파라미터와 상이한지를 확인할 수 있다(S1440). 제n 블록 데이터의 모델 파라미터가 특정 블록 데이터의 모델 파라미터와 상이한 경우, 프로세서는 제n 블 록 데이터의 모델 파라미터의 값과 특정 블록 데이터의 모델 파라미터의 값을 바탕으로 인공지능 모델을 재학습 할 수 있다(S1450). 프로세서는 재학습에 의해 학습된 제1 및 제2 모델 성능 능에서 더 큰 모델 성능을 포 함하는 모델 정보를 제(n+1) 모델 정보로 결정할 수 있다(S1460). 제n 블록 데이터의 모델 파라미터가 특정 블록 데이터의 모델 파라미터와 상이한 경우, 제n 블록 데이터의 모델 파라미터의 값을 바탕으로 인공지능 모델이 재학습됨으로써, 제1 모델 성능을 포함하는 제1 모델 정보가 획득될 수 있다. 또한, 특정 블록 데이터의 모델 파라미터의 값을 바탕으로 인공지능 모델이 재학습됨으로써, 제2 모델 성능을 포함하는 제2 모델 정보가 획득될 수 있다. 만일 제2 모델 정보의 제2 모델 성능이 제1 모델 정보의 제1 모델 성능보다 큰 경우, 제2 모델 정보가 제(n+1) 모델 정보로 결정될 수 있다. 프로세서는 상기 결정된 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터를 시계열적인 블록체인 기반 분산 원장에 제n 블록 데이터 다음으로 저장할 수 있다(S1470). 한편, 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 큰 경우, 프로세서는 제n 모 델 정보에 상응하는 제n 블록 데이터를 분산 원장에 제(n-1) 블록 데이터 다음으로 저장할 수 있다(S1480). 도 10은 실시예에 따른 장치에서 현재 모델 성능을 스토리지에 저장된 n개의 블록 데이터 각각의 모델 성 능과 비교하여 모델 성능 관리하는 방법을 설명하는 제2 순서도이다. 도 5 및 도 10을 참조하면, 프로세서는 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능 보다 작은지를 결정할 수 있다(S1510). 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 작은 경우, 프로세서는 기 설정된 구간 범위에 해당하는 블록 데이터들 각각의 모델 성능의 크기를 기준으로 해당 블록 데이터들을 정렬할 수 있 다(S1520). 기 설정된 범위에는 제1 블록 데이터 내지 제(n-1) 블록 데이터 모두가 포함되거나 그 일부 블록 데이터들만 포 함될 수도 있다. 프로세서는 상기 정렬된 블록 데이터들 중에서 가장 큰 모델 성능을 포함하는 특정 블록 데이터에서 모델 파라미터를 획득할 수 있다(S1530). 프로세서는 특정 블록 데이터의 모델 파라미터를 바탕으로 인공지능 모델을 재학습할 수 있다(S1540). 프로세서는 재학습에 의해 제(n+1) 모델 정보를 획득할 수 있다(S1550). 프로세서는 상기 획득된 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터를 분산 원장에 저장할 수 있 다(S1560). 제(n+1) 블록 데이터는 스토리지에 블록체인의 제n 블록 데이터 다음으로 저장될 수 있다. 제(n+1) 블록 데이터는 블록체인의 제n 블록 데이터에 연결될 수 있다. 한편, 제n 블록 데이터의 모델 성능이 제(n-1) 블록 데이터의 모델 성능보다 큰 경우, 프로세서는 제n 모 델 정보에 상응하는 제n 블록 데이터를 분산 원장에 제(n-1) 블록 데이터 다음으로 저장할 수 있다(S1570). 도 14는 하이퍼레저 패브릭 블록체인 기반으로 구성되어 스토리지에 저장된 블록 데이터들의 다른 예시도 이다. 도 14에 도시한 바와 같이, 스토리지에 제1 블록 데이터(Block 1) 내지 제9 블록 데이터(Block 9)가 블록 체인 형태로 분산 원장에 저장될 수 있다. 이때, 제1 블록 데이터(Block 1) 내지 제9 블록 데이터(Block 9)의 모델 성능, 즉 모델 정확도는 서로 상이할 수 있다. 현재 시점에서 인공지능 모델이 합습되어 획득된 제10 모델 정보에 상응하는 제10 블록 데이터(Block 10)의 모 델 성능이 스토리지에 저장된 제9 블록 데이터(Block 9)의 모델 성능보다 작은 경우, 스토리지에 저 장된 제1 블록 데이터(Block 1) 내지 제9 블록 데이터(Block 9) 각각의 모델 성능의 크기를 기준으로 제1 블록 데이터(Block 1) 내지 제9 블록 데이터(Block 9)가 정렬될 수 있다. 예컨대, 제1 블록 데이터(Block 1) 내지 제 9 블록 데이터(Block 9) 각각의 모델 성능의 크기를 기준으로 제1 블록 데이터(Block 1) 내지 제9 블록 데이터 (Block 9)가 내림차순으로 정렬될 수 있지만, 이에 대해서는 한정되지 않는다. 예컨대, 제8 블록 데이터(Block 8), 제1 블록 데이터(Block 1), 제9 블록 데이터(Block 9)의 순서로 정렬될 수 있다. 이후, 이와 같이 정렬된 블록 데이터들(block 1 내지 Block 9) 중에서 가장 큰 모델 성능을 포함하는 블록 데이 터, 즉 제8 블록 데이터(Block 8)가 선택되고, 상기 선택된 제8 블록 데이터(Block 8)의 모델 파라미터(C=0.7) 가 호출되는 롤백이 가능하다. 이후, 제8 블록 데이터(Block 8)의 모델 파라미터를 바탕으로 인공지능 모델이 재학습됨으로써, 모델 성능이 향 상될 수 있다. 또한, 이러한 재학습에 의해 회득된 모델 정보가 제(n+1) 모델 정보로 결정되고, 도 3 및 도 4 에 도시된 일련의 과정을 거쳐 제(n+1) 모델 정보에 상응하는 제(n+1) 블록 데이터가 분산 원장에 n블록 데이터 다음으로 저장될 수 있다. [모델 탐색 방법] 도 15는 실시예에 따른 장치에서 인공지능 모델을 탐색하는 방법을 설명하는 순서도이다. 도 5 및 도 15를 참조하면, 프로세서는 질의로부터 복수의 키워드를 추출할 수 있다(S1610). 도 2, 도 3 및 도 5에 도시한 바와 같이, 클라이언트 어플리케이션(A)은 질의를 송신하고, 프로세서는 질 의로부터 복수의 키워드를 추출할 수 있다. 예컨대, 질의는 JSON-RPC를 이용하여 수행될 수 있다. JSON-RPC는 JSON으로 인코딩된 원격 프로시저 호출일 수 있다. JSON-RPC는 매우 간단한 프로토콜로서, 소량의 데이터 타입과 명령들만을 정의하고 있다. JSON-RPC는 알림(notification, 서버로 데이터가 전송되고 응답을 요구하지 않음)을 허용하며, 다수의 호출이 서버로 전송 되고 순서없이 응답되는 것을 허용한다. 실시예에 따르면, 질의가 JSON-RPC를 이용하여 수행되므로, 저장 공간을 최소화할 수 있다. 프로세서는 상기 추출된 복수의 키워드를 기 설정된 레벨들로 분류할 수 있다(S1620). 실시예에서, 기 설정된 레벨들 적어도 2개 이상의 레벨로 구분되고, 각 레벨 각각은 각각 적어도 하나 이상의 키워드를 포함할 수 있다. 각 레벨과 각 레벨에 포함된 키워드들은 미리 사전으로 데이터베이스에 저장될 수 있다. 데이터베이스에 저장된 키워드들은 선택적으로 삭제되거나 새로 추가될 수 있다. 기 설정된 레벨은 키워드의 중요도를 나타낼 수 있다. 예컨대, 기 설정된 레벨은 범주 영역 키워드들을 포함하는 제1 레벨과 주제 영역 키워드들을 포함하는 제2 레벨 을 포함할 수 있다. 예컨대, 범위 영역을 나타내는 제1 레벨보다 주제 영역을 나타내는 제2 레벨이 더 중요한 키워드들을 가질 수 있다. 제1 레벨에 포함되는 키워드들로는 예컨대, 사업부 담당 영역에 해당하는 키워들이나 공정 담당 영역에 해당하 는 키워드들일 수 있다. 제2 레벨에 포함되는 키워드들로는 탐색 범위를 보다 더 줄일 수 키워드들로서, 예컨대 불량과 같은 일반 명사 이름이나 구체적인 불량 이름 등일 수 있다. 프로세서는 상기 분류된 레벨들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델을 탐색할 수 있다(S1630). 또한, 프로세서는 상기 분류된 레벨들을 바탕으로 상기 스토리지에 저장된 복수의 인공지능 모델 중에서 탐색하고자 하는 인공지능 모델과 관련된 데이터나 정보를 탐색할 수 있다. 탐색하고자 하는 인공지능 모델과 관련된 데이터나 정보는 해당 인공지능 모델을 구축하는데 사용된 훈련 데이터 정보, 다 양한 설계 변수, 해당 인공 지능 모델의 학습에 의해 획득된 모델 정보들 등일 수 있지만, 이에 대해서는 한정 하지 않는다. 프로세서는 코사인 측정(Cosine Measure), 유클리언 거리 측정(Euclidean Distance) 등과 같은 유사도 측 정(Similarity Measure)을 바탕으로 원하는 인공지능 모델이나 유사한 인공지능 모델을 탐색할 수 있다. 프로세 서는 매칭 인덱스 비율(매칭 인덱스 개수/질의 구성 인덱스 개수)을 바탕으로 원하는 인공지능 모델이나 유사한 인공지능 모델을 탐색할 수 있다. 도 16은 도 15의 S1630을 구체화한 도면이다. 도 5, 도 15 및 도 16을 참조하면, 프로세서는 제1 레벨로 분류된 키워드들을 바탕으로 스토리지에 저장된 복수의 인공지능 모델을 탐색할 수 있다(S1631). 프로세서는 탐색 결과, 원하는 인공지능 모델이 탐색되는지를 확인할 수 있다(S1632). 원하는 인공지능 모델이 탐색되지 않는 경우, 프로세서는 제2 레벨로 분류된 키워드들을 바탕으로 스토리 지에 저장된 복수의 인공지능 모델을 탐색할 수 있다(S1633). 실시예에 따르면, 키워드들을 중요도에 따라 여러 레벨로 분류하고, 그 분류된 레벨에 따라 탐색이 수행됨으로 써, 보다 빠르고 보다 정확하게 원하는 인공지능 모델이 탐색될 수 있다. 도 17은 인공지능 모델의 학습으로 획득된 복수의 모델 정보를 시가화한 모습을 도시한다. 도 5 및 도 17에 도시한 바와 같이, 프로세서는 스토리지에 저장된 특정 인공지능 모델과 관련된 n개 의 블록 데이터 각각에 상응하는 모델 정보를 시각화할 수 있다. 이와 같이 시각화된 영상은 도 2 및 도 3에 도 시한 바와 같이, 클라이언트 어플리케이션(A) 상에 제공될 수 있다. 이에 따라, 사용자(또는 관리자)는 클라이 언트 어플리케이션(A) 상에 제공된 상기 시각화된 영상을 통해 해당 인공지능 모델의 성능 관리 현황을 쉽게 파 악할 수 있다. 프로세서에서 미리 시각화된 영상을 생성하여 클라이언트 어플리케이션으로 제공하므로, 클라이언트 어플 리케이션에서 해당 시각화와 관련된 연산을 수행하지 않아도 되므로, 클라이언트 어플리케이션의 연산 부담을 줄여 줄 수 있다. 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 실시 예의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 실시예의 등가적 범위 내에서의 모든 변경 은 실시예의 범위에 포함된다."}
{"patent_id": "10-2022-0079749", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a은 본 발명의 일 실시 예에 따른 AI 장치를 나타낸다. 도 1b는 본 발명의 일 실시 예에 따른 AI 서버를 나타낸다. 도 2는 실시예에 따른 MLOps을 설명하는 도면이다. 도 3은 실시예에 따른 하이퍼레저 패브릭 아키텍처에서의 처리 흐름을 도시한다. 도 4는 실시예에 따른 하이퍼레저 패브릭의 구체적인 동작을 도시한다. 도 5는 실시예에 따른 장치를 도시한다. 도 6은 실시예에 따른 장치에서 모델 성능을 관리하는 방법을 설명하는 순서도이다. 도 7은 실시예에 따른 장치에서 스토리지에 저장된 n개의 블록 데이터 중 특정 블록 데이터에 포함된 모델 파라 미터를 이용하여 모델 성능 관리하는 방법을 설명하는 순서도이다. 도 8은 실시예에 따른 장치에서 현재 모델 성능을 스토리지에 저장된 n개의 블록 데이터 각각의 모델 성능과 비 교하여 모델 성능 관리하는 방법을 설명하는 제1 순서도이다. 도 9는 실시예에 따른 장치에서 현재 모델 성능과 비교된 블록 데이터의 모델 성능이 동일하지만, 모델 파라미 터가 상이한 경우에 모델 성능 관리하는 방법을 설명하는 순서도이다. 도 10은 실시예에 따른 장치에서 현재 모델 성능을 스토리지에 저장된 n개의 블록 데이터 각각의 모델 성능과 비교하여 모델 성능 관리하는 방법을 설명하는 제2 순서도이다. 도 11은 분장 원장을 구성하는 방법을 설명하는 도면이다. 도 12는 실시예에 따른 하이퍼레저 패브릭 블록체인을 이용하여 분산원장에 기록된 복수의 블록 데이터를 도시 한다. 도 13은 하이퍼레저 패브릭 블록체인 기반으로 구성되어 스토리지에 저장된 블록 데이터들의 일 예시도이다. 도 14는 하이퍼레저 패브릭 블록체인 기반으로 구성되어 스토리지에 저장된 블록 데이터들의 다른 예시도이다. 도 15는 실시예에 따른 장치에서 인공지능 모델을 탐색하는 방법을 설명하는 순서도이다. 도 16은 도 15의 S1630을 구체화한 도면이다.도 17은 인공지능 모델의 학습으로 획득된 복수의 모델 정보를 시가화한 모습을 도시한다."}
