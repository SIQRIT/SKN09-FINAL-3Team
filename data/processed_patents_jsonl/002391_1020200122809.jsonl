{"patent_id": "10-2020-0122809", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0040065", "출원번호": "10-2020-0122809", "발명의 명칭": "도커화된 인공지능 라이브러리에 대한 프록시 생성 장치 및 방법, 도커화된 인공지능 라이브", "출원인": "한국전자통신연구원", "발명자": "장철수"}}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "도커 이미지로 생성되는 인공지능 라이브러리로의 접근을 위해 미리 정의된 인터페이스를 기반으로 인공지능 라이브러리로의 중계 접속을 위한 프록시 서버 및 프록시 클라이언트를 생성하는 단계; 생성된 프록시 서버를 이용하여 인공 지능 라이브러리를 서버 형태로 구동하는 신규 도커 이미지 생성을 위한도커 파일을 생성하는 단계; 및 도커 파일을 기반으로 신규 도커 이미지를 생성하는 단계를 포함하는, 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 인터페이스는,원격 프로시져 호출(Remote Procedure Call, RPC) 통신을 통해 프록시 클라이언트는 인공지능 라이브러리를 호출하고, 프록시 서버는 프록시 클라이언트의 요청에 따라 인공지능 라이브러리를 통해 처리한 결과를 클라이언트로 응답하도록 인터페이스 정의 언어(Interface Definition Language, IDL)을 이용하여 정의되는, 도커화된인공지능 라이브러리에 대한 프록시 생성 방법."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, RPC 통신은, ROS 서비스, gRPC 또는 XML-RPC을 포함하는 복수의 RPC 통신 방식들 중 하나인, 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서, 도커 이미지는,인공지능 라이브러리의 구동 환경을 위해 요구되는 파일들이 계층화되어 적층되어 생성된 것인, 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서, 도커 이미지가 N개의 도커 계층들로 적층된 경우, 프록시 서버는,N+1 도커 계층으로 적층되는, 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서, 도커 파일에는,프록시 서버 코드 및 프록시 서버 구동 코드가 저장된 폴더명이 복사되는, 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4 항에 있어서, 도커 파일에는,신규 도커 이미지가 실행시 프록시 서버가 시작되도록 설정된 엔트리 포인트(ENTRYPOINT)가 지정되는, 도커화된인공지능 라이브러리에 대한 프록시 생성 방법.공개특허 10-2022-0040065-3-청구항 8 제1 항에 있어서, 프록시 클라이언트는,로봇 운영 시스템(Robot Operating System, ROS) 노드에 설치되어, 프록시 서버에 인공지능 라이브러리 호출을통해 ROS 노드에 인공지능 서비스를 제공하는, 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 프로그램이 기록된 메모리; 및프로그램을 실행하는 프로세서를 포함하며,프로그램은,도커 이미지로 생성되는 인공지능 라이브러리로의 접근을 위해 미리 정의된 인터페이스를 기반으로 인공지능 라이브러리로의 중계 접속을 위한 프록시 서버 및 프록시 클라이언트를 생성하는 단계; 생성된 프록시 서버를 이용하여 인공 지능 라이브러리를 서버 형태로 구동하는 신규 도커 이미지 생성을 위한도커 파일을 생성하는 단계; 및 도커 파일을 기반으로 신규 도커 이미지를 생성하는 단계를 수행하는, 도커화된 인공지능 라이브러리에 대한 프록시 생성 장치."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서, 인터페이스는,원격 프로시져 호출(Remote Procedure Call, RPC) 통신을 통해 프록시 클라이언트는 인공지능 라이브러리를 호출하고, 프록시 서버는 프록시 클라이언트의 요청에 따라 인공지능 라이브러리를 통해 처리한 결과를 클라이언트로 응답하도록 인터페이스 정의 언어(Interface Definition Language, IDL)을 이용하여 정의되는, 도커화된인공지능 라이브러리에 대한 프록시 생성 장치."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서, RPC 통신은, ROS 서비스, gRPC 또는 XML-RPC을 포함하는 복수의 RPC 통신 방식들 중 하나인, 도커화된 인공지능 라이브러리에 대한 프록시 생성 장치."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9 항에 있어서, 도커 이미지는,인공지능 라이브러리의 구동 환경을 위해 요구되는 파일들이 계층화되어 적층되어 생성된 것인, 도커화된 인공지능 라이브러리에 대한 프록시 생성 장치."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서, 도커 이미지가 N개의 도커 계층들로 적층된 경우, 프록시 서버는,N+1 도커 계층으로 적층되는, 도커화된 인공지능 라이브러리에 대한 프록시 생성 장치."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9 항에 있어서, 도커 파일에는,프록시 서버 코드 및 프록시 서버 구동 코드가 저장된 폴더명이 복사되는, 도커화된 인공지능 라이브러리에 대한 프록시 생성 장치.공개특허 10-2022-0040065-4-청구항 15 제12 항에 있어서, 도커 파일에는,신규 도커 이미지가 실행시 프록시 서버가 시작되도록 설정된 엔트리 포인트(ENTRYPOINT)가 지정되는, 도커화된인공지능 라이브러리에 대한 프록시 생성 장치."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "로봇 운영 시스템(Robot Operating System, ROS) 코어로부터 검색된 상대방 ROS 노드와 통신하는 복수의 ROS노드들로 구성된 ROS 분산 시스템에서, ROS 노드들 각각에는, 인공지능 라이브러리 프록시 클라이언트가 설치되고, 인공지능 라이브러리 프록시 서버 및 인공지능 라이브러리로 생성된 도커 이미지가 도커 컨테이너에서실행되되, 인공지능 라이브러리 프록시 클라이언트는, 원격 프로시져 호출(Remote Procedure Call, RPC) 통신을 통해 인공지능 라이브러리를 호출하고, 인공지능 라이브러리 프록시 서버는, 프록시 클라이언트의 요청에 따라 인공지능 라이브러리를 통해 처리한 결과를 클라이언트로 응답하는, 도커화된인공지능 라이브러리 기반 ROS 분산 시스템."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서, RPC 통신은, ROS 서비스, gRPC 또는 XML-RPC을 포함하는 복수의 RPC 통신 방식들 중 하나인, 도커화된 인공지능 라이브러리기반 ROS 분산 시스템."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17 항에 있어서, 일 인공지능 라이브러리 프록시 클라이언트와 다른 인공지능 라이브러리 프록시 클라이언트는, 각각 상이한 RPC 통신 방식으로 인공지능 라이브러리 프록시 서버를 호출하는, 도커화된 인공지능 라이브러리기반 ROS 분산 시스템."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18 항에 있어서, 인공지능 라이브러리와 함께 도커 컨테이너에서 실행되는 ROS 노드를 더 포함하되, 인공지능 라이브러리 프록시 클라이언트는,로봇 운영 시스템(Robot Operating System, ROS) 노드에 설치되어, 다른 ROS 노드에 설치된 다른 인공지능 라이브러리 프록시 클라이언트 또는 도커 컨테이너에 구현된 ROS 노드와 가입/출판 방식으로 통신하는, 도커화된 인공지능 라이브러리 기반 ROS 분산 시스템."}
{"patent_id": "10-2020-0122809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 16항에 있어서, ROS 노드들 및 도커 컨테이너는 각각 상이한 별도의 호스트에서 실행되는, 도커화된 인공지능 라이브러리 기반ROS 분산 시스템."}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "도커화된 인공지능 라이브러리에 대한 프록시 생성 장치 및 방법이 개시된다. 실시예에 따른 도커 이미지로 생성 되는 인공지능 라이브러리로의 접근을 위해 미리 정의된 인터페이스를 기반으로 인공지능 라이브러리로의 중계 접속을 위한 프록시 서버 및 프록시 클라이언트를 생성하는 단계, 생성된 프록시 서버를 이용하여 인공 지능 라 이브러리를 서버 형태로 구동하는 신규 도커 이미지 생성을 위한 도커 파일을 생성하는 단계 및 도커 파일을 기 반으로 신규 도커 이미지를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "기재된 실시예는 다양한 인공 지능을 융합하여 서비스를 제공할 수 있는 로봇에 관한 기술이다."}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 음성 정보, 영상 정보 및 다양한 센서 정보 등을 이용하여 음성 인식, 자연어 처리, 사물 인식, 사용자 인식, 행동 인식, 외형 특징 인식, 위치 인식, 이동 경로 생성, 관절 궤적 생성 및 조작 정보 생성 등을 수행하 는 다양한 인공지능 모듈들을 융합하여 사용자에게 서비스를 제공한다. 최신의 인공지능 모듈들은 인공 신경망(Artificial Neural Network, ANN) 기반 기계학습의 발달을 통해 성능이 크게 향상되고 있으며, 점점 더 많은 신경망 기반의 인공지능 모듈들이 출시되고 있다. 신경망 기반의 인공지능 모듈들은 인공지능 알고리즘을 개발하기 위해 Tensorflow, Caffe, PyTorch 및 Keras 등 다양한 인공지능 프레임워크와 인공지능 알고리즘에 필요한 다양한 외부 패키지들을 필요로 한다. 즉, 다양한 인공지능 프레임워크 및 외부 패키지와 의존 관계를 갖는 신경망 기반의 인공지능 모듈들을 구동하기 위해서는 운영체제에 해당 프레임워크 및 알고리즘이 의존하는 패키지들을 설치하여야 한다. 하지만, 여러 인공지능 모듈에서 필요한 인공지능 프레임워크나 외부 패키지들의 버전이 서로 다르거나, 외부 패키지 내부에서 필요로 하는 라이브러리 간에 충돌이 발생하여 의존 관계가 서로 상충하여 두 개 이상의 인공 지능 모듈을 하나의 운영체제에서 동시에 구동시키는데 어려움이 발생한다. 이런 문제를 해결하기 위해 파이썬(Python) 언어에서는 프로그램 별로 독립적인 가상의 환경을 만들 수 있는 Virtualenv를 이용하여 PyPI(The Python Package Index, https:///pypi.org)로부터 다운로드하여 설치하는 파 이썬 패키지들간의 의존성 문제를 해결한다. 하지만, Virtualenv를 이용한 패키지들은 파이썬 패키지들에 한정 되며 운영체제에서 필요한 다른 시스템 라이브러리들에 대한 가상환경을 제공하지 못하는 문제가 있다. 또한 로 봇 서비스를 개발하는 시스템 통합자 입장에서 보면, 특정 인공지능 모듈을 구동하기 위해 의존성을 갖는 패키 지들과 시스템 라이브러리들을 시스템 통합자가 전적으로 해당 모듈의 가상환경에 설치해야 하는 부담이 크다. 이런 문제를 해결하기 위해, 최근에는 도커(Docker)를 이용하여 소프트웨어 실행에 필요한 운영체제, 런타임, 시스템 라이브러리, 외부 패키지 등 모든 것을 포함하여 이미지(Image)로 만들어 구동시키는 컨테이너 (Container) 기술이 개발되었으며, 아직까지는 주로 웹서버 기반의 응용에서 활용되고 있는 실정이다. 한편, 로봇에서는 여러 모듈들을 융합하기 위한 방법으로 ROS(Robot Operating System)이라는 분산 프레임워크 를 이용하여 분산 응용 시스템을 만들어 로봇 서비스를 구성하고 있다. 하지만, 보통 인공지능 라이브러리 모듈을 개발하는 개발자는 범용의 인공지능 알고리즘 개발에 전문적 지식을 갖고 있는 반면 ROS와 같은 로봇에 특화된 분산 프레임워크에 대한 지식이 많지 않은 실정이라, 개발된 인공지 능 라이브러리 모듈을 활용하여 ROS 노드를 생성하여 도커 이미지(Docker Image)로 만드는데 어려움이 있다. 반 대로 ROS 노드들을 구성하여 로봇 시스템을 통합 개발하는 시스템 통합자들은 인공지능 모듈 및 도커에 대한 지 식이 많지 않은 실정이므로 필요한 인공지능 모듈을 ROS 프레임워크와 결합하여 도커 이미지로 만드는데 어려움 이 있다. 따라서, 종래에는 성능 좋은 인공지능 라이브러리 모듈이 새로 개발되어도 기존 모듈과의 의존성 문제로 시스템 에 통합되는 것이 용이하지 않고, 인공지능 라이브러리 모듈을 도커 이미지로 가상화하여 제공하는 경우에도 도 커 환경에 익숙하지 않은 시스템 통합 개발자는 성능 좋은 인공지능 라이브러리 모듈을 활용할 수 없는 상황이 다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 10-2125260호"}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "기재된 실시예는 분산 프레임워크에 대한 지식이 없는 개발자에 의해 개발된 도커화된 인공지능 라이브러리가 로봇 시스템에서 통합되어 활용될 수 있도록 하는데 그 목적이 있다. 기재된 실시예는 인공지능 라이브러리 및 도커에 대한 지식이 없는 개발자가 분산 노드 환경에서 다양한 인공지 능 라이브러리 모듈들이 제공하는 서비스를 기반으로 로봇 분산 시스템을 개발할 수 있도록 하는데 그 목적이 있다."}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 따른 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법은, 도커 이미지로 생성되는 인공지능 라 이브러리로의 접근을 위해 미리 정의된 인터페이스를 기반으로 인공지능 라이브러리로의 중계 접속을 위한 프록 시 서버 및 프록시 클라이언트를 생성하는 단계, 생성된 프록시 서버를 이용하여 인공 지능 라이브러리를 서버 형태로 구동하는 신규 도커 이미지 생성을 위한 도커 파일을 생성하는 단계 및 도커 파일을 기반으로 신규 도커 이미지를 생성하는 단계를 포함할 수 있다. 이때, 인터페이스는, 원격 프로시져 호출(Remote Procedure Call, RPC) 통신을 통해 프록시 클라이언트는 인공 지능 라이브러리를 호출하고, 프록시 서버는 프록시 클라이언트의 요청에 따라 인공지능 라이브러리를 통해 처 리한 결과를 클라이언트로 응답하도록 인터페이스 정의 언어(Interface Definition Language, IDL)을 이용하여 정의될 수 있다. 이때, RPC 통신은, ROS 서비스, gRPC 또는 XML-RPC을 포함하는 복수의 RPC 통신 방식들 중 하나일 수 있다. 이때, 도커 이미지는, 인공지능 라이브러리의 구동 환경을 위해 요구되는 파일들이 계층화되어 적층되어 생성된 것일 수 있다. 이때, 도커 이미지가 N개의 도커 계층들로 적층된 경우, 프록시 서버는, N+1 도커 계층으로 적층될 수 있다. 이때, 도커 파일에는, 프록시 서버 코드 및 프록시 서버 구동 코드가 저장된 폴더명이 복사될 수 있다. 이때, 도커 파일에는, 신규 도커 이미지가 실행시 프록시 서버가 시작되도록 설정된 엔트리 포인트(ENTRYPOIN T)가 지정될 수 있다. 이때, 프록시 클라이언트는, 로봇 운영 시스템(Robot Operating System, ROS) 노드에 설치되어, 프록시 서버에 인공지능 라이브러리 호출을 통해 ROS 노드에 인공지능 서비스를 제공할 수 있다. 실시예는 도커화된 인공지능 라이브러리에 대한 프록시 생성 장치로, 적어도 하나의 프로그램이 기록된 메모리 및 프로그램을 실행하는 프로세서를 포함하며, 프로그램은, 도커 이미지로 생성되는 인공지능 라이브러리로의 접근을 위해 미리 정의된 인터페이스를 기반으로 인공지능 라이브러리로의 중계 접속을 위한 프록시 서버 및 프 록시 클라이언트를 생성하는 단계, 생성된 프록시 서버를 이용하여 인공 지능 라이브러리를 서버 형태로 구동하 는 신규 도커 이미지 생성을 위한 도커 파일을 생성하는 단계 및 도커 파일을 기반으로 신규 도커 이미지를 생 성하는 단계를 수행할 수 있다. 이때, 인터페이스는, 원격 프로시져 호출(Remote Procedure Call, RPC) 통신을 통해 프록시 클라이언트는 인공 지능 라이브러리를 호출하고, 프록시 서버는 프록시 클라이언트의 요청에 따라 인공지능 라이브러리를 통해 처 리한 결과를 클라이언트로 응답하도록 인터페이스 정의 언어(Interface Definition Language, IDL)을 이용하여 정의될 수 있다. 이때, RPC 통신은, ROS 서비스, gRPC 또는 XML-RPC을 포함하는 복수의 RPC 통신 방식들 중 하나일 수 있다. 이때, 도커 이미지는, 인공지능 라이브러리의 구동 환경을 위해 요구되는 파일들이 계층화되어 적층되어 생성된 것일 수 있다. 이때, 도커 이미지가 N개의 도커 계층들로 적층된 경우, 프록시 서버는, N+1 도커 계층으로 적층될 수 있다. 이때, 도커 파일에는, 프록시 서버 코드 및 프록시 서버 구동 코드가 저장된 폴더명이 복사될 수 있다. 이때, 도커 파일에는, 신규 도커 이미지가 실행시 프록시 서버가 시작되도록 설정된 엔트리 포인트(ENTRYPOIN T)가 지정될 수 있다. 실시예에 따른 도커화된 인공지능 라이브러리 기반 ROS 분산 시스템은, 로봇 운영 시스템(Robot Operating System, ROS) 코어로부터 검색된 상대방 ROS 노드와 통신하는 복수의 ROS 노드들로 구성된 ROS 분산 시스템에서, ROS 노드들 각각에는, 인공지능 라이브러리 프록시 클라이언트가 설치되고, 인공지능 라이브러리 프록시 서버 및 인공지능 라이브러리로 생성된 도커 이미지가 도커 컨테이너에서 실행되되, 인공지능 라이브러 리 프록시 클라이언트는, 원격 프로시져 호출(Remote Procedure Call, RPC) 통신을 통해 인공지능 라이브러리를 호출하고, 인공지능 라이브러리 프록시 서버는, 프록시 클라이언트의 요청에 따라 인공지능 라이브러리를 통해 처리한 결과를 클라이언트로 응답할 수 있다. 이때, RPC 통신은, ROS 서비스, gRPC 또는 XML-RPC을 포함하는 복수의 RPC 통신 방식들 중 하나일 수 있다. 이때, 일 인공지능 라이브러리 프록시 클라이언트와 다른 인공지능 라이브러리 프록시 클라이언트는, 각각 상이 한 RPC 통신 방식으로 인공지능 라이브러리 프록시 서버를 호출할 수 있다. 이때, 인공지능 라이브러리와 함께 도커 컨테이너에서 실행되는 ROS 노드를 더 포함하되, 프록시 클라이언트는, 로봇 운영 시스템(Robot Operating System, ROS) 노드에 설치되어, 다른 ROS 노드에 설치된 다른 프록시 클라이 언트 또는 도커 컨테이너에 구현된 ROS 노드와 가입/출판 방식으로 통신할 수 있다. 이때, ROS 노드들 및 도커 컨테이너는 각각 상이한 별도의 호스트에서 실행될 수 있다."}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예에 따라, 인공지능 라이브러리 모듈 개발자는 다른 패키지 및 다양한 인공지능 프레임워크와의 의존성에 신경 쓸 필요없이 자신이 필요한 패키지 및 인공지능 프레임워크 만을 설치하여 알고리즘을 개발하고 도커 컨테 이너 안에서 독자적인 실행 환경을 제공받아 라이브러리 서비스를 제공할 수 있다. 또한, 만들어진 인공지능 라이브러리를 활용하여 분산 노드를 개발하고자 하는 개발자는 인공지능 라이브러리가 자신의 호스트 운영체제(Host OS)에 설치된 라이브러리인지 도커화된 게스트 운영체제(Guest OS)에 설치된 라이 브러인지의 여부에 상관없이 마치 로컬 호스트 운영체제에서 프로세스 간 통신 기반의 분산 환경을 꾸미는 것과 동일한 형태로 개발할 수 있어, 다양한 인공지능 라이브러리 모듈들이 의존성 문제 없이 공존하면서 손쉽게 분 산 시스템에 통합될 수 있는 효과가 있다."}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 비록 \"제1\" 또는 \"제2\" 등이 다양한 구성요소를 서술하기 위해서 사용되나, 이러한 구성요소는 상기와 같은 용 어에 의해 제한되지 않는다. 상기와 같은 용어는 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용될 수 있다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있다. 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세 서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 또는 \"포함하는(comprising)\"은 언급된 구성요소 또는 단계가 하나 이상의 다른 구성요소 또는 단 계의 존재 또는 추가를 배제하지 않는다는 의미를 내포한다."}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 해석될 수 있다. 또한, 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하에서는, 도 1 내지 도 15를 참조하여 실시예에 따른 도커화된 인공지능 라이브러리에 대한 프록시 생성 장 치 및 방법, 도커화된 인공지능 라이브러리 기반 ROS 분산 시스템이 상세히 설명된다. 로봇에서는 여러 모듈들을 융합하기 위한 방법으로 로봇 운영 시스템(Robot Operating System, ROS)이라는 분산 프레임워크를 이용하여 분산 응용 시스템을 만들어 로봇 서비스를 구성하고 있다. 도 1은 실시예가 적용되는 ROS를 활용한 분산 시스템의 개략적인 블록 구성도이다. 도 1을 참조하면, ROS를 활용한 분산 시스템은 분산 응용을 구성하는 복수의 ROS 노드(ROS Node)들(21, 22, 2 3)은 운영체제 상에서 개별 프로세스로 동작하면서 다른 ROS 노드들과 주로 가입/출판(pub/sub) 방식의 통신을 수행한다. ROS 노드들(21, 22, 23)은 일종의 네임서버인 로봇 운영 시스템 코어(ROS Core)에 연결하여 통신 대상 상대 방 ROS 노드들을 검색(lookup)한 후, 상대방 ROS 노드와 통신을 수행하여 분산 시스템을 구성한다. 이러한 분산 시스템 환경의 ROS 노드들(21, 22, 23) 각각에서 서로 상이한 인공지능 라이브러리 모듈을 사용하 고자 할 경우, 각각의 ROS 노드들(21, 22, 23)은 각각 상이한 별도의 가상환경에서 구동되어야만 한다. 따라서, 라이브러리 간의 의존성을 해소하기 위한 방법 중 하나인 가상 머신의 일종인 도커(Docker)를 활용하여 인공지능 라이브러리를 모듈화하고, 모듈화된 인공지능 라이브러리를 분산 처리 환경으로 융합하여 로봇용 서비 스를 구성할 수 있다. 도 2는 도커화된 인공지능 라이브러리와 ROS를 이용한 구성된 분산 환경의 개략적인 블록도이다. 도 2를 참조하면, 도커화된 인공지능 라이브러리와 ROS 노드를 이용하여 구성된 분산 환경으로 ROS 노드들(21, 22, 23) 각각이 인공지능 라이브러리들(31, 32, 33)과 함께 도커 이미지로 생성되어 각각 상응하는 도커 컨테이 너들(41, 42, 43)에서 구동되도록 구현될 수 있다. 그러나, 전술한 바와 같이 보통 인공지능 라이브러리 모듈을 개발하는 개발자는 범용의 인공지능 알고리즘 개발 에 전문적 지식을 갖고 있는 반면 ROS와 같은 로봇에 특화된 분산 프레임워크에 대한 지식이 많지 않은 실정이 다. 따라서, 개발된 인공지능 라이브러리 모듈을 활용하여 ROS 노드를 만들고 도커 이미지(Docker Image)를 생 성하는 것은 용이하지 않다. 반대로, ROS 노드들을 구성하여 로봇 시스템을 통합 개발하는 시스템 통합자들은 인공지능 모듈 및 도커에 대한 지식이 많지 않은 실정이므로 필요한 인공지능 모듈을 ROS 프레임워크와 결합하 여 도커 이미지로 만드는데 어려움이 있다. 즉, 도 2에 도시된 바와 같은 분산 환경을 구성하는 것은 용이하지 않다. 따라서, 실시예는 인공지능 라이브러리를 서버 형태의 도커 이미지로 만들고 ROS 노드가 클라이언트로써 서버 형태의 도커 이미지의 인공지능 라이브러리를 사용할 수 있도록 하여, 도커화된 인공지능 라이브러리 모듈 개발 자는 다른 패키지 및 다양한 인공지능 프레임워크와의 의존성에 신경쓸 필요없이 자신이 필요한 패키지 및 인공 지능 프레임워크 만을 설치하여 알고리즘을 개발하고 도커 컨테이너 안에서 독자적인 실행 환경을 제공받아 라이브러리 서비스를 제공할 수 있도록 하는 기술을 제안한다. 즉, 실시예는 도커화된 인공지능 라이브러리와 ROS를 이용한 분산 환경 구성을 용이하도록 하기 위해 ROS 노드 와 도커화된 인공지능 라이브러리 사이를 프록시하는 장치 및 방법을 제공한다. 이하, 도커화된 인공지능 라이 브러리에 대한 프록시 생성 장치 및 방법은 로봇 시스템의 분산 환경을 구성하는 실시예를 설명하나, 본 발명은 이에 한정되지 않는다. 즉, 본 발명은 로봇 시스템이 아닌 다른 종류의 분산 시스템을 구성하는 데에도 적용될 수 있음을 밝혀둔다. 도 3 내지 도 5는 실시예에 따른 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법을 설명하기 위한 도면 이다. 도 3을 참조하면, 실시예에 따라 ROS 노드에는 인공지능 라이브러리 프록시 클라이언트(AI Lib Proxy Client, 이하 '프록시 클라이언트'라 칭함)가 설치되고, 인공지능 라이브러리 프록시 서버(AI Lib Proxy Server, 이하 '프록시 서버'라 칭함)가 인공지능 라이브러리를 포함하는 도커 이미지와 함께 신규 도커 이미지로 생성되어 도커 컨테이너(미도시)에서 실행되도록 구성될 수 있다. 즉, 프록시 클라이언트 및 프록시 서버는 ROS 노드와 인공지능 라이브러리를 중계하는 역할 을 수행하도록 구현될 수 있다. 이를 통해, 개발자들이 ROS 노드 및 인공지능 라이브러리를 개발함에 있어 자유로움을 줄 수 있다. 이러한 프록시 기능을 제공하기 위해 프록시 서버 및 인공지능 라이브러리가 서버 형태로 구동될 수 있도록 구현된 신규 도커 이미지를 생성하는 방법에 대해 상세히 살펴보기로 한다. 이때, 실시예에 따른 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법은 도 3 및 도 5에 도시된 인공지 능 라이브러리 프록시 생성기(AI Lib Proxy Generator, 이하 '프록시 생성기'라 칭함)에 의해 수행될 수 있다. 도 3 내지 도 5를 참조하면, 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법은 도커 이미지로 생성 되는 인공지능 라이브러리로의 접근을 위해 미리 정의된 인터페이스를 기반으로 인공지능 라이브러리로 의 중계 접속을 위한 프록시 클라이언트 및 프록시 서버를 생성하는 단계(S210), 생성된 프록시 서버 를 이용하여 인공 지능 라이브러리를 서버 형태로 구동하는 신규 도커 이미지 생성을 위한 도커 파일 을 생성하는 단계(S220) 및 도커 파일을 이용하여 서버 형태의 신규 도커 이미지를 생성하는 단 계(S230)를 포함할 수 있다. 이때, 도커 이미지는, 인공지능 라이브러리의 구동 환경을 위해 요구되는 파일들이 계층화되어 적층되어 생 성된 것일 수 있다. 즉, 인공지능 라이브러리 모듈 개발자는 개발된 인공지능 라이브러리의 구동 환경을 위해 도커의 계층화 기술을 활용하여 해당 라이브러리에서 필요한 파일을 순차적으로 쌓아서 도커 이미지를 생성한다. 도 6은 도커 이미지의 예시도이다. 도 6을 참조하면, 도커 이미지는 얼굴 인식 인공 지능 라이브러리(FaceRecog AI Lib)가 도커 계층 N(Docker Layer N)을 형성하고, 얼굴 인식 인공 지능 라이브러리(FaceRecog AI Lib)에 필요한 파일들(52, 53)이 도커 계층 1 내지 도커 계층 N-1로 적층되어 생성된 것일 수 있다. 인공 지능 기반 얼굴인식(FaceRecog) 라이브러리에서 필요한 파일들, 예컨대, Linux 16.04, TensorFlow이 순차적으로 도커 계층(Docker Layer)들로 적층되어 도커 이미지로 생성될 수 있다. 이때, 신규 도커 이미지는, 인공지능 라이브러리에 대한 서버 기능을 수행할 수 있는 것일 수 있다. 도 7은 신규 도커 이미지의 예시도이다. 도 7에 도시된 바와 같이, 신규 도커 이미지는 도커 이미지에 프록시 서버가 도커 계층(Docker Layer) N+1로 적층되어 도커 이미지로 생성된 것일 수 있다. 한편, S210을 수행하기 위해서는 도커 이미지로 생성되는 인공지능 라이브러리로의 접근을 위해 인터페이스가 미리 정의되어 있어야 한다. 이때, 인터페이스는, 원격 프로시져 호출(Remote Procedure Call, RPC) 통신을 통해 프록시 클라이언트가 인공 지능 라이브러리를 호출하고, 프록시 서버가 프록시 클라이언트의 요청에 따라 인공지능 라이브러리를 통해 처리한 결과를 클라이언트로 응답하도록 인터페이스 정의 언어(Interface Definition Language, IDL)을 이용하여 정의될 수 있다. 즉, 개발자는 도커로 만들어진 인공지능 라이브러리에 접근하기 위해 IDL을 이용하여 인터페이 스를 정의해야 한다. 그러면, S210에서 프록시 생성기는 IDL을 기반으로 클라이언트와 서버 코드인 프록시 클라이언트와 프록시 서버를 자동으로 생성한다. 여기서, 프록시 클라이언트와 프록시 서버 사이의 RPC 통신 방식은 ROS Service 통신이나, gRPC, XML-RPC 등 IDL로부터 프로그래밍 언어로 코드 생성이 가능한 다양한 RPC(Remote Procedure Call) 방식이 가능 하므로 그 언어가 한정되지 않는다. 도 8은 인공지능 라이브러리와의 RPC 기반 인터페이스를 위한 IDL 작성 예시도이다. 일례로 ROS Service 기반의 RPC를 사용하는 경우, 입력된 이미지 소스(Image src)에 대한 얼굴인식을 수행하고, 인식된 사용자 이름(string identified_name)을 리턴하는 인공지능 라이브러리(FaceRecog)는 도 8에 도시된 바 와 같은 srv 파일(FaceRecogProxy.srv)이 IDL로써 정의될 수 있다. 이때, 이러한 IDL 파일을 호출하고자 하는 함수들마다 따로 정의하여 인터페이스의 묶음으로 처리될 수도 있다. 즉, 도 8을 참조하면, FaceRecogProxy.srv, FuncAProxy.srv, FuncBProxy.srv가 각각 IDL로써 정의되어 인터페 이스 묶음으로 처리될 수 있다. 이때, 인공지능 라이브러리 프록시 서버(AI Lib Proxy Server)는 프록시 클라이언트로부터 실행 요청을 받아 인 공지능 라이브러리를 이용하여 요청을 처리하고 결과를 전달하도록 구성된다. 도 9는 인공지능 라이브러리와의 RPC 기반 인터페이스를 위한 IDL 작성 예시도이다. 도 9를 참조하면, 일례로 다음의 얼굴인식을 위한 인공지능 라이브러리 프록시 서버(FaceRecogProxy_server)는, 프록시 클라이언트로부터 실행 요청을 받도록 준비하는 코드(rospy.Service(...))와 실행 요청을 받을 때 얼굴 인식 인공지능 라이브러리의 얼굴인식 함수(FaceRecogLibrary.FaceRecog)를 이용하여 인식된 사용자의 이름 (identified_name)을 리턴하도록 코딩된다. 이때, 복수의 IDL로 정의된 인터페이스의 묶음의 경우에는 해당 함수들 각각에 대한 대한 프록시 서버가 생성되 도록 구성될 수 있다. 한편, 도커 파일에는, 프록시 서버 코드 및 프록시 서버 구동 코드가 저장된 폴더명이 복사되고, 신규 도 커 이미지가 실행시 프록시 서버가 시작되도록 설정된 엔트리 포인트(ENTRYPOINT)가 지정될 수 있다. 이를 위해, 도 4에 도시된 바와 같이, S220는 프록시 서버 구동 코드를 생성하는 단계(S231), 도커 파일에 프록 시 서버 코드 및 구동 코드 복사 구문을 추가하는 단계(S232) 및 도커 파일 중 엔트리 포인트(ENTRYPOINT)에 프 록시 서버의 시작 구문을 추가하는 단계(S233)를 포함할 수 있다. 도 10은 실시예에 따른 프록시 서버의 구동 코드 예시도이다. 도 10을 참조하면, 만들어진 인공지능 라이브러리 도커 컨테이너가 실행될 때, 프록시 서버를 구동하기 위한 쉘 스크립트(run_server.sh)가 생성된다. 이때, 생성된 프록시 서버 및 필요한 파일들은 특정 폴더(일례: ailib_server 폴더)에 모두 저장될 수 있다. 도 11은 실시예에 따른 도커 파일의 예시도이다. 도커 파일(Dockerfile)에는 RPC 통신을 위해 필요한 기본 패키지들을 설치하도록 작성된다. 예컨대, ROS Service 기반의 RPC(Remote Procedure Call)를 사용하는 경우, 도 11에는 도커 이미지에 ROS 패키지를 추가로 설치하도록 한다(apt-get install ros-kinetic). 또한, 도커 파일에는 프록시 서버와 인터페이스하기 위한 코드와 프록시 서버를 구동하기 위한 쉘 스크립트 코 드(run_server.sh)가 저장된 폴더(ailib_server)를 새로운 도커 이미지에 복사(COPY)하도록 하고, 새로 만들어 질 도커가 시작할 때 서버를 시작하도록 설정하도록 ENTRYPOINT를 지정한다. 한편, S230에서 생성된 도커 파일을 이용하여 도커용 Command Line Interface를 통해 도커 이미지를 생성하도록 하면(docker build), 인공지능 라이브러리를 서버 형태로 시작할 수 있는 신규 도커 이미지가 생성될 수 있다. 전술한 바와 같이, 프록시 생성기에 의해 RPC 요청/응답을 위한 클라이언트 코드인 인공지능 라이브러리 프록시 클라이언트(AI Lib Proxy Client)가 생성됨에 따라, 분산 노드 개발자는 해당 노드의 로직을 작성하면서 인공지능 라이브러리 프록시 클라이언트(AI Lib Proxy Client)를 사용하여 라이브러리를 호출해주는 부분만 구 현하면 된다. 즉, 분산 노드 개발자는 자신의 호스트 운영체제 내에서 프로세스 간 통신 기반의 분산 환경을 꾸미는 것과 동 일한 형태로 통합 시스템을 개발할 수 있다. 즉, 생성된 인공지능 라이브러리가 도커 기반으로 제공되는 것인지 또는 호스트 운영체제 자체에서 제공되는 시스템 라이브러리인지를 고려하지 않고 이미 생성된 인공지능 프록시 클라이언트 코드를 이용하여 ROS 노드를 개발할 수 있다. ROS 노드에 구현된 인공지능 라이브러리 프록시 클라이언트(AI Lib Proxy Client)는 서버로 구동되는 인공지능 라이브러리 프록시 서버(AI Lib Wrappe Server)에 접근하여 RPC 요청/응답 메커니즘을 통해 라이브러리를 호출 하여 ROS 노드에게 인공지능 서비스를 제공할 수 있다. 도 12는 도커화된 인공지능 라이브러리와 ROS를 이용한 분산 환경 구성의 일 실시예를 도시한 도면이다. 도 12를 참조하면, 얼굴을 인식하는 인공 지능 라이브러리(FaceRecog), 사물을 인식하는 인공지능 라이브러리 (ObjRecog), 사용자의 행동을 인식하는 인공지능 라이브러리(PoseRecog)를 활용할 때, 실시예에 따라 생성된 인 공지능 프록시 서버(AI Lib Proxy Server)(121, 122, 123)를 포함한 도커 이미지를 이용하여 구동된 도커 컨테 이너(41, 42, 43), 인공지능 프록시 클라이언트(AI Lib Proxy Client)(111, 112, 113)를 이용하여 다양한 운영 체제와 의존 패키지 및 인공지능 프레임워크 상황에서 분산 ROS 노드를 만들어 운용되는 예가 도시되어 있다. . 도 13은 도커화된 인공지능 라이브러리와 ROS를 이용한 분산 환경 구성의 다른 실시예를 도시한 도면이다. 도 13을 참조하면, 실시예에 따라 생성된 도커 기반의 인공지능 라이브러리를 이용한 ROS 노드(FaceRecog, ObjRecog)(21, 22)와 기존 방식으로 도커에 인공지능 라이브러리와 ROS 노드를 함께 포함한 도커 컨테이너 (PoseRecog)가 서로 공존하면서 상호간에 ROS 기반의 가입/출판(pub/sub) 방식의 통신을 수행하는 예가 도시되 어 있다. 이때, 실시예에 따라 생성된 일 ROS 노드의 프록시 클라이언트는 얼굴을 인식하는 인공 지능 라이브러 리(FaceRecog)를 ROS Service 기반의 RPC 통신으로 호출하는 반면, 실시예에 따라 생성된 다른 ROS 노드의 프록시 클라이언트는 사물을 인식하는 인공 지능 라이브러리(ObjRecog)를 ProtoBuf를 사용하는 gRPC 방식 의 RPC 통신으로 호출하도록 구현될 수 있다. 도 14는 도커화된 인공지능 라이브러리와 ROS를 이용한 분산 환경 구성의 또 다른 실시예를 도시한 도면이다. 도 14를 참조하면, 도커화된 인공지능 라이브러리 모듈들이 ROS 노드들과 분리된 별도의 도커 호스트에서 구동 될 수 있음을 보여준다. 인공지능 라이브러리 모듈들을 구동하는 도커 호스트들은 일반 PC가 될 수 있으며, 클 라우드에서 제공하는 가상의 운영 환경이 될 수도 있다. 도 15는 실시예에 따른 컴퓨터 시스템 구성을 나타낸 도면이다. 실시예에 따른 도커화된 인공지능 라이브러리에 대한 프록시 생성 장치는 컴퓨터로 읽을 수 있는 기록매체와 같 은 컴퓨터 시스템에서 구현될 수 있다. 컴퓨터 시스템은 버스를 통하여 서로 통신하는 하나 이상의 프로세서, 메모리, 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치 및 스토리지를 포함할 수 있다. 또한, 컴퓨터 시스템은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있다. 프로세서 는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로그램 또는 프로세싱 인스트럭션들 을 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 휘발성 매체, 비휘발성 매체, 분리형 매체, 비분리형 매체, 통신 매체, 또는 정보 전달 매체 중에서 적어도 하나 이상을 포함하는 저장 매체일 수 있 다. 예를 들어, 메모리는 ROM이나 RAM을 포함할 수 있다."}
{"patent_id": "10-2020-0122809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상에서 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시 될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 부호의 설명100 : 인공지능 라이브러리 프록시 생성기 110 : 인공지능 라이브러리 프록시 클라이언트 120 : 인공지능 라이브러리 프록시 서버 130 : 도커 파일 140 : 도커 이미지"}
{"patent_id": "10-2020-0122809", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예가 적용되는 ROS를 활용한 분산 시스템의 개략적인 블록 구성도이다. 도 2는 도커화된 인공지능 라이브러리와 ROS를 이용한 구성된 분산 환경의 개략적인 블록도이다. 도 3 내지 도 5는 실시예에 따른 도커화된 인공지능 라이브러리에 대한 프록시 생성 방법을 설명하기 위한 도면 이다. 도 6은 도커 이미지의 예시도이다. 도 7은 신규 도커 이미지의 예시도이다. 도 8은 인공지능 라이브러리와의 RPC 기반 인터페이스를 위한 IDL 작성 예시도이다. 도 9는 인공지능 라이브러리와의 RPC 기반 인터페이스를 위한 IDL 작성 예시도이다. 도 10은 실시예에 따른 프록시 서버의 구동 코드 예시도이다. 도 11은 실시예에 따른 도커 파일의 예시도이다. 도 12는 도커화된 인공지능 라이브러리와 ROS를 이용한 분산 환경 구성의 일 실시예를 도시한 도면이다. 도 13은 도커화된 인공지능 라이브러리와 ROS를 이용한 분산 환경 구성의 다른 실시예를 도시한 도면이다. 도 14는 도커화된 인공지능 라이브러리와 ROS를 이용한 분산 환경 구성의 또 다른 실시예를 도시한 도면이다. 도 15는 실시예에 따른 컴퓨터 시스템 구성을 나타낸 도면이다."}
