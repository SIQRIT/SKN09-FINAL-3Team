{"patent_id": "10-2024-7025685", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0152306", "출원번호": "10-2024-7025685", "발명의 명칭": "멀티프로세서 컴퓨팅 디바이스에서 머신 러닝 동작들을 실행하기 위한 적응적 스케줄링", "출원인": "퀄컴 인코포레이티드", "발명자": "장, 난"}}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "다수의 프로세싱 유닛들을 갖는 컴퓨팅 디바이스 상에서 구현되는 방법으로서,상기 컴퓨팅 디바이스의 제1 프로세싱 유닛 상에서의 머신 러닝 모델의 제1 부분에서의 동작들의 실행 동안, 상기 컴퓨팅 디바이스 상의 복수의 위치들의 각각에 대해 온도를 측정하는 단계;상기 제1 프로세싱 유닛에 대해 측정된 온도가 임계 온도를 초과한다고 결정하는 단계;상기 컴퓨팅 디바이스에 대한 하나 이상의 동작 파라미터들에 기초하여, 상기 머신 러닝 모델의 제2 부분에서동작들을 실행하는데 사용할 상기 컴퓨팅 디바이스의 제2 프로세싱 유닛을 선택하는 단계; 및상기 제2 프로세싱 유닛 상에서의 상기 머신 러닝 모델의 상기 제2 부분에서의 동작들의 실행을 스케줄링하는단계를 포함하는, 방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 머신 러닝 모델의 상기 제1 부분 및 상기 머신 러닝 모델의 상기 제2 부분은 프로세싱 유닛들의 동일한 세트 상에서의 실행을 위해 구성된 뉴럴 네트워크의 계층들을 포함하는, 방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 머신 러닝 모델의 상기 제1 부분은 상기 컴퓨팅 디바이스의 프로세싱 유닛들의 제1 세트상에서의 실행을 위해 구성된 계층들의 제1 세트의 구성원이고, 상기 머신 러닝 모델의 상기 제2 부분은 상기컴퓨팅 디바이스의 프로세싱 유닛들의 제2 세트 상에서의 실행을 위해 구성된 계층들의 제2 세트의 구성원인,방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 계층들의 제1 세트는 양자화 파라미터들의 제1 세트로 구성된 계층들의 세트를 포함하는,방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 계층들의 제2 세트는 양자화 파라미터들의 제2 세트로 구성된 계층들의 세트를 포함하고,상기 양자화 파라미터들의 제2 세트는 상기 양자화 파라미터들의 제1 세트보다 더 작은 데이터 유형에 대한 양자화에 대응하는, 방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서, 상기 프로세싱 유닛들의 제1 세트는 뉴럴 프로세싱 유닛(NPU), 디지털 신호 프로세서(DSP), 및복수의 중앙 프로세싱 유닛(CPU) 코어들을 포함하는, 방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 프로세싱 유닛들의 제2 세트는 상기 복수의 CPU 코어들 및 복수의 그래픽 프로세싱 유닛(GPU) 프로세서들을 포함하는, 방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 제2 프로세싱 유닛을 선택하는 단계는 상기 머신 러닝 모델의 상기 제2 부분에서 동작들을 실행하기 위한 프로세싱 유닛들의 유형들의 랭킹에 추가로 기초하는, 방법.공개특허 10-2024-0152306-3-청구항 9 제8항에 있어서, 상기 프로세싱 유닛들의 유형들의 랭킹은 상기 머신 러닝 모델의 상기 제2 부분을 이용하여 처리되는 데이터의 크기 및 상기 컴퓨팅 디바이스 내의 프로세싱 유닛의 각각의 유형과 연관된 성능의 레벨에 기초하는, 방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 하나 이상의 동작 파라미터들은 하나 이상의 프로세싱 유닛들과 상기 제1 프로세싱 유닛사이의 거리, 상기 하나 이상의 프로세싱 유닛들의 온도, 또는 상기 하나 이상의 프로세싱 유닛들 상의 현재 부하 중 하나 이상을 포함하는, 방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 제2 프로세싱 유닛을 선택하는 단계는 임계 온도 미만의 측정된 온도를 갖는 상기 제1프로세싱 유닛으로부터 가장 먼 거리에 있는 프로세싱 유닛을 선택하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 제2 프로세싱 유닛을 선택하는 단계는:거리 임계치를 초과하는 상기 제1 프로세싱 유닛으로부터의 거리들 및 임계 온도 미만의 측정된 온도들을 갖는프로세싱 유닛들의 세트를 식별하는 단계; 및상기 프로세싱 유닛들의 식별된 세트로부터 상기 제2 프로세싱 유닛을 선택하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 프로세싱 유닛들의 세트를 식별하는 단계는 임계 부하 미만의 현재 부하를 갖는 프로세싱 유닛들을 식별하는 단계를 추가로 포함하는, 방법."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "프로세싱 시스템으로서,컴퓨터-실행가능 명령어(computer-executable instruction)들을 포함하는 메모리; 및하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은 상기 컴퓨터-실행가능 명령어들을 실행하고 상기 프로세싱 시스템으로 하여금:컴퓨팅 디바이스의 제1 프로세싱 유닛 상에서의 머신 러닝 모델의 제1 부분에서의 동작들의 실행 동안, 상기 컴퓨팅 디바이스 상의 복수의 위치들의 각각에 대해 온도를 측정하고;상기 제1 프로세싱 유닛에 대해 측정된 온도가 임계 온도를 초과한다고 결정하고;상기 컴퓨팅 디바이스에 대한 하나 이상의 동작 파라미터들에 기초하여, 상기 머신 러닝 모델의 제2 부분에서동작들을 실행하는데 사용할 상기 컴퓨팅 디바이스의 제2 프로세싱 유닛을 선택하고;상기 제2 프로세싱 유닛 상에서의 상기 머신 러닝 모델의 상기 제2 부분에서의 동작들의 실행을 스케줄링하게하는, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 머신 러닝 모델의 상기 제1 부분 및 상기 머신 러닝 모델의 상기 제2 부분은 프로세싱유닛들의 동일한 세트 상에서의 실행을 위해 구성된 뉴럴 네트워크의 계층들을 포함하는, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 머신 러닝 모델의 상기 제1 부분은 상기 컴퓨팅 디바이스의 프로세싱 유닛들의 제1 세트상에서의 실행을 위해 구성된 계층들의 제1 세트의 구성원이고, 상기 머신 러닝 모델의 상기 제2 부분은 상기컴퓨팅 디바이스의 프로세싱 유닛들의 제2 세트 상에서의 실행을 위해 구성된 계층들의 제2 세트의 구성원인,공개특허 10-2024-0152306-4-프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 계층들의 제1 세트는 양자화 파라미터들의 제1 세트로 구성된 계층들의 세트를포함하는, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 계층들의 제2 세트는 양자화 파라미터들의 제2 세트로 구성된 계층들의 세트를 포함하고,상기 양자화 파라미터들의 제2 세트는 상기 양자화 파라미터들의 제1 세트보다 더 작은 데이터 유형에 대한 양자화에 대응하는, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서, 상기 프로세싱 유닛들의 제1 세트는 뉴럴 프로세싱 유닛(NPU), 디지털 신호 프로세서(DSP),및 복수의 중앙 프로세싱 유닛(CPU) 코어들을 포함하는, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 프로세싱 유닛들의 제2 세트는 상기 복수의 CPU 코어들 및 복수의 그래픽 프로세싱 유닛(GPU) 프로세서들을 포함하는, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제14항에 있어서, 상기 프로세서는 상기 머신 러닝 모델의 상기 제2 부분 내에서 동작들을 실행하기 위하여 프로세싱 유닛들의 유형들의 랭킹에 추가로 기초하여 상기 제2 프로세싱 유닛을 선택하도록 구성된, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서, 상기 프로세싱 유닛들의 유형들의 랭킹은 상기 머신 러닝 모델의 상기 제2 부분을 이용하여처리되는 데이터의 크기 및 상기 컴퓨팅 디바이스 내의 프로세싱 유닛의 각각의 유형과 연관된 성능의 레벨에기초하는, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제14항에 있어서, 상기 하나 이상의 동작 파라미터들은 하나 이상의 프로세싱 유닛들과 상기 제1 프로세싱 유닛사이의 거리, 상기 하나 이상의 프로세싱 유닛들의 온도, 또는 상기 하나 이상의 프로세싱 유닛들 상의 현재 부하 중 하나 이상을 포함하는, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 제2 프로세싱 유닛을 선택하기 위하여, 상기 프로세서는 임계 온도 미만의 측정된 온도를 갖는 상기 제1 프로세싱 유닛으로부터 가장 먼 거리에 있는 프로세싱 유닛을 선택하도록 구성된, 프로세싱시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제23항에 있어서, 상기 제2 프로세싱 유닛을 선택하기 위하여, 상기 프로세서는:거리 임계치를 초과하는 상기 제1 프로세싱 유닛으로부터의 거리들 및 임계 온도 미만의 측정된 온도들을 갖는프로세싱 유닛들의 세트를 식별하고;상기 프로세싱 유닛들의 식별된 세트로부터 상기 제2 프로세싱 유닛을 선택하도록 구성된, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제25항에 있어서, 상기 프로세싱 유닛들의 세트를 식별하기 위하여, 상기 프로세싱 시스템은 임계 부하 미만의공개특허 10-2024-0152306-5-현재 부하를 갖는 프로세싱 유닛들을 식별하도록 추가로 구성된, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "프로세싱 시스템으로서,컴퓨팅 디바이스의 제1 프로세싱 유닛 상에서의 머신 러닝 모델의 제1 부분에서의 동작들의 실행 동안, 상기 컴퓨팅 디바이스 상의 복수의 위치들의 각각에 대해 온도를 측정하기 위한 수단;상기 제1 프로세싱 유닛에 대해 측정된 온도가 임계 온도를 초과한다고 결정하기 위한 수단;상기 컴퓨팅 디바이스에 대한 하나 이상의 동작 파라미터들에 기초하여, 상기 머신 러닝 모델의 제2 부분에서동작들을 실행하는데 사용할 상기 컴퓨팅 디바이스의 제2 프로세싱 유닛을 선택하기 위한 수단; 및상기 제2 프로세싱 유닛 상에서의 상기 머신 러닝 모델의 상기 제2 부분에서의 동작들의 실행을 스케줄링하기위한 수단을 포함하는, 프로세싱 시스템."}
{"patent_id": "10-2024-7025685", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "컴퓨터-실행가능 명령어들을 포함하는 비일시적 컴퓨터-판독가능한 저장 매체로서, 상기 컴퓨터-실행가능 명령어들은 프로세싱 시스템의 하나 이상의 프로세서들에 의해 실행될 때, 상기 프로세싱 시스템으로 하여금 방법을수행하게 하고, 상기 방법은,컴퓨팅 디바이스의 제1 프로세싱 유닛 상에서의 머신 러닝 모델의 제1 부분에서의 동작들의 실행 동안, 상기 컴퓨팅 디바이스 상의 복수의 위치들의 각각에 대해 온도를 측정하는 단계;상기 제1 프로세싱 유닛에 대해 측정된 온도가 임계 온도를 초과한다고 결정하는 단계;상기 컴퓨팅 디바이스에 대한 하나 이상의 동작 파라미터들에 기초하여, 상기 머신 러닝 모델의 제2 부분에서동작들을 실행하는데 사용할 상기 컴퓨팅 디바이스의 제2 프로세싱 유닛을 선택하는 단계; 및상기 제2 프로세싱 유닛 상에서의 상기 머신 러닝 모델의 상기 제2 부분에서의 동작들의 실행을 스케줄링하는단계를 포함하는, 비일시적 컴퓨터-판독가능한 저장 매체."}
{"patent_id": "10-2024-7025685", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시내용의 특정 양태들은 멀티프로세서 컴퓨팅 디바이스 상의 머신 러닝 모델 동작들의 스케줄링 실행을 위 한 기술들 및 장치를 제공한다. 방법은 일반적으로 컴퓨팅 디바이스의 제1 프로세싱 유닛 상에서의 머신 러닝 모델의 제1 부분에서의 동작들의 실행 동안, 컴퓨팅 디바이스 상의 복수의 위치들의 각각에 대해 온도를 측정하 는 단계를 포함한다. 제1 프로세싱 유닛에 대해 측정된 온도가 임계 온도를 초과한다고 결정된다. 컴퓨팅 디바 이스에 대한 하나 이상의 동작 파라미터들에 기초하여, 컴퓨팅 디바이스의 제2 프로세싱 유닛은 머신 러닝 모델 의 제2 부분에서 동작들을 실행 시 사용하도록 선택된다. 제2 프로세싱 유닛 상의 머신 러닝 모델의 제2 부분 내의 동작들의 실행이 스케줄링된다."}
{"patent_id": "10-2024-7025685", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 개시내용의 양태들은 머신 러닝에 관한 것으로, 더 구체적으로는, 다수의 프로세서들을 갖는 컴퓨팅 디바이 스 상의 머신 러닝 모델의 부분들의 스케줄링 실행에 관한 것이다. 스마트폰, 태블릿 컴퓨터 등과 같은 다양한 컴퓨팅 시스템들에서, 다수의 프로세서들은 뉴럴 네트워크의 상이한 부분들(예컨대, 상이한 계층들, 계층들의 그룹들, 네트워크 브랜치들, 서브네트워크들 등) 또는 다른 머신 러닝 모델을 처리하는 것과 같은 다양한 컴퓨팅 태스크들을 수행하는데 사용될 수 있다. 이러한 프로세서들은 상이 한 성능, 전력 사용, 및 열 특성들을 가질 수 있다. 예를 들어, 하나 이상의 중앙 프로세싱 유닛(CPU) 코어들, 하나 이상의 그래픽 프로세싱 유닛들(GPU들), 뉴럴 프로세싱 유닛(NPU), 하나 이상의 디지털 신호 프로세서들 (DSP들) 등을 포함하는 컴퓨팅 디바이스에서, 이러한 프로세서들의 각각은 특정 유형들의 태스크들에 적합(예컨 대, 특히 최적화)할 수 있고, 부하가 걸릴 때 상이한 양들의 열을 생성할 수 있다. 예를 들어, CPU 코어는 GPU 들, NPU들, 또는 DSP들과 같은 더 전문화된 프로세싱 유닛들에 대한 특정 태스크에 대해 더 낮은 성능을 제공할 수 있고, 더 많은 전력을 사용하고 그럼으로써 부하 시 더 많은 열을 발생시킬 수 있다. 반대로, 더 전문화된 프로세싱 유닛은 동일한 태스크를 수행하는 전문화된 프로세싱 유닛들보다 더 나은 성능을 제공하면서 전력을 덜 소비하고 열을 덜 발생시킬 수 있다. 컴퓨팅 디바이스 내의 프로세싱 유닛들은 일반적으로 이러한 프로세싱 유닛들 및 컴퓨팅 디바이스 내의 다른 컴 포넌트들에 대한 하한 및 상한 동작 온도들에 의해 정의되는 써멀 윈도우(thermal window)(예컨대, 컴퓨팅 디바 이스가 사용자에게 화상을 입히지 않고 사용자에 의해 유지될 수 있도록 하는 모바일 디바이스에 대한 케이스 온도, 배터리 수명에 대한 열 폭주 또는 열의 다른 부정적인 영향 등의 가능성을 최소화하도록 하는 배터리 온 도) 내에서 동작한다. 프로세싱 유닛이 열 상한까지 다양한 임계 온도들에 접근함에 따라, 이러한 프로세싱 유 닛들에 의해 생성된 열의 양을 감소시키기 위해 다양한 조치들이 취해질 수 있다. 예를 들어, 프로세서에 대한코어 전압이 감소되어, 프로세싱 유닛이 동작하는 클록 속도를 낮출 수 있다. 프로세싱 유닛이 동작하는 클록 속도를 감소시키는 것이 열 발생을 감소시킬 수 있지만, 그렇게 하는 것은 또한 시스템 성능을 감소시킬 수 있 다. 따라서, 필요한 것은 머신 러닝 동작들을 실행하는 컴퓨팅 시스템들의 열 관리를 위한 기술 개선이다. 특정 양태들은 멀티프로세서 컴퓨팅 디바이스 상의 머신 러닝 모델 동작들의 스케줄링 실행을 위한 컴퓨터 구현 방법을 제공한다. 방법은 일반적으로 컴퓨팅 디바이스의 제1 프로세싱 유닛 상에서의 머신 러닝 모델의 제1 부 분에서의 동작들의 실행 동안, 컴퓨팅 디바이스 상의 복수의 위치들의 각각에 대해 온도를 측정하는 단계를 포 함한다. 제1 프로세싱 유닛에 대해 측정된 온도가 임계 온도를 초과한다고 결정된다. 컴퓨팅 디바이스에 대한 하나 이상의 동작 파라미터들에 기초하여, 컴퓨팅 디바이스의 제2 프로세싱 유닛은 머신 러닝 모델의 제2 부분 에서 동작들을 실행 시 사용하도록 선택된다. 제2 프로세싱 유닛 상의 머신 러닝 모델의 제2 부분 내의 동작들 의 실행이 스케줄링된다. 다른 양태들은 전술한 방법들뿐만 아니라 본원에서 설명된 것들을 수행하도록 구성된 프로세싱 시스템들; 프로 세싱 시스템의 하나 이상의 프로세서들에 의해 실행될 때, 프로세싱 시스템으로 하여금, 전술한 방법들뿐만 아 니라 본원에서 설명된 것들을 수행하게 하는 명령들을 포함하는 비일시적 컴퓨터-판독 가능 매체들; 전술된 방 법들뿐만 아니라 본원에서 추가로 설명된 것들을 수행하기 위한 코드를 포함하는 컴퓨터-판독 가능 저장 매체에 서 구현된 컴퓨터 프로그램 제품; 및 전술된 방법들뿐만 아니라 본원에서 추가로 설명된 것들을 수행하는 수단 을 포함하는 프로세싱 시스템을 제공한다. 하기 설명 및 관련된 도면들은 하나 이상의 실시형태들의 특정한 예시적인 특징들을 상세히 기술한다."}
{"patent_id": "10-2024-7025685", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시내용의 양태들은 멀티프로세서 컴퓨팅 디바이스 상의 뉴럴 네트워크에서의 동작들의 적응적 스케줄링 실 행을 위한 기술들을 제공한다. 머신 러닝 모델들, 예컨대, 컨볼루션 뉴럴 네트워크, 순환 뉴럴 네트워크 등이 다양한 태스크들에 사용될 수 있 다. 예를 들어, 뉴럴 네트워크는 (예컨대, 프레임들이 디스플레이될 디스플레이의 리프레시 레이트에 대응하는) 더 높은 프레임 레이트에서 프레임들이 생성되도록 하는 시간적 보간을 위해 이미지의 해상도를 조정 (예컨대, 초해상도 기술들을 이용하여 입력 이미지의 해상도를 증가)하고, 이미지의 외관을 조정(예컨대, 이미 지 융합을 통해, HDR(high dynamic range) 형상화를 생성하는 것과 같은 다양한 색상 효과들을 적용, 배경 또는 전경 블러링(또한 \"보케(bokeh)\"로 알려짐)을 도입 등)하는 데 인공지능 기술들을 사용하는 공간적 스케일링에 사용될 수 있다. 다양한 시나리오들에서, 예컨대 비디오 재생, 게임 플레이 등에서, 이러한 동작들은 실시간으로 또는 거의 실시간으로 수행될 수 있고, 따라서, 상당한 양의 프로세싱 전력이 이러한 태스크들을 수행하는데 전용될 수 있다. 실시간 또는 거의 실시간으로 뉴럴 네트워크들을 이용하여 이러한 다양한 연산 태스크들을 수행하는 것이 연산 적으로 비용이 많이 드는 태스크일 수 있기 때문에, 이러한 태스크들이 실행되는 프로세서들은 이러한 태스크들 에 충분한 양의 연산 리소스들을 전용하기 위하여 상당한 양의 전력을 소모할 수 있다. 그러나, 컴퓨팅 디바이 스 내의 다양한 컴포넌트들 및 회로들의 저항 속성들로 인해, 전류 소모의 증가는 컴퓨팅 디바이스의 다양한 컴 포넌트들에 대한 동작 온도의 대응하는 증가를 초래할 수 있다. 일부 경우들에서, 뉴럴 네트워크를 이용하는 동작들의 계속적인 실행은 컴퓨팅 디바이스 내의 컴포넌트들로 하여금 컴퓨팅 디바이스의 안전하고 신뢰성있는 동작을 위해 정의된 하나 이상의 열적 한계들(예컨대, 프로세서가 손상되기 전에 프로세서에 대해 정의된 최대 온도, 열 폭주(thermal runaway) 또는 기타 파괴적 사건들을 회피하기 위해 배터리에 대해 정의된 최대 온도, 사용자가 화상입는 것을 방지하기 위하여 컴퓨팅 디바이스의 케이스에 대해 정의된 최대 온도 등)에 도달하게 할 수 있다. 이러한 열적 한계들에 도달하면, 컴퓨팅 디바이스를 그것의 정의된 열적 한계들 내에 유지하도록 다양한 조치들이 취해질 수 있다. 예를 들어, 이러한 프로세서들이 동작하는 클록 속도, 및 이러한 프로세서들 에 대응하는 전류 소모가 감소될 수 있다. 그러나, 클록 속도의 감소는 동작들을 실행하는데 필요한 시간의 양 을 증가시킬 수 있다. 비디오 프로세싱, 인-게임 이미지 렌더링 등과 같은 실시간 또는 거의 실시간으로 수행 될 태스크들의 경우, 이는 동작에 \"끊김\" 현상을 발생시킬 수 있다. 예를 들어, 비디오 프로세싱 애플리케이션 에서, 프레임들은 누락될 수 있고, 이는 생성된 비디오가 매끄럽지 않게 보이게 할 수 있다. 예시적인 컴퓨팅 디바이스 아키텍처 도 1은 뉴럴 네트워크에서의 동작들이 수행될 수 있는 복수의 프로세서들을 포함하는 예시적인 컴퓨팅 디바이스 를 도시한다. 도시된 바와 같이,컴퓨팅 디바이스는 복수의 중앙 프로세싱 유닛(CPU) 코어들, 복수의 중앙 프로세싱 유닛(CPU) 코어들, 그래픽 프로세싱 유닛(GPU), 복수의 디지털 신호 프로세서 들(DSP들), 뉴럴 프로세싱 유닛(NPU), CPU 코어들, CPU 코어들, GPU, DSP들, 및 NPU에 의해 액세스가능한 메모리, 및 복수의 온도 센서들을 포함한다. 복수의 CPU 코어들 및 복수의 CPU 코어들은, 일부 양태들에서, CPU 코어들이 \"성능\" 코어들로 지정되고 CPU 코어들이 \"효율\" 코어들로 지정되는 이종 CPU 아키텍처(예컨대 ARM(Advanced RISC Machine) 프로세서 내의 big.LITTLE 아키텍처)의 일부일 수 있다. CPU 코어들은 CPU 코어들에 대해 추가적인 프로세싱 능력들을 제공할 수 있지만, 이러한 추가적인 프로세싱 능력들을 제공하기 위하여 더 많은 전력을 소 모할 수 있다. 대조적으로, CPU 코어들은 CPU 코어들보다 더 적은 전력을 이용하여 연산적으로 덜 복잡한 컴퓨팅 태스크들의 완료를 허용하는 전력 효율적인 코어들일 수 있다. 따라서 다양한 동작 파라미터들 은 CPU 코어들 및 CPU 코어들에 걸쳐 태스크들의 실행을 스케줄링하여 CPU 코어들의 프로세싱 능력들 및 CPU 코어들의 전력 효율성을 레버리지하는데 사용될 수 있다. 예를 들어, 복잡한 연산 태스크 들, 예컨대, 큰 수 또는 부동소수점 데이터 유형들을 수반하는 태스크들은 CPU 코어들 상에서의 실행을 위 해 스케줄링될 수 있고, 작은 수 또는 정수 데이터 유형들을 수반하는 태스크들은 CPU 코어들 상에서의 실 행을 위해 스케줄링될 수 있는데, 그 이유는 작은 수 또는 정수 데이터 유형들을 수반하는 태스크들은 CPU 코어 들의 추가적인 프로세싱 특성들을 레버리지할 필요가 없을 수 있기 때문이다. GPU는 일반적으로 다양한 동작들의 병렬 실행을 허용할 수 있는 복수의 유닛들을 포함하는 프로세싱 유닛 일 수 있다. 일부 양태들에서, GPU는 컴퓨팅 디바이스와 연결되거나 또는 이에 일체화된 디스플레이 디바이스 상에서의 디스플레이를 위해 그래픽을 생성하는데 사용될 수 있는 벡터 수학 동작들 및 다른 복잡한 수학적 동작들을 실행하도록 구성될 수 있다. GPU는 벡터 수학 동작들과 같은 복잡한 태스크들에 대한 병 렬 처리를 지원할 수 있기 때문에, GPU는 또한 CPU 코어들 또는 CPU 코어들의 성능 레벨보다 더 높은 성능 레벨을 갖는 뉴럴 네트워크에서 다양한 태스크들을 수행하는데 사용될 수 있다. DSP들은 처리된 신호 출력을 생성하기 위해 다양한 데이터 입력들 상에서 신호 처리를 수행할 수 있다. 일부 양태들에서, 이러한 DSP들은 컴퓨팅 디바이스와 연결되거나 또는 이와 일체형인 다양한 이미지 캡처, 사운드 캡처, 또는 기타 데이터 캡처 디바이스들과 연관될 수 있다. 예를 들어, DSP(140A)는 모바일 디바이스 의 제1 카메라(예컨대, 광각 카메라)와 연관될 수 있고, DSP(140B)는 모바일 디바이스의 제2 카메라(예컨대, \" 정상\" 시야, 또는 인간의 시야에 근접한 시야를 갖는 카메라)와 연관될 수 있고, DSP(140C)는 모바일 디바이스 의 비디오 카메라 등과 연관될 수 있다.NPU는 일반적으로 다양한 머신 러닝 알고리즘들을 수반하는 동작들을 실행하는 특수 프로세싱 유닛일 수 있다. 일반적으로, NPU는 뉴럴 네트워크 내에서 다양한 예측 태스크들, 컨볼루션 태스크들, 서브샘플링 태스크들 등을 수행할 수 있다. 예를 들어, NPU는 고차원 텐서들로서 병렬로 구조화된 데이터를 처리하도 록 설계될 수 있고, 뉴럴 네트워크 내의 데이터 재사용을 허용하기에 충분한 크기의 버퍼를 포함할 수 있다. NPU는 뉴럴 네트워크 내의 태스크들의 실행에 맞춤화된 특수 프로세싱 유닛이기 때문에, CPU 코어들 및/또는 CPU 코어들 상에서 실행될 수 있는 일반적 태스크들은 NPU 상에서 스케줄링되지 않을 수 있 다. 컴퓨팅 디바이스 상에서의 다양한 동작들의 실행 동안, 스케줄러는 온도 센서들을 통해 CPU 코 어들, CPU 코어들, GPU, DSP들, 및 NPU의 각각에 대해 주기적으로 또는 비주기적으 로 동작 온도들을 측정할 수 있다. 도시된 바와 같이, 다양한 수의 온도 센서들이 컴퓨팅 디바이스 내의 각각의 프로세싱 유닛 상에서 구현될 수 있다. 예를 들어, CPU 코어들의 각각(예컨대, \"성능\" 코어들)은 2개의 온도 센서들을 포함할 수 있는 반면, CPU 코어들의 각각(예컨대, \"효율\" 코어들)은 단일 온도 센서를 포함할 수 있다. 컴퓨팅 디바이스의 다른 컴포넌트들의 동작 온도를 측정하기 위해, 도시되지 않 았지만, 추가적인 온도 센서들이 또한 컴퓨팅 디바이스 내에 구현될 수 있다. 논의된 바와 같이, 컴퓨팅 디바이스 내의 프로세싱 유닛들(및 다른 컴포넌트들)의 각각은 동작 온도 상한 을 정의하였을 수 있다. 일반적으로, 프로세싱 유닛은 프로세싱 유닛에 대해 정의된 동작 온도 상한을 초과하 여 동작하도록 허용되지 않을 수 있는데, 그 이유는 정의된 동작 온도 상한을 초과하는 것은 프로세싱 유닛 또 는 컴퓨팅 디바이스 내의 다른 컴포넌트들에 손상을 야기할 수 있기 때문이다. 통상적으로, 프로세싱 유 닛이 정의된 동작 온도 상한을 초과하는 것을 방지하기 위하여, 다양한 전력 제어 기술들이 프로세싱 유닛의 클 록 속도(또는 명령어들이 실행되는 레이트)를 낮추고, 따라서, 프로세싱 유닛에 의해 생성되는 열의 양을 감소 시키는데 사용될 수 있다. 그러나, 프로세싱 유닛의 클록 속도를 감소시키는 것은 프로세싱 유닛 상에서 실행 되고 있는 동작들에 부정적인 영향을 줄 수 있다. 머신 러닝 동작들이 (예컨대, 뉴럴 네트워크를 통해) 적응적으로 컴퓨팅 디바이스 상에서 실행되도록 하기 위해, 온도 측정들, 컴퓨팅 디바이스 상의 상이한 프로세싱 유닛들 사이의 공지된 거리들, 및 다른 동작 파라미터들이 머신 러닝 동작들의 실행을 스케줄링하는데 사용될 수 있다. 일반적으로, 컴퓨팅 디바이스 내의 프로세싱 유닛들의 레이아웃은 공지되어 있고 특정 컴퓨팅 디바이스의 특정 설계에 대해 고정되어 있 기 때문에, 그리고 열은 거리의 함수로써 발산된다고 가정할 수 있기 때문에, 스케줄러는 현재 뉴럴 네트 워크 동작들을 실행하고 있는 프로세싱 유닛으로부터 더 멀리 있는 프로세싱 유닛들이 현재 머신 러닝 동작들을 실행하고 있는 프로세싱 유닛에 더 가까운 프로세싱 유닛들보다 뉴럴 네트워크 동작들의 향후 실행에 사용하는 데 더 적합할 수 있다고 가정할 수 있다. 따라서, 효과적으로, 스케줄러는 현재 머신 러닝 동작들을 실행 하고 있는 현재 프로세싱 유닛보다 온도가 낮은 프로세싱 유닛들로 실행을 이동시키면서 원하는 레벨의 성능으 로 머신 러닝 동작들을 실행하기 위하여 필요한 프로세싱 능력들을 유지할 수 있다(예컨대, 프레임들 사이의 전 환이 매끄럽게 보이도록 정의된 리프레시 레이트에 따른 비디오 또는 스트리밍 콘텐츠 내의 프레임들의 생성). 예를 들어, 머신 러닝 동작들이 그러한 우선순위대로 NPU, GPU, 및 CPU 코어들 상에서의 실행을 위해 구성될 수 있다고 가정한다. 따라서, NPU, GPU, 및 CPU 코어들의 각각은 유휴 상태이고 열 임계치(예컨대, 열 상한) 미만이라고 가정하면, 머신 러닝 동작들은 초기에 NPU에 의해 실행을 위해 스 케줄링될수 있다. 하나 이상의 온도 센서들(170R 내지 170T)이 NPU의 온도가 열 임계치에 근접하거나 또는 열 임계치에 있다고 나타내는 경우, 스케줄러는 머신 러닝 동작들의 후속 실행이 GPU 또는 하나 이상 의 CPU 코어들로 이동되어야 한다고 결정할 수 있다. 이 때, GPU 및 CPU 코어들이 이러한 프로 세싱 유닛들에 대해 정의된 열 상한 미만인 온도들을 측정했다고 가정하면, 스케줄러는 GPU 또는 CPU 코어들 중 어느 것을 머신 러닝 동작들의 후속 실행에 사용할지 식별할 때 NPU로부터의 거리 및 다른 동작 파라미터들을 고려할 수 있다. 이 예에서, GPU가 CPU 코어들보다 NPU에 더 가깝기 때문에, 스케줄러는 머신 러닝 동작들의 후속 실행에 사용하기 위하여 GPU를 CPU 코어들보다 덜 적합한 후보로 간주할 수 있다. 따라서, 스케줄러는 하나 이상의 CPU 코어들에 대해 머신 러닝 동작 들의 후속 실행을 스케줄링할 수 있다. 일부 양태들에서, 거리 메트릭들은 프로세싱 유닛 단위 기준으로 계산 될 수 있다. 이러한 경우에, CPU 코어(110A)는 NPU로부터 가장 먼 거리에 있는 프로세싱 유닛이기 때문에, CPU 코어(110A)는 컴퓨팅 디바이스 상에서 머신 러닝 동작들의 후속 실행에 사용할 프로세싱 유닛 으로서 선택될 수 있다.다른 동작 파라미터들이 대안적으로 또는 추가적으로 어느 프로세싱 유닛들을 컴퓨팅 디바이스 상의 머신 러닝 동작들의 후속 실행에 사용할지 결정하는데 사용될 수 있다. 예를 들어, 특정 프로세싱 유닛이 머신 러닝 동작들의 후속 실행에 사용할 후보인지 여부를 결정할 때 각각의 프로세싱 유닛 상의 현재 부하가 고려될 수 있 다. 프로세싱 유닛이 임계값을 초과하는 현재 부하를 갖는 경우, 프로세싱 유닛은 머신 러닝 동작들의 후속 실 행에 적합한 후보라고 간주되지 않을 수 있다. 이 임계값은 선험적으로 정의되거나 또는, 예를 들어, 각각의 프로세싱 유닛의 성능 특성들에 기초하여 각각의 프로세싱 유닛에 대해 구성될 수 있다. 더 강력한 프로세싱 유닛들(예컨대, 주어진 기간 동안 더 많은 수의 동작들을 수행할 수 있는 프로세싱 유닛들)은, 예를 들어, 덜 강력한 프로세싱 유닛들보다 더 높은 사용 임계치들을 가질 수 있는데, 그 이유는 더 강력한 프로세싱 유닛들이 덜 강력한 프로세싱 유닛들보다 다른 동작들을 수행하는데 사용하기 위해 전용될 수 있는 추가적인 리소스들을 가질 수 있기 때문이다. 다른 예에서, 각각의 프로세싱 유닛의 현재 온도는 프로세싱 유닛이 머신 러닝 동작들 의 후속 실행을 위한 후보인지 여부를 결정하는데 사용될 수 있다. 일반적으로, 머신 러닝 동작들은 연산 집약 적일 수 있고, 따라서 이러한 동작들이 실행되는 임의의 프로세싱 유닛의 온도를 증가시킬 가능성이 있기 때문 에, 그것들의 열 상한 또는 다른 정의된 열 임계치들에 더 가까운 온도를 갖는 프로세싱 유닛들은 그것들의 열 상한 또는 다른 열 임계치들로부터 더 멀리 있는 온도를 갖는 프로세싱 유닛들보다 머신 러닝 동작들의 후속 실 행에 사용하기에 덜 적합할 수 있다. 그러나, 현재 부하, 온도, 및 현재 머신 러닝 동작들을 실행하고 있는 프 로세싱 유닛으로부터의 거리는 후속 머신 러닝 동작들이 실행될 프로세싱 유닛들을 선택하는데 있어서 고려될 수 있는 동작 파라미터들의 예들일 뿐이고, 다른 동작 파라미터들이 본 명세서에 논의된 동작 파라미터들과 함 께 또는 그 대신에 사용될 수 있음이 이해될 것이다. 예시적인 뉴럴 네트워크 아키텍처 도 2는 본 개시내용의 양태들에 따라 뉴럴 네트워크 내의 계층들이 컴퓨팅 디바이스 내의 프로세싱 유닛들의 상 이한 세트들(예컨대, 도 1에 도시된 컴퓨팅 디바이스의 CPU 코어들, CPU 코어들, GPU, DSP들, 및 NPU 중 하나 이상) 상에서의 프로세싱을 위해 구성된 그룹들로 조직되는 뉴럴 네트워크 의 예시적인 아키텍처를 도시한다. 일반적으로, 뉴럴 네트워크는 복수의 계층들을 포함할 수 있고, 각각의 계층은 상이한 레벨의 복잡성을 가 질 수 있다. 예를 들어, 입력으로부터 특징부 맵들을 생성하는데 사용되는 입력에 가까운 계층들은 뉴럴 네트 워크 내의 가장 복잡한 계층들일 수 있고, 이전 계층들로부터 출력된 서브샘플링된 데이터 세트들 상에 동작들 을 수행하는 계층들은 덜 복잡할 수 있다. 뉴럴 네트워크 내의 동작들을 수행하는 것에 관련된 복잡성은 공지 되어 있거나, 또는 적어도 (예컨대, 뉴럴 네트워크에서의 파라미터 카운트, 노드 카운트, 입력 크기 등에 기초 하여) 추정되기 때문에, 뉴럴 네트워크가 입력을 표현하는 출력을 생성하는 것에 더 가까워짐에 따라 감소하기 위하여, 뉴럴 네트워크 내의 계층들은 복수의 그룹들로 그룹화될 수 있다. 각각의 그룹은 컴퓨팅 디바이스 내의 특정 프로세싱 유닛들 상에서의 실행을 위해 구성될 수 있고, 뉴럴 네트워크 내의 계층들의 그룹에 서의 동작들을 실행하기 위한 선호도가 또한 정의될 수 있다. 예를 들어, 도시된 바와 같이, 뉴럴 네트워크는 제1 그룹, 제2 그룹, 및 제3 그룹으로 그 룹화될 수 있다. 뉴럴 네트워크 내의 계층들의 제1 그룹은 선호하는 순서대로 DSP들, NPU, 및 CPU 코어들 및/또는 상에서의 실행을 위해 구성될 수 있다. 제1 그룹 내의 계층 들보다 연산적으로 덜 복잡하다고 간주될 수 있는, 뉴럴 네트워크 내의 계층들의 제2 그룹은 선호하 는 순서대로 DSP들, NPU, 및 GPU 상에서의 실행을 위해 구성될 수 있다. 마지막으로, 제2 그룹 내의 계층들보다 연산적으로 덜 복잡하다고 간주될 수 있는, 계층들의 제3 그룹은 선호하는 순서대 로 CPU 코어들 및/또는 및 GPU 상에서의 실행을 위해 구성될 수 있다. 일부 양태들에서, 뉴럴 네트워크 내의 상이한 계층들은 상이한 레벨들의 양자화, 또는 데이터가 생성될 수 있는 상이한 입도들을 이용한 실행을 위해 구성될 수 있다. 계층들의 상이한 그룹들이 구성될 수 있도록 하기 위해, 계층들의 그룹 내에 포함된 각각의 계층은 동일한 양자화 레벨을 이용하는 실행을 위해 트레이닝 또는 컴 파일링될 수 있다. 예를 들어, 계층들의 제1 그룹(논의된 바와 같이, 이는 가장 높은 연산 복잡성을 갖는 계층들의 그룹에 대응할 수 있음)은 32비트 부동소수점 숫자 공간(예컨대, -3.4*1038 내지 3.4*1038의 범위의 공 간) 내에서 양자화를 위해 트레이닝되거나 또는 컴파일링될 수 있다. 계층들의 제2 그룹(이는 계층들의 제1 그룹보다 연산 복잡성이 덜한 계층들의 그룹에 대응할 수 있음)은 연산적으로 덜 복잡한 데이터 유형, 예컨대 8비트 정수 공간(예컨대, 부호가 있는 경우 -128 내지 127, 또는 부호가 없는 경우 0 내지 255의 공간) 내의 양자화를 이용하는 실행을 위해 트레이닝 또는 컴파일링될 수 있다. 따라서 계층들의 제3 그룹은 연산적으로 훨씬 덜 복잡한 데이터 유형, 예컨대, 더 작은 정수 공간(예컨대, 6 비트, 4 비트 등) 내의 양자화를 이용하는 실행을 위해 트레이닝 또는 컴파일링될 수 있다. 일반적으로, 이러한 상이한 레벨들의 양자화는 후속 머신 러닝 동작들이 전송될 수 있는 프로세서들의 선택을 제한하는 제약이 될 수 있고/있거나 후속 머신 러닝 동작들을 스케줄링하기 위해 일부 프로세서들을 더 나은 타겟으로 만들 수 있다. 예를 들어, 뉴럴 네트워크 내 의 계층들이 부동소수점 양자화를 위해 컴파일링되고, 더 나은 부동소수점 프로세싱 능력들을 갖는 프로세서들 (예컨대, \"성능\" CPU 코어들, GPU들, NPU들 등)은 이러한 계층들에서 동작들을 수행하는데 적합할 수 있지만, 부동소수점 프로세싱 능력들이 부족하거나 또는 제한된 부동소수점 프로세싱 능력들을 갖는 프로세서들(예컨대, \"효율\" CPU 코어들 등)은 이러한 계층들에서 동작들을 수행하는데 적합하지 않을 수 있다. 도 2는 뉴럴 네트워크를 복수의 계층들의 그룹들로 분할하는 것을 도시하지만, 임의의 머신 러닝 모델은 유사한 그룹들로 조직화될 수 있고, 뉴럴 네트워크를 복수의 계층들의 그룹들로 분할하는 것은 머신 러닝 모델을 상이 한 프로세싱 유닛들의 그룹들 상에서의 실행을 위해 스케줄링될 수 있는 상이한 컴포넌트들의 그룹들로 분할하 는 하나의 예일 뿐이라는 것이 인식될 것이다. 멀티프로세서 컴퓨팅 디바이스에서의 머신 러닝 동작들의 적응적 스케줄링을 위한 예시적인 방법들 도 3은 본 개시내용의 양태들에 따른 도 1에 도시된 컴퓨팅 디바이스와 같은 멀티프로세서 컴퓨팅 디바이 스 상의 머신 러닝 모델 내의 동작들의 적응적 스케줄링 실행을 위해 수행될 수 있는 예시적인 동작들을 도시한다. 도시된 바와 같이, 동작들은 블록에서 시작될 수 있는데, 멀티프로세서 컴퓨팅 디바이스의 제1 프로 세서의 머신 러닝 모델의 제1 부분 내의 동작들의 실행 동안, 복수의 프로세싱 유닛들 중 각각의 프로세싱 유닛 에 대한 온도가 측정된다. 측정들은 하나 이상의 온도 센서들(예컨대, 도 1에 도시된 온도 센서들)에 질 의하거나 또는 다른 방식으로 폴링함으로써 획득될 수 있는데, 각각의 센서는 컴퓨팅 디바이스 내의 특정 프로 세싱 유닛 또는 다른 개별 컴포넌트와 연관된다. 일부 양태들에서, 프로세싱 유닛이 그와 연관된 다수의 온도 센서들을 갖는 경우, 다양한 기술들이 프로세싱 유닛의 온도를 결정하는데 사용될 수 있다. 예를 들어, 다수의 온도 센서들에 걸친 평균 온도가 프로세싱 유닛의 온도로서 사용될 수 있다. 다른 예에서, 다수의 온도 센서들 에 걸쳐 측정된 가장 높은 온도가 프로세싱 유닛의 온도로서 사용될 수 있다. 일부 양태들에서, 측정된 온도는 순간 온도 판독치에 대응할 수 있고; 다른 양태들에서, 측정된 온도는 가장 최근의 샘플들의 수에 걸친 이동 평 균일 수 있다. 블록에서, 동작들은 제1 프로세싱 유닛에 대해 측정된 온도가 임계 온도를 초과한다고 결정하는 것을 진행한다. 블록에서, 동작들은 머신 러닝 모델의 제2 부분에서 동작들을 실행하는데 사용할 컴퓨팅 디바이스의 제2 프로세싱 유닛을 선택하는 것을 진행한다. 일반적으로, 제2 프로세싱 유닛은 컴퓨팅 디바이스에 대한 하나 이상의 동작 파라미터들에 기초하여 선택될 수 있다. 이러한 동작 파라미터들은, 예를 들어, 제1 프로세싱 유 닛과 제2 프로세싱 유닛 사이의 거리, 제2 프로세싱 유닛 상의 현재 부하, 제2 프로세싱 유닛의 현재 온도 등을 포함할 수 있다. 제1 프로세싱 유닛과 제2 프로세싱 유닛 사이의 거리와 같은 정보는, 예를 들어, 구성 파일에 정의될 수 있다. 예를 들어, 구성 파일은 머신 러닝 동작들이 수행되는 컴퓨팅 디바이스의 물리적 레이아웃에 대응하고 컴퓨팅 디바이스 내의 각각의 프로세싱 유닛의 위치를 식별하는 정보를 포함할 수 있다. 일부 양태들 에서, 구성 파일은 이러한 프로세서들이 설치되는 특정 슬롯들을 식별하는 정보를 포함할 수 있고, 다양한 가정 들이 이 정보에 기초하여 이루어질 수 있다. 예를 들어, 프로세서들이 0부터 n까지 번호가 부여된 확장 슬롯들 (확장 슬롯 0이 CPU에 가장 가까움)에 설치된 컴퓨팅 시스템에서, 컴퓨팅 시스템 내의 각각의 프로세서 사이의 상대 거리들이 결정될 수 있고, 머신 러닝 모델의 제2 부분에서 동작들을 실행하는데 사용할 프로세서를 선택할 때 사용될 수 있다. 일부 양태들에서, 제1 프로세싱 유닛으로부터의 거리가 제2 프로세싱 유닛을 선택하는데 사용되는 동작 파라미 터들 중 하나인 경우, 제2 프로세싱 유닛은 제1 프로세싱 유닛으로부터 가장 멀리 있는 임계 온도 미만의 온도 (예컨대, 프로세싱 유닛에 대해 정의된 열 상한, 프로세싱 유닛에 대해 상이한 레벨들의 성능 등을 정의하는 복 수의 열 임계치들 중 하나)를 갖는 프로세싱 유닛으로서 선택될 수 있다. 일부 양태들에서, 제2 프로세싱 유닛은 뉴럴 네트워크의 제2 부분에서 동작들을 실행하는데 사용할 프로세싱 유 닛들의 유형들의 랭킹에 기초하여 추가로 선택될 수 있다. 이러한 랭킹들은, 예를 들어, 머신 러닝 모델의 제2 부분에서 처리되는 데이터의 크기(예컨대, 32비트 부동소수점, 8비트 정수 등과 같은, 머신 러닝 모델의 제2 부분에서 데이터를 처리하는데 사용되는 데이터 유형) 및 컴퓨팅 디바이스 내의 프로세싱 유닛의 각각의 유형과 연관된 성능의 레벨(예컨대, 컴퓨팅 디바이스의 프로세싱 유닛들에 의해 지원되는 초당 부동소수점 동작들의 수, 초당 정수 동작들의 수 등)에 기초할 수 있다. 일부 양태들에서, 제2 프로세싱 유닛은 거리 임계치를 초과하는 제1 프로세싱 유닛으로부터의 거리 및 임계 온 도 미만의 측정된 온도를 갖는 프로세싱 유닛들의 세트를 식별함으로써 선택될 수 있다. 거리 임계치는 (예컨 대, 컴퓨팅 디바이스의 공지된 아키텍처 레이아웃에 따른) 프로세싱 유닛들 사이의 절대 거리일 수 있거나 또는 컴퓨팅 디바이스 내의 프로세싱 유닛들 및 확장 슬롯들의 위치들을 정의하는 일반적인 규칙들에 기초하여 가정 된 거리일 수 있다. 제2 프로세싱 유닛은 프로세싱 유닛들의 식별된 세트로부터 선택될 수 있다. 예를 들어, 제2 프로세싱 유닛은 이러한 프로세싱 유닛들의 랭킹(위에서 논의된 바와 같음), 이러한 프로세싱 유닛들 상의 현재 부하 등에 따라 프로세싱 유닛들의 식별된 세트로부터 선택될 수 있다. 일부 양태들에서, 프로세싱 유닛 들의 식별된 세트는 임계 부하 미만의 현재 부하를 갖는 프로세싱 유닛들을 식별함으로써 추가로 식별될 수 있 다. 블록에서, 머신 러닝 모델의 제2 부분 내의 동작들의 실행은 제2 프로세싱 유닛 상에서의 실행을 위해 스 케줄링될 수 있다. 일부 양태들에서, 머신 러닝 모델의 제1 부분 및 머신 러닝 모델의 제2 부분은 프로세싱 유닛들의 동일한 세트 상에서의 실행을 위해 구성된 뉴럴 네트워크의 상이한 계층들일 수 있다. 예를 들어, 머신 러닝 모델의 제1 부 분 및 머신 러닝 모델 네트워크의 제2 부분은 둘 모두 동일한 유형의 프로세서 상에서 동일한 데이터 유형을 이 용하여 실행하도록 구성되는 뉴럴 네트워크의 계층들일 수 있다. 일부 양태들에서, 머신 러닝 모델의 제1 부분은 뉴럴 네트워크의 계층들의 제1 세트 내의 계층일 수 있고, 머신 러닝 모델의 제2 부분은 뉴럴 네트워크의 계층들의 제2 세트 내의 계층일 수 있다. 계층들의 제1 세트는 컴퓨 팅 디바이스의 프로세싱 유닛들의 제1 세트 상에서의 실행을 위해 구성될 수 있다. 계층들의 제2 세트는 컴퓨 팅 디바이스의 프로세싱 유닛들의 제2 세트 상에서의 실행을 위해 구성될 수 있다. 예를 들어, 도 2에 관련하 여 위에서 논의된 바와 같이, 뉴럴 네트워크의 계층들의 제1 세트 및 뉴럴 네트워크의 계층들의 제2 세트는 상 이한 레벨들의 연산 복잡성을 갖는 계층들의 세트들을 포함할 수 있다. 일반적으로, 연산 복잡성 정보, 예컨대 머신 러닝 모델의 상이한 부분들에 의해 사용되는 데이터 유형들(및 머신 러닝 모델의 이러한 상이한 부분들에 서의 동작들의 연산 복잡성에 관한 대응하는 가정들)은 (예컨대, 머신 러닝 모델에 수반되는 구성 정보를 통해) 미리 알려질 수 있고, 컴퓨팅 디바이스 상의 후속 머신 러닝 동작들을 스케줄링하는데 사용될 수 있다. 계층들 의 제1 세트는 양자화 파라미터들의 제1 세트로 구성될 수 있고, 계층들의 제2 세트는 양자화 파라미터들의 제2 세트로 구성될 수 있다. 예를 들어, 양자화 파라미터들의 제2 세트는 양자화 파라미터들의 제1 세트보다 더 작 은 데이터 유형에 대한 양자화에 대응할 수 있다. 예를 들어, 계층들의 제1 세트는 32비트 부동소수점 숫자를 이용하여 데이터를 처리하도록 구성된 뉴럴 네트워크 내의 계층들을 포함할 수 있고, 계층들의 제2 세트는 8비 트 정수를 이용하여 데이터를 처리하도록 구성된 뉴럴 네트워크 내의 계층들을 포함할 수 있다. 물론, 이는 단 지 예일 뿐이며, 계층들의 제1 및 제2 세트들은 다양한 데이터 유형들을 이용하여 데이터를 처리 및 양자화하도 록 구성될 수 있다는 것이 인식될 것이다. 일부 양태들에서, 프로세싱 유닛들의 제1 세트는 뉴럴 프로세싱 유닛(NPU), 디지털 신호 프로세서(DSP), 및 복 수의 중앙 프로세싱 유닛(CPU) 코어들을 포함할 수 있다. 한편, 프로세싱 유닛들의 제2 세트는 복수의 CPU 코 어들 및 복수의 그래픽 프로세싱 유닛(GPU) 프로세서들을 포함할 수 있다. 이러한 경우에, 뉴럴 네트워크의 제 1 부분이 하나 이상의 CPU 코어들 상에서 실행되고 있는 경우, 뉴럴 네트워크의 제2 부분은 그에 따라 GPU 프로 세서들을 이용하는 실행에 대해 스케줄링될 수 있는데, 그 이유는 CPU 코어들이 뉴럴 네트워크의 제1 부분이 실 행되는 CPU 코어들에 상대적으로 더 가깝게 위치되고, 따라서 CPU들은 제2 세트를 이용하는 동작들을 실행 시 사용하기에 적합한 후보 프로세싱 유닛들이 아닐 수 있다고 가정될 수 있기 때문이다. 멀티프로세서 컴퓨팅 디바이스에서의 머신 러닝 동작들의 적응적 스케줄링을 위한 예시적인 프로세싱 시스템 도 4는, 예를 들어 도 3에 관련하여 본 명세서에 기재된 바와 같이 멀티프로세서 컴퓨팅 디바이스 상에서의 뉴 럴 네트워크 내의 동작들의 실행을 적응적 스케줄링하기 위한 예시적인 프로세싱 시스템을 도시한다. 프로세싱 시스템은 일부 예들에서 멀티코어 CPU일 수 있는 중앙 프로세싱 유닛(CPU)을 포함한다. CPU에서 실행되는 명령어들은, 예를 들어, CPU와 연관된 프로그램 메모리로부터 로딩될 수 있거나 또 는 메모리 내의 파티션으로부터 로딩될 수 있다.프로세싱 시스템은 또한, 그래픽 프로세싱 유닛(GPU), 디지털 신호 프로세서(DSP), 뉴럴 프로세 싱 유닛(NPU), 멀티미디어 프로세싱 유닛, 및 무선 연결성 컴포넌트와 같은 특정 기능들에 맞춰 진 추가적인 프로세싱 컴포넌트들을 포함한다. 408과 같은 NPU는 일반적으로 기계 학습 알고리즘들, 이를테면 인공 뉴럴 네트워크(ANN)들, 심층 뉴럴 네트워크 (DNN)들, 랜덤 포레스트(RF)들 등을 처리하기 위한 알고리즘들을 실행하는 데 필요한 모든 제어 및 산술 로직을 구현하도록 구성된 특수 회로이다. NPU는 때때로 대안적으로 뉴럴 신호 프로세서(NSP: neural signal processor), 텐서 처리 장치(TPU: tensor processing unit)들, 뉴럴 네트워크 프로세서(NNP: neural network processor), 지능형 처리 장치(IPU: intelligence processing unit), 비전 처리 장치(VPU: vision processing unit) 또는 그래프 처리 장치로 지칭될 수 있다. 408과 같은 NPU들은 이미지 분류, 기계 번역, 객체 검출 및 다양한 다른 예측 모델들과 같은 일반적인 기계 학 습 태스크들의 성능을 가속화하도록 구성된다. 일부 예들에서, 복수의 NPU들은 SoC(system on chip)와 같은 단 일 칩에서 인스턴스화될 수 있는 한편, 다른 예들에서, 그들은 전용 뉴럴 네트워크 가속기의 일부일 수 있다. NPU들은 트레이닝 또는 추론에 최적화되거나, 일부 경우들에서는 둘 모두 간의 성능의 균형을 맞추도록 구성될 수 있다. 트레이닝 및 추론 둘 모두를 수행할 수 있는 NPU들의 경우, 두 태스크들은 여전히 일반적으로 독립적 으로 수행될 수 있다. 트레이닝을 가속화하도록 설계된 NPU들은 일반적으로, 새로운 모델들의 최적화를 가속화하도록 구성되고, 이는 기존 데이터 세트(종종 라벨링되거나 태깅됨)를 입력하고, 데이터 세트에 대해 반복하고, 이어서 모델 성능을 개선하기 위해 가중치들 및 바이어스들과 같은 모델 파라미터들을 조정하는 것을 수반하는 고도로 계산 집약적 인 동작이다. 일반적으로, 잘못된 예측에 기반한 최적화는 모델의 계층들을 통해 다시 전파하고 예측 에러를 감소시키기 위해 기울기들을 결정하는 것을 수반한다. 추론을 가속화하도록 설계된 NPU들은 일반적으로 완전한 모델들에 대해 동작하도록 구성된다. 따라서, 그러한 NPU들은, 새로운 데이터 조각을 입력하고 이미 트레이닝된 모델을 통해 그것을 빠르게 처리하여 모델 출력(예를 들어, 추론)을 생성하도록 구성될 수 있다. 일 구현예에서, NPU는 CPU, GPU 및/또는 DSP 중 하나 이상의 부분이다. 일부 예들에서, 무선 연결성 컴포넌트는 예를 들어, 3세대(3G) 연결성, 4세대(4G) 연결성(예컨대, 4G LTE), 5세대 연결성(예컨대, 5G 또는 NR), Wi-Fi 연결성, 블루투스 연결성 및 다른 무선 데이터 송신 표준들을 위한 서브컴포넌트들을 포함할 수 있다. 무선 연결성 컴포넌트는 하나 이상의 안테나에 추가로 연결 된다. 프로세싱 시스템은 또한 임의의 방식의 센서와 연관된 하나 이상의 센서 프로세싱 유닛들, 예컨대, 도 1에 도시된 온도 센서들, 임의의 방식의 이미지 센서와 연관된 하나 이상의 이미지 신호 프로세서들 (ISP들), 및/또는 위성기반 포지셔닝 시스템 컴포넌트들(예컨대, GPS 또는 GLONASS) 뿐만 아니라 관성 포 지셔닝 시스템 컴포넌트들을 포함할 수 있는 내비게이션 프로세서를 포함할 수 있다. 프로세싱 시스템은 또한 스크린들, 터치 감지 표면들(터치 감지 디스플레이들을 포함), 물리적 버튼들, 스 피커들, 마이크들 등과 같은 하나 이상의 입력 및/또는 출력 디바이스들을 포함할 수 있다. 일부 예들에서, 프로세싱 시스템의 프로세서들 중 하나 이상은 ARM 또는 RISC-V 명령 세트에 기초할 수 있 다. 프로세싱 시스템은 또한, 동적 랜덤 액세스 메모리, 플래시 기반 정적 메모리 등과 같은 하나 이상의 정적 및/또는 동적 메모리들을 나타내는 메모리를 포함한다. 이러한 예에서, 메모리는 프로세싱 시스템 의 전술한 프로세서들 중 하나 이상에 의해 실행될 수 있는 컴퓨터-실행가능 컴포넌트들을 포함한다. 특히, 이 예에서, 메모리는 온도 측정 컴포넌트(424A), 임계치 초과 온도 결정 컴포넌트(424B), 프로세싱 유닛 선택 컴포넌트(424C), 스케줄링 컴포넌트(424D), 및 뉴럴 네트워크(424E)를 포함한다. 도시된 컴포넌트들, 및 도시되지 않은 다른 것들은 본원에서 설명된 방법들의 다양한 양태들을 수행하도록 구성될 수 있다. 대체적으로, 프로세싱 시스템 및/또는 그의 컴포넌트들은 본 명세서에 설명된 방법들을 수행하도록 구성될 수 있다.특히, 다른 실시형태들에서, 프로세싱 시스템의 양태들은 프로세싱 시스템이 서버 컴퓨터 등인 경우 와 같이 생략될 수 있다. 예를 들어, 멀티미디어 프로세싱 유닛, 무선 연결성 컴포넌트, 센서 프로 세싱 유닛들, ISP들, 및/또는 내비게이션 프로세서는 다른 실시형태들에서 생략될 수 있다. 또 한, 프로세싱 시스템의 양태들은, 모델을 트레이닝하고 모델을 사용하여 사용자 검증 예측들과 같은 추론 을 생성하는 것과 같이 분산될 수 있다. 예시적인 조항들 구현 예들은 다음의 넘버링된 조항들에 설명되어 있다. 조항 1: 다수의 프로세싱 유닛들을 갖는 컴퓨팅 디바이스 상에서 구현되는 방법으로서, 컴퓨팅 디바이스의 제1 프로세싱 유닛 상에서의 뉴럴 네트워크의 제1 부분에서의 동작들의 실행 동안, 컴퓨팅 디바이스 상의 복수의 위 치들의 각각에 대해 온도를 측정하는 단계; 제1 프로세싱 유닛에 대해 측정된 온도가 임계 온도를 초과한다고 결정하는 단계; 컴퓨팅 디바이스에 대한 하나 이상의 동작 파라미터들에 기초하여, 뉴럴 네트워크의 제2 부분에 서 동작들을 실행하는데 사용할 컴퓨팅 디바이스의 제2 프로세싱 유닛을 선택하는 단계; 및 제2 프로세싱 유닛 상에서의 뉴럴 네트워크의 제2 부분에서의 동작들의 실행을 스케줄링하는 단계를 포함하는, 방법. 조항 2: 조항 1에 있어서, 뉴럴 네트워크의 제1 부분 및 뉴럴 네트워크의 제2 부분은 프로세싱 유닛들의 동일한 세트 상에서의 실행을 위해 구성된 뉴럴 네트워크의 계층들을 포함하는, 방법. 조항 3: 조항 1 또는 조항 2에 있어서, 뉴럴 네트워크의 제1 부분은 컴퓨팅 디바이스의 프로세싱 유닛들의 제1 세트 상에서의 실행을 위해 구성된 계층들의 제1 세트의 구성원이고, 뉴럴 네트워크의 제2 부분은 컴퓨팅 디바 이스의 프로세싱 유닛들의 제2 세트 상에서의 실행을 위해 구성된 계층들의 제2 세트의 구성원인, 방법. 조항 4: 조항 3에 있어서, 계층들의 제1 세트는 양자화 파라미터들의 제1 세트로 구성된 계층들의 세트를 포함 하는, 방법. 조항 5: 조항 4에 있어서, 계층들의 제2 세트는 양자화 파라미터들의 제2 세트로 구성된 계층들의 세트를 포함 하고, 양자화 파라미터들의 제2 세트는 양자화 파라미터들의 제1 세트보다 더 작은 데이터 유형에 대한 양자화 에 대응하는, 방법. 조항 6: 조항 3 내지 조항 5 중 어느 한 조항에 있어서, 프로세싱 유닛들의 제1 세트는 뉴럴 프로세싱 유닛 (NPU), 디지털 신호 프로세서(DSP), 및 복수의 중앙 프로세싱 유닛(CPU) 코어들을 포함하는, 방법. 조항 7: 조항 6에 있어서, 프로세싱 유닛들의 제2 세트는 복수의 CPU 코어들 및 복수의 그래픽 프로세싱 유닛 (GPU) 프로세서들을 포함하는, 방법. 조항 8: 조항 1 내지 조항 7 중 어느 한 조항에 있어서, 제2 프로세싱 유닛을 선택하는 단계는 뉴럴 네트워크의 제2 부분에서 동작들을 실행하기 위한 프로세싱 유닛들의 유형들의 랭킹에 추가로 기초하는, 방법. 조항 9: 조항 8에 있어서, 프로세싱 유닛들의 유형들의 랭킹은 뉴럴 네트워크의 제2 부분을 이용하여 처리되는 데이터의 크기 및 컴퓨팅 디바이스 내의 프로세싱 유닛의 각각의 유형과 연관된 성능의 레벨에 기초하는, 방법. 조항 10: 조항 1 내지 조항 9 중 어느 한 조항에 있어서, 하나 이상의 동작 파라미터들은 하나 이상의 프로세싱 유닛들과 제1 프로세싱 유닛 사이의 거리, 하나 이상의 프로세싱 유닛들의 온도, 또는 하나 이상의 프로세싱 유 닛들 상의 현재 부하 중 하나 이상을 포함하는, 방법. 조항 11: 조항 10에 있어서, 제2 프로세싱 유닛을 선택하는 단계는 임계 온도 미만의 측정된 온도를 갖는 제1 프로세싱 유닛으로부터 가장 먼 거리에 있는 프로세싱 유닛을 선택하는 단계를 포함하는, 방법. 조항 12: 조항 10 또는 조항 11에 있어서, 제2 프로세싱 유닛을 선택하는 단계는: 거리 임계치를 초과하는 제1 프로세싱 유닛으로부터의 거리들 및 임계 온도 미만의 측정된 온도를 갖는 프로세싱 유닛들의 세트를 식별하는 단계; 및 프로세싱 유닛들의 식별된 세트로부터 제2 프로세싱 유닛을 선택하는 단계를 포함하는, 방법. 조항 13: 조항 12에 있어서, 프로세싱 유닛들의 세트를 식별하는 단계는 임계 부하 미만의 현재 부하를 갖는 프 로세싱 유닛들을 식별하는 단계를 추가로 포함하는, 방법. 조항 14: 프로세싱 시스템으로서, 컴퓨터-실행가능 명령어들을 포함하는 메모리 및 하나 이상의 프로세서들을 포함하고, 하나 이상의 프로세서들은 컴퓨터-실행가능 명령어들을 실행하고 프로세싱 시스템으로 하여금 조항 1 내지 조항 13 중 어느 한 조항에 따른 방법을 수행하게 하는, 프로세싱 시스템.조항 15: 조항 1 내지 조항 13 중 어느 한 조항에 따른 방법을 수행하기 위한 수단을 포함하는, 프로세싱 시스 템. 조항 16: 컴퓨터-실행가능 명령어들을 포함하는 비일시적 컴퓨터-판독가능 매체로서, 컴퓨터-실행가능 명령어들 은 프로세싱 시스템의 하나 이상의 프로세서들에 의해 실행될 때, 프로세싱 시스템으로 하여금 조항 1 내지 조 항 13 중 어느 한 조항에 따른 방법을 수행하게 하는, 비일시적 컴퓨터-판독가능 매체. 조항 17: 조항 1 내지 조항 13 중 어느 한 조항에 따른 방법을 수행하기 위한 코드를 포함하는 컴퓨터-판독가능 저장 매체 상에 구현된, 컴퓨터 프로그램 제품. 추가적인 고려사항들 이전의 설명은 임의의 당업자가 본원에 설명된 다양한 실시형태들을 실시할 수 있게 하도록 제공된다. 본원에 논의된 예들은 청구범위에 기재된 범위, 적용 가능성, 또는 실시형태들을 제한하는 것이 아니다. 이러한 실시 형태들에 대한 다양한 변형들이 당업자들에게 쉽게 명백할 것이며, 본원에 정의된 일반적 원리들은 다른 실시형 태들에 적용될 수 있다. 예를 들어, 본 개시내용의 범주를 벗어나지 않으면서, 논의되는 요소들의 기능 및 배 열에 있어서 변경이 이루어질 수 있다. 다양한 예들은 다양한 절차들 또는 컴포넌트들을 적절히 생략, 대체, 또는 추가할 수 있다. 예를 들어, 설명된 방법들은 설명된 것과는 상이한 순서로 수행될 수 있고, 다양한 단계 들이 추가, 생략 또는 조합될 수 있다. 또한, 일부 예들과 관련하여 설명된 특징들은 일부 다른 예들에서 조합 될 수 있다. 예를 들어, 본원에 기재된 임의의 수의 양태들을 사용하여, 장치가 구현될 수 있거나 방법이 실시 될 수 있다. 추가적으로, 본 개시내용의 범주는, 본 명세서에 기재된 본 개시내용의 다양한 양태들에 더하여 또는 그 이외의 다른 구조, 기능, 또는 구조 및 기능을 사용하여 실시되는 그러한 장치 또는 방법을 커버하도록 의도된다. 본원에 개시된 본 개시내용의 임의의 양태는 청구항의 하나 이상의 요소들에 의해 구현될 수 있다는 것이 이해되어야 한다. 본 명세서에서 사용된 바와 같이, 단어 \"예시적인\"은 \"예, 예증, 또는 예시로서 역할을 함\"을 의미한다. \"예시 적인\" 것으로 본원에 설명된 임의의 양태는 다른 양태들에 비해 바람직하거나 유리한 것으로 반드시 해석되는 것은 아니다. 본 명세서에서 사용된 바와 같이, 일 리스트의 아이템들 \"중 적어도 하나\"를 지칭하는 어구는 단일 멤버들을 포 함하여 그 아이템들의 임의의 조합을 지칭한다. 예로서, \"a, b 또는 c 중 적어도 하나\"는 a, b, c, a-b, a-c, b-c, 및 a-b-c뿐만 아니라 동일한 요소의 배수들과의 임의의 조합(예를 들어, a-a, a-a-a, a-a-b, a-a-c, a-b- b, a-c-c, b-b, b-b-b, b-b-c, c-c, 및 c-c-c 또는 a, b, 및 c의 임의의 다른 순서화)을 커버하도록 의도된다. 본 명세서에서 사용되는 용어 \"결정\"은 광범위한 액션들을 포함한다. 예를 들어, \"결정\"은 계산, 컴퓨팅, 프로 세싱, 유도, 검사, 검색(예컨대, 표, 데이터베이스 또는 다른 데이터 구조에서의 검색), 확인 등을 포함할 수 있다. 또한, \"결정\"은 수신(예를 들어, 정보 수신), 액세스(예를 들어, 메모리 내의 데이터에 액세스) 등을 포 함할 수 있다. 또한, \"결정\"은 해결, 선택, 선정, 확립 등을 포함할 수 있다. 본 명세서에 개시된 방법들은 그 방법들을 달성하기 위한 하나 이상의 단계들 또는 액션들을 포함한다. 방법 단계들 및/또는 액션들은 청구항들의 범주를 벗어나지 않고 서로 교환될 수 있다. 즉, 단계들 또는 액션들의 특정한 순서가 명시되지 않으면, 특정 단계들 및/또는 액션들의 순서 및/또는 사용은 청구항들의 범주를 벗어나 지 않고 변형될 수 있다. 또한, 위에서 설명된 방법들의 다양한 동작들은 대응하는 기능들을 수행할 수 있는 임의의 적합한 수단에 의해 수행될 수 있다. 이 수단은, 회로, 특정 용도 지향 집적 회로(ASIC) 또는 프로세서 를 포함하지만, 이에 제한되지 않는 다양한 하드웨어 및/또는 소프트웨어 컴포넌트(들) 및/또는 모듈(들)을 포 함할 수 있다. 일반적으로, 도면들에 예시된 동작들이 존재하는 경우, 그러한 동작들은 유사한 넘버링을 갖는 대응하는 상대 기능식(counterpart means-plus-function) 컴포넌트들을 가질 수 있다. 다음의 청구범위는 본원에 나타낸 실시형태들에 제한되도록 의도되지 않으며, 청구범위의 언어와 일치하는 전체 범위에 따라야 한다. 청구항 내에서, 단수의 요소에 대한 언급은 구체적으로 그렇게 언급되지 않는 한 \"하나 및 하나만\"을 의미하는 것이 아니라 오히려 \"하나 이상\"을 의미하도록 의도된다. 달리 특정하게 언급되지 않으 면, \"일부\"라는 용어는 하나 이상을 지칭한다. 구문 \"~하기 위한 수단\"을 사용하여 엘리먼트가 명시적으로 인 용되지 않는 한, 또는 방법 청구항의 경우 구문 \"~하기 위한 단계\"를 사용하여 엘리먼트가 인용되지 않는 한, 어떠한 청구항 엘리먼트도 35 U.S.C. §112(f) 조항 하에서 해석되지 않아야 한다. 당업자들에게 알려져 있는 또는 나중에 알려지게 될 본 개시내용 전체에 걸쳐 설명된 다양한 양태들의 요소들에 대한 모든 구조적 그리고 기능적 등가물들은 참조에 의해 본원에 명백히 포함되고, 청구항들에 의해 포괄되는 것으로 의도된다. 게다가,본원에 개시된 어떠한 것도, 그와 같은 개시내용이 청구항들에 명시적으로 인용되는지 여부에 관계없이 공중에 전용되도록 의도되지 않는다."}
{"patent_id": "10-2024-7025685", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면들은 하나 이상의 실시형태들의 특정 양태들을 묘사하고, 따라서 본 개시내용의 범위를 제한하는 것으로 간주되지 않아야 한다. 도 1은 멀티프로세서 컴퓨팅 디바이스의 에시적인 레이아웃을 도시한다. 도 2는 본 개시내용의 양태들에 따른 뉴럴 네트워크의 계층들이 컴퓨팅 디바이스 내의 프로세싱 유닛들의 상이 한 세트들 상에서의 프로세싱을 위해 구성된 그룹들로 조직화되는 뉴럴 네트워크의 예시적인 아키텍처를 도시한 다. 도 3은 본 개시내용의 양태들에 따른 멀티프로세서 컴퓨팅 디바이스 상의 머신 러닝 모델에서의 동작들의 적응 적 스케줄링 실행을 위한 예시적인 동작들을 도시한다. 도 4는 본 개시내용의 양태들에 따른 뉴럴 네트워크에서의 동작들의 실행의 적응적 스케줄링이 수행될 수 있는 프로세싱 시스템의 예시적인 구현예를 도시한다. 이해를 용이하게 하기 위하여, 도면들에 공통적인 동일한 요소들을 지정하기 위해 가능한 경우 동일한 참조 번 호들이 사용되었다. 일 실시형태의 요소들 및 특징들은 추가적인 언급이 없더라도 다른 실시형태들에 유익하게 통합될 수 있다는 것이 고려된다."}
