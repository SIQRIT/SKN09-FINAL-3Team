{"patent_id": "10-2022-0066100", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0166304", "출원번호": "10-2022-0066100", "발명의 명칭": "카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치 및 방법", "출원인": "경북대학교 산학협력단", "발명자": "한동석"}}
{"patent_id": "10-2022-0066100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라로부터 객체 박스가 표시된 이미지 프레임을 입력 받고, 레이더 센서로부터 레이더 정보를 입력 받는 입력부;상기 객체 박스가 표시된 이미지에 상기 레이더 정보를 매칭하여 상기 객체 박스에 레이더 포인트를 표시하는교정부;상기 이미지에 존재하는 상기 객체 박스 중 어느 하나의 객체 박스를 선택하여 상기 객체의 특징을 추출하고,상기 객체 박스에 표시된 레이더 포인트의 레이더 정보를 전처리하는 특징 추출부; 및상기 객체의 특징 및 상기 레이더 정보를 인공신경망 모델에 입력하여 상기 레이더 포인트의 정상 여부를 출력하는 출력부;를 포함하는, 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치."}
{"patent_id": "10-2022-0066100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 교정부는,상기 레이더 센서로부터 전달받은 레이더 정보를 분석하여 레이더 포인트를 산출하고, 상기 이미지 내에 표시된상기 객체 박스와 상기 레이더 포인터를 매칭하여 상기 객체 박스에 대응하는 상기 레이더 포인트를 표시하는것을 특징으로 하는, 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치."}
{"patent_id": "10-2022-0066100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 특징 추출부는,상기 선택된 객체 박스의 객체 이미지를 사전에 학습된 딥러닝 모델에 입력하여 상기 객체의 특징을 추출하는객체 특징 추출부; 및상기 객체 박스에 표시된 상기 레이더 포인트의 레이더 정보를 상기 인공신경망 모델에 입력하기 위해, 상기 레이더 정보를 사전에 설정된 일정 길이 값으로 전처리하는 레이더 정보 처리부;를 포함하는 것을 특징으로 하는,카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치."}
{"patent_id": "10-2022-0066100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 레이더 정보 처리부는,상기 레이더 정보를 사전에 설정된 일정 길이 값으로 전처리하되, 상기 레이더 정보를 레이더 반사 면적 값을기준으로 내림차순 정렬하고, 정렬된 상기 레이더 정보의 개수가 상기 일정 길이 값보다 적은 경우, 잔여 데이터 값을 0으로 처리하여 전처리하는 것을 특징으로 하는, 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더센서 고장 분류 장치."}
{"patent_id": "10-2022-0066100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0166304-3-제4항에 있어서,상기 출력부는,상기 객체의 특징과 상기 레이더 정보를 1차원 데이터 형태로 결합하여 상기 인공신경망 모델에 입력하되,상기 인공신경망 모델은,입력 데이터에 대응되는 출력 데이터로서, 상기 객체 박스에 존재하는 적어도 하나 이상의 레이더 포인트의 정상 결과와 정상으로 판단된 레이더 포인트의 레이더 인덱스를 출력하는, 카메라와 레이더 센서를 이용한 딥러닝기반 레이더 센서 고장 분류 장치."}
{"patent_id": "10-2022-0066100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "딥러닝 기반 레이더 센서 고장 분류 장치로부터 수행되는 레이더 센서 고장 분류 방법에 있어서,카메라로부터 객체 박스가 표시된 이미지 프레임을 입력 받고, 레이더 센서로부터 레이더 정보를 입력 받는 입력 단계;상기 객체 박스가 표시된 이미지에 상기 레이더 정보를 매칭하여 상기 객체 박스에 레이더 포인트를 표시하는교정 단계;상기 이미지에 존재하는 상기 객체 박스 중 어느 하나의 객체 박스를 선택하여 상기 객체의 특징을 추출하고,상기 객체 박스에 표시된 레이더 포인트의 레이더 정보를 전처리하는 특징 추출 단계; 및 상기 객체의 특징 및 상기 레이더 정보를 인공신경망 모델에 입력하여 상기 레이더 포인트의 정상 여부를 출력하는 출력 단계;를 포함하는, 레이더 센서 고장 분류 방법."}
{"patent_id": "10-2022-0066100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 교정 단계는,상기 레이더 센서로부터 전달받은 레이더 정보를 분석하여 레이더 포인트를 산출하고, 상기 이미지 내에 표시된상기 객체 박스와 상기 레이더 포인터를 매칭하여 상기 객체 박스에 대응하는 상기 레이더 포인트를 표시하는것을 특징으로 하는, 레이더 센서 고장 분류 방법."}
{"patent_id": "10-2022-0066100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 특징 추출 단계는,상기 선택된 객체 박스의 객체 이미지를 사전에 학습된 딥러닝 모델에 입력하여 상기 객체의 특징을 추출하는객체 특징 추출 단계; 및상기 객체 박스에 표시된 상기 레이더 포인트의 레이더 정보를 상기 인공신경망 모델에 입력하기 위해, 상기 레이더 정보를 사전에 설정된 일정 길이 값으로 전처리하는 레이더 정보 처리 단계;를 포함하는 것을 특징으로 하는, 레이더 센서 고장 분류 방법."}
{"patent_id": "10-2022-0066100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 레이더 정보 처리 단계는,공개특허 10-2023-0166304-4-상기 레이더 정보를 사전에 설정된 일정 길이 값으로 전처리하되, 상기 레이더 정보를 레이더 반사 면적 값을기준으로 내림차순 정렬하고, 정렬된 상기 레이더 정보의 개수가 상기 일정 길이 값보다 적은 경우, 잔여 데이터 값을 0으로 처리하여 전처리하는 것을 특징으로 하는, 레이더 센서 고장 분류 방법."}
{"patent_id": "10-2022-0066100", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 출력 단계는,상기 객체의 특징과 상기 레이더 정보를 1차원 데이터 형태로 결합하여 상기 인공신경망 모델에 입력하되,상기 인공신경망 모델은,입력 데이터에 대응되는 출력 데이터로서, 상기 객체 박스에 존재하는 적어도 하나 이상의 레이더 포인트의 정상 결과와 정상으로 판단된 레이더 포인트의 레이더 인덱스를 출력하는, 레이더 센서 고장 분류 방법."}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치에 관한 것으로, 카메라로부 터 객체 박스가 표시된 이미지 프레임을 입력 받고, 레이더 센서로부터 레이더 정보를 입력 받는 입력부; 상기 객체 박스가 표시된 이미지에 상기 레이더 정보를 매칭하여 상기 객체 박스에 레이더 포인트를 표시하는 교정부; 상기 이미지에 존재하는 상기 객체 박스 중 어느 하나의 객체 박스를 선택하여 상기 객체의 특징을 추출하고, 상 기 객체 박스에 표시된 레이더 포인트의 레이더 정보를 전처리하는 특징 추출부; 및 상기 객체의 특징 및 상기 레이더 정보를 인공신경망 모델에 입력하여 상기 레이더 포인트의 정상 여부를 출력하는 출력부;를 포함한다. 이 를 통해, 이미지 프레임에 표시된 레이더 포인트의 정상 여부를 판단하여 해당 레이더 센서가 정상 인지 고장 인 지 분류가 가능하다."}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치 및 방법에 관한 것으로, 더 욱 상세하게는 카메라의 이미지와 레이더의 레이더 정보를 융합하여 레이더의 고장을 분류하는 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어, 여러 분야에서 레이더 센서를 이용하여 물체를 감지하거나 물체를 추적하는 연구가 이루어지고 있다. 레이더센서란 전자파를 방사하여 목표물에 반사되어 되돌아오는 파를 검출하는 센서로서, 목표물까지의 거리, 이동 속도, 진행 방향 및 레이더 반사 면적(Radar Cross Section, 이하 RCS) 등을 감지할 수 있다. 이러한, 레이더 센서는 짧은 시간 동안 강한 전자파를 송출하고, 물체에 반사되어 돌아오는 신호 사이의 시간을 측정하는 진폭 변조 방식의 펄스 방식과 전자파를 지속적으로 송출하고 물체에 부딪혀 돌아오는 반사파를 측정 하여 송신 주파수와의 차이를 측정하여 물체의 움직임을 감지하는 연속파 방식으로 개발되어 왔다. 이와 같이, 레이더 센서의 센서 값에는 불필요한 노이즈가 많이 포함될 수 있으므로, RCS 값이 기준치 이하인 값들은 삭제하는 필터가 사용될 수 있다. 다만, 이러한 필터를 사용하는 것은, 레이더 센서에 고장이 발생하면 객체에 해당하는 값도 필터로 인해 삭제되 어 객체의 정보를 알 수 없는 문제가 존재한다. 또한, 필터를 사용하지 않은 경우, 카메라와 레이더를 캘리브레이션 했을 때, 검출된 객체 박스 안에 여러 포인 트가 중복되어 표시되는 문제점이 존재한다. 따라서, 레이더 센서를 통해 객체를 감시 및 추적할 때, 해당 레이더 센서를 감시 및 추적하여 산출된 데이터가 정확한 데이터인지 확인하는 기술에 대한 연구개발이 필요한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) (대한민국) 등록특허공보 제10-2294115호"}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제를 해결하기 위해 안출된 것으로, 본 발명의 목적은 딥러닝 모델을 통해 카메라 이 미지와 융합된 레이더 정보를 이용하여 레이더 센서의 고장 여부를 분류하는 카메라와 레이더 센서 융합을 이용 한 딥러닝 기반 레이더 센서 고장 분류 장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 실시예에 따른 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치는, 카메라로부터 객체 박스가 표시된 이미지 프레임을 입력 받고, 레이더 센서로부터 레이더 정 보를 입력 받는 입력부; 상기 객체 박스가 표시된 이미지에 상기 레이더 정보를 매칭하여 상기 객체 박스에 레 이더 포인트를 표시하는 교정부; 상기 이미지에 존재하는 상기 객체 박스 중 어느 하나의 객체 박스를 선택하여 상기 객체의 특징을 추출하고, 상기 객체 박스에 표시된 레이더 포인트의 레이더 정보를 전처리하는 특징 추출 부; 및 상기 객체의 특징 및 상기 레이더 정보를 인공신경망 모델에 입력하여 상기 레이더 포인트의 정상 여부 를 출력하는 출력부;를 포함한다. 이때, 상기 교정부는, 상기 레이더 센서로부터 전달받은 레이더 정보를 분석하여 레이더 포인트를 산출하고, 상 기 이미지 내에 표시된 상기 객체 박스와 상기 레이더 포인터를 매칭하여 상기 객체 박스에 대응하는 상기 레이 더 포인트를 표시할 수 있다. 그리고, 상기 특징 추출부는, 상기 선택된 객체 박스의 객체 이미지를 사전에 학습된 딥러닝 모델에 입력하여 상기 객체의 특징을 추출하는 객체 특징 추출부; 및 상기 객체 박스에 표시된 상기 레이더 포인트의 레이더 정 보를 상기 출력부의 인공신경망 모델에 입력하기 위해, 상기 레이더 정보를 사전에 설정된 일정 길이 값으로 전 처리하는 레이더 정보 처리부;를 포함할 수 있다. 이와 관련하여, 상기 레이더 정보 처리부는, 상기 레이더 정보를 사전에 설정된 일정 길이 값으로 전처리하되, 상기 레이더 정보를 레이더 반사 면적 값을 기준으로 내림차순 정렬하고, 정렬된 상기 레이더 정보의 개수가 상 기 일정 길이 값보다 적은 경우, 잔여 데이터 값을 0으로 처리하여 전처리할 수 있다. 따라서, 상기 출력부는, 상기 객체의 특징과 상기 레이더 정보를 1차원 데이터 형태로 결합하여 상기 인공신경 망 모델에 입력하되, 상기 인공신경망 모델은, 입력 데이터에 대응되는 출력 데이터로서, 상기 객체 박스에 존 재하는 적어도 하나 이상의 레이더 포인트의 정상 결과와 정상으로 판단된 레이더 포인트의 레이더 인덱스를 출 력할 수 있다. 한편, 상기 목적을 달성하기 위한 본 발명의 실시예에 따른 레이더 센서 고장 분류 방법은, 딥러닝 기반 레이더 센서 고장 분류 장치로부터 수행되는 방법으로서, 카메라로부터 객체 박스가 표시된 이미지 프레임을 입력 받고, 레이더 센서로부터 레이더 정보를 입력 받는 입력 단계; 상기 객체 박스가 표시된 이미지에 상기 레이더 정보를 매칭하여 상기 객체 박스에 레이더 포인트를 표시하는 교정 단계; 상기 이미지에 존재하는 상기 객체 박 스 중 어느 하나의 객체 박스를 선택하여 상기 객체의 특징을 추출하고, 상기 객체 박스에 표시된 레이더 포인 트의 레이더 정보를 전처리하는 특징 추출 단계; 및 상기 객체의 특징 및 상기 레이더 정보를 인공신경망 모델 에 입력하여 상기 레이더 포인트의 정상 여부를 출력하는 출력 단계;를 포함한다. 이때, 상기 교정 단계는, 상기 레이더 센서로부터 전달받은 레이더 정보를 분석하여 레이더 포인트를 산출하고, 상기 이미지 내에 표시된 상기 객체 박스와 상기 레이더 포인터를 매칭하여 상기 객체 박스에 대응하는 상기 레 이더 포인트를 표시할 수 있다. 그리고, 상기 특징 추출 단계는, 상기 선택된 객체 박스의 객체 이미지를 사전에 학습된 딥러닝 모델에 입력하 여 상기 객체의 특징을 추출하는 객체 특징 추출 단계; 및 상기 객체 박스에 표시된 상기 레이더 포인트의 레이 더 정보를 상기 인공신경망 모델에 입력하기 위해, 상기 레이더 정보를 사전에 설정된 일정 길이 값으로 전처리 하는 레이더 정보 처리 단계;를 포함할 수 있다. 이와 관련하여, 상기 레이더 정보 처리 단계는, 상기 레이더 정보를 사전에 설정된 일정 길이 값으로 전처리하 되, 상기 레이더 정보를 레이더 반사 면적 값을 기준으로 내림차순 정렬하고, 정렬된 상기 레이더 정보의 개수 가 상기 일정 길이 값보다 적은 경우, 잔여 데이터 값을 0으로 처리하여 전처리할 수 있다. 따라서, 상기 출력 단계는, 상기 객체의 특징과 상기 레이더 정보를 1차원 데이터 형태로 결합하여 상기 인공신 경망 모델에 입력하되, 상기 인공신경망 모델은, 입력 데이터에 대응되는 출력 데이터로서, 상기 객체 박스에존재하는 적어도 하나 이상의 레이더 포인트의 정상 결과와 정상으로 판단된 레이더 포인트의 레이더 인덱스를 출력할 수 있다."}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 본 발명의 일측면에 따르면, 카메라와 레이더 센서 융합을 이용한 딥러닝 기반 레이더 센서 고장 분류 장치 및 방법을 자율주행 시스템에 적용함으로써, 자율주행 시스템의 인지 오류로 인한 자율주행 차량의 교통 사고를 감소할 수 있다. 또한, 자율주행 시스템의 신뢰성이 향상되어 사람의 제어가 없는 완전 자율주행 5단계로 구동되는 자율주행 차 량에서도 사용이 가능할 수 있다."}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명이 실시될 수 있는 특정 실시예를 예시로서 도시하는 첨부 도 면을 참조한다. 이들 실시예는 당업자가 본 발명을 실시할 수 있기에 충분하도록 상세히 설명된다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있 는 특정 형상, 구조 및 특성은 일 실시예와 관련하여 본 발명의 정신 및 범위를 벗어나지 않으면서 다른 실시예 로 구현될 수 있다. 또한, 각각의 개시된 실시예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 정신 및 범 위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미로 서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모든 범위와 더불어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하거 나 유사한 기능을 지칭한다. 또한, 본 발명의 특징 및 이점들은 첨부도면에 의거한 상세한 설명으로 더욱 명확해질 것이며, 본 명세서 및 청 구범위에 사용된 용어나 단어는 통상적이고, 사전적인 의미로 해석되어서는 아니되며, 발명자가 그 자신의 발명 을 가장 최선의 방법으로 설명하기 위해 용어의 개념을 적절하게 정의할 수 있다는 원칙에 입각하여 본 발명의 기술적 사상에 부합되는 의미와 개념으로 해석되어야 한다. 이하, 도면들을 참조하여 본 발명의 바람직한 실시예들을 보다 상세하게 설명하기로 한다. 도 1은 본 발명의 실시예에 따른 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치의 블 록 도면이고, 도 2는 도 1의 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치의 예시 도면이며, 도 3는 도 1의 학습부의 예시 도면이다. 도 1을 참조하면, 카메라(C)와 레이더 센서(L)를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치(이하, 레이더 센서 고장 분류 장치)는, 카메라(C)에서 측정된 이미지 프레임과 레이더 센서(L)로부터 레이더 정보를 입력 받고, 레이더 정보에 기초하여 이미지 프레임에 표시된 레이더 포인트의 정상 여부를 판단하여 해당 레이더 센 서(L)가 정상인지 고장인지 분류하기 위해 마련된다. 이러한, 카메라(C)는, 측정된 이미지 프레임에 객체 추적 기술을 이용하여 이미지 프레임에 존재하는 객체를 객 체 박스로 표시하고, 객체 박스로 표시된 이미지 프레임을 레이더 센서 고장 분류 장치에 전달할 수 있다. 보다 구체적으로, 객체 추적 기술은, 이미지 내에서 객체를 식별하여 박스로 표시하고 해당 박스에 존재하는 객 체가 무엇인지 분류하는 기술로서, 사전에 학습된 딥러닝 모델을 이용하여 객체를 분류하는 기술이다. 이러한, 객체 추적 기술은 공지된 지역 제안 네트워크(Region Proposal Network, RPN)가 사용되는 것이 바람직하나 이에한정되지 않는다. 한편, 레이더 센서(L)는, 카메라와 동일한 방향, 동일한 시간 및 동일한 장소에 전자파를 방출하여 되돌아오는 반사파를 측정해 대상을 탐지하고 대상의 정보를 파악할 수 있다. 이때, 레이더 센서(L)는, 되돌아오는 반사파를 통해 대상의 방향, 거리 속도 및 레이더 반사 면적 등을 파악할 수 있고, 이러한 정보를 레이더 정보로서 레이더 센서 고장 분류 장치에 전달할 수 있다. 이러한, 레이더 센서 고장 분류 장치, 카메라(C) 및 레이더 센서(L)는 네트워크를 통해 통신하거나 또는 차 량에 각각 유선 연결되어 통신할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워크들로는 인터넷(Internet), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 3G, 5G, LTE(Long Term Evolution), WiFi(Wireless Fidelity), WiMAX(World Interoperability for Microwave Access), WiGig(Wireless gigabit) 등이 포함되나 이에 한정되지 않는다. 또한, 레이더 센서 고장 분류 장치는, 이동성을 갖거나 고정될 수 있다. 레이더 센서 고장 분류 장치는 서버 또는 엔진(engine) 형태일 수 있으며, 디바이스(device), 기구(apparatus), 단말 (terminal), UE(user equipment), MS(mobile station), 무선기기(wireless device), 휴대기기(handheld device) 등 다른 용어로 불 릴 수 있다. 또한, 레이더 센서 고장 분류 장치는, 운영체제(Operation System; OS), 즉 시스템을 기반으로 다양한 소프 트웨어를 실행하거나 제작할 수 있다. 상기 운영체제는 소프트웨어가 장치의 하드웨어를 사용할 수 있도록 하기 위한 시스템 프로그램으로서, 안드로이드 OS, iOS, 윈도우 모바일 OS, 바다 OS, 심비안 OS, 블랙베리 OS 등 모 바일 컴퓨터 운영체제 및 윈도우 계열, 리눅스 계열, 유닉스 계열, MAC, AIX, HP-UX 등 컴퓨터 운영체제를 모두 포함할 수 있다. 이에, 레이더 센서 고장 분류 장치는, 레이더 정보를 전달한 레이더 센서의 고장을 분류하기 위해 도 1에 도시된 바와 같이, 입력부, 교정부, 특징 추출부, 출력부, 학습부 및 통신부를 포함할 수 있다. 그리고, 레이더 센서 고장 분류 장치는, 레이더 센서 고장 분류 방법을 수행하기 위한 소프트웨어(어플리케 이션)가(이) 설치되어 실행될 수 있으며, 입력부, 교정부, 특징 추출부, 출력부, 학습부 및 통신부는 레이더 센서 고장 분류 장치에서 실행되는 레이더 센서 고장 분류 방법을 수행하기 위한 소프트웨어에 의해 제어될 수 있다. 그리고, 레이더 센서 고장 분류 장치는, 도면에는 미도시되었으나, 레이더 센서 고장 분류 장치에서 사용되 는 딥러닝 모델이 저장되거나, 카메라(C) 및 레이더 센서(L)로부터 입력된 이미지 프레임 및 레이더 정보 등이 저장되는 저장부를 더 포함할 수 있는 것은 물론, 이러한 저장부 역시 레이더 센서 고장 분류 장치에서 실 행되는 레이더 센서 고장 분류 방법을 수행하기 위한 소프트웨어에 의해 제어될 수 있다. 그리고, 레이더 센서 고장 분류 장치는, 별도의 단말이거나 또는 단말의 일부 모듈일 수 있다. 또한, 입력 부, 교정부, 특징 추출부, 출력부, 학습부 및 통신부는 통합 모듈로 형성되거나 하나 이상의 모듈로 이루어질 수 있다. 그러나, 이와 반대로 각 구성은 별도의 모듈로 이루어질 수 있다. 먼저, 입력부는, 도 3에 도시된 바와 같이 카메라(C)로부터 객체 박스가 표시된 이미지 프레임을 입력 받 고, 레이더 센서(L)로부터 레이더 정보를 입력 받는다. 이때, 입력부는 상술한 바와 같이, 레이더 센서 고장 분류 장치, 카메라(C) 및 레이더 센서(L)가 무선 으로 연결되면 네트워크 통신을 통해 카메라(C) 및 레이더 센서(L)로부터 이미지 프레임 및 레이더 정보를 입력 받고, 레이더 센서 고장 분류 장치, 카메라(C) 및 레이더 센서(L)가 차량에 각각 연결되면 차량에 마련된 서버를 통해 이미지 프레임 및 레이더 정보를 입력 받을 수 있다. 또한, 입력부는, 카메라(C)로부터 객체 박스가 표시된 이미지 프레임을 입력 받지만, 카메라ⓒ로부터 객체 박스가 표시되지 않은 이미지 프레임을 입력 받는 경우, 이미지 프레임에 객체 탐지 기술을 직접 적용하여 객체 박스를 표시할 수 있다. 이를 위해, 저장부에는 입력부에서 객체 탐지 기술을 수행하기 위한 사전에 학습 된 딥러닝 모델이 더 저장될 수 있다. 교정부는, 객체 박스가 표시된 이미지에 레이더 정보를 매칭하여 객체 박스에 레이더 포인트를 표시한다. 이때, 레이더 정보에는, 반사된 대상의 방향 값, 거리 값, 속도 값 및 레이더 반사 면적 등이 포함될 수 있다. 보다 구체적으로, 교정부는, 레이더 센서(L)로부터 전달받은 레이더 정보를 분석하여 레이더 포인트를 산 출할 수 있다. 또한, 교정부는, 카메라(C)로부터 전달받은 이미지 내에 표시된 객체 박스와 레이더 포인트를 매칭하여 객 체 박스에 대응하는 레이더 포인트를 객체 박스 내부에 표시할 수 있다. 여기서, 교정부는, 서로 다른 장치인 카메라(C) 및 레이더 센서(L)로부터 입력된 이미지와 정보를 사용하 기 위해, 서로 다른 장치의 관계를 교정(Calibration)할 수 있다. 이를 통해, 교정부는, 레이더 센서(L)가 탐지하여 전달한 레이더 정보로부터 복수의 레이더 포인트를 산출 하고, 카메라(C)로부터 전달받은 이미지에 복수의 레이더 포인트를 교정하여 객체와 복수의 레이더 포인트를 매 칭하며, 객체와 매칭된 레이더 포인트를 객체 박스에 표시하여 이미지와 레이더 정보를 융합할 수 있다. 한편, 특징 추출부는 이미지에 존재하는 객체 박스 중 어느 하나의 객체 박스를 선택하여 객체의 특징을 추출하고, 객체 박스에 표시된 레이더 포인트의 레이더 정보를 전처리한다. 이를 위해, 특징 추출부는 도 1에 도시된 바와 같이, 객체 특징 추출부와 레이더 정보 처리부를 포함할 수 있다. 먼저, 객체 특징 추출부는, 객체 박스 중 어느 하나의 객체 박스를 선택하고, 선택된 객체 박스의 객체 이 미지를 사전에 학습된 딥러닝 모델에 입력하여 객체의 특징을 추출할 수 있다. 보다 구체적으로, 사전에 마련된 딥러닝 모델에 선택한 객체 박스의 객체 이미지만을 입력하여 객체의 특징을 추출할 수 있다. 여기서, 딥러닝 모델은, 입력된 이미지에 존재하는 객체의 특징을 추출하는 인공지능 모델으로서, 합성곱 신경 망(Convolution Neural Network, CNN) 모델이 사용되는 것이 바람직하나, AlexNet 모델, GoogleNet 모델, ResNet 모델, DenseNeT 모델, Region Based CNNs 모델 및 CNNs for NPL 모델 등이 사용될 수 있어 이에 한정되 지 않는다. 이를 통해, 객체 특징 추출부는, 선택한 객체 박스의 객체 이미지를 딥러닝 모델에 입력하여 객체의 특징 을 추출할 수 있다. 한편, 레이더 정보 처리부는, 객체 박스에 표시된 레이더 포인트의 레이더 정보를 출력부의 인공신경 망 모델에 입력하기 위해, 레이더 정보를 사전에 설정된 일정 길이 값으로 전처리할 수 있다. 이와 관련하여, 레이더 정보 처리부가 레이더 포인트의 레이더 정보를 사전에 설정된 일정 길이 값으로 전 처리하는 것은, 출력부의 인공신경망 모델에 입력하기 위한 것이다. 이러한, 인공신경망 모델의 입력은, 고정된 데이터 길이 값으로 입력되어야 하지만, 객체 박스에 매칭되는 레이 더 포인트의 개수가 가변적이므로 사전에 설정된 일정 길이 값보다 레이더 포인트가 정렬된 레이더 정보의 개수 가 적을 수 있다. 이를 위해, 레이더 정보 처리부는, 객체 박스에 매칭된 레이더 포인트를 정렬하여 사전에 설정된 일정 길 이 값을 갖도록 전처리를 수행할 수 있다. 보다 구체적으로, 레이더 정보 처리부는, 객체 박스에 표시된 레이더 포인트의 레이더 정보를 레이더 반사 면적 값을 기준으로 내림차순 정렬할 수 있다. 여기서, 레이더 반사 면적 값은 표적에서 반사된 에너지의 양적인 척도를 나타내는 값으로서, 회전 방향에 따라 서로 다른 값으로 측정되어 레이더 정보에 포함될 수 있다. 이에, 레이더 정보 처리부는, 적어도 하나 이상의 레이더 포인트의 레이더 정보 각각에 포함된 레이더 반 사 면적 값을 확인하여 내림차순으로 레이더 정보를 정렬할 수 있다. 이후, 레이더 정보 처리부는, 정렬된 레이더 정보의 개수가 사전에 설정된 일정 길이 값을 갖도록 잔여 데 이터를 처리할 수 있다. 보다 구체적으로, 레이더 정보 처리부는, 객체 박스에 매칭된 레이더 포인트의 개수가 부족하여 사전에 설 정된 일정 길이 값보다 적은 경우, 정렬된 레이더 정보를 제외한 나머지 잔여 데이터들을 0으로 처리하여 객체박스의 레이더 포인트의 레이더 정보가 일정 길이 값을 갖도록 전처리할 수 있다. 한편, 출력부는, 객체의 특징 및 레이더 정보를 인공신경망 모델에 입력하여 레이더 포인트의 정상 여부를 출력한다. 이를 위해, 출력부는, 특징 추출부로부터의 객체의 특징과 전처리된 레이더 정보를 1차원 형태로 결 합할 수 있다. 이때, 인공신경망 모델은, 입력 데이터에 대응되는 출력 데이터로서, 객체 박스에 존재하는 적어도 하나 이상의 레이더 포인트의 정상 결과와 정상으로 판단된 레이더 포인트의 레이더 인덱스를 출력할 수 있다. 이러한, 인공신경망 모델은, 객체 박스에 존재하는 적어도 하나 이상의 레이더 포인트의 정상 결과를 출력하기 위한 BCE(Binary Cross Entropy) 손실 함수를 사용할 수 있다. 여기서, BCE 손실함수는, 2개의 레이블 클래스가 존재할 때 사용되는 엔트로피로서 아래의 [수학식 1]과 같이 정의된다. [수학식 1]"}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, L은 손실함수이고, N은 데이터의 개수이고, t는 실제 값이며, y는 예측 값이다. 이에, 인공신경망 모델은, BCE를 통해 계산된 값을 기초하여 객체 박스에 표시된 적어도 하나 이상의 레이더 포 인트의 전체가 비정상 포인트라면 정상 결과로서 0을 출력하고, 적어도 하나의 레이더 포인트가 정상이라면 정 상 결과로서 1을 출력할 수 있다. 또한, 인공신경망 모델은, 정상으로 판단된 레이더 포인트의 레이더 인덱스를 출력하기 위한 CCE(Categorical Cross Entropy) 손실함수를 더 사용할 수 있다. 여기서, CCE는, BCE와 같이 2개 이상의 레이블 클래스가 존재할 때 사용되는 엔트로피로서 아래의 [수학식 2]와 같이 정의된다. [수학식 2]"}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, L은 손실함수이고, N은 데이터의 개수이고, C는 클래스의 개수이고, t는 실제 값이며, y는 예측 값이다. 이에, 인공신경망 모델은, BCE를 통해 정상 결과가 1로 출력되어 레이더 포인트 중 정상 레이더 포인트가 존재 할 때, 해당 레이더 포인트를 CCE를 통해 계산된 값을 기초하여 레이더 인덱스를 출력할 수 있다. 예를 들면, 지정된 레이더 정보의 길이가 3, 정답 값이 [1, 0, 0]으로 가정하고, 입력된 최종 값이 [2.0, 1.0, 0.1]일 때, 인공신경망 모델은 Softmax 함수를 이용하여 입력된 최종 값이 1이 되도록 [0.7, 0.2, 0.1]로 변환 하고, 예측 값과 정답 값을 비교하여 CCE를 계산하여 가중치를 산출하며, 이러한 가중치를 이용하여 레이더 인 덱스를 출력한다. 이로써, 출력부는, 인공신경망 모델을 이용하여 인공신경망이 출력한 레이더 포인트의 정상 결과와 정상으 로 판단된 레이더 포인트의 레이더 인덱스를 출력하여 레이더 센서(L)의 고장을 분류할 수 있다. 한편, 학습부는, 출력부에서 이용되는 인공신경망 모델에 학습 데이터를 입력하여 업데이트를 수행할 수 있다. 보다 구체적으로, 도 3을 참조하면, 학습부는 출력부에서 이용되는 딥러닝 기반 인공신경망 모델에 학습 데이터를 입력하고, 인공신경망이 출력하는 출력 데이터와 정답 값을 비교하여 손실함수를 계산하며, 계산 된 손실함수에 기초하여 딥러닝 기반 인공신경망 모델을 업데이트할 수 있다. 예를 들어, 학습부는, 딥러닝 기반 인공신경망 모델에 학습 데이터를 입력한다. 이때, 인공신경망 모델은 입력 데이터에 대응하는 출력 데이터로서 예측값 [0.3, 0.7]을 출력한다. 이후, 학습부는 인공신경망 모델 이 출력한 예측값 [0.3, 0.7]과 학습 데이터의 정답값인 [0.0, 1.0]을 비교하여 손실 값을 계산하고, 계산된 손 실 값을 기초로 인공신경망 모델을 업데이트한다. 이를 통해, 학습부는, 출력부에서 이용하는 인공신경망 모델을 지속적으로 업데이트할 수 있고, 출력 부는 업데이트가 완료된 인공신경망 모델을 이용하여 레이더 포인트의 정상 결과와 정상으로 판단된 레이더 포인트의 레이더 인덱스를 출력함으로써, 레이더 센서(L)의 고장을 분류하는 정확성을 높일 수 있다. 한편, 통신부는, 카메라(C) 및 레이더 센서(L)와 같은 외부 기기 또는 외부 네트워크로부터 이미지 및 정 보를 송수신하기 위해 마련되는 것으로 이를 통해 레이더 센서(L) 고장 분류 방법을 수행하기 위한 소프트웨어 를 입력 받을 수 있다. 이와 관련하여, 통신부는, 출력부가 출력한 레이더 포인트의 정상 결과와 정상으로 판단된 레이더 포 인트의 레이더 인덱스를 외부 서버에 전달할 수 있고, 외부 서버로부터 인공신경망 모델에 학습되는 학습 데이 터를 전달받을 수 있다. 이로써, 레이더 센서 고장 분류 장치는, 상술한 입력부, 교정부, 특징 추출부, 출력부 , 학습부 및 통신부를 통해 카메라(C)에서 측정된 이미지 프레임과 레이더 센서(L)로부터 레이 더 정보를 입력 받고, 레이더 정보에 기초하여 이미지 프레임에 표시된 레이더 포인트의 정상 여부를 판단하여 해당 레이더 센서(L)가 정상 인지 고장 인지 분류할 수 있다. 한편, 도 4 및 도 5는 본 발명의 실시예에 따른 레이더 센서 고장 분류 방법의 흐름 도면으로서, 본 발명의 실 시예에 따른 레이더 센서 고장 분류 방법은 도 1 내지 도 3에 도시된 카메라와 레이더 센서를 이용한 딥러닝 기 반 레이더 센서 고장 분류 장치와 동일한 구성 상에서 진행되므로, 도 1 내지 도 3의 레이더 센서 고장 분류 장 치와 동일한 도면 부호를 부여하고, 반복되는 설명은 생략하기로 한다. 도 4을 참조하면, 본 발명의 실시 예에 따른 레이더 센서(L) 고장 분류 방법은, 딥러닝 기반 레이더 센서 고장 분류 장치로부터 수행되는 레이더 센서(L) 고장 분류 방법으로써, 입력 단계, 교정 단계, 특징 추출 단계 및 출력 단계를 포함한다. 먼저, 레이더 센서 고장 분류 장치는 카메라(C)로부터 객체 박스가 표시된 이미지 프레임을 입력 받고, 레 이더 센서(L)로부터 레이더 정보를 입력 받는 입력 단계를 수행한다. 이후, 레이더 센서 고장 분류 장치는, 객체 박스가 표시된 이미지에 레이더 정보를 매칭하여 객체 박스에 레이더 포인트를 표시하는 교정 단계를 수행한다. 보다 구체적으로, 레이더 센서 고장 분류 장치는, 레이더 센서(L)로부터 전달받은 레이더 정보를 분석하여 레이더 포인트를 산출하고, 이미지 내에 표시된 객체 박스와 레이더 포인트를 매칭하여 객체 박스에 대응하는 레이더 포인트를 표시하는 교정 단계를 수행할 수 있다. 그리고, 레이더 센서 고장 분류 장치는, 이미지에 존재하는 객체 박스 중 어느 하나의 객체 박스를 선택하 여 객체의 특징을 추출하고, 객체 박스에 표시된 레이더 포인트의 레이더 정보를 전처리하는 특징 추출 단계 를 수행한다. 이때, 특징 추출 단계는, 도 5에 도시된 바와 같이 객체 박스의 객체 이미지를 사전에 학습된 딥러닝 모델 에 입력하여 객체의 특징을 추출하는 객체 특징 추출 단계와 객체 박스에 표시된 레이더 포인트의 레이더 정보를 인공신경망 모델에 입력하기 위해, 레이더 정보를 사전에 설정된 일정 길이 값으로 전처리하는 레이더 정보 처리 단계를 포함할 수 있다. 이와 관련하여, 레이더 정보 처리 단계는, 레이더 정보를 사전에 설정된 일정 길이 값으로 전처리하되, 레 이더 정보를 레이더 반사 면적 값을 기준으로 내림차순 정렬하고, 정렬된 레이더 정보의 개수가 일정 길이 값보 다 적은 경우, 잔여 데이터 값을 0으로 처리하여 전처리할 수 있다. 이후, 레이더 센서 고장 분류 장치는, 객체의 특징 및 레이더 정보를 인공신경망 모델에 입력하여 레이더 포인트의 정상 여부를 출력하는 출력 단계를 수행한다. 이러한, 레이더 센서 고장 분류 장치는, 출력 단계에서 객체의 특징과 레이더 정보를 1차원 형태로 결 합하여 인공신경망 모델에 입력하고, 이때, 인공신경망 모델은 입력 데이터에 대응되는 출력 데이터로서, 객체 박스에 존재하는 적어도 하나 이상의 레이더 포인트의 정상 결과와 정상으로 판단된 레이더 포인트의 레이더 인 덱스를 출력할 수 있다. 이로써, 레이더 센서 고장 분류 장치는, 레이더 센서(L) 고장 분류 방법을 수행하여 이미지 프레임에 표시 된 레이더 포인트의 정상 여부를 판단하여 해당 레이더 센서(L)가 정상 인지 고장 인지 분류할 수 있다.이와 같은, 레이더 센서 고장 분류 방법은 다양한 컴퓨터 구성요소를 통하여 수행될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로 그램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것들이거니와 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM, DVD 와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨 어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사 용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치는 본 발명에 따른 처 리를 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상에서는 본 발명의 다양한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시예에 한정"}
{"patent_id": "10-2022-0066100", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야에서 통상 의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사 상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2022-0066100", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치의 블 록 도면이다. 도 2은 도 1의 카메라와 레이더 센서를 이용한 딥러닝 기반 레이더 센서 고장 분류 장치의 예시 도면이다. 도 3는 도 1의 학습부의 예시 도면이다. 도 4 및 도 5는 본 발명의 실시예에 따른 레이더 센서 고장 분류 방법의 흐름 도면이다."}
