{"patent_id": "10-2023-0083308", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0001137", "출원번호": "10-2023-0083308", "발명의 명칭": "연합 학습을 위한 소수 통신 라운드 학습 방법 및 시스템", "출원인": "한국과학기술원", "발명자": "문재균"}}
{"patent_id": "10-2023-0083308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "연합 학습 시스템에 의해 수행되는 소수의 통신 라운드 학습 방법에 있어서, 소수의 통신 라운드 동안 각 클라이언트로부터의 메타 학습 기반의 연합 학습을 통해 인공지능 모델을 업데이트하는 모델 준비 단계; 및 상기 준비된 인공지능 모델을 공통 태스크에 대한 추론을 위한 클라이언트 그룹에게 제공하는 모델 배치 단계를 포함하는 소수의 통신 라운드 학습 방법."}
{"patent_id": "10-2023-0083308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 모델 준비 단계는, 각 에피소드에 대해 서버에서 학습에 참여할 각 클라이언트를 선택하고, 상기 서버에서 현재 에피소드의 초기모델을 상기 선택된 각 클라이언트에게 전달하는 단계 를 포함하는 소수의 통신 라운드 학습 방법."}
{"patent_id": "10-2023-0083308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 모델 준비 단계는, 상기 선택된 각 클라이언트의 로컬 데이터 셋을 지원 셋과 쿼리 셋으로 구분하는 단계 를 포함하는 소수의 통신 라운드 학습 방법."}
{"patent_id": "10-2023-0083308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 모델 준비 단계는, 상기 선택된 각 클라이언트에서 서버로부터 글로벌 모델과 글로벌 프로토타입을 다운로드하고, 상기 다운로드된글로벌 모델을 기반으로 상기 선택된 각 클라이언트의 로컬 데이터 셋으로부터 구분된 지원 셋을 이용하여 각클래스에 대한 로컬 프로토타입을 계산하는 단계를 포함하는 소수의 통신 라운드 학습 방법."}
{"patent_id": "10-2023-0083308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 모델 준비 단계는, 상기 서버로부터 다운로드된 글로벌 모델, 글로벌 프로토타입 및 상기 계산된 로컬 프로토타입을 기반으로 상기선택된 각 클라이언트에서 로컬 손실을 계산하고, 상기 계산된 로컬 손실을 기반으로 그레디언트 하강법을 통해로컬 모델을 업데이트하고, 상기 업데이트된 로컬 모델과 상기 계산된 로컬 프로토타입을 상기 서버로전송하고, 상기 서버에서 상기 전송된 로컬 모델과 로컬 프로토타입을 집계하는 단계 를 포함하는 소수의 통신 라운드 학습 방법."}
{"patent_id": "10-2023-0083308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2025-0001137-3-제5항에 있어서,상기 모델 준비 단계는, 글로벌 프로토타입 지원 학습(Global Prototype Assisted Learning; GPAL)을 통해 로컬 프로토타입을 사용하여계산된 로컬 손실과 글로벌 프로토타입의 보조 손실에 기초하여 로컬 파라미터를 업데이트하는 단계를 포함하는 소수의 통신 라운드 학습 방법."}
{"patent_id": "10-2023-0083308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 모델 준비 단계는, 상기 선택된 각 클라이언트로부터 상기 서버에서 집계를 통해 획득된 글로벌 모델과 글로벌 프로토타입을 다운로드하고, 상기 다운로드된 글로벌 모델과 글로벌 프로토타입에 기초하여 쿼리 셋을 이용하여 로컬 모델을 메타업데이트하고, 상기 서버에서 상기 메타 업데이트된 로컬 모델을 집계하는 단계 를 포함하는 소수의 통신 라운드 학습 방법."}
{"patent_id": "10-2023-0083308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 모델 배치 단계는, 테스트 샘플을 이용하여 상기 소수 라운드 동안의 연합 학습을 통해 획득된 글로벌 모델과 글로벌 프로토타입을기반으로 예측을 수행하는 단계 를 포함하는 소수의 통신 라운드 학습 방법."}
{"patent_id": "10-2023-0083308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "연합 학습 시스템에 의해 수행되는 소수의 통신 라운드 학습 방법을 실행시키기 위해 컴퓨터 판독 가능한 저장매체에 저장된 컴퓨터 프로그램에 있어서,상기 소수의 통신 라운드 학습 방법은,소수의 통신 라운드 동안 각 클라이언트로부터의 메타 학습 기반의 연합 학습을 통해 인공지능 모델을 업데이트하는 모델 준비 단계; 및 상기 준비된 인공지능 모델을 공통 태스크에 대한 추론을 위한 클라이언트 그룹에게 제공하는 모델 배치 단계를 포함하는 것을 특징으로 하는 컴퓨터 판독 가능한 저장매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0083308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "연합 학습 시스템에 있어서, 소수의 통신 라운드 동안 각 클라이언트로부터의 메타 학습 기반의 연합 학습을 통해 인공지능 모델을 업데이트하는 모델 준비부; 및 상기 준비된 인공지능 모델을 공통 태스크에 대한 추론을 위한 클라이언트 그룹에게 제공하는 모델 배치부를 포함하는 연합 학습 시스템."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "연합 학습을 위한 소수 통신 라운드 학습 방법 및 시스템이 개시된다. 일 실시예에 따른 연합 학습 시스템에 의 해 수행되는 소수의 통신 라운드 학습 방법은, 소수의 통신 라운드 동안 각 클라이언트로부터의 메타 학습 기반 의 연합 학습을 통해 인공지능 모델을 업데이트하는 모델 준비 단계; 및 상기 준비된 인공지능 모델을 공통 태스 크에 대한 추론을 위한 클라이언트 그룹에게 제공하는 모델 배치 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 연합 학습 기술에 관한 것이다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "연합 학습(federated learning)이란 복수의 사용자들이 연합하여 하나의 인공지능 모델을 학습하는 방법이다. 구체적으로, 복수의 사용자들은 각자 소지하고 있는 학습 데이터를 사용하여 인공지능 모델을 학습하고 학습된 인공지능 모델을 중앙 서버로 업로드한다. 중앙 서버는 업로드된 인공지능 모델들을 규합하여 하나의 모델을 생성하고, 이를 다시 각 사용자들에게 분배한다. 위 과정은 하나의 통신 라운드로 정의되며, 연합 학습은 수백 내지 수천 개의 학습 라운드를 통해 안정된 인공지능 모델을 복수의 사용자들이 연합하여 학습하는 것을 목표로 한다. 분산 학습(distributed learning)과 구별되는 연합 학습의 특징은 각 사용자들이 지니고 있는 데이터의 프라이버시를 존중한다는 점으로, 각 사용자들은 중앙 서버에게 인공지능 모델을 전송할 수는 있지만, 해당 사 용자가 소지하고 있는 데이터를 업로드하지 않는다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "임의의 클라이언트 그룹이 연합 학습의 몇 라운드 내에서 자체 목적으로 글로벌 모델을 획득할 수 있는 초기 모 델을 설계하는 방법 및 시스템을 제공할 수 있다. 메타학습 접근 방식을 취해 초기 모델을 구성하여 보이지 않을 수 있는 태스크를 가진 모든 그룹이 연합학습 라 운드 내에서 높은 정확도의 글로벌 모델을 획득할 수 있도록 하는 방법 및 시스템을 제공할 수 있다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "연합 학습 시스템에 의해 수행되는 소수의 통신 라운드 학습 방법은, 소수의 통신 라운드 동안 각 클라이언트로 부터의 메타 학습 기반의 연합 학습을 통해 인공지능 모델을 업데이트하는 모델 준비 단계; 및 상기 준비된 인 공지능 모델을 공통 태스크에 대한 추론을 위한 클라이언트 그룹에게 제공하는 모델 배치 단계를 포함할 수 있 다. 상기 모델 준비 단계는, 각 에피소드에 대해 서버에서 학습에 참여할 각 클라이언트를 선택하고, 상기 서버에서 현재 에피소드의 초기 모델을 상기 선택된 각 클라이언트에게 전달하는 단계를 포함할 수 있다. 상기 모델 준비 단계는, 상기 선택된 각 클라이언트의 로컬 데이터 셋을 지원 셋과 쿼리 셋으로 구분하는 단계 를 포함할 수 있다. 상기 모델 준비 단계는, 상기 선택된 각 클라이언트에서 서버로부터 글로벌 모델과 글로벌 프로토타입을 다운로 드하고, 상기 다운로드된 글로벌 모델을 기반으로 상기 선택된 각 클라이언트의 로컬 데이터 셋으로부터 구분된 지원 셋을 이용하여 각 클래스에 대한 로컬 프로토타입을 계산하는 단계를 포함할 수 있다. 상기 모델 준비 단계는, 상기 서버로부터 다운로드된 글로벌 모델, 글로벌 프로토타입 및 상기 계산된 로컬 프 로토타입을 기반으로 상기 선택된 각 클라이언트에서 로컬 손실을 계산하고, 상기 계산된 로컬 손실을 기반으로 그레디언트 하강법을 통해 로컬 모델을 업데이트하고, 상기 업데이트된 로컬 모델과 상기 계산된 로컬 프로토타 입을 상기 서버로 전송하고, 상기 서버에서 상기 전송된 로컬 모델과 로컬 프로토타입을 집계하는 단계를 포함 할 수 있다. 상기 모델 준비 단계는, 글로벌 프로토타입 지원 학습(Global Prototype Assisted Laerning; GPAL)을 통해 로 컬 프로토타입을 사용하여 계산된 로컬 손실과 글로벌 프로토타입의 보조 손실에 기초하여 로컬 파라미터를 업 데이트하는 단계를 포함할 수 있다. 상기 모델 준비 단계는, 상기 선택된 각 클라이언트로부터 상기 서버에서 집계를 통해 획득된 글로벌 모델과 글 로벌 프로토타입을 다운로드하고, 상기 다운로드된 글로벌 모델과 글로벌 프로토타입에 기초하여 쿼리 셋을 이 용하여 로컬 모델을 메타 업데이트하고, 상기 서버에서 상기 메타 업데이트된 로컬 모델을 집계하는 단계를 포함할 수 있다. 상기 모델 배치 단계는, 테스트 샘플을 이용하여 상기 소수 라운드 동안의 연합 학습을 통해 획득된 글로벌 모 델과 글로벌 프로토타입을 기반으로 예측을 수행하는 단계를 포함할 수 있다. 연합 학습 시스템에 의해 수행되는 소수의 통신 라운드 학습 방법을 실행시키기 위해 컴퓨터 판독 가능한 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 소수의 통신 라운드 학습 방법은, 소수의 통신 라운드 동안 각 클라이언트로부터의 메타 학습 기반의 연합 학습을 통해 인공지능 모델을 업데이트하는 모델 준비 단계; 및 상 기 준비된 인공지능 모델을 공통 태스크에 대한 추론을 위한 클라이언트 그룹에게 제공하는 모델 배치 단계를 포함할 수 있다. 연합 학습 시스템은, 소수의 통신 라운드 동안 각 클라이언트로부터의 메타 학습 기반의 연합 학습을 통해 인공 지능 모델을 업데이트하는 모델 준비부; 및 상기 준비된 인공지능 모델을 공통 태스크에 대한 추론을 위한 클라 이언트 그룹에게 제공하는 모델 배치부를 포함할 수 있다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "연합 학습에 필요한 통신 라운드를 획기적으로 감소시킬 수 있다. 일반적으로 연합 학습을 수행하기 위해서는 수천 및 수만 번의 통신 라운드가 필요하지만, 본 발명은 열 번 이내의 통신 라운드를 사용하여 인공지능 모델 을 연합 학습할 수 있다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 도 1은 연합 학습 동작을 설명하기 위한 도면이다. 기존의 연합 학습은 일반적으로 중앙 서버와 각 사용자들 사이에 수많은 통신 라운드를 요구한다. 이러한 통신 조건은 시간과 대역폭 조건이 민감한 환경에서 연합 학습을 수행하기 어렵게 만든다. 특히, 차량이나 드론처럼 실시간 통신을 수행하는 응용 사례에서는 수많은 통신 라운드가 병목 현상을 일으킬 수 있다. 또한, 기존의 연 합 학습은 학습 시에 사용된 환경이 아닌 새로운 환경에 배치되었을 때 성능이 크게 감소한다는 단점이 있다. 예를 들어, '강아지를 구분하는 태스크'를 통해 학습된 연합 학습 모델은 '고양이를 구분하는 태스크(task)'에 배치되었을 때 좋은 성능을 낼 수 없다. 실시예에서는 서비스 제공자의 관점에서 연합 학습의 몇 라운드 내에서 클라이언트의 모든 그룹(자체 태스크에 집중)에 신속하게 적응할 수 있는 초기 모델을 준비하는 동작에 대하여 설명하기로 한다. 도 2는 일 실시예에 있어서, 소수의 통신 라운드를 위한 연합 학습 동작을 설명하기 위한 도면이다. 연합 학습 시스템은 메타학습(모델이 메타학습 되었을 때 추론 태스크가 보이지 않는 경우에도 신뢰할 수 있는 예측을 가능하게 함)을 채택하여 소수 라운드 연합 학습을 가능하게 하는 초기 모델을 준비할 수 있다. 다시 말해, 연합 학습 시스템은 몇 라운드 다운스트림 연합 학습에 대한 초기 모델을 메타학습할 수 있다. 메타학습 이 끝나면 서비스 제공자는 연합 학습의 빠른 라운드를 통해 협업한 후 공통 태스크를 해결하고자 하는 클라이 언트 그룹에게 학습된 모델을 제공할 수 있다. 이러한 클라이언트는 초기 메타학습 단계의 참가자일 수도 있고아닐 수도 있으며, 분류 태스크는 일반적으로 메타학습 중에 보이지 않는 것으로 간주될 수 있다. 도 2를 참고 하면, 작은 목표값 R이 주어지면, 연합 학습 시스템은 임의의 클라이언트 그룹에 대해 R 라운드 연합 학습을 활 성화하기 위해 에피소드식 학습 접근법을 취할 수 있다. 연합 학습 시스템은 로컬 손실의 평균 를 최소화할 초기 모델 을 탐색할 수 있다. 여기서, 은 배치 단계에서 미래의 클라이언트 간 연합 학 습의 R 라운드를 통해 업데이트될 모델 이다. 이는 소수 라운드 연합 학습에 맞춘 메타학습 전략을 제안한 첫 번째 태스크이다. 모델 준비는 실시간 요구 사항이 아니며 대역폭 요구가 희박할 때 종종 수행될 수 있다는 점도 언급할 가치가 있다. 도 1의 연합 학습 동작과 도 2에서 제안된 소수 라운드 연합 학습 동작에 대하여 비교하여 설명하기로 한다. 도 2에서 제안된 소수 라운드 연합 학습 동작은 로컬 클라이언트에서 개인화된 최적화 모델을 시작하는 연합 메 타학습에 대한 최근 태스크 라인과 관련하여 다른 목적과 접근 방식을 가지고 있다. 도 1의 접근 방식의 목표는 배치 단계에서 그레디언트 하강의 몇 단계 내에서 각 클라이언트에서 개인화된 로컬 모델을 획득하는 것이다. 이러한 목표를 달성하기 위해 준비 단계에서는 먼저 각 참가자에 몇 단계의 로컬 업 데이트 및 메타 업데이트가 독립적으로(자체 로컬 데이터로) 수행되고, 다양한 참가자의 데이터를 활용하기 위 해 연합 학습(또는 집계)이 채택된다. 이러한 접근 방식은 로컬 손실의 평균 를 최소화하는 를 추구하며, 여기서, 는 로컬 데이터 Dk를 사용하여 다수의 그레디언트 단계를 통해 에서 업데이 트된 로컬 모델이다. 배치 단계에서 로컬 클라이언트 모델에 중점을 두는 개인화된 연합 학습과 달리, 도 2의 소수 라운드 학습은 글로벌 모델을 획득하기 위한 연합 학습 배치의 능력을 이어받는다. 따라서, 도 2의 경우, 배치 시 R 라운드 연합 학습 시나리오를 모방하기 위해 준비 단계에서 연합 학습이 채택될 수 있다. 준비 단계"}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "에서는 협업 R 연합 학습 라운드 후 각 참가자로부터 메타 업데이트가 수행된다. 요약하면, 도 2는 소수 라운 드의 연합 학습 내에서 글로벌 모델로 이어지는 초기 모델을 준비하는 것을 목표로 하는 반면, 도 1의 개인화된 연합 학습은 로컬 데이터만을 기반으로 하는 로컬 업데이트의 소수 단계 내에서 개인화된 모델로 이어지는 초기 모델을 목표로 한다. 도 3을 참고하면, 연합 학습 시스템은 소수의 통신 라운드를 위해 모델 준비 단계 및 모델 배치 단계를 수행할 수 있다. 모델 준비 단계는 다수의 통신 라운드를 사용하는 연합 학습을 통해 임의의 실전 상황에 배치될 수 있는 인공지능 모델을 학습하는 과정이다. 모델 배치 단계는 앞서 학습된 모델을 사전에 경험하지 못한 임의의 테스트 상황에 배치하는 단계이다. 모델 준비 단계에서는 사전에 학습된 모델을 출발점으로 소수의 통신 라운 드 동안 새로운 태스크에 모델이 적응하는 과정을 거친다. 즉, 모델 준비 단계는 임의의 새로운 태스크에 소수 의 통신 라운드만을 사용하는 연합 학습을 통해 쉽게 적응할 수 있는 특별한 인공지능 모델을 연합 학습을 통해 학습하는 과정이다. 모델 준비 단계는 메타학습 기술을 사용할 수 있다. 메타학습이란 다른 성질을 가지는 여러 개의 태스크를 통 해 모델이 각 태스크에 적응하는 법을 배움으로써, 최종적으로 이전에 경험하지 못한 새로운 태스크에 마주치더 라도 인공지능 모델이 빠르게 적응하도록 하는 인공지능 학습의 부류이다. 메타학습은 이중 미분 구조를 갖는 다는 특징이 있는데, 내부의 미분은 새로운 태스크에 적응하는 역할을 담당하고, 바깥의 미분은 새로운 태스크 에 얼마나 잘 적응했는지 평가하는 역할을 담당한다. 각 미분에 대해 서로 다른 데이터를 사용하는데, 내부 미 분에 사용되는 데이터는 서포트 셋, 바깥 미분에 사용되는 데이터는 쿼리 셋이라고 부른다. 이러한 모델 준비 단계는 복수 개의 하위 단계로 구성될 수 있다. 첫째로, 일반 모델 업데이트 단계는 소수의 통신 라운드 동안 복수의 참가자들이 연합하여 모델을 학습하는 단 계이며 일반적인 메타학습의 내부 미분에 해당하는 단계이다. 추가로, 제안 알고리즘은 성능을 향상하기 위해 프로토타입을 사용한다. 프로토타입이란 데이터의 각 카테고리의 대표값이며, 특징 공간에서 각 카테고리 별 평균값으로 계산될 수 있다. 제안된 알고리즘에서 각 참가자들은 중앙 서버로 개개인이 보유한 데이터의 프로 토타입을 업로드하고, 중앙 서버는 업로드된 프로토타입에 대한 평균을 계산하여 각 참자가들에게 다시 전송할 수 있다. 중앙 서버에서 계산된 프로토타입은 전체 참가자들의 데이터 평균 정보를 지니고 있기 때문에 각 참 가자들이 인공지능 모델을 업데이트할 때 더 많은 데이터를 간접적으로 고려할 수 있도록 도와주어 성능을 향상 시킬 수 있다.둘째로, 메타 모델 업데이트 단계는 메타학습의 외부 미분의 해당하는 단계로써, 일반 모델 업데이트 단계에서 주어진 태스크에 얼마나 인공지능 모델이 잘 적응 하였는지를 측정하고, 측정된 적응 정보를 기반으로 손실 함 수를 계산하여 실제로 모델을 업데이트한다. 메타 업데이트는 연합 학습을 시작하기 위해 초기화되는 모델의 값을 조절하여, 이후 모델 배치 단계에서 어떠한 태스크가 오더라도 빠르고 정확하게 적응할 수 있도록 도와준 다. 보다 상세하게는, N을 시스템의 클라이언트 수라고 하자. 연합 학습을 사용하면 데이터 셋 Dk을 가진 각 분산 노드 k가 중앙 서버를 포함한 다른 사람에게 데이터를 공개하지 않고도 글로벌 모델 의 반복 학습에 참여할 수 있도록 한다. 주어진 라운드 r이 시작되면 각 K개의 참여 노드(일반적으로 매 라운드마다 새로 선택됨)는 서버에서 글로벌 모델 을 다운로드하고 자체 로컬 데이터 Dk를 사용하여 업데이트할 수 있다. 업데이트된 로컬 모델 는 상대적인 데이터 셋 크기 에 따라 모두 새 모델 로 집계될 서버에 업로드될 수 있다. 같은 과정이 반복될 수 있다. 연합 학습은 일반적으로 원하는 정확도를 달성하기 위해 상당한 수의 글로벌 라 운드가 필요하며, 각 라운드는 상당한 통신 리소스를 차지한다. 클라이언트 그룹이 몇 개의 연합 학습 라운드를 추구할 수 있도록 초기 모델 을 준비할 때, 에피소드 학습을 기반으로 메타학습을 사용하는데, 여기서, 각 에피소드는 R 연합 학습 라운드를 모방한 다음 추론을 수행하도록 구성될 수 있다. 메타학습이 끝나면, 배치 단계에서 서비스 제공자는 연합 학습의 R 라운드에 대해 협력한 후 일부 공통 태스크(메타학습 중에 보이지 않을 수 있음)에 대한 추론을 추구하고자 하는 모든 클라이언트 그룹에 게 학습된 초기 모델 을 제공할 수 있다. 다음으로, 메타학습(모델 준비 단계)에 대하여 설명하기로 한다. 더 정확히 말하면, 메타학습 단계는 목적 함 수를 최소화하는 것이다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 At는 에서 K 명의 참가자가 추출된 특정 그룹이고, 각각 K명의 참가자가 추출된 모든 가능한 그룹 에 대한 분포, 은 에서 시작하는 그룹 At에서 시작하는 연합 학습의 라운드 이후의 모델, Dk는 참가자 그룹 At의 K명의 참가자의 로컬 데이터 셋이다. 이와 비교하여, 종래의 개인화된 연합 학습방법에 대한 목적 함 수는 이며, 여기서 N은 시스템의 클라이언트 수이고 는 에서 시 작하는 클라이언트 k에서 몇 가지 그레디언트 단계를 거친 모델이다. 또한, 연합 학습 시스템은 기존의 연합 학습에서의 를 최소화하는 것을 목표로 반복할 수 있다. 학습이 시작되기 전에, 연합 학습 시스템은 각 클라이언트 k에 대해 로컬 데이터 셋을 지원 셋 Sk과 쿼리 셋 Qk 로 나눌 수 있다. 연합 학습의 실제 R 라운드와 일치하는 학습 환경을 만들고 배치 시 추론을 수행하기 위해 메타학습 단계의 각 에피소드에서 지원 셋을 사용하여 R 연합 라운드를 통해 모델을 업데이트한 다음 쿼리 셋을 사용하여 최종 조정(메타 업데이트)할 수 있다. 즉, 지원 셋은 연합 학습의 R 라운드를 수행하여 태스크 해결 방법을 학습하는 데 활용될 수 있다. 쿼리 셋은 지원 셋을 이용하여 수행된 태스크의 성능을 평가하고 메타 업 데이트 프로세스를 수행하는 데 사용될 수 있다. 모델이 일련의 에피소드에 노출될 때 상기 언급된 전체적인 프로세스가 반복될 수 있다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "메타학습의 자세한 절차는 알고리즘 1에 나와 있다. 간단한 요약을 위해 각 에피소드 t가 시작되면 서버는 새 로운 K 명의 참가자 셋을 선택할 수 있다. 마지막 에피소드 단계에서 이월된 모델 는 현재 에피소드의 초기모델 이 될 수 있다. 로컬 지원 셋을 통한 로컬 업데이트 및 글로벌 집계로 구성된 연합 학습의 R라운드 후, 각 라운드는 은 로 진화할 수 있다. 다음 에피소드로 이동하기 전에 메타학습 분할(MAML spirit)에 따라 초기 모델 을 조정하기 위해 로컬 쿼리 셋을 사용하여 을 기반으로 로컬 메타 업데이트가 수행될 수 있다. 이러한 메타 업데이트가 수행된 모델이 서버에서 로 집계되면 새로운 에피소드가 시작될 수 있다. 알고리즘 1:"}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "연합 학습 시스템은 손실 함수를 정의할 때, 임베딩 공간의 간단하지만 효과적인 학습 방법인 클래스 프로토타 입과 유클리드 거리 측정법을 활용할 수 있다. 각 통신 라운드 r마다 글로벌 모델 뿐만 아니라 모든 클 래스에 대한 글로벌 프로토타입 를 집계할 수 있다. 여기서 Nc는 모든 클라이언 트의 클래스 수이다. 클래스 프로토타입은 데이터 샘플에 대한 클래스 별 평균 특징이며 알고리즘 1에서 9행으 로 계산될 수 있다. 라운드 의 시작 부분에서 서버는 글로벌 모델 과 이전 라운드 r-1로부터의 글로벌 프로토타입 을 가진다. 각 참가자 k는 7행에서와 같이 먼저 서버에서 글로벌 모델 과 글로벌 프로토타입 을 다운로드 한다. 첫 번째 라운드에는 글로벌 프로토타입이 없으므로, 참가자들은 r = 0일 때만 모델 을 다운로드 한다. 참가자 k에 대한 의 로컬 프로토타입은 다운로드된 글로벌 모델 을 사용하여 9행에서와 같이 계산되며, 관련 임베더는 c로 레이블된 로컬 지원 샘플 에 해당하는 를 출력할 수 있다. 로컬 프로토타입은 클 라이언트 k의 로컬 데이터(지원 셋)를 기반으로 계산된 클래스 c의 대표 역할을 한다. 를 참가자 k에서 모든 클래스 프로토타입 셋이라고 하자( ). 여기서, Ck는 k명의 참 가자의 모든 클래스 셋이다. 이제 , , 를 사용하여, 각 참가자 k, 에 대해 와 사이의 유클리드 거리 를 기반으로 에 따라 로컬 손실이 계산될 수 있다. 로컬 프로토타입에 기반한 의 손실 함수에만 의존하면 특히 서로 다른 클라이언트 간의 데이터 분포가 비 IID((independent, identically distributed)인 경우 모델이 편향되는 경향이 있다. 이는 일반적으로 글로벌 모델의 성능 저하로 이어진다. 이러한 문제를 해결하기 위해, 글로벌 프로토타입이 로컬 모델이 로컬 데이터에 과적합되는 것을 방지하기 위해 정규화하는 형태의 사전 지식 역할을 하는 글로벌 프로토타입 지원 학습(GPAL) 전략이 제안될 수 있다. 또한, 로컬 데이터 세트에 국한되지 않는 클래스를 반영하는 글로벌 프로토타입은 로 컬 모델이 더 일반적인 임베딩 공간을 학습하는 데 도움이 될 수 있다. r-1로부터의 글로벌 프로토타입 및 이 주어지면 보조 손실 는 에서 로 컬 프로토타입 을 으로 대체하여 계산할 수 있다. 로컬 프로토타입을 사용하여 계산된 로컬 손실 과 글로벌 프로토타입을 기반으로 한 보조 손실 에 기초하여 목적 함수는 다음과 같다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 는 균형 계수이다. r = 0의 경우 글로벌 프로토타입이 첫 번째 글로벌 라운드에서 정의되지 않았기 때문에 이다. 알고리즘 1의 11행은 글로벌 프로토타입 지원 학습을 기반으로 로 컬 업데이트를 수행하며, 여기서 는 학습률이다. 연합 학습에서 클라이언트는 E회와 같이 여러 로컬 업데이트를 수행할 수 있다. 따라서, 알고리즘 1의 9행의 로컬 프로토타입 계산, 의 손실 계산 및 11번 행의 로컬 업데이트 과정을 E회 반복하여 로컬 모델 를 획득할 수 있다. 로컬 업데이트를 수행한 후, 각 참가자 k는 업데이트된 로컬 모델 와 계산된 로컬 프로토타입 를 서버로 전달할 수 있다. 서버는 알고리즘 1의 13행 및 14행에 따라 모델 및 프로토타입을 집계할 수 있다. 여기서, 가중치 계수 는 상대적인 지원 셋 크기를 반영한다. 알고리즘 1의 13행 및 14행에 대한 로컬 업데이트 및 글로벌 라운드 집계 프로세스는 R 글로벌 라운드(r = 0, 1,..., R-1) 동안 반복될 수 있다. 서버는 주어진 에피소드에서 과 을 획득할 수 있다. 연합 학습 시스템은 라운드 로컬 메타 업데이트 및 집계를 수행할 수 있다. 각 에피소드 처리 단계가 끝날 무 렵, 참가자들은 서버에서 과 을 다운로드할 수 있다. 각 참가자 k는 쿼리 셋 Qk를 사용하여 9행에서와 같이 로컬 프로토타입 를 계산할 수 있다. 쿼리 손실 는 Qk, , 및 를 기반으로 와 유사하게 계산될 수 있다. 메타 업데이트는 에 대해 쿼리 손실의 미분을 취하도록 요구될 수 있다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "그러나, 다른 사용자 위치의 이중 미분도 필요하므로 매우 불편하다. 이중 미분 항을 무시하고 19행에서와 같 이 를 로 간단히 대체될 수 있다. 이는 원본 태스크를 포함한 메타학습 변형 구 현에서 자주 수행되는 것처럼 메타학습의 유사 메타 업데이트에 대한 1차 근사치를 만드는 것과 같다. 서버는 마지막으로 모든 참가자의 메타 업데이트된 모델을 집계할 수 있다. 서버가 K명의 참가자 새로운 셋을 선택하 면서 다음 에피소드가 시작될 수 있다.실제 배치 또는 모델 테스트 단계에서, 클라이언트 그룹이 주어지면 서버는 를 설정한 다음 연합 학습의 R 라운드를 리드하여 과 을 획득할 수 있다. 테스트 샘플이 주어지면 과 을 기반으로 예측을 할 수 있다. 모델 출력은 먼저 을 사용하여 계산된 다음, 결정에 도달하기 위해 의 모든 글로벌 프로 토타입과의 거리와 비교할 수 있다. 마지막으로, 융합 분석에 대하여 설명하기로 한다. 비볼록 손실 함수(nonconvex loss functions) 에 대한 메타학습 알고리즘에 대한 특정 수렴 동작을 보장하기 위한 이론적 분석이 제공 될 수 있다. 메타학습과 관련된 연합 학습의 수렴 분석에서 일반적으로 다음과 같은 가정이 필요하다. 가정 1. 모든 i에 대해, fi는 L-smooth, 즉 임의의 , 에 대해"}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이다. 가정 2. 를 참가자 i의 단일 데이터 포인트 에 대한 손실 함수라고 하자. 모든 i = 1,2,...,N 에 대해, 주어진 참가자의 데이터 샘플 간 손실 그레디언트의 분산은 제한된다. 즉, 임의의 에 대해 이다. 가정 3. 는 시스템의 모든 참가자의 평균 로컬 손실이라고 하자. 참가자 간 손실 fi 그 레디언트의 분산은 제한된다. 즉, 임의의 에 대해 이다. 두 개의 핵심 lemma와 아래 정리는 실시예에서 제안된 소수 라운드 연합 학습 방법의 수렴을 확립한다. Lemma 1. 학습률 가 범위에 있다고 가정하자. 그러면, 의 글로벌 손실 함수 는 LF-smooth 이며, 여기서 LF = L2R이다. Lemma 2. 참가자 k에서 체계 의 로컬 손실을 정의한다. K 클라이언트가 있는 그룹 A의 경우 해당 그룹 내 평균 손실 를 정의한다. 이라 가정하자. 그런 다 음, 그룹에 걸친 의 그레디언트의 분산은 다음과 같이 제한된다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, 는 N명의 개인 풀에서 추출된 모든 가능한 K 참가자 그룹의 셋이다. 정리 1. 가정 1, 2, 3이 성립되고 이라고 가정한다. IDI는 모든 참가자의 메타 업데이트 프로세스 에서 최소 배치 크기가 되도록 한다. 그런 다음 알고리즘 1은 학습된 모델 와 관련된 손실 그레디언트에 대 해 다음과 같은 상한을 보장한다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서 는 의 최적 솔루션이고, 이다. 에피소드 T의 수가 증가함에 따라, 의 상한선은 로 설정될 수 있다. 주어진 평활도 L, 가정된 손실 그레디 언트 분산 범위(Vd, Vp) 및 목표 FL의 라운드 R 수, 오류 항 은 메타 업데이트 학습률 , 미니 배치 크기 IDI및 에피소드당 참가자 수 K에 의해 제어될 수 있다. 합리적인 값 R에 대해, , IDI, K의 실용적인 선택은 대 표적인 파라미터 값을 사용하여 충분히 작게 만들 수 있다. 일 실시예에 따르면, 일반적인 연합 학습 데이터 셋(CIFAR-100, miniImageNet, FEMNIST)를 사용하여 성능이 검 증될 수 있으며, 포괄적인 실험을 통해 제시된 알고리즘의 구성 요소들이 연합 학습의 성능을 크게 향상시켜 새 로운 세계 최고 기록을 갱신한 것을 확인할 수 있다. 도 4는 일 실시예에 있어서, 연합 학습 시스템의 구성을 설명하기 위한 블록도이고, 도 5는 일 실시예에 있어서, 소수의 통신 라운드를 위한 연합 학습 방법을 설명하기 위한 흐름도이다. 연합 학습 시스템의 프로세서는 모델 준비부 및 모델 배치부를 포함할 수 있다. 이러한 프로세 서의 구성요소들은 연합 학습 시스템에 저장된 프로그램 코드가 제공하는 제어 명령에 따라 프로세서에 의해 수 행되는 서로 다른 기능들(different functions)의 표현들일 수 있다. 프로세서 및 프로세서의 구성요소들은 도 5의 소수의 통신 라운드를 위한 연합 학습 방법이 포함하는 단계들(510 내지 520)을 수행하도록 연합 학습 시스 템을 제어할 수 있다. 이때, 프로세서 및 프로세서의 구성요소들은 메모리가 포함하는 운영체제의 코드와 적어 도 하나의 프로그램의 코드에 따른 명령(instruction)을 실행하도록 구현될 수 있다. 프로세서는 소수의 통신 라운드를 위한 연합 학습 방법을 위한 프로그램의 파일에 저장된 프로그램 코드를 메모 리에 로딩할 수 있다. 예를 들면, 연합 학습 시스템에서 프로그램이 실행되면, 프로세서는 운영체제의 제어에 따라 프로그램의 파일로부터 프로그램 코드를 메모리에 로딩하도록 연합 학습 시스템을 제어할 수 있다. 이때, 모델 준비부 및 모델 배치부 각각은 메모리에 로딩된 프로그램 코드 중 대응하는 부분의 명령을 실행 하여 이후 단계들(510 내지 520)을 실행하기 위한 프로세서의 서로 다른 기능적 표현들일 수 있다. 단계에서 모델 준비부는 소수의 통신 라운드 동안 각 클라이언트로부터의 메타 학습 기반의 연합 학 습을 통해 인공지능 모델을 업데이트할 수 있다. 모델 준비부는 각 에피소드에 대해 서버에서 학습에 참 여할 각 클라이언트를 선택하고, 서버에서 현재 에피소드의 초기 모델을 선택된 각 클라이언트에게 전달할 수 있다. 모델 준비부는 선택된 각 클라이언트의 로컬 데이터 셋을 지원 셋과 쿼리 셋으로 구분할 수 있다. 모델 준비부는 선택된 각 클라이언트에서 서버로부터 글로벌 모델과 글로벌 프로토타입을 다운로드하고, 다운로드된 글로벌 모델을 기반으로 선택된 각 클라이언트의 로컬 데이터 셋으로부터 구분된 지원 셋을 이용하 여 각 클래스에 대한 로컬 프로토타입을 계산할 수 있다. 모델 준비부는 서버로부터 다운로드된 글로벌 모델, 글로벌 프로토타입 및 계산된 로컬 프로토타입을 기반으로 선택된 각 클라이언트에서 로컬 손실을 계산하 고, 계산된 로컬 손실을 기반으로 그레디언트 하강법을 통해 로컬 모델을 업데이트하고, 업데이트된 로컬 모델 과 계산된 로컬 프로토타입을 서버로 전송하고, 서버에서 상기 전송된 로컬 모델과 로컬 프로토타입을 집계할 수 있다. 모델 준비부는 글로벌 프로토타입 지원 학습(Global Prototype Assisted Learning; GPAL)을 통 해 로컬 프로토타입을 사용하여 계산된 로컬 손실과 글로벌 프로토타입의 보조 손실에 기초하여 로컬 파라미터 를 업데이트할 수 있다. 모델 준비부는 선택된 각 클라이언트로부터 서버에서 집계를 통해 획득된 글로벌 모델과 글로벌 프로토타입을 다운로드하고, 다운로드된 글로벌 모델과 글로벌 프로토타입에 기초하여 쿼리 셋을 이용하여 로컬 모델을 메타 업데이트하고, 서버에서 메타 업데이트된 로컬 모델을 집계할 수 있다. 단계에서 모델 배치부는 준비된 인공지능 모델을 공통 태스크에 대한 추론을 위한 클라이언트 그룹에 게 제공할 수 있다. 모델 배치부는 테스트 샘플을 이용하여 소수 라운드 동안의 연합 학습을 통해 획득된 글로벌 모델과 글로벌 프로토타입을 기반으로 예측을 수행할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2023-0083308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2023-0083308", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 연합 학습 동작을 설명하기 위한 도면이다. 도 2는 일 실시예에 있어서, 소수의 통신 라운드를 위한 연합 학습 동작을 설명하기 위한 도면이다. 도 3은 일 실시예에 있어서, 메타학습 동작을 설명하기 위한 도면이다. 도 4는 일 실시예에 있어서, 연합 학습 시스템의 구성을 설명하기 위한 블록도이다. 도 5는 일 실시예에 있어서, 소수의 통신 라운드를 위한 연합 학습 방법을 설명하기 위한 흐름도이다."}
