{"patent_id": "10-2022-0077325", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0000750", "출원번호": "10-2022-0077325", "발명의 명칭": "인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수", "출원인": "인천대학교 산학협력단", "발명자": "최대진"}}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치에있어서,기계학습을 위해 사전 수집된, 복수의 훈련용 문장들 - 상기 복수의 훈련용 문장들은, 진실에 해당되는 내용이포함된 문장들과 거짓에 해당되는 내용이 포함된 문장들로 구성되어 있음 - 과 상기 복수의 훈련용 문장들 각각에 대응되는 정답 값 - 상기 복수의 훈련용 문장들 중, 진실에 해당되는 내용이 포함된 문장들에 대한 정답 값은 사전 설정된 제1 정답 값으로 지정되어 있고, 거짓에 해당되는 내용이 포함된 문장들에 대한 정답 값은 사전설정된 제2 정답 값으로 지정되어 있음 - 이 저장되어 있는 훈련 정보 저장부;상기 훈련 정보 저장부에 저장되어 있는 상기 복수의 훈련용 문장들과 각 훈련용 문장에 대응되는 정답 값을 기초로, 내용의 진실 여부를 판별하는 학습 모델을 생성하기 위한 기계학습 과정을 수행함으로써, 진실 판단 모델을 생성하는 모델 생성부; 및상기 진실 판단 모델의 생성이 완료된 이후에, 진실 여부 판단의 대상이 되는 제1 문장이 입력으로 인가되면서,상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단할 것을 지시하는 판단 명령이 인가되면, 상기 진실 판단 모델을 기초로 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단하는 판단부를 포함하는 전자 장치."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 모델 생성부는상기 복수의 훈련용 문장들 각각에 대해, 각 훈련용 문장을 단어별로 구분하여 각 훈련용 문장에 대한 단어 시퀀스를 생성한 후, 상기 복수의 훈련용 문장들 각각의 단어 시퀀스의 전단에, CLS 토큰(special classificationtoken)을 추가하고, 단어 시퀀스의 후단에 SEP 토큰(special separator token)을 추가함으로써, 상기 복수의훈련용 문장들 각각에 대응되는 입력 시퀀스를 생성하는 입력 시퀀스 생성부;상기 복수의 훈련용 문장들 각각에 대응되는 입력 시퀀스를 사전 훈련된(pre-trained) BERT(BidirectionalEncoder Representations from Transformers) 모델에 입력으로 인가하여, 상기 BERT 모델을 통해 출력되는 각훈련용 문장에 대한 출력 임베딩 시퀀스를 획득하는 임베딩부; 및상기 복수의 훈련용 문장들 각각에 대한 출력 임베딩 시퀀스에서 CLS 토큰을 구성하는 임베딩 벡터를 추출하여,상기 복수의 훈련용 문장들 각각에 대한 임베딩 벡터를, 출력 값을 생성하기 위한 완전 연결 계층(FullyConnected Layers)에 입력으로 인가함으로써, 각 훈련용 문장에 대응되는 예측 값을 산출한 후, 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값이, 각 훈련용 문장에 대응되어 지정되어 있는 정답 값에 최대로 근접하도록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행하는 학습 수행부를 포함하는 전자 장치."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 정답 값과 상기 제2 정답 값 중 어느 하나의 정답 값은 '1'로 지정되어 있고, 다른 하나의 정답 값은'0'으로 지정되어 있으며,상기 학습 수행부는상기 복수의 훈련용 문장들 각각에 대한 임베딩 벡터를 상기 완전 연결 계층에 입력으로 인가하여, 각 훈련용문장에 대응되는 상기 완전 연결 계층의 출력 값을 획득하고, 획득된 완전 연결 계층의 출력 값을 시그모이드공개특허 10-2024-0000750-3-(Sigmoid) 함수에 입력으로 인가함으로써, 0~1사이의 크기를 갖는, 상기 복수의 훈련용 문장들 각각에 대응되는예측 값을 산출한 후, 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값이, 각 훈련용 문장에 대응되어 지정되어 있는 정답 값에 최대로 근접하도록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 학습 수행부는상기 복수의 훈련용 문장들 각각에 대응되는 예측 값과 각 훈련용 문장에 대응되어 지정되어 있는 정답 값을 기초로, 하기의 수학식 1의 손실함수에 따른 손실 값이 최소가 되도록 상기 BERT 모델과 상기 완전 연결 계층에대한 기계학습을 수행하는 것을 특징으로 하는 전자 장치.[수학식 1]여기서, L은 손실 값, y'c는 상기 복수의 훈련용 문장들 중 c번째 훈련용 문장에 대응되어 지정되어 있는 정답값, yc는 상기 복수의 훈련용 문장들 중 c번째 훈련용 문장에 대응되는 예측 값을 의미함."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 판단부는상기 진실 판단 모델의 생성이 완료된 이후에, 진실 여부 판단의 대상이 되는 상기 제1 문장이 입력으로 인가되면서, 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단할 것을 지시하는 판단 명령이 인가되면, 상기제1 문장을 단어별로 구분하여 상기 제1 문장에 대한 단어 시퀀스를 생성한 후, 상기 제1 문장에 대한 단어 시퀀스의 전단에, CLS 토큰을 추가하고, 상기 제1 문장에 대한 단어 시퀀스의 후단에 SEP 토큰을 추가함으로써,상기 제1 문장에 대응되는 입력 시퀀스를 생성하는 판단용 입력 시퀀스 생성부;상기 제1 문장에 대응되는 입력 시퀀스를, 기계학습이 완료된 상기 BERT 모델에 입력으로 인가하여, 상기 BERT모델을 통해 출력되는 상기 제1 문장에 대한 출력 임베딩 시퀀스를 획득하는 판단용 임베딩부; 및상기 제1 문장에 대한 출력 임베딩 시퀀스에서 CLS 토큰을 구성하는 임베딩 벡터를 추출하여, 추출된 임베딩 벡터를 상기 제1 문장에 대한 기계학습이 완료된 상기 완전 연결 계층에 입력으로 인가함으로써, 상기 제1 문장에대응되는 판단용 예측 값을 산출한 후, 상기 판단용 예측 값이, 상기 제1 정답 값과 상기 제2 정답 값 중 어느정답 값에 더 근접한 값인지 확인하여, 상기 판단용 예측 값이 상기 제1 정답 값에 더 근접한 값으로 확인된 경우, 상기 제1 문장의 내용이 진실인 것으로 판단하고, 상기 판단용 예측 값이 상기 제2 정답 값에 더 근접한 값으로 확인된 경우, 상기 제1 문장의 내용이 거짓인 것으로 판단하는 판단 처리부를 포함하는 전자 장치."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치의동작 방법에 있어서,기계학습을 위해 사전 수집된, 복수의 훈련용 문장들 - 상기 복수의 훈련용 문장들은, 진실에 해당되는 내용이포함된 문장들과 거짓에 해당되는 내용이 포함된 문장들로 구성되어 있음 - 과 상기 복수의 훈련용 문장들 각각에 대응되는 정답 값 - 상기 복수의 훈련용 문장들 중, 진실에 해당되는 내용이 포함된 문장들에 대한 정답 값은 사전 설정된 제1 정답 값으로 지정되어 있고, 거짓에 해당되는 내용이 포함된 문장들에 대한 정답 값은 사전설정된 제2 정답 값으로 지정되어 있음 - 이 저장되어 있는 훈련 정보 저장부를 유지하는 단계;공개특허 10-2024-0000750-4-상기 훈련 정보 저장부에 저장되어 있는 상기 복수의 훈련용 문장들과 각 훈련용 문장에 대응되는 정답 값을 기초로, 내용의 진실 여부를 판별하는 학습 모델을 생성하기 위한 기계학습 과정을 수행함으로써, 진실 판단 모델을 생성하는 단계; 및상기 진실 판단 모델의 생성이 완료된 이후에, 진실 여부 판단의 대상이 되는 제1 문장이 입력으로 인가되면서,상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단할 것을 지시하는 판단 명령이 인가되면, 상기 진실 판단 모델을 기초로 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단하는 단계를 포함하는 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 진실 판단 모델을 생성하는 단계는상기 복수의 훈련용 문장들 각각에 대해, 각 훈련용 문장을 단어별로 구분하여 각 훈련용 문장에 대한 단어 시퀀스를 생성한 후, 상기 복수의 훈련용 문장들 각각에 대한 단어 시퀀스의 전단에, CLS 토큰(specialclassification token)을 추가하고, 단어 시퀀스의 후단에 SEP 토큰(special separator token)을추가함으로써, 상기 복수의 훈련용 문장들 각각에 대응되는 입력 시퀀스를 생성하는 단계;상기 복수의 훈련용 문장들 각각에 대응되는 입력 시퀀스를 사전 훈련된(pre-trained) BERT(BidirectionalEncoder Representations from Transformers) 모델에 입력으로 인가하여, 상기 BERT 모델을 통해 출력되는 각훈련용 문장에 대한 출력 임베딩 시퀀스를 획득하는 단계; 및상기 복수의 훈련용 문장들 각각에 대한 출력 임베딩 시퀀스에서 CLS 토큰을 구성하는 임베딩 벡터를 추출하여,상기 복수의 훈련용 문장들 각각에 대한 임베딩 벡터를, 출력 값을 생성하기 위한 완전 연결 계층(FullyConnected Layers)에 입력으로 인가함으로써, 각 훈련용 문장에 대응되는 예측 값을 산출한 후, 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값이, 각 훈련용 문장에 대응되어 지정되어 있는 정답 값에 최대로 근접하도록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행하는 단계를 포함하는 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제1 정답 값과 상기 제2 정답 값 중 어느 하나의 정답 값은 '1'로 지정되어 있고, 다른 하나의 정답 값은'0'으로 지정되어 있으며,상기 기계학습을 수행하는 단계는상기 복수의 훈련용 문장들 각각에 대한 임베딩 벡터를 상기 완전 연결 계층에 입력으로 인가하여, 각 훈련용문장에 대응되는 상기 완전 연결 계층의 출력 값을 획득하고, 획득된 완전 연결 계층의 출력 값을 시그모이드(Sigmoid) 함수에 입력으로 인가함으로써, 0~1사이의 크기를 갖는, 상기 복수의 훈련용 문장들 각각에 대응되는예측 값을 산출한 후, 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값이, 각 훈련용 문장에 대응되어 지정되어 있는 정답 값에 최대로 근접하도록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행하는 것을 특징으로 하는 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 기계학습을 수행하는 단계는상기 복수의 훈련용 문장들 각각에 대응되는 예측 값과 각 훈련용 문장에 대응되어 지정되어 있는 정답 값을 기초로, 하기의 수학식 1의 손실함수에 따른 손실 값이 최소가 되도록 상기 BERT 모델과 상기 완전 연결 계층에대한 기계학습을 수행하는 것을 특징으로 하는 전자 장치의 동작 방법.공개특허 10-2024-0000750-5-[수학식 1]여기서, L은 손실 값, y'c는 상기 복수의 훈련용 문장들 중 c번째 훈련용 문장에 대응되어 지정되어 있는 정답값, yc는 상기 복수의 훈련용 문장들 중 c번째 훈련용 문장에 대응되는 예측 값을 의미함."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 판단하는 단계는상기 진실 판단 모델의 생성이 완료된 이후에, 진실 여부 판단의 대상이 되는 상기 제1 문장이 입력으로 인가되면서, 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단할 것을 지시하는 판단 명령이 인가되면, 상기제1 문장을 단어별로 구분하여 상기 제1 문장에 대한 단어 시퀀스를 생성한 후, 상기 제1 문장에 대한 단어 시퀀스의 전단에, CLS 토큰을 추가하고, 상기 제1 문장에 대한 단어 시퀀스의 후단에 SEP 토큰을 추가함으로써,상기 제1 문장에 대응되는 입력 시퀀스를 생성하는 단계;상기 제1 문장에 대응되는 입력 시퀀스를, 기계학습이 완료된 상기 BERT 모델에 입력으로 인가하여, 상기 BERT모델을 통해 출력되는 상기 제1 문장에 대한 출력 임베딩 시퀀스를 획득하는 단계; 및상기 제1 문장에 대한 출력 임베딩 시퀀스에서 CLS 토큰을 구성하는 임베딩 벡터를 추출하여, 추출된 임베딩 벡터를 상기 제1 문장에 대한 기계학습이 완료된 상기 완전 연결 계층에 입력으로 인가함으로써, 상기 제1 문장에대응되는 판단용 예측 값을 산출한 후, 상기 판단용 예측 값이, 상기 제1 정답 값과 상기 제2 정답 값 중 어느정답 값에 더 근접한 값인지 확인하여, 상기 판단용 예측 값이 상기 제1 정답 값에 더 근접한 값으로 확인된 경우, 상기 제1 문장의 내용이 진실인 것으로 판단하고, 상기 판단용 예측 값이 상기 제2 정답 값에 더 근접한 값으로 확인된 경우, 상기 제1 문장의 내용이 거짓인 것으로 판단하는 단계를 포함하는 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제6항 내지 제10항 중 어느 한 항의 방법을 컴퓨터와의 결합을 통해 실행시키기 위한 컴퓨터 프로그램을 기록한컴퓨터 판독 가능 기록 매체."}
{"patent_id": "10-2022-0077325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제6항 내지 제10항 중 어느 한 항의 방법을 컴퓨터와의 결합을 통해 실행시키기 위한 저장매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2022-0077325", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전 자 장치 및 그 동작 방법을 제시함으로써, 사용자가 소정의 문장을 접하게 되었을 때, 그 문장 내의 내용이 진실 인지 거짓인지 여부를 빠르게 판별해 낼 수 있도록 지원할 수 있다."}
{"patent_id": "10-2022-0077325", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치 및 그 동작 방법에 대한 것이다."}
{"patent_id": "10-2022-0077325", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 인터넷의 보급이 활발해짐에 따라 사람들이 인터넷을 통해 다양한 정보들을 접할 수 있게 되었다. 이렇게, 인터넷을 통해서 다양한 정보들이 생산되고 전파됨에 따라, 가짜 뉴스와 같은 거짓의 내용에 담긴 정보 들도 증가하고 있다. 보통, 일반인들은 거짓의 내용이 담긴 정보를 접하게 되는 경우, 해당 정보와 관련된 전문 지식을 갖추고 있지 않은 경우가 많다는 점에서, 거짓의 내용을 그대로 신뢰하게 되는 오류를 범할 수 있다. 따라서, 인터넷을 통해서 전파되는 정보의 내용이 진실인지 거짓인지를 판별할 수 있는 기술에 대한 연구가 필 요하다. 관련해서, 최근에는 일부의 샘플 데이터를 기초로 소정의 결과를 판단하기 위한 학습 모델을 만들 수 있는 기계 학습 기반의 인공지능 기술이 등장하고 있다는 점에서, 소정의 문장에 포함된 내용이 진실인지 거짓인지를 판별 해내는 데에 있어서도 이러한 인공지능 기술의 활용을 고려할 수 있다. 이렇게, 인공지능 기술을 활용하여 문장에 포함된 내용이 진실인지 거짓인지 여부를 판단할 수 있는 모델을 만 들어두게 되면, 사용자가 소정의 문장을 접하게 되었을 때, 그 문장 내의 내용이 진실인지 거짓인지 여부를 빠 르게 판별해 낼 수 있다는 점에서, 사용자가 잘못된 정보를 획득하는 오류를 방지할 수 있을 것이다. 선행기술문헌 비특허문헌 (비특허문헌 0001) Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. . BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: Human language technologies, Volume 1 (Long and short papers) (pp. 4171-4186).(2019년 6월 공개)"}
{"patent_id": "10-2022-0077325", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치 및 그 동작 방법을 제시함으로써, 사용자가 소정의 문장을 접하게 되었을 때, 그 문장 내의 내용이 진실인지 거짓인지 여부를 빠르게 판별해 낼 수 있도록 지원하고자 한다."}
{"patent_id": "10-2022-0077325", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일실시예에 따른 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치는 기계학습을 위해 사전 수집된, 복수의 훈련용 문장들 - 상기 복수의 훈련용 문장들 은, 진실에 해당되는 내용이 포함된 문장들과 거짓에 해당되는 내용이 포함된 문장들로 구성되어 있음 - 과 상 기 복수의 훈련용 문장들 각각에 대응되는 정답 값 - 상기 복수의 훈련용 문장들 중, 진실에 해당되는 내용이 포함된 문장들에 대한 정답 값은 사전 설정된 제1 정답 값으로 지정되어 있고, 거짓에 해당되는 내용이 포함된 문장들에 대한 정답 값은 사전 설정된 제2 정답 값으로 지정되어 있음 - 이 저장되어 있는 훈련 정보 저장부, 상기 훈련 정보 저장부에 저장되어 있는 상기 복수의 훈련용 문장들과 각 훈련용 문장에 대응되는 정답 값을 기 초로, 내용의 진실 여부를 판별하는 학습 모델을 생성하기 위한 기계학습 과정을 수행함으로써, 진실 판단 모델 을 생성하는 모델 생성부 및 상기 진실 판단 모델의 생성이 완료된 이후에, 진실 여부 판단의 대상이 되는 제1 문장이 입력으로 인가되면서, 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단할 것을 지시하는 판단 명령이 인가되면, 상기 진실 판단 모델을 기초로 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단하는 판단부를 포함한다. 또한, 본 발명의 일실시예에 따른 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치의 동작 방법은 기계학습을 위해 사전 수집된, 복수의 훈련용 문장들 - 상기 복수의 훈련용 문장들은, 진실에 해당되는 내용이 포함된 문장들과 거짓에 해당되는 내용이 포함된 문장들로 구 성되어 있음 - 과 상기 복수의 훈련용 문장들 각각에 대응되는 정답 값 - 상기 복수의 훈련용 문장들 중, 진실 에 해당되는 내용이 포함된 문장들에 대한 정답 값은 사전 설정된 제1 정답 값으로 지정되어 있고, 거짓에 해당 되는 내용이 포함된 문장들에 대한 정답 값은 사전 설정된 제2 정답 값으로 지정되어 있음 - 이 저장되어 있는 훈련 정보 저장부를 유지하는 단계, 상기 훈련 정보 저장부에 저장되어 있는 상기 복수의 훈련용 문장들과 각 훈련용 문장에 대응되는 정답 값을 기초로, 내용의 진실 여부를 판별하는 학습 모델을 생성하기 위한 기계학습 과정을 수행함으로써, 진실 판단 모델을 생성하는 단계 및 상기 진실 판단 모델의 생성이 완료된 이후에, 진실 여부 판단의 대상이 되는 제1 문장이 입력으로 인가되면서, 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를판단할 것을 지시하는 판단 명령이 인가되면, 상기 진실 판단 모델을 기초로 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단하는 단계를 포함한다."}
{"patent_id": "10-2022-0077325", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치 및 그 동작 방법을 제시함으로써, 사용자가 소정의 문장을 접하게 되었을 때, 그 문장 내의 내용이 진실인지 거짓인지 여부를 빠르게 판별해 낼 수 있도록 지원할 수 있다."}
{"patent_id": "10-2022-0077325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 발명에 따른 실시예들을 첨부된 도면을 참조하여 상세하게 설명하기로 한다. 이러한 설명은 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 각 도면을 설명하면서 유사한 참조부호를 유사한 구 성요소에 대해 사용하였으며, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 본 명세서 상"}
{"patent_id": "10-2022-0077325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "에서 사용되는 모든 용어들은 본 발명이 속하는 기술분야에서 통상의 지식을 가진 사람에 의해 일반적으로 이해 되는 것과 동일한 의미를 가지고 있다. 본 문서에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구 성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있다는 것을 의미한다. 또한, 본 발명의 다양한 실시예들에 있어서, 각 구성요소들, 기능 블록들 또는 수단들은 하나 또는 그 이상의 하부 구성요소로 구성될 수 있고, 각 구성요소들이 수행하는 전기, 전자, 기계적 기능들은 전자회로, 집적회로, ASIC(Application Specific Integrated Circuit) 등 공지된 다양한 소자들 또는 기계적 요소들로 구현될 수 있으며, 각각 별개로 구현되거나 2 이상이 하나로 통합되어 구현될 수도 있다. 한편, 첨부된 블록도의 블록들이나 흐름도의 단계들은 범용 컴퓨터, 특수용 컴퓨터, 휴대용 노트북 컴퓨터, 네 트워크 컴퓨터 등 데이터 프로세싱이 가능한 장비의 프로세서나 메모리에 탑재되어 지정된 기능들을 수행하는 컴퓨터 프로그램 명령들(instructions)을 의미하는 것으로 해석될 수 있다. 이들 컴퓨터 프로그램 명령들은 컴 퓨터 장치에 구비된 메모리 또는 컴퓨터에서 판독 가능한 메모리에 저장될 수 있기 때문에, 블록도의 블록들 또 는 흐름도의 단계들에서 설명된 기능들은 이를 수행하는 명령 수단을 내포하는 제조물로 생산될 수도 있다. 아 울러, 각 블록 또는 각 단계는 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 명령들을 포 함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 가능한 실시예들에서는 블록들 또는 단계들에서 언급된 기능들이 정해진 순서와 달리 실행되는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 또는 단계들은 실질적으로 동시에 수행되거나, 역순으로 수행될 수 있으며, 경우 에 따라 일부 블록들 또는 단계들이 생략된 채로 수행될 수도 있다. 도 1은 본 발명의 일실시예에 따른 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치의 구조를 도시한 도면이다. 도 1을 참조하면, 본 발명에 따른 전자 장치는 훈련 정보 저장부, 모델 생성부 및 판단부 를 포함한다. 훈련 정보 저장부에는 기계학습을 위해 사전 수집된, 복수의 훈련용 문장들과 상기 복수의 훈련용 문장들 각각에 대응되는 정답 값이 저장되어 있다. 여기서, 상기 복수의 훈련용 문장들은, 진실에 해당되는 내용이 포함된 문장들과 거짓에 해당되는 내용이 포함 된 문장들로 구성되어 있고, 상기 복수의 훈련용 문장들 중, 진실에 해당되는 내용이 포함된 문장들에 대한 정답 값은 사전 설정된 제1 정답 값으로 지정되어 있고, 거짓에 해당되는 내용이 포함된 문장들에 대한 정답 값은 사전 설정된 제2 정답 값으로 지정되어 있다. 이때, 본 발명의 일실시예에 따르면, 상기 제1 정답 값과 상기 제2 정답 값 중 어느 하나의 정답 값은 '1'로 지 정되어 있고, 다른 하나의 정답 값은 '0'으로 지정되어 있을 수 있다. 예컨대, 상기 제1 정답 값이 '1'로 지정 되는 경우, 상기 제2 정답 값은 '0'으로 지정되고, 상기 제1 정답 값이 '0'으로 지정되는 경우, 상기 제1 정답 값은 '1'로 지정될 수 있다. 관련해서, 상기 제1 정답 값이 '1', 상기 제2 정답 값이 '0'으로 지정되어 있다고 하였을 때, 훈련 정보 저장부 에는 하기의 표 1과 같이 정보가 저장되어 있을 수 있다. 표 1 복수의 훈련용 문장들 진실 또는 거짓 정답 값 훈련용 문장 1 진실 1 훈련용 문장 2 진실 1 훈련용 문장 3 거짓 0 훈련용 문장 4 거짓 0 ... ... ... 모델 생성부는 훈련 정보 저장부에 저장되어 있는 상기 복수의 훈련용 문장들과 각 훈련용 문장에 대 응되는 정답 값을 기초로, 내용의 진실 여부를 판별하는 학습 모델을 생성하기 위한 기계학습 과정을 수행함으 로써, 진실 판단 모델을 생성한다. 이때, 본 발명의 일실시예에 따르면, 모델 생성부는 입력 시퀀스 생성부, 임베딩부 및 학습 수 행부를 포함할 수 있다. 입력 시퀀스 생성부는 상기 복수의 훈련용 문장들 각각에 대해, 각 훈련용 문장을 단어별로 구분하여 각 훈련용 문장에 대한 단어 시퀀스를 생성한 후, 상기 복수의 훈련용 문장들 각각의 단어 시퀀스의 전단에, CLS 토큰(special classification token)을 추가하고, 단어 시퀀스의 후단에 SEP 토큰(special separator token)을 추가함으로써, 상기 복수의 훈련용 문장들 각각에 대응되는 입력 시퀀스를 생성한다. 여기서, CLS 토큰과 SEP 토큰은 BERT(Bidirectional Encoder Representations from Transformers) 모델에서 소 정의 문장이 입력되었을 때, 이 문장의 입력 시퀀스의 전단과 후단에 추가되는 토큰을 의미한다. 그리고, BERT 모델이란, 자연어 처리 모델로서, 소정의 문장이 입력되면, 이 문장을 단어 단위로 구분하여 토큰화시켜, 소정 의 입력 시퀀스를 생성하고, 이 입력 시퀀스를, layer normalization, multihead self-attention, dropout, feed forward networks로 구성된, 소정 개수의 BERT 레이어들에 연쇄적으로 인가하여 출력 시퀀스를 생성해내는 모델을 의미한다. 예컨대, 상기 복수의 훈련용 문장들 중 어느 한 문장이 'Germen chocolate comes from Germany'라고 하는 경우, 입력 시퀀스 생성부는 'Germen chocolate comes from Germany'를 단어별로 구분하여 'Germen', 'chocolate', 'comes', 'from', 'Germany'라는 단어 시퀀스를 생성한 후, 해당 단어 시퀀스의 전단에 CLS 토큰 을 추가하고, 단어 시퀀스의 후단에 SEP 토큰을 추가함으로써, 도 2의 도면부호 210에 도시된 그림과 같은 'Germen chocolate comes from Germany'라는 문장에 대한 입력 시퀀스를 생성할 수 있다. 임베딩부는 상기 복수의 훈련용 문장들 각각에 대응되는 입력 시퀀스를 사전 훈련된(pre-trained) BERT 모 델에 입력으로 인가하여, 상기 BERT 모델을 통해 출력되는 각 훈련용 문장에 대한 출력 임베딩 시퀀스를 획득한 다. 관련해서, 전술한 예와 같이, 상기 복수의 훈련용 문장들 중 어느 한 문장이 'Germen chocolate comes from Germany'라고 하고, 입력 시퀀스 생성부를 통해, 'CLS', 'Germen', 'chocolate', 'comes', 'from', 'Germany', 'SEP'라는 입력 시퀀스가 생성되었다고 하는 경우, 임베딩부는 도 2의 도면부호 211에 도 시된 그림과 같이, 사전 훈련된 BERT 모델에 'CLS', 'Germen', 'chocolate', 'comes', 'from', 'Germany','SEP'라는 입력 시퀀스를 입력으로 인가하여, 상기 BERT 모델을 통해 출력되는 출력 임베딩 시퀀스를 획득할 수 있다. 이때, 상기 도 2의 예시에서 사용된 BERT 모델은 768개의 은닉 크기를 갖는 12개의 BERT 계층 으로 구성된 BERTBASE 모델이 사용되었다. 이러한 방식으로, 임베딩부는 도 2의 도면부호 211에 도시된 그림과 같이, 상기 복수의 훈련용 문장들 각 각에 대한 입력 시퀀스를 상기 BERT 모델에 입력으로 인가함으로써, 상기 BERT 모델을 통해서 출력되는 각 훈련 용 문장에 대한 출력 임베딩 시퀀스를 획득할 수 있다. 학습 수행부는 상기 복수의 훈련용 문장들 각각에 대한 출력 임베딩 시퀀스에서 CLS 토큰을 구성하는 임베 딩 벡터를 추출하여, 상기 복수의 훈련용 문장들 각각에 대한 임베딩 벡터를, 출력 값을 생성하기 위한 완전 연 결 계층(Fully Connected Layers)에 입력으로 인가함으로써, 각 훈련용 문장에 대응되는 예측 값을 산출한 후, 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값이, 각 훈련용 문장에 대응되어 지정되어 있는 정답 값에 최대로 근접하도록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행한다. 이때, 본 발명의 일실시예에 따르면, 학습 수행부는 상기 복수의 훈련용 문장들 각각에 대한 임베딩 벡터 를 상기 완전 연결 계층에 입력으로 인가하여, 각 훈련용 문장에 대응되는 상기 완전 연결 계층의 출력 값을 획 득하고, 획득된 완전 연결 계층의 출력 값을 시그모이드(Sigmoid) 함수에 입력으로 인가함으로써, 0~1사이의 크 기를 갖는, 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값을 산출한 후, 상기 복수의 훈련용 문장들 각각 에 대응되는 예측 값이, 각 훈련용 문장에 대응되어 지정되어 있는 정답 값에 최대로 근접하도록 상기 BERT 모 델과 상기 완전 연결 계층에 대한 기계학습을 수행할 수 있다. 관련해서, 전술한 예와 같이, 상기 복수의 훈련용 문장들 중 어느 한 문장이 'Germen chocolate comes from Germany'라고 하고, 임베딩부를 통해, 도면부호 220에 도시된 그림과 같은, 이 훈련용 문장에 대한 출력 임베딩 시퀀스가 획득되었다고 하는 경우, 학습 수행부는 상기 출력 임베딩 시퀀스에서 도면부호 213 으로 표시한 CLS 토큰을 구성하는 임베딩 벡터를 추출한 후, 도면부호 212에 도시된 그림과 같이, 상기 임 베딩 벡터를 완전 연결 계층에 입력으로 인가함으로써, 상기 훈련용 문장에 대응되는 출력 값을 획득할 수 있다. 그러고 나서, 학습 수행부는 상기 출력 값을 시그모이드(Sigmoid) 함수에 입력으로 인가하여 0~1사 이의 크기를 갖는 값으로 변환함으로써, 'Germen chocolate comes from Germany'라는 훈련용 문장에 대응되는 예측 값을 산출할 수 있다. 이러한 방식으로, 학습 수행부는 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값을 0~1사이의 값으로 산출할 수 있다. 이렇게, 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값이 산출되면, 학습 수행부는 상기 복수의 훈 련용 문장들 각각에 대응되는 예측 값이, 각 훈련용 문장에 대응되어 지정되어 있는 정답 값에 최대로 근접하도 록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행할 수 있다. 이때, 본 발명의 일실시예에 따르면, 학습 수행부는 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값 과 각 훈련용 문장에 대응되어 지정되어 있는 정답 값을 기초로, 하기의 수학식 1의 손실함수에 따른 손실 값이 최소가 되도록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행할 수 있다. 수학식 1"}
{"patent_id": "10-2022-0077325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, L은 손실 값, y'c는 상기 복수의 훈련용 문장들 중 c번째 훈련용 문장에 대응되어 지정되어 있는 정답 값, yc는 상기 복수의 훈련용 문장들 중 c번째 훈련용 문장에 대응되는 예측 값을 의미한다.예컨대, 상기 복수의 훈련용 문장들에 대한 정답 값이 상기 표 1과 같이 지정되어 있다고 하는 경우, 학습 수행 부는 '훈련용 문장 1'에 대한 정답 값인 '1'을 y'c에 대입하고, '훈련용 문장 1'에 대해서 산출된 예측 값 을 yc에 대입하며, '훈련용 문장 2'에 대한 정답 값인 '1'을 y'c에 대입하고, '훈련용 문장 2'에 대해서 산출된 예측 값을 yc에 대입하며, '훈련용 문장 3'에 대한 정답 값인 '0'을 y'c에 대입하고, '훈련용 문장 3'에 대해서 산출된 예측 값을 yc에 대입하며, '훈련용 문장 4'에 대한 정답 값인 '0'을 y'c에 대입하고, '훈련용 문장 4'에 대해서 산출된 예측 값을 yc에 대입하는 방식으로, 상기 복수의 훈련용 문장들 각각에 대한 정답 값과 예측 값을 기반으로 상기 수학식 1에 따른 손실 값을 연산할 수 있다. 그러고 나서, 학습 수행부는 상기 손실 값이 최소가 되도록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행할 수 있다. 이때, 본 발명의 일실시예에 따르면, 학습 수행부는 상기 손실 값이 최소가 되도록 역전파 (BackPropagation) 처리를 수행함으로써, 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행할 수 있다. 이러한 방식으로, 모델 생성부는 훈련 정보 저장부에 저장되어 있는 상기 복수의 훈련용 문장들과 그 에 대응되는 정답 값을 기초로 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행함으로써, 학습이 완료된 상기 BERT 모델과 상기 완전 연결 계층으로 구성된 상기 진실 판단 모델을 생성할 수 있다. 이렇게, 모델 생성부를 통해, 상기 진실 판단 모델의 생성이 완료된 이후에, 진실 여부 판단의 대상이 되 는 제1 문장이 입력으로 인가되면서, 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단할 것을 지시하는 판단 명령이 전자 장치에 인가되면, 판단부는 상기 진실 판단 모델을 기초로 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단한다. 이때, 본 발명의 일실시예에 따르면, 판단부는 판단용 입력 시퀀스 생성부, 판단용 임베딩부 및 판단 처리부를 포함할 수 있다. 판단용 입력 시퀀스 생성부는 상기 진실 판단 모델의 생성이 완료된 이후에, 진실 여부 판단의 대상이 되 는 상기 제1 문장이 입력으로 인가되면서, 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단할 것을 지 시하는 판단 명령이 인가되면, 상기 제1 문장을 단어별로 구분하여 상기 제1 문장에 대한 단어 시퀀스를 생성한 후, 상기 제1 문장에 대한 단어 시퀀스의 전단에, CLS 토큰을 추가하고, 상기 제1 문장에 대한 단어 시퀀스의 후단에 SEP 토큰을 추가함으로써, 상기 제1 문장에 대응되는 입력 시퀀스를 생성한다. 판단용 임베딩부는 상기 제1 문장에 대응되는 입력 시퀀스를, 기계학습이 완료된 상기 BERT 모델에 입력으 로 인가하여, 상기 BERT 모델을 통해 출력되는 상기 제1 문장에 대한 출력 임베딩 시퀀스를 획득한다. 관련해서, 판단용 입력 시퀀스 생성부는 도 2의 도면부호 210에 도시된 그림과 같이, 상기 제1 문장에 대 한 단어 시퀀스의 전후단에 CLS 토큰과 SEP 토큰을 추가하여 상기 제1 문장에 대한 입력 시퀀스를 생성할 수 있 고, 판단용 임베딩부는 도면부호 211에 도시된 그림과 같이, 상기 제1 문장에 대응되는 입력 시퀀스를, 기 계학습이 완료된 상기 BERT 모델에 입력으로 인가함으로써, 상기 BERT 모델을 통해 출력되는, 도면부호 220에 도시된 그림과 같은 상기 제1 문장에 대한 출력 임베딩 시퀀스를 획득할 수 있다. 판단 처리부는 상기 제1 문장에 대한 출력 임베딩 시퀀스에서 CLS 토큰을 구성하는 임베딩 벡터를 추출하 여, 추출된 임베딩 벡터를 상기 제1 문장에 대한 기계학습이 완료된 상기 완전 연결 계층에 입력으로 인가함으 로써, 상기 제1 문장에 대응되는 판단용 예측 값을 산출한 후, 상기 판단용 예측 값이, 상기 제1 정답 값과 상 기 제2 정답 값 중 어느 정답 값에 더 근접한 값인지 확인하여, 상기 판단용 예측 값이 상기 제1 정답 값에 더 근접한 값으로 확인된 경우, 상기 제1 문장의 내용이 진실인 것으로 판단하고, 상기 판단용 예측 값이 상기 제2 정답 값에 더 근접한 값으로 확인된 경우, 상기 제1 문장의 내용이 거짓인 것으로 판단한다. 관련해서, 상기 제1 문장에 대한 출력 임베딩 시퀀스가 도 2의 도면부호 220과 같이 획득되었다고 하는 경우, 판단 처리부는 상기 제1 문장에 대한 출력 임베딩 시퀀스에서 CLS 토큰을 구성하는 임베딩 벡터 를 추출한 후, 도면부호 212에 도시된 그림과 같이, 상기 추출된 임베딩 벡터를 상기 제1 문장에 대한 기계학습 이 완료된 상기 완전 연결 계층에 입력으로 인가함으로써, 상기 완전 연결 계층을 통과하여 산출되는 출력 값을 획득할 수 있다. 그러고 나서, 판단 처리부는 상기 출력 값을 시그모이드 함수에 입력으로 인가함으로써, 0~1사이의 크기를 갖는 값으로 변환함으로써, 상기 제1 문장에 대응되는 판단용 예측 값을 산출할 수 있다. 그 이후, 판단 처리부는 상기 판단용 예측 값이, 상기 제1 정답 값과 상기 제2 정답 값 중 어느 정답 값에 더 근접한 값인지 확인하여, 상기 판단용 예측 값이 상기 제1 정답 값에 더 근접한 값으로 확인된 경우, 상기 제1 문장의 내용이 진실인 것으로 판단하고, 상기 판단용 예측 값이 상기 제2 정답 값에 더 근접한 값으로 확인 된 경우, 상기 제1 문장의 내용이 거짓인 것으로 판단할 수 있다. 관련해서, 전술한 예와 같이, 상기 제1 정답 값이 '1', 상기 제2 정답 값이 '0'으로 지정되어 있다고 하는 경우, 판단 처리부는 상기 판단용 예측 값이 '1'에 가까운 값으로 산출되었다면, 상기 제1 문장의 내용이 진실인 것으로 판단하고, 상기 판단용 예측 값이 '0'에 가까운 값으로 산출되었다면, 상기 제1 문장의 내용이 거짓인 것으로 판단할 수 있다. 도 3은 본 발명의 일실시예에 따른 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치의 동작 방법을 도시한 순서도이다. 단계(S310)에서는 기계학습을 위해 사전 수집된, 복수의 훈련용 문장들(상기 복수의 훈련용 문장들은, 진실에 해당되는 내용이 포함된 문장들과 거짓에 해당되는 내용이 포함된 문장들로 구성되어 있음)과 상기 복수의 훈련 용 문장들 각각에 대응되는 정답 값(상기 복수의 훈련용 문장들 중, 진실에 해당되는 내용이 포함된 문장들에 대한 정답 값은 사전 설정된 제1 정답 값으로 지정되어 있고, 거짓에 해당되는 내용이 포함된 문장들에 대한 정 답 값은 사전 설정된 제2 정답 값으로 지정되어 있음)이 저장되어 있는 훈련 정보 저장부를 유지한다. 단계(S320)에서는 상기 훈련 정보 저장부에 저장되어 있는 상기 복수의 훈련용 문장들과 각 훈련용 문장에 대응 되는 정답 값을 기초로, 내용의 진실 여부를 판별하는 학습 모델을 생성하기 위한 기계학습 과정을 수행함으로 써, 진실 판단 모델을 생성한다. 단계(S330)에서는 상기 진실 판단 모델의 생성이 완료된 이후에, 진실 여부 판단의 대상이 되는 제1 문장이 입 력으로 인가되면서, 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단할 것을 지시하는 판단 명령이 인 가되면, 상기 진실 판단 모델을 기초로 상기 제1 문장의 내용이 진실인지, 거짓인지 여부를 판단한다. 이때, 본 발명의 일실시예에 따르면, 단계(S320)에서는 상기 복수의 훈련용 문장들 각각에 대해, 각 훈련용 문 장을 단어별로 구분하여 각 훈련용 문장에 대한 단어 시퀀스를 생성한 후, 상기 복수의 훈련용 문장들 각각에 대한 단어 시퀀스의 전단에, CLS 토큰을 추가하고, 단어 시퀀스의 후단에 SEP 토큰을 추가함으로써, 상기 복수 의 훈련용 문장들 각각에 대응되는 입력 시퀀스를 생성하는 단계, 상기 복수의 훈련용 문장들 각각에 대응되는 입력 시퀀스를 사전 훈련된 BERT 모델에 입력으로 인가하여, 상기 BERT 모델을 통해 출력되는 각 훈련용 문장에 대한 출력 임베딩 시퀀스를 획득하는 단계 및 상기 복수의 훈련용 문장들 각각에 대한 출력 임베딩 시퀀스에서 CLS 토큰을 구성하는 임베딩 벡터를 추출하여, 상기 복수의 훈련용 문장들 각각에 대한 임베딩 벡터를, 출력 값 을 생성하기 위한 완전 연결 계층에 입력으로 인가함으로써, 각 훈련용 문장에 대응되는 예측 값을 산출한 후, 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값이, 각 훈련용 문장에 대응되어 지정되어 있는 정답 값에 최대로 근접하도록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행하는 단계를 포함할 수 있다. 이때, 본 발명의 일실시예에 따르면, 상기 제1 정답 값과 상기 제2 정답 값 중 어느 하나의 정답 값은 '1'로 지 정되어 있고, 다른 하나의 정답 값은 '0'으로 지정되어 있을 수 있고, 이때, 상기 기계학습을 수행하는 단계는 상기 복수의 훈련용 문장들 각각에 대한 임베딩 벡터를 상기 완전 연결 계층에 입력으로 인가하여, 각 훈련용 문장에 대응되는 상기 완전 연결 계층의 출력 값을 획득하고, 획득된 완전 연결 계층의 출력 값을 시그모이드 함수에 입력으로 인가함으로써, 0~1사이의 크기를 갖는, 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값을 산출한 후, 상기 복수의 훈련용 문장들 각각에 대응되는 예측 값이, 각 훈련용 문장에 대응되어 지정되어 있는 정답 값에 최대로 근접하도록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행할 수 있다. 이때, 본 발명의 일실시예에 따르면, 상기 기계학습을 수행하는 단계는 상기 복수의 훈련용 문장들 각각에 대응 되는 예측 값과 각 훈련용 문장에 대응되어 지정되어 있는 정답 값을 기초로, 상기 수학식 1의 손실함수에 따른 손실 값이 최소가 되도록 상기 BERT 모델과 상기 완전 연결 계층에 대한 기계학습을 수행할 수 있다. 또한, 본 발명의 일실시예에 따르면, 단계(S330)에서는 상기 진실 판단 모델의 생성이 완료된 이후에, 진실 여 부 판단의 대상이 되는 상기 제1 문장이 입력으로 인가되면서, 상기 제1 문장의 내용이 진실인지, 거짓인지 여 부를 판단할 것을 지시하는 판단 명령이 인가되면, 상기 제1 문장을 단어별로 구분하여 상기 제1 문장에 대한 단어 시퀀스를 생성한 후, 상기 제1 문장에 대한 단어 시퀀스의 전단에, CLS 토큰을 추가하고, 상기 제1 문장에 대한 단어 시퀀스의 후단에 SEP 토큰을 추가함으로써, 상기 제1 문장에 대응되는 입력 시퀀스를 생성하는 단계,상기 제1 문장에 대응되는 입력 시퀀스를, 기계학습이 완료된 상기 BERT 모델에 입력으로 인가하여, 상기 BERT 모델을 통해 출력되는 상기 제1 문장에 대한 출력 임베딩 시퀀스를 획득하는 단계 및 상기 제1 문장에 대한 출 력 임베딩 시퀀스에서 CLS 토큰을 구성하는 임베딩 벡터를 추출하여, 추출된 임베딩 벡터를 상기 제1 문장에 대 한 기계학습이 완료된 상기 완전 연결 계층에 입력으로 인가함으로써, 상기 제1 문장에 대응되는 판단용 예측 값을 산출한 후, 상기 판단용 예측 값이, 상기 제1 정답 값과 상기 제2 정답 값 중 어느 정답 값에 더 근접한 값인지 확인하여, 상기 판단용 예측 값이 상기 제1 정답 값에 더 근접한 값으로 확인된 경우, 상기 제1 문장의 내용이 진실인 것으로 판단하고, 상기 판단용 예측 값이 상기 제2 정답 값에 더 근접한 값으로 확인된 경우, 상 기 제1 문장의 내용이 거짓인 것으로 판단하는 단계를 포함할 수 있다. 이상, 도 3을 참조하여 본 발명의 일실시예에 따른 전자 장치의 동작 방법에 대해 설명하였다. 여기서, 본 발 명의 일실시예에 따른 전자 장치의 동작 방법은 도 1을 이용하여 설명한 전자 장치의 동작에 대한 구성과 대응될 수 있으므로, 이에 대한 보다 상세한 설명은 생략하기로 한다. 본 발명의 일실시예에 따른 전자 장치의 동작 방법은 컴퓨터와의 결합을 통해 실행시키기 위한 저장매체에 저장 된 컴퓨터 프로그램으로 구현될 수 있다. 또한, 본 발명의 일실시예에 따른 전자 장치의 동작 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로 그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그 램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같 은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실 행될 수 있는 고급 언어 코드를 포함한다. 이상과 같이 본 발명에서는 구체적인 구성 요소 등과 같은 특정 사항들과 한정된 실시예 및 도면에 의해 설명되 었으나 이는 본 발명의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 발명은 상기의 실시예에 한정되 는 것은 아니며, 본 발명이 속하는 분야에서 통상적인 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변형이 가능하다. 따라서, 본 발명의 사상은 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등하거나 등가적 변형이 있는 모든 것들은 본 발명 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2022-0077325", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치의 구조를 도시한 도면이다. 도 2는 본 발명의 일실시예에 따른 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치의 동작을 설명하기 위한 도면이다. 도 3은 본 발명의 일실시예에 따른 인공지능 기반의 진실 판단 모델의 생성을 통해 문장에 포함된 내용의 진실 여부를 판단할 수 있는 전자 장치의 동작 방법을 도시한 순서도이다."}
