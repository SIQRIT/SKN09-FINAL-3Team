{"patent_id": "10-2020-0185615", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0094416", "출원번호": "10-2020-0185615", "발명의 명칭": "근미래 객체 위치 예측 시스템", "출원인": "(주)에이아이매틱스", "발명자": "김진혁"}}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량에서 촬영된 현재 시점 영상으로부터 객체를 인식하고 인식된 객체 각각에 속성을 부여하여 분할한 세그멘테이션(Segmentation) 영상으로 출력하는 세그멘테이션 신경망;상기 세그멘테이션 영상에서 동적 객체를 찾아 제거하여 정적 세그멘테이션 영상으로 변환하는 객체 후처리 모듈;상기 정적 세그멘테이션 영상을 입력받아 상기 정적 세그멘테이션 영상 내에서 동적 객체의 위치를 추정하며,상기 동적 객체가 위치할 것으로 추정되는 지점 각각에 객체 추정 경계 상자를 생성하고, 적어도 하나의 상기객체 추정 경계 상자가 포함된 객체 경계 상자 표본을 생성하여 출력하는 객체 경계 상자 표본 추정 신경망; 및상기 현재 시점 영상과 상기 정적 세그멘테이션 영상을 입력받고, 차량으로부터 상기 현재 시점 영상과 동일한시간의 센싱 신호를 입력 신호로 수신하며, 상기 현재 시점 영상에서 인식되는 동적 객체가 근미래에 위치할 것으로 예상되는 경계 상자를 예측하고 예측된 경계 상자와 상기 객체 추정 경계 상자의 차이인 객체 경계 잔차(Residual)를 연산하며, 상기 객체 경계 상자 표본에 상기 객체 경계 잔차를 가산하여 근미래 동적 객체의 위치를 나타내는 근미래 객체 경계 상자를 적어도 하나 포함하는 근미래 객체 경계 상자 표본을 출력하는 객체 경계잔차 추정 신경망을 포함하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,차량에서 촬영된 영상을 전처리하여 상기 현재 시점 영상을 생성하는 영상 전처리 모듈을 더 포함하는 근미래객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 영상 전처리 모듈은 차량에서 촬영된 영상에 대하여 이미지 크기 변환(Resize) 및 이미지 자르기(Crop) 중적어도 어느 하나를 수행하여 상기 현재 시점 영상을 정규화(Normalization) 하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,차량에 설치된 복수의 센서들로부터 센싱 신호들을 수신하여 정규화 하고 상기 객체 경계 잔차 추정 신경망에상기 입력 신호로 제공하는 신호 전처리 모듈을 더 포함하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 신호 전처리 모듈은 상기 센서들로부터 수신하는 OBD(On-Board Diagnostics) 신호, IMU(InertialMeasurement Unit) 신호, GPS(Global Positioning System) 신호 중 하나 이상을 조합하여 자차의 움직임과 관공개특허 10-2022-0094416-3-련된 자차 운동(Ego-Motion) 신호로 정규화 하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 입력 신호는 자차의 현재 위치, 차속, 오일러 각(euler angle), 회전각, 요 레이트(yaw rate) 중 적어도하나인 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 세그멘테이션 신경망은 상기 현재 시점 영상에서 인식된 객체들의 종류에 따라 서로 다른 속성을 부여하여상기 세그멘테이션 영상을 생성하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 세그멘테이션 신경망은 상기 현재 시점 영상에서 인식된 객체들 중, 동적 객체 각각에 서로 다른 속성을부여하고, 정적 객체는 모두 배경 속성으로 부여하여 상기 세그멘테이션 영상을 생성하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 세그멘테이션 신경망은 상기 현재 시점 영상에서 인식된 객체들 중, 동적 객체 각각에 대하여 서로 다른속성을 부여하고, 정적 객체들은 객체의 종류에 따라 서로 다른 속성을 부여하여 상기 세그멘테이션 영상을 생성하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 세그멘테이션 신경망은 상기 객체를 인식하고 분할하는 학습을 수행함에 있어 크로스-엔트로피(Cross-Entropy) 손실 함수를 이용하여 손실을 계산하고, 학습 결과로부터 확률적 경사하강법(Stochastic GradientDescent)을 이용하여 학습 모델의 파라미터를 갱신하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 객체 후처리 모듈은,상기 세그멘테이션 영상에서 동적 객체를 탐지하는 객체 탐지 신경망; 및상기 세그멘테이션 영상에서 상기 동적 객체가 위치하는 픽셀을 제거하고 제거된 픽셀을 이웃하는 정적 객체의속성으로 채우는 인페인팅 신경망공개특허 10-2022-0094416-4-을 포함하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 인페인팅 신경망은 객체 탐지 신경망으로부터 상기 동적 객체의 중심점 좌표, 폭, 및 높이 정보를 수신하여 상기 동적 객체가 포함되는 경계 상자를 추정하고, 해당 경계 상자 내의 픽셀을 이웃하는 정적 객체의 픽셀로 채우는 것으로 상기 정적 세그멘테이션 영상을 생성하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 객체 경계 상자 표본 추정 신경망은 상기 객체 추정 경계 상자를 추정하고, 추정된 객체 추정 경계 상자를정답과 대비하여 손실률을 계산하고, 계산된 손실률을 최소화하는 과정을 통해 모델 추정 파라미터를 업데이트하여 상기 객체 경계 상자 표본을 출력하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 객체 경계 상자 표본 추정 신경망은 상기 정적 세그멘테이션 영상 내에서 정적 객체의 경계 지점에 가중치를 두어 상기 객체 추정 경계 상자를 예측하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 객체 경계 상자 표본 추정 신경망은 상기 정적 세그멘테이션 영상 내에서 정적 객체의 외곽선에 대한 법선의 각도 변화율이 급격한 지점에 가중치를 두어 상기 객체 추정 경계 상자를 예측하는 근미래 객체 위치 예측시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항에 있어서,상기 객체 경계 잔차 추정 신경망은 상기 근미래 객체 경계 상자 표본과 상기 객체 경계 상자 표본을 대비하여손실률을 계산하고, 계산된 손실률을 최소화하는 과정을 통해 모델 추정 파라미터를 업데이트하여 상기 객체 경계 잔차를 연산하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 객체 경계 잔차 추정 신경망은 상기 현재 시점 영상에서 인식된 동적 객체의 위치와 상기 정적 세그멘테이션 영상 내에서의 정적 객체 경계 지점이 중복되는 위치에 가중치를 두어 상기 객체 경계 잔차를 연산하는 근미래 객체 위치 예측 시스템.공개특허 10-2022-0094416-5-청구항 18 제16항에 있어서,상기 객체 경계 잔차 추정 신경망은 상기 현재 시점 영상의 특징맵과 상기 정적 세그멘테이션 영상의 특징맵을연결하고, 상기 입력 신호를 이용하여 특징맵 연결지점을 보정하는 것으로 상기 객체 경계 잔차를 연산하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1항에 있어서,상기 현재 시점 영상에 대한 상기 근미래 객체 경계 상자 표본을 하나의 입력으로 수신하여 상기 현재 시점 영상에 출현하지 아니한 객체의 종류 및 미래 위치를 예측하여 최종 미래 객체 경계 가설 상자로 출력하는 근미래객체 경계 가설 상자 예측 신경망을 더 포함하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 근미래 객체 경계 가설 상자 예측 신경망은, 현재 시점으로부터 소정의 과거까지의 영상의 이력과, 상기세그멘테이션 신경망으로부터 출력되는 현재 시점으로부터 소정의 과거까지의 세그멘테이션 영상의 이력과, 상기 영상 이력에 포함되는 영상 각각에 대응하는 상기 입력 신호의 이력을 입력받고, 상기 근미래 객체 경계 상자 표본을 기반으로 한 확률적 모델(GMM: Gaussian Mixture Model)을 생성하고, 상기 확률적 모델의 평균을 중심점 좌표로, 표준편차를 폭 및 높이로 정하여 상기 최종 미래 객체 경계 가설 상자를 생성하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 근미래 객체 경계 가설 상자 예측 신경망은, 차량의 내비게이션 단말을 통해 출력되는 상기 현재 시점 영상에 상기 최종 미래 객체 경계 가설 상자를 오버레이하여 표시하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서,상기 근미래 객체 경계 가설 상자 예측 신경망은, 상기 최종 미래 객체 경계 가설 상자에 주석을 첨부하거나 상기 최종 미래 객체 경계 가설 상자의 색상을 달리하는 것으로 객체의 종류를 표시하는 근미래 객체 위치 예측시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제1항에 있어서,상기 현재 시점 영상에 대한 상기 근미래 객체 경계 상자 표본을 하나의 입력으로 수신하여 상기 현재 시점 영상에 출현된 객체의 종류 및 미래 위치를 예측하여 최종 미래 객체 경계 상자로 출력하는 근미래 객체 경계 상자 예측 신경망을 더 포함하는 근미래 객체 위치 예측 시스템.공개특허 10-2022-0094416-6-청구항 24 제23항에 있어서,상기 근미래 객체 경계 상자 예측 신경망은, 현재 시점으로부터 소정의 과거까지의 영상의 이력과, 상기 세그멘테이션 신경망으로부터 출력되는 현재 시점으로부터 소정의 과거까지의 세그멘테이션 영상의 이력과, 상기 영상이력에 포함되는 영상 각각에 대응하는 상기 입력 신호의 이력과, 상기 객체 후처리 모듈의 후단의 마스크 생성모듈로부터 출력되는 동적 객체를 제외한 영역을 마스크 처리한 객체 마스크 영상 이력을 입력받고, 상기 근미래 객체 경계 상자 표본을 기반으로 한 확률적 모델(GMM: Gaussian Mixture Model)을 생성하고, 상기 확률적 모델의 평균을 중심점 좌표로, 표준편차를 폭 및 높이로 정하여 상기 최종 미래 객체 경계 상자를 생성하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제24항에 있어서,상기 근미래 객체 경계 상자 예측 신경망은, 차량의 내비게이션 단말을 통해 출력되는 상기 현재 시점 영상에상기 최종 미래 객체 경계 상자를 오버레이하여 표시하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제25항에 있어서,상기 근미래 객체 경계 상자 예측 신경망은, 상기 최종 미래 객체 경계 상자에 주석을 첨부하거나 상기 최종 미래 객체 경계 상자의 색상을 달리하는 것으로 객체의 종류를 표시하는 근미래 객체 위치 예측 시스템."}
{"patent_id": "10-2020-0185615", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 카메라에서 촬영된 현재 시점의 영상을 인공 지능 기반으로 학습하여 동적 객체의 위치를 추정한 표본 을 샘플링하며, 동적 객체 위치 추정 표본을 이력 데이터를 이용하여 확률적 모델로 변경하는 학습을 통해, 동적 객체의 근미래 위치를 예측하는 근미래 객체 위치 예측 시스템에 관한 것으로서, 차량에서 촬영된 현재 시점 영 (뒷면에 계속)"}
{"patent_id": "10-2020-0185615", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 카메라에서 촬영된 현재 시점의 영상을 인공 지능 기반으로 학습하여 동적 객체의 위치를 추정한 표 본을 샘플링하며, 동적 객체 위치 추정 표본을 이력 데이터를 이용하여 확률적 모델로 변경하는 학습을 통해, 동적 객체의 근미래 위치를 예측하는 근미래 객체 위치 예측 시스템에 관한 것이다."}
{"patent_id": "10-2020-0185615", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 영상 인식 기술은 카메라에서 촬영되는 영상으로부터 객체의 위치를 인식하고, 인식된 객체의 종류 를 판별하며, 자율 주행 차량, 감시 카메라 시스템, 로봇 제어 등 다양한 산업분야에서 활용되고 있다. 예를 들 어, 자율 주행 차량에서는 정적 객체(차선, 신호등, 표지판, 건물, 보도, 장애물 등과 같은)를 인식하고 인식 결과를 토대로 차량의 주행 자세를 제어할 수 있다. 자율 주행 차량이 동적 객체(주변 차량, 보행자, 자전거, 이륜차 등과 같은)를 인식하는 경우 동적 객체와의 충돌을 예측하고 경고하거나 충돌을 회피하기 위한 자세 제 어를 수행할 수 있다. 자율 주행 차량에서 객체를 인식하고 객체에 대응하는 다른 예로서, 로봇 제어나 감시 카 메라 시스템 등에서 객체 인식 시스템이 이용될 수 있다. 종래 영상으로부터 객체의 위치를 인식하고, 이동 객체의 향후 위치를 예측하는 기술들은 주로 동역학적 접근에 근거하여 발전해왔다. 도 1을 참조하면, 영상으로부터 인식된 이동 객체의 위치가 과거 d1 지점에서 현재 d2 지점으로 이동한 경우, d1과 d2의 위치 정보 및 시간 정보를 이용하여 속도를 얻을 수 있다. 그리고 이동 객 체의 미래 위치인 d3의 위치 정보는 이동 객체가 같은 이동 방향 및 속력으로 이동할 것이라는 전제로 예측된다. 즉, 종래의 동역학적 접근 방식은 단 하나의 예측 위치만을 제시할 수 있다. 하지만, 도 2에서와 같이 객체들은 현재의 지정학적 위치 또는 다른 객체들과의 상호 관계에 다양하게 변화될 수 있는데, 종래의 동영학적 접근 방식에서는 이러한 변화에 대한 고려를 할 수 없어 객체의 미래 위치를 예측 하는데 한계가 있다. 도 2를 참조하면, 이동 객체가 보행자이며 횡단보도의 끝 지점에 위치하고 있다고 가 정해보자. 보행자의 과거에서 현재까지의 이동방향은 화살표 1로 나타낼 수 있다. 보행자는 동일한 이 동 방향과 속력으로 이동할 수 있으며(화살표 2), 횡단보도를 따라 이동 방향을 바꿀 수도 있으며(화살표 3),우측으로 약간 방향을 틀어 보도를 따라 계속 걸어갈 수도 있으며(화살표 4), 자신을 태우러 온 차량에 탑승하 기 위해 크게 방향을 전환할 수도 있으며(화살표 5), 갑자기 도로를 대각선으로 가로질러 무단횡단 할 수도 있 다(화살표 6). 보행자가 화살표 6의 방향으로 무단횡단을 시도할 가능성은 매우 적지만, 이는 실제로 일어 나는 교통사고의 유형 중 하나로서 반드시 고려될 필요가 있다. 도 2를 참조하여 고찰할 때, 근미래(near future) 객체의 위치를 예측할 때 과거의 정보를 이용하여 단 하나의 위치만을 예측하는 것은 바람직하지 않다는 것을 확인할 수 있다. 또한, 이동 객체의 움직임은 이동 객체의 종 류와 특성이 영상의 배경에서 정적 객체와 어떤 관계에 있는지, 그리고 다른 동적 객체와 어떤 상호 작용을 하 는지를 고려할 필요가 있다. 나아가, 이동 객체들은 주로 지능을 가진 생명체이거나 생명체에 의해 조작되는 장 치들로서, 동일한 외부 환경에 위치하는 경우에도 다른 행동양식을 보일 수 있으므로, 단지 외부 환경을 관찰하 는 것만으로는 정확한 예측을 할 수 없다. 즉, 향상된 근미래 객체 위치 예측 시스템이 제공될 필요성이 제기되 고 있다. 한편, 종래의 객체 인식 시스템은 이동 객체의 움직임을 예측하는데 있어서, 현재 시점에서 인지되는 객체에 대 해서만 미래 위치를 예측하고 있었다. 예를 들어, 대한민국 특허등록 제10-1979375호 \"감시 영상의 객체 행동 예측 방법\", 대한민국 특허등록 제10-2143034호 \"객체의 미래 움직임 예측을 통한 동영상에서의 객체 추적을 위 한 방법 및 시스템\", 대한민국 특허등록 제10-2143031호 \"정지 영상에서 객체의 미래 움직임을 예측하는 방법 및 시스템\", 대한민국 특허공개 제10-2020-0039547호 \"트래킹 네트워크를 포함한 CNN을 사용하여 객체를 트래킹 하는 방법 및 이를 이용한 장치\" 등은, 객체를 인식한 후에 객체의 움직임 패턴을 인공 학습하거나 객체를 인공 학습 방법으로 추적하여 객체의 근미래 위치를 예측하고 있는데, 모두 현재 시점에서 인지되는 객체에 대하여만 미래 위치나 이동 패턴 등을 예측할 수 있을 뿐이다. 하지만, 실제 주행 환경에서는 주차된 차량에 가려지거나 보도의 굴곡진 부분에서 건물 모퉁이에 가려진 보행자 가 갑자기 나타날 수 있다. 즉, 향상된 근미래 객체 위치 예측 시스템에서는 현재 영상에서 존재하지 않는 객체 들에 대한 예측도 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 특허등록 제10-1979375호 (특허문헌 0002) 대한민국 특허등록 제10-2143034호 (특허문헌 0003) 대한민국 특허등록 제10-2143031호 (특허문헌 0004) 대한민국 특허공개 제10-2020-0039547호"}
{"patent_id": "10-2020-0185615", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 카메라에서 촬영된 영상을 인공 지능 기반으로 학습하여 현재 시점 영상으로부터 동적 객체를 인식하 고 동적 객체의 근미래 위치를 예측하는 시스템을 제공하기 위한 것으로서, 현재 시점의 이미지로부터 동적 객 체를 제외한 정적인 배경이 제공하는 맥락 안에서 인공 지능 학습을 통해 동적 객체의 위치를 추정하며 표본을 생성하며, 동적 객체를 인식한 결과를 토대로 근미래 객체의 경계 상자와 표본에서 추정된 객체 추정 경계 상자 의 잔차를 학습하여 근미래 객체 경계 상자를 예측하는 것으로써, 현재 시점 영상에 이미 출현된 동적 객체의 근미래 위치는 물론 현재 시점 영상에서 출현되지 아니한 동적 객체의 근미래 위치도 예측할 수 있으며, 동적 객체의 돌발적인 위치 변동까지 예측 가능한 근미래 객체 위치 예측 시스템을 제공함에 그 목적이 있다. 또한, 본 발명은 소정의 과거 시점부터 현재 시점까지의 영상 이력과 입력 신호 이력 등을 이용하여 N개의 근미 래 객체 경계 상자 표본을 K개의 확률적 모델(Gaussian Mixture Model)로 변경하여 최종 미래 객체 경계 상자 (현재 시점에서 관찰되는 동적 객체의 근미래 위치를 나타내는 경계 상자) 및 최종 미래 객체 경계 가설 상자 (현재 시점에서 관찰되지 않는 동적 객체의 근미래 위치를 나타내는 경계 상자)로 시각화함으로써, 동적 객체의 돌발적인 위치 변동을 예측하고 차량 운전자의 안전 운전을 도모할 수 있도록 하는 근미래 객체 위치 예측 시스템을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2020-0185615", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일실시예에 따른 근미래 객체 위치 예측 시스템은, 차량에서 촬영된 현재 시점 영상으로부터 객체를 인식하고 인식된 객체 각각에 속성을 부여하여 분할한 세그멘테이션(Segmentation) 영상으로 출력하는 세그멘테 이션 신경망; 상기 세그멘테이션 영상에서 동적 객체를 찾아 제거하여 정적 세그멘테이션 영상으로 변환하는 객 체 후처리 모듈; 상기 정적 세그멘테이션 영상을 입력받아 상기 정적 세그멘테이션 영상 내에서 동적 객체의 위 치를 추정하며, 상기 동적 객체가 위치할 것으로 추정되는 지점 각각에 객체 추정 경계 상자를 생성하고, 적어 도 하나의 상기 객체 추정 경계 상자가 포함된 객체 경계 상자 표본을 생성하여 출력하는 객체 경계 상자 표본 추정 신경망; 및 상기 현재 시점 영상과 상기 정적 세그멘테이션 영상을 입력받고, 차량으로부터 상기 현재 시 점 영상과 동일한 시간의 센싱 신호를 입력 신호로 수신하며, 상기 현재 시점 영상에서 인식되는 동적 객체가 근미래에 위치할 것으로 예상되는 경계 상자를 예측하고 예측된 경계 상자와 상기 객체 추정 경계 상자의 차이 인 객체 경계 잔차(Residual)를 연산하며, 상기 객체 경계 상자 표본에 상기 객체 경계 잔차를 가산하여 근미래 동적 객체의 위치를 나타내는 근미래 객체 경계 상자를 적어도 하나 포함하는 근미래 객체 경계 상자 표본을 출 력하는 객체 경계 잔차 추정 신경망을 포함한다. 본 발명의 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 차량에서 촬영된 영상을 전처리하여 상기 현재 시점 영상을 생성하는 영상 전처리 모듈을 더 포함한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 영상 전처리 모듈은 차량에서 촬영된 영상에 대하여 이미지 크기 변환(Resize) 및 이미지 자르기(Crop) 중 적어도 어느 하나를 수행하여 상기 현재 시점 영상을 정규화(Normalization) 한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 차량에 설치된 복수의 센서들로부터 센싱 신호들을 수신하여 정규화 하고 상기 객체 경계 잔차 추정 신경망에 상기 입력 신호로 제공하는 신호 전처리 모 듈을 더 포함한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 신호 전처리 모듈은 상기 센서들로부 터 수신하는 OBD(On-Board Diagnostics) 신호, IMU(Inertial Measurement Unit) 신호, GPS(Global Positioning System) 신호 중 하나 이상을 조합하여 자차의 움직임과 관련된 자차 운동(Ego-Motion) 신호로 정 규화 한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 입력 신호는 자차의 현재 위치, 차속, 오일러 각(euler angle), 회전각, 요 레이트(yaw rate) 중 적어도 하나이다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 세그멘테이션 신경망은 상기 현재 시 점 영상에서 인식된 객체들의 종류에 따라 서로 다른 속성을 부여하여 상기 세그멘테이션 영상을 생성한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 세그멘테이션 신경망은 상기 현재 시 점 영상에서 인식된 객체들 중, 동적 객체 각각에 서로 다른 속성을 부여하고, 정적 객체는 모두 배경 속성으로 부여하여 상기 세그멘테이션 영상을 생성한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 세그멘테이션 신경망은 상기 현재 시 점 영상에서 인식된 객체들 중, 동적 객체 각각에 대하여 서로 다른 속성을 부여하고, 정적 객체들은 객체의 종 류에 따라 서로 다른 속성을 부여하여 상기 세그멘테이션 영상을 생성한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 세그멘테이션 신경망은 상기 객체를 인식하고 분할하는 학습을 수행함에 있어 크로스-엔트로피(Cross-Entropy) 손실 함수를 이용하여 손실을 계산하 고, 학습 결과로부터 확률적 경사하강법(Stochastic Gradient Descent)을 이용하여 학습 모델의 파라미터를 갱 신한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 객체 후처리 모듈은, 상기 세그멘테이 션 영상에서 동적 객체를 탐지하는 객체 탐지 신경망; 및 상기 세그멘테이션 영상에서 상기 동적 객체가 위치하 는 픽셀을 제거하고 제거된 픽셀을 이웃하는 정적 객체의 속성으로 채우는 인페인팅 신경망을 포함한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 인페인팅 신경망은 객체 탐지 신경망 으로부터 상기 동적 객체의 중심점 좌표, 폭, 및 높이 정보를 수신하여 상기 동적 객체가 포함되는 경계 상자를추정하고, 해당 경계 상자 내의 픽셀을 이웃하는 정적 객체의 픽셀로 채우는 것으로 상기 정적 세그멘테이션 영 상을 생성한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 객체 경계 상자 표본 추정 신경망은 상기 객체 추정 경계 상자를 추정하고, 추정된 객체 추정 경계 상자를 정답과 대비하여 손실률을 계산하고, 계 산된 손실률을 최소화하는 과정을 통해 모델 추정 파라미터를 업데이트하여 상기 객체 경계 상자 표본을 출력한 다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 객체 경계 상자 표본 추정 신경망은 상기 정적 세그멘테이션 영상 내에서 정적 객체의 경계 지점에 가중치를 두어 상기 객체 추정 경계 상자를 예측 한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 객체 경계 상자 표본 추정 신경망은 상기 정적 세그멘테이션 영상 내에서 정적 객체의 외곽선에 대한 법선의 각도 변화율이 급격한 지점에 가중치를 두어 상기 객체 추정 경계 상자를 예측한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 객체 경계 잔차 추정 신경망은 상기 근미래 객체 경계 상자 표본과 상기 객체 경계 상자 표본을 대비하여 손실률을 계산하고, 계산된 손실률을 최소 화하는 과정을 통해 모델 추정 파라미터를 업데이트하여 상기 객체 경계 잔차를 연산한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 객체 경계 잔차 추정 신경망은 상기 현재 시점 영상에서 인식된 동적 객체의 위치와 상기 정적 세그멘테이션 영상 내에서의 정적 객체 경계 지점이 중복되는 위치에 가중치를 두어 상기 객체 경계 잔차를 연산한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 객체 경계 잔차 추정 신경망은 상기 현재 시점 영상의 특징맵과 상기 정적 세그멘테이션 영상의 특징맵을 연결하고, 상기 입력 신호를 이용하여 특 징맵 연결지점을 보정하는 것으로 상기 객체 경계 잔차를 연산한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 현재 시점 영상에 대한 상기 근미래 객체 경계 상자 표본을 하나의 입력으로 수신하여 상기 현재 시점 영상에 출현하지 아니한 객체의 종류 및 미래 위치를 예측하여 최종 미래 객체 경계 가설 상자로 출력하는 근미래 객체 경계 가설 상자 예측 신경망을 더 포 함한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 근미래 객체 경계 가설 상자 예측 신 경망은, 현재 시점으로부터 소정의 과거까지의 영상의 이력과, 상기 세그멘테이션 신경망으로부터 출력되는 현 재 시점으로부터 소정의 과거까지의 세그멘테이션 영상의 이력과, 상기 영상 이력에 포함되는 영상 각각에 대응 하는 상기 입력 신호의 이력을 입력받고, 상기 근미래 객체 경계 상자 표본을 기반으로 한 확률적 모델(GMM: Gaussian Mixture Model)을 생성하고, 상기 확률적 모델의 평균을 중심점 좌표로, 표준편차를 폭 및 높이로 정 하여 상기 최종 미래 객체 경계 가설 상자를 생성한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 근미래 객체 경계 가설 상자 예측 신 경망은, 차량의 내비게이션 단말을 통해 출력되는 상기 현재 시점 영상에 상기 최종 미래 객체 경계 가설 상자 를 오버레이하여 표시한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 근미래 객체 경계 가설 상자 예측 신 경망은, 상기 최종 미래 객체 경계 가설 상자에 주석을 첨부하거나 상기 최종 미래 객체 경계 가설 상자의 색상 을 달리하는 것으로 객체의 종류를 표시한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 현재 시점 영상에 대한 상기 근미래 객체 경계 상자 표본을 하나의 입력으로 수신하여 상기 현재 시점 영상에 출현된 객체의 종류 및 미래 위치를 예측하여 최종 미래 객체 경계 상자로 출력하는 근미래 객체 경계 상자 예측 신경망을 더 포함한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 근미래 객체 경계 상자 예측 신경망은, 현재 시점으로부터 소정의 과거까지의 영상의 이력과, 상기 세그멘테이션 신경망으로부터 출력되는 현재 시점으로부터 소정의 과거까지의 세그멘테이션 영상의 이력과, 상기 영상 이력에 포함되는 영상 각각에 대 응하는 상기 입력 신호의 이력과, 상기 객체 후처리 모듈의 후단의 마스크 생성 모듈로부터 출력되는 동적 객체 를 제외한 영역을 마스크 처리한 객체 마스크 영상 이력을 입력받고, 상기 근미래 객체 경계 상자 표본을 기반 으로 한 확률적 모델(GMM: Gaussian Mixture Model)을 생성하고, 상기 확률적 모델의 평균을 중심점 좌표로, 표준편차를 폭 및 높이로 정하여 상기 최종 미래 객체 경계 상자를 생성한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 근미래 객체 경계 상자 예측 신경망은, 차량의 내비게이션 단말을 통해 출력되는 상기 현재 시점 영상에 상기 최종 미래 객체 경계 상자를 오버레이하여 표시한다. 본 발명의 또 다른 실시예에 따른 근미래 객체 위치 예측 시스템은, 상기 근미래 객체 경계 상자 예측 신경망은, 상기 최종 미래 객체 경계 상자에 주석을 첨부하거나 상기 최종 미래 객체 경계 상자의 색상을 달리 하는 것으로 객체의 종류를 표시한다."}
{"patent_id": "10-2020-0185615", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 근미래 객체 위치 예측 시스템에 따르면, 동적 객체를 인식한 후에 동역학적으로 동적 객체를 추적하 는 것이 아니라, 현재 시점의 이미지로부터 동적 객체를 제외한 정적인 배경이 제공하는 맥락 안에서 인공 지능 학습을 통해 동적 객체의 위치를 추정하며 표본을 생성하며, 동적 객체를 인식한 결과를 토대로 근미래 객체의 경계 상자와 표본에서 추정된 객체 추정 경계 상자의 잔차를 학습하여 근미래 객체 경계 상자를 예측함으로써, 현재 시점 영상에서 인식된 동적 객체의 근미래 위치, 현재 시점 영상에서 출현되지 아니한 동적 객체의 근미래 위치, 동적 객체의 돌발적인 위치 변동을 예측할 수 있고, 자율 주행 차량에서 동적 객체에 대한 충돌 회피 가 능성을 획기적으로 높일 수 있는 효과가 있다. 또한, 본 발명에 따르면, 소정의 과거 시점부터 현재 시점까지의 영상 이력과 입력 신호 이력 등을 이용하여 N 개의 근미래 객체 경계 상자 표본을 K개의 확률적 모델(Gaussian Mixture Model)로 변경하여 최종 미래 객체 경 계 상자(현재 시점에서 관찰되는 동적 객체의 근미래 위치를 나타내는 경계 상자) 및 최종 미래 객체 경계 가설 상자(현재 시점에서 관찰되지 않는 동적 객체의 근미래 위치를 나타내는 경계 상자)로 시각화함으로써, 동적 객 체의 돌발적인 위치 변동을 예측하고 차량 운전자의 안전 운전을 도모할 수 있도록 하는 효과가 있다."}
{"patent_id": "10-2020-0185615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부된 도면을 참조하여 본 발명에 따른 구체적인 실시예가 설명된다. 그러나 이는 본 발명을 특정 한 실시 형태에 대하여 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물, 대체물을 포함하는 것으로 이해되어야 한다. 명세서 전체에 걸쳐 유사한 구성 및 동작을 갖는 부분에 대해서는 동일한 도면 부호를 붙였다. 그리고 본 발명 에 첨부된 도면은 설명의 편의를 위한 것으로서, 그 형상과 상대적인 척도는 과장되거나 생략될 수 있다.실시예를 구체적으로 설명함에 있어서, 중복되는 설명이나 당해 분야에서 자명한 기술에 대한 설명은 생략되었 다. 또한, 이하의 설명에서 어떤 부분이 다른 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없 는 한 기재된 구성요소 외에 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 \"~부\", \"~기\", \"~모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 어떤 부분이 다른 부분과 전기적으로 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라 그 중 간에 다른 구성을 사이에 두고 연결되어 있는 경우도 포함한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제2 구성요소는 제1 구성요소로 명 명될 수 있고, 유사하게 제1 구성요소도 제2 구성요소로 명명될 수 있다. 본 발명에 따른 근미래 객체 위치 예측 시스템은 카메라로부터 촬영된 영상(image)을 핵심적인 데이터로 사용하 며, 현재 시점 영상 내에 포함된 동적 객체의 근미래 위치를 예측한다. 여기서, 동적 객체라 함은 주변 차량, 보행자, 자전거, 이륜차 등과 같은 움직이는 객체를 의미한다. 본 발명에서 사용되는 용어 중 정적 객체는 동적 객체와는 반대로 움직이지 않는 객체를 의미하며, 예컨대, 차선, 신호등, 표지판, 건물, 보도, 장애물 등과 같 은 객체이다. 본 발명의 근미래 객체 위치 예측 시스템에 대하여 구체적으로 설명하기에 앞서, 먼저 도 3을 참조하여 카메라 로부터 촬영된 영상이 이미지 데이터로 변환되는 과정을 설명한다. 카메라는 3차원의 실세계를 렌지를 통하여 2차원 평면으로 투영되는 변환 장치이다. 카메라 내의 수광부에서 수 광한 상들은 영상 센서(image sensor)를 통해 디지털 신호로 변환된다. 디지털 신호는 영상의 가로, 세로 크기 와 단위 픽셀(pixel)의 분해능을 나타내는 2차원 평면 데이터이다. 각 픽셀의 RGB 데이터는 실세계 객체들의 색 상 정보를 표현하는 데이터이며, 하나의 영상 프레임에 포함된 2차원 평면 데이터인 정지 영상은 이하의 설명에 서 '영상'으로 설명된다. 영상이 촬영된 시점이 현재인 경우 현재 시점 영상으로 설명된다. 한편, 시간 간격을 두고 반복적으로 촬영되어 저장된 영상들을 순차 영상(image sequence)이라 표현하며, 이하의 설명에서는 '영상 이력'으로 설명된다. 본 발명의 근미래 객체 위치 예측 시스템은, 영상 내 픽셀 각각에 의미론적 속성을 부여하는 신경망 기법을 이 용하여 영상을 전처리함으로써, 동적 객체가 배제되고 정적 객체만으로 구성되는 배경 영상을 생성한다. 그리고 현재 시점 영상을 입력으로 하고 근미래 영상을 정답(ground truth)으로 하는 후처리 신경망 학습을 통하여, 영 상에 나타나 있거나(이미 현재 시점 영상에 출현된) 나타날 것으로 예상되는(현재 시점 영상에서는 출현되지 아 니한) 동적 객체의 근미래 위치를 예측하는 방법을 제안한다. 여기서, 카메라가 장착된 차량이 도로를 주행하는 경우 카메라의 위치와 각도는 점진적으로 변화된다. 카메라의 움직임은 그로부터 촬영되는 영상의 변화를 초래하므로, 영상 학습 시에 카메라의 움직임에 대한 보정이 요구된 다. 본 발명에서는 이러한 카메라 움직임을 보정하기 위해 차량 센싱 신호가 입력 신호로서 이용된다. 예를 들 어, 차량 내부의 CAN(Car Area Network) 통신을 통해, 또는, OBD(On-Board Diagnostics) 단자를 통해 차량의 주행 속도, 회전각, 회전 각속도(yaw rate)를 획득할 수 있다. 다른 예로서, 차량의 내비게이션 단말이나 관성 센서(IMU)로부터 3축 가속도(X, Y, Z), 3축 회전각속도(yaw, pitch, roll), 3축 지자기 등을 얻을 수 있다. 또 다른 예로서, GPS 모듈로부터 위성에서 관측된 위도, 경도, 이동방향, 속도 등을 얻을 수 있다. 나아가, V2V(Vehicle to Vehicle), V2I(Vehicle to Infra), WiFi, LTE, 5G 통신망을 통해 추정되는 위치 및 이동 속도, Lidar, Radar 등 차량에 장착된 거리 센서로부터 고정 시설물에 대한 상대 거리 측정을 통해 획득하는 위치 및 이동 속도 등의 정보 역시 얻을 수 있다. 열거한 입력 신호 중 어느 하나를 이용하여, 또는, 이들 신호들을 복 합적으로 이용하여 영상 내 객체 위치들이 보정될 수 있을 것이다. 도 4는 본 발명에 따른 근미래 객체 위치 예측 시스템을 예시한 블록도이고, 도 5는 도 4에서 근미래 객체 예측 신경망의 구조를 예시한 블록도이다. 도 4를 참조하면, 본 발명의 근미래 객체 위치 예측 시스템은 영상 전처리 모듈과, 영상 버퍼와, 세 그멘테이션 신경망과, 세그멘테이션 버퍼와, 객체 후처리 모듈과, 객체 경계 상자 표본 추정 신 경망과, 객체 경계 잔차 추정 신경망과, 마스크 생성 모듈과, 마스크 버퍼와, 신호 전처리 모듈과, 신호 버퍼와, 근미래 객체 예측 신경망으로 구성된다. 도 5를 참조하면, 근미래 객체예측 신경망은 근미래 객체 경계 가설 상자 예측 신경망과, 근미래 객체 경계 상자 예측 신경망(32 0)으로 구성된다. 영상 전처리 모듈은 카메라로부터 촬영된 현재 시점()에서의 로우 레벨의 영상()을 수신한다. 이 현재 시점의 로우 레벨 영상()은 카메라로부터 직접 수신되거나 차량 내 다른 장치를 경유하여 수신될 수 있다. 또한, 본 발명의 근미래 객체 위치 예측 시스템이 클라우드 서버에 구축되는 경우, 현재 시점의 로우 레벨 영상 ()은 차량으로부터 원격으로 수신될 수 있다. 영상 전처리 모듈은 로우 레벨의 영상()을 전처리하여 현재 시점 영상()을 생성한다. 영상 전처리 모 듈은 로우 레벨의 영상()에 대하여 이미지 크기 변환(Resize) 및 이미지 자르기(Crop) 중 적어도 어느 하나를 수행하여 정규화 하는 것으로서 현재 시점 영상()을 생성한다. 영상 버퍼는 영상 데이터들을 프레임 단위로 고속 전송하는 수단으로서, 근미래 객체 예측 신경망에 현재 시점()으로부터 소정의 과거 시점()까지의 영상 이력()을 전송하기 위한 수단이다. 신호 전처리 모듈은 차량에 설치된 복수의 센서들로부터 센싱 신호들을 수집하여 정규화하는 수단이다. 신 호 전처리 모듈은 차량 센서들로부터 OBD(On-Board Diagnostics) 신호, IMU(Inertial Measurement Unit) 신호, GPS(Global Positioning System) 신호들, 즉, 현재 시점()에서의 로우 레벨의 신호()들을 수신하고, 이들을 조합하여 자차의 움직임과 관련된 자차 운동(Ego-Motion) 신호로 정규화 한다. 정규화 된 신 호는 본 발명에서 객체 경계 잔차 추정 신경망의 현재 시점 입력 신호()로서 제공된다. 예컨대, 입력 신 호()는 정규화 된 자차의 현재 위치, 차속, 오일러 각(euler angle), 회전각, 요 레이트(yaw rate) 중 적어도 어느 하나이거나, 이들 정규화 신호가 조합된 신호이다. 신호 버퍼는 입력 신호()들을 고속 전송하는 수단으로서, 근미래 객체 예측 신경망에 현재 시점 ()으로부터 소정의 과거 시점()까지의 입력 신호 이력()을 전송하기 위한 수단이다. 도 4 및 5에 도시된 나머지 블록들에 대하여는 도 6 이하를 참조하여 구체적으로 후술한다. 도 6은 본 발명에서 근미래 객체 경계 상자 표본을 학습하는 과정을 상세하게 묘사한 블록도이다. 도 6을 참조하면, 세그멘테이션 신경망은 차량에서 촬영된 현재 시점 영상(, 610)으로부터 객체를 인식하 고 인식된 객체 각각에 속성을 부여하여 분할한 세그멘테이션(Segmentation) 영상(, 620)으로 출력한다. 객체 후처리 모듈은 세그멘테이션 영상에서 동적 객체를 찾아 제거하여 정적(Static) 세그멘테이션 영상 (,630)으로 변환한다. 도 6에서 점선 박스로 표시한 세그멘테이션 신경망과 객체 후처리 모듈은 본 발명에서 현재 시점 영상에 의미론적 속성을 부여하여 영상을 전처리하는 과정에 해당된다. 도 8은 본 발명에서 세그멘테이션 신경망의 구조를 예시한 블록도로서, 시맨틱 세그멘테이션(Semantic Segmentation) FCN(Fully Convolutional Network) 구조를 예시한 것이다. 시멘택 세그멘테이션은 영상 내의 모 든 객체들을 의미있는 단위로 분할하는 작업을 의미하며, 영상 내 모든 픽셀의 레이블을 예측하는 dense prediction으로 지칭되기도 한다. 시맨틱 세그멘테이션 FCN은 입력 영상을 단계적으로 학습하여 객체들이 분할된 세그멘테이션 영상으로 출력한다. 세그멘테이션 신경망은 반드시 시맨틱 세그멘테이션 FCN으 로 구성될 필요는 없으며, 인스턴스 세그멘테이션(Instance Segmentation) 신경망 또는 패납틱 세그멘테이션 (Panoptic Segmentation) 신경망으로 구성될 수도 있다. 도 9의 (a)는 현재 시점 영상()의 일예를 보인 것이다. 세그멘테이션 신경망은 도 8에 예시한 바와 같은 시맨틱 세그멘테이션 신경망으로 구성될 수 있으며, 이 경우 현재 시점 영상()에서 인식된 객체들의 종류에 따 라 서로 다른 속성을 부여하여 세그멘테이션 영상()을 생성한다. 가령, 영상 내에서 하늘 영역, 도로 영역, 건 물 영역, 표지판 영역, 차량 영역, 사람 영역 등 객체의 종류별로 속성이 부여되어 도 9의 (b)에서와 같이 시맨 틱(Semantic) 세그멘테이션 영상이 생성된다. 다른 예로서, 세그멘테이션 신경망은 인스턴스 세그멘테이션(Instance Segmentation) 신경망으로 구성될 수도 있다. 이 경우, 현재 시점 영상()에서 인식된 객체들 중, 동적 객체 각각에 서로 다른 속성을 부여하고, 정적 객체는 모두 배경 속성으로 부여하여 세그멘테이션 영상()을 생성한다. 예컨대, 차량1, 차량2, 차량3, 사 람1, 사람2, 사람3 등과 같이 동적 객체 각각이 서로 다른 속성으로 부여되고 나머지 정적 객체들은 모두 동일 한 속성으로 부여되어 도 9의 (c)에서와 같이 인스턴스(Instance) 세그멘테이션 영상이 생성된다. 또 다른 예로서, 세그멘테이션 신경망은 패납틱 세그멘테이션(Panoptic Segmentation) 신경망으로 구성될 수도 있다. 이 경우, 현재 시점 영상()에서 인식된 객체들 중, 동적 객체 각각에 대하여 서로 다른 속성을 부 여하고, 정적 객체들은 객체의 종류에 따라 서로 다른 속성을 부여하여 세그멘테이션 영상()을 생성한다. 패납 틱(Panoptic) 세그멘테이션 신경망은 동적 객체는 Instance Segmentation으로 정적 객체는 Semantic Segmentation으로 분할하는 것으로서, 도 9의 (d)에서와 같이 차량1, 차량2, 차량3, 사람1, 사람2, 사람3 등 각 각의 동적 객체들이 독립적으로 분할되며, 하늘 영역, 도로 영역, 건물 영역, 표지판 영역 등의 정적 객체들은 동일한 클래스들이 동일한 속성을 갖도록 분할된다. 세그멘테이션 신경망은 객체를 인식하고 분할하는 학습을 수행함에 있어 크로스-엔트로피(Cross-Entropy) 손실 함수를 이용하여 손실을 계산하고, 학습 결과로부터 확률적 경사하강법(Stochastic Gradient Descent)을 이용하여 학습 모델의 파라미터를 갱신할 수 있다. 한편, 도 4를 참조하면, 세그멘테이션 버퍼는 세그멘테이션 신경망에서 출력되는 세그멘테이션 영상 ()들을 후술하는 근미래 객체 예측 신경망에 고속으로 전송하는 수단으로서, 현재 시점()으로부터 소정 의 과거 시점()까지의 세그멘테이션 영상 이력()을 전송하기 위한 수단이다. 도 10은 본 발명에서 객체 후처리 모듈을 상세하게 묘사한 블록도이다. 도 10을 참조하여 객체 후처리 모듈 이 세그멘테이션 영상(, 1010)으로부터 동적 객체를 찾아 제거하여 정적(Static) 세그멘테이션 영상(, 1020)으로 변환하는 과정을 상세히 설명하면 다음과 같다. 도 10을 참조하면, 객체 후처리 모듈은 객체 탐지 신경망과 인페인팅 신경망을 포함한다. 객체 탐지 신경망은 세그멘테이션 영상으로부터 동적 객체를 탐지하는 신경망으로, Convolution Layer, Fully Connected Layer들의 집합인 CNNs로 구성될 수 있다. 이러한 신경망 집합은 선택적인 탐색 없이 RPN(Region Proposal Network)을 통해서 RoI(Region of Interest)를 연산하며, 연산된 RoI를 풀링하여 동적 객 체를 탐지한다. 인페인팅 신경망은 세그멘테이션 영상에서 동적 객체가 위치하는 픽셀을 제거하고 제거된 픽셀을 이웃하는 정적 객체의 속성으로 채운다. 예를 들어, 인페인팅 신경망은 U-net으로 구성되며, 인페인팅 추정 결과와 정답을 비교하여 Generative Adversarial 손실 함수로 손실을 계산하고, Adam Optimization 알고리즘을 이용하여 학습 모델의 파라미터를 갱신하는 방법으로 학습한다. 인페인팅 신경망(15 4)은 객체 탐지 신경망으로부터 동적 객체의 중심점 좌표, 폭, 및 높이 정보를 수신하여 동적 객체가 포함 되는 경계 상자를 추정한다. 그리고 인페인팅 신경망은 추정된 경계 상자 내의 픽셀을 이웃하는 정적 객체 의 픽셀로 채우는 것으로 정적 세그멘테이션 영상을 생성한다. 다시 도 4를 참조하면, 객체 후처리 모듈에서 탐지된 동적 객체의 경계 상자는 현재 시점()에서의 영상 기 반 객체 경계 상자()로 출력되어 마스크 생성 모듈의 입력으로 전달된다. 마스크 생성 모듈은 영상 기반 객체 경계 상자()로부터 동적 객체를 제외한 영역을 마스크 처리한 마스크 영상()을 생성한다. 마스크 버퍼는 마스크 영상()들을 후술하는 근미래 객체 예측 신경망에 고속으로 전송하는 수단으로서, 현 재 시점()으로부터 소정의 과거 시점()까지의 마스크 영상 이력()을 생성하여 근미래 객체 예측 신 경망으로 전송한다. 다시 도 6을 참조하면, 객체 경계 상자 표본 추정 신경망은 정적 세그멘테이션 영상(, 630)을 입력받고, 정적 세그멘테이션 영상(, 630) 내에서 동적 객체의 위치를 추정한다. 객체 경계 상자 표본 추정 신경망(16 0)은 동적 객체가 위치할 것으로 추정되는 지점 각각에 객체 추정 경계 상자를 생성하고, 적어도 하나의 객체 추정 경계 상자가 포함된 객체 경계 상자 표본(, 640)을 출력한다. 여기서, 객체 경계 상자 표본 추정 신경망 이 정적 세그멘테이션 영상 - 즉, 동적 객체가 제거된 영상 - 으로부터 동적 객체의 위치를 추정함에 따라, 현재 시점 영상에서의 실제 동적 객체 위치와는 관계없이 정적 객체들이 형성하는 배경의 맥락에 따라 객체 추정 경계 상자가 생성될 수 있다. 객체 경계 상자 표본 추정 신경망은 객체 추정 경계 상자를 추정하고, 추정된 객체 추정 경계 상자를 정답 과 대비하여 손실률을 계산한다. 그리고 계산된 손실률을 최소화 하는 과정을 통해 모델 추정 파라미터를 업데 이트하여 객체 경계 상자 표본을 출력한다. 객체 추정 경계 상자는 동적 객체가 위치할 것으로 추정되는 지점의 중심점 좌표, 폭, 및 높이 정보로 규정되는 박스를 의미한다. 도 6의 예시에서 객체 경계 상자 표본 내에는 총 8개의 객체 추정 경계 상자가 샘플링되어 포함된 영상이 예시되었다. 도 6의 객체 경계 상자 표본은 발명의 이해를 돕기 위한 예시이며, 객체 경계 상자 표본은 실제로는 배경 영상 없이 8개의 객체 추정 경계 상자에 대한 정보를 나타내는 데이터 열로서 출력될 것이다. 일실시예로서, 객체 경계 상자 표본 추정 신경망은 정적 세그멘테이션 영상 내에서 정적 객체의 경계 지점에 가중치를 두어 객체 추정 경계 상자를 예측할 수 있다. 다른 실시예로서, 객체 경계 상자 표본 추정 신 경망은 정적 세그멘테이션 영상 내에서 정적 객체의 외곽선에 대한 법선의 각도 변화율이 급격한 지 점에 가중치를 두어 객체 추정 경계 상자를 예측할 수도 있다. 객체 경계 잔차(Residual) 추정 신경망은 객체 경계 상자 표본(, 640) 내의 객체 추정 경계 상자 각각에 대하여 현재 시점 영상에 포함된 실제 동적 객체의 위치를 반영한 객체 경계 잔차()를 연산하기 위한 수 단이다. 즉, 도 6에서와 같이 현재 시점()에서의 객체 경계 상자 표본()과 객체 경계 잔차()를 합산하는 것으로 현재 시점으로부터 근미래 시점의 객체 경계 상자 표본인 근미래 객체 경계 상자 표본(, 650)이 산출 될 수 있다. 객체 경계 잔차 추정 신경망은 현재 시점 영상(, 610)과 정적 세그멘테이션 영상(,630)을 입력받고, 신 호 전처리 모듈로부터 현재 시점의 입력 신호()를 수신한다. 그리고 동적 객체가 존재하지 않는 영상으 로부터 동적 객체의 위치를 추정하여 생성된 객체 경계 상자 표본에 대하여 객체 추정 경계 상자의 위치를 실제 동적 객체의 위치에 근접하게 보정하기 위한 객체 경계 잔차()를 연산한다. 도시한 바와 같이, 객체 경 계 상자 표본에 객체 경계 잔차()를 합산하여 근미래 객체 경계 상자 표본(, 650)이 연산된다. 도 6의 실시예에서, 객체 경계 상자 표본 내에 위치하는 총 8개의 객체 추정 경계 상자가 근미래 객체 경 계 상자 표본에서 일부 위치가 조정되어 8개의 근미래 객체 경계 상자로 출력되는 것을 확인할 수 있다. 객체 경계 잔차 추정 신경망은 근미래 객체 경계 상자 표본과 객체 경계 상자 표본을 대비하여 손실률을 계산한다. 그리고 계산된 손실률을 최소화하는 과정을 통해 모델 추정 파라미터를 업데이트하여 객체 경계 잔차()를 연산한다. 일실시예로서, 객체 경계 잔차 추정 신경망은 현재 시점 영상에서 인식된 동적 객체의 위치와 정적 세그멘테이션 영상 내에서의 정적 객체 경계 지점이 중복되는 위치에 가중치를 두어 객체 경계 잔차()를 연산할 수 있다. 다른 실시예로서, 객체 경계 잔차 추정 신경망은 현재 시점 영상의 특징맵과 정적 세그멘테이션 영상의 특징맵을 연결하고, 입력 신호()를 이용하여 특징맵 연결지점을 보정하는 것으로 객체 경계 잔차를 연산할 수도 있다. 도 6의 신경망 학습 결과로서 얻어진 근미래 객체 경계 상자 표본을 내비게이션 단말의 현재 시점 영상에 오버레이하여 출력하는 것만으로, 근미래 동적 객체의 출현 및 변동을 운전자가 쉽게 시인하도록 할 수 있다. 나아가, 도 6의 신경망 학습 결과로서 얻어진 근미래 객체 경계 상자 표본을 다른 신경망의 입력으로 사용 하여 자율 주행시 근미래에 닥칠 수 있는 다양한 사고들을 예측할 수도 있다. 여기서, 본 발명의 근미래 객체 위치 예측 시스템은 도 5의 근미래 객체 예측 신경망을 이용하여 현재 시점()에서 출현되지 아니한 객체의 미래 위치와 이미 출현된 객체의 미래 위치를 좀 더 명료하게 구분지어 학습하고 그 결과를 도출할 수 있다. 도 7은 도 4의 근미래 객체 예측 신경망을 통해 출현되지 아니한 객체 및 출현된 객체의 미래 위치를 예측하는 과정을 상세하게 묘사한 블록도이다. 도 7을 참조하여 본 발명에서 근미래 객체 경계 가설 상자 및 근미래 객체 경계 상자를 예측하는 신경망 학습을 구체적으로 설명하면 다음과 같다. 도 7을 참조하면, 근미래 객체 예측 신경망은 근미래 객체 경계 가설 상자 예측 신경망과 근미래 객 체 경계 상자 예측 신경망을 포함한다. 근미래 객체 경계 가설 상자 예측 신경망 및 근미래 객체 경계 상자 예측 신경망은 공히 도 6의 신경 망 학습 결과인 근미래 객체 경계 상자 표본을 하나의 입력으로 수신한다. 앞서 설명한 바와 같이, 근미래 객체 경계 상자 표본은 현재 시점 영상에서 동적 객체가 위치할 것으로 예측된 N개의 위치 후보를 나 타내는 N개의 근미래 객체 경계 상자를 의미한다. 근미래 객체 경계 가설 상자 예측 신경망의 다른 입력으로서 영상 버퍼에서 출력되는 영상 이력 (, 710)과, 세그멘테이션 버퍼에서 출력되는 세그멘테이션 영상 이력(, 720)과, 신호 버퍼 에서 출력되는 입력 신호 이력()이 이용된다. 영상 이력(, 710)과, 세그멘테이션 영상 이력 (, 720)과, 입력 신호 이력()은 모두 현재 시점 기준으로 과거까지의 소정의 시간동안의 데이터를 반영하여 근미래 객체 경계 상자 표본 내의 근미래 객체 경계 상자를 보정하기 위한 데이터들이다. 근미래 객체 경계 가설 상자 예측 신경망은 근미래 객체 경계 상자 표본을 기반으로 한 확률적 모델(GMM: Gaussian Mixture Model)을 생성하고, 이 확률적 모델의 평균을 중심점 좌표로, 표준편차를 폭 및 높이로 정하 여 최종 미래 객체 경계 가설 상자를 생성한다. 도 7을 참조하면, 최종 미래 객체 경계 가설 상자 표시 영상(, 740) 내에 4개의 최종 미래 객체 경계 가설 상자가 묘사되어 있다. 근미래 객체 경계 상자 표본과 대비하여 4개의 근미래 객체 경계 상자는 제거되었 고, 나머지 4개는 위치가 변동되거나 크기 변동(resize) 되었다. 물론, 최종 미래 객체 경계 가설 상자는 근미 래 객체 경계 상자와 동일한 위치 및 크기를 가질 수도 있다. 최종 미래 객체 경계 가설 상자는 배경의 맥락에 따라 현재 시점에서는 출현되지 아니한 동적 객체의 미래 위치를 추천한다. 근미래 객체 경계 가설 상자 예측 신경망은 차량의 내비게이션 단말을 통해 출력되는 현재 시점 영상(61 0)에 도 7에서 최종 도출된 4개의 최종 미래 객체 경계 가설 상자를 오버레이하여 표시할 수 있다. 또한, 근미 래 객체 경계 가설 상자 예측 신경망은 최종 미래 객체 경계 가설 상자에 주석을 첨부하거나 최종 미래 객 체 경계 가설 상자의 색상을 달리하는 것으로 객체의 종류를 표시할 수도 있다. 따라서 운전자가 오버레이로 표 시되는 최종 미래 객체 경계 가설 상자를 확인하고, 근미래에 출현할 동적 객체를 사전에 인지할 수 있도록 한 다. 근미래 객체 경계 가설 상자 신경망은 근미래 객체 경계 가설 상자 예측 신경망과 동일한 이력 데이 터(영상 이력(, 710)과, 세그멘테이션 영상 이력(, 720)과, 입력 신호 이력())를 입력받으며, 추가로 마스크 버퍼에서 출력되는 객체 마스크 영상 이력()을 더 입력받는다. 객체 마 스크 영상 이력()은 현재 시점 기준으로 과거까지의 소정의 시간동안의 객체의 위치들에 대한 정보를 이 용하여 출현된 동적 객체의 후보 위치를 보정하기 위한 데이터이다. 근미래 객체 경계 상자 예측 신경망은 근미래 객체 경계 상자 표본을 기반으로 한 확률적 모델(GMM: Gaussian Mixture Model)을 생성하고, 이 확률적 모델의 평균을 중심점 좌표로, 표준편차를 폭 및 높이로 정하여 최종 미래 객체 경계 상자를 생성한다. 도 7을 참조하면, 최종 미래 객체 경계 상자 표시 영상(, 750) 내에 4개의 최종 미래 객체 경계 상자가 묘 사되어 있다. 근미래 객체 경계 상자 표본과 대비하여 4개의 근미래 객체 경계 상자는 제거되었고, 나머지 4개는 위치가 변동되거나 크기 변동(resize) 되었다. 물론, 최종 미래 객체 경계 상자 역시 근미래 객체 경계 상자와 동일한 위치 및 크기를 가질 수도 있다. 최종 미래 객체 경계 상자는 현재 시점 영상에 이미 출현된 동 적 객체에 대한 미래의 위치를 추천한다. 근미래 객체 경계 상자 예측 신경망은 차량의 내비게이션 단말을 통해 출력되는 현재 시점 영상에 도 7에서 최종 도출된 4개의 최종 미래 객체 경계 상자를 오버레이하여 표시할 수 있다. 또한, 근미래 객체 경계 상자 예측 신경망은 최종 미래 객체 경계 상자에 주석을 첨부하거나 최종 미래 객체 경계 상자의 색상을 달리하는 것으로 객체의 종류를 표시할 수도 있다. 따라서 운전자가 오버레이로 표시되는 최종 미래 객체 경계 상자를 확인하고, 화면 상에 현재 표시되는 객체의 돌발적인 위치 변동을 사전에 인지할 수 있도록 한다. 도 11 내지 15는 본 발명에 따라 근미래 객체 위치를 예측한 결과가 내비게이션 단말에 표시되는 예를 보인 도 면들로서, 도 11 내지 13은 전방 차량에 대한 근미래 위치를 예측하는 화면을 예시하고 있고 도 14 및 15는 전 방 보행자에 대한 근미래 위치를 예측하고 있다.도 11의 (a)는 차량 전방의 현재 시점 영상()를 예시한 것으로서, 전방의 선행 차량이 주행차로 안을 달리고 있다. 도 11의 (b)는 근미래 객체 경계 상자 예측 신경망이 선행 차량 주변으로 복수의 최종 미래 객체 경 계 상자를 생성하여 현재 시점 영상()에 오버레이하여 표시한 화면을 예시하고 있다. 선행 차량의 근미래 위치 가 선행 차량의 좌측과 우측에 근접하여 집중적으로 표시되고 있다. 도 12의 (a)는 도 11의 (a)에서 소정 시간 경과된 후의 현재 시점 영상(도 12의 시점에서 현재 시점 영상)을 나 타내고 있으며, 선행 차량이 우측 차로에 걸친 상태임을 확인할 수 있다. 종래 객체를 추적하는 방식의 학습 시 스템에서는 전방 차량이 우측으로 차선을 변경하는 것으로 예측할 것이지만, 도 12의 (b)를 참조하면, 본 발명 에서는 전방 차량이 우측으로 진행할 것을 예측하는 최종 미래 객체 경계 상자와 더불어 원래의 주행차로로 복 귀하거나 좌측으로 방향을 크게 전환하는 돌발 상황을 나타내는 최종 미래 객체 경계 상자가 함께 표시되고 있 다. 도 13의 (a)는 도 12의 (a)에서 시간이 좀 더 경과된 후의 영상을 나타내고 있는데, 전방 차량이 우측 차로로 진로를 변경한 상태를 예시하고 있다. 본 발명의 근미래 객체 위치 예측 시스템은, 전방 차량이 갓길을 따라 주 행할 것으로 예측하는 최종 미래 객체 경계 상자와 함께 원래 차로로 복귀할 확률을 나타내는 최종 미래 객체 경계 상자, 전방 차량이 현 위치에 정차하는 것을 나타내는 최종 미래 객체 경계 상자가 표시되고 있다. 도 14의 (a)는 좌측의 보행자가 횡단보도 단부에 서있는 상태를 나타내고 있다. 도 14의 (b)에서와 같이, 근미 래 객체 경계 상자 예측 신경망은 전방 차량이 존재하는 상태에서 보행자가 근미래에 횡단보도 단부의 근 방 주변에서 머무르는 상황을 지배적으로 예측하지만, 횡단보도를 빠른 속도로 건너서 전방 차량 앞까지 보행자 가 이동하는 상황(도 14의 (b)에서 화면 중앙에 표시되는 최종 미래 객체 경계 상자에서와 같이)도 예측할 수 있다. 도 14의 (b)와 같은 근미래 객체 위치 예측이 이루어진다면, 전방 차량의 급정거를 예측하여 자차의 속도 를 급감속하는 제어를 수행할 수 있을 것이다. 도 15의 (a)는 도 14에서 시간이 진행되어 보행자가 전방 차량의 바로 앞에 위치하는 현재 시점 영상을 나타내 고 있다. 도 15의 (b)에서와 같이 보행자가 횡단보도를 완전히 건넌 근미래 상황 또는 보행자가 전방 차량을 피 해 횡단보도에서 방향을 바꾸어 대각선 방향으로 진행하는 근미래 상황이 예측되어 표시될 수 있다. 위에서 개시된 발명은 기본적인 사상을 훼손하지 않는 범위 내에서 다양한 변형예가 가능하다. 즉, 위의 실시예 들은 모두 예시적으로 해석되어야 하며, 한정적으로 해석되지 않는다. 따라서 본 발명의 보호범위는 상술한 실 시예가 아니라 첨부된 청구항에 따라 정해져야 하며, 첨부된 청구항에 한정된 구성요소를 균등물로 치환한 경우 이는 본 발명의 보호범위에 속하는 것으로 보아야 한다."}
{"patent_id": "10-2020-0185615", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래 이동 객체의 위치를 동역학적으로 예측하는 방법을 예시한 도면, 도 2는 횡단보도의 주변에서 이동 객체의 위치를 예측하는 예를 보인 도면, 도 3은 카메라로부터 촬영된 영상이 이미지 데이터로 변환되는 과정을 예시한 도면, 도 4는 본 발명에 따른 근미래 객체 위치 예측 시스템을 예시한 블록도, 도 5는 도 4에서 근미래 객체 예측 신경망의 구조를 예시한 블록도, 도 6은 본 발명에서 근미래 객체 경계 상자 표본을 학습하는 과정을 상세하게 묘사한 블록도, 도 7은 도 5의 근미래 객체 예측 신경망을 통해 출현되지 아니한 객체 및 출현된 객체의 미래 위치를 예측하는 과정을 상세하게 묘사한 블록도, 도 8은 본 발명에서 세그멘테이션 신경망의 구조를 예시한 블록도, 도 9는 본 발명에서 세그멘테이션 영상의 실시예들을 보인 도면, 도 10은 본 발명에서 객체 후처리 모듈을 상세하게 묘사한 블록도, 및 도 11 내지 15는 본 발명에 따라 근미래 객체 위치를 예측한 결과가 내비게이션 단말에 표시되는 예를 보인 도 면들이다."}
