{"patent_id": "10-2022-0160465", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0077984", "출원번호": "10-2022-0160465", "발명의 명칭": "설명 가능한 차원 축소 방법 및 장치", "출원인": "주식회사 케이티", "발명자": "권명은"}}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "유사도에 기반하여, 복수의 시계열 데이터를 복수의 군집으로 클러스터링하는 단계;상기 복수의 군집을 각각 대표하는 복수의 대표 변수를 결정하는 단계;군집 내에서 대표 변수와 유사도가 높은 하나 이상의 시계열 데이터를 추출하여 설명 데이터셋을 구성함으로써,상기 복수의 대표 변수에 각각 대응하는 복수의 설명 데이터셋을 생성하는 단계;인공지능 모델에 XAI 기법을 적용하여, 상기 복수의 대표 변수 중 중요도가 높은 복수의 주요 대표 변수를 결정하는 단계;상기 복수의 설명 데이터셋 중, 상기 복수의 주요 대표 변수에 각각 대응하는 복수의 주요 설명 데이터셋을 추출하는 단계;상기 복수의 주요 설명 데이터셋 내 설명 변수들을 조합하여, 복수의 검증 데이터셋을 생성하는 단계; 및복수의 대표 변수를 포함하는 입력 데이터셋이 입력되었을 때의 상기 인공지능 모델의 출력 결과와 상기 복수의검증 데이터셋이 입력되었을 때의 상기 인공지능 모델의 출력 결과들을 비교하여, 상기 복수의 검증 데이터셋중 설명용 검증 데이터셋을 선정하는 단계;를 포함하는설명 가능한 차원 축소 방법."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 복수의 검증 데이터셋을 생성하는 단계는,주요 설명 데이터셋 별로 최소 하나 이상의 설명 변수가 포함되도록 검증 데이터셋을 생성하는 단계;를 포함하는설명 가능한 차원 축소 방법."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,주요 설명 데이터셋 별로 최소 하나 이상의 설명 변수가 포함되도록 검증 데이터셋을 생성하는 단계는,상기 복수의 설명 데이터셋 각각으로부터 동일한 개수의 설명 변수를 추출하여 검증 데이터셋을 생성하는 단계;를 포함하는설명 가능한 차원 축소 방법."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2항에 있어서,상기 복수의 주요 설명 데이터셋 내 모든 설명 변수는, 상기 복수의 검증 데이터셋에서 최소 1회 이상 포함되는설명 가능한 차원 축소 방법."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 복수의 대표 변수를 포함하는 입력 데이터셋은,공개특허 10-2024-0077984-3-상기 복수의 대표 변수와 함께, 군집에 속하지 않은 일반 변수를 포함하고,상기 복수의 검증 데이터셋 각각은,상기 복수의 주요 설명 데이터셋에서 추출된 설명 변수와 함께 상기 일반 변수를 포함하는설명 가능한 차원 축소 방법."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서,상기 복수의 검증 데이터셋 각각은,상기 복수의 주요 설명 데이터셋에서 추출된 설명 변수, 주요 대표 변수로 선정되지 않은 대표 변수 및 상기 일반 변수를 포함하는설명 가능한 차원 축소 방법."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5항에 있어서,상기 복수의 군집을 각각 대표하는 복수의 대표 변수를 결정하는 단계는,특정 군집에 대응하는 대표 변수와 상기 특정 군집 내 시계열 데이터들 간의 상관관계가 일정 수준보다 낮으면,상기 특정 군집 내 시계열 데이터들을 상기 일반 변수로 분류하는 단계;를 포함하는설명 가능한 차원 축소 방법."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항에 있어서,상기 복수의 검증 데이터셋 중 설명용 검증 데이터셋을 선정하는 단계는,상기 입력 데이터셋이 입력되었을 때의 예측 모델의 기준 예측값과 상기 복수의 검증 데이터셋이 입력되었을 때의 상기 예측 모델의 검증 예측값들을 비교하여, 상기 기준 예측값과 가장 유사한 검증 예측값을 출력하게 한검증 데이터셋을 선정하는 단계;를 포함하는설명 가능한 차원 축소 방법."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1항에 있어서,상기 복수의 검증 데이터셋 중 설명용 검증 데이터셋을 선정하는 단계는,‘상기 입력 데이터셋이 입력되었을 때 XAI 모델이 출력한 주요 대표 변수의 기준 중요도 정보’와 ‘상기 복수의 검증 데이터셋이 입력되었을 때 상기 XAI 모델이 출력한 설명 변수들의 검증 중요도 정보들’을 비교하여,상기 XAI 모델이 상기 기준 중요도 정보와 가장 유사한 검증 중요도 정보를 출력하게 한 검증 데이터셋을 선정하는 단계;를 포함하는설명 가능한 차원 축소 방법."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공지능 모델을 저장하는 메모리; 및유사도에 기반하여, 복수의 시계열 데이터를 복수의 군집으로 클러스터링하고, 상기 복수의 군집을 각각 대표하는 복수의 대표 변수를 결정하고, 군집 내에서 대표 변수와 유사도가 높은 하나 이상의 시계열 데이터를 추출하여 설명 데이터셋을 구성함으로써, 상기 복수의 대표 변수에 각각 대응하는 복수의 설명 데이터셋을 생성하고,상기 인공지능 모델에 XAI 기법을 적용하여, 상기 복수의 대표 변수 중 중요도가 높은 복수의 주요 대표 변수를결정하고, 상기 복수의 설명 데이터셋 중, 상기 복수의 주요 대표 변수에 각각 대응하는 복수의 주요 설명 데이공개특허 10-2024-0077984-4-터셋을 추출하고, 상기 복수의 주요 설명 데이터셋 내 설명 변수들을 조합하여, 복수의 검증 데이터셋을 생성하고, 복수의 대표 변수를 포함하는 입력 데이터셋이 입력되었을 때의 상기 인공지능 모델의 출력 결과와 상기 복수의 검증 데이터셋이 입력되었을 때의 상기 인공지능 모델의 출력 결과들을 비교하여, 상기 복수의 검증 데이터셋 중 설명용 검증 데이터셋을 선정하는 제어부;를 포함하는설명 가능한 차원 축소 장치."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서,상기 제어부는,주요 설명 데이터셋 별로 최소 하나 이상의 설명 변수가 포함되도록 검증 데이터셋을 생성하는설명 가능한 차원 축소 장치."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 제어부는,상기 복수의 설명 데이터셋 각각으로부터 동일한 개수의 설명 변수를 추출하여 검증 데이터셋을 생성하는설명 가능한 차원 축소 장치."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11항에 있어서,상기 복수의 주요 설명 데이터셋 내 모든 설명 변수는, 상기 복수의 검증 데이터셋에서 최소 1회 이상 포함되는설명 가능한 차원 축소 장치."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10항에 있어서,상기 복수의 대표 변수를 포함하는 입력 데이터셋은,상기 복수의 대표 변수와 함께, 군집에 속하지 않은 일반 변수를 포함하고,상기 복수의 검증 데이터셋 각각은,상기 복수의 주요 설명 데이터셋에서 추출된 설명 변수와 함께 상기 일반 변수를 포함하는설명 가능한 차원 축소 장치."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14항에 있어서,상기 복수의 검증 데이터셋 각각은,상기 복수의 주요 설명 데이터셋에서 추출된 설명 변수, 주요 대표 변수로 선정되지 않은 대표 변수 및 상기 일반 변수를 포함하는설명 가능한 차원 축소 장치."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14항에 있어서,상기 제어부는,특정 군집에 대응하는 대표 변수와 상기 특정 군집 내 시계열 데이터들 간의 상관관계가 일정 수준보다 낮으면,공개특허 10-2024-0077984-5-상기 특정 군집 내 시계열 데이터들을 상기 일반 변수로 분류하는설명 가능한 차원 축소 장치."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 10항에 있어서,상기 제어부는,상기 입력 데이터셋이 입력되었을 때의 예측 모델의 기준 예측값과 상기 복수의 검증 데이터셋이 입력되었을 때의 상기 예측 모델의 검증 예측값들을 비교하여, 상기 기준 예측값과 가장 유사한 검증 예측값을 출력하게 한검증 데이터셋을 선정하는 설명 가능한 차원 축소 장치."}
{"patent_id": "10-2022-0160465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 10항에 있어서,상기 제어부는,‘상기 입력 데이터셋이 입력되었을 때 XAI 모델이 출력한 주요 대표 변수의 기준 중요도 정보’와 ‘상기 복수의 검증 데이터셋이 입력되었을 때 상기 XAI 모델이 출력한 설명 변수들의 검증 중요도 정보들’을 비교하여,상기 XAI 모델이 상기 기준 중요도 정보와 가장 유사한 검증 중요도 정보를 출력하게 한 검증 데이터셋을 선정하는설명 가능한 차원 축소 장치."}
{"patent_id": "10-2022-0160465", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "설명 가능한 차원 축소 방법이 개시된다. 본 발명에 따른 설명 가능한 차원 축소 방법은, 유사도에 기반하여, 복 수의 시계열 데이터를 복수의 군집으로 클러스터링하는 단계, 상기 복수의 군집을 각각 대표하는 복수의 대표 변 수를 결정하는 단계, 군집 내에서 대표 변수와 유사도가 높은 하나 이상의 시계열 데이터를 추출하여 설명 데이 (뒷면에 계속)"}
{"patent_id": "10-2022-0160465", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 대표 변수에 대응하는 설명 변수를 선정하고, 대표 변수를 입력했을 때의 인공지능 모델의 출력 결 과와 설명 변수를 입력했을 때의 인공지능 모델의 출력 결과를 비교하는 방식으로, 차원 축소에도 불구하고 인 공지능 모델의 판단 결과에 대한 설명을 제공할 수 있는, 설명 가능한 차원 축소 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0160465", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(artificial intelligence)은 인간의 지능으로 할 수 있는 사고, 학습, 자기계발 등을 컴퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보기술의 한 분야로, 컴퓨터가 인간의 지능적인 행동을 모방할 수 있도록 하는 것을 의미한다. 머신 러닝 또는 기타 학습 방식으로 학습된 인공지능 모델은, 입력 데이터에 대한 판단 결과를 제공하지만, 판 단 결과에 대한 근거나 입출력 데이터의 인과관계를 설명하기 힘들다는 단점이 있다. 그럼에도 불구하고, 인공 지능 기술을 사용하는 개인 또는 단체가 증가하면서, 인공지능 모델이 의사 결정을 내린 근거나 방식을 파악하 여 인공지능 모델에 대한 신뢰를 확인하고자 하는 니즈가 증가하고 있다. 설명 가능한 인공지능(eXplainable Artificial Intelligence, XAI)은, 마치 블랙박스와 같은 인공지능 모델의 한계를 극복하기 위한 기술로, 인공지능 모델의 의사 결정이나 판단 결과에 대한 해석 능력을 제공하기 위한 기 술이다. 설명 가능한 인공지능의 대표적 기법으로는 특성 중요도(feature importance), 부분 의존성 플롯 (partial dependence plots), 대리 분석(surrogate analysis), LIME(Local Interpretable Model-agnostic Explanation), SHAP(SHapley Additive exPlanations) 등이 있다. 한편 다변량 데이터란 결과에 영향을 미치는 변수가 다수 존재하는 데이터를 의미하며, 다변량 데이터가 인공지 능 모델에 입력되는 경우 이와 같은 다수의 변수가 인공지능 모델의 출력 결과에 영향을 미치게 된다. 일 예로, 금융 데이터 중 나스닥 지수를 예측한다고 가정하면, 세계 각국의 기준 금리, 채권 금리, 주가지수, 경상수지, 물가 지수, 실업률, 각종 원자재 가격, 금 가격, 코인, 환율, 기업의 펀더멘털을 반영하는 각종 지표들 등, 수 십만 가지의 변수가 나스닥 지수에 영향을 미칠 수 있다. 이러한 다변량 데이터를 이용하여 인공지능 모델이 예측을 하게 하는 경우, 이른 바 '차원의 저주'가 발생할 수 있다. 차원의 저주란 데이터의 차원이 커질수록 분석을 위한 알고리즘 실행이 매우 복잡해지고 어려워지는 것을 의미한다. '차원의 저주'와 같은 문제를 해결하기 위하여, 데이터 차원 축소 기법이 등장하였다. 즉 모든 변수가 특정 값 (예를 들어, 나스닥 지수)의 예측에 필수적인 것은 아니므로, 데이터 차원 축소 기법은, 예측에 필요한 유의미 한 변수를 선택하거나(특징 선택(feature selection)), 상관관계가 높은 변수들을 합성하거나 변형하여 새로운 저차원의 변수를 생성한다(특징 추출(feature extraction)). 한편 앞서 설명한 설명 가능한 인공지능(eXplainable Artificial Intelligence, XAI)은, 변수가 인공지능 모델 의 판단 결과에 어느 정도의 영향을 미쳤는지를 나타내는 중요도(또는 기여도)를 산출한다. 그러나 설명 가능한 인공지능(eXplainable Artificial Intelligence, XAI)이 데이터 차원 축소 기법과 결합하는 경우에는, 본래의 변수에 대한 변형이 일어나는 데이터 차원 축소 기법의 특성으로 인하여, 본래의 변수가 인공지능 모델의 판단 결과에 미치는 영향에 대한 설명이 불가능하다는 문제가 있었다."}
{"patent_id": "10-2022-0160465", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위한 것으로, 본 발명의 목적은, 대표 변수에 대응하는 설명 변수를 선정 하고, 대표 변수를 입력했을 때의 인공지능 모델의 출력 결과와 설명 변수를 입력했을 때의 인공지능 모델의 출 력 결과를 비교하는 방식으로, 차원 축소에도 불구하고 인공지능 모델의 판단 결과에 대한 설명을 제공할 수 있 는, 설명 가능한 차원 축소 방법 및 장치를 제공하기 위함이다."}
{"patent_id": "10-2022-0160465", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 설명 가능한 차원 축소 방법은, 유사도에 기반하여, 복수의 시계열 데이터를 복수의 군집으로 클러스터링하는 단계, 상기 복수의 군집을 각각 대표하는 복수의 대표 변수를 결정하는 단계, 군집 내에서 대표 변수와 유사도가 높은 하나 이상의 시계열 데이터를 추출하여 설명 데이터셋을 구성함으로써, 상기 복수의 대표 변수에 각각 대응하는 복수의 설명 데이터셋을 생성하는 단계, 인공지능 모델에 XAI 기법을 적용하여, 상기 복 수의 대표 변수 중 중요도가 높은 복수의 주요 대표 변수를 결정하는 단계, 상기 복수의 설명 데이터셋 중, 상 기 복수의 주요 대표 변수에 각각 대응하는 복수의 주요 설명 데이터셋을 추출하는 단계, 상기 복수의 주요 설 명 데이터셋 내 설명 변수들을 조합하여, 복수의 검증 데이터셋을 생성하는 단계, 및, 복수의 대표 변수를 포함 하는 입력 데이터셋이 입력되었을 때의 상기 인공지능 모델의 출력 결과와 상기 복수의 검증 데이터셋이 입력되 었을 때의 상기 인공지능 모델의 출력 결과들을 비교하여, 상기 복수의 검증 데이터셋 중 설명용 검증 데이터셋 을 선정하는 단계를 포함한다. 이 경우 상기 복수의 검증 데이터셋을 생성하는 단계는, 주요 설명 데이터셋 별로 최소 하나 이상의 설명 변수 가 포함되도록 검증 데이터셋을 생성하는 단계를 포함할 수 있다. 이 경우 주요 설명 데이터셋 별로 최소 하나 이상의 설명 변수가 포함되도록 검증 데이터셋을 생성하는 단계는, 상기 복수의 설명 데이터셋 각각으로부터 동일한 개수의 설명 변수를 추출하여 검증 데이터셋을 생성하는 단계 를 포함할 수 있다. 한편 상기 복수의 주요 설명 데이터셋 내 모든 설명 변수는, 상기 복수의 검증 데이터셋에서 최소 1회 이상 포 함될 수 있다. 한편 상기 복수의 대표 변수를 포함하는 입력 데이터셋은, 상기 복수의 대표 변수와 함께, 군집에 속하지 않은 일반 변수를 포함하고, 상기 복수의 검증 데이터셋 각각은, 상기 복수의 주요 설명 데이터셋에서 추출된 설명 변수와 함께 상기 일반 변수를 포함할 수 있다. 이 경우 상기 복수의 검증 데이터셋 각각은, 상기 복수의 주요 설명 데이터셋에서 추출된 설명 변수, 주요 대표 변수로 선정되지 않은 대표 변수 및 상기 일반 변수를 포함할 수 있다. 한편 상기 복수의 군집을 각각 대표하는 복수의 대표 변수를 결정하는 단계는, 특정 군집에 대응하는 대표 변수 와 상기 특정 군집 내 시계열 데이터들 간의 상관관계가 일정 수준보다 낮으면, 상기 특정 군집 내 시계열 데이 터들을 상기 일반 변수로 분류하는 단계를 포함할 수 있다. 한편 상기 복수의 검증 데이터셋 중 설명용 검증 데이터셋을 선정하는 단계는, 상기 입력 데이터셋이 입력되었 을 때의 예측 모델의 기준 예측값과 상기 복수의 검증 데이터셋이 입력되었을 때의 상기 예측 모델의 검증 예측 값들을 비교하여, 상기 기준 예측값과 가장 유사한 검증 예측값을 출력하게 한 검증 데이터셋을 선정하는 단계 를 포함할 수 있다. 한편 상기 복수의 검증 데이터셋 중 설명용 검증 데이터셋을 선정하는 단계는, '상기 입력 데이터셋이 입력되었 을 때 XAI 모델이 출력한 주요 대표 변수의 기준 중요도 정보'와 '상기 복수의 검증 데이터셋이 입력되었을 때 상기 XAI 모델이 출력한 설명 변수들의 검증 중요도 정보들'을 비교하여, 상기 XAI 모델이 상기 기준 중요도 정 보와 가장 유사한 검증 중요도 정보를 출력하게 한 검증 데이터셋을 선정하는 단계를 포함할 수 있다. 한편 본 발명에 따른 설명 가능한 차원 축소 장치는, 인공지능 모델을 저장하는 메모리, 및, 유사도에 기반하여, 복수의 시계열 데이터를 복수의 군집으로 클러스터링하고, 상기 복수의 군집을 각각 대표하는 복수의 대표 변수를 결정하고, 군집 내에서 대표 변수와 유사도가 높은 하나 이상의 시계열 데이터를 추출하여 설명 데 이터셋을 구성함으로써, 상기 복수의 대표 변수에 각각 대응하는 복수의 설명 데이터셋을 생성하고, 상기 인공 지능 모델에 XAI 기법을 적용하여, 상기 복수의 대표 변수 중 중요도가 높은 복수의 주요 대표 변수를 결정하고, 상기 복수의 설명 데이터셋 중, 상기 복수의 주요 대표 변수에 각각 대응하는 복수의 주요 설명 데이 터셋을 추출하고, 상기 복수의 주요 설명 데이터셋 내 설명 변수들을 조합하여, 복수의 검증 데이터셋을 생성하 고, 복수의 대표 변수를 포함하는 입력 데이터셋이 입력되었을 때의 상기 인공지능 모델의 출력 결과와 상기 복 수의 검증 데이터셋이 입력되었을 때의 상기 인공지능 모델의 출력 결과들을 비교하여, 상기 복수의 검증 데이 터셋 중 설명용 검증 데이터셋을 선정하는 제어부를 포함한다. 이 경우 상기 제어부는, 주요 설명 데이터셋 별로 최소 하나 이상의 설명 변수가 포함되도록 검증 데이터셋을 생성할 수 있다. 이 경우 상기 제어부는, 상기 복수의 설명 데이터셋 각각으로부터 동일한 개수의 설명 변수를 추출하여 검증 데 이터셋을 생성할 수 있다. 한편 상기 복수의 주요 설명 데이터셋 내 모든 설명 변수는, 상기 복수의 검증 데이터셋에서 최소 1회 이상 포 함될 수 있다. 한편 상기 복수의 대표 변수를 포함하는 입력 데이터셋은, 상기 복수의 대표 변수와 함께, 군집에 속하지 않은 일반 변수를 포함하고, 상기 복수의 검증 데이터셋 각각은, 상기 복수의 주요 설명 데이터셋에서 추출된 설명 변수와 함께 상기 일반 변수를 포함할 수 있다. 이 경우 상기 복수의 검증 데이터셋 각각은, 상기 복수의 주요 설명 데이터셋에서 추출된 설명 변수, 주요 대표 변수로 선정되지 않은 대표 변수 및 상기 일반 변수를 포함할 수 있다. 한편 상기 제어부는, 특정 군집에 대응하는 대표 변수와 상기 특정 군집 내 시계열 데이터들 간의 상관관계가 일정 수준보다 낮으면, 상기 특정 군집 내 시계열 데이터들을 상기 일반 변수로 분류할 수 있다. 한편 상기 제어부는, 상기 입력 데이터셋이 입력되었을 때의 예측 모델의 기준 예측값과 상기 복수의 검증 데이 터셋이 입력되었을 때의 상기 예측 모델의 검증 예측값들을 비교하여, 상기 기준 예측값과 가장 유사한 검증 예 측값을 출력하게 한 검증 데이터셋을 선정할 수 있다. 한편 상기 제어부는, '상기 입력 데이터셋이 입력되었을 때 XAI 모델이 출력한 주요 대표 변수의 기준 중요도 정보'와 '상기 복수의 검증 데이터셋이 입력되었을 때 상기 XAI 모델이 출력한 설명 변수들의 검증 중요도 정보 들'을 비교하여, 상기 XAI 모델이 상기 기준 중요도 정보와 가장 유사한 검증 중요도 정보를 출력하게 한 검증 데이터셋을 선정할 수 있다."}
{"patent_id": "10-2022-0160465", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 수십만건 이상의 다변량 데이터에 대한 효과적이고 빠른 차원 축소 방법을 제공할 수 있으며, 데이터의 변형이 불가피한 차원 축소를 수행하면서도 인공지능 모델의 판단 결과에 대한 설명을 제공함 으로써, 인공지능 모델의 예측에 대한 신뢰도를 높힐 수 있는 장점이 있다."}
{"patent_id": "10-2022-0160465", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘어져서 구현될 수도 있다. 아래에서는, 시계열 데이터가 금융 데이터(예를 들어, 기준 금리, 채권 금리, 주가지수, 경상수지, 물가 지수, 실업률, 각종 원자재 가격, 금 가격, 코인, 환율, 기업의 주가 등)인 것으로 가정하여 설명한다. 금융 데이터의 경우, 수십만개의 시계열 데이터가 예측 값(미래의 상승/보합/하락, 미래의 수치 (미래의 주가, 가격, 지수 등))에 영향을 미칠 수 있는데 반해, 전체적인 시계열의 길이가 상대적으로 짧고 주기적(일별, 월별, 분기별, 반기별, 월별 등)으로 수집되는 특성상 '차원의 저주'가 잘 나타난다. 다만 본 발명은 금융 데이터에 한정되지 않으며, 데이터 차원 축소 기법과 XAI 기법이 함께 적용되는 다양한 유형의 데이터에 적용될 수 있다. 도 1은 본 발명에 따른, 설명 가능한 차원 축소 장치의 구성요소를 설명하기 위한 블록도이다. 본 발명에 따른 설명 가능한 차원 축소 장치(이하 \"장치\"라 함)는, 데이터 획득부, 제어부, 메 모리 및 출력부를 포함할 수 있다. 장치는 도 1에서 도시된 구성 요소의 일부 또는 전부를 포함할 수 있다. 데이터 획득부는 복수의 시계열 데이터를 수집할 수 있다. 이를 위해 데이터 획득부는 유/무선 통신 기술을 이용하여 외부 장치와 통신하기 위한 통신 회로 또는 통신 모듈을 포함하고, 외부 장치로부터 복수의 시 계열 데이터를 수신할 수 있다. 또한 데이터 획득부는 데이터 입력부를 포함하고, 장치의 운용자로부 터 복수의 시계열 데이터를 수신할 수 있다. 제어부는 장치의 전반적인 동작을 제어할 수 있다. 용어 “제어부”는, “마이크로 프로세서”, “컨 트롤러”, “마이크로 컨트롤러”, “프로세서” 등의 용어와 혼용되어 사용될 수 있다. 또한 제어부는 메모리로부터 인공지능 모델을 독출하여 실행할 수 있다. 이에 따라, 아래에서 설명하는 인공지능 모델의 동작은, 제어부의 동작인 것으로 볼 수도 있다. 메모리는 장치의 구동을 위한 프로그램, 명령어 및 기타 데이터를 저장할 수 있다. 또한 메모리는 인공지능 모델을 저장할 수 있다. 구체적으로 인공지능 모델은 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있으며, 인공지능 모델을 구성하는 하나 이상의 명령어는 메 모리에 저장될 수 있다. 인공지능 모델는 예측 모델 및 XAI 모델를 포함할 수 있다. 예측 모델은 복수의 시계열 데 이터를 포함하는 입력 데이터셋에 기반하여 예측값을 출력하도록 트레이닝된 모델일 수 있다. 입력 데이터셋이 시계열 데이터로 구성되는 특성 상, LSTM, GRU, RNN 등의 인공 신경망이 사용될 수 있으나 이에 한정되지는 않 으며, Auto encoder 등 공지된 다양한 인경 신경망이나 기타 구조가 사용될 수 있다. 또한 예측 모델은, 지도 학습, 비지도 학습, 강화 학습, 준지도 학습 등 공지된 다양한 학습 알고리즘에 의해 트레이닝 될 수 있다. 또한 공지된 다양한 AI 기법 및 최적화 기법이 예측 모델에 적용될 수 있다. 한편 제어부는 인공지능 모델에 XAI 기법을 적용하여 대표 변수의 중요도 정보를 산출할 수 있으며, 이 경우 XAI 모델이 사용될 수 있다. 제어부는 특성 중요도(feature importance), 부분 의존성 플 롯(partial dependence plots), 대리 분석(surrogate analysis), LIME(Local Interpretable Model- agnostic Explanation), SHAP(SHapley Additive exPlanations) 등, 다양한 공지된 XIA 기법을 사용하여 대표 변수의 중요도 정보를 산출할 수 있다. 출력부는, 제어부의 제어 하에, 장치에 저장되거나 장치에서 처리하는 정보를 사용자에게 제공할 수 있다. 이를 위해 출력부는 정보를 디스플레이 하는 디스플레이 모듈 또는 정보를 사용자 단말에 전송하는 통신 모듈을 포함할 수 있다. 도 2는 본 발명에 따른, 설명 가능한 차원 축소 방법을 설명하기 위한 순서도이다. 본 발명에 따른 설명 가능한 차원 축소 방법은, 유사도에 기반하여, 복수의 시계열 데이터를 복수의 군집으로 클러스터링하는 단계(S210), 상기 복수의 군집을 각각 대표하는 복수의 대표 변수를 결정하는 단계(S220), 군집 내에서 대표 변수와 유사도가 높은 하나 이상의 시계열 데이터를 추출하여 설명 데이터셋을 구성함으로써, 상기 복수의 대표 변수에 각각 대응하는 복수의 설명 데이터셋을 생성하는 단계(S230), 인공지능 모델에 XAI 기법을 적용하여, 상기 복수의 대표 변수 중 중요도가 높은 복수의 주요 대표 변수를 결정하는 단계(S240), 상기 복수 의 설명 데이터셋 중, 상기 복수의 주요 대표 변수에 각각 대응하는 복수의 주요 설명 데이터셋을 추출하는 단 계(S250), 상기 복수의 주요 설명 데이터셋 내 설명 변수들을 조합하여, 복수의 검증 데이터셋을 생성하는 단계 (S260), 및, 복수의 대표 변수를 포함하는 입력 데이터셋이 입력되었을 때의 상기 인공지능 모델의 출력 결과와 상기 복수의 검증 데이터셋이 입력되었을 때의 상기 인공지능 모델의 출력 결과들을 비교하여, 상기 복수의 검 증 데이터셋 중 설명용 검증 데이터셋을 선정하는 단계(S270)를 포함할 수 있다. 먼저 S210을 설명하기 전, 시계열 데이터에 대한 전처리 과정을 간단하게 설명한다. 복수의 시계열 데이터 간에는 길이, 수집 주기 등에 차이가 있을 수 있다. 따라서, 제어부는 복수의 시계 열 데이터에 대한 전처리를 수행하여, 복수의 시계열 데이터를 클러스터링에 적합하도록 정규화할 수 있다. 예 를 들어 제어부는 복수의 시계열 데이터의 길이를 특정 값으로 통일하거나, 복수의 시계열 데이터의 주기 를 몇 개의 주기값(예를 들어, 일/월/분기/반기/연 등) 중 하나로 변경하고, 시계열 데이터의 유사도 판단에 적 합하도록 데이터를 수정할 수 있다. 제어부는 공지된 다양한 스무딩(Smoothing) 기법 및 데이터 보간 기법 을 이용하여 복수의 시계열 데이터를 전처리 할 수 있다.다음으로, 제어부는 유사도에 기반하여, 복수의 시계열 데이터를 복수의 군집으로 클러스터링할 수 있다 (S210). 구체적으로 제어부는 복수의 시계열 데이터 간의 유사도에 기초하여, 유사도가 높은 시계열 데이터들이 하 나의 군집에 속하도록, 복수의 시계열 데이터를 복수의 군집으로 클러스터링할 수 있다. 클러스터링에는 k- means 클러스터링 기법이 사용될 수 있으나 이에 한정되지 않으며, 다양한 클러스터링 기법이 사용될 수 있다. 이 경우 제어부는 DTW(Dynamic Time Wrapping) 기법을 이용하여 복수의 시계열 데이터 간의 유사도를 결정 할 수 있다. DTW(Dynamic Time Wrapping) 기법은, 시계열 데이터의 각 지점과, 시계열 데이터의 각 지점과 가장 유사한 위상을 가지는 다른 시계열 데이터 상의 지점을 매칭하여 비교하는 방식이다. 따라서 DTW(Dynamic Time Wrapping) 기법은, 길이가 상이하거나, 주기가 상이하거나, 중간에 누락된 값이 존재하거나, 선행 지표 및 후행 지표(예를 들어 후행 지표인 코스닥 지수는, 선행 지표는 나스닥 지수를 따라가는 경향성을 나타내기도 함)가 존재하기도 하는 금융 데이터에 적용되기 적합하다. DTW(Dynamic Time Wrapping) 기법은 공지된 기법으로 자세 한 설명은 생략하며, DTW(Dynamic Time Wrapping) 기법 외에도 시계열 데이터들 간의 유사도를 판단하는 다양한 기법이 사용될 수 있다. 한편 제어부는 복수의 시계열 데이터를 그대로 사용하여 클러스터링을 수행할 수 있으나 이에 한정되지 않 으며, 복수의 시계열 데이터를 푸리에 변환을 통해 주파수 성분을 가지는 데이터로 변환한 후 클러스터링을 수 행할 수도 있다. 아래에서는, 복수의 시계열 데이터를 복수의 군집으로 클러스터링하는 하나의 실시예를 설명한다. 도 3은 본 발명의 일 실시예에 따른, 복수의 시계열 데이터를 복수의 군집으로 클러스터링하는 방법을 설명하기 위한 순서도이다. 도 4는 1차 클러스터링 및 2차 클러스터링을 거친 후 생성된 1차 군집 들 및 2차 군집을 도시한 도면이다. 도 3은 시계열 데이터의 수가 매우 많을 때 클러스터링을 적절히 수행하기 위한 기법으로, 도 3의 실시예 외에 도 다양한 기법들이 사용될 수 있다. 제어부는 복수의 시계열 데이터에 대한 1차 클러스터링을 수행하여, 1차 군집들을 생성할 수 있다. 구체적 으로 제어부는, 복수의 시계열 데이터 상호 간의 유사도에 관계 없이, 복수의 시계열 데이터를 주기별로 분류하여 복수의 군집을 생성할 수 있다. 예를 들어 제1 군집(예를 들어, 도 4의 410)에는 수집 주기가 연 단위 인 시계열 데이터(예를 들어, 연간 경제 성장률 등), 제2 군집(예를 들어 도 4의 420)에는 수집 주기가 분기 단 위인 시계열 데이터(예를 들어, 기업 실적 등), 제3 군집에는 수집 주기가 월 단위인 시계열 데이터(예를 들어, 소비자 물가 지수 등)가 속할 수 있다. 다음으로, 제어부는 1차 군집들에 대하여 2차 클러스터링을 수행하여 2차 군집들을 생성할 수 있다(S312). 구체적으로 제어부는 유사도에 기반하여 1차 군집 내 복수의 시계열 데이터를 클러스터링 함으로써, 1차 군집 내 복수의 시계열 데이터를 복수의 2차 군집으로 클러스터링 할 수 있다. 예를 들어 제1-1 군집(예를 들어, 도 4의 411)에는 수집 주기가 연 단위인 시계열 데이터들 중 상호 간에 유사도가 높은 시계열 데이터들이 속하고, 제1-2 군집(예를 들어, 도 4의 412)에는 수집 주기가 연 단위인 시계열 데이터들 중 상호 간에 유사도 가 높은 시계열 데이터들이 속할 수 있다. 다음으로 제어부는, 2차 군집 별로, 시계열 데이터들의 상관관계값을 산출할 수 있다(S312). 구체적으로 제어부는 특정 2차 군집 내 모든 시계열 데이터 상호 간의 상관관계 값들을 산출하고, 이들의 평균 값을 해당 2차 군집에 대응하는 상관관계값으로써 산출할 수 있다. 또한 제어부는 동일한 동작을 모든 2차 군집 에 대하여 수행할 수 있다. 상관관계값의 산출을 위해, 시계열 데이터 간의 상관 관계를 분석하여 상관관계값을 산출할 수 있는 공지된 다양한 함수들이 사용될 수 있다. 다음으로 제어부는 복수의 2차 군집에 각각 대응하는 복수의 상관관계값이 임계값보다 큰지 판단할 수 있 다(S314). 그리고 제어부는 상관관계값이 임계값보다 큰 2차 군집을 최종 군집으로 분류할 수 있다(S315). 도 3에서 분류된 최종 군집은, S210에서 설명한 “군집”으로 사용될 수 있다. 반면에, 제어부는 상관관계값이 임계값보다 작은 2차 군집을 최종 군집으로 분류하지 않을 수 있다. 그리 고 모든 2차 군집에 대한 S314의 판단이 완료되면, 제어부는 최종 군집 내 시계열 데이터들을 제외한 다른 시계열 데이터들을 대상으로 다시 S311 내지 S315의 동작을 반복할 수 있다.한편 S311 내지 S315의 동작을 계속 반복하더라도, 시계열 데이터가 속한 군집에 대응하는 상관관계값이 임계값 보다 계속 작은 관계로, 최종 군집에 속하지 못하는 시계열 데이터가 생길 수 있다. 제어부는 이와 같은 시계열 데이터를 일반 변수로 설정할 수 있다. 즉 일반 변수는 S210에서 설명한 “복수의 군집” 중 어느 군집 에도 속하지 않는 시계열 데이터를 의미할 수 있다. 다시 도 2로 돌아가서, 제어부는 복수의 군집을 각각 대표하는 복수의 대표 변수를 결정할 수 있다(S220). 이와 관련해서는 도 5를 참고하여 설명한다. 도 5는 본 발명에 따른, 대표 변수를 결정하는 방법을 설명하기 위한 도면이다. 대표 변수란 해당 군집에 속하는 시계열 데이터들의 특성을 가장 잘 나타낼 수 있는(즉, 대표할 수 있는) 시계 열 데이터를 의미한다. 대표 변수는 해당 군집에 속하는 시계열 데이터들 대표할 수 있는 가상의 값일 수 있으 나 이에 한정되지 않으며, 해당 군집에 속하는 시계열 데이터들 중 어느 하나의 시계열 데이터가 대표 변수로 선정될 수도 있다. 또한 아래에서는 DBA(DTW Barycenter Averaging) 기법에 기반하여 대표 변수가 획득되는 것으로 설명하나 이에 한정되지 않으며, average sequence를 이용하여 산술평균(arithmetic mean) 값을 산출하는 방식 등, 다양한 시계열 데이터 형태 추출 기법이 사용될 수 있다. 제어부는 DBA(DTW Barycenter Averaging) 기법을 이용하여 군집에 대응하는 대표 변수를 획득할 수 있다. DBA(DTW Barycenter Averaging) 기법은, 거리 측정 방법으로 DTW를 사용하여 시계열 데이터들의 중심 (centroid)을 결정하는 방식이다. 그리고 제어부는 DBA(DTW Barycenter Averaging) 기법을 이용하여 군집 내 시계열 데이터들과의 거리들을 최소화 시키는 대표 변수를 산출할 수 있다. DBA(DTW Barycenter Averaging) 기법을 사용하는 경우, 시계열 데이터들간의 위상차에도 불구하고 군집 내 시계열 데이터들의 형태를 가장 잘 반영하는 형식으로 대표 변수가 산출되기 때문에, 대표 변수는 군집 내 시계열 데이터들의 형태를 대표할 수 있 게 된다. 도 5를 참고하면, 군집 A 내지 군집 L이 도시되어 있으며, 군집 내 복수의 시계열 데이터들은 검은색 그래프로, 군집 내 대표 변수는 붉은색 그래프로 도시되어 있다. 한편 제어부는 대표 변수가 해당 군집을 대표할 수 있는지 여부를 판단할 수 있다. 구체적으로 제어부는 특정 군집에 대응하는 대표 변수와 특정 군집 내 시계열 데이터들 간의 상관관계 값 들을 산출할 수 있다. 예를 들어 제어부는 특정 군집의 대표 변수와 특정 군집 내 제1 시계열 데이터를 비 교하여 제1 상관관계값을 산출하고, 특정 군집의 대표 변수와 특정 군집 내 제2 시계열 데이터를 비교하여 제2 상관 관계값을 산출할 수 있으며, 이러한 동작을 특정 군집 내 모든 시계열 데이터에 대하여 수행할 수 있다. 또한 제어부는 특정 군집 내 모든 시계열 데이터에 대하여 산출된 상관 관계값들을 평균하여, 평균 상관 관계값을 산출할 수 있다, 그리고 나서, 특정 군집에 대응하는 대표 변수와 특정 군집 내 시계열 데이터들 간의 상관관계가 일정 수준보 다 낮으면, 제어부는 특정 군집 내 시계열 데이터들을 일반 변수로 분류할 수 있다. 일 예로, 앞서 산출된 평균 상관 관계값이 임계값보다 낮으면, 제어부는 대표 변수가 특정 군집을 대표하지 못하는 것으로 결정 하고 특정 군집을 제거할 수 있다. 한편 제어부는 제거되는 군집에 속하던 시계열 데이터를 일반 변수로 설정할 수 있다. 앞서 설명한 바와 같이, 일반 변수는 복수의 군집 중 어느 군집에도 속하지 않는 시계열 데이 터를 의미할 수 있다. 다시 도 2로 돌아가서, 제어부는 군집 내에서 대표 변수와 유사도가 높은 하나 이상의 시계열 데이터를 추 출하여 설명 데이터셋을 구성함으로써, 복수의 대표 변수에 각각 대응하는 복수의 설명 데이터셋을 생성할 수 있다(S230). 이와 관련해서는 도 6을 참고하여 설명하한다. 도 6은 본 발명에 따른, 설명 데이터 셋을 생성하는 방법을 설명하기 위한 도면이다. 제어부는 군집 내에서 대표 변수와 유사도가 높은 하나 이상의 시계열 데이터를 추출할 수 있다. 구체적으 로 제어부는 군집의 대표 변수와 군집 내 시계열 데이터들 간의 유사도를 산출할 수 있으며, 이 경우 앞서 설명한 DTW(Dynamic Time Wrapping) 기법이 사용될 수 있으나 이에 한정되지 않는다. 예를 들어 DTW(Dynamic Time Wrapping) 기법에 기반하여 산출된 유사도가 동일한 경우, 제어부는 유클리드 놈(norm) 계산 결과를 추가적으로 이용하여 시계열 데이터들의 유사도 순위를 산출할 수 있다. 또한 제어부는 군집의 대표 변수와 유사도가 가장 높은 특정 개수의 시계열 데이터들을 추출할 수 있다. 여기서 추출된 시계열 데이터는, 대표 변수를 설명하기 위한 것으로, 설명 변수라 명칭될 수 있다. 예를 들어 도 6에서 도시한 바와 같이, 제어부는 군집 A의 대표 변수(a0)와 군집 A 내 시계열 데이터들 간 의 유사도를 산출하고, 유사도가 가장 높은 다섯개의 시계열 데이터들(a1, a2, a3, a4, a5)을 추출할 수 있으며, 이 다섯개의 시계열 데이터는 설명 변수로 설정될 수 있다. 또한 제어부는 하나 이상의 설명 변수를 포함하는 설명 데이터 셋(도 6의 설명 데이터셋 A)를 구성할 수 있다. 한편 제어부는 앞서 생성된 복수의 군집에 대하여 동일한 동작을 수행할 수 있다. 따라서 복수의 대표 변 수에 각각 대응하는 복수의 설명 데이터셋이 생성될 수 있다. 다시 도 2로 돌아아서, 제어부는 인공지능 모델에 XAI 기법을 적용하여, 복수의 대표 변수 중 중요도가 높 은 복수의 주요 대표 변수를 결정할 수 있다(S240). 구체적으로 제어부는 복수의 대표 변수를 포함하는 입력 데이터셋을 구성할 수 있다. 입력 데이터셋을 구 성하는 방법에 대해서는 도 8에서 구체적으로 설명하도록 한다. 또한 제어부는, 복수의 대표 변수를 포함하는 입력 데이터셋이 인공지능 모델(더욱 구체적으로는, 예측 모 델)에 입력되었을 때의, 복수의 대표 변수에 각각 대응하는 복수의 중요도 정보를 획득할 수 있다. 이 경 우 제어부는 공지된 다양한 XAI 기법 중 하나 이상을 적용하여 중요도 정보를 획득할 수 있으며, 이 경우 XAI 모델이 사용될 수도 있다. 여기서 중요도 정보란, 변수가 인공지능 모델의 판단 결과에 어느 정도의 영향을 미쳤는지를 나타내는 것으로, 기여도 정보로 명칭될 수도 있다. 또한 중요도 정보는 중요도를 수치화한 값일 수 있으나 이에 한정되지 않으며, 복수의 대표 변수들의 중요도 순위를 포함할 수도 있다. 그리고 나서, 제어부는 복수의 대표 변수에 각각 대응하는 복수의 중요도 정보를 이용하여, 복수의 대표 변수 중 중요도가 가장 높은 일정 개수의 대표 변수를 추출할 수 있다. 이와 같이 추출된 대표 변수를 \"주요 대 표 변수\"라 명칭할 수 있다. 다시 도 2로 돌아가서, 제어부는 복수의 설명 데이터 셋 중 복수의 주요 대표 변수에 각각 대응하는 복수 의 주요 설명 데이터셋을 추출할 수 있다. 이와 관련해서는 도 7을 참고하여 설명한다. 도 7은 본 발명에 따른, 복수의 주요 대표 변수에 각각 대응하는 복수의 주요 설명 데이터셋을 추출하는 방법을 설명하기 위한 도면이다. 설명의 편의 상, 도 7에서는 중요도가 가장 높은 두 개의 대표 변수를 추출하는 것으로 가정하여 설명한다. 도 7의 좌측 상단의 그래프를 참고하면, 입력 데이터셋을 구성하는 복수의 대표 변수의 중요도 순위가 도 시되어 있다. 예를 들어 군집 A의 제1 대표 변수(a0)는 첫번째로 중요한 대표 변수이며, 군집 B의 제2 대표 변 수(b0)는 두번째로 중요한 대표 변수이다. 이 경우 제어부는 제1 대표 변수(a0) 및 제2 대표 변수(b0)를 주요 대표 변수로 설정하고, 복수의 주요 대 표 변수에 각각 대응하는 복수의 설명 데이터셋을 추출할 수 있다. 예를 들어 제어부는 제1 대표 변수(a 0)에 대응하는 제1 설명 데이터셋(도 7의 설명 데이터셋 A)을 추출하고, 제2 대표 변수(b0)에 대응하는 제2 설 명 데이터셋(도 7의 설명 데이터셋 B)를 추출할 수 있다. 여기서 추출되는 설명 데이터 셋을 “주요 설명 데이 터 셋”이라 명칭할 수 있다. 이 경우, 제1 주요 설명 데이터셋(도 7의 설명 데이터셋 A)은 군집 A 내에서 제1 대표 변수(a0)와 가장 유사한 복수의 시계열 데이터(a1, a2, a3, a4, a5)를 포함하고, 제2 주요 설명 데이터셋(도 7의 설명 데이터셋 B)은 군 집 B 내에서 제2 대표 변수(b0)와 가장 유사한 복수의 시계열 데이터(b1, b2, b3, b4, b5)를 포함할 수 있다. 다시 도 2로 돌아가서, 제어부는 복수의 주요 설명 데이터셋 내 설명 변수들을 조합하여, 복수의 검증 데 이터셋을 생성할 수 있다(S260). 또한 제어부는 복수의 대표 변수를 포함하는 입력 데이터셋이 입력되었을 때의 인공지능 모델의 출력 결과와 복수의 검증 데이터셋이 입력되었을 때의 인공지능 모델의 출력 결과들을 비 교하여, 복수의 검증 데이터셋 중 설명용 검증 데이터셋을 선정할 수 있다(S260). 이와 관련해서는 도 8 및 도 9를 참고하여 설명한다. 도 8은 예측 모델에 대한 입력 데이터셋 및 검증 데이터셋을 구성하고, 입력 데이터셋과 검증 데이터셋의 비교 를 통해 설명용 검증 데이터셋을 선정하는 방법을 설명하기 위한 도면이다. 도 8a에서는 입력 데이터셋이 도시되어 있다. 도 8a에서 도시된 바와 같이, 제어부는 복수의 대표 변수를 포함하는 입력 데이터셋을 구성할 수 있다. 구체적으로 입력 데이터셋은, 복수의 대표 변수와 함께 군집에 속하지 않은 일반 변수를 포함할 수 있다. 앞서 설명한 바와 같이, 일반 변수는 복수의 군집 중 어느 군집에도 속하지 않는 시계열 데이터를 의미할 수 있다. 군집에 속하는 시계열 데이터들은 차원이 축소된 데이터(대표 변수)의 형태로 예측 모델에 입력되는 반면, 일반 변수는 군집에 속하지 않는다. 따라서 제어부는 복수의 대표 변수와 함께 일반 변수를 입력 데이터셋 에 포함시킬 수 있다. 한편 제어부는 복수의 대표변수를 포함하는 입력 데이터셋을 예측 모델에 입력할 수 있다. 예측 모델 은, 미리 트레이닝 및 최적화된 인공지능 모델로써, 자신의 파라미터(가중치, 편향 등)에 기반하여 입력 데이터셋에 대응하는 예측값을 출력할 수 있다. 예측 모델이 입력 데이터 셋에 기반하여 출력한 예측값을 기준 예측값이라 명칭한다. 다음으로, 제어부는 복수의 주요 설명 데이터 셋 내 설명 변수들을 조합하여, 복수의 검증 데이터셋을 생 성할 수 있다. 설명의 편의 상, 세개의 주요 대표 변수(a0, b0, c0) 및 세개의 주요 설명 데이터셋이 존재하는 것으로 가정하 여 설명한다. 또한 주요 설명 데이터셋은 각각 세개의 설명 변수를 포함하는 것으로 가정하여 설명한다. 예를 들어, 군집 A의 주요 대표 변수(a0)에 대응하는 제1 주요 설명 데이터셋은 세개의 설명 변수(a1, a2, a3) 를 포함하고, 군집 B의 주요 대표 변수(b0)에 대응하는 제2 주요 설명 데이터셋은 세개의 설명 변수(b1, b2, b3)를 포함하고, 군집 C의 주요 대표 변수(c0)에 대응하는 제3 주요 설명 데이터셋은 세개의 설명 변수(c1, c2, c3)를 포함할 수 있다. 제어부는 주요 설명 데이터셋 별로 최소 하나 이상의 설명 변수가 포함되도록 검증 데이터 셋을 구성할 수 있다. 예를 들어 도 8b를 참고하면, 제1 검증 데이터셋은 제1 주요 설명 데이터셋 내 설명 변수(a1)와 제2 주요 설명 데이터 셋 내 설명 변수(b2)와 제3 주요 설명 데이터 셋 내 설명 변수(c3)를 모두 포함한다. 즉 본 발명에서는, 입력 데이터셋에 기반하여 예측모델이 출력하는 기준 예측값과 검증 데이터셋들에 기반하여 예측모델이 출력하는 검증 예측값들을 비교하여. 기준 예측값과 유사한 검증 예측값을 출력하게 하는 검증 데이 터셋을 찾는다. 이러한 비교 방식을 고려할 때, 입력 데이터셋에는 대표 변수 a0가 포함되었으나 제1 검증 데이 터셋에는 대표 변수를 대체하는 설명 변수(a1)가 포함되지 않게 되면, 왜곡이 발생하게 된다. 따라서 제어부 는 주요 설명 데이터셋 별로 최소 하나 이상의 설명 변수가 포함되도록 검증 데이터 셋을 구성할 수 있다. 한편 제어부는 복수의 설명 데이터셋 각각으로부터 동일한 개수의 설명 변수를 추출하여 검증 데이터셋을 생성할 수 있다. 예를 들어 도 8b를 참고하면, 제1 검증 데이터셋은 제1 주요 설명 데이터셋 내 설명 변수 한개 (a1)와 제2 주요 설명 데이터 셋 내 설명 변수 한개(b2)와 제3 주요 설명 데이터 셋 내 설명 변수 한개(c3)를 포함한다. 예측 모델은 각 군집 별로 하나의 시계열 데이터(대표 변수)만을 추출하여 기준 예측값을 출력하였다. 따 라서, 검증 과정에서 각 클러스터 별로 서로 다른 개수의 설명 변수를 추출하여 검증 데이터셋을 생성하는 경우, 왜곡이 발생하게 된다. 따라서 제어부는 복수의 설명 데이터셋 각각으로부터 동일한 개수의 설명 변 수를 추출하여 검증 데이터셋을 생성할 수 있다. 한편 제어부는 복수의 설명 데이터셋 각각으로부터 설명 변수를 하나씩 추출하고, 하나씩 추출된 설명 변 수로 만들어질수 있는 모든 조합을 검증 데이터셋으로써 생성할 수 있다. 예를 들어 제1 주요 설명 데이터셋은 세개의 설명 변수(a1, a2, a3)를, 제2 주요 설명 데이터셋은 세개의 설명 변수(b1, b2, b3)를, 제3 주요 설명 데이터셋은 세개의 설명 변수(c1, c2, c3)를 포함한다. 이 경우 제어부는 3^3인 9개의 조합을 생성하고, 9개의 조합을 각각 포함하는 9개의 검증 데이터셋을 생성할 수 있다. 도 8c에는, 도 8b에서 생성된 제1 검증 데이터셋 과 다른 조합을 가지는 제2 검증 데이터셋이 도시되어 있다. 필요에 따라, 제어부는 하나씩 추출된 설명 변수로 만들어질수 있는 모든 조합을 검증 데이터셋으로 생성 하는 것 없이, 일부 조합만을 검증 데이터셋으로써 생성할 수 있다. 다만 이와 같은 경우에도, 제어부는 복수의 주요 설명 데이터셋 내 모든 설명 변수를 최소 1회 이상 포함시켜 복수의 검증 데이터셋을구성함으로써, 주요 설명 데이터셋 내 모든 설명 변수가 최소 1회 이상은 검증의 대상이 되도록 할 수 있다. 한편 앞서 설명한 바와 같이, 도 8a의 입력 데이터셋은 대표 변수 뿐만 아니라 일반 변수를 포함한다. 그리고 입력 데이터셋에는 일반 변수가 포함되었으나 검증 데이터셋에는 일반 변수가 포함되지 않게 되면, 왜곡이 발생 하게 된다. 따라서 제어부는 복수의 주요 설명 데이터셋에서 추출된 설명 변수와 함께 일반 변수를 포함시 켜 복수의 검증 데이터셋 각각을 구성할 수 있다. 한편 도 8a의 입력 데이터셋은 A 내지 Z 군집의 대표 변수들(대표 변수 a0 내지 z0)를 포함한다. 그리고 입력 데이터셋에는 A 내지 Z 군집의 대표 변수들이 포함되었으나 검증 데이터 셋에는 일부 군집의 시계열 데이터가 포함되지 않게 되면 왜곡이 발생하게 된다. 따라서 제어부는, 복수의 주요 설명 데이터셋에서 추출된 설명 변수, 주요 대표변수로 선정되지 않은 대표 변수 및 일반 변수를 포함시켜 복수의 검증 데이터셋 각각을 구성할 수 있다. 예를 들어 도 8a 및 8b를 비교하면, A 내지 C 군집의 대표 변수들(대표 변수 a0 내지 c0)는 설명 변수들(a1 내 지 a0)로 대체되었다. 다만 나머지 대표 변수들(대표 변수 d0 내지 z0)은 대체되지 않고 제1 검증 데이터셋을 그대로 구성하는 것을 알 수 있다. 다음으로, 제어부는 입력 데이터셋이 입력되었을 때의 예측 모델의 기준 예측값과 복수의 검증 데이터셋이 입력되었을 때의 예측 모델의 검증 예측값들을 비교하여, 기준 예측값과 가장 유사한 검증 예측값을 출력하게 한 검증 데이터셋을 선정할 수 있다. 구체적으로, 제어부는 복수의 검증 데이터셋을 예측모델에 개별적으로 입력하고, 입력된 검증 데이터 셋에 기반하여 예측 모델이 출력한 검증 예측값을 획득할 수 있다. 예를 들어 제어부는, 도 8b에서 도시된 바와 같이 복수의 검증 데이터셋 중 제1 검증 데이터셋을 예측 모델에 입력하여 제1 검증 예측값을 획득하고, 도 8c에서 도시된 바와 같이 복수의 검증 데이터셋 중 제2 검증 데이터셋을 예측 모델에 입력하 여 제2 검증 예측값을 획득할 수 있다. 또한 제어부는 예측 모델이 출력한 복수의 검증 예측값 중 기준 예측값과 가장 유사한 특정 검증 예 측값을 선정할 수 있다. 또한 제어부는 특정 검증 예측값이 출력되었을 때 예측 모델에 입력된 검증 데이터셋을 선정할 수 있다. 여기서 선정된 검증 데이터셋은 설명용 검증 데이터셋이라 명칭될 수 있다. 한편 제어부는 설명용 검증 데이터셋을 사용자에게 제공할 수 있다. 구체적으로 제어부는 기준 예측 값을 사용자에게 출력하고, 기준 예측값과 함께 설명용 검증 데이터셋 내 하나 이상의 설명변수를 사용자에게 출력할 수 있다. 설명용 검증 데이터셋이 도 8b의 제1 검증데이터셋이라 가정하면, 제어부는 기준 예측값과 함께 설명 변수 a1, 설명변수 b2, 설명변수 c3을 사용자에게 제공할 수 있다. 설명변수 a1은 예측 모델이 기준 예측값을 예측하는데 가장 큰 영향을 미친 대표 변수(a0)를 대체한 것으로, 제어부는 대표 변수(a0) 대신 기준 예측값을 예측하는데 가장 큰 영향을 미친 설명변수 a1를 사용자에게 제공할 수 있다. 예를 들어 대표 변수(a0)는 설명이 불가능한 가상의 값인데 반해, 설명변수 a1은 미국 10년 만 기 국채 금리일 수 있다. 설명변수 b2는 예측 모델이 기준 예측값을 예측하는데 두번째로 큰 영향을 미친 대표 변수(b0)를 대체한 것으로, 제어부는 대표 변수(a0) 대신 기준 예측값을 예측하는데 두번째로 큰 영향을 미친 설명변수 b2를 사용자에게 제공할 수 있다. 한편 앞서 설명한 기준 예측값 및 검증 예측값은 수치(예를 들어 미래의 주가, 가격, 지수 등)일 수 있으나 이 에 한정되지 않는다. 예를 들어 예측 모델이 입력 데이터셋을 복수의 클래스 중 어느 하나의 클래스로 분 류하는 분류 모델인 경우, 기준 예측값 및 검증 예측값은 예측 모델이 출력한 클래스(또는 해당 클래스의 확률)일 수 있다. 한편 설명용 검증 데이터셋을 선정하는 또 하나의 방법에 대하여 도 9를 참고하여 설명한다. 도 9은 입력 데이터셋과 검증 데이터셋의 비교를 통해 설명용 검증 데이터셋을 선정하는 또 하나의 방법을 설명 하기 위한 도면이다. 제어부는 '입력 데이터셋이 입력되었을 때 XAI 모델이 출력한 주요 대표 변수의 기준 중요도 정보'와 '복 수의 검증 데이터셋이 입력되었을 때 XAI 모델이 출력한 설명 변수들의 검증 중요도 정보들'을 비교하여, XAI모델이 기준 중요도 정보와 가장 유사한 검증 중요도 정보를 출력하게 한 검증 데이터셋을 선정할 수 있다. 구체적으로 제어부는 복수의 대표변수를 포함하는 입력 데이터셋을 인공지능 모델에 제공할 수 있다. 이 경우 XAI 모델은 예측 모델에 대하여 XAI 기법을 적용하여 대표 변수의 중요도 정보를 산출할 수 있 다. 앞서 설명한 바와 같이, 중요도 정보는 대표 변수 별 중요도를 수치화한 값 또는 대표 변수들의 중요도 순 위를 포함할 수 있다. XAI 모델이 입력 데이터셋에 기반하여 출력한 중요도 정보를 기준 중요도 정보라 명 칭한다. 다음으로, 제어부는 복수의 검증 데이터셋을 인공지능 모델에 개별적으로 입력하고, 입력된 검증 데이터 셋에 기반하여 XAI 모델이 출력한 검증 중요도 정보를 획득할 수 있다. 예를 들어 제어부는, 도 9b에 서 도시된 바와 같이 복수의 검증 데이터셋 중 제1 검증 데이터셋을 인공지능 모델에 입력하여 XAI 모델이 출력한 제1 검증 중요도 정보를 획득하고, 도 9c에서 도시된 바와 같이 복수의 검증 데이터셋 중 제2 검증 데이 터셋을 인공지능 모델에 입력하여 XAI 모델이 출력한 제2 검증 중요도 정보를 획득할 수 있다. 이 경우 제어부는 XAI 모델이 출력한 복수의 검중 중요도 정보 중 기준 중요도 정보와 가장 유사한 특정 검증 중요도 정보를 선정할 수 있다. 예를 들어 제어부는 기준 중요도 정보 내 주요 대표 변수의 중요도 순위와, 검증 중요도 정보 내에서 상기 주요 대표 변수에 상응하는 설명 변수의 중요도 순위를 비교할 수 있다. 예를 들어 제어부는, 기준 중요도 정보 내 제1 군집의 주요 대표 변수(a0)의 중요도 순위가 1위이고, 검증 중요도 정보 내 제1 군집의 설명 변수 (a1)의 중요도 순위가 1위인 경우, 제1 군집에 대하여 유사한 것으로 판단할 수 있다. 그리고 제어부는 주 요 대표 변수들의 중요도 정보와 이에 상응하는 설명 변수들의 중요도 정보를 비교하는 방식으로, 검증 중요도 정보가 기중 중요도 정보와 유사한 정도를 결정할 수 있다. 추가적으로, 제어부는 도 8에서 설명한 제1 비교 방식(기준 예측값 검증 예측값을 비교)와 도 9에서 설명 한 제2 비교 방식(기준 중요도 정보와 검증 중요도 정보)을 모두 수행하고, 제1 비교 방식에 의해 산출된 결과 와 제2 비교 방식이 의해 산출된 결과를 모두 고려하여, 인공지능 모델이 입력 데이터셋이 입력되었을 때의 인 공지능 모델의 출력 결과와 가장 유사한 출력 결과를 출력하게 한, 검증 데이터 셋을 선정할 수 있다. 도 8에서 설명한 제1 비교 방식은 주요 대표 변수(예를 들어, a0)를 임의의 설명 변수(예를 들어, a1)으로 대체 한 것이 예측값을 출력한 예측 모델의 입장에서 타당한 것인가를 검증하기 위한 것이다. 또한 도 9에서 설명한 제2 비교 방식은 주요 대표 변수(예를 들어, a0)를 임의의 설명 변수(예를 들어, a1)으로 대체한 것이 변수의 중요도를 산출한 XAI 모델의 입장에서도 타당한 것인가를 검증하기 위한 것이다. 그리고 두 개의 비교 방식을 조합하게 되면, 더욱 정확한 설명용 검증 데이터셋을 선정하여 더욱 정확한 설명 변수를 제공할 수 있는 장점이 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니 되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하 고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2022-0160465", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른, 설명 가능한 차원 축소 장치의 구성요소를 설명하기 위한 블록도이다. 도 2는 본 발명에 따른, 설명 가능한 차원 축소 방법을 설명하기 위한 순서도이다. 도 3은 본 발명의 일 실시예에 따른, 복수의 시계열 데이터를 복수의 군집으로 클러스터링하는 방법을 설명하기 위한 순서도이다. 도 4는 1차 클러스터링 및 2차 클러스터링을 거친 후 생성된 1차 군집 들 및 2차 군집을 도시한 도면이다. 도 5는 본 발명에 따른, 대표 변수를 결정하는 방법을 설명하기 위한 도면이다. 도 6은 본 발명에 따른, 설명 데이터 셋을 생성하는 방법을 설명하기 위한 도면이다. 도 7은 본 발명에 따른, 복수의 주요 대표 변수에 각각 대응하는 복수의 주요 설명 데이터셋을 추출하는 방법을 설명하기 위한 도면이다. 도 8은 예측 모델에 대한 입력 데이터셋 및 검증 데이터셋을 구성하고, 입력 데이터셋과 검증 데이터셋의 비교 를 통해 설명용 검증 데이터셋을 선정하는 방법을 설명하기 위한 도면이다. 도 9은 입력 데이터셋과 검증 데이터셋의 비교를 통해 설명용 검증 데이터셋을 선정하는 또 하나의 방법을 설명 하기 위한 도면이다."}
