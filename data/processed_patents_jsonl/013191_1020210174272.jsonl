{"patent_id": "10-2021-0174272", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0086026", "출원번호": "10-2021-0174272", "발명의 명칭": "인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템 및 방법", "출원인": "계명대학교 산학협력단", "발명자": "이종하"}}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템(100)으로서,감정상태 예측을 위한 대상자의 바이오 신호를 측정하기 위한 바이오 신호 측정부(110);감정상태 예측을 위한 대상자의 얼굴표정 이미지를 측정하기 위한 이미지 측정부(120); 및상기 바이오 신호 측정부(110)로부터 측정된 바이오 신호와, 상기 이미지 측정부(120)로부터 측정된 얼굴표정이미지를 분석하여 각각의 감정을 분류하고, 분류된 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결합하여최종 감정을 예측하는 감정 예측부(130)를 포함하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는EfficientNet 아키텍처 기반 모바일 비전 시스템."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 바이오 신호 측정부(110)는,감정상태 예측을 위한 바이오 신호로서, 대상자의 심장 박동 변이도를 의미하는 심전도를 비접촉 방식으로 측정하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 바이오 신호 측정부(110)는,감정상태 예측을 위한 바이오 신호로서, 심전도 이외에도 산소포화도, 초당 혈류량, 및 혈압을 비접촉 방식으로더 측정하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전시스템."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 감정 예측부(130)는,바이오 신호와 얼굴표정 이미지의 분석을 위한 딥러닝 알고리즘으로 콘볼루션 뉴럴 네트워크(convolutionNeural Network, CNN) 기반의 EfficientNet-B0 모델을 사용하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 감정 예측부(130)는,콘볼루션 뉴럴 네트워크(convolution Neural Network, CNN) 기반의 EfficientNet-B0 모델을 사용하되, 깊이(depth)와 너비(width)와 해상도(image resolution)를 함께 조절하는 컴파운드 스케일링 방식(compoundscaling method)이 사용되는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0086026-3-제4항에 있어서, 상기 감정 예측부(130)는,감정상태 예측을 위한 얼굴표정 이미지, 감정 클래스에 따라 추출된 바이오 신호 데이터를 저장하는 데이터베이스(DB)를 포함하여 구성하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 감정 예측부(130)는,감정상태 예측을 위한 얼굴표정 이미지와 감정 클래스에 따라 추출된 바이오 신호 데이터를 학습하여 데이터베이스(DB)에 저장하되, 데이터베이스에 저장 관리되는 감정 클래스는 행복, 중립, 슬픔, 분노, 놀라움, 혐오 및공포를 포함하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일비전 시스템."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 감정 예측부(130)는,상기 바이오 신호 측정부(110)로부터 측정된 바이오 신호와, 상기 이미지 측정부(120)로부터 측정된 얼굴표정이미지를 데이터베이스에 저장된 학습 데이터와 비교 검색한 후, 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결합하여 높은 정확도의 최종 감정 예측이 가능하도록 하는 것을 특징으로 하는, 인간의 복합감정을 예측할수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 방법으로서,(1) 바이오 신호 측정부(110)가 감정상태 예측을 위한 대상자의 바이오 신호를 측정하는 단계;(2) 이미지 측정부(120)가 감정상태 예측을 위한 대상자의 얼굴표정 이미지를 측정하는 단계; 및(3) 감정 예측부(130)가 상기 바이오 신호 측정부(110)로부터 측정된 바이오 신호와, 상기 이미지 측정부(120)로부터 측정된 얼굴표정 이미지를 분석하여 각각의 감정을 분류하고, 분류된 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결합하여 최종 감정을 예측하는 단계를 포함하는 것을 특징으로 하는, 인간의 복합감정을 예측할수 있는 EfficientNet 아키텍처 기반 모바일 비전 방법."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 바이오 신호 측정부(110)는,감정상태 예측을 위한 바이오 신호로서, 대상자의 심장 박동 변이도를 의미하는 심전도를 비접촉 방식으로 측정하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 방법."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 바이오 신호 측정부(110)는,감정상태 예측을 위한 바이오 신호로서, 심전도 이외에도 산소포화도, 초당 혈류량, 및 혈압을 비접촉 방식으로더 측정하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전방법.공개특허 10-2023-0086026-4-청구항 12 제9항에 있어서, 상기 감정 예측부(130)는,바이오 신호와 얼굴표정 이미지의 분석을 위한 딥러닝 알고리즘으로 콘볼루션 뉴럴 네트워크(convolutionNeural Network, CNN) 기반의 EfficientNet-B0 모델을 사용하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 방법."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 감정 예측부(130)는,콘볼루션 뉴럴 네트워크(convolution Neural Network, CNN) 기반의 EfficientNet-B0 모델을 사용하되, 깊이(depth)와 너비(width)와 해상도(image resolution)를 함께 조절하는 컴파운드 스케일링 방식(compoundscaling method)이 사용되는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 방법."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 상기 감정 예측부(130)는,감정상태 예측을 위한 얼굴표정 이미지, 감정 클래스에 따라 추출된 바이오 신호 데이터를 저장하는 데이터베이스(DB)를 포함하여 구성하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 방법."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 감정 예측부(130)는,감정상태 예측을 위한 얼굴표정 이미지와 감정 클래스에 따라 추출된 바이오 신호 데이터를 학습하여 데이터베이스(DB)에 저장하되, 데이터베이스에 저장 관리되는 감정 클래스는 행복, 중립, 슬픔, 분노, 놀라움, 혐오 및공포를 포함하는 것을 특징으로 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일비전 방법."}
{"patent_id": "10-2021-0174272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 감정 예측부(130)는,상기 바이오 신호 측정부(110)로부터 측정된 바이오 신호와, 상기 이미지 측정부(120)로부터 측정된 얼굴표정이미지를 데이터베이스에 저장된 학습 데이터와 비교 검색한 후, 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결합하여 높은 정확도의 최종 감정 예측이 가능하도록 하는 것을 특징으로 하는, 인간의 복합감정을 예측할수 있는 EfficientNet 아키텍처 기반 모바일 비전 방법."}
{"patent_id": "10-2021-0174272", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템 및 방법에 관한 것으로서, 보다 구체적으로는 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스 템으로서, 감정상태 예측을 위한 대상자의 바이오 신호를 측정하기 위한 바이오 신호 측정부; 감정상태 예측을 (뒷면에 계속)"}
{"patent_id": "10-2021-0174272", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 모바일 비전 시스템 및 방법에 관한 것으로서, 보다 구체적으로는 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0174272", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능의 기술 발달과 함께 감정 인식 분야가 중요한 연구 분야로 대두되고 있다. 감정이란 어떤 현상 이나 일에 대하여 일어나는 마음이나 느끼는 기분을 뜻한다. 이러한 감정는 말이나 몸짓, 표정 그리고 다른 비 언적 단서를 통해 표현될 수 있고, 많은 생리학적 신호들 또한 감정 상태에 대한 정보를 전달할 수 있다. 감정 인식을 위해 가장 널리 사용되는 지표는 얼굴 표정이다. 하지만 표정은 통제할 수 있으며, 조작이 가능하므로 진정으로 느껴지는 정서를 표정만으로 파악하기는 어렵다. 이러한 문제점을 해결하기 위해 최근 들어 지속적인 측정이 가능하고 개인의 통제를 벗어난 독립적인 바이오신 호를 이용한 감정 인식 연구가 활발히 진행 중이다. 사람의 감정과 바이오신호는 강한 상관관계가 있다는 많은 선행연구가 존재하며, 바이오신호를 통한 감정 인식은 자율신경계에 의해 통제되므로 거짓 없이 얻을 수 있다. 하지만 현재까지 바이오신호와 얼굴 표정 템플렛을 다차원 분석하여 대상자의 감정 인식에 사용한 발명은 거의 없었다. 또한, 종래의 감정인식 기술은 대부분이 표정 이미지 데이터에 기반한 특징 추출 과정을 통해 인식하는 방식으 로 분석과정이 복잡하고, 표정 인식의 신뢰성이 떨어지는 한계가 따르는 문제가 있었다. 대한민국 등록특허공 보 제10-2147052호, 공개특허공보 제10-2018-0125756호가 선행기술 문헌으로 개시되고 있다."}
{"patent_id": "10-2021-0174272", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 기존에 제안된 방법들의 상기와 같은 문제점들을 해결하기 위해 제안된 것으로서, 감정상태 예측을 위한 대상자의 바이오 신호를 측정하기 위한 바이오 신호 측정부와, 감정상태 예측을 위한 대상자의 얼굴표정 이미지를 측정하기 위한 이미지 측정부와, 바이오 신호 측정부로부터 측정된 바이오 신호와, 이미지 측정부로부 터 측정된 얼굴표정 이미지를 분석하여 각각의 감정을 분류하고, 분류된 바이오 신호의 감정과 얼굴표정 이미지 의 감정을 결합하여 최종 감정을 예측하는 감정 예측부를 포함하여 구성함으로써, 대상자의 얼굴표정 이미지만 으로 감정을 예측하는 것보다 바이오 신호를 결합하여 감정 상태를 예측하여 보다 높은 정확도를 가지며, 최적 의 파라미터로 높은 인식 성능을 유지할 수 있도록 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키 텍처 기반 모바일 비전 시스템 및 방법을 제공하는 것을 그 목적으로 한다. 또한, 본 발명은, 슈퍼디멘션 기반 딥 뉴럴 네트워크를 설계하여 바이오신호와 얼굴 표정 템플렛을 함께 분석하 여 대상자의 감정 상태를 정확도 예측할 수 있는 알고리즘을 구성함으로써, 사람의 표정으로부터 얻을 수 있는 감정 상태와 바이오 신호를 통해 알 수 있는 감정을 동시에 분석하여 감정 예측의 정확성을 높이고, 콘불루션 뉴럴 네트워크 기반의 EfficientNet-B0 아키텍쳐를 사용하여 최소한의 파라미터로 최대한의 성능 구현이 가능하 며, 향후 인공지능과 결합될 수 있는 감정지능으로서 향후 확장된 데이터 차원에서도 높은 성능을 유지할 수 있 도록 하는, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템 및 방법을 제공 하는 것을 또 다른 목적으로 한다."}
{"patent_id": "10-2021-0174272", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 특징에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템은, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템으로서, 감정상태 예측을 위한 대상자의 바이오 신호를 측정하기 위한 바이오 신호 측정부; 감정상태 예측을 위한 대상자의 얼굴표정 이미지를 측정하기 위한 이미지 측정부; 및 상기 바이오 신호 측정부로부터 측정된 바이오 신호와, 상기 이미지 측정부로부터 측정된 얼굴표정 이미지를 분 석하여 각각의 감정을 분류하고, 분류된 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결합하여 최종 감정을 예측하는 감정 예측부를 포함하는 것을 그 구성상의 특징으로 한다.바람직하게는, 상기 바이오 신호 측정부는, 감정상태 예측을 위한 바이오 신호로서, 대상자의 심장 박동 변이도를 의미하는 심전도를 비접촉 방식으로 측정 할 수 있다. 더욱 바람직하게는, 상기 바이오 신호 측정부는, 감정상태 예측을 위한 바이오 신호로서, 심전도 이외에도 산소포화도, 초당 혈류량, 및 혈압을 비접촉 방식으로 더 측정할 수 있다. 바람직하게는, 상기 감정 예측부는, 바이오 신호와 얼굴표정 이미지의 분석을 위한 딥러닝 알고리즘으로 콘볼루션 뉴럴 네트워크(convolution Neural Network, CNN) 기반의 EfficientNet-B0 모델을 사용할 수 있다. 더욱 바람직하게는, 상기 감정 예측부는, 콘볼루션 뉴럴 네트워크(convolution Neural Network, CNN) 기반의 EfficientNet-B0 모델을 사용하되, 깊이 (depth)와 너비(width)와 해상도(image resolution)를 함께 조절하는 컴파운드 스케일링 방식(compound scaling method)이 사용될 수 있다. 더욱 바람직하게는, 상기 감정 예측부는, 감정상태 예측을 위한 얼굴표정 이미지, 감정 클래스에 따라 추출된 바이오 신호 데이터를 저장하는 데이터베이 스(DB)를 포함하여 구성할 수 있다. 더욱 더 바람직하게는, 상기 감정 예측부는, 감정상태 예측을 위한 얼굴표정 이미지와 감정 클래스에 따라 추출된 바이오 신호 데이터를 학습하여 데이터베 이스(DB)에 저장하되, 데이터베이스에 저장 관리되는 감정 클래스는 행복, 중립, 슬픔, 분노, 놀라움, 혐오 및 공포를 포함할 수 있다. 더더욱 바람직하게는, 상기 감정 예측부는, 상기 바이오 신호 측정부로부터 측정된 바이오 신호와, 상기 이미지 측정부로부터 측정된 얼굴표정 이미지 를 데이터베이스에 저장된 학습 데이터와 비교 검색한 후, 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결 합하여 높은 정확도의 최종 감정 예측이 가능하도록 할 수 있다. 상기한 목적을 달성하기 위한 본 발명의 특징에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 방법은, 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 방법으로서, 바이오 신호 측정부가 감정상태 예측을 위한 대상자의 바이오 신호를 측정하는 단계; 이미지 측정부가 감정상태 예측을 위한 대상자의 얼굴표정 이미지를 측정하는 단계; 및 감정 예측부가 상기 바이오 신호 측정부로부터 측정된 바이오 신호와, 상기 이미지 측정부로부터 측정된 얼 굴표정 이미지를 분석하여 각각의 감정을 분류하고, 분류된 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결 합하여 최종 감정을 예측하는 단계를 포함하는 것을 그 구성상의 특징으로 한다.바람직하게는, 상기 바이오 신호 측정부는, 감정상태 예측을 위한 바이오 신호로서, 대상자의 심장 박동 변이도를 의미하는 심전도를 비접촉 방식으로 측정 할 수 있다. 더욱 바람직하게는, 상기 바이오 신호 측정부는, 감정상태 예측을 위한 바이오 신호로서, 심전도 이외에도 산소포화도, 초당 혈류량, 및 혈압을 비접촉 방식으로 더 측정할 수 있다. 바람직하게는, 상기 감정 예측부는, 바이오 신호와 얼굴표정 이미지의 분석을 위한 딥러닝 알고리즘으로 콘볼루션 뉴럴 네트워크(convolution Neural Network, CNN) 기반의 EfficientNet-B0 모델을 사용할 수 있다. 더욱 바람직하게는, 상기 감정 예측부는, 콘볼루션 뉴럴 네트워크(convolution Neural Network, CNN) 기반의 EfficientNet-B0 모델을 사용하되, 깊이 (depth)와 너비(width)와 해상도(image resolution)를 함께 조절하는 컴파운드 스케일링 방식(compound scaling method)이 사용될 수 있다. 더욱 바람직하게는, 상기 감정 예측부는, 감정상태 예측을 위한 얼굴표정 이미지, 감정 클래스에 따라 추출된 바이오 신호 데이터를 저장하는 데이터베이 스(DB)를 포함하여 구성할 수 있다. 더욱 더 바람직하게는, 상기 감정 예측부는, 감정상태 예측을 위한 얼굴표정 이미지와 감정 클래스에 따라 추출된 바이오 신호 데이터를 학습하여 데이터베 이스(DB)에 저장하되, 데이터베이스에 저장 관리되는 감정 클래스는 행복, 중립, 슬픔, 분노, 놀라움, 혐오 및 공포를 포함할 수 있다. 더더욱 바람직하게는, 상기 감정 예측부는, 상기 바이오 신호 측정부로부터 측정된 바이오 신호와, 상기 이미지 측정부로부터 측정된 얼굴표정 이미지 를 데이터베이스에 저장된 학습 데이터와 비교 검색한 후, 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결 합하여 높은 정확도의 최종 감정 예측이 가능하도록 할 수 있다."}
{"patent_id": "10-2021-0174272", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에서 제안하고 있는 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템 및 방법에 따르면, 감정상태 예측을 위한 대상자의 바이오 신호를 측정하기 위한 바이오 신호 측정부와, 감정상 태 예측을 위한 대상자의 얼굴표정 이미지를 측정하기 위한 이미지 측정부와, 바이오 신호 측정부로부터 측정된 바이오 신호와, 이미지 측정부로부터 측정된 얼굴표정 이미지를 분석하여 각각의 감정을 분류하고, 분류된 바이 오 신호의 감정과 얼굴표정 이미지의 감정을 결합하여 최종 감정을 예측하는 감정 예측부를 포함하여 구성함으 로써, 대상자의 얼굴표정 이미지만으로 감정을 예측하는 것보다 바이오 신호를 결합하여 감정 상태를 예측하여 보다 높은 정확도를 가지며, 최적의 파라미터로 높은 인식 성능을 유지할 수 있도록 할 수 있다.또한, 본 발명의 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템 및 방법에 따르면, 슈퍼디멘션 기반 딥 뉴럴 네트워크를 설계하여 바이오신호와 얼굴 표정 템플렛을 함께 분석하여 대상자 의 감정 상태를 정확도 예측할 수 있는 알고리즘을 구성함으로써, 사람의 표정으로부터 얻을 수 있는 감정 상태 와 바이오 신호를 통해 알 수 있는 감정을 동시에 분석하여 감정 예측의 정확성을 높이고, 콘불루션 뉴럴 네트 워크 기반의 EfficientNet-B0 아키텍쳐를 사용하여 최소한의 파라미터로 최대한의 성능 구현이 가능하며, 향후 인공지능과 결합될 수 있는 감정지능으로서 향후 확장된 데이터 차원에서도 높은 성능을 유지할 수 있도록 할 수 있다."}
{"patent_id": "10-2021-0174272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실 시할 수 있도록 바람직한 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예를 상세하게 설명함에 있어, 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단 되는 경우에는 그 상세한 설명을 생략한다. 또한, 유사한 기능 및 작용을 하는 부분에 대해서는 도면 전체에 걸쳐 동일한 부호를 사용한다.덧붙여, 명세서 전체에서, 어떤 부분이 다른 부분과 ‘연결’ 되어 있다고 할 때, 이는 ‘직접적으로 연결’ 되 어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고 ‘간접적으로 연결’ 되어 있는 경우도 포함한다. 또한, 어떤 구성요소를 ‘포함’ 한다는 것은, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제 외하는 것이 아니라 다른 구성요소를 더 포함할 수 있다는 것을 의미한다. 도 1은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템의 구성을 기능블록으로 도시한 도면이다. 도 1에 도시된 바와 같이, 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템은, 감정상태 예측을 위한 대 상자의 바이오 신호를 측정하기 위한 바이오 신호 측정부와, 감정상태 예측을 위한 대상자의 얼굴표정 이 미지를 측정하기 위한 이미지 측정부와, 바이오 신호 측정부로부터 측정된 바이오 신호와, 이미지 측 정부로부터 측정된 얼굴표정 이미지를 분석하여 각각의 감정을 분류하고, 분류된 바이오 신호의 감정과 얼 굴표정 이미지의 감정을 결합하여 최종 감정을 예측하는 감정 예측부를 포함하여 구성될 수 있다. 이하에 서는 첨부된 도면을 참조하여 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키 텍처 기반 모바일 비전 시스템의 구체적인 구성에 대해 상세히 설명하기로 한다. 바이오 신호 측정부는, 감정상태 예측을 위한 대상자의 바이오 신호를 측정하기 위한 구성이다. 이러한 바이오 신호 측정부는 감정상태 예측을 위한 바이오 신호로서, 대상자의 심장 박동 변이도를 의미하는 심 전도를 비접촉 방식으로 측정할 수 있다. 여기서, 심전도는 심장 활동에 의해 발생하는 전압 신호로서, ECG 신 호의 파형을 분석하면 심장의 이상 유무를 알 수 있으며, 심전도 신호의 R파 간격을 통하여 사람의 심박동을 계 산할 수 있다. 또한, 심박동은 자율 신경계에 의해 조절되는 것이라 감정이나 흥분 등의 다양한 상태를 진단하 는 것이 가능하다. 또한, 바이오 신호 측정부는 감정상태 예측을 위한 바이오 신호로서, 심전도 이외에도 산소포화도, 초당 혈류량, 및 혈압을 비접촉 방식으로 더 측정할 수 있다. 이미지 측정부는, 감정상태 예측을 위한 대상자의 얼굴표정 이미지를 측정하기 위한 구성이다. 이러한 이 미지 측정부는 감정상태 예측을 위한 대상자의 얼굴을 촬영하는 카메라로 구성될 수 잇다. 여기서, 카메 라는 CCTV 카메라, 웹캠, 휴대전화 카메라 등 다양할 수 구현될 수 있으며, 비접촉식으로 촬영되므로, 얼굴표정 이미지는 비접촉식 측정 데이터에 해당한다. 감정 예측부는, 바이오 신호 측정부로부터 측정된 바이오 신호와, 이미지 측정부로부터 측정된 얼굴표정 이미지를 분석하여 각각의 감정을 분류하고, 분류된 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결합하여 최종 감정을 예측하는 구성이다. 이러한 감정 예측부는 바이오 신호와 얼굴표정 이미지의 분석 을 위한 딥러닝 알고리즘으로 콘볼루션 뉴럴 네트워크(convolution Neural Network, CNN) 기반의 EfficientNet-B0 모델을 사용할 수 있다. 또한, 감정 예측부는 콘볼루션 뉴럴 네트워크(convolution Neural Network, CNN) 기반의 EfficientNet-B0 모델을 사용하되, 깊이(depth)와 너비(width)와 해상도(image resolution)를 함께 조절하는 컴파운드 스케일링 방식(compound scaling method)이 사용될 수 있다. 또한, 감정 예측부는 감정상태 예측을 위한 얼굴표정 이미지, 감정 클래스에 따라 추출된 바이오 신호 데 이터를 저장하는 데이터베이스(DB)를 포함하여 구성할 수 있다.또한, 감정 예측부는 감정상태 예측을 위한 얼굴표정 이미지와 감정 클래스에 따라 추출된 바이오 신호 데 이터를 학습하여 데이터베이스(DB)에 저장하되, 데이터베이스에 저장 관리되는 감정 클래스는 행복, 중립, 슬픔, 분노, 놀라움, 혐오 및 공포를 포함할 수 있다. 또한, 감정 예측부는 바이오 신호 측정부로부터 측정된 바이오 신호와, 이미지 측정부로부터 측 정된 얼굴표정 이미지를 데이터베이스에 저장된 학습 데이터와 비교 검색한 후, 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결합하여 높은 정확도의 최종 감정 예측이 가능하도록 할 수 있다. 이와 같이 바이오 신호 측정부와 이미지 측정부 및 감정 예측부를 포함하는 모바일 비전 시스템 은 컴퓨터 등 전자 장치로 구현될 수 있다. 보다 구체적으로 전자 장치는 스마트폰, 태블릿(tablet) PC(personal computer), 이동 전화기, 영상 전화기, 전자책 리더기, 데스크탑(desktop) PC, 랩탑(laptop) PC, 넷북(netbook) 컴퓨터, 워크스테이션(workstation), 서버(server), PDA(personal digital assistant), 미디어 박스, 게임 콘솔, 전자사전 또는 웨어러블 장치(wearable device) 중 적어도 하나를 포함할 수 있다. 다양한 실시예들에서, 전자 장치는 전술한 기기들에 한정되지는 않으며, 전술한 다양한 장치 중 둘 이상의 조합일 수 있다. 도 2는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 얼굴표정 템플릿과 바이오 신호의 일례의 구성을 도시한 도면이다. 도 2에 도시된 바와 같 이, 얼굴표정 이미지 템플릿과 바이오 신호를 결합하여 사람의 표정으로부터 얻을 수 있는 감정 상태와 바이오 신호를 통해 얻을 수 있는 감정을 동시에 분석하여 감정 예측의 정확성을 높일 수 있다. 도 3은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 이미지 감정 클래스의 구성을 일례로 도시한 도면이다. 도 3은 실험 1에 사용되는 얼굴표정 이미지 데이터는 48×48 크기의 Gray Scale 해상도를 갖는 FER2013 데이터가 사용되고, 총 20,000장의 표정 이 미지 중 학습 데이터로 15,000장, 검증 데이터로 5,000장, 테스트 데이터로 5,000장을 사용하였으며, 총 7개 클 래스 중 4개의 클래스인 angry, happy, neutral, sad을 사용하여 레이블을 변경하였다. 도 4는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 바이오 신호의 데이터의 구성을 일례로 도시한 도면이다. 도 4는 실험 2에 사용된 바이오 신호 데이터로서, 각 클래스에 맞는 데이터를 발생시킨다. 기존에 감정 클래스에 따라 추출된 데이터를 확보하 여 사용하고, FER2013 이미지 데이터는 얼굴표정 이미지가 감정 클래스의 데이터 범위 내에 포함됨을 가정한다. 도 5는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 이미지와 바이오 신호의 데이터 구성을 일례로 도시한 도면이고, 도 6은 본 발명의 일실시예 에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 감정 분석 모델의 비교 구성을 도시한 도면이며, 도 7은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있 는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 실험 1의 이미지 데이터만을 이용하는 구성을 도시한 도면이고, 도 8은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 실험 2의 바이오 신호와 이미지 데이터를 함께 이용하는 구서을 도시한 도 면이다. 도 5는 실험에 사용된 데티어를 나타내고 있으며, 도 6은 바이오 신호 및 표정 이미지를 이요하여 감 정 분석하기 위한 모델 비교를 나타내고 있으며, 도 7은 FER 2013 이미지 데이터만을 이용하여 EfficientNet-B0 모델을 학습시키고 테스트를 진행한다. EfficientNet-B0은 12800×7×7 feature를 출력하므로 Dense layer를 이용하여 256 feature로 인코딩하고, 최종적으로 1개의 예측값을 출력한다. 도 8은 바이오 신호 데이터를 사용 하기 위해 각각의 감정 클래스에 해당하는 범위 내 정규분포 샘플링을 수행하고, 한 장의 표정 이미지에서 6개 의 HRV 인덱스마다 1000개 샘플링을 수행하고 랜덤으로 값을 하나씩 추출한다. 이렇게 이미지마다 6개의 HRV 인덱스를 추출하여 개별 dense layer를 거쳐 64 feature로 인코딩 되고, 최종적으로 FER2013 이미지 데이터 256feature와 concat되어 감정 예측하는데 사용된다. 도 9는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 실험 1의 학습 및 검증 그래프를 도시한 도면이고, 도 10은 본 발명의 일실시예에 따른 인간 의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 실험 2의 학습 및 검증 그래프의 구성을 도시한 도면이며, 도 11은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 실험의 결과를 도시한 도면이고, 도 12는 본 발명 의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용 되는 실험의 테스트데이터 셋의 결과를 도시한 도면이며, 도 13은 본 발명의 일실시예에 따른 인간의 복합감정 을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 실험 결과를 그래프로 도시한 도면이다. 도 9 내지 도 13에 각각 도시된 바와 같이, 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템의 실험 결과에 따른 교차 엔트로피 손실과, 정확성을 아래의 [수학식 1] 및 [수학식 2]로 나타낼 수 있다. 수학식 1"}
{"patent_id": "10-2021-0174272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 수학식 1의 교차 엔트로피 손실(Cross-Entropy Loss)는 가중치 매개변수를 결정하기 위한 지표이고, 모 델을 훈련시킬 때 이 손실함수를 최소로 만들어주는 가중치를 찾는 것을 목표로 한다. 실제 데이터의 확률분포 와 학습된 모델이 계산한 확률 분포의 차이를 구하고, 숫자가 낮을수록 좋은 모델로 인식될 수 있다. 수학식 2"}
{"patent_id": "10-2021-0174272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 수학식 2의 정확성(Accuracy)은 훈련된 모델의 성능을 평가할 때 사용하는 평가지표로서, 전체 샘플 중 맞게 예측한 샘플 수의 비율로 숫자가 높을수록 좋은 모델로 인식될 수 있다. 도 9는 이미지만을 사용하는 실험 1의 학습 및 검증 그래프를 나타내고, 도 10은 이미지와 바이오 신호를 결합 하여 사용하는 실험 2의 학습 및 검증 그래프를 나타내며, 도 11은 실험 2에서의 학습 및 검증에서 실험 1보다 우수한 결과를 보여주는 것을 알 수 있다. 도 12는 실험 2의 테스트 데이터 셋에서도 실험 1보다 우수한 결과 를 보여주고 있으며, 도 13은 CE Loss 값이 작을수록 좋은 모델임을 나타내고, Accuracy 값이 클수록 좋은 모델 임을 나타내고 있다. 도 14는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비 전 방법의 흐름을 도시한 도면이다. 도 14에 도시된 바와 같이, 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 방법은, 바이오 신호 측정부가 감정상태 예측을 위한 대상자의 바이오 신호를 측정하는 단계(S110), 이미지 측정부가 감정상태 예측을 위한 대상자의 얼굴표정 이미지를 측정하는 단계(S120), 및 감정 예측부가 바이오 신호 측정부로부터 측정된 바이오 신호와, 이미지 측정부 로부터 측정된 얼굴표정 이미지를 분석하여 각각의 감정을 분류하고, 분류된 바이오 신호의 감정과 얼굴표정 이 미지의 감정을 결합하여 최종 감정을 예측하는 단계(S130)를 포함하여 구현될 수 있다. 단계 S110에서는, 바이오 신호 측정부가 감정상태 예측을 위한 대상자의 바이오 신호를 측정한다. 이러한 단계 S110에서의 바이오 신호 측정부는 감정상태 예측을 위한 바이오 신호로서, 대상자의 심장 박동 변이 도를 의미하는 심전도를 비접촉 방식으로 측정할 수 있다. 여기서, 심전도는 심장 활동에 의해 발생하는 전압 신호로서, ECG 신호의 파형을 분석하면 심장의 이상 유무를 알 수 있으며, 심전도 신호의 R파 간격을 통하여 사 람의 심박동을 계산할 수 있다. 또한, 심박동은 자율 신경계에 의해 조절되는 것이라 감정이나 흥분 등의 다양 한 상태를 진단하는 것이 가능하다. 또한, 바이오 신호 측정부는 감정상태 예측을 위한 바이오 신호로서, 심전도 이외에도 산소포화도, 초당 혈류량, 및 혈압을 비접촉 방식으로 더 측정할 수 있다. 단계 S120에서는, 이미지 측정부가 감정상태 예측을 위한 대상자의 얼굴표정 이미지를 측정한다. 이러한 단계 S120에서의 이미지 측정부는 감정상태 예측을 위한 대상자의 얼굴을 촬영하는 카메라로 구성될 수 잇 다. 여기서, 카메라는 CCTV 카메라, 웹캠, 휴대전화 카메라 등 다양할 수 구현될 수 있으며, 비접촉식으로 촬 영되므로, 얼굴표정 이미지는 비접촉식 측정 데이터에 해당한다. 단계 S130에서는, 감정 예측부가 바이오 신호 측정부로부터 측정된 바이오 신호와, 이미지 측정부 로부터 측정된 얼굴표정 이미지를 분석하여 각각의 감정을 분류하고, 분류된 바이오 신호의 감정과 얼굴표 정 이미지의 감정을 결합하여 최종 감정을 예측한다. 이러한 단계 S130에서의 감정 예측부는 바이오 신호 와 얼굴표정 이미지의 분석을 위한 딥러닝 알고리즘으로 콘볼루션 뉴럴 네트워크(convolution Neural Network, CNN) 기반의 EfficientNet-B0 모델을 사용할 수 있다. 여기서, 감정 예측부는 콘볼루션 뉴럴 네트워크 (convolution Neural Network, CNN) 기반의 EfficientNet-B0 모델을 사용하되, 깊이(depth)와 너비(width)와 해상도(image resolution)를 함께 조절하는 컴파운드 스케일링 방식(compound scaling method)이 사용될 수 있 다. 또한, 감정 예측부는 감정상태 예측을 위한 얼굴표정 이미지, 감정 클래스에 따라 추출된 바이오 신호 데 이터를 저장하는 데이터베이스(DB)를 포함하여 구성할 수 있다. 또한, 감정 예측부는 감정상태 예측을 위한 얼굴표정 이미지와 감정 클래스에 따라 추출된 바이오 신호 데 이터를 학습하여 데이터베이스(DB)에 저장하되, 데이터베이스에 저장 관리되는 감정 클래스는 행복, 중립, 슬픔, 분노, 놀라움, 혐오 및 공포를 포함할 수 있다. 또한, 감정 예측부는 바이오 신호 측정부로부터 측정된 바이오 신호와, 이미지 측정부로부터 측 정된 얼굴표정 이미지를 데이터베이스에 저장된 학습 데이터와 비교 검색한 후, 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결합하여 높은 정확도의 최종 감정 예측이 가능하도록 할 수 있다. 상술한 바와 같이, 본 발명의 일실시에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모 바일 비전 시스템 및 방법은, 감정상태 예측을 위한 대상자의 바이오 신호를 측정하기 위한 바이오 신호 측정부 와, 감정상태 예측을 위한 대상자의 얼굴표정 이미지를 측정하기 위한 이미지 측정부와, 바이오 신호 측정부로 부터 측정된 바이오 신호와, 이미지 측정부로부터 측정된 얼굴표정 이미지를 분석하여 각각의 감정을 분류하고, 분류된 바이오 신호의 감정과 얼굴표정 이미지의 감정을 결합하여 최종 감정을 예측하는 감정 예측부를 포함하여 구성함으로써, 대상자의 얼굴표정 이미지만으로 감정을 예측하는 것보다 바이오 신호를 결합하여 감정 상태 를 예측하여 보다 높은 정확도를 가지며, 최적의 파라미터로 높은 인식 성능을 유지할 수 있도록 할 수 있으며, 특히, 슈퍼디멘션 기반 딥 뉴럴 네트워크를 설계하여 바이오신호와 얼굴 표정 템플렛을 함께 분석하여 대상자의 감정 상태를 정확도 예측할 수 있는 알고리즘을 구성함으로써, 사람의 표정으로부터 얻을 수 있는 감정 상태와 바이오 신호를 통해 알 수 있는 감정을 동시에 분석하여 감정 예측의 정확성을 높이고, 콘불루션 뉴럴 네트워크 기반의 EfficientNet-B0 아키텍쳐를 사용하여 최소한의 파라미터로 최대한의 성능 구현이 가능하며, 향후 인공 지능과 결합될 수 있는 감정지능으로서 향후 확장된 데이터 차원에서도 높은 성능을 유지할 수 있도록 할 수 있 게 된다."}
{"patent_id": "10-2021-0174272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상 설명한 본 발명은 본 발명이 속한 기술분야에서 통상의 지식을 가진 자에 의하여 다양한 변형이나 응용이 가능하며, 본 발명에 따른 기술적 사상의 범위는 아래의 특허청구범위에 의하여 정해져야 할 것이다."}
{"patent_id": "10-2021-0174272", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템의 구성을 기능블록으로 도시한 도면. 도 2는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 얼굴표정 템플릿과 바이오 신호의 일례의 구성을 도시한 도면. 도 3은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 이미지 감정 클래스의 구성을 일례로 도시한 도면. 도 4는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 바이오 신호의 데이터의 구성을 일례로 도시한 도면. 도 5는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 이미지와 바이오 신호의 데이터 구성을 일례로 도시한 도면. 도 6은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 감정 분석 모델의 비교 구성을 도시한 도면. 도 7은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 실험 1의 이미지 데이터만을 이용하는 구성을 도시한 도면. 도 8은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 실험 2의 바이오 신호와 이미지 데이터를 함께 이용하는 구서을 도시한 도면. 도 9는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비전 시스템에 적용되는 실험 1의 학습 및 검증 그래프를 도시한 도면. 도 10은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비 전 시스템에 적용되는 실험 2의 학습 및 검증 그래프의 구성을 도시한 도면. 도 11은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비 전 시스템에 적용되는 실험의 결과를 도시한 도면. 도 12는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비 전 시스템에 적용되는 실험의 테스트데이터 셋의 결과를 도시한 도면. 도 13은 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비 전 시스템에 적용되는 실험 결과를 그래프로 도시한 도면. 도 14는 본 발명의 일실시예에 따른 인간의 복합감정을 예측할 수 있는 EfficientNet 아키텍처 기반 모바일 비 전 방법의 흐름을 도시한 도면."}
