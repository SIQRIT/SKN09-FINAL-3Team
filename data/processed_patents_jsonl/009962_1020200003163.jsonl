{"patent_id": "10-2020-0003163", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0090329", "출원번호": "10-2020-0003163", "발명의 명칭": "카메라를 이용하여 자율 주행을 수행하는 차량 및 그의 동작 방법", "출원인": "엘지전자 주식회사", "발명자": "윤용지"}}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량에 포함되는 전자 장치에 있어서,복수의 카메라들; 및적어도 하나의 프로세서를 포함하며, 상기 프로세서는, 맵 데이터, 또는 상기 차량의 주행 정보 중 적어도 하나에 기반하여 탐지 영역을 결정하고,상기 복수의 카메라들 중 적어도 하나의 카메라의 적어도 일부 시야각이 인접한 차량에 의해 차단되는지 여부에기초하여, 상기 적어도 하나의 카메라의 샘플링 레이트를 제어하고,상기 샘플링 레이트가 제어된 상기 적어도 하나의 카메라를 이용하여 상기 탐지 영역에 위치한 다른 차량의 주행 정보를 획득하고,상기 다른 차량의 주행 정보와 상기 차량의 주행 정보에 기반하여, 상기 차량의 주행을 제어하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는, 상기 적어도 하나의 카메라의 적어도 일부 시야각이 인접한 차량에 의해 차단되는 경우, 상기적어도 하나의 카메라의 샘플링 레이트가 증가되도록 제어하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는, 상기 복수의 카메라들 각각의 시야각에 기초하여, 상기 탐지 영역 중 적어도 일부를 커버하는시야각을 갖는 상기 적어도 하나의 카메라가 구동되도록 제어하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 다른 차량의 주행 정보는, 상기 다른 차량의 바퀴 정보, 차체 정보, 이동 속도, 이동 방향, 또는 시간에따른 예상 이동 궤적 중 적어도 하나를 포함하며,상기 바퀴 정보는, 바퀴의 크기, 바퀴의 반경, 바퀴의 초당 회전 수, 또는 바퀴의 방향 중 적어도 하나를 포함하며,상기 차체 정보는, 상기 차량의 길이, 또는 높이 정보 중 적어도 하나를 포함하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는, 상기 다른 차량의 주행 정보와 상기 차량의 주행 정보에 기반하여, 상기 다른 차량과 상기 차량의 충돌 예상 위치를 결정하고,공개특허 10-2021-0090329-3-상기 다른 차량이 상기 충돌 예상 위치까지 이동하는데 소요될 것으로 예상되는 제1 시간, 및 상기 차량이 상기충돌 예상 위치까지 이동하는데 소요될 것으로 예상되는 제2 시간을 추정하고,상기 제1 시간과 상기 제2 시간에 기초하여, 상기 차량의 주행 속도, 주행 차선, 또는 주행 위치 중 적어도 하나를 변경하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 프로세서는, 상기 시간에 따른 예상 이동 궤적에 기초하여, 상기 탐지 영역 중 제 1 영역에 상기 다른 차량이 진입할 것으로 예측된 시점을 결정하고,상기 적어도 하나의 카메라를 이용하여 상기 제1 영역에 상기 다른 차량이 진입한 시점을 측정하고,상기 예측된 시점과 상기 측정된 시점이 일치하지 않는 경우, 적어도 하나의 대체 센서가 구동되도록 제어하는전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 적어도 하나의 대체 센서는, 적어도 하나의 다른 카메라, 또는 적어도 하나의 라이다 중 적어도 하나를 포함하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 프로세서는, 상기 예측된 시점과 상기 측정된 시점이 일치하지는 경우, 상기 다른 차량의 주행 정보에 기초하여, 상기 다른 차량의 후속 차량에 대한 주행 정보를 추정하며,상기 후속 차량에 대한 주행 정보는, 상기 후속 차량의 이동 속도, 또는 시간에 따른 예상 이동 궤적 중 적어도하나를 포함하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는, 상기 복수의 카메라들 중 적어도 하나의 카메라의 적어도 일부 시야각이 인접한 차량에 의해차단되는 경우, 상기 차량의 속도, 상기 차량의 주행 차선, 또는 상기 차량의 주행 차선 내 위치 중 적어도 하나를 변경하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 프로세서는, 상기 탐지 영역 중 제1 영역을 커버하는 시야각을 갖는 적어도 하나의 카메라를 이용하여 상기 탐지 영역에 위치한 다른 차량의 주행 정보를 획득하고,상기 적어도 하나의 카메라의 시야각 중 지정된 크기 이상의 시야각이 인접한 차량에 의해 차단되는 경우, 상기탐지 영역 중 제2 영역을 커버하는 시야각을 갖는 적어도 하나의 다른 카메라를 이용하여 상기 탐지 영역에 위치한 다른 차량의 주행 정보를 획득하며,공개특허 10-2021-0090329-4-상기 제2 영역은, 상기 제1 영역의 적어도 일부 영역, 또는 상기 탐지 영역 중 상기 제1 영역과 다른 영역 중적어도 하나의 영역을 포함하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 프로세서는, 상기 적어도 하나의 다른 카메라를 이용하는 동안에 상기 적어도 하나의 카메라의 샘플링 동작이 적어도 일시적으로 중지되도록 제어하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 프로세서는, 상기 적어도 하나의 카메라를 통해 상기 인접한 차량의 바퀴 정보, 또는 차체 정보 중 적어도하나를 획득하고,상기 획득된 정보에 기초하여, 상기 인접한 차량에 의해 상기 적어도 하나의 카메라의 시야각 중 지정된 크기이상의 시야각이 상기 인접한 차량에 의해 차단될 것으로 예상되는 시점을 예측하고, 상기 예측된 시점 이전에, 상기 탐지 영역 중 적어도 일부를 커버하는 적어도 하나의 다른 카메라가 구동되도록제어하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,적어도 하나의 라이다를 더 포함하며,상기 프로세서는, 상기 탐지 영역 중 상기 적어도 하나의 카메라를 통해 모니터링 가능한 영역을 확인하고,상기 적어도 하나의 라이다 이용하여 상기 모니터링 가능한 영역으로 레이저 빔이 방출되도록 제어하는 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서,상기 복수의 카메라들은, 상기 차량의 램프 내부 공간에 배치된 전자 장치."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "차량에 포함되는 전자 장치의 동작 방법에 있어서,맵 데이터, 또는 상기 차량의 주행 정보 중 적어도 하나에 기반하여 탐지 영역을 결정하는 동작;상기 차량에 포함된 복수의 카메라들 중 적어도 하나의 카메라의 적어도 일부 시야각이 인접한 차량에 의해 차단되는지 여부에 기초하여, 상기 적어도 하나의 카메라의 샘플링 레이트를 제어하는 동작;상기 샘플링 레이트가 제어된 상기 적어도 하나의 카메라를 이용하여 상기 탐지 영역에 위치한 다른 차량의 주행 정보를 획득하는 동작; 및상기 다른 차량의 주행 정보와 상기 차량의 주행 정보에 기반하여, 상기 차량의 주행을 제어하는 동작을 포함하는 방법.공개특허 10-2021-0090329-5-청구항 16 제15항에 있어서,상기 샘플링 레이트를 제어하는 동작은,상기 적어도 하나의 카메라의 적어도 일부 시야각이 인접한 차량에 의해 차단되는 경우, 상기 적어도 하나의 카메라의 샘플링 레이트가 증가되도록 제어하는 동작을 포함하는 방법."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 다른 차량의 주행 정보는, 상기 다른 차량의 바퀴 정보, 차체 정보, 이동 속도, 이동 방향, 또는 시간에따른 예상 이동 궤적 중 적어도 하나를 포함하며,상기 바퀴 정보는, 바퀴의 크기, 바퀴의 반경, 바퀴의 초당 회전 수, 또는 바퀴의 방향 중 적어도 하나를 포함하며,상기 차체 정보는, 상기 차량의 길이, 또는 높이 정보 중 적어도 하나를 포함하는 방법."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 차량의 주행을 제어하는 동작은,상기 다른 차량의 주행 정보와 상기 차량의 주행 정보에 기반하여, 상기 다른 차량과 상기 차량의 충돌 예상 위치를 결정하는 동작; 상기 다른 차량이 상기 충돌 예상 위치까지 이동하는데 소요될 것으로 예상되는 제1 시간, 및 상기 차량이 상기충돌 예상 위치까지 이동하는데 소요될 것으로 예상되는 제2 시간을 추정하는 동작; 및상기 제1 시간과 상기 제2 시간에 기초하여, 상기 차량의 주행 속도, 주행 차선, 또는 주행 위치 중 적어도 하나를 변경하는 동작을 포함하는 방법."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서,상기 시간에 따른 예상 이동 궤적에 기초하여, 상기 탐지 영역 중 제 1 영역에 상기 다른 차량이 진입할 것으로예측된 시점을 결정하는 동작;상기 적어도 하나의 카메라를 이용하여 상기 제1 영역에 상기 다른 차량이 진입한 시점을 측정하는 동작; 및상기 예측된 시점과 상기 측정된 시점이 일치하지 않는 경우, 적어도 하나의 대체 센서가 구동되도록 제어하며,상기 적어도 하나의 대체 센서는, 적어도 하나의 다른 카메라, 또는 적어도 하나의 라이다 중 적어도 하나를 포함하는 방법."}
{"patent_id": "10-2020-0003163", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 예측된 시점과 상기 측정된 시점이 일치하지는 경우, 상기 다른 차량의 주행 정보에 기초하여, 상기 다른공개특허 10-2021-0090329-6-차량의 후속 차량에 대한 주행 정보를 추정하는 동작을 더 포함하며,상기 후속 차량에 대한 주행 정보는, 상기 후속 차량의 이동 속도, 또는 시간에 따른 예상 이동 궤적 중 적어도하나를 포함하는 방법."}
{"patent_id": "10-2020-0003163", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시물은 카메라를 이용하여 자율 주행을 수행하는 차량 및 그의 동작 방법에 관한 것이다. 이때, 차량에 포 함되는 전자 장치는, 복수의 카메라들, 및 적어도 하나의 프로세서를 포함하며, 상기 프로세서는, 맵 데이터, 또 는 상기 차량의 주행 정보 중 적어도 하나에 기반하여 탐지 영역을 결정하고, 상기 복수의 카메라들 중 적어도 (뒷면에 계속)"}
{"patent_id": "10-2020-0003163", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시물의 다양한 실시예들은 카메라를 이용하여 자율 주행을 수행하는 차량 및 그의 동작 방법에 관한 것이다."}
{"patent_id": "10-2020-0003163", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율 주행 차량은 사용자의 조작 없이, 스스로 운행 할 수 있는 기능을 갖는 차량을 의미한다. 자율 주행 차량 은 차량에 장착된 적어도 하나의 센서로부터 획득되는 정보를 서버로 송신하고, 서버로부터 주변의 차량 및 도 로의 상황에 대한 정보를 수신함으로써, 사용자의 조작없이 자동 주행을 수행할 수 있다. 자율 주행 차량은 카메라를 이용하여 차량 주변의 오브젝트를 검출할 수 있다. 예를 들어, 자율 주행 차량은 차 량에 장착된 카메라를 통해 주변 환경을 촬영한 이미지를 획득하고, 획득된 이미지를 분석하여 차량 주변에 위 치한 오브젝트를 검출할 수 있다."}
{"patent_id": "10-2020-0003163", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "차량에서 카메라를 이용한 오브젝트 검출 결과에 기반하여 자율 주행을 수행하는 동안에, 교차로와 같은 복잡한 환경에서 인접한 타차량, 또는 보행자에 의해 카메라의 시야각의 적어도 일부가 차단될 수 있다. 타차량, 또는 시야각에 의해 시야각의 적어도 일부가 차단되는 경우, 차량의 주행 경로에 진입하는 다른 차량을 정확히 인지 하지 못하여 충돌 사고가 발생될 수 있다. 따라서, 본 개시물의 다양한 실시예들은 복수의 카메라들을 이용하여 자율 주행을 수행하는 자율 주행 차량 및 그의 동작 방법에 대해 개시한다. 본 개시물의 다양한 실시예들은 적어도 하나의 카메라의 샘플링 레이트를 조절하여 오브젝트를 감지하는 자율 주행 차량 및 그의 동작 방법에 대해 개시한다. 본 문서에서 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2020-0003163", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 개시물이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0003163", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시물의 다양한 실시예들에 따르면, 차량에 포함되는 전자 장치는, 복수의 카메라들, 및 적어도 하나의 프 로세서를 포함하며, 상기 프로세서는, 맵 데이터, 또는 상기 차량의 주행 정보 중 적어도 하나에 기반하여 탐지 영역을 결정하고, 상기 복수의 카메라들 중 적어도 하나의 카메라의 적어도 일부 시야각이 인접한 차량에 의해 차단되는지 여부에 기초하여, 상기 적어도 하나의 카메라의 샘플링 레이트를 제어하고, 상기 샘플링 레이트가 제어된 상기 적어도 하나의 카메라를 이용하여 상기 탐지 영역에 위치한 다른 차량의 주행 정보를 획득하고, 상 기 다른 차량의 주행 정보와 상기 차량의 주행 정보에 기반하여, 상기 차량의 주행을 제어할 수 있다. 본 개시물의 다양한 실시예들에 따르면, 차량에 포함되는 전자 장치의 동작 방법은, 맵 데이터, 또는 상기 차량 의 주행 정보 중 적어도 하나에 기반하여 탐지 영역을 결정하는 동작, 상기 차량에 포함된 복수의 카메라들 중적어도 하나의 카메라의 적어도 일부 시야각이 인접한 차량에 의해 차단되는지 여부에 기초하여, 상기 적어도 하나의 카메라의 샘플링 레이트를 제어하는 동작, 상기 샘플링 레이트가 제어된 상기 적어도 하나의 카메라를 이용하여 상기 탐지 영역에 위치한 다른 차량의 주행 정보를 획득하는 동작, 및 상기 다른 차량의 주행 정보와 상기 차량의 주행 정보에 기반하여, 상기 차량의 주행을 제어하는 동작을 포함할 수 있다."}
{"patent_id": "10-2020-0003163", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시물의 다양한 실시예들에 따른 자율 주행 장치는, 적어도 하나의 카메라의 시야각의 적어도 일부가 차단 되는 경우, 적어도 하나의 카메라의 샘플링 레이트를 증가시킴으로써, 작은 영역을 통해 빠른 속도로 이동하는 타차량에 대한 탐지 정확도를 향상시킬 수 있다. 본 개시물의 다양한 실시예들에 따른 자율 주행 장치는, 적어도 하나의 카메라의 시야각의 적어도 일부가 차단 되는 경우, 차량에 포함된 적어도 하나의 다른 카메라를 구동하여 탐지를 수행함으로써, 차량의 주행 경로에 진 입할 것으로 예상되는 타차량을 인지하고, 타차량과의 충돌 사고가 발생될 가능성을 낮출 수 있다. 본 개시물의 다양한 실시예들에 따른 자율 주행 장치는, 복수의 카메라의 시야각 및/또는 자율 주행 차량에 진 입할 것으로 예상되는 타차량에 대한 탐지 결과에 기초하여 적어도 하나의 카메라의 샘플링 동작을 중단함으로 써, 불필요한 전력 소모를 방지할 수 있다."}
{"patent_id": "10-2020-0003163", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시물의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실 시예들을 참조하면 명확해질 것이다. 그러나 본 개시물은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 개시물의 개시가 완전하도록 하며, 본 개시물"}
{"patent_id": "10-2020-0003163", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이 속하는 기술분야에서 통상의 지식을 가진 자에게 개시물의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시물은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지 칭한다. 하나의 구성 요소가 다른 구성 요소와 \"연결된(connected to)\" 또는 \"커플링된(coupled to)\" 이라고 지칭되는 것은, 다른 구성 요소와 직접 연결 또는 커플링된 경우 또는 중간에 다른 구성 요소를 개재한 경우를 모두 포함 한다. 반면, 하나의 구성 요소가 다른 구성 요소와 \"직접 연결된(directly connected to)\" 또는 \"직접 커플링된 (directly coupled to)\"으로 지칭되는 것은 중간에 다른 구성 요소를 개재하지 않은 것을 나타낸다. \"및/또는\" 은 언급된 아이템들의 각각 및 하나 이상의 모든 조합을 포함한다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 개시물을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성 요소, 단계, 동작 및/또는 소자는 하나 이상의 다 른 구성 요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 비록 제1, 제2 등이 다양한 구성 요소들을 서술하기 위해서 사용되나, 이들 구성 요소들은 이들 용어에 의해 제 한되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성 요소를 다른 구성 요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 개시물의 기술적 사상 내에서 제2 구성 요소 일 수도 있음은 물 론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 개시물이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또 는 과도하게 해석되지 않는다. 본 실시예에서 사용되는 '부' 또는 '모듈'이라는 용어는 소프트웨어 또는 FPGA또는 ASIC과 같은 하드웨어 구성 요소를 의미하며, '부' 또는 '모듈'은 어떤 역할들을 수행한다. 그렇지만 '부' 또는 '모듈'은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '부' 또는 '모듈'은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '부' 또는 '모듈' 은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성 요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수 들을 포함할 수 있다. 구성요소들과 '부' 또는 '모듈'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '부' 또는 '모듈'들로 결합되거나 추가적인 구성요소들과 '부' 또는 '모듈'들로 더 분리될 수 있다. 본 개시물의 몇몇 실시예들과 관련하여 설명되는 방법 또는 알고리즘의 단계는 프로세서에 의해 실행되는 하드 웨어, 소프트웨어 모듈, 또는 그 2 개의 결합으로 직접 구현될 수 있다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 디스크, 착탈형 디스크, CD-ROM, 또는 당업 계에 알려진 임의의 다른 형태의 기록 매체에 상주할 수도 있다. 예시적인 기록 매체는 프로세서에 커플링되며, 그 프로세서는 기록 매체로부터 정보를 판독할 수 있고 저장 매체에 정보를 기입할 수 있다. 다른 방법으로, 기 록 매체는 프로세서와 일체형일 수도 있다. 프로세서 및 기록 매체는 주문형 집적회로(ASIC) 내에 상주할 수도 있다. ASIC는 사용자 단말기 내에 상주할 수도 있다. 도 1은 5G 통신 시스템에서 자율 주행 차량과 5G 네트워크의 기본동작의 일 예를 나타낸다. 자율 주행 차량(Autonomous Vehicle)은 특정 정보 전송을 5G 네트워크로 전송한다(S1). 상기 특정 정보는, 자율 주행 관련 정보를 포함할 수 있다. 상기 자율 주행 관련 정보는, 차량의 주행 제어와 직접적으로 관련된 정보일 수 있다. 예를 들어, 자율 주행 관 련 정보는 차량 주변의 오브젝트를 지시하는 오브젝트 데이터, 맵 데이터(map data), 차량 상태 데이터, 차량위치 데이터 및 드라이빙 플랜 데이터(driving plan data) 중 하나 이상을 포함할 수 있다. 상기 자율 주행 관련 정보는 자율 주행에 필요한 서비스 정보 등을 더 포함할 수 있다. 예를 들어, 상기 특정 정보는, 사용자 단말기를 통해 입력된 목적지와 차량의 안정 등급에 관한 정보를 포함할 수 있다. 그리고, 상기 5G 네트워크는 차량의 원격 제어 여부를 결정할 수 있다 (S2). 여기서, 상기 5G 네트워크는 자율 주행 관련 원격 제어를 수행하는 서버 또는 모듈을 포함할 수 있다. 그리고, 상기 5G 네트워크는 원격 제어와 관련된 정보(또는 신호)를 상기 자율 주행 차량으로 전송할 수 있다 (S3). 전술한 바와 같이, 상기 원격 제어와 관련된 정보는 자율 주행 차량에 직접적으로 적용되는 신호일 수도 있고, 나아가 자율 주행에 필요한 서비스 정보를 더 포함할 수 있다. 본 개시물의 일 실시예에서는 자율 주행 차량은, 상기 5G 네트워크에 연결된 서버를 통해 주행 경로 상에서 선택된 구간별 보험과 위험 구간 정보 등의 서비스 정보를 수신함으로써, 자율 주행과 관련된 서비스를 제공할 수 있다. 이하 도 2 내지 도 6에서는 본 개시물의 일 실시에에 따라 자율 주행 과정에서 구간별 적용 가능한 보험 서비스 를 제공하기 위하여, 자율 주행 차량과 5G 네트워크 간의 5G 통신을 위한 필수 과정(예를 들어, 차량과 5G 네트 워크 간의 초기 접속 절차 등)을 개략적으로 설명한다. 도 2는 5G 통신 시스템에서 자율 주행 차량과 5G 네트워크의 응용 동작의 일 예를 나타낸다. 자율 주행 차량은 5G 네트워크와 초기 접속(initial access) 절차를 수행한다(S20). 상기 초기 접속 절차는 하향 링크(Downlink, DL) 동작 획득을 위한 셀 서치(cell search), 시스템 정보(system information)를 획득하는 과정 등을 포함한다. 그리고, 상기 자율 주행 차량은 상기 5G 네트워크와 임의 접속(random access) 절차를 수행한다(S21). 상기 임의 접속 과정은 상향 링크(Uplink, UL) 동기 획득 또는 UL 데이터 전송을 위해 프리엠블 전송, 임의 접 속 응답 수신 과정 등을 포함하며, 단락 G에서 보다 구체적으로 설명한다. 그리고, 상기 5G 네트워크는 상기 자율 주행 차량으로 특정 정보의 전송을 스케쥴링하기 위한 UL grant를 전송 한다(S22). 상기 UL Grant 수신은 5G 네트워크로 UL 데이터의 전송을 위해 시간/주파수 자원 스케줄링을 받는 과정을 포함 한다. 그리고, 상기 자율 주행 차량은 상기 UL grant에 기초하여 상기 5G 네트워크로 특정 정보를 전송한다(S23). 그리고, 상기 5G 네트워크는 차량의 원격 제어 여부를 결정한다(S24). 그리고, 자율 주행 차량은 5G 네트워크로부터 특정 정보에 대한 응답을 수신하기 위해 물리 하향링크 제어 채널 을 통해 DL grant를 수신한다(S25). 그리고, 상기 5G 네트워크는 상기 DL grant에 기초하여 상기 자율 주행 차량으로 원격 제어와 관련된 정보(또는 신호)를 전송한다(S26). 한편, 도 3에서는 자율 주행 차량과 5G 통신의 초기 접속 과정 및 또는 임의 접속 과정 및 하향링크 그랜트 수 신 과정이 결합된 예를 S20 내지 S26의 과정을 통해 예시적으로 설명하였지만, 본 개시물의 다양한 실시예들은 이에 한정되지 않는다. 예를 들어, S20, S22, S23, S24, S24 과정을 통해 초기 접속 과정 및/또는 임의접속 과정을 수행할 수 있다. 또 한, 예를 들어 S21, S22, S23, S24, S26 과정을 통해 초기접속 과정 및/또는 임의 접속 과정을 수행할 수 있다. 또한 S23, S24, S25, S26을 통해 AI 동작과 하향링크 그랜트 수신과정이 결합되는 과정을 수행할 수 있다. 또한, 도 2에서는 자율 주행 차량 동작에 대하여 S20 내지 S26을 통해 예시적으로 설명한 것이며, 본 개시물의 다양한 실시예들은 이에 한정되지 않는다. 예를 들어, 상기 자율 주행 차량 동작은, S20, S21, S22, S25가 S23, S26과 선택적으로 결합되어 동작할 수 있 다. 또한 예를 들어, 상기 자율 주행 차량 동작은, S21, S22, S23, S26으로 구성될 수도 있다. 또한 예를 들어, 상기 자율 주행 차량 동작은, S20, S21, S23, S26으로 구성될 수 있다. 또한, 예를 들어, 상기 자율 주행 차량동작은, S22, S23, S25, S26으로 구성될 수 있다. 도 3 내지 도 6은 5G 통신을 이용한 자율 주행 차량 동작의 일 예를 나타낸다. 먼저 도 3을 참고하면, 자율 주행 모듈을 포함하는 자율 주행 차량은 DL 동기 및 시스템 정보를 획득하기 위해 SSB(synchronization signal block)에 기초하여 5G 네트워크와 초기 접속 절차를 수행한다(S30). 그리고, 상기 자율 주행 차량은 UL 동기 획득 및/또는 UL 전송을 위해 5G 네트워크와 임의 접속 절차를 수행한 다(S31). 그리고, 상기 자율 주행 차량은 특정 정보를 전송하기 위해 5G 네트워크로 UL grant를 수신한다(S32). 그리고, 상기 자율 주행 차량은 상기 UL grant에 기초하여 특정 정보를 5G 네트워크로 전송한다(S33). 그리고, 상기 자율 주행 차량은 특정 정보에 대한 응답을 수신하기 위한 DL grant를 5G 네트워크로부터 수신한 다(S34). 그리고, 상기 자율 주행 차량은 원격 제어와 관련된 정보(또는 신호)를 DL grant에 기초하여 5G 네트워크로부터 수신한다(S35). S30에 빔 관리(beam management, BM) 과정이 추가될 수 있으며, S31에 PRACH(physical random access channel) 전송과 관련된 빔 실패 복구(beam failure recovery) 과정이 추가될 수 있으며, S32에 UL grant를 포함하는 PDCCH의 빔 수신 방향과 관련하여 QCL 관계 추가될 수 있으며, S33에 특정 정보를 포함하는 PUCCH (physical uplink control channel)/PUSCH (physical uplink shared channel)의 빔 전송 방향과 관련하여 QCL 관계 추가 가 추가될 수 있다. 또한, S34에 DL grant를 포함하는 PDCCH의 빔 수신 방향과 관련하여 QCL 관계 추가될 수 있 다. 도 4를 참고하면, 자율 주행 차량은 DL 동기 및 시스템 정보를 획득하기 위해 SSB에 기초하여 5G 네트워크와 초 기 접속 절차를 수행한다(S40). 그리고, 상기 자율 주행 차량은 UL 동기 획득 및/또는 UL 전송을 위해 5G 네트워크와 임의 접속 절차를 수행한 다(S41). 그리고, 상기 자율 주행 차량은 설정된 그랜트(configured grant)에 기초하여 특정 정보를 5G 네트워크로 전송 한다(S42). 상기 5G 네트워크로부터 UL grant를 수행하는 과정 대신, 설정된 그랜드(configured grant)를 과정 은 단락 H에서 보다 구체적으로 설명한다. 그리고, 상기 자율 주행 차량은 원격 제어와 관련된 정보(또는 신호를) 상기 설정된 그랜트에 기초하여 5G 네트 워크로부터 수신한다(S43). 도 5를 참고하면, 자율 주행 차량은 DL 동기 및 시스템 정보를 획득하기 위해 SSB에 기초하여 5G 네트워크와 초 기 접속 절차를 수행한다(S50). 그리고, 상기 자율 주행 차량은 UL 동기 획득 및/또는 UL 전송을 위해 5G 네트워크와 임의 접속 절차를 수행한 다(S51). 그리고, 상기 자율 주행 차량은 5G 네트워크로부터 DownlinkPreemption IE를 수신한다(S52). 그리고, 상기 자율 주행 차량은 상기 DownlinkPreemption IE에 기초하여 프리엠션 지시를 포함하는 DCI 포맷 2_1을 5G 네트워크로부터 수신한다(S53). 그리고, 상기 자율 주행 차량은 pre-emption indication에 의해 지시된 자원(PRB 및/또는 OFDM 심볼)에서 eMBB data의 수신을 수행(또는 기대 또는 가정)하지 않는다(S54). 프리엠션 지시(preemption indication) 관련 동작은 단락 J에서 보다 구체적으로 설명한다. 그리고, 상기 자율 주행 차량은 특정 정보를 전송하기 위해 5G 네트워크로 UL grant를 수신한다(S55). 그리고, 상기 자율 주행 차량은 상기 UL grant에 기초하여 특정 정보를 5G 네트워크로 전송한다(S56). 그리고, 상기 자율 주행 차량은 특정 정보에 대한 응답을 수신하기 위한 DL grant를 5G 네트워크로부터 수신한 다(S57). 그리고, 상기 자율 주행 차량은 원격제어와 관련된 정보(또는 신호)를 DL grant에 기초하여 5G 네트워크로부터 수신한다(S58). 도 6을 참고하면, 자율 주행 차량은 DL 동기 및 시스템 정보를 획득하기 위해 SSB에 기초하여 5G 네트워크와 초 기 접속 절차를 수행한다(S60). 그리고, 상기 자율 주행 차량은 UL 동기 획득 및/또는 UL 전송을 위해 5G 네트워크와 임의 접속 절차를 수행한 다(S61). 그리고, 상기 자율 주행 차량은 특정 정보를 전송하기 위해 5G 네트워크로 UL grant를 수신한다(S62). 상기 UL grant는 상기 특정 정보의 전송에 대한 반복 횟수에 대한 정보를 포함하고, 상기 특정 정보는 상기 반 복 횟수에 대한 정보에 기초하여 반복하여 전송된다(S63). 그리고, 상기 자율 주행 차량은 상기 UL grant에 기초하여 특정 정보를 5G 네트워크로 전송한다. 그리고, 특정 정보의 반복 전송은 주파수 호핑을 통해 수행되고, 첫 번째 특정 정보의 전송은 제 1 주파수 자원 에서, 두 번째 특정 정보의 전송은 제 2 주파수 자원에서 전송될 수 있다. 상기 특정 정보는 6RB(Resource Block) 또는 1RB(Resource Block)의 협대역(narrowband)을 통해 전송될 수 있 다. 그리고, 상기 자율 주행 차량은 특정 정보에 대한 응답을 수신하기 위한 DL grant를 5G 네트워크로부터 수신한 다(S64). 그리고, 상기 자율 주행 차량은 원격제어와 관련된 정보(또는 신호)를 DL grant에 기초하여 5G 네트워크로부터 수신한다(S65). 앞서 살핀 5G 통신 기술은 후술할 본 명세서에서 제안하는 방법들과 결합되어 적용될 수 있으며, 또는 본 명세 서에서 제안하는 방법들의 기술적 특징을 구체화하거나 명확하게 하는데 보충될 수 있다. 본 명세서에서 기술되는 차량은 통신망을 통해 외부 서버에 연결되고, 자율 주행 기술을 이용하여 운전자 개입 없이 미리 설정된 경로를 따라 이동 가능하다. 본 개시물의 차량은 동력원으로서 엔진을 구비하는 내연기관 차 량, 동력원으로서 엔진과 전기 모터를 구비하는 하이브리드 차량, 동력원으로서 전기 모터를 구비하는 전기 차 량 등으로 구현될 수 있다. 이하의 실시 예에서, 사용자는 운전자, 탑승자 또는 사용자 단말기의 소유자로 해석될 수 있다. 사용자 단말기 는 사용자가 휴대 가능하고 전화 통화와 다양한 어플리케이션(application)을 실행할 수 있는 이동 단말기 예를 들어, 스마트 폰일 수 있으나 이에 한정되지 않는다. 예를 들어, 사용자 단말기는 이동 단말기, PC(Personal computer), 노트북 컴퓨터 또는 자율 주행 차량 시스템으로 해석될 수 있다. 자율주행 차량에서는 주변 위험 요소들을 실시간 센싱하는 능력에 따라 사고 발생 유형 및 빈도가 크게 달라질 수 있다. 목적지까지의 경로는 날씨, 지형 특성, 교통 혼잡도 등 다양한 원인에 의해 위험 수준이 서로 다른 구 간들을 포함할 수 있다. 본 개시물은 사용자의 목적지 입력 시 구간별로 필요한 보험을 안내하고 실시간으로 위 험구간 모니터링을 통해 보험 안내를 업데이트 한다. 본 개시물의 자율 주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 드론(Unmanned Aerial Vehicle, UAV), 로봇, 증강 현실(Augmented Reality, AR) 장치, 가상 현실 (virtual reality, VR), 5G 서비스와 관련된 장치 등과 연계 혹은 융복합될 수 있다. 예를 들어, 자율 주행 차량은 차량에 포함된 적어도 하나의 인공지능 모듈, 로봇과 연계되어 동작할 수 있다. 예를 들어, 차량은, 적어도 하나의 로봇(robot)과 상호 작용할 수 있다. 로봇은, 자력으로 주행이 가능한 이동 로봇(Autonomous Mobile Robot, AMR)일 수 있다. 이동 로봇은, 스스로 이동이 가능하여 이동이 자유롭고, 주행 중 장애물 등을 피하기 위한 다수의 센서가 구비되어 장애물을 피해 주행할 수 있다. 이동 로봇은, 비행 장치를 구비하는 비행형 로봇(예를 들면, 드론)일 수 있다. 이동 로봇은, 적어도 하나의 바퀴를 구비하고, 바퀴의 회전 을 통해 이동되는 바퀴형 로봇일 수 있다. 이동 로봇은, 적어도 하나의 다리를 구비하고, 다리를 이용해 이동되 는 다리식 로봇일 수 있다. 로봇은 차량 사용자의 편의를 보완하는 장치로 기능할 수 있다. 예를 들면, 로봇은, 차량에 적재된 짐을 사용자 의 최종 목적지까지 이동하는 기능을 수행할 수 있다. 예를 들면, 로봇은, 차량에서 하차한 사용자에게 최종 목 적지까지 길을 안내하는 기능을 수행할 수 있다. 예를 들면, 로봇은, 차량에서 하차한 사용자를 최종 목적지까지 수송하는 기능을 수행할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 통신 장치를 통해, 로봇과 통신을 수행할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇에 차량에 포함되는 적어도 하나의 전자 장치에서 처리한 데 이터를 제공할 수 있다. 예를 들면, 차량에 포함되는 적어도 하나의 전자 장치는, 차량 주변의 오브젝트를 지시 하는 오브젝트 데이터, 맵 데이터(map data), 차량 상태 데이터, 차량 위치 데이터 및 드라이빙 플랜 데이터 (driving plan data) 중 적어도 어느 하나를 로봇에 제공할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇으로부터, 로봇에서 처리된 데이터를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇에서 생성된 센싱 데이터, 오브젝트 데이터, 로봇 상태 데이터, 로봇 위치 데이터 및 로봇의 이동 플랜 데이터 중 적어도 어느 하나를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇으로부터 수신된 데이터에 더 기초하여, 제어 신호를 생성할 수 있다. 예를 들면, 차량에 포함되는 적어도 하나의 전자 장치는, 오브젝트 검출 장치에 생성된 오브젝트에 대 한 정보와 로봇에 의해 생성된 오브젝트에 대한 정보를 비교하고, 비교 결과에 기초하여, 제어 신호를 생성할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 차량의 이동 경로와 로봇의 이동 경로간의 간섭이 발생 되지 않도록, 제어 신호를 생성할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능(artificial intelligence, AI)를 구현하는 소프트웨어 모듈 또는 하드웨어 모듈(이하, 인공 지능 모듈)을 포함할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치 는, 획득되는 데이터를 인공 지능 모듈에 입력(input)하고, 인공 지능 모듈에서 출력(output)되는 데이터를 이 용할 수 있다. 인공 지능 모듈은, 적어도 하나의 인공 신경망(artificial neural network, ANN)을 이용하여, 입력되는 데이터 에 대한 기계 학습(machine learning)을 수행할 수 있다. 인공 지능 모듈은, 입력되는 데이터에 대한 기계 학습 을 통해, 드라이빙 플랜 데이터를 출력할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능 모듈에서 출력되는 데이터에 기초하여, 제어 신호를 생 성할 수 있다. 실시예에 따라, 차량에 포함되는 적어도 하나의 전자 장치는, 통신 장치를 통해, 외부 장치로부터, 인공 지능에 의해 처리된 데이터를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능에 의해 처리된 데이터에 기초하여, 제어 신호를 생성할 수 있다. 도 7a는 다양한 실시예들에 따른 차량의 헤드 램프에 포함되는 센서들을 도시한다. 도 7a를 참조하면, 다양한 실시예들에 따른 차량의 헤드 램프들(701, 703) 각각은, 적어도 두 개의 카메라(711, 713, 731, 733), 적어도 하나의 라이다(721, 723), 및 적어도 하나의 광원(741, 743)을 포함할 수 있다. 다양한 실시예들에 따르면, 제1 헤드 램프는 제1 전방 카메라, 제1 측방 카메라, 제1 라이다 , 및 적어도 하나의 제1 광원 중 적어도 하나를 포함할 수 있다. 제1 헤드 램프는 차량의 우측 전면에 장착되는 헤드 램프일 수 있으며, 제1 전방 카메라는, 차량의 전방을 센싱하도록 배치되고, 제1 측 방 카메라는, 차량의 전방 중 적어도 일부 및 우측 방향을 센싱하도록 배치될 수 있다. 제1 라이다는 차량의 전방 중 적어도 일부 및 우측 방향을 센싱하도록 배치될 수 있다. 예를 들어, 제1 전방 카메라는, 차량의 전방 센싱을 위해 제1 헤드 램프의 내부 공간 영역 중 좌측의 영역에 배치될 수 있다. 제1 측방 카 메라는, 차량의 전방 중 적어도 일부 및 우측 방향 센싱을 위해 제1 헤드 램프의 내부 공간 영역 중 우측 영역에 배치될 수 있다. 제1 라이다는, 차량의 전방 중 적어도 일부 및 우측 방향 센싱을 위해 제1 헤드 램프의 내부 공간 영역 중 우측 영역에 배치될 수 있다. 도 7a에서는, 제1 측방 카메라가 제1 라이다의 하부에 배치되었으나, 이는 예시일 뿐, 본 개시물의 다양한 실시예들은 이에 한정되지 않는다. 예를 들어, 제1 측방 카메라는 제1 라이다의 상부, 하부, 좌측, 또는 우측 중 어느 하나의 방향에 배 치될 수 있다. 일실시예에 따르면, 제1 측방 카메라와 제1 라이다는 서로 이격되어 배치될 수도 있고, 이격되지 않고 직접적으로 맞닿도록 배치될 수 있다. 적어도 하나의 제1 광원은 제1 헤드 램프(70 1)의 내부 공간 영역 중 중앙 영역에 배치될 수 있다. 이는 예시일 뿐, 본 개시물의 다양한 실시예들은 이에 한 정되지 않는다. 예를 들어, 적어도 하나의 제1 광원은, 제1 헤드 램프의 내부 공간 영역 중 제1 전방 카메라에 인접한 좌측 영역에 배치되거나, 제1 측방 카메라에 인접한 우측 영역에 배치될 수 있다.적어도 하나의 제1 광원은 복수 개일 수 있다. 예를 들어, 제1 헤드 램프는 복수의 광원들을 포함할 수 있다. 다양한 실시예들에 따르면, 제2 헤드 램프는 제2 전방 카메라, 제2 측방 카메라, 및 제2 라이다 중 적어도 하나를 포함할 수 있다. 제2 헤드 램프는 차량의 좌측 전면에 장착되는 헤드 램프일 수 있으며, 제2 전방 카메라는, 차량의 전방을 센싱하도록 배치되고, 제2 측방 카메라는, 차량의 전방 중 적어도 일부 및 좌측 방향을 센싱하도록 배치될 수 있다. 제2 라이다는 차량의 전방 중 적어도 일부 및 우측 방향을 센싱하도록 배치될 수 있다. 예를 들어, 제2 전방 카메라는, 차량의 전방 센싱을 위해 제2 헤 드 램프의 내부 공간 영역 중 우측의 영역에 배치될 수 있다. 제2 측방 카메라는, 차량의 전방 중 적 어도 일부 및 좌측 방향 센싱을 위해 제2 헤드 램프의 내부 공간 영역 중 좌측 영역에 배치될 수 있다. 제 2 라이다는, 차량의 전방 중 적어도 일부 및 좌측 방향 센싱을 위해 제2 헤드 램프의 내부 공간 영역 중 우측 영역에 배치될 수 있다. 도 7a에서는, 제2 측방 카메라가 제2 라이다의 하부에 배치되었으나, 이는 예시일 뿐, 본 개시물의 다양한 실시예들은 이에 한정되지 않는다. 예를 들어, 제2 측방 카 메라는 제2 라이다의 상부, 하부, 좌측, 또는 우측 중 어느 하나의 방향에 배치될 수 있다. 일실시예 에 따르면, 제2 측방 카메라와 제2 라이다는 서로 이격되어 배치될 수도 있고, 이격되지 않고 직접적 으로 맞닿도록 배치될 수 있다. 적어도 하나의 제2 광원은 제2 헤드 램프의 내부 공간 영역 중 중앙 영역에 배치될 수 있다. 이는 예시일 뿐, 본 개시물의 다양한 실시예들은 이에 한정되지 않는다. 예를 들어, 적 어도 하나의 제2 광원은, 제2 헤드 램프의 내부 공간 영역 중 제2 전방 카메라에 인접한 좌측 영역에 배치되거나, 제2 측방 카메라에 인접한 우측 영역에 배치될 수 있다. 적어도 하나의 제2 광원(74 3)은 복수 개일 수 있다. 예를 들어, 제2 헤드 램프는 복수의 광원들을 포함할 수 있다. 도 7b는 다양한 실시예들에 따른 헤드 램프 내 센서들의 FOV(field of view)를 도시한다. 도 7b의 차량에 장착 된 헤드 램프들은, 도 7a에 도시된 헤드 램프들(701, 703)일 수 있다. 도 7b를 참조하면, 차량은 제1 헤드 램프에 포함된 제1 전방 카메라와 제2 헤드 램프에 포함된 제2 전방 카메라를 이용하여 전방에 위치한 오브젝트를 센싱할 수 있다. 제1 전방 카메라, 및 제2 전 방 카메라 각각의 시야각(field of view)은, 예를 들어, 약 40도일 수 있다. 차량은 제1 헤드 램프에 포함된 제1 측방 카메라와 제2 헤드 램프에 포함된 제2 측방 카메라 를 이용하여 전방 및/또는 측방에 위치한 오브젝트를 센싱할 수 있다. 제1 측방 카메라, 및 제2 측방 카메라 각각의 시야각(field of view)은, 예를 들어, 약 140도일 수 있다. 차량은 제1 헤드 램프에 포함된 제1 라이다와 제2 헤드 램프에 포함된 제2 라이다를 이용 하여 전방 및/또는 측방에 위치한 오브젝트를 센싱할 수 있다. 제1 라이다, 및 제2 라이다 각각의 시 야각(field of view)은, 예를 들어, 약 120도일 수 있다. 상술한 시야각들은 예시일 뿐, 본 개시물의 다양한 실시예들은 이에 한정되지 않을 것이다. 예를 들어, 제1 헤 드 램프, 및 제2 헤드 램프에 포함된 센서들(711, 731, 721, 723, 731, 733)의 시야각은 설계자에 의해 다른 각도로 설정될 수 있다. 또한, 상술한 도 7a, 및 도 7b와 후술되는 실시예들에서는, 차량의 전면에 위치한 두 개의 헤드 램프(701, 70 3)들 각각에 하나의 라이다가 포함된 경우를 가정하여 설명하나, 본 개시물의 다양한 실시예들은 이에 한정되지 않는다. 예를 들어, 본 개시물의 다양한 실시예들은, 헤드 램프(701, 703)들 각각에 복수의 라이다들이 포함된 경우에도 동일한 방식으로 적용될 수 있으며, 차량의 후면에 위치한 헤드 램프(701, 703)들 각각에 적어도 하나 의 라이다가 포함된 경우에도 동일한 방식으로 적용될 수 있다. 상술한 도 7a 및 도 7b에 도시되지는 않았으나, 상술한 차량은, 적어도 하나의 후면 측방 카메라를 더 포함할 수 있다. 예를 들어, 차량의 후방 중 적어도 일부 및 우측 방향을 센싱하는 제1 후면 측방 카메라와 차량의 후 방 중 적어도 일부 및 좌측 방향을 센싱하는 제2 후면 측방 카메라를 더 포함할 수 있다. 제1 후면 측방 카메라 는 차량의 우측 후방 램프에 배치되고, 제2 후면 측방 카메라는 차량의 좌측 후방 램프에 배치될 수 있다. 이하에서는, 설명의 편의를 위해, 도 7a 및 도 7b에 도시된 제1 전방 카메라를 우측 전방 카메라로 지칭하 고, 제2 전방 카메라를 좌측 전방 카메라로 지칭하고, 제1 측방 카메라를 우측 측방 카메라로 지칭하 고, 제2 측방 카메라를 좌측 측방 카메라로 지칭할 수 있다. 도 8은 본 개시물의 실시예에 따른 차량의 제어 블럭도이다. 도 8을 참조하면, 차량은, 사용자 인터페이스 장치, 오브젝트 검출 장치, 통신 장치, 운전 조작 장치, 메인 ECU, 구동 제어 장치, 자율 주행 장치, 센싱부 및 위치 데이터 생성 장 치를 포함할 수 있다. 오브젝트 검출 장치, 통신 장치, 운전 조작 장치, 메인 ECU, 구동 제어 장치, 자율 주행 장치, 센싱부 및 위치 데이터 생성 장치는 각각이 전기적 신호를 생성하고, 상호간에 전기적 신호를 교환하는 전자 장치로 구현 될 수 있다. 사용자 인터페이스 장치는, 차량과 사용자와의 소통을 위한 장치이다. 사용자 인터페이스 장치는, 사 용자 입력을 수신하고, 차량에서 생성된 정보를 사용자에게 제공할 수 있다. 차량은, 사용자 인터페이스 장치 를 통해, UI(User Interface) 또는 UX(User Experience)를 구현할 수 있다. 사용자 인터페이스 장치(80 0)는, 입력 장치, 출력 장치 및 사용자 모니터링 장치를 포함할 수 있다. 오브젝트 검출 장치는, 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 오브젝트에 대한 정보는, 오 브젝트의 존재 유무에 대한 정보, 오브젝트의 위치 정보, 차량과 오브젝트와의 거리 정보, 및 차량과 오브젝트 와의 상대 속도 정보 중 적어도 어느 하나를 포함할 수 있다. 오브젝트 검출 장치는, 차량 외부의 오브젝 트를 검출할 수 있다. 오브젝트 검출 장치는, 차량 외부의 오브젝트를 검출할 수 있는 적어도 하나의 센서 를 포함할 수 있다. 오브젝트 검출 장치는, 카메라, 레이다, 라이다, 초음파 센서 및 적외선 센서 중 적어 도 하나를 포함할 수 있다. 오브젝트 검출 장치는, 센서에서 생성되는 센싱 신호에 기초하여 생성된 오브 젝트에 대한 데이터를 차량에 포함된 적어도 하나의 전자 장치에 제공할 수 있다. 카메라는 영상을 이용하여 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 카메라는 적어도 하나의 렌즈, 적어도 하나의 이미지 센서, 및 적어도 하나의 이미지 시그널 프로세서를 포함할 수 있다. 이미지 시그널 프로 세서는 이미지 센서와 전기적으로 연결되어 수신되는 신호를 처리하고, 처리되는 신호에 기초하여 오브젝트에 대한 데이터를 생성할 수 있다. 카메라는, 모노 카메라, 스테레오 카메라, AVM(Around View Monitoring) 카메라 중 적어도 어느 하나일 수 있다. 카메라는, 다양한 영상 처리 알고리즘을 이용하여, 오브젝트의 위치 정보, 오 브젝트와의 거리 정보 또는 오브젝트와의 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 획득된 영상 에서, 시간에 따른 오브젝트 크기의 변화를 기초로, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있 다. 예를 들면, 카메라는, 핀홀(pin hole) 모델, 노면 프로파일링 등을 통해, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 스테레오 카메라에서 획득된 스테레오 영상에서 디스패러티 (disparity) 정보를 기초로 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 카메라는, 차량 외부를 촬영하기 위해 차량에서 FOV(field of view) 확보가 가능한 위치에 장착될 수 있다. 카 메라는, 차량 전방의 영상을 획득하기 위해, 차량의 실내에서, 프런트 윈드 쉴드에 근접하게 배치될 수 있다. 카메라는, 프런트 범퍼 또는 라디에이터 그릴 주변에 배치될 수 있다. 카메라는, 차량 후방의 영상을 획득하기 위해, 차량의 실내에서, 리어 글라스에 근접하게 배치될 수 있다. 카메라는, 리어 범퍼, 트렁크 또는 테일 게이 트 주변에 배치될 수 있다. 카메라는, 차량 측방의 영상을 획득하기 위해, 차량의 실내에서 사이드 윈도우 중 적어도 어느 하나에 근접하게 배치될 수 있다. 또는, 카메라는, 사이드 미러, 휀더 또는 도어 주변에 배치될 수 있다. 레이다는 전파를 이용하여 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 레이다는, 전자파 송신부, 전 자파 수신부, 및 적어도 하나의 프로세서를 포함할 수 있다. 적어도 하나의 프로세서는, 전자파 송신부 및 전자 파 수신부와 전기적으로 연결되어, 수신되는 신호를 처리하고, 처리되는 신호에 기초하여 오브젝트에 대한 데이 터를 생성할 수 있다. 레이다는 전파 발사 원리상 펄스 레이다(Pulse Radar) 방식 또는 연속파 레이다 (Continuous Wave Radar) 방식으로 구현될 수 있다. 레이다는 연속파 레이다 방식 중에서 신호 파형에 따라 FMCW(Frequency Modulated Continuous Wave)방식 또는 FSK(Frequency Shift Keying) 방식으로 구현될 수 있다. 레이다는 전자파를 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브 젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 레이다 는, 차량의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 라이다는, 레이저 광을 이용하여, 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 라이다는, 광 송신부, 광 수신부 및 적어도 하나의 프로세서를 포함할 수 있다. 광 송신부 및 광 수신부와 전기적으로 연결되어, 수신 되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성할 수 있다. 라이다는, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식으로 구현될 수 있다. 라이다는, 구동식 또는 비구동식 으로 구현될 수 있다. 구동식으로 구현되는 경우, 라이다는, 모터에 의해 회전되며, 차량 주변의 오브젝트를 검 출할 수 있다. 비구동식으로 구현되는 경우, 라이다는, 광 스티어링에 의해, 차량을 기준으로 소정 범위 내에 위치하는 오브젝트를 검출할 수 있다. 차량은 복수의 비구동식 라이다를 포함할 수 있다. 라이다는, 레이 저 광 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출 하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 라이다는, 차량의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 통신 장치는, 차량 외부에 위치하는 디바이스와 신호를 교환할 수 있다. 통신 장치는, 인프라(예를 들면, 서버, 방송국), 타 차량, 단말기 중 적어도 어느 하나와 신호를 교환할 수 있다. 통신 장치는, 통신 을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 예를 들어, 통신 장치는 V2X 기술을 기반으로 외부 디바이스와 신호를 교환할 수 있다. 예를 들어, V2X 기술은 LTE 기반의 사이드링크 통신 및/또는 NR 기반의 사이드링크 통신을 포함할 수 있다. 또한 통신 장치는 5G 네트 워크를 기반으로 타 차량, 모바일 기기, 도로 등의 사물과 정보를 교환할 수 있다. V2X와 관련된 내용은 후술한 다. 예를 들어, 통신 장치는 IEEE 80211p PHY/MAC 계층 기술과 IEEE 1609 Network/Transport 계층 기술 기반의 DSRC(Dedicated Short Range Communications) 기술 또는 WAVE(Wireless Access in Vehicular Environment), SAEJ2735, SAE J2945 표준을 기반으로 외부 디바이스와 신호를 교환할 수 있다. DSRC(또는 WAVE 표준) 기술은 차량 탑재 장치 간 혹은 노변 장치와 차량 탑재 장치 간의 단거리 전용 통신을 통해 ITS(Intelligent Transport System) 서비스를 제공하기 위해 마련된 통신 규격이다. DSRC 기술은 59GHz 대역의 주파수를 사용할 수 있고, 3Mbps~27Mbps의 데이터 전송 속도를 가지는 통신 방식일 수 있다. IEEE 80211p 기술은 IEEE 1609 기술과 결합 되어 DSRC 기술 (혹은 WAVE 표준)을 지원할 수 있다. 본 개시물의 통신 장치는 V2X 기술 또는 DSRC 기술 중 어느 하나만을 이용하여 외부 디바이스와 신호를 교환할 수 있다. 또는, 본 개시물의 통신 장치는 V2X 기술 및 DSRC 기술을 하이브리드하여 외부 디바이스와 신호를 교 환할 수 있다. V2X 표준은 전기 전자 분야 표 준화 기관인 IEEE(IEEE 80211p, IEEE 1609)와 자동차 엔지니어 모임인 SAE(SAE J2735, SAE J2945 등) 등을 통해 만들어졌으며, 각각 물리 계층, SW 스텍 표준화와 응용계층 표 준화를 각각 담당한다. 특히, 메시지 표준과 관련하여, SAE에서는 V2X 통신을 위한 메시지 규격을 정의하기 위 한 표준들을 제정하였다. 운전 조작 장치는, 운전을 위한 사용자 입력을 수신하는 장치이다. 메뉴얼 모드인 경우, 차량은, 운전 조 작 장치에 의해 제공되는 신호에 기초하여 운행될 수 있다. 운전 조작 장치는, 조향 입력 장치(예를 들면, 스티어링 휠), 가속 입력 장치(예를 들면, 가속 페달) 및 브레이크 입력 장치(예를 들면, 브레이크 페 달)를 포함할 수 있다. 메인 ECU는, 차량 내에 구비되는 적어도 하나의 전자 장치의 전반적인 동작을 제어할 수 있다. 구동 제어 장치는, 차량내 각종 차량 구동 장치를 전기적으로 제어하는 장치이다. 구동 제어 장치는, 파워 트레인 구동 제어 장치, 샤시 구동 제어 장치, 도어/윈도우 구동 제어 장치, 안전 장치 구동 제어 장치, 램프 구동 제어 장치 및 공조 구동 제어 장치를 포함할 수 있다. 파워 트레인 구동 제어 장치는, 동력원 구동 제어 장치 및 변속기 구동 제어 장치를 포함할 수 있다. 샤시 구동 제어 장치는, 조향 구동 제어 장치, 브레이 크 구동 제어 장치 및 서스펜션 구동 제어 장치를 포함할 수 있다. 한편, 안전 장치 구동 제어 장치는, 안전 벨 트 제어를 위한 안전 벨트 구동 제어 장치를 포함할 수 있다. 구동 제어 장치는, 적어도 하나의 전자적 제어 장치(예를 들면, 제어 ECU(Electronic Control Unit))를 포함한다. 구동 제어 장치는, 자율 주행 장치에서 수신되는 신호에 기초하여, 차량 구동 장치를 제어할 수 있다. 예를 들면, 구동 제어 장치는, 자율 주행 장치에서 수신되는 신호에 기초하여, 파워 트레인, 조향 장치 및 브레이크 장치를 제어할 수 있다. 자율 주행 장치는, 획득된 데이터에 기초하여, 자율 주행을 위한 패스를 생성할 수 있다. 자율 주행 장치 는, 생성된 경로를 따라 주행하기 위한 드라이빙 플랜을 생성할 수 있다. 자율 주행 장치는, 드라이 빙 플랜에 따른 차량의 움직임을 제어하기 위한 신호를 생성할 수 있다. 자율 주행 장치는, 생성된 신호를 구동 제어 장치에 제공할 수 있다. 자율 주행 장치는, 적어도 하나의 ADAS(Advanced Drive Assistance System) 기능을 구현할 수 있다. ADAS 는, 적응형 크루즈 컨트롤 시스템(ACC: Adaptive Cruise Control), 자동 비상 제동 시스템(AEB: Autonomous Emergency Braking), 전방 충돌 알림 시스템(FCW: Forward Collision Warning), 차선 유지 보조 시스템(LKA: Lane Keeping Assist), 차선 변경 보조 시스템(LCA: Lane Change Assist), 타겟 추종 보조 시스템(TFA: Target Following Assist), 사각 지대 감시 시스템(BSD: Blind Spot Detection), 적응형 헤드라이트 시스템(AHS: Adaptive Headlight System), 자동 주차 시스템(APS: Auto Parking System), 보행자 충돌 알림 시스템(PD collision warning system), 교통 신호 검출 시스템(TSR: Traffic Sign Recognition), 교통 신호 보조 시스템 (TSA: Traffic Sign Assist), 나이트 비전 시스템(NV: Night Vision), 운전자 상태 모니터링 시스템(DSM: Driver Status Monitoring) 및 교통 정체 지원 시스템(TJA: Traffic Jam Assist) 중 적어도 어느 하나를 구현 할 수 있다. 자율 주행 장치는, 자율 주행 모드에서 수동 주행 모드로의 전환 동작 또는 수동 주행 모드에서 자율 주행 모드로의 전환 동작을 수행할 수 있다. 예를 들면, 자율 주행 장치는, 사용자 인터페이스 장치로부터 수신되는 신호에 기초하여, 차량의 모드를 자율 주행 모드에서 수동 주행 모드로 전환하거나 수동 주행 모드에 서 자율 주행 모드로 전환할 수 있다. 센싱부는, 차량의 상태를 센싱할 수 있다. 센싱부는, IMU(inertial measurement unit) 센서, 충돌 센서, 휠 센서(wheel sensor), 속도 센서, 경사 센서, 중량 감지 센서, 방향 센서(heading sensor), 포지션 모 듈(position module), 차량 전진/후진 센서, 배터리 센서, 연료 센서, 타이어 센서, 스티어링 센서, 온도 센서, 습도 센서, 초음파 센서, 조도 센서, 페달 포지션 센서 중 적어도 어느 하나를 포함할 수 있다. 한편, IMU(inertial measurement unit) 센서는, 가속도 센서, 자이로 센서, 자기 센서 중 하나 이상을 포함할 수 있 다. 센싱부는, 적어도 하나의 센서에서 생성되는 신호에 기초하여, 차량의 상태 데이터를 생성할 수 있다. 차 량 상태 데이터는, 차량 내부에 구비된 각종 센서에서 감지된 데이터를 기초로 생성된 정보일 수 있다. 센싱부 는, 차량 자세 데이터, 차량 모션 데이터, 차량 요(yaw) 데이터, 차량 롤(roll) 데이터, 차량 피치(pitch) 데이터, 차량 충돌 데이터, 차량 방향 데이터, 차량 각도 데이터, 차량 속도 데이터, 차량 가속도 데이터, 차량 기울기 데이터, 차량 전진/후진 데이터, 차량의 중량 데이터, 배터리 데이터, 연료 데이터, 타이어 공기압 데이 터, 차량 내부 온도 데이터, 차량 내부 습도 데이터, 스티어링 휠 회전 각도 데이터, 차량 외부 조도 데이터, 가속 페달에 가해지는 압력 데이터, 브레이크 페달에 가해지는 압력 데이터 등을 생성할 수 있다. 위치 데이터 생성 장치는, 차량의 위치 데이터를 생성할 수 있다. 위치 데이터 생성 장치는, GPS(Global Positioning System) 및 DGPS(Differential Global Positioning System) 중 적어도 어느 하나를 포 함할 수 있다. 위치 데이터 생성 장치는, GPS 및 DGPS 중 적어도 어느 하나에서 생성되는 신호에 기초하여 차량의 위치 데이터를 생성할 수 있다. 실시예에 따라, 위치 데이터 생성 장치는, 센싱부의 IMU(Inertial Measurement Unit) 및 오브젝트 검출 장치의 카메라 중 적어도 어느 하나에 기초하여 위치 데이터를 보정할 수 있다. 위치 데이터 생성 장치는, GNSS(Global Navigation Satellite System)로 명명 될 수 있다. 차량은, 내부 통신 시스템을 포함할 수 있다. 차량에 포함되는 복수의 전자 장치는 내부 통신 시스템(85 5)을 매개로 신호를 교환할 수 있다. 신호에는 데이터가 포함될 수 있다. 내부 통신 시스템은, 적어도 하 나의 통신 프로토콜(예를 들면, CAN, LIN, FlexRay, MOST, 이더넷)을 이용할 수 있다. 도 9는 다양한 실시예들에 따른 차량에 포함되는 전자 장치의 블럭도이다. 도 9의 전자 장치는, 상술한 도 7a, 도 7b, 및 도 8의 차량에 포함되는 전자 장치의 적어도 일부일 수 있다. 도 9에 도시된 전자 장치의 구성 은 일 실시 예로, 각각의 구성 요소는 하나의 칩, 부품 또는 전자 회로로 구성되거나, 칩, 부품 또는 전자 회로 의 결합으로 구성될 수 있다. 다른 실시 예에 따라, 도 9에 도시된 구성 요소들 중 일부는 복수 개의 구성 요소 로 분리되어 서로 다른 칩 또는 부품 또는 전자 회로로 구성될 수 있으며, 일부 구성 요소들은 결합되어 하나의 칩, 부품 또는 전자 회로로 구성될 수도 있다. 다른 실시 예에 따라, 도 9에 도시된 구성요소들 중 일부가 생략되거나, 도 9에 도시되지 않은 다른 구성 요소가 추가될 수 있다. 일실시예에 따르면, 도 9에 도시된 구성요소 들 중 일부 구성 요소는, 전자 장치에 포함되지 않고 차량에 포함됨으로써, 전자 장치에 포함된 적어 도 하나의 다른 구성 요소와 전기적으로 연결될 수 있다. 일실시예에 따르면, 도 9에 도시된 구성 요소들 중 적 어도 일부 구성 요소는, 도 8의 차량에 포함되는 장치일 수 있다. 도 9를 참조하면, 다양한 실시예들에 따른 전자 장치는 프로세서, 카메라 모듈, 라이다 모듈 , 통신 트랜시버, 및 메모리을 포함할 수 있다. 프로세서는 차량의 자율 주행에 필요한 전반적인 제어 동작을 수행할 수 있다. 프로세서는 도 8의 자 율 주행 장치를 포함할 수 있다. 다양한 실시예들에 따르면, 프로세서는 맵 데이터, 또는 차량의 주행 경로 정보 중 적어도 하나에 기초하 여, 카메라를 이용하여 모니터링할 탐지 영역을 결정할 수 있다. 탐지 영역은, 차량이 다른 차량(이하 '타차 량'이라 칭함)과 충돌할 가능성이 있는 영역을 포함할 수 있다. 예를 들어, 탐지 영역은, 차량의 자율 주행 경 로 내에 교차로와 같이, 차량과 타차량의 주행 경로가 중첩될 수 있는 영역을 포함할 수 있다. 일실시예에 따르 면, 프로세서는 메모리의 고정밀 맵(high definition MAP)데이터에서 현재 위치에 관련된 도로 정보 를 획득하고, 획득된 도로 정보와 주행 경로 정보를 기반으로 탐지 영역을 결정할 수 있다. 도로 정보는, 도로 의 종류, 형태, 길이, 폭, 차선 수, 또는 위치 정보 중 적어도 하나를 포함할 수 있다. 일실시예에 따르면, 프 로세서는 카메라 모듈에 포함된 적어도 하나의 카메라(예: 좌측 측방 카메라) 통해 차선의 두께, 기울어진 각도를 이용하여 차선의 전개 방향을 예측하고, 예측된 차선의 전개 방향을 더 고려하여 탐지 영역을 결정할 수 있다. 다양한 실시예들에 따르면, 프로세서는 결정된 탐지 영역에 기초하여 적어도 하나의 카메라를 구동할 수 있다. 예를 들어, 프로세서는 우측 전방 카메라, 좌측 전방 카메라, 우측 측방 카메라, 및 좌측 측방 카메라 중에서 탐지 영역 중 적어도 일부 영역을 커버하는 시야각을 갖는 적어도 하나의 카메라 를 구동할 수 있다. 일실시예에 따르면, 프로세서는 탐지 영역의 적어도 일부 영역을 커버하는 시야각을 갖는 카메라가 복수 개인 경우, 복수 개의 카메라들 중 적어도 일부만 구동하거나, 복수개의 카메라들을 동시에 구동하거나, 복수개의 카메라들을 순차적으로 구동할 수 있다. 예를 들어, 프로세서는 차량과 탐지 영역 사이의 거리, 복수 개의 카메라 각각이 커버하는 영역, 또는 타차량의 예상 이동 궤적 중 적어도 하나에 기초하 여, 복수 개의 카메라들 중에서 적어도 하나의 카메라들을 순차적으로 구동할 수 있다. 예컨대, 프로세서 는 차량과 탐지 영역 사이의 거리가 지정된 임계 거리보다 클 경우, 탐지 영역의 좌측 가장자리 영역을 포함하 는 일부 영역을 커버하는 좌측 측방 카메라를 먼저 구동하여 모니터링 영역 내의 타 차량을 탐지할 수 있 다. 프로세서는 차량과 모니터링 영역 사이의 거리가 지정된 임계 거리보다 작거나 같을 경우, 탐지 영역 의 좌측 가장자리 영역을 커버하는 시야각을 갖는 좌측 측방 카메라와 탐지 영역의 중앙 영역을 커버하는 시야각을 갖는 좌측 전방 카메라를 동시에 구동하여 모니터링 영역 내의 타 차량을 탐지한 후, 탐지 결과 에 기초하여 획득되는 타차량의 이동 궤적에 따라 우측 전방 카메라를 구동할 수 있다. 우측 전방 카메라 는 탐지 영역의 우측 가장자리 영역을 커버하는 시야각을 가질 수 있다. 이는 이해를 돕기위한 예시일 뿐, 복수의 카메라들의 구동 시점, 및/또는 순서는 이에 한정되지 않을 것이다. 다양한 실시예들에 따르면, 프로세서는 구동 중인 적어도 하나의 카메라의 시야각에 대응되는 전체 탐지 영역 중에서, 모니터링이 가능한 영역이 축소되는지 여부를 결정할 수 있다. 예를 들어, 프로세서는 구동 중인 적어도 하나의 카메라의 시야각 중 일부가 인접한 차량(예: 인접 차선(또는 옆 차선)의 차량, 반대 차선의 차량, 및/또는 동일 차선의 전방 차량)에 의해 가려짐으로써, 탐지 영역 중 모니터링이 가능한 영역이 축소되는 지 여부를 결정할 수 있다. 프로세서는 모니터링이 가능한 영역이 축소되는 경우, 구동 중인 적어도 하나 의 카메라에 포함된 CCD(Charge-Coupled Device)의 샘플링 레이트를 변경할 수 있다. 예를 들어, 프로세서(91 0)는 모니터링 가능 영역이 축소되는 속도, 또는 카메라의 시야각이 가려지는 속도에 기초하여, 구동 중인 적어 도 하나의 카메라에 포함된 CCD의 샘플링 레이트가 변경되도록, 적어도 하나의 카메라를 제어할 수 있다. 다양한 실시예들에 따르면, 프로세서는 미리 설정된(또는 지정된) 또는 변경된 샘플링 레이트에 기초하여 동작하는 카메라를 통해 탐지 영역을 촬영한 이미지들을 획득하고, 획득된 이미지들로부터 모니터링 영역 내 타 차량에 대한 주행 정보를 획득할 수 있다. 모니터링 영역 내 타차량에 대한 주행 정보는, 예를 들어, 타차량의 이동 속도, 이동 방향, 또는 시간에 따른 예상 이동 궤적 중 적어도 하나를 포함할 수 있다. 이동 속도는, 타차 량의 바퀴의 반경, 바퀴의 초당 회전 횟수, 바퀴의 각도, 또는 바퀴의 크기 중 적어도 하나를 기반으로 획득될 수 있다. 시간에 따른 예상 이동 궤적은, 이동 속도 및 이동 방향에 기초하여 결정될 수 있다. 다양한 실시예들에 따르면, 프로세서는 타차량에 대한 주행 정보를 기반으로, 전자 장치가 장착된 자 기 차량(이하 '자차'라 칭함)의 주행 동작을 수행할 수 있다. 예를 들어, 프로세서는 타차량에 대한 주행 정보와 자차의 주행 정보에 기초하여 자차의 주행 동작을 수행할 수 있다. 자차의 주행 정보는, 자차의 주행 경 로, 주행 속도, 자차의 위치, 또는 자차와 앞차 사이의 거리 중 적어도 하나를 포함할 수 있다. 프로세서 는 타차량에 대한 주행 정보와 자차의 주행 정보에 기초하여 충돌 예상 위치를 결정하고, 충돌 예상 위치까지의 타차량의 이동 시간(T1)과 자차의 이동 시간(T2)를 계산할 수 있다. 프로세서는 충돌 예상 위치까지의 타 차량의 이동 시간과 자차의 이동 시간을 비교하여, 자차의 주행 속도를 제어할 수 있다. 다양한 실시예들에 따르면, 프로세서는 타차량의 시간에 따른 예상 이동 궤적에 대한 검증을 수행하고, 대 체 센서를 구동할지 여부를 결정할 수 있다. 프로세서는 타차량의 시간에 따른 예상 이동 궤적과 타차량의 실제 이동 궤적이 일치하는 경우, 대체 센서를 구동할 필요가 없음을 결정하고, 타차량의 시간에 따른 예상 이 동 궤적에 기초하여 타차량의 후속 차량에 대하 시간에 따른 이동 궤적을 추정할 수 있다. 후속 차량의 시간에 대한 이동 궤적은, 타차량의 시간에 따른 예상 이동 궤적에 안전 거리를 적용하여 결정될 수 있다. 프로세서 는 타차량의 시간에 따른 예상 이동 궤적과 타차량의 실제 이동 궤적이 일치하지 않는 경우, 대체 센서를 구동할 수 있다. 대체 센서는, 구동되지 않은 적어도 하나의 다른 카메라, 또는 라이다 중 적어도 하나를 포함 할 수 있다. 대체 센서는, 탐지 영역 중 적어도 일부를 센싱(또는 모니터링)할 수 있는 센서로 선택될 수 있다. 일실시예에 따르면, 대체 센서가 좌측 전방 카메라인 경우, 프로세서는 탐지 영역에 대한 좌측 전방 카메라의 모니터링 가능 영역 변화에 기초하여, 좌측 전방 카메라의 샘플링 레이트를 변경할 수 있다. 다양한 실시예들에 따르면, 프로세서는 탐지 영역에 대한 모니터링 가능 영역(또는 촬영 가능 영역)을 확 보하기 위해, 자차의 속도 및/또는 위치를 변경할 수 있다. 예를 들어, 프로세서는 인접한 차량들, 및/또 는 전방의 차량으로 인해 탐지 영역을 모니터링할 수 없는 경우, 자차의 속도를 늦추거나, 동일 차선 내에서 자 차의 위치를 변경하거나, 차선을 변경할 수 있다. 이때, 프로세서는 구동 중인 적어도 하나의 카메라의 장 착 위치를 고려할 수 있다. 다양한 실시예들에 따르면, 프로세서는 탐지 영역에 기초하여 복수의 카메라들 중 적어도 하나의 카메라가 구동되도록 제어하고, 구동된 적어도 하나의 카메라의 시야각 차단 여부에 따라 적어도 하나의 다른 카메라가 추가적으로 구동되도록 제어할 수 있다. 예를 들어, 프로세서는 탐지 영역 중 적어도 일부 영역을 커버하 는 시야각을 갖는 좌측 측방 카메라를 구동하여 탐지 영역에 대한 모니터링을 수행하고, 좌측 측방 카메라 의 시야각 중 적어도 일부 시야각이 인접 차량에 의해 차단되는 경우, 좌측 전방 카메라를 구동할 수 있다. 일실시예에 따르면, 카메라의 구동은, 활성화된 상태의 카메라에서 이미지 샘플링 동작을 시작하는 것을 의미할 수 있다. 일실시예에 따르면, 카메라의 구동은, 비활성 상태에 있는 카메라를 활성화시킨 후, 활성화된 상태의 카메라에서 이미지 샘플링 동작을 시작하는 것을 의미할 수 있다. 다양한 실시예들에 따르면, 프로세서는 복수의 카메라들의 시야각들이 중첩되는 경우, 중첩된 시야각을 갖 는 복수의 카메라들 중 적어도 하나의 카메라가 샘플링 동작을 수행하도록 제어하고, 중첩된 시야각을 갖는 복 수의 카메라들 중 적어도 하나의 다른 카메라의 샘플링 동작이 적어도 일시적으로 중단되도록 제어할 수 있다. 프로세서는 타차량의 위치, 및/또는 타차량의 예상 이동 궤적에 기초하여, 중첩된 시야각을 갖는 복수의 카메라들 중에서 샘플링이 중단될 카메라를 결정할 수 있다. 중첩된 시야각을 갖는 복수의 카메라들 중에서 적 어도 하나의 카메라의 샘플링 동작이 적어도 일시적으로 중단되도록 제어함으로써, 불필요한 샘플링 동작에 의 해 전력이 소모되는 것을 방지할 수 있다. 다양한 실시예들에 따르면, 프로세서는 복수의 카메라들에 유입되는 광량에 기초하여 음영 지역을 확인하 고, 적어도 하나의 광원(예: 제1 광원, 제2 광원을 제어하여 확인된 음영 지역으로 광선을 조사할 수 있다. 일실시예에 따르면, 프로세서는 야간 주행 시, 탐지 영역에 위치한 타차량으로 광선이 조사되도록 적어도 하나의 광원을 제어할 수 있다. 프로세서는 적어도 하나의 광원으로부터 조사되는 광선이 인접 차 량(예: 반대 차선의 차량)의 카메라에 유입되지 않는 범위 내에서 타차량에 도달할 수 있도록, 광선의 조사 주 기, 방향, 또는 세기 중 적어도 하나를 조절할 수 있다. 일실시예에 따르면, 프로세서는 복수의 카메라들 을 이용하여 도로상에 위치한 고정된 크기 및/또는 고정된 형태의 오브젝트(예: 가드레일, 표지판)을 촬영하여, 복수의 카메라들 각각에 대한 오브젝트 탐지 정확도를 결정할 수 있다. 일실시예에 따르면, 프로세서는 복 수의 카메라들 각각에 대한 오브젝트 탐지 정확도를 기반으로, 탐지 영역 중 적어도 일부 영역을 모니터링할 적 어도 하나의 카메라 센서를 결정할 수 있다. 다양한 실시예들에 따르면, 프로세서는 야간 주행 시, 탐지 영역 중 적어도 하나의 카메라를 통해 모 니터링이 가능한 영역을 확인하고, 라이다 모듈에 포함된 적어도 하나의 라이다(예: 도 7a 및/또는 도 7b 의 제2 라이다)를 이용하여 모니터링이 가능한 영역으로 레이저 빔을 방출함으로써, 타차량을 검출할 수 있다. 모니터링이 가능한 영역은, 인접한 차량, 또는 보행자에 의해 가려지지 않은 영역일 수 있다. 프로세서 는 모니터링이 가능한 영역의 크기에 따라, 라이다 모듈에 포함된 적어도 하나의 라이다(예: 도 7a 및/또는 도 7b의 제2 라이다)의 레이저 빔 방출 범위를 제어할 수 있다. 예를 들어, 프로세서는 제2 라이다의 레이저 빔이 방출되는 포인트 클라우드(point cloud)의 가로 길이를 모니터링이 가능한 영역의 가로 크기에 대응되도록 조절할 수 있다. 일실시예에 따르면, 프로세서는 야간 주행 시, 모든 포인트 클라 우드로 레이저 빔을 방출하여, 모니터링이 가능한 영역의 가로 크기를 확인하고, 확인된 가로 크기를 기반으로 포인트 클라우드의 가로 길이를 조절하여 타차량을 검출할 수 있다. 카메라 모듈는 프로세서의 제어에 따라 적어도 하나의 이미지를 획득하고, 획득된 이미지를 이용하여 오브젝트를 검출할 수 있다. 일실시예에 따르면, 카메라 모듈은, 도 7a 및/또는 도 7b에 도시된 바와 같은, 좌측 측방 카메라, 좌측 전방 카메라, 우측 측방 카메라, 또는 우측 전방 카메라 중 적어도 하나를 포함할 수 있다. 일실시예에 따르면, 카메라 모듈는, 적어도 하나의 후면 측방 카메라를 더 포함할 수 있다. 다양한 실시예들에 따르면, 카메라 모듈에 포함된 적어도 하나의 카메라는 프로세서의 제어에 따라, 탐지 영역 중 적어도 일부 영역에 대한 이미지를 획득하고, 획득된 이미지를 분석하여 오브젝트(예: 타차량, 또 는 보행자)에 대한 데이터를 생성할 수 있다. 카메라 모듈은 예를 들어, 이미지 시그널 프로세서를 통해 이미지를 분석하여 타차량의 바퀴의 반경, 바퀴의 초당 회전 횟수, 바퀴의 각도, 바퀴의 크기 중 적어도 하나를 나타내는 데이터를 생성할 수 있다. 일실시예에 따르면, 이미지 시그널 프로세서는 프로세서의 적어도 일 부로 구성되거나, 프로세서와 구분되는 별도의 프로세서로 구성될 수 있다. 라이다는 프로세서의 제어에 따라 레이저 빔을 방출하여 오브젝트를 검출할 수 있다. 일실시예에 따 르면, 라이다 모듈은, 도 7a 및/또는 도 7b에 도시된 바와 같은, 제1 라이다, 또는 제2 라이다 중 적어도 하나를 포함할 수 있다. 일실시예에 따르면, 라이다는 차량의 야간 주행 시, 프로세서에 의해 요청된 방향으로 레이저 빔을 방출하고, 오브젝트에 의해 반사되어 수신되는 레이저 빔을 기반으로, 오브 젝트에 대한 데이터를 생성할 수 있다. 통신 트랜시버는 프로세서의 제어에 따라 외부 장치(예: 다른 전자 장치, 및/또는 서버)와 통신할 수 있다. 일실시예에 따르면, 통신 트랜시버는 도 8의 통신 장치, 또는 위치 데이터 생성 장치 중 적어도 일부를 포함할 수 있다. 통신 트랜시버는 트랜시버는 서버(미도시)와 통신하여 고정밀 맵 데이 터를 획득하고, 차량의 현재 위치 정보를 획득할 수 있다. 메모리는, 프로세서의 동작에 필요한 각종 데이터, 및/또는 프로그램을 저장할 수 있다. 일실시예에 따르면, 메모리는 고정밀 맵 데이터를 저장할 수 있다. 일실시예에 따르면, 메모리는 차량의 바퀴 크 기에 다른 차량의 종류에 대한 정보를 저장할 수 있다. 도 10은 다양한 실시예들에 따른 차량에서 카메라의 샘플링 레이트를 조절하여 타차량을 탐지하는 흐름도이다. 이하 실시예에서 각 동작들은 순차적으로 수행될 수도 있으나, 반드시 순차적으로 수행되는 것은 아니다. 예를 들어, 각 동작들의 순서가 변경될 수도 있으며, 적어도 두 동작들이 병렬적으로 수행될 수도 있다. 여기에서, 차량은 도 9의 전자 장치를 포함할 수 있다. 도 10을 참조하면, 동작 1001에서, 차량은 모니터링을 위한 탐지 영역을 결정할 수 있다. 일실시예들에 따르면, 차량의 전자 장치에 포함되는 프로세서는 맵 데이터, 또는 차량의 주행 경로 정보 중 적어도 하나에 기초하여, 적어도 하나의 카메라로 모니터링할 탐지 영역을 결정할 수 있다. 프로세서는 메모리의 고 정밀 맵(high definition MAP) 데이터에서 차량의 현재 위치에 관련된 도로 정보를 획득할 수 있다. 도로 정보 는, 도로의 종류, 형태, 길이, 폭, 차선 수, 또는 위치 정보 중 적어도 하나를 포함할 수 있다. 프로세서 는 획득된 도로 정보와 차량의 주행 경로 정보를 기반으로, 적어도 하나의 카메라를 이용하여 모니터링을 수행 할 탐지 영역을 결정할 수 있다. 일실시예에 따르면, 프로세서는 적어도 하나의 카메라 통해 차선의 전개 방향을 예측하고, 예측된 차선의 전개 방향을 더 고려하여 탐지 영역을 결정할 수 있다. 동작 1003에서, 차량은 전체 탐지 영역 중 모니터링이 가능한 영역이 감소되는지 여부를 결정할 수 있다. 일실 시예들에 따르면, 차량의 전자 장치에 포함되는 프로세서, 및/또는 카메라 모듈은 적어도 하나 의 카메라를 통해 탐지 영역에 대한 모니터링을 수행하는 중에 다른 오브젝트에 의해 전체 탐지 영역 중 모니터 링이 가능한 영역이 감소되는지 여부를 결정할 수 있다. 다른 오브젝트는, 예를 들어, 탐지 영역에 위치하지 않 은 인접 차량(예: 인접 차선의 차량, 동일 차선의 전방 차량, 또는 반대 차선의 차량), 보행자, 건물, 또는 가 로수 중 적어도 하나를 포함할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은 좌측 측방 카 메라를 이용하여 탐지 영역 중 적어도 일부 영역을 모니터링하는 중에, 인접 차량에 의해 좌측 측방 카메라의 시야각 중 탐지 영역에 대응되는 적어도 일부 시야각이 차단되는지(또는 가려지는지) 여부를 결정할 수 있다. 다른 예로, 예를 들어, 프로세서, 및/또는 카메라 모듈은 좌측 측방 카메라를 이용하여 탐지 영역 중 적어도 일부 영역을 모니터링하는 중에, 동일한 방향으로 주행 주인 인접 차량에 의해 좌측 측방 카메라, 및/또 는 좌측 전방 카메라의 시야각 중 탐지 영역에 대응되는 적어도 일부 시야각이 차단될 것으로 예상되는지 여부 를 결정할 수 있다. 차량은 모니터링이 가능한 영역이 감소되는 경우, 차량은 동작 1005에서 적어도 하나의 카메라의 샘플링 레이트 를 변경할 수 있다. 일실시예에 따르면, 차량의 전자 장치에 포함되는 프로세서, 및/또는 카메라 모 듈은 탐지 영역에 대한 모니터링을 수행하는 중인 적어도 하나의 카메라의 샘플링 레이트를 변경할 수 있 다. 프로세서, 및/또는 카메라 모듈은 모니터링이 가능한 영역이 감소된 크기, 또는 감소되는 속도 중 적어도 하나에 기초하여 적어도 하나의 카메라의 샘플링 레이트를 변경할 수 있다. 예를 들어, 프로세서 , 및/또는 카메라 모듈은 모니터링이 가능한 영역의 크기가 작아질 수록, 하나의 카메라가 더 빠른 속도로 샘플링을 수행하도록 샘플링 레이트를 더 큰 값으로 변경할 수 있다. 다른 예로, 프로세서, 및/또 는 카메라 모듈은 모니터링이 가능한 영역의 크기가 감소되는 속도가 빠를 수록, 하나의 카메라가 더 빠른 속도로 샘플링을 수행하도록 샘플링 레이트를 더 큰 값으로 변경할 수 있다. 본 개시물의 다양한 실시예들에 따 르면, 차량에서 모니터링이 가능한 영역이 감소되는 경우에 적어도 하나의 카메라의 샘플링 레이트를 변경함으 로써, 타차량에 대한 탐지 정확도를 향상시킬 수 있다. 동작 1007에서, 차량은 샘플링 레이트가 변경된 적어도 하나의 카메라를 이용하여 타차량에 대한 주행 정보를 획득할 수 있다. 일실시예에 따르면, 차량의 전자 장치에 포함되는 프로세서, 및/또는 카메라 모듈 은 샘플링 레이트가 변경된 적어도 하나의 카메라를 이용하여 타차량에 대한 적어도 하나의 이미지를 획득 하고, 획득된 적어도 하나의 이미지를 분석하여 타차량에 대한 주행 정보를 획득할 수 있다. 타차량은, 탐지 영 역에 위치한, 또는 탐지 영역을 주행 중인 다른 차량을 포함할 수 있다. 타차량에 대한 주행 정보는, 타차량의 이동 속도, 이동 방향, 또는 시간에 따른 예상 이동 궤적 중 적어도 하나를 포함할 수 있다. 예를 들어, 프로세 서, 및/또는 카메라 모듈은 적어도 하나의 카메라를 통해 획득된 적어도 하나의 이미지를 분석하여, 타차량의 바퀴의 반경, 바퀴의 초당 회전 횟수, 바퀴의 각도, 또는 바퀴의 크기 중 적어도 하나를 나타내는 정 보를 획득하고, 획득된 정보를 기반으로 타차량의 이동 속도, 및 이동 방향을 결정할 수 있다. 프로세서, 및/또는 카메라 모듈은 타차량의 이동 속도, 및 이동 방향에 기초하여, 타차량의 시간에 따른 이동 궤적을 결정할 수 있다. 차량은 모니터링이 가능한 영역이 감소되지 않는 경우, 차량은 동작 1011에서 지정된 샘플링 레이트에 기초하여 타차량에 대한 주행 정보를 획득할 수 있다. 일실시예에 따르면, 차량의 전자 장치에 포함되는 프로세서 , 및/또는 카메라 모듈은 탐지 영역에 대한 모니터링을 수행하는 중인 적어도 하나의 카메라의 샘플 링 레이트를 미리 지정된 샘플링 레이트로 유지하고, 샘플링 레이트가 유지된 적어도 하나의 카메라를 이용하여 타차량에 대한 주행 정보를 획득할 수 있다. 미리 지정된 샘플링 레이트는 사업자 및/또는 설계자에 의해 설정 및/또는 변경될 수 있다. 타차량에 대한 주행 정보를 획득하는 동작은, 동작 1007의 타차량의 주행 정보를 획득 하는 동작과 적어도 일부가 동일할 수 있다. 동작 1009에서, 차량은 타차량에 대한 주행 정보를 기반으로 자차의 주행 동작을 수행할 수 있다. 일실시예에 따르면, 차량의 전자 장치에 포함되는 프로세서는 타차량에 대한 주행 정보와 자차의 주행 정보를 기 반으로, 저자 장치가 장착된 자차의 속도, 및/또는 위치를 제어할 수 있다. 자차의 주행 정보는, 예를 들 어, 자차의 주행 경로, 주행 속도, 자차의 위치, 또는 자차와 앞차 사이의 거리 중 적어도 하나를 포함할 수 있 다. 프로세서는 타차량에 대한 주행 정보와 자차의 주행 정보에 기초하여, 타차량과 자차의 충돌 예상 위 치를 결정하고, 충돌 예상 위치까지의 타차량의 이동 시간(T1)과 자차의 이동 시간(T2)를 계산할 수 있다. 프로 세서는 충돌 예상 위치까지의 타차량의 이동 시간과 자차의 이동 시간을 비교하여, 자차의 주행 속도를 제 어하거나, 자차의 주행 차선을 변경할 수 있다.상술한 도 10에서는, 차량이 적어도 하나의 카메라를 이용하여 탐지 영역 중 모니터링이 가능한 영역이 축소되 는 것을 감지하고, 모니터링이 가능한 영역이 축소되는 경우, 타차량에 대한 탐지 정확도를 향상시키기 위해 적 어도 하나의 카메라의 샘플링 레이트를 제어하는 방법에 대해 설명하였다. 그러나, 모니터링이 가능한 영역이 축소되는 경우, 타차량에 대한 탐지 정확도를 향상시키기 위한 다른 방법이 수행될 수도 있다. 예를 들어, 차량 은 모니터링이 가능한 영역의 축소가 감지되는 경우, 차량의 속도를 제어하거나, 차량의 차선을 변경하여 모니 터링이 가능한 영역이 축소되는 것을 최소화할 수 있다. 다양한 실시예들에 따르면, 차량은 탐지 영역과 차량 사이의 거리에 기초하여 샘플링 레이트를 제어할 수 있다. 예를 들어, 차량은 탐지 영역과 차량 사이의 거리가 멀 수록, 적어도 하나의 카메라의 샘플링 레이트를 높게 설 정함으로써, 탐지 정확도를 향상시킬 수 있다. 도 11은 다양한 실시예들에 따른 차량에서 타차량에 대해 예측된 이동 궤적을 검증하는 흐름도이다. 도 11의 적 어도 일부 동작은 도 10의 동작 1007의 상세한 동직일 수 있다. 이하 실시예에서 각 동작들은 순차적으로 수행 될 수도 있으나, 반드시 순차적으로 수행되는 것은 아니다. 예를 들어, 각 동작들의 순서가 변경될 수도 있으며, 적어도 두 동작들이 병렬적으로 수행될 수도 있다. 여기에서, 차량은 도 9의 전자 장치를 포함할 수 있다. 도 11을 참조하면, 동작 1101에서, 차량은 타차량의 시간에 따른 이동 궤적을 예측할 수 있다. 일실시예에 따르 면, 차량의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈은 탐지 영역 내에 위치한 타차 량의 이동 속도, 및 이동 방향에 기초하여, 시간에 따라 타차량이 위치할 것으로 예측되는 예상 이동 궤적을 결 정할 수 있다. 타차량의 이동 속도, 및 이동 방향은 도 10에서 설명한 바와 같이, 적어도 하나의 이미지를 분석 하여 획득 가능한 타차량의 바퀴의 반경, 바퀴의 초당 회전 횟수, 바퀴의 각도, 또는 바퀴의 크기 중 적어도 하 나를 기반으로 결정할 수 있다. 동작 1103에서, 차량은 유효한 센싱 영역으로의 타차량 진입 시점을 예측할 수 있다. 일실시예에 따르면, 차량 의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈은 인접한 차량에 대한 정보, 또는 자차 의 주행 정보 중 적어도 하나에 기초하여 자차의 적어도 하나의 카메라를 이용하여, 탐지 영역 중 모니터링이 가능한 영역을 결정하고, 모니터링이 가능한 영역을 유효한 센싱 영역으로 결정할 수 있다. 인접한 차량에 대한 정보는, 인접한 차량의 시간에 따른 예상 이동 궤적, 인접한 차량의 길이, 높이, 또는 종류 정보 중 적어도 하 나를 포함할 수 있다. 프로세서, 및/또는 카메라 모듈은 적어도 하나의 카메라를 통해 획득되는 이미 지들을 분석하여 인접한 차량의 바퀴의 크기(또는 반경), 바퀴의 초당 회전 수, 또는 바퀴의 방향(또는 휠의 방 향) 중 적어도 하나를 획득하고, 획득된 정보에 기초하여 인접한 차량의 이동 속도, 또는 이동 방향 중 적어도 하나를 결정할 수 있다. 프로세서, 및/또는 카메라 모듈은 인접한 차량의 이동 속도, 또는 이동 방향 중 적어도 하나에 기초하여 인접한 차량의 시간에 따른 예상 이동 궤적을 결정할 수 있다. 프로세서, 및/ 또는 카메라 모듈은 바퀴의 크기에 기초하여, 인접한 차량의 종류를 결정할 수 있다. 인접한 차량의 종류 는, 예를 들어, 경차, 소형차, 중형차, 대형차, 트럭, 버스, 또는 승용차 중 적어도 하나를 나타낼 수 있다. 나 열된 예시들은 이해를 돕기 위한 것일 뿐, 본 개시물의 다양한 실시예들은 이에 한정되지 않을 것이다. 프로세 서, 및/또는 카메라 모듈은 인접한 차량의 종류에 기초하여, 차량의 높이, 및/또는 길이를 추정하거 나, 적어도 하나의 카메라를 통해 획득되는 이미지들을 분석하여 인접한 차량의 차체의 높이, 길이, 또는 형태 중 적어도 하나를 획득할 수 있다. 일실시예에 따르면, 인접한 차량의 종류 정보는, 바퀴의 크기 이외에, 차량 의 높이, 크기, 또는 형태 중 적어도 하나를 더 고려하여 결정될 수 있다. 자차의 주행 정보는, 자차의 주행 경 로, 주행 속도, 자차의 위치, 또는 자차와 앞차 사이의 거리 중 적어도 하나를 포함할 수 있다, 일실시예에 따 르면, 프로세서, 및/또는 카메라 모듈은 결정된 유효한 센싱 영역과 타차량의 시간에 따른 예상 이동 궤적에 기초하여, 타차량이 유효한 센싱 영역으로 진입할 것으로 예상되는 시점을 결정할 수 있다. 동작 1105에서, 차량은 유효한 센싱 영역으로의 타차량 진입이 감지되는지 여부를 결정할 수 있다. 일실시예에 따르면, 차량의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈은 적어도 하나의 카메라를 이용하여 유효한 센싱 영역에 대한 이미지들을 획득하여 타차량이 유효한 센싱 영역에 진입하였는지 여부를 결 정할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은 유효한 센싱 영역에서 타차량이 감지되면, 타차량이 감지된 시점을 유효한 센싱 영역으로의 타차량 진입 시점으로 결정할 수 있다.유효한 센싱 영역으로의 타차량의 진입이 감지될 경우, 차량은 동작 1107에서 유효한 센싱 영역으로의 타차량의 진입이 감지된 시점과 예측된 진입 시점이 일치되는지 여부를 결정할 수 있다. 일실시예에 따르면, 차량의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈은 동작 1103에서 예측된 진입 시점과 동작 1105 에서 측정된 진입 시점을 비교하여 일치 여부를 결정할 수 있다. 타차량의 진입이 감지된 시점과 예측된 진입 시점이 일치하는 경우, 차량은 동작 1109에서 타차량에 대한 후속 차랑의 시간에 따른 이동 궤적을 예측할 수 있다. 예를 들어, 타차량의 진입이 감지된 시점과 예측된 진입 시점 이 일치하는 경우, 차량의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈은 타차량에 대한 탐지 정확도가 지정된 조건을 만족하는 것으로 결정하고, 탐지 영역 내 후속 차량에 대한 시간에 따른 이동 궤 적을 계측할 수 있다. 후속 차량은, 탐지 영역 내에서 타차량의 뒤에 위치한 차량일 수 있다. 일실시예에 따르 면, 프로세서, 및/또는 카메라 모듈은 동작 1101에서 예측된 타차량의 시간에 따른 이동 궤적에 안전 거리를 적용하여 후속 차량의 시간에 따른 이동 궤적을 예측할 수 있다. 일실시예에 따르면, 프로세서, 및 /또는 카메라 모듈은 후속 차량에 대해서도 동작 1103, 동작 1105 및 동작 1107을 수행하고, 후속 차량의 시간에 따른 이동 궤적을 고려하여 자차의 주행을 수행할 수 있다. 타차량의 진입이 감지된 시점과 예측된 진입 시점이 일치하지 않는 경우, 차량은 동작 1111에서 타차량을 모니 터링하기 위한 대체 센서를 구동할 수 있다. 예를 들어, 타차량의 진입이 감지된 시점과 예측된 진입 시점이 일 치하지 않는 경우, 차량의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈은 타차량에 대한 탐지 정확도가 지정된 조건을 만족하지 않는 것으로 결정(또는 탐지 정확도가 낮은 것으로 결정)하고, 적어도 하나의 대체 센서를 선택하여 구동할 수 있다. 대체 센서는, 적어도 하나의 다른 카메라, 또는 라이다 중 적어 도 하나를 포함할 수 있다. 프로세서, 및/또는 카메라 모듈은 결정된 탐지 영역 중 적어도 하나의 카 메라에 의해 모니터링되지 않은 영역을 모니터링할 수 있는 시야각을 가진 적어도 하나의 다른 카메라, 또는 라 이다 중 적어도 하나를 추가적으로 구동할 수 있다. 프로세서, 및/또는 카메라 모듈은 구동 중인 적 어도 하나의 카메라 센서와 추가적으로 구동된 대체 센서를 이용하여 탐지 영역 내 위치한 타차량을 모니터링하 고, 모니터링 결과를 기반으로 자차의 주행을 수행할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카 메라 모듈은 상술한 도 10에서 설명한 바와 같은 방식으로, 대체 센서의 샘플링 레이트를 조절할 수 있다. 본 개시물의 다양한 실시예들에 따르면, 프로세서, 및/또는 카메라 모듈은, 대체 센서를 구동함으로 써, 타차량에 대한 탐지 정확도를 향상시킬 수 있다. 도 12는 다양한 실시예들에 따른 차량에서 타차량에 대해 예측된 이동 궤적에 기초하여 자율 주행을 수행하는 흐름도이다. 도 12의 적어도 일부 동작은 도 10의 동작 1009의 상세한 동직일 수 있다. 이하 실시예에서 각 동 작들은 순차적으로 수행될 수도 있으나, 반드시 순차적으로 수행되는 것은 아니다. 예를 들어, 각 동작들의 순 서가 변경될 수도 있으며, 적어도 두 동작들이 병렬적으로 수행될 수도 있다. 여기에서, 차량은 도 9의 전자 장 치를 포함할 수 있다. 도 12를 참조하면, 차량은 동작 1201에서 타차량의 예상 이동 궤적에 기초하여 충돌 예상 위치를 결정할 수 있 다. 예를 들어, 차량의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈은 타차량의 예상 이 동 궤적과 자차의 주행 정보에 기초하여, 타차량과 자차의 충돌 예상 위치를 결정할 수 있다. 충돌 예상 위치는, 타차량의 예상 이동 궤적과 자차의 주행 경로가 중첩되는 위치를 포함할 수 있다. 타차량의 예상 이동 궤적은, 도 10의 동작 1007, 및 도 11의 동작 1101에서 설명한 바와 같이 예측 또는 결정될 수 있다. 차량은 동작 1203에서 충돌 예상 위치까지의 타차량의 이동 시간(T1)을 계산하고, 동작 1205에서 충돌 예상 위 치까지의 자차의 이동 시간(T2)를 계산할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은 타 차량의 시간에 따른 예상 이동 궤적에 기초하여, 타차량이 충돌 예상 위치까지 이동하는데 소요될 것으로 예상 되는 이동 시간(T1)을 계산하고, 자차의 주행 정보를 고려하여 자차가 충돌 예상 위치까지 이동하는데 소요될 것으로 예상되는 이동 시간(T2)을 계산할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈 은 자차의 주행 정보, 및 자차와 동일한 차선에 위치한 전방 차량의 이동 속도를 고려하여, 자차가 충돌 예상 위치까지 이동하는데 소요될 것으로 예상되는 이동 시간(T2)을 계산할 수 있다. 동작 1207에서, 차랑은 충돌 예상 위치까지의 타차량의 이동 시간(T1)이 충돌 예상 위치까지의 자차의 이동 시 간(T2)보다 작거나 같은지 여부를 결정할 수 있다. 충돌 예상 위치까지의 타차량의 이동 시간(T1)이 충돌 예상 위치까지의 자차의 이동 시간(T2)보다 작거나 같은 경우, 차량은 동작 1209에서 자차의 이동 속도를 제어할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은, 충돌 예상 위치까지의 타차량의 이동 시간(T1)이 충돌 예상 위치까지의 자차의 이동 시간(T2)보다 작거나 같은 경우, 타차량이 자차보다 충돌 예상 위치를 먼저 지나가도록 자차의 이동 속도를 감소시킬 수 있다. 이동 속도는, T1과 T2의 차이에 기반하여 감소될 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모 듈은, T1과 T2이 동일한 경우, 자차의 이동 속도를 A만큼 감소시키고, T1과 T2이 동일하지 않으나, T1과 T2의 차이가 지정된 범위 이내에 해당하는 경우, 자차의 이동 속도를 B만큼 감소시킬 수 있다. 여기서, A는 B보 다 큰 값일 수 있다. 프로세서, 및/또는 카메라 모듈은, T과 T2의 차이가 지정된 범위 이내에 해당하 지 않는 경우, 자차의 이동 속도를 C만큼 감소시킬 수 있다. C는 B보다 작은 값일 수 있다. 충돌 예상 위치까지의 자차의 이동 시간(T2)이 충돌 예상 위치까지의 자차의 이동 시간(T2)보다 큰 경우, 차량 은 동작 1211에서 속도를 유지하여 주행할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은, 충돌 예상 위치까지의 타차량의 이동 시간(T1)이 충돌 예상 위치까지의 자차의 이동 시간(T2)보다 큰 경우, 타 차량보다 자차가 충돌 예상 위치를 먼저 지나가도록 자차의 이동 속도를 유지 또는 증가시킬 수 있다. 이때, 타 차량은, 상술한 도 10 내지 도 12와 같은 동작을 수행함으로써, 타차량의 이동 속도를 감소시킬 수 있다. 도 13a 및 도 13b는 다양한 실시예에 따른 차량에서 타차량의 주행 정보를 획득하는 흐름도이다. 도 13a 및 도 13b의 적어도 일부 동작은 도 10의 동작 1001 내지 동작 1007의 상세한 동직일 수 있다. 이하 실시예에서 각 동 작들은 순차적으로 수행될 수도 있으나, 반드시 순차적으로 수행되는 것은 아니다. 예를 들어, 각 동작들의 순 서가 변경될 수도 있으며, 적어도 두 동작들이 병렬적으로 수행될 수도 있다. 여기에서, 차량은 도 9의 전자 장 치를 포함할 수 있다. 이하에서 도 13a 및 도 13b의 적어도 일부 동작은, 도 14a 내지 도 14d를 참조하여 설명한다. 도 14a 내지 도 14d는 다양한 실시예들에 따른 차량에서 타차량의 주행 정보를 획득하는 예시도이다. 도 13을 참조하면, 차량은 동작 1301에서 좌측 측방 카메라 및/또는 좌측 전방 카메라를 이용하여 모니터링을 수행할 수 있다. 예를 들어, 도 14a에 도시된 바와 같이, 자차는 탐지 영역을 커버하는 시야각을 갖는 좌측 전방 카메라를 구동하여, 탐지 영역에 대한 모니터링을 수행할 수 있다. 다른 예로, 자차 는, 도 14b에 도시된 바와 같이, 탐지 영역을 커버하는 시야각을 갖는 좌측 측방 카메라를 구 동하여, 탐지 영역에 대한 모니터링을 수행할 수 있다. 또 다른 예로, 자차는, 도 14c 및 도 14d에 도시된 바와 같이, 탐지 영역 중 일부 영역을 커버하는 시야각을 갖는 좌측 측방 카메라와 탐지 영 역 중 일부 영역을 커버하는 시야각을 갖는 좌측 전방 카메라를 함께 구동하여, 탐지 영역에 대한 모니터링을 수행할 수 있다. 동작 1303에서, 차량은 좌측 측방 및/또는 좌측 전방 카메라의 시야각 내에 인접 차량이 감지되는지 여부를 결 정할 수 있다. 일실시예에 따르면, 차량의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈 은 구동 중인 좌측 측방 카메라 및/또는 좌측 전방 카메라를 통해 획득된 이미지에서 인접한 차량이 검출되는지 여부를 결정할 수 있다. 인접한 차량은, 탐지 영역이 아닌 영역에 위치한 차량으로, 예를 들어, 자차와 동일한 차선에 위치한 전방 차량, 자차의 인접 차선에 위치한 차량, 또는 자차의 반대 차선에 위치한 차량 중 적어도 하나를 포함할 수 있다. 좌측 측방 및/또는 좌측 전방 카메라의 시야각 내에 인접 차량이 감지되지 않는 경우, 차량은 1317에서 좌측 측 방 및/또는 좌측 전방 카메라를 이용하여 타차량의 주행 정보를 획득할 수 있다. 타차량의 주행 정보를 획득하 는 방식은, 동작 1011과 동일할 수 있다. 좌측 측방 및/또는 좌측 전방 카메라의 시야각 내에 인접 차량이 감지되는 경우, 차량은 동작 1305에서 인접 차 량의 바퀴 및 차체 정보를 획득할 수 있다. 예를 들어, 도 14a에 도시된 바와 같이, 자차는 좌측 전방 카 메라를 이용하여 탐지 영역을 모니터링하는 중에, 인접 차선의 차량이 감지되는 경우, 인접 차선의 차량에 대한 바퀴 및 차체 정보를 획득할 수 있다. 다른 예로, 도 14b에 도시된 바와 같이, 자차 는 좌측 측방 카메라를 이용하여 탐지 영역을 모니터링하는 중에, 인접 차선의 차량이 감지되는 경우, 인접 차선의 차량1에 대한 바퀴 및 차체 정보를 획득할 수 있다. 바퀴 정보는, 예를 들어, 바퀴 반경, 바퀴의 초당 회전 횟수, 또는 바퀴의 각도 중 적어도 하나를 포함할 수 있다. 차체 정보는, 차체 높이, 차체 길이, 또는 차량 종류 정보 중 적어도 하나를 포함할 수 있다. 차체 정보는, 좌측 측방 및/또 는 좌측 전방 카메라를 통해 획득된 이미지로부터 획득되거나, 바퀴 정보에 기초하여 추정될 수 있다. 예를 들 어, 프로세서는 바퀴 반경에 기초하여, 차체 길이, 및/또는 차량의 종류 정보를 추정할 수 있다. 예컨대, 프로세서는 바퀴의 반경이 지정된 제1 바퀴 반경 범위에 해당하는 경우, 차량의 종류가 소형인 것으로 결정하고, 바퀴의 반경이 지정된 제2 바퀴 반경 범위에 해당하는 경우, 차량의 종류가 중형인 것으로 결정할 수 있다. 프로세서는 바퀴의 반경이 지정된 제3 바퀴 반경 범위에 해당하는 경우, 차량의 종류가 대형인 것으 로 결정할 수 있다. 동작 1307에서, 차량은 인접 차량에 의해 지정된 크기 이상의 시야각이 차단될 가능성이 있는지 여부를 결정할 수 있다. 일실시예에 따르면, 차량의 전자 장치에 포함되는 프로세서, 및/또는 카메라 모듈은 좌측 측방 카메라, 및/또는 좌측 전방 카메라에 의해 감지되는 바퀴 및 차체 정보에 기초하여, 탐지 영역에 대응되는 좌측 측방 카메라, 및/또는 좌측 전방 카메라의 시야각 중 지정된 크기 이상의 시야 각이 인접 차량에 의해 차단될 가능성이 있는지 여부를 결정할 수 있다. 예를 들어, 프로세서, 및/또는 카 메라 모듈은 인접 차량의 바퀴 및 차체 정보를 분석한 결과, 인접 차량이 지정된 길이를 초과하는 대형 차 량인 경우, 탐지 영역에 대응되는 좌측 측방 카메라, 및/또는 좌측 전방 카메라의 시야각 중 지정된 크기 이상의 시야각이 인접 차량에 의해 차단될 가능성이 있는 것으로 결정할 수 있다. 다른 예로, 프로세서 , 및/또는 카메라 모듈은 인접 차량의 바퀴 및 차체 정보를 분석한 결과, 인접 차량이 지정된 길이보 다 작은 소형 또는 중형 차량인 경우, 탐지 영역에 대응되는 좌측 측방 카메라, 및/또는 좌측 전방 카메라 의 시야각 중 지정된 크기 이상의 시야각이 인접 차량에 의해 차단될 가능성이 없는 것으로 결정할 수 있 다. 나열된 예들은 이해를 돕기 위한 예시일 뿐, 본 개시물의 다양한 실시예들은 이에 한정되지 않을 것이다. 인접 차량에 의해 지정된 크기 이상의 시야각이 차단될 가능성이 있는 경우, 차량은 동작 1309에서 지정된 크기 이상의 시야각이 차단되는 시점을 예측할 수 있다. 예를 들어, 도 14a 및/또는 도 14b에 도시된 바와 같이, 자 차는 인접 차선의 차량1이 지정된 길이를 초과하는 대형 차량인 경우, 인접 차선의 차량1의 이동(또는 주행)에 의해 탐지 영역에 대응되는 좌측 전방 카메라의 시야각, 및/또는 좌측 측방 카메라 의 시야각 중 지정된 크기 이상의 시야각이 차단되는 시점을 예측할 수 있다. 프로세서, 및/또는 카 메라 모듈은 인접 차량의 크기, 인접 차량의 이동 속도, 인접 차량의 이동 방향, 인접 차량의 예상 이동 궤적, 인접 차량과 탐지 영역 사이의 거리 변화 속도, 자차의 이동 속도, 자차의 이동 방향, 자차에서 구동 중 인 카메라의 시야각 중 적어도 하나에 기초하여, 지정된 크기 이상의 시야각이 차단되는 시점을 예측할 수 있다. 동작 1311에서, 차량은 차단 시점 이전에 타차량의 정보를 획득할 수 있는지 여부를 결정할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은 예측된 차단 시점이 되기 전에, 구동 중인 적어도 하나의 카 메라를 이용하여 탐지 영역에 위치한 타차량을 포함하는 적어도 하나의 이미지를 획득하고, 획득된 이미지를 분 석하여 타차량의 정보 획득을 시도할 수 있다. 타차량의 정보는, 타차량의 정보는, 탐지 영역에 위치한 타차량 의 바퀴의 반경, 바퀴의 초당 회전 횟수, 바퀴의 각도 중 적어도 하나를 포함할 수 있다. 일실시예에 따르면, 타차량의 정보를 획득하기 위해서는, 타차량의 바퀴를 포함하는 복수개의 이미지들이 필요할 수 있다. 일실시예 에 따르면, 프로세서, 및/또는 카메라 모듈은 예측된 차단 시점까지의 남은 시간이 지정된 시간보다 크거나 같은지 여부를 결정할 수 있다. 프로세서, 및/또는 카메라 모듈은, 예측된 차단 시점까지의 남은 시간이 지정된 시간보다 작은 경우, 타차량의 정보를 획득할 수 없는 것으로 결정하고, 예측된 차단 시점 까지의 남은 시간이 지정된 시간보다 크거나 같은 경우, 타차량의 정보를 획득할 수 없는 것으로 결정할 수 있 다. 지정된 시간은, 타차량의 바퀴를 포함하는 복수개의 이미지들을 획득하는데 필요한 최소 시간일 수 있다. 차단 시점 이전에 타차량의 정보를 획득할 수 있는 경우, 차량은 동작 1313에서 차단 시점 이전에 전방 및/또는 측방 카메라를 이용하여 타차량의 주행 정보를 획득할 수 있다. 예를 들어, 예측된 차단 시점이 되기 전에 타차 량의 바퀴를 포함하는 복수 개의 이미지들을 획득할 수 있는 경우, 프로세서, 및/또는 카메라 모듈은 차단 시점 이전에 구동 중인 전방 및/또는 측방 카메라를 이용하여 타차량의 주행 정보를 획득할 수 있다. 예를 들어, 도 14a에 도시된 바와 같이, 자차는 탐지 영역에 대응되는 좌측 전방 카메라의 시야각 중 지정된 크기 이상의 시야각이 대형 차량인 인접 차선의 차량1에 의해 차단되기 전에, 좌측 전방 카메 라를 이용하여 탐지 영역에 위치한 타차량의 주행 정보를 획득할 수 있다. 다른 예로, 도 14b 에 도시된 바와 같이, 자차는 탐지 영역에 대응되는 좌측 측방 카메라의 시야각 중 지정된 크 기 이상의 시야각이 인접 차선의 차량1에 의해 차단되기 전에, 좌측 측방 카메라를 이용하여 탐지 영역에 위치한 타차량의 주행 정보를 획득할 수 있다. 타차량의 주행 정보는, 타차량의 정보(예: 바퀴 관련 정보)에 기초하여 획득 가능한 타차량의 이동 속도, 이동 방향, 또는 예상 이동 궤적 중 적어도 하나 를 포함할 수 있다. 타차량의 주행 정보를 획득하는 동작은, 도 10의 동작 1005 및 1007 중 적어도 일부 동작을 포함할 수 있다. 차량은 동작 1315에서, 차단 시점 이전에 탐지 영역에 대한 전방 카메라를 좌측 카메라에서 우측 카메라로 전환 할 수 있다. 예를 들어, 도 14a에 도시된 바와 같이, 자차는 탐지 영역에 대응되는 좌측 전방 카메 라의 시야각 중 지정된 크기 이상의 시야각이 인접 차선의 차량1에 의해 차단되기 전에, 탐지 영역 을 모니터링하는 전방 카메라를 좌측 전방 카메라에서 우측 전방 카메라로 전환할 수 있다. 이때, 프 로세서, 및/또는 카메라 모듈은 우측 전방 카메라가 비활성 상태에서 활성 상태로 전환되거나, 이미지 샘플링 동작 중단 상태에서 이미지 샘플링 동작 수행 상태로 전환되도록 제어할 수 있다. 프로세서 , 및/또는 카메라 모듈은 좌측 전방 카메라의 이미지 샘플링 동작을 중단시킬 수 있다. 본 개시 물의 다양한 실시예들에 따르면, 차량에서 복수 개의 카메라들 중 일부 카메라만을 이용하여 탐지 영역을 모니 터링함으로써, 전력 소모량을 감소시킬 수 있는 효과를 얻을 수 있다. 차단 시점 이전에 타차량의 정보를 획득할 수 없는 경우, 차량은 동작 1319에서 차단 시점 이전에 탐지 영역에 대한 전방 카메라를 좌측 카메라에서 우측 카메라로 전환할 수 있다. 예를 들어, 프로세서, 및/또는 카메 라 모듈은 예측된 차단 시점까지의 남은 시간이 지정된 시간보다 작은 경우, 예측된 차단 시점 이전에 좌 측 전방 카메라를 이용하여 타차량의 정보를 획득할 수 없는 것으로 결정하고, 탐지 영역을 모니터링하는 전방 카메라를 좌측 전방 카메라에서 우측 전방 카메라로 전환할 수 있다. 전방 카메라를 좌측 전방 카메라에서 우측 전방 카메라로 전환하는 방식은 동작 1315와 동일할 수 있다. 차량은 동작 1321에서, 전환된 카메라를 이용하여 타차량의 주행 정보를 획득할 수 있다. 예를 들어, 프로세서 , 및/또는 카메라 모듈은 동작 1319에서 구동된 우측 전방 카메라를 이용하여 탐지 영역에 위치 한 타차량의 주행 정보를 획득할 수 있다. 타차량의 주행 정보를 획득하는 동작은, 도 10의 동작 1005 및 동작 1007 중 적어도 일부를 포함하거나, 도 10의 동작 1011을 포함할 수 있다. 동작 1307의 결정 결과, 인접 차량에 의해 지정된 크기 이상의 시야각이 차단될 가능성이 없는 경우, 차량은 동 작 1331에서 좌측 측방 카메라를 이용하여 타차량의 주행 정보를 획득할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은 좌측 측방 카메라를 이용하여, 인접 차량에 의해 가려지지 않은 탐지 영역을 모니 터링함으로써, 타차량의 주행 정보를 획득할 수 있다. 예컨대, 도 14c 및/또는 도 14d에 도시된 바와 같이, 자 차는 인접 차선의 차량1이 지정된 길이보다 작은 길이를 갖는 소형 차량 또는 중형 차량인 경우, 좌측 측방 카메라를 이용하여, 인접 차선의 차량들(1411, 1414), 및/또는 반대 차선의 차량들(1415, 141 6)에 의해 가려지지 않은 탐지 가능 영역을 분석하고, 분석된 탐지 가능 영역을 통해 타차량의 주행 정보를 획 득할 수 있다. 프로세서, 및/또는 카메라 모듈은 좌측 측방 카메라를 이용하여 획득된 타차량의 주행 정보를 기반으로, 타차량이 충돌 예상 위치까지 이동하는데 소요될 것으로 예상되는 시간(T1)을 계산할 수 있다. 일실시예에 따르면, 좌측 측방 카메라를 이용하여 타차량의 주행 정보를 획득하는 동안에, 좌측 전방 카 메라는 비활성화된 상태이거나, 활성화된 상태이나 이미지 샘플링 동작이 적어도 일시적으로 중단된 상태일 수 있다. 이는, 좌측 전방 카메라에서 소모하는 전력을 감소시키기 위함이다. 동작 1333에서, 차량은 좌측 전방 카메라를 이용하여 타차량의 주행 정보를 갱신할 수 있다. 예를 들어, 프로세 서, 및/또는 카메라 모듈은, 좌측 전방 카메라를 이용하여, 좌측 측방 카메라로 모니터링 하지 못하는 탐지 영역을 모니터링하여 타차량의 주행 정보를 갱신할 수 있다. 예컨대, 도 14c 및/또는 도 14d 에 도시된 바와 같이, 자차는 인접 차선의 차량1이 지정된 길이보다 작은 길이를 갖는 소형 차량 또는 중형 차량인 경우, 좌측 전방 카메라를 이용하여, 인접 차선의 차량1, 및/또는 전방 차량 에 의해 가려지지 않은 탐지 영역에 위치한 타차량의 주행 정보를 획득할 수 있다. 프로세서, 및/또 는 카메라 모듈은 좌측 전방 카메라를 이용하여 획득된 타차량의 주행 정보를 기반으로, 타차량이 충 돌 예상 위치까지 이동하는데 소요될 것으로 예상되는 시간(T1)을 갱신할 수 있다. 좌측 전방 카메라는 동 작 1333에서 타차량의 주행 정보 갱신을 위해 구동될 수도 있고, 이전에 미리 구동된 상태일 수도 있다. 일실시 예에 따르면, 좌측 전방 카메라를 이용하여 타차량의 주행 정보를 갱신하는 동안에, 좌측 측방 카메라의 이미지 샘플링 동작은 적어도 일시적으로 중단될 수 있다. 이는, 좌측 측방 카메라에서 소모하는 전력을 감소시키기 위 함이다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은, 동작 1331에서 좌측 측방 카메라 에 의해 획득된 적어도 하나의 이미지와 좌측 전방 카메라에 의해 획득된 적어도 하나의 이미지를 기 반으로, 타차량의 주행 정보를 획득할 수 있다. 동작 1335에서, 차량은 좌측 전방 카메라의 시야에서 전방 차량에 의해 타차량의 적어도 일부가 가려지는지 여 부를 결정할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은, 좌측 전방 카메라(71 3)를 이용하여 타차량을 모니터링하는 중에 타차량의 적어도 일부분이 자차와 동일한 차선에 위치한 전방 차량 에 의해 가려지는지 여부를 결정할 수 있다. 전방 차량에 의해 타차량의 적어도 일부가 가려지는 경우, 차량은 동작 1337에서 우측 전방 카메라를 구동하여 모니터링을 수행할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은, 도 14c 및/또는 14d에 도 시된 바와 같이, 타차량의 이동에 의해 타차량의 적어도 일부분이, 전방 차량에 의해 가려지 는 시점을 인지하고, 인지된 시점에 자차의 우측 전방 카메라를 구동하여 탐지 영역 중 적어도 일부 영역을 모니터링할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은, 우측 전방 카메 라의 구동 시, 좌측 전방 카메라의 샘플링 동작을 적어도 일시적으로 중단하고, 우측 전방 카메라 를 이용하여 이미지를 샘플링할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은, 도 14c 및/또는 14d에 도시된 바와 같이, 타차량의 적어도 일부가 우측 전방 카메라의 시야각을 벗어나는 경우, 우측 측방 카메라를 구동하여 타차량에 대한 모니터링을 수행할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은, 우측 전방 카메라의 구동 시, 우측 측방 카메라를 함께 구동할 수 있다. 일실시예에 따르면, 카메라의 구동은, 활성화된 상태의 카메라에서 이미지 샘플링 동작을 시작하는 것을 의미할 수 있다. 일실시예에 따르면, 카메라의 구동은, 비활성 상태에 있는 카메 라를 활성화시킨 후, 활성화된 상태의 카메라에서 이미지 샘플링 동작을 시작하는 것을 의미할 수 있다. 일실시 예에 따르면, 프로세서, 및/또는 카메라 모듈은, 우측 전방 카메라, 및/또는 우측 측방 카메라 를 이용하여, 타차량이 탐지 영역을 완전히 벗어나는지 여부를 감지할 수 있다. 타차량이 탐 지 영역을 완전히 벗어나는 경우, 프로세서, 및/또는 카메라 모듈은, 우측 전방 카메라, 및/또 는 우측 측방 카메라의 구동을 적어도 일시적으로 중단할 수 있다. 카메라의 구동을 적어도 일시적으로 중 단하는 것은, 이미지 샘플링 중단, 및/또는 카메라의 비활성화 상태로의 전환 중 적어도 하나를 포함할 수 있다. 일실시예에 따르면, 상술한 도 13의 동작 1331 및/또는 동작 1333에서, 프로세서, 및/또는 카메라 모듈 은 인접 차선의 차량들(1411, 1414), 및/또는 반대 차선의 차량들(1415, 1416)의 주행에 의한 탐지 가능 영역의 크기 변화를 분석하고, 탐지 가능 영역의 크기 변화에 따라 좌측 측방 카메라, 및/또는 좌측 전방 카메라의 샘플링 시간을 제어할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은 탐지 가능 영역의 크기 변화에 따라 좌측 측방 카메라, 및/또는 좌측 전방 카메라의 샘플링 레이트를 제어할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은 탐지 가능 영역의 크기가 작아질 수록, 좌측 측방 카메라, 및/또는 좌측 전방 카메라의 샘플링 레이트를 증가시킬 수 있다. 이하 도 15, 도 16a, 및 도 16b에서는, 자차에 인접한 차량에 의해, 자차의 좌측 측방 카메라의 시야각 중 지정된 크기 이상의 시야각이 차단된 상황에서 타차량의 주행 정보를 획득하는 예시에 대해 개시한다. 도 15는 다양한 실시예들에 따른 차량에서 타차량의 주행 정보를 획득하는 흐름도이다. 도 15의 적어도 일부 동 작은 도 10의 동작 1001 내지 동작 1007의 상세한 동직일 수 있다. 이하 실시예에서 각 동작들은 순차적으로 수 행될 수도 있으나, 반드시 순차적으로 수행되는 것은 아니다. 예를 들어, 각 동작들의 순서가 변경될 수도 있으 며, 적어도 두 동작들이 병렬적으로 수행될 수도 있다. 여기에서, 차량은 도 9의 전자 장치를 포함할 수 있다. 이하에서 도 15의 적어도 일부 동작은, 도 16a 및 도 16b를 참조하여 설명한다. 도 16a 내지 도 16b는 다 양한 실시예들에 따른 차량에서 타차량의 주행 정보를 획득하는 예시도이다. 도 15를 참조하면, 차량은 동작 1501에서, 좌측 측방 카메라를 이용하여 모니터링을 수행할 수 있다. 예를 들어, 차량의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈은, 좌측 측방 카메라를 이용하여 탐지 영역 중 적어도 일부 영역에 대한 모니터링을 수행할 수 있다. 동작 1503에서, 차량은 좌측 측방 카메라의 시야각 내 인접 차량 및 전방 차량을 감지할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은, 도 16a 및 도 16b에 도시된 바와 같이, 좌측 측방 카메라의 전체 시야각 내에서, 지정된 길이를 초과하는 대형 차량인 인접차선의 차량1을 감지할 수 있다. 좌측 측방 카메라의 전체 시야각은, 도 7b에서 설명한 바와 같이, 120도에 대응할 수 있다. 이는 예시일 뿐, 본 개시물의 다양한 실시예들은 이에 한정되지 않을 것이다. 동작 1505에서, 차량은 인접 차량과 탐지 영역 사이의 거리를 측정할 수 있다. 일실시예에 따르면, 프로세서 , 및/또는 카메라 모듈은, 자차와 탐지 영역 사이의 거리, 자차의 이동 속도, 자차의 이동 방향, 인 접 차량의 이동 속도, 인접 차량의 이동 방향, 또는 인접 차량의 길이 중 적어도 하나를 기반으로, 인접 차량과 탐지 영역 사이의 거리를 결정할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은, 좌 측 측방 카메라를 통해 획득되는 이미지를 분석하여 인접 차량과 탐지 영역 사이의 거리를 측정할 수있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은, 도 16a 및 도 16b에 도시된 바와 같이, 좌측 측 방 카메라를 통해 인접 차선의 차량1과 전방 차량 사이의 공간을 모니터링함으로써, 인접 차 선의 차량 1과 탐지 영역 사이의 거리, 및/또는 거리 변화를 측정할 수 있다. 동작 1507에서, 차량은 측정된 거리가 지정된 임계 거리보다 작은지 여부를 결정할 수 있다. 예를 들어, 프로세 서, 및/또는 카메라 모듈은, 도 16a 및 도 16b에 도시된 바와 같이, 좌측 측방 카메라의 시야각 내에 위치한 인접 차선의 차량 1과 탐지 영역 사이의 거리를 지정된 임계 거리와 비교할 수 있다. 지정된 임계 거리는, 사업자 및/또는 설계자에 의해 설정 및/또는 변경될 수 있다. 측정된 거리가 지정된 임계거리보다 작은 경우, 차량은 동작 1509에서 측정된 거리 및 전방 차량에 기초하여 탐 지 영역을 축소할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은, 도 16a 및 도 16b에 도시 된 바와 같이, 전체 탐지 영역 중에서 인접 차선의 차량1과 전방 차량 사이의 공간을 통해 좌측 측방 카메라로 탐지 가능한 일부 영역을, 좌측 측방 카메라의 탐지 영역으로 적어도 일시적으로 축소할 수 있다. 프로세서, 및/또는 카메라 모듈은 좌측 측방 카메라를 통해, 축소된 탐지 영역 에 위치한 타차량의 정보를 획득할 수 있다. 예를 들어, 좌측 측방 카메라는 전체 시야각에 대응되는 픽셀 영역들 중, 축소된 탐지 영역에 대응되는 시야각의 픽셀 영역에 대해서만 샘플링을 수행하여 타차량의 정보를 획득할 수 있다. 동작 1511에서, 차량은 좌측 전방 카메라를 구동할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메 라 모듈은, 측정된 거리가 지정된 임계거리보다 작은 경우, 좌측 전방 카메라를 구동할 수 있다. 일 실시예에 따르면, 동작 1511은, 동작 1509와 동시에 수행되거나, 동작 1509보다 먼저 수행될 수 있다. 예를 들 어, 동작 1511은, 반드시 동작 1509 이후에 수행되는 것이 아니다. 동작 1513에서, 차량은 좌측 전방 카메라를 통해 모니터링 가능한 영역의 크기가 지정된 크기보다 큰지 여 부를 결정할 수 있다. 모니터링 가능한 영역은, 인접 차량들 사이(예: 인접 차선의 차량과 동일 차선의 전방 차 량 사이)의 공간을 통해 모니터링 가능한 영역, 전방 차량의 차체 윗 부분의 공간을 통해 모니터링 가능한 영역, 또는 전방 차량의 윈드 쉴드를 통해 모니터링 가능한 영역 중 적어도 하나를 포함할 수 있다. 지정된 크 기는, 샘플링을 통해 타차량의 정보를 획득할 수 있는 최소한의 영역을 나타내는 크기로 결정될 수 있다. 지정 된 크기는, 사업자 및/또는 설계자에 의해 설정 및/또는 변경될 수 있다. 모니터링 가능 영역의 크기가 지정된 크기보다 큰 경우, 차량은 동작 1517에서 좌측 측방 및 좌측 전방 카메라 를 이용하여 타차량의 정보를 획득할 수 있다. 예를 들어, 도 16a에 도시된 바와 같이, 자차는 좌측 측방 카메라를 이용하여 인접 차선의 차량1과 전방 차량 사이의 공간을 통해 탐지 영역을 모 니터링하고, 좌측 전방 카메라를 이용하여 인접 차선의 차량1과 전방 차량 사이의 공간, 전방 차량의 차체 윗 부분의 공간, 또는 전방 차량의 윈드 쉴드 영역에 대응되는 공간 중 적어도 하나를 통해 탐지 영역을 모니터링하여, 타차량의 정보를 획득할 수 있다. 모니터링 가능 영역의 크기가 지정된 크기보다 작거나 같은 경우, 차량은 동작 1515에서 차량의 위치를 조절하 여 모니터링 가능 영역을 확보할 수 있다. 일실시예에 따르면, 프로세서는 차량의 차선을 변경하거나, 동 일 차선 내에서 차량의 위치를 조절하여 모니터링이 가능한 영역을 추가적으로 확보할 수 있다. 예를 들어, 도 16b에 도시된 바와 같이, 전방 차량에 의해 자차의 좌측 전방 카메라의 시야각이 차단된 경우, 자차는 자차의 위치를 동일 차선 내에서 왼쪽으로 이동시킴으로써, 인접 차선의 차량 1과 전방 차량 사이의 공간을 통해 탐지 영역에 대한 좌측 전방 카메라의 모니터링 가 능 영역을 확보할 수 있다. 동작 1517에서, 차량은 좌측 측방 및 좌측 전방 카메라를 이용하여 타차량의 정보를 획득할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은, 도 16a 및 도 16b에 도시된 바와 같이, 좌측 측방 카메라 및 좌측 전방 카메라를 이용하여 인접 차선의 차량1과 전방 차량 사이의 공간을 통해 탐지 영역에 위치한 타차량의 정보를 획득할 수 있다. 동작 1507의 결정 결과, 측정된 거리가 지정된 임계거리보다 크거나 같은 경우, 차량은 도 13의 1307을 수행할 수 있다. 도 17은 다양한 실시예들에 따른 차량에서 복수의 카메라를 운용하는 흐름도이다. 도 15의 적어도 일부 동작은 도 10의 동작 1009의 상세한 동직일 수 있다. 이하 실시예에서 각 동작들은 순차적으로 수행될 수도 있으나, 반드시 순차적으로 수행되는 것은 아니다. 예를 들어, 각 동작들의 순서가 변경될 수도 있으며, 적어도 두 동작들 이 병렬적으로 수행될 수도 있다. 여기에서, 차량은 도 9의 전자 장치를 포함할 수 있다. 도 17을 참조하면, 차량은 동작 1701에서 타차량이 자차보다 먼저 충돌 예상 위치를 통과할 예정인지 여부를 결 정할 수 있다. 예를 들어, 차량의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈은, 도 12 의 동작 1201 내지 동작 1207과 같이, 타차가 자차보다 먼저 예상 충돌 위치를 통과할 예정인지 여부를 결정할 수 있다. 타차량이 자차보다 먼저 충돌 예상 위치를 통과할 예정인 경우, 차량은 동작 1703에서 자차의 속도를 제어할 수 있다. 동작 1703은 도 12의 동작 1209와 동일할 수 있다. 차량은 동작 1705에서 우측 전방 카메라의 영역에 타차량의 진입이 감지되는지 여부를 결정할 수 있다. 우측 전 방 카메라는, 예를 들어, 도 13a 및 도 13b에서 설명한 바와 같은 시점에 구동될 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은, 탐지 영역 중 적어도 일부 영역을 모니터하는 우측 전방 카메라 를 통해 타차량이 감지되는지 여부를 결정할 수 있다. 일실시예에 따르면 프로세서, 및/또는 카메라 모듈은, 우측 전방 카메라를 통해 획득되는 이미지에서 타차량이 감지되는지 여부를 결정할 수 있다 우측 전방 카메라의 영역에 타차량의 진입이 감지되는 경우, 차량은 1707에서 우측 측면 카메라를 구동하여 모 니터링을 수행할 수 있다. 동작 1709에서, 차량은 우측 전방 카메라의 영역을 타차량이 통과하는지 여부를 결정할 수 있다. 예를 들어, 프 로세서, 및/또는 카메라 모듈은 우측 전방 카메라를 통해 획득되는 이미지에서 타차량의 진입을 감지한 후, 이후 시점에 우측 전방 카메라를 통해 획득되는 이미지에서 타차량이 더이상 감지되지 않는지 여부를 결정할 수 있다. 프로세서, 및/또는 카메라 모듈은 우측 전방 카메라를 통해 획득되는 이미지에서 타차량이 더이상 감지되지 않는 경우, 타차량이 우측 전방 카메라의 영역을 통과한 것으로 결정할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은 인접한 차량(예: 자차와 동일 차선에 위치한 전방 차량)에 의해 우측 전방 카메라의 시야각 중 일부가 가려짐으로써, 우측 전방 카메라의 타차량이 검출되지 않는 경우에도, 우측 전방 카메라의 영역을 타차량이 통과한 것으로 결정할 수 있다. 우측 전방 카메라의 영역을 타차량이 통과한 경우, 차량은 동작 1711에서 우측 전방 카메라의 샘플링 동작을 중 단할 수 있다. 차량은 우측 전방 카메라의 샘플링 동작을 중단하고, 우측 측방 카메라의 샘플링 동작만을 수행 함으로써, 복수의 카메라들의 운용을 위해 소모되는 전력을 감소시킬 수 있다. 동작 1713에서, 차량은 타차량이 충돌 예상 위치를 통과하였는지 여부를 결정할 수 있다. 프로세서, 및/또 는 카메라 모듈은 우측 측방 카메라를 이용하여 감지되는 타차량의 위치 정보에 기반하여, 타차량이 충돌 예상위치를 통과하였는지 여부를 결정할 수 있다. 타차량이 충돌 예상 위치를 통과한 경우, 차량은 1715에서 우측 측방 카메라의 샘플링을 중단할 수 있다. 타차량이 자차보다 먼저 충돌 예상 위치를 통과할 예정이 아닌 경우, 차량은 동작 1717에서 충돌 예상 위치를 통과하도록 주행할 수 있다. 동작 1717은, 도 12의 동작 1211과 동일할 수 있다. 이하 도 18 및 도 19에서는, 자차에 후면 측방 카메라가 구비된 경우에 타차량의 주행 정보를 획득하는 예시에 대해 개시한다. 도 18은 다양한 실시예들에 따른 차량에서 후면 측방 카메라를 이용하여 타차량 정보를 획득하는 흐름도이다. 이하 실시예에서 각 동작들은 순차적으로 수행될 수도 있으나, 반드시 순차적으로 수행되는 것은 아니다. 예를 들어, 각 동작들의 순서가 변경될 수도 있으며, 적어도 두 동작들이 병렬적으로 수행될 수도 있다. 여기에서, 차량은 도 9의 전자 장치를 포함할 수 있다. 이하에서 도 18의 적어도 일부 동작은, 도 19를 참조하여 설 명한다. 도 19는 다양한 실시예들에 따른 차량에서 후면 측방 카메라를 이용하여 타차량 정보를 획득하는 예시 도이다. 도 18을 참조하면, 차량은 동작 1801에서 후면 측방 카메라를 이용하여 타차량의 정보를 획득할 수 있다. 예를 들어, 차량의 전자 장치에 포함된 프로세서, 및/또는 카메라 모듈은, 도 19에 도시된 바와 같이, 자 차의 후면 측방 카메라를 구동하여 탐지 영역중 적어도 일부 영역을 모니터링함으로써, 타차 량의 정보를 획득할 수 있다. 동작 1803에서, 차량은 탐지 영역에 대한 후면 측방 카메라의 시야각이 차단되는지 여부를 결정할 수 있다. 예 를 들어, 프로세서, 및/또는 카메라 모듈은, 도 19에 도시된 바와 같이, 후면 측방 카메라의 시야각이 인접 차량들(1411, 1414, 1415, 1416)에 의해 가려짐으로써, 탐지 영역을 촬영할 수 없게 되는지 여부 를 결정할 수 있다. 탐지 영역에 대한 후면 측방 카메라의 시야각이 차단되지 않은 경우, 차량은 동작 1801로 되돌아갈 수 있다. 예 를 들어, 프로세서, 및/또는 카메라 모듈은, 도 19에 도시된 바와 같이, 인접 차선의 차량 1과 인접 차선의 차량 2 사이의 공간, 및 반대 차선의 차량 1과 반대 차선의 차량 2 사이의 공간 을 통해 후면 측방 카메라로 탐지 영역을 촬영할 수 있는 경우, 후면 측방 카메라를 이용하여 타 차량의 정보를 획득할 수 있다. 탐지 영역에 대한 후면 측방 카메라의 시야각이 차단되는 경우, 차량은 동작 1805에서 후면 측방 카메라의 동작 을 정지할 수 있다. 예를 들어, 반대 차선의 차량 1의 이동으로 인해, 반대 차선의 차량1과 반대 차선의 차량 2 사이의 공간이 축소됨으로써, 후면 측방 카메라로 인접 차량들 사이의 빈 공간을 통 해 탐지 영역을 촬영할 수 없는 경우, 프로세서, 및/또는 카메라 모듈은, 후면 측방 카메라의 동작을 정지시킬 수 있다. 동작 1807에서, 차량은 좌측 측방 카메라 및/또는 좌측 전방 카메라를 이용하여 타차량의 정보를 획득할 수 있 다. 예를 들어, 프로세서, 및/또는 카메라 모듈은, 도 19에 도시된 바와 같이, 후면 측방 카메라 의 동작을 정지시키면서, 좌측 측방 카메라가 구동되도록 제어하고, 좌측 측방 카메라로 인접 차선의 차량과 전방 차량 사이의 공간을 통해 탐지 영역중 적어도 일부 영역을 모니터링함으 로써, 타차량의 정보를 획득할 수 있다. 다른 예로, 프로세서, 및/또는 카메라 모듈은, 좌측 측방 카메라와 좌측 전방 카메라를 이용하여 탐지 영역중 적어도 일부 영역을 모니터링함으로 써, 타차량의 정보를 획득할 수 있다. 좌측 측방 카메라와 좌측 전방 카메라는 동시에 구동될 수도 있고, 순차적으로 구동될 수 있다. 일실시예에 따르면, 좌측 측방 카메라 및/또는 좌측 전방 카메라를 이 용하여 타차량의 정보를 획득하는 동작은, 도 10의 적어도 일부 동작, 도 13a 및 도 13b의 적어도 일부 동작, 또는 도 15의 적어도 일부 동작을 포함할 수 있다. 도 20은 다양한 실시예들에 따른 차량에서 보행자에 의한 카메라의 시야각 차단을 고려하여 타차량의 정보를 획 득하는 흐름도이다. 이하 실시예에서 각 동작들은 순차적으로 수행될 수도 있으나, 반드시 순차적으로 수행되는 것은 아니다. 예를 들어, 각 동작들의 순서가 변경될 수도 있으며, 적어도 두 동작들이 병렬적으로 수행될 수도 있다. 여기에서, 차량은 도 9의 전자 장치를 포함할 수 있다. 이하에서 도 20의 적어도 일부 동작은, 도 21을 참조하여 설명한다. 도 21은 다양한 실시예들에 따른 차량에서 보행자에 의한 카메라의 시야각 차단을 고 려하여 타차량의 정보를 획득하는 예시도이다. 도 20을 참조하면, 차량은 동작 2001에서 보행자에 의해 카메라의 시야각 중 적어도 일부가 차단되는지 여부를 결정할 수 있다. 일실시예에 따르면, 차량의 전자 장치에 포함되는 프로세서, 및/또는 카메라 모듈 은 차량에 포함된 복수의 카메라들을 이용하여 탐지 영역을 모니터링하는 중에, 복수의 카메라들에 대응되 는 시야각 중 적어도 일부 시야각이 차단되는지 여부를 결정할 수 있다. 예를 들어, 차량은 좌측 측방 카메라, 좌측 전방 카메라, 및 우측 전방 카메라 각각을 통해 획득되는 이미지들을 합성하여 도 21에 도시된 바와 같은 하나의 이미지를 획득할 수 있다. 차량은 획득된 이미지를 분석하여, 타차량의 정보를 획득하면서, 보행 자에 의해 우측 측방 카메라의 시야각 중 적어도 일부 시야각이 차단되었음을 감지할 수 있다. 동작 2003에서, 차량은 보행자 속도에 기반하여 카메라의 시야각 중 지정된 크기 이상의 시야각이 차단되는 시 간을 예측할 수 있다. 예를 들어, 프로세서, 및/또는 카메라 모듈은 복수의 카메라들을 통해 획득되 는 이미지들을 분석하여 보행자의 속도를 추정하고, 보행자 속도에 기반하여 보행자에 의해 복수의 카메라들에 대응되는 전체 시야각 중 지정된 크기 이상의 시야각이 차단될 것으로 예상되는 시점 및/또는 시간 구간을 결정 할 수 있다. 동작 2005에서, 차량은 예측 시간 동안에 시야각이 차단된 카메라를 오프시킬 수 있다. 예를 들어, 프로세서 , 및/또는 카메라 모듈은 도 21에 도시된 바와 같이, 보행자에 의해 좌측 측방 카메라의 일부 시야각, 좌측 전방 카메라의 전체 시야각, 및 우측 전방 카메라의 일부 시야각이 차단되는 동안, 전체 시 야각이 차단된 좌측 전방 카메라를 오프시킬 수 있다. 예컨대, 프로세서, 및/또는 카메라 모듈은 좌측 전방 카메라의 전체 시야각이 차단된 동안 좌측 전방 카메라의 샘플링 동작을 중단할 수 있다. 전방 카메라 의 오프는, 전방 카메라의 비활성화를 의미하거나, 또는 활성화 상태에 있는 전방 카메라의 샘플링 동작 중단을 의미할 수 있다. 동작 2007에서, 차량은 적어도 일부 시야각이 가려지지 않은 카메라를 이용하여 타차량의 정보를 획득할 수 있 다. 예를 들어, 프로세서, 및/또는 카메라 모듈은, 좌측 전방 카메라가 오프된 동안에 보행자에 의해 전체 시야각이 차단되지 않은 좌측 측방 카메라 및 우측 전방 카메라를 이용하여 타차량의 정보를 획득할 수 있 다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은, 좌측 측방 카메라의 시야각 중 보행자에 의해 차단되지 않은 시야각에 대응되는 픽셀들, 및 우측 전방 카메라의 시야각 중 보행자에 의해 차단되지 않은 시야각에 대응되는 픽셀들에 대해서만 샘플링을 수행할 수 있다. 일실시예에 따르며, 좌측 전방 카메라는, 예측 시간이 경과된 후 다시 구동될 수 있다. 예를 들어, 도 21에 도시된 바와 같이, 보행자에 의해 좌측 전방 카메 라의 시야각이 차단되지 않은 경우, 프로세서, 및/또는 카메라 모듈은, 좌측 전방 카메라의 샘플링을 수행하여 타차량의 정보를 획득할 수 있다. 일실시예에 따르면, 프로세서, 및/또는 카메라 모듈은, 타차량의 정보를 기반으로 타차량과 자차의 충돌 예상 위치를 분석하고, 타차량 및 자차 각각이 충돌 예상 위치 까지 이동하는데 소요되는 시간을 계산함으로써, 자차의 속도를 조절 및/또는 유지할 수 있다. 상술한 바와 같이, 본 개시물의 다양한 실시예들에 따른 차량은 램프에 포함된 복수의 카메라들을 이용하여 자 율 주행을 수행함으로써, 종래의 룸미러 주변에 배치된 카메라로 감지하지 못한 오브젝트를 감지하여, 충돌 사 고가 발생될 가능성을 낮출 수 있다. 예를 들어, 차량은 램프에 포함된 복수의 카메라들을 이용하여 오브젝트를 탐지함으로써, 높이가 낮은 오브젝트를 탐지할 수 있다. 또한, 본 개시물의 다양한 실시예들에 따른 차량은 복 수의 카메라들을 선택적으로 구동함으로써, 복수의 카메라들에 의해 소모되는 전력을 최소화할 수 있다. 또한, 또한, 본 개시물의 다양한 실시예들에 따른 차량은 인접 차량의 시야각 차단에 따라 샘플링 레이트를 조절함으 로써, 타차량에 대한 탐지 정확도를 향상시킴으로써, 타차량과의 충돌 사고가 발생될 가능성을 낮출 수 있다."}
{"patent_id": "10-2020-0003163", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 5G 통신 시스템에서 자율 주행 차량과 5G 네트워크의 기본동작의 일 예를 나타낸다. 도 2는 5G 통신 시스템에서 자율 주행 차량과 5G 네트워크의 응용 동작의 일 예를 나타낸다. 도 3 내지 도 6은 5G 통신을 이용한 자율 주행 차량 동작의 일 예를 나타낸다. 도 7a는 다양한 실시예들에 따른 차량의 헤드 램프에 포함되는 센서들을 도시한다. 도 7b는 다양한 실시예들에 따른 헤드 램프 내 센서들의 FOV(field of view)를 도시한다. 도 8은 다양한 실시예들에 따른 차량의 제어 블럭도이다. 도 9는 다양한 실시예들에 따른 차량에 포함되는 전자 장치의 블럭도이다. 도 10은 다양한 실시예들에 따른 차량에서 카메라의 샘플링 레이트를 조절하여 타차량을 탐지하는 흐름도이다. 도 11은 다양한 실시예들에 따른 차량에서 타차량에 대해 예측된 이동 궤적을 검증하는 흐름도이다. 도 12는 다양한 실시예들에 따른 차량에서 타차량에 대해 예측된 이동 궤적에 기초하여 자율 주행을 수행하는 흐름도이다. 도 13a 및 도 13b는 다양한 실시예에 따른 차량에서 타차량의 주행 정보를 획득하는 흐름도이다. 도 14a 내지 도 14d는 다양한 실시예들에 따른 차량에서 타차량의 주행 정보를 획득하는 예시도이다. 도 15는 다양한 실시예들에 따른 차량에서 타차량의 주행 정보를 획득하는 흐름도이다. 도 16a 내지 도 16b는 다양한 실시예들에 따른 차량에서 타차량의 주행 정보를 획득하는 예시도이다. 도 17은 다양한 실시예들에 따른 차량에서 복수의 카메라를 운용하는 흐름도이다. 도 18은 다양한 실시예들에 따른 차량에서 후면 측방 카메라를 이용하여 타차량 정보를 획득하는 흐름도이다. 도 19는 다양한 실시예들에 따른 차량에서 후면 측방 카메라를 이용하여 타차량 정보를 획득하는 예시도이다. 도 20은 다양한 실시예들에 따른 차량에서 보행자에 의한 카메라의 시야각 차단을 고려하여 타차량의 정보를 획 득하는 흐름도이다. 도 21은 다양한 실시예들에 따른 차량에서 보행자에 의한 카메라의 시야각 차단을 고려하여 타차량의 정보를 획 득하는 예시도이다."}
