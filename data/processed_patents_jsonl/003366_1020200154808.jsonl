{"patent_id": "10-2020-0154808", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0067973", "출원번호": "10-2020-0154808", "발명의 명칭": "인공지능 로봇 교육 장치 및 그 제어 방법", "출원인": "지니주식회사", "발명자": "이원용"}}
{"patent_id": "10-2020-0154808", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 단말에 목표 경로 값이 입력되면 사전 학습된 제1 DNN 모델에 따라 동작하는 제1 관절로봇과,상기 사용자 단말에서 목표 지점 값이 산출되면 사전 학습된 제2 DNN 모델에 따라 동작하는 제2 관절로봇과, 상기 제2 관절로봇의 동작 범위 영역에 있는 타켓을 촬영하여 타겟 영상을 상기 사용자 단말로 전송하는 팬 틸트 카메라 로봇을 포함하는 인공지능 로봇 교육 장치."}
{"patent_id": "10-2020-0154808", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 관절로봇, 상기 제2 관절로봇 및 상기 팬 틸트 카메라 로봇은 조립형 블록 플레이트에 설치 가능하여,상기 조립형 블록 플레이트에서 각 로봇의 배치 위치를 다르게 할 수 있는 것을 특징으로 하는 인공지능 로봇교육 장치."}
{"patent_id": "10-2020-0154808", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "인공지능 로봇 교육 장치의 관절로봇 제어 방법에 있어서, 로봇 구조(링크 길이, 관절 각도)에 대한 순기구학(Forward Kinematic) 해석을 통해 목표 위치 좌표(Xi, Yi,Zi)에 대한 로봇의 관절 각도(αi, βi, γi)를 계산하는 단계와,목표 위치 좌표(입력 데이터) 및 상기 계산한 관절 각도(출력 데이터)로 구성된 학습 데이터 셋(set)을 이용하여 DNN(Deep Neural Network) 모델을 학습시키는 단계와,목표 경로 값을 입력받으면 상기 학습된 DNN 모델을 이용해 관절로봇의 동작을 제어하는 단계를 포함하는 방법."}
{"patent_id": "10-2020-0154808", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "인공지능 로봇 교육 장치에서 수행되는 관절로봇 제어 방법에 있어서, 로봇 구조(링크 길이, 관절 각도)에 대한 순기구학(Forward Kinematic) 해석을 통해 목표 위치 좌표(Xi, Yi,Zi)에 대한 로봇의 관절 각도(αi, βi, γi)를 계산하는 단계와,목표 위치 좌표(입력 데이터) 및 상기 계산한 관절 각도(출력 데이터)로 구성된 학습 데이터 셋(set)을 이용하여 DNN(Deep Neural Network) 모델을 학습시키는 단계와,상기 관절로봇의 동작 범위 영역에 있는 타겟을 촬영한 타겟 영상을 입력받는 단계와,상기 타겟 영상을 분석하여 상기 타겟 영상 내의 목표 지점 값을 산출하는 단계와,상기 목표 지점 값을 상기 학습된 DNN 모델에 입력하고 상기 학습된 DNN 모델을 분석하여 관절로봇의 동작을 제어하는 단계를 포함하는 방법."}
{"patent_id": "10-2020-0154808", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 관절로봇 제어 기술에 관한 것으로서, 상세하게는 다관절 로봇을 제어할 수 있는 인공지능 기반 모델 링을 통해 복잡한 수학 없이도 다관절 로봇 제어를 실연하고 학생들에게 교육할 수 있는 인공지능 로봇 교육 장 치 및 그 제어 방법에 관한 것이다. 이를 위해, 본 발명에 따른 인공지능 로봇 교육 장치는 사용자 단말에 목표 경로 값이 입력되면 사전 학습된 제1 DNN 모델에 따라 동작하는 제1 관절로봇과, 상기 사용자 단말에서 목표 지점 값이 산출되면 사전 학습된 제2 DNN 모델에 따라 동작하는 제2 관절로봇과, 상기 제2 관절로봇의 동작 범위 영역에 있는 타켓을 촬영하여 타겟 영상 을 상기 사용자 단말로 전송하는 팬 틸트 카메라 로봇을 포함한다."}
{"patent_id": "10-2020-0154808", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 관절로봇 제어 기술에 관한 것으로서, 상세하게는 다관절 로봇을 제어할 수 있는 인공지능 기반 모델 링을 통해 복잡한 수학 없이도 다관절 로봇 제어를 실연하고 다관절 로봇을 학생들에게 교육할 수 있는 인공지 능 로봇 교육 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0154808", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "수직 다관절 로봇을 제어한다는 것은 공간상에서 말단(end-effector)의 위치를 제어하는 것을 말한다. 목표위치 (x,y,z)에 도달할 수 있게 하기 위해 역기구학(Inverse Kinematics)을 해석하여 로봇 관절의 각도(θ1,θ2,θ3, ...)를 계산해야 한다. 이러한 과정을 다관절 로봇의 제어를 위한 모델링이라고 한다, 그러나 이러한 과정은 복잡도가 매우 높아 일반 대학생도 풀기 어렵기 때문에 관절 로봇을 초중고 학생에게 교 육한다는 것은 매우 어려운 일이다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제1980603호"}
{"patent_id": "10-2020-0154808", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위해 창안된 것으로서, 본 발명의 목적은 복잡한 수학 없이도 학생들 에게 관절 로봇의 제어를 실연하고 교육할 수 있도록 하는 것이다."}
{"patent_id": "10-2020-0154808", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이를 위해, 본 발명에 따른 인공지능 로봇 교육 장치는 사용자 단말에 목표 경로 값이 입력되면 사전 학습된 제 1 DNN 모델에 따라 동작하는 제1 관절로봇과, 상기 사용자 단말에서 목표 지점 값이 산출되면 사전 학습된 제2 DNN 모델에 따라 동작하는 제2 관절로봇과, 상기 제2 관절로봇의 동작 범위 영역에 있는 타켓을 촬영하여 타겟 영상을 상기 사용자 단말로 전송하는 팬 틸트 카메라 로봇을 포함한다. 여기서, 상기 제1 관절로봇, 상기 제2 관절로봇 및 상기 팬 틸트 카메라 로봇은 조립형 블록 플레이트에 설치 가능하여, 상기 조립형 블록 플레이트에서 각 로봇의 배치 위치를 다르게 할 수 있는 것을 특징으로 한다. 또한, 본 발명에 따른 인공지능 로봇 교육 장치의 관절로봇 제어 방법은 로봇 구조(링크 길이, 관절 각도)에 대 한 순기구학(Forward Kinematic) 해석을 통해 목표 위치 좌표(Xi, Yi, Zi)에 대한 로봇의 관절 각도(αi, βi, γi)를 계산하는 단계와, 목표 위치 좌표(입력 데이터) 및 상기 계산한 관절 각도(출력 데이터)로 구성된 학습 데이터 셋(set)을 이용하여 DNN(Deep Neural Network) 모델을 학습시키는 단계와, 목표 경로 값을 입력받으면 상기 학습된 DNN 모델을 이용해 관절로봇의 동작을 제어하는 단계를 포함한다. 또한, 본 발명에 따른 인공지능 로봇 교육 장치의 관절로봇 제어 방법은 로봇 구조(링크 길이, 관절 각도)에 대 한 순기구학(Forward Kinematic) 해석을 통해 목표 위치 좌표(Xi, Yi, Zi)에 대한 로봇의 관절 각도(αi, βi, γi)를 계산하는 단계와, 목표 위치 좌표(입력 데이터) 및 상기 계산한 관절 각도(출력 데이터)로 구성된 학습 데이터 셋(set)을 이용하여 DNN(Deep Neural Network) 모델을 학습시키는 단계와, 상기 관절로봇의 동작 범위 영역에 있는 타겟을 촬영한 타겟 영상을 입력받는 단계와, 상기 타겟 영상을 분석하여 상기 타겟 영상 내의 목 표 지점 값을 산출하는 단계와, 상기 목표 지점 값을 상기 학습된 DNN 모델에 입력하고 상기 학습된 DNN 모델을 분석하여 관절로봇의 동작을 제어하는 단계를 포함한다."}
{"patent_id": "10-2020-0154808", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이, 본 발명은 역기구학(inverse kinematics)에 의한 복잡한 수학식을 계산하지 않아도 지도학습 기반 모델링을 통해 관절 로봇의 끝점(end-effector)을 원하는 위치로 제어할 수 있어서 학생들에게 쉽고 간단 하게 관절 로봇의 제어를 실연하고 교육할 수 있는 효과가 있다. 또한, 관절 로봇 제어를 위한 딥러닝에서는 학습 데이터를 확보하는 것이 매우 중요하고 어려운 과정이지만, 본 발명에 따른 인공지능 로봇 교육 장치는 순기구학(forward kinematics) 해석을 통해 교육용으로 충분히 활용 가 능한 학습 데이터를 쉽고 빠르게 생성할 수 있는 효과가 있다."}
{"patent_id": "10-2020-0154808", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통 하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 \"……부\", \"…… 모듈\" 의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미 하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 이하, 도면을 참조로 하여 본 발명의 실시예에 따른 인공지능 로봇 교육 장치 및 그 제어 방법에 대하여 상세히 설명한다. 도 1은 본 발명에 따른 인공지능 로봇 교육 장치를 구성하는 로봇을 나타내고, 도 2는 본 발명에 따른 인공지능 로봇 교육 장치를 나타낸 것이다. 도 1을 참조하면, (a)는 펜(pen)을 잡고 사용자가 지정한 글자나 그림을 쓰거나 그릴 수 있는 관절 로봇이고, (b)는 임의의 위치에 놓여 있는 오브젝트(공, 주사위 등)를 집어 올릴 수 있는 관절 로봇이고, (c)는 타겟 위치 로 이동하여 타겟을 촬영할 수 있는 팬 틸트(pan-tilt) 카메라 로봇이다. 설명의 편의상, (a)의 펜 그립퍼(pen gripper) 관절 로봇을 제1 관절 로봇으로, (b)의 그립퍼(gripper) 관절 로 봇을 제2 관절 로봇으로 호칭한다. 제1 관절 로봇 및 제2 관절 로봇은 모두 3축 관절 로봇으로서, 제1 관절 로봇의 말단에는 펜 그립퍼가 장착되어 있고, 제2 관절 로봇의 말단에는 그립퍼가 장착되어 있으나, 그 말단에는 다양한 말단장치가 장착될 수 있다. 예를 들어, 관절 로봇의 말단에 실로폰을 치기 위한 실로폰 채가 장착될 수 있다. (c)의 팬 틸트 카메라 로봇은 2축 관절 로봇으로서, 스테레오 카메라, 밝기 센서, LED 디스플레이 등 을 구비하고 있다. 팬 틸트 카메라 로봇은 스테레오 카메라를 이용해 제2 관절 로봇의 동작 범위 영역에 있는 타켓을 촬영하여 타겟 영상을 획득한다. 팬 틸트 카메라 로봇은 밝기 센서를 통해 주변 밝기를 감지해 스테레오 카메라의 촬영 설정값을 변경하고, LED 디스플레이를 통해 동작 상태를 표시한다. 도 1에 도시된 제1 관절 로봇, 제2 관절 로봇 및 팬 틸트 카메라 로봇은 조립형 블록 플레이트에 설치 가능 하다. 조립형 블록 플레이트의 임의의 위치에 각 로봇의 베이스를 끼워 설치할 수 있기 때문에, 각 로봇의 상호 배치 관계를 다양하게 할 수 있다. 도 2를 참조하면, 제1 관절 로봇, 제2 관절 로봇 및 팬 틸트 카메라 로봇이 조립형 블록 플레이트 에 설치된 상태로 서로 배치되어 본 발명에 따른 인공지능 로봇 교육 장치를 구성하고 있다. 제1 관절 로봇, 제2 관절 로봇 및 팬 틸트 카메라 로봇은 각각 사용자 단말에 연결되어 있다. 사용자 단말은 각 로봇(20, 30, 40)과 통신하면서 각 로봇의 동작을 제어한다. 사용자 단말은 학습 데이터를 이용해 DNN(Deep Neural Network) 모델을 학습시키고, 학습된 DNN 모델을 이 용해 제1 관절 로봇 및 제2 관절 로봇의 동작을 제어한다. 설명의 편의상, 제1 관절 로봇의 동작 제어에 사용되는 DNN 모델을 제1 DNN 모델로, 제2 관절 로봇의 동작 제어에 사용되는 DNN 모델을 제2 DNN 모델로 호칭한다. 사용자 단말은 목표 경로 값을 입력받아 사전 학습된 제1 DNN 모델에 따라 제1 관절 로봇의 동작을 제 어한다. 제1 DNN 모델의 출력 값에 따라 관절각도가 결정되고, 제1 관절 로봇이 결정된 관절각도에 따라 움 직이면서 펜 그립퍼에 삽입된 펜이 보드 상에 목표 경로 값에 따른 글자나 그림을 쓰거나 그리게 된다. 또한, 사용자 단말은 팬 틸트 카메라 로봇으로부터 타겟 영상을 수신하여 목표 지점 값을 산출하고, 목표 지점 값을 사전 학습된 제2 DNN 모델에 입력하여 제2 DNN 모델의 출력 값을 이용해 제2 관절 로봇의 동작을 제어한다. 즉, 제2 DNN 모델의 출력 값에 따라 관절각도가 결정되고, 제2 관절 로봇이 결정된 관절각도에 따라 움직이 면서 그립퍼가 목표 지점 값에 위치한 오브젝트를 집어 올리게 된다. 본 발명에 따른 사용자 단말은 퍼스널 컴퓨터, 노트북 등이 될 수 있으나, 이에 한정되는 것은 아니며 각 로봇과 데이터 통신을 수행하며 딥러닝 알고리즘을 실행할 수 있는 장치라면 어떠한 종류의 기기라도 가능하다. 도 3은 본 발명에 따른 인공지능 로봇 교육 장치의 제1 관절 로봇를 제어하는 과정을 나타낸 것이다. 도 3을 참조하면, 먼저 본 발명에 따른 제1 관절 로봇을 제어하기 위해서는 제1 관절 로봇의 동작 제어 에 사용되는 제1 DNN 모델을 생성하는 과정이 필요하다. 제1 DNN 모델을 생성하는 과정은 학습 데이터 생성 단 계(S10) 및 제1 DNN 모델 학습 단계(S12)로 구성된다. 학습 데이터 생성 단계(S10) DNN(Deep Neural Network) 모델 학습을 위한 학습 데이터의 경우 일반적으로 자연 발생적인 데이터(이미지, 음 성 등)를 매우 많이 준비해야 하지만, 본 발명의 실시예에서는 로봇 구조(링크 길이, 관절 각도)에 대한 순기구 학(Forward Kinematic) 해석을 통해 쉽고 빠르게 충분한 양의 학습 데이터를 생성할 수 있다. 즉, 순기구학 해석을 통해 목표 위치 좌표(Xi, Yi, Zi)에 대한 로봇의 관절 각도(αi, βi, γi)를 구할 수 있 어서, 목표 위치 좌표(입력 데이터) 및 관절 각도(출력 데이터)로 구성된 학습 데이터 셋(set)을 생성할 수 있 다. 제1 DNN 모델 학습 단계(S12) 관절 로봇을 회전이 없는 3축으로 가정하여, 입력 노드(input node) 3개, 출력 노드(output node) 3개, 은닉층 (hidden layer) 1~2개, 은닉층의 노드 20~100개 정도로 DNN 구조를 만든 후 학습 데이터 셋으로 학습시켜 DNM 모델을 생성한다. 이와 같이, 학습 데이터 생성 단계(S10) 및 제1 DNN 모델 학습 단계(S12)를 통해 제1 DNN 모델이 생성되면, 제1 DNN 모델을 제1 관절 로봇의 제어에 사용한다. 목표 경로 지정 단계(S14) 사용자 단말에 목표 경로 값을 입력하면, 사용자 단말은 목표 경로 값을 제1 DNN 모델에 넣어 제1 관 절 로봇의 관절 각도 값을 출력한다. 목표 경로 값이란 제1 관절 로봇의 펜 그립퍼에 삽입된 펜 이 보드 상에 그리는 글자 또는 그림의 궤적 좌표를 의미한다. 본 발명의 실시예에서, 사용자 단말에 입력장치(마우스)를 통해 글자 또는 그림을 입력하게 되면, 입력된 글자 또는 그림의 궤적에 따른 좌표값이 자동 생성된다. 제1 관절 로봇 동작 단계(S16) 사용자 단말은 제1 DNN 모델로부터 출력되는 관절 각도 값을 이용해 제1 관절 로봇의 동작을 제어한다. 제1 관절 로봇은 사용자 단말로부터 관절 각도 값에 따른 제어신호를 수신하여 3축 관절의각도를 변화시켜 이동하면서 목표 경로 값에 대응하는 글자나 그림을 보드 상에 쓰거나 그리게 된다. 도 4는 본 발명에 따른 인공지능 로봇 교육 장치의 제2 관절 로봇을 제어하는 과정을 나타낸 것이다. 도 4를 참조하면, 먼저 본 발명에 따른 제2 관절 로봇을 제어하기 위해서는 제2 관절 로봇의 동작 제어 에 사용되는 제2 DNN 모델을 생성하는 과정이 필요하다. 제2 DNN 모델을 생성하는 과정은 학습 데이터 생성 단 계(S20) 및 제2 DNN 모델 학습 단계(S22)로 구성된다. 학습 데이터 생성 단계(S20) 및 제2 DNN 모델 학습 단계(S22)은 도 3의 학습 데이터 생성 단계(S10) 및 제1 DNN 모델 학습 단계(S12)와 동일하므로 생략한다. 학습 데이터 생성 단계(S20) 및 제2 DNN 모델 학습 단계(S22)를 통해 제2 DNN 모델이 생성되면, 제2 DNN 모델을 제2 관절 로봇의 제어에 사용한다. 한편, 사용자 단말은 팬 틸트 카메라 로봇의 동작을 제어하여 팬 틸트 카메라 로봇이 제2 관절 로 봇의 동작 범위 영역에 있는 타겟을 촬영하도록 한다. 팬 틸트 카메라 로봇은 사용자 단말의 제어 신호에 따라 2축 관절의 각도를 변화시켜 이동한 후 타겟 영상을 촬영한다(S24). 사용자 단말은 팬 틸트 카메라 로봇으로부터 타겟 영상을 수신하여 타겟 영상을 분석한다(S26). 사용 자 단말은 영상 인식 소프트웨어를 이용해 타겟 영상 내의 오브젝트를 식별하고, 식별한 오브젝트의 위치 좌표 값인 목표 지점 값을 산출한다(S28). 사용자 단말은 목표 지점 값을 제2 DNN 모델에 입력하고 제2 DNN 모델로부터 출력되는 관절 각도 값을 이 용해 제2 관절 로봇의 동작을 제어한다(S30). 제2 관절 로봇은 사용자 단말로부터 관절 각도 값에 따른 제어신호를 수신하여 3축 관절의 각도를 변화시켜 이동하면서 그립퍼를 통해 목표 지점 값에 위치하는 오 브젝트를 집어 올리게 된다. 이상에서 설명한 본 발명의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 발명의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2020-0154808", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 인공지능 로봇 교육 장치를 구성하는 로봇을 나타낸 도면. 도 2는 본 발명에 따른 인공지능 로봇 교육 장치를 나타낸 도면. 도 3은 본 발명에 따른 인공지능 로봇 교육 장치의 제1 관절로봇를 제어하는 과정을 나타낸 도면. 도 4는 본 발명에 따른 인공지능 로봇 교육 장치의 제2 관절로봇을 제어하는 과정을 나타낸 도면."}
