{"patent_id": "10-2021-0154849", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0068744", "출원번호": "10-2021-0154849", "발명의 명칭": "AI를 이용한 가상 스타일 추천 서버", "출원인": "성인규", "발명자": "성인규"}}
{"patent_id": "10-2021-0154849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기설정된 AI(Artificial Intelligence) 알고리즘에 의해 이미지 데이터 셋을 생성하고, 상기 생성된 이미지 데이터 셋을 학습하는 학습 모듈;사용자 단말장치로부터 사용자 이미지 및 스타일 이미지를 전송받는 사용자 인터페이스 모듈; 및상기 학습된 이미지 데이터 셋에 의해 상기 사용자 이미지 및 상기 스타일 이미지를 합성하여 추천 이미지를 생성하는 추론 모듈;을 포함하며,상기 사용자 인터페이스 모듈은, 상기 생성된 추천 이미지를 상기 사용자 단말장치로 전송하는 것을 특징으로하는 AI를 이용한 가상 스타일 추천 서버."}
{"patent_id": "10-2021-0154849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 학습 모듈은,기설정된 범위의 상수에 의해 연산자를 생성하는 연산자 생성부;상기 생성된 연산자를 이용하여 다수의 이미지를 생성하는 이미지 생성부; 및상기 생성된 다수의 이미지를 기설정된 유형에 따라 분류하고, 상기 분류된 이미지에 점수(score)를 부여하는분류부;를 포함하는 것을 특징으로 하는 AI를 이용한 가상 스타일 추천 서버."}
{"patent_id": "10-2021-0154849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 학습 모듈은, 상기 분류부에 의해 이미지에 부여된 점수를 상기 연산자 생성부로 피드백하여 상기 연산자를 학습시키는 것을 특징으로 하는 AI를 이용한 가상 스타일 추천 서버."}
{"patent_id": "10-2021-0154849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 학습 모듈은,랜덤 벡터를 생성하는 랜덤 벡터 입력부;상기 생성된 랜덤 벡터를 이용하여 다수의 이미지를 생성하는 이미지 생성부;임의로 생성된 임의 이미지 데이터 셋을 그라운드 트루스(Ground Truth)로 입력받고, 상기 생성된 이미지에 상기 그라운드 투루스를 반영하여 조정하며, 상기 조정된 이미지 및 상기 이미지 생성부에서 생성된 이미지를 기설정된 유형에 따라 분류하고, 상기 분류된 이미지에 점수를 부여하는 판별부;를 포함하는 것을 특징으로 하는AI를 이용한 가상 스타일 추천 서버."}
{"patent_id": "10-2021-0154849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0068744-3-제 1 항에 있어서,상기 학습 모듈은,랜덤 벡터를 생성하는 랜덤 벡터 입력부;상기 생성된 랜덤 벡터를 이용하여 다수의 이미지를 생성하는 이미지 생성부;상기 생성된 다수의 이미지 각각이 원하는 이미지 범주에 속하는지의 여부를 판별하여 판별 결과를 상기 랜덤벡터 입력기로 피드백하는 분류부; 및상기 생성된 다수의 이미지를 기설정된 유형에 따라 분류하고, 상기 분류된 이미지에 점수를 부여하는 판별부;를 포함하는 것을 특징으로 하는 AI를 이용한 가상 스타일 추천 서버."}
{"patent_id": "10-2021-0154849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항 및 제 5 항 중 어느 한 항에 있어서,상기 판별부에 의해 부여된 점수는 상기 이미지 생성부로 피드백되어, 상기 이미지 생성부 내의 맵핑 네트워크를 학습시키는 것을 특징으로 하는 AI를 이용한 가상 스타일 추천 서버."}
{"patent_id": "10-2021-0154849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,랜덤 벡터를 생성하는 랜덤 벡터 입력부;각각 기설정된 특정 이미지를 생성하는 복수의 이미지 생성자들을 포함하고, 상기 이미지 생성자 각각은 복수의이미지 블록으로 구성되며, 상기 생성된 랜덤 벡터를 이용하여 다수의 이미지를 생성하는 이미지 생성부; 및상기 복수의 이미지 생성자 중 특정 이미지 생성자를 구성하는 이미지 블록 중 일부를 다른 이미지 생성자의 이미지 블록과 대체하는 생성자 변환부;를 포함하는 것을 특징으로 하는 AI를 이용한 가상 스타일 추천 서버."}
{"patent_id": "10-2021-0154849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 2항 내지 제 7 항 중 어느 하나의 항에 있어서,상기 이미지 생성기는, StyleGAN Generator인 것을 특징으로 하는 AI를 이용한 가상 스타일 추천 서버."}
{"patent_id": "10-2021-0154849", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 추론 모듈은, StarGan-v2 모델을 적용하여 상기 사용자 이미지 및 상기 스타일 이미지를 합성하여 상기 추천 이미지를 생성하는 것을 특징으로 하는 AI를 이용한 가상 스타일 추천 서버."}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "AI를 이용한 가상 스타일 추천 서버가 개시된다. 본 발명의 실시 예에 따른 AI를 이용한 가상 스타일 추천 서버 는, 기설정된 AI(Artificial Intelligence) 알고리즘에 의해 이미지 데이터 셋을 생성하고, 생성된 이미지 데이 터 셋을 학습하는 학습 모듈, 사용자 단말장치로부터 사용자 이미지 및 스타일 이미지를 전송받는 사용자 인터페 이스 모듈, 및 학습된 이미지 데이터 셋에 의해 사용자 이미지 및 스타일 이미지를 합성하여 추천 이미지를 생성 하는 추론 모듈을 포함하며, 사용자 인터페이스 모듈은 생성된 추천 이미지를 사용자 단말장치로 전송한다."}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 AI를 이용한 가상 스타일 추천 서버에 관한 것으로서, 보다 상세하게는, AI 알고리즘에 의해 생성된 이미지 데이터 셋이 적용되어 매우 자연스러운 가상 스타일의 추천이 가능한 AI를 이용한 가상 스타일 추천 서 버에 관한 것이다."}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(AI) 기반의 가상 피팅 서비스 경쟁이 매우 뜨겁다. 초기의 가상 피팅 서비스는 의류에 한정되어 제공 되었으나, 점차 확대되어 가발, 안경과 같은 액세서리를 포함하여 헤어스타일까지 가상 피팅 서비스로 제공되고 있다. 가상 피팅 서비스에서 사용자의 만족도를 높이는 가장 핵심적인 요소는 자연스러움이다. 그러므로, 합성 이미지 의 부자연스러움은 사용자의 만족도를 저해하는 아주 치명적인 문제점이라 볼 수 있다. 가상 헤어스타일 분야의 경우, 사전에 헤어스타일 데이터베이스(DB)를 구축한 후, 가상의 이미지에 덧붙여보거 나 혹은 사용자의 얼굴 이미지를 헤어스타일 DB로부터 선택된 이미지와 합성해 보는 형태가 일반적이다. 이러한 형태의 가상 헤어스타일 방식은 합성 이미지가 매우 부자연스럽고, 새로운 헤어스타일에 대한 즉각적인 적용이 어렵기 때문에, 사용자의 요구를 충족시키기에는 한계가 있다. 특히, 가상 헤어스타일 서비스에서는 머리카락의 변칙적인 특성으로 인하여 다른 가상 피팅 서비스보다 어려움 이 따른다. 보다 구체적으로, 머리카락은 기하학적인 구조로 그 형태를 특정하기가 어렵고, 사용자의 모질에 따 라서도 피팅 후의 느낌이 달라지기 때문에, 사용자가 원하는 가상 헤어스타일 서비스의 제공이 매우 어려운 문 제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내공개특허 제10-2020-0034027호(2020. 03. 31. 공개)"}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전술한 문제점을 해결하기 위하여 본 발명이 이루고자 하는 기술적 과제는, 변형된 StyleGAN Generator를 사용 하여 이미지 데이터 셋을 생성하고, 이에 적합한 합성 모델을 사용함으로써, 사용자가 원하는 스타일을 사용자 의 사진과 자연스럽게 매칭하여 제공하는 AI를 이용한 가상 스타일 추천 서버를 제시하는데 있다. 본 발명의 해결과제는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 해결과제들은 아래의 기 재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 기술적 과제를 해결하기 위한 수단으로서, 본 발명의 실시 예에 따른 AI를 이용한 가상 스타일 추천 서 버는, 기설정된 AI(Artificial Intelligence) 알고리즘에 의해 이미지 데이터 셋을 생성하고, 생성된 이미지 데 이터 셋을 학습하는 학습 모듈, 사용자 단말장치로부터 사용자 이미지 및 스타일 이미지를 전송받는 사용자 인 터페이스 모듈, 및 학습된 이미지 데이터 셋에 의해 사용자 이미지 및 스타일 이미지를 합성하여 추천 이미지를 생성하는 추론 모듈을 포함하며, 사용자 인터페이스 모듈은 생성된 추천 이미지를 사용자 단말장치로 전송한다. 바람직하게, 학습 모듈은, 기설정된 범위의 상수에 의해 연산자를 생성하는 연산자 생성부, 생성된 연산자를 이 용하여 다수의 이미지를 생성하는 이미지 생성부, 및 생성된 다수의 이미지를 기설정된 유형에 따라 분류하고, 분류된 이미지에 점수(score)를 부여하는 분류부를 포함할 수 있다. 또한 바람직하게, 학습 모듈은, 분류부에 의해 이미지에 부여된 점수를 연산자 생성부로 피드백하여 연산자를 학습시킬 수 있다. 또한 바람직하게, 학습 모듈은, 랜덤 벡터를 생성하는 랜덤 벡터 입력부, 생성된 랜덤 벡터를 이용하여 다수의 이미지를 생성하는 이미지 생성부, 임의로 생성된 임의 이미지 데이터 셋을 그라운드 트루스(Ground Truth)로입력받고, 생성된 이미지에 그라운드 투루스를 반영하여 조정하며, 조정된 이미지 및 이미지 생성부에서 생성된 이미지를 기설정된 유형에 따라 분류하고, 분류된 이미지에 점수를 부여하는 판별부를 포함할 수 있다. 또한 바람직하게, 학습 모듈은, 랜덤 벡터를 생성하는 랜덤 벡터 입력부, 생성된 랜덤 벡터를 이용하여 다수의 이미지를 생성하는 이미지 생성부, 생성된 다수의 이미지 각각이 원하는 이미지 범주에 속하는지의 여부를 판별 하여 판별 결과를 랜덤 벡터 입력기로 피드백하는 분류부, 및 생성된 다수의 이미지를 기설정된 유형에 따라 분 류하고, 분류된 이미지에 점수를 부여하는 판별부를 포함할 수 있다. 또한 바람직하게, 판별부에 의해 부여된 점수는 이미지 생성부로 피드백되어, 이미지 생성부 내의 맵핑 네트워 크를 학습시킬 수 있다. 또한 바람직하게, 랜덤 벡터를 생성하는 랜덤 벡터 입력부, 각각 기설정된 특정 이미지를 생성하는 복수의 이미 지 생성자들을 포함하고, 이미지 생성자 각각은 복수의 이미지 블록으로 구성되며, 생성된 랜덤 벡터를 이용하 여 다수의 이미지를 생성하는 이미지 생성부, 및 복수의 이미지 생성자 중 특정 이미지 생성자를 구성하는 이미 지 블록 중 일부를 다른 이미지 생성자의 이미지 블록과 대체하는 생성자 변환부를 포함할 수 있다. 또한 바람직하게, 이미지 생성기는, StyleGAN Generator일 수 있다. 또한 바람직하게, 추론 모듈은, StarGan-v2 모델을 적용하여 사용자 이미지 및 스타일 이미지를 합성하여 추천 이미지를 생성할 수 있다."}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 사용자로부터 사용자의 이미지와 스타일 이미지를 입력 받은 후, 두 이미지를 AI에 의해 합 성함으로써, 사용자 이미지에 사용자가 원하는 스타일이 자연스럽게 적용된 스타일 추천 이미지를 통해 사용자 에게 스타일을 추천하는 AI를 이용한 가상 스타일 추천 서버를 제공하는 효과가 있다. 또한, AI를 통해 특정한 이미지를 기반으로 하여 완전히 새로운 이미지를 생성해 낼 수 있음에 따라, 단순히 헤 어스타일에 그치지 않고 가상 성형, 및 가상 패션 시뮬레이션 등 다양한 분야에 활용 가능한 효과가 있다. 더불어, 특정한 특징을 가지는 이미지 데이터 셋을 대량으로 생성해 낼 수 있으므로, 관련 분야의 연구 및 개발 에 필요한 이미지 데이터 셋에 대한 데이터베이스를 손쉽게 구축할 수 있는 효과가 있다."}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이상의 본 발명의 목적들, 다른 목적들, 특징들 및 이점들은 첨부된 도면과 관련된 이하의 바람직한 실시 예들 을 통해서 쉽게 이해될 것이다. 그러나 본 발명은 여기서 설명되는 실시 예들에 한정되지 않고 다른 형태로 구 체화될 수도 있다. 오히려, 여기서 소개되는 실시 예들은 개시된 내용이 철저하고 완전해질 수 있도록 그리고 당업자에게 본 발명의 사상이 충분히 전달될 수 있도록 하기 위해 제공되는 것이다. 본 명세서에서, 어떤 구성요소가 다른 구성요소 상에 있다고 언급되는 경우에 그것은 다른 구성요소 상에 직접 형성될 수 있거나 또는 그들 사이에 제 3의 구성요소가 개재될 수도 있다는 것을 의미한다. 또한, 도면들에 있 어서, 구성요소들의 두께는 기술적 내용의 효과적인 설명을 위해 과장된 것이다. 어떤 엘리먼트, 구성요소, 장치, 또는 시스템이 프로그램 또는 소프트웨어로 이루어진 구성요소를 포함한다고 언급되는 경우, 명시적인 언급이 없더라도, 그 엘리먼트, 구성요소, 장치, 또는 시스템은 그 프로그램 또는 소 프트웨어가 실행 또는 동작하는데 필요한 하드웨어(예를 들면, 메모리, CPU 등)나 다른 프로그램 또는 소프트웨 어(예를 들면 운영체제나 하드웨어를 구동하는데 필요한 드라이버 등)를 포함하는 것으로 이해되어야 할 것이다. 또한, 어떤 엘리먼트(또는 구성요소)가 구현됨에 있어서 특별한 언급이 없다면, 그 엘리먼트(또는 구성요소)는 소프트웨어, 하드웨어, 또는 소프트웨어 및 하드웨어 어떤 형태로도 구현될 수 있는 것으로 이해되어야 할 것이다. 또한, 본 명세서에서 사용된 용어는 실시 예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 '포함한다(comprises)' 및/또는 '포함하는(comprising)'은 언급된 구성요소는 하나 이상의 다른 구성요소의 존 재 또는 추가를 배제하지 않는다. 도 1은 본 발명의 바람직한 실시예에 따른 AI를 이용한 가상 스타일 추천 시스템의 네트워크 구성도이다. 도 1을 참조하면, 본 발명의 바람직한 실시예에 따른 AI를 이용한 가상 스타일 추천 시스템은, 유무선의 인터넷 을 통해 통신이 가능하도록 연결되는 다수의 사용자 단말장치, 및 AI를 이용한 가상 스타일 추천 서버(이 하, '추천 서버'라 한다)로 이루어진다. 다수의 사용자 단말장치는 추천 서버에서 제공하는 가상스타일 매칭을 위한 전용 어플리케이션(혹은, 앱)(이하, '스타일 매칭 앱'이라 한다)을 다운로드 받아 설치하고, 서비스를 이용하고자 하는 사용자 측에 해당 하는 컴퓨팅 장치이다. 여기서, 컴퓨팅 장치는, 스마트폰, 스마트워치, 스마트밴드, 태블릿 컴퓨터, 노트북 컴 퓨터, 데스크톱 컴퓨터, 서버 등을 포함할 수 있다. 그러나 이러한 것에 한정되지 않으며, 컴퓨터 명령을 저장 및 실행할 수 있는 메모리 및 프로세서를 구비한 임의의 형태의 컴퓨터 장치가 포함될 수 있다. 이하에서, 사용 자 단말장치라 함은 도 1에 도시한 다수의 사용자 단말장치 중 추천 서버에 접속하여 스타일 매 칭 앱을 실행한 어느 하나를 의미한다. 추천 서버는 사용자 단말장치가 다운로드 받아 설치할 수 있는 스타일 매칭 앱을 제공한다. 이러한 스타일 매칭 앱을 통해, 사용자는 자신의 사진과 원하는 스타일에 대한 이미지를 등록할 수 있고, 추천 서버 에서는 사용자가 등록한 두 이미지를 통합하여 생성된 최종 이미지를 사용자에게 제공할 수 있다. 이를 위해, 추천 서버는 기설정된 AI(Artificial Intelligence) 알고리즘에 의해 이미지 데이터 셋을 생성 하여 이 생성된 이미지 데이터 셋에 의해 AI 알고리즘을 학습시킨다. AI 알고리즘의 학습은 주기적으로 계속 진 행될 수 있으며, 학습이 진행될수록 보다 더 자연스러운 최종 이미지의 제공이 가능하다. 또한, 추천 서버는 학습된 이미지 데이터 셋에 의해 사용자 이미지와 스타일 이미지를 합성하여 사용자에 게 추천 이미지를 제공할 수 있다. 이러한 동작을 수행하는 추천 서버에 관하여는 후술하는 도 2에서 보다 상세히 설명한다. 도 2는 본 발명의 바람직한 실시예에 따른 AI를 이용한 가상 스타일 추천 서버의 블록도이다. 도 2를 참조하면, 본 발명의 바람직한 실시예에 따른 추천 서버는 학습 모듈, 사용자 인터페이스 모 듈, 추론 모듈, 저장 모듈, 및 제어 모듈을 포함한다. 학습 모듈은 기설정된 AI 알고리즘에 의해 이미지 데이터 셋을 생성하고, 이 생성된 이미지 데이터 셋을 학습시킨다. 학습 모듈은 기본적으로 StyleGAN 제너레이터(Generator)를 사용하지만, StyleGAN 제너레이터 에 입력되는 연산자와 StyleGAN 제너레이터로부터 출력되는 이미지를 처리하는 과정이 서로 다른 4가지 실시예 에 의해 실시된다. StyleGAN에 대하여는 후술하는 도 3a 내지 도 3c에서 보다 상세히 설명하고, 학습 모듈(21 0)의 4가지 실시예에 대하여는 후술하는 도 4 내지 도 7에서 보다 상세히 설명한다. 사용자 인터페이스 모듈은 본 추천 서버와 사용자 즉, 사용자 단말장치와의 인터페이스를 지원 하는 것으로, 스타일 매칭 앱을 통해 추천 서버에서 사용자에게 제공하는 정보 및 사용자가 입력하는 정보 들을 상호간에 송수신할 수 있도록 한다. 예를 들면, 사용자 인터페이스 모듈은 사용자 단말장치로부터 사용자 이미지 및 스타일 이미지를 입 력 받을 수 있다. 여기서, 사용자 이미지는 사용자의 실제 사진에 대한 이미지이고, 스타일 이미지는 사용자가 원하는 헤어스타일이 포함된 이미지이다. 또한, 사용자 인터페이스 모듈은 후술하는 추론 모듈에서 생성된 추천 이미지를 사용자 단말장치로 전달할 수 있다. 추론 모듈은 학습 모듈에 의해 학습된 이미지 데이터 셋에 의해 사용자 이미지 및 스타일 이미지를 합성하여 사용자에게 제공할 추천 이미지를 생성한다. 저장 모듈은 본 추천 서버의 동작에 필요한 모든 정보를 저장한다. 예를 들면, 저장 모듈은 학 습 모듈에 의해 생성된 이미지 데이터 셋을 저장할 수 있고, 수시로 학습되는 이미지 데이터 셋의 정보를 업데이트할 수 있다. 제어 모듈은 본 추천 서버의 전반적인 동작을 제어한다. 제어 모듈은 학습 모듈, 사용자 인터페이스 모듈, 추론 모듈, 및 저장 모듈들 간의 신호 입출력을 제어한다. 도 3a 내지 도 3c는 본 발명의 바람직한 실시예에 따른 AI를 이용한 가상 스타일 추천 서버에서 사용하는 StyleGAN 기술을 설명하기 위한 도면이다. 앞에서 언급한 바와 같이, 학습 모듈에서는 기본적으로 StyleGAN 제너레이터를 사용한다. StyleGAN 제너레 이터는 StyleGAN 모델에 의한 이미지 생성기로, 본 실시예에서는 StyleGAN 모델에 대하여 간략히 살펴본다. StyleGAN은 PGGAN을 베이스라인 모델로 활용하여 해당 아키텍처의 성능을 유의미하게 향상시킨 모델로, 가장 핵 심적인 것은 'Disentanglement' 특성을 향상시켰다는 점이다. 'Disentanglement' 특성이란, 모델이 각 이미지 의 특징을 얼마나 잘 분리해내는지에 대한 특성이다. 본 실시예에서 StyleGAN 모델을 활용하는 이유도 GAN 모델 중에서도 StyleGAN이 'Disentanglement' 특성이 매 우 강하기 때문이다. StyleGAN은 맵핑 네트워크(Mapping Network)를 통해 'Disentanglement' 특성을 향상시킬 수 있다. 이러한 맵핑 네트워크의 구조를 도 3a에 도시하였다. 도 3a를 참조하면, 랜덤 레이턴트 벡터(Random latent vector) z를 맵핑 네트워크를 통해 다른 임베딩 스페이스 (Embedding space) W의 w 벡터로 맵핑하고, w 벡터를 생성자에 대한 입력으로 설정하였다. 이러한 부분이 StyleGAN의 'Disentanglement' 특성을 직접적으로 향상시키는 핵심 요소이다. 도 3b를 통해 StyleGAN의 'Disentanglement' 특성을 살펴본다. (a)는 원본 그대로의(raw) 학습 이미지 데이터를 시각화한 것이고, (b)는 잠재 공간(latent space) Z의 분포를 시각화한 것이며, (c)는 임베딩 스페이스(embedding space) W의 분포를 시각화한 것이다. (a) 및 (b)의 경우에는 샘플링을 진행할 때 이미지의 각 특징 간의 변화가 매우 이산적(discrete)인 특성을 갖 기 때문에, 생성자가 미세한 특징의 변화를 분리해내기 어렵다. 반면, (c)의 경우에는 특징 간의 변화가 선형성(linear)을 갖기 때문에, 'Disentanglement' 특성을 향상시킬 수 있고, 이러한 특성은 사용자 정의 이미지를 생성하기 위해 반드시 필요한 특성이다. StyleGAN 모델에서는 w 벡터를 생성자에 그대로 입력하지 않고, AdalN(Adaptive Instance Normalization) 방식 을 거쳐 입력한다. 이는, StyleGAN에서 이미지를 생성할 때, 미세한 수준(fine-grained level)의 스타일을 잘분리하고 조작할 수 있는 핵심요소이다. StyleGAN에서는 수학식 1에 의해 AdalN을 결정한다. [수학식 1]"}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 3c는 맵핑 네트워크와 AdalN, 및 PGGAN을 베이스 라인으로 하는 생성자를 모두 포함한 본 실시예에 따른 StyleGAN의 최종 아키텍처를 도시한 것이다. 도 3a 내지 도 3c에서 설명한 StyleGAN 모델의 개념들은 본 추천 서버에서 사용하는 StyleGAN 제너레이터 의 개념을 뒷받침하기 위하여 언급한 것으로, 본 내용은 StyleGAN 모델에 대한 논문에 게시된 사항이므로 구체 적인 설명은 생략한다. 도 4는 도 2에 도시한 가상 스타일 추천 서버의 학습 모듈의 제1 실시예에 따른 구성도이다. 제1 실시예에 따른 학습 모듈(210a)은 연산자 생성부, 이미지 생성부, 및 분류부(Classifier) 를 포함한다. 연산자 생성부는 (256×1)에서 하나의 상수(c)를 선택하고, 이 선택된 상수(c)에 의해 연산자(z)를 생성한 다. 연산자(z)는 이미지 생성부로 입력된다. 이미지 생성부는 연산자 생성부로부터 입력된 연산자(z)를 이용하여 다수의 이미지 즉, 이미지 데이 터 셋을 생성한다. 또한, 이미지 생성부는 앞에서 설명한 StyleGAN 모델에 의한 이미지 데이터 셋을 생성 하는 StyleGAN 제너레이터에 해당한다. 분류부는 이미지 생성부에서 생성된 이미지를 기설정된 유형에 따라 분류하고, 이 분류된 이미지에 점수(score)를 부여한다. 점수를 최대화하는 잠재 공간(latent space) Z의 분포를 찾도록 연산자(z)를 학습시켜 이미지 데이터 셋을 생성하는 것이 본 학습 모듈(210a)의 목표이다. 도 5는 도 2에 도시한 가상 스타일 추천 서버의 학습 모듈의 제2 실시예에 따른 구성도이다. 제2 실시예에 따른 학습 모듈(210b)은 랜덤 벡터 입력부, 이미지 생성부(212'), 및 판별부를 포함한 다. 랜덤 벡터 입력부는 (512×1)에서 랜덤 벡터(Random vector(Latent code))를 생성하여 이미지 생성부 (212')로 제공한다. 이미지 생성부(212')는 랜덤 벡터 입력부로부터 입력되는 랜덤 벡터를 이용하여 이미지 데이터 셋을 생성 한다. 본 실시예의 이미지 생성부(212')는 그 입력값이 랜덤 벡터라는 점에서만 차이가 있을 뿐 제1 실시예에서 언급한 이미지 생성부와 그 동작은 유사하다. 판별부는 이미지 생성부(212')와는 별도로 임의로 생성된 임의 데이터 셋(Target Dataset)을 그라운드 트 루스(Ground Truth)로 입력 받고, 상기 임의 데이터 셋에 그라운드 투루스를 반영하여 조정한다. 이후, 판별부는 그라운드 투루스가 반영된 임의 데이터 셋과, 이미지 생성부(212')에서 생성한 이미지를 기설정된 유형에 따라 분류한 후, 이 분류된 이미지에 점수를 부여한다. 판별부에 의해 부여된 점수는 이미지 생성부(212')로 피드백된다. 즉, 이미지별로 부여된 점수에 따라 StyleGAN 제너레이터의 맵핑 네트워크를 학습시키게 된다. 도 6는 도 2에 도시한 가상 스타일 추천 서버의 학습 모듈의 제3 실시예에 따른 구성도이다. 제3 실시예에 따른 학습 모듈(210c)은 랜덤 벡터 입력부, 이미지 생성부(212'), 분류부, 및 판별부 를 포함한다. 본 실시예에서의 랜덤 백터 입력부 및 이미지 생성부(212')는 그 동작이 동일하다. 그러므로, 동일한 구성 에 대한 설명은 생략하고, 동일한 구성에 대하여 동일한 도면부호를 표기하였다. 다만, 본 실시예에서의 이미지 생성부(212')는 자신의 동작에 의해 생성된 이미지를 분류부 및 판별부 모두로 각각 전송한다. 분류부는 이미지 생성부(212')에서 생성되는 이미지 데이터 셋을 입력 받고, 이 이미지 각각이 원하는 이 미지 범주에 속하는지의 여부를 판별하여 이 판별 결과를 랜덤 벡터 입력기로 피드백한다. 판별부는 이미지 생성부(212')로부터 이미지 데이터 셋을 입력 받고, 입력 받은 다수의 이미지 각각을 기 설정된 유형에 따라 분류하며, 이 분류된 이미지에 점수를 부여한다. 이후, 판별부에 의해 부여된 점수는 이미지 생성부(212')로 피드백되어 맵핑 네트워크를 학습시킨다. 본 실시예는, 정보 이론의 아이디어에 기반하여 이미지의 의미론적(semantic) 정보를 latent variable c로 대변 하여 잠재 벡터 z와 더불어 추가적인 입력으로 설정하는 InfoGAN 매커니즘을 StyleGAN에 적용한 방식이다. 이 추가적인 입력에 따라 목적 함수도 변경된다. 결과적으로 수학식 2와 같은 information regularized min-max 문 제를 해결하는 구조이며, 이 때문에 생성자는 이미지의 의미론적 정보도 함께 고려하여 학습하게 된다. [수학식 2]"}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "맵핑 네트워크의 입력을 잠재 벡터 z와 데이터 분포(data distribution) d의 의미론적 특징에 해당하는 latent variable c로 구성하고, 분류부에서 Info loss를 계산한다. 분류부에서 계산된 Info loss는 랜덤 벡 터 입력부로 제공된다. 도 7은 도 2에 도시한 가상 스타일 추천 서버의 학습 모듈의 제4 실시예에 따른 구성도이다. 제4 실시예에 따른 학습 모듈(210c)은 랜덤 벡터 입력부, 이미지 생성부(212''), 및 생성자 변환부를 포함한다. 여기서, 랜덤 벡터 입력부는 이전 실시예와 동일하다. 이미지 생성부(212'')는 각각 기설정된 특정 이미지를 생성하는 복수의 이미지 생성자들을 포함하고, 이미지 생 성자 각각은 복수의 이미지 블록(레이어)으로 구성되며, 랜덤 벡터 입력부로부터 입력되는 랜덤 벡터를 이 용하여 다수의 이미지를 생성한다. 생성자 변환부는 복수의 이미지 생성자 중 특정 이미지 생성자를 구성하는 이미지 블록 중 일부를 다른 이 미지 생성자의 이미지 블록과 대체하는 동작을 수행한다. 도 8a 및 도 8b는 도 7에 도시한 제4 실시예에 따른 학습 모듈의 동작을 설명하기 위한 도면이다. 제4 실시예에 따른 학습 모듈(210d)은 생성자의 네트워크를 대체하는 방식이다. 이러한 방식을 활용하면, 오직 StyleGAN만 독자적으로 활용하여 빠르고 효율적인 대량 이미지 데이터 셋의 생성이 가능하다. 또한, 직접적으로 생성하고자 하는 이미지의 세세한 특징까지 조정이 가능하다. 제4 실시예에 따른 학습 모듈(210d)의 효과를 확인하기 위해, StyleGAN의 생성자 네트워크를 도 8a를 통해 살펴 본다. 8a를 참조하면, 생성자 네트워크 내의 위치에 따라 각 레이어가 어떤 이미지 특성에 영향을 주는지 확인 할 수 있다. 네트워크 전반부에 위치한 4개의 레이어는 세밀하지는 않지만 전반적인 이미지의 윤곽을 잡아주는 콜스 스타일 (coarse style)로, 예를 들면, 얼굴형, 안경 착용 유무와 같은 특성을 제어할 수 있다. 또한, 네트워크의 중앙에 위치한 4개의 레이어는 콜스 스타일 보다는 조금 더 세밀한 미들 스타일(middle style), 예를 들면, 눈을 뜨고 있는지 감고 있는지에 대한 여부, 및 헤어스타일과 같은 특성을 제어할 수 있다. 기존 모델에서는 참조(reference)하고자 하는 이미지의 스타일을 AdalN을 통해 입력하는 방식으로 스타일 기반 의 이미지를 생성하였지만, 본 실시예에서는 이미지 레벨(image-level)이 아닌 네트워크 레벨(network-level)에 서 스타일을 제어하는 방식을 사용한다. 이러한 방식은 생성자 네트워크의 특정 레이어를 다른 생성자 레이어와 대체함으로써 구현된다. 도 8b를 참조하여 이러한 매커니즘을 살펴본다. 도 8b를 참조하여, (a)에는 서양인 유아 안면 이미지와 이를 생성하는 생성자 A를 예시하였고, (b)에는 동양인 성인 안면 이미지와 이를 생성하는 생성자 B를 예시하였다. 본 실시예에 따르면, 이러한 두 생성자를 이용하여 동양인 유아 안면 이미지를 생성할 수 있다. 보다 구체적으 로, 생성자 A의 5, 6, 7번째의 레이어(이전 기재에서 '블록'의 기재와 동일한 개념임)(A')를 생성자 B의 5, 6, 7번째의 레이어(B')로 대체한다. 이러한 동작에 의하면, 서양인 유아 안면 이미지와 동양인 성인 안면 이미지를 합성하여 동양인 유아 안면 이미 지를 생성할 수 있다. 즉, 두 이미지를 합성하여 전혀 다른 새로운 이미지를 생성해 낼 수 있다. 본 실시예에 따르면, 제4 실시예에 따른 학습 모듈을 통해 생성된 사진의 coarse 특성(얼굴형, 자세 등)부 터 middle 특성(헤어스타일, 표정 등), 및 fine 특성(모질, 피부 등)까지 세밀한 제어가 가능하다. 더불어, 네 트워크 레벨에서의 접근으로 StyleGAN만을 이용하는 방식이기 때문에, 효율적으로 대규모의 이미지 데이터 셋을 생성할 수 있다. 앞에서 설명한 바와 같이, 본원발명에서는 4가지 형태의 학습 모듈이 구현된다. 이러한 4가지 형태의 학습 모듈을 통해 각 이미지 데이터 셋마다 상이한 데이터 분포(data distribution)을 가지는 대규모의 이미지 데이터 셋 예를 들면, 10만장 이상을 구축하는 것이 가능하다. 또한, 이미지 데이터 셋이 전부 합성 이미지로 구성되기 때문에, 개인 정보 및 개인 프라이버시 이슈에서 자유 로울 수 있다. 그러므로, 다양한 데이터 분포를 가지는 다수의 이미지 데이터 셋을 활용해 데이터 중심적으로 AI 모델의 성능을 향상시킬 수 있다. 도 9는 도 2에 도시한 추론 모듈에서 사용하는 개념의 결정 과정을 설명하기 위한 흐름도이다. 학습 모듈에서 대용량 이미지 데이터 셋에 대한 학습이 완료되면, 사용자 단말장치로부터 사용자 이 미지 및 스타일 이미지를 전송받은 후, 추론 모듈에서 사용자에게 제공할 추천 이미지를 생성한다. 이를 위해, 추론 모듈에서 사용할 벤치마크를 결정하고(S310), AI 모델을 선정하여야 한다(S320). 벤치마 크를 결정하고, AI 모델을 선정하는 과정에 관하여는 후술하는 도 10 내지 도 11에서 보다 상세히 설명한다. 도 10은 도 9에서 도시한 벤치마크 결정 과정을 설명하기 위한 도면이다. AI 모델의 성능을 평가하는 지표로, 첫번째는 AI 모델이 생성해 낸 이미지가 얼마나 사실 같은가(Fidelity)에 대한 벤치마크이고, 두번째는 AI 모델이 합성해 낼 수 있는 스타일이 얼마나 다양한가(Diversity)에 대한 벤치 마크이다. 첫번째 항목인 Fidelity를 위해, FID(Frechet Inception Distance)라는 매트릭을 활용한다. 이 매트릭은 실제 이미지와 생성된 이미지 간의 특정 거리 측정에 가장 널리 사용되는 매트릭 중 하나로, 프레쳇 거리는 곡선을 따라가는 점들의 위치와 순서를 고려한 곡선 간의 유사성을 측정하는 방법이다. 이는 두 분포 사이의 거리를 측 정할 때에도 사용된다. 수학적으로, 프레쳇 거리는 두 다변량 정규분포(multivariate normal distribution) 사 이의 거리를 계산하는데 사용되며, 이를 수학식 3에 나타내었다. [수학식 3]"}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, X 및 Y는 두 개의 다변량 정규분포로 가정된 실제 이미지와 생성된 이미지의 임베딩이다. μX와 μY는 벡터 X와 Y의 크기(magnitude)이고, Tr은 행렬의 대각합이다. 이를 통해 생성한 이미지와 실제 이미지 간의 거 리가 얼마나 되는지를 확률적으로 신뢰가능한 수준으로 측정할 수 있다. 두번째 항목인 Diversity를 위해, LPIPS(Learned Percetual Image Patch Similarity)라는 매트릭을 사용한다. LPIPS는 신경망 모델에서 추출되는 특성을 이용하여 학습에 의해 사람의 인지적 특성에 맞도록 유사도를 평가하 는 새로운 매트릭이다. 이러한 다양성 지표는 인간이 느끼는 이미지의 지각적 유사성 측면과 관련해 굉장히 복잡한 기법을 요하는데, 가장 많이 사용하는 PSNR, SSIM과 같은 지표는 너무 단순하고 얕은 함수로서, 인간의 지각에 대한 미묘한 차이를 설명하는데 실패하였다. 이에, perceptual loss와 관련한 분석을 통해 해당 loss를 바탕으로 한 Perceptual Similarity Evaluation Network인 LPIPS를 본 발명에 적용한다. LPIPS의 Deep Neural Network 구조를 도 10에 예시하였다. 도 10에 예시한 아키텍쳐를 통해 L2 거리(distance)를 수학식 4에 의해 계산하고자 하며, 이 거리를 통해 지각 적 유사성 측면에 있어 객관적 평가 지표로의 활용이 가능하다. [수학식 4]"}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 5, "content": "도 11은 도 2에 도시한 추론 모듈에서 사용하는 AI 모델을 설명하기 위한 개념도이다. AI 모델을 이미지 합성에 적용하기 위해서는, 첫번째로 AI 모델을 제어 가능하게 활용하여 스타일 합성을 보장 해야 한다는 것과, 두번째로 서비스할 AI 모델을 서빙하는 컴퓨팅 환경의 최적화 문제를 해결해야 한다. 첫번째 문제를 해결하기 위해서는, 원본 이미지(source image)와 참조 이미지(reference image)를 합성할 수 있 는 모델을 사용해야 한다. 여기서, 원본 이미지는 사용자 이미지가 되고, 참조 이미지는 스타일 이미지가 된다. 이는, 적대적 생성 네트워크(Generative Adversarial Network : GAN) 중에서도 단순히 이미지를 랜덤하게 생성 하는 것이 아닌 스타일 트랜스퍼(Style Transfer)의 기능을 내재한 모델을 활용해야 한다는 의미가 되며, 본 발 명에서는 여러 모델들의 수행 결과물에 대해 FID 및 LPIPS 벤치마크를 적용하여 비교한 결과, StarGan-v2 모델 을 선정하였다. 도 11에 StarGan-v2 모델의 전체 프레임워크를 도시하였다. 이를 참조하여 살펴보면, StarGan-v2 모델은 싱글 제너레이터를 사용하여 모든 가능한 도메인의 맵핑을 학습할 수 있다. X, Y를 sets of images and possible domain이라고 할 때, 이미지 x와 임의의 도메인 y에 대해 StarGan-v2 모델의 목적은 싱글 제너레이터 G 가 x에 상응하는 도메인 y에 대한 구분 가능한 이미지를 생성하게 하는 것이다. 예를 들면, 어떤 이미지 x가 있고, '금발'이라는 도메인이 있을 때 G가 x의 다양한 금발 버전을 만들어 낼 수 있게 하는 것이 StarGan-v2 모델의 학습 목표이다. 본 실시예에 따르면, 사전에 학습된 각 도메인의 스타일 공간 내에서 domain-specific style vectors를 생성해 내고, G로 하여금 스타일 벡터를 반영하도록 학습시킨다. (a)의 제너레이터 G는 입력 이미지 x를 출력 이미지 G(xs)로 변환한다. 이때, 맵핑 네트워크 F 혹은 스타일 인 코더 E 중 하나를 통해 생성된 domain-specific style code S를 반영하다. 여기서, AdalN을 사용하는데, 이는 스타일 코드 s를 G에 반영하기 위함이다. 이 's'가 style specific domain y를 표현하게 되고, 도메인 정보 y를 G에게 주지 않기 때문에, G가 모든 도메인의 이미지들을 통합할 수 있게 되었다. (b)의 맵핑 네트워크 F는 주어진 잠재 코드 z와 도메인 y에 대하여, 맵핑 네트워크는 style code s = F_y(z)를 생성한다. 여기서, F는 모든 가능한 도메인에 대한 스타일 코드를 제공하기 위해 여러 출력 브랜치(branch)를 가진 MLP로 구성된다. F는 diverse style codes를 랜덤하게 샘플링하여 생성할 수 있으며, 멀티 태스크 아키텍쳐는 F로 하여금 효율적 이고 효과적으로 만든 모든 도메인에 대한 스타일 구상을 학습하게 한다. (c)의 스타일 인코더 E는 주어진 이미지 x와 상응하는 도메인 y에 대하여 인코더 E는 style code s = E_y(s)를 추출한다. F와 유사하게, E도 멀티태스크 학습 설정에 유리하다. E는 다른 참조 이미지를 사용하여 diverse style codes를 만들어낸다. 이것은 G로 하여금 참조 이미지 x의 스타 일 s를 반영하는 출력 이미지를 합성해 낼 수 있도록 한다. (d)의 식별자(Discriminator) D는 멀티플 출력 브랜치들(multiple output branches)로 구성되는 멀티태스크 식 별자이다. 각각의 브랜치 D_y는 이미지 x가 도메인 y에 해당하는 진짜 이미지인지, 모조 이미지 G(x,s)인지를 구분하는 바이너리 식별(binary classification)을 학습한다.전체 프레임워크는 주어진 이미지 x in X, 그에 대한 오리지널 도메인 y in Y에 대해 목적 함수(objectives)를 통해 학습한다. 트레이닝시, 잠재 코드 z와 타겟 도메인 y를 랜덤하게 샘플링하고, target style code s = F_y(z)를 생성한다. 제너레이터 G는 이미지 x와 s를 입력으로 받아 출력 이미지인 G(x,s)를 생성하는 방법을 adversarial loss를 통해 학습하고, 수학식 5로 표현할 수 있다. [수학식 5]"}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "G는 스타일 코드 s를 활용하기 위해 style reconstruction loss를 사용하는데, 이는 여러 인코더를 사용하여 이 미지에서 잠재 코드 맵핑을 학습하는 이전의 접근 방식들과 유사하다. 다만, StarGAN-v2에서는 멀티플 도메인에 대한 출력을 위해 싱글 인코더 E에 대해서만 학습을 한다는 점에서 다 른 모델들과 차이가 있다. 이러한 차이점은 스타일 코드 도입을 통해 얻을 수 있는 효과를 부각시킬 수 있다. 인코더 E는 G가 입력 이미지(사용자 이미지)를 참조 이미지(스타일 이미지)의 스타일을 반영하여 변형할 수 있 게 한다. 인코더 E에서 사용하는 수식을 수학식 6에 나타내었다. [수학식 6]"}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "Style Diversification Loss Objective는 제너레이터 G가 더욱 다양한 이미지를 만들어 낼 수 있게 하기 위해, diverse sensitive loss를 통해 명시적으로 정규화(regularize)한다. Regularization term을 최대화하는 것은 제너레이터가 다양한 이미지를 생성하기 위해 이미지 공간을 탐구하고, 의미 있는 스타일 특성을 찾게 한다. 다 만, 기존의 형식에서 분모가 조금만 차이가 나도 손실이 증가하므로, 안정적인 트레이닝을 위해 수학식 7을 사 용한다. [수학식 7]"}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "생성된 이미지 G(x,s)가 도메인 불변특성을 적절히 보장하기 위해 cycle consistency loss가 고안되었으며, s=E_Y(x)는 입력 이미지 x의 추정된 스타일 코드이고, y는 x의 원본 도메인이다. G가 입력 이미지 x를 복원할 때 입력 x, s의 추정된 스타일 코드를 포함시켜 G는 x의 스타일을 충실히 변화시키면서도 x의 원래 특성을 보존 시키도록 한다. 이에 사용되는 수식을 수학식 8에 나타내었다. [수학식 8]"}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이상에서 설명한 바와 같이, 본 AI를 이용한 가상 스타일 추천 서버는 특정한 이미지를 기반으로 완전히 새로운 이미지를 생성해 낸다. 그러므로, 헤어 스타일, 얼굴 성형, 패션 스타일 등의 관련 시뮬레이션이 가능하다. 또 한, 특정한 특징을 가지는 이미지 데이터 셋을 대량으로 생성해 낼 수 있으므로, 관련 분야에서 이미지 데이터 셋 구축에 기여한다."}
{"patent_id": "10-2021-0154849", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "본 발명이 속하는 기술분야의 당업자는 본 발명이 그 기술적 사상이나 필수적 특징을 변경하지 않고서 다른 구 체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면 에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범위는 상기 상세한 설명보다 는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다.부호의 설명 100 : 사용자 단말장치 200 : 추천 서버 210 : 학습 모듈 220 : 사용자 인터페이스 모듈 230 : 추론 모듈 240 : 저장 모듈 250 : 제어 모듈"}
{"patent_id": "10-2021-0154849", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 바람직한 실시예에 따른 AI를 이용한 가상 스타일 추천 시스템의 네트워크 구성도, 도 2는 본 발명의 바람직한 실시예에 따른 AI를 이용한 가상 스타일 추천 서버의 블록도, 도 3a 내지 도 3c는 본 발명의 바람직한 실시예에 따른 AI를 이용한 가상 스타일 추천 서버에서 사용하는 StyleGAN 기술을 설명하기 위한 도면, 도 4는 도 2에 도시한 가상 스타일 추천 서버의 학습 모듈의 제1 실시예에 따른 구성도, 도 5는 도 2에 도시한 가상 스타일 추천 서버의 학습 모듈의 제2 실시예에 따른 구성도, 도 6는 도 2에 도시한 가상 스타일 추천 서버의 학습 모듈의 제3 실시예에 따른 구성도, 도 7은 도 2에 도시한 가상 스타일 추천 서버의 학습 모듈의 제4 실시예에 따른 구성도, 도 8a 및 도 8b는 도 7에 도시한 제4 실시예에 따른 학습 모듈의 동작을 설명하기 위한 도면, 도 9는 도 2에 도시한 추론 모듈에서 사용하는 개념의 결정 과정을 설명하기 위한 흐름도, 도 10은 도 9에서 도시한 벤치마크 결정 과정을 설명하기 위한 도면, 도 11은 도 2에 도시한 추론 모듈에서 사용하는 AI 모델을 설명하기 위한 개념도이다."}
