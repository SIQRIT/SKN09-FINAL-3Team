{"patent_id": "10-2022-0112422", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0033591", "출원번호": "10-2022-0112422", "발명의 명칭": "빅데이터 분석을 이용하여 도출된 키워드의 계층적 배열 방법 및 그 장치", "출원인": "주식회사 아르스프락시아", "발명자": "김도훈"}}
{"patent_id": "10-2022-0112422", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "핵심 네트워크 추출부가 텍스트에서 전체 네트워크를 구성하고, 의미상으로 핵심적인 네트워크 추출 단계;차등화부가 중앙성 세부 지표의 기능에 따라 언어 심리의 층위를 단계화하여 키워드 배열을 차등화 하는 단계;및시각화부가 키워드들의 선후관계에 대한 통계적 계산을 통해 핵심적으로 수렴하는 노드와 링크를 자동적으로 시각화 하는 단계를 포함하는 빅데이터 분석을 이용하여 도출된 키워드의 계층적 배열 방법 및 그 장치."}
{"patent_id": "10-2022-0112422", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 차등화부가 중앙성 세부 지표의 기능에 따라 언어 심리의 층위를 단계화 하여 키워드 배열을 차등화 하는단계는상기 키워드들을 2 차 함축어 (Secondary connotation), 1 차 함축어 (Primary connotation), 2 차 지시어(Secondary denotation) 및 1 차 지시어 (Primary denotation) 로 차등화하는 것을 특징으로 하는 키워드의 계층적 배열 방법 및 그 장치."}
{"patent_id": "10-2022-0112422", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 2 차 함축어 (Secondary connotation), 1 차 함축어 (Primary connotation), 2 차 지시어 (Secondarydenotation) 및 1 차 지시어 (Primary denotation) 는 동심원 상에 위치되도록 디스플레이 되며,상기 2 차 함축어 (Secondary connotation) 가 동심원의 가장 내부에 위치에 디스플레이 되고, 상기 1 차 함축어 (Primary connotation) 는 상기 2 차 함축어 (Secondary connotation) 의 외주에 디스플레이되며,상기 2 차 지시어 (Secondary denotation) 는 상기 1 차 함축어 (Primary connotation) 의 외주에 디스플레이되고,상기 1 차 지시어 (Primary denotation) 는 상기 2 차 지시어 (Secondary denotation) 의 외주에 디스플레이되는 것을 특징으로 하는 키워드의 계층적 배열 방법 및 그 장치."}
{"patent_id": "10-2022-0112422", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 2 차 함축어 (Secondary connotation) 는 추출된 핵심적인 네트워크 상에 위치한 키워드들의 In-Closeness Centrality 값이 가장 높은 단어로 결정되고,상기 1 차 함축어 (Primary connotation) 는 추출된 2 차 함축어 (Secondary connotation) 들과 네트워크 상에있는 키워드 중에서 PBS 값이 가장 높은 단어로 결정되며,상기 2 차 지시어 (Secondary denotation) 는 추출된 상기 1 차 함축어 (Primary connotation) 들과 네트워크상에 있는 키워드 중에서 보나시치 영향력 (Bonacci Power) 값이 가장 높은 단어로 결정되고,상기 1 차 지시어 (Primary denotation) 는 추출된 상기 2 차 지시어 (Secondary denotation) 들과 네트워크상에 있는 키워드 중에서 Betweenness 값이 가장 높은 단어로 결정되는 것을 특징으로 하는 키워드의 계층적 배열방법 및 그 장치.공개특허 10-2024-0033591-3-"}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 핵심 네트워크 추출부가 텍스트에서 전체 네트워크를 구성하고, 의미상으로 핵심적인 네트워크 추출 단계, 차등화부가 중앙성 세부 지표의 기능에 따라 언어 심리의 층위를 단계화하여 키워드 배열을 차등화 하는 단계 및 시각화부가 키워드들의 선후관계에 대한 통계적 계산을 통해 핵심적으로 수렴하는 노드와 링크를 자동적 으로 시각화 하는 단계를 포함하는 빅데이터 분석을 이용하여 도출된 키워드의 계층적 배열 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 빅데이터 분석을 이용하여 도출된 키워드의 계층적 배열 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "통신 기술의 발달로 개인들은 PC를 통해 인터넷 기술을 이용하여 인터넷상에서 네트워크를 형성함으로써 종래의 장소와 시간적 제약을 동시에 해결하는 역할을 하고 있다. 이와 더불어 개인이 자신의 인터넷상의 가상 공간에 서 타인과 관계를 맺을 수 있는 서비스, 즉, 커뮤니케이션을 제공하고 다양한 정보를 공유할 수 있도록 하는 서 비스가 대두되었는데, 이를 소셜 네트워크 서비스(Social Networking Service, SNS) 또는 소셜 커뮤니티 서비스 (SCS: Social Community Service)라 한다. 상기 소셜 네트워크 서비스의 대표적인 형태는 싸이월드, 네이버, 다음 등이 제공하는 미니홈피, 블로그, 카페 등이었고, 최근에는 트위터, 미투데이, 페이스북 유튜브 등 그 형태도 새롭게 진화하고 있다. 소셜네트워크 서비스를 포함한 각종 빅데이터 소통 플랫폼에서는 텍스트, 사진, 동영상을 중심으로 방대한 양의 데이터가 생산되고 있다. 그 중에서도 텍스트는 가장 직접적으로 발화자들의 감성, 생각, 여론을 파악할 수 있는 매체가 된다. 종래의 텍스트마이닝(text-mining) 기법은 빅데이터 문서에 포함된 키워드의 빈도수를 세거나, 문서의 긍-부정 비율에 대한 감성분석을 수행하거나, 동시 출현하는 키워드간의 연결관계를 네트워크로 시각화한다. 그러나 발화자들의 말이 궁극적으로 수렴하는 대상 (욕망, 걱정, 여론 등) 이나 주요 컨셉 (키워드) 이 다른 개념들과의 연결성 속에서 어떤 감성과 의미를 담는지에 대해 직관적인 분석을 수행하는 기술은 제한적으로만 개발되어 있다. 또한, 종래의 키워드의 분석은 단순히 정량적인 분석에 그치게 되어 각 키워드에 대하여 이용자들 혹은 대중들 이 긍정적으로, 부정적으로 또는 중립적으로 판단하는지에 대한 정보를 제공하고 있지 못하고 있다. 실질적으로 정부기관이나 일반기업에서는 핵심 키워드에 대한 정보 뿐만 아니라, 이러한 키워드들에 대한 감성 값에 대한 정보를 디스플레이하는 시스템을 통해 효과적으로 여론 형성 전략을 수립할 수 있는 기술에 대한 요 구가 높아지고 있다."}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 빅데이터에 의해 추출된 각 키워드들의 정량적인 분석 뿐만 아니라, 이러한 키워드들의 감성값인 긍 정, 부정 및 중립에 대한 정보를 제공할 수 있는 빅데이터 분석 및 사회심리분석 모델에 기반하여 키워드의 배 열패턴을 재 구조화 함으로써 궁극적으로 수렴하는 여론의 대상을 직관적으로 도출하는 UI 알고리즘과, 주요 키 워드에 투영된 발화자들의 감성을 네트워크에 연결된 컨셉들과의 관계를 통해 새롭게 가중치 조정을 하여 긍-부 정의 강도를 시각화하는 UI 알고리즘을 제공하는 것을 해결하고자 하는 과제로 한다."}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 상술한 과제를 해결하기 위하여, 핵심 네트워크 추출부가 텍스트에서 전체 네트워크를 구성하고, 의 미상으로 핵심적인 네트워크 추출 단계, 차등화부가 중앙성 세부 지표의 기능에 따라 언어 심리의 층위를 단계 화하여 키워드 배열을 차등화 하는 단계 및 시각화부가 키워드들의 선후관계에 대한 통계적 계산을 통해 핵심적 으로 수렴하는 노드와 링크를 자동적으로 시각화 하는 단계를 포함하는 빅데이터 분석을 이용하여 도출된 키워"}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "드의 계층적 배열 방법 및 그 장치를 제공하는 것을 과제의 해결 수단으로 한다. 또한, 상기 차등화부가 중앙성 세부 지표의 기능에 따라 언어 심리의 층위를 단계화 하여 키워드 배열을 차등화 하는 단계는 상기 키워드들을 2 차 함축어 (Secondary connotation), 1 차 함축어 (Primary connotation), 2 차 지시어 (Secondary denotation) 및 1 차 지시어 (Primary denotation) 로 차등화하는 것을 특징으로 하는"}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "키워드의 계층적 배열 방법 및 그 장치를 제공하는 것을 과제의 해결 수단으로 한다.또한, 상기 2 차 함축어 (Secondary connotation), 1 차 함축어 (Primary connotation), 2 차 지시어 (Secondary denotation) 및 1 차 지시어 (Primary denotation) 는 동심원 상에 위치되도록 디스플레이 되며, 상기 2 차 함축어 (Secondary connotation) 가 동심원의 가장 내부에 위치에 디스플레이 되고, 상기 1 차 함축 어 (Primary connotation) 는 상기 2 차 함축어 (Secondary connotation) 의 외주에 디스플레이 되며, 상기 2 차 지시어 (Secondary denotation) 는 상기 1 차 함축어 (Primary connotation) 의 외주에 디스플레이 되고, 상기 1 차 지시어 (Primary denotation) 는 상기 2 차 지시어 (Secondary denotation) 의 외주에 디스플레이"}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "되는 것을 특징으로 하는 키워드의 계층적 배열 방법 및 그 장치를 제공하는 것을 과제의 해결 수단으로 한다. 또한, 상기 2 차 함축어 (Secondary connotation) 는 추출된 핵심적인 네트워크 상에 위치한 키워드들의 In- Closeness Centrality 값이 가장 높은 단어로 결정되고, 상기 1 차 함축어 (Primary connotation) 는 추출된 2 차 함축어 (Secondary connotation) 들과 네트워크 상에 있는 키워드 중에서 PBS 값이 가장 높은 단어로 결정되 며, 상기 2 차 지시어 (Secondary denotation) 는 추출된 상기 1 차 함축어 (Primary connotation) 들과 네트 워크 상에 있는 키워드 중에서 보나시치 영향력 (Bonacci Power) 값이 가장 높은 단어로 결정되고, 상기 1 차 지시어 (Primary denotation) 는 추출된 상기 2 차 지시어 (Secondary denotation) 들과 네트워크상에 있는 키 워드 중에서 Betweenness 값이 가장 높은 단어로 결정되는 것을 특징으로 하는 키워드의 계층적 배열 방법 및"}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 5, "content": "그 장치를 제공하는 것을 과제의 해결 수단으로 한다."}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 빅데이터에 의해 추출된 각 키워드들의 정량적인 분석 뿐만 아니라, 이러한 키워드들의 감성값인 긍 정, 부정 및 중립에 대한 정보를 제공할 수 있는 빅데이터 분석 및 사회심리분석 모델에 기반하여 키워드의 배 열패턴을 재 구조화 함으로써 궁극적으로 수렴하는 여론의 대상을 직관적으로 도출하는 UI 알고리즘과, 주요 키 워드에 투영된 발화자들의 감성을 네트워크에 연결된 컨셉들과의 관계를 통해 새롭게 가중치 조정을 하여 긍-부 정의 강도를 시각화하는 UI 알고리즘을 제공할 수 있다."}
{"patent_id": "10-2022-0112422", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에 서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였 으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 명세서 전체에서 \"워드\"와 \"단어\"는 동일한 의미로 사용된다. 아래에서는 첨부한 도면을 참고하여 실시예들에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자 가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형식으로 구현될 수 있으 며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 도 1 은 본 개시의 일실시예에 따른 머신 러닝 워크플로우(machine learning workflow)를 보여주는 도면이다. 도 1 에 따르면, 머신 러닝 워크플로우의 1단계는 수집(acquisition) 단계이다. 머신 러닝을 하기 위해서 는 기계(machine)에 학습시켜야 할 데이터가 필요하다. 자연어 처리(natural language processing)의 경우 자 연어 데이터를 코퍼스(corpus)라고 부른다. 코퍼스는 조사나 연구 목적에 의해서 특정 도메인으로부터 수집된 텍스트의 집합을 의미한다. 코퍼스, 즉, 텍스트 데이터의 파일 형식은 txt, csv, xml 파일 등 다양하며 그 출처 도 음성 데이터, 웹 수집기를 통해 수집된 데이터, 영화 리뷰 등으로 다양하다. 웹 수집기를 통해 데이터를 수 집할때는 데이터를 크롤링(crawling)하여 수집한다. 1단계를 통해 데이터가 수집되었다면 2단계는 데이터를 점검 (inspection) 하고 탐색 (exploration) 하는 단계 이다 . 이 단계에서는 데이터의 구조, 노이즈 데이터, 머신 러닝 적용을 위해서 데이터를 어떻게 정제 (cleaning) 해야 하는지를 결정한다. 이 단계는 탐색적 데이터 분석(exploratory data analysis, EDA) 단계라 고도 하는데, 이 단계에서는 독립 변수(independent variables), 종속 변수(dependent variables), 변수 유형 (type of variables), 변수의 데이터 타입(data type of variables) 등을 점검하며 데이터의 특징과 내재하는 구조적 관계를 알아내는 과정이다. 3단계는 전처리(preprocessing) 및 정제(cleaning)과정이다. 이 단계는 토큰화, 정제(cleaning), 정규화 (normalization), 불용어 제거(removal of stopwords) 등이 포함된다. 4단계는 모델링(modeling) 및 학습(training)과정이다. 전처리(preprocessing)가 끝났다면, 머신 러닝에 대한 코드를 작성하는 모델링 단계가 시작된다. 적절한 머신 러닝 알고리즘을 선택하여 모델링이 끝났다면 전처 리가 완료된 데이터를 머신 러닝 알고리즘을 통해 기계에게 학습 (training) 시킨다. 기계가 데이터에 대한 학 습을 마치고 난 후 학습이 제대로 되었다면 그 후에 기계는 사용자가 원하는 태스크(task)인 기계번역, 음성인 식, 텍스트 분류 등의 자연어 처리 작업을 수행할 수 있게 된다. 5단계는 평가(evaluation)단계이다. 기계가 학습을 완료하였으며 사용자는 테스트용 데이터로 모델링된 코 드의 성능을 평가한다. 평가 방법은 기계가 예측한 데이터가 테스트용 데이터의 실제 정답과 얼마나 가까 운지를 측정하는 방법을 취한다. 만일 평가 결과가 만족스럽지 못하면 제 4 단계가 재수행되고 재평가가 이루어진다. 감성 분석에서 감성 스코어(sentiment score)는 감성 극성(sentiment polarity)의 좀더 정밀한(precise) 표현 (representation) 이다. 감성 스코어는 단순히 +1이 긍정적, -1이 부정적, 0이 중립적이라고만 판단하게 표시할 수도 있고, 긍정적인 정 도를 1~5, 긍정적인 정도를 -1~-5와 같인 뎁스 가중치를 더 줄 수도 있다. 이와 같이 +1, -1, 0과 같은 값을 감 성 레이블이라고도 한다. 감성 분석의 보통 첫번째 단계는 프리-프로세싱(pre-processing)이다. 프리-프로세싱에는 텍스트의 노이즈를 줄 이기 위한 다양한 기술이 적용된다. 프리-프로세싱에 일반적으로 적용되는 기술로는 숫자 제거(remove numbers), 어간추출(stemming), 품사 태깅(part of speech tagging), 구두점 제거(remove punctuation), 소문자화(lowercase), 및 불용어(stopwords) 제거 등이 있다. 토픽 모델링은 문서 집합에서 토픽을 찾아내는 프로세스를 말한다. 토픽 모델링은 검색 엔진이나 고객 민원 처 리와 같이 문서의 주제(topic)를 알아내는 것이 중요한 응용에서 사용된다. 토픽 모델링은, 대용량 텍스트 수집 의 비지도 분석(unsupervised analysis)을 다루는 다수의 애플리케이션을 위해 선택되는 모델이 되었다. 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)은 토픽 모델링의 대표적인 알고리즘이다. LDA는 문서 들이 토픽들의 혼합으로 구성되어 있으며, 토픽들은 확률 분포에 기반하여 단어들을 생성한다고 가정한다. 데이 터가 주어지면, LDA는 문서가 생성되던 과정을 역추적 한다. 토픽 모델링의 중요한 응용은 감성 분석 분야이다. 최근 토픽 모델링은 측면기반의 의견 마이닝(aspect-based opinion mining)에 성공적으로 이용되고 있다. 토픽 모델링은 리뷰(텍스트) 및 다른 감성 관련 데이터세트 (datasets)에서 비지도 방식으로 감성이 포함된 잠재 토픽 측면(aspect)을 식별할 수 있다. 여기서 측면 혹은 양상(aspect)은 어느 제품의 한가지 측면과 같은 것으로서, 예를 들면 데스크탑 컴퓨터에서 하나의 측면(aspect)은 전체 디자인(overall design), 배터리, 스크린 및 CPU 라고 할 수 있다. 최근 연구는 일반적으로 리뷰에서 언급되는 제품의 속성(attribute)이나 특성(feature)을 측면(aspect)으로 정 의한다. 또한 제품의 속성이나 특성은 일관성 있는(coherent) 토픽이나 측면으로 분류될 수 있다. 예를 들어, '컵케익(cupcake)'과 '스테이크'는 음식점에서 음식('food') 토픽의 일부이다. 감성 분석은 제품, 서비스, 이베트, 사람 혹은 아이디어에 대한 일련의 글(a pieces of writings) 혹은 의견 - 예를 들어 제품 리뷰, 영화 리뷰, 블로깅, 포럼, 트윗 등 - 이 긍정적(positive)인지, 부정적(negative)인지 혹 은 중립적 (neutral) 인지를 판단하는 과정이다. 감성 분석(sentiment analysis)은 마케팅 뿐만 아니라 과학 리서치에도 중요한 이슈로 떠오르고 있다. 제품 판 매자는 제품에 대한 소비자의 평가를 빠르게 관찰하고 싶을 때 감성 분석을 이용할 수 있다. 감성 분석을 다루는 토픽 모델은 일반적으로 개별 단어에 대한 감성 레이블을 포함한다. JST나 역 JST(Reverse JST), ASUM, USTM 과 같은 토픽 모델은 어떤 토픽에서 개별 단어들에 대한 감성 사전(prior)을 셋팅하기 위해 기존에 존재하는 감성 단어 사전을 이용한다. 다른 접근법으로 감성 단어의 씨드(seed) 사전(dictionary)을 시 작한 다음 기대값-최대화 접근법(expectation-maximization approach)으로 새로운 감성 사전(prior) 베타(β) 를 학습시키는 방법도 제안되고 있다. 이러한 접근법은 새로운 감성 단어, 특히 사전에 리스트할 수 없었던 측 면-관련 감성 단어를 발견할 수 있도록 하며 다른 측면에서 동일한 단어에 대해 다른 감성 사전(prior)을 가지 며, 감성 분류를 대체적으로 개선하는 것으로 나타난다. 한편, 최근에는 분산 단어 표현(distributed word representation)의 발전이 현대의 자연어 처리에도 발전을 가 져왔다. (Yoav Goldberg. 2015. A primer on neural network models for natural language processing. CoRR, abs/1510.00726.) 이 접근법에서 단어(words)는 의미론적 기하학 공간에서 의미론적(semantic) 관계를 캡처하기 위해 유클리드 공간에 삽입된다. 또, 텍스트 분류, 감성 어휘 추출, 품사 태그 지정, 구문 분석 등을 포함한 수 많은 자연 언어 처리 문제에 분산 단어 표현이 적용된다. 특히 워드 임베딩에 대한 장/단기 메모리 (LSTM) 네트 워크는 감성 분석에 성공적으로 적용되어 왔다. (Xin Wang, Yuanchao Liu, Chengjie Sun, Baoxun Wang, and Xiaolong Wang. 2015. Predicting polarities of tweets by composing word embeddings with long short-term memory. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages1343-1353, Beijing, China. Association for Computational Linguistics.) 토픽 모델과 단어 벡터를 결합하는 여러 접근법, 예를 들어 Cao et al. 의 신경 토픽 모델 및 Yang et al.(2015a)의 가우스 혼합 토픽 모델이 제안된 바 있지만, 이들은 감성 기반 토픽 모델까지는 확장되지 않았다. (Ziqiang Cao, Sujian Li, Yang Liu, Wenjie Li, and Heng Ji. 2015. A novel neural topic model and its super-vised extension. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January 25-30, 2015, Austin, Texas, USA., pages 2210-2216.) (Min Yang, Tianyi Cui, and Wenting Tu. 2015a. Ordering-sensitive and semantic-aware topic modeling. CoRR, abs/1502.0363.) 감성 분석에 대한 측면 기반 접근법(aspect-based approach)은 감성 극성을 예측하기 위해 학습된 분류자 (classifier)에 의해 보여지는 사전 정의되고 보통 수동으로 구성된 어휘 또는 단어를 포함하는 어구를 추출한 다. 이 작업들은 일반적으로 느낌(\"행복\", \"실망\")을 표현하는 감성 단어와 특정 사물이나 측면에 대한 감성을 표현 하는 평가 단어(\"완벽\", \"끔찍한\")를 구분한다. 이러한 단어는 기존에 알려진 사전에서 나오지만 토픽 모델은 개별 단어의 감성을 전체 텍스트의 전체 판단과 특정 측면의 개별 평가로 결합해야 한다. 오피니언 마이닝 (opinion mining)의 최근 개관에 따르면, 감성 어휘집(sentiment lexicon)은 대부분의 방법에서 핵심적인 역할 을 한다. 최근에는 여러 주제 모델이 제안되어 감성 분석에 성공적으로 사용되고 있다. LDA (Latent Dirichlet Allocation)와 그 확장 (Lin et al., 2012, Yang et al., 2015b, Lu et al., 2011)에 기초한 확률론적 토픽 모 델은 감성에 대한 문서-특화 분포가 있음을 가정하는데, 이는 감성이 문서에 보통 기록되어 있고 토픽 모델의 사전(prior)은 어휘집(lexicon)에 기반하기 때문이다. (Chenghua Lin, Yulan He, Richard Everson, and Stefan Ruger. 2012. Weakly supervised joint sentiment-topic detection from text. IEEE Transactions on Knowledge and Data Engineering, 24:1134 -1145.) (Zaihan Yang, Alexander Kotov, Aravind Mohan, and Shiyong Lu. 2015b. Parametric and non-parametric user-aware sentiment topic models. In Proceedings of the 38-th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 413-422. ACM.) (B. Lu, M. Ott, C. Cardie, andB.K. Tsou. 2011. Multiaspect sentiment analysis with topic models. Data Mining Workshops (ICDMW), 2011 IEEE 11thInter-national Conference, pages 81- 88.) 도 2 는 본 발명의 일 실시예에 따른 언어 심리의 층위를 단계화한 키워드 배열 중 핵심적으로 수렴하는 노드와 링크를 시각화 하는 방법을 도시한 것이고, 도 3 은 본 발명의 일 실시예에 따른 키워드의 언어 심리의 층위를 도시한 것이며, 도 4 는 본 발명의 일 실시예에 다른 키워드간 중요도의 위계 및 주요 스토리 구조에 따른 배열 을 풍배도 (windrose) 인터페이스로 구현된 것을 도시한 것이다. 도 2 내지 4 를 참조하면, 본 발명의 일 실시예에 따른 언어 심리의 층위를 단계화한 키워드 배열 중 핵심적으 로 수렴하는 노드와 링크를 시각화 하는 방법은 핵심 네트워크 추출부가 텍스트에서 전체 네트워크를 구성하고, 의미상으로 핵심적인 네트워크 추출 단계 , 차등화부가 중앙성 세부 지표의 기능에 따라 언어 심리의 층위 를 단계화하여 키워드 배열을 차등화 하는 단계 및 시각화부가 키워드들의 선후관계에 대한 통계적 계산 을 통해 핵심적으로 수렴하는 노드와 링크를 자동적으로 시각화 하는 단계 를 포함하도록 구비될 수 있다. 보다 구체적으로, 텍스트에서 전체 네트워크를 추출하여 차등화부는 중앙성 세부 지표의 기능에 따라 언어 심리 의 층위를 단계화 하여 키워드 배열을 차등화할 수 있는데, 이 때 도 3 의 가장 내부에 위치한 2 차 함축어 (Secondary connotation) 부터 정의하여 1 차 함축어 (Primary connotation) 및 2 차 지시어 (Secondary denotiona) 을 거쳐 동심원 외부에 있는 1 차 지시어 (Primary denotation) 까지 순차적으로 정의하도록 구비될 수 있다. 보다 구체적으로, 2 차 함축어는 추출된 핵심적인 네트워크 상에 위치한 키워드들의 In-Closeness Centrality 값이 가장 높은 단어로 결정되도록 구비될 수 있다. Closeness centrality 는 연결된 그래프에서 노드의 근접 중심성은 그래프에서 노드와 다른 모든 노드 사이의 최단 경로 길이의 합계의 역수로 계산되는 네트워크의 중심성을 측정한 것이다. 따라서 노드가 더 중심에 있을수록 다른 모든 노드에 더 가깝도록 구비된다. 다음으로, 1 차 함축어는 추출된 2 차 함축어들과 네트워크 상에 있는 키워드 중에서 PBS 값이 가장 높은 단어 로 결정되도록 구비될 수 있다. PBS 는 Potential Boundary Spanner 로서, 단어가 갖는 잠재적인 영향력을 판단하는 지표이다. 다음으로, 2 차 지시어는 1 차 함축어들과 네트워크 상에 있는 키워드 중에서 보나시치 영향력 (Bonacci Power) 값이 가장 높은 단어로 결정되도록 구비될 수 있다. 보나시치 영향력 (Bonacci Power) 은 단어가 가지는 객관적인 영향력을 평가하는 지표이다. 마지막으로, 1 차 지시어는 추출된 2 차 지시어들과 네트워크상에 있는 키워드 중에서 Betweenness 값이 가장 높은 단어로 결정되도록 구비될 수 있다. Betweenness 값은 Degree Centrality의 단점을 보완하여 단순히 얼마나 이웃과의 관계를 가졌는가가 아닌 전체 네트워크에서 해당 노드가 얼마나 다른 노드들과 잘 연결되어 있는가를 따진다. 네트워크에서 두 노드간에 얼마나 연관이 있는지를 측정할때 가장 일반적이며 많이쓰는 방법이 Shortest Path를 이용하는 방법이다. 즉 A, B 두 노드간에 거리가 얼마나 되는가를 통해 노드간의 관계를 나타낸다. Betweenness 는 이를 이용하여 A,B간의 영향력을 조사할때 V라는 노드를 꼭 지나가야한다면 V가 \"두 관계를 정 의하는데 중심이 되는 역할을 한다\" 라는 의미를 수식화하여 중요도를 표현한다. 네트워크에서 임의의 두 노드 관의 관계를 정의할때 V 노드를 거쳐가는 경우가 많을수록 V가 중요하다고 표현하는 것이다. 위와 같은 분석 방법을 통해, 도 4 에 도시된 바와 같이 가장 내심의 의사를 내포하는 키워드인 A 가 추출되고, A 와 네트워크 상에 있으며, A 로부터 1'', 1', 1 내지 4'', 4', 4 가 순차적으로 추출되어 디스플레이 될 수 있다. 도 4 에 도시된 풍배도의 디스플레이는 사용자들에게 키워드의 잠재적 의미를 도출할 수 있도록 직관력을 제공 할 수 있다. 일 예로, 어떠한 유력 정치인이 인터뷰에서 1, 2, 3, 4 와 관련된 키워드를 발제하였을 때, 1 차 지시어인 1, 2, 3, 4 는 발화자의 진정한 의도가 내포된 키워드들로 볼 수 없다. 따라서, 1 차 지시어인 1, 2, 3, 4 의 보다 깊은 의도가 내포된 키워드인 2 차 지시어인 1', 2', 3', 4' 를 디 스플레이 할 수 있으며, 2 차 지시어보다 더 깊은 의도가 내포된 키워드인 1 차 함축어인 1'', 2'', 3'', 4'' 를 디스플레이 되며, 결국 1 차 지시어로부터 발화자가 진정으로 내포하는 키워드인 A 를 디스플레이 되도록 구 비될 수 있다. 앞서 설명한 바와 같이, 실제로는 가장 내심의 의사인 2 차 함축어부터 도출되지만, 실제 사용자들에게는 동심 원상 가장 외부에 있는 1 차 지시어로부터 2 차 함축어가 도출되는 형식으로 디스플레이 함으로써, 2 차 함축어 가 도출되는 논리를 사용자가 이해할 수 있는 근거를 제공할 수 있는 효과가 있다. 다만, 이와 같은 표시 방법은 사용자의 편의에 따라 변형되어 사용될 수 있으며, 색상의 종류나 표시되는 도형 은 본 발명의 설명의 편의를 위해 예를 든 것이며, 이는 본원 발명의 권리범위를 한정하지 않는다."}
{"patent_id": "10-2022-0112422", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 은 본 발명의 일 실시예에 따른 머신 러닝 워크플로우(machine learning workflow)를 보여주는 도면이다. 도 2 는 본 발명의 일 실시예에 따른 언어 심리의 층위를 단계화한 키워드 배열 중 핵심적으로 수렴하는 노드와 링크를 시각화 하는 방법을 도시한 것이다. 도 3 은 본 발명의 일 실시예에 따른 키워드의 언어 심리의 층위를 도시한 것이다. 도 4 는 본 발명의 일 실시예에 다른 키워드간 중요도의 위계 및 주요 스토리 구조에 따른 배열을 풍배도 (windrose) 인터페이스로 구현된 것을 도시한 것이다."}
