{"patent_id": "10-2021-0130812", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0047686", "출원번호": "10-2021-0130812", "발명의 명칭": "영상 복원을 위한 네트워크 학습 방법", "출원인": "주식회사 픽스트리", "발명자": "신재섭"}}
{"patent_id": "10-2021-0130812", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학습부에서 각각의 PD 별로 독립적으로 사전 학습(Pre-training)을 수행한 PD들을 순차적 단계로 연결한 복수의PD(Pre-trained Decoder)로 구성된 딥러닝 네트워크에 대하여 학습을 수행하는 과정; 및상기 학습부에서 각 단계 별 PD와 연결된 DAF로 구성된 복수의 DAF 모듈에 대한 학습을 수행하는 과정;을 포함하는 것을 특징으로 하는 영상 복원을 위한 네트워크 학습 방법."}
{"patent_id": "10-2021-0130812", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 학습부에서 하위 단계에서 최상위 단계까지의 상기 복수의 PD 및 상기 복수의 DAF를 하위 단계에서부터 순차적으로 단계를연결해 가면서 학습하는 것을 특징으로 하는 영상 복원을 위한 네트워크 학습 방법."}
{"patent_id": "10-2021-0130812", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 학습부에서 복수의 PD와 복수의 DAF를 영상의 해상도, 프레임율, 비트율, 품질 계수 중 1개 또는 복수개로구성된 스케일 레벨 별로, 각각의 PD와 DAF로 단계를 구성하는 것을 특징으로 하는 영상 복원을 위한 네트워크학습 방법."}
{"patent_id": "10-2021-0130812", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 학습부에서, 상기 복수의 PD 중 각각의 스케일 레벨에 사용되는 PD를 선별하고, 상기 각각의 스케일 레벨에 사용되는 PD에서최초 학습 시 입력 영상의 스케일별로 각각 독립적으로 학습을 수행하는 것을 특징으로 하는 영상 복원을 위한네트워크 학습 방법."}
{"patent_id": "10-2021-0130812", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 학습부에서, 학습이 완료된 단계까지의 네트워크 상에서 다음 단계의 학습 시, 이미 학습이 완료된 단계까지에 포함된 PD 및DAF는 업데이트되지 않도록 하고 새로이 추가되는 단계에 포함된 PD 및 DAF만을 학습하여 업데이트 되도록 하는것을 특징으로 하는 영상 복원을 위한 네트워크 학습 방법."}
{"patent_id": "10-2021-0130812", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 학습부에서, 상기 복수의 PD 중 최초 스케일 레벨에서 이용되는 PD를 제외한 나머지 단계에서 이용되는 PD마다 파라미터 인플레이팅을 수행해서 이전 단계의 PD 출력과, 이전 하위 단계들의 DAF의 출력들과, 원본 입력을 해당 단계 입력스케일로 스케일링한 영상을 포함하는 다수개의 입력을 받아 학습을 수행하도록 하는 것을 특징으로 하는 영상복원을 위한 네트워크 학습 방법.공개특허 10-2023-0047686-3-"}
{"patent_id": "10-2021-0130812", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상 복원을 위한 네트워크 학습 방법을 개시한다. 본 실시예는 모자이크에서부터 저저도 노이즈를 포함하는 합성 저화질 이미지, 실제 저화질 이미지 모두에서 발 생하는 단일 왜곡, 수많은 조합과 강도로 구성된 복합 왜곡, 실제 왜곡, 학습과정에서 미학습된 왜곡, 복원 가능 여부 또는 복원 불가능 여부를 판별하는 능력을 하나의 통합된 인공신경망으로 구현하여 영상을 복원할 수 있도 록 하는 네트워크 학습 방법을 제공한다."}
{"patent_id": "10-2021-0130812", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 일 실시예는 영상 복원을 위한 네트워크 학습 방법에 관한 것이다."}
{"patent_id": "10-2021-0130812", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에 기술되는 내용은 단순히 본 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구성하는 것이 아니 다. 일반적으로 저해상도 영상을 고해상도 영상으로 복원하는 기술은 복원에 사용되는 입력영상의 수 또는 복원 기 술에 따라 구분된다. 입력영상의 수에 따라 단일영상 초해상도 복원 기술과 연속영상 초해상도 복원 기술로 구 분된다. 일반적으로 단일영상 초해상도 영상복원 기술은 연속영상 초해상도 영상복원에 비하여 처리 속도는 빠르지만, 복원에 필요한 정보가 부족하므로 영상 복원의 품질이 낮다. 연속영상 초해상도 영상복원 기술은 연속적으로 획득된 다수의 영상들로부터 추출된 다양한 특징을 이용하므로 단일영상 초해상도 영상복원 기술에 비하여 복원된 영상의 품질은 우수하나, 알고리즘이 복잡하고 연산량이 많 아 실시간 처리가 어렵다. 복원 기술에 따라서는 보간법을 이용한 기술, 에지 정보를 이용한 기술, 주파수 특성을 이용한 기술, 딥러닝 등 과 같은 기계학습을 이용한 기술 등이 있다. 보간법을 이용한 기술은 처리 속도가 빠르지만 가장자리 부분이 흐 릿해지는 단점이 있다. 에지 정보를 이용한 기술은 속도도 빠르고 가장자리의 선명도를 유지하면서 영상을 복원할 수 있으나, 에지 방 향을 잘못 추정한 경우에는 시각적으로 두드러지는 복원 에러를 포함할 수 있는 단점이 있다. 주파수 특성을 이용한 기술은 고주파성분을 이용하여 에지 정보를 이용한 기술과 같이 가장자리의 선명도를 유 지하며 영상을 복원할 수 있으나 경계선 부근의 Ringing Artifact가 발생하는 단점이 있다. 마지막으로 예제 기 반 또는 딥러닝과 같은 기계학습을 이용한 기술은 복원된 영상의 품질이 가장 우수하지만 처리속도가 매우 느리 다. 상술한 바와 같이 기존의 다양한 고해상도 영상 복원 기술들 중 연속영상 초해상도 영상복원 기술은 기존의 보 간법을 이용한 디지털 줌 기능이 필요한 분야에 적용될 수 있으며, 보간법 기반의 영상복원 기술에 비해 우수한 품질의 영상을 제공한다. 그러나, 기존의 초해상도 영상복원 기술은, 제한된 리소스와 실시간 처리가 요구되는 전자광학 장비에는 복잡한 연산량으로 인해 적용할 수 있는 기술이 제한적이다. 실시간 처리가 가능한 기존의 단일영상 기반의 초해상도 영상복원 기술은 기 설정된 배수 이상의 고배율로 영상 확대가 필요한 경우에 연속영상 기반의 복원 기술에 비해 성능 저하가 크다는 문제가 있다."}
{"patent_id": "10-2021-0130812", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 실시예는 모자이크에서부터 저저도 노이즈를 포함하는 합성 저화질 이미지, 실제 저화질 이미지 모두에서 발 생하는 단일 왜곡, 수많은 조합과 강도로 구성된 복합 왜곡, 실제 왜곡, 학습과정에서 미학습된 왜곡, 복원 가 능 여부 또는 복원 불가능 여부를 판별하는 능력을 하나의 통합된 인공신경망으로 구현하여 영상을 복원할 수 있도록 하는 네트워크 학습 방법을 제공하는 데 목적이 있다."}
{"patent_id": "10-2021-0130812", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 실시예의 일 측면에 의하면, 학습부에서 복수의 PD(Pretrained Decoder) 별로 영상의 스케일(Scale)에 따라 각각 독립적으로 학습을 수행하는 과정; 및 상기 학습부에서 상기 PD 별로 파라미터 인플레이팅 후, DAF(Domain Aware Fusion) 출력을 입력으로 받을 수 있도록 하고, 복수의 DAF 모듈을 연결하고 이에 대한 학습을 수행하는 과정;을 포함하는 것을 특징으로 하는 영상 복원을 위한 네트워크 학습 방법을 제공한다."}
{"patent_id": "10-2021-0130812", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이 본 실시예에 의하면, 모자이크에서부터 저저도 노이즈를 포함하는 합성 저화질 이미 지, 실제 저화질 이미지 모두에서 발생하는 단일 왜곡, 수많은 조합과 강도로 구성된 복합 왜곡, 실제 왜곡, 학 습과정에서 미학습된 왜곡, 복원 가능 여부 또는 복원 불가능 여부를 판별하는 능력을 하나의 통합된 인공신경 망으로 구현하여 영상을 복원하는 네트워크 학습을 수행할 수 있는 효과가 있다."}
{"patent_id": "10-2021-0130812", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 제1 실시예에 따른 PPD 형태의 영상 복원 장치를 위한 인공지능 네트워크 구성 및 그 학습 방법을 나타 낸 도면이다. 본 발명의 영상 복원 장치를 위한 인공지능 네트워크는 영상의 스케일별로 각각 독립적으로 학습을 수행한 복수 의 PD(Pretrained Decoder)를 캐스캐이드(Cascade) 방식으로 연결한 PPD(Pretrained Progressive Decoder) 형 태를 가진다. 본 발명의 인공지능 네트워크 및 그 학습 방법을 적용한 영상 복원 장치는 복수의 PD에서 영상의 스케일별로 각각 추론한 추론 결과를 다음에 연결된 PD로 입력하는 과정을 수행한다. [PPD (추론) 네트워크 구조 설명] 다시 말해, k 단계의 추론 네트워크 블록(PDk-1, Ik-1 detail, Ik-1 content (또는 DAFk-1(제2 실시예의 경우))과 해당 단 계의 추론 결과 영상의 스케일 레벨 k (Ik detail)를 설정하고, 각 단계에 PD와 DAF(제2 실시예의 경우 포함)를 구 성하여, 하위 단계에서부터 순차적으로 다음 상위 단계와 연결한다. 각 단계의 PD는 다수개의 입력을 받아 처리 할 수 있도록 파라미터 인플레이팅을 적용할 수 있다. 단, 최하위 단계에서는 입력 영상에 대하여 해당 스케일 로 스케일링된 한 개의 입력만을 PD에 적용할 수도 있으므로, 최하위 단계의 PD에서는 파라미터 인플레이팅을 적용하지 않을 수 있다. 즉, k>1(최하위 단계가 아닌 단계)에서는 이전 단계의 PD에서 추론한 결과(즉, Ik-1 detail)를 해당 단계의 PD(즉, PDk-1)로 입력하고, 해당 단계의 PD에서는 파라미터(Parameter) 인플레이팅(Inflating)을 통해 두 개(예시적으로 두 개이며 다수 개일 수도 있음)의 입력인, 이전 PD의 추론 결과(즉, Ik-1 detail)와, 입력 영상을 해당 단계 입력 스케일로 스케일링한 결과인 Ik-1 content (또는, 도 2의 경우, 해당 단계의 DAF(즉, DAFk-1)의 출력)를 입력으로 받 아, 해당 단계에서 업스케일링된 스케일 레벨 k 영상(Ik detail)을 추론하는 인공 지능 네트워크 구조를 갖는다. 본 실시예에 따른 복수의 PD(Pretrained Decoder)는 PDk-1(k=1), PDk-1 I(k>1)를 포함한다. 본 발명의 인공 지능 네트워크를 적용한 영상 복원 장치는 PDk-1(k=1), 내지 PDk-1 I(k>1)를 캐스케이드 방식으로 연결한 PPD(Pretrained Progressive Decoder) 구조를 가진다. PDk-1(k=1) 및 PDk-1 I(k>1)를 연결한 구조에서 각각의 PD를 통한 영상의 스케일 레벨별 추론 결과는 상위 단계의 PD로 입력되는 구조를 갖는다. 즉, PPD로 구성된 인공 지 능 네트워크의 최상위 단계 PD의 출력을 통해 입력 영상에 대하여 업스케일된 최상위 스케일 레벨의 영상을 복 원할 수 있는 것이다. PDk-1(k=1)는 해당 단계 입력 스케일로 다운스케일된 영상(Ik-1 content, k=1)만을 입력받고, 이에 인공 지능 학습 결 과를 반영하여, 기 설정된 배수로 업스케일링한 제1 스케일 레벨 업스케일 복원 영상(Ik detail, k=1)을 출력한다. PDk-1 I(k>1)는 해당 단계 입력 스케일로 다운스케일된 영상(Ik-1 content, k>1)과 이전 PD의 출력 복원 영상(Ik-1 detail, k>1)을 입력 받는다. PDk-1 I(k>1)는 해당 단계 입력 스케일로 다운스케일된 영상(Ik-1 content, k>1)과 이전 PD의 출 력 복원 영상(Ik-1 detail, k>1)에 인공 지능 학습 결과를 반영하여 기 설정된 배수로 업스케일링한 제 k 스케일 레 벨 업스케일 복원 영상(Ik detail, k>1)을 출력한다. 이하, PDk-1(k=1)에 해당하는 PD0의 동작 과정에 대해 예시적으로 설명한다. PD0는 제1 단계에 포함되며, 해당 스케일 레벨로 다운스케일링한 제0 스케일 레벨 영상(I0 content)만을 입력 받는 다. PD0는 제0 스케일 레벨 영상(I0 content)에 인공 지능 학습 결과를 반영하여 기 설정된 배수로 업스케일링한 제 1 스케일 레벨 복원 영상(I1 detail)을 출력한다. 이하, PDk-1 I(k>1)에 해당하는 PD1 I, PD2 I, PD3 I, PD4 I의 동작 과정에 대해 예시적으로 설명한다. PD1 I는 제2 단계에 포함되며, 해당 단계 입력 스케일로 다운스케일링한 영상(I1 content)과 제1 스케일 레벨 복원 영 상(I1 detail)을 입력받는다. PD1 I는 해당 단계 입력 스케일로 다운스케일링한 영상(I1 content)과 제1 스케일 레벨 복 원 영상(I1 detail)에 인공 지능 학습 결과를 반영하여, 기 설정된 배수로 업스케일링한 제2 스케일 레벨 복원 영상 (I2 detail)을 출력한다. PD2 I는 제3 단계에 포함되며, 해당 단계 입력 스케일로 다운스케일링한 영상(I2 content)과 제2 스케일 레벨 복원 영 상(I2 detail)을 입력받는다. PD2 I는 해당 단계 입력 스케일로 다운스케일링한 영상(I2 content)과 제2 스케일 레벨 복 원 영상(I2 detail)에 인공 지능 학습 결과를 반영하여 기 설정된 배수로 업스케일링한 제3 스케일 레벨 복원 영상 (I3 detail)을 출력한다. PD3 I는 제4 단계에 포함되며, 해당 단계 입력 스케일로 다운스케일링한 영상 (I3 content)과 제3 스케일 레벨 복원 영상(I3 detail)을 입력 받는다. PD3 I는 해당 단계 입력 스케일로 다운스케일링한 영상(I3 content)과 제3 스케일 레벨 복원 영상(I3 detail)에 인공 지능 학습 결과를 반영하여 기 설정된 배수로 업스케일링한 제4 스케일 레벨 복원 영 상(I4 detail)을 출력한다. PD4 I는 제5 단계에 포함되며, 해당 단계 입력 스케일로 다운스케일링한 영상(I4 content)과 제4 스케일 레벨 복원 영 상(I4 detail)을 입력 받는다. PD4 I는 해당 단계 입력 스케일로 다운스케일링한 영상(I4 content)과 제4 스케일 레벨 복 원 영상(I4 detail)에 인공 지능 학습 결과를 반영하여 기 설정된 배수로 업스케일링한 제5 스케일 레벨 복원 영상 (I5 detail)을 출력한다. 본 실시예에서는 제5 스케일 레벨 복원 영상(I5 detail)을 본 발명의 인공 지능 네트워크 및 학습 방법을 적용한 영 상 업스케일 복원 장치의 출력으로 사용한다. [PPD 네트워크 학습 방법] 본 실시예에 따른 복수의 PD(Pretrained Decoder)는 영상의 스케일(Scale)별로 각각 독립적으로 초기 학습을 수 행한 후, PPD 형식으로 캐스캐이드로 하위 단계에서 순차적으로 상위 단계 PD들을 연결하면서, 각 단계에 해당 하는 PD 추가 시 마다 추가되는 PD에 대하여 튜닝 학습을 진행하며, 이때 이미 이전 단계에서 튜닝 학습이 완료 된 PD에 대해서는 다시 학습하지 않도록 한다. 전체 학습 네트워크의 구성은 복수의 PD로 구성되며, 복수의 PD는 PDk-1(k=1), PDk-1 I(k>1)를 포함한다. 이때 아 래첨자 I가 표기될 경우, 해당 PD에 파라미터 인플레이팅이 적용되었음을 나타낸다. 파라미터 인플레이팅은 사 전 학습된 네트워크의 입력 채널을 다수 개로 확장하기 위한 방법이다. 해당 방법은 사전 학습된 입력 채널을 다수 개로 복사하는 과정, 복사한 다수 개의 채널을 연결(Concatenation)하는 과정, 연결된 채널 내 파라미터들 의 스케일을 조정하는 과정으로 구성된다. 본 발명의 영상 복원 장치 네트워크는 영상의 스케일 레벨 별로 단계를 구성하여 PDk-1(k=1), 내지 PDk-1 I(k>1)를 단계별 캐스캐이드 방식으로 연결한다. 영상 복원 장치 네트워크에 포함된 PDk-1 I(k>1)는 복수개의 입력을 수용할 수 있도록 파라미터 인플레이팅이 적용 될 수 있다. PPD 구조의 네트워크를 학습하기 위하여, 각각 독립적으로 학습한 PDk-1(k=1) 내지 PDk-1 I(k>1)를 순차적으로 프 로그레시브하게 연결하면서 각 단계별 PD에 대한 튜닝 학습을 진행하여 전체 네트워크를 학습하는 방법을 사용 한다. 다시 말해, PPD와 같은 네트워크 구조에서는 복수의 스케일 레벨 별 단계 들에 포함된 PD들을 한 번에 학 습하기 어렵다. 이러한 문제를 해결하기 위해서, 네트워크 구성 요소 인 각 단계 별 PD를 순차적으로 연결하면 서, 새로이 추가되는 PD에 대하여 기존 초기 학습 파라미터를, 추가되는 네트워크에 맞추어 튜닝하는 튜닝 학습 을 진행하여 해당 단계를 위하여 새로 연결되는 PD의 학습을 완료한다. 이때 이전 단계까지 연결되면서 튜닝 학 습이 완료된 기 연결된 PD는 학습하지 않고, 추가되는 PD에 대해서만 학습한다. 복수의 스케일을 학습하는 과정을 각각의 스케일별로 독립적으로 수행한 후 서로 연결할 수 있으나, 본 발명에 서는 각각의 스케일별로 사전에 독립적으로 학습한 PD를 단계적으로 연결하면서, 새로이 연결되는 PD를 포함하 는 네트워크까지의 구성을 기반으로, 새로이 연결되는 PD에 대하여 튜닝 학습을 진행하여 스케일 레벨 별 추가 연결 단계의 네트워크를 순차적으로 연결하는 것이다. 이러한 방식으로 PDk-1(k=1), PDk-1 I(k>1)는 각각의 네트워크 파라미터가 학습되어 설정된다. PPD에서 각 단계에 서의 PD는 원본을 해당 단계 입력으로 스케일링한 영상과 함께, 이전 단계의 PD를 통해 업 스케일한 복원 영상 등, 이용 가능한 영상 정보를 해당 단계의 PD의 입력으로 이용하고, 학습 목표 영상으로, 최초 클린 원본 영상 을 해당 단계 PD의 출력 스케일 레벨과 동일하게 스케일링한 영상을 적용하여, 학습을 수행한다. 본 발명의 인 공지능 네트워크를 학습 시에는, 다양한 왜곡이 반영된 입력 영상을 원본 입력 영상으로 사용할 수 있으며, 이 러한 왜곡이 반영된 영상을 입력 원본으로 하여, 왜곡이 없는 원래의 입력 영상인 최초 클린 원본 영상을 출력 할 수 있도록 인공지능 네트워크를 학습하여야 한다. PDk-1(k=1)는 해당 단계 입력 스케일로 스케일링한 영상(Ik-1 content, k=1)만을 입력으로 받고, PDk-1(k=1)의 출력인 제 k (k=1) 스케일 레벨 복원 영상(Ik detail, k=1)의 스케일 레벨로 최초 클린 원본 영상을 스케일링한 영상을 목 표 영상으로 하여 튜닝 학습을 수행한다. PDk-1 I(k>1)는 해당 단계 입력 스케일로 다운스케일링한 영상(Ik-1 content, k>1)과 이전 단계 PD의 출력 스케일 레벨 복원 영상(Ik-1 detail, k>1)을 입력으로 받고, PDk-1 I(k>1)의 출력인 제 k (k>1) 스케일 레벨 복원 영상(Ik detail, k>1)의 스케일 레벨로 최초 클린 원본 영상을 스케일링한 영상을 목표 영상으로 하여 튜닝 학습을 수행한다. 다음 단계인 PDk I는 해당 단계 입력 스케일로 스케일링한 영상(Ik content, k>1)과 현재 단계 PDk-1 I(k>1)의 출력 스 케일 레벨 복원 영상(Ik detail, k>1)을 입력으로 받아, PDk I의 출력인 제 k+1 (k>1) 스케일 레벨 복원 영상(Ik+1 detail, k>1)의 스케일 레벨로 최초 클린 원본 영상을 스케일링한 영상을 목표 영상으로 하여 튜닝 학습을 수 행한다. 도 2는 제2 실시예에 따른 DAF를 적용한 인공지능 네트워크 구성 및 그 학습 방법을 나타낸 도면이다. [PPD 및 DAF (추론) 네트워크 구조 설명] 제2 실시예에 따른 본 발명의 인공지능 네트워크의 구조는 제1 실시예의 구조에서 각 단계별로 DAF(Domain Aware Fusion) 모듈을 추가로 적용하는 구조이다. (도 2 참조) 즉, 제2 실시예는, 제1 실시예의 구조에서, 각 단계별 PD 앞 단에 DAF를 추가한 구조이다. 다시 말해, 제1 실시 예의 구조에서 각 단계의 PD의 입력 중 하나인 해당 단계 입력 스케일로 스케일링한 입력 영상을 그대로 입력으 로 사용하지 않고, 대신에 해당 입력 위치에 DAF 모듈을 추가 후, 해당 단계 입력 스케일로 스케일링한 입력 영 상을 포함한 해당 단계에서 이용 가능한 다양한 정보를 이용하여, 해당 단계의 PD 출력을 얻기 위한 최적의 정 보를 생성한 후 이를 해당 단계 PD의 입력으로 사용하는 구조이다. 즉, 복수의 DAF 모듈(DAFk-1, k>1)은 하위 단계에 포함된 DAF 출력 영상들을 해당 단계의 입력 스케일로 스케일 링한 영상(IL→k-1 da-content, k>1, (k-1)>L≥0)(단, k=2인 경우, I0→1 da-content= I0→1 content), 해당 단계의 입력 스케일 로 다운스케일링한 영상(Ik-1 content, k>1), 이전 단계 PD의 출력 복원 영상(Ik-1 detail, k>1) 등 이용 가능한 정보를 기반으로 현재 단계의 DAF(DAFk-1, k>1)를 수행하여, 현재 단계의 PD의 최적 출력을 얻을 수 있도록 하는 최적 DAF 출력 정보(Ik-1 da-content, k>1)를 생성한다. [DAF 구조 및 기능 설명] 제2 실시예의 DAF는 해당 단계의 PD를 통한 최적의 업스케일링 복원 영상 출력을 얻기 위해 필요한 정보를 생성 하는 모듈로, 여러가지 구조의 모듈을 적용할 수 있다. 그 중 일 예시로 도 3의 구조와 기능에 대하여 설명한다. 복수의 DAF 모듈은, 입력 영상을 해당 단계 입력 스케일로 스케일링한 영상, 해당 단계의 하위 단계별 DAF 출력 들을 해당 단계의 입력 스케일로 스케일링한 영상들, 이전 단계 PD 출력 복원 영상을, 각 단계마다 입력 정보로 받는다. 각 단계의 DAF 모듈은 입력 영상을 해당 단계 입력 스케일로 스케일링한 영상, 해당 단계의 하위 단계별 DAF 출 력들을 해당 단계의 입력 스케일로 스케일링한 영상들과, 이전 단계 PD 출력 복원 영상과의 차감값을 각각 산출 한다. DAF 모듈은 상기 각 차감값을 그룹 컨벌루션을 취한 후 소프트맥스(Softmax)에 입력하여 출력값을 합산했을 때 총합이 1이되도록 한다. DAF 모듈은 소프트맥스를 거친 각 출력값에, 이전 단계 PD 출력 복원 영상을 곱한 후 합산하여, DAF 출력 정보(Ik-1 da-content, k>1)로 생성하여, 이후에 연결된 PD에 입력한다. 이러한 과정을 거쳐서 출력되는 DAF 출력 정보는 하위 단계의 PD 출력 정보가 단계를 거치면서 실제 입력 영상 정보의 특징을 약화시키지 않고 유지할 수 있도록 하는 기능을 수행한다. 즉, DAF 모듈은, 본 발명의 네트워크 에서 필요한 기능을 수행하도록 설계하여 학습, 적용할 수 있으며, 도 3의 예시에서와 같이, 본 발명의 추론 네 트워크의 출력을 목표하는 방향으로 유지할 수 있도록 하는 기능을 할 수도 있다. [PPD 및 DAF 네트워크 학습 방법] 제2 실시예의 네트워크 학습 방법은 제1 실시예에서의 학습방법과 같이 프로그레시브 방식을 사용하며, 제1 실 시예와의 차이점은 DAF를 추가하여, 단계별 학습 시 각 단계의 PD와 함께 DAF도 추가하여 같이 학습하는 점이다. 제2 실시예에 따른 복수의 PD(Pretrained Decoder)는 영상의 스케일(Scale)별로 각각 독립적으로 초기 학습을 수행한 후, PPD 형식으로 캐스캐이드로 하위 단계에서 순차적으로 상위 단계 PD와 DAF를 연결하면서, 각 단계에 해당하는 PD 및 DAF 추가 시 마다 추가되는 PD 및 DAF에 대하여 튜닝 학습을 진행하고, 이때 이미 이전 단계에 서 튜닝 학습이 완료된 PD 및 DAF에 대해서는 다시 학습하지 않도록 한다. 전체 학습 네트워크의 구성은 복수의 PD와 DAF로 구성되며, 복수의 PD는 PDk-1(k=1), PDk-1 I(k>1)를 포함하며, 복 수의 DAF는 DAFk-1 (k>1)를 포함한다. 이때 아래첨자 I가 표기될 경우, 해당 PD에 파라미터 인플레이팅이 적용되 었음을 나타낸다. 파라미터 인플레이팅은 사전 학습된 네트워크의 입력 채널을 다수 개로 확장하기 위한 방법이 다. 해당 방법은 사전 학습된 입력 채널을 다수 개로 복사하는 과정, 복사한 다수 개의 채널을 연결 (Concatenation)하는 과정, 연결된 채널 내 파라미터들의 스케일을 조정하는 과정으로 구성된다. PPD 구조의 네트워크를 학습하기 위하여, 각각 독립적으로 학습한 PDk-1(k=1) 내지 PDk-1 I(k>1)와, 초기화 되어 있는 각 단계별 DAFk-1 (k>1)를, 각 단계 별로 순차적으로 프로그레시브하게 연결하면서, 각 단계 별 PD에 대한 튜닝 학습과 각 단계별 DAF에 대한 학습을 진행하여 전체 네트워크를 학습하는 방법을 사용한다. 다시 말해, PPD와 같은 네트워크 구조에서는 복수의 단계들에 포함된 PD들과 DAF들을 한 번에 학습하기 어렵다. 이러한 문 제를 해결하기 위해서, 네트워크 구성 요소 인 각 단계 별 PD와 DAF를 순차적으로 연결하면서, 새로이 추가되는 PD에 대하여, 기존 초기 학습 파라미터를 추가되는 네트워크에 맞추어 튜닝하는 튜닝 학습을 진행하고, 새로이 추가되는 DAF에 대하여 초기화 되어 있는 파라미터를 추가되는 네트워크에 맞추어 학습을 진행하여, 해당 단계 를 위하여 새로 연결되는 PD와 DAF의 학습을 완료한다. 이때 이전 단계까지 연결되면서 학습의 완료된 기 연결 된 PD와 DAF는 학습하지 않고, 추가되는 PD와 DAF에 대해서만 학습한다. 복수의 스케일을 학습하는 과정을 각각의 스케일별로 독립적으로 수행한 후 서로 연결할 수 있으나, 본 발명에 서는 각각의 스케일별로 사전에 독립적으로 학습한 PD를 단계적으로 연결하면서, 새로이 연결되는 PD와 DAF를 포함하는 네트워크까지의 구성을 기반으로, 새로이 연결되는 PD에 대하여 튜닝 학습을 진행하고, 추가 연결되는 DAF에 대하여 학습을 진행하여, 단계 별 네트워크를 순차적으로 연결하는 것이다. 이러한 방식으로 PDk-1(k=1), PDk-1 I(k>1)와 DAFk-1 (k>1)의 각각의 네트워크 파라미터가 학습되어 설정된다. 실시예 2의 PPD 구조의 네트워크에서, 각 단계에서의 PD는 이전 단계 PD의 출력 영상과, 해당 단계의 DAF 출력 정보를 입력으로 이용하고, 학습 목표 영상으로 최초 클린 원본 영상을 해당 스케일 레벨의 PD의 출력 스케일과 동일하게 스케일링한 영상을 적용하여, 학습을 수행한다. 이때 해당 단계의 DAF도 동시에 학습이 진행되며, DAF는, 이전 단계의 PD의 업스케일 복원 영상 출력, 해당 단 계 보다 하위 단계의 DAF 출력들을 현재 단계의 DAF 입력 스케일로 스케일링한 정보들 등, 이용 가능한 정보를 해당 단계의 DAF의 입력으로 적용한 후, 출력 되는 정보를 해당 단계의 PD의 입력으로 적용하고, 해당 단계의 PD의 출력이 학습 목표 영상인 최초 클린 원본 영상을 해당 스케일 레벨로 스케일한 영상이 될 수 있도록 해당 단계의 PD와 함께 DAF 학습을 수행한다. PDk-1(k=1)는 해당 단계 입력 스케일로 스케일링된 영상(Ik-1 content, k=1)만을 입력으로 받고, PDk-1(k=1)의 출력인 제 k (k=1) 스케일 레벨 복원 영상(Ik detail, k=1)의 스케일 레벨로 최초 클린 원본 영상을 스케일링한 영상을 목 표 영상으로 하여 튜닝 학습을 수행한다. DAFk-1 (k>1)는 입력으로, 해당 단계 하위 단계까지에서 얻어진 이용 가능한 다양한 정보를 이용할 수 있으며, 일례로, 도 2에서와 같이, I0 content를 현재 단계의 입력 스케일로 스케일링한 영상, 현재 단계 이전 모든 하위 단 계의 DAF 출력 정보들(DAFk-1 출력 정보, 현재 단계>k>1 인 모든 k)을 현재 단계의 입력 스케일로 스케일링한 정 보와, 원본 입력 영상을 현재 단계의 입력 스케일로 다운스케일링한 영상(Ik-1 content, k>1)과, 이전 단계 PD의 출 력 복원 영상(Ik-1 detail, k>1) 등 이용 가능한 모든 정보를 입력으로 이용할 수 있다. DAFk-1 (k>1)에 대한 학습은 이러한 입력 정보에 대하여, 해당 단계의 PDk-1 (k>1)가 학습 목표 영상을 생성할 수 있도록 하는 최적의 영상 정보를 출력하도록 학습된다. PDk-1 I(k>1)는, DAFk-1(k>1)의 출력 정보와 이전 단계 PD의 출력 복원 영상(Ik-1 detail, k>1)을 입력으로 받아, PDk- 1 I(k>1)의 출력인 제 k (k>1) 스케일 레벨 업스케일 복원 영상(Ik detail, k>1)의 스케일 레벨로 최초 클린 원본 영상을 스케일링한 영상을 목표 영상으로 하여 튜닝 학습을 수행한다. 본 실시예에 따른 영상 복원 장치는 학습부를 포함한다. 학습부는 복수의 PD(Pretrained Decoder) 별로 영상의 스케일(Scale)에 따라 각각 독립적으로 학습을 수행한다. 학습부는 하위 스케일 레벨(Scale LEVEL)에서 최상위 스케일 레벨까지의 복수의 PD 및 복수의 DAF를 단계(STEP) 별로 연결하면서 학습을 수행한다. 학습부는 복수의 PD 및 DAF 별로 이전 단계에서 학습한 PD 및 DAF에 대해서 다시 학습을 수행하지 않도록 한다. 학습부는 복수의 PD 중 각각의 스케일 레벨 영상 출력을 얻기 위해 사용되는 PD를 단계별로 선별한다. 학습부는 각각의 단계에 사용되는 PD에서 최초 학습 시 입력 영상의 스케일별로 각각 독립적으로 학습을 수행한다. 학습 부는 각각의 스케일 레벨별로 학습이 완료된 PD와 각 PD 앞단의 DAF를 연결한 구조상에서 하위 스케일 레벨부터 단계별로 학습을 수행한다. 학습부는 학습이 완료된 단계까지의 네트워크에서 다음 단계를 추가 연결 후 새로이 추가된 단계의 학습 시에는 이전 단계가 학습 및 업데이트되지 않도록 하는 프로그레시브 학습을 수행한다. 학습부는 복수의 PD 중 최초 스케일 레벨에서 이용되는 PD를 제외한 나머지 단계에서 이용되는 PD마다 파라미터 인플레팅을 수행해서 이전 단계의 PD 출력과 해당 단계의 DAF의 출력을 입력 받아 학습을 수행하도록 한다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0130812", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 실시예에 따른 PPD 형태에서 이미지 처리를 방법을 나타낸 도면이다. 도 2는 본 실시예에 따른 DAF 적용 구조에서 이미지 처리 방법을 나타낸 도면이다. 도 3a,3b는 본 실시예에 따른 DAFk 모듈의 이미지 처리 방법을 나타낸 도면이다."}
