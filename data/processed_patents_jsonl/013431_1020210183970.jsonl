{"patent_id": "10-2021-0183970", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0095162", "출원번호": "10-2021-0183970", "발명의 명칭": "이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법, 서버 및 컴퓨터프로그", "출원인": "주식회사 와따", "발명자": "김경식"}}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치에 의해 수행되는 방법에 있어서,건물의 출입구 영역을 촬영한 이미지 데이터를 수집하는 단계;상기 건물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우드 데이터를 수집하는 단계;상기 수집된 이미지 데이터 및 상기 수집된 제1 라이다 포인트 클라우드 데이터를 분석하여 객체를 식별하는 단계; 및상기 건물 내부를 실시간으로 스캔함에 따라 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 분석하여상기 식별된 객체의 동선을 추적하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 객체를 식별하는 단계는,기 학습된 인공지능 모델 - 상기 기 학습된 인공지능 모델은 복수의 객체에 대한 정보가 레이블링(Labeling)된복수의 이미지 데이터 및 복수의 라이다 포인트 클라우드 데이터를 학습데이터로 하여 기 학습된 모델임 - 을이용하여 상기 수집된 이미지 데이터로부터 복수의 제1 객체를 식별하고, 상기 식별된 복수의 제1 객체에 대한하나 이상의 제1 특징점을 추출하는 단계;상기 기 학습된 인공지능 모델을 이용하여 상기 수집된 제1 라이다 포인트 클라우드 데이터로부터 복수의 제1객체를 식별하고, 상기 식별된 복수의 제1 객체에 대한 하나 이상의 제2 특징점을 추출하는 단계; 및상기 식별된 복수의 제1 객체 각각에 대한 식별코드를 부여하고, 상기 부여된 식별코드와 상기 추출된 하나 이상의 제1 특징점 및 상기 추출된 하나 이상의 제2 특징점을 매칭하여 저장함으로써, 상기 식별된 복수의 제1 객체에 대한 제1 객체 데이터베이스를 구축하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 하나 이상의 제1 특징점을 추출하는 단계는,상기 식별된 복수의 제1 객체 중 상기 수집된 이미지 데이터를 수집한 카메라 센서와의 거리가 기 설정된 거리이내인 제1 객체에 대해서만 상기 하나 이상의 제1 특징점을 추출하는 단계를 포함하며,상기 하나 이상의 제2 특징점을 추출하는 단계는,상기 식별된 복수의 제1 객체 중 상기 수집된 제1 라이다 포인트 클라우드 데이터를 수집한 라이다 센서와의 거리가 기 설정된 거리 이내인 제1 객체에 대해서만 상기 하나 이상의 제2 특징점을 추출하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 식별된 복수의 제1 객체에 대한 제1 객체 데이터베이스를 구축하는 단계는,공개특허 10-2023-0095162-3-상기 건물의 출입구 영역에 설치되는 제1 카메라 센서를 통해 수집되는 제1 이미지 데이터로부터 추출된 하나이상의 제1 특징점을 이용하여 상기 제1 객체 데이터베이스를 구축하고, 상기 건물 내부의 적어도 일부 영역에설치되는 복수의 제2 카메라 센서를 통해 수집되는 복수의 제2 이미지 데이터로부터 추출된 하나 이상의 제1 특징점을 이용하여 상기 구축된 제1 객체 데이터베이스를 업데이트하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 하나 이상의 제1 특징점을 추출하는 단계는,상기 수집된 이미지 데이터를 분석하여, 상기 식별된 복수의 제1 객체 각각에 대한 종류, 연령, 성별, 의복의속성 정보 - 상기 속성 정보는 상기 의복의 종류 및 색상을 포함함 - 및 상체와 하체의 비율 중 적어도 하나를상기 식별된 복수의 제1 객체 각각에 대한 제1 특징점으로 추출하는 단계를 포함하며,상기 하나 이상의 제2 특징점을 추출하는 단계는,상기 수집된 제1 라이다 포인트 클라우드 데이터를 분석하여 상기 식별된 복수의 제1 객체 각각에 대한 중심점좌표, 종류 및 3D 경계 박스(Boundary box)의 속성 정보 - 상기 속성 정보는 상기 3D 경계 박스의 가로, 세로및 높이 값을 포함함 - 중 적어도 하나를 제2 특징점으로 추출하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 식별된 객체의 동선을 추적하는 단계는,상기 복수의 제2 라이다 포인트 클라우드 데이터 중 하나 이상의 제2 라이다 포인트 클라우드 데이터를 분석하여 상기 하나 이상의 제2 라이다 포인트 클라우드 데이터에 포함된 제2 객체를 식별하고, 상기 식별된 제2 객체의 특징점을 추출하는 단계;기 구축된 제1 객체 데이터베이스에 포함된 복수의 제1 객체 각각에 대한 특징점과 상기 추출된 제2 객체의 특징점을 비교하여 상기 복수의 제1 객체 중 상기 식별된 제2 객체와 동일한 어느 하나의 제1 객체를 선택하는 단계; 및상기 식별된 제2 객체의 속도 및 이동 방향에 관한 정보를 상기 선택된 어느 하나의 제1 객체에 대응되는 식별코드와 매칭하여 상기 건물 내부의 지도 상에 기록하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 복수의 제1 객체 중 상기 식별된 제2 객체와 동일한 어느 하나의 제1 객체를 선택하는 단계는,상기 복수의 제1 객체 각각에 대한 특징점과 상기 추출된 제2 객체의 특징점 간의 일치율을 산출하고, 상기 산출된 일치율이 가장 높은 값을 가지는 어느 하나의 제1 객체를 상기 식별된 제2 객체와 동일한 객체로서 선택하되, 상기 선택된 어느 하나의 제1 객체에 대한 일치율이 기 설정된 값 미만인 경우, 상기 식별된 제2 객체에 대응되는 식별코드를 신규 부여하는 단계; 및상기 신규 부여된 식별코드와 상기 추출된 제2 객체의 특징점을 매칭하여 상기 기 구축된 제1 객체 데이터베이스 상에 기록하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,공개특허 10-2023-0095162-4-상기 식별된 제2 객체의 속도 및 이동 방향에 관한 정보를 상기 선택된 어느 하나의 제1 객체에 대응되는 식별코드와 매칭하여 기록하는 단계는,상기 추출된 제2 객체의 특징점을 이용하여 상기 기 구축된 제1 객체 데이터베이스에 기 저장된 상기 선택된 어느 하나의 제1 객체의 특징점을 업데이트하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 기 구축된 제1 객체 데이터베이스에 기 저장된 상기 선택된 어느 하나의 제1 객체의 특징점을 업데이트하는 단계는,상기 복수의 제2 라이다 포인트 클라우드 데이터로부터 상기 식별된 제2 객체에 대한 복수의 특징점이 추출되는경우, 상기 복수의 제2 라이다 포인트 클라우드 데이터를 각각 수집한 복수의 라이다 센서 중 상기 식별된 제2객체와의 거리가 기 설정된 값 이내인 라이다 센서로부터 수집된 제2 라이다 포인트 클라우드 데이터를 선택하고, 상기 선택된 제2 라이다 포인트 클라우드 데이터로부터 추출된 특징점만을 이용하여 상기 선택된 어느 하나의 제1 객체의 특징점을 업데이트하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 식별된 객체의 동선을 추적하는 단계는,상기 식별된 객체의 속성에 기초하여, 상기 식별된 객체에 대한 단위 시간당 최대 이동 거리를 산출하고, 상기산출된 단위 시간당 최대 이동 거리를 이용하여 상기 복수의 제2 라이다 포인트 클라우드 데이터 중 적어도 하나의 제2 라이다 포인트 클라우드 데이터를 선택하는 단계; 및상기 선택된 적어도 하나의 제2 라이다 포인트 클라우드 데이터만을 이용하여 상기 식별된 객체의 동선을 추적하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 식별된 객체의 동선을 추적하는 단계는,상기 복수의 제2 라이다 포인트 클라우드 데이터를 분석하여 제2 객체를 식별하는 단계; 상기 복수의 제2 라이다 포인트 클라우드 데이터 각각을 수집한 복수의 라이다 센서와 상기 식별된 제2 객체 간의 거리를 각각 산출하는 단계; 및상기 산출된 거리에 기초하여 상기 복수의 제2 라이다 포인트 클라우드 데이터 각각으로부터 추출하고자 하는특징점의 속성을 결정하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "프로세서;네트워크 인터페이스;메모리; 및상기 메모리에 로드(load)되고, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 포함하되,공개특허 10-2023-0095162-5-상기 컴퓨터 프로그램은,건물의 출입구 영역을 촬영한 이미지 데이터를 수집하는 인스트럭션(instruction);상기 건물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우드 데이터를 수집하는 인스트럭션;상기 수집된 이미지 데이터 및 상기 수집된 제1 라이다 포인트 클라우드 데이터를 분석하여 객체를 식별하는 인스트럭션; 및상기 건물 내부를 실시간으로 스캔함에 따라 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 분석하여상기 식별된 객체의 동선을 추적하는 인스트럭션을 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적서버."}
{"patent_id": "10-2021-0183970", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨팅 장치와 결합되어,건물의 출입구 영역을 촬영한 이미지 데이터를 수집하는 단계;상기 건물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우드 데이터를 수집하는 단계;상기 수집된 이미지 데이터 및 상기 수집된 제1 라이다 포인트 클라우드 데이터를 분석하여 객체를 식별하는 단계; 및상기 건물 내부를 실시간으로 스캔함에 따라 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 분석하여상기 식별된 객체의 동선을 추적하는 단계를 포함하는,이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법을 실행시키기 위하여 컴퓨터로 판독가능한 기록매체에 저장된,컴퓨터로 읽을 수 있는 기록매체에 기록된 컴퓨터프로그램."}
{"patent_id": "10-2021-0183970", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법, 서버 및 컴퓨터프로그램이 제공된다. 본 발명의 다양한 실시예에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법은 컴퓨팅 장 치에 의해 수행되는 방법에 있어서, 건물의 출입구 영역을 촬영한 이미지 데이터를 수집하는 단계, 상기 건물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우드 데이터를 수집하는 단계, 상기 수집된 이미지 데이터 및 상기 수집된 제1 라이다 포인트 클라우드 데이터를 분석하여 객체를 식별하는 단계 및 상기 건물 내부를 실시간으로 스캔함에 따라 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 분석하여 상기 식별된 객체의 동선을 추적 하는 단계를 포함한다."}
{"patent_id": "10-2021-0183970", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 다양한 실시예는 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법, 서버 및 컴 퓨터프로그램에 관한 것으로, 보다 구체적으로, 이미지 데이터와 라이다 센서 데이터로 실내에 위치하는 객체의 동선을 추적할 수 있는 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법, 서버 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2021-0183970", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "실내 위치확인시스템(IPS, Indoor Positioning System)은 건물 내부와 같은 실내에서 사용자의 위치 및 사용자 의 이동 동선을 파악하는 시스템이다. 사용자의 위치 및 사용자의 이동 동선에 관한 정보는 실내에서의 이동 경 로를 안내하는 기술뿐만 아니라 사용자의 니즈를 파악하여 최적의 서비스를 제공하는 기술 등 다양한 분야에서 활용 가능한 정보라는 점에서 활용성이 큰 바, 사용자의 실내 위치를 정확하게 파악하고, 이를 기반으로 사용자 의 동선을 정확하게 추적하는 기술에 대한 개발이 활발하게 진행되고 있다. 일반적으로, 개방된 공간의 경우 사용자 단말(예: 스마트폰)에 포함된 위치 센서(예: GPS 센서) 등을 이용하여 사용자의 위치 파악 및 동선 추적 동작을 비교적 정확하게 수행할 수 있으나, 폐쇄된 공간의 경우 개방된 공간 대비 위치 센서의 정확도가 현저하게 떨어지기 때문에 사용자의 위치를 정확하게 파악하고, 이를 통해 사용자의 이동 동선을 정확하게 추적하는데 한계가 있다. 이러한 점을 고려하여, 종래에는 위치 센서를 통한 위치 파악과 이를 통한 동선 추적이 어려운 실내 공간에 대 해서는 무선랜(Wi-Fi), 블루투스, 자기장, RFID 태그, 초음파 발생장치, 이동통신 기지국 등의 기술을 복합적으 로 이용하고 있다. 그러나, 이러한 종래의 방법은 스마트폰과 같은 개인 장치를 통한 통신을 바탕으로 하므로, 사용자가 개인 장치 에 어플리케이션을 직접 설치해야 하는 번거로움이 있고, 통신하는 동안 Wi-Fi나 블루투스를 자동으로 감지하기위해 장치의 배터리가 빠르게 소모된다는 문제가 있다. 특히, 대형 마트, 쇼핑몰 또는 백화점과 같이 규모가 큰 다중이용시설들의 경우, 실내 공간이 크고, 동선을 추 적해야 하는 사용자들이 많아 센서의 신호가 약해지기 때문에, 상대적으로 더 많은 장치들을 설치해야 하는 바, 장치들의 설치 및 유지에 상당한 인력 및 시간이 소요된다는 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1897018호 (2018.09.10.)"}
{"patent_id": "10-2021-0183970", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 상술된 종래의 문제점을 해소하기 위한 목적으로, 건물의 출입구 영역에 설 치되는 카메라 센서를 통해 수집되는 이미지 데이터와 라이다 센서를 통해 수집되는 라이다 센서 데이터를 이용 하여 건물 내부에 진입하는 객체를 특정하고, 객체를 특정한 이후 건물 내부에 설치된 라이다 센서를 통해 실시 간으로 수집되는 라이다 센서 데이터를 이용하여 특정된 객체의 위치 및 동선을 추적함으로써, 개인 장치를 통 하지 않고 객체의 위치 파악 및 동선 추적 동작을 수행할 수 있는 이미지 데이터 및 라이다 센서 데이터를 이용 한 객체의 동선 추적방법을 제공하는 것이다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0183970", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 일 실시예에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체 의 동선 추적방법은 컴퓨팅 장치에 의해 수행되는 방법에 있어서, 건물의 출입구 영역을 촬영한 이미지 데이터 를 수집하는 단계, 상기 건물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우드 데이터를 수집하는 단계, 상 기 수집된 이미지 데이터 및 상기 수집된 제1 라이다 포인트 클라우드 데이터를 분석하여 객체를 식별하는 단계 및 상기 건물 내부를 실시간으로 스캔함에 따라 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 분석하 여 상기 식별된 객체의 동선을 추적하는 단계를 포함할 수 있다. 다양한 실시예에서, 상기 객체를 식별하는 단계는, 기 학습된 인공지능 모델 - 상기 기 학습된 인공지능 모델은 복수의 객체에 대한 정보가 레이블링(Labeling)된 복수의 이미지 데이터 및 복수의 라이다 포인트 클라우드 데 이터를 학습데이터로 하여 기 학습된 모델임 - 을 이용하여 상기 수집된 이미지 데이터로부터 복수의 제1 객체 를 식별하고, 상기 식별된 복수의 제1 객체에 대한 하나 이상의 제1 특징점을 추출하는 단계, 상기 기 학습된 인공지능 모델을 이용하여 상기 수집된 제1 라이다 포인트 클라우드 데이터로부터 복수의 제1 객체를 식별하고, 상기 식별된 복수의 제1 객체에 대한 하나 이상의 제2 특징점을 추출하는 단계 및 상기 식별된 복수의 제1 객체 각각에 대한 식별코드를 부여하고, 상기 부여된 식별코드와 상기 추출된 하나 이상의 제1 특징점 및 상기 추출 된 하나 이상의 제2 특징점을 매칭하여 저장함으로써, 상기 식별된 복수의 제1 객체에 대한 제1 객체 데이터베 이스를 구축하는 단계를 포함할 수 있다. 다양한 실시예에서, 상기 하나 이상의 제1 특징점을 추출하는 단계는, 상기 식별된 복수의 제1 객체 중 상기 수 집된 이미지 데이터를 수집한 카메라 센서와의 거리가 기 설정된 거리 이내인 제1 객체에 대해서만 상기 하나 이상의 제1 특징점을 추출하는 단계를 포함하며, 상기 하나 이상의 제2 특징점을 추출하는 단계는, 상기 식별된 복수의 제1 객체 중 상기 수집된 제1 라이다 포인트 클라우드 데이터를 수집한 라이다 센서와의 거리가 기 설정 된 거리 이내인 제1 객체에 대해서만 상기 하나 이상의 제2 특징점을 추출하는 단계를 포함할 수 있다. 다양한 실시예에서, 상기 식별된 복수의 제1 객체에 대한 제1 객체 데이터베이스를 구축하는 단계는, 상기 건물 의 출입구 영역에 설치되는 제1 카메라 센서를 통해 수집되는 제1 이미지 데이터로부터 추출된 하나 이상의 제1 특징점을 이용하여 상기 제1 객체 데이터베이스를 구축하고, 상기 건물 내부의 적어도 일부 영역에 설치되는 복 수의 제2 카메라 센서를 통해 수집되는 복수의 제2 이미지 데이터로부터 추출된 하나 이상의 제1 특징점을 이용하여 상기 구축된 제1 객체 데이터베이스를 업데이트하는 단계를 포함할 수 있다. 다양한 실시예에서, 상기 하나 이상의 제1 특징점을 추출하는 단계는, 상기 수집된 이미지 데이터를 분석하여, 상기 식별된 복수의 제1 객체 각각에 대한 종류, 연령, 성별, 의복의 속성 정보 - 상기 속성 정보는 상기 의복 의 종류 및 색상을 포함함 - 및 상체와 하체의 비율 중 적어도 하나를 상기 식별된 복수의 제1 객체 각각에 대 한 제1 특징점으로 추출하는 단계를 포함하며, 상기 하나 이상의 제2 특징점을 추출하는 단계는, 상기 수집된 제1 라이다 포인트 클라우드 데이터를 분석하여 상기 식별된 복수의 제1 객체 각각에 대한 중심점 좌표, 종류 및 3D 경계 박스(Boundary box)의 속성 정보 - 상기 속성 정보는 상기 3D 경계 박스의 가로, 세로 및 높이 값을 포함함 - 중 적어도 하나를 제2 특징점으로 추출하는 단계를 포함할 수 있다. 다양한 실시예에서, 상기 식별된 객체의 동선을 추적하는 단계는, 상기 복수의 제2 라이다 포인트 클라우드 데 이터 중 하나 이상의 제2 라이다 포인트 클라우드 데이터를 분석하여 상기 하나 이상의 제2 라이다 포인트 클라 우드 데이터에 포함된 제2 객체를 식별하고, 상기 식별된 제2 객체의 특징점을 추출하는 단계, 기 구축된 제1 객체 데이터베이스에 포함된 복수의 제1 객체 각각에 대한 특징점과 상기 추출된 제2 객체의 특징점을 비교하여 상기 복수의 제1 객체 중 상기 식별된 제2 객체와 동일한 어느 하나의 제1 객체를 선택하는 단계 및 상기 식별 된 제2 객체의 속도 및 이동 방향에 관한 정보를 상기 선택된 어느 하나의 제1 객체에 대응되는 식별코드와 매 칭하여 상기 건물 내부의 지도 상에 기록하는 단계를 포함할 수 있다. 다양한 실시예에서, 상기 복수의 제1 객체 중 상기 식별된 제2 객체와 동일한 어느 하나의 제1 객체를 선택하는 단계는, 상기 복수의 제1 객체 각각에 대한 특징점과 상기 추출된 제2 객체의 특징점 간의 일치율을 산출하고, 상기 산출된 일치율이 가장 높은 값을 가지는 어느 하나의 제1 객체를 상기 식별된 제2 객체와 동일한 객체로서 선택하되, 상기 선택된 어느 하나의 제1 객체에 대한 일치율이 기 설정된 값 미만인 경우, 상기 식별된 제2 객 체에 대응되는 식별코드를 신규 부여하는 단계 및 상기 신규 부여된 식별코드와 상기 추출된 제2 객체의 특징점 을 매칭하여 상기 기 구축된 제1 객체 데이터베이스 상에 기록하는 단계를 포함할 수 있다. 다양한 실시예에서, 상기 식별된 제2 객체의 속도 및 이동 방향에 관한 정보를 상기 선택된 어느 하나의 제1 객 체에 대응되는 식별코드와 매칭하여 기록하는 단계는, 상기 추출된 제2 객체의 특징점을 이용하여 상기 기 구축 된 제1 객체 데이터베이스에 기 저장된 상기 선택된 어느 하나의 제1 객체의 특징점을 업데이트하는 단계를 포 함할 수 있다. 다양한 실시예에서, 상기 기 구축된 제1 객체 데이터베이스에 기 저장된 상기 선택된 어느 하나의 제1 객체의 특징점을 업데이트하는 단계는, 상기 복수의 제2 라이다 포인트 클라우드 데이터로부터 상기 식별된 제2 객체에 대한 복수의 특징점이 추출되는 경우, 상기 복수의 제2 라이다 포인트 클라우드 데이터를 각각 수집한 복수의 라이다 센서 중 상기 식별된 제2 객체와의 거리가 기 설정된 값 이내인 라이다 센서로부터 수집된 제2 라이다 포인트 클라우드 데이터를 선택하고, 상기 선택된 제2 라이다 포인트 클라우드 데이터로부터 추출된 특징점만을 이용하여 상기 선택된 어느 하나의 제1 객체의 특징점을 업데이트하는 단계를 포함할 수 있다. 다양한 실시예에서, 상기 식별된 객체의 동선을 추적하는 단계는, 상기 식별된 객체의 속성에 기초하여, 상기 식별된 객체에 대한 단위 시간당 최대 이동 거리를 산출하고, 상기 산출된 단위 시간당 최대 이동 거리를 이용 하여 상기 복수의 제2 라이다 포인트 클라우드 데이터 중 적어도 하나의 제2 라이다 포인트 클라우드 데이터를 선택하는 단계 및 상기 선택된 적어도 하나의 제2 라이다 포인트 클라우드 데이터만을 이용하여 상기 식별된 객 체의 동선을 추적하는 단계를 포함할 수 있다. 다양한 실시예에서, 상기 식별된 객체의 동선을 추적하는 단계는, 상기 복수의 제2 라이다 포인트 클라우드 데 이터를 분석하여 제2 객체를 식별하는 단계, 상기 복수의 제2 라이다 포인트 클라우드 데이터 각각을 수집한 복 수의 라이다 센서와 상기 식별된 제2 객체 간의 거리를 각각 산출하는 단계 및 상기 산출된 거리에 기초하여 상 기 복수의 제2 라이다 포인트 클라우드 데이터 각각으로부터 추출하고자 하는 특징점의 속성을 결정하는 단계를 포함할 수 있다. 상술한 과제를 해결하기 위한 본 발명의 다른 실시예에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객 체의 동선 추적서버는 프로세서, 네트워크 인터페이스, 메모리 및 상기 메모리에 로드(load)되고, 상기 프로세 서에 의해 실행되는 컴퓨터 프로그램을 포함하되, 상기 컴퓨터 프로그램은, 건물의 출입구 영역을 촬영한 이미 지 데이터를 수집하는 인스트럭션(instruction), 상기 건물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우 드 데이터를 수집하는 인스트럭션, 상기 수집된 이미지 데이터 및 상기 수집된 제1 라이다 포인트 클라우드 데 이터를 분석하여 객체를 식별하는 인스트럭션 및 상기 건물 내부를 실시간으로 스캔함에 따라 수집되는 복수의제2 라이다 포인트 클라우드 데이터를 분석하여 상기 식별된 객체의 동선을 추적하는 인스트럭션을 포함할 수 있다. 상술한 과제를 해결하기 위한 본 발명의 또 다른 실시예에 따른 컴퓨터로 읽을 수 있는 기록매체에 기록된 컴퓨 터프로그램은 컴퓨팅 장치와 결합되어, 건물의 출입구 영역을 촬영한 이미지 데이터를 수집하는 단계, 상기 건 물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우드 데이터를 수집하는 단계, 상기 수집된 이미지 데이터 및 상기 수집된 제1 라이다 포인트 클라우드 데이터를 분석하여 객체를 식별하는 단계 및 상기 건물 내부를 실 시간으로 스캔함에 따라 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 분석하여 상기 식별된 객체의 동선을 추적하는 단계를 포함하는 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법을 실행 시키기 위하여 컴퓨터로 판독가능한 기록매체에 저장될 수 있다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2021-0183970", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 다양한 실시예에 따르면, 건물의 출입구 영역에 설치되는 카메라 센서를 통해 수집되는 이미지 데이 터와 라이다 센서를 통해 수집되는 라이다 센서 데이터를 이용하여 건물 내부에 진입하는 객체를 특정하고, 객 체를 특정한 이후 건물 내부에 설치된 라이다 센서를 통해 실시간으로 수집되는 라이다 센서 데이터를 이용하여 특정된 객체의 위치 및 동선을 추적함으로써, 비교적 적은 비용으로 객체의 위치 파악 및 동선 추적 동작을 수 행할 수 있다는 이점이 있다."}
{"patent_id": "10-2021-0183970", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0183970", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 명세서에서 사용되는 \"부\" 또는 “모듈”이라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소 를 의미하며, \"부\" 또는 “모듈”은 어떤 역할들을 수행한다. 그렇지만 \"부\" 또는 “모듈”은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. \"부\" 또는 “모듈”은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수 도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\" 또는 “모 듈”은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라 이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 \"부\" 또는 “모듈”들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 \"부\" 또는 “모듈”들로 결합되거나 추가적인 구성요소들과 \"부\" 또는 “모듈”들로 더 분리될 수 있다. 공간적으로 상대적인 용어인 \"아래(below)\", \"아래(beneath)\", \"하부(lower)\", \"위(above)\", \"상부(upper)\" 등 은 도면에 도시되어 있는 바와 같이 하나의 구성요소와 다른 구성요소들과의 상관관계를 용이하게 기술하기 위 해 사용될 수 있다. 공간적으로 상대적인 용어는 도면에 도시되어 있는 방향에 더하여 사용시 또는 동작시 구성 요소들의 서로 다른 방향을 포함하는 용어로 이해되어야 한다. 예를 들어, 도면에 도시되어 있는 구성요소를 뒤 집을 경우, 다른 구성요소의 \"아래(below)\"또는 \"아래(beneath)\"로 기술된 구성요소는 다른 구성요소의 \"위 (above)\"에 놓여질 수 있다. 따라서, 예시적인 용어인 \"아래\"는 아래와 위의 방향을 모두 포함할 수 있다. 구성 요소는 다른 방향으로도 배향될 수 있으며, 이에 따라 공간적으로 상대적인 용어들은 배향에 따라 해석될 수 있 다. 본 명세서에서, 컴퓨터는 적어도 하나의 프로세서를 포함하는 모든 종류의 하드웨어 장치를 의미하는 것이고, 실시 예에 따라 해당 하드웨어 장치에서 동작하는 소프트웨어적 구성도 포괄하는 의미로서 이해될 수 있다. 예 를 들어, 컴퓨터는 스마트폰, 태블릿 PC, 데스크톱, 노트북 및 각 장치에서 구동되는 사용자 클라이언트 및 애 플리케이션을 모두 포함하는 의미로서 이해될 수 있으며, 또한 이에 제한되는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 본 명세서에서 설명되는 각 단계들은 컴퓨터에 의하여 수행되는 것으로 설명되나, 각 단계의 주체는 이에 제한 되는 것은 아니며, 실시 예에 따라 각 단계들의 적어도 일부가 서로 다른 장치에서 수행될 수도 있다. 도 1은 본 발명의 일 실시예에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적시스템을 도시한 도면이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추 적시스템은 객체의 동선 추적서버, 사용자 단말, 외부 서버 및 네트워크를 포함할 수 있다. 여기서, 도 1에 도시된 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적시스템은 일 실시예에 따른 것이고, 그 구성 요소가 도 1에 도시된 실시예에 한정되는 것은 아니며, 필요에 따라 부가, 변경 또는 삭 제될 수 있다. 일 실시예에서, 객체의 동선 추적서버는 건물, 주차장 등과 같은 실내에 진입한 객체(예: 사람, 자동차, 오토바이, 자전거 등)의 동선을 추적할 수 있다. 다양한 실시예에서, 객체의 동선 추적서버는 건물의 출입구 영역에 구비되는 카메라 센서를 통해 수집된 이미지 데이터 및 제1 라이다 센서를 통해 수집되는 제1 라이다 포인트 클라우드 데이터를 이용하여 건물에 진 입하는 객체를 특정할 수 있고, 이후, 건물 내부에 설치된 제2 라이다 센서들로부터 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 이용하여 특정된 객체에 대한 동선을 추적할 수 있다. 다양한 실시예에서, 객체의 동선 추적서버는 건물의 출입구 영역에 구비되는 제1 라이다 센서를 통해 수집 되는 제1 라이다 포인트 클라우드 데이터만을 이용하여 건물에 진입하는 객체를 특정할 수 있고, 이후, 건물 내 부에 설치된 제2 라이다 센서들로부터 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 이용하여 특정된 객체에 대한 동선을 추적할 수 있다. 다양한 실시예에서, 객체의 동선 추적서버는 네트워크를 통해 사용자 단말과 연결될 수 있으며, 사용자 단말로 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법에 따라 복수의 객체 에 대한 동선 추적 결과를 제공할 수 있다. 여기서, 사용자 단말은 건물을 관리하는 관리자의 단말을 의미할 수 있다. 예를 들어, 사용자 단말은 휴대성과 이동성이 보장되는 무선 통신 장치로서, 건물을 관리하는 관리자의 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있으나, 이에 한 정되지 않는다. 또한, 여기서, 네트워크는 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미할 수 있다. 예를 들어, 네트워크는 근거리 통신망(LAN: Local Area Network), 광역 통신망 (WAN: Wide Area Network), 인터넷(WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통 신망 등을 포함할 수 있다. 또한, 여기서, 무선 데이터 통신망은 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), 5GPP(5th Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency), 블루투스(Bluetooth) 네트워크, NFC(Near-Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등을 포함할 수 있으나, 이에 한정되지는 않는다. 일 실시예에서, 외부 서버는 네트워크를 통해 객체의 동선 추적서버와 연결될 수 있으며, 객체 의 동선 추적서버가 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법을 수행함에 따 라 생성되는 각종 정보 및 데이터(예: 식별된 객체들에 대한 식별코드, 특징점, 동선 정보 등)를 저장 및 관리 할 수 있다. 예를 들어, 외부 서버는 객체의 동선 추적서버의 외부에 별도로 구비되는 저장 서버일 수 있으나, 이에 한정되지 않는다. 이하, 도 2를 참조하여 이미지 데이터 및 라이다 센서 데이터를 이용한 객체 의 동선 추적방법을 수행하는 객체의 동선 추적서버의 하드웨어 구성에 대해 설명하도록 한다. 도 2는 본 발명의 다른 실시예에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적서버의 하드웨어 구성도이다. 도 2를 참조하면, 다양한 실시예에서, 객체의 동선 추적서버(이하, \"서버\")는 하나 이상의 프로세서 , 프로세서에 의하여 수행되는 컴퓨터 프로그램을 로드(Load)하는 메모리, 버스, 통 신 인터페이스 및 컴퓨터 프로그램을 저장하는 스토리지를 포함할 수 있다. 여기서, 도 2에는"}
{"patent_id": "10-2021-0183970", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명의 실시예와 관련 있는 구성요소들만 도시되어 있다. 따라서, 본 발명이 속한 기술분야의 통상의 기술자 라면 도 2에 도시된 구성요소들 외에 다른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 프로세서는 서버의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발 명의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성될 수 있다. 또한, 프로세서는 본 발명의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프 로그램에 대한 연산을 수행할 수 있으며, 서버는 하나 이상의 프로세서를 구비할 수 있다. 다양한 실시예에서, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저장하는 램(RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포 함할 수 있다. 또한, 프로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템온칩(SoC: system on chip) 형태로 구현될 수 있다. 다양한 실시예에서, 프로세서는 신경망의 학습을 위한 연산을 수행할 수 있다. 프로세서는 딥러닝 (Deep learning)에서 학습을 위한 입력 데이터의 처리, 입력 데이터에서의 피처 추출, 오차 계산, 역전파 (backpropagation)를 이용한 신경망의 가중치 업데이트 등의 신경망의 학습을 위한 계산을 수행할 수 있다. 또한, 프로세서의 CPU, GPGPU, 및 TPU 중 적어도 하나가 네트워크 함수의 학습을 처리할 수 있다. 예를 들 어, CPU 와 GPGPU가 함께 네트워크 함수의 학습, 네트워크 함수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 발명의 일 실시예에서 복수의 컴퓨팅 장치의 프로세서를 함께 사용하여 네트워크 함수의 학습, 네트워크 함 수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 발명의 일 실시예에 따른 컴퓨팅 장치에서 수행되는 컴퓨 터 프로그램은 CPU, GPGPU 또는 TPU 실행가능 프로그램일 수 있다. 여기서 네트워크 함수는 인공 신경망, 뉴럴 네트워크와 상호 교환 가능하게 사용될 수 있다. 본 명세서에서 네 트워크 함수는 하나 이상의 뉴럴 네트워크를 포함할 수도 있으며, 이 경우 네트워크 함수의 출력은 하나 이상의 뉴럴 네트워크의 출력의 앙상블(ensemble)일 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 발명의 다양한 실시예에 따른 방 법/동작을 실행하기 위하여 스토리지로부터 컴퓨터 프로그램을 로드할 수 있다. 메모리에 컴퓨 터 프로그램이 로드되면, 프로세서는 컴퓨터 프로그램을 구성하는 하나 이상의 인스트럭션들을 실행함으로써 상기 방법/동작을 수행할 수 있다. 메모리는 RAM과 같은 휘발성 메모리로 구현될 수 있을 것 이나, 본 발명의 기술적 범위가 이에 한정되는 것은 아니다. 버스는 서버의 구성 요소 간 통신 기능을 제공한다. 버스는 주소 버스(address Bus), 데이터 버 스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 서버의 유무선 인터넷 통신을 지원한다. 또한, 통신 인터페이스는 인터넷 통 신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 발명의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 몇몇 실시예에서, 통신 인터페이스는 생략될 수도 있다. 스토리지는 컴퓨터 프로그램을 비 임시적으로 저장할 수 있다. 서버를 통해 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적프로세스 또는 라이다 포인트 클라우드 데이터 기반 객체의 동선 추적프로세스를 수행하는 경우, 스토리지는 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적프로세스 또는 라이다 포인트 클라우드 데이터 기반 객체의 동선 추적프로세스를 제공하기 위하여 필요한 각종 정보를 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드될 때 프로세서로 하여금 본 발명의 다양한 실시예에 따른 방 법/동작을 수행하도록 하는 하나 이상의 인스트럭션들을 포함할 수 있다. 즉, 프로세서는 상기 하나 이상 의 인스트럭션들을 실행함으로써, 본 발명의 다양한 실시예에 따른 상기 방법/동작을 수행할 수 있다. 일 실시예에서, 컴퓨터 프로그램은 건물의 출입구 영역을 촬영한 이미지 데이터를 수집하는 단계, 건물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우드 데이터를 수집하는 단계, 수집된 이미지 데이터 및 수집된 제1 라이다 포인트 클라우드 데이터를 분석하여 객체를 식별하는 단계 및 건물 내부를 실시간으로 스캔함에 따 라 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 분석하여 식별된 객체의 동선을 추적하는 단계를 포 함하는 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법을 수행하도록 하는 하나 이상의 인스트럭션을 포함할 수 있다. 또한, 일 실시예에서, 컴퓨터 프로그램은 건물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우드 데이 터를 수집하는 단계, 수집된 제1 라이다 포인트 클라우드 데이터를 분석하여 객체를 식별하는 단계 및 건물 내 부를 실시간으로 스캔함에 따라 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 분석하여 식별된 객체의 동선을 추적하는 단계를 포함하는 라이다 포인트 클라우드 데이터 기반 객체의 동선 추적방법을 수행하도록 하 는 하나 이상의 인스트럭션을 포함할 수 있다.본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 이하, 도 3 내지 5를 참조하여 서버에 의해 수행되는 이미지 데이터 및 라이다 센서 데이 터를 이용한 객체의 동선 추적방법에 대해 설명하도록 한다. 도 3은 본 발명의 또 다른 실시예에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법 의 순서도이다. 여기서, 도 3에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법을 수행하기 위하여, 건물 내에 복수의 카메라 센서 및 복수의 라이다 센서가 설치될 수 있다. 보다 구체적으로, 먼저, 건물 내에 진입하는 객체를 특정하기 위하여, 건물의 출입구와 인접한 위치에 객체를 촬영 또는 스캔하기 위한 카메라 센서(예: 제1 카메라 센서)와 라이다 센서(예: 제1 라이다 센서)가 설치될 수 있다. 또한, 건물 내 공간을 이동하는 객체의 동선을 추적하기 위하여, 건물 내의 복수의 라이다 센서(예: 제2 라이다 센서)가 설치될 수 있다. 이때, 복수의 제2 라이다 센서는 커버리지가 겹쳐지도록 설치 즉, 제2 라이다 센서를 통해 수집되는 복수의 제2 라이다 포인트 클라우드 데이터 각각의 적어도 일부분이 중첩되도록 설치될 수 있으 나, 이에 한정되지 않는다. 또한, 특정된 객체에 대한 특징점들을 검증 및 업데이트하기 위하여, 다수의 객체들이 방문하는 주요 지점들(예: 건물이 대형 마트인 경우, 카트 보관소, 계산대, 이벤트 발생 장소 등) 곳곳에 카메라 센서(예: 제2 카메라 센서)가 설치될 수 있다. 도 3을 참조하면, S110 단계에서, 서버는 이미지 데이터 및 제1 라이다 포인트 클라우드 데이터를 수집할 수 있다. 예를 들어, 서버는 제1 카메라 센서를 통해 건물의 출입구 영역을 촬영한 제1 이미지 데이터를 수집할 수 있고, 제1 라이다 센서를 통해 건물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우드 데이터를 수집할 수 있다. 여기서, 제1 이미지 데이터 및 제1 라이다 포인트 클라우드 데이터는 동일한 객체를 특정하기 위하여, 동일한 시점(또는 소정의 시간이내)에 촬영 또는 스캔된 데이터일 수 있으나, 이에 한정되지 않는다. 또한, 여기서, 제1 이미지 데이터 및 제1 라이다 포인트 클라우드 데이터는 건물 내부에 진입하는 객체를 특정 하기 위해 사용되는 기초자료인 바, 보다 정확하게 객체를 식별하고, 식별된 객체에 대한 특징점을 추출하기 위 하여, 제1 카메라 센서 및 제1 라이다 센서는 건물의 출입구 영역과 근접한 위치(예: 건물의 출입구로부터 5M 이내)에 설치될 수 있으나, 이에 한정되지 않는다. 다양한 실시예에서, 서버는 제1 카메라 센서를 통해 건물의 출입구 영역을 촬영한 동영상 데이터를 수집할 수 있고, 수집된 동영상 데이터를 분석하여 동영상 데이터에 포함된 객체가 제1 카메라 센서와 기 설정된 거리 이내에 위치할 때마다 또는 동영상 데이터에 포함된 객체의 크기가 기 설정된 크기 이상이 될 때마다 화면을 캡 처(Capture)함으로써, 이미지 데이터를 생성할 수 있다. 그러나, 이에 한정되지 않는다. S120 단계에서, 서버는 S110 단계를 거쳐 수집된 제1 이미지 데이터 및 제1 라이다 포인트 클라우드 데이 터를 이용하여 객체를 식별할 수 있다. 다양한 실시예에서, 서버는 제1 이미지 데이터 및 제1 라이다 포인트 클라우드 데이터를 분석하여 제1 이 미지 데이터 및 제1 라이다 포인트 클라우드 데이터에 포함된 제1 객체를 특정할 수 있다. 예를 들어, 서버 는 기 학습된 인공지능 모델을 이용하여 제1 이미지 데이터 및 제1 라이다 포인트 클라우드 데이터를 분석 함으로써, 제1 객체를 식별할 수 있고, 식별된 객체에 대한 특징점을 추출할 수 있으며, 추출된 특징점에 기초 하여 식별된 객체를 특정할 수 있다. 이하, 도 4를 참조하여 구체적으로 설명하도록 한다. 도 4는 다양한 실시예에서, 제1 인공지능 모델을 이용하여 객체 데이터베이스를 구축하는 방법을 설명하기 위한 순서도이다. 도 4를 참조하면, S210 단계에서, 서버는 객체 식별 및 특징점 추출 동작을 수행하기 위하여, 제1 인공지 능 모델을 생성할 수 있다. 여기서, 제1 인공지능 모델(예: 신경망)은 하나 이상의 네트워크 함수로 구성되며, 하나 이상의 네트워크 함수 는 일반적으로 ‘노드’라 지칭될 수 있는 상호 연결된 계산 단위들의 집합으로 구성될 수 있다. 이러한 ‘노드 ’들은 ‘뉴런(neuron)’들로 지칭될 수도 있다. 하나 이상의 네트워크 함수는 적어도 하나 이상의 노드들을 포 함하여 구성된다. 하나 이상의 네트워크 함수를 구성하는 노드(또는 뉴런)들은 하나 이상의 ‘링크’에 의해 상 호 연결될 수 있다. 제1 인공지능 모델 내에서, 링크를 통해 연결된 하나 이상의 노드들은 상대적으로 입력 노드 및 출력 노드의 관 계를 형성할 수 있다. 입력 노드 및 출력 노드의 개념은 상대적인 것으로서, 하나의 노드에 대하여 출력 노드 관계에 있는 임의의 노드는 다른 노드와의 관계에서 입력 노드 관계에 있을 수 있으며, 그 역도 성립할 수 있다. 전술한 바와 같이, 입력 노드 대 출력 노드 관계는 링크를 중심으로 생성될 수 있다. 하나의 입력 노드에 하나 이상의 출력 노드가 링크를 통해 연결될 수 있으며, 그 역도 성립할 수 있다. 하나의 링크를 통해 연결된 입력 노드 및 출력 노드 관계에서, 출력 노드는 입력 노드에 입력된 데이터에 기초 하여 그 값이 결정될 수 있다. 여기서 입력 노드와 출력 노드를 상호 연결하는 노드는 가중치(weight)를 가질 수 있다. 가중치는 가변적일 수 있으며, 제1 인공지능 모델이 원하는 기능을 수행하기 위해, 사용자 또는 알고 리즘에 의해 가변될 수 있다. 예를 들어, 하나의 출력 노드에 하나 이상의 입력 노드가 각각의 링크에 의해 상 호 연결된 경우, 출력 노드는 상기 출력 노드와 연결된 입력 노드들에 입력된 값들 및 각각의 입력 노드들에 대 응하는 링크에 설정된 가중치에 기초하여 출력 노드 값을 결정할 수 있다. 전술한 바와 같이, 제1 인공지능 모델은 하나 이상의 노드들이 하나 이상의 링크를 통해 상호연결 되어 제1 인 공지능 모델 내에서 입력 노드 및 출력 노드 관계를 형성한다. 제1 인공지능 모델 내에서 노드들과 링크들의 개 수 및 노드들과 링크들 사이의 연관관계, 링크들 각각에 부여된 가중치의 값에 따라, 제1 인공지능 모델의 특성 이 결정될 수 있다. 예를 들어, 동일한 개수의 노드 및 링크들이 존재하고, 링크들 사이의 가중치 값이 상이한 두 제1 인공지능 모델이 존재하는 경우, 두 개의 제1 인공지능 모델들은 서로 상이한 것으로 인식될 수 있다. 제1 인공지능 모델을 구성하는 노드들 중 일부는, 최초 입력 노드로부터의 거리들에 기초하여, 하나의 레이어 (layer)를 구성할 수 있다. 예를 들어, 최초 입력 노드로부터 거리가 n인 노드들의 집합은, n 레이어를 구성할 수 있다. 최초 입력 노드로부터 거리는, 최초 입력 노드로부터 해당 노드까지 도달하기 위해 거쳐야 하는 링크 들의 최소 개수에 의해 정의될 수 있다. 그러나, 이러한 레이어의 정의는 설명을 위한 임의적인 것으로서, 제1 인공지능 모델 내에서 레이어의 차수는 전술한 것과 상이한 방법으로 정의될 수 있다. 예를 들어, 노드들의 레 이어는 최종 출력 노드로부터 거리에 의해 정의될 수도 있다. 최초 입력 노드는 제1 인공지능 모델 내의 노드들 중 다른 노드들과의 관계에서 링크를 거치지 않고 데이터가 직접 입력되는 하나 이상의 노드들을 의미할 수 있다. 또는, 제1 인공지능 모델 네트워크 내에서, 링크를 기준 으로 한 노드 간의 관계에 있어서, 링크로 연결된 다른 입력 노드들 가지지 않는 노드들을 의미할 수 있다. 이 와 유사하게, 최종 출력 노드는 제1 인공지능 모델 내의 노드들 중 다른 노드들과의 관계에서, 출력 노드를 가 지지 않는 하나 이상의 노드들을 의미할 수 있다. 또한, 히든 노드는 최초 입력 노드 및 최후 출력 노드가 아닌 제1 인공지능 모델을 구성하는 노드들을 의미할 수 있다. 본 발명의 일 실시예에 따른 제1 인공지능 모델은 입 력 레이어의 노드가 출력 레이어에 가까운 히든 레이어의 노드보다 많을 수 있으며, 입력 레이어에서 히든 레이 어로 진행됨에 따라 노드의 수가 감소하는 형태의 제1 인공지능 모델일 수 있다. 제1 인공지능 모델은 하나 이상의 히든 레이어를 포함할 수 있다. 히든 레이어의 히든 노드는 이전의 레이어의 출력과 주변 히든 노드의 출력을 입력으로 할 수 있다. 각 히든 레이어 별 히든 노드의 수는 동일할 수도 있고 상이할 수도 있다. 입력 레이어의 노드의 수는 입력 데이터의 데이터 필드의 수에 기초하여 결정될 수 있으며히든 노드의 수와 동일할 수도 있고 상이할 수도 있다. 입력 레이어에 입력된 입력 데이터는 히든 레이어의 히 든 노드에 의하여 연산될 수 있고 출력 레이어인 완전 연결 레이어(FCL: fully connected layer)에 의해 출력될 수 있다. 다양한 실시예에서, 제1 인공지능 모델은 딥러닝(Deep learning) 모델일 수 있다. 딥러닝 모델(예: 딥 뉴럴 네트워크(DNN: deep neural network, 심층신경망)는 입력 레이어와 출력 레이어 외에 복수의 히든 레이어를 포함하는 제1 인공지능 모델을 의미할 수 있다. 딥 뉴럴 네트워크를 이용하면 데이터의 잠재적인 구조(latent structures)를 파악할 수 있다. 즉, 사진, 글, 비디오, 음성, 음악의 잠재적인 구조(예를 들어, 어떤 물체가 사진에 있는지, 글의 내용과 감정이 무엇인지, 음성의 내용과 감정이 무엇인지 등)를 파악할 수 있다. 딥 뉴럴 네트워크는 컨벌루셔널 뉴럴 네트워크(CNN: convolutional neural network), 리커런트 뉴럴 네트워크 (RNN: recurrent neural network), 오토 인코더(auto encoder), GAN(Generative Adversarial Networks), 제한 볼츠만 머신(RBM: restricted boltzmann machine), 심층 신뢰 네트워크(DBN: deep belief network), Q 네트워 크, U 네트워크, 샴 네트워크 등을 포함할 수 있으나, 이에 한정되지 않는다. 다양한 실시예에서, 네트워크 함수는 오토 인코더를 포함할 수도 있다. 여기서, 오토 인코더는 입력 데이터와 유사한 출력 데이터를 출력하기 위한 인공 신경망의 일종일 수 있다. 오토 인코더는 적어도 하나의 히든 레이어를 포함할 수 있으며, 홀수 개의 히든 레이어가 입출력 레이어 사이에 배치될 수 있다. 각각의 레이어의 노드의 수는 입력 레이어의 노드의 수에서 병목 레이어(인코딩)라는 중간 레 이어로 축소되었다가, 병목 레이어에서 출력 레이어(입력 레이어와 대칭)로 축소와 대칭되어 확장될 수도 있다. 차원 감소 레이어와 차원 복원 레이어의 노드는 대칭일 수도 있고 아닐 수도 있다. 또한, 오토 인코더는 비선형 차원 감소를 수행할 수 있다. 입력 레이어 및 출력 레이어의 수는 입력 데이터의 전처리 이후에 남은 센서들의 수와 대응될 수 있다. 오토 인코더 구조에서 인코더에 포함된 히든 레이어의 노드의 수는 입력 레이어에서 멀어 질수록 감소하는 구조를 가질 수 있다. 병목 레이어(인코더와 디코더 사이에 위치하는 가장 적은 노드를 가진 레이어)의 노드의 수는 너무 작은 경우 충분한 양의 정보가 전달되지 않을 수 있으므로, 특정 수 이상(예를 들 어, 입력 레이어의 절반 이상 등)으로 유지될 수도 있다. 뉴럴 네트워크는 교사 학습(supervised learning), 비교사 학습(unsupervised learning), 및 반교사학습(semi supervised learning) 중 적어도 하나의 방식으로 학습될 수 있다. 뉴럴 네트워크의 학습은 출력의 오류를 최소 화하기 위한 것이다. 보다 구체적으로, 뉴럴 네트워크의 학습은 반복적으로 학습 데이터를 뉴럴 네트워크에 입 력시키고 학습 데이터에 대한 뉴럴 네트워크의 출력과 타겟의 에러를 계산하고, 에러를 줄이기 위한 방향으로 뉴럴 네트워크의 에러를 뉴럴 네트워크의 출력 레이어에서부터 입력 레이어 방향으로 역전파(backpropagation) 하여 뉴럴 네트워크의 각 노드의 가중치를 업데이트 하는 과정이다. 먼저, 교사 학습의 경우 각각의 학습 데이터에 정답이 레이블링 되어있는 학습 데이터를 사용하며(즉, 레이블링 된 학습 데이터), 비교사 학습의 경우는 각각의 학습 데이터에 정답이 레이블링 되어 있지 않을 수 있다. 즉, 예를 들어 데이터 분류에 관한 교사 학습의 경우의 학습 데이터는 학습 데이터 각각에 카테고리가 레이블링 된 데이터 일 수 있다. 레이블링된 학습 데이터가 뉴럴 네트워크에 입력되고, 뉴럴 네트워크의 출력(카테고리)과 학습 데이터의 레이블을 비교함으로써 오류(error)가 계산될 수 있다. 다음으로, 데이터 분류에 관한 비교사 학습의 경우 입력인 학습 데이터가 뉴럴 네트워크 출력과 비교됨으로써 오류가 계산될 수 있다. 계산된 오류는 뉴럴 네트워크에서 역방향(즉, 출력 레이어에서 입력 레이어 방향)으로 역전파 되며, 역전파에 따라 뉴럴 네트워크의 각 레이어의 각 노드들의 연결 가중치가 업데이트 될 수 있다. 업 데이트 되는 각 노드의 연결 가중치는 학습률(learning rate)에 따라 변화량이 결정될 수 있다. 입력 데이터에 대한 뉴럴 네트워크의 계산과 에러의 역전파는 학습 사이클(epoch)을 구성할 수 있다. 학습률은 뉴럴 네트워크 의 학습 사이클의 반복 횟수에 따라 상이하게 적용될 수 있다. 예를 들어, 뉴럴 네트워크의 학습 초기에는 높은 학습률을 사용하여 뉴럴 네트워크가 빠르게 일정 수준의 성능을 확보하도록 하여 효율성을 높이고, 학습 후기에 는 낮은 학습률을 사용하여 정확도를 높일 수 있다. 뉴럴 네트워크의 학습에서 일반적으로 학습 데이터는 실제 데이터(즉, 학습된 뉴럴 네트워크를 이용하여 처리하 고자 하는 데이터)의 부분집합일 수 있으며, 따라서, 학습 데이터에 대한 오류는 감소하나 실제 데이터에 대해 서는 오류가 증가하는 학습 사이클이 존재할 수 있다. 과적합(overfitting)은 이와 같이 학습 데이터에 과하게 학습하여 실제 데이터에 대한 오류가 증가하는 현상이다. 예를 들어, 노란색 고양이를 보여 고양이를 학습한 뉴럴 네트워크가 노란색 이외의 고양이를 보고는 고양이임을 인식하지 못하는 현상이 과적합의 일종일 수 있다. 과적합은 머신러닝 알고리즘의 오류를 증가시키는 원인으로 작용할 수 있다. 이러한 과적합을 막기 위하여 다양 한 최적화 방법이 사용될 수 있다. 과적합을 막기 위해서는 학습 데이터를 증가시키거나, 레귤라이제이션 (regularization), 학습의 과정에서 네트워크의 노드 일부를 생략하는 드롭아웃(dropout) 등의 방법이 적용될 수 있다. 다양한 실시예에서, 서버는 복수의 이미지 데이터 및 복수의 라이다 포인트 클라우드 데이터를 이용하여 학습 데이터를 생성할 수 있고, 생성된 학습 데이터를 이용하여 제1 인공지능 모델을 학습시킬 수 있다. 예를 들어, 서버는 카메라 센서를 통해 이미지 데이터를 프레임 단위로 수집하고, 라이다 센서를 통해 라이다 포인트 클라우드 데이터를 프레임 단위로 수집하며, 프레임 각각에 정답(예: 인식할 객체에 대한 정보)를 레이 블링(Labeling) 함으로써, 학습 데이터 셋을 구축할 수 있다. 이후, 서버는 구축된 학습 데이터 셋을 이용 하여 제1 인공지능 모델을 학습시킬 수 있다. 보다 구체적으로, 서버는 학습 입력 데이터 세트 각각을 하나 이상의 네트워크 함수에 입력시키고, 하나 이상의 네트워크 함수로 연산된 출력 데이터 각각과 학습 입력 데이터 세트 각각의 레이블에 해당하는 학습 출 력 데이터 세트 각각을 비교하여 오차를 도출할 수 있다. 즉, 제1 인공지능 모델의 학습에서 학습 입력 데이터 는 하나 이상의 네트워크 함수의 입력 레이어에 입력될 수 있으며, 학습 출력 데이터는 하나 이상의 네트워크 함수의 출력과 비교될 수 있다. 서버는 학습 입력 데이터에 대한 하나 이상의 네트워크 함수의 연산 결과 와 학습 출력 데이터(레이블)의 오차에 기초하여 신경망을 학습시킬 수 있다. 또한, 서버는 오차에 기초하여 하나 이상의 네트워크 함수의 가중치를 역전파 방식으로 조정할 수 있다. 즉, 서버는 학습 입력 데이터에 대한 하나 이상의 네트워크 함수의 연산 결과와 학습 출력 데이터의 오차 에 기초하여 하나 이상의 네트워크 함수의 출력이 학습 출력 데이터에 가까워지도록 가중치를 조정할 수 있다. 서버는 하나 이상의 네트워크 함수의 학습이 사전 결정된 에폭 이상 수행된 경우, 검증 데이터를 이용하여 학습의 중단 여부를 결정할 수 있다. 사전 결정된 에폭은 전체 학습 목표 에폭의 일부일 수 있다. 검증 데이터 는 레이블링된 학습 데이터 세트 중 적어도 일부로 구성될 수 있다. 즉, 서버는 학습 데이터 세트를 통해 신경망의 학습을 수행하며, 제1 인공지능 모델의 학습이 사전 결정된 에폭 이상 반복된 후, 검증 데이터를 이용 하여 제1 인공지능 모델의 학습 효과가 사전 결정된 수준 이상인지 여부를 판단할 수 있다. 예를 들어, 서버 는 100개의 학습 데이터를 이용하여 목표 반복 학습 횟수가 10회인 학습을 수행하는 경우, 사전 결정된 에 폭인 10회의 반복 학습을 수행한 후, 10개의 검증 데이터를 이용하여 3회의 반복 학습을 수행하여, 3회의 반복 학습 동안 제1 인공지능 모델 출력의 변화가 사전 결정된 수준 이하인 경우 더 이상의 학습이 무의미한 것으로 판단하고 학습을 종료할 수 있다. 즉, 검증 데이터는 제1 인공지능 모델의 반복 학습에서 에폭별 학습의 효과가 일정 이상인지 이하인지 여부에 기초하여 학습의 완료를 결정하는 데 이용될 수 있다. 전술한 학습 데이터, 검 증 데이터의 수 및 반복 횟수는 하나의 예시일 뿐 이에 한정되지 않는다. 서버는 테스트 데이터 세트를 이용하여 하나 이상의 네트워크 함수의 성능을 테스트하여 하나 이상의 네트 워크 함수의 활성화 여부를 결정함으로써, 수면 평가 모델을 생성할 수 있다. 테스트 데이터는 제1 인공지능 모 델의 성능을 검증하기 위하여 사용될 수 있으며, 학습 데이터 세트 중 적어도 일부로 구성될 수 있다. 예를 들 어, 학습 데이터 세트 중 70%는 제1 인공지능 모델의 학습(즉, 레이블과 비슷한 결과값을 출력하도록 가중치를 조정하기 위한 학습)을 위해 활용될 수 있으며, 30%는 제1 인공지능 모델의 성능을 검증하기 위한 테스트 데이 터로써 활용될 수 있다. 서버는 학습이 완료된 제1 인공지능 모델에 테스트 데이터 세트를 입력하고 오차를 측정하여 사전 결정된 성능 이상인지 여부에 따라 제1 인공지능 모델의 활성화 여부를 결정할 수 있다. 서버는 학습이 완료된 제1 인공지능 모델에 테스트 데이터를 이용하여 학습 완료된 제1 인공지능 모델의 성능을 검증하고 학습 완료된 제1 인공지능 모델의 성능이 사전 결정된 기준 이상인 경우 해당 제1 인공지능 모 델을 다른 어플리케이션에서 사용하도록 활성화할 수 있다. 또한, 서버는 학습 완료된 제1 인공지능 모델 의 성능이 사전 결정된 기준 이하인 경우 해당 제1 인공지능 모델을 비활성화하여 폐기할 수 있다. 예를 들어, 서버는 정확도(accuracy), 정밀도(precision), 재현율(recall) 등의 요소를 기준으로 하여 생성된 제1 인 공지능 모델의 성능을 판단할 수 있다. 전술한 성능 평가 기준은 예시일 뿐이며 본 발명은 이에 제한되지 않는 다. S220 단계에서, 서버는 제1 인공지능 모델을 통해 제1 이미지 데이터를 분석함으로써, 제1 객체를 식별할 수 있고, 식별된 제1 객체에 대한 하나 이상의 제1 특징점을 추출할 수 있다. 예를 들어, 서버는 제1 이미 지 데이터를 입력 프레임으로 하여 제1 인공지능 모델의 입력함으로써, 제1 이미지 데이터에 포함된 제1 객체를 식별할 수 있고, 식별된 제1 객체에 대한 하나 이상의 제1 특징점을 추출할 수 있다. 여기서, 제1 특징점은 이미지 데이터를 분석함에 따라 추출되는 것으로, 예를 들어, 제1 특징점은 객체의 종류 (예: 사람, 자동차, 오토바이, 자전거 등), 연령, 성별, 의복의 속성(예: 의복의 종류 및 색상 등) 및 상체와 하체의 비율 등)을 포함할 수 있으나, 이에 한정되지 않는다. 다양한 실시예에서, 서버는 하나의 제1 이미지 데이터에 복수의 제1 객체가 포함되어 있는 경우, 복수의 제1 객체 각각을 식별하고, 식별된 복수의 제1 객체 각각에 대한 제1 특징점을 개별적으로 추출하되, 복수의 제 1 객체 중 제1 이미지 데이터를 수집한 제1 카메라 센서와 기 설정된 거리 이내(예: 5M)인 제1 객체에 대해서만 제1 특징점을 추출할 수 있다. 즉, 카메라 센서와 객체 사이의 거리가 가까울수록 이미지 데이터 상에 해당 객체에 대한 상세한 정보가 포함되 는 바, 서버는 보다 정밀하게 특징점을 추출하기 위하여 카메라 센서와 가까운 위치에 있는 객체에 대해서 만 특징점을 추출할 수 있다. S230 단계에서, 서버는 제1 인공지능 모델을 통해 제1 라이다 포인트 클라우드 데이터를 분석하여 제1 객 체를 식별할 수 있고, 식별된 제1 객체에 대한 하나 이상의 제2 특징점을 추출할 수 있다. 예를 들어, 서버 는 제1 라이다 포인트 클라우드 데이터를 입력 프레임으로 하여 복셀화(Voxelization)할 수 있고, 제1 인 공지능 모델을 통해 복셀화된 제1 라이다 포인트 클라우드 데이터를 분석하여 제1 객체를 식별할 수 있으며, 식 별된 제1 객체에 대한 하나 이상의 제2 특징점을 추출할 수 있다. 여기서, 제2 특징점은 라이다 포인트 클라우드 데이터를 분석함에 따라 추출되는 것으로, 예를 들어, 제2 특징 점은 객체의 중심점 좌표, 종류 및 3D 경계 박스의 속성 정보(예: 가로, 세로 높이 값 등)을 포함할 수 있으나, 이에 한정되지 않는다. 다양한 실시예에서, 서버는 하나의 제1 라이다 포인트 클라우드 데이터에 복수의 제1 객체가 포함되어 있 는 경우, 복수의 제1 객체 각각을 식별하고, 식별된 복수의 제1 객체 각각에 대한 제2 특징점을 개별적으로 추 출하되, 복수의 제1 객체 중 제1 라이다 포인트 클라우드 데이터를 수집한 제1 라이다 센서와 기 설정된 거리 이내(예: 5M)인 제1 객체에 대해서만 제2 특징점을 추출할 수 있다. 즉, 라이다 센서로부터 수집되는 라이다 포인트 클라우드 데이터의 경우, 이미지 데이터 대비 비교적 적은 정보 (예: 윤곽, 형태, 크기 등)만을 담고 있는 바, 서버는 보다 정밀하게 특징점을 추출하기 위하여 라이다 센 서와 가까운 위치에 있는 객체에 대해서만 특징점을 추출할 수 있다. S240 단계에서, 서버는 S220 단계에서 추출된 하나 이상의 제1 특징점 및 S230 단계에서 추출된 하나 이상 의 제2 특징점을 이용하여 제1 객체 데이터베이스를 구축할 수 있다. 보다 구체적으로, 서버는 제1 인공지능 모델을 통해 제1 이미지 데이터 및 제1 라이다 포인트 클라우드 데 이터를 분석함으로써 식별된 제1 객체에 대하여 고유의 식별코드를 부여할 수 있고, 부여된 식별 코드와 해당 제1 객체에 대한 제1 특징점 및 제2 특징점을 매칭하여 저장할 수 있다. 또한, 서버는 서로 다른 복수의 제1 이미지 데이터 및 복수의 제2 라이다 포인트 클라우드 데이터 상기의 S220 단계 내지 S240 단계를 반복적으로 수행하여 복수의 제1 객체에 대한 정보를 저장함으로써, 제1 객체 데이 터베이스를 구축할 수 있다. 다양한 실시예에서, 서버는 제1 객체에 대한 제1 특징점 및 제2 특징점을 이용하여 제1 객체에 대한 식별 코드를 생성하고, 생성된 식별코드를 제1 객체에 부여할 수 있다. 예를 들어, 서버는 객체를 대상으로 추 출 가능한 복수의 특징점 각각을 순차적으로 결합하여 하나의 염색체(chromosome) 형태의 식별코드 템플릿을 생 성할 수 있다. 이후, 서버는 제1 객체에 대하여 추출된 제1 특징점 및 제2 특징점 각각에 대하여 난수(0 내지 1 범위 내의 수)를 설정하고, 설정된 난수를 제1 객체에 대한 제1 특징점 및 제2 특징점 각각에 대응되는 식별코드 템플릿 상의 위치에 배치함으로써 특징점이 반영된 식별코드를 생성할 수 있다. 다양한 실시예에서, 서버는 건물 내부의 적어도 일부 영역(예: 카드 보관소, 계산대, 이벤트 발생 지점 등)에 설치되는 복수의 제2 카메라로부터 복수의 제2 이미지 데이터를 수집할 수 있고, 복수의 제2 이미지 데이 터를 분석함으로써 복수의 제2 객체에 대한 제1 특징점을 추출할 수 있으며, 추출된 복수의 제2 객체에 대한 제 1 특징점을 이용하여 기 구축된 제1 객체 데이터베이스에 기 저장된 복수의 제1 객체에 대한 정보(예: 복수의제2 객체 각각에 대응되는 복수의 제1 객체들의 정보)를 업데이트할 수 있다. 또한, 서버는 후술되는 도 5의 S310 단계 및 S320 단계를 거쳐, 건물 내부에 설치되는 복수의 제2 라이다 센서로부터 복수의 제2 라이다 포인트 클라우드 데이터를 수집할 수 있고, 복수의 제2 라이다 포인트 클라우드 데이터를 분석함으로써 복수의 제2 객체에 대한 제2 특징점을 추출할 수 있으며, 추출된 복수의 제2 객체에 대 한 제2 특징점을 이용하여 기 구축된 제1 객체 데이터베이스에 기 저장된 복수의 제1 객체에 대한 정보(예: 복 수의 제2 객체 각각에 대응되는 복수의 제1 객체들의 정보)를 업데이트할 수 있다. 즉, 서버는 건물 내에 설치되는 복수의 제2 카메라 센서 및 복수의 제2 라이다 센서를 통해 수집되는 데이 터를 이용하여 객체들의 동선을 추적할 뿐만 아니라, 객체들의 동선을 추적하는 과정에서 수집되는 특징점들을 이용하여 기 구축된 제1 객체 데이터베이스를 지속적으로 업데이트함으로써, 객체의 동선 추적 동작의 성능을 지속적으로 향상시킬 수 있다. 다양한 실시예에서, 서버는 복수의 제2 라이다 포인트 클라우드 데이터에 동일한 제2 객체가 포함됨에 따 라 하나의 제2 객체에 대하여 복수의 특징점이 추출되는 경우, 복수의 제2 라이다 센서 중 하나의 제2 객체와의 거리가 기 설정된 값 이내인 제2 라이다 센서로부터 수집된 제2 라이다 포인트 클라우드 데이터를 선택하고, 선 택된 제2 라이다 포인트 클라우드 데이터로부터 추출된 특징점만을 이용하여 기 구축된 제1 객체 데이터베이스 를 업데이트할 수 있다. 상술된 바와 같이, 라이다 포인트 클라우드 데이터의 경우 이미지 데이터 대비 상대적으로 제한된 정보만을 포 함하고 있는 바, 객체와 거리가 먼 라이다 센서로부터 수집된 라이다 포인트 클라우드로부터 추출된 특징점이 객체와 거리가 가까운 라이다 센서로부터 수집된 라이다 포인트 클라우드로부터 추출된 특징점보다 상대적으로 정확하지 못하다는 한계가 있다. 이러한 점을 고려하여, 서버는 라이다 포인트 클라우드 데이터로부터 추출된 특징점을 기반으로 제1 객체 데이터베이스를 업데이트 하되, 객체와 기 설정된 거리 이내에 위치하는 라이다 센서로부터 수집된 라이다 포인 트 클라우드 데이터 즉, 상대적으로 정확한 특징점이 추출 가능한 라이다 포인트 클라우드 데이터로부터 추출된 값을 이용하여 기 구축된 제1 객체 데이터베이스를 업데이트할 수 있다. 그러나, 이에 한정되지 않는다. 다시 도 3을 참조하면, S130 단계에서, 서버는 S120 단계를 거쳐 제1 객체 데이터베이스를 구축함으로써 객체를 특정한 후, 건물 내부를 실시간으로 스캔함에 따라 수집되는 복수의 제2 라이다 포인트 클라우드 데이터 를 분석하여 특정된 객체의 동선을 추적할 수 있다. 이하, 도 5를 참조하여, 서버에 의해 수행되는 객체의 동선 추적 방법에 대해 보다 구체적으로 설명하도록 한다. 도 5는 다양한 실시예에서, 객체의 동선을 추적하는 방법을 설명하기 위한 순서도이다. 도 5를 참조하면, S310 단계에서, 서버는 복수의 제2 라이다 포인트 클라우드 데이터를 수집할 수 있다. 예를 들어, 서버는 건물 내부의 적어도 일부 영역에 각각 설치된 복수의 제2 라이다 센서로부터 기 설정된 주기마다 복수의 제2 라이다 포인트 클라우드 데이터를 수집할 수 있다. 그러나, 이에 한정되지 않는다. S320 단계에서, 서버는 S310 단계를 거쳐 수집된 복수의 제2 라이다 포인트 클라우드 데이터 중 하나 이상 의 제2 라이다 포인트 클라우드 데이터를 분석하여 하나 이상의 제2 라이다 포인트 클라우드 데이터에 포함된 제2 객체를 식별하고, 식별된 제2 객체의 특징점을 추출할 수 있다. 여기서, 하나 이상의 제2 라이다 포인트 클라우드 데이터를 분석하여 제2 객체를 식별하는 동작 및 제2 객체에 대한 특징점을 추출하는 동작은 도 4의 S230 단계와 동일한 형태로 구현될 수 있다. 예를 들어 서버는 하 나 이상의 제2 라이다 포인트 클라우드 데이터를 제1 인공지능 모델에 입력함으로써, 하나 이상의 제2 라이다 포인트 클라우드 데이터에 포함된 제2 객체를 식별하고, 식별된 제2 객체에 대한 특징점을 추출할 수 있다. 그 러나, 이에 한정되지 않는다. 다양한 실시예에서, 서버는 식별된 제1 객체의 속성(예: 종류, 연령, 성별 등)에 기초하여, 객체에 대한 단위 시간당 최대 이동 거리를 산출할 수 있고, 산출된 단위 시간당 최대 이동 거리를 이용하여 복수의 제2 라 이다 포인트 클라우드 데이터 중 적어도 하나의 제2 라이다 포인트 클라우드 데이터를 선택할 수 있으며, 선택 된 적어도 하나의 제2 라이다 포인트 클라우드 데이터만을 이용하여 제2 객체 식별 동작 및 제2 객체 특징점 추출 동작을 수행할 수 있다. 그러나, 이에 한정되지 않는다. 다양한 실시예에서, 서버는 복수의 제2 라이다 포인트 클라우드 데이터를 분석하여 제2 객체를 식별할 수 있고, 복수의 제2 라이다 포인트 클라우드 데이터 각각을 수집한 복수의 제2 라이다 센서와 제2 객체 간의 거리 를 각각 산출할 수 있으며, 산출된 거리에 기초하여 복수의 제2 라이다 포인트 클라우드 데이터 각각으로부터 추출하고자 하는 특징점의 속성(예: 종류, 개수 등)을 결정할 수 있다. 그러나, 이에 한정되지 않는다. S330 단계에서, 서버는 기 구축된 제1 객체 데이터베이스에 포함된 복수의 제1 객체 각각에 대한 특징점과 S320 단계를 거쳐 추출된 제2 객체의 특징점을 비교하여 복수의 제1 객체 중 제2 객체와 동일한 어느 하나의 제 1 객체를 선택할 수 있다. 다양한 실시예에서, 서버는 복수의 제1 객체 각각에 대한 특징점과 제2 객체의 특징점 간의 일치율을 산출 하고, 산출된 일치율이 가장 높은 값을 가지는 어느 하나의 제1 객체를 제2 객체와 동일한 객체로서 선택할 수 있다. 여기서, 일치율은 전체 특징점 개수 대비 동일한 특징점 개수의 비율일 수 있으나, 이에 한정되지 않는다. 다양한 실시예에서, 서버는 복수의 제1 객체 각각에 대한 특징점을 이용하여 생성된 복수의 식별코드와 제 2 객체의 특징점을 이용하여 생성된 코드를 비교하여 제2 객체와 동일한 어느 하나의 제1 객체를 선택할 수 있 다. 예를 들어, 서버는 염색체 형태의 식별코드 템플릿과 제2 객체의 특징점을 이용하여 제2 객체에 대한 코드를 생성할 수 있고, 제2 객체에 대한 코드와 복수의 제1 객체 각각에 대한 식별코드(예: 염색체 형태의 식 별코드 템플릿과 복수의 제1 객체 각각의 특징점을 이용하여 생성된 코드)를 비교하여 복수의 제1 객체 중 제2 객체에 대한 코드와 동일한 식별코드(또는 일치율이 가장 높은 식별코드)의 제1 객체를 선택할 수 있다. S340 단계에서, 서버는 S330 단계에서 선택된 어느 하나의 제1 객체에 대응되는 식별코드와 식별된 제2 객 체의 속도 및 이동 방향에 관한 정보를 매칭하여 건물 내부의 지도 상에 기록할 수 있다(예: 도 6 및 7). 다양한 실시예에서, 서버는 복수의 제1 객체 중 제2 객체의 특징점과 일치하는 제1 객체가 부재한 경우 또 는 상기의 방법에 따라 선택된 어느 하나의 제1 객체에 대한 일치율이 기 설정된 값 미만인 경우, 제2 객체에 대응되는 식별코드를 신규 부여할 수 있고, 신규 부여된 식별코드와 제2 객체의 특징점을 매칭하여 기 구축된 제1 객체 데이터베이스 상에 기록할 수 있다. S350 단계에서, 서버는 기 설정된 조건을 만족했는지 여부를 판단할 수 있다. 여기서, 기 설정된 조건은 특정 객체에 대한 동선 추적을 종료하기 위한 조건일 수 있다. 일례로, 서버는 특정 객체에 대한 동선 추 적 종료 트리거(Trigger)가 감지되는 지 여부, 예를 들어, 동선 추적 중인 객체가 건물 외부로 나가거나 관리자 로부터 객체의 동선 추적 동작의 종료 명령이 수신되었는지 여부를 판단할 수 있다. S360 단계에서, 서버는 S350 단계를 거쳐 기 설정된 조건을 만족한 것으로 판단되는 경우, 제2 객체에 대 한 동선 추적 동작을 종료할 수 있다. 이후, 서버는 기 구축된 제1 객체 데이터베이스에서 동선 추적 동작 이 종료된 객체에 대한 정보(예: 객체의 식별코드, 제1 및 2 특징점 및 동선 정보(예: 속도, 방향, 동선 등))를 추출하여 별도의 저장 공간에 저장할 수 있다. 이를 통해, 별도의 저장 공간에 저장된 정보들 즉, 사용자의 위 치 및 사용자의 이동 동선에 관한 정보를 이용하여 실내 이동 경로 안내, 사용자의 니즈 파악 등 다양한 분야에 서 활용할 수 있다. 한편, 서버는 S350 단계를 거쳐 기 설정된 조건을 만족하지 않는 것으로 판단되는 경우, 기 설정된 조건이 만족될 때까지 상기의 S310 내지 S340 단계를 반복적으로 수행할 수 있다. 이하, 도 8 및 9를 참조하여, 서버 에 의해 수행되는 라이다 포인트 클라우드 데이터 기반 객체의 동선 추적방법에 대해 설명하도록 한다. 도 8은 본 발명의 또 다른 실시예에 따른 라이다 포인트 클라우드 데이터 기반 객체의 동선 추적방법의 순서도 이다. 여기서, 도 8에 따른 라이다 포인트 클라우드 데이터 기반 객체의 동선 추적방법을 수행하기 위하여, 건물 내에 복수의 라이다 센서가 설치될 수 있다. 보다 구체적으로, 먼저 건물 내에 진입하는 객체를 특정하기 위하여, 건물의 출입구와 인접한 위치에 객체를 스 캔하기 위한 라이다 센서(예: 제1 라이다 센서)가 설치될 수 있다. 또한, 건물 내 공간을 이동하는 객체의 동선을 추적하기 위하여, 건물 내의 복수의 라이다 센서(예: 제2 라이다 센서)가 설치될 수 있다. 이때, 복수의 제2 라이다 센서는 커버리지가 겹쳐지도록 설치 즉, 제2 라이다 센서를 통해 수집되는 복수의 제2 라이다 포인트 클라우드 데이터 각각의 적어도 일부분이 중첩되도록 설치될 수 있으 나, 이에 한정되지 않는다. 도 8을 참조하면, S410 단계에서, 서버는 제1 라이다 포인트 클라우드 데이터를 수집할 수 있다. 여기서, 제1 라이다 포인트 클라우드 데이터를 수집하는 동작은 도 3의 S110 단계와 동일한 형태로 구현될 수 있다. 예 를 들어, 서버는 제1 라이다 센서를 통해 건물의 출입구 영역을 스캔한 제1 라이다 포인트 클라우드 데이 터를 수집할 수 있다. 그러나, 이에 한정되지 않는다. S420 단계에서, 서버는 S410 단계를 거쳐 수집된 제1 라이다 포인트 클라우드 데이터를 이용하여 객체를 식별할 수 있다. 다양한 실시예에서, 서버는 제1 라이다 포인트 클라우드 데이터를 분석하여 제1 라이다 포인트 클라우드 데이터에 포함된 제1 객체를 특정할 수 있다. 예를 들어, 서버는 기 학습된 인공지능 모델을 이용하여 제1 라이다 포인트 클라우드 데이터를 분석함으로써, 제1 객체를 식별할 수 있고, 식별된 객체에 대한 특징점을 추 출할 수 있으며, 추출된 특징점에 기초하여 식별된 객체를 특정할 수 있다. 이하, 도 9를 참조하여 구체적으로 설명하도록 한다. 도 9는 다양한 실시예에서, 제2 인공지능 모델을 이용하여 객체 데이터베이스를 구축하는 방법을 설명하기 위한 순서도이다. 도 9을 참조하면, S510 단계에서, 서버는 객체 식별 및 특징점 추출 동작을 수행하기 위하여, 제2 인공지 능 모델을 생성할 수 있다. 다양한 실시예에서, 서버는 복수의 라이다 포인트 클라우드 데이터를 이용하여 학습 데이터를 생성할 수 있고, 생성된 학습 데이터를 이용하여 제2 인공지능 모델을 학습시킬 수 있다. 예를 들어, 서버는 라이다 센서를 통해 라이다 포인트 클라우드 데이터를 프레임 단위로 수집하고, 프레임 각각에 정답(예: 인식할 객체에 대한 정보)를 레이블링 함으로써, 학습 데이터 셋을 구축할 수 있다. 이후, 서버는 구축된 학습 데이터 셋 을 이용하여 제2 인공지능 모델을 학습시킬 수 있다. 여기서, 제2 인공지능 모델의 구조 및 종류와 제2 인공지능 모델의 학습 방법은 제1 인공지능 모델과 동일할 수 있으나, 이에 한정되지 않는다. 또한, 서버는 도 3에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법과 도 8에 따른 라이다 포인트 클라우드 데이터 기반 객체의 동선 추적방법을 수행하기 위하여 제1 인공지능 모델 및 제2 인공지능 모델을 각각 개별적으로 생성하는 것으로 설명하고 있으나, 이에 한정되지 않고, 복수의 이미지 데이 터 및 복수의 라이다 포인트 클라우드 데이터를 포함하는 학습 데이터 셋을 이용하여 하나의 인공지능 모델(예: 제1 인공지능 모델)을 생성하고, 생성된 하나의 인공지능 모델을 통해 상기의 방법들을 모두 수행할 수 있다. S520 단계에서, 서버는 제2 인공지능 모델을 통해 제1 라이다 포인트 클라우드 데이터를 분석하여 제1 객 체를 식별할 수 있고, 식별된 제1 객체에 대한 하나 이상의 제2 특징점을 추출할 수 있다. 여기서, 제1 객체 식 별 및 특징점 추출 동작은 도 4의 S230 단계와 동일한 형태로 구현될 수 있다. 예를 들어, 서버는 제1 라 이다 포인트 클라우드 데이터를 입력 프레임으로 하여 복셀화할 수 있고, 제2 인공지능 모델을 통해 복셀화된 제1 라이다 포인트 클라우드 데이터를 분석하여 제1 객체를 식별할 수 있으며, 식별된 제1 객체에 대한 하나 이 상의 특징점을 추출할 수 있다. 그러나, 이에 한정되지 않는다. 또한, 여기서, 특징점은 라이다 포인트 클라우드 데이터를 분석함에 따라 추출되는 것으로 상기의 제2 특징점과 동일하게 객체의 중심점 좌표, 종류 및 3D 경계 박스의 속성 정보(예: 가로, 세로 높이 값 등)을 포함할 수 있 으나, 이에 한정되지 않는다. 다양한 실시예에서, 서버는 제1 라이다 포인트 클라우드 데이터에 복수의 제1 객체가 포함된 경우, 복수의 제1 객체 각각을 식별하고, 식별된 복수의 제1 객체 각각에 대한 특징점을 추출하되, 복수의 제1 객체 중 복수 의 제1 객체 각각에 대응되는 영역에 포함된 라이다 포인트의 개수가 기 설정된 개수 이상인 제1 객체에 대해서 만 하나 이상의 특징점을 추출할 수 있다. 상술된 바와 같이, 라이다 센서로부터 수집되는 라이다 포인트 클라우드 데이터의 경우, 이미지 데이터 대비 상 대적으로 적은 정보만을 담고 있는 바, 보다 정밀한 특징점을 추출하기 위하여 라이다 센서와 가까운 위치에 위 치하는 객체에 대해서만 특징점을 추출하도록 제한할 필요성이 있다. 이때, 라이다 센서와 객체 사이의 거리가 가까울수록 객체에 대응되는 영역에 포함되는 라이다 포인트의 개수가 많아지는 것을 고려하여, 서버는 임 계치 이상의 라이다 포인트 개수를 포함하는 객체에 대해서만 특징점을 추출함으로써, 정확한 특징점이 추출되 도록 할 수 있다. S530 단계를 거쳐, 서버는 S520 단계에서 추출된 하나 이상의 특징점을 이용하여 제1 객체 데이터베이스를 구축할 수 있다. 여기서, 제1 객체 데이터베이스 구축 동작은 도 4의 S240 단계와 동일한 형태로 구현될 수 있 다. 예를 들어, 서버는 제2 인공지능 모델을 통해 제1 라이다 포인트 클라우드 데이터를 분석함으로써 식 별된 제1 객체에 대하여 고유의 식별코드를 부여할 수 있고, 부여된 식별코드와 해당 제1 객체에 대한 특징점을 매칭하여 저장할 수 있다. 그러나, 이에 한정되지 않는다. 또한, 기 구축된 제1 객체 데이터베이스를 업데이트하는 동작 또한 도 4의 S240 단계와 동일한 형태로 구현될 수 있다. 예를 들어, 서버는 비교적 정확하게 추출된 특징점을 이용하여 기 구축된 제1 객체 데이터베이스 를 업데이트하기 위한 목적으로, 라이다 센서와 객체 사이의 거리를 고려하여, 복수의 제2 라이다 포인트 클라 우드 데이터에 동일한 제2 객체가 포함됨에 따라 하나의 제2 객체에 대하여 복수의 특징점이 추출되는 경우, 복 수의 제2 라이다 포인트 클라우드 데이터 중 하나의 제2 객체에 대응되는 영역에 포함된 라이다 포인트의 개수 가 기 설정된 개수 이상인 제2 라이다 포인트 클라우드 데이터를 선택하고, 선택된 제2 라이다 포인트 클라우드 데이터로부터 추출된 특징점만을 이용하여 기 구축된 제1 객체 데이터베이스를 업데이트할 수 있다. 다시, 도 8을 참조하면, S430 단계에서, 서버는 S420 단계를 거쳐 제1 객체 데이터베이스를 구축함으로써 객체를 특정한 후, 내부를 실시간으로 스캔함에 따라 수집되는 복수의 제2 라이다 포인트 클라우드 데이터를 분 석하여 특정된 객체의 동선을 추적할 수 있다. 여기서, 특정된 객체의 동선을 추적하는 동작은 도 5의 S310 단 계 내지 S360 단계와 동일한 형태로 구현될 수 있으나, 이에 한정되지 않는다. 전술한 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법 및 라이다 포인트 클라우드 데이 터 기반 객체의 동선 추적방법은 도면에 도시된 순서도를 참조하여 설명하였다. 간단한 설명을 위해 이미지 데 이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법 및 라이다 포인트 클라우드 데이터 기반 객체의 동 선 추적방법은 일련의 블록들로 도시하여 설명하였으나, 본 발명은 상기 블록들의 순서에 한정되지 않고, 몇몇 블록들은 본 명세서에 도시되고 시술된 것과 상이한 순서로 수행되거나 또는 동시에 수행될 수 있다. 또한, 본 명세서 및 도면에 기재되지 않은 새로운 블록이 추가되거나, 일부 블록이 삭제 또는 변경된 상태로 수행될 수 있다."}
{"patent_id": "10-2021-0183970", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2021-0183970", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적시스템을 도시한 도면이다. 도 2는 본 발명의 다른 실시예에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적서버의 하드웨어 구성도이다. 도 3은 본 발명의 또 다른 실시예에 따른 이미지 데이터 및 라이다 센서 데이터를 이용한 객체의 동선 추적방법 의 순서도이다. 도 4는 다양한 실시예에서, 제1 인공지능 모델을 이용하여 객체 데이터베이스를 구축하는 방법을 설명하기 위한 순서도이다. 도 5는 다양한 실시예에서, 객체의 동선을 추적하는 방법을 설명하기 위한 순서도이다. 도 6 및 7은 다양한 실시예에서, 객체의 동선이 지도상에 기록된 형태를 예시적으로 도시한 도면이다. 도 8은 본 발명의 또 다른 실시예에 따른 라이다 포인트 클라우드 데이터 기반 객체의 동선 추적방법의 순서도 이다. 도 9는 다양한 실시예에서, 제2 인공지능 모델을 이용하여 객체 데이터베이스를 구축하는 방법을 설명하기 위한 순서도이다."}
