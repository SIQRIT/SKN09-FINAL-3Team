{"patent_id": "10-2019-0106848", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0106908", "출원번호": "10-2019-0106848", "발명의 명칭": "인공지능 로봇과 그의 제어 방법", "출원인": "엘지전자 주식회사", "발명자": "이원희"}}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 로봇이 복약 스케줄에 따라 복용 대상자와 사용자를 매칭하는 단계;상기 사용자에게 설정되어 있는 약을 토출하는 단계;상기 사용자에 대한 영상 데이터를 판독하여 상기 사용자의 복약 여부를 확인하는 단계;상기 사용자의 복약 후의 영상 데이터를 판독하고, 상기 사용자의 복약 후의 생체 데이터에 대한 감지 신호를판독하여 상기 사용자의 이상 유무를 판단하는 단계; 및상기 사용자에게 이상이 발생한 경우, 응급 처리를 수행하는 단계를 포함하는 인공지능 로봇의 제어 방법."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공지능 로봇은,본체부 내에 상기 약을 수용하는 공간을 포함하는 약 수용부가 형성되어 있으며, 상기 본체부 외면에 상기 약을토출하거나 주입하는 입출부가 형성되어 있는 것을 특징으로 하는 인공지능 로봇의 제어 방법."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 사용자의 복약 여부를 판단하는 단계는, 상기 약을 토출한 후, 사용자가 상기 약을 복용하는 영상 데이터를 수득하여 상기 영상 데이터와 지난 주기의 영상 데이터를 비교하는 딥러닝을 수행하여 복용 여부를 판단하는것을 특징으로 하는 인공지능 로봇의 제어 방법."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 사용자의 이상 유무를 판단하는 단계는,복약 후 영상 데이터를 수득하는 단계, 상기 영상 데이터를 딥러닝하여 사용자의 행동 패턴을 분석하는 단계,상기 사용자의 복약 후의 생체 데이터에 대한 감지 신호를 수득하는 단계,상기 감지 신호 및 상기 사용자의 행동 패턴을 조합하여 상기 사용자의 이상 유무를 판단하는 단계를 포함하는 것을 특징으로 하는 인공지능 로봇의 제어 방법."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 생체 데이터는상기 사용자의 심장 박동 수 및 체온 정보를 포함하는 것을 특징으로 하는 인공지능 로봇의 제어 방법."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,공개특허 10-2019-0106908-3-상기 사용자와 복용 대상자를 매칭하는 단계는상기 인공지능 로봇이 이동하면서 상기 사용자를 탐색하는 단계, 그리고탐색된 상기 사용자에 대한 영상 데이터가 수득되면 상기 복용 대상자 정보와 상기 사용자에 대한 영상 데이터를 매칭하는 단계를 포함하는 것을 특징으로 하는 인공지능 로봇의 제어 방법."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 사용자가 있을 위치를 추정하여 추정된 위치로 이동하는 단계를 더 포함하는 것을 특징으로 하는 인공지능로봇의 제어 방법."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 인공지능 로봇은 상기 복약 스케줄에 대하여 서버로부터 복약 명령 정보를 수신하는 것을 특징으로 하는인공지능 로봇의 제어 방법."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 인공지능 로봇은 상기 복약 스케줄에 대하여 상기 사용자로부터 직접 정보를 입력받고, 저장된 상기 복약스케줄에 따라 상기 복용 대상자를 탐색하는 것을 특징으로 하는 인공지능 로봇의 제어 방법."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제5항에 있어서,상기 인공지능 로봇이 상기 사용자를 매칭하는 단계는,상기 복약 스케줄에 따라 주변 알림을 통해 주변의 사용자를 불러들이고, 상기 사용자의 영상 데이터를 판독하여 상기 복용 대상자인지 판단하는 것을 특징으로 하는 인공지능 로봇의 제어 방법."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "외관을 형성하고, 복약 스케줄에 따라 토출되는 약을 수용하는 본체부;상기 본체부를 지지하는 지지부;주행 영역의 영상을 촬영하여 영상 정보를 생성하는 영상 획득부; 및상기 복약 스케줄에 따라 사용자에 약을 토출시키고, 사용자에 대한 영상 데이터를 판독하여 상기 사용자의 복약 여부를 확인하고, 상기 사용자의 복약 후의 영상 데이터 및 생체 데이터를 판독하여 상기 사용자의 이상 유무를 판단하는 제어부를 포함하는 인공지능 로봇."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제어부는 상기 사용자에게 이상이 발생한 경우, 응급 처리를 수행하도록 제어하는 것을 특징으로 하는 인공지능 로봇."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,공개특허 10-2019-0106908-4-상기 인공지능 로봇은,상기 본체부 외면에 상기 약을 토출하거나 주입하는 입출부가 형성되어 있는 것을 특징으로 하는 인공지능로봇."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 제어부는 상기 약을 토출한 후, 사용자가 상기 약을 복용하는 영상을 수득하여 상기 영상 데이터와 지난주기의 영상 데이터를 비교하는 딥러닝을 수행하여 복용 여부를 판단하는 것을 특징으로 하는 인공지능 로봇."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제어부는, 복약 후 영상 데이터를 수득하고, 상기 영상 데이터를 딥러닝하여 사용자의 행동 패턴을 분석하고, 상기 사용자의 복약 후의 생체 데이터를 수득하고, 상기 생체 데이터 및 상기 사용자의 행동 패턴을 조합하여 상기 사용자의 이상 유무를 판단하는 것을 특징으로 하는 인공지능 로봇."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 생체 데이터는상기 사용자의 심장박동 수 및 체온 정보를 포함하는 것을 특징으로 하는 인공지능 로봇."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 지지부는상기 인공지능 로봇을 이동시키는 주행부를 포함하고,상기 제어부는 상기 주행부를 구동하여 상기 인공지능 로봇이 이동하면서 상기 사용자를 탐색하는 것을 특징으로 하는 인공지능 로봇."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 제어부는 상기 사용자가 있을 위치를 추정하여 추정된 위치로 상기 주행부를 구동시키는 것을 특징으로 하는 인공지능 로봇."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 인공지능 로봇은 상기 복약 스케줄에 대하여 서버로부터 복약 명령 정보를 수신하는 것을 특징으로 하는인공지능 로봇."}
{"patent_id": "10-2019-0106848", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서,상기 인공지능 로봇은 상기 복약 스케줄에 대하여 상기 사용자로부터 직접 정보를 입력받는 인터페이스를 더 포함하고,상기 저장부는 저장된 상기 복약 스케줄에 따라 상기 복용대상자를 탐색하는 것을 특징으로 하는 인공지능로봇.공개특허 10-2019-0106908-5-청구항 21 제11항에 있어서,상기 인공지능 로봇은 상기 복약 스케줄에 따라 주변 알림을 통해 주변의 사용자를 불러들이고, 상기 사용자의영상 데이터를 판독하여 상기 복용 대상자인지 판단하는 것을 특징으로 하는 인공지능 로봇."}
{"patent_id": "10-2019-0106848", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 외관을 형성하고, 복약 스케줄에 따라 토출되는 약을 수용하는 본체부; 상기 본체부를 지지하는 지지 부; 주행 영역의 영상을 촬영하여 영상 정보를 생성하는 영상 획득부; 및 상기 복약 스케줄에 따라 사용자에 약 을 토출시키고, 사용자에 대한 영상 데이터를 판독하여 상기 사용자의 복약 여부를 확인하고, 상기 사용자의 복 약 후의 영상 데이터 및 생체 데이터를 판독하여 상기 사용자의 이상 유무를 판단하는 제어부를 포함하는 인공지 능 로봇을 제공한다. 따라서, 사용자를 판별하고, 해당 사용자에 매칭된 약을 토출함으로써 사용자가 복용하여야 하는 시간, 종류, 양 등의 실수를 방지할 수 있어 안정성이 확보될 수 있다. 약 복용 후의 사용자의 반응을 센서 로 검출하고, 딥러닝 등을 수행하여 사용자의 반응을 학습함으로써 응급 상황 등을 판단하고 그에 따라 대처할 수 있다."}
{"patent_id": "10-2019-0106848", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사용자에 복약 서비스를 제공하는 인공지능 로봇에 있어서, 사용자의생체 정보를 측정하여 그에 따른 서비스를 제공하는 인공지능 로봇 및 인공지능 로봇의 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0106848", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 산업용으로 개발되어 공장 자동화의 일 부분을 담당하여 왔다. 최근에는 로봇을 응용한 분야가 더욱 확 대되어, 의료용 로봇, 우주 항공 로봇 등이 개발되고, 일반 가정에서 사용할 수 있는 가정용 로봇도 만들어지고 있다. 이러한 로봇 중에서 자력으로 주행이 가능한 것을 인공지능 로봇이라고 한다. 로봇 이용의 증가에 따라, 단순 기능의 반복 수행을 넘어서 다양한 정보, 재미, 서비스를 제공할 수 있는 로봇 에 대한 요구가 많아지고 있다. 이에 따라, 가정, 식당, 매장, 공공 장소 등에 배치되어 사람에게 편의를 제공하는 다양한 로봇이 개발되고 있 다. 또한, 원격으로 로봇을 조종하여 환자를 돌보는 서비스들에 제안되고 있다. 예를 들어, 선행 문헌 (미국 등록 특허 US9361021호)은 원격으로 로봇을 조종하여 환자를 돌보는 기능을 수행하며, 디스플레이를 통해 환자의 정 보를 선택적으로 표시하고, 환자의 실시간 영상을 표시하는 등의 부가 기능을 제공하고 있다. 또한, 선행 문헌(일본 등록 특허 JP5852706B9호)에는 원격으로 로봇을 조종하여 사용자에게 접근하고, 다양한 서비스를 제공하며, 각종 센서 카메라 및 디스플레이를 시스템으로 포함한다. 그러나 이러한 원격 제어 로봇의 경우, 직접적으로 사용자에게 접근하여 해당 사용자가 복용할 약을 제공하고, 이에 대한 피드백을 확인하지 않는다. 이와 같이 사용자에 대한 헬스 케어를 제공하는 로봇 서비스의 경우, 원격으로 관리자가 직접 해당 로봇을 제어 하는 것이 기재되어 있을 뿐, 로봇 자체가 사람을 구분하고 그에 맞는 약을 토출하는 등의 자발적인 인공지능 로봇에 대하여는 개시하지 않는다. [선행기술문헌] [특허문헌] 미국 등록 특허 US9361021호, 공개일자 2015년 03월 19일"}
{"patent_id": "10-2019-0106848", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 제1 과제는 사용자에 복약 서비스를 제공하는 인공지능 로봇으로서, 사용자를 판별하고, 해당 사용자 에 매칭된 약을 토출함으로써 사용자가 복용하여야 하는 시간, 종류, 양 등의 실수를 방지할 수 있는 헬스 케어 로봇을 제공하는 것이다. 본 발명의 제2 과제는 사용자의 복약 시점을 정확하게 기록하여 이후 치료 및 처방에 활용 가능한 헬스 케어 로 봇을 제공하는 것이다. 본 발명의 제3 과제는 로봇이 제공하는 이벤트인 약토출에 대한 약 복용 후의 사용자의 반응을 센서로 검출하고, 딥 러닝 등을 수행하여 사용자의 반응을 학습함으로써 응급 상황 등을 판단할 수 있는 헬스 케어 로 봇을 제공하는 것이다.본 발명의 제4 과제는 서버로부터 사용자의 약 투약에 대한 명령을 수신하거나, 이미 설정되어 있는 스케줄에 따라 사용자를 판별하여 특정 약을 토출하고, 복용 사실에 대한 영상을 촬영하여 복용 확인을 진행할 수 있는 헬스 케어 로봇을 제공하는 것이다."}
{"patent_id": "10-2019-0106848", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 인공지능 로봇이 복약 스케줄에 따라 복용 대상자와 사용자를 매칭하는 단계; 상기 사용자에게 설정 되어 있는 약을 토출하는 단계; 상기 사용자에 대한 영상 데이터를 판독하여 상기 사용자의 복약 여부를 확인하 는 단계; 상기 사용자의 복약 후의 영상 데이터를 판독하고, 상기 사용자의 복약 후의 생체 데이터에 대한 감지 신호를 판독하여 상기 사용자의 이상 유무를 판단하는 단계; 및 상기 사용자에게 이상이 발생한 경우, 알람 및 응급 처리를 수행하는 단계를 포함하는 인공지능 로봇의 제어 방법을 제공한다. 상기 인공지능 로봇은, 상기 본체부 내에 상기 약을 수용하는 공간을 포함하는 약 수용부가 형성되어 있으며, 상기 본체부 외면에 상기 약을 토출하거나 주입하는 입출부가 형성될 수 있다. 상기 사용자의 복약 여부를 판단하는 단계는, 상기 약을 토출한 후, 사용자가 상기 약을 복용하는 영상을 수득 하여 상기 영상 데이터와 지난 주기의 영상 데이터를 비교하는 딥러닝을 수행하여 복용 여부를 판단할 수 있다. 상기 사용자의 이상 유무를 판단하는 단계는, 복약 후 영상 데이터를 수득하는 단계, 상기 영상 데이터를 딥러 닝하여 사용자의 행동 패턴을 분석하는 단계, 상기 사용자의 복약 후의 생체 데이터에 대한 감지 신호를 수득하 는 단계, 상기 감지 신호 및 상기 사용자의 행동 패턴을 조합하여 상기 사용자의 이상 유무를 판단하는 단계를 포함할 수 있다. 상기 생체 데이터는 상기 사용자의 심장박동 수 및 체온 정보를 포함할 수 있다. 상기 사용자와 복용 대상자를 매칭하는 단계는 상기 인공지능 로봇이 이동하면서 상기 사용자를 탐색하는 단계, 탐색된 상기 사용자에 대한 영상 데이터가 수득되면 상기 복용 대상자 정보와 상기 사용자에 대한 영상 데이터 를 매칭하는 단계를 포함할 수 있다. 상기 사용자가 있을 위치를 추정하여 추정된 위치로 이동하는 단계를 더 포함할 수 있다. 상기 인공지능 로봇은 상기 복약 스케줄에 대하여 서버로부터 복약 명령 정보를 수신할 수 있다. 상기 인공지능 로봇은 상기 복약 스케줄에 대하여 상기 사용자로부터 직접 정보를 입력받고, 저장된 상기 복약 스케줄에 따라 상기 복용대상자를 탐색할 수 있다. 상기 인공지능 로봇이 상기 사용자를 매칭하는 단계는, 상기 복약 스케줄에 따라 주변 알림을 통해 주변의 사용 자를 불러들이고, 상기 사용자의 영상 데이터를 판독하여 상기 복용 대상자인지 판단할 수 있다. 한편, 본 발명의 실시예는 외관을 형성하고, 복약 스케줄에 따라 토출되는 약을 수용하는 본체부; 상기 본체부 를 지지하는 지지부; 주행 영역의 영상을 촬영하여 영상 정보를 생성하는 영상 획득부; 및 상기 복약 스케줄에 따라 사용자에 약을 토출시키고, 사용자에 대한 영상 데이터를 판독하여 상기 사용자의 복약 여부를 확인하고, 상기 사용자의 복약 후의 영상 데이터 및 생체 데이터를 판독하여 상기 사용자의 이상 유무를 판단하는 제어부 를 포함하는 인공지능 로봇을 제공한다. 상기 제어부는 상기 사용자에게 이상이 발생한 경우, 알람 및 응급 처리를 수행하도록 제어할 수 있다. 상기 인공지능 로봇은, 상기 본체부 외면에 상기 약을 토출하거나 주입하는 입출부가 형성될 수 있다. 상기 제어부는 상기 약을 토출한 후, 사용자가 상기 약을 복용하는 영상을 수득하여 상기 영상 데이터와 지난 주기의 영상 데이터를 비교하는 딥러닝을 수행하여 복용 여부를 판단할 수 있다. 상기 제어부는, 복약 후 영상 데이터를 수득하고, 상기 영상 데이터를 딥러닝하여 사용자의 행동 패턴을 분석하 고, 상기 사용자의 복약 후의 생체 데이터를 수득하고, 상기 생체 데이터 및 상기 사용자의 행동 패턴을 조합하 여 상기 사용자의 이상 유무를 판단할 수 있다. 상기 생체 데이터는 상기 사용자의 심장박동 수 및 체온 정보를 포함할 수 있다. 상기 지지부는 상기 인공지능 로봇을 이동시키는 주행부를 포함하고, 상기 제어부는 상기 주행부를 구동하여 상 기 인공지능 로봇이 이동하면서 상기 사용자를 탐색할 수 있다.상기 제어부는 상기 사용자가 있을 위치를 추정하여 추정된 위치로 상기 주행부를 구동시킬 수 있다. 상기 인공지능 로봇은 상기 복약 스케줄에 대하여 서버로부터 복약 명령 정보를 수신할 수 있다. 상기 인공지능 로봇은 상기 복약 스케줄에 대하여 상기 사용자로부터 직접 정보를 입력받는 인터페이스를 더 포 함하고, 상기 저장부는 저장된 상기 복약 스케줄에 따라 상기 복용대상자를 탐색할 수 있다. 상기 인공지능 로봇은 상기 복약 스케줄에 따라 주변 알림을 통해 주변의 사용자를 불러들이고, 상기 사용자의 영상 데이터를 판독하여 상기 복용 대상자인지 판단할 수 있다."}
{"patent_id": "10-2019-0106848", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 해결 수단을 통해, 본 발명은 사용자를 판별하고, 해당 사용자에 매칭된 약을 토출함으로써 사용자가 복용 하여야 하는 시간, 종류, 양 등의 실수를 방지할 수 있어 안정성이 확보될 수 있다. 또한, 사용자의 복용 시점 및 복용 여부를 정확하게 기록하여 이후 치료 및 처방에 활용가능하다. 본 발명은 로봇이 제공하는 이벤트인 약토출에 대한 약 복용 후의 사용자의 반응을 센서로 검출하고, 딥러닝 등 을 수행하여 사용자의 반응을 학습함으로써 응급 상황 등을 판단하고 그에 따라 대처할 수 있다. 그리고, 서버로부터 사용자의 약 투약에 대한 명령을 수신하거나, 이미 설정되어 있는 스케줄에 따라 사용자를 판별하여 특정 약을 토출하고, 복용 사실에 대한 영상을 촬영하여 복용 확인을 진행할 수 있어 더욱 명확한 헬 스 케어가 가능하다."}
{"patent_id": "10-2019-0106848", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서 언급되는 “전(F)/후(R)/좌(Le)/우(Ri)/상(U)/하(D)” 등의 방향을 지칭하는 표현은 도면에 표시된 바 에 따라 정의하나, 이는 어디까지나 본 발명이 명확하게 이해될 수 있도록 설명하기 위한 것이며, 기준을 어디 에 두느냐에 따라 각 방향들을 다르게 정의할 수도 있음은 물론이다. 이하에서 언급되는 구성요소 앞에 ‘제1, 제2’ 등의 표현이 붙는 용어 사용은, 지칭하는 구성요소의 혼동을 피 하기 위한 것일 뿐, 구성요소 들 사이의 순서, 중요도 또는 주종관계 등과는 무관하다. 예를 들면, 제1 구성요 소 없이 제2 구성요소 만을 포함하는 발명도 구현 가능하다. 도면에서 각 구성의 두께나 크기는 설명의 편의 및 명확성을 위하여 과장되거나 생략되거나 또는 개략적으로 도 시되었다. 또한 각 구성요소의 크기와 면적은 실제크기나 면적을 전적으로 반영하는 것은 아니다. 또한, 본 발명의 구조를 설명하는 과정에서 언급하는 각도와 방향은 도면에 기재된 것을 기준으로 한다. 명세 서에서 구조에 대한 설명에서, 각도에 대한 기준점과 위치관계를 명확히 언급하지 않은 경우, 관련 도면을 참조 하도록 한다. 이하 도 1 내지 도 3을 참조하여, 인공지능 로봇 중 복약 서비스 로봇을 예로 들어 설명하나, 반드시 이에 한정 될 필요는 없다. 도 1은 본 발명의 일 실시예에 따른 인공지능 로봇 시스템의 구성도이고, 도 2는 도 1의 인공지능 로봇을 바라 본 입면도이고, 도 3은 도 1의 인공지능 로봇의 제어 관계를 나타낸 블록도이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 로봇 시스템은, 하나 이상의 로봇을 구비하여 집 또는 병원 등 다양한 장소에서 서비스를 제공할 수 있다. 예를 들어, 로봇 시스템은 가정 등에서 사용자와 인터랙션 (interaction)하며, 사용자에 대한 투약 스케줄에 따라 사용자를 판별하고, 해당 사용자에 대한 약을 토출하고, 사용자의 약 복용 여부를 판단 및 복용 후 반응을 판단하여 그에 따른 조치가 가능한 인공지능 로봇을 포함 할 수 있다. 바람직하게는, 본 발명의 일 실시예에 따른 로봇 시스템은, 복수의 인공지능 로봇 및 복수의 인공지능 로봇 을 관리하고 제어할 수 있는 서버를 포함할 수 있다. 서버는 원격에서 복수의 로봇의 상태를 모니터링하고, 제어할 수 있고, 로봇 시스템은 복수의 로봇을 이용하여 더 효과적인 서비스 제공이 가능하다. 복수의 로봇 및 서버는 하나 이상의 통신 규격을 지원하는 통신 수단(미도시)을 구비하여, 상호 통신할 수 있다. 또한, 복수의 로봇 및 서버는 PC, 이동 단말기, 외부의 다른 서버와 통신할 수 있다. 예를 들어, 복수의 로봇 및 서버는 IEEE 802.11 WLAN, IEEE 802.15 WPAN, UWB, Wi-Fi, Zigbee, Z-wave, Blue-Tooth 등과 같은 무선 통신 기술로 무선 통신하게 구현될 수 있다. 로봇은 통신하고자 하는 다른 장치 또는 서버의 통신 방식이 무엇인지에 따라 달라질 수 있다. 특히, 복수의 로봇은 5G 네트워크를 통해 다른 로봇 및/또는 서버와 무선통신을 구현할 수 있다. 로봇 이 5G 네트워크를 통해 무선 통신하는 경우, 실시간 응답 및 실시간 제어가 가능하다. 또한, 복수의 로봇 및 서버는 MQTT(Message Queueing Telemetry Transport) 방식으로 통신할 수 있고, HTTP(HyperText Transfer Protocol) 방식으로 통신할 수 있다. 또한, 복수의 로봇 및 서버는 HTTP 또는 MQTT 방식으로 PC, 이동 단말기, 외부의 다른 서버와 통신할 수 있다. 경우에 따라서, 복수의 로봇 및 서버는 2이상의 통신 규격을 지원하고, 통신 데이터의 종류, 통신에 참여 하는 기기의 종류에 따라 최적의 통신 규격을 사용할 수 있다. 사용자는 PC, 이동 단말기 등의 사용자 단말을 통하여 로봇 시스템 내의 로봇들에 관한 정보를 확인하거 나 제어할 수 있다. 본 명세서에서 '사용자'는 적어도 하나의 로봇을 통한 서비스를 이용하는 사람으로, 로봇을 구매 또는 대여하여 가정 등에서 사용하는 개인 고객 및 로봇을 이용하여 직원 또는 고객에게 서비스를 제공하는 기업의 관리자, 직 원들과 이러한 기업이 제공하는 서비스를 이용하는 고객들을 포함할 수 있다. 따라서, '사용자'는 개인 고객 (Business to Consumer: B2C)과 기업 고객(Business to Business : B2B)을 포함할 수 있다. 서버는 클라우드(cloud) 서버로 구현되어, 사용자는 사용자 단말기가 통신 연결된 서버에 저장된 데이 터와 서버가 제공하는 기능, 서비스를 이용할 수 있다. 로봇에 클라우드 서버가 연동되어 로봇을 모니터링, 제어하고 다양한 솔루션과 콘텐츠를 원격으로 제공할 수 있다. 서버는, 로봇들, 기타 기기로부터 수신되는 정보를 저장 및 관리할 수 있다. 상기 서버는 로봇들의 제조사 또는 제조사가 서비스를 위탁한 회사가 제공하는 서버일 수 있다. 상기 서버는 로봇들을 관리하고 제어하는 관제 서버일 수 있다. 상기 서버는 로봇들을 일괄적으로 동일하게 제어하거나, 개별 로봇 별로 제어할 수 있다. 또한, 서버 는 로봇들 중 적어도 일부 로봇에 대해서 그룹으로 설정한 후에 그룹별로 제어할 수 있다. 한편, 상기 서버는, 복수의 서버로 정보, 기능이 분산되어 구성될 수도 있고, 하나의 통합 서버로 구성될 수 도 있을 것이다. 로봇 및 서버는 하나 이상의 통신 규격을 지원하는 통신 수단(미도시)을 구비하여, 상호 통신할 수 있다. 로봇은 서버로 공간(space), 사물(Object), 사용(Usage) 관련 데이터(Data)를 서버로 전송할 수 있다. 여기서, 데이터는 공간(space), 사물(Object) 관련 데이터는 로봇이 인식한 공간(space)과 사물(Object)의 인식 관련 데이터이거나, 영상획득부가 획득한 공간(space)과 사물(Object)에 대한 이미지 데이터일 수 있다. 실시예에 따라서, 로봇 및 서버는 사용자, 음성, 공간의 속성, 장애물 등 사물의 속성 중 적어도 하나를 인식하도록 학습된 소프트웨어 또는 하드웨어 형태의 인공신경망(Artificial Neural Networks: ANN)을 포함할 수 있다. 본 발명의 일 실시예에 따르면, 로봇 및 서버는 딥러닝(Deep Learning)으로 학습된 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network) 등 심층신경망(Deep Neural Network: DNN)을 포함할 수 있다. 예를 들어, 로봇의 제어부에는 CNN(Convolutional Neural Network) 등 심층신경망 구조(DNN)가 탑재될 수 있다. 서버는 로봇으로부터 수신한 데이터, 사용자에 의해 입력되는 데이터 등에 기초하여, 심층신경망(DNN)을 학습시킨 후, 업데이트된 심층신경망(DNN) 구조 데이터를 로봇으로 전송할 수 있다. 이에 따라, 로봇이 구비하는 인공지능(artificial intelligence)의 심층신경망(DNN) 구조를 업데이트할 수 있다. 또한, 사용(Usage) 관련 데이터(Data)는 로봇의 사용에 따라 획득되는 데이터로, 사용 이력 데이터, 센서부 에서 획득된 감지 신호 등이 해당될 수 있다. 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력받고, 입력 데이터에 포함된 사람, 사물, 공간의 속 성을 인식하여, 그 결과를 출력할 수 있다. 또한, 상기 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력받고, 로봇의 사용(Usage) 관련 데이 터(Data)를 분석하고 학습하여 사용 패턴, 사용 환경 등을 인식할 수 있다. 한편, 공간(space), 사물(Object), 사용(Usage) 관련 데이터(Data)는 통신부를 통하여 서버로 전송될 수 있다. 서버는 수신한 데이터에 기초하여, 심층신경망(DNN)을 학습시킨 후, 업데이트된 심층신경망(DNN) 구조 데이 터를 인공지능 로봇으로 전송하여 업데이트하게 할 수 있다. 이에 따라, 로봇이 점점 스마트하게 되며, 사용할수록 진화되는 사용자 경험(UX)을 제공할 수 있다. 로봇 및 서버는 외부 정보(external information)도 이용할 수 있다. 예를 들어, 서버가 다른 연계 서비스 서버(도시하지 않음)로부터 획득한 외부 정보를 종합적으로 사용하여 우수한 사용자 경험을 제공할 수 있다. 또한, 본 발명에 따르면, 로봇이 능동적으로 먼저 정보를 제공하거나 기능, 서비스를 추천하는 음성을 출력 함으로써 사용자에게 더욱 다양하고 적극적인 제어 기능을 제공할 수 있다. 도 2는 사용자에게 복약 서비스를 제공할 수 있는 인공지능 로봇을 예시한다. 인공지능 로봇은 사용자에게 복약 서비스 등을 제공할 수 있는 인공지능 로봇으로서, 디스플레이(180a)를 구 비하여 유저 인터페이스 화면 등 소정 영상을 표시할 수 있는 헤드부, 복약할 약제를 수용하고, 제어에 따 라 해당 약을 토출하는 본체부, 그리고 헤드부 및 본체부를 지지하며 이동 가능하도록 주행하는 주 행부를 포함한다. 이러한 헤드부, 본체부 및 주행부의 구성은 다양하게 구현될 수 있으며 도 2에 한정되는 것은 아니 다. 헤드부는 디스플레이를 포함하며, 이벤트, 광고, 복약 관련 정보 등을 포함하는 유저 인터페이스(UI) 화면 을 디스플레이(180a)에 표시할 수 있다. 디스플레이(180a)는 터치스크린으로 구성되어 입력 수단으로도 사용될 수 있다. 또한, 인공지능 로봇은, 터치, 음성 입력 등으로 사용자 입력을 수신하여, 사용자 입력에 대응하는 정보를 디스플레이(180a) 화면에 표시할 수 있다. 실시예에 따라서, 인공지능 로봇은, 안내를 위하여, 티켓, 항공권, 바코드, QR 코드 등을 식별할 수 있는 스 캐너를 구비할 수 있다. 헤드부는 영상획득부의 카메라를 더 포함할 수 있다. 카메라는 상기 헤드부에 배치되어 상기 헤드 부가 향하는 방향의 소정 범위의 영상 데이터를 획득할 수 있다. 예를 들어, 인공지능 로봇이 사용자를 탐색할 때, 상기 헤드부는 상기 카메라가 식별되는 사용자를 향하 도록 회전할 수 있다. 실시예에 따라서, 인공지능 로봇은 2개의 디스플레이(180a, 180b)를 포함할 수 있고, 2개의 디스플레이 (180a, 180b) 중 적어도 하나는 터치스크린으로 구성되어 입력 수단으로도 사용될 수 있다 이때, 2개의 디스플레이(180a, 180b) 중 하나는 헤드부에 배치되고, 다른 디스플레이(180b)는 본체부에 형성될 수 있으나 이에 한정되는 것은 아니다. 이러한 인공지능 로봇은 헤드부를 지지하는 본체부 내부에 소정의 수용부(도시하지 않음)를 포함할 수 있다. 수용부는 투입구 및 배출부 사이에 내부 공간을 갖도록 형성되어 있으며, 투입구를 통해 주입되 는 소정의 약을 분류하여 저장할 수 있다. 본체부의 일 면에 형성되는 투입구 및 배출부는 서로 분리되어 있을 수 있고 일체로 형성되어 있 을 수도 있다. 주행부는 바퀴, 모터 등을 구비하여 주행을 담당할 수 있다. 또한 인공지능 로봇이 고정되어 있는 경우, 주행부는 지지 영역으로서 기능을 수행할 수 있다. 주행부가 주행을 진행하는 경우, 하나 이상의 절개부(20a)를 포함할 수 있다. 이러한 절개부(20a)는 내부의 전방 라이더(미도시)가 동작 가능하도록 상기 주행 모듈에서 절개되는 부분으 로, 상기 주행 모듈의 외주면의 전방에서 측방에 걸쳐 형성될 수 있다. 상기 전방 라이더는 상기 주행 모듈의 내부에서 상기 절개부(10a)와 마주보도록 배치될 수 있다. 이에 따라, 상기 전방 라이더는 상기 절개부(10a)를 통하여 레이저를 방출할 수 있다. 내부의 후방 라이더(미도시)가 동작 가능하도록 상기 주행부에서 절개되는 부분인 다른 절개부(도시하지 않 음)가 상기 주행부의 외주면의 후방에서 측방에 걸쳐 형성될 수 있으며, 이는 내부의 후방 라이더가 동작 가능하도록 형성된다. 또한, 주행구역 내 바닥에 낭떠러지의 존재 여부를 감지하는 절벽 감지 센서 등 내부의 센서가 동작 가능하도록 상기 주행부에서 절개되는 또 다른 절개부를 포함할 수 있다. 한편, 상기 주행부의 외면에도 센서가 배치될 수 있다. 상기 주행부의 외면에는 장애물을 감지하기 위 한 초음파 센서 등 장애물 감지 센서가 배치될 수 있다. 예를 들어, 초음파 센서는 초음파 신호를 이용하여 장애물과 인공지능 로봇들 사이의 거리를 측정하기 위한 센서일 수 있다. 상기 초음파 센서는 상기 인공지능 로봇과 근접한 장애물을 감지하기 위한 기능을 수행할 수 있다. 이러한 인공지능 로봇은 특정 공간을 주행하면서 부여된 임무를 수행할 수 있다. 인공지능 로봇은 스스로 소정 목적지까지의 경로를 생성하여 이동하는 자율 주행, 사람 또는 다른 로봇을 따라가며 이동하는 추종 주행 을 수행할 수 있다. 안전사고 발생을 방지하기 위해서, 인공지능 로봇은 영상획득부를 통하여 획득되는 영상 데이터, 센서부에서 획득되는 센싱 데이터 등에 기초하여 이동 중 장애물을 감지하여 회피하면서 주 행할 수 있다. 구체적으로 이러한 인공지능 로봇은, 서버 또는 특정 스케줄에 따라 저장되어 있는 특정 약을 특정 사용자에게 토출하는 복약 서비스를 제공할 수 있다. 인공지능 로봇에는 사용 환경 및 용도에 따라 최적화된 서비스를 제공하기 위해 모듈러 디자인이 적용될 수 있다. 이하에서는 인공지능 로봇의 제어를 위한 내부 블록도를 설명한다. 도 3은 도 1의 인공지능 로봇의 제어 관계를 나타낸 블록도이다. 도 3을 참조하면, 본 발명의 일 실시예에 따른 인공지능 로봇은, 인공지능 로봇의 전반적인 동작을 제어 하는 제어부, 각종 데이터를 저장하는 저장부, 서버 등 다른 기기와 데이터를 송수신하는 통신부 를 포함할 수 있다. 제어부는, 인공지능 로봇 내 저장부, 통신부, 구동부, 센서부, 출력부 등을 제어하여, 인공지능 로봇의 동작 전반을 제어할 수 있다. 저장부는 인공지능 로봇의 제어에 필요한 각종 정보들을 기록하는 것으로, 휘발성 또는 비휘발성 기록 매체를 포함할 수 있다. 기록 매체는 마이크로 프로세서(micro processor)에 의해 읽힐 수 있는 데이터를 저장 한 것으로, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자 기 테이프, 플로피 디스크, 광 데이터 저장 장치 등을 포함할 수 있다. 통신부는 적어도 하나의 통신모듈을 포함하여 인공지능 로봇이 인터넷, 또는 소정의 네트워크에 연결되 도록 할 수 있고 다른 기기와 통신하게 할 수 있다. 또한, 통신부는 서버에 구비되는 통신 모듈과 연결하여 인공지능 로봇과 서버 간의 데이터 송수 신을 처리할 수 있다. 본 발명의 일 실시예에 따른 인공지능 로봇은 마이크를 통하여 사용자의 음성 입력을 수신하는 음성 입력부 를 더 포함할 수 있다. 음성 입력부는, 아날로그 소리를 디지털 데이터로 변환하는 처리부를 포함하거나 처리부에 연결되어, 사용 자 입력 음성 신호를 제어부 또는 서버에서 인식할 수 있도록 데이터화할 수 있다. 한편, 저장부에는 음성 인식을 위한 데이터가 저장될 수 있고, 상기 제어부는 음성 입력부를 통 하여 수신되는 사용자의 음성 입력 신호를 처리하고 음성 인식 과정을 수행할 수 있다. 한편, 제어부는 음성 인식 결과에 기초하여 로봇이 소정 동작을 수행하도록 제어할 수 있다. 한편, 인공지능 로봇은 출력부를 포함하여, 소정 정보를 영상으로 표시하거나 음향으로 출력할 수 있다. 출력부는 사용자의 명령 입력에 대응하는 정보, 사용자의 명령 입력에 대응하는 처리 결과, 동작모드, 동 작상태, 에러상태 등을 영상으로 표시하는 디스플레이(180a, 180b)를 포함할 수 있다. 실시예에 따라서, 인공지 능 로봇은 복수개의 디스플레이(180a, 180b)를 포함할 수 있다. 실시예에 따라서는, 상기 디스플레이(180a, 180b) 중 적어도 일부는 터치패드와 상호 레이어 구조를 이루어 터 치스크린으로 구성될 수 있다. 이 경우에, 터치스크린으로 구성되는 디스플레이(180a)는 출력 장치 이외에 사용 자의 터치에 의한 정보의 입력이 가능한 입력 장치로도 사용될 수 있다. 또한, 출력부는 오디오 신호를 출력하는 음향 출력부를 더 포함할 수 있다. 음향 출력부는 제어 부의 제어에 따라 경고음, 동작모드, 동작상태, 에러상태 등의 알림 메시지, 사용자의 명령 입력에 대응하 는 정보, 사용자의 명령 입력에 대응하는 처리 결과 등을 음향으로 출력할 수 있다. 음향 출력부는, 제어 부로부터의 전기 신호를 오디오 신호로 변환하여 출력할 수 있다. 이를 위해, 스피커 등을 구비할 수 있다. 실시예에 따라서, 인공지능 로봇은 소정 범위를 촬영할 수 있는 영상획득부를 더 포함할 수 있다. 영상획득부는 인공지능 로봇 주변, 외부 환경 등을 촬영하는 것으로, 카메라 모듈을 포함할 수 있다. 이러한 카메라는 촬영 효율을 위해 각 부위별로 여러 개가 설치될 수도 있고, 앞서 설명한 바와 같이 헤드부에 배치될 수 있다. 영상획득부는, 사용자 인식용 영상을 촬영할 수 있다. 제어부는 상기 영상획득부가 촬영하여 획 득된 영상에 기초하여 외부 상황을 판단하거나, 사용자(안내 대상)를 인식할 수 있다. 또한, 로봇이 인공지능 로봇인 경우에, 상기 제어부는, 상기 영상획득부가 촬영하여 획득하는 영 상에 기초하여 로봇이 주행하도록 제어할 수 있다. 한편, 상기 영상획득부가 촬영하여 획득된 영상은 저장부에 저장될 수 있다. 인공지능 로봇은 이동을 위한 구동부를 더 포함할 수 있고, 상기 구동부는 제어부의 제어에 따라, 본체를 이동시킬 수 있다. 구동부는 로봇의 주행부 내에 배치될 수 있으며, 본체를 이동시키는 적어도 하나의 구동 바퀴(미도시)를 포함할 수 있다. 구동부는 구동 바퀴에 연결되어 구동 바퀴를 회전시키는 구동 모터(미도시)를 포함할 수 있다. 구동 바퀴는 본체의 좌, 우 측에 각각 구비될 수 있으며, 이하, 각각 좌륜과 우륜이라고 한다. 좌륜과 우륜은 하나의 구동 모터에 의해 구동될 수도 있으나, 필요에 따라 좌륜을 구동시키는 좌륜 구동 모터와 우륜을 구동시키는 우륜 구동 모터가 각각 구비될 수도 있다. 좌륜과 우륜의 회전 속도에 차이를 두어 좌측 또 는 우측으로 본체의 주행방향을 전환할 수 있다. 한편, 인공지능 로봇은 인공지능 로봇의 동작, 상태와 관련된 각종 데이터를 센싱하는 센서들을 포함하는 센서부를 포함할 수 있다. 상기 센서부는 로봇의 동작을 감지하고 동작 정보를 출력하는 동작 감지 센서를 더 포함할 수 있다. 예 를 들어, 동작 감지 센서로는, 자이로 센서(Gyro Sensor), 휠 센서(Wheel Sensor), 가속도 센서(Acceleration Sensor) 등을 사용할 수 있다. 상기 센서부는 장애물을 감지하는 장애물 감지 센서를 포함할 수 있고, 상기 장애물 감지 센서는, 적외선 센서, 초음파 센서, RF 센서, 지자기 센서, PSD(Position Sensitive Device) 센서, 주행구역 내 바닥에 낭떠러 지의 존재 여부를 감지하는 절벽 감지 센서, 라이다(light detection and ranging: Lidar) 등 포함할 수 있다. 한편, 상기 장애물 감지 센서는 인공지능 로봇의 주행(이동) 방향에 존재하는 물체, 특히 장애물을 감지하여 장 애물 정보를 제어부에 전달한다. 이때, 제어부는, 감지된 장애물의 위치에 따라 인공지능 로봇의 움직임을 제어할 수 있다. 한편, 제어부는 통신부를 통해 인공지능 로봇의 동작상태 또는 사용자 입력 등을 서버 등으로 전송하도록 제어할 수 있다. 이러한 제어부는 서버 또는 기 설정된 스케줄에 따라 투약 명령이 수신되면, 사용자를 탐색하기 위한 주변 영상을 수득하고, 영상 데이터에 따라 사용자가 이번 투약 스케줄의 대상자인지 판단한다. 이때, 사용자가 특정되면, 제어부는 해당 약을 토출하고 사용자에게 제공한다. 또한 제어부는 토출한 약을 사용자가 복약하는지 여부 역시 영상 획득부의 영상을 판독하여 판단할 수 있다. 또한, 제어부는 복약 후의 사용자 상태에 대한 영상 및 센서로부터의 감지 신호에 따라 사용자의 상태를 판단하고 이에 따라 알람 또는 응급 처리 등의 서비스를 진행할 수 있다. 제어부는 이와 같은 영상 데이터 및 감지 신호로부터 사용자의 판별, 사용자의 행동 판단을 컴퓨터 비전 시스템을 통해 수행할 수 있다. 이하에서는 도 4 내지 도 6을 참고하여 인공지능 로봇의 헬스 케어 방법에 대하여 상세히 설명한다. 도 4는 도 1의 인공지능 로봇의 제1 시나리오에 따른 복약 서비스 제어 방법을 도시한 순서도이고, 도 5는 도 1 의 인공지능 로봇의 제2 시나리오에 따른 헬스케어 방법을 도시한 순서도이며, 도 6은 도 1의 인공지능 로봇의 복약 정보 입력에 대한 시나리오를 도시한 순서도이다. 먼저, 인공지능 로봇은 서버로부터 복약 서비스에 대한 정보를 전송받는다(S11). 즉, 인공지능 로봇은 서버로부터 특정 사용자에 대한 복약 스케줄에 따라 복약 명령 및 복약 정보를 전송 받는다. 복약 정보로는 현재 복약을 하여야 하는 스케줄 상의 복용 대상자 정보, 복약할 특정 약의 종류 및 복약 방법 등에 대한 정보를 포함할 수 있다. 인공지능 로봇의 제어부는 수신된 복약 정보에 따라 주변을 주행하면서 주변에 해당 사용자가 있는지 사용자의 얼굴을 탐색한다(S12). 즉, 제어부는 영상 획득부로부터 주변의 영상을 획득하고, 영상 데이터에서 사용자가 존재할 때, 사 용자의 외관의 특징점을 파악하여 해당 사용자의 외관의 특징점을 복용 대상자의 정보와 비교하여 발견된 사용 자가 해당하는 복용 대상자인지 판단한다. 이러한 사용자 매칭에는 SLAM(Simulation language for alternative modeling)을 이용한 컴퓨터 비전 시스템이 활용될 수 있다. 해당 사용자가 복용 대상자인 것으로 판별되면, 인공지능 로봇은 서버 접속을 진행하여 해당 복용 대상자 에 대한 복약 정보를 수신한다(S14). 이때, 수신하는 복약 정보는 이전 주기의 복약 실시에 대한 정보 등을 포함할 수 있다. 다음으로 인공지능 로봇은 해당 사용자 앞으로 이동하여 해당 사용자에게 적합한 복약 시점이 도래되었음을 알리고 그에 따라 적합한 약을 토출한다(S15). 이러한 약은 복약 정보에 따라 특정 약이 토출부를 통해 배출됨으로써 진행될 수 있다. 다음으로, 제어부는 영상 획득부로부터 카메라를 통해 추출된 영상 데이터를 수득하고 해당 영상 데 이터를 분석하여 사용자의 행동 패턴을 추출한다(S16). 이때, 추출된 현재 사용자 행동 패턴을 정의하고, 사용자에 대한 복약 정보에서 이전 주기에서의 복약 시의 행 동 패턴을 읽어들여 이번 주기의 행동 패턴이 이전 주기의 행동 패턴에서 벗어나는지 판단한다(S17). 이러한 행동 패턴 비교는 이전 복약 주기에서 사용자의 복약 동작의 영상들과 현재 주기에서의 사용자의 복약 동작에 대한 영상을 서로 비교함으로써 현재 주기에서 사용자가 복약을 정확하게 진행하였는지 판단할 수 있다. 사용자가 현재 주기에서 복약을 정확히 진행한 것으로 판단되면(S18), 제어부는 카메라를 통하여 사용자에 대한 영상 데이터를 수득한다(S19). 제어부는 수득된 영상 데이터를 통해 복약 후의 사용자의 행동을 추출할 수 있다. 이때, 제어부는 사용자가 복약 후 앉거나, 쓰러지거나, 휘청거리는 등의 행동이 있는지 파악하고 이러한 패턴에 대하여 키워드와 딥러닝을 통한 분석을 진행하고 분석 결과를 저장한다(S20). 또한, 제어부는 복수의 센서부를 통해 사용자의 생체 정보를 측정하고 그에 따른 감지 신호를 수득할 수 있다(S21). 이러한 생체 정보에 대한 감지 신호는 사용자의 체온 변화, 심장 박동 등에 대한 감지 신호일 수 있다. 이때, 사용자의 행동 패턴 및 생체 정보에 대한 감지 신호는 서버로 전송할 수 있다(S22). 이때, 서버는 수신된 정보를 데이터 베이스에 저장하여 다음 주기에서 비교 자료로 활용될 수 있고, 수신된 정보를 기초로 사 용자의 복약 후 상태를 판단하여 그에 따른 명령을 인공지능 로봇에 전송할 수 있다(S23). 다음으로 인공지능 로봇이 서버로부터 원격으로 사용자의 상태에 대한 판단 결과를 수신하거나 추가 정보 요청을 수신하면, 인공지능 로봇은 사용자에 대하여 추가 정보를 제공할 수 있는지 판단할 수 있다(S24). 즉, 사용자의 상태를 판단할 수 있을 정도로 충분한 생체 정보 측정이 이루어 졌는지 다시 판단할 수 있다. 충분한 생체 정보 측정이 이루어졌다고 판단되면, 인공지능 로봇은 서버로부터 복약에 의해 사용자에게 이상이 있는 것으로 판단되는 정보가 수득된 것인지 판단한다(S25). 인공지능 로봇이 서버로부터 사용자에 대한 복약 이상이 있는 것으로 명령을 수신한 경우, 알람을 발생하 고, 응급 처리 등을 위한 동작을 수행한다(S26). 즉, 사용자의 복약 후 영상 데이터를 분석하고, 이를 저장한 뒤 서버로 전송하고, 생체 정보를 측정하고 그 에 따른 정보를 서버로 전달했을 때, 일 예로 사용자가 주저 앉음을 영상 데이터를 통해 판단하고, 생체 정 보를 통해 사용자의 체온이 갑작스럽게 상승한 것으로 판단되면, 서버는 이에 대하여 알람 및 응급처리 등을 필요로 하는 상황으로 판단하여 그에 대한 결과를 전송할 수 있다. 이에 따라 인공지능 로봇은 음성 또는 사이렌 알람 등을 진행하여 주변에 해당 사용자에게 이상이 발생한 것 을 알릴 수 있다. 또한 응급 상황에 대한 연락망을 가동하여 연계되어 있는 병원 또는 응급센터 등에 도움을 요 청할 수 있다. 한편, 서버로부터 주변을 탐색하여 사용자가 발견되지 않으면, 주행 영역의 맵 정보를 이용하여 사용자가 있 을만한 위치를 추정할 수 있다(S27). 이때, 위치 추정에 대하여는 이전 주기의 복약 정보로부터의 주요 사용자 거점을 위주로 사용자 위치를 추정할 수 있다.인공지능 로봇은 추정된 위치로 이동하여 해당 사용자가 존재하는지 여부를 다시 탐색할 수 있다(S28). 이와 같이, 인공지능 로봇은 서버로부터 복약 스케줄에 따른 복약 서비스 진행 명령이 수신되면, 주변에 대한 영상 데이터를 획득하고, 이를 분석하여 사용자 판단, 복약 판단, 복약 후 사용자 상태 판단 등을 진행하 여 적극적이고 적절한 복약에 대한 대응을 수행할 수 있다. 따라서, 복약이 완전히 진행되었는지 체크할 수 있고, 복약 후에 사용자 상태를 체크할 수 있어 부작용 등에 의 한 사용자 이상에 대하여 적극적이고 적합한 대응이 가능하다. 한편, 인공지능 로봇이 주행부를 포함하지 않는 고정형 로봇인 경우, 도 5와 같이 복약 서비스를 제공할 수 있다. 먼저, 인공지능 로봇은 서버와 연결된 상태에서(S100), 동작이 시작되면, 인공지능 로봇은 서버로 부터 사용자에 대한 복약 스케줄에 따라 복약 명령 및 복약 정보를 전송 받는다(S101). 복약 정보로는 현재 복약을 하여야 하는 스케줄 상의 복용 대상자 정보, 복약할 특정 약의 종류 및 복약 방법 등에 대한 정보를 포함할 수 있다. 인공지능 로봇의 제어부는 주변에 존재하는 사용자에게 소리 및 화면 변화 등의 알람을 수행하여 복약 주기가 도래하였음을 알린다(S102). 이때, 소리 알람은 정해진 알림음일 수 있으며, “000님, 약 드실 시간입니다.” 등의 안내 멘트일 수 있다. 이와 같은 알람에 의해 주변의 사용자가 인공지능 로봇의 카메라 앞으로 이동하면, 카메라는 상기 사용자의 영상을 촬영하여 상기 사용자가 현재 주기에서의 복용 대상자인지 판단한다(S103). 즉, 제어부는 영상 획득부로부터 주변의 영상을 획득하고, 영상 데이터에서 사용자가 존재할 때, 사 용자의 외관의 특징점을 파악하여 해당 사용자의 외관의 특징점을 복용 대상자의 정보와 비교하여 발견된 사용 자가 해당하는 복용 대상자인지 판단한다. 이러한 사용자 매칭에는 SLAM 을 이용한 컴퓨터 비전 시스템이 활용 될 수 있다. 해당 사용자가 복용 대상자인 것으로 판별되면, 인공지능 로봇은 서버 접속을 진행하여 해당 복용 대상자 에 대한 복약 정보를 수신한다(S104). 이때, 수신하는 복약 정보는 이전 주기의 복약 실시에 대한 정보 등을 포함할 수 있다. 다음으로 인공지능 로봇은 해당 사용자 앞으로 이동하여 해당 사용자에게 적합한 복약 시점을 알리고 그에 따라 적합한 약을 토출한다(S105). 즉, 복약 정보에 따라 특정 약이 토출부를 통해 배출됨으로써 진행될 수 있다. 다음으로, 제어부는 영상 획득부로부터 카메라를 통해 추출된 영상 데이터를 수득하고 해당 영상 데 이터를 분석하여 사용자의 행동 패턴을 추출한다(S106). 이때, 추출된 현재 사용자 행동 패턴을 정의하고, 사용자에 대한 복약 정보에서 이전 복약 시의 행동 패턴을 읽 어들여 이번 행동 패턴이 이전 행동 패턴에서 벗어나는지 판단한다(S107). 이러한 행동 패턴 비교는 이전 복약 주기에서 사용자의 복약 동작의 영상들과 현재 주기에서의 사용자의 복약 동작에 대한 영상을 서로 비교함으로써 현재 주기에서 사용자가 복약을 정확하게 진행하였는지 판단할 수 있다. 사용자가 현재 주기에서 복약을 정확히 진행한 것으로 판단되면(S108), 제어부는 카메라를 통하여 사용자 에 대한 영상 데이터를 수득한다. 제어부는 수득된 영상 데이터를 통해 복약 후의 사용자의 행동을 추출할 수 있다(S109). 이때, 제어부는 사용자가 복약 후 앉거나, 쓰러지거나, 휘청거리는 등의 행동이 있는지 파악하고 이러한 패턴에 대하여 키워드와 딥러닝을 통한 분석을 진행하고 분석 결과를 저장한다(S110). 또한, 제어부는 복수의 센서부를 통해 사용자의 생체 정보를 측정하고 그에 따른 감지 신호를 수득할 수 있다(S111). 이러한 생체 정보에 대한 감지 신호는 사용자의 체온 변화, 심장 박동 등에 대한 감지 신호를 수득할 수 있다. 이때, 사용자의 행동 패턴 및 생체 정보에 대한 감지 신호는 서버로 전송할 수 있다(S112). 이때, 서버 는 수신된 정보를 데이터 베이스에 저장하여 다음 주기에서 비교 자료로 활용될 수 있고, 수신된 정보를 기초로 사용자의 복약 후 상태를 판단하여 그에 따른 명령을 인공지능 로봇에 전송할 수 있다. 다음으로 인공지능 로봇이 서버로부터 원격으로 사용자의 상태에 대한 판단 결과를 수신하거나 추가 정보 요청을 수신하면, 인공지능 로봇은 사용자에 대하여 추가 정보를 제공할 수 있는지 판단할 수 있다. 즉, 사 용자의 상태를 판단할 수 있을 정도로 충분한 생체 정보 측정이 이루어 졌는지 다시 판단할 수 있다(S113). 충분한 생체 정보 측정이 이루어졌다고 판단되면(S114), 인공지능 로봇은 서버로부터 원격으로 복약에 대 하여 이상이 있는 것으로 판단된 것인지 판단한다. 인공지능 로봇이 서버로부터 사용자에 대한 복약 이상이 있는 것으로 명령을 수신한 경우(S115), 알람을 발생하고, 응급 처리 등을 위한 동작을 수행한다(S116). 즉, 사용자의 복약 후 영상 데이터를 분석하고, 이를 저장한 뒤 서버로 전송하고, 생체 정보를 측정하고 그 에 따른 정보를 서버로 전달했을 때, 일 예로 사용자가 주저 앉음을 영상 데이터를 통해 판단하고, 생체 정 보를 통해 사용자의 체온이 갑작스럽게 상승한 것으로 판단되면, 서버는 이에 대하여 알람 및 응급처리 등을 필요로 하는 상황으로 판단하여 그에 대한 결과를 전송할 수 있다. 이에 따라 인공지능 로봇은 음성 또는 사이렌 알람 등을 진행하여 주변에 해당 사용자에게 이상이 발생한 것 을 알릴 수 있다. 또한 응급 상황에 대한 연락망을 가동하여 연계되어 있는 병원 또는 응급센터 등에 도움을 요 청할 수 있다. 이와 같이, 인공지능 로봇은 서버로부터 복약 스케줄에 따른 복약 서비스 진행 명령이 수신되면, 주변에 대한 영상 데이터를 획득하고, 이를 분석하여 사용자 판단, 복약 판단, 복약 후 사용자 상태 판단 등을 진행하 여 적극적이고 적절한 복약에 대한 대응을 수행할 수 있다. 한편, 인공 지능 로봇은 사용자로부터 직접 복약 일정 등에 대한 스케줄을 수신하여 그에 따라 복약 서비스 를 진행할 수 있다. 즉, 도 6과 같이, 사용자로부터 특정 사용자에 대한 복약 스케줄 정보를 직접 수신할 수 있다. 먼저, 사용자가 해당 인공지능 로봇의 디스플레이(180a)에서 스케줄 입력 아이콘을 선택하여 스케줄 입력 메 뉴에 진입하면(S300), 제어부는 복약 스케줄 입력 모드로 전환하여 수신될 스케줄에 대한 요청 리스트를 디스플레이한다. 즉, 제어부는 디스플레이에 사용자 정보, 복약 날짜, 복약 시간, 복약 주기, 약 종류, 안내사항 등에 대한 요청 리스트를 디스플레이할 수 있다. 사용자는 디스플레이된 요청 리스트에 대하여 해당 정보를 입력할 수 있다(S301). 인공지능 로봇이 해당 정보를 수신하면, 제어부는 저장부에 해당 정보에 따라 세팅을 진행하고, 사용자 정보에 대하여 매칭을 진행한다. 이때 사용자 정보로는 사용자 사진 촬영 등을 통해 영상 데이터를 수신 할 수 있으며, 그와 달리 개인 정보 또는 개인 암호를 설정하여 입력을 완료할 수 있다(S302). 일 예로, 특정 약에 대한 복약 스케줄을 입력하는 경우, 시작 날짜, 예를 들어 2019년 5월 1일부터 복약 시작 후 30일 동안, 매일 8시, 14시, 21시를 복약 시간으로 스케줄을 입력할 수 있다. 이때, 약의 종류가 무엇인지 구체적으로 기입할 수 있다. 이러한 복약 스케줄에 대한 정보가 수신되고, 사용자 정보가 수신되어 매칭이 완성되면 제어부는 입력이 완료된 것으로 판단하고, 이를 저장부에 기록하고 일정에 따라 복약 서비스를 수행한다. 즉, 설정된 시작일의 첫 시간에 다다르면, 인공지능 로봇은 도 4에서 설명한 바와 같이, 사용자를 탐색하고, 탐색된 사용자가 복용 대상자인지 확인되면, 해당 사용자에게 복약 시점을 알림하고, 해당 약을 토출하여 복약 을 유도한다(S303). 이때, 해당 사용자에게 복약 스케줄 확인을 위한 메뉴를 제공, 즉 복약을 하였는지를 묻는 확인 버튼 등을 제공 할 수 있으며, 이러한 복약 확인 버튼을 누름하도록 유도하여 복약 완료를 촉구할 수 있다(S304). 또한, 도 4 및 도 5에서와 같이 사용자에 대한 영상을 분석하여 복약 사실을 확인할 수 있으며, 복약이 완료되 면 이후의 사용자 영상을 판독 하여 이상 유무를 판단할 수 있다. 이와 같이, 인공 지능 로봇이 사용자로부터 직접 복약 스케줄을 수신하고, 그에 따라 복약 서비스를 제공함 으로써 외부의 서버와 별도로 주행 영역 내에서 개별적으로 복약 서비스가 가능하다. 이하에서는 도 7 및 도 8을 참고하여, 서버와 별도로 주행 영역 내에서의 개별적인 복약 서비스에 대하여 설 명한다. 도 7은 도 1의 인공지능 로봇의 제3 시나리오에 따른 복약 서비스 제어 방법을 도시한 순서도이다. 구체적으로, 도 6과 같이 설정된 복약 스케줄에 따라 동작이 시작되면, 인공지능 로봇은 저장부로부터 특정 사용자에 대한 복약 정보를 읽어들인다(S401). 복약 정보로는 현재 복약을 하여야 하는 스케줄 상의 복용 대상자 정보, 복약할 특정 약의 종류 및 복약 방법 등에 대한 정보를 포함할 수 있다. 인공지능 로봇의 제어부는 수신된 복약 정보에 따라 주변을 주행하면서 주변에 해당 사용자가 있는지 사용자의 얼굴을 탐색한다(S402). 즉, 제어부는 영상 획득부로부터 주변의 영상을 획득하고, 영상 데이터에서 사용자가 존재할 때, 사 용자의 외관의 특징점을 파악하여 해당 사용자의 외관의 특징점을 복용 대상자의 정보와 비교하여 발견된 사용 자가 해당하는 복용 대상자인지 판단한다. 이러한 사용자 매칭에는 SLAM 을 이용한 컴퓨터 비전 시스템이 활용 될 수 있다(S403). 해당 사용자가 복용 대상자인 것으로 판별되면, 인공지능 로봇은 서버 접속을 진행하여 해당 복용 대상자 에 대한 복약 정보를 수신한다(S404). 이때, 수신하는 복약 정보는 이전 주기의 복약 실시에 대한 정보 등을 포함할 수 있다. 다음으로 인공지능 로봇은 해당 사용자 앞으로 이동하여 해당 사용자에게 적합한 복약 시점을 알리고 그에 따라 적합한 약을 토출한다(S405). 이러한 약은 복약 정보에 따라 특정 약이 토출부를 통해 배출됨으로써 진행될 수 있다. 다음으로, 제어부는 영상 획득부로부터 카메라를 통해 추출된 영상 데이터를 수득하고 해당 영상 데 이터를 분석하여 사용자의 행동 패턴을 추출한다(S406). 이때, 추출된 현재 사용자 행동 패턴을 정의하고, 사용자에 대한 복약 정보에서 이전 복약 시의 행동 패턴을 읽 어들여 이번 행동 패턴이 이전 행동 패턴에서 벗어나는지 판단한다(S407). 이러한 행동 패턴 비교는 이전 복약 주기에서 사용자의 복약 동작의 영상들과 현재 주기에서의 사용자의 복약 동작에 대한 영상을 서로 비교함으로써 현재 주기에서 사용자가 복약을 정확하게 진행하였는지 판단할 수 있다 (S408). 사용자가 현재 주기에서 복약을 정확히 진행한 것으로 판단되면, 제어부는 카메라를 통하여 사용자에 대한 영상 데이터를 수득한다(S409). 제어부는 수득된 영상 데이터를 통해 복약 후의 사용자의 행동을 추출할 수 있다. 이때, 제어부는 사용자가 복약 후 앉거나, 쓰러지거나, 휘청거리는 등의 행동이 있는지 파악하고 이러한 패턴에 대하여 키워드와 딥러닝을 통한 분석을 진행하고 분석 결과를 저장한다(S410). 또한, 제어부는 복수의 센서부를 통해 사용자의 생체 정보를 측정하고 그에 따른 감지 신호를 수득할 수 있다(S411). 이러한 생체 정보에 대한 감지 신호는 사용자의 체온 변화, 심장 박동 등에 대한 감지 신호를 수득할 수 있다. 이때, 사용자의 행동 패턴 및 생체 정보에 대한 감지 신호는 저장부에 기록할 수 있다(S412). 제어부 는 저장부에 저장된 이번 주기의 행동 패턴 및 생체 정보에 대한 감지 신호를 다음 주기에서 비교 자 료로 활용될 수 있다. 다음으로 제어부는 사용자의 상태에 대하여 딥러닝을 통해 판단하며(S413), 이때, 사용자의 상태를 판단할 수 있을 정도로 충분한 생체 정보 측정이 이루어 졌는지 다시 판단할 수 있다(S414).충분한 생체 정보 측정이 이루어졌다고 판단되면, 인공지능 로봇은 복약에 대하여 사용자에게 이상이 있는지 최종적으로 판단한다(S415). 인공지능 로봇이 사용자에 대한 복약 이상이 있는 것으로 판단한 경우, 알람을 발생하고, 응급 처리 등을 위 한 동작을 수행한다(S416). 즉, 사용자의 복약 후 영상 데이터를 분석하고, 이를 저장한 뒤 생체 정보를 측정하였을 때, 일 예로 사용자가 주저 앉음을 영상 데이터를 통해 판단하고, 생체 정보를 통해 사용자의 체온이 갑작스럽게 상승한 것으로 판단 되면, 알람 및 응급처리 등을 필요로 하는 상황으로 판단할 수 있다. 이에 따라 인공지능 로봇은 음성 또는 사이렌 알람 등을 진행하여 주변에 해당 사용자에게 이상이 발생한 것 을 알릴 수 있다. 또한 응급 상황에 대한 연락망을 가동하여 연계되어 있는 병원 또는 응급센터 등에 도움을 요 청할 수 있다. 한편, 주변을 탐색하여 사용자가 발견되지 않으면, 주행 영역의 맵 정보를 이용하여 사용자가 있을만한 위치를 추정할 수 있다(S417). 이때, 위치 추정에 대하여는 이전 복약 정보로부터의 주요 사용자 거점을 위주로 사용자 위치를 추정할 수 있다. 인공지능 로봇은 추정된 위치로 이동하여 해당 사용자가 존재하는지 여부를 다시 탐색할 수 있다(S418). 이와 같이, 인공지능 로봇은 설정되어 있는 복약 스케줄에 따른 복약 서비스 진행 명령이 수신되면, 주변에 대한 영상 데이터를 획득하고, 이를 분석하여 사용자 판단, 복약 판단, 복약 후 사용자 상태 판단 등을 진행하 여 적극적이고 적절한 복약에 대한 대응을 수행할 수 있다. 따라서, 복약이 완벽히 진행되었는지 체크할 수 있고, 복약 후에 사용자 상태를 체크할 수 있어 부작용 등에 의 한 사용자 이상에 대하여 적극적이고 적합한 대응이 가능하다. 도 8은 도 1의 인공지능 로봇의 제4 시나리오에 따른 복약 서비스 제어 방법을 도시한 순서도이다. 인공지능 로봇이 주행부를 포함하지 않는 고정형 로봇인 경우에도, 서버와 연결됨 없이 사용자로 부터 복약 스케줄에 대한 정보를 도 6과 같이 입력 받아 해당 주행 영역 내에서 인공지능 로봇이 주체적으로 서비스를 제공할 수 있다. 동작이 시작되면, 인공지능 로봇은 사용자에 대한 복약 스케줄에 따라 복약 정보를 저장부로부터 읽어 들인다(S500). 복약 정보로는 현재 복약을 하여야 하는 스케줄 상의 복용 대상자 정보, 복약할 특정 약의 종류 및 복약 방법 등에 대한 정보를 포함할 수 있다. 인공지능 로봇의 제어부는 주변에 존재하는 사용자에게 소리 및 화면 변화 등의 알람을 수행하여 복약 주기가 도래하였음을 알린다(S501). 이때, 소리 알람은 정해진 수신음일 수 있으며, “000님, 약 드실 시간입니다.” 등의 안내 멘트일 수 있다. 이와 같은 알람에 의해 주변의 사용자가 인공지능 로봇의 카메라 앞으로 이동하면, 카메라는 상기 사용자의 영상을 촬영하여 상기 사용자가 현재 주기에서의 복용 대상자인지 판단한다(S502). 즉, 제어부는 영상 획득부로부터 주변의 영상을 획득하고, 영상 데이터에서 사용자가 존재할 때, 사 용자의 외관의 특징점을 파악하여 해당 사용자의 외관의 특징점을 복용 대상자의 정보와 비교하여 발견된 사용 자가 해당하는 복용 대상자인지 판단한다. 이러한 사용자 매칭에는 SLAM 을 이용한 컴퓨터 비전 시스템이 활용 될 수 있다. 해당 사용자가 복용 대상자인 것으로 판별되면, 인공지능 로봇은 저장부 로부터 해당 복용 대상자에 대 한 복약 정보를 수신한다(S504). 이때, 수신하는 복약 정보는 이전 주기의 복약 실시에 대한 정보 등을 포함할 수 있다. 다음으로 인공지능 로봇은 해당 사용자 앞으로 이동하여 해당 사용자에게 적합한 복약 시점을 알리고 그에 따라 적합한 약을 토출한다(S505). 다음으로, 제어부는 영상 획득부로부터 카메라를 통해 추출된 영상 데이터를 수득하고 해당 영상 데 이터를 분석하여 사용자의 행동 패턴을 추출한다(S506). 이때, 추출된 현재 사용자 행동 패턴을 정의하고, 사용 자에 대한 복약 정보에서 이전 복약 시의 행동 패턴을 읽어들여 이번 행동 패턴이 이전 행동 패턴에서 벗어나는 지 판단한다. 이러한 행동 패턴 비교는 이전 복약 주기에서 사용자의 복약 동작의 영상들과 현재 주기에서의 사용자의 복약 동작에 대한 영상을 서로 비교함으로써 현재 주기에서 사용자가 복약을 정확하게 진행하였는지 판단할 수 있다 (S507). 사용자가 현재 주기에서 복약을 정확히 진행한 것으로 판단되면(S508), 제어부는 카메라를 통하여 사용자 에 대한 영상 데이터를 수득한다(S509). 제어부는 수득된 영상 데이터를 통해 복약 후의 사용자의 행동을 추출할 수 있다. 이때, 제어부는 사용자가 복약 후 앉거나, 쓰러지거나, 휘청거리는 등의 행동이 있는지 파악하고 이러한 패턴에 대하여 키워드와 딥러닝을 통한 분석을 진행하고 분석 결과를 저장한다(S510). 또한, 제어부는 복수의 센서부를 통해 사용자의 생체 정보를 측정하고 그에 따른 감지 신호를 수득할 수 있다(S511). 이러한 생체 정보에 대한 감지 신호는 사용자의 체온 변화, 심장 박동 등에 대한 감지 신호를 수득할 수 있다. 이때, 사용자의 행동 패턴 및 생체 정보에 대한 감지 신호는 저장부에 기록할 수 있다(S512). 제어부 는 저장부에 저장된 이번 주기의 행동 패턴 및 생체 정보에 대한 감지 신호를 다음 주기에서 비교 자 료로 활용될 수 있다. 다음으로 제어부는 사용자의 상태에 대하여 딥러닝을 통해 판단하며(S513), 이때, 사용자의 상태를 판단할 수 있을 정도로 충분한 생체 정보 측정이 이루어 졌는지 다시 판단할 수 있다(S514). 충분한 생체 정보 측정이 이루어졌다고 판단되면, 인공지능 로봇은 복약에 대하여 사용자에게 이상이 있는지 최종적으로 판단한다(S515). 인공지능 로봇이 사용자에 대한 복약 이상이 있는 것으로 판단한 경우, 알람을 발생하고, 응급 처리 등을 위 한 동작을 수행한다(S516). 즉, 사용자의 복약 후 영상 데이터를 분석하고, 이를 저장한 뒤 생체 정보를 측정하였을 때, 일 예로 사용자가 주저 앉음을 영상 데이터를 통해 판단하고, 생체 정보를 통해 사용자의 체온이 갑작스럽게 상승한 것으로 판단 되면, 알람 및 응급처리 등을 필요로 하는 상황으로 판단할 수 있다. 이에 따라 인공지능 로봇은 음성 또는 사이렌 알람 등을 진행하여 주변에 해당 사용자에게 이상이 발생한 것 을 알릴 수 있다. 또한 응급 상황에 대한 연락망을 가동하여 연계되어 있는 병원 또는 응급센터 등에 도움을 요 청할 수 있다. 한편, 본 발명의 다른 실시예에 따른 복약 서비스를 제공하는 인공지능 로봇 시스템을 설명한다. 도 9는 본 발명의 다른 실시예에 따른 인공지능 로봇 시스템의 구성도이고, 도 10은 도 9의 홈로봇을 바라 본 도면이다. 도 9 및 도 10을 참고하면, 본 발명의 다른 실시예에 따른 로봇시스템은, 하나 이상의 로봇을 구비하여 집 등의 규정된 장소에서 서비스를 제공할 수 있다. 예를 들어, 로봇 시스템은 가정 등에서 사용자와 인터랙션 (interaction)하며, 사용자에게 다양한 엔터테이징을 제공하는 홈 로봇을 포함할 수 있다. 또한 이러한 홈 로봇이 사용자에 대한 투약 스케줄에 따라 사용자를 판별하고, 해당 사용자에 대한 약을 토출하고, 사용자 의 약 복용 여부를 판단 및 복용 후 반응을 판단하여 그에 따른 조치가 가능할 수 있다. 바람직하게는, 본 발명의 일 실시예에 따른 로봇 시스템은, 복수의 인공지능 로봇 및 복수의 인공지능 로 봇을 관리하고 제어할 수 있는 서버를 포함할 수 있다. 복수의 로봇 및 서버는 하나 이상의 통신 규격을 지원하는 통신 수단(미도시)을 구비하여, 상호 통신할 수 있다. 또한, 복수의 로봇 및 서버는 PC, 이동 단말기, 외부의 다른 서버와 통신할 수 있다. 예를 들어, 복수의 로봇 및 서버는 IEEE 802.11 WLAN, IEEE 802.15 WPAN, UWB, Wi-Fi, Zigbee, Z- wave, Blue-Tooth 등과 같은 무선 통신 기술로 무선 통신하게 구현될 수 있다. 로봇은 통신하고자 하는 다 른 장치 또는 서버의 통신 방식이 무엇인지에 따라 달라질 수 있다. 특히, 복수의 로봇은 5G 네트워크를 통해 다른 로봇 및/또는 서버와 무선통신을 구현할 수 있다. 로봇이 5G 네트워크를 통해 무선 통신하는 경우, 실시간 응답 및 실시간 제어가 가능하다. 사용자는 PC, 이동 단말기 등의 사용자 단말을 통하여 로봇 시스템 내의 로봇들에 관한 정보를 확인하 거나 제어할 수 있다. 서버는 클라우드(cloud) 서버로 구현되어, 사용자는 사용자 단말기가 통신 연결된 서버에 저장된 데이터와 서버가 제공하는 기능, 서비스를 이용할 수 있다. 로봇에 클라우드 서버가 연동되어 로봇 을 모니터링, 제어하고 다양한 솔루션과 콘텐츠를 원격으로 제공할 수 있다. 서버는, 로봇, 기타 기기로부터 수신되는 정보를 저장 및 관리할 수 있다. 상기 서버는 로봇의 제조사 또는 제조사가 서비스를 위탁한 회사가 제공하는 서버일 수 있다. 상기 서버는 로봇을 관리 하고 제어하는 관제 서버일 수 있다. 상기 서버는 로봇을 일괄적으로 동일하게 제어하거나, 개별 로봇 별로 제어할 수 있다. 도 1에서 설명한 바와 같이 로봇 및 서버는 사용자, 음성, 공간의 속성, 장애물 등 사물의 속성 중 적 어도 하나를 인식하도록 학습된 소프트웨어 또는 하드웨어 형태의 인공신경망(Artificial Neural Networks: ANN)을 포함할 수 있다. 본 발명의 일 실시예에 따르면, 로봇 및 서버는 딥러닝(Deep Learning)으로 학습된 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network) 등 심층신경망(Deep Neural Network: DNN)을 포함할 수 있다. 예를 들어, 로봇의 제어부에는 CNN(Convolutional Neural Network) 등 심층신경망 구조(DNN)가 탑재될 수 있다. 서버는 로봇으로부터 수신한 데이터, 사용자에 의해 입력되는 데이터 등에 기초하여, 심층신경망(DNN) 을 학습시킨 후, 업데이트된 심층신경망(DNN) 구조 데이터를 로봇으로 전송할 수 있다. 이에 따라, 로봇 이 구비하는 인공지능(artificial intelligence)의 심층신경망(DNN) 구조를 업데이트할 수 있다. 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력받고, 입력 데이터에 포함된 사람, 사물, 공간의 속 성을 인식하여, 그 결과를 출력할 수 있다. 또한, 상기 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력받고, 로봇의 사용(Usage) 관련 데 이터(Data)를 분석하고 학습하여 사용 패턴, 사용 환경 등을 인식할 수 있다. 서버는 수신한 데이터에 기초하여, 심층신경망(DNN)을 학습시킨 후, 업데이트된 심층신경망(DNN) 구조 데이 터를 인공지능 로봇으로 전송하여 업데이트하게 할 수 있다. 이에 따라, 로봇이 점점 스마트하게 되며, 사용할수록 진화되는 사용자 경험(UX)을 제공할 수 있다. 홈로봇 및 서버는 외부 정보(external information)도 이용할 수 있다. 예를 들어, 서버가 다른 연 계 서비스 서버(도시하지 않음)로부터 획득한 외부 정보를 종합적으로 사용하여 우수한 사용자 경험을 제공 할 수 있다. 또한, 본 발명에 따르면, 로봇이 능동적으로 먼저 정보를 제공하거나 기능, 서비스를 추천하는 음성을 출 력함으로써 사용자에게 더욱 다양하고 적극적인 제어 기능을 제공할 수 있다. 도 10는 사용자에게 복약 서비스를 제공할 수 있는 홈 로봇의 외관을 도시하는 정면도이다. 도 10을 참조하면, 홈 로봇은, 외관을 형성하고 그 내부에 각종 부품을 수납하는 본체(111b, 112b)를 포함 한다. 본체(111b, 112b)는 홈 로봇을 구성하는 각종 부품들이 수용되는 공간을 형성하는 바디(body, 111b)와 상 기 바디(111b)의 하측에 배치되어 상기 바디(111b)를 지지하는 지지부(112b)를 포함할 수 있다. 이러한 본체 내에는 약품을 수납할 수 있는 수용부가 형성될 수 있다. 또한, 본체의 외면으로 수용되어 있는 약품을 주입 및/또는 토출할 수 있는 입출입구가 형성될 수 있다. 또한, 홈 로봇은 본체(111b, 112b)의 상측에 배치되는 헤드(head, 110b)를 포함할 수 있다. 헤드(110b)의 전면에는 영상을 표시할 수 있는 디스플레이(182b)가 배치될 수 있다.본 명세서에서 전면 방향은 +y 축 방향을 의미하고, 상하 방향은 z축 방향, 좌우 방향은 x축 방향을 의미할 수 있다. 상기 헤드(110b)는 x축을 중심으로 소정 각도 범위 내에서 회전할 수 있다. 이에 따라, 전면에서 봤을 때, 상기 헤드(110b)는 사람이 고개를 상하 방향으로 끄덕거리는 것처럼 상하 방향으 로 움직이는 노딩(Nodding) 동작이 가능하다. 예를 들어, 상기 헤드(110b)는 사람이 머리를 상하 방향으로 끄덕 거리는 것처럼 소정 범위 내에서 회전 후 원위치 복귀 동작을 1회 이상 수행할 수 있다. 한편, 실시예에 따라서는, 헤드(100b) 중 사람의 안면에 대응할 수 있는 디스플레이(182b)가 배치되는 전면 중 적어도 일부가 노딩되도록 구현될 수 있다. 따라서, 상기 헤드(110b) 전체가 상하 방향으로 움직이는 실시예를 중심으로 기술하지만, 특별히 설명하지 않는 한, 헤드(110b)가 상하 방향으로 노딩(Nodding)하는 동작은, 디스플레이가 배치되는 전면 중 적어도 일부 가 상하 방향으로 노딩하는 동작으로 대체 가능할 것이다. 상기 바디(111b)는 좌우 방향으로 회전 가능하도록 구성될 수 있다. 즉, 상기 바디(111b)는 z축을 중심으로 360 도 회전 가능하도록 구성될 수 있다. 또한, 실시예에 따라서는, 상기 바디(111b)도 x축을 중심으로 소정 각도 범위 내에서 회전가능하게 구성됨으로 써, 상하 방향으로도 끄덕거리는 것처럼 움직일 수 있다. 이 경우에, 상기 바디(111b)가 상하 방향으로 회전함 에 따라, 상기 바디(111b)가 회전하는 축을 중심으로 상기 헤드(110b)도 함께 회전할 수 있다. 한편, 홈 로봇은 본체(111b, 112b) 주변, 적어도 본체(111b, 112b) 전면을 중심으로 소정 범위를 촬영할 수 있는 영상 획득부를 포함할 수 있다. 영상 획득부는 본체(111b, 112b) 주변, 외부 환경 등을 촬영하는 것으로, 카메라 모듈을 포함할 수 있다. 이러한 카메라는 촬영 효율을 위해 각 부위별로 여러 개가 설치될 수도 있다. 바람직하게, 영상 획득부는, 본체(111b, 112b) 전면의 영상을 획득하도록 헤드(110b)의 전면에 구비되는 전면 카메라를 포함할 수 있다. 또한, 홈 로봇은 사용자의 음성 입력을 수신하는 음성 입력부를 포함할 수 있다. 음성 입력부는 아날로그 소리를 디지털 데이터로 변환하는 처리부를 포함하거나 처리부에 연결되어 사용자 입력 음성 신호를 서버 또는 제어부에서 인식할 수 있도록 데이터화할 수 있다. 음성 입력부는 사용자 음성 입력 수신의 정확도를 높이고, 사용자의 위치를 판별하기 위해, 복수의 마이크 를 포함할 수 있다. 예를 들어, 음성 입력부는 적어도 2이상의 마이크를 포함할 수 있다. 복수의 마이크(MIC)는, 서로 다른 위치에 이격되어 배치될 수 있고, 음성 신호를 포함한 외부의 오디오 신호를 획득하여 전기적인 신호로 처리할 수 있다. 한편, 입력 장치인 마이크는 음향을 발생시킨 음원, 사용자의 방향 추정을 위하여 최소 2개가 필요하며, 마이크 사이의 간격은 물리적으로 멀리 떨어져 있을수록 방향 검출의 해상도(각도)가 높다. 실시예에 따라서는 2개의 마이크가 상기 헤드(110b)에 배치될 수 있다. 또한, 상기 헤드(110b)의 후면에 2개의 마이크를 더 포함함으로써, 사용자의 3차원 공간상의 위치를 판별할 수 있다. 또한, 음향 출력부가 헤드(110b)의 좌우측면에 배치되어, 소정 정보를 음향으로 출력할 수 있다. 한편, 도 10에 예시된 로봇의 외관 및 구조는 예시적인 것으로 본 발명은 이에 한정되지 않는다. 예를 들 어, 도 10에서 예시된 로봇의 회전 방향과 달리 로봇 전체가 특정 방향으로 기울어지거나 흔들리는 동작도 가능하다. 도 11은 도 10의 홈 로봇의 복약 서비스 제어 방법을 나타내는 순서도이다. 먼저, 홈 로봇은 일반적인 홈 로봇으로서 기능을 수행한다. 즉, 일반모드로서, 사용자에게 엔터테이닝 기능을 제공할 수 있으며, 일 예로, 음악, 날씨, 기사, 홈 어플라이 언스 서비스 및/또는 대화 모드를 구현할 수 있다(S600). 이때, 상기 서버로부터 복약 스케줄에 따라 복약 명령이 수신되면(S601), 홈 로봇은 일반모드에서 헬스케 어 모드로 전환된다. 즉, 홈 로봇은 서버로부터 특정 사용자에 대한 복약 스케줄에 따라 복약 명령 및 복약 정보를 전송받는 다(S602). 복약 정보로는 현재 복약을 하여야 하는 스케줄 상의 복용 대상자 정보, 복약할 특정 약의 종류 및 복약 방법 등에 대한 정보를 포함할 수 있다. 홈 로봇의 제어부는 수신된 복약 정보에 따라 주변을 주행하면서 주변에 해당 사용자가 있는지 사용 자의 얼굴을 탐색한다(S603). 즉, 제어부는 영상 획득부로부터 주변의 영상을 획득하고, 영상 데이터 에서 사용자가 존재할 때, 사용자의 외관의 특징점을 파악하여 해당 사용자의 외관의 특징점을 복용 대상자의 정보와 비교하여 발견된 사용자가 해당하는 복용 대상자인지 판단한다. 해당 사용자가 복용 대상자인 것으로 판별되면, 홈 로봇은 서버 접속을 진행하여 해당 복용 대상자에 대 한 복약 정보를 수신한다. 이때, 수신하는 복약 정보는 이전 주기의 복약 실시에 대한 정보 등을 포함할 수 있 다. 홈 로봇은 해당 사용자 앞으로 이동하여 해당 사용자에게 적합한 복약 시점을 알리고 그에 따라 적합 한 약을 토출한다. 제어부는 영상 획득부로부터 카메라를 통해 추출된 영상 데이터를 수득하고 해당 영상 데이터를 분석하여 사용자의 행동 패턴을 추출한다(S604). 이때, 추출된 현재 사용자 행동 패턴을 정의하고, 사용자에 대한 복약 정보에서 이전 복약 시의 행동 패턴을 읽 어들여 이번 행동 패턴이 이전 행동 패턴에서 벗어나는지 판단한다. 이러한 행동 패턴 비교는 이전 복약 주기에서 사용자의 복약 동작의 영상들과 현재 주기에서의 사용자의 복약 동작에 대한 영상을 서로 비교함으로써 현재 주기에서 사용자가 복약을 정확하게 진행하였는지 판단할 수 있다 (S605). 사용자가 현재 주기에서 복약을 정확히 진행한 것으로 판단되면, 제어부는 카메라를 통하여 사용자에 대한 영상 데이터를 수득한다. 제어부는 수득된 영상 데이터를 통해 복약 후의 사용자의 행동을 추출할 수 있다 (S606). 이때, 제어부는 사용자가 복약 후 앉거나, 쓰러지거나, 휘청거리는 등의 행동이 있는지 파악하고 이러한 패턴에 대하여 키워드와 딥러닝을 통한 분석을 진행하고 분석 결과를 저장한다. 또한, 제어부는 복수의 센서부를 통해 사용자의 생체 정보를 측정하고 그에 따른 감지 신호를 수득할 수 있다. 이러한 생체 정보에 대한 감지 신호는 사용자의 체온 변화, 심장 박동 등에 대한 감지 신호를 수득할 수 있다. 이때, 사용자의 행동 패턴 및 생체 정보에 대한 감지 신호는 서버로 전송할 수 있다. 이때, 서버는 수신 된 정보를 데이터 베이스에 저장하여 다음 주기에서 비교 자료로 활용될 수 있고, 수신된 정보를 기초로 사용자 의 복약 후 상태를 판단하여 그에 따른 명령을 홈 로봇에 전송할 수 있다. 다음으로 홈 로봇이 서버로부터 원격으로 사용자의 상태에 대한 판단 결과를 수신하거나 추가 정보 요 청을 수신하면, 홈 로봇은 사용자에 대하여 추가 정보를 제공할 수 있는지 판단할 수 있다. 즉, 사용자의 상태를 판단할 수 있을 정도로 충분한 생체 정보 측정이 이루어 졌는지 다시 판단할 수 있다. 충분한 생체 정보 측정이 이루어졌다고 판단되면(S607), 홈 로봇은 서버로부터 원격으로 복약에 대하여 이상이 있는 것으로 판단된 것인지 판단한다. 홈 로봇이 서버로부터 사용자에 대한 복약 이상이 있는 것으로 명령을 수신한 경우, 알람을 발생하고, 응급 처리 등을 위한 동작을 수행한다(S608). 즉, 사용자의 복약 후 영상 데이터를 분석하고, 이를 저장한 뒤 서버로 전송하고, 생체 정보를 측정하고 그 에 따른 정보를 서버로 전달했을 때, 일 예로 사용자가 주저 앉음을 영상데이터를 통해 판단하고, 생체 정보 를 통해 사용자의 체온이 갑작스럽게 상승한 것으로 판단되면, 서버는 이에 대하여 알람 및 응급처리 등을 필요로 하는 상황으로 판단하여 그에 대한 결과를 전송할 수 있다. 이에 따라 홈 로봇은 음성 또는 사이렌 알람 등을 진행하여 주변에 해당 사용자에게 이상이 발생한 것을 알 릴 수 있다. 또한 응급 상황에 대한 연락망을 가동하여 연계되어 있는 병원 또는 응급센터 등에 도움을 요청할 수 있다. 홈 로봇은 복약 이상이 없는 것으로 판단되면, 헬스케어 모드를 종료하고 다시 홈 로봇의 일반모드로 전환된다(S609). 본 발명에 따른 로봇 시스템은 상기한 바와 같이 설명된 실시예들의 구성과 방법이 한정되게 적용될 수 있는 것 이 아니라, 상기 실시예들은 다양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또는 일부가 선택적으로 조 합되어 구성될 수도 있다. 한편, 본 발명의 실시예에 따른 로봇 시스템의 제어 방법은, 프로세서가 읽을 수 있는 기록매체에 프로세서 가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 프로세서가 읽을 수 있는 기록매체는 프로세서에 의해 읽혀 질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 프로세서가 읽을 수 있는 기록매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있으며, 또한, 인터넷을 통한 전송 등 과 같은 캐리어 웨이브의 형태로 구현되는 것도 포함한다. 또한, 프로세서가 읽을 수 있는 기록매체는 네트워크 로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 프로세서가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2019-0106848", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2019-0106848", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능 로봇 시스템의 구성도이다. 도 2는 도 1의 인공지능 로봇을 바라본 입면도이다. 도 3은 도 1의 인공지능 로봇의 제어 관계를 나타낸 블록도이다. 도 4는 도 1의 인공지능 로봇의 제1 시나리오에 따른 복약 서비스 제어 방법을 도시한 순서도이다. 도 5는 도 1의 인공지능 로봇의 제2 시나리오에 따른 복약 서비스 제어 방법을 도시한 순서도이다. 도 6은 도 1의 인공지능 로봇의 복약 정보 입력에 대한 시나리오를 도시한 순서도이다. 도 7은 도 1의 인공지능 로봇의 제3 시나리오에 따른 복약 서비스 제어 방법을 도시한 순서도이다. 도 8은 도 1의 인공지능 로봇의 제4 시나리오에 따른 복약 서비스 제어 방법을 도시한 순서도이다. 도 9는 본 발명의 다른 실시예에 따른 인공지능 로봇 시스템의 구성도이다. 도 10은 도 9의 홈로봇을 바라본 도면이다. 도 11은 도 10의 홈로봇의 복약 서비스 제어 방법을 나타내는 순서도이다."}
