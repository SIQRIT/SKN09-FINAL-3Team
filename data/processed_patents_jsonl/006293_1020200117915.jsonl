{"patent_id": "10-2020-0117915", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0035767", "출원번호": "10-2020-0117915", "발명의 명칭": "전자 장치 및 이의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "김현준"}}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 제어 방법에 있어서, 제1 공간에 위치하는 제1 로봇을 제어하기 위한 UI를 표시하는 단계;사용자 조작 명령에 기초하여 상기 제1 로봇을 제어하기 위한 제어 명령을 상기 제1 로봇에 전송하는 단계;상기 제1 로봇이 상기 제1 공간과 다른 제2 공간으로 이동하기 어려우면, 상기 제2 공간에 위치하는 제2 로봇을확인하는 단계; 및상기 확인된 제2 로봇을 제어하기 위한 UI를 표시하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 확인된 제2 로봇이 상기 제1 로봇과 인접한 영역으로 이동하도록 하는 제어 명령을 상기 제2 로봇에 전송하는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제2 로봇이 상기 제1 로봇과 인접한 영역으로 이동하면, 상기 제2 로봇으로부터 상기 제2 로봇이 촬상한제2 이미지를 수신하는 단계;를 더 포함하고,상기 제2 로봇을 제어하기 위한 UI를 표시하는 단계는,상기 수신된 제2 이미지를 포함하는 UI를 표시하는 단계를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 로봇으로부터 상기 제1 로봇이 촬상한 제1 이미지를 수신하는 단계;를 더 포함하고,상기 제1 로봇을 제어하기 위한 UI를 표시하는 단계는,상기 수신된 제1 이미지를 포함하는 UI를 표시하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제1 로봇을 제어하는 위한 UI를 표시하는 단계는,상기 제1 로봇이 상기 제1 공간에서 상기 제2 공간을 향해 이동하면서 촬상한 제1 이미지를 수신하고, 상기 수신된 제1 이미지를 포함하는 UI를 표시하는 단계;를 포함하고, 상기 촬상된 제1 이미지에서 장애물을 식별하는 단계; 및상기 식별된 장애물이 화면의 기설정된 영역에 표시되는 경우, 상기 제1 로봇이 상기 제2 공간으로 이동하기 어려운 것으로 결정하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 로봇으로부터 상기 제1 로봇이 상기 제1 공간에서 제2공간으로 이동하면서 식별한 장애물에 관한 정보공개특허 10-2022-0035767-3-를 수신하는 단계;를 더 포함하고, 상기 확인하는 단계는,상기 수신된 정보를 기초로 상기 제1 로봇이 상기 제2 공간으로 이동하기 어려운 것으로 확인되면, 상기 제2 공간에 로봇이 존재하는지 확인하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제2 공간에 로봇이 존재하지 않는 것으로 확인되면, 서버에 상기 제2 공간과 연결된 제3 공간에 대한 정보를 요청하는 단계; 상기 서버로부터 수신한 정보를 기초로 상기 제3 공간에 위치하는 제3 로봇이 상기 제2 공간으로 이동할 수 있는지 확인하는 단계;상기 제3 로봇이 상기 제2 공간으로 이동가능 한 경우, 상기 제3 로봇을 제어하기 위한 UI를 표시하는 단계;를더 포함하는 제어 방법."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 제2 로봇을 확인하는 단계는,상기 제1 로봇이 상기 제1 공간에서 상기 제2 공간으로 이동하기 어려우면, 서버에 상기 제2 공간에 위치하는로봇의 정보를 요청하는 단계; 및상기 서버로부터 상기 제2 공간에 위치하는 제2 로봇의 정보를 수신하는 단계; 를 포함하고,상기 제2 로봇에 관한 정보는,상기 제2 로봇의 이미지, 제2 로봇의 종류, 식별 정보, 위치 정보, 배터리 정보 및 이동 가능한 영역에 관한 정보 중 적어도 하나를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제2 로봇을 제어하기 위한 UI를 표시하는 단계는,상기 제2 로봇의 정보를 수신하면, 상기 수신된 제2 로봇의 정보를 표시하는 단계;상기 표시된 제2 로봇의 정보를 선택하는 사용자 입력을 수신하면, 상기 제2 로봇에서 촬상된 제2 이미지를 표시하는 단계; 및상기 제2 로봇의 위치 또는 방향을 제어하기 위한 UI를 표시하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 확인된 제2 로봇에 제어 권한을 요청하는 단계; 및상기 제2 로봇으로부터 제어 권한 승인 메시지를 수신하면, 상기 제1 로봇이 기설정된 위치로 이동하도록 하는제어 명령을 상기 제1 로봇에 전송하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치에 있어서,통신 인터페이스;공개특허 10-2022-0035767-4-디스플레이; 및제1 공간에 위치하는 제1 로봇을 제어하기 위한 UI를 표시하도록 상기 디스플레이를 제어하고,사용자 조작 명령에 기초하여 상기 제1 로봇을 제어하기 위한 제어 명령을 상기 제1 로봇에 전송하도록 상기 통신 인터페이스를 제어하고,상기 제1 로봇이 상기 제1 공간과 다른 제2 공간으로 이동하기 어려우면, 상기 제2 공간에 위치하는 제2 로봇을확인하고,상기 확인된 제2 로봇을 제어하기 위한 UI를 표시하도록 상기 디스플레이를 제어하는 프로세서;를 포함하는, 전자 장치."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는,상기 확인된 제2 로봇이 상기 제1 로봇과 인접한 영역으로 이동하도록 하는 제어 명령을 상기 제2 로봇에 전송하도록 상기 통신 인터페이스를 제어하는, 전자 장치."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 프로세서는,상기 제2 로봇이 상기 제1 로봇과 인접한 영역으로 이동하면, 상기 제2 로봇으로부터 상기 제2 로봇이 촬상한제2 이미지를 수신하고,상기 수신된 제2 이미지를 포함하는 UI를 표시하도록 상기 디스플레이를 제어하는, 전자 장치."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 프로세서는,상기 제1 로봇으로부터 상기 제1 로봇이 촬상한 제1 이미지를 수신하고,상기 수신된 제1 이미지를 포함하는 UI를 표시하도록 상기 디스플레이를 제어하는, 전자 장치."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 프로세서는,상기 제1 로봇이 상기 제1 공간에서 상기 제2 공간을 향해 이동하면서 촬상한 제1 이미지를 수신하고, 상기 수신된 제1 이미지를 포함하는 UI를 표시하도록 상기 디스플레이를 제어하고, 상기 촬상된 제1 이미지에서 장애물을 식별하고, 상기 식별된 장애물이 화면의 기설정된 영역에 표시되는 경우, 상기 제1 로봇이 상기 제2 공간으로 이동하기 어려운 것으로 결정하는, 전자 장치."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 프로세서는,상기 제1 로봇으로부터 상기 제1 로봇이 상기 제1 공간에서 제2공간으로 이동하면서 식별한 장애물에 관한 정보공개특허 10-2022-0035767-5-를 수신하고,상기 수신된 정보를 기초로 상기 제1 로봇이 상기 제2 공간으로 이동하기 어려운 것으로 확인되면, 상기 제2 공간에 로봇이 존재하는지 확인하는, 전자 장치."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 프로세서는,상기 제1 로봇이 상기 제1 공간에서 상기 제2 공간으로 이동하기 어려우면, 서버에 상기 제2 공간에 위치하는로봇의 정보를 요청하고,상기 서버로부터 상기 제2 공간에 위치하는 제2 로봇의 정보를 수신하고,상기 제2 로봇에 관한 정보는,상기 제2 로봇의 이미지, 제2 로봇의 종류, 식별 정보, 위치 정보, 배터리 정보 및 이동 가능한 영역에 관한 정보 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 프로세서는,상기 제2 로봇의 정보를 수신하면, 상기 수신된 제2 로봇의 정보를 표시하고, 상기 표시된 제2 로봇의 정보를 선택하는 사용자 입력을 수신하면, 상기 제2 로봇에서 촬상된 제2 이미지를 포함하는 UI 및 상기 제2 로봇의 위치 또는 방향을 제어하기 위한 UI를 표시하도록 상기 디스플레이를 제어하는,전자 장치."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 프로세서는,상기 확인된 제2 로봇에 제어 권한을 요청하고,상기 제2 로봇으로부터 제어 권한 승인 메시지를 수신하면, 상기 제1 로봇이 기설정된 위치로 이동하도록 하는제어 명령을 상기 제1 로봇에 전송하도록 상기 통신 인터페이스를 제어하는, 전자 장치."}
{"patent_id": "10-2020-0117915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "전자 장치의 제어 방법을 실행하기 위한 프로그램을 포함하는 컴퓨터 판독 가능 기록 매체에 있어서,상기 제어 방법은,제1 공간에 위치하는 제1 로봇을 제어하기 위한 UI를 표시하는 단계;사용자 조작 명령에 기초하여 상기 제1 로봇을 제어하기 위한 제어 명령을 상기 제1 로봇에 전송하는 단계;상기 제1 로봇이 상기 제1 공간과 다른 제2 공간으로 이동하기 어려우면, 상기 제2 공간에 위치하는 제2 로봇을확인하는 단계; 및상기 확인된 제2 로봇을 제어하기 위한 UI를 표시하는 단계;를 포함하는 기록 매체."}
{"patent_id": "10-2020-0117915", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치의 제어 방법이 개시된다. 본 개시에 따른 전자 장치의 제어 방법은 제1 공간에 위치하는 제1 로봇을 제어하기 위한 UI를 표시하는 단계, 사용자 조작 명령에 기초하여 제1 로봇을 제어하기 위한 제어 명령을 제1 로 봇에 전송하는 단계, 제1 로봇이 제1 공간과 다른 제2 공간으로 이동하기 어려우면, 제2 공간에 위치하는 제2 로 봇을 확인하는 단계 및 확인된 제2 로봇을 제어하기 위한 UI를 표시하는 단계를 포함한다."}
{"patent_id": "10-2020-0117915", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 이의 제어 방법으로, 더욱 상세하게는 로봇을 제어하는 전자 장치 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0117915", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇 관련 기술이 발전하면서 다양한 로봇이 등장하고 있으며, 로봇을 이용한 서비스도 등장하고 있다. 가령, 사용자는 박물관, 쇼핑 센터와 같은 장소를 직접 방문하지 않더라도 박물관, 미술관, 쇼핑 센터에 존재하는 로 봇의 비전 기술을 이용하여 박물관, 미술관의 작품을 감상하거나, 쇼핑 센터에 존재하는 물건을 보고 구입하면 서 박물관, 미술관, 쇼핑 센터와 같은 장소를 직접 방문한 것과 동일한 효과를 누릴 수 있다. 이외에도 사람이 직접 들어가기 위험한 공사 현장이나 작업 현장에서 로봇을 사용함으로써 사용자는 원하는 작 업을 수행할 수 있다. 한편, 이와 같은 로봇의 경우, 사용자 제어에 따른 이동이 용이해야 하기 때문에 계단, 에스컬레이터와 같은 장 애물을 통과할 수 있는 로봇으로 제작되는 경우가 많다. 그러나, 장애물을 통과하는 로봇의 경우, 로봇의 관절을 위한 장치, 로봇의 평행 유지를 위한 장치와 같은 복잡 한 기술을 요하는 장치를 필요로 한다는 점에서 비용이 비싸고, 로봇이 장애물을 통과하는 과정에서 전복될 가 능성이 있다는 단점이 존재한다."}
{"patent_id": "10-2020-0117915", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점을 해결하기 위한 것으로, 복수의 로봇을 제어하는 UI를 제공하여, 로봇이 이동하지 못 하는 상황에서도 사용자가 끊김없이 서비스를 제공받도록 하는 전자 장치 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0117915", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 제1 공간에 위치하는 제1 로봇을 제어하기 위한 UI를 표시하는 단계, 사용자 조작 명령에 기초하여 상기 제1 로봇을 제어하기 위한 제어 명령을 상기 제1 로봇에 전 송하는 단계, 상기 제1 로봇이 상기 제1 공간과 다른 제2 공간으로 이동하기 어려우면, 상기 제2 공간에 위치하 는 제2 로봇을 확인하는 단계 및 상기 확인된 제2 로봇을 제어하기 위한 UI를 표시하는 단계를 포함한다. 한편, 본 개시의 다른 일 실시 예에 따른 전자 장치는, 통신 인터페이스, 디스플레이 및 제1 공간에 위치하는 제1 로봇을 제어하기 위한 UI를 표시하도록 상기 디스플레이를 제어하고, 사용자 조작 명령에 기초하여 상기 제 1 로봇을 제어하기 위한 제어 명령을 상기 제1 로봇에 전송하도록 상기 통신 인터페이스를 제어하고, 상기 제1 로봇이 상기 제1 공간과 다른 제2 공간으로 이동하기 어려우면, 상기 제2 공간에 위치하는 제2 로봇을 확인하고, 상기 확인된 제2 로봇을 제어하기 위한 UI를 표시하도록 상기 디스플레이를 제어하는 프로세서를 포 함한다."}
{"patent_id": "10-2020-0117915", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 문서의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 문서에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 문서의 실시 예의 다양한 변경(modifications), 균등물 (equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 문서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 문서에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 문서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 예를 들면, 제1 사용자 기기와 제2 사용자 기기는, 순서 또는 중요도와 무관하게, 서로 다른 사용자 기기를 나타낼 수 있다. 예를 들면, 본 문서에 기재된 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 바꾸어 명명될 수 있다. 본 문서에서 사용된 \"모듈\", \"유닛\", \"부(part)\" 등과 같은 용어는 적어도 하나의 기능이나 동작을 수행하는 구 성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 및 소 프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\", \"유닛\", \"부(part)\" 등은 각각이 개별적인 특정한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나의 프로세서로 구현될 수 있다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 문서에서 사용된 용어들은 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다른 실시 예의 범위를 한 정하려는 의도가 아닐 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 문서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 문서에 사용된 용어 들 중 일반적인 사전에 정의된 용어들은, 관련 기술의 문맥상 가지는 의미와 동일 또는 유사한 의미로 해석될 수 있으며, 본 문서에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 경우에 따라서, 본 문서에서 정의된 용어일지라도 본 문서의 실시 예들을 배제하도록 해석될 수 없다. 한편, 본 개시에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지 능 전자 장치)를 지칭할 수 있다. 이하에서는 도면을 참조하여 본 개시에 대해 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시 예에 따른 시스템을 설명하기 위한 도면이다. 도 1에 도시된 바와 같이 본 개시의 일 실시 예에 따른 시스템은 전자 장치, 제1 로봇(200-1), 제2 로봇(200-2) 및 서버를 포함한다. 도 1에서는 제1 로봇(200-1) 및 제2 로봇(200-2), 두 개의 로봇만이 도 시되었으나, 시스템은 N개의 로봇을 포함할 수 있다. 전자 장치는 제1 로봇(200-1), 제2 로봇(200-2) 및 서버와 통신을 수행할 수 있다. 도 1에서 전자 장치는 스마트폰으로 도시되었으나, 본 개시의 다양한 실시 예들에 따른 전자 장치는 태블릿 PC, 휴대폰, TV, 전자 칠판, 모니터, 랩탑 PC, 카메라 또는 웨어러블 장치(가령, 시계, 안경, 머리 착용 형 장치(Head-mounted-device)(HMD))를 포함할 수 있다. 한편, 전자 장치는 반드시 이에 한하는 것은 아 니며, 디스플레이를 포함하면서 외부 장치와 통신을 수행할 수 있는 장치라면 본 개시의 전자 장치가 될 수 있다. 전자 장치는 제1 로봇(200-1) 또는 제2 로봇(200-2)을 제어할 수 있다. 구체적으로, 전자 장치는 제1 로봇(200-1) 또는 제2 로봇(200-2)에 제어 명령을 전송할 수 있다. 이를 위하여 전자 장치는 제1 로봇 (200-1) 또는 제2 로봇(200-2)을 제어하기 위한 UI(User Interface)를 표시할 수 있다. 전자 장치는 제1 로봇(200-1) 또는 제2 로봇(200-2)이 특정 공간을 이동하면서 특정 공간의 이미지를 촬상 하도록 제어할 수 있다. 그리고, 전자 장치는 제1 로봇(200-1) 또는 제2 로봇(200-2)이 촬상한 이미지를 제1 로봇(200-1) 또는 제2 로봇(200-2)로부터 수신하여 표시할 수 있다. 이에 따라, 전자 장치는 제1 로 봇(200-1) 또는 제2 로봇(200-2)이 위치하는 공간에 존재하지 않더라도, 제1 로봇(200-1) 또는 제2 로봇(200- 2)를 통하여 제1 로봇(200-1) 또는 제2 로봇(200-2)가 위치하는 특정 공간의 이미지를 표시할 수 있다. 제1 로봇(200-1) 또는 제2 로봇(200-2)는 동일한 공간에 존재할 수 있으나, 서로 다른 공간에 존재할 수도 있다. 가령, 제1 로봇(200-1)이 이동하지 못하는 공간에 제2 로봇(200-2)이 존재할 수 있다. 제1 로봇(200-1) 또는 제2 로봇(200-2)은 전자 장치로부터 수신한 제어 명령에 따라 동작할 수 있다. 제1 로봇(200-1) 또는 제2 로봇(200-2)은 제어 명령에 따라 특정 공간을 이동하거나, 특정 공간의 이미지를 촬영할 수 있다. 뿐만 아니라, 특정 공간에서 발생되는 소리를 수집하여 전자 장치에 전송하거나, 전자 장치(10 0)의 사용자가 발화한 음성 신호를 수신하고, 이를 출력할 수도 있다. 제1 로봇(200-1) 또는 제2 로봇(200-2)은 다양한 형태가 될 수 있다. 구체적으로, 제1 로봇(200-1) 또는 제2 로 봇(200-2)은 사람의 형태와 비슷한 관절형 로봇(보행형 로봇)일 수도 있으며, 바퀴/캐터필러형 로봇, 비행형 로 봇(가령, 드론), 수중에서 동작하는 수영형 로봇일 수도 있다. 다만, 반드시 이에 한하는 것은 아니며, 전자 장 치의 사용자의 제어 명령을 수신하고, 수신된 제어 명령에 따라 동작할 수 있는 장치라면 본 개시에 따른 로봇이 될 수 있다. 한편, 전자 장치는 서버로부터 제1 로봇(200-1) 또는 제2 로봇(200-2)의 정보를 수신할 수 있다. 서 버는 전자 장치로부터 수신된 다양한 요청을 처리할 수 있는 장치로, 전자 장치로부터 다양한 정보를 수신하거나, 전자 장치에 다양한 정보를 전송할 수 있다. 구체적으로, 전자 장치는 서버에 특정 공간에 위치하는 로봇에 관한 정보를 요청할 수 있으며, 요청 에 대한 응답으로 서버로부터 제1 로봇(200-1) 또는 제2 로봇(200-2)의 위치 정보를 수신할 수 있다. 또는, 전자 장치는 서버로부터 제1 로봇(200-1) 또는 제2 로봇(200-2)이 위치하는 공간의 이미지를 수신할 수도 있다. 전자 장치는 제1 로봇(200-1) 또는 제2 로봇(200-2)로부터 이미지를 수신하기 이전에 서버로부터 제1 로봇(200-1) 또는 제2 로봇(200-2)이 존재하는 공간의 이미지를 수신할 수 있다. 한편, 서버는 제1 로봇(200-1) 또는 제2 로봇(200-2)으로부터 제1 로봇(200-1) 또는 제2 로봇(200-2)의 위치 정보를 수신할 수 있다. 구체적으로, 서버는 주기적으로 제1 로봇(200-1) 또는 제2 로봇(200-2)로부 터 제1 로봇(200-1) 또는 제2 로봇(200-2)의 위치 정보를 수신할 수 있다. 또는 서버는 제1 로봇(200-1) 또는 제2 로봇(200-2)로부터 제1 로봇(200-1) 또는 제2 로봇(200-2)이 위치하는 공간의 이미지 정보를 수신할 수도 있다. 이하에서는 도면을 통하여 본 개시의 전자 장치, 로봇 및 서버의 동작에 대하여 구체적으로 설 명하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 2에 도시된 바와 같이, 전자 장치는 통신 인터페이스, 디스플레이 및 프로세서를 포함 할 수 있다. 통신 인터페이스는 전자 장치가 로봇 또는 서버와 같은 외부 전자 장치(미도시)와 통신을 수행하기 위한 구성 요소이다. 전자 장치는 통신 인터페이스를 통하여 로봇에 제어 명령을 전송 하고, 로봇으로부터 로봇이 촬상한 이미지를 수신할 수 있다. 또한, 전자 장치는 통신 인터페이 스를 통하여 서버에 특정 공간에 대한 정보 또는 특정 공간에 위치하는 로봇에 관한 정보를 요청할 수 있으며, 서버로부터 특정 공간에 대한 정보 또는 특정 공간에 위치하는 로봇에 관한 정보를 수신할 수 도 있다. 통신 인터페이스는 유선 통신 모듈(미도시), 근거리 무선 통신 모듈(미도시), 무선 통신 모듈(미도시) 등 과 같은 다양한 통신 모듈을 포함할 수 있다. 여기에서, 유선 통신 모듈은 유선 이더넷(Ethernet)과 같이 유선 통신 방식에 따라 외부 장치(미도시)와 통신을 수행하기 위한 모듈이다. 그리고, 근거리 무선 통신 모듈이란 블루투스(Bluetooth, BT), BLE(Bluetooth Low Energy), ZigBee 방식 등과 같은 근거리 무선 통신 방식에 따라 근거리에 위치한 외부 장치(미도시)와 통신을 수행하기 위한 모듈이다. 또한, 무선 통신 모듈이란 WiFi, IEEE 등과 같은 무선 통신 프로토콜에 따라 외부 네 트워크에 연결되어 외부 장치(미도시)와 통신을 수행하는 모듈이다. 이 밖에 무선 통신 모듈은 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 5세대 네트워크(5G Networks) 등과 같은 다양한 이동 통신 규격에 따라 이동 통신망에 접속하여 통신을 수행하 는 이동 통신 모듈을 더 포함할 수도 있다. 디스플레이는 전자 장치를 통해 제공 가능한 다양한 컨텐츠 화면을 제공할 수 있다. 본 개시에서 디 스플레이는 로봇을 제어하기 위한 UI를 표시하거나, 로봇으로부터 수신한 이미지를 포함하는 UI 를 표시할 수 있다. 또는, 디스플레이는 전자 장치에서 생성된 증강 현실 이미지를 표시할 수도 있다. 디스플레이는 LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플레이, PDP(Plasma Display Panel), Wall, Micro LED 등과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 디스플 레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 한편, 디스플레이는 터치 센서와 결 합된 터치 스크린, 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display) 등으로 구현될 수 있다. 프로세서는 메모리(미도시)와 전기적으로 연결되어 전자 장치의 전반적인 동작 및 기능을 제어할 수 있다. 예를 들어, 프로세서는 운영 체제 또는 응용 프로그램을 구동하여 프로세서에 연결된 하드웨어 또는 소프트웨어 구성요소들을 제어할 수 있고, 각종 데이터 처리 및 연산을 수행할 수 있다. 또한, 프로세서 는 다른 구성요소들 중 적어도 하나로부터 수신된 명령 또는 데이터를 휘발성 메모리에 로드하여 처리하고, 다양한 데이터를 비휘발성 메모리에 저장할 수 있다. 이를 위해, 프로세서는 해당 동작을 수행하기 위한 전용 프로세서(예, 임베디드 프로세서) 또는 메모리 디 바이스에 저장된 하나 이상의 소프트웨어 프로그램을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세 서(예: CPU (Central Processing Unit) 또는 어플리케이션 프로세서 (application processor (AP))로 구현될 수 있다. 본 개시에서, 프로세서는 디지털 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP)), 마이크로프로세서(microprocessor), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)), GPU(graphics- processing unit) 또는 커뮤니케이션 프로세서(communication processor(CP)), ARP 프로세서(Address Resolution Protocol processor) 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 또한, 프 로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수 도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 프로세서는 제1 공간에 위치하는 제1 로봇(200-1)을 제어할 수 있다. 구체적으로, 프로세서는 로봇 을 제어하는 제어 명령을 생성하여 이를 로봇에 전송하도록 통신 인터페이스를 제어할 수 있다. 이를 위하여 프로세서는 제1 로봇을 제어하기 위한 UI를 표시하도록 디스플레이를 제어할 수 있다. 프로세서는 제1 로봇(200-1)이 촬상한 이미지를 전자 장치에 전송하도록 제어할 수 있고, 제1 로봇 (200-1)으로부터 수신한 이미지를 포함하는 UI를 표시하도록 디스플레이를 제어할 수 있다. 한편, 프로세서는 제1 로봇(200-1)이 제1 공간에서 제1 공간과 다른 제2 공간으로 이동하기 어려우면, 제2 공간에 위치하는 제2 로봇을 확인할 수 있다. 이때, 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동하기 어 려운 이유는 실시 예에 따라 다양할 수 있다. 가령, 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동하는 과 정에서 통과할 수 없는 장애물을 만나는 경우인 경우가 이에 해당할 수 있다. 또는, 제1 로봇(200-1)의 배터리 가 기설정된 값 이하이거나, 제2 공간이 제1 로봇(200-1)에 대한 제어 명령이 도달하지 않는 영역인 경우와 같 이 제1 로봇(200-1)의 상태(배터리, 고장 등) 또는 제1 로봇(200-1)에 대한 제어 명령을 전송하는 통신 상태에 따라 제1 로봇이 제1 영역에서 제2 영역으로 이동하기 어려울 수 있다. 이때, 프로세서는 서버에 제2 공간에 위치하는 로봇의 정보를 요청할 수 있다. 프로세서는 서버로부터 제2 공간에 위치하는 로봇의 정보를 수신하면, 제2 공간에 위치하는 제2 로봇 (200-2)과 연결되어 제2 로봇(200-2)을 제어할 수 있다. 이때, 프로세서는 제2 로봇을 제어하기 위한 UI를 표시하도록 디스플레이를 제어할 수 있다. 이하, 프로세서의 구체적인 동작에 대해서는 도 4에서 구체적으로 기술하기로 한다. 한편, 도 2의 전자 장치에 도시된 구성 요소들은 전자 장치의 성능 및/또는 종류에 대응하여 적어도 하나의 구성 요소의 추가, 변경되거나 삭제될 수 있다. 또한, 구성 요소들의 위치는 전자 장치의 성능 또 는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통상의 지식을 가지는 자에게 용이하게 이해될 것이다. 도 3은 본 개시의 일 실시 예에 따른 로봇의 구성을 설명하기 위한 블록도이다. 도 3에 도시된 바와 같이, 로봇은 통신 인터페이스, 구동 장치, 센서, 메모리, 카메 라, 마이크, 스피커 및 프로세서을 포함할 수 있다. 통신 인터페이스는 로봇이 전자 장치 또는 서버와 통신을 수행하기 위한 구성요소이다. 로 봇은 통신 인터페이스를 통하여 전자 장치 또는 서버에 로봇이 촬상한 이미지를 전송 할 수 있다. 또한, 로봇은 통신 인터페이스를 통하여 서버에 로봇의 위치 정보를 전송할 수 있다. 그리고, 로봇은 통신 인터페이스를 통하여 전자 장치로부터 제어 명령을 수신할 수도 있다. 구동 장치는 로봇을 이동시킬 수 있다. 이를 위하여, 구동 장치는 하나 또는 둘 이상의 바퀴와 연결되고, 바퀴를 회전시킬 수 있는 모터 등의 구동 유닛을 구비할 수 있다. 그리고, 구동 장치는 프로세 서의 제어 신호에 따라 로봇의 이동, 정지, 방향 전환 등의 주행 동작을 수행할 수 있다. 센서는 로봇 주변의 장애물을 감지할 수 있다. 구체적으로, 센서는 초음파 센서(supersonic sensor), 적외선 센서(Infrared sensor), RF 센서, 카메라 등을 이용하여 로봇 주변의 장애물의 위치 및 장애물과의 거리를 감지할 수 있다. 또한, 센서는 장애물과의 충돌을 통하여 장애물을 감지하는 충돌 센서 를 더 포함할 수 있다. 메모리는 로봇의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이 브(SSD) 등으로 구현될 수 있다. 카메라는 로봇이 위치하는 공간에 대한 이미지를 촬상할 수 있다. 카메라는 하나 이상의 이미지 센서, 렌즈, 이미지 시그널 프로세서를 포함할 수 있다. 카메라는 로봇의 전면 상에 위치하는 것이 일반적이나 반드시 이에 한하는 것은 아니며, 로봇의 후면, 측면 상에 위치할 수도 있다. 마이크는 로봇의 외부로부터 사운드를 입력받고, 입력된 사운드에 대응하는 신호를 생성하기 위한 구 성이다. 프로세서는 마이크를 통하여 로봇이 위치한 공간의 사운드를 입력 받고, 이에 대응되는 신호를 생성할 수 있다. 스피커는 오디오 프로세서에 의해 디코딩이나 증폭, 노이즈 필터링과 같은 다양한 처리 작업이 수행된 각 종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시지를 출력하는 구성이다. 프로세서는 메모리(미도시)와 전기적으로 연결되어 로봇의 전반적인 동작 및 기능을 제어할 수 있다. 예를 들어, 프로세서는 운영 체제 또는 응용 프로그램을 구동하여 프로세서에 연결된 하드웨어 또는 소프트웨어 구성요소들을 제어할 수 있고, 각종 데이터 처리 및 연산을 수행할 수 있다. 또한, 프로세서는 다른 구성요소들 중 적어도 하나로부터 수신된 명령 또는 데이터를 휘발성 메모리에 로드하여 처리하고, 다양한 데이터를 비휘발성 메모리에 저장할 수 있다. 이를 위해, 프로세서는 해당 동작을 수행하기 위한 전용 프로세서(예, 임베디드 프로세서) 또는 메모리 디 바이스에 저장된 하나 이상의 소프트웨어 프로그램을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세 서(예: CPU (Central Processing Unit) 또는 어플리케이션 프로세서 (application processor (AP))로 구현될 수 있다. 프로세서는 통신 인터페이스를 통하여 수신한 제어 명령에 따라 로봇이 동작할 수 있도록 로봇 의 각 구성 요소들의 동작 및 기능을 제어할 수 있다. 가령, 프로세서는 제어 명령에 따라 로봇이 이동하도록 구동 장치를 제어하거나, 로봇이 위치하는 공간을 촬상하도록 카메라를 제어할 수 있다. 도 4는 본 개시의 일 실시 예에 따라 서버 및 전자 장치와 통신을 수행하는 전자 장치를 설명하기 위한 시퀀스 도이다. 제1 로봇(200-1) 및 제2 로봇(200-2)은 서버에 위치 정보를 전송할 수 있다(S401, S402). 구체적으로, 제 1 로봇(200-1) 및 제2 로봇(200-2)은 제1 로봇(200-1) 및 제2 로봇(200-2)에 포함된 가속도 센서 및 자이로 센 서와 같은 위치 감지 센서를 이용하여 제1 로봇(200-1) 및 제2 로봇(200-2)의 위치를 식별하고, 식별된 위치 정 보를 서버에 주기적으로 전송할 수 있다. 그리고, 서버는 제1 로봇(200-1) 및 제2 로봇(200-2)의 위 치를 저장할 수 있다. 또한, 제1 로봇(200-1) 및 제2 로봇(200-2)은 서버에 제1 로봇(200-1) 및 제2 로봇(200-2)에 관한 정보를 전송할 수 있다. 가령, 제1 로봇(200-1) 및 제2 로봇(200-2)은 서버에 제1 로봇(200-1) 및 제2 로봇(200- 2)의 종류, 이미지 정보, 식별 정보, 위치 정보, 배터리 정보 및 이동 가능한 영역에 관한 정보를 전송할 수 있 다. 그리고, 서버는 제1 로봇(200-1) 및 제2 로봇(200-2)로부터 수신한 다양한 정보들을 저장할 수 있다. 한편, 전자 장치에 포함된 프로세서는 통신 인터페이스를 통하여 제1 공간에 위치하는 제1 로봇 (200-1)과 연결할 수 있다(S403). 구체적으로, 전자 장치가 제1 공간에 위치하는 로봇과 연결하고자 하는 경우, 프로세서는 서버 에 제1 공간에 위치하는 로봇의 정보를 요청하는 신호를 전송하도록 통신 인터페이스를 제어할 수 있다. 전자 장치로부터 로봇의 정보를 요청하는 신호를 수신한 서버는 제1 공간에 존재하는 로봇을 식별하 고, 제1 로봇(200-1)으로 받은 신호를 기초로 제1 공간에 제1 로봇(200-1)이 존재함을 식별하고, 제1 로봇(200- 1)의 정보를 전송할 수 있다. 이때, 제1 로봇의 정보는 제1 로봇의 이미지, 종류, 식별 정보, 위치 정보, 배터 리 정보, 이동 가능한 영역에 관한 정보 중 적어도 하나를 포함할 수 있다. 서버로부터 제1 공간에 위치하는 제1 로봇(200-1)의 정보를 수신하면, 프로세서는 제1 로봇(200-1)에 제어 권한을 요청할 수 있다. 구체적으로, 프로세서는 전자 장치의 식별 정보, 주소 정보 및 사용자 식별 정보를 전송하여 제1 로봇(200-1)에 제어 권한을 요청할 수 있다. 그리고, 제1 로봇(200-1)은 전자 장치 로부터 수신한 전자 장치의 정보를 기초로 전자 장치에 제어 권한을 부여할 수 있다. 이에 따라, 전자 장치는 제1 로봇(200-1)과 연결할 수 있다. 한편, 제1 로봇(200-1)이 전자 장치와 연결되면, 제1 로봇(200-1)은 제1 로봇(200-1)이 위치한 제1 공간의 이미지를 촬상하고(S404), 촬상한 이미지를 전자 장치에 전송할 수 있다(S405). 그리고, 프로세서는 제1 로봇(200-1)으로부터 수신한 이미지를 기초로 제1 로봇(200-1)을 원격으로 제어할 수 있다. 이를 위하여, 프로세서는 제1 공간에 위치하는 제1 로봇(200-1)을 제어하기 위한 UI를 표시하도록 디스플 레이를 제어할 수 있다(S406). 이때, 제1 로봇(200-1)을 제어하기 위한 UI는 제1 로봇(200-1)이 촬상한 이미지를 포함하는 UI를 포함할 수 있다. 또한, 프로세서는 제1 로봇(200-1)이 촬상한 이미지를 기초로 증강 현실 이미지를 생성하고, 생성된 증강 현실 이미지를 포함하는 UI를 표시하도록 디스플레이를 제어할 수 있다. 프로세서는 제1 로봇(200-1)을 제어하기 위한 UI를 통하여 제1 로봇(200-1)을 제어하기 위한 사용자 입력 을 수신할 수 있다. 그리고, 프로세서는 사용자 입력에 기초하여 제1 로봇을 제어하기 위한 제어 신호를 제1 로봇(200-1)에 전송할 수 있다(S407). 제1 로봇(200-1)은 전자 장치로부터 수신한 제어 신호에 기초하여 동작할 수 있다. 구체적으로, 제1 로봇 (200-1)은 제어 신호에 따라 제1 공간을 이동하거나 제1 공간에 위치하는 객체를 촬영하여 전자 장치에 전 송할 수 있다. 또한, 제1 로봇(200-1)은 제어 신호에 따라 제1 공간에서 발생되는 사운드를 수집하여 전자 장치 에 전송할 수 있다. 또는, 제1 로봇(200-1)은 전자 장치의 사용자가 발화한 사용자 음성을 수신하고, 수신한 음성을 출력할 수도 있다. 한편, 전자 장치가 전송한 제어 신호에 따라 제1 로봇(200-1)의 이동이 불가능한 경우가 발생할 수 있다. 가령, 제1 로봇(200-1)이 통과하기 어려운 장애물을 만나거나, 제1 로봇(200-1)의 배터리가 기설정된 값 이하인 경우, 제1 로봇(200-1)이 고장난 경우, 제1 로봇(200-1)에 대한 제어 명령을 수신하는 통신 상태가 불량인 경 우 또는 제1 로봇(200-1)에 설정된 이동 영역 제한에 따라 제1 로봇은 제2 공간으로 이동할 수 없을 수 있다 (S408). 여기에서, 제2 공간은, 이와 같은 이동 불가 사유로 제1 로봇(200-1)이 이동할 수 없는 공간을 나타낸 다. 제1 로봇(200-1)은 제1 공간에서 제2 공간으로 이동 불가능한 경우, 제2 공간으로 이동이 불가능하다는 메시지 를 전자 장치에 전송할 수 있다(S409). 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동하기 어려운 경우, 프로세서는 제2 공간에 위치하는 제 2 로봇을 확인할 수 있다. 구체적으로, 프로세서는 서버에 제2 공간에 존재하는 로봇의 정보를 요청 할 수 있다(S410). 그리고, 서버는 제2 공간에 존재하는 로봇을 식별할 수 있다(S411). 구체적으로, 서버는 S402 단계에 서 제2 로봇(200-2)으로부터 수신한 제2 로봇(200-2)의 위치 정보를 기초로 제2 로봇(200-2)이 제2 공간에 존재 한다는 것을 식별할 수 있다. 그리고, 서버는 제2 로봇의 정보를 전자 장치에 전송할 수 있다. 이때, 제2 공간에 복수의 제2 로봇 이 존재하는 경우, 서버는 복수의 제2 로봇(200-2)에 관한 정보를 제공할 수도 있으나, 복수의 제2 로봇 (200-2) 중 하나를 선택하여 선택한 제2 로봇(200-2)의 정보를 전자 장치에 제공할 수 있다. 가령, 서버는 제2 공간에 위치하는 복수의 제2 로봇(200-2) 중 제1 로봇(200-1)에 가장 인접한 제2 로봇 (200-2)을 선택하여, 선택된 제2 로봇(200-2)의 정보를 전자 장치에 전송할 수 있다. 또는 서버는 제 2 공간에 위치하는 복수의 제2 로봇(200-2) 중 배터리 용량이 가장 많은 제2 로봇(200-2)을 선택하여, 선택된 제2 로봇의 정보를 전자 장치에 전송할 수 있다. 이때, 제2 로봇(200-2)에 관한 정보는, 제2 로봇(200- 2)의 이미지 정보, 제2 로봇(200-2)의 종류, 식별 정보, 위치 정보, 배터리 정보 및 이동 가능한 영역에 관한 정보 중 적어도 하나를 포함할 수 있다. 서버로부터 제2 로봇에 관한 정보를 수신하면, 프로세서는 수신한 제2 로봇(200-2)에 관한 정보를 표 시하도록 디스플레이를 제어할 수 있다(S413). 구체적으로, 프로세서는 제2 로봇(200-2)의 이미지를 비롯하여 제2 로봇(200-2)의 식별 정보, 위치 정보, 배터리 정보 또는 이동 가능한 영역에 관한 정보 중 적어도 하나를 표시하도록 디스플레이를 제어할 수 있다. 그리고, 프로세서는 제2 로봇과 연결하기 위한 사용자 입력을 수신할 수 있다(S414). 구체적으로, 프로세 서는 디스플레이에 표시된 제2 로봇(200-2)에 관한 정보를 선택하는 사용자 입력을 수신할 수 있다. 가령, 프로세서는 디스플레이에 표시된 제2 로봇의 이미지를 선택하는 사용자 입력을 수신할 수 있다. 제2 로봇에 관한 정보를 사용자 입력을 수신하면, 프로세서는 제2 로봇(200-2)과 연결할 수 있다(S415). 구체적으로, 프로세서는 전자 장치의 식별 정보, 주소 정보 및 사용자 식별 정보 중 적어도 하나를 전송하여 제2 로봇(200-2)에 제어 권한을 요청할 수 있다. 그리고, 제2 로봇(200-2)은 전자 장치로부터 수 신한 정보를 기초로 전자 장치에 제어 권한 승인 메시지를 전송하여 전자 장치에 제2 로봇(200-2)에 대한 제어 권한을 부여할 수 있다. 이에 따라, 전자 장치는 제2 로봇(200-2)과 연결되어 제2 로봇(200-2)을 제어할 수 있다. 한편, 제2 로봇(200-2)으로부터 제어 권한 승인 메시지를 수신하면, 프로세서는 제1 로봇(200-1)이 기설정 된 위치로 이동하도록 하는 제어 명령을 제1 로봇(200-1)에 전송하도록 통신 인터페이스를 제어할 수 있다. 이때, 기설정된 위치는 제1 로봇(200-1)의 스테이션이거나, 제1 공간이 제2 공간이 아닌 다른 공간과 연 결된 지점이 될 수 있다. 제2 로봇(200-2)은 전자 장치와 연결되면 제2 공간의 이미지를 촬상하고(S416), 제2 로봇(200-2)이 촬상한 제2 공간의 이미지를 전자 장치에 전송할 수 있다(S417). 그리고, 프로세서는 제2 로봇(200-2)으로부터 수신한 이미지를 기초로 제2 로봇(200-2)을 원격으로 제어할 수 있다. 구체적으로, 프로세서는 제2 공간에 존재하는 제2 로봇(200-2)을 제어하기 위한 UI를 표시하도록 디스플레이를 제어할 수 있다(S418). 여기에서, 제2 로봇(200-2)을 제어하기 위한 UI는 제2 로봇(200-2)이 촬상 한 이미지를 포함하는 UI를 포함할 수 있다. 또한, 프로세서는 제2 로봇(200-2)이 촬상한 이미지를 기초로 증강 현실 이미지를 생성하고, 생성된 증강 현실 이미지를 포함하는 UI를 표시하도록 디스플레이를 제어할 수 있다. 이와 같은 과정을 통하여 전자 장치는 제1 공간에 위치하는 제1 로봇(200-1)을 제어하면서 제1 로봇(200- 1)이 촬상한 이미지를 획득할 수 있으며, 제1 로봇(200-1)이 제2 공간으로 이동하기 어려운 경우 제2 로봇(200- 2)을 제어하면서 제2 로봇(200-2)이 촬상한 이미지를 획득할 수 있게 된다. 도 5A 내지 도 5E는 제1 로봇(200-1) 및 제2 로봇(200-2)으로부터 제1 로봇(200-1) 및 제2 로봇(200-2)이 촬상 한 이미지를 수신하고, 수신된 이미지를 표시하는 전자 장치를 설명하기 위한 도면이다. 도 5A는 장애물이 존재하는 공간에 존재하는 로봇을 설명하기 위한 도면으로, 가령, 계단과 같은 장애물이 존재 하는 미술관 또는 박물관에 존재하는 로봇을 나타내는 도면이다. 본 개시에서 장애물은 로봇이 이동하지 못하도 록 로봇의 이동을 제한하는 객체로, 계단 뿐만 아니라 에스컬레이터, 엘리베이터, 문, 펜스(fence)와 같은 다양 한 형태가 될 수 있다. 또한, 도 5A의 공간은 미술관 또는 박물관 뿐만 아니라, 다양한 공간이 될 수 있음은 물 론이다. 여기에서, 제1 로봇(200-1)이 위치하는 영역(가령, 그림 A 및 그림 B가 존재하는 영역)을 제1 공간이라 하고, 장애물에 의해 제1 로봇(200-1)이 이동 불가능한 영역(가령, 그림 C 및 그림 D가 존재하는 영역)을 제2 공간이 라 기술할 수 있다. 제1 로봇(200-1)은 전자 장치로부터 제어 신호를 수신하고, 수신된 제어 신호에 따라 제1 공간을 이동하면 서 이미지를 촬상할 수 있다. 가령, 제1 로봇(200-1)은 전자 장치로부터 수신한 제어 신호에 기초하여, A 그림 또는 B그림을 촬영하고 촬영된 A 그림 또는 B 그림의 이미지를 전자 장치에 전송할 수 있다. 그리고, 프로세서는 제1 로봇(200-1)으로부터 제1 로봇(200-1)이 촬상한 이미지를 수신하고, 수신된 이미 지를 포함하는 UI를 표시하도록 디스플레이를 제어할 수 있다. 가령, 도 5b에 도시된 바와 같이, 프로세서는 제1 로봇(200-1)이 촬상한 그림 A의 이미지를 수신하고, 수 신된 그림 A를 포함하는 이미지를 포함하는 UI를 표시하도록 디스플레이를 제어할 수 있다. 한편, 도 5c에 도시된 바와 같이, 프로세서는 제1 로봇(200-1)이 제1 공간에서 제2 공간을 향해 이동하는 중에 촬상한 이미지를 수신하고, 제1 로봇(200-1)으로부터 수신한 이미지를 화면에 표시하도록 디스플레이(12 0)를 제어할 수 있다. 이때, 프로세서는 제1 로봇(200-1)으로부터 제1 공간에서 제2 공간을 향해 이동하는 중에 촬상한 이미지에 서 장애물을 식별할 수 있다. 구체적으로, 프로세서는 객체 인식 프로그램이나 이미지에 포함된 객체를 인 식하도록 학습된 인공지능 모델을 이용하여 화면에 표시된 이미지에서 장애물을 식별할 수 있다. 그리고, 프로세서는 식별된 장애물이 화면의 기설정된 영역에 위치하는 경우, 제1 로봇(200-1)이 제2 공간 으로 이동하기 어려운 것으로 결정할 수 있다. 이에 대해서는 도 6a 및 도 6b에서 구체적으로 설명하도록 한다. 또는, 프로세서는 제1 로봇(200-1)으로부터 직접 장애물에 관한 정보를 수신할 수도 있다. 프로세서 는 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동하면서 식별한 장애물에 관한 정보를 수신하고, 수신된 정보를 기초로 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동하기 어려운 것으로 확인할 수도 있다. 이와 관련하여, 제1 로봇(200-1)은 제1 로봇(200-1)에 포함된 적외선 센서, 광 센서 및 카메라와 같은 다양한 센서를통하여 제1 로봇(200-1)의 전방에 위치한 장애물을 식별하고, 식별된 장애물을 우회하거나 넘어갈 수 있는지 계 산할 수 있다. 그리고, 계산 결과에 기초하여 식별된 장애물의 정보 및 장애물을 넘어가거나 통과할 수 있는지 여부 등을 포함하는 장애물에 관한 정보를 전자 장치에 전송할 수 있다. 프로세서는 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동하기 어려운 것으로 확인되면, 제2 공간에 위치하는 제2 로봇(200-2)을 확인할 수 있다. 구체적으로, 도 4에서 상술한 바와 같이, 프로세서는 서버에 제2 공간에 존재하는 로봇의 정보를 요 청하고, 서버로부터 제2 공간에 존재하는 제2 로봇(200-2)의 정보를 수신하고, 수신된 제2 로봇(200-2)의 정보를 표시할 수 있다. 좀 더 구체적으로, 프로세서는 서버로부터 수신한 제2 로봇(200-2)의 정보를 기초로 제2 로봇(200- 2)에 대한 가상 이미지를 생성하고, 생성된 가상 이미지를 기초로 증강 현실 이미지를 생성할 수 있다. 구체적으로, 도 5d에 도시된 바와 같이, 프로세서는 제1 로봇(200-1)이 촬상한 장애물을 포함하는 이미지 에 서버로부터 수신한 제2 로봇(200-2)에 대한 가상 이미지를 렌더링하여 증강 현실 이미지를 생성하고, 생성된 증강 현실 이미지를 표시하도록 디스플레이를 제어할 수 있다. 이에 따라, 전자 장치의 사용 자는 제2 공간에 제2 로봇(200-2)이 존재함을 시각적으로 인식할 수 있게 된다. 한편, 프로세서는 디스플레이에 표시된 증강 현실 이미지에서 제2 로봇(200-2)의 정보를 선택하는 사 용자 입력을 수신할 수 있다. 가령, 프로세서는 도 5d와 같이 제2 로봇(200-2)에 대한 가상 이미지를 선택 하는 사용자 입력을 수신할 수 있다. 제2 로봇(200-1)에 대한 가상 이미지를 선택하는 사용자 입력을 수신하면, 프로세서는 제2 로봇(200-2)에 제어 권한을 요청하는 신호를 전송할 수 있다. 그리고, 제2 로봇(200-2)으로부터 제2 로봇(200-2)에 대한 제어 권한을 받으면, 제2 로봇(200-2)과 연결되어 제2 로봇(200-2)을 제어할 수 있다. 그리고, 프로세서는 제2 로봇(200-2)이 제1 로봇(200-1)과 인접한 영역으로 이동하도록 하는 제어 명령을 제2 로봇(200-2)에 전송하도록 통신 인터페이스를 제어할 수 있다. 여기에서 '인접한 영역'은, 제1 로봇 (200-1)이 이동할 수 없는 제2 공간의 영역으로 제1 로봇(200-1)의 전방에 위치한 장애물과 만나는 영역을 나타 낸다. 이에 따라, 제2 로봇(200-2)은 제2 공간이 장애물과 만나는 영역으로 이동할 수 있다. 프로세서는 제2 로봇(200-2)이 제1 로봇(200-1)과 인접한 영역으로 이동하면 제2 로봇(200-2)으로부터 제2 로봇(200-2)이 촬상한 이미지를 수신하고, 수신된 이미지를 포함하는 UI를 표시하도록 디스플레이를 제어 할 수 있다. 가령, 프로세서는 제2 로봇(200-2)이 제1 로봇(200-1)과 인접한 영역인 C 그림 앞으로 이동하 게 되면, 제2 로봇(200-2)이 제2 공간의 이미지를 촬상하고, 촬상된 이미지를 전송하도록 제2 로봇(200-2)을 제 어할 수 있다. 그리고, 도 5e에 도시된 바와 같이, 제2 로봇(200-2)으로부터 제2 로봇(200-2)이 촬상한 이미지 (가령, 그림 C의 이미지)를 포함하는 UI를 표시하도록 디스플레이를 제어할 수 있다. 이에 따라, 전자 장치는 특정 공간에 장애물이 존재하더라도 특정 공간에 존재하는 복수의 로봇을 이용하 여 장애물에 대한 제약 없이 특정 공간의 이미지를 사용자에게 제공할 수 있게 되며, 사용자는 공간에 대한 제 약 없이 연속적인 서비스를 제공 받을 수 있게 된다. 도 6은 로봇이 촬상한 이미지에서 장애물을 식별하고, 가상의 이미지를 표시하는 전자 장치를 설명하기 위한 도 면이다. 도 6a는 로봇으로부터 장애물이 포함된 이미지를 수신하여 표시하는 전자 장치를 설명하기 위한 도면이 고, 도 6b는 장애물이 포함된 이미지에서 장애물을 식별하고, 다른 공간의 이미지를 표시하는 전자 장치를 설명 하기 위한 도면이다. 상술한 바와 같이 제1 로봇(200-1)은 제1 공간을 이동하면서 이미지를 촬상하고, 촬상된 이미지를 전자 장치 에 전송할 수 있다. 그리고, 프로세서는 제1 로봇(200-1)으로부터 제1 로봇(200-1)이 촬상한 이미지 를 수신하고, 수신한 이미지를 표시하도록 디스플레이를 제어할 수 있다. 한편, 프로세서는 제1 로봇(200-1)이 촬상한 이미지에서 장애물을 식별할 수 있다. 구체적으로, 프로세서 는 메모리(미도시)에 저장된 객체 인식 프로그램 또는 이미지에 포함된 객체를 인식하도록 학습된 인공지 능 모델을 이용하여, 제1 로봇(200-1)에 포함된 장애물을 식별할 수 있다. 그리고, 프로세서는 식별된 장애물이 디스플레이의 화면의 기설정된 영역에 표시되는 경우, 제1 로봇(200-1)이 장애물을 넘어갈 수 없다고 판단할 수 있다. 여기에서, 기설정된 영역은 로봇의 전방에 위치한 장애물의 크기를 대략적으로 식별하여 로봇이 장애물을 넘을 수 있는지 판단하기 위한 영역으로, 디스플레이 화면의 중심 영역을 포함하면서 전체 화면 면적의 일정 비율 이상을 차지하는 영역이다. 프로세서는 제1 로봇(200-1)이 촬상한 이미지에 포함된 장애물이 화면의 기설정된 영역 내에 표시되 고, 기설정된 영역에서 장애물을 제외한 영역(빗금친 영역)의 면적이 기정의된 값 이하인 경우, 제1 로봇 (200-1)이 장애물을 넘어 이동할 수 없다고 확인할 수 있다. 가령, 프로세서는 제1 로봇(200-1)이 촬상한 이미지에서 문을 식별하고, 문이 화면의 기설정된 영역 내에 표시되고, 기설정된 영역에서 문을 제외한 영역의 면적이 기정의된 값 이하인 경우, 제1 로봇(200- 1)이 장애물을 넘어 이동할 수 없다고 판단할 수 있다. 장애물에 의해 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동할 수 없다고 확인된 경우, 프로세서는 제2 공간에 관한 정보를 서버에 요청할 수 있다. 구체적으로, 프로세서는 서버에 제1 로봇(200-1)의 식별 정보를 전송하고, 제1 로봇(200-1)의 식별 정보를 기초로 제1 로봇(200-1)의 위치와 인접한 제2 공간에 관한 정보를 요청할 수 있다. 여기에서 제2 공간에 관한 정보는 제2 공간의 이미지 정보 또는 제2 공간에 포함된 객체의 이미지 정보를 포함할 수 있다. 또한, 프 로세서는 서버에 제2 공간에 위치하는 로봇의 정보를 요청할 수 있다. 도 4에서 상술한 바와 같이, 제1 로봇(200-1) 및 제2 로봇(200-2)은 서버에 주기적으로 식별 정보 및 위치 정보를 전송한다는 점에서, 서버에는 제1 로봇(200-1) 및 제2 로봇(200-2)의 위치 정보가 저장될 수 있다. 따라서, 전자 장치로부터 제1 로봇(200-1)의 식별 정보를 수신한 서버는 제1 로봇(200-1)의 식별 정 보를 토대로 제1 로봇의 위치 정보를 식별할 수 있다. 또한, 서버는 제1 로봇(200-1)의 위치 정보를 기초로 제1 로봇(200-1)과 인접한 제2 공간에 관한 정보를 획득할 수 있다. 이를 위하여 서버는 복수의 공간에 대한 공간 정보를 저장할 수 있다. 구체적으로, 서버 는 복수의 공간 각각에 위치하는 공간 수집 장치로부터 공간 정보를 수신하고, 수신된 공간 정보를 저장할 수 있다. 이와 관련하여, 서버의 동작에 대해서는 도 7 및 도 8에서 구체적으로 설명하기로 한다. 서버는 획득한 제2 공간에 대한 정보 및 제2 공간에 위치하는 로봇의 정보를 전자 장치에 전송할 수 있다. 구체적으로, 서버는 제2 공간의 이미지 정보, 제2 공간에 위치하는 제2 로봇(200-2)의 이미지 정보, 식별 정보, 위치 정보, 배터리 정보 및 이동 가능한 영역에 관한 정보 중 적어도 하나를 전자 장치에 전송 할 수 있다. 한편, 서버에 저장된 로봇에 관한 정보를 기초로, 제2 공간에 로봇이 존재하지 않는 것으로 확인될 수도 있다. 이 경우, 프로세서는 서버에 제2 공간과 연결된 제3 공간에 대한 정보를 요청할 수 있다. 구체 적으로, 프로세서는 제3 공간의 위치 정보 및 제3 공간에 위치하는 로봇의 정보를 수신할 수 있다. 그리고, 제3 공간에 위치하는 제3 로봇이 제2 공간으로 이동할 수 있는지 확인하고, 제3 로봇을 제어하기 위한 UI를 표시할 수 있다. 한편, 제2 공간에 위치하는 로봇이 존재하는 경우, 프로세서는 서버로부터 수신한 제2 공간에 대한 정보 및 제2 공간에 위치하는 로봇의 정보를 기초로, 증강 현실 이미지를 생성하고 이를 표시하도록 디스플레이 를 제어할 수 있다. 구체적으로, 프로세서는 제1 로봇(200-1)으로부터 수신한 이미지에 서버로부터 수신한 제2 공간의 이 미지 및 제2 로봇(200-2)의 이미지를 렌더링하여 증강현실 이미지를 생성할 수 있다. 이때, 프로세서는 제 1 로봇(200-1)으로부터 수신한 이미지에서 기 설정된 영역에 표시된 장애물의 위치에 제2 공간의 이미지 및 제2 로봇(200-2)의 이미지를 렌더링하도록 디스플레이를 제어할 수 있다. 또한, 프로세서는 제2 공간의 이미지 및 제2 로봇(200-2)의 이미지를 렌더링하면서 장애물에 대응되는 그래픽 효과를 제공하도록 디스 플레이를 제어할 수 있다. 가령, 프로세서는 도 6b에 도시된 바와 같이, 제2 공간의 이미지 및 제2 로봇(200-2)의 이미지를 렌더링 하면서 문이 열리는 그래픽 효과를 제공하도록 디스플레이를 제어할 수 있 다. 이에 따라, 프로세서는 제1 로봇(200-1)이 장애물을 만나 제1 공간에서 제2 공간으로 이동하기 어려운 경 우, 제2 공간의 이미지 및 제2 공간에 존재하는 제2 로봇의 이미지를 포함하는 UI를 표시하도록 디스플레이 를 제어할 수 있다. 도 7은 본 개시의 일 실시 예에 따라 공간 정보를 수집하여 저장하는 서버를 설명하기 위한 도면이다. 본 개시의 각각의 공간에는 공간 정보 수집 장치가 위치할 수 있다. 여기에서, 공간 정보 수집 장치 는 공간 정보 수집 장치가 놓인 공간을 촬상하여 공간에 대한 이미지를 생성하는 장치로, 카메라, CCTV를 비롯한 다양한 촬상 장치를 의미한다. 구체적으로, 도 8에 도시된 바와 같이, 장애물이 위치한 영역으로 기준으로 제1 공간을 촬상하는 공간 수집 장 치(500-1) 및 제2 공간을 촬상하는 공간 수집 장치(500-2)가 존재할 수 있다. 한편, 도 8에는 제1 공간에 대한 공간 수집 장치(500-1) 및 제2 공간에 대한 공간 수집 장치(500-2)가 각각 하나인 것으로 도시하였으나, 각각의 공간에는 복수의 공간 수집 장치가 위치할 수 있다. 공간 정보 수집 장치는 공간 정보 수집 장치가 놓인 공간에 대한 공간 정보를 수집할 수 있다(S710). 구체적으로, 공간 정보 수집 장치는 공간 정보 수집 장치가 위치한 공간을 촬영하면서 공간에 존재하 는 로봇이나 다양한 객체들을 포함하는 이미지를 생성할 수 있다. 가령, 도 8을 참조하면, 제1 공간 수집 장치(500-1)는 제1 공간 및 제1 공간에 위치하는 로봇이나 다양한 객체 들을 촬영하여, 제1 공간에 대한 공간 정보를 수집할 수 있다. 또한, 제2 공간 수집 장치(500-2)는 제2 공간 및 제2 공간에 위치하는 로봇이나 다양한 객체들을 촬영하여, 제2 공간에 대한 공간 정보를 수집할 수 있다. 공간 수집 장치는 수집된 공간 정보를 서버에 전송할 수 있다(S720). 구체적으로, 공간 수집 장치 는 서버와 연결되어 주기적으로 서버)에 수집된 공간 정보를 전송할 수 있다. 서버는 공간 정보 수집 장치로부터 수신한 공간 정보를 영상처리를 통해 재구성하여 저장할 수 있다 (S730). 구체적으로, 서버는 공간 정보 수집 장치로부터 수신한 공간 정보에 포함된 이미지를 확대, 축소, 회전하는 유클리드 기하학적 변환을 수행하거나, 이미지의 색보정 또는 색 변환을 수행하거나, 제1 공간 수집 장치(500-1)(또는 제2 공간 수집 장치(500-2))로부터 수신한 복수의 이미지를 결합하여 제1 공간에 대한 하나의 이미지를 생성하는 등 다양한 영상 처리를 통하여 각 공간에 대한 공간 정보를 재구성하여 저장할 수 있 다. 그리고, 서버는 재구성된 공간 정보를 공간 정보 수집 장치에 전송할 수 있다(S740). 이 경우, 공간 정보 수집 장치는 서버로부터 수신한 재구성된 공간 정보를 기초로 공간 정보를 재수집할 수 있다. 한편, 서버에 저장된 공간 정보를 기반으로, 복수의 공간 정보가 연결될 수 있다(S750). 구체적으로, 서버 의 관리자는 각 공간에 대한 지리적 정보를 기초로, 복수의 공간 정보를 연결할 수 있다. 또 다른 실시 예로, 각 공간에 대한 지리적 정보가 서버에 입력되면, 서버는 입력된 지리적 정보를 기초로, 복수의 공간 정보 각각을 연결할 수도 있다. 가령, 서버가 수신한 지리적 정보에 제1 공간과 제2 공간이 연결되고, 제2 공간과 제3 공간이 연결된 것으로 나타나 있다면, 서버는 제1 공간에 대한 공간 정 보 및 제2 공간에 대한 공간 정보를 하나의 쌍으로, 제2 공간에 대한 공간 정보 및 제3 공간에 대한 공간 정보 를 하나의 쌍으로 매핑할 수 있다. 그리고, 서버는 서로 연결된 복수의 공간 정보를 서버에 저장할 수 있다(S760). 이에 따라, 서버는 전자 장치로부터 제1 로봇(500-1)의 식별 정보를 수신하는 경우, 제1 로봇(500- 1)의 식별 정보를 토대로 제1 로봇(500-1)의 위치 정보를 확인하고, 확인된 제1 로봇(500-1)의 위치 정보를 기 초로 제1 로봇(500-1)과 인접한 제2 공간에 대한 정보를 식별할 수 있다. 도 9는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 전자 장치는 제1 공간에 위치하는 제1 로봇(200-1)과 연결할 수 있다. 구체적으로, 전자 장치는 제1 로봇(200-1)에 제어 권한 요청 메시지를 전송하고, 제1 로봇(200-1)으로부터 제어 권한을 수신할 수 있다. 전자 장치가 제1 로봇(200-1)과 연결되면, 제1 로봇을 제어하기 위한 UI를 표시할 수 있다(S910). 구체적으로, 제1 로봇(200-1)과 연결되면, 제1 로봇(200-1)으로부터 제1 로봇(200-1)이 촬상한 이미지를 수신하 고, 수신된 이미지를 포함하는 UI를 표시할 수 있다. 이때, 제1 로봇(200-1)이 제1 공간에서 제2 공간을 향해 이동하면서 촬상한 이미지를 수신하고, 수신된 이미지를 포함하는 UI를 표시할 수 있다. 그리고, 사용자 조작 명령에 기초하여 제1 로봇(200-1)을 제어하기 위한 제어 명령을 제1 로봇(200-1)에 전송할 수 있다. 이에 따라, 제1 로봇(200-1)은 제어 명령에 따라 제1 공간을 이동하면서 제1 공간을 촬상할 수 있다. 그리고, 제1 로봇(200-1)이 제1 공간과 다른 제2 공간으로 이동할 수 있는지 확인할 수 있다. 구체적으로, 제1 로봇(200-1)이 제1 공간에서 제2 공간을 향해 이동하면서 촬상한 이미지에서 장애물을 식별하고, 식별된 장애물 이 화면의 기설정된 영역에 위치하는 경우, 제1 로봇이 제1 공간에서 제2 공간으로 이동하기 어려운 것으로 결 정할 수 있다. 다른 일 실시 예에 따라, 제1 로봇(200-1)으로부터 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동하면서 식별한 장애물에 관한 정보를 수신하고, 수신된 장애물에 관한 정보를 기초로 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동할 수 있는지 확인할 수 있다. 이를 위하여, 제1 로봇(200-1)은 전자 장치의 제어 명령 에 따라 이동하면서 적외선 센서, 광 센서 및 카메라와 같은 다양한 센서를 통하여 장애물을 식별할 수 있다. 그리고, 제1 로봇(200-1)은 식별된 장애물에 관한 정보를 전자 장치에 전송할 수 있다. 제1 로봇(200-1)이 제1 공간과 다른 제2 공간으로 이동하기 어려우면, 제2 공간에 위치하는 제2 로봇(200-2)을 확인할 수 있다(S930). 제1 로봇(200-1)으로부터 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동하면서 식별한 장애물에 관한 정보 를 수신하는 경우, 수신된 정보를 기초로 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동하기 어려운 것으 로 확인되면, 제2 공간에 로봇이 존재하는지 확인할 수 있다. 구체적으로, 제1 로봇(200-1)이 제1 공간에서 제2 공간으로 이동하기 어려우면, 서버에 제2 공간에 위치하 는 로봇의 정보를 요청할 수 있다. 그리고, 서버로부터 제2 공간에 위치하는 제2 로봇(200-2)의 정보를 수 신할 수 있다. 이때, 제2 로봇(200-2)의 정보는 제2 로봇(200-2)의 이미지, 종류, 식별 정보, 위치 정보, 배터 리 정보 및 이동 가능한 영역에 관한 정보 중 적어도 하나를 포함할 수 있다. 한편, 이때, 제2 공간에 로봇이 존재하지 않는 것으로 확인되면, 서버에 제2 공간과 연결된 제3 공간에 대 한 정보를 요청하고, 서버로부터 수신한 정보를 기초로 제3 공간에 위치하는 제3 로봇(200-3)이 제2 공간 으로 이동할 수 있는지 확인할 수 있다. 그리고, 제3 로봇(200-3)이 제2 공간으로 이동가능 한 경우, 제3 로봇 (200-3)을 제어하기 위한 UI를 표시할 수 있다. 서버로부터 제2 로봇(200-2)의 정보를 수신하면, 수신된 제2 로봇(200-2)의 정보를 표시할 수 있다. 가령, 제2 로봇(200-2)의 이미지 정보를 표시할 수 있다. 그리고, 표시된 제2 로봇(200-2)을 선택하는 사용자 입력을 수신하면, 제2 로봇(200-2)에서 촬상된 제2 이미지 를 표시할 수 있다. 구체적으로, 제2 로봇(200-2)을 선택하는 사용자 입력을 수신하면, 제2 로봇(200-2)에 제어 권한을 요청할 수 있다. 이때, 제2 로봇(200-2)으로부터 제어 권한 승인을 수신하면, 제2 로봇(200-2)과 연결되어 제2 로봇(200- 2)에 제어 명령을 전송할 수 있다. 그리고, 확인된 제2 로봇(200-2)을 제어하기 위한 UI를 표시할 수 있다(S940). 이때, 제2 로봇(200-2)이 제1 로봇(200-1)과 인접한 영역으로 이동하도록 하는 제어 명령을 제2 로봇(200-2)에 전송할 수 있다. 제2 로봇(200-2)이 제1 로봇(200-1)과 인접한 영역으로 이동하면, 제2 로봇(200-2)으로부터 제 2 로봇(200-2)이 촬상한 이미지를 수신하고, 제2 로봇(200-2)으로부터 수신한 이미지를 포함하는 UI를 표시할 수 있다. 제2 로봇(200-2)으로부터 제어 권한 승인을 수신하고 제2 로봇(200-2)이 제1 로봇(200-1)과 인접한 영역으로 이 동하면, 제1 로봇(200-1)이 제1 로봇(200-1)의 스테이션과 같은 기설정된 위치로 이동하도록 하는 제어 명령을 제1 로봇(200-1)에 전송할 수 있다. 이상에서 전자 장치 또는 서버 중 적어도 하나를 통해 수행되는 것으로 기재된 다양한 동작들은, 전 자 장치의 제어 방법 또는 전자 장치를 포함하는 시스템의 제어 방법 내지 동작 방법의 형태로 하나 이상의 전 자 장치를 통해 수행될 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합된 것 을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 본 개시에서 설명되는 실시 예들은 ASICs(Application Specific Integrated Circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(Programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processor), 제어기(controller), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessor), 기타 기능 수행을 위한 전기적인 유닛(unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 상술한 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 사용자 장치 또는 관리자 장치에서의 처리동작을 수행하기 위 한 컴퓨터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer- readable medium)에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 사용자 장치 및/또는 관리자 장치의 처리 동작을 상술한 특정 기기가 수행하도록 한다. 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상 술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있다. 또한, 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시"}
{"patent_id": "10-2020-0117915", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해돼서는 안 될 것이다."}
{"patent_id": "10-2020-0117915", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 시스템을 설명하기 위한 도면, 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도, 도 3은 본 개시의 일 실시 예에 따른 로봇의 구성을 설명하기 위한 블록도, 도 4는 본 개시의 일 실시 예에 따라 서버 및 전자 장치와 통신을 수행하는 전자 장치를 설명하기 위한 시퀀스 도, 도 5a는 장애물이 존재하는 공간에 존재하는 로봇을 설명하기 위한 도면, 도 5b는 로봇으로부터 수신한 이미지를 표시하는 전자 장치를 설명하기 위한 도면, 도 5c는 장애물이 포함된 이미지를 표시하는 전자 장치를 설명하기 위한 도면, 도 5d는 로봇이 존재하는 공간과 다른 공간에 존재하는 다른 로봇을 표시하는 전자 장치를 설명하기 위한 도면, 도 5e는 도 5d의 다른 공간에 존재하는 다른 로봇으로부터 수신한 이미지를 표시하는 전자 장치를 설명하기 위 한 도면, 도 6a는 장애물이 포함된 이미지를 로봇으로부터 수신하여 표시하는 전자 장치를 설명하기 위한 도면, 도 6b는 장애물이 포함된 이미지에서 장애물을 식별하고, 다른 공간의 이미지를 표시하는 전자 장치를 설명하기 위한 도면, 도 7은 본 개시의 일 실시 예에 따라 공간 정보를 수집하여 저장하는 서버를 설명하기 위한 도면, 도 8은 본 개시의 일 실시 예에 따른 공간 수집 장치를 설명하기 위한 도면, 및 도 9는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
