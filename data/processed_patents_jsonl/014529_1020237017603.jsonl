{"patent_id": "10-2023-7017603", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0162918", "출원번호": "10-2023-7017603", "발명의 명칭": "카메라를 통해 촬영한 영상을 바탕으로 퍼팅거리를 구하는 스마트 퍼팅 디바이스 및 이를 이", "출원인": "김영국", "발명자": "김영국"}}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "홀과, 상기 홀에 꽂힌 깃대의 영상을 획득하는 영상 획득부; 및상기 영상 획득부에 의해 획득된 영상에서 홀을 식별하여 퍼팅 위치에 대한 상기 홀의 고저차를 구하고, 상기영상에서 상기 깃대를 식별하여 상기 깃대의 길이를 구하고, 상기 고저차와 상기 깃대의 길이를 바탕으로 상기퍼팅 위치에서 상기 홀까지의 수평 거리를 산출하는 프로세서를 포함하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 고저차 및 상기 수평 거리 중 적어도 하나를 출력하는 출력부를 더 포함하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 출력부는,상기 고저차 및 상기 수평 거리 중 적어도 하나를 시각적으로 표시하는 디스플레이를 포함하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,가속도 센서를 더 포함하고,상기 프로세서는,상기 가속도 센서의 감지값을 바탕으로 상기 영상 획득부가 기 설정된 기준자세로 정렬되었는지를 판단하고, 정렬된 것으로 판단된 경우 출력부를 통해 알림을 출력하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,사용자로부터 소정의 명령을 입력받는 입력부를 더 포함하고,상기 프로세서는,상기 알림이 출력된 후 상기 입력부를 통해 촬영 명령이 입력되면, 상기 영상 획득부를 통해 영상이 획득되도록제어하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 프로세서는,상기 영상 획득부에 의해 획득된 영상을, 상기 가속도 센서의 감지값을 바탕으로 보정하고, 보정된 영상에서 상기 깃대의 길이를 구하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,공개특허 10-2023-0162918-3-상기 프로세서는,상피 스마트 퍼팅 디바이스가 지면에 놓인 상태에서 상기 영상 획득부를 통해 구한 제 1 획득영상과, 상기 스마트 퍼팅 디바이스가 상기 지면으로부터 소정 거리 이격된 상태에서 구한 제 2 획득영상을 바탕으로 상기 고저차를 구하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 고저차 및 상기 수평 거리 중 적어도 하나를 출력하는 출력부; 및골프 퍼터용 퍼터 헤드를 더 포함하고,상기 프로세서, 영상 획득부 및 출력부는 상기 퍼터 헤드에 배치되는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,가속도 센서; 및상기 고저차 및 수평 거리에 대한 정보를 무선으로 전송하는 무선통신모듈을 더 포함하고,상기 가속도 센서 및 상기 무선통신모듈은 상기 퍼터 헤드에 배치되는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 고저차 및 상기 수평 거리 중 적어도 하나를 출력하는 출력부; 및골프 퍼터용 퍼터 헤드를 더 포함하고,상기 영상 획득부는 상기 퍼터 헤드에 배치되고,상기 퍼터 헤드와 분리된 것으로서, 상기 프로세서 및 상기 출력부를 포함하는 서브 디바이스를 더 포함하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 퍼터 헤드에 배치되고 상기 영항 획득부에 의해 획득된 영상을 무선으로 전송하는 제 1 무선통신모듈; 및상기 서브 디바이스에 배치되고, 상기 제 1 무선통신모듈과 통신하는 제 2 무선통신모듈을 더 포함하는 스마트퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "홀이 위치한 지점에서 공의 영상을 획득하는 영상 획득부; 및상기 영상 획득부에 의해 획득된 영상에서 상기 공을 식별하여, 상기 공과 상기 홀 간의 고저차 및 상기 공의너비를 구하고, 상기 고저차 및 상기 공의 너비를 바탕으로 상기 공까지의 수평 거리를 구하는 프로세서를 포함하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,볼마커를 더 포함하고,상기 영상 획득부 및 상기 프로세서는 상기 볼마커에 배치되는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2023-0162918-4-제 13 항에 있어서,상기 고저차 및 상기 수평 거리 중 적어도 하나를 출력하는 출력부를 더 포함하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 출력부는,상기 볼마커에 배치되는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항에 있어서,상기 볼마커와 분리된 서브 디바이스를 더 포함하고,상기 출력부는,상기 서브 디바이스에 배치되는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 1 항에 있어서,상기 프로세서는,인공지능 기반의 객체 탐지 알고리즘을 이용하여 상기 영상으로부터 상기 홀과 상기 깃대를 식별하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 1 항에 있어서,상기 프로세서는,상기 영상에 표현된 색상을 분석하여 상기 홀과 상기 깃대를 식별하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "수평 방향으로 소정 거리 이격된 제 1 카메라 및 제 2 카메라를 구비한 영상 획득부; 및상기 영상 획득부가 같은 위치에 있는 상태에서 상기 제 1 카메라에 의해 촬영된 제 1 획득 영상과, 상기 제 2카메라에 의해 촬영된 제 2 획득 영상을 바탕으로 퍼팅 위치에 대한 홀의 고저차 및 상기 퍼팅 위치에서 상기홀까지의 수평 거리를 산출하는 프로세서를 포함하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "수평 및 수직 방향으로 소정 거리 이격된 제 1 카메라 및 제 2 카메라를 구비한 영상 획득부; 및상기 영상 획득부가 같은 위치에 있는 상태에서 상기 제 1 카메라에 의해 촬영된 제 1 획득 영상과, 상기 제 2카메라에 의해 촬영된 제 2 획득 영상을 바탕으로 퍼팅 위치에 대한 상기 홀의 고저차 및 상기 퍼팅 위치에서상기 홀까지의 수평 거리를 산출하는 프로세서를 포함하는 스마트 퍼팅 디바이스."}
{"patent_id": "10-2023-7017603", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 스마트 퍼팅 디바이스는, 홀과, 상기 홀에 꽂힌 깃대의 영상을 획득하는 영상 획득부와, 상기 영상 획 득부에 의해 획득된 영상에서 홀을 식별하여 퍼팅 위치에 대한 상기 홀의 고저차를 구하고, 상기 영상에서 상기 깃대를 식별하여 상기 깃대의 길이를 구하고, 상기 고저차와 상기 깃대의 길이를 바탕으로 상기 퍼팅 위치에서 상기 홀까지의 수평 거리를 산출하는 프로세서를 포함한다."}
{"patent_id": "10-2023-7017603", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 골프용 스마트 퍼팅 디바이스 및 이를 이용한 퍼팅거리 측정 방법에 관한 것으로, 보다 상세하게는, 카메라를 이용하여 촬영한 영상을 바탕으로 퍼팅거리를 측정할 수 있는 스마트 퍼팅 디바이스 및 이를 이용한 퍼팅거리 측정 방법에 관한 것이다."}
{"patent_id": "10-2023-7017603", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 골프용 퍼터는, 퍼팅 그린에서 홀에 골프 공을 넣을 때 사용하는 골프 채이다. 정확한 퍼팅을 위해 서는 공으로부터 홀까지의 거리와 그린의 지형, 그린 속도 등을 정확하게 파악하여야 하는데, 이는 고도의 숙련 이 필요하다. 이런 이유로, 그린에 대한 정확한 정보와 경험을 가지고 있는 캐디를 동반하여 경기를 하는 경우가 일반적인데, 최근, 골프의 대중화와 인기에 힘입어 골프 인구가 증가하여 캐디가 부족할 뿐만 아니라, 캐디 동반에 수반되는 비용도 만만치 않아 캐디를 동반하지 않아도 플레이가 허용되는 골프장들도 늘고 있다. 그런데, 캐디를 동반하지 않고 플레이를 하는 경우, 초급자들이 퍼팅거리나 방향 등의 그린 정보를 파악하는 것 이 매우 어려워 경기의 재미가 반감될 뿐 아니라 타수가 늘어 경기 운영이 지체됨으로써 다른 팀들에게도 피해 를 주는 문제가 있다. 따라서, 퍼팅을 하는데 필요한 정보를 골퍼에게 제공함으로써 혼자서도 정확한 퍼팅을 할 수 있도록 하는 장비가 필요하다. 미국등록특허 US8608595호(이하, '종래기술'이라고 함.)는, 사용자가 의도한 퍼팅 방향(즉, 퍼터로부터 직선으 로 홀을 향하는 방향)과 실제 퍼팅이 이루어지는 방향(즉, 퍼팅이 이루어지는 순간에 퍼터 헤드의 전면에 수직 한 방향)이 디스플레이에 표시되는 퍼터를 개시하고 있다. 종래기술은 홀의 위치 정보를 구하기 위해 카메라가 획득한 영상을 활용하고 있는데, 특히, 상기 영상에 표현된 홀의 크기(즉, 직경)를 바탕으로 퍼터로부터 홀까지의 거리를 구한다. 그런데, 통상적으로 퍼팅이 주로 이루어지는 그린에는 굴곡(undulation)이 있기 때문에 카메라가 퍼터 헤드에 위치하는 경우 그린 상황에 따라서는 홀을 촬영하기 어려워 홀까지의 정확한 거리를 구할 수 없는 문제가 있다. 이러한 문제를 해결하기 위해 종래기술은 카메라를 샤프트에 설치하였으나, 이 경우, 샤프트에 많은 무게가 부 여되기 때문에 퍼팅 스트로크에 영향을 미쳐 경기력을 저하시키는 문제가 있을 뿐만 아니라, 카메라와 디스플레 이가 사용자의 시야를 가려 퍼팅 동작을 방해하는 문제가 있었다."}
{"patent_id": "10-2023-7017603", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 첫째, 카메라를 이용해 획득한 영상을 이용하여 홀까지의 거리를 구하는 스 마트 퍼팅 디바이스 및 이를 이용한 퍼팅거리 측정 방법을 제공하는 것이다. 둘째, 카메라로부터 획득한 영상을 통해 홀까지의 거리를 구하되, 상기 카메라를 퍼터 헤드에 구비함으로써 상 기 카메라의 부가로 인해 퍼터의 무게 중심이 지면에서 수직한 방향으로 이동되는 것을 억제한 스마트 퍼팅 디 바이스를 제공하는 것이다. 셋째, 지면의 굴곡으로 인해 카메라로 홀을 촬영할 수 없는 경우에도, 홀까지의 거리를 상당한 정확도로 측정할 수 있는 스마트 퍼팅 디바이스 및 이를 이용한 퍼팅거리 측정 방법을 제공하는 것이다. 넷째, 카메라를 이용하여 퍼터로부터 홀까지의 거리와 퍼팅 위치와 홀 간의 고저차를 구할 수 있는 스마트 퍼팅 디바이스 및 이를 이용한 퍼팅거리 측정 방법을 제공하는 것이다."}
{"patent_id": "10-2023-7017603", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 스마트 퍼팅 디바이스는, 홀과, 상기 홀에 꽂힌 깃대의 영상을 획득하는 영상 획득부와, 상기 영상 획득부에 의해 획득된 영상에서 홀을 식별하여 퍼팅 위치에 대한 상기 홀의 고저차를 구하고, 상기 영상에서 상 기 깃대를 식별하여 상기 깃대의 길이를 구하고, 상기 고저차와 상기 깃대의 길이를 바탕으로 상기 퍼팅 위치에 서 상기 홀까지의 수평 거리를 산출하는 프로세서를 포함한다. 상기 고저차 및 상기 수평 거리 중 적어도 하나를 출력하는 출력부를 더 포함할 수 있다. 상기 출력부는, 상기 수평 거리 및 상기 고저차 중 적어도 하나를 시각적으로 표시하는 디스플레이를 포함할 수 있다. 상기 스마트 퍼팅 디바이스는, 가속도 센서를 더 포함할 수 있고, 상기 프로세서는, 상기 가속도 센서의 감지값 을 바탕으로 상기 영상 획득부가 기 설정된 기준자세로 정렬되었는지를 판단하고, 정렬된 것으로 판단된 경우출력부를 통해 알림을 출력할 수 있다. 상기 스마트 퍼팅 디바이스는, 사용자로부터 소정의 명령을 입력받는 입력부를 더 포함할 수 있고, 상기 프로세 서는, 상기 알림이 출력된 후 상기 입력부를 통해 촬영 명령이 입력되면, 상기 영상 획득부를 통해 영상이 획득 되도록 제어할 수 있다. 상기 프로세서는, 상기 영상 획득부에 의해 획득된 영상을, 상기 가속도 센서의 감지값을 바탕으로 보정하고, 보정된 영상에서 상기 깃대의 길이를 구할 수 있다. 상기 프로세서는, 상피 스마트 퍼팅 디바이스가 지면에 놓인 상태에서 상기 영상 획득부를 통해 구한 제 1 획득 영상과, 상기 스마트 퍼팅 디바이스가 상기 지면으로부터 소정 거리 이격된 상태에서 구한 제 2 획득영상을 바 탕으로 상기 고저차를 구할 수 있다. 상기 스마트 퍼팅 디바이스는, 상기 고저차 및 상기 수평 거리 중 적어도 하나를 출력하는 출력부와, 골프 퍼터 용 퍼터 헤드를 더 포함할 수 있다. 상기 프로세서, 영상 획득부 및 출력부는 상기 퍼터 헤드에 배치될 수 있다. 상기 스마트 퍼팅 디바이스는, 가속도 센서와, 상기 고저차 및 수평 거리에 대한 정보를 무선으로 전송하는 무 선통신모듈을 더 포함할 수 있다. 상기 가속도 센서 및 상기 무선통신모듈은 상기 퍼터 헤드에 배치될 수 있다. 상기 스마트 퍼팅 디바이스는, 상기 고저차 및 상기 수평 거리 중 적어도 하나를 출력하는 출력부와, 골프 퍼터 용 퍼터 헤드를 더 포함할 수 있다. 상기 영상 획득부는 상기 퍼터 헤드에 배치될 수 있다. 상기 스마트 퍼팅 디바이스는, 상기 퍼터 헤드와 분리된 것으로서, 상기 프로세서 및 상기 출력부를 포함하는 서브 디바이스를 더 포함할 수 있다. 상기 스마트 퍼팅 디바이스는, 상기 퍼터 헤드에 배치되고 상기 영항 획득부에 의해 획득된 영상을 무선으로 전 송하는 제 1 무선통신모듈과, 상기 서브 디바이스에 배치되고, 상기 제 1 무선통신모듈과 통신하는 제 2 무선통 신모듈을 더 포함할 수 있다. 본 발명의 다른 측면에 따르면, 스마트 퍼팅 디바이스는, 홀이 위치한 지점에서 공의 영상을 획득하는 영상 획 득부와, 상기 영상 획득부에 의해 획득된 영상에서 상기 공을 식별하여, 상기 공과 상기 홀 간의 고저차 및 상 기 공의 너비를 구하고, 상기 고저차 및 상기 공의 너비를 바탕으로 상기 공까지의 수평 거리를 구하는 프로세 서를 포함한다. 상기 스마트 퍼팅 디바이스는, 볼마커를 더 포함할 수 있고, 상기 영상 획득부 및 상기 프로세서는 상기 볼마커 에 배치될 수 있다. 상기 스마트 퍼팅 디바이스는, 상기 고저차 및 상기 수평 거리 중 적어도 하나를 출력하는 출력부를 더 포함할 수 있다. 상기 출력부는, 상기 볼마커에 배치될 수 있다. 상기 스마트 퍼팅 디바이스는, 상기 볼마커와 분리된 서브 디바이스를 더 포함할 수 있고, 상기 출력부는, 상기 서브 디바이스에 배치될 수 있다. 상기 프로세서는, 인공지능 기반의 객체 탐지 알고리즘을 이용하여 상기 영상으로부터 상기 홀과 상기 깃대를 식별할 수 있다. 상기 프로세서는, 상기 영상에 표현된 색상을 분석하여 상기 홀과 상기 깃대를 식별할 수 있다. 본 발명의 또 다른 측면에 따르면, 스마트 퍼팅 디바이스는, 수평 방향으로 소정 거리 이격된 제 1 카메라 및 제 2 카메라를 구비한 영상 획득부와, 상기 영상 획득부가 같은 위치에 있는 상태에서 상기 제 1 카메라에 의해 촬영된 제 1 획득 영상과, 상기 제 2 카메라에 의해 촬영된 제 2 획득 영상을 바탕으로 퍼팅 위치에 대한 홀의 고저차 및 상기 퍼팅 위치에서 상기 홀까지의 수평 거리를 산출하는 프로세서를 포함한다. 본 발명의 또 다른 측면에 따르면, 스마트 퍼팅 디바이스는, 수평 및 수직 방향으로 소정 거리 이격된 제 1 카 메라 및 제 2 카메라를 구비한 영상 획득부와, 상기 영상 획득부가 같은 위치에 있는 상태에서 상기 제 1 카메 라에 의해 촬영된 제 1 획득 영상과, 상기 제 2 카메라에 의해 촬영된 제 2 획득 영상을 바탕으로 퍼팅 위치에대한 상기 홀의 고저차 및 상기 퍼팅 위치에서 상기 홀까지의 수평 거리를 산출하는 프로세서를 포함한다. 본 발명의 스마트 퍼팅 디바이스를 이용한 퍼팅거리 측정방법은, (a) 영상 획득부에 의해 전방의 영상이 획득되 는 단계와, (b) 상기 영상을 바탕으로 퍼팅거리를 구하는 단계와, (c) 상기 퍼팅거리를 출력부를 통해 출력하는 단계를 포함한다. 상기 (a)단계는, (a-1) 가속도 센서의 감지값을 바탕으로 스마트 퍼팅 디바이스가 기 설정된 기준자세로 정렬되 었는지를 판단하는 단계와, (a-2) 상기 (a-1)단계에서 상기 스마트 퍼팅 디바이스가 상기 기준자세로 정렬된 것으로 판단된 경우 출력부를 통해 알림을 출력하는 단계와, (a-3) 상기 알림이 출력된 후 입력부를 통해 소정의 명령이 입력되면, 상기 영상 획득부에 의해 상기 영상이 획득되는 단계를 더 포함할 수 있다. 상기 (b)단계는, 상기 영상에서 깃대를 식별하여, 식별된 깃대의 길이를 바탕으로 상기 스마트 퍼팅 디바이스로 부터 상기 홀까지의 수평 거리를 구하는 단계를 포함할 수 있다. 상기 (c)단계는, 상기 수평 거리를 상기 퍼팅거리로서 상기 출력부를 통해 출력하는 단계를 포함할 수 있다. 상기 (b)단계는, 상기 영상에서 퍼팅위치에 대한 상기 홀의 고저차를 구하고, 상기 고저차 및 상기 깃대의 높이 를 바탕으로 상기 수평 거리를 구하는 단계를 더 포함할 수 있다. 상기 출력부를 통해 상기 고저차를 출력하는 단계를 더 포함할 수 있다. 상기 (a)단계는, 상기 스마트 퍼팅 디바이스가 지면에 놓인 상태에서 상기 영상 획득부를 통해 제 1 획득영상을 구하는 단계와, 상기 스마트 퍼팅 디바이스를 지면으로부터 소정의 상승 높이까지 들어 올린 상태에서 상기 영 상 획득부를 통해 제 2 획득영상을 구하는 단계를 포함할 수 있고, 상기 (b)단계는, 상기 제 2 획득영상에서 구 한 상기 홀의 높이 및 상기 제 1 획득영상과 상기 제 2 획득영상을 바탕으로 구한 상기 상승 높이를 바탕으로 상기 고저차를 구하는 단계를 포함할 수 있다. 상기 (b)단계는, 상기 영상에서 공을 식별하여, 식별된 공의 너비를 바탕으로 상기 공으로부터 상기 홀까지의 수평 거리를 구하는 단계를 포함할 수 있고, 상기 (c)단계는, 상기 수평 거리를 상기 퍼팅거리로서 상기 출력부 를 통해 출력하는 단계를 포함할 수 있다. 상기 (b)단계는, 상기 영상에서 상기 공과 상기 홀 간의 고저차를 구하고, 상기 고저차 및 상기 공의 너비를 바 탕으로 상기 수평 거리를 구하는 단계를 포함할 수 있다. 상기 퍼팅거리 측정 방법은, 상기 출력부를 통해 상기 고저차를 출력하는 단계를 더 포함할 수 있다. 상기 (a)단계는, 공과 상기 홀을 연결하는 직선을 기준으로 양쪽에서 각각 제 1 획득영상과 제 2 획득영상을 구 하는 단계와, 상기 제 1 획득영상과 상기 제 2 획득영상을 바탕으로 퍼팅 방향을 설정하여 상기 출력부를 통해 표시하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-7017603", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 스마트 퍼팅 디바이스 및 이를 이용한 퍼팅거리 측정 방법은, 획득영상을 바탕으로 구한 깃대의 길이를 바탕으로 홀까지의 거리를 산출하기 때문에 종래 홀컵을 촬영하여 퍼팅거리를 계산하던 방 식과 비교하여, 지면 굴곡의 영향을 덜 받을 뿐만 아니라, 카메라를 퍼터 헤드에 위치하더라도 깃대를 촬영하여 퍼팅거리를 산출할 수 있어 퍼터 무게 중심을 낮추는데 유리한 효과가 있다. 또한, 퍼터와 깃대 사이에 언덕이 있어 깃대의 하단 일부가 촬영되지 못하는 경우에도, 통상적인 퍼팅 환경에서 는 깃대의 전체 길이에 비해 가려지는 부분이 미미하기 때문에, 깃대 길이를 바탕으로 퍼팅거리를 산출하더라도 비교적 높은 정확도를 구현하는 것이 가능하다. 특히, 종래 홀컵을 촬영하여 퍼팅거리를 산출하는 방식에서는 불가능한 그린 굴곡에서도 상당한 정확도의 퍼팅거리를 구할 수 있는 이점이 있다. 본 발명의 일 실시예에 따른 스마트 퍼팅 디바이스 및 이를 이용한 퍼팅거리 측정 방법은, 지면에 놓인 공을 촬 영하여 공의 너비를 구하고, 이를 바탕으로 퍼팅거리를 산출하는 방식이다. 따라서, 공이 홀보다 낮은 위치(즉, 오르막 라이)인 경우에도 퍼터를 홀의 위치에 두고 공을 촬영할 수 있어 오르막 라이에서도 퍼팅거리를 구할 수 있다. 또한, 공이 홀보다 높은 내리막 라이에서는 퍼터를 홀의 위치에 두고 공을 촬영하는 경우 공의 아랫부분이 부분 적으로 지면에 가려질 수는 있으나, 그렇다고 하더라도 통상적인 그린의 굴곡이나 퍼팅거리에서 지면이 공의 중 앙부분까지 가리지는 않기 때문에 특별한 경우가 아닌 한 공의 너비 측정이 가능하다. 따라서, 내리막 라이에서도 우수한 거리 측정 성능이 보장되는 효과가 있다. 또한, 본 발명의 스마트 퍼팅 디바이스는 종래 홀컵을 촬영하여 퍼팅거리를 계산하던 방식과 비교하여, 지면 굴 곡의 영향을 덜 받을 뿐만 아니라, 카메라를 퍼터 헤드에 위치하더라도 깃대를 촬영하여 퍼팅거리를 산출할 수 있어 퍼터 무게 중심을 낮추는데 유리한 효과가 있다. 또한, 본 발명의 스마트 퍼팅 디바이스는, 퍼팅거리를 구하기 위한 영상을 촬영하는 카메라를 퍼터 헤드에 구비 할 수 있기 때문에 퍼터의 무게 중심이 퍼터 헤드 측에 유지될 수 있어, 사용자에게 일반적인 퍼터와 매우 유사 한 스윙 밸런스를 제공할 수 있는 효과가 있다. 또한, 일반적으로 퍼터는 그 종류에 따라 샤프트의 길이, 샤프트가 지면과 이루는 각도(라이각(lie angle)) 등 이 다르기 때문에, 종래와 같이 샤프트에 카메라를 설치하는 경우 해당 퍼터에 맞도록 카메라를 튜닝하여야 하 다. 그러나, 본 발명의 스마트 퍼팅 디바이스는 지면과 맞닿는 퍼터 헤드에 카메라가 설치됨으로써 영상이 구해 지는 기준이 일정하기 때문에(즉, 지면과 매우 근접한 위치에서 영상이 획득됨), 퍼터를 여러 규격으로 제조하 더라도 규격별로 카메라 튜닝작업을 할 필요 없이 하나의 공통된 방식으로 튜닝하여도 무방하다. 따라서, 본 발 명의 스마트 퍼팅 디바이스는 제품의 개발, 생산 관리 등의 측면에서 유리할 뿐만 아니라, 더 나아가 유지, 보 수 차원에서도 효율적인 이점이 있다."}
{"patent_id": "10-2023-7017603", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도 록 하고, 본 발명이 속"}
{"patent_id": "10-2023-7017603", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발 명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 도 1은 본 발명의 스마트 퍼팅 디바이스와, 이를 포함하는 스마트 퍼팅 시스템을 도시한 것이다. 도 2 는 도 1의 스마트 퍼팅 디바이스의 주요 구성들 간의 제어관계를 도시한 블록도이다. 도 1 내지 도 2를 참조하면, 본 발명의 일 실시예에 따른 스마트 퍼팅 시스템은 스마트 퍼팅 디바이스 와 모바일 디바이스를 포함할 수 있다. 스마트 퍼팅 디바이스와 모바일 디바이스는 상호 간에 무선 통신 방식으로 데이터를 교환할 수 있다. 스마트 퍼팅 디바이스에 의해 처리된 결과가 무선 통신을 통해 모바일 디바이스로 전송되고, 모바일 디바이스는 전송받은 정보를 사용자가 인지할 수 있도록 출력할 수 있다. 모바일 디바이스는, 무선 통신 기능을 갖춘 것으로서, 정보를 시각, 청각 및/또는 촉각(예를 들어, 햅틱 (haptic)) 방식으로 출력하는 기기일 수 있으며, 예를 들어, 블루투스 이어폰이나 스마트폰일 수 있으나, 반드 시 이에 한정되어야 하는 것은 아니다. 모바일 디바이스는 무선 통신 기능을 위한 무선통신모듈을 구비할 수 있으며, 상기 무선통신모듈은, 반드 시 이에 한정되어야 하는 것은 아니나, 근거리 무선통신모듈(예를 들어, 블루투스, 비콘, NFC 등), 무선 인터넷 모듈(예를 들어, WiFi) 중 적어도 하나를 포함할 수 있다. 스마트 퍼팅 디바이스는, 영상 획득부, 프로세서, 가속도 센서, 입력부, 충전 배터리, 충전부, 메모리 및/또는 출력부를 포함할 수 있다. 영상 획득부는 디지털 이미지를 촬영하는 카메라(5a, 도 5 참조)를 포함할 수 있다. 영상 획득부(또는 카 메라(5a))는 하나 이상의 정지 영상 또는 소정 주기로 촬영한 다수의 정지 영상들로 구성된 동영상을 촬영할 수 있다. 프로세서는 영상 획득부에 의해 획득된 영상(이하, '획득영상'이라고 함.)을 바탕으로 공으로부터 홀 까지의 수평 거리(이하, '퍼팅거리'라고 함.)를 구할 수 있다. 프로세서는 퍼팅거리가 출력부를 통해 출력되도록 제어할 수 있다. 프로세서는 영상 획득부와 출력부 뿐만 아니라, 후술하는 각종 장치들을 제어한다. 프로세서는 전 자적 기록매체에 기록된 프로그램의 연산을 실행, 처리하는 제어 장치 또는 그 기능을 내장한 칩일 수 있고, 중 앙연산처리장치(CPU)를 포함할 수 있다. 출력부는 정보를 시각적으로 표시하는 LCD, LED 등의 디스플레이, 음향으로 출력하는 스피커 및 네 트워크로 전송 가능한 전기적 신호로써 출력하는 무선통신모듈 중 적어도 하나를 포함할 수 있다. 무선통신모듈은 네트워크를 통해 다른 디바이스, 예를 들어, 블루투스 이어폰이나 스마트폰과 통신이 가능하다. 무선통신모듈은 근거리 무선통신모듈(예를 들어, 블루투스, 비콘, NFC 등), 무선 인터넷 모듈(예 를 들어, WiFi) 중 적어도 하나를 포함할 수 있다. 가속도 센서는 x, y, z축으로 작용하는 중력을 측정하는 센서일 수 있다. 여기서, x, y, z축은, 스마트 디 바이스를 기준으로 구성된 상대좌표계로 정의하였다. 입력부는, 스마트 퍼팅 디바이스의 작동에 필요한 각종 명령을 사용자로부터 입력 받는 것일 수 있다. 입력부는 버튼, 스위치, 터치 패널 등의 각종 입력 수단으로 구현될 수 있으며, 실시예에 따라, 모바일 디 바이스가 입력부를 구성하는 것도 가능하다. 충전 배터리는, 스마트 퍼팅 디바이스의 작동에 필요한 전원을 공급하는 것으로써 일회용 또는 재충전 이 가능한 전지를 포함할 수 있다. 충전 배터리를 충전하기 위해 외부 전원과 연결되는 충전부가 구비될 수 있다. 충전부는 충전 배터 리를 충전 및/또는 방전시키는 회로를 포함할 수 있다. 충전부는 USB(A, B, C type, micro type 등), 마이크로 5핀, 라이트닝 8핀 등의 단자를 포함할 수 있으며, 이에 한정되지 않고 기 공지된 다양한 방식의 단자 를 포함하는 것도 가능하다. 메모리는 데이터(또는, 정보)를 저장하는 기록수단으로써, 휘발성, 비휘발성, ROM, RAM, EEPROM, 플래시 메 모리 등을 포함할 수 있으며, 이에 한정되지 않고 기 공지된 다양한 방식의 메모리를 포함하는 것도 가능하다. 출력부는 프로세서에 의해 처리된 결과를 출력하는 것으로, 정보를 시각적으로 표시하는 LCD, LED 등의 디스플레이, 음향으로 출력하는 스피커 및 네트워크로 전송 가능한 전기적 신호로써 출력하는 무선통신 모듈 중 적어도 하나를 포함할 수 있다. 도 3은 본 발명의 제 1 실시예에 따른 스마트 퍼팅 디바이스(100a)의 주요부들을 보인 블록도이다. 도 3을 참조 하면, 본 발명의 제 1 실시예에 따른 스마트 퍼팅 디바이스(100a)는, 도 2에 도시된 여러 장치들 중 적어도 영 상 획득부, 가속도 센서 및 무선통신모듈을 구비한 제 1 서브 디바이스와, 도 2에 도시된 여러 장치들 중 적어도 프로세서와 디스플레이를 구비한 제 2 서브 디바이스를 포함할 수 있다. 제 1 서브 디바이스와 제 2 서브 디바이스는 하나의 장치에 배치되되, 하나의 장치 상에서는 물리적 으로는 서로 분리 배치되는 것을 특징으로 한다. 즉, 제 1 서브 디바이스는 영상 획득부, 가속도 센서 및 무선통신모듈의 집합체 또는 조립체로 이루어지고, 제 2 서브 디바이스는 프로세서와 디스 플레이의 집합체 또는 조립체로 이루어져, 제 1 서브 디바이스와 제 2 서브 디바이스 서로 간에 전기적으로는 연결되되 물리적 또는 공간상으로는 분리 또는 구분되도록 구성될 수 있다. 예를 들어, 영상 획득부, 가속도 센서 및 무선통신모듈은 제 1 PCB(Printed Circuit Board: 인쇄회 로기판)에 실장되고, 프로세서와 디스플레이는 제 2 PCB에 실장될 수 있다. 한편, 실시예에서, 충전 배터리는 제 1 서브 디바이스에 구비되나, 반드시 이에 한정되어야 하는 것은 아니고, 제 2 서브 디바이스에 구비되는 것도 가능하다. 도 4는 도 3의 스마트 퍼팅 디바이스의 일례로 퍼터(100a1)를 도시한 것으로, 도 4의 (a)는 퍼터를 위에서 내려 다본 것이고, 도 4의 (b)는 퍼터를 정면에서 바라본 것이다. 도 4를 참조하면, 본 발명의 실시예에 따른 스마트 퍼팅 디바이스(100a)는 퍼터(100a1)일 수 있다. 퍼터 (100a1)는 퍼터 헤드, 샤프트, 그립, 영상 획득부, 프로세서, 출력부를 포함할 수 있다. 퍼 터 헤드는 골프 공과 접촉되는 타구면을 형성한다. 이하, 타구면이 대향하는 방향을 전방으로 정의한다. 퍼터 헤드는 그 형태가 어느 한 가지로 한정되어야 하는 것은 아니다. 예를 들어, 퍼터 헤드는 블레이드 (blade)형 또는 말렛(mallet)형 중 어느 것도 무방하다. 샤프트는 퍼터 헤드로부터 상측으로 연장된다. 샤프트의 상단에는 그립이 끼워질 수 있다. 그립 의 상단에는 입력부가 구비될 수 있다. 퍼터 헤드는 샤프트의 하단에 결합될 수 있다. 통상의 퍼터와 마찬가지로 퍼터 헤드는 공구를 이용하 여 샤프트로부터 분리될 수 있다. 바람직하게는, 제 1 서브 디바이스와 제 2 서브 디바이스는 퍼 터 헤드에 구비될 수 있다. 도 5는 본 발명의 다른 실시예에 따른 퍼터(100a2)를 도시한 것이다. 도 6은 본 발명의 또 다른 실시예들에 따 른 퍼터들(100a3, 100a4)을 도시한 것이다. 도 5를 참조하면, 실시예에 따른 퍼터(100a2)에서, 퍼터 헤드는 전면에 개구부를 갖는 수용실(M)을 형성하는 헤드 하우징과, 상기 개구부에 삽입되며 타구면(41, 도 4 참조.)을 형성하는 타구면 형성체를 포함할 수 있다. 영상 획득부는, 수용실(M) 내에 배치되어 영상을 획득하는 카메라(5a)를 포함할 수 있다. 타구면 형성체 의 전면 또는 타구면을 형성하는 면에는 카메라(5a)의 렌즈(미도시)와 대응하는 개구부 또는 시창이 형성될 수 있다. 상기 시창에는 렌즈 보호를 위한 투명한 쉴드(shield, 6)가 구비될 수 있다. 쉴드는 강화 유리일 수 있다. 실시예에 따라 카메라(5a)는 수용실(M)의 외측에 배치될 수도 있다. 예를 들어, 도 6의 (a)에 도시된 바와 같이, 카메라(5a)는 퍼터 헤드의 토우(toe)측에 구비되거나, 도 6의 (b)에 도시된 바와 같이 퍼터 헤드의 상측에 구비될 수 있다. 더 나아가, 카메라(5a)는 평시에는 수용실(M) 내에 수용되어 있다가, 사용자의 수동 조 작에 의해 또는 입력부를 통한 제어 명령의 입력에 따라 자동으로 수용실(M)로부터 인출되도록 구성될 수도 있다. 프로세서는 수용실(M)에 배치될 수 있다. 그리고, 수용실(M)에는 가속도 센서, 충전 배터리, 메모리 및 충전부 중 적어도 하나가 더 구비될 수 있다. 다르게는, 실시예에 따라 가속도 센서, 충전 배터리, 메모리 및 충전부 중 적어도 하나는 샤프 트나 그립에 구비되는 것도 가능하다. 가속도 센서는 x, y, z축으로 작용하는 중력을 측정하는 센서일 수 있다. 여기서, x, y, z축은, 예시적으로 도 6에 도시된 바와 같이 퍼터 헤드를 기준으로 구성된 상대좌표계로 정의하였다. 퍼터(100a) 또는 퍼터 헤드의 자세는 개개인의 셋업 방식이나, 깃대와 퍼팅 지점 간의 고저차에 따라 쉽게 달라질 수가 있다. 거리 산출을 위해 필요한 획득 영상은 퍼터(100a) 또는 퍼터 헤드가 기 설정된 자세로 정 렬되었을 시 구해진 것일 필요가 있다. 실시예에서 프로세서는, 가속도 센서에 의한 감지 결과를 바탕으 로 퍼터 헤드가 기 설정된 방향으로 정렬되었는지, 즉, 기준자세인지를 판단하고, 기준자세로 판단된 경우 알림신호를 출력한다. 그리고, 상기 알림신호에 따라 출력부는 알림을 출력할 수 있다. 상기 알림을 인지한 사용자가 입력부를 통해 촬영 명령을 입력하면 카메라(5a)에 의해 촬영이 이루어져 영상이 획득될 수 있다. 디스플레이가 구비되는 경우, 디스플레이의 화면은 퍼터 헤드의 상면을 구성할 수 있다. 상기 화면 에는 퍼팅거리(D1)가 표시될 수 있다. 실시예에 따라, 퍼팅거리(D1)는 스마트 퍼팅 디바이스로부터 홀까지의 수평거리, 즉, 3차원 공간 상에 서 스마트 퍼팅 디바이스로부터 홀을 직선으로 연결한 선을 수평면 상에 정투영하였을 시의 길이로 정 의될 수 있다. 다르게는, 퍼팅거리는, 도 19에 도시된 바와 같이, 홀로부터 공까지의 수평거리, 즉, 3차원 공간 상에 서 스마트 퍼팅 디바이스로부터 공을 직선으로 연결한 선(이때, 스마트 퍼팅 디바이스는 홀 과 실질적으로 동일한 지점에 위치한 상태임)을 수평면 상에 정투영하였을 시의 길이(D1)로 정의될 수 있다. 또한, 프로세서는 영상 획득부에 의해 획득된 영상(이하, '획득영상'이라고 함)을 바탕으로 홀과 퍼 팅지점 간의 고저차(H2)를 구하고, 이렇게 구해진 고저차(H2)가 퍼팅거리(D1)와 함께 출력부를 통해 출력되 도록 제어할 수 있다. 상기 퍼팅지점은 스마트 퍼팅 디바이스 또는 공의 위치일 수 있다. 한편, 도 5를 참조하면, 디스플레이는, 프로세서의 제어에 의해, 퍼팅 지점과 홀 간의 높이차 또는 고저차(H2, 도 13 참조.) 및/또는 퍼팅 방향(E) 등을 더 표시할 수 있다. 도 7은 도 3의 스마트 퍼팅 디바이스의 다른 예로 볼마커(100a5)를 도시한 것이다. 볼마커(100a5)는 집어 올릴 볼(공)의 지점을 마크하기 위해 코스 상에 놓아두는 인공물로 정의될 수 있다. 본 발명의 스마트 퍼팅 디바이스 는 볼마커(100a5)일 수 있다. 볼마커(100a5)는 제 1 서브 디바이스와 제 2 서브 디바이스를 포 함할 수 있다. 제 2 서브 디바이스가 수평한 바닥에 놓인 상태에서, 제 1 서브 디바이스에 구비된 카메라(5a)는 렌 즈의 주축이 수평 방향으로 정렬되도록 구성될 수 있다. 제 1 서브 디바이스와 제 2 서브 디바이스는 실질적으로 전술한 실시예들(100a1 내지 100a4)에 적용 된 것과 동일하므로 설명을 생략한다. 도 8은 본 발명의 제 2 실시예에 따른 스마트 퍼팅 디바이스(100b)의 주요부들을 보인 블록도이다. 도 9는 도 8 의 스마트 퍼팅 디바이스(100b)의 일례를 도시한 것이다. 도 8 내지 도 9를 참조하면, 실시예에 따른 스마트 퍼팅 디바이스(100b1)는 퍼터를 포함할 수 있는데, 도 4 내 지 도 6을 참조하여 전술한 퍼터(100a1, 100a2, 100a3, 100a4)와는 다르게 제 1 서브 디바이스만이 퍼터 헤드에 구비되고, 제 2 서브 디바이스는 퍼터와는 분리된 별도의 디바이스를 구성한다. 제 2 서브 디바이스는, 제 1 서브 디바이스에 구비된 제 1 무선통신모듈과 무선 통신이 가능한 제 2 무선통신모듈(미도시)과, 상기 제 2 무선통신모듈과 프로세서의 동작에 필요한 전원을 공급하기 위한 별도의 충전 배터리(미도시)를 포함할 수 있다. 제 1 서브 디바이스의 영상 획득부에 의해 획득된 영상 데이터가 무선 통신을 통해 제 2 서브 디바이스 의 프로세서에 입력될 수 있다. 실시예에 따라, 제 2 서브 디바이스는 퍼터 헤드에 착탈되는 방식으로 구성될 수 있으며, 이 경우, 사 용자의 선택에 따라 제 2 서브 디바이스는 퍼터 헤드에 설치된 상태에서 동작하거나, 퍼터 헤드로부 터 분리된 상태에서 동작할 수 있다. 한편, 제 2 서브 디바이스에서 처리된 퍼팅 정보(예를 들어, 고저차나 퍼팅거리)는 모바일 디바이스 로 전송될 수 있다. 다르게는, 제 2 서브 디바이스 대신 모바일 디바이스(200, 도 1 참조.)가 그 기능을 대신할 수도 있다. 도 10은 도 8의 스마트 퍼팅 디바이스(100b)의 다른 예를 도시한 것이다. 도 10을 참조하면, 실시예에 따른 스 마트 퍼팅 디바이스(100b2)는 볼마커를 구성하는 제 1 서브 디바이스와, 상기 볼마커와는 분리된 별도의 디바이스를 구성하는 제 2 서브 디바이스를 포함할 수 있다. 제 2 서브 디바이스는, 제 1 서브 디바이스에 구비된 제 1 무선통신모듈과 무선 통신이 가능한 제 2 무선통신모듈(미도시)과, 상기 제 2 무선통신모듈과 프로세서등의 동작에 필요한 전원을 공급하기 위한 별도의 충전 배터리를 포함할 수 있다. 제 1 서브 디바이스의 영상 획득부에 의해 획득된 영상 데이터가 무선 통신을 통해 제 2 서브 디바이스 의 프로세서에 입력될 수 있다. 실시예에 따라, 제 2 서브 디바이스는 상기 볼마커에 착탈되는 방식으로 구성될 수 있으며, 이 경우, 사용 자의 선택에 따라 제 2 서브 디바이스는 상기 볼마커에 설치된 상태에서 동작하거나, 상기 볼마커로부터 분리된 상태에서 동작할 수 있다. 제 2 서브 디바이스는 모바일 디바이스와 통신 가능하게 구비될 수 있다. 이 경우, 제 2 서브 디바이 스의 프로세서에 의해 처리된 퍼팅 정보가 모바일 디바이스로 전송된 후 사용자가 인지할 수 있는 형태로 출력될 수 있다. 한편, 전술한 본 발명의 실시예들에 따른 스마트 퍼팅 디바이스는 획득영상으로부터 구한 깃대에 대한 정보를 바탕으로 퍼팅거리(D1)를 산출할 수 있다. 이하, 도 11 내지 도 14를 참조하여 퍼팅거리(D1)를 구하는방법을 설명한다. 이하, 스마트 퍼팅 디바이스가 퍼터를 포함하여 구성되는 것을 기준으로 설명하나, 후술하는 설명은 스마 트 퍼팅 디바이스가 볼마커를 포함하여 구성되는 경우에도 실질적으로 동일하게 적용될 수 있다. 도 11은 수평한 지면에서 구한 것들로써 스마트 퍼팅 디바이스로부터 홀까지의 거리에 따른 획득영상들을 도시 한 것이다. 도 12는 스마트 퍼팅 디바이스가 기준자세가 아닌 상태에서 구한 깃대 이미지와 기준자세로 조정된 상태에서 구한 깃대 이미지를 비교하여 도시한 것이다. 도 13은 (a)는 획득영상에서 보이는 홀과 깃대의 위치를 카메라가 제 1 위치에 있을 시 구한 것과 제 2 위치에 있을 시 구한 것을 비교하여 보인 것이고, (b)는 상기 제 1 위치에서의 카메라, 홀 및 깃대의 위치관계를 도시한 것이고, (c)는 상기 제 2 위치에서의 카메라, 홀 및 깃 대의 위치관계를 도시한 것이다. 도 14는 카메라가 기준자세에 있을 시에 촬영한 획득영상에서, 카메라로부터 홀컵까지의 거리에 대한 깃대 상단의 좌표를 고저차 별로 도시한 것이다. 도 11 내지 도 14를 참조하면, 퍼터 헤드로부터 깃대까지의 수평 거리, 즉, 퍼팅거리(D1)는 획득영상에 표시된 홀과 깃대에 대한 정보로부터 구해질 수 있다. 이하, 도면에서 21'과 22'는 각각 획득영상에 나 타난 홀과 깃대의 이미지를 지시한다. 구체적으로, 프로세서는 획득영상에서 홀과 깃대에 각각 대응하는 특징들을 검출하고, 검출된 특징 들을 바탕으로 깃대 상단의 좌표 및/또는 홀로부터 깃대의 상단까지의 길이(이하, '깃대 길이'라고 함.)를 구할 수 있다. 영상에서 객체를 탐지하는 것(object detection)은 SIFT(Scale Invariant Feature Transformation), HOG(Histogram of Oriented Gradient), LBP(Local Binary Pattern), Harr-like features, ORB(Oriented FAST and Rotated BRIEF) 등의 여러 방식이 알려져 있다. 이 밖에도 최근에 활발한 연구가 이루어지고 있는 딥러닝 (deep learning) 등의 인공지능 기반의 객체 탐지 알고리즘도 유용하다. 프로세서는 이러한 기 공지된 객체 탐지 알고리즘을 이용하여 획득영상에서 홀 및/또는 깃대를 검출할 수 있다. 도 11을 참조하면, 프로세서는, 획득영상에서 홀과 깃대를 검출한 것으로부터 깃대 상단의 좌표 (y1), 홀로부터 깃대의 상단까지의 길이(즉, 깃대 길이(h1')), 홀의 위치(h2') 중 적어도 하나를 구하고, 이렇게 구해진 값들을 바탕으로 퍼팅거리(D1)를 결정할 수 있다. 획득영상은, 바람직하게는, 퍼터가 기준자세인 상태에서 카메라(5a)에 의해 촬영된 것이다. 프로세서는 가속도 센서의 감지값을 바탕으로 현재 퍼터가 기준자세로 정렬된 상태인지 여부를 결정할 수 있다. 예를 들어, 기준자세는 가속도 센서의 y축(도 6 참조)이 중력방향으로 정렬된 상태로 정의될 수 있고, 이 경우, 프로세서는 가속도 센서의 x축 값 및 z축 값이 실질적으로 0인 경우 퍼터가 기준자세인 것으 로 판단할 수 있다. 다르게는, 프로세서는 가속도 센서의 x축 및 z축 측정값들의 크기가 기 설정된 기준값 이내인 경우 퍼터 가 기준자세인 것으로 판단할 수 있다. 이 경우, 프로세서는 획득영상에서 가속도 센서의 상기 측정 값에 대응하는 x, y, z 축에 회전각을 보정하여 깃대와 홀에 대한 정보를 구하고, 이를 바탕으로 퍼팅 거리(D1)를 산출할 수 있다. 한편, 도 11에서 보이는 바와 같이, 획득영상에서의 깃대 길이는 카메라(5a) 로부터의 거리(D1')에 대해 비선형 적으로 변화한다. 실험에 의해 미리 거리(D1')별 깃대 길이 정보가 구축되어 메모리에 저장될 수 있으며, 프로세서는 메모리에 저장된 상기 거리(D1')별 깃대 길이 정보와 획득 영상에서 검출한 깃대 길이(h1', 도 11 내지 도 12 참조)를 바탕으로 퍼팅거리(D1)를 결정할 수 있다. 수평한 지면에 홀과 카메라(5a)가 위치하는 경우 거리 D1'가 퍼팅거리(D1)가 되나, 홀과 카메라(5a) 간 에 고저차가 있는 경우에는 거리(D1')을 수평면 상에 정사영한 거리 D1이 퍼팅거리가 된다. 거리(D1')에 대한 깃대 길이 정보는 실제 깃대의 길이별로 저장된 것을 수 있다. 즉, 깃대로부터 같은 거리로 떨어진 지점에서 촬영을 하더라도 실제 깃대의 규격(길이)에 따라 획득영상에서 보이는 깃대의 길이가 다를 것 이기 때문에, 깃대의 규격에 따라 거리(D1')별 깃대 길이 정보를 구축할 필요가 있는 것이다. 도 13 내지 도 14를 참조하면, 퍼터 헤드와 홀 사이에 고저차(H2)가 있는 경우, 프로세서는 획득영상 에서 깃대(22b)의 길이(h1', 이하, '깃대 길이'라고 함)와 홀의 높이(h2', 이하, '홀 높이'라고 함)를 구하 고, 이들을 바탕으로 퍼팅거리(D1)를 산출할 수 있다.도 14에 도시된 바와 같이, 카메라(5a)가 기준자세에 있을 시에 촬영한 획득영상들에 근거하여, 카메라(5a)로부 터 홀까지의 거리(그래프에서 X축)에 대한 깃대 상단의 좌표(그래프에서 Y축)가 고저차 별로 구해지고, 이 렇게 구해진 데이터가 메모리에 미리 저장되어 있을 수 있다. 이러한 데이터는 또한 깃대의 규격(즉, 실제 깃대의 길이)별로 분류되어 저장된 것일 수 있다. 한편, 획득영상에서 깃대 상단의 높이(y1)는 깃대 길이(h1')와 홀 높이(h2')를 합한 값이기 때문에, 실시예에 따라, 프로세서는 획득영상에서 상단의 높이(y1)와 홀의 높이(h2')를 구한 후, 두 값의 차(y1-h2')로부터 깃 대 길이(h1')을 구할 수 있다. h1'과 h2'가 구해지면, 프로세서는 이들 값들과 앞서 설명한 메모리에 저장된 데이터를 바탕으로 거리 (D1'), 실제 고저차(H2)와 퍼팅거리(D1)를 산출할 수 있다. 도 14는 홀 높이(H2')가 0.3m이고, 깃대 상단의 높이가 y1인 경우 메모리에 저장된 데이터를 바탕으로 거리 (D1')를 구하는 것을 예시적으로 보여주고 있으며, 이러한 과정을 식으로 표현하면 다음과 같다. D1'= f1(h1', h2') ....... H2'= f2(h1', h2') ....... D1 = f3(D1', H2') ....... 한편, 도 15는 (a)퍼터 헤드가 바닥에 있을 때와, (b)바닥으로부터 들어 올려졌을 때를 도시한 것이다. 도 10은 (a)퍼터 헤드(또는, 마커)가 바닥에 있을 때 획득 영상에 보이는 깃대와, (b)퍼터 헤드(또는, 마커)가 바닥으로 부터 들어 올려졌을 때 획득 영상에 보이는 깃대를 도시한 것이다. 이하, 도 15 내지 도 16을 참조하여, 지면의 굴곡(예를 들어, 언덕)으로 인해 홀 또는 깃대의 하단이 보이지 않는 경우에도 홀까지의 거리와 고저차를 정확 하게 측정하는 방법을 설명한다. 한편, 도 14에는 H2'가 0보다 큰 경우를 예로 들었으나, H2'가 0보다 작은 경우의 데이터도 실험에 의해 미리 구하여 메모리에 저장할 수 있음은 물론이다. 도 15의 (a)와 같이 홀과 퍼터 헤드 사이에 언덕이 있어 획득영상(도 16의 (a) 참조.)에 홀 또는 깃 대의 하단이 보이지 않는 경우, 앞서 설명한 실시예에 따르면 깃대 길이는 획득영상에서 보이는 깃대의 중단(즉, 지면과 깃대가 만나는 지점)으로부터 상단까지의 길이를 바탕으로 구해진다. 이 경우, 언덕에 의 해 깃대가 가려지는 부분이 많아질수록 퍼팅거리(D1)의 오차가 커지게 되는 문제가 있다. 이 경우, 퍼팅거 리(D1)는 언덕에 의해 가려지지 않는 부분의 깃대 길이를 바탕으로 구해지기 때문이다. 이와 같은 문제를 보완하기 위해, 본 실시예에 따른 퍼팅거리 측정 방법은, 지면으로부터 퍼터를 들어올려 홀 또는 깃대의 하단이 보이는 상태(도 9의 (b) 참조.)에서 구한 획득영상(도 16의 (b) 참조.)을 바탕 으로 프로세서에 의해 퍼팅거리(D1)가 구해진다. 이때의 획득영상은 홀 또는 깃대의 하단(즉, 홀과 깃대가 만나는 부분)이 촬영한 것이어야 한 다. 사용자가 눈대중으로 퍼터를 적당한 높이까지 들어올려서 촬영을 할 수도 있겠으나, 실시예에 따라 퍼 터가 들어올려지는 과정에서 영상(바람직하게는, 동영상)이 촬영되고, 이 과정에서 프로세서가 영상에서 홀(21')이나 깃대(22')의 하단을 식별한 경우 출력부를 통해 알림이 출력되도록 구성되는 것도 가능하다. 상 기 알림을 확인한 사용자가 입력부를 통해 촬영 명령을 입력하면, 촬영을 통해 영상이 획득될 수 있다. 한편, 본 발명의 일 실시예에 따르면, 지면에 퍼터가 놓인 상태(도 15의 (a) 참조.)에서 구한 제 1 획득영 상(도 16의 (a) 참조.)과, 지면으로부터 퍼터를 들어올린 상태(도 15의 (b) 참조.)에서 구한 제 2 획득영상 (도 16의 (b) 참조.)을 바탕으로 고저차(H3)를 구할 수 있다. 홀과 퍼터 헤드 사이의 높이차, 즉, 고저차(H3)를 구하기 위해서는 홀 또는 깃대의 하단이 보이 는 획득영상을 구하여야 한다. 먼저, 도 15의 (b)에 도시된 바와 같이 퍼터를 들어 올린 상태에서 획득영상을 구하고, 이를 바탕으로 홀의 높이(H2)를 구한다. 홀의 높이 H2는, 도 15의 (b)에 도시된 바와 같이, 획득영상이 구해지는 시점에서의 퍼터 헤드의 위치와 홀 간의 높이차에 해당하는 것이기 때문에, 실제 퍼팅이 이루어지는 지면상의 위치(즉, 공의 위치)와 홀 간의 고저차(H3)을 구하기 위해서는, 앞서 구한 홀의 높이 H2를 퍼터를 들어 올린 높이 T를 이용하여 보정하여야 한다. 따라서, 퍼터를 들어 올린 높이 T를 구하여야 하는데, 이는 퍼터 헤드가 지면에 놓인 상태(도 15의 (a) 참조)에서 구한 제 1 획득영상(도 16의 (a))에서의 깃대(22')의 위치와 퍼터 헤드를 지면으로부터 들어올린 상태(도 15의 (b) 참조)에서 구한 제 2 획득영상(도 16의 (b))에서의 깃대(22')의 위치를 바탕으로 구해질 수 있다. 즉, 프로세서는 상기 제 1 획득영상과 상기 제 2 획득영상에서 각각 깃대(22')를 식별하고, 양 영상들의 비 교를 통해 깃대(22')의 변위(t)를 구하고, 이렇게 구한 변위(t)를 바탕으로 홀의 높이(H2)를 보정하여 최종적으 로 고저차(H3)을 구할 수 있다. 한편, 깃대(22')의 변위(t)를 바탕으로 실제로 퍼터가 들어올려진 높이(T)를 구하기 위해서는, 퍼팅거리 (D1) 별로 변위(t)와 상승 높이(T)가 매칭된 정보(이하, '퍼팅거리별 변위-상승 높이 정보'라고 함.)를 미리 알 고 있어야 하며, 이는 실험에 의해 미리 구해질 수 있는 것으로서 메모리에 기저장된 것일 수 있다. 여기서, 퍼팅거리(D1)는 퍼터 헤드로부터 홀까지의 수평거리에 해당하기 때문에 상기 제 2 획득영상으로 부터 구해질 수 있으며, 이렇게 구해진 거리 D1과 변위 t를 알면 퍼팅거리별 변위-상승 높이 정보로부터 상승 높이(T)를 구할 수 있다. 그 다음, 프로세서는 앞서 구한 높이 H2와 상승 높이 T를 바탕으로 최종적으로 고저차 H3를 구할 수 있다. (H3=H2-T) 도 17은 본 발명의 다른 실시예에 따른 스마트 퍼팅 디바이스를 이용한 퍼팅거리 측정 방법을 설명하기 위한 것으로써, 스마트 퍼팅 디바이스를 홀컵 위치에 놓고 공을 촬영한 영상을 도시한 것이다. 도 18은 스마트 퍼팅 디 바이스가 기준자세가 아닌 상태에서 구한 공의 이미지와 기준자세로 조정된 상태에서 구한 공의 이미지를 비교 하여 도시한 것이다. 도 19의 (a)는 획득영상에서 보이는 공을 카메라가 제 1 위치에 있을 시와 제 2 위치에 있 을 시를 비교하여 보인 것이고, (b)는 상기 제 1 위치에서의 카메라와 공의 위치관계를 도시한 것이고, (c)는 상기 제 2 위치에서의 카메라와 공의 위치관계를 도시한 것이다. 도 20은 카메라가 기준자세에 있을 시에 촬영 한 획득영상에서, 카메라로부터 공까지의 거리에 대한 공의 폭을 고저차 별로 도시한 것이다. 도 17 내지 도 20를 참조하면, 본 발명의 다른 실시예에 따른 스마트 퍼팅 디바이스는 획득영상에서 구한 공에 대한 정보를 바탕으로 퍼팅거리(D1)를 구할 수 있다. 여기서, 획득영상은 스마트 퍼팅 디바이스 를 실질적으로 홀의 위치에 놓고 공을 촬영해서 구한 것이다. 이하, 스마트 퍼팅 디바이스가 퍼터 를 포함하여 구성되는 것을 기준으로 설명하나, 후술하는 설명은 스마트 퍼팅 디바이스가 볼마커를 포함하 여 구성되는 경우에도 실질적으로 동일하게 적용될 수 있다. 홀로부터 공까지의 거리(D1, 도 13 참조)에 따라 공의 폭 (W1', 획득영상에서 구한 값임.)이 달라 진다. 공이 카메라(5a)로부터 멀어질수록 폭(W1')이 점점 작아지며, 이러한 변화는 미시적으로는 비선형적 이다. 전술한 실시예들에서와 마찬가지로, 퍼터가 기준자세로 정렬된 상태에서 영상이 획득되며, 도 18에서 공 (25', 획득영상에서 보이는 공)은 퍼터가 기준자세로 정렬된 상태에서 영상에서 보이는 공을 표시한 것이다. 도 18에서 h2'는 퍼터가 기준자세인 상태에서 카메라(5a)에 의해 촬영된 영상에서의 공(25')의 높이이고, w1'은 공(25')의 폭 길이를 표시한 것이다.(이하, w1'을 '공 폭'이라고 함.) 그리고, h2과 w1 은 각각 퍼터(1 0)가 기준자세로 정렬되기 전에 카메라(5a)에 의해 촬영된 영상에서의 공의 높이와 폭 길이이다. 실험에 의해 미리 거리(D1')별 공의 폭(w1)에 대한 정보가 구축되어 메모리에 저장될 수 있으며, 프로세서 는 메모리에 저장된 정보와 획득 영상에서 검출한 공 폭(w1')을 바탕으로 퍼팅거리(D1)를 결정할 수 있 다. 수평한 지면에 공과 카메라(5a)가 위치하는 경우, 도 19의 (b)에 도시된 바와 같이 거리(D1')가 퍼팅거리 (D1)가 되나, 도 19의 (c)에 도시된 바와 같이 공과 카메라(5a) 간에 고저차가 있는 경우에는 거리(D1')을 수평면 상에 정사영한 거리 D1이 퍼팅거리가 된다. 도 19 내지 도 20를 참조하면, 퍼터 헤드와 공 사이에 고저차(H2)가 있는 경우, 프로세서는 획득영상 에서 공 폭(w1')과 공 높이(h2')를 구하고, 이들을 바탕으로 퍼팅거리(D1)를 산출할 수 있다.도 20에 도시된 바와 같이, 카메라(5a)가 기준자세에 있을 시에 촬영한 획득영상들에 근거하여, 카메라(5a)로부 터 공까지의 거리(그래프에서 X축)에 대한 공 폭(그래프에서 Y축)이 고저차 별로 구해지고, 이렇게 구해진 데이터가 메모리에 미리 저장되어 있을 수 있다. 도 20에는 H2'가 0보다 큰 경우를 예로 들었으나, H2'가 0 보다 작은 경우의 데이터도 실험에 의해 미리 구하여 메모리에 저장할 수 있음은 물론이다. h2'과 w1'가 구해지면, 프로세서는 이들 값들과 앞서 설명한 메모리에 저장된 데이터를 바탕으로 거리 (D1'), 실제 고저차(H2)와 퍼팅거리(D1)를 산출할 수 있다. 도 20은 공 높이(H2')가 0.3m이고, 공 폭이 w1'인 경우 메모리에 저장된 데이터를 바탕으로 거리(D1')를 구 하는 것을 예시적으로 보여주고 있으며, 이러한 과정을 식으로 표현하면 다음과 같다. D1'= g1(w1', h1') ....... H1'= g2(w1', h1') ....... D1 = g3(D1', H1') ....... 이와 같이 획득영상에 표시된 공을 이용하여 퍼팅거리(D1)를 구하는 방식은, 지면으로부터 돌출된 형상의 공을 식별하여 정보를 얻는 것이기 때문에 지면 상에 위치한 홀을 영상에서 식별하는 것보다 정확도가 뛰어 나다. 특히, 공이 홀보다 낮은 위치에 있는 경우(즉, 오르막 라이), 공의 위치에 퍼터를 놓고 촬영을 하는 경우 홀을 식별하기기 어렵기 때문에, 종래와 같이 홀을 식별하여 거리를 산출하는 방식은 한계가 있다. 이에 반해, 동일한 조건에서 본원 발명은 퍼터를 상대적으로 지대가 높은 홀에 놓고 촬영을 하기 때문에 공을 위에서 내려다보게 되어 식별이 가능하며, 따라서 전술한 방법에 따라 퍼팅거리(D1)를 구할 수 있다. 더 나아가, 반대로 공이 홀보다 높은 위치에 있다고 하더라도, 통상적인 범위의 그린 면적, 그린에 형 성된 굴곡 또는 고저차, 공의 반지름(즉, 지면으로부터 공의 중심까지의 높이) 등을 고려할 시 대체적 으로 영상에서 공 폭(w1')이 식별 가능하므로, 내리막 라이에서도 퍼팅거리(D1)를 정확하게 측정할 수 있는 효 과가 있다. 도 21은 본 발명의 실시예들에 따른 스마트 퍼팅 디바이스를 이용한 퍼팅거리 측정 방법을 도시한 순서도이다. 도 21을 참조하면, 본 발명의 일 실시예에 따른 퍼팅거리 측정 방법은 퍼팅거리 측정 모드를 시작하는 단계 (S1), 깃대의 길이를 설정하는 단계(S2), 촬영 자세를 조정하는 단계(S3), 퍼터가 기준자세인지를 판단하는 단계(S4), S3단계의 판단 결과에 따라 퍼터가 기준자세로 정렬되었음을 알리는 단계(S5), 획득영상을 구하 는 단계(S6), 획득영상으로부터 퍼팅 정보를 산출하는 단계(S7) 및/또는 S7단계에서 산출된 퍼팅 정보를 출력하 는 단계(S8)를 포함할 수 있다. S1단계는, 퍼팅거리 측정 모드에 진입하기 위한 명령이 입력되는 단계이다. 사용자가 입력부를 통해 시작 명령을 입력할 수 있다. 입력부는 퍼터에 구비되어 사용자로부터 각종 제어 명령을 입력 받는 인터페이 스를 제공하는 것으로써, 버튼, 스위치, 터치센서, 모션센서 등의 각종 입력 수단을 포함할 수 있다. 실시예에 서, 입력부는 그립의 상단에 배치되나, 반드시 이에 한정되어야 하는 것은 아니다. S2단계는 깃대길이를 설정하는 단계이다. S1단계에서 입력부를 통한 시작 명령이 입력되면, 프로세서는 디스플레이를 통해 깃대길이(또는, 규격)를 설정할 수 있는 메뉴를 표시할 수 있다. (도 24의 (a) 참조) 사 용자는 입력부를 통해 깃대길이(즉, 현재 진행 중인 경기에 사용되고 있는 실제 깃대의 길이)를 선택할 수 있다. 디스플레이가 구비된 경우, 깃대길이를 선택할 수 있는 메뉴가 디스플레이를 통해 표시될 수 있 다. 다르게는, 스피커를 통해 깃대길이 선택에 대한 안내와 선택 현황을 중계하는 음성이 출력되는 것도 가능하 며, 이러한 음성을 네트워크로 전송하기 위한 신호가 무선통신모듈을 통해 출력되는 것도 가능하다. 한편, 앞서 도 17 내지 도 20를 참조하여 설명한 공에 대한 정보를 이용하는 방식의 스마트 퍼팅 디바이스 에서는 S2단계는 필요치 않으므로 생략될 수 있다. S3단계에서는 기준자세로 정렬하기 위해 사용자가 퍼터를 움직이게 되고, 이 과정에서 가속도 센서에 의한 측정이 이루어진다. 프로세서는, 가속도 센서의 측정값을 바탕으로 퍼터가 기준자세로 정렬되었는지를 판단할 수 있다. 가속도 센서의 측정값이 출력부를 통해 출력될 수 있으며, 이렇게 출력된 값들을 확인하면서 사용자는 퍼터의 자세를 계속하여 수정할 수 있다. 이때, 프로세서는 가속도 센서의 측정값을 바탕으로 퍼터 의 x축 회전각(즉, 상하 각도)과 y축 회전각(즉, 좌우 각도)을 계산할 수 있으며, 이들 값들이 실시예에 따 라, 디스플레이가 구비된 경우에는 도 24의 (b)에 도시된 바와 같이 표시될 수 있다. 실시예에 따라, 상하 각도와 좌우 각도는 스피커를 통해 출력되거나, 무선통신모듈을 통해 네트워크로 전송될 수 있다. 사용자는 출력부를 통해 출력된 상하 각도 및 좌우 각도를 확인하면서 퍼터를 계속하여 움직여 보게 되 고, 이 과정에서 변화하는 상하 각도와 좌우 각도가 각각 기준치 이하인 되면, 프로세서는 퍼터 헤드가 기준자세가 된 것으로 판단(S4)하고, 기준자세로 정렬되었음을 알리는 알림이 출력부를 통해 출력되도록 제 어할 수 있다. 이하, 출력부로써 디스플레이를 예로써 설명하나, 스피커 또는 무선통신모듈도 가능함은 물론이다. 이후, 출력부를 통해 출력된 알림을 인지한 사용자가 입력부를 통해 영상획득명령을 인가하면, 프로세서 는 상기 영상획득명령에 대응하여 카메라(5a)에 의해 촬영이 이루어지도록 제어하고, 이렇게 촬영된 영상을 퍼팅거리(D1)를 구하는데 사용할 획득영상으로 정의할 수 있다.(S6) S6단계에서 촬영이 완료되면 프로세서 는 디스플레이를 통해 촬영 완료 메시지가 출력되도록 제어할 수 있다. (도 24의 (c) 참조) 이후, S7단계에서 프로세서는 앞서 설명한 실시예들에 따라 획득영상으로부터 퍼팅 정보를 산출할 수 있다. 상기 퍼팅 정보는 앞서 설명한 고저차(H2, H3) 및 퍼팅거리(D1) 중 적어도 하나를 포함할 수 있다. (도 24의 (d), (e)참조) 프로세서는 상기 퍼팅 정보가 출력부를 통해 출력되도록 제어할 수 있다(S8). 퍼팅 정보가 출력된 후, 사용자가 실제로 퍼팅을 하기 위한 셋업 자세를 취하게 되면, 프로세서는 현재 퍼터 헤드가 퍼팅방향(이에 대해서는 도 22 내지 도 23을 참조하여 후술 함.)으로 정렬이 되었는지를 판단하고, 그 결과에 따라 출력부를 통해 방향 지시 알림(E, 도 5/ 도 24의 (d), (e) 참조)을 출력할 수 있다. 예를 들어, 도 24의 (d)와 같이 퍼터 헤드가 퍼팅 방향으로 정렬이 된 경우, 프로세서는 디스플레이 를 통해 소정 색(예를 들어, 초록색)의 화살표를 표시하고, 도 24의 (e)와 같이 퍼터 헤드가 기준자세로 정 렬되지 않은 경우에는 다른 색(예를 들어, 빨간색)의 화살표가 표시되도록 제어할 수 있다. 한편, 도 22 내지 도 23을 참조하면, 본 발명의 일 실시예에 따른 퍼터는 공과 홀을 직선으로 연결 하는 선을 기준으로 양쪽에서 각각 구한 제 1 획득영상(M1)과 제 2 획득영상(M2)을 바탕으로 퍼팅 방향을 판단 할 수 있다. 예를 들어, 도 22에 도시된 바와 같이 공으로부터 홀을 향하는 제 1 방향으로는 경사가 있으나, 상기 제 1 방향과 직교하는 제 2 방향으로는 경사가 없는 경우, 제 1 획득영상(M1)에서 구한 공의 Y축 좌표값 및 홀의 Y축 좌표값은, 각각 제 2 획득영상(M2)에서 구한 공의 Y축 좌표값 및 홀의 Y축 좌표값과 실질 적으로 동일하다. 이러한 경우 프로세서는 상기 제 1 방향으로 퍼팅할 것, 즉, 홀을 향해 똑바로 치면 된다는 것을 결과로서 출력할 수 있다. 다른 예로, 도 23에 도시된 바와 같이 공으로부터 홀을 향하는 제 1 방향으로는 경사가 없으나, 상기 제 1 방향과 직교하는 제 2 방향으로는 경사가 있는 경우, 제 1 획득영상(M1)에서 구한 공의 Y축 좌표값 및 홀의 Y축 좌표값은, 제 2 획득영상(M2)에서 구한 공의 Y축 좌표값 및 홀의 Y축 좌표값과 각각 다르 게 된다. 이러한 경우 프로세서는 상기 제 2 방향으로의 경사를 고려하여 지대가 높은 쪽으로 퍼팅을 할 것 을 결과로서 출력할 수 있다. 더 나아가, 프로세서는, 제 1 획득영상(M1)에서 구한 공의 Y축 좌표값과 제 2 획득영상(M2)에서 구한 공의 Y 축 좌표값의 크기를 비교하여 홀을 향하는 방향에 대해 좌, 우측 중 어느 측으로 어느 정도의 각도로 퍼팅 방향을 할 것인지도 판단할 수 있다. 도 25는 퍼팅거리 측정 방법의 다른 실시예를 설명하기 위한 도면이다. 도 25를 참조하면, 본 실시예에 따른 퍼 팅거리 측정 방법은 획득영상에 표현된 색상을 분석하여 홀과 깃대를 식별할 수 있다. 구체적으로, 프 로세서는 획득 영상에 표현된 색상을 분석하여 깃대의 윤곽, 깃대의 최상단 지점 및 홀을 검출하고, 이렇게 검출된 결과를 바탕으로 깃대 길이(h1') 및/또는 고저차(h2')를 구할 수 있다. 스마트 퍼팅 디바이스는 레이저를 이용하여 깃발을 인식하는 깃발인식모듈(미도시)를 포함할 수 있다. 상 기 깃발인식모듈은 레이저에 의해 깃발이 감지된 경우 이를 짧은 진동으로 알려주는 졸트 기능(JOLT)을 구현하 는 것일 수 있다. 졸트 기능은 이미 레이저 거리 측정기에 널리 적용되고 있는 기술이므로 구체적인 설명은 생 략한다. 상기 깃발인식모듈에 의해 깃발이 인식되면, 프로세서는 획득영상에 표현된 색상들을 분석하여 깃발의 윤곽 을 검출할 수 있다. 통상적으로 깃발은 먼 거리에서도 용이하게 식별될 수 있도록 배경과 대비를 이루는 색상으 로 이루어지므로, 프로세서는 획득 영상을 구성하는 화소들의 색상들을 분석하여 깃발의 윤곽과 깃발 상단의 위치를 검출할 수 있다. 또한, 프로세서는 획득영상에 표현된 색상을 분석하여 깃대와 홀이 만나는 지점을 검출할 수 있으며, 이렇게 구해진 지점(즉, 홀의 위치)과 앞서 구한 깃발 상단의 위치를 바탕으로 획득 영상에서의 깃대 길이(h1')를 구할 수 있다. 더 나아가, 프로세서는 홀의 위치를 바탕으로 고저차(h2')를 구할 수 있다. 도 26은 퍼팅거리 측정 방법의 또 다른 실시예를 설명하기 위한 도면이다. 도 26을 참조하면, 홀의 위치와 깃발 상단의 위치는 인공지능에 기반한 영상 분석 방법에 의해 구해질 수 있다. 메모리에는 딥러닝 기반으로 학습된 인공 신경망이 저장될 수 있으며, 프로세서는 상기 인공 신경망을 이용한 획득 영상의 분석 과정을 통해 홀의 위치와 깃발 상단의 위치를 검출할 수 있다. 상기 인공 신경망은 기 알려진 다양한 방식으로 구현될 수 있다. 예를 들어, 프로세서는 도 26에 도시된 바와 같이, 획득 영상에서 깃대를 인식하여 박스 형태로 깃대가 표현 된 영역을 정의할 수 있으며, 여기서, 상기 박스는 홀을 지나는 수평선을 하측 가로로 하고, 깃대의 상단을 지 나는 수평선을 상측 가로로 하는 직사각형일 수 있다. 또한, 프로세서는 획득 영상에서 깃발을 인식하여 박스 형태로 깃발이 표현된 영역을 정의할 수 있으며, 이 경우, 깃발의 상단을 지나는 수평선이 직사각형 박스의 상측 가로를 정의할 수 있다. 도 27은 퍼팅거리 측정 방법의 또 다른 실시예를 설명하기 위한 도면이다. 도 27을 참조하면, 본 발명의 일 실 시예에 따른 스마트 퍼팅 디바이스는 영상 획득부가 스테레오 방식의 2 개의 획득 이미지를 구하도록 구성될 수 있다. 구체적으로, 영상 획득부는 수평방향(또는, 좌우방향)으로 일정 거리 이격된 2 개의 카메라를 포함할 수 있 다. 같은 위치에서 동일한 대상을 상기 2 개의 카메라를 이용하여 촬영함으로써 시차가 다른 두개의 획득 영상 을 구하게 되고, 이렇게 구한 두 개의 획득 영상을 이용하여 프로세서는 퍼팅위치에 대한 홀의 고저차 및/또 는 대상까지의 거리(또는, 퍼팅위치로부터 홀까지의 수평거리)를 구할 수 있다. 도 27에서 L1은 좌측에 위치하는 제 1 카메라에 의해 획득된 제 1 획득 영상이고, R1은 우측에 위치하는 제 2 카메라에 의해 획득된 제 2 획득 영상이다. 프로세서는 상기 제 1 획득 영상과 상기 제 2 획득 영상을 바탕으로 Disparity Map 또는 Depth Map을 구할 수 있다. 통상적으로 이러한 맵들을 생성하는 데에는 매우 큰 연산량이 필요하기 때문에, 바람직하게는, 프로세서는 제 1, 2 획득 영상에서 각각 깃대(또는, 깃발) 및/또는 공만을 식별하고, 이들에 대한 차이(disparity)만을 맵으로 생성할 수 있다. 획득 영상에서 깃대 또는 공을 식별하는 것은 인공지능 알고리즘에 의해 이루어질 수 있다. 실시예에 따라, 차이(disparity)는 양 영상에서의 밝기 차일 수 있다. 프로세서는 획득영상의 밝기 정보를 분석할 수 있다. 색상을 제외하고 밝기만을 비교할 시 영상에서 표현된 객체들은 어두울수록 멀리 떨어진 것이다. 프로세서는 제 1 획득 영상으로부터 제 1 밝기 정보를 구하고, 제 2 획득 영상으로부터 제 2 밝기 정보 를 구한 후, 제 1, 2 밝기 정보들의 차이를 바탕으로 타겟(예를 들어, 깃대나 공)까지의 거리를 구할 수 있다. 참고로, 도 27에서 L2는 제 1 획득 영상을 밝기 정보를 이용하여 처리한 영상이고, R2는 제 2 획득 영상을 밝기 정보를 이용하여 처리한 영상이다. 색상이나, 형태 등의 영상을 구성하는 다양한 정보들 중에서, 상대적으로 데이터량이 적은 밝기 정보를 이용하 여 거리를 구하기 때문에 연산량을 줄일 수 있는 효과가 있다. 도 28은 퍼팅거리 측정 방법의 또 다른 실시예를 설명하기 위한 도면이다. 도 28을 참조하면, 영상 획득부는 좌우(또는, 수평) 및 상하(또는, 수직)로 소정 거리 이격된 2 개의 카메라를 포함할 수 있다. 같은 위치에서 동일한 대상을 상기 2 개의 카메라를 이용하여 촬영함으로써 시차가 다른 두개의 획득 영상을 구 하게 되고, 이렇게 구한 두 개의 획득 영상에서 프로세서는 깃대의 좌우 편차(xa) 및 상하 편차(ya)를 구하 고, 구해진 값들을 바탕으로 퍼팅 위치에 대한 홀의 고저차 및/또는 깃대까지의 거리(또는, 퍼팅위치로부터 홀 까지의 수평거리)를 구할 수 있다."}
{"patent_id": "10-2023-7017603", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 스마트 퍼팅 디바이스와, 이를 포함하는 스마트 퍼팅 시스템을 도시한 것이다. 도 2는 도 1의 스마트 퍼팅 디바이스의 주요 구성들 간의 제어관계를 도시한 블록도이다. 도 3은 본 발명의 제 1 실시예에 따른 스마트 퍼팅 디바이스의 주요부들을 보인 블록도이다. 도 4는 도 3의 스마트 퍼팅 디바이스의 일례로 퍼터를 도시한 것으로, 도 4의 (a)는 퍼터를 위에서 내려다본 것 이고, 도 4의 (b)는 퍼터를 정면에서 바라본 것이다. 도 5는 본 발명의 다른 실시예에 따른 퍼터를 도시한 것이다. 도 6은 본 발명의 또 다른 실시예들에 따른 퍼터들을 도시한 것이다. 도 7은 도 3의 스마트 퍼팅 디바이스의 다른 예로 볼마커를 도시한 것이다. 도 8은 본 발명의 제 2 실시예에 따른 스마트 퍼팅 디바이스의 주요부들을 보인 블록도이다. 도 9는 도 8의 스마트 퍼팅 디바이스의 일례를 도시한 것이다. 도 10은 도 8의 스마트 퍼팅 디바이스의 다른 예를 도시한 것이다. 도 11은 수평한 지면에서 구한 것들로써 스마트 퍼팅 디바이스로부터 홀까지의 거리에 따른 획득영상들을 도시 한 것이다. 도 12는 스마트 퍼팅 디바이스가 기준자세가 아닌 상태에서 구한 깃대 이미지와 기준자세로 조정된 상태에서 구 한 깃대 이미지를 비교하여 도시한 것이다. 도 13은 (a)는 획득영상에서 보이는 홀과 깃대의 위치를 카메라가 제 1 위치에 있을 시 구한 것과 제 2 위치에 있을 시 구한 것을 비교하여 보인 것이고, (b)는 상기 제 1 위치에서의 카메라, 홀 및 깃대의 위치관계를 도시 한 것이고, (c)는 상기 제 2 위치에서의 카메라, 홀 및 깃대의 위치관계를 도시한 것이다. 도 14는 카메라가 기준자세에 있을 시에 촬영한 획득영상에서, 카메라로부터 홀컵까지의 거리에 대한 깃대 상단 의 좌표를 고저차 별로 도시한 것이다. 도 15는 (a)스마트 퍼팅 디바이스가 바닥에 있을 때와, (b)바닥으로부터 들어 올려졌을 때를 도시한 것이다. 도 16은 (a)스마트 퍼팅 디바이스가 바닥에 있을 때 획득 영상에 보이는 깃대와, (b)스마트 퍼팅 디바이스가 바 닥으로부터 들어 올려졌을 때 획득 영상에 보이는 깃대를 도시한 것이다. 도 17은 본 발명의 다른 실시예에 따른 스마트 퍼팅 디바이스를 이용한 퍼팅거리 측정 방법을 설명하기 위한 것으로써, 스마트 퍼팅 디바이스를 홀컵 위치에 놓고 공을 촬영한 영상을 도시한 것이다. 도 18은 스마트 퍼팅 디바이스가 기준자세가 아닌 상태에서 구한 공의 이미지와 기준자세로 조정된 상태에서 구한 공의 이미지를 비교하여 도시한 것이다. 도 19의 (a)는 획득영상에서 보이는 공을 카메라가 제 1 위치에 있을 시와 제 2 위치에 있을 시를 비교하여 보 인 것이고, (b)는 상기 제 1 위치에서의 카메라와 공의 위치관계를 도시한 것이고, (c)는 상기 제 2 위치에서의 카메라와 공의 위치관계를 도시한 것이다. 도 20은 카메라가 기준자세에 있을 시에 촬영한 획득영상에서, 카메라로부터 공까지의 거리에 대한 공의 폭을 고저차 별로 도시한 것이다. 도 21은 본 발명의 실시예들에 따른 스마트 퍼팅 디바이스를 이용한 퍼팅거리 측정 방법을 도시한 순서도이다. 도 22는 공이 홀보다 높은 경우의 일례로서, 공과 깃대의 위치(a), 제 1 획득영상에 표시된 공과 깃대의 위치 (b) 및 제 2 획득영상에 표시된 공과 깃대의 위치(c)를 도시한 것이다. 도 23은 공과 홀을 연결한 선을 기준으로 양쪽 지대가 높이차가 있는 경우의 일례로서, 공과 깃대의 위치(a), 제 1 획득영상에 표시된 공과 깃대의 위치(b) 및 제 2 획득영상에 표시된 공과 깃대의 위치(c)를 도시한 것이다. 도 24는 퍼터 헤드의 디스플레이를 통해 표시되는 화면들을 도시한 것이다. 도 25는 퍼팅거리 측정 방법의 다른 실시예를 설명하기 위한 도면이다. 도 26은 퍼팅거리 측정 방법의 또 다른 실시예를 설명하기 위한 도면이다. 도 27은 퍼팅거리 측정 방법의 또 다른 실시예를 설명하기 위한 도면이다."}
