{"patent_id": "10-2022-0021056", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0123809", "출원번호": "10-2022-0021056", "발명의 명칭": "음성 및 표정에 기반한 캐릭터의 동작 및 감정 표현 시스템", "출원인": "박일호", "발명자": "박일호"}}
{"patent_id": "10-2022-0021056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "캐릭터의 동작과 감정을 표현하는 애니메이션을 생성하는 방법으로서, 임의의 문장을 포함하는 음성신호를 텍스트 데이터로 변환하고 구문 분석하여 상기 문장을 포함하는 구문 데이터를 생성하는 단계; 상기 음성신호로부터 캐릭터의 특징을 포함하는 캐릭터 데이터를 생성하는 단계; 복수의 제스처 애니메이션 중에서 상기 구문 데이터에 매칭되는 제1 애니메이션을 선택하는 단계; 복수의 얼굴 애니메이션 중에서 상기 캐릭터 데이터에 매칭되는 제2 애니메이션을 선택하는 단계; 및 상기 구문 데이터에 따른 제스처와 상기 캐릭터 데이터에 따른 얼굴 표정을 각각 제1 및 제2 애니메이션에 블렌딩하는 단계;를 포함하는 것을 특징으로 하는, 캐릭터의 동작과 감정을 표현하는 애니메이션의 생성 방법."}
{"patent_id": "10-2022-0021056", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 캐릭터의 동작과 감정을 표현하는 애니메이션을 생성하는 방법에 관한 것으로, 일 실시예에서, 임의의 문장을 포함하는 음성신호를 텍스트 데이터로 변환하고 구문 분석하여 상기 문장을 포함하는 구문 데이터를 생성 하는 단계; 상기 음성신호로부터 캐릭터의 특징을 포함하는 캐릭터 데이터를 생성하는 단계; 복수의 제스처 애니 메이션 중에서 상기 구문 데이터에 매칭되는 제1 애니메이션을 선택하는 단계; 복수의 얼굴 애니메이션 중에서 상기 캐릭터 데이터에 매칭되는 제2 애니메이션을 선택하는 단계; 및 상기 구문 데이터에 따른 제스처와 상기 캐 릭터 데이터에 따른 얼굴 표정을 각각 제1 및 제2 애니메이션에 블렌딩하는 단계;를 포함하는 캐릭터의 동작과 감정을 표현하는 애니메이션의 생성 방법을 개시한다."}
{"patent_id": "10-2022-0021056", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컴퓨터를 이용한 캐릭터 애니메이션 생성 시스템에 관한 것으로, 보다 상세하게는, 음성과 표정에 기 초하여 캐릭터의 동작과 감정을 표현하는 애니메이션을 생성하는 캐릭터 애니메이션 생성 시스템에 관한 것이다."}
{"patent_id": "10-2022-0021056", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "애니메이션(animation)에 포함되는 디지털 캐릭터(Digital Character)는 다양한 분야에 응용되며, 예를 들면 연 극 배우의 모션을 감지하고 이를 디지털 캐릭터로 애니메이션화 하기도 한다. 다른 예로는, 디지털 캐릭터는 또한 음향에 동기되어 동영상으로 재생되기도 한다. 예를 들면, 한국 공개특허 제2006-0054678호(2006년 5월 23일)에는 음향에 캐릭터를 동기화시키는 기술이 개시되어 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 특허문헌1: 한국 공개특허 제2006-0054678호 (2006년 5월 23일 공개) (특허문헌 0002) 특허문헌2: 한국 공개특허 제2006-0031449호 (2006년 4월 12일 공개)"}
{"patent_id": "10-2022-0021056", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면 사용자가 소정 문장을 포함하는 음성신호를 발화하면 이 음성신호에 기초하여 또 는 상기 음성신호 및 사용자의 얼굴 표정에 기초하여 캐릭터에 동작과 표정을 블렌딩하여 캐릭터 애니메이션 동 영상을 생성하는 캐릭터 애니메이션 생성 시스템을 개시한다."}
{"patent_id": "10-2022-0021056", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 캐릭터의 동작과 감정을 표현하는 애니메이션을 생성하는 방법으로서, 임의의 문장을 포함하는 음성신호를 텍스트 데이터로 변환하고 구문 분석하여 상기 문장을 포함하는 구문 데이터를 생 성하는 단계; 상기 음성신호로부터 캐릭터의 특징을 포함하는 캐릭터 데이터를 생성하는 단계; 복수의 제스처애니메이션 중에서 상기 구문 데이터에 매칭되는 제1 애니메이션을 선택하는 단계; 복수의 얼굴 애니메이션 중 에서 상기 캐릭터 데이터에 매칭되는 제2 애니메이션을 선택하는 단계; 및 상기 구문 데이터에 따른 제스처와 상기 캐릭터 데이터에 따른 얼굴 표정을 각각 제1 및 제2 애니메이션에 블렌딩하는 단계;를 포함하는 캐릭터의 동작과 감정을 표현하는 애니메이션의 생성 방법을 개시한다. 본 발명의 일 실시예에 따르면, 상기 애니메이션의 생성 방법을 실행시키기 위한 컴퓨터 프로그램이 기록된 컴 퓨터 판독가능 기록매체를 개시한다."}
{"patent_id": "10-2022-0021056", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면 사용자가 발화하는 음성신호 및 표정에 기초하여 발화한 문장의 각 단어나 구문 및 감정에 대응하는 동작과 얼굴 표정을 자동적으로 매칭하고 블렌딩하여 캐릭터 애니메이션 영상을 자동적이고 창의적으로 제작할 수 있는 기술적 효과를 가진다. 또한 본 발명의 일 실시예에 따른 애니메이션 생성 기술은 사용자의 대사와 행동 및 감정 표현을 애니메이션 캐 릭터가 하는 것처럼 구현할 수 있으므로 오늘날과 같은 비대면 시대에 특히 유용하고 필요한 기술적 이점이 있 다."}
{"patent_id": "10-2022-0021056", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이상의 본 발명의 목적들, 다른 목적들, 특징들 및 이점들은 첨부된 도면과 관련된 이하의 바람직한 실시예들을 통해서 쉽게 이해될 것이다. 그러나 본 발명은 여기서 설명되는 실시예들에 한정되지 않고 다른 형태로 구체화 될 수도 있다. 오히려, 여기서 소개되는 실시예들은 개시된 내용이 철저하고 완전해질 수 있도록 그리고 당업자 에게 본 발명의 사상이 충분히 전달될 수 있도록 하기 위해 제공되는 것이다. 본 명세서에서 제1, 제2 등의 용어가 구성요소들을 기술하기 위해서 사용된 경우, 이들 구성요소들이 이 같은 용어들에 의해서 한정되어서는 안된다. 이들 용어들은 단지 어느 구성요소를 다른 구성요소와 구별시키기 위해 서 사용되었을 뿐이다. 여기에 설명되고 예시되는 실시예들은 그것의 상보적인 실시예들도 포함한다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 '~를 포 함한다', '~로 구성된다', 및 '~으로 이루어진다'라는 표현은 언급된 구성요소 외에 하나 이상의 다른 구성요소 의 존재 또는 추가를 배제하지 않는다. 본 명세서에서 용어 '소프트웨어'는 컴퓨터에서 하드웨어를 움직이는 기술을 의미하고, 용어 '하드웨어'는 컴퓨 터를 구성하는 유형의 장치나 기기(CPU, 메모리, 입력 장치, 출력 장치, 주변 장치 등)를 의미하고, 용어 '단계'는 소정의 목을 달성하기 위해 시계열로 연결된 일련의 처리 또는 조작을 의미하고, 용어 '컴퓨터 프로그 램', '프로그램', 또는 '알고리즘'은 컴퓨터로 처리하기에 합한 명령의 집합을 의미하고, 용어 '프로그램 기록 매체'는 프로그램을 설치하고 실행하거나 유통하기 위해 사용되는 프로그램을 기록한 컴퓨터로 읽을 수 있는 기 록매체를 의미한다. 본 명세서에서 발명의 구성요소를 지칭하기 위해 사용된 '~부', '~모듈', '~유닛', '~블록', '~보드' 등의 용어 는 적어도 하나의 기능이나 동작을 처리하는 물리적, 기능적, 또는 논리적 단위를 의미할 수 있고 이는 하나 이상의 하드웨어나 소프트웨어 또는 펌웨어로 구현되거나 또는 하나 이상의 하드웨어, 소프트웨어, 및/또는 펌웨 어의 결합으로 구현될 수 있다. 본 명세서에서 '처리장치', '컴퓨터', '컴퓨팅 장치', '서버 장치', '서버'는 윈도우, 맥, 또는 리눅스와 같은 운영체제, 컴퓨터 프로세서, 메모리, 응용프로그램들, 기억장치(예를 들면, HDD, SDD), 및 모니터를 구비한 장 치로 구현될 수 있다. 컴퓨터는 예를 들면, 데스크톱 컴퓨터나 노트북, 모바일 단말기 등과 같은 장치일 수 있 으나 이들은 예시적인 것이며 이에 한정되는 것은 아니다. 모바일 단말기는 스마트폰, 태블릿 PC, 또는 PDA와 같은 모바일 무선통신기기 중 하나일 수 있다. 본 명세서에서, 구성요소 'A'가 구성요소 'B'에게 정보, 내역, 및/ 또는 데이터를 전송한다고 함은 구성요소 'A'가 구성요소 'B'에게 직접 전송하거나 또는 구성요소 'A'가 적어도 하나 이상의 다른 구성요소를 통해서 구 성요소 'B'에 전송하는 것을 포함하는 의미로 사용한다. 애니메이션산업 진흥에 관한 법률에 따르면 애니메이션은 \"실물의 세계 또는 상상의 세계에 존재하는 스스로 움 직이지 않는 피사체를 2D, 3D, CG, 스톱모션 등 다양한 기법과 매체를 이용하여 가공함으로써 움직이는 이미지 로 창출하는 영상\"이라고 정의하고 있다. 본 명세서에서 \"애니메이션\"은 이러한 정의를 포함할 뿐만 아니라 실 존하는 캐릭터 또는 가상의 캐릭터의 몸체의 적어도 일부가 움직이는 동영상을 포괄하여 의미하는 것으로 해석 한다. 또한 본 명세서에서 '애니메이션'은 '애니메이션 동영상', '애니메이션 영상', '동영상', '영상' 등으로 칭하기도 한다. 본 명세서에 언급되는 '캐릭터'는 애니메이션 영상에 나타나는 실제의 또는 가공의 인물이나 동물 등 시각적 상 징물을 포괄하여 지칭하는 것이며, 예컨대 가공의 캐릭터로는 각종 만화 등의 주인공이나 아바타 등을 의미할 수 있다. 본 명세서에서 언급되는 캐릭터의 '제스처'는 애니메이션 내에서 캐릭터의 몸짓, 손짓 등 몸체의 적어도 일부의 움직임이나 동작을 의미한다. 제스처는 단순히 캐릭터 일부 몸체의 움직임을 의미할 수도 있고 캐릭터의 내면의 심리적 상태의 표현이거나 어떤 대상에 대한 신호일 수도 있다. 본 명세서에서는 특별한 제한이 없는 한 제스처 를 '움직임'이나 '동작'과 동일한 의미로 사용하기로 한다. 또한 본 명세서에서 때로는 '제스처'가 캐릭터의 얼 굴 표정의 움직임이나 캐릭터 얼굴의 눈, 코, 입 등 얼굴의 적어도 일부분의 움직임까지 포괄하여 의미할 수도 있다. 이하 도면을 참조하여 본 발명을 상세히 설명하도록 한다. 아래의 특정 실시예들을 기술하는데 있어서 여러 가 지의 특정적인 내용들은 발명을 더 구체적으로 설명하고 이해를 돕기 위해 작성되었다. 하지만 본 발명을 이해 할 수 있을 정도로 이 분야의 지식을 갖고 있는 독자는 이러한 여러 가지의 특정적인 내용들이 없어도 사용될 수 있다는 것을 인지할 수 있다. 또한 발명을 기술하는 데 있어서 공지 또는 주지관용 기술이면서 발명과 크게 관련 없는 부분들은 본 발명을 설명하는 데 있어 혼돈을 막기 위해 기술하지 않음을 미리 언급해 둔다. 도1은 본 발명의 일 실시예에 따른 캐릭터 애니메이션 생성 시스템(이하 간단히 \"애니메이션 생성 시스템\" 또는 \"시스템\"이라고도 함)을 설명하기 위한 블록도이다. 도1을 참조하면, 일 실시예에 따른 애니메이션 생성 시스템 은 음성 및 표정 분석모듈, 비주얼 매니저, 및 애니메이션 아카이브를 포함할 수 있다. 음성 및 표정 분석모듈(이하 간단히 '분석모듈'이라고도 함)은 사용자가 발화하는 음성을 수신하여 음성을 분석하여 구문 데이터와 캐릭터 데이터를 생성할 수 있다. 대안적 실시예에서 분석모듈은 사용자가 발화하 는 음성 및 사용자의 표정을 수신하고 분석하여 구문 데이터와 캐릭터 데이터를 생성할 수 있다. 일 실시예에서 분석모듈은 STT 분석부, 구문 분석부, 음성 분석부, 및 캐릭터 데이터 생성 부를 포함한다. 대안적 실시예에서 분석모듈은 표정 분석부를 더 포함할 수 있다. 분석모듈은 사용자가 발화하는 음성신호를 수신하기 위해 마이크와 같은 음성수신 장치를 구비할 수 있다. 또한 일 실시예에서 사용자의 표정을 촬영하여 수신하기 위해 카메라와 같은 이미지 촬상 장치를 추가로 구비할 수 있다. 분석모듈이 수신하는 음성신호는 사용자가 발화하는 소정의 문장을 포함할 수 있다. 여기서 '문장'은 반드 시 주어와 동사를 포함해야 하는 것은 아니며 하나 이상의 단어의 집합일 수 있다. 마이크와 같은 음성수신 장 치를 통해 입력된 음성신호는 STT(Speech-to-Text) 분석부로 전달된다. STT 분석부는 음성신호를 해 석하여 문자 데이터로 전환하는 기능부이다. STT 분석부에서 생성된 문자 데이터는 구문 분석부로 전달된다. 구문 분석부는 문자 데이터 내 의 문장을 단어별 및/또는 구문별 해석하여 구문 데이터를 생성할 수 있다. 일 실시예에서 '구문 데이터'는 사용자가 발화한 문장(즉, 문장을 텍스트로 전환한 텍스트 데이터) 및 상기 문 장에 대한 구문 분석된 데이터(이하 '메타 데이터'라 한다)를 포함할 수 있다. 예를 들어, 메타 데이터는 상기 문장을 구성하는 각각의 단어 및/또는 구문에 대응(매칭)하는 동작을 나타내는 동작 정보, 및 각각의 단어 및/ 또는 구문에 대응(매칭)하는 감정을 나타내는 감정 정보를 포함할 수 있다. 예를 들어 사용자가 발화한 문장 중 에 '너무 기뻐'와 같은 문장이 포함된 경우, 구문 분석부는 '기뻐'란 단어에 대응하여 '기쁨을 표시하는 동작'을 동작 정보로서 메타 데이터에 포함시킬 수 있다. 또한 구문 분석부는 '너무 기뻐'의 문장으로부터 '기쁨' 또는 '행복'이라는 감정을 매칭시킬 수 있고 이에 따라 메타 데이터는 기분류된 감정의 종류 중 '기쁨' 또는 '행복'을 감정 정보로서 메타 데이터에 포함시킬 수 있다. 일 실시예에서, 구문 분석부는 문장을 형태소 기반으로 분석할 수 있고 이에 따라 메타 데이터가 동사의 시제에 관한 시제 정보(예컨대, 미래형인지 완료형인지, 가정법인지 등을 판단하는 정보)를 더 포함할 수 있다. 예를 들어 사용자가 발화한 문장이 '~했다'라는 단어를 포함한 경우, '~했'이라는 형태소로부터 해당 동작을 이 미 완료했다고 판단할 수 있고, 다른 예로서, 문장이 '~하겠다'라는 단어를 포함한 경우 형태소 분석을 통해 해 당 동작을 아직 하지 않았다고 판단할 수 있다. 또 다른 예로서 문장이 '~할텐데'라는 단어를 포함한 경우 구문 분석부는 해당 동작을 하지 않았다고 판단할 수 있다. 일 실시예에서, 구문 분석부는 문장을 구성하는 각각의 단어 및/또는 구문에 대응(매칭)하는 동작을 캐릭 터가 수행하도록 동작 정보를 생성한다. 그러나 문장의 내용이나 뉘앙스에 따라, 캐릭터가 반드시 상기 문장 내 에 포함된 단어(동사)와 일치하는 동작을 하는 것은 아니다. 예를 들어 사용자가 발화한 문장이 '뛰어야겠다'와 같이 미래형이거나 또는 '뛰었을 텐데'와 같이 가정법을 의미하는 경우 캐릭터가 뛰는 동작을 반드시 해야 하는 것이 아니므로, 구문 분석부는 '뛰다'는 단어에 대응하여 뛰는 동작의 동작 정보를 생성하지 않을 수도 있 고(예컨대, 이 경우 '뒤는 동작'이 아니라 '생각하는 동작' 또는 '후회하는 동작'을 동작 정보로서 생성할 수도 있고, 더 나아가 이 경우 '후회' 또는 '슬픔' 등의 감정을 감정 정보로서 생성할 수도 있다), 구문 분석부(11 2)는 문장의 전체적인 의미나 뉘앙스에 기초하여 동작 정보 및/또는 감정 정보를 생성하는 것이 바람직하다. 그 러므로 메타 데이터가 시제 정보를 더 포함하는 일 실시예에서, 구문 분석부는 문장의 단어나 구문 뿐만 아니라 시제 정보 및 문장의 문맥이나 뉘앙스에 기초하여 각 단어나 구문에 대응하는 동작의 동작 정보 및/또는 감정 정보를 생성할 수 있다. 분석 모듈은 문장을 발화하는 사용자의 감정에 관한 정보를 생성하기 위해 음성 분석부를 포함한다. 음성 분석부는 사용자가 발화하는 음성을 수신하고 이로부터 음성의 톤, 피치, 발화 속도 등 하나 이상의 음성신호의 분석기준에 따라 분석하고, 분석 결과에 따라 사용자(발화자)의 감정 상태를 인식할 수 있다. 음성 분석부가 사용자의 감정을 인식하기 위해 종래 공지된 다양한 방식이 적용될 수 있다. 예를 들어 음 성 분석부는 발화하는 음성의 주파수 변화, 발화 속도 등을 고려할 수 있다. 예를 들어, 사용자가 발화하 는 음성의 주파수 변화(또는 음성 내 음절의 높낮이 변화)를 측정하여 사용자의 감정상태를 감지할 수 있다. 일 실시예에서 음성 분석부는 사용자가 발화하는 문장 전체에 대해 하나의 감정 상태를 인식할 수 있다. 보다 바람직한 실시예에서 음성 분석부는 문장내 각 단어별 및/또는 구문별로 해당 단어나 구문에 대응하는 감 정 상태를 분석할 수도 있다. 분석 모듈은 사용자의 감정에 관한 정보를 생성하기 위해 표정 분석부를 더 포함할 수 있다. 표정 분 석부는 예컨대 카메라로 촬영한 사용자의 얼굴 표정을 수신하고 이로부터 사용자의 감정을 인식할 수 있다. 얼굴 표정으로부터 감정을 인식하는 것은 당업계에 공지된 기술이며 예컨대 한국 등록특허 제10- 1317047호 (얼굴표정을 이용한 감정인식 장치 및 그 제어방법) 등에 개시되어 있다. 캐릭터 데이터 생성부는 캐릭터에 부여할 특징(이하 '캐릭터 특징'이라고도 함)을 나타내는 데이터(이하 '캐릭터 데이터'라고도 함)를 생성하는 기능부이다. 일 실시예에서 캐릭터 특징은 캐릭터의 감정, 성별, 나이, 및 외모 중 적어도 하나를 포함할 수 있고 이에 따라 캐릭터 데이터는 감정 데이터, 성별 데이터, 나이 데이터, 및 외모 데이터 중 적어도 하나를 포함할 수 있다. 캐릭터 데이터 생성부는 구문 분석부가 생성한 구문 데이터, 및 음성 분석부와 표정 분석부 에서 판단한 감정 정보를 수신하고 이들 중 적어도 하나에 기초하여 캐릭터 데이터를 생성할 수 있다. 일 예로서, 구문 데이터에서 포함된 문장기호나 문장의 단어 및/또는 구문이 감정 판단에 기여할 수 있다. 예를 들어 문장 내에 감정을 나타내는 특정 단어(예컨대 감탄사나 의성어, 의태어 등)가 포함되어 있으면 그에 대응하여 기쁨, 슬픔, 또는 놀라움 등의 감정이라고 판단할 수 있다. 따라서 캐릭터 데이터 생성부는 이러한 구문 데이터 및 음성 분석부와 표정 분석부에서 분석된 감정 정보에 기초하여 문장의 각 단어 단위로 또는 각 구문 단위로 각각 대응되는 감정을 선택할 수 있다. 이 때 감정의 종류는 기쁨, 슬픔, 화남, 놀람, 공 포 등으로 분류되어 있고, 문장의 각 단어마다 및/또는 각 구문마다 감정이 하나씩 매칭될 수 있다. 대안적 실 시예에서, 문장의 각 단어마다 및/또는 각 구문마다 하나 이상의 감정이 복합적으로 매칭될 수도 있고, 이 경우 하나의 단어 및/또는 구문에 매칭되는 복수개의 감정들에 대해 가중치가 적용되어 복합적인 감정이 매칭될 수 있다. 캐릭터 데이터 생성부는 구문 분석부가 생성한 구문 데이터, 음성 분석부에서 판단한 음성 정보, 및 표정 분석부에서 획득한 얼굴 표정 중 적어도 하나에 기초하여 성별 데이터, 나이 데이터, 및 외 모 데이터를 생성할 수 있다. 예를 들어 캐릭터의 성별과 나이는 사용자의 음성 및/또는 사용자의 얼굴을 분석하여 판단할 수 있고, 사용자가 발화한 문장에 사용된 단어나 구문을 분석하여 성별 및/또는 나이 판단의 추가적 또는 보조적 기준으로 사용할 수 있다. 캐릭터의 외모는 예컨대 캐릭터가 뚱뚱한 몸매인지 홀쭉한 몸매인지 등 캐릭터의 외형에 관한 정보이 며, 예를 들어 사용자의 음성 및/또는 사용자의 얼굴을 분석하여 판단할 수 있다. 이와 같이 캐릭터 데이터 생성부가 캐릭터의 감정, 성별, 나이, 및 외모를 판단하여 캐릭터 데이터를 생성 하는 것은 예컨대 딥러닝 알고리즘을 이용하여 구현할 수 있다. 즉 다양한 음성신호와 문장을 학습 데이터로 이 용하여 인공신경망을 기계학습 시킴으로써 임의의 음성신호에 대한 감정, 성별, 나이, 및 외모에 관한 정보를 출력하도록 구현할 수 있다. 또한 분석 모듈의 상술한 각 구성요소들(111,112,113,114,115)의 각각은 하나 이상의 알고리즘이나 소프트웨어로 구현되거나 소프트웨어와 하드웨어 또는 펌웨어의 결합으로 구현될 수 있음 을 당업자는 이해할 것이다. 애니메이션 아카이브는 복수개의 애니메이션 동영상을 저장할 수 있다. 일 실시예에서 애니메이션 아카이 브는 복수개의 제스처 동영상 및 복수개의 얼굴 동영상을 포함한다. 각각의 제스처 동영상은 캐릭터가 취 할 수 있는 각기 다른 동작을 각각 표현하는 짧은 길이의 동영상이다. 예를 들어 각 제스처 동영상은 뛰다, 앉 다, 손을 들다 등 기본적인 동작을 표현하거나 기쁨, 슬픔, 화남 등 감정에 따른 동작을 표현한다. 예를 들어 도2는 일 실시예에 따라 캐릭터의 감정 분류에 따라 캐릭터의 동작을 표현하는 제스처 동영상의 일부를 예로서 나타내었다. 도시한 실시예에서는 감정의 종류를 놀람, 행복, 화남, 공포, 슬픔의 5가지로 분류하였고 각 감정 에 따라 하나 이상의 기본 행동을 표현하는 제스처 동영상 및 하나 이상의 부가 행동을 표현하는 제스처 동영상 을 포함할 수 있다. 도2에서는 감정을 5가지로 분류하였지만 이는 예시적인 것일 뿐이며 발명의 구체적 실시 상 황에 따라 감정 분류 개수가 달라질 수 있음은 물론이다. 각 제스처 동영상마다 식별정보(예컨대 식별번호나 메타 데이터 등)나 라벨이 부여되어 있고 하나 이상의 동작 및/또는 감정이 하나 이상의 제스처 동영상의 식별정보나 라벨에 매칭되어 있을 수 있다. 각각의 얼굴 동영상은 캐릭터가 취할 수 있는 각기 다른 얼굴 표정을 표현하는 짧은 길이의 동영상이다. 각 얼 굴 동영상은 웃다, 울다, 찡그리다, 화내다 등 기본적인 감정 표현에 따른 얼굴 표정을 표현한다. 예를 들어 슬 픈 표정의 얼굴 동영상은 눈썹 끝과 입꼬리가 내려가는 것을 표현하고 기쁜 표정의 동영상은 눈썹이 올라가고 입꼬리가 올라가는 것을 표현할 수 있다. 각 얼굴 동영상마다 식별정보나 라벨이 부여되어 있고 하나 이상의 감 정이 하나 이상의 얼굴 동영상의 식별정보나 라벨에 매칭되어 있을 수 있다. 일 실시예에서 애니메이션 아카이브는 캐릭터 데이터의 캐릭터 특징에 따라 다양한 동작의 제스처 동영상 및/또는 얼굴 동영상을 포함할 수 있다. 예를 들어 '뛰다'라는 하나의 동작에 대해서도 캐릭터의 성별이나 나이 또는 외모에 따라 뛰는 동작이 다를 수 있고, '웃다' 또는 '울다' 등 감정 표현에 대해서도 캐릭터의 성별, 나 이, 또는 외모에 따라 동작이 각각 다를 수 있다. 그러므로 바람직하게는 하나의 동작이나 감정에 대해 캐릭터 의 특징에 따라 다양하고 세분화된 제스처 동영상 및/또는 얼굴 동영상을 구비하는 것이 바람직하다. 각각의 제스처 동영상 및/또는 얼굴 동영상마다 부여되는 식별정보나 라벨은 사용자가 부여하는 것일 수도 있지 만 바람직하게는 인공지능(AI) 등의 기계학습 알고리즘에 의해 자동적으로 부여될 수 있다. 예를 들어, 기계학 습 알고리즘은 식별정보나 라벨이 표시된 제스처 동영상 또는 얼굴 동영상을 학습용 데이터로 이용하여 학습한 후 임의의 제스처 또는 얼굴 동영상에 대해 식별정보나 라벨을 표시할 수 있다. 각각의 제스처 동영상 및/또는 얼굴 동영상은 상술한 바와 같이 기본적인 동작이나 감정을 나타내는 짧은 길이 의 단위 동영상이며 예를 들어 수분의 1초 내지 수초 사이의 길이를 갖는다. 일 실시예에 각각의 제스처 동영상 및/또는 얼굴 동영상은 특정 캐릭터가 아직 입혀지지 않은 형태의 동영상일 수 있다. 예를 들어 제스처 동영상은 관절, 뼈대 등 몸체의 특징점의 움직임을 정의하는 동영상일 수 있고 얼굴 동영상은 눈, 코, 입 등 얼굴의 특징점의 움직임을 정의하는 동영상일 수 있으며, 이러한 제스처 및/또는 얼굴 동영상에 특정 캐릭터의 외관이 입혀지는 리타겟 작업은 본 발명에 따른 캐릭터 애니메이션 동영상을 생성하기 직전 또는 생성한 이후 단계에서 수행될 수 있음을 이해할 것이다. 비주얼 매니저는 사용자가 발화한 음성신호에 따른 동작과 얼굴 표정을 캐릭터에 입혀서 애니메이션 영상 을 생성하는 기능부이다. 일 실시예에서 비주얼 매니저는 분석모듈에서 생성된 구문 데이터와 캐릭터 데이터를 수신하고, 이에 기초하여 애니메이션 아카이브에서 적절한 제스처 애니메이션과 얼굴 애니메이션 을 선택하고, 선택된 제스처 애니메이션과 얼굴 애니메이션을 구문 데이터와 캐릭터 데이터에 따라 블렌딩하여 캐릭터 애니메이션을 생성한다. 일 실시예에서 비주얼 매니저는 제스처 블렌딩부와 얼굴 블렌딩부를 포함한다. 제스처 블렌딩부 는 분석모듈로부터 수신한 구문 데이터와 캐릭터 데이터에 기초하여 애니메이션 아카이브에서 적절한 제스처 동영상을 선택한다. 예를 들어 제스처 블렌딩부는 구문 데이터의 단어 및/또는 구문의 동작 정보와 캐릭터 데이터의 캐릭터 특징(성별, 나이, 감정, 외모 중 적어도 하나)에 기초하여 하나 이상의 제스처 동영상을 선택할 수 있고, 단어 및/또는 구문의 발화한 시간 순서대로 이에 대응하는 제스처 동영상을 블렌딩하 여 시간적으로 연결된 하나의 애니메이션을 생성할 수 있다. 예를 들어 얼굴 블렌딩부는 구문 데이터의 단어 및/또는 구문의 감정 정보와 캐릭터 데이터의 특징(성별, 나이, 감정, 외모 중 적어도 하나)에 기초하여 하나 이상의 얼굴 동영상을 선택할 수 있고, 단어 및/또는 구문 의 발화한 시간 순서대로 이에 대응하는 얼굴 표정의 변화를 제스처 동영상과 블렌딩한다. 또한 일 실시예에서 얼굴 블렌딩부는 구문 데이터의 문장과 캐릭터의 입술 모양을 맞추는 입술 블렌딩(립싱크)도 수행할 수 있 다. 예를 들어 얼굴 블렌딩부는 구문 데이터의 문장(텍스트 정보)에 따른 각 단어의 모음의 발화 시점과 캐릭터의 입모양의 타이밍을 맞추어 입술 블렌딩을 수행할 수 있다. 이제 도3을 참조하여 캐릭터 애니메이션 생성 시스템의 예시적 동작을 설명하기로 한다. 도3을 참조하면, 단계(S10)에서 마이크(도시 생략) 등의 음성수신 장치를 통해 사용자가 발화하는 음성신호를 수신한다. 예를 들 어 도3의 실시예에서 사용자가 \"안녕하세요. 만나서 반가워요\"라는 문장을 발화하였다고 가정한다. 단계(S20)에서 분석 모듈의 STT 분석부와 구문 분석부에 의해 상기 문장을 구문 분석하여 구문 데이터를 생성한다. 예를 들어 STT 분석부(1110는 사용자가 발화한 음성신호를 '안녕하세요. 만나서 반가워요' 라는 텍스트 데이터로 변환하고 구문 분석부는 상기 문장을 구문 분석하여 각 단어나 구문에 따른 동작 정 보(예컨대 인사하는 동작, 손을 흔드는 동작 등) 및 감정 정보(예를 들어 기쁨, 놀람 등의 감정)를 포함하는 메 타 데이터를 생성할 수 있다. 또한 단계(S20)와 동시에 또는 순차적으로, 단계(S30)에서 분석 모듈의 음성 분석부가 사용자의 음성 신호를 분석하고 (예컨대 카메라 등의 촬영 장치가 있는 경우) 표정 분석부가 사용자의 얼굴 표정을 분석 한다. 각 분석에 따른 정보가 캐릭터 데이터 생성부로 전달되고 캐릭터 데이터 생성부는 이에 기초하 여 성별, 나이, 감정, 및 외모 중 적어도 하나에 대한 캐릭터 특징을 포함하는 캐릭터 데이터를 생성할 수 있다. 대안적으로 캐릭터 데이터 생성부는 구문 데이터에 포함된 문장(텍스트 정보)와 동작 정보 및 감정 정보도 참조하여 캐릭터 데이터를 생성할 수 있다. 구문 데이터와 캐릭터 데이터가 비주얼 매니저로 전달되고, 단계(S40)에서 비주얼 매니저는 복수의 제스처 동영상이 저장된 애니메이션 아카이브에서 상기 구문 데이터와 캐릭터 데이터에 매칭되는 하나 이 상의 제스처 동영상을 선택한다. 예를 들어 비주얼 매니저는 구문 데이터의 문장에 포함된 하나 이상의 단 어 또는 구문 및 캐릭터 데이터에 포함된 캐릭터 특징에 기초하여 하나 이상의 제스처 동영상을 선택할 수 있다. 이 때 일 실시예에서 비주얼 매니저는 구문 데이터의 시제 정보를 추가로 이용하여 제스처 동영상을 선택 할 수 있다. 예를 들어 사용자가 발화한 문장이 미래형이거나 가정법이라고 판단하면 해당 단어나 구문이 직접 적으로 나타내는 동작이 아닌 다른 동작을 선택할 수 있다. 단계(S40)와 동시에 또는 순차적으로, 단계(S50)에서 비주얼 매니저는 복수의 얼굴 동영상이 저장된 애니 메이션 아카이브에서 구문 데이터와 캐릭터 데이터에 매칭되는 하나 이상의 얼굴 동영상을 선택한다. 예를 들어 비주얼 매니저는 구문 데이터의 문장에 포함된 하나 이상의 단어 또는 구문 및 캐릭터 데이터에 포함된 캐릭터 특징에 기초하여 하나 이상의 얼굴 동영상을 선택할 수 있다. 그 후 비주얼 매니저는 선택된 하나 이상의 제스처 동영상 및 하나 이상의 얼굴 동영상을 블렌딩한다 (S60). 이 단계(S60)에서 캐릭터의 입술 모양을 사용자가 발화한 문장에 따라 립싱크하는 입술 블렌딩도 수행할 수 있다. 다음으로 단계(S70)에서 예컨대 리타겟 등의 추가 작업을 수행하여 최종적으로 캐릭터에 제스처와 얼 굴이 블렌딩된 캐릭터 애니메이션 동영상을 생성할 수 있다. 도4는 일 실시예에 따라 캐릭터의 동작과 감정을 표현하는 애니메이션을 생성하는 또 다른 예를 나타낸다. 설명 의 편의를 위해 도3의 일부 단계(S20, S30, S60, S70)를 도4에 표시하였다. 도4를 참조하면, 사용자가 특정 문장을 발화하면 분석모듈의 STT 분석부와 구문 분석부가 STT 분석 및 구문 분석을 수행하여 구문 데이터를 생성하고(S20) 음성 분석부와 표정 분석부가 음성신호 와 얼굴 표정을 각각 분석하여 캐릭터 데이터를 생성한다(S30). 구문 데이터와 캐릭터 데이터는 각각 비주얼 매니저의 제스처 블렌딩부와 얼굴 블렌딩부로 전달 되고 비주얼 매니저는 구문 데이터와 캐릭터에 데이터에 기초하여 애니메이션 아카이브에서 가정 적 절한 하나 이상의 제스처 동영상과 얼굴 동영상을 선택하여 불러온다. 그 후 비주얼 매니저는 선택된 하나 이상의 제스처 동영상과 얼굴 동영상을 블렌딩하고(S60) 캐릭터 애니 메이션 동영상을 생성한다(S70). 이 때 예를 들어 사용자가 \"어… 잠깐! 내가 바본 줄 알아?\"라는 문장을 발화 하였다고 가정하면, 비주얼 매니저는 구문 데이터와 캐릭터 데이터에 기초하여, '어… 잠깐!'이라는 구문 에 대응하여 생각하는 동작을 매칭하고 '내가'라는 단어에 대해 자신을 가리키는 동작을 매칭하고 '바본 줄 알 아?'라는 구문에 대해 화를 내는 동작을 매칭하여 각각의 제스처 동영상을 선택하여 불러온다. 또한 비주얼 매니저는 구문 데이터와 캐릭터 데이터에 기초하여, '어… 잠깐!'이라는 구문에 대해 생각하 는 얼굴 표정을 매칭하고 '내가 바본 줄 알아!'라는 구문에 대해 화를 내는 얼굴 표정을 매칭하여 각각의 얼굴 동영상을 선택하여 불러온다. 그 후 비주얼 매니저는 이와 같이 선택된 제스처 동영상을 시간적으로(즉, 문장 발화 시간에 따라) 블렌딩 하고 얼굴 동영상도 시간적으로(문장 발화 시간에 따라) 및 공간적으로(즉, 제스처와 합성하여) 블렌딩하여 캐 릭터 애니메이션을 생성한다. 이 때 비주얼 매니저는 문장의 각 단어의 발화 타이밍에 맞추어 입술 움직임 을 블렌딩하여 립싱크를 시킬 수도 있다. 이와 같이 본 발명의 일 실시예에 따르면 사용자가 발화하는 음성신호와 표정에 따라 그에 대응하는 적절한 제 스처와 얼굴 표정을 캐릭터에 입혀서 캐릭터 애니메이션을 생성할 수 있으므로 한 문장 내에서도 시간적으로 다 양한 감정 변화를 표현하고 그에 따른 제스처도 변화시킬 수 있다. 이제 도5 내지 도7을 참조하여 본 발명의 일 실시예에 따른 캐릭터 애니메이션 생성 시스템과 무선케어 장 치가 통합된 시스템을 설명하기로 한다. 도5를 참조하면, 본 발명의 일 실시예에 따른 무선케어장치가 통합된 캐릭터 애니메이션 생성 시스템(10 0)을 블록도로 도시하였다. 여기서 애니메이션 생성 시스템의 구성 및 동작은 도1 내지 도4를 참조하여 설 명하였고 이하에서는 차이점을 위주로 설명하기로 한다. 도5를 참조하면, 애니메이션 생성 시스템에서 생성한 동영상 데이터는 근거리 통신망(N2)과 광역 통신망 (N1)을 경유하여 서버에 저장될 수 있다. 여기서, 근거리 통신망(N2)은 무선 근거리 통신망일 수 있고 예 를 들면 와이파이나 블루투스 통신을 지원하는 무선 근거리 통신망일 수 있다. 광역 통신망(N1)은 인터넷과 같 은 통신망일 수 있다. 무선케어장치는 사운드 또는 텍스트 인식 기반의 동영상 캐릭터 자동 생성 시스템으로부터 소정 거리(예를 들면, 1킬로미터) 이내에 설치될 수 있다. 여기서, 소정 거리는 사운드 또는 텍스트 인식 기반의 동영상 캐릭터 자동 생성 시스템과 근거리 무선 통신이 가능한 거리이다. 무선케어장치는 무선 디바이스의 무선 신호를 감지할 수 있고, 감지된 무선 디바이스가 페이크 디바이스인 지 여부를 판별할 수 있다. 무선케어장치는, 구체적으로, 무선 디바이스의 타입을 추정하는 타입 추정 동작과, 무선 디바이스의 타입 에 따른 취약점으로 무선 디바이스를 공격하여 무선 디바이스가 페이크 디바이스인지 여부를 판별하는 동작을 수행한다. 여기서, 타입 추정 동작은, 포트 스캐닝 동작과 프로토콜 스캐닝 동작의 결과에 따라서 무선 디바이스의 타입을 추정하는 동작이다. 포트 스캐닝 동작은 무선 디바이스의 오픈 포트를 찾는 동작이고, 프로토콜 스캐닝 동작은 포트 스캐닝 동작의 수행결과로 알아낸 오픈 포트(Open Port)에서 사용하는 프로토콜을 찾는 동작이다. 프로토콜 스캐닝 동작은, 오픈 포트(Open Port)의 종류를 확인하는 동작과, 오픈 포트의 종류에 따른 프로토콜 확인용 패킷을 작성하여 오픈 포트(Open Port)를 가진 무선 디바이스에게 전송하는 동작과, 무선 디바이스로부 터 프로토콜 확인용 패킷에 대한 응답이 수신되는지를 확인하는 동작이다. 여기서, 응답은 오픈 포트(Open Port)를 가진 무선 디바이스의 배너(Banner) 정보와 서비스(Service) 정보 중 적어도 하나를 포함하며, 배너 정 보 또는 서비스 정보가 무선 디바이스의 타입을 나타내는 정보를 포함한다. 타입 추정 동작은 프로토콜 스캐닝 동작의 수행결과로 찾은 프로토콜로부터 서비스의 종류를 추정하는 제1추정 동작과, 무선 디바이스의 타입을 나타내는 정보로부터 서비스의 종류를 추정하는 제2추정동작과, 제1추정동작에 의해 추정된 서비스의 종류와 제2추정동작에 의해 추정된 서비스의 종류를 비교하는 동작과, 비교 결과 양자가 다를 경우에 무선 디바이스의 타입을 나타내는 정보로부터 오픈 포트(Open Port)를 가진 무선 디바이스의 타입 을 추정하는 동작을 수행한다. 서버는 도1을 참조하여 설명한 캐릭터의 동작 자동 생성 시스템과 통신적으로 연결되어 물리적으로 1개 이 상의 장치 또는 기억장치, 운영체제, 펌웨어, 응용 프로그램, 통신부, 및 기타 리소스를 각각 구비하거나 일부 자원들을 공유하도록 구성될 수 있다. 도5에는 본 시스템의 설명을 위해서, 무선장치(15: 15a, 15b, 15c, 15d)를 추가적으로 도시하였다. 무선케어장치는 서버와 애니메이션 생성 시스템의 통신을 해킹할 수 있는 위험한 디바이스(이하 '페이크 디바이스'라고도 함)를 검출하고, 통신을 차단할 수 있다. 이하에서 무선케어장치의 동작을 보다 상세히 설명하기로 한다. 무선케어장치는 무선 디바이스의 통신을 모니터링할 수 있고, 근거리 무선 통신도 할 수 있다. 예를 들어 무선 디바이스는 블루투스(Bluetooth) 또는 와이파이(Wi-Fi)와 같은 근거리 무선 통신 기술 표준에 따 른 통신을 할 수 있다. 무선 디바이스는 시스템에 나쁜 영향을 줄 수도 있는 디바이스이고, 무선케어 장치는 무선 디바이스에서 페이크 디바이스를 선별할 수 있다. 무선 디바이스는 스마트폰이나 무 선통신이 가능한 노트북과 같은 장치일 수 있으나, 이들에만 한정되는 것은 아니다. 무선케어장치는 타입 추정동작 및 페이크 디바이스 선별 및 차단 동작을 수행할 수 있다. 후술하겠지만, 무선케어장치에 포함된 통신부(도6과 그 설명 참조)는 무선 디바이스가 출력하는 무선 신호들을 감지할 수 있다. 여기서, 무선 신호는 예를 들면 블루투스 통신을 위해 출력되는 신호 또는 와이파이 통신을 위해 출력되는 신호일 수 있다. 무선케어장치는 통신부에 의해 감지된 디바이스들 중에서 소정 기 준에 따라 하나 이상의 디바이스를 타겟 디바이스로서 선별할 수 있다. 여기서, 소정 기준은 신호의 세기일 수 있다. 후술하겠지만, 무선케어장치에 포함된 진단모듈은, 예를 들면, 타겟 디바이스의 타입을 추정할 수 있 고, 또한 타겟 디바이스가 페이크 디바이스인지 여부를 판단할 수 있다. 본 실시예에서, 무선 디바이스의 갯수는 각각 4개로 도시되어 있으나, 이러한 갯수는 예시적인 것으로서 이 보다 적거나 또는 많을 수 있다. 이하에서는, 무선 디바이스가 타겟 디바이스라고 가정하고, 타입 추정동작, 페이크 디바이스 선별동작, 및 차단동작을 순차적으로 설명하기로 한다. 타입 추정 동작 타겟 디바이스의 타입을 추정하는 동작이다. 본 실시예에서, 진단모듈은 포트 스캐닝(Port Scanning) 동작 과, 프로토콜 스캐닝(Protocol Scanning) 동작과, 타입 추정 동작(Type Assumption)을 수행할 수 있다. 포트 스캐닝(Port Scanning) 동작은 타겟 디바이스의 오픈 포트(Open Port)를 찾는 것이다. 즉, 포트 스캐 닝(Port Scanning) 동작은 타겟 디바이스(15a), 타겟 디바이스(15b), 타겟 디바이스(15c), 및 타겟 디바이스 (15d) 각각에 대하여 어떤 포트가 오픈되어 있는지를 확인하는 동작이다. 포트 스캐닝(Port Scanning) 동작은 예를 들면, 풀 스캐닝(FULL SCNNING) 또는 스텔스 스캐닝(STEALTH SCANNING) 이라 불리우는 기술들에 의해 수행될 수 있다. 풀 스캐닝은 완벽한 TCP 세션(Session)을 맺어서 열려 있는 포트를 확인하는 기술이다. 스텔스 스캐닝은 하프 스캔(half scan) 기술의 일종이며, 포트 확인용 패킷을 전송하고 그러한 포트 확인용 패킷에 대한 응답(response)이 오면 응답한 포트가 열려있는 것이고, 응답이 오지 않으면 포트가 닫혀 있는 것으로 판단한다. 스텔스 스캐닝은 예를 들면, FIN, NULL, 또는 XMASH 일 수 있다. 포트(Port)는 네트워크 서비스나 특정 프로세스를 식별하는 논리 단위이며, 포트를 사용하는 프로토콜 (Protocol)은 예를 들면 전송 계층 프로토콜이다. 전송 계층 프로토콜의 예를 들면 전송 제어 프로토콜(TCP)과 사용자 데이터그램 프로토콜(UDT)와 같은 것일 수 있다. 포트들은 번호로 구별되며, 이러한 번호를 포트 번호라 고 부른다. 예를 들면, 포트 번호는 IP 주소와 함께 사용된다. 포트 번호는 예를 들면 3가지 종류로 분류될 수 있다. 포트 번호가 0번 ~ 1023번에 속하면 잘 알려진 포트(well-known port)이고, 포트 번호가 1024번 ~ 49151번에 속하면 등록된 포트(registered port)이고, 포트 번호가 49152번 ~ 65535번에 속하면 동적 포트(dynamic por t)이다. 한편, 잘 알려진 포트의 대표적인 예를 들면, 20번: FTP(data), 21번: FTP(제어), 22번: SSH, 23번: 텔넷, 53번: DNS, 80번: 월드 와이드 웹 HTTP, 119번: NNTP, 443번: TLS/SSL 방식의 HTTP 이다. 이러한 포트 번호들과 포트 종류는 예시적인 것임을 당업자는 용이하게 알 수 있을 것이다. 본 발명의 설명의 목적을 위해서, 타겟 디바이스(15a)의 오픈 포트는 80번 포트이고, 타겟 디바이스(15b)의 오 프 포트는 23번 포트이고, 타겟 디바이스(15c)의 오픈 포트는 5555번 포트이고, 타겟 디바이스(15d)의 오픈 포 트는 5559번 포트라고 가정한다. 포트 스캐닝(Port Scanning) 동작은 타겟 디바이스의 오픈 포트(Open Port)를 찾는 동작이다. 예를 들면, 진단모듈은 포트 스캐닝 동작을 통해서, 타겟 디바이스(15a)의 오픈 포트는 80번 포트가, 타겟 디바이스(15b)의 오프 포트는 23번 포트이고, 타겟 디바이스(15c)의 오픈 포트는 5555번 포트이고, 타겟 디바이스(15d)의 오픈 포트는 5559번 포트라는 것을 알아낸다. 프로토콜 스캐닝(Protocol Scanning) 동작은 오픈 포트(Open Port)에서 사용되는 프로토콜의 종류를 알기 위한 동작이다. 여기서, 오픈 포트는 포트 스캐닝 동작에 의해 알아낸 것이다. 예를 들면, 진단모듈은 타겟 디바이스 (15a)의 오픈 포트인 80번 포트에서 사용되는 프로토콜이 무엇인지를 찾는다. 또한, 진단모듈은 타겟 디바이스(15b)의 23번 포트에서 사용되는 프로토콜과, 타겟 디바이스(15c)의 5555번 포 트에서 사용되는 프로토콜과, 타겟 디바이스(15d)의 5559번 포트에서 사용되는 프로토콜이 무엇인지를 각각 찾 는다. 진단모듈에 의해 수행되는 프로토콜 스캐닝 동작은, 오픈 포트의 종류를 확인하는 동작, 오픈 포트의 종류에 따 라서 오픈 포트에 보낼 패킷(이하, '프로토콜 확인용 패킷')를 작성하는 동작, 프로토콜 확인용 패킷을 상기 오 픈 포트를 가진 무선 디바이스에게 전송하는 동작, 및 프로토콜 확인용 패킷을 전송한 상기 무선 디바이스로부 터 응답이 수신되는지를 확인하는 동작을 포함한다. 프로토콜 확인용 패킷은 예를 들면 스크립트(Script)일 수 있다. 오픈 포트의 종류를 확인하는 동작은, 포트 스캐닝 동작에 의해 알아낸 오픈 포트의 종류가 무엇인지를 확인하 는 동작이다. 예를 들면, 오픈 포트의 종류를 확인하는 동작은 상기 오픈 포트가 잘 알려진 포트(well-known port), 등록된 포트(registered port), 또는 동적 포트(dynamic port) 중 어디에 해당되는지를 확인하는 동작 이다. 오픈 포트의 종류를 확인하는 동작의 수행을 위해서, 포트 번호에 따라서 포트의 종류가 분류된 데이터 (예를 들면, <표1>)(이하, '포트 종류 데이터')가 미리 준비되어 있어야 한다. 이러한 '포트 종류 데이터'는 무 선케어장치에 의해 저장되어 관리될 수 있다. 일 실시예에 따르면, 진단모듈은, '포트 종류 데이터'를 참조함으로써, 상기 오픈 포트의 종류를 알 수 있다. 예를 들면, 진단모듈은 타겟 디바이스(15a)의 80번 포트와 타겟 디바이스(15b)의 23번 포트는 잘 알려진 포트 (well-known port)이고, 타겟 디바이스(15c)의 5555번 포트와 타겟 디바이스(15d)의 5559번 포트는 동적 포트 (dynamic port)임을 알 수 있다. 진단모듈은, 오픈 포트의 종류에 맞는 프로토콜 확인용 패킷을 작성하는 동작을 수행한다. 예를 들면, 타겟 디바이스(15a)의 80번 포트는 월드 와이드 웹 HTTP 프로토콜을 사용하는 것으로 잘 알려진 포 트(well-known port)이므로, 웹 HTTP 프로토콜을 사용하여 프로토콜 확인용 패킷을 작성하여 타겟 디바이스(15a)에게 전송한다. 타겟 디바이스(15a)로부터 웹 HTTP 프로토콜을 이용하여 작성된 프로토콜 확인용 패킷에 대한 응답이 있으면, 진단모듈은 타겟 디바이스(15a)의 80번 포트가 웹 HTTP 프로토콜을 이용한다고 결정한다. 한편, 타겟 디바이스(15a)로부터 웹 HTTP 프로토콜을 이용하여 작성된 프로토콜 확인용 패킷에 대한 응답이 없 으면, 진단모듈은 타겟 디바이스(15a)의 80번 포트가 웹 HTTP 프로토콜을 이용하지 않는다고 결정한다. 이러한 경우, 진단모듈은 월드 와이드 웹 HTTP 프로토콜이 아닌 다른 프로토콜을 사용하여 프로토콜 확인용 패킷을 작 성한 후 타겟 디바이스(15a)에게 전송한다. 타겟 디바이스(15a)로부터 웹 HTTP 프로토콜이 아닌 다른 프로토콜로 작성된 프로토콜 확인용 패킷에 대한 응답 이 있으면, 진단모듈은 타겟 디바이스(15a)의 80번 포트가 상기 다른 프로토콜을 이용한다고 결정한다. 만약, 타겟 디바이스(15a)로부터 웹 HTTP 프로토콜이 아닌 상기 다른 프로토콜로 작성된 프로토콜 확인용 패킷에 대한 응답이 없으면, 진단모듈은 타겟 디바이스(15a)의 80번 포트가 상기 다른 프로토콜을 이용하지 않는다고 결정한 다. 이후, 타겟 디바이스(15a)는 타겟 디바이스(15a)로부터 응답이 올때까지 또 다른 프로토콜을 사용하여 프로 토콜 확인용 패킷을 작성하여 전송한다. 진단모듈은 상술한 방법에 의해 타겟 디바이스의 각각의 오픈 포트 에서 실제 사용되는 프로토콜의 종류를 알아 낸다. 진단모듈은, 상술한 포트 스캐닝 동작의 수행결과와 프로토콜 스캐닝(Protocol Scanning) 동작의 수행결과 중 적어도 하나의 결과를 이용하여, 타겟 디바이스의 각각의 타입(type)을 추정하는 타입 추정 동작(Type Assumption)을 수행한다. 일 실시예에 따르면, 진단모듈에 의해 수행되는 타입 추정 동작(Type Assumption)은, 프로토콜 스캔 동작의 수 행결과로 알아낸 프로토콜의 종류로부터 서비스의 종류를 추정하는 동작과, 그렇게 추정된 서비스의 종류로부터 무선 디바이스의 타입을 추정하는 동작을 포함한다. 프로토콜의 종류로부터 서비스의 종류를 추정하는 동작은, 통상적으로 서비스마다 주로 사용되는 프로토콜이 정 해져 있다는 경험에 기초한 것이다. 예를 들면, RTSP, RTP, 또는 RTCP 프로토콜은, 주로 스트리밍 서비스를 지 원한다. 즉, 프로토콜마다 주로 지원되는 서비스들을 정의한 데이터(이하, '프로토콜-서비스 매핑(mapping) 데 이터'가 준비되면, 진단모듈은 '프로토콜-서비스 매핑 데이터'를 이용하여, 프로토콜의 종류로부터 서비스의 종 류를 추정할 수 있다. '프로토콜-서비스 매핑 데이터'는 무선케어장치에 의해 저장되어 관리될 수 있다. 서비스의 종류로부터 타겟 디바이스의 타입을 추정하는 동작도, 통상적으로 무선 디바이스들의 타입별로 주 로 사용되는 서비스가 정해져 있다는 경험에 기초한 것이다. 예를 들면, RTSP, RTP, 또는 RTCP 프로토콜은 주로 스트리밍 서비스를 지원하고, 이러한 스트리밍 서비스는 예를 들면 IP TV와 같은 무선 디바이스에 의해 제공된 다. 즉, 서비스마다 주로 제공되는 무선 디바이스들의 타입을 정의한 데이터(이하, '서비스-타입 매핑(mapping) 데이터'가 준비되면, 진단모듈은 '서비스-타입 매핑 데이터'를 이용하여, 서비스의 종류로부터 무선 디바이스의 타입을 추정할 수 있다. '서비스-타입 매핑 데이터'는 무선케어장치에 의해 저장되어 관리될 수 있다. 한편, 프로토콜 확인용 패킷에 대한 응답에는 타겟 디바이스의 배너(Banner) 정보와 서비스(Service) 정보 중 적어도 하나를 포함할 수 있다. 프로토콜 확인용 패킷에 대한 응답에 포함된 배너(Banner) 정보에는 통상적으로, 타겟 디바이스에서 사용되 는 운영체제(Operating System)가 어떤 종류인지를 나타내는 데이터가 포함되어 있다. 진단모듈은, 운영체제의 종류를 알면 서비스의 종류를 알거나 또는 타겟 디바이스의 타입을 추정할 수 있다. 프로토콜 확인용 패킷에 대한 응답에 포함된 서비스(Service) 정보에는 통상적으로 타겟 디바이스가 어떠한 타 입인지를 나타내는 데이터가 포함되어 있다. 예를 들면, 서비스(Service) 정보에는 '나의 아이폰'(My iPhone)과 같은 데이터가 포함되어 있을 수 있으며, 이러한 데이터는 타겟 디바이스의 타입을 직접적으로 나타내는 정보이 다. 일 실시예에 따르면, 진단모듈에 의해 수행되는 타입 추정 동작(Type Assumption)은, 타겟 디바이스의 배너 (Banner) 정보와 서비스(Service) 정보 중 적어도 하나의 정보와, 상술한 포트 스캐닝 동작의 수행결과와 프로 토콜 스캐닝(Protocol Scanning) 동작의 수행결과 중 적어도 하나의 수행결과를 이용한다. 예를 들면, 진단모듈에 의해 수행되는 타입 추정 동작(Type Assumption)은, 제1 추정동작, 제2 추정동작, 비교 동작, 및 타입결정동작을 포함한다. 제1 추정동작은 프로토콜 스캐닝 동작에 의해 획득된 프로토콜의 종류로부터 서비스의 종류를 추정하는 동작이 다. 제2 추정동작은 타겟 디바이스의 배너(Banner) 정보와 서비스(Service) 정보 중 적어도 하나의 정보를 이용하여 서비스의 종류를 추정하는 동작이다. 비교동작은, 제1 추정동작에 의해 추정된 서비스의 종류와 제2 추정동작에 의해 추정된 서비스의 종류를 비교하 는 동작이다. 타입결정동작은, 제1 추정동작에 의해 추정된 서비스의 종류와 제2 추정동작에 의해 추정된 서비스의 종류가 서 로 다를 경우에 제2 추정동작에 의해 추정된 서비스의 종류로부터 타겟 디바이스의 타입을 결정하고, 제1 추정동작에 의해 추정된 서비스의 종류와 제2 추정동작에 의해 추정된 서비스의 종류가 서로 같을 경우에 제1추 정동작 또는 제2 추정동작에 의해 추정된 서비스의 종류로부터 타겟 디바이스들의 타입을 추정하는 동작이 다. 한편, 타겟 디바이스의 배너(Banner) 정보와 서비스(Service) 정보가 없거나, 그러한 배너 정보와 서비스 정보에 서비스의 종류를 추정할 수 있는 데이터가 없을 경우, 타입 추정 동작(Type Assumption)은, 제1 추정동 작과 타입결정동작을 포함한다. 즉, 제2 추정동작과 비교동작의 수행이 없이, 제1추정동작과 타입결정동작만으 로 타입 추정 동작이 수행될 수 있다. 페이크 디바이스 선별 동작은 타겟 디바이스 중에서 페이크 디바이스를 선별하는 동작이다. 본 실시예에서, 진단모듈은, 타겟 디바이스의 각각에 대하여 페이크 디바이스인지 여부를 판단한다. 예를 들면, 진단모듈은, 타겟 디바이스 중에서 타겟 디바이스(15a)에 대하여 페이크 디바이스인지 여부를 판단하고, 타 겟 디바이스(15b)에 대하여 페이크 디바이스인지 여부를 판단하고, 타겟 디바이스(15c)에 대하여 페이크 디바이 스인지 여부를 판단하고, 그리고 타겟 디바이스(15d)에 대하여 페이크 디바이스인지 여부를 판단할 수 있다. 여"}
{"patent_id": "10-2022-0021056", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기서, 순서는 예시적인 것으로서, 본 발명이 속하는 기술분야에 종사하는 자(이하, '당업자')가 본 발명을 실시 할때 상황에 맞도록 순서를 정할 수 있을 것이다. 진단모듈은 페이크(fake) 디바이스인지 여부를 판단하는 대상이 되는 대상 디바이스의 타입에 따른 취약점을 공 격하고, 진단모듈은 타겟 디바이스에 대한 공격이 성공하는지 여부에 따라서, 타겟 디바이스가 페이크 디바이스 인지 여부를 판단한다. 통상적으로, 무선 디바이스의 취약점(vulnerability)은 공격자가 디바이스의 정보 보증 을 낮추는데 사용되는 약점을 의미한다. 타겟 디바이스(15a)가 '타겟 디바이스' 인 경우를 예로 들면, 진단모듈은 타겟 디바이스(15a)가 가진 취약점에 대한 공격이 성공하는지 여부에 따라서, 타겟 디바이스(15a)가 페이크 디바이스 인지 여부를 판단할 수 있다. 즉, 진단모듈은, 타겟 디바이스(15a)가 가진 취약점에 대한 공격이 성공하면 타겟 디바이스(15a)가 페이크 디바 이스가 아니라고 판단하고, 타겟 디바이스(15a)가 가진 취약점에 대한 공격이 성공하지 못하면 타겟 디바이스 (15a)가 페이크 디바이스라고 판단한다. 진단모듈은, 타겟 디바이스의 각각의 타입에 따른 취약점을 선택하고, 선택한 취약점을 이용해서 타겟 디바 이스의 각각을 공격하고, 그러한 공격 결과에 기초하여 타겟 디바이스 중에서 페이크 디바이스를 선별 할 수 있다. 본 발명의 다른 실시예에 따른 진단모듈은, 타겟 디바이스의 각각의 타입을 추정하고, 추정한 각각에 타입 에 대응된 취약점을 공격하고, 그러한 공격결과에 기초하여 타겟 디바이스 중에서 페이크 디바이스를 판단 할 수 있다. 상술한 실시예들에서, 진단모듈은 타입별로 취약점이 대응된 데이터('타입별 취약점 데이터')를 참조하여, 타겟 디바이스의 타입에 따른 취약점 공격용 메시지를 생성할 수 있다. 타입별 취약점 데이터는 무선케어장치 에 구비된 기억장치(후술하기로 함)에 의해 저장되어 관리되는 것일 수 있다. 다르게는, 무선케어장치 가 접근가능하도록 통신적으로 연결된 외부의 기억장치(미 도시)에 타입별 취약점 데이터에 저장되어 관리 될 수 있다. 상술한 실시예들에서, 타겟 디바이스의 타입에 따른 취약점을 선택하는 동작은, 타입별 취약점 데이터를 참 조하여 타겟 디바이스의 타입에 대응되는 취약점을 찾는 동작일 수 있다. 상술한 실시예들에서, 진단모듈은 타입별로 취약점이 대응된 데이터('타입별 취약점 데이터')를 참조하여, 타겟 디바이스의 타입에 따른 취약점 공격용 메시지를 생성할 수 있다. 타입별 취약점 데이터는 무선케어장치 에 구비된 기억장치(후술하기로 함)에 의해 저장되어 관리되는 것일 수 있다. 다르게는, 무선케어장치 가 접근가능하도록 통신적으로 연결된 외부의 기억장치(미 도시)에 타입별 취약점 데이터에 저장되어 관리 될 수 있다. 상술한 실시예들에서, 타겟 디바이스의 타입에 따른 취약점을 선택하는 동작은, 타입별 취약점 데이터를 참 조하여 타겟 디바이스의 타입에 대응되는 취약점을 찾는 동작일 수 있다. 상술한 실시예들에서, 타겟 디바이스의 취약점을 공격하는 동작은 예를 들면 진단모듈이 취약점 공격용 메 시지를 타겟 디바이스에게 전송하는 동작일 수 있다. 상술한 실시예들에서, 진단모듈은 타겟 디바이스가 취약점 공격에 대한 응답을 할 경우에는 타겟 디바이스가 페 이크 디바이스가 아니라고 판단을 하고, 타겟 디바이스가 취약점 공격에 대한 응답을 하지 않을 경우에는 타겟 디바이스가 페이크 디바이스라고 판단할 수 있다. 이하에서는, 무선 디바이스들이 가지는 취약점과 취약점 공격용 메시지에 대하여 예시적으로 설명하기로 한다. 일 예를 들면, 타겟 디바이스는 다음과 같은 타입의 취약점을 가진 라우터(router)일 수 있다. . 취약점: 권한 없는 공격자가 HTTP GET 메소드로 \"/category_view.php\" URL에 접근할 수 있음 . 취약점 공격용 메시지: GET/category_view.php 다른 예를 들면, 타겟 디바이스는 다음과 같은 타입의 취약점을 가진 라우터(router)일 수 있다. ㆍ취약점: 권한 없는 공격자가 HTTP GET 메소드로 \"/mydlink/get_TriggedEventHistory.asp\" URL에 접근할 수 있음 . 취약점 공격용 메시지: GET/mydlink/get_TriggedEventHistory.asp 또 다른 예를 들면, 타겟 디바이스는 다음과 같은 타입의 취약점을 가진 라우터(router)일 수 있다. . 취약점: 권한 없는 공격자가 HTTP GET 메소드로 \"/router_info.xml?section=wps\" URL에 접근하여 타겟 디바 이스의 PIN 과 MAC 주소 등의 정보를 얻을 수 있음. . 취약점 공격용 메시지: GET/router_info.xml?section=wps 또 다른 예를 들면, 타겟 디바이스는 다음과 같은 타입의 취약점을 가진 라우터(router)일 수 있다. . 취약점: 권한 없는 공격자가 HTTP POST 메소드로 \"/wpsacts.php\" URL에 접근할 시 데이터에 스크립트 구문을 넣을 수 있는 있음. . 취약점 공격용 메시지: GET//wpsacts.php 본 발명의 실시예들에 따르면, 타겟 디바이스는 같은 종류의 기능을 가진 것이라도 취약점이 다르다면 서로 다 른 타입으로 취급된다. 예를 들면, 상술한 라우터들은 취약점이 서로 달라서, 따라서 서로 다른 타입의 타겟 디 바이스로 구별된다. 다른 예를 들면, 타겟 디바이스의 제조사가 같고, 같은 종류의 디바이스라고 하더라도 펌 웨어(firm ware)가 서로 다르다면 다른 타입으로 취급된다. 본 발명의 일 실시예에 따르면, '타입별 취약점 데이터'는 타겟 디바이스의 타입별로 취약점이 각각 대응된 데 이터일 수 있다. 이러한 타입별 취약점 데이터가 저장되어 관리될 경우, 진단모듈은 타입별 취약점 데이터를 참 조해서 타겟 디바이스의 취약점을 공격한다. 다르게는(alternatively), '타입별 취약점 데이터'는 타겟 디바이스의 타입별로 '취약점 공격용 메시지'가 대응 된 데이터일 수 있다. 본 발명의 다른 실시예에 따르면, 타입별 취약점 데이터가 미리 준비되어 있지 않을 수 있다. 이러한 실시예의 경우, 진단모듈은 타겟 디바이스의 타입에 대응된 취약점 공격용 메시지를 직접 생성할 수 있다(예를 들면, 취 약점 공격부가 타입별로 취약점 공격용 메시지를 직접 생성할 수 있도록 구성된 경우). 차단동작은, 페이크 디바이스의 통신을 차단하는 동작이다. 차단동작은 페이크 디바이스에 대하여 디도스(DDos) 공격을 함으로써 페이크 디바이스의 통신을 차단시키는 동작이다. 예를 들면, 진단모듈은 페이크 디바이스에게 대량의 메시지를 전송하며, 대량의 메시지를 전송받은 페이크 디바 이스는 그러한 메시지에 대응하느라 다른 기기와의 통신이 불능 상태에 빠지게 된다. 이처럼, 진단모듈은 취약 점이 있는 타겟 디바이스의 통신을 차단시킬 수 있다. 예를 들면, 무선 디바이스(15a)가 페이크 디바이스라고 가정하면, 진단모듈은 페이크 디바이스(15a)에 대하여 디도스(DDos) 공격을 함으로써 블루투스 기기의 통신을 차단시킨다. 즉, 진단모듈은 페이크 디바이스(15a)에게 대량의 메시지를 전송함으로써, 대량의 메시지를 전송받은 페이크 디바이스(15a)는 그러한 메시지에 대응하느라 다른 블루투스 디바이스와 통신을 할 수 없게 된다. 이처럼, 진단모듈은 페이크 디바이스(15a)만 통신을 차단시 킬 수 있다. 이하에서는, 본 발명의 일 실시예에 따른 무선케어장치의 예시적 구성을 설명하기로 한다. 본 발명의 무선케어장치는, 포트 스캐닝부, 프로토콜 스캐닝부, 타입 추정부, 판단부, 운영체제, 통신부, 취약점 공격부, 컴퓨터 프로세서, 주변 기기, 기억장치, 및 메모리를 포함하며, 이들 구성요소는 서로 동작적으 로 연결되어 있다. 한편, 포트 스캐닝부, 프로토콜 스캐닝부, 타입 추정부, 판단부, 및 취약점 공격부를 진단 모듈로 통칭하기로 한다. 진단모듈은 상술한 타입 추정동작, 페이크 디바이스 선별동작 및 차단동작을 수행할 수 있다. 구체적으로, 포트 스캐닝부가 포트 스캐닝 동작을 수행하고, 프로토콜 스캐닝부는 프로토콜 스캐닝 동작을 수행하고, 타입 추정부 는 디바이스의 타입을 추정하고, 판단부는 페이크 디바이스 선별동작 및 차단동작을 수행할 수 있다. 이들 각각 의 동작은 상술한 부분을 참조하기 바란다. 포트 스캐닝부는 상술한 포트 스캐닝 동작을 수행한다. 포트 스캐닝부는 포트 확인용 패킷을 작성하고 통신부를 통해서 포트 확인용 패킷을 무선 디바이스에게 전송하고, 포트 확인용 패킷에 대한 응답이 수신되는지를 확 인하여 무선 디바이스에서 오픈된 포트를 결정한다. 프로토콜 스캐닝부는 상술한 프로토콜 스캐닝 동작을 수행한다. 프로토콜 스캐닝부는 프로토콜 확인용 패킷을 작성하고, 통신부를 통해서 프로토콜 확인용 패킷을 무선 디바이스에게 전송하고, 프로토콜 확인용 패킷에 대한 응답이 수신되는지를 확인하고, 오픈된 포트에서 실제 사용되는 프로토콜을 결정한다. 취약점 공격부는 취약점 공격용 메시지를 통신부를 통해서 대상 디바이스로 전송하며, 판단부는 취약점 공격용 메시지에 대한 응답이 있는지 여부를 확인한 후, 응답이 있으면 대상 디바이스가 페이크 디바이스가 아니고, 응 답이 없으면 페이크 디바이스라고 판단한다. 운영체제는 하드웨어를 관리할 뿐 아니라 응용 소프트웨어를 실행하기 위하여 하드웨어 추상화 플랫폼과 공통 시스템 서비스를 제공하는 소프트웨어이고, 기억장치와 메모리는 각각 프로그램이 저장되고 실행되기 위한 공간 을 제공하는 기록매체를 포함한다. 컴퓨터 프로세서는 중앙처리장치(CPU)이며, 이러한 중앙처리장치는 컴퓨터 시스템을 통제하고 프로그램의 연산을 실행하는 컴퓨터의 제어 장치, 또는 그 기능을 내장한 칩이다. 메모리 및/또는 기억장치에는 프로그램이 저장 또는 실행되는 공간을 제공하며, 또한 프로토콜-서비스 매핑 (mapping) 데이터 또는 서비스-타입 매핑(mapping) 데이터와 같이 본원 발명의 동작에 필요한 데이터들을 저장 할 수 있다. 메모리 및/또는 기억장치는, 또한, 각종 데이터를 임시 및/또는 영구적으로 저장할 수 있다. 예를 들면, 메모리 및/또는 기억장치는 취약점 공격용 메시지를 저장할 수 있다. 타입 추정부는 상술한 타입 추정 동작을 수행한다. 일 실시예에 따르면, 타입 추정부는 무선 디바이스의 배 너(Banner) 정보와 서비스(Service) 정보 중 적어도 하나의 정보와, 포트 스캐닝부의 동작결과와 프로토콜 스캐 닝부의 동작결과 중 적어도 하나의 동작결과를 이용한다. 다른 실시예에 따르면, 포트 스캐닝부의 동작결과와 프로토콜 스캐닝부의 동작결과 중 적어도 하나의 결과를 이 용한다. 이들 실시예들에 대한 상세한 설명은 상술한 바가 있으므로, 생략하기로 한다. 일 실시예에 따르면, 기억장치 및/또는 메모리에는 타입 추정부의 타입 추정 결과가 저장된다. 타입 추정 결과 는 무선 디바이스 별로 타입이 대응된 데이터이다. 한편, 기억장치 및/또는 메모리에는 타입별 취약점 데이 터도 저장되어 있을 수 있다. 타입별 취약점 데이터(타입별로 취약점이 대응된 데이터임)는 대상 디바이스의 타입이 가지는 취약점을 찾기 위해서 사용된다. 취약점 공격부는 타입별 취약점 데이터를 참조하여 대상 디바이스의 타입에 대응되는 취약점을 찾아서 취약점 공격용 메시지를 생성할수 있다. 이후, 취약점 공격용 메시지는 통신부를 통해서 대상 디바이스로 전송된다. 판 단부는 취약점 공격용 메시지에 대한 응답이 있는지 여부를 확인한 후, 응답이 있으면 대상 디바이스가 페이크 디바이스가 아니고, 응답이 없으면 페이크 디바이스라고 판단한다. 도6은 본 발명의 일 실시예에 따른 무선케어 방법을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 무선 케어 방법은 시스템에 근접한 타겟 디바이스('타겟 디바이스'라고도 함)들 중에서 페이크 디바이스를 판별 하기 위한 것이다. 도6을 참조하면, 본 발명의 일 실시예에 따른 무선케어 방법은 타겟 디바이스의 타입을 추정하는 단계(S100); 타겟 디바이스의 타입에 따른 취약점을 선택하는 단계(S300); S300단계에서 선택한 상기 취약점을 공격하는 단 계(S400); 및 상기 타겟 디바이스에 대한 공격이 성공하는지 여부에 따라서, 상기 타겟 디바이스가 페이크 디바 이스 인지 여부를 판단하는 단계(S500)를 포함할 수 있다. 본 발명의 일 실시예에 따른 무선케어방법은, 무선 디바이스의 타입별로 취약점을 대응시킨 무선 디바이스 타입 별 취약점 데이터를 저장하여 관리하는 단계(S200);를 더 포함할 수 있다. 상술한 취약점을 선택하는 단계(S300)는, 무선 디바이스 타입별 취약점 데이터를 참조하여 타겟 디바이스의 타 입에 대응되는 취약점을 찾는 동작을 포함한다. 상술한 타겟 디바이스를 공격하는 단계(S400)는, 상기 타겟 디바이스의 타입에 따른 취약점을 선택하는 단계 (S300)에서 선택된 취약점을 공격하는 취약점 공격용 메시지를 생성하여 타겟 디바이스에게 전송하는 단계일 수 있다. 상술한 타겟 디바이스가 페이크 디바이스 인지 여부를 판단하는 단계(S500)는 타겟 디바이스가 상기 취약점 공 격용 메시지에 대한 응답을 할 경우에는 타겟 디바이스가 페이크 디바이스가 아니라고 판단을 하고, 타겟 디바 이스가 상기 취약점 공격용 메시지에 대한 응답을 하지 않을 경우에는 타겟 디바이스가 페이크 디바이스라고 판 단하는 단계일 수 있다. 이하에서는, 본 발명의 일 실시예에 따른 무선케어 방법이 도5를 참조하여 설명한 무선케어장치에 적용되 었다고 가정한다. 타겟 디바이스의 타입을 추정하는 단계(S100)는 도5를 참조하여 설명한 내용을 참조하기 바란다. 타입별 취약점 데이터 저장 및 관리 단계(S200)는 타겟 디바이스의 타입을 추정하는 단계(S100)의 결과를 무선 케어장치가 기록매체에 저장 및 관리하는 단계이다. 한편, 장치가 아닌 다른 컴퓨터(미 도시)가 S100 단계를 수행하는 것도 가능하다. 취약점을 선택하는 단계(S300)는 무선케어장치가 타겟 디바이스의 타입에 따른 취약점을 선택하는 단계이 다. 예를 들면, 취약점 공격부는 타입 추정부에 의해 추정된 타겟 디바이스의 타입에 따른 취약점을 선택할 수 있다. 이를 위해서, 기억장치에는 타입별 취약점 데이터를 저장되어 있으며, 취약점 공격부는 그러한 타입별 취 약점 데이터를 참조하여 타겟 디바이스의 타입에 대응된 취약점을 선택할 수 있다. 타겟 디바이스를 공격하는 단계(S400)는, 무선케어장치가 타겟 디바이스의 취약점을 공격하는 단계이다. 예를 들면, 취약점 공격부가 타겟 디바이스에게 취약점 공격용 메시지를 전송한다. 취약점 공격용 메시지는 타 겟 디바이스의 타입에 따라 선택된 취약점 데이터에 기초하여 생성된 것이다. 취약점 공격부는 취약점 공격용 메시지를 직접 생성할 수 있다. 타겟 디바이스가 페이크 디바이스 인지 여부를 판단하는 단계(S500)는, 예를 들면, 무선케어장치의 판단부 는 타겟 디바이스가 취약점 공격용 메시지에 대한 응답을 할 경우에는 타겟 디바이스가 페이크 디바이스가 아니 라고 판단을 하고, 타겟 디바이스가 상기 취약점 공격용 메시지에 대한 응답을 하지 않을 경우에는 타겟 디바이 스가 페이크 디바이스라고 판단할 수 있다. 도7은 본 발명의 일 실시예에 따른 무선 디바이스의 타입을 추정하는 방법을 설명하기 위한 도면이다. 도7을 참조하면, 본 발명의 일 실시예에 따른 무선 디바이스의 타입을 추정하는 방법은 타겟 디바이스의 오픈 포트(Open Port)를 찾는 포트 스캐닝 단계(Port Scanning step)(S110), 포트 스캐닝 단계(Port Scanningstep)(S110)의 수행결과로 찾아낸 오픈 포트(Open Port)에서 사용하는 프로토콜을 찾는 프로토콜 스캐닝 단계 (Protocol Scanning step)(S120), 상술한 스캔 단계들(S110, S120)의 결과에 기초하여, 타겟 디바이스의 타입 을 추정하는 타입 추정 단계(Type Assumption step)(S130)를 포함할 수 있다. 이하에서는, 본 발명의 일 실시예에 따른 무선 디바이스의 타입을 추정하는 방법이 도5를 참조하여 설명한 장치 에 적용되었다고 가정하고, 본 발명의 일 실시예에 따른 무선 디바이스의 타입을 추정하는 방법을 설명하 기로 한다. 포트 스캐닝 단계(S110)는 무선 디바이스의 오픈 포트(Open Port)를 찾는 것이다. 즉, 포트 스캐닝 단계 (S110)는, 도 2를 참조하여 설명한 포트 스캐닝(Port Scanning) 동작을 수행하는 단계이다. 본 실시예에서도, 본 발명의 설명의 목적을 위해서, 무선 디바이스(15a)의 오픈 포트는 80번 포트가, 무선 디바 이스(15b)의 오프 포트는 23번 포트이고, 무선 디바이스(15c)의 오픈 포트는 5555번 포트이고, 무선 디바이스 (15d)의 오픈 포트는 5559번 포트라고 가정하기로 한다 포트 스캐닝 단계(S110)는 무선 디바이스의 오픈 포트(Open Port)를 찾는 것이다. 예를 들면, 포트 스캐닝 단계(S110)의 수행결과, 무선 디바이스(15a)의 오픈 포트는 80번 포트가, 무선 디바이스(15b)의 오프 포트는 23 번 포트이고, 무선 디바이스(15c)의 오픈 포트는 5555번 포트이고, 무선 디바이스(15d)의 오픈 포트는 5559번 포트라는 것을 알게된다. 프로토콜 스캐닝 단계(S120)는, 오픈 포트(Open Port)에서 실제 사용되는 프로토콜의 종류를 알기 위한 단계이 다. 즉, 프로토콜 스캐닝 단계(S120)는, 도2를 참조하여 설명한 프로토콜 스캐닝 동작을 수행하는 단계이다. 한 편, 오픈 포트는 포트 스캐닝 단계(S110)의 수행결과로 획득된 것이다. 예를 들면, 프로토콜 스캐닝 단계(S120)는, 무선 디바이스(15a)의 오픈 포트인 80번 포트에서 사용되는 프로토 콜의 종류를 알아내는 동작을 수행한다. 또한, 프로토콜 스캐닝 단계(S120)는 무선 디바이스(15b)의 23번 포트 에서 사용되는 프로토콜과, 무선 디바이스(15c)의 5555번 포트에서 사용되는 프로토콜과, 무선 디바이스(5d)의 5559번 포트에서 사용되는 프로토콜이 무엇인지를 찾는 동작을 수행한다. 이처럼, 프로토콜 스캐닝 단계(S120) 는 무선 디바이스의 모든 오픈 포트에 대하여 실제 사용되는 프로토콜의 종류를 알아내는 단계이다. 프로토콜 스캐닝 단계(S120)는, 오픈 포트의 종류를 확인하는 단계, 프로토콜 확인용 패킷을 작성하는 단계, 프 로토콜 확인용 패킷을 상기 오픈 포트를 가진 타겟 디바이스에게 전송하는 단계, 및 프로토콜 확인용 패킷을 전 송한 타겟 디바이스로부터 응답이 존재하는지를 확인하는 단계를 포함한다. 한편, 오픈 포트의 종류를 확인하는 단계는 상술한 오픈 포트의 종류를 확인하는 동작을 수행하는 단계이고, 프로토콜 확인용 패킷을 작성하는 단계 는 상술한 프로토콜 확인용 패킷을 작성하는 동작을 수행하는 단계이고, 타겟 디바이스로부터 응답이 수신되는 지를 확인하는 단계는 상술한 타겟 디바이스로부터 응답이 수신되는지를 확인하는 동작을 수행하는 단계이다. 따라서, 이들 단계들에 대한 보다 상세한 설명은 생략하기로 한다. 오픈 포트의 종류를 확인하는 단계는, 포트 스캐닝 동작에 의해 획득된 오픈 포트가 잘 알려진 포트(well-known port), 등록된 포트(registered port), 또는 동적 포트(dynamic port)에 해당되는지를 확인하는 동작을 수행한 다. 일 실시예에 따르면, 오픈 포트의 종류를 확인하는 단계는. 포트 종류 데이터를 참조함으로써, 포트 스캐닝 동 작에 의해 획득된 오픈 포트의 종류를 알아내는 동작을 수행한다. 일 실시예에 따르면, 프로토콜 확인용 패킷을 작성하는 단계는, 오픈 포트의 종류에 따라서 프로토콜 확인용 패 킷을 작성하는 동작을 수행한다. 예를 들면, 프로토콜 확인용 패킷을 작성하는 단계는, 무선 디바이스(15a)의 80번 포트는 월드 와이드 웹 HTTP 프로토콜을 사용하는 것으로 잘 알려진 포트(well-known port)이므로, 웹 HTTP 프로토콜을 사용하여 프로토콜 확인용 패킷을 작성하는 동작을 수행한다. 또한, 프로토콜 확인용 패킷을 작성하는 단계는, 무선 디바이스(15a)로부터 웹 HTTP 프로토콜을 이용하여 작성 된 프로토콜 확인용 패킷에 대한 응답이 없으면, IoT 디바이스(15a)의 80번 포트가 웹 HTTP 프로토콜을 이용하 지 않는다고 결정하고, 월드 와이드 웹 HTTP 프로토콜이 아닌 다른 프로코롤을 사용하여 프로토콜 확인용 패킷 을 작성하는 동작을 수행한다. 프로토콜 확인용 패킷을 무선 디바이스에게 전송하는 단계는, 프로토콜 확인용 패킷을 타겟 디바이스에게 전송 하는 단계이다. 프로토콜 확인용 패킷을 타겟 디바이스에게 전송하는 단계는, 타겟 디바이스로부터 응답이 올 때까지 프로토콜 확인용 패킷을 전송하는 동작을 수행한다. 프로토콜 확인용 패킷을 전송한 타겟 디바이스로부터 응답이 존재하는지를 확인하는 단계는, 상기 타겟 디바이 스로부터 프로토콜 확인용 패킷에 대한 응답이 오는지를 모니터링하고, 응답이 오면 그러한 응답에 사용된 프로 토콜을 해당 오픈 포트에서 실제 사용되는 프로토콜이라고 결정하는 동작을 수행한다. 타입 추정 단계(S130)는 상술한 포토 스캐닝 단계(S110)의 수행결과와 프로토콜 스캐닝 단계(S120)의 수행결과 중 적어도 하나의 결과를 이용하여, 타겟 디바이스들의 각각의 타입(type)을 추정하는 타입 추정 동작을 수행하 는 단계이다. 즉, 타입 추정 단계(S130)는 상술한 타입 추정 동작을 수행하는 단계이다. 일 실시예에 따르면, 타입 추정 단계(S130)는, 프로토콜 스캐닝 동작의 수행결과로 알아낸 프로토콜의 종류로부 터 서비스의 종류를 추정하는 단계와, 서비스의 종류로부터 타겟 디바이스의 타입을 추정하는 단계를 포함한다. 여기서, 프로토콜의 종류로부터 서비스의 종류를 추정하는 단계는 상술한 프로토콜의 종류로부터 서비스의 종류 를 추정하는 동작을 수행하는 단계이고, 서비스의 종류로부터 타겟 디바이스의 타입을 추정하는 단계는 상술한 서비스의 종류로부터 타겟 디바이스의 타입을 추정하는 동작을 수행하는 단계이다. 따라서, 이들 단계들에 대한 상세한 설명은 도1과 도5의 실시예의 설명을 참조하기 바란다. 이상과 같이 본 발명이 속하는 분야에서 통상의 지식을 가진 자라면 이러한 명세서의 기재로부터 다양한 수정 및 변형이 가능함을 이해할 수 있다. 그러므로 본 발명의 범위는 설명된 실시예에 국한되어 정해져서는 아니되 며 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2022-0021056", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 본 발명의 일 실시예에 따른 캐릭터 애니메이션 생성 시스템을 설명하기 위한 블록도, 도2는 일 실시예에 따라 캐릭터의 감정 분류에 따른 캐릭터의 동작을 표현하는 복수의 제스처 애니메이션을 설 명하는 도면, 도3은 일 실시예에 따라 음성 및 표정에 기반하여 캐릭터의 동작과 감정을 표현하는 애니메이션을 생성하는 예 시적인 방법을 설명하는 흐름도, 도4는 일 실시예에 따라 캐릭터의 동작과 감정을 표현하는 애니메이션을 생성하는 과정을 설명하는 도면, 도5는 무선케어장치가 통합된 캐릭터 애니메이션 생성 시스템을 설명하기 위한 도면, 도6은 일 실시예에 따른 무선케어 방법을 설명하기 위한 도면, 도7은 일 실시예에 따른 무선 디바이스의 타입을 추정하는 방법을 설명하는 도면이다."}
