{"patent_id": "10-2008-7013497", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2008-0075147", "출원번호": "10-2008-7013497", "출원인": "마이크로소프트 코포레이션", "발명자": "버지즈, 크리스토퍼, 제이."}}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "주어진 쿼리(query)에 대해 반환된 항목들의 개선된 랭킹(ranking)들을 제공하는 랭킹 시스템에 있어서,순위화(ordering)가 요구되는 항목들의 초기 집합; 및상기 항목들의 가장 관련성 있는 순위화의 획득을 용이하게 하기 위해 높이 랭크된 항목들의 하나 이상의 감소하는 부분집합을 재랭크하는 다중 중첩(nested) 랭킹 컴포넌트(120)를 포함하는 랭킹 시스템."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 다중 중첩 랭킹 컴포넌트는 기계 학습 또는 통계적 방법들을 통해 트레이닝된 다수의 랭킹 알고리즘을 포함하는 랭킹 시스템."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 다수의 랭킹 알고리즘은상기 항목들의 초기 집합을 랭크하도록 트레이닝된 최소한 하나의 초기 랭킹 알고리즘(NET0); 및항목들의 이전의 재랭크된 부분집합들로부터 선택된 랭크된 항목들 상에서 후속적으로 트레이닝된 하나 이상의후속 랭킹 알고리즘을 포함하는 랭킹 시스템."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 항목들의 제1 부분집합은 목록상의 최고 순위 위치들 내의 항목들을 포함하는 랭킹 시스템."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 새로운 트레이닝 집합을 형성하기 위해 각 트레이닝 집합으로부터 하나 이상의 항목들을 부분적으로 제외함으로써 각각의 이전의 트레이닝 집합을 연속적으로 줄여나가는 트레이닝 집합 변경 컴포넌트를 더포함하고, 각각의 새로운 트레이닝 집합은 상기 이전의 트레이닝 집합으로부터의 항목들의 부분집합을 포함하는랭킹 시스템."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 다수의 랭킹 알고리즘은 대응하는 트레이닝 집합을 사용하여 연속적인 방식으로 트레이닝되는 랭킹 시스템."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 다중 중첩 랭킹 컴포넌트는 가장 관련성 높은 점수화 항목들을 목록의 상위에 배치하기위해 하나 이상의 분리된 단계에서 검색 컴포넌트에 의해 검색된 항목들의 초기 집합의 부분집합을 재순위화하는 랭킹 시스템."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 검색 결과 목록을 사용자에게 나타내는 디스플레이 컴포넌트를 더 포함하고, 상기 검색 결과목록은 다수의 따로따로 트레이닝된 신경망들을 사용하여 재순위화된 항목들의 최소한 하나의 부분집합을 포함하는 랭킹 시스템."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "주어진 쿼리에 대해 반환된 항목들의 개선된 랭킹들을 제공하는 방법에 있어서, 항목들의 초기 순위화된 집합을 검색하는 액트; 및- 3 -공개특허 10-2008-0075147상기 항목들의 가장 관련성 있는 순위화의 획득을 용이하게 하기 위해 랭크된 항목들의 하나 이상의 감소하는부분집합을 재랭크하는 액트를 포함하는 랭킹 제공 방법."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 항목들의 초기 집합을 랭크하고, 그로부터 항목들의 상위 부분집합을 선택해서 재랭크하는 액트를 더 포함하는 랭킹 제공 방법."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 항목들의 상위 부분집합의 재랭킹 액트는 하나 이상의 분리된 단계에서 행해지는 랭킹제공 방법."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 재랭킹 액트는높이 랭크된 항목들의 감소하는 상위 부분집합들을 선택하는 액트;변경된 랭킹 알고리즘을 트레이닝하기 위해 사용된 트레이닝 집합들을 변경하는 액트; 및높이 랭크된 항목들의 상위 부분집합들을 재순위화하는 액트를 포함하는 랭킹 제공 방법."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 트레이닝 집합들을 변경하는 액트는최소한 하나의 변경된 트레이닝 집합을 형성하기 위해, 다수의 낮게 랭크된 항목들을 제외하고, 그 안에 높이랭크된 항목들의 최소한 상위 부분집합을 남김으로써, 최소한 제1 트레이닝 집합을 줄여나가는 액트; 및상기 최소한 하나의 변경된 트레이닝 집합 상에서 최소한 하나의 변경된 랭킹 알고리즘을 트레이닝하는 액트를 포함하는 랭킹 제공 방법."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 상기 재랭킹 액트는 최소한 하나의 트레이닝된 랭킹 알고리즘을 통해 행해지는 랭킹 제공방법."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서, 목록을 사용자에게 나타내는 액트를 더 포함하고, 상기 목록은 재랭크된 항목들의 부분집합을포함하는 랭킹 제공 방법."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서, 상기 항목들의 초기 집합으로부터의 항목들의 부분집합을 재순위화하는 랭킹 제공 방법."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제9항에 있어서, 상기 재랭킹 액트는 데이터 집합들(datasets) 상에서 트레이닝된 하나 이상의 랭킹 알고리즘을이용하고, 더 작은 데이터 집합들 상에서 트레이닝되는 랭킹 알고리즘은 더 큰 데이터 집합들 상에서 트레이닝된 것들보다 더욱 복잡한 학습 알고리즘인 랭킹 제공 방법."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "주어진 쿼리에 대해 반환된 항목들의 개선된 랭킹들을 제공하는 랭킹 시스템에 있어서, 주어진 쿼리에 대한 항목들의 초기 순위화된 집합을 검색하는 수단; 및- 4 -공개특허 10-2008-0075147상기 항목들의 가장 관련성 있는 순위화의 획득을 용이하게 하기 위해 높이 랭크된 항목들의 하나 이상의 감소하는 부분집합을 재랭크하는 수단을 포함하는 랭킹 시스템."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 다수의 랭킹 알고리즘을 따로따로 트레이닝하는 것을 용이하게 하기 위해 트레이닝 집합들을변경하는 수단을 더 포함하는 랭킹 시스템."}
{"patent_id": "10-2008-7013497", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서, 순위화된 항목들의 목록을 나타내는 수단을 더 포함하고, 상기 목록은 재랭크된 항목들의 최소한 하나의 부분집합을 포함하는 랭킹 시스템.명 세 서기 술 분 야본 발명은 주어진 쿼리에 대해 반환된 항목들의 개선된 랭킹을 제공하는 랭킹 시스템 및 방법에 관한 것이다. <1>배 경 기 술검색은 컴퓨터 사용자들에게 애플리케이션 및 운영 체제의 매우 중요한 특징이 되었다. 더군다나, 그것은 컴퓨 <2>팅 시장 내에서 매우 수익성 있는 섹터로 되었다. 한편, 광고주는 키워드를 사고, 및/또는 소정의 검색 용어가들어갈 때 원하는 목록 위치에 프리미엄을 지불하고 있다. 한편, 소비자는 주로 검색 품질에 관심을 갖고, 흔히 과거의 성능이나 평판에 기초하여 검색 애플리케이션 또는 엔진을 선택한다.가장 일반적으로, 사용자는 인터넷이나, 그들의 네트워크나, 또는 그들의 로컬 PC 상에서 특정 콘텐트를 찾기 <3>위해 텍스트 검색을 시작한다. 검색 요청은 여러 가지 포맷으로 제출될 수 있다. 사용자는 그 자신이 찾고 있는 콘텐트 및 검색 위치에 의존하여 키워드, 구, 또는 단어들의 임의의 조합을 사용할 수 있다. 검색 엔진의임무는 사용자의 쿼리에 관련된 문서를 검색하는 것이다. 동일하거나 유사한 용어에 관련된 몇몇 문서가 존재할 때, 그 문서들을 쿼리 및 사용자에 대한 그들의 관련성 정도를 반영한 순서로 사용자에게 제시하기 위해서는적절한 기술이 있어야 한다. 그러므로, 검색된 문서들의 랭킹은 정보 검색에 있어서 가장 해 볼만한 일일 수있다. 대부분의 사용자가 통상적으로 (검색 엔진에 의해 반환된) 목록의 상위에 있는 처음 몇 개의 결과만을보기 때문에, 이들 결과에 대한 높은 정확도를 달성하는 것이 더욱더 중요해졌다.종래의 랭킹 시스템은 양호한 랭킹을 만들어내기 위해 계속 노력하지만, 여전히 문제가 남아있다. 이것은 부분 <4>적으로, 쿼리에 응답하여 반환될 수 있는 대량의 문서들 때문이다. 이 문제를 거리를 두고 보면, 현재 인터넷또는 웹상에 대략 250억 개의 문서(예를 들어, 웹사이트, 이미지, URL)가 있다. 그러므로, 임의의 한 쿼리에응답하여 수백만은 아니더라도 수천의 문서가 반환될 수 있다. 그러한 많은 양의 문서를 정확하게 랭크(rank)하기 위해 현재 랭킹 시스템에 의해 이루어진 시도에도 불구하고, 상위 결과는 여전히 쿼리 및/또는 사용자에대해 가장 관련성 있는 것이 아닐 수도 있다. 이것은 몇 가지 이유 때문에 발생한다. 한 가지 이유는 그러한종래의 랭킹 시스템이 높이 랭크된 결과를 희생하여 낮은 랭킹 결과를 개선해 보려고 시도할 수 있기 때문에,상위에 반환된 결과의 관련성이 감소될 수 있다는 것이다. 두 번째 가능한 이유는 (모든 가능한 쿼리에 대한)전체 문제를 해결하기 위해 단일의 랭킹 알고리즘을 사용하는 것이 너무 제한적일 수 있다는 것이다. 따라서,랭킹 시스템의 성능에 대한 희생을 최소화하면서 검색 항목들의 랭킹을 개선할 필요성이 남아있다.발명의 상세한 설명다음은 여기에서 설명된 시스템 및/또는 방법의 몇몇 실시양상의 기본적인 이해를 제공하기 위해 단순화된 요약 <5>을 나타낸 것이다. 이 요약은 여기에서 설명된 시스템 및/또는 방법의 광범위한 개요가 아니다. 그것은 그러한 시스템 및/또는 방법의 핵심적인/중요한 특징을 식별한다거나 그 범위를 나타내고자 하는 것이 아니다. 그유일한 목적은 나중에 제시되는 더욱 상세한 설명에 대한 서론으로서 단순화된 형태로 몇몇 개념을 제시하기 위한 것이다.본 출원은 랭킹 결과의 개선을 용이하게 하는 시스템(들) 및/또는 방법에 관한 것이다. 특히, 본 시스템 및 방 <6>- 5 -공개특허 10-2008-0075147법은 이전에 랭크된 항목의 부분집합을 재랭크하기 위해 다중 중첩 단계에서 랭킹 기술을 적용한다. 상이한 랭킹 기술들이 이러한 방식으로 이용될 수 있지만, 설명 및 간결함을 위해, 하나의 랭킹 기술이 여기에서 설명될것이다.본 시스템 및 방법은 랭킹 작업을, 높이 또는 더 높이 랭크된 항목들의 감소하는 부분집합에 랭킹 기술이 적용 <7>되는 단계들로 나누는 것을 포함한다. 랭킹 기술이 랭킹 항목에 트레이닝되는 신경망을 이용한다고 하자. 다수의 망은 사용자에게 제시된 더욱 관련성 있는 상위 번호의 항목들을 생성하기 위해 더 작은 정보 집합으로 트레이닝될 수 있다. 예를 들어, 사용자가 검색 컴포넌트에 쿼리를 제출했다고 상상해보자. 검색 컴포넌트는 주어진 쿼리에 대해 백 만개가 넘는 항목을 검색할 수 있는데, 항목은 문서, 파일, 이미지 또는 URL에 대응할 수있다. 제1 신경망은 항목들의 이 초기 집합의 순위를 정하도록 트레이닝될 수 있다. 랭크된 항목들의 초기 집합으로부터, 상위 약간의(예를 들어, 상위 2500개) 결과를 선택해서, 그것들의 순위를 다시 정하기 위해 이용될수 있는 제2 신경망을 트레이닝한다. 제2 신경망은 항목들의 변경된 집합-이 경우에, 상위 2500개 항목-을 사용하여 트레이닝될 수 있다. 그 후, 2500개 항목은 제2 신경망을 통해 재랭크될 수 있다. 재랭크된 2500개 항목으로부터, 높이 랭크된 항목의 더 작은 부분집합(예를 들어, 1000개)을 선택하여, 계속해서 그것들의 순위를다시 정하기 위해 제3 신경망을 트레이닝한다. 상위 1000개가 재랭크된 후에, 상위 랭크된 항목들의 더 작은부분집합은 다른 신경망-예를 들어, 상위 100개-을 트레이닝하기 위해 사용될 수 있다. 상위 100개는 또한 재랭크될 수 있는 상위 10개를 얻기 위해 유사한 방식으로 재랭크될 수 있다. 전체 효과는 분리된 단계로 상위2500개의 결과를 재랭크하는 것인데, 이것은 검색 컴포넌트의 전체 랭킹 성능을 효과적으로 증가시킨다. 대부분의 사용자는 주어진 쿼리에 대해 반환된 상위 약간의 결과만을 검토할 뿐이다. 상기 시스템 및 방법을 사용함으로써, 상위 약간의 결과는 그들의 관련성 및 랭킹 순위를 개선하기 위해 반복적으로 재랭크된다. 그러한다단식 시스템의 사용으로부터의 개선은 부분적으로, 각 단계에서, 그 단계에서 사용된 학습 기계가 해결되고있는 전체 랭킹 문제 중의 작은 하위-문제만을 해결하면 된다는 사실로부터 비롯될 수 있다. 다단식 시스템의두 번째 이점은 (웹 검색과 같은) 몇몇 애플리케이션의 경우에, 결과가 실시간으로 반환되어야 한다는 사실에기인한다. 그러므로, 랭킹을 수행하기 위해 단일 알고리즘만이 사용되면, 그 알고리즘은 매우 빨라야 한다.그러나, 다단식 방법에서, 각 문제는 훨씬 적은 데이터를 포함하고, 따라서 더욱 정교한(그리고 더욱 느린) 랭킹 방법이 각 단계에서 적용될 수 있다.상기 및 관련 목적을 달성하기 위해, 본 발명의 소정의 예시적인 실시양상이 다음의 상세한 설명 및 첨부 도면 <8>과 함께 여기에서 설명된다. 그러나, 이들 실시양상은 본 발명의 원리가 이용될 수 있는 다양한 방식 중의 몇가지만을 나타낸 것이고, 본 발명은 그러한 모든 실시양상 및 그 등가물을 포함하고자 한다. 본 발명의 그외다른 장점 및 새로운 특징은 도면과 함께 고려할 때 본 발명의 다음의 상세한 설명으로부터 명백해질 수 있다.실 시 예본 시스템 및/또는 방법은 도면과 관련하여 이제 설명되는데, 동일한 참조 번호는 도면 전체에 걸쳐 동일한 요 <20>소를 나타내기 위해 사용된다. 다음 설명 부분에서는, 설명의 목적으로, 다수의 특정 상세가 시스템 및/또는방법의 완전한 이해를 제공하기 위해 설명된다. 그러나, 본 시스템 및/또는 방법이 이들 특정 상세 없이도 실시될 수 있다는 것은 명백하다. 다른 경우에, 잘 알려진 구조 및 장치는 그들의 설명을 용이하게 하기 위해 블록도 형태로 도시된다.여기에서 사용된 바와 같이, \"컴포넌트\" 및 \"시스템\"이라는 용어는 컴퓨터 관련 엔티티, 즉 하드웨어, 하드웨어 <21>와 소프트웨어의 조합, 소프트웨어 또는 실행 소프트웨어를 나타내기 위한 것이다. 예를 들어, 컴포넌트는 프로세서상에서 실행되는 프로세스, 프로세서, 개체, 실행파일, 실행 스레드, 프로그램 및 컴퓨터일 수 있는데,이것에 제한되는 것은 아니다. 실례로서, 서버상에서 실행되는 애플리케이션 및 서버는 컴포넌트일 수 있다.하나 이상의 컴포넌트는 프로세스 및/또는 실행 스레드 내에 존재할 수 있고, 하나의 컴포넌트는 하나의 컴퓨터상에 국한될 수 있고 및/또는 2개 이상의 컴퓨터들 사이에서 분산될 수 있다.본 시스템 및/또는 방법은 다중 중첩 랭킹 방법을 사용하여 재랭크하기 위해 각 단계에서 높이 랭크된 항목들의 <22>최적 부분집합을 인식하고 식별하는 것과 관련하여 다양한 추론 방식 및/또는 기술을 포함할 수 있다. 특히,재랭크하기 위해 선택된 높이 랭크된 항목들의 최적 부분집합은 사용자에 의해 제출된 각 쿼리에 대해, 검색된항목의 수에 기초하여 바뀔 수 있다. 예를 들어, 상위 1500개 항목은 처음에 제1 단계에서 재랭크되고, 제2 단계에서, 이전의 재랭크된 항목들로부터의 상위 250개 항목은 다른 재랭킹을 위해 선택될 수 있다. 다른 쿼리에서, 시스템은 항목들의 감소하는 부분집합의 상이한 분해가 더욱 적절하다는 것을 결정할 수 있다. 즉, 그러한추론 방식 또는 인공 지능은 검색된 항목의 수에 기초하고 및/또는 사용자 선호도와 관련하여 이들 결정을 자동- 6 -공개특허 10-2008-0075147으로 하기 위해 이용될 수 있다. 검색된 항목의 명백한 관련성은 또한 의사 결정 과정에 고려될 수 있다. 예를 들어, 관련성은 항목에 할당된 값에 따라 평가될 수 있다. 이 값은 어느 항목이 높이 랭크된 항목으로서 고려되어야 하는 지와 관련하여 임계치를 확인하기 위해 이용될 수 있다. 그러므로, 추론 방식은 예를 들어, 주어진 쿼리에 대한 특정 단계에서, 1000개의 랭크된 항목들 중 상위 100개를 재랭크할 것인지 상위 50개를 재랭크할 것인지 판정할 수 있다. 후속 단계에서, 항목들의 더 작은 부분집합이 (예를 들어, 100개의 항목 중의 상위 10개를) 더욱 재랭크하기 위해 선택될 수 있다. 이것은 사용자가 상위 랭크된 항목을 가질 때까지 반복될수 있다. 재랭킹을 행하기 위한 단계들의 수의 선택은 또한 하나 이상의 다양한 추론 방식을 이용함으로써 용이하게 될 수 있다. 그러나, 재랭크하기 위한 부분집합 크기의 각 선택에 대해, 랭킹 알고리즘은 오프라인으로트레이닝되어야 한다는 것을 알 수 있을 것이다.여기에서 사용된 바와 같이, \"추론\"이라는 용어는 일반적으로, 이벤트 및/또는 데이터를 통해 획득한 관측들의 <23>집합으로부터 시스템, 환경 및/또는 사용자의 상태에 대해 판단을 내리거나 그 상태를 추론하는 프로세스를 일컫는다. 추론은 예를 들어, 특정 콘텍스트 또는 액션을 식별하기 위해 이용될 수 있고, 또는 상태들에 관한 확률 분포를 생성할 수 있다. 추론은 확률적일 수 있는데, 즉 데이터 및 이벤트의 고려에 기초하여 관심 있는 상태들에 관한 확률 분포의 계산일 수 있다. 추론은 또한 이벤트 및/또는 데이터의 집합으로부터 더 높은 레벨의이벤트를 구성하기 위해 이용된 기술을 일컬을 수 있다. 그러한 추론은 이벤트들이 시간적으로 가깝게 상관되는 안 되든, 그리고 이벤트들 및 데이터가 하나의 이벤트 및 데이터 소스로부터 온 것이든지 몇 개의 이벤트 및데이터 소스로부터 온 것이든지, 관측된 이벤트들 및/또는 저장된 이벤트 데이터의 집합으로부터 새로운 이벤트또는 액션의 구성을 초래한다.사용자에게 가장 관련 있는 항목이 결과 목록의 상위에 나타나도록 사용자의 쿼리에 응답하여 검색된 항목들의 <24>랭킹은 대부분의 종래의 검색 엔진에게는 여전히 비교적 문제가 있는 작업이다. 기계 학습 알고리즘을 수반하는 다양한 해결책이 이 문제를 해결하기 위해 제시되었지만, 대부분은 그들의 랭킹을 학습하기 위해 매번의 쿼리 결과의 전체 집합에 적용된다. 불행히도, 임의의 가능한 쿼리에 대해 매우 많은 수의 문서를 랭크하는 방법을 학습하는 것은 매우 어려운 일이다.아래의 도 1-8에서 설명된 본 출원은 검색 결과의 상위에 관하여 높은 정확도로 랭킹을 학습하는 기계 학습 방 <25>법을 사용한다. 더욱 구체적으로, 다중 중첩 랭킹 방법은 단계적으로(하나 이상) 재랭킹을 수행하기 위해 이용될 수 있는데, 각 단계에서는 결과의 새로운 분포를 생성한다. 새로운 분포가 생성되는 방식은 랭크된 항목의매우 상위에서 약간의 문서들 또는 항목들의 양호한 랭킹의 획득에 기초할 수 있다. 각각의 후속 단계에 대한트레이닝 집합은 이전의 랭커(ranker)에 의해 높이 랭크된 결과만을 포함하도록 줄어든다. 이것은 문제를 더작고 더 쉬운 하위작업들로 나누고, 단계들의 각각에 대한 랭킹을 따로따로 학습한다. 또한, 하위작업들이 더작기 때문에, 더욱 정교한(그리고 더욱 느린) 랭킹 알고리즘이 적용될 수 있다. 기본 랭커가 이미 양호한 랭킹을 생성한다는 것과, 관련된 문서들이 랭크된 목록의 상위에 근처에 배치된다는 것이 가정된다. 그러므로, 각각의 다음 랭커의 목적은 높은 점수화 결과의 재랭킹만을 학습하는 것이다.더욱이, 랭크된 목록의 하위에 배치된 관련 문서들이 학습하기 더욱 어려운 경향이 있으므로, 랭킹 알고리즘 또 <26>는 모듈이 그들의 랭크를 그다지 개선할 것 같지 않다고 가정하는 것이 합리적이다. 따라서, 각 트레이닝 집합은 학습이 목록의 상위에 있는 항목들의 랭킹(또는 재랭킹)에 집중할 수 있게 트레이닝 집합으로부터 그러한 어려운 관련 항목들을 제외하도록 줄어들 수 있다.단계적으로 높이 랭크된 항목들의 재랭킹을 달성하기 위해 이용될 수 있는 다수의 상이한 랭킹 모델이 있다. <27>설명의 간결성 및 용이성을 위해, 본 출원은 Burges 등 저의 \"Learning to Rank Using Gradient Descent\",Proceedings of the 22nd International Conference on Machine Learning, Bonn, 2005에서 설명된 신경망 알고리즘과 관련하여 설명될 것이다. 이 알고리즘은 RankNet이라 칭해질 것이다. 종래의 실시에서, 신경망은 레이블(labeled) 예제를 입력에 나타내고, 신경망을 통해 앞으로 전달하며, 신경망의 출력 및 레이블 데이터로부터얻은 원하는 출력에 기초하여 에러 함수의 값을 계산하고, 마지막으로 (예를 들어, 트레이닝 데이터 전체에 걸쳐 평균했을 때) 에러 함수의 값을 점점 더 줄일 수 있도록 가중치를 조정함으로써 트레이닝될 수 있다.여기에서 설명된 신경망 알고리즘(예를 들어, 위에서 참조한 U.S. 출원 번호 제11/066,514호 참조)은 예제의 쌍 <28>의 함수인 비용을 최소화하기 위한 랭크된 데이터 집합의 학습을 수반한다. 특히, 이 신경망은 예제의 쌍의 사용을 통해 데이터 포인트들 집합의 랭킹을 학습할 수 있고, 더 높은 관련성 점수를 갖는 예제에 더 높은 값을할당하는 쌍에 관한 함수를 학습할 수 있다. 이 신경망 랭킹 알고리즘은 다중 중첩 랭커의 각 단계(예를 들어,하나 이상의 단계)에서 적용될 수 있다. 알고리즘은 예제의 쌍에서 트레이닝되고, 그 출력은 데이터 포인트의- 7 -공개특허 10-2008-0075147최종 랭킹을 생성하기 위해 사용된다. 역전달(back-propagation) 단계는 쌍별(pair-wise) 에러에 기초하여 비용 함수에 적응될 수 있다. 다중 중첩 랭커의 각 단계에서 행해지는 트레이닝 집합의 변경은 랭크된 목록 내의문서들의 위치에 대한 정보를 트레이닝 절차 내로 도입하고, 높은 점수화 결과의 순위화의 학습에 더 많은 가중치를 부과하고자 하는 시도로 보여질 수 있다.여기에서 제시된 다중 중첩 랭커 방법은 랭킹 문제를 더 작고 더욱 관리가능한 작업으로 분할하는 것을 용이하 <29>게 한다. 즉, 한번에 백만개의 검색 항목을 처리하는 대신에, 상위 부분집합만의 랭킹을 개선하기 위해 백만개의 상위 부분집합이 중점적으로 다루어진다. 따라서, 각 단계 후, 학습 알고리즘이 상위 결과의 재랭킹에 집중하도록, 결과들의 새로운 분포가 생성될 수 있다. 랭커의 성능은 쌍별 정확도보다 오히려 랭크된 목록의 상위에 있는 결과들 집합을 사용하여 측정된다. 그러므로, 이 방법은 또한 높은 점수화 문서를 재랭크하는 방법의학습에 더 많은 비중을 둠으로써 트레이닝 중에 사용된 비용 함수와 평가 측정치 사이의 간격을 메울 수 있다.다중 중첩 랭킹 방법은 도 1-8과 관련하여 더욱 설명된다.이제, 도 1을 참조하면, 높이 랭크된 항목을 재랭크함으로써 주어진 쿼리에 대해 반환된 항목들의 랭킹의 개선 <30>을 용이하게 하는 랭킹 시스템(100)의 일반적인 블록도가 도시된다. 시스템(100)은 주어진 쿼리에 대한 항목들의 초기 집합을 검색하는 검색 컴포넌트(110)를 포함한다. 예를 들어, 사용자가 \"childhood illness andantibiotics\"에 대한 검색을 실행했다고 가정하자. 검색 컴포넌트(110)는 그들 검색 용어에 관련된 다수의 항목을 검색할 수 있다. 그 다음, 검색된 항목은 다중 중첩 랭킹 컴포넌트(120)의 제1 트레이닝 집합으로서 이용될 수 있다. 다중 중첩 랭킹 컴포넌트(120)는 검색 결과 목록의 상위에서의 가장 관련성 있는 항목들의 획득을용이하게 하기 위해 높이 랭크된 항목들의 하나 이상의 감소하는 부분집합을 랭크하거나 재랭크할 수 있다.다중 중첩 랭킹 컴포넌트(120)는 다수의 신경망을 포함할 수 있다. 각 신경망은 랭킹을 학습하기 위해 항목들 <31>의 트레이닝 집합을 사용하여 따로 트레이닝된다. 더욱 구체적으로, 위에서 언급된 RankNet에서, 각 신경망은예제의 쌍에 기초한 확률 비용 함수를 사용하여 랭킹을 학습할 수 있다. 트레이닝 동안에, 신경망은 예를들어, 나타낸 제1 예제가 제2 예제보다 더 높이 랭크되도록 요구되는 순서로 예제의 쌍을 나타내고; 신경망을갱신하기 위해 사용된 비용 함수는 두 개의 예제에 대한 신경망의 출력에 의존한다. 예를 들어, 샘플 A에 신경망의 입력이 주어지고, 그 다음에 샘플 B에 주어진다고 가정하고; 샘플 A가 샘플 B보다 신경망 랭크가 더 높은것이 바람직하다고 가정하자. 신경망이 B보다 A에 더 낮은 숫자를 출력하면, 비용은 크고, 신경망은 이에 따라그 가중치를 갱신하여, 이 비용을 감소시킨다. 게다가, 트레이닝 단계 동안에, 제1 예제가 항상 또는 거의 항상 제2 예제보다 더 높이 랭크된다고 가정될 수 있다. 그러나, 테스팅 단계 동안에, 신경망은 단일 예제들을,다음에 데이터를 랭크하기 위해 사용되는 하나의 숫자에 매핑할 수 있다.쿼리에 응답하여 검색된 항목들의 초기 집합은 이러한 방식으로 랭크될 수 있다. 이러한 랭크된 항목 목록으로 <32>부터, 높이 랭크된 항목들의 부분집합은 이러한 항목들 부분집합을 사용하여 다른 신경망을 트레이닝함으로써재랭크될 수 있다. 실제로, 예를 들어, 100,000개의 (랭크된) 결과 중에서, 시스템은 상위 2500개의 항목을 선택해서, 2500개 항목의 감소하는 부분집합 상에서 다수의 재랭킹 반복을 실행한다고 상상해보자. 결과적으로,(상위 2500개 항목으로부터의) 상위 10개의 항목은 실행된 재랭킹 단계의 수에 의존하여 한번 이상 재랭킹되고및/또는 다시 뒤섞일 수 있다. 그러므로, 단계=0(재랭킹 이전) 및 다음에 단계=3(3번의 중첩된 반복 후)에서목록 내의 상위 위치에 있는 항목의 비교는 상이한 항목을 얻을 수도 있고 아닐 수도 있다. 그러나, 몇몇 경우에, 상위 위치 내의 항목은 최소한 한번은 변경되었을 수 있다.이제, 도 2를 참조하면, 다중 중첩 랭킹 방법을 사용하여 높이 랭크된 항목들을 재랭크함으로써 주어진 쿼리에 <33>대해 반환된 항목들의 랭킹의 개선을 용이하게 하는 랭킹 시스템(200)의 블록도가 도시된다. 특히, 시스템(200)은 데이터의 초기 트레이닝 집합(예를 들어, 쿼리에 응답하여 검색된 항목들)을 수신하는 랭킹 컴포넌트(210)를 포함한다. 랭킹 컴포넌트(210)는 샘플의 쌍에 기초한 확률 비용 함수를 사용하여 랭킹을 학습할 수 있다. 더욱 구체적으로, 랭킹 컴포넌트(210)는 샘플 A가 샘플 B보다 높게 랭크될 타깃 확률 과 함께 Rd 내의샘플 쌍[A,B]의 집합이 주어지는 학습 알고리즘을 이용할 수 있다. 형태 의 모델을 이용하여,샘플 집합의 랭크 순위는 f에 의해 얻은 실제 값에 의해 지정되는데, 더욱 구체적으로, 는모델이 x2보다 x1을 더 높게 랭크한다는 것을 의미한다고 가정된다. 출력으로부터 확률로의 맵은 기호 논리학함수 를 사용하여 모델링되는데, 여기에서 및 이다(xi는 xj보다- 8 -공개특허 10-2008-0075147높게 랭크된다). 비용 함수는 또한 랭킹을 학습하기 위해 신경망과 함께 이용될 수 있다. 비용 함수는 2개의연속적인 트레이닝 샘플의 출력 차의 함수가 될 수 있다: 즉, 인데, 제1 샘플은 제2 샘플보다 높거나동일한 랭크를 갖는 것으로 가정한다.그러므로, 랭킹 컴포넌트(210)는 랭크된 항목(220)을 제공할 수 있고, 이것에 의해, 랭크된 항목의 부분집합은 <34>새로운 또는 변경된 트레이닝 집합(230)으로서 이용될 수 있다. 이 새로운 트레이닝 집합은 각 단계에서, 트레이닝 집합이 트레이닝 집합 변경 컴포넌트(250)에 의해 점점 줄어들게 변경될 수 있는 다중 중첩 랭킹 컴포넌트(240)에 제공될 수 있다. 새로운 또는 변경된 집합이 생성되면, 그것은 특정 단계에서 항목들의 주어진 부분집합에 대한 신경망을 생성하기 위해 신경망 트레이닝(260)에서 사용될 수 있다.도 3은 검색 결과 목록의 상위 또는 그 근처에 주어진 쿼리에 대해 가장 관련성 있는 항목들을 배치하는 것을 <35>용이하게 하기 위해 항목들의 부분집합에 대해 단계적으로 랭킹 함수 또는 모델을 적용함으로써 높이 랭크된 항목들의 재랭킹을 개략적으로 나타낸 것이다. 사용자 또는 탐색 및 검색 시스템은 단계들의 수, 및/또는 각 단계에서 재랭크하기 위한 (높이 랭크된) 항목들의 수를 결정할 수 있다. 도 3에 도시된 바와 같이, 선택된 높이랭크된 항목들은 하나 이상의 단계에서 재랭크될 수 있고, 이것에 의해 각각의 연속적인 단계에서, 재랭크된 항목들의 부분집합은 항목들의 이전의 부분집합으로부터 감소된다. 실제로, 예를 들어, 트레이닝 쿼리 집합이 있고, 각각의 쿼리 qi에 대해, 검색 엔진에서 사용된 기본 랭커에 의해 (검색된 R개의 항목으로부터) 상위 R1개의 결과 중에서 랭크된 문서 집합 이 있다고 상상해보자. 이들 항목의 랭킹에 대한 정보(예를 들어, 그들의 점수)는 또한 랭킹의 후속 단계에 대한 입력으로서 사용될 수 있다.다중 중첩 랭킹 방법은 하나 이상의 단계에서 상위 결과들을 재랭크하기 위해 랭킹 알고리즘(예를 들어, 도 1 <36>및 도 2에서의 랭킹 컴포넌트)를 적용한다. 각 단계에서, 랭킹 컴포넌트/알고리즘/함수에는 높이 랭크된 항목들의 감소하는 부분집합을 포함하는 매번의 쿼리 결과의 새로운 분포가 제공된다. 그러므로, 각 단계 후, 트레이닝 집합은 다음과 같은 방식으로 줄어드는데: 제1 단계(300)에서, 랭킹 함수는 상위 R1개 결과의 전체 집합에적용되고(305), 예를 들어, 쿼리 당 R1 = 2500개의 문서(예를 들어, 개체, 파일, URL, 이미지 등)이다. 트레이닝 절차는 제1 신경망 Net1을 계산한다(310). 결과들은 Net1을 사용하여 계산된 점수를 감소시킴으로써 정렬될수 있다(315). 그 후, 트레이닝 집합은 Net1에 따라 최고 점수를 받는 상위 R2개 문서만이 각 쿼리에 대해 남도록 변경된다.제2 단계(320)는 Net2를 생성하고, R3개 상위 점수 문서만이 다음 트레이닝 집합을 위해 유지된다. 이렇게 줄 <37>어드는 절차는 텔레스코핑(telescoping)이라 칭해질 수 있는데, 이것은 제1 단계 후에 R1에서 (R2-1)로의 랭크로 문서들의 Net1 랭크를 고정하고, Net2로 상위 R2개 문서들을 재랭킹하며, 제2 단계 후에 랭크된 R2에서 (R3-1)로 배치된 문서들의 랭크를 다시 고정하고, Net3으로 상위 R3개 결과를 재랭크하는 등등(예를 들어, 단계 3,단계 4 등등)으로 된다. 그러므로, 다중 중첩 랭킹의 각 단계 후, 쿼리 당 모든 R1개 결과에 대한 랭크된 목록이 생성되어 평가를 위해 사용될 수 있다. 단계들의 수 및 각 단계에서의 항목들의 수는 변할 수 있다. 그러므로, 한 쿼리에 대해, R1=2500, R2=1000, R3=100, R4=10인 4개의 단계가 사용될 수 있고, 다른 쿼리에서,R1=2500, R2=100, R3=10인 3개의 단계가 사용될 수 있다. 각 단계에서의 항목들의 수는 항목들이 감소 부분집합에서 나타나는 동안은 이전의 예에서의 것들과 다를 수 있다는 것을 알 수 있을 것이다. 이와 유사하거나 동일한 텔레스코핑 절차는 유효성 검사 및 테스트 집합에 적용될 수 있다.앞의 예시적인 시나리오에서 나타낸 바와 같이, 이 방법은 문제를 작은 부분으로 나누므로, 각 신경망은 실행하 <38>기 위한 더 작고 단순한 작업을 갖는다. 또한, 데이터 집합을 줄어들게 하는 것은 트레이닝 집합으로부터 랭크된 목록의 하위에 있는 곤란한 관련 문서를 아마도 제거할 수 있을 것이고, 알고리즘이 높은 점수 관련 문서의랭킹에 집중할 수 있게 한다.우리가 예시적으로 설명한 랭킹 알고리즘의 비용 함수가 2개의 연속적인 트레이닝 샘플의 출력 차에 의존한다는 <39>것을 상기해 보자. 여기에서 설명된 바와 같이, 샘플들은 특정 쿼리에 응답하여 검색 엔진에 의해 반환된 문서들 또는 다른 항목들이다. 그 후, 각각의 반복 후에, 트레이닝 샘플에 대한 신경망의 출력은 쿼리에 관련된 그들의 랭킹을 생성한다. 현재의 비용 함수 형태로 인해, 랭킹 알고리즘은 랭크된 목록의 그들의 위치에 관계없이 문서들의 정확한 쌍별 순위화를 학습하려고 시도한다. 따라서, 트레이닝 동안에, 신경망은 목록의 상위에있는 관련 결과들의 일부를 약간 아래로 이동하는 것을 희생하더라도, 목록의 하위에 있는 문서들을 상당히 위- 9 -공개특허 10-2008-0075147로 이동함으로써 쌍별 에러를 개선하는 것이 가능하다. 실험 데이터는 이것이 실제로 트레이닝 동안에 발생할수 있다는 것을 증명했다.이제, 도 4를 참조하면, 랭킹 항목에 대한 텔레스코핑 방식을 도시한 도면으로서, 특히 높이 랭크된 항목들의 <40>감소하는 부분집합과, 중첩된 신경망과의 상호작용의 트레이닝시의 그들의 사용 사이의 관계를 도시한 블록도가있다. 도면은 높이 랭크된 항목들의 초기 집합을 선택한 다음에 그것의 각각의 연속적인 부분집합을 줄어들게하는 텔레스코핑 실시양상을 보여준다. 항목들을 랭크하기 위해 사용된 신경망은 또한 그러한 부분집합에 기초하여 연속적으로 변경될 수 있다. 랭킹의 텔레스코핑 특성의 결과로서, 검색 결과 내의 더욱 관련된 항목들은목록의 상위에서 가장 관련된 항목들을 얻기 위해 재랭크된다.도면에 도시된 바와 같이, (검색 컴포넌트에 의해 검색된 다음에 랭크된 항목들의 목록으로부터 얻은) 높이 랭 <41>크된 항목들(410)의 초기 집합은 제1 신경망(420)을 트레이닝하기 위해 사용될 수 있다. 그 다음, 트레이닝된신경망(420)은 높이 랭크된 항목들의 연속적인 부분집합(430)을 얻기 위해 항목들(410)에 적용될 수 있다. 이것은 검색 결과 목록의 상위에 있는 항목들의 미세 조정을 용이하게 하기 위해 사용자가 원하는 만큼 많은 반복동안 계속될 수 있다. 이것은 도 4에 도시되는데, 신경망 netG(G는 1보다 크거나 같은 정수)는 대응하는 변경된 트레이닝 집합에 의해 트레이닝될 수 있다.다양한 방법이 이제 일련의 액트를 통해 설명될 것이다. 본 시스템 및/또는 방법은 몇몇 액트들이 본 출원에 <42>따라, 여기에 도시되고 설명된 것과 상이한 순서로 및/또는 그외 다른 액트와 동시에 발생할 수 있으므로, 액트들의 순서에 의해 제한되지 않는다는 것을 이해할 것이고 알 수 있을 것이다. 예를 들어, 본 분야에 숙련된 기술자들은 방법이 대안적으로 상태도에서와 같이 일련의 서로 관련된 상태 또는 이벤트로서 나타내질 수 있다는것을 이해할 것이고 알 수 있을 것이다. 게다가, 본 출원에 따른 방법을 구현하기 위해 도시된 모든 액트가 요구되는 것은 아니다.이제, 도 5를 참조하면, 높이 랭크된 항목들을 재랭크함으로써 주어진 쿼리에 대해 반환된 항목들의 랭킹의 개 <43>선을 용이하게 하는 예시적인 방법(500)을 도시한 흐름도가 있다. 방법(500)은 액트(510)에서 검색 컴포넌트에의해 주어진 쿼리에 대한 항목들의 초기 집합을 검색하는 것을 포함한다. 이 항목 집합은 항목의 초기 랭킹을얻기 위해 임의의 랭킹 함수 또는 알고리즘을 사용하여 랭크될 수 있다. 다음에 액트(520)에서, 방법(500)은쿼리에 대해 더욱 관련성 있는 항목들을 검색 결과 목록의 상위에 위치시키는 것을 용이하게 하기 위해 높이 랭크된 항목들의 하나 이상의 감소하는 부분집합을 재랭크할 수 있다. 일단 항목들의 원하는 재랭킹이 실행되면,검색 결과의 목록은 사용자에게 제시될 수 있다. 그러므로, 500,000개의 항목이 사용자의 쿼리에 응답하여 반환된다고 상상해보라. 낮게 랭크된 항목의 랭킹(예를 들어, 목록의 하위 근처 또는 임계치 이하)을 개선하고자시도하기보다는 오히려, 방법은 그 노력을 높이 랭크된 항목에 집중한다. 따라서, 목록상의 상위 3000개의 항목이 선택될 수 있다. 결과적으로, 상위 300개 항목의 중첩된 그룹은 항목의 현재 랭킹이 부분적으로 이전의랭킹에 의해 결정될 수 있도록, 연속적인 방식으로 재랭크된다.도 6을 참조하면, 다중 중첩 랭킹 방법을 사용하여 높이 랭크된 항목들을 재랭크함으로써 주어진 쿼리에 대해 <44>반환된 항목들의 랭킹의 개선을 용이하게 하는 예시적인 방법(600)을 도시한 흐름도가 있다. 방법(600)은 액트(610)에서 쿼리에 응답하여 다수의 항목을 검색하는 것을 포함한다. 액트(620)에서, 항목들은 임의의 원하는랭킹 함수 또는 모드를 사용하여 랭크될 수 있다. 높이 랭크된 항목들(예를 들어, 상위 V개의 항목들, 여기에서 V는 1보다 큰 정수)의 랭킹을 개선하기 위해, 높이 랭크된 항목들은 다중 중첩 랭킹 방법을 사용하여 재랭크될 수 있다(액트(630)). 즉, 동일하거나 유사한 랭킹 함수는 한번에 전체 항목 그룹에 적용되기 봐는 오히려단계적으로(예를 들어, 항목들의 감소하는 부분집합에서) 높이 랭크된 항목들에 적용될 수 있다. 예를 들어,상위 2500개의 항목은 선택되어, 상위 2500개 항목의 새로운 순위를 얻기 위해 재랭크될 수 있다. 그 후, 상위100개의 항목은 선택되어, 상위 100개 항목의 새로운 순위를 얻기 위해 재랭크될 수 있고-한편, (상위 100개보다 낮게 랭크된) 나머지 2400개 항목의 랭킹은 변경되지 않고 그대로 남아 있다. 원한다면, 재랭킹의 또 다른단계가, 예를 들어 상위 10개의 항목에서 실행될 수 있다. 액트(640)에서, 재랭크된 항목들 및 검색 컴포넌트에 의해 검색된 나머지 항목들은 사용자에게 제시될 수 있다.아래의 도 7 및 도 8에서, 설명된 방법(700, 800)은 다른 경우에 랭킹보다 상위 항목들(또는 더욱 일반적으로 <45>항목들의 소정의 부분집합)의 랭킹의 정확도가 더욱 중요한 임의의 순위화 문제에 적용할 수 있다는 것을 알 수있을 것이다. 검색 엔진은 이것이 적용되는 애플리케이션의 많은 예들 중의 하나이고, 거기에 반드시 관련된쿼리가 있어야 하는 것은 아니다.이제, 도 7을 참조하면, 대응하는 랭킹 컴포넌트를 트레이닝하기 위해 개별적이고 연속적으로 사용되는 트레이 <46>- 10 -공개특허 10-2008-0075147닝 집합을 줄어들게 하거나 변경함으로써 주어진 쿼리에 대해 반환된 항목들의 랭킹의 개선을 용이하게 하는 예시적인 방법(700)을 도시한 흐름도가 있다. 방법(700)은 검색 컴포넌트 또는 엔진에 의해 쿼리에 응답하여 항목을 검색하는 액트(710)를 포함한다. 액트(720)에서, 랭킹 컴포넌트는 트레이닝 집합을 사용하여 계산되거나트레이닝될 수 있다. 검색 컴포넌트에 의해 검색된 항목들은 랭킹 컴포넌트를 사용하여 랭크될 수 있다(액트(730)). 액트(740)에서, 트레이닝 집합은 낮게 랭크된 항목(예를 들어, 관련성이 결정하기 더욱 어려운 낮은점수화 항목)을 제외함으로써 변경되거나 줄어들 수 있다. 결과적으로, 랭킹 컴포넌트는 더욱 관련성 있는 높은 점수화 항목의 랭킹에 집중할 수 있다. 액트(750)에서, 새로운 또는 변경된 랭킹 컴포넌트는 변경된 트레이닝 집합을 사용하여 트레이닝될 수 있다. 나머지 항목(예를 들어, 제외되지 않은 것들)은 변경된 랭킹 컴포넌트에 의해 다시 랭크될 수 있다(액트(760)). 액트(740 내지 760)에서 발생하는 프로세스는 원하는 만큼 반복될수 있고, 이것에 의해, 높이 랭크된 항목들의 감소하는 부분집합이 그들의 대응하는 변경된 트레이닝 집합에 의해 재랭크된다.도 8에, 다중 중첩 랭킹 방법을 사용하여 높이 랭크된 항목들의 감소하는 부분집합을 재랭크함으로써 주어진 쿼 <47>리에 대해 반환된 항목들의 랭킹의 개선을 용이하게 하는 예시적인 방법(800)을 도시한 흐름도가 있다. 방법(800)은 주어진 쿼리에 대해 검색된 랭크된 항목 목록으로부터 높이 랭크된 항목을 추출하는 액트(810)를 포함한다. 예를 들어, 검색된 200만 개의 문서 중에서 상위 1000개 문서를 선택하는 것을 상상해보라. 액트(820)에서, 랭킹 컴포넌트(예를 들어, 기계 학습 신경망)는 (추출된) 높이 랭크된 항목에서 트레이닝될 수 있다. 따라서, 상위 1000개 항목은 트레이닝 집합으로서 이용된다. 액트(830)에서, 이들 항목은 최근에 트레이닝된 랭킹 컴포넌트에 의해 재랭크될 수 있다. 이것은 검색 컴포넌트를 통해 검색된 200만 개의 문서로부터의 임의의정보가 이 재랭킹 프로세스에서 고려되지 않는다는 것을 의미한다. 액트(840)에서, 재랭크된 높이 랭크된 항목들의 부분집합은 랭킹 컴포넌트의 트레이닝을 다시 변경하기 위해 추출될 수 있다. 따라서, 이제, 재랭크된100개 항목 목록으로부터 상위 100개 항목을 선택하고, 랭킹 컴포넌트를 재트레이닝하기 위해 새로운 또는 변경된 트레이닝 집합으로서 상위 100개 항목을 사용하는 것을 상상해보라. 그 다음, 액트(850)에서, 100개 항목은변경된 랭킹 컴포넌트에 의해 재랭크될 수 있다. 이것은 이제 100개 항목 목록에서 상위 10개 항목을 선택하여이들을 유사한 방식으로 재랭크함으로써 다시 반복될 수 있다. 알 수 있는 바와 같이, 목록상의 상위 10개 항목은 각 단계에서 반복적으로 재순위화될 수 있다.이제, 도 9를 참조하면, 도면은 검색 결과의 재랭킹, 특히 높이 랭크된 항목의 재랭킹을 매우 작은 규모로 설명 <48>한다. 사용자가 \"strollers\"에 대한 웹 쿼리를 입력했고, 많은 항목이 반환되었으며 그 다음에 랭크되었다고상상해 보자. 블록(900)은 이 랭킹으로부터 비롯된 상위 5개 항목의 목록을 제공한다. 상위 5개 항목(예를 들어, URL)의 개선된 순위를 얻기 위해, 다중 중첩 방법은 단계적으로(예를 들어, 하나 이상의 단계로) 항목을 재순위화하기 위해 이용될 수 있다. 더욱 실제 규모에서, 시스템은 이 쿼리에 대해 250만 개의 검색된 항목을 처리할 수 있으므로, 상위 10개 항목 및/또는 상위 항목의 순위화를 궁극적으로 개선하기 위한 상위 5000개 항목의 재순위화에 관한 작업은 사용자에게 상당히 유리할 수 있다. 따라서, 항목의 재랭킹 후, 5개 항목의 새로운순위가 얻어진다(블록(910)). 그 다음, 최종 결과 목록은 도 10에 도시된 바와 같이 사용자에게 제시될 수 있다. 다수의 중첩 랭킹 컴포넌트에 의해 소모된 처리 시간은 무시할 만하고, 사용자에게 별로 눈에 띄지않으며; 결과 목록의 상위에 가장 관련 있는 항목을 제공하는데 있어서의 개선된 정확도는 검색 컴포넌트로 사용자 만족감을 상당히 증가시킨다.본 출원의 다양한 실시양상에 대한 추가 상황을 제공하기 위해, 도 11 및 다음 설명은 본 출원의 다양한 실시양 <49>상이 구현될 수 있는 적합한 컴퓨팅 환경(1100)의 간단한 일반 설명을 제공하고자 하는 것이다. 시스템(들) 및/또는 방법(들)이 하나 이상의 컴퓨터 또는 기타 장치에 의해 실행된 프로그램 모듈과 같은 컴퓨터 실행가능 명령어의 일반적인 문맥으로 설명되지만, 본 분야에 숙련된 기술자들은 본 발명이 또한 기타 프로그램 모듈과의조합으로 및/또는 하드웨어와 소프트웨어의 조합으로서 구현될 수 있다는 것을 인식할 것이다.그러나, 일반적으로, 프로그램 모듈은 특정 태스크를 수행하거나 특정 데이터 유형을 구현하는 루틴, 프로그램, <50>개체, 컴포넌트, 데이터 구조 등을 포함한다. 운영 환경(1110)은 적합한 운영 환경의 일례에 불과하며, 본 시스템 및/또는 방법의 용도 또는 기능성의 범위에 관해 어떤 제한을 암시하고자 하는 것이 아니다. 본 시스템및/또는 방법과 함께 사용하기 적합한 기타 잘 알려진 컴퓨터 시스템, 환경 및/또는 구성은 퍼스널 컴퓨터, 핸드헬드 또는 랩톱 장치, 멀티프로세서 시스템, 마이크로프로세서 기반 시스템, 프로그램가능한 가전제품, 네트워크 PC, 미니컴퓨터, 메인프레임 컴퓨터, 상기 시스템들이나 장치들을 포함하는 분산 컴퓨팅 환경, 기타 등등이 있지만 이에 제한되는 것은 아니다.도 11과 관련하여, 시스템 및/또는 방법의 다양한 실시양상을 구현하는 예시적인 환경(1100)은 컴퓨터(1112)를 <51>- 11 -공개특허 10-2008-0075147포함한다. 컴퓨터(1112)는 처리 장치(1114), 시스템 메모리(1116) 및 시스템 버스(1118)를 포함한다. 시스템버스(1118)는 시스템 메모리(1116)를 포함하는(제한되지는 않음) 시스템 컴포넌트들을 처리 장치(1114)에 연결한다. 처리 장치(1114)는 각종 시판중인 프로세서들 중의 어느 것이라도 될 수 있다. 듀얼 마이크로프로세서및 기타 멀티-프로세서 아키텍처가 또한 처리 장치(1114)로서 이용될 수 있다.시스템 버스(1118)는 메모리 버스 또는 메모리 컨트롤러, 주변 버스 또는 외부 버스, 및/또는 각종 이용가능 버 <52>스 아키텍처 중의 임의의 것을 이용하는 로컬 버스를 비롯한 몇몇 유형의 버스 구조(들) 중 어느 것이라도 될수 있는데, 이러한 버스 아키텍처는 11비트 버스, ISA(industry standard architecture), MCA(micro channelarchitecture), EISA(Enhanced ISA), IDE(Intelligent Drive Electronics), VLB(VESA Local Bus),PCI(peripheral component interconnect), USB(Universal Serial Bus), AGP(Advanced Graphics Port),PCMCIA(Personal Computer Memory Card International Association bus) 및 SCSI(Small Computer SystemsInterface)를 포함하지만 이에 제한되는 것은 아니다.시스템 메모리(1116)는 휘발성 메모리(1120) 및 비휘발성 메모리(1122)를 포함한다. 시동 중과 같은 때에, 컴 <53>퓨터(1112) 내의 구성요소들 사이의 정보를 전송하는 기본 루틴을 포함하는 기본 입/출력 시스템(BIOS)은 비휘발성 메모리(1122) 내에 저장되어 있다. 예시적으로, 비휘발성 메모리(1122)는 판독 전용 메모리(ROM), 프로그램가능 ROM(PROM), 전기적으로 프로그램가능 ROM(EPROM), 전기적으로 소거가능 프로그램가능 ROM(EEPROM) 또는플래시 메모리를 포함할 수 있지만 이에 제한되는 것은 아니다. 휘발성 메모리(1120)는 외부 캐시 메모리로서동작하는 랜덤 액세스 메모리(RAM)를 포함한다. 예시적으로, RAM은 동기식 RAM(SRAM), 동적 RAM(DRAM), 동기식DRAM(SDRAM), 2배속 SDRAM(DDR SDRAM), 인핸스드 SDRAM(ESDRAM), 싱크링크 DRAM(SLDRAM) 및 다이렉트 램버스RAM(DRRAM)과 같은 많은 형태로 이용가능한데, 이에 제한되는 것은 아니다.컴퓨터(1112)는 또한 이동식/비이동식, 휘발성/비휘발성 컴퓨터 저장 매체를 포함한다. 도 11은, 예를 들어 디 <54>스크 저장 장치(1124)를 도시하고 있다. 디스크 저장 장치(1124)는 자기 디스크 드라이브, 플로피 디스크 드라이브, 테이프 드라이브, 재즈(Jaz) 드라이브, 지프(Zip) 드라이브, LS-100 드라이브, 플래시 메모리 카드 또는메모리 스틱과 같은 장치를 포함하는데, 이에 제한되는 것은 아니다. 또한, 디스크 저장 장치(1124)는 컴팩트디스크 ROM 장치(CD-ROM), CD 기록가능 드라이브(CD-R Drive), CD 재기입가능 드라이브(CD-RW Drive) 또는DVD-ROM 드라이브(digital versatile disk ROM)와 같은 광 디스크 드라이브를 포함하는(이것에 제한되지 않음)기타 저장 매체와 결합하여 또는 분리하여 저장 매체를 포함할 수 있다. 시스템 버스(1118)로의 디스크 저장장치(1124)의 접속을 용이하게 하기 위해, 인터페이스(1126)와 같은 이동식 또는 비이동식 인터페이스가 통상적으로 사용된다.도 11은 적합한 운영 환경(1110)에서 설명된 기본 컴퓨터 자원들과 사용자들 사이의 중간자로서 동작하는 소프 <55>트웨어를 설명하고 있다는 것을 알 수 있을 것이다. 그러한 소프트웨어는 운영 체제(1128)를 포함한다. 디스크 저장 장치(1124) 상에 저장될 수 있는 운영 체제(1128)는 컴퓨터 시스템(1112)의 자원을 제어하고 할당하는동작을 한다. 시스템 애플리케이션(1130)은 시스템 메모리(1116) 내에 또는 디스크 저장 장치(1124) 상에 저장된 프로그램 모듈(1132) 및 프로그램 데이터(1134)를 통해 운영 체제(1128)에 의한 자원 관리를 이용한다. 본시스템 및/또는 방법은 다양한 운영 체제들, 또는 운영 체제들의 조합으로 구현될 수 있다는 것을 알 수 있을것이다.사용자는 입력 장치(들)(1136)를 통해 명령 또는 정보를 컴퓨터(1112)에 입력한다. 입력 장치(1136)는 마우스, <56>트랙볼, 스타일러스, 터치패드와 같은 포인팅 장치, 키보드, 마이크, 조이스틱, 게임 패드, 위성 안테나, 스캐너, TV 튜너 카드, 디지털 카메라, 디지털 비디오 카메라, 웹 카메라 등을 포함하는데 이에 제한되는 것은 아니다. 이들 및 기타 입력 장치는 인터페이스 포트(들)(1138)를 경유하여 시스템 버스(1118)를 통해 처리 장치(1114)에 접속한다. 인터페이스 포트(들)(1138)는 예를 들어, 직렬 포트, 병렬 포트, 게임 포트 및USB(universal serial bus)를 포함한다. 출력 장치(들)(1140)는 입력 장치(들)(1136)와 동일한 유형의 포트들중의 소정의 것을 사용한다. 그러므로, 예를 들어, USB 포트는 컴퓨터(1112)에 입력을 제공하고, 컴퓨터(1112)로부터의 정보를 출력 장치(1140)에 출력하기 위해 사용될 수 있다. 출력 어댑터(1142)는 기타 출력 장치(1140) 중에서 특히, 특정 어댑터를 필요로 하는 모니터, 스피커 및 프린터와 같은 몇몇 출력 장치(1140)가 있다는 것을 나타내기 위해 제공된다. 출력 어댑터(1142)는 출력 장치(1140)와 시스템 버스(1118) 사이에 접속수단을 제공하는 비디오 및 사운드 카드를 예시적으로 포함하는데, 이에 제한되는 것은 아니다. 원격 컴퓨터(들)(1144)과 같은 기타 장치 및/또는 장치의 시스템은 입력 및 출력 능력을 제공한다는 것을 알 수 있을 것이다.- 12 -공개특허 10-2008-0075147컴퓨터(1112)는 원격 컴퓨터(들)(1144)와 같은 하나 이상의 원격 컴퓨터로의 논리적 접속을 사용하여 네트워크 <57>화된 환경에서 동작할 수 있다. 원격 컴퓨터(들)(1144)는 퍼스널 컴퓨터, 서버, 라우터, 네트워크 PC, 워크스테이션, 마이크로프로세서 기반 가전제품, 피어 장치 또는 기타 공통 네트워크 노드 등일 수 있고, 통상적으로컴퓨터(1112)와 관련하여 설명된 구성요소들의 대부분 또는 그 전부를 포함한다. 간결하게 하기 위해, 하나의메모리 저장 장치(1146)만이 원격 컴퓨터(들)(1144)와 함께 도시되어 있다. 원격 컴퓨터(들)(1144)는 네트워크인터페이스(1148)를 통해 컴퓨터(1112)에 논리적으로 접속된 다음에, 통신 접속(1150)을 통해 물리적으로 접속된다. 네트워크 인터페이스(1148)는 LAN 및 WAN과 같은 통신 네트워크를 포함한다. LAN 기술은 FDDI(FiberDistributed Data Interface), CDDI(Copper Distributed Data Interface), 이더넷(Ethernet)/IEEE 1102.3, 토큰 링(Token Ring)/IEEE 1102.5 등을 포함한다. WAN 기술은 점 대 점 링크, ISDN(Integrated ServicesDigital Networks) 및 그 변형과 같은 회선 교환망, 패킷 교환망 및 DSL(Digital Subscriber Lines)을 포함하는데 이에 제한되는 것은 아니다.통신 접속(들)(1150)은 네트워크 인터페이스(1148)를 버스(1118)에 접속하기 위해 이용된 하드웨어/소프트웨어 <58>를 나타낸다. 통신 접속(1150)은 명확하게 도시하기 위해 컴퓨터(1112) 내부에 도시되었지만, 컴퓨터(1112)의외부에도 있을 수 있다. 네트워크 인터페이스(1148)에 접속하기 위해 필요한 하드웨어/소프트웨어는 단지 예시적인 목적을 위해, 일반 전화 등급 모뎀, 케이블 모뎀 및 DSL 모뎀을 포함하는 모뎀, ISDN 어댑터 및 이더넷 카드와 같은 내부 및 외부 기술을 포함한다.상기 설명된 것은 본 시스템 및/또는 방법의 예를 포함한다. 물론, 본 시스템 및/또는 방법을 설명하기 위해 <59>컴포넌트 또는 방법의 가능한 모든 조합을 설명할 수는 없지만, 본 분야에 숙련된 기술자는 본 시스템 및/또는방법의 더 많은 조합과 변경이 가능하다는 것을 인식할 것이다. 따라서, 본 시스템 및/또는 방법은 첨부된 청구범위의 정신 및 범위 내에서 그러한 모든 변경, 수정 및 변형을 포함하고자 하는 것이다. 더욱이, \"포함하다(includes)\"라는 용어가 상세한 설명 또는 청구범위에서 사용되는 한도까지, 그러한 용어는 \"포함하는(comprising)\"이라는 용어가 청구범위에서 연결어로서 이용될 때 해석되는 바와 같이 \"포함하는(comprising)\"이라는 용어와 유사한 방식으로 포괄적인 의미로 사용하고자 하는 것이다.도면의 간단한 설명도 1은 높이 랭크된 항목들을 재랭크함으로써 주어진 쿼리에 대해 반환된 항목들의 랭킹의 개선을 용이하게 하 <9>는 랭킹 시스템의 블록도.도 2는 다중 중첩 랭킹 방법을 사용하여 높이 랭크된 항목들을 재랭크함으로써 주어진 쿼리에 대해 반환된 항목 <10>들의 랭킹의 개선을 용이하게 하는 랭킹 시스템의 블록도.도 3은 주어진 쿼리에 대해 가장 관련성 있는 항목들을 검색 결과 목록의 상위 또는 그 근처에 배치하는 것을 <11>용이하게 하기 위한 다중 중첩 랭킹 방법을 사용하여 랭킹 항목들을 설명하는 블록도.도 4는 랭킹 항목에 대한 텔레스코핑(telescoping) 방식을 도시한 도면으로서, 특히 높이 랭크된 항목들의 감소 <12>하는 부분집합과, 중첩된 신경망과의 상호작용의 트레이닝시의 그들의 사용 사이의 관계를 도시한 블록도.도 5는 높이 랭크된 항목들을 재랭크함으로써 주어진 쿼리에 대해 반환된 항목들의 랭킹의 개선을 용이하게 하 <13>는 예시적인 방법을 도시한 흐름도.도 6은 다중 중첩 랭킹 방법을 사용하여 높이 랭크된 항목들을 재랭크함으로써 주어진 쿼리에 대해 반환된 항목 <14>들의 랭킹의 개선을 용이하게 하는 예시적인 방법을 도시한 흐름도.도 7은 대응하는 랭킹 컴포넌트를 트레이닝하기 위해 개별적이고 연속적으로 사용되는 트레이닝 집합을 줄여나 <15>가거나 변경함으로써 주어진 쿼리에 대해 반환된 항목들의 랭킹의 개선을 용이하게 하는 예시적인 방법을 도시한 흐름도.도 8은 다중 중첩 랭킹 방법을 사용하여 높이 랭크된 항목들의 감소하는 부분집합을 재랭크함으로써 주어진 쿼 <16>리에 대해 반환된 항목들의 랭킹의 개선을 용이하게 하는 예시적인 방법을 도시한 흐름도.도 9는 검색 컴포넌트에 의해 검색된 항목들의 집합으로부터 높이 랭크된 항목들의 부분집합을 재순위화하는 것 <17>을 매우 작은 규모로 설명하는 도면.도 10은 쿼리에 응답하여 사용자에게 제시된 변경된 검색 결과를 보여주는 예시적인 사용자 인터페이스. <18>- 13 -공개특허 10-2008-0075147도 11은 본 발명의 여러 실시양상을 구현하는 예시적인 환경을 도시한 도면. <19>도면 도면1- 14 -공개특허 10-2008-0075147 도면2- 15 -공개특허 10-2008-0075147 도면3- 16 -공개특허 10-2008-0075147 도면4- 17 -공개특허 10-2008-0075147 도면5 도면6- 18 -공개특허 10-2008-0075147 도면7- 19 -공개특허 10-2008-0075147 도면8- 20 -공개특허 10-2008-0075147 도면9- 21 -공개특허 10-2008-0075147 도면10- 22 -공개특허 10-2008-0075147 도면11- 23 -공개특허 10-2008-0075147"}
{"patent_id": "10-2008-7013497", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "항목들 랭킹의 개선을 용이하게 하는 고유 시스템 및 방법이 제공된다. 이 시스템 및 방법은 분리된 단계에서 높이 랭크된 항목들의 감소하는 부분집합들을 재랭크하는 것을 포함한다. 특히, 기본 랭킹 컴포넌트는 항목들의 집합을 랭크할 수 있다. 상위의 또는 높은 랭킹 항목들의 부분집합은 선택되어, 이들 높이 랭크된 문서들 사이 의 랭킹을 개선하는 컴포넌트를 트레이닝하기 위한 새로운 트레이닝 집합으로서 사용될 수 있다. 이 프로세스는 임의 수의 연속적으로 높이 랭크된 부분집합들 상에서 반복될 수 있다. 그러므로, 높이 랭크된 항목들은 가장 관련성 있는 항목들을 검색 결과 목록의 상위에 배치하는 것을 용이하게 하기 위해 더 높이 랭크된 항목들에 집 중함으로써 분리된 단계에서 재순위화될 수 있다."}
{"patent_id": "10-2008-7013497", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 주어진 쿼리에 대해 반환된 항목들의 개선된 랭킹을 제공하는 랭킹 시스템 및 방법에 관한 것이다. <1>"}
{"patent_id": "10-2008-7013497", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "검색은 컴퓨터 사용자들에게 애플리케이션 및 운영 체제의 매우 중요한 특징이 되었다. 더군다나, 그것은 컴퓨 <2> 팅 시장 내에서 매우 수익성 있는 섹터로 되었다. 한편, 광고주는 키워드를 사고, 및/또는 소정의 검색 용어가 들어갈 때 원하는 목록 위치에 프리미엄을 지불하고 있다. 한편, 소비자는 주로 검색 품질에 관심을 갖고, 흔 히 과거의 성능이나 평판에 기초하여 검색 애플리케이션 또는 엔진을 선택한다. 가장 일반적으로, 사용자는 인터넷이나, 그들의 네트워크나, 또는 그들의 로컬 PC 상에서 특정 콘텐트를 찾기 <3> 위해 텍스트 검색을 시작한다. 검색 요청은 여러 가지 포맷으로 제출될 수 있다. 사용자는 그 자신이 찾고 있 는 콘텐트 및 검색 위치에 의존하여 키워드, 구, 또는 단어들의 임의의 조합을 사용할 수 있다. 검색 엔진의 임무는 사용자의 쿼리에 관련된 문서를 검색하는 것이다. 동일하거나 유사한 용어에 관련된 몇몇 문서가 존재 할 때, 그 문서들을 쿼리 및 사용자에 대한 그들의 관련성 정도를 반영한 순서로 사용자에게 제시하기 위해서는 적절한 기술이 있어야 한다. 그러므로, 검색된 문서들의 랭킹은 정보 검색에 있어서 가장 해 볼만한 일일 수 있다. 대부분의 사용자가 통상적으로 (검색 엔진에 의해 반환된) 목록의 상위에 있는 처음 몇 개의 결과만을 보기 때문에, 이들 결과에 대한 높은 정확도를 달성하는 것이 더욱더 중요해졌다. 종래의 랭킹 시스템은 양호한 랭킹을 만들어내기 위해 계속 노력하지만, 여전히 문제가 남아있다. 이것은 부분 <4> 적으로, 쿼리에 응답하여 반환될 수 있는 대량의 문서들 때문이다. 이 문제를 거리를 두고 보면, 현재 인터넷 또는 웹상에 대략 250억 개의 문서(예를 들어, 웹사이트, 이미지, URL)가 있다. 그러므로, 임의의 한 쿼리에 응답하여 수백만은 아니더라도 수천의 문서가 반환될 수 있다. 그러한 많은 양의 문서를 정확하게 랭크(rank) 하기 위해 현재 랭킹 시스템에 의해 이루어진 시도에도 불구하고, 상위 결과는 여전히 쿼리 및/또는 사용자에 대해 가장 관련성 있는 것이 아닐 수도 있다. 이것은 몇 가지 이유 때문에 발생한다. 한 가지 이유는 그러한 종래의 랭킹 시스템이 높이 랭크된 결과를 희생하여 낮은 랭킹 결과를 개선해 보려고 시도할 수 있기 때문에, 상위에 반환된 결과의 관련성이 감소될 수 있다는 것이다. 두 번째 가능한 이유는 (모든 가능한 쿼리에 대한) 전체 문제를 해결하기 위해 단일의 랭킹 알고리즘을 사용하는 것이 너무 제한적일 수 있다는 것이다. 따라서, 랭킹 시스템의 성능에 대한 희생을 최소화하면서 검색 항목들의 랭킹을 개선할 필요성이 남아있다. 발명의 상세한 설명"}
{"patent_id": "10-2008-7013497", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "다음은 여기에서 설명된 시스템 및/또는 방법의 몇몇 실시양상의 기본적인 이해를 제공하기 위해 단순화된 요약 <5>"}
{"patent_id": "10-2008-7013497", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "을 나타낸 것이다. 이 요약은 여기에서 설명된 시스템 및/또는 방법의 광범위한 개요가 아니다. 그것은 그러 한 시스템 및/또는 방법의 핵심적인/중요한 특징을 식별한다거나 그 범위를 나타내고자 하는 것이 아니다. 그 유일한 목적은 나중에 제시되는 더욱 상세한 설명에 대한 서론으로서 단순화된 형태로 몇몇 개념을 제시하기 위 한 것이다. 본 출원은 랭킹 결과의 개선을 용이하게 하는 시스템(들) 및/또는 방법에 관한 것이다. 특히, 본 시스템 및 방 <6> - 5 -공개특허 10-2008-0075147법은 이전에 랭크된 항목의 부분집합을 재랭크하기 위해 다중 중첩 단계에서 랭킹 기술을 적용한다. 상이한 랭 킹 기술들이 이러한 방식으로 이용될 수 있지만, 설명 및 간결함을 위해, 하나의 랭킹 기술이 여기에서 설명될 것이다. 본 시스템 및 방법은 랭킹 작업을, 높이 또는 더 높이 랭크된 항목들의 감소하는 부분집합에 랭킹 기술이 적용 <7> 되는 단계들로 나누는 것을 포함한다. 랭킹 기술이 랭킹 항목에 트레이닝되는 신경망을 이용한다고 하자. 다 수의 망은 사용자에게 제시된 더욱 관련성 있는 상위 번호의 항목들을 생성하기 위해 더 작은 정보 집합으로 트 레이닝될 수 있다. 예를 들어, 사용자가 검색 컴포넌트에 쿼리를 제출했다고 상상해보자. 검색 컴포넌트는 주 어진 쿼리에 대해 백 만개가 넘는 항목을 검색할 수 있는데, 항목은 문서, 파일, 이미지 또는 URL에 대응할 수 있다. 제1 신경망은 항목들의 이 초기 집합의 순위를 정하도록 트레이닝될 수 있다. 랭크된 항목들의 초기 집 합으로부터, 상위 약간의(예를 들어, 상위 2500개) 결과를 선택해서, 그것들의 순위를 다시 정하기 위해 이용될 수 있는 제2 신경망을 트레이닝한다. 제2 신경망은 항목들의 변경된 집합-이 경우에, 상위 2500개 항목-을 사 용하여 트레이닝될 수 있다. 그 후, 2500개 항목은 제2 신경망을 통해 재랭크될 수 있다. 재랭크된 2500개 항 목으로부터, 높이 랭크된 항목의 더 작은 부분집합(예를 들어, 1000개)을 선택하여, 계속해서 그것들의 순위를 다시 정하기 위해 제3 신경망을 트레이닝한다. 상위 1000개가 재랭크된 후에, 상위 랭크된 항목들의 더 작은 부분집합은 다른 신경망-예를 들어, 상위 100개-을 트레이닝하기 위해 사용될 수 있다. 상위 100개는 또한 재 랭크될 수 있는 상위 10개를 얻기 위해 유사한 방식으로 재랭크될 수 있다. 전체 효과는 분리된 단계로 상위 2500개의 결과를 재랭크하는 것인데, 이것은 검색 컴포넌트의 전체 랭킹 성능을 효과적으로 증가시킨다. 대부 분의 사용자는 주어진 쿼리에 대해 반환된 상위 약간의 결과만을 검토할 뿐이다. 상기 시스템 및 방법을 사용 함으로써, 상위 약간의 결과는 그들의 관련성 및 랭킹 순위를 개선하기 위해 반복적으로 재랭크된다. 그러한 다단식 시스템의 사용으로부터의 개선은 부분적으로, 각 단계에서, 그 단계에서 사용된 학습 기계가 해결되고 있는 전체 랭킹 문제 중의 작은 하위-문제만을 해결하면 된다는 사실로부터 비롯될 수 있다. 다단식 시스템의 두 번째 이점은 (웹 검색과 같은) 몇몇 애플리케이션의 경우에, 결과가 실시간으로 반환되어야 한다는 사실에 기인한다. 그러므로, 랭킹을 수행하기 위해 단일 알고리즘만이 사용되면, 그 알고리즘은 매우 빨라야 한다. 그러나, 다단식 방법에서, 각 문제는 훨씬 적은 데이터를 포함하고, 따라서 더욱 정교한(그리고 더욱 느린) 랭 킹 방법이 각 단계에서 적용될 수 있다. 상기 및 관련 목적을 달성하기 위해, 본 발명의 소정의 예시적인 실시양상이 다음의 상세한 설명 및 첨부 도면 <8> 과 함께 여기에서 설명된다. 그러나, 이들 실시양상은 본 발명의 원리가 이용될 수 있는 다양한 방식 중의 몇 가지만을 나타낸 것이고, 본 발명은 그러한 모든 실시양상 및 그 등가물을 포함하고자 한다. 본 발명의 그외 다른 장점 및 새로운 특징은 도면과 함께 고려할 때 본 발명의 다음의 상세한 설명으로부터 명백해질 수 있다. 실 시 예 본 시스템 및/또는 방법은 도면과 관련하여 이제 설명되는데, 동일한 참조 번호는 도면 전체에 걸쳐 동일한 요 <20> 소를 나타내기 위해 사용된다. 다음 설명 부분에서는, 설명의 목적으로, 다수의 특정 상세가 시스템 및/또는 방법의 완전한 이해를 제공하기 위해 설명된다. 그러나, 본 시스템 및/또는 방법이 이들 특정 상세 없이도 실 시될 수 있다는 것은 명백하다. 다른 경우에, 잘 알려진 구조 및 장치는 그들의 설명을 용이하게 하기 위해 블 록도 형태로 도시된다. 여기에서 사용된 바와 같이, \"컴포넌트\" 및 \"시스템\"이라는 용어는 컴퓨터 관련 엔티티, 즉 하드웨어, 하드웨어 <21> 와 소프트웨어의 조합, 소프트웨어 또는 실행 소프트웨어를 나타내기 위한 것이다. 예를 들어, 컴포넌트는 프 로세서상에서 실행되는 프로세스, 프로세서, 개체, 실행파일, 실행 스레드, 프로그램 및 컴퓨터일 수 있는데, 이것에 제한되는 것은 아니다. 실례로서, 서버상에서 실행되는 애플리케이션 및 서버는 컴포넌트일 수 있다. 하나 이상의 컴포넌트는 프로세스 및/또는 실행 스레드 내에 존재할 수 있고, 하나의 컴포넌트는 하나의 컴퓨터 상에 국한될 수 있고 및/또는 2개 이상의 컴퓨터들 사이에서 분산될 수 있다. 본 시스템 및/또는 방법은 다중 중첩 랭킹 방법을 사용하여 재랭크하기 위해 각 단계에서 높이 랭크된 항목들의 <22> 최적 부분집합을 인식하고 식별하는 것과 관련하여 다양한 추론 방식 및/또는 기술을 포함할 수 있다. 특히, 재랭크하기 위해 선택된 높이 랭크된 항목들의 최적 부분집합은 사용자에 의해 제출된 각 쿼리에 대해, 검색된 항목의 수에 기초하여 바뀔 수 있다. 예를 들어, 상위 1500개 항목은 처음에 제1 단계에서 재랭크되고, 제2 단 계에서, 이전의 재랭크된 항목들로부터의 상위 250개 항목은 다른 재랭킹을 위해 선택될 수 있다. 다른 쿼리에 서, 시스템은 항목들의 감소하는 부분집합의 상이한 분해가 더욱 적절하다는 것을 결정할 수 있다. 즉, 그러한 추론 방식 또는 인공 지능은 검색된 항목의 수에 기초하고 및/또는 사용자 선호도와 관련하여 이들 결정을 자동 - 6 -공개특허 10-2008-0075147으로 하기 위해 이용될 수 있다. 검색된 항목의 명백한 관련성은 또한 의사 결정 과정에 고려될 수 있다. 예 를 들어, 관련성은 항목에 할당된 값에 따라 평가될 수 있다. 이 값은 어느 항목이 높이 랭크된 항목으로서 고 려되어야 하는 지와 관련하여 임계치를 확인하기 위해 이용될 수 있다. 그러므로, 추론 방식은 예를 들어, 주 어진 쿼리에 대한 특정 단계에서, 1000개의 랭크된 항목들 중 상위 100개를 재랭크할 것인지 상위 50개를 재랭 크할 것인지 판정할 수 있다. 후속 단계에서, 항목들의 더 작은 부분집합이 (예를 들어, 100개의 항목 중의 상 위 10개를) 더욱 재랭크하기 위해 선택될 수 있다. 이것은 사용자가 상위 랭크된 항목을 가질 때까지 반복될 수 있다. 재랭킹을 행하기 위한 단계들의 수의 선택은 또한 하나 이상의 다양한 추론 방식을 이용함으로써 용 이하게 될 수 있다. 그러나, 재랭크하기 위한 부분집합 크기의 각 선택에 대해, 랭킹 알고리즘은 오프라인으로 트레이닝되어야 한다는 것을 알 수 있을 것이다. 여기에서 사용된 바와 같이, \"추론\"이라는 용어는 일반적으로, 이벤트 및/또는 데이터를 통해 획득한 관측들의 <23> 집합으로부터 시스템, 환경 및/또는 사용자의 상태에 대해 판단을 내리거나 그 상태를 추론하는 프로세스를 일 컫는다. 추론은 예를 들어, 특정 콘텍스트 또는 액션을 식별하기 위해 이용될 수 있고, 또는 상태들에 관한 확 률 분포를 생성할 수 있다. 추론은 확률적일 수 있는데, 즉 데이터 및 이벤트의 고려에 기초하여 관심 있는 상 태들에 관한 확률 분포의 계산일 수 있다. 추론은 또한 이벤트 및/또는 데이터의 집합으로부터 더 높은 레벨의 이벤트를 구성하기 위해 이용된 기술을 일컬을 수 있다. 그러한 추론은 이벤트들이 시간적으로 가깝게 상관되 는 안 되든, 그리고 이벤트들 및 데이터가 하나의 이벤트 및 데이터 소스로부터 온 것이든지 몇 개의 이벤트 및 데이터 소스로부터 온 것이든지, 관측된 이벤트들 및/또는 저장된 이벤트 데이터의 집합으로부터 새로운 이벤트 또는 액션의 구성을 초래한다. 사용자에게 가장 관련 있는 항목이 결과 목록의 상위에 나타나도록 사용자의 쿼리에 응답하여 검색된 항목들의 <24> 랭킹은 대부분의 종래의 검색 엔진에게는 여전히 비교적 문제가 있는 작업이다. 기계 학습 알고리즘을 수반하 는 다양한 해결책이 이 문제를 해결하기 위해 제시되었지만, 대부분은 그들의 랭킹을 학습하기 위해 매번의 쿼 리 결과의 전체 집합에 적용된다. 불행히도, 임의의 가능한 쿼리에 대해 매우 많은 수의 문서를 랭크하는 방법 을 학습하는 것은 매우 어려운 일이다. 아래의 도 1-8에서 설명된 본 출원은 검색 결과의 상위에 관하여 높은 정확도로 랭킹을 학습하는 기계 학습 방 <25> 법을 사용한다. 더욱 구체적으로, 다중 중첩 랭킹 방법은 단계적으로(하나 이상) 재랭킹을 수행하기 위해 이용 될 수 있는데, 각 단계에서는 결과의 새로운 분포를 생성한다. 새로운 분포가 생성되는 방식은 랭크된 항목의 매우 상위에서 약간의 문서들 또는 항목들의 양호한 랭킹의 획득에 기초할 수 있다. 각각의 후속 단계에 대한 트레이닝 집합은 이전의 랭커(ranker)에 의해 높이 랭크된 결과만을 포함하도록 줄어든다. 이것은 문제를 더 작고 더 쉬운 하위작업들로 나누고, 단계들의 각각에 대한 랭킹을 따로따로 학습한다. 또한, 하위작업들이 더 작기 때문에, 더욱 정교한(그리고 더욱 느린) 랭킹 알고리즘이 적용될 수 있다. 기본 랭커가 이미 양호한 랭킹 을 생성한다는 것과, 관련된 문서들이 랭크된 목록의 상위에 근처에 배치된다는 것이 가정된다. 그러므로, 각 각의 다음 랭커의 목적은 높은 점수화 결과의 재랭킹만을 학습하는 것이다. 더욱이, 랭크된 목록의 하위에 배치된 관련 문서들이 학습하기 더욱 어려운 경향이 있으므로, 랭킹 알고리즘 또 <26> 는 모듈이 그들의 랭크를 그다지 개선할 것 같지 않다고 가정하는 것이 합리적이다. 따라서, 각 트레이닝 집합 은 학습이 목록의 상위에 있는 항목들의 랭킹(또는 재랭킹)에 집중할 수 있게 트레이닝 집합으로부터 그러한 어 려운 관련 항목들을 제외하도록 줄어들 수 있다. 단계적으로 높이 랭크된 항목들의 재랭킹을 달성하기 위해 이용될 수 있는 다수의 상이한 랭킹 모델이 있다. <27> 설명의 간결성 및 용이성을 위해, 본 출원은 Burges 등 저의 \"Learning to Rank Using Gradient Descent\", Proceedings of the 22nd International Conference on Machine Learning, Bonn, 2005에서 설명된 신경망 알고 리즘과 관련하여 설명될 것이다. 이 알고리즘은 RankNet이라 칭해질 것이다. 종래의 실시에서, 신경망은 레이 블(labeled) 예제를 입력에 나타내고, 신경망을 통해 앞으로 전달하며, 신경망의 출력 및 레이블 데이터로부터 얻은 원하는 출력에 기초하여 에러 함수의 값을 계산하고, 마지막으로 (예를 들어, 트레이닝 데이터 전체에 걸 쳐 평균했을 때) 에러 함수의 값을 점점 더 줄일 수 있도록 가중치를 조정함으로써 트레이닝될 수 있다. 여기에서 설명된 신경망 알고리즘(예를 들어, 위에서 참조한 U.S. 출원 번호 제11/066,514호 참조)은 예제의 쌍 <28> 의 함수인 비용을 최소화하기 위한 랭크된 데이터 집합의 학습을 수반한다. 특히, 이 신경망은 예제의 쌍의 사 용을 통해 데이터 포인트들 집합의 랭킹을 학습할 수 있고, 더 높은 관련성 점수를 갖는 예제에 더 높은 값을 할당하는 쌍에 관한 함수를 학습할 수 있다. 이 신경망 랭킹 알고리즘은 다중 중첩 랭커의 각 단계(예를 들어, 하나 이상의 단계)에서 적용될 수 있다. 알고리즘은 예제의 쌍에서 트레이닝되고, 그 출력은 데이터 포인트의 - 7 -공개특허 10-2008-0075147최종 랭킹을 생성하기 위해 사용된다. 역전달(back-propagation) 단계는 쌍별(pair-wise) 에러에 기초하여 비 용 함수에 적응될 수 있다. 다중 중첩 랭커의 각 단계에서 행해지는 트레이닝 집합의 변경은 랭크된 목록 내의 문서들의 위치에 대한 정보를 트레이닝 절차 내로 도입하고, 높은 점수화 결과의 순위화의 학습에 더 많은 가중 치를 부과하고자 하는 시도로 보여질 수 있다. 여기에서 제시된 다중 중첩 랭커 방법은 랭킹 문제를 더 작고 더욱 관리가능한 작업으로 분할하는 것을 용이하 <29> 게 한다. 즉, 한번에 백만개의 검색 항목을 처리하는 대신에, 상위 부분집합만의 랭킹을 개선하기 위해 백만개 의 상위 부분집합이 중점적으로 다루어진다. 따라서, 각 단계 후, 학습 알고리즘이 상위 결과의 재랭킹에 집중 하도록, 결과들의 새로운 분포가 생성될 수 있다. 랭커의 성능은 쌍별 정확도보다 오히려 랭크된 목록의 상위 에 있는 결과들 집합을 사용하여 측정된다. 그러므로, 이 방법은 또한 높은 점수화 문서를 재랭크하는 방법의 학습에 더 많은 비중을 둠으로써 트레이닝 중에 사용된 비용 함수와 평가 측정치 사이의 간격을 메울 수 있다. 다중 중첩 랭킹 방법은 도 1-8과 관련하여 더욱 설명된다. 이제, 도 1을 참조하면, 높이 랭크된 항목을 재랭크함으로써 주어진 쿼리에 대해 반환된 항목들의 랭킹의 개선 <30> 을 용이하게 하는 랭킹 시스템의 일반적인 블록도가 도시된다. 시스템은 주어진 쿼리에 대한 항목들 의 초기 집합을 검색하는 검색 컴포넌트를 포함한다. 예를 들어, 사용자가 \"childhood illness and antibiotics\"에 대한 검색을 실행했다고 가정하자. 검색 컴포넌트는 그들 검색 용어에 관련된 다수의 항 목을 검색할 수 있다. 그 다음, 검색된 항목은 다중 중첩 랭킹 컴포넌트의 제1 트레이닝 집합으로서 이용 될 수 있다. 다중 중첩 랭킹 컴포넌트는 검색 결과 목록의 상위에서의 가장 관련성 있는 항목들의 획득을 용이하게 하기 위해 높이 랭크된 항목들의 하나 이상의 감소하는 부분집합을 랭크하거나 재랭크할 수 있다. 다중 중첩 랭킹 컴포넌트는 다수의 신경망을 포함할 수 있다. 각 신경망은 랭킹을 학습하기 위해 항목들 <31> 의 트레이닝 집합을 사용하여 따로 트레이닝된다. 더욱 구체적으로, 위에서 언급된 RankNet에서, 각 신경망은 예제의 쌍에 기초한 확률 비용 함수를 사용하여 랭킹을 학습할 수 있다. 트레이닝 동안에, 신경망은 예를 들어, 나타낸 제1 예제가 제2 예제보다 더 높이 랭크되도록 요구되는 순서로 예제의 쌍을 나타내고; 신경망을 갱신하기 위해 사용된 비용 함수는 두 개의 예제에 대한 신경망의 출력에 의존한다. 예를 들어, 샘플 A에 신경 망의 입력이 주어지고, 그 다음에 샘플 B에 주어진다고 가정하고; 샘플 A가 샘플 B보다 신경망 랭크가 더 높은 것이 바람직하다고 가정하자. 신경망이 B보다 A에 더 낮은 숫자를 출력하면, 비용은 크고, 신경망은 이에 따라 그 가중치를 갱신하여, 이 비용을 감소시킨다. 게다가, 트레이닝 단계 동안에, 제1 예제가 항상 또는 거의 항 상 제2 예제보다 더 높이 랭크된다고 가정될 수 있다. 그러나, 테스팅 단계 동안에, 신경망은 단일 예제들을, 다음에 데이터를 랭크하기 위해 사용되는 하나의 숫자에 매핑할 수 있다. 쿼리에 응답하여 검색된 항목들의 초기 집합은 이러한 방식으로 랭크될 수 있다. 이러한 랭크된 항목 목록으로 <32> 부터, 높이 랭크된 항목들의 부분집합은 이러한 항목들 부분집합을 사용하여 다른 신경망을 트레이닝함으로써 재랭크될 수 있다. 실제로, 예를 들어, 100,000개의 (랭크된) 결과 중에서, 시스템은 상위 2500개의 항목을 선 택해서, 2500개 항목의 감소하는 부분집합 상에서 다수의 재랭킹 반복을 실행한다고 상상해보자. 결과적으로, (상위 2500개 항목으로부터의) 상위 10개의 항목은 실행된 재랭킹 단계의 수에 의존하여 한번 이상 재랭킹되고 및/또는 다시 뒤섞일 수 있다. 그러므로, 단계=0(재랭킹 이전) 및 다음에 단계=3(3번의 중첩된 반복 후)에서 목록 내의 상위 위치에 있는 항목의 비교는 상이한 항목을 얻을 수도 있고 아닐 수도 있다. 그러나, 몇몇 경우 에, 상위 위치 내의 항목은 최소한 한번은 변경되었을 수 있다. 이제, 도 2를 참조하면, 다중 중첩 랭킹 방법을 사용하여 높이 랭크된 항목들을 재랭크함으로써 주어진 쿼리에 <33> 대해 반환된 항목들의 랭킹의 개선을 용이하게 하는 랭킹 시스템의 블록도가 도시된다. 특히, 시스템 은 데이터의 초기 트레이닝 집합(예를 들어, 쿼리에 응답하여 검색된 항목들)을 수신하는 랭킹 컴포넌트 를 포함한다. 랭킹 컴포넌트는 샘플의 쌍에 기초한 확률 비용 함수를 사용하여 랭킹을 학습할 수 있 다. 더욱 구체적으로, 랭킹 컴포넌트는 샘플 A가 샘플 B보다 높게 랭크될 타깃 확률 과 함께 Rd 내의 샘플 쌍[A,B]의 집합이 주어지는 학습 알고리즘을 이용할 수 있다. 형태 의 모델을 이용하여, 샘플 집합의 랭크 순위는 f에 의해 얻은 실제 값에 의해 지정되는데, 더욱 구체적으로, 는 모델이 x2보다 x1을 더 높게 랭크한다는 것을 의미한다고 가정된다. 출력으로부터 확률로의 맵은 기호 논리학 함수 를 사용하여 모델링되는데, 여기에서 및 이다(xi는 xj보다 - 8 -공개특허 10-2008-0075147높게 랭크된다). 비용 함수는 또한 랭킹을 학습하기 위해 신경망과 함께 이용될 수 있다. 비용 함수는 2개의 연속적인 트레이닝 샘플의 출력 차의 함수가 될 수 있다: 즉, 인데, 제1 샘플은 제2 샘플보다 높거나 동일한 랭크를 갖는 것으로 가정한다. 그러므로, 랭킹 컴포넌트는 랭크된 항목을 제공할 수 있고, 이것에 의해, 랭크된 항목의 부분집합은 <34> 새로운 또는 변경된 트레이닝 집합으로서 이용될 수 있다. 이 새로운 트레이닝 집합은 각 단계에서, 트레 이닝 집합이 트레이닝 집합 변경 컴포넌트에 의해 점점 줄어들게 변경될 수 있는 다중 중첩 랭킹 컴포넌트 에 제공될 수 있다. 새로운 또는 변경된 집합이 생성되면, 그것은 특정 단계에서 항목들의 주어진 부분집 합에 대한 신경망을 생성하기 위해 신경망 트레이닝에서 사용될 수 있다. 도 3은 검색 결과 목록의 상위 또는 그 근처에 주어진 쿼리에 대해 가장 관련성 있는 항목들을 배치하는 것을 <35> 용이하게 하기 위해 항목들의 부분집합에 대해 단계적으로 랭킹 함수 또는 모델을 적용함으로써 높이 랭크된 항 목들의 재랭킹을 개략적으로 나타낸 것이다. 사용자 또는 탐색 및 검색 시스템은 단계들의 수, 및/또는 각 단 계에서 재랭크하기 위한 (높이 랭크된) 항목들의 수를 결정할 수 있다. 도 3에 도시된 바와 같이, 선택된 높이 랭크된 항목들은 하나 이상의 단계에서 재랭크될 수 있고, 이것에 의해 각각의 연속적인 단계에서, 재랭크된 항 목들의 부분집합은 항목들의 이전의 부분집합으로부터 감소된다. 실제로, 예를 들어, 트레이닝 쿼리 집합 이 있고, 각각의 쿼리 qi에 대해, 검색 엔진에서 사용된 기본 랭커에 의해 (검색된 R개의 항 목으로부터) 상위 R1개의 결과 중에서 랭크된 문서 집합 이 있다고 상상해보자. 이들 항목 의 랭킹에 대한 정보(예를 들어, 그들의 점수)는 또한 랭킹의 후속 단계에 대한 입력으로서 사용될 수 있다. 다중 중첩 랭킹 방법은 하나 이상의 단계에서 상위 결과들을 재랭크하기 위해 랭킹 알고리즘(예를 들어, 도 1 <36> 및 도 2에서의 랭킹 컴포넌트)를 적용한다. 각 단계에서, 랭킹 컴포넌트/알고리즘/함수에는 높이 랭크된 항목 들의 감소하는 부분집합을 포함하는 매번의 쿼리 결과의 새로운 분포가 제공된다. 그러므로, 각 단계 후, 트레 이닝 집합은 다음과 같은 방식으로 줄어드는데: 제1 단계에서, 랭킹 함수는 상위 R1개 결과의 전체 집합에 적용되고, 예를 들어, 쿼리 당 R1 = 2500개의 문서(예를 들어, 개체, 파일, URL, 이미지 등)이다. 트레이 닝 절차는 제1 신경망 Net1을 계산한다. 결과들은 Net1을 사용하여 계산된 점수를 감소시킴으로써 정렬될 수 있다. 그 후, 트레이닝 집합은 Net1에 따라 최고 점수를 받는 상위 R2개 문서만이 각 쿼리에 대해 남 도록 변경된다. 제2 단계는 Net2를 생성하고, R3개 상위 점수 문서만이 다음 트레이닝 집합을 위해 유지된다. 이렇게 줄 <37> 어드는 절차는 텔레스코핑(telescoping)이라 칭해질 수 있는데, 이것은 제1 단계 후에 R1에서 (R2-1)로의 랭크 로 문서들의 Net1 랭크를 고정하고, Net2로 상위 R2개 문서들을 재랭킹하며, 제2 단계 후에 랭크된 R2에서 (R3- 1)로 배치된 문서들의 랭크를 다시 고정하고, Net3으로 상위 R3개 결과를 재랭크하는 등등(예를 들어, 단계 3, 단계 4 등등)으로 된다. 그러므로, 다중 중첩 랭킹의 각 단계 후, 쿼리 당 모든 R1개 결과에 대한 랭크된 목록 이 생성되어 평가를 위해 사용될 수 있다. 단계들의 수 및 각 단계에서의 항목들의 수는 변할 수 있다. 그러 므로, 한 쿼리에 대해, R1=2500, R2=1000, R3=100, R4=10인 4개의 단계가 사용될 수 있고, 다른 쿼리에서, R1=2500, R2=100, R3=10인 3개의 단계가 사용될 수 있다. 각 단계에서의 항목들의 수는 항목들이 감소 부분집 합에서 나타나는 동안은 이전의 예에서의 것들과 다를 수 있다는 것을 알 수 있을 것이다. 이와 유사하거나 동 일한 텔레스코핑 절차는 유효성 검사 및 테스트 집합에 적용될 수 있다. 앞의 예시적인 시나리오에서 나타낸 바와 같이, 이 방법은 문제를 작은 부분으로 나누므로, 각 신경망은 실행하 <38> 기 위한 더 작고 단순한 작업을 갖는다. 또한, 데이터 집합을 줄어들게 하는 것은 트레이닝 집합으로부터 랭크 된 목록의 하위에 있는 곤란한 관련 문서를 아마도 제거할 수 있을 것이고, 알고리즘이 높은 점수 관련 문서의 랭킹에 집중할 수 있게 한다. 우리가 예시적으로 설명한 랭킹 알고리즘의 비용 함수가 2개의 연속적인 트레이닝 샘플의 출력 차에 의존한다는 <39> 것을 상기해 보자. 여기에서 설명된 바와 같이, 샘플들은 특정 쿼리에 응답하여 검색 엔진에 의해 반환된 문서 들 또는 다른 항목들이다. 그 후, 각각의 반복 후에, 트레이닝 샘플에 대한 신경망의 출력은 쿼리에 관련된 그 들의 랭킹을 생성한다. 현재의 비용 함수 형태로 인해, 랭킹 알고리즘은 랭크된 목록의 그들의 위치에 관계없 이 문서들의 정확한 쌍별 순위화를 학습하려고 시도한다. 따라서, 트레이닝 동안에, 신경망은 목록의 상위에 있는 관련 결과들의 일부를 약간 아래로 이동하는 것을 희생하더라도, 목록의 하위에 있는 문서들을 상당히 위 - 9 -공개특허 10-2008-0075147로 이동함으로써 쌍별 에러를 개선하는 것이 가능하다. 실험 데이터는 이것이 실제로 트레이닝 동안에 발생할 수 있다는 것을 증명했다. 이제, 도 4를 참조하면, 랭킹 항목에 대한 텔레스코핑 방식을 도시한 도면으로서, 특히 높이 랭크된 항목들의 <40> 감소하는 부분집합과, 중첩된 신경망과의 상호작용의 트레이닝시의 그들의 사용 사이의 관계를 도시한 블록도가 있다. 도면은 높이 랭크된 항목들의 초기 집합을 선택한 다음에 그것의 각각의 연속적인 부분집합을 줄어들게 하는 텔레스코핑 실시양상을 보여준다. 항목들을 랭크하기 위해 사용된 신경망은 또한 그러한 부분집합에 기초 하여 연속적으로 변경될 수 있다. 랭킹의 텔레스코핑 특성의 결과로서, 검색 결과 내의 더욱 관련된 항목들은 목록의 상위에서 가장 관련된 항목들을 얻기 위해 재랭크된다. 도면에 도시된 바와 같이, (검색 컴포넌트에 의해 검색된 다음에 랭크된 항목들의 목록으로부터 얻은) 높이 랭 <41> 크된 항목들의 초기 집합은 제1 신경망을 트레이닝하기 위해 사용될 수 있다. 그 다음, 트레이닝된 신경망은 높이 랭크된 항목들의 연속적인 부분집합을 얻기 위해 항목들에 적용될 수 있다. 이 것은 검색 결과 목록의 상위에 있는 항목들의 미세 조정을 용이하게 하기 위해 사용자가 원하는 만큼 많은 반복 동안 계속될 수 있다. 이것은 도 4에 도시되는데, 신경망 netG(G는 1보다 크거나 같은 정수)는 대응하는 변경 된 트레이닝 집합에 의해 트레이닝될 수 있다. 다양한 방법이 이제 일련의 액트를 통해 설명될 것이다. 본 시스템 및/또는 방법은 몇몇 액트들이 본 출원에 <42> 따라, 여기에 도시되고 설명된 것과 상이한 순서로 및/또는 그외 다른 액트와 동시에 발생할 수 있으므로, 액트 들의 순서에 의해 제한되지 않는다는 것을 이해할 것이고 알 수 있을 것이다. 예를 들어, 본 분야에 숙련된 기 술자들은 방법이 대안적으로 상태도에서와 같이 일련의 서로 관련된 상태 또는 이벤트로서 나타내질 수 있다는 것을 이해할 것이고 알 수 있을 것이다. 게다가, 본 출원에 따른 방법을 구현하기 위해 도시된 모든 액트가 요 구되는 것은 아니다. 이제, 도 5를 참조하면, 높이 랭크된 항목들을 재랭크함으로써 주어진 쿼리에 대해 반환된 항목들의 랭킹의 개 <43> 선을 용이하게 하는 예시적인 방법을 도시한 흐름도가 있다. 방법은 액트에서 검색 컴포넌트에 의해 주어진 쿼리에 대한 항목들의 초기 집합을 검색하는 것을 포함한다. 이 항목 집합은 항목의 초기 랭킹을 얻기 위해 임의의 랭킹 함수 또는 알고리즘을 사용하여 랭크될 수 있다. 다음에 액트에서, 방법은 쿼리에 대해 더욱 관련성 있는 항목들을 검색 결과 목록의 상위에 위치시키는 것을 용이하게 하기 위해 높이 랭 크된 항목들의 하나 이상의 감소하는 부분집합을 재랭크할 수 있다. 일단 항목들의 원하는 재랭킹이 실행되면, 검색 결과의 목록은 사용자에게 제시될 수 있다. 그러므로, 500,000개의 항목이 사용자의 쿼리에 응답하여 반 환된다고 상상해보라. 낮게 랭크된 항목의 랭킹(예를 들어, 목록의 하위 근처 또는 임계치 이하)을 개선하고자 시도하기보다는 오히려, 방법은 그 노력을 높이 랭크된 항목에 집중한다. 따라서, 목록상의 상위 3000개의 항 목이 선택될 수 있다. 결과적으로, 상위 300개 항목의 중첩된 그룹은 항목의 현재 랭킹이 부분적으로 이전의 랭킹에 의해 결정될 수 있도록, 연속적인 방식으로 재랭크된다. 도 6을 참조하면, 다중 중첩 랭킹 방법을 사용하여 높이 랭크된 항목들을 재랭크함으로써 주어진 쿼리에 대해 <44> 반환된 항목들의 랭킹의 개선을 용이하게 하는 예시적인 방법을 도시한 흐름도가 있다. 방법은 액트 에서 쿼리에 응답하여 다수의 항목을 검색하는 것을 포함한다. 액트에서, 항목들은 임의의 원하는 랭킹 함수 또는 모드를 사용하여 랭크될 수 있다. 높이 랭크된 항목들(예를 들어, 상위 V개의 항목들, 여기에 서 V는 1보다 큰 정수)의 랭킹을 개선하기 위해, 높이 랭크된 항목들은 다중 중첩 랭킹 방법을 사용하여 재랭크 될 수 있다(액트). 즉, 동일하거나 유사한 랭킹 함수는 한번에 전체 항목 그룹에 적용되기 봐는 오히려 단계적으로(예를 들어, 항목들의 감소하는 부분집합에서) 높이 랭크된 항목들에 적용될 수 있다. 예를 들어, 상위 2500개의 항목은 선택되어, 상위 2500개 항목의 새로운 순위를 얻기 위해 재랭크될 수 있다. 그 후, 상위 100개의 항목은 선택되어, 상위 100개 항목의 새로운 순위를 얻기 위해 재랭크될 수 있고-한편, (상위 100개보 다 낮게 랭크된) 나머지 2400개 항목의 랭킹은 변경되지 않고 그대로 남아 있다. 원한다면, 재랭킹의 또 다른 단계가, 예를 들어 상위 10개의 항목에서 실행될 수 있다. 액트에서, 재랭크된 항목들 및 검색 컴포넌트 에 의해 검색된 나머지 항목들은 사용자에게 제시될 수 있다. 아래의 도 7 및 도 8에서, 설명된 방법(700, 800)은 다른 경우에 랭킹보다 상위 항목들(또는 더욱 일반적으로 <45> 항목들의 소정의 부분집합)의 랭킹의 정확도가 더욱 중요한 임의의 순위화 문제에 적용할 수 있다는 것을 알 수 있을 것이다. 검색 엔진은 이것이 적용되는 애플리케이션의 많은 예들 중의 하나이고, 거기에 반드시 관련된 쿼리가 있어야 하는 것은 아니다. 이제, 도 7을 참조하면, 대응하는 랭킹 컴포넌트를 트레이닝하기 위해 개별적이고 연속적으로 사용되는 트레이 <46> - 10 -공개특허 10-2008-0075147닝 집합을 줄어들게 하거나 변경함으로써 주어진 쿼리에 대해 반환된 항목들의 랭킹의 개선을 용이하게 하는 예 시적인 방법을 도시한 흐름도가 있다. 방법은 검색 컴포넌트 또는 엔진에 의해 쿼리에 응답하여 항 목을 검색하는 액트를 포함한다. 액트에서, 랭킹 컴포넌트는 트레이닝 집합을 사용하여 계산되거나 트레이닝될 수 있다. 검색 컴포넌트에 의해 검색된 항목들은 랭킹 컴포넌트를 사용하여 랭크될 수 있다(액트 ). 액트에서, 트레이닝 집합은 낮게 랭크된 항목(예를 들어, 관련성이 결정하기 더욱 어려운 낮은 점수화 항목)을 제외함으로써 변경되거나 줄어들 수 있다. 결과적으로, 랭킹 컴포넌트는 더욱 관련성 있는 높 은 점수화 항목의 랭킹에 집중할 수 있다. 액트에서, 새로운 또는 변경된 랭킹 컴포넌트는 변경된 트레이 닝 집합을 사용하여 트레이닝될 수 있다. 나머지 항목(예를 들어, 제외되지 않은 것들)은 변경된 랭킹 컴포넌 트에 의해 다시 랭크될 수 있다(액트). 액트(740 내지 760)에서 발생하는 프로세스는 원하는 만큼 반복될 수 있고, 이것에 의해, 높이 랭크된 항목들의 감소하는 부분집합이 그들의 대응하는 변경된 트레이닝 집합에 의 해 재랭크된다. 도 8에, 다중 중첩 랭킹 방법을 사용하여 높이 랭크된 항목들의 감소하는 부분집합을 재랭크함으로써 주어진 쿼 <47> 리에 대해 반환된 항목들의 랭킹의 개선을 용이하게 하는 예시적인 방법을 도시한 흐름도가 있다. 방법 은 주어진 쿼리에 대해 검색된 랭크된 항목 목록으로부터 높이 랭크된 항목을 추출하는 액트를 포함 한다. 예를 들어, 검색된 200만 개의 문서 중에서 상위 1000개 문서를 선택하는 것을 상상해보라. 액트 에서, 랭킹 컴포넌트(예를 들어, 기계 학습 신경망)는 (추출된) 높이 랭크된 항목에서 트레이닝될 수 있다. 따 라서, 상위 1000개 항목은 트레이닝 집합으로서 이용된다. 액트에서, 이들 항목은 최근에 트레이닝된 랭 킹 컴포넌트에 의해 재랭크될 수 있다. 이것은 검색 컴포넌트를 통해 검색된 200만 개의 문서로부터의 임의의 정보가 이 재랭킹 프로세스에서 고려되지 않는다는 것을 의미한다. 액트에서, 재랭크된 높이 랭크된 항목 들의 부분집합은 랭킹 컴포넌트의 트레이닝을 다시 변경하기 위해 추출될 수 있다. 따라서, 이제, 재랭크된 100개 항목 목록으로부터 상위 100개 항목을 선택하고, 랭킹 컴포넌트를 재트레이닝하기 위해 새로운 또는 변경 된 트레이닝 집합으로서 상위 100개 항목을 사용하는 것을 상상해보라. 그 다음, 액트에서, 100개 항목은 변경된 랭킹 컴포넌트에 의해 재랭크될 수 있다. 이것은 이제 100개 항목 목록에서 상위 10개 항목을 선택하여 이들을 유사한 방식으로 재랭크함으로써 다시 반복될 수 있다. 알 수 있는 바와 같이, 목록상의 상위 10개 항 목은 각 단계에서 반복적으로 재순위화될 수 있다. 이제, 도 9를 참조하면, 도면은 검색 결과의 재랭킹, 특히 높이 랭크된 항목의 재랭킹을 매우 작은 규모로 설명 <48> 한다. 사용자가 \"strollers\"에 대한 웹 쿼리를 입력했고, 많은 항목이 반환되었으며 그 다음에 랭크되었다고 상상해 보자. 블록은 이 랭킹으로부터 비롯된 상위 5개 항목의 목록을 제공한다. 상위 5개 항목(예를 들 어, URL)의 개선된 순위를 얻기 위해, 다중 중첩 방법은 단계적으로(예를 들어, 하나 이상의 단계로) 항목을 재 순위화하기 위해 이용될 수 있다. 더욱 실제 규모에서, 시스템은 이 쿼리에 대해 250만 개의 검색된 항목을 처 리할 수 있으므로, 상위 10개 항목 및/또는 상위 항목의 순위화를 궁극적으로 개선하기 위한 상위 5000개 항목 의 재순위화에 관한 작업은 사용자에게 상당히 유리할 수 있다. 따라서, 항목의 재랭킹 후, 5개 항목의 새로운 순위가 얻어진다(블록). 그 다음, 최종 결과 목록은 도 10에 도시된 바와 같이 사용자에게 제시될 수 있 다. 다수의 중첩 랭킹 컴포넌트에 의해 소모된 처리 시간은 무시할 만하고, 사용자에게 별로 눈에 띄지 않으며; 결과 목록의 상위에 가장 관련 있는 항목을 제공하는데 있어서의 개선된 정확도는 검색 컴포넌트로 사 용자 만족감을 상당히 증가시킨다. 본 출원의 다양한 실시양상에 대한 추가 상황을 제공하기 위해, 도 11 및 다음 설명은 본 출원의 다양한 실시양 <49> 상이 구현될 수 있는 적합한 컴퓨팅 환경의 간단한 일반 설명을 제공하고자 하는 것이다. 시스템(들) 및 /또는 방법(들)이 하나 이상의 컴퓨터 또는 기타 장치에 의해 실행된 프로그램 모듈과 같은 컴퓨터 실행가능 명 령어의 일반적인 문맥으로 설명되지만, 본 분야에 숙련된 기술자들은 본 발명이 또한 기타 프로그램 모듈과의 조합으로 및/또는 하드웨어와 소프트웨어의 조합으로서 구현될 수 있다는 것을 인식할 것이다. 그러나, 일반적으로, 프로그램 모듈은 특정 태스크를 수행하거나 특정 데이터 유형을 구현하는 루틴, 프로그램, <50> 개체, 컴포넌트, 데이터 구조 등을 포함한다. 운영 환경은 적합한 운영 환경의 일례에 불과하며, 본 시 스템 및/또는 방법의 용도 또는 기능성의 범위에 관해 어떤 제한을 암시하고자 하는 것이 아니다. 본 시스템 및/또는 방법과 함께 사용하기 적합한 기타 잘 알려진 컴퓨터 시스템, 환경 및/또는 구성은 퍼스널 컴퓨터, 핸 드헬드 또는 랩톱 장치, 멀티프로세서 시스템, 마이크로프로세서 기반 시스템, 프로그램가능한 가전제품, 네트 워크 PC, 미니컴퓨터, 메인프레임 컴퓨터, 상기 시스템들이나 장치들을 포함하는 분산 컴퓨팅 환경, 기타 등등 이 있지만 이에 제한되는 것은 아니다. 도 11과 관련하여, 시스템 및/또는 방법의 다양한 실시양상을 구현하는 예시적인 환경은 컴퓨터를 <51> - 11 -공개특허 10-2008-0075147포함한다. 컴퓨터는 처리 장치, 시스템 메모리 및 시스템 버스를 포함한다. 시스템 버스는 시스템 메모리를 포함하는(제한되지는 않음) 시스템 컴포넌트들을 처리 장치에 연결 한다. 처리 장치는 각종 시판중인 프로세서들 중의 어느 것이라도 될 수 있다. 듀얼 마이크로프로세서 및 기타 멀티-프로세서 아키텍처가 또한 처리 장치로서 이용될 수 있다. 시스템 버스는 메모리 버스 또는 메모리 컨트롤러, 주변 버스 또는 외부 버스, 및/또는 각종 이용가능 버 <52> 스 아키텍처 중의 임의의 것을 이용하는 로컬 버스를 비롯한 몇몇 유형의 버스 구조(들) 중 어느 것이라도 될 수 있는데, 이러한 버스 아키텍처는 11비트 버스, ISA(industry standard architecture), MCA(micro channel architecture), EISA(Enhanced ISA), IDE(Intelligent Drive Electronics), VLB(VESA Local Bus), PCI(peripheral component interconnect), USB(Universal Serial Bus), AGP(Advanced Graphics Port), PCMCIA(Personal Computer Memory Card International Association bus) 및 SCSI(Small Computer Systems Interface)를 포함하지만 이에 제한되는 것은 아니다. 시스템 메모리는 휘발성 메모리 및 비휘발성 메모리를 포함한다. 시동 중과 같은 때에, 컴 <53> 퓨터 내의 구성요소들 사이의 정보를 전송하는 기본 루틴을 포함하는 기본 입/출력 시스템(BIOS)은 비휘 발성 메모리 내에 저장되어 있다. 예시적으로, 비휘발성 메모리는 판독 전용 메모리(ROM), 프로그 램가능 ROM(PROM), 전기적으로 프로그램가능 ROM(EPROM), 전기적으로 소거가능 프로그램가능 ROM(EEPROM) 또는 플래시 메모리를 포함할 수 있지만 이에 제한되는 것은 아니다. 휘발성 메모리는 외부 캐시 메모리로서 동작하는 랜덤 액세스 메모리(RAM)를 포함한다. 예시적으로, RAM은 동기식 RAM(SRAM), 동적 RAM(DRAM), 동기식 DRAM(SDRAM), 2배속 SDRAM(DDR SDRAM), 인핸스드 SDRAM(ESDRAM), 싱크링크 DRAM(SLDRAM) 및 다이렉트 램버스 RAM(DRRAM)과 같은 많은 형태로 이용가능한데, 이에 제한되는 것은 아니다. 컴퓨터는 또한 이동식/비이동식, 휘발성/비휘발성 컴퓨터 저장 매체를 포함한다. 도 11은, 예를 들어 디 <54> 스크 저장 장치를 도시하고 있다. 디스크 저장 장치는 자기 디스크 드라이브, 플로피 디스크 드라 이브, 테이프 드라이브, 재즈(Jaz) 드라이브, 지프(Zip) 드라이브, LS-100 드라이브, 플래시 메모리 카드 또는 메모리 스틱과 같은 장치를 포함하는데, 이에 제한되는 것은 아니다. 또한, 디스크 저장 장치는 컴팩트 디스크 ROM 장치(CD-ROM), CD 기록가능 드라이브(CD-R Drive), CD 재기입가능 드라이브(CD-RW Drive) 또는 DVD-ROM 드라이브(digital versatile disk ROM)와 같은 광 디스크 드라이브를 포함하는(이것에 제한되지 않음) 기타 저장 매체와 결합하여 또는 분리하여 저장 매체를 포함할 수 있다. 시스템 버스로의 디스크 저장 장치의 접속을 용이하게 하기 위해, 인터페이스와 같은 이동식 또는 비이동식 인터페이스가 통상적 으로 사용된다. 도 11은 적합한 운영 환경에서 설명된 기본 컴퓨터 자원들과 사용자들 사이의 중간자로서 동작하는 소프 <55> 트웨어를 설명하고 있다는 것을 알 수 있을 것이다. 그러한 소프트웨어는 운영 체제를 포함한다. 디스 크 저장 장치 상에 저장될 수 있는 운영 체제는 컴퓨터 시스템의 자원을 제어하고 할당하는 동작을 한다. 시스템 애플리케이션은 시스템 메모리 내에 또는 디스크 저장 장치 상에 저장 된 프로그램 모듈 및 프로그램 데이터를 통해 운영 체제에 의한 자원 관리를 이용한다. 본 시스템 및/또는 방법은 다양한 운영 체제들, 또는 운영 체제들의 조합으로 구현될 수 있다는 것을 알 수 있을 것이다. 사용자는 입력 장치(들)를 통해 명령 또는 정보를 컴퓨터에 입력한다. 입력 장치는 마우스, <56> 트랙볼, 스타일러스, 터치패드와 같은 포인팅 장치, 키보드, 마이크, 조이스틱, 게임 패드, 위성 안테나, 스캐 너, TV 튜너 카드, 디지털 카메라, 디지털 비디오 카메라, 웹 카메라 등을 포함하는데 이에 제한되는 것은 아니 다. 이들 및 기타 입력 장치는 인터페이스 포트(들)를 경유하여 시스템 버스를 통해 처리 장치 에 접속한다. 인터페이스 포트(들)는 예를 들어, 직렬 포트, 병렬 포트, 게임 포트 및 USB(universal serial bus)를 포함한다. 출력 장치(들)는 입력 장치(들)와 동일한 유형의 포트들 중의 소정의 것을 사용한다. 그러므로, 예를 들어, USB 포트는 컴퓨터에 입력을 제공하고, 컴퓨터(111 2)로부터의 정보를 출력 장치에 출력하기 위해 사용될 수 있다. 출력 어댑터는 기타 출력 장치 중에서 특히, 특정 어댑터를 필요로 하는 모니터, 스피커 및 프린터와 같은 몇몇 출력 장치가 있 다는 것을 나타내기 위해 제공된다. 출력 어댑터는 출력 장치와 시스템 버스 사이에 접속 수단을 제공하는 비디오 및 사운드 카드를 예시적으로 포함하는데, 이에 제한되는 것은 아니다. 원격 컴퓨터 (들)과 같은 기타 장치 및/또는 장치의 시스템은 입력 및 출력 능력을 제공한다는 것을 알 수 있을 것이다. - 12 -공개특허 10-2008-0075147컴퓨터는 원격 컴퓨터(들)와 같은 하나 이상의 원격 컴퓨터로의 논리적 접속을 사용하여 네트워크 <57> 화된 환경에서 동작할 수 있다. 원격 컴퓨터(들)는 퍼스널 컴퓨터, 서버, 라우터, 네트워크 PC, 워크스 테이션, 마이크로프로세서 기반 가전제품, 피어 장치 또는 기타 공통 네트워크 노드 등일 수 있고, 통상적으로 컴퓨터와 관련하여 설명된 구성요소들의 대부분 또는 그 전부를 포함한다. 간결하게 하기 위해, 하나의 메모리 저장 장치만이 원격 컴퓨터(들)와 함께 도시되어 있다. 원격 컴퓨터(들)는 네트워크 인터페이스를 통해 컴퓨터에 논리적으로 접속된 다음에, 통신 접속을 통해 물리적으로 접속 된다. 네트워크 인터페이스는 LAN 및 WAN과 같은 통신 네트워크를 포함한다. LAN 기술은 FDDI(Fiber Distributed Data Interface), CDDI(Copper Distributed Data Interface), 이더넷(Ethernet)/IEEE 1102.3, 토 큰 링(Token Ring)/IEEE 1102.5 등을 포함한다. WAN 기술은 점 대 점 링크, ISDN(Integrated Services Digital Networks) 및 그 변형과 같은 회선 교환망, 패킷 교환망 및 DSL(Digital Subscriber Lines)을 포함하 는데 이에 제한되는 것은 아니다. 통신 접속(들)은 네트워크 인터페이스를 버스에 접속하기 위해 이용된 하드웨어/소프트웨어 <58> 를 나타낸다. 통신 접속은 명확하게 도시하기 위해 컴퓨터 내부에 도시되었지만, 컴퓨터의 외부에도 있을 수 있다. 네트워크 인터페이스에 접속하기 위해 필요한 하드웨어/소프트웨어는 단지 예시 적인 목적을 위해, 일반 전화 등급 모뎀, 케이블 모뎀 및 DSL 모뎀을 포함하는 모뎀, ISDN 어댑터 및 이더넷 카 드와 같은 내부 및 외부 기술을 포함한다. 상기 설명된 것은 본 시스템 및/또는 방법의 예를 포함한다. 물론, 본 시스템 및/또는 방법을 설명하기 위해 <59> 컴포넌트 또는 방법의 가능한 모든 조합을 설명할 수는 없지만, 본 분야에 숙련된 기술자는 본 시스템 및/또는 방법의 더 많은 조합과 변경이 가능하다는 것을 인식할 것이다. 따라서, 본 시스템 및/또는 방법은 첨부된 청 구범위의 정신 및 범위 내에서 그러한 모든 변경, 수정 및 변형을 포함하고자 하는 것이다. 더욱이, \"포함하다 (includes)\"라는 용어가 상세한 설명 또는 청구범위에서 사용되는 한도까지, 그러한 용어는 \"포함하는 (comprising)\"이라는 용어가 청구범위에서 연결어로서 이용될 때 해석되는 바와 같이 \"포함하는(comprising)\"이 라는 용어와 유사한 방식으로 포괄적인 의미로 사용하고자 하는 것이다."}
