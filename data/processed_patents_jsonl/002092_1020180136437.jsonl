{"patent_id": "10-2018-0136437", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0053170", "출원번호": "10-2018-0136437", "발명의 명칭": "인공지능 실행가속을 위한 인공지능 실행모델 설정방법 및 인공지능 실행가속시스템", "출원인": "박정우", "발명자": "박정우"}}
{"patent_id": "10-2018-0136437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 실행가속시스템에 있어서,인공지능 학습 결과로 생성된 웨이트파일 및 인공지능모델을 포함하는 학습모델을 분석하여, 인공지능 실행 가속을 위한 인공지능 학습모델의 데이터 가중치를 산출하는 실행가중치 추출모듈;상기 학습모델을 산출하는 인공지능학습서버로부터 상기 학습모델을 로딩 하고, 상기 로딩된 학습모델을 인공지능 실행 가속 시스템에서 이용 가능한 커스텀레이어로 변환 후, 상기 커스텀레이어(custom layer)를 최적화하여실행모델을 산출하는 인공지능 가속실행파일설정모듈; 및상기 실행모델을 전달받아 상기 실행모델에 대응되는 실행 환경을 구성하여 인공지능 실행속도를 가속하는 인공지능 실행 가속 모듈; 을 포함하는 인공지능 실행가속시스템."}
{"patent_id": "10-2018-0136437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 인공지능 실행가속파일 설정모듈; 은상기 인공지능 학습모델에 컨볼루션(convolution) 및 렐루(Relu)를 포함하는 연산함수를 이용하여 상기 학습모델의 메타데이터를 가시화하여 커스텀레이어를 생성하고, 상기 생성된 커스텀레이어의 최적화 필요여부를 판단하는 것을 특징으로 하는 인공지능실행 가속시스템."}
{"patent_id": "10-2018-0136437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, 상기 인공지능 실행가속파일 설정모듈; 은상기 커스텀레이어의 접점, 중복최적화, GPU(Graphic Processing Unit)구현 가능성을 포함하는 최적화 조건을산출하여 산출결과에 따라 커스텀레이어의 최적화를 판단하는 것을 특징으로 하는 인공지능 실행가속시스템."}
{"patent_id": "10-2018-0136437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 실행가중치 추출모듈은상기 인공지능 학습 서버에 기 저장된 가중치 파일 형식을 추출하고, 추출된 가중치 파일 형식을 상기 실행모델에 최적화된 형태로 변환하는 것을 특징으로 하는 인공지능실행 가속시스템."}
{"patent_id": "10-2018-0136437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서, 상기 실행가속모듈은 실행모델의 실행단계 별 소요 메모리 할당량의 최적값을 산출하고, 병렬처리를 포함하는 실행단계 별 완료 여부를 파악하여, 완료된 단계에서 다시 사용하지 않는 데이터를 삭제한 메모리 영역을 재사용하여 상기 인공지능실행 가속모듈의 메모리를 최적화 하는 것을 특징으로 하는 인공지능 실행가속시스템."}
{"patent_id": "10-2018-0136437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서, 상기 실행가속모듈은 공개특허 10-2020-0053170-3-CPU와 GPU간의 데이터 처리를 변환하여, 비 동기(Async)로 GPU 내부에서 인공지능 실행모델이 처리되도록 하여오버헤드 발생을 최소화하는 것을 특징으로 하는 인공지능 실행가속시스템."}
{"patent_id": "10-2018-0136437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "인공지능 실행가속을 위한 인공지능 실행모델 설정방법에 있어서,(A) 인공지능 학습서버에서 학습 결과로 생성된 웨이트 파일 및 인공지능 모델을 포함하는 학습모델을 상기 인공지능 학습서버로부터 로딩하는 단계;(B) 인공지능 가속 실행파일 설정모듈에서 상기 학습모델을 콘벌루션(convolution) 및 렐루(ReLu)를 포함하는연산함수를 이용하여 상기 학습모델의 메타데이터를 가시화하는 단계;(C) 인공지능 가속 실행파일 설정모듈에서 상기 가시화된 학습모델 파일을 NMS(Non Maximum Suppression)및 풀링(Pooling)을 포함하는 커스텀레이어설정 함수를 이용하여 인공지능 실행 가속기에서 사용 가능한 커스텀레이어로 설정하는 단계; (D) 인공지능 가속 실행파일 설정모듈에서 상기 커스텀레이어의 접점, 중복최적화, GPU구현 가능성을 포함하는최적화 조건을 산출하여 산출결과에 따라 상기 커스텀레이어의 최적화 여부를 판단하는 단계; (E) 인공지능 가속 실행파일 설정모듈에서 상기 커스텀레이어가 최적화된 것으로 판단된 경우, 로딩된 가중치파일을 상기 커스텀레이어에 부가하여 인공지능 실행가속기에서 사용 가능한 실행모델로 변환하는 단계; 를 포함하는 인공지능 실행모델 설정방법."}
{"patent_id": "10-2018-0136437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서, 상기 인공지능 실행모델 설정 방법은(F) 인공지능 실행 가속 모듈에서 상기 실행모델을 전달받아 상기 실행모델에 대응되는 실행 환경을 구성하여인공지능 실행속도를 가속하는 단계; 를 더 포함하는 것을 특징으로 하는 인공지능 실행모델 설정방법."}
{"patent_id": "10-2018-0136437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7항에 있어서, (E) 상기 커스텀레이어에 부가하여 인공지능 실행가속기에서 사용 가능한 모델설정파일로 변환하는 단계; 는 실행가중치 추출모듈에서 상기 인공지능 학습 서버에 기 저장된 가중치 파일 형식을 추출하는 단계; 추출된 가중치 파일 형식을 상기 학습모델에 최적화된 가중치 파일 형태로 변환하는 단계; 및상기 최적화된 가중치 파일을 실행모델에 적용하는 단계; 를 포함하는 것을 특징으로 하는 인공지능 실행모델설정방법."}
{"patent_id": "10-2018-0136437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8항에 있어서, 상기 (F) 인공지능 실행 가속 모듈에서 상기 실행모델을 전달받아 상기 실행모델에 대응되는실행 환경을 구성하여 인공지능 실행속도를 가속하는 단계; 는실행모델의 인공지능 실행단계 별 소요 메모리 할당량의 최적값을 산출하는 단계; 및상기 인공지능 실행단계 별 소요 메모리 영역을 재사용하여 상기 인공지능 실행 가속모듈의 메모리를 최적화 하는 단계; 를 포함하는 것을 특징으로 하는 인공지능 실행모델 설정방법. 공개특허 10-2020-0053170-4-청구항 11 제 8항에 있어서, 상기 (F) 인공지능 실행 가속 모듈에서 상기 실행모델을 전달받아 상기 실행모델에 대응되는실행 환경을 구성하여 인공지능 실행속도를 가속하는 단계; 는CPU와 GPU간의 데이터 처리를 변환하여 비동기적으로 GPU 내부에서 인공지능 실행모델이 처리되도록 하여 오버헤드 발생을 최소화하는 것을 특징으로 하는 인공지능 실행모델 설정방법."}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 실행가속시스템 및 인공지능 실행모델 설정방법을 제공한다. 실시예에 따른 인공지능 실행가속시스템은 인공지능 학습 결과로 생성된 웨이트파일 및 인공지능모델을 포함하는 학습모델을 분석하여, 인공지능 실행 가속 을 위한 인공지능 학습모델의 데이터 가중치를 산출하는 실행가중치 추출모듈; 학습모델을 산출하는 인공지능학 습서버로부터 학습모델을 로딩 하고, 로딩된 학습모델을 인공지능 실행 가속 시스템에서 이용 가능한 커스텀레이 어로 변환 후, 커스텀레이어(custom layer)를 최적화하여 실행모델을 산출하는 인공지능 가속실행파일설정모듈; 및 실행모델을 전달받아 실행모델에 대응되는 실행 환경을 구성하여 인공지능 실행속도를 가속하는 인공지능 실 행 가속 모듈; 을 포함한다."}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "인공지능 실행가속 시스템 및 인공지능 실행모델 설정방법에 관한 것으로 구체적으로, 학습기능을 제거하고 인 공지능 실행기능만을 수행하도록 서버를 구성하여 인공지능 실행 속도를 높이고 메모리 사용량을 경감시킨 인공 지능 실행모델 설정방법, 인공지능 실행가속시스템 및 실행가속서버에 관한 것이다."}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 명세서에서 달리 표시되지 않는 한, 이 섹션에 설명되는 내용들은 이 출원의 청구항들에 대한 종래 기술이 아니며, 이 섹션에 포함된다고 하여 종래 기술이라고 인정되는 것은 아니다. 인공지능(artificial intelligence)은 인간의 지능으로 할 수 있는 사고, 학습, 자기 개발 등을 컴퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보기술의 한 분야로서, 컴퓨터가 인간의 지능적인 행동을 모방 할 수 있도록 하는 기술이다. 또한 인공지능은 그 자체로 존재하는 것이 아니라, 컴퓨터 과학의 다른 분야와 직 간접으로 많은 관련을 맺고 있다. 특히 현대에는 정보기술의 여러 분야에서 인공지능적 요소를 도입하여 그 분 야의 문제 풀이에 활용하려는 시도가 매우 활발하게 이루어지고 있고, 인공지능을 실생활 여러 측면에 결합시켜 디지털 기기의 기능을 확장하고 있는 추세이다. 인공지능은 크게 학습기능을 수행하는 서버와 실행기능을 수행하는 모듈로 나눌 수 있다. 학습 기능을 수행하는 서버에서는 방대한 데이터를 수집하고 그 데이터에서 특징을 찾아 데이터 패턴 등 전자기기를 학습시키기 위한 데이터 처리를 수행하고, 실행기능을 수행하는 모듈에서는 학습을 통해 최적화된 값을 이용하여 입력되는 데이 터를 처리하여 이를 바탕으로 한 추론 기능을 제공하게 된다. 인공지능 학습과정은 데이터 처리량이 방대하기 때문에 고성능의 서버와 수십 기가에 이르는 메모리 등이 필요 하다. 학습과정에서는 데이터 인식, 해석, 패턴화 등 고도의 연산처리가 지속적으로 이루어지기 때문에 학습 결 과를 가지고 인공지능 실행 과정을 거칠 경우, 데이터 처리속도가 매우 느릴 수 밖에 없다. 인터넷이 단절된 상황에서도 학습된 인공지능은 그 역할을 해야 하는데, 종래 클라우드기반의 인공지능 서비스 는 인터넷 연결이 불가능한 환경에서 인공지능 기능을 수행할 수 없다. 이를 해결하기 위해 인공지능기능이 수 행되는 에지 단말에 인공지능 학습 기능이 함께 설치되는 경우, 인공지능 모델의 데이터 처리속도가 너무 느려 져 실제 단말 사용에 큰 불편함이 있게 된다. 또한, 프로그램 개발자는 인공지능을 이용하는 프로그램을 개발하려면 난해한 인공지능 API를 숙지해야만 관련 프로그램을 개발할 수 있는 한계가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국 특허출원 제10-2017-0055772호(2017.04.28)"}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "(특허문헌 0002) 2. 한국 특허등록 제10-2016-7035262호(2015.06.01) 발명의 내용"}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 인공지능 실행 가속화를 위해, 인공지능 학습기능과 실행기능을 분리함으로써, 인공지능 시스 템 에지(edge) 단의 스마트 기기에서 학습기능을 제외한 인공지능 실행 기능만을 수행하게 하는 인공지능 실행 가속 시스템 및 인공지능 실행모델 설정방법을 제공함에 있다. 특히, 실시예에 따른 인공지능 실행 가속 서버가 사용하는 가중치 값은 외부 학습서버로부터 웨이트 파일 을 추출하여 실행모델에 최적화된 가중치 값을 생성하고, 이를 실행모델에 적용하여 인공지능 실행모듈에서의 데이터 처리 속도를 가속화 하도록 한다."}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 따른 인공지능 실행가속시스템은 인공지능 학습 결과로 생성된 웨이트파일 및 인공지능모델을 포함하 는 학습모델을 분석하여, 인공지능 실행 가속을 위한 인공지능 학습모델의 데이터 가중치를 산출하는 실행가중 치 추출모듈; 학습모델을 산출하는 인공지능학습서버로부터 상기 학습모델을 로딩 하고, 로딩된 학습모델을 인 공지능 실행 가속 시스템에서 이용 가능한 커스텀레이어로 변환 후, 상기 커스텀레이어(custom layer)를 최적화 하여 실행모델을 산출하는 인공지능 가속실행파일설정모듈; 및 실행모델을 전달받아 상기 실행모델에 대응되는 실행 환경을 구성하여 인공지능 실행속도를 가속하는 인공지능 실행 가속 모듈; 을 포함한다. 다른 실시예에 따른 인공지능 실행가속을 위한 인공지능 실행모델 설정방법은 (A) 인공지능 학습서버에서 학습 결과로 생성된 웨이트 파일 및 인공지능 모델을 포함하는 학습모델을 인공지능 학습서버로부터 로딩하는 단계; (B) 인공지능 가속 실행파일 설정모듈에서 상기 학습모델을 콘벌루션(convolution) 및 렐루(ReLu)를 포함하는 연산함수를 이용하여 학습모델의 메타데이터를 가시화하는 단계; (C) 인공지능 가속 실행파일 설정모듈에서 상 기 가시화된 학습모델 파일을 NMS(Non Maximum Suppression)및 풀링(Pooling)을 포함하는 커스텀레이어 설정 함수를 이용하여 인공지능 실행 가속기에서 사용 가능한 커스텀레이어로 설정하는 단계; (D) 인공지능 가속 실 행파일 설정모듈에서 커스텀레이어의 접점, 중복최적화, GPU구현 가능성을 포함하는 최적화 조건을 산출하여 산 출결과에 따라 상기 커스텀레이어의 최적화 여부를 판단하는 단계; (E) 인공지능 가속 실행파일 설정모듈에서 커스텀레이어가 최적화된 것으로 판단된 경우, 로딩된 가중치 파일을 커스텀레이어에 부가하여 인공지능 실행가 속기에서 사용 가능한 실행모델로 변환하는 단계; 를 포함한다."}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같은 인공지능 실행가속 서버는 인공지능의 학습기능과 실행기능을 분리함으로써, 소요되는 메모리 와 하드웨어 자원(CPU 및 GPU)의 소요량을 절감함으로써 인공지능 모델의 실행을 위한 서버 비용을 절감하고, 처리 성능을 향상시킬 수 있으며, 저 사양의 에지 단 장치에서도 인공지능 모델을 실행할 수 있게 되어 인터넷 이 불가능한 상황에서도 인공지능을 이용한 서비스를 제공할 수 있도록 한다. 실시예를 통해 고가의 서버에서 실행해야 하는 인공지능 모델을 PC급 기기에서 실행할 수 있으며, 인공지능 모 델을 소형의 IoT 기기에서도 빠르게 작은 메모리로 실행 할 수 있도록 한다. 또한, 설정방식으로 인공지능 모델을 탑재하고, 미리 학습된 웨이트 파일을 에지 단말 엔진에 로딩하여 실행하 는 방식으로 사용하므로, 인공지능을 알지 못하는 일반 개발자들도 인공지능을 이용하는 프로그램을 만들 수 있 도록 한다."}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이"}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 도면부호는 동일 구성 요소를 지칭한다. 본 발명의 실시 예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명의 실시 예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도 1은 이해를 돕기 위해 종래 인공지능 서비스 구조와 실시예에 따른 인공지능 실행가속 시스템 구조를 비교한 도면이고, 도 2는 종래 인공지능 시스템과 실시예에 따른 인공지능 실행 가속 시스템의 기능 비교를 위한 도면 이다. 도 1 및 2를 참조하면, 종래의 인공지능 서비스 시스템은 학습기능과 실행기능이 결합된 형태의 시스템으로 구 성되어 있다. 반면, 실시예에 따른 인공지능 실행가속시스템은 학습단계의 시스템 구성을 제거한 인공지능 가속 실행 서버로만 구성되고, 인공지능 실행 가속 서버는 인공지능 실행기능만을 수행하도록 구성된다. 실시예에 따 른 인공지능 실행 가속시스템에서는 인공지능 학습 기능을 제거하여 인공지능 시스템의 에지 단말에서 인공지능 기능의 실행속도를 향상시킬 수 있도록 한다. 또한, 학습기능을 제거한 인공지능 시스템을 제공함으로써 인공지 능 실행기능을 고속화 하고, 인공지능 실행에 필요한 메모리를 대폭적으로 절감할 수 있도록 한다. 아울러, 실 시예에서 제공하는 멀티 플랫폼으로 소형 사물인터넷 기기부터 대형 서버까지 인공지능 기능 지원이 가능하도록 한다. 아울러, 인공지능 프로그램에 대한 코딩 지식 없이도, API(Application Programming Interface) 방식으 로 인공지능 기능을 구현 할 수 있도록 한다. 도 3은 실시예에 따른 인공지능 실행 가속 서버의 데이터 처리 블록을 나타낸 도면이고, 도 4는 실시예에 따른 인공지능 실행가속시스템에 포함된 각 구성의 기능을 설명하기 위한 도면이다. 도 3 및 4를 참조하면, 실시예에 따른 인공지능 실행가속 서버는 실행가중치 추출모듈, 가속 실행파 일 설정모듈, 최적화 모듈 및 실행가속모듈을 포함하여 구성될 수 있다. 본 명세서에서 사용되 는 '모듈' 이라는 용어는 용어가 사용된 문맥에 따라서, 소프트웨어, 하드웨어 또는 그 조합을 포함할 수 있는 것으로 해석되어야 한다. 예를 들어, 소프트웨어는 기계어, 펌웨어(firmware), 임베디드코드(embedded code), 및 애플리케이션 소프트웨어일 수 있다. 또 다른 예로, 하드웨어는 회로, 프로세서, 컴퓨터, 집적 회로, 집적회로 코어, 센서, 멤스(MEMS; Micro-Electro-Mechanical System), 수동 디바이스, 또는 그 조합일 수 있다. 먼저, 인공지능 학습 서버는 클라우드 서버로서 머신러닝, 딥러닝 등 인공지능 수행에 필요한 학습데이터를 수 집한다. 이후 학습데이터로부터 특징을 추출하기 위해 학습 데이터 차원 별로 가중치 값을 산출하고, 산출된 웨 이트 값들을 누산하여 데이터 패턴을 학습한다. 외부 인공지능 학습서버는 학습 결과로 가중치 파라미터 및 인 공지능 모델을 생성하게 된다. 실행가중치 추출모듈은 인공지능 학습 결과로 생성된 웨이트파일 및 인공지능모델을 포함하는 학습모델을 분석하여, 인공지능 실행 가속을 위한 인공지능 학습모델의 데이터 가중치를 산출한다. 실시예에서 가중치 값 (weight value)은 전자기기로 입력되는 실제 조건에 따른 제어 결과값의 조건 별 가중치 값이 될 수 있다. 가속실행파일 설정모듈은 인공지능 학습 결과로 생성된 가중치 파일 및 인공지능 모델을 포함하는 학습모 델을 산출하는 인공지능학습서버로부터 학습모델을 로딩 하고, 로딩된 학습모델을 가시화하여 인공지능 가속실 행 시스템에서 사용 가능한 커스텀레이어를 생성하고, 커스텀레이어의 최적화 여부를 판단한 후 실행모델을 산 출한다. 최적화 모듈은 커스텀레이어의 최적화 여부를 확인하고, 부가적인 최적화 과정이 불필요한 경우, 자동으로 최적화 과정을 수행한다. 실시예에서 최적화 과정은 콘켓(concat), 컨볼루션(convolution), 엑티베이션 (activation), RPN(Region Proposal Network), NMS(Non Maximum Suppression), 풀링(Pooling) 등을 포함하는 최적화 연산함수에 의해 수행될 수 있다. 커스텀레이어의 최적화가 완료되면 실행모델이 생성되고, 이후 최적화 모듈은 실행가중치 추출모듈로부터 전달받은 실행모델의 가중치 값을 실행모델에 적용한다. 실행가속모듈은 실행모델을 전달받아 실행모델에 대응되는 실행 환경을 구성하여 인공지능 실행속도를 가 속할 수 있도록 한다. 실시예에 따른 실행가속모듈은 종래 인공지능 소프트웨어에 학습기능과 실행기능이 결합된 것과는 달리, 학습기능을 제거하고 인공지능 실행기능만을 수행하도록 구성된다. 이를 통해, 인공지능 명령 처리 속도를 높이고, 메모리 사용량을 줄일 수 있다. 특히, 인공지능 실행모듈을 안드로이드, 라즈베리파 이 등 소형 IoT 기기에 설치하는 경우 종래 텐서플로(tensorflow), 카페(Caffe) 등과 같은 기계 학습용 엔진보 다 빠른 데이터 처리를 수행할 수 있도록 한다. 또한, 실행가속모듈은 실행모델의 실행단계 별 소요 메모리 할당량의 최적값을 산출하고, 병렬처리를 포함 하는 실행단계 별 완료 여부를 파악하여, 완료된 단계에서 다시 사용하지 않는 데이터를 삭제한 메모리 영역을 재사용하여 메모리 최적화를 구현할 수 있다. 구체적으로 실행가속모듈은 수많은 연산처리 과정 하나하나 의 완료여부를 파악하고, 데이터 처리가 완료된 단계에서 불필요한 데이터를 모두 삭제한다. 이때 각 단계에서 결과값으로 산출된 데이터만 남기고 결과값 산출에 이용된 데이터들은 다시는 사용되지 않는 불필요한 데이터로 간주되어 삭제될 수 있다. 실행가속모듈은 처리 완료된 단계에서 불필요한 데이터를 삭제한 후 생성된 스 페어 메모리 영역을 재 사용하도록 함으로써 인공지능 실행 가속모듈의 메모리를 최적화 할 수 있다. 이하, 실시예에 따른 인공지능 가속실행 시스템을 구성하는 각 모듈의 데이터 처리 과정을 보다 자세히 설명하 도록 한다. 도 5는 가속실행파일 설정모듈과 최적화 모듈의 데이터 처리과정을 나타낸 도면이다. S10 단계에서 가속실행파일 설정모듈은 외부의 인공지능 학습서버로부터 학습모델을 로딩한다. 학습모델은 외부학습서버에서 인공지능 학습 결과로 생성된 가중치 파일 및 인공지능 모델을 포함하는 데이터이다. S20 단계에서는 가속실행파일 설정모듈에서 학습모델구성을 가시화 한다. 예컨대, 학습모델구성 가시화 과 정은 인공지능 학습모델에 컨볼루션(convolution) 및 렐루(Relu)를 포함하는 연산함수를 이용하여 학습모델의 메타데이터를 가시화하고, 가시화된 학습모델을 커스텀레이어로 변환한 후, 변환된 커스텀레이어의 최적화 필요 여부를 판단하는 과정을 통해 수행될 수 있다. 또한, S20 단계에서는 가시화된 학습모델 파일을 RPN(Reverse Polish notation), NMS(Non Maximum Suppression), Pooling 등을 포함하는 모델설정 함수를 이용하여 인공지능 실행 가속기에서 사용 가능한 커스터마이징 레이어로 설정할 수 있다. S40 단계에서는 가속실행파일 설정모듈에서 커스텀레이어를 자동으로 최적화하여 실행모델을 산출한다. 실 시예에서 레이어 최적화 과정은 도 4에 도시된 실행모델 설정모듈의 모델 파트에 구성된 함수들의 조합하 여 구현할 수 있다. S50 단계에서는 실행가중치 추출모듈로부터 최적화된 가중치 파일을 로드하고 이를 실행모델에 적용한 후 최적화된 실행모델 및 가중치 파일을 압축저장 한다. S60 단계에서는 인공지능 기능이 다시 실행될 때, 기 저장된 실행모델을 로딩한다. S70 단계에서는 고속실행모 듈에서 최적화된 실행모델을 로딩하여 데이터 처리가능 하도록 하여 인공지능 기능을 가속화 할 수 있도록 한다. 도 6은 외부 학습 서버에서 일어나는 인공지능 학습과정에서 필요한 데이터 처리과정과 인공지능 실행 서버에서 수행되는 가속실행파일 설정모듈과 최적화 모듈의 데이터 처리과정을 나타낸 도면이다. 도 6에 도시된 딥러닝 학습단계에서의 데이터 처리과정은 인공지능 학습단계에서 구현되는 데이터 처리과정의 예로서, 인공지능 가속실행시스템 내에서 가동되는 것이 아니라 시스템 외부의 학습 서버에서 발생하는 데이터 처리과정이다. 시스템 외부의 학습 서버에서는 딥러닝 학습 기능이 시작되면, 인공지능 모델을 설계하여 인공지능 학습모델 파 일을 생성한다. 이후 입출력 데이터를 분석하고 초기 가중치를 설정하는 과정을 반복하여 입출력 데이터를 학습 시키고, 입출력 세부 데이터의 가중치의 최적값을 산출한다. S600 단계에서는 최적화된 가중치 파일을 추출하여 가중치 파일을 생성한다. 인공지능 가속 시스템에서는 외부 학습서버에서 생성된 학습모델파일과 가중치 파일을 이용하여 인공지능 실행 모델을 생성한다. 이하 도 6을 참조하여 인공지능 실행모델의 생성과정을 설명한다. 인공지능 가속 실행 서버가 시작되면, S610 단계에서는 실행가중치 추출모듈에서 외부 학습 서버로부터 학 습모델 및 가중치 파일을 포함하는 학습파일을 로딩한다. S620 단계에서는 학습모델의 메타데이터 분석 등을 통해 학습 모델을 가시화하고 로딩한 가중치 파일을 이용하 여 커스텀레이어를 설정한다. 이후, S630 단계에서는 커스텀레이어의 최적화 필요 여부를 파악한다. 예컨대, S630 단계에서는 커스터마이징 레이어의 접점, 중복최적화, GPU구현 가능성을 포함하는 최적화 조건을 산출하여 산출결과에 따라 커스텀레이어 의 최적화를 판단할 수 있다. 만일 커스텀레이어의 최적화 과정이 필요한 경우, 커스터마이징 레이어의 학습모델을 최적화 한 후 실행모델을 생성하여 저장한다. 실시예에 따른 최적화 과정은 학습모델의 형태 및 이용함수에 따라 달라질 수 있다. S640 단계에서는 최적화 과정 이후 최적화된 실행모델에 대응되는 실행환경을 구성한다. S630 단계에서 커스텀레이어의 최적화가 불필요한 것으로 판단되면 S640 단계로 진입하고, S650 단계에서는 커 스텀레이어가 최적화 완료된 실행모델을 이용하여 인공지능 기능을 고속실행 가능하도록 한다. 도 7내지 도 10은 실시예에 따른 커스텀레이어의 최적화 과정을 나타낸 도면이다. 도 7은 커스텀레이어의 모듈 연산 위치 및 순서를 조정하여 최적화 하는 예를 설명하기 위한 도면이다. 도 7에 도시된 바와 같이, 실시예에서는 커스텀레이어의 최적화 과정에서 연산함수 및 모듈 위치 및 순서를 조 정하여 레이어 최적화를 수행하여 실행모델을 생성할 수 있다. ReLU(Rectified Linear Unit)연산은 다차원 행렬의 입력 x의 요소 값 각각에 대하여 공식 ReLU = max(0, x)를 통해 계산된다. 이 계산은 다른 입력값과의 혼합을 통하지 않고 자체적으로 계산되는 Unary 연산이므로 병렬처 리가 가능하다. (병렬처리는 계산 과정에서 계산 유닛(Unit) 서로 간의 결과값에 대한 상호 참조 의존성이 없어 야 가능하다.) 가장왼쪽의 첫번째 그림에서 결국 하나로 합쳐져서 수행되는 구조로 되어 있는 ReLU가 있을 때, 도 7의 (b)와 같이 수행하면 3번으로 나뉘어진 ReLU 호출을 1번으로 줄 일수 있다. (a)와 같이 3번으로 나뉘어 져 있을 때에는 연산모듈이 이들 요소상호간의 병렬처리 가능성을 확신할 수 없어서 안전하게 계산하기 위해 3 번의 함수 호출을 Serial하게 3번 수행하지만, ReLU연산을 하나로 합쳐서 병렬성이 존재함을 명시적으로 알려주 면 3번의 호출이 동시에 수행되어 속도가 향상되도록 한다. 도 7의 (b)에서 ReLU연산은 3군데의 장소에 분리되어 배치된 메모리를 대상으로 수행된다. Concat은 3군데에 흩 어져 있는 메모리의 연산 대상 값들을 한군데로 모아주는 역할을 한다. 이를 통해, 연속 메모리에 존재하는 숫 자는 Cache의 접근방식과 동기화 되어 속도를 향상시킨다.도 8은 실시예에 따른 커스텀레이어의 최적화 과정 중 연산방식 수정을 통한 최적화 과정을 설명하기 위한 도면 이다. 도 8에 도시된 예는 기존 여러 단계 연산방식을 한 단계로 수정하기 위한, 커스텀 연산자의 플러그인 (Plugin)을 이용하는 예로서, 도 8의 (a)는 크기 8x8 행렬에서 짝수항만을 선택하는 이븐 셀렉트(Even Selection) 연산을 나타낸 것이다. 인공지능에서 짝수 항 선택연산을 구현하는 방식은 평균 풀링(Average Pooling) 함수의 파라미터로 Kernel Size=1x1로하고, Stride Size=2x2하여 수행한다. 간단히 AvgPool 1x1/2 로 표현한다. 도 8의 (b)는 홀수 항을 뽑아내는 OddSelection 연산을 표현한 것이다. 이걸 전통적인 인공지능 연산방식을 사 용하여 구현하는 방법은 위의 두 번째 그림에서 (1,1)~(7,7) 부분을 크롭(Crop)하여 잘라내고, 세 번째 그림의"}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "붉은색 부분을 패딩(Padding)한 다음 AvgPool 1x1/2 연산을 수행하는 것이다. 순서를 요약하면, OddSelection = Crop + Padding + AvgPool 1x1/2 의 3단계로 구현된다. 3단계 연산처리를 2번째 그림에서 보이는 것처럼 직 접 OddSelection의 1단계처리로 구현하여 속도를 향상시킬 수 있다. 도 9는 실시예에 따른 가중치 파일 추출과정을 나타낸 도면이다. 도 9를 참조하면, 실행가중치 추출모듈은 S601 단계에서 먼저 외부 학습서버의 학습모델 가중치를 추출한 다. S603 단계에서는 추출된 학습모델의 가중치를 인공지능 가속실행모듈에 최적화된 가중치로 변환하고, S605 단계 에서는 인공지능 가속실행모듈에 최적화된 가중치 파일을 저장한다. 도 10은 실시예에 따른 실행모델의 고속실행 과정을 나타낸 도면이다. 실시예에서는 인공지능 실행모델의 고속실행을 위해, S651 단계에서는 실행가속모듈에서 실행모델에 알맞 은 실행 환경을 구성한다. 이후, S653 단계에서는 실행가속모듈의 메모리 최적화 과정을 수행하고, S655 단계에서는 CPU와 GPU 간 처리 최적화를 수행한다. S657 단계에서는 실행가속모듈에서 인공지능 실행모델의 고속 실행을 구현한다. 도 11은 실시예에 따른 인공지능 실행모델 설정모듈의 함수 블록을 나타낸 도면이다. 도 11에 도시된 바와 같이, 인공지능 모델은 어느 정도 표준화된 컨볼루션(Convolution), 렐루(ReLU), Batch Normalization, Concat, Pooling등의 연산자를 레고블럭방식으로 조립하여 구성하게 된다. 그러나, 실제 구현되 는 인공지능 모델은 레고블럭방식의 연산자들 만으로는 부족하여 기존에 제공되지 않는 연산을 불가피하게 사용 하게 된다. 이렇게 추가되는 인공지능 커스텀 (Custom) 연산자는 속도가 빠르게 최적화된 연산자가 아닌 경우가 많다. 인공지능 연산은 병렬처리 속도가 빠른 GPU를 이용해야 하는데, 기본 연산 외에 추가되는 인공지능 연산 자는 CPU를 이용한 방식으로 구현되어 있는 경우가 대부분이다. 산업 현장적용을 위해서는 표준과 다른 연산자 를 사용할 필요가 있는데, 비 표준의 연산자는 산업현장에서 직접 구현하여 사용하여야 한다. 이들을 Custom 연 산자 Plugin이라고 하고, Custom 연산자 Plugin을 동작시키는 방식은 아래의 3가지가 있다. 도 12는 실시예에 따른 커스텀 (Custom) 연산자의 플러그인(Plugin) 사용기능을 설명하기 위한 도면이다. 도 12를 참조하면, (a)에 도시된 방식은 Custom Plugin을 CPU에서 동작시키는 방식인데, CPU와 GPU간의 통신 시 간이 필요하고 GPU보다 느린 CPU로 구현되어 있어 속도에 많은 손해가 발생한다. 도 12의 (b)에 도시된 방식은 연산기능자체는 GPU에 구현되어 있으나 CPU가 제어를 총괄하고 있어서 CPU와 GPU 간의 통신시간이 많이 필요한 경우이다. 역시 속도에 있어서 손해가 발생한다. 도 12의 (c)에 도시된 방식이 실시예에 따른 인공지능 가속모듈에서 구현하는 속도 최적화된 방식이다. CPU는 작업의 시작과 종료만을 제어하고, 나머지 연산은 GPU에서 비 동기화 (Async) 방식으로 일괄 처리된다. 커스텀 (Custom) 연산자를 사용하기 위해 CPU와 제어신호 통신 시간이 불필요하고, 커스텀 연산자도 GPU로 구현되어 있 다. 즉, 실시예에 따른 인공지능 실행가속모듈은 기존에 GPU로 구현되지 않은 연산자를 GPU방식을 사용하여 속 도향상을 이루고, 이렇게 구현된 연산자를 사용할 때 기존GPU연산자들 사이에 삽입되어 CPU의 통제를 받지 않고 GPU내부에서 CPU와 비 동기화 방식으로 수행하도록 하여 속도향상을 이룬다. 도 13은 실시예에 따른 메모리 최적화 과정을 설명하기 위한 인공지능 학습 진행 과정을 나타낸 도면이다. 도 13을 참조하면, 실시예에서 수행하는 메모리최적화 과정을 통해 인공지능 실행 가속 모듈의 메모리를 절약 하도록 한다. 도 13에 도시된 인공지능의 학습에서 있어서 핵심 절차라고 할 수 있는 역전이(BackPropagation) 를 수행하기 위해서 각 레이어의 연산결과를 저장하고 있어야 한다. 역전이(BackPropagation)작업이 완료되면 해당메모리는 재 사용 가능한 상태가 된다. 그러나, 실행단계에서 필요한 메모리는 아래에 기술하는 바와 같이 훨씬 적은 메모리를 사용할 수 있고, 그 소요량은 유동적일 수 있다. 도 13의 (a) 그림은 학습에 필요한 메모리 용량을 나타낸 것이다. 총 Memory1 + Memory2 + Memory3 의 용량이 필요하다. (b)는 실행단계에 필요한 메모리를 나타낸 것이다. 레이어가 실행되면 이전에 사용하던 메모리는 더 이상 용도 가 없어지므로 다음 레이어에서 재사용할 수 있다. 이러한 특징을 전체 인공지능 모델에 적용하여 최대로 필요 한 메모리를 미리 계산해서 메모리 풀(Memory Pool)형식으로 운영하면 메모리 소요량을 대폭 줄일 수 있다. (C)는 메모리 풀(Memory Pool)에 필요한 소요량을 계산하는 것을 표현하고 있다. 인공지능 실행단계에서 사용하 는 메모리는 GPU메모리인데, GPU의 실행은 CPU와 독립적으로 비동기(Async)로 동작하게 되므로, 일단 GPU로 제 어가 넘어가게 되면 메모리가 언제 사용되고 언제 사용용도가 없어지는 지를 CPU에서 판단할 수 없다. 그래서 GPU에서 사용하는 메모리에 대한 소요 스케쥴링을 GPU로 제어가 넘어가기 전에 미리 정해야 한다. (c)에 표시된 이러한 메모리 사용 스케쥴링을 보면, 각 레이어 별로 최대 메모리 사용량을 추출한다. 레이어1과 레이어4는 기 대되는 메모리 사용량을 그대로 추출하고, 레이어2와 레이어3는 병렬로 처리될 수 있으므로 각각의 사용량을 총 합(Sum)하여 추출한다. 실시예에서는 이렇게 추출한 각 레이어의 메모리 사용량 중에서 최대값을 본 인공지능 모델에서 필요로 하는 최대메모리로 산출하고, 실행단계에서 사용한다. 이러한 산출 및 사용 절차는 시스템에서 자동으로 이루어 질 수 있다. 이상에서와 같은 인공지능 실행가속 시스템은 인공지능의 학습기능과 실행기능을 분리함으로써, 소요되는 메모 리와 하드웨어 자원(CPU 및 GPU)의 소요량을 절감함으로써 인공지능 모델의 실행을 위한 서버 비용을 절감하고, 처리 성능을 향상시킬 수 있으며, 저 사양의 에지 단 장치에서도 인공지능 모델을 실행할 수 있게 되어 인터넷 이 불가능한 상황에서도 인공지능을 이용한 서비스를 제공할 수 있도록 한다. 실시예를 통해 고가의 서버에서 실행해야 하는 인공지능 모델을 PC급 기기에서 실행할 수 있으며, 인공지능 모 델을 소형의 IoT 기기에서도 빠르게 작은 메모리로 실행 할 수 있도록 한다. 또한, 설정방식으로 인공지능 모델을 탑재하고, 미리 학습된 웨이트 파일을 에지 단말 엔진에 로딩하여 실행하 는 방식으로 사용하므로, 인공지능을 알지 못하는 일반 개발자들도 인공지능을 이용하는 프로그램을 만들 수 있 도록 한다."}
{"patent_id": "10-2018-0136437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "개시된 내용은 예시에 불과하며, 특허청구범위에서 청구하는 청구의 요지를 벗어나지 않고 당해 기술분야에서 통상의 지식을 가진 자에 의하여 다양하게 변경 실시될 수 있으므로, 개시된 내용의 보호범위는 상술한 특정의 실시예에 한정되지 않는다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13"}
{"patent_id": "10-2018-0136437", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래 인공지능 서비스 구조와 실시예에 따른 인공지능 실행가속 시스템 구조를 비교한 도면 도 2는 종래 인공지능 시스템과 실시예에 따른 인공지능 실행 가속 시스템의 기능 비교를 위한 도면 도 3은 실시예에 따른 인공지능 실행 가속 서버의 데이터 처리 블록을 나타낸 도면 도 4는 실시예에 따른 인공지능 실행가속시스템에 포함된 각 구성의 기능을 설명하기 위한 도면 도 5는 가속실행파일 설정모듈과 최적화 모듈의 데이터 처리과정을 나타낸 도면 도 6은 외부 학습 서버에서 일어나는 인공지능 학습과정에서 필요한 데이터 처리과정과 인공지능 실행 서버에서 수행되는 가속실행파일 설정모듈과 최적화 모듈의 데이터 처리과정을 나타낸 도면 도 7은 실시예에 따른 커스텀레이어의 최적화 과정을 나타낸 도면 도 8은 실시예에 따른 커스텀레이어의 최적화 과정 중 연산방식 수정을 통한 최적화 과정을 설명하기 위한 도면 도 9는 실시예에 따른 가중치 파일 추출과정을 나타낸 도면 도 10은 실시예에 따른 실행모델의 고속실행 과정을 나타낸 도면 도 11은 실시예에 따른 인공지능 실행모델 설정모듈의 함수 블록을 나타낸 도면 도 12는 실시예에 따른 커스텀 (Custom) 연산자의 플러그인(Plugin) 사용기능을 설명하기 위한 도면 도 13은 실시예에 따른 메모리 최적화 과정을 설명하기 위한 인공지능 학습 진행 과정을 나타낸 도면"}
