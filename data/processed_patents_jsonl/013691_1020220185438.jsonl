{"patent_id": "10-2022-0185438", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0054134", "출원번호": "10-2022-0185438", "발명의 명칭": "이미지 센서의 이미지를 이용한 학습 기반 화질 개선 방법 및 이를 지원하는 전자 장치", "출원인": "삼성전자주식회사", "발명자": "한대중"}}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서, 디스플레이 모듈;통신 회로;복수개의 카메라들을 포함하는 카메라 모듈; 및상기 디스플레이 모듈, 상기 통신 회로 및 상기 카메라 모듈과 작동적으로 연결된 프로세서를 포함하고, 상기프로세서는,상기 카메라 모듈을 통해 이미지 데이터를 획득하고, 상기 이미지 데이터에 기반하여 비닝(Binning) 처리를 수행하고, 상기 이미지 데이터를 상기 통신 회로를 통해서버로 전송하고, 상기 비닝 처리에 기반하여 비닝 이미지를 획득하고, 상기 비닝 이미지에 기반하여 학습 데이터를 획득하고, 상기 서버로부터 상기 이미지 데이터를 기반으로 생성된 실측 데이터를 획득하고, 상기 학습 데이터와 상기 실측 데이터에 기반하여 줌 배율에 대한 학습을 수행하고, 및 상기 줌 배율에 대응하는 파라미터를 생성하여 매핑하도록 설정된 전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 복수개의 카메라들은, 제1 배율의 메인 카메라 및 상기 메인 카메라의 출력을 위한 이미지 센서; 및상기 제1 배율보다 큰 제2 배율의 적어도 하나의 줌 카메라 및 상기 적어도 하나의 줌 카메라의 출력을 위한 멀티 픽셀 센서(MPS, multi pixel sensor)를 포함하는 전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 이미지 데이터는 넌-베이어(non-Bayer) 이미지를 포함하고,상기 학습 데이터는 상기 넌-베이어 이미지에 기반하여 저해상도 베이어로 변환된 상기 비닝 이미지가 영상 처리된 데이터를 포함하고,상기 실측 데이터는 상기 서버에 의해 상기 넌-베이어 이미지에 기반하여 고해상도 베이어로 변환된 리모자익(Remosaic) 이미지를 포함하는 전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 하나의 항에 있어서, 상기 프로세서는, 사용자 입력에 기반하여 학습 동작과 관련된 어플리케이션을 실행하고, 공개특허 10-2024-0054134-3-상기 어플리케이션 실행에 기반하여 상기 복수개의 카메라들 중 지정된 배율의 줌 카메라를 실행하고,상기 줌 카메라의 멀티 픽셀 센서로부터 상기 이미지 데이터를 획득하도록 설정된 전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제3항 중 어느 하나의 항에 있어서, 상기 프로세서는, 상기 멀티 픽셀 센서에서 출력된 넌-베이어 이미지에 대해 비닝 처리를 통해 픽셀 평균 머지(pixel averagemerge)를 수행하고,상기 비닝 처리 동작에 병렬적으로, 상기 넌-베이어 이미지를, 상기 통신 회로를 통해, 상기 서버로 전송하도록설정된 전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제3항 중 어느 하나의 항에 있어서, 상기 프로세서는 뉴럴 네트워크(neural network)를 포함하고,상기 뉴럴 네트워크를 이용하여, 상기 학습 데이터와 상기 실측 데이터에 기반하여 상기 줌 배율에 대한 학습을수행하도록 설정된 전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 프로세서는,지정된 줌 모드에서 동일한 입력으로부터 생성된 상기 학습 데이터와 상기 실측 데이터의 페어(pair)를 이용하여, 상기 뉴럴 네트워크를 통해, 딥-러닝(deep-learning) 기반의 학습을 수행하도록 설정된 전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제3항 중 어느 하나의 항에 있어서, 상기 프로세서는,학습 결과에 따라 뉴럴 네트워크가 지정된 줌 모드에서 사용할 파라미터를 생성하고,상기 파라미터를 지정된 줌 모드의 줌 배율에 매핑하여, 줌 배율 별 파라미터를 룩업 테이블로 관리하도록 설정된 전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 프로세서는,사용자 입력에 기반하여 영상 촬영과 관련된 어플리케이션을 실행하고,상기 어플리케이션 실행에 기반하여, 영상 촬영을 수행하는 동안, 줌 실행을 위한 사용자 입력을 수신하고,상기 사용자 입력에 기반하여 상기 복수개의 카메라들 중 지정된 배율의 줌 카메라를 실행하고, 상기 줌 카메라의 멀티 픽셀 센서로부터 이미지 데이터를 획득하도록 설정된 전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 프로세서는,공개특허 10-2024-0054134-4-상기 이미지 데이터에 기반하여 비닝 처리를 수행하고,상기 비닝 처리에 기반하여 비닝 이미지를 획득하고,상기 비닝 이미지에 기반하여 결과 데이터를 획득하고,상기 사용자 입력에 기반한 줌 배율이 제1 배율에 해당하는 경우, 상기 결과 데이터를 줌 배율에 대응하여 제1줌 처리하고,상기 사용자 입력에 기반한 줌 배율이 상기 제1 배율보다 큰 제2 배율에 해당하는 경우, 상기 제2 배율에 대응하는 파라미터에 기반하여 상기 결과 데이터를 제2 줌 처리하도록 설정된 전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항 또는 제10항에 있어서, 상기 프로세서는,상기 제2 배율에 대해, 대응하는 학습 데이터에 기반하여 뉴럴 네트워크에서 사용할 파라미터를 결정하고,상기 제2 배율에 설정된 파라미터를 상기 결정된 파라미터로 변경하고,변경된 파라미터에 따른 줌 배율에 따라 상기 결과 데이터를 디지털 크롭 후 업스케일하여 출력하도록 설정된전자 장치."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "전자 장치의 동작 방법에 있어서, 상기 전자 장치의 카메라 모듈을 통해 이미지 데이터를 획득하는 동작; 상기 이미지 데이터에 기반하여 비닝(Binning) 처리를 수행하고, 상기 이미지 데이터를 통신 회로를 통해 서버로 전송하는 동작; 상기 비닝 처리에 기반하여 비닝 이미지를 획득하는 동작; 상기 비닝 이미지에 기반하여 학습 데이터를 획득하는 동작; 상기 서버로부터 상기 이미지 데이터를 기반으로 생성된 실측 데이터를 획득하는 동작; 상기 학습 데이터와 상기 실측 데이터에 기반하여 줌 배율에 대한 학습을 수행하는 동작; 및 상기 줌 배율에 대응하는 파라미터를 생성하여 매핑하는 동작을 포함하는 방법."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 이미지 데이터는 넌-베이어(non-Bayer) 이미지를 포함하고,상기 학습 데이터는 상기 넌-베이어 이미지에 기반하여 저해상도 베이어로 변환된 상기 비닝 이미지가 영상 처리된 데이터를 포함하고,상기 실측 데이터는 상기 서버에 의해 상기 넌-베이어 이미지에 기반하여 고해상도 베이어로 변환된 리모자익(Remosaic) 이미지를 포함하는 방법."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 이미지 데이터를 획득하는 동작은,사용자 입력에 기반하여 학습 동작과 관련된 어플리케이션을 실행하는 동작, 공개특허 10-2024-0054134-5-상기 어플리케이션 실행에 기반하여 상기 복수개의 카메라들 중 지정된 배율의 줌 카메라를 실행하는 동작,상기 줌 카메라의 멀티 픽셀 센서(MPS, multi pixel sensor)로부터 상기 이미지 데이터를 획득하는 동작을 포함하는 방법."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항 내지 제14항 중 어느 하나의 항에 있어서, 상기 비닝 처리 및 상기 전송하는 동작은,상기 멀티 픽셀 센서에서 출력된 넌-베이어 이미지에 대해 비닝 처리를 통해 픽셀 평균 머지(pixel averagemerge)를 수행하는 동작,상기 비닝 처리 동작에 병렬적으로, 상기 넌-베이어 이미지를, 상기 통신 회로를 통해, 상기 서버로 전송하는동작을 포함하는 방법."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항 내지 제14항 중 어느 하나의 항에 있어서, 상기 학습을 수행하는 동작은,뉴럴 네트워크(neural network)를 이용하여, 상기 학습 데이터와 상기 실측 데이터에 기반하여 상기 줌 배율에대한 학습을 수행하는 동작을 포함하는 방법."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 학습을 수행하는 동작은,지정된 줌 모드에서 동일한 입력으로부터 생성된 상기 학습 데이터와 상기 실측 데이터의 페어(pair)를 이용하여, 상기 뉴럴 네트워크를 통해, 딥-러닝(deep-learning) 기반의 학습을 수행하는 동작을 포함하는 방법."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항 내지 제14항 중 어느 하나의 항에 있어서, 상기 매핑하는 동작은,학습 결과에 따라 뉴럴 네트워크가 지정된 줌 모드에서 사용할 파라미터를 생성하는 동작,상기 파라미터를 지정된 줌 모드의 줌 배율에 매핑하여, 줌 배율 별 파라미터를 룩업 테이블로 관리하는 동작을포함하는 방법."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서, 사용자 입력에 기반하여 영상 촬영과 관련된 어플리케이션을 실행하는 동작,상기 어플리케이션 실행에 기반하여, 영상 촬영을 수행하는 동안, 줌 실행을 위한 사용자 입력을 수신하는동작,상기 사용자 입력에 기반하여 상기 복수개의 카메라들 중 지정된 배율의 줌 카메라를 실행하는 동작, 상기 줌 카메라의 멀티 픽셀 센서로부터 이미지 데이터를 획득하는 동작,상기 이미지 데이터에 기반하여 비닝 처리를 수행하는 동작,상기 비닝 처리에 기반하여 비닝 이미지를 획득하는 동작,상기 비닝 이미지에 기반하여 결과 데이터를 획득하는 동작,공개특허 10-2024-0054134-6-상기 사용자 입력에 기반한 줌 배율이 제1 배율에 해당하는 경우, 상기 결과 데이터를 줌 배율에 대응하여 제1줌 처리하는 동작,상기 사용자 입력에 기반한 줌 배율이 상기 제1 배율보다 큰 제2 배율에 해당하는 경우, 상기 제2 배율에 대응하는 파라미터에 기반하여 상기 결과 데이터를 제2 줌 처리하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2022-0185438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 제2 줌 처리하는 동작은,상기 제2 배율에 대해, 대응하는 학습 데이터에 기반하여 뉴럴 네트워크에서 사용할 파라미터를 결정하는 동작,상기 제2 배율에 설정된 파라미터를 상기 결정된 파라미터로 변경하는 동작,변경된 파라미터에 따른 줌 배율에 따라 상기 결과 데이터를 디지털 크롭 후 업스케일하여 출력하는 동작을 포함하는 방법."}
{"patent_id": "10-2022-0185438", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 다양한 실시예들은 이미지 센서(image sensor)의 이미지를 이용한 학습 기반 화질 개선을 지원할 수 있는 방법 및 이를 지원하는 전자 장치를 제공한다. 본 개시의 일 실시예에 따른 전자 장치는, 디스플레이 모듈, 통신 회로, 복수개의 카메라들을 포함하는 카메라 모듈, 및 프로세서를 포함할 수 있다. 일 실시예에 따른 상기 (뒷면에 계속)"}
{"patent_id": "10-2022-0185438", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 실시예는 이미지 센서(image sensor)의 이미지를 이용한 학습 기반 화질 개선을 지원할 수 있는 방법 및 이를 지원하는 전자 장치를 제공한다."}
{"patent_id": "10-2022-0185438", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "디지털 기술의 발달과 함께 스마트 폰(smart phone), 디지털 카메라(digital camera), 및/또는 웨어러블 장치 (wearable device)와 같은 다양한 유형의 전자 장치가 널리 사용되고 있다. 이러한, 전자 장치는 기능 지지 및 증대를 위해, 전자 장치의 하드웨어적인 부분 및/또는 소프트웨어적인 부분이 지속적으로 개발되고 있다. 최근에는 전자 장치를 이용한 영상 촬영 기능의 사용 증가에 따라, 전자 장치에서의 보다 고 성능 및 고화질의 영상 촬영 기능을 지원하기 위한 다양한 연구가 진행되고 있다. 일 실시예에 따르면, 전자 장치(예: 고 사양의 전자 장치)는 복수개의 카메라들(예: 메인(main) 카메라, 광각 카메라, 줌(zoom) 카메라)을 적용하여, 디지털 카메라(예: DSLR(digital single lens reflex) 카메라)의 렌즈 교환 방식의 카메라의 경험을 제공할 수 있다. 예를 들어, 전자 장치는 고정된 줌 배율(예: 약 x3배 또는 약 x10배)의 줌 카메라(예: 약 x1배 카메라와 다른 배율을 갖는 카메라)를 제공하여, 원경의 풍경 또는 피사체를 선명하게 촬영할 수 있다. 예를 들어, 전자 장치는 고 배율의 줌 기능을 제공하기 위해 복수개의 줌 카메라를 적용하여 카메라의 줌 성능을 향상하고 고 화질의 이미지를 제공할 수 있다. 일 실시예에 따르면, 전자 장치(예: 일반 사양의 전자 장치)는 영상 처리를 통한 줌 기능을 제공할 수 있다. 예 를 들어, 이미지 센서의 출력(예: 이미지)에 대해 원하는 줌 배율에 따른 ROI(region of image) 영역을 크롭 (crop) 후 영상 처리(예: 업스케일(upscale) 처리)를 통해 줌 카메라와 같은 이미지를 획득할 수 있다. 이러한 줌 기능을 디지털 크롭(digital crop) 줌이라 할 수 있다. 다만, 디지털 크롭 기반 줌 기능으로 획득하는 이미 지는 픽셀(pixel) 간 보간(interpolation)에 의한 화질 열화가 발생할 수 있다. 최근 전자 장치는 줌 카메라 기반 줌 기능과 디지털 크롭 기반 줌 기능을 함께 적용하고 있다. 예를 들어, 전자 장치는 하이브리드(hybrid) 줌 구조(예: 옵티컬-디지털 크롭(optical-digital crop) 줌 구조)를 적용하여 줌 성 능을 보다 향상하고 보다 고 화질의 이미지를 제공할 수 있다. 예를 들어, 전자 장치의 카메라는 고정된 배율의 옵티컬 렌즈(optical lens) 설계를 가지는 구조일 수 있으며, 설계된 배율 외에는 물리적으로 다른 배율의 줌 이미지를 획득할 수 없다. 따라서, 전자 장치는 카메라(예: 줌 카메라)를 통해 획득된 이미지에 디지털 크롭으 로 고정된 배율 이상의 이미지를 획득하도록 할 수 있다. 이와 같이, 전자 장치는 하이브리드 줌 구조를 통해 고 배율 줌 기능을 제공할 수 있다. 하지만, 최근에는 사용 자의 보다 고 배율의 줌 성능과 이미지의 화질 개선에 대한 니즈(needs)가 증가하고 있고, 사용자의 니즈를 충 족하기 위한 영상 처리 기술에 대한 다양한 연구가 진행 중에 있다. 상술한 정보는 본 개시에 대한 이해를 돕기 위한 목적으로 하는 배경 기술(related art)로 제공될 수 있다. 상 술한 내용 중 어느 것도 본 개시와 관련된 종래 기술(prior art)로서 적용될 수 있는지에 대하여 어떠한 주장이 나 결정이 제기되지 않는다. 본 개시의 일 실시예에서는, 이미지 센서(image sensor)의 이미지를 이용한 학습 기반 화질 개선을 지원할 수 있는 방법 및 이를 지원하는 전자 장치를 제공한다. 본 개시의 일 실시예에서는, 이미지 센서(예: MPS, multi pixel sensor)의 저해상도 및 고해상도 이미지를 이용 하여 딥-러닝(deep-learning) 기반 줌 이미지의 화질 개선 방법 및 이를 지원하는 전자 장치를 제공한다. 본 개시의 일 실시예에서는, 하이브리드(hybrid) 줌 구조(예: 옵티컬-디지털 크롭(optical-digital crop) 줌 구 조)에서 멀티 픽셀 센서(MPS)의 비닝(binning) 출력 및 리모자익(remosaic) 출력을 이용하여 초고해상도(SR, super resolution) 딥-러닝 기반의 학습을 통해 학습하고, 학습된 데이터(예: 학습 데이터)를 전자 장치에 적용 하여, 전자 장치에서의 줌 이미지의 화질 개선을 지원할 수 있는 방법 및 장치를 제공한다. 본 문서에서 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2022-0185438", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다. 본 개시의 일 실시예에 따른 전자 장치는, 디스플레이 모듈, 통신 회로, 복수개의 카메라들을 포함하는 카메라 모듈, 및 상기 디스플레이 모듈, 상기 통신 회로 및 상기 카메라 모듈과 작동적으로 연결된 프로세서를 포함할 수 있다. 일 실시예에 따른 상기 프로세서는, 상기 카메라 모듈을 통해 이미지 데이터를 획득하도록 동작할 수 있다. 일 실시예에 따른 상기 프로세서는, 상기 이미지 데이터에 기반하여 비닝(Binning) 처리를 수행하고, 상 기 이미지 데이터를 상기 통신 회로를 통해 서버로 전송하도록 동작할 수 있다. 일 실시예에 따른 상기 프로세 서는, 상기 비닝 처리에 기반하여 비닝 이미지를 획득하도록 동작할 수 있다. 일 실시예에 따른 상기 프로세서 는, 상기 비닝 이미지에 기반하여 학습 데이터를 획득하도록 동작할 수 있다. 일 실시예에 따른 상기 프로세서 는, 상기 서버로부터 상기 이미지 데이터를 기반으로 생성된 실측 데이터를 획득하도록 동작할 수 있다. 일 실 시예에 따른 상기 프로세서는, 상기 학습 데이터와 상기 실측 데이터에 기반하여 줌 배율에 대한 학습을 수행하 도록 동작할 수 있다. 일 실시예에 따른 상기 프로세서는, 상기 줌 배율에 대응하는 파라미터를 생성하여 매핑 하도록 동작할 수 있다. 본 개시의 일 실시예에 따른 전자 장치의 동작 방법은, 상기 전자 장치의 카메라 모듈을 통해 이미지 데이터를 획득하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 이미지 데이터에 기반하여 비닝(Binning) 처리 를 수행하고, 상기 이미지 데이터를 통신 회로를 통해 서버로 전송하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 비닝 처리에 기반하여 비닝 이미지를 획득하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 비닝 이미지에 기반하여 학습 데이터를 획득하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 서 버로부터 상기 이미지 데이터를 기반으로 생성된 실측 데이터를 획득하는 동작 수행을 포함할 수 있다. 상기 동 작 방법은, 상기 학습 데이터와 상기 실측 데이터에 기반하여 줌 배율에 대한 학습을 수행하는 동작 수행을 포 함할 수 있다. 상기 동작 방법은, 상기 줌 배율에 대응하는 파라미터를 생성하여 매핑하는 동작 수행을 포함할 수 있다. 상기와 같은 과제를 해결하기 위하여 본 개시의 다양한 실시예들에서는, 상기 방법을 프로세서에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 판독 가능한 기록 매체를 포함할 수 있다. 일 실시예에 따르면, 하나 이상의 프로그램들을 저장하는 비 일실적(non-transitory) 컴퓨터 판독 가능 저장 매 체(또는 컴퓨터 프로그램 프로덕트(product))가 기술된다. 일 실시예에 따르면, 하나 이상의 프로그램들은, 전 자 장치의 프로세서에 의해 실행될 시, 상기 전자 장치의 카메라 모듈을 통해 이미지 데이터를 획득하는 동작, 상기 이미지 데이터에 기반하여 비닝(Binning) 처리를 수행하고, 상기 이미지 데이터를 통신 회로를 통해 서버 로 전송하는 동작, 상기 비닝 처리에 기반하여 비닝 이미지를 획득하는 동작, 상기 비닝 이미지에 기반하여 학 습 데이터를 획득하는 동작, 상기 서버로부터 상기 이미지 데이터를 기반으로 생성된 실측 데이터를 획득하는 동작, 상기 학습 데이터와 상기 실측 데이터에 기반하여 줌 배율에 대한 학습을 수행하는 동작, 및 상기 줌 배 율에 대응하는 파라미터를 생성하여 매핑하는 동작을 수행하는 명령어를 포함할 수 있다. 본 개시의 적용 가능성의 추가적인 범위는 이하의 상세한 설명으로부터 명백해질 것이다. 그러나 본 개시의 사 상 및 범위 내에서 다양한 변경 및 수정은 당업자에게 명확하게 이해될 수 있으므로, 상세한 설명 및 본 개시의바람직한 실시예와 같은 특정 실시예는 단지 예시로 주어진 것으로 이해되어야 한다. 본 개시의 일 실시예에 따른 전자 장치, 그 동작 방법 및 기록 매체에 따르면, 고 사양 및 일반 사양의 전자 장 치 모두에서 적용 가능한 줌 기능 및 줌 이미지의 화질 개선 방법을 제공할 수 있다. 일 실시예에 따르면, 전자 장치에서 하이브리드 줌 지원 시에, 미리 학습된 학습 데이터에 기반한 해상도 조절을 통해 고 해상력을 구현할 수 있다. 일 실시예에 따르면, 전자 장치는 카메라(예: 줌 카메라)를 통해 획득된 줌 이미지에 대해, 줌 이미지 에 대응하는 학습 데이터를 이용하여, 디지털 크롭을 수행하여 줌 카메라의 고정된 배율 이상의 이미지를 획득 할 수 있도록 지원할 수 있다. 이를 통해, 줌 카메라의 이미지 화질 개선을 지원할 수 있다. 일 실시예에 따르 면, 멀티 픽셀 센서(MPS, multi pixel sensor)의 저해상도 및 고해상도 이미지를 이용하여 줌 이미지에 대한 화 질을 개선하고, 사용자의 줌 기능 사용 시나리오에서 고 배율의 줌 성능과 이미지의 화질 개선에 대한 니즈 (needs)를 충족할 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부 터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0185438", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 다양한 실시예들에 따른 네트워크 환경 내의 전자 장치의 블록도이다. 도 1을 참조하면, 네트워크 환경에서 전자 장치는 제1 네트워크(예: 근거리 무선 통신 네트워크)를 통하여 전자 장치와 통신하거나, 또는 제2 네트워크(예: 원거리 무선 통신 네트워크)를 통하여 전자 장치 또는 서버 중 적어도 하나와 통신할 수 있다. 일 실시예에 따르면, 전자 장치(10 1)는 서버를 통하여 전자 장치와 통신할 수 있다. 일 실시예에 따르면, 전자 장치는 프로세서 , 메모리, 입력 모듈, 음향 출력 모듈, 디스플레이 모듈, 오디오 모듈, 센서 모듈, 인터페이스, 연결 단자, 햅틱 모듈, 카메라 모듈, 전력 관리 모듈, 배터 리, 통신 모듈, 가입자 식별 모듈, 또는 안테나 모듈을 포함할 수 있다. 어떤 실시예에서 는, 전자 장치에는, 이 구성요소들 중 적어도 하나(예: 연결 단자)가 생략되거나, 하나 이상의 다른 구성요소가 추가될 수 있다. 어떤 실시예에서는, 이 구성요소들 중 일부들(예: 센서 모듈, 카메라 모듈 , 또는 안테나 모듈)은 하나의 구성요소(예: 디스플레이 모듈)로 통합될 수 있다. 프로세서는, 예를 들면, 소프트웨어(예: 프로그램)를 실행하여 프로세서에 연결된 전자 장치 의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이 터 처리 또는 연산을 수행할 수 있다. 일 실시예에 따르면, 데이터 처리 또는 연산의 적어도 일부로서, 프로세 서는 다른 구성요소(예: 센서 모듈 또는 통신 모듈)로부터 수신된 명령 또는 데이터를 휘발성 메모리에 저장하고, 휘발성 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 비휘발성 메모리에 저장할 수 있다. 일 실시예에 따르면, 프로세서는 메인 프로세서(예: 중앙 처리 장치 (CPU, central processing unit) 또는 어플리케이션 프로세서(AP, application processor)) 또는 이와는 독립 적으로 또는 함께 운영 가능한 보조 프로세서(예: 그래픽 처리 장치(GPU, graphic processing unit), 신 경망 처리 장치(NPU, neural processing unit), 이미지 시그널 프로세서(ISP, image signal processor), 센서 허브 프로세서(sensor hub processor), 또는 커뮤니케이션 프로세서(CP, communication processor))를 포함할 수 있다. 예를 들어, 전자 장치가 메인 프로세서 및 보조 프로세서를 포함하는 경우, 보조 프로 세서는 메인 프로세서보다 저전력을 사용하거나, 지정된 기능에 특화되도록 설정될 수 있다. 보조 프 로세서는 메인 프로세서와 별개로, 또는 그 일부로서 구현될 수 있다. 보조 프로세서는, 예를 들면, 메인 프로세서가 인액티브(inactive)(예: 슬립(sleep)) 상태에 있는 동 안 메인 프로세서를 대신하여, 또는 메인 프로세서가 액티브(예: 어플리케이션 실행) 상태에 있는 동 안 메인 프로세서와 함께, 전자 장치의 구성요소들 중 적어도 하나의 구성요소(예: 디스플레이 모듈 , 센서 모듈, 또는 통신 모듈)와 관련된 기능 또는 상태들의 적어도 일부를 제어할 수 있다. 일 실시예에 따르면, 보조 프로세서(예: 이미지 시그널 프로세서 또는 커뮤니케이션 프로세서)는 기능적으로 관련 있는 다른 구성요소(예: 카메라 모듈 또는 통신 모듈)의 일부로서 구현될 수 있다. 일 실시예에 따르면, 보조 프로세서(예: 신경망 처리 장치)는 인공지능 모델의 처리에 특화된 하드웨어 구조를 포함할 수 있다. 인공지능 모델은 기계 학습을 통해 생성될 수 있다. 이러한 학습은, 예를 들어, 인공지능 모델이 수행 되는 전자 장치 자체에서 수행될 수 있고, 별도의 서버(예: 서버)를 통해 수행될 수도 있다. 학습 알 고리즘은, 예를 들어, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경 망(DNN: deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 하드웨어 구조 이외에, 추가적으로 또는 대체적으로, 소프트웨어 구조를 포 함할 수 있다. 메모리는, 전자 장치의 적어도 하나의 구성요소(예: 프로세서 또는 센서 모듈)에 의해 사 용되는 다양한 데이터를 저장할 수 있다. 데이터는, 예를 들어, 소프트웨어(예: 프로그램) 및, 이와 관련 된 명령에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있다. 메모리는, 휘발성 메모리 또는 비 휘발성 메모리를 포함할 수 있다. 프로그램은 메모리에 소프트웨어로서 저장될 수 있으며, 예를 들면, 운영 체제(OS, operating system), 미들 웨어(middleware) 또는 어플리케이션을 포함할 수 있다. 입력 모듈은, 전자 장치의 구성요소(예: 프로세서)에 사용될 명령 또는 데이터를 전자 장치 의 외부(예: 사용자)로부터 수신할 수 있다. 입력 모듈은, 예를 들면, 마이크, 마우스, 키보드, 키 (예: 버튼), 또는 디지털 펜(예: 스타일러스 펜)을 포함할 수 있다. 음향 출력 모듈은 음향 신호를 전자 장치의 외부로 출력할 수 있다. 음향 출력 모듈은, 예를 들 면, 스피커 또는 리시버를 포함할 수 있다. 스피커는 멀티미디어 재생 또는 녹음 재생과 같이 일반적인 용도로 사용될 수 있다. 리시버는 착신 전화를 수신하기 위해 사용될 수 있다. 일 실시예에 따르면, 리시버는 스피커와 별개로, 또는 그 일부로서 구현될 수 있다. 디스플레이 모듈은 전자 장치의 외부(예: 사용자)로 정보를 시각적으로 제공할 수 있다. 디스플레이 모듈은, 예를 들면, 디스플레이, 홀로그램 장치, 또는 프로젝터 및 해당 장치를 제어하기 위한 제어 회로 를 포함할 수 있다. 일 실시예에 따르면, 디스플레이 모듈은 터치를 감지하도록 설정된 터치 센서, 또는 상기 터치에 의해 발생되는 힘의 세기를 측정하도록 설정된 압력 센서를 포함할 수 있다. 오디오 모듈은 소리를 전기 신호로 변환시키거나, 반대로 전기 신호를 소리로 변환시킬 수 있다. 일 실시 예에 따르면, 오디오 모듈은, 입력 모듈을 통해 소리를 획득하거나, 음향 출력 모듈, 또는 전자장치와 직접 또는 무선으로 연결된 외부 전자 장치(예: 전자 장치)(예: 스피커 또는 헤드폰)를 통해 소리를 출력할 수 있다. 센서 모듈은 전자 장치의 작동 상태(예: 전력 또는 온도), 또는 외부의 환경 상태(예: 사용자 상태) 를 감지하고, 감지된 상태에 대응하는 전기 신호 또는 데이터 값을 생성할 수 있다. 일 실시예에 따르면, 센서 모듈은, 예를 들면, 제스처 센서, 자이로 센서, 기압 센서, 마그네틱 센서, 가속도 센서, 그립 센서, 근접 센서, 컬러 센서, IR(infrared) 센서, 생체 센서, 온도 센서, 습도 센서, 또는 조도 센서를 포함할 수 있다. 인터페이스는 전자 장치가 외부 전자 장치(예: 전자 장치)와 직접 또는 무선으로 연결되기 위해 사용될 수 있는 하나 이상의 지정된 프로토콜들을 지원할 수 있다. 일 실시예에 따르면, 인터페이스는, 예 를 들면, HDMI(high definition multimedia interface), USB(universal serial bus) 인터페이스, SD(secure digital) 카드 인터페이스, 또는 오디오 인터페이스를 포함할 수 있다. 연결 단자는, 그를 통해서 전자 장치가 외부 전자 장치(예: 전자 장치)와 물리적으로 연결될 수 있는 커넥터를 포함할 수 있다. 일 실시예에 따르면, 연결 단자는, 예를 들면, HDMI 커넥터, USB 커넥터, SD 카드 커넥터, 또는 오디오 커넥터(예: 헤드폰 커넥터)를 포함할 수 있다. 햅틱 모듈은 전기적 신호를 사용자가 촉각 또는 운동 감각을 통해서 인지할 수 있는 기계적인 자극(예: 진 동 또는 움직임) 또는 전기적인 자극으로 변환할 수 있다. 일 실시예에 따르면, 햅틱 모듈은, 예를 들면, 모터, 압전 소자, 또는 전기 자극 장치를 포함할 수 있다. 카메라 모듈은 정지 영상 및 동영상을 촬영할 수 있다. 일 실시예에 따르면, 카메라 모듈은 하나 이 상의 렌즈들, 이미지 센서들, 이미지 시그널 프로세서들, 또는 플래시들을 포함할 수 있다. 전력 관리 모듈은 전자 장치에 공급되는 전력을 관리할 수 있다. 일 실시예에 따르면, 전력 관리 모 듈은, 예를 들면, PMIC(power management integrated circuit)의 적어도 일부로서 구현될 수 있다. 배터리는 전자 장치의 적어도 하나의 구성요소에 전력을 공급할 수 있다. 일 실시예에 따르면, 배터 리는, 예를 들면, 재충전 불가능한 1차 전지, 재충전 가능한 2차 전지 또는 연료 전지를 포함할 수 있다. 통신 모듈은 전자 장치와 외부 전자 장치(예: 전자 장치, 전자 장치, 또는 서버) 간 의 직접(예: 유선) 통신 채널 또는 무선 통신 채널의 수립, 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 통신 모듈은 프로세서(예: 어플리케이션 프로세서)와 독립적으로 운영되고, 직접(예: 유선) 통 신 또는 무선 통신을 지원하는 하나 이상의 커뮤니케이션 프로세서를 포함할 수 있다. 일 실시예에 따르면, 통 신 모듈은 무선 통신 모듈(예: 셀룰러 통신 모듈, 근거리 무선 통신 모듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예: LAN(local area network) 통신 모듈, 또는 전력선 통신 모듈)을 포함할 수 있다. 이들 통신 모듈 중 해당하는 통신 모듈은 제1 네트워크(예: 블 루투스, WiFi(wireless fidelity) direct 또는 IrDA(infrared data association)와 같은 근거리 통신 네트워크) 또는 제2 네트워크(예: 레거시 셀룰러 네트워크, 5G 네트워크, 차세대 통신 네트워크, 인터넷, 또는 컴퓨터 네트워크(예: LAN 또는 WAN(wide area network))와 같은 원거리 통신 네트워크)를 통하여 외부의 전자 장치와 통신할 수 있다. 이런 여러 종류의 통신 모듈들은 하나의 구성요소(예: 단일 칩)로 통합되거 나, 또는 서로 별도의 복수의 구성요소들(예: 복수 칩들)로 구현될 수 있다. 무선 통신 모듈은 가입자 식 별 모듈에 저장된 가입자 정보(예: 국제 모바일 가입자 식별자(IMSI))를 이용하여 제1 네트워크 또는 제2 네트워크와 같은 통신 네트워크 내에서 전자 장치를 확인 또는 인증할 수 있다. 무선 통신 모듈은 4G 네트워크 이후의 5G 네트워크 및 차세대 통신 기술, 예를 들어, NR 접속 기술(new radio access technology)을 지원할 수 있다. NR 접속 기술은 고용량 데이터의 고속 전송(eMBB, enhanced mobile broadband), 단말 전력 최소화와 다수 단말의 접속(mMTC, massive machine type communications), 또는 고신뢰도와 저지연(URLLC, ultra-reliable and low-latency communications)을 지원할 수 있다. 무선 통신 모 듈은, 예를 들어, 높은 데이터 전송률 달성을 위해, 고주파 대역(예: mmWave 대역)을 지원할 수 있다. 무 선 통신 모듈은 고주파 대역에서의 성능 확보를 위한 다양한 기술들, 예를 들어, 빔포밍(beamforming), 거 대 배열 다중 입출력(massive MIMO(multiple-input and multiple-output)), 전차원 다중입출력(FD-MIMO, full dimensional MIMO), 어레이 안테나(array antenna), 아날로그 빔형성(analog beam-forming), 또는 대규모 안테 나(large scale antenna)와 같은 기술들을 지원할 수 있다. 무선 통신 모듈은 전자 장치, 외부 전자 장치(예: 전자 장치) 또는 네트워크 시스템(예: 제2 네트워크)에 규정되는 다양한 요구사항을 지원할 수 있다. 일 실시예에 따르면, 무선 통신 모듈은 eMBB 실현을 위한 Peak data rate(예: 20Gbps 이상),mMTC 실현을 위한 손실 Coverage(예: 164dB 이하), 또는 URLLC 실현을 위한 U-plane latency(예: 다운링크(DL) 및 업링크(UL) 각각 0.5ms 이하, 또는 라운드 트립 1ms 이하)를 지원할 수 있다. 안테나 모듈은 신호 또는 전력을 외부(예: 외부의 전자 장치)로 송신하거나 외부로부터 수신할 수 있다. 일 실시예에 따르면, 안테나 모듈은 서브스트레이트(예: PCB) 위에 형성된 도전체 또는 도전성 패턴으로 이루어진 방사체를 포함하는 안테나를 포함할 수 있다. 일 실시예에 따르면, 안테나 모듈은 복수의 안테나 들(예: 어레이 안테나)을 포함할 수 있다. 이런 경우, 제1 네트워크 또는 제2 네트워크와 같은 통신 네트워크에서 사용되는 통신 방식에 적합한 적어도 하나의 안테나가, 예를 들면, 통신 모듈에 의하여 상기 복수의 안테나들로부터 선택될 수 있다. 신호 또는 전력은 상기 선택된 적어도 하나의 안테나를 통하여 통신 모 듈과 외부의 전자 장치 간에 송신되거나 수신될 수 있다. 어떤 실시예에 따르면, 방사체 이외에 다른 부품 (예: RFIC(radio frequency integrated circuit))이 추가로 안테나 모듈의 일부로 형성될 수 있다. 다양한 실시예들에 따르면, 안테나 모듈은 mmWave 안테나 모듈을 형성할 수 있다. 일 실시예에 따르면, mmWave 안테나 모듈은 인쇄 회로 기판, 상기 인쇄 회로 기판의 제1 면(예: 아래 면)에 또는 그에 인접하여 배치 되고 지정된 고주파 대역(예: mmWave 대역)을 지원할 수 있는 RFIC, 및 상기 인쇄 회로 기판의 제2 면(예: 윗 면 또는 측 면)에 또는 그에 인접하여 배치되고 상기 지정된 고주파 대역의 신호를 송신 또는 수신할 수 있는 복수의 안테나들(예: 어레이 안테나)을 포함할 수 있다. 상기 구성요소들 중 적어도 일부는 주변 기기들간 통신 방식(예: 버스, GPIO(general purpose input and output), SPI(serial peripheral interface), 또는 MIPI(mobile industry processor interface))을 통해 서로 연결되고 신호(예: 명령 또는 데이터)를 상호간에 교환할 수 있다. 일 실시예에 따르면, 명령 또는 데이터는 제2 네트워크에 연결된 서버를 통해서 전자 장치와 외 부의 전자 장치간에 송신 또는 수신될 수 있다. 외부의 전자 장치(102, 또는 104) 각각은 전자 장치 와 동일한 또는 다른 종류의 장치일 수 있다. 일 실시예에 따르면, 전자 장치에서 실행되는 동작들의 전부 또는 일부는 외부의 전자 장치들(102, 104, 또는 108) 중 하나 이상의 외부의 전자 장치들에서 실행될 수 있다. 예를 들면, 전자 장치가 어떤 기능이나 서비스를 자동으로, 또는 사용자 또는 다른 장치로부터의 요청에 반응하여 수행해야 할 경우에, 전자 장치는 기능 또는 서비스를 자체적으로 실행시키는 대신에 또는 추가 적으로, 하나 이상의 외부의 전자 장치들에게 그 기능 또는 그 서비스의 적어도 일부를 수행하라고 요청할 수 있다. 상기 요청을 수신한 하나 이상의 외부의 전자 장치들은 요청된 기능 또는 서비스의 적어도 일부, 또는 상 기 요청과 관련된 추가 기능 또는 서비스를 실행하고, 그 실행의 결과를 전자 장치로 전달할 수 있다. 전 자 장치는 상기 결과를, 그대로 또는 추가적으로 처리하여, 상기 요청에 대한 응답의 적어도 일부로서 제 공할 수 있다. 이를 위하여, 예를 들면, 클라우드 컴퓨팅, 분산 컴퓨팅, 모바일 에지 컴퓨팅(MEC, mobile edge computing), 또는 클라이언트-서버 컴퓨팅 기술이 이용될 수 있다. 전자 장치는, 예를 들어, 분산 컴퓨팅 또는 모바일 에지 컴퓨팅을 이용하여 초저지연 서비스를 제공할 수 있다. 다른 실시예에 있어서, 외부의 전자 장치는 IoT(internet of things) 기기를 포함할 수 있다. 서버는 기계 학습 및/또는 신경망을 이용 한 지능형 서버일 수 있다. 일 실시예에 따르면, 외부의 전자 장치 또는 서버는 제2 네트워크 내에 포함될 수 있다. 전자 장치는 5G 통신 기술 및 IoT 관련 기술을 기반으로 지능형 서비스(예: 스마트 홈, 스마트 시티, 스마트 카, 또는 헬스 케어)에 적용될 수 있다. 도 2는 다양한 실시예들에 따른 카메라 모듈을 예시하는 블럭도이다. 도 2를 참조하면, 카메라 모듈은 렌즈 어셈블리(lens assembly), 플래쉬(flash), 이미지 센서 (image sensor), 이미지 스태빌라이저(image stabilizer), 메모리(memory)(예: 버퍼 메모리), 또는 이미지 시그널 프로세서(image signal processor)를 포함할 수 있다. 렌즈 어셈블리는 이미지 촬영의 대상인 피사체로부터 방출되는 빛을 수집할 수 있다. 렌즈 어셈블리 는 하나 또는 그 이상의 렌즈들을 포함할 수 있다. 일 실시예에 따르면, 카메라 모듈은 복수의 렌즈 어셈 블리들을 포함할 수 있다. 이런 경우, 카메라 모듈은, 예를 들면, 듀얼 카메라, 360도 카메라, 또는 구형 카메라(spherical camera)를 형성할 수 있다. 복수의 렌즈 어셈블리들 중 일부는 동일한 렌즈 속성 (예: 화각, 초점 거리, 자동 초점, f 넘버(f number), 또는 광학 줌)을 갖거나, 또는 적어도 하나의 렌즈 어셈 블리는 다른 렌즈 어셈블리의 렌즈 속성들과 다른 하나 이상의 렌즈 속성들을 가질 수 있다. 렌즈 어셈블리 는, 예를 들면, 광각 렌즈 또는 망원 렌즈를 포함할 수 있다. 플래쉬는 피사체로부터 방출 또는 반사되는 빛을 강화하기 위하여 사용되는 빛을 방출할 수 있다. 일 실시 예에 따르면, 플래쉬는 하나 이상의 발광 다이오드들(예: RGB(red-green-blue) LED, white LED, infrared LED, 또는 ultraviolet LED), 또는 xenon lamp를 포함할 수 있다. 이미지 센서는 피사체로부터 방출 또는 반사되어 렌즈 어셈블리를 통해 전달된 빛을 전기적인 신호로 변환함으로써, 상기 피사체에 대응하는 이미지를 획득할 수 있다. 일 실시예에 따르면, 이미지 센서는, 예 를 들면, RGB 센서, BW(black and white) 센서, IR 센서, 또는 UV 센서와 같이 속성이 다른 이미지 센서들 중 선택된 하나의 이미지 센서, 동일한 속성을 갖는 복수의 이미지 센서들, 또는 다른 속성을 갖는 복수의 이미지 센서들을 포함할 수 있다. 이미지 센서에 포함된 각각의 이미지 센서는, 예를 들면, CCD(charged coupled device) 센서 또는 CMOS(complementary metal oxide semiconductor) 센서를 이용하여 구현될 수 있다. 이미지 스태빌라이저는 카메라 모듈 또는 이를 포함하는 전자 장치의 움직임에 반응하여, 렌즈 어셈블리에 포함된 적어도 하나의 렌즈 또는 이미지 센서를 특정한 방향으로 움직이거나 이미지 센서 의 동작 특성을 제어(예: 리드 아웃(read-out) 타이밍을 조정 등)할 수 있다. 이는 촬영되는 이미지에 대 한 상기 움직임에 의한 부정적인 영향의 적어도 일부를 보상하게 해 준다. 일 실시예에 따르면, 이미지 스태빌 라이저는 카메라 모듈의 내부 또는 외부에 배치된 자이로 센서(미도시) 또는 가속도 센서(미도시)를 이용하여 카메라 모듈 또는 전자 장치의 그런 움직임을 감지할 수 있다. 일 실시예에 따르면, 이미지 스태빌라이저는, 예를 들면, 광학식 이미지 스태빌라이저로 구현될 수 있다. 메모리는 이미지 센서를 통하여 획득된 이미지의 적어도 일부를 다음 이미지 처리 작업을 위하여 적 어도 일시 저장할 수 있다. 예를 들어, 셔터에 따른 이미지 획득이 지연되거나, 또는 복수의 이미지들이 고속으 로 획득되는 경우, 획득된 원본 이미지(예: Bayer-patterned 이미지 또는 높은 해상도의 이미지)는 메모리(25 0)에 저장이 되고, 그에 대응하는 사본 이미지(예: 낮은 해상도의 이미지)는 디스플레이 모듈을 통하여 프 리뷰(preview)될 수 있다. 이후, 지정된 조건이 만족되면(예: 사용자 입력 또는 시스템 명령) 메모리에 저 장되었던 원본 이미지의 적어도 일부가, 예를 들면, 이미지 시그널 프로세서에 의해 획득되어 처리될 수 있다. 일 실시예에 따르면, 메모리는 메모리의 적어도 일부로, 또는 이와는 독립적으로 운영되는 별 도의 메모리로 구성될 수 있다. 이미지 시그널 프로세서는 이미지 센서를 통하여 획득된 이미지 또는 메모리에 저장된 이미지에 대하여 하나 이상의 이미지 처리들을 수행할 수 있다. 상기 하나 이상의 이미지 처리들은, 예를 들면, 깊이 지 도(depth map) 생성, 3차원 모델링, 파노라마 생성, 특징점 추출, 이미지 합성, 또는 이미지 보상(예: 노이즈 감소, 해상도 조정, 밝기 조정, 블러링(blurring), 샤프닝(sharpening), 또는 소프트닝(softening))을 포함할 수 있다. 추가적으로 또는 대체적으로, 이미지 시그널 프로세서는 카메라 모듈에 포함된 구성 요소들 중 적어도 하나(예: 이미지 센서)에 대한 제어(예: 노출 시간 제어, 또는 리드 아웃 타이밍 제어 등)를 수 행할 수 있다. 이미지 시그널 프로세서에 의해 처리된 이미지는 추가 처리를 위하여 메모리에 다시 저장되거나 카메라 모듈의 외부 구성 요소(예: 메모리, 디스플레이 모듈, 전자 장치, 전자 장치, 또는 서버)로 제공될 수 있다. 일 실시예에 따르면, 이미지 시그널 프로세서는 프로세서 의 적어도 일부로 구성되거나, 프로세서와 독립적으로 운영되는 별도의 프로세서로 구성될 수 있다. 이미지 시그널 프로세서가 프로세서와 별도의 프로세서로 구성된 경우, 이미지 시그널 프로세서(26 0)에 의해 처리된 적어도 하나의 이미지는 프로세서에 의하여 그대로 또는 추가의 이미지 처리를 거친 후 디스플레이 모듈을 통해 표시될 수 있다. 일 실시예에 따르면, 전자 장치는 각각 다른 속성 또는 기능을 가진 복수의 카메라 모듈들을 포함할 수 있다. 이런 경우, 예를 들면, 상기 복수의 카메라 모듈들 중 적어도 하나는 광각 카메라이고, 적어도 다른 하나는 망원 카메라일 수 있다. 유사하게, 상기 복수의 카메라 모듈들 중 적어도 하나는 전면 카메라 이고, 적어도 다른 하나는 후면 카메라일 수 있다. 본 문서에 개시된 다양한 실시예들에 따른 전자 장치는 다양한 형태의 장치가 될 수 있다. 전자 장치는, 예를 들면, 휴대용 통신 장치(예: 스마트폰), 컴퓨터 장치, 휴대용 멀티미디어 장치, 휴대용 의료 기기, 카메라, 웨 어러블 장치, 또는 가전 장치를 포함할 수 있다. 본 문서의 실시예에 따른 전자 장치는 전술한 기기들에 한정되 지 않는다. 본 문서의 다양한 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한 정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템 에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제1\", \"제2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위 해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제2) 구성요소에, \"기능적으로\" 또는 \"통신적으로\"라는 용어와 함께 또는 이런 용어 없 이, \"커플드\" 또는 \"커넥티드\"라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으 로(예: 유선으로), 무선으로, 또는 제3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서의 다양한 실시예들에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함 할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부 가 될 수 있다. 예를 들면, 일 실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형 태로 구현될 수 있다. 본 문서의 다양한 실시예들은 기기(machine)(예: 전자 장치) 의해 읽을 수 있는 저장 매체(storage medium)(예: 내장 메모리 또는 외장 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어 (예: 프로그램)로서 구현될 수 있다. 예를 들면, 기기(예: 전자 장치)의 프로세서(예: 프로세서 )는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것 을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매체의 형 태로 제공될 수 있다. 여기서, ‘비일시적’은 저장 매체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전 자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장되는 경 우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory(CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예: 스 마트 폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있으며, 복수의 개체 중 일부는 다른 구성요소에 분리 배치될 수도 있다. 다양한 실시 예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상 의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱(heuristic)하게 실행되거 나, 상기 동작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추가될 수 있다. 도 3은 본 개시의 일 실시예에 따른 전자 장치의 구성을 개략적으로 도시하는 도면이다. 도 3을 참조하면, 본 개시의 일 실시예에 따른 전자 장치는 디스플레이 모듈, 카메라 모듈, 메 모리, 및/또는 프로세서를 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 도 1을 참조한 설 명 부분에서 설명한 바와 같은 전자 장치의 구성 요소의 전부 또는 적어도 일부를 포함할 수 있다. 일 실시예에 따르면, 디스플레이 모듈은 도 1의 디스플레이 모듈과 동일 또는 유사한 구성을 포함할 수 있다. 일 실시예에 따라, 디스플레이 모듈은 디스플레이를 포함할 수 있고, 디스플레이를 통해 전자 장 치의 외부(예: 사용자)로 다양한 정보를 시각적으로 제공할 수 있다. 일 실시예에 따르면, 디스플레이 모 듈은 프로세서의 제어 하에, 실행하는 어플리케이션 및 그의 사용과 관련된 다양한 정보(예: 컨텐츠,이미지(image), 비디오(video), 프리뷰 이미지(preview image))를 시각적으로 제공할 수 있다. 일 실시예에 따라, 디스플레이 모듈은 터치 센서(touch sensor), 터치의 세기를 측정할 수 있는 압력 센서 (pressure sensor) 및/또는 자기장 방식의 스타일러스 펜을 검출하는 터치 패널(touch panel)(예: 디지타이저) 을 포함할 수 있다. 일 실시예에 따르면, 디스플레이 모듈은 터치 센서, 압력 센서 및/또는 터치 패널에 기반하여 디스플레이 모듈의 특정 위치에 대한 신호(예: 전압, 광량, 저항, 전자기 신호 및/또는 전하량) 의 변화를 측정함으로써 터치 입력 및/또는 호버링 입력(또는 근접 입력)을 감지할 수 있다. 일 실시예에 따르 면, 디스플레이 모듈은 액정 표시 장치(LCD, liquid crystal display), OLED(organic light emitted diode), AMOLED(active matrix organic light emitted diode)를 포함할 수 있다. 일 실시예에 따르면, 디스플 레이 모듈은 플렉서블 디스플레이(flexible display)를 포함할 수 있다. 일 실시예에 따르면, 카메라 모듈은 도 1 또는 도 2의 카메라 모듈에 대응할 수 있다. 일 실시예에 따르면, 카메라 모듈은 활성화 시에 피사체 촬영을 통해 관련 결과(예: 촬영 이미지)를 프로세서 및/ 또는 디스플레이 모듈에 전달할 수 있다. 일 실시예에 따르면, 카메라 모듈은 외부의 피사체(또는 객체)를 촬영하고, 이미지 데이터를 생성할 수 있 다. 예를 들어, 카메라 모듈은 이미지 센서(예: 도 2의 이미지 센서)를 포함할 수 있다. 일 실시예에 따르면, 이미지 센서는 멀티 픽셀 센서(MPS, multi pixel sensor)를 포함할 수 있다. 일 실시예에 따르면, 카메라 모듈은 이미지 센서에 의해 피사체의 광학적 신호를 전기적 신호로 변환할 수 있다. 이를 위 해, 이미지 센서는 복수의 픽셀들이 2차원적으로 배열된 픽셀 어레이를 포함할 수 있다. 예를 들어, 복수 의 픽셀들 각각에는 복수의 기준색들 중 하나의 색이 할당될 수 있다. 예를 들어, 복수의 기준색들은 RGB(red, green, blue), 또는 RGBW(red, green, blue, white)를 포함할 수 있다. 일 실시예에 따르면, 카메라 모듈은 이미지 센서(예: 멀티 픽셀 센서)를 이용하여 이미지 데이터를 생성할 수 있다. 일 실시예에서, 이미지 데이터는 이미지, 넌-베이어(non-Bayer) 이미지, 이미지 프레임 및 프 레임 데이터와 같이 다양하게 지칭될 수 있다. 일 실시예에 따르면, 이미지 데이터는 프로세서(예: 이미지 시그널 프로세서(ISP, image signal processor) 및/또는 신경망 처리 장치(NPU, neural processing unit))에 입력 데이터로서 제공되거나, 메모리에 저장될 수 있다. 일 실시예에서, 메모리에 저 장된 이미지 데이터는 프로세서로 제공될 수 있다. 일 실시예에 따르면, 메모리는 도 1의 메모리에 대응할 수 있다. 일 실시예에 따르면, 메모리는 전자 장치에 의해 사용되는 다양한 데이터를 저장할 수 있다. 일 실시예에서, 데이터는, 예를 들어, 어플 리케이션(예: 도 1의 프로그램), 및 어플리케이션과 관련된 명령(command)에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있다. 일 실시예에서, 데이터는, 카메라 모듈을 통해 획득하는 이미지 데이터 및 이미 지 데이터에 기반하여 처리되는 다양한 이미지(예: 넌-베이어 이미지, 베이어(Bayer) 이미지, 및/또는 리모자익 (Remosaic) 이미지) 관련 데이터를 포함할 수 있다. 일 실시예에서, 데이터는, 사용자와 상호작용으로 사용자의 학습에 기반하여 획득하는 다양한 학습 데이터 및 파라미터(parameters)를 포함할 수 있다. 일 실시예에서, 데 이터는, 인공지능(AI, artificial intelligence) 기반 영상 처리를 지원하기 위한 다양한 스키마(schema)(또는 알고리즘, 모델, 네트워크 또는 함수(function))를 포함할 수 있다. 예를 들어, 인공지능 기반 영상 처리를 지원하기 위한 스키마는, 뉴럴 네트워크(neural network)를 포함할 수 있다. 일 실시예에서, 뉴럴 네트워크는 ANN(Artificial Neural Network), CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restricted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network, Plain Residual Network, Dense Network, Hierarchical Pyramid Network, 및/또는 Fully Convolutional Network 중 적어도 하나에 기초한 뉴럴 네트워크 모델을 포함할 수 있다. 일 실시예에 따라, 뉴럴 네트워크 모델의 종류는 전술한 예에 제한하지 않는 다. 일 실시예에 따라, 메모리는, 실행 시에, 프로세서가 동작하도록 하는 인스트럭션들(instructions)을 저장할 수 있다. 예를 들어, 어플리케이션은 메모리 상에 소프트웨어(예: 도 1의 프로그램)로서 저장 될 수 있고, 프로세서에 의해 실행 가능할 수 있다. 일 실시예에 따라, 어플리케이션은 전자 장치에 서 다양한 기능 또는 서비스(예: 인공지능에 기반한 영상 촬영 기능)를 제공할 수 있는 다양한 어플리케이션일 수 있다. 일 실시예에 따르면, 프로세서는, 전자 장치의 사용자에 의해 요구되는 응용 계층 처리 기능을 할 수 있다. 일 실시예에 따르면, 프로세서는 전자 장치의 다양한 블록들을 위한 기능의 제어 및 명령을 제 공할 수 있다. 일 실시예에 따르면, 프로세서는 전자 장치의 각 구성 요소들의 제어 및/또는 통신에 관한 연산이나 데이터 처리를 수행할 수 있다. 예를 들어, 프로세서는 도 1의 프로세서의 구성 및/또 는 기능 중 적어도 일부를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 전자 장치의 구성 요소 들과 작동적으로 연결될 수 있다. 일 실시예에 따르면, 프로세서는 전자 장치의 다른 구성 요소로부 터 수신된 명령 또는 데이터를 메모리에 로드(load)하고, 메모리에 저장된 명령 또는 데이터를 처리 하고, 결과 데이터를 저장할 수 있다. 일 실시예에 따르면, 프로세서는 어플리케이션 프로세서(AP, application processor)일 수 있다. 일 실시 예에 따르면, 프로세서는 전자 장치의 연산과 멀티미디어 구동 기능을 담당하는 시스템 반도체일 수 있다. 일 실시예에 따르면, 프로세서는 시스템 온 칩(SoC, system-on-chip) 형태로 구성되어, 여러 반도체 기술을 하나로 집적하고, 시스템 블록들을 하나의 칩으로 구현한 기술집약적 반도체 칩을 포함할 수 있다. 일 실시예에 따르면, 프로세서의 시스템 블록들은, 도 3에 예시한 바와 같이, 그래픽 처리 장치(GPU, graphics processing unit), 이미지 시그널 프로세서(ISP, image signal processor), 중앙 처리 장 치(CPU, central processing unit), 신경망 처리 장치(NPU, neural processing unit), 디지털 시그 널 프로세서(digital signal processor), 모뎀(modem), 커넥티비티(connectivity), 및/또는 시 큐리티(security) 블록을 포함할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 위한 뉴럴 네트워크를 이용한 학습 데이터를 생성하는 것과 관련된 전반적인 동작을 제어할 수 있다. 일 실시예에 따르면, 프로세서는 어플리케이션을 실행하고, 어플 리케이션의 실행에 따라 요구되는 뉴럴 네트워크 기반의 태스크(예: 학습 데이터 생성 태스크)를 수행하도록 할 수 있다. 일 실시예에 따르면, 프로세서는 이미지 센서(예: 멀티 픽셀 센서)의 저해상도 이미지 및 고해상도 이미지를 이용한 딥-러닝(deep-learning) 기반의 줌 화질 개선을 위한 전반적인 동작을 제어할 수 있 다. 일 실시예에 따라, GPU는 그래픽 처리를 담당할 수 있다. 일 실시예에 따르면, GPU는 CPU의 명 령을 받아 디스플레이 상에 사물(또는 물체)들의 모양, 위치, 색상, 음영, 움직임, 및/또는 질감을 표현하기 위 한 그래픽 처리를 수행할 수 있다. 일 실시예에 따라, ISP는 이미지 및 비디오의 영상 처리 및 보정을 담당할 수 있다. 일 실시예에 따르면, ISP는 카메라 모듈의 이미지 센서(예: 도 2의 이미지 센서)에서 전송된 가공되지 않은 데이터 (예: 로우 데이터(raw data))를 보정하여 사용자가 선호하는 형태의 이미지를 생성하는 역할을 할 수 있다. 일 실시예에 따르면, ISP는 카메라 모듈에서 발생할 수 있는 물리적 한계점들을 보정하고, R/G/B(red, green, blue) 값들을 보간(interpolation) 및 노이즈(noise)를 제거할 수 있다. 일 실시예에 따르면, ISP(32 0)는 이미지의 부분적인 밝기를 조절하고, 디테일한 부분을 강조하는 것과 같은 후처리를 수행할 수 있다. 예를 들어, ISP는 카메라 모듈을 통해 획득하는 이미지의 화질 튜닝 및 보정 과정을 자체적으로 거쳐 사용 자가 선호하는 결과물을 생성할 수 있다. 일 실시예에 따르면, ISP는 줌(zoom) 이미지의 화질 개선, 신속한 영상 처리 및 전류 소모 감소(예: 저전 력)를 위해 인공지능 기반 영상 처리 기술을 지원할 수 있다. 예를 들어, ISP는 저전력을 유지하는 동시에 이미지 화질을 개선할 수 있고, 이를 위해 인공지능 기반의 영상 촬영을 지원할 수 있다. 일 실시예에 따르면, ISP는 고 배율의 줌 이미지의 화질을 높이는 것과 관련된 인공지능 기반 영상 처리를 지원할 수 있다. 일 실시예에 따르면, ISP는 NPU와 연동하여 촬영 중인 장면의 부분들을 인식 및/또 는 분류하는 장면 세분화(scene segmentation)(예: 이미지 세그멘테이션(image segmentation)) 기술을 지원할 수 있다. 예를 들어, ISP는 하늘, 수풀, 및/또는 피부와 같은 객체에 각기 다른 파라미터를 적용하여 처리 하는 기능을 포함할 수 있다. 예를 들어, ISP는 영상 촬영에 지정되는 줌 배율에 따라 각기 다른 파라미터 를 적용하여 처리하는 기능을 포함할 수 있다. 일 실시예에 따르면, ISP는 인공지능 기능을 통해 영상 촬 영 시, 사람 얼굴을 감지하여 표시하거나 그 얼굴의 좌표와 정보를 이용하여 이미지의 밝기, 초점, 및/또는 색 상을 조절할 수 있다. 일 실시예에 따라, CPU는 프로세서에 대응하는 역할을 담당할 수 있다. 일 실시예에 따르면, CPU는 사용자의 명령을 해독하고, 산술과 논리연산, 및/또는 데이터 처리의 역할을 수행할 수 있다. 예를 들어, CPU는 기억, 해석, 연산, 및 제어라는 기능을 담당할 수 있다. 일 실시예에 따르면, CPU는 전자 장치의 전반적인 기능을 제어할 수 있다. 예를 들어, CPU는 운영체제(OS, operating system) 위 에서 전자 장치의 모든 소프트웨어(예: 어플리케이션)를 실행하고, 하드웨어 장치를 제어할 수 있다. 일 실시예에 따라, CPU는 하나의 프로세서 코어(single core)를 포함하거나, 복수의 프로세서 코어들 (multi-core)을 포함할 수 있다. 일 실시예에 따르면, CPU는 어플리케이션을 실행하고, 어플리케이션의 실 행에 따라 요구되는 뉴럴 네트워크 기반의 태스크들을 수행하도록 프로세서의 전반적인 동작을 제어할 수 있다. 일 실시예에 따라, NPU는 인공지능의 딥-러닝 알고리즘에 최적화된 처리를 담당할 수 있다. 일 실시예에 따르면, NPU는 딥-러닝 알고리즘 연산(예: 인공지능 연산)에 최적화된 프로세서로, 빅데이터(big data)를 사람의 신경망처럼 빠르고 효율적으로 처리할 수 있다. 예를 들어, NPU는 인공지능 연산에 주로 이용될 수 있다. 일 실시예에 따르면, NPU는 카메라 모듈을 통해 영상 촬영 시 배경 안의 사물, 환경, 및/또는 인물을 인식하여 자동으로 초점을 조정하거나, 음식 사진 촬영 시 카메라 모듈의 촬영 모드를 음식 모드로 자동 전환하거나, 및/또는 촬영된 결과물에서 불필요한 피사체만 지우는 처리를 담당할 수 있다. 일 실시예에 따르면, 전자 장치는 GPU, ISP, CPU, 및 NPU와 같은 모든 프로세서를 상호작용하여 통합 머신 러닝(machine learning) 처리를 지원할 수 있다. 일 실시예에 따라, DSP는 디지털 신호를 빠르게 처리하도록 도와주는 집적회로를 나타낼 수 있다. 일 실시 예에 따르면, DSP는 아날로그 신호를 디지털로 변경하여 고속 처리하는 기능을 수행할 수 있다. 일 실시예에 따라, 모뎀은 전자 장치에서 다양한 통신 기능을 사용할 수 있도록 해주는 역할을 수행 할 수 있다. 예를 들어, 모뎀은 기지국과 신호를 주고받으면서 전화 및 데이터 송수신과 같은 통신을 지원 할 수 있다. 일 실시예에 따르면, 모뎀은 LTE 및 2G 내지 5G와 같은 통신 기술을 지원하는 통합 모뎀(예: 셀룰러(cellular) 모뎀, LTE 모뎀, 5G 모뎀, 및 5G-Advanced 모뎀, 및 6G 모뎀)을 포함할 수 있다. 일 실시예 에 따르면, 모뎀은 인공지능 알고리즘을 적용한 인공지능 모뎀을 포함할 수 있다. 일 실시예에 따라, 커넥티비티는 IEEE 802.11에 기반한 무선 데이터 전송을 지원할 수 있다. 일 실시예에 따르면, 커넥티비티는 IEEE 802.11(예: Wi-Fi) 및/또는 802.15(예: Bluetooth, ZigBee, UWB)에 기반한 통 신 서비스를 지원할 수 있다. 예를 들어, 커넥티비티는 비면허 대역을 사용하여 실내와 같이 국지적인 지 역에서 불특정 다수를 대상으로 통신 서비스를 지원할 수 있다. 일 실시예에 따라, 시큐리티는 전자 장치에 저장된 데이터나 서비스 간의 독립적인 보안 실행 환경을 제공할 수 있다. 일 실시예에 따르면, 시큐리티는 전자 장치의 생체 인식, 모바일 신분증, 및/또는 페이먼트와 같은 서비스 제공 시, 사용자 인증을 하는 과정에서 소프트웨어 및 하드웨어 상의 보안을 통해 외부 로부터 해킹 발생을 방지하는 역할을 담당할 수 있다. 예를 들어, 시큐리티는 전자 장치의 자체의 보 안 강화를 위한 기기 보안(device security)과 전자 장치에서의 모바일 신분증, 페이먼트, 자동차 키와 같 은 사용자 정보를 기반으로 하는 보안 서비스(security service)에서 독립적인 보안 실행 환경을 제공할 수 있 다. 본 개시의 일 실시예에 따르면, 프로세서는 처리 회로(processing circuitry) 및/또는 실행 가능한 프로그 램 요소(executable program elements)를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 처리 회로 및 /또는 실행 가능한 프로그램 요소에 기반하여, 고 배율의 줌 성능을 향상하고, 고 배율 줌 이미지의 영상 처리 를 지원하는 것과 관련된 동작을 제어(또는 처리)할 수 있다. 일 실시예에 따르면, 프로세서는 카메라 모듈(예: 줌 카메라)을 통해 이미지 데이터(예: 넌-베이어 이미지)를 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 이미지 데이터에 기반하여 비닝(Binning) 처리를 수행하고, 이미지 데이터를 통신 회로(예: 도 1의 무선 통신 모듈)를 통해 서버(예: 도 6의 서버)로 전송하는 동작을 수행할 수 있다. 일 실시예에 따르면, 상기 프로세서는 비닝 처리에 기반 하여 비닝 이미지를 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 비닝 이미지에 기 반하여 학습 데이터를 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는, 서버로부터 이 미지 데이터를 기반으로 생성된 실측 데이터를 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서 는 학습 데이터와 실측 데이터에 기반하여 줌 배율에 대해 학습하는 동작을 수행할 수 있다. 일 실시예에 따르면, 상기 프로세서는 줌 배율에 대응하는 파라미터를 생성하여 매핑하는 동작을 수행할 수 있다. 일 실시예에 따라, 전자 장치의 프로세서의 상세 동작에 관하여 후술하는 도면들을 참조하여 설명된 다. 일 실시예에 따르면, 프로세서에서 수행하는 동작들은, 기록 매체(또는 컴퓨터 프로그램 프로덕트 (product))로 구현될 수 있다. 예를 들어, 기록 매체는 프로세서에서 수행하는 다양한 동작을 실행시키기 위한 프로그램을 기록한 비 일시적(non-transitory) 컴퓨터(computer)로 판독 가능한 기록 매체를 포함할 수 있 다. 본 개시에서 설명되는 실시예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합된 것을 이용하 여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하 면, 일 실시예에서 설명되는 동작들은 ASICs(Application Specific Integrated Circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기(controllers), 마이크로 컨트롤러 (micro-controllers), 마이크로프로세서(microprocessors), 및/또는 기타 기능 수행을 위한 전기적인 유닛 (unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일 실시예에서, 기록 매체(또는 컴퓨터 프로그램 프로덕트)는, 상기 전자 장치의 카메라 모듈을 통해 이미지 데 이터를 획득하는 동작, 상기 이미지 데이터에 기반하여 비닝(Binning) 처리를 수행하고, 상기 이미지 데이터를 통신 회로를 통해 서버로 전송하는 동작, 상기 비닝 처리에 기반하여 비닝 이미지를 획득하는 동작, 상기 비닝 이미지에 기반하여 학습 데이터를 획득하는 동작, 상기 서버로부터 상기 이미지 데이터를 기반으로 생성된 실측 데이터를 획득하는 동작, 상기 학습 데이터와 상기 실측 데이터에 기반하여 줌 배율에 대한 학습을 수행하는 동 작, 및 상기 줌 배율에 대응하는 파라미터를 생성하여 매핑하는 동작을 실행시키기 위한 프로그램을 기록한 컴 퓨터로 판독 가능한 기록 매체를 포함할 수 있다. 도 4 및 도 5는 일 실시예에 따른 전자 장치에서 하이브리드 줌 시나리오의 일 예를 도시하는 도면들이다. 일 실시예에 따르면, 전자 장치는 카메라 모듈(예: 줌 카메라)에 의한 줌 기능과 디지털 크롭 (digital crop) 줌 기능의 조합을 통해 고 배율 줌 기능을 제공할 수 있다. 일 실시예에 따라, 도 4는 기존 옵티컬-디지털 하이브리드 줌(conventional optical-digital hybrid zoom) 시 나리오의 일 예를 나타낼 수 있다. 예를 들어, 도 4에서는 전자 장치가 제1 카메라(예: x1 배율의 메인 카 메라)와 제2 카메라(예: x3 배율의 줌 카메라)를 포함하는 카메라 모듈을 포함하고, 카메라 모듈을 통해서 x1 배율 ~ x10 배율의 줌 기능(예: 주밍(zooming))을 제공하는 예를 나타낼 수 있다. 일 실시예에 따라, 도 5는 멀티 픽셀 센서(MPS) 기반 옵티컬-디지털 하이브리드 줌 시나리오의 일 예를 나타낼 수 있다. 예를 들어, 도 5에서는 멀티 픽셀 센서, 제1 카메라(예: x1 배율의 메인 카메라) 및 제2 카메라(예: x3 배율의 줌 카메라)를 포함하는 카메라 모듈을 포함하고, 카메라 모듈을 통해서 x1 배율 ~ x10 배 율의 줌 기능(예: 주밍)을 제공하는 예를 나타낼 수 있다. 일 실시예에서, 도 4 및 도 5에 예시한 바와 같이, 엘리먼트 (A)는 줌 구간(또는 범위)을 나타내는 다양한 배율 의 예를 나타낼 수 있다. 엘리먼트 (B)는 센서(예: 이미지 센서 또는 멀티 픽셀 센서)의 포맷(format)을 나타내 는 CFA(color filter array) 패턴(예: 컬러 필터 모양(Bayer pattern))의 예를 나타낼 수 있다. 엘리먼트 (C) 는 각 배율에 대응하는 해상도의 예를 나타낼 수 있다. 엘리먼트 (D)는 최종 줌이 적용된 이미지 뷰(image view)의 예를 나타낼 수 있다. 도 4를 참조하면, 도 4의 배율(C)에서 줌 x1(zoom x1)은 제1 카메라(예: 메인 카메라)의 줌 배율을 나타내고, 줌 x3(zoom x3)은 제2 카메라(예: 줌 카메라)의 고정된 줌 배율을 나타낼 수 있다. 도 4의 예시에서, 줌 x1과 줌 x3의 줌 배율 외의 다른 줌 배율(예: x2, x6, x10)은 제1 카메라 및 제2 카메라의 센서(예: 이미지 센서) 또 는 이미지의 영역을 줌 배율에 기반하여 크롭 후, 오리지널(original) 이미지의 사이즈(size)를 만들기 위한 업 스케일(upscale) 영상 처리(예: bi-linear interpolation, bi-cubic interpolation, 및/또는 image fusion)를 통해 줌 기능이 제공된 예를 나타낼 수 있다. 일 실시예에 따르면, 도 4에 예시한 바와 같은 기존 옵티컬-디지 털 하이브리드 줌 시나리오에서는 이미지 크롭 후, 이미지를 오리지널 이미지의 사이즈로 복원하기 위한 업스케 일 적용 시, 픽셀(pixel) 간 보간(interpolation)을 수행할 수 있다. 하지만, 픽셀 간 보간을 통해 추정된 픽셀 값은 화질 열화가 발생할 수 있다. 예를 들어, 기존 옵티컬-디지털 하이브리드 줌 시나리오에서는 줌 배율이 증가함에 따라 디지털 크롭의 ROI(region of image)(예: 크롭 영역)의 사이즈는 작아지게 되고, 반대로 오리지널 이미지의 복원을 위한 업스케일 양은 커질 수 있다. 따라서, 줌 배율이 증가할수록 화질 열화는 더 크게 발생할 수 있다. 일 실시예에 따라, 도 5는 줌 배율이 커짐에 따라 발생하는 화질 열화를 멀티 픽셀 센서 기반의 리모자익 (Remosaic) 고해상도 출력을 이용하여 개선하는 예를 나타낼 수 있다. 일 실시예에서, 도 5와 도 4에 따른 줌 시나리오의 차이는 x3 배율의 제2 카메라(예: 줌 카메라)에 적용된 센서가 x1 배율의 제1 카메라(예: 메인 카메 라)에 적용된 일반적인 센서(예: RGB Bayer Pattern 이미지 센서)가 아닌 각 컬러 채널(color channel)이 복수 개의 NxN(N은 2 이상 자연수)(예: 2x2, 3x3, 4x4) 픽셀들의 조합으로 이루어진 멀티 픽셀 구조의 넌-베이어 패 턴(non-Bayer pattern)의 멀티 픽셀 센서를 적용한 예를 나타낼 수 있다. 도 5를 참조하여, 멀티 픽셀 센서가 적용된 x3 배율의 카메라(예: 줌 카메라)를 이용한 옵티컬-디지털 하이브리 드 줌 동작에 대해 설명한다. 예를 들어, 옵티컬-디지털 하이브리드 줌 동작에서 줌 배율 x3.1 ~ x5.9 까지는 x3 배율의 줌 카메라의 멀티 픽셀 센서의 비닝(Binning) 출력(예: 12MP 저해상도 출력)을 이용하여 각 줌 배율 에 따른 디지털 크롭 줌을 적용할 수 있다. 예를 들어, 옵티컬-디지털 하이브리드 줌 동작에서 줌 배율 x6은 줌 카메라의 멀티 픽셀 센서의 리모자익(Remosaic) 출력(예: 48MP 고해상도 출력)을 이용하여 각 줌 배율에 따른 디지털 크롭 줌을 적용할 수 있다. 예를 들어, 옵티컬-디지털 하이브리드 줌 시나리오의 경우, 멀티 픽셀 센서 가 적용된 x2 줌 배율 기반 이미지 크롭의 경우, 리모자익(Remosaic) 출력의 크롭을 통한 줌 배율 영상의 해상 도가 확보됨으로써, 오리지널 이미지의 사이즈를 만들기 위한 업스케일이 필요하지 않을 수 있다. 예를 들어, 옵티컬-디지털 하이브리드 줌 시나리오(예: 줌 배율 x6 시나리오)의 경우, 멀티 픽셀 센서의 리모자익 출력으로 해상도가 2배로 된 상태에서 크롭 줌(예: x2배)를 수행함에 따라, 오리지널 이미지의 사이즈 복원이 필요하지 않을 수 있다. 따라서, 도 4에 예시된 기존 옵티컬-디지털 하이브리드 줌 시나리오 대비 x6 줌 배율 이미지에 대해 3MP에서 12MP로의 업스케일이 필요하지 않으며, x10 줌 배율에서 디지털 크롭 적용은 1.07MP에서 12MP로의 업스케일 적용이 아니라, 멀티 픽셀 센서 기반의 리모자익(Remosaic) 적용에 따른 4.3MP에서 12MP로의 업스케일 이 적용됨에 따라 기존 방식 대비 화질 열화가 적을 수 있다. 본 개시의 일 실시예에 따르면, 옵티컬-디지털 하이브리드 줌 구조에서 멀티 픽셀 센서의 비닝(이하, ‘Binning ’이라 명명함) 출력과 리모자익(이하, ‘Remosaic’이라 명명함) 출력을 이용하여, 초고해상도(SR, super resolution)(이하, ‘SR’이라 명명함) 딥-러닝 기반의 데이터와 실측 데이터(GT, Ground Truth)(이하, ‘GT’ 라 명명)를 효율적으로 학습하여 학습 데이터(예: 네트워크 파라미터(Network parameters))를 도출할 수 있다. 본 개시의 일 실시예에 따르면, 학습된 학습 데이터를 전자 장치(예: 뉴럴 네트워크)에 적용하여 줌 이미 지의 화질 개선 및 스틸 이미지(still image), 프리뷰 이미지(preview image) 및 비디오(video)에서도 끊김 없 이 고 배율의 줌 이미지를 제공할 수 있다. 본 개시의 일 실시예에 따른 구체적인 방법은 이하의 상세한 설명으 로부터 명백해질 것이다. 도 6은 본 개시의 일 실시예에 따른 학습 데이터를 위한 학습 시스템 및 그 동작 예를 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른 멀티 픽셀 센서의 비닝 동작 예의 설명을 위해 도시하는 도면이다. 도 8은 본 개시의 일 실시예에 따른 멀티 픽셀 센서의 리모자익 동작 예의 설명을 위해 도시하는 도면이다. 일 실시예에 따르면, 도 6에서는 전자 장치에서 옵티컬-디지털 하이브리드 줌 기능을 위한 학습 데이터를 생성하는 구조(예: 네트워크 시스템) 및 그 동작의 일 예를 나타낼 수 있다. 일 실시예에 따르면, 도 6의 예시 에서는, 멀티 픽셀 센서의 동일한 출력(예: 넌-베이어 이미지)으로부터 생성하는 저해상도(LR, low resolution) 이미지 및 고해상도(HR, high resolution) 이미지를 이용하여 SR 딥-러닝 학습에 기반한 학습 데 이터를 제공하는 일 예를 나타낼 수 있다. 예를 들어, 도 6의 예시에서는 x3 배율의 줌 카메라에서 멀티 픽셀 센서의 넌-베이어 이미지(예: CFA 출력)을 프로세서를 통한 베이어(Bayer) 변환을 통해 Binning 이미지(예: 저해상도 이미지)와 Remosaic 이미지(예: 고해상도 이미지)를 생성하고, 저해상도 및 고해상도의 이 미지 페어(pair)를 이용한 SR 딥-러닝 기반 학습을 통해 전자 장치의 네트워크(예: SR Network)를 이 용한 고 배율 줌 기능을 위한 화질 개선 방안을 설명한다. 도 6을 참조하면, 일 실시예에 따른 네트워크 시스템(예: 옵티컬-디지털 하이브리드 줌 구조)는 전자 장치(10 1)와 서버(예: 도 1의 서버)를 포함할 수 있다. 일 실시예에서, 전자 장치는 카메라 모듈(예: 도 1 또는 도 2의 카메라 모듈), 프로세서 (예: 도 1 또는 도 3의 프로세서)를 포함할 수 있다. 일 실시예에서, 도시하지는 않았으나, 전자 장치 는 메모리(예: 도 1 또는 도 3의 메모리)를 포함할 수 있다. 일 실시예에서, 서버는 머신 러닝 클라우드(machine learning cloud)) 또는 네트워크 서버를 포함할 수 있 다. 일 실시예에서, 서버는 전자 장치의 외부에 존재하고, 전자 장치와 상호 연동하여 기계 학 습(예: 딥-러닝 학습)을 통해 인공지능 모델을 생성할 수 있는 다른 전자 장치를 포함할 수 있다. 일 실시예에 따르면, 카메라 모듈은 이미지 센서를 포함할 수 있다. 일 실시예에 따르면, 카메라 모 듈은 도시하지는 않았으나, 렌즈(예: 도 2의 렌즈 어셈블리)를 포함할 수 있다. 일 실시예에 따라, 도 6에서, 카메라 모듈은 지정된 배율을 갖는 줌 카메라를 나타낼 수 있고, 이미지 센서는 줌 카메라 에 포함되고 멀티 픽셀(multi pixel)의 구조를 갖는 멀티 픽셀 센서(MPS)를 나타낼 수 있다. 이하에서, 이미지 센서는 멀티 픽셀 센서인 것으로 명명하여 설명한다. 일 실시예에 따르면, 멀티 픽셀 센서는 동일한 컬러 필터(color filter)를 공유하는 픽셀들의 조합이 2x2, 3x3 또는 4x4와 같은 복수개의 NxN(N은 2 이상 자연수) 픽셀들의 조합으로 이루어진 멀티 픽셀 구조의 넌-베이 어 패턴(non-Bayer pattern)의 이미지 센서(예: 넌-베이어 센서)를 나타낼 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서는 픽셀의 개수를 최대한 늘려 고해상도를 제공하고, 픽셀 간 Binning 을 제공함으로써 픽셀 사이즈(pixel size)를 증가시키는 효과를 가질 수 있다. 예를 들어, 멀티 픽셀 센서(61 0)는 고해상도와 고감도 센싱이 가능하다. 일 실시예에 따라, 멀티 픽셀 센서의 동작 예가 도 7 및 도 8에 도시된다. 일 실시예에 따라, 도 7 및 도 8은 2x2 48MP 멀티 픽셀 센서의 출력에 대한 예를 도시할 수 있다. 일 실시예에 따라, 도 7은 2x2 멀티 픽셀 센서의 Binning 동작에 따른 출력(예: 48MP -> 12MP)의 예를 나 타낼 수 있다. 예를 들어, 도 7은 복수개의 픽셀들에서 각각 이웃한 4개의 동일한 컬러 픽셀을 Binning하여 한 개의 픽셀(예: 블록 단위 픽셀)로 구성하여, 예를 들어, 12MP의 해상도와 2배의 밝기가 개선되는 감도 비 개선 출력의 예를 나타낼 수 있다. 일 실시예에 따라, 도 8은 2x2 멀티 픽셀 센서의 Remosaic 동작에 따른 출력(예: 48MP Non-Bayer -> 48MP Bayer)의 예를 나타낼 수 있다. 예를 들어, 도 8은 2x2 48MP 멀티 픽셀 센서의 출력을 일반적인 베이어 패턴 (Bayer pattern)으로 만들기 위해 Remosaic 알고리즘을 적용하여 변환함으로써, 48MP 고해상도 출력을 구현한 예를 나타낼 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서의 넌-베이어(non-Bayer) 출력은 Remosaic 알고리즘을 통해 고해상도 의 베이어(Bayer) 출력을 획득할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서는 고해상도의 베이어 출력 을 획득하는 과정에서 이미지의 아티팩트(artifact)가 발생할 수 있는데, 이를 개선 및 보완하는 알고리즘이 Remosaic 알고리즘에 포함될 수 있다. 일 실시예에서, 아티팩트는, 예를 들어, 위색(false color), 컬러 노이즈 및 패턴 노이즈(color noise & pattern noise), 텍스쳐 에러(texture error), 및/또는 메이즈 노이즈(maze noise)를 포함할 수 있다. 일 실시예에 따르면, 기존의 멀티 픽셀 센서를 이용한 영상 처리의 경우, 전자 장치 내부에 Remosaic 알고리즘을 구현함에 따라, 사용자에게 사용 가능한 수준의 처리 속도와 전류 소모가 필요할 수 있다. 따라서, 기존의 멀티 픽셀 센서의 경우 속도(speed) 처리 기반의 Remosaic 알고리즘을 적용하여 일부 아티팩트의 개선 대비 속도를 우선으로 처리할 수 있다. 본 개시의 일 실시예에 따른 멀티 픽셀 센서를 이용한 영상 처리의 경우, 전자 장치의 외부에 위치된 서버에 Remosaic 알고리즘을 구현할 수 있다. 예를 들어, 본 개시에서 딥-러닝 학습은 서버를 통해 별도로 동작하도록 함으로써, Remosaic 알고리즘 동작에 필요한 처리 속도와 전류 소모에 제한되지 않을 수 있 다. 예를 들어, 본 개시의 일 실시예에 따른 멀티 픽셀 센서는 속도를 우선하는 Remosaic 알고리즘 대비 고해상력을 위한 해상도 처리 기반의 Remosaic 알고리즘(예: 프리미엄(premium) Remosaic 알고리즘)을 적용하여 속도 대비 아티팩트의 개선을 우선으로 처리하도록 할 수 있다. 예를 들어, 멀티 픽셀 센서는 개선된 고해 상력의 이미지(예: GT, ground truth)를 획득할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서의 출력은 3가지 모드를 포함할 수 있다. 예를 들어, 멀티 픽셀 센서 의 출력은 멀티 픽셀의 형태인 넌-베이어 출력, 각 컬러 필터를 공유하는 픽셀의 조합에 대해 픽셀 평균 (pixel average)로 머지(merge)하여 감도 비를 개선한 Binning 출력, 및 넌-베이어 출력에 대해 Remosaic 알고 리즘을 통하여 일반 베이어 형태로 변환한 고해상도 출력을 포함할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센 서의 각 출력은, 예를 들어, 멀티 픽셀 센서의 모드 전환을 통해 선택될 수 있다. 본 개시의 일 실시 예에 따른 멀티 픽셀 센서는 넌-베이어 출력(예: 넌-베이어 이미지)을 이용할 수 있으며, 멀티 픽셀 센서의 모드 전환에 따른 지연(delay)과 Remosaic 알고리즘에 필요한 로직, 파워(power) 및/또는 처리 시간을 필요로 하지 않을 수 있다. 일 실시예에 따르면, 학습 동작 시에, 멀티 픽셀 센서의 출력(예: 넌-베이어 이미지)은, 전자 장치 의 프로세서로 학습 데이터로써 입력되고, 서버로 실측 데이터(예: GT)를 생성하도록 전달될 수 있다. 예를 들어, 전자 장치의 Binning 처리와 서버의 Remosaic 처리에 사용되는 이미지는 멀티 픽셀 센서에 출력되는 동일한 넌-베이어 이미지가 이용될 수 있다. 일 실시예에 따르면, 전자 장치는 프로세서(예: 도 3의 ISP)를 통해 Binning 처리를 수행할 수 있다(블록 601). 일 실시예에 따르면, 전자 장치는 멀티 픽셀 센서의 출력(예: 2x2, 3x3 또는 4x4의 넌-베이어 이미지)에 대해 픽셀 평균 머지(pixel average merge)를 통한 감도 비가 우수한 Binning 처리 를 통해 Binning 이미지를 생성할 수 있다. 일 실시예에 따르면, 프로세서는 멀티 픽셀 센서의 출력에 대해 실시간 처리를 통해 지연 없이 Binning 처리된 저해상도 베이어로 변환된 Binning 이미지를 ISP에 전달할 수 있다. 일 실시예에 따라, 멀티 픽셀 센서는 카메라 모듈의 렌즈(예: 도 2의 렌즈 어셈블리)로부터 로 우 데이터(raw data)를 수신할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서는 멀티 픽셀 센서의 CFA(color filter array) 패턴(예: 컬러 필터 모양(Bayer pattern))에 따라 CFA 데이터(또는 CFA 이미지)를 실 시간으로 수신할 수 있다. 일 실시예에 따라, 멀티 픽셀 센서는 수신된 로우 데이터를 멀티 픽셀 센서 의 출력 특성(예: 넌-베이어 패턴)에 맞게 프로세서로 실시간으로 전달할 수 있다. 일 실시예에 따르 면, 프로세서는 멀티 픽셀 센서의 넌-베이어 이미지를 수신하면, 넌-베이어 이미지를 전자 장치와 연결된 서버에 실시간으로 전송할 수 있다. 일 실시예에 따라, 프로세서는 멀티 픽셀 센서의 넌-베이어 이미지에 기반하여, Binning 처리를 수행할 수 있다. 일 실시예에 따르면, 프로세서는 Binning 처리에 기반하여 Binning 이미지를 출력할 수 있다. 일 실시예에서, Binning 이미지는 줌 이미지 및 딥-러닝 저해상도 학습 이미지에 사용될 수 있다. 일 실시예에 따르면, Binning 이미지는, 학습 동작에서는, 도 6에 예시한 바와 같이, ISP를 통 해 영상 처리되어 네트워크를 위한 입력 이미지(예: 학습 데이터)로 사용될 수 있다. 일 실시예에 따 르면, Binning 이미지는, 사용자에 의한 촬영 동작에서 줌 기능을 수행하는 동작에서는, ISP를 통해 영상 처리되어 사용자 입력에 대응하는 줌 배율(예: 약 x3.1 ~ x5.9 배율)로 확대된 출력 이미지를 생성하기 위 한 입력 이미지로 사용될 수 있다. 일 실시예에 따르면, 프로세서는 Binning 이미지를 ISP를 통해 영상 처리(예: 이미지 시그널 프 로세싱(image signal processing))를 수행할 수 있다(블록 603). 예를 들어, 프로세서는 Binning 처리된 Binning 이미지를 ISP를 통해 디모자익(demosaic), 음영 보정, 색감 보정, 노이즈 제거, 및 선명도 조정과 같은 영상 처리를 수행할 수 있다. 일 실시예에 따르면, 프로세서는 영상 처리에 따른 데이터를 학 습 데이터로 출력할 수 있다. 일 실시예에 따르면, 프로세서는 Binning 이미지를 영상 처리 후 학습 데이터로써 ISP의 네트워크(예: SR 네트워크 또는 뉴럴 네트워크)로 전달할 수 있다. 일 실시예에 따르면, 서버는 전자 장치로부터 전송된 멀티 픽셀 센서의 출력인 넌-베이어 이미 지를 수신하고(블록 605), 수신된 넌-베이어 이미지에 대해 Remosaic 알고리즘을 이용한 Remosaic 처 리를 통해(블록 607), 고해상도 베이어로 변환된 Remosaic 이미지(예: 딥-러닝 고해상도 학습 이미지)를 생성할 수 있다. 일 실시예에 따르면, 서버는 Remosaic 이미지를 전자 장치(예: 전자 장치(10 1)의 네트워크)로 실시간으로 전송할 수 있다. 일 실시예에 따르면, 서버는 멀티 픽셀 센서에서 출력된 넌-베이어 기반 출력(예: 2x2, 3x3 또는 4x4 의 넌-베이어 이미지)의 멀티 픽셀에 대해 Remosaic 알고리즘을 이용하여 고해상도 베이어로 변환할 수 있 다. 일 실시예에 따르면, 서버는 전자 장치로부터 전자 장치의 멀티 픽셀 센서의 넌-베이 어 이미지를 수신하고, 멀티 픽셀 센서의 넌-베이어 이미지를 RDI(raw dump interface)를 이용 하여 서버의 메모리에 저장할 수 있다. 일 실시예에 따르면, 서버는 메모리에 저장된 멀티 픽셀 센서의 넌-베이어 이미지를 소프 트웨어 또는 하드웨어 기반의 지정된 Remosaic 알고리즘을 이용하여 고해상도의 베이어로 변환할 수 있다. 일 실시예에 따르면, 서버는 고해상도의 베이어 변환에 기반하여 Remosaic 이미지를 생성할 수 있다. 일 실시예에 따르면, 서버는 Remosaic 이미지를 실시간으로 전자 장치의 네트워크로 전달할수 있다. 일 실시예에 따르면, Remosaic 이미지는 딥-러닝 고행상도 GT(Ground Truth)로 이용될 수 있다. 일 실시예에서, 서버에서 사용되는 Remosaic 알고리즘은 화질 우선 위주의 Remosaic 알고리즘이 적용될 수 있다. 예를 들어, 화질 우선 위주의 Remosaic 알고리즘은 Remosaic에 의한 고화질의 이미지(예: Remosaic 이미 지)를 획득하기 위한 알고리즘일 수 있다. 일 실시예에 따른 Remosaic 알고리즘에 의해 생성되는 Remosaic 이미지는 전자 장치의 네트워크의 실측 데이터로 사용될 수 있다. 예를 들어, Remosaic 이미지 는 SR 딥-러닝의 GT 이미지로 이용될 수 있으며, 전자 장치에서는 줌 시나리오에서 Binning 이미지 를 입력으로 사용하여 고 배율의 줌 기능을 수행할 수 있다. 일 실시예에 따르면, 네트워크는 서버로부터 멀티 픽셀 센서의 이미지 데이터(예: 넌-베이어 이 미지)를 화질 우선의 Remosaic 알고리즘에 기반하여 Remosaic된 고화질의 이미지(예: Remosaic 이미지 )를, 통신 회로(예: 도 1의 무선 통신 모듈)를 통해 수신할 수 있다. 일 실시예에 따르면, 네트워크 는 학습 데이터와 서버로부터 수신된 실측 데이터(예: Remosaic 이미지)의 페어(pair)에 기반하여 동작 중인 줌 배율에 대해 학습하는 동작을 수행할 수 있다. 예를 들어, 네트워크는 학습 데이터 (예: 변환된 Binning 이미지)와 실측 데이터(예: Remosaic 이미지)의 페어를 이용하여 SR 딥-러닝 기반의 학습을 수행할 수 있다. 예를 들어, 네트워크는, 지정된 줌 모드에서 동일한 입력(예: 멀티 픽셀 센서의 넌-베이어 이미지)으로부터 생성된 학습 데이터와 실측 데이터의 페어를 이용하여 학습할 수 있다. 일 실시예에 따르면, 네트워크는 줌 배율에 대응하는 파라미터를 생성하여 매핑할 수 있다. 일 실시예에 따르면, 네트워크는 학습 결과에 따라 네트워크가 지정된 줌 모드에서 사용할(또는 적용 가능한) 파 라미터를 생성할 수 있다. 일 실시예에 따르면, 프로세서는 학습 결과에 기반한 파라미터를 지정된 줌 모 드의 줌 배율에 매핑할 수 있다. 예를 들어, 프로세서는 네트워크에서 사용할 줌 배율 별 SR 네트워 크 파라미터를 룩업 테이블로 관리할 수 있다. 일 실시예에 따르면, 네트워크는 줌 화질 개선을 위한 SR 딥-러닝 학습 기반의 뉴럴 네트워크(Neural Network)일 수 있다. 일 실시예에 따르면, 최근에 저조도 및 SR 화질 개선은 딥-러닝을 이용한 방법이 화질적으 로 우세한 결과를 보여 주고 있다. 본 개시의 일 실시예에서는, 학습 데이터와 GT 이미지를 확보하기 위해 멀티 픽셀 센서의 동일한 출력(예: 넌-베이어 이미지)에 대해 저해상도 기반의 Binning 이미지(예: 학습 데이터)와 고해상도 기반의 Remosaic 이미지(예: 실측 데이터)의 페어(pair)를 SR 딥-러닝 학습에 이용하여, 네 트워크의 파라미터를 제공할 수 있다. 일 실시예에 따르면, 파라미터는 학습에 따라 줌 배율마다 다르게 제공될 수 있다. 도 6을 참조하여 살펴본 바와 같이, 본 개시의 일 실시예에 따르면, 전자 장치는 카메라 모듈(예: 줌 카메라)의 멀티 픽셀 센서를 이용하여, Binning 이미지를 저해상도(LR) 학습 데이터로 사용하고, Remosaic 이미지를 고해상도(HR) GT(예: 실측 데이터)로 사용할 수 있다. 이를 통해, 본 개시의 일 실시예에 따른 전자 장치는, 학습 동작(예: 학습 장치로서 동작)에서, 딥-러닝 학습에 필요한 학습 데이터와 GT 간 이미지 확 보 문제를 해결할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는, 실질적인 사용 동작(예: 영상 촬영 시 줌 기능을 수행하는 장치로서 동작)에서, 전자 장치에서의 Remosaic 처리 시간과 멀티 픽셀 센서 의 모드 전환에 따른 이슈를 해결할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 네트워크를 이용하여 Remosaic에 따른 고해상도 이미지를 제공할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 네트워크를 이용하여 스틸 이미지(still image) 뿐만 아니라, 처리 시간 및 모드 전환에 따른 이슈가 있는 프리뷰 이미지(preview image) 및 비디오(video)에서 고해상도 이미지를 제공하는 초고해상도(SR, super resolution)(예: UHD(3840 x 2160))의 줌(예: SR 줌)을 제공할 수 있다. 예를 들어, SR 줌은 저해상도(LR, low resolution) 이미지를 고해상도(HR, high resolution) 이미지로 변환하는 줌을 나타내며, 화질 개선을 동반한 줌 방식을 의미할 수 있다. 본 개시에서는 저해상도 이미지를 고해상도로 변환하는 SR 줌의 화질 개선을 지원할 수 있다. 일 실시예에 따르면, 본 개시에서 SR 줌은 줌 배율에 근거하여 크롭된 Binning 이미지에 대해 SR 딥- 러닝 학습이 적용된 줌을 나타낼 수 있다. 일 실시예에 따르면, SR 딥-러닝 학습에 있어서 학습 데이터와 GT 이미지(예: 실측 데이터) 확보는 SR 성능에 중요 요인일 수 있고, 실질적으로 동일 시점의 학습 데이터와 GT 이미지가 확보되어야, 학습 데이터의 결과와 개선 목표인 GT 간의 Loss Function의 최소화를 통해 목표 성능을 확보할 수 있다. 본 개시의 일 실시예에 따르 면, SR 딥-러닝 학습에 필요한 학습 데이터와 GT 이미지는, 예를 들어, 전자 장치에서 실질적으로 동일 시 간에서 확보한 이미지(예: 전자 장치에 의해 촬영되는 이미지)을 이용하여 학습 데이터와 GT 이미지의 페어를 구성할 수 있다. 이를 통해, 전자 장치는 멀티 픽셀 센서를 모드 전환 없이 넌-베이어 멀티 픽 셀만을 출력하도록 동작하고, 넌-베이어 멀티 픽셀에 따른 동일한 넌-베이어 이미지를 전자 장치의 프로세 서를 통해 Binning 처리하고, 서버를 통해 Remosaic 이미지를 변환하도록 동작할 수 있다. 이에 기반 하여, 전자 장치는 실질적으로 동일한 t 시간에서의 저해상도 학습 데이터와 고해상도 GT 이미지의 페어를 구하고, 이를 이용하여 SR 딥-러닝 학습의 결과 파라미터(parameters)(예: 네트워크 파라미터)를 전자 장치 의 네트워크에 반영할 수 있다. 일 실시예에 따르면, 전자 장치는 디지털 크롭 줌(digital crop zoom)의 화질 개선이 필요한 배율을 정의 할 수 있다. 예를 들어, 전자 장치는 이미지 크롭 후 오리지널(original) 이미지 사이즈를 만들기 위해 적 용된 업스케일(upscale)로 인한 화질 열화를 SR 딥-러닝을 통해 개선하기 위한 줌 배율을 정의할 수 있다. 일 실시예에 따르면, 개선 가능한 줌 배율은 멀티 픽셀 센서의 NxN 조건을 따를 수 있다. 예를 들어, 멀티 픽셀 센서가 멀티 픽셀 2x2의 센서인 경우 x2 배율을 화질 개선을 위한 목표 줌 배율로 정의할 수 있다. 예를 들어, 멀티 픽셀 센서가 멀티 픽셀 3x3의 센서인 경우 x3 배율을 화질 개선을 위한 목표 줌 배율로 정의할 수 있다, 예를 들어, 멀티 픽셀 센서가 멀티 픽셀 4x4의 센서인 경우 x4 배율을 화질 개선을 위한 목표 줌 배율로 정의할 수 있다. 본 개시의 일 실시예들이 이제 제한하는 것은 아니며, 전술한 줌 배율 외의 다 른 다양한 줌 배율로도 정의될 수 있다. 본 개시의 일 실시예에 따르면, 전자 장치는 SR 딥-러닝이 적용될 줌 구간에서 학습 데이터를 위한 저해상 도 이미지는 Binning 처리 후 줌 배율에 따른 크롭을 통해 획득할 수 있다. 일 실시예에 따르면, 딥-러닝을 위 한 입력은 네트워크의 구성에 따라 크롭된 이미지 또는 크롭 후 업스케일 이미지 모두 사용 가능하다. 일 실시예에 따르면, 전자 장치는 프로세서(예: ISP) 내에 업스케일 이미지 처리 알고리즘(예: bi- linear interpolation, bi-cubic interpolation, 및/또는 image fusion)을 적용하여, 전자 장치의 네트워 크의 입력이 지연 없이 처리 가능하도록 할 수 있다. 본 개시의 일 실시예에 따르면, SR 딥-러닝에서 GT를 위한 고해상도 이미지는 전자 장치의 Binning 처리 시 사용한 동일한 멀티 픽셀 센서의 넌-베이어 이미지를 이용할 수 있다. 예를 들어, 서버는 전자 장 치의 멀티 픽셀 센서의 넌-베이어 이미지를 수신하고, 전자 장치로부터 수신된 멀티 픽셀 센서 의 넌-베이어 이미지를 서버의 RDI를 통해 메모리에 저장할 수 있다. 일 실시예에 따르면, 서버는 메모리에 저장된 넌-베이어 이미지를 지정된 하드웨어 또는 소프트웨어 Remosaic 알고리즘을 이용하여 고해상도 및 고화질의 Remosaic 이미지(예: 고해상도 이미지)를 획득할 수 있다. 일 실시예에 따른 Remosaic 알고리즘은 화질 우선의 Remosaic 알고리즘을 적용할 수 있다. 일 실시예에 따르면, 화질 우선의 Remosaic 알고리즘의 경우, GT를 구하기 위한 처리 시간 및 전류 소모가 연산 량에 따라 증가할 수 있으나, 본 개시의 일 실시예에서는 GT를 구하기 위한 처리는 서버에 의해 처리될 수 있고, 전자 장치 에서 GT는 SR 딥-러닝 학습에만 이용함에 따라, 전자 장치의 네트워크에서는 GT를 구하기 위한 처리 시간 및 전류 소모와 같은 이슈는 발생하지 않을 수 있다. 본 개시의 일 실시예에 따르면, 전자 장치는 전술한 동작을 통해 획득한 저해상도 학습 데이터와 고해상도 GT의 페어를 이용하여 SR 딥-러닝을 통해 학습할 수 있다. 일 실시예에서, 딥-러닝은 네트워크의 구성에 따라 저해상도 학습 데이터의 입력에 대해 크롭한 이미지 또는 크롭 후 업스케일을 적용한 업스케일 이미지 중 선택하여 학습 가능하다. 일 실시예에 따르면, 최종 SR 딥-러닝 결과는 전자 장치에 적용된 네트워크의 파라미터(parameters) 로 출력될 수 있다. 일 실시예에 따르면, 전자 장치의 네트워크의 입력은 멀티 픽셀 센서의 넌- 베이어 이미지를 이용한 Binning 이미지를 사용할 수 있다. 따라서, 본 개시에서는 멀티 픽셀 센서가 적용 된 줌 카메라(예: x3 배율의 줌 카메라)의 출력은 모두 멀티 픽셀 센서의 넌-베이어 이미지가 이용될 수 있다. 일 실시예에 따르면, 전자 장치는 멀티 픽셀 센서의 넌-베이어 이미지에 대해 ISP를 이용한 영 상 처리를 통해 생성된 Binning 이미지를 이용하여 x3 줌과 x3.1 ~ x5,9 줌까지의 디지털 크롭 줌 이미지를 제 공할 수 있다. 일 실시예에 따르면, 전자 장치는 멀티 픽셀 센서의 넌-베이어 이미지에 대해 x6 줌에 서는 ISP를 이용한 영상 처리를 통해 생성된 Binning 이미지를 SR 딥-러닝에서 학습된 네트워크를 이 용하여 지정된 파라미터에 기반하여 업스케일 함으로써, 열화 없는 줌 이미지를 제공할 수 있다. 따라서, 본 개 시의 실시예에 따르면, 줌 카메라에 적용된 멀티 픽셀 센서의 모드 전환 및 Remosaic 처리 없이 Binning이미지만으로 고화질의 줌 이미지를 제공할 수 있다. 예를 들어, 종래에서는, 멀티 픽셀 센서가 Binning 이미지를 기본으로 사용하고, 고해상도가 필요한 시나리오에서 모드 전환에 따라 Remosaic 이미지를 사용하여 고해상도 이미지를 출력하도록 할 수 있다. 하지만, Remosaic 이미지는 실시간 처리가 어렵고, 저조도에서 노이 즈가 열세할 수 있다. 이에, 본 개시의 실시예에서는, 멀티 픽셀 센서가 Binning 이미지만을 사용하도록 동작하고, Binning 이미지를 사용하여 학습된 결과의 Remosaic GT를 이용한 고해상도 이미지를 출력하도록 할 수 있다. 본 개시의 일 실시예에 따르면, 전자 장치는, 학습 동작(예: 학습 장치로서 동작)에서는, 멀티 픽셀 센서 를 통해 넌-베이어(non-Bayer) 이미지를 출력하도록 동작할 수 있다. 본 개시의 일 실시예에 따르면, 전자 장치는, 실질적인 사용 동작(예: 영상 촬영 시 줌 기능을 수행하는 장치로서 동작)에서는, 멀티 픽셀 센서 를 통해 넌-베이어 이미지 출력과 Binning 이미지 출력이 모두 가능하도록 동작할 수 있다. 본 개시의 일 실시예에 따르면, SR 딥-러닝이 적용된 줌 배율(예: x6 배율) 이상의 줌 구간(예: x6 ~ x12 줌 구 간)에 대해서는, 예를 들어, SR 딥-러닝 출력 기반 SR 디지털 크롭 줌(예: 도 9의 예시)과 SR 딥-러닝 출력 기 반 고 배율 SR 줌(예: 도 10의 예시)을 선택적으로 제공할 수 있다. 이의 예가 도 9 및 도 10에 도시된다. 도 9는 본 개시의 일 실시예에 따른 멀티 픽셀 센서 기반 딥-러닝 줌 시나리오의 예를 나타낼 수 있다. 도 10은 본 개시의 일 실시예에 따른 멀티 픽셀 센서 기반 딥-러닝 줌 시나리오의 예를 나타낼 수 있다. 일 실시예에 따라, 도 9는 SR 딥-러닝 출력 기반 SR 디지털 크롭 줌 동작의 예를 나타낼 수 있다. 예를 들어, 도 9는 SR 1차 딥-러닝 x12배 줌 시나리오의 예를 나타낼 수 있다. 일 실시예에 따라, SR 디지털 크롭 줌은, SR 딥-러닝이 적용된 네트워크를 통해 업스케일 시에도 화질 열화가 없는 줌 이미지를 구할 수 있다. 예를 들 어, SR 줌(예: x3 배율의 멀티 픽셀 센서를 이용한 SR 딥-러닝 학습이 적용된 x6배 줌) 이상의 배율에서는 디지털 크롭 줌 적용이 가능하다. 일 실시예에서, SR 줌은 줌 배율에 근거하여 크롭된 Binning 이미지에 대해 SR 딥-러닝 학습이 적용된 줌을 나타낼 수 있다. 일 실시예에서, SR 디지털 크롭 줌이 적용된 이미지는 SR 딥- 러닝 학습과 별개로 SR 줌 출력 이미지에 대해 디지털 크롭 줌이 적용된 이미지를 나타낼 수 있다. 일 실시예에 따르면, SR 디지털 크롭 줌 적용을 통해, 특정 배율(예: x6배 줌 결과를 기준으로 디지털 크롭 줌이 적용된 x2 배(예: x6.1 ~ x12 배율의 구간)까지는 업스케일에 따른 화질 열화가 적은 이미지를 구할 수 있으며, ISP 내 영상 처리 화질 개선 적용을 통해 별도의 처리 시간은 필요하지 않을 수 있다. 일 실시예에 따라, 도 9의 예시와 같이, SR 딥-러닝이 적용된 줌 배율(예: x6배)을 기준으로 배율이 증가할 수 록, SR 디지털 크롭에 의한 화질 열화가 발생할 수도 있다. 예를 들어, 디지털 크롭 줌에 따른 업스케일 화질 열화가 유사하게 발생할 수 있다. 이에, 본 개시의 일 실시예에서는 SR 딥-러닝을 확장하여 SR 디지털 크롭에 의한 화질 열화가 발생하는 줌 배율(예: x12배, 예를 들어, 디지털 크롭 x2배 이상에서 화질 열화가 발생하는 x12.1 이상의 배율)에서 2차 SR 딥-러닝 학습을 이용한 네트워크를 이용하여 화질을 보다 개선할 수 있다. 일 실시예에 따라, 도 10은 SR 딥-러닝 출력 기반 고 배율 SR 줌 동작의 예를 나타낼 수 있다. 예를 들어, 도 10은 SR 1차 및 2차 딥-러닝 x12배 이상의 줌 시나리오의 예를 나타낼 수 있다. 일 실시예에 따라, 도 10에서는, 예를 들어, ISP의 Binning 이미지(예: 도 9의 x6배에 적용된 SR 줌을 이용한 SR 디지털 크롭 줌 에 의한 화질 열화가 발생하는 줌 배율(예: x12.1 이상의 배율)에서 화질 개선을 지원하는 예를 나타낼 수 있다. 일 실시예에 따르면, 전자 장치는 학습 동작에서 2차 딥-러닝에 기반하여 고 배율 SR 줌을 위한 학 습 데이터를 구성할 수 있고, 영상 촬영에 따른 고 배율 SR 줌 동작 시에 미리 학습된 2차 딥-러닝에 관한 학습 데이터를 이용하여 고 배율 SR 줌을 지원하도록 동작할 수 있다. 예를 들어, 도 10의 예시에서는, 멀티 픽셀 센 서의 Binning이 적용된 줌 x6 크롭 이미지에 대응하는 학습 데이터 기준으로, GT 이미지는 48MP Remosaic 처리에 따른 12MP Crop 이미지로 구현될 수 있다. 일 실시예에 따르면, 도 10에서는, 2차 SR 딥-러닝은, 예를 들어, 4x4 멀티 픽셀 센서(예: 200MP 센서)를 기준으로 12M 1/4 Binning, 50MP 1/2 Binning, 200MP Remosaic의 출력을 이용하여 동작하는 예를 나타낼 수 있 다. 일 실시예에 따르면, 전자 장치는 x3 배율의 줌은 4x4 12MP Binning 처리된 Binning 이미지를 이용하 고, x3.1 ~ x5.9 배율까지의 줌은 Binning 이미지에 디지털 크롭 줌을 처리한 디지털 크롭 이미지를 이용할 수 있다. 일 실시예에 따르면, 전자 장치는 x6 배율의 줌에서는, x6 배율에 대해 학습된 학습 데이터(예: Binning 크롭 저해상도 학습 데이터)와 학습 데이터에 대응하는 실측 데이터(예: 2x2 Binning 50MP 고해상도 GT)를 페어로 학습된(예: SR 1차 딥-러닝이 학습) 데이터를 이용하여 동작할 수 있다. 일 실시예에 따르면, 전자 장치는 학습 시에, 네트워크의 입력으로, 4x4 Binning 데이터를 이용할 수 있다. 그리고, x6.1 ~x 11.9 배율까지는 SR 줌 출력을 이용한 디지털 크롭 줌을 적용하고, x12배의 고 배율 줌 에서는 딥-러닝 학습을 위해 SR 줌 기반 디지털 크롭 줌을 저해상도 학습 데이터로, 200MP Remosaic 이미지를 고해상도 GT 페어로 학습함으로써, SR 2차 딥-러닝이 학습될 수 있다. 일 실시예에 따르면, 전자 장치는, 촬영에 따른 줌 동작 시에, SR 2차 딥-러닝의 학습 데이터를 이용하여 네트워크의 파라미터를 구하고, 이를 전자 장치의 네트워크에 적용하여, 고 배율에서의 고화질 의 줌 이미지를 제공하도록 할 수 있다. 여기서, 전자 장치의 네트워크는 1차 및 2차 SR 딥-러닝 학 습을 통한 파라미터 변경을 통해 줌 배율에 따라 유동적으로 동작할 수 있다. 도 11은 본 개시의 일 실시예에 따른 전자 장치의 동작 예를 설명하기 위한 도면이다. 일 실시예에 따르면, 도 11에서는 전자 장치에서 하이브리드 줌 동작의 일 예를 나타낼 수 있다. 일 실시 예에 따르면, 도 11의 예시에서는, 저해상도 이미지 및 고해상도 이미지를 이용하여 SR 딥-러닝 학습에 기반한 학습 데이터에 줌 배열에 따른 파라미터를 적용하여 줌 기능을 제공하는 일 예를 나타낼 수 있다. 예를 들어, 도 11의 예시에서는 전자 장치의 네트워크(예: SR Network)를 이용하여 개선된 화질을 갖는 고 배율 줌 기능을 설명한다. 도 11을 참조하면, 일 실시예에 따른 전자 장치는 카메라 모듈(예: 도 1 또는 도 2의 카메라 모듈 ), 프로세서(예: 도 1 또는 도 3의 프로세서)를 포함할 수 있다. 일 실시예에서, 도시하지는 않 았으나, 전자 장치는 메모리(예: 도 1 또는 도 3의 메모리)를 포함할 수 있다. 일 실시예에 따르면, 도 11에 도시된 전자 장치의 구성 요소는 도 6을 참조한 설명 부분에서 설명한 바와 같은 전자 장치 의 구성 요소에 대응할 수 있으며, 구체적인 설명은 생략한다. 일 실시예에 따라, 도 11에서, 카메라 모듈은 지정된 배율의 줌 카메라를 나타낼 수 있고, 멀티 픽셀의 구 조를 갖는 멀티 픽셀 센서를 포함할 수 있다. 일 실시예에서, 멀티 픽셀 센서는 동일한 컬러 필터 (color filter)를 공유하는 픽셀들의 조합이 2x2, 3x3 또는 4x4와 같은 복수개의 NxN 픽셀들의 조합으로 이루어 진 멀티 픽셀 구조의 넌-베이어 패턴(non-Bayer pattern)의 이미지 센서를 나타낼 수 있다. 일 실시예에 따르면, 전자 장치는 이미지를 촬영하는 동작 중에 사용자 입력에 기반한 줌 동작을 수행할 수 있다. 일 실시예에 따르면, 전자 장치는 줌 동작 시에 멀티 픽셀 센서의 넌-베이어(non-Bayer) 이 미지(예: 이미지 데이터)을 획득할 수 있다. 예를 들어, 멀티 픽셀 센서의 출력은 멀티 픽셀의 형태 인 넌-베이어 이미지를 포함할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서는 카메라 모듈의 렌즈(예: 도 2의 렌즈 어셈블리)로부터 로우 데이터(raw data)를 수신할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서는 멀티 픽셀 센서의 CFA(color filter array) 패턴(예: 넌-베이어 패턴)에 따라 CFA 데이터(예: 넌-베이어 이미지)을 출력할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서의 출력(예: 넌-베이어 이미지는 전자 장치의 프로세서 로 입력될 수 있다. 일 실시예에 따르면, 프로세서(예: 도 3의 ISP)는 수신된 넌-베이어 이미지에 대해 Binning 처 리를 수행할 수 있다(블록 1101). 일 실시예에 따르면, 전자 장치는 멀티 픽셀 센서에서 출력된 넌- 베이어 기반 출력(예: 2x2, 3x3 또는 4x4의 넌-베이어 패턴의 넌-베이어 이미지)에 대해 Binning 처리(블 록 1101)를 통해 픽셀 평균 머지(pixel average merge)를 통한 감도 비가 우수한 Binning 이미지(예: 저 해상도의 베이어 이미지)를 획득할 수 있다. 일 실시예에서, Binning 이미지는 저해상도 이미지를 나타낼 수 있다. 또한 멀티 픽셀 센서의 출력은 센서 내부의 프로세서를 통하여 Binning 처리를 수행할 수 있다. 이 경우, 센서의 출력은 별도의 Binning 처리 없이 ISP로 바로 입력될 수 있다. 일 실시예에 따르면, 프로세서는 Binning 이미지를 ISP를 통해 이미지 시그널 프로세싱(image signal processing)을 수행할 수 있다(블록 1103). 예를 들어, 프로세서는 Binning 이미지를 ISP를 통해 디모자익(demosaic), 음영 보정, 색감 보정, 노이즈 제거, 및 선명도 조정과 같은 영상 처리를 수행할 수 있다. 일 실시예에 따르면, 프로세서는 영상 처리에 따른 결과 데이터를 출력할 수 있다. 일 실시예에 따르면, 프로세서는 Binning 이미지의 영상 처리를 통해 획득된 결과 데이터를 대응하는 줌 배율에 따라 출력할 수 있다. 일 실시예에 따르면, 프로세서는 결과 데이터를 적용된 줌 구간에 따라 주밍(zooming)하고, 주밍된 이미지를 디스플레이(예: 도 1 또는 도 3의 디스플레이 모듈)상에 표시할 수 있다. 일 실시예에 따르면, 프로세서는 x3 배율의 줌 카메라에서 적용된 줌 배율이 x3 배율의 줌인 경우, 결과 데이터에 기반하여 x3 줌을 적용하여 출력할 수 있다. 일 실시예에 따르면, 프로세서는 x3 배율의 줌 카메라에서 적용된 줌 배율이 x3.1 ~ x5.9 배율의 줌인 경우 결과 데이터를 대응하는 줌 배율에 맞게 디지털 크롭 후 업스케일하여 출력할 수 있다. 일 실시예에 따르면, 프로세서는 x3 배율의 줌 카메라에서 지정된 배율(예: 고 배율) 이상의 줌 배율(예: x6 배율 이상의 줌)의 줌인 경우 결과 데이터에 대응하는 학습 데이터에 매칭된 파라미터를 이용하여 대 응하는 줌을 적용하여 출력할 수 있다. 예를 들어, 프로세서는 지정된 배율 이상의 줌에서는 네트워크 로부터 결과 데이터에 대응하는 학습 데이터에 매칭된 파라미터를 식별하고, 현재 촬영에 설정된 파 라미터를 학습 데이터에 기반한 파라미터로 변경하고, 변경된 파라미터에 따른 줌 배율에 따라 결과 데이터 를 디지털 크롭 후 업스케일하여 출력할 수 있다. 일 실시예에 따르면, 전자 장치의 네트워크 는 줌 배율마다 설정된 파라미터를 룩업 테이블로 관리할 수 있다. 일 실시예에 따르면, 네트워크는 줌 화 질 개선을 위한 SR 딥-러닝 학습 기반의 뉴럴 네트워크(Neural Network)일 수 있다. 이상에서 살펴본 바와 같이, 본 개시의 실시예들에 따르면, 전자 장치의 줌 카메라의 화질을 개선할 수 있 다. 예를 들어, 줌 카메라의 고정된 줌 배율 외의 보다 고 배율의 줌 배율에서의 줌 이미지 화질을 개선할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서를 이용한 줌 화질 및 사용 시나리오를 개선할 수 있다. 예를 들어, 전자 장치는 전자 장치의 줌 카메라의 멀티 픽셀 센서의 Remosaic 변환을 위한 로직(예: Remosaic 알고리즘)이 불필요할 수 있고, 멀티 픽셀 센서에서 Remosaic 출력의 Binning 또는 Remosaic을 위한 모드 전환이 불필요할 수 있다. 일 실시예에 따르면, 전자 장치는 멀티 픽셀 센서의 동일한 출 력을 이용하여 전자 장치에서의 저해상도 이미지(예: Binning 저해상도 학습 데이터)과 서버에서의 고해상도 이미지(또는 실측 데이터)(예: Remosaic 고해상도 GT 이미지)을 페어로 하는 싱크 이미지(sync imag e)를 확보할 수 있다. 일 실시예에 따르면, 전자 장치는 저해상도 이미지와 고해상도 이미지의 페어를 SR 딥-러닝 학습에 이용하여, 전자 장치의 네트워크의 파라미터를 대응하는 줌 배열에 따라 적응적으로 변경할 수 있고, 파라미터 변경을 통해 SR 줌을 확장할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는, 디스플레이 모듈(예: 도 1 또는 도 3의 디스플레이 모듈), 통신 회로(예: 도 1의 무선 통신 모듈), 복수개의 카메라들을 포함하는 카메라 모듈(예: 도 1 내지 도 3의 카메라 모듈), 및 상기 디스플레이 모듈, 상기 통신 회로 및 상기 카메라 모듈과 작동적으로 연결된 프로 세서(예: 도 1, 도 3, 도 6 또는 도 9의 프로세서)를 포함할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 카메라 모듈을 통해 이미지 데이터를 획득하도록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 이미지 데이터에 기반하여 비닝(Binning) 처리를 수행 하고, 상기 이미지 데이터를 상기 통신 회로를 통해 서버로 전송하도록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 비닝 처리에 기반하여 비닝 이미지를 획득하도록 동작할 수 있다. 일 실시예에 따 르면, 상기 프로세서는, 상기 비닝 이미지에 기반하여 학습 데이터를 획득하도록 동작할 수 있다. 일 실시 예에 따르면, 상기 프로세서는, 상기 서버로부터 상기 이미지 데이터를 기반으로 생성된 실측 데이터를 획 득하도록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 학습 데이터와 상기 실측 데이터에 기반하여 줌 배율에 대한 학습을 수행하도록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 줌 배율에 대응하는 파라미터를 생성하여 매핑하도록 동작할 수 있다. 일 실시예에 따르면, 상기 복수개의 카메라들은, 제1 배율의 메인 카메라 및 상기 메인 카메라의 출력을 위한 이미지 센서를 포함할 수 있다. 일 실시예에 따르면, 상기 복수개의 카메라들은, 상기 제1 배율보다 큰 제2 배 율의 적어도 하나의 줌 카메라 및 상기 적어도 하나의 줌 카메라의 출력을 위한 멀티 픽셀 센서(MPS, multi pixel sensor)를 포함할 수 있다. 일 실시예에 따르면, 상기 이미지 데이터는 넌-베이어(non-Bayer) 이미지를 포함할 수 있다. 일 실시예에 따르 면, 상기 학습 데이터는 상기 넌-베이어 이미지에 기반하여 저해상도 베이어로 변환된 상기 비닝 이미지가 영상 처리된 데이터를 포함할 수 있다. 일 실시예에 따르면, 상기 실측 데이터는 상기 서버에 의해 상기 넌-베이어 이미지에 기반하여 고해상도 베이어로 변환된 리모자익(Remosaic) 이미지를 포함할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 사용자 입력에 기반하여 학습 동작과 관련된 어플리케이션을 실행 하고, 상기 어플리케이션 실행에 기반하여 상기 복수개의 카메라들 중 지정된 배율의 줌 카메라를 실행하고, 상기 줌 카메라의 멀티 픽셀 센서로부터 상기 이미지 데이터를 획득할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 멀티 픽셀 센서에서 출력된 넌-베이어 이미지에 대해 비닝 처 리를 통해 픽셀 평균 머지(pixel average merge)를 수행하고, 상기 비닝 처리 동작에 병렬적으로, 상기 넌-베이 어 이미지를, 상기 통신 회로를 통해, 상기 서버로 전송할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 프로세서는 뉴럴 네트워크(neural network)를 포함할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 뉴럴 네트워크를 이용하여, 상기 학습 데이터와 상기 실측 데이터에 기반하여 상기 줌 배율에 대한 학습을 수행할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 지정된 줌 모드에서 동일한 입력으로부터 생성된 상기 학습 데이터 와 상기 실측 데이터의 페어(pair)를 이용하여, 상기 뉴럴 네트워크를 통해, 딥-러닝(deep-learning) 기반의 학 습을 수행할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 학습 결과에 따라 뉴럴 네트워크가 지정된 줌 모드에서 사용할 파 라미터를 생성하고, 상기 파라미터를 지정된 줌 모드의 줌 배율에 매핑하여, 줌 배율 별 파라미터를 룩업 테이 블로 관리할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 사용자 입력에 기반하여 영상 촬영과 관련된 어플리케이션을 실행 하도록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 어플리케이션 실행에 기반하여, 영상 촬영을 수행하는 동안, 줌 실행을 위한 사용자 입력을 수신하도록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 사용자 입력에 기반하여 상기 복수개의 카메라들 중 지정된 배율의 줌 카메라를 실행하 도록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 줌 카메라의 멀티 픽셀 센서로부터 이 미지 데이터를 획득하도록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 이미지 데이터에 기반하여 비닝 처리를 수행하도록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 비닝 처리에 기반하여 비닝 이미지를 획득하도록 동작 할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 비닝 이미지에 기반하여 결과 데이터를 획득하도 록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 사용자 입력에 기반한 줌 배율이 제1 배 율에 해당하는 경우, 상기 결과 데이터를 줌 배율에 대응하여 제1 줌 처리하도록 동작할 수 있다. 일 실시예에 따르면, 상기 프로세서는, 상기 사용자 입력에 기반한 줌 배율이 상기 제1 배율보다 큰 제2 배율에 해당하 는 경우, 상기 제2 배율에 대응하는 파라미터에 기반하여 상기 결과 데이터를 제2 줌 처리하도록 동작할 수 있 다. 일 실시예에 따르면, 상기 프로세서는, 상기 제2 배율에 대해, 대응하는 학습 데이터에 기반하여 뉴럴 네 트워크에서 사용할 파라미터를 결정하고, 상기 제2 배율에 설정된 파라미터를 상기 결정된 파라미터로 변경하고, 변경된 파라미터에 따른 줌 배율에 따라 상기 결과 데이터를 디지털 크롭 후 업스케일하여 출력할 수 있다. 이하에서는 다양한 실시예들의 전자 장치의 동작 방법에 대해서 상세하게 설명한다. 다양한 실시예들에 따 른 전자 장치에서 수행하는 동작들은, 전자 장치의 다양한 프로세싱 회로(various processing circuitry) 및/또는 실행 가능한 프로그램 요소(executable program elements)를 포함하는 프로세서에 의 해 실행될 수 있다. 일 실시예에 따라, 전자 장치에서 수행하는 동작들은, 메모리에 저장되고, 실행 시에, 프로세서가 동작하도록 하는 인스트럭션들(instructions)에 의해 실행될 수 있다. 도 12는 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 일 실시예에 따라, 도 12는 일 실시예에 따른 전자 장치에서 영상 촬영 시에 사용자의 주밍에 따른 줌 배 율에 따라 적용될 파라미터를 위한 학습 방법을 지원하는 예를 나타낼 수 있다. 본 개시의 일 실시예에 따른 전자 장치에서, 학습 방법은, 예를 들어, 도 12에 도시된 흐름도에 따라 수행 될 수 있다. 도 12에 도시된 흐름도는 전자 장치의 학습 방법의 일 실시예에 따른 흐름도에 불과하며, 적 어도 일부 동작의 순서는 변경되거나 병렬적으로 수행되거나, 독립적인 동작으로 수행되거나, 또는 적어도 일부 다른 동작이 적어도 일부 동작에 보완적으로 수행될 수 있다. 본 개시의 일 실시예에 따르면, 동작 1201 내지 동작 1215는 전자 장치의 적어도 하나의 프로세서에서 수행될 수 있다. 일 실시예에 따르면, 도 12에서 설명되는 동작은, 예를 들어, 도 3 내지 도 11에서 설명된 동작들에 결합하여 휴리스틱(heuristic)하게 수행되거나, 설명된 동작들의 적어 일부 동작의 상세 동작으로 휴리스틱하게 수행될수 있다. 도 12에 도시한 바와 같이, 일 실시예에 따른 전자 장치가 수행하는 동작 방법(예: SR 줌을 지원하기 위한 학습 방법)은, 카메라 모듈의 이미지 데이터를 획득하는 동작, 이미지 데이터에 기반하여 Binning 처리를 수행 및 이미지 데이터를 서버로 전송하는 동작, Binning 이미지를 획득하는 동작, Binning 이미지에 대해 영상 처리를 수행하는 동작, 학습 데이터를 획득하는 동작, 서버로부 터 실측 데이터를 획득하는 동작, 학습 데이터와 실측 데이터에 기반하여 줌 배율에 대한 학습을 수행하 는 동작, 및 줌 배율에 대응하는 파라미터를 생성하여 매핑하는 동작을 포함할 수 있다. 도 12를 참조하면, 동작 1201에서, 전자 장치의 프로세서는 카메라 모듈의 이미지 데이터를 획 득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 사용자 입력에 기반하여 학습 동작과 관 련된 어플리케이션(예: 카메라 어플리케이션)을 실행할 수 있다. 일 실시예에 따르면, 프로세서는 어플리 케이션 실행에 기반하여 카메라 모듈을 실행(또는 활성화)할 수 있다. 일 실시예에 따르면, 프로세서(12 0)는 카메라 모듈을 통해 획득되는 이미지(예: 프리뷰 이미지(preview image))를 표시하도록 디스플레이 모듈을 제어할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 실행하는 사용자 입력을 감지 하는 것에 기반하여 영상 촬영을 시작할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 수행하는 동안 줌 실행(예: 주밍)을 위한 사용자 입력을 수 신할 수 있고, 사용자 입력에 기반하여 카메라 모듈의 줌 기능을 실행(예: 줌 카메라 활성화)할 수 있다. 예를 들어, 프로세서는 이미지를 촬영하는 동작 중에 사용자 입력에 기반한 줌 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 카메라 모듈의 복수개의 카메라들 중 지정된 배율에 대응하는 줌 카메 라를 실행하고, 줌 카메라의 멀티 픽셀 센서로부터 이미지 데이터를 획득할 수 있다. 일 실시예에 따르면, 프로세서는 줌 동작 시에 멀티 픽셀 센서의 이미지 데이터를 획득할 수 있다. 일 실시예에서, 이미지 데이터는 넌-베이어(non-Bayer) 이미지를 포함할 수 있다. 예를 들어, 멀티 픽셀 센서 의 출력은 멀티 픽셀의 넌-베이어 패턴에 기반한 넌-베이어 이미지를 포함할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서는 영상 촬영을 수행하는 동안, 카메라 모듈의 렌즈(예: 마이크로 렌즈)로부 터 가공되지 않은 로우 데이터(raw data)를 수신할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서는 멀티 픽셀 센서의 CFA(color filter array) 패턴(예: 넌-베이어 패턴)에 따라 CFA 데이터(예: 넌-베이어 이미 지)을 출력할 수 있다. 동작 1203에서, 프로세서는 이미지 데이터에 기반하여 Binning 처리를 수행 및 이미지 데이터를 서버(63 0)로 전송하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 수신된 넌-베이어 이미지에 대해 Binning 처리를 수행할 수 있다. 일 실시예에 따르면, 프로세서는 멀티 픽셀 센서에서 출력된 넌-베 이어 기반 출력(예: 2x2, 3x3 또는 4x4의 넌-베이어 패턴의 넌-베이어 이미지)에 대해 Binning 처리를 통해 픽 셀 평균 머지(pixel average merge)를 수행할 수 있다. 일 실시예에 따르면, 프로세서는 Binning 처리 동 작에 병렬적으로(또는 휴리스틱하게) 멀티 픽셀 센서로부터 수신된 이미지 데이터를, 통신 회로(예: 도 1 의 무선 통신 모듈)를 통해, 지정된 서버로 전송할 수 있다. 동작 1205에서, 프로세서는 Binning 이미지를 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로 세서는 Binning 처리를 통해 픽셀 평균 머지에 기반한 감도 비가 우수한 Binning 이미지(예: 저해상도의 베이어 이미지)을 획득할 수 있다. 일 실시예에서, Binning 이미지는 저해상도 이미지를 나타낼 수 있다. 동작 1207에서, 프로세서는 Binning 이미지에 대해 영상 처리하는 동작을 수행할 수 있다. 일 실시예에 따 르면, 프로세서는 Binning 이미지를 ISP를 통해 이미지 시그널 프로세싱(image signal processing) 을 수행할 수 있다. 예를 들어, 프로세서는 Binning 이미지를 디모자익(demosaic), 음영 보정, 색감 보정, 노이즈 제거, 및 선명도 조정과 같은 영상 처리를 수행할 수 있다. 동작 1209에서, 프로세서는 학습 데이터를 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세 서는 ISP에 기반한 영상 처리에 따른 학습 데이터를 출력할 수 있다. 동작 1211에서, 프로세서는 서버로부터 실측 데이터를 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 서버로부터 멀티 픽셀 센서의 이미지 데이터(예: 넌-베이어 이미지)를 화질 우선의 Remosaic 알고리즘에 기반하여 Remosaic된 고화질의 이미지(예: Remosaic 이미지))를, 통신 회로(예: 도 1의 무선 통신 모듈)를 통해 수신할 수 있다. 동작 1213에서, 프로세서는 학습 데이터와 실측 데이터에 기반하여 줌 배율에 대해 학습하는 동작을 수행 할 수 있다. 일 실시예에 따르면, 프로세서는, 네트워크(예: 뉴럴 네트워크)를 통해, 학습 데이터(예: 변환된 Binning 이미지)와 실측 데이터(예: Remosaic 이미지)의 페어에 기반한 딥-러닝 기반의 학습 을 수행할 수 있다. 예를 들어, 프로세서는, 지정된 줌 모드에서 동일한 입력(예: 멀티 픽셀 센서의 넌-베이어 이미지)으로부터 생성된 학습 데이터와 실측 데이터의 페어를 이용하여 네트워크에서 학습할 수 있다. 동작 1215에서, 프로세서는 줌 배율에 대응하는 파라미터를 생성하여 매핑하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 학습 결과에 따라 네트워크가 지정된 줌 모드에서 사용할(또는 적용 가 능한) 파라미터를 생성할 수 있다. 일 실시예에 따르면, 프로세서는 학습 결과에 기반한 파라미터를 지정 된 줌 모드의 줌 배율에 매핑할 수 있다. 예를 들어, 프로세서는 네트워크에서 사용할 줌 배율 별 파 라미터를 룩업 테이블로 관리할 수 있다. 도 13은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 일 실시예에 따라, 도 13은 일 실시예에 따른 전자 장치에서 영상 촬영 시에 사용자의 주밍에 따른 줌 배 율에 따라 파라미터를 변경하여 SR 줌을 지원하는 예를 나타낼 수 있다. 본 개시의 일 실시예에 따른 전자 장치에서, 영상 촬영 시에 SR 줌을 지원하는 방법은, 예를 들어, 도 13 에 도시된 흐름도에 따라 수행될 수 있다. 도 13에 도시된 흐름도는 전자 장치의 SR 줌 동작의 일 실시예 에 따른 흐름도에 불과하며, 적어도 일부 동작의 순서는 변경되거나 병렬적으로 수행되거나, 독립적인 동작으로 수행되거나, 또는 적어도 일부 다른 동작이 적어도 일부 동작에 보완적으로 수행될 수 있다. 본 개시의 일 실시 예에 따르면, 동작 1301 내지 동작 1319는 전자 장치의 적어도 하나의 프로세서에서 수행될 수 있다. 일 실시예에 따르면, 도 13에서 설명되는 동작은, 예를 들어, 도 3 내지 도 11에서 설명된 동작들에 결합하여 휴리스틱하게 수행되거나, 설명된 동작들의 적어 일부 동작의 상세 동작으로 휴리스틱하게 수행될 수 있다. 도 13에 도시한 바와 같이, 일 실시예에 따른 전자 장치가 수행하는 동작 방법(예: SR 줌을 지원하기 위한 영상 처리 방법)은, 카메라 모듈의 이미지 데이터를 획득하는 동작, 이미지 데이터에 기반하여 Binning 처리를 수행하는 동작, Binning 이미지를 획득하는 동작, Binning 이미지에 대해 영상 처 리를 수행하는 동작, 결과 데이터를 획득하는 동작, 지정된 줌 구간의 줌 동작인지 판단하는 동작 , 지정된 줌 구간의 줌 동작이 아닌 경우, 결과 데이터를 줌 배율에 대응하여 제1 줌 처리하는 동작 , 지정된 줌 구간의 줌 동작인 경우, 줌 배율에 대응하는 파라미터를 결정하는 동작, 파라미터에 기반하여 제2 줌 처리하는 동작, 및 줌 처리에 따른 이미지를 출력하는 동작을 포함할 수 있다. 도 13을 참조하면, 동작 1301에서, 전자 장치의 프로세서는 카메라 모듈의 이미지 데이터를 획 득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 사용자 입력에 기반하여 영상 촬영과 관 련된 어플리케이션(예: 카메라 어플리케이션)을 실행할 수 있다. 일 실시예에 따르면, 프로세서는 어플리 케이션 실행에 기반하여 카메라 모듈을 실행(또는 활성화)할 수 있다. 일 실시예에 따르면, 프로세서(12 0)는 카메라 모듈을 통해 획득되는 이미지(예: 프리뷰 이미지(preview image))을 표시하도록 디스플레이 모듈을 제어할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 실행하는 사용자 입력을 감지 하는 것에 기반하여 영상 촬영을 시작할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 수행하는 동안 줌 실행(예: 주밍)을 위한 사용자 입력을 수 신할 수 있고, 사용자 입력에 기반하여 카메라 모듈의 줌 기능을 실행(예: 줌 카메라 활성화)할 수 있다. 예를 들어, 프로세서는 이미지를 촬영하는 동작 중에 사용자 입력에 기반한 줌 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 카메라 모듈의 복수개의 카메라들 중 지정된 배율에 대응하는 줌 카메 라를 실행하고, 줌 카메라의 멀티 픽셀 센서로부터 이미지 데이터를 획득할 수 있다. 일 실시예에 따르면, 프로세서는 줌 동작 시에 멀티 픽셀 센서의 이미지 데이터를 획득할 수 있다. 일 실시예에서, 이미지 데이터는 넌-베이어(non-Bayer) 이미지를 포함할 수 있다. 예를 들어, 멀티 픽셀 센서 의 출력은 멀티 픽셀의 넌-베이어 패턴에 기반한 넌-베이어 이미지를 포함할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서는 영상 촬영을 수행하는 동안, 카메라 모듈의 렌즈(예: 마이크로 렌즈)로부 터 가공되지 않은 로우 데이터(raw data)를 수신할 수 있다. 일 실시예에 따르면, 멀티 픽셀 센서는 멀티 픽셀 센서의 CFA(color filter array) 패턴(예: 넌-베이어 패턴)에 따라 CFA 데이터(예: 넌-베이어 이미 지)을 출력할 수 있다. 동작 1303에서, 프로세서는 이미지 데이터(예: 넌-베이어 이미지)에 기반하여 Binning 처리하는 동작을 수 행할 수 있다. 일 실시예에 따르면, 프로세서는 수신된 넌-베이어 이미지에 대해 Binning 처리를 수행할 수 있다. 일 실시예에 따르면, 프로세서는 멀티 픽셀 센서에서 출력된 넌-베이어 기반 출력(예: 2x2, 3x3 또는 4x4의 넌-베이어 패턴의 넌-베이어 이미지)에 대해 Binning 처리를 통해 픽셀 평균 머지(pixel average merge)를 수행할 수 있다. 동작 1305에서, 프로세서는 Binning 이미지를 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로 세서는 Binning 처리를 통해 픽셀 평균 머지에 기반한 감도 비가 우수한 Binning 이미지(예: 저해상도의 베이어 이미지)를 획득할 수 있다. 일 실시예에서, Binning 이미지는 저해상도 이미지를 나타낼 수 있다. 동작 1307에서, 프로세서는 Binning 이미지에 대해 영상 처리하는 동작을 수행할 수 있다. 일 실시예에 따 르면, 프로세서는 Binning 이미지를 ISP를 통해 이미지 시그널 프로세싱(image signal processing) 을 수행할 수 있다. 예를 들어, 프로세서는 Binning 이미지를 디모자익(demosaic), 음영 보정, 색감 보정, 노이즈 제거, 및 선명도 조정과 같은 영상 처리를 수행할 수 있다. 동작 1309에서, 프로세서는 결과 데이터를 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세 서는 ISP에 기반한 영상 처리에 따른 결과 데이터를 출력할 수 있다. 동작 1311에서, 프로세서는 지정된 줌 구간의 줌 동작인지 여부를 판단하는 동작을 수행할 수 있다. 일 실 시예에 따르면, 프로세서는 사용자 입력에 기반한 줌 동작을 위한 줌 배율이 제1 배율(예: 고정된 줌 배율 범위(예: x3배의 줌 배율 또는 x3.1 ~ x5.9배의 줌 배율))에 해당하는지, 또는 제1 배율보다 큰 제2 배율(예: 지정된 고 배율(예: x6 배율) 이상의 줌 배율(예: SR 줌 배율))에 해당하는지 판단할 수 있다. 일 실시예에서, 지정된 줌 구간은, 예를 들어, 제1 배율보다 큰 제2 배율을 포함하는 구간을 나타낼 수 있다. 동작 1311에서, 프로세서는 지정된 줌 구간의 줌 동작이 아닌 경우(예: 동작 1311의 ‘아니오’), 동작 1313에서, 결과 데이터를 줌 배율에 대응하여 제1 줌 처리하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프 로세서는 x3 배율의 줌 카메라에서 적용된 줌 배율이 x3 배율인 경우, 결과 데이터에 기반하여 x3 줌을 적 용하여 출력할 수 있다. 일 실시예에 따르면, 프로세서는 x3 배율의 줌 카메라에서 적용된 줌 배율이 x3.1 ~ x5.9 배율의 줌인 경우 결과 데이터를 대응하는 줌 배율에 맞게 디지털 크롭 후 업스케일하여 출력할 수 있다. 동작 1311에서, 프로세서는 지정된 줌 구간의 줌 동작인 경우(예: 동작 1311의 ‘예’), 동작 1315에서, 줌 배율에 대응하는 파라미터를 결정하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 x3 배 율의 줌 카메라에서 지정된 고 배율(예: x6 배율) 이상의 줌 배율(예: SR 줌 배율)인 경우, 결과 데이터에 대응 하는 학습 데이터에 매칭된 파라미터를 결정할 수 있다. 예를 들어, 프로세서는 지정된 배율 이상의 줌에 서는 네트워크로부터 결과 데이터에 대응하는 학습 데이터를 추출하고, 학습 데이터에 기반하여 네트워크 (예: 뉴럴 네트워크)에서 사용할 파라미터를 결정할 수 있다. 일 실시예에 따르면, 프로세서는 네트 워크에서 사용할 파리미터의 설정을 실시간으로 전환할 수 있다. 동작 1317에서, 프로세서는 파라미터에 기반하여 제2 줌 처리하는 동작을 수행할 수 있다. 일 실시예에 따 르면, 결정된 파라미터를 이용하여 대응하는 줌을 적용하여 출력할 수 있다. 일 실시예에 따르면, 프로세서 는 현재 촬영에 설정된 파라미터를 학습 데이터에 기반한 파라미터로 변경하고, 변경된 파라미터에 따른 줌 배율에 따라 결과 데이터를 디지털 크롭 후 업스케일하여 출력할 수 있다. 동작 1319에서, 프로세서는 줌 처리에 따른 이미지를 출력하는 동작을 수행할 수 있다. 일 실시예에 따르 면, 프로세서는 동작 1313의 제1 줌 처리 동작 또는 동작 1317의 제2 줌 처리 동작에 따른 이미지를 출력 하도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 Binning 이미지의 영상 처리를 통해 획득된 결과 데이터를 대응하는 줌 배율에 따라 출력할 수 있다. 일 실시예에 따르면, 프로세서는 결과 데이터를 적용 된 줌 구간에 따라 주밍(zooming)하고, 주밍된 이미지를 디스플레이(예: 도 1 또는 도 3의 디스플레이 모듈 ) 상에 표시할 수 있다. 상기 전자 장치의 카메라 모듈을 통해 이미지 데이터를 획득하는 동작 수행을 포함할 수 있다. 상기 동작 방법 은, 상기 이미지 데이터에 기반하여 비닝(Binning) 처리를 수행하고, 상기 이미지 데이터를 통신 회로를 통해 서버로 전송하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 비닝 처리에 기반하여 비닝 이미지를 획 득하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 비닝 이미지에 기반하여 학습 데이터를 획득하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 서버로부터 상기 이미지 데이터를 기반으로 생성된 실측 데이터를 획득하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 학습 데이터와 상기 실측 데이터에 기반하여 줌 배율에 대한 학습을 수행하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 줌 배율에 대응 하는 파라미터를 생성하여 매핑하는 동작 수행을 포함할 수 있다. 일 실시예에 따르면, 상기 이미지 데이터는 넌-베이어(non-Bayer) 이미지를 포함할 수 있다. 일 실시예에 따르 면, 상기 학습 데이터는 상기 넌-베이어 이미지에 기반하여 저해상도 베이어로 변환된 상기 비닝 이미지가 영상 처리된 데이터를 포함할 수 있다. 일 실시예에 따르면, 상기 실측 데이터는 상기 서버에 의해 상기 넌-베이어 이미지에 기반하여 고해상도 베이어로 변환된 리모자익(Remosaic) 이미지를 포함할 수 있다. 일 실시예에 따르면, 상기 이미지 데이터를 획득하는 동작은, 사용자 입력에 기반하여 학습 동작과 관련된 어플 리케이션을 실행하는 동작, 상기 어플리케이션 실행에 기반하여 상기 복수개의 카메라들 중 지정된 배율의 줌 카메라를 실행하는 동작, 상기 줌 카메라의 멀티 픽셀 센서(MPS, multi pixel sensor)로부터 상기 이미지 데이 터를 획득하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 비닝 처리 및 상기 전송하는 동작은, 상기 멀티 픽셀 센서에서 출력된 넌-베이어 이 미지에 대해 비닝 처리를 통해 픽셀 평균 머지(pixel average merge)를 수행하는 동작, 상기 비닝 처리 동작에 병렬적으로, 상기 넌-베이어 이미지를, 상기 통신 회로를 통해, 상기 서버로 전송하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 학습을 수행하는 동작은, 뉴럴 네트워크(neural network)를 이용하여, 상기 학습 데 이터와 상기 실측 데이터에 기반하여 상기 줌 배율에 대한 학습을 수행하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 학습을 수행하는 동작은, 지정된 줌 모드에서 동일한 입력으로부터 생성된 상기 학습 데이터와 상기 실측 데이터의 페어(pair)를 이용하여, 상기 뉴럴 네트워크를 통해, 딥-러닝(deep-learning) 기 반의 학습을 수행하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 매핑하는 동작은, 학습 결과에 따라 뉴럴 네트워크가 지정된 줌 모드에서 사용할 파 라미터를 생성하는 동작, 상기 파라미터를 지정된 줌 모드의 줌 배율에 매핑하여, 줌 배율 별 파라미터를 룩업 테이블로 관리하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 사용자 입력에 기반하여 영상 촬영과 관련된 어플리케이션을 실행하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 어플리케이션 실행에 기반하여, 영상 촬영을 수행하는 동 안, 줌 실행을 위한 사용자 입력을 수신하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 사용자 입력 에 기반하여 상기 복수개의 카메라들 중 지정된 배율의 줌 카메라를 실행하는 동작 수행을 포함할 수 있다. 상 기 동작 방법은, 상기 줌 카메라의 멀티 픽셀 센서로부터 이미지 데이터를 획득하는 동작 수행을 포함할 수 있 다. 상기 동작 방법은, 상기 이미지 데이터에 기반하여 비닝 처리를 수행하는 동작 수행을 포함할 수 있다. 상 기 동작 방법은, 상기 비닝 처리에 기반하여 비닝 이미지를 획득하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 비닝 이미지에 기반하여 결과 데이터를 획득하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 사용자 입력에 기반한 줌 배율이 제1 배율에 해당하는 경우, 상기 결과 데이터를 줌 배율에 대응하여 제1 줌 처리하는 동작 수행을 포함할 수 있다. 상기 동작 방법은, 상기 사용자 입력에 기반한 줌 배율이 상기 제1 배율보다 큰 제2 배율에 해당하는 경우, 상기 제2 배율에 대응하는 파라미터에 기반하여 상기 결과 데이터를 제 2 줌 처리하는 동작 수행을 포함할 수 있다. 일 실시예에 따르면, 상기 제2 줌 처리하는 동작은, 상기 제2 배율에 대해, 대응하는 학습 데이터에 기반하여 뉴럴 네트워크에서 사용할 파라미터를 결정하는 동작, 상기 제2 배율에 설정된 파라미터를 상기 결정된 파라미 터로 변경하는 동작, 변경된 파라미터에 따른 줌 배율에 따라 상기 결과 데이터를 디지털 크롭 후 업스케일하여 출력하는 동작을 포함할 수 있다. 본 명세서와 도면에 개시된 본 개시의 다양한 실시예들은 본 개시의 기술 내용을 쉽게 설명하고 본 개시의 이해 를 돕기 위해 특정 예를 제시한 것일 뿐이며, 본 개시의 범위를 한정하고자 하는 것은 아니다. 따라서 본 개시 의 범위는 여기에 개시된 실시예들 이외에도 본 개시의 기술적 사상을 바탕으로 도출되는 모든 변경 또는 변형 된 형태가 본 개시의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2022-0185438", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면 설명과 관련하여, 동일 또는 유사한 구성 요소에 대해서는 동일 또는 유사한 참조 부호가 사용될 수 있다. 도 1은 다양한 실시예들에 따른 네트워크 환경 내의 전자 장치의 블록도이다. 도 2는 다양한 실시예들에 따른 카메라 모듈을 예시하는 블록도이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치의 구성을 개략적으로 도시하는 도면이다. 도 4는 일 실시예에 따른 전자 장치에서 하이브리드 줌 시나리오의 일 예를 도시하는 도면들이다. 도 5는 일 실시예에 따른 전자 장치에서 하이브리드 줌 시나리오의 일 예를 도시하는 도면이다. 도 6은 본 개시의 일 실시예에 따른 학습 데이터를 위한 학습 시스템 및 그 동작 예를 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른 멀티 픽셀 센서의 비닝 동작 예의 설명을 위해 도시하는 도면이다. 도 8은 본 개시의 일 실시예에 따른 멀티 픽셀 센서의 리모자익 동작 예의 설명을 위해 도시하는 도면이다. 도 9는 본 개시의 일 실시예에 따른 멀티 픽셀 센서 기반 딥-러닝 줌 시나리오의 예를 나타낼 수 있다. 도 10은 본 개시의 일 실시예에 따른 멀티 픽셀 센서 기반 딥-러닝 줌 시나리오의 예를 나타낼 수 있다. 도 11은 본 개시의 일 실시예에 따른 전자 장치의 동작 예를 설명하기 위한 도면이다. 도 12는 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 도 13은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다."}
