{"patent_id": "10-2024-0129855", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0046205", "출원번호": "10-2024-0129855", "발명의 명칭": "무선 통신 시스템에서 채널 상태 정보를 보고하는 방법 및 장치", "출원인": "주식회사 아이티엘", "발명자": "박동현"}}
{"patent_id": "10-2024-0129855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법에 있어서,단말이 AI(artificial intelligence) 채널 상태 정보(channel state information, CSI) 보고를 위한 업링크 자원을 할당 받는 단계;상기 업링크 자원에 기초하여 AI CSI 페이로드 크기 조정 여부를 결정하는 단계; 및상기 AI CSI 페이로드 크기를 조정한 경우, 조정된 상기 AI CSI 페이로드 크기에 기초하여 상기 업링크 자원을통해 상기 AI CSI 보고를 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0129855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 AI CSI 보고를 위한 상기 업링크 자원이 충분한 경우, 상기 단말은 상기 업링크 자원을 통해 상기 AI CSI보고를 수행하고,상기 AI CSI 보고를 위한 상기 업링크 자원이 충분하지 않은 경우, 상기 AI CSI 페이로드 크기를 조정하는, 방법."}
{"patent_id": "10-2024-0129855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 AI CSI 페이로드 크기는 AI CSI 모델 성능, 신뢰도 및 채널 환경 중 적어도 어느 하나에 기초하여 결정된양자화 방법에서 AI 인코더 출력 크기를 조정하여 수행되는, 방법."}
{"patent_id": "10-2024-0129855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,AI 인코더는 AI CSI 입력들에 기초하여 결정된 상기 양자화 방법을 통해 AI 인코딩 및 양자화 절차를 수행하여AI 인코더 출력을 생성하되,상기 AI 인코더 출력은 AI 인코더 출력 크기와 출력 노드 당 양자화 비트 수를 통해 도출되는 비트 스트링이고, 상기 AI 인코더 출력 크기, 상기 출력 노드 당 양자화 비트 수 및 상기 비트 스트링 중 적어도 어느 하나를 조정하여 상기 AI CSI 페이로드 크기를 조정하는, 방법."}
{"patent_id": "10-2024-0129855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,조정된 상기 AI CSI 페이로드 크기에 기초하여 상기 업링크 자원이 상기 AI CSI 보고를 수행하기에 충분한경우, 상기 단말은 상기 업링크 자원을 통해 상기 AI CSI 보고를 수행하고,조정된 상기 AI CSI 페이로드 크기에 기초하여 상기 업링크 자원이 상기 AI CSI 보고를 수행하기에 충분하지 않은 경우, 상기 단말은 AI 인코더 출력의 적어도 하나의 서브 시퀀스 중 일부 서브 시퀀스에 대한 전송을 생략하공개특허 10-2025-0046205-3-는, 방법."}
{"patent_id": "10-2024-0129855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 AI 인코더 출력은 적어도 하나의 AI 인코더 각각에 대응되는 서브 시퀀스에 기초하여 상기 적어도 하나의서브 시퀀스를 포함하되,상기 적어도 하나의 AI 인코더 각각에 대응되는 서브 시퀀스는 AI 인코더 우선순위에 기초하여 높은 우선순위를갖는 서브 시퀀스 순서로 AI CSI 페이로드에 할당되는, 방법."}
{"patent_id": "10-2024-0129855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,AI 인코더 각각은 레이어, 랭크, 서브 밴드 및 포트 중 적어도 어느 하나에 대응되고, 상기 AI 인코더 우선순위는 상기 AI 인코더 각각에 대응되는 상기 레이어, 랭크, 서브 밴드 및 포트 중 적어도어느 하나에 기초하여 결정되는, 방법."}
{"patent_id": "10-2024-0129855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서,AI 인코더 각각은 AI CSI 콘텐츠에 대응되고, 상기 AI 인코더 우선순위는 상기 AI 인코더 각각에 대응되는 상기 AI CSI 콘텐츠에 기초하여 결정되는, 방법."}
{"patent_id": "10-2024-0129855", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "무선 사용 장치에 있어서,적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 의해 상기 무선 사용자 장치가 특정 동작을 수행하도록 하는 명령들(instructions)을 저장하는 메모리를 포함하고,상기 특정 동작은:AI(artificial intelligence) 채널 상태 정보(channel state information, CSI) 보고를 위한 업링크 자원을 할당 받고,상기 업링크 자원에 기초하여 AI CSI 페이로드 크기 조정 여부를 결정하고, 및상기 AI CSI 페이로드 크기를 조정한 경우, 조정된 상기 AI CSI 페이로드 크기에 기초하여 상기 업링크 자원을통해 상기 AI CSI 보고를 수행하는, 장치."}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "무선 통신 시스템에서 단말이 AI(artificial intelligence) 채널 상태 정보(channel state information, CSI) 보고를 위한 업링크 자원을 할당 받는 단계, 업링크 자원에 기초하여 AI CSI 페이로드 크기 조정 여부를 결정하 는 단계 및 AI CSI 페이로드 크기를 조정한 경우, 조정된 AI CSI 페이로드 크기에 기초하여 업링크 자원을 통해 AI CSI 보고를 수행하는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 무선 통신 시스템에서 채널 상태 정보(channel state information, CSI)를 보고하는 방법 및 장치에 대한 것이다. 구체적으로, 무선 통신 시스템에서 인공지능 머신러닝(artificial intelligence/machine learning, AI/ML) 기반 시스템을 위한 CSI를 보고하는 방법 및 장치에 대한 것이다."}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "ITU(International Telecommunication Union)에서는 IMT(International Mobile Telecommunication) 프레임워 크 및 표준에 대해서 개발하고 있으며, 최근에는 \"IMT for 2020 and beyond\"라 칭하여지는 프로그램을 통하여 5 세대(5G) 통신을 위한 논의를 진행 중이다. \"IMT for 2020 and beyond\"에서 제시하는 요구사항들을 충족하기 위해서, 3GPP(3rd Generation Partnership Project) NR(New Radio) 시스템은 다양한 시나리오, 서비스 요구사항, 잠재적인 시스템 호환성 등을 고려하여, 시간-주파수 자원 단위 기준에 대한 다양한 뉴머롤로지(numerology)를 지원하는 방향으로 논의되고 있다. 또한, 5G 통신은 높은 캐리어 주파수(carrier frequency) 상에서 발생하는 높은 경로-손실(path-loss), 페이즈 -잡음(phase-noise), 주파수 오프셋(frequency offset) 등의 좋지 않은 채널 환경을 극복하고자 복수의 빔을 통 한 물리 신호 또는 물리채널의 전송을 지원할 수 있다. 이를 통해서 5G 통신은 eMBB(enhanced Mobile Broadband), mMTC(massive Machine Type Communications), URLLC(Ultra Reliable and Low Latency Communication) 등의 애플리케이션을 지원할 수 있다."}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 과제는 무선 통신 시스템에서 AI/ML 모델 입력 및 출력 중 적어도 어느 하나에 해당하는 채널 상태 정보(channel state information, CSI) 보고를 수행하는 방법 및 장치에 대한 것이다. 본 개시의 기술적 과제는 무선 통신 시스템에서 AI(artificial intelligence) CSI 보고를 수행하는 방법 및 장 치에 대한 것이다. 본 개시의 기술적 과제는 무선 통신 시스템에서 UCI(uplink control information)전송을 위해 스케줄링된 업링 크 자원을 고려하여 AI CSI 페이로드 크기를 조정하는 방법 및 장치에 대한 것이다. 본 개시의 기술적 과제는 무선 통신 시스템에서 복수 개의 AI 인코더에 대응되는 각각의 서브 시퀀스를 업링크 자원에 할당하고, 일부 서브 시퀀스를 생략하는 방법 및 장치에 대한 것이다. 본 개시에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 양상에 따라, 방법에 있어서, 단말이 AI(artificial intelligence) 채널 상태 정보(channel state information, CSI) 보고를 위한 업링크 자원을 할당 받는 단계, 업링크 자원에 기초하여 AI CSI 페이로드 크기 조정 여부를 결정하는 단계 및 AI CSI 페이로드 크기를 조정한 경우, 조정된 AI CSI 페이로드 크기에 기초 하여 업링크 자원을 통해 AI CSI 보고를 수행하는 단계를 포함할 수 있다. 또한, 본 개시의 일 양상에 따라, 무선 사용자 장치에 있어서, 적어도 하나의 프로세서 및 적어도 하나의 프로 세서에 의해 무선 사용자 장치가 특정 동작을 수행하도록 하는 명령들(instructions)을 저장하는 메모리를 포함 하고, 특정 동작은: AI(artificial intelligence) 채널 상태 정보(channel state information, CSI) 보고를 위 한 업링크 자원을 할당 받고, 업링크 자원에 기초하여 AI CSI 페이로드 크기 조정 여부를 결정하고, 및 AI CSI 페이로드 크기를 조정한 경우, 조정된 AI CSI 페이로드 크기에 기초하여 업링크 자원을 통해 AI CSI 보고를 수 행할 수 있다. 또한, 다음의 사항들은 동일하게 적용될 수 있다. 본 개시의 일 양상에 따라, AI CSI 보고를 위한 업링크 자원이 충분한 경우, 단말은 업링크 자원을 통해 AI CSI 보고를 수행하고, AI CSI 보고를 위한 업링크 자원이 충분하지 않은 경우, AI CSI 페이로드 크기를 조정할 수 있다.또한, 본 개시의 일 양상에 따라, AI CSI 페이로드 크기는 AI CSI 모델 성능, 신뢰도 및 채널 환경 중 적어도 어느 하나에 기초하여 결정된 양자화 방법에서 AI 인코더 출력 크기를 조정하여 수행될 수 있다. 또한, 본 개시의 일 양상에 따라, 단말 측 모델 내 AI 인코더는 AI CSI 입력들에 기초하여 결정된 양자화 방법 을 통해 AI 인코딩 및 양자화 절차를 수행하여 AI 인코더 출력을 생성하되, AI 인코더 출력은 AI 인코더 출력 크기와 출력 노드 당 양자화 비트 수를 통해 도출되는 비트 스트링이고, AI 인코더 출력 크기, 출력 노드 당 양 자화 비트 수 및 비트 스트링 중 적어도 어느 하나를 조정하여 AI CSI 페이로드 크기를 조정할 수 있다. 또한, 본 개시의 일 양상에 따라, AI 인코더 출력은 양자화 스텝(quantization step)과 범위(range)를 기반으로 가장 높거나 신뢰성 있는 출력 값을 기준으로 상이한 보고(differential reporting) 동작을 통해 추가적인 출력 값들을 함께 보고할 수 있다. 또한, 본 개시의 일 양상에 따라, 조정된 AI CSI 페이로드 크기에 기초하여 업링크 자원이 AI CSI 보고를 수행 하기에 충분한 경우, 단말은 업링크 자원을 통해 AI CSI 보고를 수행하고, 조정된 AI CSI 페이로드 크기에 기초 하여 업링크 자원이 AI CSI 보고를 수행하기에 충분하지 않은 경우, 단말은 AI 인코더 출력의 적어도 하나의 서 브 시퀀스 중 일부 서브 시퀀스에 대한 전송을 생략할 수 있다. 또한, 본 개시의 일 양상에 따라, AI 인코더 출력은 적어도 하나의 AI 인코더 각각에 대응되는 서브 시퀀스에 기초하여 적어도 하나의 서브 시퀀스를 포함하되, 적어도 하나의 AI 인코더 각각에 대응되는 서브 시퀀스는 AI 인코더 우선순위에 기초하여 높은 우선순위를 갖는 서브 시퀀스 순서로 AI CSI 페이로드에 할당될 수 있다. 또한, 본 개시의 일 양상에 따라, AI 인코더 각각은 레이어, 랭크, 서브 밴드 및 포트 중 적어도 어느 하나에 대응되고, AI 인코더 우선순위는 AI 인코더 각각에 대응되는 레이어, 랭크, 서브 밴드 및 포트 중 적어도 어느 하나에 기초하여 결정될 수 있다. 또한, 본 개시의 일 양상에 따라, AI 인코더 각각은 AI CSI 콘텐츠에 대응되고, AI 인코더 우선순위는 AI 인코 더 각각에 대응되는 AI CSI 콘텐츠에 기초하여 결정될 수 있다."}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 무선 통신 시스템에서 CSI 보고를 수행하는 방법을 제공할 수 있다. 본 개시에 따르면, 무선 통신 시스템에서 AI CSI 보고를 수행하는 방법을 제공할 수 있다. 본 개시에 따르면, 무선 통신 시스템에서 CSI 보고를 수행하는 방법을 제공할 수 있다. 본 개시에 따르면, 무선 통신 시스템에서 AI CSI 보고를 수행하는 방법을 제공할 수 있다. 본 개시에 따르면, 무선 통신 시스템에서 UCI 전송을 위해 스케줄링된 업링크 자원을 고려하여 AI CSI 페이로드 크기를 조정하는 방법을 제공할 수 있다. 본 개시에 따르면, 무선 통신 시스템에서 복수 개의 AI 인코더에 대응되는 각각의 서브 시퀀스를 업링크 자원에 할당하고, 일부 서브 시퀀스를 생략하는 방법을 제공할 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 본 개시의 실시예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙인다. 본 개시에 있어서, 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\" 또는 \"접속\"되어 있다고 할 때, 이는 직접 적인 연결 관계 뿐만 아니라, 그 중간에 또 다른 구성요소가 존재하는 간접적인 연결관계도 포함할 수 있다. 또 한 어떤 구성요소가 다른 구성요소를 \"포함한다\" 또는 \"가진다\"고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 배제하는 것이 아니라 또 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 있어서, 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용되 며, 특별히 언급되지 않는 한 구성요소들 간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 개시의 범 위 내에서 일 실시예에서의 제1 구성요소는 다른 실시예에서 제2 구성요소라고 칭할 수도 있고, 마찬가지로 일 실시예에서의 제2 구성요소를 다른 실시예에서 제1 구성요소라고 칭할 수도 있다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위함이며, 구성요소들이 반드 시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위 로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 다양한 실시예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들은 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시예도 본 개시의 범위에 포함된다. 또한, 다양한 실시예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시예도 본 개시의 범위에 포함된다. 본 개시는 무선 통신 네트워크를 대상으로 설명하며, 무선 통신 네트워크에서 이루어지는 동작은 해당 무선 통 신 네트워크를 관할하는 시스템(예를 들어 기지국)에서 네트워크를 제어하고 신호를 송신 또는 수신하는 과정에 서 이루어지거나, 해당 무선 네트워크에 결합한 단말에서 신호를 송신 또는 수신하는 과정에서 이루어질 수 있 다. 기지국을 포함하는 다수의 네트워크 노드들(network nodes)로 이루어지는 네트워크에서 단말과의 통신을 위해 수행되는 다양한 동작들은 기지국 또는 기지국 이외의 다른 네트워크 노드들에 의해 수행될 수 있음은 자명하다. '기지국(BS: Base Station)'은 고정국(fixed station), Node B, eNodeB(eNB), ng-eNB, gNodeB(gNB), 액세스 포인트(AP: Access Point) 등의 용어에 의해 대체될 수 있다. 또한, '단말(terminal)'은 UE(User Equipment), MS(Mobile Station), MSS(Mobile Subscriber Station), SS(Subscriber Station), 비-AP 스테이션 (non-AP STA) 등의 용어로 대체될 수 있다. 본 개시에서, 채널을 전송 또는 수신한다는 것은 해당 채널을 통해서 정보 또는 신호를 전송 또는 수신한다는 의미를 포함한다. 예를 들어, 제어 채널을 전송한다는 것은, 제어 채널을 통해서 제어 정보 또는 신호를 전송한 다는 것을 의미한다. 유사하게, 데이터 채널을 전송한다는 것은, 데이터 채널을 통해서 데이터 정보 또는 신호 를 전송한다는 것을 의미한다. 이하의 설명에 있어서, 본 개시의 다양한 예시들이 적용되는 시스템을 기존의 시스템과 구별하기 위한 목적으로 NR(New Radio) 시스템이라는 용어를 사용하지만, 본 개시의 범위가 이러한 용어에 의해 제한되는 것은 아니다. NR 시스템에서는 다양한 시나리오, 서비스 요구사항 및 잠재적인 시스템 호환성 등을 고려하며 다양한 서브캐리 어 스페이싱(Subcarrier Spacing, SCS)을 지원하고 있다. 또한, NR 시스템은 높은 캐리어 주파수(carrier frequency) 상에서 발생하는 높은 방향-손실(path-loss), 페이즈-잡음(phase-noise) 및 주파수 오프셋 (frequency offset) 등의 좋지 않은 채널 환경을 극복하고자 복수의 빔을 통한 물리 신호/채널의 전송을 지원할 수 있다. 이를 통해, NR 시스템에서는 eMBB(enhanced Mobile Broadband), mMTC(massive Machine Type Communications)/uMTC(ultra Machine Type Communications) 및 URLLC(Ultra Reliable and Low Latency Communications) 등의 애플리케이션을 지원할 수 있다. 이하, 5G 이동 통신 기술은, NR 시스템뿐만 아니라, 기존의 LTE-A(Long Term Evolution-Advanced) 시스템 및 LTE(Long Term Evolution) 시스템까지 포함하여 정의될 수 있다. 5G 이통 통신은 새롭게 정의된 NR 시스템뿐만 아니라 이전 시스템과의 역호환성(Backward Compatibility)을 고려하여 동작하는 기술을 포함할 수 있다. 따라 서, 하기 5G 이동 통신은 NR 시스템에 기초하여 동작하는 기술 및 이전 시스템(e.g., LTE-A, LTE)에 기초하여 동작하는 기술을 포함할 수 있으며, 특정 시스템으로 한정되는 것은 아니다.우선, 본 발명이 적용되는 무선 통신 시스템의 물리 자원 구조에 대해서 간략히 설명하고자 한다. 도 1은 본 개시가 적용될 수 있는 NR 프레임 구조를 설명하기 위한 도면이다. NR에서 시간 도메인의 기본 단위는 일 수 있고, 이고, N=4096일 수 있 다. 한편, LTE에서 시간 도메인 기본 단위는 일 수 있고, 이고, =2048일 수 있다. NR 시간 기본 단위와 LTE 시간 기본 단위 사이의 배수 관계에 대한 상수는 k= 로서 정의될 수 있다. 도 1을 참조하면, 하향링크/상향링크(DL/UL) 전송을 위한 프레임의 시간 구조는 를 가질 수 있다. 여기서, 하나의 프레임은 시간에 해당하는 10개의 서브프레임으로 구성된다. 서브프레임마다 연속적인 OFDM 심볼의 수는 = 일 수 있다. 또한, 각 프레임은 동일한 크기의 2개의 하프 프레임(half frame)으로 나누어지며, 하프 프레임 1은 서브 프레임 0-4로 구성되고, 하프 프레임 2는 서브 프레 임 5-9로 구성될 수 있다. 는 하향링크(DL)와 상향링크(UL) 간의 타이밍 어드밴스(TA)를 나타낸다. 여기서, 상향링크 전송 프레임 i 의 전송 타이밍은 단말에서 하향링크 수신 타이밍을 기반으로 아래의 수학식 1에 기초하여 결정된다. [수학식 1]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 은 듀플렉스 모드 (duplex mode) 차이 등으로 발생하는 TA 오프셋 (TA offset) 값일 수 있다. FDD (Frequency Division Duplex)에서 은 0 값을 가지지만, TDD (Time Division Duplex)에서는 DL-UL 스위칭 시간에 대한 마진을 고려해서 의 고정된 값으로 정의될 수 있다. 일 예로, 서브 6GHz이하 주파 수인 FR1(Frequency Range 1)의 TDD(Time Division Duplex)에서 는 39936 또는 25600일 수 있 다. 39936는 20.327μs이고, 25600는 13.030μs이다. 또한, 밀리미터파(mmWave) 주파수인 FR2(Frequency Range 2)에서 는 13792일 수 있다. 이때, 13792는 7.020 μs이다. 도 2는 본 개시가 적용될 수 있는 NR 자원 구조를 나타내는 도면이다. 자원 그리드(resource grid) 내의 자원요소(Resource Element, RE)는 각 서브캐리어 스페이싱에 따라서 인덱싱 될 수 있다. 여기서, 안테나 포트마다 그리고 서브캐리어 스페이싱마다 하나의 자원 그리드를 생성할 수 있다. 상향링크 및 하향링크 송수신은 해당 자원 그리드를 기반으로 수행될 수 있다. 주파수 도메인 상에서 하나의 자원 블록(Resource Block, RB)은 12개의 RE로 구성되며 12개의 RE마다 하나의 RB 에 대한 인덱스(nPRB)를 구성할 수 있다. RB에 대한 인덱스는 특정 주파수 대역 또는 시스템 대역폭 내에서 활 용될 수 있다. RB에 대한 인덱스는 아래의 수학식 2와 같이 정의될 수 있다. 여기서, 는 하나의 RB 당 서 브캐리어의 개수를 의미하고, k는 서브캐리어 인덱스를 의미한다.[수학식 2]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "NR 시스템의 다양한 서비스와 요구사항을 만족하도록 다양한 뉴머롤러지가 설정될 수 있다. 예를 들어, LTE/ LTE-A 시스템에서 하나의 서브캐리어 스페이싱(SCS)을 지원할 수 있으나, NR 시스템에서는 복수의 SCS를 지원할 수 있다. 복수의 SCS를 지원하는 NR 시스템을 위한 새로운 뉴머롤로지는, 700MHz나 2GHz 등의 주파수 범위(frequency range) 또는 캐리어(carrier)에서 넓은 대역폭을 사용할 수 없었던 문제를 해결하기 위해, 3GHz 이하, 3GHz- 6GHz, 6GHZ-52.6GHz 또는 52.6GHz 이상과 같은 주파수 범위 또는 캐리어에서 동작할 수 있다. 아래의 표 1은 NR 시스템에서 지원하는 뉴머롤러지의 예시를 나타낸다. [표 1]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "상기 표 1을 참조하면, 뉴머롤러지는 OFDM(Orthogonal Frequency Division Multiplexing) 시스템에서 사용하는 서브캐리어 스페이싱(SCS), CP(Cyclic Prefix) 길이 및 슬롯당 OFDM 심볼의 수 등을 기준으로 정의될 수 있다. 상기 값들은 하향링크에 대해서 상위계층 파라미터 DL-BWP-mu 및 DL-BWP-cp을 통하여, 상향링크에 대해서 상위 계층 파라미터 UL-BWP-mu 및 UL-BWP-cp을 통해 단말에게 제공될 수 있다. 상기 표 1에서 서브캐리어 스페이싱 설정 인덱스(u)가 2인 경우, 서브캐리어 스페이싱(Δf)은 60kHz이고, 노멀 CP 및 확장 CP(Extended CP)가 적용될 수 있다. 그 외의 뉴머롤러지 인덱스의 경우에는 노멀 CP만 적용될 수 있 다. 노멀 슬롯(normal slot)은 NR 시스템에서 기본적으로 하나의 데이터 및 제어 정보를 전송하는데 사용하는 기본 시간 단위로 정의할 수 있다. 노멀 슬롯의 길이는 기본적으로 14개 OFDM 심볼의 수로 설정될 수 있다. 또한, 슬 롯과 다르게 서브 프레임은 NR시스템에서 1ms에 해당하는 절대적인 시간 길이를 가지고, 다른 시간 구간의 길이 를 위한 참고 시간으로 활용될 수 있다. 여기서, LTE 시스템과 NR 시스템의 공존 또는 호환성(backwardcompatibility)을 위해 LTE의 서브 프레임과 같은 시간 구간이 NR 규격에 필요할 수 있다. 예를 들어, LTE에서 데이터는 단위 시간인 TTI(Transmission Time Interval)에 기초하여 전송될 수 있으며, TTI는 하나 이상의 서브 프레임 단위로 설정될 수 있었다. 여기서, 하나의 서브 프레임은 1ms로 설정될 수 있으 며, 14개의 OFDM 심볼(또는 12개의 OFDM 심볼)이 포함될 수 있다. 또한, NR에서 넌-슬롯 (non-slot)이 정의될 수 있다. 넌-슬롯은 노멀 슬롯보다 적어도 하나의 심볼만큼 작은 수 를 가지는 슬롯을 의미할 수 있다. 예를 들어, URLLC 서비스와 같이 낮은 지연 시간을 제공하는 경우, 노멀 슬 롯보다 작은 심볼 수를 가지는 넌-슬롯을 통해 지연 시간을 줄일 수 있다. 여기서, 넌-슬롯에 포함된 OFDM 심볼 수는 주파수 범위를 고려하여 결정될 수 있다. 예를 들어, 6GHz 이상의 주파수 범위에서는 1 OFDM 심볼 길이의 넌-슬롯을 고려할 수도 있다. 추가적인 예시로서, 넌-슬롯을 정의하는 OFDM 심볼의 수는 적어도 2개의 OFDM 심 볼을 포함할 수 있다. 여기서, 넌-슬롯에 포함되는 OFDM 심볼 수의 범위는 소정의 길이(예를 들어, 노멀 슬롯 길이-1)까지의 미니 슬롯의 길이로서 설정될 수 있다. 다만, 넌-슬롯의 규격으로서 OFDM 심볼 수는 2, 4 또는 7 개의 심볼로 범위가 제한될 수 있으나, 이에 한정되지는 않는다. 또한, 예를 들어, 6GHz 이하의 비면허 대역에서는 u가 1 및 2에 해당하는 서브캐리어 스페이싱이 사용되고, 6GHz 초과의 비면허 대역에서는 u가 3 및 4에 해당하는 서브캐리어 스페이싱이 사용될 수 있다. 예를 들어, u가 4인 경우는 SSB(Synchronization Signal Block)를 위해서 사용될 수도 있다. [표 2]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "표 2는 서브캐리어 스페이싱 설정(u)별로, 노멀 CP의 경우의 슬롯 당 OFDM 심볼 개수(), 프레임 당 슬롯 개수( ), 서브프레임 당 슬롯의 개수( )를 나타낸다. 표 2에서는 14개의 OFDM 심볼을 갖는 노멀 슬롯을 기준으로 상술한 값들을 나타낸다. [표 3]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "표 3은 확장 CP가 적용되는 경우(즉, u가 2인 경우로서 서브캐리어 스페이싱이 60kHz일 때), 슬롯 당 OFDM 심볼 개수가 12인 노멀 슬롯을 기준으로 프레임 당 슬롯의 수 및 서브프레임당 슬롯의 수를 나타낸다. 전술한 같이 하나의 서브프레임은 시간 축 상에서 1ms에 해당할 수 있다. 또한, 하나의 슬롯은 시간 축 상에서 14개의 심볼에 해당할 수 있다. 예를 들어, 하나의 슬롯은 시간 축 상에서 7개의 심볼에 해당할 수 있다. 이에 따라, 하나의 무선 프레임에 해당하는 10ms 내에서 각각의 고려될 수 있는 슬롯 및 심볼 개수가 다르게 설정될 수 있다. 표 4는 각각의 SCS에 따른 슬롯 수 및 심볼 수를 나타낼 수 있다. 표 4에서 480kHz의 SCS는 고려되지 않을 수 있으나, 이러한 예시들로 한정되지 않는다. [표 4]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "단말은 DL(downlink) CSI(channel state information) 보고 절차를 통해 다운링크 CSI 파라미터들(e.g., CQI, PMI, RI, L1-RSRP, etc)을 계산하고, 계산된 CSI 정보를 기지국으로 보고할 수 있다. 기지국은 수신한 CSI 정보 를 다운링크 데이터 전송에 활용할 수 있다. CSI 파라미터들은 채널 상태와 연관된 측정 값으로 기지국은 측정 값을 기반으로 다운링크 데이터 전송을 수행할 수 있다. 기지국은 CSI 파라미터들에 기초하여 데이터 스케줄링 정보를 단말로 지시할 수 있다. 단말은 일반적으로 기지국에 의해서 전송되는 CSI-RS를 수신함으로써 CSI 계산 과 유도된 CSI 파라미터들을 기지국에게 피드백 정보로써 보고한다. 또는, 단말은 CSI-RS에 추가적으로 다른 다 운링크 신호(e.g. SSB(synchronization signal block))을 통해 채널 상태를 측정하고, 측정된 값을 기지국으로 보고할 수 있다. RI(rank indicator) 선택: RI는 CSI 파라미터로 특정 채널 환경에서 다운링크 전송을 위해 사용 가능한 레이어 수를 지칭할 수 있다. RI는 다운링크 전송을 사용할 수 있는 비-연관 경로(uncorrelated path)들의 최대 수를 의미할 수 있다. 여기서, 다 른 CSI 파라미터(e.g. PMI, CQI)는 RI에 의해 제공되는 랭크(rank)를 기반으로 계산될 수 있다. PMI(precoding matrix index) 선택: PMI는 프리코딩 행렬(precoding matrix)에 해당하는 인덱스들의 셋을 포함할 수 있다. 기지국은 단말로부터 보 고된 PMI를 다운링크 전송에 적용할 수 있다. 다만, 기지국은 해당 PMI가 아닌 다른 프리코딩 행렬을 적용할 수 있는 구현의 자유도를 가질 수 있다. 일 예로, 상기 PMI를 위한 프리코딩 행렬을 보고하기 위해서 복수 타입의 코드북이 규격에서 지원될 수 있다. 각각의 코드북 타입에 대해서는 후술한다. 코드북 타입 - Type 1 single-panel codebooks - Type 1 multi-panel codebooks - Type 2 codebooks - Enhanced Type 2 codebooks 일 예로, PMI 선택은 상기와 같은 코드북 타입, RI 값에 의해 대표되는 전송 레이어 수 및 다른 CSI 보고 설정 파라미터(e.g. antenna panel dimensions)에 기초하여 수행될 수 있다. 각 코드북은 프리코딩 행렬들의 셋을 포 함할 수 있다. 일 예로, NR에서는 듀얼 스테이지 프리코딩 메트릭스(dual-stage precoding matrix) 코드북 디자 인이 적용될 수 있지만, 이에 한정되는 것은 아닐 수 있다. 듀얼 스테이지 프리코딩 메트릭스는 하기 수학식 3과 같을 수 있다. 수학식 3에서 W1는 DFT(discrete fourier transform) 빔 또는 코드북 타입에 따른 양쪽 편광(polarization)을 위한 빔 그룹을 나타내는 행렬일 수 있고, W2는 코드북 타입에 따라 하기 중 하나가 선택될 수 있다. W2 코드북 타입 - Beam selection from W1 - Weighting coefficients for the beams in W1 - Cophasing values between two polarizations [수학식 3]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "단말은 코드북 타입으로 \"Type I single-panel codebook\"과 \"Type I multi-panel codebook\"을 위해 선택한 코 드북과 주어진 채널 환경에서 가능한 모든 프리코딩 행렬을 사용하여 수신단에서 가장 높은 SINR(signal interference noise ratio) 값을 나타내는 PMI 값을 계산한다. 일 예로, 타입 1(type 1) 코드북은 SU- MIMO(single user multi input multi output) 시나리오에서 PMI 선택을 위해서 고려될 수 있으나, 이에 한정되 지 않는다. 타입 2(Type II) 코드북은 직교 DFT 빔들의 셋을 고려할 수 있다. 수학식 3에서 W1 행렬은 DFT 빔들에 연관된 정보를 포함하고, PMI 선택 함수는 주어진 채널 환경과 DFT 빔들의 수를 위해 각 직교 빔 그룹 내에 모든 DFT 빔들을 위한 빔 진폭 스케일링(beam amplitude scaling)과 cophasing 값(W2)을 계산한다. 단말은 PMI 선택함수 에 기초하여 i1과 i2 값을 기지국에게 보고할 수 있으며, 각 인덱스들은 최대 SINR 값을 제공하는 프리코딩 행 렬(W)에 해당한다. 타입 2 코드북 기반 PMI는 타입 1 코드북 기반 PMI 보다 더 정확한 채널 정보를 제공할 수 있다. 타입 2 코드북은 복수의 빔들이 채널 고유벡터(eigenvector)의 추정을 위해 적용되기 때문에 더 정확한 채널 정보를 제공할 수 있다. 일 예로, 타입 2 코드북 기반 PMI는 복수의 빔들을 고려하기 때문에 MU(multi)- MIMO 시나리오에서 사용될 수 있으나, 이에 한정되는 것은 아닐 수 있다. 일 예로, 타입 2 코드북은 랭크 2까지 만 지원할 수 있고, 향상된 타입 2 코드북은 오버헤드 감소 방법과 함께 최대 랭크 4까지 지원할 수 있으며, 이 와 관련해서는 후술한다. 또한, 상술한 바에 기초하여 단말이 수행하는 CSI 보고는 명시적 CSI 피드백(explicit CSI feedback) 및 묵시적 CSI 피드백(implicit CSI 피드백)을 고려할 수 있다. 명시적 CSI 피드백은 단말이 측정한 채널 상태를 나타내는 채널 정보(e.g. channel eigenvector/eigenvalue, SVD)를 그대로 피드백하는 방법으로 기지국이 보고된 CSI를 어떻게 처리하는지 여부를 고려하지 않을 수 있다. 반면, 묵시적 CSI 피드백은 가능한 하나의 프리코더 코드북 에서 후보 프리코더 메트릭스 셋 내의 선택된 프리코더 매트릭스(desired precoder matrix) W를 지시하는 방법 일 수 있다. 일 예로, CSI 피드백과 관련된 CSI 파라미터(또는 CSI 콘텐츠)는 하기 표 5와 같을 수 있으나, 이에 한정되는 것은 아닐 수 있다.[표 5]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "하나의 CSI 보고 내의 CSI 콘텐츠는 표 5내의 CSI 파라미터들의 서로 다른 조합에 의해 설정될 수 있다. 여기서, 하나의 CSI 보고 내의 CSI 콘텐츠는 reportQuantity에 의해 설정될 수 있다. 일 예로, \"none\"으로 설정된 경우, 기지국은 비주기적 CSI-RS (aperiodic CSI-RS) 전송을 트리거링 할 수 있다. 비주기적 CSI-RS 전송은 단말에 의해 채널 측정과 수신 파라미터 조정을 위해 트리거링할 수 있으며, 관 련 CSI 보고는 단말에 의해 수행되지 않을 수 있다. 비주기적 CSI-RS 전송은 하기와 같이 동기화 목적의 트래킹 (tracking)을 위한 CSI-RS 또는 TRS(tracking reference signal)의 비주기적 전송이나 단말이 수신 필터를 조 정하기 위한 공간 비주기적 수신 빔 스위핑을 위한 경우일 수 있으나, 이에 한정되는 것은 아닐 수 있다. 하기 동작들은 기지국이 단말에게 비주기적 CSI 보고를 요구하는 것이 아니지만, 비주기적 CSI 요청과 동일한 프레임 워크 내에서 동작할 수 있다. - Aperiodic transmission of the Tracking Reference Signal (TRS or CSI-RS for tracking) - Aperiodic Rx beam sweeping (so called P3 beam sweep) - UE에게 그 Rx spatial received filter를 조정 또한, 하나의 CSI 보고 내의 CSI 콘텐츠는 하기 표 6과 같이 설정될 수 있으나, 이에 한정되는 것은 아닐 수 있 다. 일 예로, 하기 표 6의 CSI 콘텐츠들 조합은 기지국이 어떤 CSI 콘텐츠들의 조합들이 주로 필요할 것인지에 대한 대표적인 조합에 해당하는 것들로 구성 되었다. [표 6]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "일 예로, 표 6의 \"cri-RI-i1\"은 도 3과 같이 \"Hybrid beamformed/non-precoded CSI acquisition operation\"에 기초하여 동작할 수 있다. 기지국은 주로 CSI-RS 자원마다 몇몇 포트를 가진 단말 특정(UE-specifically) beamformed CSI-RS를 CSI 획득(CSI acquisition) 목적을 위해 사용할 수 있다. 다만, 기지국이 각 단말을 위해 CSI-RS를 어떻게 빔포밍할것인지를 인지하기 위해 중간에 non-precoded CSI-RS 자원을 다수의 안테나 포트(e.g. 32 ports)와 함께 전송할 수 있다. 여기서, 단말은 수신한 CSI-RS에 기초하여 전체 안테나 포트(e.g. 32 ports)에 해당하는 PMI를 보고할 수 있으며, 이를 통해 단말은 선호하는 빔 방향을 지시할 수 있다. 일 예로, CSI-RS의 빔포밍은 보고된 프리코더의 광대역/롱-텀 파트(wideband/long-term part)에 기초할 수 있다. 즉, 보고된 W1 메트릭스는 단말 특 정 CSI-RS 빔포밍을 수행하기 위해서 사용될 수 있다. 또한, 숏-텀 서브밴드 CS(short-term/subband CSI)(W2) 는 그 빔포밍 CSI-RS로부터 결정될 수 있다. 일 예로, non-precoded CSI-RS는 CSI-RS 빔포밍을 어떻게 수행하는지 인지하기 위해 사용될 수 있으며, 이 에 기초하여 단말은 W1에 해당하는 CSI 보고만 필요하고, W2에 대한 보고는 필요하지 않을 수 있다. 상술한 바 를 통해 오버헤드가 줄어들 수 있다. 또한, 단말은 특정 송신 안테나 수를 기반으로 PMI를 선택할 수 있다. 구체적으로, 단말은 보고 설정(reporting configuration)에 연관된 구성 CSI-RS(configured CSI-RS)의 안테나 포트 수에 의해 주어지는 특정 송신 안테 나 수를 기반으로 PMI를 선택할 수 있다. 또한, 기지국은 MU-MIMO 스케줄링의 경우에 동시에 스케줄링되는 다른 단말의 간섭이나 채널을 고려하여 타겟 단말에서 보고된 PMI가 아닌 다른 PMI를 선택할 수 있다. 상술한 점을 고려하여 무선 통신 시스템에서 2가지 CSI 타입이 정의될 수 있으며, 하기 표 7과 같을 수 있다. [표 7]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "구체적으로, 타입 1 CSI(type 1 CSI)는 송신단에서 서로 다른 안테나 설정에 기초하여 서로 다른 서브 코드북 형태를 가질 수 있다. 일 예로, 도 4는 본 개시에 적용 가능한 타입 1 CSI를 나타낸 도면이다. 구체적으로, 도 4(a)는 (N1, N2) =(4,2)로 16개의 안테나 포트가 설정되는 경우일 수 있다. 타입 1 싱글 패널 CSI를 위한 프리 코딩 행렬 W는 2개의 행렬(W1, W2)의 곱으로 표현될 수 있으며, 각각은 전체 PMI의 다른 부분으로써 독립적으로보고될 수 있다. 일 예로, W1은 롱-텀 주파수 독립(long-term frequency independent) 채널 특성을 반영할 수 있으며, 이에 따라 전체 대역폭에 해당하는 채널 정보를 보고할 수 있다.(Wideband reporting) 일 예로, W1은 하기 수학식 4와 같을 수 있다. W1은 다른 방향을 지시하는 빔들의 집합을 지시할 수 있으며, 행렬 B는 하나의 빔을 정의할 수 있다. 수학식 4에서 2 X 2 블록 구조를 기반으로 2개의 편파(polarization)를 가질 수 있으며, W1의 선택은 동일한 빔 방향을 갖는 제한된 셋(limited set)을 선택하는 것일 수 있다. [수학식 4]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "구체적인 일 예로, 랭크 1 또는 2의 경우, W1 행렬에 의해 단일 빔 또는 네 개의 이웃하는 빔들이 지시될 수 있 다. 4개의 이웃하는 빔들 중 정확한 빔은 서브 밴드마다 보고되는 W2에 의해 선택될 수 있으며, 이를 통해 서브 밴드마다 최적회된 빔을 선택할 수 있다. 또한, W2는 2개의 편파 사이에 cophasing을 제공할 수 있다. W1이 단 일 빔을 정의하는 경우, 단일 컬럼(column) 행렬이 되는 B에서 W2는 2개의 편파 사이의 cophasing만 제공할 수 있다. 반면, 복수 개의 이웃 빔들이 W1에 의해 정의되는 경우, W2는 하나의 정확한 빔을 선택하고, 해당 빔 내 의 2개의 편파 사이의 cophasing을 제공할 수 있다. 반면, 랭크 2보다 큰 경우, W1은 N개의 이웃 직교 빔들을 정의할 수 있으며, 이는 수학식 5와 같을 수 있다. 수 학식 5에서 R개의 전송 레이어들의 전송을 위해 사용되는 N개의 빔이 지시될 수 있으며, W2는 2개의 편파 사이 에서 cophasing만 제공할 수 있다. 여기서, 최대 8개 전송 레이어까지 동일 단말에게 전송이 가능할 수 있다. [수학식 5]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "반면, W2는 숏-텀(short-term)으로 잠재적으로 주파수에 따라 다른 채널 특성을 지시할 수 있다. W2는 특정 경 우에 보고되지 않을 수 있다. 여기서, 기지국은 PRG(physical resource block group)마다 W2를 랜덤하게 선택 할 수 있으며, 단말은 이러한 가정에 기초하여 CQI(channel quality indicator)를 선택할 수 있다. 또한, 도 4(b)는 타입 1 멀티 패널 CSI일 수 있다. 멀티 패널 CSI는 복수의 안테나 패널이 기지국에서 사용되는 경우를 고려하여 적용될 수 있다. 여기서, 서로 상이한 패널들 사이의 코히런스(coherence)가 보장되기 어려울 수 있다. 일 예로, 도 4(b)는 (N1, N2) = (4, 1)이고, 4개의 패널에 의해 32개의 안테나 포트를 갖는 경우일 수 있으나, 이에 한정되는 것은 아닐 수 있다. 여기서, 도 4(a)의 싱글 패널과 도 4(b)의 멀티 패널의 차이는 상이 한 안테나 패널들의 안테나 포트 사이에서 코히런스(coherence)가 보장되기 어려울 수 있다는 점이다. 멀티 패 널에서도 W1은 싱글 패널과 동일하게 다른 편파와 패널들을 위한 동일한 빔들의 셋일 수 있다. 반면, 멀티 패널 의 경우, W2가 편파들 사이뿐만 아니라 멀티 패널들 사이의 cophasing을 서브밴드마다 제공할 수 있다. 타입 2 CSI는 타입 1 CSI보다 더 높은 공간 그레뉼리티(spatial granularity)를 가지는 채널 정보를 제공할 수 있으며, 주로 MU-MIMO 시나리오에 적용될 수 있다. 일 예로, 타입 2 CSI는 최대 랭크는 2개까지 제한될 수 있고, 향상된 타입 2 CSI는 4개의 랭크까지 확장될 수 있으나, 특정 형태로 한정되는 것은 아닐 수 있다. 하기 에서는 설명의 편의를 위해 타입 2 CSI 및 향상된 타입 2 CSI로 지칭하지만 이에 한정되는 것은 아닐 수 있다. 여기서, 상술한 수학식 3 및 4에서 W1은 광대역 보고일 수 있다. 타입 2 CSI는 최대 4개의 빔까지 보고할 수 있 고, B 내에 4개 열에 해당될 수 있다. W2는 B 내의 4개까지 보고된 각 빔 및 2개 편파 각각을 위해 진폭 값(부 분적으로 wideband 그리고 부분적으로 subband reporting) 및 위상 값(subband reporting)을 제공할 수 있다. 타입 2 CSI는 메인 레이(main ray)와 진폭 및 위상 정보를 제공하는 점에서 타입 1에 비해 상세한 채널 모델 정 보를 제공할 수 있다. 기지국은 복수의 단말로부터 보고된 CSI에 기초하여 어떤 단말들의 조합들이 동시에 같은시간/주파수 자원 상에서 전송이 적절한지 결정할 수 있다. 또한, 향상된 타입 2 CSI(e.g. Rel-16 enhanced Type 2 CSI)를 고려할 수 있다. 향상된 타입 2 CSI는 타입 2 CSI와 동일하게 광대역 상의 빔들의 집합과 추가 협대역 상의 combining coefficient들의 집합을 함께 보고할 수 있다. 여기서, 보고된 빔들은 각 전송 레이어를 위한 프리코더 벡터들의 집합을 제공하기 위해 combining coefficient들을 이용하여 선형적으로 결합될 수 있다. 일 예로, 기존 타입 2 CSI에서는 각 서브밴드를 위해 독 립적으로 combining coefficient 값이 보고될 수 있다. 이에 따라 기존 타입 2 CSI에서는 인접 서브밴드들 사이 채널이 상당한 상호 연관성을 가진다는 사실을 고려할지라도, Per-subband 상에 상대적으로 큰 combining coefficient 값을 보고해야 하므로 오버헤드가 커질 수 있었다. 향상된 타입 2 CSI는 이러한 오버헤드를 줄이기 위해서 주파수 상의 상호 관련성(correlation)을 이용할 수 있다. 또한, 향상된 타입 2 CSI는 PMI 보고의 주파 수 도메인 그래뉼리티를 개선할 수 있다. 일 예로, 주파수 도메인 유닛(frequency domain unit)을 기반으로 서 브밴드 또는 하프 서브 밴드에서 압축 동작이 적용될 수 있다. 기존 타입 2 CSI는 서브밴드 당 하나의 프리코더 를 사용하지만 향상된 타입 2 CSI는 주파수 도메인 유닛마다 추천되는 프리코더를 사용할 수 있다. 다만, 실제 보고는 모든 주파수 유닛들을 위해 함께 수행될 수 있다. 구체적으로, 레이어 k가 주어지는 경우, 모든 주파수 도메인 유닛을 위한 보고되는 프리코더는 하기 수학식 6과 같이 표현될 수 있다. 여기서, N은 주파수 도메인 유 닛의 수일 수 있다. [수학식 6]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "여기서, 수학식 6은 레이어와 안테나의 매핑이 아닐 수 있으며, 레이어 k에 대한 주파수 도메인 유닛들의 전체 셋을 위한 프리코더 벡터들의 셋을 의미할 수 있다. 전체 k 레이어를 위해 k개의 프리코더 벡터들의 집합이 있 고 각 집합은 N 개 프리코더 벡터들로 구성될 수 있으며, 특정 주파수 도메인 유닛 n을 위한 레이어와 안테나 포트 매핑은 하기 수학식 6과 같을 수 있다. 또한, 수학식 7의 벡터들을 위한 표현에서 W1은 기존 타입 2 CSI와 동일하게 상술한 수학식 4와 같을 수 있다. [수학식 7]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "여기서, B 열들은 L개 선택된 빔들에 해당할 수 있으며, W1은 모든 주파수 도메인 유닛들을 위해 동일할 수 있 다. (wideband reporting) 또한, W1은 모든 레이어를 위해 동일할 수 있다. 또한, 일 예로, 향상된 타입 2 CSI는 압축 메트릭스(compression matrix) (size M x N)를 고려할 수 있다. 는 DFT 기본으로부터 행 벡터들의 집합으로 구성될 수 있으며, 주파수 도메인의 N 차원(N 주파수 도 메인 유닛)으로부터 더 작은 지연 도메인의 M 차원으로 변형을 제공할 수 있다. 는 주파수 독립적일 수 있지만 각 레이어를 위해서 독립적으로 보고될 수 있다. 즉, 는 모든 주파수 도메인 유닛을 위해 하나의 공통 메트릭스일 수 있으나 각 레이어를 위해서 독립적으로 보고될 수 있다. 의 행의 수는 수학식 8의 M과 같을 수 있다. 수학식 8에서 R은 서브프레임 당 주파수 도메인 유닛의 수(R=1 또는 2)일 수 있고, p는 압축의 양을 조절하는 설정 파라미터(configurable parameter)일 수 있다. [수학식 8]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "최종적으로 (2L x M)는 딜레이 도메인에서 빔 도메인으로 매핑을 수행할 수 있다. 일 예로, 기존 타입 2 CSI의 W2는 모든 서브밴드를 위해 유사한 행렬을 생성할 수 있으며, 해당 행렬은 주파수(subband) 도메인에서 빔 도메인으로 매핑할 수 있다. 반면, 는 더 작은 지연 도메인으로부터 빔 도메인으로 할당을 수행할 수 있다. 는 보고되는 랭크 및 압축 팩터 파라미터 p에 의해 조정될 수 있으며, 이를 통해 더 적은 파라미터 를 기반으로 보고를 수행할 수 있다. 또한, 값을 통해서 보고될 CSI 양을 조정할 수 있 으며, 이를 통해 더 작은 크기를 의기반으로 더 적은 파라미터들을 보고할 수 있다. 또한, 일 예로, 향상된 타입 2 CSI는 감소된 오버헤드 및 향상된 주파수 도메인 그래눌리티와 함께 보고되는 랭 크가 최대 4로 확장되고, 선택 가능한 최대 빔 수도 6개로 확장될 수 있다. 하기 표 8은 향상된 타입 2 CSI의 가능한 설정을 나타낼 수 있으나, 이에 한정되지 않는다. [표 8]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "또한, 업링크 전송에서 멀티 안테나 프리코딩을 고려할 수 있다. PUSCH(physical uplink shared channel) MIMO 프리코딩은 최대 4개의 레이어를 지원할 수 있다. 업링크 전송과 관련하여 DFT 기반 프리코딩의 경우, SU(single-user) MIMO만 지원될 수 있다. 일 예로, 단말은 두 개의 상이한 PUSCH 프리코딩 모드로 코드북 기반 전송(codebook-based transmission) 및 논-코드북 기반 전송(non-codebook based transmission)을 수행할 수 있다. 코드북 기반 프리코딩의 경우, 기지국이 전송하는 업링크 그랜트에는 프리코더 관련 정보(e.g. PMI)가 포 함될 수 있다. 단말은 다운링크 전송과 상이하게 업링크에서 기지국에 의해 제공된 프리코더를 사용하는 것으로 가정한다. 또한, 업링크 MIMO 전송에서 단말 안테나들 사이에는 코히런스(coherence)가 가정될 수 있으며, 두 개의 안테나 상에서 전송되는 신호의 위상이 조정될 수 있다. 여기서, 안테나 포트들 사이에 코히런스가 없는 경우, 각각의 안테나 포트들은 랜덤한 상대적 위상을 야기할 수 있어 안테나 포트 특정 웨이트 팩터들의 사용이 제한됨을 의미할 수 있다. 일 예로, 안테나 포트들 간의 코히런스는 전체 코히런스(full coherence), 부분 코히런스(partial coherence) 및 코히런스 적용 없음(no coherence) 중 어느 하나에 해당할 수 있으며, 해당 정보는 단말 능력 정보로 제공될 수 있다. 또한, 코드북 기반 PUSCH를 위한 복수 개의 SRS(sounding reference signal) 사용을 고려할 수 있다. 도 5는 본 개시에 적용 가능한 복수 개의 SRS를 사용하는 방법을 나타낸 도면이다. 도 5를 참조하면, 단말은 멀 티 포트 SRS 상에서 상대적으로 큰 빔들을 전송할 수 있다. 일 예로, 해당 빔들은 다른 단말 안테나 패널(다른 방향)에 해당할 수 있으며, 각 패널은 안테나 요소들의 셋을 포함할 수 있다. 즉, 각 패널은 멀티포트 SRS의 안테나 포트들에 해당할 수 있다. 기지국은 어떤 빔을 통해 전송을 수행할지 여부를 결정하기 위해서 SRI(SRS Resource Indicator)를 단말로 전달할 수 있다. 단말은 SRI 및 프리코더 정보로 레이어 수와 프리코더를 기반으 로 선택된 빔 내에서 수행할 전송을 결정할 수 있다. 도 6은 본 개시에 적용 가능한 논-코드북 기반 프리코딩을 수행하는 방법을 나타낸 도면이다. 도 6을 참조하면, 논-코드북 기반 프리코딩을 수행하는 경우, 단말은 기지국으로부터 전달받은 프리코더 지시자(precoder indication) 및 채널 측정을 기반으로 전송을 수행할 수 있다. 단말은 코드북 기반 프리코딩에서는 기지국에 의 한 채널 측정에 기초하여 선택된 업링크 프리코더를 기반으로 전송을 수행하였으나 논-코드북에서는 채널 상호 성(reciprocity)을 기반으로 측정에 기초하여 선택된 프리코더를 통해 업링크 전송이 수행될 수 있다. 여기서, 프리코더 메트릭스 W의 각 열은 해당 레이어를 위한 디지털 빔일 수 있다. 단말은 N개의 레이어를 위한 프리코 더를 선택하는 경우에 N개의 다른 빔 방향을 선택한 것으로 볼 수 있으며, 각 빔은 하나의 가능한 레이어에 해 당할 수 있다. 일 예로, 도 6을 참조하면, 단말은 선택한 프리코딩을 기반으로 PUSCH 전송이 가능할 수 있다. 다만, 단말이 다 운링크 채널 측정을 기반으로 선택한 프리코더가 기지국 관점에서 최상의 프리코더가 아닐 수 있다. 상술한 점 을 고려하여 기지국은 단말이 선택한 프리코더를 수정할 수 있다. 일 예로, 기지국은 단말이 선택한 일부 빔들 또는 일부 열들을 프리코더에서 제거할 수 있으며, 이에 대한 정보를 단말로 전송할 수 있다. 구체적으로, 기지 국은 측정된 SRS 정보를 기반한 빔 선택의 결과를 다시 단말에게 SRI를 통해서 지시할 수 있다. 단말은 지시된 정보를 기반으로 단말은 일부 빔 전송만을 수행하며 이것은 묵시적으로 감소된 레이어 전송을 지시하는 것을 의 미할 수 있다. 단말은 기지국으로 UCI(uplink control information)을 전송할 수 있다. 일 예로, 단말은 UCI를 PUCCH(physical uplink control channel) 및 PUSCH 상에서 동시에 전송할 수 있다. 구체적으로, 단말은 상위 레이어 시그널링 또는 다이나믹 시그널링을 통해 \"simultaneous PUCCH and PUSCH transmission\" 파라미터를 지 시받고, UCI에 대한 PUCCH와 PUSCH 동시 전송을 설정할 수 있다. 즉, 단말은 PUCCH와 PUSCH에 대한 동시 전송을 수행하도록 설정될 수 있다. 여기서, PUCCH와 PUSCH가 동일한 캐리어에서 전송되는 경우, \"Non-single carrier waveform transmission\"을 야기할 수 있다. 이에 따라서, PUCCH와 PUSCH는 주파수 위치 자원 할당 크기, 전송 파워 및 그밖의 요소에 기초하여 큰 전송 백오프(transmission backoff (e.g. 10dB))를 기반으로 전송될 수 있 다. 반면, PUCCH와 PUSCH가 상이한 캐리어에서 전송되는 경우, 단일 PA(power amplitude) 또는 복수 PA에 기초 하여 큰 파워 백오프가 요구되거나 또는 요구되지 않을 수 있다. 또 다른 일 예로, 단말은 PUCCH와 PUSCH에 대한 동시 전송이 필요한 경우에 PUCCH를 드롭하고, PUSCH에 UCI를 포함하여 전송할 수 있다. 일 예로, PUSCH에 피기백되는 UCI 타입은 HARQ(hybrid automatic repeat and request), CSI 타입 1 및 CSI 타입 2 중 적어도 어느 하나일 수 있다. 반면 SR(scheduling request)는 PUSCH 상에서 피기백되지 않고, BSR(buffer state report)로 대체될 수 있으나, 이에 한정되는 것은 아니다. 상위레이어 파라미터 베타 값은 PUSCH 상에 전송되는 무선 자원의 양을 결정하기 위해 사용되며 해당 값은 기 지국에서 단말에게 지시될 수 있다. 베타 값은 무선 자원 양에 기초하여 그 범위가 클 수 있다. 단말이 PUSCH 상에서 UCI를 전송하는 경우, 단말은 상술한 베타 값과 함께 PUSCH 상의 UCI 페이로드 크기 및 PUSCH 주파수 효 율을 고려하여 UCI 전송을 위해 요구되는 무선 자원의 양을 결정할 수 있다. 이를 통해 UCI를 위해 불필요하게 많은 자원이 사용되는 것을 방지할 수 있으며, 해당 동작은 상위레어어 파라미터에 의해서 제어될 수 있다. 또한, 일 예로, UCI 정보 비트의 크기는 UCI 타입에 따라서도 상이할 수 있으며, 이에 따라 상이한 UCI 핸들링 방법이 고려될 수 있다. 하기 표 9의 케이스를 고려할 수 있다.[표 9] [표 10]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "일 예로, PUCCH 기반 서브밴드 CSI 보고 및 타입 1 CSI 피드백 PUSCH 기반 보고(PUCCH-based subband CSI reporting and PUSCH-based reports with Type 1 CSI feedback)인 경우, CSI 파트 1(CSI Part 1)은 RI (if reported), CRI(CSI-RS Resource Indicator)(if reported)를 포함할 수 있다. 또한, CSI 파트 1은 첫 번째 코 드워드(first codeword, first CW)를 위해 CQI를 포함할 수 있다. CSI 파트 2는 RI가 4보다 큰 경우에 두 번째 CW를 위해 CQI와 PMI를 포함할 수 있다. CSI 파트 1은 PUSCH를 통한 타입 2 CSI 피드백을 위해 추가적으로 \"non-zero wideband amplitude coefficient per layer\" 수의 지시를 포함할 수 있다. 여기서, \"Wideband amplitude coefficient\"는 Type 2 CB의 일부이며, coefficient 값이 0인지 아닌지 여부에 따라서 PMI 페이로드 크기가 상이해질 수 있다. 또한, CSI 파트 1 및 CSI 파트 2 각각은 표 11 및 표 12에 기초하여 설정될 수 있다. [표 11]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "[표 12]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "또한, 다양한 업링크 데이터 스케줄링이 필요할 수 있다. 베타 값은 PUSCH의 UCI 및 UCI마다 잠재적으로 상이한 QoS 요구사항들을 고려하여 단말에게 다이나믹하게 지시될 수 있다. 일 예로, 기지국은 상위 레이어를 통해 사 전에 설정한 4가지 다른 베타 값들 중 어느 하나의 값을 DCI(downlink control information)을 통해 지시할 수 있다. 일 예로, UCI를 PUSCH 상에 할당하는 경우, HARQ가 가장 우선순위가 높고, CSI 타입 1 및 CSI 타입 2 순으로 우 선순위가 결정될 수 있다. 우선순위는 UCI가 전송되는 PUSCH 상의 DMRS에 가깝게 맵핑되는지 여부에 기초하여 확인될 수 있다. 여기서, UCI가 1 또는 2비트 HARQ의 경우, 2비트 HARQ 비트를 가장하여 펑처링을 위한 일부 RE들이 예약될 수 있으며, 펑처링을 통해 해당 정보가 전송될 수 있다. 또한, UCI가 HARQ 2비트보다 크고 CSI 파트 1과 CSI 파트 2인 경우, 레이트 매칭은 가장 첫 번째 DMRS 심볼 다음 오른쪽 non-DMRS 심볼부터 이용 가능한 RE들에서 시작되 어 HARQ 첫 번째가 수행되고, 그 다음으로 CSI 파트 1 및 CSI 파트 2 순으로 수행될 수 있다. 또한, 일 예로, CSI 파트 1은 HARQ에 의해 펑처링되는 것을 방지하기 위해 HARQ를 위한 예약된 RE에는 할당되지 않을 수 있다. 반면, CSI 파트 2와 업링크 데이터는 예약된 RE에 할당될 수 있다.(즉, 잠재적으로 펑쳐링되는 것을 수반할 수 있다.) PUSCH 상의 UCI는 주파수 우선으로 할당되고, 그 후 시간 순서로 할당될 수 있다. 즉, 가장 낮은 이용 가능한 심볼의 가장 낮은 이용가능한 RE를 시작으로 PUSCH 상의 UCI가 할당될 수 있다. 상술한 바를 통해 기지국은 UCI 를 빨리 디코딩할 수 있다. 하나의 업링크 심볼 내에서 PUSCH 상의 UCI를 위한 주파수 다이버시티 게인을 최대 화 하기 위해서 UCI를 위한 RE들은 'frequency-distributed' 방식으로 할당될 수 있으나, 이에 한정되지 않는다. 구체적으로, UCI가 할당될 하나의 OFDM(orthogonal frequency division multiplexing) 심볼 내 2개 인 접 RE들 사이의 거리(d)는 UCI를 위해서 할당될 변조 심볼들의 수가 업링크 심볼 내에 이용가능한 RE수보다 크거나 혹은 같은 경우에 1로 설정될 수 있다(d=1) 그렇지 않은 경우, d는 floor(업링크 심볼 내 이용 가능한 RE 수/UCI를 위해 할당될 변조심볼들의 수)에 의해서 결정될 수 있다. 여기서, d>1 for a UL symbol일 수 있으며, 해당 심볼에서 UCI 변조 심볼들의 할당은 주파수 그 심볼에서 UCI 변조심볼들의 할당은 frequency distributed하게 될 수 있다. 또한, 모든 UCI 타입들은 PUSCH 전송의 모든 레이어에 할당되어 같은 PUSCH 변조를 사용할 수 있다. 일 예로, CSI는 가장 높은 MCS(modulation coding scheme)를 가지는 레이어에만 할당될 수 있으나, 이에 한정되지 않는다. 일 예로, UL MIMO 전송에서 2개 TB가 LTE에서 사용되는데 5G NR에서는 4개 레이어 UL MIMO 전송이 하나의 TB를 위해서 사용되기 때문에 CSI가 가장 높은 MCS를 가지는 레이어에만 할당될 수 있다. 또한, PUSCH 상에 주파수 호핑이 인에이블된 경우, UCI 변조 심볼들은 대략 같은 사이즈의 2개 파트로 나뉠 수 있다. 2개 나뉜 파트들은 2개 홉들 각각에 할당될 수 있으며, 대략적으로 동일한 파트로 나눠질 수 있다. 이에 따라, PUSCH 상의 UCI 피기백에 의한 업링크 데이터 상의 안 좋은 영향을 2개의 홉 상으로 동일하게 분배할 수 있다. 또한, PUSCH 기반 CSI 보고에서 부분 CSI 생략(partial CSI omission)을 고려할 수 있다. PUSCH 기반 CSI 보고 (PUSCH-based CSI reporting)와 타입 2 CSI 보고에서 CSI 페이로드 크기는 RI(rank indicator) 선택에 따라 다 이나믹하게 변경될 수 있다. 구체적인 일 예로, 타입 2 CSI 보고가 수행되는 경우, RI가 2인 경우의 PMI 페이로 드는 RI가 1인 경우의 PMI 페이로드보다 2배 정도 더 많을 수 있다. 기지국은 RI 선택을 사전에 인지할 수 없으 므로 PUSCH 스케줄링을 수행하는 경우에 단말이 선택할만한 RI 값을 예상하여 스케줄링을 수행할 수 있다. 따라 서, 기지국과 단말 사이에 RI 선택에 의한 불일치(misalignment)가 발생할 수 있다. 기지국이 예상한 RI 값보다 단말이 선택한 RI가 큰 경우, CSI 페이로드 크기가 커질 수 있고, 이에 따라 PUSCH 상에 포함되지 못할 수 있다. 즉, 코드 레이트가 너무 크거나 또는 uncoded systematic 비트들이 포함되지 못할 수 있다. 상술한 경우 에 단말은 CSI 보고를 드롭하는 대신에 부분 CSI 생략을 통해 일부 우선순위가 높은 CSI 정보들을 PUSCH를 통해 기지국으로 보고할 수 있다. 일 예로, 도 7은 본 개시에 적용 가능한 CSI 생략을 나타낸 도면이다. 도 7을 참조하면, CSI 정보 중 일부(71 0)는 보고에 포함되고, 나머지 일부는 보고에서 생략될 수 있다. 일 예로, 단말은 CSI 파트 2 내의 CSI 콘 텐츠에 대한 오더링(ordering)을 통해 수행할 수 있다. 복수의 CSI 보고가 PUSCH 상에 전송되는 경우, 모든 CSI 보고들에서 광대역 CSI 요소(wideband CSI component)(i.e., wideband PMI and CQI)들은 UCI의 MSB(most significant bit) 비트에 할당되며, 서브밴드 CSI(각 CSI report)는 \"even SB CSI - Odd SB CSI - even SB CSI\"의 방식으로 할당될 수 있으며, 이는 도 7과 같을 수 있다. 일 예로, UCI 코드 레이트가 임계 값을 초과하는 경우, UCI LSB(least significant bit) 비트들의 일부가 생략 될 수 있다. 여기서, 생략은 코드 레이트가 임계 값 아래로 내려갈 때까지 수행될 수 있으며, 이는 도 7과 같을 수 있다. 일 예로, 도 7에서 \"SB CSI for odd numbered\"가 먼저 생략될 수 있으나, 이에 한정되는 것은 아 닐 수 있다. 일 예로, 기지국은 주파수 도메인 상의 missing PMI/CQI 값을 추정하여 PMI/CQI를 인터폴레이트(interpolate) 할 수 있다. 즉, 기지국이 일부 생략되는 SB CSI들에 대해서 최대로 인터폴레이트하여 추정할 수 있도록 상술한 순서를 기반으로 생략이 수행될 수 있다. 상술한 바를 통해 전체 연속적인 SB CSI를 모두 생략하는 것보다 높은 성능을 유지할 수 있다. 일 예로, 하기에서는 AI/ML(artificial intelligence/machine learning) 기반 동작이 수행될 수 있다. 여기서, AI/ML 기반 프레임 워크 상에서 하기 표 13의 용어가 사용될 수 있으나, 이에 한정되는 것은 아닐 수 있다.[표 13]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "일 예로, 딥러닝(deep learning)은 머신러닝(machine learning, ML)의 하위 카테고리로 멀티 레이어 신경망 (multi layer neural network)을 파라미터화 하는데 집중하는 방식일 수 있다. 딥러닝은 데이터의 대표성을 학 습하는 방법일 수 있으며, 주로 이미지의 분류(classification), 음성 인식(speech recognition) 및 자연어 처 리(natural language processing)에서 높은 성능을 나타내고 있다. 다만, 딥러닝은 트레이닝 과정에서 많은 데 이터가 요구될 수 있으며, 많은 양의 데이터 셋에 대한 딥러닝 기반 모델을 트레이닝하기 위해 요구되는 계산 복잡도가 높을 수 있어 높은 하드웨어 성능이 요구될 수 있다. AI/ML과 관련하여, AI/ML 기반 이동 통신이 수행될 수 있다. 일 예로, AI는 기존 무선 통신 시스템에 기초하 여 동작하는 장치들의 데이터를 관리하여 CAPEX OPEX 비용을 줄일 수 있었다. 여기서, 차세대 네트워크 도입을 위해서는 낮은 운영비용 및 비용 대비 높은 수익 보정이 필요할 수 있는데 AI는 이러한 네트워크 운영에 대한 복잡도와 최적화 문제를 해결하는데 도움을 줄 수 있다. 또한, 네트워크 지능화 및 자동화는 차세대 이동 통신 시스템에서 중요한 이슈일 수 있으며, AI/ML 기반으로 해당 문제가 해결될 수 있다. 일 예로, 예산 관리, 네트워크 관리, 장비 라이프 사이클 관리, SLA(service level agreement) 관리, 네트워크 성능 관리 및 네트워크 플 래닝이 AI/ML 기반으로 수행될 수 있다. AI/ML은 네트워크 운용 및 사용의 QoE(Quality of Experience)를 높여 줄 수 있으나, 이에 한정되는 것은 아닐 수 있다. 또한, AI/ML은 네트워크 품질을 개선하고 보다 개인화된 서비 스 제공을 강화할 수 있으나, 특정 형태로 한정되지 않는다. 일 예로, AI/ML 기반 동작은 모델 생성(model generation)과 인퍼런스 동작(inference operation)의 두 가지 동작을 고려할 수 있다. 모델 생성은 모델 트레이닝(model training), 모델 유효화(model validation), 모델 테스팅(model testing) 및 적용 단계를 기반으로 수행될 수 있다. 일 예로, 모델 트레이닝은 입력/출력, 사전/ 사후 프로세싱 및 온라인/오프라인 적용 중 적어도 어느 하나를 기반으로 수행될 수 있으나, 이에 한정되는 것 은 아닐 수 있다. 또한, 인퍼런스 동작은 입력/출력, 사전/사후 프로세싱 및 적용 단계를 기반으로 수행될 수 있다. 일반적인 AI/ML 프레임워크와 AI/ML 모델의 라이프 사이클 관리(life cycle management, LCM) 절차는 하기 단계를 기반 으로 수행될 수 있다. 일 예로, 도 8은 본 개시에 적용 가능한 AI/ML 모델 라이프 사이클 관리를 나타낸 도면이 다. 도 8을 참조하면, AI/ML 모델을 위한 데이터 수집이 수행될 수 있다. 여기서, 수집된 데이터는 모델 트레이 닝을 위한 데이터, 모델 관리 및 성능 모니터링을 위한 모니터링 데이터 및 모델 인퍼런스를 위한 인퍼런스 데 이터를 포함할 수 있다. 모델 트레이닝은 트레이닝 데이터를 기반으로 모델 학습을 수행할 수 있으며, 학습 및 업데이트된 모델은 저장될 수 있다. 여기서, 모델은 기능이나 모델 식별자 또는 모델 및 추가 정보 관련 식별자 에 기초하여 저장될 수 있으나, 특정 형태로 한정되지 않는다. 또한, 모델 트레이닝은 모델 관리 및 성능 모니 터링에 기초하여 모델 트레이닝 제어 정보를 기반으로 수행될 수 있다. 모델 관리 및 성능 모니터링은 모니터링 데이터를 기반으로 모델 인퍼런스를 제어할 수 있다. 모델 관리 및 성 능 모니터링은 모델 인퍼런스의 활성화/비활성화/선택/스위칭/폴백 및 그 밖의 동작을 제어할 수 있다. 모델 관 리 및 성능 모니터링은 모델 인퍼런스를 통해 수행된 결과 정보를 획득할 수 있다. 모델 인퍼런스는 인퍼런스 데이터를 획득하여 인퍼런스 동작을 수행하고, 결과 정보를 획득할 수 있다. 모델 인퍼런스는 스토리지에 저장 된 모델을 전달받을 수 있으며, 이에 기초하여 인퍼런스 동작을 수행할 수 있다. LCM(life cycle management) 절차와 관련하여 하나의 AI/ML 모델은 하나의 모델 아이디(Model ID) 및 이와 관 련된 정보 및/또는 모델 기능을 AI/ML 동작을 위해서 가질 수 있으며, 이는 상술한 바와 같다. LCM 절차 내의 동작 - Data Collection - Model Training - Functionality/model identification - Model transfer - Model Inference - Functionality/model selection, activation, deactivation, switching and fallback operation - Functionality/model monitoring - Model update - Model Storage - UE capability 일 예로, 무선 통신 시스템에서 AI/ML 기반 동작은 하기 케이스를 고려할 수있다. 다만, 이는 하나의 일 예일 뿐, AIML 기반 동작이 다른 케이스에 적용되는 것도 고려할 수 있다. 무선 통신 시스템의 AI/ML 기반 동작 CSI(Channel State Information): compression (**), temporal prediction (*) BM(Beam Management): spatial prediction (*), temporal prediction (*) Positioning: direct (*), assisted (*) (**)는 two-side model (*)는 single side model 구체적인 일 예로, 투-사이드 모델을 이용하여 CSI 압축을 위한 AI/ML 모델 합동 트레이닝을 고려할 수 있 다.(AI/ML Model training collaborations for CSI compression using two-sided model) 일 예로, CSI 압축과 관련하여 AI/ML 모델 인퍼런스는 단말과 기지국 양측에서 수행될 수 있다. 즉, AI/ML 모델 인퍼런스는 투-사이드에서 수행될 수 있다. 이를 위해 단말에는 CSI 생성 파트(CSI generation part)가 설정될 수 있으며, 기지국에는 CSI 생성 파트에 대응하는 CSI 재구성 파트(CSI reconstruction part)가 설정될 수 있다. CSI 생성 파트는 CSI 압축을 위한 부분이고, CSI 재구성 파트는 매시브 MIMO(massive MIMO) 시나리오에서 더 좋은 MU(multi-user) 스케줄링 동작을 위해 보다 정확한 CSI를 획득(recover)하기 위해 사용될 수 있으나, 이에 한정되지 않고, 투-사이드 AI/ML 모델에 대한 협동은 다양한 형태로 수행될 수 있다. 또 다른 일 예로, 단말의 능력(capability) 또는 컴퓨팅 파워(computing power)의 제약을 고려하여 제3의 엔티 티(e.g. 단말을 위한 서버)가 AI/ML 모델 트레이닝 또는 인퍼런스 동작을 수행하는 것을 고려할 수 있다. 즉, 상술한 AI/ML 동작으로 단말 측의 동작(e.g. model training/inference/monitoring/switching/ activation/deactivation/validation/testing)은 다른 엔티티의 동작을 포함할 수 있으며, 특정 형태로 한정되 지 않는다. 일 예로, 합동 트레이닝(training collaboration)은 하기 타입 1 내지 타입 3을 고려할 수 있다. 하기에서는 기 지국 또는 네트워크 측에서 수행하는 AI/ML 모델 관련 모든 동작은 네트워크 단에서 수행하는 것으로 가정한다. 다만, 이에 한정되는 것은 아닐 수 있다. 네트워크는 기지국을 포함하는 포괄적 용어이므로 두 용어가 혼용되어 사용될 수 있으며, 네트워크에서 수행되는 것은 기지국 측과 더 넓은 범위의 네트워크 측 모두를 포함할 수 있 으며, 하기에서는 설명의 편의를 위해 네트워크에서 동작되는 것으로 서술한다. 일 예로, 합동 트레이닝은 타입 1(type 1)에 기초하여 수행될 수 있다. 타입 1은 하나의 사이드/엔티티 (side/entity)에서 AI/ML 모델에 대한 트레이닝이 수행되는 방식일 수 있다. 그 후, 다른 사이드/엔티티는 특정 모델 파트를 다운로딩/또는 업로딩을 통해 획득할 수 있으며, 이를 기반으로 CSI 피드백 동작이 수행될 수 있다. 구체적인 일 예로, 도 9는 타입 1에 기초하여 AI/ML 모델 트레이닝이 수행되는 방법을 나타낸 도면이다. 도 9를 참조하면, 네트워크 측에서 조인트 트레이닝 방식으로 단말의 CSI 생성 파트와 기지국의 CSI 재구성 파트 에 대한 모델 트레이닝이 수행될 수 있다. 그 후, 네트워크 사이드는 트레이닝된 모델 정보를 단말로 다운 로딩을 통해 제공하고, 네트워크에도 적용할 수 있다. 또 다른 일 예로, 단말 측에서 조인트 트레이 닝 방식으로 단말의 CSI 생성 파트와 기지국의 CSI 재구성 파트에 대한 모델 트레이닝이 수행될 수 있다. 그 후, 단말 사이드는 트레이닝된 모델 정보를 단말에 적용하고, 네트워크에 업링크를 통해 제공할 수 있다. 즉, AI/ML 모델은 하나의 사이드/엔티티에서 트레이닝될 수 있으며, 트레이닝된 AI/ML 모델이 다른 사이 드/엔티티로 전달될 수 있다. 구체적인 일 예로, 네트워크 사이드 모델 1 트레이닝은 네트워크에서 트레이닝 목적을 위한 CSI 생성 관련 데이 터 셋을 이용하여 CSI 생성 파트를 트레이닝하고, 해당 결과 값을 CSI 재구성 파트의 트레이닝 루프 내로 전달 하여 CSI 재구성 파트를 트레이닝할 수 있다. 여기서, 기지국에 위치하는 CSI 재구성 파트는 이후 AI/ML 모델 기반 CSI 피드백을 위해서 활용될 수 있다. 반면, 기지국에 의해서 모델 트레이닝을 수행한 CSI 생성 파트(즉, CSI encoder)는 단말에게 무선 인터페이스를 통해 트레이닝된 모델 정보를 전달할 수 있다.(UE download AI/ML model) 단말은 다운로드한 CSI 생성 파트 모델을 사용하여 AI/ML 모델 기반 CSI 피드백 동작을 수행할 수 있다. 즉, CSI 생성 파트를 통해서 CSI 압축을 수행하여 CSI 피드백을 수행할 수 있다. 반면, AI/ML 모델이 단말 사이드에서 트레이닝되는 경우, 단말 사이드 타입 1 트레이닝은 단말에서 트레이닝 목 적을 위한 CSI 생성의 데이터 셋을 이용하여 CSI 생성 파트를 트레이닝할 수 있다. 그 후, 출력 값을 CSI 재구 성 파트의 트레이닝 루프로 제공하고, 이에 기초하여 CSI 재구성 파트를 트레이닝할 수 있다. 일 예로, 단말에 위치할 CSI 생성 파트는 이후 AI/ML 모델 기반 CSI 피드백 정보 생성을 위해 사용될 수 있다. 기지국에 의해서모델 트레이닝을 수행한 CSI 재구성 파트(즉, CSI decoder)는 기지국에게 무선 인터페이스를 통해 트레이닝된 모델 정보를 전달할 수 있다. (UE upload AI/ML model). 이후 기지국은 단말 업로드를 통해 수신한 CSI 재구성 파트 모델을 사용하여 AI/ML 모델 기반 CSI 피드백 동작을 수행할 수 있다. 즉, CSI 재구성 파트를 통해서 CSI 피드백 정보 회복을 수행하여 CSI 피드백을 수행할 수 있다. 또한, AI/ML 모델 합동 트레이닝 타입 1은 AI/ML 모델 교환이 필요할 수 있다. 일 예로, AI/ML 모델의 인퍼런스 는 모델 인퍼런스를 위한 공통 참조와 공통의 AI/ML 모델 인퍼런스 알고리즘이 필요할 수 있으며, 이를 위한 AL/ML 모델 교환이 필요할 수 있다. 일 예로, 단말 특정 합동 트레이닝 타입 1은 단말에서 인지하고 있는 AI/ML 모델 구조의 오픈 포맷을 기반으로 AI/ML 모델 전달이 수행될 수 있다. 반면, 단말에 특정되지 않는 합동 트레 이닝 타입 1은 단말이 AI/ML 모델 구조에 대한 인지 없이 오픈 포맷 내의 모델 전달을 의미할 수 있다. 일 예로, 네트워크 측에서 단말 사이드 모델에 대한 트레이닝을 수행하는 경우, 단말 특정 모델은 단말 능력과 단 말 모델 구조를 기반으로 네트워크 측에서 트레이닝이 수행되도록 할 수 있으나, 특정 형태로 한정되는 것은 아 닐 수 있다. 또 다른 일 예로, 도 10은 본 개시에 적용 가능한 타입 2에 기초하여 AI/ML 모델 트레이닝이 수행되는 방법을 나타낸 도면이다. 도 10을 참조하면, 타입 2 모델 트레이닝은 하나의 동일 루프 내의 CSI 생성 파트와 CSI 재구 성 파트가 모두 수행되는 관점에서 타입 1과 동일할 수 있지만 특정 사이드/엔티티에서 트레이닝이 수행되지 않 고, 앙쪽 사이드/엔티티 모두에서 트레이닝을 수행하는 점에서 타입 1과 차이가 있다. 즉, 네트워크와 단말 모 두 트레이닝에 관여할 수 있다. 일 예로, 도 10을 참조하면, 단말 측은 데이터 샘플을 기반으로 FP(forward propagation) 동작을 수행할 수 있 다. 즉, 단말은 CSI 피드백 결과를 생성할 수 있으며, 이에 대한 정보로 FP 결과를 네트워크 측으로 전달 할 수 있다. 그 후, 네트워크는 FP 결과를 기반으로 CSI 재구성 동작을 수행할 수 있으며, 이를 통해 CSI 재구성 파트를 트레이닝할 수 있다. 네트워크 측은 상술한 바에 기초하여 BP(backward propagation) 정보(e.g. gradients)를 생성할 수 있으며, 생성된 BP 정보를 다시 단말로 전달할 수 있다. 단말 측은 네트워크 측으로부 터 수신한 BP 정보를 기반으로 CSI 생성 파트에 대한 트레이닝을 수행할 수 있다. 여기서, 데이터 셋은 단말과 네트워크 측에서 모두 정렬(align)될 수 있으며, 상술한 바를 통해 트레이닝이 수행될 수 있다. 또한, 일 예로, 도 11은 본 개시에 적용 가능한 타입 3에 기초하여 AI/ML 모델 트레이닝이 수행되는 방법을 나 타낸 도면이다. 도 11을 참조하면, 타입 3 모델 트레이닝은 순차적 트레이닝 방법으로 타입 1 및 타입 2의 조인 트 합동 트레이닝과 상이하게 각 노드별로 순차적/독립적으로 모델 트레이닝이 수행될 수 있다. 즉, 타입 3 모 델 트레이닝은 하나의 동일 루프 내에서 CSI 생성 파트와 CSI 재구성 파트가 트레이닝되지 않고, 분리된 루프 내에서 가지국과 단말 사이에 정렬된 데이터 셋 정보 교환을 기반으로 모델 트레이닝이 수행될 수 있다. 일 예 로, 타입 3 모델 트레이닝은 타입 1 모델 트레이닝과 동일하게 네트워크 우선 트레이닝 또는 단말 우선 트레이 닝으로 구별할 수 있다. 도 11을 참조하면, 네트워크 우선 트레이닝의 경우, 네트워크는 네트워크 측에 설정되는 CSI 재구성 모델의 트 레이닝을 위한 CSI 생성 파트를 사용할 수 있다. 다만, 해당 CSI 생성 파트는 트레이닝을 위한 것으로 이후 모 델 인퍼런스에서는 사용되지 않을 수 있다. 네트워크 측은 CSI 생성 파트의 입력 값( )을 기반으로 해당 CSI 생성 파트와 그 출력 값( 및 이에 기초한 CSI 재구성 파트의 모델 트레이닝을 통해 최종 출력 값( )을 생성할 수 있다. 트레이닝이 완 료된 CSI 재구성 파트는 네트워크의 AI/ML 기반 CSI 피드백 동작을 위해 사용될 수 있다. 그 후, 네트워크 측은 모델 트레이닝 종료 후 단말에게 네트워크 측의 모델 트레이닝에서 활용한 데이터 세트 정보(e.g. dataset including labels and intermediate results)를 공유할 수 있다. 단말 측은 데이터 세트 정보를 CSI 생성 파트 트레이닝에 적용할 수 있다. 그 후, 단말 측에서 수행된 CSI 생성 파트와 네트워크 에서 수행된 CSI 재구성 파트를 통해서 조인트 인퍼런스 동작이 수행될 수 있다. 또한, 단말 측에서 트레 이닝한 CSI 생성 파트에 대한 정보(e.g. model/functionality identification process - 이용 가능한 CSI 생성 파트의 정보)는 네트워크로 보고 또는 전달될 수 있다. 네트워크는 단말로부터 획득한 CSI 생성 파트에 대한 정보를 기반으로 단말의 CSI 생성 파트 모델에 대응하는 CSI 재구성 파트를 선택하거나 최적화를 수행할 수 있다. 일 예로, 네트워크 우선 타입 3 합동 트레이닝을 위한 단말 측 CSI 생성 모델 트레이닝에 대한 옵션들은 하기 표 14와 같이 고려될 수 있다. [표 14]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 22, "content": "단말 측 CSI 출력 포맷 또는 기지국 측 CSI 입력 포맷은 하기 표 15와 같을 수 있다. 즉, 단말에서 AI/ML을 고 려하여 생성되어 기지국으로 전달되는 CSI는 하기 표 15의 형태일 수 있다. 표 15에서 옵션 1은 단말 측 CSI 출 력 포맷 또는 기지국 측 CSI 입력 포맷이 기존 CSI 피드백과 유사한 형태로 프리코딩 메트릭스 형태인 경우일 수 있다. 단말은 확인한 레이어 수 정보와 함께 프리코팅 메트릭스 형태로 CSI 피드백을 기지국으로 보고할 수 있다. 일 예로, 단말은 표 15의 옵션 1-b(option 1-b)의 도메인으로 앵글러-딜레이 도메인(angular-delay domain) 상에서 CSI 피드백을 보고할 수 있으나 해당 실시예로 한정되는 것은 아닐 수 있다. (e.g. via spatial-frequency DFT domain transformation to angular/delay domain) 반면, 표 15에서 옵션 2는 단말 측 CSI 출력 포맷 또는 기지국 측 CSI 입력 포맷이 명시적인 CSI 피드백 (explicit CSI feedback)으로 채널 매트릭스인 경우일 수 있다. 즉, 옵션 2의 명시적인 CSI 피드백은 채널 매트 릭스로 각 레이어에 할당되는 프리코딩 벡터들을 포함하지 않을 수 있다. 명시적인 채널 매트릭스는 공간-주파 수 도메인에서의 채널을 기반으로 하는 경우(옵션 2-a, option 2-a) 및 앵글러 딜레이 도메인에서의 채널을 기 반으로 하는 경우(옵션 2-b, option 2b)를 고려할 수 있으나, 특정 형태로 한정되지 않는다. 일 예로, 옵션 2-b 의 앵글러/딜레이 도메인의 경우, 앵글러/딜레이 도메인 기반 인덱스들의 서브 셀렉션에 의해 손실이 야기될 수 있으나, 이에 한정되는 것은 아닐 수 있다. [표 15]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 23, "content": "하기에서는 무선 통신 시스템에서 AI/ML 기반 CSI 압축(CSI compression)을 수행하여 AI/ML 기반 CSI 보고를 수행하는 방법에 대해 서술한다. 구체적으로, AI/ML 기반 CSI 압축을 무선 통신 시스템에서 적용하는 경우에 CSI 페이로드 크기를 고려하여 UCI(uplink control information) 보고를 수행하는 방법일 수 있다. 일 예로, 하기에서는 설명의 편의를 위해 무선 통신 시스템에서 AI/ML 기반 CSI 압축에 기초하여 생성되는 CSI는 AI CSI 로 지칭하지만 해당 명칭으로 한정되는 것은 아니며, AI/ML 기반 CSI 압축에 기초한 동작을 기반으로 도출되는 CSI에 동일하게 적용될 수 있다. 여기서, AI CSI 페이로드는 AI/ML 기반 CSI 보고를 고려하여 조정될 수 있으며, 하기에서는 이에 대해 서술한다. 또한, 하기에서 제안하는 AI-CSI 페이로드 조정 방법은 AI/ML을 기반하는 다른 유스 케이스(use case) 상에서 특정 정보를 단말이 기지국측에게 AI/ML 모델 동작을 위해서 전달해야 하는 경우에 해당 특정 정보에 대한 페이 로드 조정 방법으로도 적용이 가능하다. 따라서, 하기에서 제안하고 있는 방법들은 오직 AI-CSI 보고에 대한 유스 케이스(use case)로 한정되지 않고, 다른 유스 케이스(use case)들에서 상향링크 보고를 위해서 적용이 가능할 수 있다. 도 12는 본 개시에 적용 가능한 AI 인코더 구조 및 이에 기초하여 입력으로부터 출력을 도출하는 방법을 나타낸 도면이다. 도 12를 참조하면, AI 인코더는 AI CSI 입력들(AI CSI inputs, 1221)을 획득하고, AI/ML 기반 CSI 압축(CSI compression)을 수행하여 AI 인코더 출력(AI encoder output, 1222)을 생성할 수 있다. AI CSI 입력들은 AI/ML 기반 동작 관련 다양한 정보들을 포함할 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. AI 인코더는 AI/ML 모델 관련 AI CSI 입력들을 사용하여 AI/ML 기반 CSI 압축을 위한 AI 인 코딩을 수행하고, 이후 양자화(quantization) 절차를 수행할 수 있다. AI 인코더는 AI 인코딩 및 양자화 절차 후에 AI 인코더 출력을 도출할 수 있다. AI 인코더 출력은 비트 스트링(bit string) 또는 비트 시퀀 스(bit sequence) 형태의 정보일 수 있으나, 이에 한정되는 것은 아닐 수 있다. 단말은 AI/ML 기반 CSI 압축에 대한 AI 인코더 출력 정보를 기지국으로 전달할 수 있다. 기지국은 단말로 부터 AI 인코더 출력 정보를 획득하고, 기지국에 위치한 CSI 재구성 파트(CSI reconstruction part)에 해당하는 AI 디코더를 통해 AI 인코더 출력 정보에 대한 디코딩 절차를 수행하여 AI/ML 기반 CSI 입력들에 대한 정보를 재구성(reconstruct)할 수 있다. 일 예로, AI CSI 압축을 기반으로 하는 상술한 AI CSI 정보 전달 절차 는 LCM (Life Cycle Management) 절차 내의 트레이닝/추론/모니터링 및 그 밖의 절차 중 적어도 어느 하나의 과 정에서 수행될 수 있다. 또한, AI CSI 압축에 기초하여 AI CSI 정보를 전달하는 상술한 절차는 다른 AI 모델 모 니터링이나 모델 스위칭에도 활용될 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 여기서, AI 인코더 출력은 상술한 AI CSI일 수 있으며, 단말은 AI CSI를 기지국으로 보고하여 상술한 동 작이 수행될 수 있다. 하기에서는 AI CSI 보고를 수행하기 위한 구체적인 동작에 대해 서술한다. 일 예로, AI/ML 기반 CSI 압축을 통한 AI CSI 보고들 상호 간의 적용 가능한 새로운 콘텐츠 및 전송 방식은 하기 표 16 및 표 17과 같을 수 있다. [표 16] [표 17]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 24, "content": "일 예로, 표 16 및 표 17의 정보들은 기지국 설정, 채널 환경, 단말 능력 및 다른 정보 중 적어도 어느 하나에 기초하여 LCM 절차 내의 각 단계마다 다양한 형태의 AI CSI 보고들 조합에 대한 정보일 수 있다. AI CSI 보고는표 16 및 표 17에 기초하여 구성 및 설정될 수 있다. 또한, AI CSI 보고는 표 16 및 표 17 이외의 다른 콘텐츠 나 다른 단계를 고려하여 구성 및 설정될 수 있으며, 특정 형태로 한정되지 않는다. 일 예로, AI 인코더 입력으로 로우 채널 매트릭스(raw channel matrix, H) 또는 레이 채널 메트릭스(ray channel matrix, V)의 고유벡터(eigenvector)가 제공될 수 있다. 로우 채널 매트릭스가 AI 인코더의 입력으로 제공되는 경우, 고유벡터 계산은 기지국에서 수행될 수 있으며, 이에 따라 기지국 복잡도가 증가할 수 있다. 또 한, 로우 채널 매트릭스는 프리코더 선택과 관련하여 불필요한 정보를 더 포함할 수 있으며, 이에 따라 오버헤 드가 증가할 수 있다. 상술한 특성들을 고려하면 AI 인코더의 입력 값으로 제공되는 AI CSI 콘텐츠(CSI content) 정보를 기반으로 AI 디코더 성능이 상이해질 수 있으며, 상술한 점을 고려하여 표 16 및 표 17 내의 입력 값들 중에서 적절한 입력 값들을 조합을 기반으로 AI CSI 보고 절차를 수행할 필요성이 있다. 일 예로, AI/ML 기반 CSI 피드백 절차가 수행되는 경우, AI/ML 기반 양자화된 CSI 압축 정보(AI/ML 기반 quantized CSI compression information)와 기존 CSI 보고/콘텐츠 정보(CSI report/contents information)가 동일한 에어 인터페이스를 통해 전달될 수 있다. 일 예로, AI/ML 기반 양자화된 CSI 압축 정보는 AI 인코더를 기반으로 도출되는 AI CSI 정보일 수 있으며, 기존 CSI 보고/콘텐츠는 채널 상태를 고려하여 보고되는 CSI 정보 일 수 있다. 일 예로, 기존 CSI 보고/콘텐츠는 AI/ML 모델을 기반하지 않은 무선채널 관련된 다양한 형태의 정 보를 포함할 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 다만, 하기에서는 설명의 편의를 위해 기존 CSI 정보로 지칭한다. 일 예로, AI/ML 기반 양자화된 CSI 압축 정보로 AI CSI 정보에 대한 AI CSI 보고 필드는 기존 CSI 보고 필드와 상이할 수 있다. 구체적으로, AI/ML 기반 양자화된 CSI 압축 정보에 해당하는 피드백 정보로 AI CSI 정보는 기 존 CSI 보고를 기반으로 분류될 수 있으나, CSI 보고 내에서 기존과 상이한 형태의 CSI 콘텐츠로 결정될 수 있 다. 또 다른 일 예로, AI/ML 기반 양자화된 CSI 압축 정보에 해당하는 피드백 정보로 AI CSI 정보는 새로운 CSI 보 고 타입으로 결정될 수 있다. 즉, AI-기반 CSI 보고(AI-based CSI report)는 기존 CSI 보고 방식과 상이한 새 로운 타입의 보고일 수 있으나, 해당 실시예로 한정되는 것은 아닐 수 있다. 또한, 투-사이드 모델(two-sided model)에서 오토 인코더를 지원하기 위해 PMI 정보(e.g., Type-3 codebook)를 포함하는 AI 기반 CSI 피드백 보고에 해당하는 새로운 코드북 타입이 결정될 수 있다. 새로운 코드북 타입은 'AI 기반 CSI 압축 피드백'을 효율적으로 지원하기 위해 새롭게 정의되는 상이한 형태의 CSI 콘텐츠 및 양자화 방법을 기반으로 결정될 수 있으나, 이에 한정되는 것은 아닐 수 있다. 또 다른 일 예로, AI CSI 보고 필드와 관련하여 기지국은 단말에게 AI/ML 모델을 위해 실제 트레이닝 데이터를 피드백하도록 설정할 수 있다. 단말이 AI/ML 모델에 대한 실제 트레이닝 데이터를 피드백하는 경우, 단말이 기 지국으로 전달하는 AI/ML CSI 보고에는 기존 PMI 정보와 실제 트레이닝 데이터 모두에 해당하는 CSI 파라미터들 이 포함될 수 있다. 또 다른 일 예로, AI CSI 보고 필드에는 새로운 CSI 필드(e.g., AI-based auto-encoder/NN parameters)가 적용 되는 것도 가능할 수 있다. 또 다른 일 예로, 단말은 계산 복잡도 수치에 대한 시그널링을 고려하여 단말 측에서 수행해야 하는 계산 복잡 도 정보를 AI CSI 보고 형태로 기지국에 전달할 수 있다. 일 예로, 계산 복잡도 수치에 대한 시그널링은 CPU 수, AI 기반 CSI 보고들의 수 및 그 밖의 정보를 기반으로 상이하게 설정될 수 있다. 구체적인 일 예로, AI 기 반 CSI 보고들의 수는 AI 기반 CSI 보고에 해당하는 계산 측정과 연관되어 상이하게 결정될 수 있으며 이에 따 라 계산 복잡도 수치가 상이해질 수 있다. 또 다른 일 예로, AI 기반 CSI 보고들의 수는 단말이 복수 개의 컴포 넌트 캐리어에서 수행하는지 여부 및 그 밖의 정보에 기초하여 상이하게 결정될 수 있으며 이에 따라 계산 복잡 도 수치가 상이해질 수 있으나, 특정 형태로 한정되는 것은 아닐 수 있다. 일 예로 기존 무선 통신 시스템에서 하나의 CSI 보고를 위한 시간 내에 보고되어야 하는 모든 CSI 콘텐츠들을 전송하기 위해 충분한 자원이 단말에게 제공되지 않을 수 있다. 단말은 CSI 보고를 위한 업링크 스케줄링에 기 초하여 업링크 자원을 제공받고, 이에 기초하여 CSI 콘텐츠를 포함하는 CSI 보고를 기지국으로 전달할 수 있다. 여기서, 단말이 기지국으로부터 제공받은 업링크 스케줄링에 기초하여 모든 CSI 콘텐츠들을 보고하기 위한 충분한 업링크 자원을 할당받지 못한 경우, 단말은 보고해야 하는 CSI 콘텐츠들 중 일부를 생략하고 나머지 CSI 콘 텐츠만을 보고할 수 있다. 즉, 단말은 CSI 생략(CSI omission)을 수행할 수 있다. 구체적인 일 예로, 단말이 상 술한 표 7의 타입 2 CSI 보고를 수행하는 경우로 RI가 2인 경우를 고려할 수 있다. 단말은 MU-MIMO 스케줄링 지 원을 고려하여 제한된 수의 레이어를 기반으로 CSI 보고를 수행할 수 있다. 여기서, RI가 2인 경우, PMI의 페이 로드는 RI가 1인 경우에 비해 약 2배 정도 많을 수 있다. 또한, 기지국은 단말에 의해 사전에 선택되는 RI를 인 지할 수 없으므로 기지국은 PUSCH 스케줄링을 수행하는 경우에 단말이 선택할 것으로 예상되는 RI 값을 기반으 로 스케줄링을 수행할 수 있다. 상술한 점을 고려하면, 기지국과 단말 사이의 RI 선택에 대한 비-정렬 (misalignment)이 발생할 수 있으며, 상술한 경우에 단말은 PUSCH 상에서 CSI 페이로드를 모두 전송할 수 없다. 일 예로, 코드 레이트가 큰 정보 또는 'uncoded systematic bit' 들이 PUSCH 상에서 전송되지 않을 수 있다. 따라서, CSI 보고 내의 일부 CSI 콘텐츠들은 드롭되거나 생략될 수 있다. 다만, 일부 중요한 CSI 파트들(i.e. contents)이 드롭되면 전체 시스템 상에서 성능 열하가 발생할 수 있으며, 상술한 점을 고려하여 기존에는 \"eType II codebook (CB)\"을 위한 CSI 파트 2가 3개의 그룹으로 나누어지도록 구성될 수 있으며, 이는 상술한 바와 같다. 여기서, CSI 그룹을 기반으로 CSI 파트들 중 중요한 CSI 파트들에 해당하는 정보들에 더 높은 우선 순위를 부여하여 PUSCH 상에서 전송되도록 할 수 있다. 일 예로, AI/ML 기반 CSI 압축 피드백은 상술한 \"eType II Code Book(CB)\"와 상이하게 'non-zero coefficients' , 'SD basis' , 'FD basis' , 'indication of non-zero coefficients' 등을 포함하지 않을 수 있다. 즉, AI/ML 기반 CSI 압축 피드백으로 AI CSI 정보는 CSI 관련 정보 자체라기보다는 그것이 압축된 양자화 정보(compressed quantization information)를 의미할 수 있다. 구체적으로, CSI 압축 피드백을 위한 AI/ML 모 델 내 CSI 생성 파트(CSI generation part)에서는 AI CSI 입력들을 기반으로 AI 인코딩 및 양자화 절차가 수행 될 수 있으며, 이에 따라 AI 인코더 출력이 도출될 수 있다. 단말에게 AI/ML CSI 보고를 위해 충분한 업링크 자 원이 할당되지 않는 경우, 단말은 AI 인코더 출력으로 양자화된 비트 정보들에 대해 중요도를 기반으로 선택적 으로 일부 비트 정보들을 기지국에게 전송할 수 있다. 일 예로, 모델 트레이닝(training) 및 모델 추론 (inference) 절차 중 적어도 어느 하나에서 AI CSI 보고를 수행해야 하는 경우, 단말은 양자화된 비트 정보들 중 중요도를 기반으로 일부 양자화된 비트 정보를 선택적으로 기지국에게 전송할 수 있다. 하기에서는 기지국에 의해 단말에 할당된 업링크 자원이 모든 AI CSI 정보를 전달하는데 충분하지 않은 경우, 해당 AI CSI 정보를 적어도 포함하는 UCI(또는 CSI) 페이로드가 AI CSI 정보 전달을 위해 조정되는 경우에 대해 서술한다. 또 다른 일 예로, 하기에서는 결정된 양자화된 CSI 정보 비트들이 양자화된 CSI 비트 서브 시퀀스, 우선순위 및 그 밖의 정보에 기초하여 일부 생략되는 AI CSI 생략이 수행될 수 있으며, 이와 관련하여 후술한다. 일 예로, 표 18의 옵션 1 내지 옵션 4 기반 동작이 수행될 수 있으나, 이에 한정되는 것은 아닐 수 있다. 구체 적으로, 단말은 AI 인코더 내의 양자화 절차와 관련하여 양자화 레졸루션을 가변적으로 설정하도록 하여 AI 인 코더 출력의 페이로드 크기를 조정하도록 할 수 있다.(옵션 1) 즉, 단말은 AI 인코더 내에서 업링크 자원 크기 를 고려하여 양자화 타입, 레벨 및 패턴 중 적어도 어느 하나를 제어할 수 있다. 또한, 상술한 바에 기초하여 기지국과 단말에 대한 양자화 정렬이 수행될 수 있다. 구체적인 일 예로, 표 18의 옵션 1에서 양자화는 AI CSI 콘텐츠에 따라 양자화 레벨을 조정하는 방식일 수 있다. 양자화 방법 및 양자화를 위한 비트 스트링 중 적어도 어느 하나는 AI CSI 콘텐츠들 사이의 우선순위에 따라 상이하게 적용될 수 있다. 또한, 각각의 CSI 생성 파트 (CSI generation parts)들마다 상이한 CSI 페이로드 크기를 결정할 수 있으나, 이에 한정되는 것은 아닐 수 있 다. 또 다른 일 예로, 단말 측 AI 인코더의 출력 크기는 다른 CSI 파라미터들을 고려하여 고정된 형태일 수 있다. (옵션 2) AI 인코더 출력 크기는 채널 특성이나 단말이 선택한 RI 값에 의해서도 변경되지 않도록 AI 인코더 내 에서 AI/ML 기반 CSI 피드백 압축 레벨이 조정될 수 있으나, 해당 실시예로 한정되지 않는다. 또 다른 일 예로, AI/ML 기반 CSI 압축은 레이어, 랭크, 서브 밴드 및 포트들 중 적어도 어느 하나를 기반으로 상이한 우선순위를 갖는 복수의 그룹들로 구분되러 수행될 수 있다. (옵션 3) 여기서, AI/ML 기반 CSI 압축을 기반으로 AI 인코터 출력으로 도출되는 AI CSI들 중 우선순위가 낮은 그룹에 대응되는 AI CSI들의 전송이 생략 될 수 있다. 또 다른 일 예로, AI CSI 정보들에 대한 하나의 AI CSI 보고는 복수 개의 서브 보고들로 분리되어 수행될 수 있 다.(옵션 4) 여기서, 각각의 서브 보고들은 제한된 업링크 자원으로 인해 상이한 전송 시간에 보고될 수있으며, 상술한 점을 고려하여 이전에 전송된 서브 보고들과 그 이후로 전송되는 서브 보고들의 관계를 결정할 필요성이 있다. 일 예로, 하나의 AI CSI 보고에 연관된 복수 개의 서브 보고들은 상이한 시간에 업링크 전송 자 원을 고려하여 보고될 수 있으며, 상술한 점을 통해 AI/ML 기반 CSI 압축 정보가 생략되지 않도록 할 수 있다. [표 18]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 25, "content": "표 18에서 제안된 옵션들은 단말 측의 AI/ML 인코더 측에서 적어도 하나 이상의 옵선들을 가진 조합을 기반으로 AI/ML 기반 CSI 압축 절차에 적용하는 것을 기본적으로 가정할 수 있다. 다만, 기지국과 단말 사이의 \"two- sided AI/ML model(기지국 및 단말 측에 각각 AI/ML 모델이 위치하고, 서로 상호 호환을 바탕으로 동작하는 모 델)\"을 기반으로 하는 다른 유스 케이스들에도 적용할 수 있다. 또한, 일 예로, 해당 인코더 내에서 인코딩 및 양자화 절차 중 적어도 어느 하나가 수행될 수 있으나, 구현에 따라서 양자화 절차는 인코딩 절차와 독립적으로 수행되는 것도 가능할 수 있다. 양자화 정렬(quantization alignment)은 기지국과 단말 사이에서 수행될 수 있다. 여기서, 양자화 정렬은 적응 적 CSI 페이로드 크기 조절을 위해 수행될 수 있으며, 이를 통해 제한된 업링크 자원에서 효율적으로 AI CSI 보 고를 수행하도록 할 수 있다. 구체적으로, 기지국은 단말로부터 전달되는 CSI 생성 파트 출력 값으로 AI CSI 정보의 디코딩을 위해 단말에 의 해 보고되는 양자화된 AI CSI 정보의 크기를 사전에 인지할 필요성이 있다. 단말에 의해 수행되는 양자화 방법 이 기지국과 서로 정렬되지 못하면, 기지국은 단말 측 CSI 생성 파트 출력 값을 성공적으로 디코딩할 수 없다. 또는, 기지국이 단말의 양자화 방법 및 이에 대한 파라미터 설정 정보를 사전에 인지하지 못하는 경우, 기지국은 단말과 양자화 정렬을 제대로 수행할 수 없고 단말 측 CSI 생성 파트 출력 값을 성공적으로 디코딩할 수 없 다. 즉, 단말 측 CSI 생성 파트의 인코더 출력이 기지국 측 CSI 재구성 파트(CSI reconstruction part)의 입력 으로 전송되는 상황에서 양자화 정렬이 이루어질 필요성이 있다. 도 13은 본 개시에 적용 가능한 AI 인코더에서 스칼라 양자화가 수행되는 방법을 나타낸 도면이다. 도 13을 참 조하면, 양자화 정렬을 위해 기지국 측 디코더(decoder)는 양자화 절차를 고려하여 하기 수학식 9에 의해 도출 되는 비트 스트링 또는 비트 시퀀스를 단말로부터 수신할 수 있다. 수학식 9에서 S는 비트 스트링또는 비트 시 퀀스일 수 있으며, 단말 측 AI 인코더의 출력 값일 수 있다. 여기서, K는 인코더 출력 레이어의 노드들 수로 인 코더 출력 크기일 수 있다. 또한, Q는 각 노드 당 양자화 비트 수 일 수 있다. 즉, AI 인코더 출력 값은 출력 노드들의 크기 및 각 노드 당 양자화 비트 수의 곱으로 그 크기가 결정될 수 있다. [수학식 9]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 26, "content": "일 예로, AI/ML에 기초하여 추론 절차가 수행되는 경우, CSI 보고 내에서 사용되는 비트 수는 양자화를 통해 최 소화될 수 있으며, 이를 통해 업링크 자원 소모를 줄일 수 있다. 도 13을 참조하면, 단말 측 인코더와 기지국 측 디코더는 단말과 기지국 사이에서 교환되는 비트 스트링(또는 비스 시퀀스) S를 사전에 인지할 수 있 다. 일 예로, 비트 스트링 S는 사전에 기 설정된 값으로 고정될 수 있다. 또 다른 일 예로, 비트 스트링 S는 기지국에 의해 단말로 시그널링되는 값 또는 그 시그널링을 기반하여 결정되는 값일 수 있으나, 특정 형태로 한정되지 않는다. 비트 스트링 S는 인코더의 출력 크기(또는 사이즈, K, 1310)와 노드 당 양자화 비트 수(Q, 1320) 값으로 결정되므로 인코더의 출력 크기 K와 노드 당 양자화 비트 수 Q의 하나 이 상의 조합에 기초하여 상이하게 결정될 수 있다. 일 예로, 상술한 양자화 노드는 서로 다른 AI-CSI 콘텐츠 들의 각각 또는 그 일부 조합에 대응할 수 있다. 구체적인 일 예로, 하나의 출력 노드 #0(Output node #0)이 L1-RSRP 값에 대응하는 경우, 해당 노드에 대응하는 Q 값(e.g. 7bit) 및 Q 값의 범위(e.g. [-140, 44] dBm with 1dB step)가 결정될 수 있다. 여기서, 다른 출력 노드로 출력 노드 #1(Output node #1)이 RI 값에 대응되는 경우, 해당 노드에 해당하는 Q 값 및 Q 값의 범위는 독립적으로 결정될 수 있다. 따라서, 보고되는 AI CSI 콘텐츠들을 고려하여 보고되는 조합 및 양자화 방식에 따 라서 전체 비트 스트링 S 값이 결정될 수 있다. 다만, 상술한 경우는 하나의 일 예일 뿐, 이에 한정되는 것은 아닐 수 있다. 가능한 모든 AI CSI와 CSI를 위한 파라미터/콘텐츠(parameter/contents)들에 따라 적용되는 양자 화 방식을 제안된 비트 스트링 결정 방법에 따라 적용할 수 있다. 일 예로, 기지국과 단말은 비트 스트링 S가 사전에 인지되더라도 인코더의 출력 크기 K와 노드 당 양자화 비트 수 Q를 정확히 유도하기 어려울 수 있다. 구체적인 일 예로, CSI 압축 협력 타입 2와 타입 3 트레이닝에서 인코더 파트와 디코더 파트가 상이한 구조를 가지는 경우, 기지국과 단말은 양자화 정렬로 비트 스트링 S 를 인지하더라도 인코더 출력 크기 K와 노드 당 양자화 비트 수 Q을 인지하지 못할 수 있다. 보다 구체적인 일 예로, 고정된 비트 스트링 S에 대해서 \"S = K1xQ1 = K2xQ2 쪋\" 복수의 조합들 이 존재할 수 있으므로 기지국과 단말은 비트 스트링 S뿐만 아니라 인코더 출력 크기 K와 노드 당 양자화 비트 수 Q 모두를 인지할 필요성이 있으며, 이에 기초하여 양자화 정렬이 수행될 수 있다. 다만, 상술한 방식에 의해 양자화 절차가 동작하지 않는 경우로 \"S\" 값만을 기지국과 단말 사이에서 사전에 기 설정된 값, 상위 레이어 설정 및 물리계층 시그널링(L1 signaling) 중 적어도 하나의 방식에 의해 지시될 수 있 으며, 특정 형태로 한정되지 않는다. 일 예로, 기지국과 단말 사이에 양자화 정렬을 위해 기지국은 단말의 능력(capability) 정보를 고려하여 AI 인 코더 양자화 동작을 위한 인코더 출력 크기 K 및 노드 당 양자화 비트 수 Q 중 적어도 어느 하나에 연관된 설정 (또는 양자화 레벨 관련 파라미터 설정)을 상위레이어 시그널링을 통해 단말로 지시할 수 있다. 단말은 기지국 시그널링에 기초하여 지시된 설정 정보에 따라 동작하거나 또는 지시된 정보에 기초하여 제한된 값의 범위 내에 서 단말 AI/ML 모델에서 선호하는 값의 선택을 기반으로 양자화 레벨을 AI 인코더에 적용할 수 있다. 그 후, 단 말은 선택한 양자화 레벨 관련 정보(또는 파라미터)를 사이드 정보 형태로 AI CSI 보고에 함께 추가적으로 기지 국으로 전달할 수 있다. 또 다른 일 예로, AI 인코더 양자화 동작을 위한 인코더 출력 크기 K 및 노드 당 양자화 비트 Q 중 적어도 어느 하나에 연관된 설정(또는 양자화 레벨 관련 파라미터 설정)는 기지국과 단말 사이에서 기 설정되는 것도 가능할 수 있다. 단말은 기 설정된 정보에 따라 동작하거나 기 설정된 정보에 기초하여 제한된 범위 내에서 단말 선택 을 기반으로 선호하는 양자화 레벨을 AI 인코더에 적용할 수 있다. 그 후, 단말은 양자화 레벨 관련 정보(또는 파라미터)를 사이드 정보 형태로 AI CSI 보고에 함께 기지국으로 전달할 수 있다. 또 다른 일 예로, 상술한 바 와 같이 K 및 Q 값이 아닌 S 값이 기지국과 단말 사이에서 기 설정되는 것도 가능할 수 있다. 또 다른 일 예로, AI 인코더와 AI 디코더 사이에서 양자화 방법이 공유될 수 있다. 상술한 협력 타입 1(collaboration type 1)인 경우, 양자화 방법에 대한 정보는 모델 전달(model transfer) 과정에서 공유될 수 있다. 일 예로, 협력 타입 1은 하나의 엔티티에서 AI/ML 모델을 결정하고, 다른 엔티티로 모델을 전달하는 타입 일 수 있으며, AI/ML 모델 전달과 함께 양자화 방법에 대한 정보도 같이 전달될 수 있다. 구체적인 일 예로, 기 지국이 모델링을 수행하는 경우, 기지국은 단말로 모델 전달을 수행하는 과정에서 양자화 방법 정보를 함께 전 달할 수 있다. 또는, 단말에 의해 상기 협력 타입 모델 1을 기반한 모델 트레이닝 수행하는 경우, 단말은 기지 국으로 모델 전달을 수행하는 과정에서 양자화 방법 정보를 함께 전달할 수 있으나, 해당 실시예로 한정되지 않 는다. 또 다른 일 예로, 협력 타입 2(collaboration type 2) 또는 협력 타입 3(collaboration type 3)인 경우, 단말과 네트워크 사이의 초기 정보 교환에서 양자화 방법에 대한 정보가 공유될 수 있으나, 해당 실시예로 한정 되지 않는다. 또한, 양자화 정렬을 위해 각 단말의 벤더들마다 고유의 양자화 방법을 사용하는 경우에 네트워크 측에서 CSI 보고를 처리하는 복잡도가 클 수 있다. 또한, 각 단말의 벤더들마다 고유의 양자화 방법을 사용하는 경우에는 저장공간 처리 및 스위칭 지연이 야기될 수 있다. 상술한 점을 고려하여 기지국이 양자화 방법을 결정하고 네트 워크 측에서 AI 모델 트레이닝(Training)을 수행할 수 있다. 상술한 바와 같이 양자화 방법이 다이나믹하게 결정되는 경우, 단말 측의 AI/ML 모델 기반 CSI 생성 파트(CSI generation part)의 출력으로 CSI 페이로드 크기가 조절될 수 있다. 일 예로, AI/ML 모델의 CSI 생성 파트의 인 코더 출력 크기 K 및 노드 당 양자화 비트 수 Q 중 적어도 어느 하나가 양자화 조정을 통해 변경될 수 있으며, 이에 따라 AI CSI 비트 스트링 S의 크기가 상이하게 조정될 수 있다. 즉, 수학식 9에 기초하여 상술한 K 및 Q 중 적어도 어느 하나에 기초하여 또는 K 및 Q 값을 사용하지 않고 바로 S가 조정될 수 있다. 다만, 기지국과 단말 사이에 양자화 정렬을 위해 상술한 바와 같은 시그널링을 수행하는 경우라도 단말 구현 상 의 자유도에 따라 상이한 양자화 절차 수행이 가능할 필요성이 있다. 따라서, 특정 양자화 모델(e.g. scalar quantization or vector quantization) 및 관련 파라미터들 (e.g. 상기 Q, K, S 등)을 모두 공유하는 것보다는 양자화 레벨을 정의하여 해당 양자화 레벨에 연관된 특정 양자화 모델 및 관련 파라미터 설정하는 방법이 필요 할 수 있다. 하기 표 19는 양자화 레벨로 'High', 'Medium' 및 'Low'로 구분한 것으로 기지국은 표 19에 따른 시그널링을 단말로 제공할 수 있다. 단말은 기지국으로부터 시그널링된 값을 기반으로 양자화 절차를 수행할 수 있다. 다만, 하기 표 19는 설명의 편의를 위한 하나의 일 예일 뿐 이에 한정되는 것은 아닐 수 있다. [표 19]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 27, "content": "구체적인 일 예로, 단말은 표 19의 스칼라 양자화 레벨('High', 'Medium' 및 'Low') 각각과 연관된 양자화 모델 및 관련 파라미터 값들을 기지국으로부터 사전에 설정 또는 제공 받을 수 있다. 단말은 제공된 값을 기준으로 양자화 절차를 수행하여 CSI 페이로드 크기를 조정할 수 있다. 또는, 단말은 제공된 값을 기반으로 단말의 선택에 의해 결정된 양자화 절차를 수행하여 CSI 페이로드 크기를 조정할 수 있다. 표 19는 스칼라 양자화 레벨을 기반으로 양자화 방법이 설정 및 적용에 대한 예시일 수 있으며, 다른 양자화 모델을 기반으로 설정될 수 있다. 또한, 설정된 다른 양자화 모델을 위한 파라미터 값들이 같은 양자화 레벨에 상기 표와 같이 매핑 되어 설정 및 지시되는 것도 가능할 수 있으며, 특정 형태로 한정되지 않는다. 상술한 바에 기초하여 다수의 양자화 모델이 존재하더라도 관련 파라미터들의 조합을 제한할 수 있으며, 이에 따라 기지국과 단말 사이에 양자화 구현이 간단해질 수 있다. 또한, 일 예로, 특정 양자화 모델과 파라미터로 한정되는 AI 모델의 사용은 기지국과 단말 사이에 다수의 AI 모델을 저장해야 하는 구현 복잡도가 증가할 수 있 으며, 비용도 증가하는 단점이 존재할 수 있다. 상술한 바를 통해구현 부담과 비용 증가 부담을 줄이면서 CSI 페이로드 크기를 조정할 수 있다. 또 다른 일 예로, 표 19와 같이 양자화 레벨을 정의하지 않고, LCM 절차 내에서 AI 모델, 특징(feature) 및 네 트워크 condition 구분을 위해서 사용되는 AI 모델/특징 ID(AI Model/Feature ID/Associated ID) 및 해당 모델 내에서 사용되는 AI 인코더 인덱스 중 적어도 어느 하나에 기초하여 양자화 모델 및 관련 파라미터 값들이 연관 및 매칭될 수 있으며, 표 20과 같을 수 있다. 단말은 표 20에 대한 정보를 상위 레이어 시그널링을 통해 기지국 으로부터 획득할 수 있다. 또한, 표 20에 대한 정보는 기 설정된 정보일 수 있으나, 이에 한정되지 않는다. 단 말은 제공된 값을 기준으로 양자화 절차를 수행하여 CSI 페이로드 크기를 조정할 수 있다. 또는, 단말은 제공된 값을 기반으로 단말의 선택에 의해 결정된 양자화 절차를 수행하여 CSI 페이로드 크기를 조정할 수 있다. 즉, 적응적으로 AI 및 양자화 모델/파라미터 관련 정보, CSI 콘텐츠 및 연관된 우선순위 정보들 중 적어도 어느 하 나를 활용하여 업링크 자원을 통해 전달되는 AI CSI 보고와 관련된 CSI 페이로드 크기를 조정할 수 있다. [표 20]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 28, "content": "즉, 단말은 기지국으로부터 시그널링되거나 기 설정된 양자화 관련 정보 또는 양자화 관련 파라미터에 대응되는 양자화 절차를 수행하거나 기 설정된 양자화 관련 정보 또는 양자화 관련 파라미터를 기반으로 단말의 선택에 의해 결정된 양자화 절차를 수행함으로써 CSI 페이로드 크기가 조정되도록 할 수 있다. 여기서, 상술한 표 19 및 표 20은 하나의 일 예일 수 있으며 단말은 상이한 정보(또는 파라미터)를 기반으로 양자화 절차를 수행할 수 있다. AI/ML 기반 CSI 콘텐츠는 하나 또는 그 이상의 CSI 파트로 구성 또는 설정될 수 있다. 이러한 구성 또는 설정은 기지국 설정 또는 단말 능력(UE Capability) 보고를 통해 기지국과 단말 사이에 공유되거나 기 설정된 값으로 결정될 수 있다. 하기에서 AI CSI 보고는 1개 또는 2개 AI 기반 CSI 파트들이 사용되는 것을 기준으로 설명하지 만 이는 설명의 편의를 위한 것일 뿐 이에 한정되는 것은 아닐 수 있다. 즉, AI CSI 보고에서 2개 이상의 CSI 파트들이 사용되는 것도 가능할 수 있다. 또한, 하기에서는 설명의 편의를 위해 하나의 CSI 파트로 구성된 AI CSI 보고와 적어도 두 개의 CSI 파트들로 구성된 AI CSI 보고를 기준으로 관련 내용을 서술한다. 다만, 이는 설명의 편의를 위한 구성일 뿐 이에 한정되 는 것은 아닐 수 있다. 일 예로, 투 사이드 AI/ML 모델(two-sided AI/ML model)을 기반하는 CSI 압축을 위해 어떤 모델 형태(e.g. layer-common model, layer specific model, rank-common model 또는 rank-specific model)가 적용되는지 여부에 따라 한 개의 CSI 파트로 구성된 AI CSI 보고 및 적어도 두 개의 CSI 파트로 구성 된 AI CSI 보고 형태가 사용될 수 있으나, 이에 한정되지 않는다. 일 예로, 한 개의 CSI 파트만 사용되는 경우, 기지국과 단말은 양자화 정렬을 통해 AI/ML 모델 전체 출력 CSI 페이로드 크기를 모델에 따라서 고정 또는 미리설정된 것으로 결정할 수 있다. 즉, AI 인코더 출력 시퀀스의 크기는 채널 특성이나 단말이 선택한 'RI' 값, 'non-zero coefficient 값의 수' , 'SD' 및 'FD basis의 수'에 의해 변경되지 않을 수 있다. 하기에서는 기지국에 의해서 단말에게 할당된 업링크 자원을 통해 전달할 수 있는 UCI(CSI) 페이로드 크기를 우 선순위에 기초하여 양자화 방법을 상이하게 적용하여 조정하도록 하는 방안에 대해 서술한다. 또 다른 일 예로, 양자화 방법은 우선순위를 고려하지 않고 단말에 의해서 구현적으로 선택한 방식에 따라서 적용될 수 있으나, 이에 한정되지 않는다. AI 기반 압축 CSI(i.e. UCI) 보고 절차는 기존 CSI 보고 방법과 상이하게 AI 인코더 내 에서 AI 인코딩 및 양자화 절차를 통해 도출되는 AI 인코더 출력을 AI CSI로 보고할 수 있다. 일 예로, 양자화 절차는 다양한 구현 방법들을 통해 단말 구현에 의해서 적용될 수 있다. 양자화 정렬은 수신 측(즉, 기지국 디 코더)에서 해당 AI 기반 압축 CSI 정보를 정확하게 디코딩하기 위해 사전에 기지국과 단말이 수행할 수 있다. 하기에서는 AI 기반 UCI(CSI) 페이로드 크기를 조절하는 방법으로 사전에 설정된 복수의 Q(노드 당 양자화 비트 수)들 중에서 인코더 출력 노드(encoder output node), 노드 그룹(node group) 또는 시퀀스 그룹(sequence group)마다 독립적인 양자화 비트 수 Q를 사용하는 방법에 대해 서술한다. 상술한 바를 통해 전체 AI 인코더 비 트 스트링 크기를 우선순위 또는 기 설정된 규칙에 의해 조정할 수 있다. 단말은 기지국에 의해 할당된 업링크 자원을 통해 UCI 보고를 수행하기 위해 업링크 자원 양을 고려하여 UCI 페이로드 크기를 적응적으로 결정할 수 있다. 여기서, 단말에 의해 결정된(또는 선택된) 정보는 사이드 정보로써 기지국에게 AI 압축 CSI 보고와 함께 전달될 수 있고, 기지국 측 AI 디코더는 이를 활용하여 디코딩을 수행할 수 있다. 하기에서 서술하는 방법들은 상술한 양자화 정렬 방법을 위해서 제안된 시그널링 및 절차를 기반하는 동작할 수 있다. 구체적인 일 예로, 표 17에서 보여주는 우선순위 관련 정보와 표 18 및 표 19내의 양자화 정렬을 위한 파 라미터 설정이 하기 서술하는 방안에 적용될 수 있으나, 이에 한정되지 않는다. 도 14는 본 개시에 적용 가능한 AI 인코더 내의 적응적 양자화 방법에 따라 AI CSI 페이로드 사이즈를 조절하는 방법을 나타낸 도면이다. 일 예로, AI 인코더의 출력 크기 K는 사전에 결정되고, 노드 당 양자화 비트 수 Q는 적응적으로 결정되는 경우 를 고려할 수 있다. 도 14를 참조하면, AI 인코더의 출력 크기(K, 1410)는 4로 결정되고, 노드 당 양자화 비트 수(Q, 1420)는 Q1 또는 Q2로 결정될 수 있다. 다만, 도 14는 설명의 편의를 위한 일 예일 뿐 이에 한정되지 않 는다. 여기서, AI 인코더의 출력 노드들 중 높은 CSI contents의 우선순위를 가지는 출력 노드는 더 큰 양자화 비트(Q1)의 값을 갖고, 낮은 우선순위를 갖는 출력 노드는 Q1보다 작은 양자화 비트(Q2) 값을 갖도록 결정될 수 있다. 즉, AI 인코더 출력 노드의 우선순위에 기초하여 양자화 비트 값이 상이하게 결정될 수 있으며, 상술한 바에 따라 CSI 페이로드 크기를 조정할 수 있다. 구체적인 일 예로, 도 14에서 AI 인코더 출력 크기(K, 1410)는 랭크 수, 레이어 또는 다른 CSI contents 중 적 어도 어느 하나에 기초하여 결정될 수 있다. AI 인코더 출력 노드 각각에 대해서 Q 값이 개별적으로 적용될 수 있다. 또 다른 일 예로, AI 인코더 출력 노드 각각에 대해서 Q 값이 개별적으로 적용된 후 K 값은 UCI 크기 조 정을 위한 목적으로 적응적으로 재조정되는 것도 가능할 수 있으나, 이에 한정되는 것은 아닐 수 있다. 노드당 양자화 비트로 복수의 Q 값은 기지국 시그널링에 의해 지시되거나 기 설정된 값일 수 있다. 단말은 복수 의 Q 값들 중에서 Q1과 Q2가 사용되는 각각의 출력 노드들을 결정할 수 있다. 일 예로, 단말은 상술한 표 17의 우선순위 정보(e.g. layer 정보, Sub-band 정보, Antenna port정보, Rank 수, AI compressed CSI content, Quantization granularity, latent space 크기 및 AI-CSI content들과 조합들) 중 적어도 어느 하나를 기반으 로 출력 노드의 Q 값을 결정할 수 있다. 그 후, 결정된 우선순위에 각각 매핑되는 양자화 동작 설정 및 결정에 따라서 각각 시퀀스 그룹에 대응하는 출 력 노드들이 결정될 수 있으며, 각각의 출력 노드들에서 양자화된 비트 시퀀스가 생성될 수 있다. 각각의 출력 노드들을 통해서 생성되는 양자화된 비트 시퀀스는 멀티플렉싱/제어기를 거쳐서 최종 AI 인코더의 출력으로 시 퀀스 비트(S, 1430)가 생성될 수 있다. 또한, 일 예로, 단말은 우선순위를 고려하지 않고, 단말 구현 정보 및/또는 기지국으로부터 설정/기설정을 기반 으로 출력 노드의 Q 값을 결정할 수 있다. 즉, 어떤 CSI 콘텐츠 관련 정보가 각 출력 노드의 Q 값에 대응하는지 는 단말 구현에 맡길 수 있다. 일 예로, 도 14에서 출력 노드 #0 및 출력 노드 #1이 Q1에 대응하는 시퀀스 그룹1에 포함되고, 나머지 출력 노드 #2 및 출력 노드 #3은 Q2에 대응하는 시퀀스 그룹 2에 포함될 수 있다. 여기서, 각 시퀀스 그룹마다 상이한 양자화가 수행될 수 있으며, 이에 기초하여 최종 출력 시퀀스 비트(S, 1430)가 결정되어 CSI 페이로드 크기가 조정될 수 있다. 일 예로, 출력 노드에 해당하는 비트 열은 하나의 전송 레이어에 연관될 수 있다. 또 다른 일 예로, 출력 노드 에 해당하는 비트 열은 전송 레이어에 대응하는 것이 아닌 모든 레이어에 공통적으로 대응할 수 있으나, 이에 한정되는 것은 아닐 수 있다. 하기 표 21은 AI 기반 CSI 페이로드 크기 조정을 수행하는 경우에 우선순위 기반 양자화 비트 조정을 나타낸다. 상술한 바와 같이 AI 인코더의 출력 노드마다 상이한 양자화 비트 수가 결정될 수 있으며, 표 21에서는 서브 시 퀀스 그룹 단위로 CSI 페이로드 조정이 가능할 수 있다. 구체적으로, 단말은 기지국으로부터 할당 받은 업링크 자원을 고려하여 높은 우선순위에 대응하는 AI 인코더 출력의 서브 그룹으로 시퀀스 그룹 1에 포함되는 출력 노 드에 양자화 비트 수 Q1을 할당하고, 낮은 우선순위에 대응하는 AI 인코더 출력의 서브 그룹으로 시퀀스 그룹 2 에 포함되는 출력 노드에 양자화 비트 수 Q2를 할당할 수 있다. 상술한 바를 통해 AI 인코더 출력으로 비트 스 트링(S)가 조정될 수 있으며, 단말은 조정된 비트 스트링(S)를 기반으로 업링크 자원을 통해 AI CSI 보고를 수 행할 수 있다. [표 21]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 29, "content": "도 15는 본 개시에 적용 가능한 AI 인코더 내의 적응적 양자화 방법에 따라 AI CSI 페이로드 사이즈를 조절하는 방법을 나타낸 도면이다. 일 예로, AI 인코더의 출력 크기 K는 사전에 결정되고, 노드 당 양자화 비트 수 Q는 적응적으로 결정되는 경우를 고려할 수 있다. 도 15를 참조하면, AI 인코더의 출력 크기(K, 1510)는 4이고, 양 자화 비트 수(Q, 1520)는 Q1, Q2 또는 Q3로 각각 결정될 수 있다. 즉, 도 15에서는 도 14에서보다 노드 당 양자 화 비트 수 및 이에 대응하는 시퀀스 그룹 수가 더 세분화되어 구분될 수 있다. 일 예로, AI 인코더의 출력 노 드들 중 높은 우선순위를 가지는 출력 노드는 가장 큰 양자화 비트(Q1)의 값을 갖고, 그 다음 우선순위를 갖는 출력 노드는 Q1보다 작은 양자화 비트(Q2) 값을 갖고, 마지막 우선순위를 갖는 출력 노드는 Q2보다 작은 양자화 비트(Q3)를 갖도록 할 수 있다. 즉, AI 인코더 출력 노드의 우선순위에 기초하여 양자화 비트 값을 조정할 수 있으며, 이에 따라 CSI 페이로드 크기를 줄일 수 있다. 일 예로, 도 15에서 AI 인코더 출력 크기(K, 1510)는 랭크 수 또는 레이어 또는 다른 CSI 콘텐츠 관련 정보들 중 적어도 어느 하나에 기초하여 결정될 수 있다. 여기서, AI 인코더 출력 노드 각각에 대해서 Q 값이 개별적으 로 적용될 수 있다. 또 다른 일 예로, AI 인코더 출력 노드 각각에 대해서 Q 값이 개별적으로 적용된 후 K 값은 UCI 크기 조정을 위한 목적으로 적응적으로 재조정되는 것도 가능할 수 있으나, 이에 한정되는 것은 아닐 수 있 다. 복수의 Q 값으로 Q1, Q2 및 Q3는 기지국 시그널링에 의해 결정되거나 기 결정될 수 있다. 단말은 복수의 Q 값들 중에서 Q1, Q2 및 Q3가 사용되는 각각의 출력 노드들을 결정할 수 있다. 일 예로, 단말은 상술한 표 17의 우선 순위 정보(e.g. layer 정보, Sub-band 정보, Antenna port정보, Rank 수, AI compressed CSI content, Quantization granularity, latent space 크기 및 AI-CSI content들과 조합들) 중 적어도 어느 하나를 기반으 로 출력 노드의 Q 값을 결정할 수 있다. 결정된 우선순위에 각각 매핑되는 양자화 동작 설정 및 결정에 따라서 각각 시퀀스 그룹에 대응하는 출력 노드 들이 결정될 수 있다. 그 후, 각각의 출력 노드들을 통해서 생성되는 양자화된 비트 시퀀스는 멀티플렉싱/제어 기를 거쳐서 최종 AI 인코더의 출력 시퀀스 비트(S, 1530)로 생성될 수 있다. 또한, 일 예로, 위와 유사하게 단말은 우선순위를 고려하지 않고, 단말 구현 정보를 기반으로 출력 노드의 Q 값 을 결정할 수 있다. 도 15에서 출력 노드 #0 및 출력 노드 #1이 Q1에 대응하는 시퀀스 그룹 1에 포함되고, 출력 노드 #2는 Q2에 대응하는 시퀀스 그룹 2에 포함되고, 출력 노드 #3은 Q3에 대응하는 시퀀스 그룹 3에 포함될 수있다. 여기서, 각 시퀀스 그룹마다 상이한 양자화 절차가 수행될 수 있으며, 이에 기초하여 최종 출력 시퀀스 비트(S, 1530)가 결정되어 CSI 페이로드 크기가 조정될 수 있다. 일 예로, 출력 노드에 해당하는 비트 열은 하 나의 전송 레이어에 연관될 수 있다. 또 다른 일 예로, 출력 노드에 해당하는 비트 열은 전송 레이어에 대응하 는 것이 아닌 모든 레이어에 공통적으로 대응할 수 있으나, 이에 한정되는 것은 아닐 수 있다. 하기 표 22는 AI 기반 CSI 페이로드 크기 조정을 수행하는 경우에 우선순위 기반 양자화 비트를 조정을 나타낼 수 있다. 상술한 바와 같이 AI 인코더의 출력 노드마다 상이한 양자화 비트 수가 결정될 수 있으며, 표 22에서 는 서브 시퀀스 그룹 단위로 CSI 페이로드 조정이 가능할 수 있다. 구체적으로, 단말은 기지국으로부터 할당 받 은 업링크 자원을 고려하여 높은 우선순위에 대응하는 AI 인코더 출력의 서브 그룹으로 시퀀스 그룹 1에 포함되 는 출력 노드에 양자화 비트 수 Q1을 할당하고, 그 다음 우선순위에 대응하는 AI 인코더 출력의 서브 그룹으로 시퀀스 그룹 2에 포함되는 출력 노드에 양자화 비트 수 Q2를 할당하고, 마지막 우선순위에 대응하는 AI 인코더 출력의 서브 그룹으로 시퀀스 그룹 3에 포함되는 출력 노드에 양자화 비트 수 Q3를 할당할 수 있다. 상술한 바 를 통해 AI 인코더 출력으로 비트 스트링(S)가 조정될 수 있으며, 단말은 조정된 비트 스트링(S)를 기반으로 업 링크 자원을 통해 AI CSI 보고를 수행할 수 있다. [표 22]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 30, "content": "도 16은 본 개시에 적용 가능한 AI 인코더 내의 적응적 양자화 방법에 따라 AI CSI 페이로드 사이즈를 조절하는 방법을 나타낸 도면이다. 도 16을 참조하면, 도 14 및 도 15와 상이하게 AI 인코더 출력 크기 K가 조정될 수 있으며, 이에 따라 CSI 페이로드 크기도 조정될 수 있다. 일 예로, 단말은 출력 노드(또는 레이어) 크기를 UCI(CSI) 전송을 스케줄링하는 업링크 그랜트에 의해 할당된 업링크 자원을 고려하여 조정할 수 있으며, 이를 통해 업링크 자원에 맞도록 CSI 페이로드 크기를 조정할 수 있다. 도 17은 본 개시에 적용 가능한 본 개시에 적용 가능한 AI 인코더 내의 적응적 양자화 방법에 따라 AI CSI 페이 로드 사이즈를 조절하는 방법을 나타낸 도면이다. 도 17을 참조하면, 양자화 절차를 위해서 고려되는 파라미터 들로 AI 인코더 출력 크기(K, 1710)와 양자화 비트 수(Q, 1720)가 조정되지 않고, 기 결정된 K 및 Q에 의해 CSI 페이로드 크기가 결정될 수 있다. 여기서, 기 결정된 K와 Q를 기반으로 CSI 페 이로드 크기를 조정하기 위해 AI UCI 펑처링(AI UCI puncturing)이 AI 인코더 출력 노드(레이어)에 적용될 수 있다. 일 예로, 단말은 UCI(CSI) 전송을 스케줄링하는 업링크 그랜트에 의해 할당된 업링크 자원을 고려하여 AI UCI 펑처링을 수행할 수 있다. 이를 통해, AI 인코더 출력으로 비트 스트링 S가 업링크 자원을 통해 전송될 수 있도록 CSI 페이로드 크기가 조정될 수 있다. 도 17에서 단말은 할당된 업링크 자원을 고려하여 출력 노드 #0 내지 출력 노드 #3 중 출력 노드 #2 및 출력 노드 #3에 대한 부분을 펑처링할 수 있으며, 이를 통해 UCI 페이로 드 크기는 업링크 자원 내로 제한할 수 있다. 일 예로, 어떤 출력 노드(Output node)에 해당하는 AI UCI 정보를 펑처링할지는 해당 UCI(CSI) 콘텐츠의 이미 상기 기술된 우선순위에 따라서 결정할 수 있다. 또 다른 일 예로, AI 인코더는 특정된 K 값 및 Q 값을 기반으로 CSI 페이로드 생성을 위한 양자화 절차를 수행 할 수 있다. 여기서, 단말은 복수 개의 AI 인코더들을 사용할 수 있으며, 복수 개의 AI 인코더 중 적어도 하나 의 AI 인코더를 선택하여 사용할 수 있다. 도 18은 본 개시에 적용 가능한 AI 인코더 스위칭에 기초하여 AI CSI 페이로드 크기를 조정하는 방법을 나타낸 도면이다. 도 18을 참조하면, 단말은 두 개의 AI 인코더를 사용할 수 있으며, 두 개의 AI 인코더 중 적어도 어 느 하나를 선택하여 사용할 수 있다. 다만, 이는 설명의 편의를 위한 것일 뿐, 이에 한정되는 것은 아닐 수 있 다. 도 18에서 첫 번째 AI 인코더는 특정된 Q1 값 및 K1 값에 따라 결정되는 S1 값을 기반으로 양자화를수행하고, 두 번째 AI 인코더는 특정된 Q2 값 및 K2 값에 따라 결정되는 S2 값을 기반으로 양자화를 수행 할 수 있다. 여기서, 단말은 UCI를 스케줄링하는 업링크 그랜트에 따라 할당된 업링크 자원의 크기 및 보고되어 야 하는 CSI 페이로드를 고려하여 AI CSI 보고를 결정할 수 있다. 구체적으로, 단말은 CSI 페이로드 크기를 고 려하여 복수 개의 AI 인코더 중 적어도 어느 하나의 AI 인코더를 선택할 수 있다. 일 예로, 단말은 AI 인코더 모델을 고려하여 AI 인코더 모델 수 및 단말 능력을 기반으로 특정 인코더에 대한 선택을 수행할 수 있다. 도 18을 참조하면, 단말은 업링크 자원을 고려하여 두 개의 AI 인코더(1810, 1820) 중 어느 하나의 AI 인코더를 선 택하고, 선택된 AI 인코더에 대한 비트 스트링 S로 결정되는 CSI 페이로드를 업링크 자원을 통해 기지국으로 전 달할 수 있다. 일 예로, 단말에 구성되는 복수 개의 AI 인코더마다 우선순위가 상이할 수 있으며, 단말은 우선 순위가 높은 AI 인코더에 대한 비트 스트링을 먼저 전송할 수 있으나, 이에 한정되지 않는다. 그 우선순위는 상 술한 AI CSI 콘텐츠에 연관된 정보를 기반으로 그 정보가 처리되는 AI 인코더는 해당 AI CSI 콘텐츠에 연관되며, 만약 복수 개의 AI CSI 콘텐츠들이 존재하는 경우, 그 중에서 가장 높거나 또는 낮은 우선순위를 기 준으로 AI 인코더에 대한 우선 순위를 결정할 수 있다. 단말은 선택된 AI 인코더에 대한 비트 스트링 S를 업링크 자원을 통해 기지국으로 전달한 후 AI 인코더를 스위 칭하고, 이후 시점에 단말에 할당되는 업링크 자원을 통해 다른 AI 인코더의 비트 스트링을 기지국으로 전송할 수 있다. 즉, 각각의 AI 인코더에 대한 비트 스트링은 상이한 시점에 TDM(time division multiplexing) 방식으 로 전송될 수 있으나, 이에 한정되지 않는다. 또 다른 일 예로, 단말은 할당 받은 업링크 자원이 충분하면 복수 개의 AI인코더 모두의 비트 스트링을 AI 인코 더 출력으로 구성하여 함께 전송할 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 또한, 일 예로, 단말 은 단말의 구현 복잡도를 고려하여 AI 인코더 모델 수를 제한할 수 있다. 또는, 기지국은 단말 능력 정보에 기 초하여 단말에게 AI 인코더 모델 수를 설정해 줄 수 있으며, 특정 실시예로 한정되지 않는다. 그러한 복수 개의 AI 인코더 사이의 시퀀스 할당 순서는 사전에 결정된 방법 또는 기지국 설정으로부터 결정할 수 있다. 일 예로 인코더 ID 값 순서, 인코더 우선순위 순서, 인코더 설정 인덱스 순서, 연관된 AI-CSI 콘텐츠 또는 그 AI-CSI 우 선순위 순서 등 중 적어도 하나를 기반으로 그 AI 인코더 사이의 시퀀스 할당 순서를 결정할 수 있다. 또한, 도 18에서 AI 인코더의 양자화 관련 파라미터들(Q, K, S)이 기 설정된 상태인 경우를 기준으로 서술하였 으나, 이에 한정되지 않고 AI 인코더마다 양자화 관련 파라미터(Q, K, S)가 조절되는 것도 가능할 수 있다. 즉, 양자화 절차 내에서 양자화 관련 파라미터들(Q, K, S)을 조절하여 AI CSI 페이로드 크기를 조정하는 도 13 내지 도 17의 방법들은 도 18 및 하기 사항들의 방법들과 조합되어 사용될 수 있다. 일 예로, 하나의 AI 인코딩을 기 준으로 적용되는 방식은 도 18 내의 AI 인코딩 각각에 적용되어 조합하여 활용될 수 있다. 즉, 하기 방법의 각 각의 도면에 기초한 방식들은 조합하여 사용될 수 있으며, 특정 형태로 한정되지 않는다. 도 19는 본 개시에 적용 가능한 하나 이상의 AI 인코더 조합을 통해 AI CSI 페이로드 크기를 조정하는 방법을 나타낸 도면이다. 도 19를 참조하면, AI 인코더는 레이어, 서브-밴드 및 포트 중 적어도 어느 하나를 기준으로 연관되는 AI CSI 콘텐츠를 기준으로 독립적으로 구성될 수 있다. 이를 위해 단말과 기지국은 사전에 AI 인코더 모델 구조와 연관된 설정 정보를 사전에 인지할 필요성이 있으며, 기지국은 단말로 상위 레이어 시그널링을 통 해 지시하거나 사전에 기 설정될 수 있다. 또한, 일 예로, 기지국과 단말은 상위 레이어 시그널링에 기초하여 지시된 정보 내에서 선호 설정 선택이 가능할 수 있으나, 이에 한정되지 않는다. 단말은 AI-CSI 보고와 함께 상술한 설정 정보를 사이드 정보 형태로 기지국에게 전달할 수 있으며, 기지국은 해 당 설정 정보를 이용하여 AI CSI 디코딩을 수행할 수 있다. 일 예로, 업링크 자원이 충분하지 않은 경우, 각각의 독립적인 AI 인코더를 통해 인코딩된 AI CSI 정보들은 가 장 낮은 우선순위를 가지는 AI 인코더의 서브 시퀀스를 기반으로 생략(omission)될 수 있다. 또 다른 일 예로, 업링크 자원이 충분하지 않은 경우, 각각의 독립적인 AI 인코더를 통해 인코딩된 AI CSI 정보들은 가장 낮은 우 선순위를 가지는 AI 인코더로부터 서브 시퀀스를 기반으로 드롭(drop)될 수 있다. 또 다른 일 예로, 업링크 자 원이 충분하지 않은 경우, 각각의 독립적인 AI 인코더를 통해 인코딩된 AI CSI 정보들은 가장 낮은 우선순위를 가지는 AI 인코더로부터 서브 시퀀스를 기반으로 펑처링(puncturing)될 수 있다. 즉, 단말은 할당된 업링크 자 원을 고려하여 우선순위가 높은 AI 인코더의 서브 시퀀스를 우선 할당하여 전송하고, 우선순위가 낮은 AI 인코 더의 서브 시퀀스는 전송하지 않을 수 있다. 도 19를 참조하면, 각각의 AI 인코더(1910, 1920, 1930)는 각각은 각각의 서브시퀀스를 생성할 수 있다. 일 예 로, 각각의 AI 인코더(1910, 1920, 1930)는 레이어, 서브밴드 및 포트 중 적어도 어느 하나에 대응하여 설정될 수 있으며, 이에 따라 상이한 CSI 콘텐츠 정보를 기반으로 각각의 서브 시퀀스를 생성할 수 있다. 도 19에서 AI인코더 #0이 가장 높은 우선순위를 가지는 서브 시퀀스를 생성할 수 있으며, AI 인코더 #N-1은 가 장 낮은 우선순위를 가지는 서브 시퀀스를 생성할 수 있다. 다만, 이는 설명의 편의를 위한 것일 뿐 이에 한정 되지 않는다. 여기서, 가장 낮은 우선순위를 가지는 서브 시퀀스는 단말이 할당받은 업링크 자원에 따라 CSI 페 이로드 크기를 조절하기 위해 생략, 드롭 및 펑처링 중 적어도 어느 하나가 수행될 수 있다. 또 다른 일 예로, 레이어, 서브 밴드 및 포트 중 적어도 어느 하나에 대응하여 연관되는 AI 인코더는 복수 개일 수 있으며, 복수 개의 AI 인코더 각각에 연관된 AI CSI 양자화된 비트 시퀀스들은 동일한 우선순위를 갖을 수 있으나, 특정 형태로 한정되는 것은 아닐 수 있다. 또 다른 일 예로, 도 20은 본 개시에 적용 가능한 하나 이상의 AI 인코더 조합을 통해 AI CSI 페이로드 크기를 조정하는 방법을 나타낸 도면이다. 도 20은 도 19와 상이하게 AI CSI 콘텐츠를 기준으로 각각의 AI 인코더 (2010, 2020, 2030)가 매핑될 수 있다. 도 19에서는 레이어, 서브 밴드 및 포트 중 적어도 어느 하나에 대응되 는 AI 인코더가 AI 인코딩을 수행하였으나 도 20에서는 공통 레이어, 서브 밴드 및 포트 중 적어도 어느 하나에 따라 생성되는 AI CSI 콘텐츠를 기준으로 서로 다른 AI 인코딩을 수행하는 방법일 수 있다. 구체적인 일 예로, ground-truth CSI 정보, channel eigenvector/eigenvalue 및 target CSI 정보는 가장 높은 우선순위를 가지는 AI 콘텐츠일 수 있으며, 이에 대응되는 AI 인코더는 가장 높은 우선순위를 가질 수 있다. 가 장 높은 우선순위를 갖는 AI CSI 콘텐츠에 대응되는 AI 인코더의 서브 시퀀스는 AI 인코더 출력 시퀀스에서 MSB(most significant bit)에 매핑되고, 더 낮은 우선순위를 갖는 AI CSI 콘텐츠들은 LSB(least significant bit) 쪽으로 매핑될 수 있다. 즉, 우선순위가 높은 AI CSI 콘텐츠에 대응되는 서브 시퀀스가 우선하여 매핑될 수 있다. 일 예로, AI CSI 콘텐츠들 상호 간의 우선순위가 결정되고, 결정된 우선순위를 기반하여 상이한 AI 인코딩이 수 행될 수 있다. 여기서, 양자화 방법은 모두 동일하거나 서로 독립적일 수 있으나, 특정 형태로 한정되지 않는다. 동일한 양자화 방법이 적용되는 경우, 단말은 CSI 페이로드 크기 조정을 위해 우선순위가 낮은 서브 시 퀀스(들)을 드롭할 수 있다. 반면, 독립적인 양자화 방법이 각각 적용되는 경우, 단말은 해당 AI CSI 콘텐츠에 따라 제안된 양자화 정도를 조정하여 CSI 페이로드에 포함되도록 제어할 수 있으나, 해당 실시예로 한정되지 않 는다. 도 21은 본 개시에 적용 가능한 적용 가능한 하나 이상의 AI 인코더 조합을 통해 AI CSI 페이로드 크기를 조정 하는 방법을 나타낸 도면이다. AI CSI 콘텐츠는 CSI 파트 1과 CSI 파트 2에 해당하는 콘텐츠를 포함할 수 있다. 여기서, CSI 파트 1과 CSI 파트 2는 설명의 편의를 위한 것일 뿐 해당 명칭으로 한정되는 것은 아닐 수 있다. CSI 파트 1에 해당하는 AI CSI 콘텐츠 정보와 CSI 파트 2에 해당하는 AI CSI 콘텐츠 정보들 각각은 서로 독립적 으로 AI CSI 인코딩을 수행할 수 있다. 일 예로, CSI 파트들은 고정된 크기를 가지는 CSI 파트 1과 가변적 크기 를 갖는 CSI 파트 2로 구분될 수 있다. 여기서, 고정된 크기를 가지는 CSI 파트 1 내의 특정 파트(또는 필드)를 통해 CSI 파트 2의 전체 크기가 지시될 수 있다. 일 예로, 양자화 특성에 따라 CSI 파트 2의 크기를 지시하는 파라미터들은 CSI 파트 1 내에서 제공될 수 있다. 또 다른 일 예로, CSI 파트 2 크기 정보는 단말과 기지국이 페어링된 AI/ML 모델 아이디 정보, 특징 정보 및 그 밖의 정보에 기초하여 결정될 수 있으며, K, Q 및 S가 상술 한 바에 의해 결정될 수 있다. 일 예로, 도 21을 참조하면, CSI 파트 1에 해당하는 AI CSI 콘텐츠에 대응하는 AI 인코더(2111, 2112, 2113)의 서브 시퀀스들은 CSI 파트 2에 해당하는 AI CSI 콘텐츠에 대응하는 AI 인코더 (2121, 2122, 2123)의 서브 시퀀스보다 우선하여 AI 인코더 출력에 할당될 수 있다. 또한, CSI 파트 1 내에서는 AI CSI 콘텐츠에 따라 각각의 AI 인코더가 구성되고, 이에 따라 N개의 서브 시퀀스가 분리될 수 있다. 여기서, N개의 서브 시퀀스는 AI CSI 콘텐츠의 우선순위에 따라 각각의 우선순위가 부여될 수 있다. 또한, CSI 파트 2 내에서는 레어어, 랭크 서브 밴드 및 포트 중 적어도 어느 하나에 따라 각각의 AI 인코더가 구성되고, 이에 따 라 N개의 서브 시퀀스가 분리될 수 있다. 여기서, N개의 서브 시퀀스 각각에 대해서도 우선순위가 부여될 수 있 으며, 이는 상술한 바와 같다. CSI 파트 1에 대한 서브 시퀀스들이 우선순위에 기초하여 AI 인코터 출력에서 우 선하여 할당되고, CSI 파트 2에 대한 서브 시퀀스들이 우선순위에 기초하여 그 이후에 할당될 수 있다. 단말은 할당된 업링크 자원이 충분하지 않은 경우 우선순위가 낮은 서브 시퀀스들 일부를 생략하여 전송하지 않을 수 있다. 도 21에서는 CSI 파트 2 내의 일부 서브 시퀀스에 대한 전송이 단말에 할당된 업링크 자원을 고려하여 생 략될 수 있으나, 이는 하나의 일 예일 뿐 이에 한정되지 않는다.도 22는 본 개시에 적용 가능한 적용 가능한 하나 이상의 AI 인코더 조합을 통해 AI CSI 페이로드 크기를 조정 하는 방법을 나타낸 도면이다. 도 22를 참조하면, CSI 파트 1은 AI CSI 콘텐츠 각각에 대응하는 AI 인코더 (2211, 2212, 2213)에 의해 생성되는 출력을 하나의 서브 시퀀스로 생성할 수 있다. 반면, CSI 파트 2는 AI CSI 콘텐츠 각각에 대응하는 AI 인코더(2221, 2222, 2223)에서 각각의 서브 시퀀스가 생성하고, 각각의 서브 시퀀스 들은 우선순위에 따라 CSI 파트 1 이후에 할당될 수 있다. 단말은 CSI 파트 1 및 CSI 파트 2 모두를 할당하기에 업링크 자원이 충분하지 않으면 우선순위가 낮은 CSI 파트 2의 일부 서브 시퀀스에 대한 전송을 생략할 수 있다. 또한, AI/ML 모델 생성 파트로 단말 내의 AI 인코더 출력은 서브 시퀀스(또는 서브 시퀀스 그룹)를 기준으로 CSI 생략, 드롭 및 펑처링 중 적어도 어느 하나를 수행할 수 있으며, 이에 기초하여 부분적으로 디코딩이 가능 할 수 있다. 일 예로, AI 인코더 출력에 해당하는 비트 스트링은 N개의 서브 시퀀스(N개 그룹)로 나눠질 수 있 다. 서브 시퀀스는 첫 번째(RI/2) 레이어들에 해당하는 정보만을 포함할 수 있다. 또 다른 일 예로, 첫 번째 서 브 시퀀스는 스칼라 양자화 기반 양자화된 출력 시퀀스의 MSB만을 포함하고 두 번째 서브 시퀀스는 나머지 LSB 들을 포함할 수 있으며, CSI 필드들의 할당 순서는 하기 표 23과 같을 수 있다. [표 23]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 31, "content": "표 23에서 가장 높은 우선순위를 가지는 서브 시퀀스를 첫 번째 그룹으로 결정하며 이후 표 23과 같은 순서로 낮은 우선순위를 가지는 N 번째 서브 시퀀스 그룹을 구성할 수 있다. 단말은 파트 2 내의 서브 시퀀스를 기준으 로 할당된 스케줄링 자원이 충분하지 않은 경우, 낮은 우선순위를 갖는 서브 시퀀스를 전송하지 않을 수 있다. 즉, 단말은 낮은 우선순위를 갖는 서브 시퀀스에 대해서 CSI 생략, 드롭 및 펑처링 중 적어도 어느 하나를 수행 할 수 있다. 여기서, 우선순위는 각각의 레이어 값에 대응되도록 구성될 수 있다. 또한, 인터-레이어 CSI 보고 우선화 (Inter-layer CSI report prioritization) 방식으로써 전체 AI-CSI 비트 스트링(또는 비트 시퀀스)는 각 레이 어에 대응하는 서브 시퀀스들을 기준으로 구성될 수 있고, 가장 낮은 인덱스를 갖는 레이어부터 높은 인덱스를 갖는 레이어들 순서로 우선순위가 결정될 수 있다. 또는 반대로 매핑되는 것도 가능할 수 있으며, 특정 형태로 한정되지 않는다. 여기서, 상술한 우선순위를 기준으로 CSI 파트 2 내의 일부 시퀀스에 대한 전송이 생략(또는 드롭, 펑처링)될 수 있다. CSI 파트 1과 CSI 파트 2는 상술한 도 21 및 도 22처럼 각각 독립적으로 AI 인코딩이 수행될 수 있다. 여기서, CSI 파트 1(또는 파트 1)은 표 23 및 하기 표 24와 같이 레이어 공통 정보와 CSI 파트 2를 위한 크기 정보(사이드정보)를 제공할 수 있다. 일 예로, CSI 파트 1 내의 CSI 정보들은 CSI 파트 2 내의 CSI 정보들보다 우선순위가 높은 AI CSI 정보일 수 있다. 이에 따라서, CSI 파트 1 내의 AI CSI 정보는 생략(또는 드롭, 펑처링)이 수행되지 않는 서브 시퀀스들일 수 있으나, 이에 한정되는 것은 아닐 수 있다. 반면, CSI 파트 2에해당하는 정보들은 상술한 방법들과 유사하게 낮은 우선순위에 해당하는 서브 시퀀스들이 전송되지 않을 수 있 다. AI CSI 보고를 위해 단말에 할당된 업링크 자원이 충분하지 않은 경우, 단말은 CSI 파트 2에 해당하는 CSI 정보들과 연관된 서브 시퀀스들 중 우선순위가 낮은 서브 시퀀스 일부를 드롭하여 전송하지 않을 수 있다. 즉, CSI 파트 1과 CSI 파트 2를 위한 AI 인코딩은 독립적으로 수행될 수 있으며, 각 파트 내에서도 각각의 AI 인코 딩이 수행될 수 있다. 일 예로, 각 파트 내에서 공통적인 AI 인코딩이 적용되는 것도 가능할 수 있으며, 특정 형태로 한정되지 않는다. [표 24]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 32, "content": "또 다른 일 예로, 상술한 표 24를 참조하면, 서브 시퀀스들 간의 우선순위를 결정은 CSI 인코더 출력의 노드당 양자화 비트 수(Q)를 기준으로 Q, K 또는 S 값이 가장 큰 비트 스트링에 대응하는 서브 시퀀스를 가장 높은 우 선순위를 갖는 서브 시퀀스로 그룹화(e.g. Group 1)할 수 있다. 동일한 형태로 Q, K 또는 S 값을 기준으로 서브 시퀀스에 대한 그룹화가 수행될 수 있으며, 표 24와 같을 수 있다. 상술한 바와 같이 CSI를 포함하는 UCI의 페이로드 구조는 레이어 별로 적용되거나 모든 레이어에 대해 공통으로 적용되는 구조일 수 있다. 단말에 UCI를 전송하기 위해 할당된 업링크 자원(PUSCH)이 충분하지 않은 경우, 단말 은 일부 CSI 또는 서브 시퀀스(또는 서브 시퀀스 그룹)에 대한 전송을 생략(또는 드롭, 펑처링, 레이트매칭 (rate matching))할 수 있다. 일 예로, 일부 CSI 또는 서브 시퀀스(또는 서브 시퀀스 그룹)에 대한 전송을 생략 하는 우선순위는 하기 표 25의 정보들을 고려하여 결정될 수 있으나, 이에 한정되는 것은 아닐 수 있다. [표 25]"}
{"patent_id": "10-2024-0129855", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 33, "content": "도 23은 본 개시에 적용 가능한 단말 동작을 나타낸 순서도이다. 도 23을 참조하면, 단말은 기지국으로부터 AI CSI 보고를 위한 업링크 자원(UL grant)을 할당 받을 수 있다. 단말은 업링크 자원의 양(또는 크기)와 AI CSI 콘텐츠의 AI 페이로드 사이즈를 비교할 수 있다.(S2310) 일 예로, AI CSI 콘텐츠는 AI와 관련된 CSI 콘텐츠 및 기존 CSI 콘텐츠를 더 포함할 수 있으나, 해당 실시예로 한정되는 것은 아닐 수 있다. 도 23를 참조하면, 단말은 AI CSI 보고를 위한 충분한 업링크 자원이 할당되었는지 여부를 확인할 수 있 다.(S2320) 즉, 단말은 업링크 자원의 양과 AI CSI 페이로드 크기를 비교할 수 있다. 여기서, 단말이 충분한 업링크 자원을 할당 받은 경우, 단말은 AI 인코더 출력에 대한 비트 스트링을 AI CSI 페이로드에 포함하여 AI CSI 보고를 수행할 수 있다.(S2330) 반면, 단말이 충분한 업링크 자원을 할당 받지 못한 경우, 단말은 AI CSI 페이로드 크기 및 AI 인코더 출력 크 기를 조정할 수 있다.(S2340) 여기서, AI 인코더 출력 크기는 AI CSI 모델 성능, 신뢰도, 채널 환경, 유스 케이 스 및 시나리오에 기초하여 적용되는 양자화 방법을 통해 조정될 수 있으며, 상술한 바와 같을 수 있다. 일 예 로, 단말은 AI 인코더와 관련하여 양자화 관련 방법 및 파라미터들을 활용할 수 있는지를 적응적으로 결정할 수 있다. 만약 그렇지 않은 경우, 단말은 AI 인코더 내의 양자화 방법 및 관련 파라미터들을 제안된 방법으로 조정 하여 AI 인코더 크기를 조절할 수 있다. 여기서, 상술한 AI 인코더 크기가 조정되는 경우라도 단말과 기지국 사 이 구현의 복잡도와 효율적인 양자화 정렬 절차를 위해서 제한된 범위 내에서 AI 인코더 크기가 다시 조정될 수 있다. 즉, 단말은 조정된 AI 인코더 출력 전송을 위해 충분한 업링크 자원(또는 임계 값)이 할당되었는지를 판 단하고(S2350), 충분한 업링크 자원이 존재하면 AI 인코더 출력을 포함하는 AI CSI 보고를 수행할 수 있 다.(S2360) 반면, 충분한 업링크 자원이 존재하지 않는 경우, 단말은 AI 인코더 출력에 대한 일부 서브 시퀀스 를 생략(또는 드롭, 펑처링)할 수 있다.(S2370) 또 다른 일 예로, 단말은 AI/ML 기반 CSI 콘텐츠(AI CSI 콘텐츠)뿐만 아니라 기존 CSI 콘텐츠를 동시에 기지국 으로 전송할 수 있다. 즉, 단말은 UCI 전송을 위해 할당받은 업링크 자원 내에서 AI CSI 콘텐츠와 기존 CSI 콘 텐츠를 모두 전송할 수 있다. 여기서, 하나의 CSI 보고는 기존 CSI 보고 또는 AI CSI 보고일 수 있다. 일 예로, 기존 CSI 콘텐츠는 AI CSI 성능 모니터링을 목적으로 송수신될 수 있다. 즉, 얼마나 AI-CSI 보고가 신뢰도 있게 보고되어 사용되고 있는지에 대한 비교 지표일 수 있다. 상술한 경우에는 AI CSI 콘텐츠와 기존 CSI 콘텐츠는 특정 시간에서 하나의 CSI 보고 또는 복수의 CSI 보고를 기반으로 단말에서 기지국으로 보고될 수 있다. 일 예 로, AI CSI 콘텐츠와 기존 CSI 콘텐츠는 하나의 CSI 보고 내에서 멀티플렉싱될 수 있다. 여기서, 상술한 CSI 페 이로드 조정 방법과 관련하여 기존 CSI 콘텐츠들을 어떻게 처리할지 여부에 대한결정이 필요할 수 있다. 일 예로, 도 24는 본 개시에 적용 가능한 AI CSI 콘텐츠와 기존 CSI 콘텐츠를 멀티플렉싱하여 전송하는 방법을 나타낸 도면이다. 도 24(a)를 참조하면, 기존 CSI 콘텐츠들은 항상 AI CSI 콘텐츠들보다 우선할 수 있다. 즉, 단말은 할당된 업링 크 자원 상에서 MSB에 기존 CSI 콘텐츠들을 우선 할당하고, 남은 업링크 자원에 AI CSI를 할당할 수 있다. 여기 서, 업링크 자원 양(또는 크기)에 따라 AI CSI 콘텐츠 일부가 생략될 수 있다. 또 다른 일 예로, 도 24(b)를 참조하면, 단말은 할당된 업링크 자원 상에서 MSB에 CSI 파트 1를 우선 할당하고, 남은 업링크 자원에 CSI 파트 2를 할당할 수 있다. 여기서, CSI 파트 1 및 CSI 파트 2 각각에서 기존 CSI 콘텐 츠가 AI CSI 콘텐츠보다 우선하여 할당될 수 있다. 일 예로, 업링크 자원 양(또는 크기)에 따라 LSB 쪽에 할당 된 CSI 콘텐츠 일부가 생략될 수 있다. 또 다른 일 예로, 도 24(c)를 참조하면, 단말은 할당된 업링크 자원 상에서 MSB에 CSI 파트 1를 우선 할당하고, 남은 업링크 자원에 CSI 파트 2를 할당할 수 있다. 여기서, CSI 파트 1 내에서는 기존 CSI 콘텐츠가 먼저 할당되고, AI CSI 콘텐츠가 나중에 할당될 수 있다. 반면, CSI 파트 2 내에서는 기존 CSI 콘텐츠와 AI CSI 콘텐츠가 교차로 할당될 수 있다. 일 예로, 업링크 자원 양(또는 크기)에 따라 LSB 쪽에 할당된 CSI 콘텐츠 일 부가 생략될 수 있다. 또 다른 일 예로, 도 24(d)를 참조하면, 단말은 할당된 업링크 자원 상에서 MSB에 CSI 파트 1를 우선 할당하고, 남은 업링크 자원에 CSI 파트 2를 할당할 수 있다. 여기서, CSI 파트 1 및 CSI 파트 2 내에서는 기존 CSI 콘텐 츠와 AI CSI 콘텐츠가 교차로 할당될 수 있다. 일 예로, 업링크 자원 양(또는 크기)에 따라 LSB 쪽에 할당된 CSI 콘텐츠 일부가 생략될 수 있다. 도 25는 본 개시에 적용 가능한 AI CSI 보고를 수행하는 방법을 나타낸 도면이다. 도 25를 참조하면, 단말은 AI CSI 보고를 위한 업링크 자원을 할당 받을 수 있다.(S2510) 즉, 단말은 UCI 전송을 위해 기지국으로부터 업링크 그랜트를 획득하고, 획득한 업링크 자원을 통해 AI CSI 보고를 수행할 수 있다. 여기서, 단말은 업링크 자원에 기초하여 AI CSI 페이로드 크기 조정 여부를 결정할 수 있다.(S2520) 일 예로, AI CSI 보고를 위한 업링크 자원 이 충분한 경우, 단말은 업링크 자원을 통해 AI CSI 보고를 수행할 수 있다. 반면, AI CSI 보고를 위한 업링크 자원이 충분하지 않은 경우, 단말은 AI CSI 페이로드 크기를 조정할 수 있다. 즉, 업링크 자원 양이 AI CSI 페 이로드 양보다 작으면 단말은 AI CSI 페이로드 크기를 조정할 수 있다. 단말이 AI CSI 페이로드 크기를 조정한경우, 단말은 조정된 AI CSI 페이로드 크기에 기초하여 업링크 자원을 통해 AI CSI 보고를 수행할 수 있 다.(S2530) 여기서, AI CSI 페이로드 크기는 AI CSI 모델 성능, 신뢰도 및 채널 환경 중 적어도 어느 하나에 기 초하여 결정된 양자화 방법에서 AI 인코더 출력 크기를 조정하여 수행될 수 있다. 일 예로, AI 인코더는 AI CSI 입력들에 기초하여 결정된 양자화 방법을 통해 AI 인코딩 및 양자화 절차를 수행하여 AI 인코더 출력을 생성할 수 있다. AI 인코더 출력은 AI 인코더 출력 크기와 출력 노드 당 양자화 비트 수를 통해 도출되는 비트 스트링 이고, AI 인코더 출력 크기, 출력 노드 당 양자화 비트 수 및 비트 스트링 중 적어도 어느 하나를 조정하여 AI CSI 페이로드 크기를 조정할 수 있으며, 상술한 도 13 내지 도 17과 같을 수 있다. 또한, 일 예로, 상술한 AI 인코더 출력은 양자화 스텝(quantization step)과 범위(range)를 기반으로 가장 높거 나 신뢰성 있는 출력 값을 기준으로 상이한 보고(differential reporting) 동작을 통해 추가적인 출력 값들을 함께 보고할 수 있다. 또한, 조정된 AI CSI 페이로드 크기에 기초하여 업링크 자원이 AI CSI 보고를 수행하기에 충분한 경우, 단말은 업링크 자원을 통해 AI CSI 보고를 수행할 수 있다. 반면, 조정된 AI CSI 페이로드 크기에 기초하여 업링크 자 원이 AI CSI 보고를 수행하기에 충분하지 않은 경우, 단말은 AI 인코더 출력의 적어도 하나의 서브 시퀀스 중 일부 서브 시퀀스에 대한 전송을 생략(또는 드롭, 펑처링)할 수 있다. 여기서, AI 인코더 출력은 적어도 하나의 AI 인코더 각각에 대응되는 서브 시퀀스에 기초하여 적어도 하나의 서브 시퀀스를 포함할 수 있다. 적어도 하나 의 AI 인코더 각각에 대응되는 서브 시퀀스는 AI 인코더 우선순위에 기초하여 높은 우선순위를 갖는 서브 시퀀 스 순서로 AI CSI 페이로드에 할당될 수 있다. 일 예로, AI 인코더 각각은 레이어, 랭크, 서브 밴드 및 포트 중 적어도 어느 하나에 대응되고, AI 인코더 우선순위는 AI 인코더 각각에 대응되는 레이어, 랭크, 서브 밴드 및 포트 중 적어도 어느 하나에 기초하여 결정될 수 있다. 또 다른 일 예로, AI 인코더 각각은 AI CSI 콘텐츠에 대 응되고, AI 인코더 우선순위는 AI 인코더 각각에 대응되는 AI CSI 콘텐츠에 기초하여 결정될 수 있으며, 이는 도 18 내지 도 22와 같을 수 있다. 도 26은 본 개시가 적용될 수 있는 기지국 장치 및 단말 장치를 나타낸 도면이다. 기지국 장치는 프로세서, 안테나부, 트랜시버, 메모리를 포함할 수 있다. 프로세서는 베이스밴드 관련 신호 처리를 수행하며, 상위계층 처리부 및 물리계층 처리부를 포함할 수 있다. 상위계층 처리부는 MAC(Medium Access Control) 계층, RRC(Radio Resource Control) 계 층, 또는 그 이상의 상위계층의 동작을 처리할 수 있다. 물리계층 처리부는 물리(physical, PHY) 계층의 동작(예를 들어, 업링크 수신 신호 처리, 하향링크 송신 신호 처리)을 처리할 수 있다. 프로세서는 베이 스밴드 관련 신호 처리를 수행하는 것 외에도, 기지국 장치 전반의 동작을 제어할 수도 있다. 안테나부는 하나 이상의 물리적 안테나를 포함할 수 있고, 복수개의 안테나를 포함하는 경우 MIMO(Multiple Input Multiple Output) 송수신을 지원할 수 있다. 또한, 빔포밍(Beamforming)을 지원할 수 있 다. 메모리는 프로세서의 연산 처리된 정보, 기지국 장치의 동작에 관련된 소프트웨어, 운영체제, 애플리케이션 등을 저장할 수 있으며, 버퍼 등의 구성요소를 포함할 수도 있다. 기지국의 프로세서는 본 발명에서 설명하는 실시예들에서의 기지국의 동작을 구현하도록 설정될 수 있다. 단말 장치는 프로세서, 안테나부, 트랜시버, 메모리를 포함할 수 있다. 일 예로, 본 발명에서 단말 장치는 기지국 장치와 통신을 수행할 수 있다. 또 다른 일 예로, 본 발명 에서 단말 장치는 다른 단말 장치와 사이드링크 통신을 수행할 수 있다. 즉, 본 발명의 단말 장치 는 기지국 장치 및 다른 단말 장치 중 적어도 어느 하나의 장치와 통신할 수 있는 장치를 지칭하는 것으 로 특정 장치와의 통신으로 한정되는 것은 아니다. 프로세서는 베이스밴드 관련 신호 처리를 수행하며, 상위계층 처리부 및 물리계층 처리부를 포함할 수 있다. 상위계층 처리부는 MAC 계층, RRC 계층, 또는 그 이상의 상위계층의 동작을 처리할 수 있다. 물리계층 처리부는 PHY 계층의 동작(예를 들어, 하향링크 수신 신호 처리, 업링크 송신 신호 처 리)을 처리할 수 있다. 프로세서는 베이스밴드 관련 신호 처리를 수행하는 것 외에도, 단말 장치 전반의 동작을 제어할 수도 있다.안테나부는 하나 이상의 물리적 안테나를 포함할 수 있고, 복수개의 안테나를 포함하는 경우 MIMO 송수신 을 지원할 수 있다. 또한, 빔포밍(Beamforming)을 지원할 수 있다. 메모리는 프로세서의 연산 처리된 정보, 단말 장치의 동작에 관련된 소프트웨어, 운영체제, 애플리케이션 등을 저장할 수 있으며, 버퍼 등의 구성요소를 포함할 수도 있다. 본 발명의 일 예에 따른 단말 장치는 차량과 연관될 수 있다. 일 예로, 단말 장치는 차량에 통합되 거나, 차량에 위치되거나 또는 차량상에 위치될 수 있다. 또한, 본 발명에 따른 단말 장치는 차량 자체일 수도 있다. 또한, 본 발명에 따른 단말 장치는 웨어러블 단말과 AV/VR, IoT 단말, 로봇 단말, 공공안전 (Public safety) 단말 중 적어도 하나일 수 있다. 이러한 본 발명이 적용 가능한 단말 장치는, 인터넷 접 속, 서비스 수행, 네비게이션, 실시간 정보, 자율 주행, 안전 및 위험 진단과 같은 서비스를 위해 사이드링크를 활용한 인터렉티브 서비스가 지원되는 다양한 형태의 어떠한 통신 기기도 포함할 수 있다. 또한, 사이드링크 동 작이 가능한 AR/VR 기기 혹은 센서가 되어 릴레이 동작을 수행하는 어떠한 형태의 통신 기기도 포함될 수 있다. 여기서, 본 발명이 적용되는 차량은 자율 주행차, 반-자율 주행차, 비-자율 주행차 등을 포함할 수 있다. 한편, 본 발명의 일 예에 따른 단말 장치는 차량과 연관되는 것으로 설명하나, 상기 UE들 중 하나 이상은 차량 과 연관되지 않을 수 있다. 이는 일 예로, 설명된 일 예에 따라 본 발명의 적용이 한정되도록 해석되지 않아야 한다. 또한, 본 발명의 일 예에 따른 단말 장치는 기지국 장치로부터 AI CSI 보고를 위한 업링크 자원을 할당 받을 수 있다. 즉, 단말 장치는 UCI 전송을 위해 기지국 장치로부터 업링크 그랜트를 획득하 고, 획득한 업링크 자원을 통해 AI CSI 보고를 수행할 수 있다. 여기서, 단말 장치는 업링크 자원에 기초 하여 AI CSI 페이로드 크기 조정 여부를 결정할 수 있다. 일 예로, AI CSI 보고를 위한 업링크 자원이 충분한 경우, 단말 장치는 업링크 자원을 통해 AI CSI 보고를 수행할 수 있다. 반면, AI CSI 보고를 위한 업링크 자원이 충분하지 않은 경우, 단말 장치는 AI CSI 페이로드 크기를 조정할 수 있다. 즉, 업링크 자원 양이 AI CSI 페이로드 양보다 작으면 단말 장치는 AI CSI 페이로드 크기를 조정할 수 있다. 단말 장치가 AI CSI 페이로드 크기를 조정한 경우, 단말 장치는 조정된 AI CSI 페이로드 크기에 기초하여 업링크 자원 을 통해 AI CSI 보고를 수행할 수 있다. 여기서, AI CSI 페이로드 크기는 AI CSI 모델 성능, 신뢰도 및 채널 환 경 중 적어도 어느 하나에 기초하여 결정된 양자화 방법에서 AI 인코더 출력 크기를 조정하여 수행될 수 있다. 일 예로, AI 인코더는 AI CSI 입력들에 기초하여 결정된 양자화 방법을 통해 AI 인코딩 및 양자화 절차를 수행 하여 AI 인코더 출력을 생성할 수 있다. AI 인코더 출력은 AI 인코더 출력 크기와 출력 노드 당 양자화 비트 수 를 통해 도출되는 비트 스트링이고, AI 인코더 출력 크기, 출력 노드 당 양자화 비트 수 및 비트 스트링 중 적 어도 어느 하나를 조정하여 AI CSI 페이로드 크기를 조정할 수 있으며, 상술한 도 13 내지 도 17과 같을 수 있 다. 또한, 일 예로, 상술한 AI 인코더 출력은 양자화 스텝(quantization step)과 범위(range)를 기반으로 가장 높거 나 신뢰성 있는 출력 값을 기준으로 상이한 보고(differential reporting) 동작을 통해 추가적인 출력 값들을 함께 보고할 수 있다. 또한, 조정된 AI CSI 페이로드 크기에 기초하여 업링크 자원이 AI CSI 보고를 수행하기에 충분한 경우, 단말 장 치는 업링크 자원을 통해 AI CSI 보고를 수행할 수 있다. 반면, 조정된 AI CSI 페이로드 크기에 기초하여 업링크 자원이 AI CSI 보고를 수행하기에 충분하지 않은 경우, 단말 장치는 AI 인코더 출력의 적어도 하 나의 서브 시퀀스 중 일부 서브 시퀀스에 대한 전송을 생략(또는 드롭, 펑처링)할 수 있다. 여기서, AI 인코더 출력은 적어도 하나의 AI 인코더 각각에 대응되는 서브 시퀀스에 기초하여 적어도 하나의 서브 시퀀스를 포함할 수 있다. 적어도 하나의 AI 인코더 각각에 대응되는 서브 시퀀스는 AI 인코더 우선순위에 기초하여 높은 우선순 위를 갖는 서브 시퀀스 순서로 AI CSI 페이로드에 할당될 수 있다. 일 예로, AI 인코더 각각은 레이어, 랭크, 서브 밴드 및 포트 중 적어도 어느 하나에 대응되고, AI 인코더 우선순위는 AI 인코더 각각에 대응되는 레이어, 랭크, 서브 밴드 및 포트 중 적어도 어느 하나에 기초하여 결정될 수 있다. 또 다른 일 예로, AI 인코더 각각은 AI CSI 콘텐츠에 대응되고, AI 인코더 우선순위는 AI 인코더 각각에 대응되는 AI CSI 콘텐츠에 기초하여 결정될 수 있으며, 이는 도 18 내지 도 22와 같을 수 있다. 또한, 본 개시의 다양한 실시예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(generalprocessor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 본 개시의 범위는 다양한 실시예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다. 본 개시의 다양한 실시예는 모든 가능한 조합을 나열한 것이 아니고 본 개시의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있 다."}
{"patent_id": "10-2024-0129855", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시가 적용될 수 있는 무선 통신 시스템의 프레임 구조를 설명하기 위한 도면이다. 도 2는 본 개시가 적용될 수 있는 무선 통신 시스템의 자원 구조를 나타내는 도면이다. 도 3은 본 개시가 적용될 수 있는 CSI-RS 자원을 나타낸 도면이다. 도 4는 본 개시에 적용될 수 있는 타입 1 CSI를 나타낸 도면이다.도 5는 본 개시에 본 개시에 적용될 수 있는 복수 개의 SRS를 사용하는 방법을 나타낸 도면이다. 도 6은 본 개시에 적용될 수 있는 논-코드북 기반 프리코딩을 수행하는 방법을 나타낸 도면이다. 도 7은 본 개시에 적용될 수 있는 CSI 생략을 나타낸 도면이다. 도 8은 본 개시에 적용될 수 있는 AI/ML 모델 라이프 사이클 관리를 나타낸 도면이다. 도 9는 본 개시에 적용될 수 있는 타입 1에 기초하여 AI/ML 모델 트레이닝이 수행되는 방법을 나타낸 도면이다. 도 10은 본 개시에 적용될 수 있는 타입 2에 기초하여 AI/ML 모델 트레이닝이 수행되는 방법을 나타낸 도면이다. 도 11은 본 개시에 적용될 수 있는 타입 3에 기초하여 AI/ML 모델 트레이닝이 수행되는 방법을 나타낸 도면이다. 도 12는 본 개시에 적용 가능한 AI 인코더 구조 및 이에 기초하여 입력으로부터 출력을 도출하는 방법을 나타낸 도면이다. 도 13은 본 개시에 적용 가능한 AI 인코더에서 스칼라 양자화가 수행되는 방법을 나타낸 도면이다. 도 14는 본 개시에 적용 가능한 AI 인코더 내의 적응적 양자화 방법에 따라 AI CSI 페이로드 사이즈를 조절하는 방법을 나타낸 도면이다. 도 15는 본 개시에 적용 가능한 AI 인코더 내의 적응적 양자화 방법에 따라 AI CSI 페이로드 사이즈를 조절하는 방법을 나타낸 도면이다. 도 16은 본 개시에 적용 가능한 AI 인코더 내의 적응적 양자화 방법에 따라 AI CSI 페이로드 사이즈를 조절하는 방법을 나타낸 도면이다. 도 17은 본 개시에 적용 가능한 본 개시에 적용 가능한 AI 인코더 내의 적응적 양자화 방법에 따라 AI CSI 페이 로드 사이즈를 조절하는 방법을 나타낸 도면이다. 도 18은 본 개시에 적용 가능한 AI 인코더 스위칭에 기초하여 AI CSI 페이로드 크기를 조정하는 방법을 나타낸 도면이다. 도 19는 본 개시에 적용 가능한 하나 이상의 AI 인코더 조합을 통해 AI CSI 페이로드 크기를 조정하는 방법을 나타낸 도면이다. 도 20은 본 개시에 적용 가능한 하나 이상의 AI 인코더 조합을 통해 AI CSI 페이로드 크기를 조정하는 방법을 나타낸 도면이다. 도 21은 본 개시에 적용 가능한 적용 가능한 하나 이상의 AI 인코더 조합을 통해 AI CSI 페이로드 크기를 조정 하는 방법을 나타낸 도면이다. 도 22는 본 개시에 적용 가능한 적용 가능한 하나 이상의 AI 인코더 조합을 통해 AI CSI 페이로드 크기를 조정 하는 방법을 나타낸 도면이다. 도 23은 본 개시에 적용 가능한 단말 동작을 나타낸 순서도이다. 도 24는 본 개시에 적용 가능한 AI CSI 콘텐츠와 기존 CSI 콘텐츠를 멀티플렉싱하여 전송하는 방법을 나타낸 도 면이다. 도 25는 본 개시에 적용 가능한 AI CSI 보고를 수행하는 방법을 나타낸 도면이다. 도 26은 본 개시가 적용될 수 있는 기지국 장치 및 단말 장치를 나타낸 도면이다."}
