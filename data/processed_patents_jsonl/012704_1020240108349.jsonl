{"patent_id": "10-2024-0108349", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0131289", "출원번호": "10-2024-0108349", "발명의 명칭": "모델 생성 결과 처리 방법, 장치, 전자 기기 및 저장 매체", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "티안, 멍"}}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "텍스트 처리 분야에 적용되는 모델 생성 결과 처리 방법에 있어서,생성식 대규모 모델(generative large model)의 텍스트 생성 결과를 분해하여(disassembled), 복수의 결과 논리 유닛을 획득하는 단계 - 각 상기 결과 논리 유닛은 상기 텍스트 생성 결과 중의 프래그먼트(fragment)를 포함하고, 각 상기 프래그먼트는 상기 텍스트 생성 결과의 논리 추리 관계 중의 하나의 전제(premise) 또는 결론을 독립적으로 표기(marking)할 수 있고, 상기 텍스트 생성 결과는 상기 생성식 대규모 모델이 텍스트 입력 정보에 기반하여 생성한 응답 결과임 -;상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는논리 추리도(logical reasoning graph)를 생성하는 단계; 및상기 논리 추리도에 기반하여, 상기 생성식 대규모 모델이 상기 텍스트 생성 결과를 생성하기 위해 사용하는 논리 추리가 정확한지 여부를 결정하는 단계;를 포함하는,모델 생성 결과 처리 방법."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의 결과 논리 유닛을 획득하는 단계는,사전 트레이닝된 논리 분해 모델을 사용하여, 상기 생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의결과 논리 유닛을 획득하는 단계를 포함하는,모델 생성 결과 처리 방법."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는논리 추리도를 생성하는 단계는,상기 복수의 결과 논리 유닛에 기반하여, 사전 트레이닝된 논리 추리도 생성 모델(logic reasoning graphgeneration model)을 사용하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하는 단계를 포함하는,모델 생성 결과 처리 방법."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는논리 추리도를 생성하는 단계의 전에, 상기 방법은,생성식 대규모 모델의 텍스트 입력 정보를 분해하여, 복수의 입력 논리 유닛을 획득하는 단계를 더 포함하고,각 상기 입력 논리 유닛은 상기 텍스트 입력 정보 중의 프래그먼트를 포함하고, 각 상기 프래그먼트는 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있는,모델 생성 결과 처리 방법. 공개특허 10-2024-0131289-3-청구항 5 제4항에 있어서,상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는논리 추리도를 생성하는 단계는,상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 입력 논리 유닛을 참조하여, 상기 복수의 결과 논리 유닛사이의 논리 추리 관계를 표시할 수 있는 상기 논리 추리도를 생성하는 단계를 포함하는,모델 생성 결과 처리 방법."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 입력 논리 유닛을 참조하여, 상기 복수의 결과 논리 유닛사이의 논리 추리 관계를 표시할 수 있는 상기 논리 추리도를 생성하는 단계는,상기 복수의 입력 논리 유닛과 상기 복수의 결과 논리 유닛에 기반하여, 미리 설정된 샘플 데이터베이스에서,관련성이 가장 높은 샘플을 검색하는 단계 - 상기 샘플 데이터베이스는 복수 그룹의 샘플을 포함하고, 각 상기샘플은 입력 샘플 정보에 대응하는 복수의 입력 샘플 논리 유닛, 결과 샘플 정보에 대응하는 복수의 결과 샘플논리 유닛 및 복수의 결과 샘플 논리 유닛에 대응하는 샘플 논리 추리도를 포함함 -; 및상기 복수의 입력 논리 유닛, 상기 복수의 결과 논리 유닛, 상기 복수의 입력 샘플 논리 유닛, 상기 복수의 결과 샘플 논리 유닛 및 대응하는 상기 샘플 논리 추리도에 기반하여, 사전 트레이닝된 다른 생성식 대규모 모델을 사용하여, 상기 복수의 결과 논리 유닛에 대응하는 상기 논리 추리도를 생성하는 단계;를 포함하는,모델 생성 결과 처리 방법."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 논리 추리도에 기반하여, 상기 생성식 대규모 모델이 상기 텍스트 생성 결과를 생성하는 논리 추리가 정확한지 여부를 결정하는 단계는,상기 논리 추리도를 복수의 2층 서브도(two-layer subgraph)로 분해하는 단계 - 각 상기 2층 서브도는 하나의논리 추리 단계를 표기함 -;각 상기 2층 서브도의 논리 추리가 정확한지 여부를 판정하는 단계; 및상기 복수의 2층 서브도의 논리 추리가 모두 정확한 것에 응답하여, 상기 생성식 대규모 모델이 상기 텍스트 생성 결과를 생성하는 논리 추리가 정확하다고 결정하는 단계;를 포함하는,모델 생성 결과 처리 방법."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "텍스트 처리 분야에 적용되는 모델 생성 결과 처리 장치에 있어서,생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의 결과 논리 유닛을 획득하기 위한 분해 모듈(disassembly module) - 각 상기 결과 논리 유닛은 상기 텍스트 생성 결과 중의 프래그먼트를 포함하고, 각 상기 프래그먼트는 상기 텍스트 생성 결과의 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수있고, 상기 텍스트 생성 결과는 상기 생성식 대규모 모델이 텍스트 입력 정보에 기반하여 생성한 응답 결과임-;상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는논리 추리도를 생성하기 위한 생성 모듈(generating module); 및공개특허 10-2024-0131289-4-상기 논리 추리도에 기반하여, 상기 생성식 대규모 모델이 생성한 상기 텍스트 생성 결과의 논리 추리가 정확한지 여부를 결정하기 위한 평가 모듈(evaluation module);을 포함하는,모델 생성 결과 처리 장치."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 분해 모듈은,사전 트레이닝된 논리 분해 모델을 사용하여, 상기 생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의결과 논리 유닛을 획득하는데 사용되는,모델 생성 결과 처리 장치."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 생성 모듈은,상기 복수의 결과 논리 유닛에 기반하여, 사전 트레이닝된 논리 추리도 생성 모델을 사용하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하는데 사용되는,모델 생성 결과 처리 장치."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 분해 모듈은 또한,생성식 대규모 모델의 텍스트 입력 정보를 분해하여, 복수의 입력 논리 유닛을 획득하는데 사용되고, 각 상기입력 논리 유닛은 상기 텍스트 입력 정보 중의 프래그먼트를 포함하고, 각 상기 프래그먼트는 논리 추리 관계중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있는,모델 생성 결과 처리 장치."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 생성 모듈은,상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 입력 논리 유닛을 참조하여, 상기 복수의 결과 논리 유닛사이의 논리 추리 관계를 표시할 수 있는 상기 논리 추리도를 생성하는데 사용되는,모델 생성 결과 처리 장치."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 생성 모듈은,상기 복수의 입력 논리 유닛과 상기 복수의 결과 논리 유닛에 기반하여, 미리 설정된 샘플 데이터베이스에서,관련성이 가장 높은 샘플을 검색하고, 상기 샘플 데이터베이스는 복수 그룹의 샘플을 포함하고, 각 상기 샘플은입력 샘플 정보에 대응하는 복수의 입력 샘플 논리 유닛, 결과 샘플 정보에 대응하는 복수의 결과 샘플 논리 유닛 및 복수의 결과 샘플 논리 유닛에 대응하는 샘플 논리 추리도를 포함하고,상기 복수의 입력 논리 유닛, 상기 복수의 결과 논리 유닛, 상기 복수의 입력 샘플 논리 유닛, 상기 복수의 결과 샘플 논리 유닛 및 대응하는 상기 샘플 논리 추리도에 기반하여, 사전 트레이닝된 기타 생성식 대규모 모델공개특허 10-2024-0131289-5-을 사용하여, 상기 복수의 결과 논리 유닛에 대응하는 상기 논리 추리도를 생성하는데 사용되는,모델 생성 결과 처리 장치."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항 내지 제13항 중 어느 한 항에 있어서,상기 평가 모듈은,상기 논리 추리도를 복수의 2층 서브도로 분해하기 위한 분해 유닛 - 각 상기 2층 서브도는 하나의 논리 추리단계를 표기함 -;각 상기 2층 서브도의 논리 추리가 정확한지 여부를 판정하기 위한 판정 유닛; 및상기 복수의 2층 서브도의 논리 추리가 모두 정확한 것에 응답하여, 상기 생성식 대규모 모델이 상기 텍스트 생성 결과를 생성하는 논리 추리가 정확하다고 결정하기 위한 결정 유닛;을 포함하는,모델 생성 결과 처리 장치."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 연결되는 메모리;를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서에 의해 제1항 내지제7항 중 어느 한 항의 방법이 수행되도록 하는,전자 기기."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 기록 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제7항 중 어느 한 항의 방법을 수행하도록 하는,비일시적 컴퓨터 판독 가능 기록 매체."}
{"patent_id": "10-2024-0108349", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "비일시적 컴퓨터 판독 가능 기록 매체에 저장되어 있는 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행될 때, 제1항 내지 제7항 중 어느 한 항의 방법을 구현하는,컴퓨터 프로그램."}
{"patent_id": "10-2024-0108349", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시 모델 생성 결과 처리 방법, 장치, 전자 기기 및 저장 매체를 제공하고, 기계 학습과 자연 언어 처리 등 의 인공 지능"}
{"patent_id": "10-2024-0108349", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것이다. 구체적인 구현 방안은 생성식 대규모 모델의 텍스트 생성 결과를 분해하 여 복수의 결과 논리 유닛을 획득하고, 각 결과 논리 유닛은 텍스트 생성 결과 중의 프래그먼트를 포함하고, 각 프래그먼트는 텍스트 생성 결과의 논리 추리 관계에서, 하나의 전제 또는 결론을 독립적으로 표기할 수 있고, 텍 스트 생성 결과는 생성식 대규모 모델이 텍스트 입력 정보에 기반하여 생성된 응답 결과이고, 복수의 결과 논리 유닛에 기반하여, 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하고, 논 리 추리도에 기반하여, 생성식 대규모 모델이 텍스트 생성 결과를 생성하는 논리 추리의 정확한지 여부를 결정한 다. 본 개시의 기술은 생성식 대규모 모델의 논리 추리가 정확한지 여부를 효율적이고 정확하게 결정할 수 있다. 대 표 도 - 도1"}
{"patent_id": "10-2024-0108349", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2024-0131289 CPC특허분류 G06F 16/338 (2019.01) G06F 16/36 (2019.01) G06N 20/00 (2021.08) G06N 5/02 (2023.01) 발명자 펑, 씬웨이 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 10 스트리트, 넘버 10, 바이두 캠퍼스 2플로어 펑, 즈판 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 10 스트리트, 넘버 10, 바이두 캠퍼스 2플로어 추이, 씨아오펑 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 10 스트리트, 넘버 10, 바이두 캠퍼스 2플로어시, 치아오치아오 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 10 스트리트, 넘버 10, 바이두 캠퍼스 2플로어 우, 화 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 10 스트리트, 넘버 10, 바이두 캠퍼스 2플로어명 세 서 청구범위 청구항 1 텍스트 처리 분야에 적용되는 모델 생성 결과 처리 방법에 있어서, 생성식 대규모 모델(generative large model)의 텍스트 생성 결과를 분해하여(disassembled), 복수의 결과 논 리 유닛을 획득하는 단계 - 각 상기 결과 논리 유닛은 상기 텍스트 생성 결과 중의 프래그먼트(fragment)를 포 함하고, 각 상기 프래그먼트는 상기 텍스트 생성 결과의 논리 추리 관계 중의 하나의 전제(premise) 또는 결론 을 독립적으로 표기(marking)할 수 있고, 상기 텍스트 생성 결과는 상기 생성식 대규모 모델이 텍스트 입력 정 보에 기반하여 생성한 응답 결과임 -; 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도(logical reasoning graph)를 생성하는 단계; 및 상기 논리 추리도에 기반하여, 상기 생성식 대규모 모델이 상기 텍스트 생성 결과를 생성하기 위해 사용하는 논 리 추리가 정확한지 여부를 결정하는 단계; 를 포함하는, 모델 생성 결과 처리 방법. 청구항 2 제1항에 있어서, 생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의 결과 논리 유닛을 획득하는 단계는, 사전 트레이닝된 논리 분해 모델을 사용하여, 상기 생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의 결과 논리 유닛을 획득하는 단계를 포함하는, 모델 생성 결과 처리 방법. 청구항 3 제1항에 있어서, 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하는 단계는, 상기 복수의 결과 논리 유닛에 기반하여, 사전 트레이닝된 논리 추리도 생성 모델(logic reasoning graph generation model)을 사용하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추 리도를 생성하는 단계를 포함하는, 모델 생성 결과 처리 방법. 청구항 4 제1항에 있어서, 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하는 단계의 전에, 상기 방법은, 생성식 대규모 모델의 텍스트 입력 정보를 분해하여, 복수의 입력 논리 유닛을 획득하는 단계를 더 포함하고, 각 상기 입력 논리 유닛은 상기 텍스트 입력 정보 중의 프래그먼트를 포함하고, 각 상기 프래그먼트는 논리 추 리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있는, 모델 생성 결과 처리 방법. 청구항 5 제4항에 있어서, 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하는 단계는, 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 입력 논리 유닛을 참조하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 상기 논리 추리도를 생성하는 단계를 포함하는, 모델 생성 결과 처리 방법. 청구항 6 제5항에 있어서, 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 입력 논리 유닛을 참조하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 상기 논리 추리도를 생성하는 단계는, 상기 복수의 입력 논리 유닛과 상기 복수의 결과 논리 유닛에 기반하여, 미리 설정된 샘플 데이터베이스에서, 관련성이 가장 높은 샘플을 검색하는 단계 - 상기 샘플 데이터베이스는 복수 그룹의 샘플을 포함하고, 각 상기 샘플은 입력 샘플 정보에 대응하는 복수의 입력 샘플 논리 유닛, 결과 샘플 정보에 대응하는 복수의 결과 샘플 논리 유닛 및 복수의 결과 샘플 논리 유닛에 대응하는 샘플 논리 추리도를 포함함 -; 및 상기 복수의 입력 논리 유닛, 상기 복수의 결과 논리 유닛, 상기 복수의 입력 샘플 논리 유닛, 상기 복수의 결 과 샘플 논리 유닛 및 대응하는 상기 샘플 논리 추리도에 기반하여, 사전 트레이닝된 다른 생성식 대규모 모델 을 사용하여, 상기 복수의 결과 논리 유닛에 대응하는 상기 논리 추리도를 생성하는 단계; 를 포함하는, 모델 생성 결과 처리 방법. 청구항 7 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 논리 추리도에 기반하여, 상기 생성식 대규모 모델이 상기 텍스트 생성 결과를 생성하는 논리 추리가 정확 한지 여부를 결정하는 단계는, 상기 논리 추리도를 복수의 2층 서브도(two-layer subgraph)로 분해하는 단계 - 각 상기 2층 서브도는 하나의 논리 추리 단계를 표기함 -; 각 상기 2층 서브도의 논리 추리가 정확한지 여부를 판정하는 단계; 및 상기 복수의 2층 서브도의 논리 추리가 모두 정확한 것에 응답하여, 상기 생성식 대규모 모델이 상기 텍스트 생 성 결과를 생성하는 논리 추리가 정확하다고 결정하는 단계; 를 포함하는, 모델 생성 결과 처리 방법. 청구항 8 텍스트 처리 분야에 적용되는 모델 생성 결과 처리 장치에 있어서, 생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의 결과 논리 유닛을 획득하기 위한 분해 모듈 (disassembly module) - 각 상기 결과 논리 유닛은 상기 텍스트 생성 결과 중의 프래그먼트를 포함하고, 각 상 기 프래그먼트는 상기 텍스트 생성 결과의 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있고, 상기 텍스트 생성 결과는 상기 생성식 대규모 모델이 텍스트 입력 정보에 기반하여 생성한 응답 결과임 -; 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하기 위한 생성 모듈(generating module); 및상기 논리 추리도에 기반하여, 상기 생성식 대규모 모델이 생성한 상기 텍스트 생성 결과의 논리 추리가 정확한 지 여부를 결정하기 위한 평가 모듈(evaluation module); 을 포함하는, 모델 생성 결과 처리 장치. 청구항 9 제8항에 있어서, 상기 분해 모듈은, 사전 트레이닝된 논리 분해 모델을 사용하여, 상기 생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의 결과 논리 유닛을 획득하는데 사용되는, 모델 생성 결과 처리 장치. 청구항 10 제8항에 있어서, 상기 생성 모듈은, 상기 복수의 결과 논리 유닛에 기반하여, 사전 트레이닝된 논리 추리도 생성 모델을 사용하여, 상기 복수의 결 과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하는데 사용되는, 모델 생성 결과 처리 장치. 청구항 11 제8항에 있어서, 상기 분해 모듈은 또한, 생성식 대규모 모델의 텍스트 입력 정보를 분해하여, 복수의 입력 논리 유닛을 획득하는데 사용되고, 각 상기 입력 논리 유닛은 상기 텍스트 입력 정보 중의 프래그먼트를 포함하고, 각 상기 프래그먼트는 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있는, 모델 생성 결과 처리 장치. 청구항 12 제11항에 있어서, 상기 생성 모듈은, 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 입력 논리 유닛을 참조하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 상기 논리 추리도를 생성하는데 사용되는, 모델 생성 결과 처리 장치. 청구항 13 제12항에 있어서, 상기 생성 모듈은, 상기 복수의 입력 논리 유닛과 상기 복수의 결과 논리 유닛에 기반하여, 미리 설정된 샘플 데이터베이스에서, 관련성이 가장 높은 샘플을 검색하고, 상기 샘플 데이터베이스는 복수 그룹의 샘플을 포함하고, 각 상기 샘플은 입력 샘플 정보에 대응하는 복수의 입력 샘플 논리 유닛, 결과 샘플 정보에 대응하는 복수의 결과 샘플 논리 유 닛 및 복수의 결과 샘플 논리 유닛에 대응하는 샘플 논리 추리도를 포함하고, 상기 복수의 입력 논리 유닛, 상기 복수의 결과 논리 유닛, 상기 복수의 입력 샘플 논리 유닛, 상기 복수의 결 과 샘플 논리 유닛 및 대응하는 상기 샘플 논리 추리도에 기반하여, 사전 트레이닝된 기타 생성식 대규모 모델을 사용하여, 상기 복수의 결과 논리 유닛에 대응하는 상기 논리 추리도를 생성하는데 사용되는, 모델 생성 결과 처리 장치. 청구항 14 제8항 내지 제13항 중 어느 한 항에 있어서, 상기 평가 모듈은, 상기 논리 추리도를 복수의 2층 서브도로 분해하기 위한 분해 유닛 - 각 상기 2층 서브도는 하나의 논리 추리 단계를 표기함 -; 각 상기 2층 서브도의 논리 추리가 정확한지 여부를 판정하기 위한 판정 유닛; 및 상기 복수의 2층 서브도의 논리 추리가 모두 정확한 것에 응답하여, 상기 생성식 대규모 모델이 상기 텍스트 생 성 결과를 생성하는 논리 추리가 정확하다고 결정하기 위한 결정 유닛; 을 포함하는, 모델 생성 결과 처리 장치. 청구항 15 전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 연결되는 메모리; 를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서에 의해 제1항 내지 제7항 중 어느 한 항의 방법이 수행되도록 하는, 전자 기기. 청구항 16 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 기록 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제7항 중 어느 한 항의 방법을 수행하도록 하는, 비일시적 컴퓨터 판독 가능 기록 매체. 청구항 17 비일시적 컴퓨터 판독 가능 기록 매체에 저장되어 있는 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행될 때, 제1항 내지 제7항 중 어느 한 항의 방법을 구현하는, 컴퓨터 프로그램. 발명의 설명 기 술 분 야 본 개시는 컴퓨터 기술 분야에 관한 것으로, 구체적으로 기계 학습과 자연 언어 처리 등의 인공지능 기술 분야 에 관한 것으로, 특히 모델 생성 결과 처리 방법, 장치, 전자 기기 및 저장 매체에 관한 것이다."}
{"patent_id": "10-2024-0108349", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "생성식 대규모 모델(generative large model)의 광범위한 응용에 따라, 생성식 대규모 모델의 효과 평가도 매우 중요한 기술이 된다. 생성식 대규모 모델의 효과 평가는 생성식 대규모 모델의 텍스트 생성 결과가 정확한지 여부를 판정하는 것이다. 생성식 대규모 모델의 효과 평가는 기존 모델의 작업 평가와 다른 것은, 생성식 대규모 모델의 텍스트 생성 결과는 유일하게 고정되어 있지 않기 때문에, 효과 평가 시의 문자열의 매칭 여부를 간단하게 평가할 수 없다."}
{"patent_id": "10-2024-0108349", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 모델 생성 결과 처리 방법, 장치, 전자 기기 및 저장 매체를 제공한다. 본 개시의 일 측면에 따르면, 모델 생성 결과 처리 방법을 제공하고, 생성식 대규모 모델의 텍스트 생성 결과를 분해하여(disassembled), 복수의 결과 논리 유닛을 획득하는 단계 - 각 상기 결과 논리 유닛은 상기 텍스트 생성 결과 중의 프래그먼트(fragment)를 포함하고, 각 상기 프래그먼트 는 상기 텍스트 생성 결과의 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있고, 상기 텍스트 생성 결과는 상기 생성식 대규모 모델이 텍스트 입력 정보에 기반하여 생성된 응답 결과임 -; 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도(logical reasoning graph)를 생성하는 단계; 및 상기 논리 추리도에 기반하여, 상기 생성식 대규모 모델이 상기 텍스트 생성 결과를 생성하는 논리 추리가 정확 한지 여부를 평가하는 단계를 포함한다. 본 개시의 다른 측면에 따르면, 모델 생성 결과 처리 장치를 제공하고, 생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의 결과 논리 유닛을 획득하기 위한 분해 모듈 (disassembly module) - 각 상기 결과 논리 유닛은 상기 텍스트 생성 결과 중의 프래그먼트를 포함하고, 각 상 기 프래그먼트는 상기 텍스트 생성 결과의 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있고, 상기 텍스트 생성 결과는 상기 생성식 대규모 모델이 텍스트 입력 정보에 기반하여 생성된 응답 결과임 -; 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하기 위한 생성 모듈(generating module); 및 상기 논리 추리도에 기반하여, 상기 생성식 대규모 모델이 상기 텍스트 생성 결과를 생성하는 논리 추리의 정확 한지 여부를 평가하기 위한 평가 모듈(evaluation module);을 포함한다. 본 개시의 또 다른 측면에 따르면, 전자 기기를 제공하고, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프 로세서에 통신 연결되는 메모리;를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 수행 가능 한 명령이 저장되어 있고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프 로세서에 의해 상기 측면 및 임의의 가능한 구현 방식의 방법이 수행되도록 한다. 본 개시의 또 다른 측면에 따르면, 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체를 제공 하고, 상기 컴퓨터 명령은 상기 컴퓨터가 상기 측면 및 임의의 가능한 구현 방식의 방법을 수행하도록 한다. 본 개시의 또 다른 측면에 따르면, 컴퓨터 프로그램 제품을 제공하고, 컴퓨터 프로그램을 포함하고, 상기 컴퓨 터 프로그램이 프로세서에 의해 수행될 때, 상기 측면 및 임의의 가능한 구현 방식의 방법을 구현한다. 본 개시의 기술에 따르면, 생성식 대규모 모델의 논리 추리가 정확한지 여부를 효율적이고 정확하게 결정할 수 있고, 나아가 생성식 대규모 모델의 평가 효율을 효과적으로 향상시킬 수 있다. 본 명세서에서 설명된 내용은 본 발명의 실시예의 키 또는 중요한 특징을 표기하려는 것이 아니고, 또한 본 발 명의 범위를 제한하려는 것도 아닌 것을 이해하여야 한다. 본 발명의 다른 특징은 이하의 명세서를 통해 용이하 게 이해할 수 있다."}
{"patent_id": "10-2024-0108349", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 결부하여 본 출원의 예시적 실시예를 설명하되, 여기에는 이해를 돕기 위한 본 출원의 실"}
{"patent_id": "10-2024-0108349", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "시예의 다양한 세부 사항이 포함되며, 이는 단지 예시적인 것으로 간주되어야 한다. 따라서, 본 기술분야의 통 에서의 기술자는 본 출원의 범위와 사상을 벗어나지 않으면서, 여기서 설명되는 실시예에 대한 다양한 변경과 수정이 이루어질 수 있음을 이해해야 한다. 마찬가지로, 명확성 및 간결성을 위해, 아래의 설명에서 공지된 기 능과 구조에 대한 설명을 생략한다. 분명히, 설명된 실시예는 본 출원의 일부 실시예이고, 모든 실시예가 아니다. 본 출원의 실시예에 의하면, 당업 자는 창조적인 노력없이 획득되는 모든 기타 실시예는 모두 본 출원의 보호 범위에 속한다. 설명해야 하는 바로는, 본 출원의 실시예에 관한 단말 디바이스는 휴대 전화, 휴대 정보 단말(PerSonal Digital ASSiStant, PDA), 무선 휴대 장치, 태블릿 컴퓨터(Tablet Computer)등의 스마트 디바이스를 포함할 수 있지만, 이에 한정하지 않는다. 디스플레이 디바이스는 컴퓨터, 텔레비전 등의 디스플레이 기능을 갖추는 기기를 포함할 수 있지만, 이에 한정하지 않는다. 또한, 본 명세서의 용어“및/또는”은 관련 객체에서의 관련 관계를 설명하며 3가지 관계가 존재함을 나타낸다. 예를 들어 A및/또는 B는, A가 단독으로 존재; A와 B가 동시에 존재; B가 단독으로 존재하는 3가지 경우를 나타 낼 수 있다. 문자 \"/\"는 일반적으로 전후 관련 대상이 \"또는”의 관계를 가짐을 나타낸다. 도 1은 본 개시의 제1 실시예에 따른 개략도이다. 도 1에 도시된 바와 같이, 본 실시예는 모델 생성 결과 처리 방법을 제공하고, 구체적으로 다음과 같은 단계를 포함할 수 있고, S101, 생성식 대규모 모델의 텍스트 생성 결과를 분해하여 복수의 결과 논리 유닛을 획득하고, 본 실시예의 각 결과 논리 유닛은 텍스트 생성 결과 중의 프래그먼트를 포함하고, 각 프래그먼트는 텍스트 생성 결과의 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있고, 텍스트 생성 결과는 생성식 대규모 모델이 텍스트 입력 정보에 기반하여 생성된 응답 결과이다. 본 실시예의 모델 생성 결과 처리 방법의 수행 주체는 모델 생성 결과 처리 장치일 수 있고, 상기 장치는 하나 의 독립된 전자 기기일 수 있고, 또는 소프트웨어 기반을 사용한 응용일 수도 있고, 생성식 대규모 모델의 생성 효과를 평가한다. 본 실시예의 생성식 대규모 모델은 생성식 언어 모델(General Language Model; GLM)이라고도 불리고, 생성식 대 규모 언어 모델이라고도 불린다. 본 실시예에서 생성식 대규모 모델이 텍스트 처리 분야에서 사용하는 것을 예로 하여, 사용할 때 상기 생성식 대규모 모델에 텍스트 입력 정보를 입력하고, 상기 생성식 대규모 모델은 텍스트 입력 정보에 기반하여 텍스트 생성 결과를 생성하여 출력할 수 있다. 실제 응용 시나리오에서, 생성식 대규모 모델이 텍스트 생성 결과를 생 성하는 효과를 향상시키기 위해, 생성식 대규모 모델의 생성 결과에 대해 일부 상응하는 처리를 수행할 필요가있고, 생성식 대규모 모델의 논리 추리가 정확한지 여부를 효율적이고 정확하게 결정하는 것을 구현하고, 생성 식 대규모 모델에 대해 정확하고 효과적인 평가를 수행할 수도 있다. 나아가, 평가 결과에 기반하여, 반대로 생 성식 대규모 모델을 최적화하여, 생성식 대규모 모델의 텍스트 생성 효과를 대폭 향상시킬 수 있다. 생성식 대규모 모델의 텍스트 생성 결과가 보통 길기 때문에, 복수의 문장을 포함할 수 있다. 그 중 각 결과 논 리 유닛에서의 프래그먼트는 텍스트 생성결과 중의1개의 문장, 또는 연속된 2개 이상의 문장일 수 있다. 즉, 프 래그먼트가 텍스트 생성 결과에서 반드시 연속된 1개의 세그먼트이고, 중단된 2개 이상의 세그먼트의 결합은 안 된다. 구체적으로, 본 실시예에서, 텍스트 생성 결과를 분해하는 원칙은, 분해 후의 각 결과 논리 유닛이, 텍스트 생 성 결과에 대해 논리 관계 추리를 수행할 때에, 하나의 전제 또는 결론인 것을 확보한다. S102, 복수의 결과 논리 유닛에 기반하여, 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논 리 추리도를 생성하고, 본 실시예의 논리 추리도는, 즉 복수의 결과 논리 유닛을 논리 추리 관계에 따라 구성된 유방향 비순환도 (directed acyclic graph)이다. S103, 논리 추리도에 기반하여, 생성식 대규모 모델이 텍스트 생성 결과를 생성하는 논리 추리가 정확한지 여부 를 결정한다. 논리 추리도의 생성은 복수의 결과 논리 유닛 사이의 논리 추리 관계에 기반하여 생성되므로, 논리 추리도에서 의 복수의 결과 논리 유닛 사이의 논리 추리 관계를 참조하여, 생성식 대규모 모델이 텍스트 생성 결과를 생성 하는 논리 추리의 정확한지 여부를 평가할 수 있고, 나아가 논리 추리 차원에서 생성식 대규모 모델을 평가하는 것을 구현할 수 있다. 즉 생성식 대규모 모델이 텍스트 생성 결과를 생성하는 논리 추리가 정확한 경우, 생성식 대규모 모델의 논리 추리가 정확한 것을 나타내고, 생성식 대규모 모델이 텍스트 생성 결과를 생성하는 논리 추 리가 정확하지 않은 경우, 생성식 대규모 모델의 논리 추리가 정확하지 않은 것을 나타낸다. 본 실시예의 모델 생성 결과 처리 방법은, 텍스트 생성 결과를 분해하여 복수의 결과 논리 유닛을 획득하고, 복 수의 결과 논리 유닛의 논리 추리도를 생성하고, 나아가, 상기 논리 추리도에 따라 생성식 대규모 모델이 텍스 트 생성 결과를 생성하는 논리 추리의 정확한지 여부를 결정함으로써, 생성식 대규모 모델의 논리 추리의 정확 한지 여부를 결정하는 것을 더욱 효과적으로 구현한다. 따라서, 본 실시예의 기술 방안을 사용하면, 논리 추리 의 차원에서 효율적이고 정확하게 생성식 대규모 모델의 텍스트 생성 결과를 효과적으로 평가하고, 생성식 대규 모 모델을 효과적으로 평가하는 것을 더 효율적이고 정확하게 구현할 수 있다. 또한, 본 실시예의 기술 방안은 인력으로 수동 처리를 수행할 필요없이, 전자동으로 수행할 수 있어, 인건비를 크게 줄이고 평가 속도를 향상시 키며, 나아가 생성식 대규모 모델의 평가 효율을 효과적으로 향상시킬 수 있다. 도 2는 본 개시의 제2 실시예에 따른 개략도이다. 본 실시예의 모델 생성 결과 처리 방법은, 상술한 도 1과 같 은 실시예의 기술 방안에 기반하여, 더 나아가, 본 개시의 기술 방안을 더 상세하게 설명한다. 도 2에 도시된 바와 같이, 본 실시예의 모델 생성 결과 처리 방법은 구체적으로 다음과 같은 단계를 포함할 수 있고, S201, 사전 트레이닝된 논리 분해 모델(logic disassembly model)을 사용하여, 생성식 대규모 모델의 텍스트 생 성 결과를 분해하여, 복수의 결과 논리 유닛을 획득하고, 이 단계는 상술한 도 1에 도시된 실시예의 단계 S101의 구현 방식이다. 이러한 구현 방식에서, 사전 트레이닝된 논리 분해 모델을 사용하여, 자동으로 텍스트 생성 결과를 분해한다. 구체적으로 구현할 때, 상기 텍스트 생성 결과를 논리 분해 모델에 입력하고, 상기 논리 분해 모델은 입력된 텍스트 생성 결과에 기반하여, 대응하는 복 수의 결과 논리 유닛을 직접 출력한다. 본 실시예의 상기 논리 분해 모델은 트레이닝 전에 복수 그룹의 트레이닝 데이터를 수집할 수 있고, 각 그룹의 트레이닝 데이터는 트레이닝 코퍼스(training corpus) 및 수동으로 상기 트레이닝 코퍼스를 분해하여 획득한 복 수의 트레이닝 논리 유닛을 포함한다. 분해의 원칙은 분해 후의 각 트레이닝 논리 유닛이 트레이닝 코퍼스에 대 해 논리 관계 추리를 수행할 때, 하나의 전제 또는 결론인 것을 확보한다. 그 다음에, 복수 그룹의 트레이닝 데 이터를 사용하여 논리 분해 모델을 트레이닝하여, 상기 논리 분해 모델이 분해 능력을 학습할 수 있다. 본 실시예에서 논리 분해 모델을 사용하여, 텍스트 생성 결과에 대해 지능적인 분해를 수행함으로써, 분해된 복 수의 결과 논리 유닛의 정밀도를 효과적으로 향상시킬 수 있고, 분해 효율을 향상시킬 수 있다. 또한, 선택적으로, 도 1에 도시된 실시예의 단계 S101은 미리 설정된 분해 전략에 따라 생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의 결과 논리 유닛을 획득할 수도 있다. 예를 들어, 미리 설정된 분해 전략은 분해 후의 각 결과 논리 유닛이 텍스트 생성 결과의 논리 추리 관계에서, 하나의 전제 또는 결론인 것을 확보하도록 설정할 수 있다. 구체적으로 구현할 때, 먼저, 문장의 입도(granularity)에 따라 텍스트 생성 결과를 분할하고, 그 다음에, 모든 프래그먼트 분할 방식을 순회하여, 텍스트 생성 결과의 다양한 분할 결과를 획득할 수 있다. 각 상기 프래그먼 트 분할 방식에서, 하나의 문장을 단독적으로 하나의 프래그먼트로 분할하거나, 또는 인접하는 2개 또는 2개 이 상의 연속된 문장을 하나의 프래그먼트로 분할할 수 있다. 그 다음에, 각 분할 결과 중의 각 분할의 프래그먼트 를 검출하고, 이가 텍스트 생성 결과의 논리 추리 관계 중의 1개의 전제 또는 1개의 결론으로 할 수 있는지 여 부를 검출할 수 있다. 마지막으로, 모든 분할 결과로부터, 하나의 분해된 모든 프래그먼트를 모두 하나의 전제 또는 결론으로 하는 분할 결과로서, 최종적으로 필요한 분해 결과로서 선택하고, 대응하는 복수의 결과 논리 유 닛을 획득할 수 있다. 미리 설정된 분해 전략 방식에 따라 분해하면, 효율적이고 정확하게 복수의 결과 논리 유닛을 획득할 수도 있다. S202, 복수의 결과 논리 유닛에 기반하여, 사전 트레이닝된 논리 추리도 생성 모델을 사용하여 복수의 결과 논 리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하고, 본 실시예에서, 하나의 논리 추리도 생성 모델을 사전 트레이닝하고, 사용할 때에, 상기 논리 추리도 생성 모델 에 복수의 결과 논리 유닛을 입력할 수 있고, 상기 논리 추리도 생성 모델은 입력된 정보에 기반하여, 복수의 결과 논리 유닛으로 구성된 논리 추리도를 생성할 수 있다. 상기 논리 추리도 생성 모델은 트레이닝 시에, 복수 그룹의 트레이닝 데이터를 사용하여 트레이닝하고 획득할 수 있고, 각 트레이닝 데이터는 복수의 트레이닝 논리 유닛 및 복수의 트레이닝 논리 유닛에 기반하여 라벨링된 트레이닝 논리 추리도를 포함할 수 있다. 복수 그룹의 트레이닝 데이터를 사용하여, 상기 논리 추리도 생성 모 델을 트레이닝함으로써, 상기 논리 추리도 생성 모델이 복수의 트레이닝 논리 유닛에 기반하여, 상기 트레이닝 논리 추리도를 생성하는 능력을 학습할 수 있다. 사용할 때에, 복수의 결과 논리 유닛을 상술한 방식을 통해 트레이닝된 논리 추리도 생성 모델에 입력하며, 이 때, 상기 논리 추리도 생성 모델은 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리 도를 생성하여 출력할 수 있다. 상술한 논리 추리도 생성 모델에 기반하여 논리 추리도를 지능적으로 생성하는 방식은 효율적이고 정확하게 복 수의 결과 논리 유닛의 논리 추리도를 생성할 수 있다. S203, 논리 추리도를 복수의 2층 서브도로 분해하고, 각 2층 서브도는 하나의 논리 추리 단계를 표기하고, 구체적으로, 2층 서브도를 분해할 때, 논리 추리도에서의 추리 관계에 따라, 최소 논리 관계 서브도, 즉 2층 서 브도를 분할한다. 예를 들면, 도 3은 본 개시에서 제공되는 논리 추리도이다. 본 실시예의 분해 프로세스에 따 라, 도 3에 도시된 논리 추리도를 2개의 2층 서브도로 분해할 수 있고, 예를 들어, A, B, 및 C로 구성된 2층 서 브도와, C, D, 및 E로 구성된 2층 서브도이다. 각 2층 서브도는 즉 하나의 논리 추리 단계에 대응한다. 상기 방 식을 통해 논리 추리도에서의 모든 2층 서브도를 분해할 수 있다. S204, 각 2층 서브도의 논리 추리가 정확한지 여부를 판정하고, 구체적으로, 판정시에, 사전 트레이닝된 추리 모델을 사용하여, 각 2층 서브도의 논리 추리가 정확한지 여부를 추리할 수 있다. 예를 들면, 사용할 때에, 각 2층 서브도를 논리 추리도 중 위에서 아래로 왼쪽에서 오른쪽으로 의 순서로, 차례로 추리 모델에 입력할 수 있다. 나아가, 입력된 각 2층 서브도에 의해 표시된 논리 추리가 정 확한지 여부를 추리 모델이 순차적으로 판정한다. 본 실시예의 추리 모델은, 대규모 언어 모델(Large Language Model; LLM)을 사용하여 구현할 수도 있다. 선택적으로, 본 실시예에서, 일정한 전략을 설정하는 것을 통해, 각 2층 서브도의 추리가 정확한지 여부를 판정할 수도 있고, 각 2층 서브도의 논리 추리가 정확한지 여부를 정확하 게 판정할 수도 있다. S205, 복수의 2층 서브도의 논리 추리가 모두 정확한 것에 응답하여, 생성식 대규모 모델이 텍스트 생성 결과를 생성하는 논리 추리가 정확하다고 결정한다. 다시 말하면, 복수의 2층 서브도 중 하나의 2층 서브도의 논리 추리가 정확하지 않으면, 상기 생성식 대규모 모 델이 텍스트 생성 결과를 생성하는 논리 추리가 정확하지 않은 것으로 간주되고, 또한 생성식 대규모 모델의 논 리 추리가 정확하지 않다고 결정한다. 본 실시예의 단계 S203-S205는 상술한 도 1에 도시된 실시예의 단계 S103의 구체적인 구현 방식이다. 구체적으로, 이러한 구현 방식에서, 논리 추리도를 복수의 2층 서브도로 분해하고, 각 2층 서브도의 단일한 논 리 추리 단계가 정확한지 여부를 판정하는 것을 통해, 생성식 대규모 모델이 텍스트 생성 결과를 생성하는 논리 추리가 정확한지 여부를 판정하고, 나아가 생성식 대규모 모델에 의해 생성된 논리 추리가 정확한지 여부를 판 단한다. 본 실시예에서, 이러한 방식을 통해 매번 1개의 2층 서브도만을 판정하고, 즉 한 번에 하나의 논리 추리 단계가 정확한지 여부만을 판정하면, 생성식 대규모 모델에 의해 생성된 텍스트 생성 결과의 논리 추리가 정확한지 여 부를 판정하는 판정 난이도를 효과적으로 줄일 수 있고, 생성식 대규모 모델의 논리 추리가 정확한지 여부를 판 정하는 정밀도를 효과적으로 향상시키고, 나아가, 생성식 대규모 모델의 텍스트 생성 결과 평가의 정밀도 및 평 가 효율을 효과적으로 향상시킬 수 있고, 생성식 대규모 모델의 평가 효과를 대폭 향상시킬 수 있다. 본 실시예의 모델 생성 결과 처리 방법은 상술한 방식을 사용하여, 생성식 대규모 모델의 논리 추리가 정확한지 여부를 정확하게 판정하는 것을 통해, 생성식 대규모 모델의 평가를 자동적으로 구현할 수 있어, 시간과 힘을 줄이고, 평가 속도를 효과적으로 단축하며, 생성식 대규모 모델의 평가 효율을 향상시킨다. 또한, 텍스트 생성 결과의 논리 추리도에 의해 분해된 각 2층 서브도의 논리 추리를 판정하는 것을 통해, 텍스트 생성 결과의 논리 추리를 판정하는 것을 구현하고, 나아가 생성식 대규모 모델의 텍스트 생성 결과의 평가를 구현하며, 평가의 정 확도 및 평가 효율을 효과적으로 향상시킬 수 있다. 도 4는 본 개시의 제3 실시예에 따른 개략도이다. 본 실시예의 모델 생성 결과 처리 방법은, 상술한 도 1에 도 시된 실시예의 기술 방안에 기반하여, 더 나아가, 본 개시의 기술 방안을 더 상세하게 설명한다. 도 4에 도시된 바와 같이, 본 실시예의 모델 생성 결과 처리 방법은 구체적으로 다음과 같은 단계를 포함할 수 있고, S401, 사전 트레이닝된 논리 분해 모델을 사용하여, 생성식 대규모 모델의 텍스트 입력 정보와 텍스트 생성 결 과를 각각 분해하여, 복수의 입력 논리 유닛과 복수의 결과 논리 유닛을 획득하고, 각 상기 입력 논리 유닛은, 텍스트 입력 정보 중의 프래그먼트를 포함하고, 각 프래그먼트는, 텍스트 입력 정보 의 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있다. 각 결과 논리 유닛은, 텍스트 생 성 결과 중의 프래그먼트를 포함하고, 각 프래그먼트는, 텍스트 생성 결과의 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있는 것에 대응한다. 구체적인 구현 방식은 상술한 도 2에 도시된 실시예의 단계 S201의 관련 기재를 참조할 수 있고, 여기에서는 설명을 생략한다. S402, 복수의 결과 논리 유닛에 기반하여, 복수의 입력 논리 유닛을 참조하여 복수의 결과 논리 유닛 사이의 논 리 추리 관계를 표시할 수 있는 논리 추리도를 생성하고, 다시 말하면, 본 실시예의 복수의 결과 논리 유닛의 논리 추리도의 생성, 복수의 결과 논리 유닛뿐만 아니라, 복수의 입력 논리 유닛을 동시에 참조할 필요가 있다. 예를 들어 상기 단계 S402를 구체적으로 구현할 때, 다음과 같은, 복수의 입력 논리 유닛과 복수의 결과 논리 유닛에 기반하여, 미리 설정된 샘플 데이터베이스에서, 관련성이 가장 높은 샘플을 검색하는 단계; 복수의 입력 논리 유닛과 복수의 결과 논리 유닛, 및 복수의 입력 샘플 논리 유닛, 복수의 결과 샘플 논리 유닛, 및 대응하는 샘플 논리 추리도에 기반하여, 사전 트레이닝된 기타 생성식 대규모 모델을 사용하여, 복수 의 결과 논리 유닛에 대응하는 논리 추리도를 생성하는 단계;를 포함할 수 있다. 본 실시예의 미리 설정된 샘플 데이터베이스에서는 복수 그룹의 샘플이 저장될 수 있다. 각 그룹의 샘플에서, 입력 샘플 정보에 대응하는 복수의 입력 샘플 논리 유닛, 결과 샘플 정보에 대응하는 복수의 결과 샘플 논리 유 닛 및 복수의 결과 샘플 논리 유닛에 대응하는 샘플 논리 추리도를 포함할 수 있다. 본 실시예에서, 샘플 데이터베이스 중의 정보도 모두 텍스트 형식이고, 즉 각 그룹의 샘플 중의 입력 샘플 정보 는 텍스트 입력 샘플 정보이고, 결과 샘플 정보는 텍스트 결과 샘플 정보이고, 즉 입력 샘플 정보는 생성식 대 규모 모델의 텍스트 입력 정보일 수도 있고, 결과 샘플 정보는 생성식 대규모 모델에 의해 생성된 텍스트 생성결과일 수도 있다. 복수의 입력 샘플 논리 유닛과 복수의 결과 샘플 논리 유닛은 각각 상술한 단계 S401의 복수 의 입력 논리 유닛과 복수의 결과 논리 유닛 분해 방식을 사용하여 획득할 수 있다. 본 실시예의 샘플 논리 추 리도는 복수의 결과 샘플 논리 유닛에 기반하여 수동으로 라벨링할 수 있다. 구체적으로 검색할 때, 본 실시예에서 복수의 입력 논리 유닛과 복수의 결과 논리 유닛에 기반하여, 미리 설정 된 샘플 데이터베이스에서, 관련성이 가장 높은 샘플을 검색할 수 있다. 여기의 관련성이 가장 높은 샘플은, 복 수의 입력 논리 유닛과 복수의 결과 논리 유닛의 전체적인 콘텍스트 어의에서, 관련성이 가장 높은 복수의 입력 샘플 논리 유닛과 복수의 결과 샘플 논리 유닛에 대응하는 샘플로 간주할 수 있다. 그 다음에, 복수의 입력 논리 유닛과 복수의 결과 논리 유닛 및 관련성이 가장 높은 샘플에 포함되는 각 부분 정보를 결합하고, 생성식 대규모 모델을 함께 입력하여, 사전 트레이닝된 기타 생성식 대규모 모델이 관련성이 가장 높은 샘플에서의 복수의 결과 샘플 논리 유닛에 기반하여 샘플 논리 추리도의 생성 방식을 생성하고, 복수 의 결과 샘플 논리 유닛에 대응하는 샘플 논리 추리도를 생성할 수 있다. 본 실시예에서, 사전 트레이닝된 기타 생성식 대규모 모델은 본 실시예에서 평가하는 생성식 대규모 모델이 아니라, 이미 트레이닝된 기타 생성식 대 규모 모델이다. 선택적으로, 본 실시예에서, 샘플 데이터베이스 내의 각 그룹의 샘플에서는, 결과 샘플 정보에 대응하는 복수의 결과 샘플 논리 유닛 및 복수의 결과 샘플 논리 유닛에 대응하는 샘플 논리 추리도만을 포함할 수 있다. 이 경우에 대응하여, 구체적으로 검색할 때, 복수의 결과 논리 유닛만에 기반하여, 미리 설정된 샘플 데이터베 이스에서, 관련성이 가장 높은 샘플을 검색하고, 구체적인 복수의 결과 샘플 논리 유닛과 대응되는 샘플 논리 추리도에 기반하여, 사전 트레이닝된 기타 생성식 대규모 모델을 사용하여, 복수의 결과 논리 유닛에 대응하는 논리 추리도를 생성할 수도 있다. 그러나, 이러한 구현 방식은 상술한 샘플 데이터베이스에 입력 샘플 정보가 동시에 포함되는 대응하는 복수의 입력 샘플 논리 유닛 및 대응하는 기술 방안과 비교하여, 정밀도가 조금 떨어진다. 본 실시예에서, 관련성이 가장 높은 샘플을 검색하고, 기타 생성식 대규모 모델을 사용하여 논리 추리도를 지능 적으로 생성하는 방식을 통해, 복수의 결과 논리 유닛의 논리 추리도를 정확하고 효율적으로 생성할 수 있다. S403, 논리 추리도를 복수의 2층 서브도로 분해하고, 각 2층 서브도는 하나의 논리 추리 단계를 표기하고, S404, 각 2층 서브도의 논리 추리가 정확한지 여부를 판정하고, S405, 복수의 2층 서브도의 추리가 모두 정확한 것에 응답하여, 생성식 대규모 모델이 텍스트 생성 결과를 생성 하는 논리 추리가 정확하다고 결정한다. 본 실시예의 단계 S403-S405의 구체적인 구현 방식은, 상술한 도 2에 도시된 실시예의 단계 S203-S205의 기재를 참조할 수 있고, 여기에서는 설명을 생략한다. 본 실시예의 모델 생성 결과 처리 방법은 상술한 방식을 사용하여 복수의 결과 논리 유닛의 논리 추리도를 보다 정확하고 효율적으로 생성할 수 있고, 나아가 생성식 대규모 모델의 논리 추리가 정확한지 여부를 판정하는 정 밀도를 향상시킬 수 있으며, 나아가 생성식 대규모 모델의 평가의 정밀도 및 평가 효율을 효과적으로 향상시킬 수 있다. 이하는 구체적인 예를 들어, 본 개시의 생성식 대규모 모델의 평가 방법을 설명한다. 예를 들어 이러한 예에서, 텍스트 입력 정보 쿼리(query)는, 경찰이 도둑을 잡고, 4명의 용의자 갑, 을, 병, 정 을 잡았다. 그들의 진술은 갑이 말한 것은: 내가 훔친 것이 아닙니다. 을이 말한 것은: 갑이 훔쳤습니다. 병이 말한 것은: 내가 아닙니다. 정이 말한 것은: 을이 훔쳤습니다. 그들 중 단 한 명만이 참말을 한 것으로 이미 알 고 있습니다. 누가 도둑입니까? 상기 텍스트 입력 정보를 생성식 대규모 모델에 입력하고, 상기 생성식 대규모 모델에 의해 생성된 텍스트 생성 결과 응답(response)은 문제의 문장에 따르면, \"을이 말한 것은: 갑이 훔쳤습니다. 갑이 말한 것은: 내가 훔친 것이 아닙니다”이고, 그러면 갑과 을 중에는 반드시 한 사람이 참말을 하고, 그러면 병과 정은 모두 거짓말을 하고, 즉 병은 거짓말을 하고, 병은 도둑이다. 예를 들면, 단계 S401에 따라, 텍스트 입력 정보 쿼리(query)를 분해하여 획득한 복수의 입력 논리 유닛은, 하 기의 입력 논리 유닛을 포함하고, 즉, 첫 번째 입력 논리 유닛[쿼리-유닛-1], 경찰이 도둑을 잡고, 4명의 용의자 갑, 을, 병, 정을 잡았다. 그들의 진술은; 두 번째 입력 논리 유닛[쿼리-유닛-2], 갑이 말한 것은: 내가 훔 친 것이 아닙니다, 세 번째 입력 논리 유닛[쿼리-유닛-3], 을이 말한 것은: 갑이 훔쳤습니다; 네 번째 입력 논 리 유닛[쿼리-유닛-4], 병이 말한 것은: 내가 아닙니다, 다섯 번째 입력 논리 유닛[쿼리-유닛-5], 정이 말한 것 은: 을이 훔쳤습니다; 여섯 번째 입력 논리 유닛[쿼리-유닛-6], 그들 중 단 한 명만이 참말을 한 것으로 이미 알고 있습니다; 일곱 번째 입력 논리 유닛[쿼리-유닛-7], 누가 도둑입니까?;를 포함한다. 마찬가지로, 단계 S401에 따라, 텍스트 생성 결과 응답(response)을 분해하여 획득한 복수의 결과 논리 유닛은 포함한다. 즉, 첫 번째 결과 논리 유닛 [응답-유닛-1], 을이 말한 것은: 갑이 훔쳤습니다; 두 번째 결과 논리 유닛 [응답-유닛-2], 갑이 말한 것은: 내가 훔친 것이 아닙니다; 세 번째 결과 논리 유닛 [응답-유닛-3], 그러 면 갑과 을 중에는 반드시 한 사람이 참말을 하고; 네 번째 입력 논리 유닛 [응답-유닛-4], 그러면 병과 정은 모두 거짓말을 하고, 다섯 번째 입력 논리 유닛 [응답-유닛-5], 즉 병은 거짓말을 하고, 여섯 번째 입력 논리 유닛 [응답-유닛-6], 병은 도둑이다;를 포함한다. 그 다음에, 단계 S302의 방식에 따라 복수의 결과 논리 유닛의 논리 추리도를 생성할 수 있다. 본 실시예에서, 논리 추리 과정은 하나의 체인형 또는 트리형 구조가 아니라, 하나의 유방향 비순환도와 같은 것이다. 논리 추리 과정은 문제의 추리 과정을 나타내고, 생성된 논리 추리도의 각 노드는 하나의 최소 논리 유 닛이며, 즉 하나의 결과 논리 유닛이다. 논리 추리도에서의 각 2차 서브도는 하나의 최소 추리 과정을 나타낸다. 본 실시예의 샘플 데이터베이스는, 구체적으로, 콘텍스트 학습(In-Context-Learning; ICL) 데이터베이스일 수 있다. 구체적으로, 상술한 단계 S402의 구체적인 구현 방식에 따라, ICL 데이터베이스에서 검색하는 것은, ICL 검색이 라고 부를 수 있다. 구체적으로 검색할 때, 복수의 입력 논리 유닛과 복수의 결과 논리 유닛을 입력하고, 입력 된 복수의 입력 논리 유닛과 복수의 결과 논리 유닛에 따라, ICL 데이터베이스에서 관련성이 가장 높은 샘플을 검색한다. 원 샷(one-shot)의 방식으로 프롬프트(prompt)로 결합되고, 상기 결합된 프롬프트(prompt) 중 관련성 이 가장 높은 샘플에서의 복수의 입력 샘플 논리 유닛, 복수의 결과 샘플 논리 유닛 및 샘플 논리 추리도를 결 합하여 생성된다. 그 다음에, 복수의 입력 논리 유닛과 복수의 결과 논리 유닛 및 결합된 프롬프트(prompt)가, 생성식 대규모 모 델을 사용하여, 복수의 결과 논리 유닛에 대응하는 논리 추리도를 생성한다. 예를 들면, 도 5는 본 실시예에 의 해 생성되는 논리 추리도의 개략도이다. 마지막으로, 도 5에서 획득된 논리 추리도에 기반하여 논리 판정을 수행한다. 실제 응용에서, 전체 논리 추리도 의 정확성을 한 번에 판정하는 것은 비교적 곤란하기 때문에, 상술한 단계 S403-S405의 구현 방식을 참조할 수 있고, 우선 논리 추리도를 하나하나의 2층 서브도로 분해하고, 각 2층 서브도는 하나의 논리 추리 단계를 나타 내, 매번 하나의 2층 서브도만을 판정하고, 다시 말하면, 한 번에 하나의 논리 추리 단계가 정확한지 여부만을 판정하고, 이런 방식은 전체적인 판정 난이도를 감소시키고, 판정 효과를 대폭 향상시킨다. 구체적인 판정 프로세스에서, LLM 구현에 기반하여 논리 추리 모델을 사용하여 구현할 수 있다. LLM을 사용하여 아래에서 위로 순서로 논리 추리도 중의 각 2층 서브도의 논리 추리 단계의 정확성을 판정하고, 각 논리 추리 단계가 모두 정확한 경우, 전체 논리 추리 과정은 모두 정확하고, 그렇지 않은 경우, 논리 추리 과정에 논리성 문제가 존재한다고 판정한다. 이런 방법은 논리 추리형 문제를 제공한 논리 추리의 정확성을 판정할 뿐만 아니 라, 또한 오류가 발생한 단계를 정확하게 포지셔닝할 수 있다. 예를 들면, 도 6A, 도 6B, 및 도 6C는 각각 도 5에 도시된 논리 추리도를 분할한 2층 서브도이다. 도 6A, 도 6B, 및 도 6C의 3개의 2층 서브도의 논리 추리 단계가 모두 정확하다고 판정된 경우, 생성식 대규모 모델에 의 해 생성된 텍스트 생성 결과의 논리 추리가 정확한 것을 판정할 수 있고, 생성식 대규모 모델을 평가하는 것을 구현한다. 본 개시의 실시예의 상술한 방법은, 생성식 대규모 모델에 기반하여 생성된 하나의 텍스트 생성 결과를 평가한 다. 실제 응용 시나리오에서, 하나의 세그먼트 시간 내에서, 생성식 대규모 모델은, 여러 번의 생성 태스크를 수행할 수 있다. 구체적으로, 본 개시의 실시예의 상술한 방식에 따라 생성 태스크를 매번 수행하는 경우, 생성 식 대규모 모델이 텍스트 생성 결과를 생성하는 논리 추리가 정확한지 여부를 평가할 수 있다. 나아가, 상기 세 그먼트 시간의 정확률이 예를 들어 95%, 98% 또는 다른 비례 등 미리 설정된 비례 역치에 도달했는지 여부를 통 계할 수 있고, 도달한 경우, 상기 생성식 대규모 모델의 정확률이 높고 효과가 좋은 것으로 결정하고, 그렇지않은 경우, 상기 생성식 대규모 모델의 정확률과 효과가 좋지 않은 것으로 간주할 수 있다. 논리성은 생성식 대규모 모델의 논리 추리 능력이 좋고 나쁨을 반영하는 가장 중요한 차원이고, 이부 복잡한 논 리 추리 태스크를 해결하는데 필요한 능력이며, 평가 단계에서 모델 텍스트 생성 결과 중 논리성 문제를 발견할 경우, 논리 추리 문제의 효과 평가와 효과 최적화에 중요한 역할을 할 수 있다. 다른 차원에 비해, 논리성은 더 높은 지능의 체현이며, 논리성 평가의 난이도가 매우 높고, 종래의 방법은 비교적 좋은 효과를 달성하기 어렵기 때문에, 본 개시에서 제공되는 모델 생성 결과 처리 방법은 논리성의 각도로부터, 생성식 대규모 모델을 평가하 는 것은 생성식 대규모 모델용 논리 추리의 자동 평가 프레임워크이고, 보다 효과적으로 생성식 대규모 모델의 논리성을 평가할 수 있어, 생성식 대규모 모델의 논리 추리의 평가 정확도 및 평가 효과를 효과적으로 향상시킬 수 있다. 본 개시의 실시예의 상술한 모델 생성 결과 처리 방법은 우선 논리 유닛의 분할을 수행하고, 그 다음에 논리 추 리도를 생성하고, 논리 추리도 중의 각 2층 서브도를 획득하고, 그 다음에 각 2층 서브도가 입도인, 즉 최소 논 리 추리 단계를 평가함으로써, 생성식 대규모 모델의 논리 추리가 정확한지 여부를 결정하는 난이도를 대폭 줄 일 수 있고, 즉 생성식 대규모 모델의 평가 난이도를 효과적으로 줄일 수 있으며, 나아가 생성식 대규모 모델의 평가 효과를 대폭 향상시킨다. 또한, 본 개시의 실시예의 상술한 모델 생성 결과 처리 방법은 자연 언어를 사용하여 전체 추리 과정을 나타내 어, 범용성이 더 높고, 더 많은 유형의 문제에 적용될 수 있다. 또한, 본 개시의 실시예의 상술한 모델 생성 결과 처리 방법은 논리 추리도를 생성하는 것을 통해 전체적인 논 리 추리의 논리 추리 과정을 나타내고, 텍스트 생성 결과의 논리 추리 오류를 효과적으로 검출할 뿐만 아니라, 논리 추리의 결실, 논리 추리의 전도(inversion) 상황을 검출할 수도 있어, 데이터 논리 복구에 사용될 수 있다. 또한, 본 개시의 실시예의 상술한 모델 생성 결과 처리 방법은 생성식 대규모 모델의 논리 추리가 정확한지 여 부를 정확하게 결정할 수 있고, 나아가 생성식 대규모 모델의 평가를 자동적으로 구현할 수 있어, 시간과 힘을 줄이고, 평가 속도를 효과적으로 단축하며 평가 효율을 효과적으로 향상시킬 수 있다. 또한, 논리 추리도를 생 성하는 방식을 통해 평가하고, 최소 논리 유닛 즉 논리 추리도 중의 각 2층 서브도의 논리 추리를 평가하는 방 식을 통해 생성식 대규모 모델의 논리 추리가 적확한지 여부의 정확도를 더욱 효과적으로 향상시키고, 나아가 생성식 대규모 모델 평가의 정확도를 효과적으로 향상시키고, 평가 효율을 향상시킬 수 있다. 상술한 본 개시의 실시예에서 텍스트 처리 분야에 응용되는 것을 예로 하고, 실제 응용에서, 본 개시의 기술 방 안은, 음성 처리 분야에 응용될 수도 있다. 예를 들면, 우선, 음성 정보를 수집하고, 음성 인식을 통해, 대응하 는 텍스트 정보를 획득할 수 있다. 그 다음에, 텍스트 정보에 기반하여, 본 개시의 상술한 기술 방안을 사용하 여 모델의 생성 결과를 처리하는 것을 구현하고, 나아가 생성식 대규모 모델의 논리 추리가 정확한지 여부를 정 확하게 결정하는 것을 효율적이고 정확하게 구현하며, 최종적으로 생성식 대규모 모델을 정확하고 효과적으로 평가하는 것을 구현할 수 있다. 도 7은 본 개시의 제4 실시예에 따른 개략도이다. 도 7에 도시된 바와 같이, 본 실시예는 모델 생성 결과 처리 장치를 제공하고, 텍스트 처리 분야에 적용되고, 분해 모듈, 생성 모듈 및 평가 모듈을 포 함하고, 분해 모듈은 생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의 결과 논리 유닛을 획득하는데 사 용되고, 각 결과 논리 유닛은 상기 텍스트 생성 결과 중의 프래그먼트를 포함하고, 각 상기 프래그먼트는 상기 텍스트 생성 결과의 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있고, 상기 텍스트 생 성 결과는 상기 생성식 대규모 모델이 텍스트 입력 정보에 기반하여 생성된 응답 결과이고, 생성 모듈은 상기 복수의 결과 논리 유닛에 기반하여 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계 를 표시할 수 있는 논리 추리도를 생성하는데 사용되고, 평가 모듈은 상기 논리 추리도에 기반하여 상기 생성식 대규모 모델이 상기 텍스트 생성 결과를 생성하는 논리 추리의 정확한지 여부를 평가하는데 사용된다. 본 실시예의 모델 생성 결과 처리 장치는 상술 모듈을 사용하여 모델 생성 결과 처리의 구현 원리 및 기술 적 효과를 구현하고, 상술한 관련 방법의 실시예의 구현과 같으며, 상세한 것은 상술한 관련 방법의 실시예의 기재를 참조할 수 있고, 여기서는 설명을 생략한다. 도 8은 본 개시의 제5 실시예에 따른 개략도이다. 도 8에 도시된 바와 같이, 본 실시예는 모델 생성 결과 처리 장치를 제공하고, 상술한 도 7에 도시된 것과 동일한 이름 및 동일한 기능 모듈: 분해 모듈, 생성 모 듈, 및 평가 모듈을 포함한다. 본 실시예의 모델 생성 결과 처리 장치에서, 분해 모듈은, 사전 트레이닝된 논리 분해 모델을 사용하여, 상기 생성식 대규모 모델의 텍스트 생성 결과를 분해하여, 복수의 결과 논리 유닛을 획득하는데 사용된다. 나아가 선택적으로, 본 개시의 한 실시예에서 생성 모듈은, 상기 복수의 결과 논리 유닛에 기반하여, 사전 트레이닝된 논리 추리도 생성 모델을 사용하여 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 논리 추리도를 생성하는데 사용된다. 나아가 선택적으로, 본 개시의 일 실시예에서 분해 모듈은 또한, 생성식 대규모 모델의 텍스트 입력 정보를 분해하여, 복수의 입력 논리 유닛을 획득하는데 사용되고, 각 상기 입력 논리 유닛은 상기 텍스트 입력 정보 중의 프래그먼트를 포함하고, 각 상기 프래그먼트는 논리 추리 관계 중의 하나의 전제 또는 결론을 독립적으로 표기할 수 있다. 나아가 선택적으로, 본 개시의 한 실시예에서 생성 모듈은, 상기 복수의 결과 논리 유닛에 기반하여, 상기 복수의 입력 논리 유닛을 참조하여, 상기 복수의 결과 논리 유닛 사이의 논리 추리 관계를 표시할 수 있는 상기 논리 추리도를 생성하는데 사용된다. 나아가 선택적으로, 본 개시의 한 실시예에서 생성 모듈은, 상기 복수의 입력 논리 유닛과 상기 복수의 결과 논리 유닛에 기반하여, 미리 설정된 샘플 데이터베이스에서, 관련성이 가장 높은 샘플을 검색하고, 상기 샘플 데이터베이스는 복수 그룹의 샘플을 포함하고, 각 상기 샘플은 입력 샘플 정보에 대응하는 복수의 입력 샘플 논리 유닛, 결과 샘플 정보에 대응하는 복수의 결과 샘플 논리 유 닛 및 복수의 결과 샘플 논리 유닛에 대응하는 샘플 논리 추리도를 포함하고, 상기 복수의 입력 논리 유닛, 상기 복수의 결과 논리 유닛, 상기 복수의 입력 샘플 논리 유닛, 상기 복수의 결 과 샘플 논리 유닛 및 상기 대응하는 상기 샘플 논리 추리도에 기반하여, 사전 트레이닝된 기타 생성식 대규모 모델을 사용하여 상기 복수의 결과 논리 유닛에 대응하는 상기 논리 추리도를 생성하는데 사용된다. 나아가 선택적으로, 도8에 도시된 바와 같이, 본 개시의 일 실시예에서 평가 모듈은 분해 유닛, 판 정 유닛 및 결정 유닛을 포함하고, 분해 유닛은 상기 논리 추리도를 복수의 2층 서브도로 분해하는데 사용되고, 각 상기 2층 서브도는 하나 의 논리 추리 단계를 표기하고, 판정 유닛은 각 상기 2층 서브도의 논리 추리가 정확한지 여부를 판정하는데 사용되고, 결정 유닛은 상기 복수의 2층 서브도의 논리 추리가 모두 정확한 것에 응답하여, 상기 생성식 대규모 모 델이 상기 텍스트 생성 결과를 생성하는 논리 추리가 정확하다고 결정하는데 사용된다. 본 실시예의 모델 생성 결과 처리 장치는 상술 모듈을 사용하여 모델 생성 결과 처리의 구현 원리 및 기술 적 효과를 구현하고, 상술한 관련 방법의 실시예의 구현과 같으며, 상세한 것은 상술한 관련 방법의 실시예의 기재를 참조할 수 있고, 여기서는 설명을 생략한다. 본 개시의 기술 방안에 따르면, 관련된 사용자 개인 정보의 획득, 저장, 응용 등은 모두 관련된 법률 법규의 규 정에 부합하고, 또한 공서 양속을 위반하지 않는다. 본 개시의 실시예에 따르면, 본 개시는 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램 제품을 더 제공한 다. 도 9에 도시된 바와 같이, 본 발명의 실시예를 구현할 수 있는 예시적인 전자 기기의 개략적인 블록도이다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 운영 플랫폼, 서버, 블레이드 서버, 대형 컴퓨터, 및 다른 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 의미한다. 전자 기기는 개인 디지털 처리, 셀룰러폰, 스마트폰, 웨어러블 기기 및 다른 유사한 계산 장치와 같은 다양한 형태의 이동 장치를 의미할 수도 있다. 본문에서 나타낸 부재, 이들의 연결과 관계, 및 이들의 기능은 단지 예시적인 것으로, 본문에서 설명 및/또는 요구된 본 발명의 구현을 한정하지 않는다. 도 9에 도시된 바와 같이, 기기는 컴퓨팅 유닛을 포함하고, 컴퓨팅 유닛은 판독 전용 메모리 (ROM)에 저장되어 있는 컴퓨터 프로그램 또는 저장 유닛로부터 랜덤 액세스 메모리(RAM) 에 로 드된 컴퓨터 프로그램에 따라, 다양한 적절한 동작과 처리를 실행할 수 있다. RAM에는 기기가 동작하 는데 필요한 여러가지 프로그램과 데이터도 저장할 수 있다. 컴퓨팅 유닛, ROM 및 RAM는 버스 를 통해 서로 연결된다. 입력/출력 (I/O)인터페이스도 버스에 연결된다. 기기 중의 복수 컴포넌트는 I/O인터페이스에 연결되고, 키보드, 마우스 등과 같은 입력 유닛; 여러가지 타입의 디스플레이, 스피커 등과 같은 출력 유닛; 디스크, 광디스크 등과 같은 저장 유닛 및 네트워크 카드, 모뎀, 무선통신 트랜시버 등과 같은 통신 유닛을 포함한다. 통신 유닛은 기기 가 인터넷 등과 같은 컴퓨터 네트워크 및 여러가지 통신 네트워크 중의 적어도 하나를 통해 다른 기기와 정보/데이터를 교환할 수 있다. 컴퓨팅 유닛은 여러가지 처리와 계산 능력을 갖춘 범용 처리 컴포넌트 및 전용 처리 컴포넌트 중의 적어도 하나일 수 있다. 컴퓨팅 유닛의 일부 예는, 중앙 처리 유닛 (CPU), 그래픽스 처리 유닛(GPU), 다양한 전용 인공지능(AI)계산 팁, 다양한 기계학습 모델 알고리즘을 실행하는 컴퓨팅 유닛, 디지털 신호 프로세서(DSP) 및 임의의 적절한 프로세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만, 이에 한정되지 않는다. 컴퓨팅 유닛 은 본 발명에 기재된 방법 등과 같은 상기의 다양한 방법과 처리를 실행한다. 예를 들면, 일부 실시예에서, 본 발명에 기재된 방법은 저장 유닛 등과 같은 기계 판독 가능 매체에 유형적으로 포함되는 컴퓨터 소프트웨어 프로그램으로 구현할 수 있다. 예를 들어, 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM및 통신 유닛 중의 적어도 하나를 통해 기기에 로드 및/또는 인스톨될 수 있다. 컴퓨 터 프로그램이 RAM에 로드되어 컴퓨팅 유닛에 의해 실행될 경우, 본 발명에 기재된 방법의 하나 또는 복수의 단계를 실행할 수 있다. 대안적으로, 다른 실시예에서, 컴퓨팅 유닛은 다른 임의의 적절한 방식(예 를 들면, 펌웨어에 의해)을 통해 본 발명에 기재된 방법을 실행하도록 구성될 수 있다. 설명된 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로그래밍 가 능한 게이트 어레이(FPGA), 특정 용도 대상 집적 회로(ASIC), 특정 용도 대상 표준제품(ASSP), 시스템 온 칩 시 스템(SOC), 부하 프로 그래 밍 가능 논리 장치(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 결합에서 구현될 수 있다. 이러한 다양한 실시형태는 하나 또는 다수의 컴퓨터 프로그램에서의 구현을 포함할 수 있고, 상기 하나 또는 다수의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그 램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 전용 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력 장치, 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신할 수 있으며, 데이터 및 명령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치, 및 상기 적 어도 하나의 출력 장치에 전송할 수 있다. 본 발명의 방법을 실시하기 위한 프로그램 코드는 하나 또는 복수의 프로그래밍 언어의 임의의 결합을 사용하여 작성할 수 있다. 이러한 프로그램 코드는 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 때 흐름도 및 블록도 중의 적어도 하나에 규정된 기능/동작이 실행되도록, 대형 기계(슈퍼 컴퓨터), 전용 컴퓨터 또는 다른 프로그램 가능한 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공할 수 있다. 프로그램 코드는 완전히 기계 에서 실행되거나, 부분적으로 기계에서 실행되거나, 독립된 소프트웨어 패키지로서 부분적으로 기계에서 실행되 고, 부분적으로 리모트 기계에서 실행되거나 또는 완전히 리모트 기계 또는 서버에서 실행될 수 있다. 본 발명의 문맥에서, 기계 판독 가능 매체는 명령 실행 시스템, 장치 또는 기기의 사용, 또는 명령 실행 시스템, 장치 또는 기기와 결합하여 사용되는 프로그램을 포함하거나 저장할 수 있는 유형적인 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 기록 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선, 또는 반도체 시스템, 장치 또는 기기, 또는 상술한 내용의 임의의 적절한 결합을 포함하지만, 이에 한정되지 않는다. 기계 판독 가능 기록 매체의 더 구체적인 예는 하나 또는 복 수의 와이어에 기반한 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 판독 전용 메 모리(ROM), 소거 가능 프로그래머블 판독 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, 포터블 컴팩트 디스 크 판독 전용 메모리(CD-ROM), 광학 저장 장치, 자기 저장 장치 또는 상술한 내용의 임의의 적절한 결합을 포함 한다. 사용자와의 인터랙션을 제공하기 위하여, 컴퓨터에서 여기서 설명된 시스템 및 기술을 실시할 수 있고, 상기 컴 퓨터는 사용자에게 정보를 표시하기 위한 표시 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 표시 장치) 모니터); 및 키보드 및 지향 장치(예를 들어, 마우스 또는 트랙 볼)를 구비하며, 사용자는 상기 키보드 및 상기 지 향 장치를 통해 컴퓨터에 입력을 제공한다. 다른 타입의 장치는 또한 사용자와의 인터랙션을 제공할 수 있는데, 예를 들어, 사용자에게 제공된 피드백은 임의의 형태의 감지 피드백(예를 들어, 시각적 피드백, 청각 피드백, 또는 촉각 피드백)일 수 있고; 임의의 형태(소리 입력, 음성 입력, 또는 촉각 입력)로 사용자로부터의 입력을 수신할 수 있다. 여기서 설명된 시스템 및 기술은 백엔드 부재를 포함하는 계산 시스템(예를 들어, 데이터 서버로 사용됨), 또는 미들웨어 부재를 포함하는 계산 시스템(예를 들어, 애플리케이션 서버), 또는 프론트 엔드 부재를 포함하는 계 산 시스템(예를 들어, 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 구비하는 사용자 컴퓨터인 바, 사용 자는 상기 그래픽 사용자 인터페이스 또는 상기 네트워크 브라우저를 통해 여기서 설명된 시스템 및 기술의 실 시형태와 인터랙션할 수 있음), 또는 이러한 백엔드 부재, 미들웨어 부재, 또는 프론트 엔드 부재의 임의의 결 합을 포함하는 계산 시스템에서 구현될 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 시스템의 부재를 서로 연결시킬 수 있다. 통신 네트워크의 예는, 근거리 통신망(LAN), 광역망 (WAN), 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고 일반적으로 통신 네트워크를 통해 서로 인터랙션한다. 대응되는 컴퓨터에서 실행되고 또한 서로 클라이언트- 서버 관계를 가지는 컴퓨터 프로그램을 통해 클라이언트 및 서버의 관계를 생성한다. 서버는 클라우드 서버일 수 있고, 분산 시스템의 서버일 수 있거나, 또는 블록 체인을 결합한 서버일 수도 있다. 위에서 설명된 다양한 형태의 프로세스를 사용하여 단계를 재배열, 추가 또는 삭제할 수 있음을 이해해야 한다. 예를 들어, 본 발명에 기재된 각 단계는 동시에, 순차적으로, 또는 상이한 순서로 수행될 수 있으며, 본 발명에 개시된 기술적 해결수단이 이루고자 하는 결과를 구현할 수 있는 한, 본문은 여기서 한정되지 않는다."}
{"patent_id": "10-2024-0108349", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 구체적인 실시형태는 본 출원의 보호 범위를 한정하지 않는다. 본 기술분야의 통상의 기술자는, 설계 요구 및 다른 요소에 따라 다양한 수정, 조합, 서브 조합 및 대체를 진행할 수 있음을 이해해야 한다. 본 출원의 정 신 및 원칙 내에서 이루어진 임의의 수정, 등가 교체 및 개선 등은 모두 본 출원의 보호 범위 내에 포함되어야 한다."}
{"patent_id": "10-2024-0108349", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부 도면은 본 해결수단을 더 잘 이해하기 위한 것으로, 본 발명에 대해 한정하는 것으로 구성되지 않는다. 도 1은 본 개시의 제1 실시예에 따른 개략도이다. 도 2는 본 개시의 제2 실시예에 따른 개략도이다. 도 3은 본 개시에서 제공되는 논리 추리도이다. 도 4는 본 개시의 제3 실시예에 따른 개략도이다. 도 5는 본 실시예에 의해 생성되는 논리 추리도의 개략도이다. 도 6a, 도 6b 및 도 6c는 각각 도 5에 도시된 논리 추리도 분할의 2층 서브도이다. 도 7은 본 개시의 제4 실시예의 개략도이다. 도 8은 본 개시의 제5 실시예의 개략도이다. 도 9는 본 개시의 실시예 방법을 구현하기 위한 전자 기기의 블록도이다."}
