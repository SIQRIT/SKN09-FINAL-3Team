{"patent_id": "10-2023-0135269", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0170358", "출원번호": "10-2023-0135269", "발명의 명칭": "기계학습 모델 연산 제어 방법 및 시스템", "출원인": "리벨리온 주식회사", "발명자": "강민후"}}
{"patent_id": "10-2023-0135269", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서에 의해서 수행되는, 기계학습 모델에 대한 연산 제어 방법에 있어서,연산 스킵을 위한 임계값을 결정하는 단계;기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 액티베이션(activation) 값을 획득하는 단계;상기 액티베이션 값이 상기 임계값 미만인지 여부를 판정하는 단계; 및상기 액티베이션 값이 상기 임계값 미만인 경우, 상기 기계학습 모델에서 상기 액티베이션 값과 연관된 연산이생략되도록 상기 기계학습 모델에 대한 연산을 제어하는 단계를 포함하는, 연산 제어 방법."}
{"patent_id": "10-2023-0135269", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 적어도 하나의 프로세서에 의해서 수행되는 기계학습 모델에 대한 연산 제어 방법이 개시된다. 이 방 법은 연산 스킵을 위한 임계값을 결정하는 단계, 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 액티베 이션 값을 획득하는 단계, 액티베이션 값이 임계값 미만인지 여부를 판정하는 단계 및 액티베이션 값이 임계값 미만인 경우, 기계학습 모델에서 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산을 제어 하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0135269", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 기계학습에 대한 연산 제어 방법에 관한 것으로, 구체적으로 연산 결과에 영향을 미치지 않을 액티베 이션(activation) 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산을 제어하는 방법 및 시스템에 관 한 것이다."}
{"patent_id": "10-2023-0135269", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능을 구현하기 위한 기계학습 모델은 인공신경망(artificial neural network)을 포함하여 구성될 수 있다. 인공신경망은 복수의 레이어를 포함할 수 있고, 복수의 레이어의 각각에는 적어도 하나의 노드가 포함될 수 있다. 또한, 노드는 가중치와 관련될 수 있고, 인공신경망의 학습이 반복되어 수행될수록 가중치가 일정한 값으로 수렴될 수 있다. 그런데 인공신경망이 복잡하거나 입력 데이터의 개수가 많아질수록, 최종 결과를 출력되기까지 요구되는 하드웨 어 리소스가 증가되고, 더불어 지연시간이 증가될 수 있다. 이에 따라, 인공신경망으로 투입되는 컴퓨팅 자원 을 절감하고, 더불어 연산 결과를 빠르게 출력할 수 있는 기계학습 모델에 대한 요구가 발생하고 있다."}
{"patent_id": "10-2023-0135269", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상기와 같은 문제점을 해결하기 위한 기계학습 모델 연산 제어 방법, 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램, 컴퓨터 판독 가능한 기록 매체 및 장치(시스템)를 제공한다."}
{"patent_id": "10-2023-0135269", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 방법, 장치(시스템) 및/또는 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램을 포함한 다양한 방식으로 구현될 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서에 의해서 수행되는, 기계학습 모델에 대한 연산 제어 방법은, 연산 스킵을 위한 임계값을 결정하는 단계, 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 액 티베이션 값을 획득하는 단계, 액티베이션 값이 임계값 미만인지 여부를 판정하는 단계 및 액티베이션 값이 임 계값 미만인 경우, 기계학습 모델에서 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산을 제어하는 단계를 포함할 수 있다. 또한, 임계값을 결정하는 단계는, 적어도 하나의 레이어와 연관된 복수의 액티베이션 값의 분포에 기초하여, 임 계값을 결정하는 단계를 포함할 수 있다. 또한, 임계값을 결정하는 단계는, 적어도 하나의 레이어와 연관된 복수의 액티베이션 값 중, 비교 대상이 되는 타깃 액티베이션 값을 획득하는 단계 및 획득된 타깃 액티베이션 값이 임계값 미만이면, 임계값이 미리 결정된 크기만큼 증가되도록 임계값을 갱신하는 단계를 포함할 수 있다. 또한, 임계값을 결정하는 단계는, 임계값이 변동되지 않은 시간을 측정하는 단계 및 측정된 시간이 미리 결정된 임계시간에 도달하면, 임계값이 미리 결정된 크기만큼 감소되도록 임계값을 갱신하는 단계를 포함할 수 있다. 또한, 액티베이션 값을 획득하는 단계는, 기계학습 모델에 포함된 제1 레이어로부터 출력된 액티베이션 값을 획 득하는 단계를 포함하고, 기계학습 모델에 대한 연산을 제어하는 단계는, 액티베이션 값이 임계값 미만인 경우, 액티베이션 값을 영(zero)으로 결정하여 메모리에 저장하는 단계를 포함할 수 있다. 또한, 기계학습 모델에 대한 연산을 제어하는 단계는, 제1 레이어로부터의 출력 값이 입력되는 제2 레이어와 연 관된 연산이 수행되는 경우, 영으로 결정된 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델의 연산을 제어하는 단계를 포함할 수 있다. 또한, 액티베이션 값을 획득하는 단계는, 액티베이션 값을 메모리로부터 획득하는 단계를 포함하고, 액티베이션 값은 기계학습 모델에 포함된 제1 레이어로부터의 출력 값을 포함할 수 있다. 또한, 기계학습 모델에 대한 연 산을 제어하는 단계는, 제1 레이어로부터의 출력 값이 입력되는 제2 레이어와 연관된 연산이 수행되고, 제1 레 이어로부터의 출력 값이 임계값 미만인 경우, 제2 레이어에서 제1 레이어로부터의 출력 값과 연관된 연산이 생 략되도록 기계학습 모델의 연산을 제어하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서에 의해서 수행되는 기계학습 모델에 대한 연산 제어 방 법은, 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 액티베이션 값을 획득하는 단계 - 액티베이션 값 은 미리 정해진 포맷의 부동소수점으로 표현됨 -, 부동소수점으로 표현된 액티베이션 값 중에서 지수를 획득하 는 단계, 획득된 지수가 임계값 미만인지 여부를 판정하는 단계 및 획득된 지수가 임계값 미만인 경우, 기계학 습 모델에서 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산을 제어하는 단계를 포함할 수 있다. 또한, 임계값은 2를 미리 정해진 횟수로 거듭하여 곱한 값일 수 있다. 또한, 액티베이션 값과 임계값의 각각은 2진수일 수 있다. 또한, 연산 제어 방법은, 액티베이션 값을 획득하는 단계 이전에, 적어도 하나의 레이어와 연관된 복수의 액티 베이션 값의 분포에 기초하여, 임계값을 결정하는 단계를 더 포함할 수 있다. 또한, 임계값을 결정하는 단계는, 적어도 하나의 레이어와 연관된 복수의 액티베이션 값 중, 비교 대상이 되는 타깃 액티베이션 값을 결정하는 단계, 결정된 타깃 액티베이션 값으로부터 타깃 지수를 획득하는 단계 및 획득 된 타깃 지수가 임계값 미만이면, 임계값이 미리 결정된 크기만큼 증가되도록 임계값을 갱신하는 단계를 포함할 수 있다. 또한, 임계값을 갱신하는 단계는, 임계값에 2를 곱하여 임계값을 증가시키는 단계를 포함할 수 있다. 또한, 임계값을 결정하는 단계는, 임계값이 변동되지 않은 시간을 측정하는 단계 및 측정된 시간이 미리 결정된 임계시간에 도달하면, 임계값이 미리 결정된 크기만큼 감소되도록 임계값을 갱신하는 단계를 포함할 수 있다. 또한, 임계값을 갱신하는 단계는, 임계값에 2를 나누어 임계값을 갱신하는 단계를 포함할 수 있다. 또한, 액티베이션 값을 획득하는 단계는, 기계학습 모델에 포함된 제1 레이어로부터 출력된 액티베이션 값을 획 득하는 단계를 포함하고, 기계학습 모델에 대한 연산을 제어하는 단계는, 획득된 지수가 임계값 미만인 경우, 액티베이션 값을 영(zero)으로 결정하여 메모리에 저장하는 단계를 포함할 수 있다. 또한, 기계학습 모델에 대한 연산을 제어하는 단계는, 제1 레이어로부터의 출력 값이 입력되는 제2 레이어와 연 관된 연산이 수행되는 경우, 영으로 결정된 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델의 연산을 제어하는 단계를 포함할 수 있다. 또한, 액티베이션 값을 획득하는 단계는, 액티베이션 값을 메모리로부터 획득하는 단계를 포함하고, 액티베이션 값은 기계학습 모델에 포함된 제1 레이어로부터의 출력 값을 포함하고, 기계학습 모델에 대한 연산을 제어하는 단계는, 제1 레이어로부터의 출력 값이 입력되는 제2 레이어와 연관된 연산이 수행되고, 제1 레이어로부터의 출력 값 중 지수가 임계값 미만인 경우, 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델의 연산을 제어 하는 단계를 포함할 수 있다. 상술된 연산 제어 방법을 컴퓨터에서 실행하기 위해 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램이 제공될 수 있다. 본 개시의 일 실시예에 따른 프로세싱 시스템은 하나 이상의 인스트럭션을 저장하는 메모리 및 메모리의 하나 이상의 인스트럭션을 실행함으로써, 연산 스킵을 위한 임계값을 결정하고, 기계학습 모델에 포함된 적어도 하나 의 레이어와 연관된 액티베이션 값을 획득하고, 액티베이션 값이 임계값 미만인지 여부를 판정하고, 액티베이션 값이 임계값 미만인 경우, 기계학습 모델에서 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산을 제어하도록 구성된 프로세서를 포함할 수 있다."}
{"patent_id": "10-2023-0135269", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일부 실시예에 따르면, 연산 결과에 영향을 미치지 않을 액티베이션(activation) 값이 결정되고, 결 정된 액티베이션 값과 연관된 연산이 기계학습 모델에서 생략되도록 기계학습 모델에 대한 연산이 제어될 수 있 다. 이에 따라, 기계학습 모델의 동작시키기 위해서 투입되는 컴퓨팅 자원이 절감될 수 있고, 더불어 기계학습 모델로부터 연산 결과가 출력되기까지의 시간이 단축될 수 있다. 본 개시의 일부 실시예에 따르면, 기계학습 모델을 구성하는 적어도 하나의 레이어에 분포된 액티베이션 값에 기초하여, 연산 스킵(skip)을 위한 임계값이 동적으로 결정될 수 있다. 이에 따라, 기계학습 모델의 운영 환경 에 기초하여 적응적으로 임계값이 결정되고, 스킵 대상이 되는 액티베이션 값의 범위가 유연하게 결정될 수 있 다. 본 개시의 일부 실시예에 따르면, 하드웨어에 친화적인 부동소수점으로 액티베이션 값이 표현되고, 액티베이션 값에 포함된 지수(exponent)와 임계값이 비교되어 스킵 대상이 되는 액티베이션 값이 더욱 빠르게 결정될 수 있 다. 본 개시의 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 다른 효과들은 청구범위의 기재로부"}
{"patent_id": "10-2023-0135269", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자('통상의 기술자'라 함)에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0135269", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 실시를 위한 구체적인 내용을 첨부된 도면을 참조하여 상세히 설명한다. 다만, 이하의 설명에 서는 본 개시의 요지를 불필요하게 흐릴 우려가 있는 경우, 널리 알려진 기능이나 구성에 관한 구체적 설명은 생략하기로 한다. 첨부된 도면에서, 동일하거나 대응하는 구성요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예 들의 설명에 있어서, 동일하거나 대응되는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나, 구성 요소에 관한 기술이 생략되어도, 그러한 구성요소가 어떤 실시예에 포함되지 않는 것으로 의도되지는 않는다. 개시된 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예 들을 참조하면 명확해질 것이다. 그러나, 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 통상의 기술 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시예에 대해 구체적으로 설명하기로 한다. 본 명세서에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서, 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어 가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 또한, 복수의 표현은 문맥상 명백하게 복수인 것으로 특정하지 않는 한, 단수의 표현을 포함한다. 명세서 전체 에서 어떤 부분이 어떤 구성요소를 포함한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 '모듈' 또는 '부'라는 용어는 소프트웨어 또는 하드웨어 구성요소를 의미하며, '모 듈' 또는 '부'는 어떤 역할들을 수행한다. 그렇지만, '모듈' 또는 '부'는 소프트웨어 또는 하드웨어에 한정되 는 의미는 아니다. '모듈' 또는 '부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서, '모듈' 또는 '부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이 크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 또는 변수들 중 적어도 하나를 포 함할 수 있다. 구성요소들과 '모듈' 또는 '부'들은 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '모듈' 또는 '부'들로 결합되거나 추가적인 구성요소들과 '모듈' 또는 '부'들로 더 분리될 수 있다. 본 개시의 일 실시예에 따르면, '모듈' 또는 '부'는 프로세서 및 메모리로 구현될 수 있고, 회로(circuit, circuitry)로 구현될 수 있다. '회로(circuit, circuitry)'와 같은 용어는 하드웨어 상의 회로를 의미하기도 하지만 소프트웨어 상의 회로를 의미할 수도 있다. '프로세서'는 범용 프로세서, 중앙 처리 장치(CPU), 마이크 로프로세서, 디지털 신호 프로세서(DSP), 제어기, 마이크로제어기, 상태 머신 등을 포함하도록 넓게 해석되어야 한다. 몇몇 환경에서, '프로세서'는 주문형 반도체(ASIC), 프로그램가능 로직 디바이스(PLD), 필드 프로그램가 능 게이트 어레이(FPGA) 등을 지칭할 수도 있다. '프로세서'는, 예를 들어, DSP와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, DSP 코어와 결합한 하나 이상의 마이크로프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디바이스들의 조합을 지칭할 수도 있다. 또한, '메모리'는 전자 정보 를 저장 가능한 임의의 전자 컴포넌트를 포함하도록 넓게 해석되어야 한다. '메모리'는 임의 액세스 메모리 (RAM), 판독-전용 메모리(ROM), 비-휘발성 임의 액세스 메모리(NVRAM), 프로그램가능 판독-전용 메모리(PROM), 소거-프로그램가능 판독 전용 메모리(EPROM), 전기적으로 소거가능 PROM(EEPROM), 플래쉬 메모리, 자기 또는 마 킹 데이터 저장장치, 레지스터들 등과 같은 프로세서-판독가능 매체의 다양한 유형들을 지칭할 수도 있다. 프 로세서가 메모리로부터 정보를 판독하고/하거나 메모리에 정보를 기록할 수 있다면 메모리는 프로세서와 전자통신 상태에 있다고 불린다. 프로세서에 집적된 메모리는 프로세서와 전자 통신 상태에 있다. 본 개시에서, '복수의 A의 각각' 또는 '복수의 A 각각'은 복수의 A에 포함된 모든 구성 요소의 각각을 지칭하거 나, 복수의 A에 포함된 일부 구성 요소의 각각을 지칭할 수 있다. 또한, 이하의 실시예들에서 사용되는 제1, 제2, A, B, (a), (b) 등의 용어는 어떤 구성요소를 다른 구성요소와 구별하기 위해 사용되는 것일 뿐, 그 용어에 의해 해당 구성요소의 본질이나 차례 또는 순서 등이 한정되지는 않는다. 또한, 이하의 실시예들에서, 어떤 구성요소가 다른 구성요소에 '연결', '결합' 또는 '접속'된다고 기재된 경우, 그 구성요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성요소 사이에 또 다른 구성요소가 '연결', '결합' 또는 '접속'될 수도 있다고 이해되어야 한다. 또한, 이하의 실시예들에서 사용되는 '포함한다(comprises)' 및/또는 '포함하는(comprising)'은 언급된 구성요 소, 단계, 동작 및/또는 소자는 하나 이상의 다른 구성요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제 하지 않는다. 또한, 이하의 실시예들에서, '미만인지 여부를 판정' 또는 '미만인 경우' 등을 개시하고 있으나, '이하인지 여 부를 판정' 또는 '이하인 경우' 등도 해당 실시예들에 적용될 수 있다. 본 개시의 다양한 실시예들을 설명하기에 앞서, 사용되는 용어에 대하여 설명하기로 하기로 한다. 본 개시에서, '기계학습 모델'은 주어진 입력에 대한 해답(answer)을 추론하는데 사용하는 임의의 모델을 포함 할 수 있다. 일 실시예에 따르면, 기계학습 모델은 입력 레이어(층), 복수 개의 은닉 레이어 및 출력 레이어를 포함한 인공신경망 모델을 포함할 수 있다. 여기서, 각 레이어는 복수의 노드를 포함할 수 있다. 또한, 본 개 시에서, 기계학습 모델은 인공신경망 모델을 지칭할 수 있으며, 인공신경망 모델은 기계학습 모델을 지칭할 수 있다. 본 개시의 실시예에서, '액티베이션(activation) 값'은 기계학습 모델을 구성하는 적어도 하나의 레이어와 연관 된 연산 결과 및/또는 연산을 위한 입력 값일 수 있다. 여기서, 적어도 하나의 레이어는 액티베이션 함수와 연 관될 수 있다. 예컨대, 액티베이션 값은 레이어에 포함된 적어도 하나의 노드와 연관된 연산 결과일 수 있다. 액티베이션이 '인풋 액티베이션(input activation)' 및/또는 '아웃풋 액티베이션(output activation)과 연관될 수 있다. 여기서, 인풋 액티베이션은 기계학습 모델을 구성하는 적어도 하나의 레이어로 데이터가 입력되는 것 과 관련되고, 아웃풋 액티베이션은 기계학습 모델을 구성하는 적어도 하나의 레이어로부터 데이터가 출력된 것 과 관련될 수 있다. 하나의 액티베이션은 제1 레이어에 대해서는 아웃풋 액티베이션이 될 수 있고, 제2 레이어 에 대해서는 인풋 액티베이션이 될 수 있다. 본 개시에서, '인스트럭션(instruction)'은 기능을 기준으로 묶인 일련의 컴퓨터 판독가능 명령어들로서 컴퓨터 프로그램의 구성요소이자 프로세서에 의해 실행되는 것을 지칭할 수 있다. 도 1은 본 개시의 일 실시예에 따른, 뉴럴 프로세싱 시스템(NPS)을 설명하기 위한 블록도이다. 도 1을 참조하 면, 본 개시의 몇몇 실시예들에 따른 뉴럴 프로세싱 시스템(NPS)은 뉴럴 프로세싱 장치, 호스트 시스템(HS) 및 호스트 인터페이스(HIO)를 포함할 수 있다. 뉴럴 프로세싱 장치는 인공신경망을 이용하여 연산을 수행하는 장치일 수 있다. 뉴럴 프로세싱 장치는 예를 들어, 딥 러닝(deep learning) 연산 작업을 수행하는 것에 특화된 장치일 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 뉴럴 프로세싱 장치는 뉴럴 프로세싱 장치가 아닌 다른 프로세싱 장치일 수도 있다. 예컨대, 뉴럴 프로세싱 장치는 각각 그래픽 프로세싱 장치(GPU, graphics processing unit), 중앙 처리 장치(CPU, central processing unit) 및 그 외의 다른 종류의 프로세싱 장치일 수도 있다. 호스트 시스템(HS)은 뉴럴 프로세싱 장치에 연산 작업을 지시하고, 연산 작업의 결과를 회수하는 시스템일 수 있다. 호스트 시스템(HS)은 뉴럴 프로세싱 장치에 비해서 딥 러닝 연산 작업에 특화되지 않은 시스템일 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 호스트 인터페이스(HIO)는 뉴럴 프로세싱 장치와 호스트 시스템(HS) 사이에서 데이터 및 컨트롤 신호를 전송 할 수 있다. 호스트 인터페이스(HIO)는 예를 들어, 호스트 시스템(HS)의 커맨드 및 데이터를 뉴럴 프로세싱 장 치로 전달할 수 있고, 이에 따라 뉴럴 프로세싱 장치가 연산 작업을 수행할 수 있다. 뉴럴 프로세싱 장치는 연산 작업을 완료하면 이에 대한 결과를 인터럽트 요청을 통해서 호스트 시스템(HS)으로 전달할 수 있 다. 호스트 인터페이스(HIO)는 예를 들어, PCIe(PCI Express)일 수 있으나, 이에 제한되는 것은 아니다. 도 2는 도 1의 뉴럴 프로세싱 장치를 세부적으로 설명하기 위한 블록도이다. 도 2를 참조하면, 뉴럴 프로세싱 장치는 뉴럴 코어 SoC, 오프 칩 메모리, 비휘발성 메모리 인터페이스 및 휘발성 메모리 인터페 이스를 포함할 수 있다. 뉴럴 코어 SoC는 시스템 온 칩(System on Chip) 장치일 수 있다. 뉴럴 코어 SoC는 인공지능 연산 유닛 으로 가속기(Accelerator)를 포함할 수 있다. 뉴럴 코어 SoC는 예를 들어, GPU(graphics processing unit), FPGA(field programmable gate array) 또는 ASIC(application-specific integrated circuit) 중 적어 도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 뉴럴 코어 SoC는 별도의 외부 인터페이스를 통해서 다른 외부의 연산 유닛들과 데이터를 교환할 수 있다. 또한, 뉴럴 코어 SoC는 비휘발성 메모리 인터페이스 및 휘발성 메모리 인터페이스를 통해서 각각 비휘발성 메모리 및 휘발성 메모리와 연결될 수 있다. 오프 칩 메모리는 뉴럴 코어 SoC의 칩 외부에 배치된 메모리일 수 있다. 오프 칩 메모리는 비휘발 성 메모리 및 휘발성 메모리를 포함할 수 있다. 비휘발성 메모리는 전원이 공급되지 않아도 저장된 정보를 계속 유지하는 메모리일 수 있다. 비휘발성 메 모리는 후술하는 기계학습 모델에 대한 연산을 제어하기 위한 하나 이상의 인스트럭션을 저장할 수 있다. 비휘발성 메모리는 예를 들어, ROM(Read-Only Memory), PROM(Programmable Read-Only Memory), EAROM(Erasable Alterable ROM), EPROM(Erasable Programmable Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory)(예를 들어, 낸드 플래시 메모리(NAND Flash memory), 노어 플래시 메모리(NOR Flash memory)), UVEPROM(Ultra-Violet Erasable Programmable Read-Only Memory), FeRAM(Ferroelectric Random Access Memory), MRAM(Magnetoresistive Random Access Memory), PRAM(Phase- change Random Access Memory), SONOS(silicon-oxide-nitride-oxide-silicon), RRAM(Resistive Random Access Memory), NRAM(Nanotube Random Access Memory), 마그네틱 컴퓨터 기억 장치(예를 들면, 하드 디스크, 디스켓 드라이브, 마그네틱 테이프), 광디스크 드라이브 또는 3D 크로스포인트 메모리(3D XPoint memory) 중 적어도 하 나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 휘발성 메모리는 비휘발성 메모리와 달리, 저장된 정보를 유지하기 위해서 전력을 지속적으로 필요로 하는 메모리일 수 있다. 휘발성 메모리는 예를 들어, DRAM(Dynamic Random Access Memory), SRAM(Static Random Access Memory), SDRAM(Synchronous Dynamic Random Access Memory) 및 DDR SDRAM(Double Data Rate SDRAM) 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 비휘발성 메모리 인터페이스는 예를 들어, PATA(Parallel Advanced Technology Attachment), SCSI(Small Computer System Interface), SAS(Serial Attached SCSI), SATA(Serial Advanced Technology Attachment) 및 PCIe(PCI Express) 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 휘발성 메모리 인터페이스는 예를 들어, SDR(Single Data Rate), DDR(Double Data Rate), QDR(Quad Data Rate), 및 XDR(eXtreme Data Rate, Octal Data Rate) 중 적어도 하나일 수 있다. 단, 본 실시예가 이에 제한 되는 것은 아니다. 일 실시예에 따르면, 뉴럴 코어 SoC는 적어도 하나의 프로세서를 포함할 수 있고, 프로세서는 비휘발성 메 모리 또는 휘발성 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 연산 스킵을 위한 임계값 을 결정하고, 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 액티베이션 값을 획득하고, 액티베이션 값이 임계값 미만인지 여부를 판정하고, 액티베이션 값이 임계값 미만인 경우, 기계학습 모델에서 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산을 제어하도록 구성될 수 있다. 도 3은 본 개시의 일 실시예에 따른, 도 1의 뉴럴 코어 SoC를 세부적으로 설명하기 위한 블록도이다. 도 3 에 도시된 바와 같이, 뉴럴 코어 SoC는 프로세싱 유닛, 메모리, 액티베이션 로드/스토어 유닛 , 온 칩 버퍼 및 로드/스토어 유닛을 포함할 수 있다. 프로세싱 유닛은 기계학습 모델과 연관된 연산을 수행하는 모듈일 수 있다. 프로세싱 유닛은 1차원 연산뿐만 아니라 2차원 매트릭스 연산(예컨대, 컨볼루션 연산 등)을 수행할 수 있다. 프로세싱 유닛은 인 풋 액티베이션(Act_In) 값을 수신하여 가중치와 곱셈한 연산 결과에 기초하여, 아웃풋 액티베이션(Act_Out) 값을 생성할 수 있다. 2차원 매트릭스 연산을 위해, 프로세싱 유닛은 PE(Processing Element) 어레이(array)(미도시)를 포함할 수 있다. PE 어레이는 복수의 프로세싱 엘리먼트(Processing Element)를 포함할 수 있다. 복수의 프로세싱 엘 리먼트의 각각에는 프로세싱 유닛의 자원이 할당된 것으로서, 논리적 또는 물리적으로 구현될 수 있다. 복수의 프로세싱 엘리먼트의 각각은 인공신경망을 구성하는 적어도 하나의 레이어와 관련될 수 있다. 가령, 복 수의 프로세싱 엘리먼트 중에서 제1 프로세싱 엘리먼트 내지 제4 프로세싱 엘리먼트의 각각은 제1 레이어에 포 함된 제1 노드 내지 제4 노드의 각각과 관련될 수 있다. 다른 예로서, 복수의 프로세싱 엘리먼트 중에서 제5 프로세싱 엘리먼트 내지 제8 프로세싱 엘리먼트의 각각은 제2 레이어에 포함된 제5 노드 내지 제8 노드의 각각 과 관련될 수 있다. 복수의 프로세싱 엘리먼트의 각각은, 인풋 액티베이션(Act_In) 값과 가중치(weight)에 대 한 곱셈 연산을 수행할 수 있다. 일 실시예에서, 프로세싱 유닛은 적어도 하나의 프로세싱 엘리먼트로부터 수신된 적어도 하나의 액티베이 션 값에 기초하여, 아웃풋 액티베이션(Act_Out) 값을 출력할 수 있다. 메모리는 프로세싱 유닛으로 인풋 액티베이션(Act_In) 값을 제공하고, 프로세싱 유닛으로부터 아웃풋 액티베이션(Act_Out) 값을 수신하여 저장할 수 있다. 예컨대, 메모리는 인풋 액티베이션(Act_In) 과 아웃풋 액티베이션(Act_Out)의 각각과 연관된 값을 일시적으로 저장할 수 있다. 몇몇 실시예에 따르면, 메 모리는 버퍼 등과 같은 저장수단을 포함할 수 있다. 인풋 액티베이션(Act_In) 및 아웃풋 액티베이션(Act_Out)은 신경망 네트워크의 레이어의 입력과 출력과 관련될 수 있다. 이 경우, 신경망 네트워크의 레이어가 복수인 경우 이전 레이어의 출력값이 다음 레이어의 입력값이 되므로, 이전 레이어의 아웃풋 액티베이션(Act_Out) 값이 다음 레이어의 인풋 액티베이션(Act_In) 값으로 활용 될 수 있다. 액티베이션 로드/스토어 유닛은 온 칩 버퍼로부터 획득된 인풋 액티베이션(Act_In) 값을 메모리(32 0)로 전달하고, 메모리로부터 획득된 아웃풋 액티베이션(Act_Out) 값을 온 칩 버퍼로 전달할 수 있다. 즉, 액티베이션 로드/스토어 유닛은 액티베이션의 로드 작업과 스토어 작업을 모두 수행할 수 있다. 온 칩 버퍼는 뉴럴 코어 SoC 내부에 위치한 저장 수단으로서, 뉴럴 코어 SoC가 작업에 필요한 모 든 입력 데이터를 외부로부터 수신하여 임시로 저장할 수 있다. 또한, 온 칩 버퍼는 뉴럴 코어 SoC에 의해서 연산된 출력 데이터를 외부로 전송하기 위해서 일시적으로 저장할 수 있다. 온 칩 버퍼는 액티베이션 로드/스토어 유닛을 통해, 인풋 액티베이션(Act_In) 값을 메모리로 전 송하고, 아웃풋 액티베이션(Act_Out) 값을 메모리로부터 수신할 수 있다. 온 칩 버퍼는 액티베이션 로드/스토어 유닛 외에도, 프로세싱 유닛과 직접 데이터를 송수신할 수 있다. 로드/스토어 유닛은 외부 인터페이스를 통해서 외부에서 입력 데이터, 프로그램 또는 제어 신호 중 적어도 하나를 수신할 수 있다. 로드/스토어 유닛은 온 칩 버퍼로 수신된 입력 데이터, 프로그램 또는 제어 신호 중 적어도 하나를 전송할 수 있다. 또한, 로드/스토어 유닛은 외부 인터페이스를 통해서 출력 데이 터를 외부로 전달할 수 있다. 로드/스토어 유닛은 프로세싱 유닛이 생성한 출력 데이터를 외부로 전 송할 수 있다. 일 실시예에 따르면, 메모리는 연산량이 많은 프로세싱 유닛으로 액티베이션 값을 빠르게 제공하고, 액티베이션을 빠르게 수신하여 뉴럴 코어 SoC의 연산 속도가 더욱 향상될 수 있다. 일 실시예에 따르면, 메모리에 저장된 액티베이션 값 중에서, 연산 스킵 대상이 되는 액티베이션 값이 결정되고, 결정된 액티베 이션 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산이 제어될 수 있다. 여기서, 액티베이션 값과 연관된 연산이 생략된다는 것은, 엘리먼트 어레이에 포함된 일부의 프로세싱 엘리먼트에서 연산이 생략되는 것 을 의미할 수 있다. 예컨대, 액티베이션 값과 연관된 연산이 생략되는 것은, 관련 프로세싱 엘리먼트에 의해 가중치가 확인되는 프 로세스, 가중치와 액티베이션 값을 곱셈 연산하는 프로세스 등이 생략되는 것을 의미할 수 있다. 추가적으로 또는 대안적으로, 관련 프로세싱 엘리먼트는 스킵 대상이 되는 액티베이션 값에 대한 연산 결과값을 영으로 출 력할 수 있다. 영으로 출력된 연산 결과값은 다른 액티베이션의 출력 결과값과 추가 연산(예컨대, 덧셈 연산"}
{"patent_id": "10-2023-0135269", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "등)되고, 추가 연산된 결과값이 아웃풋 액티베이션 값으로 출력될 수 있다. 연산 스킵 대상을 결정하기 위하여 활성화 함수가 이용될 수 있다. 인공신경망 기술분야에서 활성화 함수로서 ReLU(Rectified Linear Unit) 함수가 이용되고 있다. ReLU는 입력값이 영(zero)보다 크면 입력값을 영으로 출 력하고, 입력값이 영보다 작으면 입력값을 그대로 출력하는 함수이다. 그런데 ReLU 함수는 입력값을 영으로 결 정하기 위해 기준되는 임계값을 영으로 고정하고 있을 뿐, 임계값을 기계학습 모델의 환경에 따라 적응적으로 변화시키지 않고 있다. 이에 따라, ReLU 함수를 이용하는 입력값이 양의 실수인 경우에, 출력값은 영이 되지 않는다. 반면에, 후술하는 바와 같이 본 개시의 다양한 실시예에 따르면, 연산 스킵 대상의 기준이 되는 임계값이 다양 한 값으로 결정될 수 있다. 이에 따라, 액티베이션 값이 양의 실수가 되더라도, 액티베이션 값은 영으로 변경 되어 메모리에 저장될 수 있다. 또한, 연산 스킵을 위한 임계값은. 기계학습 모델에 포함된 적어도 하나의 레 이어와 연관된 복수의 액티베이션 값의 분포에 기초하여, 적응적이고 동적으로 변경될 수 있다. 도 4는 본 개시의 일 실시예에 따른, 도 3의 프로세싱 유닛을 세부적으로 설명하기 위한 블록도이다. 도 4에 예시된 바와 같이, 프로세싱 유닛은 임계값 결정 모듈, 제어 모듈 및 연산 모듈을 포 함할 수 있다. 임계값 결정 모듈은 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 복수의 액티베이션 값의 분포 에 기초하여, 임계값을 동적으로 결정할 수 있다. 여기서, 임계값은 영(zero) 이상의 값일 수 있다. 또한, 임 계값은 하한값과 상한값이 미리 결정될 수 있다. 하한값으로 영이 결정될 수 있으며, 상한값으로서, 0을 초과 하는 임의의 자연수 또는 실수가 결정될 수 있다. 일 실시예에 따르면, 임계값 결정 모듈은 적어도 하나의 레이어와 연관된 복수의 액티베이션 값 중, 비교 대상이 되는 타깃 액티베이션 값을 획득하고, 획득된 타깃 액티베이션 값이 임계값 미만/이하이면, 임계값이 미 리 결정된 크기만큼 증가되도록 임계값을 갱신할 수 있다. 일 실시예에 따르면, 타깃 액티베이션 값의 절대값 과 임계값이 비교되어, 타깃 액티베이션 값이 임계값 미만/이하인지 여부가 판정될 수 있다. 이렇게 절대값이 임계값과 비교되는 경우, -a에서부터 +a까지의 범위(여기서 'a'는 임의의 실수)에 포함된 액티베이션 값이 스킵 대상으로 결정될 수 있다. 본 개시의 실시예에서, 임계값 결정 모듈은 임계값과 액티베이션 값/지수(exponent)을 비교할 때에, 임계 값이 액티베이션 값/지수 이하인지를 판정할 수 있다. 설명의 편의를 위해서, 후술하는 실시예에서, 임계값이 액티베이션 값/지수 미만인지 여부가 판정되는 것으로 설명한다. 또한, 후술하는 실시예에서, 액티베이션 값이 임계값 미만라는 것은, 액티베이션 값이 임계값 미만이거나 액티베이션 값에 대한 절대값이 임계값 미만인 것을 의미할 수 있다. 또 다른 실시예에 따르면, 임계값 결정 모듈은 적어도 하나의 레이어와 연관된 복수의 액티베이션 값 중, 비교 대상이 되는 타깃 액티베이션 값을 획득하고 타깃 액티베이션 값으로부터 지수를 추출한 후, 추출된 지수 가 임계값 미만이면 임계값이 미리 결정된 크기만큼 증가되도록 임계값을 갱신할 수 있다. 몇몇 실시예에 따르 면, 임계값 결정 모듈은 임계값에 2를 곱합으로써, 임계값을 2배수로 증가시킬 수 있다. 일 실시예에 따르면, 임계값 결정 모듈은 임계값이 변동되지 않은 시간을 측정하고, 측정된 시간이 미리 결정된 임계시간에 도달하면, 임계값이 미리 결정된 크기만큼 감소되도록 임계값을 갱신할 수 있다. 몇몇 실시 예에 따르면, 임계값 결정 모듈은 임계값에 2를 나눔으로써, 임계값을 감소시킬 수 있다. 연산 모듈은 기계학습 모델에 의해 구현된 알고리즘과 연관된 연산을 수행할 수 있다. 일 실시예에 따르 면, 연산 모듈은 PE 어레이를 포함할 수 있다. PE 어레이는 복수의 프로세싱 엘리먼트를 포함하고, 복수 의 프로세싱 엘리먼트의 각각은, 인공신경망을 구성하는 적어도 하나의 레이어와 관련될 수 있다. 예를 들어, 복수의 프로세싱 엘리먼트의 각각은, 인풋 액티베이션(Act_In) 값과 가중치에 대한 곱셈 연산을 수행할 수 있다. 일 실시예에서, 연산 모듈은 적어도 하나의 프로세싱 엘리먼트로부터 출력된 적어도 하나의 액티베이션 값 에 기초하여, 아웃풋 액티베이션(Act_Out) 값을 출력할 수 있다. 제어 모듈은 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 액티베이션 값 중에서 스킵 대상이 되는 액티베이션 값을 결정하고, 결정된 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산 을 제어할 수 있다. 일 실시예에 따르면, 제어 모듈은 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 액티베이션 값이 연산 스킵을 위한 임계값(즉, 임계값 결정 모듈에 의해 결정된 임계값) 미만인지 여부를 판정할 수 있다. 일 실시예에 따르면, 제어 모듈은 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 액티베이션 값의 절대값이 임계값 미만이지 여부를 판정함으로써, 스킵 대상이 되는 액티베이션 값을 결 정할 수 있다. 몇몇 실시예에 따르면, 액티베이션 값은 미리 정해진 포맷의 부동소수점으로 표현될 수 있다. 예컨대, 액티베 이션 값은 IEEE(Institute of Electrical and Electronics Engineers)에서 제안하는 FP16 포맷의 부동소수점으 로 표현되어 메모리에 저장될 수 있다. 이 경우, 제어 모듈은 부동소수점으로 표현된 액티베이션 값 중에 서 지수(exponent)를 획득하고, 획득된 지수가 임계값 미만인지 여부를 판정할 수 있다. 또한, 임계값은 2의 배수로서 결정될 수 있으며, 임계값과 액티베이션 값은 2진수로 표현될 수 있다. 여기서 미리 정해진 포맷은 다양한 정밀도 포맷(Precision format)을 포함할 수 있다. 예를 들면, 미리 정해진 포맷에는 INT2, INT8, INT16, FP8, FP16, FP32, FP64, bfloat16, TensorFloat, fp24 등과 같은 다양한 정밀도 포맷이 포함될 수 있고, 다양하게 설정될 수 있는 부동소수점(Configurable Floating Point) 포맷이 포함될 수 있다. 제어 모듈은 액티베이션 값/지수가 임계값 미만인 것으로 판정된 경우, 기계학습 모델에서 임계값 미만에 해당하는 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산을 제어할 수 있다. 일 실시예에 따르면, 액티베이션 값이 아웃풋 액티베이션 값이고 액티베이션 값/지수가 임계값 미만인 경우, 제 어 모듈은 액티베이션 값을 영(zero)으로 결정하여 메모리에 저장할 수 있다. 연산 모듈은 영에 해 당하는 액티베이션 값이 인풋 액티베이션 값으로서 특정 레이어에 입력되는 경우, 영 값을 가지는 인풋 액티베 이션 값과 연관된 연산을 생략할 수 있다. 예컨대, 영 값을 입력받은 프로세싱 엘리먼트는 인풋 액티베이션 값 과 연관된 연산을 수행하지 않을 수 있다. 몇몇 실시예에 따르면, 아웃풋 액티베이션 값이 원래 값 그대로 메모리에 저장되고, 제어 모듈은 특정 아 웃풋 액티베이션 값/지수가 임계값 미만이고 특정 아웃풋 액티베이션 값이 특정 레이어로 입력되는 경우, 특정 레이어에서 특정 아웃풋 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산을 제어할 수 있 다. 예컨대, 제어 모듈은 임계값 미만의 값/지수를 가지는 특정 아웃풋 액티베이션 값에 대한 스킵 처리 를 나타내는 플래그(skip flag) 또는 스킵 명령을 연산 모듈로 전달하고, 연산 모듈은 스킵 플래그 또는 스킵 명령과 연관된 특정 액티베이션 값과 연관된 연산을 생략할 수 있다. 다른 예로서, 제어 모듈 은 임계값 미만의 값 또는 지수를 가지는 특정 아웃풋 액티베이션 값이 입력되는 특정 프로세싱 엘리먼트를 식 별하고, 식별된 특정 프로세싱 엘리먼트로 스킵 플래그/스킵 명령을 전달하고, 특정 프로세싱 엘리먼트는 특정 아웃풋 액티베이션 값과 연관된 연산을 생략할 수 있다. 도 5는 본 개시의 일 실시예에 따른 인공신경망 모델을 나타내는 예시도이다. 인공신경망 모델은, 기계학습 모델의 일 예로서, 기계학습(Machine Learning) 기술과 인지과학에서, 생물학적 신경망의 구조에 기초 하여 구현된 통계학적 학습 알고리즘 또는 그 알고리즘을 실행하는 구조일 수 있다. 일 실시예에 따르면, 인공신경망 모델은, 생물학적 신경망에서와 같이 시냅스의 결합으로 네트워크를 형성 한 인공 뉴런인 노드(Node)들이 시냅스의 가중치를 반복적으로 조정하여, 특정 입력에 대응한 올바른 출력과 추 론된 출력 사이의 오차가 감소되도록 학습함으로써, 문제 해결 능력을 가지는 기계학습 모델을 나타낼 수 있다. 예를 들어, 인공신경망 모델은 기계학습, 딥러닝 등의 인공지능 학습법에 사용되는 임의의 확률 모델, 뉴 럴 네트워크 모델 등을 포함할 수 있다. 일 실시예에 따르면, 인공신경망 모델은 도 4에서 예시된, 연산 모듈과 연관될 수 있다. 인공신경망 모델에서는 추론(inference)이 필요한 다양한 모델이 포함될 수 있다. 가령, 인공신경망 모델 은 하나 이상의 증권 거래소의 마켓 데이터를 기초로 생성된 입력 데이터를 이용하여 미래의 한 시점에서 타겟 증권 거래소에서의 증권 주문과 연관된 데이터(예를 들어, 가격, 가격 변동 등에 대한 데이터)를 추론하도 록 구성된 인공신경망 모델을 포함할 수 있다. 인공신경망 모델은 다층의 노드들과 이들 사이의 연결로 구성된 다층 퍼셉트론(MLP: multilayer perceptron)으로 구현될 수 있다. 본 실시예에 따른 인공신경망 모델은 MLP를 포함하는 다양한 인공신경 망 모델 구조들 중의 하나를 이용하여 구현될 수 있다. 도 5에 도시된 바와 같이, 인공신경망 모델은, 외 부로부터 입력 신호 또는 데이터를 수신하는 입력층, 입력 데이터에 대응한 출력 신호 또는 데이터 를 출력하는 출력층, 입력층과 출력층 사이에 위치하며 입력층으로부터 신호를 받아 특성을 추출하여 출력층으로 전달하는 n개(여기서, n은 양의 정수)의 은닉층(530_1 내지 530_n)으로 구성될 수 있다. 여기서, 출력층은 은닉층(530_1 내지 530_n)으로부터 신호를 받아 외부로 데이터를 출력할 수 있다. 인공신경망 모델의 학습 방법에는, 교사 신호(정답)의 입력에 의해서 문제의 해결에 최적화되도록 학습하 는 지도 학습(Supervised Learning) 방법과, 교사 신호를 필요로 하지 않는 비지도 학습(Unsupervised Learning) 방법이 있다. 예컨대, 인공신경망 모델은 타겟 증권 거래소에서의 증권 주문과 연관된 데이터 를 추론하도록 지도 학습 및/또는 비지도 학습될 수 있다. 예를 들어, 인공신경망 모델은 참조 입력 데이 터로부터 하나 이상의 미래 시점에서의 타겟 종목의 참조 가격을 추론하도록 지도 학습될 수 있다. 이렇게 학 습된 인공신경망 모델은 뉴럴 프로세싱 시스템에 포함될 수 있다. 예컨대, 학습된 인공신경망 모델 에 포함된 각 노드의 가중치가, PE 어레이에 포함된 복수의 엘리먼트 프로세싱에 적용되어, 인공신경망 모델 과 연관된 알고리즘이 하드웨어 기반으로 빠르게 수행될 수 있다. 도 5에 예시된 바와 같이, 복수의 레이어(520 내지 540)의 각각에 적어도 하나의 액티베이션 값이 출력되고, 출 력된 액티베이션 값은 다음 번째에 위치한 레이어로 입력될 수 있다. 즉, n 번째 레이어는 n+1 번째 레이어의 연산 결과에 영향을 미칠 수 있다. 인공신경망 모델에 포함된 출력층으로부터 최종적인 출력값이 출 력될 수 있다. 한편, 특정 노드로부터 출력되는 아웃풋 액티베이션 값이 최종 결과에 영향을 미치지 않을 정도로 미미한 값을 가질 수 있다. 이러한 경우, 최종 결과에 영향을 미치지 않을 정도의 미미한 값을 가지는 액티베이션 값과 연 관된 연산을 생략하면, 뉴럴 프로세싱 시스템의 컴퓨팅 자원과 전력 자원이 절감될 수 있고, 최종 결과가 더욱 빠르게 출력될 수 있다. 상술한 바와 같이, 본 개시의 일 실시예에 따르면, 액티베이션 값/지수와 임계값을 비 교하여, 연산 스킵 대상이 되는 액티베이션 값이 결정될 수 있다. 도 6 내지 도 9를 참조하여, 액티베이션 값과 연관된 연산이 스킵 처리되는 다양한 실시예에 대해서 설명하기로 한다. 도 6은 본 개시의 일 실시예에 따른, 액티베이션 값과 연관된 연산을 생략하기 위해 액티베이션 값을 변경하여 메모리에 저장하는 방법을 예시하는 도면이다. 도 6에 예시된 연산 모듈과 제어 모듈은 도 4에 예시된 제어 모듈과 연산 모듈과 대응될 수 있다. 도 6을 참조하면, 연산 모듈은 기계학습 모델에 포함되는 적어도 하나의 레이어에 의해서 연산된 결과 값 을 기초로, 아웃풋 액티베이션(Act_Out) 값을 출력할 수 있다. 여기서, 아웃풋 액티베이션 값은 V#1인 것으로 예시되어 있다. 제어 모듈은 아웃풋 액티베이션 값(V#1)이 임계값(Th) 미만인지 여부를 판정할 수 있다. 제어 모듈 은 아웃풋 액티베이션 값(V#1)이 임계값(Th) 미만인 것으로 판정되면, 아웃풋 액티베이션 값(V#1)을 영으로 결 정하여 메모리에 저장할 수 있다. 즉, 제어 모듈은 아웃풋 액티베이션 값(V#1)이 임계값(Th) 미만이 면, 아웃풋 액티베이션 값(V#1)을 영으로 변경하여 메모리에 저장할 수 있다. 메모리에 저장된 복수 의 아웃풋 액티베이션 값 중에서, 영을 가지는 액티베이션 값과 연관된 연산이 생략될 수 있다. n 번째(여기서, n은 자연수) 레이어로부터 출력된 아웃풋 액티베이션 값은 n+1 번째 레이어의 인풋 액티베이션 값 으로서 이용될 수 있는데, n+1 번째 레이어에서 연산이 수행될 때에, 영을 가지는 액티베이션 값과 연관된 연산 이 생략될 수 있다. 도 7은 본 개시의 다른 실시예에 따른, 임계값 미만에 해당하는 액티베이션 값과 연관된 연산을 생략하는 방법 을 예시하는 도면이다. 도 7에 예시된 제어 모듈은 도 4에 예시된 제어 모듈과 대응될 수 있다. 도 7을 참조하면, 본 개시의 다른 실시예에서는 메모리에 아웃풋 액티베이션 값이 오리지널 값으로서 저장 될 수 있다. 첨언하면, 아웃풋 액티베이션 값이 임계값(Th) 미만이더라도, 아웃풋 액티베이션 값이 변경되지 않고 오리지널 값으로 메모리에 저장될 수 있다. 메모리에 아웃풋 액티베이션 값이 오리지널 값으로 저장된 상태에서, 제어 모듈은 기계학습 모델의 특정 레이어로 입력되는 아웃풋 액티베이션 값을 획득할 수 있다. 도 7에서 아웃풋 액티베이션 값은 V#2인 것으로 예시되어 있다. 제어 모듈은 아웃풋 액티베이션 값(V#2)이 임계값(Th) 미만인지 여부를 판정할 수 있다. 제어 모듈 은 아웃풋 액티베이션 값(V#2)이 임계값(Th) 미만인 것으로 판정되면, 아웃풋 액티베이션 값(V#2)과 연관된 연 산이 스킵 처리되도록 기계학습 모델에 대한 연산을 제어할 수 있다. 예컨대, 임계값 미만에 해당하는 아웃풋액티베이션 값(V#2)이 특정 레이어로 입력되는 경우, 제어 모듈은 특정 레이어에서 특정 아웃풋 액티베이 션 값과 연관된 연산이 생략되도록 기계학습 모델의 연산을 제어할 수 있다. 몇몇 실시예에서, 제어 모듈(72 0)은 임계값 미만에 해당하는 특정 아웃풋 액티베이션 값에 대한 스킵 플래그(skip flag) 또는 스킵 명령을, 연 산 모듈로 전달할 수 있다. 이 경우, 연산 모듈은 스킵 플래그 또는 스킵 명령과 연관된 특정 액티베이션 값과 연관된 연산을 생략할 수 있다. 다른 예로서, 제어 모듈은 임계값 미만에 해당하는 아웃풋 액티베이션 값 (V#2)이 입력되는 특정 프로세싱 엘리먼트를 식별하고, 식별된 특정 프로세싱 엘리먼트로 스킵 플래그 또는 스 킵 명령을 전달하고, 특정 프로세싱 엘리먼트는 아웃풋 액티베이션 값과 연관된 연산을 생략할 수 있다. 도 8은 본 개시의 또 다른 실시예에 따른, 임계값 미만의 지수를 가지는 액티베이션 값과 연관된 연산을 생략하 는 방법을 예시하는 도면이다. 도 8에 예시된 제어 모듈은 도 4에 예시된 제어 모듈과 대응될 수 있 다. 도 8을 참조하면, 본 개시의 또 다른 실시예에서는 액티베이션 값이 IEEE에서 제안하는 FP16 포맷의 부동소수점 으로 표현되어 메모리에 저장될 수 있다. 또한, 임계값은 2의 배수이며, 동적으로 결정될 수 있다. 추가 적으로 또는 대안적으로, 임계값과 액티베이션 값의 각각은 2진수로 표현될 수 있다. 제어 모듈은 액티베이션 값(V#3)을 메모리로부터 획득하고, 액티베이션 값(V#3) 중에서 지수를 추출 할 수 있다. 제어 모듈은 획득된 지수가 임계값 미만인지 여부를 판정할 수 있다. 제어 모듈은 지 수가 임계값 미만인 것으로 판정된 경우, 기계학습 모델에서 임계값 미만에 해당하는 지수를 가지는 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델에 대한 연산을 제어할 수 있다. 예컨대, 임계값 미만에 해당하 는 지수를 가지는 아웃풋 액티베이션 값(V#3)이 특정 레이어로 입력되는 경우, 제어 모듈은 특정 레이어에 서 특정 아웃풋 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델의 연산을 제어할 수 있다. 몇몇 실 시예에서, 제어 모듈은 임계값 미만의 지수를 가지는 특정 아웃풋 액티베이션 값에 대한 스킵 플래그 또는 스킵 명령을 연산 모듈로 전달할 수 있다. 이 경우, 연산 모듈은 스킵 플래그 또는 스킵 명령과 연관된 특정 액티베이션 값과 연관된 연산을 생략할 수 있다. 다른 예로서, 제어 모듈은 임계값 미만에 해당하는 지수 를 가지는 아웃풋 액티베이션 값(V#3)이 입력되는 특정 프로세싱 엘리먼트를 식별하고 식별된 특정 프로세싱 엘 리먼트로 스킵 플래그 또는 스킵 명령을 전달하고, 특정 프로세싱 엘리먼트는 아웃풋 액티베이션 값과 연관된 연산을 생략할 수 있다. 또 다른 실시예에서, 제어 모듈은 메모리에 저장된 아웃풋 액티베이션(Act_Out) 값 중에서 스킵 대상 이 되는 액티베이션 값을 결정하고, 결정된 액티베이션 값을 영으로 변경할 수 있다. 예컨대, 제어 모듈 은 메모리에 아웃풋 액티베이션 값이 저장될 때에, 아웃풋 액티베이션 값에 포함된 지수를 추출하고, 추출 된 지수가 임계값(Th) 미만인지 여부를 판정할 수 있다. 제어 모듈은 아웃풋 액티베이션 값이 임계값(Th) 미만인 것으로 판정되면, 아웃풋 액티베이션 값을 영으로 결정하여 메모리에 저장할 수 있다. 즉, 제어 모듈은 아웃풋 액티베이션 값이 임계값(Th) 미만이면, 아웃풋 액티베이션 값이 영으로 변경하여 메모리 에 저장할 수 있다. 메모리에 저장된 복수의 아웃풋 액티베이션 값 중에서, 영 값을 가지는 액티베 이션 값은 기계학습 모델에서 연산이 생략될 수 있다. 도 9는 본 개시의 일 실시예에 따른, 모든 액티베이션 값과 연관된 연산을 수행하는 제1 기계학습 모델과 일부 액티베이션 값과 연관된 연산을 수행하는 제2 기계학습 모델을 예시한 도면이다. 제1 기계학습 모델 과 제2 기계학습 모델은 인공신경망인 것으로 예시되어 있다. 도 9에서는 제1 기계학습 모델과 제2 기계학습 모델에 포함된 n 번째 레이어(Layer_n)로부터 제1 액티베이션 값(Act#1), 제2 액티베이션 값 (Act#2) 및 제3 액티베이션 값(Act#3)이 출력되는 것으로 예시되어 있다. 도 9에 예시된 바와 같이, 제1 기계 학습 모델에 포함된 n+1 번째 레이어(Layer_n+1)는 n 번째로부터 출력된 모든 액티베이션 값(Act#1, Act#2, Act#3)에 대해서 연산을 수행하고 있다. 반면에, 제2 기계학습 모델에 포함된 n 번째 레이어(Layer_n)로부터 출력된 액티베이션 값(Act#1, Act#2, Act#3)의 각각과 임계값이 비교되어, 스킵 대상 액티베이션 값(Act#2)이 결정될 수 있다. 여기서, 스킵 대상 액티베이션 값(Act#2)은 최종 결과값에 영향을 미치는 정도가 미미할 수 있다. 다른 예로서, 제2 기계학습 모델에 포함된 n 번째 레이어(Layer_n)로부터 출력된 복수의 액티베이션 (Act#1, Act#2, Act#3)로부터 복수의 지수가 획득되고, 획득된 복수의 지수의 각각과 임계값이 비교되어, 스킵 대상 액티베이션 값(Act#2)이 결정될 수 있다. 도 9에서는 스킵 대상 액티베이션 값이 제2 액티베이션 값 (Act#2)인 것으로 예시되어 있고, 점선으로 표시되어 있다. 도 9에 예시된 바와 같이, n+1 번째 레이어 (Layer_n+1)에 포함된 모든 노드들이 제2 액티베이션 값(Act#2)을 입력받은 경우, n+1 번째 레이어(Layer_n+1)에서의 연산량이 대폭 감소될 수 있다. 즉, 제1 기계학습 모델에 포함된 n+1 번째 레이어(Layer_n+1)와 비교하여, 제2 기계학습 모델에 포함된 n+1 번째 레이어(Layer_n+1)의 연산량이 대략 33% 정도로 감소될 수 있다. 이하, 도 10 내지 도 12를 참조하여, 기계학습 모델에 대한 연산 제어 방법에 대해서 설명한다. 도 10 내지 도 12에 도시된 방법은, 본 개시의 목적을 달성하기 위한 일 실시예일 뿐이며, 필요에 따라 일부 단계가 추가되거 나 삭제될 수 있음은 물론이다. 또한, 도 10 내지 도 12에 도시된 방법은, 뉴럴 프로세싱 시스템에 포함된 적 어도 하나의 프로세서에 의해서 수행될 수 있다. 예컨대, 도 10 내지 도 12에 도시된 방법은, 도 2 및 도 3의 프로세싱 유닛에 포함된 임계값 결정 모듈, 제어 모듈 및/또는 연산 모듈에 의해서 수행될 수 있다. 설명의 편의를 위해서 도 2의 뉴럴 코어 SOC에 포함된 프로세싱 유닛에 의해서, 도 10 내지 도 12에 도시된 각 단계가 수행되는 것으로 설명하기로 한다. 도 10은 본 개시의 일 실시예에 따른, 기계학습 모델에 대한 연산 제어 방법을 설명하는 흐름도이다. 프 로세싱 유닛은 연산 스킵을 위한 임계값을 동적으로 결정할 수 있다(S1010). 프로세싱 유닛은 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 복수의 액티베이션 값의 분포에 기초하여, 임계값을 동적으로 결정할 수 있다. 복수의 액티베이션 값의 분포에 기초하여, 임계값을 동적으로 결정하는 구체적인 방법은 도 11을 참조하 여 후술하기로 한다. 프로세싱 유닛은 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 액티베이션 값을 획득할 수 있다 (S1020). 여기서, 액티베이션 값은 인풋 액티베이션 값 또는 아웃풋 액티베이션 값일 수 있다. 예컨대, 특정 레이어로부터 출력된 액티베이션 값은 메모리에 저장되고, 프로세싱 유닛은 메모리에 접근하여 액티베이션 값을 획득할 수 있다. 다른 예로서, 프로세싱 유닛은 메모리에 저장되기 전에 특정 레이어로부터 출력되는 액티베이 션 값을 특정 레이어와 연관된 프로세싱 엘리먼트로부터 수신할 수 있다. 그 후, 프로세싱 유닛은 획득된 액티베이션 값이 임계값 미만인지 여부를 판정할 수 있다(S1030). 이 경우, 프 로세싱 유닛은 획득된 액티베이션 값의 절대값이 임계값 미만인지 여부를 판정할 수 있다. 다음으로, 프로세싱 유닛은 획득된 액티베이션 값이 임계값 미만인 것으로 판정되는 경우, 기계학습 모델에서 액티베이션 값과 연관된 연산이 스킵 처리되도록 기계학습 모델에 대한 연산을 제어할 수 있다(S1040). 일 실 시예에 따르면, 프로세싱 유닛은 기계학습 모델에 포함된 제1 레이어로부터 출력된 액티베이션 값을 획득하고, 획득된 액티베이션 값이 임계값 미만인 경우, 액티베이션 값을 영(zero)으로 결정하여 메모리에 저장할 수 있다. 프로세싱 유닛은 제1 레이어로부터의 출력 값이 입력되는 제2 레이어와 연관된 연산이 수행되는 경우, 영으로 결정된 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델의 연산을 제어할 수 있다. 몇몇 실시예에서, 메모리에는 값이 조정되지 않고 오리지널 형태로 액티베이션 값이 저장될 수 있다. 여기서, 액티베이션 값은 기계학습 모델에 포함된 제1 레이어로부터의 출력 값일 수 있다. 이렇게 메모리에 원본 액티 베이션 값이 저장된 상태에서, 프로세싱 유닛은 제1 레이어로부터의 출력 값이 입력되는 제2 레이어와 연관된 연산이 수행되고 제1 레이어로부터의 출력 값이 임계값 미만인 경우, 제2 레이어에서 제1 레이어로부터의 출력 값과 연관된 연산이 생략되도록 기계학습 모델의 연산을 제어할 수 있다. 한편, 프로세싱 유닛은 획득된 액티베이션 값이 임계값 이상인 것으로 판정되는 경우, 기계학습 모델에서 액티 베이션 값과 연관된 연산이 수행되도록 기계학습 모델에 대한 연산을 제어할 수 있다(S1050). 도 10은 하나의 액티베이션 값과 연관된 하나의 사이클을 예시하는 도면으로서, 액티베이션 값이 기계학습 모델 로부터 출력되거나 입력되는 경우에 도 10과 연관된 프로세스가 반복되어 수행될 수 있다. 도 11은 본 개시의 일 실시예에 따른, 임계값이 동적으로 결정되는 방법을 설명하는 흐름도이다. 도 11 에 따른 방법은 임계값이 동적으로 설정하기 위한 명령이 수신되는 경우에 진행될 수 있다. 도 11에 따 른 방법은 임계값을 정적으로 변경하기 위한 명령이 수신되는 경우에 중단될 수 있다. 임계값이 정적으 로 결정되는 경우, 현재 결정된 임계값이 계속적으로 유지되거나 미리 결정된 디폴트 값으로 임계값이 변경될 수 있다. 프로세싱 유닛은 카운터 값과 임계값 각각을 미리 결정된 초기값으로 결정할 수 있다(S1110). 여기서, 카운터 값에 대한 초기 값은 '0'으로 결정될 수 있고, 임계값에 대한 초기 값은 디폴트 값으로 결정될 수 있다. 그 후, 프로세싱 유닛은 특정 레이어로부터 출력된 액티베이션 값(Act_Value)을 획득할 수 있다(S1120). 이어 서, 프로세싱 유닛은 획득된 액티베이션 값(Act_Value)이 임계값 미만인지 여부를 판정할 수 있다(S1130). 이경우, 프로세싱 유닛은 획득된 액티베이션 값(Act_Value)의 절대값이 임계값 미만인지 여부를 판정할 수 있다. 프로세싱 유닛은 획득된 액티베이션 값(Act_Value)이 임계값 미만인 것으로 판정되면, 액티베이션 값을 영으로 결정하여 메모리에 저장할 수 있다(S1140). 몇몇 실시예에서는, 프로세싱 유닛은 액티베이션 값을 영으로 변 경하지 하고, 원래의 값 그대로 메모리에 저장할 수 있다. 이어서, 프로세싱 유닛은 임계값을 미리 결정된 크 기만큼 증가시켜, 임계값을 갱신할 수 있다(S1150). 한편, 프로세싱 유닛은 획득된 액티베이션 값(Act_Value)이 임계값 이상인 것으로 판정되면, 임계값이 변동되지 않은 지속시간을 측정하기 위하여, 카운터 값을 증가시킬 수 있다(S1160). 이어서, 프로세싱 유닛은 카운터 값 이 미리 결정된 값(즉, N)에 도달하였는지 여부를 판정할 수 있다(S1170). 즉, 프로세싱 유닛은 카운터 값에 기초하여, 임계값이 변동되지 않은 지속시간이 미리 결정된 임계시간에 도달하였는지 여부를 판정할 수 있다. 프로세싱 유닛은 카운터 값이 미리 결정된 값(즉, N)에 도달한 것으로 판정되는 경우, 카운터 값을 초기화하고 임계값을 미리 결정된 값만큼 감소시켜 임계값을 갱신할 수 있다(S1180). 즉, 프로세싱 유닛은 임계값이 변동 되지 않은 지속시간이 미리 결정된 임계시간에 도달한 경우, 임계값을 미리 결정된 값만큼 감소시켜 임계값을 갱신할 수 있다. 한편, S1170 단계에서 카운터 값이 미리 결정된 값(즉, N)에 도달하지 않은 것으로 판정되는 경우, 카운터 값을 미리 결정된 값만큼 증가시킬 수 있다(S1190). 여기서, 증가되는 카운터 값은 임계값을 증가시키는 값과 상이 할 수 있다. 도 11에 예시된 바와 같이, 액티베이션 값과 임계값의 비교 횟수는 복수의 액티베이션 값의 개수와 상응하여 반 복적으로 수행될 수 있다. 즉, S1120 단계 이후부터가 복수의 액티베이션 값의 개수와 상응하여 반복적으로 수 행될 수 있다. 상술한 바와 같이, 임계값은 획일적으로 고정되지 않고, 액티베이션 값의 분포에 기초하여 동적으로 결정될 수 있다. 도 12는 본 개시의 또 다른 실시예에 따른, 기계학습 모델에 대한 연산 제어 방법을 설명하는 흐름도이다. 프로세싱 유닛은 연산 스킵을 위한 임계값을 동적으로 결정할 수 있다(S1210). 여기서, 임계값은 2를 미리 정해진 횟수로 거듭하여 곱한 값일 수 있다. 추가적으로 또는 대안적으로, 임계값과 액티베이션 값의 각각은 2진수일 수 있다. 프로세싱 유닛은 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 복수의 액티베이션 값의 분포에 기초 하여, 임계값을 결정할 수 있다. 예컨대, 액티베이션 값과 임계값의 각각은 2진수일 수 있다. 복수의 액티베 이션 값의 분포에 기초하여, 임계값을 동적으로 결정하는 구체적인 방법은 도 13을 참조하여 후술하기로 한다. 프로세싱 유닛은 기계학습 모델에 포함된 적어도 하나의 레이어와 연관된 액티베이션 값을 획득할 수 있다 (S1220). 여기서, 액티베이션 값은 인풋 액티베이션 값 또는 아웃풋 액티베이션 값일 수 있다. 예컨대, 특정 레이어로부터 출력된 액티베이션 값은 메모리에 저장되고, 프로세싱 유닛은 메모리에 접근하여 액티베이션 값을 획득할 수 있다. 다른 예로서, 프로세싱 유닛은 메모리에 저장되기 전에 특정 레이어로부터 출력되는 액티베이 션 값을 특정 레이어와 연관된 프로세싱 엘리먼트로부터 수신할 수 있다. 그 후, 프로세싱 유닛은 획득된 액티베이션 값으로부터 지수를 획득할 수 있다(S1230). 이어서, 프로세싱 유닛 은 획득된 지수가 임계값 미만인지 여부를 판정할 수 있다(S1240). 그 후, 프로세싱 유닛은 획득된 지수가 임계값 미만인 것으로 판정되는 경우, 기계학습 모델에서 임계값 미만의 지수를 가지는 액티베이션 값과 연관된 연산이 스킵 처리되도록 기계학습 모델에 대한 연산을 제어할 수 있다 (S1250). 일 실시예에 따르면, 프로세싱 유닛은 기계학습 모델에 포함된 제1 레이어로부터 출력된 액티베이션 값을 획득하고, 액티베이션 값으로부터 획득된 지수가 임계값 미만인 경우, 액티베이션 값을 영으로 결정하여 메모리에 저장할 수 있다. 프로세싱 유닛은 제1 레이어로부터의 출력 값이 입력되는 제2 레이어와 연관된 연산 이 수행되는 경우, 영으로 결정된 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델의 연산을 제어할 수 있다. 몇몇 실시예에서, 메모리에는 값이 변경되지 않고 오리지널 형태로 액티베이션 값이 저장될 수 있다. 여기서, 액티베이션 값은 기계학습 모델에 포함된 제1 레이어로부터의 출력 값일 수 있다. 이렇게 메모리에 원본 액티 베이션 값이 저장된 상태에서, 프로세싱 유닛은 제1 레이어로부터의 출력 값이 입력되는 제2 레이어와 연관된 연산이 수행되고 제1 레이어로부터의 출력 값 중 지수가 임계값 미만인 경우, 관련 액티베이션 값과 연관된 연산이 생략되도록 기계학습 모델의 연산을 제어할 수 있다. 한편, 프로세싱 유닛은 획득된 지수가 임계값 이상인 것으로 판정되는 경우, 지수를 가지는 액티베이션 값과 연 관된 연산이 수행되도록 기계학습 모델에 대한 연산을 제어할 수 있다(S1260). 도 12는 하나의 액티베이션 값과 연관된 하나의 사이클을 예시하는 도면으로서, 액티베이션 값이 기계학습 모델 로부터 출력되거나 입력되는 경우에 도 12와 연관된 프로세스가 반복되어 수행될 수 있다. 도 13은 본 개시의 또 다른 실시예에 따른, 임계값이 동적으로 결정되는 방법을 설명하는 흐름도이다. 도 13에 따른 방법은 임계값이 동적으로 설정하기 위한 명령이 수신되는 경우에 진행될 수 있다. 도 13 에 따른 방법은 임계값을 정적으로 변경하기 위한 명령이 수신되는 경우에 중단될 수 있다. 임계값이 정 적으로 결정되는 경우, 현재 결정된 임계값이 계속적으로 유지되거나 미리 결정된 디폴트 값으로 임계값이 변경 될 수 있다. 프로세싱 유닛은 카운터 값과 임계값 각각을 미리 결정된 초기값으로 결정할 수 있다(S1310). 여기서, 카운터 값에 대한 초기 값은 '0'이 결정될 수 있고, 임계값에 대한 초기 값은 디폴트 값이 결정될 수 있다. 그 후, 프로세싱 유닛은 특정 레이어로부터 출력된 액티베이션 값(Act_Value)을 획득하고, 획득된 액티베이션 값으로부터 지수를 획득할 수 있다(S1320). 이어서, 프로세싱 유닛은 획득된 지수가 임계값 미만인지 여부를 판정할 수 있다(S1330). 여기서, 임계값은 2를 미리 정해진 횟수로 거듭하여 곱한 값일 수 있다. 추가적으로 또는 대안적으로, 액티베이션 값과 임계값의 각각은 2진수일 수 있다. 프로세싱 유닛은 획득된 지수가 임계값 미만인 것으로 판정되면, 액티베이션 값을 영으로 결정하여 메모리에 저 장할 수 있다(S1340). 몇몇 실시예에서는, 프로세싱 유닛은 액티베이션 값을 영으로 변경하지 하고, 원래의 값 그대로 메모리에 저장할 수 있다. 이어서, 프로세싱 유닛은 임계값을 미리 결정된 크기만큼 증가시켜, 임계 값을 갱신할 수 있다(S1350). 이때, 프로세싱 유닛은 임계값에 2를 곱하여 임계값을 증가시킬 수 있다. 한편, 프로세싱 유닛은 획득된 지수가 임계값 이상인 것으로 판정되면, 임계값이 변동되지 않은 지속시간을 측 정하기 위하여, 카운터 값을 증가시킬 수 있다(S1360). 이어서, 프로세싱 유닛은 카운터 값이 미리 결정된 값 (즉, N)에 도달하였는지 여부를 판정할 수 있다(S1370). 즉, 프로세싱 유닛은 카운터 값에 기초하여, 임계값이 변동되지 않은 지속시간이 미리 결정된 임계시간에 도달하였는지 여부를 판정할 수 있다. 프로세싱 유닛은 카운터 값이 미리 결정된 값(즉, N)에 도달한 것으로 판정되는 경우, 카운터 값을 초기화하고 임계값을 미리 결정된 값만큼 감소시켜 임계값을 갱신할 수 있다(S1380). 이때, 프로세싱 유닛은 임계값에 2를 나누어 임계값을 감소시킬 수 있다. 한편, S1370 단계에서 카운터 값이 미리 결정된 값(즉, N)에 도달하지 않은 것으로 판정되는 경우, 카운터 값을 미리 결정된 값만큼 증가시킬 수 있다(S1390). 여기서, 증가되는 카운터 값은 임계값을 증가시키는 값과 상이 할 수 있다. 도 13에 예시된 바와 같이, 액티베이션 값으로부터 획득한 지수와 임계값의 비교 횟수는 복수의 액티베이션 값 의 개수와 상응하여 반복적으로 수행될 수 있다. 즉, S1320 단계 이후부터가 복수의 액티베이션 값의 개수와 상응하여 반복적으로 수행될 수 있다. 상술한 흐름도 및 상술한 설명은 일 예시일 뿐이며, 일부 실시예에서는 상이하게 구현될 수 있다. 예를 들어, 일부 실시예에서는 각 단계의 순서가 바뀌거나, 일부 단계가 반복 수행되거나, 일부 단계가 생략되거나, 일부 단계가 추가될 수 있다. 상술한 방법은 컴퓨터에서 실행하기 위해 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램으로 제공될 수 있다. 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하 는 것일수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록 수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수 도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD 와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체 의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다.본 개시의 방법, 동작 또는 기법들은 다양한 수단에 의해 구현될 수도 있다. 예를 들어, 이러한 기법들은 하드 웨어, 펌웨어, 소프트웨어, 또는 이들의 조합으로 구현될 수도 있다. 본원의 개시와 연계하여 설명된 다양한 예시적인 논리적 블록들, 모듈들, 회로들, 및 알고리즘 단계들은 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양자 의 조합들로 구현될 수도 있음을 통상의 기술자들은 이해할 것이다. 하드웨어 및 소프트웨어의 이러한 상호 대 체를 명확하게 설명하기 위해, 다양한 예시적인 구성요소들, 블록들, 모듈들, 회로들, 및 단계들이 그들의 기능 적 관점에서 일반적으로 위에서 설명되었다. 그러한 기능이 하드웨어로서 구현되는지 또는 소프트웨어로서 구 현되는 지의 여부는, 특정 애플리케이션 및 전체 시스템에 부과되는 설계 요구사항들에 따라 달라진다. 통상의 기술자들은 각각의 특정 애플리케이션을 위해 다양한 방식들로 설명된 기능을 구현할 수도 있으나, 그러한 구현 들은 본 개시의 범위로부터 벗어나게 하는 것으로 해석되어서는 안 된다. 하드웨어 구현에서, 기법들을 수행하는 데 이용되는 프로세싱 유닛들은, 하나 이상의 ASIC들, DSP들, 디지털 신 호 프로세싱 디바이스들(digital signal processing devices; DSPD들), 프로그램가능 논리 디바이스들 (programmable logic devices; PLD들), 필드 프로그램가능 게이트 어레이들(field programmable gate arrays; FPGA들), 프로세서들, 제어기들, 마이크로제어기들, 마이크로프로세서들, 전자 디바이스들, 본 개시에 설명된 기능들을 수행하도록 설계된 다른 전자 유닛들, 컴퓨터, 또는 이들의 조합 내에서 구현될 수도 있다. 따라서, 본 개시와 연계하여 설명된 다양한 예시적인 논리 블록들, 모듈들, 및 회로들은 범용 프로세서, DSP, ASIC, FPGA나 다른 프로그램 가능 논리 디바이스, 이산 게이트나 트랜지스터 로직, 이산 하드웨어 컴포넌트들, 또는 본원에 설명된 기능들을 수행하도록 설계된 것들의 임의의 조합으로 구현되거나 수행될 수도 있다. 범용 프로세서는 마이크로프로세서일 수도 있지만, 대안으로, 프로세서는 임의의 종래의 프로세서, 제어기, 마이크로 제어기, 또는 상태 머신일 수도 있다. 프로세서는 또한, 컴퓨팅 디바이스들의 조합, 예를 들면, DSP와 마이크 로프로세서, 복수의 마이크로프로세서들, DSP 코어와 연계한 하나 이상의 마이크로프로세서들, 또는 임의의 다 른 구성의 조합으로서 구현될 수도 있다. 펌웨어 및/또는 소프트웨어 구현에 있어서, 기법들은 랜덤 액세스 메모리(random access memory; RAM), 판독 전 용 메모리(read-only memory; ROM), 비휘발성 RAM(non-volatile random access memory; NVRAM), PROM(programmable read-only memory), EPROM(erasable programmable read-only memory), EEPROM(electrically erasable PROM), 플래시 메모리, 컴팩트 디스크(compact disc; CD), 자기 또는 마킹 데이 터 스토리지 디바이스 등과 같은 컴퓨터 판독가능 매체 상에 저장된 명령들로서 구현될 수도 있다. 명령들은 하나 이상의 프로세서들에 의해 실행 가능할 수도 있고, 프로세서(들)로 하여금 본 개시에 설명된 기능의 특정 양태들을 수행하게 할 수도 있다. 소프트웨어로 구현되는 경우, 상술된 기법들은 하나 이상의 명령들 또는 코드로서 컴퓨터 판독 가능한 매체 상 에 저장되거나 또는 컴퓨터 판독 가능한 매체를 통해 전송될 수도 있다. 컴퓨터 판독가능 매체들은 한 장소에 서 다른 장소로 컴퓨터 프로그램의 전송을 용이하게 하는 임의의 매체를 포함하여 컴퓨터 저장 매체들 및 통신 매체들 양자를 포함한다. 저장 매체들은 컴퓨터에 의해 액세스될 수 있는 임의의 이용 가능한 매체들일 수도 있다. 비제한적인 예로서, 이러한 컴퓨터 판독가능 매체는 RAM, ROM, EEPROM, CD-ROM 또는 다른 광학 디스크 스토리지, 자기 디스크 스토리지 또는 다른 자기 스토리지 디바이스들, 또는 소망의 프로그램 코드를 명령들 또 는 데이터 구조들의 형태로 이송 또는 저장하기 위해 사용될 수 있으며 컴퓨터에 의해 액세스될 수 있는 임의의 다른 매체를 포함할 수 있다. 또한, 임의의 접속이 컴퓨터 판독가능 매체로 적절히 칭해진다. 예를 들어, 소프트웨어가 동축 케이블, 광섬유 케이블, 연선, 디지털 가입자 회선 (DSL), 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들을 사용하여 웹사이트, 서버, 또는 다른 원격 소스로부터 전송되면, 동축 케 이블, 광섬유 케이블, 연선, 디지털 가입자 회선, 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들은 매 체의 정의 내에 포함된다. 본원에서 사용된 디스크(disk) 와 디스크(disc)는, CD, 레이저 디스크, 광 디스크, DVD(digital versatile disc), 플로피디스크, 및 블루레이 디스크를 포함하며, 여기서 디스크들(disks)은 보통 자기적으로 데이터를 재생하고, 반면 디스크들(discs)은 레이저를 이용하여 광학적으로 데이터를 재생한다. 위 의 조합들도 컴퓨터 판독가능 매체들의 범위 내에 포함되어야 한다. 소프트웨어 모듈은, RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터들, 하드 디스크, 이동식 디스크, CD-ROM, 또는 공지된 임의의 다른 형태의 저장 매체 내에 상주할 수도 있다. 예시적인 저장 매체는, 프로세서가 저장 매체로부터 정보를 판독하거나 저장 매체에 정보를 기록할 수 있도록, 프로세서 에 연결될 수 있다. 대안으로, 저장 매체는 프로세서에 통합될 수도 있다. 프로세서와 저장 매체는 ASIC 내에 존재할 수도 있다. ASIC은 유저 단말 내에 존재할 수도 있다. 대안으로, 프로세서와 저장 매체는 유저 단말에서 개별 구성요소들로서 존재할 수도 있다. 이상 설명된 실시예들이 하나 이상의 독립형 컴퓨터 시스템에서 현재 개시된 주제의 양태들을 활용하는 것으로 기술되었으나, 본 개시는 이에 한정되지 않고, 네트워크나 분산 컴퓨팅 환경과 같은 임의의 컴퓨팅 환경과 연계 하여 구현될 수도 있다. 또 나아가, 본 개시에서 주제의 양상들은 복수의 프로세싱 칩들이나 장치들에서 구현 될 수도 있고, 스토리지는 복수의 장치들에 걸쳐 유사하게 영향을 받게 될 수도 있다. 이러한 장치들은 PC들, 네트워크 서버들, 및 휴대용 장치들을 포함할 수도 있다."}
{"patent_id": "10-2023-0135269", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 명세서에서는 본 개시가 일부 실시예들과 관련하여 설명되었지만, 본 개시의 발명이 속하는 기술분야의 통상 의 기술자가 이해할 수 있는 본 개시의 범위를 벗어나지 않는 범위에서 다양한 변형 및 변경이 이루어질 수 있 다. 또한, 그러한 변형 및 변경은 본 명세서에 첨부된 특허청구의 범위 내에 속하는 것으로 생각되어야 한다."}
{"patent_id": "10-2023-0135269", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 실시예들은, 이하 설명하는 첨부 도면들을 참조하여 설명될 것이며, 여기서 유사한 참조 번호는 유사 한 요소들을 나타내지만, 이에 한정되지는 않는다. 도 1은 본 개시의 일 실시예에 따른, 뉴럴 프로세싱 시스템을 설명하기 위한 블록도이다. 도 2는 도 1의 뉴럴 프로세싱 장치를 세부적으로 설명하기 위한 블록도이다. 도 3은 본 개시의 일 실시예에 따른, 도 1의 뉴럴 코어 SoC를 세부적으로 설명하기 위한 블록도이다. 도 4는 본 개시의 일 실시예에 따른, 도 3의 프로세싱 유닛을 세부적으로 설명하기 위한 블록도이다. 도 5는 본 개시의 일 실시예에 따른 인공신경망 모델을 나타내는 예시도이다. 도 6은 본 개시의 일 실시예에 따른, 액티베이션 값과 연관된 연산을 생략하기 위해 액티베이션 값을 변경하여 메모리에 저장하는 방법을 예시하는 도면이다. 도 7은 본 개시의 다른 실시예에 따른, 임계값 미만에 해당하는 액티베이션 값과 연관된 연산을 생략하는 방법 을 예시하는 도면이다. 도 8은 본 개시의 또 다른 실시예에 따른, 임계값 미만의 지수를 가지는 액티베이션 값과 연관된 연산을 생략하 는 방법을 예시하는 도면이다. 도 9는 본 개시의 일 실시예에 따른, 모든 액티베이션 값과 연관된 연산을 수행하는 제1 기계학습 모델과 일부 액티베이션 값과 연관된 연산을 수행하는 제2 기계학습 모델을 예시한 도면이다. 도 10은 본 개시의 일 실시예에 따른, 기계학습 모델에 대한 연산 제어 방법을 설명하는 흐름도이다.도 11은 본 개시의 일 실시예에 따른, 임계값이 동적으로 결정되는 방법을 설명하는 흐름도이다. 도 12는 본 개시의 또 다른 실시예에 따른, 기계학습 모델에 대한 연산 제어 방법을 설명하는 흐름도이다. 도 13은 본 개시의 또 다른 실시예에 따른, 임계값이 동적으로 결정되는 방법을 설명하는 흐름도이다."}
