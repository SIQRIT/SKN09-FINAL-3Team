{"patent_id": "10-2021-0153963", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0068058", "출원번호": "10-2021-0153963", "발명의 명칭": "인공 신경망 기반 특징 정보 처리 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "오성찬"}}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "데이터를 저장하는 메모리;상기 메모리를 제어하는 프로세서;를 포함하되,상기 프로세서는,이미지의 특징 맵을 기반으로 버텍스를 포함하는 그래프를 추출하고,상기 버텍스에 대응되는 특징 벡터를 추출하고,상기 그래프와 상기 특징 벡터를 인공 신경망을 기반으로 처리하며,상기 그래프는 상기 버텍스의 위치와 상기 버텍스 간의 연결 관계에 관한 정보를 포함하는, 인공신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 인공 신경망은 GCN(Graph Convolution Network)인,인공신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 버텍스 간의 연결 관계에 관한 정보는 상기 버텍스에 대한 엣지 집합과 인접 행렬을 포함하는,인공신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 엣지 집합과 상기 인접 행렬은 K-최근접 이웃 알고리즘, 랜덤 샘플링 알고리즘, 혹은 들로네 삼각 분할 알고리즘을 이용하여 획득되는, 인공신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 특징 벡터는 그래프 컨볼루션 레이어(graph convolution layer)를 통해 획득되는,인공 신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 특징 벡터는 K-최근접 이웃 알고리즘 혹은 랜덤 샘플링 알고리즘을 이용하여 획득되는,인공 신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2023-0068058-3-제1 항에 있어서,상기 버텍스는 상기 특징 맵과 컨볼루션 레이어(convolution layer)를 통해 획득한 상기 특징맵에 대한 중요도맵(importance map)을 이용하여 획득되는,인공 신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "이미지의 특징 맵을 기반으로 버텍스로 이루어진 그래프를 추출하는 단계;상기 버텍스에 대응되는 특징 벡터를 추출하는 단계;상기 그래프와 상기 특징 벡터를 인공 신경망을 기반으로 처리하는 단계;를 포함하되,상기 그래프는 상기 버텍스의 위치와 상기 버텍스 간의 연결 관계에 관한 정보를 포함하는, 인공신경망 기반 특징 정보 처리 방법."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 인공 신경망은 GCN(Graph Convolution Network)인,인공신경망 기반 특징 정보 처리 방법."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8 항에 있어서,상기 버텍스 간의 연결 관계에 관한 정보는 상기 버텍스에 대한 엣지 집합과 인접 행렬을 포함하는,인공신경망 기반 특징 정보 처리 방법."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 엣지 집합과 상기 인접 행렬은 K-최근접 이웃 알고리즘, 랜덤 샘플링 알고리즘, 혹은 들로네 삼각 분할 알고리즘을 이용하여 획득되는, 인공신경망 기반 특징 정보 처리 방법."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8 항에 있어서,상기 특징 벡터는 그래프 컨볼루션 레이어(graph convolution layer)를 통해 획득되는,인공 신경망 기반 특징 정보 처리 방법."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서, 상기 특징 벡터는 K-최근접 이웃 알고리즘 혹은 랜덤 샘플링 알고리즘을 이용하여 획득되는,인공 신경망 기반 특징 정보 처리 방법."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8 항에 있어서,상기 버텍스는 상기 특징 맵과 컨볼루션 레이어(convolution layer)를 통해 획득한 상기 특징맵에 대한 중요도공개특허 10-2023-0068058-4-맵(importance map)을 이용하여 획득되는,인공 신경망 기반 특징 정보 처리 방법."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "데이터를 저장하는 메모리;상기 메모리를 제어하는 프로세서;를 포함하되,상기 프로세서는,인공 신경망을 기반으로 처리된 버텍스를 포함하는 그래프와 특징 벡터를 획득하고,상기 그래프와 상기 특징 벡터를 기반으로 이미지의 특징 맵을 출력하고,상기 특징 맵을 기반으로 상기 이미지의 화소별 분석 결과를 획득하되,상기 그래프는 상기 버텍스의 위치와 상기 버텍스 간의 연결 관계에 관한 정보를 포함하는, 인공 신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 인공 신경망은 GCN(Graph Convolution Network)인,인공 신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15 항에 있어서,상기 출력되는 이미지의 특징 맵은 컨볼루션 레이어(convolution layer)를 통해 출력되는,인공 신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15 항에 있어서,상기 화소별 분석 결과는 전 연결 레이어(fully connected layer)를 통해 획득되는,인공 신경망 기반 특징 정보 처리 장치."}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 인공신경망 기반 특징 정보 처리 방법 및 장치에 대한 것이다. 본 개시의 일 실시예에 따른 인공 신경 망 기반 특징 정보 처리 장치는 데이터를 저장하는 메모리, 메모리를 제어하는 프로세서를 포함하되, 프로세서는 이미지의 특징 맵을 기반으로 버텍스를 포함하는 그래프를 추출하고, 버텍스에 대응되는 특징 벡터를 추출하고, 그래프와 특징 벡터를 인공 신경망을 기반으로 처리하며, 그래프는 버텍스의 위치와 버텍스 간의 연결 관계에 관 한 정보를 포함할 수 있다."}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공 신경망 기반 특징 정보 처리 방법 및 장치에 대한 것이다. 보다 상세하게는, 메모리 및 파라미 터 측면에서 효율적인 인공신경망 기반 특징 정보 처리 기술에 대한 것이다."}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 기계학습 또는 머신 러닝(machine learning)이라 불리는 기술이 소프트웨어 기술로부터 금융, 경제에 이 르기까지 다양한 분야에 응용되고 있으며 특히 컴퓨터 비전 및 영상처리 분야의 비약적인 발전을 선도하는 핵심 기술로 자리 잡고 있다. 이러한 기계학습 기술은 인공지능(Artificial Intelligent: AI)의 한 분야로 주어진 데이터로부터 패턴이나 특 성을 학습하여 새로운 데이터에 대해 분석을 수행해낼 수 있도록 하는 알고리즘 및 관련 분야를 의미한다. 최근 들어 딥러닝(deep learning)이라는 기계학습 기법이 핵심 기술로 대두되면서 관련 기술 및 응용 분야에 대한 관심이 높아지고 있다. 딥러닝 기법이란 생물의 신경계를 모방한 인공신경망(artificial neural network)의 모델로서, 기존의 인공신경 망 모델이 얇은 층의 뉴런 모델들의 연결로 구성되어 있다면, 딥러닝 기법은 뉴런 모델의 층을 깊게 쌓아 올림 으로써 신경망의 학습 능력을 높이는 모델을 적용하는 기술이다. 인공신경망 기반의 영상정보 처리에는 대표적으로 다수의 파라미터(parameter)와 메모리 사용량이 요구되는 CNN(Convolutional Neural Networks)이 이용되고 있다. CNN(convolutional neural network)을 구성하는 컨볼루션 레이어(convolution layer)는 컨볼루션(convolution) 연산과 바이어스(bias) 덧셈, 비선형 활성함수(non-linear activation)으로 구성된다. -채널 2차원 특징맵 을 입력으로 하여 - 채널 특징맵 을 출력하는 경우 2D 컨볼루션 레이어의 연산과정은 식과 같이 표현된다."}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "식 의 과 은 각각 가중치 및 바이어스 파라미터이며 학습에 따라 갱신된다. 위의 구성에서 학습의 대상이 되는 파라메터의 수는 이며, 해당 레이어의 출력 특징 맵을 저장하기 위한 메모리 는 에 비례한다. 한편, 일반적인 영상과 그로부터 도출된 특징 맵에는 중복된 정보가 많이 포함되어 있게 되므로, 영상의 실질적 인 유효 정보량은 특징 맵의 메모리 소모량보다 낮기 때문에 구현 시의 비효율성이 존재한다."}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은 파라미터와 메모리 사용량이 감소시킬 수 있는 인공신경망 기반의 특징 정보 처리를 수행하는 데 있다. 본 개시의 목적은 CNN(Convolutional neural networks)을 대신하여, 메모리 및 파라메터 수 측면에서 효율적인 GCN(Graph Convolution Networks) 등의 인공 신경망을 영상 처리에 이용하는 데 있다. 본 개시의 목적은 인공 신경망의 입력 데이터에 융통성을 부여하여 인공 신경망을 환경 적응적인 정보 처리에 이용하는 데 있다. 본 개시의 다른 목적 및 장점들은 하기의 설명에 의해서 이해될 수 있으며, 본 개시의 실시예에 의해 보다 분명 하게 알게 될 것이다. 또한, 본 개시의 목적 및 장점들은 특허청구범위에 나타낸 수단 및 그 조합에 의해 실현 될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른 인공신경망 기반 특징 정보 처리 장치는, 데이터를 저장하는 메모리, 상기 메모리 를 제어하는 프로세서를 포함하되, 상기 프로세서는, 이미지의 특징 맵을 기반으로 버텍스를 포함하는 그래프를 추출하고, 상기 버텍스에 대응되는 특징 벡터를 추출하고, 상기 그래프와 상기 특징 벡터를 인공 신경망을 기반 으로 처리하며, 상기 그래프는 상기 버텍스의 위치와 상기 버텍스 간의 연결 관계에 관한 정보를 포함할 수 있 다.한편, 상기 인공 신경망은 GCN(Graph Convolution Network)일 수 있다. 한편, 상기 버텍스 간의 연결 관계에 관한 정보는 상기 버텍스에 대한 엣지 집합과 인접 행렬을 포함할 수 있다. 한편, 상기 엣지 집합과 상기 인접 행렬은 K-최근접 이웃 알고리즘, 랜덤 샘플링 알고리즘, 혹은 들로네 삼각 분할 알고리즘을 이용하여 획득될 수 있다. 한편, 상기 특징 벡터는 그래프 컨볼루션 레이어(graph convolution layer)를 통해 획득될 수 있다. 한편, 상기 특징 벡터는 K-최근접 이웃 알고리즘 혹은 랜덤 샘플링 알고리즘을 이용하여 획득될 수 있다. 한편, 상기 버텍스는 상기 특징 맵과 컨볼루션 레이어(convolution layer)를 통해 획득한 상기 특징맵에 대한 중요도 맵(importance map)을 이용하여 획득될 수 있다. 본 개시의 일 실시예에 따른 인공신경망 기반 특징 정보 처리 방법은, 이미지의 특징 맵을 기반으로 버텍스로 이루어진 그래프를 추출하는 단계, 상기 버텍스에 대응되는 특징 벡터를 추출하는 단계, 상기 그래프와 상기 특 징 벡터를 인공 신경망을 기반으로 처리하는 단계를 포함하되, 상기 그래프는 상기 버텍스의 위치와 상기 버텍 스 간의 연결 관계에 관한 정보를 포함할 수 있다. 한편, 상기 인공 신경망은 GCN(Graph Convolution Network)일 수 있다. 한편, 상기 버텍스 간의 연결 관계에 관한 정보는 상기 버텍스에 대한 엣지 집합과 인접 행렬을 포함할 수 있다. 한편, 상기 엣지 집합과 상기 인접 행렬은 K-최근접 이웃 알고리즘, 랜덤 샘플링 알고리즘, 혹은 들로네 삼각 분할 알고리즘을 이용하여 획득될 수 있다. 한편, 상기 특징 벡터는 그래프 컨볼루션 레이어(graph convolution layer)를 통해 획득될 수 있다. 한편, 상기 특징 벡터는 K-최근접 이웃 알고리즘 혹은 랜덤 샘플링 알고리즘을 이용하여 획득될 수 있다. 한편, 상기 버텍스는 상기 특징 맵과 컨볼루션 레이어(convolution layer)를 통해 획득한 상기 특징맵에 대한 중요도 맵(importance map)을 이용하여 획득될 수 있다. 본 개시의 일 실시예에 따른 인공신경망 기반 특징 정보 처리 장치는, 데이터를 저장하는 메모리, 상기 메모리 를 제어하는 프로세서를 포함하되, 상기 프로세서는 인공 신경망을 기반으로 처리된 이미지의 특징맵에 대한 버 텍스를 포함하는 그래프와 특징 벡터를 획득하고, 상기 그래프와 상기 특징 벡터를 기반으로 상기 이미지의 특 징 맵을 출력하고, 상기 특징 맵을 기반으로 상기 이미지의 화소별 분석 결과를 획득하되, 상기 그래프는 상기 버텍스의 위치와 상기 버텍스 간의 연결 관계에 관한 정보를 포함할 수 있다."}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 인공 신경망 기반의 특징 정보 처리 시 파라미터와 메모리 사용량을 감소시킬 수 있다. 본 개시의 일 실시예에 따르면, 인공 신경망 기반의 환경 적응적인 정보 처리를 수행할 수 있다. 본 개시의 일 실시예에 따르면, 인공 신경망 기반의 특징 정보 처리 시 유연한 형태의 리셉티브 필드(receptive field)를 가질 수 있다. 본 개시의 실시 예들에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 이하의 본 개시의 실시 예들에 대한 기재로부터 본 개시의 기술 구성이 적용되는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 도출되고 이해될 수 있다. 즉, 본 개시에서 서술하는 구성을 실시함에 따 른 의도하지 않은 효과들 역시 본 개시의 실시 예들로부터 당해 기술 분야의 통상의 지식을 가진 자에 의해 도 출될 수 있다."}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위함이며, 구성요소들이 반드 시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위 로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들을 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 개시의 범위에 포함된다. 또한, 다양한 실시 예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 개시의 범위에 포함된다. 본 개시를 상세히 설명함에 앞서, 본 개시에 적용될 수 있는 인공신경망 중 하나인 GCN(Graph Convolution Network)에 대하여 설명하고자 한다. GCN(Graph Convolution Network)은 언어처리, 분자구조, 소셜 네트워크 등 개별적으로 분산되어 있는 정보의 분 석에 일반적으로 사용될 수 있다. 그래프 컨볼루션(graph convolution)의 연산 과정은 식 와 같다."}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "그래프 컨볼루션 레이어의 입력은 n개의 버텍스(vertex)과 그를 연결하는 엣지(edge)으로 구성된 그래프 G=(V,E)와 각 버텍스에 대응되는 - 채널 특징 벡터이다. 식 의 는 - 채널 특징벡터를 각 행 으로 가지는 행렬이며, W 와 b는 각각 가중치(weight) 행렬과 바이어스(bias) 벡터 파라미터이다. 또한 식 의 A는 N×N 인접행렬으로서, 그래프의 엣지에 의한 연결관계, 즉 버텍스 간 연 결 관계를 표현한다. 여기서 그래프 컨볼루션 레이어의 파라미터 수는 으로 이 고 이라 가정하면 2차원 컨볼루션 레이어의 파라미터 수의 약 배이다.표 1"}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "표 1은 2차원 컨볼루션 레이어와 그래프 컨볼루션 레이어의 비교를 통해 차이를 요약한 표이다. 두 레이어의 입력, 출력 특징의 채널 수를 각각 로 동일하다고 가정하면, 학습 파라미터의 수는 2 차원 컨볼루션 레이어가 약 배 많기 때문에 그래프 컨볼루션 레이어가 학습 파라미터의 저장용량 측면에 서 효율적이다. 영상 정보 처리 장치에 제공되는 영상신호는 주로 2차원 배열의 형태이기 때문에, 추가적인 과정 없이 컨볼루션 레이어(convolution layer)를 이용할 수 있다는 장점이 있다. 한편, CNN에서의 특징 맵의 좌표는 공간 또는 사 간 좌표에 해당하기 때문에 정보 간의 공간적인 관계를 해석하는데 유리하지만 모든 화소에 특징벡터를 위치시 키기 때문에 정보의 중복이 많은 것으로 생각할 수 있다. <표 1>의 레이어 구성에서 출력 특징 맵의 저장에는 에 비례하는 메모리가 필요하다. GCN의 그래프의 버텍스(vertex)와 엣지(edge)에 의한 연관 관계를 적절히 설정하여 N<HW를 만족하면 그래프 컨볼루션 레이어(Graph Convolution Layer)가 2차원 컨볼루션 레이어 보다 낮은 메모리 요구량을 가진다. 일반적인 영상에 포함된 정보는 공간적으로 중복되는 경우가 많기 때문에 정보처리에 유용한 버텍스(vertex)의 수는 영상의 화소 수보다 훨씬 작다(N≪사전 실험에서 특징 맵의 화소 수 (H×W)에 비해 버텍스(vertex)의 수(N)는 화소 수의 1/10에도 미치지 못하게 된다. 한편, GCN(Graph Convolution Network)은 희소한 형태의 입력이나 개별 노드의 연결관계에 관련된 정보처리에 적합하고 메모리 복잡도 및 신경망 파라메터 저장용량이 낮다는 장점이 있으나 2차원 영상에 적용되기 힘들다는 측면이 있다. 이하, 도면을 참조하여 상세히 설명되는 본 개시에서는, 특징 맵 또는 입력영상으로부터 그래프(graph) 및 버텍 스(vertex) 별 특징 벡터를 도출하여 GCN(Graph Convolution Network)을 적용하여 본 개시에서 제안하는 특징 정보 처리 기술에 대하여 설명한다. 그러나, 이는 본 개시의 설명의 명료함을 위한 것이어서, 본 개시의 인공 신경망이 GCN 외에 다른 네트워크 구성일 수 있음은 자명하며, 본 개시가 이에 한정되는 것은 아니다. 도 1은 본 개시의 일 실시예에 따른 특징 맵으로부터 그래프의 변환을 도시한 것이다. 보다 상세하게는, 그래프 특징 인코더에 의하면 특징 맵의 변환 과정을 설명하기 위한 것이다. 그래프 특징 인코더 모듈은 H×W의 공간적 크기와 의 채널을 가지는 특징 맵(feature map)을 입력으 로 받을 수 있다. 특징 맵을 기반으로 인코더는 임의의 N개의 버텍스(vertex, V)로 이루어진 그래프와 개 별 버텍스(vertex)에 대응되는 채널 특징 벡터들을 추출할 수 있다. 즉, 인코더는 특징 맵을 로 표현되는 특징 벡터 와 버텍스(V) 및 버텍스를 연결하는 엣지(Edge)을 포함하는 그래프 G=(V,E) 로 변환하여 표현할 수 있다. 특징 벡터와 그래프는 이후 인공 신경망(예를 들어, GCN(Graph Convolution Network))에 의한 메모리 효율적인 후속 정보처리가 가능할 수 있다. 한편, 도 1의 인코더는 도 8의 인공신경망 기반 특징 정보 처리 장치이거나, 이에 포함될 수 있으며, 하기 도 2 내지 도 6을 참조하여 설명하는 특징 정보 처리 방법을 수행하는 주체일 수 있다. 그래프 특징 변환 과정과 관련된 특징 정보 처리 과정에 대하여는 하기에서 다른 도면을 참조하여 더욱 상세하 게 설명한다. 도 2는 본 개시의 일 실시예에 따른 특징 맵과 그래프의 변환 과정을 도시한 것이다. 일 예로서, 입력 영상 혹은 이미지가 주어진다고 가정한다. 입력 이미지는 2차원 컨볼루션 레이어(2D conv. layer, 201)를 거쳐 처리될 수 있으며, 이를 통해 이미지에 대한 특징 맵이 생성될 수 있다. 또한, 이미지에 대한 특징 맵은 i X j 크기를 갖는 c 채널로 표현될 수 있으며, (혹은 F(i, j))와 같 이 표현될 수 있다. 입력 영상(이미지)에 대한 그래프 특징을 추출을 하기 위해 버텍스는 입력 특징 맵과 2D 컨 볼루션 레이어를 이용하여 얻은 중요도 맵(importance map) H(i,j)을 이용할 수 있다. 일 예로서, 중요도 맵은 특징 맵을 다시 2차원 컨볼루션 레이어에 통과시킴으로써 획득될 수 있다. 획득된 중요도 맵은 그래프의 버텍스를 획득하는 데 사용될 수 있다. 그래프의 버텍스는 비-맥시멀 서프레션 (non-maximal suppression, 203)을 거쳐 추출될 수 있다. 비-맥시멀 서프레션을 거쳐 추출된 그래프의 버텍스는 인코딩 그래프 구성(encoding graph construction, 204) 모듈 및 그래프 구성(graph construction, 205) 모듈에 입력될 수 있다. 그래프의 버텍스 간을 잇는 선을 나타내는 엣지(Edge) 집합 E와 각 버텍스간 연결 관계를 나타내는 인접행렬 A 는 그래프 구성(graph construction, 205) 모듈을 통해 획득될 수 있다. 그래프 구성 모듈은 일 예로서, K-최근 접 이웃(K-nearest neighbor), 랜덤 샘플링(random sampling), 들로네 삼각분할(Delaunay triangulation) 등의 알고리즘을 기반으로 구현될 수 있다. 그래프 구성 모듈에서 획득된 그래프 G는 버텍스(V)의 위치와 버텍스 간의 연결관계에 관한 정보만을 포함하므 로, 이후의 인공 신경망(예를 들어, GCN) 기반의 정보 처리를 위해서는 특징 맵 F(i,j)을 버텍스 별 특징벡터 로 변환하는 것이 필요할 수 있다. 이를 위해 본 구현예에서는 인코딩 그래프 구성(encoding graph construction, 204) 모듈을 이용하여 특징 맵의 화소를 입력 버텍스로 하고 이에 대응되는 그래프의 버텍스 V를 출력 버텍스로 하는 그래프 를 생성할 수 있다. 일 예로서, 특징 맵의 화소와 그래프의 버텍스는 1:1 대응일 수도 있으나, n:1 대응될 수도 있다. 즉, 특 징 맵의 화소를 그래프의 각 버텍스와 연관시킬 수 있다. 인코딩 그래프 구성(Encoding graph construction) 모 듈은 그래프 구성(graph construction) 모듈과 유사하게 K-최근접 이웃(K-nearest neighbor), 랜덤 샘플링 (random sampling) 등의 알고리즘을 이용할 수 있다. 이후, 추출된 특징 맵의 화소 별 특징 벡터를 그래프 컨볼루션 레이어(graph convolution layer, 206)를 통과시 켜 특징 벡터 를 얻을 수 있다. 위와 같은 도 2의 과정에 의하면, 버텍스와 버텍스 간의 연결 관계를 나타내는 엣지를 포함하는 그래프 G=(V, E)는 그래프 컨볼루션 레이어를 통과하여 획득된 특징 벡터와 각각 연관될 수 있다. 보다 상세하게는, 그 래프의 각 버텍스는 다른 버텍스와 연결될 수 있으며, 각 버텍스에는 특징 벡터가 연관될 수 있다. 한편, 위와 같은 과정은 도 1의 인코더, 혹은 도 8의 인공신경망 기반 특징 정보 처리 장치에 의해 수행될 수 있으며, 도 6, 및 도 7의 인공신경망 기반 특징 정보 처리 방법에 포함될 수 있다. 이에 대하여는, 하기에서 각 도면을 참조하여 더욱 상세하게 설명할 것이다. 도 3은 본 개시의 일 실시예에 따른 그래프로부터 특징 맵의 변환을 도시한 것이다. 일 예로서, 도 3은 상기에서 설명된 특징 맵의 그래프-특징 벡터 변환을 통해 생성된 그래프(G=(V,E)) 및 특징 벡터 를 기반으로 할 수 있다. 영상의 분할(segmentation), 움직임 추정 등과 같이 특징 맵이나 이미지의 형태의 출력이 요구되는 응용 예에 본 개시가 적용되기 위해, 도 3과 같은 변환이 수행될 수 있다. 도 3의 변환은 도 2의 변환의 역과정에 해당할 수 있으며, 디코더 (Decoder) 모듈 혹은 도 8의 인공신경망 기반 특징 정보 처리 장치에 의해 수행될 수 있다. 도 3의 변환 과정은 그래프 및 특징 벡터를 특징 맵으로 변환하는 과정에 대한 것일 수 있다. 일 예로서, 도 3의 그래프로부터의 특징 맵의 변환은 도 1의 인코더와는 반대로 버텍스와 그간의 연결 관계인 엣지를 포함하는 그래프를 입력으로 하고, 특징 맵의 화소를 출력으로 하는 그래프 와 인공신경망(예를 들어, GCN)으로 구현될 수 있다. 일 예로서, 인코더에서 생성된 그래프 에서 각 버텍스와 연관된 특징 맵 의 화소를 연결하는 엣지의 방향을 반대로 하면 버텍스에서 특징맵의 화소로 향하는 엣지를 얻을 수 있기 때문 에 를 구할 수 있다. 를 이용하면, 출력 특징맵 을 획득할 수 있다. 이 과정에 대하여는 도 4, 도 5, 도 7 및 도 8을 참조하여 더욱 상세하게 설명할 것이다. 도 4는 본 개시의 일 실시예에 따른 특징 맵 및 그래프 변환을 통한 특징 맵 출력을 도시한 것이다. 보다 상세 하게는, 영상 분할(image segmentation)이나 깊이 추정과 같이 화소 별 분석(예를 들어, 분류/추정) 결과가 요 구될 경우, 본 도 4와 도 5의 인코더 및 디코더를 이용하는 실행 예에 대한 것이다. 일 예로서, 도 4의 특징 맵 및 그래프 변환을 수행하는 특징 정보 처리 시스템은 도 2 내지 도 3의 과정과 연관 될 수 있으며, 컨볼루션 레이어(예를 들어, CNN), 인코더, 인공 신경망(예를 들어, 그래프 컨볼루션 네트 워크(Graph Convolution Network, GCN), 디코더 및 컨볼루션 레이어(예를 들어, CNN)를 포함할 수 있다. 일 예로서, 인코더는 도 1의 인코더를 포함하며, 디코더는 도 3의 과정을 수행하는 디코더를 포함할 수 있다. 또한, 상기 인코더 및 디코더는 도 8의 특징 정보 처리 장치에 포함되거나, 특징 정보 처리 장치 자체 로 표현될 수 있다. 일 예로서, 입력 영상은 컨볼루션 레이어를 통해 인코더에 입력될 수 있다. 인코더에 입력되는 입력 영상 은 특징 맵으로 표현된 형태일 수 있다. 인코더는 도 1 및 도 2를 참조하여 설명한 과정을 수행하여 특징 맵을 특징 벡터와 연관된 그래프 특징으로 변환할 수 있고, 그래프 특징은 인공 신경망(예를 들어, GCN)을 이용 하여 처리될 수 있다. 이후, 도 3의 변환을 수행하는 디코더(decoder) 및 컨볼루션 레이어(convolution layer)를 이용하여 출 력을 도출할 수 있다. 도출된 출력은 화소를 표현하는 특징 맵의 형태일 수 있다. 주된 고준위 처리는 메모리 효율적인 그래프 기반 인공 신경망을 통해 이루어질 수 있으나, 디코더 및 컨볼루션 레이어를 더 활 용함으로써 특징 맵 출력하여 화소 별 분석 결과를 획득하기 위해 사용할 수 있다. 도 5는 본 개시의 일 실시예에 따른 특징 맵과 그래프 변환에 따른 이미지 분류 과정을 도시한 것이다. 보다 상세하게는, 도 5는 도 4의 과정을 보다 상세히 설명하기 위한 도면으로서, 특징 맵 및 그래프 변환을 통 한 특징 맵 출력하여 화소 별 분석을 통한 이미지 분류 결과를 도출하는 응용 예에 대한 도면이다. 도 5의 과정을 설명하기에 앞서, 도 4의 과정을 통해 인코더를 통해 특징 맵과 그래프-특징 벡터 간의 변 환이 수행되고, 인공 신경망을 통해 특징 정보의 처리가 수행되었다고 가정한다. 즉, 이미지에 대한 특징 맵을 획득한 후 도 2의 특징 맵-그래프 특징 변환 과정을 수행하는 모듈을 이용하여 그래프 특징의 형태로 변환 한 후, 그래프 기반의 신경망를 통해 일정 처리가 되었다고 가정한다. 이후, 풀링 레이어(pooling layer) 및 전 연결 레이어(fully-connected layer)을 통한 특징 벡터 및 그래프의 화소 별 분석이 수행될 수 있다. 일 예로서, 화소별 분석에는 화소 별 이미지 분류 결과나 이미지의깊이 추정 결과 등이 포함될 수 있다. 일 예로서, 풀링 레이어 및/혹은 전 연결 레이어는 디코더에 포함될 수 있으며, 디코더는 도 4의 디 코더일 수 있다. 도 6은 본 개시의 일 실시예에 따른 인공 신경망 기반 특징 정보 처리 방법을 도시한 것이다. 보다 상세하게는, 상기에서 언급한 특징 맵-그래프 특징 변환 과정에 기초한 인공 신경망 기반 특징 정보 처리 방법의 일 예를 설명하기 위한 도면이다. 도 6의 과정은 상기에서 언급한 인코더 혹은 도 8의 인공신경망 기반 특징 정보 처리 장치에 의해 수행될 수 있다. 먼저, 특징 맵을 기반으로 그래프를 추출(S601)하는 과정이 수행될 수 있다. 특징 맵은 입력 영상(이미지)을 기 반으로 할 수 있으며, 그래프는 버텍스와 각 버텍스 간의 연결 관계에 관한 정보를 포함하도록 표현될 수 있다. 일 예로서, 버텍스는 특징 맵과 컨볼루션 레이어(convolution layer)를 통해 획득한 특징맵에 대한 중요도 맵 (importance map)을 이용하여 획득될 수 있다. 상기에서 언급한 바와 같이, 특징 맵에서 그래프를 추출하는 과 정은 2차원 컨볼루션 레이어 및 비-맥시멀 서프레션을 거치는 과정을 포함할 수 있다. 또한, 일 예로서, 버텍스 간의 연결 관계에 관한 정보는 버텍스에 대한 엣지 집합과 인접 행렬을 포함할 수 있다. 또한, 엣지 집합과 인 접 행렬은 K-최근접 이웃 알고리즘, 랜덤 샘플링 알고리즘, 혹은 들로네 삼각 분할 알고리즘 등을 이용하여 획 득될 수 있다. 이후, 추출된 그래프의 버텍스에 대한 특징 벡터를 추출(S602)하는 과정이 수행될 수 있다. 특징 벡터는 그래프 컨볼루션 레이어(graph convolution layer)를 통해 획득될 수 있다. 일 예로서, 특징 벡터는 K-최근접 이웃 알 고리즘 혹은 랜덤 샘플링 알고리즘을 이용하여 획득될 수 있다. 이후, 그래프 및 특징 벡터를 인공신경망을 기반으로 처리(S603)할 수 있다. 일 예로서, 여기서 인공신경망은 그래프 컨볼루션 네트워크(GCN)일 수 있다. 이에 의하면, 영상정보처리에서 주로 이용되는 특징 맵 자체의 처리 를 대신하여, 메모리 및 파라메터 수 측면에서 효율적인 그래프와 특징 벡터 형태를 이용할 수 있다. 본 개시 에 의해 그래프를 구성하면 컨볼루션 레이어의 사각형의 리셉티브 필드(receptive field)와는 달리 유연한 형태 의 리셉티브 필드(receptive field)를 가질 수 있다. 또한, 다수의 인공신경망을 본 개시에서 제시한 바와 같이 구동하면, 효율적인 데이터 처리가 가능할 수 있다. 한편, 도 6은 본 개시의 일 실시예에 해당하므로, 본 개시가 이에 한정되는 것은 아니어서, 일부 단계가 추가되 거나, 일부 단계가 제거되거나, 일부 단계가 동시에 수행되는 것도 가능하며, 순서가 변경되는 것도 가능하다. 도 7은 본 개시의 다른 일 실시예에 따른 인공 신경망 기반 특징 정보 처리 방법을 도시한 것이다. 보다 상세하게는, 상기에서 언급한 그래프 특징-특징 맵 변환 과정에 기초한 인공 신경망 기반 특징 정보 처리 방법의 일 예를 설명하기 위한 도면이다. 도 7의 과정은 상기에서 언급한 디코더 혹은 도 8의 인공신경망 기반 특징 정보 처리 장치에 의해 수행될 수 있으며, 도 2의 역 과정의 일부 혹은 전부를 포함할 수도 있다. 일 예로 서, 도 7의 특징 맵 및 이미지 화소별 처리가 필요한 경우에 수행될 수 있다. 일 예로서, 도 7의 인공 신경망 기반 특징 정보 처리 방법은 도 6의 인공 신경망 기반 특징 정보 처리 방법이 수행된 이후에 수행될 수 있으나, 본 개시가 이에 한정되는 것은 아니다. 먼저, 인공 신경망을 기반으로 처리된 그래프와 특징 벡터가 획득(S701)될 수 있다. 일 예로서, 그래프와 특징 벡터는 이미지의 특징 맵으로부터 추출된 것일 수 있으며, 인공 신경망은 GCN을 포함한 다양한 인공 신경망이 활용될 수 있다. 그래프는 버텍스와 버텍스 간의 연결 관계를 포함한 정보에 의해 표현될 수 있으며, 버텍스 간 의 연결 관계를 포함한 정보는 도 6에서 설명한 바와 동일할 수 있다. 이후, 그래프와 특징 벡터를 기반으로 이미지의 특징 맵을 출력(S702)할 수 있다. 그래프 및 그래프의 버텍스와 관련된 특징 벡터들은 이미지의 화소와 연관될 수 있다. 특징 맵의 화소와 그래프의 버텍스는 1:1 대응일 수도 있으나, n:1 대응될 수도 있다. 이후, 특징 맵을 기반으로 이미지의 화소 별 분석 결과를 획득(S703)할 수 있다. 이미지의 화소별 분석 결과에 는 이미지 깊이 추정, 영상 분할 및/혹은 움직임 추정 등의 화소별 분류/추정 결과가 포함될 수 있다. 위와 같은 분석 결과는 풀링 레이어 및/혹은 전 연결 레이어 등을 거쳐 출력될 수 있다. 도 8은 본 개시의 일 실시예에 따른 인공 신경망 기반 특징 정보 처리 장치를 도시한 것이다. 보다 상세하게는, 상기에서 언급한 그래프 특징-특징 맵 혹은 특징 맵-그래프 특징 변환 과정에 기초한 인공 신 경망 기반 특징 정보 처리 방법을 수행할 수 있는 장치의 일 예를 설명하기 위한 도면이다. 도 6 및 도 7의 과 정은 도 8의 인공신경망 기반 특징 정보 처리 장치에 의해 수행될 수 있으며, 상기에서 인코더, 디코더 및/혹은 임의의 모듈이 수행하는 과정은 도 8의 장치에 의해 수행될 수 있다. 일 예로서, 도 8의 인공신경망 기반 특징 정보 처리 장치는 데이터를 저장하는 메모리, 외부와 데이 터를 송수신하는 송수신부 및 메모리 및/혹은 송수신부를 제어하는 프로세서를 포함할 수 있다. 한편, 도면에 포함된 컴포넌트 외에 다른 컴포넌트를 더 포함할 수 있다. 일 예로서, 프로세서가 인코더로서의 역할을 포함하는 경우, 프로세서는 특징 맵을 기반으로 버텍스 를 포함하는 그래프를 추출하고, 버텍스에 대응되는 특징 벡터를 추출하고, 그래프와 특징 벡터를 인공 신경망 을 기반으로 처리하며, 그래프는 버텍스의 위치와 버텍스 간의 연결 관계에 관한 정보를 포함할 수 있다. 한편, 인공 신경망은 GCN(Graph Convolution Network)일 수 있다. 또한, 버텍스 간의 연결 관계에 관한 정보는 버텍스 에 대한 엣지 집합과 인접 행렬을 포함할 수 있다. 또한, 엣지 집합과 인접 행렬은 K-최근접 이웃 알고리즘, 랜 덤 샘플링 알고리즘, 혹은 들로네 삼각 분할 알고리즘을 이용하여 획득될 수 있다. 또한, 특징 벡터는 그래프 컨볼루션 레이어(graph convolution layer)를 통해 획득될 수 있으며, K-최근접 이웃 알고리즘 혹은 랜덤 샘플 링 알고리즘을 이용하여 획득될 수 있다. 또한, 버텍스는 특징 맵과 컨볼루션 레이어(convolution layer)를 통 해 획득한 특징맵에 대한 중요도 맵(importance map)을 이용하여 획득될 수 있다. 한편, 다른 일 예로서, 프로세서가 디코더로서의 역할을 포함하는 경우, 프로세서는 인공 신경망 기반 처 리된 그래프와 특징 벡터를 획득하고, 그래프와 특징 벡터를 기반으로 이미지의 특징 맵을 출력할 수 있다. 일 예로서, 특징 맵은 입력 영상(이미지)로부터 추출된 것일 수 있으며, 또한, 특징 맵을 기반으로 이미지의 화소 별 분석 결과를 획득할 수 있다. 일 예로서, 그래프는 버텍스는 특징 벡터와 관련되어 표현될 수 있으며, 버텍 스의 위치와 버텍스 간의 연결 관계에 관한 정보를 포함할 수 있다. 일 예로서, 인공 신경망은 GCN(Graph Convolution Network)일 수 있으며, 출력되는 이미지의 특징 맵은 컨볼루션 레이어(convolution layer)를 통해 출력될 수 있다. 또한, 화소별 분석 결과는 영상 분할, 이미지 분류, 깊이 추정, 이미지 내 객체의 움직임 추 정 등에 사용될 수 있으며, 전 연결 레이어(fully connected layer)를 통해 획득될 수 있다. 도 9는 본 개시의 일 실시예에 따른 특징 정보 처리에 의한 영역 분할 결과를 도시한 것이다. 본 개시에서 설명한 특징맵-그래프 특징 변환 및 그래프 컨볼루션 레이어를 이용하여 구현한 신경망과 CNN 기반 의 신경망을 이용한 시티스케이프 데이터셋(Cityscapes dataset)을 대상으로 한 성능비교를 실시하였다. 여기서, 변환 및 그래프 컨볼루션 레이어를 포함하는 신경망은 GCN을 이용하였다. 두 신경망을 이용하여 FPN(Feature Pyramid Network)를 구축하였다. CNN 및 GCN간 성능 비교는 하기 <표 2>와 같다. 표 2 정확도(mIoU) 메모리 사용량 파라메터 저장 용량 CNN 기반 FPN 70.4% 20GB 2433MB GCN 기반 FPN 68.2 12GB 606MB 두 신경망은 유사한 정확도를 보이지만, 본 발명의 모듈을 사용한 그래프 컨볼루션 기반의 방법이 메모리 사용 량과 파라메터 저장용량에서 확연히 효율적임을 확인할 수 있다. 본 개시의 다양한 실시 예는 모든 가능한 조합을 나열한 것이 아니고 본 개시의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시 예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있다. 또한, 본 개시의 다양한 실시 예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 또한, 하나의 소프트웨어가 아닌 하나 이상의 소프트웨어의 결합에 의해 구현될 수 있으며, 일 주 체가 모든 과정을 수행하지 않을 수 있다. 예를 들어, 고도의 데이터 연산 능력 및 방대한 메모리를 요구하는 딥러닝 과정은 클라우드나 서버에서 이루어지고, 사용자 측은 딥러닝이 완료된 인공 신경망만을 이용하는 방식 으로 구현될 수도 있으며, 이에 한정되지 않음은 자명하다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(general processor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 예를 들어, 상기 범용 프로세서를 포함한 다양한 형태 를 띨 수도 있다. 하나 혹은 그 이상의 결합으로 이루어진 하드웨어로 개시될 수도 있음은 자명하다. 본 개시의 범위는 다양한 실시 예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행 가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러 한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다. 일 실시예로서, 본 개시의 일 실시예에 따른 비-일시적 컴퓨터-판독가능 매체에 저장된 컴퓨터 프로그램은, 컴 퓨터에서, 이미지의 특징 맵을 기반으로 버텍스로 이루어진 그래프를 추출하는 단계, 상기 버텍스에 대응되는 특징 벡터를 추출하는 단계, 상기 그래프와 상기 특징 벡터를 인공 신경망을 기반으로 처리하는 단계를 수행하 되, 상기 그래프는 상기 버텍스의 위치와 상기 버텍스 간의 연결 관계에 관한 정보를 포함할 수 있다. 한편, 각 도면을 참조하여 설명한 내용은 각 도면에만 한정되는 것은 아니며, 상반되는 내용이 없는 한 상호 보 완적으로 적용될 수도 있다."}
{"patent_id": "10-2021-0153963", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상에서 설명한 본 개시는, 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 있어 본 개시의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경이 가능하므로, 본 개시의 범위는 전술한 실시 예 및 첨부된 도면에 의해 한정되는 것이 아니다."}
{"patent_id": "10-2021-0153963", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 특징 맵으로부터 그래프의 변환을 도시한 것이다. 도 2는 본 개시의 일 실시예에 따른 특징 맵과 그래프의 변환 과정을 도시한 것이다. 도 3은 본 개시의 일 실시예에 따른 그래프로부터 특징 맵의 변환을 도시한 것이다. 도 4는 본 개시의 일 실시예에 따른 특징 맵 및 그래프 변환을 통한 특징 맵 출력을 도시한 것이다. 도 5는 본 개시의 일 실시예에 따른 특징 맵과 그래프 변환에 따른 이미지 분류 과정을 도시한 것이다. 도 6은 본 개시의 일 실시예에 따른 인공 신경망 기반 특징 정보 처리 방법을 도시한 것이다. 도 7은 본 개시의 다른 일 실시예에 따른 인공 신경망 기반 특징 정보 처리 방법을 도시한 것이다. 도 8은 본 개시의 일 실시예에 따른 인공 신경망 기반 특징 정보 처리 장치를 도시한 것이다. 도 9는 본 개시의 일 실시예에 따른 특징 정보 처리에 의한 영역 분할 결과를 도시한 것이다."}
