{"patent_id": "10-2023-0122550", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0039725", "출원번호": "10-2023-0122550", "발명의 명칭": "비대면 치과 진단 서비스를 위한 치아 판별 자동 라벨링 서버 및 방법", "출원인": "주식회사 비디와이드", "발명자": "이정혁"}}
{"patent_id": "10-2023-0122550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "메모리; 및치아 판별을 위한 구강 이미지의 라벨링 처리를 수행하기 위한 프로세서;를 포함하고,상기 프로세서는,제1 구강 이미지 데이터를 데이터 생성 기준에 따라 처리하여 학습 데이터를 생성하되, 해당 구강 이미지의 구도에 따라 구분하여 상기 학습 데이터를 생성하고,생성된 상기 학습 데이터를 성능 평가 기준에 따라 검증하고,검증된 상기 학습 데이터를 이용하여 제2 구강 이미지 데이터로부터 치아 객체의 위치를 특정하고 속성을 매칭시키기 위한 라벨링 인공지능 모델을 생성하되, 구강 이미지의 구도별로 각각에 대응되는 라벨링 인공지능 모델을 별도로 생성하고, 및상기 제2 구강 이미지 데이터를 상기 라벨링 인공기능 모델에 입력하여 사전 설정된 분류에 따라 치아 객체를판별하는 라벨링 처리를 자동으로 수행하는, 치아 판별 자동 라벨링 서버."}
{"patent_id": "10-2023-0122550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 프로세서는,상기 학습 데이터를 생성할 때, 상기 제1 구강 이미지 데이터로부터 사전 설정된 전처리 기준에 따라 데이터 전처리를 수행하고,전처리된 상기 제1 구강 이미지 데이터에 사전 설정된 라벨링 기준에 따라 라벨링을 수행하고, 및상기 라벨링 수행된 상기 학습 데이터를 사전 설정된 형식으로 저장하는, 치아 판별 자동 라벨링 서버."}
{"patent_id": "10-2023-0122550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 프로세서는,상기 데이터 전처리를 수행할 때, 상기 복수의 구강 이미지 데이터로부터 오류 이미지 삭제, 비식별화 처리, 사이즈 표준화, 노이즈 제거 및 해상도 조절 중 적어도 하나 이상의 전처리 동작을 수행하고, 복수의 제1 구강 이미지 데이터의 데이터 정상성 비율을 조정하는, 치아 판별 자동 라벨링 서버."}
{"patent_id": "10-2023-0122550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "에 있어서,상기 프로세서는,좌측면 구강 이미지, 우측면 구강 이미지, 정면 구강 이미지, 상교합면 구강 이미지 및 하교합면 구강 이미지각각에 대응되는 라벨링 인공지능 모델을 생성하되, 각 구강 이미지의 구도에 따라 하이퍼 파라미터를 조정하고상기 치아 타입 속성의 판단 기준을 차별화 하여 상기 라벨링 인공지능 모델을 생성하는, 치아 판별 자동 라벨링 서버."}
{"patent_id": "10-2023-0122550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 4에 있어서,상기 프로세서는,상기 학습 데이터를 상기 성능 평가 기준에 따라 검증할 때, 상기 학습 데이터의 치아 타입 속성별 분류된 클래스 라벨링과 실제 클래스 라벨링을 비교하여 클래스 라벨링의 성공 여부를 판단하고,상기 분류된 클래스 라벨링 및 상기 실제 클래스 라벨링 각각은, 정상치 클래스, 충치 클래스 및 보철치 클래스를 포함하는, 치아 판별 자동 라벨링 서버."}
{"patent_id": "10-2023-0122550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 프로세서는,상기 학습 데이터를 상기 성능 평가 기준에 따라 검증할 때, 전처리 수행된 상기 제1 구강 이미지 데이터에 대한 전처리된 자동 라벨 범위와 실제 라벨 범위의 중복 정도를 파악하고, 파악된 중복 정도가 중복 기준치 이상인 경우, 전처리 성공으로 판단하는, 치아 판별 자동 라벨링 서버."}
{"patent_id": "10-2023-0122550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "치아 판별 자동 라벨링 서버에 의해 수행되는 방법에 있어서, 제1 구강 이미지 데이터를 데이터 생성 기준에 따라 처리하여 학습 데이터를 생성하되, 해당 구강 이미지의 구도에 따라 구분하여 상기 학습 데이터를 생성하는 단계;생성된 상기 학습 데이터를 성능 평가 기준에 따라 검증하는 단계;검증된 상기 학습 데이터를 이용하여 제2 구강 이미지 데이터로부터 치아 객체의 위치를 특정하고 속성을 매칭시키기 위한 라벨링 인공지능 모델을 생성하되, 구강 이미지의 구도별로 각각에 대응되는 라벨링 인공지능 모델을 별도로 생성하는 단계; 및상기 제2 구강 이미지 데이터를 상기 라벨링 인공기능 모델에 입력하여 사전 설정된 분류에 따라 치아 객체를판별하는 라벨링 처리를 자동으로 수행하는 단계를 포함하는, 치아 판별 자동 라벨링 방법."}
{"patent_id": "10-2023-0122550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 학습 데이터를 생성하는 단계는, 공개특허 10-2025-0039725-4-상기 제1 구강 이미지 데이터로부터 사전 설정된 전처리 기준에 따라 데이터 전처리를 수행하는 단계;전처리된 상기 제1 구강 이미지 데이터에 사전 설정된 라벨링 기준에 따라 라벨링을 수행하는 단계; 및상기 라벨링 수행된 상기 학습 데이터를 사전 설정된 형식으로 저장하는 단계를 포함하는, 치아 판별 자동 라벨링 방법."}
{"patent_id": "10-2023-0122550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 8 및 9 중 어느 한 항의 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "비대면 치과 진단 서비스를 위한 치아 판별 자동 라벨링 서버 및 방법이 개시된다. 본 발명의 일 실시예에 따른 치아 판별 자동 라벨링 서버는, 제1 구강 이미지 데이터를 데이터 생성 기준에 따라 처리하여 학습 데이터를 생 성하되, 해당 구강 이미지의 구도에 따라 구분하여 학습 데이터를 생성하고, 생성된 학습 데이터를 성능 평가 기 준에 따라 검증하고, 검증된 학습 데이터를 이용하여 제2 구강 이미지 데이터로부터 치아 객체의 위치를 특정하 고 속성을 매칭시키기 위한 라벨링 인공지능 모델을 생성하되, 구강 이미지의 구도별로 각각에 대응되는 라벨링 인공지능 모델을 별도로 생성하고, 및 제2 구강 이미지 데이터를 라벨링 인공기능 모델에 입력하여 사전 설정된 분류에 따라 치아 객체를 판별하는 라벨링 처리를 자동으로 수행한다."}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시되는 실시예들은 비대면 치과 진단 서비스를 위한 치아 판별 자동 라벨링 서버 및 방법과 관련된다."}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "국민건강검진 항목 중 치과 항목에 대한 검진 대상자가 증가하고 있지만, 수검률 감소로 인해 구강 건강 관리가 소홀하고, 이에 따라 구강 질환의 발병률이 증가하고 있는 추세이다. 이의 원인으로, 치과 검사 중 치과의사의 육안 검사로 인한 검진 결과의 부정확성과 검사 결과에 따른 실제 치료로의 연계 부족 등으로 파악되고 있다. 한편, 치과 진료비용이 상승하면서 구강 질환을 호소하는 환자들의 비용 부담이 증가하는 데 반해, 치과의사들 의 영업 이익은 감소하는 상황이다. 이에, 운용자는 치과 진료 환경을 개선하기 위한 방안을 모색하게 되었다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허공보 제10-2085572호 (2020. 03. 02.)"}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 실시예들은 구강 질환 파악을 위한 치아 판별 결과의 신뢰성을 향상시키기 위한 비대면 치과 진단 서비 스를 위한 치아 판별 자동 라벨링 서버 및 방법을 제공하고자 한다."}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 치아 판별 자동 라벨링 서버는, 메모리; 및 치아 판별을 위한 구강 이미지의 라벨링 처리를 수행하기 위한 프로세서;를 포함하고, 상기 프로세서는, 제1 구강 이미지 데이터를 데이터 생성 기준에 따라 처 리하여 학습 데이터를 생성하되, 해당 구강 이미지의 구도에 따라 구분하여 상기 학습 데이터를 생성하고, 생성 된 상기 학습 데이터를 성능 평가 기준에 따라 검증하고, 검증된 상기 학습 데이터를 이용하여 제2 구강 이미지 데이터로부터 치아 객체의 위치를 특정하고 속성을 매칭시키기 위한 라벨링 인공지능 모델을 생성하되, 구강 이 미지의 구도별로 각각에 대응되는 라벨링 인공지능 모델을 별도로 생성하고, 및 상기 제2 구강 이미지 데이터를 상기 라벨링 인공기능 모델에 입력하여 사전 설정된 분류에 따라 치아 객체를 판별하는 라벨링 처리를 자동으로 수행한다. 상기 프로세서는, 상기 학습 데이터를 생성할 때, 상기 제1 구강 이미지 데이터로부터 사전 설정된 전처리 기준 에 따라 데이터 전처리를 수행하고, 전처리된 상기 제1 구강 이미지 데이터에 사전 설정된 라벨링 기준에 따라 라벨링을 수행하고, 및 상기 라벨링 수행된 상기 학습 데이터를 사전 설정된 형식으로 저장할 수 있다. 상기 프로세서는, 상기 데이터 전처리를 수행할 때, 상기 복수의 구강 이미지 데이터로부터 오류 이미지 삭제, 비식별화 처리, 사이즈 표준화, 노이즈 제거 및 해상도 조절 중 적어도 하나 이상의 전처리 동작을 수행하고, 복수의 제1 구강 이미지 데이터의 데이터 정상성 비율을 조정할 수 있다. 상기 프로세서는, 상기 라벨링을 수행할 때, 상기 제1 구강 이미지 데이터로부터 특정된 치아 객체를 사전 설정 된 속성으로 라벨링 하되, 정상치, 충치 및 보철치 중 적어도 하나 이상의 치아 타입 속성과 작업 속성으로 라 벨링할 수 있다. 상기 프로세서는, 좌측면 구강 이미지, 우측면 구강 이미지, 정면 구강 이미지, 상교합면 구강 이미지 및 하교 합면 구강 이미지 각각에 대응되는 라벨링 인공지능 모델을 생성하되, 각 구강 이미지의 구도에 따라 하이퍼 파 라미터를 조정하고 상기 치아 타입 속성의 판단 기준을 차별화 하여 상기 라벨링 인공지능 모델을 생성할 수 있 다. 상기 프로세서는, 상기 학습 데이터를 상기 성능 평가 기준에 따라 검증할 때, 상기 학습 데이터의 치아 타입 속성별 분류된 클래스 라벨링과 실제 클래스 라벨링을 비교하여 클래스 라벨링의 성공 여부를 판단하고, 상기 분류된 클래스 라벨링 및 상기 실제 클래스 라벨링 각각은, 정상치 클래스, 충치 클래스 및 보철치 클래스를 포 함할 수 있다. 상기 프로세서는, 상기 학습 데이터를 상기 성능 평가 기준에 따라 검증할 때, 전처리 수행된 상기 제1 구강 이 미지 데이터에 대한 전처리된 자동 라벨 범위와 실제 라벨 범위의 중복 정도를 파악하고, 파악된 중복 정도가 중복 기준치 이상인 경우, 전처리 성공으로 판단할 수 있다. 일 실시예에 따른 치아 판별 자동 라벨링 방법은, 치아 판별 자동 라벨링 서버에 의해 수행되는 방법에 있어서, 제1 구강 이미지 데이터를 데이터 생성 기준에 따라 처리하여 학습 데이터를 생성하되, 해당 구강 이미지의 구 도에 따라 구분하여 상기 학습 데이터를 생성하는 단계; 생성된 상기 학습 데이터를 성능 평가 기준에 따라 검 증하는 단계; 검증된 상기 학습 데이터를 이용하여 제2 구강 이미지 데이터로부터 치아 객체의 위치를 특정하고 속성을 매칭시키기 위한 라벨링 인공지능 모델을 생성하되, 구강 이미지의 구도별로 각각에 대응되는 라벨링 인 공지능 모델을 별도로 생성하는 단계; 및 상기 제2 구강 이미지 데이터를 상기 라벨링 인공기능 모델에 입력하 여 사전 설정된 분류에 따라 치아 객체를 판별하는 라벨링 처리를 자동으로 수행하는 단계를 포함한다. 상기 학습 데이터를 생성하는 단계는, 상기 제1 구강 이미지 데이터로부터 사전 설정된 전처리 기준에 따라 데 이터 전처리를 수행하는 단계; 전처리된 상기 제1 구강 이미지 데이터에 사전 설정된 라벨링 기준에 따라 라벨 링을 수행하는 단계; 및 상기 라벨링 수행된 상기 학습 데이터를 사전 설정된 형식으로 저장하는 단계를 포함한 다."}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시되는 실시예들에 따르면, 라벨링 인공지능 모델의 성능이 향상됨에 따라 비대면 치과 진단 결과의 신뢰성이 향상될 수 있다는 효과를 기대할 수 있다. 또한, 개시되는 실시예들에 따르면, 사회적 효과 면에서 구강 이미지 및 라벨링 데이터를 추후 빅데이터 기반 치과의료 분야에 활용할 수 있고, 파노라마 분석 및 턱관절 예측. 교정 질환 예측, 구강암 조기 발견 등 다양한 분야에 활용 할 수 있다. 또한, 개시되는 실시예들에 따르면, 사회적 가치 협업 면에서 지자체나 보건소의 협업을 통해 유치원, 학교 등 정기적인 구강검진이 필요한 청소년에게 서비스를 제공하고, 지역 소외계층 및 저소득 자녀들에게 무상제공으로 사회 가치 환원할 수 있고, 거동이 불편하여 구강 검진이 어려운 노령자와 장애인 계층에게 서비스 무상제공을 통해 구강건강 증진할 수 있으며, 솔루션을 통해 치아 판별에 대한 초기 발견 실패로 인해 발생하는 치아 치료 비용을 줄일 수 있으며, 불필요한 치료를 하지 않고 건강한 구강 관리를 할 수 있는 홈 케어 구강 검진시스템으 로 새로운 구강 관리 솔루션을 제공할 수 있다. 또한, 개시되는 실시예들에 따르면, 기술적 효과 면에서, 사용자 편의성을 고려한 비대면 치아 솔루션(치아 판 별, 치주 질환, 우식확률 등) 개발에 활용할 수 있고, 다양한 치아 상태(정상, 우식 4단계) 및 질환(치은염, 치주염 등)으로 확장하여 활용하고 있으며, 교정기, 금니 등 치료를 통한 부착물을 인식하도록 확장할 수 있고, 치아 이미지 전처리 기술을 통해 현재는 외부 환경으로 인해 인식할 수 없는 스마트폰 촬영 이미지를 인식하도 록 확장할 수 있다. 또한, 개시되는 실시예들에 따르면, 경제적 효과 면에서, 비대면 치아 판별 웹 서비스 이용자 중 충치 치료로 이어지는 환자와 치료 환자 중 성실 고객으로 전환되어 수요기업을 반복 이용하는 고객을 매출 규모로 산정할 수 있다는 효과를 기대할 수 있다."}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 구체적인 실시형태를 설명하기로 한다. 이하의 상세한 설명은 본 명세서에서 기술된 방법, 장치 및/또는 시스템에 대한 포괄적인 이해를 돕기 위해 제공된다. 그러나 이는 예시에 불과하며 본 발명은 이에 제한되지 않는다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다. 도 1은 일 실시예에 따른 치아 판별 자동 라벨링 서버를 설명하기 위한 블록도이다. 이하에서는, 일 실시예에 따른 치아 판별 자동 라벨링 방법을 설명하기 위한 예시도인 도 2 내지 도 8을 참고하 여 설명하기로 한다. 도 1을 참고하면, 치아 판별 자동 라벨링 서버는 프로세서, 메모리 및 통신부를 포함한다. 도 1에 도시된 구성요소들은 본 개시에 따른 치아 판별 자동 라벨링 서버를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 치아 판별 자동 라벨링 서버는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 도 1에 도시된 구성요소들은 통신 네트워크(미도시)를 통해 서로 간에 통신 가능하게 연결될 수 있다. 몇몇 실 시예들에서, 통신 네트워크는 인터넷, 하나 이상의 로컬 영역 네트워크(local area networks), 광역 네트워크 (wire area networks), 셀룰러 네트워크, 모바일 네트워크, 그 밖에 다른 종류의 네트워크들, 또는 이러한 네트 워크들의 조합을 포함할 수 있다. 프로세서는 치아 판별을 위한 구강 이미지의 라벨링 처리를 수행하기 위한 구성일 수 있다. 프로세서는 제1 구강 이미지 데이터를 데이터 생성 기준에 따라 처리하여 학습 데이터를 생성하되, 해당 구강 이미지의 구도에 따라 구분하여 학습 데이터를 생성할 수 있다. 이때, 데이터 생성 기준은 라벨링 인공지 능 모델을 생성하기 위해 입력되는 입력값인 학습 데이터를 제1 구강 이미지 데이터를 이용하여 생성하기 위한 기준을 의미할 수 있다.상기 제1 구강 이미지 데이터는 라벨링 인공지능 모델의 생성을 위해 수집되는 구강 이미지를 포함하는 데이터 로, 이미지 및 이미지와 매칭되는 각종 텍스트를 포함할 수 있다. 개시되는 실시예의 라벨링 인공지능 모델은 객체 탐지를 위한 아키텍처로 YOLO를 적용할 수 있으며, 이에 한정 되지 않는다. 구강 이미지 내 치아인 객체의 위치와 종류를 동시에 판별하기 위해서 객체 인식 모델인 YOLO를 이용할 수 있다. YOLO를 이용한 구강 이미지 내 객체 탐지는 다음과 같은 절차를 통해 이루어질 수 있다. 먼저, 구강 이미지를 SХS 그리드(Grid)로 분할하고, 각 그리드를 바운딩 박스(B)와 클래스(C)로 미리 정의할 수 있다. 다음, 출력 이미지를 S Х S Х (B Х 3 + C) 크기의 텐서로 바운딩 박스(Bounding boxes)와 클래스 확률 (Class probability map)을 예측할 수 있다. 이때, 바운딩 박스의 경우 위치(x, y 좌표), 크기(너비, 높이) 및 객체의 신뢰도(confidence)뿐만 아니라 객체의 클래스 확률도 제공할 수 있다. 개시되는 실시예에서는 구강 이 미지(치아 이미지)를 2,560 Х 2,560 그리드로 분할하여 치아 영역만을 탐지할 수 있다. 출력 텐서의 크기는 2,560 Х 2,560 Х (1 Х 3 + 1) = 19,660,800일 수 있다. 이때, 모델 학습의 경우 YOLO 객체 탐지 아키텍쳐에 서는 구도면과 클래스를 함께 이용하여 라벨링 인공지능 모델의 단일 통합 모델을 구성하나 특정 구도면에 따라 특성을 고려하는 것이 어려울 수 있다. 이에, 개시되는 실시예에서는 구강 이미지의 5종 구도면(도 2의 좌측면, 우측면, 정합면, 상교합면, 하교합면의 구강 이미지)에 따른 라벨링 인공지능 모델을 각 구도면에 따라 개별 모 델로 초기 구성하고, 각 특성에 맞게 하이퍼 파라미터(학습률, 배치 크기, 최적화 알고리즘 등)를 조정하여 개 선할 수 있다. 프로세서는 생성된 학습 데이터를 성능 평가 기준에 따라 검증할 수 있다. 이하에서는, 라벨링 인공지능 모델 생성을 위한 학습 데이터를 생성하는 방법을 구체적으로 설명하기로 한다. 구체적으로, 프로세서는 학습 데이터를 생성할 때, 제1 구강 이미지 데이터로부터 사전 설정된 전처리 기 준에 따라 데이터 전처리를 수행할 수 있다. 프로세서는 데이터 전처리를 수행할 때, 복수의 구강 이미지 데이터로부터 오류 이미지 삭제, 비식별화 처 리, 사이즈 표준화, 노이즈 제거 및 해상도 조절 중 적어도 하나 이상의 전처리 동작을 수행하고, 복수의 제1 구강 이미지 데이터의 데이터 정상성 비율을 조정할 수 있다. 일 예로, 프로세서는 구강 이미지 데이터의 구강 이미지 상에 스크래치가 기준치 이상이거나, 구강 이미지 의 조도가 기준치 미만으로 어두워서 구강 객체 인식이 어렵다고 판단되는 등의 오류 및 이상이 발생한 구강 이 미지 데이터를 삭제할 수 있다. 다른 예로, 프로세서는 개인 식별 정보를 비롯한 제1 구강 이미지 데이터로부터 생략해야 하는 정보를 삭 제하여 구강 이미지 데이터를 비식별화 할 수 있다. 프로세서는 환자의 신원을 식별할 수 있도록 하는 개 인 식별 정보를 비식별화 처리하되, 해당 정보를 제거하거나, 해당 정보를 대체할 수 있는 정보로 변경하거나, 또는 마스킹 작업을 수행할 수 있다. 예를 들어, 표 1을 참고하면, 프로세서는 제1 구강 이미지 데이터에 포함된 가입번호, 환자 생년월일, 환자이름, 추천 의사 등과 같은 값을 삭제하거나, 또는 기관 이름, 추천 의사 ID, 환자 연령, 환자 주소 등의 태그를 삭제할 수 있다. 표 1 코드 식별 정보 비고 0x0008,0x0050Accession Number (가입 번호) 값 삭제 0x0008,0x0080Institution Name (기관 이름) 태그 삭제 0x0008,0x0096Referring PhysicianID Sequence (추천 의사 ID 순번) 태그 삭제 0x0008,0x1048Physicians Of Record (기록 의사) 태그 삭제 0x0008,0x1050Performing Physician Name (수행의사 이름) 태그 삭제 0x0008,0x1052Performing PhysicianID Sequence (수행의사 ID 순번) 태그 삭제 0x0008,0x1060Name Of Physician Reading Study (의사 독서연구 이름) 태그 삭제 0x0008,0x1062Physician Reading StudyID Sequence (의사 독서연구 ID 순번) 태그 삭제 0x0010,0x0030Patient Birth Date (환자 생년월일) 년도 유지 0x0010,0x0050Patient Insurance Plan Code Sequence (환자 보험 계획 코드 순번) 태그 삭제 0x0010,0x0101Patient Primary Language Code Seq (환자 기본언어 코드 순번) 태그 삭제 0x0010,0x1000Other Patient IDs (기타 환자 ID) 태그 삭제 0x0010,0x1001Other Patient Names (기타 환자 이름) 태그 삭제 0x0010,0x1002Other PatientIDs Sequence (기타 환자 ID 순번) 태그 삭제 0x0010,0x1010Patient Age (환자 연령) 태그 삭제0x0010,0x1040Patient Address (환자 주소) 태그 삭제 0x0010,0x1060Patient Mother Birth Name (환자 모친 생년 이름) 태그 삭제 0x0010,0x0010Patient Name (환자 이름) 값 삭제 0x0008,0x0090Referring Physician Name (추천 의사 이름) 값 삭제 다른 예로, 프로세서는 제1 구강 이미지 데이터의 구강 이미지의 사이즈를 사전 설정된 사이즈로 표준화할 수 있다. 제1 구강 이미지 데이터는 다양한 크기와 해상도를 가지고 있기 때문에, 라벨링 인공지능 모델의 학습 을 위해서 입력된 구강 이미지는 동일한 크기로 변환하는 작업이 요구될 수 있다. 예를 들어, 구강 이미지의 사 이즈를 1,280 x 1,280 해상도로 리사이징하고 가로 및 세로의 비율을 사이즈 표준화 할 수 있다. 다른 예로, 도 3을 참고하면, 프로세서는 제1 구강 이미지 데이터 내 구강 이미지의 노이즈를 제거하고, 해상도를 향상시키는 조절을 할 수 있다. 구강 이미지는 치과 의사 및 관련 관계자들로부터 다양한 환경 조건 (촬영 환경, 장비의 품질, 전송 과정 등)에 의해 노이즈가 포함되어, 학습의 정확도를 저하시킬 수 있다. 이에, 프로세서는 구강 이미지의 사이즈를 1,280 x 1,280 해상도로 리사이징 하여 표준화 할 수 있다. 개시되는 실시예는 라벨링 인공지능 모델 생성을 위한 모든 구강 이미지 데이터를 동일한 해상도로 조절하기 때문에, 라 벨링 인공지능 모델링 학습에 있어서 일관성을 유지할 뿐만 아니라 연산 효율성을 증대시킬 수 있다. 즉, 프로 세서는 구강 이미지로부터 노이즈 제거 및 고해상도 조절을 통해 고품질의 이미지를 획득할 수 있다. 다른 예로, 프로세서는 복수의 제1 구강 이미지 데이터의 데이터 정상성 비율을 조정할 수 있다. 이때, 데 이터 정상성은 수집된 복수의 제1 구강 이미지 데이터에서 라벨링 인공지능 모델링에 활용할 수 있는 정상적인 데이터의 비율을 의미하는 것으로, 프로세서는 수학식 1을 이용하여 생성할 수 있다. 이때, 데이터 정상성 이 높을수록 학습에 활용할 수 있는 유용한 데이터가 많다는 것을 의미할 수 있다. 이에, 개시되는 실시예는 제 1 구강 이미지 데이터의 전체 대비 80% 이상의 데이터를 사용함으로써 데이터의 정규화 및 표준화할 경우 라벨 링 인공지능 모델링의 안정성 및 수렴 속도를 개선시킬 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상기 은 학습에 도움이 되는 데이터(프레임) 수, 은 학습에 방해가 되는 데이터(프레임) 수 및 는 학 습의 방해가 되는 데이터의 종류를 의미할 수 있다. 다음, 프로세서는 전처리된 제1 구강 이미지 데이터에 사전 설정된 라벨링 기준에 따라 라벨링을 수행할 수 있다. 즉, 프로세서는 이후 입력되는 제2 구강 이미지 데이터에 대한 자동 라벨링을 수행하도록 라벨링 인공지능 모델의 입력에 대한 출력(라벨링)을 트레이닝 하는 것이다. 구체적으로, 도 4를 참고하면, 프로세서는 라벨링 처리를 수행하고자 하는 구강 이미지를 결정하고, 구강 이미지에서 라벨링이 필요한 시작 지점과 끝 지점을 선택하여 라벨링 폴리곤을 생성할 수 있다. 다음, 프로세서는 생성된 라벨링 폴리곤에 대응되는 라벨링(예를 들어, normal: 정상치, cavity: 충치, prosthetic: 보철치)을 입력할 수 있다. 다음, 도 5와 같이, 프로세서는 복수의 라벨링 폴리곤에 대응되는 라벨링을 입력한 라벨링 파일을 저장할 수 있다. 이때, 파일명과 위치는 변경하지 않고 저장할 수 있다. 다음, 도 6을 참고하면, 프로세서는 라벨링을 입력한 파일 각각에 대한 라벨링의 종류 및 라벨링의 형태를 포함하는 라벨링 결과를 사전 설정된 라벨링 기준에 따라 검수할 수 있다. 상기 라벨링의 종류는 정상 치아 : normal (황색), 충치 : cavity(적색) 및 보철 치아 : prosthetic(녹색)를 포함할 수 있다. 상기 라벨링의 형태 는 직사각형(Rectangle) 형태일 수 있다. 참고로, 도 6의 a)는 비정상으로 라벨링이 실패한 경우를 나타내는 것 이고, c)는 라벨링이 성공적으로 이루어진 경우를 나타내는 것일 수 있다. 프로세서는 검수 결과에 따라 비정상 판정된 파일에 대해 라벨링 재작업을 수행할 수 있다. 이때, 프로세 서는 크기 및 분류 수정을 통해 라벨링 재작업을 수행할 수 있다. 프로세서는 작업 시트를 활용하여 라벨링 이슈사항 및 특이사항을 입력할 수 있다. 프로세서는 고정 입력 정보를 입력할 수 있다. 상기 고정 입력 정보는 담당 인원, 번호, 작업 이미지명, 이미지 폴더 및 원본 이미지명을 포함할 수 있으며, 이에 한정되지 않는다. 이때, 작업자의 제어가 개입되는 경우, 프로세서는 작 업자 입력 정보를 추가로 입력할 수 있다. 상기 작업자 입력 정보는 작업 여부(완료 여부), 작업 날짜(완료 날 짜) 및 비고(이슈사항 및 특이사항)를 포함할 수 있다. 다음, 프로세서는 라벨링 수행된 학습 데이터를 사전 설정된 형식으로 저장할 수 있다. 구체적으로, 프로 세서는 학습 데이터를 반정형 데이터(json) 형식으로 저장할 수 있으며, 이에 한정되지 않는다. 표 2를 참 고하면, 반정형 데이터 형식은 번호, 도구 버전, 라벨링 모양, 라벨링 좌표, 파일명, 가로 크기 및 세로 크기를 포함할 수 있다. 표 2 번호 항목명 형식구분 항목 설명 예시 1no number필수번호 00001 2versionstring필수가공 작업 도구 버전5.0.1 3shape json 선택라벨링 포맷 { \"label\":\"prosthetic\", \"points\":[[782.741935483871, 1426.7096774193549], [1350.483870967742, 2039.6129032258063]], \"shape_type\": \"rectangle\" } 4image_namestring필수파일명 \"FIR_12345.png\" 5height number필수세로 크기 3000 6width number필수가로 크기 4496 프로세서는 라벨링을 수행할 때, 제1 구강 이미지 데이터로부터 특정된 치아 객체를 사전 설정된 속성으로 라벨링 하되, 정상치, 충치 및 보철치 중 적어도 하나 이상의 치아 타입 속성과 작업 속성으로 라벨링 할 수 있 다. 상기 치아 타입 속성은 라벨링 처리되는 치아와 관련된 속성(예를 들어, 정상치, 충치 및 보철치)을 의미하 는 것이고, 작업 속성은 학습 데이터 생성 시의 라벨링 작업과 관련된 속성을 의미할 수 있다. 이때, 작업 속성 은 생략 가능할 수 있다. 프로세서는 좌측면 구강 이미지, 우측면 구강 이미지, 정면 구강 이미지, 상교합면 구강 이미지 및 하교합 면 구강 이미지 각각에 대응되는 라벨링 인공지능 모델을 생성할 수 있다. 이때, 프로세서는 각 구강 이미 지의 구도에 따라 하이퍼 파라미터를 조정하고 치아 타입 속성의 판단 기준을 차별화 하여 라벨링 인공지능 모 델을 생성할 수 있다. 예를 들어, 도 2를 참고하면, 제1 구강 이미지 데이터는 좌측면 구강 이미지, 우측면 구강 이미지, 정면 구강 이미지, 상교합면 구강 이미지 및 하교합면 구강 이미지를 포함할 수 있으며, 각각은 촬영된 각도가 서로 다르 기 때문에 치아에서 발생하는 정상치, 충치 및 보철치와 같은 치아 타입의 형태도 서로 다르게 나타날 수 있다. 개시되는 실시예에서는 보다 정확한 라벨링을 위해 각 구강 이미지의 구도에 따라 라벨링 인공지능 모델을 차별 화하여 생성할 수 있다. 이때, 구도면 (좌측면, 우측면, 정합면, 상교합면, 하교합면)에 따른 라벨링 인공지능 모델을 초기 구성하되, 각 특성에 따라 학습률, 배치 크기, 최적화 알고리즘 등을 포함하는 하이퍼 파라미터를 조정할 수 있다. 프로세서는 학습 데이터를 성능 평가 기준에 따라 검증할 때, 학습 데이터의 치아 타입 속성별 분류된 클 래스 라벨링과 실제 클래스 라벨링을 비교하여 클래스 라벨링의 성공 여부를 판단할 수 있다. 이때, 분류된 클 래스 라벨링은 정상치 클래스, 충치 클래스 및 보철치 클래스를 포함할 수 있다. 상기 실제 클래스 라벨링 각각 은 정상치 클래스, 충치 클래스 및 보철치 클래스를 포함할 수 있다. 또한, 프로세서는 혼동 행렬 (Confusion Matrix)로부터 정밀도(Precision), 재현율(Recall)을 통해 최종적인 F1 Score를 비교할 수 있다. 프로세서는 학습 데이터를 성능 평가 기준에 따라 검증할 때, 전처리 수행된 제1 구강 이미지 데이터에 대 한 전처리된 자동 라벨 범위(예측된 자동 라벨의 범위)와 실제 라벨 범위의 중복 정도를 파악하고, 파악된 중복 정도가 중복 기준치 이상인 경우, 전처리 성공으로 판단할 수 있다. 구체적으로, 프로세서는 예측된 자동 라벨의 범위와 실제 라벨의 범위가 얼마나 겹치는지를 나타내는 지표 로, 각 구강 이미지에 대한 IoU를 계산한 후, 모든 이미지에 대한 평균 IoU를 도출할 수 있다. 이때, IoU는 수 학식 1을 통해 산출할 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이때, 이고, 을 의미할 수 있다."}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "한편, 도 7을 참고하면, 프로세서는 학습 데이터를 성능 평가 기준에 따라 검증을 수행하고, 검증 결과를 획득할 수 있다. 구체적으로, 무작위 치아 검증 데이터(예를 들어, 5,000개)를 대상으로 치아 실측 및 예측을 수행한 전처리 이 미지 평가(IoU) 지표를 그래프로 나타낼 수 있다. 이때, 전처리 이미지 평가 지표는 a) 정밀도: Precision, b) 재현율: Recall 및 c) F1 Score를 포함할 수 있다. 도 7을 참고하면, 전처리 과정에서 이미지 평가의 경우 0.91 로서 예측된 치아의 영역과 실제 치아의 영역이 상대적으로 매우 높은 일치성을 보이는 것을 확인할 수 있다. 이는, 해당 전처리 과정(예를 들어, 개인정보 비식별화, 사이즈 표준화, 노이즈 제거 및 해상도 향상, 데이터 정상성)에서 고정밀 및 고해상도 입력 데이터의 품질 향상과 더불어 효과적인 과정임을 입증하는 것일 수 있다. 치아 분류 평가에서는 정밀도(예측 기준)와 재현율(실측 기준) 간의 트레이드 오프(trade-off) 관계를 지니기 때문에 각 클래스마다 상세 분석이 가능할 수 있다. 즉, F1 Score는 0.1~0.95에서 클래스에 구분없이 정밀도 및 재현율을 고려한 상대적으로 높은 일치성을 보이는 것일 확인할 수 있다. 반면에 0.1 이하의 경우 보철치에서 낮은 정밀도로 인해 일치성이 작았고 0.95 이상에서도 보철치에서 낮은 재현율로 인해 낮은 일치성을 확인할 수 있다. 이러한 분석 결과를 기초로, 프로세서는 특정 클래스(예를 들어, 보철치)에서의 성능 저하 원인을 기초로 라벨링 인공지능 모델링의 하이퍼 파라미터를 개선하거나 또는 데이터 전처리 방법을 추가하여 해당 클 래스의 성능을 개선할 수 있다. 도 8을 참고하면, 프로세서는 치아 판별 자동 라벨링 솔루션 결과를 시각화 하여 출력할 수 있다. 구체적 으로, 무작위 치아 검증 데이터(예를 들어, 5,000개)를 대상으로 치아 판별 자동 라벨링 결과를 시각화로 나타 낸 것일 수 있다. 그 결과 프로세서는 직사각형 형태로 바운딩 정보를 비롯한 3종 클래스(청색: 정상치, 주황색: 충치, 녹색: 보철치) 및 예측 확률(0.0 ~ 1.0)을 제공할 수 있다. 이러한 결과는 치아의 상태나 위치를 정확하게 판별함으로써 치과 의료 분야에서 높은 활용성으로 기대할 수 있다. 프로세서는 상술한 동작을 통해 검증 및 개선된 학습 데이터를 획득할 수 있다. 프로세서는 검증된 학습 데이터를 이용하여 제2 구강 이미지 데이터로부터 치아 객체의 위치를 특정하고 속성을 매칭시키기 위한 라벨링 인공지능 모델을 생성할 수 있다. 이때, 프로세서는 구강 이미지의 구도별 로 각각에 대응되는 라벨링 인공지능 모델을 별도로 생성할 수 있다. 상기 제2 구강 이미지 데이터는 라벨링 인 공지능 모델을 이용하여 자동 라벨링 처리 될 구강 이미지를 의미할 수 있다. 프로세서는 제2 구강 이미지 데이터를 라벨링 인공기능 모델에 입력하여 사전 설정된 분류에 따라 치아 객 체를 판별하는 라벨링 처리를 자동으로 수행할 수 있다. 이때, 라벨링 인공지능 모델은 사전 학습된 모델일 수 있다. 본 개시의 프로세서는 하나 이상의 코어로 구성될 수 있으며, 컴퓨팅 장치의 중앙 처리 장치(central processing unit), 범용 그래픽 처리 장치 (general purpose graphics processing unit), 텐서 처리 장치 (tensor processing unit) 등의 데이터 분석, 딥러닝을 위한 프로세서를 포함할 수 있다. 프로세서는 메모 리에 저장된 컴퓨터 프로그램을 판독하여 본 개시에 따른 기계 학습을 위한 데이터 처리를 수행할 수 있다. 본 개시에 따라 프로세서는 신경망의 학습을 위한 연산을 수행할 수 있다. 프로세서는 딥러닝 (deep learning)에서 학습을 위한 입력 데이터의 처리, 입력 데이터에서의 피처 추출, 오차 계산, 역전파 (backpropagation)를 이용한 신경망의 가중치 업데이트 등의 신경망의 학습을 위한 계산을 수행할 수 있다. 상기 뉴럴 네트워크 모델은 딥 뉴럴 네트워크일 수 있다. 본 개시에서, 신경망, 네트워크 함수, 뉴럴 네트워크 (neural network)는 동일 한 의미로 사용될 수 있다. 딥 뉴럴 네트워크(DNN: deep neural network, 심층신경망)는 입력 레이어와 출력 레이어 외에 복수의 히든 레이어를 포함하는 신경망을 의미할 수 있다. 딥 뉴럴 네트 워크를 이용하면 데이터의 잠재적인 구조(latent structures)를 파악할 수 있다. 즉, 사진, 글, 비디오, 음성, 음악의 잠재적인 구조(예를 들어, 어떤 물체가 사진에 있는지, 글의 내용과 감정이 무엇인지, 음성의 내용과 감 정이 무엇인지 등)를 파악할 수 있다. 딥 뉴럴 네트워크는 컨벌루셔널 뉴럴 네트워크(CNN: convolutional neural network), 리커런트 뉴럴 네트워크(RNN: recurrent neural network), 제한 볼츠만 머신(RBM: restricted boltzmann machine), 심층 신뢰 네트워크(DBN: deep belief network), Q 네트워크, U 네트워크, 샴 네트워크 등을 포함할 수 있다. 컨벌루셔널 뉴럴 네트워크는 딥 뉴럴 네트워크의 일종으로서, 컨벌루셔널 레이어를 포함하는 신경망을 포함한다. 컨벌루셔널 뉴럴 네트워크는, 최소 한의 전처리(preprocess)를 사용하도록 설계된 다계층 퍼셉트론 (multilayer perceptrons)의 한 종류이다. CNN은 하나 또는 여러 개의 컨벌루셔널 레이어와 이와 결합된 인공 신경망 계층들로 구성될 수 있다. CNN은 가중치와 풀링 레이어(pooling layer)들을 추가로 활용할 수 있다. 이 러한 구조 덕분에 CNN은 2차원 구 조의 입력 데이터를 충분히 활용할 수 있다. 컨벌루셔널 뉴럴 네트워크는 이 미지에서 오브젝트를 인식하기 위하여 사용될 수 있다. 컨벌루셔널 뉴럴 네트워크는, 이미지 데이터를 차원을 가진 행렬로 나타내어 처리할 수 있다. 예를 들어 RGB(red-green-blue)로 인코딩 된 이미지 데이터의 경우, R, G, B 색상별로 각각 2 차원(예를 들어, 2 차원 이미지 인 경우) 행렬로 나타내 질 수 있다. 즉, 이미지 데이터 의 각 픽셀의 색상 값이 행렬의 성분이 될 수 있으며 행렬의 크기는 이미지의 크기와 같을 수 있다. 따라서, 이 미지 데이터는 3개의 2차원 행렬로(3차원의 데이터 어레이)로 나타내질 수 있다. 컨벌루셔널 뉴럴 네트워크에서, 컨벌루셔널 필터를 이동해가며 컨벌루셔널 필터와 이미지의 각 위치에서의 행렬 성분끼리 곱하는 것으로 컨벌루셔널 과정(컨벌루셔널 레이어의 입출력)을 수행할 수 있다. 컨벌루셔널 필터는 n*n 형태의 행렬로 구성될 수 있다. 컨벌루셔널 필터는, 일반적으로 이미지의 전체 픽셀의 수보다 작은 고정된 형태의 필터로 구성될 수 있다. 즉, m*m 이미지를 컨벌루셔널 레이어(예를 들어, 컨벌루셔널 필터의 사이즈가 n*n인 컨벌루셔널 레이어)입력시키는 경우, 이미지의 각 픽셀을 포함하는 n*n 픽셀을 나타내는 행렬이 컨벌루셔 널 필터와 성분 곱 (즉, 행렬의 각 성분끼리의 곱) 될 수 있다. 컨벌루셔널 필터와의 곱에 의하여 이 미지에서 컨벌루셔널 필터와 매칭되는 성분이 추출될 수 있다. 예를 들어, 이미지에서 상하 직선 성분을 추출하기 위한 3*3 컨벌루셔널 필터는 [[0,1,0], [0,1,0], [0,1,0]] 와 같이 구성될 수 있다. 이미지에서 상하 직선 성분을 추 출하기 위한 3*3 컨벌루셔널 필터가 입력 이미지에 적용되면 이미지에서 컨벌루셔널 필터와 매칭되는 상하 직선 성분이 추출되어 출력될 수 있다. 컨벌루셔널 레이어는 이미지를 나타낸 각각의 채널에 대한 각각의 행렬(즉, R, G, B 코딩 이미 지의 경우, R, G, B 색상)에 컨벌루셔널 필터를 적용할 수 있다. 컨벌루셔널 레이 어는 입력 이미지에 컨벌루셔널 필터를 적용하여 입력 이미지에서 컨벌루셔널 필터 와 매칭되는 피쳐를 추출할 수 있다. 컨벌루셔널 필터의 필터 값(즉, 행렬의 각 성 분의 값)은 컨벌루셔널 뉴럴 네트워크의 학습 과정에서 역전파에 의하여 업데이트 될 수 있다. 컨벌루셔널 레이어의 출력에는, 서브샘플링 레이어가 연결되어 컨벌 루셔널 레이어의 출력을 단순화하여 메모리 사용량과 연산량을 줄일 수 있다. 예를 들어, 2*2 맥스 풀링 필터를 가지는 풀링 레이어에 컨벌루셔널 레이어의 출력을 입 력시키는 경우, 이미지의 각 픽셀에서 2*2 패치마다 각 패치에 포함되는 최대값을 출력하여 이미지를 압축할 수 있다. 전술한 풀링은 패치에서 최소값을 출력하거나, 패치의 평균값을 출력하는 방식일 수도 있으며 임의의 풀링 방식이 본 개시에 포함될 수 있다. 컨벌루셔널 뉴럴 네트워크는, 하나 이상의 컨벌루셔널 레이어, 서브 샘플링 레이어를 포함할 수 있다. 컨벌루셔 널 뉴럴 네트워크는 컨벌루셔널 과정과 서브샘플링 과정(예를 들어, 전술한 맥스 풀링 등)을 반복적으로 수행하 여 이미지에서 피쳐를 추출할 수 있다. 반복적인 컨벌루션널 과정과 서브샘플링 과정을 통해 뉴럴 네트워크는 이미지의 글로벌 피쳐를 추출할 수 있다. 컨벌루셔널 레이어 또는 서브샘플링 레이어의 출력은 풀 커넥티드 레이어(fully connected layer)에 입력될 수 있다. 풀 커넥티드 레이어는 하나의 레이어에 있는 모든 뉴런과 이웃한 레이어에 있는 모든 뉴런이 연결되는 레 이어이 다. 풀 커넥티드 레이어는 뉴럴 네트워크에서 각 레이어의 모든 노드가 다른 레이 어의 모든 노드에 연 결된 구조를 의미할 수 있다. 프로세서의 CPU, GPGPU, 및 TPU 중 적어도 하나가 네트워크 함수의 학습을 처리할 수 있다. 예를 들어, CPU와 GPGPU가 함께 네트워크 함수의 학습, 네트워크 함수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 개시의 일 실시예에서 복수의 컴퓨팅 장치의 프로세서를 함께 사용하여 네트워크 함수의 학습, 네트워크 함수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 개시의 일 실시예에 따른 컴퓨팅 장치에서 수행되는 컴퓨터 프로그램은, CPU, GPGPU 또는 TPU 실행가능 프로그램일 수 있다. 메모리는 치아 판별 자동 라벨링 방법을 제공하기 위한 컴퓨터 프로그램을 저장할 수 있으며, 저장된 컴퓨 터 프로그램은 프로세서에 의해 판독되어 구동될 수 있다. 메모리는 프로세서가 생성하거나 결 정한 임의의 형태의 정보 및 통신부가 수신한 임의의 형태의 정보를 저장할 수 있다. 메모리는 치아 판별 자동 라벨링 서버의 다양한 기능을 지원하는 데이터와, 프로세서의 동작을 위한 프로그램을 저장할 수 있고, 입/출력되는 데이터들을 저장할 있고, 치아 판별 자동 라벨링 서버에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 치아 판별 자동 라벨링 서버의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 상술한 메모리는 후술하는 컴퓨팅 장치의 컴퓨터 판독 가능 저장 매체일 수 있다. 이러한, 메모리 는 플래시 메모리 타입(Flash memory type), 하드디스크 타입(Hard disk type), SSD 타입(Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(Multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(Random access memory; RAM), SRAM(Static random access memory), 롬(Read-only memory; ROM), EEPROM(Electrically erasable programmable read-only memory), PROM(Programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스크 중 적어도 하나의 타 입의 저장매체를 포함할 수 있다. 또한, 메모리는 본 장치와는 분리되어 있으나, 유선 또는 무선으로 연결된 데 이터베이스가 될 수도 있다. 통신부는 외부 장치와 통신을 가능하게 하는 하나 이상의 구성 요소를 포함할 수 있으며, 예를 들어, 방송 수신 모듈, 유선통신 모듈, 무선통신 모듈, 근거리 통신 모듈, 위치정보 모듈 중 적어도 하나를 포함할 수 있다. 이러한, 통신부는 후술하는 컴퓨팅 장치의 네트워크 통신 인터페이스일 수 있다. 도 9는 일 실시예에 따른 치아 판별 자동 라벨링 방법을 설명하기 위한 흐름도이다. 도 9에 도시된 방법은 예를 들어, 전술한 치아 판별 자동 라벨링 서버에 의해 수행될 수 있다. 도시된 흐름도에서는 상기 방법을 복수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되거나, 다른 단계와 결합되어 함께 수행되거나, 생략되거나, 세부 단계들로 나뉘어 수행되거나, 또는 도시되지 않은 하나 이상의 단계가 부가 되어 수행될 수 있다. 1100 단계에서, 치아 판별 자동 라벨링 서버는 프로세서를 통해 제1 구강 이미지 데이터를 데이터 생 성 기준에 따라 처리하여 학습 데이터를 생성하되, 해당 구강 이미지의 구도에 따라 구분하여 학습 데이터를 생 성할 수 있다. 구체적으로, 프로세서는 제1 구강 이미지 데이터로부터 사전 설정된 전처리 기준에 따라 데이터 전처리를 수행할 수 있다. 다음, 프로세서는 전처리된 제1 구강 이미지 데이터에 사전 설정된 라벨링 기준에 따라 라벨링을 수행할 수 있다. 다음, 프로세서는 라벨링 수행된 상기 학습 데이터를 사전 설정된 형식으로 저장할 수 있다. 1200 단계에서, 치아 판별 자동 라벨링 서버는 프로세서를 통해 생성된 학습 데이터를 성능 평가 기 준에 따라 검증할 수 있다. 1300 단계에서, 치아 판별 자동 라벨링 서버는 프로세서를 통해 검증된 학습 데이터를 이용하여 제2 구강 이미지 데이터로부터 치아 객체의 위치를 특정하고 속성을 매칭시키기 위한 라벨링 인공지능 모델을 생성 하되, 구강 이미지의 구도별로 각각에 대응되는 라벨링 인공지능 모델을 별도로 생성할 수 있다. 1400 단계에서, 치아 판별 자동 라벨링 서버는 프로세서를 통해 제2 구강 이미지 데이터를 라벨링 인 공기능 모델에 입력하여 사전 설정된 분류에 따라 치아 객체를 판별하는 라벨링 처리를 자동으로 수행할 수 있 다. 도 10은 일 실시예에 따른 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위한 블록도이다. 도시된 실시예에 서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가질 수 있고, 이하에 기술된 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 컴퓨팅 장치는 일 실시예에 따른 치아 판별 자동 라벨링 서버에 포함된 하나 이상의 컴포넌트일 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있 다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실 행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작 들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메 모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자 기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치 에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다. 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다."}
{"patent_id": "10-2023-0122550", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이상에서 본 발명의 대표적인 실시예들을 상세하게 설명하였으나, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 상술한 실시예에 대하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형이 가능함을 이해할 것이다. 그러므로 본 발명의 권리범위는 설명된 실시예에 국한되어 정해져서는 안 되며, 후술하는 청구 범위뿐만 아니라 이 청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2023-0122550", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 치아 판별 자동 라벨링 서버를 설명하기 위한 블록도 도 2 내지 도 8은 일 실시예에 따른 치아 판별 자동 라벨링 방법을 설명하기 위한 예시도 도 9는 일 실시예에 따른 치아 판별 자동 라벨링 방법을 설명하기 위한 흐름도 도 10은 일 실시예에 따른 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위한 블록도"}
