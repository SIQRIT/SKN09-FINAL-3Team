{"patent_id": "10-2022-0119177", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0069813", "출원번호": "10-2022-0119177", "발명의 명칭": "멀티 클라우드 엣지 시스템", "출원인": "한국전자통신연구원", "발명자": "김대원"}}
{"patent_id": "10-2022-0119177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "코어 클라우드;멀티 클러스터 기반 제1 엣지(A FIRST EDGE) 노드 시스템; 및멀티 클러스터 기반 니어 엣지(NEAR EDGE) 노드 시스템을 포함하고,상기 멀티 클러스터 기반 제1 엣지 노드 시스템은복수의 작업 노드들; 및스케줄러를 가지는 마스터 노드를 포함하는, 멀티 클라우드 엣지 시스템."}
{"patent_id": "10-2022-0119177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 제1 엣지 노드 시스템과 상기 니어 엣지 노드 시스템을 터널링 프로토콜에 따라 고속 네트워크로연결하는, 멀티 클라우드 엣지 시스템."}
{"patent_id": "10-2022-0119177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 제1 엣지 노드 시스템과 상기 니어 엣지 노드 시스템의 협업 연산에 따른 데이터를 공유 저장하는 공유 저장장치를 더 포함하는, 멀티 클라우드 엣지 시스템."}
{"patent_id": "10-2022-0119177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 제1 엣지 노드 시스템과 상기 니어 엣지 노드 시스템의 데이터를 기반으로 협업 연산에 필요한 리소스를제어하는 매니지먼트 노드를 더 포함하는, 멀티 클라우드 엣지 시스템."}
{"patent_id": "10-2022-0119177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 제1 엣지 노드 시스템 또는 상기 니어 엣지 노드 시스템은 컴퓨팅 노드들을 포함하고,상기 컴퓨팅 노드들은 컨테이너 플랫폼 기반으로 모놀리틱 어플리케이션(MONOLITHIC APPLICATION), 마이크로 서비스(MICRO SERVICE) 및 서비스형 함수(FUNCTION AS A SERVICE)를 제공하는, 멀티 클라우드 엣지 시스템."}
{"patent_id": "10-2022-0119177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 제1 엣지 노드 시스템은 외부 기기로부터 태스크(TASK)에 대한 연산 로드를 요청받고,상기 마스터 노드는 상기 스케줄러를 이용하여 상기 태스크(TASK)를 수행할 수 있는 어플리케이션이 배포된 작업 노드를 결정하고, 상기 결정된 작업 노드는 상기 태스크를 수행하고, 상기 마스터 노드가 상기 태스크가 수행된 결과를 수집하여 상기 외부 기기에 응답하는, 멀티 클라우드 엣지 시스템."}
{"patent_id": "10-2022-0119177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2023-0069813-3-청구항 1에 있어서,상기 코어 클라우드와 상기 제1 엣지 노드 시스템이 제공하는 수직 협업 계산에 의한 서비스 및 상기 제1 엣지노드 시스템과 상기 니어 엣지 노드 시스템이 제공하는 수평 협업 계산에 의한 서비스를 제공하는, 멀티 클라우드 엣지 시스템."}
{"patent_id": "10-2022-0119177", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "멀티 클라우드 엣지 시스템이 개시된다. 본 발명의 일실시예에 따른 멀티 클라우드 엣지 시스템은 코어 클라우 드; 멀티 클러스터 기반 제1 엣지(A FIRST EDGE) 노드 시스템; 및 멀티 클러스터 기반 니어 엣지(NEAR EDGE) 노 드 시스템을 포함하고, 상기 멀티 클러스터 기반 제1 엣지 노드 시스템은 복수의 작업 노드들; 및 스케줄러를 가 지는 마스터 노드를 포함한다."}
{"patent_id": "10-2022-0119177", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 멀티 클라우드 엣지 시스템에 관한 것으로, 특히 엣지 컴퓨팅의 서비스를 위하여 다중 클러스터를 구 성하고, 이를 관리하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0119177", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "엣지 컴퓨팅 기술은 엔터프라이즈 데이터 센터 또는 중앙 집중식 클라우드 서비스 중 일부를 필요로 하고, 이를 포함하는 다양한 분산 컴퓨팅 토폴로지의 일부분으로써 컴퓨팅 스토리지 소프트웨어 등을 코어에서 엣지로 배포 한다. 그리고, 기존 클라우드-단말 중심의 중앙 집중형 클라우드 인프라보다 빠른 서비스 제공을 위해 서비스 사용자에 근접한 컴퓨팅 자원을 선택적으로 활용하는 코어 클라우드-클라우드 엣지-단말 협업 기반 저지연 데이 터 처리 기술을 제공함으로써 응답 속도와 필수 안전(Safety-Critical) 서비스의 안정성을 보장한다. 최근 사용자가 원하는 대규모 단말들이 생성하는 폭증 데이터의 중앙 클라우드 집중화로 인한 처리 및 전송 지 연 극복을 위해, 단말 근접 위치에서 데이터를 처리하는 지능형 클라우드 엣지 서비스를 제공하는 기술 개발 및 관련 서비스 시스템들이 출시되고 있다. 그 중 단일 클러스터로 운영되는 쿠버네티스(Kubernetes)의 경우, OCI 기반의 컨테이너 환경을 오케스트레이션 및 통합 운영하도록 설계된 도구로서 현재 가장 많이 사용되는 도구이 다. 그러나 쿠버네티스의 경우에는 단일 클러스터 환경의 용도가 제한되어 있고, 다중 클러스터를 연계하기 위 한 도구가 필요하다. 예를 들어, Rancher는 다중 클러스터로 구성된 쿠버네티스를 지원하기 위하여 다중 쿠버네 티스 클러스터를 설치하고 설정하도록 고안되었다. 그리고 사용자가 손쉽게 퍼블릭 클라우드와 베어 메탈 서버 까지 모두 지원할 수 있도록 고안되어 설계되었다. 또한, 분산되어 있는 클라우드 엣지와 코어 클라우드를 연계하여 서비스하기 위해 다양한 방법들이 연구되고 있 다. 이를 위해, L7 레이어 기반의 서비스 메시 기술로 오픈소스 진영의 오픈시프트(Istio)가 활발히 진행되고 있다. 서비스 메시는 마이크로 서비스 간의 연계를 위하여 개발된 프로그램이다. 이 방법은 다중 네트워크 상에 서 제어 플레인을 공유하고 게이트웨이를 통하여 클러스터간 통신하므로 두 개의 네트워크가 직접 연결되지 않 아도 된다. 클라우드 컴퓨팅은 데이터를 처리하는 곳이 데이터 센터이지만, 엣지 컴퓨팅은 대규모 엣지 단말들이 생성하는 방대한 데이터의 클라우드 집중화로 인한 처리 및 전송 지연 극복을 위해 단말 근접 위치에서 데이터를 처리하 고 클라우드-엣지-단말 간 분산 협업을 수행하는 고성능의 플랫폼이 필요하다. 그러나, 기존 엣지 시스템은 다중 클러스터를 감안한 관리 방법의 미흡, 베어메탈, 컨테이너, FaaS 서비스 등에 최적화되지 않은 형태로 서비스 제공, 여유 자원 부족 시 성능 보장을 위한 자원 추가 방법 미제공, 수직적/수 평적 협업을 위한 응용프로그램 수준에서 설계 필요, 다중 클러스터를 고속으로 연결하기 위한 네트워크 구조가 미흡, 쿠버네티스에 사용되는 OCI의 성능 문제(응답 속도 민감한 서비스 지연), 완벽한 협업 솔루션을 위한 아 키텍처 상의 기술 부재 등의 문제점을 가지고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개 특허 제10-2018-0119905호, 2018년 11월 5일 공개(명칭: 분산형 클라우드 기반 어플 리케이션 실행 시스템, 이에 적용되는 장치 및 장치의 동작 방법)"}
{"patent_id": "10-2022-0119177", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2022-0119177", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 엣지 컴퓨팅에서 컨테이너에 기반한 분산 컴퓨팅 환경을 지원하도록 다중 클러스터 간 연계할 수 있는 터널링 기반의 고속 네트워크 환경을 구성하는 것이다. 또한, 본 발명의 목적은 연계된 네트워크 상에서 클러스터 간의 최적 관리 및 서비스의 협업을 위하여 새로운 고성능 아키텍처를 제안하는 것이다. 또한, 본 발명의 목적은 클라우드와 엣지 간 수직적 및 수평적 협업 최적화를 위한 시스템의 구조 및 지능형 스 케줄링 방법을 제공함으로써 응용프로그램 개발자가 엣지-엣지 단말간 수직적 협업, 엣지-클라우드 엣지 간 수 평적 협업을 연동하는 엣지 플랫폼 기반 분산 협업을 시스템 레벨에서 적용 및 구체화하도록 지원하는 것이다. 또한, 본 발명의 목적은 컨테이너의 효율성을 높이기 위한 메모리 기반 저장장치를 활용하여 고성능 컨테이너 및 컨테이너 간 데이터 연계를 위한 글로벌 캐시를 구성하는 것이다."}
{"patent_id": "10-2022-0119177", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명에 따른 멀티 클라우드 엣지 시스템은 코어 클라우드; 멀티 클러스터 기반 제1 엣지(A FIRST EDGE) 노드 시스템; 및 멀티 클러스터 기반 니어 엣지(NEAR EDGE) 노드 시스템을 포함하고, 상기 멀티 클러스터 기반 제1 엣지 노드 시스템은 복수의 작업 노드들; 및 스케줄러를 가지는 마스터 노드를 포 함한다. 이 때, 제1 엣지 노드 시스템과 상기 니어 엣지 노드 시스템을 터널링 프로토콜에 따라 고속 네트워크로 연결할 수 있다. 이 때, 제1 엣지 노드 시스템과 상기 니어 엣지 노드 시스템의 협업 연산에 따른 데이터를 공유 저장하는 공유 저장장치를 더 포함할 수 있다. 이 때, 제1 엣지 노드 시스템과 상기 니어 엣지 노드 시스템의 데이터를 기반으로 협업 연산에 필요한 리소스를 제어하는 매니지먼트 노드를 더 포함할 수 있다. 이 때, 제1 엣지 노드 시스템 또는 상기 니어 엣지 노드 시스템은 컴퓨팅 노드들을 포함하고, 상기 컴퓨팅 노드 들은 컨테이너 플랫폼 기반으로 모놀리틱 어플리케이션(MONOLITHIC APPLICATION), 마이크로 서비스(MICRO SERVICE) 및 서비스형 함수(FUNCTION AS A SERVICE)를 제공할 수 있다. 이 때, 제1 엣지 노드 시스템은 외부 기기로부터 태스크(TASK)에 대한 연산 로드를 요청받고, 상기 마스터 노드 는 상기 스케줄러를 이용하여 상기 태스크(TASK)를 수행할 수 있는 어플리케이션이 배포된 작업 노드를 결정하 고, 상기 결정된 작업 노드는 상기 태스크를 수행하고, 상기 마스터 노드가 상기 태스크가 수행된 결과를 수집 하여 상기 외부 기기에 응답할 수 있다. 이 때, 코어 클라우드와 상기 제1 엣지 노드 시스템이 제공하는 수직 협업 계산에 의한 서비스 및 상기 제1 엣 지 노드 시스템과 상기 니어 엣지 노드 시스템이 제공하는 수평 협업 계산에 의한 서비스를 제공할 수 있다."}
{"patent_id": "10-2022-0119177", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 컨테이너의 효율성을 높이기 위한 메모리 기반 저장장치를 활용하여 고성능 컨테이너 및 컨 테이너 간 데이터 연계를 위한 글로벌 캐시를 구성함으로써 클러스터 간의 효율적인 협업을 위한 고성능 아키텍 처를 제공할 수 있다. 또한, 본 발명은 터널링 기반의 고속 네트워크를 연결하여 클러스터 간의 협업 서비스를 제공할 수 있다. 또한, 본 발명은 코어 클라우드와 엣지 간의 수평적 협업과 엣지와 엣지 단말 간의 수평적 협업을 연동하는 엣 지 플랫폼 기반의 분산 협업이 시스템 레벨에서 적용 구체화되도록 할 수 있다."}
{"patent_id": "10-2022-0119177", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명을 첨부된 도면을 참조하여 상세히 설명하면 다음과 같다. 여기서, 반복되는 설명, 본 발명의 요지를 불 필요하게 흐릴 수 있는 공지 기능, 및 구성에 대한 상세한 설명은 생략한다. 본 발명의 실시형태는 당 업계에서 평균적인 지식을 가진 자에게 본 발명을 보다 완전하게 설명하기 위해서 제공되는 것이다. 따라서, 도면에서의 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. 이하, 본 발명에 따른 바람직한 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 본 발명에 따른 엣지 서비스를 위한 다중 클러스터 연계 아키텍처 구조의 일 예를 나타낸 도면이다. 도 1을 참조하면, 본 발명에 따른 엣지 시스템 상에서, 수직 협업은 코어 클라우드와 엣지 간의 협업 을 지칭하고, 수평 협업은 엣지와 이웃 엣지 간의 협업을 지칭할 수 있다. 이 때, 각 협업을 위해서는 도 1에 도시된 것과 같은 네트워크 연결이 필요하다. 따라서, 본 발명에서는 협업을 위한 터널링 기반 고속 네트워크가 구성되고, 상호간의 클러스터를 연계하기 위한 공유된 스토리지 및 저장소를 구성할 수 있다. 이렇게 구성된 엣지 시스템은 전체 관리를 담당하는 글로벌 스케줄러에 의해서 구동되고 관리될 수 있다. 이 때, 클러스터의 노드들은 컨테이너 플랫폼으로 모놀리틱 응용, 마이크로 서비스 및 FaaS(Function as a Service) 시스템 등으로 이루어 질 수 있다. 앞서 말한 바와 같이 컨테이너 플랫폼은 메모리 기반 저장 장치를 활용한 메모리 상주형 컨테이너를 기반으로 구성하고, 글로벌 캐시 역시 고속 구성을 위한 메모리 기반 스토리 지를 활용할 수 있다. 이 때, 기존 엣지 서비스는 도 2에 도시된 것처럼 수직적 협업만 지원하는 형태로 다음과 같은 문제점을 가지고 있다. - 이동체 이동 지원 미흡 - 부분적인 수직적 협업 - 협업을 위한 제한적인 연동 기술 - 서비스 연계 부분적 지원 즉, 도 2와 같은 기존 엣지 서비스를 위한 시스템은 클라우드와 엣지 둘만의 관계로 구성되지만, 본 발명에서 제안하는 엣지 서비스 시스템은 도 3과 같이 클라우드, 엣지뿐만 아니라 이웃 엣지(Near Edge)라는 개념적 엣지 가 추가된 3가지 위치(3 Locations)로 구성될 수 있다. 이 때, 3가지 위치(3 Locations)는 클라우드 (Public / Private Cloud), 엣지 (사용자와 직접 연결되어 서비스 되는 엣지), 이웃 엣지 (Near Edge로 엣지와 가까운 주변 엣지)를 의미할 수 있다. 또한, 도 2를 참조하면, 기존 엣지 서비스는 모놀리틱 응용과 마이크로 서비스만을 제공하지만, 본 발명에서 제 안하는 엣지 서비스 시스템에서는 도 3에 도시된 것처럼 모놀리틱 응용(Monolithic App), 마이크로 서비스 (Micro Service), 서비스형 함수(FaaS)에 해당하는 3가지 애플리케이션 형태(3 Application Types)를 지원할 수 있다. 이 때, 3가지 애플리케이션 형태(3 Application Types)는 [표 1]과 같이 응용프로그램의 복잡도나 서비스 규모, 그리고 자원사용 형태 측면에서 서로 다른 특성을 가질 수 있다. 표 1 애플리케이션 형태 복잡도규모 자원사용 형태 모놀리틱 응용 간단 중 상시 자원사용 마이크로 서비스 복잡 상 부분적 자원사용 확대/축소 가능 서비스형 함수 간단 하 한시적 자원사용 따라서, 본 발명에서 제안하는 엣지 서비스는 이러한 특성을 잘 반영한 상호 협업이나 서비스 이동과 같은 기능 을 효과적으로 적용할 필요가 있다. 이 때, 도 3에 따르면, 본 발명에 따른 엣지 서비스 시스템의 수직적 및 수평적 협업 최적화는 3LT(3 Locations, 3 Application Types )을 바탕으로 지원할 수 있다. 즉, 도 2와 같은 기존 엣지 서비스는 부분적이 고, 수직적 협업만 제공하기 때문에 서비스 협업이 제한적이거나 서비스 연계가 부분적이라는 한계를 가지고 있 다. 따라서, 본 발명에서는 이러한 문제점을 해결하기 위하여, 도 3에 도시된 3LT 기반 엣지 서비스 시스템을 통해 위치나 서비스 타입에 관계없이 다양한 수직적 및 수평적 협업이 가능한 구조를 제안한다. 이 때, 도 4는 본 발명에 따른 수직적 및 수평적 협업이 가능한 엣지 서비스의 일 예를 나타낸 것으로, 3L를 이 용한 스케일 아웃, 3L를 이용한 스케일 업, 3L를 이용한 예측형 오버 엣지 등의 형태에 상응하게 클라우드와 엣 지 시스템 간 주요 협업을 지원할 수 있다. 도 5는 본 발명에 따른 인메모리 컨테이너 스토리지 기반 컨테이너 시스템 구조의 일 예를 나타낸 도면이다. 도 5를 참조하면, 본 발명에 따른 인메모리 컨테이너 스토리지 시스템은 인메모리 컨테이너 스토리지, 인 메모리 컨테이너 스토리지 엔진, 메인 메모리, 디스크 스토리지 및 원격 스토리지로 구성될 수 있다. 이하에서는 도 6을 참조하여 본 발명에 따른 인메모리 컨테이너 스토리지 시스템의 구조 및 동작 흐름을 보다 상세하게 설명하도록 한다. 먼저, 컨테이너는 비휘발성 특성을 갖는 메인 메모리상의 스토리지인 인메모리 컨테이너 스토리지를 생성 할 수 있고, 인메모리 컨테이너 스토리지 상에 컨테이너의 스토리지 볼륨을 구성할 수 있다. 컨테이너는 인메모리 컨테이너 스토리지 상에 컨테이너가 수행되는 파일 시스템(docker의 예는 /var/lib/docker) 볼륨인 컨테이너 스토리지 볼륨을 생성하고 동작할 수 있다. 따라서, 컨테이너에서 발생한 컨 테이너 접근 명령은 인메모리 컨테이너 스토리지로 전달될 수 있다. 인메모리 컨테이너 스토리지 엔진은 메인 메모리, 디스크 스토리지 및 원격 스토리지를 통합하여 단일 형 상의 인메모리 컨테이너 스토리지를 생성할 수 있다. 또한, 인메모리 컨테이너 스토리지 엔진은 메인 메모리와 디스크 스토리지 및 원격 스토리지를 통합 사용하여 디스크 접근 명령을 처리한다. 이 때, 인메모리 컨테이너 스토리지는 인메모리 컨테이너 스토리지 엔진을 통해 표준 블록 스토리지 형식의 인터페이스를 제공함으로써 별도의 수정없이 운영할 수 있다. 이하에서는 도 7을 참조하여 본 발명에 따른 인메모리 컨테이너 스토리지 엔진의 구조를 보다 상세하게 설명하 도록 한다. 도 7을 참조하면, 인메모리 컨테이너 스토리지 엔진은 스토리지 인터페이스 모듈, 스토리지 접근 분 산 모듈, 스토리지 제어 모듈로 구성될 수 있다. 먼저, 스토리지 인터페이스 모듈은 표준 블록 스토리지 형식의 인터페이스를 제공할 수 있고, 컨테이너에 서 발생한 디스크 접근 명령을 수신할 수 있다. 이렇게 수신된 명령어는 스토리지 접근 분산 모듈로 전달 될 수 있다. 스토리지 접근 분산 모듈은 디스크 접근 명령의 특징에 따라서 메인 메모리 스토리지, 디스크 스토리지 혹 은 원격 스토리지를 사용하여 서비스를 수행할지 여부를 결정할 수 있다. 이 후, 스토리지 제어 모듈에 포 함된 메인 메모리 제어 모듈, 디스크 스토리지 제어 모듈 및 원격 스토리지 제어 모듈로 접근 명령을 전달할 수 있다. 스토리지 제어 모듈은 메인 메모리 제어 모듈, 디스크 스토리지 제어 모듈, 원격 스토리지 제어 모듈, 메 인 메모리 디스크 생성 모듈, 디스크 백업/복원 모듈, 실시간 동기화 모듈로 구성될 수 있다. 메인 메모리 제어 모듈은 메인 메모리를 사용하여 디스크 접근 명령을 처리할 수 있으며, 이는 고속의 접근 속 도를 제공할 수 있다. 예를 들어, 메인 메모리 제어 모듈로 디스크 접근 명령이 수신되는 경우, 메인 메모리 디스크 생성 모듈을 통해 블록 단위로 전송된 디스크 접근 명령어들을 주소 단위로 접근 가능한 메인 메모리상에 실제로 읽기(Read)/쓰기 (Write) 처리할 수 있다. 이를 통해 메인 메모리 상에 가상 디스크의 데이터들을 생성 및 저장할 수 있다. 디스크 스토리지 제어 모듈은 디스크 스토리지를 사용하여 가상 데스크 접근 명령을 처리할 수 있다. 도 8은 본 발명에 따른 컨테이너 인메모리 스토리지 생성 방식의 일 예를 나타낸 도면이다. 도 8을 참조하면, 메인 메모리 스토리지와 디스크 스토리지를 통합하여 단일 하이브리드 형태의 컨테 이너 인메모리 스토리지를 생성하는 방법을 보여준다. 인메모리 컨테이너 스토리지는 표준 블록 스토리지 형식을 제공하며, 스토리지의 앞부분에 메인 메모리 스 토리지의 영역을 매핑하고, 뒷 부분에 디스크 스토리지 영역을 매핑하여 생성될 수 있다. 예를 들어, 메인 메모리 스토리지의 블록 ID 1부터 N에 해당하는 영역은 인메모리 컨테이너 스토리지(80 0)의 블록ID 1부터 N에 해당하는 영역에 매핑될 수 있다. 또한, 디스크 스토리지의 블록 ID 1부터 M에 해 당하는 영역은 인메모리 컨테이너 스토리지의 블록 ID N+1부터 N+M에 해당하는 영역으로 매핑될 수 있다. 이 때, 컨테이너 인메모리 스토리지에서 블록 ID N과 N+1 사이에 메인 메모리 스토리지의 영역과 디 스크 스토리지의 영역을 구분하기 위한 스토리지 경계가 설정될 수 있다. 도 9는 본 발명에 따른 인메모리 스토리지에 구현된 컨테이너 파일 시스템의 일 예를 나타낸 도면이다. 도 9를 참조하면, 본 발명에 따라 컨테이너에서 사용하는 파일 시스템은 인메모리 컨테이너 스토리지 상에 구성 될 수 있다. 본 발명에 따르면, 컨테이너의 메인 메모리 구동을 위해 컨테이너의 기본 파일 시스템이 메인 메모리에서 구동 될 수 있다. 예를 들어, 컨테이너의 경우에는 기존의 리눅스 환경의 커널에 포함되어 있는 파일 시스템 통합 (Unifying File system) 기능을 사용하여 사용자가 필요한 파일을 개별적으로 제공할 수 있다. 이 때, 파일 시스템 통합(Unifying File system) 기능은 단일 마운트 지점에 여러 파일 시스템을 마운트하는 개 념이며, 새로운 파일 시스템 유형을 생성하는 대신에 VFS(virtual file system) 계층에서 모든 디렉토리 항목을 통합하여 처리할 수 있다. 따라서, 파일 시스템 통합 기능을 사용하면 하위 파일 시스템의 디렉토리 항목이 상 위 파일 시스템의 디렉토리 항목과 병합되어 마운트된 모든 파일 시스템의 논리적 조합이 생성될 수 있다. 그러 므로 시스템에서 공유된 전체 파일 시스템에 대한 관리 및 파일 찾기가 로컬에서 가능하게 되고, 전체 공유를 위한 파일 관리가 수월해질 수 있다. 즉, 도 9에 도시된 것처럼, 본 발명에 따른 컨테이너 파일 시스템은 통합 파일 시스템으로써 계층(layer) 형태 로 구성될 수 있다. 통합 접근 영역(merged), 컨테이너 계층 (container layer) 및 이미지 계층(image layer)으로 분류되는 각 계층은 인메모리 컨테이너 스토리지 상에 특정 디렉토리를 생성 및 마운트하여 동작할 수 있다. 먼저, 컨테이너 계층은 쓰기(write)가 가능한 계층으로, 최상단 계층에 생성되어 각 컨테이너마다 자신만 의 상태를 가질 수 있게 해준다. 이 때, 컨테이너가 생성된 이후 모든 변경 작업이 컨테이너 계층에서 수 행될 수 있다. 또한, 컨테이너 계층에서의 읽기(read)/쓰기(write)는 메모리 상에서 이루어지기 때문에 빠 른 속도로 동작할 수 있다. 그리고, 파일 관리의 효율성을 위해 실제 이미지와 컨테이너 이미지의 차분 (difference) 정보를 포함할 수 있다. 이미지 계층은 읽기(read) 전용 계층으로 다른 컨테이너와 공유할 수 있다. 이 때, 다른 계층과 공유된 이 미지를 컨테이너 계층에서 여러 개로 동작 시킬 수 있다. 즉, 이미지 계층은 서로 다른 여러 시스템과 컨테이너 이미지를 공유함으로써 그 효율성을 높일 수가 있다. 예를 들어, 도 9에 도시된 것처럼, 이미지 계층의 컨테이너 이미지는 컨테이너 배포 시 이미지를 공용 레 포지터리(예:github)에서 풀링해야 된다. 이 때, 성능 보장을 위하여 컨테이너 시스템에서 사용하는 이미지를 로컬에 보관하거나 사전에 가져다 놓음으로써 효율적으로 동작할 수 있다. 본 발명에서는 이미 풀링한 이미지를 재사용하기 위하여 공유 스토리지에 보관하는 방법을 제안하도록 한다. 앞 서 설명한 바와 같이 이미지 계층의 많은 이미지들은 인메모리 컨테이너 스토리지 상에 존재하고, 전체 시 스템의 컨테이너 이미지는 백업을 진행하여 디스크 스토리지 혹은 원격 스토리지에 저장하는데, 이를 이미지 계 층에 추가할 수 있다. 이를 통해 전체 시스템의 컨테이너 이미지를 컨테이너 계층에서도 사용 가능하 고, 통합 접근 영역을 통해서도 지속적으로 이미지들을 제공할 수 있다. 통합 접근 영역은 컨테이너 계층과 이미지 계층의 모든 파일 시스템에 접근 가능하도록 계층의 링크 정보를 포함할 수 있고, 이러한 링크 정보는 사용자에게 공유함으로써 파일 접근을 가능하게 할 수 있다. 도 10은 본 발명에 따른 인메모리 컨테이너 스토리지의 이미지 공유 환경의 일 예를 나타낸 도면이다. 도 10을 참조하면, 본 발명에 따른 인메모리 컨테이너 스토리지에서 공유 데이터를 제공하기 위해서는 공유 스 토리지를 이용할 수 있다. 예를 들어, 공유 스토리지는 네트워크 파일 스토리지일수도 있고(SAN, NAS 등) 로컬 디스크 내에 연결된 스토리지 일수도 있다. 도 10을 참조하면, 본 발명에 따른 이미지 공유 환경은 공유 스토리지에 저장된 컨테이너 이미지를 사용 자의 요청에 의하여 사용자에게 제공하는 구조일 수 있다. 예를 들어, 도 5 및 도 7에 도시된 인메모리 컨테이너 스토리지 관리 모듈의 컨테이너 파일 시스템 계층 관리 모듈을 통하여 공유 관리 기능을 제공할 수 있고, 사용자에게 파일 공유를 위한 영역을 개별적으로 구성하여 제 공함으로써 사용자에게 공유 데이터를 제공할 수 있다. 이하에서는 도 11을 참조하여 도 10과 같이 공유 데이터 제공을 위한 인메모리 컨테이너 스토리지를 갖는 노드 (Node)에서 데이터를 공유하는 과정을 상세하게 설명하도록 한다. 도 11은 본 발명에 따른 데이터 공유 시 모든 데이터를 공유하는 것이 아니라, 공유 데이터를 사용하는 그룹에 따라 공유하고 싶은 데이터를 구별하여 제공함으로써 보안성을 향상시킬 수 있는 사용자(Tenant) 접근 방법을 나타내고 있다. 먼저, 사용자(Tenant)의 요청에 따라 Node A 인메모리 컨테이너 스토리지에 사용자의 디렉토리 (/sharedData/tenant)를 생성하고, 컨테이너 계층(upper 디렉토리)에서 사용자의 디렉토리 (/sharedData/tenant) 밑에 하나의 디렉토리(diff)를 생성하고 맵핑할 수 있다. 이 때, 파일시스템 관리를 위하 여 사용자의 데이터는 중복제거(deduplication)된 데이터를 사용할 수 있다. 이렇게 생성된 diff 디렉토리는 컨 테이너 계층에 해당되고, 사용자가 파일에 접근하거나 편집/수정하여 저장하는 데이터에 해당할 수 있다. 또한, work 디렉토리도 사용자의 디렉토리 밑에 생성하여 맵핑할 수 있다. work 디렉토리는 컨테이너 계층의 사용자 데이터 저장 영역에 해당할 수 있다. 또한, 이미지 계층에서 최하위에 위치하는 lower 디렉토리(lowerdir2=/sharedData/base/File1-Link, File2-Link쪋FileN-Link/)는 공유 스토리지의 모든 파일 링크를 저장하고 있는 관리 포인트로써 (/sharedData/base...)로 설정될 수 있다. 이 때, 이미지 계층에서는 사용자가 필요한 파일을 선택할 수 있도록 lower 디렉토리 (lowerdir2=/sharedData/base/File1-Link, File2-Link쪋FileN-Link/)를 관리 시스템으로 노출시킬 수 있는데, 이미지 계층에 생성된 lower 디렉토리(lowerdir1=/sharedData/tenantA/base/File1-Link, File2-Link)가 upper 디렉토리와 연계하여 사용자가 선택한 파일에 대해서만 링크 정보를 배치시킬 수 있다. 이러한 과정을 통하여 사용자는 자신이 선택한 파일만 하위 시스템을 통하여 볼 수 있게 된다. 따라서, 사용자는 자신과 공유된 사용자 디렉토리를 통하여 파일을 공유 받을 수 있고, lower 디렉토리들은 항 상 불변의 상태를 유지할 수 있다. 즉, lower 디렉토리들은 읽기 전용으로 사용됨으로써 여러 사람들이 데이터 를 공유할 때 쓰기(write)가 발생하는 문제를 효율적으로 방지할 수 있다. 만약, lower 디렉토리 파일에 변경 사항이 발생할 경우, upper 디렉토리에 그 변경 사항을 기록하기 때문에 전체적인 공유 파일도 효율적으로 관리 할 수 있다. 도 12는 도 5에 도시된 인메모리 컨테이너 스토리지 관리 모듈의 상세 구조의 일 예를 나타낸 도면이다. 도 12를 참조하면, 본 발명에 따른 인메모리 컨테이너 스토리지 관리 모듈은 컨테이너 파일 시스템 계층 관리 모듈, 인메모리 컨테이너 스토리지 생성 관리 모듈, 인메모리 컨테이너 스토리지 공유 관리 모듈 및 인메 모리 컨테이너 엔진 관리 모듈로 구성될 수 있다. 컨테이너 파일 시스템 계층 관리 모듈은 컨테이너 파일 시스템의 현재 상태 및 구동 상태를 모니터링 할 수 있 다. 또한, 인메모리 컨테이너 스토리지를 사용할 경우, 컨테이너 시스템의 생성 및 상태를 관리할 수도 있다. 인메모리 컨테이너 스토리지 생성 관리 모듈은 사용자의 요청에 의해 컨테이너를 인메모리 형태로 구성하고자 할 경우, 인메모리 컨테이너 스토리지를 생성할 수 있다. 이 때, 인메모리 컨테이너 스토리지가 생성 완료 되면, 컨테이너 파일 시스템 계층 관리 모듈이 시스템의 컨테이너 파일 시스템을 생성하게 된다. 인메모리 컨테이너 스토리지 공유 관리 모듈은 사용자의 요청에 따라 이미지 계층을 공유하도록 스토리지 간의 공유 파일 시스템을 생성하고, 이를 동기화 하는 작업을 수행할 수 있다. 이 때, 이미지 계층의 링크 정보는 하 나의 시스템에 병합되고 이를 동기화할 수 있다. 인메모리 컨테이너 스토리지 엔진 관리 모듈은 시스템의 인메모리 컨테이너 스토리지 드라이버를 구동하고 생성 하며, 이에 대한 상태를 모니터링 할 수 있다. 이하에서는 도 13을 참조하여 본 발명에 따른 인메모리 컨테이너 스토리지 관리 모듈에서 데이터 공유 관리를 수행하는 과정을 상세하게 설명하도록 한다. 먼저, 사용자(Tenant)가 시스템에 접근하여 파일 공유를 요청 및 선택할 수 있다(S1302, S1304). 이 때, 사용자는 파일 공유를 받을 사용자와 파일 공유를 제공하기 위한 제공자로 나뉠 수 있다. 따라서, 사용자가 파일 공유를 제공하는 제공자인지 여부를 판단할 수 있다(S1306). 단계(S1306)의 판단결과 사용자가 파일 공유를 받는 사용자이면, 해당 사용자가 최초의 사용자인지 여부를 판단 할 수 있다(S1308). 단계(S1308)의 판단결과 최초 사용자이면, 사용자 디렉토리를 생성하고(S1310), 관련 디렉토리들을 생성하여 (S1312) 전체 시스템 환경을 마운트할 수 있다(S1314). 이 후, 사용자 디렉토리의 Lower 디렉토리로 이동하여(S1316), 사용자가 요청한 공유 파일에 대한 링크 정보를 공유 스토리지 베이스(Base)로부터 찾아 생성할 수 있다(S1318). 또한, 단계(S1308)의 판단결과 최초 사용자가 아니면, 사용자의 디렉토리의 Lower 디렉토리로 바로 이동하여 (S1316), 사용자가 요청한 공유 파일에 대한 링크 정보를 공유 스토리지 베이스(Base)로부터 찾아 생성할 수 있 다 (S1318). 또한, 단계(S1306)의 판단결과 사용자가 파일 공유를 제공하는 제공자이면, 공유 스토리지로 접근하여 파일을 업로드하고(S1320), 공유 스토리지 베이스로 이동하여(S1322) 공유 파일 링크를 생성할 수 있다(S1324). 도 14는 본 발명에 따른 클러스터간 연결 구조의 일 예를 나타낸 도면이다. 본 발명은 엣지 컴퓨팅 서비스를 원활하게 제공하고, 대용량 데이터의 처리 및 분산 환경의 효율성을 극대화하 기 위한 것이다. 따라서, 코어 클라우드와 클라우드 엣지 간 수직 분산 환경과 클라우드 엣지들 간의 수평 분산 환경에 대한 고려사항은 엣지 컴퓨팅의 협업 기능을 제공하기 위해 필수적인 요구된다. 예를 들어, 클러스터를 넘어 지역적으로 분산 배치되는 엣지 컴퓨팅의 분산 환경 서비스가 고속 네트워크로 연 결되기 위해서는 클러스터 간의 상호 연결 및 고속 분산 배치 기술이 필수적이다. 그러므로, 클러스터간 연결 구조는 클라우드 엣지 시스템의 다중 클러스터 노드 상 네트워크 연결 기능과 이에 대한 인터페이스를 고려하여 설계되어야 한다. 또한, 네트워크 연결 기능과 함께 빠른 데이터 이동 및 저장소를 연동하기 위한 기능 역시 요 구된다. 도 14를 참조하면, 본 발명에 따른 서비스 연결 구조는 코어-엣지, 엣지-엣지 간 연계하기 위한 다중 클러스터 상의 네트워크 연결 기능을 의미할 수 있다. 다시 말하면, 클라우드 엣지의 이동형 서비스에 따른 근접 엣지의 사용 및 무중단 서비스를 위하여 서로 다른 네트워크를 연계하기 위한 기능에 해당할 수 있다. 이 때, 본 발명은 다중 클러스터를 네트워크로 연계하기 위하여 고속의 게이트웨이(Gateway Engine) 기능과 클 러스터 내부에 인식을 위한 기본 라우팅(Route engine) 기능을 제공할 수 있다. 게이트웨이 및 라우터는 클러스 터 상의 관리 기능으로 글로벌 엣지 스케줄러를 통하여 지역적으로 배포가 가능하다 이 때, 고속의 게이트웨이는 다중 클러스터를 고속으로 연계 운용하기 위한 네트워크 연결 방식으로, 두 네트워 크 간의 터널링을 이용하여 연계할 수 있다. 터널링을 통해 페이로드를 터널링 구간에서 캡슐화하고, 특정 프로토콜을 사용함으로써 신뢰성 있는 데이터 전 송을 보장할 수 있다. 또한, 터널링은 인터넷의 7 계층(Layer) 중 L7, L3, L2 계층에서 적용이 가능하다. 저수 준의 계층의 터널링을 지원할수록 상위 레이어에서 사용하는 많은 프로토콜을 그대로 사용할 수 있고, 성능 또 한 빠르다. 도 14에서는 L3 계층의 터널링을 이용하여 두 클러스터를 연계하는 일 예를 나타낸다. 이렇게 연결된 터널링에 사용되는 프로토콜의 경우, 다른 프로토콜의 비해 처리 속도가 느린 경우가 많은데, 본 발명에서는 이를 극복하 기 위하여 커널 바이패스를 위한 사용자 수준의 네트워크 드라이버(DPDK, Data Plane Development Kit)를 사용 하여 터널링 네트워크와 연결하도록 한다. 그리고, 마스터 노드와 워커 노드 간의 인터페이스는 터널링 인터페이스와 브리지를 통하여 연결될 수 있고, 기 존의 오버레이 네트워크로 구성된 네트워크와 연결될 수 있다.보다 상세하게는 도 14에 도시된 클러스터간 연결 구조에 의해 고속 게이트웨이 엔진 기능, 글로벌 공유 캐시 기능, 커널 바이패스 지원 네트워크 스택 구성 기능, 사용자 수준 네트워크 드라이버 관리 기능 및 라우터 에이 전트 기능을 제공할 수 있다. 고속 게이트웨이 엔진 기능은 사용자 수준의 네트워크 드라이버를 활용한 L3 계층의 다중 클러스터 터널링 기능 을 수행할 수 있다. 글로벌 공유 캐시 기능은 메모리 기반 저장소를 활용한 네트워크 기반 스토리지 시스템을 활용하여 고속의 공유 스토리지를 만든 후 로컬 공유 캐시와 연계하여 데이터를 공유하기 위한 저장소 기능으로써 마스터 노드에 있는 스토리지를 네트워크 기반 공유 스토리지로 활용할 수 있다. 커널 바이패스 지원 네트워크 스택 구성 기능은 커널 바이패스를 위한 라이브러리, 장치 관리 및 구성 관리 기 능(예 DPDK 하드웨어 지원 스택)에 해당할 수 있다. 사용자 수준 네트워크 드라이버 관리 기능은 사용자 수준의 네트워크 드라이버를 배포, 연결 및 관리하기 위한 CLI 기능(응용단에서 제공되는 네트워크 드라이버 예: Cisco FD.io 등)에 해당할 수 있다. 라우터 에이전트 기능은 모든 노드에서 실행되고 다른 클러스터에서 동기화된 Endpoint resources를 사용하여 경로를 구성하고, 전체 클러스터 간 연결을 활성화할 수 있다. 이 때, Iptable의 규칙을 설정할 수 있는데, 게 이트웨이 엔진과 연결되어 통신하기 위하여 게이트웨이 엔진의 라우팅 테이블을 가지게 될 수 있다. 도 15는 본 발명에 따른 엣지 서비스 시스템 스케줄러 구성의 일 예를 나타낸 도면이다. 기존의 엣지 서비스 시스템의 스케줄러는 특정 로직으로 정해진 고정적인 스케줄러로, 이러한 비적응형 스케줄 러는 서비스 규모나 사용 패턴의 변화에 대해 능동적으로 자원을 배치하거나 사용하는데 최적화하기 힘든 구조 를 갖는다. 따라서, 본 발명에서는 기존 스케줄러의 문제점들을 개선하기 위한 다중 클러스터 기반의 새로운 스케줄러를 제 안하고자 한다. 본 발명을 통해 제안하는 스케줄러의 적용 대상은 모놀리틱 응용이나 마이크로 서비스를 실행하기 위한 상주형 컨테이너와 서비스형 함수(FaaS)의 실행을 위한 비상주형 컨테이너에 해당할 수 있다. 도 15를 참조하면, 본 발명에 따른 엣지 서비스 시스템 스케줄러는 글로벌 엣지 스케줄러와 3 Locations 에 해당하는 3가지 스케줄러(1520, 1530, 1540)를 포함한 4종류의 스케줄러로 구성될 수 있다. 글로벌 엣지 스케줄러는 클라우드 스케줄러, 마스터 엣지 스케줄러, 이웃 엣지 스케줄러 를 연동하기 위한 스케줄러에 해당할 수 있다. 클라우드 스케줄러는 공용 및 개인용 클라우드의 스케줄러에 해당할 수 있다. 마스터 엣지 스케줄러는 주요 서비스가 실행되는 엣지(마스터 엣지)의 스케줄러에 해당할 수 있다. 이웃 엣지 스케줄러는 마스터 엣지의 주변에 있는 이웃 엣지의 스케줄러에 해당할 수 있다. 이렇게 구성된 엣지 서비스 스케줄러는 동적으로 정책 설정이 가능한 스케줄러이면서 로그 데이터 분석을 통한 지능형 스케줄러이다. 또한, 스케줄링 정책 변경에 따른 비용을 최소화할 수 있으며, 대기 및 지연 시간을 최소 화할 수 있다. 또한, 도 15에 도시된 엣지 서비스 스케줄러를 이용함으로써 엣지 서비스에서 수평적 협업 및 수직적 협업을 시 스템 수준에서 적용할 수 있다. 예를 들어, 본 발명에 따른 엣지 서비스 스케줄러는 Leveled 스케줄러와 Shared 스케줄러를 결합한 복합적인 형 태의 스케줄러에 해당할 수 있다. 이 때, Leveled 스케줄러는 순차적 처리를 위한 형태의 스케줄러이고, Shared 스케줄러는 서로 경쟁하여 최적의 조건을 찾는 형태의 스케줄러에 해당한다. 예를 들어, 도 16에 도시된 스케줄러는 3 Leveled 스케줄러 형식으로, 마스터 엣지 스케줄러, 이웃 엣지 스케줄 러, 클라우드 스케줄러 순으로 스케줄링 작업이 이루어질 수 있다. 만약, 1 Level인 마스터 엣지 스케줄러를 통해 자원 할당이 성공하면, 2 Level인 이웃 엣지 스케줄러와 3 Level인 클라우드 스케줄러의 실행은 생략될 수 있다. 그러나 1 Level인 마스터 엣지 스케줄러에서 자원 할당이 실패한다면, 순차적으로 다음 Level의 스케줄러 로 해당 업무가 전달될 수 있다. 서비스 개발자는 이러한 Leveled 스케줄러를 사용하여 시스템 레벨에서 엣지 서비스의 부하 분산과 서비스 간 협업을 적용할 수 있다. 이처럼, Leveled 스케줄러는 작업을 순차적으로 처리하지만, Shared 스케줄러는 스케줄러 간에 경쟁모드로써 동 작할 수 있다. 예를 들어, 2개 이상의 스케줄러들에 동시에 작업을 요청한 뒤 각 스케줄러로부터 후보들을 받고, 그 중에 가장 적합한 것을 선택하여 업무를 처리하는 방식으로 동작할 수 있다. 다른 예를 들어, 도 17에 도시된 스케줄러는, 2 Level로 구성된 Leveled 스케줄러이면서, 2 Level에서는 이웃 엣지 스케줄러와 클라우드 스케줄러가 Shared 스케줄러로 구성된 본 발명에서 제안하는 복합적인 스케줄러에 해 당할 수 있다. 만약, 1 Level인 마스터 엣지 스케줄러에서 자원 할당이 실패하면, 2 Level에서는 경쟁모드를 통해 이웃 엣지 스케줄러와 클라우드 스케줄러에게 작업을 동시에 요청하게 된다. 이 후, 이웃 엣지 스케줄러와 클라우드 스케 줄러로부터 후보를 받고, 그 중에 가장 적합한 것을 선택하여 작업을 처리할 수 있다. 도 18은 본 발명에 따른 엣지 서비스 시스템의 스케줄러 정책 실행기의 일 예를 나타낸 도면이다. 도 18을 참조하면, 본 발명에 따른 복합 스케줄러를 실행하기 위한 스케줄러 정책 실행기는 엣지 스케줄러 정책 실행기와 실제 컨테이너를 실행할 클러스터(엣지 / 이웃 엣지 / 클라우드 클러스터)로 구성될 수 있다. 본 발명에 따른 스케줄러 정책 실행기를 구성하는 주요 컴포넌트의 기능은 [표 2]와 같다. 표 2 컴포넌트 기능 글로벌 스케줄러 REST API사용자 인터페이스나 명령어 도구로부터 관련 응용 컨테이너를 할당 요청하는 스케줄러에 해당하는 REST API 글로벌 스케줄러 핸들러글로벌 스케줄러 REST API를 처리하는 컴포넌트 요청 큐 관리기 글로벌 스케줄러 핸들러로부터 컨테이너의 할당 요청들을 수신하여 그 데이터를 저장하고 관리하는 컴포넌트 글로벌 스케줄러 제어기요청 큐로부터 스케줄링 요청 데이터를 꺼내어 글로벌 스케줄러 작업 쓰레드를 생성 및 실행시키는 컴포넌트 글로벌 스케줄러 작업 쓰레드스케줄러 작업을 해당 마스터 노드의 글로벌 스케줄러 에이전트에 전 달할 메시지 형태로 변환하여 작업 메시지 큐에 저장하는 쓰레드 엣지 클러스터 메타 데이터 저장소엣지 클러스터 관련된 메타 데이터들을 저장하는 저장소 작업 메시지 큐 엣지 스케줄러 정책 실행기와 클러스터 간 스케줄러 작업 메시지를 저 장하는 저장소 글로벌 스케줄러 에이전트클러스터의 마스터 노드에서 작업 메시지 큐로부터 자신에 해당하는 스케줄러 작업 메시지를 수신하여 REST API를 호출하는 컴포넌트 엣지(클라우드) 스케줄러배정되지 않은 컨테이너를 감지하고, 컨테이너를 실행할 워커노드를 선별하는 컴포넌트 워커 에이전트 워커 노드에서 컨테이너를 실행하는 에이전트 이하에서는 도 19를 참조하여 본 발명에 따른 스케줄러 정책 실행기의 처리 흐름을 상세하게 설명하도록 한다. 도 19를 참조하면, 클라이언트로부터 요청받은 컨테이너를 워커 노드에 생성 및 실행하는 과정은 다음과 같다. 먼저, 사용자가 컨테이너 생성에 해당하는 REST API를 호출하면, 호출된 REST API를 처리하기 위해 글로벌 스케 줄러 핸들러가 실행될 수 있다. 이 후, 글로벌 스케줄러 핸들러는 요청된 데이터를 요청 큐 관리기에 송신할 수 있고, 요청 큐 관리기는 요청된 데이터를 큐에 저장할 수 있다. 이 후, 글로벌 스케줄러 제어기는 우선순위를 고려하여 요청 큐로부터 처리할 데이터를 가져와 글로벌 스케줄러 작업 쓰레드를 생성하고, 처리할 데이터를 전달하여 스케줄링 작업을 실행할 수 있다. 이 후, 글로벌 스케줄러 작업 쓰레드는 요청된 작업을 분석하고, 스케줄러 작업을 해당하는 클러스터에 요청할 메시지 형태로 변환하여 작업 메시지 큐 관리기에 전달할 수 있다. 이 후, 작업 메시지 큐 관리기가 전달된 메시지를 작업 메시지 큐에 저장하면, 클러스터의 글로벌 스케줄러 에 이전트가 작업 메시지 큐로부터 엣지 및 이웃 엣지에 해당하는 메시지가 있는지 체크하여 해당 메시지를 가져올 수 있다. 이 후, 글로벌 스케줄러 에이전트는 가져온 메시지를 분석하고, 자신의 엣지 API 서버에게 해당 API 호출한다. 이 후, 엣지 스케줄러가 워커 노드들에 있는 워커 에이전트들을 통하여 요청한 컨테이너를 생성 및 실행할 수 있다. 도 20은 도 18에 도시된 스케줄러 정책 실행기의 3단계 요청 큐의 처리 순서의 일 예를 나타낸 동작흐름도이다. 본 발명에서 제안하는 제안하는 스케줄러 정책 실행기는 스케줄링을 요청했지만 반복적으로 실패한 요청을 우선 적으로 처리하거나 우선순위 옵션을 갖는 요청을 기본 스케줄링 요청보다 우선적으로 처리하기 위해 요청 큐를 3단계로 나누어 처리할 수 있다. 이 때, 3단계 요청 큐는 첫 번째 프런트 큐(First Front Queue, FF), 두 번째 프런트 큐(Second Front Queue, SF), 베이스 큐(Base Queue, B) 순으로 구성될 수 있다. 첫 번째 프런트 큐(First Front Queue)는 스케줄링을 요청했지만 반복적으로 실패한 요청을 우선으로 처리하기 위한 큐에 해당할 수 있다. 두 번째 프런트 큐(Second Front Queue)는 우선순위 옵션을 갖는 요청을 기본 스케줄링 요청보다 우선으로 처리 하기 위한 큐에 해당할 수 있다. 도 20을 참조하면, 엣지 스케줄러 정책 실행기의 3단계 요청 큐의 처리는, 먼저 요청된 데이터에 우선순위 옵션 (FAST Option)이 있는지 여부를 판단하고(S2005), 우선순위 옵션이 있으면 두 번째 프런트 큐에 저장하고 (S2010), 우선순위 옵션이 없으면 베이스 큐에 저장할 수 있다(S2020). 이 후, 첫 번째 프런트 큐(First Front Queue), 두 번째 프런트 큐(Second Front Queue), 베이스 큐(Base Queue)의 순서대로 큐에 데이터가 있는지 체크하고, 각 큐로부터 N개씩 순서대로 스케줄링 작업 큐에 생성하여 스케줄링을 시도할 수 있다(S2030). 이 후, 스케줄링이 성공하였는지 여부를 판단하고(S2035), 스케줄링에 실패하였으면, 각 요청의 실패한 횟수 (Fail_Num)를 1 증가시키고(S2040), 실패한 횟수가 정해진 실패 횟수(K*)를 초과하였는지 여부를 판단할 수 있 다(S2045). 단계(S2045)의 판단결과 실패한 횟수가 정해진 실패 횟수(K*)를 초과하면, 요청을 첫 번째 프런트 큐(First Front Queue)에 저장할 수 있다(S2050). 또한, 단계(S2045)의 판단결과 실패한 횟수가 정해진 실패 횟수(K*)를 초과하지 않으면, 다시 한번 우선순위 옵 션이 있는지 여부를 판단한 뒤(S2055) 우선순위 옵션이 있으면 두 번째 프런트 큐에 저장하고(S2010), 우선순위 옵션이 없으면 베이스 큐에 저장할 수 있다(S2020). 또한, 단계(S2035)의 판단결과 스케줄링에 성공하였으면 스케줄링 작업을 종료할 수 있다. 이 때, 도 20에 도시된 스케줄링 작업은 3단계 요청 큐에 모든 요청 데이터가 없을 때까지 반복하고 데이터가 없으면 대기할 수 있다. 도 21은 본 발명에 따른 지능형 스케줄러 기반 서비스 분산 협업의 동적 배치 연동의 일 예를 나타낸 도면이다. 도 21을 참조하면, 본 발명에서 제안하는 엣지 서비스 시스템의 스케줄러는 고정적 스케줄러가 아닌 지능형 스 케줄러에 해당할 수 있다. 예를 들어, 도 21과 같이 제안하는 엣지 서비스 시스템은 분산-협업 동적 배치 지능형 분석기를 기반으로 클라우드, 엣지, 이웃 엣지에 대한 실시간 모니터링 데이터 및 로그를 수집하고, 수집된 데이터를 딥 러닝과 같 은 AI 분석을 통하여 다양한 서비스를 동적 배치할 수 있다.도 22는 본 발명에 따른 지능형 스케줄러를 적용한 엣지 서비스 시스템의 일 예를 나타낸 도면이다. 본 발명에서 제안하는 엣지 서비스 시스템은 인공지능 트레이닝을 통하여 지능형 스케줄러 정책을 도출할 때 많 은 히스토리 데이터를 필요로 할 수 있다. 이 때, 엣지 서비스 시스템을 구축하고 바로 인공지능 트레이닝을 수행하는 것은 불가능하지만, 일정 기간 동안 히스토리 데이터를 수집한 후에는 엣지 스케줄러 정책 트레이닝을 수행할 수 있다. 도 22에 도시된 엣지 서비스 시스템을 구성하는 주요 구성 요소 및 주요 구성 요소들 각각의 기능은 [표 3]과 같다. 표 3 구성 요소 기능 엣지 스케줄러 정 책 메타데이터 저 장소엣지 스케줄러 정책(Edge Scheduler Policy, ESP)을 저장하는 저장소 엣지 스케줄러 정 책 플랜너엣지 응용 별 정보 수집기와 엣지 클러스터 정보 수집기로부터 수집한 정보를 기 반으로 정책을 수립하는 컴포넌트 엣지 응용 별 정 보 수집기엣지에서 구동되는 응용 별로 응답속도, CPU 실사용률, 메모리 실사용률, 기타 자 원사용 상태를 수집하는 컴포넌트 엣지 클러스터 정 보 수집기클러스터를 구성하는 물리적 노드 별 CPU 실사용률, 메모리 실사용률 등의 정보를 수집하는 컴포넌트 엣지 스케줄러 정 책 로그 데이터 저장소엣지 스케줄러 정책 로그기를 통하여 엣지 스케줄러 정책을 적용한 결과를 저장하 는 저장소 엣지 스케줄러 정 책 트레이너엣지 스케줄러 정책 로그 데이터 저장소로부터 히스토리 데이터를 가져와 트레이 닝 하는 컴포넌트 엣지 스케줄러 정 책 평가기엣지 스케줄러 정책을 적용한 후 최적화 정도에 따른 평가하는 컴포넌트 엣지 스케줄러 정 책 실행기여러 엣지 스케줄러 정책을 적용한 후 최적화 정도에 따른 평가하여 가장 좋은 정 책을 실행하는 컴포넌트 엣지 스케줄러 정 책 로그기실행된 스케줄러 정책과 그 결과를 로그로 저장하는 컴포넌트 도 23은 본 발명에 따른 지능형 스케줄러를 적용한 엣지 서비스 시스템의 최적화 처리 흐름의 일 예를 나타낸 도면이다. 본 발명에서 지능형 스케줄러를 적용한 엣지 서비스 시스템의 최적화 핵심은 최소비용으로 최적화하는 방법과 최대한 빠른 속도로 최적화하는 방법을 모두 제공하는 것이다. 도 23을 참조하면, 지능형 스케줄러를 적용한 엣지 서비스 시스템의 처리 순서는 먼저, 엣지 응용 별 정보 수집 기와 엣지 클러스터 정보 수집기를 통하여 컨테이너 플랫폼의 정보를 수집할 수 있다. 이 후, 엣지 스케줄러 정책 플랜너가 엣지 응용 별 정보 수집기와 엣지 클러스터 정보 수집기를 통해 수집된 정 보를 바탕으로 엣지 스케줄러 정책 메타데이터 저장소로부터 정책을 선정할 수 있다. 이 후, 컨테이너 플랫폼의 부하 정도에 따라 ESP 적용 비용 최소화 타입, ESP 적용 최적화 타입 중 하나를 선택 할 수 있다. 이 후, 엣지 스케줄러 정책 실행기를 통하여 컨테이너들을 할당할 수 있다. 이 후, 엣지 스케줄러 정책을 적용하기 전과 엣지 스케줄러 정책을 적용한 후에 대한 상대 비교를 통하여 타입 별 엣지 스케줄러 정책에 대한 평가를 수행할 수 있다. 이 후, 최종적으로 선택된 엣지 스케줄러 정책을 비적용 부분이 없도록 전체적으로 적용할 수 잇다. 이 후, 엣지 스케줄러 정책 로그기를 통하여 최종적으로 선택된 엣지 스케줄러 정책이 적용된 결과를 엣지 스케 줄러 정책 로그데이터 저장소에 저장할 수 있다. 이 후, 엣지 스케줄러 정책 트레이너는 저장된 엣지 스케줄러 정책 로그데이터를 수집할 수 있고, 엣지 스케줄 러 정책 트레이너를 통하여 최적화된 지능형 엣지 정책을 생성할 수 있다. 상기의 도 1 내지 도 23을 통해 설명한 본 발명에 따른 멀티 클라우드 엣지 시스템은 다른 시스템 혹은 기존의 시스템과 비교하였을 때 다음과 같은 장점이 존재한다. 고속의 컨테이너 시스템 - 인메모리 기반의 컨테이너를 구성하여 고속의 컨테이너 플랫폼을 유지 메모리 제약 사항 해결 - 확장형 스토리지 구조로 메모리의 크기에 대한 제약사항을 해결하고, 실시간 백업 환 경을 통한 백업/리스토어 기능으로 휘발성 메모리에 의한 문제점을 해결 공유에 적합한 구조 - 현재 시스템에서 제공되는 Unifying file system을 이용하여 데이터 및 이미지를 메모리 상에서 공유 가능 커널 병합된 손쉬운 사용 - 시스템을 구성하는 각 모듈이 리눅스에 포함되어 손쉽게 시스템을 구성 및 사용할 수 있음 L3 레벨의 다중 클러스터의 사용자 레벨 네트워크 터널링 연결 - 다중 클러스터 네트워크의 연결을 고속으로 수 행하기 위하여 커널 바이패스 네트워크 스택을 활용한 터널링 기법을 적용하여 고속 네트워크를 구성 협업을 위한 최적화된 지능형 스케줄러 기능 제공 - 저지연 서비스에 적합한 스케줄링이 가능하고, 수직적 협업과 수평적 협업을 통합한 협업 적용 가능 - 시스템 레벨에서 협업 적용 가능 - 지능형 오프로딩 기반의 협업 가능 - 끊김이 없는 서비스 연계 가능 - 클라우드/엣지/이웃 엣지를 포함한 통합적인 분산처리 가능 - 로그나 통계 정보를 기반으로 효율적인 지능형 스케줄러 정책 생성 가능 이상에서와 같이 본 발명에 따른 멀티 클라우드 엣지 시스템은 상기한 바와 같이 설명된 실시예들의 구성과 방 법이 한정되게 적용될 수 있는 것이 아니라, 상기 실시예들은 다양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또는 일부가 선택적으로 조합되어 구성될 수도 있다."}
{"patent_id": "10-2022-0119177", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 엣지 서비스를 위한 다중 클러스터 연계 아키텍처 구조의 일 예를 나타낸 도면이다. 도 2는 기존 엣지 서비스를 위한 시스템의 일 예를 나타낸 도면이다. 도 3은 본 발명에 따라 클라우드, 엣지, 이웃 엣지를 포함하는 3Locarions 기반의 엣지 서비스 시스템의 일 예를 나타낸 도면이다. 도 4는 본 발명에 따른 수직적 및 수평적 협업이 가능한 엣지 서비스의 일 예를 나타낸 도면이다. 도 5는 본 발명에 따른 인메모리 컨테이너 스토리지 기반 컨테이너 시스템 구조의 일 예를 나타낸 도면이다. 도 6은 도 5에 도시된 인메모리 컨테이너 스토리지의 상세 구조의 일 예를 나타낸 도면이다. 도 7은 도 5에 도시된 인메모리 컨테이너 스토리지 엔진의 상세 구조의 일 예를 나타낸 도면이다. 도 8은 본 발명에 따른 컨테이너 인메모리 스토리지 생성 방식의 일 예를 나타낸 도면이다. 도 9는 본 발명에 따른 인메모리 스토리지에 구현된 컨테이너 파일 시스템의 일 예를 나타낸 도면이다. 도 10은 본 발명에 따른 인메모리 컨테이너 스토리지의 이미지 공유 환경의 일 예를 나타낸 도면이다. 도 11은 본 발명에 따른 사용자 공유 환경에 대한 구성의 일 예를 나타낸 도면이다. 도 12는 도 5에 도시된 인메모리 컨테이너 스토리지 관리 모듈의 상세 구조의 일 예를 나타낸 도면이다. 도 13은 본 발명에 따른 인메모리 컨테이너 스토리지 관리 모듈에서 데이터 공유 관리를 위한 상세 과정의 일 예를 나타낸 동작흐름도이다. 도 14는 본 발명에 따른 클러스터간 연결 구조의 일 예를 나타낸 도면이다. 도 15는 본 발명에 따른 엣지 서비스 시스템 스케줄러 구성의 일 예를 나타낸 도면이다. 도 16은 본 발명에 따른 Leveled 스케줄러의 일 예를 나타낸 도면이다. 도 17은 본 발명에 따른 Shared/Leveled 복합 스케줄러의 일 예를 나타낸 도면이다. 도 18은 본 발명에 따른 엣지 서비스 시스템의 스케줄러 정책 실행기의 일 예를 나타낸 도면이다. 도 19는 도 18에 도시된 스케줄러 정책 실행기의 처리 흐름의 일 예를 나타낸 도면이다. 도 20은 도 18에 도시된 스케줄러 정책 실행기의 3단계 요청 큐의 처리 순서의 일 예를 나타낸 동작흐름도이다. 도 21은 본 발명에 따른 지능형 스케줄러 기반 서비스 분산 협업의 동적 배치 연동의 일 예를 나타낸 도면이다. 도 22는 본 발명에 따른 지능형 스케줄러를 적용한 엣지 서비스 시스템의 일 예를 나타낸 도면이다. 도 23은 본 발명에 따른 지능형 스케줄러를 적용한 엣지 서비스 시스템의 최적화 처리 흐름의 일 예를 나타낸 도면이다."}
