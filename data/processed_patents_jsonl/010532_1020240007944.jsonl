{"patent_id": "10-2024-0007944", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0015763", "출원번호": "10-2024-0007944", "발명의 명칭": "SaaS 형 아바타 생성 서비스 제공 방법 및 장치", "출원인": "주식회사 굳갱랩스", "발명자": "안두경"}}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치에 의한, 아바타 생성 소프트웨어 개발 도구(SDK: Software Development Kit) 기반의 아바타 생성서비스 제공 방법에 있어서,상기 서비스에 사용자 계정을 등록하는 단계;상기 등록된 사용자 계정에 대응하는 아바타 계정을 생성하는 단계;상기 소프트웨어 개발 도구를 이용하여, 상기 생성된 아바타 계정에 대응하는 아바타를 생성하는 단계를 포함하되,상기 아바타를 생성하는 단계는, 상기 아바타와 연관된 기정의된 복수 개의 아바타 설정정보를 기반으로 상기아바타 설정정보에 대응하는 아바타가 생성되도록 제어하는 단계를 포함하는, 아바타 생성 서비스 제공 방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 기정의된 복수 개의 아바타 설정정보는 아바타의 이름, 아바타의 성격(custom persona), 아바타의 형상,아바타의 목소리, 아바타의 제스쳐 및 감정 중 적어도 둘에 대한 설정을 포함하는, 아바타 생성 서비스 제공 방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 사용자 계정을 등록함에 대응하여, 상기 사용자 계정에 대응하는 API 키(key)를 발급하는 단계를 더 포함하되, 하나의 아바타가 하나의 API에 대응하도록 제어하는, 아바타 생성 서비스 제공 방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 발급된 API 키를 기반으로, 상기 사용자 계정에 대응하는 적어도 하나의 아바타 계정을 관리하는, 아바타생성 서비스 제공 방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 복수 개의 아바타 계정이 하나의 사용자 계정에 연동되어 리스트로 관리되는, 아바타 생성 서비스 제공 방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 복수 개의 아바타 계정에 대한 아바타 설정정보가 상기 리스트로 관리되는, 아바타 생성 서비스 제공방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5 항에 있어서,상기 리스트를 이용하여, 상기 아바타 계정에 대응하는 기생성된 아바타를 복사, 수정 및 삭제하도록 허여하는사용자 인터페이스를 제공하는, 아바타 생성 서비스 제공 방법.공개특허 10-2025-0015763-3-청구항 8 제 3 항에 있어서,상기 아바타 API 사용 내역을 관리하는 단계를 더 포함하는, 아바타 생성 서비스 제공 방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 API 사용 내역을 기반으로 사용 내역에 상응하는 비용을 상기 등록된 사용자 계정에 대응하는 계좌에 과금하는 단계를 더 포함하는, 아바타 생성 서비스 제공 방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서, 상기 생성된 아바타를 테스트하는 환경을 제공하는 단계를 더 포함하는, 아바타 생성 서비스 제공 방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 테스트하는 환경에서, 사용자의 표정 및 제스처 중 적어도 하나를 상기 설정정보를 기반으로 상기 아바타가 잘 트래킹하는지 테스트하도록 허여하는, 아바타 생성 서비스 제공 방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서, 상기 테스트하는 환경에서, 사용자의 문맥에 대응하여 상기 설정정보를 기반으로 상기 아바타가 잘 표현하는지테스트하도록 허여하는, 아바타 생성 서비스 제공 방법."}
{"patent_id": "10-2024-0007944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "아바타 생성 소프트웨어 개발 도구(SDK: Software Development Kit) 기반의 아바타 생성 서비스 제공 장치에 있어서,사용자 단말과 통신하는 통신 모듈; 및상기 통신모듈을 이용하여, 상기 사용자 단말로부터 입력 정보를 수신하여, 상기 서비스에 사용자 계정을 등록하고, 상기 등록된 사용자 계정에 대응하는 아바타 계정을 생성하며, 상기 소프트웨어 개발 도구를 이용하여,상기 생성된 아바타 계정에 대응하는 아바타를 생성하도록 제어하는 프로세서를 포함하되,상기 프로세서는, 상기 아바타와 연관된 기정의된 복수 개의 아바타 설정정보를 기반으로 상기 아바타 설정정보에 대응하는 아바타가 생성되도록 제어하는, 아바타 생성 서비스 제공 장치."}
{"patent_id": "10-2024-0007944", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 양태는, 컴퓨팅 장치에 의한, 아바타 생성 소프트웨어 개발 도구(SDK: Software Development Kit) 기반의 아바타 생성 서비스 제공 방법을 개시하고 있다. 상기 방법은, 상기 서비스에 사용자 계정을 등록하는 단 계, 상기 등록된 사용자 계정에 대응하는 아바타 계정을 생성하는 단계, 상기 소프트웨어 개발 도구를 이용하여, 상기 생성된 아바타 계정에 대응하는 아바타를 생성하는 단계를 포함하되, 상기 아바타를 생성하는 단계는, 상기 아바타와 연관된 기정의된 복수 개의 아바타 설정정보를 기반으로 상기 아바타 설정정보에 대응하는 아바타가 생 성되도록 제어하는 단계를 포함한다."}
{"patent_id": "10-2024-0007944", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 아바타 생성 서비스 방법에 관한 것으로, 보다 상세하게는, 개발자가 용이하게 3차원 아바타 생성할 수 있도록 지원하는 플랫폼을 제공하는 방법에 관한 것이다."}
{"patent_id": "10-2024-0007944", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현대 디지털 환경에서 인공지능(AI: Artificial Intelligence)은 대체로 텍스트 미디어를 통해 존재하고 표현한 다. 그러나 최근에는 사람과 사람, 사람과 AI를 연결해주는 아바타 기술이 주목받고 있다. 아바타는 사용자의 디지털 ID를 표현하는 주요 수단으로, 기존 2D 캐릭터 이미지에서 3D 아바타로의 변화를 의 미한다. 기존의 온라인 커뮤니케이션 서비스인 줌(Zoom) 및 구글의 화상 회의는 영상 통화 방식으로 진행되어외모와 개인의 프라이버시에 대한 부담감을 유발할 수 있다. 또한, 상대방의 편견을 받을 수 있는 문제점이 존 재하며, 대화 시 상호간의 얼굴 및 상태를 계속 주시해야 하는 불편함이 있다. 더욱이, 별도의 커뮤니케이션 서 비스 앱을 설치하는 어려움과 부담감도 있다. 한편, 기존의 딥러닝 모델은 사람의 표정과 몸짓을 파악하여 애니메이션 데이터로 만들어주는데 리소스 (resource)를 크게 소모하였다. 또한, 단말 상의 성능 파편화로 인해 균등한 딥러닝 인퍼런스 성능을 보장해주 는 단말단의 솔루션이 부재하였다. 또한, 실시간 딥러닝 인퍼런스 서비스를 단말에서 적용하기 위한 단말 OS마 다의 SDK(Software Development Kit)가 필요하며, SDK를 임베딩하는 개발자의 어려움도 존재하였다. 즉, 현재까지의 아바타 렌더링 기반의 서비스는 다음과 같은 문제점이 존재한다. 1) 딥러닝 모델의 리소스 소모가 큼으로 사람의 표정과 몸짓을 파악하여 애니메이션 데이터로 만들어주는데 큰 부담을 초래하였다. 2) 단말 상의 성능 파편화로 인해 균등한 딥러닝 인퍼런스 성능을 보장해주는 단말단의 솔루션이 부재하였다. 3) 실시간 딥러닝 인퍼런스 서비스를 단말에서 적용하기 위한 단말 OS 마다의 SDK가 필요하였다. 4) SDK를 임베딩하는 개발자들이 퍼포먼스 튜닝이나 기존 레거시 코드 등의 어려움을 겪었다. 추가적으로, 위와 같은, AI와 3D 아바타를 연결해주는 기술적 요소들의 허들이 존재하며, 실시간성이 중요한 아 바타 데이터를 하나의 아바타 API로 지원하는 솔루션의 부재 등의 문제가 있다."}
{"patent_id": "10-2024-0007944", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상술한 문제점을 해결하기 위한 본 발명의 일 양태에 따른 목적은, 사람과 사람, 사람과 AI를 3D 아바타로 연결 해주는 기술들을 제공하는 것이다. 본 발명의 다른 목적은, 현재까지 이러한 기술에 표준이 정립되지 않고 있었는데, 현재까지 정립되지 않은 3D 아바타 기술을 체계화하고, 이를 API화하여 SaaS 플랫폼으로 제공하는 것이다."}
{"patent_id": "10-2024-0007944", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 양태에 따른, 컴퓨팅 장치에 의한, 아바타 생성 소프트웨어 개발 도 구(SDK: Software Development Kit) 기반의 아바타 생성 서비스 제공 방법은, 상기 서비스에 사용자 계정을 등 록하는 단계, 상기 등록된 사용자 계정에 대응하는 아바타 계정을 생성하는 단계, 상기 소프트웨어 개발 도구를 이용하여, 상기 생성된 아바타 계정에 대응하는 아바타를 생성하는 단계를 포함하되, 상기 아바타를 생성하는 단계는, 상기 아바타와 연관된 기정의된 복수 개의 아바타 설정정보를 기반으로 상기 아바타 설정정보에 대응하 는 아바타가 생성되도록 제어하는 단계를 포함할 수 있다. 상기 기정의된 복수 개의 아바타 설정정보는 아바타의 이름, 아바타의 성격(custom persona), 아바타의 형상, 아바타의 목소리, 아바타의 제스쳐 및 감정 중 적어도 둘에 대한 설정을 포함할 수 있다. 상기 방법은, 상기 사용자 계정을 등록함에 대응하여, 상기 사용자 계정에 대응하는 API 키(key)를 발급하는 단 계를 더 포함하되, 하나의 아바타가 하나의 API에 대응하도록 제어할 수 있다. 상기 발급된 API 키를 기반으로, 상기 사용자 계정에 대응하는 적어도 하나의 아바타 계정을 관리할 수 있다. 복수 개의 아바타 계정이 하나의 사용자 계정에 연동되어 리스트로 관리될 수 있다. 상기 복수 개의 아바타 계정에 대한 아바타 설정정보가 상기 리스트로 관리될 수 있다. 상기 리스트를 이용하여, 상기 아바타 계정에 대응하는 기생성된 아바타를 복사, 수정 및 삭제하도록 허여하는 사용자 인터페이스를 제공할 수 있다. 상기 방법은, 상기 아바타 API 사용 내역을 관리하는 단계를 더 포함할 수 있다. 상기 방법은, 상기 API 사용 내역을 기반으로 사용 내역에 상응하는 비용을 상기 등록된 사용자 계정에 대응하 는 계좌에 과금하는 단계를 더 포함할 수 있다.상기 방법은, 상기 생성된 아바타를 테스트하는 환경을 제공하는 단계를 더 포함할 수 있다. 상기 테스트하는 환경에서, 사용자의 표정 및 제스처 중 적어도 하나를 상기 설정정보를 기반으로 상기 아바타 가 잘 트래킹하는지 테스트하도록 허여할 수 있다. 상기 테스트하는 환경에서, 사용자의 문맥에 대응하여 상기 설정정보를 기반으로 상기 아바타가 잘 표현하는지 테스트하도록 허여할 수 있다. 상기한 목적을 달성하기 위한 본 발명의 다른 양태에 따른, 아바타 생성 소프트웨어 개발 도구(SDK: Software Development Kit) 기반의 아바타 생성 서비스 제공 장치는, 사용자 단말과 통신하는 통신 모듈 및 상기 통신모 듈을 이용하여, 상기 사용자 단말로부터 입력 정보를 수신하여, 상기 서비스에 사용자 계정을 등록하고, 상기 등록된 사용자 계정에 대응하는 아바타 계정을 생성하며, 상기 소프트웨어 개발 도구를 이용하여, 상기 생성된 아바타 계정에 대응하는 아바타를 생성하도록 제어하는 프로세서를 포함하되, 상기 프로세서는, 상기 아바타와 연관된 기정의된 복수 개의 아바타 설정정보를 기반으로 상기 아바타 설정정보에 대응하는 아바타가 생성되도록 제어할 수 있다."}
{"patent_id": "10-2024-0007944", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 3차원 아바타 커뮤니케이션을 위한 서비스 제공 방법, 장치 및 시스템에 따르면, 개발자들이 쉽게 3D 아바타를 이용하여 사람과 AI를 연결할 수 있게 되며, 다양한 산업의 니즈를 충족시킬 수 있게 하는 효과가 있 다. 이는 디지털 ID의 주요 표현 수단이 2D에서 3D 아바타로 변경되는 추세를 따라가는 전략이며, 이를 통해 다양한 산업의 니즈를 충족시킬 수 있다."}
{"patent_id": "10-2024-0007944", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포 함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제 1, 제 2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목 들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다.어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1a는 본 발명의 일 실시예에 따른 3차원 아바타 커뮤니케이션을 위한 서비스 제공 시스템을 나타낸 개념도이 다. 도 1a에 도시된 바와 같이, 본 발명의 일 실시예에 따른 3차원 아바타 커뮤니케이션을 위한 서비스 제공 시 스템은 사용자 단말, 아바타 커뮤니케이션 서버 및 LLM 서버를 포함할 수 있다. 도 1a를 참조하면, 사용자는 사용자 단말을 이용하여 아바타 커뮤니케이션 플랫폼에 접속할 수 있다. 이는 아바타 커뮤니케이션 서버로의 접속을 통해 이루어질 수 있다. 사용자는 아바타 커뮤니케이션 플랫폼에 로 그인하여 아바타 커뮤니케이션 서버가 제공하는 플랫폼 서비스를 이용할 수 있다. 사용자는 사용자 단말 을 통해 자신만의 아바타를 생성할 수 있다. 아바타의 생성은 아바타의 형상, 제스쳐, 말투 등에 대한 설 정을 입력함에 의해 이루어질 수 있다. 아바타는 3D 기반의 아바타일 수 있다. 사용자는 아바타 커뮤니케이션 서버를 매개로 LLM(Large Language Model) 서버와 연결될 수 있다. 이를 통해, 서버는 사용자가 생성한, 자신만의 아바타가 LLM 기반의 능력을 탑재한 상태에서, 사용자와 채 팅 또는 바디 트랙킹을 하는 형태로, 대화하도록 제어할 수 있다. 여기서, 바디 트랙킹은 풀 바디 트랙킹(Full Body Trackinig) 개념을 포함하는 것으로, 페이셜 블렌드쉐이프(Facial Blendshape : 얼굴 표정 및 립싱크) 및 바디 제스쳐(Body Gesture : 몸 동작)를 트랙킹하는 것을 포함한다. 한편, 본 명세서 상에서, 이를 AI 아바타라고 부를 수 있다. 이때, 사용자 단말과 아바타 커뮤니케이션 서 버 간에 송수신하는 데이터는 실시간으로 전송될 수 있다. 즉, 사용자와 AI를 3D 아바타를 통해 실시간으 로 연결할 수 있는 것이다. 사용자는 AI 아바타의 이름, 캐릭터(character)(\"커스텀 페르소나\" 및/또는 \"성격\" 등이라는 용어와 대응될 수 있음), 형상, 목소리(\"보이스(voice)\"라고 부를 수 있음), 제스쳐 및 감정(\"이모션(emotion)\"이라 부를 수 있음) 등을 특정할 수 있다. 예를 들어, AI 아바타의 캐릭터를 MBTI의 ISFJ 성향의 여자 대학생으로 설정할 수 있다. 이와 같이 성격이 설정되면, 사용자의 질의에 대한 AI 아바타의 답변이 설정된 성격을 고려하여 여자 대 학생의 감성 및 지식수준 등을 고려하여 결정될 수 있다. AI 아바타의 캐릭터 설정을 위해서는, 프롬프트 (prompt)를 이용할 수 있다. 아바타 커뮤니케이션 서버는 사용자 단말과 LLM 서버를 연결하여, 사용자가 선택 및 생성한 아 바타에 AI 기반의 성능을 부여하고, 이를 기반으로 사용자와 3D 아바타를 통해 질의응답을 진행할 수 있다. 아바타 커뮤니케이션 서버는 사용자 단말과 연동하며, 사용자 요청에 응답하여 3D 아바타를 생성하고 LLM 서버와 통신하면서, 사용자 요청에 대응하여 생성된 3D 아바타의 형상을 결정하고 표현을 생성할 수 있다. 여기서, 표현은 아바타의 제스처(gesture)와 감정(emotion)에 대한 설정과 연관될 수 있다. 먼저, 아바타 커뮤니케이션 서버는 다수의 사용자에 대한 아바타 계정 리스트를 관리할 수 있다. 서버 는 하나의 사용자가 다수의 아바타 계정을 갖는 것을 허여할 수 있다. 특히, 사용자에 의해 생성된 아바타 는 서버에서 운영하는 플랫폼이 아닌, 다른 플랫폼에 호환되어 사용될 수 있다. 즉, 서버는 서버 에서 자체 운영하는 플랫폼 이외에, 사용자가 개발자로써 직접 만든 아바타 기반의 웹 서비스(또는 애플리 케이션 서비스)에서, 서버를 통해 생성된 아바타가 활용되는 것을 허여할 수 있다. 즉, 이러한 경우, 사용 자는 서비스 개발자일 수 있고, 아바타 커뮤니케이션 서버는 개발자를 위한 SDK(Software Development Kit)를 제공하는 역할을 한다. 일 예에서, 아바타 커뮤니케이션 서버는 생성된 아바타를 테스트해 볼 수 있는 환경을 제공한다. 이러한 환경을 \"플레이그라운드(playground)\"라고 부를 수 있다. 사용자는 서버를 통해 생성한 3D 아바타를 플레 이그라운드에서 직접 테스트해 볼 수 있다. 예를 들어, 제스쳐 및 보이스가 사용자가 선택한 설정에 맞게 실행 되는지, 사용자의 질의에 적절히 대답하는지, 움직임은 부자연스럽지 않은지 등을 체크해볼 수 있다. 한편, 본 명세서 상에서, 아바타 커뮤니케이션 서버는 아바타 커뮤니케이션 장치, 아바타 커뮤니케이션 서 비스 제공 장치, 아바타 커뮤니케이션 플랫폼 운영 장치, 서비스 제공 장치, 서버, 장치 등으로 표현될 수 있다. 일 예에서, 상기 아바타 커뮤니케이션는 컴퓨팅 장치로 구현될 수 있다. 여기서 말하는 컴퓨터 장치는 서 버 급 컴퓨터 단말기로 구현될 수 있다. 상기 컴퓨터 장치는 통상적인 컴퓨터 단말이 가지는 입력 장치, 표시 장치, 네트워킹 장치, 하드디스크, 프로그램을 저장하는 메모리 및 메모리에 저장된 프로그램을 수행시키는 프 로세서 등을 구비할 수 있다. 다만, 반드시 서버 급 컴퓨터 단말로 구현되어야 하는 것은 아니다. LLM 서버는 chatGPT 등 생성형 AI 기반의 애플리케이션을 제공하는 서버 장치일 수 있다. 여기서, 생성형 AI란, 기계 학습 모델 중 하나로, 데이터를 학습하여 새로운 데이터를 생성하거나 예측하는 데 사용된다. 예를 들어, 이미지, 텍스트, 음악 등의 새로운 콘텐츠를 생성하는 데 사용될 수 있다. 본 발명의 일 실시예에 따르면, LLM 서버는 AI를 기반으로, 사용자의 질의에 적절한 답변을 제시한다. LLM 서버가 사용자의 질문에 대한 답변을 텍스트로 아바타 커뮤니케이션 서버로 제공하면, 아바타 커 뮤니케이션 서버는 텍스트 답변에 아바타의 표현(제스쳐, 표정, 목소리 등)을 입혀 답변이 사용자에게 보 다 실감나게 전달되는 것을 가능케 한다. 즉, LLM 서버는 생성형 AI 알고리즘을 실행하고, 생성된 데이터 를 아바타 커뮤니케이션 서버로 실시간으로 전송하거나 처리하는 데 사용되는 서버일 수 있는 것이다. 한편, LLM 서버는 아바타 커뮤니케이션 서버와 하나의 장치로 구현될 수도 있다. 즉, 아바타 커뮤니 케이션 서버는 자체 LLM 기능을 탑재하여 별도 LLM 서버 없이 동작할 수 있다. 도 1b는 본 발명의 다른 실시예에 따른 3차원 아바타 커뮤니케이션을 위한 서비스 제공 시스템을 나타낸 개념도 이다. 도 1b에 도시된 바와 같이, 본 발명의 다른 실시예에 따른 3차원 아바타 커뮤니케이션을 위한 서비스 제 공 시스템은 사용자 단말, 아바타 커뮤니케이션 서버 및 사용자 단말를 포함할 수 있다. 도 1b를 참조하면, 아바타 커뮤니케이션 서버가 제공하는 아바타 커뮤니케이션 서비스는, 도 1a의 실시예 와 같이, 사용자와 AI를 잇는 기능(Human-AI)을 수행하기도 하지만, 사용자와 사용자를 잇는 기능(Human- Human)을 수행할 수도 있다. 본 발명의 일 실시예에 따르면, 아바타 커뮤니케이션 서버는 기존의 영상 기반 커뮤니케이션과는 달리, 가 상의 3D 환경에서 커뮤니케이션이 진행되도록 허여한다. 이를 위해 사용자를 대신하여 동작하는 3D 아바타를 사 용하여 커뮤니케이션이 수행될 수 있다. 사용자 단말(140, 160)을 통해 생성된 3D 아바타는 사용자 1 및 사용자 2의 얼굴 표정 및 바디 제스쳐를 실시간으로 투사하여 상대방과의 상호작용을 가능하게 한다. 기본적인 커뮤니 케이션 기능은 줌 혹은 구글 미트(meet)와 유사하게 화상통화를 수행하는 방식으로 아바타가 사용자를 대신하는 것처럼 제공될 수 있다. 이때, 1:1뿐만 아니라 N:N 간의 커뮤니케이션 인프라를 구축하여 다수의 사용자 간의 3D 아바타 커뮤니케이션을 가능하게 한다. 한편, 음성 및 아바타 제스쳐 애니메이션 데이터만 양방향 통신 트래 픽에 사용하여 종래 영상 커뮤니케이션에 비해 월등한 데이터 트래픽 절약이 가능하도록 할 수 있다. 보다 상세하게는, 사용자 1이 사용자 단말을 이용하여 아바타 1을 생성하고, 사용자 2는 사용자 단말(16 0)을 이용하여 각각 아바타 2를 생성할 수 있다. 이때, 아바타 커뮤니케이션 서버는 아바타 1과 아바타 2 간의 커뮤니케이션이 가능하게 중계한다. 아바타 간의 커뮤니케이션은 사용자를 트랙킹함에 의해 이루어질 수 있다. 예를 들어, 사용자 1이 웃는 표정을 지으면, 사용자 단말을 통해 접속된 아바타 커뮤니케이션 서버 에서 이를 분석하여 아바타 1이 사용자 1과 동일한 표정을 짓도록 할 수 있다. 이에 대한 응답으로, 사용 자 2가 손을 흔들며 인사를 하면, 사용자 단말을 통해 접속된 아바타 커뮤니케이션 서버에서 이를 분 석하여 아바타 2가 사용자 2와 같이 손을 흔들며 인사하는 제스쳐를 표현하도록 제어할 수 있다. 즉, 사용자 1과 2는 아바타 1과 2를 통해 서로 커뮤니케이션할 수 있는 것이다. 아바타는 복수 개로 한정되는 것은 아니고, 3 이상의 아바타가 함께 커뮤니케이션하는 것도 가능하다. 한편, 사용자 1과 사용자 2의 아바타 1 및 아바타 2로의 입력은 표정, 제스쳐만으로 제한되지 않는다. 음성 또 는 텍스트 등의 입력에도 아바타가 반응하도록 제어할 수 있다. 즉, 사용자 1이 음성 또는 텍스트 입력을 제공 하면, 이를 분석하여 아바타 1의 표현을 생성하도록 할 수 있다. 반대로, 사용자 2가 음성 또는 텍스트 입력을 제공하면, 이를 분석하여 아바타 2의 표현을 생성하도록 할 수 있다. 이때, 아바타 1 및 2의 음성 또는 텍스트 입력 기반의 표현은 사용자 단말(140, 160)에서 각각 표시될 수 있다. 사용자 단말(140, 160)은 각각 화면을 분 할하여 두 아바타를 표시할 수 있다. 그리고는, 사용자 1 및 2의 표정, 행동, 음성 및/또는 텍스트 기반의 입력 에 대응하여 생성된 아바타 1 및 2의 표현을 사용자 단말(140, 160)의 화면에서 표시되도록 할 수 있다. 즉, 사용자 1과 사용자 2의 두 사용자들은 아바타 1과 아바타 2를 매개로 아바타 커뮤니케이션 서버에 의 해 생성된 플랫폼 상에서, 커뮤니케이션할 수 있도록 한다. 전술한 바와 같이, 도 1a 및 도 1b를 참조하면, 아바타 커뮤니케이션 서버(120, 150)는 사용자와 AI, 사용자와 사용자, 그리고 AI와 AI를 연결하는 기능을 제공할 수 있다. 이때, 사용자와 사용자, 그리고 AI와 AI를 연결하 는 기능은 사용자와 AI를 연결하는 기능을 기반으로 구현될 수 있다. 사용자와 아바타를 연결함에 있어서, 이를 Human2Avatar라는 기술로 정의할 수 있다. H2A라 쓸 수 있다. 기술적으로, Human2Avatar 기술은 (i) 사용자 자신을 최대한 잘 따라하게 만드는 아바타 기술과 (ii) 사용자가 만든 문맥을 최대한 잘 표현하는 아바타 기술로 나뉘어 구현될 수 있다. 앞서, 전자의 사용자를 따라하게 하는 아바타 기술을 Video2Avatar라 정의할 수 있다. V2A라 쓸 수 있다. 또한, 사용자의 문맥을 최대한 잘 표현하도 록 하는 아바타 기술을 Text2Avatar라 정의할 수 있다. T2A라 쓸 수 있다. 이는 이하 도 2에서 보다 상세히 설 명한다. 한편, 본 발명의 다른 실시예에 따르면, 사용자 단말(110, 140, 160)은 아바타 커뮤니케이션 서버에서 제 공하는 애플리케이션을 다운로드 받아 애플리케이션을 통해 아바타 기반의 커뮤니케이션 서비스를 이용할 수 있 다. 또한, 개발자로서 아바타 커뮤니케이션 서버가 제공하는 SDK를 이용하여 아바타를 생성하고 생성된 아 바타를 다른 플랫폼으로 공유할 수 있다. 도 2는 도 1a 또는 도 1b의 시스템에 포함된 아바타 커뮤니케이션 장치를 구체적으로 나타낸 블록도이다. 도 2 에 도시된 바와 같이, 본 발명의 일 실시예에 따른 아바타 커뮤니케이션 장치는 LLM, 커스텀 페르소나 (220: custom persona), 아바타 표현 생성부 및 SDK를 포함할 수 있다. 도 2를 참조하면, LLM은, 사용자 입력 컨텐츠에 대해, 자연어 처리를 수행하여 대응하는 결과 컨텐츠를 생 성하는 구성요소이다. LLM은, 앞서 설명한 바와 같이, HyperClovaX, Bard 등과 같은 생성형 AI일 수 있다. 이들은 사용자의 입력 컨텐츠(질의, 요청 등과 연관될 수 있음)를 입력받아, 자연어 처리를 수행하고, 그에 대 응하는 결과 컨텐츠를 생성한다. 이는 클라우드 기반의 딥러닝 기술로 구현될 수 있다. 한편, 사용자 입력 및 출력 컨텐츠는 다음과 같이 정의될 수 있다. - 입력: 이미지(image), 비디오(video), 오디오(audio) 및 텍스트(text) 매체 중 적어도 하나 - 출력: 오디오, 텍스트, 페이셜 블렌드쉐이프들(facial blendshape), 바디 포즈(body pose) 예를 들어, 입력이 오디오인 경우, 이는 사용자의 음성 입력일 수 있다. 사용자가 \"최근 정치 이슈에 대해 알려 줘\"라고 사용자 단말의 마이크에 이야기를 하는 경우, 마이크를 통해 수신되는 음성 신호가 입력이 될 수 있다. 텍스트 기반의 입력 컨텐츠는 텍스트 입력 창에 사용자가 텍스트로 메시지를 입력함에 의해 생성된다. 입력이 이미지 및 비디오인 경우, 이는 사용자 단말의 카메라를 통해 사용자(및/또는 사용자 이외의 피사체)를 촬영함 에 의해 획득된 것일 수 있다. 여기에는, 사용자의 행동, 포즈, 얼굴 표정 등이 포함될 수 있다. LLM은 입력 컨텐츠를 분석하여 사용자의 질문 내용에 대해 아바타 성격으로 설정된 커스텀 페르소나 의 프롬프트를 기준으로 생성형 답변을 처리한다. 그리고는, 커스텀 페르소나를 통해 설정된 아바타의 성 격에 기반하여 아바타 표현 생성부를 통해, 입력 컨텐츠 분석 결과에 대응하는 출력 컨텐츠를 아바타가 표 현하도록 제어할 수 있다. 커스텀 페르소나는 아바타의 성격을 정의한다. 보다 구체적으로, 커스텀 페르소나는 연령, 지식수준, 전문영역, 국가 중 적어도 하나를 특정하여 아바타를 특정 스타일(style)에 매칭시킨다. 커스텀 페르소나는 LLM의 프롬프트(prompt)와 연관하여 아바타의 성격을 결정할 수 있다. 즉, 상기 프롬프트를 생성함에 의해 아바타의 성격이 결정될 수 있다. 또한, 다양한 설정 파라미터를 사용자가 특정함에 의해, 아바타의 기반 지식 데이터가 사용자가 원하는 방향으로 적절히 생성될 수 있다. 즉, 커스텀 페르소나 에서 정의되는 성격에 따라 아바타가 전달하는 지식 수준이 결정될 수 있는 것이다. 예를 들어, 사용자는 변호사 정도의 법적 전문성을 갖도록 사용자의 아바타를 설정할 수도 있다. 또 다른 예에서는, IT 기업 박사 정 도의 기술 전문성을 갖도록 사용자의 아바타를 설정할 수도 있다. 즉, 기반 지식 데이터가 커스텀 페르소나 를 통해 매우 디테일하게 결정될 수 있는 것이다. 한편, 전문 지식뿐만 아니라, 사람의 성격을 특정하여 아바타의 성격을 설정해 놓을 수도 있다. 사람의 성격은 최신 유행하는 MBTI를 따를 수도 있다. 또는, 예민한 성격, 둔감한 성격과 같이, 조금 브로드한 개념의 성격을 설정해놓을 수도 있다. 커스텀 페르소나가 위와 같이, 캐릭터를 특정하는데는, 하이퍼 파라미터 튜닝(hyper parameter tuning) 기 법, 롱-텀 메모리(Long Term Memory) 기법 등이 적용될 수 있다. 이를 통해, 성격 및 스타일이 매우 디테일하며 다양하게 결정된다. 부가적으로, 커스텀 페르소나의 설정에 따라 다국어 지원이 가능할 수 있다. 아바타 표현 생성부는 커스텀 페르소나에서 설정된 아바타의 성격에 맞게, LLM을 통해 생성된 결과 컨텐츠를 표현하기 위한 아바타의 표현을 적절히 생성하는 구성요소이다. 아바타의 표현은 아바타의 표정, 형태, 제스쳐, 음성과 연관된 것들이 포함된다. 일 예로, 아바타 표현 생성부는 입력 컨텐츠를 분석하여 사용자의 감정을 파싱할 수 있다. 한편, 앞서 설명한 바와 같이, 입력 컨텐츠의 종류에 따라 아바타의 표현에 영향을 주는 기술의 종류가 분류될 수 있다. 예를 들어, 비디오(또는 이미지) 입력을 아바타 표현으로 출력하는 경우, 이러한 기술을 Video2Avatar 라 정의할 수 있다. 또한, 텍스트(또는 음성) 입력을 아바타 표현으로 출력하는 경우, 이러한 기술을 Text2Avatar라 정의할 수 있다. 음성의 경우, Voice2Avatar라 정의할 수 있다. Video2Avatar기술은 나의 표정과 제스쳐를 최대한 정밀하게 아바타에 투사하는 트래킹형 딥러닝 기술이다. 이 기술은 주로 카메라가 있는 환경에서 사용하기에 적합한 기술이다. Text2Avatar 기술은 사용자가 생성한 문맥인 목소리, 텍스트를 최대한 비슷하게 아바타에 투사하는 생성형 딥러 닝 기술이다. 이 기술은 주로 카메라 없는 환경이나 마이크 환경 또는 텍스트 채팅 환경에서 사용될 수 있다. V2A(Video2Avatar)뿐만 아니라 T2A(Text2Avatar)는 아바타 표현 생성부를 통해 자연어 처리 및 감정 분석 등이 수행되고, 분석 결과에 대응하는 아바타의 표정, 제스쳐, 감정, 및/또는 목소리 등을 결정한 후, 3D 아바 타가 이를 적절히 잘 표현하는 방식으로 실행될 수 있다. 특히, T2A의 경우, 텍스트 입력의 문맥을 파악하여 그 에 대응하는 답변이 LLM에서 생성되고, 생성된 답변을 아바타 표현 생성부를 이용하여 3D 아바타가 잘 표 현하도록 함에 의해 구현될 수 있다. 특히 본 발명의 일 실시예에 있어서, 아바타 표현 생성부는 실시간성을 담보할 수 있다. 즉, 사용자와 아 바타를 실시간으로 연결할 수 있다. 이를 위해, 아바타 표현 생성부는 실시간 클라우드 기반의 딥러닝 모 델로 구현될 수 있다. 이를 통해, 사용자 단말에서 딥러닝 모델을 구동하지 않고 클라우드 상의 서버에서 딥러 닝 모델을 수행하고 실시간으로 사용자의 아바타에 딥러닝 결과를 연결해줄 수 있는 것이다. 아바타 표현 생성 부의 동작은 도 3을 통해 보다 상세히 설명한다. 도 3은 도 2의 아바타 표현 생성부의 구성을 보다 구체적으로 나타낸 상세블록도이다. 도 3에 도시된 바와 같이, 아바타 표현 생성부는 형상 모듈, 제스쳐 및 이모션 모듈 및 보이스 모듈을 포함할 수 있 다. 도 3을 참조하면, 형상 모듈은 아바타의 기본적인 시각적 형상을 결정한다. 형상 모듈은 다양한 형상 의 아바타들에 대한, 3D 아바타 파일(File) 및 메타데이터(metadata), 아바타 3D 애니메이션 포멧 정의, 프로필 이미지, 사용자 정의 페르소나 데이터를 가지고 있을 수 있다. 형상 모듈은 본 발명의 일 실시예에 따른 아바타 커뮤니케이션 서버가 제공하는 아바타 플랫폼이 아닌, 다 른 아바타 플랫폼(예를 들어, 제페토(Zepeto), 브이로이드(Vroid) 등)에서 기생성된 아바타의 형상도 활용하도 록 할 수 있다. 즉, 타 아바타 플랫폼의 아바타의 형상에 대한 애니메이션 데이터에 호환성을 부여할 수 있다. 제스쳐 및 이모션 모듈은 LLM에서 생성해준 답변(text)을 기반으로 감정 추출 및 3D 아바타 애니메이션 데 이터를 생성하는 딥러닝 모델을 실행하는 모듈이다. 제스쳐 및 이모션 모듈은, 형상 모듈을 통해 생성된 기본 아바타의 형상에 다양한 표정 및 행동을 부 여하여 아바타가 사용자 단말에서의 움직임 또는 문맥에 따라 움직이도록 할 수 있다. 한편, 형상 모듈 및/또는 제스쳐 및 이모션 모듈을 통해 생성되는 아바타의 시각적 표현과 연관된 데 이터는 표준 3D 포맷 기반의 파일 포맷으로 생성될 수 있다. 일 예로, GLTF 파일, FBX(Filmbox) 파일, 유니티 (unity) 파일 및 언리얼(unreal) 파일 포맷을 지원할 수 있다. 제스쳐 및 이모션 모듈은 아바타의 호환성을 부여하기 위해, 아바타의 표정, 립싱크, 바디 포즈, 보이스 등을 생성하는 딥러닝 인퍼런스 모델을 포함한다. 이러한 딥러닝 인퍼런스 모델은, 비디오나 텍스트 데이터가 들어오면, 이를 아바타가 움직이는 블랜드쉐입, 립싱크, 바디제스쳐 등의 게임 및 애니메이션 산업 표준으로 사 용되는 3D 아바타 애니메이션 데이터(숫자 및 문자 데이터로 이루어져 있음)를 생성해 내는 딥러닝 모델일 수 있다. 딥러닝 인퍼런스 결과물은 아래와 같다. - 얼굴 표정 : Facial Blendshape 데이터 - 바디제스쳐 : 모션캡쳐 데이터와 호환되는 바디 애니메이션 데이터 제스쳐 및 이모션 모듈은 한 세트의 페이셜 블렌드쉐이프들(facial blendshape)을 기반으로 아바타의 표정 을 정의할 수 있다. 기본적으로 ARKit 페이셜 블렌드쉐이프들을 기반으로 아바타의 표정을 결정할 수 있다. 여 기에, 몇몇 블렌드쉐이프들을 추가하여 총 52개의 얼굴 표정 애니메이션으로 동작하게 제어할 수 있다. 제스쳐 및 이모션 모듈은 한 세트의 비짐(viseme), 한 세트의 브이로이드(Vroid), 한 세트의 추가적인 쉐 이프 키들(additional shape keys) 및 한 세트의 바디 제스처 포즈들(body gesture pose) 중 적어도 하나를 기 반으로 아바타의 표정뿐만 아니라 행동을 정의할 수 있다. 특히, 바디 애니케이션과 관련하여, ARCore 바디 포 즈 에스티메이션 기능, Mixame 바디 애니메이션 기능 및 MoCap 기술을 기반으로 사용자의 몸짓을 트랙킹하고 트 랙킹된 몸짓 관련 데이터를 기반으로 아바타의 행동을 결정할 수 있다. 특히, 제스쳐 및 이모션 모듈은, 상기 비짐 블렌드쉐이프(또는 페이스북 립싱크 기술) 기법을 기반으로, 립싱크(Lip Sync) 기능을 제공할 수 있 다. 이를 통해, 비짐 및 페이스북과 같은 레거시 시스템과의 호환이 가능하도록 지원한다. 한편, 일 예에서, 아바타 1은 제 1 아바타 플랫폼(예를 들어, 제페토)의 아바타이고, 아바타 2는 제 2 아바타 플랫폼(예를 들어, 브이로이드)의 아바타라고 할 때, 사용자가 아바타 1과 아바타 2를, 본 발명의 일 실시예에 따른 아바타 커뮤니케이션 서버가 제공하는 플랫폼에서, 상호 작용하도록 제어할 수 있다. 다수의 아바타 플랫 폼에서 생성된 아바타들에 호환성을 부여하기 위해, 장치는 타 플랫폼의 아바타 형상, 표정, 바디 제스쳐를 지 원하는 규격을 미리 내장하고 있을 수 있다. 그리고는, 아바타마다 해당 아바타가 구현되고 있는 플랫폼을 식별 하여, 식별된 플랫폼에서 지원하고 있는 데이터 규격을 확인한다. 그리고는, 이를 표준 규격(공통 인터페이스) 으로 변환한다. 그런 다음, 변환된 (공통 인터페이스) 아바타 데이터를 본 발명의 일 실시예에 따른 아바타 커 뮤니케이션 서버가 제공하는 서비스의 규격에 따른 아바타 데이터로 생성함에 의해, 서로 다른 플랫폼의 아바타 들의 형상, 표정, 제스처 등이 하나의 플랫폼에서 호환되도록 할 수 있다. 이러한 과정을 통해, 타 플랫폼의 아바타와 본 발명의 일 실시예에 따른 아바타 커뮤니케이션 서버가 제공하는 서비스에서 생성된 오리지널(original) 아바타가 함께 공존하는 환경을 제공할 수 있다. 이를 원활하게 구현하 기 위해, 앞서 설명한 바와 같이, 아바타의 비디오, 이미지 및/또는 오디오 데이터에 관한 공통 인터페이스가 요구될 수 있고, 형상 모듈 및/또는 제스쳐 및 이모션 모듈은 상기 공통 인터페이스를 기반으로 다양 한 플랫폼의 아바타들을 하나의 커뮤니케이션 시스템 상에서 동작하도록 아바타 관련 데이터의 변환 과정을 수 행할 수 있다. 추가적으로, 형상 모듈 및/또는 제스쳐 및 이모션 모듈은 사용자의 실시간 얼굴 표정을 검출하는 딥 러닝 기술을 기반으로 사용자의 감정을 분석할 수 있다. 이는 클라우드 또는 서비스 단말 기반 딥러닝 기술에 의해 구현될 수 있다. 실시간 얼굴 표정 인식 딥러닝 모델을 학습시켜 특정 표정에 대응하는 감정을 매칭시킴에 의해 사용자의 현재 감정을 결정할 수 있다. 그리고는, 분석된 현재 감정을 표현하기 위해 감정과 대응되어 기 정의된 표정 및/또는 제스처 데이터를 기반으로 사용자가 생성한 아바타가 매칭되는 표정 및/또는 제스처를 수 행하도록 제어할 수 있다. 보이스 모듈은 아바타의 음성 표현을 결정한다. 보이스 모듈은 STT(Speech To Text) 및 TTS(Text To Speech) 모델을 통해 음성을 텍스트로, 텍스트를 음성을 변환할 수 있다. 또한, 다국어를 인식 및 변환시키는 기능을 수행할 수 있다. 또한, 커스텀 페르소나를 통해 설정된 말투에 대응하는 음성이 출력될 수 있도록 제어 한다. 한편, 보이스 모듈은 음성 데이터를 분석을 이용하여 사용자의 감정을 인식할 수 있다. 음성 기반으로 실 시간 인식될 수 있는 감정은 8종으로 구분될 수 있다. 이는, 중립, 평온, 행복, 슬픔, 화남, 두려움, 혐오 및 놀람으로 구분될 수 있다. 이때, 보이스 모듈은 감정 카테고리별 컨피던스 값(confidence value)을 제공할 수 있다. 보이스 모듈을 통해 분석된 감정은 보이스 모듈을 통해 아바타의 목소리에 반영되어 표출될 수 있다. 또는, 음성을 통해 분석된 감정을 기반으로, 형상 모듈 및/또는 제스쳐 및 이모션 모듈이 그에 대응되는 표정 및 제스처를 아바타가 취하도록 할 수도 있다. 다시 도 2로 돌아가서, 아바타 커뮤니케이션 장치는 사용자가, 아바타 기반 서비스 개발자인 경우에 유용하게 사용가능한 SDK를 포함할 수 있다. SDK는 웹 상에서 사용자가 로그인하여 본 발명의 일 실시예에 따 른 아바타 생성 및 커뮤니케이션 기능을 이용할 수 있도록 제어할 수 있다. 플레이그라운드를 통해 생성된 아바 타의 테스트로 가능하게 다양한 기능을 제공할 수 있다. 웹뿐만 아니라, 안드로이드(Android), 유니티(unity), iOS 등 다양한 개발환경에서 본 발명의 일 실시예에 따른 아바타가 구현되도록 할 수 있다. 이는 공통 인터페이 스를 통해 이루어질 수 있다. 도 4는 Video2Avatar의 화면을 나타낸 도면이다. 도 4를 참조하면, 본 발명의 일 실시예에 따른 아바타 커뮤니케이션 플랫폼은 화면의 일 영역(도 4의 하단)에 사용자의 이미지 및/또는 비디오를 배열할 수 있다. 이때, 둘 이상의 사용자 간의 커뮤니케이션이라면, 이들의 얼굴 형상을 배열할 수 있다. 특히, 본 발명의 일 실시예에 따른 아바타 커뮤니케이션에서는, 사용자의 실제 얼 굴이 아닌, 사용자의 실제 얼굴 표정을 따라하는 아바타를 화면에 표현하는 것이 바람직한 만큼, 하단 우측의 사용자의 얼굴 표정을 따라하는 아바타를 사용자 단말이 표시하도록 할 수 있다. 도 4의 상단 도면을 참고하면, 도 4의 우측 하단의 사용자 얼굴과 동일한 표정의 아바타가 표현되는 것을 알 수 있다. 이때, 서버는 상단 도면의 좌측 상단 부분의 실제 사용자 비디오 데이터를 블렌드쉐이프 기반으로 분석한다. 그 리고는, 분석된 정보를 기반으로 (안경 쓴) 아바타가 사용자와 동일한 표정과 제스처를 하도록 제어할 수 있다. 즉, 사용자의 표정과 제스쳐를 최대한 정밀하게 아바타에 투사하는 트래킹형 딥러닝 기술을 통해 사용자의 표정 과 제스쳐를 실시간으로 따라하도록 할 수 있다. 이와 같이, 실시간 사용자의 표정 또는 제스쳐를 반영한 아바타의 시각적 데이터가 사용자 단말 화면의 다른 일 영역(도 4의 상단)에 배열되도록 하여, 사용자는 실시간으로 자신의 표정과 아바타의 따라하는 표정을 한 눈에 확인할 수 있도록 한다. 즉, 사용자가 하나의 화면에서 아바타와 자신의 표정을 함께 볼 수 있도록 사용자 인터 페이스를 구성할 수 있다. 또한, 화상통화의 사용자 부분의 화면을 아바타로 대체하여 아바타끼리의 대화가 이루어지도록 할 수 있다. 이 를 통해, 영상 통화에서 사용자의 실제 얼굴을 보여줘야하는 프라이버시 부담감을 제거한다. 또한, 사용자의 외 모에 대한 편견을 상대방이 받을 수 있는 문제점을 해소하고, 사용자의 현재 상태를 계속 주시하며 대화해야 하 는 영상 통화의 문제점을 해소할 수 있는 것이다. 도 5a는 도 1a의 AI와 사용자와의 커뮤니케이션 서비스 개발을 위한 SDK 모듈을 설명하기 위한 개념도이다. 도 5a를 참조하면, SDK 모듈은 LLM 모듈 및 커스텀 페르소나, 그리고, 아바타 표현 생성부를 통해 생성되는 AI 기반의 아바타를, 사용자, 특히 개발자와 연결하는 기능을 수행한다. SDK를 통해 사용자는 AI와 사람(특히, 개 발자) 간의 인터페이스 역할을 수행할 수 있다. 본 발명의 일 실시예에 따르면, 개발자로의 AI 기반 아바타 생성을 위한 SDK 제공을 위해서, 다음의 절차가 진 행될 수 있다. 먼저, 개발자 등록 절차가 진행되는 것이 바람직하다. 아바타 커뮤니케이션 장치는 웹 페이지 또는 별도의 애플 리케이션을 통해 개발자의 접속을 허여할 수 있다. 해당 페이지에서, 개발자에게 API 키(Key)를 발급할 수 있고, 장치는 이를 관리할 수 있다. 개발자가 등록 절차를 수행하고 나면, 장치는 아바타 생성을 지원한다. 아바타 생성을 위해 아바타의 계정을 먼 저 생성하고 그에 대한 설정 정보를 입력받을 수 있다. 이때 앞서, 도 2 및 도 3을 통해 설명한 AI 아바타를 커스터마이징하기 위한 다양한 정보를 설정할 수 있다. 이는 다음을 포함한다. ㆍ 아바타 이름 ㆍ 아바타의 성격(Custom Persona) ㆍ 아바타의 보이스(voice) ㆍ 아바타의 제스쳐 & 이모션 설정(Video2Avatar, Text2Avatar custom 세부 설정) ㆍ 3D 아바타 형태 설정 ㆍ 아바타 계정 리스트 관리(생성/수정/삭제) 개발자는 사용자 단말을 통해, 웹 페이지 및/또는 애플리케이션에 접속하여, 아바타의 이름, 성격, 보이스, 제 스처 및 이모션, 3D 아바타 형상 설정 등을 생성할 수 있다. 개발자는 다수의 아바타를 생성하고, 그에 대한 계 정 리스트를 생성하여 자신이 생성한 아바타들을 관리할 수 있다. 생성 이후, 수정이 필요하면 아바타의 이름, 성격 등을 수정할 수 있고, 삭제도 가능하다. 추가 생성도 가능하다. 이와 같이 다수의 아바타를 개발자가 생성하고 나면, 플레이 그라운드를 통해 생성된 아바타를 테스트할 수 있 다. 보다 구체적으로, 생성된 아바타의 Video2Avatar 및 Text2Avatar의 세부 설정을 테스트해 볼 수 있다. 예를 들어, 생성된 아바타가 사용자의 표정 및 행동을 잘 따라하는지, 그리고, 사용자의 음성 또는 텍스트 명령을 잘 해석하여 문맥에 맞는 표정 및 행동을 취하는지 등을 시험해 볼 수 있다. 생성된 아바타와 텍스트 및 보이스로 채팅 환경에서 설정된 목소리와 성격 등을 테스트해 볼 수 있는 환경을 제공한다. 한편, 상기한 개발자 등록, 아바타 계정 생성 및 설정 정의, 플레이그라운드의 제공, 관련 설정을 위한 대쉬보 드(dashboard)의 제공은 SaaS(Software as a Service) 형태로 제공될 수 있다. 보다 구체적으로, SaaS 서비스는, 사용자가 사용자 계정을 등록함에 대응하여, 사용자 계정에 대응하는 API 키 (key)를 발급하는 단계를 포함한다. 이때, 하나의 아바타가 하나의 API에 대응하도록 제어할 수 있다. 그리고 이때, 발급된 API 키를 기반으로, 사용자 계정에 대응하는 적어도 하나의 아바타 계정이 함께 관리된다. 특히, 복수 개의 아바타 계정이 하나의 사용자 계정에 연동되어 리스트로 관리될 수도 있다. 복수 개의 아바타 계정은 각각 서로 다른 아바타 설정정보로 이루어질 수 있다. 이때, 다수의 아바타 설정정보가 아바타 계정과 연동되어 상기 리스트에 의해 관리될 수 있다. 한편, 본 발명의 실시예에 따르면, 아바타 관리 리스트를 이용하여, 아바타 계정에 대응하는 기생성된 아바타를 복사, 수정 및 삭제하도록 허여하는 사용자 인터페이스가 제공될 수 있다(도 7 참조). 추가적으로, SaaS 서비스 는 아바타 API 사용 내역을 관리하는 기능을 더 포함한다. 이때, API 사용 내역을 기반으로 사용 내역에 상응하 는 비용을 등록된 사용자 계정에 대응하는 계좌에 과금할 수 있다. 도 5b는 도 1b의 사용자와 사용자와의 커뮤니케이션 서비스 개발을 위한 SDK 모듈을 설명하기 위한 개념도이다. 도 5b를 참조하면, 장치는, 도 5a와 유사하게, SaaS 형태로 사용자와 사용자(Human-Human) 간의 아바타 커뮤니 케이션 인터페이스를 사용자들에게 제공할 수 있다. 이때, 아바타 표현 생성부를 통해 생성된 둘 이상의 아바타 들(아바타 형상 모듈, 제스처/이모션 모듈 및 보이스 모듈 기반으로 생성된 것일 수 있음)이 SDK를 통해 사용자 와 연결될 수 있다. 즉, 사용자는 SDK를 통해 각각 하나 이상의 아바타를 생성하고 생성된 아바타를 이용하여 서로 간에 커뮤니케이션을 수행할 수 있다. 위와 같은, 개발자 등록, 아바타 계정 생성 및 설정, 플레이그라운드의 제공 등은 대쉬보드를 제공함에 의해 수 행될 수 있다. 추가적으로, 장치는 아바타 API 사용 내역 관리, 추후 API 사용 과금 등을 부과하는 기능을 실행 할 수 있다. 이때, 하나의 아바타는 하나의 API에 대응될 수 있다. 즉, 본 발명의 실시예에 따르면, 사용자와 사용자뿐만 아니라, 사용자와 AI를 3D 아바타를 통해 실시간 연결 및 표현하는 API 기능을 제공한다. 도 6은 도 5a 및 도 5b의 SDK를 이용하여 아바타를 생성하는 UI/UX 화면을 나타낸 도면이다. 도 6을 참조하면, 장치는 사용자에게 아바타를 생성할 수 있는 사용자 인터페이스를 제공한다. 도 6의 실시예와 같이, 장치는 아바타의 이름을 입력하는 란, LLM 모델을 선택하는 란, TTS 모델을 선택하는 란, 특정 언어에 대 응하는 목소리를 설정하는 란, Text2Avatar(T2A) 관련 정보를 설정하는 란 및 프롬프트를 생성하는 란 등을 제 공한다. 아바타 이름은 사용자가 직접 해당 란에 타이핑을 함에 의해 생성될 수 있다. LLM 모델은 azure, chatGPT 등 미 리 정의된 다양한 LLM 모델 중 하나를 선택함에 의해 설정될 수 있다. TTS도 naver, azure 등 미리 정의된 TTS 모델 중 하나를 선택함에 의해 설정될 수 있다. 목소리는 언어별로 다르게 설정할 수 있다. 예를 들어, 한국어 목소리는 여자 아이 목소리로, 영문 묵소리는 남자 성인 목소리로 설정할 수 있다. 이는 기정의된 목소리들 중 하나를 선택하는 방식도 가능하지만, 사용자가 직접 자신의 목소리를 입력함에 의해 사용자 목소리를 따라하도 록 할 수도 있다. T2A 설정은 nvidia, text2avatar 및 azure 등과 같은 모델들 중 하나를 선택함에 의해 이루어 질 수 있다. 프롬프트는 사용자가 직접 아바타의 성격을 지칭하는 텍스트를 입력함에 의해 생성될 수 있다. 이와 같은 새로운 아바타 생성과 관련된 다양한 파라미터들을 입력하고 나서, 아바타의 형상을 결정할 수 있다. 우측 상단의 두번째 아이콘 \"change avatar\"를 클릭하면, 기정의된 다수의 아바타 형상이 표시될 수 있다. 사용 자는 이들 중 하나를 자신의 아바타로 선택할 수 있다. 그리고, 우측 상단의 첫번째 아이콘 \"create\"를 클릭하 면, 좌측의 아바타 관련 파라미터들을 기반으로 \"change avatar\" 기능 기반의 다수 아바타들 중 선택한 아바타 의 형상으로 자신만의 3D 아바타가 생성되게 된다. 즉, 위와 같은 과정을 통해, 하나의 아바타 계정이 생성될 수 있다. 도 7은 도 6을 통해 생성된 아바타들을 관리하는 UI/UX 화면을 나타낸 도면이다. 도 7을 참조하면, 장치는 접속된 사용자에게 자신이 생성한 아바타를 관리하는 사용자 인터페이스를 제공한다. 사용자는 하나 또는 그 이상의 아바타를 생성할 수 있고, 생성된 아바타는 서버에 저장된다. 그리고, 리스트를 통해 관리될 수 있다. 도 7의 실시예에서, 사용자는 안경쓴 아바타 1과 멜빵바지 아바타 2를 생성해 놓고 있다. 이들 아바타의 박스에 마우스 커서를 접근시키면, \"Playground\", \"Edit\" 및 \"More\" 아이콘이 생성된다. \"Playground\" 아이콘을 클릭하면, 장치는 해당 아바타를 플레이그라운드로 가져간다. 사용자는 여기서 자신이 만든 아바타의 성격, 표현, 형상, 목소리 등을 다양하게 테스트해 볼 수 있다. \"Edit\" 아이콘을 클릭하면, 장치 는 다시 도 6의 사용자 인터페이스를 제공하면서, 기 설정된 정보를 표시한다. 여기서, 사용자는 기존의 설정을 자유롭게 변경할 수 있다. \"More\" 아이콘을 클릭하면, 생성된 아바타를 웹 상에 공유하는 기능을 활성화될 수 있다. 또는, 해당 아바타를 복사시키는 기능을 활성화시킬 수도 있고, 삭제시키는 기능을 활성화시킬 수도 있다. 즉, 도 7의 사용자 인터페이스를 통해 사용자는 효율적으로 자신이 생성한 다수의 아바타를 관리할 수 있 다. 물론 좌측의 \"Create New Avatar\" 아이콘을 이용하여 신규 아바타를 더 생성할 수 있음은 자명한 것이다. 도 8은 도 6을 통해 생성된 아바타를 이용하여 커뮤니케이션 서비스를 이용하는 화면을 나타낸 도면이다. 도 8을 참조하면, 장치는 생성된 아바타를 가지고 다양한 기능을 테스트해볼 수 있는 플레이그라운드를 제공한 다. 플레이그라운드에서, 장치는 chatbot 형태로 아바타와 대화할 수 있다. 이때, 아바타는 사용자의 메시지를 반응하여 AI 기반의 답변을 수행한다. 사용자의 메시지에 대한 답변시, 아바타에게 설정된 커스텀 페르소나, 목 소리, 표현방식 등을 기반으로 아바타의 표현이 결정된다. 일 예로, 사용자가 채팅을 입력하는 동안에는, 아바타는 사용자의 말에 귀를 기울이는 듯한 동작을 수행한다. 그리고, 사용자의 채팅에 대해, LLM을 통해 답변이 생성되면, 생성된 답변을 아바타가 설정된 목소리, 표현방식 등을 이용하여 생동감있게 표현한다. 한편, 아바타로의 입력은 반드시 텍스트 채팅 형태로 이루어져야 하는 것 은 아니고, 음성 기반으로 이루어질 수도 있다. 이상에서 설명된 시스템 또는 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 시스템, 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크 로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에 서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가"}
{"patent_id": "10-2024-0007944", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "사용되는 것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처 리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세 서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시예들에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설 계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto- optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드 뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하 드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2024-0007944", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2024-0007944", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 발명의 일 실시예에 따른 3차원 아바타 커뮤니케이션을 위한 서비스 제공 시스템을 나타낸 개념도, 도 1b는 본 발명의 다른 실시예에 따른 3차원 아바타 커뮤니케이션을 위한 서비스 제공 시스템을 나타낸 개념도, 도 2는 도 1a 또는 도 1b의 시스템에 포함된 아바타 커뮤니케이션 장치를 구체적으로 나타낸 블록도, 도 3은 도 2의 아바타 표현 생성부의 구성을 보다 구체적으로 나타낸 상세블록도, 도 4는 Video2Avatar의 화면을 나타낸 도면, 도 5a는 도 1a의 AI와 사용자와의 커뮤니케이션 서비스 개발을 위한 SDK 모듈을 설명하기 위한 개념도, 도 5b는 도 1b의 사용자와 사용자와의 커뮤니케이션 서비스 개발을 위한 SDK 모듈을 설명하기 위한 개념도, 도 6은 도 5a 및 도 5b의 SDK를 이용하여 아바타를 생성하는 UI/UX 화면을 나타낸 도면, 도 7은 도 6을 통해 생성된 아바타들을 관리하는 UI/UX 화면을 나타낸 도면, 도 8은 도 6을 통해 생성된 아바타를 이용하여 커뮤니케이션 서비스를 이용하는 화면을 나타낸 도면이다."}
