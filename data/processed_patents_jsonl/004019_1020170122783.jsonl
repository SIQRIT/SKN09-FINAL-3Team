{"patent_id": "10-2017-0122783", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0033974", "출원번호": "10-2017-0122783", "발명의 명칭": "인공지능 이용한 이동 로봇 및 이동 로봇의 제어방법", "출원인": "엘지전자 주식회사", "발명자": "정장훈"}}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "본체를 이동시키는 주행부;주행 중 주변의 물건을 감지하는 센싱부;정보를 입력받거나 수신하고, 정보를 출력하거나 송신하는 커뮤니케이션 모듈; 및상기 커뮤니케이션 모듈로부터 입력되거나 수신한 구역 정보에 의해 특정되는 구역을 주행하며 물건을 탐색하게제어하고, 감지한 발견물의 식별 정보 및 위치 정보를 상기 커뮤니케이션 모듈을 통해 출력하거나 송신하게 제어하는 제어부를 포함하는 이동 로봇."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,주행 구역 중 일부 구역이 구분되게 구비되고,상기 제어부는,상기 구역 정보에 의해 특정되는 상기 일부 구역을 주행하며 물건을 탐색하게 제어하는, 이동 로봇."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 커뮤니케이션 모듈은,복수의 물건 정보를 입력받거나 수신하고, 각각의 물건 정보마다 매칭되는 구역 정보를 입력받거나 수신하고,상기 제어부는,현재 위치가 속한 구역에 따라 탐색하는 물건이 달라지게 제어하는, 이동 로봇."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 제어부는,상기 커뮤니케이션 모듈로부터 입력받거나 수신한 물건 정보에 따라 특정되는 물건을 탐색하게 제어하는, 이동로봇."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 제어부는,상기 커뮤니케이션 모듈로부터 신규로 입력받거나 수신한 물건 정보와 기저장된 물건 정보를 비교하여, 매칭되면 상기 커뮤니케이션 모듈을 통해 기저장된 물건 정보를 제시하게 제어하는, 이동 로봇."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 제어부는,상기 센싱부터부터 획득된 이미지를 이용하여 물건을 탐색하게 제어하되, 발견물의 이미지를 제외한 정보를 상공개특허 10-2019-0033974-3-기 커뮤니케이션 모듈을 통해 출력하거나 송신하게 제어하는, 이동 로봇."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "주행을 위한 구역 정보를 입력 받는 입력 단계;상기 구역 정보에 의해 특정되는 구역을 주행하며 물건을 탐색하는 주행 단계; 및상기 주행 단계에서 감지한 발견물의 식별 정보 및 위치 정보를 출력하는 출력 단계를 포함하는 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,주행 구역 중 일부 구역이 구분되게 구비되고,상기 입력 단계에서 상기 구역 정보에 의해 상기 일부 구역이 특정되는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7항에 있어서,상기 입력 단계에서 상기 구역 정보의 입력에 의해 가구의 아래 구역이 특정 가능하게 구비되는, 이동 로봇의제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7항에 있어서,상기 구역 정보는 외부의 상한면까지의 높이 정보를 포함하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 7항에 있어서,상기 구역 정보는 일부 구역의 이미지를 포함하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 7항에 있어서,상기 입력 단계에서,복수의 물건 정보를 입력받고, 각각의 물건 정보마다 매칭되는 구역 정보를 입력받고,상기 주행 단계에서,현재 위치가 속한 구역에 따라 탐색하는 물건이 달라지는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 7항에 있어서,상기 입력 단계에서 물건 정보를 입력받고,상기 주행 단계에서 상기 물건 정보에 따라 특정되는 물건을 탐색하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 물건 정보는 물건의 부피 정보를 포함하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2019-0033974-4-제 13항에 있어서,상기 물건 정보는 물건의 종류 이름 또는 이미지를 포함하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 13항에 있어서,상기 입력 단계에서,신규로 입력된 물건 정보와 기저장된 물건 정보를 비교하여, 매칭되면 사용자에게 기저장된 물건 정보를 제시하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 13항에 있어서,상기 입력 단계에서,신규로 입력된 물건 정보와 기저장된 물건 정보를 비교하여, 매칭되면 신규로 입력된 물건 정보 및 기저장된 물건 정보 중 어느 하나를 선택하도록 제시하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 7항에 있어서,상기 출력 단계에서, 발견물의 발견 시간 정보를 출력하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 7항에 있어서,상기 주행 단계에서 획득된 이미지를 이용하여 물건을 탐색하되, 상기 출력 단계에서 발견물의 이미지를 제외한정보를 출력하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19항에 있어서,상기 입력 단계에서 물건 정보를 입력받고,상기 물건 정보는 물건의 이미지를 포함하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0122783", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 이동 로봇은, 본체를 이동시키는 주행부; 주행 중 주변의 물건을 감지하는 센싱부; 정보를 입력 받거나 수신하고, 정보를 출력하거나 송신하는 커뮤니케이션 모듈; 및 상기 커뮤니케이션 모듈로부터 입력되거나 수신한 구역 정보에 의해 특정되는 구역을 주행하며 물건을 탐색하게 제어하고, 감지한 발견물의 식별 정보 및 위치 정보를 상기 커뮤니케이션 모듈을 통해 출력하거나 송신하게 제어하는 제어부를 포함한다. 본 발명에 따른 이동 로봇의 제어방법은, 주행을 위한 구역 정보를 입력 받는 입력 단계; 상기 구역 정보에 의해 특정되는 구역을 주행하며 물건을 탐색하는 주행 단계; 및 상기 주행 단계에서 감지한 발견물의 식별 정보 및 위 치 정보를 출력하는 출력 단계를 포함한다."}
{"patent_id": "10-2017-0122783", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 이동 로봇 및 이동 로봇의 제어방법에 관한 것으로, 보다 자세하게는 이동 로봇의 인식 기술에 관한 것이다."}
{"patent_id": "10-2017-0122783", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 산업용으로 개발되어 공장 자동화의 일 부분을 담당하여 왔다. 최근에는 로봇을 응용한 분야가 더욱 확 대되어, 의료용 로봇, 우주 항공 로봇 등이 개발되고, 일반 가정에서 사용할 수 있는 가정용 로봇도 만들어지고 있다. 이러한 로봇 중에서 자력으로 주행이 가능한 것을 이동 로봇이라고 한다. 가정에서 사용되는 이동 로봇의 대표적인 예는 로봇 청소기이다. 이동 로봇이 스스로 주행 구역을 학습하여 맵핑하고, 맵 상에서 현재 위치를 파악하는 기술들이 알려져 있다. 또한, 이동 로봇을 이용한 각종 스마트 기능들이 알려져 있다. 종래 기술(한국공개특허공보 공개번호 10-2013- 0030932)에는, 청소작업 중 장애물이 감지되거나, 주행에 장애가 있을 경우 상기 영상획득수단을 이용하여 촬영 을 실시하고 촬영된 정보를 사용자 단말기로 전송하여, 분실한 물건을 찾아줄 수 있는 기술이 개시된다.선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허공보 공개번호 10-2013-0030932 (공개일자 2013. 3. 28.) 비특허문헌"}
{"patent_id": "10-2017-0122783", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기 종래 기술에서는 이동 로봇이 물건을 찾기 위해서 주행 구역 내 우선 순위 없이 모든 구역을 이동할 가능 성이 커, 물건을 찾기 까지 오랜 시간이 소요되는 문제가 있다. 본 발명의 제 1과제는 이러한 문제를 해결하여 이동 로봇이 효율적으로 물건을 찾게 하는 것이다. 본 발명의 제 2과제는 이동 로봇이 감지한 발견물의 정보를 통해, 사용자가 곧바로 해당 위치로 가서 발견물을 획득할 수 있게 유도하는 것이다. 본 발명의 제 3과제는, 복수의 분실물이 있는 경우에도 각 분실물의 성격을 고려하여, 효율적인 물건 탐색이 가 능케 하는 것이다. 본 발명의 제 4과제는, 이동 로봇이 탐색할 구역을 사용자가 용이하게 입력할 수 있게 하는 것이다. 상기 종래 기술에서는 이동 로봇이 찾으려는 분실물의 특정없이 물건을 탐색함으로써, 불필요한 발견물 정보가 사용자에게 무분별하게 전달되는 문제가 있다. 본 발명의 제 5과제는 이러한 문제를 해결하는 것이다. 본 발명의 제 6과제는, 이동 로봇이 감지할 분실물을 사용자가 용이하게 입력할 수 있게 하는 것이다. 본 발명의 제 7과제는, 기저장된 정보를 활용하여 사용자의 정보 입력을 스마트하게 보조하게 하는 것이다. 상기 종래 기술에서는 이동 로봇이 발견물의 영상을 사용자에게 전송함으로써, 발견물의 영상에 사용자의 프라 이버시가 노출될 수 있는 문제가 있다. 본 발명의 제 8과제는 이러한 문제를 해결하는 것이다."}
{"patent_id": "10-2017-0122783", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제들을 해결하기 위하여, 본 발명의 해결 수단에 따른 이동 로봇은, 본체를 이동시키는 주행부; 주행 중 주변의 물건을 감지하는 센싱부; 정보를 입력받거나 수신하고, 정보를 출력하거나 송신하는 커뮤니케이션 모듈; 및 상기 커뮤니케이션 모듈로부터 입력되거나 수신한 구역 정보에 의해 특정되는 구역을 주행하며 물건을 탐색 하게 제어하고, 감지한 발견물의 식별 정보 및 위치 정보를 상기 커뮤니케이션 모듈을 통해 출력하거나 송신하 게 제어하는 제어부를 포함한다. 주행 구역 중 일부 구역이 구분되게 구비될 수 있다. 상기 제어부는, 상기 구역 정보에 의해 특정되는 상기 일 부 구역을 주행하며 물건을 탐색하게 제어할 수 있다. 상기 커뮤니케이션 모듈은, 복수의 물건 정보를 입력받거나 수신하고, 각각의 물건 정보마다 매칭되는 구역 정 보를 입력받거나 수신할 수 있다. 상기 제어부는, 현재 위치가 속한 구역에 따라 탐색하는 물건이 달라지게 제어할 수 있다. 상기 제어부는, 상기 커뮤니케이션 모듈로부터 입력받거나 수신한 물건 정보에 따라 특정되는 물건을 탐색하게 제어할 수 있다. 상기 제어부는, 상기 커뮤니케이션 모듈로부터 신규로 입력받거나 수신한 물건 정보와 기저장된 물건 정보를 비 교하여, 매칭되면 상기 커뮤니케이션 모듈을 통해 기저장된 물건 정보를 제시하게 제어할 수 있다. 상기 제어부는, 상기 센싱부터부터 획득된 이미지를 이용하여 물건을 탐색하게 제어하되, 발견물의 이미지를 제 외한 정보를 상기 커뮤니케이션 모듈을 통해 출력하거나 송신하게 제어 수 있다. 상기 과제들을 해결하기 위하여, 본 발명의 해결 수단에 따른 이동 로봇의 제어방법은, 주행을 위한 구역 정보 를 입력 받는 입력 단계; 상기 구역 정보에 의해 특정되는 구역을 주행하며 물건을 탐색하는 주행 단계; 및 상 기 주행 단계에서 감지한 발견물의 식별 정보 및 위치 정보를 출력하는 출력 단계를 포함한다. 주행 구역 중 일부 구역이 구분되게 구비될 수 있다. 상기 입력 단계에서 상기 구역 정보에 의해 상기 일부 구 역이 특정될 수 있다. 상기 입력 단계에서 상기 구역 정보의 입력에 의해 가구의 아래 구역이 특정 가능하게 구비될 수 있다. 상기 구역 정보는 외부의 상한면까지의 높이 정보를 포함할 수 있다. 상기 구역 정보는 일부 구역의 이미지를 포함할 수 있다. 상기 입력 단계에서, 복수의 물건 정보를 입력받고, 각각의 물건 정보마다 매칭되는 구역 정보를 입력받을 수 있다. 상기 주행 단계에서, 현재 위치가 속한 구역에 따라 탐색하는 물건이 달라질 수 있다. 상기 입력 단계에서 물건 정보를 입력받을 수 있다. 상기 주행 단계에서 상기 물건 정보에 따라 특정되는 물건 을 탐색할 수 있다. 상기 물건 정보는 물건의 부피 정보를 포함할 수 있다. 상기 물건 정보는 물건의 종류 이름 또는 이미지를 포함할 수 있다. 상기 입력 단계에서, 신규로 입력된 물건 정보와 기저장된 물건 정보를 비교하여, 매칭되면 사용자에게 기저장 된 물건 정보를 제시할 수 있다. 상기 입력 단계에서, 신규로 입력된 물건 정보와 기저장된 물건 정보를 비교하여, 매칭되면 신규로 입력된 물건 정보 및 기저장된 물건 정보 중 어느 하나를 선택하도록 제시할 수 있다. 상기 출력 단계에서, 발견물의 발견 시간 정보를 출력할 수 있다. 상기 주행 단계에서 획득된 이미지를 이용하여 물건을 탐색하되, 상기 출력 단계에서 발견물의 이미지를 제외한 정보를 출력할 수 있다. 상기 물건 정보는 물건의 이미지를 포함할 수 있다."}
{"patent_id": "10-2017-0122783", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "구역 정보에 의해 특정되는 구역을 주행하며 물건을 탐색하게 함으로써, 이동 로봇이 분실물이 있을 가능성이 큰 일부 구역을 우선적으로 탐색하게 할 수 있는 효과가 있다. 사용자에게 발견물의 식별 정보 및 위치 정보를 출력함으로써, 사용자가 해당 발견물의 위치를 곧바로 인지하여, 용이하게 발견물을 획득할 수 있는 효과가 있다. 또한, 분실물이 있을 가능성이 높은 가구의 아래 구역을 특정하여, 효율적으로 분실물을 찾을 수 있는 효과가 있다. 또한, 외부의 상한면까지의 높이 정보 및/또는 일부 구역의 이미지를 이용하여 구역 정보를 입력함으로써, 사용 자가 이동 로봇의 탐색을 위한 일부 구역을 용이하게 특정할 수 있다. 또한, 복수의 물건 정보 및 각각의 물건 정보마다 매칭되는 구역 정보를 입력 받음으로써, 복수의 분실물을 동 시에 탐색하면서도, 각각의 분실물마다 탐색 범위를 달리할 수 있어, 효율적인 분실물 탐색이 가능해진다. 또한, 물건 정보를 입력 받음으로써, 이동 로봇이 사용자가 찾기를 원하는 분실물을 집중적으로 탐색할 수 있고, 나아가 사용자가 불필요한 정보를 출력받지 않아도 되어 편리하다. 또한, 물건의 부피 정보, 물건의 종류 이름, 및/또는 이미지를 이용하여 물건 정보를 입력함으로써, 사용자가 이동 로봇이 탐색할 물건을 용이하게 특정할 수 있다. 또한, 신규로 입력된 물건 정보와 기저장된 물건 정보가 매칭되면 사용자에게 기저장된 물건 정보를 제시함으로 써, 사용자는 신규로 입력한 물건 정보가 이미 기저장되어 있는지 여부를 확인할 수 있다.또한, 신규로 입력된 물건 정보와 기저장된 물건 정보가 매칭되면 신규로 입력된 물건 정보 및 기저장된 물건 정보 중 어느 하나를 선택하도록 제시함으로써, 사용자가 기저장 물건 정보를 활용하여 물건 정보를 입력할 수 있도록 편의성을 제공하되, 사용자가 유사한 다른 물건 정보를 신규로 입력하려 할 때, 제어부가 신규의 물건 정보를 기저장 물건 정보로 오인하는 오류의 발생을 막을 수 있다. 또한, 발견 시간 정보를 출력함으로써, 사용자가 발견물의 정보가 어느 시점에 발생한 것인지 알 수 있어, 사용 자가 출력 정보를 더욱 편리하게 활용할 수 있게 한다. 상기 주행 단계에서 획득된 이미지를 이용하여 물건을 감지하되, 상기 출력 단계에서 발견물의 이미지를 제외한 정보를 출력함으로써, 사용자의 사생활(프라이버시)를 보호할 수 있으면서도, 이미지 획득을 통한 감지의 정확 성 상승 효과를 얻을 수 있다."}
{"patent_id": "10-2017-0122783", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명인 이동 로봇은 바퀴 등을 이용하여 스스로 이동이 가능한 로봇을 의미하고, 가정 도우미 로봇 및 로봇 청소기 등이 될 수 있다. 이하 도 1 내지 도 5를 참조하여, 이동 로봇 중 로봇 청소기를 예로들어 설명하나, 반드시 이에 한정될 필 요는 없다. 이동 로봇은 본체를 포함한다. 이하, 본체의 각부분을 정의함에 있어서, 주행구역 내의 천장을 향하는 부분을 상면부(도 2 참조)로 정의하고, 주행구역 내의 바닥을 향하는 부분을 저면부(도 4 참조)로 정의하고, 상기 상면부와 저면부 사이에서 본체의 둘레를 이루는 부분 중 주행방향을 향하는 부분을 정면부(도 3 참조)라고 정의한다. 또한, 본체의 정면부와 반대 방향을 향하는 부분을 후면부로 정의할 수 있다. 본체 는 이동 로봇를 구성하는 각종 부품들이 수용되는 공간을 형성하는 케이스를 포함할 수 있다. 이동 로봇은, 주변의 물건을 감지하는 센싱부를 포함한다. 센싱부는, 이동 로봇의 주행 중 주변 물건의 정보를 감지할 수 있다. 센싱부는, 이동 로봇의 주변 환경 정보를 감지할 수 있다. 센싱 부는 낭떠러지나 장애물 등의 주변 환경 정보를 감지할 수 있다. 센싱부의 주변 물건 감지 기능을 통 하여, 이동 로봇은 물건을 탐색할 수 있다. 상기 주변의 물건은, 주행면 상에 놓여진 가구나 분실물 및 외부의 상측 물체 등을 의미한다. 외부의 상측 물체 는, 이동 로봇의 상측 방향에 배치되는 천장이나 가구의 하측면 등이 될 수 있다. 상기 주변 물건의 정보는, 이동 로봇이 촬영한 영상 정보를 포함할 수 있다. 상기 주변 물건의 정보는, 이 동 로봇이 상기 주변의 물건까지의 거리 정보를 포함할 수 있다. 센싱부는 본체의 상면부 및/또는 전방부에 구비될 수 있다. 센싱부의 감지 방향은 상측, 전후방 및/또는 측방이 될 수 있다. 센싱부는, 주변 물건의 영상을 감지하거나 주변 물건까지의 거리를 감지할 수 있다. 센싱부는 이동 중 시간에 따른 각 위치에서 상기 주변 물건의 정보를 감지할 수 있다. 센싱부는 주변 물건의 영상을 감지하는 영상 감지부를 포함할 수 있다. 영상 감지부는 주행구역 을 촬영하는 것으로, 디지털 카메라를 포함할 수 있다. 상기 디지털 카메라는 적어도 하나의 광학렌즈와, 상기 광학렌즈를 통과한 광에 의해 상이 맺히는 다수개의 광다이오드(photodiode, 예를 들어, pixel)를 포함하여 구 성된 이미지센서(예를 들어, CMOS image sensor)와, 상기 광다이오드들로부터 출력된 신호를 바탕으로 영상을 구성하는 디지털 신호 처리기(DSP: Digital Signal Processor)를 포함할 수 있다. 상기 디지털 신호 처리기는 정지영상은 물론이고, 정지영상으로 구성된 프레임들로 이루어진 동영상을 생성하는 것도 가능하다. 센싱부는 주변 물체까지의 거리를 감지하는 거리 감지부를 포함할 수 있다. 거리 감지부는 본체 의 정면부에 배치될 수 있다. 거리 감지부는 전방의 장애물을 감지할 수 있다. 복수의 거리 감지부 가 구비될 수 있다. 초음파 또는 적외선 등을 이용하여 거리 감지부가 구현될 수 있다. 카메라를 이 용하여 거리 감지부가 구현될 수 있다. 센싱부는 주행구역 내 바닥에 낭떠러지의 존재 여부를 감지하는 낭떠러지 감지부를 포함할 수 있다. 복수의 낭떠러지 감지부가 구비될 수 있다. 센싱부는 바닥의 영상을 획득하는 하부 영상 센서를 더 포함할 수 있다. 이동 로봇은 본체를 이동시키는 주행부를 포함한다. 주행부는 바닥에 대해 본체를 이 동시킨다. 주행부는 본체를 이동시키는 적어도 하나의 구동 바퀴를 포함할 수 있다. 주행부 는 구동 모터를 포함할 수 있다. 구동 바퀴는 본체의 좌, 우 측에 각각 구비될 수 있으며, 이하, 각각 좌륜(166(L))과 우륜(166(R))이라고 한다. 좌륜(166(L))과 우륜(166(R))은 하나의 구동 모터에 의해 구동될 수도 있으나, 필요에 따라 좌륜(166(L))을 구 동시키는 좌륜 구동 모터와 우륜(166(R))을 구동시키는 우륜 구동 모터가 각각 구비될 수도 있다. 좌륜(166 (L))과 우륜(166(R))의 회전 속도에 차이를 두어 좌측 또는 우측으로 본체의 주행방향을 전환할 수 있다. 이동 로봇은 바닥을 청소하는 청소부를 포함할 수 있다. 이동 로봇은 주행 구역을 이동하며 청 소할 수 있다. 청소부는, 이물질을 흡입하는 흡입 장치, 비질을 수행하는 브러시(184, 185), 흡입장치나 브러시에 의해 수거된 이물질을 저장하는 먼지통(미도시) 및/또는 걸레질을 수행하는 걸레부(미도시) 등을 포함 할 수 있다. 본체의 저면부에는 공기의 흡입이 이루어지는 흡입구(180h)가 형성될 수 있다. 본체 내에는 흡입구 (180h)를 통해 공기가 흡입될 수 있도록 흡입력을 제공하는 흡입장치(미도시)와, 흡입구(180h)를 통해 공기와 함께 흡입된 먼지를 집진하는 먼지통(미도시)이 구비될 수 있다. 케이스에는 상기 먼지통의 삽입과 탈거를 위한 개구부가 형성될 수 있고, 상기 개구부를 여닫는 먼지통 커 버가 케이스에 대해 회전 가능하게 구비될 수 있다.흡입구(180h)를 통해 노출되는 솔들을 갖는 롤형의 메인 브러시와, 본체의 저면부 전방측에 위치하며, 방사상으로 연장된 다수개의 날개로 이루어진 솔을 갖는 보조 브러시가 구비될 수 있다. 이들 브러시(184, 185)들의 회전에 의해 주행구역내 바닥으로부터 먼지들이 제거되며, 이렇게 바닥으로부터 분리된 먼지들은 흡입구(180h)를 통해 흡입되어 먼지통에 모인다. 배터리는 상기 구동 모터뿐만 아니라, 이동 로봇의 작동 전반에 필요한 전원을 공급할 수 있다. 배터 리가 방전될 시, 이동 로봇는 충전을 위해 충전대로 복귀하는 주행을 실시할 수 있으며, 이러한 복귀 주행 중, 이동 로봇는 스스로 충전대의 위치를 탐지할 수 있다. 충전대는 소정의 복귀 신호를 송출하는 신호 송출부(미도시)를 포함할 수 있다. 상기 복귀 신호는 초음파 신호 또는 적외선 신호일 수 있으나, 반드시 이에 한정되어야하는 것은 아니다. 이동 로봇은, 정보를 입력받거나 수신하고 정보를 출력하거나 송신하는 커뮤니케이션 모듈을 포함한 다. 커뮤니케이션 모듈은 외부의 다른 기기와 정보를 송수신하는 통신부를 포함할 수 있다. 커뮤니케 이션 모듈은 정보를 입력하는 입력부를 포함할 수 있다. 커뮤니케이션 모듈은 정보를 출력하는 출력부를 포함할 수 있다. 일 예로, 이동 로봇은 입력부로부터 직접 정보를 입력받을 수 있다. 다른 예로, 이동 로봇은 별 도의 단말기에 입력된 정보를 통신부를 통해 수신받을 수 있다. 일 예로, 이동 로봇은 출력부로 직접 정보를 출력시킬 수 있다. 다른 예로, 이동 로봇은 통신부 를 통해 별도의 단말기로 정보를 송신하여, 단말기가 정보를 출력하게 할 수 있다. 통신부는, 외부의 서버, 단말기 및/또는 충전대 등과 통신하게 구비될 수 있다. 통신부는 상기 복귀 신호를 수신하는 신호 감지부(미도시)를 포함할 수 있다. 충전대는 신호 송출부를 통해 적외선 신호를 송출하고, 상기 신호 감지부는 상기 적외선 신호를 감지하는 적외선 센서를 포함할 수 있다. 이동 로봇 은 충전대로부터 송출된 적외선 신호에 따라 충전대의 위치로 이동하여 충전대와 도킹 (docking)한다. 이러한 도킹에 의해 이동 로봇의 충전 단자와 충전대의 충전 단자 간에 충 전에 이루어진다. 통신부는, 스마트폰이나 컴퓨터 등의 단말기로부터 입력된 정보를 수신할 수 있다. 통신부는 단 말기로 출력될 정보를 송신할 수 있다. 단말기는 통신부로부터 받은 정보를 출력할 수 있다. 통신부는 단말기로부터 각종 명령 신호를 수신할 수 있다. 통신부는 단말기로부터 주행을 위한 구역 정보를 수신받을 수 있다. 통신부는 단말기로부터 찾고자하는 물건 정보를 입력받을 수 있 다. 통신부는 단말기는 주행 중 감지한 발견물의 정보를 송신할 수 있다. 통신부는 단말기(30 0)로 발견물의 식별 정보를 송신할 수 있다. 통신부는 단말기로 발견물의 위치 정보를 송신할 수 있 다. 입력부는 On/Off 또는 각종 명령을 입력받을 수 있다. 입력부는 상기 구역 정보를 입력받을 수 있다. 입력부는 상기 물건 정보를 입력받을 수 있다. 입력부는, 각종 버튼이나 터치패드, 또는 마이크 등을 포함할 수 있다. 출력부는 각종 정보를 사용자에게 알릴 수 있다. 출력부는 스피커 및/또는 디스플레이를 포함할 수 있다. 출력부는 주행 중 감지한 발견물의 정보를 출력할 수 있다. 출력부는 발견물의 식별 정보를 출 력할 수 있다. 출력부는 발견물의 위치 정보를 출력할 수 있다. 이동 로봇은 맵핑 및/또는 현재 위치를 인식하는 등 각종 정보를 처리하고 판단하는 제어부를 포함한 다. 제어부는 이동 로봇를 구성하는 각종 구성들의 제어를 통해, 이동 로봇의 동작 전반을 제어 할 수 있다. 제어부는, 상기 영상을 통해 주행 구역을 맵핑하고 현재 위치를 맵 상에서 인식 가능하게 구 비될 수 있다. 즉, 제어부는 슬램(SLAM : Simultaneous Localization and Mapping) 기능을 수행할 수 있 다. 제어부는 커뮤니케이션 모듈로부터 정보를 받아 처리할 수 있다. 제어부는 입력부로부터 정보를 입력 받아 처리할 수 있다. 제어부는 통신부로부터 정보를 받아 처리할 수 있다. 제어부(14 0)는 센싱부로부터 감지 정보를 입력 받아 처리할 수 있다. 감지 정보란 상기 주변 물체의 정보를 의미한 다. 제어부는 출력을 위해 커뮤니케이션 모듈로 정보를 줄 수 있다. 제어부는 통신부로 정보를 줄 수 있다. 제어부는 출력부의 출력을 제어할 수 있다. 제어부는 주행부의 구동을 제어할 수 있다. 제어부는 청소부의 동작을 제어할 수 있다. 이동 로봇은 각종 데이터를 저장하는 저장부를 포함한다. 저장부는 이동 로봇의 제어에 필 요한 각종 정보들을 기록하는 것으로, 휘발성 또는 비휘발성 기록 매체를 포함할 수 있다. 저장부에는 주행구역에 대한 맵이 저장될 수 있다. 상기 맵은 이동 로봇과 통신부을 통해 정보 를 교환할 수 있는 외부 단말기에 의해 입력된 것일 수도 있고, 이동 로봇이 스스로 학습을 하여 생성한 것일 수도 있다. 전자의 경우, 외부 단말기로는 맵 설정을 위한 어플리케이션(application)이 탑재된 리모 콘, PDA, 랩탑(laptop), 스마트 폰, 태블릿 등을 예로 들 수 있다. 현실의 주행구역은 맵 상의 주행구역과 대응될 수 있다. 상기 주행구역은 이동 로봇이 주행 경험이 있는 모든 평면상의 구역 및 현재 주행하고 있는 평면상의 구역을 모두 합한 범위로 정의될 수 있다. 제어부는 주행부의 동작을 바탕으로 이동 로봇의 이동 경로를 파악할 수도 있다. 예를 들어, 제 어부는 구동 바퀴의 회전속도를 바탕으로 이동 로봇의 현재 또는 과거의 이동속도, 주행한 거리 등을 파악할 수 있으며, 각 구동 바퀴(166(L), 166(R))의 회전 방향에 따라 현재 또는 과거의 방향 전환 과정 또한 파악할 수 있다. 이렇게 파악된 이동 로봇의 주행 정보를 바탕으로, 맵 상에서 이동 로봇의 위 치가 갱신될 수 있다. 또한, 상기 영상 정보를 이용하여, 맵 상에서 이동 로봇의 위치가 갱신될 수도 있다. 제어부는, 커뮤니케이션 모듈로부터 입력되거나 수신한 구역 정보에 의해 특정되는 구역을 이동 로봇 이 주행하게 제어할 수 있다. 제어부는 이동 로봇이 상기 특정되는 구역을 주행하며 물건을 탐 색하게 제어할 수 있다. 제어부는 커뮤니케이션 모듈로부터 입력되거나 수신한 물건 정보에 따른 물 건을 탐색하게 제어할 수 있다. 제어부는 감지한 발견물의 식별 정보 및 위치 정보를 커뮤니케이션 모듈 을 통해 출력하거나 단말기로 송신하게 제어할 수 있다. 이하, 도 6 내지 9를 참고하여, 본 발명의 실시예들에 따른 이동 로봇의 제어방법을 설명한다. 각 순서도 들에서 서로 중복되는 내용은 동일한 도면 부호로 표기하고, 중복되는 설명은 생략한다. 제어방법은 제어부에 의해 수행될 수 있다. 상기 제어방법의 적어도 일부는, 단말기의 제어부 등의 이동 로봇 외부의 별도의 제어장치에 의해 수행될 수도 있다. 본 발명은, 이동 로봇의 제어방법이 될 수 있고, 상기 제어방법을 수행하는 제어부를 포함하는 이동 로봇이 될 수도 있다. 본 발명은, 상기 제어방법의 각 단계를 포함하는 컴퓨터 프로그램이 될 수도 있고, 상기 제어방법을 컴퓨터로 구현하기 위한 프 로그램이 기록된 기록매체가 될 수도 있다. 상기 '기록매체'는 컴퓨터로 판독 가능한 기록매체를 의미한다. 본 발명은, 하드웨어와 소프트웨어를 모두 포함하는 이동 로봇 제어 시스템이 될 수도 있다. 제어방법의 순서도 도면들의 각 단계와 순서도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션(instruction)들 에 의해 수행될 수 있다. 상기 인스트럭션들은 범용 컴퓨터 또는 특수용 컴퓨터 등에 탑재될 수 있고, 상기 인 스트럭션들이 순서도 단계(들)에서 설명된 기능들을 수행하는 수단을 생성하게 된다. 또한, 몇 가지 실시예들에서는 단계들에서 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능하다. 예컨대, 잇달아 도시되어 있는 두 개의 단계들은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 단계들이 때 때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 도 6을 참고하여, 상기 제어방법은, 사용자가 이동 로봇에 정보를 입력하는 입력 단계(S100)를 포함한다. 상기 제어방법은, 입력 단계(S100)에서 입력 받은 정보를 근거로 하여 주행하는 주행 단계(S200)를 포함한다. 상기 제어방법은, 주행 단계(S200)에서 획득한 정보를 출력하는 출력 단계(S300)를 포함한다. 입력 단계(S100), 주행 단계(S200) 및 출력 단계(S300)는 순차적으로 진행될 수 있다. 제어부는 물건 정보를 입력받을 수 있다. 제어부는 구역 정보를 입력받을 수 있다. 제어부는 상 기 물건 정보 및 상기 구역 정보를 근거로 하여 이동 로봇의 주행을 제어할 수 있다. 제어부는 발견 물의 식별 정보를 출력하게 제어할 수 있다. 제어부는 발견물의 위치 정보를 출력하게 제어할 수 있다. 입력 단계(S100)에서 물건 정보를 입력받을 수 있다. 입력 단계(S100)에서, 찾고자 하는 물건을 특정하기 위해 물건 정보를 입력받을 수 있다. 일 예로, 상기 물건 정보는 저장된 DB(Data Base) 내에서 선택될 수 있다. 저장된 DB는 갱신될 수 있다. 통신부 나 입력부를 통해 수신 또는 입력 받은 정보를 이용하여, DB가 갱신될 수 있다. 다른 예로, 상기 물 건 정보는 유무선 네트워크를 통해 제공되는 DB 내에서 선택될 수도 있다. 또 다른 예로, 상기 물건 정보는 사 용자에 의해 직접 입력될 수도 있다. 상기 물건 정보는 물건의 종류 이름을 포함할 수 있다. 예를 들어, 물건의 종류 이름은, 열쇠, 열쇠고리 포함 열쇠, 자동차 열쇠, 리모콘, 자동차 리모콘, 자물쇠, 핸드폰, 무선전화기, 태블릿, 지폐(한화, 외화), 동전(한 화, 외화), 책자(수첩, 다이어리, 배달음식 메뉴판) 등이 있다. 상기 물건의 종류 이름은 사용자에 의해 직접 입력될 수 있다. 상기 물건의 종류 이름은 저장된 DB 내에서 선택 될 수 있다. 상기 물건의 종류 이름은 인터넷 상에서 선택될 수 있다. 상기 물건의 종류 이름은, 포괄 명칭 및 구체적 명칭 중 선택적으로 입력될 수 있다. 물건의 종류 이름은 상위 개념으로 입력될 수도 있고, 하위 개념으로 입력될 수도 있다. 예를 들어, 물건의 종류 이름은 '지폐'로 입력될 수도 있고, '달러 지폐' 나 '미국 지폐'로 입력될 수도 있다. 상기 물건의 종류 이름은, 조건없는 명칭 및 조건있는 명칭 중 선택적으로 입력될 수 있다. 예를 들어, 물건의 종류 이름은 조건없는 '열쇠'로 입력될 수도 있고, 조건있는 '열쇠고리 포함한 열쇠'로 입력될 수도 있다. 상기 물건 정보는 물건의 이미지를 포함할 수 있다. 물건의 이미지는 사진 또는 그림일 수 있다. 상기 이미지는 사용자에 의해 직접 촬영한 사진일 수 있다. 상기 이미지는 저장된 DB 내에서 선택될 수 있다. 상기 이미지는 인터넷 상에서 선택될 수 있다. 입력 단계(S100)에서, 선택되거나 촬영된 화면 상의 복수의 물건 이미지를 모두 입력받을 수 있다. 입력 단계 (S100)에서, 선택되거나 촬영된 화면 상의 복수의 물건 이미지 중 어느 한 물건 이미지가 선택되어 입력될 수 있다. (도 14참고) 상기 물건 정보는 물건의 부피 정보를 포함할 수 있다. 상기 부피 정보는 차지하는 면적 정보를 포함할 수 있다. 상기 부피 정보는 높이 정보를 포함할 수 있다. 상기 부피 정보는 가로 길이, 세로 길이 및 높이를 포함 할 수 있다. 입력 단계(S100)에서 구역 정보를 입력받을 수 있다. 입력 단계(S100)에서, 주행을 위한 구역 정보를 입력받을 수 있다. 일 예로, 상기 구역 정보는 저장된 DB 내에서 선택될 수 있다. DB내의 복수의 구역 중 어느 하나를 선택하여, 구역 정보를 입력 받을 수 있다. 복수의 구역에 대한 저장된 DB는 갱신될 수 있다. 이동 로봇 주행하며 얻 은 정보를 이용하여 맵이 갱신될 때, 복수의 구역에 대한 DB도 갱신될 수 있다. 또한, 상기 구역 정보는 저장된 주행 구역의 맵 상에서 사용자에 의해 일정 구역으로 선택될 수도 있다. 다른 예로, 상기 구역 정보는 사용자가 직접 입력한 특정의 구역에 대한 성질에 대한 정보일 수 있다. 주행 구역 중 일부 구역이 구분되게 구비될 수 있다. 맵 상의 주행 구역이 분할되어 복수의 일부 구역으로 구분 될 수도 있고, 맵 상의 주행 구역 중 일부가 별도로 특정되어 일부 구역으로 구분될 수도 있다. 이동 로봇이 주행 중 감지한 정보를 이용하여, 주행 구역 중 일부 구역을 구분할 수 있다. 예를 들어, 이 동 로봇이 감지한 이미지 또는 거리 정보 등을 이용하여, 주행 구역 중 일부 구역을 구분할 수 있다. 소정 구분 기준에 따라 주행 구역 중 일부 구역이 구분될 수 있다. 입력 단계(S100)에서 상기 구역 정보에 의해 상기 일부 구역이 특정될 수 있다. 일 예로, 상기 소정 구분 기준은, 주행 구역 중 각각의 실이 일부 구역으로 구분되게 구비될 수 있다. 다른 예 로, 상기 소정 구분 기준은, 주행 구역 중 외부의 상한면까지의 높이가 소정치 이하인 구역이 일부 구역으로 구 분되게 구비될 수 있다. 입력 단계(S100)에서 입력된 상기 구역 정보에 따라, 이동 상기 외부의 상한면이 상대적으로 낮은 가구(책상, 식탁, 의자, 침대 등)의 아래 구역이 선택될 수 있다. 상기 입력 단계에서 상기 구역 정보의 입력에 의해 가구 의 아래 구역이 특정 가능하게 구비될 수 있다.상기 구역 정보는, 외부의 상한면까지의 높이 정보를 포함할 수 있다. 상기 외부의 상한면은 이동 로봇이 상측으로 마주보는 외부의 면으로서, 실내의 천장면이나 가구의 하측면 등이 될 수 있다. 외부의 상한면까지의 높이는, 주행 구역의 바닥에서 외부의 상한면까지의 높이가 될 수도 있고, 이동 로봇에서 외부의 상한면까 지의 높이가 될 수도 있다. 예를 들어, 사용자가 외부의 상한면의 높이 정보로 특정 값을 입력하면, 주행 구역 중 외부의 상면의 높이가 상기 특정 값 이하인 일부 구역이 특정될 수 있다. 상기 구역 정보는, 특정 가구의 아래 구역 정보를 포함할 수 있다. 예를 들어, 사용자가 특정 가구의 아래 구역 을 선택하여, 일부 구역이 특정될 수 있다. 상기 구역 정보는 일부 구역의 이미지를 포함할 수 있다. 입력된 일부 구역의 이미지를 이용하여, 상기 일부 구 역의 이미지와 대응되는 일부 구역이 특정될 수 있다. 예를 들어, 사용자가 침대 아래 구역의 이미지를 입력하 여, 일부 구역으로서 침대 아래 구역이 특정될 수 있다. 주행 단계(S200)에서, 이동 로봇은 주행 구역 내에서 주행한다. 주행 단계(S200)에서, 이동 로봇은 상기 구역 정보에 의해 특정되는 구역을 주행할 수 있다. 주행 단계(S200)에서, 이동 로봇은 상기 구역 정 보에 따라 특정된 상기 일부 구역을 주행할 수 있다. 주행 단계(S200)에서, 이동 로봇은 물건을 탐색할 수 있다. 즉, 주행 단계(S200)에서 이동 로봇은 물 건을 탐색(감지)할 수 있다. 주행 단계(S200)에서, 이동 로봇은 상기 물건 정보에 따라 특정되는 물건을 탐색할 수 있다. 주행 단계(S200)에서, 상기 구역 정보에 의해 특정되는 일부 구역을 주행하며 물건을 탐색할 수 있다. 이동 로봇은 저장된 맵 상에서 특정된 일부 구역으로 이동하여, 특정된 일부 구역 내에서 주행하며 물건을 탐색할 수 있다. 제어부는, 감지된 물건과 상기 물건 정보에 따라 특정되는 물건을 비교하여, 유사도를 판 단할 수 있다. 감지된 물건이 상기 특정되는 물건에 해당된다고 판단되면, 제어부는 감지된 물건을 발견물 로 보게 된다. 주행 단계(S200)에서, 이동 로봇은 발견물의 정보를 저장한다. 주행 단계(S200)에서 복수의 발견물이 감지된 경우, 각각의 발견물에 대응하는 발견물의 정보가 저장된다. 주행 단계(S200)에서, 물건 정보에 따라 특정된 물건이 발견되면, 특정된 구역을 모두 주행하지 않더라도, 충전 대로 복귀하게 구현할 수도 있다. 출력 단계(S300)에서 저장된 발견물의 정보가 출력된다. 복수의 발견물이 감지된 경우, 출력 단계(S300)에서 각 각의 발견물에 대응하는 발견물의 정보가 출력될 수 있다. 이를 통해, 사용자는 이동 로봇이 주행 단계 (S200)를 거쳐 찾아낸 발견물을 확인할 수 있다. 상기 발견물의 정보는 발견물의 식별 정보를 포함할 수 있다. 발견물의 식별 정보는 발견물의 종류를 나타내는 이름을 포함할 수 있다. 출력 단계(S300)에서, 발견물의 식별 정보는 입력된 물건의 종류 이름과 매칭되게 출력될 수 있다. 예를 들어, 입력된 물건 정보에 매칭되는 발견물이 표시되도록 출력될 수 있다. 일 예로, 발견물의 식별 정보는 발견물의 이미지를 포함할 수 있다. 다른 예로, 발견물의 식별 정보는 발견물의 이미지를 제외한 다른 정보만 포함할 수 있다. 주행 단계(S200)에서 획득된 이미지를 이용하여 물건을 탐색하되, 출력 단계(S300)에서 발견물의 이미지를 제 외한 정보를 출력할 수 있다. 이를 통해, 사용자의 사생활(프라이버시)를 보호할 수 있으면서도, 이미지 획득을 통한 감지의 정확성 상승 효과를 얻을 수 있다. 발견물의 식별 정보는 발견물의 부피를 포함할 수 있다. 예를 들어, 발견물의 부피 정보는 가로 길이, 세로 길 이 및 높이를 포함할 수 있다. 상기 발견물의 정보는 발견물의 위치 정보를 포함할 수 있다. 상기 위치 정보는, 맵 상의 위치로 출력될 수 있 다. (도 15 및 도 16 참고) 예를 들어, 주행 구역의 맵과 맵 상의 발견물의 위치가 표시되어, 출력될 수 있다. 상기 발견물의 정보는 발견 시간 정보를 포함할 수 있다. 상기 발견 시간 정보는 해당 발견물의 발견 날짜 및/ 또는 시간을 포함할 수 있다. 출력 단계(S300)에서, 발견물의 식별 정보를 출력할 수 있다. 출력 단계(S300)에서, 발견물의 위치 정보를 출력 할 수 있다. 출력 단계(S300)에서, 발견물의 발견 시간 정보를 출력할 수 있다.이하, 도 7a 내지 도 8을 참고하여, 제 1 내지 4 실시예에 따른 제어방법을 설명하면 다음과 같다. 도 7a 내지 도 8에서, 입력 단계(S101, S102, S110), 주행 단계(S201, S202, S203, S211, S212) 및 출력 단계(S310)를 순 차적으로 도시한다. 도 7a를 참고하여, 제 1실시예에 따른 제어방법은, 상기 구역 정보를 입력 받는 과정(S101)을 포함한다. 상기 과정(S101) 후, 이동 로봇이 상기 구역 정보에 따라 특정된 구역을 주행하며, 물건을 탐색하는 과정(S20 1)이 진행된다. 상기 과정(S201)을 통한 발견물의 정보는 저장부에 저장된다. 상기 과정(S201) 후, 발견물 의 식별 정보 및 위치 정보를 출력하는 과정(S310)이 진행된다. 제 1실시예에서는, 입력 단계(S101)에서 물건 정보를 입력하지 않으며, 주행 단계(S201)에서 감지된 모든 물건을 발견물로 판단할 수 있다. 도 7b를 참고하여, 제 2실시예에 따른 제어방법은, 상기 물건 정보를 입력 받는 과정(S102)을 포함한다. 상기 과정(S102) 후, 이동 로봇이 주행하며, 상기 물건 정보에 따라 특정된 물건을 탐색하는 과정(S202)이 진행 된다. 상기 과정(S202)에서 이동 로봇은 주행 구역의 전체 내에서 주행할 수 있다. 또는, 상기 과정(S20 2)에서 이동 로봇이 상기 특정된 물건을 발견할 때까지, 주행 구역의 전체 내에서 주행할 수도 있다. 상기 과정(S202) 후, 발견물의 식별 정보 및 위치 정보를 출력하는 과정(S310)이 진행된다. 제 2실시예에서는, 입력 단계(S102)에서 구역 정보를 입력하지 않으며, 주행 단계(S202)에서 이동 로봇이 주행 구역 전체를 주행하 고, 특정된 물건만을 발견물로 판단할 수 있다. 도 7c를 참고하여, 제 3실시예에 따른 제어방법은, 상기 물건 정보 및 구역 정보를 입력 받는 과정(S110)을 포 함한다. 상기 과정(S110) 후, 이동 로봇이 상기 구역 정보에 따라 특정된 구역에서 주행하며, 상기 물건 정보에 따라 특정된 물건을 탐색하는 과정(S203)이 진행된다. 상기 과정(S203)에서 이동 로봇은 특정된 일 부 구역 내에서 주행할 수 있다. 또는, 상기 과정(S203)에서 이동 로봇이 상기 특정된 물건을 발견할 때까 지, 특정된 일부 구역 내에서 주행할 수도 있다. 상기 과정(S203) 후, 발견물의 식별 정보 및 위치 정보를 출력 하는 과정(S310)이 진행된다. 제 3실시예에서는, 입력 단계(S110)에서 구역 정보 및 물건 정보를 모두 입력하며, 주행 단계(S203)에서 이동 로봇이 특정된 구역을 주행하고, 특정된 물건만을 발견물로 판단할 수 있다. 도 8을 참고하여, 다른 실시예에 따른 제어방법은, 정보를 입력 받는 과정(S110)을 포함한다. 입력 받은 구역 정보를 근거로 하여, 주행 구역 중 일부 구역의 선택 여부를 판단하는 과정(S120)이 진행된다. 상기 과정(S12 0)에서 일부 구역이 선택된 것으로 판단되면, 선택된 일부 구역에서 이동 로봇이 주행하는 과정(S211)이 진행된다. 상기 과정(S120)에서 일부 구역이 선택되지 않은 것으로 판단되면, 주행 구역의 전체 구역에서 이동 로봇이 주행하는 과정(S212)이 진행된다. 상기 과정(S211, S212)에서, 입력 받은 물건 정보를 근거로 하여 특정된 물건을 탐색할 수 있다. 상기 과정(S211, S212) 후, 발견물의 식별 정보 및 위치 정보를 출력하는 과정 (S310)이 진행된다. 상기 과정(S211)은, 특정된 일부 구역에서만 물건 탐색 기능이 활성화되게 설정될 수 있다. 특정된 일부 구역에 서 바닥에 놓여진 물건을 감지한 경우, 이를 발견물 정보로 저장하게 설정될 수 있다. 이동 로봇이 특정된 일부 구역에서 바닥에 놓여진 물건을 감지한 경우, 사용자에게 출력 신호를 송신하게 설정될 수 있다. 이동 로 봇이 특정된 일부 구역이 아닌 구역에서 바닥에 놓여진 물건을 감지한 경우, 이를 발견물 정보로 저장하지 않게 설정될 수 있다. 이동 로봇이 특정된 일부 구역이 아닌 구역에서 바닥에 놓여진 물건을 감지한 경우, 사용자에게 출력 신호를 송신하지 않게 설정될 수 있다. 한편, 입력 단계(S100)에서, 저장된 물건 정보 들 중 하나를 선택하는 방식으로, 물건 정보를 입력할 수 있다. 입력 단계(S100)에서 사용자가 선택 가능한 새로운 물건 정보를 저장시킬 수 있다. 새롭게 저장된 물건 정보는 여러 물건 정보들 중 하나로 저장되며, 차후의 입력 단계(S100)에서 선택될 수 있다. 예를 들어, 사용자는 자신 의 소지한 열쇠에 대한 물건 정보를 신규로 저장시킨 후, 차후에 열쇠를 잃어버린 상황 발생시 기저장된 열쇠에 대한 물건 정보를 선택하는 방식으로 물건 정보를 입력할 수 있다. 입력 단계(S100)에서 '물건 정보를 입력받는다'는 것은, ⅰDB 내에서 물건 정보가 선택되는 것, 및 ⅱDB 내에 없는 신규의 물건 정보를 입력 받는 것을 포괄하는 의미이다. 입력 단계(S100)에서 사용자가 직접 사진을 촬영 /업로드하거나 물건의 종류 이름을 타이핑하는 등을 통해, '물건 정보를 신규로 입력받을 수 있다. 도 9를 참고하여, 또 다른 실시예에 따른 입력 단계(S100)를 설명하면 다음과 같다. 입력 단계(S100)에서, 상기 물건 정보를 신규로 입력 받는 과정(S151)이 진행될 수 있다. 상기 과정(S151)에서 입력된 신규의 물건 정보와 기저장된 물건 정보의 매칭 여부를 판단하는 과정(S153)이 진 행된다. 상기 과정(S153)에서, 신규로 입력된 물건 정보와 기저장된 물건 정보를 비교한다. 상기 과정(S153)에 서, 상기 신규의 물건 정보는 기저장된 복수의 물건 정보와 각각 비교할 수 있다. 상기 과정(S153)에서, 상기 신규의 물건 정보와 어느 한 기저장 물건 정보가 소정의 유사도 이상이 되면, 매칭되는 것으로 판단할 수 있다. 상기 과정(S153)에서 신규로 입력된 물건 정보와 기저장된 물건 정보가 매칭되면, 사용자에게 기저장된 물건 정 보를 제시하는 과정(S154)이 진행될 수 있다. 상기 과정(S154)에서 매칭되는 기저장 물건 정보가 사용자에게 디 스플레이 등으로 출력될 수 있다. 이를 통해, 사용자는 신규로 입력한 물건 정보가 이미 기저장되어 있는지 여 부를 확인할 수 있다. 상기 과정(S153)에서 신규로 입력된 물건 정보와 기저장된 물건 정보가 매칭되면, 신규로 입력된 물건 정보 및 기저장된 물건 정보 중 어느 하나를 선택하도록 제시하는 과정(S155)이 진행될 수 있다. 상기 과정(S155)에서, 사용자의 의사에 따라 신규로 입력된 물건 정보 및 기저장 물건 정보 중 어느 하나가 선택될 수 있다. 상기 과 정(S155)은, 기저장 물건 정보의 선택 여부를 판단하는 과정일 수 있다. 이를 통해, 사용자가 기저장 물건 정보 를 활용하여 물건 정보를 입력할 수 있도록 편의성을 제공하되, 사용자가 유사한 다른 물건 정보를 신규로 입력 하려 할 때, 제어부가 신규의 물건 정보를 기저장 물건 정보로 오인하는 오류의 발생을 막을 수 있다. 본 실시예에서, 상기 과정(S154)이후 상기 과정(S155)가 진행된다. 구체적으로, 상기 과정(S153)에서 신규로 입 력된 물건 정보와 기저장된 물건 정보가 매칭되면, 사용자에게 기저장된 물건 정보를 제시하고, 신규로 입력된 물건 정보 및 기저장 물건 정보 중 어느 하나가 선택되는 과정(S155)이 진행된다. 상기 과정(S153)에서, 신규로 입력된 물건 정보와 기저장된 물건 정보가 매칭되지 않는 것으로 판단되면, 신규 로 입력된 물건 정보가 저장되는 과정(S158)이 진행된다. 신규로 입력된 물건 정보는 저장부에 저장되고, 차후에 또 다른 신규로 입력된 물건 정보와 비교될 수 있다. 이 경우, 주행 단계(S200)에서는 신규로 입력된 물 건 정보에 따라 특정된 물건을 탐색한다. 상기 과정(S155)에서 기저장 물건 정보가 선택되지 않으면, 신규로 입력된 물건 정보가 저장되는 과정(S158)이 진행된다. 상기 과정(S155)에서 신규로 입력된 물건 정보가 선택되면, 신규로 입력된 물건 정보가 저장되는 과 정(S158)이 진행된다. 상기 과정(S158)에 대한 설명은 상술한 바와 같다. 상기 과정(S155)에서 신규로 입력된 물건 정보가 선택되지 않으면, 신규로 입력된 물건 정보를 저장하지 않는다. (S159) 상기 과정(S155)에서 기저장 물건 정보가 선택되면, 신규로 입력된 물건 정보를 저장하지 않는 다. (S159) 이 경우, 신규로 입력된 물건 정보의 저장 없이 다음 단계가 진행될 수 있다. 이 경우, 주행 단계 (S200)에서는 선택된 기저장 물건 정보에 따라 특정된 물건을 탐색한다. 한편, 맵 상의 기설정된 복수의 구역이 구분되고, 입력 단계(S100)에서 복수의 구역 중 어느 하나를 선택하는 방식으로 구역 정보를 입력할 수도 있다. 또한, 사용자의 지정에 따라 복수의 구역의 구분이 변경되게 구현될 수도 있다. 이하, 도 10 내지 도 16을 참고하여, 상기 제어방법이 구현되기 위한 사용자 환경(인터페이스)의 예시를 설명하 면 다음과 같다. 도 10 내지 도 16은 디스플레이 화면의 예시를 나타내는 도면으로서, 단말기의 디스플레 이를 예로 들었으나 이에 반드시 제한될 필요는 없다. 또한, 도 10 내지 도 16의 화면상에 나오는 표시 부분 및 입력 부분을 선택하기 위하여, 본 실시예에서는 화면을 터치하는 방식을 예로 들었으나, 이에 제한될 필요는 없 다. 본 실시예에서, 별도의 단말기에 입력된 정보를 통신부를 통해 수신받으며, 도 10 내지 도 14의 화면 은 단말기의 터치 스크린의 화면이다. 그러나, 다른 예로서, 이동 로봇의 본체 상에 터치 스크 린이나 기타의 버튼 등의 입력부로부터 정보를 입력받을 수도 있으며, 도 10 내지 도 14의 화면이 본체 상의 터치 스크린에 구현될 수도 있다. 본 실시예에서, 통신부를 통해 별도의 단말기로 정보를 송신하며, 도 15 및 도 16의 화면은 단말기 의 출력 화면이다. 그러나, 다른 예로서, 이동 로봇은 디스플레이 등의 출력부로 직접 정보를 출력시킬 수 있으며, 도 15 및 도 16의 화면이 본체 상의 스크린에 구현될 수도 있다. 도 10을 참고하여, 입력 단계(S100)에서 물건 정보 및 구역 정보를 입력하는 메인 화면이 출력될 수 있다. 상기 물건 탐색 기능의 활성 여부 입력부(D100)가 구비될 수 있다. 사용자는 활성 여부 입력부(D100)를 터치 등의 방식으로 선택하여, 상기 물건 탐색 기능(분실물 찾기 기능)을 On/Off 할 수 있다. 도 10에는 상기 물건 탐색 기 능이 On된 상태를 보여준다. 도 10을 참고하여, 입력 단계(S100)에서 탐색하는 물건 표시부(D110) 및 주행하려는 구역 표시부(D120)가 서로 매칭되어 출력될 수 있다. 물건 표시부(D100)에 표시된 물건은 찾을 분실물일 수 있다. 구역 표시부(D120)에 표 시된 구역은, 해당되는 물건을 찾을 장소를 의미한다. 도 10을 참고하여, 물건 표시부(D110)와 구역 표시부(D120)는 매칭되어, 하나의 세트로 표시될 수 있다. 복수의 상기 세트가 구비될 수 있다. 복수의 상기 세트는 서로 다를 수 있다. 세트 선택부(D130)가 구비되어, 복수의 상기 세트 중 사용자가 상기 물건 탐색 기능을 활성시키려는 세트만 선택될 수 있다. 세트 선택부(D130)를 터치 하여 해당 세트에 따른 주행을 활성시키거나 비활성 시킬 수 있다. 세트 선택부(D130)에 의해 어느 한 특정 세 트에 따른 주행이 활성되면, 이동 로봇은 상기 특정 세트의 구역 정보에 따른 구역을 주행하며, 상기 특정 세트의 물건 정보에 따른 물건을 탐색한다. 도 10에서는, 자동차 키를 등록된 장소(일부 구역)에서만 탐색하는 기능, 및 화폐를 모든 장소(주행 구역 전체)에서 탐색하는 기능이 활성된 것을 보여주고, 리모콘을 탐색하는 기 능이 비활성된 것을 보여준다. 입력 단계(S100)에서 복수의 물건 정보를 입력받을 수 있다. 도 10을 참고하여, 복수의 물건(자동차 키 및 화폐)에 대한 물건 정보가 물건 표시부(D110) 및 세트 선택부(D130)에 의해 입력될 수 있다. 복수의 물건 정보를 입력 받을 때, 입력 단계(S100)에서 각각의 물건 정보마다 매칭되는 구역 정보를 입력받을 수 있다. 도 10을 참고하여, 복수의 물건(자동차 키 및 화폐)에 매칭되는 구역 정보(등록된 장소만, 모든 장 소)가 구역 표시부(D120) 및 세트 선택부(D130)에 의해 입력될 수 있다. 입력 단계(S100)에서 복수의 물건 정보 및 각각의 물건 정보마다 매칭되는 구역 정보를 입력 받은 경우, 주행 단계(S200)에서 현재 위치가 속한 구역에 따라 탐색하는 물건이 달라진다. 예를 들어, 도 10에 따른 입력 단계 (S100) 이후 주행 단계(S200)에서, 특정된 일부 구역(등록된 장소)을 주행하는 중에는 자동차 키 및 화폐를 탐 색하고, 특정된 일부 구역이 아닌 구역을 주행하는 중에는 화폐만을 탐색할 수 있다. 도 10을 참고하여, 각각의 세트별 물건 표시부(D110)를 터치 등을 통해 선택하여, 물건 정보를 변경할 수 있다. 각각의 세트별 구역 표시부(D120)를 터치 등을 통해 선택하여, 구역 정보를 변경할 수 있다. 도 10을 참고하여, 물건 추가부(D150)를 터치 등을 통해 선택하여, 선택 가능한 물건 정보를 추가로 생성시킬 수 있다. 물건 추가부(D150)를 선택하여, 신규의 상기 세트를 생성시킬 수 있다. 또한, 구역 추가부(D160)를 터 치 등을 통해 선택하여, 선택 가능한 구역 정보를 추가로 생성시킬 수 있다. 도 11a 및 도 11b는 구체적인 구역 정보를 입력하는 화면이 도시된 도면으로서, 도 11a는 주행 구역 전체를 선 택한 상태의 화면이고, 도 11b는 주행 구역 중 일부 구역을 선택한 상태의 화면이다. 도 11a 및 도 11b는 도 10 의 화면에서 구역 표시부(D120)을 선택한 경우, 나타나는 화면일 수 있다. 도 11a를 참고하여, 전체 구역 활성부(D161)가 터치 등을 통해 선택되어 활성되면, 해당 세트의 물건은 주행 구 역 전체에서 탐색된다. 도 11b를 참고하여, 전체 구역 활성부(D161)가 터치 등을 통해 선택되어 비활성되면, 해당 세트의 물건 입력된 일부 구역에서 탐색된다. 구역 정보 식별부(D163)에 해당 구역을 나타내는 명칭이나 특징 등이 표시될 수 있다. 복수의 구역 정보 식별부(D163)가 구비될 수 있고, 각각의 구역 정보 식별부(D163)에 대응하는 구역 정보 활성 부(D164)가 구비될 수 있다. 구역 정보 활성부(D164)를 통해, 활성되는 구역의 범위를 변경시킬 수 있다. 구역 정보 활성부(D164)에 의해 선택된 구역 정보 식별부(D163)에 대응되는 구역 정보만 입력받게 되고, 해당 세트의 물건은 상기 입력된 구역 정보에 의해 특정된 일부 구역에서만 탐색된다. 또한, 구역 추가부(D162)를 터치 등을 통해 선택하여, 선택 가능한 구역 정보 식별부(D163)를 추가로 생성시킬 수 있다. 도 11a 및 도 11b를 참고하여, 확인부(D168)의 선택을 통해, 해당 세트의 현재 상태를 최종 설정할 수 있다. 취 소부(D168)의 선택을 통해, 도 11a 및 도 11b의 화면에서의 설정 변경을 취소할 수 있다. 도 12는 일부 구역의 구체적인 정보를 입력 받는 화면이 도시된 도면이다. 도 11b의 화면에서, 구역 추가부 (D162) 또는 구역 정보 식별부(D163)를 선택하면 도 12의 화면이 출력되게 구비될 수 있다. 도 12의 화면에는, 구역의 명칭이 표시되는 부분(D167a)이 구비된다. 구역 정보를 이미지(사진)로 입력하기 위한 구역 이미지 입력 부(D165)를 선택하면, 사진을 직접 촬영하기 위한 입력부(D165a) 및 기저장된 사진 중 어느 하나를 선택하기 위 한 입력부(D165b)가 구비된다. 구역 정보를 인터넷 상의 정보에서 검색하기 위한 검색 입력부(D166)를 선택하는것도 가능하다. 도 12의 화면에는, 입력된 사진이 표시되는 부분(D167b)이 구비될 수 있다. 도 12의 화면에는, 상기 외부의 상한면까지의 높이 정보를 입력하기 위한 높이 입력부(D167c)가 구비될 수 있다. 확인부(D167d)의 선택을 통해, 변경된 구역 정보로 최종 설정할 수 있다. 취소부(D167e)의 선택을 통해, 도 12의 화면에서의 설 정 변경을 취소할 수 있다. 도 13a 및 도 13b는 구체적인 물건 정보를 입력하는 화면이 도시된 도면으로서, 도 13a는 사진(이미지) 촬영 또 는 사진 선택을 위한 화면이고, 도 13b는 인터넷 검색을 위한 화면이다. 도 10의 화면에서, 물건 표시부(D110)를 선택하면 도 13a 또는 도 13b의 화면이 출력되게 구비될 수 있다. 도 13a 및 도 13b의 화면에는, 물건의 명칭이 표시되는 부분(D111a)이 구비된다. 물건 정보를 이미지(사진)로 입력 하기 위한 물건 이미지 입력부(D112)를 선택하면, 사진을 직접 촬영하기 위한 입력부(D112a) 및 기저장된 사진 중 어느 하나를 선택하기 위한 입력부(D112b)가 구비된다. 구역 정보를 인터넷 상의 정보에서 검색하기 위한 검 색 입력부(D113)를 선택하는 것도 가능하다. 검색 입력부(D113)을 터치 등으로 선택하면, 도 13b의 화면이 출력 된다. 도 13b의 화면에서 검색부(D113a)을 통해 물건 정보를 인터넷 상에서 검색할 수 있다. 도 13a 및 도 13b 의 화면에는, 입력된 사진이 표시되는 부분(D111b)이 구비될 수 있다. 도 13a 및 도 13b의 화면에는, 물건의 부 피 정보를 입력하기 위한 부피 입력부(D111c)가 구비될 수 있다. 확인부(D111d)의 선택을 통해, 변경된 물건 정 보로 최종 설정할 수 있다. 취소부(D111e)의 선택을 통해, 도 13a 및 도 13b의 화면에서의 설정 변경을 취소할 수 있다. 도 14는 입력된 이미지 내의 복수의 물건 중 일부를 선택하는 과정을 보여주는 화면이다. 도 13a의 화면에서 입 력부(D112a) 또는 입력부(D112b)를 선택하여 직접 사진을 촬영하거나 사진을 선택하면, 해당 사진(이미지)이 도 14의 화면에 구비될 수 있다. 도 13b의 화면에서 검색부(D113a)를 선택하여 사진을 검색하면, 해당 사진(이미지)이 도 14의 화면에 구비될 수 있다. 도 14의 화면에 표시된 사진 내에 복수의 물건이 있는 경우, 복수의 물건 중 일부를 선택 가능하게 구비될 수 있다. 도 14를 참고하여, 이미지의 일부를 구획함으로써 복수 의 물건 중 어느 한 물건이 선택될 수 있다. 도 15는 발견물의 식별 정보 및 위치 정보를 출력하는 메인 화면이 도시된 도면이다. 상기 물건 탐색 기능이 활 성된 상태에서 주행 단계(S200)를 마치면, 출력 단계(S300)에 따른 도 15 또는 도 16의 화면이 출력될 수 있다. 도 15 및 도 16의 화면에는, 주행 단계(S200)가 종료되었음을 알리는 주행 종료 알림부(D301)가 구비된다. 주행"}
{"patent_id": "10-2017-0122783", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "종료 알림부(D301)는 메시지 형식으로 표시될 수 있다. 도 15 및 도 16의 화면에는, 발견물의 정보를 요약해서"}
{"patent_id": "10-2017-0122783", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "알려주는 요약 정보 표시부(D302)가 구비될 수 있다. 예를 들어, 요약 정보 표시부(D302)에는 발견물의 개수 및 /또는 발견물의 위치의 개수가 표시될 수 있다. 닫기부(D380)을 선택하여, 도 15 및 도 16의 화면의 출력을 종료시킬 수 있다. 설정부(D390)을 선택하여, 도 15 및 도 16의 화면의 출력을 종료시키면서, 도 10의 화면이 출력되게 할 수 있다. 도 15를 참고하여, 위치 정보 선택부(D310)를 선택하여, 맵 및 맵 상의 발견물 위치 표시가 출력되게 할 수 있 다. 위치 정보 선택부(D310)를 선택하면, 맵 및 맵 상의 위치 표시가 보여지는 위치 표시창(D311)이 출력된다. 도 16을 참고하여, 식별 정보 선택부(D320)를 선택하여, 발견물의 식별 정보가 출력되게 할 수 있다. 식별 정보 선택부(D320)를 선택하면, 식별 정보 표시부(D323)가 출력된다. 식별 정보 표시부(D323)에는 발견물의 종류 명 칭이 표시될 수 있다. 식별 정보 표시부(D323)에는, 입력 단계(S100)에서 입력 받은 물건의 종류 명칭 중 발견 물에 대응하는 종류 명칭이 표시될 수 있다. 또한, 식별 정보 표시부(D323)와 대응되는 발견물의 위치 정보가 표시되는 위치 정보 표시부(D322)가 출력될 수 있다. 식별 정보 표시부(D323)와 위치 정보 표시부(D322)는 쌍을 이루며 출력된다. 또한, 식별 정보 표시부(D323)와 대응되는 위치 표시 활성부(D321)가 구비될 수 있다. 복수의 발견물 리스트 중, 위치 표시 활성부(D321)를 통해 활성된 발견물에 대해서만, 맵 상에서 위치 표시되게 구비될 수 있다. 또한, 식별 정보 표시부(D323)와 대응되는 위치 확인부(D324)가 구비될 수 있다. 복수의 발견물이 감 지된 경우, 복수의 발견물 중 특정 발견물에 대응하는 위치 확인부(D324)를 선택하면, 맵 상에 상기 특정 발견 물의 위치가 강조되어 표시된다. 예를 들어, 발견물인 동전의 위치 확인을 위해 해당하는 위치 확인부(D324)를 터치하면, 위치 표시창(D311)에 맵 및 동전의 위치(D311a)가 표시될 수 있다."}
{"patent_id": "10-2017-0122783", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 이동 로봇 및 이동 로봇을 충전시키는 충전대를 도시한 사시도이 다. 도 2는 도 1의 이동 로봇을 상측에서 바라본 입면도이다. 도 3은 도 1의 이동 로봇을 정면에서 바라본 입면도이다. 도 4는 도 1의 이동 로봇을 하측에서 바라본 입면도이다. 도 5는 도 1의 이동 로봇의 주요 구성들 간의 제어관계를 도시한 블록도이다. 도 6은 본 발명의 일 실시예에 따른 이동 로봇의 제어방법을 도시한 순서도이다. 도 7a는 본 발명의 제 1실시예에 따른 이동 로봇의 제어방법을 도시한 순서도이고, 도 7b는 본 발명의 제 2실시 예에 따른 이동 로봇의 제어방법을 도시한 순서도이고, 도 7c는 본 발명의 제 3실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이다. 도 8은 본 발명의 다른 실시예에 따른 이동 로봇의 제어방법을 도시한 순서도이다. 도 9는 본 발명의 또 다른 실시예에 따른 입력 단계(S100)를 도시한 순서도 이다. 도 10 내지 도 16은, 본 발명의 제어방법의 일 실시예에 따른 사용자 환경을 나타낸 도면들이다. 도 10 내지 도 14는 입력 단계(S100)에서 사용자의 입력을 위한 사용자 환경을 보여주고, 도 15 및 도 16은 출력 단계(S300)에 서 사용자에게 출력하기 위한 사용자 환경을 보여준다. 도 10은 물건 정보 및 구역 정보를 입력하는 메인 화면이 도시된 도면이다. 도 11a 및 도 11b는 구체적인 구역 정보를 입력하는 화면이 도시된 도면으로서, 도 11a는 주행 구역 전체를 선 택한 상태의 화면이고, 도 11b는 주행 구역 중 일부 구역을 선택한 상태의 화면이다. 도 12는 일부 구역의 구체적인 정보를 입력 받는 화면이 도시된 도면이다. 도 13a 및 도 13b는 구체적인 물건 정보를 입력하는 화면이 도시된 도면으로서, 도 13a는 사진(이미지) 촬영 또 는 사진 선택을 위한 화면이고, 도 13b는 인터넷 검색을 위한 화면이다. 도 14는 입력된 이미지 내의 복수의 물건 중 일부를 선택하는 과정을 보여주는 화면이다. 도 15 및 도 16은, 발견물의 식별 정보 및 위치 정보를 출력하는 화면이 도시된 도면이다."}
