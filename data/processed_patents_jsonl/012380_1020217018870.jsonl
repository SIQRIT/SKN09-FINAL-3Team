{"patent_id": "10-2021-7018870", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0106444", "출원번호": "10-2021-7018870", "발명의 명칭": "개별 사용자에 대한 개인화된 식이 및 건강 권고 또는 추천을 생성하기 위한 자동화된 방법", "출원인": "메드트로닉 미니메드 인코포레이티드", "발명자": "하다드 야론"}}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하드웨어 기반 프로세싱 시스템을 통해 개인화된 식이 및 건강 권고 또는 추천을 생성하기 위한 서버리스 아키텍처를 사용하여 구현되는 컴퓨터 구현 데이터 수집 및 처리 방법으로서, 상기 방법은,저장 모듈 내의 복수의 상이한 소스들로부터 데이터를 수집 및 집계하는 단계 - 상기 데이터는 상이한 타입이나유형의 데이터를 포함함 -;상기 상이한 타입이나 유형의 데이터를 상기 건강 및 영양 플랫폼과 호환가능한 표준화된 구조화된 형식으로 변환함으로써, 상기 데이터의 소스의 불가지론적인 방식으로 상기 상이한 타입이나 유형의 데이터 각각을 연속적으로 처리하는 단계;상기 건강 및 영양 플랫폼으로부터의 정보를 부분적으로 이용하여, 표준화된 구조화된 형식으로 변환된 데이터를 분석하는 단계; 및복수의 개별 사용자들 각각에 대한 개인화된 식이 및 건강 권고 또는 추천을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 상이한 타입이나 유형의 데이터는 구조화된 데이터 및 비구조화된 데이터를 포함하는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 데이터는 복수의 개별 사용자들에 특이적인 음식, 건강 또는 영양 데이터를 포함하는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 표준화된 구조화된 데이터는,하나 이상의 인공 신경망들;하나 이상의 회귀 모델들;하나 이상의 결정 트리 모델들;하나 이상의 서포트 벡터 머신들;하나 이상의 베이지안 네트워크들;하나 이상의 확률적 머신러닝 모델들;하나 이상의 가우시안 프로세싱 모델들;하나 이상의 히든 마코프 모델들; 및하나 이상의 딥러닝 네트워크들을 포함하는 하나 이상의 머신러닝 모델들을 사용하여 분석되는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 데이터는 복수의 애플리케이션 프로그래밍 인터페이스(API)들을 통해 상기 복수의 상이한소스들로부터 수집 및 집계되는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 하나 이상의 상이한 엔티티들과 연관된 토큰 모듈을 통해 상기 복수의 API들과 통신하는 단계를 더 포함하고, 상기 복수의 API들로부터의 데이터는 검색 모듈을 사용하여 수집 및 집계되며, 상기 검색 모듈공개특허 10-2021-0106444-3-은 상기 토큰 모듈로부터 분리되고 독립적인, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 토큰 모듈은 기존의 토큰들을 리프레시하고 토큰 변경들에 관한 알림 업데이트들을 제공하도록 구성되며, 새로운 토큰이 생성될 때마다, 상기 새로운 토큰은 상기 토큰 모듈에 저장되는 것에 더하여,상기 검색 모듈에서 개별적으로 복제되는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 저장 모듈은, 중복 데이터를 검증, 검사 및 제거하고, 선택된 유형의 데이터를 통합함으로써 상기 데이터를 감소시키며, 상기 데이터를 배치에 유지시키도록 구성되는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 데이터를 수집 및 집계하는 단계는 상기 데이터를 복수의 스트림들에 저장하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 데이터를 처리하는 단계는, 상이한 조건들이 발생할 때, 상기 복수의 스트림들 내에 저장된 상기 데이터에 대해 람다 함수들을 실행하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 람다 함수들은 상기 데이터가 상기 복수의 스트림들에 수집 및 저장되는 경우에만 실행되고, 상기 저장된 데이터에 대한 상기 람다 함수들의 실행은 상기 복수의 스트림들 중 관련 스트림으로 데이터의 각 행을 채널링 및 전송하도록 구성되는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 데이터는 상기 복수의 스트림들 중 하나의 스트림으로부터 다른 스트림으로 캐스케이딩(cascading)함으로써 데이터 파이프라인을 따라 전진되는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서, 상기 복수의 스트림들 각각은 상기 데이터가 각각의 스트림에 저장되는 시간 프레임을 정의하는 보존 정책을 갖는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 복수의 스트림들은 복수의 샤드들을 포함하고, 각각의 샤드는 (1) 큐에 진입하고, (2)상기 보존 정책의 만료시 상기 큐를 빠져나가는 데이터 레코드들의 문자열을 포함하며, 상기 데이터 레코드들의문자열은 복수의 개별 사용자들에게 특이적인 음식 소비, 건강 또는 영양 기록을 포함하는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 복수의 스트림들 내의 샤드들의 수를 제어함으로써, 상기 데이터가 처리되고 있는 속도를 제어하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항에 있어서, 상기 복수의 상이한 소스들로부터 데이터를 수집 및 집계하는 단계는, (1) 작업 스케줄러를 사용하여 미리 결정된 시간 간격들에서 데이터가 인출되게 하는 소스들의 제1 세트로부터 데이터를 인출하는단계, 및 (2) 복수의 인출 요청들 및 푸시 요청들로부터의 데이터가 중앙집중형 위치에 스트리밍되도록, 소스들의 제2 세트로부터 푸시되는 데이터를 수신하는 단계 - 상기 소스들의 제2 세트로부터의 데이터의 푸시는 상기데이터와 연관된 하나 이상의 알림들에 의해 선행됨 -, 및 (3) 상기 데이터가 대응하는 알림과 함께 도달하지않는 경우에 상기 대응하는 알림과 연관된 데이터를 인출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2021-0106444-4-제1항에 있어서, 상기 저장된 데이터의 일 부분은 하나 이상의 이미징 장치들을 사용하여 캡처된 복수의 이미지들을 포함하고, 선택된 람다 함수는 상기 저장된 데이터의 일부에 대해 실행되어, 상기 복수의 이미지들 중 임의의 이미지가 그들의 영양 성분에 대해 분석될 하나 이상의 음식 이미지들을 포함하는지 여부를 검출하는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 하나 이상의 음식물 이미지들은 타임스탬프들 및 위치정보들과 연관되어 사용자의 음식섭취의 시간적 및 공간적 추적을 가능하게 하고, 상기 사용자의 음식 섭취의 시간적 및 공간적 추적은 식사 시간 또는 식사의 내용을 예측하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "하드웨어 기반 프로세싱 시스템을 통해 개인화된 식이 및 건강 권고 또는 추천을 생성하기 위한 서버리스 아키텍처를 사용하여 구현되는 데이터 수집 및 처리 시스템으로서, 상기 시스템은 적어도 하나의 하드웨어 기반 프로세서 및 메모리를 포함하고, 상기 메모리는 비일시적 프로세서 판독가능 매체 상에 인코딩되는 프로세서 실행가능 명령들을 포함하며, 상기 프로세서 실행가능 명령들은 상기 프로세서에 의해 실행되는 경우,저장 모듈 내의 복수의 상이한 소스들로부터 데이터를 수집 및 집계하게 하고 - 상기 데이터는 상이한 타입이나유형의 데이터를 포함함 -;상기 상이한 타입이나 유형의 데이터를 건강 및 영양 플랫폼과 호환되는 표준화된 구조화된 형식으로 변환함으로써, 소스의 불가지론적인 방식으로 상기 상이한 타입이나 유형의 데이터 각각을 연속적으로 처리하게 하며;상기 건강 및 영양 플랫폼으로부터의 정보를 부분적으로 이용하여, 상기 표준화된 구조화된 형식으로 변환된 데이터를 분석하게 하고;복수의 개별 사용자들 각각에 대한 개인화된 식이 및 건강 권고 또는 추천을 생성하게 하도록 구성되는,시스템."}
{"patent_id": "10-2021-7018870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "개인화된 식이 및 건강 권고 또는 추천을 생성하기 위한 서버리스 데이터 수집 및 처리 시스템으로서, 상기 시스템은,하드웨어 기반 처리 시스템에 의해 실행되는 경우, 저장 모듈 내의 복수의 상이한 소스들로부터 데이터를 수집및 집계하도록 구성될 수 있는 검색 모듈 - 상기 데이터는 상이한 타입 또는 형태의 데이터를 포함함 -; 및상기 하드웨어 기반 처리 시스템에 의해 실행되는 경우, 상기 상이한 타입이나 유형의 데이터를 건강 및 영양플랫폼과 호환되는 표준화된 구조화된 형식으로 변환함으로써, 소스의 불가지론적인 방식으로 상기 상이한 타입이나 유형의 데이터 각각을 연속적으로 처리하게 하도록 구성될 수 있는 표준화 모듈; 및상기 하드웨어 기반 처리 시스템에 의해 실행되는 경우, 상기 건강 및 영양 플랫폼으로부터의 정보를 부분적으로 이용하여, 상기 표준화된 구조화된 형식으로 변환된 데이터를 분석하게 하고, 복수의 개별 사용자들 각각에대한 개인화된 식이 및 건강 권고 또는 추천을 생성하게 하도록 구성될 수 있는 하나 이상의 머신러닝 모델들을갖는 플랫폼을 포함하는, 시스템."}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 소스로부터의 영양 및 건강 데이터를 분석에 적합한 구조화된 파일 포맷으로 표준화하기 위해 자율적인 기능을 갖는 서버리스 아키텍처(serverless architecture)를 이용할 수 있는 방법, 시스템 및 플랫폼이 제공된다. 플랫폼은 인증 컴포넌트, 데이터 검색 컴포넌트, 파이프라인 컴포넌트, 표준화 컴포넌트, 및 저장 컴 포넌트를 포함할 수 있다. 컴포넌트들은 자율적인 기능들의 세트들, 스트리밍 애플리케이션들, 알림 메시지들, 및 서로 논리적으로 연결되는 다른 객체들을 포함할 수 있다. 컴포넌트들은 직렬로 연결될 수 있고, 데이터는 스 트림에서 순차적으로 컴포넌트들을 통해 흐를 수 있다. 개시된 아키텍처를 사용하여, 플랫폼은 효율적이고 비용 효율적인 방식으로 대량의 데이터를 집계 및 처리하고, 표준화된 구조화된 데이터를 분석하며, 개별적인 최종 사 용자에게 개인화된 식이 및 건강 권고 또는 추천을 생성할 수 있다."}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원의 교차 참조 본 출원은 미국 특허 임시출원 제62/782,275호(2018년 12월 19일 출원), 및 미국 특허출원 제16/709,721호 (2019년 12월 10일 출원)에 대한 우선권을 주장하며, 이들의 내용은 전체로서 본원에 참조로 포함된다."}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "기술분야 본원에 기재된 청구대상의 실시예들은 일반적으로, 개인화된 식이 및 건강 권고 또는 추천, 및 이를 자동으로 생성하기 위한 기술을 제공하는 것에 관한 것이다. 보다 구체적으로, 본 청구대상의 실시예들은 개별 사용자들에 대한 개인화된 식이 및 건강 권고 또는 추천을 생성하기 위해 데이터를 자동으로 수집하고 처리하는 서버리 스(serverless) 아키텍처에 관한 것이다."}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 몇 년 동안, 건강 관련 데이터를 고객에게 제공하기 위해 많은 장치들 및 소프트웨어 애플리케이션들이 개 발되었다. 이러한 장치들 및 소프트웨어 애플리케이션들은 활동을 모니터링할 수 있고, 사람들로 하여금 그들의 음식 소비 및 운동 습관을 모니터링하고, 수면 패턴을 모니터링하며, 사용자들로부터의 건강 정보를 수동적으로 수집할 수 있게 한다. 그러나, 현재 모든 데이터를 표준화하고 일괄 처리하기 위한 업계 표준은 없다. 특히, 데 이터가 다양한 상이한 포맷들로 다양한 소스들로부터 획득되기 때문에, 수집된 데이터는 통합하기가 어렵다. 이 는 사용자들이 그들의 필요한 영양성분들에 대한 완전한 정보를 갖기 어렵게 하고, 따라서 상이한 음식들이 건 강에 미치는 영향 및 음식 소비에 대하여 사용자들이 시의적절하고 정보에 입각한 결정을 내릴 수 있는 능력을 저해한다. 다양한 음식-관련, 영양 및 건강 데이터를 통합하고 처리하는 것은 많은 과제를 내포하고 있다. 예를 들어, 데 이터는 상이한 데이터 유형(예를 들어, 구조화되거나 구조화되지 않은, 시계열 등)으로서 제공될 수 있고, 유용 한 정보를 추출하고 전달하기 위해 상이한 방법 또는 도구를 사용하여 처리될 수 있다. 또한 이러한 장치 및 소 프트웨어 애플리케이션을 이용하여 수집되는 데이터의 양은 수천 또는 수백만 개의 데이터 포인트들이 규칙적으 로 또는 임의 간격으로 자주 수집되는 정도로 대규모일 수 있다. 수집될 데이터의 양은 장치들 및 소프트웨어 애플리케이션들이 사용자들의 일상적인 삶들과 점점 더 상호 연결됨에 따라 시간에 따라 기하급수적으로 증가하 는 경향이 있다. 일부 경우에는, 애플리케이션 프로그래밍 인터페이스(API)에 대한 업데이트가 이루어지는 경우, 이러한 변경으로 인해 특정 API가 데이터 손실을 초래할 수 있다. 따라서, 다양한 상이한 소스들로부터의 음식-관련, 영양 및 건강 데이터의 통합 및 프로세싱과 관련된 문제들을 포함하는 이러한 문제들을 해결하기 위한 기술들, 시스템들, 방법들 및 기술들을 제공하는 것이 바람직하다. 또 한, 다른 바람직한 특징들 및 특성들은 첨부된 도면들 및 전술한 기술 분야 및 배경과 관련하여 취해진 다음의 상세한 설명 및 첨부된 청구항들로부터 명백해질 것이다. 본원에서는, 대량의 음식-관련, 영양 및 건강 데이터를 확장가능한 방식으로 취급할 수 있고, 데이터가 생성되 고 처리되는 속도의 예측 불가능성(unpredictability)을 관리할 수 있는 플랫폼이 개시된다. 개시된 플랫폼은 또한 다수의 상이한 데이터 타입들을 처리할 수 있고, 다수의 상이한 소스들로부터 데이터를 수신하도록 적응될 수 있다. 또한 플랫폼은 데이터 처리 또는 데이터 손실과 관련된 문제 없이 기저의 API에 대한 변경 사항을 지 원할 수 있다. 본원에 개시된 플랫폼은 대량의 음식-관련, 영양 및 건강 데이터의 처리, 통합 및 구조화를 가능하게 하는 하나 이상의 모듈을 포함할 수 있다. 모듈들은 서로 분리될 수 있고, 이로써 각각의 컴포넌트 또는 모듈의 유지보수 및 재사용성의 용이성을 보장한다. 본원에 개시된 플랫폼은 서버리스 아키텍처(serverless architecture)를 이 용하여 대용량 데이터를 취급할 수 있다. 서버리스 아키텍처에서, AMAZON® Lambda와 같은 툴들을 이용하면, 플 랫폼을 통해 데이터가 스트리밍될 수 있고, 코드 프로세싱은 프로세싱 기능들이 스트리밍 데이터에 의해 트리거 될 때에만 수행될 수 있다. 이러한 함수들은 일반적으로 \"람다(lambda) 함수\"로 알려져 있다. 이러한 방식으로 람다 함수들을 사용하는 것은, 컴퓨팅 자원들이 연속적으로 동작하는 것을 필요로 하지 않기 때문에, 데이터를 처리하기 위한 컴퓨팅 자원들이 더 효율적으로 사용되게 할 수 있다. 서버리스 아키텍처는 본원에 개시된 플랫 폼에 의해 대량의 데이터가 효율적으로 처리될 수 있게 해줄 수 있다. 플랫폼 컴포넌트들은 많은 데이터 유형과 인터페이스하도록 구성될 수 있다. 검색 모듈에서, 람다 함수들의 세 트는 연결된 애플리케이션들로부터 데이터를 가져오도록(pull) 구성될 수 있고, 주기적으로 데이터를 검색하는 시간 기반 작업 스케줄러를 구현할 수 있다. 람다 함수들의 다른 세트는 연결된 애플리케이션들로부터 알림을 수신하고 푸시된 데이터를 수신할 준비를 할 수 있다. 람다 함수들의 다른 세트는 가져온(pulled) 데이터 및 푸 시된 데이터를 통합하고 데이터를 플랫폼을 통해 캐스케이드되는 스트림에 전송할 수 있다. 추가적인 람다 함수 들은 프로세싱을 위해 스트림으로부터 데이터를 변환시킬 수 있으며, 이는 데이터를 표준화된 구조화된 포맷으 로 변환할 수 있다. 변환된 구조화된 데이터는 사용자에게 영양 및 건강에 대한 통찰력 또는 추천을 제공하기 위해 더 분석될 수 있다.본 개시의 일 실시예에서, 데이터 수집 및 처리 방법이 제공된다. 상기 방법은 서버리스 아키텍처를 사용하여 구현될 수 있다. 서버리스 아키텍처는 상기 방법이 확장될 수 있게 하고, 새로운 타입이나 유형의 데이터 또는 새로운 소스들이 도입될 때 이들을 지원하도록 할 수 있다. 본원에 개시된 방법은 복수의 상이한 소스들로부터 데이터를 수집 및 집계(aggregating)하는 단계를 포함할 수 있으며, 여기서 데이터는 상이한 타입 또는 유형의 데이터를 포함한다. 상이한 타입이나 유형의 데이터는 구조화된 데이터 및 비구조화된 데이터뿐만 아니라 시계 열 센서 데이터를 포함할 수 있다. 데이터는 복수의 개별 사용자들에게 특이적인 음식, 건강 또는 영양 데이터 를 포함할 수 있다. 상기 방법은 상이한 타입이나 유형의 데이터를 건강 및 영양 플랫폼과 호환될 수 있는 표준 화된 구조화된 포맷으로 변환함으로써, 소스의 불가지론적인(agnostic) 방식으로 상이한 타입이나 유형의 데이 터 각각을 연속적으로 처리하는 단계를 더 포함할 수 있다. 상기 방법은 또한 건강 및 영양 플랫폼으로부터의 정보를 부분적으로 이용하여 표준화된 구조화된 포맷으로 변환된 데이터를 분석하는 단계를 포함할 수 있다. 표 준화된 구조화된 데이터는 하나 이상의 머신러닝 모델을 사용하여 분석될 수 있다. 분석에 기초하여, 복수의 개 별 사용자 각각에 대해 개인화된 식이 및 건강 권고 또는 추천이 생성될 수 있다. 일부 실시예들에서, 복수의 상이한 소스들은 모바일 장치들, 웨어러블 장치들, 의료 장치들, 가전 기기들, 또는 헬스케어 데이터베이스들 중 2개 이상을 포함할 수 있다. 모바일 장치들은 스마트 장치들(예를 들어, 스마트폰, 태블릿)을 포함할 수 있고, 웨어러블 장치들은 활동 추적기들, 스마트워치들, 스마트 글래스들, 스마트 링들, 스마트 패치들, 항산화 모니터들, 수면 센서들, 바이오마커 혈액 모니터들, 심박 속도 변동성(HRV: heart rate variability) 모니터들, 스트레스 모니터들, 온도 모니터들, 자동 스케일들, 지방 모니터들, 또는 스마트 패브 릭들 중 하나 이상을 포함한다. 의료 장치들은 혈당 모니터들, 심박 속도 모니터들, 혈압 모니터들, 땀 센서들, 인슐린 펌프들, 케톤 모니터들, 젖산 모니터들, 철분 모니터들, 또는 전류 피부저항 반응(GSR: galvanic skin response) 센서들 중 하나 이상을 포함할 수 있다. 본원에 개시된 청구대상의 예시적인 실시예들은 휴대용 전자 의료 장치들과 같은 의료 장치들과 함께 구현될 수 있다. 많은 상이한 응용이 가능하지만, 일 실시예는 주입 시 스템 전개의 일부로서 인슐린 주입 장치(또는 인슐린 펌프)를 포함할 수 있다. 단순화를 위해, 주입 시스템 동 작, 인슐린 펌프 및/또는 주입 세트 동작, 및 시스템들의 다른 기능적인 양태들(및 시스템들의 개별적인 동작 구성요소들)과 관련된 통상적인 기술들은 본원에서 상세하게 설명되지 않을 수 있다. 주입 펌프(예를 들어, 인 슐린 펌프)의 예들은 미국 특허 제4,562,751호, 제4,685,903호, 제5,080,653호, 제5,505,709호, 제5,097,122호, 제6,485,465호, 제6,554,798호, 제6,558,320호, 제6,558,351호, 제6,641,533호, 제6,659,980호, 제6,752,787호, 제6,817,990호, 제6,932,584호, 및 제7,621,893호에 설명된 타입일 수 있으나, 이들로 제한되지는 않으며, 각각은 본원에 참조로 포함된다. 의료 데이터베이스는 유전적 데이터베이스, 혈액 검사 데이터베이스, 바이옴(biome) 데이터베이스, 또는 전자 의료 기록(EMR: electronic medical records)을 포함할 수 있다. 일부 실시예들에서, 복수의 상이한 소스들로부터의 데이터는 하루에 걸쳐 고르지 않게 분포되는 일별 106개 정 도의 데이터 포인트들을 적어도 포함할 수 있다. 데이터는 복수의 애플리케이션 프로그래밍 인터페이스(API: application programming interface)를 통해 복수의 상이한 소스들로부터 수집 및 집계(aggregated)될 수 있다. 일부 경우에는 데이터의 처리가 기저의 API의 변경이나 업데이트에 영향을 받지 않기 때문에, 기저의 API 에 대한 변경이나 업데이트가 이루어질 때, 데이터가 데이터 손실 없이 처리될 수 있다. 일부 실시예들에서, 데이터의 수집 및 집계는 복수의 스트림들에 데이터를 저장하는 단계를 포함할 수 있다. 데 이터의 처리는, 상이한 조건들이 발생할 때, 복수의 스트림들에 저장된 데이터에 대해 람다 함수들을 실행하는 단계를 더 포함할 수 있다. 람다 함수들은 데이터가 수집되어 복수의 스트림들에 저장되는 경우에만 실행될 수 있다. 저장된 데이터에 대한 람다 함수들의 실행은 데이터의 각각의 행을 복수의 스트림들로부터 관련 스트림으 로 채널링 및 전송하도록 구성된다. 데이터는 하나의 스트림으로부터 복수의 스트림들의 다른 스트림으로 캐스 케이딩(cascading)함으로써 데이터 파이프라인을 따라 전달될 수 있다. 일부 실시예들에서, 복수의 상이한 소스들로부터의 데이터의 수집 및 집계는 데이터를 인출(pull)할 수 있 는 제1 세트의 소스들로부터 데이터를 인출하는 단계, 및 복수의 인출 요청들 및 푸시 요청들로부터의 데이 터가 중앙화된 위치로 스트림되도록 제2 소스 세트로부터 푸시되는 데이터를 수신하는 단계를 포함할 수 있다. 데이터는 작업 스케줄러를 사용하여 미리 결정된 시간 간격들에서 소스들의 제1 세트로부터 인출될 수 있다. 데 이터는 또한 데이터가 제2 소스 세트로부터 푸시될 때 제2 세트의 소스들로부터 수신될 수 있다. 일부 경우에, 소스들의 제2 세트로부터의 데이터의 푸시 전에 데이터와 연관된 하나 이상의 알림이 선행될 수 있다. 다른 경 우에, 데이터가 대응하는 알림과 함께 도착하지 않는 경우 대응하는 알림과 연관된다. 일부 예들에서, 소스들의 제1 세트 및 소스들의 제2 세트는 제1 및 제2 세트들 모두에 공통인 하나 이상의 소스들을 포함할 수 있다. 다른 예들에서, 소스들의 제1 세트 및 소스들의 제2 세트는 서로 상이한 소스들을 포함할 수 있다. 일부 실시예들에서, 복수의 스트림들 각각은 데이터가 각각의 스트림에 저장되는 시간 프레임을 정의하는 보존 정책(retention policy)을 가질 수 있다. 시간 프레임은, 예를 들어 약 24시간 내지 약 168시간의 범위일 수 있 다. 데이터는 각각의 데이터의 소스(들)의 사전 지식 없이 분리되는(decouple) 방식으로 복수의 스트림들에 저 장될 수 있다. 복수의 스트림들은 복수의 샤드(shard)들을 포함할 수 있다. 각각의 샤드는 큐에 들어가고 보존 정책이 만료되면 큐를 종료하는, 데이터 레코드들의 문자열을 포함할 수 있다. 데이터 레코드들의 문 자열은 복수의 개별 사용자들에게 특정한 음식 소비, 건강 또는 영양 기록들을 포함할 수 있다. 복수의 스트림 들에서 다수의 샤드들을 제어함으로써, 데이터가 처리되고 있는 속도가 제어될 수 있다. 일부 실시예들에서, 상기 방법은 하나 이상의 상이한 엔티티들과 연관된 토큰 모듈을 통해 복수의 API들과 통신 하는 단계를 포함할 수 있다. 복수의 API들로부터의 데이터는 검색 모듈을 사용하여 수집 및 집계될 수 있으며, 이에 의해 검색 모듈은 토큰 모듈로부터 분리되고 독립될 수 있다. 토큰 모듈은 기존의 토큰들을 리프레시하고 토큰 변경들에 관한 알림 업데이트들을 제공하도록 구성될 수 있다. 새로운 토큰이 생성될 때마다, 새로운 토큰 은 토큰 모듈에 저장되는 것에 더하여, 검색 모듈에서 개별적으로 복제될 수 있다. 일부 경우에, 검색 모듈은 데이터를 수집 및 집계하도록 구성될 수 있고, 데이터를 유지, 저장 또는 처리하도록 구성되지는 않는다. 일부 실시예들에서, 수집된 데이터의 일부 또는 전부가 건강 및 영양 플랫폼에 제공되고 이용될 수 있다. 추가 적으로 또는 선택적으로, 수집된 데이터의 일부는 하나 이상의 써드파티들에 전송될 수 있다. 데이터는 건강 및 영양 플랫폼에 제공되고 이용되기 전에, 표준화된 구조화된 형식으로 변환될 수 있다. 일부 실시예들에서, 복수의 데이터 소스들로부터의 데이터는 저장 모듈에 수집되고 집계될 수 있다. 저장 모듈 은 중복 데이터를 확인, 검사 및 제거하도록 구성될 수 있다. 저장 모듈은 데이터를 배치들로 유지하도록 구성 될 수 있다. 저장 모듈은 선택된 타입의 데이터를 통합함으로써 데이터를 감소시키도록 구성될 수 있다. 일부 경우에, 저장된 데이터의 일부는 하나 이상의 이미징 장치들을 사용하여 캡쳐된 복수의 이미지들을 포함할 수 있다. 선택된 람다 함수는 저장된 데이터의 일부에 대해 실행되어, 복수의 이미지들 중 어느 것이 그들의 영 양 성분에 대해 분석될 하나 이상의 음식 이미지들을 포함하는지를 검출할 수 있다. 하나 이상의 음식 이미지들 은 타임스탬프 및 지오로케이션들과 연관될 수 있으며, 이에 의해 사용자의 음식 섭취의 시간적 및 공간적 추적 을 가능하게 한다. 사용자의 음식 섭취의 시간적 및 공간적 추적은 식사의 소비 시간 또는 식사의 내용물을 예 측하는 단계를 포함할 수 있다. 본 개시의 또 다른 실시예에서, 서버리스 데이터 수집 및 처리 시스템이 제공된다. 시스템은 복수의 상이한 소 스들로부터 데이터를 수집하고 집계하도록 구성된 검색 모듈을 포함할 수 있으며, 여기서 데이터는 데이터의 상 이한 타입이나 유형을 포함한다. 시스템은 또한 데이터의 상이한 타입이나 유형을 건강 및 영양 플랫폼과 호환 될 수 있는 표준화된 구조화된 형식으로 변환함으로써, 소스의 불가지론적인 방식으로 상이한 타입이나 유형의 데이터 각각을 연속적으로 처리하도록 구성된 표준화 모듈을 포함할 수 있다."}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "본 요약은 이하의 상세한 설명에서 더 설명되는 개념들의 선택을 간략한 형태로 소개하기 위해 제공된다. 본 요 약은 청구대상의 핵심적인 특징들 또는 본질적인 특징들을 식별하기 위한 것이 아니며, 청구대상들의 범위를 결 정하는 데에 있어서의 보조로서 사용되도록 의도되지도 않는다. 본 개시의 상이한 실시예들은 개별적으로, 집합 적으로, 또는 서로 조합하여 이해될 수 있음을 이해할 것이다. 본원에 기재된 본 개시의 다양한 실시예들은 이 하에 제공되는 특정 응용예들 중 임의의 것에 적용될 수 있거나, 임의의 다른 유형의 건강, 영양 또는 음식-관 련 모니터링/추적/추천 시스템 및 방법에 대해 적용될 수 있다."}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 상세한 설명은 본질적으로 단지 예시적인 것이며, 청구대상의 실시예들 또는 이러한 실시예들의 응용 및 용도를 제한하고자 하는 것은 아니다. 본원에 사용되는 바와 같이, 단어 \"예시적인\"은 \"예, 인스턴스, 또는 예 시로서 기능하는\" 것을 의미한다. 본원에서 예시로서 설명되는 임의의 구현예는 반드시 다른 구현예들에 비해"}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "바람직하거나 유리한 것으로 해석되는 것은 아니다. 또한, 선행 기술 분야, 배경, 간략한 요약 또는 하기의 상 세한 설명에서 제시된 임의의 표현되거나 암시된 이론에 의해 구속될 것으로 의도하지 않는다. 또한, 본원에서 언급된 모든 공개문헌, 특허, 및 특허출원은, 각각의 개별적인 공개문헌, 특허, 또는 특허출원이 구체적이고 개 별적으로 참고로 포함되는 것으로 표시되는 것과 동일한 정도로 본원에 참고로 포함됨을 유의해야 한다. 이제, 본 개시의 예시적인 실시예들이 상세히 참조될 것이며, 그 예들은 첨부된 도면들에 도시되어 있다. 가능 하다면, 동일한 도면부호들은 동일하거나 유사한 부분들을 지칭하도록 도면들 및 개시내용 전반에 걸쳐 사용될 것이다. 오늘날 많은 애플리케이션들이 개인들로부터 건강, 영양, 및 피트니스 데이터를 수집하고 있다. 일부 애플리케 이션들은 모바일 전화들 또는 웨어러블 장치들 상에서 구현될 수 있고, 활동 레벨들 및 생체 통계치들, 예를 들 어, 심장 박동, 혈압 및 인슐린 레벨들을 수동적으로 추적할 수 있다. 일부 애플리케이션들은 사용자들이 그들 의 식단들, 운동 루틴들, 및 수면 습관들을 기록하게 할 수 있고, 기록된 데이터로부터 건강 메트릭들을 계산할 수 있다. 개인들이 다수의 애플리케이션들로부터 획득된 무수한 데이터를 추적하는 것은 어려울 수 있다. 개별 데이터 세트들은 특히, 사용자들이 다른 유형 또는 세트의 건강 및 영양 데이터 간의 영향 및 관계를 완전히 이 해하지 못하는 경우, 종종 사용자들에게 필요한 통찰력을 제공하지 못할 수 있다. 결과적으로, 사용자들은 그들 의 건강 또는 웰빙을 향상시키기 위해 실행 가능한 단계들을 취하는 데 필요한 도구들이 부족할 수 있다. (본원 에 개시된 바와 같은) 플랫폼은 사용자들에게 보다 정확하고 유용한 영양 및/또는 건강 정보를 제공하기 위하여 다수의 애플리케이션들로부터 방대한 양의 건강, 음식-관련 및 영양 데이터를 수집 및 통합하고, 데이터를 처리 하도록 구성될 수 있다. 일부 예에서, 신경망 및 다른 머신러닝 알고리즘이 데이터를 분석하고 개인 사용자에게개인화된 건강 추천을 제공하는 데 사용될 수 있다. 본원에 개시된 플랫폼은 사용자들에 의해 제출된 및/또는 상이한 유형의 써드파티 애플리케이션들로부터 검 색된 데이터를 수집 및 집계할 수 있고, 데이터의 상이한 타입이나 유형을 건강 및 영양 플랫폼과 호환될 수 있는 표준화된 구조화된 형식으로 변환함으로써, 그의 소스의 불가지론적인 방식으로 데이터를 처리할 수 있 다. 일부 실시예들에서, 본원에 개시된 플랫폼은 건강 및 영양 플랫폼과 통합되거나 또는 건강 및 영양 플랫폼 의 일부로서 제공될 수 있다. 다른 실시예들에서, 본원에 개시된 플랫폼은 건강 및 영양 플랫폼으로부터 분리되 어 제공될 수 있다. 본원에 개시된 플랫폼, 또는 본 개시와 일관되는 건강 및 영양 플랫폼에 대한 임의의 변형 이 고려될 수 있다. 건강 및 영양 플랫폼의 예들은 미국 특허출원 제13/784,845호 및 제15/981,832호에 기재되 어 있으며, 이들 모두는 그 전문이 본원에 참고로 포함된다. 본원에 개시된 플랫폼은 데이터가 플랫폼을 통해 스트리밍될 때, 대량의 건강 및 영양 데이터를 처리하기 위한 자율 함수들을 갖는 서버리스(serverless) 아키텍처를 사용하여 구현될 수 있다. 서버리스 아키텍처를 사용하면 플랫폼이 예를 들어, 하루에 106개의 데이터 포인트들 정도의 대량의 데이터를 처리할 수 있도록 허용할 수 있 는데, 이는 하루에 균등하게 또는 고르지 않게 분배될 수 있다. 서버리스 아키텍처를 사용하는 것은 수신되는 데이터 흐름에 따라 필요할 때에 서버 자원이 사용되기 때문에 데이터 트래픽의 큰 변동과 관련된 예측 불가능 성을 완화하는 데 유리하다. 자율 함수들은 데이터 항목들이 수신되거나 저장될 때와 같이 특정 이벤트에 응답 하여 트리거될 수 있다. 서버리스 아키텍처를 사용하여 플랫폼을 구현하면 특정 함수들이 호출되는 경우에만 비 용이 발생할 수 있으므로 비용 이점을 제공할 수도 있다. 또한, 함수들은 짧은 시간 동안 실행될 수 있고, 이는 프로세서를 연속적으로 사용하는 것과 관련된 비용들을 제거한다. 데이터가 수신되지 않을 때, 자율 함수들은 트리거될 필요가 없으며, 따라서 프로세싱 비용들은 발생하지 않는다. 서버리스 아키텍처를 사용하여 플랫폼을 구현하는 추가적인 장점은 이러한 아키텍처가 통상적인 서버 기반 시스템들을 사용하여 관련 비용을 발생시키지 않으면서 확장성을 허용할 수 있다는 점이다. 서버리스 플랫폼에 의해 처리되는 데이터가 많을수록 데이터 처리 를 위한 자율 함수들을 트리거하는 호출 수가 증가할 것이다. 추가 비용은 증가된 함수 호출 수에 기초한다. 서 버리스 아키텍처를 사용하면 추가적인 서버 자원, 유지 보수 또는 인력에 대한 투자가 제거될 수 있기 때문에 본 개시의 플랫폼을 사용하여 비용 절감이 실현할 수 있다. 본원에 기술된 바와 같은 서버리스 아키텍처는 애플리케이션들이 써드파티 서비스들에 의해 호스팅되는 소프트 웨어 디자인 배치일 수 있다. 써드파티 서비스의 예들은 AMAZON® Web Services Lambda, TWILIO® Functions, 및 MICROSOFT® Azure Functions를 포함할 수 있다. 일반적으로 인터넷에서 서버 애플리케이션을 호스트하려면 가상 또는 물리적 서버뿐만 아니라 애플리케이션을 실행하는 데 필요한 운영 체제 및 기타 웹 서버 호스팅 프로 세스를 관리해야 한다. 서버리스 아키텍처의 써드파티 서비스에 애플리케이션을 호스팅하면 서버 소프트웨어 및 하드웨어 관리의 부담이 써드파티 서비스로 넘어간다. 서버리스 아키텍처 내에서 작업하도록 개발된 애플리케이션들은 개별적으로 호출되고 스케일링될 수 있는 개별 적인 자율 함수들에 의해 분리될 수 있다. 본원에서 설명되는 일부 써드파티 서비스들의 예에서, 함수들은 예를 들어 Lambda 함수들, Twilio 함수들, 및 Azure 함수들로서 알려져 있을 수 있다. 이러한 함수들은 이벤트들에 응답하여 트리거될 때 컴퓨팅 동작을 수행하는, 상태 없는(stateless) 컨테이너이다. 이들은 컴퓨팅 성능을 계 속 사용하는 대신, 한 번 호출하는 동안 또는 제한된 수의 호출을 포함하는 기간 동안에 컴퓨팅 성능을 사용할 수 있음을 의미하는, 일시적이다. 자율 함수들은 써드파티 서비스에 의해 완전히 관리될 수 있다. 자율 함수를 갖는 서버리스 아키텍처는 종종 \"서비스형 함수(Functions as a Service)\"로 지칭될 수 있다. 자율 함수들은 기 저의 서버리스 아키텍처에 의해 지원되는 언어에 따라 다양한 프로그래밍 언어를 사용하여 구현될 수 있다. 예 시적 언어들은 JavaScript, Python, Go, Java, C 및 Scala를 포함한다. 자율 함수들에 의해 수행되는 컴퓨팅 작업들은 데이터를 저장하는 단계, 알림을 트리거링하는 단계, 파일들을 처리하는 단계, 작업들을 스케줄링하는 단계, 및 애플리케이션들을 확장하는 단계를 포함할 수 있다. 예를 들어, 자율 함수는 모바일 애플리케이션으로부터의 애플리케이션 프로그래밍 인터페이스(API) 호출로서 요청을 수신하고, 요청 내의 파라미터들에 속하는 값들을 검사하며, 검사된 값들에 기초하여 출력을 생성하는 동작을 수행하고, 데이터베이스 내의 테이블 항목들을 수정함으로써 데이터베이스에 출력 데이터를 저장할 수 있다. 자 율 함수에 의해 수행되는 처리 동작의 일 예는 부호들을 편집 가능한 텍스트로 변환하는, PDF 파일들 또는 이미 지 파일들 상의 광학 문자 인식(OCR: optical character recognition)일 수 있다. 스케줄된 작업들의 예들은 주기적으로 데이터베이스에서 중복 항목들을 제거하는 것, 연결된 애플리케이션에서 데이터를 요청하는 것, 및 액세스 토큰을 갱신하는 것일 수 있다. 자율 함수들은 애플리케이션들로부터 데이터를 검색하고, 처리를 위해 써드파티 서비스들에 데이터를 포스팅하면서, 애플리케이션들의 확장들로서 작용할 수 있다. 예를 들어, 자율함수를 사용하여, 스태프가 볼 수 있는 별도의 헬프 데스크 채팅 프로그램에 서비스 데스크 티켓이 전달될 수 있다. 본원에서 설명되는 것과 같은 서버리스 아키텍처를 사용하는 것의 장점은 이들이 쉽게 확장가능하다는 것이다. 자원이 필요한 경우 수평적 확장 또는 추가적인 자원 추가가 수행될 수 있다. 예를 들어, 처리된 요청의 양이 확장되는 경우, 아키텍처는 추가적인 컴퓨팅 자원을 자동으로 조달할 수 있다. 임시 자율 함수들은 런타임 수요 에 따라 생성되고 제거될 수 있기 때문에 확장이 더 쉽게 수행될 수 있다. 서버리스 아키텍처는 표준화되기 때 문에, 문제가 발생하는 경우 유지보수하기가 더 쉽다. 서버리스 아키텍처를 사용하는 또 다른 장점은 서버리스 아키텍처가 비용 효율적일 수 있다는 점이다. 자율 함 수들은 임시적이기 때문에, 컴퓨팅 파워는 함수가 호출될 때에만 사용될 수 있다. 따라서, 함수가 호출되지 않 을 때, 컴퓨팅 파워에 대한 과금이 이뤄지지 않는다. 이러한 지불 구조는 요청이 간혹 발생하거나 트래픽이 일 관되지 않을 때 장점이 있다. 서버가 연속적으로 실행되고 있지만 1분당 하나의 요청만 처리하는 경우, 서버가 작동되어 실행되는 시간과 비교하면 요청을 처리하는 시간이 적기 때문에 서버가 비효율적일 수 있다. 대조적으 로, 서버리스 아키텍처를 사용하면, 임시 자율 함수가 컴퓨팅 파워를 사용하여 요청을 처리하고 나머지 시간은 휴면 상태로 유지할 것이다. 트래픽이 일관되지 않는 경우, 요청이 빈번하지 않을 때에는 적은 컴퓨팅 파워가 사용될 수 있다. 트래픽이 급증할 때에는, 많은 양의 컴퓨팅 파워가 사용될 수 있다. 통상적인 환경에서, 트래 픽 급증을 다루기 위해 하드웨어 개수가 증가할 필요가 있을 수 있지만, 트래픽이 잠잠해진 경우에는 하드웨어 가 낭비될 것이다. 그러나, 서버리스 환경에서는 유연한 확장을 통해 트래픽 급증 시에만 비용 지불을 증가시키 고 낮은 트래픽 기간 동안에는 비용을 절감할 수 있다. 본원에 개시된 서버리스 아키텍처는 스트리밍 데이터를 통합 및 처리할 수 있다. 스트리밍 데이터는 여러 소스 에 의해 연속적으로 생성되고 동시에 처리되는 데이터이다. 서버리스 아키텍처는 데이터가 생성될 때, 스트리밍 데이터를 신속하게 그리고 적시에(예를 들어, 실질적으로 실시간으로) 수집하고 처리할 수 있다. 이는 데이터를 수집하고, 데이터베이스에 저장하고, 나중에 분석하는 것과 대조된다. 서버리스 아키텍처는 데이터를 캡처, 변 환 및 분석하도록 특별히 설계된 서비스들을 가질 수 있다. 이러한 서비스들은, 스트리밍 데이터를 상이한 종류 의 써드파티 애플리케이션들과 상호운용 가능한 형식들로 압축하고, 암호화하고, 변환하기 위해 자율 함수들을 보완할 수 있다. 자율 함수들은 플랫폼이 여러 작업들, 예를 들어, 인증, 허가, 데이터 통합, 데이터 전송, 데이터 처리, 및 표 준화 등을 수행할 수 있게 할 수 있다. 특정 자율 함수들은 외부 API(Application Programming Interface)와 통신하고 애플리케이션 사용 권한을 관리하기 위해 액세스 토큰을 교환, 저장, 갱신 및 삭제할 수 있다. 일부 자율 함수들은 데이터를 플랫폼으로 푸시하고 인출하는 연결된 애플리케이션들로부터 데이터를 검색하고, 수집 된 모든 데이터를 스트림으로 통합할 수 있다. 다른 자율 함수들은 스트리밍된 데이터를 플랫폼의 다른 구성요 소들로 전송할 수 있다. 일부 다른 자율 함수들은 데이터를 정렬하고, 데이터를 상이한 파일 형식으로 변환하며, 불필요한 데이터를 제거하고, 및/또는 데이터를 표준화함으로써 데이터를 처리할 수 있다. 일부 다른 자율 함수들은 저장 및 분석을 위해 데이터를 전처리할 수 있다. 플랫폼 내의 모듈들은 유지보수 또는 업데이트를 용이하게 하기 위해 분리될 수 있다. 본원에서 설명되는 모듈 은, 구성요소로서 상호교환적으로 지칭될 수 있다. 반대로, 본원에 설명된 모듈은 해당 모듈이 구성요소들의 그 룹을 포함하도록 하나 이상의 구성요소들을 포함할 수 있다. 모듈들을 분리함으로써, 데이터는 플랫폼 구성요소 들을 통해 흐를 수 있고, 데이터 손실 없이 처리될 수 있다. 예를 들어, 토큰들은 하나의 구성요소로부터 다른 구성요소로 복사될 수 있고, 2개의 구성요소들은 서로 의존하지 않도록 분리될 수 있다. 일부 경우에, 하나의 구성요소는 스트림을 리디렉션하도록 구성될 수 있는 반면, 다른 구성요소는 처리를 위해 구성될 수 있다. 저장 을 위해 제3 구성요소가 구성될 수 있다. 본원에 개시된 플랫폼은 각각의 모듈이 하나 이상의 다른 모듈들 상에 서의 상호 동작 의존성을 요구하지 않고 특정 기능을 수행하도록 구성되는 모듈 방식으로 설계될 수 있다. 서버리스 아키텍처를 갖는 개시된 플랫폼은 빅데이터 처리에 적합하며, 건강 및 영양 플랫폼 또는 다른 써드파 티 애플리케이션과 호환되는 표준화된 구조화된 형식으로, 많은 상이한 타입이나 유형의 데이터를 통합하기 위 한 유연성을 플랫폼에 제공한다. 플랫폼은 사용자들로부터 데이터를 수집할 수 있으며, 다양한 써드파티 애플리 케이션들로부터의 여러 API와 통합하여 다른 유형의 데이터를 수집할 수도 있다. 일부 실시예들에서, 플랫폼은 다양한 소스들(예를 들어, 인터넷, 기존의 데이터베이스들, 사용자 입력 등)로부터 연속적으로 업데이트되는 음 식 온톨로지를 생성하여, 모든 음식 유형들(예를 들어, 기본 음식들, 포장된 음식들, 레시피들, 식당 음식들 등)의 임의의 획득 가능한 정보를 조직화하고 분석할 수 있다. 일부 실시예들에서, 플랫폼은 또한 사용자들이소비된 식사, 수행된 운동 또는 활동들, 수면의 양, 및 다른 건강 데이터에 관한 정보를 수동으로 기록하게 할 수 있다. 일부 실시예들에서, 플랫폼의 써드파티 애플리케이션들과의 통합은 플랫폼이 다수의 데이터 수집 장치 들 및 서비스들(예를 들어, 모바일 장치들, 혈당 센서들, 헬스케어 제공자 데이터베이스들 등) 간에 개인화된 데이터 네트워크를 생성하게 하여, 신진대사(예를 들어, 수면, 운동, 혈액 검사, 스트레스, 혈당, DNA 등)에 의 해 영향을 받을 수 있거나, 또는 영향을 미칠 수 있는 바이오마커들의 임의의 획득 가능한 정보를 통합할 수 있 다. 메드트로닉(Medtronic), 애보트(Abbott), 덱스콤(Dexcom) 등과 같은 회사에 의해 제조된 의료 장치들과 플 랫폼의 통합은 장치 사용 데이터 및 건강 관련 데이터와 같은 데이터를 플랫폼에 제공할 수 있다. 플랫폼은 다 양한 정보를 연결하거나 상관시킴으로써 음식 온톨로지, 수동 로그, 및 개인화된 데이터 네트워크를 합성하여, 상이한 음식들이 각각의 개인에게 어떻게 영향을 미칠 수 있는지에 대한 통찰력을 도출하고, 각각의 개인에 대 한 개인화된 음식, 건강 및 웰니스 추천을 더 생성할 수 있다. 플랫폼의 실시예들은 AMAZON® Lambda, AMAZON® S3 및 AMAZON® Kinesis를 포함하는 AMAZON® Web Service 솔 루션들을 이용할 수 있다. 다른 실시예들은 GOOGLE® 클라우드 서비스 또는 MICROSOFT® Azure와 같은 서비스들 로부터의 유사한 도구들을 이용할 수 있다. 도면들을 참조하는 이하의 설명은 플랫폼이 구현될 수 있는 환경에 대한 컨텍스트를 제공하고, 플랫폼을 통한 데이터 스트림들뿐만 아니라 플랫폼의 구조를 상세히 기술한다. 도 1은 일부 실시예들에 따른 생태계를 도 시한다. 일 양태에서, 생태계는 시스템 아키텍처 또는 플랫폼을 포함할 수 있다. 플랫폼은 복수의 상 이한 소스들(예를 들어, 장치들, 인터넷, 및 데이터베이스(들))로부터 데이터를 수집하고 집계 (aggregate)할 수 있다. 도 1에 도시된 바와 같이, 생태계는 장치들을 포함할 수 있다. 장치들 은 웨어러블 장치(예를 들어, 스마트 워치, 활동 추적기, 스마트 글래스, 스마트 링, 스마트 패치, 스마트 패브릭 등), 모바일 장치(예를 들어, 핸드폰, 스마트폰, 음성 레코더 등), 및/또는 의료 장치(예를 들어, 혈당 모니터, 인슐린 펌프, 혈압 모니터, 심박수 모니터, 땀 센서, 전기피부반응(GSR) 모니터, 피부온도 센서 등)을 포함할 수 있다. 일부 경우에, 장치들은 가전 제품들(예를 들어, 음식 및 식이 습관을 추적할 수 있는 스마트 냉장고, 소비되는 음식물의 양 및 유형을 추적할 수 있는 스마트 전자레인지 등) 또는 사용자 신체 활동 레벨을 추적할 수 있는 게임 콘솔들을 포함할 수 있다. 장치들은 서로 통신할 수 있다. 플랫폼 은 동시에 또는 상이한 시간에 하나 이상의 장치들과 통신할 수 있다. 장치들은 하나 이상의 센서들을 포함할 수 있다. 센서들은 신호를 검출하거나 정보를 획득하도록 구성되는 임의의 장치, 모듈, 유닛, 또는 서브시스템일 수 있다. 센서들의 비제한적인 예들은 관성 센서(예를 들어, 가속 도계, 자이로스코프들, 관성 측정 유닛들(IMU들)을 형성할 수 있는 중력 검출 센서), 위치 센서(예를 들어, GPS(global positioning system) 센서, 위치 삼각측량을 가능하게 하는 모바일 장치 송신기), 심박수 모니터, 온도 센서(예를 들어, 외부 온도 센서, 피부 온도 센서), 사용자를 둘러싸는 환경(예를 들어, 온도, 습도, 밝기)을 검출하도록 구성된 환경 센서, 용량성 터치 센서(capacitive touch sensor), GSR 센서, 비전 센서(예를 들어, 가시광, 적외선, 또는 자외선 광을 검출할 수 있는 이미징 장치들, 카메라들), 열화상 센서, 위치 센서, 근접 거리 측정 센서(예를 들어, 초음파 센서, 광 검출 및 레인징 장치(LIDAR), 전파시간 또는 깊이 카메라), 고도 센서, 자세 센서(예를 들어, 나침반), 압력 센서(예를 들어, 기압계), 습도 센서, 진동 센서, 오디오 센서 (예를 들어, 마이크), 필드 센서(예를 들어, 자력계, 전자기 센서, 무선 센서), HRV 모니터에 사용되는 센서(예 를 들어, 심전도(ECG: electrocardiogram) 센서, 심탄동도(ballistocardiogram) 센서, 광용적맥파(PPG: photoplethysmogram) 센서), 혈압 센서, 액체 검출기, Wi-Fi/블루투스/셀룰러 네트워크 신호 강도 검출기, 주변 광 센서, 자외선(UV) 센서, 산소 포화도 센서, 또는 본원의 다른 곳에서 설명된 바와 같은 이들의 조합 또는 임 의의 다른 센서 또는 감지 장치를 포함할 수 있다. 센서들은 웨어러블 장치들, 모바일 장치들, 또는 의료 장치 들 중 하나 이상에 위치될 수 있다. 일부 경우에, 센서는 사용자의 신체 내부에 배치될 수 있다. 장치들은 또한 플랫폼과 통신할 수 있는 임의의 컴퓨팅 장치를 포함할 수 있다. 컴퓨팅 장치의 비제 한적인 예들은 모바일 장치, 스마트폰/휴대폰, 태블릿, PDA(personal digital assistant), 랩탑 또는 노트북 컴퓨터, 데스크톱 컴퓨터, 미디어 콘텐츠 플레이어, 텔레비전 세트, 비디오 게임 스테이션/시스템, 가상 현실 시스템, 증강 현실 시스템, 마이크, 또는 다양한 유형의 건강, 영양 또는 음식 데이터를 분석, 수신, 제공 또는 디스플레이할 수 있는 임의의 전자 장치를 포함할 수 있다. 장치는 핸드헬드(handheld) 물체일 수 있다. 장치는 휴대용일 수 있다. 장치는 사람 사용자에 의해 운반될 수 있다. 일부 경우에, 장치는 사람 사용자로부터 원격으 로 위치될 수 있고, 사용자는 무선 및/또는 유선 통신들을 사용하여 장치를 제어할 수 있다. 플랫폼은 인터넷 및 데이터베이스(들)(예를 들어, 다른 음식, 영양, 또는 헬스케어 제공자)와 통신할 수 있다. 예를 들어, 플랫폼은 전자 의료 기록(EMR: electronic medical records)을 포함하는 헬스케어데이터베이스와 통신할 수 있다. 일부 실시예들에서, 데이터베이스(들)는 Hadoop 분산 파일 시스템(HDFS: Hadoop distributed file system)과 같은 구조화되지 않은 데이터베이스 또는 형식에 저장된 데이터를 포함할 수 있다. HDFS 데이터 저장소는 구조화되지 않은 데이터에 대한 스토리지를 제공할 수 있다. HDFS는 확장 가능 하고 안정적인 데이터 스토리지를 제공하는 Java 기반 파일 시스템이며 상용 서버의 대규모 클러스터들을 확장 하도록 설계될 수 있다. HDFS 데이터 저장소는 MapReduce와 같은 병렬 처리 알고리즘에 유용할 수 있다. 플랫폼은 또한 플랫폼에 의해 수집되거나 생성되는 임의의 데이터 또는 정보를 저장하기 위해 추가적 인 데이터베이스(들)와 통신할 수 있다. 추가적인 데이터베이스(들)는 보안 클라우드 데이터베이스의 컬렉션일 수 있다. 복수의 상이한 소스들로부터의 데이터는 상이한 타입이나 유형의 데이터(구조화된 데이터 및 /또는 구조화되지 않은 데이터)를 포함할 수 있다. 일부 경우에, 데이터는 하나 이상의 장치들, 센서들, 또는 모니터링 시스템들에 의해 수집된 시계열 데이터를 포함할 수 있다. 시계열 데이터는 주기적인 센서 판독 또는 다른 데이터를 포함할 수 있다. 플랫폼은 수십, 수백, 수천, 수십만, 또는 수백만 개에 이르는 임의의 수 또는 유형의 장치들로부터 데이터를 수신할 수 있다. 플랫폼은 상이한 타입들 또는 유형들의 데이터를 표 준화된 구조화된 형식으로 변환함으로써, 소스의 불가지론적인 방식으로 상이한 타입이나 유형의 데이터 각각을 연속적으로 처리할 수 있다. 표준화된 구조화된 형식으로 변환된 데이터는 건강 및 영양 플랫폼과 호환될 수 있 다. 본원의 다른 곳에 기재된 바와 같이, 플랫폼은 건강 및 영양 플랫폼과 통합되거나 또는 건강 및 영양 플랫폼의 일부로서 제공될 수 있다. 일부 실시예들에서, 플랫폼은 건강 및 영양 플랫폼으로부터 분리되어 제공될 수 있다. 플랫폼은 서로 간에 그리고 서로로부터 스트리밍 데이터를 전송할 수 있는 구성요소들(또는 모듈들)의 세 트를 포함할 수 있다. 일부 실시예들에서, 데이터는 AMAZON® Kinesis 데이터 스트림들을 이용하는 지속적 큐에 저장될 수 있다. 일부 실시예들에서, 데이터는 하나 이상의 개별 사용자에게 특정한 음식, 건강, 또는 영양 데 이터를 포함할 수 있다. 플랫폼은 건강 및 영양 플랫폼으로부터의 정보를 부분적으로 이용하여 표준화된 구조화된 형식으로 변환된 데이터를 분석할 수 있다. 일부 실시예들에서, 플랫폼은 하나 이상의 머신러닝 모델들 또는 자연어 처리(NLP: natural language processing) 기술들을 사용하여 표준화된 구조화된 데이터를 분석할 수 있다. 본 개시에서 사용될 수 있는 머신러닝 모델들 또는 알고리즘들은 지도(또는 예측) 학습, 반 (semi)-지도 학습, 능동 학습, 비지도 머신러닝, 또는 강화 학습을 포함할 수 있다. 인공지능은 사람처럼 동작하고 반응하는 지능형 기계의 창조를 강조하는 컴퓨터 과학의 영역이다. 인공지능을 가진 컴퓨터들이 설계 목적으로 하는 활동들 중 일부는 학습을 포함한다. 인공지능 알고리즘의 예들은, 이에 제 한되는 것은 아니지만, 핵심 학습, 배우 비평가 방법, 강화, 심화 결정론적 정책 그라디언트(DDPG: deep deterministic policy gradient), 멀티-에이전트 심화 결정론적 정책 그래디언트(MADDPG: multi-agent deep deterministic policy gradient) 등을 포함한다. 머신러닝은 인간의 지식의 기술적 발전에 맞춰지는 인공지능 (AI) 분야를 지칭한다. 머신러닝은 새로운 시나리오, 테스트 및 적응에 대한 노출을 통해 컴퓨팅의 지속적인 발전을 촉진하는 한편, 개 선된 결정과, 동일하지는 않지만 후속 상황을 위해, 패턴 및 추세 검출을 사용한다. 컴퓨터 시스템은 머신러닝 (ML) 알고리즘 및 통계 모델을 사용하여 명시적인 명령들을 사용하지 않고도, 그 대신에 패턴 및 추론에 의존하 여 특정 작업을 효과적으로 수행할 수 있다. 머신러닝 알고리즘들은 작업을 수행하도록 명시적으로 프로그램되 지 않고도 예측 또는 의사결정을 내리기 위해 \"훈련 데이터\"라고 하는 샘플 데이터를 기반으로 수학적 모델을 구축한다. 머신러닝 알고리즘들은 작업을 수행하기 위한 특정 명령들의 알고리즘을 개발하는 것이 불가능할 때 사용될 수 있다. 예를 들어, 지도 학습 알고리즘들은 입력과 원하는 출력을 모두 포함하는 데이터 세트의 수학적 모델을 구축한 다. 데이터는 훈련 데이터로 알려져 있으며 훈련 예들의 세트로 구성된다. 각각의 훈련 예들은 하나 이상의 입 력들 및 지도(supervisory) 신호로도 알려진 원하는 출력을 갖는다. 반-지도 학습 알고리즘들의 경우, 일부 훈 련 예들에서는 원하는 출력이 누락된다. 수학적 모델에서, 각각의 훈련 예는 배열 또는 벡터로 표현되고, 훈련 데이터는 행렬로 표현된다. 목적 함수의 반복된 최적화를 통해 지도 학습 알고리즘들은 새 입력과 연관된 출력 을 예측하는 데 사용될 수 있는 함수를 학습한다. 최적화 함수는 알고리즘이 훈련 데이터의 일부가 아닌 입력에 대한 출력을 정확하게 결정하게 할 것이다. 시간에 따라 출력 또는 예측의 정확도를 향상시키는 알고리즘은 해 당 작업을 수행하도록 학습되었다고 지칭된다. 지도 학습 알고리즘들은 분류 및 회귀를 포함한다. 분류 알고리 즘들은 출력이 제한된 값들의 세트로 제한될 때 사용되며, 회귀 알고리즘들은 출력이 범위 내의 임의의 숫자 값 을 가질 수 있는 경우 사용된다. 유사도 학습은 회귀 및 분류와 밀접하게 관련된 지도 머신러닝의 영역이지만, 그의 목표는 두 오브젝트가 얼마나 유사하거나 관련되는지를 측정하는 유사도 함수를 사용하여 예들로부터 배우는 것이다. 강화 학습은 누적 보상의 개념을 최대화하기 위해 소프트웨어 에이전트가 환경에서 어떻게 조치를 취해야 하는 지에 관련된 머신러닝 영역이다. 이 분야는 일반성으로 인해, 게임 이론, 제어 이론, 운영 연구, 정보 이론, 시 뮬레이션 기반 최적화, 멀티 에이전트 시스템, 스웜(swarm) 지능, 통계 및 유전자 알고리즘과 같은 많은 분야에 서 연구되고 있다. 머신러닝에서, 환경은 대개, 마르코프 결정 프로세스(MDP: Markov Decision Process)로 표현 된다. 많은 강화 학습 알고리즘들은 동적 프로그래밍 기술을 사용한다. 강화 학습 알고리즘들은 MDP의 정확한 수학적 모델에 대한 지식을 가정하지 않으며, 정확한 모델이 실현 불가능할 때 사용된다. 예측 모델링 및 기타 유형의 데이터 분석에서, 하나의 데이터 샘플을 기반으로 하는 단일 모델은 분석 결과의 신뢰도에 영향을 줄 수 있는 바이어스, 높은 변동성 또는 명백한 부정확성을 가질 수 있다. 상이한 모델들을 조 합하거나 다수의 샘플들을 분석함으로써, 더 나은 정보를 제공하도록 이러한 제한들의 효과들이 감소될 수 있다. 이와 같이, 앙상블 방법들은 구성 학습 알고리즘들 중 임의의 알고리즘으로부터 획득될 수 있는 것보다 더 양호한 예측 성능을 얻기 위하여 다수의 머신러닝 알고리즘들을 사용할 수 있다. 앙상블은, 훈련될 수 있고 예측하는 데 사용될 수 있기 때문에 지도 학습 알고리즘이다. 따라서 훈련된 앙상블 은 구축되는 모델들의 가설 공간에 반드시 포함될 필요가 없는 단일 가설을 나타낸다. 따라서, 앙상블들은 그들 이 표현할 수 있는 함수들에서 더 많은 유연성을 갖는 것으로 보일 수 있다. 앙상블 모델은 예측이 조합되는 개 별적으로 훈련된 분류기들의(신경망 또는 의사결정 트리와 같음) 세트를 포함할 수 있다. 예를 들어, 앙상블 모델링의 한 가지 일반적인 예는 여러 의사결정 트리를 활용하고 다른 변수 및 규칙을 기반 으로 결과를 예측하도록 설계된 분석 모델의 유형인 랜덤 포레스트 모델이다. 랜덤 포레스트 모델은, 상이한 샘 플 데이터를 분석하고, 상이한 인자들을 평가하거나 또는 공통 변수들에 상이하게 가중치를 두는, 의사결정 트 리들을 혼합한다. 이어서, 다양한 결정 트리들의 결과들이 단순 평균으로 전환되거나 추가적인 가중치를 통해 집계된다. Hadoop 및 다른 빅데이터 기술의 출현으로 더 많은 양의 데이터를 저장 및 분석할 수 있게 되었고, 이로 인해 분석 모델을 상이한 데이터 샘플에 대해 실행할 수 있다. 구현예에 따라 임의의 개수의 머신러닝 모델을 조합하여 앙상블 모델을 최적화할 수 있다. 머신러닝 모델에서 구현될 수 있는 머신러닝 알고리즘 또는 모델의 예는 선형 회귀, 로지스틱 회귀, 및 K-평균 클러스터링과 같은 회귀 모델, 하나 이상의 결정 트리 모델(예를 들어, 랜덤 포레스트 모델), 하나 이상의 서포트 벡터 머신, 하나 이상의 인공 신경망, 하나 이상의 딥러닝 망(예를 들어, 적어도 하나의 순환 신경망, 딥 러닝을 이용한 시퀀스 대 시퀀스 맵핑, 딥 러닝을 이용한 시퀀스 인코딩 등), 퍼지 논리 기반 모델, 유전자 프로그래밍 모델, 베이지 안(Bayesian) 네트워크 또는 다른 베이지안 기술, 확률적 머신러닝 모델, 가우시안 프로세싱 모델, 히든 마르코 프 모델, 자기회귀 이동 평균(ARMA) 모델, 자기회귀적 통합 이동 평균(ARIMA) 모델, 자기회귀 조건부 이분산 (ARCH) 모델과 같은 시계열 모델, 일반화된 자기회귀 조건부 이분산(GARCH) 모델, 이동 평균(MA) 모델 또는 기 타 모델, 그리고 위의 임의의 것의 경험적으로 유도된 조합 등을 포함할 수 있지만, 이들로 제한되지 않는다. 머신러닝 알고리즘의 타입들은 접근 방식, 입력 및 출력 데이터 타입, 해결하려는 작업 또는 문제 유형에 따라 다르다. 히든 마르코프 모델(HMM: Hidden Markov model)은 모델링되는 시스템이 관찰되지 않은(은닉) 상태를 갖는 마르 코프 프로세스로 가정되는 통계적 마르코프 모델이다. HMM은 가장 단순한 동적 베이지안 네트워크로 간주될 수 있다. 베이지안 네트워크, 신뢰 네트워크(belief network) 또는 유향 비순환(directed acyclic) 그래픽 모델은 방향이 있는 비순환 그래프(DAG: directed acyclic graph)를 이용하여 그들의 조건부 독립성 및 랜덤 변수들의 세트를 나타내는 확률적 그래픽 모델이다. 변수들의 시퀀스들을 모델링하는 베이지안 네트워크는 동적 베이지안 네트워크라고 한다. 불확실성 하에서 의사 결정 문제를 표현하고 해결할 수 있는 베이지안 네트워크의 일반화를 영향 관계도라고 한다. 서포트 벡터 머신(SVM)(서포트 벡터 네트워크로도 알려져 있음)은 분류 및 회귀에 사용되는 관련된 지도 학습 방법들의 세트이다. 훈련 예들의 세트가 주어진 경우, 각각은 2개의 카테고리들 중 하나에 속하는 것으로 표시 되고, SVM 훈련 알고리즘은 새로운 예가 특정 카테고리 또는 다른 카테고리에 속하는지를 예측하는 모델을 구축 한다. SVM 훈련 알고리즘은 비-확률적, 2진, 선형 분류기이다. 선형 분류를 수행하는 것 외에도, SVM은 커널 트 릭이라고 하는 것을 사용하여 비선형적인 분류를 효율적으로 수행할 수 있으며, 그들의 입력을 고차원 특징 공 간으로 암묵적으로 맵핑한다. 의사결정 트리 학습은 예측 모델로서, 항목(분기로 표시됨)에 대한 관찰로부터 항목의 목표 값(리프(leaves)로 표시됨)에 대한 결론으로 이어지는 의사결정 트리를 사용한다. 목표 변수가 개별 값들의 세트를 취할 수 있는 트리 모델은 분류 트리라고 하는데, 이러한 트리 구조에서 리프는 클래스 레이블을 나타내며, 분기는 해당 클래 스 레이블로 이어지는 특징들의 연결(conjunction)을 나타낸다. 목표 변수가 연속적인 값(일반적으로 실수)을 취할 수 있는 의사결정 트리를 회귀 트리라고 한다. 의사 결정 분석에서, 결정 트리는 결정들 및 의사 결정을 시각적으로 그리고 명시적으로 표현하는 데에 사용될 수 있다. 딥러닝 알고리즘들은 다중 비선형 변환으로 구성된 모델 아키텍처를 사용하여 고수준 추상 및 데이터를 모델링 하는 데 사용되는, 머신러닝에 사용되는 알고리즘들의 컬렉션을 지칭할 수 있다. 딥러닝은 신경망을 구축하고 훈련하는 데 사용되는 구체적인 접근법이다. 딥러닝은 인공신경망 내의 여러 은닉층들로 구성된다. 딥러닝 알고 리즘의 예들은, 예를 들어, Siamese 네트워크, 전이 학습, 순환 신경망(RNN), 장단기 메모리(LSTM) 네트워크, 컨볼루션 신경망(CNN), 변환기 등을 포함할 수 있다. 예를 들어, 딥러닝 접근법은 장단기 메모리(LSTM) 및 게이 트 순환 유닛(GRU)과 같은 순환 신경망(RNN)을 이용할 수 있다. RNN(및 변형들)을 사용하는 시계열 예측을 위한 하나의 신경망 아키텍처는 자동 인코더로서 작용하는 자기회귀적(autoregressive) seq2seq 신경망 아키텍처다. 일부 실시예들에서, 앙상블 모델은 하나 이상의 딥러닝 알고리즘들을 포함할 수 있다. 임의의 수의 상이한 머신 러닝 기술이 또한 이용될 수 있음에 유의해야 한다. 구현예에 따라, 앙상블 모델은, 부트스트랩 집계 앙상블 알 고리즘(배깅(bagging) 분류기 방법으로도 지칭됨), 부스팅 앙상블 또는 분류기 알고리즘, 스태킹(stacking) 앙 상블 알고리즘 또는 분류기, 모델 버킷(bucket of models) 앙상블 알고리즘, 베이즈 최적 분류기 알고리즘, 베 이지안 파라미터 평균 알고리즘, 베이지안 모델 조합 알고리즘 등으로서 구현될 수 있다. 종종 배깅(bagging)으로 약칭되는 부트스트랩 집계는 각각의 모델이 앙상블 투표에서 동일한 가중치를 갖는 것 을 포함한다. 모델 분산을 촉진하기 위해 배깅은 훈련 세트의 무작위로 인출된 서브세트를 사용하여 앙상블에서 의 각각의 모델을 훈련시킨다. 일 예로서, 랜덤 포레스트 알고리즘은 매우 높은 분류 정확도를 달성하기 위해 랜덤 결정 트리와 배깅(bagging)을 조합한다. 배깅 분류기 또는 앙상블 방법은 각각의 분류기를 훈련 세트의 무 작위 재분배에 대해 훈련시킴으로써 해당 앙상블에 대한 개별 분류기들을 생성한다. 각각의 분류기의 훈련 세트 는 N개의 예들(여기서, N은 원래의 훈련 세트의 크기임)을 교체 가능하게 무작위로 인출함으로써 생성될 수 있 는데, 원래의 예들의 다수가 결과적인 훈련 세트 내에서 반복될 수 있는 반면, 다른 것들은 제외될 수 있다. 앙 상블의 각각의 개별 분류기는 훈련 세트의 상이한 무작위 샘플링을 이용하여 생성된다. 배깅은 훈련 세트의 작 은 변화가 예측에서 큰 변화를 가져오는 \"불안정한\" 학습 알고리즘(예를 들어, 신경망 및 의사결정 트리)에 효 과적이다. 대조적으로, 부스팅은 이전 모델이 잘못 분류한 훈련 인스턴스를 강조하도록 각각의 새로운 모델 인스턴스를 훈 련시킴으로써 앙상블을 점진적으로 구축하는 것을 포함한다. 일부 경우에, 부스팅은 배깅(bagging)보다 더 양호 한 정확도를 제공하는 것으로 나타났지만, 또한 훈련 데이터에 오버-핏(over-fit)하는 경향이 있다. 부스팅 분 류기는 분류기들의 시리즈를 생성하는 데 사용될 수 있는 방법들의 패밀리를 지칭할 수 있다. 시리즈의 각각의 멤버에 사용되는 훈련 세트는 시리즈의 이전 분류기(들)의 성능을 기반으로 선택된다. 부스팅에서, 시리즈의 이 전의 분류기에 의해 부정확하게 예측되는 예들은 정확하게 예측된 예들보다 더 자주 선택된다. 따라서, 부스팅 은 현재 앙상블의 성능이 좋지 않은 예들을 더 잘 예측할 수 있는 새로운 분류기를 생성하도록 시도한다. 부스 팅의 일반적인 구현예는 Adaboost이지만, 새로운 알고리즘이 더 나은 결과를 얻기 위해 보고되고 있다. 스태킹(Stacking)(종종 스택 일반화로 지칭됨)은 여러 다른 학습 알고리즘들의 예측을 조합하기 위해 학습 알고 리즘을 훈련하는 것을 포함한다. 스태킹은 두 단계로 작동하는데, 여러 개의 기본 분류기를 사용하여 클래스가 예측된 다음, 일반화 오류를 줄이기 위해 새 학습자를 사용하여 예측이 결합된다. 먼저, 이용 가능한 데이터를 사용하여 다른 알고리즘들 모두가 훈련되고, 그 다음, 다른 알고리즘들의 모든 예측들을 추가적인 입력들로서 이용하여 최종 예측을 수행하도록 결합기 알고리즘이 훈련된다. 임의의 결합기 알고리즘이 사용되는 경우, 스태 킹은 이론적으로 본 문헌에 기술된 앙상블 기술들 중 임의의 것을 나타낼 수 있지만, 실제로는 로지스틱 회귀 모델이 결합기로서 종종 사용된다. \"모델 버킷(bucket of models)\"은 각 문제점에 대해 최상의 모델을 선택하기 위해 모델 선택 알고리즘이 사용되 는 앙상블 기술이다. 하나의 문제만을 이용하여 테스트될 경우 모델의 버킷은 세트 내의 최상의 모델보다 더 나 은 결과를 생성할 수 없지만 여러 문제들에 걸쳐 평가될 때에는 대개, 해당 세트의 임의의 모델보다 평균적으로 훨씬 더 좋은 결과를 생성한다. 모델 선택에 사용되는 하나의 일반적인 접근법은 교차 검증 선택이다(종종 \"베 이크-오프 콘테스트(bake-off comtest)\"라고 불림). 교차 검증 선택은, 훈련 세트를 사용하여 모두 시도해보고"}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "가장 잘 동작하는 것을 선택하는 것으로 요약될 수 있다. 게이팅(gating)은 교차 검증 선택을 일반화한 것이다.이는 버킷에 있는 모델 중 문제를 해결하기에 가장 적합한 모델을 결정하기 위해 다른 학습 모델을 훈련하는 것 을 포함한다. 종종, 게이팅 모델에 퍼셉트론(perceptron)이 이용된다. 이는 \"최상의\" 모델을 선택하는 데 사용 되거나, 버킷의 각 모델로부터의 예측에 선형 가중치를 부여하는 데 사용될 수 있다. 모델의 버킷이 문제들의 대규모 세트와 함께 사용되는 경우, 훈련하는 데 오랜 시간이 걸리는 일부 모델의 훈련을 피하는 것이 바람직할 수 있다. 랜드마크 학습은 이 문제를 해결하고자 하는 메타 학습 접근법이다. 이는 버킷에 있는 빠른(그러나 부 정확한) 알고리즘만 훈련하고, 이러한 알고리즘의 성능을 사용하여 가장 잘 수행하는 느린(그러나 정확한) 알고 리즘을 결정하는 것을 돕는 것을 포함한다. 베이즈 최적 분류기는 분류 기술이다. 이는 가설 공간에 있는 모든 가설들의 앙상블이다. 평균적으로, 어떠한 다른 앙상블도 이를 능가할 수 없다. 나이브 베이즈 최적 분류기는 데이터가 클래스에 조건부로 독립적이라고 가정하고 계산을 보다 실현 가능하게 하는 분류기의 일 버전이다. 각각의 가정에는 해당 가정이 참인 경우 훈련 데이터 세트가 시스템으로부터 샘플링될 가능성에 비례하는 투표가 제공된다. 유한한 크기의 데이터의 훈련을 용이하게 하기 위해, 각각의 가설의 투표는 또한 그 가설의 사전 확률과 곱해진다. 그러나, 베이즈 최적 분류기 에 의해 표현되는 가설은 앙상블 공간(모든 가능한 앙상블의 공간)에서의 최적의 가설이다. 베이지안 파라미터 평균화(BPA: Bayesian parameter averaging)는 가설 공간으로부터의 가설을 샘플링하고 베이 즈 법칙을 이용하여 이들을 조합함으로써 베이즈 최적 분류기를 근사화하고자 하는 앙상블 기술이다. 베이즈 최 적 분류기와는 달리, 베이지안 모델 평균화(BMA)는 실무적으로 구현될 수 있다. 전형적으로, 가설은 MCMC와 같 은 몬테 카를로(Monte Carlo) 샘플링 기술을 이용하여 샘플링된다. 예를 들어, 분포를 나타내는 가설을 도출하 기 위해 깁스 샘플링이 사용될 수 있다. 특정 상황 하에서, 가설들이 이러한 방식으로 도출되고, 베이즈 법칙에 따라 평균화되는 경우, 이 기술은 베이즈 최적 분류기의 예측 오차의 최대 두 배로 제한되는 예측 오차를 갖는 것으로 나타났다. 베이지안 모델 조합(BMC: Bayesian model combination)은 베이지안 모델 평균화(BMA)에 대한 알고리즘 교정이 다. 앙상블의 각 모델을 개별적으로 샘플링하는 대신, 이는 가능한 앙상블의 공간으로부터(균일한 파라미터를 갖는 Dirichlet 분포로부터 무작위로 도출되는 모델 가중치들을 이용하여) 샘플링한다. 이러한 변형은 BMA가 단 일 모델에 모든 가중치를 부여하는 쪽으로 수렴하는 경향을 극복한다. BMC는 BMA보다 계산적으로 다소 비싸지만, 훨씬 더 좋은 결과를 산출하는 경향이 있다. BMC로부터의 결과는 BMA 및 배깅(bagging)보다 평균적으 로(통계적 유의성 있음) 양호한 것으로 나타났다. 모델 가중치를 계산하기 위해 배이즈 법칙을 사용하는 것은 각 모델에 주어진 데이터의 확률을 계산하는 것을 필요로 한다. 일반적으로 앙상블의 모델들 중 어느 모델도 훈 련 데이터가 생성되는 분포와 정확히 일치하지는 않으므로, 이들 모두는 이 항에 대해 0에 가까운 값을 정확하 게 수신한다. 이는 전체 모델 공간을 샘플링할 수 있을 정도로 앙상블이 충분히 큰 경우에는 잘 작동하지만 이 러한 경우는 거의 불가능하다. 결과적으로, 훈련 데이터 내의 각각의 패턴은 앙상블 가중치로 하여금 훈련 데이 터의 분포에 가장 가까운 앙상블의 모델 쪽으로 이동하게 할 것이다. 이것은 본질적으로 모델 선택을 수행하기 위한 불필요하게 복잡한 방법으로 감소한다. 앙상블에 대한 가능한 가중치들은 심플렉스 위에 놓여 있는 것으로 시각화될 수 있다. 심플렉스의 각 꼭지점에서, 모든 가중치는 앙상블의 단일 모델에 제공된다. BMA는 훈련 데이 터의 분포에 가장 가까운 꼭지점 쪽으로 수렴한다. 대조적으로, BMC는 이러한 분포가 심플렉스 상으로 투영하는 지점 쪽으로 수렴한다. 즉, 생성 분포에 가장 가까운 하나의 모델을 선택하는 대신에, 생성 분포에 가장 가까운 모델들의 조합을 추구한다. BMA의 결과는 종종 모델의 버킷으로부터 최상의 모델을 선택하기 위해 교차 검증을 사용함으로써 근사화될 수 있다. 마찬가지로, BMC로부터의 결과들은 가능한 가중치들의 무작위 샘플링으로부터 최상의 앙상블 조합을 선택하기 위해 교차 검증을 사용함으로써 근사화될 수 있다. 다시 도 1을 참조하면, 표준화된 구조화된 데이터의 분석에 기초하여, 플랫폼은 복수의 개별 사용자 각각 에 대한 개인화된 식이 및 건강 권고 또는 추천을 더 생성할 수 있다. 데이터는 API 게이트웨이를 사용하여 플랫폼에 연결함으로써 플랫폼으로 들어갈 수 있다. 따라서, 데이터 는 API 게이트웨이를 통해 플랫폼에 접속하는 복수의 애플리케이션 프로그래밍 인터페이스(API)를 통해 복수의 상이한 소스로부터 수집 및 집계될 수 있다. 데이터는 자율 함수를 사용하여 플랫폼에 집계, 처리 및 저장될 수 있으며, 이는 들어오는 데이터가 플랫폼 내의 상이한 모듈 또는 구성요소를 통해 스트리밍될 때 트리거된다. 플 랫폼 내의 구성요소/모듈은 서로 분리되어, 유지보수, 업데이트 및 재사용성의 용이성을 보장할 수 있다. 플랫 폼에 의한 데이터 처리는 기저의 API에 대한 변경이나 업데이트의 영향을 받지 않는다. 플랫폼에서 서버리스 아 키텍처를 사용하면 기저의 API에 대한 변경 또는 업데이트가 수행될 때 데이터 손실 없이 데이터를 처리할 수 있다.플랫폼은 실시간으로 또는 거의 실시간으로 대량의 스트리밍 데이터를 처리하도록 구성될 수 있다. 일부 실시예들에서, 플랫폼은 복수의 상이한 소스들로부터 데이터를 수집, 집계 및 처리할 수 있다. 데이터는 하루에 걸쳐 균등하게 또는 고르지 않게 분포되는 일별 적어도 106개 정도의 데이터 포인트를 포함할 수 있다. 데이터 의 일부는 밀리초 정도로 API 게이트웨이로부터 검색될 수 있다. 일부 경우에, 플랫폼은 실시간으로 처리 될 수 없는 벌크 데이터를 수신할 수 있다. 플랫폼은 대규모 데이터 볼륨의 분석을 허용하도록 구성된 파일 형 식(예: Parquet)으로 데이터를 출력할 수 있다. 도 2는 일부 실시예들에 따른 플랫폼의 블록도를 도시한다. 플랫폼은 토큰 모듈, 검색 모듈, 파 이프라인 모듈, 표준화 모듈, 및 저장 모듈을 포함할 수 있다. 모듈들은 데이터를 인증, 다이렉 트, 저장 또는 처리할 수 있는 함수들, 저장 유닛들, 또는 애플리케이션들의 그룹들을 나타낼 수 있다. 데이터 는 모듈들을 직렬로 통과할 수 있지만, 각각의 구성요소 내에 제공되는 자율 함수들은 직렬 또는 병렬 방식으로 배열될 수 있다. 플랫폼에 연결된 API는 인증될 수 있고 토큰 모듈을 사용하여 권한 허가될 수 있다. 검색 모듈은 연결된 애플리케이션들로부터 데이터를 검색하도록 구성될 수 있다. 파이프라인 모듈은 추가 적인 처리 또는 저장을 위해 데이터를 호스트 및 써드파티 애플리케이션에 다이렉트하도록 구성될 수 있다. 표 준화 모듈은 데이터를 처리하고 데이터를 표준화된 구조화된 형식으로 변환할 수 있다. 표준화된 구조화된 데이터는 플랫폼 내에서, 예를 들어, 본원에 기술된 하나 이상의 머신러닝 모델을 사용하여 더 분석될 수 있다. 대안적으로, 표준화된 구조화된 데이터는 분석을 위해 하나 이상의 써드파티 애플리케이션으로 내보내질 수 있 다. 마지막으로, 저장 모듈은 처리된 데이터를 저장하고, 수동 데이터 수집을 모니터링하며, 상이한 타입 의 분석을 위해 사용될 데이터를 준비시킬 수 있다. 토큰 모듈은 외부 API들 및 데이터 서비스들을 통합할 수 있고, 이들 외부 API들을 인증하고 권한 부여하 는 것을 담당한다. 토큰 모듈은 써드파티 애플리케이션들을 인증할 때 토큰 모듈로서 그 자신을 나타내거 나 나타내지 않을 수 있다. 예를 들어, 토큰 모듈은 외부 API들 및 데이터 서비스들과 통신할 때, 그 자체 를 플랫폼으로서 또는 써드파티 애플리케이션들로부터 데이터를 수집하는 상이한 서비스로서 나타낼 수 있 다. 이것은 토큰 모듈이 자신의 ID들을 그대로 유지하면서 써드파티 애플리케이션들에 의한 서비스들을 익 명화하는 것을 허용할 수 있다. 따라서, 토큰 모듈은 상이한 엔티티들(예를 들어, 회사들)에 의해 제공되는 하 나 이상의 써드파티 애플리케이션들에 대한 액세스를 관리하기 위해 사용될 수 있다. 토큰 모듈은 토큰들을 생성, 갱신 및 삭제할 수 있다. 토큰 모듈은 기존 토큰을 새로 고치고 토큰 변경에 대한 알림 업데이트를 제공할 수 있다. 토큰 모듈에 의해 생성된 토큰들은 복제될 수 있고, 토큰 모듈로부 터 분리되고 독립적인 검색 모듈로 전송될 수 있다. 새로운 토큰이 생성될 때마다, 새로운 토큰은 토큰 모듈에 저장되는 것에 더하여, 검색 모듈에서 개별적으로 복제될 수 있다. 생성된 토큰들은 만기 날짜를 가질 수 있다. 허가를 유지하기 위해, 토큰 모듈은 스케줄에 기초하여 검색 모듈에 토큰들을 발행할 수 있다. 일부 실시예들에서, 검색 모듈은, 필요한 토큰들을 갖지 않거나 또는 토큰들이 적절하게 동작하지 않는 경우, 토큰 모듈에 간단한 알림 서비스를 이용하여 메시지를 전송할 수 있다. 토큰 모듈은 외부 API들을 통합하기 위해 OAuth를 사용할 수 있다. 사용자는 플랫폼을 사용하여 애플 리케이션에 로그인할 수 있다. 플랫폼의 API를 사용하여, 애플리케이션은 사용자와 하나 이상의 추가적인 써드 파티 애플리케이션 사이의 인증 프로세스를 개시하도록 요청할 수 있다. 사용자가 하나 이상의 써드파티 애플리 케이션들에 의해 인증될 때, 플랫폼을 사용하는 애플리케이션은 플랫폼 상에 저장되는 액세스 토큰을 수신 한다. 인증 프로세스는 OAuth 1.0 또는 OAuth 2.0을 사용할 수 있다. 검색 모듈은 플랫폼에 연결된 API들로부터 데이터를 검색할 수 있다. 검색 모듈은 플랫폼이 다 수의 타입의 애플리케이션들, 웨어러블 장치들, 모바일 장치들, 의료 장치들, 데이터 세트들, 데이터 소스들과 통합하기 위한 허브로서 기능할 수 있다. 검색 모듈은 다양한 장치들과 인터페이스할 수 있고 데이터를 수신할 수 있다. 데이터는 대응하는 애플리케이션에 의해 일반적으로 내보내지는 형태로 수신될 수 있다. 검색 모듈 은 다수의 상이한 애플리케이션들로부터의 데이터를 스트림으로 통합할 수 있는 프로세싱 함수들의 세트를 포함할 수 있다. 데이터는 비동기 방식으로 통합될 수 있으며, 고정된 기간 동안 스트림에서 지속될 수 있다. 데이터가 수신되고 스트림으로 통합된 후에는 처리를 위해 다른 모듈에 대한 데이터 패키지로서 다이렉트될 수 있다. 검색 모듈은 다른 모듈들로부터 분리되고 독립적일 수 있다. 예를 들어, 검색 모듈은 데이터를 수집 및 집계하도록만 구성될 수 있고, 데이터를 지속, 저장 또는 처리하도록 구성되지는 않을 수 있다. 검색 모듈은 데이터를 인출(pull)하고, 푸시된 데이터를 수신하도록 구성될 수 있다. 데이터는 연결된 API 들로부터 직접 수집되거나 모바일 장치들로부터 수신될 수 있다. 이러한 실시예들에서, 모바일 장치 애플리케이션들로부터의 데이터는 AMAZON® S3 버킷과 같은 버킷 오브젝트에 저장될 수 있다. 푸시되고 인출된 데이터는 동시에 또는 상이한 시간에 수신될 수 있다. 수신된 푸시되고 인출된 데이터는 데이터 스트림들로 이동될 수 있 다. 데이터는 다양한 스테이지들에서의 프로세싱 함수들을 사용하여 플랫폼 내의 상이한 모듈들로 전송될 수 있 다. 데이터 스트림은 데이터 레코드들의 큐인 데이터 샤드(shard)를 포함할 수 있다. 샤드 수를 변경하면 데이 터가 처리되는 속도가 변경될 수 있다. 따라서, 플랫폼은 스트림들 내의 샤드들의 수를 제어함으로써, 데이터가 처리되고 있는 속도를 제어할 수 있다. 각 데이터 스트림은 데이터가 스트림에서 지속되는 기간을 지시하는 보 존 정책을 가질 수 있다. 일부 실시예들에서, 데이터는 24시간 내지 168시간 범위의 기간 동안 유지될 수 있다. 각 샤드는 큐에 들어가고 보존 정책이 만료되면 큐를 빠져나가는, 데이터 레코드들의 문자열을 포함할 수 있다. 보존 기간 내의 어느 시점에서나 큐의 이전 데이터 레코드들을 볼 수 있으며, 스트림이 이전 히스토리 상태로 반복될 수 있다. 이 기간이 만료되면 데이터 레코드들이 큐를 빠져나갈 수 있다. 개별 서비스는 한 타입 으로부터 데이터를 푸시할 수 있고, 검색 모듈에 의해 인출되는 다른 타입의 데이터를 가질 수 있다. 일부 실시예들에서, 데이터 레코드들의 문자열은 복수의 개별 사용자들에 특이적인 음식 소비, 건강 또는 영양 기록 들을 포함할 수 있다. 애플리케이션들로부터의 데이터 인출은 주기적으로 시간 기반 작업 스케줄러에 의해 수행 될 수 있다. 데이터가 플랫폼 내로 인출될 수 있는 애플리케이션들의 예들은 Withings와 같은 써드파티 애 플리케이션들을 포함할 수 있다. 검색 모듈은 또한 데이터를 플랫폼으로 푸시하는 애플리케이션들로부터 데이터를 검색할 수 있다. 플랫폼 으로 데이터를 푸시할 수 있는 서비스들 및 장치들의 예들은 Abbott FreeStyle Libre, Garmin, FitBit 등을 포 함할 수 있다. 이러한 장치들은 검색 모듈에 의해 수신될 수 있는 알림들을 플랫폼에 전송할 수 있다. 이에 응답하여, 검색 모듈은 이러한 애플리케이션들로부터 데이터를 인출할 수 있고, 데이터를 스트 림 또는 복수의 스트림들로 통합/저장할 수 있다. 일부 경우에, 데이터는 알림과 동시에 플랫폼으로 전송될 수 있고, 따라서, 검색 모듈이 그에 응답으로 데이터를 인출할 필요성이 없어진다. 일부 실시예들에서, 검색 모듈은 또한 토큰 모듈에 의해 생성된 토큰들을 저장할 수 있다. 토큰들은 검색 모듈과 함께 제공된 서버리스 데이터베이스에 저장될 수 있다. 파이프라인 모듈은 플랫폼을 통한 데이터의 흐름을 제어할 수 있다. 파이프라인 모듈은, Welltok, Medtronic 등을 포함할 수 있는 써드파티 애플리케이션들로의 데이터 전송을 용이하게 할 수 있다. 파 이프라인 모듈은 또한 플랫폼 내의 스트리밍 애플리케이션들로 데이터를 전송할 수 있다. 데이터는 이벤트 들에 반응하여 트리거되는 자율 함수들을 사용하여 전송될 수 있다. 이벤트들은 객체를 생성하고, SNS 메시지와 같은 알림 메시지를 수신하는 것을 포함할 수 있다. 일부 실시예들에서, 파이프라인 모듈은 AMAZON® Lambda 함수들 및 AMAZON® S3 버킷들을 이용하여 AMAZON® Kinesis 스트림에 의해 구현될 수 있다. Kinesis는 이벤트들에 응답하여, 플랫폼 내의 다양한 자원들로 데이터를 다이렉트시키는 Lambda 함수들을 트리거할 수 있 다. 이벤트는 스트림 내의 데이터 샤드의 수신일 수 있다. 표준화 모듈은 써드파티 애플리케이션들에 의해 판독될 수 있거나 표준화된 데이터 파일에 대해 수행된 분 석을 갖는 표준화된 통합된 구조화된 데이터 파일을 생성함으로써, 플랫폼을 통해 데이터 스트리밍을 관리 및 처리할 수 있다. 표준화 모듈은 데이터 스트림 상에서 상이한 프로세싱 함수들을 구현할 수 있는 구성 요소들의 세트를 포함할 수 있다. 프로세싱 함수들은 정렬하는 것, 데이터를 다른 형식으로 변환하는 것, 및 중 복 데이터를 제거하는 것을 포함할 수 있다. 처리된 데이터 스트림들은 저장되거나, 캐시되거나, 또는 추가적인 데이터 스트림들로 보내질 수 있다. 저장 모듈은 플랫폼의 수동적 데이터 수집 활동들을 관리할 수 있다. 데이터 수집 활동들의 관리는, 스트 리밍된 데이터를 분석하고, 분류하고, 저장하는 것뿐만 아니라, 수동적 데이터 수집 SDK에 의해 인출된 스트리 밍된 데이터의 로그들을 유지하는 것을 포함할 수 있다. 저장 모듈은 모바일 장치들 상에서 연결된 애플리 케이션들 또는 네이티브 애플리케이션들로부터 인출된 데이터에 대한 분석을 자동으로 수행할 수 있다. 모바일 장치 카메라는 수동적으로 이미지 데이터를 수집할 수 있으며, 이는 수동적 데이터 수집 소프트웨어 개발 키트 (SDK: software development kit)에 의해 스토리지 모듈에 푸시될 수 있다. 저장 모듈은 신경망을 이용하여 구축된 2진 분류기를 이용하여, 음식 항목을 포함하거나 음식 항목을 포함하지 않는 이미지들을 분류 할 수 있다. 이 데이터는 분석 전에 전처리되거나 암호화될 수 있다. 이어지는 도면 설명들에서, 플랫폼 내의 각각의 모듈은 하나 이상의 구성요소들을 포함하는 것으로 설명될 수 있다. 이러한 구성요소들은 작업을 수행하기 위한 그룹으로서 구성되고 논리적으로 연결되는, 하나 이상의 자율 함수들, 데이터 스트림들, 스트리밍 애플리케이션들, 스토리지 버킷들, 또는 다른 구성요소들의 그룹들을 각각 포함할 수 있다. 플랫폼을 통해 스트리밍되는 데이터는 이러한 그룹들 내에서 하나 이상의 자율 함수들을 트리거링할 수 있다. 예를 들어, AMAZON® Lambda 함수는 AMAZON® Kinesis 데이터 스트림 또는 AMAZON® A3 이벤트를 이용하여 트리거될 수 있다. 예를 들어, Kinesis는 스트림에서 새 레코드를 발견할 때 Lambda 함수 를 트리거할 수 있다. 함수들은 또한 DynamoDB 테이블에 기록된 레코드에 응답하여 트리거될 수 있다. AMAZON® Lambda는 새로운 레코드가 언제 이용 가능한지를 판단하기 위해 이러한 소스들을 폴링(poll)할 수 있다. 도 3은 일부 실시예들에 따른 토큰 모듈의 구성요소들을 도시한다. 토큰 모듈은 인증 및 토큰 생성 구성요소, 토큰 리프레시 구성요소, 및 토큰 저장 구성요소를 포함할 수 있다. 인증 및 토큰 생성 구성요소는 외부 API와 통신할 수 있다. 인증 및 토큰 생성 구성요소는 URL에서 연결 요청들을 수신하고 요청들을 저장할 수 있다. 토큰들은 사용자 액세스 토큰일 수 있다. 토큰들은 만기 날짜, 권 한 및 식별자를 포함할 수 있다. 일부 실시예들에서, 요청들은 테이블에 저장될 수 있다. 인증 및 토큰 생성 구 성요소는 또한 허가 URL을 유지할 수 있다. 사용자에게 권한이 부여된 후 콜백 함수는 사용자를 권한 부여 URL 로 리턴시킬 수 있다. 외부 API가 인증되고 권한 허가되면, 인증 및 토큰 생성 구성요소는 토큰 모듈에 저 장된 토큰을 발행할 수 있다. 또한 토큰들은 테이블에 저장될 수 있다. 또한, 인증 및 토큰 생성 구성요소는 토 큰들을 복제하고, 복제된 토큰을 수신 모듈에 전송할 수 있다. 토큰의 만료일과 같은 토큰 정보는 토큰과 함께 수신 모듈로 복사될 수 있다. 토큰들은 또한 그들이 만료될 때 구성요소를 사용하여 삭제될 수 있다. 토큰 리프레시 구성요소는 주기적으로 실행되고, 기존 토큰들의 만료 날짜들을 검사하며, 곧 만료될 토큰 들을 리프레시하는 스케줄링 구성요소일 수 있다. 토큰 리프레시 구성요소는 토큰들에 대한 가입자들을 업 데이트할 수 있다. 알림은 토큰 상태의 변경사항에 대한 업데이트를 제공할 수 있다. 토큰 리프레시 구성요소는 예를 들어, 간단한 알림 서비스를 이용하여 구성요소들을 업데이트할 수 있다. 토큰 저장 구성요소는 플랫 폼 내의 토큰들의 기록을 유지할 수 있다. 토큰들이 생성되거나 리프레시될 때, 이들은 토큰 저장 구성요소 에 저장될 수 있다. 도 4는 일부 실시예들에 따른 수신 모듈의 구성요소들을 도시한다. 수신 모듈은 토큰 저장 구성요소 , 데이터 푸시 구성요소, 데이터 인출 구성요소, 및 데이터 통합 구성요소를 포함할 수 있 다. 토큰 저장 구성요소는 토큰 모듈에 의해 생성된 토큰들을 저장할 수 있다. 토큰 저장 구성요소는 또 한 토큰 모듈로부터 리프레시된 토큰들을 검색할 수 있다. 토큰 모듈이 API를 인증하는 경우, 이는 새로운 토큰을 생성하기 위해 검색 모듈에 메시지를 전송할 수 있다. 메시지는 토큰 정보를 포함할 수 있다. 생 성된 토큰은 테이블에 저장될 수 있다. 발행된 토큰들은 테이블에 저장될 수도 있다. 토큰 저장 구성요소 는 이미 저장된 토큰들을 업데이트하기 위해 토큰 모듈로부터 알림을 수신할 수 있다. 예를 들어, 토큰 저 장 구성요소는 토큰의 시간대 필드를 업데이트하기 위해 토큰 모듈로부터 명령을 수신할 수 있다. 토 큰 저장 구성요소는 기존의 곧 만료되는 토큰을 새로운 토큰으로 대체하기 위한 알림을 수신할 수 있다. 데이터 푸시 구성요소는 외부 API들이 데이터를 수신 모듈에 푸시하게 할 수 있다. 외부 API들은 API 게이트웨이를 이용하여 수신 모듈과 통신할 수 있다. 데이터 푸시 구성요소는 외부 API들로부터의 알 림들에 대해 구독(subscribe)할 수 있다. 데이터가 이용가능한 경우, 데이터 푸시 구성요소는 외부 API에 의해 푸시되는 데이터를 검색하도록 프롬프트될 수 있다. 이 데이터는 로컬에 저장될 수 있다. 수신 모듈 은 하나 이상의 저장 버킷들과 같은 하나 이상의 객체들에 미처리 응답 데이터를 저장할 수 있다. 데이터 인출 구성요소는 외부 API들로부터 데이터를 인출(pull)할 수 있다. 데이터는 스케줄에 기초하여, 검색 모듈에 저장된 유효한 토큰들을 갖는 API들로부터 인출될 수 있다. 데이터 인출 구성요소는 스 트리밍을 위해 이용가능한 모든 데이터를 제공하지는 않을 수 있다. 대신에, 데이터 인출 구성요소는 이 데이터의 부분적인 서브세트를 데이터 통합 구성요소에 제출할 수 있다. 데이터 통합 구성요소는 (a) 데이터 푸시 구성요소로부터의 푸시된 데이터 및 (b) 데이터 인출 구성 요소로부터 인출된 데이터를, 데이터 스트림들에 위치시킬 수 있다. 본원에서 사용되는 \"통합 (consolidation)\"이라는 용어는 써드파티 애플리케이션들로부터 수신된 데이터를 하나 이상의 데이터 스트림들 로 이동시키는 것을 포함할 수 있다. 데이터 통합 구성요소는 데이터 푸시 구성요소, 데이터 인출 구성요 소, 또는 이들 모두로부터 푸시 알림을 통해 데이터를 스트림들로 이동시키도록 프롬프트될 수 있다. 데이 터 통합 구성요소는 API로부터 히스토리 데이터(예를 들어, 이전 달로부터 수집된 데이터)를 검색하기 위 한 자율 함수를 포함할 수 있다. 예를 들어, 새로운 사용자가 플랫폼에 등록되는 경우, 히스토리 데이터 함수는한 번만 호출될 수 있다. 하나 이상의 데이터 스트림들로부터의 데이터의 일부는 로컬로 저장될 수 있다. 데이 터 통합 구성요소는 플랫폼 내의 다른 연결된 모듈들에 하나 이상의 데이터 스트림들을 제공할 수 있다. 도 5는 일부 실시예들에 따른 파이프라인 모듈의 구성요소들을 도시한다. 파이프라인 모듈은 데이터 스트림으로부터 애플리케이션들로 데이터를 전송하기 위한 구성요소 및 플랫폼 내에서 데이터를 전송 하기 위한 구성요소를 포함할 수 있다. 파이프라인은 파이프라인 설계 패턴을 활용할 수 있고, 직렬로 접속된 구성요소들의 그룹을 포함할 수 있다. 예시적인 구성요소들은 스트리밍된 데이터를 전송하는 데 사용되는 람다 함수들을 포함할 수 있다. 스트리밍된 데이터에 대해 동작하는 람다 함수들은 데이터를 제공하는 외부 API(들), 처리 속도, 및/또는 플랫폼 내의 다른 조건들에 따라 상이할 수 있다. 스트림으로부터 전달되는 데이터는, 플랫 폼의 2개 이상의 구성요소들이 동일한 데이터를 처리할 필요가 있는 경우에 복제될 수 있다. 도 6은 일부 실시예들에 따른 표준화 모듈의 구성요소들을 도시한다. 표준화 모듈은 원시 데이터 저 장 모듈, 데이터 정렬 모듈, 일기, 데이터 감소 모듈, 모니터링 모듈 및 변환 모듈 을 포함할 수 있다. 다른 실시예들에서, 표준화 모듈은 상이한 또는 부가적인 데이터 처리 구성요소 들을 포함할 수 있다. 구성요소들은 직렬로 배열될 수 있어서, 스트림은 저장 모듈에 의한 데이터 분석 또 는 저장을 위한 준비 동안에 연속적으로 다수의 구성요소들에 의해 단계적으로 처리될 수 있다. 데이터가 업데 이트되고 수신 모듈에 제공되는 경우, 표준화 모듈 내의 스트림들에 업데이트들이 반영될 수 있다. 원시 데이터 저장 모듈은 써드파티 애플리케이션들로부터 수집된 데이터를 저장할 수 있다. 저장되는 데이 터는 플랫폼 구성요소들에 의한 처리를 거치지 않은 \"원시(raw)\" 데이터일 수 있다. 이러한 데이터는 Apple Health Kit과 같은 모바일 장치들 상의 애플리케이션들로부터 수동적으로 수집될 수 있다. 원시 데이터는 원시 저장 모듈에 직접 저장될 수 있고, 토큰 모듈 및 검색기를 우회할 수 있다. 데이터 정렬 모듈은 파이프라인 모듈로부터 수신된 데이터를 정렬할 수 있다. 데이터는 사용자 ID, 데이터 타입, 또는 활동 타임스탬프에 의해 정렬될 수 있다. 정렬은 함수에 의해 호출될 수 있고 플랫폼상의 애 플리케이션 스트리밍을 사용하여 수행될 수 있다. 정렬된 데이터는 빠른 액세스를 위해 캐시될 수 있다. 정렬된 데이터는 쉽게 저장하거나 분석 도구로 로딩하기 위해 AMAZON® Kinesis Firehose stream과 같은 스트림 내에 배치될 수 있다. 정렬 후에, 데이터는 표준화 모듈 내의 다른 도구들을 사용하여 처리될 수 있다. 또한, 데이터 정렬 모듈은 캐시를 검사함으로써, 수신하는 데이터가 중복 데이터가 아니라는 것을 검증할 수 있 다. 일기는 써드파티 애플리케이션들에 의한 또는 최종 사용자들에 의한 소비를 위해 표준화된 처리된 데이터 를 저장할 수 있다. 일기는 수동으로 기록된 데이터 및 도출된 데이터를 저장할 수 있다. 수동으로 기록된 데이 터는 식사, 운동, 자가-보고된 감정, 수면 기간 및 자가-보고된 품질, 키, 체중, 약물, 및 인슐린 수준을 포함 할 수 있다. 도출된 데이터는 기록된 데이터로부터 계산될 수 있고, 체지방율 및 기초대사율(BMR: basal metabolic rate)과 같은 메트릭을 포함할 수 있다. 연결된 애플리케이션들로부터 수동적으로 수집된 데이터는 이 데이터와 통합될 수 있으며, Fitbit, Apple Watch, Oura ring 및 Runkeeper와 같은 애플리케이션들 및 웨어 러블 장치들로부터의 동기화된 건강 정보를 포함할 수 있다. 개별적인 일기 항목들은 표준화된 구조화된 형식으 로 변환되는 이러한 통합된 처리된 데이터를 포함할 수 있다. 항목들은 한 번에 하나씩 또는 벌크로 추가될 수"}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "있다. 빠른 액세스를 위해 일기 항목들이 캐시될 수 있다. 사용자에게 요약 정보 및 추천을 제공하는 보고서를"}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "생성하기 위해 플랫폼에 의해 일기 항목이 사용될 수 있다. 예를 들어, 일기 항목들은 요약 혈당 정보, 식사 통 계 및 식사 습관을 개선하기 위한 팁, 및 혈당과 신체 활동, 수면 및 기분 사이의 상관관계를 포함하는 보고서 를 생성할 수 있다. 데이터 감소 모듈은 데이터 스트림으로부터 여분의 또는 외부적인 항목들을 제거할 수 있다. 데이터 감소 모듈은 여분의 또는 외부적인 항목들을 제거하기 위해 Map-Reduce 알고리즘을 사용할 수 있다. 예를 들어, 써드파티 애플리케이션 MyFitnessPal은 영양소를 음식과 쌍을 이루게 할 수 있다. 각각의 영양소에 대해, MyFitnessPal은 음식 내의 각각의 영양소를 목록화할 수 있다. 그러나, 많은 영양소가 동일한 음식 항목 내에 포함될 수 있기 때문에 이는 많은 중복 항목들을 초래할 수 있다. 데이터 감소 모듈은 각각의 음식이 그의 영양 정보와 함께 한번 나열되도록, \"음식\" 키를 생성하고 각각의 음식의 영양소를 값으로서 목록(list)화함으 로써 이러한 항목들을 통합할 수 있다. 모니터링 모듈은 표준화 모듈의 처리 단계들이 정확하게 동작하고 있는 것을 보장할 수 있다. 이를 위해, 모니터링 모듈은 더미 데이터를 생성할 수 있다. 더미 데이터는 스트림 내에 배치될 수 있고, 데이 터 표준화 모듈 내의 처리 모듈들 중 하나 이상에 전달될 수 있다. 모니터링 모듈에 의해 생성된 더미 데이터는 프로세싱에 사용되는 하나 이상의 데이터 타입들로부터 온 것일 수 있다. 모니터링 모듈은 더미 데이터 를 테스트하는 것으로부터 리포트를 생성하고, 리포트를 외부 분석 서비스(예컨대, DATADOG®)에 제공할 수 있 다. 변환 모듈은 스트리밍 데이터를 다른 데이터 형식으로 변환할 수 있다. 데이터가 변환되는 파일 형식들은 표준화 모듈 내의 후속된 처리 단계들에 의존할 수 있다. 예를 들어, 변환 모듈은 데이터를 FoodPrintTM 데이터 형식으로 변환할 수 있다. 변환된 스트리밍 데이터는 빠른 액세스를 위해 캐시에 저장되거 나, 표준화 모듈 내의 다른 처리 단계들로 전송될 수 있다. 도 7은 일부 실시예들에 따른 저장 모듈의 구성요소들을 도시한다. 저장 모듈은 데이터 모니터링 모 듈, 데이터 분류 모듈, 및 데이터 저장 모듈을 포함할 수 있다. 저장 모듈의 구성요소들은 수동 적으로 수집된 데이터에 대해 동작할 수 있다. 수동 데이터는 사용자 모바일 장치 상의 애플리케이션들로부터 수집될 수 있다. 데이터 모니터링 모듈은 구성요소들을 모니터링하기 위해 플랫폼 내의 상이한 구성요소들로부터 보고된 데 이터를 수신하는 하나 이상의 람다 함수들을 포함할 수 있다. 데이터는 외부 장치들로부터의 구성요소들에 의해 수집될 수 있다. 람다 함수들 중 하나는 수집되는 데이터에 대한 정보를 인쇄할 수 있는 애플리케이션을 호출할 수 있다. 모니터링 프로세스는 데이터를 획득하고, 데이터를 저장하며, 데이터를 패키징하고, 데이터를 암호화 하며, 데이터를 업로드하고, 데이터를 하나 이상의 서버에 저장하는 것을 포함하여, 수동적으로 수집된 데이터 에 대해 수행되는 상이한 동작들을 분석할 수 있다. 추가적인 람다 함수는 로그 파일에 모니터링 프로세스를 통 해 수집된 정보를 저장할 수 있으며, 이는 URL에 저장될 수 있다. 데이터 분류 모듈은 수동적으로 수집된 데이터를 포함하는 암호화된 파일들을 수신할 수 있다. 데이터 분 류 모듈은 수집된 데이터가 분류될 수 있기 전에 이러한 파일들에 대해 전처리를 수행하는 하나 이상의 람 다 함수들을 포함할 수 있다. 전처리 활동들은 파일 압축 해제 및 복호화를 포함할 수 있다. 데이터 분류 모듈 은 수집된 데이터를 분류하기 위해 람다 함수들을 사용할 수 있다. 분류는 컨볼루션(convolutional) 또는 순환 신경망과 같은 머신러닝 또는 딥러닝 기술을 이용하는 것을 포함할 수 있다. 예를 들어, 음식이 이러한 이미지 내에 존재하는지 여부를 결정하기 위해 휴대폰 카메라로 촬영된 이미지들에 대해 이미지 인식 분석이 수행될 수 있다. 음식을 포함하는 이미지들은 일기에 저장될 수 있으며, 여기서 영양 정보는 이들 이미지로부터 추출 될 수 있다. 분류가 완료된 후, 분류된 데이터는 분류기의 문제를 해결하기 위해 디버그 버킷에 저장될 수 있다. 데이터 분류 모듈은 데이터가 손상되거나 도난되는 경우에 데이터가 익명화될 것을 보장하기 위해 하나 이상의 보안 정책들을 구현할 수 있다. 예를 들어, 이미지들에 있는 사람들의 얼굴은 흐릿할 수 있다. 데 이터가 클라우드에 업로드되는 경우에도 데이터가 암호화될 수 있다. 데이터 저장 모듈은 분류된 수동 데이터를 저장할 수 있다. 저장된 데이터는 써드파티 애플리케이션들에 의해 분석될 수 있으며, 데이터 분석 모델을 개선하기 위해 분석(예를 들어, 위치정보, 파일 해상도 및 카메라 모듈 데이터)을 사용자에게 제공할 수 있다. 저장되는 수동 데이터는 로그된(logged) 정보뿐만 아니라 이미지 데이터를 포함할 수 있다. 로그된 정보는 써드파티 애플리케이션들로부터의 수동 입력 또는 자동 로그된 수면 및 활동 정보를 포함할 수 있다. 분류된 데이터는 일시적으로 데이터 저장 모듈에 저장될 수 있고, 고정된 시간 주기 후에 삭제될 수 있다. 도 8 내지 도 12는 플랫폼 내의 모듈들의 예시적인 실시예들을 도시한다. 예시적인 실시예들은 AMAZON® Web 서비스들 및 AMAZON® Lambda 서버리스 컴퓨팅을 이용할 수 있다. GOOGLE® Cloud Functions 및 MICROSOFT ® Azure와 같은 다른 서버리스 아키텍처를 사용하여 본원에 개시된 인프라를 생성할 수도 있다. 유사한 타입의 서버리스 아키텍처를 사용하여 플랫폼이 개발되는 경우, 플랫폼의 구성요소들은 본원에 기술된 실시예들과 유사 할 수 있다. 이러한 다이어그램의 구성요소들은 람다(Lambda) 함수, API 게이트웨이, 웹 서버, 단순 알림 서비 스(SNS: simple notification service) 메시지, 저장 버킷, Kinesis Firehose 스트림, 및 스트리밍 애플리케이 션을 포함할 수 있다. 람다 함수는 AMAZON® Lambda를 사용하여 구현되는 바와 같이, 자율 함수일 수 있다. 이는 이벤트들에 반응하여 트리거되고, 호출될 때에만 활성화되는 함수이다. 이러한 함수는 서버 자원이 활성화되어야 하는 시간을 줄일 수 있다. 람다 함수는 인증, 권한 부여, 데이터 전송, 처리 및 스토리지 기능을 구현하기 위해 사용될 수 있다. 전술한 기능들 중 하나 이상은 하나 이상의 람다 함수들을 사용하여 구현될 수 있다. 예를 들어, 람다 함수는 API 게이트웨이를 인증하고 인증 서버로부터 토큰을 요청하기 위해 사용될 수 있다. 다른 람다 함수는 권한 부 여된 API를 URL로 리다이렉트하는 데 사용될 수 있다. 추가적인 람다 함수는 토큰들을 발행하고, 새로 고치고삭제할 수 있다. 유사하게, 데이터를 인출(pull)하거나 푸시(push)하고, 인출된 및 푸시된 데이터를 통합하며, 스트림으로부터 상이한 장소들로 상이한 데이터 항목들을 다이렉트하기 위해 상이한 람다 함수들이 사용될 수 있다. 람다 함수는 데이터 스트림, 데이터 스토리지 및 스트리밍 애플리케이션을 포함하여 여러 타입의 AMAZON ® objects와 통합할 수 있다. API 게이트웨이는 외부 애플리케이션들로부터 플랫폼으로 데이터를 전송하기 위해 외부 API들과 플랫폼을 연결 할 수 있다. 또한 API 게이트웨이는 외부 API들과 데이터 서비스들을 통합하기 위해 전체 OAuth 프로세스에 대 한 외부 엔트리 포인트를 제공한다. 또한, 플랫폼은 API 게이트웨이를 통해 데이터를 푸시하는 API들을 구독 (subscribe)할 수 있으며, 따라서 데이터가 푸시될 준비가 되었을 때 게이트웨이를 통해 알림을 받을 수 있다. API 게이트웨이는 외부 API들이 플랫폼 자체로부터 데이터를 수신하도록 허용할 수도 있다. 애플리케이션 API들은 HTTP 호출을 사용하여 데이터를 전송하고 데이터와 상호 작용할 수 있다. API는 이들 API 와 상호작용하기 위한 규칙 세트를 정의하는 REST를 따를 수 있다. 요청 메시지들을 전송함으로써 자원들에 대 해 데이터를 POST하거나, 자원들로부터 데이터를 GET하거나, 자원의 데이터를 업데이트하거나, 자원으로부터 데 이터를 삭제할 수 있다. 이러한 메시지들은 메시지, 사용자, 인증 정보, 타임스탬프 및 기타 메시지 정보를 갖 는 텍스트 필드를 포함할 수 있다. API 게이트웨이는 HTTP 요청들을 사용하여 애플리케이션들과 통신할 수 있다. 웹 서버는 HTTP 리소스와 같은 자원을 저장할 수 있고, 네트워크를 통해 플랫폼에 접속될 수 있다. 웹 서버는 인증 정보를 저장할 수 있고, 플랫폼이 외부 API들로부터 사용자 데이터에 액세스할 수 있게 하기 위해서 토큰 들을 플랫폼에 발행할 수 있다. 웹 서버는 또한 처리된 정보를 저장할 수 있다. 플랫폼 상에서 실행되는 애플리케이션들은 웹 서버들 상에 저장된 데이터에 액세스할 수 있다. 스트리밍 애플리케이션들은 웹 서버들 상 에서 호스트될 수 있다. AMAZON® S3 버킷은 사용자들 및 애플리케이션들이 데이터를 저장하게 할 수 있다. 데이터 오브젝트들은 버킷에 업로드 및 다운로드될 수 있다. 버킷은 저장된 필드에 대한 정보를 제공하는 메타데이터를 포함할 수도 있다. 버킷은 권한을 수정함으로써 사용자 또는 애플리케이션에 대한 액세스를 제한하거나 허용할 수 있다. 플랫폼 은 검색기로부터의 스트림들을 이용한 처리 및 통합을 위해 버킷들로부터 데이터를 검색할 수 있다. AMAZON® Kinesis streams는 스트리밍 데이터를 다른 도구로 로딩할 수 있다. 이들은 또한 데이터를 암호화하고 변환할 수 있다. Firehose streams는 처리를 위해 데이터를 스토리지 또는 애플리케이션들로 보내기 위해 람다 함수와 함께 사용될 수 있다. Kinesis는 저장될 데이터를 배치(batch)하고 압축하며, 사용해야 하는 스토리지의 양을 최소화할 수 있다. 이는 스트리밍 데이터를 암호화함으로써 보안을 향상시킬 수 있다. 스트리밍 애플리케이션들은 AMAZON® Web Service에 의해 호스팅될 수 있으며, 높은 성능을 갖고 안전하게 실행 될 수 있다. 애플리케이션들은 필요에 따라, 데이터가 그들에게 전송될 때, 온-디맨드 방식으로 사용될 수 있다. 스트리밍 애플리케이션들은 데이터가 처리된 후 데이터를 다이렉트하는 람다 함수와 쌍을 이룰 수 있다. 도 8은 일부 실시예들에 따른 토큰 모듈의 일 실시예를 도시한다. 토큰 모듈은 플랫폼을 외부 API들에 연결하는 API 게이트웨이를 포함할 수 있다. 람다 함수 연결은 테이블 내의 외부 API들로부 터의 연결 요청들을 저장할 수 있다. 외부 API들은 람다 함수에 의해 인증되고 권한 부여될 수 있다. 인증 후에, 토큰을 생성하기 위해 람다 함수가 호출될 수 있다. 예시된 실시예에서, 리프레시로 불리는 람다는 토큰을 리프레시하기 위해 메시지를 전송할 수 있다. 다른 람다는 기존 토큰들에 대해 데이터베이스를 검 색할 수 있다. 토큰들은 검색 모듈에 대해 발행될 수 있다. 또한 검색 모듈 상에 저장된 하나 이상의 토큰 들을 디스에이블시키기 위해 람다 디스에이블이 호출될 수 있다. 다른 람다는 CRUD(create, read, update, 및 delete) 동작을 위해 사용될 수 있다. 도 9는 검색 모듈의 일 실시예를 도시한다. 도 9의 예에서, 검색 모듈은 토큰 모듈 실시예로부 터 메시지들을 수신하여 토큰들을 갱신, 생성, 및 비활성화할 수 있다. 메시지들은 단순 알림 서비스(SNS: simple notification service) 메시지들일 수 있다. 토큰들은 토큰 데이터 테이블에서 업데이트될 수 있다. 도 9의 데이터 푸시 구성요소를 참조하면, 검색기는 연결된 외부 API들로부터 푸시된 데이터를 수신하기 위해 API 게이트웨이에 접속할 수 있다. 구독 람다는 알림 함수에 SNS 메시지를 전송할 수 있으며, 이는 검색 모듈 실시예에 푸시될 데이터를 나타낸다. 도 9에서 데이터 인출 구성요소를 참조 하면, 함수 scheduled_poll은 토큰 데이터 테이블에 리스트된 바와 같이 연결된 외부 API들을 폴링 (poll)할 수 있다. SNS 메시지 getdata는 새로운 데이터가 이용가능하다고 통지할 수 있고, 푸시되고 풀된데이터는 람다 함수 get_data_sns를 사용하여 검색될 수 있다. 함수 get_historic_data_sns는 보존 기간 내의 이전 시점으로부터 데이터를 수신하여 데이터 스트림에 추가할 수 있다. 버킷 검색기-데이터는 디버깅 또는 백업을 위해 검색기에 전송된 데이터를 저장할 수 있다. 도 10은 파이프라인 모듈의 일 실시예를 도시한다. 이 실시예에서, 2개의 스트리밍 애플리케이션들 과 2개의 람다 함수들이 직렬로 연결될 수 있다. 검색기 모듈 실시예로부터의 데이터는 data_distribution이라고 불리는 스트리밍 애플리케이션으로 전송될 수 있다. 람다 함수 data_distribution은 이러한 데이터를 표준화 모듈 실시예로 보낼 수 있다. 다른 스트리밍 애플리 케이션 third_party_data 및 대응하는 람다 함수는 스트림을 써드파티 애플리케이션 버킷으 로 전송할 수 있다. 도 11은 표준화 모듈의 일 실시예를 도시한다. 이 실시예는 직렬 처리 체인뿐만 아니라, 직렬 처리 체인의 다양한 단계들에서 다수의 캐시들 및 AMAZON® Kinesis 스트림들을 포함할 수 있다. 데이터는 예를 들어, AMAZON® Kinesis Firehose를 사용하여, AMAZON® S3 버킷에 저장될 수 있다. 스트리밍 데이터는 파이프 라인 실시예뿐만 아니라 드롭오프라 불리는 저장 영역으로부터 수신될 수 있다. 데이터는 정렬기 람 다에 의해 정렬될 수 있고, 대응하는 람다에 의해 sorter_cache 및 sorter-unprocessed 스 트림 모두에 저장되도록 보내질 수 있다. 그 후, 데이터는 변환기 함수를 사용하여 변환될 수 있고, 변환기 람다 함수를 이용하여 일기 자원으로 보내질 수 있다. 변환된 데이터는 diary_bulk 함수에 의해 일기에 저장되고 캐싱될 수 있다. 단일 일기 항목은 diary_single 함수에 의해 추출되어 일 기에 저장될 수 있다. 변환된 데이터는 또한 2개의 food_processor_caches에 저장될 수 있다. 데이터는 lambda_function food_processor에 의해 감소되고, 함수 food_processor_diary에 의해 일기로 전 달될 수 있다. coordination_cache 함수는 함수들이 병렬로 실행되지 못하도록 뮤텍스(mutex)로서 기능한다. 도 12는 저장 모듈의 일 실시예를 도시한다. 데이터 모니터링 모듈은 함수 data_collection 을 이용하여 시스템 구성요소들로부터의 데이터를 모니터링할 수 있다. 스트림은 애플리케이션 monitor_stream에 의해 모니터링될 수 있다. 추가적인 람다 함수는 모니터링 프로세스로부터 도메 인으로의 로그들을 저장할 수 있다. 데이터 분류 모듈은 \"드롭오프(dropoff)\" 로부터 데이터를 수집하고, 람다 함수 firestorm을 이용하여 데이터를 전처리하고, 음식 이미지들을 분류할 수 있다. 람다 함수 save_image는 음식 항목으로 분류되지 않은 항목을 디버그 및 이미지 디버그 버킷에 위치시킬 수 있다. 음식으로 분류되는 이미지들은 food_images, 일기, 및 분석 버킷 내의 저장 모듈에 의해 저 장될 수 있다. 도 13 내지 도 18은 개시된 실시예들에 따른 방법들의 예를 도시하는 흐름도이다. 도 13 내지 도 18에 관련하여, 도시된 각각의 방법의 단계들이 반드시 제한적인 것은 아니다. 단계들은 첨부된 청구항들의 범위를 벗어나지 않고 추가, 생략 및/또는 동시에 수행될 수 있다. 각각의 방법은 임의의 수의 부가적 또는 대안적인 작업들을 포함할 수 있고, 도시된 작업들은 예시된 순서로 수행될 필요가 없다. 각각의 방법은 본원에서 상세히 설명되지 않은 추가적인 기능을 갖는 보다 포괄적인 프로시저 또는 프로세스에 통합될 수 있다. 또한, 도시된 작업들 중 하나 이상은 의도된 전체 기능이 그대로 남아 있는 한, 각각의 방법의 실시예에서 잠재적으로 생략될 수 있다. 또한, 각각의 방법은 각각의 방법과 관련하여 수행되는 다양한 작업들 또는 단계들이 소프트웨어, 하 드웨어, 펌웨어, 또는 이들의 임의의 조합에 의해 수행될 수 있다는 점에서 컴퓨터-구현된다. 예시를 위해, 각 각의 방법의 이하의 설명은 도 1과 관련하여 위에서 언급된 구성요소들을 지칭할 수 있다. 특정 실시예들에서, 이러한 프로세스의 일부 또는 모든 단계들, 및/또는 실질적으로 동등한 단계들은 비-일시적일 수 있거나 비-일 시적일 수 있는 프로세서 판독 가능한 매체 상에 저장되거나 그에 포함되는 프로세서 판독가능 명령들의 실행에 의해 수행된다. 예를 들어, 도 13 내지 도 18의 설명에서, 플랫폼의 다양한 구성요소들(예를 들어, 토큰 모듈, 검색 모듈, 파이프라인 모듈, 표준화 모듈, 저장 모듈 및 이들의 임의의 구성 요소들)은 다양한 동작들, 작업들 또는 단계들을 수행하는 것으로서 설명될 수 있지만, 이는 이러한 다양한 동 작들, 작업들 또는 단계들을 수행하기 위한 명령들을 실행하는 이러한 엔티티들의 프로세싱 시스템(들)을 참조 한다는 것을 이해해야 한다. 구현예에 따라, 프로세싱 시스템(들)의 일부가 중앙에 위치될 수 있거나, 함께 동 작하는 다수의 서버 시스템들 사이에 분산될 수 있다. 도 13은 개시된 실시예들에 따른 하드웨어 기반의 프로세싱 시스템을 통해 개인화된 식이 및 건강 권고 또는 추 천을 생성하기 위한 건강 및 영양 플랫폼을 포함하는 서버리스 아키텍처를 사용하여 구현되는 컴퓨터-구현 데이터 수집 및 처리 방법을 도시하는 흐름도이다. 방법은 검색 모듈이 저장 모듈 내의 복수의 상이한 소스들로부터 데이터를 수집하고 집계하는 단계에서 시작한다. 데이터는 상이한 타입이나유형의 데이터(예를 들어, 복수의 개별 사용자들에게 특이적인 음식, 건강 또는 영양 데이터를 포함하는 구조화 된 데이터 및 비구조화된 데이터)를 포함할 수 있다. 단계에서, 표준화 모듈은, 예를 들어, 상이한 타입이나 유형의 데이터를 건강 및 영양 플랫폼 과 호환되는 표준화된 구조화된 형식으로 변환함으로써, 그의 소스의 불가지론적인 방식으로 상이한 타입이나 유형의 데이터 각각을 연속적으로 처리할 수 있다. 단계에서, 표준화된 구조화된 형식으로 변환된 데이터는 건강 및 영양 플랫폼으로부터 (적어도 부분 적으로) 정보를 이용하여 분석될 수 있다. 예를 들어, 표준화된 구조화된 데이터는 하나 이상의 인공 신경망, 하나 이상의 회귀 모델, 하나 이상의 결정 트리 모델, 하나 이상의 서포트 벡터 머신, 하나 이상의 베이지안 네 트워크, 하나 이상의 확률적 머신러닝 모델, 하나 이상의 가우시안 프로세싱 모델, 하나 이상의 히든 마르코프 모델, 및 하나 이상의 딥러닝 네트워크를 포함하지만 이에 제한되지 않는, 하나 이상의 머신러닝 모델을 사용하 여 분석될 수 있다. 단계에서, 복수의 개별 사용자들 각각에 대한 개인화된 식이 및 건강 권고 또는 추천 이 생성될 수 있다. 도 14는 개시된 실시예들에 따라 복수의 상이한 소스들로부터 데이터를 수집 및 집계하기 위한 방법을 예 시하는 흐름도이다. 방법은 작업 스케줄러를 사용하여 미리 결정된 시간 간격들에서 데이터를 허용하는 소스들의 제1 세트로부터 데이터가 인출되는 단계에서 시작한다. 단계에서, 소스들의 제2 세트로부 터 푸시되고 있는 데이터와 연관된 하나 이상의 알림이 수신될 수 있다. 단계에서, 각각의 대응하는 알림 에 대한 데이터가 대응하는 알림과 함께 도착했는지 여부가 판단될 수 있다. 단계에서, 각각의 대응하는 알림에 대한 데이터가 대응하는 알림과 함께 도달하지 않았다고 판단된 경우, 방법은 대응하는 알림과 연 관된 데이터가 대응하는 알림과 함께 도달하지 않은 경우 대응하는 알림과 연관된 데이터가 인출되는, 단계 로 진행한다. 단계에서, 각각의 대응하는 알림에 대한 데이터가 대응하는 알림과 함께 도달하지 않 았다고 판단된 경우, 방법은 소스들의 제2 세트로부터 푸시되는 데이터가 수신될 수 있는, 단계로 진행한다. 복수의 푸시 요청들로부터의 데이터는 중앙집중형 위치로 스트리밍될 수 있다. 도 15는 개시된 실시예들에 따른 저장 모듈 내의 복수의 상이한 소스들로부터 데이터를 수집 및 집계하기 위한 방법을 도시하는 흐름도이다. 방법은 하나 이상의 상이한 엔티티들과 연관된 토큰 모듈 이 하나 이상의 상이한 엔티티들과 연관된 복수의 애플리케이션 프로그래밍 인터페이스(API)와 통신할 수 있는 단계에서 시작한다. 토큰 모듈은 기존의 토큰들을 리프레시하고 토큰 변경들에 관한 알림 업데이트 들을 제공할 수 있다. 새로운 토큰이 생성될 때마다, 새로운 토큰은 토큰 모듈에 저장되는 것에 부가하여 검색 모듈에서 개별적으로 복제된다. 검색 모듈은 토큰 모듈로부터 분리되고 독립적이다. 단계에서, 검색 모듈은 하나 이상의 상이한 엔티티들과 연관된 복수의 API들을 통해 복수의 상이한 소스들로부터의 복수의 개별 사용자들에 대해 특이적인 상이한 타입이나 유형의 데이터(예를 들어, 음식, 건강 또는 영양 데이터를 포함하는 구조화된 데이터 및 비구조화된 데이터)를 수집 및 집계할 수 있다. 단계에서, 저장 모듈은 수집 및 집계된 데이터를 검증 및 검사하고, 수집 및 집계된 데이터로부터 중복 데이터를 제거하며, 수집 및 집계된 데이터의 선택된 타입들을 통합하고, 수집 및 집계된 데이터를 감소시 키며, 통합된 데이터를 배치(batch)들에 유지시킬 수 있다. 도 16은 개시된 실시예들에 따른 복수의 상이한 소스들로부터 수집 및 집계된 데이터를 저장하고, 수집 및 집계 된 데이터를 처리하는 방법을 도시하는 흐름도이다. 방법은 검색 모듈이 저장 모듈에서 복수의 스트림들 내의 복수의 상이한 소스들로부터 수집 및 집계된 데이터를 저장하는, 단계에서 시작한 다. 일 실시예에서, 복수의 스트림들은 각각의 스트림에 데이터가 저장되는 시간 프레임을 정의하는 보존 정책 을 각각 갖는다. 단계에서, 상이한 조건들이 발생할 때, 수집 및 집계된 데이터는 복수의 스트림들에 저 장되는 수집 및 집계된 데이터에 대해 람다 함수들을 실행함으로써 처리될 수 있다. 단계의 일 실시예에 서, 람다 함수들은 데이터가 수집되고 복수의 스트림들에 저장될 때만 실행된다. 예를 들어, 단계에서, 람다 함수들은 단계에서 저장된 데이터에 대해 실행되어 데이터의 각 행을 복수의 스트림들 중 관련 스트 림으로 채널링 및 전송하며, 단계에서, 수집 및 집계된 데이터는 복수의 스트림들 중 하나의 스트림으로 부터 다른 스트림으로 캐스케이딩(cascading)함으로써 데이터 파이프라인을 따라 전진된다. 도 17은 개시된 실시예들에 따른 복수의 스트림들 내의 복수의 상이한 소스들로부터 수집 및 집계된 데이터를 저장하기 위한 방법을 도시하는 흐름도이다. 방법은 검색 모듈이 저장 모듈에서 복수의 스트림들 내의 복수의 상이한 소스들로부터 수집 및 집계된 데이터를 저장하는, 단계에서 시작하며, 여기서 복수의 스트림들은 복수의 샤드들을 포함할 수 있고, 각각의 샤드는 큐에 진입하고, 보존 정책 만료 시에 큐를 빠져나가는 데이터 레코드들의 문자열을 포함한다. 데이터 레코드들의 문자열은 복수의 개별 사용자 들에게 특이적인 음식 소비, 건강 또는 영양 레코드들을 포함할 수 있다. 단계에서, 복수의 스트림들 내 의 샤드들의 수는 데이터가 처리되는 속도를 제어하도록 제어될 수 있다. 도 18은 개시된 실시예들에 따른 그의 영양 성분을 결정하기 위해 이미지들을 분석하는 방법을 도시하는 흐름도이다. 저장된 수집 및 집계된 데이터의 일부는 하나 이상의 이미징 장치들을 사용하여 캡처된 이미지들을 포함할 수 있다. 단계에서, 하나 이상의 선택된 람다 함수(들)가 저장된 데이터의 해당 부분에 대해 실행 되어, 복수의 이미지들 중 어느 것이라도 그들의 영양 성분에 대해 분석될 하나 이상의 음식 이미지를 포함하는 지를 검출할 수 있다. 음식 이미지들은 타임스탬프들 및 위치정보에 연관되어, 단계에서, 예를 들어 식사 시간 또는 식사의 내용을 예측함으로써 사용자의 음식 섭취의 시간적 및 공간적 추적을 가능하게 한다. 컴퓨터 판독가능 저장 매체는 단일 매체일 수 있지만, \"컴퓨터 판독가능 저장 매체\" 등이라는 용어는, 명령들의 하나 이상의 세트들을 저장하는 단일 매체 또는 다수의 매체(예를 들어, 중앙화된 또는 분산된 데이터베이스, 및/또는 연관된 캐시들 및 서버들)를 포함하는 것으로 이해되어야 한다. 용어 \"컴퓨터 판독가능 저장 매체\" 등 은 또한, 기계에 의해 실행하기 위한 명령들의 세트를 저장, 인코딩 또는 전달할 수 있고 기계로 하여금 본 발 명의 방법들 중 임의의 하나 이상의 방법을 수행하게 하는, 임의의 매체를 포함하는 것으로 이해되어야 한다. 이에 따라, \"컴퓨터 판독가능 저장 매체\" 등이라는 용어는 솔리드 스테이트 메모리, 광학 매체, 및 자기 매체를 포함하지만, 이에 제한되지 않는다. 전술한 설명은 본 발명의 여러 실시예들의 양호한 이해를 제공하기 위하여, 특정 시스템들, 구성요소들, 방법들 등의 예들과 같은 다수의 특정 세부사항들을 제시한다. 그러나, 통상의 기술자에게는 본 발명의 적어도 일부 실 시예들이 이러한 특정 새부사항들 없이도 실시될 수 있다는 것이 명백할 것이다. 다른 예들에서, 잘 알려진 구 성요소들 또는 방법들은 본 발명을 불필요하게 모호하게 하는 것을 방지하기 위해서 상세히 설명되지 않거나 간 단한 블록도 형태로 제시된다. 따라서, 제시된 구체적인 세부사항은 단지 예시적인 것이다. 특정 구현예들은 이 들 예시적인 세부사항들로부터 변경되고, 여전히 본 발명의 범위 내에 있는 것으로 간주될 수 있다. 상기 설명에서, 다수의 세부사항들이 제시된다. 그러나, 본 개시의 이점을 갖는 통상의 기술자에게는 본 발명의 실시예들이 이러한 특정 세부사항들 없이도 실시될 수 있다는 것이 명백할 것이다. 일부 예들에서, 잘 알려진 구조들 및 장치들은 설명을 모호하게 하는 것을 피하기 위해, 상세하지 않은 블록도 형태로 도시된다. 상세한 설명의 일부 부분들은 컴퓨터 메모리 내의 데이터 비트들에 대한 동작들의 알고리즘들 및 기호 표현들의 관점으로 제시된다. 이러한 알고리즘 설명 및 표현은 데이터 처리 분야의 통상의 기술자가 그들의 작업의 내용"}
{"patent_id": "10-2021-7018870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "을 해당 기술분야의 통상의 기술자에게 가장 효과적으로 전달하기 위해 사용되는 수단이다. 알고리즘은 여기에 있으며, 일반적으로 원하는 결과를 초래하는 단계들의 일관성 있는 시퀀스가 되도록 고안된다. 단계들은 물리적 양들의 물리적 조작들을 필요로 하는 단계들이다. 통상적으로, 반드시는 아니지만, 이들 양들은 저장, 전달, 조 합, 비교, 및 달리 조작될 수 있는 전기적 또는 자기적 신호들의 형태를 취한다. 주로 일반적인 용도를 위해, 이러한 신호들을 비트들, 값들, 구성요소들, 기호들, 문자들, 용어들, 숫자들 등으로서 지칭하는 것이 때때로 편리하다는 것이 입증되었다. 그러나, 이들 및 유사한 용어들 모두는 적절한 물리적 양들과 연관되어야 하고 이들 양들에 적용되는 편리한 레 이블들일 뿐이라는 것을 이해해야 한다. 상기 설명으로부터 명확하게 달리 언급되지 않는 한, 상세한 설명 전체 에 걸쳐, \"결정하는\", \"식별하는\", \"추가하는\", \"선택하는\" 등과 같은 용어를 이용하는 설명은 컴퓨터 시스템의 레지스터들 및 메모리들 내의 물리적(예를 들어, 전자) 양들로서 표현된 데이터를 조작하고, 이를 컴퓨터 시스 템 메모리들 또는 레지스터들 또는 다른 정보 저장 장치, 전송 또는 디스플레이 장치들 내의 물리적 양들로서 유사하게 표현된 다른 데이터로 변환하는, 컴퓨터 시스템 또는 유사한 전자 컴퓨팅 장치의 동작들 및 프로세스 들을 지칭함을 이해해야 한다. 본 발명의 실시예들은 또한 본원에서의 동작들을 수행하기 위한 장치에 관한 것이다. 이 장치는 필요한 목적을 위해 특별히 구성될 수 있거나, 컴퓨터에 저장된 컴퓨터 프로그램에 의해 선택적으로 활성화되거나 재구성되는 범용 컴퓨터를 포함할 수 있다. 이러한 컴퓨터 프로그램은 플로피 디스크, 광 디스크, CD-ROM, 및 자기-광학 디 스크, 읽기 전용 메모리(ROM), 랜덤 액세스 메모리(RAM), EPROM, EEPROM, 자기 또는 광학 카드, 또는 전자 명령 들을 저장하기에 적합한 임의의 유형의 매체와 같은, 그러나 이에 제한되지 않는 컴퓨터 판독가능 저장 매체에 저장될 수 있다.본원에 제시된 알고리즘 및 디스플레이는 본질적으로 임의의 특정 컴퓨터 또는 다른 장치에 관련되지 않는다. 다양한 시스템들이 본원의 교시들에 따른 프로그램들과 함께 사용될 수 있거나, 또는 필요한 방법 단계들을 수 행하기 위해 보다 특수화된 장치를 구성하는 것이 편리한 것으로 입증될 수 있다. 이러한 다양한 시스템들에 필 요한 구조는 본원에 제공된 설명으로부터 명백할 것이다. 또한, 본 발명은 임의의 특정 프로그래밍 언어를 참조 하여 설명되지 않는다. 본원에서 설명되는 바와 같이, 다양한 프로그래밍 언어들이 본 발명의 교시를 구현하기 위해 사용될 수 있음이 이해될 것이다. 적어도 하나의 예시적인 실시예가 상기의 상세한 설명에서 제시되었지만, 많은 변형들이 존재한다는 것을 이해 할 것이다. 또한, 본원에 설명된 예시적인 실시예 또는 실시예들은 어떠한 방식으로도 청구대상의 범위, 응용가 능성 또는 구성을 제한하도록 의도되지 않는다는 것을 이해해야 한다. 오히려, 전술한 상세한 설명은 본 기술 분야의 통상의 기술자에게 설명된 실시예 또는 실시예들을 구현하기 위한 편리한 로드맵을 제공할 것이다. 청구 범위에 의해 정의되는 범위를 벗어나지 않고, 본 특허출원의 출원시에 공지된 균등물 및 예측가능한 균등물을 포함하는, 구성요소들의 기능 및 배열에 다양한 변화가 이루어질 수 있다는 것이 이해되어야 한다."}
{"patent_id": "10-2021-7018870", "section": "도면", "subsection": "도면설명", "item": 1, "content": "청구대상에 대한 보다 완전한 이해는 이하의 도면들과 관련하여 고려될 때 상세한 설명 및 청구항들을 참조함으 로써 도출될 수 있으며, 여기서 유사한 도면부호들은 도면들 전반에 걸쳐 유사한 구성요소들을 지칭한다. 도 1은 일부 실시예들에 따른 생태계를 도시한다. 도 2는 일부 실시예들에 따른 플랫폼의 블록도를 도시한다. 도 3은 일부 실시예들에 따른 토큰 모듈의 구성요소들을 도시한다. 도 4는 일부 실시예들에 따른 수신 모듈의 구성요소들을 도시한다.도 5는 일부 실시예들에 따른 파이프라인 모듈의 구성요소들을 도시한다. 도 6은 일부 실시예들에 따른 표준화 모듈의 구성요소들을 도시한다. 도 7은 일부 실시예들에 따른 저장 모듈의 구성요소들을 도시한다. 도 8은 일부 실시예들에 따른 도 3의 토큰 모듈의 일 예를 도시한다. 도 9는 일부 실시예들에 따른 도 4의 검색 모듈의 일 예를 도시한다. 도 10은 일부 실시예들에 따른 도 5의 파이프라인 모듈의 일 예를 도시한다. 도 11은 일부 실시예들에 따른 도 6의 표준화 모듈의 일 예를 도시한다. 도 12는 일부 실시예에 따른 도 7의 저장 모듈의 일 예를 도시한다. 도 13은 개시된 실시예들에 따른 하드웨어 기반의 처리 시스템을 통해 개인화된 식이 및 건강 권고 또는 추천을 생성하기 위한 건강 및 영양 플랫폼을 포함하는 서버리스 아키텍처를 사용하여 구현되는 컴퓨터-구현 데이터 수 집 및 처리 방법을 도시하는 흐름도이다. 도 14는 개시된 실시예들에 따른 복수의 상이한 소스들로부터 데이터를 수집 및 집계하기 위한 방법을 도시하는 흐름도이다. 도 15는 개시된 실시예들에 따른, 저장 모듈 내의 복수의 상이한 소스들로부터 데이터를 수집 및 집계하기 위한 방법을 도시하는 흐름도이다. 도 16은 개시된 실시예들에 따른 복수의 상이한 소스들로부터 수집 및 집계된 데이터를 저장하고, 저장 모듈 내 의 수집 및 집계된 데이터를 처리하기 위한 방법을 도시하는 흐름도이다. 도 17은 개시된 실시예들에 따른 복수의 스트림들 내의 복수의 상이한 소스들로부터 수집 및 집계된 데이터를 저장하기 위한 방법을 도시하는 흐름도이다. 도 18은 개시된 실시예들에 따른 그의 영양 성분을 결정하기 위해 이미지를 분석하는 방법을 도시하는 흐름도이 다."}
