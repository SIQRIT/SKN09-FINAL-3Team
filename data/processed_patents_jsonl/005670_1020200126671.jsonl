{"patent_id": "10-2020-0126671", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0044011", "출원번호": "10-2020-0126671", "발명의 명칭": "텍스트 스타일 변환 방법 및 시스템, 및 이의 구현을 위한 학습 방법", "출원인": "아주대학교산학협력단", "발명자": "손경아"}}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력 텍스트를 획득하는 단계;인코더를 통해, 획득된 입력 텍스트에 대한 잠재 표현(latent representation)을 획득하는 단계;스타일 임베딩 모델을 통해, 타겟 스타일에 대응하는 스타일 임베딩(style embedding)을 획득하는 단계;획득된 스타일 임베딩을 상기 잠재 표현에 결합하는 단계; 및디코더를 통해, 결합된 잠재 표현에 대한 출력 텍스트를 획득하는 단계를 포함하는,텍스트 스타일 변환 방법."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 잠재 표현을 획득하는 단계는,상기 입력 텍스트를 상기 인코더로 입력하는 단계; 및상기 인코더의 신경망을 통해, 상기 입력 텍스트에 대응하는 상기 잠재 표현을 획득하는 단계를 포함하는,텍스트 스타일 변환 방법."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 스타일 임베딩을 획득하는 단계는,상기 타겟 스타일에 대응하는 스타일 정보를 상기 스타일 임베딩 모델로 입력하는 단계; 및상기 스타일 임베딩 모델의 신경망을 통해, 상기 타겟 스타일에 대응하는 상기 스타일 임베딩을 획득하는 단계를 포함하는,텍스트 스타일 변환 방법."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 출력 텍스트를 획득하는 단계는,상기 결합된 잠재 표현을 상기 디코더로 입력하는 단계; 및상기 디코더의 신경망을 통해, 상기 결합된 잠재 표현에 대응하는 상기 출력 텍스트를 획득하는 단계를 포함하고,상기 출력 텍스트는 상기 입력 텍스트를 상기 타겟 스타일에 따라 변환하여 재구성한 텍스트인텍스트 스타일 변환 방법."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 잠재 표현 및 상기 스타일 임베딩은 벡터 형태를 갖고,상기 결합하는 단계는, 공개특허 10-2022-0044011-3-상기 잠재 표현 및 상기 스타일 임베딩의 벡터 합을 통해 상기 결합된 잠재 표현을 획득하는 단계를 포함하는,텍스트 스타일 변환 방법."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 결합된 잠재 표현을 획득하는 단계는,상기 스타일 임베딩에 스타일 강도를 적용하는 단계; 및상기 스타일 강도가 적용된 상기 스타일 임베딩과 상기 잠재 표현의 벡터 합을 통해 상기 결합된 잠재 표현을획득하는 단계를 포함하고,상기 출력 텍스트를 획득하는 단계는,상기 스타일 강도에 따라 변화하는 출력 텍스트를 획득하는,텍스트 스타일 변환 방법."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "입력 텍스트로부터 잠재 표현 벡터를 제공하는 신경망을 포함하는 인코더;타겟 스타일에 대응하는 스타일 임베딩 벡터를 제공하는 신경망을 포함하는 스타일 임베딩 모델; 및상기 잠재 표현 벡터와 상기 스타일 임베딩 벡터의 결합에 의해 제공되는 결합된 잠재 표현 벡터를 이용하여 출력 텍스트를 제공하는 신경망을 포함하는 디코더를 구현하도록 구성되는 적어도 하나의 컴퓨팅 장치를포함하는,텍스트 스타일 변환 시스템."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 결합된 잠재 표현 벡터는,상기 잠재 표현 벡터와 상기 스타일 임베딩 벡터의 벡터 합에 의해 제공되는,텍스트 스타일 변환 시스템."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 적어도 하나의 컴퓨팅 장치 중 어느 하나는,상기 스타일 임베딩 벡터에 스타일 강도를 적용하고,상기 스타일 강도가 적용된 상기 스타일 임베딩 벡터와 상기 잠재 표현 벡터의 벡터 합을 통해 상기 결합된 잠재 표현을 제공하도록 구현되는,텍스트 스타일 변환 시스템."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 디코더는,상기 스타일 강도에 따라 변화하는 출력 텍스트를 제공하는,텍스트 스타일 변환 시스템."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2022-0044011-4-제9항에 있어서, 상기 적어도 하나의 컴퓨팅 장치 중 어느 하나는,서로 다른 스타일 강도가 적용된 복수의 스타일 임베딩 벡터들을 제공하고,상기 디코더는, 상기 복수의 스타일 임베딩 벡터들과 상기 잠재 표현에 기초하여 복수의 출력 텍스트를 제공하고,상기 복수의 출력 텍스트 중 적어도 일부는 서로 다른,텍스트 스타일 변환 시스템."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "입력 텍스트로부터 스타일 변환된 출력 텍스트를 재구성하는 인코더와 디코더, 및 스타일 변환을 위한 스타일임베딩 벡터를 제공하는 스타일 임베딩 모델을 포함하는 텍스트 스타일 변환 시스템의 학습 방법에 있어서,상기 출력 텍스트의 재구성 결과에 기초하여 상기 인코더와 상기 디코더의 학습을 제어하는 단계; 및스타일의 분류 결과에 기초하여 상기 스타일 임베딩 모델의 학습을 제어하는 단계를 포함하는,텍스트 스타일 변환 시스템의 학습 방법."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 인코더와 상기 디코더의 학습을 제어하는 단계는,상기 출력 텍스트의 재구성 결과에 기초한 재구성 손실 함수에 따라, 상기 인코더에 포함된 신경망 및 상기 디코더에 포함된 신경망을 업데이트하는 단계를 포함하는,텍스트 스타일 변환 시스템의 학습 방법."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 인코더와 상기 디코더의 학습을 제어하는 단계는,상기 인코더의 신경망이, 상기 입력 텍스트를 이용하여 잠재 표현 벡터를 제공하는 단계;상기 스타일 임베딩 모델의 신경망이, 상기 입력 텍스트의 스타일 정보를 이용하여 스타일 임베딩 벡터를 제공하는 단계;상기 잠재 표현 벡터와 상기 스타일 임베딩 벡터의 결합을 통해 결합된 잠재 표현 벡터를 획득하는 단계; 및상기 디코더의 신경망이, 상기 결합된 잠재 표현 벡터를 이용하여 상기 출력 텍스트를 재구성하는 단계를 더 포함하는,텍스트 스타일 변환 시스템의 학습 방법."}
{"patent_id": "10-2020-0126671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서, 상기 스타일 임베딩 모델의 학습을 제어하는 단계는,상기 인코더의 신경망이, 상기 입력 텍스트를 이용하여 잠재 표현 벡터를 제공하는 단계;설정된 스타일의 수에 대응하는 복수의 스타일 임베딩들 각각에 대해, 상기 잠재 표현과의 유사도를 산출하는단계;산출된 유사도들에 기초하여 상기 입력 텍스트의 스타일을 분류하는 단계; 및분류 결과에 기초한 분류 손실 함수에 따라 상기 스타일 임베딩 모델의 신경망의 학습을 제어하는 단계를 포함공개특허 10-2022-0044011-5-하는,텍스트 스타일 변환 시스템의 학습 방법."}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 기술적 사상에 의한 일 양태에 따른 텍스트 스타일 변환 방법은, 입력 텍스트를 획득하는 단계; 인코 더를 통해, 획득된 입력 텍스트에 대한 잠재 표현을 획득하는 단계; 스타일 임베딩 모델을 통해, 타겟 스타일에 대응하는 스타일 임베딩을 획득하는 단계; 획득된 스타일 임베딩을 상기 잠재 표현에 결합하는 단계; 및 디코더 를 통해, 결합된 잠재 표현에 대한 출력 텍스트를 획득하는 단계를 포함한다."}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시(disclosure)의 기술적 사상은 텍스트 스타일 변환 방법 및 시스템, 및 이의 구현을 위한 학습 방법에 관한 것이다."}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "텍스트 스타일 변환은 지정된 스타일 속성으로 텍스트를 수정하는 태스크이다. 특정 스타일(예컨대, 긍정)을 갖 는 입력 텍스트가 주어지면, 텍스트 스타일 변환은 다른 스타일(예컨대, 부정)을 얻기 위해 상기 입력 텍스트를 변경하는 것을 목표로 한다. 이러한 텍스트 스타일 변환에 있어서, 주어진 목표 스타일을 반영하고, 스타일과 무관한 부분의 내용을 유지하 고, 자연스러운 문장을 생성하는 것이 중요하다. 종래의 방식에 따르면, 텍스트 스타일 변환을 위한 모델은 소스 문장 및 목표 문장 쌍을 포함하는 병렬 데이터 세트를 사용하는 지도 학습 방법을 활용하여 제공되었다. 그러나, 이러한 방식은 지정된 스타일과 전체적으로 일대일 대응을 달성하는 병렬 데이터 세트를 획득하는 것이 불가능할 수 있다. 또한, 입력 텍스트 내에서 스타일 구성 요소와 내용 구성 요소를 분리하려는 분리 접근 방식이 연구되고 있으나, 상기 구성 요소들이 상호 배타적이지 않으므로 문장을 스타일 구성 요소와 내용 구성 요소로 나누는 것 이 어려울 수 있다. 또한 이러한 분리는 정보의 손실을 유발할 우려가 있다."}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 일 과제는, 텍스트 스타일 변환 시 문장 복원 능력 및 스타일의 정확성을 향상시키 는 방법 및 시스템을 제공하는 것이다. 본 발명이 해결하고자 하는 일 과제는, 스타일의 강도를 반영하여 입력 텍스트의 스타일을 변환할 수 있는 방법 및 시스템을 제공하는 것이다."}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위하여, 본 개시의 기술적 사상에 의한 일 양태(aspect)에 따른 텍스트 스타일 변 환 방법은, 입력 텍스트를 획득하는 단계; 인코더를 통해, 획득된 입력 텍스트에 대한 잠재 표현을 획득하는 단 계; 스타일 임베딩 모델을 통해, 타겟 스타일에 대응하는 스타일 임베딩을 획득하는 단계; 획득된 스타일 임베 딩을 상기 잠재 표현에 결합하는 단계; 및 디코더를 통해, 결합된 잠재 표현에 대한 출력 텍스트를 획득하는 단 계를 포함한다. 실시 예에 따라, 상기 잠재 표현을 획득하는 단계는, 상기 입력 텍스트를 상기 인코더로 입력하는 단계; 및 상 기 인코더의 신경망을 통해, 상기 입력 텍스트에 대응하는 상기 잠재 표현을 획득하는 단계를 포함할 수 있다. 실시 예에 따라, 상기 스타일 임베딩을 획득하는 단계는, 상기 타겟 스타일에 대응하는 스타일 정보를 상기 스 타일 임베딩 모델로 입력하는 단계; 및 상기 스타일 임베딩 모델의 신경망을 통해, 상기 타겟 스타일에 대응하 는 상기 스타일 임베딩을 획득하는 단계를 포함할 수 있다. 실시 예에 따라, 상기 출력 텍스트를 획득하는 단계는, 상기 결합된 잠재 표현을 상기 디코더로 입력하는 단계; 및 상기 디코더의 신경망을 통해, 상기 결합된 잠재 표현에 대응하는 상기 출력 텍스트를 획득하는 단계를 포함 하고, 상기 출력 텍스트는 상기 입력 텍스트를 상기 타겟 스타일에 따라 변환하여 재구성한 텍스트일 수 있다. 실시 예에 따라, 상기 잠재 표현 및 상기 스타일 임베딩은 벡터 형태를 갖고, 상기 결합하는 단계는, 상기 잠재 표현 및 상기 스타일 임베딩의 벡터 합을 통해 상기 결합된 잠재 표현을 획득하는 단계를 포함할 수 있다.실시 예에 따라, 상기 결합된 잠재 표현을 획득하는 단계는, 상기 스타일 임베딩에 스타일 강도를 적용하는 단 계; 및 상기 스타일 강도가 적용된 상기 스타일 임베딩과 상기 잠재 표현의 벡터 합을 통해 상기 결합된 잠재 표현을 획득하는 단계를 포함하고, 상기 출력 텍스트를 획득하는 단계는, 상기 스타일 강도에 따라 변화하는 출 력 텍스트를 획득하는 단계를 포함할 수 있다. 본 개시의 기술적 사상에 의한 일 양태에 따른 텍스트 스타일 변환 시스템은, 입력 텍스트로부터 잠재 표현 벡 터를 제공하는 신경망을 포함하는 인코더; 타겟 스타일에 대응하는 스타일 임베딩 벡터를 제공하는 신경망을 포 함하는 스타일 임베딩 모델; 및 상기 잠재 표현 벡터와 상기 스타일 임베딩 벡터의 결합에 의해 제공되는 결합 된 잠재 표현 벡터를 이용하여 출력 텍스트를 제공하는 신경망을 포함하는 디코더를 구현하도록 구성되는 적어 도 하나의 컴퓨팅 장치를 포함한다. 본 개시의 기술적 사상에 의한 일 양태에 따른 텍스트 스타일 변환 시스템은 입력 텍스트로부터 스타일 변환된 출력 텍스트를 재구성하는 인코더와 디코더, 및 스타일 변환을 위한 스타일 임베딩 벡터를 제공하는 스타일 임 베딩 모델을 포함한다. 상기 텍스트 스타일 변환 시스템의 학습 방법은, 상기 출력 텍스트의 재구성 결과에 기 초하여 상기 인코더와 상기 디코더의 학습을 제어하는 단계; 및 스타일의 분류 결과에 기초하여 상기 스타일 임 베딩 모델의 학습을 제어하는 단계를 포함한다. 실시 예에 따라, 상기 인코더와 상기 디코더의 학습을 제어하는 단계는, 상기 출력 텍스트의 재구성 결과에 기 초한 재구성 손실 함수에 따라, 상기 인코더에 포함된 신경망 및 상기 디코더에 포함된 신경망을 업데이트하는 단계를 포함할 수 있다. 실시 예에 따라, 상기 인코더와 상기 디코더의 학습을 제어하는 단계는, 상기 인코더의 신경망이, 상기 입력 텍 스트를 이용하여 잠재 표현 벡터를 제공하는 단계; 상기 스타일 임베딩 모델의 신경망이, 상기 입력 텍스트의 스타일 정보를 이용하여 스타일 임베딩 벡터를 제공하는 단계; 상기 잠재 표현 벡터와 상기 스타일 임베딩 벡터 의 결합을 통해 결합된 잠재 표현 벡터를 획득하는 단계; 및 상기 디코더의 신경망이, 상기 결합된 잠재 표현 벡터를 이용하여 상기 출력 텍스트를 재구성하는 단계를 더 포함할 수 있다. 실시 예에 따라, 상기 스타일 임베딩 모델의 학습을 제어하는 단계는, 상기 인코더의 신경망이, 상기 입력 텍스 트를 이용하여 잠재 표현 벡터를 제공하는 단계; 설정된 스타일의 수에 대응하는 복수의 스타일 임베딩들 각각 에 대해, 상기 잠재 표현과의 유사도를 산출하는 단계; 산출된 유사도들에 기초하여 상기 입력 텍스트의 스타일 을 분류하는 단계; 및 분류 결과에 기초한 분류 손실 함수에 따라 상기 스타일 임베딩 모델의 신경망의 학습을 제어하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 기술적 사상에 따르면, 스타일 표현을 위한 스타일 임베딩 모델을 문장 재구성을 위한 인코더 및 디 코더와 분리함으로써, 인코더 및 디코더의 신경망 구조가 보다 간단해지고, 텍스트의 재구성 능력이 향상될 수 있다. 또한, 상기 스타일 임베딩 모델이 분리됨에 따라, 스타일 변환 시 스타일 강도를 설정 및 조절하여 스타일 변환 정도를 변화시킬 수 있다. 이에 따라, 종래의 방식에 비해 보다 연속적인 스타일 변환이 가능하므로, 텍스트 스 타일 변환 시스템의 활용도가 향상될 수 있다. 본 개시의 기술적 사상에 따른 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과"}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 기술적 사상에 따른 예시적인 실시 예들은 당해 기술 분야에서 통상의 지식을 가진 자에게 본 개시의 기술적 사상을 더욱 완전하게 설명하기 위하여 제공되는 것으로, 아래의 실시 예들은 여러 가지 다른 형태로 변 형될 수 있으며, 본 개시의 기술적 사상의 범위가 아래의 실시 예들로 한정되는 것은 아니다. 오히려, 이들 실 시 예들은 본 개시를 더욱 충실하고 완전하게 하며 당업자에게 본 발명의 기술적 사상을 완전하게 전달하기 위 하여 제공되는 것이다. 본 개시에서 제1, 제2 등의 용어가 다양한 부재, 영역, 층들, 부위 및/또는 구성 요소들을 설명하기 위하여 사 용되지만, 이들 부재, 부품, 영역, 층들, 부위 및/또는 구성 요소들은 이들 용어에 의해 한정되어서는 안 됨은 자명하다. 이들 용어는 특정 순서나 상하, 또는 우열을 의미하지 않으며, 하나의 부재, 영역, 부위, 또는 구성 요소를 다른 부재, 영역, 부위 또는 구성 요소와 구별하기 위하여만 사용된다. 따라서, 이하 상술할 제1 부재, 영역, 부위 또는 구성 요소는 본 개시의 기술적 사상의 가르침으로부터 벗어나지 않고서도 제2 부재, 영역, 부 위 또는 구성 요소를 지칭할 수 있다. 예를 들면, 본 개시의 권리 범위로부터 이탈되지 않은 채 제1 구성 요소 는 제2 구성 요소로 명명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 달리 정의되지 않는 한, 여기에 사용되는 모든 용어들은 기술 용어와 과학 용어를 포함하여 본 개시의 개념이 속하는 기술 분야에서 통상의 지식을 가진 자가 공통적으로 이해하고 있는 바와 동일한 의미를 지닌다. 또한, 통상적으로 사용되는, 사전에 정의된 바와 같은 용어들은 관련되는 기술의 맥락에서 이들이 의미하는 바와 일관 되는 의미를 갖는 것으로 해석되어야 하며, 여기에 명시적으로 정의하지 않는 한 과도하게 형식적인 의미로 해 석되어서는 아니 될 것이다. 어떤 실시 예가 달리 구현 가능한 경우에 특정한 공정 순서는 설명되는 순서와 다르게 수행될 수도 있다. 예를 들면, 연속하여 설명되는 두 공정이 실질적으로 동시에 수행될 수도 있고, 설명되는 순서와 반대의 순서로 수행 될 수도 있다. 첨부한 도면에 있어서, 예를 들면, 제조 기술 및/또는 공차에 따라, 도시된 형상의 변형들이 예상될 수 있다. 따라서, 본 개시의 기술적 사상에 의한 실시 예들은 본 개시에 도시된 영역의 특정 형상에 제한된 것으로 해석 되어서는 아니 되며, 예를 들면, 제조 과정에서 초래되는 형상의 변화를 포함하여야 한다. 도면 상의 동일한 구 성요소에 대해서는 동일한 참조부호를 사용하고, 이들에 대한 중복된 설명은 생략한다. 여기에서 사용된 '및/또는' 용어는 언급된 부재들의 각각 및 하나 이상의 모든 조합을 포함한다. 이하에서는 첨부한 도면들을 참조하여 본 개시의 기술적 사상에 의한 실시 예들에 대해 상세히 설명한다. 도 1은 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 시스템의 개략적인 블록도이다. 텍스트 스타일 변환(text style transfer)은, 입력된 텍스트의 내용은 보존하면서 새로운 스타일 또는 원하는 스타일을 반영하여 새로운 출력 텍스트를 제공하는 작업을 의미한다. 일례로, 텍스트 스타일 변환은 특정 스타 일(예컨대, 긍정)이 포함된 입력 텍스트가 주어진 경우, 다른 스타일(예컨대, 부정)을 얻기 위해 상기 입력 텍 스트를 변경하는 작업을 포함할 수 있다. 최근 머신러닝, 딥러닝 등의 인공지능 기술이 발전함에 따라, 인공지능 기반의 학습을 통해 텍스트 스타일 변환 을 위한 모델 또는 시스템을 구현하기 위한 다양한 연구들이 진행되고 있다. 이에 기초하여 도 1을 참조하면, 텍스트 스타일 변환 시스템은 상술한 텍스트 스타일 변환 동작을 수행하는 시스템으로 구현될 수 있다. 이러한 텍스트 스타일 변환 시스템은 하나 또는 둘 이상의 컴퓨팅 디바이스를포함할 수 있다. 텍스트 스타일 변환 시스템이 둘 이상의 컴퓨팅 디바이스로 구현되는 경우, 도 1에 도시된 구성들은 상기 둘 이상의 컴퓨팅 디바이스에 분할되어 구현되고, 상기 둘 이상의 컴퓨팅 디바이스는 네트워크를 통해 연결될 수 있다. 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 시스템은 문장 재구성 모듈 및 스타일 임베딩 모 듈을 포함할 수 있다. 문장 재구성 모듈은 입력 텍스트의 재구성(복원)을 통해 출력 텍스트를 제공하는 동작, 및 이를 위한 학습 동작을 수행하는 모듈일 수 있다. 예컨대, 문장 재구성 모듈은 인코더 및 디코더를 포함할 수 있 다. 인코더는 입력 텍스트를 처리하여, 상기 입력 텍스트에 대응하는 잠재 표현(latent representation)을 제 공할 수 있다. 상기 잠재 표현은 입력 텍스트의 압축된 표현으로서, 일례로 벡터 형태를 가질 수 있다. 따라서, 상기 잠재 표현은 잠재 표현 벡터로도 지칭될 수 있다. 디코더는 인코더로부터 제공된 상기 잠재 표현, 또는 상기 잠재 표현에 스타일 임베딩 모듈로부 터 제공되는 스타일 임베딩(style embedding)이 결합된 잠재 표현을 이용하여 출력 텍스트를 제공할 수 있다. 이를 정리하면, 디코더는 입력 텍스트를 상기 스타일 임베딩에 대응하는 스타일로 변환하여 재구성한 출력 텍스트를 제공할 수 있다. 인코더와 디코더 각각은 신경망(neural network)을 포함하는 하드웨어, 소프트웨어, 또는 이들의 조 합으로 구현될 수 있다. 실시 예에 따라, 인코더와 디코더는, 텍스트에 포함된 동일한 단어에 대한 다양한 의미를 포착하기 위해, Transformer 기반의 시퀀스 대 시퀀스 모델로 구현될 수 있다. 예컨대, 동일한 단어가 감성적 텍스트에서 미묘하게 다른 의미를 가질 수 있고, 인코더와 디코더는 Transformer 기반 모델에서 관계 정보를 사용함으로써 상술한 미묘한 차이를 포착할 수 있다. 상기 Transformer 기반의 시퀀스 대 시퀀스 모델에 대해서는 \"Google's multilingual neural machine translation system: Enablindg zero-shot translation. Transactions of the Association for Computational Linguistics, 5:339-351 (Johnson et al. 2017)\", \"Attention is all you need. In advances in neural information processing systems, pages 5998- 6008 (Vaswani et al. 2017)\" 등에 의해 공지된 바, 이에 대한 상세한 설명은 생략하기로 한다. 인코더의 신경망은 상기 입력 텍스트로부터 상기 잠재 표현을 제공하도록 학습되고, 디코더의 신경망 은 상기 잠재 표현으로부터 출력 텍스트를 제공하도록 학습될 수 있다. 실시 예에 따라, 인코더 및 디코더 는 오토인코더(autoencoder)로 구현되어, 입력 텍스트와 동일한 출력 텍스트를 제공하도록 학습될 수 있다. 종래의 경우, 텍스트 스타일 변환을 위한 하나의 모듈(모델)에서 문장의 재구성을 위한 학습 및 스타일 변환을 위한 학습이 모두 수행되도록 구현되었다. 이에 따라 모델의 구조가 복잡해지고, 스타일의 변환 시 이산적으로 만 변환이 가능하다는 단점이 존재하였다. 반면 본 개시의 실시 예에 따른 문장 재구성 모듈에 포함된 인코더와 디코더는, 문장(텍스트)의 재구성 손실에 의해서만 학습(훈련)될 수 있으므로, 종래에 비해 구조가 단순화될 수 있다. 또한 문장의 재구성 을 위한 학습이 집중적으로 수행될 수 있고, 그 결과 문장의 복원 능력이 종래에 비해 향상될 수 있다. 인코더 및 디코더의 학습 동작과 관련된 상세한 내용은 추후 도 2를 통해 설명하기로 한다. 한편, 스타일 임베딩 모듈은 입력 스타일에 기초한 스타일 임베딩(style embedding)을 제공할 수 있다. 이 러한 스타일 임베딩 모듈은 스타일 임베딩 모델, 유사도 산출기, 및 스타일 분류기(style classifier; 135)를 포함할 수 있다. 스타일 임베딩 모델은 입력 스타일을 처리하여, 상기 입력 스타일에 대응하는 스타일 임베딩을 제공할 수 있다. 상기 스타일 임베딩은 벡터 형태로 제공될 수 있다. 이 경우, 상기 스타일 임베딩은 스타일 임베딩 벡터 로도 지칭될 수 있다. 상기 입력 스타일은 변환하고자 하는 스타일(타겟 스타일)을 나타내는 스타일 정보(또는 스타일 레이블(label))에 대응할 수 있으나, 이에 한정되는 것은 아니다. 예컨대, 상기 입력 스타일은 긍정, 부 정 등과 같이 문장의 전반적인 태도나 분위기 등을 나타낼 수 있다. 전술한 바와 같이, 상기 스타일 임베딩은 인코더로부터 제공되는 잠재 표현에 결합될 수 있다. 디코더 는 스타일 임베딩이 결합된 잠재 표현을 이용하여 출력 텍스트를 제공함으로써, 스타일 임베딩에 따라 스타일이 변환되는 텍스트를 재구성할 수 있다. 또한, 본 개시의 실시 예에 따르면, 스타일 임베딩의 결합 시 스타일 강도가 설정될 수 있고, 이에 따라 스타일 의 변환 정도가 달라질 수 있다. 예컨대 스타일 강도가 클수록 문장의 스타일 변환 정도가 강해질 수 있고, 스 타일 강도 값의 부호에 따라 문장의 스타일이 유사 스타일로 변환되거나 반대 스타일로 변환될 수도 있다. 이에 대해서는 추후 도 5 내지 도 7을 참조하여 보다 상세히 설명하기로 한다. 실시 예에 따라, 스타일 임베딩 모델은 신경망(neural network)을 포함하는 하드웨어, 소프트웨어, 또는 이들의 조합으로 구현될 수 있다. 유사도 산출기 및 스타일 분류기는 스타일 임베딩 모델의 학 습을 위한 구성에 해당할 수 있다. 스타일 임베딩 모듈에 포함된 구성들을 이용한 학습 동작에 대해서는 추후 도 3을 통해 설명하기로 한다. 도 2는 본 개시의 예시적 실시 예에 따른 문장 재구성 모듈의 인코더 및 디코더의 학습 동작을 설명하기 위한 도면이다. 도 2 내지 도 3의 실시 예에 따른 학습 동작은 학습 디바이스에 의해 수행될 수 있다. 상기 학습 디바이스는 도 1의 텍스트 스타일 변환 시스템을 구성하는 적어도 하나의 컴퓨팅 디바이스를 포함하거나, 별도의 학습용 컴퓨팅 디바이스를 포함할 수 있다. 도 2를 참조하면, 입력 텍스트(x)가 인코더로 입력되면, 인코더는 입력 텍스트(x)에 기초한 잠재 표 현(또는 잠재 표현 벡터; z)를 제공(출력)할 수 있다. 한편, 스타일 임베딩 모델로는 입력 텍스트(x)의 스 타일에 해당하는 입력 스타일(s)이 입력될 수 있다. 스타일 임베딩 모델은 상기 입력 스타일(s)에 기초하 여, 스타일 임베딩(또는 스타일 임베딩 벡터; se)을 제공할 수 있다. 인코더로부터 제공되는 잠재 표현(z)과, 스타일 임베딩 모델로부터 제공되는 스타일 임베딩(se)은 콤 바이너(combiner; 112)에 의해 서로 결합될 수 있다. 예컨대, 결합된 잠재 표현(z*)은 잠재 표현(z)과 스타일 임베딩(se)의 벡터 합에 해당할 수 있으나, 이에 한정되는 것은 아니다. 결합된 잠재 표현(z*)은 디코더로 입력될 수 있다. 디코더는 상기 결합된 잠재 표현(z*)에 기초하여 출력 텍스트(x')를 제공할 수 있다. 실시 예에 따라, 인코더 및 디코더는 오토인코더로 구현됨으로써, 출력 텍스트(x')가 입력 텍스트 (x)와 동일해지도록 학습될 수 있다. 인코더 및 디코더는 재구성 손실(reconstruction loss)이 최소 화되도록 학습(훈련)될 수 있다. 실시 예에 따라, 학습 시 신뢰도 및 성능의 향상을 위해 라벨 스무딩 정규화 (label smoothing regularization) 기법이 사용될 수 있다. 상기 재구성 손실(Lrec)은 아래의 수학식 1에 개시 된 재구성 손실 함수에 따라 산출될 수 있다. [수학식 1]"}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, v는 어휘의 크기를 나타내고, ε는 스무딩 파라미터(smoothing parameter)를 나타낸다. p와 는 각각 어휘에 대한 예측 확률 분포와 실제 확률 분포를 나타낼 수 있다. Eθe 는 인코더를 나타내고, Dθd는 디코더를 나 타낸다. 인코더 및 디코더 각각은 재구성 손실(Lrec)에 기초하여, 상기 재구성 손실(Lrec)이 최소화되도록 신경 망의 출력층 및 은닉층의 가중치를 갱신함으로써 학습 동작을 수행할 수 있다. 이 때 가중치를 갱신하는 동작은 역전파 알고리즘(back-propagation algorithm)에 따라 출력 텍스트의 생성 동작이 이루어지는 방향과는 반대의 방향으로 수행될 수 있다(예컨대, 디코더의 신경망의 출력층, 은닉층, 인코더의 신경망의 출력층, 및 은닉층의 순서). 한편, 이러한 재구성 손실(Lrec)은 인코더 및 디코더의 학습에만 영향을 미칠 뿐, 스타일 임베딩 모델 에는 영향을 미치지 않을 수 있다. 또한, 인코더 및 디코더는 재구성 손실(Lrec)에 의해서만 학습되므로, 문장의 재구성(복원)을 위한 집중적인 학습이 가능할 수 있다. 도 3은 본 개시의 예시적 실시 예에 따른 스타일 임베딩 모듈의 스타일 임베딩 모델 및 스타일 분류기의 학습 동작을 설명하기 위한 플로우차트이다. 도 3을 참조하면, 입력 텍스트(x)의 스타일을 나타내는 입력 스타일(s)이 스타일 임베딩 모델로 입력될 수 있다. 스타일 임베딩 모델은 복수의 스타일 임베딩들(S1, S2, 쪋, Sk; k는 스타일의 수(종류))을 포함하는 스타일 임베딩 세트(S)를 출력할 수 있다. 스타일 임베딩 세트(S)에 포함된 복수의 스타일 임베딩들 각각은 대응하는 스타일을 갖는 다양한 텍스트에 적용 가능한 일종의 공통 표현(common representation)에 해당할 수 있다. 이 경우, 복수의 스타일 임베딩들 중 어느 하나는, 입력 스타일(s)에 대응하는 스타일 임베딩에 해당할 수 있다. 예를 들어, 스타일의 종류가 '긍정' 및 '부정'의 두 가지인 경우, 스타일 임베딩 세트(S)는 '긍정'에 대응하는 제1 스타일 임베딩(S1)과, '부정'에 대응하는 제2 스타일 임베딩(S2)을 포함할 수 있다. 입력 스타일(s)이 '긍정'에 해당할 경우, 복수의 스타일 임베딩들 중 제1 스타일 임베딩(S1)이 입력 스타일(s)에 대응하는 스타일 임베딩일 수 있다. 한편, 인코더로는 입력 텍스트(x)가 입력될 수 있다. 인코더는 상기 입력 텍스트(x)에 기초한 잠재 표현(z)를 제공(출력)할 수 있다. 입력 텍스트(x)에서 스타일 표현과 관련된 부분이 분리되지 않으므로, 잠재 표현(z)에는 입력 텍스트(x)의 스타일 특성이 반영될 수 있다. 유사도 산출기는 스타일 임베딩 세트(S)에 포함된 스타일 임베딩들(S1, S2, 쪋, Sk) 각각과 잠재 표현(z) 사이의 유사도(SIM(z,S))를 산출할 수 있다. 예컨대, 유사도 산출기는 스타일 임베딩과 잠재 표현의 내적 (dot product)을 산출함으로써 상기 유사도를 산출할 수 있다. 스타일 분류기는 산출된 유사도들을 비교하여, 가장 유사도가 높은 스타일 임베딩(s')을 입력 스타일(s)의 스타일 임베딩으로서 분류할 수 있다. 예컨대, 전술한 예시에서 입력 텍스트(x)의 스타일이 '긍정'에 해당할 경 우, 제1 스타일 임베딩(S1)과 잠재 표현(z)의 유사도(SIM(z,S1))는 제2 스타일 임베딩(S2)과 잠재 표현(z)의 유 사도(SIM(z,S2))보다 높을 수 있다. 스타일 분류기는 상기 분류된 스타일 임베딩에 대한 분류 손실을 아래의 수학식 2에 따라 개시된 분류 손 실 함수에 따라 산출할 수 있다. [수학식 2]"}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 Cθc 는 스타일 분류기를 나타내고, si는 입력 텍스트 x의 스타일을 나타내며, simz,Si 는 잠재 표현과 스타일 임베딩 간의 유사성을 나타낼 수 있다. 스타일 임베딩 모델 및 스타일 분류기 각각은, 분류 손실(Lse)에 기초하여, 상기 분류된 스타일 임베 딩에 대한 분류 손실이 최소화되도록 신경망을 업데이트(출력층 및 은닉층의 가중치를 갱신)함으로써 학습 동작 을 수행할 수 있다. 이 때 가중치를 갱신하는 동작은 역전파 알고리즘(back-propagation algorithm)에 따라 스 타일의 분류 동작이 이루어지는 방향과는 반대의 방향으로 수행될 수 있다. 한편, 이러한 분류 손실(Lse)은 스타일 임베딩 모델 및 스타일 분류기의 학습에만 영향을 미칠 뿐, 문 장 재구성 모듈에 포함된 인코더 및 디코더에는 영향을 미치지 않을 수 있다. 또한, 스타일 임베 딩 모델은 상기 분류 손실(Lse)에 의해서만 학습되므로, 스타일 변환을 위한 집중적인 학습이 가능할 수 있 다. 도 1 내지 도 3의 실시 예에 따르면, 본 개시의 실시 예에 따른 텍스트 스타일 변환 시스템은 문장 재구성 모듈과 스타일 임베딩 모듈을 분리하여, 문장의 재구성(복원)을 위한 학습 및 스타일 표현을 위한 학습 이 서로 분리되어 수행될 수 있다. 이에 따라, 문장 재구성 모듈의 인코더와 디코더의 구조가 단 순화되고, 문장의 복원 능력이 향상될 수 있다. 상술한 실시 예들에 따라 학습된 문장 재구성 모듈 및 스타일 임베딩 모듈을 이용한 텍스트 스타일 변 환 동작에 대해, 이하 도 4 내지 도 7을 참조하여 설명하기로 한다. 도 4는 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 방법을 설명하기 위한 플로우차트이다. 도 5는 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 시스템의 텍스트 스타일 변환 동작을 설명하기 위한 도면이 다. 도 4와 도 5를 참조하면, 텍스트 스타일 변환 방법은 입력 텍스트(x)를 획득하는 단계(S300), 및 인코더를 통해 입력 텍스트에 대한 잠재 표현을 획득하는 단계를 포함할 수 있다(S310). 입력 텍스트(x)는 텍스트 스타일 변환 시스템을 구성하는 적어도 하나의 컴퓨팅 장치 중 어느 하나로 입력 될 수 있다. 예컨대 입력 텍스트(x)는 통신 인터페이스나 각종 공지된 입력 수단을 통해 입력될 수 있다. 인코더는 신경망을 통해, 입력 텍스트(x)에 대응하는 잠재 표현(또는 잠재 표현 벡터)을 제공할 수 있다. 텍스트 스타일 변환 방법은 스타일 임베딩 모델로부터 출력되는 스타일 임베딩을 상기 잠재 표현에 결합하 는 단계(S320), 및 디코더를 통해, 상기 결합된 잠재 표현에 대한 출력 텍스트를 획득하는 단계를 포함할 수 있다(S330). 스타일 임베딩 모델은 변환할 스타일의 정보(또는 레이블)을 포함하는 입력 스타일(s)을 획득할 수 있다. 입력 텍스트(x)와 마찬가지로, 입력 스타일(s)은 상기 적어도 하나의 컴퓨팅 중 어느 하나로 입력될 수 있다. 한편, 입력 스타일(s)은 변환하고자 하는 타겟 스타일의 스타일 정보(또는 스타일 레이블)에 해당할 수 있으나, 실시 예에 따라서는 입력 텍스트(x)의 스타일을 나타내는 스타일 정보일 수도 있다. 스타일 임베딩 모델은 신경망을 통해, 입력 스타일(s)에 대응하는 스타일 임베딩(또는 스타일 임베딩 벡터)을 제공할 수 있다. 텍스트 스타일 변환 시스템은 상기 잠재 표현과 상기 스타일 임베딩을 결합함으로써, 결합된 잠재 표현을 획득할 수 있다. 상술한 바와 같이 텍스트 스타일 변환 시스템은 상기 잠재 표현과 상기 스타일 임베딩의 벡터 합을 산출하는 콤바이너를 포함할 수 있으나, 이에 한정되는 것은 아니다. 디코더는 신경망을 통해, 상기 결합된 잠재 표현에 대응하는 출력 텍스트(y)를 제공함으로써, 입력 텍스트 (x)의 스타일이 변환된 텍스트를 재구성할 수 있다. 실시 예에 따라, 텍스트 스타일 변환 시스템은 상기 스타일 임베딩에 스타일 강도를 적용하고, 스타일 강도 가 적용된 스타일 임베딩과 상기 잠재 표현을 결합할 수도 있다. 상술한 바와 같이, 스타일 강도의 값에 따라 스타일 변환의 정도가 달라질 수 있는 바, 스타일 강도의 적용에 따라 보다 다양한 출력 텍스트가 제공될 수 있 다. 스타일 강도(w)는 아래의 수학식 3에 기초하여 적용될 수 있다. [수학식 3]"}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, z*는 결합된 잠재 표현을 의미하고, z는 잠재 표현을 의미하며, se는 스타일 임베딩을 의미할 수 있다. 상기 수학식 3에 기초하면, 스타일 강도의 부호에 따라 출력 텍스트(y)의 스타일이 변경될 수도 있다. 예컨대 입력 스타일(s)이 입력 텍스트(x)의 스타일과 동일하고, 스타일 강도가 음수의 값을 갖는 경우, 출력 텍스트 (y)는 입력 텍스트(x)와 반대의 스타일을 갖는 문장으로 재구성될 수 있을 것이다. 종래의 텍스트 스타일 변환 방법에 따르면 스타일 강도의 적용이 불가능하므로, 출력 텍스트의 스타일은 설정된 스타일의 종류에 따라 이산적으로 변환된다. 그러나, 본 개시에 따르면 스타일 강도의 조절에 따라 동일한 스타 일에 대해서도 다양한 형태의 출력 텍스트가 제공될 수 있으므로, 출력 텍스트의 스타일이 보다 연속적으로 변 환될 수 있다.이하 도 6 내지 도 7을 참조하여, 본 개시의 실시 예에 따른 텍스트 스타일 변환의 예들을 설명하기로 한다. 도 6은 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 방법에 따라 입력 텍스트의 스타일이 변환된 출력 텍스트의 예들을 나타낸다. 텍스트 스타일 변환 시스템은 부정적(negative) 스타일을 갖는 입력 텍스트를 긍정적(positive) 스타일의 출력 텍스트로 변환할 수 있다. 예컨대, \"so, no treatment and no medication to help me deal with my condition.\"과 같은 입력 텍스트에는 부정적 스타일을 나타내는 'no' 부분이 존재할 수 있다. 텍스트 스타일 변 환 시스템은 입력 텍스트 중 부정적 스타일과 관련된 부분(단어)을 긍정적 스타일을 나타내는 단어('best', 'great' 등)로 변경함으로써, 입력 텍스트를 긍정적 스타일의 출력 텍스트로 변환할 수 있다. 이 경우, 스타일 임베딩 모듈로 입력되는 입력 스타일은 '긍정'에 해당하는 스타일 정보(또는 스타일 레이 블)일 수 있다. 또는, 입력 스타일은 상기 입력 텍스트의 스타일에 대응하는 '부정'에 해당하고, 입력 텍스트의 잠재 표현과 스타일 임베딩의 결합 시 스타일 강도(w)가 음수의 값을 가질 수 있다. 또는, 텍스트 스타일 변환 시스템은 긍정적 스타일을 갖는 입력 텍스트를 부정적 스타일의 출력 텍스트로 변환할 수 있다. 예컨대, \"he is very thorough and genuinely cares for his customers.\"와 같은 입력 텍스트 에는 긍정적 스타일을 나타내는 'thorough' 및 'genuinely'부분이 존재할 수 있다. 텍스트 스타일 변환 시스템 은 입력 텍스트 중 긍정적 스타일과 관련된 부분(단어)을 부정적 스타일을 나타내는 단어('never', 'lazy', 'not' 등)로 변경함으로써, 입력 텍스트를 부정적 스타일의 출력 텍스트로 변환할 수 있다. 이 경우, 스타일 임베딩 모듈로 입력되는 입력 스타일은 '부정'에 해당하는 스타일 정보(또는 스타일 레이 블)일 수 있다. 또는, 입력 스타일은 상기 입력 텍스트의 스타일에 대응하는 '부정'에 해당하고, 입력 텍스트의 잠재 표현과 스타일 임베딩의 결합 시 스타일 강도(w)가 음수의 값을 가질 수 있다. 또한, 텍스트 스타일 변환 시스템은 스타일 강도(w)에 따라 서로 다른 출력 텍스트를 제공할 수도 있다. 텍 스트 스타일 변환 시스템은 스타일 강도(w)의 값이 클수록 스타일 변환 정도가 증가한 출력 텍스트를 제공 할 수 있다. 도 6에 도시된 예들 각각에서, 스타일 강도(w)가 8에서 10으로 증가할수록 출력 텍스트의 변환 정 도가 전반적으로 증가함을 확인할 수 있다. 본 개시의 실시 예에 따른 텍스트 스타일 변환 시스템은 문장의 재구성을 위한 문장 재구성 모듈과, 스 타일 표현을 위한 스타일 임베딩 모듈이 분리되어 구현됨으로써, 스타일 변환 시 스타일 강도를 적용함으로 써 보다 다양한 형태의 출력 텍스트를 획득할 수 있다. 도 7은 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 방법에 따른 출력 텍스트와, 종래의 방법에 따른 출력 텍스트를 비교한 예이다. 종래의 텍스트 스타일 변환 방법의 경우 하나의 모델에서 문장 재구성 및 스타일 임베딩의 학습이 모두 이루어 질 수 있다. 이에 따라 모델의 복잡도가 증가하게 되고, 스타일 변환 시 이산적 스타일 변환만이 가능해지는 문 제가 존재한다. 도 7에 도시된 바와 같이, 종래의 방법은 동일한 스타일로의 변환 시에는 입력 텍스트와 동일한 출력 텍스트만을 제공하게 된다. 반면, 본 개시의 실시 예에 따른 텍스트 스타일 변환 방법의 경우, 문장 재구성 모듈과 스타일 임베딩 모듈 이 별도로 구현되므로, 스타일 변환 시 보다 다양한 표현을 활용한 스타일 변환이 가능할 수 있다. 도 7에 도시된 바와 같이, 본 개시의 실시 예에 따른 텍스트 스타일 변환 방법의 경우, 입력 텍스트를 동일한 스타일로 변환하더라도 입력 텍스트와는 다른 표현이 포함된 출력 텍스트가 제공될 수 있다. 하기의 표 1은, 종래의 텍스트 스타일 변환 방법과 본 개시의 실시 예에 따른 텍스트 스타일 변환 방법에 대한 평가 결과를 나타낸다.[표 1]"}
{"patent_id": "10-2020-0126671", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "표 1에 기재된 'Accuracy' 항목은 입력 텍스트와 출력 텍스트의 동일성을 나타내는 항목으로서, 값이 낮을수록 스타일 변환 정도가 높음을 나타낸다. 즉, 본 개시에 따른 텍스트 스타일 변환 방법은 종래의 방법에 비해 텍스 트의 스타일 변환이 효과적으로 이루어짐을 알 수 있다. 한편, 본 개시에 따르면 스타일 강도의 조절이 가능하 고, 스타일 강도가 낮아질수록 스타일 변환 정도가 감소하므로 'Accuracy'항목의 값은 높아질 수 있다. 또한, 'Self-BLEU(bilingual evaluation understudy)' 항목은 텍스트 중 스타일과 관련되지 않은 부분의 동일 성에 대한 항목으로서, 값이 높을수록 입력 텍스트 중 스타일과 관련되지 않은 부분이 잘 유지된 출력 텍스트가 재구성됨을 의미한다. 즉, 본 개시에 따른 텍스트 스타일 변환 방법은 종래의 방법에 비해 입력 텍스트 중 스타 일과 관련되지 않은 부분을 잘 유지하고 있음을 알 수 있다. 도 8은 도 1의 텍스트 스타일 변환 시스템을 구성하는 디바이스의 제어 구성을 나타내는 개략적인 블록도이다. 도 8을 참조하면, 본 개시의 실시 예에 따른 디바이스는 도 1에서 상술한 텍스트 스타일 변환 시스템 을 구성하는 적어도 하나의 컴퓨팅 장치 중 어느 하나에 대응할 수 있다. 이러한 디바이스는 프로세서 및 메모리를 포함할 수 있다. 다만, 디바이스의 구성 요소가 전술한 예에 한정되는 것은 아니다. 예를 들어, 디바이스는 전술한 구성 요소들보다 더 많은 구성 요소를 포함하거나 더 적은 구성 요소를 포함할 수 있다. 또한, 프로세서는 적어도 하나일 수 있으며, 메모리 또한 적어도 하나일 수 있다. 또한, 프로세서 및 메모리가 하나의 칩으로 결합된 형태일 수도 있다. 본 개시의 일 실시 예에 따르면, 프로세서는 입력 텍스트 및 상기 입력 텍스트의 스타일 정보를 이용하여 문장 재구성 모듈의 인코더 및 디코더의 학습을 수행할 수 있다. 또한, 프로세서는 입력 텍 스트 및 스타일 정보를 이용하여 스타일 임베딩 모듈의 학습을 수행할 수 있다. 실시 예에 따라, 프로세서는 프로세서는 학습된 문장 재구성 모듈 및 스타일 임베딩 모듈을 이용하여, 입력 텍스트의 스타일을 타겟 스타일로 변환한 출력 텍스트를 획득하거나, 입력 텍스트의 스타일을 스타일 강도에 따라 다양하게 변환한 출력 텍스트를 획득할 수 있다. 이러한 프로세서는 CPU, AP(application processor), 집적 회로, 마이크로컴퓨터, ASIC(application specific integrated circuit), FPGA(field programmable gate array), 및/또는 NPU(neural processing unit) 등의 하드웨어를 포함할 수 있다. 본 개시의 일 실시 예에 따르면, 메모리는 디바이스의 동작에 필요한 프로그램 및 데이터를 저장할 수 있다. 또한, 메모리는 프로세서를 통해 생성되거나 획득된 데이터 중 적어도 하나를 저장할 수 있다. 예를 들어, 메모리는 학습용 텍스트나 손실 함수 등을 저장할 수 있다. 메모리는 롬(ROM), 램(RAM), 플래시 메모리, SSD, HDD 등의 저장 매체 또는 저장 매체들의 조합으로 구성 될 수 있다. 상기한 실시 예들의 설명은 본 개시의 더욱 철저한 이해를 위하여 도면을 참조로 예를 든 것들에 불과하므로, 본 개시의 기술적 사상을 한정하는 의미로 해석되어서는 안될 것이다. 또한, 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 있어 본 개시의 기본적 원리를 벗어나지 않 는 범위 내에서 다양한 변화와 변경이 가능함은 명백하다 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2020-0126671", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 시스템의 개략적인 블록도이다. 도 2는 본 개시의 예시적 실시 예에 따른 문장 재구성 모듈의 인코더 및 디코더의 학습 동작을 설명하기 위한 도면이다. 도 3은 본 개시의 예시적 실시 예에 따른 스타일 임베딩 모듈의 스타일 임베딩 모델 및 스타일 분류기의 학습 동작을 설명하기 위한 플로우차트이다.도 4는 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 방법을 설명하기 위한 플로우차트이다. 도 5는 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 시스템의 텍스트 스타일 변환 동작을 설명하기 위 한 도면이다. 도 6은 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 방법에 따라 입력 텍스트의 스타일이 변환된 출력 텍스트의 예들을 나타낸다. 도 7은 본 개시의 예시적 실시 예에 따른 텍스트 스타일 변환 방법에 따른 출력 텍스트와, 종래의 방법에 따른 출력 텍스트를 비교한 예이다. 도 8은 도 1의 텍스트 스타일 변환 시스템을 구성하는 디바이스의 제어 구성을 나타내는 개략적인 블록도이다."}
