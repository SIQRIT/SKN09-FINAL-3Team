{"patent_id": "10-2020-0120922", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0099991", "출원번호": "10-2020-0120922", "발명의 명칭": "딥 러닝 처리 장치, 방법, 기기 및 저장 매체", "출원인": "베이징 바이두 넷컴 사이언스 앤 테크놀로지 코.,", "발명자": "공 샤오장"}}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥 러닝 처리 장치로서, 컨볼루션 신경망의 컨볼루션층의 컨볼루션 커널 파라미터 값 행렬과 제1 오차 그래디언트 값 행렬의 행렬 곱셈-누적 연산을 수행하여, 복수의 중간 행렬을 획득하도록 구성된 적어도 하나의 행렬 곱셈-누적 모듈;상기 복수의 중간 행렬의 요소들을 재구성하지 않고 상기 복수의 중간 행렬을 저장하도록 구성된 저장 장치; 및상기 저장 장치로부터 상기 복수의 중간 행렬을 판독하고 병렬 방식으로 상기 컨볼루션층의 컨볼루션 방식에 따라 상기 복수의 중간 행렬을 기반으로 행렬 누적 연산을 수행함으로써, 상기 컨볼루션층에 대한 제2 오차 그래디언트 값 행렬을 획득하도록 구성된 복수의 행렬 누적 모듈을 포함하는, 딥 러닝 처리 장치."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 중간 행렬은 상기 컨볼루션층의 입력의 복수의 채널과 연관되고, 상기 제2 오차 그래디언트 값 행렬은 상기 복수의 채널에 대한 복수의 채널 행렬을 포함하며,상기 복수의 행렬 누적 모듈 중 각각의 행렬 누적 모듈은,상기 복수의 채널에 대응하는 복수의 병렬 경로 중 하나의 병렬 경로 상에서, 상기 복수의 중간 행렬 중 상기복수의 채널 중의 하나의 채널과 관련된 중간 행렬을 누적하여, 상기 하나의 채널에 대한 상기 채널 행렬을 획득하도록 구성되거나, 또는매번의 누적에 있어서, 상기 복수의 중간 행렬 중의 하나의 중간 행렬을 상기 복수의 채널 행렬 중의 하나의 채널 행렬의 중간 결과에 누적시키도록 구성되는, 딥 러닝 처리 장치."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 저장 장치는 목표 저장 위치에 상기 제2 오차 그래디언트 값 행렬을 저장하도록 구성되고, 상기 제2 오차그래디언트 값 행렬은 상기 행렬 누적 연산 이전에 all-zero 값을 갖고;상기 복수의 행렬 누적 모듈은 병렬 방식으로 상기 복수의 중간 행렬과 상기 목표 저장 위치에 저장된 초기값을갖는 상기 제2 오차 그래디언트 값 행렬을 누적하도록 구성되는, 딥 러닝 처리 장치."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 복수의 행렬 누적 모듈 중 적어도 하나의 행렬 누적 모듈은,누적할 행렬 중의 제1 요소 및 제2 요소를 수신하고, 상기 제1 요소와 상기 제2 요소를 누적하여 누적 요소를획득하도록 구성된 덧셈 연산 유닛;상기 누적 요소를 상기 저장 장치에 기록하도록 구성된 데이터 기록 유닛;상기 누적 요소를 캐시하도록 구성된 제1 캐시 영역; 및상기 덧셈 연산 유닛이 제3 요소와 상기 누적 요소의 누적을 수행하고자 할 경우 상기 저장 장치로부터 상기 누적 요소를 판독할 수 없음이 확정됨에 따라, 상기 제1 캐시 영역에 캐시된 상기 누적 요소를 상기 덧셈 연산 유닛에 제공하도록 구성된 바이패스 모듈공개특허 10-2021-0099991-3-을 포함하되, 상기 제1 캐시 영역의 기록 속도는 상기 저장 장치보다 빠르고, 상기 누적 요소는 상기 제1 캐시영역에서 복수의 클럭 사이클 동안 캐시되는, 딥 러닝 처리 장치."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 저장 장치는 온-칩 랜덤 액세스 메모리를 포함하는, 딥 러닝 처리 장치."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 딥 러닝 처리 장치는,상기 적어도 하나의 행렬 곱셈-누적 모듈이 상기 행렬 곱셈-누적 연산 과정에서 생성한 제1 중간 연산 결과 및상기 복수의 행렬 누적 모듈이 상기 행렬 누적 연산 과정에서 생성한 제2 중간 연산 결과를 캐시하도록 구성된제2 캐시 영역을 더 포함하는, 딥 러닝 처리 장치."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 딥 러닝 처리 장치는 벡터 계산 모듈을 더 포함하되,상기 벡터 계산 모듈은,벡터 레벨에서 상기 제2 캐시 영역 중 상기 제1 중간 연산 결과 및 상기 제2 중간 연산 결과를 저장하기 위한저장 영역을 0으로 설정하는 동작; 및벡터 레벨에서 상기 행렬 누적 연산의 최종 연산 결과를 상기 딥 러닝 처리 장치의 저장 장치에 상기 제2 오차그래디언트 값 행렬의 적어도 일부분으로서 선택적으로 기록하는 동작중 적어도 하나를 수행하도록 구성되는, 딥 러닝 처리 장치."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,범용 처리 장치로부터 상기 CNN의 상기 컨볼루션층의 컨볼루션 방향 작업에 대한 명령어 세트를 획득하고 상기명령어 세트를 파싱하도록 구성된 명령어 처리 모듈; 및파싱된 상기 명령어 세트를 기반으로 상기 적어도 하나의 행렬 곱셈-누적 모듈 및 상기 복수의 행렬 누적 모듈에 대한 제어 신호를 생성하도록 구성된 제어 신호 생성 모듈을 더 포함하는, 딥 러닝 처리 장치."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 적어도 하나의 행렬 곱셈-누적 모듈은 병렬 방식으로 상기 행렬 곱셈-누적 연산을 수행하도록 구성된 복수의 행렬 곱셈-누적 모듈을 포함하는, 딥 러닝 처리 장치."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "딥 러닝 처리를 수행하는 방법으로서,딥 러닝 처리 장치의 적어도 하나의 행렬 곱셈-누적 모듈이 컨볼루션 신경망의 컨볼루션층의 컨볼루션 커널 파라미터 값 행렬과 제1 오차 그래디언트 값 행렬의 행렬 곱셈-누적 연산을 수행하여 복수의 중간 행렬을 획득하도록 하는 단계;상기 복수의 중간 행렬의 요소들을 재구성하지 않고 상기 복수의 중간 행렬을 저장 장치에 저장하는 단계;공개특허 10-2021-0099991-4-상기 저장 장치로부터 상기 복수의 중간 행렬을 판독하는 단계; 및상기 딥 러닝 처리 장치의 복수의 행렬 누적 모듈이 병렬 방식으로 컨볼루션층의 컨볼루션 방식에 따라 상기 복수의 중간 행렬을 기반으로 행렬 누적 연산을 수행함으로써, 상기 컨볼루션층에 대한 제2 오차 그래디언트 값행렬을 획득하도록 하는 단계를 포함하는, 딥 러닝 처리를 수행하는 방법."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 복수의 중간 행렬은 상기 컨볼루션층의 입력의 복수의 채널과 연관되고, 상기 제2 오차 그래디언트 값 행렬은 상기 복수의 채널에 대한 복수의 채널 행렬을 포함하며,상기 복수의 행렬 누적 모듈이 병렬 방식으로 상기 컨볼루션층의 컨볼루션 방식에 따라 상기 복수의 중간 행렬을 기반으로 행렬 누적 연산을 수행하는 것은, 상기 복수의 행렬 누적 모듈 중 각각의 행렬 누적 모듈이 상기 복수의 채널에 대응하는 복수의 병렬 경로 중 하나의 병렬 경로 상에서, 상기 복수의 중간 행렬 중 상기 복수의 채널 중의 하나의 채널과 관련된 중간 행렬을누적하여, 상기 하나의 채널에 대한 상기 채널 행렬을 획득하도록 하거나, 또는상기 복수의 행렬 누적 모듈 중 각각의 행렬 누적 모듈이 매번의 누적에 있어서, 상기 복수의 중간 행렬 중의하나의 중간 행렬을 상기 복수의 채널 행렬 중의 하나의 채널 행렬의 중간 결과에 누적시키도록 하는 것을 포함하는, 딥 러닝 처리를 수행하는 방법."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 복수의 행렬 누적 모듈이 병렬 방식으로 상기 컨볼루션층의 컨볼루션 방식에 따라 상기 복수의 중간 행렬을 기반으로 행렬 누적 연산을 수행하는 단계는, 상기 복수의 행렬 누적 모듈 중의 적어도 하나의 행렬 누적 모듈이,제1 요소 및 제2 요소를 누적하여 누적 요소를 획득하는 것;상기 누적 요소를 상기 저장 장치에 기록하는 것;상기 누적 요소를 제1 캐시 영역에 캐시하는 것; 및상기 덧셈 연산 유닛이 제3 요소 및 상기 누적 요소의 누적을 수행하고자 할 경우 상기 저장 장치로부터 상기누적 요소를 판독할 수 없음이 확정됨에 따라, 상기 제1 캐시 영역에 캐시된 상기 누적 요소를 상기 제3 요소와의 누적에 사용되도록 제공하는 것을 포함하되, 상기 제1 캐시 영역의 기록 속도는 상기 저장 장치보다 빠르고, 상기 누적 요소는 상기 제1 캐시영역에서 복수의 클럭 사이클 동안 캐시되는, 딥 러닝 처리를 수행하는 방법."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 적어도 하나의 행렬 곱셈-누적 모듈이 상기 행렬 곱셈-누적 연산 과정에서 생성한 제1 중간 연산 결과 및상기 복수의 행렬 누적 모듈이 상기 행렬 누적 연산 과정에서 생성한 제2 중간 연산 결과를 제2 캐시 영역에 캐시하는 단계를 더 포함하는, 딥 러닝 처리를 수행하는 방법."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 딥 러닝 처리 장치의 벡터 계산 모듈이, 벡터 레벨에서 상기 제2 캐시 영역 중 상기 제1 중간 연산 결과 및 상기 제2 중간 연산 결과를 저장하기 위한저장 영역을 0으로 설정하는 동작; 및공개특허 10-2021-0099991-5-벡터 레벨에서 상기 행렬 누적 연산의 최종 연산 결과를 상기 딥 러닝 처리 장치의 저장 장치에 상기 제2 오차그래디언트 값 행렬의 적어도 일부분으로서 선택적으로 기록하는 동작중 적어도 하나를 수행하도록 하는 단계를 더 포함하는, 딥 러닝 처리를 수행하는 방법."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항 내지 제14항 중 어느 한 항에 있어서 범용 처리 장치로부터 상기 CNN의 상기 컨볼루션층의 컨볼루션 방향 작업에 대한 명령어 세트를 획득하고 상기명령어 세트를 파싱하는 단계; 및파싱된 상기 명령어 세트를 기반으로 상기 적어도 하나의 행렬 곱셈-누적 모듈 및 상기 복수의 행렬 누적 모듈에 대한 제어 신호를 생성하는 단계를 더 포함하는, 딥 러닝 처리를 수행하는 방법."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항 내지 제14항 중 어느 한 항에 있어서, 상기 적어도 하나의 행렬 곱셈-누적 모듈은 복수의 행렬 곱셈-누적 모듈을 포함하고, 상기 적어도 하나의 곱셈-누적 모듈이 상기 행렬 곱셈-누적 연산을 수행하는 것은,상기 복수의 행렬 곱셈-누적 모듈이 병렬 방식으로 상기 행렬 곱셈-누적 연산을 수행하도록 하는 것을포함하는, 딥 러닝 처리를 수행하는 방법."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "전자 기기로서,제1항 내지 제9항 중 어느 한 항에 따른 적어도 하나의 딥 러닝 처리 장치; 및상기 적어도 하나의 딥 러닝 처리 장치와 결합되고 상기 적어도 하나의 딥러닝 처리 장치에 컨볼루션 신경망(CNN)에 대한 훈련을 수행하기 위한 명령어를 제공하도록 구성된 적어도 하나의 범용 처리 장치를 포함하는, 전자 기기."}
{"patent_id": "10-2020-0120922", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "비일시적 컴퓨터 판독 가능한 저장 매체로서,내부에 컴퓨터 프로그램이 저장되어 있고, 상기 프로그램이 프로세서에 의해 실행될 경우 제10항 내지 제16항중 어느 한 항의 상기 방법을 구현하는, 비일시적 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2020-0120922", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 실시예는 인공 지능 분야에 관한 것으로, 딥 러닝 처리 장치, 방법, 기기 및 저장 매체를 제공한다. 딥 러닝 처리 장치는 컨볼루션 신경망 중 컨볼루션층의 컨볼루션 커널 파라미터 값 행렬과 제1 오차 그래디언트 값 행렬의 행렬 곱셈-누적 연산을 하여, 복수의 중간 행렬을 획득하도록 구성된 적어도 하나의 행렬 곱셈-누적 모듈; 복수의 중간 행렬의 요소들을 재구성하지 않고 복수의 중간 행렬을 저장하도록 구성된 저장 장치; 및 저장 장치로부터 복수의 중간 행렬을 판독하고 병렬 방식으로 컨볼루션층의 컨볼루션 방식에 따라 복수의 중간 행렬을 기반으로 행렬 누적 연산을 하여, 컨볼루션층에 대한 제2 오차 그래디언트 값 행렬을 획득하도록 구성된 복수의 행렬 누적 모듈을 포함한다. 이러한 딥 러닝 처리 장치는 컨볼루션 역방향 작업의 계산 효율을 높이고, 계산 속 도 및 전력 소비 등 방면에서 향상된 효과를 얻을 수 있다."}
{"patent_id": "10-2020-0120922", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 실시예는 전체적으로 데이터 처리 분야에 관한 것이고, 보다 상세하게는 인공 지능 분야에 관한 것이다."}
{"patent_id": "10-2020-0120922", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥 러닝은 인공 신경망의 연구 방향 중의 하나이다. 최근 인공 지능 분야에서 하드웨어와 소프트웨어가 끊임없 이 개선됨에 따라, 딥 러닝 기술은 빠른 발전을 보이고 있다. 딥 러닝 기술은 컴퓨터 비전, 자연어 처리, 오디 오 분석 등과 같은 다양한 분야에 적용될 수 있다. 컨볼루션 신경망(CNN)은 딥 러닝 기술의 영향력 있는 네트워 크 모델로, 특히 이미지 및 텍스트 데이터와 관련된 응용에 적합하다. 컨볼루션 신경망과 관련된 연산에는 주로 컨볼루션(convolution) 연산, 완전 연결(FC) 연산, 풀링(pooling) 연산, 벡터 연산, 활성화 연산 등이 포함되고, 그 중 가장 중요한 연산은 컨볼루션 작업이다. CNN 훈련 과정에서 모델 최적화를 구현하기 위해 훈련 데이터를 사용하여 순방향 연산을 수행하는 것 외에도 역 전파 방식을 사용하여 모델의 파라미터 최적화를 구현하기도 한다. CNN 훈련 프로세스는 모두 컨볼루션층의 대량의 컨볼루션 작업과 컨볼루션 역방향 작업과 관련이 있다. 일부 CNN 아키텍처에서 컨볼루션 작업과 컨볼루션 역방향 작업은 전체 아키텍처 연산의 컴퓨팅 자원 및 시간의 대부 분을 차지할 수 있다. 딥 러닝 프로세서는 딥 러닝 연산을 구현하는데 사용될 수 있고, 딥 러닝 네트워크 훈련 을 지원할 수 있다. 딥 러닝 프로세서가 컨볼루션 작업 및/또는 컨볼루션 역방향 작업을 더 빠르고 효율적으로 처리하기를 요구하고 있으며, 이는 전체 딥 러닝 네트워크, 특히 CNN의 훈련을 가속화하는데 도움이 될 수 있다. 본 개시의 실시예에서는, 딥 러닝 처리를 수행하는 방법을 제공한다. 본 개시의 제1 양태에 있어서, 딥 러닝 처리 장치를 제공한다. 상기 딥 러닝 처리 장치는 컨볼루션 신경망의 컨 볼루션층의 컨볼루션 커널 파라미터 값 행렬과 제1 오차 그래디언트 값 행렬의 행렬 곱셈-누적 연산을 수행하여, 복수의 중간 행렬을 획득하도록 구성된 적어도 하나의 행렬 곱셈-누적 모듈; 상기 복수의 중간 행렬 의 요소들을 재구성하지 않고 상기 복수의 중간 행렬을 저장하도록 구성된 저장 장치; 및 상기 저장 장치로부터 상기 복수의 중간 행렬을 판독하고 병렬 방식으로 상기 컨볼루션층의 컨볼루션 방식(convolution scheme)에 따 라상기 복수의 중간 행렬을 기반으로 행렬 누적 연산을 수행함으로써, 상기 컨볼루션층에 대한 제2 오차 그래디 언트 값 행렬을 획득하도록 구성된 복수의 행렬 누적 모듈을 포함한다. 본 개시의 제2 양태에 있어서, 딥 러닝 처리를 수행하는 방법을 제공한다. 상기 방법은 딥 러닝 처리 장치의 적 어도 하나의 행렬 곱셈-누적 모듈이 컨볼루션 신경망의 컨볼루션층의 컨볼루션 커널 파라미터 값 행렬과 제1 오 차 그래디언트 값 행렬의 행렬 곱셈-누적 연산을 수행하여 복수의 중간 행렬을 획득하도록 하는 단계; 복수의 중간 행렬의 요소들을 재구성하지 않고 복수의 중간 행렬을 저장 장치에 저장하는 단계; 상기 저장 장치로부터 상기 복수의 중간 행렬을 판독하는 단계; 및 상기 딥 러닝 처리 장치의 복수의 행렬 누적 모듈이 병렬 방식으로 컨볼루션층의 컨볼루션 방식에 따라 복수의 중간 행렬을 기반으로 행렬 누적 연산을 수행함으로써, 상기 컨볼루 션층에 대한 제2 오차 그래디언트 값 행렬을 획득하도록 하는 단계를 포함한다. 본 개시의 제3 양태에 있어서, 전자 기기를 제공한다. 상기 전자 기기는 제1 양태에 따른 적어도 하나의 딥 러 닝 처리 장치; 및 상기 적어도 하나의 딥 러닝 처리 장치에 결합되고 상기 적어도 하나의 딥 러닝 처리 장치에 컨볼루션 신경망(CNN)에 대한 훈련을 수행하기 위한 명령어를 제공하도록 구성된 적어도 하나의 범용 처리 장치 를 포함한다. 본 개시의 제4 양태에 있어서, 내부에 컴퓨터 프로그램이 저장된 컴퓨터 판독 가능한 저장 매체를 제공하며, 상 기 프로그램이 프로세서에 의해 실행될 경우 본 개시의 제2 양태에 따른 방법을 구현한다. 본 개시의 명세서에 제공되는 설명은 본 개시 실시예의 핵심 또는 중요한 특징을 제한하려는 것이 아니며, 또한 본 개시의 범위를 제한하려는 것도 아님을 이해할 것이다. 본 개시의 다른 특징들은 이하의 설명을 통해 쉽게 이해될 것이다."}
{"patent_id": "10-2020-0120922", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부된 도면을 참조하여 본 개시의 실시예를 보다 상세하게 설명하고자 한다. 도면에 본 개시의 일 부 실시예를 도시하였으나, 본 개시는 다양한 형태로 구현될 수 있고 본 명세서에 제시된 실시예에 국한되는 것 이 아니라, 이러한 실시예들은 다만 본 개시를 더 철저하고 완벽하게 설명하기 위해 제공되는 것으로 이해하여 야 한다. 본 개시의 도면 및 실시예는 단지 예시적인 것으로, 본 개시의 청구 범위를 제한하는 것이 아님은 자 명할 것이다. 본 개시의 실시예 설명에서, \"포함하는\" 및 이와 유사한 용어는 개방적인 의미, 즉 \"포함하되 제한하지 않는\" 것으로 이해되어야 한다. \"기반하여\"는 \"적어도 부분적으로 기반하여\"로 이해되어야 한다. \"일 실시예\" 또는 \" 상기 실시예\"는 \"적어도 하나의 실시예\"로 이해되어야 한다. \"제1\", \"제2\" 등은 다르거나 같은 대상을 지칭할 수 있다. 이하 명세서에서 또한 이와 다른 명확하고 함축적인 정의를 포함할 수도 있다. 상술한 바와 같이, 컨볼루션 신경망(CNN)의 훈련 및 추론, 특히 컨볼루션층의 컨볼루션 작업 및 역방향 컨볼루 션 작업에 있어서 매우 복잡한 작업들을 처리해야 한다. 범용 프로세서를 사용하여 CNN 훈련 또는 추론을 수행 할 경우 처리 효율이 매우 낮다. 현재 일부 방안에서 그래픽 처리 장치(GPU)를 사용하여 CNN 처리, 특히 CNN 훈 련을 구현한다. GPU는 SIMT(Single Instruction Multiple Thread) 기술을 사용하여 대량의 스레드를 통해 연산 을 스케줄링하고 구현하므로, 계산 속도를 높일 수 있다. 그러나 GPU에는 대량의 레지스터 파일, 복잡한 스레드 스케줄링 메커니즘 및 캐시 관리가 필요하므로, 전력 소비가 높고 계산 효율이 떨어진다. 따라서, 딥 러닝 처리, 특히 CNN 관련 처리를 위해 보다 효율적인 처리 장치를 제공하는 것이 필요하다. CNN 관련 처리를 위한 처리 장치를 설명하기 전에 우선 CNN에 대한 간략한 소개를 한다. CNN은 딥 러닝 모델 중 하나로서, 딥 러닝 모델에서 처리에 사용되는 파라미터 세트의 값은 훈련 프로세스를 통해 결정된다. 머신 러닝 모델은 훈련 파라미터 세트를 사용하여 수신된 입력을 대응하는 출력에 매핑한다. 따라서, 머신 러닝 모델의 훈 련 과정은 훈련 데이터로부터 입력과 출력 간의 매핑 또는 연관 관계를 학습하는 것으로 볼 수 있다. CNN은 일반적으로 입력층, 컨볼루션층, 풀링층, 활성화층, 완전 연결층 및 출력층을 포함할 수 있다. 구체적인 처리 태스크 요구 및 구성에 따라 CNN의 컨볼루션층, 풀링층, 활성화층 및 완전 연결층의 개수, 연결 관계 등은 모두 다양하게 변할 수 있다. 도 1은 CNN 구조의 일 예로, 입력층, 컨볼루션층, 활성화층, 풀링층 …… 완전 연결층 및 출력층를 나타낸다. 모델에 의해 처리되는 입력은 입력층으로 서 CNN에 제공되어 처리된다. 순방향 처리에서, 입력된 데이터는 복수의 중간층을 거쳐 처리되고, 최 종적으로 출력층의 출력 결과로 획득된다. CNN의 훈련 과정에서, 훈련 데이터는 순방향 처리를 거쳐야 할 뿐만 아니라 또한 역방향 처리도 거쳐야 한다. 역방향 처리에 있어서, 일반적으로 CNN 파라미터 세트의 현재 값 조건 하에서 입력된 훈련 데이터를 처리함으로써 획득된 출력과 이상적인 출력 사이의 오차를 계산하고, 그 후 상기 오차를 반대 방 향(즉, 출력층에서 입력층으로의 방향)을 따라 전파한다. 역전파 과정에서, 경사 하강법에 따라 CNN의 각 층의 파라미터의 현재 값을 조정한다. 여러 차례의 훈련을 통해, CNN의 출력과 이상적인 출 력 사이의 오차는 모델이 수렴될 때까지 점점 작아진다. 이로써 훈련 과정이 완료된다. 도 1의 CNN의 구조는 단지 예시일 뿐임은 자명한 것이다. 실제 응용에서 CNN은 필요에 따라 다른 네트워크 구성 을 가질 수 있으며, 보다 많은 네트워크 층, 다른 유형의 네트워크 층 또는 다양한 유형의 네트워크 층의 다른 연결 관계를 가질 수 있다. 본 개시의 실시예는 이에 대해 제한하지 않는다. 일부 실시예에서, 전용 딥 러닝 프로세서를 사용하여 CNN 훈련과 관련한 작업을 처리할 수 있다. 도 2는 일부 실시예에 따른 예시적인 처리 아키텍처를 개략적으로 나타낸다. 예시적인 처리 아키텍처는 이기종 아 키텍처(Heterogeneous architecture)로서, 범용 처리 장치 및 이와 결합된 딥 러닝 처리 장치를 포 함한다.범용 처리 장치는 예를 들어 하나 또는 복수의 범용 프로세서(CPU) 코어, 하나 또는 복수의 디지털 신호 프로세서(DSP) 코어 등을 포함할 수 있다. 범용 처리 장치는 예를 들어 범용 스칼라 프로세서일 수 있다. 범용 처리 장치는 축소 명령어 세트 컴퓨터(RISC) 유형의 명령어와 같은 일반적인 컴퓨터 명령어를 실행할 수 있고, 또한 딥 러닝 처리와 관련된 자체 정의된 명령어를 파싱하고 실행할 수도 있다. 범용 처리 장치 는 딥 러닝 모델의 관련 처리를 구현하기 위해, 딥 러닝 처리와 관련된 명령어를 딥 러닝 처리 장치에 제 공할 수 있다. 딥 러닝 처리 장치(딥 러닝 프로세서, 딥 러닝 처리 기기로 지칭되기도 함)는 예를 들어, 딥 러닝 계산을 구현하는 소프트웨어 모듈 및 하드웨어 회로를 포함하는 전용 딥 러닝 코프로세서일 수 있다. 딥 러닝 처리 장 치는 예를 들어 프로그래밍 가능한 데이터 처리 장치(FPGA), 주문형 집적회로(ASIC) 등으로 구현될 수 있 다. 딥 러닝 처리 장치는 복수의 모듈을 포함하며, 딥 러닝을 위해 정의된 관련 명령어를 통해 복수의 모 듈 작업을 스케줄링하고, 복수의 모듈 사이에서 데이터 인터랙션(interaction)을 수행할 수도 있다. 딥 러닝 처 리 장치의 모듈은 구현하고자 하는 딥 러닝 처리 태스크에 따라 구성될 수 있다. 일부 구현에서, 딥 러닝 처리 장치는 CNN 훈련 태스크를 수행하도록 구성될 수 있다. 이러한 구현에서, 범용 처리 장치는 딥 러닝 처리 장치에 CNN 훈련을 수행하기 위한 해당 명령어를 제공한다. 상술한 바와 같이, CNN 훈련 과정에는 컨볼루션층의 대량의 컨볼루션 작업과 컨볼루션 역방향 작업이 수반되고, 이는 많은 컴퓨팅 자원 및 시간을 소모한다. 따라서, 컨볼루션 작업 및 컨볼루션 역방향 작업의 개선에 의해 CNN 훈련을 크게 가속화시킬 수 있다. 본 개시의 실시예에 따라, 딥 러닝 처리 장치를 제공한다. 상기 딥 러닝 처리 장치는 컨볼루션층의 컨볼루션 방 향 작업을 수행할 수 있다. 상기 딥 러닝 처리 장치는 CNN에서 컨볼루션층의 컨볼루션 커널 파라미터 값 행렬과 제1 오차 그래디언트 값 행렬의 행렬 곱셈-누적 연산을 수행하여 복수의 중간 행렬을 획득하도록 구성된 하나 또는 복수의 행렬 곱셈-누적 모듈을 포함한다. 복수의 중간 행렬은 재구성할 필요가 없이 저장 장치에 저장된다. 상기 딥 러닝 처리 장치는, 저장 장치로부터 복수의 중간 행렬을 판독하고 병렬 방식으로 컨볼루션층 의 컨볼루션 방식(convolution scheme)에 따라 복수의 중간 행렬을 기반으로 행렬 누적 연산을 수행하여, 컨볼 루션층에 대한 제2 오차 그래디언트 값 행렬을 획득하도록 구성된 복수의 행렬 누적 모듈을 더 포함한다. 상기 방식에 있어서, CNN 훈련 과정에서, 행렬 곱셈-누적 및 행렬 누적 연산은 특정 모듈을 통해 구현되며, 복수의 행렬 누적 모듈이 병렬 방식으로 연산을 수행할 수 있음으로써, 컨볼루션 역방향 작업의 계산 효율을 현저히 향 상시킬 수 있고, 계산 속도와 전력 소비 측면에서도 현저한 개선 효과를 얻을 수 있다. 도 3a는 본 개시의 일부 실시예에 따른 딥 러닝 처리 장치의 예시적 구조를 나타낸다. 딥 러닝 처리 장치는 CNN 의 컨볼루션층의 행렬과 관련한 계산을 구현하는 행렬 계산 모듈을 포함하는 딥 러닝 처리 장치일 수 있다. 행렬 계산 모듈은 하나 또는 복수의 행렬 곱셈-누적 모듈(310-1, …… ,310-N)을 포함하며, 여기서 N은 1 보다 크거나 같은 정수일 수 있다. 설명의 편의를 위해, 행렬 곱셈-누적 모듈(310-1, …… ,310-N)은 통 합 또는 개별적으로 행렬 곱셈-누적 모듈로 지칭될 수 있다. 하나 또는 복수의 행렬 곱셈-누적 모듈 은 CNN 컨볼루션층의 컨볼루션 커널 파라미터 값 행렬과 제1 오차 그래디언트 값 행렬의 행렬 곱셈-누적 연산을 구현하도록 구성된다. 컨볼루션층의 행렬 곱셈-누적 연산은 복수의 중간 행렬을 생성할 수 있다. 행렬 계산 모듈은 복수의 행렬 누적 모듈(320-1, …… ,320-M)을 더 포함하고, 여기서 M은 2 보다 크거나 같은 정수일 수 있다. 설명의 편의를 위해, 행렬 누적 모듈(320-1, …… ,320-M)은 통합 또는 개별적으로 행렬 누적 모듈로 지칭될 수 있다. 이러한 행렬 누적 모듈은 컨볼루션층의 컨볼루션 방식에 따라 병렬 방 식으로 복수의 중간 행렬을 기반으로 행렬 누적 연산을 수행하여 현재 컨볼루션층에 대한 오차 그래디언트 값 행렬(\"제2 오차 그래디언트 값 행렬\"로 지칭되기도 함)을 획득하도록 구성된다. 작업 과정에서, 행렬 곱셈-누적 연산에 의해 생성된 복수의 중간 행렬은 딥 러닝 처리 장치의 저장 장치 에 저장된다. 저장 장치는 온-칩 랜덤 액세스 메모리(RAM)와 같은 온-칩 저장 장치일 수 있다. 예를 들어, 스태틱 랜덤 액세스 메모리(SRAM) 또는 다른 유형의 메모리일 수 있다. 복수의 중간 행렬이 동시에 생성 되지 않을 수 있으므로, 행렬 곱셈-누적 모듈이 해당 중간 행렬을 생성할 때마다, 상기 중간 행렬은 저장 장치의 대응하는 저장 위치에 저장될 수 있다. 일부 실시예에서, 복수의 행렬 곱셈-누적 모듈이 존재 할 경우, 복수의 행렬 곱셈-누적 모듈은 컨볼루션 커널 파라미터 값 행렬과 제1 오차 그래디언트 값 행렬 의 행렬 곱셈-누적 연산을 병렬로 수행할 수 있다. 일부 실시예에서, 행렬 계산 모듈은 행렬 계산 모듈 중 각각 모듈의 연산 명령어를 수신하도록 구성 된 명령어 처리 모듈을 더 포함할 수 있다. 이러한 명령어 세트는 예를 들어 CNN의 컨볼루션층의 컨볼루션방향 작업을 위한 명령어 세트를 포함하는 자체 정의된(self-defined) 딥 러닝 명령어 세트일 수 있다. 명령어 처리 모듈은 예를 들어 딥 러닝 처리 장치와 결합된 범용 처리 장치로부터 명령어 세트를 획득 할 수 있다. 명령어 처리 모듈은 명령어 세트를 딥 러닝 처리 장치에 의해 실행 가능한 명령어들로 파싱할 수 있다. 일부 실시예에서, 행렬 계산 모듈은 또한 명령어 파싱 및 제어 신호 생성과 관련된 모듈일 수 있다. 도 3b 에 도시된 바와 같이, 행렬 계산 모듈은 파싱된 명령어 세트를 기반으로 적어도 하나의 행렬 곱셈-누적 모 듈 및 복수의 행렬 누적 모듈에 대한 제어 신호를 생성하여, 적어도 하나의 행렬 곱셈-누적 모듈 및 복수의 행렬 누적 모듈의 해당 작업을 제어하도록 구성된 제어 신호 생성 모듈을 더 포함할 수 있다. 도 3b의 예에서, 제어 신호 생성 모듈은 파싱된 명령어 세트에 따라 제어 신호를 판독하고 기록 하도록 구성된 판독-기록 제어 모듈을 포함하고, 판독-기록 제어 신호는 적어도 하나의 행렬 곱셈-누적 모 듈 및 복수의 행렬 누적 모듈이 저장 장치 내의 데이터를 판독하고 기록하는 것을 제어하기 위 한 신호이다. 제어 신호 생성 모듈은 순환 제어 모듈을 더 포함할 수 있다. 행렬 곱셈-누적 모듈 이 복수 차례의 행렬 곱셈-누적 연산을 순환적으로 수행 및/또는 행렬 누적 모듈이 복수 차례의 행렬 누적 연산을 순환적으로 수행하고자 하는 경우, 순환 제어 모듈은 파싱된 명령어 세트에 따라 순환 제어 신호를 생성하여, 각각의 행렬 곱셈-누적 모듈의 행렬 곱셈-누적 연산의 순환 및/또는 각각의 행렬 누적 모듈의 행렬 누적 연산의 순환을 제어하도록 구성된다. 이상으로 도 3a 및 3B를 참조하여 딥 러닝 처리 장치 중 행렬 계산 모듈의 일부 예시적인 실시예를 개략적으로 설명하였다. 일부 실시예에서, 딥 러닝 처리 장치는 행렬 계산 모듈과 함께 CNN 훈련 태 스크를 구현하기 위한 다른 모듈들을 더 포함할 수 있다. 도 3c는 본 개시의 일부 실시예에 따른 딥 러닝 처리 장치의 예시적인 구조를 나타낸다. 도 3c에 도시한 바와 같이, 딥 러닝 처리 장치는 행렬 계산 모듈 외에, 데이터 판독-기록 모듈, 데이터 변환 모듈, 벡터 계산 모듈 및 선택적인 풀링 모듈 및 전치 모듈(transposition module; 306)을 더 포함한다. 행렬 계산 모듈외에, 벡터 계산 모듈 및 선택적인 풀링 모듈과 전치 모듈은 모두 저장 장치에 액세스하여 처리하고자 하는 데 이터를 판독하고 처리된 데이터를 저장 장치에 기록할 수 있다. 따라서 저장 장치는 경우에 따라 공 유 저장 장치로 지칭된다. 데이터 판독-기록 모듈은 딥 러닝 처리 장치 외부의 저장 장치/기기(오프칩 저장 장치/기기로도 지칭 됨)로부터 CNN 훈련 과정에 필요한 데이터를 판독하고, 데이터를 저장 장치에 저장하도록 구성된다. 데이 터 변환 모듈은 저장 장치로부터 변환하고자 하는 데이터를 판독하고, 데이터의 각 요소에 대한 재구 성(예컨대, 데이터를 3차원 또는 더 높은 차원의 행렬에서 2차원 행렬의 포맷으로 변환하거나, 행렬에서 벡터로 의 변환 등)과 같은 데이터에 대한 포맷 변환을 수행한다. 변환된 데이터는 저장 장치에 다시 저장된다. 행렬 계산 모듈은 CNN 훈련 과정에 수반되는 행렬 계산 작업을 수행하도록 구성되고, 벡터 계산 모듈(30 4)은 CNN 훈련 과정에 수반되는 벡터 계산 작업을 수행하도록 구성된다. 풀링 모듈은 CNN의 풀링층과 관련 된 작업을 수행하도록 구성되고, 전치 모듈은 CNN의 훈련 과정에 수반되는 행렬 전치 작업을 수행하도록 구성된다. 일부 실시예에서, 풀링층 관련 작업 및 전치 작업은 대응하는 행렬 계산 작업 및 벡터 계산 작업으로 변환될 수도 있으므로, 이로써 행렬 계산 모듈 및 벡터 계산 모듈에 의해 구현될 수 있다. 저장 장치 는 예를 들어 스태틱 랜덤 액세스 메모리(SRAM) 또는 다른 유형의 메모리와 같은 온-칩 랜덤 액세스 메모 리(RAM)일 수 있다. 행렬 계산 모듈, 벡터 계산 모듈 및 선택적인 풀링 모듈과 전치 모듈 은 모두 저장 장치에 액세스하여 처리하고자 하는 데이터를 판독하고 처리된 데이터를 저장 장치에 기록할 수 있다. 따라서 저장 장치는 경우에 따라 공유 저장 장치로 지칭된다. 이하에서 CNN 컨볼루션층의 컨볼루션 역방향 작업에서의 행렬 계산 모듈의 행렬 곱셈-누적 모듈 및 행렬 누적 모듈의 구체적인 연산에 대한 더 깊은 이해를 도모하고자, 도 4a 및 도 4b를 참조하여 컨볼루션 층의 컨볼루션 작업 및 컨볼루션 역방향 작업에 대해 간략하게 설명하고자 한다. 도 4a는 컨볼루션층의 컨볼루션 작업을 나타낸다. 컨볼루션 작업은 CNN의 순방향 계산 과정에서 발생한다. CNN 중 하나의 컨볼루션층에 있어서, 처리할 입력은 이전 층의 출력 또는 CNN의 입력층으로부터 전달받은 것이다. 컨볼루션층의 입력은 일반적으로 하나 또는 복수의 특징 맵을 포함하고, 각각의 특징 맵은 2차원 행렬로 나타낼 수 있다. 입력 특징 맵의 개수는 입력된 채널의 개수이다(c개 채널로 가정함). 컨볼루션층은 컨볼루션 작업을 구현하기 위한 하나 또는 복수의 컨볼루션 커널을 포함한다. 컨볼루션 커널 의 개수는 CNN에서 임의로 설정될 수 있다(컨볼루션 커널의 개수를 \"k\"로 가정함). 각각의 컨볼루션 커널의 크기를 로 가정하며, 여기서 c는 채널의 개수이고, 는 컨볼루션 커널의 높이와 폭을 나타낸다. 즉, 각각의 컨볼루션 커널을 의 컨볼루션 커널 파라미터 값 행렬로 나타낼 수 있다. 훈련 과정의 순방향 처리에서 컨볼루션 커널 파라미터 값 행렬은 현재 훈련 단계에서 확정된 값이다. 컨볼루션 작업을 수행함에 있어서, 각 컨볼루션 커널은 컨볼루션 작업의 scheme에 따라 컨볼루션층의 입력 특징 맵 상에서 이동한다. 예를 들어 일정한 보폭(stride)을 기준으로 특징 맵 상에서 왼쪽에서 오른쪽으로, 위에 서 아래로 이동하여, 획득한 요소에 대해 컨볼루션 연산을 수행하고, 최종적으로 컨볼루션층의 출력 특징 맵을 획득한다. 컨볼루션 작업은 다음과 같이 나타낼 수 있다. 수학식"}
{"patent_id": "10-2020-0120922", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 는 컨볼루션층의 출력 높이, 는 컨볼루션층의 출력 폭, 는 컨볼루션 커널의 개수를 나타낸다. 수 학식에 따르면 컨볼루션층의 출력 특징 맵의 크기는 이고, 개 2차원 행렬 로 표현할 수 있다. 컨볼루션 작업에서, 매번 입력 특징 맵으로부터 의 입력 서브 행렬(입력 윈도우로 지칭되기도 함)을 추출하고, 이는 k개 컨볼루션 커널 중 각각의 컨볼루션 커널의 컨볼루션 커널 파라미터 값 행렬(크 기 )과 곱셈하기 위한 개의 입력 요소를 포함한다. 의 입력 서브 행렬과 의 컨볼루션 커널 파라미터 값 행렬의 곱셈은 경우에 따라 입력 요소 중 c개 의 2차원 행렬과 컨볼루션 커널 파라미터 값 행렬의 c개 의 2차원 행렬의 행렬 곱셈으로 표현할 수 있다. 또한, 상기 두 개의 3차원 서브 행렬을 다른 크기의 2차원 서브 행렬로 변환한 다음 행렬 곱셈을 수행할 수 있음은 물론이다. 컨볼루션 작업 scheme에 따르면, 컨볼루션 커널은 입력 특징 맵에서 개의 윈도우를 추출하여 컨볼 루션 연산을 수행할 수 있다고 가정한다. 도 4a는 c개의 입력 특징 맵 중 하나의 특징 맵으로부터 추출된 크기를 갖는 입력 윈도우와 크기의 컨볼루션 커널을 갖는 하나의 컨볼루션 커널 파라미터 값 행렬에 대해 컨볼루션 연산을 수행하여, 컨볼루션층의 출력 특징 맵의 하나의 출력 요소(44 0)를 획득하는 것을 나타낸다. 복수의 컨볼루션 커널이 존재하는 경우, 각각의 컨볼루션 커널은 유사한 처 리를 수행한다. 컨볼루션 연산은 행렬 곱셈-누적 연산으로서, 행렬 요소의 곱셈, 덧셈 연산으로 분해될 수 있다. 행렬 계산 모듈에서 행렬 곱셈-누적 모듈에 의해 컨볼루션 연산이 수행될 수 있다. 일부 실시 예에서 순방향 컨볼루션에 있어서, 수학식에서 나타낸 컨볼루션층의 컨볼루션 작업을 대응하는 행렬 곱셈-누 적 연산으로 분할할 수 있고, 행렬 곱셈-누적 모듈에 의해 구현할 수 있다. 예를 들어, 입력 특징 맵 중 개 입력 서브 행렬과 컨볼루션 커널의 컨볼루션 커널 파라미터 값 행렬의 행렬 곱셈은 번의 계산 으로 분해될 수 있고, 매번 컨볼루션층의 출력 특징 맵 중 개의 출력 요소를 산출하여 획득할 수 있다. 상기와 같이 컨볼루션층의 순방향 컨볼루션 작업에 대해 설명하였다. 컨볼루션층의 컨볼루션 역방향 작업은 상 술한 컨볼루션 작업의 반대 방향이다. 도 4b는 컨볼루션층의 컨볼루션 역방향 작업을 나타낸다. 역방향 처리에 서, CNN의 특정 컨볼루션층에 대해, 컨볼루션층의 다음 층(CNN의 순방향 방향에서의 다음 층, 예를 들어 도 1의 컨볼루션층의 다음 층은 활성화층 임)의 오차 그래디언트 값 행렬(본원에서 \"제1 오차 그래디언트 값 행렬\"로 지칭됨)을 산출할 수 있다. 제1 오차 그래디언트 값 행렬의 크기는 컨볼루션층의 출력 특징 맵의 크기 와 같은 바, 즉, 이다. 컨볼루션 역방향 작업은 컨볼루션층의 제1 오차 그래디언트 값 행렬 및 컨 볼루션층의 컨볼루션 커널 파라미터 값 행렬의 컨볼루션 역방향 연산(이것은 행렬 요소의 곱셈, 덧셈 연산으로 분해될 수 있음)을 수행하여 복수의 중간 행렬을 획득한 다음, 복수의 중간 행렬을 컨볼루션층의 입력 특징 맵 의 대응하는 위치에 순차적으로 중첩하여, 현재 컨볼루션층에 대한 오차 그래디언트 값 행렬(본 명세서에서 \"제 2 오차 그래디언트 값 행렬\"로 지칭됨)을 획득한다. 컨볼루션층의 컨볼루션 역방향 작업은 다음과 같이 나타낼 수 있다.수학식"}
{"patent_id": "10-2020-0120922", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 는 다음 층의 제1 오차 그래디언트 값 행렬의 높이이고, 는 오차 그래디언트 값 행렬의 폭이며,"}
{"patent_id": "10-2020-0120922", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "는 오차 그래디언트 값 행렬의 채널 개수(즉, 2차원 행렬 의 개수)이다. 수학식에 따르면, 각각의 컨볼루션 커널 과 제1 오차 그래디언트 값 행렬 중 대응 요소를 곱한 후, k개 채널의 오차 그래디언 트 곱셈-누적을 함께 누적시켜야 한다. 컨볼루션 역방향 작업에서, 하나의 컨볼루션 커널에 대해, 제1 오차 그래디언트 값 행렬로부터 오차 그래 디언트 값을 매번 추출하여, 의 컨볼루션 커널 파라미터 값 행렬과 컨볼루션 역방향 연산 을 진행한다. k개 컨볼루션 커널에 대해, 컨볼루션 역방향 연산에서 제1 오차 그래디언트 값 행렬 중 k개 채널의 오차 그래디언트와 컨볼루션 커널 파라미터 값 행렬의 곱셈값을 합계하여 중간 행렬을 획득한 다. 컨볼루션 역방향 연산은 또한 행렬 곱셈-누적 모듈에 의해 구현될 수 있다. 컨볼루션 역방향 연 산은 또한 행렬 곱셈-누적 연산으로 간주될 수 있으며, 이는 행렬 요소의 곱셈 및 덧셈 연산으로 분해될 수 있다. 일부 실시예에서, 행렬 계산 모듈이 복수의 행렬 곱셈-누적 모듈을 포함하는 경우, 컨볼루션 커널 파 라미터 값 행렬과 제1 오차 그래디언트 값 행렬의 행렬 곱셈-누적 연산을 수행함에 있어서, 복수의 행렬 곱셈- 누적 모듈은 행렬 곱셈-누적 연산을 병렬로 수행할 수 있다. 의 행렬 곱셈 -누적 연산은 임의 크기의 2차원 행렬의 행렬 곱셈-누적 계산으로 분해될 수 있다. 행렬 곱셈-누적 연산을 거친 후, 크기의 개 중간 행렬을 포함하는 복수의 중간 행렬을 획득한다고 가정한다. 이러한 중간 행렬은 컨볼루션 역방향 작업의 최종 결과가 아니며, 컨볼루션층의 컨볼루션 방식에 따라 합계 또는 누적되어야 한다. 본 개시의 예시적인 실시예에서, 복수의 행렬 누적 모듈에 의해 복수의 중간 행렬의 행렬 누적 연산을 병렬로 구현한다. 컨볼루션층의 컨볼루션 방식은 구체적으로 컨볼루션 작 업에서 컨볼루션 커널이 컨볼루션층의 입력 특징 맵으로부터 입력 윈도우를 추출하는 방식에 따라 결정되며, 이 러한 방식에는 컨볼루션 커널의 이동 방법(예컨대, 왼쪽에서 오른쪽으로, 위에서 아래로) 및 이동 보폭(예컨대, 윈도우는 하나의 요소를 단위로 이동하거나 또는 기타 다른 기 설정 개수의 요소를 단위로 이동함)이 포함된다. 도 5는 복수의 중간 행렬의 누적 방식을 나타낸다. 도 5의 예에서, 설명의 편의를 위해 채널의 개수를 c=1로 가 정한다. 도 5는 복수의 중간 행렬(크기는 )을 중첩하여 제2 오차 그래디언트 값 행렬을 획득하는 것을 나타낸다. 채널의 개수가 1보다 큰 경우, 각각의 채널에는 개 2차원 행렬 이 존재하며, 이를 각 각 대응하게 중첩하여 하나의 채널 행렬을 획득할 수 있다. 최종적으로 획득한 c개 채널 행렬은 제2 오차 그래 디언트 값 행렬로 간주된다. 도 5에 도시된 바와 같이, 제1 중간 행렬이 행렬 곱셈-누적 모듈에 의해 산출될 경우, 이는 초기값을 갖는 제2 오차 그래디언트 값 행렬의 제1 위치(좌측 상부 모서리 위치)에 누적될 것이다. 제1 중간 행렬 이 3 * 3개 요소를 포함하는 매트릭스라고 가정하면, 이는 초기 2차원 행렬의 좌측 상부 모서리의 3 * 3 요소의 서브 행렬에 누적된다. 행렬 누적 모듈의 행렬 누적 연산 과정에서, 제2 오차 그래디언트 값 행렬은 초기에 all-zero 값을 가지며, 저장 장치의 목표 저장 위치에 저장된다. 행렬 누적 모듈은 저 장 장치의 목표 저장 위치로부터 제2 오차 그래디언트 값 행렬에 누적될 해당 초기값을 판독하고, 제 1 중간 행렬의 각각의 요소와 제2 오차 그래디언트 값 행렬의 해당 초기값을 누적한다. 누적 결과는 저장 장치의 목표 저장 위치에 다시 기록된다. 제2 오차 그래디언트 값 행렬의 각각의 요소의 저장 장치 내 저장 위치는 변경되지 않는다. 제2 중간 행렬이 행렬 곱셈-누적 모듈에 의해 산출될 경우, 행렬 누적 모듈에 의해 제2 오차 그 래디언트 값 행렬의 제2 위치에 누적될 것이고, 이는 제1 위치에 대해 오른쪽으로 하나의 요소만큼 이동된다(컨 볼루션 커널의 보폭이 하나의 요소라고 가정함). 제2 중간 행렬의 일부 요소는 제2 오차 그래디언트 값 행렬 중 이미 제1 중간 행렬의 부분 요소가 누적된 요소들에 계속 누적되고, 일부 요소는 제2 오차 그래디언트 값 행렬의 초기값(즉, 0)에 누적된다. 행렬 누적 모듈은 저장 장치로부터 제2 중간 행 렬에 누적될 요소를 판독할 수 있다. 제3 중간 행렬이 행렬 곱셈-누적 모듈에 의해 산출될 경우, 이는 또한 유사한 방식으로 제2 오차 그 래디언트 값 행렬의 대응하는 서브 행렬에 누적될 것이고, 제3 중간 행렬의 각각의 요소는 해당 위치 의 누적 값 또는 초기값에 누적된다. 크기의 개 중간 행렬이 중첩된 후, 중첩된 결과는 최종적 으로 제2 오차 그래디언트 값 행렬을 형성한다. 본 개시의 실시예에서, 상술한 바와 같이, 행렬 곱셈-누적 모듈이 중간 행렬을 산출한 후, 중간 행렬의 요 소를 재구성할 필요 없이 중간 행렬을 저장 장치에 저장할 수 있다. 즉, 중간 행렬은 다른 방식으로 재구 성되거나 분할될 필요 없이 행렬 곱셈-누적 모듈이 생성한 요소 배열 순서 그대로 저장될 수 있다. 일부 실시예에서, 각각의 행렬 누적 모듈은 각각의 행렬 누적 연산에서 하나의 중간 행렬에 대한 누적 연 산을 수행할 수 있고, 복수의 행렬 누적 모듈은 누적 연산을 병렬로 수행할 수 있다. 제2 오차 그래디언트 값 행렬은 저장 장치의 특정 저장 위치에 저장되고, 행렬 곱셈-누적 모듈이 산출한 중간 행렬은 저장 시 재구성될 필요가 없기 때문에, 행렬 누적 모듈은 각각의 중간 행렬이 결정된 후, 신속하게 상기 중간 행렬을 저장 장치에 저장된 제2 오차 그래디언트 값 행렬의 해당 행렬 요소의 현재 값에 바로 누적시킬 수 있고, 각각의 중간 행렬을 순서에 따라 직렬로 누적할 필요가 없다(여기서 순서는 컨볼루션 커널의 컨볼루션 방 식, 즉 입력 특징 맵 상에서 컨볼루션 커널의 이동 방식 및 보폭을 의미함). 예를 들어, 도 5의 예에서 제2 중 간 행렬이 먼저 산출될 경우, 제1 중간 행렬이 아직 누적되지 않더라도, 상기 중간 행렬은 제2 오차 그래디언트 값 행렬의 해당 위치에서 초기값을 갖는 요소에 바로 중첩된다. 일부 실시예에서, 순환 제어 모듈은 복수의 행렬 누적 모듈이 제2 오차 그래디언트 값 행렬 중 동일 한 요소 위치에서 동시에 누적되는 것을 방지하도록, 행렬 누적 모듈의 행렬 누적 연산을 제어하도록 구성 될 수 있다. 이러한 병렬 행렬 누적은 컨볼루션 역방향 작업의 계산 속도를 더 향상시킬 수 있으며, 복수의 행 렬 곱셈-누적 모듈이 존재하여 이러한 행렬 곱셈-누적 모듈이 병렬로 행렬 곱셈-누적 연산을 수행하 는 경우에 특히 적합하다. 그 원인은 이러한 상황하에서 일부 행렬 곱셈-누적 모듈이 중간 행렬을 더 빠르 게 출력할 수 있기 때문이다. 일부 실시예에서, 병렬 행렬 누적 과정 시, 컨볼루션층의 입력이 복수의 채널을 갖는 경우, 이는 제2 오차 그래 디언트 값 행렬이 복수의 채널에 대한 복수의 채널 행렬(각각의 채널 행렬은 도 5의 하나의 2차원 행렬과 같은 하나의 2차원 행렬임)을 포함하고, 복수의 행렬 누적 모듈이 복수의 채널에 따라 행렬 누적 연산을 병렬로 수행하도록 구성될 수 있음을 의미한다. 복수의 행렬 누적 모듈은 복수의 채널에 대응하는 복수의 병렬 경로를 구현할 수 있고, 각각의 병렬 경로에는 행렬 누적 연산을 수행하기 위한 하나 또는 복수의 행렬 누 적 모듈이 있을 수 있다. 각각의 병렬 경로 상의 행렬 누적 모듈은 복수의 중간 행렬 중에서 복수의 채널 중 하나의 채널과 연관된 중간 행렬에 대해 누적 연산을 수행하여, 상기 하나의 채널에 대한 채널 행렬을 획득하도록 구성된다. 일부 실시예에서, 병렬 행렬 누적 연산은 채널에 따라 분할되지 않고 중간 행렬을 기준으로 구현될 수 있다. 각 각의 행렬 누적 모듈은 누적할 때마다 복수의 중간 행렬 중 하나의 중간 행렬을 복수의 채널 행렬 중 하나 의 채널 행렬의 중간 결과에 누적하도록 구성된다. 일부 실시예에서, 행렬 계산 모듈은 캐시 영역(명세서에서 \"제2 캐시 영역\"으로 지칭되기도 함)을 더 포함 할 수 있다. 두개 행렬의 행렬 곱셈-누적 연산과 행렬 누적 연산 과정에서, 비교적 많은 중간 연산 결과가 생성 되고, 이러한 중간 연산 결과는 추후 연산에서 다시 호출되므로, 모듈 내에 캐시 영역을 설정함으로써 행렬 계 산 모듈과 저장 장치 사이의 데이터 전송을 효과적으로 감소시키고, 행렬 곱셈-누적 연산 속도를 더 향상시키며 전력 소모를 낮출 수 있다. 도 6은 이러한 실시예를 나타낸다. 도 6에 도시된 바와 같이, 행렬 계산 모듈은 적어도 하나의 행렬 곱셈-누적 모듈이 행렬 곱셈-누적 연산 과정에서 생성한 중간 연산 결과 (\"제1 중간 연산 결과\"로 지칭되기도 함) 및/또는 복수의 행렬 곱셈-누적 모듈이 행렬 곱셈-누적 연산 과 정에서 생성한 중간 연산 결과(\"제2 중간 연산 결과\"로 지칭되기도 함)를 임시저장하도록 구성된 캐시 영역 을 더 포함한다. 행렬 곱셈-누적 모듈 및 행렬 누적 모듈의 행렬 계산 과정에서, 딥 러닝 처리 장치의 벡터 계산 모듈의 벡터 계산 기능을 추가적으로 이용할 수도 있으며, 이를 통해 행렬 계산 모듈에서 관련 기능 에 의해 초래되는 복잡성 증가 문제를 피할 수 있다. 일부 실시예에서, 도 6에서 나타낸 것과 같이, 벡터 계산모듈은 벡터 레벨에서 행렬 계산 모듈이 캐시 영역에 대한 제로값 설정 및/또는 데이터 판독 작 업을 수행하는 것을 돕도록 구성될 수 있다. 일부 실시예에서, 벡터 계산 모듈은 벡터 레벨에서 캐시 영역 중 행렬 곱셈-누적 모듈의 중간 연산 결과 및/또는 행렬 누적 모듈의 중간 연산 결과를 저장하기 위한 영역을 제로 값으로 설정하도록 구 성될 수 있다. 즉, 벡터 계산 모듈은 중간 연산 결과에 대응하는 저장 영역을 행 또는 열 기준으로 제로 값으로 설정할 수 있다. 대안적으로 또는 부가적으로, 벡터 계산 모듈은 벡터 레벨에서 각각의 행렬 누적 모듈에 의해 수행된 행렬 누적 연산의 최종 연산 결과를 제2 오차 그래디언트 값 행렬의 적어도 일부분으 로써 저장 장치에 선택적으로 기록되도록 더 구성될 수 있다. 이는 컨볼루션 과정에서 패딩(padding) 요소 가 증가될 수 있는 상황을 해결하기 위한 것이다. 컨볼루션 역방향 작업에서, 순방향에서 추가된 패딩 요소를 삭제함으로써 최종 오차 그래디언트 값 행렬의 요소로 사용하지 않는다. 벡터 계산 모듈은 벡터 레벨에서 행 단위 또는 열 단위로 패딩 요소를 더 잘 필터링할 수 있다. 벡터 계산 모듈의 처리는 제어 신호에 의해 제어될 수 있고, 이러한 제어 신호는 자체 정의된 딥 러닝과 관련된 명령어 세트를 파싱함으로써 결정될 수 있다. 다른 일 실시예에서, 벡터 계산 모듈의 기능을 사용 하지 않고, 행렬 계산 모듈에 해당 기능을 설정함으로써 캐시 영역의 제로 값 설정 및 데이터의 선택적 기 록을 구현할 수도 있음은 자명할 것이다. 일부 실시예에서, 행렬 누적 모듈이 행렬 누적 연산을 수행함에 있어서 저장 장치에 대해 판독 및 기 록하여야 할 경우, 행렬 누적 연산 및 데이터 판독 및 기록의 일정한 지연으로 인해, \"데이터 위험(data hazard)\"을 무릅써야 하는 상황이 발생할 수 있다. 행렬 누적 모듈이 데이터 누적을 수행함에 있어서, 복 수의 요소를 순차적으로 누적해야 할 수 있으며, 누적 결과는 저장 장치의 동일한 저장 위치에 저장된다. 예를 들어, 최종적으로 획득된 제2 오차 그래디언트 값 행렬의 하나의 요소는 2개 또는 그 이상의 중간 행렬 중 의 요소를 누적한 결과일 수 있다. \"데이터 위험\" 상황은 현재 두 요소의 누적 과정에서, 이전 두 요소의 누적 연산 완료될 때까지 반드시 대기하여야 함을 가리키므로, 이는 데이터 누적 파이프 라인이 중지되는 상황을 초 래할 수 있다. 일부 실시예에서, \"데이터 위험\" 문제를 해결하기 위해 행렬 누적 모듈에 바이패스 메커니즘을 사용하는 방식을 제공한다. 도 7은 본 개시의 일부 실시예에 따른 행렬 누적 모듈의 예시적인 구조를 나타낸다. 도 7에 도시된 바와 같이, 행렬 누적 모듈은 중첩될 행렬 중 2개 요소의 누적을 수행하여 누적 요소를 획득하 도록 구성된 덧셈 연산 유닛을 포함한다. 덧셈 연산 유닛은 예를 들어 부동 소수점 덧셈 연산 유닛 또는 다른 형식의 덧셈 연산 유닛일 수 있다. 행렬 누적 모듈은 덧셈 연산 유닛이 산출한 누적 요소 를 저장 장치의 대응 저장 위치에 기록하도록 구성된 데이터 기록 유닛을 더 포함한다. 행렬 누적 모 듈은 저장 장치의 대응하는 저장 위치로부터 누적 요소를 판독하여 다음 요소와 계속 누적하도록 구 성된 데이터 판독 유닛을 더 포함한다. 행렬 누적 연산에서, 덧셈 연산 유닛은 2개 이상의 요소에 대한 누적을 수행해야 할 수 있고, 모든 요소의 누적이 완료될 때까지 2개 요소의 누적 결과는 매번 다음 요소와 계속 누적될 것이다. 누적될 행렬은 중간 행렬 및 중간 행렬이 누적되는 제2 오차 그래디언트 값 행렬 중의 서브 행렬일 수 있고, 이의 행렬 요소는 일반적으 로 이미 산출된 것이다. 그러나 데이터 기록 유닛에서 저장 장치로의 데이터 판독-기록 및 덧셈 연산 유닛의 연산에는 일정한 지연이 있기 때문에, 일부 상황에서, 데이터 기록 유닛이 덧셈 연산 유닛 에 의해 산출된 제1 요소와 제2 요소의 누적 결과인 누적 요소를 저장 장치에 기록하고 있는 와중에, 다음으로 누적될 제3 요소가 이미 준비되어 있을 수 있다. 종래의 방식에서, 데이터 기록 유닛이 누적 요소의 기록을 완성할 때까지 대기한 후, 데이터 판독 유닛을 활성화하여 대응하는 저장 위치로부터 상기 누적 요소를 다시 판독하고, 덧셈 연산 유닛에 제공하여 누적을 진행하므로, \"데이터 위험\"을 초래하여 큰 지연이 발생된다. 도 7의 실시예에서, 행렬 누적 모듈은 덧셈 유닛에 의해 산출된 누적 요소를 하나의 캐시 영역 (\"제1 캐시 영역\"으로도 지칭됨)에 캐시하도록 구성된 바이패스 모듈을 포함한다. 캐시 영역의 기록 속도는 일반적으로 저장 장치의 기록 속도보다 빠르다. \"데이터 위험\"이 발생하는 경우, 즉 덧셈 연 산 유닛이 제3 요소와 이전의 누적 요소를 누적하고자 할 때에 저장 장치의 대응하는 저장 위치로부터 상 기 누적 요소가 판독될 수 없음이 확정될 경우, 바이패스 모듈은 캐시 영역에 캐시된 누적 요소를 덧 셈 연산 유닛에 제공하도록 구성된다. 이와 같이, 덧셈 연산 유닛은 제3 요소가 이용 가능할 경우 제 3 요소와 누적 요소의 추가 누적을 신속하게 수행할 수 있다. 일부 상황에서, \"데이터 위험\"이 발생하지 않은 것으로 확정될 경우, 즉 데이터 판독 유닛이 저장 장치로부터 적시에 누적 요소를 판독할 수 있을 경우, 바이패스 모듈은 저장 장치로부터 판독된 누적 요소를 누적 연산을 위해 덧셈 연산 유닛에 제공할 수 있다. 캐시 영역에서 누적 요소의 캐시 시간은 딥 러닝 처리 장치의 복수의 클럭 사이클일 수 있다. 구체적 으로 캐시되는 시간은 캐시 영역의 크기 및/또는 \"데이터 위험\"을 초래할 수 있는 지연 시간의 길이(즉, 캐시 시간이 지연 시간보다 길어야 함)로 정해진다. 이러한 지연 시간의 길이는 일반적으로 덧셈 연산 유닛 의 연산 지연, 데이터 기록 유닛의 데이터 기록 지연 및 데이터 판독 유닛의 데이터 판독 지연 에 따라 결정된다. 일부 실시예에서, 누적 요소가 계산되어 캐시 영역에 캐시되는 시간과 제3 요소의 도달 시간 사이의 시간 차가 지연 시간보다 작은 경우, 덧셈 연산 유닛이 제3 요소 요소와 누적 요소의 누적을 수행하고 할 때에 누적 요소가 저장 장치로부터 판독될 수 없음이 확정될 수 있으므로, 캐시 영역의 누적 요소를 덧셈 연산 유닛에 입력으로서 제공할 수 있다. 이하에서 도 8을 참조하여 본 개시의 실시예에 대해 보다 구체적으로 설명하고자 한다. 도 8은 본 개시의 예시 적인 실시예에 따른 딥 러닝 처리를 수행하는 방법의 흐름도를 개략적으로 나타낸다. 방법은 적어도 부분적으로 딥 러닝 처리 장치에 의해 구현된다. 에서, 딥 러닝 처리 장치는 적어도 하나의 행렬 곱셈-누적 모듈이 컨볼루션 신경망 중 컨볼루션층의 컨볼루션 커널 파라미터 값 행렬과 제1 오차 그래디언트 값 행렬의 행렬 곱셈-누적 연산을 진행하여 복수의 중 간 행렬을 획득하도록 한다. 에서, 딥 러닝 처리 장치는 복수의 중간 행렬의 요소를 재구성하지 않고 복수의 중간 행렬을 저장 장치에 저장한다. 에서, 딥 러닝 처리 장치는 저장 장치로부터 복수의 중간 행렬을 판독한다. 에서, 딥 러닝 처리 장치는 복수의 행렬 누적 모듈이 병렬 방식으로 컨볼루션층의 컨볼루션 방식에 따라 복수의 중간 행렬을 기반으로 행렬 누적 연산을 수행하여, 컨볼루션층의 제2 오차 그래디 언트 값 행렬을 획득하도록 한다. 일부 실시예에서, 복수의 중간 행렬은 컨볼루션층의 입력의 복수의 채널과 관련되고, 제2 오차 그래디언트 값 행렬은 복수의 채널에 대한 복수의 채널 행렬을 포함한다. 일부 실시예에서, 복수의 행렬 누적 모듈이 컨볼루션 층의 컨볼루션 방식에 따라 행렬을 기반으로 누적 연산을 수행하는 것은 다음 동작들 중 하나를 포함한다: 복수 의 행렬 누적 모듈의 각각의 행렬 누적 모듈이 복수의 채널에 대응하는 복수의 병렬 경로 중 하나의 병렬 경로 상에서, 복수의 중간 행렬 중 복수의 채널 중의 하나의 채널과 관련된 중간 행렬에 대해 누적 연산을 수행하여, 상기 채널에 대한 채널 행렬을 획득하도록 하는 동작; 또는 복수의 행렬 누적 모듈 중 각각의 행렬 누적 모듈이 매번 누적 연산을 진행할 때마다, 복수의 중간 행렬 중의 하나의 중간 행렬을 복수의 채널 행렬 중의 하나의 채 널 행렬의 중간 결과에 누적하도록 한다. 일부 실시예에서, 복수의 행렬 누적 모듈이 컨볼루션층의 컨볼루션 방식에 따라 행렬을 기반으로 누적 연산을 수행하도록 하는 것은, 복수의 행렬 누적 모듈 중 적어도 하나의 행렬 누적 모듈이, 제1 요소와 제2 요소를 누 적하여 누적 요소를 획득하고; 누적 요소를 저장 장치에 기록하며; 누적 요소를 제1 개시 영역에 캐시하되, 제1 캐시 영역의 기록 속도는 저장 장치의 기록 속도보다 빠르며, 누적 요소가 제1 캐시 영역에서 복수의 클럭 사이 클 동안 캐시되고; 그리고 덧셈 연산 유닛이 제3 요소와 누적 요소를 누적하고자 할 때에 저장 장치로부터 누적 요소가 판독될 수 없음이 확정됨에 따라, 제1 캐시 영역에 캐시된 누적 요소가 제3 요소의 누적에 사용되도록 제공되도록 하는 것을 포함한다. 일부 실시예에서, 딥 러닝 처리 장치는 적어도 하나의 행렬 곱셈-누적 모듈이 행렬 곱셈-누적 과정에서 생 성한 제1 중간 연산 결과 및 복수의 행렬 누적 모듈이 행렬 누적 과정에서 생성한 제2 중간 연산 결과를 제2 캐 시 영역에 캐시한다. 일부 실시예에서, 딥 러닝 처리 장치는 딥 러닝 처리 장치의 벡터 계산 모듈이: 벡터 레벨에서 제2 캐시 영역 중 제1 중간 연산 결과 및 제2 중간 연산 결과를 저장하기 위한 저장 영역을 제로 값으로 설정하는 동작; 및 벡터 레벨에서 행렬 누적 연산의 최종 연산 결과를 딥 러닝 처리 장치의 저장 장치에 제2 오차 그래디언트 값 행렬의 적어도 일부분으로서 선택적으로 기록하는 동작 중 적어도 하나를 수행하도록 한다. 일부 실시예에서, 딥 러닝 처리 장치는 범용 처리 장치로부터 CNN의 컨볼루션층의 컨볼루션 방향 작업을 위한 명령어 세트를 획득하고 해당 명령어 세트를 파싱하고; 파싱된 명령어 세트를 기반으로 적어도 하나의 행 렬 곱셈-누적 모듈 및 복수의 행렬 누적 모듈의 제어 신호를 생성한다. 일부 실시예에서, 적어도 하나의 행렬 곱셈-누적 모듈은 복수의 행렬 곱셈-누적 모듈을 포함하고, 여기서 적어 도 하나의 행렬 곱셈-누적 모듈이 행렬 곱셈-누적 연산을 수행하도록 하는 것은, 복수의 행렬 곱셈-누적 모듈이행렬 곱셈-누적 연산을 병렬 방식으로 수행하도록 하는 것을 포함한다. 도 9는 본 개시의 실시예를 구현하기 위한 컴퓨팅 기기의 블록도를 개략적으로 나타낸다. 도시한 바와 같 이, 기기는 읽기 전용 메모리(ROM; 902)에 저장된 컴퓨터 프로그램 명령어 또는 저장부에서 랜덤 액 세스 메모리(RAM; 903)에 로드된 컴퓨터 프로그램 명령어에 따라, 여러가지 적절한 동작 및 처리를 수행할 수 있는 처리 장치를 포함한다. 처리 장치는 본 개시원에서 설명한 하나 또는 복수의 딥 러닝 처리 장치 를 포함할 수 있다. 처리 장치는 하나 또는 복수의 범용 처리 장치을 더 포함할 수 있다. RAM에는 컴퓨팅 기기의 동작에 필요한 다양한 프로그램과 데이터도 저장되어 있다. 처리 장치, ROM 및 RAM은 버스를 통해 서로 연결된다. 입출력(I/O) 인터페이스도 버스에 연결된 다. 키보드, 마우스 등과 같은 입력부; 다양한 유형의 디스플레이, 스피커 등과 같은 출력부; 자기 디스 크, 광 디스크와 같은 저장부; 및 네트워크 카드, 모뎀, 무선 통신 송수신기 등과 같은 통신부를 포 함하는 기기의 다양한 부재는 I/O 인터페이스에 연결된다. 통신부는 기기가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신 네트워크를 통해 다른 기기와 정보 및/또는 데이터를 교환하도록 허용한 다. 처리 장치는 처리 및 컴퓨팅 기능을 구비한 다양한 범용 및/또는 전용 처리 부재일 수 있다. 처리 장치 의 일부 예로, 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU), 다양한 전용 인공 지능(AI) 컴퓨팅 칩, 머신 러닝 모델 알고리즘을 실행하는 다양한 컴퓨팅 장치, 디지털 신호 프로세서(DSP) 및 임의의 적절한 프로세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만, 이들로 한정되지 않는다. 처리 장치는 방법과 같은 위에서 상술한 다양한 방법 및 처리를 수행한다. 예를 들어, 일부 실시예에서 방법은 저장부과 같은 기계 판독 가능한 매체에 유형적으로 포함된 컴퓨터 소프트웨어 프로그램으로 구현될 수 있다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신부를 통해 기기에 로드 및/ 또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로드되고 처리 장치에 의해 실행될 경우, 상술한 방 법의 하나 또는 복수의 단계가 수행될 수 있다. 대체적으로, 다른 일 실시예에서 처리 장치는 임의의 다른 적합한 방식으로 (예를 들어, 펌웨어에 의해) 방법을 수행하도록 구성될 수 있다. 위에서 설명된 기능들은 적어도 일부가 하나 또는 복수의 하드웨어 논리 부재에 의해 실행될 수 있다. 예를 들 어, 비제한적으로, 사용 가능한 시범적인 유형의 하드웨어 논리 부재에는 필드 프로그램 가능한 게이트 어레이 (FPGA), 전용 집적 회로(ASIC), 전용 표준 제품(ASSP), 시스템 온 칩의 시스템(SOC), 복합 프로그램 가능한 논 리 소자(CPLD) 등이 포함된다. 본원의 방법을 구현하기 위한 프로그램 코드는 하나 또는 복수의 프로그래밍 언어의 임의의 조합으로 프로그래 밍될 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 다른 프로그램 가능한 데이터 처리 장치 의 프로세서 또는 컨트롤러에 제공될 수 있으며, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 경우, 흐름도 및/또는 블록도에 지정된 기능/동작들이 구현되도록 할 수 있다. 프로그램 코드는 전체적으로 기계에서 실행되거나, 부분적으로 기계에서 실행되거나, 독립형 소프트웨어 패키지로서 기계에서 실행되거나, 또는 부분 적으로 원격 기계에서 실행되거나 완전히 원격 기계 또는 서버에서 실행될 수 있다. 본원에서, 기계 판독 가능한 매체는 명령어 실행 시스템, 장치 또는 기기에 의해 또는 명령어 실행 시스템, 장 치 또는 기기와 결합하여 사용하기 위한 프로그램을 포함하거나 저장할 수 있는 유형의 매체일 수 있다. 기계 판독 가능한 매체는 기계 판독 가능한 신호 매체 또는 기계 판독 가능한 저장 매체일 수 있다. 기계 판독 가능 한 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적절한 조합을 포함할 수 있지만, 이들로 한정되지 않는다. 기계 판독 가능한 저장 매체의 보다 구체적인 예로, 하나 또는 복수의 와이어에 기반한 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 판독 전용 메모리(ROM), 소거 및 프로그램 가능한 판독 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, CD- ROM, 광학 저장 기기, 자기 저장 기기 또는 상술한 내용의 임의의 적절한 조합 등이 포함된다. 그 밖에, 특정 순서로 각 동작들을 설명하였으나, 이는 이러한 동작들이 도시된 특정 순서 또는 순차적 순서로 수행되도록 요구되거나 모든 도시된 동작들이 예기한 결과를 달성하기 위해 수행되어야 함을 이해해야 한다. 일 정한 환경에서, 복수의 태스크 및 병렬 처리는 유리할 수 있다. 마찬가지로, 위 설명에 여러 개의 구체적인 구 현 세부사항이 포함되어 있지만, 이들이 본원의 청구 범위를 한정하는 것으로 해석되어서는 안된다. 독립적인 실시예의 컨텍스트에서 설명된 특정 특징들은 단일 구현으로 조합되어 구현될 수 있다. 반대로, 단일 구현의 컨텍스트에서 설명된 다양한 특징은 또한 복수의 구현에서 독립적으로 또는 임의의 적절한 하위 조합으로 구현될 수도 있다. 구조 특징 및/또는 방법 논리적 동작에 특정된 언어로 본 개시의 실시예를 설명하였지만, 첨부된 청구범위에서 한정된 주제는 위에서 설명한 특정된 특징 또는 동작에 반드시 한정되는 것은 아님을 이해해야 한다. 반대로, 위에서 설명한 특정된 특징 및 동작은 단지 청구범위의 예시적 형태를 구현하기 위한 것이다."}
{"patent_id": "10-2020-0120922", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시 실시예의 상술한 특징 및 다른 특징, 장점 및 양태는 아래의 도면과 상세한 설명을 통해 더 명확해질 것이다. 도면에서 동일하거나 유사한 표기는 동일하거나 유사한 요소를 나타낸다. 도 1은 컨볼루션 신경망(CNN)의 예시적 구조 블록도를 개략적으로 나타낸다. 도 2는 일부 실시예에 따른 예시적인 처리 아키텍처의 블록도를 개략적으로 나타낸다. 도 3a는 본 개시의 일부 실시예에 따른 딥 러닝 처리 장치의 예시적 구조 블록도를 개략적으로 나타낸다. 도 3b는 본 개시의 다른 일부 실시예에 따른 딥 러닝 처리 장치의 예시적 구조 블록도를 개략적으로 나타낸다. 도 3c는 본 개시의 또 다른 일부 실시예에 따른 딥 러닝 처리 장치의 예시적 구조 블록도를 개략적으로 나타낸 다. 도 4a는 CNN의 컨볼루션층의 컨볼루션 작업을 개략적으로 나타낸다. 도 4b는 CNN의 컨볼루션층의 컨볼루션 역방향 작업을 개략적으로 나타낸다.도 5는 본 개시의 일부 실시예에 따른 행렬 누적 과정을 개략적으로 나타낸다. 도 6은 본 개시의 다른 일부 실시예에 따른 행렬 연산 모듈의 예시적 구조 블록도를 개략적으로 나타낸다. 도 7은 본 개시의 다른 일부 실시예에 따른 행렬 누적 모듈의 예시적 구조 블록도를 개략적으로 나타낸다. 도 8은 본 개시의 실시예에 따른 태스크 처리를 수행하는 방법의 흐름도를 개략적으로 나타낸다. 도 9는 본 개시의 복수 실시예를 구현할 수 있는 컴퓨팅 기기의 블록도를 나타낸다."}
