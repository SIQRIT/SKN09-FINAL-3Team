{"patent_id": "10-2021-0149409", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0064149", "출원번호": "10-2021-0149409", "발명의 명칭": "리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법", "출원인": "인하대학교 산학협력단", "발명자": "신도형"}}
{"patent_id": "10-2021-0149409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "강화학습 모델의 에이전트(Agent)에서 시나리오(scenario)에 따라 공정표 및 공정의 흐름 환경(Environment)에나타나는 공정표 액티비티(Activity)의 공정 별 리소스(resource) 조합을 선택하는 행동(Action)을 수행하는 제1단계; 및강화학습 모델의 에이전트(Agent)는 리스크(Risk) 확률이 반영된 새로운 시나리오(scenario)가 등장하면 공정표상 리스크(Risk)를 반영하여 목표 공기 및 목표 비용을 만족시킬 수 있는 행동(Action)을 선택하는 제2단계;를포함하는 것을 특징으로 하는 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법."}
{"patent_id": "10-2021-0149409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 제1단계는 상기 리소스(resource)는 공사 수행에 들어가는 인력, 장비, 자재를 포함하는 것을 특징으로 하는 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법."}
{"patent_id": "10-2021-0149409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서, 상기 제1단계는 상기 에이전트(Agent)는 복수의 상태(State)를 단계별로 이동하며 액티비티(Activity) 별 행동리스트(Action list)에서 적절한 행동(Action)을 고르도록 학습하는 단계인 것을 특징으로 하는 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법."}
{"patent_id": "10-2021-0149409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 제1단계 또는 제2단계 이후에, 시나리오(Scenario)가 끝난 뒤 예측된 공기(工期) 및 비용 정보는 기 취득한 목적 공기 및 비용 정보 사이의 오차에 따라 보상을 주는 제3단계;를 더 포함하는 것을 특징으로 하는 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법."}
{"patent_id": "10-2021-0149409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서, 상기 제1단계에서 에이전트(Agent)는 마지막 상태에 도달했을 때 선택한 액티비티(Activity)별 리소스 조합에따른 총 공기(工期) 및 비용을 계산하여 목표 공기 및 비용을 비교한 결과를 토대로 적절한 보상(Reward)을 주는 것을 특징으로 하는 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법."}
{"patent_id": "10-2021-0149409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4항에 있어서, 상기 제3단계는, 상기 오차가 허용 수준이면 양(+)의 보상을 주고, 허용 수준이 아니면 음(-)의 보상을 주는 단공개특허 10-2023-0064149-3-계인 것을 특징으로 하는 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법."}
{"patent_id": "10-2021-0149409", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법에 관한 것으로, AI 기반의 건설계획 시뮬레이션의 여러 기술들 중 강화학습을 기반으로 하여 건설관리 및 계획 수립을 최적화할 수 있어 기 존 건설 계획 및 관리 시뮬레이션 기술이 갖는 공사에 투입되는 다양한 리소스 및 예측할 수 없는 리스크에 최적 화 기능이 부재하다는 한계를 해결할 수 있고, 리스크(Risk)를 반영하여 공기 및 비용을 예측하므로 신뢰성이 높 고, 리소스 조합의 최적화까지 수행할 수 있으므로 건설계획 및 관리에 더욱 효율적으로 활용될 수 있는 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법을 제공한다."}
{"patent_id": "10-2021-0149409", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법에 관한 것으로서, 더욱 상 세하게는 실제와 가장 유사한 건설관리 및 계획 수립을 위하여 리스크의 확률분포 및 공정의 정보를 확률로써 적용할 수 있는 공정계획 최적화 방법에 관한 것이다."}
{"patent_id": "10-2021-0149409", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 공정계획 수립이란 설계, 시공, 원가 등의 지식을 기반으로 계약문서와 원가를 분석하여 공사의 목 적물을 계약된 공기 내에 완성하기 위한 일정계획을 수립하는 것이다. 기존 공정계획 기술의 경우, 리스크가 제대로 반영되지 못한다는 특성이 있으며, 이로 인해, 기존의 공정계획을 통해 얻은 예측 공기와 비용은 그 정확도가 떨어진다는 한계가 존재한다. 특히, 1년간의 공정계획을 보여주는 연간공정표만 하더라도 수백 개 이상의 공정으로 구성되게 되는데, 이러한 공정들의 자원최적화에는 상당한 노력과 시간이 소요된다는 문제가 있다. 이를 해결하기 위해서 Micro-Cyclone, Stroboscope 등의 공정계획 시뮬레이션이 개발되었으며, 국내외 건설 관 리/계획을 위한 가장 대표적인 기술은 Oracle사의 Primavera P6와 Microsoft의 MS Project가 존재한다. 이러한 공정관리 시뮬레이션을 사용할 경우, 일정관리 뿐 아니라 공정계획에 따른 비용관리, 자원관리 등의 기 능을 함께 활용할 수 있다는 장점이 있다. 그런데, 상기 Oracle사의 Primavera P6와 Microsoft의 MS Project 프로그램들은 건설 수행의 리스크를 반영할 수 없고, 작업 환경에 따라 달라지는 작업 별 생산성 변동을 확률분포로 이용하여 적용할 수 없으므로 두 프로 그램을 통해 최적화된 공기와 비용은 실제와 차이가 날 수 밖에 없다는 한계가 존재한다. 즉, 기존의 공정계획 시뮬레이션은 공기예측 및 자원최적화에는 어느 정도 유효하지만, 리스크에 따른 공정계획 불확실성과 공사 리소스 변동에 따른 공정 별 공기 및 비용의 변화를 적극적으로 반영하지 못하므로, 기존 기술 로 예측된 공기 및 비용의 정확도는 실제와 큰 차이가 있다는 한계가 있다. 이러한 공정계획 기술과 관련된 선행기술로 공개특허 제10-2013-0049391호(참고문헌 1), 등록특허 제10-0191405 호(참고문헌 2) 등도 제안된 바 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 참고문헌 1: 공개특허 제10-2013-0049391호 (특허문헌 0002) 참고문헌 2: 등록특허 제10-0191405호"}
{"patent_id": "10-2021-0149409", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 이러한 문제점들을 해결하기 위한 것으로서 본 발명은 실제와 가장 유사한 건설관리 및 계획 수립을 위하여 리스크의 확률분포 및 공정의 정보를 확률로써 적용할 수 있는 AI 기반의 건설관리 및 계획 최적 화 방법을 제공하는데 그 목적이 있다.특히, 본 발명은 AI 기반의 건설계획 시뮬레이션의 여러 기술들 중 강화학습을 기반으로 하여 건설관리 및 계획 수립을 최적화할 수 있는 공정계획 최적화 방법을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2021-0149409", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이와 같은 기술적 과제를 해결하기 위해 본 발명은; 강화학습 모델의 에이전트(Agent)에서 시나리오(scenario)에 따라 공정표 및 공정의 흐름 환경(Environment)에 나타나는 공정표 액티비티(Activity)의 공정 별 리소스(resource) 조합을 선택하는 행동(Action)을 수행하는 제 1단계; 및 강화학습 모델의 에이전트(Agent)는 리스크(Risk) 확률이 반영된 새로운 시나리오(scenario)가 등장 하면 공정표 상 리스크(Risk)를 반영하여 목표 공기 및 목표 비용을 만족시킬 수 있는 행동(Action)을 선택하는 제2단계;를 포함하는 것을 특징으로 하는 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법을 제공한다. 이때, 상기 제1단계는 상기 리소스(resource)는 공사 수행에 들어가는 인력, 장비, 자재를 포함하는 것을 특징 으로 한다. 그리고, 상기 제1단계는 상기 에이전트(Agent)는 복수의 상태(State)를 단계별로 이동하며 액티비티(Activity) 별 행동 리스트(Action list)에서 적절한 행동(Action)을 고르도록 학습하는 단계인 것을 특징으로 한다. 아울러, 상기 제1단계 또는 제2단계 이후에, 시나리오(Scenario)가 끝난 뒤 예측된 공기(工期) 및 비용 정보는 기 취득한 목적 공기 및 비용 정보 사이의 오차에 따라 보상을 주는 제3단계;를 더 포함하는 것을 특징으로 한 다. 이때, 상기 제1단계에서 에이전트(Agent)는 마지막 상태에 도달했을 때 선택한 액티비티(Activity)별 리소스 조 합에 따른 총 공기(工期) 및 비용을 계산하여 목표 공기 및 비용을 비교한 결과를 토대로 적절한 보상(Reward) 을 주는 것을 특징으로 한다. 그리고, 상기 제3단계는, 상기 오차가 허용 수준이면 양(+)의 보상을 주고, 허용 수준이 아니면 음(-)의 보상을 주는 단계인 것을 특징으로 한다."}
{"patent_id": "10-2021-0149409", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 기존 건설 계획 및 관리 시뮬레이션 기술이 갖는 공사에 투입되는 다양한 리소스 및 예측할 수 없는 리스크에 최적화 기능이 부재하다는 한계를 강화학습 인공지능 기반의 기술을 통해 해결하는 효과가 있 다. 특히, 본 발명에 따르면 강화학습을 활용한 AI 기반의 건설계획 시뮬레이션 모델을 통해 리스크(Risk)를 반영하 여 공기 및 비용을 예측하므로 신뢰성이 높고, 리소스 조합의 최적화까지 수행할 수 있으므로 건설계획 및 관리 에 더욱 효율적으로 활용될 수 있다."}
{"patent_id": "10-2021-0149409", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법을 첨부한 도면 을 참고로 하여 상세히 기술되는 실시 예에 의하여 그 특징들을 이해할 수 있을 것이다. 이에 앞서, 본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정해서 해석되어서 는 아니 되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념을 적절하게 정의할 수 있다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 따라서, 본 명세서에 기재된 실시 예와 도면에 도시된 구성은 본 발명의 가장 바람직한 일 실시 예에 불과할 뿐 이고, 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원시점에 있어서 이들은 대체할 수 있는 다 양한 균등물과 변형 예들이 있을 수 있음을 이해하여야 한다. 본 발명에 따른 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법은 리스크에 따른 공 정계획의 불확실성과 공사 리소스 변동에 따른 공정 별 공기 및 비용의 변화를 적극적으로 반영할 수 있도록 실 제와 가장 유사한 건설 관리 및 계획 수립을 위하여 리스크의 확률분포 및 공정 정보를 확률로써 적용할 수 있 는 AI 기반의 건설관리 및 계획 최적화 방법이다. 여기서, 상기 리소스(resource)는 공사 수행에 들어가는 인력, 장비, 자재 등을 포함하는 개념이다. 특히, 본 발명은 AI 기반의 건설계획 시뮬레이션의 여러 기술들 중 강화학습을 기반으로 한다. 우선 도 1은 강화학습 모델의 일반적 구조를 도시한 도면이다. 이를 참고하면, 강화학습 기반의 딥러닝은 에이 전트(Agent)를 학습시키는 방법으로 수행된다. 도 1에서와 같이 에이전트(Agent)는 자유롭게 여러가지 행동(action)을 취할 수 있으며, 해당 행동 (action)은 에이전트(Agent)가 처해진 환경(Environment)의 상태(State)를 파악하여 결정된다. 여기서, 에이전트(Agent)가 취하는 행동(action)에 따라 에이전트(Agent)는 보상(Reward) 또는 페널 티(Penalty)를 받게 되며, 에이전트(Agent)가 보상(Reward)이 높아지는 방향으로 학습하도록 학습의 방향 을 결정시키게 되며, 이러한 강화학습 모델에 의한 학습방식은 매 상황별로 달라지는 시나리오(scenario)가 존 재할 때 활용하는데 가장 적합하며 최근에는 주로 Atari game, Starcraft 등의 게임을 플레이하는 모델로도 자 주 활용된다. 한편, 도 2는 본 발명에 따른 강화학습을 활용한 AI 기반 건설계획 시뮬레이션 모델의 학습을 위한 공정표 상 강화학습 필요 요소의 정의 예를 도시한 도면이다. 이에 의하면, 건설계획 시뮬레이션에서 공정표 및 공정의 흐름은 환경(Environment)에 해당한다고 볼 수 있으며, 공정표의 액티비티(Activity)는 환경(Environment)에서 나타나는 상태 정보로 활용할 수 있다. 에이전트(Agent)가 공정의 흐름에서 나타나는 액티비티(Activity)에 들어갈 수 있는 공정 별 리소스 조합 의 선택을 행동(Action)이라고 생각한다면, 강화학습의 에이전트(Agent)가 행동(Action)할 수 있는 조건은 모두 갖춰지게 된다. 또한, 실제 공정 관리자가 건설계획 시뮬레이션을 이용한다고 가정할 때, 목적 공기(工期) 및 비용의 정보는 취 득 가능한 정보이므로, 하나의 시나리오(Scenario)가 끝난 뒤 예측된 공기(工期) 및 비용 정보와 목적 공기 및 비용 사이의 오차가 얻어질 수 있다. 그리고, 이러한 예측된 공기(工期) 및 비용 정보와 목적 공기 및 비용 사이의 오차가 허용할 만한 수준이면 양 (+)의 보상, 허용할 만한 수준이 아니면 음(-)의 보상을 주게 된다면, 에이전트(Agent)가 행하는 행동 (Action)에 따른 보상을 적절하게 정의할 수 있다. 이러한 건설계획 시뮬레이션을 위한 강화학습 모델이 수행될 경우, 실제 시공 중 예측하지 못한 이벤트(event) 가 발생했을 때, 해당 이벤트(event) 발생 시점 이후의 후속 공정에 대한 빠른 최적화 조치 또한 쉽게 가능해진 다.이하에서는 도 3 및 도 4를 참고로 리스크 및 DEAS 데이터를 적용한 강화학습 기반 AI 시뮬레이션의 상세 구동 과정을 설명한다. 먼저, 도 3의 (a) 내지 (d)는 본 발명에 따른 강화학습을 활용한 AI 기반 건설계획 시뮬레이션 모델 학습 수행 순서를 순차적으로 도시한 도면들이다. 여기서, 도 3의 (a) 내지 (d)는 시뮬레이션 모델의 학습 구동 사항의 이해를 돕기 위하여 공사 수행에 들어가는 인력, 장비, 자재 등의 리소스(resource)에 대한 행동(Action)만을 취하는 것으로 나타낸 것이다. 이에 의하면 도 3의 (a) 내지 (c)에서와 같이 상태(State)는 '1'에서 '3'으로 이동함에 따라 에이전트 (Agent)는 액티비티 별 행동 리스트(Action list)에서 적절한 행동(Action)을 고르도록 학습된다. 예를 들어, 도 3의 (a)는 상태(State)가 '1'로서 액티비티 #1의 행동 리스트(Action list) 'A1'은 \"1) 1 Backhoe + 2 Dump\", \"2) 2 Backhoe + 5 Dump\" 및 \"3) 3 Backhoe + 8 Dump\"임을 알 수 있다. 여기서, 에이전트(Agent)는 \"상태(State)=1\"에서 \"행동(Action)=3\"을 선택하면 액티비티 #1의 행동 리스 트(Action list) 'A1'의 행동(Action) \"3) 3 Backhoe + 8 Dump\"을 적절한 행동으로 고르도록 학습한다. 다음으로 도 3의 (b)는 상태(State)가 '2'로서 액티비티 #2의 행동 리스트(Action list) 'A2'는 \"1) 1 Backhoe + 2 Dump\", \"2) 2 Backhoe + 5 Dump\" 및 \"3) 3 Backhoe + 8 Dump\"임을 알 수 있다. 여기서, 에이전트(Agent)는 \"상태(State)=2\"에서 \"행동(Action)=2\"를 선택하면 액티비티 #2의 행동 리스 트(Action list) 'A2'의 행동(Action) \"2) 2 Backhoe + 5 Dump\"를 적절한 행동으로 고르도록 학습한다. 그리고, 도 3의 (c)는 상태(State)가 '3'으로서 액티비티 #3의 행동 리스트(Action list) 'A3'는 \"1) 1 Backhoe + 2 Dump\", \"2) 2 Backhoe + 5 Dump\" 및 \"3) 3 Backhoe + 8 Dump\"임을 알 수 있다. 여기서 에이전트 (Agent)는 \"상태(State)3\"에서 \"행동(Action)=2\"를 선택하면 액티비티 #3의 행동 리스트(Action list) 'A3'의 행동(Action) \"2) 2 Backhoe + 5 Dump\"를 적절한 행동으로 고르도록 학습한다. 그리고, 마지막 상태인 도 3의 (d)는 상태(State)가 '4(End)'임을 알 수 있다. 여기서, 에이전트(Agent)가 선택한 액티비티(Activity #1 ~ #3)별 리소스는 액티비티 #1의 행동 리스트 (Action list) 'A1'의 행동(Action) \"3) 3 Backhoe + 8 Dump\", 액티비티 #2의 행동 리스트(Action list) 'A2' 의 행동(Action) \"2) 2 Backhoe + 5 Dump\", 액티비티 #3의 행동 리스트(Action list) 'A3'의 행동(Action) \"2) 2 Backhoe + 5 Dump\"임을 알 수 있다. 이와 같이 마지막 상태인 네 번째 시점인 도 3의 (d)에 도달했을 때, 에이전트(Agent)가 선택한 액티비티 (Activity #1 ~ #3)별 리소스 조합에 따른 총 공기(工期) 및 비용을 계산하고, 이를 목표 공기 및 비용과 비교 하게 된다. 그리고, 계산된 리소스 조합에 따른 총 공기(工期) 및 비용과 목표 공기 및 비용을 비교한 결과를 토대로 적절 한 보상(Reward)을 주게 되면 에이전트(Agent)는 각 액티비티(Activity #1 ~ #3) 별 리소스(resource) 선 택에 대한 보상(Reward)을 통해 학습하게 된다. 이와 같은 학습 과정에서, 에이전트(Agent)는 액티비티(Activity #1 ~ #3)별 적절한 리소스 조합을 도출할 수 있게 되므로, 액티비티(Activity)에 따라 최적화된 리소스가 반영된 공정표를 제공할 수 있다. 한편, 도 4의 (a) 및 (b)는 본 발명에 따른 강화학습을 활용한 AI 기반 건설계획 시뮬레이션 모델 학습 수행시 리스크(Risk)가 반영된 시나리오 예를 도시한 도면들이다. 이는 상기 도 3의 (a) 내지 (d)를 수행한 이후 개발된 시뮬레이션 기술 내 시나리오(scenario)에서 리스크 (Risk)에 대한 최적화를 수행하게 된다. 도 4와 같은 공정표 케이스에서 리스크(Risk) 확률이 반영된 새로운 시나리오(scenario 2, 3)가 도 4의 (a), (b)와 같이 등장하게 되면, 리스크(Risk)가 나타남에 따라 에이전트(Agent)가 어떤 행동을 취해야 하는지 까지 학습하게 된다. 여기서, 리스크(Risk)가 반영되지 않았을 때와 리스크(Risk)가 반영되었을 때의 많은 시나리오(scenario)가 존 재하는 다양한 케이스의 공정표를 통해 강화학습 모델이 학습되면, 강화학습 모델의 에이전트(Agent)는 공 정표 상 어떤 위치에 리스크(Risk)가 존재하더라도 목표 공기 및 목표 비용을 만족시킬 수 있는 행동(Action)을 선택하게 되며, 이때 선택된 리소스 조합에 따른 공기 및 비용이 예측 공기 및 비용이 된다. 이상에서와 같이 예측된 공기 및 비용은 리스크(Risk)가 반영된 공기 및 비용이므로 신뢰성이 높고, 리소스 조 합의 최적화까지 수행할 수 있으므로 더욱 효율적으로 활용될 수 있다. 위에서 설명한 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화 방법을 정리하면, 강화학습 모델의 에이전트(Agent)에서 시나리오(scenario)에 따라 공정표 및 공정의 흐름 환경(Environment)에 나타 나는 공정표 액티비티(Activity)의 공정 별 리소스(resource) 조합을 선택하는 행동(Action)을 수행하는 제1단 계 및 강화학습 모델의 에이전트(Agent)는 리스크(Risk) 확률이 반영된 새로운 시나리오(scenario)가 등장 하면 공정표 상 리스크(Risk)를 반영하여 목표 공기 및 목표 비용을 만족시킬 수 있는 행동(Action)을 선택하는 제2단계를 포함하여 이루어진다. 이때, 상기 제1단계는 상기 리소스(resource)는 공사 수행에 들어가는 인력, 장비, 자재를 포함하고, 상기 제1 단계는 상기 에이전트(Agent)는 복수의 상태(State)를 단계별로 이동하며 액티비티(Activity) 별 행동 리 스트(Action list)에서 적절한 행동(Action)을 고르도록 학습하는 단계이다. 아울러, 상기 제1단계 또는 제2단계 이후에, 시나리오(Scenario)가 끝난 뒤 예측된 공기(工期) 및 비용 정보는 기 취득한 목적 공기 및 비용 정보 사이의 오차에 따라 보상을 주는 제3단계를 더 포함한다. 이때, 상기 제1단계에서 에이전트(Agent)는 마지막 상태에 도달했을 때 선택한 액티비티(Activity)별 리소 스 조합에 따른 총 공기(工期) 및 비용을 계산하여 목표 공기 및 비용을 비교한 결과를 토대로 적절한 보상 (Reward)을 주게 된다. 그리고, 상기 제3단계는, 상기 오차가 허용 수준이면 양(+)의 보상을 주고, 허용 수준이 아니면 음(-)의 보상을 주는 단계이다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형 가능 한 것으로, 본 발명의 보호범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모 든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0149409", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 리스크 발생 확률 및 DEAS 데이터를 반영한 AI 기반 공정계획 최적화를 위한 강화학습 모델의 일반적 구 조를 도시한 도면이다. 도 2는 본 발명에 따른 강화학습을 활용한 AI 기반 건설계획 시뮬레이션 모델의 학습을 위한 공정표 상 강화학 습 필요 요소의 정의 예를 도시한 도면이다. 도 3의 (a) 내지 (d)는 본 발명에 따른 강화학습을 활용한 AI 기반 건설계획 시뮬레이션 모델 학습 수행 순서를 순차적으로 도시한 도면들이다. 도 4의 (a) 및 (b)는 본 발명에 따른 강화학습을 활용한 AI 기반 건설계획 시뮬레이션 모델 학습 수행시 리스크 가 반영된 시나리오 예를 도시한 도면들이다."}
