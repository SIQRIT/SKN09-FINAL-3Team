{"patent_id": "10-2020-0029565", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0111104", "출원번호": "10-2020-0029565", "발명의 명칭": "인공지능에 기반하여 영상을 분석하는 카메라 및 그것의 동작 방법", "출원인": "한화테크윈 주식회사", "발명자": "김현호"}}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "네트워크를 통해 서로 통신할 수 있는 인공지능 카메라들 중 어느 하나의 동작 방법에 있어서:상기 인공지능 카메라들 각각은 딥 러닝 방식을 이용한 영상 분석을 수행하도록 구성되는 인공지능 프로세서를포함하되,상기 동작 방법은,상기 네트워크를 통해 다른 인공지능 카메라와 서로 등록 정보를 교환함으로써, 상기 다른 인공지능 카메라와함께 상기 영상 분석을 위한 클러스터를 구성하는 단계;상기 네트워크를 통해 노멀 카메라들에 액세스할 수 있도록, 상기 노멀 카메라들의 등록 정보를 상기 다른 인공지능 카메라와 공유하는 단계;상기 노멀 카메라들 중 하나를 할당받을 때, 상기 할당된 노멀 카메라에 액세스하여 상기 할당된 노멀 카메라에의해 촬영된 영상을 수신하는 단계;상기 인공지능 프로세서를 이용하여 상기 수신된 영상을 분석하는 단계; 및상기 수신된 영상의 상기 분석에 따른 결과 정보를 상기 할당된 노멀 카메라의 식별자와 함께 상기 네트워크를통해 외부 장치로 전송하는 단계를 포함하는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,추가적인 인공지능 카메라의 등록 정보를 수신하는 단계; 및상기 수신된 등록 정보에 따라 상기 추가적인 인공지능 카메라에 액세스하여 상기 추가적인 인공지능 카메라를상기 클러스터에 추가하는 단계를 더 포함하는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 클러스터를 구성하는 단계는 상기 다른 인공지능 카메라와 통신하여 상기 인공지능 카메라들 중 어느 하나를 상기 클러스터의 마스터 노드로 결정하는 단계를 포함하되,상기 할당된 노멀 카메라는 상기 마스터 노드로부터의 커맨드에 따라 결정되는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 촬영된 영상을 수신하는 단계는,상기 할당된 노멀 카메라에서 생성된 이벤트 알람 신호를 수신하는 단계; 및상기 이벤트 알람 신호에 응답하여 상기 할당된 노멀 카메라에 상기 촬영된 영상의 제공을 요청하는 단계를 포함하는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 클러스터를 구성하는 단계는 상기 다른 인공지능 카메라와 통신하여 상기 인공지능 카메라들 중 어느 하나를 상기 클러스터의 마스터 노드로 결정하는 단계를 포함하되,공개특허 10-2020-0111104-3-상기 이벤트 알람 신호는 상기 마스터 노드를 통해 수신되는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서,상기 촬영된 영상을 수신하는 단계는,상기 할당된 노멀 카메라에 상기 촬영된 영상의 제공을 요청하기 전에, 상기 이벤트 알람 신호에 응답하여 상기할당된 노멀 카메라의 설정을 소정의 설정값으로 변경하는 단계를 더 포함하는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 할당된 노멀 카메라에 의해 촬영된 영상을 수신하는 단계에서,상기 인공지능 프로세서를 이용하여 상기 수신된 영상을 분석할 때 딥러닝에 따른 확률이 임계치 이상이 되는지여부에 따라, 상기 할당된 노멀 카메라로부터 수신하는 상기 영상의 길이는 가변적으로 조절되는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 다른 인공지능 카메라와 상태 메시지들을 통신하는 단계;상기 상태 메시지들에 근거하여 상기 다른 인공지능 카메라가 비정상으로 판별될 때, 상기 다른 인공지능 카메라에 할당된 다른 노멀 카메라에 액세스하여 상기 다른 노멀 카메라에 의해 촬영된 영상을 추가적으로 수신하는단계;상기 인공지능 프로세서를 이용하여 상기 추가적으로 수신된 영상을 분석하는 단계; 및상기 추가적으로 수신된 영상의 상기 분석에 따른 결과 정보를 상기 다른 노멀 카메라의 식별자와 함께 상기 네트워크를 통해 상기 외부 장치로 전송하는 단계를 더 포함하는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 인공지능 카메라는 이미지 센서를 더 포함하되,상기 이미지 센서를 통해 영상을 촬영하는 단계; 및상기 인공지능 프로세서를 이용하여 상기 촬영된 영상을 분석하는 단계를 더 포함하는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 외부 장치로 전송하는 단계는,상기 촬영된 영상, 제 1 메타 데이터, 및 제 2 메타 데이터를 상기 외부 장치로 전송하는 단계를 포함하되,상기 제 1 메타 데이터는 상기 촬영된 영상의 상기 분석에 따른 결과 정보를 포함하고,상기 제 2 메타 데이터는 상기 수신된 영상의 상기 분석에 따른 상기 결과 정보를 및 상기 할당된 노멀 카메라의 상기 식별자를 포함하는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서,상기 클러스터를 구성하는 단계는,사용자 단말기로부터 상기 다른 인공지능 카메라의 상기 등록 정보를 수신하는 단계; 및공개특허 10-2020-0111104-4-상기 수신된 등록 정보를 이용하여 상기 다른 인공지능 카메라와 통신을 수행함으로써 상기 클러스터를 구성하는 단계를 포함하는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1 항에 있어서,상기 노멀 카메라들의 등록 정보를 상기 다른 인공지능 카메라와 공유하는 단계는,사용자 단말기로부터 상기 노멀 카메라들의 등록 정보를 수신하는 단계; 및상기 수신된 등록 정보를 상기 다른 인공지능 카메라에 제공하는 단계를 포함하는 동작 방법."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "광학계;상기 광학계를 통해 수신되는 빛에 따라 생성된 영상을 처리하도록 구성되는 제 1 프로세서;상기 제 1 프로세서의 제어에 응답하여 동작하되, 딥 러닝 방식에 기반하여 상기 처리된 영상을 분석하도록 구성되는 제 2 프로세서; 및네트워크를 통한 통신을 제공하는 네트워크 인터페이스를 포함하되,상기 제 1 프로세서는,상기 네트워크를 통해 외부 인공지능 카메라와 서로 등록 정보를 교환함으로써, 상기 외부 인공지능 카메라와함께 영상 분석을 위한 클러스터를 구성하고,상기 네트워크를 통해 노멀 카메라들에 액세스할 수 있도록, 상기 노멀 카메라들의 등록 정보를 상기 외부 인공지능 카메라와 공유하고,상기 노멀 카메라들 중 하나를 할당받을 때, 상기 할당된 노멀 카메라에 액세스하여 상기 할당된 노멀 카메라에의해 촬영된 영상을 수신하고,상기 제 2 프로세서에 상기 수신된 영상을 분석하도록 커맨드하고,상기 수신된 영상의 상기 분석에 따른 결과 정보를 상기 할당된 노멀 카메라의 식별자와 함께 상기 네트워크를통해 외부 장치로 전송하도록 구성되는 카메라."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 제 1 프로세서는 추가적인 인공지능 카메라의 등록 정보가 수신될 때, 상기 수신된 등록 정보에 따라 상기추가적인 인공지능 카메라에 액세스하여 상기 추가적인 인공지능 카메라를 상기 클러스터에 추가하도록 구성되는 카메라."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 13 항에 있어서,상기 제 1 프로세서는 상기 외부 인공지능 카메라와 통신하여 상기 클러스터의 카메라들 중 어느 하나를 상기클러스터의 마스터 노드로 결정하도록 구성되고,상기 할당된 노멀 카메라는 상기 마스터 노드로부터의 커맨드에 따라 결정되는 카메라."}
{"patent_id": "10-2020-0029565", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 13 항에 있어서,상기 제 1 프로세서는 상기 할당된 노멀 카메라에 상기 촬영된 영상의 제공을 요청하기 전에, 상기 할당된 노멀카메라의 설정을 소정의 설정값으로 변경하도록 구성되는 카메라.공개특허 10-2020-0111104-5-청구항 17 제 13 항에 있어서,상기 제 1 프로세서는 상기 제 2 프로세서에서 상기 수신된 영상을 분석할 때 딥러닝에 따른 확률이 임계치 이상이 되는지 여부에 따라, 상기 할당된 노멀 카메라로부터 수신하는 상기 영상의 길이를 가변적으로 조절하도록구성되는 카메라."}
{"patent_id": "10-2020-0029565", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "네트워크를 통해 서로 통신할 수 있는 인공지능 카메라들 중 어느 하나의 동작 방법에 있어서, 인공지능 카메라 들 각각은 딥 러닝 방식을 이용한 영상 분석을 수행하도록 구성되는 인공지능 프로세서를 포함하되, 동작 방법은, 네트워크를 통해 다른 인공지능 카메라와 서로 등록 정보를 교환함으로써 다른 인공지능 카메라와 함께 영상 분석을 위한 클러스터를 구성하는 단계, 네트워크를 통해 노멀 카메라들에 액세스할 수 있도록 노멀 카메라 들의 등록 정보를 다른 인공지능 카메라와 공유하는 단계, 노멀 카메라들 중 하나를 할당받을 때, 할당된 노멀 카메라에 액세스하여 할당된 노멀 카메라에 의해 촬영된 영상을 수신하는 단계, 인공지능 프로세서를 이용하여 수신된 영상을 분석하는 단계, 그리고 수신된 영상의 분석에 따른 결과 정보를 할당된 노멀 카메라의 식별자와 함께 네트워크를 통해 외부 장치로 전송하는 단계를 포함한다."}
{"patent_id": "10-2020-0029565", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상을 촬영할 수 있는 카메라 및 그것의 동작 방법에 관한 것으로, 좀 더 구체적으로는 인공지능에 기반하여 영상을 분석하는 카메라 및 그것의 동작 방법에 관한 것이다."}
{"patent_id": "10-2020-0029565", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "통신 네트워크를 통하여 외부 장비와 연결된 카메라들을 포함하는 영상 촬영 시스템에서, 카메라들은 호스트 장 치 및 사용자 단말기와 같은 외부 장비와 통신을 수행하지만, 카메라들도 서로 P2P(peer to peer) 방식에 의하 여 통신을 수행할 수도 있다. 그럼에도 불구하고, 종래에는 카메라들은 외부 장비와 통신하여 서비스를 제공하 는 방식들이 주를 이루었다. 이러한 경우, 카메라들 사이의 통신은 일반적으로 수행되지 않아 카메라들 각각은 개별적으로 동작할 수 있다. 한편, 인공지능 기능을 포함하는 카메라가 개발되고 있다. 인공지능 기술은 딥 러닝(기계학습) 및 딥 러닝을 활 용한 요소 기술들로 구성된다. 딥 러닝은 입력 데이터의 특징들을 스스로 분류/학습하는 알고리즘이며, 요소 기 술은 딥 러닝을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 시각적 이해, 추론/예측, 지 식 표현 등의 기술들을 포함할 수 있다. 시각적 이해는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함할 수 있다. 추론/예 측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함할 수 있다. 지식 표현은 인간의 경험정보를 지식데이터로 자동화 처리하는 기술로서, 지 식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함할 수 있다. 위 기재된 내용은 오직 본 발명의 기술적 사상들에 대한 배경 기술의 이해를 돕기 위한 것이며, 따라서 그것은 본 발명의 기술 분야의 당업자에게 알려진 선행 기술에 해당하는 내용으로 이해될 수 없다."}
{"patent_id": "10-2020-0029565", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시 예들은 인공지능에 기반한 영상 분석 범위를 효율적으로 확장시킬 수 있는 인공지능 카메라 및 그것의 동작 방법에 관한 것이다."}
{"patent_id": "10-2020-0029565", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 네트워크를 통해 서로 통신할 수 있는 인공지능 카메라들 중 어느 하나의 동작 방법 에 있어서, 상기 인공지능 카메라들 각각은 딥 러닝 방식을 이용한 영상 분석을 수행하도록 구성되는 인공지능 프로세서를 포함하되, 상기 동작 방법은, 상기 네트워크를 통해 다른 인공지능 카메라와 서로 등록 정보를 교환 함으로써, 상기 다른 인공지능 카메라와 함께 상기 영상 분석을 위한 클러스터를 구성하는 단계; 상기 네트워크 를 통해 노멀 카메라들에 액세스할 수 있도록, 상기 노멀 카메라들의 등록 정보를 상기 다른 인공지능 카메라와 공유하는 단계; 상기 노멀 카메라들 중 하나를 할당받을 때, 상기 할당된 노멀 카메라에 액세스하여 상기 할당 된 노멀 카메라에 의해 촬영된 영상을 수신하는 단계; 상기 인공지능 프로세서를 이용하여 상기 수신된 영상을 분석하는 단계; 및 상기 수신된 영상의 상기 분석에 따른 결과 정보를 상기 할당된 노멀 카메라의 식별자와 함 께 상기 네트워크를 통해 외부 장치로 전송하는 단계를 포함한다. 상기 동작 방법은 추가적인 인공지능 카메라의 등록 정보를 수신하는 단계; 및 상기 수신된 등록 정보에 따라 상기 추가적인 인공지능 카메라에 액세스하여 상기 추가적인 인공지능 카메라를 상기 클러스터에 추가하는 단계 를 더 포함할 수 있다.상기 클러스터를 구성하는 단계는 상기 다른 인공지능 카메라와 통신하여 상기 인공지능 카메라들 중 어느 하나 를 상기 클러스터의 마스터 노드로 결정하는 단계를 포함하되, 상기 할당된 노멀 카메라는 상기 마스터 노드로 부터의 커맨드에 따라 결정될 수 있다. 상기 촬영된 영상을 수신하는 단계는, 상기 할당된 노멀 카메라에서 생성된 이벤트 알람 신호를 수신하는 단계; 및 상기 이벤트 알람 신호에 응답하여 상기 할당된 노멀 카메라에 상기 촬영된 영상의 제공을 요청하는 단계를 포함할 수 있다. 상기 클러스터를 구성하는 단계는 상기 다른 인공지능 카메라와 통신하여 상기 인공지능 카메라들 중 어느 하나 를 상기 클러스터의 마스터 노드로 결정하는 단계를 포함하되, 상기 이벤트 알람 신호는 상기 마스터 노드를 통 해 수신될 수 있다. 상기 촬영된 영상을 수신하는 단계는, 상기 할당된 노멀 카메라에 상기 촬영된 영상의 제공을 요청하기 전에, 상기 이벤트 알람 신호에 응답하여 상기 할당된 노멀 카메라의 설정을 소정의 설정값으로 변경하는 단계를 더 포함할 수 있다. 상기 할당된 노멀 카메라에 의해 촬영된 영상을 수신하는 단계에서, 상기 인공지능 프로세서를 이용하여 상기 수신된 영상을 분석할 때 딥러닝에 따른 확률이 임계치 이상이 되는지 여부에 따라, 상기 할당된 노멀 카메라로 부터 수신하는 상기 영상의 길이는 가변적으로 조절될 수 있다. 상기 동작 방법은 상기 다른 인공지능 카메라와 상태 메시지들을 통신하는 단계; 상기 상태 메시지들에 근거하 여 상기 다른 인공지능 카메라가 비정상으로 판별될 때, 상기 다른 인공지능 카메라에 할당된 다른 노멀 카메라 에 액세스하여 상기 다른 노멀 카메라에 의해 촬영된 영상을 추가적으로 수신하는 단계; 상기 인공지능 프로세 서를 이용하여 상기 추가적으로 수신된 영상을 분석하는 단계; 및 상기 추가적으로 수신된 영상의 상기 분석에 따른 결과 정보를 상기 다른 노멀 카메라의 식별자와 함께 상기 네트워크를 통해 상기 외부 장치로 전송하는 단 계를 더 포함할 수 있다. 상기 인공지능 카메라는 이미지 센서를 더 포함하되, 상기 동작 방법은 상기 이미지 센서를 통해 영상을 촬영하 는 단계; 및 상기 인공지능 프로세서를 이용하여 상기 촬영된 영상을 분석하는 단계를 더 포함할 수 있다. 상기 외부 장치로 전송하는 단계는, 상기 촬영된 영상, 제 1 메타 데이터, 및 제 2 메타 데이터를 상기 외부 장 치로 전송하는 단계를 포함하되, 상기 제 1 메타 데이터는 상기 촬영된 영상의 상기 분석에 따른 결과 정보를 포함하고, 상기 제 2 메타 데이터는 상기 수신된 영상의 상기 분석에 따른 상기 결과 정보를 및 상기 할당된 노 멀 카메라의 상기 식별자를 포함할 수 있다. 상기 클러스터를 구성하는 단계는, 사용자 단말기로부터 상기 다른 인공지능 카메라의 상기 등록 정보를 수신하 는 단계; 및 상기 수신된 등록 정보를 이용하여 상기 다른 인공지능 카메라와 통신을 수행함으로써 상기 클러스 터를 구성하는 단계를 포함할 수 있다. 상기 노멀 카메라들의 등록 정보를 상기 다른 인공지능 카메라와 공유하는 단계는, 사용자 단말기로부터 상기 노멀 카메라들의 등록 정보를 수신하는 단계; 및 상기 수신된 등록 정보를 상기 다른 인공지능 카메라에 제공하 는 단계를 포함할 수 있다. 본 발명의 다른 일면은 카메라에 관한 것이다. 본 발명의 실시 예에 따른 카메라는, 광학계; 상기 광학계를 통 해 수신되는 빛에 따라 생성된 영상을 처리하도록 구성되는 제 1 프로세서; 상기 제 1 프로세서의 제어에 응답 하여 동작하되, 딥 러닝 방식에 기반하여 상기 처리된 영상을 분석하도록 구성되는 제 2 프로세서; 및 네트워크 를 통한 통신을 제공하는 네트워크 인터페이스를 포함하되, 상기 제 1 프로세서는, 상기 네트워크를 통해 외부 인공지능 카메라와 서로 등록 정보를 교환함으로써, 상기 외부 인공지능 카메라와 함께 영상 분석을 위한 클러 스터를 구성하고, 상기 네트워크를 통해 노멀 카메라들에 액세스할 수 있도록, 상기 노멀 카메라들의 등록 정보 를 상기 외부 인공지능 카메라와 공유하고, 상기 노멀 카메라들 중 하나를 할당받을 때, 상기 할당된 노멀 카메 라에 액세스하여 상기 할당된 노멀 카메라에 의해 촬영된 영상을 수신하고, 상기 제 2 프로세서에 상기 수신된 영상을 분석하도록 커맨드하고, 상기 수신된 영상의 상기 분석에 따른 결과 정보를 상기 할당된 노멀 카메라의 식별자와 함께 상기 네트워크를 통해 외부 장치로 전송하도록 구성된다. 상기 제 1 프로세서는 추가적인 인공지능 카메라의 등록 정보가 수신될 때, 상기 수신된 등록 정보에 따라 상기 추가적인 인공지능 카메라에 액세스하여 상기 추가적인 인공지능 카메라를 상기 클러스터에 추가하도록 구성될 수 있다.상기 제 1 프로세서는 상기 외부 인공지능 카메라와 통신하여 상기 클러스터의 카메라들 중 어느 하나를 상기 클러스터의 마스터 노드로 결정하도록 구성되고, 상기 할당된 노멀 카메라는 상기 마스터 노드로부터의 커맨드 에 따라 결정될 수 있다. 상기 제 1 프로세서는 상기 할당된 노멀 카메라에 상기 촬영된 영상의 제공을 요청하기 전에, 상기 할당된 노멀 카메라의 설정을 소정의 설정값으로 변경하도록 구성될 수 있다. 상기 제 1 프로세서는 상기 제 2 프로세서에서 상기 수신된 영상을 분석할 때 딥러닝에 따른 확률이 임계치 이 상이 되는지 여부에 따라, 상기 할당된 노멀 카메라로부터 수신하는 상기 영상의 길이를 가변적으로 조절하도록 구성될 수 있다."}
{"patent_id": "10-2020-0029565", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예들에 따르면, 인공지능에 기반한 영상 분석 범위를 효율적으로 확장시킬 수 있는 인공지능 카 메라 및 그것의 동작 방법이 제공된다."}
{"patent_id": "10-2020-0029565", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 바람직한 실시 예를 첨부한 도면을 참조하여 상세히 설명한다. 하기의 설명에서는 본 발 명에 따른 동작을 이해하는데 필요한 부분만이 설명되며 그 이외 부분의 설명은 본 발명의 요지를 모호하지 않 도록 하기 위해 생략될 것이라는 것을 유의하여야 한다. 또한 본 발명은 여기에서 설명되는 실시 예에 한정되지"}
{"patent_id": "10-2020-0029565", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "않고 다른 형태로 구체화될 수도 있다. 단지, 여기에서 설명되는 실시 예는 본 발명이 속하는 기술분야에서 통 상의 지식을 가진 자에게 본 발명의 기술적 사상을 용이하게 실시할 수 있을 정도로 상세히 설명하기 위하여 제 공되는 것이다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 여기에서 사용된 용 어는 특정한 실시예들을 설명하기 위한 것이며 본 발명을 한정하기 위한 것이 아니다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. \"X, Y, 및 Z 중 적어도 어느 하나\", 그리고 \"X, Y, 및 Z로 구성된 그룹으로부터 선택된 적어도 어느 하나\"는 X 하나, Y 하나, Z 하나, 또는 X, Y, 및 Z 중 둘 또는 그 이상의 어떤 조합 (예를 들면, XYZ, XYY, YZ, ZZ) 으로 해석될 수 있다. 여기에서, \"및/또는\"은 해 당 구성들 중 하나 또는 그 이상의 모든 조합을 포함한다. 도 1은 본 발명의 실시 예에 따른 영상 촬영 시스템을 보여주는 블록도이다. 영상 촬영 시스템은 여기에 설명된 실시 예들에 따른 방법들을 수행하도록 동작하는 복수의 장치들, 서버들, 및 /또는 소프트웨어 구성 요소들을 포함할 수 있다. 도 1에 도시된 장치들 및 서버들은 다른 방식으로 배치될 수 있고, 그러한 장치들 및/또는 서버들에 의해 제공되는 동작들 및 서비스들은 여기에 설명된 실시 예들을 수행하 기 위해 결합되거나 분리될 수 있으며, 더 많은 수 혹은 더 적은 수의 장치들 및 서버들에 의해 수행될 수도 있 다. 하나 또는 그 이상의 장치들 및/또는 서버들은 동일한 혹은 다른 독립체들(entities), 예를 들면 기업들에 의해 구동될 수 있다. 도 1을 참조하면, 영상 촬영 시스템은 네트워크, 사용자 단말기, 복수의 인공지능(artificial intelligence) 카메라들(121~123), 제 1 내지 제 n 노멀 카메라들(131~13n), 및 영상 관리 서버를 포함할 수 있다. 네트워크는 공용 네트워크(public network), 적어도 하나의 사설 네트워크(private network), 유선 네트워 크, 무선 네트워크, 다른 적절한 타입의 네트워크, 및 그것들의 조합들 중 적어도 하나를 포함할 수 있다. 영상 촬영 시스템 내 구성 요소들 각각은 유선 통신 기능 및 무선 통신 기능 중 적어도 하나를 포함할 수 있으 며, 그에 따라 네트워크를 통해 상호 간 통신할 수 있다. 사용자 단말기는 네트워크를 통해 복수의 인공지능 카메라들(121~123), 제 1 내지 제 n 노멀 카메라들 (131~13n), 및 영상 관리 서버와 통신할 수 있다. 사용자 단말기는 복수의 인공지능 카메라들 (121~123) 및 제 1 내지 제 n 노멀 카메라들(131~13n) 각각으로부터 촬영되고 있는 영상을 실시간으로 수신하고, 수신된 영상을 디스플레이할 수 있다. 또한, 사용자 단말기는 영상 관리 서버에 액세스하 여, 영상 관리 서버에 저장된 영상들을 수신하고, 수신된 영상들을 디스플레이할 수 있다. 이때, 영상 관 리 서버에 저장된 영상들은 복수의 인공지능 카메라들(121~123) 및 제 1 내지 제 n 노멀 카메라들 (131~13n)에 의해 촬영된 영상들일 수 있다. 영상 관리 서버는 영상과 연관하여 움직임 감지, 얼굴 감지, 침입 감지, 총 소리 감지, 오브젝트/패턴 정 보, 오브젝트들의 유사도 정보 등 다양한 타입들을 정보를 포함할 수 있는 메타 데이터를 더 저장한다. 그러나, 본 발명의 실시 예들은 여기에 한정되지 않는다. 예를 들면, 영상 및 영상과 연관된 메타 데이터는 서로 다른 데이터베이스들에 저장될 수 있다. 메타 데이터는 인공지능 카메라에 의해 제공될 수 있다. 사용자 단말기는 영상 관리 서버로부터 메타 데이터를 수신하고, 수신된 메타 데이터가 나타내는 정보를 디스플레이하고, 메타 데이터를 선택하는 사용자 입 력에 응답하여 영상 관리 서버로부터 해당 영상을 수신하고, 수신된 영상을 디스플레이할 수 있다. 실시 예들에서, 사용자 단말기는 컴퓨터 장치를 포함하되, 컴퓨터 장치는 네트워크에 연결된 복수의 인공지능 카메라들(121~123), 제 1 내지 제 n 노멀 카메라들(131~13n), 및 영상 관리 서버와 같은 구성 요 소에 액세스하고, 그로부터 영상을 수신하고, 수신된 영상을 디스플레이하기 위한 응용 애플리케이션들을 포함 할 수 있다. 복수의 인공지능 카메라들(121~123)이 영상 촬영 시스템에 제공될 수 있다. 도 1에서, 3개의 인공지능 카 메라들(121~123)이 제공되는 것으로 예시되어 있다. 제 1 내지 제 3 인공지능 카메라들(121~123) 각각은 인공지 능에 기반하여 영상 분석을 수행하도록 구성되는 적어도 하나의 인공지능 프로세서를 포함한다. 제 1 내지 제 3 인공지능 카메라들(121~123) 각각은 영상을 촬영하고, 촬영된 영상을 인공지능 프로세서를 통해 분석하고, 촬영 된 영상 및 영상 분석 결과를 영상 관리 서버에 제공할 수 있다. 또한, 제 1 내지 제 3 인공지능 카메라들 각각은 오디오를 녹음하고, 인공지능 프로세서를 통해 녹음된 오디오를 분석하고, 녹음된 오디오 및 오디오 분 석 결과를 영상 관리 서버에 제공할 수 있다. 이하, 설명의 편의를 위해 영상 분석을 위한 동작들을 중심 으로 본 발명의 실시 예들이 설명된다. 그러나, 이는 설명의 편의를 위한 것으로, 본 발명의 기술적 사상은 오디오 분석에도 적용될 수 있다. 제 1 내지 제 3 인공지능 카메라들(121~123) 각각은 제 1 내지 제 n 노멀 카메라들(131~13n) 중 적어도 하나로 부터 영상을 수신하고, 수신된 영상을 인공지능 프로세서를 통해 분석하고, 영상 분석 결과를 영상 관리 서버 에 제공할 수 있다. 이때, 노멀 카메라는 비 인공지능(non-AI) 카메라일 수 있다. 예를 들면, 노멀 카메라 는 인공지능이 아닌, 모션 감지(motion detection), 얼굴 감지(face detection), 소리 감지(sound detection) 와 같은 종래의 이벤트 감지 알고리즘들을 수행하도록 구성되는 프로세서를 포함할 수 있으며, 반면 인공지능 프로세서는 포함하지 않을 수 있다. 제 1 내지 제 3 인공지능 카메라들(121~123)은 서로 등록 정보를 교환함으로써 영상 분석을 위한 클러스터 (CLST)를 구성하고, 각 노멀 카메라를 클러스터(CLST) 내 인공지능 카메라들(121~123) 중 어느 하나에 할당할 수 있다. 이때, 등록 정보는 인공지능 카메라의 URL(uniform resource locator) 어드레스, IP(internet protocol) 어드레스, 포트(port) 번호, 카메라 로그인 계정과 같은 카메라에 액세스하기 위한 정보를 포함할 수 있다. 각 인공지능 카메라의 등록 정보는 사용자 단말기로부터 제 1 내지 제 3 인공지능 카메라들 (121~123) 중 어느 하나에 수신될 수 있으며, 제 1 내지 제 3 인공지능 카메라들(121~123)에 의해 공유될 수 있 다. 실시 예들에서, 제 1 내지 제 3 인공지능 카메라들(121~123)은 그것들의 등록 정보를 주기적으로 동기화할 수 있다. 제 1 내지 제 3 인공지능 카메라들(121~123) 각각에 어떤 노멀 카메라를 할당할지 여부는 다양한 방식들에 따라 결정될 수 있다. 예를 들면, 제 1 내지 제 3 인공지능 카메라들(121~123)은 서로에게 자신의 가용 자원을 알리 고, 그러한 가용 자원을 참조하여 각 노멀 카메라에 대한 할당이 수행될 수 있다. 예를 들면, 제 1 내지 제 3 인공지능 카메라들(121~123)은 서로 통신하여 마스터 노드로서 기능할 인공지능 카메라를 결정하고, 마스터 노 드는 테스크 스케줄링의 기능을 수행할 수 있다. 마스터 노드는 제 1 내지 제 3 인공지능 카메라들(121~123) 각 각의 가용 자원을 참조하여 각 노멀 카메라를 제 1 내지 제 3 인공지능 카메라들(121~123) 중 어느 하나에 할당 할 수 있다. 이와 같이, 제 1 내지 제 3 인공지능 카메라들(121~123)을 포함하는 클러스터(CLST)를 구성하여 제 1 내지 제 n 노멀 카메라들(131~13n)의 영상들을 분석함으로써, 각 노멀 카메라는 제 1 내지 제 3 인공지능 카메라들 (121~123) 중 어느 하나에 예를 들면 가용 자원을 참조함으로써 할당될 수 있고, 따라서 제 1 내지 제 n 노멀 카메라들(131~13n)의 영상들에 대한 분석은 별도의 인공지능 기능을 포함하는 서버를 제공하지 않고도 제 1 내 지 제 3 인공지능 카메라들(121~123)을 이용하여 효율적으로 수행될 수 있다. 이에 따라, 별도의 인공지능 기능 을 포함하는 서버 없이도, 인공지능에 기반한 영상 분석은 제 1 내지 제 n 인공지능 카메라들(121~123)에 의해 촬영되는 영상들뿐만 아니라 제 1 내지 제 n 노멀 카메라들(131~13n)에 의해 촬영되는 영상들에까지 확장될 수 있다. 따라서, 인공지능에 기반한 영상 분석의 범위를 효율적으로 확장시킬 수 있는 인공지능 카메라 및 그것을 포함하는 영상 촬영 시스템이 제공될 수 있다. 도 2는 도 1의 인공지능 카메라들 중 어느 하나의 실시 예를 보여주는 블록도이다. 도 3은 도 2의 메인 프로세 서의 실시 예를 보여주는 블록도이다. 도 4는 도 2의 인공지능 프로세서의 실시 예를 보여주는 블록도이다. 도 2를 참조하면, 인공지능 카메라는 광학계, 이미지 센서, 램(220, Random Access Memory: RAM), EEPROM(230, Electrically Erasable and Programmable Read Only Memory), 스토리지, 메인 프로세 서, 네트워크 인터페이스, 및 인공지능(artificial intelligence: AI) 프로세서를 포함할 수 있다. 광학계는 피사체로부터의 빛을 광학적으로 처리한다. 이미지 센서는 메인 프로세서의 제어에 응답하여 동작할 수 있다. 이미지 센서는 렌즈를 통해 수신된 광학 신호를 전기 신호로 변환하고, 변환된 전기 신호를 디지털화하여 영상을 생성하도록 구성된다. 예를 들면, 이미지 센서는 아날로그 영상 신호를 디지털 영상 데이터로 변환하도록 구성되는 아 날로그 디지털 컨버터를 포함할 수 있다. 램은 메인 프로세서와 연결된다. 램은 메인 프로세서에 의해 처리된 영상을 일시적으로 저 장할 수 있다. 램은 버퍼 메모리로서 사용될 수 있다. 램은 메인 프로세서의 워킹 메모리로서 사용될 수 있다. EEPROM(Electrically Erasable and Programmable Read Only Memory, 230)은 메인 프로세서 의 동작에 필요한 프로그램 코드들 및/또는 명령어들을 저장할 수 있다. 스토리지는 메인 프로세서 의 동작들에 필요한 설정 데이터를 저장할 수 있다. 또한, 스토리지는 메인 프로세서에 의해 실행될 프로그램 코드들 및/또는 명령어들을 더 저장할 수 있다. 이러한 프로그램 코드들 및/또는 명령어들은 스 토리지로부터 램에 로딩되고, 메인 프로세서에 의해 실행될 수 있다. 아래에서 설명될 메인 프 로세서의 동작들 중 적어도 일부는 메인 프로세서에 의해 이러한 프로그램 코드들 및/또는 명령어들 을 실행함으로써 수행될 수 있다. 실시 예들에서, 스토리지는 플래시 메모리와 같은 불휘발성 저장 매체를 포함할 수 있다. 메인 프로세서는 인공지능 카메라의 제반 동작을 제어한다. 메인 프로세서는 네트워크 인터페이 스를 통해 네트워크(50, 도 1 참조)에 연결된 구성 요소들과 통신할 수 있다. 메인 프로세서는 이미 지 센서로부터 수신된 영상을 적절히 처리하도록 구성되며, 처리된 영상을 네트워크 인터페이스를 통 해 사용자 단말기에 라이브-뷰로 전송할 수 있다. 또한, 메인 프로세서는 처리된 영상을 네트워크 인 터페이스를 통해 영상 관리 서버에 업로드할 수 있다. 나아가, 메인 프로세서는 마이크로폰(미 도시)을 통해 수신되는 오디오 데이터를 수신하고, 수신된 오디오 데이터를 적절히 처리하고, 처리된 오디오 데 이터를 네트워크 인터페이스를 통해 외부 장비로 전송할 수 있다. 이러한 경우, 오디오 데이터 및 영상 데 이터는 멀티미디어 데이터를 구성할 수 있다. 도 3을 참조하면, 메인 프로세서는 코어 프로세서, 데이터 포메터, 데이터 변환기, 리사이 저, MPEG(Moving Picture Experts Group) 인코더, 및 JPEG(Joint Photographic Experts Group) 인 코더를 포함한다. 코어 프로세서는 인공지능 카메라(200, 도 2 참조)의 제반 동작을 제어한다. 또한, 코어 프로세서는 데이터 포매터, 데이터 변환기, 리사이저, MPEG 인코더, 및 JPEG 인코더를 제어한다. 데이터 포메터는 이미지 센서(210, 도 2 참조)로부터의 영상을 램에 저장하며, 데이터 변 환부는 적색(R), 녹색(G), 및 청색(B) 형식의 영상 데이터를 휘도(Y) 및 색차(Cb, Cr) 형식의 영상 데이터 로 변환하며, 리사이저는 영상 데이터의 해상도를 변환할 수 있다. MPEG 인코더는 동영상 인코더로서 동영상 데이터를 압축하며, JPEG 인코더는 정지 영상 인코더로서 정지 영상 데이터를 압축할 수 있다. 이 와 같이, 메인 프로세서는 이미지 센서로부터 수신된 영상을 처리하도록 구성된다. 실시 예들에서, 데이터 포메터, 데이터 변환기, 리사이저, MPEG 인코더, 및 JPEG 인코더 와 같은 영상 처리를 위한 구성 요소들은 각각 하드웨어, 소프트웨어, 펌웨어, 및 그것들의 조합을 통해 구현될 수 있으며, 서로 결합되거나 더 많은 구성 요소들로 분리될 수 있다. 데이터 포메터, 데이터 변환 기, 리사이저, MPEG 인코더, 및 JPEG 인코더 중 적어도 하나가 소프트웨어로 구현되는 경 우, 소프트웨어는 도 2의 스토리지와 같은 컴퓨터로 판독 가능한 저장 매체에 저장될 수 있으며, 코어 프 로세서에 의해 실행될 수 있다. 또한, 데이터 포메터, 데이터 변환기, 리사이저, MPEG 인 코더, 및 JPEG 인코더와 같은 와 같은 영상 처리를 위한 구성 요소들 중 적어도 일부는 이미지 프로 세싱 유닛과 같은 하나의 전용 프로세서를 통해 구현될 수 있다. 다시 도 2를 참조하면, 메인 프로세서는 처리된 영상을 분석하도록 인공지능 프로세서에 커맨드할 수 있다. 인공지능 프로세서는 인공지능 방식에 기반하여 처리된 영상을 분석하도록 구성된다. 영상 분석 결 과는 예를 들면 램에 임시 저장되며, 메인 프로세서는 영상 분석 결과를 해당 영상과 함께 네트워크 인터페이스를 통해 사용자 단말기 혹은 영상 관리 서버에 전송할 수 있다. 도 4를 참조하면, 인공지능 프로세서는 데이터 학습부 및 데이터 분석부를 포함할 수 있다. 데 이터 학습부는 딥 러닝 프레임워크를 포함할 수 있으며, 이에 따라 CNN(Convolutional neural network)과 같은 신경망 알고리즘, SIFT(Scale Invariant Feature Transform)와 같은 비전 알고리즘을 수행할 수 있다. 데 이터 학습부는 오브젝트/패턴 인지, 오브젝트들의 유사도 검사 등의 다양한 영상 분석 기준들을 학습할 수 있다. 데이터 학습부는 영상 분석을 위하여 어떤 데이터를 이용할지에 관한 기준들을 학습(traning)하고 추론(inferencing)할 수 있다. 데이터 학습부는 학습에 이용될 데이터를 획득하고, 획득된 데이터를 데이 터 분석 모델에 적용함으로써, 영상 분석을 위한 기준을 학습해 나갈 수 있다. 데이터 분석부는 메인 프로세서(250, 도 2 참조)의 요청에 응답하여 입력된 영상에 대한 분석을 수행할 수 있다. 데이터 분석부는 학습된 데이터 인식 모델을 이용하여 영상 분석을 수행할 수 있다. 데이터 분석부 는 학습에 의해 설정된 기준들에 따라 데이터를 획득하고, 획득된 데이터를 입력 값으로 하는 데이터 분석 모델을 이용함으로써 영상 분석을 수행하고, 분석에 따른 결과 정보를 출력할 수 있다. 또한, 영상 분석의 결과 정보는 데이터 분석 모델을 업데이트하는데 이용될 수 있다.데이터 학습부 및 데이터 분석부는 각각 하드웨어, 소프트웨어, 펌웨어, 및 그것들의 조합을 통해 구 현될 수 있으며, 서로 결합되거나 더 많은 구성 요소들로 분리될 수 있다. 데이터 학습부 및 데이터 분석 부 중 적어도 하나는 인공지능을 위한 전용 하드웨어 칩 형태로 구현되거나, 범용 프로세서 또는 그래픽 전용 프로세서를 통해 구현될 수 있다. 데이터 학습부 및 데이터 분석부 중 적어도 하나가 소프트웨 어로 구현되는 경우, 소프트웨어는 도 2의 스토리지와 같은 컴퓨터로 판독 가능한 저장 매체에 저장될 수 있으며, 상기 범용 프로세서 또는 그래픽 전용 프로세서와 같은 프로세서에 의해 실행될 수 있다. 데이터 학습부 및 데이터 분석부는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치 들에 각각 탑재될 수도 있다. 예를 들면, 데이터 학습부는 외부 장치에 포함되고, 데이터 분석부는 인공지능 카메라(200, 도 2 참조)에 포함될 수 있다. 이러한 경우, 데이터 학습부 및 데이터 분석부 는 유선 또는 무선으로 통신할 수 있으며, 데이터 학습부는 구축한 모델 정보를 데이터 분석부로 제 공할 수도 있고, 데이터 분석부로 입력된 데이터는 추가 학습 데이터로서 데이터 학습부로 제공될 수 도 있다. 다시 도 2를 참조하면, 메인 프로세서는 다른 인공지능 카메라들과 서로 등록 정보를 교환함으로써 영상 분석을 위한 클러스터(CLST, 도 1 참조)를 구성하고, 제 1 내지 제 n 노멀 카메라들(131~13n)에 액세스할 수 있 도록 제 1 내지 제 n 노멀 카메라들(131~13n)의 등록 정보를 다른 인공지능 카메라들과 공유할 수 있다. 다른 인공지능 카메라들 및 제 1 내지 제 n 노멀 카메라들(131~13n)과의 통신들은 네트워크 인터페이스를 통해 수행된다. 메인 프로세서는 제 1 내지 제 n 노멀 카메라들(131~13n) 중 어느 하나를 할당 받을 때, 할당된 노멀 카메라에 의해 촬영된 영상을 분석하도록 인공지능 프로세서를 제어할 수 있다. 도 5는 인공지능 카메라의 출력 데이터의 포멧의 실시 예를 개념적으로 보여주는 도면이다. 도 2 및 도 5를 참조하면, 메인 프로세서는 영상(VD), 오디오(AD), 제 1 메타 데이터(META1), 및 제 2 메 타 데이터(META2)를 포함하는 출력 데이터(DOUT)를 네트워크 인터페이스를 통해 사용자 단말기 혹은 영상 관리 서버에 전송할 수 있다. 영상(VD) 및 오디오(AD)는 도 2를 참조하여 설명된 바와 같이 메인 프 로세서에 의해 생성된다. 제 1 메타 데이터(META1)는 영상(VD) 및/또는 오디오(AD)에 대한 인공지능 프로 세서의 분석 결과 정보를 포함할 수 있다. 제 2 메타 데이터(META2)는 노멀 카메라로부터 수신된 영상 및/ 또는 오디오에 대한 인공지능 프로세서의 분석 결과 정보를 포함할 수 있다. 제 2 메타 데이터(META2)는 해당 노멀 카메라의 식별자를 더 포함할 수 있다. 식별자는 노멀 카메라의 아이디, IP 어드레스 등 노멀 카메라를 식별할 수 있는 다양한 종류들의 데이터를 포함할 수 있다. 이에 따라, 출력 데 이터(DOUT)를 수신하는 사용자 단말기 혹은 영상 관리 서버는 출력 데이터(DOUT)에 포함된 제 2 메타 데이터(META2)가 어떤 노멀 카메라에 대응하는 것임을 판별할 수 있다. 메인 프로세서의 동작들과 관련된 좀 더 상세한 내용이 이하에서 설명된다. 도 6은 인공지능 카메라에 의해 촬영된 영상을 분석하는 방법을 보여주는 순서도이다. 도 2 및 도 6을 참조하면, S110단계에서, 이미지 센서를 통해 영상이 촬영된다. S120단계에서, 촬영된 영 상이 인공지능 프로세서를 이용하여 분석된다. 메인 프로세서는 이미지 센서를 통해 촬영된 영 상을 처리하고, 처리된 영상을 분석하도록 인공지능 프로세서에 커맨드할 수 있다. 메인 프로세서는 촬영된 영상, 오디오, 영상의 분석에 따른 결과 정보를 도 5에 도시된 출력 데이터(DOUT)의 영상(VD) 필드, 오 디오(AD) 필드, 및 제 1 메타 데이터(META1) 필드에 각각 포함시킬 수 있다. 도 7은 본 발명의 실시 예에 따른 노멀 카메라들과 인터랙션할 수 있는 클러스터를 구성하기 위한 인공지능 카 메라의 동작 방법을 보여주는 순서도이다. 도 8은 도 7의 S210단계의 실시 예를 보여주는 순서도이다. 도 9는 도 7의 S220단계의 실시 예를 보여주는 순서도이다. 도 1 및 도 2와 함께 도 7을 참조하면, S210단계에서, 인공지능 카메라는 다른 인공지능 카메라와 서로 등 록 정보를 교환함으로써 다른 인공지능 카메라와 함께 영상 분석을 위한 클러스터를 구성한다. 제 1 내지 제 3 인공지능 카메라들(121~123)은 도 1을 참조하여 설명된 바와 같이 네트워크를 통해 서로 통신할 수 있으며, 각 인공지능 카메라는 다른 인공지능 카메라에 등록 정보를 전송하고 다른 인공지능 카메라로부터 등록 정보를 수신함으로써 인공지능 카메라들(121~123)을 포함하는 클러스터(CLST)가 생성될 수 있다. 각 인공지능 카메라의 등록 정보는 사용자 단말기를 통해 사용자로부터 제공될 수 있다. 도 8을 참조하면, 인공지능 카메라는 사용자 단말기로부터 다른 인공지능 카메라의 등록 정보를 수신하고(S211), 수신된 등록 정보에 대응하는 인공지능 카메라와 통신을 수행함으로써 해당 인공지능 카메라와 함께 클러스터(CLS T)를 구성할 수 있다. 예를 들면, 사용자 단말기가 제 1 인공지능 카메라에 액세스하여 제 2 및 제 3 인공지능 카메라들(122, 123)의 등록 정보를 제공하면, 제 1 인공지능 카메라는 제공된 등록 정보를 이용 하여 제 2 및 제 3 인공지능 카메라들(122, 123) 각각에 액세스함에 따라, 제 1 내지 제 3 인공지능 카메라들 (121~123)은 서로의 등록 정보를 공유할 수 있다. 이에 따라, 제 1 내지 제 3 인공지능 카메라들(121~123)을 포 함하는 클러스터(CLST)가 생성될 수 있다. 클러스터(CLST)의 생성 시에, 클러스터(CLST)의 제 1 내지 제 3 인공지능 카메라들(121~123)은 서로 통신하여 그 중 어느 하나를 마스터 노드로 결정하는 협상을 수행할 수 있다. 이에 따라, 제 1 내지 제 3 인공지능 카메 라들(121~123) 중 어느 하나는 마스터(master) 노드로서 기능하고, 나머지 인공지능 카메라들은 에이전트 (agent) 노드로서 기능할 수 있다. 마스터 노드는 제 1 내지 제 n 노멀 카메라들(131~13n)의 영상들에 대해 딥 러닝 방식을 이용한 영상 분석들을 수행하도록, 제 1 내지 제 n 노멀 카메라들(131~13n) 각각을 제 1 내지 제 3 인공지능 카메라들(121~123) 중 어느 하나에 할당할 수 있다. 다시 도 1, 도 2, 및 도 7을 참조하면, S220단계에서, 인공지능 카메라는 제 1 내지 제 n 노멀 카메라들 (131~13n)의 등록 정보를 다른 인공지능 카메라와 공유한다. 이에 따라, 제 1 내지 제 3 인공지능 카메라들 (121~123) 각각은 네트워크를 통해 제 1 내지 제 n 노멀 카메라들(131~13n)에 액세스할 수 있게 된다. 예를 들면, 인공지능 카메라는 다른 인공지능 카메라에 노멀 카메라의 등록 정보를 제공할 수 있으며, 또한 다 른 인공지능 카메라로부터 노멀 카메라의 등록 정보를 수신할 수 있다. 이때, 등록 정보는 노멀 카메라의 URL(uniform resource locator) 어드레스, IP(internet protocol) 어드레스, 포트(port) 번호, 카메라 로그인 계정과 같은 카메라에 액세스하기 위한 정보를 포함할 수 있다. 노멀 카메라의 등록 정보는 사용자 단말기를 통해 사용자로부터 제공될 수 있다. 다양한 방식들에 따라 제 1 내지 제 n 노멀 카메라들(131~13n)의 등록 정보가 제 1 내지 제 3 인공지능 카메라들(121~123)에 공유될 수 있다. 도 9를 참조하면, 인공지능 카메라는 사용자 단말기로부터 제 1 내지 제 n 노멀 카메라들 (131~13n)의 등록 정보를 수신하고(S221), 수신된 등록 정보를 다른 인공지능 카메라에게 제공할 수 있다. 예를 들면, 사용자 단말기가 제 1 인공지능 카메라에 제 1 내지 제 n 노멀 카메라들(131~13n)의 등록 정보 를 제공하면, 제 1 인공지능 카메라는 제공된 등록 정보를 제 2 및 제 3 인공지능 카메라들(122, 123)에 제공할 수 있다. 도 10은 클러스터를 구성한 후 인공지능 카메라들에 저장 및 공유되는 클러스터 정보를 보여주는 테이블이다. 클러스터(CLST)가 생성된 후 클러스터(CLST) 내 제 1 내지 제 3 인공지능 카메라들(121~123)은 클러스터 정보 (CLSTIF)를 저장 및 공유할 수 있다. 도 1 및 도 10을 참조하면, 클러스터 정보(CLSTIF)는 제 1 내지 제 3 인공 지능 카메라들(121~123)의 식별자들(AICAM1, AICAM2, AICAM3) 각각에 대응하는 IP 어드레스, 인공지능에 기반한 테스크들의 처리에 따른 인공지능 프로세서의 사용량, 메인 프로세서의 사용량을 포함할 수 있다. 클러스터 정보(CLSTIF)는 제 1 내지 제 3 인공지능 카메라들(121~123) 중 마스터 노드에 의해 수집되고, 제 1 내지 제 3 인공지능 카메라들(121~123) 전체에 공유될 수 있다. 클러스터 정보(CLSTIF)의 인공지능 프로세서의 사용량 및 메인 프로세서의 사용량을 참조하여, 마스터 노드는 제 1 내지 제 n 노멀 카메라들(131~13n) 각각을 제 1 내지 제 3 인공지능 카메라들(121~123) 중 어느 하나에 할당할 수 있다. 사용자는 사용자 단말기를 통해 클러스터(CLST)의 제 1 내지 제 3 인공지능 카메라들(121~123) 중 어느 하 나에 액세스하여 클러스터 정보(CLSTIF)의 적어도 일부를 조회할 수 있다. 도 11은 클러스터를 구성한 후 인공지능 카메라들에 저장 및 공유되는 노멀 카메라 정보를 보여주는 테이블이다. 도 11에서, 설명의 편의를 위해 영상 촬영 시스템에 5개의 노멀 카메라들이 제공되는 것으로 예시 된다. 클러스터(CLST) 내 제 1 내지 제 3 인공지능 카메라들(121~123)은 노멀 카메라 정보(NRMCAMIF)를 저장 및 공유 할 수 있다. 도 1 및 도 11을 참조하면, 노멀 카메라 정보(NRMCAMIF)는 제 1 내지 제 5 노멀 카메라들(131~13 5)의 식별자들(NRMCAM1~NRMCAM5) 각각에 대응하는 IP 어드레스 및 감지 이벤트 타입을 포함할 수 있다. 실시 예 들에서, 노멀 카메라는 인공지능이 아닌 종래의 이벤트 감지 알고리즘들 중 적어도 하나에 기반한 영상 분석을 수행하도록 구성되는 프로세서를 포함할 수 있으며, 노멀 카메라 정보(NRMCAMIF)는 노멀 카메라에 채용된 이벤 트 감지 알고리즘의 이벤트 타입에 대한 정보를 더 저장할 수 있다. 예를 들면, 감지 이벤트 타입은 모션 감지, 얼굴 감지, 소리 감지 등을 포함할 수 있다.도 12는 노멀 카메라들과 인터랙션할 수 있는 클러스터에 인공지능 카메라를 추가하는 방법의 실시 예를 보여주 는 순서도이다. 도 1 및 도 2와 함께 도 12를 참조하면, S310단계에서, 인공지능 카메라는 사용자 단말기로부터 추가 적인 인공지능 카메라의 등록 정보를 수신할 수 있다. S320단계에서, 인공지능 카메라는 수신된 등록 정보 에 따라 상기 추가적인 인공지능 카메라에 액세스하여 해당 인공지능 카메라를 클러스터(CLST)에 추가한다. 또 한, 수신된 등록 정보는 인공지능 카메라를 포함한 클러스터(CLST) 내 인공지능 카메라들에 공유될 수 있 다. 예를 들면, 사용자에 의해 입력된 추가적인 인공지능 카메라의 등록 정보가 사용자 단말기를 통해 제 1 인공지능 카메라에 제공되면, 제 1 인공지능 카메라는 제공된 등록 정보를 제 2 및 제 3 인공지능 카메라들(122, 123)에 전송할 수 있다. 제 1 내지 제 3 인공지능 카메라들(121~123) 각각은 제공된 등록 정보에 따라 추가적인 인공지능 카메라에 액세스하고, 제 1 내지 제 3 인공지능 카메라들(121~123) 및 추가적인 인공지 능 카메라는 서로의 등록 정보를 공유할 수 있다. 이에 따라, 해당 인공지능 카메라는 클러스터(CLST)에 추가될 수 있다. S330단계에서, 인공지능 카메라는 추가된 인공지능 카메라에 각 노멀 카메라의 등록 정보를 공유할 수 있 다. 예를 들면, 제 1 내지 제 3 인공지능 카메라들(121~123)은 노멀 카메라 정보(NRMCAMIF, 도 11 참조)를 추가 적인 인공지능 카메라에 공유할 수 있다. 이와 같이, 클러스터(CLST)의 자원들은 상대적으로 용이하게 확장될 수 있으며, 따라서 별도의 인공지능 기능을 포함하는 서버의 제공 혹은 증설 없이도, 그 자체로 영상을 촬영할 수 있는 인공지능 카메라의 추가를 통해, 영 상 촬영에 의한 감시 범위를 넓히면서도 인공지능에 기반한 영상 분석을 지원받을 수 있는 노멀 카메라들의 개 수를 확장할 수 있다. 도 13은 본 발명의 실시 예에 따른 클러스터에 포함된 인공지능 카메라에서 노멀 카메라의 영상을 분석하는 방 법을 보여주는 순서도이다. 도 1 및 도 2와 함께 도 13을 참조하면, S410단계에서, 인공지능 카메라에 제 1 내지 제 n 노멀 카메라들 (131~13n) 중 어느 하나가 할당될 수 있다. 위에서 설명된 바와 같이, 할당은 클러스터(CLST) 내 제 1 내지 제 3 인공지능 카메라들(121~123) 중 마스터 노드에 의해 수행될 수 있다. 이때, 인공지능 카메라는 마스터 노드일 수 있고, 에이전트 노드일 수도 있다. 노멀 카메라가 할당될 때, S420단계가 수행된다. S420단계에서, 인공지능 카메라는 할당된 노멀 카메라에 액세스하여 할당된 노멀 카메라에 의해 촬영된 영 상을 수신한다. S430단계에서, 인공지능 카메라는 인공지능 프로세서를 이용하여 수신된 영상을 분석한다. S440단계에서, 인공지능 카메라는 영상의 분석에 따른 결과 정보를 할당된 노멀 카메라의 식별자와 함께 영상 관리 서버로 전송한다. 인공지능 카메라는 영상의 분석에 따른 결과 정보 및 노멀 카메라의 식 별자를 도 5에 도시된 출력 데이터(DOUT)의 제 2 메타 데이터(META2) 필드에 포함시킬 수 있다. 이와 같이, 인공지능 카메라들(121~123)을 포함하는 클러스터(CLST)를 통해 제 1 내지 제 n 노멀 카메라들 (131~13n)의 영상들을 분석함으로써, 각 노멀 카메라는 인공지능 카메라들(121~123) 중 어느 하나에 예를 들면 가용 자원을 참조함으로써 할당될 수 있고, 따라서 제 1 내지 제 n 노멀 카메라들(131~13n)의 영상들에 대한 분 석은 별도의 인공지능 기능을 포함하는 서버를 제공하지 않고도 기 제공된 인공지능 카메라들(121~123)을 이용 하여 효율적으로 수행될 수 있다. 이에 따라, 별도의 인공지능 기능을 포함하는 서버 없이도, 인공지능에 기반 한 영상 분석은 제 1 내지 제 n 인공지능 카메라들(121~123)에 의해 촬영되는 영상들뿐만 아니라 제 1 내지 제 n 노멀 카메라들(131~13n)에 의해 촬영되는 영상들에까지 확장될 수 있다. 따라서, 인공지능에 기반한 영상 분 석의 범위를 효율적으로 확장시킬 수 있는 영상 분석 방법이 제공될 수 있다. 도 14는 도 12의 S420단계의 실시 예를 보여주는 순서도이다. 도 1 및 도 2와 함께 도 14를 참조하면, S421단계에서, 인공지능 카메라는 할당된 노멀 카메라들(131~131) 중 어느 하나로부터 이벤트 알람 신호를 수신할 수 있다. 이벤트 알람 신호가 수신될 때, S422단계가 수행될 수 있다. 노멀 카메라는 인공지능이 아닌, 모션 감지, 얼굴 감지, 소리 감지와 같은 종래의 이벤트 감지 알고리즘들을 수 행하도록 구성될 수 있으며, 이벤트의 감지에 응답하여 이벤트 알람 신호를 생성할 수 있다. 실시 예들에서, 인 공지능 카메라는 노멀 카메라의 할당에 응답하여, 이벤트의 감지에 응답하여 이벤트 알람 신호를 제공해줄것을 노멀 카메라에 요청할 수 있으며, 노멀 카메라는 인공지능 카메라에 이벤트 알람 신호를 제공할 수 있다. 실시 예들에서, 마스터 노드는 이벤트의 감지에 응답하여 이벤트 알람 신호를 제공해줄 것을 노멀 카메라 에 요청할 수 있으며, 노멀 카메라는 마스터 노드에 이벤트 알람 신호를 제공할 수 있다. 이러한 방식에서, 인 공지능 카메라가 마스터 노드인 경우, 노멀 카메라로부터 이벤트 알람 신호를 수신할 수 있다. 인공지능 카메라가 에이전트 노드인 경우, 마스터 노드를 통해 이벤트 알람 신호를 수신할 수 있다. 노멀 카메라는 이벤트를 감지한 경우, 인공지능(혹은 딥러닝)을 통한 영상 분석을 지원하는 특수 모드로 진입할 수 있다. 예를 들면, 노멀 카메라는 미리 설정된 값들로 내부 설정값들을 변경할 수 있다. 이벤트의 감지는 인 공지능을 통한 영상 분석이 필요한 것을 의미하는 바, 인공지능을 통한 영상 분석에 적합하도록 미리 설정된 값 들로 설정값들을 변경할 수 있다. 영상 관리 서버로 송신되어 디스플레이를 통해 사용자에게 제공되기에 적합한 영상과 인공지능을 통한 영상 분석에 적합한 영상은 상이할 수 있다. 인공지능을 통한 영상 분석에 적합 한 영상을 촬영하도록 노멀 카메라가 설정되어 있는 경우, 영상 관리 서버를 통해 수신되는 영상을 시청하 는 사용자는 불편함을 느낄 수 있다. 이러한 이유에서, 노멀 카메라는 평소에는 사용자에게 제공되기에 적합한 영상을 촬영하도록 설정되어 있을 수 있다. 반면, 인공지능 카메라가 사용자에게 제공되기에 적합한 영상 을 수신하여 영상 분석을 수행하는 경우, 영상 분석에 적합하도록 영상에 대해 전처리를 수행할 것이 요구된다. 전처리 과정에서 영상에 많은 노이즈들이 발생할 수 있고, 많은 시간이 소요될 수 있다. 이러한 이유에서, 노멀 카메라의 설정값들은 인공지능을 통한 영상 분석에 적합한 값들로 변경되고, 인공지능 카메라는 해당 설정 하에서 촬영된 영상을 노멀 카메라로부터 수신할 수 있다. 이에 따라, 인공지능 카메라는 영상에 대한 전 처리을 하지 않거나 줄어든 전처리 과정을 통해 빠르고 정확하게 영상 분석을 수행할 수 있다. 즉, 인공지능 카 메라에 적합하게 샤프니스(sharpness) 혹은 노출(exposure) 등의 설정값들이 조절되어, 노멀 카메라의 영 상 품질(Image Quality)을 인공지능(혹은 딥러닝)에 적합하도록 할 수 있다. 노멀 카메라는 인공지능 카메라 으로부터의 설정값 제어요청에 응답하여 설정값들을 변경할 수 있고, 이벤트의 감지에 응답하여 설정값들 을 변경할 수도 있다. 또는, 영상 관리 서버의 제어에 응답하여 설정값들을 변경할 수도 있다. 이러한 노 멀 카메라의 특수 모드로의 진입은 S422단계 이전에 수행될 수 있다. 노멀 카메라는 인공지능을 통한 영상 분석에 필요한 프레임들을 촬영하는 동안에만 특수 모드의 값들로 내부 설 정값들을 변경하고, 이후 다시 설정값들을 이전 설정값들으로 복원할 수 있다. 또는, 인공지능 카메라는 인공지능 카메라의 영상 분석이 종료될 때 설정값들을 복원하도록 노멀 카메라를 제어할 수 있다. S422단계에서, 이벤트 알람 신호에 응답하여, 인공지능 카메라는 촬영된 영상의 제공을 노멀 카메라에 요 청한다. S423단계에서, 인공지능 카메라는 노멀 카메라로부터 영상을 수신하고, 인공지능 프로세서를 이용하 여 수신된 영상을 분석할 수 있다. 다른 실시 예로서, 인공지능 카메라는 할당된 노멀 카메라에 상시로 액세스하여 영상을 수신하고, 수신된 영상을 분석할 수도 있다. 인공지능 카메라는 노멀 카메라의 영상을 분석할 때, 딥러닝(혹은 인공지능)에 따른 확률이 임계치 이상이 되는지 여부에 따라 S422단계 및 S423단계를 통해 노멀 카메라로부터 수신하는 영상의 길이를 가변적으로 제어 할 수 있다. 인공지능 프로세서는 예를 들면 딥러닝을 통한 영상 분석과 함께, 딥러닝에 따른 확률을 출력 할 수 있으며, 이러한 확률이 임계치 이상인 경우 영상 분석이 완료된 것을 의미할 수 있다. 딥러닝에 따른 확 률이 임계치 이상이 되는 경우 추가적인 영상 분석이 필요하지 않으므로, 인공지능 카메라 및/또는 메인 프로세서는 딥러닝에 따른 확률이 임계치 이상이 되는지 여부에 따라 노멀 카메라로부터 수신하는 영상의 길이를 가변적으로 조절할 수 있다. 인공지능 카메라는 딥러닝에 따른 확률이 임계치 이상이 되는지 여부 에 따라 상대적으로 짧은 길이의 영상을 수신하거나 상대적으로 긴 길이의 영상을 수신할 수 있다. 예를 들면, 인공지능 카메라는 추가적인 영상이 필요한 경우 영상을 추가로 요청하여 수신할 수 있으며, 이러한 경우 추가적인 영상의 길이, 추가적인 영상을 요청하는 횟수 등은 딥러닝에 따른 확률에 따라 가변적으로 조절될 수 있다. 인공지능 카메라가 노멀 카메라로부터 정지 영상을 수신하는 경우, 딥러닝에 따른 확률이 임계치 이상이 되는지 여부에 따라 추가적인 정지 영상을 요청할 수 있고, 인공지능 카메라가 노멀 카메라로부터 동적 영 상을 수신하는 경우, 딥러닝에 따른 확률이 임계치 이상이 되는지 여부에 따라 동적 영상을 송신 중단을 요청할 수 있다.이와 같이, 인공지능 카메라는 딥러닝에 따른 확률이 임계치 이상이 되는지 여부에 따라 노멀 카메라로부 터 수신하는 영상의 길이를 가변적으로 제어할 수 있다. 이에 따라, 노멀 카메라의 설정값들을 변경하거나 복원 하는 시간도 빨라질 수 있다. 도 15는 본 발명의 다른 실시 예에 따른 클러스터에 포함된 인공지능 카메라에서 노멀 카메라의 영상을 분석하 는 방법을 보여주는 순서도이다. 도 1 및 도 2와 함께 도 15를 참조하면, S510단계에서, 인공지능 카메라는 다른 인공지능 카메라와 상태 메시지들을 송수신하여 클러스터(CLST) 내 인공지능 카메라들(121~123) 중 비정상인 인공지능 카메라가 존재하 는지 여부를 판별한다. 인공지능 카메라들(121~123)은 주기적으로 상태 메시지들을 교환할 수 있다. S520단계에서, 인공지능 카메라는 클러스터(CLST) 내 인공지능 카메라가 비정상일 때 S530단계를 수행한다. 이하, 설명의 편의를 위해 인공지능 카메라가 클러스터(CLST)의 마스터 노드라고 가정한다. S530단계는 마스터 노드에 의해 수행될 수 있다. S530단계에서, 인공지능 카메라는 비정상인 인공지능 카 메라에 할당되었던 노멀 카메라를 다른 인공지능 카메라에 할당할 수 있다. 마스터 노드는 클러스터 정보 (CLSTIF, 도 10 참조)의 인공지능 프로세서의 사용량 및 메인 프로세서의 사용량을 참조하여, 해당 노멀 카메라 를 제 1 내지 제 3 인공지능 카메라들(121~123) 중 어느 하나에 할당할 수 있다. 이하, 설명의 편의를 위해 해 당 노멀 카메라가 인공지능 카메라에 할당된다고 가정한다. S540단계에서, 인공지능 카메라는 할당된 노멀 카메라에 액세스하여 영상을 수신한다. S550단계에서, 인공 지능 카메라는 인공지능 프로세서를 이용하여 수신된 영상을 분석한다. S560단계에서, 인공지능 카메 라는 영상의 분석에 따른 결과 정보를 해당 노멀 카메라의 식별자와 함께 영상 관리 서버로 전송한다. 이와 같이, 클러스터(CLST) 내 비정상인 자원은 상대적으로 용이하게 클러스터(CLST)로부터 배제될 수 있으며, 따라서 인공지능에 기반한 영상 분석은 노멀 카메라의 영상에 대해 안정적으로 수행될 수 있다. 예를 들면, 인 공지능에 기반한 영상 분석이 노멀 카메라에 대해 미제공되는 시간은 감소하거나 최소화될 수 있다. 비록 특정 실시 예들 및 적용 례들이 여기에 설명되었으나, 이는 본 발명의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 발명은 상기의 실시예에 한정되는 것은 아니며 본 발명이 속하는 분야에서 통상적인 지식을 가진 자라면 이러한 기재로부터 다양한 수정들 및 변형들이 가능하다. 따라서, 본 발명의 사상은 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등하거나 등가적 변형이 있는 모든 것들은 본 발명 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2020-0029565", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 영상 촬영 시스템을 보여주는 블록도이다. 도 2는 도 1의 인공지능 카메라들 중 어느 하나의 실시 예를 보여주는 블록도이다. 도 3은 도 2의 메인 프로세서의 실시 예를 보여주는 블록도이다. 도 4는 도 2의 인공지능 프로세서의 실시 예를 보여주는 블록도이다. 도 5는 인공지능 카메라의 출력 데이터의 포멧의 실시 예를 개념적으로 보여주는 도면이다. 도 6은 인공지능 카메라에 의해 촬영된 영상을 분석하는 방법을 보여주는 순서도이다. 도 7은 본 발명의 실시 예에 따른 노멀 카메라들과 인터랙션할 수 있는 클러스터를 구성하기 위한 인공지능 카 메라의 동작 방법을 보여주는 순서도이다. 도 8은 도 7의 S210단계의 실시 예를 보여주는 순서도이다. 도 9는 도 7의 S220단계의 실시 예를 보여주는 순서도이다. 도 10은 클러스터를 구성한 후 인공지능 카메라들에 저장 및 공유되는 클러스터 정보를 보여주는 테이블이다. 도 11은 클러스터를 구성한 후 인공지능 카메라들에 저장 및 공유되는 노멀 카메라 정보를 보여주는 테이블이다. 도 12는 노멀 카메라들과 인터랙션할 수 있는 클러스터에 인공지능 카메라를 추가하는 방법의 실시 예를 보여주 는 순서도이다. 도 13은 본 발명의 실시 예에 따른 클러스터에 포함된 인공지능 카메라에서 노멀 카메라의 영상을 분석하는 방 법을 보여주는 순서도이다. 도 14는 도 12의 S420단계의 실시 예를 보여주는 순서도이다. 도 15는 본 발명의 다른 실시 예에 따른 클러스터에 포함된 인공지능 카메라에서 노멀 카메라의 영상을 분석하 는 방법을 보여주는 순서도이다."}
