{"patent_id": "10-2020-0126326", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0042916", "출원번호": "10-2020-0126326", "발명의 명칭": "제품 결함 이미지 원격 학습을 통한 비전 검사 시스템", "출원인": "(주)미래융합정보기술", "발명자": "김원태"}}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라, 센서와 LED 조명과 콘트롤러와 연결되고, 머신 비전 영상 분석 SW를 구비한 머신 비전 검사 시스템을구비하며, 제품 ID를 판독하고, 제품의 카메라 영상 데이터의 형상 판단 검사/이물질 검사/스크래치 검사를 제공하는 불량 검사 모듈과 불량 판정 모듈과 학습용 제조용 데이터 전송 모듈을 구비하는 엣지 플랫폼; 상기 엣지 플랫폼과 연결되고 서비스 플랫폼과 연동하는 미들웨어; 상기 엣지 플랫폼과 상기 미들웨어를 통해 연동되며, 불량 판정 제조 지능, 불량 예측 제조 지능을 제공하며,누적되어 저장된 불량 이미지 학습 데이터와 비교하여 비정형 불량 이미지를 검출하고, 제품의 카메라 영상 데이터의 이물질 유무 검사, 형상 검사, 정상/불량 판정 결과 데이터를 제공하는 딥러닝 알고리즘을 사용한 제품결함 이미지 원격 학습을 통한 비전 검사를 제공하는 서비스 플랫폼을 포함하는 제품 결함 이미지 원격 학습을통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제품은 바코드, QR 코드, 또는 13.56MHz RFID 태그 중 어느 하나가 부착되는, 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 추가적으로, PC는 상기 제품에 바코드가 부착된 경우, 제품에 부착된 바코드를 인식하는 바코드 리더기와 인식모듈을 더 포함하는, 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 추가적으로, PC는 상기 제품에 QR 코드가 부착된 경우, 제품에 부착된 QR 코드를 인식하는 QR 코드 인식 모듈을더 포함하는, 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 추가적으로, 상기 제품에 13.56MHz RFID 태그가 부착된 경우, 13.56MHz RFID 리더와 \"제품 코드 전송 미들웨어\"를 통해 연결되는 PC의 SW 모듈을 더 포함하는, 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 미들웨어는 바코드 리더, QR 코드 인식기 또는 13.56MHz RFID 리더에 의해 인식된 제품에 부착된 추출된 모델정보에 해당하는 바코드, QR 코드 또는 13.56MHz RFID 태그 정보 중 어느 하나를 상기 엣지 플랫폼으로부터 상기 서비스 플랫폼으로 전송하는 제품 코드 전송 미들웨어; 및 제품 결함 이미지 원격 학습을 통한 비전 검사 방법에 따라 머신 비전 시스템으로부터 전송된 비정형 불량 가공데이터를 전송받아 딥러닝 모델 훈련 시스템에 의해 누적되어 저장된 불량 이미지 학습 데이터(이물질, 스크래치)와 비교하여 비정형 불량 이미지를 검출하는 비정형 불량 판정 학습 모델을 구비하고, 딥러닝 형상 판단 시스템에 의해 AI 딥러닝 모듈에 의해 카메라 영상 데이터의 이물질 유무 검사, 형상 검사, 정상/불량 판정 결과공개특허 10-2022-0042916-3-데이터를 상기 서비스 플랫폼으로부터 상기 엣지 플랫폼으로 전송하는 딥러닝 미들웨어를 포함하는 제품 결함이미지 원격 학습을 통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 엣지 플랫폼은 불량 검사 모듈(형상 판단 검사, 이물질 검사, 스크래치 검사, 검사 데이터 기준 스펙 정보취합, 검사 예측 분석 화면, 검사 결과 화면, 양품/불량 검사 결과 판정 라벨링 저장 및 전송), 불량 판정 모듈(판정 라벨링, 임계치 분석), 불량 예측 모듈(형상 예측 분석, 이물질 예측 분석, 스크래치 예측 분석, 예측 규칙 상관 계수 모듈), 학습용 제조 데이터 전송 모듈(제조 데이터 저장 및 전송 모듈)을 포함하며, 상기 서비스 플랫폼은 상기 엣지 플랫폼과 불량 판정 제조 지능, 불량 예측 제조 지능, 학습용 제조 데이터를공유하며, 상기 서비스 플랫폼은 딥러닝 후 개발 지능을 제공하는 제조 지능 서비스 모듈을 구비하며, Python 프레임워크상에 Scikit-learn Engine, CNN, RNN, 오디오 인코더, 학습용 제조 데이터를 저장하는 DB 모듈, 커뮤니케이션모듈을 포함하는 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 제품의 카메라 영상 데이터의 머신 비전 영상 분석 SW는 i) 그레이 스케일 영상 처리, 또는 ii) 딥러닝 알고리즘을 사용하며, 카메라 영상의 이미지는 그레이스케일 이미지, RGB 이미지, HSI 이미지, YCbCr, JPEG 이미지, TIFF 이미지, GIF이미지를 적용하며, 상기 딥러닝 알고리즘은 CNN(Convolutional Neural Network), R-CNN(Recurrent Convolutional NeuralNetwork), Fast RCNN, 및 Faster RCNN(Region based Convolutional Neural Network) 알고리즘, YOLO(You OnlyLook Once), SSD(Single Shot Detector) 알고리즘 중 어느 하나의 알고리즘을 사용하여 카메라 영상 데이터의이물질과 스크래치의 결함이 있는 객체들을 검출하여 제품의 불량 여부를 판단하는, 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 머신 비전 영상 분석 SW는 i) 그레이 스케일 영상 처리를 사용하며, 카메라 영상 데이터(RGB 영상)을 그레이 스케일 영상 데이터로 변환하고, 그레이 스케일 영상을 사용하여 버퍼링하여 저장하고, 이미지 프로세싱(image processing) 및 영상 분석 기능을 제공하며, 관심 영역(ROI, Region of Interest)을 그레이 스케일(grayscale)로 변환하며, 관심 영역(ROI)의 외곽선이 추출되는 실험에 의한 특정 임계값(threshold)을 사용하여관심 영역(ROI)의 이미지의 히스토그램(histogram)[x축 영상의 각 픽셀의 화소 값, y축 해당 화소 값의 갯수(빈도수)]을 구하고, 그 관심영역 이미지를 Ostu 알고리즘을 사용하여 임계값을 기준으로 0,1로 이진화(binarization)한 후, 히스토그램 평활화(histogram equalization)를 통해 관심 영역(ROI)의 영상의 전처리를수행하며, sobel edge operator(소벨 엣지 연산자, sobel mask) 또는 canny edge operator(캐니 엣지 연산자)를 사용하여 x 방향의 미분과 y 방향의 미분을 구하고, sobel mask의 가중치를 영상의 화소 값에 곱하고 이들더하는 convolution에 의해 관심 영역 이미지의 엣지(edge, 물체 영역, 배경 영역의 경계에 위치하는 화소들)를검출하고 특정 임계값을 적용하여 생성된 엣지 영상의 결함 객체들의 윤곽선을 검출하고, 형상 특징(ShapeFeatures)을 추출하고,Ostu 알고리즘을 사용한 임계 방법을 사용하는 경우, 화소 값 f(x,y)들이 특정 임계값을 기준으로 입력 영상에대하여 물체 영역과 배경 영역으로 분리하고, 화소 값 f(x,y)이 특정 임계값 보다 클 경우 물체 영역에 속하는화소로 결정하며, 반대로 화소 값 f(x,y)이 특정 임계값 보다 작은 경우 배경 영역에 속하는 화소로 결정하는,제품 결함 이미지 원격 학습을 통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2022-0042916-4-제8항에 있어서, 상기 머신 영상 분석 SW의 딥러닝 알고리즘은 CNN 알고리즘을 사용하며, AlexNet, ZFNet, VGGNet, GoogLeNet,ResNet 중 어느 하나의 알고리즘을 사용하며, 상기 CNN 알고리즘을 사용하여 영상의 특징 추출과 분류하고 학습 모델의 누적된 결함 이미지의 학습 데이터와비교하여 결함이 있는 객체(이물질, 스크래치)를 추출된 이미지를 상기 서비스 플랫폼으로 전송하여 상기 서비스 플랫폼이 제품의 불량 여부를 판단하는, 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 서비스 플랫폼은 딥러닝 기반의 머신비전 플랫폼에서, 센서와 카메라를 사용한 PC의 비전 검사(얼룩,찍힘, 긁힘), 제품 형상 검사(미타발, 변형 불량), Blob 검사(도금 유무 판단)의 AI View를 제공하며,센서는 Trigger Input을 발생하여 카메라로 전송하면, 카메라는 조명 Strobe를 제어하기 위해 Digital Output을발생하여 이미지 센서에서 이미지 데이터를 생성하고 PC로 전송하고,PC는 필요에 따라, 이미지 데이터의 Inspection 검사(얼룩, 찍힘, 긁힘), 제품 형상 검사(미타발, 변형 불량),Blob 검사(도금 유무)를 검사하며, Inspection 검사(얼룩, 찍힘, 긁힘)는 양품 이미지와 불량 이미지를 등록한 후 구분 임계치를 기준으로 실시간으로 이미지의 불량을 판단하고, 제품 형상 검사(미타발, 변형 불량)는 제품의 형상의 모양과 크기를 양품 이미지를 기준으로 제품의 형상 변형유무를 판단하는 Blob 검사(도금 유무)는 정상 도금 영역의 밝기와 불량 도금 영역의 밝기 비교를 통한 마련된 기준으로 도금 유무를 판단하는, 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템."}
{"patent_id": "10-2020-0126326", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제품 결함 이미지 원격 학습을 통한 비전 검사 시스템 및 방법이 개시된다. 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템은 카메라, 센서와 LED 조명과 콘트롤러와 연결되고, 머신 비전 영상 분석 SW를 구비한 머신 비 전 검사 시스템을 구비하며, 제품 ID를 판독하고, 제품의 카메라 영상 데이터의 형상 판단 검사/이물질 검사/스 (뒷면에 계속)"}
{"patent_id": "10-2020-0126326", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝 기반 머신 비전 검사 시스템에 관한 것으로, 보다 상세하게는 카메라 영상 데이터의 형상 판 단 검사/이물질 검사/스크래치 검사를 제공하는 불량 검사 모듈과 불량 판정 모듈과 학습용 제조용 데이터 전송 모듈을 구비하는 엣지 플랫폼과 미들웨어를 통해 연동되는 서비스 플랫폼을 구비하며, 서비스 플랫폼은 불량 판 정 제조 지능, 불량 예측 제조 지능을 제공하며, 학습 데이터에 기초하여 딥러닝 알고리즘을 사용한 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템에 관한 것이다."}
{"patent_id": "10-2020-0126326", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "머신 비전(MV, machine vision)은 로봇, 기계, 비전 시스템의 소프트웨어 기술이 융합된 기술로써 산업체의 공 장 자동화(FA, Factory Automation) 공정에서 wafer, 디스플레이, PCB 검사, LED chip 반도체 패키지 검사 등 의 여러 분야에서 제품 표면 결함 검사, PCB 결함 검사, LED chip package, 기타 제품의 불량을 검출하는데 머 신 비전 검사 시스템을 사용한다. 머신 비전 검사 시스템은 대량으로 생산되는 제품 표면의 결함을 검사하여 제 품의 불량을 검출하는데 사용된다. 머신 비전 검사 시스템은 광학 조명(LED 또는 할로겐 조명), 고해상도 카메라, 카메라 인터페이스 장비[Frame Grabber, Gigabit Ethernet(GigE), IEEE 1394, camera link, USB 3.0], 산업용 PC의 I/O와 모션 제어(motion control)를 담당하는 비전 영상처리 보드, 비전 영상 처리 소프트웨어를 구비한다. PC 기반의 머신 비전 검사 시스템은 광학 조명(LED 또는 할로겐 조명), 카메라, 카메라 인터페이스[Frame Grabber, Gigabit Ethernet(GigE), IEEE 1394, 카메라 링크, USB 3.0], 컴퓨터에 탑재된 비전 영상처리 보드가 구비된 비전 검사 시스템, 제품 표면 이미지의 검사(inspection)를 위한 비전 검사 영상처리 SW에 의해 이미지 프로세싱(image processing)를 통해 제품 표면의 이물질, 스크래치, 패턴 오류를 검출한다. 비전 검사 영상처리 SW는 이미지 획득(frame grabbing)/이미지 처리(imgae processing)/특징 추출(feature extraction)/결함 검출과 제어 기능을 제공하며, 카메라와 연동된 컴퓨터의 비전 검사 시스템은 실시간으로 제품 표면 결함을 검사하여 영상 처리(image processing)와 결함 검출 알고리즘을 가진 소프트웨어에 의해 정상 이미지와 검사 이미지의 특징값을 비교하여 이물질, 스크래치, 패턴 오류, 찍힘성 결함과 결함 위치를 측정하여 제품 불량을 검출한다. □ 비전 검사 시스템의 기능 1) 디스플레이 패널 및 반도체 샘플/제품 정밀 촬영(비전 검사) 2) 결함 검출 및 양불 판정 Review 3) 광학 카메라 및 조명 제어 4) 검사 스테이지 유닛 이송 제어 5) 비상 상황 시 알람 발생 기능 카메라와 PC를 연결하는 카메라 인터페이스는 프레임 그래버(Frame Grabber), Gigabit Ethernet(GigE), IEEE 1394a, IEEE 1394b, camera link, USB 3.0를 사용한다. 표 1은 머신 비전 카메라 인터페이스를 나타낸다. 비전 검사 시스템은 기존 Frame Grabber를 사용하거나, 또는 ㎛ 단위 고해상도 정밀 측정과 대용량 데이터를 고 속으로 처리하기 위해 기가비트 이더넷(GigE), CoaXpres 등의 카메라 인터페이스를 사용하여 영상처리를 한다. 표 1 구분 Gigabit Ethernet(GigE) IEEE 1394a IEEE 1394b camera link 케이블 길이100m 4.5m(리피터를 사용하는 경우 72m까지 가능)4.5m(리피터를 사용하 는 경우 72m까지 가능)최대 15m 대역폭100 Mb/s 32 Mbytes/s 64 Mbytes/s 255Mbytes/s(base configuration) 680Mbytes/s(full configuration) Bit rate1000 Mb/s 400 Mb/s 800 Mb/s > 2000 Mb/s 표준GigE Vision StandardIEEE 1394 Trade Association DCAM StandardIEEE 1394 Trade Association DCAM StandardAIA 카메라 링크 표준 인터페이스 보 드기가비트 이더넷 보드IEEE 1394a 보드 특별한 프레임 그래버 카메라 최대수제한 없음 16대 (DCAM) 16대 (DCAM) 프레임 그래버당 2대 케이블 Industrial and consumerIndustrial and consumerIndustrial and consumerIndustrial 도 1은 엔코더를 구비한 컨베이어 벨트 생산 라인에서 센서와 ID 리더기와 카메라와 광학 조명을 구비하는 비전 검사 시스템 구성도이다. 멀티 광학 모듈 비전 검사 시스템은 외면 케이스가 하우징되는 기구부, 상기 기구부의 정면에는 키보드 마우스를 구비하는 컴퓨터와 모니터를 구비 하며, 고정된 지지대에 line scan 카메라 또는 area scan 카메라를 구성하는 고해상도 멀티 카메라가 구비된 카 메라부와, 카메라부 하단에 설치된 광학 조명부와, 카메라부와 광학조명부 하단에 위치되며 피검사체가 XY-스테 이지에 놓이는 검사 스테이지와, 상기 검사 스테이지가 놓이는 베이스와, 베이스 밑에 진동 저감 Air Cylinder 구조의 방진 설비, 비전 검사 장비 좌우를 지지하는 프레임, XYZ 위치 이동을 제어하는 스테이지 유닛 이송 모 듈을 포함하며, 상기 카메라부는 고정된 지지대에 라인 스캔 카메라 또는 에어리어 스캔 카메라를 구성하는 멀티 카메라가 카메 라 인터페이스를 통해 각각 하나의 카메라가 각각 하나의 PC에 연결되고, 각각의 PC는 네트워크 허브를 통해 LAN과 TCP/IP를 통해 메인 서버 컴퓨터에 연결되며, 상기 메인 서버 컴퓨터는 네트워크 허브를 통해 LAN과 TCP/IP를 통해 엔코더/분배기와 연결되며, 상기 엔코더/분배기는 라인 스캔 카메라 또는 에어리어 스캔 카메라를 구성하는 멀티 카메라에 연결되며, 상기 카메라부는 라인 스캔 카메라 또는 에어리어 스캔 카메라를 구성하는 멀티 카메라들을 구비하며, 각각의 카메라는 제품 표면 결함의 정밀 측정을 위해 일반 CCD 카메라보다 100배 정도 향상된 고해상도 10~100㎛(pixel size)의 정밀 측정이 가능한 TDI 카메라를 사용하며, 상기 방진 설비는 10~100㎛ pixel size의 정밀 측정을 위한 라인 스캔 또는 에어리어 카메라를 사용한 비전 검 사 시스템의 정밀 측정시 진동을 저감시키기 위해 상기 베이스 밑에 격자보 하단의 Air Cylinder 구조를 이용한 방진 시스템을 사용하였으며, 즉, 석정반과 Isolator를 설치하여 외부 진동에 대한 차단 및 내부 진동을 방지한 다. 1) ID 리더기(제품에 부착된 DPM 코드, 또는 1D 또는 2D 코드 판독): 공장 자동화 공정에서 생산 라인의 컨베이 어 벨트로 이송된 검사 대상체, 또는 검사 대상체 이송 로봇의 로더(loader)에 의해 검사 스테이지(XY 스테이지)의 놓인 제품의 ID를 판독하여 컴퓨터로 검출된 제품ID를 전송한다. 2) 광학 조명(illumination): 비전 검사 시스템에서 광학 조명은 흰색 또는 적색 LED 조명, 또는 광섬유 가이드 를 가지는 할로겐 조명 사용하며, 본 발명의 실시예에서는 LED를 사용하였다. LED 조명을 사용하는 경우, 일렬로 배열된 white LED와 조명 콘트롤러, 또는 카메라 렌즈 주위를 둘러싼 많은 LED들로 구성된 링 LED와 조명 콘트롤러 사용한다. 3) 카메라 Line Scan 카메라 또는 Area Scan 카메라는 멀티 카메라들을 구비하며, 각각의 카메라는 제품 표면 결함의 정밀 측정을 위해 일반 CCD 카메라보다 100배 정도 향상된 고해상도 10~20㎛ 단위까지 정밀 측정이 가능한 TDI camera를 사용한다. 10~20㎛ 단위까지 카메라의 정밀 측정이 요구되지 않는 경우, TDI 카메라 보다 해상도가 낮은 CCD 카메라, 또는 CMOS 이미지 센서(CMOS Image Sensor, CIS)가 사용된다. 4) 엔코더(Encoder) 산업체의 공장 자동화 공정에서 컴퓨터와 연결된 스텝 모터 드라이버(Step Motor Driver)와 스텝 모터(Step Motor, 서보 모터)의 구동에 의해 동작되는 컨베이어 벨트 시스템 위에서 지지대에 고정된 상태에서 광학 조명 과 고해상도 멀티 카메라를 구비하는 Line scan 카메라 또는 Area scan 카메라가 설치된 상황에서, 엔코더(Encoder)는 공장의 생산 라인에서 컨베이어 벨트(conveyor belt)를 동작시키는 경우, 서보 모터의 정확 한 이송량을 측정한다. 상기 기구부는 로더(loader)에 의해 검사 스테이지(XY 스테이지)의 놓는 피검사체 이송 로봇을 더 포함한다. 상기 기구부는 공장 자동화 공정에서 생산 라인의 컨베이어 벨트로 이송된 피검사체, 또는 피검사체 이송 로봇 의 로더(loader)에 의해 검사 스테이지(XY 스테이지)의 놓인 제품의 ID를 제품에 부착된 DPM 코드, 또는 바코드 또는 QR 코드를 판독하여 컴퓨터로 검출된 제품ID를 전송하는 ID 리더기를 더 포함할 수 있다. 상기 스테이지 유닛 이송 모듈은 리니어 모터에 의해 X축 방향으로 라인 스캔 카메라가 이동하고, 리니어 모터 에 의해 Y축 방향으로 검사 스테이지의 위치 이동, Z1, Z2, Z3축 상하 방향으로 카메라부가 이동된다. 상기 리니어 모터는 제어 컴퓨터에 연동된 모터 구동부에 의해 작동되며, 모터의 속도와 이동 위치를 제어하기 위해 PID 제어를 사용한다. 상기 방진 설비는 10~100㎛ pixel size의 정밀 측정을 위한 Line Scan 또는 Area scan 카메라를 사용한 비전 검사 시스템의 정밀 측정시 진동을 저감시키기 위해 상기 베이스 밑에 격자보 하단의 Air Cylinder 구조를 이용 한 방진 시스템을 사용하였으며, 즉, 석정반과 Isolator를 설치하여 외부 진동에 대한 차단 및 내부 진동을 방 지하는 것을 특징으로 한다. 머신 비전은 기구부와 라인 스캔 카메라 또는 에어리어 스캔 카메라와 연동된 카메라 인터페이스(Frame Grabber, Gigabit Ethernet(GigE), IEEE 1394a, IEEE 1394b, 카메라 링크, USB 3.0)를 통해 연결된 컴퓨터의 비전 검사용 영상처리 알고리즘이 영상 처리(image processing)[ 영상 획득, 영상 이진화, 영상 처 리, 영상 분석, 영상 해석]를 통해 제품 표면의 디스플레이의 이물, 스크래치, 패턴 오류 등의 결함과결함의 위치를 분석하여 제품의 불량을 걸러낸다 예를 들면, TFT-LCD 패널의 표면 결함 검사 시에, Line Scan 카메라를 사용하여 획득된 영상이 카메라 인터페이 스를 통해 산업용 PC에서 획득된 TFT-LCD의 이미지는 대용량이기 때문에 생산 공정에서 적용하기 위해 빠른 영 상 처리 시간이 요구된다. TFT-LCD 영상은 반복되는 패턴을 갖고 있기 인접 패턴과의 영상차를 이용하여 쉽게 LCD 불량 영역이 검출된다. 이와 관련된 선행기술2로써, 특허 공개번호 10-2019-0063839에서는 \"제조 공정에서 딥러닝을 활용한 머신 비전 기반 품질검사 방법 및 시스템\"이 제공된다. 도 2는 종래의 딥러닝 기반 분류기 생성 과정의 동작 흐름도이다. 제조 공정에서 딥러닝을 활용한 머신 비전 기반 품질 검사 방법은, 학습용 제품 영상을 생성하는 단계; 생성된 학습용 제품 영상으로 양품과 불량품을 구분하기 위한 분류기를 학습시키는 단계; 및 학습된 분류기를 이용하여. 제품을 양품 또는 불량품으로 판정하는 단계를 포함한다. 이에 따라, 학습에 의해 판별 대상의 데이 터의 특징값을 스스로 찾을 수 있고, 결함의 정형화가 어려워 수동 검사에 의존하는 검사 영역에 대해서도 머신 비전 기반 검사가 가능해진다. 품질 검사를 통해 제품을 양품 또는 불량으로 판정하기 위해, 먼저, 검사 카메라의 위치를 정렬하여 검사 대상 제품을 카메라로 촬영하고, 카메라 촬영을 통해 생성된 영상에서 관심 영역을 추출하여 저장한다. 관심 영역의 대상 이미지를 학습 모델 생성의 이미지 전처리 과정에서와 같이, 일정 규격의 사이즈의 작은 이미지로 중첩되 도록 자른다(cropping). 다음, 품질 검사 장치는, 각각의 조각 이미지 각각에 대해 분류기를 이용하여 검사를 수행한다. 이때, 심층신경 망 알고리즘은 분류 결과로 학습을 통해 분류기를 생성할 때 사용된 학습 데이터들 중 가장 근접한 이미지의 분 류 번호와 확률 값을 결과로 출력한다. 이에, 각각의 조각된 이미지를 딥러닝 기반 분류기를 통해, 해당 인덱스 에서 가장 높은 확률로 분류표가 양품인지 결함인지 확인하여, 판정 결과값을 표시한다. 이때, 결함 제품인 경 우 결함으로 판명하고 결함 영역을 표시하여 준다. 이와 관련된 선행기술3로써, 특허등록번호 10-11827680000에서는 \"머신비전 시스템을 위한 검사 장치 및 방법\" 이 등록되어 있다. 머신비전 시스템을 위한 검사 장치는 내부를 조명하는 하나 이상의 조명들을 구비하며 일정 형상을 갖는 거치 대; 카메라 기능을 가지며, 상기 거치대의 내부에 위치한 검사 객체를 상기 거치대에 고정된 채 촬영 가능한 휴 대용 단말기; 및 상기 휴대용 단말기의 지시에 따라 상기 휴대용 단말기의 촬영 조건을 설정하고, 설정된 촬영 조건에 따라 상기 조명들을 제어하는 제어부를 포함한다. 이와 관련된 선행기술4로써, 특허등록번호 10-1688641에서는 \"머신 비전 기반 전자부품 검사 시스템\"이 등록되 어 있다. 머신 비전 기반 전자부품 검사 시스템은, 품질검사를 위해 다수로 공급된 다종의 전자부품이 미정렬 안착되어 자동선별되도록 마련된 선별플레이트가 내부에 구비된 하우징, 상기 선별플레이트의 상부에서 설정된 거리로 위 치 이동가능하게 설치된 위치이동장치, 상기 위치이동장치에 설치되어 상기 선별플레이트상에 랜덤하게 배치된 상기 전자부품을 촬영하는 카메라장치, 상기 하우징에 설치되어 상기 카메라장치로부터 촬영된 영상정보를 기반 으로 상기 전자부품 각각의 위치 및 각도를 산출하는 분석 장치, 상기 위치이동장치에 설치되어 상기 분석장치 로부터 판별된 상기 전자부품의 위치 및 각도 등의 산출값을 기반으로 상기 선별플레이트에 랜덤 배치된 상기 전자부품을 흡착시켜 상기 선별플레이트상의 지정된 위치로 순차이동시키는 그리퍼장치, 상기 그리퍼장치에 의 해 이동되어 정렬고정된 상기 전자부품을 각 대상에 따른 용량에 맞춰 상기 품질검사를 수행하도록 상기 위치이 동장치에 설치된 검사장치 및, 상기 위치이동장치, 상기 카메라장치, 상기 분석장치, 상기 그리퍼장치 및 상기 검사장치의 작동을 제어하는 제어장치를 포함하여 이루어지되, 상기 그리퍼장치는 상기 전자부품을 개별적으로 흡착시킨 상태에서 회전되도록 하는 회전장치가 구비되고, 상기 회전장치는 상기 그리퍼장치에 흡착된 상기 전 자부품의 각각을 상기 분석장치의 상기 산출값을 토대로 회전시켜 상기 선별플레이트에 랜덤 배치된 각각의 상 기 전자부품이 상기 검사장치에서 정방향 위치되어 상기 품질검사가 수행되도록 한다. 이와 관련된 선행기술5로써, 특허등록번호 10-21089560000에서는 \"인공지능을 활용한 머신비전 모듈형 소프트웨 어를 갖는 머신비전 검사장치 및 그 장치의 구동방법, 그리고 컴퓨터 판독가능 기록매체\"가 등록되어 있다. 인공지능을 활용한 머신비전 모듈형 소프트웨어를 갖는 머신비전 검사장치 및 그 장치의 구동방법, 그리고 컴퓨 터 판독가능 기록매체에 관한 것으로, 발명의 실시예에 따른 인공지능을 활용한 머신비전 모듈형 소프트웨어를 갖는 머신비전 검사장치는, 지정 제품과 관련한 복수의 검사 항목에 대한 제1 볼륨의 학습 샘플 데이터를 인공 지능 기반의 비전 검사를 위해 사용자마다 다르게 저장하는 저장부, 및 다르게 저장한 제1 볼륨의 학습 샘플 데 이터 및 생산 라인의 촬영장치에서 제공하는 촬영영상을 근거로 검사 항목별로 인공지능 기반의 딥러닝을 수행 하여 지정 제품의 비전 검사를 수행하며, 비전 검사의 결과를 근거로 제1 볼륨에서 제2 볼륨으로 학습 샘플 데 이터를 확장시키는 제어부를 포함할 수 있다. 이와 관련된 선행기술6로써, 특허공개번호 10-2019-0063839에서는 \"제조 공정에서 딥러닝을 활용한 머신 비전 기반 품질검사 방법 및 시스템\"이 공개되어 있다. 제조 공정에서 딥러닝을 활용한 머신 비전 기반 품질검사 방법 및 시스템이 제공된다. 본 발명의 실시예에 따른 품질 검사 방법은, 학습용 제품 영상을 생성하고, 생성된 학습용 제품 영상으로 양품과 불량품을 구분하기 위한 분류기를 학습시키며, 학습된 분류기를 이용하여 제품을 양품 또는 불량품으로 판정한다. 이에 의해, 학습에 의 해 판별 대상의 데이터의 특징값을 스스로 찾을 수 있어, 결함의 정형화가 어려워 수동 검사에 의존하는 검사 영역에 대해서도 머신 비전 기반 검사가 가능해진다. 이와 관련된 선행기술7로써, 특허공개번호 10-2019-0067439에서는 \"딥러닝 기반의 반도체 비전 검사 시스템에서 의 제어 변수 설정 장치 및 방법\"이 공개되어 있다. 딥러닝 기반의 반도체 비전 검사 시스템에서의 제어 변수 설정 장치의 동작방법에 있어서, 영상 획득 장치의 동 작을 제어하는 복수의 제어 변수들에 대한 정보를 수신하는 단계, 수신된 복수의 제어 변수들에 대한 정보에 포 함된 복수의 제어 변수들의 개수 및 복수의 제어 변수들 각각의 변수 값의 개수를 이용하여 제어 변수 집합을 구성하는 단계, 적어도 하나 이상의 비전 검사 샘플에 대해, 구성된 제어 변수 집합의 구성 원소 각각에 대응되 는 복수의 제어 변수들의 변수 값들이 각각 반영된 영상 획득 장치에 의해 획득된 이미지들을 수신하는 단계, 및 이미 학습된 딥러닝 기반의 신경망을 이용하여 수신된 이미지들 중 최종 이미지를 결정하고, 결정된 최종 이 미지를 획득하기 위한 복수의 제어 변수들 각각의 최종 변수 값들을 획득하는 단계를 포함하고, 구성된 제어 변 수 집합의 구성 원소 각각은 복수의 제어 변수들을 모두 포함하고, 구성된 제어 변수 집합의 서로 다른 임의의 2개의 구성 원소들은 적어도 하나 이상 동일한 제어 변수들간에 다른 변수 값들을 가지도록 대응시킨 것을 특징 으로 하는, 제어 변수 설정 장치의 동작방법이 개시된다. 기업은 스마트 공장(Smart Factory)이 전혀 구축되지 않은 초기 단계에서, 제조 산업 분야에서 원자재 입고, 제 품 수/발주, 생산 계획, 생산 지시, 작업 상황, LOT 관리, 공정 관리, 품질 관리, 입고/출고/재고 관리, 판매 실적 관리 등은 현장에서 완전 수작업으로 재고 공정 프로세스의 정보들을 전산화하기가 쉽지 않다. 스마트 팩토리는 제조 실행 시스템(MES, Manufacturing Execution System)과 비전 검사 시스템, 품질관리 시스 템(QMS, Quality Management System)이 결합되어 구축되고, 제품에 바코드 마킹 과정이 존재하며, 비전 검사 시 스템은 제조 공정에 따라 생산 라인이 머신 비전 시스템이 비정정형 데이터로 생성되는 제품의 결함을 검출하여 불량을 걸러낸다. 그러나, 비전 검사 시스템은 실시간으로 카메라의 영상을 통해 비정형 패턴의 결함과 금속 표 면의 난반사, 진동에 의해 비전 인식 오류가 발생된다. MES(제조 실행 시스템, Manufacturing Execution System)는 제조 공정상의 실시간 카메라 비전검사 모니터링, 제어, 물류 및 작업내역 추적 관리, 양불 상태 파악, 불량 관리에 초점을 맞춘 그러나, 기존의 머신비전 불량 검출 시스템은 제조 공정과 제품 생산 라인에 컨베이어 벨트와 인코더, 카메라와 비전 시스템을 설치하기에 고가의 설치 비용이 들고, 이미 머신비전(MV)을 도입한 기업 입장에서는 다시 딥러닝 비전 시스템 설치시에 중복 투자가 될 수 있다. 또한, 스마트 팩토리를 구축하는 제조 공정과 생산 라인와 머신 러닝 비전 시스템을 갖춘 대기업 이외에 중소 기업은 현실적으로 생산 라인에 1억이 넘는 컨베이어 벨트와 딥러 닝 비전 시스템 구축이 어렵고, 많은 비용이 드는 인공 지능 프로그래밍을 사용한 딥러닝 비전 검사 시스템을 도입하기 어려운게 현실이다. 선행기술문헌 특허문헌 (특허문헌 0001) 특허등록번호 10-1772673 (등록일자 2017년 08월 23일), \"멀티 광학 모듈 비전 검사 시스템\", 주식회사 에이피에스 (특허문헌 0002) 특허공개번호 10-2019-0063839 (공개일자 2019년 06월 10일), \"제조 공정에서 딥러닝을 활용한 머신 비전 기반 품질검사 방법 및 시스템\", 전자부품연구원 (특허문헌 0003) 특허등록번호 10-11827680000 (등록일자 2012년 09월 07일), \"머신비전 시스템을 위한 검사 장 치 및 방법\", 주식회사 엠비젼 (특허문헌 0004) 특허등록번호 10-1688641 (등록일자 2016년 12월 15일), \"머신 비전 기반 전자부품 검사 시스 템\", 동서대학교산학협력단, (주)케이엠시스 (특허문헌 0005) 특허등록번호 10-21089560000 (등록일자 2020년 05월 04일), \"인공지능을 활용한 머신비전 모 듈형 소프트웨어를 갖는 머신비전 검사장치 및 그 장치의 구동방법, 그리고 컴퓨터 판독가능 기록매체\", 주식회 사 만컴퍼니 (특허문헌 0006) 특허공개번호 10-2019-0063839 (공개일자 2019년 06월 10일), \"제조 공정에서 딥러닝을 활용한 머신 비전 기반 품질검사 방법 및 시스템\", 한국전자기술연구원 (특허문헌 0007) 특허공개번호 10-2019-0067439 (공개일자 2019년 06월 17일), \"딥러닝 기반의 반도체 비전 검 사 시스템에서의 제어 변수 설정 장치 및 방법\", 한국전자통신연구원"}
{"patent_id": "10-2020-0126326", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기 문제점을 해결하기 위한 본 발명의 목적은 카메라 영상 데이터의 형상 판단 검사/이물질 검사/스크래치 검 사를 제공하는 불량 검사 모듈과 불량 판정 모듈과 학습용 제조용 데이터 전송 모듈을 구비하는 엣지 플랫폼과 미들웨어를 통해 연동되는 서비스 플랫폼을 구비하며, 서비스 플랫폼은 불량 판정 제조 지능, 불량 예측 제조 지능을 제공하며, 학습 데이터에 기초하여 딥러닝 알고리즘을 사용한 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템을 제공한다."}
{"patent_id": "10-2020-0126326", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 목적을 달성하기 위해, 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템은 카메라, 센서와 LED 조명과 콘트롤러와 연결되고, 머신 비전 영상 분석 SW를 구비한 머신 비전 검사 시스템을 구비하며, 제품 ID를 판독하고 제품의 카메라 영상 데이터의 형상 판단 검사/이물질 검사/스크래치 검사를 제공하는 불량 검사 모듈 과 불량 판정 모듈과 학습용 제조용 데이터 전송 모듈을 구비하는 엣지 플랫폼; 상기 엣지 플랫폼과 연결되고 서비스 플랫폼과 연동하는 미들웨어; 및 상기 엣지 플랫폼과 상기 미들웨어를 통해 연동되며, 불량 판정 제조 지능, 불량 예측 제조 지능을 제공하며, 누적되어 저장된 불량 이미지 학습 데이터와 비교하여 비정형 불량 이 미지를 검출하고, 제품의 카메라 영상 데이터의 이물질 유무 검사, 형상 검사, 정상/불량 판정 결과 데이터를 제공하는 딥러닝 알고리즘을 사용한 제품 결함 이미지 원격 학습을 통한 비전 검사를 제공하는 서비스 플랫폼을 포함한다."}
{"patent_id": "10-2020-0126326", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템은 카메라 영상 데이터의 형상 판단 검사/이물 질 검사/스크래치 검사를 제공하는 불량 검사 모듈과 불량 판정 모듈과 학습용 제조용 데이터 전송 모듈을 구비 하는 엣지 플랫폼과 미들웨어를 통해 연동되는 서비스 플랫폼을 구비하며, 서비스 플랫폼은 불량 판정 제조 지 능, 불량 예측 제조 지능을 제공하며, 학습 데이터에 기초하여 딥러닝 알고리즘을 사용한 제품 결함 이미지 원 격 학습을 통한 비전 검사를 제공한다. 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템은 컨베이어 벨트와 머신 비전 시스템이 구비된 스마트 팩 토리를 구축하기 어려운 중소 기업들이 상대적으로 적은 비용으로 인공 지능 프로그래밍을 사용한 딥러닝 비전 검사 시스템을 구축하여 제품 결함을 포함하는 학습 데이터를 기초로 딥러닝 비전 시스템에 의해 제품의 결함 (이물질, 스크래치 등)을 판단하고 제품의 불량 여부를 판단하게 되었다. 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법은 머신비전 기반 PCB 불량판정 및 불량예측을 지원하는 머신 비전 기반 PCB 제조 지능과, Pan Valve 및 Dual Check Valve의 불량을 판정할 수 있는 Valve 제조지능(머신비전 기반 PCB 제조 지능, 머신비전 기반 Valve 제조 지능)을 제공한다. 머신비전 기반 PCB 제조 지능은 미삽, 오삽 등의 불량을 검출할때 아래쪽의 컨덴서에 가려서 머신비전에서 잘못 찾는 경우에 딥러닝을 사용하여 제대로 찾을 수 있도록 지능형 머신비전을 제공한다. 머신비전 기반 Valve 제조 지능은 머신비전에서 스크래치 불량검출을 하기 위해 카메라를 추가로 설치하고 수차 례 나눠 여러장을 촬영해야 하지만, 한번 촬영한 전체 이미지를 딥러닝을 통해 스크래치 불량을 검출함으로서 검사 시간과 비용을 줄이게 되었다."}
{"patent_id": "10-2020-0126326", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부된 도면을 참조하여 발명의 구성 및 동작을 상세하게 설명한다. 본 발 명의 설명에 있어서 관련된 공지의 기능 또는 공지의 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하 게 흐릴 수 있다고 판단되는 경우 그 자세한 설명을 생략한다. 또한, 첨부된 도면 번호는 동일한 구성을 표기할 때에 다른 도면에서 동일한 도면번호를 부여한다. 본 발명의 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템 및 방법은 제품 ID를 판독하고 카메라 영상 데 이터의 형상 판단 검사/이물질 검사/스크래치 검사를 제공하는 불량 검사 모듈과 불량 판정 모듈과 학습용 제조 용 데이터 전송 모듈을 구비하는 엣지 플랫폼과 미들웨어를 통해 연동되는 서비스 플랫폼을 구비하며, 서비스 플랫폼은 불량 판정 제조 지능, 불량 예측 제조 지능을 제공하며, 학습 데이터에 기초하여 딥러닝 알고리즘을 사용한다. 도 3a, 3b는 PC와 연결되는 카메라와 조명과 콘트롤러를 구비하며, 제품의 결함(이물질, 스크래치 등)을 검출하 여 제품의 불량을 판단하는 수동 비전 검사기, 주요 기능을 나타낸 도면이다. * 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템의 특징 1) 딥러닝 비전검사 기능을 모듈화 하여 기존 머신비전 검사시스템과 연동하여 검사 능력을 고도화할 수 있다. 2) 머신비전 검사 시스템에서 취득한 테스트용 이미지와 참조용 판정 결과를 이용하여 딥러닝용 데이터 구축을 간편하게 지원한다. * 주요기능 1. 머신비전 불량 검출 시스템 : 기존 머신비전 장비가 있는 경우 딥러닝 비전 불량 검출 모듈만 도입 가능하다. 2. 머신비전 인터페이스 : 기존 머신비전으로부터 테스트 시료 이미지와 참조용 판정 결과를 받는다. 3. 딥러닝 학습 : 전달받은 이미지와 참조용 판정 결과로 딥러닝 학습 진행 4. 딥러닝 판정 : 불량검출 대상 시료 이미지에 대하여 2에서 만들어진 학습 모델로 판정 진행 5. 딥러닝 재학습 : 현장 작업자는 3의 판정 결과를 보고 최종 판정을 하며, 이 결과는 딥러닝 학습 자료로 재 사용된다. 6. 2~6의 단계가 충분히 진행이 되면 딥러닝 비젂검사의 판정 정확도가 높아저 사용자의 별도 판정이 필요없게 된다. 도 4는 본 발명에 따른 딥러닝 알고리즘을 사용한 제품 결함 이미지 원격 학습을 사용한 머신비전 제조지능 플 랫폼을 나타낸 도면이다. 기존에 보유한 머신비전 검사장비를 Hybrid 형태로 지능화하여 새로운 제품 및 예외적인 불량 유형의 발생에 신 속하게 대처할 수 있는 딥러닝 머신비전 플랫폼을 지원한다. 이를 통해 도입 기업은 스마트 팩토리 운영 연속성 을 확보할 수 있다. 1. 기업에 기 도입된 머신비전 검사장비의 지능화를 지원하는 AI 솔루션을 탑재하여 제조지능 엣지 플랫폼(Edge Platform)을 공급한다. 2. 도입기업의 머신비전 검사 데이터(제품의 카메라 영상 데이터)에 예외적인 불량유형이 발생하거나 새로운 제 품을 검사해야 할 경우, 서비스 플랫폼(Service Platform)에서 딥러닝 후 고도화 된 제조지능을 엣지 플랫폼 (Edge Platform)으로 공급한다. 3. 서비스 플랫폼(Service Platform)에서 유사 업종별 공동의 제조 데이터 학습을 통해 머신비전 제조 지능을 고도화하여 기존의 엣지 플랫폼(Edge Platform)의 지능을 향상시킬 수 있도록 지속적인 고객 관리 서비스를 제 공한다. 4. 선진화된 도입 기업의 제조지능 또는 학습데이터를 수익 쉐어 기반으로 활용하여 신규 딥러닝 플랫폼 구축기 간을 단축한다. 본 발명의 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템은 제품 ID를 판독하고 카메라 영상 데이터의 형상 판단 검사/이물질 검사/스크래치 검사를 제공하는 불량 검사 모듈과 불량 판정 모듈과 학습용 제조용 데이 터 전송 모듈을 구비하는 엣지 플랫폼과 미들웨어를 통해 연동되는 서비스 플랫폼을 구비하며, 서비스 플랫폼은 불량 판정 제조 지능, 불량 예측 제조 지능을 제공하며, 학습 데이터에 기초하여 딥러닝 알고리즘을 사용한다. 상기 제품은 바코드, QR 코드, 또는 13.56MHz RFID 태그 중 어느 하나가 부착된다. 추가적으로, PC는 상기 제품에 바코드가 부착된 경우, 제품에 부착된 바코드를 인식하는 바코드 리더기와 인식 모듈을 더 포함한다. 추가적으로, PC는 상기 제품에 QR 코드가 부착된 경우, 제품에 부착된 QR 코드를 인식하는 QR 코드 인식 모듈을 더 포함한다. 추가적으로, 상기 제품에 13.56MHz RFID 태그가 부착된 경우, 13.56MHz RFID 리더와 \"제품 코드 전송 미들웨 어\"를 통해 연결되는 PC의 SW 모듈을 더 포함한다. 제품 결함 이미지 원격 학습을 통한 비전 검사 시스템은 카메라, 센서와 LED 조명과 콘트롤러와 연결되고, 머신 비전 영상 분석 SW를 구비한 머신 비전 검사 시스템을 구비하며, 머신 비전 검사 시스템의 컴퓨터(PC)에 연결된 인식기(바코드 리더, QR 코드 인식기 또는 13.56MHz RFID 리더)가 제품 ID(바코드, QR 코드, 13.56MHz RFID 태그)를 판독하고, 제품의 카메라 영상 데이터의 형상 판단 검사/이물질 검사/스크래치 검사를 제공하는 불량 검 사 모듈과 불량 판정 모듈과 학습용 제조용 데이터 전송 모듈을 구비하는 엣지 플랫폼; 상기 엣지 플랫폼과 연 결되고 서비스 플랫폼과 연동하는 미들웨어; 및 상기 엣지 플랫폼과 상기 미들웨어를 통해 연동되며, 불량 판정 제조 지능, 불량 예측 제조 지능을 제공하며, 누적되어 저장된 불량 이미지 학습 데이터(이물질 또는 스크래치 가 포함된 불량의 이미지의 훈련 data set)와 비교하여 비정형 불량 이미지를 검출하고, 제품의 카메라 영상 데 이터의 이물질 유무 검사, 형상 검사, 정상/불량 판정 결과 데이터를 제공하는 AI 딥러닝 알고리즘을 사용한 제 품 결함 이미지 원격 학습을 통한 비전 검사를 제공하는 서비스 플랫폼을 포함한다. 엣지 플랫폼은 불량 검사 모듈(형상 판단 검사, 이물질 검사, 스크래치 검사, 검사 데이터 기준 스펙 정보 취합, 검사 예측 분석 화면, 검사 결과 화면, 양품/불량 검사 결과 판정 라벨링 저장 및 전송), 불량 판정 모듈 (판정 라벨링, 임계치 분석), 불량 예측 모듈(형상 예측 분석, 이물질 예측 분석, 스크래치 예측 분석, 예측 규 칙 상관 계수 모듈), 학습용 제조 데이터 전송 모듈(제조 데이터 저장 및 전송 모듈)을 포함한다. 서비스 플랫폼은 상기 엣지 플랫폼과 불량 판정 제조 지능, 불량 예측 제조 지능, 학습용 제조 데이터를 공유하 며, 서비스 플랫폼은 딥러닝 후 개발 지능을 제공하는 제조 지능 서비스 모듈을 구비하며, Python 프레임워크 상에 Scikit-learn Engine, CNN, RNN, 오디오 인코더, 학습용 제조 데이터를 저장하는 DB 모듈, 커뮤니케이션 모듈을 포함한다. 상기 미들웨어는 바코드 리더, QR 코드 인식기 또는 13.56MHz RFID 리더에 의해 인식된 제품에 부착된 추출된 모델정보에 해당하 는 바코드, QR 코드 또는 13.56MHz RFID 태그 정보 중 어느 하나를 상기 엣지 플랫폼으로부터 상기 서비스 플랫 폼으로 전송하는 제품 코드 전송 미들웨어; 및 제품 결함 이미지 원격 학습을 통한 비전 검사 방법에 따라 머신 비전 시스템으로부터 전송된 비정형 불량 가공 데이터를 전송받아 딥러닝 모델 훈련 시스템에 의해 누적되어 저장된 불량 이미지 학습 데이터(이물질, 스크래 치)와 비교하여 비정형 불량 이미지를 검출하는 비정형 불량 판정 학습 모델을 구비하고, 딥러닝 형상 판단 시 스템에 의해 AI 딥러닝 모듈에 의해 카메라 영상 데이터의 이물질 유무 검사, 형상 검사, 정상/불량 판정 결과 데이터를 상기 서비스 플랫폼으로부터 상기 엣지 플랫폼으로 전송하는 딥러닝 미들웨어를 포함한다. 딥러닝 툴은 Tensorflow, Keras, Caffe, PyTorch 중 어느 하나를 사용할 수 있다. 카메라부와 광학조명부 하단에 위치되며 피검사체가 XY-스테이지에 놓이는 검사 스테이지와, 상기 검사 스테이 지가 놓이는 베이스와, 비전 검사 장비를 지지하는 프레임, XYZ 위치 이동을 제어하는 스테이지 유닛 이송 모듈 을 더 포함하며, 카메라가 카메라 인터페이스를 통해 PC에 연결되고, PC는 네트워크 허브를 통해 LAN과 TCP/IP를 통해 메인 서버 컴퓨터에 연결된다. 참고로, 카메라 영상 데이터의 영상 분석 SW는 i) 그레이 스케일 영상 처리, 또는 ii) 딥러닝 알고리즘을 사용 할 수 있다. 카메라 영상의 이미지는 그레이스케일 이미지, RGB 이미지, HSI 이미지, YCbCr, JPEG 이미지, TIFF 이미지, GIF 이미지 등이 적용가능하다. 실시예에서는 그레이스케일(grayscale) 이미지를 사용하였다. i) 그레이 스케일 영상 처리 영상 분석 SW는 카메라 영상 데이터(RGB 영상)을 그레이 스케일 영상 데이터로 변환하고, 그레이 스케일 영상을 사용하여 버퍼링하여 저장하고, 이미지 프로세싱(image processing) 및 영상 분석 기능을 제공하며, 관심 영역 (ROI, Region of Interest)을 그레이 스케일(grayscale)로 변환하며, 관심 영역(ROI)의 외곽선이 추출되는 실 험에 의한 특정 임계값(threshold)을 사용하여 관심 영역(ROI)의 이미지의 히스토그램(histogram)[x축 영상의 각 픽셀의 화소 값, y축 해당 화소 값의 갯수(빈도수)]을 구하고, 그 관심영역 이미지를 Ostu 알고리즘을 사용 하여 임계값을 기준으로 0,1로 이진화(binarization)한 후, 히스토그램 평활화(histogram equalization)를 통 해 관심 영역(ROI)의 영상의 전처리를 수행하며, sobel edge operator(소벨 엣지 연산자, sobel mask) 또는 canny edge operator(캐니 엣지 연산자)를 사용하여 x 방향의 미분과 y 방향의 미분을 구하고, sobel mask의 가중치를 영상의 화소 값에 곱하고 이들 더하는 convolution에 의해 관심 영역 이미지의 엣지(edge, 물체 영역, 배경 영역의 경계에 위치하는 화소들)를 검출하고 특정 임계값을 적용하여 생성된 엣지 영상의 결함 객체들의윤곽선을 검출하고, 형상 특징(Shape Features)을 추출한다. Ostu 알고리즘을 사용한 임계 방법을 사용하는 경우, 화소 값 f(x,y)들이 특정 임계값을 기준으로 입력 영상에 대하여 물체 영역과 배경 영역으로 분리하고, 화소 값 f(x,y)이 특정 임계값 보다 클 경우 물체 영역에 속하는 화소로 결정하며, 반대로 화소 값 f(x,y)이 특정 임계값 보다 작은 경우 배경 영역에 속하는 화소로 결정한다. ii) 딥러닝 알고리즘(CNN 알고리즘 등)을 사용하여 영상의 특징 추출과 분류하고 학습 모델의 누적 저장된 학습 데이터DB의 결함 이미지의 학습 데이터(이물질, 스크래치 등)와 비교하여 결함이 있는 객체(이물질, 스크래치 등)를 추출한다. 머신 비전 영상 분석 SW의 딥러닝 알고리즘은 CNN(Convolutional Neural Network), R-CNN(Recurrent Convolutional Neural Network), Fast RCNN, 및 Faster RCNN(Region based Convolutional Neural Network) 알 고리즘, YOLO(You Only Look Once), SSD(Single Shot Detector) 알고리즘 중 어느 하나의 알고리즘을 사용하여 영상의 객체들을 검출한다(object detection). 머신 비전 영상 분석 SW의 딥러닝 알고리즘은 CNN 알고리즘을 사용하며, AlexNet, ZFNet, VGGNet, GoogLeNet, ResNet 중 어느 하나의 알고리즘을 사용하며, 상기 CNN 알고리즘을 사용하여 영상의 특징 추출(feature extraction)과 분류(classification)하고, 학습 모델 에 따라 학습데이터DB에 누적되어 저장된 결함 이미지의 학습 데이터와 비교하여 결함이 있는 객체(이물질, 스 크래치)를 추출한다. 딥러닝의 CNN(Conventional Neural Network) 알고리즘은 카메라 입력 영상으로부터 입력층(input layer)/n개의 은닉층(hidden layer)(Layer 1, Layer 2, Layer 3... )/출력층(output layer)으로 구성되며, 다층구조의 컨볼 루션 신경망(CNN)을 사용하여 Multilayer Perceptron을 통해 영상의 특징 추출(feature extraction)과 객체를 분류(classification)하여 결함이 있는 객체(이물질, 스크래치 등)를 검출한다. 컨볼루션 신경망(CNN, Convolutional Neural Network)은 컨볼루셔널 층(Convolutional Layer), 풀링 층 (Pooling Layer), FC 층(Fully Connected Layer, 완전연결층)을 포함하는 3개의 레이어가 사용된다. CNN 알고리즘은 가중치(weight)를 갖는 마스크(예, 3x3 윈도우)를 이동해가며 컨볼루셔널 층(Convolutional Layer)과 풀링 층(Pooling Layer)에 의해 각각 convolution(합성곱)과 subsampling을 반복하여 영상의 데이터 량을 줄이며 영상의 왜곡에 강인한 특징을 추출(feature extraction)하며, 컨볼루션에 의해 특징맵(feature map)을 추출하고, 신경망(Neural Network)에 의해 학습 모델에 따라 검출된 결함이 있는 객체(이물질, 스크래치 등)를 분류(classification)한다. CNN 알고리즘을 사용한 영상처리에서, 컨볼루션(convolution)은 가중치를 갖는 마스크(예, 3x3 윈도우)를 사용 하여 영상처리가 이루어지며, 입력 영상에 가중치를 갖는 마스크(예, 3x3 윈도우)를 이동해가며, 현재 입력 영 상에 가중치를 갖는 마스크를 씌운 후 입력 영상의 픽셀값과 마스크의 가중치를 각각 곱한 후 그 합을 출력 영 상의 픽셀값으로 정해진다. subsampling은 화면 크기를 줄이는 과정이며, 해당영역의 최대치를 선택하는 max pooling을 사용한다. FC 층(Fully Connected Layer, 완전연결층)은 신경망의 입력단자에 연결시켜 학습에 의해 객체를 분류한다. 현재 5층의 convolution layer와 3층의 fully_connected layer로 이루어져 있다. 컨볼루셔널 층(Convolutional Layer)의 출력은 Max-Pooling Layer에 의해 subsampling을 진행하여 image의 사 이즈가 줄여지며, Max-Pooling의 출력은 FC 층(Fully Connected Layer)에서 객체의 클래스를 분류한다. 결과적으로, 카메라 영상의 결함이 있는 객체들을 추출하기 위해 CNN 구조의 중간 몇 개의 컨볼루션 층 (convolutional layer)에서 객체 위치영역과 종류 정보를 포함하는 특징맵(feature map)을 추출하고, 풀링 층 (Pooling layer)를 통과함에 따라 특징맵(feature map)의 크기가 작아지며 각각 다른 크기의 특징지도에서 객체 위치영역 정보를 추출하여 객체들을 검출하여, FC 층(Fully Connected Layer, 완전 연결층)에 의해 학습 모델의 사전 학습 데이터와 비교하여 결함이 있는 객체(이물질, 스크래치)를 분류(classification)한다. 카메라의 입력 영상 I로부터 입력층/은닉층/출력층의 다층 구조의 컨볼루션 신경망(CNN)을 사용하여 영상의 특 징 벡터 x를 추출하며; 추출된 영상의 특징 벡터 x로부터 함수를반복 적용하여 출력 벡터 를 계산한다: 여기서, hi는 i번째 은닉 특징 벡터, hi-1은 i-1번째 은닉 특징 벡터, Wi는 신경망 회로의 가중치 파라미터 (weight parameter, 상수값), bi는 신경망 회로의 바이어스 값이다. 입력 특징 벡터는 로 설정되며, 총 L 개의 은닉층(hidden layer)이 존재할 경우 h1,h2,...hL을 차례로 계산하여 최종 출력 벡터는 로 결정된다. 또한, h1,h2,...hL-1은 시스템의 출력으로 드러나지 않는 양 으로 은닉 특징 벡터(Hidden Feature Vector)라고 불린다. hL-1은 L-1 번째 은닉 특징 벡터이다."}
{"patent_id": "10-2020-0126326", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "R-CNN의 기본적인 구조는 입력 이미지에서 Selective Search라는 Region Proposal 생성 알고리즘을 사용하여, 객체가 존재할 것으로 추정되는 Region Proposal들을 추출한다. 각각의 Region Proposal들은 사각형 모양의 Bounding Box 안의 이미지 형태인데, 모든 Region Proposal들에 대하여 크기를 동일하게 만든 후 CNN을 거쳐 분 류하는 작업을 수행한다. R-CNN은 모든 Region Proposal마다 하나의 CNN(Convolutional Neural Network)을 실행해야 하므로 속도가 느려 지며, 이미지 특징 추출을 위한 모델, 분류를 위한 모델, Bounding Box를 잡아주는 모델을 동시에 학습해야 하 므로 기계 학습에 걸리는 시간이 많이 들었다. R-CNN의 속도 문제를 해결하기 위해, Fast R-CNN이라는 모델이 개발되었다. Fast R-CNN 모델은 Feature를 입력 이미지로부터 추출하는 것이 아니라, CNN을 거친 특징맵(Feature Map) 상에서 RoI Pooling을 사용하여 특징 (Feature)을 추출한다. Faster R-CNN은, Region Proposal을 생성하는 방법 자체를 CNN 내부에 네트워크 구조로 넣은 모델이다. 이 네트 워크를 RPN(Region Proposal Network)라고 한다. RPN을 통해 RoI Pooling을 수행하는 레이어와 Bounding Box를 추출하는 레이어가 같은 특징 맵(feature map)을 공유할 수 있다. Fast RCNN은 전체 영상과 객체들을 입력받고, 전체 영상에 대한 CNN의 특징 지도(feature map)를 획득한다. ROI(Region of Interest) 풀링층은 각각의 개체에 대하여 특징맵(feature map)으로부터 고정된 길이의 특징벡터 를 추출한다. 각각의 특징벡터는 FC 층(Fully Connected layer)을 통해 하나의 시퀀스가 되어, 소프트맥스 (Softmax)를 통한 확률 추정과 경계 박스의 위치를 출력한다. 풀링(Pooling)은 다양한 위치에서 특징의 통계를 집계하여 이미지의 해상도를 줄일 수 있는 하위 샘플링 프로세 스이며, 풀링은 회전, 노이즈 및 왜곡과 같은 이미지 변형에 견고성을 향상시켜, 풀링은 최대값 풀링과 평균값 풀링 두 가지 방법이 사용된다. 하나의 CNN 분류기는 컨볼루션층과 풀링층이 반복되며 그 구조에 따라 다양한 기능의 층(layer)들이 추가될 수 있다. 입력 이미지에 대하여 컨볼루션과 풀링 과정을 거쳐 추출된 특징(faeture)은 학습 모델의 학습 데이터에 따라 다양한 분류기들(예, SVM 분류기)을 적용시켜 객체들(예, 이물질, 스크래치 등)이 분류될 수 있다. Faster R-CNN은 입력 이미지에 대해 통째로 Convolution Layer를 여러 번 거쳐서 특징을 추출하며, 이렇게 추출 된 출력 특징 맵을 RPN과 RoI Pooling Layer가 공유하게 된다. RPN은 특징맵(feature map)에서 Region Proposal들을 추출하며, RoI Pooling Layer는 RPN에서 추출된 Region Proposal들에 대해 RoI 풀링을 수행한다. 딥러닝을 사용한 카메라 영상 데이터의 실시간 객체 인식을 위해 YOLO(You Only Look Once) 모델이 사용될 수 있다. YOLO는 각 이미지를 SxS 개의 그리드(grid, 경계 상자)로 분할하고, 각 그리드의 신뢰도를 계산하여 그리드 내 객체 인식시 정확도를 반영하여 이미지 전체를 한번에 보는 방식으로 클래스를 구분하며, YOLO는 단순한 처리로 다른 모델에 비해 2배 정도 높은 성능을 갖고 있다. 그리드에 객체 포함 여부를 계산하기 위해, 객체 클래스 점 수를 계산한다. 이 결과로 총 S x S x N 객체가 예측된다. YOLO와 유사하면서 더 나은 성능을 보이는 SSD(Single Shot Detector) 모델은 영상내 객체 검출 속도 및 정확도 사이의 균형감이 고유한 장점, SSD는 입력 이미지에 대한 CNN을 단 한번만 실행하고도 특징 맵(feature map) 계 산이 가능하여 다양한 스케일의 객체 검출 가능하다. SSD는 카메라 영상 내의 객체 검출(object detection)을 위한 그리드(grid)가 표시되는 객체 검출 속도 및 정확 도 사이의 균형이 있는 인공지능 기반 객체 검출 알고리즘이다. SSD는 1회에만 입력 이미지에 대하여 CNN(Convolutional Neural Network)을 실행하고, 특징 맵(feature map)을 계산한다. 그리드 및 객체 분류 확률 을 예측하기 위해 특징 맵을 3 × 3 필터 크기로 CNN을 수행한다. SSD는 CNN처리 후, 그리드(grid)를 예측한다. 이 방법은 다양한 스케일의 객체를 검출할 수 있다 도 5는 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 비즈니스 모델을 나타낸 도면이다. 수요 기업(제조 기업)은 엣지 시스템으로써 지능화된 머신 비전 솔류션을 도입하고, 제조 지능 마켓 플레이스 (MiraeCIT)에서 학습/불량 판정과 불량 예측 모델을 수행하며, 제조 지능 마켓 플레이스(MiraeCIT)는 클라우드 컴퓨팅을 통해 자동차부품/사출 성형/전자부품/제약/식품 등의 산업별 전문가 그룹과 연계된다. 도 6은 카메라, 조명, 콘트롤 박스, PC 또는 PLC와 연결되는 비전 시스템 결선도이다. 제품 결함 이미지 원격 학습을 통한 AI 머신 비전 검사 시스템은 PC, PLC, 카메라, 센서, 조명, 콘트롤러를 포함한다. 콘트롤러는 카메라, 센서, 조명과 연결되며, 카메라와 연결된 PC는 PLC와 연결될 수 있다. PC와 연결되는 카메라와 조명과 콘트롤러를 구비하며, 제품의 결함(이물질, 스크래치 등) 을 검출하여 제품의 불량(스크래치, 이물질 등)을 판단하는 수동 비전 검사기는 추가적으로 카메라에 Trigger Input을 제공하는 센서를 더 구비한다. AI 머신 비전 검사 시스템에서 조명은 흰색 또는 적색 LED 조명, 또는 광섬유 가이드를 가지는 할로겐 조 명 사용하며, 실시예에서는 LED 조명과 조명 콘트롤러를 사용하였다. LED 조명을 사용하는 경우, 일렬로 배열된 white LED와 조명 콘트롤러, 또는 카메라 렌즈 주위를 둘러싼 다수의 LED들로 구성된 링 LED와 조명 콘트롤러 사용한다. 조명은 링 LED 조명, 상면/좌상/우상 경사각도 조명, 백 라 이트 조명 등이 사용될 수 있다. 추가적으로 딥러닝 기반의 비전영상처리 SW를 구비하는 PC는 Ethernet cable을 통해 연결되는 PLC를 더 구비한다. 상기 제품의 카메라 영상 데이터의 머신 비전 영상 분석 SW는 i) 그레이 스케일 영상 처리, 또는 ii) 딥러닝 알 고리즘을 사용하며, 카메라 영상의 이미지는 그레이스케일 이미지, RGB 이미지, HSI 이미지, YCbCr, JPEG 이미지, TIFF 이미지, GIF 이미지를 적용하며, 상기 딥러닝 알고리즘은 CNN(Convolutional Neural Network), R-CNN(Recurrent Convolutional Neural Network), Fast RCNN, 및 Faster RCNN(Region based Convolutional Neural Network) 알고리즘, YOLO(You Only Look Once), SSD(Single Shot Detector) 알고리즘 중 어느 하나의 알고리즘을 사용하여 카메라 영상 데이터의 이물질과 스크래치의 결함이 있는 객체들을 검출하여 제품의 불량 여부를 판단한다. 머신 비전 영상 분석 SW의 딥러닝 알고리즘은 CNN(Convolutional Neural Network), R-CNN(Recurrent Convolutional Neural Network), Fast RCNN, 및 Faster RCNN(Region based Convolutional Neural Network) 알 고리즘, YOLO(You Only Look Once), SSD(Single Shot Detector) 알고리즘 중 어느 하나의 알고리즘을 사용하여 영상의 객체들을 검출하여(object detection) 제품의 불량 여부를 판정한다. 엣지 플랫폼의 머신 비전 영상 분석 SW의 딥러닝 알고리즘은 CNN 알고리즘을 사용하며, AlexNet, ZFNet, VGGNet, GoogLeNet, ResNet 중 어느 하나의 알고리즘을 사용하며, 상기 CNN 알고리즘을 사용하여 영상의 특징 추출과 분류하고 학습 모델의 누적된 결함 이미지의 학습 데이터와 비교하여 결함이 있는 객체(이물질, 스크래치)를 추출하고, 결함이 있는 객체를 포함하는 이미지를 상기 서비스 플랫폼으로 전송하여 상기 서비스 플랫폼이 제품의 불량 여부를 판단한다. 제품은 바코드, QR 코드, 또는 13.56MHz RFID 태그가 부착될 수 있다. 추가적으로, PC는 제품에 바코드가 부착된 경우, 제품에 부착된 바코드를 인식하는 바코드 리더기와 인식 모듈 을 더 포함할 수 있다. 추가적으로, PC는 제품에 QR 코드가 부착된 경우, 제품에 부착된 QR 코드를 인식하는 QR 코드 인식 모듈을 더 포함할 수 있다. 추가적으로, 제품에 13.56MHz RFID 태그가 부착된 경우, 13.56MHz RFID 리더와 \"제품 코드 전송 미들웨어\"를 통 해 연결되는 PC의 SW 모듈을 더 구비할 수 있다. 상기 미들웨어는 바코드 리더, QR 코드 인식기 또는 13.56MHz RFID 리더에 의해 인식된 제품에 부착된 추출된 모델정보에 해당하 는 바코드, QR 코드 또는 13.56MHz RFID 태그 정보 중 어느 하나를 상기 엣지 플랫폼으로부터 상기 서비스 플랫 폼으로 전송하는 제품 코드 전송 미들웨어; 및 제품 결함 이미지 원격 학습을 통한 비전 검사 방법에 따라 머신 비전 시스템으로부터 전송된 비정형 불량 가공 데이터를 전송받아 딥러닝 모델 훈련 시스템에 의해 누적되어 저장된 불량 이미지 학습 데이터(이물질, 스크래 치)와 비교하여 비정형 불량 이미지를 검출하는 비정형 불량 판정 학습 모델을 구비하고, 딥러닝 형상 판단 시 스템에 의해 AI 딥러닝 모듈에 의해 카메라 영상 데이터의 이물질 유무 검사, 형상 검사, 정상/불량 판정 결과 데이터를 상기 서비스 플랫폼으로부터 상기 엣지 플랫폼으로 전송하는 딥러닝 미들웨어를 포함한다. 추가적으로, PC는 딥러닝 기반의 2D 비전 검사 후, 제품 이동을 제어하도록 로봇 인터페이스를 통해 제어 로봇 과 연동될 수 있다. 도 7은 딥러닝 기반의 머신비전 플랫폼에서 센서와 카메라를 사용한 PC의 비전 검사(얼룩, 찍힘, 긁힘), 제품 형상 검사(미타발, 변형 불량), Blob 검사(도금 유무 판단)의 AI View를 나타낸 그림이다. 센서는 Trigger Input을 발생하여 카메라로 전송하면, 카메라는 조명 Strobe를 제어하기 위해 Digital Output을 발생하여 이미지 센서에서 이미지 데이터를 생성하고 PC로 전송한다. PC는 필요에 따라, 이미지 데이터의 Inspection 검사(얼룩, 찍힘, 긁힘), 제품 형상 검사(미타발, 변형 불량), Blob 검사(도금 유무)를 검사한다. Inspection 검사(얼룩, 찍힘, 긁힘)는 양품 이미지와 불량 이미지를 등록한 후 구분 임계치를 기준으로 실시간 으로 이미지의 불량을 판단한다. 제품 형상 검사(미타발, 변형 불량)는 제품의 형상의 모양과 크기를 양품 이미지를 기준으로 제품의 형상 변형 유무를 판단한다. Blob 검사(도금 유무)는 정상 도금 영역의 밝기와 불량 도금 영역의 밝기 비교를 통한 마련된 기준으로 도금 유 무를 판단한다. 도 8은 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 솔류션 구성도이다. 센서, 카메라, 조명, 콘트롤 박스, PC 또는 PLC와 연결되는 머신비전 AI 시스템 구성도를 참조하면, 딥러닝 기 반의 머신 비전 플랫폼에서 불량 판정 지능을 개발하고 지속적인 학습이 가능하다. 학습된 지능은 딥러닝 기반의 머신 비전 플랫폼에서 실행하여 공정 결함 검출율을 높인다. 지속적인 제조 데이터 축적을 통해 수준 높은 지능형 비전 시스템으로 진화하도록 지원한다. 도 9는 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 솔류션 아키텍처이다. 제품 결함 이미지 원격 학습을 통한 비전 검사 방법의 머신 비전 AI 솔루션 아키텍처는 제품 모델 식별(영상 촬 영, QR 코드 인식, 모델 정보 추출), 모델별 검사 수행(모델별 검사 알고리즘 선택->이물질 유무 검사->형상 판 단 검사->스크래치 유무 검사-> 형상 치수 검사), 제품 분류(제어 로봇 인터페이스-> 불량 판별 데이터 저장 -> 미들웨어 데이터 전송)를 실행한다. 도 10은 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 모델링 아키텍처이다. 머신 비전 AI 모델링 아키텍처는 MS Windows10 운영체제가 설치된 PC에서 MS SQL express, Image Storage, Python(Scikit-learn, Keras, Tensorflow 딥러닝 툴 사용), Python Flask 1.1.1, 2D 비전검사와 MES(제조 실 행 시스템, Manufacturing Execution System) 인터페이스, AI 학습 모듈, 제품 검사 관리 모듈, 제품 실시간검사 모듈을 구비한다. 스마트 팩토리는 제조 실행 시스템/품질 관리 시스템(MES/QMS)가 구축되고, 제품에 바코드 마킹 과정이 추가되 며, 제조 공정에 따라 생산 라인이 머신 비전 시스템이 제품의 불량을 걸러낸다. MES(제조 실행 시스템, Manufacturing Execution System)는 제조 공정상의 실시간 카메라 비전검사 모니터링, 제어, 물류 및 작업내역 추적 관리, 양불 상태 파악, 불량 관리에 초점을 맞춘 현장 제조 실행 시스템이다. 도 11은 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 미들웨어 아키텍처이다. 제조 기업의 기 구축된 머신 비전(MV) 시스템과 새롭게 도입된 딥러닝 비전 검사 시스템은 미들웨어 (Middleware)를 통해 PC와 통신되며, PC는 제품의 검사기준에 따라 제품 검사 정보 통합 관리하는 통합 운영관리 소프트웨어를 구비하며, 데이터 송 수신, 형상 수치 정보 전달, 취득 데이터 가공, DB 운영 관리, 제품 검사 기준 정보를 저장하는 데이터베이스를 구비한다. 머신 비전(MV) 시스템은 미들웨어를 통해 카메라 영상의 검사 결과 이미지 형상 수치 정보를 미들웨어를 통해 PC와 딥러닝 비전 검사 시스템으로 전달하고, 딥러닝 비전 검사 시스템으로부터 기 누적 저장된 제품 불량과 결 함 학습 데이터에 기초하여 제품 검사 기준(이물질, 스크래치 등)에 따라 판정 데이터 결과를 PC와 미들웨어를 통해 머신 비전(MV) 시스템으로 전송한다. 도 12는 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 플랫폼 프로세스이다. 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법은 훈련 단계는, 제조 기업(수요 기업)에서 요구하는 수집된 불량 판정 데이터에 기초하여 비정형적인 불량 및 결 함 데이터를 제공하는 단계; 머신 비전 시스템은 상기 불량 및 결함 데이터에 기초하여 제품 검사 기준에 따라 이물질 유무 검사, 형상 유무 검사, 스크래치 유무 검사를 실시하고, 카메라 영상의 머신 비전 검사 결과 데이터를 제공하는 단계; 미들웨어는 데이터 송수신(TCP/IP), 머신 비전 검사 결과 데이터 수집, 제품 불량과 결함 데이터를 가공하여 PC 로 학습용 데이터를 제공하는 단계; 및 딥러닝 시스템은 카메라 영상의 이미지의 데이터 전처리, 딥러닝 모델 훈련(training), 딥러닝 모델 검증하는 단계를 포함한다. 실행 단계는, 제조 기업(수요 기업)에서 요구하는 수집된 불량 판정 데이터에 기초하여 비정형적인 불량 및 결 함 데이터를 제공하는 단계; 딥러닝 시스템은 상기 불량 및 결함 데이터에 기초하여 제품 검사 기준에 따라 이물질 유무 검사, 형상 유무 검 사, 스크래치 유무 검사를 실시하고, 카메라 영상의 딥러닝 검사 결과 데이터를 제공하는 단계; 미들웨어는 데이터 송수신(TCP/IP), 딥러닝 검사 결과 데이터 수집, 제품 불량과 결함 데이터를 가공하여 PC의 DB 통합 관리 저장되며, PC로 검사용 데이터를 제공하는 단계; 및 딥러닝 시스템은 카메라 영상의 비정형적인 이미지 판독, ?비정형적읶 형상 검사, 비정형적인 정상/불량 판단, 비정형적인 불량 및 결함이 포함된 검사 결과 데이터를 미들웨어를 통해 PC로 제공하는 단계를 포함한다. 도 13은 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 플랫폼 통합 아키텍처이다. 1) 제품 결함 이미지 원격 학습을 통한 비전 검사 방법의 머신 비전 AI 솔루션 아키텍처는 제품 모델 식별(영상 촬영, QR 코드 인식, 모델 정보 추출), 모델별 검사 수행(모델별 검사 알고리즘 선택->이물질 유무 검사->형상 판단 검사->스크래치 유무 검사-> 형상 치수 검사), 제품 분류(제어 로봇 인터페이스-> 불량 판별 데이터 저장 -> 미들웨어 데이터 전송)를 실행한다. 2) 검사 결과 이미지 형상 수치 정보 전달 3) 주요 기능: 데이터 송수신, 형상 수치 정보 전달, 취득 데이터 가공, DB 운영 관리 4) 데이터베이스에 저장된 제품 검사기준 운영, 비정형 불량 가공 데이터 정보 전달 5) 딥러닝 모델 훈련 시스템: 훈련 데이터셋 -> 데이터 라벨링, 데이터 전처리 -> 딥 인공 신경망 학습 -> 딥러 닝 모델 생성, 테스트 데이터 셋의 딥러닝 모델 검증 6) 비정형 불량 판정 학습 모델 전달 7) 딥러닝 형상 판단 시스템: 딥러닝 딥러닝 모델, 이미지 판독, 형상 검사, 정상/불량 판정, 결과 데이터 전송 8) 비정향 불량 판정 결과 전달 자재 투입, 모델 정보 추출, 이물질 유무 검사, 형상 판단 검사, 스크래치 유무 검사, 형상치수 검사, 자재 출 하의 순서로 동작된다. 도 14는 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법에 따라 머신비전 기반 PCB 불량판정 및 불량예측 을 지원하는 머신 비전 기반 PCB 제조 지능과, Pan Valve 및 Dual Check Valve의 불량을 판정할 수 있는 Valve 제조지능(머신비전 기반 PCB 제조 지능, 머신비전 기반 Valve 제조 지능)을 개발한 사례이다. 머신비전 기반 PCB 제조 지능은 미삽, 오삽 등의 불량을 검출할때 아래쪽의 컨덴서에 가려서 머신비전에서 잘못 찾는 경우에 딥러닝을 사용하여 제대로 찾을 수 있도록 지능형 머신비전을 만든 사례이다. 머신비전 기반 Valve 제조 지능은 머신비전에서 이물질과 스크래치 불량검출을 하기 위해 카메라를 추가로 설치 하고 수차례 나눠 여러장을 촬영해야 하지만, 한번 촬영한 전체 이미지를 딥러닝을 통해 이물질과 스크래치 불 량을 검출함으로서 검사 시간과 비용을 절감하게 되었다. 본 발명의 제품 결함 이미지 원격 학습을 통한 비전 검사 방법은 컨베이어 벨트와 머신 비전 시스템이 구비된 스마트 팩토리를 구축하기 어려운 중소 기업들이 상대적으로 적은 비용으로 인공 지능 프로그래밍을 사용한 딥 러닝 비전 검사 시스템을 구축하여 제품 결함을 포함하는 학습 데이터를 기초로 딥러닝 비전 시스템에 의해 제 품의 결함(이물질, 스크래치 등)을 판단하고 제품의 불량 여부를 판단하게 되었다. 본 발명에 따른 실시예들은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현되고 컴퓨터 판독 가능 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 기록 매체는 프로그램 명령, 데이터 파일, 데이 터 구조를 단독으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능 기록 매체는 스토리지, 하드 디스크, 플 로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램 (RAM), 플래시 메모리 등과 같은 저장 매체에 프로그램 명령을 저장하고 수행하도록 구성된 하드웨어 장치가 포 함될 수 있다. 프로그램 명령의 예는 컴파일러에 의해 만들어지는 것과, 기계어 코드뿐만 아니라 인터프리터를 사용하여 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 상기 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로써 작동하도록 구성될 수 있다. 이상에서 설명한 바와 같이, 본 발명의 방법은 프로그램으로 구현되어 컴퓨터의 소프트웨어를 이용하여 읽을 수 있는 형태로 기록매체(CD-ROM, RAM, ROM, 메모리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등)에 저장될 수 있다. 본 발명의 구체적인 실시예를 참조하여 설명하였지만, 본 발명은 상기와 같이 기술적 사상을 예시하기 위해 구 체적인 실시 예와 동일한 구성 및 작용에만 한정되지 않고, 본 발명의 기술적 사상과 범위를 벗어나지 않는 한 도 내에서 다양하게 변형하여 실시될 수 있다. 따라서, 그와 같은 변형도 본 발명의 범위에 속하는 것으로 간주 해야 하며, 본 발명의 범위는 후술하는 특허청구범위에 의해 결정되어야 한다."}
{"patent_id": "10-2020-0126326", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 엔코더를 구비한 컨베이어 벨트 생산 라인에서 센서와 ID 리더기와 카메라와 광학 조명을 구비하는 비전 검사 시스템 구성도이다. 도 2는 종래의 딥러닝 기반 분류기 생성 과정의 동작 흐름도이다. 도 3a, 3b는 PC와 연결되는 카메라와 조명과 콘트롤러를 구비하며, 제품의 결함(이물질, 스크래치 등)을 검출하 여 제품의 불량을 판단하는 수동 비전 검사기, 주요 기능을 나타낸 도면이다. 도 4는 본 발명에 따른 딥러닝 알고리즘을 사용한 제품 결함 이미지 원격 학습을 사용한 머신비전 제조지능 플 랫폼을 나타낸 도면이다. 도 5는 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 비즈니스 모델을 나타낸 도면이다. 도 6은 카메라, 센서, 조명과 콘트롤 박스, PC, PLC의 비전 시스템 결선도이다. 도 7은 딥러닝 기반의 머신비전 플랫폼에서 센서와 카메라를 사용한 PC의 비전 검사(얼룩, 찍힘, 긁힘), 제품 형상 검사(미타발, 변형 불량), Blob 검사(도금 유무 판단)의 AI View를 나타낸 그림이다. 도 8은 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 솔류션 구성도이다. 도 9는 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 솔류션 아키텍처이다. 도 10은 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 모델링 아키텍처이다. 도 11은 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 미들웨어 아키텍처이다. 도 12는 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 플랫폼 프로세스이다. 도 13은 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법의 머신 비전 AI 플랫폼 통합 아키텍처이다. 도 14는 제품 결함 이미지 원격 학습을 사용한 비전 검사 방법에 따라 머신비전 기반 PCB 불량판정 및 불량예측 을 지원하는 머신 비전 기반 PCB 제조 지능과, Pan Valve 및 Dual Check Valve의 불량을 판정할 수 있는 Value 제조지능(머신비전 기반 PCB 제조 지능, 머신비전 기반 Valve 제조 지능)을 개발한 사례이다."}
