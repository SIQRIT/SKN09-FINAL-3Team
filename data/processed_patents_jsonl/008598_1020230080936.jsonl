{"patent_id": "10-2023-0080936", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0178780", "출원번호": "10-2023-0080936", "발명의 명칭": "교사 모델의 사전 지식을 이용한 지식 증류 시스템", "출원인": "인하대학교 산학협력단", "발명자": "배승환"}}
{"patent_id": "10-2023-0080936", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기 정의된 하드 샘플링 손실(hard sampling loss)을 적용하여 학생 모델이 구분하기 어려운 이미지 데이터를 생성하는 이미지 생성부; 및상기 이미지 생성부에서 생성한 이미지를 이용하여 지식 증류를 수행하는 지식 증류부를 포함하는 교사 모델의사전 지식을 이용한 지식 증류 시스템."}
{"patent_id": "10-2023-0080936", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 이미지 생성부는,하기의 수학식을 사용하여 이미지를 생성하고, 는 교사 모델이며, 은 교사 모델에 이미지 를 입력했을 때의 출력 분포이고, 에서 는 레이블 와 이미지 사이의 교차 엔트로피(cross entropy)이며, 는 하드샘플링 손실(hard sampling loss)이고, 는 이미지의 정규화 요소(regularization term)로, 이미지 의 전체분산과 L2_노름(L2_norm)으로 구성되어 있으며, 는 의 척도 인자(scaling factor)인 교사 모델의 사전지식을 이용한 지식 증류 시스템."}
{"patent_id": "10-2023-0080936", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,이미지 생성부는학생 모델의 손실을 최대화하여 학생 모델이 분류하기 어려운 이미지를 생성하는 제1 이미지 생성부; 및학생 모델이 하나의 클래스로 정하기 어려워하는 이미지를 생성하기 위해 학생 모델이 균일분포 (uniformdistribution)를 출력분포로 갖는 이미지를 생성하는 제2 이미지 생성부 중 적어도 하나를 포함하는 교사 모델의 사전 지식을 이용한 지식 증류 시스템."}
{"patent_id": "10-2023-0080936", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 제1 이미지 생성부는하기의 수학식을 사용하여 이미지를 생성하고,공개특허 10-2024-0178780-3-은 하기의 수학식로 정의되며, 는 학습을 진행 중인 학생 모델이고, 은 의 척도 인자인 교사 모델의 사전 지식을 이용한 지식 증류 시스템."}
{"patent_id": "10-2023-0080936", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서,상기 제2 이미지 생성부는하기의 수학식을 사용하여 이미지를 생성하고,은 하기의 수학식로 정의되며, 은 쿨백-라이블러(Kullback-Leibler) 발산을 의미하고, 는 학습을 진행 중인 학생 모델이고, 균일분포 는 클래스의 개수가 일 때 이고, 모든 값을 로 동일하게 갖는 분포이며, 는의 척도 인자인 교사 모델의 사전 지식을 이용한 지식 증류 시스템."}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 교사 모델의 사전 지식을 이용한 지식 증류 시스템에 관한 것이다. 본 발명에 따르면, 교사 모델의 사전 지식을 이용한 지식 증류 시스템은 기 정의된 하드 샘플링 손실(hard sampling loss)을 적용하여 학생 모델이 구분하기 어려운 이미지 데이터를 생성하는 이미지 생성부; 및 상기 이 미지 생성부에서 생성한 이미지를 이용하여 지식 증류를 수행하는 지식 증류부를 포함한다. 이와 같이 본 발명의 실시예에 따르면, 데이터를 자동으로 생성할 수 있어, 대규모 학습데이터 수집이 어려운 경 우나 데이터 도메인이 계속 변화하는 경우와 같이 학습 데이터를 확보하기 어려운 상황에서도 높은 정확도를 가 진 고성능의 학생 모델을 학습시킬 수 있다."}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 교사 모델의 사전 지식을 이용한 지식 증류 시스템에 관한 것으로서, 더욱 상세하게는 학생 모델이 정확히 판별하기 어려운 이미지를 생성하여 최종적으로는 테스트 정확도를 향상하는 하드 샘플링(hard sampling) 이미지 생성 기법을 이용하여 지식 증류를 수행하는 교사 모델의 사전 지식을 이용한 지식 증류 시스 템에 관한 것이다."}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "지식 증류(knowledge distillation)는 높은 예측 정확도를 가진 교사 모델의 지식을 단순하고 가벼운 학생 모델 에 이전하여, 학생 모델이 교사 모델과 유사한 높은 성능을 내도록 하는 딥러닝 방법 중 하나로, 높은 성능을 지녔지만 무거운 모델을 성능은 유지하면서 경량화하는 용도로 사용된다. 최근 사생활 보호를 위해 데이터 사용이 법률로 인해 제한을 받고 있는 상황에서 임베디드 기기의 사용 증가로 경량화된 인공지능 모델이 요구됨에 따라 지식 증류 기법의 필요성이 커지고 있다. 하지만, 기존의 지식 증류 방법은 이미지 분류를 수행하는 교사 모델과 학습 이미지, 분류 레이블로 이루어진 학습 데이터를 모두 사용하여, 교사 모델을 모방하는 학생 네트워크를 학습시키는데, 이 과정에서 학습에 사용한 데이터를 필요로 한다. 따라서, 기존의 지식 증류 방법은 학습 데이터를 확보하기 어려운 상황에서는 적용하기 어렵다는 한계가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2368064(2022.02.22.) 비특허문헌 (비특허문헌 0001) Yin, Hongxu, et al. \"Dreaming to distill: Data-free knowledge transfer via deepinversion.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020."}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명에 따르면, 교사 모델과 학생 모델 간의 지식 증류에서 별도의 학습 데이터 없이도 지식 증류를 수행할 수 있는 교사 모델의 사전 지식을 이용한 지식 증류 시스템을 제공하기 위한 것이다."}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이러한 기술적 과제를 이루기 위한 본 발명의 일 실시예에 따르면 교사 모델의 사전 지식을 이용한 지식 증류 시스템은 기 정의된 하드 샘플링 손실(hard sampling loss)을 적용하여 학생 모델이 구분하기 어려운 이미지 데 이터를 생성하는 이미지 생성부; 및 상기 이미지 생성부에서 생성한 이미지를 이용하여 지식 증류를 수행하는 지식 증류부를 포함한다."}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이와 같이 본 발명에 따르면, 데이터를 자동으로 생성할 수 있어, 대규모 학습데이터 수집이 어려운 경우나 데 이터 도메인이 계속 변화하는 경우와 같이 학습 데이터를 확보하기 어려운 상황에서도 높은 정확도를 가진 고성 능의 학생 모델을 학습시킬 수 있다."}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를 상세히 설명하기로 한다. 이 과정에서 도면에 도시된 선들의 두께나 구성요소의 크기 등은 설명의 명료성과 편의상 과장되게 도시되어 있을 수 있다. 또한 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서, 이는 사용자, 운용자의 의도 또는 관례에 따라 달라질 수 있다. 그러므로 이러한 용어들에 대한 정의는 본 명세서 전반에 걸친 내용을 토대로 내 려져야 할 것이다. 도 1은 본 발명의 일 실시예에 따른 교사 모델의 사전 지식을 이용한 지식 증류 시스템을 설명한 도면이다. 도 1에 도시된 바와 같이 교사 모델의 사전 지식을 이용한 지식 증류 시스템은 이미지 생성부 및 지 식 증류부를 포함한다. 이 때, 이미지 생성부는 제1 이미지 생성부 및 제2 이미지 생성부 중 적어도 하나를 포함한다. 이미지 생성부는 하드 샘플링 기법을 사용하여 학생 모델이 구분하기 어려운 이미지 데이터를 생성한다. 더욱 구체적으로, 임의로 정한 레이블 와 가우시안 랜덤 노이즈로 만든 이미지 를 사용하여 하기의 수학식 1 을 통해 손실(loss)을 최적화하고 이미지를 생성한다. 수학식 1"}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이 때, 는 교사 모델이며, 은 교사 모델에 이미지 를 입력했을 때의 출력 분포이고, 에서 는 레이블 와 이미지 사이의 교차 엔트로피(cross entropy)이다. 또한, 는 이미지의 정규화 요소(regularization term)로, 이미지 의 전체 분산과 L2_노름(L2_norm)으로 구 성되어 있으며, 이미지 의 전체 분산(total variance)에 페널티를 주어 인접한 픽셀들의 값을 비슷한 값으로 만들어 줌으로써 노이즈와 같은 이미지를 현실적인 이미지로 바꿔주는 역할을 수행하며, 는 의 척도 인자 (scaling factor)이다. 또한, 의 경우, 이미지 가 실제 이미지의 데이터 분포를 더 잘 따라가게 만드는 것으로 하기의 수학식 2를 통해 정의된다. 수학식 2"}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이 때, 와 는 모델의 번째 컨볼루션 레이어(convolutional layer)에서 추정된 특징맵의 평균과 분 산이다. 또한, 는 하드 샘플링 손실(hard sampling loss)로, 기존의 이미지 생성 과정에 추가되며, 생성하는 이미지 의 목적에 따라 기 설정된 형태 중 하나로 치환된다. 제1 이미지 생성부는 수학식 1에서 를 로 치환하여 하기의 수학식 3과 같이 학생 모델의 손실 을 최대화하여 학생 모델이 분류하기 어려운 이미지를 생성한다.수학식 3"}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이 때, 은 하기의 수학식 4로 정의되며, 학습을 진행중인 학생 모델 에 를 입력해 나온 출력분포"}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "와 레이블 간의 교차 엔트로피를 사용하여 학생 모델의 분류 손실(classification loss)을 직접 구하고, 이를 전체 손실에서 차감한다. 수학식 4"}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "따라서, 학생 모델의 손실을 최대화하여 학생 모델이 분류하기 어려운 이미지를 생성하는 경우, 를 최대화해야 하므로 학생 모델의 손실을 크게 만들기 위해 학생 모델이 맞추기 어려운 이미지를 생성하게 된다. 또한, 은 의 척도 인자이다. 반면, 제2 이미지 생성부는 수학식 1에서 를 로 치환하여 하기의 수학식 5와 같이 학생 모 델이 하나의 클래스로 정하기 어려워하는 이미지를 생성하기 위해 학생 모델이 균일분포 (uniform distribution)를 출력분포로 갖는 이미지를 생성한다. 수학식 5"}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이 때, 은 하기의 수학식 6으로 정의되며, 는 의 척도 인자이다. 수학식 6"}
{"patent_id": "10-2023-0080936", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 6에서 은 쿨백-라이블러(Kullback-Leibler) 발산을 의미한다. 제2 이미지 생성부는 쿨백-라이블러을 통해 을 사용하여 생성한 이미지 의 출력분포 값과, 모든 레이 블의 값들을 동일한 값으로 갖는 균일분포 간의 차이를 최소화한다.이 때, 는 이미지 을 학생 모델 에 입력했을 때 생성되는 출력분포이며, 균일분포 는 클래스의 개수 가 일 때 이고, 모든 값을 로 동일하게 갖는 분포이다. 이를 통해, 손실을 줄이는 과정에서 를 최소화해야 하므로 학생 모델의 출력분포를 균일분포와 비슷하게 만들어주는 이미지를 생성하게 된다. 지식 증류부는 이미지 생성부에서 생성된 이미지를 사용하여 지식 증류를 수행한다. 이 때, 지식 증류를 수행하는 과정은, 통상의 기술자에게 공지된 방식을 적용할 수 있는 바, 이에 대한 구체적 인 설명은 생략한다. 본 발명의 일 실시예에 따라 지식 증류를 수행한 학생 모델과 종래 기술의 학생 모델의 성능을 검증하기 위해, 각각 딥인버전(DeepInversion, DI), 적응형 딥인버전(Adaptive DeepInversion, ADI), 부정적 학생 손실 (Negative Student Loss, NSL), 균일분포 손실(Uniform Distribution Loss, UDL)을 사용하여 생성한 4개의 모 델에 CIFAR-10 데이터셋을 사용한 이미지 분류를 수행시킨 후, 학생 모델의 정확도를 측정하였다. 이 때, NSL은 본 발명의 일 실시예에 따라 제1 이미지 생성부에서 설계한 손실이며, UDL은 제2 이미지 생 성부에서 설계한 손실이다. 또한, CIFAR-10은 학습 데이터셋 50,000장, 테스트 데이터셋 10,000장으로 구성된 데이터셋으로, 10개 클래스 이미지가 포함되어 있다. 이때, 교사 모델로 ResNet-34 모델을, 학생 모델로 ResNet-18 모델을 사용하였으며, CIFAR-10 데이터셋을 사용 하는 과정에서 교사 모델을 학습할 때에는 학습 데이터셋을 사용해 학습을 진행하였고, 학생 모델을 학습하는 과정에서는 학습 데이터셋을 사용하지 않았다. 또한, 모델의 정확도를 측정할 때는 테스트 데이터셋 만을 사용하였다. 모든 실험에서 하이퍼파라미터 , , 을 1, , 10으로 각각 설정하였고, NSL 실험에서는 수학식 1의 을 1로 설정하였으며, UDL 실험 에서는 수학식 1의 을 10으로 설정하였다. 또한, DI (DeepInversion)와 ADI (Adaptive DeepInversion)을 학습할 때는 비특허문헌 1에서 설정한 파라미터 를 활용하였다. 이 때, 미니배치(minibatch)는 32*32 해상도의 256개의 이미지로 구성 된다. 지식 증류 방법으로는 통상의 기술 자에게 공지된 방식을 활용하였다. 모델 학습은 총 250epcoch에 걸쳐 수행되었다. 옵티마이저는 SGD옵티마이저를 사용하였으며 학습률(learning rate)은 0.1로 설정하였고, 이때 학습률 감쇠를 위해 100epoch마다 0.1씩 곱하였다. 지식 증류 과정에서 ADI, NSL, UDL의 학습과정의 경우 미리 생성해둔 DI 이미지 1000 배치를 가지고 학습을 시 작하였으며, 1 epoch가 끝날 때 마다 학습을 중단시키고 2개의 배치를 각각의 손실에 따라 생성하여 학습 데이 터에 추가하여 최종적으로 1500개의 배치의 이미지를 사용하였다. DI방법을 학습할 때에는 처음부터 총 1500개의 배치를 사용하였고 학습 중에 따로 이미지를 생성하지 않았다. 도 2 및 도 3는 본 발명의 일 실시예에 따라 지식 증류를 수행한 학생 모델과 종래 기술의 학생 모델의 정확도 를 나타낸 도면이다. 도 2 및 도 3에 도시된 바에 따르면, UDL 방법이 93.23%의 정확도를 달성해 가장 높은 정확도를 나타냈고, NSL 방법은 92.19%의 정확도로 측정이 되어 ADI의 정확도인 92.74% 보다 떨어지는 것을 확인하였다.도 4는 본 발명의 일 실시예에 따라 생성된 이미지와 종래 기술이 생성한 이미지의 예시를 나타낸 도면이다. 도 4에 도시된 바에 따르면, NSL 의 경우 학생 모델이 맞추기 힘든 이미지를 무리하게 생성함으로써 전체적으로 사람도 구분하기 힘든 이미지를 생성하는 것을 보였고, UDL은 모든 클래스가 균일분포로 나오게 만드는 이미지 를 생성해 냄으로써 여러 개의 사물이 섞인 것과 같은 이미지를 만들어 낸다. 이와 같이 본 발명에 따르면, 데이터를 자동으로 생성할 수 있어, 대규모 학습데이터 수집이 어려운 경우나 데 이터 도메인이 계속 변화하는 경우와 같이 학습 데이터를 확보하기 어려운 상황에서도 높은 정확도를 가진 고성 능의 학생 모델을 학습시킬 수 있다. 본 발명은 도면에 도시된 실시예를 참고로 하여 설명되었으나 이는 예시적인 것에 불과하며, 당해 기술이 속하 는 분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서 본 발명의 진정한 기술적 보호범위는 아래의 특허청구범위의 기술적 사상에 의하여 정해져야 할 것이다."}
{"patent_id": "10-2023-0080936", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 교사 모델의 사전 지식을 이용한 지식 증류 시스템을 설명한 도면이다. 도 2 및 도 3는 본 발명의 일 실시예에 따라 지식 증류를 수행한 학생 모델과 종래 기술의 학생 모델의 정확도 를 나타낸 도면이다. 도 4는 본 발명의 일 실시예에 따라 생성된 이미지와 종래 기술이 생성한 이미지의 예시를 나타낸 도면이다."}
