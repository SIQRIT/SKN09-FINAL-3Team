{"patent_id": "10-2023-0118383", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0035853", "출원번호": "10-2023-0118383", "발명의 명칭": "데이터 분류 장치 및 데이터 분류 방법, 데이터 분류를 위한 학습 방법", "출원인": "성균관대학교산학협력단", "발명자": "이채규"}}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "데이터 분류 장치의 데이터 분류를 위한 학습 방법에 있어서,레이블(label)된 제1 학습용 데이터 그룹으로부터 제1 학습결과 데이터를 출력하도록 제1 신경망을 사전 학습(pre-training)시키는 단계;레이블된 제2 학습용 데이터 그룹으로부터 제2 학습결과 데이터를 출력하도록 제2 신경망을 사전 학습시키는 단계;언레이블(unlabel)된 학습용 데이터 그룹을 획득하고, 상기 언레이블된 학습용 데이터 그룹으로부터 의사(pseudo) 레이블 데이터를 생성하는 단계; 및상기 의사 레이블 데이터를 기초로 상기 제1 신경망과 상기 제2 신경망이 테스트 데이터 그룹을 서로 교번되게분류하여 제3 학습결과 데이터를 각각 출력하도록 상기 제1 신경망과 상기 제2 신경망을 능동 학습(activelearning)시키는 단계;를 포함하는데이터 분류를 위한 학습 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 의사 레이블 데이터를 생성하는 단계는,상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이한지 여부를판단하는 단계;상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하면 상기 제1학습결과 데이터의 예측 신뢰도가 임계값보다 높고 상기 제2 학습결과 데이터의 예측 신뢰도가 상기 임계값보다낮은 조건을 만족하는 제1 의사 레이블 데이터를 생성하는 단계; 및상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하고, 상기 제2 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 높고 상기 제1 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만족하는 제2 의사 레이블 데이터를 생성하는 단계;를 포함하는데이터 분류를 위한 학습 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 능동 학습시키는 단계는,상기 제1 신경망의 상기 능동 학습시의 에포크(epoch)가 홀수 에포크인지 짝수 에포크인지 여부를 여부를 판단하는 단계;상기 홀수 에포크이면 상기 제1 의사 레이블 데이터를 학습 데이터로 이용하여 상기 제1 신경망을 학습시키는단계; 및상기 짝수 에포크이면 상기 제2 의사 레이블 데이터를 학습 데이터로 이용하여 상기 제1 신경망을 학습시키는단계;를 포함하는공개특허 10-2025-0035853-3-데이터 분류를 위한 학습 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 능동 학습시키는 단계는,상기 제2 신경망의 상기 능동 학습시의 에포크가 홀수 에포크인지 짝수 에포크인지 여부를 여부를 판단하는 단계;상기 홀수 에포크이면 상기 제2 의사 레이블 데이터를 학습 데이터로 이용하여 상기 제2 신경망을 학습시키는단계; 및상기 짝수 에포크이면 상기 제1 의사 레이블 데이터를 학습 데이터로 이용하여 상기 제2 신경망을 학습시키는단계;를 포함하는데이터 분류를 위한 학습 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 제1 신경망과 상기 제2 신경망을 능동 학습시킨 후 각각의 학습용 데이터 그룹을 갱신하는 단계를 더 포함하는데이터 분류를 위한 학습 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 제1 신경망과 상기 제2 신경망은 상기 테스트 데이터 그룹에 대해 적어도 50%의 정확도를 갖도록 상기 레이블된 제1 학습용 데이터 그룹과 상기 레이블된 제2 학습용 데이터 그룹의 비율을 조정하여 학습시키는데이터 분류를 위한 학습 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 레이블된 제1 학습용 데이터 그룹과 상기 레이블된 제2 학습용 데이터 그룹은 서로 다른 이미지 데이터를각각 포함하는데이터 분류를 위한 학습 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "데이터 그룹을 획득하는 획득부;기 학습된 제1 신경망과 제2 신경망을 실행하기 위한 명령어를 포함하는 저장부; 및상기 명령어를 수행함으로써 상기 데이터 그룹으로부터 의사 레이블 데이터를 생성하고, 상기 의사 레이블 데이터를 기초로 상기 제1 신경망과 상기 제2 신경망이 상기 데이터 그룹을 서로 교번되게 분류하도록 처리하는 처리부;를 포함하는공개특허 10-2025-0035853-4-데이터 분류 장치."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 제1 신경망은 레이블된 제1 학습용 데이터 그룹을 사전 학습하여 제1 학습결과 데이터를 출력하도록 학습되고, 상기 제2 신경망은 레이블된 제2 학습용 데이터 그룹을 사전 학습하여 제2 학습결과 데이터를 출력하도록학습되는데이터 분류 장치."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 의사 레이블 데이터는,상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하면서 상기제1 학습결과 데이터의 예측 신뢰도가 임계값보다 높고 상기 제2 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만족하는 제1 의사 레이블 데이터와,상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하면서 상기제2 학습결과 데이터의 예측 신뢰도가 임계값보다 높고 상기 제1 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만족하는 제2 의사 레이블 데이터를 포함하는데이터 분류 장치."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 제1 신경망은 학습시의 에포크가 홀수 에포크인 경우에 상기 제1 의사 레이블 데이터를 학습 데이터로 이용하여 학습되고,상기 에포크가 짝수 에포크인 경우에 상기 제2 의사 레이블 데이터를 학습 데이터로 이용하여 학습되는데이터 분류 장치."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서,상기 제2 신경망은 학습시의 에포크가 홀수 에포크인 경우에 상기 제2 의사 레이블 데이터를 학습 데이터로 이용하여 학습되고,상기 에포크가 짝수 에포크인 경우에 상기 제1 의사 레이블 데이터를 학습 데이터로 이용하여 학습되는데이터 분류 장치."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 9 항에 있어서,상기 제1 신경망은 상기 데이터 그룹에 대해 적어도 50%의 정확도를 갖도록 상기 레이블된 제1 학습용 데이터공개특허 10-2025-0035853-5-그룹의 비율을 조정하여 학습되고,상기 제2 신경망은 상기 데이터 그룹에 대해 적어도 50%의 정확도를 갖도록 상기 레이블된 제2 학습용 데이터그룹의 비율을 조정하여 학습되는데이터 분류 장치."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 9 항에 있어서,상기 제1 학습용 데이터 그룹과 상기 제2 학습용 데이터 그룹은 서로 다른 이미지 데이터를 각각 포함하는데이터 분류 장치."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "획득부, 저장부 및 처리부를 포함하는 데이터 분류 장치의 데이터 분류 방법에 있어서,상기 획득부를 통해 데이터 그룹을 획득하는 단계;상기 처리부가 상기 데이터 그룹을 기초로 의사 레이블 데이터를 생성하는 단계; 및상기 처리부가 상기 의사 레이블 데이터를 기초로 상기 저장부 내에 기 학습된 제1 신경망과 제2 신경망이 상기데이터 그룹을 서로 교번되게 분류하도록 처리하는 단계;를 포함하는데이터 분류 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 제1 신경망은 레이블된 제1 학습용 데이터 그룹을 사전 학습하여 제1 학습결과 데이터를 출력하도록 학습되고, 상기 제2 신경망은 레이블된 제2 학습용 데이터 그룹을 사전 학습하여 제2 학습결과 데이터를 출력하도록학습되는데이터 분류 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 의사 레이블 데이터는,상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하면서 상기제1 학습결과 데이터의 예측 신뢰도가 임계값보다 높고 상기 제2 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만족하는 제1 의사 레이블 데이터와,상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하면서 상기제2 학습결과 데이터의 예측 신뢰도가 임계값보다 높고 상기 제1 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만족하는 제2 의사 레이블 데이터를 포함하는데이터 분류 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "공개특허 10-2025-0035853-6-제 17 항에 있어서,상기 제1 신경망은 학습시의 에포크가 홀수 에포크인 경우에 상기 제1 의사 레이블 데이터를 학습 데이터로 이용하여 학습되고,상기 에포크가 짝수 에포크인 경우에 상기 제2 의사 레이블 데이터를 학습 데이터로 이용하여 학습되는데이터 분류 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 17 항에 있어서,상기 제2 신경망은 학습시의 에포크가 홀수 에포크인 경우에 상기 제2 의사 레이블 데이터를 학습 데이터로 이용하여 학습되고,상기 에포크가 짝수 에포크인 경우에 상기 제1 의사 레이블 데이터를 학습 데이터로 이용하여 학습되는데이터 분류 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 16 항에 있어서,상기 제1 신경망은 상기 데이터 그룹에 대해 적어도 50%의 정확도를 갖도록 상기 레이블된 제1 학습용 데이터그룹의 비율을 조정하여 학습되고,상기 제2 신경망은 상기 데이터 그룹에 대해 적어도 50%의 정확도를 갖도록 상기 레이블된 제2 학습용 데이터그룹의 비율을 조정하여 학습되는데이터 분류 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 16 항에 있어서,상기 제1 학습용 데이터 그룹과 상기 제2 학습용 데이터 그룹은 서로 다른 이미지 데이터를 각각 포함하는데이터 분류 방법."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "컴퓨터 프로그램을 저장하고 있는 컴퓨터 판독 가능 기록매체로서,상기 컴퓨터 프로그램은,획득부, 저장부 및 처리부를 포함하는 데이터 분류 장치의 데이터 분류 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함하고,상기 방법은,상기 획득부를 통해 데이터 그룹을 획득하는 단계;상기 처리부가 상기 데이터 그룹을 기초로 의사 레이블 데이터를 생성하는 단계; 및상기 처리부가 상기 의사 레이블 데이터를 기초로 상기 저장부 내에 기 학습된 제1 신경망과 제2 신경망이 상기데이터 그룹을 서로 교번되게 분류하도록 처리하는 단계;를 포함하는공개특허 10-2025-0035853-7-컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2023-0118383", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "컴퓨터 판독 가능 기록매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램은,데이터 분류 장치의 데이터 분류를 위한 학습 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함하고,상기 방법은,레이블된 제1 학습용 데이터 그룹으로부터 제1 학습결과 데이터를 출력하도록 제1 신경망을 사전 학습시키는 단계;레이블된 제2 학습용 데이터 그룹으로부터 제2 학습결과 데이터를 출력하도록 제2 신경망을 사전 학습시키는 단계;언레이블된 학습용 데이터 그룹을 획득하고, 상기 언레이블된 학습용 데이터 그룹으로부터 의사 레이블 데이터를 생성하는 단계; 및상기 의사 레이블 데이터를 기초로 상기 제1 신경망과 상기 제2 신경망이 테스트 데이터 그룹을 서로 교번되게분류하여 제3 학습결과 데이터를 각각 출력하도록 상기 제1 신경망과 상기 제2 신경망을 능동 학습시키는 단계;를 포함하는기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0118383", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 데이터 분류 장치의 데이터 분류를 위한 학습에 관한 것으로, 레이블(label)된 제1 학습용 데이터 그 룹으로부터 제1 학습결과 데이터를 출력하도록 제1 신경망을 사전 학습(pre-training)시키고, 레이블된 제2 학습 용 데이터 그룹으로부터 제2 학습결과 데이터를 출력하도록 제2 신경망을 사전 학습시키며, 언레이블(unlabel)된 학습용 데이터 그룹을 획득하고, 언레이블된 학습용 데이터 그룹으로부터 의사(pseudo) 레이블 데이터를 생성하 고, 의사 레이블 데이터를 기초로 제1 신경망과 제2 신경망이 테스트 데이터 그룹을 서로 교번되게 분류하여 제3 학습결과 데이터를 각각 출력하도록 제1 신경망과 제2 신경망을 능동 학습(active learning)시키는 것을 특징으 로 한다."}
{"patent_id": "10-2023-0118383", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝(deep learning) 모델을 활용한 데이터 분류 기술과 관련이 있고, 특히 데이터 분류를 위한 데 이터 레이블링(labeling) 기술과 관련이 있다."}
{"patent_id": "10-2023-0118383", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술의 발전으로 인해, 다양한 분야에서 인공지능 모델을 활용하고자 하는 요구가 증가하고 있다. 하 지만, 딥러닝 기반의 인공지능 모델을 학습시키기 위해서는 충분한 학습 데이터가 필요하며, 수작업으로 학습 데이터를 생성하는 것은 비용과 시간이 많이 소요되는 대표적인 작업 중 하나이다. 기존의 데이터 레이블링 기술에서는 수작업으로 데이터에 레이블을 부여하는 방식이 일반적이었다. 그러나, 이 러한 방식은 시간과 인력의 비용이 많이 소요되는 문제가 있다. 특히, 대규모 데이터 셋을 처리하는 경우에 레 이블링 작업이 현실적으로 어렵고 비용이 많이 소요된다. 또한, 인간의 주관적인 판단이나 실수로 인해 잘못된 레이블이 부여될 수도 있다. 이러한 문제들은 인공지능 모델의 성능에 직접적인 영향을 미칠 수 있다. 한편, 딥러닝을 활용하여 학습 데이터를 자동으로 생성하고 효율적으로 레이블링하는 기법이 능동형 학습과 반 지도 학습 분야에서 다각도로 연구 개발되고 있으며, 이는 인간 주석자의 역할을 딥러닝 모델로 대체하는데 주 안점을 두고 있다."}
{"patent_id": "10-2023-0118383", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "상술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지 기술이라 할 수는 없다. 선행기술문헌특허문헌 (특허문헌 0001) 공개특허공보 제10-2020-0095334호 (2020년08월10일 공개)"}
{"patent_id": "10-2023-0118383", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예에서는, 딥러닝 모델을 활용한 데이터 분류 과정에서 데이터 레이블링 작업의 효율성과 정확성 을 높일 수 있는 기술을 제안하고자 한다. 본 발명의 실시예에서는, 사전 학습(pre-training)과 언레이블(unlabel) 데이터에 대한 능동 학습(active learning)을 결합한 데이터 분류 기술을 제안하고자 한다. 본 발명이 해결하고자 하는 과제는 상기에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 해결하고 자 하는 과제는 아래의 기재들로부터 본 발명이 속하는 통상의 지식을 가진 자에 의해 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0118383", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 데이터 분류 장치의 데이터 분류를 위한 학습 방법에 있어서, 레이블(label)된 제1 학습용 데이터 그룹으로부터 제1 학습결과 데이터를 출력하도록 제1 신경망을 사전 학습(pre-training)시키는 단계; 레이블된 제2 학습용 데이터 그룹으로부터 제2 학습결과 데이터를 출력하도록 제2 신경망을 사전 학습시 키는 단계; 언레이블(unlabel)된 학습용 데이터 그룹을 획득하고, 상기 언레이블된 학습용 데이터 그룹으로부터 의사(pseudo) 레이블 데이터를 생성하는 단계; 및 상기 의사 레이블 데이터를 기초로 상기 제1 신경망과 상기 제2 신경망이 테스트 데이터 그룹을 서로 교번되게 분류하여 제3 학습결과 데이터를 각각 출력하도록 상기 제1 신경망과 상기 제2 신경망을 능동 학습(active learning)시키는 단계;를 포함하는 데이터 분류를 위한 학습 방 법을 제공할 수 있다. 여기서, 상기 의사 레이블 데이터를 생성하는 단계는, 상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학 습결과 데이터의 예측 신뢰도가 서로 상이한지 여부를 판단하는 단계; 상기 제1 학습결과 데이터의 예측 신뢰도 와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하면 상기 제1 학습결과 데이터의 예측 신뢰도가 임계 값보다 높고 상기 제2 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만족하는 제1 의사 레이 블 데이터를 생성하는 단계; 및 상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하고, 상기 제2 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 높고 상기 제1 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만족하는 제2 의사 레이블 데이터를 생성하는 단계;를 포 함할 수 있다. 또한, 상기 능동 학습시키는 단계는, 상기 제1 신경망의 상기 능동 학습시의 에포크(epoch)가 홀수 에포크인지 짝수 에포크인지 여부를 여부를 판단하는 단계; 상기 홀수 에포크이면 상기 제1 의사 레이블 데이터를 학습 데 이터로 이용하여 상기 제1 신경망을 학습시키는 단계; 및 상기 짝수 에포크이면 상기 제2 의사 레이블 데이터를 학습 데이터로 이용하여 상기 제1 신경망을 학습시키는 단계;를 포함할 수 있다. 또한, 상기 능동 학습시키는 단계는, 상기 제2 신경망의 상기 능동 학습시의 에포크가 홀수 에포크인지 짝수 에 포크인지 여부를 여부를 판단하는 단계; 상기 홀수 에포크이면 상기 제2 의사 레이블 데이터를 학습 데이터로 이용하여 상기 제2 신경망을 학습시키는 단계; 및 상기 짝수 에포크이면 상기 제1 의사 레이블 데이터를 학습 데이터로 이용하여 상기 제2 신경망을 학습시키는 단계;를 포함할 수 있다. 또한, 상기 방법은, 상기 제1 신경망과 상기 제2 신경망을 능동 학습시킨 후 각각의 학습용 데이터 그룹을 갱신 하는 단계를 더 포함할 수 있다. 또한, 상기 제1 신경망과 상기 제2 신경망은 상기 테스트 데이터 그룹에 대해 적어도 50%의 정확도를 갖도록 상 기 레이블된 제1 학습용 데이터 그룹과 상기 레이블된 제2 학습용 데이터 그룹의 비율을 조정하여 학습시킬 수 있다.또한, 상기 레이블된 제1 학습용 데이터 그룹과 상기 레이블된 제2 학습용 데이터 그룹은 서로 다른 이미지 데 이터를 각각 포함할 수 있다. 본 발명의 실시예에 따르면, 데이터 그룹을 획득하는 획득부; 기 학습된 제1 신경망과 제2 신경망을 실행하기 위한 명령어를 포함하는 저장부; 및 상기 명령어를 수행함으로써 상기 데이터 그룹으로부터 의사 레이블 데이터 를 생성하고, 상기 의사 레이블 데이터를 기초로 상기 제1 신경망과 상기 제2 신경망이 상기 데이터 그룹을 서 로 교번되게 분류하도록 처리하는 처리부;를 포함하는 데이터 분류 장치를 포함할 수 있다. 여기서, 상기 제1 신경망은 레이블된 제1 학습용 데이터 그룹을 사전 학습하여 제1 학습결과 데이터를 출력하도 록 학습되고, 상기 제2 신경망은 레이블된 제2 학습용 데이터 그룹을 사전 학습하여 제2 학습결과 데이터를 출 력하도록 학습될 수 있다. 또한, 상기 의사 레이블 데이터는, 상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예 측 신뢰도가 서로 상이하면서 상기 제1 학습결과 데이터의 예측 신뢰도가 임계값보다 높고 상기 제2 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만족하는 제1 의사 레이블 데이터와, 상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하면서 상기 제2 학습결과 데이터 의 예측 신뢰도가 임계값보다 높고 상기 제1 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만 족하는 제2 의사 레이블 데이터를 포함할 수 있다. 또한, 상기 제1 신경망은 학습시의 에포크가 홀수 에포크인 경우에 상기 제1 의사 레이블 데이터를 학습 데이터 로 이용하여 학습되고, 상기 에포크가 짝수 에포크인 경우에 상기 제2 의사 레이블 데이터를 학습 데이터로 이 용하여 학습될 수 있다. 또한, 상기 제2 신경망은 학습시의 에포크가 홀수 에포크인 경우에 상기 제2 의사 레이블 데이터를 학습 데이터 로 이용하여 학습되고, 상기 에포크가 짝수 에포크인 경우에 상기 제1 의사 레이블 데이터를 학습 데이터로 이 용하여 학습될 수 있다. 또한, 상기 제1 신경망은 상기 데이터 그룹에 대해 적어도 50%의 정확도를 갖도록 상기 레이블된 제1 학습용 데 이터 그룹의 비율을 조정하여 학습되고, 상기 제2 신경망은 상기 데이터 그룹에 대해 적어도 50%의 정확도를 갖 도록 상기 레이블된 제2 학습용 데이터 그룹의 비율을 조정하여 학습될 수 있다. 또한, 상기 제1 학습용 데이터 그룹과 상기 제2 학습용 데이터 그룹은 서로 다른 이미지 데이터를 각각 포함할 수 있다. 본 발명의 실시예에 따르면, 획득부, 저장부 및 처리부를 포함하는 데이터 분류 장치의 데이터 분류 방법에 있 어서, 상기 획득부를 통해 데이터 그룹을 획득하는 단계; 상기 처리부가 상기 데이터 그룹을 기초로 의사 레이 블 데이터를 생성하는 단계; 및 상기 처리부가 상기 의사 레이블 데이터를 기초로 상기 저장부 내에 기 학습된 제1 신경망과 제2 신경망이 상기 데이터 그룹을 서로 교번되게 분류하도록 처리하는 단계;를 포함하는 데이터 분류 방법을 제공할 수 있다. 여기서, 상기 제1 신경망은 레이블된 제1 학습용 데이터 그룹을 사전 학습하여 제1 학습결과 데이터를 출력하도 록 학습되고, 상기 제2 신경망은 레이블된 제2 학습용 데이터 그룹을 사전 학습하여 제2 학습결과 데이터를 출 력하도록 학습될 수 있다. 또한, 상기 의사 레이블 데이터는, 상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예 측 신뢰도가 서로 상이하면서 상기 제1 학습결과 데이터의 예측 신뢰도가 임계값보다 높고 상기 제2 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만족하는 제1 의사 레이블 데이터와, 상기 제1 학습결과 데이터의 예측 신뢰도와 상기 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하면서 상기 제2 학습결과 데이터 의 예측 신뢰도가 임계값보다 높고 상기 제1 학습결과 데이터의 예측 신뢰도가 상기 임계값보다 낮은 조건을 만 족하는 제2 의사 레이블 데이터를 포함할 수 있다. 또한, 상기 제1 신경망은 학습시의 에포크가 홀수 에포크인 경우에 상기 제1 의사 레이블 데이터를 학습 데이터 로 이용하여 학습되고, 상기 에포크가 짝수 에포크인 경우에 상기 제2 의사 레이블 데이터를 학습 데이터로 이 용하여 학습될 수 있다. 또한, 상기 제2 신경망은 학습시의 에포크가 홀수 에포크인 경우에 상기 제2 의사 레이블 데이터를 학습 데이터 로 이용하여 학습되고, 상기 에포크가 짝수 에포크인 경우에 상기 제1 의사 레이블 데이터를 학습 데이터로 이용하여 학습될 수 있다. 또한, 상기 제1 신경망은 상기 데이터 그룹에 대해 적어도 50%의 정확도를 갖도록 상기 레이블된 제1 학습용 데 이터 그룹의 비율을 조정하여 학습되고, 상기 제2 신경망은 상기 데이터 그룹에 대해 적어도 50%의 정확도를 갖 도록 상기 레이블된 제2 학습용 데이터 그룹의 비율을 조정하여 학습될 수 있다. 또한, 상기 제1 학습용 데이터 그룹과 상기 제2 학습용 데이터 그룹은 서로 다른 이미지 데이터를 각각 포함할 수 있다. 본 발명의 실시예에 따르면, 컴퓨터 프로그램을 저장하고 있는 컴퓨터 판독 가능 기록매체로서, 상기 컴퓨터 프 로그램은, 획득부, 저장부 및 처리부를 포함하는 데이터 분류 장치의 데이터 분류 방법을 프로세서가 수행하도 록 하기 위한 명령어를 포함하고, 상기 방법은, 상기 획득부를 통해 데이터 그룹을 획득하는 단계; 상기 처리부 가 상기 데이터 그룹을 기초로 의사 레이블 데이터를 생성하는 단계; 및 상기 처리부가 상기 의사 레이블 데이 터를 기초로 상기 저장부 내에 기 학습된 제1 신경망과 제2 신경망이 상기 데이터 그룹을 서로 교번되게 분류하 도록 처리하는 단계;를 포함할 수 있다. 본 발명의 실시예에 따르면, 컴퓨터 판독 가능 기록매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그 램은, 데이터 분류 장치의 데이터 분류를 위한 학습 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함하 고, 상기 방법은, 레이블된 제1 학습용 데이터 그룹으로부터 제1 학습결과 데이터를 출력하도록 제1 신경망을 사전 학습시키는 단계; 레이블된 제2 학습용 데이터 그룹으로부터 제2 학습결과 데이터를 출력하도록 제2 신경 망을 사전 학습시키는 단계; 언레이블된 학습용 데이터 그룹을 획득하고, 상기 언레이블된 학습용 데이터 그룹 으로부터 의사 레이블 데이터를 생성하는 단계; 및 상기 의사 레이블 데이터를 기초로 상기 제1 신경망과 상기 제2 신경망이 테스트 데이터 그룹을 서로 교번되게 분류하여 제3 학습결과 데이터를 각각 출력하도록 상기 제1 신경망과 상기 제2 신경망을 능동 학습시키는 단계;를 포함할 수 있다."}
{"patent_id": "10-2023-0118383", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 의하면, 기존의 수작업 방식에 의존하지 않고 자동화된 레이블링 기술을 활용하여 대량의 데이터를 빠르게 생성할 수 있다. 이를 통해 연구 개발자들은 더 많은 데이터를 보다 쉽고 신속하게 생성할 수 있으며, 인공지능 모델의 학습 효과를 극대화할 수 있다. 또한, 본 발명의 실시예에 의하면, 오토레이블링 툴을 통해 자동으로 레이블을 부여함으로써 인력과 시간을 절 감할 수 있다. 수백 만 개에서 수십 억 개에 이르는 대규모 데이터 셋을 수작업으로 레이블링하는 것은 상당한 비용이 들어가는 작업이다. 따라서, 비용 측면에서도 레이블링 작업을 효율화하고 비용을 절감할 수 있는 자동 레이블링 기술과 도구의 필요성이 크게 증가하고 있다. 또한, 본 발명의 실시예에 의하면, 오토레이블링 툴을 사용하여 모델이 자동으로 데이터에 레이블을 부여함으로 써 인간의 실수나 주관적인 판단으로 인한 잘못된 레이블링을 최소화할 수 있다. 이를 통해 인공지능 모델의 정 확도와 성능을 향상시킬 수 있다. 또한, 본 발명의 실시예에 의하면, 레이블링 작업의 효율성과 정확성이 향상되면 더 많은 데이터를 생성하고 활 용할 수 있다. 이는 연구 개발자들에게 다양한 분야에서 인공지능 모델을 개발하고 적용할 수 있는 기회를 제공 한다. 또한, 기업들은 더욱 효과적으로 데이터를 생성하고 활용하여 제품 및 서비스를 개발할 수 있다. 또한, 본 발명의 실시예에 의하면, 효율적이고 정확한 데이터 레이블링 작업을 통해 학습 데이터 셋의 품질을 향상시킬 수 있다. 이는 인공지능 모델의 성능을 향상시키고 실제 문제에 대한 예측 능력을 향상시킬 수 있다. 또한, 본 발명의 실시예에 의하면, 레이블링 작업의 자동화와 효율화를 통한 연구와 개발은 인공지능 기술의 실 용적인 활용을 촉진시키고, 기업들은 더욱 효과적으로 데이터를 생성하고 활용하여 경쟁력을 강화할 수 있게 한 다. 이를 통해 다양한 분야에서 인공지능 기술을 보다 실용적으로 활용할 수 있으며, 산업 및 사회의 발전을 촉 진시킬 수 있다."}
{"patent_id": "10-2023-0118383", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 다 양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명의 범주 는 청구항에 의해 정의될 뿐이다. 본 발명의 실시예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명은 본 발명의 실시예들을 설 명함에 있어 실제로 필요한 경우 외에는 생략될 것이다. 그리고 후술되는 용어들은 본 발명의 실시예에서의 기 능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 본 발명의 실시예에서는, 데이터 레이블링 작업의 효율성과 정확성을 향상시키고, 기존의 수작업 방식에 의존하 지 않고도 자동화된 레이블링 기술을 활용하여 대량의 학습 데이터를 빠르게 생성할 수 있는 데이터 분류 기술 을 제안하고자 한다. 이를 통해 더 많은 데이터를 보다 쉽고 신속하게 생성할 수 있으며, 인공지능 모델의 학습 효과를 극대화할 수 있다. 또한, 본 발명의 실시예에서는, 능동 학습과 오토레이블링 툴을 활용하여 데이터 레이블링 작업의 효율성과 정 확성을 개선할 수 있으며, 능동 학습을 통해 핵심 데이터를 자동으로 선택하고, 오토레이블링 툴을 통해 자동으 로 레이블을 부여함으로써 데이터 레이블링 작업을 자동화하고 비용과 시간을 절감할 수 있는 데이터 분류 기술 을 제안하고자 한다. 이를 통해 연구 개발자들은 더욱 효과적으로 데이터를 생성하고 인공지능 모델의 개발에 활용할 수 있다. 또한, 본 발명의 실시예에서는, 레이블링 작업의 효율성과 정확성을 개선하는 것뿐만 아니라, 학습 데이터의 수 가 증가하고 다양한 분야에서 인공지능 기술이 요구되는 현대 사회에서 필요한 학습 데이터를 효율적으로 생성 하고 관리할 수 있는 시스템을 제안하고자 한다. 또한, 본 발명의 실시예에서는, 데이터 레이블링 작업의 비용을 절감하고 인공지능 모델의 성능을 향상시킴으로 써 기업들은 더욱 효과적으로 데이터를 생성 및 활용하여 경쟁력을 강화할 수 있는 데이터 분류 기술을 제안하 고자 한다. 이는 산업 및 사회 전반에 걸친 데이터 활용의 중요성을 강조하는 요소로 작용할 수 있다. 본 발명의 실시예에서 다루고 있는 주요 용어들을 정리하면 다음과 같다. 오토레이블링 툴; 오토레이블링 툴은 인공지능 모델이 자동으로 데이터에 레이블을 부여하는 기술이다. 이를 통해 수작업으로 레 이블링하는 시간과 비용을 대폭으로 줄일 수 있다. 오토레이블링 툴은 딥러닝 모델을 활용하여 이미지, 텍스트, 오디오 등 다양한 형식의 데이터에 자동으로 레이블을 부여할 수 있다. 이를 통해 인간의 개입을 최소화하고 빠 른 속도로 대량의 데이터를 레이블링할 수 있다. 능동 학습; 능동 학습은 인공지능 모델이 레이블링에 필요한 핵심적인 샘플을 스스로 선택하고, 인간 전문가가 해당 샘플에 레이블을 부여하는 방식으로 학습을 진행하는 기술이다. 능동 학습은 모델의 불확실성을 측정하고, 해당 불확실 성이 높은 데이터를 선별하여 레이블링에 사용한다. 이를 통해 수작업으로 레이블링해야 하는 데이터의 양을 줄 이고 모델의 성능과 정확도를 향상시킬 수 있다. 학습 데이터 셋; 본 발명은 적절한 학습 데이터 셋의 구성을 위해 레이블이 있는 데이터와 레이블이 없는 데이터를 활용한다. 레 이블이 있는 데이터를 통해 딥러닝 모델을 사전 학습시키고, 레이블이 없는 데이터를 활용하여 능동 학습과 오 토레이블링을 수행한다. 데이터의 다양성과 균형성을 고려하여 적절한 데이터 셋을 구성하며, 필요에 따라 추가 적인 데이터 수집과 전 처리를 수행할 수 있다. 학습 모델; 본 발명은 딥러닝 모델을 활용하여 데이터 레이블링 작업을 수행한다. 예를 들어, 이미지 데이터의 경우 EfficientNet-B0와 같은 딥러닝 모델을 사용하여 객체 검출, 분할, 분류 등의 작업을 자동으로 수행한다. 학습 모델은 오토레이블링 툴과 능동 학습 기능을 포함하여 데이터에 자동으로 레이블을 부여하고, 학습의 진행 과정 에서 모델의 성능을 향상시키기 위해 계속해서 업데이트 및 개선될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예에 대해 상세히 설명하기로 한다. 도 1은 본 발명의 실시예에 따른 데이터 분류 방법을 수행하거나, 데이터 분류를 위한 학습 방법을 수행하기 위 한 데이터 분류 장치의 기능을 설명하기 위한 블록도이다. 도 1에 도시한 바와 같이, 데이터 분류 장치는 획득부, 처리부 및 저장부를 포함할 수 있 다. 획득부는 데이터 분류를 위한 데이터 그룹 또는 데이터 학습을 위한 데이터 그룹을 획득할 수 있다. 이러 한 데이터 그룹은, 예를 들어 사물, 동식물 등과 같은 여러 가지 다양한 객체들에 대한 이미지(image)들을 포함 할 수 있다. 처리부는 획득부를 통해 획득되는 데이터 그룹으로부터 의사 레이블 데이터를 생성하고, 저장부(13 0)에 포함된 신경망이 데이터 그룹을 서로 교번되게 분류하도록 처리할 수 있다. 이를 위해 처리부는 학습 용 데이터 그룹으로부터 학습결과 데이터를 출력하도록 신경망을 학습시킬 수 있으며, 생성된 의사 레이블 데이 터를 기초로 신경망이 테스트 데이터 그룹을 서로 교번되게 분류하여 학습결과 데이터를 각각 출력하도록 신경 망을 학습시킬 수 있다. 이러한 처리부는, 예를 들어 마이크로프로세서(microprocessor) 기반의 컴퓨팅 장 치를 포함할 수 있다. 저장부는 획득부를 통해 획득되는 데이터 그룹으로부터 데이터를 분류하도록 학습되는 신경망을 포함 할 수 있다. 이러한 신경망은, 예를 들어 데이터 분류 장치의 데이터 분류 프로그램 내에 포함될 수 있으 며, 저장부는 이 데이터 분류 프로그램과 데이터 분류 프로그램의 실행에 필요한 정보들을 저장할 수 있다. 이러한 저장부는 컴퓨터 시스템에 의해 읽혀질 수 있는 데이터가 저장되는 기록 장치, 예를 들어 ROM(read only memory), RAM(random access memory) 등을 포함할 수 있으며, 특정 기록 장치에 한정되지 않는 다. 저장부 내의 데이터 분류 프로그램 및 실행 정보들은 필요에 따라 처리부에 의해 로드될 수 있다. 또한, 데이터 분류 프로그램은 도시 생략된 전처리부를 더 포함할 수도 있다. 전처리부는 처리부에서 데이 터를 분류하기 전에 데이터 그룹의 임의의 이미지에 대한 전처리를 수행하는 수단으로서, 이는 획득된 데이터그룹으로부터 특성 정보를 예측하는 정확도를 향상시키기 위함이다. 이러한 전처리부는 획득된 이미지 내에서 특성 정보에 해당하는 영역을 크롭(crop)하여 크롭된 이미지를 생성하고, 크롭된 이미지에 히스토그램 평활화 기법 등을 적용하여 전처리 이미지를 생성할 수 있다. 다만, 이러한 전처리부는 본 발명의 실시예에 따른 데이 터 분류 장치의 필수 구성 요소는 아니며, 필요에 따라 전처리부 없이 데이터 분류 결과를 출력하도록 구 현할 수도 있다. 도 2는 도 1의 데이터 분류 장치의 저장부 내의 신경망 구조를 예시적으로 설명하기 위한 블록도이다. 도 2에 도시한 바와 같이, 데이터 분류 장치의 신경망은, 언레이블 학습용 데이터 그룹, 제1 신경망 (134a), 제2 신경망(134b), 제1 학습용 데이터 그룹(136a) 및 제2 학습용 데이터 그룹(136b)을 포함할 수 있다. 도 2에 도시한 바와 같이, 제1 신경망(134a)과 제2 신경망(134b)은 기 학습된 신경망이며, 저장부는 이러 한 제1 신경망(134a)과 제2 신경망(134b)을 실행하기 위한 명령어를 포함하고 있다. 처리부는 이 명령어를 수행함으로써 획득부를 통해 획득되는 데이터 그룹으로부터 의사 레이블 데이 터를 생성하고, 생성된 의사 레이블 데이터를 기초로 제1 신경망(134a)과 제2 신경망(134b)이 데이터 그룹을 서 로 교번되게 분류하도록 처리할 수 있다. 여기서, 제1 신경망(134a)은 레이블된 제1 학습용 데이터 그룹(136a)을 사전 학습하여 제1 학습결과 데이터를 출력하도록 학습되고, 제2 신경망(134b)은 레이블된 제2 학습용 데이터 그룹(136b)을 사전 학습하여 제2 학습결 과 데이터를 출력하도록 학습될 수 있다. 의사 레이블 데이터는, 제1 학습결과 데이터의 예측 신뢰도와 제2 학습결과 데이터의 예측 신뢰도가 서로 상이 하면서 제1 학습결과 데이터의 예측 신뢰도가 임계값보다 높고 제2 학습결과 데이터의 예측 신뢰도가 임계값보 다 낮은 조건을 만족하는 제1 의사 레이블 데이터와, 제1 학습결과 데이터의 예측 신뢰도와 제2 학습결과 데이 터의 예측 신뢰도가 서로 상이하면서 제2 학습결과 데이터의 예측 신뢰도가 임계값보다 높고 제1 학습결과 데이 터의 예측 신뢰도가 임계값보다 낮은 조건을 만족하는 제2 의사 레이블 데이터를 포함할 수 있다. 제1 신경망은(134a) 학습시의 에포크(epoch)가 홀수 에포크인 경우에 제1 의사 레이블 데이터를 학습 데이터로 이용하여 학습되고, 에포크가 짝수 에포크인 경우에 제2 의사 레이블 데이터를 학습 데이터로 이용하여 학습될 수 있다. 또한, 제2 신경망(134b)은 학습시의 에포크가 홀수 에포크인 경우에 제2 의사 레이블 데이터를 학습 데이터로 이용하여 학습되고, 에포크가 짝수 에포크인 경우에 제1 의사 레이블 데이터를 학습 데이터로 이용하 여 학습될 수 있다. 이에 따라, 본 발명의 실시예에 따른 데이터 분류 장치는, 획득부를 통해 데이터 그룹을 획득하게 되 면, 처리부가 데이터 그룹을 기초로 의사 레이블 데이터를 생성하고, 생성된 의사 레이블 데이터를 기초로 도 2의 사전 학습된 제1 신경망(134a)과 제2 신경망(134b)이 데이터 그룹을 서로 교번되게 분류하도록 처리할 수 있다. 도 3은 도 1의 데이터 분류 장치의 데이터 분류를 위한 학습 방법, 예컨대 사전 학습 방법을 예시적으로 설명하기 위한 블록도이다. 사전 학습 시에는 제1 신경망(134a)은 레이블된 제1 학습용 데이터 그룹(136a)으로부터 제1 학습결과 데이터를 출력하도록 학습될 수 있다. 또한, 제2 신경망(134b)은 레이블된 제2 학습용 데이터 그룹(136b)으로부터 제2 학습결과 데이터를 출력하도록 학습될 수 있다. 이때, 제1 신경망(134a)과 제2 신경망(134b)은 테스트 데이터 그룹에 대해 적어도 50%의 정확도를 갖도록 레이블된 제1 학습용 데이터 그룹(136a)과 레이블된 제2 학습용 데이터 그룹(136b)의 비율을 조정하여 학습될 수 있다. 또한, 테스트 데이터 그룹은 전체 데이터 셋의 적어도 20%를 차지하도록 설정될 수 있다. 도 4는 도 1의 데이터 분류 장치의 데이터 분류를 위한 학습 방법, 예컨대 능동 학습 방법을 예시적으로 설명하기 위한 블록도이다. 제1 신경망(134a)과 제2 신경망(134b)을 통해 사전 학습이 수행되면, 획득부는 언레이블된 학습용 데이터 그룹을 획득하고, 언레이블된 학습용 데이터 그룹으로부터 의사 레이블 데이터를 생성할 수 있다. 이러한 의사 레이블 데이터가 생성되면, 데이터 분류 장치는 생성된 의사 레이블 데이터를 기초로 제1 신 경망(134a)과 제2 신경망(134b)이 테스트 데이터 그룹을 서로 교번되게 분류하여 제3 학습결과 데이터를 각각 출력하도록 제1 신경망(134a)과 제2 신경망(134b)을 능동 학습시킬 수 있다. 도 5는 도 4의 능동 학습 방법에서 의사 레이블 데이터를 생성하고 학습용 데이터 그룹을 갱신하는 과정의 상세 흐름도이다. 도 5에 도시한 바와 같이, 획득부를 통해 언레이블된 학습용 데이터 그룹이 획득되면(S100), 처리부 는 획득된 언레이블된 학습용 데이터 그룹을 기초로 의사 레이블 데이터를 생성할 수 있다(S102). 여기서, 의사 레이블 데이터를 생성하는 단계는, 제1 학습결과 데이터의 예측 신뢰도와 제2 학습결과 데이터의 예측 신뢰도가 서로 상이한지 여부를 판단하는 단계; 제1 학습결과 데이터의 예측 신뢰도와 제2 학습결과 데이 터의 예측 신뢰도가 서로 상이하면 제1 학습결과 데이터의 예측 신뢰도가 임계값보다 높고 제2 학습결과 데이터 의 예측 신뢰도가 임계값보다 낮은 조건을 만족하는 제1 의사 레이블 데이터를 생성하는 단계; 및 제1 학습결과 데이터의 예측 신뢰도와 제2 학습결과 데이터의 예측 신뢰도가 서로 상이하고, 제2 학습결과 데이터의 예측 신 뢰도가 임계값보다 높고 제1 학습결과 데이터의 예측 신뢰도가 임계값보다 낮은 조건을 만족하는 제2 의사 레이 블 데이터를 생성하는 단계;를 포함할 수 있다. 의사 레이블 데이터가 생성되면, 처리부는 각각의 신경망(134a, 134b)의 학습시의 에포크에 따라 능동 학 습을 수행할 수 있다. 구체적으로, 능동 학습시키는 단계는, 제1 신경망(134a)의 능동 학습시의 에포크가 홀수 에포크인지 짝수 에포 크인지 여부를 여부를 판단하는 단계(S104); 홀수 에포크이면 제1 의사 레이블 데이터를 학습 데이터로 이용하 여 제1 신경망(134a)을 학습시키는 단계(S106); 및 짝수 에포크이면 제2 의사 레이블 데이터를 학습 데이터로 이용하여 제1 신경망(134a)을 학습시키는 단계(S112);를 포함할 수 있다. 유사하게, 능동 학습시키는 단계는, 제2 신경망(134b)의 능동 학습시의 에포크가 홀수 에포크인지 짝수 에포크 인지 여부를 여부를 판단하는 단계(S104); 홀수 에포크이면 제2 의사 레이블 데이터를 학습 데이터로 이용하여 제2 신경망(134b)을 학습시키는 단계(S106); 및 짝수 에포크이면 제1 의사 레이블 데이터를 학습 데이터로 이용 하여 제2 신경망(134b)을 학습시키는 단계(S112);를 포함할 수 있다. 즉, 본 발명의 실시예에서는 각각의 신경망(134a, 134b)의 학습시의 에포크에 따라 해당 신경망 자신의 의사 레 이블 데이터를 학습 데이터로 이용하거나 상대방 신경망의 의사 레이블 데이터를 학습 데이터로 이용하는 교번 적인 능동 학습을 수행하는 것을 특징으로 한다. 이러한 교번적인 능동 학습이 수행되면, 처리부는 각각의 학습용 데이터 그룹을 갱신할 수 있다(S108). 도 6은 본 발명의 실시예에 따른 데이터 분류 장치의 데이터 분류 방법을 예시적으로 설명하는 블록도이다. 각각의 학습된 신경망(134a, 134b)을 통해 테스트 데이터 그룹을 분류하여 각각의 데이터 분류 결과를 출 력할 수 있다. 이후에 사용자는 각각의 데이터 분류 결과에 대한 정확도를 측정할 수 있으며, 정확도 측정 결과를 토대로 각각 의 모델 중 성능이 더 우수한 모델을 선택하거나 재활용할 수 있다. 도 7은 본 발명의 실시예에 따른 데이터 분류 장치의 데이터 분류를 위한 학습 방법을 예시적으로 설명하 기 위한 개념도이다. 본 발명의 실시예에 따른 학습 방법은 사전 학습 단계와 능동 학습 단계로 크게 구분될 수 있으며, 학습 단계에 서 사용되는 데이터는 아래와 같이 4개의 그룹으로 각각 정의될 수 있다. LA: 사전 학습된 제1 신경망(134a)에 대한 레이블 데이터(제1 학습용 데이터 그룹, 136a) LB: 사전 학습된 제2 신경망(134b)에 대한 레이블 데이터(제2 학습용 데이터 그룹, 136b) T: 정확도를 평가하기 위한 레이블 데이터(테스트 데이터 그룹, 138) U: 능동 학습 수행을 위한 언레이블 데이터(언레이블 학습용 데이터 그룹, 132) 첫 번째 단계에서는 두 개의 신경망 모델(134a, 134b)이 각각의 레이블이 지정된 데이터 그룹에 대해 사전 학습 된다. 이 경우 테스트 데이터 그룹(T)은 전체 데이터 세트의 20%를 차지하고, 사전 학습용 데이터 그룹(LA, LB) 은 각 모델이 T에 대해 50%의 정확도를 갖도록 비율을 조정하여 학습될 수 있다. 두 번째 단계에서는 사전 학습된 각 모델(134a, 134b)이 레이블이 지정되지 않은 데이터 그룹 U에 의사 레이블 을 지정하여 서로 학습할 데이터를 생성하는 능동 학습을 수행할 수 있다. 의사 레이블링 데이터는 레이블링되 지 않은 데이터 그룹 U를 분류할 때 각 모델이 예측한 최고 확률의 클래스 결과가 서로 다르고, 미리 정의된 임 계값과 비교하여 한 모델의 예측 신뢰도가 임계값보다 높고 다른 모델의 예측 신뢰도가 임계값보다 낮은 다음 조건을 만족할 때 생성된다. 이러한 조건은 다음 [수학식 1]과 같이 표현될 수 있다. 수학식 1"}
{"patent_id": "10-2023-0118383", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[수학식 1]에서 PA는 제1 신경망(134a)의 예측 신뢰도이고, PB는 제2 신경망(134b)의 예측 신뢰도를 의미할 수 있다. 또한, δ는 임계값을 의미할 수 있다. 선택된 데이터 중 제1 신경망 모델(134a)의 예측 신뢰도가 높은 데이터 그룹과 제2 신경망 모델(134b)의 예측 신뢰도가 높은 데이터 그룹을 구분하여 모델 학습에 사용한다. 구체적으로, 짝수 에포크에서는 자신의 의사 레이블링된 데이터를 학습 데이터로 사용하고, 홀수 에포크에서는 상대방의 레이블링된 데이터를 학습 데이터로 사용한다. 학습할 때는 미리 학습한 레이블링된 데이터 그룹(LA, LB)을 함께 학습한다. 레이블링되지 않은 데이터 그룹 U는 불변이며, 도 7에서 RA와 RB는 각 에포크마다 새로 갱 신되어 생성된 데이터 그룹을 나타낸다. 본 발명의 실시예에서는 Caltech101 데이터 세트와 EfficientNet-B0을 사용하여 제안한 기법의 실험 결과로 구 성하였다. Caltech101 데이터 셋은 이미지 분류 작업에 널리 사용되는 공개 데이터 셋 중 하나이며, 101개의 서로 다른 카 테고리에 속하는 이미지로 구성되어 있다. Caltech101 데이터 세트는 주로 사물과 동물의 이미지를 포함하고 있다. 각 카테고리에는 최소 80개 이상의 이 미지가 포함되어 있다. 이 데이터 셋은 총 9,144개의 이미지로 구성되어 있으며, 훈련 세트와 테스트 셋으로 나 뉜다. 각 이미지의 크기와 해상도가 다르며 배경, 조명, 회전이 다를 수 있다. 이러한 이미지들은 실제 세계의 이미지 분류 작업을 모방하기 위해 포함되어 있다. Caltech101 데이터 셋은 딥러닝 모델의 성능 평가, 이미지 분류 알고리즘 개발, 전이 학습 등 다양한 컴퓨터 비 전 작업에 사용할 수 있다. 이 데이터 셋은 공개적으로 사용 가능하며 학계 연구자 및 컴퓨터 비전 개발자들이 많이 활용하고 있다.EfficientNet-B0은 신경 아키텍처 검색(NAS)을 통해 탐색된 가장 작은 모델이며 계산 및 매개변수 효율성을 갖 춘 딥 러닝 모델이다. EfficientNet-B0은 이미지 분류 작업을 위해 설계되었으며 다양한 컴퓨터 비전 작업에 적 용할 수 있다. 복합 스케일링: EfficientNet은 복합 스케일링이라는 개념을 사용해 네트워크를 확장한다. 이는 네트워크의 깊 이, 폭, 해상도를 동시에 조정하여 모델의 성능과 효율성을 향상시킨다. EfficientNet-B0은 효율적인 구조를 유 지하면서 모델을 작게 유지한다. EfficientNet 아키텍처: 효율적인 네트워크 구조를 사용하여 계산 및 파라메트릭 효율성을 극대화한다. 심층적 으로 분리 가능한 컨볼루션, 역잔차, 스퀴즈 앤 여기 등의 기법을 활용하여 더 적은 파라미터로 더 많은 표현력 을 얻을 수 있다. 광범위한 애플리케이션: EfficientNet-B0은 이미지 분류, 물체 감지, 분할, 전이 학습 등 다양한 컴퓨터 비전 작업에 활용될 수 있다. 이 모델의 작은 크기와 효율성은 모바일 디바이스나 경량 환경에 배포하기에 적합하다. 도 8은 본 발명의 데이터 분류 장치의 테스트 그룹에 대한 학습 에포크 반복 횟수에 따른 정확도를 예시적 으로 표현한 실험결과 그래프이다. 테스트 그룹 T에서 각 모델의 정확도가 50%에 가까워지도록 훈련 데이터의 비율을 조정하였다. 사전 학습 데이 터 그룹 LA와 LB는 각각 전체 Caltech101 데이터 세트의 20%를 차지하며 서로 다른 이미지 데이터를 가지고 있다. 이 데이터로 모델 A와 B를 50회에 걸쳐 학습시켜 각각의 데이터에 대해 99%의 정확도로 테스트 그룹 T를 분류했으며, 추가 사전 학습 후에도 정확도가 50%에서 크게 벗어나지 않는 것을 확인하였다. 아래 [표 1]은 각 추가 학습 에포크에 대한 테스트 그룹 T의 정확도를 보여주고 있다. 표 1 Epochs 1 2 3 4 5 6 7 8 9 10 EfficientNet A48.7151.1049.3651.6550.0750.5552.4051.0452.2651.38 EfficientNet B49.9550.6749.6349.3551.2751.1850.0650.7350.9451.94 도 9 및 도 10은 도 8의 테스트 그룹에 대해서 조건 별 학습 에포크 반복 횟수에 따른 정확도를 비교한 실험결 과 그래프이다. 각각의 능동적 학습을 수행한 결과는 다음 두 가지 조건의 결과이다. 조건 1: 의사 라벨링된 데이터를 교환하지 않고 상대방의 라벨링된 데이터를 학습에 사용하는 경우. 조건 2: 홀수 에포크에는 자신의 라벨링된 데이터를 사용하고 짝수 에포크에는 상대방의 라벨링된 데이터를 사 용하는 경우. 아래 [표 2]는 조건 1에서 의사 라벨링 데이터를 교환하지 않고 상대방의 라벨링 데이터를 학습에 사용했을 때 테스트 그룹 T의 에포크별 정확도를 보여주고 있으며, 도 9는 이러한 [표 2]를 그래픽으로 표현한 것이다. 표 2 Epochs 2 4 6 8 10 12 14 16 18 20 EfficientNet A56.5661.6362.3761.5862.7261.8962.3462.4362.6062.16 EfficientNet B59.3860.1460.3261.7562.3162.3461.7662.0361.9361.95 [표 2]와 도 9에 나타난 바와 같이, 7개의 에포크가 지나면 두 모델 모두 62%의 정확도로 수렴하는 것을 확인할 수 있다. 조건 1에서는 두 모델의 예측이 동일하여 더 이상 서로를 능가하지 못하자, 조건 2에서는 홀수 에포크에는 자신 의 라벨링된 데이터를 사용하고 짝수 에포크에는 상대방의 라벨링된 데이터를 사용하여 각 모델의 예측 편향성 을 높였다. 아래 [표 3]은 조건 2로 학습했을 때 에포크 별 테스트 그룹 T의 정확도를 나타내고 있으며, 도 10은 이러한 [표 3]을 그래픽으로 표현한 것이다. 표 3 Epochs 2 4 6 8 10 12 14 16 18 20 EfficientNet A61.4262.3463.1463.3764.8565.4164.4965.6965.4465.82 EfficientNet B60.0462.2362.8963.8263.8465.2565.8565.6866.2066.19 의사 레이블링된 데이터를 교환한 결과, 조건 1의 정확도는 4회차에 도달했고, 이후에도 지속적으로 조금씩 상 승하였다. 20회 에포크에서는 약 66%의 정확도를 달성하여 능동 학습을 하지 않았을 때보다 약 16%p 향상되었음 을 확인할 수 있었다. 이상 설명한 바와 같은 본 발명의 실시예에 의하면, 기존의 수작업 방식에 의존하지 않고 자동화된 레이블링 기 술을 활용하여 대량의 데이터를 빠르게 생성할 수 있으며, 이를 통해 연구 개발자들은 더 많은 데이터를 보다 쉽고 신속하게 생성할 수 있고, 인공지능 모델의 학습 효과를 극대화할 수 있을 것으로 기대된다. 한편, 첨부된 블록도의 각 블록과 흐름도의 각 단계의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수행될 수도 있다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이 터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 의 프로세서를 통해 수행되는 그 인스트럭션들이 블록도의 각 블록에서 설명된 기능들을 수행하는 수단을 생성 하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 기록매체(또는 메모리) 등에 저장되는 것도 가능하므로, 그 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 기록매체(또는 메모리)에 저장된 인스 트럭션들은 블록도의 각 블록에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 그리고, 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되 는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동작 단계들이 수 행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 수 행하는 인스트럭션들은 블록도의 각 블록에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 적어도 하나 이상의 실행 가능한 인스트럭션들을 포 함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실시 예들에서는 블록들에서 언 급된 기능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순 으로 수행되는 것도 가능하다."}
{"patent_id": "10-2023-0118383", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 데이터 분류 방법을 수행하거나, 데이터 분류를 위한 학습 방법을 수행하기 위 한 데이터 분류 장치의 기능을 설명하기 위한 블록도이다. 도 2는 도 1의 데이터 분류 장치의 저장부 내의 신경망 구조를 예시적으로 설명하기 위한 블록도이다. 도 3은 도 1의 데이터 분류 장치의 데이터 분류를 위한 학습 방법, 예컨대 사전 학습 방법을 예시적으로 설명하기 위한 블록도이다. 도 4는 도 1의 데이터 분류 장치의 데이터 분류를 위한 학습 방법, 예컨대 능동 학습 방법을 예시적으로 설명하기 위한 블록도이다. 도 5는 도 4의 능동 학습 방법에서 의사 레이블 데이터를 생성하고 학습용 데이터 그룹을 갱신하는 과정의 상세 흐름도이다. 도 6은 본 발명의 실시예에 따른 데이터 분류 장치의 데이터 분류 방법을 예시적으로 설명하는 블록도이다. 도 7은 본 발명의 실시예에 따른 데이터 분류 장치의 데이터 분류를 위한 학습 방법을 예시적으로 설명하 기 위한 개념도이다. 도 8은 본 발명의 데이터 분류 장치의 테스트 그룹에 대한 학습 에포크 반복 횟수에 따른 정확도를 예시적 으로 표현한 실험결과 그래프이다. 도 9 및 도 10은 도 8의 테스트 그룹에 대해서 조건 별 학습 에포크 반복 횟수에 따른 정확도를 비교한 실험결 과 그래프이다."}
