{"patent_id": "10-2023-0095137", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0014694", "출원번호": "10-2023-0095137", "발명의 명칭": "능동학습에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동작 방법", "출원인": "울산과학기술원", "발명자": "백승렬"}}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서,학습대상인 데이터셋을 저장하는 메모리; 및상기 데이터셋에 기반해 딥러닝 모델을 학습하고, 상기 딥러닝 모델을 모사하는 대리 모델을 생성하도록 구성된프로세서를 포함하고,상기 대리 모델은,상기 데이터셋 중 라벨링데이터가 적은 희소영역 내의 언라벨데이터를 탐색하도록 구성된 제1 레이어; 및학습된 상기 딥러닝 모델을 이용해 상기 언라벨데이터를 예측하도록 구성된 제2 레이어를 포함하는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 희소영역은,상기 대리 모델이 상기 데이터셋 중 특정 영역을 예측 불확실성이 높다고 예측하는 영역인 것을 특징으로 하는,능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 예측 불확실성은,상기 대리 모델이 특정 데이터에 대해 예측하는 경우 상기 특정 데이터에 대한 정합률에 상응하는 지표로서, 상기 특정 데이터에 대한 정보량에 반비례하는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 대리 모델은,상기 언라벨데이터 중 정보량이 가장 많은 희소탐색데이터를 라벨링하는 것을 특징으로 하는, 능동학습(ActiveLearning)에 기반한 딥러닝을 수행하는 전자 장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제2 레이어는,상기 라벨링데이터를 이용해 상기 딥러닝 모델을 학습하고, 예측된 상기 언라벨데이터에 대해 라벨링을 수행하는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 대리 모델은, 공개특허 10-2025-0014694-3-상기 라벨링이 수행됨에 응답하여 업데이트되는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제1 레이어는,상기 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 초기 단계에 상응하는 제1 스테이지 내지 제1기준 스테이지에 이용되는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 제2 레이어는,상기 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 후기 단계에 상응하는 제2 기준 스테이지 내지최후 스테이지에 이용되는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 대리 모델은,상기 라벨링데이터가 추가될 때마다 업데이트되는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 대리 모델은,상기 라벨링데이터에 대응되는 데이터포인트를 추가하고, 모델 파라미터를 업데이트하는 것을 특징으로 하는,능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 대리 모델은,업데이트된 상기 모델 파라미터를 언라벨데이터의 불확실성을 추정하는 것을 특징으로 하는, 능동학습(ActiveLearning)에 기반한 딥러닝을 수행하는 전자 장치."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법에 있어서,데이터셋에 기반해 딥러닝 모델을 학습하는 단계; 및상기 딥러닝 모델을 모사하는 대리 모델을 생성하는 단계를 포함하고,상기 딥러닝 모델을 모사하는 대리 모델을 생성하는 단계는,상기 데이터셋 중 라벨링데이터가 적은 희소영역 내의 언라벨데이터를 탐색하는 단계; 및학습된 상기 딥러닝 모델을 이용해 상기 언라벨데이터를 예측하는 단계를 포함하는 것을 특징으로 하는, 능동학공개특허 10-2025-0014694-4-습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 데이터셋 중 라벨링데이터가 적은 희소영역 내의 언라벨데이터를 탐색하는 단계는,상기 대리 모델이 상기 데이터셋 중 특정 영역을 예측 불확실성이 높다고 예측하는 단계를 포함하는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법.."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 예측 불확실성은,상기 대리 모델이 특정 데이터에 대해 예측하는 경우 상기 특정 데이터에 대한 정합률에 상응하는 지표로서, 상기 특정 데이터에 대한 정보량에 반비례하는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법.."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 언라벨데이터 중 정보량이 가장 많은 희소탐색데이터를 라벨링하는 단계를 더 포함하는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법.."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 대리 모델은, 상기 라벨링이 수행됨에 응답하여 업데이트되는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법.."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 대리 모델은,상기 라벨링데이터에 대응되는 데이터포인트를 추가하고, 모델 파라미터를 업데이트하는 것을 특징으로 하는,능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법.."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 대리 모델은,업데이트된 상기 모델 파라미터를 언라벨데이터의 불확실성을 추정하는 것을 특징으로 하는, 능동학습(ActiveLearning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법.."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 딥러닝 모델을 모사하는 대리 모델을 생성하는 단계는,상기 라벨링데이터를 이용해 상기 딥러닝 모델을 학습하는 단계; 및예측된 상기 언라벨데이터에 대해 라벨링을 수행하는 단계를 포함하는 것을 특징으로 하는, 능동학습(ActiveLearning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법..공개특허 10-2025-0014694-5-청구항 20 제12항에 있어서,상기 딥러닝 모델을 모사하는 대리 모델을 생성하는 단계는,상기 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 상응하는 제1 스테이지 내지 제1 기준 스테이지에서 각기 학습되는 단계를 포함하는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법.."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제12항에 있어서,상기 언라벨데이터를 예측하는 단계는,상기 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 후기 단계에 상응하는 제2 기준 스테이지 내지최후 스테이지에서 각기 학습되는 단계를 포함하는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한딥러닝을 수행하는 전자 장치의 동작 방법.."}
{"patent_id": "10-2023-0095137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제12항에 있어서,상기 대리 모델은,상기 라벨링데이터가 추가될 때마다 업데이트되는 것을 특징으로 하는, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법.."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치는, 학습대상 인 데이터셋을 저장하는 메모리 및 데이터셋에 기반해 딥러닝 모델을 학습하고, 딥러닝 모델을 모사하는 대리 모 델을 생성하도록 구성된 프로세서를 포함하고, 대리 모델은, 데이터셋 중 라벨링데이터가 적은 희소영역 내의 언 라벨데이터를 탐색하도록 구성된 제1 레이어 및 학습된 딥러닝 모델을 이용해 언라벨데이터를 예측하도록 구성된 제2 레이어를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝(Deep Learning) 의 일종인 능동학습(Active Learning)은 학습된 모델에 대해 레이블이 없는 언라벨데이 터의 불확실성을 추정하여 정해진 로스함수 내에 학습 곡선을 가장 가파르게 만들 수 있는 레이블될 후보 데이 터를 찾는 학습 방식이다. 최근 딥러닝이 뛰어난 성능을 보이면서 다양한 분야에 능동학습이 적용되고 있다. 하지만, 대부분의 능동학습 적용례들은 불확실성 측정 기법 기반의 레이블이 될 데이터를 선별하는 방법론들을 이용하고 있고, 이 경우 딥러닝 기반 학습이 갖는 내재적 특성을 능동학습에 적극적으로 반영하지 못하는 문제 가 있다. 또한 딥러닝에서 능동학습을 바로 적용할 경우 데이터를 배치(batch) 단위로 선택하는 것에 어려움이 발생하는 문제도 있다. 예컨대 하나의 배치 단위로 선택하는 경우 데이터의 특성이 서로 유사한 유사 데이터가 같이 선택 되어 데이터의 샘플링이 충분히 이루어지지 않는다. 따라서, 언라벨데이터에 대해 라벨링하는 대안적 모델을 이용한 새로운 레이블링 방법에 대한 요구가 높아지는 실정이다. 선행기술문헌 특허출원 제10-2020-0063613호(2020.05.27.)"}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 예시적 실시예들은 언라벨데이터에 대해 라벨링하는 대안적 모델을 이용한 새로운 라벨링 방법으로서 베이지안 대리 학습자를 통하여 개별 데이터에 대해 라벨링을 하고, 배치를 모아 학습하는 방식을 제공하는 능 동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동작 방법을 제공하는 데에 목적이 있 다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 과제를 해결하기 위하여, 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝 을 수행하는 전자 장치는, 학습대상인 데이터셋을 저장하는 메모리 및 데이터셋에 기반해 딥러닝 모델을 학습하 고, 딥러닝 모델을 모사하는 대리 모델을 생성하도록 구성된 프로세서를 포함하고, 대리 모델은, 데이터셋 중 라벨링데이터가 적은 희소영역 내의 언라벨데이터를 탐색하도록 구성된 제1 레이어 및 학습된 딥러닝 모델을 이 용해 언라벨데이터를 예측하도록 구성된 제2 레이어를 포함하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 희소영역은, 대리 모델이 데이터셋 중 특정 영역을 예측 불확실성이 높다고 예측하는 영역인 것을 특징으로 한 다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 예측 불확실성은, 대리 모델이 특정 데이터에 대해 예측하는 경우 특정 데이터에 대한 정합률에 상응하는 지표 로서, 특정 데이터에 대한 정보량에 반비례하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 대리 모델은, 언라벨데이터 중 정보량이 가장 많은 희소탐색데이터를 라벨링하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 제2 레이어는, 라벨링데이터를 이용해 딥러닝 모델을 학습하고, 예측된 언라벨데이터에 대해 라벨링을 수행하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 대리 모델은, 라벨링이 수행됨에 응답하여 업데이트되는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 제1 레이어는, 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 초기 단계에 상응하는 제1 스테이지 내지 제1 기준 스테이지에 이용되는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 제2 레이어는, 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 후기 단계에 상응하는 제2 기준 스테 이지 내지 최후 스테이지에 이용되는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 대리 모델은, 라벨링데이터가 추가될 때마다 업데이트되는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 대리 모델은, 라벨링데이터에 대응되는 데이터포인트를 추가하고, 모델 파라미터를 업데이트하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 대리 모델은, 업데이트된 모델 파라미터를 언라벨데이터의 불확실성을 추정하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법은, 데이터셋에 기반해 딥러닝 모델을 학습하는 단계 및 딥러닝 모델을 모사하는 대리 모델을 생성하는 단계 를 포함하고, 딥러닝 모델을 모사하는 대리 모델을 생성하는 단계는, 데이터셋 중 라벨링데이터가 적은 희소영 역 내의 언라벨데이터를 탐색하는 단계 및 학습된 딥러닝 모델을 이용해 언라벨데이터를 예측하는 단계를 포함 하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법에 있어서, 데이터셋 중 라벨링데이터가 적은 희소영역 내의 언라벨데이터를 탐색하는 단계는, 대리 모델이데이터셋 중 특정 영역을 예측 불확실성이 높다고 예측하는 단계를 포함하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법에 있어서, 예측 불확실성은, 대리 모델이 특정 데이터에 대해 예측하는 경우 특정 데이터에 대한 정합률에 상응하는 지표로서, 특정 데이터에 대한 정보량에 반비례하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법은 언라벨데이터 중 정보량이 가장 많은 희소탐색데이터를 라벨링하는 단계를 더 포함하는 것을 특징으로 한 다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법에 있어서, 대리 모델은, 라벨링이 수행됨에 응답하여 업데이트되는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법에 있어서, 대리 모델은, 라벨링데이터에 대응되는 데이터포인트를 추가하고, 모델 파라미터를 업데이트하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법에 있어서, 대리 모델은, 업데이트된 모델 파라미터를 언라벨데이터의 불확실성을 추정하는 것을 특징으로 한 다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법에 있어서, 딥러닝 모델을 모사하는 대리 모델을 생성하는 단계는, 라벨링데이터를 이용해 딥러닝 모델을 학 습하는 단계 및 예측된 언라벨데이터에 대해 라벨링을 수행하는 단계를 포함하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법에 있어서, 딥러닝 모델을 모사하는 대리 모델을 생성하는 단계는, 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 상응하는 제1 스테이지 내지 제1 기준 스테이지에서 각기 학습되는 단계를 포함하는 것을 특 징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법에 있어서, 언라벨데이터를 예측하는 단계는, 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 후기 단계에 상응하는 제2 기준 스테이지 내지 최후 스테이지에서 각기 학습되는 단계를 포함하는 것을 특징으로 한 다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방 법에 있어서, 대리 모델은, 라벨링데이터가 추가될 때마다 업데이트되는 것을 특징으로 한다. 이 외에도, 본 개시의 기술적 사상을 구현하기 위한 실행하기 위한 컴퓨터 판독 가능한 기록 매체에 저장된 컴 퓨터 프로그램이 더 제공될 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기 록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동 작 방법은 베이지안(Bayesian) 대리 모델을 사용하여 기존 딥러닝 모델의 학습 행동을 효율적으로 예측할 수 있 다. 베이지안 대리 모델은 딥러닝 모델의 예측 결과를 사용하여 라벨링되지 않은 데이터의 불확실성을 추정함으 로써 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택할 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동 작 방법은 학습의 초기 및 후기 단계 모두에서 잘 수행될 수 있어, 종래의 능동학습 방법이 신뢰도 저하를 일으 키던 불확실성 추정치를 개선할 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동 작 방법은 이미지 및 텍스트 분류 작업 모두에 적용될 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동 작 방법은 종래의 능동학습 방법론에 비해 성능 벤치마크가 가장 우수하다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동 작 방법은 널리 정립된 베이지안 접근 방식을 채택하여 계산 효율적이고 최적의 탐색을 제공하며, 각 단계에서 새로운 데이터 인스턴스가 선택되어 전체 데이터 세트에 대한 결과 정보 획득을 최대화할 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동 작 방법은 가장 불확실한 데이터 포인트를 빠르게 식별할 수 있으며 대리 GP 학습자를 즉시 업데이트할 수 있고, 새로 추가된 데이터 포인트를 기반으로 업데이트되면 공간 이웃에 대한 예측의 신뢰도가 즉각적으로 향상 될 수 있다. 본 개시의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 '부, 모듈, 부재, 블록'이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블 록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간 접적인 연결은 무선 통신망을 통해 연결되는 것을 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '본 개시에 따른 장치'는 연산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치들 이 모두 포함된다. 예를 들어, 본 개시에 따른 장치는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인 공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목 적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이 루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습 (unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learnin g)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다.본 개시의 예시적인 실시예에 따르면, 프로세서는 인공지능을 구현할 수 있다. 인공지능이란 사람의 신경세포 (biological neuron)를 모사하여 기계가 학습하도록 하는 인공신경망(Artificial Neural Network) 기반의 기계 학습법을 의미한다. 인공지능의 방법론에는 학습 방식에 따라 훈련데이터로서 입력데이터와 출력데이터가 같이 제공됨으로써 문제(입력데이터)의 해답(출력데이터)이 정해져 있는 지도학습(supervised learning), 및 출력데 이터 없이 입력데이터만 제공되어 문제(입력데이터)의 해답(출력데이터)이 정해지지 않는 비지도학습 (unsupervised learning), 및 현재의 상태(State)에서 어떤 행동(Action)을 취할 때마다 외부 환경에서 보상 (Reward)이 주어지는데, 이러한 보상을 최대화하는 방향으로 학습을 진행하는 강화학습(reinforcement learning)으로 구분될 수 있다. 또한, 인공지능의 방법론은 학습 모델의 구조인 아키텍처에 따라 구분될 수도 있는데, 널리 이용되는 딥러닝 기술의 아키텍처는, 합성곱신경망(CNN; Convolutional Neural Network), 순환신 경망(RNN; Recurrent Neural Network), 트랜스포머(Transformer), 생성적 대립 신경망(GAN; generative adversarial networks) 등으로 구분될 수 있다. 본 장치와 시스템은 인공지능 모델을 포함할 수 있다. 인공지능 모델은 하나의 인공지능 모델일 수 있고, 복수 의 인공지능 모델로 구현될 수도 있다. 인공지능 모델은 뉴럴 네트워크(또는 인공 신경망)로 구성될 수 있으며, 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘을 포함할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해 결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 예시적으로, 장치는 input layer, hidden layer, output layer를 포함할 수 있다. 장치를 구성하는 뉴 럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력(input)으로부터 예측하고자 하는 결과 (output)를 추론할 수 있다. 프로세서는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train, 또는 학습(learn)하거나, 수신되는 입력 데이터를 기초로 연산을 수행하고, 수행 결과를 기초로 정보 신호(information signal)를 생성하거나, 뉴럴 네 트워크를 재훈련(retrain)할 수 있다. 뉴럴 네트워크의 모델들은 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network 등 다양한 종류의 모델들을 포함할 수 있으나 이에 제한되지는 않는다. 프로세서는 뉴럴 네트워크의 모델들에 따른 연산을 수행하기 위한 하나 이상의 프로세서를 포함할 수 있다. 예를 들어 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론(multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함 할 수 있으나 이에 한정되는 것이 아닌 임의의 뉴럴 네트워크를 포함할 수 있음은 통상의 기술자가 이해할 것이다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network, Generative Modeling, eXplainable AI, Continual AI, Representation Learning, AI for Material Design, 자 연어 처리를 위한 BERT, SP-BERT, MRC/QA, Text Analysis, Dialog System, GPT-3, GPT-4, 비전 처리를 위한 Visual Analytics, Visual Understanding, Video Synthesis, ResNet 데이터 지능을 위한 Anomaly Detection,Prediction, Time-Series Forecasting, Optimization, Recommendation, Data Creation 등 다양한 인공지능 구 조 및 알고리즘을 이용할 수 있으며, 이에 제한되지 않는다. 이하, 첨부된 도면을 참조하여 본 개시의 실시예를 상세하게 설명한다. 도 1은 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 전자 장치를 도시하는 블록도이 다. 도 1을 참고하면 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 는 입/출력부, 통 신부, 식별부, 데이터베이스 및 프로세서를 포함할 수 있다. 이하에서는, 전자 장치는 능동학습(Active Learning)에 기반한 딥러닝 수행 방법을 구현하는 전자적 장치이며, 능동학습(Active Learning)에 기반한 딥러닝 수행 방법은 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치(1 0)를 통해 구현되는 것으로 가정된다. 입/출력부는 사용자 입력을 받거나 또는 사용자에게 정보를 출력하는 각종 인터페이스나 연결 포트 등일 수 있다. 입/출력부는 입력 모듈과 출력 모듈로 구분될 수 있다. 입력 모듈은 사용자로부터 사용자 입력을 수신한다. 입력 모듈은 영상 정보(또는 신호), 오디오 정보(또는 신호), 데이터, 또는 사용자로부터 입력되는 정보의 입력을 위한 것으로서, 적어도 하나의 카메라, 적어도 하나 의 마이크로폰 및 사용자 입력부 중 적어도 하나를 포함할 수 있다. 입력부에서 수집한 음성 데이터나 이미지 데이터는 분석되어 사용자의 제어명령으로 처리될 수 있다. 사용자 입력은 키 입력, 터치 입력, 음성 입력을 비롯한 다양한 형태로 이루어질 수 있다. 이러한 사용자 입력 을 받을 수 있는 입력 모듈의 예로는 전통적인 형태의 키패드나 키보드, 마우스는 물론, 사용자의 터치를 감지 하는 터치 센서, 음성 신호를 입력 받는 마이크, 영상 인식을 통해 제스처 등을 인식하는 카메라, 사용자 접근 을 감지하는 조도 센서나 적외선 센서 등으로 구성되는 근접 센서, 가속도 센서나 자이로 센서 등을 통해 사용 자 동작을 인식하는 모션 센서 및 그 외의 다양한 형태의 사용자 입력을 감지하거나 입력 받는 다양한 형태의 입력 수단을 모두 포함하는 포괄적인 개념이다. 여기서, 터치 센서는 디스플레이 패널에 부착되는 터치 패널이나 터치 필름을 통해 터치를 감지하는 압전식 또 는 정전식 터치 센서, 광학적인 방식에 의해 터치를 감지하는 광학식 터치 센서 등으로 구현될 수 있다. 이외에 도 입력 모듈은 자체적으로 사용자 입력을 감지하는 장치 대신 사용자 입력을 입력 받는 외부의 입력 장치를 연 결시키는 입력 인터페이스(USB 포트, PS/2 포트 등)의 형태로 구현될 수도 있다. 출력 모듈은 각종 정보를 출력해 사용자에게 이를 제공할 수 있다. 출력 모듈은 영상을 출력하는 디스플레이, 소리를 출력하는 스피커(및/또는 이와 연결된 증폭기(amplifier)), 진동을 발생시키는 햅틱 장치 및 그 외의 다 양한 형태의 출력 수단을 모두 포함하는 포괄적인 개념이다. 이외에도 출력 모듈은 상술한 개별 출력 수단을 연 결시키는 포트 타입의 출력 인터페이스의 형태로 구현될 수도 있다. 일 예로, 디스플레이 형태의 출력 모듈은 텍스트, 정지 영상, 동영상을 디스플레이 할 수 있다. 디스플레이는 액정 디스플레이(LCD: Liquid Crystal Display), 발광 다이오드(LED: light emitting diode) 디스플레이, 유기 발광 다이오드(OLED: Organic Light Emitting Diode) 디스플레이, 평판 디스플레이(FPD: Flat Panel Display), 투명 디스플레이(transparent display), 곡면 디스플레이(Curved Display), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(1D display), 홀로그래픽 디스플레이(holographic display), 프로젝터 및 그 외의 영상 출력 기능을 수행할 수 있는 다양한 형태의 장치를 모두 포함하는 광의의 영상 표시 장치를 의미하는 개념 이다. 이러한 디스플레이는 입력 모듈의 터치 센서와 일체로 구성된 터치 디스플레이의 형태일 수도 있다. 통신부는 외부 기기와 통신할 수 있다. 따라서, 장치(디바이스)는 통신부를 통해 외부 기기와 정보를 송수 신할 수 있다. 예를 들어, 장치는 통신부를 이용해 전기차 충전관리 시스템 내에 저장 및 생성된 정보들이 공유 되도록 외부 기기와 통신을 수행할 수 있다. 통신부는 예를 들어, 유선통신 모듈, 무선통신 모듈, 근거리 통신 모듈, 위치정보 모듈 중 적어도 하나를 포함할 수 있다. 여기서, 통신, 즉 데이터의 송수신은 유선 또는 무선으로 이루어질 수 있다. 이를 위해 통신부는 LAN(Local Area Network)를 통해 인터넷 등에 접속하는 유선 통신 모듈, 이동 통신 기지국을 거쳐 이동 통신 네트워크에 접속하여 데이터를 송수신하는 이동 통신 모듈, 와이파이(Wi-Fi) 같은 WLAN(Wireless Local Area Network) 계 열의 통신 방식이나 블루투스(Bluetooth), 직비(Zigbee)와 같은 WPAN(Wireless Personal Area Network) 계열의 통신 방식을 이용하는 근거리 통신 모듈, GPS(Global Positioning System)과 같은 GNSS(Global NavigationSatellite System)을 이용하는 위성 통신 모듈 또는 이들의 조합으로 구성될 수 있다. 통신에 사용되는 무선 통 신 기술은 저전력 통신을 위한 NB-IoT(Narrowband Internet of Things) 를 포함할 수 있다. 이때, 예를 들어 NB-IoT 기술은 LPWAN(Low Power Wide Area Network) 기술의 일례일 수 있고, LTE Cat(category) NB1 및/또는 LTE Cat NB2 등의 규격으로 구현될 수 있으며, 상술한 명칭에 한정되는 것은 아니다. 추가적으로 또는 대체적으 로, 다양한 실시예들에 따른 무선 기기에서 구현되는 무선 통신 기술은 LTE-M 기술을 기반으로 통신을 수행할 수 있다. 이때, 일 예로, LTE-M 기술은 LPWAN 기술의 일례일 수 있고, eMTC(enhanced Machine Type Communication) 등의 다양한 명칭으로 불릴 수 있다. 예를 들어, LTE-M 기술은 1) LTE CAT 0, 2) LTE Cat M1, 3) LTE Cat M2, 4) LTE non-BL(non-Bandwidth Limited), 5) LTE-MTC, 6) LTE Machine Type Communication, 및 /또는 7) LTE M 등의 다양한 규격 중 적어도 어느 하나로 구현될 수 있으며 상술한 명칭에 한정되는 것은 아니 다. 추가적으로 또는 대체적으로, 다양한 실시예들에 따른 무선 기기에서 구현되는 무선 통신 기술은 저전력 통 신을 고려한 지그비(ZigBee), 블루투스(Bluetooth) 및 저전력 광역 통신망(Low Power Wide Area Network, LPWAN) 중 적어도 어느 하나를 포함할 수 있으며, 상술한 명칭에 한정되는 것은 아니다. 일 예로 ZigBee 기술은 IEEE 802.15.4 등의 다양한 규격을 기반으로 소형/저-파워 디지털 통신에 관련된 PAN(personal area network s)을 생성할 수 있으며, 다양한 명칭으로 불릴 수 있다. 유선 통신 모듈은, 지역 통신(Local Area Network; LAN) 모듈, 광역 통신(Wide Area Network; WAN) 모듈 또는 부가가치 통신(Value Added Network; VAN) 모듈 등 다양한 유선 통신 모듈뿐만 아니라, USB(Universal Serial Bus), HDMI(High Definition Multimedia Interface), DVI(Digital Visual Interface), RS-232(recommended standard232), 전력선 통신, 또는 POTS(plain old telephone service) 등 다양한 케이블 통신 모듈을 포함할 수 있다. 무선 통신 모듈은 와이파이(Wifi) 모듈, 와이브로(Wireless broadband) 모듈 외에도, GSM(global System for Mobile Communication), CDMA(Code Division Multiple Access), WCDMA(Wideband Code Division Multiple Access), UMTS(universal mobile telecommunications system), TDMA(Time Division Multiple Access), LTE(Long Term Evolution), 4G, 5G, 6G 등 다양한 무선 통신 방식을 지원하는 무선 통신 모듈을 포함할 수 있 다. 무선 통신 모듈은 신호를 송신하는 안테나 및 송신기(Transmitter)를 포함하는 무선 통신 인터페이스를 포함할 수 있다. 또한, 무선 통신 모듈은 제어부의 제어에 따라 무선 통신 인터페이스를 통해 제어부로부터 출력된 디 지털 제어 신호를 아날로그 형태의 무선 신호로 변조하는 신호 변환 모듈을 더 포함할 수 있다. 무선 통신 모듈은 신호를 수신하는 안테나 및 수신기(Receiver)를 포함하는 무선 통신 인터페이스를 포함할 수 있다. 또한, 무선 통신 모듈은 무선 통신 인터페이스를 통하여 수신한 아날로그 형태의 무선 신호를 디지털 제 어 신호로 복조하기 위한 신호 변환 모듈을 더 포함할 수 있다. 근거리 통신 모듈은 근거리 통신(Short range communication)을 위한 것으로서, 블루투스(Bluetooth쪠), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless-Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 근거리 통신을 지원할 수 있다. 위치정보 모듈은 본 개시에 따른 전자 장치의 위치(또는 현재 위치)를 획득하기 위한 모듈로서, 그의 대표 적인 예로는 GPS(Global Positioning System) 모듈 또는 WiFi(Wireless Fidelity) 모듈이 있다. 예를 들어, GPS모듈을 활용하면, GPS 위성에서 보내는 신호를 이용하여 본 전자 장치의 위치를 획득할 수 있다. 다른 예로 서, Wi-Fi모듈을 활용하면, Wi-Fi모듈과 무선신호를 송신 또는 수신하는 무선 AP(Wireless Access Point)의 정 보에 기반하여, 본 전자 장치의 위치를 획득할 수 있다. 필요에 따라서, 위치정보모듈은 치환 또는 부가적 으로 본 장치의 위치에 관한 데이터를 얻기 위해 통신부의 다른 모듈 중 어느 기능을 수행할 수 있다. 위치정보 모듈은 본 장치의 위치(또는 현재 위치)를 획득하기 위해 이용되는 모듈로, 본 장치의 위치를 직접적으로 계산 하거나 획득하는 모듈로 한정되지는 않는다. 식별부는 영상 인식을 통해 오브젝트 등을 인식하는 카메라, 오브젝트 접근을 감지하는 감지 센서, 사용자 의 입력에 따른 터치 센서 및 그 외의 다양한 형태의 외부 입력을 감지하거나 입력 받는 다양한 형태의 식별/센 싱 수단을 모두 포함하는 포괄적인 개념일 수 있다. 카메라는 촬영 모드에서 이미지 센서에 의해 얻어지는 정지영상 또는 동영상 등의 화상 프레임을 처리한다. 처 리된 화상 프레임은 디스플레이부(또는 본 개시의 전자 장치의 화면)에 표시되거나 메모리에 저장될 수 있다. 한편, 상기 카메라가 복수개일 경우, 매트릭스 구조를 이루도록 배치될 수 있으며, 이와 같이 매트릭스 구조를 이루는 카메라들을 통해 다양한 각도 또는 초점을 갖는 복수의 영상정보가 입력될 수 있고, 또한 상기 카메라들 은 3차원의 입체영상을 구현하기 위한 좌 영상 및 우 영상을 획득하도록, 스트레오 구조로 배치될 수도 있다. 식별부는 입/출력부 내의 입력 모듈과 동일한 것으로 이해될 수 있거나 및/또는 입력 모듈과는 별도의 것으로 이해될 수도 있다. 식별부는 지자기 센서(Magnetic sensor), 가속도 센서(Acceleration sensor), 온 /습도 센서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서, 근접 센서, RGB 센서 (illuminance sensor), 라이다(radar) 센서, 조도 센서, 및 전류 센서 중 하나 이상을 더 포함할 수 있으나, 이에 한정되는 것은 아니다. 각 센서들의 기능은 그 명칭으로부터 당업자가 직관적으로 추론할 수 있으므로, 구 체적인 설명은 생략하기로 한다. 데이터베이스는 각종 정보를 저장할 수 있다. 데이터베이스는 데이터를 임시적으로 또는 반영구적으로 저 장할 수 있다. 예를 들어, 데이터베이스에는 제1 디바이스 및/또는 제2 디바이스를 구동하기 위한 운용 프로그 램(OS: Operating System), 웹 사이트를 호스팅하기 위한 데이터나 점자 생성을 위한 프로그램 내지는 어플리케 이션(예를 들어, 웹 어플리케이션)에 관한 데이터 등이 저장될 수 있다. 또, 데이터베이스는 상술한 바와 같이 모듈들을 컴퓨터 코드 형태로 저장할 수 있다. 데이터베이스의 예로는 하드 디스크(HDD: Hard Disk Drive), SSD(Solid State Drive), 플래쉬 메모리 (flash memory), 롬(ROM: Read-Only Memory), 램(RAM: Random Access Memory) 등이 있을 수 있다. 이러한 데이 터베이스는 내장 타입 또는 탈부착 가능한 타입으로 제공될 수 있다. 프로세서는 전자 장치의 전반적인 동작을 제어한다. 이를 위해 프로세서는 각종 정보의 연산 및 처리를 수행하고 제1 디바이스 및/또는 제2 디바이스의 구성요소들의 동작을 제어할 수 있다. 예를 들어, 프로 세서는 능동학습 기반 딥러닝 방법 을 위한 프로그램 내지 어플리케이션을 실행시킬 수 있을 것이다. 프로세서는 하드웨어 소프트웨어 또는 이들의 조합에 따라 컴퓨터나 이와 유사한 장치로 구현될 수 있다. 하드웨어적으로 프로세서는 전기적인 신호를 처리하여 제어 기능을 수행하는 전자 회로 형태로 제공될 수 있으며, 소프트웨어적으로는 하드웨어적인 프로세서를 구동시키는 프로그램 형태로 제공될 수 있다. 한편, 이하 의 설명에서 특별한 언급이 없는 경우에는 제1 디바이스 및/또는 제2 디바이스의 동작은 프로세서의 제어 에 의해 수행되는 것으로 해석될 수 있다. 즉, 능동학습(Active Learning)에 기반한 딥러닝 수행 방법, 또는 능 동학습(Active Learning)에 기반한 딥러닝 수행 장치의 동작 방법을 위한 프로그램 내지 어플리케이션으로 구현 되는 모듈들이 실행되는 경우, 모듈들은 프로세서가 제1 디바이스 및/또는 제2 디바이스를 이하의 동작들 을 수행하도록 제어하는 것으로 해석될 수 있다. 프로세서는 본 장치 내의 구성요소들의 동작을 제어하기 위한 알고리즘 또는 알고리즘을 재현한 프로그램 에 대한 데이터를 저장하는 메모리, 및 메모리에 저장된 데이터를 이용하여 전술한 동작을 수행하는 적어도 하 나의 세부프로세서(미도시)로 구현될 수 있다. 이때, 메모리와 프로세서는 각각 별개의 칩으로 구현될 수 있다. 또는, 메모리와 프로세서는 단일 칩으로 구현될 수도 있다. 또한, 프로세서는 이하의 도 2 내지 도 8에서 설명될 본 개시에 따른 다양한 실시 예들을 본 장치 상에서 구현하기 위하여, 위에서 살펴본 구성요소들을 중 어느 하나 또는 복수를 조합하여 제어할 수 있다. 본 개시의 예시적인 실시예에 따르면, 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치는 적어도 하나의 뉴럴네트워크 모델을 포함하는 복수의 학습 및/또는 예측모델을 이용하여 구성될 수 있다. 예를 들어, 전자 장치는 언라벨데이터에 대해 라벨링하는 대안적 모델을 이용한 새로운 레이블링 방법으로서 베 이지안 대리 학습자를 통하여 개별 데이터에 대해 라벨링을 하고, 배치를 모아 학습하는 방식을 제공하는 능동 학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동작 방법을 제공할 수 있다. 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 장치의 동작 방법은 라벨링된 데이터가 적은 상황에서 모델의 성능을 향상시키기 위해 사용될 수 있다. 여기에서 능동학습은 라벨링된 데이터(이하, 라벨링데이터)가 적은 상황에서 모델의 성능을 향상시키기 위해 사용되는 기법으로, 라벨링되지 않은 데이터(이하, 언라벨데이터) 중에서 가장 정보가 많은 데이터를 선택하여 라벨링을 추가하는 방식으로 작동할 수 있다. 능동학습은 다양한 분야에서 사용될 수 있다. 예를 들어, 능동학습 의료 영상 분석, 이미지 및 비디오 분석, 랭 킹, 바이오 및 헬스 인포매틱스, 자연어 처리 등의 분야에서 사용될 수 있다. 예컨대 의료 영상 분석에서는, 의 료 영상 데이터를 라벨링하는 데에 많은 비용이 들기 때문에, 라벨링된 데이터를 최소화하고, 라벨링되지 않은데이터 중에서 가장 정보가 많은 데이터를 선택하여 라벨링하는 방법으로 능동학습이 사용된다. 이미지 및 비디 오 분석에서는, 대규모 데이터셋을 라벨링하는 데에 많은 비용이 들기 때문에, 라벨링된 데이터를 최소화하고, 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택하여 라벨링하는 방법으로 능동학습이 사용된다. 랭킹 모델을 학습할 때, 랭킹이 잘못된 검색 결과를 선택하여 라벨링하고, 이를 사용하여 랭킹 모델 을 업데이트함으로써 검색 엔진에서 검색 결과를 랭킹하는 데에 능동학습이 사용된다. 바이오 및 헬스 인포매틱 스 분야에서는, 바이오 데이터를 라벨링하는 데에 많은 비용이 들기 때문에, 라벨링된 데이터를 최소화하고, 라 벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택하여 라벨링하는 방법으로 능동학습이 사용된다. 물론 자연어 처리 분야에서도 능동학습이 사용될 수 있다. 예를 들어, 텍스트 분류, 개체명 인식, 의미론적 역 할 할당 등의 작업에서 능동학습이 사용될 수 있다. 텍스트 분류에서는, 대규모 텍스트 데이터를 라벨링하는 데 에 많은 비용이 들기 때문에, 라벨링된 데이터를 최소화하고, 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택하여 라벨링하는 방법으로 능동학습이 사용될 수 있다. 개체명 인식에서는, 문장에서 인물, 장소, 조직 등의 개체명을 인식하는 작업에서 능동학습이 사용될 수 있다. 예시적인 실시예에서, 능동학습은 라벨링된 데이터가 적은 경우 라벨링되지 않은 데이터 중에서 가장 정보가 많 은 데이터를 선택하여 라벨링하고, 이를 사용하여 개체명 인식 모델을 학습할 수 있다. 의미론적 역할 할당에서 는, 문장에서 주어, 목적어, 보어 등의 의미론적 역할을 할당하는 작업에서 능동학습이 사용될 수 있다. 라벨링 된 데이터가 적은 경우, 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택하여 라벨링하고, 이를 사용하여 의미론적 역할 할당 모델을 할 수 있다. 이러한 방식으로 능동학습은 자연어 처리 분야에서도 라벨링된 데이터를 최소화하고, 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택하여 모델의 성능을 향상시키는 데에 사용될 수 있다. 보다 구체적으로, 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전 자 장치는, 학습대상인 데이터셋을 저장하는 메모리 및 데이터셋에 기반해 딥러닝 모델을 학습하고, 딥러닝 모 델을 모사하는 대리 모델을 생성하도록 구성된 프로세서를 포함하고, 대리 모델은, 데이터셋 중 라벨링데이터가 적은 희소영역 내의 언라벨데이터를 탐색하도록 구성된 제1 레이어 및 학습된 딥러닝 모델을 이용해 언라벨데이 터를 예측하도록 구성된 제2 레이어를 포함하는 것을 특징으로 할 수 있다. 보다 구체적으로, 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전 자 장치의 동작 방법은, 데이터셋에 기반해 딥러닝 모델을 학습하는 단계 및 딥러닝 모델을 모사하는 대리 모델 을 생성하는 단계를 포함하고, 딥러닝 모델을 모사하는 대리 모델을 생성하는 단계는, 데이터셋 중 라벨링데이 터가 적은 희소영역 내의 언라벨데이터를 탐색하는 단계 및 학습된 딥러닝 모델을 이용해 언라벨데이터를 예측 하는 단계를 포함하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동 작 방법은 베이지안(Bayesian) 대리 모델을 사용하여 기존 딥러닝 모델의 학습 행동을 효율적으로 예측할 수 있 다. 베이지안 대리 모델은 딥러닝 모델의 예측 결과를 사용하여 라벨링되지 않은 데이터의 불확실성을 추정함으 로써 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택할 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동 작 방법은 학습의 초기 및 후기 단계 모두에서 잘 수행될 수 있어, 종래의 능동학습 방법이 신뢰도 저하를 일으 키던 불확실성 추정치를 개선할 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동 작 방법은 이미지 및 텍스트 분류 작업 모두에 적용될 수 있다. 도 2는 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 전자 장치를 세부적으로 도 시하는 개념도이다. 도 2를 도 1과 함께 참조하면, 전자 장치(도 1, 10)는 두 가지 모드인 탐색 모드(도 2의 제1 레이어에서 수행) 와 활용 모드(도 2의 제2 레이어에서 수행)를 결합하여 새로운 라벨링 데이터에 대한 정보 이득을 최대화할 수 있다. 이를 위해 전자 장치는 베이지안(Bayesian) 대리 모델을 사용하여 기존 딥러닝 모델의 학습 행동을 효율적으로 예측하고, 라벨링 데이터가 추가될 때마다 대리 모델을 즉시 업데이트하여 기존 딥러닝 모델의 지속 적인 학습 행동을 모사할 수 있다. 따라서, 전자 장치는 딥러닝 모델을 다시 학습시킬 필요 없이 라벨링 데 이터를 추가로 활용할 수 있다. 능동학습은 탐색 모드, 활용 모드 두 가지 모드로 나눌 수 있다. 탐색 모드(exploration mode) 는 라벨링데이터 가 적은 영역인 희소 영역을 더 잘 탐색하기 위해 불확실성이 높은 데이터를 선택하도록 구성된다. 활용 모드 (exploitation mode)는 라벨링데이터를 사용하여 모델을 학습하고, 학습된 모델을 사용하여 라벨링되지 않은 데 이터(언라벨데이터)를 예측하고, 이를 기반으로 가장 정보가 많은 데이터를 선택하여 라벨링한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 제1 레이어는, 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 초기 단계에 상응하는 제1 스테이지 내지 제1 기준 스테이지에 이용되는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 제2 레이어는, 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 후기 단계에 상응하는 제2 기준 스테 이지 내지 최후 스테이지에 이용되는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 제1 레이어는, 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 초기 단계에 상응하는 제1 스테이지 내지 제1 기준 스테이지에 이용되는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 제2 레이어는, 데이터셋 중 소정의 배치 크기를 가지는 학습 스테이지 중 후기 단계에 상응하는 제2 기준 스테 이지 내지 최후 스테이지에 이용되는 것을 특징으로 한다. 전자 장치가 실행하는 제1 딥러닝 모델(Deep Learning Model; )은 라벨링되지 않은 데이터셋인 언라벨데이 터를 크기가 인 배치(batch) 단위로 입력받을 수 있다. 제1 딥러닝 모델(Deep Learning Model; )은 크기가 인 배치 단위로 학습을 수행하는 스테이지(stage)를 적어도 하나 가질 수 있다. 본 개시의 예시적 실시예에 따른 전자 장치는 제1 딥러닝 모델(Deep Learning Model; )을 모사하는 대리모델인 제2 딥러닝 모델(Deep Learning Model; )를 더 포함할 수 있다. 제2 딥러닝 모델( )은 제1 효용함수(u1)를 따르고 탐색 모드에 상 응하는 제1 레이어, 및 제2 효용함수(u2)를 따르고 활용 모드에 상응하는 제2 레이어를 포함할 수 있다. 예시적인 실시예에서, 제1 효용함수(u1)의 값에 상응하고 제1 레이어의 출력인 제1 엔트로피(Ent 1)는 제2 레이 어로 입력될 수 있다. 예시적인 실시예에서, 제2 효용함수(u2)의 값에 상응하고 제2 레이어의 출력인 제1 엔트 로피(Ent 2)는 제2 딥러닝 모델( )을 업데이트할 수 있다. 본 개시의 예시적 실시예는 두 가지 모드인 제1 레이어의 탐색 모드와 제2 레이어의 활용 모드를 결합하여 새로 운 라벨링 데이터에 대한 정보 이득을 최대화할 수 있다. 탐색 모드는 불확실성, 및 다양성 두 가지 방법으로 나뉜다. 불확실성 기반 방법은, 모델이 해당 데이터에 대한 예측의 불확실성이 높은 데이터를 선택하여 라벨링하는 방법을 의미한다. 불확실성 기반 방법은 모델이 해당 데 이터에 대해 예측을 할 때, 예측의 불확실성이 높은 경우를 의미하는데, 이러한 데이터를 라벨링함으로써, 모델 이 해당 데이터에 대한 예측을 개선할 수 있다. 본 개시의 탐색 모드에서는 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택하여 라벨링을 추가 한다. 구체적으로, 탐색 모드에서는 라벨링된 데이터가 적은 희소 영역을 더 잘 탐색하기 위해 불확실성이 높은 데이터를 선택할 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 희소영역은, 대리 모델이 데이터셋 중 특정 영역을 예측 불확실성이 높다고 예측하는 영역인 것을 특징으로 한 다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 예측 불확실성은, 대리 모델이 특정 데이터에 대해 예측하는 경우 특정 데이터에 대한 정합률에 상응하는 지표 로서, 특정 데이터에 대한 정보량에 반비례하는 것을 특징으로 한다. 다양성에 기반한 방법은, 모델이 다양한 종류의 데이터를 학습하도록 하는 방법이다. 이는 모델이 학습한 데이 터가 다양하면, 새로운 데이터에 대한 예측 능력이 더욱 향상될 수 있기 때문이다. 다양성에 기반한 방법은, 라 벨링된 데이터가 적은 상황에서 모델이 다양한 종류의 데이터를 학습할 수 있도록 돕는다. 탐색 모드는 라벨링 된 데이터가 적은 상황에서 모델의 성능을 향상시키는 데에 사용될 수 있다. 여기에서, '불확실성'이란 모델이 해당 데이터에 대해 예측을 할 때, 모델이 해당 데이터를 얼마나 잘 이해하고 있는지에 대한 지표이다. 불확실성이 높은 데이터를 선택함으로써, 모델이 해당 데이터에 대한 이해를 개선하고, 더 나은 예측을 할 수 있도록 돕는다. 따라서 능동학습에서의 불확실성이란 해당 능동학습 기반 딥러 닝 모델이 특정 데이터에 대해 예측을 할 때, 예측의 불확실성이 높은 경우를 의미한다. 예를 들어, 이미지 분 류 작업에서 모델이 어떤 이미지를 분류할 때, 해당 이미지에 대한 예측의 불확실성이 높은 경우, 해당 이미지 를 선택하여 라벨링하는 것이 탐색 모드에서의 불확실성이다. 이러한 데이터를 라벨링함으로써, 모델이 해당 데 이터에 대한 예측을 개선할 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 대리 모델은, 언라벨데이터 중 정보량이 가장 많은 희소탐색데이터를 라벨링하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 제2 레이어는, 라벨링데이터를 이용해 딥러닝 모델을 학습하고, 예측된 언라벨데이터에 대해 라벨링을 수행하는 것을 특징으로 한다. 탐색 모드는 다양한 방법으로 구현될 수 있다. 본 발명에서는 pre-clustering, 개별 데이터 인스턴스의 예측 변 화 추정, 또는 라벨링데이터-언라벨데이터 상호 정보 최대화 등의 방법이 사용될 수 있다. 이러한 방법들은 모 두 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택하는 데에 있어서 효율적인 방법이다. 활용 모드는 라벨링된 데이터를 사용하여 딥러닝 모델을 학습하고, 학습된 모델을 사용하여 라벨링되지 않은 데 이터를 예측하는 모드이다. 전자 장치는 활용 모드를 통해 라벨링데이터를 사용하여 딥러닝 모델을 학습하 고, 학습된 모델을 사용하여 언라벨데이터를 예측할 수 있다. 이 예측 결과를 사용하여 전자 장치는 언라벨 이터 중에서 가장 정보가 많은 데이터를 선택하여 라벨링을 추가할 수 있다. 전자 장치는 라벨링된 데이터 를 사용하여 모델을 재학습하거나, 라벨링데이터를 사용하여 모델의 하이퍼파라미터를 조정함으로써 딥러닝 모 델의 성능을 개선할 수 있다. 본 개시의 예시적 실시예에 따르면, 전자 장치는 초기 학습 단계에서는 제1 레이어를 이용해 탐색 모드를 적용함으로써 라벨링데이터가 적은 상황에서 모델의 성능을 향상시킬 수 있고, 후기 학습 단계에서는 제2 레이 어를 이용해 활용 모드를 적용함으로써 모델의 성능을 극대화할 수 있다. 전자 장치의 제2 딥러닝 모델( ; 본 개시에서는 f^로도 표현됨)인 대리 모델은 구체적으로 베이지안 대리 모델을 사용하여 제1 딥러닝 모델()의 학습 행동을 효율적으로 예측할 수 있다. 제2 딥러닝 모델( )은 딥러닝 모델의 예측 결과를 사용하여 언라벨데이터의 불확실성을 추정할 수 있다. 이를 통해 언라벨데이터 중에서 가장 정보가 많은 데이터가 선택될 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 대리 모델은, 라벨링이 수행됨에 응답하여 업데이트되는 것을 특징으로 한다. 본 개시의 예시적인 실시예에 따르면, 제2 딥러닝 모델( )은 라벨링데이터가 추가될 때마다 즉시 업데이트될 수 있다. 구체적으로, 제2 딥러닝 모델( )이 업데이트되는 과정은 다음과 같다. 단계 1: 전자 장치는 라벨링데이터가 추가되면(updated data set), 새로운 데이터 포인트를 제2 딥러닝 모 델( )에 추가할 수 있다. 단계 2: 제2 딥러닝 모델( )은 새로운 데이터 포인트를 사용하여 모델 파라미터를 업데이트할 수 있다. 단계 3: 제2 딥러닝 모델( )은 업데이트된 모델 파라미터를 사용하여 언라벨 데이터의 불확실성을 추정할 수 있고, 가장 정보가 많은 데이터를 선택할 수 있다. 단계 4: 전자 장치는 선택된 데이터를 라벨링하고, 라벨링데이터를 사용하여 딥러닝 모델을 학습할 수 있다. 단계 5: 전자 장치는 학습된 딥러닝 모델을 사용하여 언라벨데이터를 예측할 수 있고, 예측된 값을 제2 딥 러닝 모델( )에 추가하여 모델을 업데이트할 수 있다. 단계 6: 단계 1 내지 단계 5 를 반복하여 언라벨데이터 중에서 가장 정보가 많은 데이터를 선택하고, 이를 라벨 링하여 딥러닝 모델을 학습하는 과정을 계속한다. 단계 1 내지 단계 6의 방식으로 제2 딥러닝 모델( )은 라벨링데이터가 추가될 때마다 즉시 업데이트되며, 언라 벨데이터 중에서 가장 정보가 많은 데이터를 선택하는 데에 있어서 효율화를 달성할 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 대리 모델은, 라벨링데이터가 추가될 때마다 업데이트되는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 대리 모델은, 라벨링데이터에 대응되는 데이터포인트를 추가하고, 모델 파라미터를 업데이트하는 것을 특징으로 한다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치에 있어서, 대리 모델은, 업데이트된 모델 파라미터를 언라벨데이터의 불확실성을 추정하는 것을 특징으로 한다. 도 3은 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법을 나타내는 도면이다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 방법은 레이블이 지정 되지 않은 데이터의 사전 클러스터링을 수행하고, 개별 데이터 인스턴스에 레이블이 지정된 경우 예측이 어떻게 변경될지 예측하거나, 레이블이 지정된 데이터 인스턴스와 레이블이 지정되지 않은 데이터 인스턴스 간의 상호 정보(mutual information)를 최대화함으로써 선택된 레이블을 다양화할 수 있다. 본 개시에서, 데이터 인스턴스(data instance)란 데이터셋(dataset)을 구성하는 하나의 데이터 단위를 의미할 수 있다. 예를 들어, 이미지 데이터셋에서는 하나의 이미지가 하나의 데이터 인스턴스가 될 수 있다. 텍스트 데 이터셋에서는 하나의 문서나 문장이 하나의 데이터 인스턴스가 될 수 있다. 데이터 인스턴스는 모델이 학습하고 예측하는 데에 사용되는 가장 작은 단위일 수 있다. 본 개시의 능동 학습에서는 이러한 데이터 인스턴스 중에서 가장 정보가 많은 데이터 인스턴스를 선택하여 라벨링하는 방법을 사용할 수 있다. 본 개시에서, 상호 정보(mutual information)란, 두 변수 사이의 상호 의존성을 나타내는 지표일 수 있다. 본 개시의 능동 학습에서는 상호 정보를 사용하여, 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선 택하는 방법을 사용할 수 있다. 이러한 방법을 사용하여능동 학습은 라벨링되지 않은 데이터를 최대한 효율적으 로 활용하여 모델의 성능을 향상시키는 데에 사용될 수 있다. 구체적으로, 상호 정보는 다음과 같이 계산될 수 있다: 두 변수 X와 Y가 있을 때, X와 Y의 상호 정보는 다음과 같이 정의될 수 있다: I(X;Y) = H(X) - H(X|Y) 여기서 H(X)는 변수 X의 엔트로피(entropy)를 나타내며, H(X|Y)는 변수 Y가 주어졌을 때 변수 X의 조건부 엔트 로피(conditional entropy)를 나타낸다. 상호 정보는 두 변수가 서로 독립적일 때는 0이 될 수 있다. 상호 정보에 인덱스를 부여해 달리 표현하면 다음과 같다. 두 데이터 인스턴스 x_i와 x_j가 있을 때, 이들 간의 상호 정보는 다음과 같이 정의될 수 있다: I(x_i; x_j) = H(x_i) + H(x_j) - H(x_i, x_j) 여기서 H(x_i)는 데이터 인스턴스 x_i의 엔트로피(entropy)를 나타내며, H(x_j)는 데이터 인스턴스 x_j의 엔트로피를 나타낸다. H(x_i, x_j)는 두 데이터 인스턴스 x_i와 x_j의 결합 엔 트로피(joint entropy)를 나타낸다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 방법은 학습자 (Learner)의 행동을 추정하기 위해 가우시안 프로세스 대리(Gaussian Process Surrogate) 모델을 사용하는데, 이는 다른 유형의 대리 모델을 사용하는 선행 기술 접근 방식보다 더 효율적이고 정확할 수 있다. 가우시안 프로세스(GP) 대리 모델은 능동학습에서 사용되는 베이지안 대리 모델 중 하나일 수 있다. GP 대리 모 델은 라벨링된 데이터를 사용하여 기본 학습 모델의 학습 과정을 모사하고, 이를 사용하여 라벨링되지 않은 데 이터 중에서 가장 정보가 많은 데이터를 선택하는 방법을 사용할 수 있다. 구체적으로, GP 대리 모델은 다음과 같은 방법으로 작동할 수 있다: 단계 1': 라벨링된 데이터를 사용하여 기본 학습 모델을 학습할 수 있다. 단계 2'. 학습된 기본 학습 모델을 사용하여 라벨링되지 않은 데이터에 대한 예측을 수행할 수 있다. 단계 3'. 예측 결과를 사용하여, 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택할 수 있다. 이는 불확실성에 기반한 방법이나 다양성에 기반한 방법 등을 사용하여 수행될 수 있다. 단계 4'. 선택된 데이터를 라벨링하고, 라벨링된 데이터를 사용하여 기본 학습 모델을 업데이트할 수 있다. 단계 5'. 업데이트된 기본 학습 모델을 사용하여, 다시 라벨링되지 않은 데이터에 대한 예측을 수행할 수 있다. 단계 6'. 상기 단계 1' 내지 단계 5'의 과정을 반복하여, 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데 이터를 선택하고, 이를 라벨링하여 기본 학습 모델을 업데이트하는 방법으로 능동학습을 수행할 수 있다. GP 대 리 모델은 베이지안 추정(Bayesian inference) 기법을 사용하여, 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택하는 데에 사용될 수 있다. 이 모델은 라벨링되지 않은 데이터에 대한 예측에 기여한다. 본 개시 전체에서, 입력 X와 출력 Y의 데이터 공간이 주어졌다고 가정한다. 표준 지도 학습에서 레이블이 지정 된 훈련셋 T ={(x1, y1), . . . , (xN, yN)} ⊂ X × Y는 X와 Y의 공동 분포에서 샘플링된다(f : X →Y). 대신 활성 학습에서는 초기에 입력 데이터 세트 X = {x1, . . . , xN}이 표시된다. 대신 능동 학습에서는 초기에 입력 데이터 세트 X = {x1, . . . , xN}이 표시된다. 그런 다음 학습 알고리즘에 B 데이터 인스턴스에 레이블을 지정하도록 제안하는 예산이 제공된다. 활성 학습의 출력은 T에서 선택된 요소를 지정하는 크기 B의 {1,...,N}의 레이블이 지정된 인덱스 하위 집합 L이다. 본 개시는 분류 문제에 초점을 맞추고 Y ⊂ (C는 클래스 수이고 기준 학습기 f는 = 1 및 ≥ 0이고 은 f(x)의 j번째 요소(j번째 클래스에 해당). 본 개시에서는 기본 학습 알고리즘과 그 출력(분류 함수)을 모두 나타내기 위해 f를 사용할 수 있다. 본 개시는 L을 구축하기 위해 증분 접근 방식을 취한다. 레이블이 지정된 점 L0의 초기 인덱스 세트에서 시작하 여 각 단계 t에서 Lt는 단일 레이블 인덱스 : = 에 의해 증가될 수 있다. 이 프로세스는 효용함 수 를 따르며 = ∪ { } 에서 u의 최대화로 가 선택되도록 설정된다. 좋은 효용함수는 1) 각 데이터 인스턴스가 분류 결정을 내리는 것이 얼마나 어려운지(또는 불확실한지), 2) 레 이블이 지정될 때 데이터 인스턴스가 다른 데이터 인스턴스에 얼마나 영향을 미치는지, 즉 포인트에 레이블이 지정될 때 다른 인스턴스에 대한 결정이 어떻게 개선되는지를 포착해야 한다. 이러한 목표를 실현하려면 단계별 로 f가 어떻게 업데이트되는지 지속적으로 관찰할 수 있는 기능이 필요하다. ( 는 에서 훈련된 학습자를 나 타냄). 단일 단계에서 B 데이터 인스턴스를 u의 첫 번째 B 최대화기로 동시에 선택하는 것은 데이터 인스턴스 xi가 가 장 높은 효용 u(i)를 갖는 경우 공간적 이웃이 유사하게 높은 효용 값을 나타낼 가능성이 있다는 점을 고려할 때 차선책이다. 그러나 일단 xi에 레이블이 지정되고 그에 따라 f가 재학습되면 이러한 공간 집계에 레이블을 지정하면 이러한 이웃에 대해 더 정확한 예측을 제공할 수 있으므로 중복될 수 있다. 하지만 엄청나게 높은 계 산 비용으로 인해 f가 DNN(심층 신경망)일 때 이 연속 재훈련 전략을 적용하는 것은 어렵다. 기존 접근 방식은 학습자 f(즉, 순수한 탐색)와 독립적인 효용을 설계하거나 또는 레이블이 지정된 데이터의 공 간적 다양성을 촉진하는 보조 프로세스를 채택할 수 있다. 특히 후자는 종종 다양성을 유지하는 것과 어려운 레 이블 선택을 절충하기 위해 하이퍼파라미터 및/또는 휴리스틱을 조정해야 한다. 본 개시의 알고리즘에 따른 방법은 기본 학습자 f의 지속적인 학습 동작을 시뮬레이션하여 계산적으로 효율적인 대리 학습자 를 병렬로 학습하는 것이다. 이를 위해 본 개시는 가우시안 프로세스(Gaussian process; GP) 추 정기를 사용할 수 있다. 이를 통해 효용함수 u를 설계하고 효율적으로 평가하는 데 잘 발달된 베이지안 추론 기 술을 사용할 수 있다. 또한, 본 개시의 접근 방식은 데이터 인스턴스(높은 효용성)에 레이블이 지정되면 대리 학습자 가 즉시 업데 이트되고 그에 따라 이웃의 효용이 억제되기 때문에 레이블 다양성을 촉진하기 위한 추가 메커니즘이 필요하지않다. 주어진 예산 B에 대해 DNN 학습자 f는 매 I번째 단계에서만 훈련된다. 이 I번째 단계 사이의 f의 동작은 지속적 으로 업데이트되는 대리 GP 학습자 에 의해 캡처된다(각 새 레이블에 대해 재교육됨). 각 I번째 단계에서 대 리 는 f로 제공된다. 이 경우, 본 개시는 출력 레이어로 softmax를 사용한다. 이 I번째 단계 사이에서 는 I번째 단계의 대리자와 해당 참값간의 차이를 기반으로 훈련된다. 레이블 지정을 위해 선택된 각 새 데이터 인스턴스 x에 대해 해당 GP 훈련 레이블은 y f(x)로 얻을 수 있다. 본 개시는 f 및 에 의해 만들어진 예측이 얼마나 불확실하고 영향력이 있는지 각각 나타내는 두 가지 유형의 효용 함수를 사 용할 수 있다. t 데이터 인스턴스가 t 단계에서 이미 레이블이 지정되었다고 가정합니다. 일반성을 잃지 않고 의 첫 번째 t 포인트에 해당하는 레이블이 지정된 교육 세트를 구성하고 는 레이블이 지정되지 않은 세트, 즉 으로 사용한다고 가정한다. 커널: GP Prior는 입력 x 및 x'와 최신 학습기 f(x) 및 f(x')의 해당 출력을 기반으로 구성된 가우시안 커널의 조합을 기반으로 수식 내지 수식 과 같이 인스턴스화될 수 있다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기에서 > 0 는 하이퍼파라미터이다. 이 커널을 사용하면 결과 대리자가 기본 딥 러닝 f의 동작을 충실히 캡처하고 형성된 클래스 경계를 부드럽게 하는 것을 방지할 수 있다. 4,500개 레이블의 중간 단계에서 별도의 베이스라인 네트워크를 훈련할 때(CIFAR10 데이터 세트의 경우. 도 4에 서 보다 상세히 설명될 것이다), 10개의 서로 다른 무작위 초기화에 대한 실험에서 훈련 세트에서 와 f 사이 의 평균 절대 편차가 표준 커널 만 사용하는 경우에서 42%(0.012 정도) 감소했음을 보여준다. 예측 모델: GP 학습기 는 모든 클래스 및 데이터 인스턴스에서 i.i.d.(independent identically distributed) 가우시안 우도(Gaussian likelihood) 를 사용할 수 있다. 여기서 N (μ, σ2)는 평균 μ 및 분산 σ2를 갖는 가우시안 분포이다. 이 우도를 GP 프라이어(수식 )과 결 합하여 레이블이 지정되지 않은 점 xi ∈ Ut에 대한 의 예측은 크기 C의 가우시안 랜덤 벡터로 다음 수식 와 같이 제공된다: 수식 를 따르는 모델은 능동학습이 진행됨에 따라 빠르게 증가하는 크기 t × t의 커널 행렬 Kt를 반전할 필 요가 있다. -예측(수식 )의 계산 복잡성을 관리 가능한 수준으로 유지하기 위해 두 세트의 기본 포인트 및 를 사용하여 희소 GP 근사를 채택할 수 있다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "기준점(basis point) U는 K-평균 클러스터링을 사용하여 찾은 X의 클러스터 중심으로 구하고 V는 C차원 확률 심 플렉스로 무작위로 샘플링한다. 예측 평가(수식 )의 계산 복잡성은 이제 레이블이 지정된 데이터 포인트에 대해 선형이 된다 ( ). 예측 분산 기반 효용함수 u1: 베이지안 모델로서 레이블이 지정되지 않은 입력 xi에 대한 의 출력은 불확실성 을 정량화하는 자연스러운 방법을 제공하는 확률 분포 이다. 입력 xi에 대한 예측 공분산 행렬의 j번째 대각선 요소는 j번째 클래스에 대한 예측의 엔트로피를 나타낸다. 이 행렬의 추적은 현재 모델 예측이 xi에 대해 얼마나 불확실한지 전반적으로 캡처한다. 개별 데이터 포인트의 엔트로피 자체는 레이블이 지정될 때 이러한 엔터티가 얼마나 영향력이 있는지 반영하지 않으므로 이 파라미터를 최대화하면 이상값을 선택하는 경향이 관찰된다. 이는 예측 공분산의 대각선 항 이 해당 레이블이 지정되지 않은 지점이 레이블이 지정된 교육 세트에서 벗어 날수록 증가하는 경향이 있다는 사실에서 볼 수 있다(대규모 문제에 대한 이 동작 분석용). 대신, xi에 레이블 이 지정되면 남아 있는 레이블이 지정되지 않은 전체 세트 의 예측 엔트로피가 어떻게 감소하는지에 따라 효용 를 정의한다. 이를 위해 각 연속 단계에서 레이블이 지정되지 않은 세트의 예측 공분산을 유지한다. 공분산 추정치는 모델에서 등방성이므로 데이터 포인트당 하나의 대각선 항목만 저장한다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 는 T t 및 xi에 대해 훈련된 모델에 의해 예측된 에 대한 공분산을 나타내는 경우 (xi에 레이블이 지정되었다고 가정), u(i)를 직접 계산하는 데는 O(tK2 +K3) 시간이 걸리며 이는 중간 크기의 데이터 세트의 경우에도 불가능하다. Q(i)와 Qt 사이의 차이가 수식 에서 랭크 1이라는 점에 주목하여 계산적으로 효율적인 솔루션을 얻을 수 있 다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수식 을 사용하여 수식 에 Sherman-Morrison-Woodbury 행렬 항등식을 적용하면 다음과 같은 식을 얻을 수 있다: 이 형식으로 유틸리티 는 이 제공될 때 -시간에 평가될 수 있다. 역 이 단계 0에서 명 시적으로 계산되면 각 단계 t에서 시간의 을 기반으로 도 계산할 수 있다. 본 개시의 방법은 학습자 f 매개변수의 엔트로피와 그 근사치를 최소화하는 베이지안 능동학습 접근 방식이라고 일견 해석될 수 있다. 그러나 이러한 접근 방식과 달리 본 개시는 데이터에 대한 예측에 대한 엔트로피를 최소 화하는 방법을 설명한다. 즉, 개시는 엔트로피 계산을 f의 파라메트릭 형식과 독립적으로 만들고 GP를 심층 학 습기 f의 대용으로 사용할 수 있게 만드는 방법을 제시한다. 효용 함수 u1을 사용하여 모델은 레이블이 지정되지 않은 데이터 인덱스 세트 {t + 1, . . . , N}에 대해 u1의 최대화로 다음 레이블 를 결정한다. 이 접근 방식은 u1이 xi에 레이블이 지정되어 있다는 가정을 기반으로 도 출되었음에도 불구하고 u1이 후보 지점 xi의 실제 레이블을 필요로 하지 않기 때문에 실현 가능하다. 이 속성은 i.i.d. 가우시안 잡음 모델로부터 기인한다. 일반적으로 기본 분류 함수 의 경우 입력 x가 주어진 데이터 y를 관찰할 우도 는 가우시안이 아니므로 GP 모델에서 로지스틱 우도 모델이 더 일반적으로 사용된다. 그러 나 이는 각 후보의 레이블을 명시적으로 포함하는 공분산 예측으로 이어지지만 이러한 레이블은 해당 데이터 포 인트가 실제로 선택된 경우에만 사용할 수 있다. 효용함수 u2는 클래스 조건부 엔트로피에 기반하며, DNN이 만든 클래스 조건부 예측 분포의 엔트로피를 기반으 로 한다. 효용함수 u2에 softmax 활성화를 적용하면 입력 xi에 대한 최종 DNN 출력 는 엔트로피를 측정할 수 있는 크기 C의 확률 분포로 제공됩니다. 이는 연속 GP 예측 분포에 대해 정의된 u1에 사용된 엔트로피와 다 르다. 효용함수 u2를 설계하는 간단한 방법은 각 단계에서 f-예측의 엔트로피를 다음 수식 와 같이 측정하는 것입니다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기에서 Ent(p)는 분포 p의 엔트로피이다. 를 최대화하면 분류할 가장 불확실한 지점을 효과적으로 선택할 수 있다. 그러나 이 전략을 구현하려면 높 은 교육 비용으로 인해 실행 불가능한 각 단계에서 ft를 재교육해야 한다. 대신, 모든 I번째 단계에서만 f를 훈 련하고 중간 단계에 대한 엔트로피 값을 추정하기 위해 GP 대리를 사용한다. 단계 s(I의 정수배)에서 DNN 분류 기 fs가 새로 훈련되고 해당 엔트로피 값 가 계산된다고 가정한다. 대리 예측 을 사용하여 원래 DNN 엔트로피 값 를 보정하여 중간 단계의 엔트로피 값을 생성합니다. 보정된 엔트로피 초기화 후 는 단계 s에서 로, 새로운 엔트로피는 단계 t > s에서 다음과 같이 주어진다:"}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서 는 GP 대리 가 만든 평균 예측 의 softmax 출력이다. 데이터 인스턴스 에 주석을 달면 뿐만 아니라 이웃에서도 GP 예측의 불확실성이 줄어든다. 이러한 방식으로 보정된 엔트로피는 중간 단계에서 새로 레이블이 지정된 지점으로 인해 발생하는 불확실성의 지속적인 감소를 반영한다. 본 개시에 따른 효용함수 는 기본 학습자가 만든 클래스 조건부 예측 분포의 엔트로피를 기반으로 정의될 수 있다. 본 개시의 알고리즘은 (추정된) 엔트로피가 가장 높은 데이터를 선택할 수 있다. 또한 후보 지점 xi에 레 이블이 지정될 때 레이블이 지정되지 않은 세트의 모든 데이터 인스턴스의 예측 엔트로피가 어떻게 감소하는지 에 따라 효용함수 를 정의할 가능성을 탐색했다. 이 수량은 각 후보 x의 레이블을 포함하므로 직접 평가할 수 없다. 대신, 각 클래스 j ∈ {1, . . . , C}마다 본 개시는 잠정적으로 해당 클래스 레이블을 xi에 할당하고 결 과적인 엔트로피 감소를 측정했다. 최종 효용 는 학습자가 예측한 해당 클래스 확률 에 의해 가 중된 이러한 가상 엔트로피 값의 평균으로 구할 수 있다. 예비 실험에서 원래 효용인 u2에 의해 달성된 최종 분 류 정확도는 u3보다 평균 0.2% 낮았지만(CIFAR10 데이터 세트에서) u3보다 약 40배 더 빨랐다. u3 평가의 주요 병목 현상은 가설 후보별로 레이블이 지정되지 않은 전체 집합에 대한 엔트로피 값의 계산이었다. u2의 이러한 경쟁력 있는 성능은 u2를 최대화하는 것이 u1에서 사용된 예측 엔트로피와 달리 이상값을 선택하지 않는다는 사 실에 기인할 수 있다. 이상치(훈련 세트에서 벗어난 점). 이 아티팩트는 일반적으로 분류 목적으로는 바람직하 지 않지만, 낮은 클래스 조건부 엔트로피 값으로 할당되기 때문에 이상치가 선택되지 않기 때문에 능동 학습에 서 유리한 부작용이 있다. 본 개시 효용 u1은 레이블이 지정될 때 예측 분산의 예상 감소를 사용할 수 있다. 이론적으로 더 매력적인 접근 방식은 예상되는 테스트 오류 감소를 사용하는 것일 수 있다. 그러나 실측 레이블을 사용할 수 없기 때문에 이 러한 오류 감소를 직접 계산할 수 없다. 따라서 기존 접근법은 특정 모델 가정을 도입했다(특정 학습자에게만 해당될 수 있음). 학습자 예측을 u2 효용과 유사하게 기본 실측에 대한 대용으로 사용했다. 본 개시의 두 효용함수 u1과 u2는 보완적인 강점을 가지고 있다. 효용함수 u1은 레이블이 지정되지 않은 전체 세트에서 전반적인 불확실성 감소를 측정한다. 이것은 학습의 초기 단계(즉, 레이블 t의 수가 제한됨)에 특히 적합하지만 당면한 작업에 불가지론적이라는 점에서 제한적입니다. 예측 공분산 는 전적으로 X의 입력 데이터 인스턴스가 어떻게 분포되어 있는지에 따라 결정되며 획득한 레이 블과 독립적이다(수식 ). 반면에 효용함수 u2는 f(x)의 엔트로피에 의해 캡처된 레이블 정보를 이용할 수 있 다. 그러나 초기 학습 단계에서는 학습기 f의 성능이 제한되므로 추정된 엔트로피를 신뢰할 수 없다. u1과 u2의 장점을 각 단계에서 자동으로 하나씩 선택하여 결합할 수 있다. 각 단계 t에서, u1 또는 u2는 [t 100, t]의 시간 창에 걸쳐 평균화된 테스트 정확도 증가 St를 초기 값 S0와 비교하여 선택될 수 있다: u1은 하 이퍼파라미터 T가 있는 일 때 선택될 수 있다. 그렇지 않으면 u2가 선택될 수 있다. 테스트 데이터 를 사용할 수 없으므로 에 추가하기 전에 대신 t에서 새로 레이블이 지정된 교육 데이터 포인트를 단일 테 스트 포인트로 사용할 수 있다. t < 100일 때 St가 정의되지 않기 때문에 처음 100단계에 대해 u1을 사용할 수 있다. 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법은 능동학습의 탐색 및 활용 모드를 모두 결합하여 새로운 레이블로 인한 정보 획득을 최적화할 수 있다. 또한, 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법은 베이스라인 학습자 (baseline learner)에 베이지안 대체(Bayesian surrogate)를 사용하여 선행 기술 접근 방식과 비교하여 학습자 의 행동을 보다 효율적이고 정확하게 예측할 수 있다.베이스라인 학습자(baseline learner)란, 능동학습에서 라벨링되지 않은 데이터에 대한 예측을 수행하는 기본 모델을 의미할 수 있다. 이 모델은 초기에 라벨링된 데이터를 사용하여 학습되며, 이후에는 능동학습 알고리즘 에 의해 라벨링되지 않은 데이터를 선택하여 학습이 진행될 수 있다. 베이스라인 학습자는 능동학습 에서 가장 중요한 역할 중 하나를 담당할 수 있다. 초기에는 라벨링된 데이터가 적기 때문에, 베이스라인 학습자는 라벨링 된 데이터를 기반으로 모델을 학습하고, 이를 사용하여 라벨링되지 않은 데이터에 대한 예측을 수행할 수 있다. 이후에는 능동학습 알고리즘에 의해 라벨링되지 않은 데이터 중에서 가장 정보가 많은 데이터를 선택하여 라벨 링하고, 이를 사용하여 베이스라인 학습자를 업데이트할 수 있다. 베이스라인 학습자는 일반적으로 신경망 (neural network)이나 결정 트리(decision tree) 등의 기본 모델을 사용할 수 있다. 이 모델은 초기에 라벨링된 데이터를 사용하여 학습되며, 이후에는 Active learning 알고리즘에 의해 라벨링되지 않은 데이터를 선택하여 학습이 진행될 수 있다. 베이스라인 학습자는 능동학습 에서 가장 기본적인 모델이며, 이를 사용하여 능동학습 알고리즘의 성능을 평가하고, 다른 능동학습 알고리즘과 비교할 수 있다 도 4는 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법에 따라 레이블이 지정되는 동작을 나타내는 도면이다. 초기 학습 단계에서 본 개시 알고리즘은 드물게 레이블이 지정된 데이터 영역을 채우는 데 중점을 둔 효용함수 u1 을 선택하는 경향이 있다. 더 많은 레이블이 획득됨에 따라 기본 학습자의 (시뮬레이션된) 테스트 정확도가 향상되었고 이에 따라 본 개시의 알고리즘은 더 어려운 레이블에 초점을 맞춘 효용함수 u2를 선택했다. 도 4를 참조하면, 좌상단에는 2D 이진 분류 문제가 표시되어 있다. 데이터 세트는 가우시안 분포와 가우시안 노 이즈가 있는 코사인 함수 그래프에서 샘플링되었다. 소수의 이상값은 수동으로 추가될 수 있다. 두 클래스는 각 각 파란색 원과 주황색 x로 강조 표시될 수 있다. 도 4를 참조하면, 우상단에는 능동학습의 처음 10단계에서 선택된 레이블(자홍색 십자 표시)이 표시된다. 본 개 시에 따른 알고리즘은 고밀도 영역 내에서 뚜렷한 지점을 샘플링하는 경향이 있는 u1을 선택한다. 도 4를 참조하면, 우하단에는 능동학습의 51~60단계에서 선택한 레이블이 표시된다. 여기서 알고리즘은 효용함 수 u2로 전환하고 학습자가 형성한 결정 경계에 가까운 데이터 포인트를 선택한다. 여기에서 이상값은 선택되지 않는다. 도 4를 참조하면, 가운데 지점에서 엔트로피 값이 가장 높은 데이터 포인트를 동시에 선택하면 공간적으로 집계 된 레이블이 생성될 수 있다. 특히 초기 학습 단계(중상단)에서는 학습자 f의 엔트로피 추정이 부정확하여 정보 가 없는 지점을 샘플링할 수 있다. 도 4를 참조하면 좌하단에서 획득한 레이블 수에 대한 알고리즘의 분류 정확도가 표현될 수 있다. 도 5는 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법의 성능을 나타내는 그래프 이다. 도 5는 다양한 활성 학습 알고리즘의 정확도(%)를 나타내며, 음영 영역의 너비는 표준 편차의 두 배를 나 타낸다. 본 개시는 4개의 벤치마크 데이터 세트에서 알고리즘의 성능을 평가한다. CIFAR10 데이터 세트에는 10개의 클래 스에서 32×32 크기의 60,000개 컬러 이미지가 포함되어 있다. 그 중 50,000개의 이미지는 학습용으로 사용되었 고(클래스당 5,000개의 이미지) 나머지 10,000개의 이미지는 테스트용으로 예약되었다. 마찬가지로 CIFAR100 데 이터 세트는 100개 클래스(클래스당 500개 이미지)의 60,000개 이미지를 제공할 수 있다. FashionMNIST의 데이터 세트는 10개 클래스의 70,000개의 28×28 그레이스케일 이미지로 구성될 수 있다. 이 중 60,000개의 이미지는 훈련에 사용되었고 나머지 10,000개의 이미지는 테스트 세트로 사용되었다. Caltech256 데이터 세트는 256개의 객체 범주와 배경 클래스의 30,607개 이미지로 구성될 수 있다. 여기서 클래스당 이미지의 수와 각 이미지의 크기가 다를 수 있다. 총 22,897개의 이미지와 7,710개의 이미지가 학습과 테스트에 사용되었다. 비교를 위해 Sener와 Savarese의 core-set 접근 방식(CoreSet) learning loss(LearningLoss), Variational adversarial active learning(VAAL), task-aware VAAL-extension (TA-VAAL), 순차적 GCN 기반 알고리즘 (SeqGCN), 다양한 그래디언트 임베딩에 의한 배치 능동 학습(BADGE), 그래디언트 놈 기반 접근법(GradNorm), 가 중치 감쇠 스케줄링 체계(WS)가 사용될 수 있다. 전체 실험에서 처음에는 600개의 이미지에 무작위로 레이블을 지정하고 기본 학습자를 훈련했다. 그 후 레이블 세트가 최종 예산 B = 15,000에 도달할 때까지 각각의 활성 학습 알고리즘에 의해 레이블이 확장되었다. 초기 학습 단계에서 레이블 획득 성능을 평가하기 위해 학습자를 600, 800, 1,000개의 레이블에 대해 평가하고 이후 1,000개의 추가 레이블마다 평가했다(I=1,000). 이것은 다양한 라벨링 버지 B = {600, 800, 1000, . . . , 15,000} 를 사용한 일련의 실험을 구성했는데, 이들 모두는 데이터 세트당 클래스 수와 일치하는 완전 연결 (Fully Connected; FC) 계층과 결합될 수 있다. ResNet101의 pool5 계층을 3개의 FC 계층과 결합하면 지속적으로 다른 네트워크보다 우수한 성능을 보인다. 학 습자는 초기 학습률이 0.01인 확률적 경사 하강법으로 학습되었다. 학습률은 매 10 epoch마다 10%로 감소했다. 미니 배치 크기와 총 에포크 수는 각각 30과 100으로 고정되었다. GP 대리 f의 경우 ResNet101의 pool5 레이어 출력을 입력 x로 사용했다. 모든 실험은 무작위 초기화로 10회 반복되었고 결과는 평균화되었다. CoreSet 및 VAAL은 데이터의 전체 분포를 분석하므로 특히 영향력 있는 데이터 포인트를 감지하는 데 효과적이 며 라벨이 제한적인 경우 다른 방법보다 더 높은 정확도를 달성할 수 있다. 그러나 탐색 기반 방법은 학습자 f의 예측을 직접 활용하지 않으므로 결과적으로 어려운(또는 불확실한) 데이터 포인트를 선택하지 못할 수 있다. 이로 인해 f가 보다 신뢰할 수 있는 불확실성 추정치를 제공하는 학습 후반 단계에서 성능이 저하되었다. WS, LearningLoss 및 BADGE는 CIFAR10의 이후 학습 단계에서 CoreSet 및 VAAL보 다 더 높은 정확도를 달성하는 이 작업별 정보를 활용할 수 있다. TA-VAAL 및 SeqGCN은 VAAL과 비슷한 성능을 보였다. 서로 다른 알고리즘의 성능은 데이터 세트에 따라 크게 다르다. CIFAR10 및 FashionMNIST에는 클래스가 10개뿐 일 수 있다. 그들에게는 적은 수의 레이블로도 기본 학습자가 매우 정확한 불확실성 예측을 제공했으며 착취 기 반 방법인 LearningLoss 및 WS가 우수한 성능을 보여주었다. CIFAR100과 Caltech256은 많은 수의 레이블이 있 더라도 클래스 수가 많기 때문에 학습자 f의 클래스 예측 및 불확실성 추정을 신뢰할 수 없다. 이 경우 탐색 기 반 방법(VAAL 및 CoreSet)이 더 높은 정확도를 보였다(각각 CIFAR100 및 Caltech256에 대해). 탐색과 착취를 결합함으로써 BADGE는 순수한 탐색 또는 착취 기반 방법보다 전반적으로 높은 정확도를 얻었다. 특히 FashionMNIST의 초기 단계에서 다른 기본 방법 중 최고의 성능을 달성했다. 이 두 가지 활성 학습 모드를 단일 가우시안 프로세스 모델에 통합하여 f의 지속적인 학습 동작을 캡처함으로써 본 개시의 알고리즘은 CIFAR100 및 Caltech256에서 상당한 개선을 보여주었다. CIFAR10 및 FashionMNIST의 경우 결과는 비교한 최고의 알고리즘(WS 및 BADGE)과 동등할 수 있다. 실험에서 평가된 모든 알고리즘에 대해 전체 정확도는 더 강력한 기준선 학습자를 사용할 수 있다. 본 개시의 예시적 실시예에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치 및 이의 동 작 방법은 종래의 능동학습 방법론(BADGE, TA-VAAL 및 순차 GCN 알고리즘)에 비해 성능 벤치마크가 가장 우수한 특징이 있다(state-of-the-art). 도 6은 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법에 의해 처리되는 제1 레이 어 및 제2 레이어의 성능을 나타내는 그래프이다. 도 6을 참조하면, 최종 알고리즘의 두 변형인 효용함수 u1 전용 및 효용함수 u2 전용의 성능은 각각 u1 및 u2 효용만 사용할 수 있음이 정의된다. y축은 최종 알고리즘의 정확도 오프셋을 나타낸다. 음수 오프셋은 최종 버 전이 더 낫다는 것을 나타낸다. 본 개시의 최종 알고리즘은 u1과 u2 효용의 보완적인 강점을 결합하여 탐색과 활용 사이에 적절한 절충안을 제공할 수 있다. 도 6을 참조하면, 각각 u1(u1 전용) 및 u2(u2 전용)만 사용하는 최종 알고리즘의 두 가지 변형으로 실험을 수행 한 결과를 나타낸다. 탐색 효용함수 u1은 CIFAR100과 학습자의 예측이 부정확한 FashionMNIST의 초기 학습 단계 에서 더 효과적이었다. 이 성능 이점(u2에만 해당)은 기본 학습자가 보다 신뢰할 수 있는 신뢰 추정치를 제공함 에 따라 FashionMNIST의 이후 학습 단계에서 사라졌다. 본 개시의 활용 효용함수 u2는 정반대의 동작을 보였다. 상호 보완적인 강점을 결합하여 탐색과 착취를 거래함으로써 본 개시의 최종 알고리즘은 지속적으로 u1 전용 및 u2 전용을 능가했다. 따라서, 도 6의 개념은 탐색 및 활용에 일정부분 기여한다. 도 7은 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법의 하이퍼파라미터의 성능을 나타내는 그래프이다. 도 7은 다양한 하이퍼파라미터 σx, σy 및 T 값의 효과(CIFAR10 데이터 세트, 래스터 순서). y축은 최종 알고 리즘의 정확도 오프셋을 나타낸다. 도 7을 통해, 다양한 하이퍼파라미터의 영향을 확인할 수 있다.본 개시의 하이퍼파라미터는 데이터 세트 전체에서 고정되었으며 문제의 정보나 당면한 데이터를 사용하지 않고 결정되었다. 일반적으로 작업 및 데이터 세트별로 튜닝하면 성능이 향상될 수 있지만 이를 위해서는 레이블이 희박한 능동적 학습에서는 습득하기 어렵다. CIFAR10에서 기본 포인트 K(식 5)의 수를 늘리면 성능이 약간 향상되어 2,000(라벨 수에 따라 평균 약 0.06%까 지)에 도달하고 성능이 포화 상태가 될 수 있다: K = 500 선택 계산 복잡도(K의 2차)를 기반으로 만들어졌다. 성능 변화는 원래 σx 값(식 2)이 [0.3, 8] 범위의 계수로 확대되었을 때 무시할 수 있었다. 그러나 배율 계수 가 0.1 미만일 때 정확도가 급격히 떨어졌다. 변화하는 σy의 효과는 비슷했다(수식 ). 잡음 수준 σ2(수식 )는 작은 값 10^(-10)으로 유지되었다. 범위에서 이 값을 변경해도 눈에 띄는 성능 변화는 보이지 않았다. T 값을 2 증가시키면 중간 정도의 성능 저하가 발생했다(약 -0.05%). 그림 4 는 다양한 σx, σy 및 T 값의 효과를 보여준다. 본 개시는 학습자가 얻은 지식의 활용과 문제 탐색을 기본 신경망 학습자의 대용으로 단일 가우시안 프로세스 (GP) 모델에 통합하는 새로운 능동 학습 알고리즘을 제시했다. 착취를 위해 본 개시 모델은 단계별 정보의 총 이득을 최대화하여 최적의 레이블 선택을 제공할 수 있다. 착취하는 동안 본 개시의 계산 효율적인 GP 대리자는 단일 레이블이 제공될 때마다 즉시 업데이트되어 실제로 재교육할 필요 없이 기본 학습자의 지속적인 학습 동작 을 충실하게 시뮬레이션하는 데 도움이 될 수 있다. 이를 통해 별도의 하이퍼파라미터 조정이 필요할 수 있는 레이블 다양성을 촉진하기 위한 추가 메커니즘을 도입하지 않아도 될 수 있다. 다양한 난이도의 4가지 분류 데 이터 세트에 대한 실험을 통해 본 개시는 알고리즘이 최신 기술보다 월등히 뛰어나거나 동등하다는 것을 입증했 다. 도 8은 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 전자 장치를 도시하는 블록도이 다. 본 개시에 따른 능동학습(Active Learning)에 기반한 딥러닝을 수행하는 전자 장치의 동작 방법, 또는 능동 학습(Active Learning)에 기반한 딥러닝 수행 방법은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록 매체로 구현될 수 있다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플 래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다. 본 발명에 따른 전자 장치(도 1, 10)는 컴퓨팅 장치에 대응될 수 있으며, 컴퓨팅 장치는 적어도 하나의 프로세서, 프로그램을 포함하는 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함할 수 있다. 또한, 컴퓨팅 장치는 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 본 발명에 따른 장치의 각 부품은 상술한 하나의 컴퓨팅 장치에 모두 포함되거나 각각 별개의 장치에 구현 될 수도 있다."}
{"patent_id": "10-2023-0095137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2023-0095137", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 전자 장치를 도시하는 블록도이 다. 도 2는 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 전자 장치를 세부적으로 도시하 는 개념도이다. 도 3은 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법을 나타내는 도면이다. 도 4는 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법에 따라 레이블이 지정되는 동작을 나타내는 도면이다. 도 5는 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법의 성능을 나타내는 그래프 이다. 도 6은 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법에 의해 처리되는 제1 레이 어 및 제2 레이어의 성능을 나타내는 그래프이다. 도 7은 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 방법의 하이퍼파라미터의 성능을 나타내는 그래프이다. 도 8은 본 개시의 예시적 실시예에 따른 능동학습에 기반한 딥러닝을 수행하는 전자 장치를 도시하는 블록도이 다."}
