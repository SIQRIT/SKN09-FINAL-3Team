{"patent_id": "10-2018-0071462", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0133580", "출원번호": "10-2018-0071462", "발명의 명칭": "사용자의 음성 신호를 기반으로 감정, 나이 및 성별을 동시에 인식하는 방법 및 시스템", "출원인": "한국과학기술원", "발명자": "이수영"}}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터에 의해 실행되는 사용자 특성 정보 인식 방법에 있어서, 음성 신호에 해당하는 입력 데이터 셋(input data set)을 대상으로, 미리 지정된 복수의 특성 별로 프레임(frame)을 구분하는 단계;구분된 상기 특성 별 프레임을 대상으로, 컨볼루션 뉴럴 네트워크(convolution neural network)를 기반으로 상기 복수의 특성 별 손실 함수에 기초하여 학습을 수행하는 단계; 및상기 학습을 통해 생성된 학습 모델에 기초하여 입력된 음성 신호에 해당하는 서로 다른 복수의 사용자 특성 정보를 인식하는 단계를 포함하는 사용자 특성 정보 인식 방법."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 학습을 수행하는 단계는,소프트맥스(softmax) 함수에 기초하여 상기 복수의 특성 별로 손실(loss)을 계산하는 단계; 및계산된 상기 복수의 특성 별 손실의 합에 기초하여 최종 학습의 기준을 설정하는 단계를 포함하는 사용자 특성 정보 인식 방법."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 복수의 특성 별로 프레임(frame)을 구분하는 단계는,상기 입력 데이터 셋(input data set)을 대상으로, 사용자의 감정(emotion), 나이(age) 및 성별(gender)을 위한 프레임으로 구분하는 것을 특징으로 하는 사용자 특성 정보 인식 방법."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 학습을 수행하는 단계는,상기 컨볼루션 뉴럴 네트워크에 기반하는 각 컨볼루션 레이어를 대상으로 샘플링(sampling)을 수행하는 맥스 풀링(max pooling)을 수행하는 단계를 포함하는 사용자 특성 정보 인식 방법."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 사용자 특성 정보를 인식하는 단계는,상기 입력된 음성 신호로부터 사용자의 감정, 나이 및 성별을 동시에 인식하는 것을 특징으로 하는 사용자 특성 정보 인식 방법."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2019-0133580-3-제1항에 있어서,상기 사용자 특성 정보를 인식하는 단계는,상기 사용자 특성 정보가 감정에 해당하는 경우, 상기 입력된 음성 신호로부터 사용자의 감정 상태가 중립, 기쁨, 슬픔, 분노, 혐오, 놀람, 공포 중 어느 하나에 해당하는지 여부를 인식하는 것을 특징으로 하는 사용자 특성 정보 인식 방법."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,인식된 상기 사용자 특성 정보를 기반으로 사용자의 현재 상태에 해당하는 서비스를 제공하는 단계를 더 포함하는 사용자 특성 정보 인식 방법."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "사용자 특성 정보 인식 시스템에 있어서, 음성 신호에 해당하는 입력 데이터 셋(input data set)을 대상으로, 미리 지정된 복수의 특성 별로 프레임(frame)을 구분하는 프레임 구분부;구분된 상기 특성 별 프레임을 대상으로, 컨볼루션 뉴럴 네트워크(convolution neural network)를 기반으로 상기 복수의 특성 별 손실 함수에 기초하여 학습을 수행하는 학습 제어부; 및상기 학습을 통해 생성된 학습 모델에 기초하여 입력된 음성 신호에 해당하는 서로 다른 복수의 사용자 특성 정보를 인식하는 사용자 특성 인식부를 포함하는 사용자 특성 정보 인식 시스템."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 학습 제어부는,소프트맥스(softmax) 함수에 기초하여 상기 복수의 특성 별로 손실(loss)을 계산하고, 계산된 상기 복수의 특성별 손실의 합에 기초하여 최종 학습의 기준을 설정하는 것을 특징으로 하는 사용자 특성 정보 인식 시스템."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 프레임 구분부는,상기 입력 데이터 셋(input data set)을 대상으로, 사용자의 감정(emotion), 나이(age) 및 성별(gender)을 위한 프레임으로 구분하는 것을 특징으로 하는 사용자 특성 정보 인식 시스템."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 학습 제어부는,상기 컨볼루션 뉴럴 네트워크에 기반하는 각 컨볼루션 레이어를 대상으로 샘플링(sampling)을 수행하는 맥스 풀링(max pooling)을 수행하는 것을 특징으로 하는 사용자 특성 정보 인식 시스템.공개특허 10-2019-0133580-4-청구항 12 제8항에 있어서,상기 사용자 특성 인식부는,상기 입력된 음성 신호로부터 사용자의 감정, 나이 및 성별을 동시에 인식하는 것을 특징으로 하는 사용자 특성 정보 인식 시스템."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,상기 사용자 특성 인식부는,상기 사용자 특성 정보가 감정에 해당하는 경우, 상기 입력된 음성 신호로부터 사용자의 감정 상태가 중립, 기쁨, 슬픔, 분노, 혐오, 놀람, 공포 중 어느 하나에 해당하는지 여부를 인식하는 것을 특징으로 하는 사용자 특성 정보 인식 시스템."}
{"patent_id": "10-2018-0071462", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서,인식된 상기 사용자 특성 정보를 기반으로 사용자의 현재 상태에 해당하는 서비스를 제공하는 서비스 제공부를 더 포함하는 사용자 특성 정보 인식 시스템."}
{"patent_id": "10-2018-0071462", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자의 음성 신호를 기반으로 감정, 나이 및 성별을 동시에 인식하는 방법 및 시스템이 개시된다. 컴퓨터에 의해 실행되는 사용자 특성 정보 인식 방법에 있어서, 음성 신호에 해당하는 입력 데이터 셋(input data set)을 대상으로, 미리 지정된 복수의 특성 별로 프레임(frame)을 구분하는 단계, 구분된 상기 특성 별 프레임을 대상으 로, 컨볼루션 뉴럴 네트워크(convolution neural network)를 기반으로 상기 복수의 특성 별 손실 함수에 기초하 여 학습을 수행하는 단계, 및 상기 학습을 통해 생성된 학습 모델에 기초하여 입력된 음성 신호에 해당하는 서로 다른 복수의 사용자 특성 정보를 인식하는 단계를 포함할 수 있다."}
{"patent_id": "10-2018-0071462", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예들은 사용자의 감정, 나이 및 성별을 인식하는 기술에 관한 것으로서, 더욱 상세하게는 딥러닝 (deep learning)을 기반으로 사용자의 감정, 나이 및 성별을 인식하는 기술에 관한 것이다."}
{"patent_id": "10-2018-0071462", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 비서, 생체 인식 기반 보안 등 사용자와 기계 간의 인터페이스 기술에 대한 관심이 증대되면서, 음성 및 얼굴 표정을 비롯한 생체 데이터로부터 인간의 감정 등의 특성을 인식하는 기술들이 활발하게 연구되고 있다. 음성 신호를 이용한 감정 인식 기술은 여러 분야에서 활용될 수 있다. 예를 들면, 사용자가 화가 난 것으로 예 상되는 감정 상태인 경우, 격양된 감정을 진정시키는 어조, 차분한 말투 등으로 서비스를 제안하도록 하여 해당 서비스와 연결하는 지능형 대응이 가능하다. 또한, 사용자의 감정 상태가 슬픔으로 예측되는 경우, 슬픈 발라 드 등의 음악을 제안하는 등의 서비스와 지능형 대응이 가능하다. 고객센터, 전화상담, 전화 교육 등의 스마트폰(smartphone) 기반 서비스를 이용하는 과정에 있어서 사용자의 감 정, 나이, 성별에 대한 정보를 알면 사용자의 상태에 적합한 서비스의 제공이 가능해진다. 한국공개특허 제10-2011-0011969호는 WTM을 기반으로 손실함수와 최대마진기법을 통한 음성 감정 인식 모델 구 축 방법에 관한 것으로, WTM(Watson-Tellegen Emotional Model)의 감정군들 사이의 기하학적 거리를 사용하여 각 감정 사이의 차이를 수치화하고, 설정한 값들을 기초로 하여 손실함수(loss function)의 값을 구하고, 구해 진 손실함수를 기초로 하여 각 음성 감정 모델의 파라미터를 구하는 감정 인식 모델을 구축하는 기술을 개시하 고 있다."}
{"patent_id": "10-2018-0071462", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 딥 러닝(deep learning)을 기반으로 사용자의 음성 신호로부터 사용자의 감정, 나이 및 성별을 인식 하는 기술에 관한 것이다.또한, 인식된 사용자의 감정, 나이 및 성별에 적합한 서비스를 제공하는 기술에 관한 것이다."}
{"patent_id": "10-2018-0071462", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "컴퓨터에 의해 실행되는 사용자 특성 정보 인식 방법에 있어서, 음성 신호에 해당하는 입력 데이터 셋(input data set)을 대상으로, 미리 지정된 복수의 특성 별로 프레임(frame)을 구분하는 단계, 구분된 상기 특성 별 프 레임을 대상으로, 컨볼루션 뉴럴 네트워크(convolution neural network)를 기반으로 상기 복수의 특성 별 손실 함수에 기초하여 학습을 수행하는 단계, 및 상기 학습을 통해 생성된 학습 모델에 기초하여 입력된 음성 신호에 해당하는 서로 다른 복수의 사용자 특성 정보를 인식하는 단계를 포함할 수 있다. 일측면에 따르면, 상기 학습을 수행하는 단계는, 소프트맥스(softmax) 함수에 기초하여 상기 복수의 특성 별로 손실(loss)을 계산하는 단계, 및 계산된 상기 복수의 특성 별 손실의 합에 기초하여 최종 학습의 기준을 설정하 는 단계를 포함할 수 있다. 다른 측면에 따르면, 상기 복수의 특성 별로 프레임(frame)을 구분하는 단계는, 상기 입력 데이터 셋(input data set)을 대상으로, 사용자의 감정(emotion), 나이(age) 및 성별(gender)을 위한 프레임으로 구분할 수 있다. 또 다른 측면에 따르면, 상기 학습을 수행하는 단계는, 상기 컨볼루션 뉴럴 네트워크에 기반하는 각 컨볼루션 레이어를 대상으로 샘플링(sampling)을 수행하는 맥스 풀링(max pooling)을 수행하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 사용자 특성 정보를 인식하는 단계는, 상기 입력된 음성 신호로부터 사용자의 감 정, 나이 및 성별을 동시에 인식할 수 있다. 또 다른 측면에 따르면, 상기 사용자 특성 정보를 인식하는 단계는, 상기 사용자 특성 정보가 감정에 해당하는 경우, 상기 입력된 음성 신호로부터 사용자의 감정 상태가 중립, 기쁨, 슬픔, 분노, 혐오, 놀람, 공포 중 적어 도 하나에 해당하는지 여부를 인식할 수 있다. 또 다른 측면에 따르면, 인식된 상기 사용자 특성 정보를 기반으로 사용자의 현재 상태에 해당하는 서비스를 제 공하는 단계를 더 포함할 수 있다. 사용자 특성 정보 인식 시스템에 있어서, 음성 신호에 해당하는 입력 데이터 셋(input data set)을 대상으로, 미리 지정된 복수의 특성 별로 프레임(frame)을 구분하는 프레임 구분부, 구분된 상기 특성 별 프레임을 대상으 로, 컨볼루션 뉴럴 네트워크(convolution neural network)를 기반으로 상기 복수의 특성 별 손실 함수에 기초하 여 학습을 수행하는 학습 제어부, 및 상기 학습을 통해 생성된 학습 모델에 기초하여 입력된 음성 신호에 해당 하는 서로 다른 복수의 사용자 특성 정보를 인식하는 사용자 특성 인식부를 포함할 수 있다. 일측면에 따르면, 상기 학습 제어부는, 소프트맥스(softmax) 함수에 기초하여 상기 복수의 특성 별로 손실 (loss)을 계산하고, 계산된 상기 복수의 특성 별 손실의 합에 기초하여 최종 학습의 기준을 설정할 수 있다. 다른 측면에 따르면, 상기 프레임 구분부는, 상기 입력 데이터 셋(input data set)을 대상으로, 사용자의 감정 (emotion), 나이(age) 및 성별(gender)을 위한 프레임으로 구분할 수 있다. 또 다른 측면에 따르면, 상기 학습 제어부는, 상기 컨볼루션 뉴럴 네트워크에 기반하는 각 컨볼루션 레이어를 대상으로 샘플링(sampling)을 수행하는 맥스 풀링(max pooling)을 수행할 수 있다. 또 다른 측면에 따르면, 상기 사용자 특성 인식부는, 상기 입력된 음성 신호로부터 사용자의 감정, 나이 및 성 별을 동시에 인식할 수 있다. 또 다른 측면에 따르면, 상기 사용자 특성 인식부는, 상기 사용자 특성 정보가 감정에 해당하는 경우, 상기 입 력된 음성 신호로부터 사용자의 감정 상태가 중립, 기쁨, 슬픔, 분노, 혐오, 놀람, 공포 중 적어도 하나에 해당 하는지 여부를 인식할 수 있다. 또 다른 측면에 따르면, 인식된 상기 사용자 특성 정보를 기반으로 사용자의 현재 상태에 해당하는 서비스를 제 공하는 서비스 제공부를 더 포함할 수 있다."}
{"patent_id": "10-2018-0071462", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 딥 러닝(deep learning) 기반 학습 알고리즘 중 컨볼루션 뉴럴 네트워크(convolution neural network)를 기반 학습을 이용하여 사용자의 음성 신호로부터 사용자의 감정, 나이 및 성별을 동시에 인식할 수있다. 또한, 사용자의 나이 및 성별과 함께 사용자의 감정을 인식함으로써, 성별에 따라, 그리고 나이에 따라 서로 다 른 음역대, 톤, 속도 등의 변화를 반영하여 보다 정확하게 사용자의 감정 상태를 인식할 수 있다."}
{"patent_id": "10-2018-0071462", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 본 실시예들은 사용자의 음성 신호를 기반으로 사용자의 감정, 나이, 성별을 동시에 인식하는 기술에 관한 것으 로서, 특히, 딥러닝 기법 중 컨볼루션 뉴럴 네트워크를 기반으로 학습하여 생성된 학습 모델을 이용하여 입력된 사용자의 음성 신호에 기초하여 사용자의 현재 감정 상태, 나이, 및 성별을 동시에 인식하는 기술에 관한 것이다. 본 실시예들에서, \"사용자 특성 정보\"는, 사용자의 감정, 나이 및 성별 등의 사용자의 상태를 나타낼 수 있다. 본 실시예들에서, \"컨볼루션 뉴럴 네트워크 기반 학습\"은 손실 함수(joint loss)가 최소화 값으로 수렴되도록 학습이 진행되는 것을 나타낼 수 있다. 도 1은 본 발명의 일실시예에 있어서, 사용자 특성 정보 인식 시스템의 내부 구성을 도시한 블록도이고, 도 2는 본 발명의 일실시예에 있어서, 사용자 특성 정보 인식 방법을 도시한 흐름도이다. 본 실시예에 따른 사용자 특성 정보 인식 시스템은 프로세서, 버스, 네트워크 인터페이스, 및 메모리를 포함할 수 있다. 메모리는 운영체제 및 서비스 제공 루틴를 포함할 수 있다. 프로세서는 프레임 구분부, 학습 제어부, 사용자 특성 인식부 및 서비스 제공부를 포 함할 수 있다. 다른 실시예들에서 사용자 특성 정보 인식 시스템은 도 1의 구성요소들보다 더 많은 구성 요소들을 포함할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예 를 들어, 사용자 특성 정보 인식 시스템은 디스플레이나 트랜시버(transceiver)와 같은 다른 구성요소들을 포함할 수도 있다. 메모리는 컴퓨터에서 판독 가능한 기록 매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치(permanent mass storage device)를 포함할 수 있다. 또한, 메모리에는 운영체제와 서비스 제공 루틴을 위한 프로그램 코드가 저장될 수 있다. 이러한 소 프트웨어 구성요소들은 드라이브 메커니즘(drive mechanism, 미도시)을 이용하여 메모리와는 별도의 컴퓨 터에서 판독 가능한 기록 매체로부터 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판독 가능한 기록 매체는 플 로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록 매체(미 도시)를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록 매체가 아닌 네트워크 인터페이스를 통해 메모리에 로딩될 수도 있다. 버스는 사용자 특성 정보 인식 시스템의 구성요소들 간의 통신 및 데이터 전송을 가능하게 할 수 있 다. 버스는 고속 시리얼 버스(high-speed serial bus), 병렬 버스(parallel bus), SAN(Storage Area Network) 및/또는 다른 적절한 통신 기술을 이용하여 구성될 수 있다. 네트워크 인터페이스는 사용자 특성 정보 인식 시스템을 컴퓨터 네트워크에 연결하기 위한 컴퓨터 하 드웨어 구성요소일 수 있다. 네트워크 인터페이스는 사용자 특성 정보 인식 시스템을 무선 또는 유 선 커넥션을 통해 컴퓨터 네트워크에 연결시킬 수 있다. 사용자 특성 정보 인식 시스템은 서버에 접속한 사용자 단말로 사용자의 음성 신호를 기반으로 사용자의 감정, 나이 및 성별 등의 사용자 특성 정보를 인식하고, 인식된 특성에 해당하는 서비스를 제공하도록 플랫폼 (platform) 형태로 구현될 수도 있고, 사용자 단말에 마련된 스피커 등을 통해 입력된 음성 신호를 기반으로 사 용자의 감정, 나이 및 성별 등의 사용자 특성 정보를 인식하는 어플리케이션(application, 즉, 서비스 앱) 형태 로 구현될 수도 있다. 이때, 사용자 단말에 어플리케이션 형태로 구현된 경우, 사용자 단말에서 인식된 사용자 특성 정보는 어플리케이션을 통해 서버인 서비스 제공자 단말로 전달될 수 있으며, 서비스 제공자 단말은 수신 된 사용자 특성 정보에 해당하는 서비스를 어플리케이션을 통해 사용자 단말로 제공할 수 있다. 프로세서는 기본적인 산술, 로직 및 사용자 특성 정보 인식 시스템의 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 네트워크 인터페이스에 의해, 그리고 버스를 통해 프로세서로 제공될 수 있다. 프로세서는 프레임 구분부, 학습 제어부, 사용자 특성 인식부 및 서비스 제공부를 위한 프로그램 코드를 실행하도록 구성될 수 있다. 이러한 프로그램 코드는 메모리와 같은 기록 장치에 저장될 수 있다. 프레임 구분부, 학습 제어부, 사용자 특성 인식부 및 서비스 제공부는 도 2의 단계들(210 내지 240 단계)을 수행하기 위해 구성될 수 있다. 210 단계에서, 프레임 구분부는 음성 신호에 해당하는 입력 데이터 셋(input data set)을 대상으로, 미리 지정된 복수의 특성 별로 프레임(frame)을 구분할 수 있다. 예를 들어, 사용자의 감정, 나이 및 성별을 동시에 인식하기 위한 학습 모델을 생성하고자 하는 경우, 프레임 구분부는 미리 수집된 서로 다른 다양한 사용자 들의 음성 신호에 해당하는 입력 데이터 셋을 사용자의 감정에 해당하는 프레임, 나이에 해당하는 프레임, 성별 에 해당하는 프레임으로 구분할 수 있다. 일례로, 프레임 구분부는 MFC(Mel Frequency Cepstral Coefficient)에 기초하여 음성 신호에 해당하는 입 력 데이터 셋에서 미리 지정된 유효한 소리에 해당하는 특징(feature)을 추출할 수 있다. 이때, 프레임 구분부 는 입력 데이터 셋 전체를 대상으로 특징을 추출하는 것이 아니라, 일정 구간, 즉, 일정 프레임씩 구분하 고, 프레임 별로 스펙트럼(spectrum) 분석을 통해 특징(feature)을 추출할 수 있다. 예컨대, 시간 영역에서 음 성 신호는 지속적으로 변화하므로, 변화하는 소리를 대상으로 특징을 추출하기 위해 미리 지정된 짧은 시간 내 에서는 음성 신호가 많이 변화지 않는다고 가정할 수 있다. 즉, 오차 범위 내에서 실제로 음성 신호의 변화가 거의 없다고 해석할 수 있다. 그러면, 프레임 구분부는 각 프레임 별로 파워 스펙트럼(즉, 주파수)를 계 산할 수 있다. 여기서, 프레임 별로 계산된 파워 스펙트럼이 특징(feature), 즉, 특징 벡터로서 추출될 수 있 다. 이처럼, 뉴럴 주파수 주파수가 계산되면, 각 구간에서 얼마만큼의 에너지가 존재하는지 여부를 알 수 있다. 220 단계에서, 학습 제어부는 상기 구분된 특성 별 프레임들을 대상으로, 컨볼루션 뉴럴 네트워크 (convolution neural network)를 기반으로 복수의 특성 별 손실 함수에 기초하여 학습을 수행할 수 있다. 즉, 프레임 구분부에서 계산된 파워 스펙트럼이 속하는 프레임들이 컨볼루션 뉴럴 네트워크의 입력층(input layer)의 입력값으로 설정될 수 있다. 예컨대, 특성(성별, 나이, 감정 등) 별로 25개의 프레임들이 학습을 위 해 입력층에 설정될 수 있다. 이처럼, 입력된 프레임 별 파워 스펙트럼, 즉, 각 특성(성별, 나이, 감정)에 해 당하는 특징 벡터들을 입력으로 받아 학습을 수행할 수 있다. 이때, 학습 제어부는 입력층(input layer), 은닉층(hidden layer) 및 출력층(output layer)으로 구성된 컨볼루션 뉴럴 네트워크 구조에서, 출력층에서 제시 한 값에 대해 실제 원하는 값으로 학습이 수행되도록 제어할 수 있다. 여기서, 각 층은 서로 교차되는 가중치 (weight) 값으로 연결되어 있을 수 있으며, 학습 제어부는 동일한 입력층에 대한 원하는 값이 출력되도록 각 층 별로 개개의 가중치를 조정하여 학습을 수행되도록 제어할 수 있다. 구체적으로, 학습 제어부는 적어도 하나의 은닉층에 속하는 특성 별 각 콘볼루션 레이어(CNN_ReLU)를 대상 으로 샘플링(sampling)을 수행하는 맥스 풀링(max pooling)을 수행할 수 있다. 예컨대, 학습 제어부는 적 어도 특성 별로 25장의 프레임이 설정된 경우, 25장의 프레임들에 해당하는 특징 벡터들에 가중치를 곱한 값 중 가장 큰 값을 특성 별(예컨대, 성별, 나이, 감정 별)로 모으는 맥스 풀링을 수행할 수 있다. 맥스 풀링이 수행되면, 학습 제어부는 소프트맥스(softmax) 함수에 기초하여 복수의 특성 별로 손실(los s)을 계산할 수 있으며, 계산된 복수의 특성 별 손실의 합에 기초하여 최종 학습의 기준을 설정할 수 있다. 즉, 학습 제어부는 감정, 나이, 성별 각각에 해당하는 손실을 계산하고, 계산된 손실(loss)을 아래의 수학 식 1에 기초하여 합쳐 조인트 손실(joint loss)을 계산할 수 있다. 그리고, 조인트 손실을 최종 학습의 기준으 로 설정할 수 있다. 다시 말해, 조인트 손실을 최소화하도록 학습이 수행되도록 감정, 나이, 성별 각각에 해당 하는 손실(loss)이 계산되도록 학습이 수행될 수 있다.[수학식 1]"}
{"patent_id": "10-2018-0071462", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서, Lgender는 소프트맥스(softmax) 함수에 기초하여 계산된 성별에 해당하는 손실, Lage는 나이에 해당 하는 손실, Lemotion은 감정에 해당하는 손실을 나타낼 수 있다. 이처럼, 소프트맥스 함수를 이용하여 감정, 나이, 성별 각각에 해당하는 손실(loss)을 계산하고, 계산된 손실의 합으로써 조인트 손실(joint loss)를 계산하여 최종 학습의 기준으로 설정함으로써, 하나의 음성 신호를 대상으 로 여러 가지 태스크(task)에 해당하는 사용자의 감정, 나이, 성별을 동시에 인식하기 위한 멀티 태스크 학습 (multi-task learning)이 수행될 수 있다. 수학식 1에 따르면, 학습 제어부는 각 태스크(성별, 감정, 나이) 별로 가중치를 단순하게 더하는 것이 아 니라, 변수화하여 학습시켜 weighted sum을 최종 학습의 기준으로 설정할 수 있다. 230 단계에서, 사용자 특성 인식부는 학습을 통해 생성된 학습 모델에 기초하여 입력된 음성 신호에 해당 하는 서로 다른 복수의 사용자 특성 정보를 동시에 인식할 수 있다. 예컨대, 수학식 1에 기초하여 계산된 조인 트 손실(joint loss)을 최종 학습의 기준으로 설정하여 생성된 학습 모델에 사용자 단말의 스피커 등을 통해 입 력된 음성 신호를 입력으로 설정할 수 있다. 그리고, 학습 모델의 출력으로서, 상기 입력된 음성 신호를 대상 으로 인식된 사용자의 나이 및 성별이 출력될 수 있다. 이때, 나이 및 성별과 함께 사용자의 현재 감정 상태가 동시에 인식되어 출력될 수 있다. 일례로, 사용자의 나이와 성별에 따라 음성의 음역대와 강도가 상이할 수 있다. 예컨대, 여성의 음역대가 남성 보다 고주파 대역으로 차이를 보이며, 어린 아이일수록 주파수 대역이 어른보다 상대적으로 높은 차이점을 가질 수 있다. 이처럼, 학습 모델에서 사용자의 성별 및 나이가 인식됨과 동시에 사용자의 현재 감정 상태가 세부적 으로 인식되어 출력될 수 있다. 감정의 상태에 따라 음성의 톤, 속도, 떨림 등의 변화가 존재하며, 톤, 속도, 떨림 등을 나타내는 특징 벡터들, 음성 신호의 음역대 및 강도에 해당하는 특징 벡터들을 기반으로 해당 성별의 해당 나이의 사용자의 감정 상태가 미리 지정된 복수의 감정 상태 중 어디에 해당하는지 여부가 인식될 수 있다. 예컨대, 사용자의 감정 상태가 중립, 기쁨, 슬픔, 분노, 혐오, 놀람, 공포 등 7가지 감정 중 적어도 하 나에 해당하는지 여부가 인식될 수 있다. 예컨대, 20대 여성이나 7세 이하의 아이의 음성 신호의 경우, 추출된 특징 벡터에 해당하는 주파가 기쁨에 해당 하나, 40대 남성의 경우, 분노, 놀람에 해당하는 것과 같이 서로 상이할 수 있다. 이에 따라, 학습 모델로 입 력되는 하나의 음성 신호를 대상으로 사용자의 나이, 성별 및 감정이라는 세 가지 특성을 동시에 인식함으로써, 사용자의 나이 및 성별에 따라 달라지는 생리적 음성 특성을 반영하여 사용자의 실제 감정 상태를 보다 잘 인식 할 수 있다. 여기서는 기쁨에 해당하는 경우를 예로 들어 설명하였으나, 둘 이상의 감정 상태에 해당하는 것으 로 인식될 수도 있다. 예컨대, 놀람 및 공포에 해당하는 감정 상태, 놀람, 공포 및 분노의 감정 상태 등으로 인식되는 것 역시 가능할 수 있다. 240 단계에서, 사용자의 나이, 성별 및 감정이 인식되면, 서비스 제공부는 인식된 나이, 성별 및 감정을 기반으로 사용자의 상태에 적합한 서비스를 제공할 수 있다. 예를 들어, 음악 서비스를 제공하는 경우, 사용자의 감정이 기쁨에 해당하고 7세 이하의 여아에 해당하는 경우, 생일 축하 동요를 제공할 수 있다. 사용자의 감정이 기쁨에 해당하고 7세 이하의 남아에 해당하는 경우, 미리 지정된 해당 나이대에서 인기 있는 만화 엔딩곡이나 오프닝곡 등을 제공할 수 있다. 사용자의 감정이 기쁨에 해당하고 20대의 남성에 해당하는 경우, 미리 지정된 해당 나이대에서 인기 있는 KPOP 등을 제공할 수 있다. 영화 서비스를 제공하는 경우에도 마찬가지로, 서비스 제공부는 사용자의 감정, 나이 및 성별을 고려하여, 서비스를 제공할 수 있다. 이외에, 고객 센터, 전화 상담 시, 연결된 상대방 단말을 통해 입력된 음성 신호를 기반으로 사용자의 감정, 나 이 및 성별이 인식되면, 서비스 제공부는 미리 지정된 고객 대응 매뉴얼에서 상기 인식된 사용자의 감정, 나이 및 성별에 해당하는 대응 방법을 고객 센터나 전화 상담사의 단말로 제공할 수 있다. 이때, 인식된 사용 자의 감정, 나이 및 성별 정보가 함께 제공될 수 있다. 그러면, 고객 센터 담당자나 전화 상담사가 사용자의 감정, 나이 및 성별 정보, 상기 제공된 대응 방법을 참고하여 사용자의 현재 상태에 알맞게 사용자의 요청 사항 에 효과적으로 대응하도록 도움을 줄 수 있다. 예컨대, 사용자가 제품 고장, 오배송으로 인해 고객 센터로 전화한 경우, 감정 상태가 분노인 사용자가 있을 수도 있고, 중립인 사용자가 존재할 수도 있다. 이때, 서비스 제공부는 인식된 사용자의 나이, 성별 및 감정 상태와 함께 해당하는 대응방법을 제공함으로써, 고객 센터 담당자가 해당 사용자에게 적절한 대응을 하도록 할 수 있다. 예컨대, 고령인 남성이고, 감정이 분노 상태인 경우, 많은 시간을 소비하거나 분노 게이지를 높이지 않고 신속하게 요구 사항을 들어주도록 할 수 있으며, 이 때, 고령의 남성이 인지하기 쉬운 말투 및 속도로 전화에 응대하도록 하는 대응 방법을 제공할 수 있다. 도 3은 본 발명의 일실시예에 있어서, 컨볼루션 뉴럴 네트워크 구조를 도시한 도면이다. 도 3을 참고하면, 컨볼루션 뉴럴 네트워크는 입력층, 은닉층 및 출력층을 포함할 수 있다. 은닉층는 복수개의 레이어(layer)로 구성될 수 있다. 도 3에서, 40차원의 멜 스펙트로그램(mel spectrogram) 25개가 입력층의 입력으로 설정될 수 있다. 이때, 특성 (감정, 나이, 성별) 별로, 25개의 프레임들(즉, mel spectrogram*25)이 입력으로 설정될 수 있다. 멜 스펙트로 그램은 인간의 청각적 지각 방식에 최적화된 2D 표현 방식으로, 주파수 축에서 STFT(Short Time Fourier Transform)을 압축하여 가장 중요한 정보를 보존하는 음성 신호 표현 기법을 나타낼 수 있다. 이처럼, 입력층에 특성 별로 복수개의 프레임들이 설정되면, 각 프레임에 해당하는 특징 벡터 별로 가중치가 곱 해지고, 가중치가 곱해진 값들 중 최대값을 특성 별로 모으는 맥스 풀링(max pooling)이 수행될 수 있다. 맥스 풀링된 값들을 대상으로 소프트맥스 함수에 기초하여 특성 별 손실(loss)이 계산되고, 계산된 손실을 상기 수학식 1에 기초하여 합함으로써, 음성 신호에서 감정, 성별, 나이를 동시에 인식하기 위한 학습 모델을 생성하 는 조인트 손실(joint loss) 계산할 수 있다. 이처럼, 조인트 손실이 계산되면, 최종 학습 기준으로 설정하고, 입력 데이터 셋을 대상으로 상기 조인트 손실이 최소값에 수렴하도록 학습이 수행될 수 있다. 그러면, 특정 음 성 신호가 입력되면, 상기 학습이 수행됨에 따라 생성된 학습 모델을 기반으로, 상기 입력된 특정 음성 신호에 서 추출된 특징 벡터를 상기 학습 모델의 입력으로 설정하여, 상기 음성 신호에 해당하는 사용자의 나이, 성별 및 감정이 인식되어 출력값으로 출력될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2018-0071462", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3"}
{"patent_id": "10-2018-0071462", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 있어서, 사용자 특성 정보 인식 시스템의 내부 구성을 도시한 블록도이다. 도 2는 본 발명의 일실시예에 있어서, 사용자 특성 정보 인식 방법을 도시한 흐름도이다. 도 3은 본 발명의 일실시예에 있어서, 컨볼루션 뉴럴 네트워크 구조를 도시한 도면이다."}
