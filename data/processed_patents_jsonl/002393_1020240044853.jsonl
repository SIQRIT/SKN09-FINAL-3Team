{"patent_id": "10-2024-0044853", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0151644", "출원번호": "10-2024-0044853", "발명의 명칭": "인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템", "출원인": "백운복", "발명자": "백운복"}}
{"patent_id": "10-2024-0044853", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음원 사이트로부터 제공받은 음성합성 대상노래를 가창음성 합성(SVS) 모델에 입력하여 상기 음성합성 대상노래의 가사중 사람 이름 및 인칭 대명사를 사용자 이름으로 자동 변경한 가창 데이터를 생성하는 합성부; 및상기 생성된 가창 데이터를 상기 음원 사이트로 제공하는 제공부를 포함하는인공지능 기반 사용자 맞춤형 가창서비스 제공 시스템."}
{"patent_id": "10-2024-0044853", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 사용자 이름은 사용자의 실명 및 닉네임을 포함하는 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템."}
{"patent_id": "10-2024-0044853", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "음원 사이트로부터 제공받은 음성합성 대상노래를 가창음성 합성(SVS) 모델에 입력하여 상기 가사 데이터가 반영된 가창 데이터를 생성하는 합성부; 및상기 생성된 가창 데이터를 상기 음원 사이트로 제공하는 제공부를 포함하는 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템."}
{"patent_id": "10-2024-0044853", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 상기 음원 사이트에서 상기 음성합성 대상노래를 선택받는 지정부; 및상기 SVS 모델을 구축할 때 BEGAN(Boundary Equilibrium GAN(Generative Adversarial Network))에 기반한BEGANSing 모델 또는 HIFI-GAN(High Fidelity Speech Synthesis GAN(Generative Adversarial Network))을 이용하는 모델설정부;상기 SVS 모델을 구축하기 위하여 적어도 하나의 가수의 음성 데이터셋을 수집하고, 상기 적어도 하나의 가수의음성 데이터셋이 기 설정된 수를 만족하지 않는 경우 데이터 증강(Data Augmentation)을 수행하고, 상기 데이터증강시 피치변조(Pitch Shift) 및 속도조절(Time Stretch)로 증강한 음원 데이터셋을 이용하도록 하는 데이터증강부;상기 가사 데이터를 TTS(Text to Speech)를 이용하여 음성으로 변환할 때, Glow-TTS를 이용하여 텍스트와 음성간 가장 가능성이 높은 정렬(Alignment)을 자동으로 검색해 텍스트 순서에 따라 발화를 차례로 정렬하도록 하는정렬부; 및상기 가창 데이터에 대하여 상기 노래의 적어도 하나의 저작권 단말의 이용허락이 전제된 경우, 상기 가창 데이터를 공유 및 유통하는 스트리밍부; 및상기 공유 및 유통으로 인한 수익이 발생하는 경우, 상기 음원 사이트 및 적어도 하나의 저작권 단말로 수익을분배하는 분배부;를 더 포함하는 것을 특징으로 하는 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템."}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템이 제공되며, 음원 사이트로부터 제공받은 음성합성 대상 노래를 SVS 모델에 입력하여 상기 음성합성 대상노래의 가사중 사람 이름 및 인칭 대명사를 사용자 이름으로 자 동 변경한 가창 데이터를 생성하는 합성부; 및 상기 생성된 가창 데이터를 상기 음원 사이트로 제공하는 제공부 를 포함한다."}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 가창 서비스에 관한 것으로, 보다 상세하게는 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템 을 제공한다."}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성합성 기술(TTS; Text-To-Speech)을 기반으로 고수준의 음성합성시스템이 개발되면서, 음정과 감정을 포괄하 여 가창데이터를 합성해내는 가창음성 합성(Singing Voice Synthesis; 이하 'SVS'라 함)로 발전하고 있다. 메타 버스와 가상 엔터테이너에 대한 관심이 급증하면서 다양한 SVS 모델에 대한 연구 또한 활발하다. SVS란 가사 (Text)와 노래하는 음성(Voice), 그리고 멜로디 정보가 담겨있는 미디(MIDI)데이터를 입력으로 하여 자연스럽게 노래를 합성하는 시스템이다. 최근에는 AI 기반 지능형 디바이스의 응용시나리오 수준이 높아짐에 따라 딥러닝 이나 종단기술(End-to-End)을 활용하는 고성능 알고리즘 연구로 이어져 이미지 합성에 주로 적용되었던 DNN, LSTM, GAN을 SVS 모델에도 적용하기 위한 연구가 활발히 시도되고 있다. 이때, 클라이언트 단말로 음원을 제작하거나 가수의 음성을 합성하는 방법이 연구 및 개발되었는데, 이와 관련 하여, 선행기술인 한국공개특허 제2012-0122295호(2012년11월07일 공개) 및 한국공개특허 제2021-0155520호 (2021년12월23일 공개)에는, 음성합성기술을 이용하여 보컬 콘텐츠를 생성하기 위해, 가사, 음계, 음길이 및 창 법을 포함한 음악정보를 입력하면 음계에 따른 운율을 설정된 음길이로 발성하여 음성으로 합성하는 구성과, 가 수 및 노래를 지정한 후 DNN 기반 추론모델을 이용하여 가수에 대한 음색 및 가창 스타일을 생성하고, 음색이 조절된 포먼트(Formant) 및 가창 스타일이 조절된 음고골격을 생성하며, DNN 기반 SR 변환모델을 이용하여 포먼 트로 마스킹된 음고골격으로부터 노래에 대한 가창음성을 생성하는 구성이 각각 개시되어 있다. 다만, 전자의 경우 가사 뿐만 아니라 음계, 음길이 및 창법을 모두 전문가가 아닌 일반인인 사용자가 설정해야 하므로 복잡한 조작을 하지 못하거나 전문가적인 지식이 없는 경우에는 설정 자체가 불가하여 사용할 수가 없다. 후자의 경우에도 음색, 가창 스타일, 포먼트 및 음조골격에 대한 미세조정작업이 요구되는데 역시 일반 인인 사용자는 음악제작에 대한 기본적인 지식이 없는 경우 이 작업마저 어려운 경우가 대다수다. 이에, 사용 자가 가사를 바꾸는 개사를 하는 경우 원 가수의 목소리로 개사된 가사를 불러주는 가창 시스템의 연구 및 개발 이 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허 제2012-0122295호(공개일: 2012년11월07)"}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 음원 사이트로부터 제공받은 음성합성 대상노래를 가창음성 합성(SVS) 모델에 입력하여 음성합성 대 상노래의 가사중 사람 이름 및 인칭 대명사를 사용자 이름으로 자동 변경한 가창 데이터를 생성하여 상기 음원 사이트로 제공할 수 있는 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템를 제공하는데 그 목적이 있다. 본 발명의 다른 목적은 음원 사이트로부터 제공받은 음성합성 대상노래 및 가사 데이터를 가창음성 합성(SVS) 모델에 입력하여 상기 가사 데이터가 반영된 가창 데이터를 생성하여 음원 사이트로 제공할 수 있는 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템을 제공하는데 있다."}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템은 음원 사이트로부터 제공받은 음성합성 대상노래를 가창음성 합성(SVS) 모델에 입력하여 상기 음성합성 대상노래의 가사중 사람 이름 및 인칭 대명사를 사용자 이름으로 자동 변경한 가창 데이터를 생성하는 합성부; 및 상기 생성된 가창 데이터를 상기 음원 사이트 로 제공하는 제공부를 포함하는 것을 특징으로 한다. 상기 사용자 이름은 사용자의 실명 및 닉네임을 포함할 수 있다. 상기 인공지능 기반 사용자 맞춤형 가창 서비 스 제공 시스템은 상기 음원 사이트에서 상기 음성합성 대상노래를 선택받는 지정부; 및 상기 SVS 모델을 구축 할 때 BEGAN(Boundary Equilibrium GAN(Generative Adversarial Network))에 기반한 BEGANSing 모델 또는 HIFI-GAN(High Fidelity Speech Synthesis GAN(Generative Adversarial Network))을 이용하는 모델설정부를 더 포함할 수 있다. 본 발명의 다른 실시예에 따른 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템은 음원 사이트로부터 제 공받은 음성합성 대상노래를 가창음성 합성(SVS) 모델에 입력하여 상기 가사 데이터가 반영된 가창 데이터를 생 성하는 합성부; 및 상기 생성된 가창 데이터를 상기 음원 사이트로 제공하는 제공부를 포함하는 것을 특징으로 한다. 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템은 상기 SVS 모델을 구축하기 위하여 적어도 하나의 가수 의 음성 데이터셋을 수집하고, 상기 적어도 하나의 가수의 음성 데이터셋이 기 설정된 수를 만족하지 않는 경우 데이터 증강(Data Augmentation)을 수행하고, 상기 데이터 증강시 피치변조(Pitch Shift) 및 속도조절(Time Stretch)로 증강한 음원 데이터셋을 이용하도록 하는 데이터증강부;상기 가사 데이터를 TTS(Text to Speech)를 이용하여 음성으로 변환할 때, Glow-TTS를 이용하여 텍스트와 음성 간 가장 가능성이 높은 정렬(Alignment)을 자동으로 검색해 텍스트 순서에 따라 발화를 차례로 정렬하도록 하는 정렬부; 및 상기 가창 데이터에 대하여 상 기 노래의 적어도 하나의 저작권 단말의 이용허락이 전제된 경우, 상기 가창 데이터를 공유 및 유통하는 스트리 밍부;를 더 포함할 수 있다. 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템은 상기 공유 및 유통으로 인한 수익이 발생하는 경우, 상기 음원 사이트 및 적어도 하나의 저작권 단말로 수익을 분배하는 분배부;를 더 포함할 수 있다."}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 본 발명은 음원 사이트로부터 제공받은 음성합성 대 상노래를 SVS 모델에 입력하여 음성합성 대상노래의 가사중 사람 이름 및 인칭 대명사를 사용자 이름으로 자동 변경한 가창 데이터를 생성하여 음원 사이트로 제공할 수 있다. SVS란 가사(Text)와 노래하는 음성(Voice), 그리고 멜로디 정보가 담겨있는 미디(MIDI)데이터를 입력으로 하여 자연스럽게 노래를 합성하는 시스템으로서, 노래 음성합성은 원하는 음악의 미디 파일과 가사를 입력받으면 지 정된 목소리로 노래를 생성하는 서비스이다. 또한 본 발명은 음원 사이트를 통해 노래를 선택하는 경우, SVS 가창 음성합성을 이용하여 노래를 부른 원 가수 가 부른 것 같은 가창 데이터를 생성함으로써 전문가가 아니더라도 일반인도 누구나 개사를 해보고 이에 대한 결과를 확인해볼 수 있으며, 사용자 이름으로 변경한 음원에 대한 거래나 유통을 할 수 있도록 플랫폼을 제공할 수 있고, 실연자인 가수와 노래를 작곡한 작곡가의 권리에 대한 보상으로 수익을 배분할 수 있어 인기있는 음원 의 경우 판매량이나 관심을 더 높일 수 있으며, 인기가 없던 음원의 경우 개사로 인하여 다시 흥행할 수 있는 기회를 제공할 수 있다. 또한 본 발명은 원곡의 가사 중 사람 이름 및 인칭 대명사를 사용자 이름으로 변경하는 것을 특정하여 이 외의 가사의 무분별한 변경으로 인해 불러올 폐해를 방지할 수 있다."}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미하며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 명세서 전체에서 사용되는 정도의 용어 \"약\", \"실질적으로\" 등은 언급된 의미에 고유한 제조 및 물질 허용오차 가 제시될 때 그 수치에서 또는 그 수치에 근접한 의미로 사용되고, 본 발명의 이해를 돕기 위해 정확하거나 절 대적인 수치가 언급된 개시 내용을 비양심적인 침해자가 부당하게 이용하는 것을 방지하기 위해 사용된다. 본 발명의 명세서 전체에서 사용되는 정도의 용어 \"~(하는) 단계\" 또는 \"~의 단계\"는 \"~ 를 위한 단계\"를 의미하지 않는다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 한편, '~부'는 소프트웨어 또는 하드웨어 에 한정되는 의미는 아니며, '~부'는 어드레싱 할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객 체 지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회 로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또 는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 본 명세서에 있어서 단말, 장치 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말, 장치 또는 디바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기 술된 동작이나 기능 중 일부도 해당 서버와 연결된 단말, 장치 또는 디바이스에서 수행될 수도 있다. 본 명세서에서 있어서, 단말과 매핑 또는 매칭으로 기술된 동작이나 기능 중 일부는, 단말의 식별 정보인 단말 기의 고유번호나 개인의 식별정보를 매핑 또는 매칭한다는 의미로 해석될 수 있다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 인공지능 기반 사용자 맞춤 가사를 이용한 가창 서비스 제공 시스템을 설명 하기 위한 도면이다. 도 1을 참조하면, 인공지능 기반 사용자 맞춤 가사를 이용한 가창 서비스 제공 시스템 은, 음원 사이트, 가창 서비스 제공 서버, 적어도 하나의 저작권자 단말을 포함할 수 있다. 다만, 이러한 도 1의 인공지능 기반 사용자 맞춤 가사를 이용한 가창 서비스 제공 시스템은, 본 발명의 일 실시예에 불과하므로, 도 1을 통하여 본 발명이 한정 해석되는 것은 아니다. 본 발명의 실시예에 따른 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템은 음원 사이트 및 가창 서비스 제공 서버을 포함한다. 음원 사이트은 음성합성 대상노래 및 사용자 이름을 가창 서비스 제공 서버로 제공한다. 가창 서비스 제공 서버는 상기 음원 사이트로부터의 상기 음성합성 대상노래를 SVS 모델에 입력하여 상기 음성합성 대상노래의 가사중 사람 이름 및 인칭 대명사를 사용자 이름으로 자동 변경한 가창 데이터를 생 성하여 음원 사이트로 제공한다. 상기 인칭 대명사의 예에는 나, 너, 당신, 그, 그녀, 그들 등이 있고, 상기 인칭 대명사는 체언과 조사가 어울 려 줄어진 준말(한국어 어문 규범 한글 맞춤법 제 4 장 제 5 절 제 33 항 참조)을 포함할 수 있다. 그 예로는 날, 널, 그녈 등이 있다. 또한, 상기 사용자 이름은 사용자의 실명 및 닉네임을 포함할 수 있고, 상기 사용자 이름 뒤에 이어지는 조사는 문법에 맞게 자동으로 변경할 수 있는 것을 포함한다. 이때, 도 1의 각 구성요소들은 일반적으로 네트워크를 통해 연결된다. 예를 들어, 도 1에 도시된 바와 같 이, 음원 사이트은 네트워크를 통하여 가창 서비스 제공 서버와 연결될 수 있다. 그리고, 가창 서비스 제공 서버는, 네트워크를 통하여 적어도 하나의 음원 사이트, 적어도 하나의 저작권자 단말과 연결될 수 있다. 또한, 적어도 하나의 저작권자 단말은, 네트워크를 통하여 가창 서비 스 제공 서버와 연결될 수 있다. 여기서, 네트워크는, 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의 미하는 것으로, 이러한 네트워크의 일 예에는 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷(WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), 5GPP(5th Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency), 블루투스 (Bluetooth) 네트워크, NFC(Near-Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워 크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 하기에서, 적어도 하나의 라는 용어는 단수 및 복수를 포함하는 용어로 정의되고, 적어도 하나의 라는 용어가 존재하지 않더라도 각 구성요소가 단수 또는 복수로 존재할 수 있고, 단수 또는 복수를 의미할 수 있음은 자명 하다 할 것이다. 또한, 각 구성요소가 단수 또는 복수로 구비되는 것은, 실시예에 따라 변경가능하다 할 것이다. 음원 사이트는, 인공지능 기반 사용자 맞춤형 가창 서비스 관련 웹 페이지, 앱 페이지, 프로그램 또는 애 플리케이션을 이용하여 노래를 선택하고 사용자 이름을 업로드하고, SVS 모델로 출력된 가창 데이터를 수신하는 서버일 수 있다. 여기서, 음원 사이트는, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저가 탑재된 노트북, 데스크톱(Desktop), 랩톱 (Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 음원 사이트는, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 음원 사이트은, 예를 들어, 휴대성과 이동 성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트 폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기 반의 무선 통신 장치를 포함할 수 있다. 가창 서비스 제공 서버는, 인공지능 기반 사용자 맞춤 가사를 이용한 가창 서비스 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 제공하는 서버일 수 있다. 그리고, 가창 서비스 제공 서버는, 적어도 하나 의 SVS 모델을 구축하기 위해 음성 데이터셋을 수집 및 전처리하고, 적어도 하나의 SVS 모델에 입력하여 학습 및 검증을 진행함으로써 모델링하며, 가장 퀄리티가 높은 또는 정확도가 높은 SVS 모델을 가창 서비스 제공 서 버의 SVS 모델로 세팅하는 서버일 수 있다. 또한, 가창 서비스 제공 서버는, 음원 사이트에서 노래를 선택하고 가사 데이터를 입력하는 경우, 가수의 음성으로 가사를 부른 가창 데이터를 생성한 후 음원 사 이트로 전달하는 서버일 수 있다. 그리고, 가창 서비스 제공 서버는, 적어도 하나의 저작권자 단말 로부터 이용허락을 받은 경우, 음원 사이트에서 사용자 이름으로 자동 변경한 가사 데이터로 생성된 가창 데이터에 대한 유통을 수행하는 서버일 수 있고, 수익이 발생하는 경우 음원 사이트 및 적어도 하나 의 저작권자 단말로 분배하는 서버일 수 있다. 여기서, 가창 서비스 제공 서버는, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저가 탑재된 노트북, 데스크톱, 랩톱 등 을 포함할 수 있다. 적어도 하나의 저작권자 단말은, 인공지능 기반 사용자 맞춤 가사를 이 용한 가창 서 비스 관련 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 이용하여 음원에 대한 저작권을 등록하고, 이 용허락 여부를 설정하는 단말일 수 있다. 이용허락을 한 경우 저작권자 단말은 음원 사이트로부터 제 공받은 사용자 이름으로 개사 한 음원에 대하여 유통으로 수익이 발생하는 경우 수익을 분배받는 단말일 수 있 다. 적어도 하나의 저작권자 단말은, 인공지능 기반 사용자 맞춤 가사를 이용한 가창 서비스 관련 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 이용하여 음원에 대한 저작권을 등록하고, 이용허락 여부를 설정하는 단말일 수 있다. 이용허락을 한 경우 저작권자 단말은 음원 사이트로부터 제공받은 사용자 이름으로 개사한 음원에 대하여 유통으로 수익이 발생하는 경우 수익을 분배받는 단말일 수 있다. 여기서, 적어도 하나의 저작권자 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨 터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저가 탑재된 노트북, 데스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 저작권자 단말은, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 도 2는 도 1의 시스템에 포함된 가창 서비스 제공 서버를 설명하기 위한 블록 구성도이고, 도 3 및 도 4는 본 발명의 일 실시예에 따른 인공지능 기반 사용자 맞춤 가사를 이용한 가창 서비스가 구현된 일 실시예를 설명하 기 위한 도면이다. 상기 가창 서비스 제공 서버는 상기 음원 사이트에서 상기 음성합성 대상노래를 선택받는 지정부 ; 상기 음성합성 대상노래를 상기 SVS 모델에 입력하여 상기 음성합성 대상노래의 가사중 사람 이름 및 인 칭 대명사를 사용자 이름으로 자동 변경한 상기 가창 데이터를 생성하는 합성부; 및 상기 가창 데이터를 상기 음원 사이트로 제공하는 제공부를 포함한다. 도 2를 참조하면, 가창 서비스 제공 서버는, 지정부, 합성부, 제공부, 모델설정부, 데이터증강부, 정렬부, 스트리밍부, 분배부를 포함할 수 있다. 본 발명의 일 실시예에 따른 가창 서비스 제공 서버나 연동되어 동작하는 다른 서버(미도시)가 적어도 하 나의 음원 사이트 및 적어도 하나의 저작권자 단말로 인공지능 기반 사용자 맞춤 가사를 이용한 가창 서비스 애플리케이션, 프로그램, 앱 페이지, 웹 페이지 등을 전송하는 경우, 음원 사이트 및 저작권자 단 말은, 인공지능 기반 사용자 맞춤 가사를 이용한 가창 서비스 애플리케이션, 프로그램, 앱 페이지, 웹 페 이지 등을 설치하거나 열 수 있다. 또한, 웹 브라우저에서 실행되는 스크립트를 이용하여 서비스 프로그램이 적어도 하나의 음원 사이트 및 적어도 하나의 저작권자 단말에서 구동될 수도 있다. 여기서, 웹 브 라우저는 웹(WWW: World Wide Web) 서비스를 이용할 수 있게 하는 프로그램으로 HTML(Hyper Text Mark-up Language)로 서술된 하이퍼 텍스트를 받아서 보여주는 프로그램을 의미하며, 예를 들어 넷스케이프(Netscape), 익스플로러(Explorer), 크롬 등을 포함한다. 또한, 애플리케이션은 단말 상의 응용 프로그램을 의미하며, 예를 들어, 모바일 단말(스마트폰)에서 실행되는 앱을 포함한다. 도 2를 참조하면, 지정부는, 음원 사이트로부터 음성합성 대상노래를 선택받을 수 있다. 합성부는, 음원 사이트로부터의 사용자 이름을 제공받는 경우, 기 구축된 SVS(Singing Voice Synthesis) 모델을 이용할 수 있다. 전통적인 SVS 모델은 크게 조각연결(Concatenative/Non-Parametric) 기반 의 방법과 통계적 방법을 확장시킨 매개변수(Statistical Parametric Method)기반의 방법으로 접근할 수 있다. 연결 기반의 SVS 모델은 꽤 높은 음질의 소리를 제공하는 반면 연결된 유닛들간의 경계가 불연속성을 띄어 유연 성(Flexibility)이 부족하여 매우 큰 용량의 데이터베이스가 필요로 하다는 문제가 있었다. 가수의 녹음 목록 에서 선택한 짧은 웨이브 파형 유닛을 변형하여 연결하는 모델도 존재하는데, 상술한 문제점을 회피하기 위해 훈련된 HMM(Hidden Markov Model)에 의해 예측된 음향 매개변수(Acoustic Parameter)로부터 가창데이터의 웨이 브파형을 합성하는 통계적 매개변수 기반의 SVS 모델을 이용할 수도 있다. 이 모델은 연결기반 모델에 비해 요 구되는 데이터의 양이 적으나 프로세스 모듈 구조가 대부분 다중 파이프라인이며, 합성된 노래의 자연스러움 (Naturalness)을 저하시키는 과평활화(Over-Smoothing) 문제가 제기되었다. 이때까지는 밴드, 주파수 파형 등 의 보코더 파라미터를 예측하는 SVS 시스템이 많이 나왔다면, 최근에는 BEGAN 기반의 학습을 수행하되 인코더와 보코더, 여러 요인들마다 다양한 알고리즘을 적용한 모델들이 제안되면서 Cycle-BEGAN 같은 변형알고리즘도 등 장하기 시작했다. <BEGAN> BEGAN은 기본적으로 판별자로 오토인코더(Auto-Encoder)를 사용한다. 따라서 판별자는 이미지를 복원하고 진짜 이미지와 가짜 이미지를 구별하는 두 가지 역할을 하게 되는데, 이때 두 역할 간의 균형을 맞추어 안정적인 학 습을 할 수 있도록 하이퍼파라미터 감마(γ)∈[0,1]를 두었다. 수학식 1"}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서 G(x)는 생성된 가짜 샘플, y는 실제 샘플, L은 오토인코더의 재구성 에러이다. 감마값이 작을수 록 판별자가 실제 샘플 y를 오코인코딩 하는데 더 초점을 두기 때문에 생성된 샘플의 품질(Quality)은 높아지지만 다양성(Diversity)이 낮아지고 감마값이 높으면 그 반대로 나타난다. 이때, 보코더 특성이 아닌 선형 스펙 트로그램(Linear-Spectrogram)을 생성해내는 한국어 SVS 시스템을 이용할 수도 있는데 해당 모델은 적절한 양의 텍스트, 미디, 음성의 입력데이터로부터 멜 스펙트로그램(Mel-Spectrogram)을 생성해낸 후 이를 선형 스펙트로 그램으로 업샘플링하는 과정을 거친다. 또한, 음성 향상 마스킹기법을 적용하여 발음의 정확성을 높고, 특히 CGAN(Conditional GAN)을 적용하면 더 현실적인 가창데이터를 생성할 수 있다. 이에 본 발명의 일 실시예에서 도 한국어 SVS모델에 기반하여 CGAN을 기반으로 한 보코더 파라미터 대신 스펙트로그램을 생성할 수 있고, 안정 적인 학습과 합성된 노래의 음질을 높이기 위해 BEGAN-Objective를 적용할 수 있다. 또, 음성신호를 노래로 변 환하는 학습모델 구조와 생성자 손실함수를 이용할 수도 있는데, 본 발명의 일 실시예에서는 입력 및 출력데이 터로 로그 멜-스펙트로그램(Log Mel-Spectrogram)과 멜로디 파형(Melody Contour)을 L1 Loss와 함께 사용하고 특정값으로 세팅한 조절상수 베타를 이용할 수 있고, 인코더와 보코더, 적대적 방법의 적용여부에 따른 실험모 델을 만들어 성능을 테스트할 수도 있다. <GAN> GAN은 대표적인 생성모델들 중 하나로 모델이 수렴에 도달하면 생성자는 실제 샘플과 거의 구분되지 않는 샘플 을 생성해 낼 수 있지만, 어느 순간 생성자가 의미없이 계속 같은 모양의 생성물을 출력해내는 모드붕괴(Mode Collapse) 현상이 발생한다. 예를 들어, 판별자를 속이는 데만 최적화된 생성자와 지역최적화(Local Minima)에 빠진 판별자 하에서는 학습효과를 기대할 수 없으므로 적대적 학습과정을 수행하는 동안 특정요소에 치우치지 않도록 학습불안정 및 불균형을 해소해야 한다. 이때, BEGAN(Boundary Equilibrium Generative Adversarial Networks)은 이러한 GAN의 한계를 극복하고자 구글에서 제안한 알고리즘으로 일반적인 GAN이 실제 샘플과 생성 된 샘플간의 분포를 일치시키기 위한 학습을 수행하는 반면, BEGAN은 오토인코더 아키텍처를 사용하여 손실 분 포를 일치시킨다. 또한 판별자와 생성자 사이의 균형을 조정해주는 평형 개념(Equilibrium Concept)을 도입하 여 하이퍼파라미터 감마(γ)를 통해 생성데이터의 다양성(Diversity)과 품질(Quality) 사이의 균형을 조정할 수 있어 다른 GAN 모델보다 더 나은 성능을 보인다. 이때, 자연스러운 노래를 합성해 낼 수 있는 SVS 모델 구조를 설계하고, 상술한 BEGAN의 생성자 손실함수에 L1 Loss를 추가하는 방식도 이용될 수 있는데, L2 Loss와 달리 오 디오의 특성상 나타날 수 있는 이상치를 적절히 무시하면서 과적합을 방지할 수 있는 조절자 역할이 기대되지만 실제로 생성된 데이터의 다양성과 품질 사이의 균형을 조절하는 역할을 했던 하이퍼 파라미터 감마(γ)의 역할 이 반전되는 시점이 나타날 수 있다. 이에, 본 발명의 일 실시예에서는 상술한 BEGAN의 SVS 응용영역에서도 이 미지생성 성능과 견줄 수 있도록 제안된 모델을 바탕으로 L1 Loss가 야기하는 문제에 대한 가설 및 개선점을 찾 아볼 수 있다. 일정 품질을 만족하면서도 다양한 변형을 생성할 수 있는 최적의 파라미터값들이 찾기 위해 구 간별 테스트를 수행하고 성능을 검증할 수 있다. <BEGAN-Sing> BEGAN-Sing 모델을 바탕으로 파라미터 튜닝방법으로 개선할 수 있는 방법을 찾기 위해 먼저 L1 Loss가 사운드 품질에 미치는 영향력과 이상치의 제곱을 이용하는 L2 Loss가 미치는 영향력을 선분석한 후 개선점을 찾는 테스 트를 수행할 수 있다. 이는, L1 Loss의 가중치를 조절할 수 있도록 알파(α) 파라미터를 도입하는 것이며 이는 측정값과 실제 값의 차이에 비례하는 제어변수에 보정효과를 주기 위한 비례제어이론(Proposition Control Theory)에 근거할 수 있다. 수학식 2"}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2에서 λ는 학습률을 의미한다. 수학식 3"}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 3에서 x는 도메인 인코더/디코더 출력값 샘플이다. 수학식 4"}
{"patent_id": "10-2024-0044853", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 4에서, x는 도메인 인코더/디코더 출력값 샘플이고 y는 실제데이터의 스펙트로그램 값에서의 샘플이다. λ는 학습률을 의미하고 kt는 L(G(x))를 얼마나 강조할 것인지를 조절하는 인자로 γ에 의해 조절된다. BEGAN- Sing 모델의 생성자 손실함수에는 실제값(Ground Truth)와 생성물의 스팩트로그램(Generated Spectrogram)간의 픽셀분포를 반영하기 위해 L1 Loss를 추가하였으나, 이로 인해 생성된 데이터의 다양성과 품질 사이의 균형을 조절할 수 있었던 γ가 의미를 잃어버리는 문제가 발생할 수 있다. 즉, 값이 낮아져도 어느 지점에서는 생성물 의 품질이 높아지지 않는 현상이 발생한다. 이에 LG에서 과적합(Over-Fitting) 문제가 일어나 γ 본래의 목적 을 방해한다는 가설을 세우고, L1 Loss에 과적합회피를 위해 알파(α)를 도입하고 이 값을 조절하면서 γ의 역 할손실없이 품질을 보증할 수 있도록 튜닝하면서 학습시킬 수 있다. 제공부는, SVS 모델로부터 생성된 가창 데이터를 음원 사이트로 제공할 수 있다. 음원 사이트 는, 음성합성을 위한 노래를 선택하고, 사용자이름으로 변경한 가사 데이터를 가창 서비스 제공 서버로 제 공할 수 있고, 그 결과인 가창 데이터를 수신할 수 있다. 모델설정부는, SVS 모델을 구축할 때 BEGAN(Boundary Equilibrium GAN(Generative Adversarial Networ k))에 기반한 BEGANSing 모델 또는 HIFI-GAN(High Fidelity Speech Synthesis GAN(Generative Adversarial Network))을 이용할 수 있다. BEGANSing 모델은 상술한 바와 같으므로 중복된 내용의 설명은 생략하고, HIFI- GAN을 설명한다. HIFI-GAN은 음성합성 속도와 메모리 효율을 높이기 위하여 음성 오디오의 주기적 신호를 구별 해 내는 방식을 이용하여 일반적인 모델보다 좋은 품질의 음성을 빠르게 생성해 낼 수 있다. HIFI-GAN 모델은 멜 스펙토그램을 입력으로 받는다. 생성기(Generator)에서는 먼저 역방향 합성곱 신경망을 이용해 업샘플링을 진행한다. 그 후 MRF(Multi-Receptive Field Fusion) 모듈을 이용하여 다양한 길이의 패턴을 병렬로 관측하고 최종적으로 파형을 생성해낸다. 판별기(Discriminator)에서는 다양한 주기적 패턴을 식별하고 처리하기 위하여 여러 부 판별자로 구성된 다중 기간 판별자(Multi-Period Discriminator)를 이용한다. 이는 동일한 간격으로 구성된 샘플들을 입력으로 받는다. 이를 위해서 1차원으로 구성된 오디오를 2차원 데이터로 바꾼다. 그 후 2 차원 합성곱을 해당 데이터에 적용하여 주기적인 샘플들을 독립적으로 처리한다. 이후 가중치 정규화를 적용하 고, 계산된 그래디언트(Gradient)를 전달하여 훈련을 진행한다. <노래 음성합성> 노래 음성합성은 원하는 음악의 미디 파일과 가사를 입력받으면 지정된 목소리로 노래를 생성하는 서비스이다. 여기에서는 입력으로부터 멜 스펙토그램을 생성하기위해 MLP(Multi-Layer Perception)-Singer 모델을 이용할 수 있다. MLP-Singer는 Vision Literature for Attention-Free Image Classification에서 소개된 MLP-Mixer 모 델을 기반으로 하며, 합성 속도, 오디오 품질에서 GAN 모델을 기반으로 한 다른 모델들에 비해 좋은 결과를 낼 수 있다. 따라서, 이 모델을 이용하여 언어, 시간, 멜로디 정보를 음향적 특징에 매핑하여 멜 스펙토그램을 만 들 수 있다. MLP Singer 모델에서는 훈련을 위해 가사와 음의 높낮이 시퀀스, 해당 가사로 부른 노래를 입력으 로 받는다. 이후 텍스트와 음은 시간 순서대로 정렬되어 있다고 가정하고 각각에 대해 임베딩을 진행한다. 완 전연결계층(Feed Forward Layer)을 이용해 입력의 특징을 잘 찾을 수 있는 잠재 공간(Latent Space)에 투영을 한다. 그 다음 진행할 Mixer Block에는 텍스트와 피치 정보를 확산시키는 Channel Mixer와 확산된 정보를 받아서 특징 을 추출하는 Token Mixer가 들어 있다. Channel Mixer에서 정보를 확장시키면 Token Mixer에서 인접한 위치의정보들 간 관계를 고려하여 특징을 생성한다. 이후 Mixer Block의 출력을 멜 스펙토그램으로 만든다. 멜 스펙 토그램으로부터 최종 음성을 출력하는 모델으로 TTS와 마찬가지로 HIFI-GAN을 이용한다. <백엔드> 백엔드(Backend)에서는 모델을 통해 결과를 빠른 시간 안에 제공하기 위하여 경량화된 웹 프레임워크인 플라스 크를 이용할 수 있다. Rest API를 이용하여 프론트엔드와 통신을 하며 사용자로부터 요청이 들어오면 선택한 목소리에 해당하는 음성합성 모델을 불러 음성합성을 진행한다. 또, 추후 학습 데이터 보완과 다양한 컨텐츠에 활용이 가능하도록 입력한 텍스트를 데이터베이스인 MySQL에 저장한다. <REST API> REST는 Representational State Transfer의 약자로 자원의 표현에 의한 상태 전달을 의미한다. 자원의 상태에 는 POST, GET, PUT, DELETE 총 4개가 있으며 해당 상태가 의도하는 바를 쉽게 파악할 수 있고, 서버와 클라이언 트의 역할을 명확하게 분리할 수 있다는 장점이 있다. 따라서, 서버는 REST API를 이용하여 다양한 기기, 브라 우저와 통신이 가능하다. 이에, 프론트엔드와의 소통을 위하여 Rest API를 이용할 수 있다. 먼저, 텍스트 음 성변환에서 사용자로부터 문장을 입력받고 만든 음성을 출력하기 위해 POST 방법을 이용한다. 그리고, SVS에서 는 사용자가 원하는 곡을 선택하면 미리 생성해 둔 노래를 바로 출력하기 위하여 GET 방법을 사용한다. 마지막 으로 API 문서화 및 테스트를 위하여 Swagger를 이용한다. <데이터베이스> 텍스트 음성변환에서 입력받은 문장을 저장하기 위해, 노래 음성합성에서 모델을 통해 생성된 노래의 저장 경로 를 저장하기 위해 MySQL을 이용할 수 있다. 플라스크에서 데이터 베이스를 연결하고 통신할 때 ORM방식을 이용 한다. ORM은 Object Relational Mapping으로 객체지향의 클래스와 관계형 데이터베이스의 테이블을 자동으로 연 결해준다. 따라서 SQL문 쿼리(Query)가 아닌 직관적인 코드를 이용하여 데이터를 조작할 수 있다. 그리고 해 당 객체들을 재활용할 수 있으며, 매핑 정보가 명확하다는 점에서 재사용 및 유지보수가 편리하다는 장점이 있 다. <Web Server & Middleware> 본 논문의 웹 서비스에서는 웹 서버로 Nginx를, 미들웨어로 Gunicorn을 이용할 수 있다. 먼저 Nginx는 경량 웹 서버이다. Event-Driven 방식을 이용함으로써 여러 요청을 이벤트 처리자를 통해 비동기 방식으로 처리하여 적 은 자원으로도 더 빠르게 서비스 할 수 있다. 그리고, Gunicorn은 Python WSGI(Web Server Gateway Interface)로 웹서버로 부터 요청을 받으면 WSGI를 통해 해당 요청을 애플리케이션으로 전달한다. 플라스크 역 시 해당 역할을 수행할 수 있으나 단일 쓰레드(Thread)로 동작하여 요청이 많아질 경우 처리 능력이 저하된다는 단점이 있다. 이를 보완하기 위하여 멀티 쓰레드가 지원되는 Gunicorn을 이용하여 요청이 많아지더라도 효율적 으로 처리할 수 있도록 한다. <프론트엔드> 프론트엔드의 경우 Next.js를 이용하여 서버 사이드 렌더링(Rendering)을 통한 페이지를 제공한다. 따라서 기 존 모든 스크립트가 실행되기 전 빈 화면을 보여주는 클라이언트 사이드 렌더링과 다르게 정적 HTML을 서버에서 빌드하여 제공하고 필요한 경우 스크립트를 실행하여 빌드한다. 또한 통합적 State관리를 위해 Redux를, Action 상태와 백엔드 API 호출 상태를 확인하기 위해 Redux DevTools를 이용할 수 있다. <서버 사이드 렌더링> 사용자가 요청해서 받은 내용을 화면에 표시하는 방법에는 클라이언트 사이드 렌더링, 서버 사이드 렌더링 두가 지가 있다. 여기서 React는 기본적으로 클라이언트 사이드 렌더링을 지원한다. 이는 요청이 들어오면 백엔드 로 요청이 가고 데이터를 불러오는 시간 동안 로딩이 진행되며 이 시간 동안 빈 화면이 보이게 된다. 그러나 서버 사이드 렌더링은 서버에서 미리 준비해둔 화면을 보여주게 되며 데이터를 불러올 때까지의 로딩 시간 동안 기능을 사용할 수는 없으나 화면이 보이기에 로딩이 빠르다고 느낄 수 있게 한다. 본 발명의 일 실시예에서는, 서버 사이드 렌더링 기능을 지원하는 Next.js를 이용하여 웹 사이트에 접속하면 바로 콘텐츠를 볼 수 있도록 할 수 있다. 데이터증강부는, SVS 모델을 구축하기 위하여 적어도 하나의 가수의 음성 데이터셋을 수집하고, 적어도 하 나의 가수의 음성 데이터셋이 기 설정된 수를 만족하지 않는 경우 데이터 증강(Data Augmentation)을 수행하고,데이터 증강시 피치변조(Pitch Shift) 및 속도조절(Time Stretch)로 증강한 음원 데이터셋을 이용하도록 할 수 있다. 데이터 증강을 음성인식에 적용하는 경우, 결과를 고려해 피치변조 및 속도조절로 증강한 데이터셋을 이 용하여 SVS 모델을 학습시킬 수 있다. <속도조절> Time Stretching은 음원 전체길이를 줄이거나 늘려서 새로운 음원을 만들어내는 기법이다. 한 음원에 대해 총 N 개의 추가적인 음원을 제작할 수 있는데, 예를 들어, 원래 음원에 비해 40%, 30%, 20%, 10%의 속도를 느리게 하거나 또 원래 음원에 비해 10%, 20%, 30%, 40% 속도를 빠르게 수행할 수 있다. Time Stretching 기법은 변 형시키는 정도를 높게 설정하여 변형시켜도 Pitch Shift 기법 보다는 자연스러워지는 정도가 크게 손상을 입지 않아 훨씬 많은 음원 증강을 가능하게 할 수 있다는 점이 장점이다. 다만 50%, 60% 등 그 이상 만큼의 변형을 주지 않는 것이 바람직한데, 그 이유 중 첫 번째는 그 이상의 정도로 변형을 주면 증강된 음원 데이터의 수가 매우 많아지게 되고 그렇게 증강된 음원데이터가 과하게 많으면 어느 순간부터는 학습에 소요되는 시간이 길어 지지만 그에 비해 음원의 퀄리티는 그에 비례해서 증가하지 않고 별 차이가 없는 등 효율적인 측면에서 Time Stretching 기법으로 생성된 음원의 수를 조정하기 위함일 수 있다. 두 번째는 보통 사람이 일상 생활에서 말 을 느리거나 빠르게 말하게 되면 모음이 길어지고 짧아지도록 하여 말의 빠르기를 조절하며, 모음이 아닌 자음 을 천천히 말하게 늘리거나 어색하고 부자연스럽다고 느끼게 된다. 그러나 Time Stretching 기법은 자음 부분 이 모음 부분과 같은 비율로 길이가 변하기 때문에 변형을 많이 주면 줄수록 발음이 이상해지고 어색하게 들리 게 된다. 이러한 이유로 50% 이상으로는 변형을 주지 않고 최대 40%까지 Time Stretching 기법을 통해 늘리거 나 줄이는 것이 바람직하다. <피치변조> Pitch Shifting이란, 음성 신호의 길이를 유지한 채 음의 높낮이를 변형하는 것을 의미한다. 음성 데이이터셋과 SVS 모델은 12평균율을 기반으로 하므로, 모든 반음 간의 주파수 비율이 일정하다. 따라서, 원본 음성 파일에 대해 반음의 정수 배 간격으로 Pitch Shifting을 적용하더라도 기존의 음률을 유지할 수 있게 된다. 사람의 목 소리에 Pitch Shifting을 적용했을 때의 문제점은, 음의 높낮이가 바뀜에 따라 음색도 같이 변화한다는 것이다. 한 가수의 목소리에 특화된 SVS를 목표로 하였으므로, 원본 데이터와 상이한 음색을 가진 데이터는 모델 학습에 악영향을 줄 수 있다. 따라서, 본 발명의 일 실시예에서는 음색의 변화가 적은 범위 내에서만 Pitch Shifting 을 이용할 수 있다. 정렬부는, 가사 데이터를 TTS(Text to Speech)를 이용하여 음성으로 변환할 때, Glow-TTS를 이용하여 텍스 트와 음성 간 가장 가능성이 높은 정렬(Alignment)을 자동으로 검색해 텍스트 순서에 따라 발화를 차례로 정렬 하도록 할 수 있다. 텍스트 음성변환도 노래 음성합성과 마찬가지로 음성합성을 위한 모델학습이 필요하다. 두 모델 모두 데이터 수집, 데이터 전처리, 음성합성 모델을 이용하는 과정으로 진행한다. 여기에서 텍스트 음 성변환은 평문 발화, 노래 음성합성은 노래 생성이라는 목표 각각에 알맞는 데이터와 모델을 이용하여 학습을 진행한다. 서비스를 제공하기 위해 문장을 입력받으면 멜 스펙토그램을 생성하는 모델, 멜 스펙토그램을 최종 목소리로 출력하는 모델 총 2개가 필요하다. 먼저 멜 스펙토그램을 생성하는 모델은 텍스트를 분석하여 발음과 말투 구축에 관여한다. 그리고 최종 목소리를 출력하는 모델은 출력 오디오의 노이즈를 줄여주고 학습 데이터 셋의 화자와 유사한 음색을 가지도록 보완한다. <텍스트 음성변환> 텍스트 음성변환은 문장을 입력 받으면 원하는 목소리로 변환하여 음성 파일로 제공하는 서비스이다. 여기에서 는 문장으로부터 멜 스펙토그램을 생성하기위해 Glow-TTS 모델을 이용할 수 있다. 이 모델은 텍스트와 음성의 잠재적 표현 사이에 가장 가능성이 높은 정렬을 스스로 검색해 입력된 텍스트 순서에 따라 발화를 차례대로 정 렬한다. 이 모델은 텍스트와 음성의 잠재적 표현 사이에 가장 가능성이 높은 정렬을 스스로 검색해 입력된 텍 스트 순서에 따라 발화를 차례대로 정렬한다. 이를 통해 더 빠르게 음성을 합성하며, 서로 다른 억양을 갖춘 목소리를 생성할 수 있다. 따로 정렬 모델을 구축하지 않고도 음성을 합성하는 모델이 추후 가수의 목소리를 입력받아 가수에 최적화된 모델을 구축하기에도 적합하다. Glow-TTS 모델에서는 훈련을 위해 텍스트와 해당 텍스트의 음성을 입력으로 받는다. 인코더는 FastSpeech의 인 코더와 같은 구조이며 트랜스포머의 인코더에서 인접한 위치의 정보 사이의 연관성을 잘 반영하기 위하여 순방 향 신경망을 1×1 합성곱으로 교체한다. 이후 텍스트 순서에 맞게 발화를 정렬하기 위해 Monotonic Alignment Search 알고리즘을 이용하여 발화 관련 변수들의 정렬을 수행한다. 기간 예측기는 바로 전에 생성된 정렬을 평가하기 위해 사용된다. 디코더에서 정렬된 변수들을 변환하여 최종적으로 멜 스펙토그램을 만든다. 이후, 멜 스펙토그램으로부터 최종 음성을 출력하는 모델로 상술한 HIFI-GAN을 이용한다. 스트리밍부는, 음원 사이트에서 가사 데이터를 제공받아 얻은 가창 데이터에 대하여 노래의 적어도 하나의 저작권 단말의 이용허락이 전제된 경우, 가창 데이터를 공유 및 유통할 수 있다. 분배부는, 공유 및 유통으로 인한 수익이 발생하는 경우, 음원 사이트 및 적어도 하나의 저작권 단말로 수익을 분배할 수 있다."}
{"patent_id": "10-2024-0044853", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능 기반 사용자 맞춤형 가창 서비스 제공 시스템을 설명하기 위한 도 면이다. 도 2는 도 1의 시스템에 포함된 가창 서비스 제공 서버를 설명하기 위한 블록 구성도이다. 도 3 및 도 4는 본 발명의 일 실시예에 따른 인공지능 기반 사용자 맞춤 가사를 이용한 가창 서비스가 구현된 일 실시예를 설명하기 위한 도면이다."}
