{"patent_id": "10-2021-0126603", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0124933", "출원번호": "10-2021-0126603", "발명의 명칭": "오프라인 음성 인식 방법, 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램 제품", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "푸, 시아오인"}}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인식할 음성 데이터를 음절 인식 결과로 디코딩하며;상기 음절 인식 결과를 해당하는 문자로 변환하여, 상기 문자를 상기 음성 데이터의 음성 인식 결과로 하는것,을 포함하는오프라인 음성 인식 방법."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인식할 음성 데이터를 음절 인식 결과로 디코딩하는 것은음절 디코더를 이용하여 상기 음성 데이터를 디코딩하여 상기 음절 인식 결과를 얻는 것,을 포함하며;여기서, 상기 음절 디코더는 음절 기반의 음향 모델 및 음절 기반의 언어 모델을 결합하여 상기 음성 데이터를디코딩하기 위한 것인오프라인 음성 인식 방법."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 음향 모델은 종단간 스트리밍식 멀티 레이어 어텐션 차단(SMLTA, Streaming Multi-Layer TruncatedAttention) 모델을 포함하며; 및/또는,상기 언어 모델은 장단기 기억 네트워크(LSTM, Long Short Term Memory) 언어 모델을 포함하는 오프라인 음성인식 방법."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,4-비트 정량화 방법을 사용하여 상기 LSTM 언어 모델의 모델 체적을 압축하는오프라인 음성 인식 방법."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 음절 인식 결과를 해당하는 문자로 변환하는 것은스트리밍식 변환기(Transformer) 모델을 이용하여, 상기 음절 인식 결과를 해당하는 문자로 변환하는 것,을 포함하는오프라인 음성 인식 방법."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기의 스트리밍식 Transformer 모델을 이용하여, 상기 음절 인식 결과를 해당하는 문자로 변환하는 것은상기 Transformer 모델 중의 각 어텐션 구조에 타임 마스크 동작을 각각 추가하여, 상기 타임 마스크 동작을 이용하여 스트리밍식 음절 변환을 구현하는 것,을 포함하는공개특허 10-2021-0124933-3-오프라인 음성 인식 방법."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "인식할 음성 데이터를 음절 인식 결과로 디코딩하기 위한 오프라인 디코딩 모듈; 및상기 음절 인식 결과를 해당하는 문자로 변환하여, 상기 문자를 상기 음성 데이터의 음성 인식 결과로 하기 위한 음절 변환 모듈,을 포함하는오프라인 음성 인식 장치."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 오프라인 디코딩 모듈은 음절 디코더를 이용하여 상기 음성 데이터를 디코딩하여, 음절 인식 결과를 얻으며; 여기서, 상기 음절 디코더는 음절 기반의 음향 모델 및 음절 기반의 언어 모델을 결합하여 상기 음성 데이터를 디코딩하기 위한 것인오프라인 음성 인식 장치."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 음향 모델은 종단간 스트리밍식 멀티 레이어 어텐션 차단(SMLTA, Streaming Multi-Layer TruncatedAttention) 모델을 포함하며; 및/또는,상기 언어 모델은 장단기 기억 네트워크(LSTM, Long Short Term Memory) 언어 모델을 포함하는오프라인 음성 인식 장치."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 오프라인 디코딩 모듈은 또한 4-비트 정량화 방법을 사용하여 상기 LSTM 언어 모델의 모델 체적을 압축하기 위한 것인오프라인 음성 인식 장치."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 음절 변환 모듈은 스트리밍식 변환기(Transformer) 모델을 이용하여, 상기 음절 인식 결과를 해당하는 문자로 변환하는오프라인 음성 인식 장치."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 음절 변환 모듈은 상기 Transformer 모델 중의 각 어텐션 구조에 타임 마스크 동작을 각각 추가하여, 상기타임 마스크 동작을 이용하여 스트리밍식 음절 변환을 구현하는오프라인 음성 인식 장치."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서에 통신 연결되는 메모리,를 포함하는 전자 기기에 있어서,공개특허 10-2021-0124933-4-상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어가 저장되어 있고, 상기 명령어는 상기 적어도 하나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서로 하여금 제1항 내지 제6항 중 어느한 항에 따른 방법을 수행하게 하는 전자 기기."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨터 명령어가 저장되어 있는 비휘발성 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 명령어는 상기 컴퓨터로 하여금 제1항 내지 제6항 중 어느 한 항에 따른 방법을 수행하게 하기 위한 것인 비휘발성 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2021-0126603", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "프로세서에 의해 실행될 때 제1항 내지 제6항 중 어느 한 항에 따른 방법을 구현하는 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2021-0126603", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 오프라인 음성 인식 방법, 장치, 전자 기기 및 저장 매체를 개시하였으며, 음성 인식, 자연어 처리 및 딥 러닝 등 인공 지능 분야에 관한 것이며, 여기의 방법은 인식할 음성 데이터를 음절 인식 결과로 디코딩하며; 상기 음절 인식 결과를 해당하는 문자로 변환하여, 상기 문자를 상기 음성 데이터의 음성 인식 결과로 하는 것, 을 포함한다. 본 개시의 상기 방안을 적용하면, 음성 인식 결과의 정확성 등을 향상시킬 수 있다."}
{"patent_id": "10-2021-0126603", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공 지능 기술 분야에 관한 것이며, 특히 음성 인식, 자연어 처리 및 딥 러닝 등 분야에 관한 것이 며, 구체적으로, 오프라인 음성 인식 방법, 장치, 전자 기기 및 저장 매체이다."}
{"patent_id": "10-2021-0126603", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재, 음성 인식은 음성 입력, 음성 다이얼링, 자동차 내비게이션 등 다양한 장면에 이미 광범위하게 적용되었 다. 음성 인식 방식은 주로 온라인 음성 인식 및 오프라인 음성 인식으로 나뉜다. 여기서, 온라인 음성 인식은 일반 적으로 음성 데이터를 네트워크를 통해 서버에 업로드하여 디코딩해야 하므로, 음성 인식의 성능이 네트워크 품 질의 영향을 크게 받으며, 음성 데이터를 업로드해야 하므로 개인 정보의 유출 등이 쉽게 일어난다. 다시 말하 면, 온라인 음성 인식은 신뢰성 및 사밀성 등 방면의 요구를 만족시킬 수 없다. 오프라인 음성 인식은 음성 데이터를 서버에 업로드할 필요가 없고, 기기 로컬에서 직접 디코딩을 함으로써, 신 뢰성 및 사밀성 등 방면의 요구를 만족시킨다. 하지만, 기기 측의 계산 및 저장 자원 등에 보다 한계가 있으므 로, 일반적으로 인식 모델 체적을 제한해야 하므로, 음성 인식 결과의 정확성이 보다 낮음 등 문제를 초래한다."}
{"patent_id": "10-2021-0126603", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 오프라인 음성 인식 방법, 장치, 전자 기기 및 저장 매체를 제공한다."}
{"patent_id": "10-2021-0126603", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "오프라인 음성 인식 방법은 인식할 음성 데이터를 음절 인식 결과로 디코딩하며; 상기 음절 인식 결과를 해당하는 문자로 변환하여, 상기 문자를 상기 음성 데이터의 음성 인식 결과로 하는 것,을 포함한다. 오프라인 음성 인식 장치는 인식할 음성 데이터를 음절 인식 결과로 디코딩하기 위한 오프라인 디코딩 모듈; 및 상기 음절 인식 결과를 해당하는 문자로 변환하여, 상기 문자를 상기 음성 데이터의 음성 인식 결과로 하기 위 한 음절 변환 모듈,을 포함한다. 전자 기기는 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 연결되는 메모리,를 포함하며, 여기서, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어가 저장되어 있고, 상기 명령어는 상 기 적어도 하나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서로 하여금 상기에 따른 방법을 수행하 게 한다. 컴퓨터 명령어가 저장되어 있는 비휘발성 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 명령어는 상기 컴 퓨터로 하여금 상기에 따른 방법을 수행하게 하기 위한 것이다. 컴퓨터 프로그램 제품은 프로세서에 의해 실행될 때 상기에 따른 방법을 구현하는 컴퓨터 프로그램을 포함한다. 상기 개시 중의 일 실시예는 아래의 장점 또는 유익한 효과를 가진다. 음절 기반의 2단계 오프라인 음성 인식 방식을 제안하였으며, 오프라인 음성 인식 과정은 2개의 단계로 나뉘며, 우선 문맥과 무관한 음절을 기본적인 음향 모델링 유닛으로 하고, 인식할 음성 데이터를 디코딩하여 음절 인식 결과를 얻으며, 다음에는, 인식 결과 의 가독성을 만족시키기 위해, 음절 인식 결과를 해당하는 문자로 변환하여 필요한 음성 인식 결과를 얻는다. 상기 방식은 계산 및 저장 자원 등에 대한 점용을 증대하지도 않을뿐더러, 음성 인식 결과의 정확성 등을 확보 했다. 본 부분에서 설명한 내용은 본 개시의 실시예의 결정적이거나 중요한 특징을 나타내기 위한 것이 아니며, 본 개 시의 범위를 제한하기 위한 것도 아님을 이해해야 한다. 본 개시의 기타 특징은 아래의 설명서를 통해 쉽게 이 해하게 될 것이다."}
{"patent_id": "10-2021-0126603", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 본 개시의 예시적 실시예에 대해 첨부된 도면을 결부하여 설명하도록 하며, 여기서 이해를 돕기 위 해 본 개시의 실시예의 다양한 세부 내용을 포함하며, 이들은 단지 예시적인 것으로 간주되어야 한다. 따라서, 당해 분야의 통상적인 기술자는 본 개시의 범위 및 사상을 벗어나는 것이 없이, 여기서 설명한 실시예에 대해 다양한 변형 및 수정을 할 수 있음을 이해해야 한다. 마찬가지로, 명확성 및 간결성을 위해, 아래의 설명에서는 공지된 기능 및 구조에 대한 설명을 생략한다. 또한, 본문에서 용어 “및/또는”는 단지 관련 대상의 관련 관계를 설명하며, 세가지 관계를 표시할 수 있으며, 예를 들어, A 및/또는 B 는 A 가 단독으로 존재하거나, 동시에 A 및 B 가 존재하거나, B 가 단독으로 존재하는 세가지 상황을 표시한다. 또한, 본문에서 문자 부호 “/”는 일반적으로 전후 관련 대상이 “또는”의 관계임을 표시한다. 도 1은 본 개시에 따른 오프라인 음성 인식 방법의 실시예의 흐름도이다. 도 1에서 도시한 바와 같이, 아래의 구체적인 구현 방식을 포함한다. 단계 101에서, 인식할 음성 데이터를 음절 인식 결과로 디코딩한다. 단계 102에서, 음절 인식 결과를 해당하는 문자로 변환하며, 얻은 문자를 음성 데이터의 음성 인식 결과로 한다. 본 개시의 방법 실시예의 상기 방안은 음절 기반의 2단계 오프라인 음성 인식 방식을 제안하였으며, 오프라인 음성 인식 과정은 2개의 단계로 나뉘며, 우선 문맥과 무관한 음절(syllable)을 기본적인 음향 모델링 유닛으로 하고, 인식할 음성 데이터를 디코딩하여 음절 인식 결과를 얻으며, 다음에는 인식 결과의 가독성을 만족시키기 위해, 음절 인식 결과를 해당하는 문자로 변환하여 필요한 음성 인식 결과를 얻는다. 상기 방식은 계산 및 저장 자원 등에 대한 점용을 증대하지도 않을뿐더러, 음성 인식 결과의 정확성 등을 확보했다. 인식할 음성 데이터를 음절 인식 결과로 디코딩할 때, 구체적으로, 음절 디코더를 이용하여 음성 데이터를 디코 딩하여, 음절 인식 결과를 얻을 수 있으며, 여기서, 음절 디코더는 음절 기반의 음향 모델 및 음절 기반의 언어 모델을 결합하여 음성 데이터를 디코딩하기 위한 것이다. 바람직하게는, 음향 모델은 종단간 스트리밍식 멀티 레이어 어텐션 차단(SMLTA, Streaming Multi-Layer Truncated Attention) 모델일 수 있으며, 및/또는, 언어 모델은 장단기 기억 네트워크(LSTM, Long Short Term Memory) 언어 모델일 수 있다. 종래의 오프라인 음성 인식 시스템은 일반적으로 음향 모델, 언어 모델 및 디코더 등 세 부분으로 구성된다. 도 2에서 도시한 바와 같이, 도 2는 종래의 오프라인 음성 인식 방식의 설명도이며, 디코더를 이용하여 언어 모델 및 음향 모델에 따라 입력된 음성 데이터를 디코딩하여, 음성 인식 결과를 얻을 수 있다. 기기 측의 계산 및 저 장 자원에 한계가 있음을 고려하여, 상대 엔트로피(relative entropy) 기반의 방법 등을 사용하여 언어 모델을 클립핑하여, n차원 언어 모델을 얻을 수 있으며, 일반적으로 n차원 언어 모델의 체적은 수십 M 정도로 제어되며, 온라인 언어 인식 중의 서버 측의 언어 모델 체적에 비해 약 1000배 감소되지만, 언어 모델의 체적을 대폭적으로 클립핑하면 음성 인식 결과의 정확성이 대폭적으로 저감되게 하고, n차원 언어 모델을 이용하여 인 식할 때 디코딩 경로를 확장해야 하며, 동일한 발음은 해당할 가능성이 있는 문자가 복수 개 있으므로, 임베디 드 기기의 계산 자원의 요구를 만족시키기 위해, 인식된 후보 결과를 클립핑해야 하는데, 정확한 인식 결과는 매우 쉽게 사전에 클립핑되어 인식 오류를 초래하므로, 음성 인식 결과의 정확성 등이 더 감소되었다. 하지만 본 개시에 따른 오프라인 음성 인식 방식에서는, 음절 기반의 신경망 언어 모델을 이용하여 n차원 언어 모델을 대체함으로써, 모델 체적을 효과적으로 감소시키는 동시에, 클립핑 등으로 인한 문제를 방지하며, 언어 인식 결과의 정확성 등을 더 향상시켰다. 또한, 음절 기반의 신경망 언어 모델을 사용하여, 디코딩할 때 음절 인식 결과를 직접 출력하여, 나아가, 음절 인식 결과를 해당하는 문자로 변환하며, 발음부터 문자로까지의 변환을 진행할 필요가 없으므로, 디코더의 검색 공간을 크게 감소시킬 수 있으며, 특히 오프라인 음성 인식의 디코딩 자원에 한계가 있는 장면에 적용되며, 오 프라인 음성 인식의 성능 등을 효과적으로 보장해 냈다. 상기와 같이, 본 개시에 따른 오프라인 음성 인식 방식에서 사용하는 음향 모델은 음절 기반의 종단간 SMLTA 모 델일 수 있다. 도 3은 본 개시에 따른 음절 기반의 종단간 SMLTA 모델의 구조 설명도이다. 도 3에서 도시한 바와 같이, 상기 모델은 주로 인코더(Encoder), 타이밍 시퀸스류 분류(CTC, Connectionist temporal classification) 및 디코더 (Decoder) 세 부분으로 구성되며, 디코더는 음성 문자 변환(LAS, Listen, Attend and Spell) 디코더일 수 있다. 여기서, 인코더에는 하나의 합성곱(Conv)층 및 N개의 LSTM+일괄 정규화(BN, Batch Normalize)층을 포함할 수 있 으며, N의 구체적인 값은 실제 수요에 따라 결정될 수 있으며, 예를 들어 5일 수 있다. CTC에는 하나의 선형 변 환(Linear)층 및 하나의 정규화(Softmax)층을 포함할 수 있다. LAS 디코더에는 하나의 어텐션(Attention)층, M 개의 LSTM층 + 정규화(LN, Layer Normalize)층 및 하나의 Softmax 층을 더 포함할 수 있으며, M의 구체적인 값 은 마찬가지로 실제 수요에 따라 결정할 수 있으며, 예를 들어 2일 수 있다. 도 3에서 도시한 SMLTA 모델의 입력(input)은 음성 데이터에서 추출된 특징 데이터일 수 있으며, 출력(output) 은 CTC 출력 및 LAS 출력을 포함하며, 모두 음절 디코더에 제공하여, 음절 디코더가 이 두 개의 출력 결과에 따 르고 언어 모델 등을 결합하여, 음절 인식 결과를 디코딩해 내도록 할 수 있다. 처리 효율 등을 향상시키기 위해, 도 3에서 도시한 인코더 및 디코더 중의 LSTM는 모두 단방향 LSTM일 수 있다. 또한, 도 3에서 도시한 SMLTA 모델은 저빈도를 사용한 SMLTA(light-SMLTA) 모델일 수 있으며, 이로써 처리 효율 을 향상시키는 동시에, 음향 모델의 계산량 등을 더 감소시킬 수 있다.상기와 같이, 본 개시에 따른 오프라인 음성 인식 방식에서 사용한 언어 모델은 음절 기반의 LSTM 언어 모델일 수 있다. 도 4는 본 개시에 따른 음절 기반의 LSTM 언어 모델의 구조 설명도이다. 도 4에서 도시한 바와 같이, N개의 LSTM+LSTM 층을 포함할 수 있으며, N의 구체적인 값은 실제 수요에 따라 결정할 수 있으며, 두 개의 LSTM 은 동 일할 수도 있고, 상이할 수도 있으며, 예를 들어 파라미터 배치가 상이할 수 있다. 또한, 4-비트(bit) 정량화 방법을 사용하여 LSTM 언어 모델의 모델 체적을 압축함으로써, LSTM 언어 모델의 체 적을 더 감소시킬 수 있다. 일반적인 언어 모델이 사용한 32-bit 의 저장 구조에 비해, 4-bit 정량화 압축을 거 친 후의 모델 체적은 원래의 1/8 밖에 안 된다. 4-bit 정량화 방법의 구체적인 구현은 종래 기술이다. 음절 디코더의 출력이 음절 인식 결과, 즉 하나의 음절 서열이며, 보통 사용자에게 있어서 식별할 수 없으므로, 인식 결과의 가독성을 만족시키기 위해, 또한 음절 인식 결과를 해당하는 문자로 변환, 즉 음절 서열을 해당하 는 문자 서열로 변환해야 한다. 구체적으로, 음절 변환 모델, 예를 들어 스트리밍식 변환기(Transformer) 모델을 사용하여, 음절 인식 결과를 해당하는 문자로 변환할 수 있다. 도 5는 본 개시에 따른 스트리밍식 Transformer 모델의 구조 설명도이다. 도 5에서 도시한 바와 같이, 본 개시 에 따른 스트리밍식 Transformer 모델과 표준적인 Transformer 모델의 구조는 유사하며, 모두 인코더+디코더의 구조를 사용하며, 구체적인 처리 방식은 모두 아래와 같다. 음절 인식 결과는 우선 입력 인코딩(Input Embedding) 및 위치 인코딩(Positional Encoding)을 통해 특징 변환을 하고 인코더의 N층 캐스케이드의 Attention 모듈 및 잔여 오차 모듈을 이용하여 특징 인코딩을 하며, 디코더는 히스토리 출력에 대해 마찬가지로 출력 인코딩(Output Embedding) 및 위치 인코딩을 하고, 히스토리 출력의 인코딩 결과 및 인코더가 출력한 특징 인코딩 등을 결합하며, M 층 캐스케이드의 Attention 모듈 및 잔여 오차 모듈 등을 이용하여 출력 결과를 얻으 며, N 및 M의 구체적인 값은 모두 실제 수요에 따라 결정될 수 있다. 도 5에서 도시한 바와 같이, 표준적인 Transformer 모델과 다른 것은, 본 개시에 따른 스트리밍식 Transformer 모델에서, 각 어텐션 구조에 타임 마스크(Time mask) 동작을 각각 추가함으로써, 상기 타임 마스크 동작을 이용 하여 스트리밍식 음절 변환을 구현하여, 디코딩 결과를 스트리밍식으로 출력하는 기능을 구현한다. 상기 설명을 기반으로, 도 6은 본 개시에 따른 오프라인 음성 인식의 구현 과정의 설명도이다. 도 6에서 도시한 바와 같이, 오프라인 디코딩 시스템 및 음절 변환 시스템은 오프라인 음성 인식 시스템을 구성 하며, 인식할 음성 데이터에 대해, 우선 오프라인 디코딩 시스템 중의 음절 디코더에 의해 음절 기반의 음향 모 델 및 음절 기반의 언어 모델을 결합하여 음성 데이터를 디코딩함으로써, 음절 인식 결과를 얻는다. 음절 디코더는 신경망(NN, Neural Network) 언어 모델 기반의 중영문 음절 디코더일 수 있으며, 음향 모델은 저 빈도의 종단간 SMLTA 모델일 수 있으며, 언어 모델은 LSTM 모델일 수 있으며, 그리고, 4-bit 정량화 방법을 사 용하여 LSTM 언어 모델의 모델 체적을 압축할 수 있다. 도 6에서 도시한 바와 같이, 오프라인 디코딩 시스템이 출력한 음절 인식 결과에 대해, 음절 변환 시스템 중의 스트리밍식 Transformer 모델을 이용하여, 음절 인식 결과를 해당하는 문자로 변환함으로써, 인식할 음성 데이 터의 음성 인식 결과를 얻을 수 있다. 설명해야 할 점은, 전술한 방법 실시예에 있어서, 간단하게 설명하기 위해, 이를 일련의 동작 조합으로 표현하 였지만, 당업자에게 있어서 본 개시는 설명한 동작 순서의 제한을 받지 않으며, 본 개시에 따르면, 어떤 단계들 은 기타 순서를 사용하거나 동시에 진행될 수도 있음을 이해해야 한다. 다음, 당업자는, 설명서에서 설명한 실 시예는 모두 바람직한 실시예이며, 관련된 동작 및 모듈은 본 개시에서 반드시 필요한 것이 아님을 이해해야 한 다. 이상은 방법 실시예에 관한 설명이며, 아래에서는 장치 실시예를 통해 본 개시에 따른 방안에 대해 더 설명하도 록 한다. 도 7은 본 개시에 따른 오프라인 음성 인식 장치 실시예의 구성 구조의 설명도이다. 도 7에서 도시한 바와 같이, 오프라인 디코딩 모듈 및 음절 변환 모듈을 포함한다. 오프라인 디코딩 모듈은 인식할 음성 데이터를 음절 인식 결과로 디코딩하기 위한 것이다. 음절 변환 모듈은 음절 인식 결과를 해당하는 문자로 변환하며, 얻은 해당하는 문자를 음성 데이터의 음성 인식 결과로 하기 위한 것이다. 인식할 음성 데이터를 음절 인식 결과로 디코딩할 때, 구체적으로, 오프라인 디코딩 모듈은 음절 디코더를 이용하여 음성 데이터를 디코딩하여 음절 인식 결과를 얻으며; 여기서, 음절 디코더는 음절 기반의 음향 모델 및 음절 기반의 언어 모델을 결합하여 음성 데이터를 디코딩하기 위한 것이다. 바람직하게는, 음향 모델은 종단간 SMLTA 모델일 수 있으며, 및/또는, 언어 모델은 LSTM 언어 모델일 수 있다. 여기서, SMLTA 모델은 저빈도의 SMLTA 모델일 수 있다. 또한, 오프라인 디코딩 모듈은 4-bit 정량화 방법 을 사용하여 LSTM 언어 모델의 모델 체적을 압축함으로써, LSTM 언어 모델의 체적을 더 감소시킨다. 음절 디코더의 출력은 음절 인식 결과, 즉 하나의 음절 서열이며, 일반적인 사용자에게 있어서 식별할 수 없으 므로, 인식 결과의 가독성을 만족하기 위해, 음절 변환 모듈은 또한 음절 인식 결과를 해당하는 문자로 변 환하며, 즉 음절 서열을 해당하는 문자 서열로 변환할 필요도 있다. 구체적으로, 음절 변환 모듈은 스트리밍식 Transformer 모델을 이용하여, 음절 인식 결과를 해당하는 문자 로 변환할 수 있다. 스트리밍식 Transformer 모델과 표준적인 Transformer 모델의 구조는 유사하며, 상이한 점은, 음절 변환 모듈 은 스트리밍식 Transformer 모델 중의 각 어텐션 구조에 타임 마스크 동작을 각각 추가하여, 상기 타임 마 스크 동작을 이용하여 스트리밍식 음절 변환을 구현할 수도 있다. 도 7에 도시한 장치 실시예의 구체적인 작업 흐름은 전술한 실시예 중의 관련 설명을 참조하며, 더 중복적으로 설명하지 않도록 한다. 종합해보면, 본 개시의 장치 실시예에 따른 방안은, 음절 기반의 2단계 오프라인 음성 인식 방식을 제안하였으 며, 오프라인 음성 인식 과정을 2개의 단계로 나뉘며, 우선 문맥과 무관한 음절을 기본적인 음향 모델링 유닛으 로 하고, 인식할 음성 데이터를 디코딩하여 음절 인식 결과를 얻으며, 다음에는, 인식 결과의 가독성을 만족시 키기 위해, 음절 인식 결과를 해당하는 문자로 변환하여 필요한 음성 인식 결과를 얻는다. 상기 방식은 계산 및 자원 저장 등에 대한 점용을 증대하지도 않을뿐더러, 음성 인식 결과의 정확성 등도 확보한다. 본 개시에 따른 방안은 인공 지능 분야에 적용될 수 있으며, 특히 음성 인식, 자연어 처리 및 딥 러닝 등 분야 에 관한 것이다. 인공 지능은 컴퓨터로 하여금 사람의 어떤 사고 과정 및 지능적 행위(예를 들어 학습, 추론, 사고, 계획 등)를 흉내내게 하는 것을 연구하는 학과이며, 하드웨어 층면의 기술도 있고 소프트웨어 층면의 기술도 있으며, 인공 지능 하드웨어 기술에는 일반적으로 센서, 전용 인공 지능 칩, 클라우드 컴퓨팅, 분산 저장, 빅 데이터 처리와 같은 기술이 포함되며, 인공 지능 소프트웨어 기술에는 주로 컴퓨터 비전 기술, 음성 인식 기술, 자연어 처리 기술, 머신 러닝/딥 러닝, 빅 데이터 처리 기술, 지식 그래프 기술 등 여러 방향이 포함된다. 본 개시의 실시예에 따르면, 본 개시는 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램 제품을 더 제공한 다. 도 8은 본 개시의 실시예의 예시적 실시예를 구현하기 위한 전자 기기의 예시적 블록도를 도시하였다. 전 자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 워크 스테이션, 개인 휴대 정보 단말기, 서버, 블레이드 서버, 메인 프레임 컴퓨터 및 기타 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 나타내기 위한 것이다. 전자 기기 는 개인 휴대 정보 단말기, 셀룰러 폰, 스마트 폰, 웨어러블 기기 및 기타 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장치를 나타낼 수도 있다. 본문에 기재된 부품, 이들의 연결 및 관계, 및 이들의 기능은 단지 예 시일 뿐이며, 본문에서 설명 및/또는 요구되는 본 개시의 구현을 제한하려는 것이 아니다. 도 8에서 도시한 바와 같이, 기기는 컴퓨팅 유닛을 포함하며, 이는 읽기 전용 기억 장치(ROM)에 저장된 컴퓨터 프로그램 또는 저장 유닛로부터 랜덤 액세스 메모리(RAM)에 로딩된 컴퓨터 프로그램에 의해, 다양한 적합한 동작 및 처리를 수행할 수 있다. RAM에서, 기기가 동작하는데 필요한 다양한 프 로그램 및 데이터를 더 저장할 수 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스를 통해 서로 연 결된다. 입력/출력(I/O) 인터페이스도 버스에 연결된다. 기기 중의 복수의 부품은 I/O 인터페이스에 연결되며, 키보드, 마우스 등과 같은 입력 유닛; 다 양한 유형의 디스플레이, 스피커 등과 같은 출력 유닛; 자기 디스크, 광 디스크 등과 같은 저장 유닛; 및 네트워크 카드, 모뎀, 무선 통신 송수신기 등과 같은 통신 유닛을 포함한다. 통신 유닛은 기기로 하여금 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신 네트워크를 통해 기타 기기와 정보/데 이터를 교환하도록 허락한다. 컴퓨팅 유닛은 다양한 처리 및 계산 능력을 가지는 범용 및/또는 전용 프로세싱 컴포넌트일 수 있다. 컴퓨 팅 유닛의 일부 예시는 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU), 다양한 전용 인공 지능(AI) 컴퓨팅 칩, 머신 러닝 모델 알고리즘을 실행하는 다양한 컴퓨팅 유닛, 디지털 신호 처리 프로세서(DSP), 및 임의의 적 합한 프로세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만, 이에 제한되지 않는다. 컴퓨팅 유닛은 상 술한 각 방법 및 처리, 예를 들어 본 개시에 따른 방법을 수행한다. 예를 들어, 일부 실시예에서, 본 개시에 따 른 방법은 컴퓨터 소프트웨어 프로그램으로 구현될 수 있으며, 저장 유닛과 같은 기계 판독 가능 매체에 유형적으로 저장될 수 있다. 일부 실시예에서, 컴퓨터 프로그램의 부분 또는 전부는 ROM 및/또는 통신 유 닛에 의해 기기 상에 로딩되거나 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되고 컴퓨팅 유 닛에 의해 수행될 경우, 본 개시에 따른 방법의 하나 또는 복수의 단계를 수행할 수 있다. 선택적으로, 기 타 실시예에서, 컴퓨팅 유닛은 기타 임의의 적합한 방식을 통해(예를 들어, 펌웨어에 의해) 본 개시에 따 른 방법을 수행하도록 배치될 수 있다. 본문에서 이상 설명한 시스템 및 기술의 여러 가지 실시 형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로그램 가능 게이트 어레이(FPGA), 전용 집적 회로(ASIC), 특정 용도 표준 제품(ASSP), 시스템 온 칩 (SOC), 부하 프로그램 가능 논리 소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합에서 구현할 수 있다. 이러한 여러 가지 실시 형태는 하나 또는 복수의 컴퓨터 프로그램에서 실시되는 것을 포함할 수 있으며, 상기 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로 그램 가능 시스템에서 수행 및/또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 전용 또는 범용 프로그 램 가능 프로세서일 수 있으며, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부터 데이 터 및 명령어를 수신할 수 있으며, 데이터 및 명령어를 상기 저장 시스템, 상기 적어도 하나의 입력 장치 및 상 기 적어도 하나의 출력 장치에 전송할 수 있다. 본 개시의 방법을 실시하기 위한 프로그램 코드는 하나 또는 그 이상의 프로그래밍 언어의 임의의 조합을 사용 하여 프로그래밍할 수 있다. 이 프로그램 코드들은 범용 컴퓨터, 전용 컴퓨터 또는 기타 프로그램 가능 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공되어, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 때 흐름도 및/또는 블록도에서 규정한 기능 및/또는 단계를 실시하도록 할 수 있다. 프로그램 코드는 전부 기계에 서 실행, 부분적으로 기계에서 실행되고, 독립형 소프트웨어 패키지로서 부분적으로 기계에서 실행되고 부분적 으로 원격 기계 상에서 실행 또는 전부 원격 기계 또는 서버에서 실행될 수 있다. 본 개시의 문맥에서, 기계 판독 가능 매체는 유형 매체일 수 있으며, 이는 명령어 실행 시스템, 장치 또는 기기 가 사용하거나 명령어 실행 시스템, 장치 또는 기기와 결합하여 사용하기 위한 프로그램을 포함하거나 저장할 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체 일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 이들의 임의의 적절한 조합을 포함 할 수 있지만 이에 제한되지는 않는다. 기계 판독 가능 저장 매체의 보다 구체적인 예시로 는 하나 또는 그 이상의 와이어를 기반으로 한 전기적 연결, 휴대용 컴퓨터 디스크, 하드 드라이브, 랜덤 액세 스 메모리(RAM), 읽기 전용 메모리(ROM), 소거 가능 및 프로그램 가능 읽기용 기억 장치(EPROM 또는 플래시 메 모리), 광섬유, 휴대용 컴팩트 디스크 읽기 전용 메모리(CD-ROM), 광학 저장 장치, 자기적 저장 장치 또는 이들 의 임의의 적절한 조합을 포함한다. 사용자와의 대화를 제공하기 위하여, 컴퓨터 상에서 여기서 설명하는 시스템 및 기술을 실시할 수 있으며, 상기 컴퓨터는 사용자에게 정보를 표시하기 위한 디스플레이 장치(예를 들어 CRT(음극선관) 또는 LCD(액정 디스플레 이)모니터); 및 키보드와 지향 장치(예를 들어, 마우스 또는 트랙볼)를 구비하며, 사용자는 상기 키보드와 상기 지향 장치를 통해 컴퓨터에 입력을 제공할 수 있다. 기타 유형의 장치도 사용자와의 대화에 사용될 수 있으며, 예를 들어 사용자에게 제공된 피드백은 임의의 형식의 센싱 피드백(예를 들어, 시점적 피드백, 청각적 피드백 또는 촉각적 피드백)일 수 있으며, 임의의 형식(소리 입력, 음성 입력 또는 촉각 입력을 포함)으로 사용자로부 터의 입력을 수신할 수 있다. 여기서 설명한 시스템 및 기술을 백그라운드 부품을 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버) 또는 미 들웨어 부품을 포함하는 컴퓨팅 시스템(예를 들어, 애플리케이션 서버) 또는 프론트 엔드 부품을 포함하는 컴퓨 팅 시스템(예를 들어, 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 구비한 사용자 컴퓨터, 사용자는 상기 그래픽 사용자 인터페이스 또는 상기 네트워크 브라우저를 통해, 여기서 설명한 시스템 및 기술의 실시 형태 와 대화할 수 있음), 또는 이러한 백그라운드 부품, 미들웨어 부품 또는 프론트 엔드 부품을 포함하는 임의의 조합의 컴퓨팅 시스템에서 실시할 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트 워크)을 통해 시스템의 부품을 서로 연결할 수 있다. 통신 네트워크의 예시로는 근거리 통신망(LAN), 광역 통신 망(WAN) 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트와 서버를 포함할 수 있다. 클라이언트와 서버는 일반적으로 서로 멀러 떨어져 있으 며, 일반적으로 통신 네트워크를 통해 서로 대화한다. 대응되는 컴퓨터에서 작동되고 서로 클라이언트-서버 관 계를 가지는 컴퓨터 프로그램을 구비함으로써, 클라이언트와 서버의 관계를 발생한다. 서버는 클라우드 서버일 수 있으며, 클라우드 컴퓨팅 서버 또는 클라우드 호스트라고도 불리며, 클라우드 컴퓨팅 서비스 체계 중 하나의 호스트 제품으로서, 전통적인 물리적 호스트 및 가상 사설 서버(VPS)에 존재하는 관리 난이도가 크고 업무 확장 성이 약한 단점을 해결한다. 서버는 분산 시스템의 서버이거나 블록 체인과 결합된 서버일 수도 있다. 이해해야 할 점은, 이상에서 설명한 여러 가지 형태의 과정을 사용하여, 순서를 다시 순서 배열, 추가 또는 삭 제하는 단계들을 사용할 수 있다. 예를 들어, 본 개시에서 기재한 각 단계들은 병렬적으로 수행할 수도 있고 순 차적으로 수행할 수도 있으며 상이한 순서로 수행할 수도 있는 바, 본 개시에서 개시한 기술적 해결 수단에서 기대하는 결과를 구현할 수만 있으면, 본문은 이에 대해 한정하지 않는다. 상기 구체적인 실시 형태는 본 개시의 보호 범위를 한정하지 않는다. 본 기술 분야에서 통상의 지식을 가진 자 들은 설계 요구와 기타 요소에 근거하여 다양한 수정, 결합, 하위 결합 및 교체를 할 수 있다는 것을 이해해야 한다. 본 개시의 사상 및 원칙 내에서 진행한 임의의 수정, 균등한 교체 및 개선 등은 모두 본 개시의 보호 범 위 내에 포함되어야 한다."}
{"patent_id": "10-2021-0126603", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면은 본 해결 수단을 더 잘 이해하기 위한 것이며, 본 개시에 대해 한정하지 않는다. 여기서, 도 1은 본 개시에 따른 오프라인 음성 인식 방법의 실시예의 흐름도이며; 도 2는 종래의 오프라인 음성 인식 방식의 설명도이며; 도 3은 본 개시에 따른 음절 기반의 종단간 SMLTA 모델의 구조 설명도이며; 도 4는 본 개시에 따른 음절 기반의 종단간 LSTM 언어 모델의 구조 설명도이며; 도 5는 본 개시에 따른 스트리밍식 Transformer 모델의 구조 설명도이며; 도 6은 본 개시에 따른 오프라인 음성 인식의 구현 과정의 설명도이며; 도 7은 본 개시에 따른 오프라인 음성 인식 장치의 실시예의 구성 구조의 설명도이며; 도 8은 본 개시의 실시예를 구현하기 위한 예시적 전자 기기의 예시적 블록도를 도시하였다."}
