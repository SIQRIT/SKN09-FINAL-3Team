{"patent_id": "10-2020-0012154", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0004803", "출원번호": "10-2020-0012154", "발명의 명칭": "전자 장치 및 이의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "최우제"}}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,마이크로폰;통신부;상기 전자 장치로부터 수신된 사용자 음성을 음성 인식 처리하는 음성 인식 서버에 의해 판단된 제어 명령에 기초한 제어 명령 판단 툴이 저장된 메모리; 및사용자 음성이 상기 마이크로폰을 통해 수신되면, 상기 수신된 사용자 음성을 음성 인식 처리하여 사용자 의도정보를 획득하고, 상기 획득된 사용자 의도 정보와 관련된 외부 기기의 상태 정보를 상기 통신부를 통해 복수의외부 기기를 제어하기 위한 기기 제어 서버로부터 수신하며, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보를, 상기 제어 명령 판단 툴에 적용하여상기 복수의 외부 기기 중 제어 대상 기기를 제어하기 위한 제어 명령을 판단하고, 상기 판단된 제어 명령을 상기 통신부를 통해 상기 기기 제어 서버로 전송하는 프로세서;를 포함하는 전자 장치."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 제어 명령 판단 툴은, 사용자 의도 정보, 외부 기기의 상태 정보 및 상기 음성 인식 서버에 의해 판단된 제어 명령이 서로 매칭된 적어도 하나의 룰을 포함하는 룰 DB를 포함하고, 상기 프로세서는, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보에 대응되는 룰이 상기 룰 DB에 존재하는경우, 상기 대응되는 룰에 매칭된 제어 명령을 상기 사용자 음성에 대응되는 제어 명령으로 판단하는, 전자 장치."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 프로세서는, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보에 대응되는 룰이 상기 룰 DB에 존재하지않는 경우, 상기 통신부를 통해 상기 사용자 음성을 상기 음성 인식 서버로 전송하고, 상기 사용자 음성에 기초하여 상기 음성 인식 서버에서 판단된 제어 명령이 상기 통신부를 통해 수신되면, 상기수신된 제어 명령을 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보와 매칭하여 신규 룰을 생성하고, 상기 생성된 신규 룰을 상기 룰 DB에 업데이트하는, 전자 장치."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 제어 명령 판단 툴은, 사용자 의도 정보 및 외부 기기의 상태 정보를 입력으로 하고, 음성 인식 서버에 의해 판단된 제어 명령을 출력으로 하여 학습된 인공 지능 모델을 포함하고, 상기 프로세서는, 공개특허 10-2021-0004803-3-상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보를 상기 학습된 인공 지능 모델에 입력하고, 상기 학습된 인공 지능 모델로부터 출력되는 제어 명령을 상기 사용자 음성에 대응되는 제어 명령으로 판단하는, 전자 장치."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 프로세서는, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보가 입력된 상기 학습된 인공 지능 모델로부터 상기 제어 명령이 출력되지 않는 경우, 상기 통신부를 통해 상기 사용자 음성을 상기 음성 인식 서버로 전송하고, 상기 사용자 음성에 기초하여 상기 음성 인식 서버에서 판단된 제어 명령이 상기 통신부를 통해 수신되면, 상기획득된 사용자 의도 정보, 상기 수신된 외부 기기의 상태 정보 및 상기 수신된 제어 명령에 기초하여 상기 학습된 인공 지능 모델을 재학습시키는, 전자 장치."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서, 상기 프로세서는, 상기 수신된 외부 기기의 상태 정보에 기초하여 상기 획득된 사용자 의도 정보만으로 상기 제어 대상 기기 및제어 대상 기기의 동작을 특정할 수 있는 경우, 상기 제어 명령 판단 툴을 이용함 없이, 상기 획득된 사용자 의도 정보에 기초하여 상기 제어 명령을 판단하는, 전자 장치."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 상기 획득된 사용자 의도 정보는, 엔티티에 관한 정보를 포함하고, 상기 프로세서는, 상기 기기 제어 서버로부터 상기 엔티티와 관련된 복수의 외부 기기의 상태 정보가 수신되면, 상기 획득된 사용자 의도 정보만으로 상기 제어 대상 기기를 특정할 수 없다고 판단하고, 상기 제어 명령 판단 툴을 이용하여 상기 제어 명령을 판단하는, 전자 장치."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서, 상기 통신부는, IR(Infrared) 통신 모듈;을 포함하고, 상기 프로세서는, 상기 제어 대상 기기가 IR 방식으로 제어 가능한 기기인 경우, 상기 판단된 제어 명령을 상기 IR 통신 모듈을통해 상기 제어 대상 기기로 전송하는, 전자 장치."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "전자 장치의 제어 방법에 있어서,상기 전자 장치로부터 수신된 사용자 음성을 음성 인식 처리하는 음성 인식 서버에 의해 판단된 제어 명령에 기초한 제어 명령 판단 툴을 저장하는 단계; 사용자 음성이 수신되면, 상기 수신된 사용자 음성을 음성 인식 처리하여 사용자 의도 정보를 획득하는 단계;상기 획득된 사용자 의도 정보와 관련된 외부 기기의 상태 정보를 복수의 외부 기기를 제어하기 위한 기기 제어공개특허 10-2021-0004803-4-서버로부터 수신하는 단계; 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보를, 제어 명령 판단 툴에 적용하여 상기복수의 외부 기기 중 제어 대상 기기를 제어하기 위한 제어 명령을 판단하는 단계; 및상기 판단된 제어 명령을 상기 기기 제어 서버로 전송하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서, 상기 제어 명령 판단 툴은, 사용자 의도 정보, 외부 기기의 상태 정보 및 상기 음성 인식 서버에 의해 판단된 제어 명령이 서로 매칭된 적어도 하나의 룰을 포함하는 룰 DB를 포함하고, 상기 제어 명령을 판단하는 단계는, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보에 대응되는 룰이 상기 룰 DB에 존재하는경우, 상기 대응되는 룰에 매칭된 제어 명령을 상기 사용자 음성에 대응되는 제어 명령으로 판단하는, 제어 방법."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보에 대응되는 룰이 상기 룰 DB에 존재하지않는 경우, 상기 사용자 음성을 상기 음성 인식 서버로 전송하는 단계; 및 상기 사용자 음성에 기초하여 상기 음성 인식 서버에서 판단된 제어 명령이 수신되면, 상기 수신된 제어 명령을상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보와 매칭하여 신규 룰을 생성하고, 상기 생성된 신규 룰을 상기 룰 DB에 업데이트하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 9 항에 있어서, 상기 제어 명령 판단 툴은, 사용자 의도 정보 및 외부 기기의 상태 정보를 입력으로 하고, 음성 인식 서버에 의해 판단된 제어 명령을 출력으로 하여 학습된 인공 지능 모델을 포함하고, 상기 제어 명령을 판단하는 단계는, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보를 상기 학습된 인공 지능 모델에 입력하고, 상기 학습된 인공 지능 모델로부터 출력되는 제어 명령을 상기 사용자 음성에 대응되는 제어 명령으로 판단하는, 제어 방법."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보가 입력된 상기 학습된 인공 지능 모델로부터 상기 제어 명령이 출력되지 않는 경우, 상기 사용자 음성을 상기 음성 인식 서버로 전송하는 단계; 및 상기 사용자 음성에 기초하여 상기 음성 인식 서버에서 판단된 제어 명령이 수신되면, 상기 획득된 사용자 의도정보, 상기 수신된 외부 기기의 상태 정보 및 상기 수신된 제어 명령에 기초하여 상기 학습된 인공 지능 모델을재학습시키는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 9 항에 있어서, 상기 수신된 외부 기기의 상태 정보에 기초하여 상기 획득된 사용자 의도 정보만으로 상기 제어 대상 기기 및공개특허 10-2021-0004803-5-제어 대상 기기의 동작을 특정할 수 있는 경우, 상기 제어 명령 판단 툴을 이용함 없이, 상기 획득된 사용자 의도 정보에 기초하여 상기 제어 명령을 판단하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서, 상기 획득된 사용자 의도 정보는, 엔티티에 관한 정보를 포함하고, 상기 기기 제어 서버로부터 상기 엔티티와 관련된 복수의 외부 기기의 상태 정보가 수신되면, 상기 획득된 사용자 의도 정보만으로 상기 제어 대상 기기를 특정할 수 없다고 판단하고, 상기 제어 명령 판단 툴을 이용하여 상기 제어 명령을 판단하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 1 항에 있어서, 상기 제어 대상 기기가 IR 방식으로 제어 가능한 기기인 경우, 상기 판단된 제어 명령을 상기 제어 대상 기기로전송하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "음성 인식 서버에 있어서, 통신부;상기 음성 인식 서버가 전자 장치로부터 수신된 사용자 음성에 기초하여 판단한 제어 명령에 기초한 제어 명령판단 툴이 저장된 메모리; 및사용자 음성이 상기 통신부를 통해 상기 전자 장치로부터 수신되면, 상기 수신된 사용자 음성을 음성 인식 처리하여 사용자 의도 정보를 획득하고, 상기 획득된 사용자 의도 정보와 관련된 외부 기기의 상태 정보를 상기 통신부를 통해 복수의 외부 기기를 제어하기 위한 기기 제어 서버로부터 수신하며, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보를, 상기 제어 명령 판단 툴에 적용하여상기 복수의 외부 기기 중 제어 대상 기기를 제어하기 위한 제어 명령을 판단하고, 상기 판단된 제어 명령을 상기 통신부를 통해 상기 기기 제어 서버로 전송하는 프로세서;를 포함하는 음성 인식 서버."}
{"patent_id": "10-2020-0012154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서, 상기 제어 명령 판단 툴은, 사용자 의도 정보, 외부 기기의 상태 정보 및 상기 음성 인식 서버가 판단한 제어 명령이 서로 매칭된 적어도하나의 룰을 포함하는 룰 DB, 및 사용자 의도 정보 및 외부 기기의 상태 정보를 입력으로 하고, 상기 음성 인식 서버가 판단한 제어 명령을 출력으로 하여 학습된 인공 지능 모델 중 적어도 하나를 포함하는, 음성 인식 서버."}
{"patent_id": "10-2020-0012154", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 본 전자 장치는, 마이크로폰, 통신부, 전자 장치로부터 수신된 사용자 음성을 음성 인식 처리하는 음성 인식 서버에 의해 판단된 제어 명령에 기초한 제어 명령 판단 툴이 저장된 메모리 및 사용자 음성 을 음성 인식 처리하여 사용자 의도 정보를 획득하고, 사용자 의도 정보와 관련된 외부 기기의 상태 정보를 복수 의 외부 기기를 제어하기 위한 기기 제어 서버로부터 수신하며, 사용자 의도 정보 및 외부 기기의 상태 정보를 제어 명령 판단 툴에 적용하여 복수의 외부 기기 중 제어 대상 기기를 제어하기 위한 제어 명령을 판단하고, 판 단된 제어 명령을 기기 제어 서버로 전송하는 프로세서를 포함한다."}
{"patent_id": "10-2020-0012154", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 이의 제어 방법에 관한 것으로, 보다 상세하게는, 사용자의 음성을 통해 외부 기기를 제어하는 전자 장치 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0012154", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 네트워크 통신 기술 및 음성 인식 기술이 발달함에 따라 사용자는 네트워크를 통해 연결된 각종 전자 기기 들의 동작을 음성으로 제어할 수 있게 되었다. 예를 들어, 사용자는 IoT(Internet of Things) 환경이나 홈 네트워크 환경에서 허브 장치(예를 들어, AI 스피커 등)에 음성 명령을 발화함으로써 주변의 각종 전자 기기들의 동작을 제어할 수 있다. 이때, 종래에는 허브 장치를 통해 수신된 사용자의 음성 명령을 클라우드를 통해 해석 및 처리하여 기기를 제어 하였는 데, 이 경우 해석 및 처리 과정에서 딜레이가 발생하여 사용자가 느끼는 반응 속도가 저하되는 문제가 발생할 수 있다."}
{"patent_id": "10-2020-0012154", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점에 착안하여 안출된 것으로, 본 개시의 목적은, 멀티 디바이스 환경에서 사용자의 음성 을 통해 신속하고 정확하게 기기들을 제어할 수 있는 전자 장치 및 이의 제어 방법을 제공함에 있다."}
{"patent_id": "10-2020-0012154", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 전자 장치는, 마이크로폰, 통신부, 상기 전자 장치로 부터 수신된 사용자 음성을 음성 인식 처리하는 음성 인식 서버에 의해 판단된 제어 명령에 기초한 제어 명령 판단 툴이 저장된 메모리 및 사용자 음성이 상기 마이크로폰을 통해 수신되면, 상기 수신된 사용자 음성을 음성 인식 처리하여 사용자 의도 정보를 획득하고, 상기 획득된 사용자 의도 정보와 관련된 외부 기기의 상태 정보를 상기 통신부를 통해 복수의 외부 기기를 제어하기 위한 기기 제어 서버로부터 수신하며, 상기 획득된 사용자 의 도 정보 및 상기 수신된 외부 기기의 상태 정보를, 상기 제어 명령 판단 툴에 적용하여 상기 복수의 외부 기기 중 제어 대상 기기를 제어하기 위한 제어 명령을 판단하고, 상기 판단된 제어 명령을 상기 통신부를 통해 상기 기기 제어 서버로 전송하는 프로세서를 포함한다. 또한, 상기 제어 명령 판단 툴은, 사용자 의도 정보, 외부 기기의 상태 정보 및 상기 음성 인식 서버에 의해 판 단된 제어 명령이 서로 매칭된 적어도 하나의 룰을 포함하는 룰 DB를 포함하고, 상기 프로세서는, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보에 대응되는 룰이 상기 룰 DB에 존재하는 경우, 상기 대응되는 룰에 매칭된 제어 명령을 상기 사용자 음성에 대응되는 제어 명령으로 판단할 수 있다. 또한, 상기 프로세서는, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보에 대응되는 룰이 상기 룰 DB에 존재하지 않는 경우, 상기 통신부를 통해 상기 사용자 음성을 상기 음성 인식 서버로 전송하고, 상기 사용자 음성에 기초하여 상기 음성 인식 서버에서 판단된 제어 명령이 상기 통신부를 통해 수신되면, 상기 수신된 제어 명령을 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보와 매칭하여 신규 룰 을 생성하고, 상기 생성된 신규 룰을 상기 룰 DB에 업데이트할 수 있다. 또한, 상기 제어 명령 판단 툴은, 사용자 의도 정보 및 외부 기기의 상태 정보를 입력으로 하고, 음성 인식 서 버에 의해 판단된 제어 명령을 출력으로 하여 학습된 인공 지능 모델을 포함하고, 상기 프로세서는, 상기 획득 된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보를 상기 학습된 인공 지능 모델에 입력하고, 상기 학습된 인공 지능 모델로부터 출력되는 제어 명령을 상기 사용자 음성에 대응되는 제어 명령으로 판단할 수 있 다. 또한, 상기 프로세서는, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보가 입력된 상기 학습된 인공 지능 모델로부터 상기 제어 명령이 출력되지 않는 경우, 상기 통신부를 통해 상기 사용자 음성을 상기 음성 인식 서버로 전송하고, 상기 사용자 음성에 기초하여 상기 음성 인식 서버에서 판단된 제어 명령이 상기 통신부를 통해 수신되면, 상기 획득된 사용자 의도 정보, 상기 수신된 외부 기기의 상태 정보 및 상기 수 신된 제어 명령에 기초하여 상기 학습된 인공 지능 모델을 재학습시킬 수 있다. 또한, 상기 프로세서는, 상기 수신된 외부 기기의 상태 정보에 기초하여 상기 획득된 사용자 의도 정보만으로 상기 제어 대상 기기 및 제어 대상 기기의 동작을 특정할 수 있는 경우, 상기 제어 명령 판단 툴을 이용함 없이, 상기 획득된 사용자 의도 정보에 기초하여 상기 제어 명령을 판단할 수 있다. 또한, 상기 획득된 사용자 의도 정보는, 엔티티에 관한 정보를 포함하고, 상기 프로세서는, 상기 기기 제어 서 버로부터 상기 엔티티와 관련된 복수의 외부 기기의 상태 정보가 수신되면, 상기 획득된 사용자 의도 정보만으 로 상기 제어 대상 기기를 특정할 수 없다고 판단하고, 상기 제어 명령 판단 툴을 이용하여 상기 제어 명령을 판단할 수 있다. 또한, 상기 통신부는, IR(Infrared) 통신 모듈을 포함하고, 상기 프로세서는, 상기 제어 대상 기기가 IR 방식으 로 제어 가능한 기기인 경우, 상기 판단된 제어 명령을 상기 IR 통신 모듈을 통해 상기 제어 대상 기기로 전송 할 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 상기 전자 장치로부터 수신된 사용자 음성을 음 성 인식 처리하는 음성 인식 서버에 의해 판단된 제어 명령에 기초한 제어 명령 판단 툴을 저장하는 단계, 사용 자 음성이 수신되면, 상기 수신된 사용자 음성을 음성 인식 처리하여 사용자 의도 정보를 획득하는 단계, 상기 획득된 사용자 의도 정보와 관련된 외부 기기의 상태 정보를 복수의 외부 기기를 제어하기 위한 기기 제어 서버 로부터 수신하는 단계, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보를, 제어 명령 판 단 툴에 적용하여 상기 복수의 외부 기기 중 제어 대상 기기를 제어하기 위한 제어 명령을 판단하는 단계 및 상 기 판단된 제어 명령을 상기 기기 제어 서버로 전송하는 단계를 포함한다. 또한, 상기 제어 명령 판단 툴은, 사용자 의도 정보, 외부 기기의 상태 정보 및 상기 음성 인식 서버에 의해 판 단된 제어 명령이 서로 매칭된 적어도 하나의 룰을 포함하는 룰 DB를 포함하고, 상기 제어 명령을 판단하는 단 계는, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보에 대응되는 룰이 상기 룰 DB에 존 재하는 경우, 상기 대응되는 룰에 매칭된 제어 명령을 상기 사용자 음성에 대응되는 제어 명령으로 판단할 수 있다. 또한, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보에 대응되는 룰이 상기 룰 DB에 존 재하지 않는 경우, 상기 사용자 음성을 상기 음성 인식 서버로 전송하는 단계 및 상기 사용자 음성에 기초하여 상기 음성 인식 서버에서 판단된 제어 명령이 수신되면, 상기 수신된 제어 명령을 상기 획득된 사용자 의도 정 보 및 상기 수신된 외부 기기의 상태 정보와 매칭하여 신규 룰을 생성하고, 상기 생성된 신규 룰을 상기 룰 DB 에 업데이트하는 단계를 더 포함할 수 있다. 또한, 상기 제어 명령 판단 툴은, 사용자 의도 정보 및 외부 기기의 상태 정보를 입력으로 하고, 음성 인식 서 버에 의해 판단된 제어 명령을 출력으로 하여 학습된 인공 지능 모델을 포함하고, 상기 제어 명령을 판단하는 단계는, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보를 상기 학습된 인공 지능 모델에 입력하고, 상기 학습된 인공 지능 모델로부터 출력되는 제어 명령을 상기 사용자 음성에 대응되는 제어 명령으 로 판단할 수 있다. 또한, 상기 획득된 사용자 의도 정보 및 상기 수신된 외부 기기의 상태 정보가 입력된 상기 학습된 인공 지능 모델로부터 상기 제어 명령이 출력되지 않는 경우, 상기 사용자 음성을 상기 음성 인식 서버로 전송하는 단계 및 상기 사용자 음성에 기초하여 상기 음성 인식 서버에서 판단된 제어 명령이 수신되면, 상기 획득된 사용자 의도 정보, 상기 수신된 외부 기기의 상태 정보 및 상기 수신된 제어 명령에 기초하여 상기 학습된 인공 지능 모델을 재학습시키는 단계를 더 포함할 수 있다. 또한, 상기 수신된 외부 기기의 상태 정보에 기초하여 상기 획득된 사용자 의도 정보만으로 상기 제어 대상 기 기 및 제어 대상 기기의 동작을 특정할 수 있는 경우, 상기 제어 명령 판단 툴을 이용함 없이, 상기 획득된 사 용자 의도 정보에 기초하여 상기 제어 명령을 판단하는 단계를 더 포함할 수 있다. 또한, 상기 획득된 사용자 의도 정보는, 엔티티에 관한 정보를 포함하고, 상기 기기 제어 서버로부터 상기 엔티 티와 관련된 복수의 외부 기기의 상태 정보가 수신되면, 상기 획득된 사용자 의도 정보만으로 상기 제어 대상 기기를 특정할 수 없다고 판단하고, 상기 제어 명령 판단 툴을 이용하여 상기 제어 명령을 판단하는 단계를 더 포함할 수 있다. 또한, 상기 제어 대상 기기가 IR 방식으로 제어 가능한 기기인 경우, 상기 판단된 제어 명령을 상기 제어 대상 기기로 전송하는 단계를 더 포함할 수 있다. 한편, 본 개시의 일 실시 예에 따른 음성 인식 서버는, 통신부, 상기 음성 인식 서버가 전자 장치로부터 수신된 사용자 음성에 기초하여 판단한 제어 명령에 기초한 제어 명령 판단 툴이 저장된 메모리 및 사용자 음성이 상기 통신부를 통해 상기 전자 장치로부터 수신되면, 상기 수신된 사용자 음성을 음성 인식 처리하여 사용자 의도 정 보를 획득하고, 상기 획득된 사용자 의도 정보와 관련된 외부 기기의 상태 정보를 상기 통신부를 통해 복수의 외부 기기를 제어하기 위한 기기 제어 서버로부터 수신하며, 상기 획득된 사용자 의도 정보 및 상기 수신된 외 부 기기의 상태 정보를, 상기 제어 명령 판단 툴에 적용하여 상기 복수의 외부 기기 중 제어 대상 기기를 제어 하기 위한 제어 명령을 판단하고, 상기 판단된 제어 명령을 상기 통신부를 통해 상기 기기 제어 서버로 전송하 는 프로세서를 포함한다. 또한, 상기 제어 명령 판단 툴은, 사용자 의도 정보, 외부 기기의 상태 정보 및 상기 음성 인식 서버가 판단한 제어 명령이 서로 매칭된 적어도 하나의 룰을 포함하는 룰 DB, 및 사용자 의도 정보 및 외부 기기의 상태 정보 를 입력으로 하고, 상기 음성 인식 서버가 판단한 제어 명령을 출력으로 하여 학습된 인공 지능 모델 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2020-0012154", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 멀티 디바이스 환경에서 사용자의 음성을 통해 신속하고 정확 하게 기기들을 제어할 수 있게 된다."}
{"patent_id": "10-2020-0012154", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시를 설명함에 있어, 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있 다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 동일한 구성의 중복 설명은 되도록 생략하기로 한다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 본 개시에서 사용한 용어는 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 제한 및/또는 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, '포함하다' 또는 '가지다' 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 다른 구성요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요소와 상기 다 른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시의 실시 예들에서 사용되는 용어들은 다르게 정의되지 않는 한, 해당 기술 분야에서 통상의 지식을 가진 자에게 통상적으로 알려진 의미로 해석될 수 있다. 이하에서 첨부된 도면을 참조하여 본 개시의 다양한 실시 예를 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따른 음성 제어 시스템을 설명하기 위한 예시도이다. 도 1에 따르면, 음성 제어 시스템은 전자 장치, 외부 기기(200-1, 200-2), 음성 인식 서버 및 기기 제어 서버를 포 함할 수 있다. 전자 장치와 외부 기기(200-1, 200-2)는 가정 또는 사무실과 같은 댁내에서 홈 네트워크 환경 내지 사 물 인터넷 네트워크 환경을 구성할 수 있다. 전자 장치는 스마트 스피커, AI 스피커, 스마트 TV, 스마트 냉장고, 스마트폰, 액세스 포인트, 노트북, 데 스크탑 PC, 태블릿 등과 같은 다양한 종류의 장치로 구현될 수 있다. 한편, 사물 인터넷 환경에서 사물의 종류에는 제한이 없으므로, 외부 기기(200-1, 200-2)의 종류 역시 제한이 없다. 도 1에는 TV 1(200-1) 및 TV 2(200-2)를 도시하였으나, 이는 일 예일 뿐, 에어컨, 스마트 조명, 선풍기, 세탁기, 전자 렌지, 도어락, 사운드 바, 홈시어터, 스마트폰, TV, 냉장고 등 전자 장치와 통신 연결되어 전자 장치를 통해 동작이 제어될 수 있는 기기이면 그 종류에 제한이 없다. 이때, 전자 장치는 사용자 음성에 따라 외부 기기(200-1, 200-2)의 동작을 제어할 수 있다. 예를 들어, 사용자가 외부 기기(200-1, 200-2)의 동작을 제어하기 위한 사용자 음성을 발화하면, 전자 장치 는 발화된 사용자 음성을 수신하여 음성 인식 서버로 전송함으로써 음성 인식 서버 및 기기 제 어 서버를 통해 외부 기기(200-1, 200-2)의 동작을 제어할 수 있다. 구체적으로, 음성 인식 서버는 전자 장치로부터 수신된 사용자 음성에 대응되는 제어 명령을 판단하 고, 판단된 제어 명령을 기기 제어 서버로 전송할 수 있다. 여기서, 제어 명령은, 음성 인식 서버가, 기기 제어 서버로부터 수신한 외부 기기(200-1, 200-2)의 상태 정보에 기초하여, 후술할 사용자 의도 정보를 해석한 결과로서, 사용자가 음성을 통해 제어하고자 하는 제 어 대상 기기 및 그 제어 대상 기기의 동작에 관한 정보를 포함할 수 있다. 구체적으로, 전자 장치로부터 사용자 음성이 수신되면, 음성 인식 서버는 수신된 사용자의 음성을 음 성 인식 처리하여 사용자 음성에 대응되는 사용자 의도 정보를 획득할 수 있다. 여기서, 음성 인식 서버가 수행하는 음성 인식 처리는, 사용자의 음성을 텍스트로 변환하는 ASR(Auto Speech Recognition) 처리와, ASR 처리에 의해 텍스트로 변환된 사용자 음성을 기계가 이해할 수 있는 표현으로 변환하는 NLU(Natural Language Understanding) 처리를 포함한다. 여기서, 사용자 의도 정보는, 음성 인식 서버가, 외부 기기(200-1, 200-2)의 상태 정보를 이용하여 제어 명령을 판단하기 전에, 사용자 음성을 음성 인식 처리한 결과로서, 엔티티(entity) 및 엔티티의 동작(action)에 관한 정보를 포함할 수 있다. 음성 인식 처리 결과인 엔티티 및 엔티티의 동작은 사용자 음성에 따라 다양할 수 있으며, 경우에 따라 엔티티 가 존재하지 않거나 엔티티의 동작이 특정되지 않을 수도 있다. 그러나, 이하에서는 설명의 편의를 위해, 사용 자가 외부 기기(200-1, 200-2)의 동작을 제어하기 위한 사용자 음성을 발화한 것을 전제로, 엔티티가 외부 기기 (200-1, 200-2)로 특정되고, 엔티티의 동작이 외부 기기(200-1, 200-2)의 동작으로 특정되는 경우를 예로 들어 설명한다. 이와 같이, 사용자 의도 정보가 획득되면, 음성 인식 서버는 획득된 사용자 의도 정보와 관련된 엔티티 즉, 외부 기기(200-1, 200-2)의 상태 정보를 기기 제어 서버로 요청할 수 있다. 여기서, 상태 정보는, 외부 기기(200-1, 200-2)의 현재 동작 상태와 관련된 정보로서, 예를 들어, 외부 기기 (200-1, 200-2)의 전원 온/오프 상태에 관한 정보, 외부 기기(200-1, 200-2)의 기능과 관련된 설정 정보, 외부 기기(200-1, 200-2)의 댁내 위치 정보 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 요청한 상태 정보가 기기 제어 서버로부터 수신되면, 음성 인식 서버는, 수신된 외부 기기(200-1, 200-2)의 상태 정보에 기초하여 사용자 의도 정보를 해석함으로써 제어 명령을 판단할 수 있다. 구체적으로, 음성 인식 서버는, 외부 기기(200-1, 200-2)의 상태 정보에 기초하여, 사용자 의도 정보만으 로 제어 대상 기기 및 제어 대상 기기의 동작이 특정될 수 있는지 판단하고, 특정되는 경우, 추가적인 해석없이, 특정된 제어 대상 기기 및 동작에 관한 정보를 포함하는 제어 명령을 판단할 수 있다. 그러나, 사용자 의도 정보만으로 제어 대상 기기 및 동작이 특정되는지 않는 경우, 음성 인식 서버는 음성 인식 서버가 가지고 있는 자체 정책에 따라 사용자 의도 정보를 추가적으로 해석하여 제어 명령을 판단할 수 있다. 이에 관한 보다 자세한 내용은 후술하기로 한다. 음성 인식 서버는 위와 같이 판단된 제어 명령을 기기 제어 서버로 전송하고, 기기 제어 서버는 음성 인식 서버로부터 수신한 제어 명령에 기초하여 제어 대상 기기의 동작을 제어할 수 있게 된다. 기기 제어 서버는 기기 제어 서버와 네트워크를 통해 연결된 기기들을 사용자 계정 별로 등록하고, 등록된 기기들의 상태 정보를 수집 및 관리할 수 있다. 도 1의 예에서, 기기 제어 서버는 전자 장치 및 외부 기기(200-1, 200-2)를 등록하고, 전자 장치 및 외부 기기(200-1, 200-2)의 상태 정보를 수집하여 관리할 수 있다. 따라서, 기기 제어 서버는 음성 인식 서버로부터 외부 기기(200-1, 200-2)의 상태 정보 전송이 요청 되는 경우, 요청에 응답하여 외부 기기(200-1, 200-2)의 상태 정보를 음성 인식 서버로 전송할 수 있다. 한편, 기기 제어 서버는 등록된 기기들 각각에 대한 제어 신호 세트를 저장 및 관리할 수 있다. 여기서, 제어 신호 세트는 해당 기기의 각종 동작을 제어할 수 있는 제어 코드 세트를 말한다. 동일한 동작에 관한 제어 명령이더라도 기기마다 제조사별로 또는 모델 별로 제어 코드가 상이할 수 있으므로, 기기 제어 서버는 등록된 기기들의 동작을 제어하기 위해 기기 별 제어 신호 세트를 저장 및 관리할 수 있 다. 이때, 제어 신호 세트는 기기로부터 직접 수신되거나 또는 기기 제조사가 관리하는 서버를 통해 획득될 수 있을 것이다. 따라서, 기기 제어 서버는 음성 인식 서버로부터 제어 명령이 수신되면, 제어 대상 기기 및 제어 대 상 기기의 동작에 대응되는 제어 신호를 제어 신호 세트에서 확인하고, 확인된 제어 신호를 제어 대상 기기로 전송하여 제어 대상 기기의 동작을 제어할 수 있다. 이하에서, 구체적인 예를 들어 음성 인식 시스템의 동작을 설명한다. 예를 들어, 도 1에 도시된 바와 같이, 가정 내에는 전자 장치, TV 1(200-1) 및 TV 2(200-2)가 IoT 네트워크를 구성하고 있으며, TV 1(200-1) 및 TV 2(200-2)는 사용자 계정을 통해 기기 제어 서버에 등록되어 있다. 이때, 사용자는 어떤 TV 인지 특정하지 않고 \"TV 틀어줘\"와 같은 사용자 음성을 전자 장치로 발화할 수 있다. 전자 장치는 사용자 음성을 음성 인식 서버로 전송하고, 음성 인식 서버는 수신된 사용자 음성 을 ASR(Automatic Speech Recognition) 처리하여 \"TV 틀어줘\"와 같은 ASR 처리 결과를 획득하고, ASR 처리 결 과를 NLU(Natural Language Understanding) 처리하여 \"TV power-on\"과 같은 사용자 의도 정보를 획득할 수 있 다. 이 경우, 사용자 의도 정보에 포함된 엔티티는 \"TV\"가 되고, 엔티티의 동작은 \"power-on\"이 될 것이다. 이와 같이 사용자 의도 정보가 획득되면, 음성 인식 서버는 사용자 의도 정보와 관련된 외부 기기 즉, TV 의 상태 정보를 기기 제어 서버로 요청할 수 있다. 이때, 기기 제어 서버에 등록된 사용자의 TV는 TV 1(200-1)과 TV 2(200-2)가 있으므로, 기기 제어 서버 는 음성 인식 서버의 요청에 응답하여, 상태 정보 전송이 요청된 당시의 TV 1(200-1)의 상태 정보 및 TV 2(200-2)의 상태 정보를 음성 인식 서버로 전송할 수 있다. 이에 따라, 음성 인식 서버는, 수신된 TV 1(200-1) 및 TV 2(200-2)의 상태 정보에 기초하여, 사용자 의도 정보만으로 제어 명령이 특정되는지 판단할 수 있다. 위 예에서, 사용자 의도 정보에 포함된 엔티티는 \"TV\"이지만, TV 1(200-1) 및 TV 2(200-2) 각각 대한 상태 정보 가 기기 제어 서버로부터 수신되었으므로, 사용자 의도 정보만으로는 TV가 TV 1(200-1) 및 TV 2(200-2) 중 어느 TV인지 특정될 수 없다. 즉, 사용자 의도 정보만으로는 제어 대상 기기가 특정되지 않으므로, 음성 인식 서버는 사용자 의도 정보 만으로 제어 명령을 특정할 수 없다고 판단하고, 자체 정책에 따라 제어 명령을 판단할 수 있다. 여기서, 자체 정책은, 음성 인식 서버가 자체적으로 제어 명령을 판단하기 위한 수단으로, 예를 들어, 질 의에 대한 사용자의 응답을 통해 제어 명령을 판단하는 정책 등을 포함할 수 있으나, 이에 한정되는 것은 아니 다. 위 예에서, 음성 인식 서버는 TV 1(200-1) 및 TV 2(200-2) 중 어떤 TV의 전원을 켤지 묻는 질의를 전자 장치로 전송하고, 전자 장치는 수신된 질의를 출력할 수 있다. 이에 따라, 사용자가 예를 들어\"TV 1\"과 같은 응답을 발화하면, 전자 장치는 이를 수신하여 음성 인식 서버로 전송하고, 음성 인식 서버 는 수신된 음성에 기초하여 TV 1(200-1)을 제어 대상 기기로 판단할 수 있다. 따라서, 음성 인식 서버는 \"TV 틀어줘\"에 대응되는 제어 명령으로 \"TV 1 power-on\"을 판단하고, 판단된 제 어 명령을 기기 제어 서버로 전송할 수 있다. 이 경우, 제어 대상 기기는 \"TV 1(200-1)\"이 되고, 제어 대 상 기기의 동작은 \"power-on\"이 될 것이다. 만일 위 예와 달리, 사용자 계정에 하나의 TV만 등록되어 있는 경우, 등록된 하나의 TV에 관한 상태 정보만이 기기 제어 서버로부터 수신될 것이므로, 음성 인식 서버는 사용자 의도 정보만으로 제어 대상 기기를 특정할 수 있게 된다. 따라서, 음성 인식 서버는 자체 정책을 이용하는 등의 추가적인 해석없이, 특정된 제어 대상 기기인\"TV\" 및 특정된 동작인\"power-on\"을 포함하는 제어 명령인 \"TV power-on\"을 판단할 수 있을 것 이다. 이는 복수의 TV가 등록된 경우라도 사용자가 처음부터 \"TV 1(200-1) 틀어줘\"와 같이 제어 대상 기기를 특 정하여 발화한 경우에도 마찬가지이다. 한편, \"TV 1 power-on\"과 같은 제어 명령이 수신되면, 기기 제어 서버는 TV 1(200-1)에 대응되는 제어 신 호 세트에서 \"power-on\"에 해당하는 제어 신호를 확인하고, 확인된 제어 신호를 TV 1(200-1)으로 전송할 수 있 다. 이에 따라, TV 1(200-1)은 턴-온되며, 사용자는 TV 1(200-1)을 통해 방송 프로그램을 시청할 수 있게 된다. 이와 같이, 본 개시의 일 실시 예에 따르면, 전자 장치는, 수신된 사용자 음성을 음성 인식 서버로 전송함으로써 음성 인식 서버가 판단한 제어 명령을 통해 외부 기기(200-1, 200-2)의 동작을 제어할 수 있 다. 한편, 본 개시의 일 실시 예에 따르면, 전자 장치는, 수신된 사용자 음성에 대한 제어 명령을 직접 판단하 여 외부 기기(200-1, 200-2)의 동작을 제어할 수 있다. 구체적으로, 전자 장치는, 음성 인식 서버를 통해 외부 기기(200-1, 200-2)를 제어했던 히스토리 정 보에 기초하여 제어 명령을 판단하기 위한 툴을 생성하고, 생성된 제어 명령 판단 툴에 기초하여 제어 명령을 판단할 수 있다. 여기서, 제어 명령 판단 툴은, 1) 사용자 의도 정보, 외부 기기의 상태 정보 및 제어 명령이 서로 매칭되어 있 는 룰, 또는 2) 사용자 의도 정보 및 외부 기기의 상태 정보를 입력으로 하고, 제어 명령을 출력으로 하여 학습 된 인공 지능 모델이 될 수 있다. 이를 위해, 전자 장치는 음성 인식 기능을 구비하며, 수신된 사용자 음성을 음성 인식 처리하여 사용자 의 도 정보를 획득할 수 있다. 여기서, 전자 장치의 음성 인식 기능은, 전술한 ASR 및 NLU 처리 기능 중 적어도 하나를 포함할 수 있다. 예를 들어, 전자 장치가 ASR 및 NLU 처리 기능을 모두 포함하는 경우, 전자 장치는 수신된 사용자 음 성을 음성 인식 처리하여 사용자 의도 정보를 획득할 수 있다. 또한, 전자 장치가 ASR 처리 기능만 포함하는 경우, 전자 장치는 사용자 음성에 대한 ASR 처리 결과 를 음성 인식 서버로 전송하고, 음성 인식 서버로부터 NLU 처리 결과 즉, 사용자 의도 정보를 획득할 수 있다. 또한, 전자 장치가 NLU 기능만 포함한 경우, 전자 장치는 수신된 사용자 음성을 음성 인식 서버(40 0)로 전송하고, 음성 인식 서버로부터 수신한 ASR 처리 결과를 NLU 처리하여 사용자 의도 정보를 획득할 수 있다. 이때, 전자 장치가 자신의 ASR 처리 기능이나 NLU 처리 기능을 이용하여 사용자 음성을 처리하였으나, 그 처리 결과의 신뢰도가 일정 수준 미만인 경우, 전자 장치는 음성 인식 서버로 사용자 음성에 대한 ASR 처리 및/또는 NLU 처리를 요청하고, 음성 인식 서버로부터 요청한 처리 결과를 획득할 수도 있다. 이 에 관한 자세한 내용은 후술한다. 이에 따라, 전자 장치는 획득된 사용자 의도 정보와 관련된 외부 기기(200-1, 200-2)의 상태 정보를 기기 제어 서버로 요청하여 수신하고, 수신된 외부 기기(200-1, 200-2)의 상태 정보 및 상기 획득된 사용자 의 도 정보를 상기 제어 명령 판단 툴에 적용함으로써 제어 명령을 판단할 수 있다. 또한, 전자 장치는 판단된 제어 명령을 기기 제어 서버로 직접 전송함으로써, 음성 인식 서버를 거치지 않고 외부 기기(200-1, 200-2)의 동작을 제어할 수 있다. 이와 같이, 전자 장치가 수신된 사용자 음성을 직접 음성 인식 처리하여 제어 명령을 판단하거나, 판단된 제어 명령을 기기 제어 서버로 직접 전송하는 경우, 음성 인식 서버를 통해 제어 명령을 판단하고 전 송하는 경우보다 신속하게 외부 기기(200-1, 200-2)의 동작을 제어할 수 있다. 한편, 제어 명령 판단 툴을 이용하여 제어 명령을 판단하는 경우, 사용자 의도 정보 및 외부 기기(200-1, 200- 2)의 상태 정보를, 룰과 비교하거나 인공 지능 모델에 입력하는 등 비교적 간단한 동작을 통해 제어 명령이 판 단되게 되므로, 전술한 음성 인식 서버의 자체 정책을 이용하여 제어 명령을 판단하는 경우 보다 빠르게 제어 명령이 판단될 수 있다. 따라서, 음성 인식 서버가 자체 정책을 통해 제어 명령을 판단하는 경우 발 생될 수 있는 딜레이가 개선될 수 있다. 이하에서는, 도 2를 참조하여, 본 개시의 일 실시 예에 따른 전자 장치의 동작을 자세히 설명한다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 블럭도이다. 도 2에 따르면, 전자 장치는 마이크, 프로세서, 통신부 및 메모리를 포함한다. 마이크는 음파 형태의 사운드를 외부로부터 수신하여 전기적 신호로 변환한 후 변환된 전기적 신호를 프로 세서로 제공한다. 특히, 마이크는 사용자 음성을 수신하여 대응되는 전기적 신호를 프로세서로 제공할 수 있다. 통신부는 외부의 각종 서버 또는 각종 기기들과 통신을 수행하기 위한 구성이다. 특히, 통신부는 음성 인식 서버 또는 기기 제어 서버와 통신을 수행하여, 사용자 음성, 사용자 의도 정보, 외부 기기의 상태 정보, 제어 명령 등과 같은 각종 정보 내지 데이터를 송, 수신할 수 있다. 또한, 통신부는 전자 장치 주변의 외부 기기들(200-1, 200-2)과 통신을 수행하여 IoT 환경이나 홈네 트워크 환경을 구성할 수 있다. 메모리는 저장된 데이터 또는 정보에 프로세서 등이 접근할 수 있도록, 데이터 또는 정보를 전기 또 는 자기 형태로 저장할 수 있다. 특히, 메모리에는, 제어 명령을 판단하기 위한 기초가 되는 제어 명령 판단 툴, 제어 명령 판단 툴을 관리하기 위한 툴 관리 모듈, 음성 인식 기능을 수행하고 제어 명령을 판단하기 위한 음성 인식 모듈 , 및 외부 기기(200-1, 200-2)의 상태 정보를 모니터링하고 제어 명령을 송, 수신하기 위한 기기 제어 모 듈 등이 저장될 수 있다. 프로세서는 전자 장치의 전반적인 동작을 제어한다. 특히, 프로세서는 메모리에 저장된 제 어 명령 판단 툴, 툴 관리 모듈, 음성 인식 모듈, 기기 제어 모듈 등을 로딩하여 각 모듈 의 기능을 수행할 수 있다. 구체적으로, 도 2는, 프로세서가 메모리에 저장된 기기 제어 모듈, 음성 인식 모듈, 및 툴 관리 모듈을 로딩하여 해당 기능을 수행하고 있는 상태를 도시하고 있다. 제어 명령 판단 툴은, 음성 인식 모듈(구체적으로는, NLU 모듈(123-2))이, 후술할 바와 같이 사용자 의도 정보 및 외부 기기의 상태 정보를 적용하여 제어 명령을 판단하기 위한 수단으로, 전자 장치가 이전 에 외부 기기를 제어했던 히스토리 정보에 기초하여 생성되는 룰, 또는 전자 장치가 이전에 외부 기기를 제어했던 히스토리 정보에 기초하여 학습되는 인공 지능 모델을 포함할 수 있다. 여기서, 히스토리 정보에는, 이전 제어 당시 획득된 사용자 의도 정보, 이전 제어 당시 외부 기기의 상태 정보 및 이전 제어 당시 음성 인식 서버에 의해 판단된 제어 명령(특히, 자체 정책에 의해 판단된 제어 명령)이 포함될 수 있다. 구체적으로, 룰 DB(141-1)는 제어 명령을 판단하기 위한 복수의 룰을 포함하는 데이터 베이스이다. 룰 DB(141- 1)는 예를 들어, 아래 표 1과 같이 사용자 의도 정보, 외부 기기의 상태 정보 및 제어 명령이 서로 매칭되어 있 는 룩 업 테이블 형태일 수 있으나, 이에 한정되는 것은 아니다. 표 1 사용자 의도 정보 외부 기기의 상태 정보 제어 명령 룰 1TV power-on TV 1(200-1): off TV 2(200-2): onTV 1(200-1) power-on 룰 2에어컨 power-on 에어컨 1: off에어컨 2: off 에어컨 2 power-on 룰 DB(141-1)의 각 룰에는, 사용자 의도 정보, 외부 기기의 상태 정보 및 제어 명령이 서로 매칭되어 있으므로, 음성 인식 모듈은, 후술할 바와 같이, 사용자 음성에 대응되는 사용자 의도 정보 및 외부 기기의 상태 정보를 획득하고, 획득된 사용자 의도 정보 및 외부 기기의 상태 정보에 대응되는 룰을 룰 DB(141-1)에서 확인하 여 신속하게 제어 명령을 판단할 수 있게 된다. 인공 지능 모델(141-2)은 사용자 의도 정보 및 외부 기기의 상태 정보를 입력으로 하고, 제어 명령을 출력으로 하여 학습된다. 따라서, 후술할 바와 같이, 음성 인식 모듈은, 획득된 사용자 의도 정보 및 외부 기기의 상태 정보를 상기 학습된 인공 지능 모델에 입력함으로써, 신속하게 제어 명령을 획득할 수 있다. 툴 관리 모듈은 메모리에 저장된 제어 명령 판단 툴을 관리할 수 있다. 구체적으로, 툴 관리 모듈은 음성 인식 모듈이 제어 명령을 판단할 때 제어 명령 판단 툴을 이 용할 수 있도록, 적절한 시점에 메모리에 접속하여 제어 명령 판단 툴 중 적어도 일부를 프로세서 에 로딩할 수 있다. 예를 들어, 툴 관리 모듈은 음성 인식 모듈의 요청이 있는 때, 룰 DB(141-1)에 포함된 적어도 일부의 룰 및/또는 인공 지능 모델(141-2)을 프로세서에 로딩할 수 있다. 그러나, 로딩 시점이 이에 한정되는 것 은 아니다. 가령, 툴 관리 모듈은, 실시 예에 따라, 사용자 음성이 수신된 때 또는 전자 장치의 전원 이 온된 때 등과 같이 음성 인식 모듈이 제어 명령을 판단하기 전의 다양한 시점에 제어 명령 판단 툴 을 프로세서에 로딩할 수 있다. 한편, 툴 관리 모듈는 제어 명령 판단 툴을 업데이트할 수 있다. 이에 관하여는 후술하기로 한다. 기기 제어 모듈은 기기 제어 서버를 통해 외부 기기의 상태 정보를 모니터링하고, 음성 인식 모듈 로 제공할 수 있다. 구체적으로, 기기 제어 모듈은, 음성 인식 모듈로부터 외부 기기의 상태 정보가 요청되면, 통신부 를 통해 기기 제어 서버로 외부 기기의 상태 정보를 요청하고, 기기 제어 서버로부터 수신되는 현재 외부 기기의 상태 정보를 음성 인식 모듈로 제공할 수 있다. 한편, 기기 제어 모듈은, 후술하는 실시 예와 같이 툴 관리 모듈로부터 외부 기기의 상태 정보가 요 청되면, 기기 제어 서버로부터 수신되는 현재 외부 기기의 상태 정보를 툴 관리 모듈로 제공할 수도 있다. 또한, 기기 제어 모듈은 음성 인식 모듈이 판단한 제어 명령을 기기 제어 서버로 전송하여 제어 대상 기기의 동작을 제어할 수 있다. 구체적으로, 기기 제어 모듈은, 음성 인식 모듈로부터 제어 명령이 수신되면, 수신된 제어 명령을 통 신부를 통해 기기 제어 서버로 전송할 수 있다. 이에 따라, 기기 제어 서버가 제어 명령에 대응 되는 제어 신호를 제어 대상 기기로 전송함으로써, 제어 대상 기기의 동작이 제어될 수 있다. 음성 인식 모듈은 마이크를 통해 수신되는 사용자 음성에 대응되는 제어 명령을 판단할 수 있다. 구체적으로, 음성 인식 모듈은 음성 인식 기능을 수행할 수 있다. 이를 위해, 음성 인식 모듈은 ASR 모듈(123-1) 및 NLU 모듈(123-2)을 포함할 수 있다. ASR 모듈(123-1)은 사용자 음성을 인식하고, 인식된 사용자 음성을 텍스트로 출력할 수 있다. 예를 들어, \"TV 틀어줘\"와 같은 사용자 음성이 마이크를 통해 수신되면, ASR 모듈(123-1)은 이를 인식하여 \"TV 틀어줘\"와 같은 텍스트를 NLU 모듈(123-2)로 출력할 수 있다. 이를 위해, ASR 모듈(123-1)은 음향(acoustic) 모델 및 언어(language) 모델을 포함할 수 있다. 이때, 음향 모 델은 발성에 관련된 정보를 포함할 수 있고, 언어 모델은 단위 음소 정보 및 단위 음소 정보의 조합에 대한 정 보를 포함할 수 있다. 따라서, ASR 모듈(123-1)은 발성에 관련된 정보 및 단위 음소 정보에 대한 정보를 이용하 여 사용자 음성을 텍스트로 변환할 수 있다. NLU 모듈(123-2)은 ASR 모듈(123-1)로부터 수신된 텍스트의 의미 즉, 사용자 음성에 대응되는 사용자 의도를 파 악할 수 있다. 예를 들어, \"TV 틀어줘\"와 같은 텍스트가 ASR 모듈(123-1)로부터 수신되면, NLU 모듈(123-2)은 이를 분석하여 \"TV power-on\"과 같은 사용자 의도 정보를 획득할 수 있다. 이를 위해, NLU 모듈(123-2)은, ASR 모듈(123-1)로부터 수신된 텍스트에 대해, 키워드 매칭(keyword matching), 구문 분석(syntactic analysis) 및 의미 분석(semantic analysis) 등의 작업을 수행하여 사용자 의 도를 파악할 수 있다. 도 2에서는 음성 인식 모듈이 ASR 모듈(123-1) 및 NLU 모듈(123-2)를 모두 포함하는 것을 예로 들었으나, 실시 예가 이에 한정되는 것은 아니다. 즉, 예를 들어 음성 인식 모듈은, ASR 모듈(123-1) 또는 NLU 모듈 (123-2) 중 하나만을 포함할 수도 있으며, 이 경우, 음성 인식 모듈은 나머지 모듈의 역할에 해당하는 처 리를 음성 인식 서버로 요청하고, 그 처리 결과를 수신할 수도 있다. 이때, 어느 경우이든 음성 인식 모듈은, 음성 인식 처리 결과 즉, ASR 처리 및/또는 NLU 처리 결과의 신뢰 도가 일정 수준 미만인 경우, 음성 인식 서버로 사용자 음성에 대한 ASR 처리 및/또는 NLU 처리를 요청하 고, 그 처리 결과를 획득할 수도 있음은 전술한 바와 같다. 이와 같이, 음성 인식 모듈은 마이크를 통해 수신된 사용자 음성을 음성 인식 처리하여 사용자 음성 에 대응되는 사용자 의도 정보를 획득할 수 있다. 또한, 음성 인식 모듈은 사용자 의도 정보와 관련된 외부 기기의 상태 정보를 획득할 수 있다. 구체적으로, 상술한 바와 같이 사용자 의도 정보가 획득되면, NLU 모듈(123-2)(이하에서, NLU 모듈(123-2)의 동 작은, 음성 인식 모듈이 ASR 모듈(123-1)만 포함하는 실시 예의 경우에는, 음성 인식 모듈이 수행하 는 것으로 볼 수 있다.)은 획득된 사용자 의도 정보와 관련된 외부 기기의 상태 정보를 기기 제어 모듈을 통해 기기 제어 서버로부터 수신할 수 있다. 이와 같이, 사용자 의도 정보 및 외부 기기의 상태 정보가 획득되면, NLU 모듈(123-2)은, 제어 명령 판단 툴 중 룰 DB(141-1)의 로딩을 툴 관리 모듈에 요청할 수 있다. 이에 따라, 룰 DB(141-1)가 프로세서에 로딩되면, NLU 모듈(123-2)은 로딩된 룰 DB(141-1) 중 상기 획득 된 사용자 의도 정보 및 외부 기기의 상태 정보와 동일한 사용자 의도 정보 및 외부 기기의 상태 정보가 매칭되 어 있는 룰이 룰 DB(141-1)에 존재하는지 확인하고, 존재하는 경우, 해당 룰에 매칭되어 있는 제어 명령을, 사 용자 음성에 대응되는 제어 명령으로 판단할 수 있다. 예를 들어, 이전에 사용자가 \"TV 틀어줘\"라는 사용자 음성을 발화함에 따라 음성 인식 서버를 통해 TV 1(200-1)을 제어했던 히스토리에 기초하여, 상기 표 1의 룰 1과 같은 룰이 생성되어 룰 DB(141-1)에 저장되어 있고, 이후에 다시 사용자가 \"TV 틀어줘\"라는 음성을 발화한 경우를 가정하자. 이 경우, 음성 인식 모듈은 사용자 음성을 음성 인식 처리하여 \"TV power-on\"이라는 사용자 의도 정보를 획득하고, NLU 모듈(123-2)은 TV와 관련된 외부 기기의 상태 정보를 기기 제어 모듈을 통해 기기 제어 서 버로부터 수신할 수 있다. 또한, NLU 모듈(123-2)은 툴 관리 모듈에 룰 DB(141-1)의 로딩을 요청하고, 이에 따라, 룰 1을 포함하는 룰 DB(141-1)가 프로세서에 로딩될 수 있다. 이때, NLU 모듈(123-2)로 수신된 외부 기기의 상태 정보가 \"TV 1(200-1) off\" 및 \"TV 2(200-2) on\"인 경우, 룰 DB(141-1)에는 사용자 의도 정보가 \"TV power-on\"이고, 외부 기기의 상태 정보가 \"TV 1(200-1) off\" 및 \"TV 2(200-2) on\"인 룰 1이 존재하므로, 음성 인식 모듈은 룰 1에 매칭되어 있는 제어 명령인 \"TV 1(200-1) power-on\"을, 현재 수신된 \"TV 틀어줘\"에 대한 제어 명령으로 즉시 판단할 수 있다. 이상에서는, 음성 인식 모듈의 요청에 따라 메모리에 저장된 전체 룰 DB(141-1)가 프로세서에 로딩되는 것을 예로 들어 설명하였으나, 실시 예가 이에 한정되는 것은 아니다. 가령, 사용자 의도 정보와 관련된 외부 기기를 포함하는 룰들만 프로세서에 로딩될 수도 있다. 예를 들어, 상기 표 1과 같은 룰 DB(141-1)가 메모리에 저장되어 있고, 상술한 예에서와 같이 \"TV power-on\"이라는 사 용자 의도 정보가 획득되면, 음성 인식 모듈은 사용자 의도 정보와 관련된 외부 기기 즉, TV를 포함하는 룰의 로딩을 툴 관리 모듈로 요청할 수 있다. 이에 따라, 툴 관리 모듈은 룰 DB(141-1) 중 TV를 포함 하는 룰 1만 프로세서에 로딩할 수 있다. 이 경우, 음성 인식 모듈이 매칭되는 룰의 존부를 확인할 때 비교 대상이 줄어들게 되므로, 보다 신속하게 제어 명령의 존부가 판단될 수 있을 것이다. 한편, 본 개시의 다른 일 실시 예에 따르면, 사용자 의도 정보 및 외부 기기의 상태 정보가 획득된 경우, NLU 모듈(123-2))은 제어 명령 판단 툴 중 인공 지능 모델(141-2)의 로딩을 툴 관리 모듈에 요청할 수도 있다. 이에 따라, 인공 지능 모델(141-2)이 프로세서에 로딩되면, NLU 모듈(123-2)은, 획득된 사용자 의도 정보 및 외부 기기의 상태 정보를 인공 지능 모델(141-2)에 입력하고, 이에 따라 출력되는 제어 명령(예를 들어, 복수의 제어 명령들 중 가장 높은 확률 값을 갖는 제어 명령)을, 사용자 음성에 대응되는 제어 명령으로 판단할 수 있다. 예를 들어, 이전에 사용자가 \"TV 틀어줘\"라는 사용자 음성을 발화함에 따라 음성 인식 서버를 통해 TV 1(200-1)을 제어 했던 히스토리에 기초하여, 사용자 의도 정보(\"TV power-on\") 및 사용자 의도 정보와 관련된 외부 기기의 상태 정보(\"TV 1(200-1) off\", \"TV 2(200-2) on\")가 입력되는 경우 제어 명령(\"TV 1(200-1) power-on\")이 가장 높은 확률 값으로 출력되도록 하여 인공 지능 모델(141-2)이 학습되어 있는 경우를 가정하자. 이 경우, 이후에 다시 사용자가 \"TV 틀어줘\"라는 음성을 발화한 경우를 가정하면, 음성 인식 모듈은 사용 자 음성을 음성 인식 처리하여 \"TV power-on\"이라는 사용자 의도 정보를 획득하고, NLU 모듈(123-2)는 TV와 관 련된 외부 기기의 상태 정보를 기기 제어 모듈을 통해 기기 제어 서버로부터 수신할 수 있다. 이때, 수신된 외부 기기의 상태 정보가 \"TV 1(200-1) off\", \"TV 2(200-2) on\"인 경우, NLU 모듈(123-2)은, 현 재 획득된 사용자 의도 정보인 \"TV power-on\" 및 현재 수신한 외부 기기의 상태 정보인 \"TV 1(200-1) off\", \"TV 2(200-2) on\"을 상기 학습된 인공 지능 모델(141-2)에 입력할 수 있다. 이에 따라, NLU 모듈(123-2)은, 인 공 지능 모델(141-2)에서 출력되는 제어 명령 \"TV 1(200-1) power-on\"을 현재 수신된 \"TV 틀어줘\"에 대한 제어 명령으로 즉시 판단할 수 있다. 한편, 본 개시의 일 실시 예에 따르면, NLU 모듈(123-2)은, 제어 명령 판단 툴을 이용하기 전에, 도 1의 음성 인식 서버의 동작과 같이, 획득된 사용자 의도 정보 및 외부 기기의 상태 정보에 기초하여 사용자 의 도 정보만으로 제어 명령이 특정되는지를 먼저 판단하고, 사용자 의도 정보만으로 제어 명령이 특정되는 경우에 는 제어 명령 판단 툴을 이용하지 않고 상기 획득된 사용자 의도 정보에 기초하여 제어 명령을 바로 판단 할 수도 있다. 예를 들어, 위 예에서 기기 등록 서버에 등록된 사용자 계정의 TV가 1대이고, \"TV off\"라는 TV의 상태 정 보가 수신된 경우, \"TV power-on\"이라는 사용자 의도 정보만으로, 제어 대상 기기 및 제어 대상 기기의 동작이 특정되므로, 음성 인식 모듈은 툴 관리 모듈로 제어 명령 판단 툴을 요청하지 않고,\"TV power- on\"을 \"TV 틀어줘\"라는 사용자 음성에 대한 제어 명령으로 바로 판단할 수도 있을 것이다. 이와 같이, 사용자 음성에 대응되는 제어 명령이 판단되면, 음성 인식 모듈은 판단된 제어 명령을 기기 제 어 모듈로 전송함으로써, 제어 대상 기기의 동작을 제어할 수 있다. 한편, 툴 관리 모듈은 룰 DB(141-1) 또는 인공 지능 모델(141-2)을 업데이트 할 수 있다. 구체적으로, 음 성 인식 모듈은 획득된 사용자 의도 정보 및 외부 기기의 상태 정보에 대응되는 룰이 룰 DB(141-1)에 존재 하지 않거나, 획득된 사용자 의도 정보 및 외부 기기의 상태 정보를 인공 지능 모델(141-2)에 입력하였으나 제 어 명령이 출력되지 않는 경우(예를 들어, 기설정된 확률 값 이상을 갖는 제어 명령이 없는 경우), 획득된 사용 자 의도 정보 및 외부 기기의 상태 정보를 툴 관리 모듈로 전송하고, 통신부를 통해 사용자 음성을 음성 인식 서버로 전송할 수 있다. 이에 따라, 음성 인식 서버는 도 1에서 전술한 바와 같이 사용자 음성에 대응되는 제어 명령을 판단하고, 판단된 제어 명령을 기기 제어 서버 및 전자 장치로 전송할 수 있다. 또는 음성 인식 서버는 판 단된 제어 명령을 기기 제어 서버로만 전송하고, 기기 제어 서버가 전자 장치로 제어 명령을 전 송할 수도 있다. 이때, 기기 제어 서버로 전송된 제어 명령은, 도 1에서 전술한 바와 같이, 제어 신호 형태로 제어 대상 기 기로 전송되어 제어 대상 기기의 동작을 제어하는데 이용된다. 한편, 전자 장치로 전송된 제어 명령은 룰 DB(141-1)나 인공 지능 모델(141-2)를 업데이트하는데 이용되게 된다. 구체적으로, 음성 인식 서버에서 판단된 제어 명령이 통신부를 통해 수신되면, 툴 관리 모듈은, 음성 인식 모듈로부터 수신한 사용자 의도 정보 및 외부 기기의 상태 정보를, 음성 인식 서버로부터 수신한 제어 명령과 매칭시켜 신규 룰을 생성하고, 생성된 신규 룰을 룰 DB(141-1)에 업데이트 할 수 있다. 또한, 툴 관리 모듈은, 음성 인식 모듈로부터 수신한 사용자 의도 정보 및 외부 기기의 상태 정보를 입력으로 하고, 음성 인식 서버로부터 수신한 제어 명령을 출력으로 하여 인공 지능 모델을 학습시킴으로써, 인공 지능 모델(141-2)을 업데이트할 수 있다. 이와 같이, 업데이트된 룰 DB(141-1) 및 인공 지능 모델(141-2)은 이후 마이크를 통해 수신되는 사용자 음 성에 대응되는 제어 명령 판단에 이용될 수 있다. 한편, 이상에서는, 툴 관리 모듈이 음성 인식 모듈로부터 사용자 의도 정보 및 외부 기기의 상태 정 보를 모두 수신하는 것을 예로 들었으나, 실시 예가 이에 한정되는 것은 아니다. 예를 들어, 음성 인식 모듈은 획득된 사용자 의도 정보만을 툴 관리 모듈로 전송할 수 있다. 이에 따 라, 툴 관리 모듈은 음성 인식 모듈로부터 수신된 사용자 의도 정보와 관련된 외부 기기의 상태 정보 를 기기 제어 모듈로 요청하고, 기기 제어 모듈로부터 외부 기기의 상태 정보를 직접 수신할 수도 있 다. 한편, 이상에서는, NLU 모듈(123-2)이 제어 명령을 판단하기 위해 룰 DB(141-1) 또는 인공 지능 모델(142-2)을 이용하는 예를 각각 설명하였다. 그러나, 본 개시의 일 실시 에에 따르면, NLU 모듈(123-2)은, 먼저 룰 DB(141- 1)를 이용하여 제어 명령 판단을 시도하고, 획득된 사용자 의도 정보 및 외부 기기의 상태 정보에 대응되는 룰 이 룰 DB(141-1) 존재하지 않는 경우, 인공 지능 모델(141-2)을 이용하여 제어 명령을 판단할 수 있다. 또는 본 개시의 다른 실시 예에 따르면, NLU 모듈(123-2)은, 먼저 인공 지능 모델(141-2)을 이용하여 제어 명령 판단을 시도하고, 기설정된 확률 값 이상을 갖는 제어 명령이 인공 지능 모델(141-2)에서 출력되지 않는 경우, 룰 DB(141-1)에 기초하여 제어 명령을 판단할 수도 있다. 위 두 실시 예에서, 룰 DB(141-1) 및 인공 지능 모델(141-2) 어느 것을 이용하더라도 제어 명령이 판단되지 않 는 경우, 툴 관리 모듈은 전술한 바와 같이 룰 DB(141-1) 및 인공 지능 모델(141-2)을 업데이트할 수 있다. 이하에서는, 도 3 내지 도 5을 참조하여 본 개시의 다양한 실시 예들을 설명한다. 도 3 내지 도 5를 설명함에 있어 전술한 것과 동일한 내용의 중복 설명은 생략한다. 도 3은 본 개시의 일 실시 예에 따른 음성 인식 시스템을 도시한 도면이다. 도 3에 따르면, 음성 인식 시스템 (1000')은, 전자 장치, 스마트 TV(200-3), 스마트 에어컨 1(200-4), 스마트 에어컨 2(200-5), 레거시 TV(200-6), 액세스 포인트, 음성 인식 서버 및 기기 제어 서버을 포함할 수 있다. 전자 장치와 스마트 TV(200-3), 에어컨 1(200-4), 에어컨 2(200-5)는 인터넷 연결이 가능한 기기들로, 댁 내에서 IoT 네트워크를 구성하고 있으며, 액세스 포인트를 통해 음성 인식 서버 및 기기 제어 서 버와 연결될 수 있다. 한편, 레거시 TV(200-6)의 경우, 인터넷 연결이 불가능하며, IR 통신 방식으로만 동 작의 제어가 가능하다. 한편, 음성 인식 서버 및 기기 제어 서버는 클라우드 서버일 수 있으나, 이에 한정되는 것은 아니다. 이러한 상황에서, 사용자는 기기 제어 서버에 접속하여 스마트 TV(200-3), 에어컨 1(200-4), 에어컨 2(200-5), 레거시 TV(200-6)를 자신의 계정에 등록할 수 있다. 이때, 기기 제어 서버는 액세스 포인트를 통해 연결된 스마트 TV(200-3), 에어컨 1(200-4), 에어컨 2(200-5)에 대하여만 상태 정보의 모니터링 및 동작의 제어가 가능하고, 레거시 TV(200-6)에 대하여는 상태 정 보의 모니터링과 동작의 제어가 불가능하다. 다만, 레거시 TV(200-6)의 사용자 계정을 통해 알 수 있다. 한편, 이전에 외부 기기를 제어했던 히스토리 정보에 기초하여 아래 표 2와 같은 룰 DB가 전자 장치의 메 모리에 저장되어 있을 수 있다. 표 2 사용자 의도 정보 외부 기기의 상태 정보 제어 명령 룰 1TV power-on 스마트 TV(200-3): on 레거시 TV(200-6)레거시 TV(200-6) power-on 룰 2에어컨 power-on에어컨 1(200-4): off 에어컨 2(200-5): off에어컨 2(200-5) power-on 이와 같은 상황에서, \"TV 틀어줘\"와 같은 사용자 음성이 수신되면, 전자 장치는 전술한 바와 같이, 사용자 음성을 음성 인식 처리하여 \"TV power-on\"과 같은 사용자 의도 정보를 획득하고, TV의 상태 정보를 기기 제어 서버로 요청할 수 있다. 이에 따라, \"스마트 TV(200-3) on\", \"레거시 TV(200-6)\"와 같은 상태 정보가 수 신되면, 전자 장치는 표 2의 룰 1에 기초하여 \"레거시 TV(200-6) power-on\"을 제어 명령으로 판단할 수 있 다. 다만, 이 경우에는 기기 제어 서버를 통한 레거시 TV(200-6)의 동작 제어가 불가능하므로, 전자 장치(10 0)는 판단된 제어 명령을 직접 레거시 TV(200-6)로 전송하여, 레거시 TV(200-6)의 동작을 제어할 수 있다. 이를 위해, 전자 장치는 IR 블라스터 등과 같은 IR 신호를 송, 수신하기 위한 구성을 포함할 수 있다. 한편, 에어컨 1(200-4) 및 에어컨 2(200-5)가 모두 off인 상태에서 사용자가 \"에어컨 틀어줘\"와 같은 음성을 발 화한 경우, 전자 장치는 표 2의 룰 2에 따라 \"에어컨 2(200-5) power-on\"와 같은 제어 명령을 판단할 수 있다. 이 경우에는 기기 제어 서버를 통한 에어컨 2(200-5)의 동작 제어가 가능하므로, 전자 장치는 도 1 및 도 2에서 전술한 바와 같이, 기기 제어 서버로 제어 명령을 전송하여 에어컨 2(200-5)의 동작을 제어할 수 있다. 그러나, 실시 예가 이에 한정되는 것은 아니다. 즉, 기기 제어 서버를 통한 동작 제어가 가능한 경우에도, 실시 예에 따라 와이 파이 다이렉트 등과 같은 기기 간 통신 방식을 통해 전자 장치가 제어 명령을 직접 에어컨 2(200-5)로 전송함으로써, 에어컨 2(200-5)의 동작을 제어할 수도 있을 것이다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치의 블럭도이다. 도 4에 따르면, 전자 장치(100')는 마이크, 프로세서, 통신부, 메모리, 스피커 및 디스플레이를 포함할 수 있다. 마이크는 하나 이상의 마이크로폰으로 구현될 수 있으며, 전자 장치(100')와 일체형으로 구현될 수도 있고, 분리형으로 구현될 수도 있다. 여기서, 분리형 마이크는 마이크로폰이 전자 장치(100')의 본체에 포함되 지 않고 따로 떨어져서 유선 또는 무선으로 전자 장치(100')와 연결되는 형태를 의미한다. 통신부는 각종 서버나 기기들과 통신을 수행하여, 다양한 정보(또는 데이터)를 송수신할 수 있는 하드웨어 를 지칭할 수 있다. 통신부는 TCP/IP(Transmission Control Protocol/Internet Protocol), UDP(User Datagram Protocol), HTTP(Hyper Text Transfer Protocol), HTTPS(Secure Hyper Text Transfer Protocol), FTP(File Transfer Protocol), SFTP(Secure File Transfer Protocol), MQTT(Message Queuing Telemetry Transport) 등의 통신 규 약(프로토콜)을 이용하여 외부의 서버(400, 500)나 기기들(200-1 내지 200-6)과 다양한 정보를 송수신할 수 있 다. 통신부는 각종 서버(400, 500) 및 복수의 외부 기기(200-1 내지 200-6)와 각종 네트워크를 통해 연결될 수 있다. 여기서, 네트워크는 영역 또는 규모에 따라 개인 통신망(PAN; Personal Area Network), 근거리 통신망 (LAN; Local Area Network), 광역 통신망(WAN; Wide Area Network) 등을 포함하며, 네트워크의 개방성에 따라 인트라넷(Intranet), 엑스트라넷(Extranet), 또는 인터넷(Internet) 등을 포함할 수 있다. 통신부는 근거리 무선 통신 모듈(미도시) 및 무선랜 통신 모듈(미도시) 중 적어도 하나의 통신 모듈을 포 함할 수 있다. 근거리 무선 통신 모듈(미도시)은 근거리에 위치한 외부 기기와 무선으로 데이터 통신을 수행하 는 통신 모듈로써, 예를 들어, 블루투스(Bluetooth) 모듈, 지그비(ZigBee) 모듈, NFC(Near Field Communication) 모듈, 적외선 통신 모듈, IR(Infrared) 통신 모듈, 와이파이 모듈(와이 파이 P2P 기능 사용 시) 등이 될 수 있다. 또한, 무선랜 통신 모듈(미도시)은 와이파이(WiFi), IEEE 등과 같은 무선 통신 프로토콜 에 따라 외부 네트워크에 연결되어 외부 서버 또는 외부 기기와 통신을 수행하는 모듈이다. 이 밖에 통신부는 실시 예에 따라 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), 5G(5th Generation mobile communications) 등과 같은 다양한 이동 통신 규격에 따 라 이동 통신망에 접속하여 통신을 수행하는 이동 통신 모듈을 더 포함할 수도 있으며, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), IEEE(Institute of Electrical and Eletronics Engineers) 1394, RS-232, RS-422, RS-485, Ethernet 등과 같은 통신 규격에 따른 유선 통신 모듈(미도시)을 더 포함할 수도 있다. 한편, 통신부는 상술한 유무선 통신 방식에 따른 네트워크 인터페이스(Network Interface) 또는 네트워크 칩을 포함할 수 있다. 또한, 통신 방식은 상술한 예에 한정되지 아니하고, 기술의 발전에 따라 새롭게 등장하는 통신 방식을 포함할 수 있다. 메모리에는 전자 장치(100') 또는 프로세서의 동작을 위한 운영체제(O/S), 각종 프로그램 또는 애플 리케이션, 및 데이터가 저장될 수 있다. 구체적으로, 메모리에는 전자 장치(100') 또는 프로세서의 동작에 필요한 적어도 하나의 인스트럭션(instruction), 모듈 또는 데이터가 저장될 수 있다. 여기서, 인스트럭션은 전자 장치(100') 또는 프로세서의 동작을 지시하는 부호 단위로서, 컴퓨터가 이해할 수 있는 언어인 기계어로 작성된 것일 수 있다. 모듈은 작업 단위의 특정 작업을 수행하는 일련의 인스트럭션의 집합체(instruction set)일 수 있다. 데이터는 문자, 수, 영상 등을 나타낼 수 있는 비트(bit) 또는 바이트 (byte) 단위의 정보일 수 있다. 메모리는 프로세서에 의해 액세스 되며, 프로세서에 의해 인스트럭션, 모듈, 인공지능 모델 또 는 데이터에 대한 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 이를 위해, 메모리는 내장 메모리 또는 외장 메모리를 포함할 수 있다. 내장 메모리는, 휘발성 메모리 또 는 비휘발성 메모리(non-volatile Memory) 중 적어도 하나를 포함할 수 있다. 휘발성 메모리는, 예를 들어 DRAM(dynamic RAM), SRAM(static RAM), SDRAM(synchronous dynamic RAM) 등일 수 있다. 비휘발성 메모리는 예 를 들어 OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, NAN flash memory, NOR flash memory 등일 수 있다. 또한, 내장 메모리는 Solid State Drive(SSD)일 수 있다. 외장 메모리는 flash drive, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital) 또는 Memory Stick 등을 포함할 수 있다. 외장 메모리는 다양한 인터페이스를 통하여 전자 장치(100')와 기능적으로 연결될 수 있다. 또한, 전자 장치(100')는 하드 드라이브와 같은 저장 장 치를 더 포함할 수도 있다. 스피커는 전기적 신호를 청각적인 형태(예: 음성)로 출력하는 장치이다. 스피커는 오디오 처리부(미도시) 에 의해 디코딩이나 증폭, 노이즈 필터링과 같은 다양한 처리 작업이 수행된 각종 오디오 데이터뿐만 아니라 각 종 알림 음이나 음성 메시지를 직접 소리로 출력할 수 있다. 예를 들어, 음성 인식 서버의 자체 정책에 따 른 질의가 통신부를 통해 수신되면, 스피커는 수신된 질의를 음성으로 출력할 수 있다. 디스플레이는 정보를 시각적인 형태(예: 그래픽, 문자, 이미지 등)로 출력하는 장치이다. 디스플레이(16 0)는 이미지 프레임을 디스플레이 영역의 전체 또는 일부 영역에 표시할 수 있다. 예를 들어, 음성 인식 서버 의 자체 정책에 따른 질의가 통신부를 통해 수신되면, 디스플레이는 수신된 질의를 문자로 출력 할 수 있다. 프로세서는 메모리에 저장된 각종 프로그램(예를 들어, 적어도 하나의 인스트럭션, 모듈 등)이나 데 이터를 읽어, 본 개시의 다양한 실시 예들에 따른 전자 장치(100')의 동작을 수행할 수 있다. 메모리에 저장된 룰 DB, 인공 지능 모델, 음성 인식 모듈, 기기 제어 모듈 등은, 프로세서에 의해 로 딩되어 해당 기능이 각각 수행될 수 있다. 이를 위해, 프로세서는 메모리에 저장된 각종 프로그램 및 데이터의 적어도 일부를 로딩하기 위한 내부 메모리를 포함할 수 있다. 한편, 프로세서는 중앙처리장치(central processing unit(CPU)), controller, 어플리케이션 프로세서 (application processor(AP)), 마이크로 프로세서(microprocessor unit(MPU)), 커뮤니케이션 프로세서 (communication processor(CP)), GPU(Graphic Processing Unit), VPU(Vision Processing Unit), NPU(Neural Processing Unit), 또는 ARM 프로세서 중 하나 또는 그 이상을 포함할 수 있다. 한편, 도 2에서는, 획득된 사용자 의도 정보 및 외부 기기의 상태 정보에 대응되는 룰이 룰 DB(141-1)에 존재하 지 않거나, 획득된 사용자 의도 정보 및 외부 기기의 상태 정보를 인공 지능 모델(141-2)에 입력하였으나 제어 명령이 출력되지 않는 때, 음성 인식 서버로 사용자 음성이 전송되는 것을 예로 들었으나, 실시 예가 이에 한정되는 것은 아니다. 즉, 실시 예에 따라, 프로세서는, 대응되는 룰의 존재 여부나 인공 지능 모델로부터 제어 명령의 출력 여 부와 무관하게, 사용자 음성이 수신되면 수신된 사용자 음성을 항상 음성 인식 서버로 전송할 수도 있다. 이러한 실시 예에서, 대응되는 룰이 룰 DB(141-1)에 존재하거나 인공 지능 모델로부터 제어 명령이 출력되는 경 우에는, 전자 장치 및 음성 인식 서버 각각이 판단한 제어 명령이 기기 제어 서버로 각각 전송 되게 되므로, 기기 제어 서버는 전자 장치(100') 및 음성 인식 서버로부터 동일한 제어 명령을 각각 수신하게 될 수 있다. 이러한 경우에는, 2 개의 제어 명령을 수신한 기기 제어 서버가 2번째로 수신한 제어 명령을 무시하거나, 또는 2 개의 제어 신호를 수신한 제어 대상 기기가 2 번째로 수신한 제어 신호를 무시함으로써, 제어 대상 기기 가 동일한 동작을 2번 수행하는 오류를 막을 수 있다. 이때, 기기 제어 서버가 2 번째로 수신하는 제어 명령 또는 제어 대상 기기가 2 번째로 수신하는 제어 신 호는, 대부분 음성 인식 서버가 전송한 제어 명령 및 그에 따른 제어 신호가 될 것이다. 이는, 제어 명령 판단 툴에 의한 제어 명령 판단이 음성 인식 서버의 제어 명령 판단보다 빠르기 때문이다. 한편, 도 1 및 도 2에서는 음성 인식 서버의 추가적인 해석이 필요한 경우로, 사용자 의도 정보만으로 제 어 대상 기기가 특정되지 않는 경우를 예로 들었으나, 이에 한정되는 것은 아니며, 제어 대상 기기는 특정되더 라도 제어 대상 기기의 동작이 특정되지 않는 경우에도 음성 인식 서버의 추가적인 해석이 필요하다. 예를 들어, 사용자 계정에 하나의 TV(200-1)가 등록되어 있고, 사용자가 \"MBC 틀어줘\"와 같은 사용자 음성을 발 화한 경우, 전자 장치(100')는 음성 인식 처리를 통해 \"TV Channel MBC\"와 같은 사용자 의도 정보를 획득하고, \"TV\"의 상태 정보를 기기 제어 서버로 요청할 수 있다. 이때, TV 1(200-1)이 켜져 있는 상태인 경우, 기기 제어 서버는 \"TV 1(200-1) on\"과 같은 상태 정보를 전 자 장치(100')로 전송할 수 있다. 한편, TV 1(200-1)의 상태 정보가 on/off 정보에 국한되지 않음은 도 1에 관 한 설명에서 전술한 바와 같다. 예를 들어, TV 1(200-1)에서 재생 중인 현재 방송 채널에 관한 정보, 현재 설정 된 TV 1(200-1)의 볼륨에 관한 정보 등이 실시 예에 따라 상태 정보에 더 포함될 수도 있음은 물론이다. 그러나, 전자 장치(100')는 \"MBC\"가 몇 번의 채널을 의미하는지 알 수 없으므로, 음성 인식 서버로 사용자 음성을 전송할 수 있다. (\"MBC 틀어줘\"와 관련하여 룰도 존재하지 않고, 인공 지능 모델도 학습되지 않은 상태 를 전제한다.) 이에 따라, 음성 인식 서버 역시, 음성 인식 처리를 통해 \"TV Channel MBC\"와 같은 사용자 의도 정보를 획 득하고, 기기 제어 서버로부터 \"TV 1(200-1) on\"과 같은 상태 정보를 수신할 수 있다. 음성 인식 서버 역시 \"MBC\"가 몇 번의 채널을 의미하는지 알 수 없으므로, 사용자 의도 정보만으로 제어 대상 기기 즉, TV 1(200-1)의 동작이 특정되지 않는다고 판단하고, 사용자 질의와 같은 자체 정책에 따른 추가 적인 해석을 통해 MBC가 11번 채널인 것을 확인하게 된다. 이에 따라, 음성 인식 서버는 \"TV 1(200-1) Channel 11”과 같은 제어 명령을 판단하여 기기 제어 서버 로 전송하고, 이에 따라, TV 1(200-1)의 채널이 변경될 수 있다. 이때, 음성 인식 서버 또는 기기 제어 서버는 음성 인식 서버가 판단한 제어 명령을 전자 장치 (100')로 전송하게 되며, 이에 따라, 전자 장치(100')의 프로세서는 아래 표 3의 룰 1과 같은 룰을 생성하 여 룰 DB(141-1)를 업데이트 할 수 있다. 표 3 사용자 의도 정보 외부 기기의 상태 정보 제어 명령 룰 1TV Channel MBC TV 1(200-1): on TV 1(200-1) Channel 11 룰 2에어컨 power-on 에어컨 1: off 에어컨 2: off에어컨 2 power-on 이후 TV 1(200-1)이 켜져 있는 상태에서 사용자가 다시 \"MBC 틀어줘\"와 같은 사용자 음성을 발화하면, 프로세서 는 상기 표 3의 룰 1을 이용하여 신속하게 제어 명령을 판단할 수 있게 된다. 한편, 이상에서는 전자 장치(100')가 제어 명령 판단 툴을 이용하여 사용자 음성에 대응되는 제어 명령을 판단하는 다양한 예들을 설명하였다. 그러나, 본 개시의 일 실시 예에 따르면, 음성 인식 서버가 제어 명 령 판단 툴을 이용하여 사용자 음성에 대응되는 제어 명령을 판단할 수도 있다. 도 5는 본 개시의 일 실시 예에 따른 음성 인식 서버의 블럭도이다. 도 5에 따르면, 음성 인식 서버는 통 신부, 프로세서 및 메모리를 포함할 수 있다. 통신부는 외부의 각종 서버 또는 각종 기기들과 통신을 수행하기 위한 구성이다. 특히, 통신부는 전 자 장치 및 기기 제어 서버와 통신을 수행하여, 사용자 음성, 사용자 의도 정보, 외부 기기의 상태정보, 제어 명령 등과 같은 각종 정보 내지 데이터를 송, 수신할 수 있다. 메모리는 저장된 데이터 또는 정보에 프로세서 등이 접근할 수 있도록, 데이터 또는 정보를 전기 또 는 자기 형태로 저장할 수 있다. 특히, 메모리에는, 제어 명령을 판단하기 위한 기초가 되는 제어 명령 판 단 툴 및 자체 정책, 제어 명령 판단 툴을 관리하기 위한 툴 관리 모듈, 음성 인식 기능을 수행 하고 제어 명령을 판단하기 위한 음성 인식 모듈, 및 외부 기기(200-1, 200-2)의 상태 정보를 모니터링하 고 제어 명령을 송, 수신하기 위한 기기 제어 모듈 등이 저장될 수 있다. 프로세서는 음성 인식 서버의 전반적인 동작을 제어한다. 특히, 프로세서는 메모리에 저장 된 제어 명령 판단 툴, 툴 관리 모듈, 음성 인식 모듈, 기기 제어 모듈 등을 로딩하여 각 모듈의 기능을 수행할 수 있다. 구체적으로, 도 5는, 프로세서가 메모리에 저장된 기기 제어 모듈, 음성 인식 모듈, 및 툴 관리 모듈을 로딩하여 해당 기능을 수행하고 있는 상태를 도시하고 있다. 도 5에 도시된 구성들 중 도 2 및 도 4에 도시된 구성들과 명칭이 동일한 구성들은, 도 2 및 도 4에 도시된 구 성들과 동일한 내용이거나 또는 동일하게 동작할 수 있다. 이하에서는, 도 2 및 도 4에서 전술한 것과 동일한 내용의 중복 설명을 생략하고, 차이가 있는 내용을 위주로 설명하기로 한다. 도 5를 보면, 마이크가 없는 것을 제외하고, 각 구성들이 도 2의 전자 장치의 구성과 동일한 것을 볼 수 있다. 전자 장치에서는 사용자 음성이 마이크를 통해 수신되지만, 음성 인식 서버에서는 통신부 를 통해 전자 장치로부터 수신될 수 있다. 한편, 음성 인식 서버는, 획득된 사용자 의도 정보 및 외부 기기의 상태 정보에 대응되는 룰이 룰 DB(431- 1) 존재하지 않거나, 획득된 사용자 의도 정보 및 외부 기기의 상태 정보를 인공 지능 모델(431-2)에 입력하였 으나 제어 명령이 출력되지 않는 경우이더라도, 자체 정책을 통해 직접 제어 명령을 판단하게 되므로, NLU 모듈 (123-2)이 판단한 제어 명령을 직접 툴 관리 모듈로 전달하면 되고, 통신부를 통해 외부에서 수신할 필요가 없다. 예를 들어, 통신부를 통해 전자 장치로부터 사용자 음성이 수신되면, 음성 인식 모듈은 수신된 사용자 음성을 ASR 및 NLU 처리하여 사용자 의도 정보를 획득하고, 획득된 사용자 의도 정보와 관련된 외부 기 기의 상태 정보를 기기 제어 모듈을 통해 기기 제어 서버로부터 수신할 수 있다. 이에 따라, NLU 모듈(423-2)은 툴 관리 모듈로 제어 명령 판단 툴의 로딩을 요청하고, 로딩된 제어 명령 판단 툴을 이용하여 도 2에서 전술한 바와 같이 사용자 음성에 대응되는 제어 명령을 판단할 수 있다. 한편, 제어 명령 판단 툴을 이용하여 제어 명령을 판단할 수 없는 경우, NLU 모듈(423-2)은, 획득된 사용 자 의도 정보 및 외부 기기의 상태 정보를 툴 관리 모듈로 전달한다. 또한, NLU 모듈(723-2)은 자체 정책 을 이용하여 제어 명령을 판단한다. 자체 정책을 통해 제어 명령이 판단되면, NLU 모듈(423-2)은 판단된 제어 명령을 툴 관리 모듈로 전달하게 되며, 툴 관리 모듈은 NLU 모듈(423-2)로부터 전달받은 사용자 의도 정보, 외부 기기의 상태 정보 및 제어 명령에 기초하여, 도 2에서 전술한 바와 같이 룰 DB(431-1) 또는 인공 지능 모델(431-2)를 업데이트할 수 있다. 이와 같이, 업데이트된 룰 DB 및 인공 지능 모델은, 이후에 통신부를 통해 전자 장치로부 터 수신되는 사용자 음성에 대응되는 제어 명령의 판단에 이용될 수 있다. 한편, 일반적으로 음성 인식 서버와 같은 서버 장치는 전자 장치와 같은 클라이언트 장치에 비해 대 용량의 저장 공간과 고속의 연산 속도를 가질 수 있다. 따라서, 음성 인식 서버에는, 다양한 상황에서 입력되는 다양한 음성을 원하는 속도로 처리할 수 있는 대 용량 고성능의 음성 인식 모듈(ASR 모듈(423-1) 및 NLU 모듈(423-2) 등)이 탑재될 수 있다. 그러나, 전자 장치의 경우, 저장 공간이나 연산 성능의 한계로 인해 탑재될 수 있는 음성 인식 모듈 (ASR 모듈(123-1) 및 NLU 모듈(123-2) 등)에 한계가 있다. 따라서, 본 개시의 일 실시 예에 따르면, 전자 장치로부터 사용자 음성에 대한 음성 인식 처리(ASR 처리 및/또는 NLU 처리)가 요청되는 경우, 음성 인식 서버의 음성 인식 모듈은, 수신된 사용자 음성을 전자 장치의 요청에 따라 음성 인식 처리하고, 그 결과(ASR 처리 결과인 텍스트 또는 NLU 처리 결과인 사용 자 의도 정보)를 통신부를 통해 전자 장치로 전송할 수 있다. 도 6은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 나타내는 흐름도이다. 도 6에 따르면, 전자 장치(100, 100')는 음성 인식 서버에 의해 판단된 제어 명령에 기초한 제어 명령 판 단 툴을 저장할 수 있다(S610). 이때, 제어 명령 판단 툴은, 1) 사용자 의도 정보, 외부 기기의 상태 정보 및 음성 인식 서버에 의해 판단된 제어 명령이 서로 매칭된 적어도 하나의 룰을 포함하는 룰 DB(141-1), 및 2) 사용자 의도 정보 및 외부 기기의 상태 정보를 입력으로 하고, 음성 인식 서버에 의해 판단된 제어 명령을 출력으로 하여 학습된 인 공 지능 모델(141-2) 중 적어도 하나를 포함할 수 있다. 한편, 사용자 음성이 수신되면, 전자 장치(100, 100')는, 수신된 사용자 음성을 음성 인식 처리하여 사용자 의 도 정보를 획득하고(S620), 획득된 사용자 의도 정보와 관련된 외부 기기의 상태 정보를 기기 제어 서버로 요청하여 수신할 수 있다(S630). 이에 따라, 전자 장치(100, 100')는, 획득된 사용자 의도 정보 및 수신된 외부 기기의 상태 정보를, 제어 명령 판단 툴에 적용하여, 제어 대상 기기를 제어하기 위한 제어 명령을 판단하고(S640), 판단된 제어 명령을 기기 제어 서버로 전송할 수 있다(S650). 예를 들어, 전자 장치(100, 100')는, 획득된 사용자 의도 정보 및 수신된 외부 기기의 상태 정보에 대응되는 룰 이 룰 DB(141-1)에 존재하는 경우, 대응되는 룰에 매칭된 제어 명령을 사용자 음성에 대응되는 제어 명령으로 판단할 수 있다. 만일, 대응되는 룰이 룰 DB(141-1)에 존재하지 않으면, 전자 장치(100, 100')는, 사용자 음성을 음성 인식 서버 로 전송하고, 이에 따라, 음성 인식 서버에서 판단된 제어 명령이 수신되면, 수신된 제어 명령을 상 기 획득된 사용자 의도 정보 및 수신된 외부 기기의 상태 정보와 매칭하여 신규 룰을 생성하고, 생성된 신규 룰 을 룰 DB(141-1)에 업데이트할 수 있다. 한편, 전자 장치(100, 100')는, 획득된 사용자 의도 정보 및 수신된 외부 기기의 상태 정보를 인공 지능 모델 (141-2)에 입력하고, 인공 지능 모델(141-2)로부터 출력되는 제어 명령을 사용자 음성에 대응되는 제어 명령으 로 판단할 수도 있다. 이때, 인공 지능 모델(141-2)로부터 제어 명령이 출력되지 않으면, 전자 장치(100, 100')는, 사용자 음성을 음 성 인식 서버로 전송하고, 이에 따라, 음성 인식 서버에서 판단된 제어 명령이 수신되면, 획득된 사 용자 의도 정보, 수신된 외부 기기의 상태 정보 및 수신된 제어 명령에 기초하여 인공 지능 모델을 재학습시킬 수 있다. 한편, 본 개시의 일 실시 예에 따르면, 전자 장치(100, 100')는, 외부 기기의 상태 정보에 기초하여 사용자 의 도 정보만으로 제어 대상 기기 및 제어 대상 기기의 동작을 특정할 수 있는 경우, 제어 명령 판단 툴을 이 용함 없이, 사용자 의도 정보에 기초하여 제어 명령을 판단할 수 있다. 이때, 기기 제어 서버로부터 사용자 의도 정보에 포함된 엔티티와 관련된 복수의 외부 기기의 상태 정보가 수신되면, 전자 장치(100, 100')는, 사용자 의도 정보만으로 제어 대상 기기를 특정할 수 없다고 판단하고, 제 어 명령 판단 툴을 이용하여 제어 명령을 판단할 수 있다. 한편, 전자 장치(100, 100')는, 제어 대상 기기가 IR 방식으로 제어 가능한 기기인 경우, 제어 명령을 제어 대 상 기기로 직접 전송할 수도 있다. 이상과 같은 본 개시의 다양한 실시 예에 따르면, 멀티 디바이스 환경에서 사용자의 음성을 통해 신속하고 정확 하게 기기들을 제어할 수 있게 된다. 한편, 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 여기서, 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치 (100, 100') 또는 음성 인식 서버를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세서의 제어하에 다른 구성요소들 을 이용하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태 로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 일 실시 예에 따르면, 본 개시에 개시된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행 할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상의 설명은 본 개시의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 개시가 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 개시의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 또한, 본 개시에 따른 실시 예들은 본 개시의 기술 사상을 한정하기 위한 것이 아니라 설명하기 한 것이고, 이러한 실시 예에 의하여 본 개시의 기술 사상의 범위가 한정되는 것은 아니다. 따라서, 본 개시의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 개 시의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2020-0012154", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 음성 제어 시스템을 도시한 도면, 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 블럭도, 도 3은 본 개시의 일 실시 예에 따른 음성 제어 시스템을 도시한 도면, 도 4는 본 개시의 일 실시 예에 따른 전자 장치의 블럭도, 도 5는 본 개시의 일 실시 예에 따른 음성 인식 서버의 블럭도, 및 도 6은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 도시한 흐름도이다."}
