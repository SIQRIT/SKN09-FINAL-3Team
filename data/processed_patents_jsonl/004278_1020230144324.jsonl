{"patent_id": "10-2023-0144324", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0018347", "출원번호": "10-2023-0144324", "발명의 명칭": "무인 탐사 및 정찰을 위한 드론 유닛과, 드론 유닛의 자율 비행 시스템 및 그 방법", "출원인": "한국과학기술원", "발명자": "명현"}}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "무인 탐사 및 정찰을 위한 드론 유닛의 자율 비행 시스템에 있어서,드론 유닛에 장착된 카메라를 통해 제1 정보를 획득하고, 라이다(LiDAR)를 통해 제2 정보를 획득하며, 관성 측정 장치(IMU)를 통해 제3 정보를 획득하는 정보 획득부;상기 제2 정보 및 상기 제3 정보를 통해 상기 드론 유닛의 위치를 추정하고, 상기 제1 정보 및 상기 제2 정보를통해 대상 물체의 좌표 값을 획득하며, 상기 드론 유닛의 위치 추정 값과 상기 대상 물체의 좌표 값, 및 상기제2 정보를 기반으로 3차원 지도와 미지 영역 탐사 알고리즘을 구축하는 정보 처리부; 상기 3차원 지도와 상기 미지 영역 탐사 알고리즘을 기반으로 한 장애물 회피 경로를 생성하는 경로 생성부; 및 상기 장애물 회피 경로를 상기 드론 유닛에 적용하는 비행 제어부를 포함하는 드론 유닛의 자율 비행 시스템."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 정보 획득부는상기 카메라를 통해 대상 물체 인식에 관한 상기 제1 정보를 획득하고, 상기 라이다를 통해 상기 드론 유닛의위치 추정 및 지도 생성을 위한 상기 제2 정보를 획득하며, 상기 관성 측정 장치를 통해 상기 드론 유닛의 실시간 각속도 및 가속도 정보에 관한 상기 제3 정보를 획득하는, 드론 유닛의 자율 비행 시스템."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 정보 처리부는상기 제1 정보를 통해 목표물인 대상 물체를 인식하며, 상기 제1 정보와 상기 제2 정보로부터 상기 대상 물체의좌표를 산출하여 상기 대상 물체의 좌표 값을 획득하는, 드론 유닛의 자율 비행 시스템."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 정보 처리부는상기 제2 정보, 상기 제3 정보, 및 상기 3차원 지도를 이용하여 상기 드론 유닛의 위치를 추정하고, 위치 추정오차를 보정하여 상기 드론 유닛의 목표 지점을 수정하는 것을 특징으로 하는, 드론 유닛의 자율 비행 시스템."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 정보 처리부는상기 대상 물체의 좌표 값과 상기 제2 정보, 그리고 상기 드론 유닛의 위치 추정 값을 이용하여 상기 3차원 지도를 작성하며, 상기 3차원 지도와 상기 제2 정보 및 상기 제3 정보로부터 상기 드론 유닛의 실시간 위치를 추정하고, 해당 위치 추정 값으로 상기 미지 영역 탐사 알고리즘을 처리하는, 드론 유닛의 자율 비행 시스템."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,공개특허 10-2025-0018347-3-상기 정보 처리부는지역적 탐색 구간(local horizon) 영역 내의 프런티어(frontier) 중에서 가장 멀고, 덩어리(cluster)의 크기가큰 프런티어를 최적의 프런티어로 선택하여 이동하는 과정을 반복하는 상기 미지 영역 탐사 알고리즘을 처리하는, 드론 유닛의 자율 비행 시스템."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 경로 생성부는상기 3차원 지도와 상기 미지 영역 탐사 알고리즘을 기반으로 샘플링(sampling) 기반의 최단 거리를 탐색하고,좁은 영역에서 장애물을 회피하도록 경로를 수정하여 상기 장애물 회피 경로를 생성하는, 드론 유닛의 자율 비행 시스템."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 비행 제어부는상기 경로 생성부에 의해 생성된 상기 장애물 회피 경로에 따라 상기 드론 유닛의 비행 움직임을 제어하는, 드론 유닛의 자율 비행 시스템."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "무인 탐사 및 정찰을 위한 드론 유닛에 있어서, 제1 정보를 획득하는 카메라;제2 정보를 획득하는 라이다(LiDAR);제3 정보를 획득하는 관성 측정 장치(IMU);적어도 하나의 명령어(instruction)를 저장하는 메모리; 및상기 적어도 하나의 명령어를 실행하여, 상기 제1 정보, 상기 제2 정보 및 상기 제3 정보를 통해 작성된 3차원지도와 미지 영역 탐사 알고리즘을 기반으로 한 장애물 회피 경로에 따라 비행 움직임을 제어하는 제어부를 포함하는 드론 유닛."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 드론 유닛은드론 프레임;상기 드론 프레임의 중심부에 위치하며, 상기 카메라, 상기 라이다 및 상기 관성 측정 장치, 상기 메모리 및 상기 제어부가 구비된 본체;상기 드론 프레임과 연결되며, 상기 본체를 중심으로 사각형 형태를 나타내는 결합식 프로펠러 가드;상기 드론 프레임의 네 개의 각 암(arm)에 하방으로 부착되어 비행을 위한 추력을 발생시키는 프로펠러; 및상기 드론 프레임의 네 개의 모서리 각 하단에 위치하며, 상기 결합식 프로펠러 가드와 결합되는 랜딩기어를 포함하는 드론 유닛."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 결합식 프로펠러 가드는공개특허 10-2025-0018347-4-사각형 형태의 네 측면 중앙에 탄성 소재를 결합하여 충격을 흡수하는 것을 특징으로 하는, 드론 유닛."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "무인 탐사 및 정찰을 위한 드론 유닛의 자율 비행 시스템에 의한 자율 비행 방법에 있어서,드론 유닛에 장착된 카메라를 통해 제1 정보를 획득하고, 라이다(LiDAR)를 통해 제2 정보를 획득하며, 관성 측정 장치(IMU)를 통해 제3 정보를 획득하는 단계;상기 제2 정보 및 상기 제3 정보를 통해 상기 드론 유닛의 위치를 추정하고, 상기 제1 정보 및 상기 제2 정보를통해 대상 물체의 좌표 값을 획득하며, 상기 드론 유닛의 위치 추정 값과 상기 대상 물체의 좌표 값, 및 상기제2 정보를 기반으로 3차원 지도와 미지 영역 탐사 알고리즘을 구축하는, 정보를 처리하는 단계; 상기 3차원 지도와 상기 미지 영역 탐사 알고리즘을 기반으로 한 장애물 회피 경로를 생성하는 단계; 및 상기 장애물 회피 경로를 상기 드론 유닛에 적용하는 단계를 포함하는 드론 유닛의 자율 비행 방법."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 획득하는 단계는상기 카메라를 통해 대상 물체 인식에 관한 상기 제1 정보를 획득하고, 상기 라이다를 통해 상기 드론 유닛의위치 추정 및 지도 생성을 위한 상기 제2 정보를 획득하며, 상기 관성 측정 장치를 통해 상기 드론 유닛의 실시간 각속도 및 가속도 정보에 관한 상기 제3 정보를 획득하는, 드론 유닛의 자율 비행 방법."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 정보를 처리하는 단계는상기 제1 정보를 통해 목표물인 대상 물체를 인식하며, 상기 제1 정보와 상기 제2 정보로부터 상기 대상 물체의좌표를 산출하여 상기 대상 물체의 좌표 값을 획득하는, 드론 유닛의 자율 비행 방법."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 정보를 처리하는 단계는상기 제2 정보, 상기 제3 정보, 및 상기 3차원 지도를 이용하여 상기 드론 유닛의 위치를 추정하고, 위치 추정오차를 보정하여 상기 드론 유닛의 목표 지점을 수정하는 것을 특징으로 하는, 드론 유닛의 자율 비행 방법."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 정보를 처리하는 단계는상기 대상 물체의 좌표 값과 상기 제2 정보, 그리고 상기 드론 유닛의 위치 추정 값을 이용하여 상기 3차원 지도를 작성하며, 상기 3차원 지도와 상기 제2 정보 및 상기 제3 정보로부터 상기 드론 유닛의 실시간 위치를 추정하고, 해당 위치 추정 값으로 상기 미지 영역 탐사 알고리즘을 처리하는, 드론 유닛의 자율 비행 방법."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 정보를 처리하는 단계는지역적 탐색 구간(local horizon) 영역 내의 프런티어(frontier) 중에서 가장 멀고, 덩어리(cluster)의 크기가큰 프런티어를 최적의 프런티어로 선택하여 이동하는 과정을 반복하는 상기 미지 영역 탐사 알고리즘을 처리하공개특허 10-2025-0018347-5-는, 드론 유닛의 자율 비행 방법."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 장애물 회피 경로를 생성하는 단계는상기 3차원 지도와 상기 미지 영역 탐사 알고리즘을 기반으로 샘플링(sampling) 기반의 최단 거리를 탐색하고,좁은 영역에서 장애물을 회피하도록 경로를 수정하여 상기 장애물 회피 경로를 생성하는, 드론 유닛의 자율 비행 방법."}
{"patent_id": "10-2023-0144324", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 드론 유닛에 적용하는 단계는상기 경로 생성부에 의해 생성된 상기 장애물 회피 경로에 따라 상기 드론 유닛의 비행 움직임을 제어하는, 드론 유닛의 자율 비행 방법."}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 무인 탐사 및 정찰을 위한 자율 비행 드론 유닛과 위치 추정, 물체 인식, 경로 생성 및 미지 영역 탐 사를 포함한 드론 유닛의 자율 비행 시스템 및 그 방법에 관한 것으로서, 드론 유닛에 장착된 카메라를 통해 제1 정보를 획득하고, 라이다(LiDAR)를 통해 제2 정보를 획득하며, 관성 측정 장치(IMU)를 통해 제3 정보를 획득하는 정보 획득부, 상기 제2 정보 및 상기 제3 정보를 통해 상기 드론 유닛의 위치를 추정하고, 상기 제1 정보 및 상 기 제2 정보를 통해 대상 물체의 좌표 값을 획득하며, 상기 드론 유닛의 위치 추정 값과 상기 대상 물체의 좌표 값, 및 상기 제2 정보를 기반으로 3차원 지도와 미지 영역 탐사 알고리즘을 구축하는 정보 처리부, 상기 3차원 지도와 상기 미지 영역 탐사 알고리즘을 기반으로 한 장애물 회피 경로를 생성하는 경로 생성부 및 상기 장애물 회피 경로를 상기 드론 유닛에 적용하는 비행 제어부를 포함한다."}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 무인 탐사 및 정찰을 위한 드론 유닛과, 드론 유닛의 자율 비행 시스템 및 그 방법에 관한 것으로서, 보다 상세하게는 무인 탐사 및 정찰을 위한 자율 비행 드론 유닛과 위치 추정, 물체 인식, 경로 생성 및 미지 영역 탐사를 포함한 자율 비행 프레임워크에 관한 것이다."}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 드론 유닛은 비행 기능을 구비하고 있어서 다양한 분야에 적용되고 있다. 그 중에서 드론 유닛은 사람이 접근하기 힘든 미지의 환경을 탐사 및 정찰하여 다양한 정보를 획득하는 등의 감시역할을 하는 분야에서 두각을 나타내고 있다. 다만, 미지의 환경에서 드론 유닛이 자율 비행하여 탐사 혹은 정찰 임무를 수행하기 위 해서는 충돌에 강인한 하드웨어를 갖는 것이 중요하며, 경량, 소형, 긴 비행 시간의 모든 조건을 만족해야 한다. 또한, 미지의 환경에서 드론이 자율 비행하여 탐사 혹은 정찰 임무를 수행하기 위해서는 실시간으로 정확하게 위치를 추정하고, 위치 추정 오차를 보정할 수 있어야 하며, 안전하게 장애물을 회피하는 경로를 생성하고, 효 율적인 미지 영역 탐사 알고리즘을 갖는 자율 비행 프레임워크 개발이 필요하다."}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 추력 효율, 무게, 크기 및 충돌에 강인함을 고려한 새로운 형상의 드론 유닛의 플랫폼을 제안 하고자 한다. 본 발명의 목적은 실시간으로 위치를 추정하고, 위치 추정 오차를 보정해서 목표 지점의 좌표를 수정하여 드론 유닛이 안정적인 출발점으로 복귀하는 알고리즘과, 좁은 영역에서 안전하게 장애물을 회피하는 경로 생성 알고 리즘, 센서 융합을 통한 정확한 목표물의 좌표 획득 알고리즘, 및 지역적 탐색 구간(local horizon)을 활용한 미지 영역 탐사 알고리즘을 제안하고자 한다. 다만, 본 발명이 해결하고자 하는 기술적 과제들은 상기 과제로 한정되는 것은 아니며, 본 발명의 기술적 사상 및 영역으로부터 벗어나지 않은 범위에서 다양하게 확장될 수 있다."}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 무인 탐사 및 정찰을 위한 드론 유닛의 자율 비행 시스템에 있어서, 드론 유닛에 장착 된 카메라를 통해 제1 정보를 획득하고, 라이다(LiDAR)를 통해 제2 정보를 획득하며, 관성 측정 장치(IMU)를 통 해 제3 정보를 획득하는 정보 획득부, 상기 제2 정보 및 상기 제3 정보를 통해 상기 드론 유닛의 위치를 추정하 고, 상기 제1 정보 및 상기 제2 정보를 통해 대상 물체의 좌표 값을 획득하며, 상기 드론 유닛의 위치 추정 값 과 상기 대상 물체의 좌표 값, 및 상기 제2 정보를 기반으로 3차원 지도와 미지 영역 탐사 알고리즘을 구축하는 정보 처리부, 상기 3차원 지도와 상기 미지 영역 탐사 알고리즘을 기반으로 한 장애물 회피 경로를 생성하는 경 로 생성부 및 상기 장애물 회피 경로를 상기 드론 유닛에 적용하는 비행 제어부를 포함한다. 본 발명의 실시예에 따른 무인 탐사 및 정찰을 위한 드론 유닛에 있어서, 제1 정보를 획득하는 카메라, 제2 정 보를 획득하는 라이다(LiDAR), 제3 정보를 획득하는 관성 측정 장치(IMU), 적어도 하나의 명령어(instruction) 를 저장하는 메모리 및 상기 적어도 하나의 명령어를 실행하여, 상기 제1 정보, 상기 제2 정보 및 상기 제3 정 보를 통해 작성된 3차원 지도와 미지 영역 탐사 알고리즘을 기반으로 한 장애물 회피 경로에 따라 비행 움직임 을 제어하는 제어부를 포함한다. 또한, 상기 드론 유닛은 드론 프레임, 상기 드론 프레임의 중심부에 위치하며, 상기 카메라, 상기 라이다 및 상 기 관성 측정 장치, 상기 메모리 및 상기 제어부가 구비된 본체, 상기 드론 프레임과 연결되며, 상기 본체를 중 심으로 사각형 형태를 나타내는 결합식 프로펠러 가드, 상기 드론 프레임의 네 개의 각 암(arm)에 하방으로 부 착되어 비행을 위한 추력을 발생시키는 프로펠러 및 상기 결합식 프로펠러 가드의 각 모서리 하단에 결합되는 랜딩기어를 포함할 수 있다. 본 발명의 실시예에 따른 무인 탐사 및 정찰을 위한 드론 유닛의 자율 비행 시스템에 의한 자율 비행 방법에 있 어서, 드론 유닛에 장착된 카메라를 통해 제1 정보를 획득하고, 라이다(LiDAR)를 통해 제2 정보를 획득하며, 관 성 측정 장치(IMU)를 통해 제3 정보를 획득하는 단계, 상기 제2 정보 및 상기 제3 정보를 통해 상기 드론 유닛 의 위치를 추정하고, 상기 제1 정보 및 상기 제2 정보를 통해 대상 물체의 좌표 값을 획득하며, 상기 드론 유닛 의 위치 추정 값과 상기 대상 물체의 좌표 값, 및 상기 제2 정보를 기반으로 3차원 지도와 미지 영역 탐사 알고 리즘을 구축하는, 정보를 처리하는 단계, 상기 3차원 지도와 상기 미지 영역 탐사 알고리즘을 기반으로 한 장애 물 회피 경로를 생성하는 단계 및 상기 장애물 회피 경로를 상기 드론 유닛에 적용하는 단계를 포함한다."}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 미지의 환경에서 드론 유닛이 자율적으로 비행하여 목표물의 좌표를 포함한 정밀한 3차원 지도를 획득 후 안전하게 출발점으로 복귀하는 탐사 혹은 정찰 임무를 수행할 수 있다. 본 발명의 실시예에 따르면, 드론 유닛에 탄성 소재를 활용한 결합식 프로펠러 가드를 사용함으로써, 무게와 공 기 흐름을 막는 영역을 최소화하고, 불가피한 충돌에 탄력적으로 충격을 흡수하여 안정적인 비행 유지가 가능하 다. 본 발명의 실시예에 따르면, 드론 유닛은 드론 프레임에 랜딩기어가 결합되고, 랜딩기어에 결합식 프로펠러 가 드가 결합되는 구조를 가지며, 드론 프레임의 네 개의 각 암(arm)에 프로펠러가 하방으로 부착됨으로써, 랜딩기 어가 프로펠러를 가리는 영역을 최소화하여 추력 효율 및 비행시간을 극대화할 수 있다."}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "다만, 본 발명의 효과는 상기 효과들로 한정되는 것은 아니며, 본 발명의 기술적 사상 및 영역으로부터 벗어나 지 않는 범위에서 다양하게 확장될 수 있다."}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하"}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며, 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소, 단계, 동작 및/또는 소자는 하나 이상의 다 른 구성요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적 으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하 게 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예들을 보다 상세하게 설명하고자 한다. 도면 상의 동일한 구성요소에 대해서는 동일한 참조 부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 본 발명은 무인 탐사 및 정찰을 위한 자율 비행 드론 유닛과 위치 추정, 물체 인식, 경로 생성 및 미지 영역 탐 사를 포함한 자율 비행 프레임워크를 제안하는 것을 그 요지로 한다. 본 발명의 실시예에 따르면, 드론 유닛의 위치 추정의 오차를 보정하되, 갑작스러운 위치의 변화를 방지하기 위 해 루프 클로징(loop-closing) 방식을 사용하지 않고, 이동 목표 지점의 좌표에 위치 추정의 오차를 곱하는 방 식을 사용한다. 또한, 본 발명의 실시예에 따르면, 광선 투사(Ray-casting)을 활용하여 2단계로 장애물과 충돌을 회피하는 경로 를 생성하고, 라이다(LiDAR)와 카메라의 센서 융합을 통해 정확한 목표물의 좌표 획득 및 이를 포함한 정밀한 3 차원 지도를 획득하는 것을 특징으로 한다. 이하에서는 도 1 내지 도 12를 참조하여 본 발명에 대해 상세히 설명한다. 도 1은 본 발명의 실시예에 따른 드론 유닛의 자율 비행 시스템의 세부 구성을 블록도로 도시한 것이다. 또한, 도 6은 본 발명의 실시예에 따른 목표물의 좌표 혹은 표적의 좌표 획득 알고리즘에 의한 결과 이미지를 도시한 것이고, 도 7은 본 발명의 실시예에 따른 위치 추정 알고리즘에 의한 결과 이미지를 도시한 것이며, 도 8은 본 발명의 실시예에 따른 미지 영역 탐사 알고리즘에 의한 결과 이미지를 도시한 것이고, 도 9는 본 발명의 실시예 에 따른 경로 생성 알고리즘에 의한 결과 이미지를 도시한 것이다. 여기서, 도 7은 본 발명의 실시예에 따른 위치 추정 알고리즘 중에서도 위치 추정 오차가 보정되는 장면에 대한 이미지를 도시한 것이다. 도 1의 본 발명의 실시예에 따른 드론 유닛의 자율 비행 시스템은 무인 탐사 및 정찰을 위한 자율 비행 드론 유 닛과 위치 추정, 물체 인식, 경로 생성 및 미지 영역 탐사를 포함한 자율 비행 프레임워크를 제공한다. 이를 위해, 본 발명의 실시예에 따른 드론 유닛의 자율 비행 시스템은 정보 획득부, 정보 처리부 , 경로 생성부 및 비행 제어부를 포함한다. 본 발명의 실시예에 따른 드론 유닛은 카메라, 라이다(Light Detection And Ranging, LiDAR), 관성 측정 장치(Inertial Measurement Unit, IMU)를 포함할 수 있다. 이에, 정보 획득부는 드론 유닛에 장착 된 카메라를 통해 제1 정보를 획득하고, 라이다(LiDAR)를 통해 제2 정보를 획득하며, 관성 측정 장치(IMU)를 통 해 제3 정보를 획득한다. 정보 획득부는 카메라를 통해 대상 물체 인식에 관한 제1 정보를 획득하고, 라 이다를 통해 드론 유닛의 위치 추정 및 지도 생성을 위한 제2 정보를 획득하며, 관성 측정 장치를 통해 드론 유 닛의 실시간 각속도 및 가속도 정보에 관한 제3 정보를 획득할 수 있다. 여기서, 카메라는 CMOS, CCD(Charge Coupled Device) 이미지 센서 등을 이용하여 영상을 촬영하며, 영상 데이터 및 무인체의 오도메트리(Visual odometry) 데이터를 획득할 수 있다. 라이다(LiDAR)는 레이저 펄스를 반사체(또는 대상 물체)에 조사하고, 반사체로부터 반사되어 돌아오는 시간을 측정하여 반사체의 위치 좌표를 측정하는 레이더 시스템일 수 있다. 공지된 바와 같이, 라이다는 반사 강도로 부터 측정 및 연산한 위치 좌표를 측정 데이터로 저장하며, 측정 데이터는 3D 그래프 구조를 이미지화하기 위한"}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "기초 정보로 활용될 수 있다. 이 때, 라이다(LiDAR)는 해당 기술분야에서 이미 널리 사용되고 있는 장치이므로, 그 주와 동작원리에 대해서는 설명을 생략한다. 관성 측정 장치(IMU)는 자이로 센서(자이로스코프)에서 각속도, 즉 회전하는 속도를 측정하고, 가속도계 (accelerometer)에서 (가속도 = 선가속도 + 중력가속도), 즉 실제 드론 유닛의 순수한 가속력 값과 중력 방향에 대해 얼마나 기울어져 있는지 자세 정보가 합쳐진 값을 측정한다. 예를 들면, IMU는 무인체의 회전각으로서 전 진방향(Roll축 방향), 전진방향의 우측방향(Pitch축 방향), 중력방향(Yaw축 방향) 각각의 각속도 중분치 등의 자세 관련 센서 데이터를 생성하고, 가속도 센서를 이용하여 무인체 속도 중분치 등의 가속도 관련 센서 데이터 를 생성할 수 있다. 가속도 센서는 무인체의 속도 중분치와 중력 가속도를 포함하는 값이 측정되는 가속도 관 련 센서이다. 정보 처리부는 드론 유닛의 카메라, 라이다 및 관성 측정 장치로부터 획득된 제1 정보, 제2 정보 및 제3 정보를 이용하여 위치 추정 알고리즘, 좌표 획득 알고리즘 및 미지 영역 탐사 알고리즘을 처리한다. 보다 구체적으로, 정보 처리부는 제2 정보 및 제3 정보를 통해 드론 유닛의 위치를 추정하고, 제1 정보 및 제2 정보를 통해 대상 물체(또는 표적)의 좌표 값을 획득하며, 드론 유닛의 위치 추정 값과 대상 물체의 좌표 값, 및 제2 정보를 기반으로 3차원 지도와 미지 영역 탐사 알고리즘을 구축한다. 정보 처리부는 라이다 (LiDAR)에서 스캔하는 제2 정보와 드론의 위치 값으로 장애물 지도를 작성하고, 장애물 지도에 대상 물체의 좌 표 값을 포함하여 3차원 지도를 생성한다. 정보 처리부는 센서 융합을 통해 정확한 목표물(대상 물체 또는 표적)의 좌표를 획득하는 좌표 획득 알고 리즘을 처리한다. 보다 상세하게, 정보 처리부는 제1 정보를 통해 목표물인 표적(또는 대상 물체)를 인식 하며, 제1 정보와 제2 정보로부터 대상 물체의 좌표를 산출하여 대상 물체의 좌표 값을 획득할 수 있다. 도 6 을 참조하여 설명하자면, 정보 처리부는 TensorRT로 가속화한 YOLOv4 인공지능 학습망을 이용하여 표적 을 검출하고 표적의 2차원 좌표를 획득하며(도 6(a)), 도 6(b)에 도시된 바와 같이, 표적의 3차원 좌표를 획득할 수 있다. 정보 처리부는 라이다(LiDAR)의 거리 정보와 표적의 2차원 좌표를 매칭하여 정확한 3차 원 표적 좌표를 계산할 수 있으며, 특이치 필터(Outlier filter), 클러스터링(clustering), 공분산 필터 (covariance filter) 처리 및 표적의 중점 좌표를 복셀(voxel)로 관리할 수 있다. 또한, 정보 처리부는 도 6(c)에 도시된 바와 같이, 표적의 종류에 따라 3차원 지도 상에 각기 다른 색깔의 마커(marker)로 나타내는 것을 특징으로 한다. 상기 마커(marker)는 구 또는 사각형과 같은 모형으로 나타낼 수 있으며, 2차원 및 3차원 으로 표현이 가능하다. 또한, 표적의 종류에 따라 다른 마커로 표현되며, 색상 또한 다르게 표현 가능하다. 정보 처리부는 실시간으로 위치를 추정하고, 위치 추정 오차를 보정해서 목표 지점을 수정하며, 출발점으 로 드론 유닛을 안전하게 복귀하는 위치 추정 알고리즘을 처리한다. 보다 상세하게, 정보 처리부는 제2 정보, 제3 정보, 및 3차원 지도를 이용하여 드론 유닛의 위치를 추정하고, 위치 추정 오차를 보정하여 드론 유 닛의 목표 지점을 수정할 수 있다. 정보 처리부는 Fast-LIO2 기술을 사용하여 제2 정보, 제3 정보, 및 3 차원 지도로부터 드론 유닛의 실시간 위치를 추정할 수 있다. 이 때, 본 발명의 실시예에 따른 드론 유닛의 자 율 비행 시스템은 드론 유닛이 건물과 같은 실내에 입장하기 직전에 주변의 맵(map, 도 7에서 초록색을 제 외한 컬러)을 저장하며, 퇴장 직후에 라이다(LiDAR)로 스캔한 데이터와 주변의 맵을 매칭(도 7에서 초록색)하여 드리프트(drift, 누적된 위치 추정의 오차)를 계산하며, 드리프트의 역수를 목표 지점의 좌표에 곱함으로써, 드 론 유닛이 출발점에 정확하게 도착 가능하도록 알고리즘을 처리할 수 있다. 도 7에서 초록색을 제외한 컬러는드론 유닛이 실내 입장 직전에 저장한 주변 맵을 나타내고, 초록색은 실내 퇴장 직후에 라이다(LiDAR)로 스캔한 데이터와 저장한 맵을 매칭(matching)한 모습을 나타낸다. 이에 따라서, 정보 처리부는 키프레임(Keyframe)을 모두 저장하고, 이를 매칭하는 루프 클로징(loop- closing) 방식과 다르게 연산량이 적고, 위치 추정 값이 불안정한 현상 예를 들면, 드론의 경우, 위치 추정 값 이 불안정(갑자기 튀는 현상)하게 되면 비행이 불안정한 문제가 발생하는 현상을 방지할 수 있다. 정보 처리부는 지역적 탐색 구간(local horizon)을 활용한 미지 영역 탐사 알고리즘을 처리한다. 보다 상 세하게, 정보 처리부는 대상 물체의 좌표 값과 제2 정보, 그리고 드론 유닛의 위치 추정 값을 이용하여 3 차원 지도를 작성하며, 3차원 지도와 제2 정보 및 제3 정보로부터 드론 유닛의 실시간 위치를 추정하고, 해당 위치 추정 값으로 미지 영역 탐사 알고리즘을 처리할 수 있다. 이 때, 정보 처리부는 점유 격자지도 (Occupancy grid map)를 이용하여 프런티어(frontier) 영역을 검출하며, 지역적 탐색 구간(local horizon) 영 역 내의 프런티어(frontier) 영역들 중에서 가장 멀고, 덩어리(cluster)의 크기가 큰 프런티어 영역을 최적의 프런티어로 선택하여 이동하는 과정을 반복하는 미지 영역 탐사 알고리즘을 처리하여 탐사 효율을 극대화할 수 있다. 상기 프런티어 영역은 미지 영역과 인접한 자유 영역을 나타내는 것으로, 예를 들어 문(door)을 나타낼 수 있다. 이에, 프런티어의 gain 함수는 하기의 [수학식 1]과 같다. [수학식 1]"}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, x는 프런티어(frontier)의 중심 좌표를 나타내고, o은 드론 유닛의 현재 좌표를 나타내며, S(x)는 프런 티어 클러스터(frontier cluster)의 크기를 나타내고, 는 프런티어의 gain을 나타낸다. 도 8을 참조하면, 도 8(a)에서 초록색 영역은 실내 공간에서의 프런티어(frontier)를 나타내고, 흰색 구 (sphere)는 프런티어 덩어리의 중심점을 나타낸다. 또한, 도 8(b)에서 하늘색 박스는 지역적 탐색 구간(local horizon) 영역을 나타내고, 파란색 직육면체는 지역적 탐색 구간 내의 최적의 프런티어를 나타낸다. 이에 따라 서, 기존의 프런티어를 기반으로 한 탐사 방법은 전체 맵 중 가장 가까운 프런티어로 이동하는 것을 단순 반복 하여 불필요한 움직임이 많으나, 본 발명의 실시예에 따른 드론 유닛의 자율 비행 시스템은 지역적 탐색 구간(local horizon) 영역 내의 프런티어(frontier) 영역들 중에서 가장 멀고, 덩어리(cluster)의 크기가 큰 프런티어 영역을 최적의 프런티어로 선택하여 이동하는 과정을 반복하는 미지 영역 탐사 알고리즘을 처리하여 탐사 효율을 극대화할 수 있음을 확인할 수 있다. 도 1에서 경로 생성부는 3차원 지도와 미지 영역 탐사 알고리즘을 기반으로 한 장애물 회피 경로를 생성한 다. 경로 생성부는 2단계로 좁은 영역에서 안전하게 장애물을 회피하는 경로 생성 알고리즘을 사용하여 경로를 생성할 수 있다. 보다 상세하게, 경로 생성부는 3차원 지도와 미지 영역 탐사 알고리즘을 기반으 로 샘플링(sampling) 기반의 최단 거리를 탐색하고, 좁은 영역에서 장애물을 회피하도록 경로를 수정하는 경로 생성 알고리즘을 이용하여 장애물 회피 경로를 생성할 수 있다. 제1 단계로 경로 생성부는 Informed-RRT# 방식을 이용하여 샘플링(sampling) 기반의 최단거리를 탐색할 수 있다. 이 때, Informed 방식은 최초 경로 생성 후, 샘플링(sampling) 영역을 조절하여 최적 값으로 수렴을 더 빠르게 해주는 방식을 나타내고, RRT# 방식은 유사 최적 트리(pseudo-optimal tree)를 계속 유지하며 코스트 (cost)가 개선되는 모든 엣지(edge)에 대해 리와이어(rewire) 진행하여 수렴을 더 빠르게 해주는 방식을 나타낸 다. 이에, 경로 생성부는 전술한 두 방식을 결합한 Informed-RRT# 방식으로 1차 최단거리를 탐색하는 것 을 특징으로 한다. 제1 단계에서는 장애물과의 충돌을 고려하긴 하나 최소 안전 반경만을 고려하고, 최단 거리 를 우선으로 하므로 장애물이나 벽에 붙어서 경로가 생성된다. 제2 단계로 경로 생성부는 안전한 경로로 경로를 수정할 수 있다. 경로 생성부는 Informed-RRT# 방 식의 결과에서 경로 상의 점들에 전 방향 광선 투사(ray-casting)을 수행해서 모든 방향에 대해 장애물까지의 거리를 탐지하고, 안전한 영역 내의 중점으로 경로를 변경한다. 이에 따라서, 도 9(a)를 살펴보면, 주황색은 제1 단계의 Informed-RRT# 결과를 나타내고, 옥색은 제2 단계의 더 안전한 경로 결과를 나타내며, 자주색은 전 방향 광선 투사(ray-casting)를 수행한 결과를 나타내는 것을 확인할 수 있다. 이에 따라서 도 9(b)에 도시된바와 같이, 드론 유닛이 약 70cm 폭의 좁은 문을 통과할 수 있게 된다. 도 1을 참조하면, 비행 제어부는 장애물 회피 경로를 드론 유닛에 적용한다. 비행 제어부는 경 로 생성부에 의해 생성된 장애물 회피 경로에 따라 드론 유닛의 비행 움직임을 제어할 수 있다. 도 2는 본 발명의 실시예에 따른 드론 유닛의 사시도를 도시한 것이고, 도 3은 본 발명의 실시예에 따른 드론 유닛의 평면도를 도시한 것이다. 또한, 도 4는 본 발명의 실시예에 따른 드론 프레임 및 결합식 프로펠러 가드 와 랜딩기어의 평면도를 도시한 것이고, 도 5는 본 발명의 실시예에 따른 드론 프레임에 결합식 프로펠러 가드 와 랜딩기어를 차례로 결합하는 과정을 도시한 것이다. 본 발명의 실시예에 따른 드론 유닛은 추력 효율, 무게, 크기, 충돌에 강인함을 고려한 새로운 형상을 나 타내는 것을 특징으로 한다. 도 2 내지 도 5를 참조하면, 드론 유닛은 드론 프레임과 결합식 프로펠러 가드 및 랜딩기어 로 전체 면적의 기본 구조를 가지며, 결합식 프로펠러 가드의 중앙인 드론 프레임에 본체가 위 치한다. 이 때, 드론 프레임은 도 5에 도시된 검은 카본 전체 영역 중 결합식 프로펠러 가드와 랜딩 기어를 제외한 부분을 나타내는 것을 특징으로 하며, 상기 본체가 부착 및 고정된다. 여기서, 드론 유닛 의 드론 프레임에 결합된 결합식 프로펠러 가드 및 랜딩기어는 본체를 중심으로 사각형 형 태를 나타내며, 가로, 세로 및 높이가 약 41 × 41 × 24.5cm 이다. 이는 일반적인 실내 환경의 가장 좁은 문 의 폭이 70cm 인 것을 감안하여 제작된 것으로, 가장 좁은 문도 통과할 수 있다. 드론 유닛의 본체에는 초소형 카메라, 3D 라이다(LiDAR, 220), 비행제어장치(또는 제어부, 230), 드 론용 온보드 PC를 포함하며, PC용 6Cell LiPo 배터리 1300mAh 및 모터용 6Cell LiPo 배터리 5200mAh를 포함한다. 도 2 및 도 3에는 도시되지 않았으나, 드론 유닛의 본체에는 관성 측정 장치 (IMU, 미도시)가 포함되며, 명령어를 저장하는 메모리가 포함될 수 있다. 카메라는 정확한 표적 탐지를 위한 제1 정보를 획득하는 것으로 초소형 글로벌 셔터(global shutter) 카메 라이며, 3D 라이다는 정밀한 위치 추정과 장애물 탐지를 위한 제2 정보를 획득하고, 관성 측정 장치(미도 시)는 제3 정보를 획득한다. 또한, 비행제어장치는 적어도 하나의 명령어를 실행하여, 제1 정보, 제2 정보 및 제3 정보를 통해 작성된 3차원 지도와 미지 영역 탐사 알고리즘을 기반으로 한 장애물 회피 경로에 따 라 비행 움직임을 제어한다. 드론 유닛은 본 발명의 실시예에 따른 드론 유닛의 자율 비행 시스템에 의한 알고리즘 처리로 인한 명령어에 따라 비행할 수 있다. 이 때, 드론 유닛은 PC용 6Cell LiPo 배터리 1300mAh 및 모터용 6Cell LiPo 배터리 5200mAh 2개를 포함한 무게가 2.317kg이며, 최대 비행 시간은 약 12분이다. 드론 유닛의 결합식 프로펠러 가드는 본체를 중심으로 사각형 형태를 나타내며, 사각형 형태의 네 측 면 각각의 중앙에 탄성 소재를 결합하여 드론 유닛의 충격을 흡수할 수 있다. 탄성 소재를 활용한 결합식 프로펠러 가드는 무게와 공기 흐름을 막는 영역을 최소화하며 불가피한 충돌에 탄력적으로 충격을 흡수하여 안정적인 드론 유닛의 비행 유지를 가능하게 한다. 또한, 드론 유닛의 드론 프레임에 랜딩기어가 결합되고, 랜딩기어에 결합식 프로펠러 가드 가 결합되는 구조를 가지며, 긴 비행 시간을 위해 드론 프레임의 네 개의 각 암(arm)에 하방으로 부 착되어 비행을 위한 추력 효율을 극대화하는 네 개의 프로펠러를 포함한다. 드론 유닛은 하방에 부 착된 프로펠러를 포함하고, 랜딩기어가 프로펠러를 가리는 영역을 최소화하여 추력 효율 및 비행시간 을 극대화할 수 있다. 도 4를 참조하면, 드론 유닛의 드론 프레임은 각 모서리 하단에 랜딩기어가 결합되고, 랜딩기어(20 4)에 결합식 프로펠러 가드가 결합된다. 도 5(a) 및 도 5(b)를 살펴보면, 드론 프레임의 네 개의 모 서리 각 하단에 랜딩기어가 결합된다. 이후에, 도 5(c)에서 드론 프레임에 결합된 랜딩기어 중 간 부근에 교차 형태로 결합식 프로펠러 가드가 결합된다. 이에 따라서, 랜딩기어는 결합식 프로펠 러 가드의 모서리 하단에 위치하고, 결합식 프로펠러 가드의 중앙부가 지면과 일정 거리 이상 이격되 어 형성되도록 함으로써, 드론 프레임의 네 개의 각 암(arm)에 하방으로 부착되는 프로펠러를 가리는 영역 을 최소화하여 드론 유닛의 추력 효율과 비행시간을 극대화할 수 있게 한다.도 10 및 도 11은 본 발명의 실시예에 따른 드론 유닛 및 드론 유닛의 자율 비행 시스템을 이용한 실험 결과를 도시한 것이다. 도 10은 본 발명의 실시예에 따른 드론 유닛이 임무를 수행 및 검증하는 환경을 나타낸 것이고, 도 11은 본 발 명의 실시예에 따른 드론 유닛의 자율 비행 시스템으로 작성한 정밀 3차원 지도를 나타낸 것이다. 본 발명의 실시예에 따른 드론 유닛은 약 50 × 30 × 7m3의 장애물과 건물 복합 전장 상황 모사 환경에서 무인 정찰 및 탐사하여 정밀한 3차원 지도를 작성하고, 원점으로 복귀하는 임무 수행 및 검증하였다. 검증 환경에서 본 발명의 실시예에 따른 드론 유닛은 도 10에 도시된 환경에서 충돌 없이 모든 코스를 완전 자율 비행으로 무 인 정찰 및 탐사하여 도 11에 도시된 바와 같은 정밀한 3차원 지도를 작성하였고, 원점으로 복귀하는 임무를 완 수하였다. 도 12는 본 발명의 실시예에 따른 드론 유닛의 자율 비행 방법의 동작 흐름도를 도시한 것이다. 도 12의 본 발명의 실시예에 따른 드론 유닛의 자율 비행 방법은 도 1에 도시된 본 발명의 실시예에 따른 드론 유닛의 자율 비행 시스템에 의해 수행된다. 도 12를 참조하면, 단계 S1210에서, 드론 유닛에 장착된 카메라를 통해 제1 정보를 획득하고, 라이다(LiDAR)를 통해 제2 정보를 획득하며, 관성 측정 장치(IMU)를 통해 제3 정보를 획득한다. 단계 S1210은 카메라를 통해 대 상 물체 인식에 관한 제1 정보를 획득하고, 라이다를 통해 드론 유닛의 위치 추정 및 지도 생성을 위한 제2 정 보를 획득하며, 관성 측정 장치를 통해 드론 유닛의 실시간 각속도 및 가속도 정보에 관한 제3 정보를 획득할 수 있다. 단계 S1220에서, 드론 유닛의 카메라, 라이다 및 관성 측정 장치로부터 획득된 제1 정보, 제2 정보 및 제3 정보 를 이용하여 위치 추정 알고리즘, 좌표 획득 알고리즘 및 미지 영역 탐사 알고리즘을 처리한다. 보다 구체적으 로, 단계 S1220은 제2 정보 및 제3 정보를 통해 드론 유닛의 위치를 추정하고, 제1 정보 및 제2 정보를 통해 대 상 물체(또는 표적)의 좌표 값을 획득하며, 드론 유닛의 위치 추정 값과 대상 물체의 좌표 값, 및 제2 정보를 기반으로 3차원 지도와 미지 영역 탐사 알고리즘을 구축한다. 단계 S1220은 라이다(LiDAR)에서 스캔하는 제2 정보와 드론의 위치 값으로 장애물 지도를 작성하고, 장애물 지도에 대상 물체의 좌표 값을 포함하여 3차원 지 도를 생성한다. 단계 S1220은 센서 융합을 통해 정확한 목표물(대상 물체 또는 표적)의 좌표를 획득하는 좌표 획득 알고리즘을 처리한다. 보다 상세하게, 단계 S1220은 제1 정보를 통해 목표물인 표적(또는 대상 물체)를 인식하며, 제1 정 보와 제2 정보로부터 대상 물체의 좌표를 산출하여 대상 물체의 좌표 값을 획득할 수 있다. 단계 S1220은 TensorRT로 가속화한 YOLOv4 인공지능 학습망을 이용하여 표적을 검출하고 2차원 좌표를 획득할 수 있다. 단계 S1220은 라이다(LiDAR)의 거리 정보와 2차원 좌표를 매칭하여 정확한 3차원 표적 좌표를 계산할 수 있으며, 특 이치 필터(Outlier filter), 클러스터링(clustering), 공분산 필터(covariance filter) 처리 및 표적의 중점 좌표를 복셀(voxel)로 관리할 수 있다. 또한, 단계 S1220은 표적의 종류에 따라 3차원 지도 상에 각기 다른 색 깔의 마커(marker)로 나타내는 것을 특징으로 한다. 상기 마커(marker)는 구 또는 사각형과 같은 모형으로 나 타낼 수 있으며, 2차원 및 3차원으로 표현이 가능하다. 또한, 표적의 종류에 따라 다른 마커로 표현되며, 색상 또한 다르게 표현 가능하다. 단계 S1220은 실시간으로 위치를 추정하고, 위치 추정 오차를 보정해서 목표 지점을 수정하며, 출발점으로 드론 유닛을 안전하게 복귀하는 위치 추정 알고리즘을 처리한다. 보다 상세하게, 단계 S1220은 제2 정보, 제3 정보, 및 3차원 지도를 이용하여 드론 유닛의 위치를 추정하고, 위치 추정 오차를 보정하여 드론 유닛의 목표 지점을 수정할 수 있다. 단계 S1220은 Fast-LIO2 기술을 사용하여 제2 정보, 제3 정보, 및 3차원 지도로부터 드론 유 닛의 실시간 위치를 추정할 수 있다. 이 때, 본 발명의 실시예에 따른 드론 유닛의 자율 비행 방법은 드론 유 닛이 건물과 같은 실내에 입장하기 직전에 주변의 맵을 저장하며, 단계 S1220은 퇴장 직후에 라이다(LiDAR)로 스캔한 데이터와 주변의 맵을 매칭하여 드리프트(drift, 누적된 위치 추정의 오차)를 계산하며, 드리프트의 역 수를 목표 지점의 좌표에 곱함으로써, 드론 유닛이 출발점에 정확하게 도착 가능하도록 알고리즘을 처리할 수 있다. 단계 S1220은 지역적 탐색 구간(local horizon)을 활용한 미지 영역 탐사 알고리즘을 처리한다. 보다 상세하게, 단계 S1220은 대상 물체의 좌표 값과 제2 정보, 그리고 드론 유닛의 위치 추정 값을 이용하여 3차원지도를 작성하며, 3차원 지도와 제2 정보 및 제 정보로부터 드론 유닛의 실시간 위치를 추정하고, 해당 위치 추 정 값으로 미지 영역 탐사 알고리즘을 처리할 수 있다. 이 때, 단계 S1220은 점유 격자지도(Occupancy grid map)를 이용하여 프런티어(frontier) 영역을 검출하며, 지역적 탐색 구간(local horizon) 영역 내의 프런티어 (frontier) 영역들 중에서 가장 멀고, 덩어리(cluster)의 크기가 큰 프런티어 영역을 최적의 프런티어로 선택하 여 이동하는 과정을 반복하는 미지 영역 탐사 알고리즘을 처리하여 탐사 효율을 극대화할 수 있다. 상기 프런 티어 영역은 미지 영역과 인접한 자유 영역을 나타내는 것으로, 예를 들어 문(door)을 나타낼 수 있다. 단계 S1230에서, 3차원 지도와 미지 영역 탐사 알고리즘을 기반으로 한 장애물 회피 경로를 생성한다. 단계 S1230은 2단계로 좁은 영역에서 안전하게 장애물을 회피하는 경로 생성 알고리즘을 사용하여 경로를 생성할 수 있다. 보다 상세하게, 단계 S1230은 3차원 지도와 미지 영역 탐사 알고리즘을 기반으로 샘플링(sampling) 기반 의 최단 거리를 탐색하고, 좁은 영역에서 장애물을 회피하도록 경로를 수정하는 경로 생성 알고리즘을 이용하여 장애물 회피 경로를 생성할 수 있다. 제1 단계로 단계 S1230은 Informed-RRT# 방식을 이용하여 샘플링(sampling) 기반의 최단거리를 탐색할 수 있다. 이 때, Informed 방식은 최초 경로 생성 후, 샘플링(sampling) 영역을 조절하여 최적 값으로 수렴을 더 빠르게 해주는 방식을 나타내고, RRT# 방식은 유사 최적 트리(pseudo-optimal tree)를 계속 유지하며 코스트(cost)가 개선되는 모든 엣지(edge)에 대해 리와이어(rewire) 진행하여 수렴을 더 빠르게 해주는 방식을 나타낸다. 이에, 단계 S1230은 전술한 두 방식을 결합한 Informed-RRT# 방식으로 1차 최단거리를 탐색하는 것을 특징으로 한다. 제1 단계에서는 장애물과의 충돌을 고려하긴 하나 최소 안전 반경만을 고려하고, 최단 거리를 우선으로 하므로 장애물이나 벽에 붙어서 경로가 생성된다. 제2 단계로 단계 S1230은 안전한 경로로 경로를 수정할 수 있다. 단계 S1230은 Informed-RRT# 방식의 결과에서 경로 상의 점들에 전 방향 광선 투사(ray-casting)을 수행해서 모든 방향에 대해 장애물까지의 거리를 탐지하고, 안전한 영역 내의 중점으로 경로를 변경한다. 단계 S1240에서, 장애물 회피 경로를 드론 유닛에 적용한다. 단계 S1240은 단계 S1230에 의해 생성된 장애물 회피 경로에 따라 드론 유닛의 비행 움직임을 제어할 수 있다. 이상에서 설명된 시스템 또는 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(Field Programmable Gate Array), PLU(programmable logic unit), 마이크로프로세서, 또 는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특 수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는"}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2023-0144324", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2023-0144324", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 드론 유닛의 자율 비행 시스템의 세부 구성을 블록도로 도시한 것이다. 도 2는 본 발명의 실시예에 따른 드론 유닛의 사시도를 도시한 것이다. 도 3은 본 발명의 실시예에 따른 드론 유닛의 평면도를 도시한 것이다. 도 4는 본 발명의 실시예에 따른 드론 프레임 및 결합식 프로펠러 가드와 랜딩기어의 평면도를 도시한 것이다. 도 5는 본 발명의 실시예에 따른 드론 프레임에 결합식 프로펠러 가드와 랜딩기어를 차례로 결합하는 과정을 도 시한 것이다. 도 6은 본 발명의 실시예에 따른 목표물의 좌표 혹은 표적의 좌표 획득 알고리즘에 의한 결과 이미지를 도시한 것이다.도 7은 본 발명의 실시예에 따른 위치 추정 알고리즘에 의한 결과 이미지를 도시한 것이다. 도 8은 본 발명의 실시예에 따른 미지 영역 탐사 알고리즘에 의한 결과 이미지를 도시한 것이다. 도 9는 본 발명의 실시예에 따른 경로 생성 알고리즘에 의한 결과 이미지를 도시한 것이다. 도 10 및 도 11은 본 발명의 실시예에 따른 드론 유닛 및 드론 유닛의 자율 비행 시스템을 이용한 실험 결과를 도시한 것이다. 도 12는 본 발명의 실시예에 따른 드론 유닛의 자율 비행 방법의 동작 흐름도를 도시한 것이다."}
