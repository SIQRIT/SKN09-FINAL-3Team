{"patent_id": "10-2020-0128617", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0046023", "출원번호": "10-2020-0128617", "발명의 명칭": "인공지능", "출원인": "주식회사 인포쉐어", "발명자": "전승준"}}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "자살고위험군 면담자의 행동을 촬영하여 유효데이터를 획득하기 위한 3D 카메라가 설치된 서브컴퓨터를 포함하는 정보획득장치(110) 및 정보획득장치(110)와 무선 또는 유선으로 연결되어 입력되는 영상에 따른 유효데이터를 저장하는 계측서버(120)를 포함하는 계측장치(100)와;상기 계측장치(100)와 유선 또는 무선으로 연결되어 인가되는 유효데이터를 기준으로 얼굴, 표정, 행동에 따른각각의 데이터를 분리하여 분석모듈(200)과;상기 분석모듈(200)로부터 인가되는 분리된 이미지를 기 저장된 표준화데이터에 매칭시켜 면담자의 심리상태를분석 및 결과를 표출하는 분석서버(300);를 포함하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템."}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 분석모듈(200)은,흑백 영역에 대한 픽셀값의 평균차에 의한 임계치 구분에 의해 특징을 판단, 파악하는 얼굴분석모듈(210);특정 근육의 활동 상태를 분석하기 위하여 액션유닛(Action Units)으로 이루어지는 동작인식모듈(220)과;음성에서 특징을 추출하고, 추출된 최솟값(Minimum pitch(Hz))과 최댓값(Maximum pitch(Hz))을 지정하며, 지정된 음성파형 내에서 12개의 특징을 추출하는 음성인식모듈(230);을 포함하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템."}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 얼굴분석모듈(210)은,흰색 부분 영상 픽셀들의 밝기 합에서 검은색 부분의 밝기 합을 뺀 차로 계산되며, 영상 및 이미지 검색 시에이 값이 특징(feature)에 부여된 임계치 보다 큰지 작은지에 따라 파악하고자 하는 대상물체라고 추측하는 것을특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템."}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 동작인식모듈(220)은, 이마아래, 입술 끝 당김, 입술 끝 아래, 입술 다뭄, 입술 빨음, 눈 깜빡임을 포함하는 발생유무 상태와,이마 중심 올림, 이마 외부 올림, 이마 아래, 눈꺼풀 위로, 볼 위, 코 찡그림, 윗 입술 위, 입술 끝 당김, 보조개, 입술 끝 아래, 아래턱 위, 입술 늘림, 입술 나뉨, 턱 아래를 포함하는 발생 정도 상태를 인식하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템."}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 음성파형 내에서 12개의 특징 추출은, 음성파형의 고저, 기울기, 파형의 고저 변화수 특징 추출, 측정초당 음절수, CID 비율, 발화당 음정수, 발화당공개특허 10-2022-0046023-3-단어수, 발화당 내용어수, 음소착어, 의미착어, 후속발화 개시시간, 도치어, 간투사, 반복어, 수정어인 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템."}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 분석서버(300)는, 분석모듈(200)로부터 공급되는 유효데이터를 기준으로 감정에 대한 시간변화에 따른 그래프 형태의 이력제공,이력에 따른 감정별 해당 동영상 연동 제공 및 해동인식 분석에 따른 분서데이터를 제공하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템."}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "계측장치(100)로부터 입력되는 영상 또는 이미지를 통해 얼굴표정, 머리 및 손의 움직임을 감지하여 모션을 감지하여 영상 또는 이미지를 획득하고, 음성에서 최솟값과 최댓값의 파형을 검출하는 모션감지 및 음성인식단계(S10)와; 모션감지 및 음성인식단계(S10)를 통해 인가되는 유효데이터에서 특정 영역을 추출하여 면담자의 감정상태를 파악하고, 음성파형에서 특징을 추출하는 특정영역, 음성특징추출단계(S20); 및특정영역, 음성특징추출단계(S20)를 통해 인가되는 영역데이터를 기준으로 기 저장된 표준화데이터에 매칭시켜면전자의 심리를 판단, 분석하는 분석단계(S30);를 포함하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법."}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 모션감지 및 음성인식단계(S10)는, 계측장치의 3D 카메라를 통해 이마아래, 입술 끝 당김, 입술 끝 아래, 입술 다뭄, 입술 빨음, 눈 깜빡임을 포함하는 발생유무 상태와,이마 중심 올림, 이마 외부 올림, 이마 아래, 눈꺼풀 위로, 볼 위, 코 찡그림, 윗 입술 위, 입술 끝 당김, 보조개, 입술 끝 아래, 아래턱 위, 입술 늘림, 입술 나뉨, 턱 아래를 포함하는 발생 정도 상태를 인식하고, 입력된음성에서 최솟값과 최댓값에 따른 음성파형을 계측서버에 저장하는 것을 특징으로 하는 인공지능(AI) 기반 영상및 음성정보를 활용한 자살고위험군 조기선별방법."}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 특정영역, 음성특징추출단계(S20)는, 얼굴이 정면을 향하도록 변형하기 위하여 눈 검출을 이용하여 두 눈이 정확히 수평이 되도록 얼굴을 회전한 후두 눈 사이의 거리가 항상 같도록 얼굴을 축소시키며, 얼굴 이미지에서 배경, 머리, 이마, 귀, 턱은 잘라내는기하학적 변형 및 다듬기단계(S21)와;조명에 따라 왼쪽 얼굴과 오른쪽 얼굴이 전혀 다른 얼굴처럼 보일 수 있으므로 표준화된 밝기와 대조값을 얻기위해서 얼굴의 왼쪽과 오른쪽을 나누어서 히스토그램 균등화하는 히스토그램 균등화단계(S22)와; 히스토그램 균등화단계(S22)에서 증가될 수 있는 픽셀 노이즈를 감소시키기 위해 양방향(Bilateral Filter)를이용하여 이미지를 매끈하게 하면서 경계선을 뚜렷이 하는 스무딩단계(S23)와;스무딩단계(S23)에서 스무딩 된 이미지에 타원형의 마스크를 씌워 정면을 향하는 얼굴만을 추출하는 마스크단계(S24)와;마이크를 통해 입력되는 음성에서 최솟값과 최댓값의 음성파형을 검출하는 음성파형인식단계(S25)와; 음성파형인식단계(S25)를 통해 추출된 음성파형 내에서 12개의 특징 추출하는 파형특징추출단계(S26);공개특허 10-2022-0046023-4-를 포함하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법."}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 파형특징추출단계(S26)는, 음성파형의 고저, 기울기, 파형의 고저 변화수 특징 추출, 측정초당 음절수, CID 비율, 발화당 음정수, 발화당단어수, 발화당 내용어수, 음소착어, 의미착어, 후속발화 개시시간, 도치어, 간투사, 반복어, 수정어인 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법."}
{"patent_id": "10-2020-0128617", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 분석단계(S30)는, 모션감지 및 음성인식단계(S10)를 통해 획득한 유효데이터를 특정영역, 음성특징추출단계(S20)의 기하학적 변형및 다듬기단계(S21), 히스토그램 균등화단계(S22), 스무딩단계(S23), 마스크단계(S24)를 통해 회득된 얼굴이미지 및 음성파형 내에서 12개의 특징 추출한 데이터를 표준데이터테이블(310)과 비교, 매칭하고,매칭된 이미지 및 음성파형특징에 따른 데이터를 환자군과 정상군 데이터와 비교하여 객관적인 정보와 해석데이터를 추출 및 표시하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법."}
{"patent_id": "10-2020-0128617", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템 및 방법에 관한 것으로, 자살고위험군 면담자의 행동을 촬영하여 유효데이터를 획득하기 위한 3D 카메라가 설치된 서브컴퓨터를 포함하는 정보획득장치 및 정보획득장치와 무선 또는 유선으로 연결되어 입력되는 영상에 따른 유효데이터를 저장하는 계 (뒷면에 계속)"}
{"patent_id": "10-2020-0128617", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 확 대 적용 가능하고, 3D 카메라를 통해 실시간 자살고위험군 면담자의 행동양식을 획득하고 심리학 및 신경과학 전 문가에 작성된 행동양식 표준화데이터를 통해 분석 및 판단하여 심리상태를 객관적으로 평가할 수 있는 효과가 있다. CPC특허분류 G06Q 50/22 (2021.08) G10L 15/02 (2013.01) G10L 15/16 (2013.01) G10L 25/63 (2013.01) G10L 25/66 (2013.01) G16H 50/20 (2018.01) G10L 2015/088 (2013.01)명 세 서 청구범위 청구항 1 자살고위험군 면담자의 행동을 촬영하여 유효데이터를 획득하기 위한 3D 카메라가 설치된 서브컴퓨터를 포함하 는 정보획득장치 및 정보획득장치와 무선 또는 유선으로 연결되어 입력되는 영상에 따른 유효데이터 를 저장하는 계측서버를 포함하는 계측장치와; 상기 계측장치와 유선 또는 무선으로 연결되어 인가되는 유효데이터를 기준으로 얼굴, 표정, 행동에 따른 각각의 데이터를 분리하여 분석모듈과; 상기 분석모듈로부터 인가되는 분리된 이미지를 기 저장된 표준화데이터에 매칭시켜 면담자의 심리상태를 분석 및 결과를 표출하는 분석서버; 를 포함하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템. 청구항 2 제1항에 있어서, 상기 분석모듈은, 흑백 영역에 대한 픽셀값의 평균차에 의한 임계치 구분에 의해 특징을 판단, 파악하는 얼굴분석모듈; 특정 근육의 활동 상태를 분석하기 위하여 액션유닛(Action Units)으로 이루어지는 동작인식모듈과; 음성에서 특징을 추출하고, 추출된 최솟값(Minimum pitch(Hz))과 최댓값(Maximum pitch(Hz))을 지정하며, 지정 된 음성파형 내에서 12개의 특징을 추출하는 음성인식모듈; 을 포함하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템. 청구항 3 제2항에 있어서, 상기 얼굴분석모듈은, 흰색 부분 영상 픽셀들의 밝기 합에서 검은색 부분의 밝기 합을 뺀 차로 계산되며, 영상 및 이미지 검색 시에 이 값이 특징(feature)에 부여된 임계치 보다 큰지 작은지에 따라 파악하고자 하는 대상물체라고 추측하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템. 청구항 4 제2항에 있어서, 상기 동작인식모듈은, 이마아래, 입술 끝 당김, 입술 끝 아래, 입술 다뭄, 입술 빨음, 눈 깜빡임을 포함하는 발생유무 상태와, 이마 중심 올림, 이마 외부 올림, 이마 아래, 눈꺼풀 위로, 볼 위, 코 찡그림, 윗 입술 위, 입술 끝 당김, 보조 개, 입술 끝 아래, 아래턱 위, 입술 늘림, 입술 나뉨, 턱 아래를 포함하는 발생 정도 상태를 인식하는 것을 특 징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템. 청구항 5 제2항에 있어서, 상기 음성파형 내에서 12개의 특징 추출은, 음성파형의 고저, 기울기, 파형의 고저 변화수 특징 추출, 측정초당 음절수, CID 비율, 발화당 음정수, 발화당단어수, 발화당 내용어수, 음소착어, 의미착어, 후속발화 개시시간, 도치어, 간투사, 반복어, 수정어인 것을 특 징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템. 청구항 6 제1항에 있어서, 상기 분석서버는, 분석모듈로부터 공급되는 유효데이터를 기준으로 감정에 대한 시간변화에 따른 그래프 형태의 이력제공, 이력에 따른 감정별 해당 동영상 연동 제공 및 해동인식 분석에 따른 분서데이터를 제공하는 것을 특징으로 하 는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템. 청구항 7 계측장치로부터 입력되는 영상 또는 이미지를 통해 얼굴표정, 머리 및 손의 움직임을 감지하여 모션을 감 지하여 영상 또는 이미지를 획득하고, 음성에서 최솟값과 최댓값의 파형을 검출하는 모션감지 및 음성인식단계 (S10)와; 모션감지 및 음성인식단계(S10)를 통해 인가되는 유효데이터에서 특정 영역을 추출하여 면담자의 감정상태를 파 악하고, 음성파형에서 특징을 추출하는 특정영역, 음성특징추출단계(S20); 및 특정영역, 음성특징추출단계(S20)를 통해 인가되는 영역데이터를 기준으로 기 저장된 표준화데이터에 매칭시켜 면전자의 심리를 판단, 분석하는 분석단계(S30); 를 포함하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법. 청구항 8 제7항에 있어서, 상기 모션감지 및 음성인식단계(S10)는, 계측장치의 3D 카메라를 통해 이마아래, 입술 끝 당김, 입술 끝 아래, 입술 다뭄, 입술 빨음, 눈 깜빡임을 포함 하는 발생유무 상태와, 이마 중심 올림, 이마 외부 올림, 이마 아래, 눈꺼풀 위로, 볼 위, 코 찡그림, 윗 입술 위, 입술 끝 당김, 보조 개, 입술 끝 아래, 아래턱 위, 입술 늘림, 입술 나뉨, 턱 아래를 포함하는 발생 정도 상태를 인식하고, 입력된 음성에서 최솟값과 최댓값에 따른 음성파형을 계측서버에 저장하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법. 청구항 9 제7항에 있어서, 상기 특정영역, 음성특징추출단계(S20)는, 얼굴이 정면을 향하도록 변형하기 위하여 눈 검출을 이용하여 두 눈이 정확히 수평이 되도록 얼굴을 회전한 후 두 눈 사이의 거리가 항상 같도록 얼굴을 축소시키며, 얼굴 이미지에서 배경, 머리, 이마, 귀, 턱은 잘라내는 기하학적 변형 및 다듬기단계(S21)와; 조명에 따라 왼쪽 얼굴과 오른쪽 얼굴이 전혀 다른 얼굴처럼 보일 수 있으므로 표준화된 밝기와 대조값을 얻기 위해서 얼굴의 왼쪽과 오른쪽을 나누어서 히스토그램 균등화하는 히스토그램 균등화단계(S22)와; 히스토그램 균등화단계(S22)에서 증가될 수 있는 픽셀 노이즈를 감소시키기 위해 양방향(Bilateral Filter)를 이용하여 이미지를 매끈하게 하면서 경계선을 뚜렷이 하는 스무딩단계(S23)와; 스무딩단계(S23)에서 스무딩 된 이미지에 타원형의 마스크를 씌워 정면을 향하는 얼굴만을 추출하는 마스크단계 (S24)와; 마이크를 통해 입력되는 음성에서 최솟값과 최댓값의 음성파형을 검출하는 음성파형인식단계(S25)와; 음성파형인식단계(S25)를 통해 추출된 음성파형 내에서 12개의 특징 추출하는 파형특징추출단계(S26);를 포함하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법. 청구항 10 제9항에 있어서, 상기 파형특징추출단계(S26)는, 음성파형의 고저, 기울기, 파형의 고저 변화수 특징 추출, 측정초당 음절수, CID 비율, 발화당 음정수, 발화당 단어수, 발화당 내용어수, 음소착어, 의미착어, 후속발화 개시시간, 도치어, 간투사, 반복어, 수정어인 것을 특 징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법. 청구항 11 제7항에 있어서, 상기 분석단계(S30)는, 모션감지 및 음성인식단계(S10)를 통해 획득한 유효데이터를 특정영역, 음성특징추출단계(S20)의 기하학적 변형 및 다듬기단계(S21), 히스토그램 균등화단계(S22), 스무딩단계(S23), 마스크단계(S24)를 통해 회득된 얼굴이미 지 및 음성파형 내에서 12개의 특징 추출한 데이터를 표준데이터테이블과 비교, 매칭하고, 매칭된 이미지 및 음성파형특징에 따른 데이터를 환자군과 정상군 데이터와 비교하여 객관적인 정보와 해석데이 터를 추출 및 표시하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선 별방법. 발명의 설명 기 술 분 야 본 발명은 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템 및 방법에 관한 것으로, 더욱 상세하게는 3D 카메라를 통해 실시간 자살고위험군 면담자의 행동양식을 획득하고, 심리학 및 신경과학 전 문가에 의해 작성된 행동양식 표준화데이터를 통해 분석 및 판단(또는 연산)하여 심리상태를 객관적으로 평가할 수 있도록 한 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2020-0128617", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 자살생각과 자살시도를 포함하는 자살행동은 객관적, 정량적 기준이 불분명하여 지역 내 자살예방센 터는 자살업무 담당자들의 관리 포인트가 모호하고, 밀착관리에 어려움이 있다. 또한, 각 지자체는 행정안전부 지역안전지수 자살분야 등급 개선을 위한 다양한 사업을 실시하고 있으나 실효성 미미하며, 포스트 코로나 시대 에 맞춰 상담 및 관리체계를 비대면 중심으로 전환하려는 노력을 기울이고 있다. 또한, 자살행동을 하는 사람은 사회와의 소통이 극히 제한적으로 이루어지기 때문에, 가족, 연인 또는 친구와의 소통은 큰 힘이 되고 있다. 그러나, 평소 우울감, 상실감, 좌절 등의 감정표현을 숨긴 후 극단적 선택을 하는 경우가 빈번하게 발생하고, 이러한 갑작스러운 감정변화가 자살행동으로 이어지는 경우가 많다. 이와 같이, 자살사망자의 심리 상태는 불안정할 수 있으며, 이러한 심리 상태가 정확히 모니터링되지 않아 많은 지자체 내의 문제가 발생하고 있다. 상기와 같이 정보기술 기반으로 심리상태를 파악하는 선행문헌으로 대한민국 등록특허 제10-1689021호 (2016.12.23. 공고)의 '센싱장비를 이용한 심리상태 판단 시스템 및 그 방법'은 상담 또는 면접 중인 피검자를 대상으로, 적어도 하나의 센싱 디바이스를 이용하여 상기 피검자의 모션 정보, 생체 신호 정보, 음성 정보 중 적어도 하나의 정보를 계측하는 단계; 상기 계측의 인자 별로 계측 데이터에 의해 분류 가능한 복수의 상태 유 형 정보를 기초로, 상기 적어도 하나의 센싱 디바이스의 계측 데이터를 이용하여 상기 피검자의 현재 상태에 대 응하는 적어도 하나의 상태 유형 정보를 필터링하는 단계; 및 상기 필터링된 적어도 하나의 상태 유형 정보를 심리 분류 테이블과 매칭시켜, 상기 피검자가 가진 적어도 하나의 심리 상태를 추출하여 제공하는 단계를 포함하고, 상기 심리 분류 테이블은, 이종의 복수의 심리 상태에 대해, 상기 복수의 상태 유형 정보 중 상기 심리 상태 각각에 대응하는 해당 상태유형 정보가 개별 매핑되어 있으며, 상기 피검자의 모션 정보는 상기 피검자의 얼굴 영역에서 추출된 표정 정보 및 신체 영역에서 추출된 제스처 정보를 포함하며, 상기 피검자의 생체 신호 정보는 상기 피검자의 맥박, 체온, 혈압, 뇌파 신호 중 적어도 하나를 포함하고, 상기 적어도 하나의 상태 유형 정보를 필터링하는 단계는, 상기 계측의 인자 별로 계측 데이터에 의해 분류 가능한 복수의 상태 유형 정보를 저장하되, 상기 모션 정보의 계측 인자의 경우, 상기 표정 정보에 따라 분류 가능한 복수의 제1 모션 상태 유형 정보와, 상기 제스쳐 정보에 따라 분류 가능한 복수의 제2 모션 상태 유형 정보를 개별 저장하고 있으며, 상기 복수의 제1 모션 상태 유형 정보는 상기 얼굴 영역에서 움직임 변화가 검출된 근육 부위에 대응하여 분류 가능 한 복수의 행동 유형 정보이고, 상기 적어도 하나의 심리 상태를 추출하여 제공하는 단계는, 상기 모션 정보의 계측 인자의 경우, 상기 필터링된 제1 모션 상태 유형 및 제2 모션 상태 유형을 상기 심리 분류 테이블과 각각 매칭시켜, 상기 표정과 상기 제스처에 대응하는 심리 상태를 개별 추출하되, 상기 제1 모션상태 유형에 매칭된 심리 상태와 상기 제2 모션 상태 유형에 매칭된 심리 상태 간의 감정 레벨 차를 비교하여, 상기 감정 레벨 차가 임계치 이상이면, 상기 제2 모션 상태 유형에 매핑된 심리 상태를 소거하고 상기 제1 모션상태 유형에 매칭된 심리 상태만을 추출하여 제공하며, 상기 음성 정보에 대한 복수의 상태 유형 정보는, 상기 피검자의 목소리 떨 림, 목소리 세기의 급격한 상승 또는 하강 변화, 질문에 대한 답변 시간 경과, 기 설정된 특정 단어의 반복적 진술에 해당하는 유형 중 선택된 복수의 유형에 대응하는 상태 유형 정보를 각각 포함하는 것을 특징으로 한다. 상기의 선행문헌은 센싱장비를 이용한 심리상태 판단 시스템 및 그 방법에 따르면, 상담 또는 면접 중에 피검자 의 행동 양식을 실시간 모니터링하고 분석함에 따라 피검자의 행동 양식에 대응하는 심리 상태를 더욱 객관적으 로 도출할 수 있으며 심리 상태의 판별 정확도를 높일 수 있는 이점이 있다. 그러나, 상기의 선행문헌은 유형별 질문에 대한 면담자의 심리학적, 신경과학적으로 객관화된 평가를 할 수 없 다는 문제점을 가지고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-1689021호(2016.12.23. 공고)"}
{"patent_id": "10-2020-0128617", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 선행문헌의 문제점을 개선하기 위하여 3D 카메라를 통해 실시간 피 실험자의 행동양식을 획득 하고 심리학 및 신경과학 전문가에 작성된 행동양식 표준화데이터를 통해 분석 및 판단하여 심리상태를 객관적 으로 평가할 수 있도록 한 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템 및 방법 을 제공하는 데 목적이 있다. 또한, 본 발명은 객관성 있는 식별 방법을 제공하기 위해 특정 모션분석기술을 통해 유형별 질문에 대한 면담자 의 심리학적, 신경과학적으로 객관화된 평가를 할 수 있도록 한 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템 및 방법을 제공하는 데 목적이 있다."}
{"patent_id": "10-2020-0128617", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 상기한 목적을 달성하기 위한 수단으로, 면담자의 행동을 촬영하여 유효데이터를 획득하기 위한 3D 카메라가 설치된 서브컴퓨터를 포함하는 정보획득장 치 및 정보획득장치와 무선 또는 유선으로 연결되어 입력되는 영상에 따른 유효데이터를 저장하는 계측서버를 포함하는 계측장치와; 상기 계측장치와 유선 또는 무선으로 연결되어 인가되는 유효데이터를 기준으로 얼굴, 표 정, 행동에 따른 각각의 데이터를 분리하여 분석모듈과; 상기 분석모듈로부터 인가되는 분리된 이미지를 기 저 장된 표준화데이터에 매칭시켜 면담자의 심리상태를 분석 및 결과를 표출하는 분석서버;를 포함하는 것을 특징 으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템을 제공한다. 본 발명의 분석모듈은, 흑백 영역에 대한 픽셀값의 평균차에 의한 임계치 구분에 의해 특징을 판단, 파악하는 얼굴분석모듈; 특정 근육의 활동 상태를 분석하기 위하여 액션유닛(Action Units)으로 이루어지는 동작인식모듈 과; 음성에서 특징을 추출하고, 추출된 최솟값(Minimum pitch(Hz))과 최댓값(Maximum pitch(Hz))을 지정하며, 지정된 음성파형 내에서 12개의 특징을 추출하는 음성인식모듈;을 포함하는 것을 특징으로 한다. 본 발명의 얼굴분석모듈은, 흰색 부분 영상 픽셀들의 밝기 합에서 검은색 부분의 밝기 합을 뺀 차로 계산되며, 영상 및 이미지 검색 시에 이 값이 특징(Feature)에 부여된 임계치 보다 큰지 작은지에 따라 파악하고자 하는 대상물체라고 추측하는 것을 특징으로 한다. 본 발명의 동작인식모듈은, 이마아래, 입술 끝 당김, 입술 끝 아래, 입술 다뭄, 입술 빨음, 눈 깜빡임을 포함하 는 발생유무 상태와, 이마 중심 올림, 이마 외부 올림, 이마 아래, 눈꺼풀 위로, 볼 위, 코 찡그림, 윗 입술 위, 입술 끝 당김, 보조개, 입술 끝 아래, 아래턱 위, 입술 늘림, 입술 나뉨, 턱 아래를 포함하는 발생 정도 상 태를 인식하는 것을 특징으로 한다. 본 발명의 음성파형 내에서 12개의 특징 추출은, 음성파형의 고저, 기울기, 파형의 고저 변화수 특징 추출, 측 정초당 음절수, CID 비율, 발화당 음정수, 발화당 단어수, 발화당 내용어수, 음소착어, 의미착어, 후속발화 개 시시간, 도치어, 간투사, 반복어, 수정어인 것을 추출하는 것을 특징으로 한다. 본 발명의 분석서버는, 분석모듈로부터 공급되는 유효데이터를 기준으로 감정에 대한 시간변화에 따른 그래프 형태의 이력제공, 이력에 따른 감정별 해당 동영상 연동 제공 및 해동인식 분석에 따른 분서데이터를 제공하는 것을 특징으로 한다. 본 발명은 상기한 목적을 달성하기 위한 또 다른 수단으로, 계측장치로부터 입력되는 영상 또는 이미지를 통해 얼굴표정, 머리 및 손의 움직임을 감지하여 모션을 감지하여 영상 또는 이미지를 획득하는 모션감지 및 음성인식단계와; 모션감지 및 음성인식단계를 통해 인가되는 유효데 이터에서 특정 영역을 추출하여 면담자의 감정상태를 파악하는 특정영역, 음성특징추출단계; 및 특정영역, 음성 특징추출단계를 통해 인가되는 영역데이터를 기준으로 기 저장된 표준화데이터에 매칭시켜 면전자의 심리를 판 단, 분석하는 분석단계;를 포함하는 것을 특징으로 하는 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고 위험군 조기선별방법을 제공한다. 본 발명의 모션감지 및 음성인식단계는, 계측장치의 3D 카메라를 통해 이마아래, 입술 끝 당김, 입술 끝 아래, 입술 다뭄, 입술 빨음, 눈 깜빡임을 포함하는 발생유무 상태와, 이마 중심 올림, 이마 외부 올림, 이마 아래, 눈꺼풀 위로, 볼 위, 코 찡그림, 윗 입술 위, 입술 끝 당김, 보조개, 입술 끝 아래, 아래턱 위, 입술 늘림, 입 술 나뉨, 턱 아래를 포함하는 발생 정도 상태를 인식하여 계측서버에 저장하는 것을 특징으로 한다. 본 발명의 특정영역, 음성특징추출단계는, 얼굴이 정면을 향하도록 변형하기 위하여 눈 검출을 이용하여 두 눈 이 정확히 수평이 되도록 얼굴을 회전한 후 두 눈 사이의 거리가 항상 같도록 얼굴을 축소시키며, 얼굴 이미지 에서 배경, 머리, 이마, 귀, 턱은 잘라내는 기하학적 변형 및 다듬기단계와; 조명에 따라 왼쪽 얼굴과 오른쪽 얼굴이 전혀 다른 얼굴처럼 보일 수 있으므로 표준화된 밝기와 대조값을 얻기 위해서 얼굴의 왼쪽과 오른쪽을 나누어서 히스토그램 균등화하는 히스토그램 균등화단계와; 히스토그램 균등화단계에서 증가될 수 있는 픽셀 노 이즈를 감소시키기 위해 양방향 필터(Bilateral Filter)를 이용하여 이미지를 매끈하게 하면서 경계선을 뚜렷이 하는 스무딩단계와; 스무딩 된 이미지에 타원형의 마스크를 씌워 정면을 향하는 얼굴만을 추출하는 마스크단계 와; 마이크를 통해 입력되는 음성에서 최솟값과 최댓값의 음성파형을 검출하는 음성파형인식단계와; 음성파형인 식단계(S25)를 통해 추출된 음성파형 내에서 12개의 특징을 추출하는 파형특징추출단계;를 포함하는 것을 특징 으로 한다. 본 발명의 파형특징추출단계는, 음성파형의 고저, 기울기, 파형의 고저 변화수 특징 추출, 측정초당 음절수, CID 비율, 발화당 음정수, 발화당 단어수, 발화당 내용어수, 음소착어, 의미착어, 후속발화 개시시간, 도치어, 간투사, 반복어, 수정어인 것을 특징으로 한다. 본 발명의 분석단계는, 모션감지 및 음성인식단계(S10)를 통해 획득한 유효데이터를 특정영역, 음성특징추출단 계의 기하학적 변형 및 다듬기단계, 히스토그램 균등화단계, 스무딩단계, 마스크단계를 통해 회득된 얼굴이미지 및 음성파형 내에서 12개의 특징 추출한 데이터를 표준데이터테이블과 비교, 매칭하고, 매칭된 이미지 및 음성 파형특징에 따른 데이터를 환자군과 정상군 데이터와 비교하여 객관적인 정보와 해석데이터를 추출 및 표시하는 것을 특징으로 한다."}
{"patent_id": "10-2020-0128617", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 기 상용화된 비전-디텍팅 기술의 적용으로 기존 모션인식기술 및 움직임관련 알고리즘(기술)과의 연 동을 통해 더욱 강력한 평가기능의 시스템을 구축할 수 있고, 심리학적 신경과학적인 표준데이터 테이블에 대한 알고리즘을 적용함으로써 사회적 문제로 대두 되고 있는 정신적 문제에 대한 기초 평가 프로그램으로 응용이 가 능한 감성 및 심리치료 분야에 대한 활용 가능 센서디바이스를 사용한 IOT 연동 기술 분야에 확대 적용 가능한 효과가 있다. 본 발명은 3D 카메라를 통해 실시간 피 실험자의 행동양식을 획득하고 심리학 및 신경과학 전문가에 작성된 행 동양식 표준화데이터를 통해 분석 및 판단하여 심리상태를 객관적으로 평가할 수 있는 효과가 있다. 또한, 본 발명은 다양한 분야에서 효과적으로 사용이 가능한 것은 물론 특히, 모션분석기술에 의한 객관성 있는 식별 방법을 제공함으로써 유형별 질문에 대한 면담자의 심리학적, 신경과학적으로 객관화된 평가를 할 수 있는 효과가 있다."}
{"patent_id": "10-2020-0128617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에서 사용되는 기술적 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한 정하려는 의도가 아님을 유의해야 하고, 본 발명에서 사용되는 기술적 용어는 본 발명에서 특별히 다른 의미로 정의되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 의미로 해석되어야 하며, 과도하게 포괄적인 의미로 해석되거나, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 발명에서 사용되는 기술적인 용어가 본 발명의 사상을 정확하게 표현하지 못하는 잘못된 기술적 용어 일 때에는, 당업자가 올바르게 이해할 수 있는 기술적 용어로 대체되어 이해되어야 할 것이다. 또한, 본 발명에 서 사용되는 일반적인 용어는 사전에 정의되어 있는 바에 따라, 또는 전후 문맥상에 따라 해석되어야 하며, 과 도하게 축소된 의미로 해석되지 않아야 한다. 아울러, 본 발명에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 데, 예를 들어 \"구성된다\" 또는 \"포함한다\" 등의 용어는 발명에 기재된 여러 구성 요소들, 또는 여러 단계를 반 드시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들은 포함되지 않을 수도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한다. 본 발명에 의한 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템 및 방법을 설명한 다. 본 발명의 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템은 면담자의 행동을 촬영 하여 유효데이터를 획득하기 위한 3D 카메라가 설치된 서브컴퓨터를 포함하는 정보획득장치 및 정보획득장치와 무선 또는 유선으로 연결되어 입력되는 영상에 따른 유효데이터를 저장하는 계측서버(12 0)를 포함하는 계측장치와; 상기 계측장치로부터 인가되는 유효데이터를 기준으로 얼굴, 표정, 행동 에 따른 각각의 데이터를 분리하여 분석모듈과; 상기 분석모듈에서 분리된 이미지를 기 저장된 데이터에 매칭시켜 면담자의 심리상태를 분석 및 결과를 표출하는 분석서버;를 포함하는 것을 특징으로 한다. 상기와 같은 특징으로 이루어지는 본 발명의 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기 선별시스템 및 방법을 첨부된 도면을 통해 상세하게 설명한다. 도 1을 참조하여 상세하게 설명하면, 본 발명의 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조 기선별시스템은 계측장치, 분석모듈, 분석서버를 포함한다. 상기 계측장치는 면담자의 행동을 촬영하여 유효데이터를 획득하기 위한 3D 카메라가 설치된 서브컴퓨터 를 포함하는 정보획득장치 및 정보획득장치와 무선 또는 유선으로 연결되어 입력되는 영상에 따 른 유효데이터를 저장하는 계측서버를 포함한다. 상기 분석모듈은 계측장치와 유선 또는 무선으로 연결되어 인가되는 유효데이터를 기준으로 얼굴, 표 정, 행동에 따른 각각의 데이터를 분류, 분석할 수 있도록 얼굴분석모듈, 동작인식모듈 및 얼굴분석 모듈을 포함하며, 상기 얼굴분석모듈, 동작인식모듈 및 얼굴분석모듈에 의해 분류 및 분석 된 이미지 데이터를 분서서버로 인가한다. 상기 얼굴분석모듈은 흰색 부분 영상 픽셀들의 밝기 합에서 검은색 부분의 밝기 합을 뺀 차로 계산되며, 영상 및 이미지 검색 시에 이 값이 특색(feature)에 부여된 임계치 보다 큰지 작은지에 따라 파악하고자 하는 대상물체라고 추측한다. 상기 얼굴분석모듈은 영상인식에 사용되는 영상 특색(feature)들은 특징 점을 이용한 SIFT(Scale- Invariant Feature Transform), 템플릿 매칭을 이용한 HOG(Histogram of Oriented Gradient), 그리고 LBP(Local Binary Pattern), MCT(Modified Census Transform) 등 여러 가지가 있지만, 그 중에서도 에이다부스 트(Adaboost: Adaptive Boosting)와 주로 함께 쓰이는 하르 유사 특징(Haar-like Feature)은 기본적으로 영상 에서의 영역과 영역의 밝기 차를 이용한다. 또한, 모양에 따른 기본 특색(feature)들에 따라 이것들을 다수 조합하여 다양한 위치 및 크기에서 물체에 대한 특징을 추출한다. 각 기본 특색(feature)들의 특징 값은, 사각형의 흰색 부분 영상 픽셀들의 밝기 합에서 검은색 부분의 밝기 합 을 뺀 차로 계산되며, 영상 및 이미지 검색 시에 이 값이 특색(Feature)에 부여된 임계치 보다 큰지 아닌지에 따라서 파악하고자 하는 대상물체로 추측한다. 여기에서 대상물체인지 확신을 하기 위해서는 의미 있는 특색(feature)들을 파악하는 것이 중요한데, 이는 특정 영역의 인식 대상에서는 비슷한 값들을 나타내면서 대상이 아닌 경우에는 무작위한 값을 내는 경우를 구분하는 것과 같다. 하르 유사 특징(Haar-like Feature)을 이용한 얼굴인식의 경우, 눈을 예로 들면 눈의 영역은 주변보다 어두운 특징이 있기 때문에 이러한 특징은 사람 얼굴 검출에 의미 있는 특징이 된다. 그리고 이러한 의미 있는 특징의 선정은 에이다부스트(Adaboost)와 같은 부스팅(Boosting) 알고리즘과 같은 기 계 학습 알고리즘을 통해 이루어진다. 이처럼 하르 유사 특징은 기초 특색(feature)에 의한 물체의 기하학적 정 보를 가지면서 단위 영역의 밝기 차를 이용하기 때문에 사람 얼굴과 같은 경우에는 특징적인 밝기 차를 가지기 때문에 비교적 적용하기 적합하다. 상기 동작인식모듈은 이마아래, 입술 끝 당김, 입술 끝 아래, 입술 다뭄, 입술 빨음, 눈 깜빡임을 포함하 는 발생유무 상태와, 이마 중심 올림, dl마 외부 올림, 이마 아래, 눈꺼풀 위로, 볼 위, 코 찡그림, 윗 입술 위, 입술 끝 당김, 보조개, 입술 끝 아래, 아래턱 위, 입술 늘림, 입술 나뉨, 턱 아래를 포함하는 발생 정도 상 태를 인식한다. 상기 음성인식모듈은 마이크를 통해 입력되는 음성에서 특징을 추출하고, 추출된 최솟값(Minimum pitch(Hz))과 최댓값(Maximum pitch(Hz))을 지정한다. 상기 음성인식모듈은 음성파형 내에서 추출되는 12개의 특징은 음성파형의 고저, 기울기, 파형의 고저 변 화수 특징 추출, 측정초당 음절수, CID 비율, 발화당 음정수, 발화당 단어수, 발화당 내용어수, 음소착어, 의미 착어, 후속발화 개시시간, 도치어, 간투사, 반복어, 수정어 등을 추출한다. 상기 분석서버는 분석모듈로부터 인가되는 분리된 이미지를 기 저장된 표준화데이터에 매칭시켜 면담 자의 심리상태를 분석 및 결과를 표출한다. 또한, 분석서버는 표준데이터테이블과 유효데이터를 비교·분석하고, 비교·분석된 유효데이터에 대 한 분석 및 결과는 분석 결과를 토대로 \"표정분석\"과 \"행동분석\"의 그래프를 자동으로 생성하고, 그래프에서 각 항목에 따라 선형 그래프에서 항목에 대한 그래프 정보가 명확하게 표시된다. 상기 분석서버는 음성인식모듈에서 지정된 음성파형 내에서 12개로 추출한 특징을 수치화하고, 수치 화된 데이터와 기저장된 환자군과 정상군 데이터를 비교 및 분석한다. 상기와 같이 구성되는 본 발명의 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법을 이용하여 심리상태를 판단하는 감정인식 분석을 통한 자살고위험군 조기선별방법을 설명한다. 본 발명의 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법은 정보획득장치로부 터 입력되는 영상을 통해 얼굴표정, 머리 및 손의 움직임을 감지하여 모션을 감지하여 영상 또는 이미지를 획득 하는 모션감지 및 음성인식단계(S10)와; 모션감지 및 음성인식단계(S10)를 통해 인가되는 유효데이터에서 특정 영역을 추출하여 면담자의 감정상태를 파악하는 특정영역, 음성특징추출단계(S20); 및 특정영역, 음성특징추출 단계(S20)를 통해 인가되는 영역데이터를 기준으로 기 저장된 표준화데이터에 매칭시켜 면전자의 심리를 판단, 분석하는 분석단계(S30);를 포함한다. 상기 특정영역 추출단계(S20)는 기하학적 변형 및 다듬기단계(S21), 균등화단계(S22), 스무딩단계(S23), 마스크 단계(S24)를 포함한다. 상기 기하학적 변형 및 다듬기단계(S21)는 얼굴이 정면을 향하도록 변형해주는 단계이다. 얼굴이 잘 정렬이 되 어있어야 얼굴 인식 알고리즘이 정확한 특징점을 찾아 인식할 수 있기 때문이다. 즉. 얼굴 검출시 정렬된 얼굴 이미지를 되살리는 것 같지만, 얼굴을 되살리는 과정이 정확하지는 않기 때문에 정확한 얼굴이미지를 획득하기 위하여 기하학적 변형 및 다듬기단계(S21)를 수행한다. 또한, 더 정확한 정렬을 위해서 눈 검출을 이용하여 두 눈이 정확히 수평이 되도록 얼굴을 회전시킨다. 또한 두 눈 사이의 거리가 항상 같도록 얼굴을 축소시킨다. 이후 얼굴 이미지에서 배경, 머리, 이마, 귀, 턱은 잘라내어 특정 부분에 대한 이미지를 획득한다. 상기 균등화단계(S22)는 얼굴 인식 시 조명의 영향을 많이 받는다. 특히 조명에 따라 왼쪽 얼굴과 오른쪽 얼굴 이 전혀 다른 얼굴처럼 보일 수 있다. 그러므로 더 표준화된 밝기와 대조값을 얻기 위해서 얼굴의 왼쪽과 오른 쪽을 나누어서 히스토그램 균등화를 시켜준다. 그리고 왼쪽과 오른쪽을 나누어서 히스토그램 균등화하면, 경계선이 생기게 된다. 그러므로 히스토그램 균등화 를 왼쪽에서 중심 쪽 방향으로, 또는 오른쪽에서 중심 쪽 방향으로 향하도록 수행한다. 그리고 전체 얼굴을 히 스토그램 평등화 시킨 이미지까지, 세 개의 이미지를 결합한다. 상기 스무딩단계(S23)는 히스토그램 균등화까지 수행하게 되면 이미지의 픽셀 노이즈가 증가할 수도 있다. 이 픽셀 노이즈를 감소시키기 위해 스무딩 과정이 필요하다. 이 단계에서는 양방향필터(Bilateral Filter)를 사용 한다. 상기 양방향필터(Bilateral Filter)는 이미지를 매끈하게 만들어 주면서 경계선을 뚜렷하게 한다. 상기 마스크단계(S24)는 기하학적 변형 및 다듬기단계(S21)에서 이미 배경 이미지 등은 제거를 했지만 이미지의 코너부분의 그림자 때문에 인식 과정에서 문제가 생길 것을 방지하여 타원형의 마스크를 씌워주는 과정을 수행 한다. 이 과정은 스무딩까지 된 이미지에 타원을 그려 정면을 향하는 얼굴만을 추출한다. 상기와 같은 단계를 통해 추출되는 얼굴 이미지는 영상인식에 사용되는 영상 특색(Feature)들은 특징 점을 이용 한 SIFT 또는 Naive Bayes 분류기, 템플릿 매칭을 이용한 HOG, 그리고 LBP, MCT등 여러 가지가 있지만, 그 중에 서도 Naive Bayes 분류기, 에이다부스트(Adaboost: Adaptive Boosting)와 주로 함께 쓰이는 하르 유사 특징 (Haar-like Feature)은 기본적으로 영상에서의 영역과 영역의 밝기 차를 이용한다. 상기 Naive Bayes 분류기는 다차원 특징벡터에 대하여 모든 차원이 서로 독립적이라는 매우 강한 가정에 기반하 며, 각 차원은 또한 일반적으로 1차원 가우시안 확률 분포임을 가정하여 전체 학습자료에 대하여 단지 평균과 분산만을 추정한다. 주어진 분류 'c' 에 대하여 입력벡터 'x' 가 주어졌을 때 사후확률(a posteriori probability)은 수학식 1과 같이 표현된다. 수학식 1"}
{"patent_id": "10-2020-0128617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "각각의 차원의 우도(likelihood)는 정규분포로 가정되며, 수학식 2와 같이 계산된다. 수학식 2"}
{"patent_id": "10-2020-0128617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "학습과정은 주어진 학습자료의 평균과 분산만이 필요하다. 또한, 수학식 에서 모든 차원이 독립적으로 가정 되므로 구현이 매우 간단하고 성능에 영향을 주는 요소가 적기 때문에 감정인식의 baseline 성능을 구하기 위하 여 사용된다. 그리고 상기 에이다부스트 알고리즘은 단순한 가설에 근거한 많은 약분류기(Weak Classifier)을 결합하여 강분 류기(Strong Classifier)를 생성하는 방법이다. 약분류기란 무작위 추측(Random Guessing)과 비슷한 수준의 결 과의 분류기를 말한다. 여러 약분류기를 이용하여 샘플들을 인식하고, 정확히 인식된 샘플에 대해서는 가중치를 감소시키고, 인식되지 않은 샘플에 대해서는 가중치를 증가시켜서 다음 약분류기에 반영시킨다. 즉, 가중치가 큰 필터들부터 먼저 사용되어 얼굴이 아닌 이미지들을 최대한 먼저 걸러낸 후, 가중치가 다음으로 큰 필터 순으 로 사용하게 된다. 최정적으로 강분류기는 각 단계에서 생성된 약분류기들의 조압으로 구성된다. 또한, 하나의 강분류기를 만드는 과정을 부스팅(Boosting)이라 하며 강분류기들을 케스케이드(Cascade)형태로 구성하여 최종적으로 에이다부스트(Adaboost) 얼굴검출기를 만들게 된다. 부스팅(Boosting) 알고리즘은 아래 그 림과 같이 3단계로 이루어진다. 첫 번째로 얼굴영상 즉 포지티브 샘플(Positive Sample)과 비 얼굴영상, 네거티브 샘플(Negative Sample)로 나누어 데이터를 수집한다. 이 데이터를 토대로 얻은 하르 특색(Haar Feature)들 중에서 만족하는 얼굴 검출률 을 얻을 때까지 반복하여 얼굴과 비 얼굴을 구분해 낼 수 있는 소수의 값들을 찾는다. 마지막으로는 앞에서 찾 은 하르 특색(Haar Feature) 즉, 약분류기들을 모아서 하나의 강분류기를 구성한다. 이후 강분류기들을 케스케이드(Cascade) 형태로 연결하여 여러 단계로 구성한 에이다부스트(Adaboost) 고속 얼 굴 검출기를 구성하는 과정은 아래와 같이 4단계로 이루어진다. 첫 번째로 전체 단계에서의 개수 및 각 단계에서의 얼굴 검출률을 미리 정한다. 시작단계에서는 낮은 검출률로 시작하게 되지만 후반 단계로 갈수록 검출률을 높인다. 이때 각 단계에서의 얼굴 검출률은 그 단계의 강분류기 를 구성하는 약분류기의 개수에 영향을 미치게 된다. 두 번째로는 각 단계에서 지정된 얼굴 검출률에 도달할 때까지 하르 특색(Haar Feature), 즉 약분류기를 추가 하면서 하나의 강분류기를 훈련시킨다. 이렇게 하나의 단계가 완성되면 앞의 과정을 반복하면서 다음 단계(세번 재)의 강분류기를 훈련시킨다. 이때 이전단계에서 훈련에 참가했던 비 얼굴 이미지는 제외시키고 새로운 비 얼 굴 이미지를 추가하여 훈련시킨다. 그리고 얼굴 이미지인 경우 앞 단계에서 구분할 수 없었던 데이터들만 다음 단계의 훈련에 참가시킨다. 위의 과 정을 계속 반복을 하여 원하는 단계의 개수와 얼굴 검출률을 얻을 때까지 반복훈련을 시킨다. 이렇게 해서 최종 적(네번째)으로 케스케이드(Cascade) 형태의 얼굴 검출용인 에이다부스트(Adaboost)를 구성하게 된다. 또한, 모양에 따른 기본 특색(Feature)들에 따라 이것들을 다수 조합하여 다양한 위치 및 크기에서 물체에 대한 특징을 추출한다. 각 기본 특색(Feature)들의 특징 값은, 사각형의 흰색 부분 영상 픽셀들의 밝기 합에서 검은색 부분의 밝기 합 을 뺀 차로 계산되며, 영상 및 이미지 검색 시에 이 값이 특색(Feature)에 부여된 임계치 보다 큰지 아닌지에따라서 파악하고자 하는 대상물체로 추측한다. 여기에서 대상물체인지 확신을 하기 위해서는 의미 있는 특색(Feature)들을 파악하는 것이 중요한데, 이는 특정 영역의 인식 대상에서는 비슷한 값들을 나타내면서 대상이 아닌 경우에는 무작위한 값을 내는 경우를 구분하는 것과 같다. 또한, 하르 유사 특징(Haar-like Feature)을 이용한 얼굴인식의 경우, 눈을 예로 들면 눈의 영역은 주변보다 어 두운 특징이 있기 때문에 이러한 특징은 사람 얼굴 검출에 의미 있는 특징이 된다. 그리고 이러한 의미 있는 특징의 선정은 에이다부스트(Adaboost)와 같은 부스팅(Boosting) 알고리즘과 같은 기 계 학습 알고리즘을 통해 이루어진다. 이처럼 하르 유사 특징은 기초 특색(Feature)에 의한 물체의 기하학적 정 보를 가지면서 단위 영역의 밝기 차를 이용하기 때문에 사람 얼굴과 같은 경우에는 특징적인 밝기 차를 가지기 때문에 비교적 적용하기 적합하다. 또한, 자살고위험군의 얼굴표정 특징점 분석하기 위하여 SVM(Support Vector Machine)을 사용한다. 상기 SVM(Support Vector Machine)은 지도학습을 통해 데이터를 분류하는 기법으로 분류 결과를 알고 있는 데이 터 그룹들에 대하여 그룹과 그룹을 나누는 결정 경계를 설정할 때, 판별경계(Hyper Plane)와 결정 경계와 학습 데이터 사이의 거리(Margin)의 개념을 사용한다. 상기 분석서버는 표준데이터테이블과 유효데이터를 비교 및 분석하여 도 8과 같이 분석 결과를 토대로 \"표 정 분석\"과 \"행동 분석\"의 그래프는 자동으로 생성되면서 원형 차트 그래프에서 각 항목을 선택하면, 우측의 선 형 그래프에서 선택된 항목에 대한 그래프 정보가 좀 더 명확하게 표시된다. 본 발명은 기 상용화된 비전-디텍팅 기술의 적용으로 기존 모션인식기술 및 움직임관련 알고리즘(기술)과의 연 동을 통해 더욱 강력한 평가기능의 시스템을 구축할 수 있는 것은 물론 심리학적 신경과학적인 표준데이터 테이 블에 대한 알고리즘을 적용함으로써 사회적 문제로 대두 되고 있는 정신적 문제에 대한 기초 평가 프로그램으로 응용이 가능 감성 및 심리치료 분야에 대한 적용 가능 센서디바이스를 사용한 IOT 연동 기술 분야에 확대 적용 가능하다. 또한, 3D 카메라를 통해 실시간 자살고위험군 면담자의 행동양식을 획득하고 심리학 및 신경과학 전문가에 작성 된 행동양식 표준화데이터를 통해 분석 및 판단하여 심리상태를 객관적으로 평가할 수 있다. 더욱이 다양한 분야에서 효과적으로 사용이 가능한 것은 물론 특히, 모션분석기술에 의한 객관성 있는 식별 방 법을 제공함으로써 유형별 질문에 대한 면담자의 심리학적, 신경과학적으로 객관화된 평가를 할 수 있다. 본 명세서는 다수의 특정한 구현물의 세부사항들을 포함하지만, 이들은 어떠한 고안이나 청구 가능한 것의 범위 에 대해서도 제한적인 것으로서 이해되어서는 안되며, 오히려 특정한 고안의 특정한 실시형태에 특유할 수 있는 특징들에 대한 설명으로서 이해되어야 한다. 한편, 본 명세서와 도면에 개시된 본 고안의 실시 예들은 이해를 돕기 위해 특정 예를 제시한 것에 지나지 않으 며, 본 고안의 범위를 한정하고자 하는 것은 아니다. 여기에 개시된 실시 예들 이외에도 본 고안의 기술적 사상"}
{"patent_id": "10-2020-0128617", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은, 본 고안이 속하는 기술분야에서 통상의 지식을 가진 자 에게 자명한 것이다."}
{"patent_id": "10-2020-0128617", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별시스템을 도시한 개략도. 도 2는 본 발명의 인공지능(AI) 기반 영상 및 음성정보를 활용한 자살고위험군 조기선별방법을 도시한 순서도. 도 3은 도 2의 특정영역, 음성특징추출단계에 따른 추출하는 단계를 도시한 도면. 도 4는 도 2에 도시된 모션감지 및 음성인식단계에서 행동분석을 하기 위해 손의 위치를 판별하는 상태를 도시 한 도면. 도 5는 도 3에 도시된 특정영역, 음성특징추출단계에서 얼굴의 기하학적 변형단계를 통해 얼굴에서 배경, 머리, 이마, 턱을 잘라내는 과정에 대한 상태를 단계적으로 도시한 도면. 도 6는 도 3에 도시된 특정영역, 음성특징추출단계에서 히스토그램 균등화단계를 통해 얼굴을 균등하게 분할하 여 이미지를 획득하는 상태를 도시한 도면. 도 7은 도 3에 도시된 특정영역, 음성특징추출단계에서 마스크단계를 통해 얼굴에 마스크가 적용되어 얼굴을 추 출되는 상태를 도시한 도면."}
