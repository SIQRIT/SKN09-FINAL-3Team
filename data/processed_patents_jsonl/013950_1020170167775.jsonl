{"patent_id": "10-2017-0167775", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0067638", "출원번호": "10-2017-0167775", "발명의 명칭": "음성 인식 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "백서현"}}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 인식 장치의 동작 방법에 있어서,오디오 신호를 수신하여 음성 인식을 수행하는 단계;실행 중인 컨텐츠에 대한 컨텐츠 정보를 획득하는 단계;상기 음성 인식을 수행하여 인식한 음성으로부터 상기 컨텐츠 정보에 기초하여 사용자 입력을 분석하는 단계;상기 분석된 사용자 입력과 상기 컨텐츠 정보에 기초하여 응답을 생성하는 단계; 및상기 응답을 출력하는 단계를 포함하는, 음성 인식 장치의 동작 방법."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 음성 인식을 수행하여 인식한 음성으로부터 상기 컨텐츠 정보에 기초하여 사용자 입력을 분석하는 단계는,상기 컨텐츠 정보에 기초하여 상기 인식한 음성에 대한 자연어 이해(Natural Language Understanding)를 수행하는 단계를 포함하는, 음성 인식 장치의 동작 방법."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 컨텐츠 정보에 기초하여 상기 인식한 음성에 대한 자연어 이해를 수행하는 단계는,상기 인식한 음성에 대한 자연어 이해를 수행하는 단계; 및상기 컨텐츠 정보에 기초하여 상기 인식한 음성에 대한 자연어 이해를 수정하는 단계를 포함하는, 음성 인식 장치의 동작 방법."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 컨텐츠 정보는,상기 실행 중인 컨텐츠의 내용에 관련된 컨텐츠 내용 정보와 상기 실행 중인 컨텐츠의 실행에 관련된 컨텐츠 실행 정보 중 적어도 하나 이상의 정보를 포함하는, 음성 인식 장치의 동작 방법."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 분석된 사용자 입력과 상기 컨텐츠 정보에 기초하여 응답을 생성하는 단계는,상기 응답의 적절성을 판단하는 단계; 및상기 응답이 적절하지 않다고 판단하는 경우, 상기 응답을 수정하는 단계를 포함하는, 음성 인식 장치의 동작공개특허 10-2019-0067638-3-방법."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 응답의 적절성을 판단하는 단계는,상기 응답의 보편 적절성 및 사용자 적절성 중 적어도 하나 이상을 판단하는 단계를 포함하는, 음성 인식 장치의 동작 방법."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,음성 인식 장치가 동작하는 상황(situation)과 관련된 상황 정보를 획득하는 단계를 더 포함하고,상기 분석된 사용자 입력과 상기 컨텐츠 정보에 기초하여 응답을 생성하는 단계는,상기 상황 정보에 기초하여 상기 응답을 생성하는 단계를 포함하는, 음성 인식 장치의 동작 방법."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 음성 인식을 수행하여 인식한 음성으로부터 상기 컨텐츠 정보에 기초하여 사용자 입력을 분석하는 단계는,상기 상황 정보에 기초하여 상기 사용자 입력을 분석하는 단계를 포함하는, 음성 인식 장치의 동작 방법.상황정보상황 정보"}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 응답을 출력하는 단계는,상기 컨텐츠 정보 및 상기 상황 정보 중 적어도 하나 이상의 정보에 기초하여 상기 응답의 출력 형태를 결정하는 단계를 포함하는, 음성 인식 장치의 동작 방법."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 상황 정보는,상기 음성 인식 장치의 위치, 움직임, 주변 환경, 상기 음성 인식 장치가 다른 전자 장치와 연결되었는지 여부및 상기 음성 인식 장치의 사용자의 특성과 관련된 정보 중 적어도 하나 이상을 포함하는, 음성 인식 장치의 동작 방법."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "오디오 신호를 수신하는 수신부;상기 오디오 신호에 대한 음성 인식을 수행하고, 실행 중인 컨텐츠에 대한 컨텐츠 정보를 획득하며, 상기 음성공개특허 10-2019-0067638-4-인식을 수행하여 인식한 음성으로부터 상기 컨텐츠 정보에 기초하여 사용자 명령을 분석하고, 상기 분석된 사용자 입력과 상기 컨텐츠 정보에 기초하여 응답을 생성하는 적어도 하나 이상의 프로세서; 및상기 응답을 출력하는 출력부를 포함하는, 음성 인식 장치."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 적어도 하나 이상의 프로세서는, 상기 컨텐츠 정보에 기초하여 상기 인식한 음성에 대한 자연어 이해를 수행하는, 음성 인식 장치."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 적어도 하나 이상의 프로세서는,상기 인식한 음성에 대한 자연어 이해를 수행하고, 상기 컨텐츠 정보에 기초하여 상기 인식한 음성에 대한 자연어 이해를 수정하는, 음성 인식 장치."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 컨텐츠 정보는,상기 실행 중인 컨텐츠의 내용에 관련된 컨텐츠 내용 정보와 상기 실행 중인 컨텐츠의 실행에 관련된 컨텐츠 실행 정보 중 적어도 하나 이상의 정보를 포함하는, 음성 인식 장치."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 적어도 하나 이상의 프로세서는, 상기 응답의 적절성을 판단하고, 상기 응답이 적절하지 않다고 판단하는 경우 상기 응답을 수정하는, 음성 인식장치."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 적어도 하나 이상의 프로세서는,상기 응답의 보편 적절성 및 사용자 적절성 중 적어도 하나 이상을 판단하는, 음성 인식 장치."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,외부 정보를 감지하는 감지부를 더 포함하고,상기 적어도 하나 이상의 프로세서는,공개특허 10-2019-0067638-5-상기 감지부를 제어하여 상기 음성 인식 장치가 동작하는 상황과 관련된 상황 정보를 획득하며, 상기 상황 정보에 기초하여 상기 응답을 생성하는, 음성 인식 장치."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 적어도 하나 이상의 프로세서는,상기 상황 정보에 기초하여 상기 사용자 입력을 분석하는, 음성 인식 장치."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서,상기 적어도 하나 이상의 프로세서는, 상기 컨텐츠 정보 및 상기 상황 정보 중 적어도 하나 이상의 정보에 기초하여 상기 응답의 출력 형태를 결정하는, 음성 인식 장치."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서,상기 음성 인식 장치가 상황 정보는,상기 음성 인식 장치의 위치, 움직임, 주변 환경, 상기 음성 인식 장치가 다른 전자 장치와 연결되었는지 여부및 상기 음성 인식 장치의 사용자의 특성과 관련된 정보 중 적어도 하나 이상을 포함하는 것을 특징으로 하는음성 인식 장치."}
{"patent_id": "10-2017-0167775", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제1항 내지 제10항 중 어느 한 항의 휴대용 전자 장치의 동작을 수행하도록 하는 프로그램이 저장된 기록매체를포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2017-0167775", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 컨텐츠에 기초하여 사용자 입력을 분석하고 응답을 생성하여 출력하는 음성 인식 장치 및 그 동작 방 법에 관한 것으로, 음성 인식 장치의 동작 방법은, 오디오 신호를 수신하여 음성 인식을 수행하는 단계, 실행 중 인 컨텐츠에 대한 컨텐츠 정보를 획득하는 단계, 상기 음성 인식을 수행하여 인식한 음성으로부터 상기 컨텐츠 정보에 기초하여 사용자 입력을 분석하는 단계, 상기 분석된 사용자 입력과 상기 컨텐츠 정보에 기초하여 응답을 생성하는 단계 및 상기 응답을 출력하는 단계를 포함한다."}
{"patent_id": "10-2017-0167775", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 음성 인식 장치 및 그 동작 방법에 관한 것으로서, 보다 구체적으로 실행 중인 컨텐츠에 기초하여 사 용자 입력을 분석하고 응답을 생성하여 출력하는 음성 인식 방법 및 장치에 관한 것일 수 있다. 본 개시는 딥러닝 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인공지능 (AI) 시스템 및 그 응용에 관련된 것이다."}
{"patent_id": "10-2017-0167775", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 Rule 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 Rule 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다.인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조 작 제어(행동 제어) 등을 포함한다. 최근에 스마트폰과 같이 다양한 기능을 복합적으로 수행하는 전자 장치들이 개발됨에 따라, 조작성을 향상시키 기 위하여 음성 인식 기능이 탑재된 전자 장치들이 출시되고 있다. 음성 인식 기능은, 사용자가 별도의 버튼을 조작하거나 또는 터치 모듈에 대한 접촉을 하지 않고, 음성을 통해 장치를 손쉽게 제어할 수 있도록 한다. 음성 인식 기능에는 다양한 인공지능 기술이 활용될 수 있다. 언어적 이해를 통해 사용자의 발화 내용을 정확하 게 인식하고, 발화 내용에 포함된 사용자의 의도를 파악할 수 있다. 또한, 시각적 이해를 통해 사용자가 사용하 는 컨텐츠에 대한 이해가 가능하고, 추론 예측을 통해 사용자의 의도 및 사용자가 실행 중인 컨텐츠에 따른 적 절한 응답을 생성할 수도 있다. 나아가, 동작 제어를 통해 생성한 응답을 적절한 형태로 출력할 수도 있다."}
{"patent_id": "10-2017-0167775", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 컨텐츠에 기초하여 사용자 입력을 분석하고 응답을 생성하여 출력하는 음성 인식 장치 및 그 동작 방 법을 제공한다."}
{"patent_id": "10-2017-0167775", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 음성 인식 장치의 동작 방법은, 오디오 신호를 수신하여 음성 인식을 수행하는 단계, 실행 중 인 컨텐츠에 대한 컨텐츠 정보를 획득하는 단계, 상기 음성 인식을 수행하여 인식한 음성으로부터 상기 컨텐츠 정보에 기초하여 사용자 입력을 분석하는 단계, 상기 분석된 사용자 입력과 상기 컨텐츠 정보에 기초하여 응답 을 생성하는 단계 및 상기 응답을 출력하는 단계를 포함한다. 일 실시예에 따른 음성 인식 장치는, 오디오 신호를 수신하는 수신부, 상기 오디오 신호에 대한 음성 인식을 수 행하고, 실행 중인 컨텐츠에 대한 컨텐츠 정보를 획득하며, 상기 음성 인식을 수행하여 인식한 음성으로부터 상 기 컨텐츠 정보에 기초하여 사용자 명령을 분석하고, 상기 분석된 사용자 입력과 상기 컨텐츠 정보에 기초하여 응답을 생성하는 프로세서 및 상기 응답을 출력하는 출력부를 포함한다. 일 실시예에 따른 컴퓨터에 의해서 실행 가능한 명령어들을 포함하는 프로그램을 기록한 비일시적 기록 매체는, 오디오 신호를 수신하여 음성 인식을 수행하는 단계, 실행 중인 컨텐츠에 대한 컨텐츠 정보를 획득하는 단계, 상기 음성 인식을 수행하여 인식한 음성으로부터 상기 컨텐츠 정보에 기초하여 사용자 입력을 분석하는 단계, 상기 분석된 사용자 입력과 상기 컨텐츠 정보에 기초하여 응답을 생성하는 단계 및 상기 응답을 출력하는 단계 를 실행하기 위한 명령어들을 포함하는 프로그램을 포함한다."}
{"patent_id": "10-2017-0167775", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 또한, 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기 술을 채용할 수 있다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 본 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미 하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. \"부\", \"모듈\"은 어드레싱될 수 있는 저장 매체에 저장되며 프로세서에 의해 실행될 수 있는 프로그램에 의해 구현될 수도 있다. 예를 들어, “부”, \"모듈\" 은 소프트웨어 구성 요소들, 객체 지향 소프트웨어 구성 요소들, 클래스 구성 요소 들 및 태스크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로 그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테 이블들, 어레이들 및 변수들에 의해 구현될 수 있다. 도 1은 일 실시예에 따른 음성 인식 방법을 설명하기 위한 도면이다. 도 1을 참조하면, 일 실시예에 따른 음성 인식 장치는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 수신하고, 수신한 오디오 신호에 포함된 음성 신호에 대해서 음성 인식을 수행할 수 있다. 그 후, 음성 인식 장치는 음성 신호에 포함된 사용자 입력을 이해하고, 사용자 입력에 따른 응답을 생성하고 출력할 수 있다. 이러한 과정을 통해 사용자는 음성 신호를 통해 음성 인식 장치를 제어할 수 있다. 나아가, 일 실시예에 따른 음성 인식 장치는, 음성 인식 기술과 인공지능 기술의 결합을 통해 사용자 입력 에 대한 획일화된 분석 및 이해를 넘어, 사용자의 의도 및 음성 인식 장치가 동작하는 상황에 적합한 응답을 생성하여 출력할 수 있다. 예를 들어, 일 실시예에 따른 음성 인식 장치는, 딥러닝 기반 인공지능시스템일 수 있다. 일 실시예에 따르면, 음성 인식 장치는 인공지능 기술을 이용함으로써, 인간의 언어를 인식하고 응용 및 처리할 수 있고, 음성 인식 장치가 동작하는 상황을 추론 및 예측할 수도 있다. 보다 구체적으로 설명하면, 음성 인식 장치는 대기 상태(idle state)에서 오디오 신호를 수신할 수도 있지 만, 특정 상황에서 오디오 신호를 수신할 수도 있다. 예를 들어, 컨텐츠를 실행 중에 오디오 신호를 수신할 수 도 있다. 이 경우, 음성 인식 장치는 오디오 신호에 대하여 음성 인식을 수행하여, 인식된 음성으로부터 사용자 입력을 단순히 분석하기 보다는, 음성 인식 장치에서 실행 중인 컨텐츠에 기초하여 사용자 입력을 분석함으로써, 사용자의 발화 의도를 보다 정확하게 이해할 수 있다. 나아가, 사용자 입력에 따른 응답을 생성 하여 출력하는 경우에도, 실행 중인 컨텐츠 및 음성 인식 장치가 동작하는 상황에 기초하여 응답을 생성함 으로써, 적절한 응답을 적절한 형태로 출력할 수 있다. 도 1을 참조하면, 음성 인식 장치에는 팬더가 출연하는 비디오 컨텐츠가 실행되고 있다. 이 경우, 음 성 인식 장치는 실행 중인 비디오 컨텐츠에 기초하여 사용자 입력을 분석함으로써, 사용자의 의도를 보다 정확하게 이해할 수 있다. 예를 들어, 사용자가 비디오 컨텐츠에 출연하는 팬더가 사는 곳을 알고 싶은 경우, \"저 팬더는 어디 살아\"라고 질문할 수 있다. 이때, 종래의 음성 인식 장치는 오디오를 신호를 수신하여 음성 인식을 수행하더라도, 사용자가 지칭하는 \"저 팬더\"가 어떤 팬더인지 알 수 없어 사용자의 의도 를 정확하게 이해하기 어렵다. 이와 비교하여, 일 실시예에 따른 음성 인식 장치는 실행 중인 비디오 컨텐 츠에 기초하여 사용자 입력을 분석함으로써, 사용자가 '실행 중인 비디오 컨텐츠에 출연하는 팬더'가 어디에 살 고 있는지 묻는 것임을 이해할 수 있다. 또한, 음성 인식 장치는 사용자 입력에 따른 응답 역시 실행 중인 비디오 컨텐츠에 기초하여 생성함으로써 적절한 응답을 생성할 수 있다. 예를 들어, 음성 인식 장치는 실행 중인 비디오 컨텐츠에 기초하여 '실행 중인 비디오 컨텐츠에 출연하는 팬더'가 'Y 동물원'에 살고 있음을 추론할 수 있다. 도 1에서는 오디오 신호를 수신하고, 수신한 오디오 신호에 포함된 사용자 입력을 이해하고 그에 따른 응답을 생성하며 출력하는 음성 인식 장치에 대해서 설명하고 있으나, 이에 한정되지 않고, 제스처, 문자, 비디오 등 다양한 입력 신호를 수신하여 해당 신호에 포함된 사용자 입력을 이해하고 그에 따른 응답을 생성하며 출력 하는 것도 가능하다. 예를 들어, 음성 인식 장치를 포함하는 전자 장치가 다양한 센서 및/또는 사용자 인 터페이스 등을 통해 사용자의 제스처, 문자, 비디오 등의 신호를 수신하고, 수신한 신호에 포함된 사용자 입력 을 이해하고 그에 따른 응답을 생성하며 출력하는 것도 가능하다. 나아가, 음성 인식 장치는 음성 인식 장치가 동작하는 상황, 실행 중인 비디오 컨텐츠 등을 고려하여 적절한 형태의 응답을 출력할 수 있다. 예를 들어, 음성 인식 장치는 음성 인식 장치가 동작하는 상 황에 기초하여, 사용자의 비디오 컨텐츠 시청에 방해가 되지 않는 방법으로 응답을 출력할 수 있다. 응답을 출력하는 방법에 대해서는 아래에서 자세히 설명하도록 한다. 도 2는 일 실시예에 따른 음성 인식 방법을 보다 구체적으로 설명하기 위한 도면이다. 도 2에 도시된 음성 인식 방법은 도 1 에서 수행되는 음성 인식 방법을 포함할 수 있다. 또한, 아래에서는 음성 인식 장치가 도 1과 마찬가지로 팬더가 출연하는 비디오 컨텐츠를 실행하고 있는 경우를 예로 들어 설 명한다. 도 2를 참조하면, 일 실시예에 따른 음성 인식 장치는, 팬더가 출연하는 비디오 컨텐츠를 실행 중, 사 용자의 음성을 포함하는 오디오 신호를 수신한다. 예를 들어, 사용자가 “저 팬더는 어디 살아?”라고 묻는 경우, 음성 인식 장치는 해당 음성을 포함하는 오디오 신호를 수신한다. 일 실시예에서 음성 인식 장치는, 수신한 오디오 신호에 대하여 음성 인식을 수행할 수 있다. 음성 인식 장치는 수신한 오디오 신호에 대해서 음성 인식을 수행함으로써, 사용자 입력을 수신할 수 있다. 즉, 사용자가 “저 팬더는 어디 살아?”라고 묻는 경우, 음성 인식 장치는 “저 팬더는 어디 살 아?”라는 문장의 의미를 그대로 이해하여 이를 사용자 입력으로 수신할 수 있다. 이러한 음성 인식은 사 용자의 음성 신호를 획일적으로 분석하고 이해하는 과정이다. 이때, 음성 인식 장치는 인공지능 기술을 이용함으로써, 오디오 신호에 포함되는 화자의 언어를 인식하고 응용 및 처리할 수 있다. 보다 구체적으로 음성 인식 장치는 사용자의 개인적인 특성, 예를 들어, 억 양, 언어 습관, 자주 사용하는 어휘나 표현 등을 학습(딥러닝)하거나, 음성 신호의 언어적 이해, 예를 들어, 자 연어 처리 등을 통해 음성 인식의 정확도를 높일 수 있다.일 실시예에서 음성 인식 장치는, 실행 중인 컨텐츠, 즉, 팬더가 출연하는 비디오 컨텐츠에 대한 컨텐 츠 정보를 획득할 수 있다. 컨텐츠 정보는 실행 중인 컨텐츠의 내용 정보와 실행 정보를 포함할 수 있다. 컨텐츠의 내용 정보는 컨텐츠의 줄거리, 컨텐츠에 포함된 객체의 상태, 객체 간의 관계 등과 같이 컨텐츠 자체 에 관한 정보 등을 포함할 수 있다. 또한, 컨텐츠의 실행 정보는 컨텐츠의 명칭, 컨텐츠의 진행 정도 등 컨텐츠 의 실행 상태를 나타내는 정보 등을 포함할 수 있다. 예를 들어, 음성 인식 장치는 실행 중인 컨텐츠에 대 하여, 줄거리, 출연하는 동식물, 사람 및 그들 간의 관계, 비디오 컨텐츠의 명칭, 전체 플레이 타임 및 현 재 얼마나 진행되었는지 등에 대한 정보를 획득할 수 있다. 이때, 음성 인식 장치는 인공지능 기술을 이용하여 폭넓고 깊은 컨텐츠 정보의 획득이 가능하다. 예 를 들어, 음성 인식 장치는 컨텐츠에 대한 시각적 이해를 통해 실행 중인 컨텐츠의 장면을 이해도를 높일 수 있다. 또한, 컨텐츠 정보의 획득은 오디오 신호에 대한 음성 인식과 병렬적 또는 순차적으로 이루어질 수 있다. 컨텐츠 정보의 획득과 음성 인식이 순차적으로 이루어지는 경우, 음성 인식을 먼저 수행 하는 것도 가능하고, 컨텐츠 정보의 획득이 먼저 이루어질 수도 있다. 또한, 컨텐츠 정보의 획득은 다른 프로세스와 별개로, 컨텐츠가 실행 중인 경우, 지속적, 상시적으로 수행될 수도 있다. 일 실시예에서, 음 성 인식 장치는 실행 중인 컨텐츠를 분석하여 컨텐츠 정보를 획득할 수도 있고, 실행 중인 컨텐츠와 관련 된 정보를 외부, 예를 들어, 서버, SNS, 데이터베이스 등에서 획득할 수도 있다. 일 실시예에서 음성 인식 장치는, 음성 인식 결과와 획득한 컨텐츠 정보를 기초로 사용자 입력을 분석 할 수 있다. 여기서, 사용자 입력 분석은 음성 인식 단계에서 사용자의 음성 신호를 획일적 으로 분석하고 이해하는 것과 달리, 사용자의 발화 의도를 보다 정확하게 이해하는 것이다. 예를 들어, 음성 인 식을 통해서는 \"저 팬더는 어디 살아?\"라는 문장의 의미를 그대로 이해하였다면, 사용자 입력 분석을 통해서는 획득한 컨텐츠 정보를 기초로 사용자의 질문이 '실행 중인 비디오 컨텐츠에 출연하는 팬더'가 어디에 살고 있는지 묻는 것임을 이해할 수 있다. 음성 인식 장치는 인공지능 기술을 이용하여 사용자 입력을 보다 정확하게 이해할 수 있다. 예를 들어, 음 성 인식 장치는 컨텐츠 정보를 기초로 사용자의 의도를 논리적으로 추론하고 예측함으로써, 사용자 입력을 보다 정확하게 이해할 수 있다. 일 실시예에서 음성 인식 장치는, 인식한 사용자 입력에 따라 획득한 컨텐츠 정보를 기초로 응답을 생성 할 수 있다. 음성 인식 장치는 획득한 컨텐츠 정보를 기초로하여 사용자가 원하는 적절한 응답을 생 성할 수 있다. 이때, 음성 인식 장치는 컨텐츠 정보뿐 아니라, 음성 인식 장치가 상황 정보를 함께 고려할 수도 있다. 음성 인식 장치가 상황 정보는, 음성 인식 장치의 위치, 움직임, 주변 환경, 상기 음성 인식 장치가 다른 전자 장치와 연결되었는지 여부 및 음성 인식 장치를 사용하는 사용자의 특성 과 관련된 정보 등을 포함할 수 있다. 또한, 음성 인식 장치는 응답 생성을 위하여 다양한 방법을 이용할 수 있다. 예를 들어, 음성 인식 장치는 컨텐츠 정보를 통해 컨텐츠의 종류를 판단하고, 컨텐츠가 영화인 경우, 플롯 분석, 인물 분석, 시 나리오 분석 등의 영화 분석 기법을 통해 응답을 생성할 수 있고, 컨텐츠가 음악인 경우, 음악 검색 시스템 (Music Information Retrieval System), 화음 분석, 조성 분석 등의 음악 분석 기법을 통해 응답을 생성할 수 도 있다. 이러한 과정을 통해 생성한 응답은 사용자가 진정으로 의도한 사용자 입력을 이해하여 생성한 응답이 므로 사용자가 원하는 응답일 가능성이 높다. 예를 들어, 음성 인식 장치는 컨텐츠 정보를 통해 실행 중인 컨텐츠가 팬더의 생활에 관한 다큐멘터리라는 정보를 획득하고, 데이터 베이스로부터 사용자가 감상하는 장면은 Y 동물원에서 촬영되었다는 것을 알아내어, \"Y 동물원에 삽니다\"라는 응답을 생성할 수 있다. 이때, 음성 인식 장치는 인공지능 기술을 이용하여 최적의 응답을 생성할 수 있다. 예를 들어, 음성 인식 장치는 지식 관리를 통해 데이터 베이스를 활용함으로써 사용자가 원하는 응답에 가장 가까운 응답을 생성 하거나 응답의 적절성을 판단할 수 있다. 여기서 데이터 베이스는 지식 기반 데이터 베이스일 수 있다. 일 실시예에서 음성 인식 장치는, 생성한 응답을 출력할 수 있다. 이때, 음성 인식 장치는 컨텐츠 정 보, 음성 인식 장치가 상황 정보 등을 고려하여 적절한 형태의 응답을 출력할 수 있다. 예를 들어, 음성 인식 장치는 응답을 출력하는 시점에 실행 중인 컨텐츠에서 팬더의 생활에 대한 해설이 출력되는 중이거나, 음성 인식 장치 주변이 시끄러워 사용자가 응답을 제대로 들을 수 없는 환경인 경우, 음성이 아 닌 자막으로 응답을 출력할 수도 있다. 이때, 음성 인식 장치는 인공지능 기술을 이용하여 보다 적절한 응답의 출력 형태를 결정할 수 있다. 이하에서는 첨부된 도면을 참조하여, 본 개시의 실시예에 따른 음성 인식 방법 및 음성 인식 장치를 상세히 설 명한다. 상술한 바와 같이, 본 개시의 실시예에 따른 음성 인식 방법 및 음성 인식 장치는 실행 중인 컨텐츠에 기초하여 음성 인식을 수행하고, 그에 따른 적절한 응답을 적절한 형태로 제공할 수 있다. 도 3은 일 실시예에 따른 음성 인식 장치의 동작 방법을 나타내는 흐름도이다. 도 3을 참조하면, 먼저 310 단계에서, 음성 인식 장치는 오디오 신호를 수신하여 음성 인식을 수행한다. 그 후, 320 단계에서, 음성 인식 장치는 실행 중인 컨텐츠에 대한 컨텐츠 정보를 획득한다. 컨텐츠 정보는, 실행 중인 컨텐츠의 내용 정보와 실행 정보를 포함할 수 있다. 도 3에서는 310 단계가 수행되고 320 단계가 수행되도록 도시하고 있으나, 310 단계와 320 단계는 순차적 또는 병렬적으로 수행될 수 있으며, 순차적으로 수행되는 경우, 320 단계가 먼저 수행되고, 그 후, 310 단계가 수행 될 수도 있다. 나아가, 도 3에는 도시하지 않았으나, 음성 인식 장치는 동작하는 상황(situation)과 관련된 상황 정보를 획득하는 단계를 더 수행할 수도 있다. 330 단계에서, 음성 인식 장치는 음성 인식을 수행하여 인식한 음성으로부터 상기 컨텐츠 정보에 기초하여 사용자 입력을 분석한다. 일 실시예에서, 음성 인식 장치는 컨텐츠 정보에 기초하여 인식한 음성에 대한 자연어 이해(Natural Language Understanding)를 수행할 수 있다. 보다 구체적으로, 인식한 음성에 대한 자연어 이해를 수행하고, 컨텐츠 정보에 기초하여 인식한 음성에 대한 자연어 이해를 수정할 수 있다. 또한, 음성 인식 장치는 상황 정보에 기초하여 사용자 입력을 분석할 수도 있다. 그 후, 340 단계에서, 음성 인식 장치는 분석된 사용자 입력과 컨텐츠 정보에 기초하여 응답을 생성한다. 일 실시예에서, 음성 인식 장치는 응답의 적절성을 판단하고, 응답이 적절하지 않다고 판단하는 경우, 응 답을 수정할 수 있다. 이때, 응답의 보편 적절성, 사용자 적절성 등을 판단할 수 있다. 또한, 음성 인식 장치 는 상황 정보에 기초하여 응답을 생성할 수도 있다. 350 단계에서, 음성 인식 장치는 응답을 출력한다. 일 실시예에서, 음성 인식 장치는 컨텐츠 정보, 상황 정보 등에 기초하여 응답의 출력 형태를 결정할 수 있다. 일 실시예에 따르면, 실행 중인 컨텐츠에 기초하여 음성 인식을 수행하고, 그에 따른 적절한 응답을 적절한 형 태로 제공할 수 있다. 도 4 내지 6은 일 실시예에 따른 음성 인식 시스템을 설명하기 위한 도면이다. 도 4에 도시된 바와 같이, 일 실시예에 따른 음성 인식 시스템은, 음성 인식 장치를 포함할 수 있다. 예를 들어, 음성 인식 장치는, 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 웨어러블 디바이스, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라, 자동차의 전자 제어 장치 및 중앙 정보 디스플레이(CID, Central Information Display) 등 모바일 컴퓨팅 장치 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 음성 인식 시스템은, 독립된 장치가 아닌 다른 장치의 일 구성으로 포함될 수도 있다. 예를 들어, 음성 인식 시스템은, 스마트폰 내에 포함되거나, 자동차 내에 포함되는 전자 제어 장치 또는 센터 인포메이션 디스플레이(CID) 내에 포함될 수도 있다. 일 실시예에 따른 음성 인식 장치는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 수신하고, 수신한 오디오 신호에 포함된 음성 신호에 대해서 음성 인식을 수행할 수 있다. 그 후, 음성 인식 장치는 인신한 음성으로부터 사용자 입력을 이해하고, 사용자 입력에 따른 응답을 생성하고 출력할 수 있다. 또한, 도 5에 도시된 바와 같이, 일 실시예에 따른 음성 인식 시스템은 웨어러블 장치(100-1) 및 웨어러블 장치 (100-1)와 연결된 전자 장치를 포함할 수 있다. 웨어러블 장치(100-1)와 전자 장치는 유선 또는 무선 으로 연결 될 수 있다. 예를 들어, 웨어러블 장치(100-1)는, 와치, 밴드, 안경, 헤드폰, 이어폰 등의 형태를 가지는 모바일 컴퓨팅 장 치 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 또한, 웨어러블 장치(100-1)와 연결된 전자 장치는, 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA, 랩톱, 미디어 플레이어, 마이크로 서버, GPS 장치, 웨어러블 디바이스, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라, 자동차의 전자 제어 장치 및 중앙 정보 디스플레이 등 모바일 컴퓨팅 장치 또는 비모바일 컴퓨팅 장치일 수 있 으나, 이에 제한되지 않는다. 일 실시예에 따른 웨어러블 장치(100-1)는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받 고, 입력된 오디오 신호를 전자 장치에게 송신할 수 있다. 또는, 웨어러블 장치(100-1)는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호로부터 검출된 음성 신호를 전자 장 치에게 송신할 수 있다. 또는, 웨어러블 장치(100-1)는, 사용자가 발화한 음성 신호를 포함하는 오디 오 신호를 입력 받고, 입력된 오디오 신호로부터 검출된 음성 신호의 특징을 전자 장치에게 송신할 수도 있다. 전자 장치는, 웨어러블 장치(100-1)로부터 수신된 신호에 기초하여 음성 인식을 수행할 수 있다. 예를 들 어, 전자 장치는 웨어러블 장치(100-1)에서 입력된 오디오 신호로부터 검출된 음성 신호에 대해서 음성 인 식을 수행할 수 있다. 전자 장치는, 음성 인식에 따른 응답을 출력할 수 있고, 또는 웨어러블 장치(100- 1)가 음성 인식에 따른 응답을 출력하도록 웨어러블 장치(100-1)에게 음성 인식 결과를 송신할 수 있다. 나아가, 도 6에 도시된 바와 같이, 일 실시예에 따른 음성 인식 시스템은 음성 인식 장치(100-2) 및 음성 인식 장치(100-2)와 와 연결되는 서버를 포함할 수도 있다. 음성 인식 장치(100-2) 와 서버는 유선 또는 무선으 로 연결될 수 있다. 음성 인식 장치(100-2) 는 사용자가 발화한 음성 신호를 포함하는 오디오 신호, 오디오 신호로부터 검출된 음성 신호 또는 음성 신호의 특징을 서버에 송신하고, 서버는 이를 수신하여 음성 인식을 수행할 수 있다. 또한, 서버는 음성 인식 장치(100-2)가 음성 인식에 따른 응답을 출력하도록 음성 인식 장치(100-2)에게 음성 인식 결과를 송신할 수 있다. 일 실시예에 따른 음성 인식 시스템은 딥러닝 기반 인공지능 시스템일 수 있다. 일 실시예에 따른 음성 인식 시 스템은 인공지능 기술을 이용함으로써, 음성 인식 장치가 동작하는 상황을 추론하고 예측하여, 인간의 언어를 인식하고 처리할 수 있다. 아래에서는 도 7 내지 도 12를 참조하여 일 실시예에 따른 음성 인식 장치의 구체적인 동작 방법을 설명하도록 한다. 이때, 도 1과 마찬가지로 팬더가 출연하는 비디오 컨텐츠를 실행하고 있는 경우를 예로 들어 설명하 도록 한다. 도 7은 일 실시예에 따른 음성 인식 장치에서 컨텐츠 정보를 획득하는 방법을 설명하기 위한 도면이다. 상술한 바와 같이 컨텐츠 정보는, 실행 중인 컨텐츠의 내용에 관련된 내용 정보와 실행에 관련된 실행 정 보를 포함할 수 있다. 도 7을 참조하면, 일 실시예에 따른 음성 인식 장치는 실행 중인 컨텐츠의 분 석 및 데이터 베이스(702, 703)을 이용하여 컨텐츠 정보를 획득할 수 있다. 예를 들어, 데이터 베이스 (702, 703)는, 컨텐츠의 내용, 컨텐츠의 형식 등에 대한 데이터를 포함하는 컨텐츠 관련 데이터 베이스와 실행 중인 컨텐츠의 상태를 나타내는 데이터를 포함하는 컨텐츠 실행 상태 관련 데이터 베이스를 포함할 수 있다. 컨텐츠 관련 데이터 베이스는 지식 기반 데이터 베이스일 수 있으며, 음성 인식 장치에 저장되어 있 을 수도 있고, 외부 장치에 저장되어 있어 음성 인식 장치가 통신부를 통해 외부 장치에 접속하여 이 용하는 것도 가능하다. 컨텐츠 실행 상태 관련 데이터 베이스는 컨텐츠의 실행에 따라 생성, 저장 및 관리 되는 데이터 베이스이므로 컨텐츠를 실행하는 장치 또는 컨텐츠를 실행하는 장치와 연결된 다른 장치에 저장될 수 있다. 따라서, 음성 인식 장치에서 컨텐츠를 실행하는 경우, 컨텐츠 실행 상태 관련 데이터 베이스 는 음성 인식 장치에 저장되거나, 음성 인식 장치와 연결된 저장 장치에 저장될 수도 있다. 일 실시예에 따른 음성 인식 장치는 실행 중인 컨텐츠를 분석하고, 컨텐츠 관련 데이터 베이스 로부터 실행 중인 컨텐츠와 관련된 정보를 획득하여 컨텐츠 내용 정보를 획득할 수 있다. 도 7을 참조하면, 음성 인식 장치는 실행 중인 컨텐츠에 대하여 인공지능 기술을 이용하여 시각적 이해를 수행하 고, 시나리오 분석 기법을 이용하여 분석하며, 컨텐츠의 메타 데이터 등을 이용하여 컨텐츠의 내용을 이해할 수 있다. 예를 들어, 음성 인식 장치는 시각적 이해를 통해 컨텐츠에 팬더가 출연한다는 것을 알 수 있고, 시 나리오 분석을 통해 컨텐츠가 동물원에서 팬더의 생활에 관한 것임을 알 수 있다. 또한, 음성 인식 장치는 컨텐츠 관련 데이터 베이스로부터 실행되는 프로그램의 명칭이 '동물원에 가다'이고, 방송 회차는 '12화'이며, 그 내용은 '동물원에서의 팬더 생활에 대한 탐구'라는 정보를 획득할 수 있다. 이와 같이 획득한 컨텐츠 내용 정보는 컨텐츠의 줄거리, 컨텐츠에 포함된 객체의 상태, 객체 간의 관계 등 과 같이 컨텐츠 자체에 관한 정보 등을 포함할 수 있다. 예를 들어, 도 7을 참조하면, 음성 인식 장치에서 실행 중인 컨텐츠에는 실내 우리 안에 있는 팬더와 우리 밖에서 카메라를 들고 있는 사람들이 있으며, 사람들은 동물원에서 팬더를 관람 중인 관람객임을 알 수 있다. 일 실시예에 따른 음성 인식 장치는 컨텐츠 관련 데이터 베이스와 컨텐츠 실행 상태 관련 데이터 베 이스로부터 컨텐츠 실행 정보를 획득할 수 있다. 상술한 바와 같이, 도 7을 참조하면, 음성 인식 장 치는 컨텐츠 관련 데이터 베이스로부터 실행되는 프로그램의 명칭이 '동물원에 가다'이고, 방송 회차 는 '12화'이며, 그 내용은 '동물원에서의 팬더 생활에 대한 탐구'라는 정보를 획득할 수 있다. 또한, 음성 인식 장치는 컨텐츠 실행 상태 관련 데이터 베이스로부터 실행 중인 컨텐츠의 플레이 타임이 1시간이고, 그 중 12분이 지나갔으며, 사운드는 80/100으로 출력되고 있고, 자막이 존재하나 현재는 사용중이 아니며, 실행 중인 컨텐츠는 VOD 라는 정보를 획득할 수 있다. 이와 같이 획득한 컨텐츠의 실행 정보는 줄거리 진행도, 주요 내용 등을 포함할 수 있다. 도 7을 참조하면, 음성 인식 장치에서 실행 중인 컨텐츠에는 전체 내용 중 100/500 만큼 진행 되었고, 주요 내용 은 동물원에서 팬더의 생활에 관한 것임을 알 수 있다. 도 8은 일 실시예에 따른 음성 인식 장치에서 사용자 입력을 인식하는 방법을 설명하기 위한 도면이다. 일 실시예에 따른 음성 인식 장치는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 수신하고, 수신한 오디오 신호 내에 포함된 음성 신호 분석을 수행한다. 예를 들어, 도 8을 참조하면, 사용자가 \"저 팬더는 어디 살아?\"라고 묻는 경우, 음성 인식 장치는 수신한 오디오 신호에서 \"저 팬더는 어디 살 아?\"라는 사용자의 음성 신호만을 추출할 수 있다. 이 과정에서, 음성 인식 장치는 음성 신호의 분석을 통 해 사용자는 남자이고, 사용자의 연령은 대략 30대이며, 사용자의 감정 상태는 평온한 상태임을 알 수 있다. 일 실시예에 따른 음성 인식 장치는, 음성 신호에 대해 자연어 이해를 수행하기 위한 문장 분석을 수 행할 수 있다. 문장 분석 과정에서는 자연어 이해를 수행하기 위하여 문장 부호를 처리하고, 문장을 분리 한다. 도 8을 참조하면, \"저 팬더는 어디 살아?\"라는 사용자의 음성 신호를 [저(Anaphora) / 팬더 (Subject:Animal)/ 어디(Question:Where) / 살아(Object:Live)] 로 분리한다. 그 후, 일 실시예에 따른 음성 인식 장치는, 분석한 문장에 대해서 자연어 이해를 수행하여 문장 내용을 이해한다. 도 8에서 도시하는 문장 분석 및 자연어 이해 과정은 일 실시예에 불과하며, 도 8에 도시된 방법과 다른 방법으로 자연어 이해를 수행하는 것도 가능하다. 또한, 음성 인식 장치는 인공지능 기술을 이용함으 로써, 오디오 신호에 포함되는 화자의 언어를 인식하고 응용 및 처리할 수 있다. 보다 구체적으로 음성 인식 장 치는 사용자의 개인적인 특성, 예를 들어, 억양, 언어 습관, 자주 사용하는 어휘나 표현 등을 학습(딥 러닝)하거나, 음성 신호의 언어적 이해, 예를 들어, 자연어 처리 등을 통해 음성 인식의 정확도를 높일 수 있다. 일 실시예에서 음성 인식 장치는, 음성 인식 결과에 대해서 내용의 결핍 및/또는 모호성을 분석한다. 이는 음성 인식 장치가 음성 인식을 통해 사용자 입력을 정확하게 이해하였는지 여부를 판단하는 과정이다. 음성 인식 결과를 분석한 결과, 음성 인식 장치가 사용자 입력을 정확하게 이해하기에 음성 신 호에 담긴 내용이 부족하거나 그 내용이 모호한 경우, 음성 인식 장치는 컨텐츠 정보를 이용하여 자연어 이해 결과를 수정할 수 있다. 즉, 음성 인식을 통해 인식한 사용자 입력을 수정할 수 있다. 보다 구체적으로, 도 7에 도시한 것과 같이, 음성 인식 장치는 실행 중인 컨텐츠의 내용 정보와 실행 정보를 포함하는 컨텐츠 정보를 획득할 수 있다. 음성 인식 장치는 컨텐츠 정보를 통해 음성 신호에 담긴 내용을 보충하거나 내용을 명확히 하여 사용자의 발화 의도, 즉, 사용자가 진정으로 의도한 사용자 입력을 보다 정확하게 이해할 수 있다. 예를 들어, 도 8을 참조하면, 음성 인식 장치는 실행 중인 컨텐츠의 내용 정보와 실행 정보를 기초로 사용자가 진정으로 의도한 사용자의 질문이 '동물원에 가다 라는 프로그램의 12화 100/500 시점에 나오 는 우리 안의 팬더'가 어디 살고 있는지 묻는 것임을 이해할 수 있다. 또한, 음성 인식 장치는 인공지능 기술을 이용하여 사용자의 의도를 보다 정확하게 이해할 수 있다. 예를 들어, 음성 인식 장치는 컨텐츠 정 보를 기초로 사용자의 의도를 논리적으로 추론하고 예측함으로써, 사용자 입력을 보다 정확하게 이해할 수있다. 도 9는 일 실시예에 따른 음성 인식 장치에서 음성 인식 장치가 상황 정보를 획득하는 방법을 설명하기 위한 도 면이다. 일 실시예에 따른 음성 인식 장치는 음성 인식 장치가 동작하는 상황과 관련된 상황 정보를 획 득할 수 있다. 도 9을 참조하면, 일 실시예에 따른 음성 인식 장치는 외부 정보를 감지하는 감지부, 사용자 프로파일 등을 이용하여 상황 정보를 획득할 수 있다. 음성 인식 장치는 감지부에서 감지하는 정보를 이용하여 음성 인식 장치가 동작하는 상황을 판 단하기 위한 다양한 정보를 수신하고 감지할 수 있다. 예를 들어, 감지부는, 음성 인식 장치의 위치, 움직임과 관련된 정보, 음성 인식 장치를 사용하고 있는 사용자에 대한 정보, 음성 인식 장치의 주변 환경 정보 등을 수신하거나 감지할 수 있다. 사용자 프로파일은 음성 인식 장치를 사용하고 있는 사용자에 대한 정보로, 음성 인식 장치에 저장되어 있을 수도 있고, 통신부를 통해 외부 장치로부터 수신할 수도 있다. 또한, 음성 인식 장치 는 감지부를 통해 획득된 사용자 정보를 기초로 사용자 프로파일을 업데이트 할 수도 있다. 도 10은 일 실시예에 따른 음성 인식 장치에서 응답 생성 방법을 설명하기 위한 도면이다. 도 10을 참조하면, 일 실시예에 따른 음성 인식 장치는 인식한 사용자 입력에 따라 사용에 명령에 따른 응 답을 생성할 수 있다. 여기서 응답은 사용자 입력에 따른 음성 인식 장치의 동작을 포함할 수 있다. 음성 인식 장치는 실행 중인 컨텐츠의 내용 정보와 실행 정보를 포함하는 컨텐츠 정보를 기초로 응답을 생성할 수 있으며, 또한, 음성 인식 장치가는 상황 정보를 기초로 응답을 생성할 수도 있다. 또한, 음성 인식 장치는 응답을 생성하기 위하여 데이터 베이스를 이용할 수도 있다. 예를 들어, 음성 인식 장치는 \"저 팬더는 어디 살아?\"라는 사용자의 질문에 대한 응답을 생성하기 위하여, 컨텐츠 정보 또는 데이터 베이스로부터 '동물원에 가다 라는 프로그램의 12화 100/500 시점에 나오는 우리 안의 팬더'가 사육되는 동물원 명칭이나 주소 등을 획득하여 응답을 생성할 수 있다. 또한, 음성 인식 장치는 사용자가 현재 TV에 방영되고 있는 드라마의 내용을 묻는 경우, 컨텐츠 정보 또는 데이터 베이스로부터 사용자 가 본 시점 이후의 내용만을 획득하여 응답을 생성할 수도 있다. 음성 인식 장치는 상황 정보에 포함 된 사용자 특성 정보를 이용하여, 청소년 사용자의 경우, 연령 제한에 맞는 응답을 생성함으로써, 사용자 적응 적 응답을 생성할 수도 있다. 나아가, 음성 인식 장치는 인공지능 기술을 이용하여 최적의 응답을 생성할 수 있다. 예를 들어, 음성 인 식 장치는 지식 관리를 통해 데이터 베이스를 활용함으로써 사용자가 원하는 응답에 가장 가까운 응답을 생성할 수 있다. 도 11은 일 실시예에 따른 음성 인식 장치에서 적절성 판단 방법을 설명하기 위한 도면이다. 일 실시예에 따른 음성 인식 장치는 생성한 응답에 대한 적절성을 판단하여, 응답이 적절하지 않다고 판단 하는 경우, 응답을 수정할 수 있다. 응답 자체는 정확한 응답이지만, 응답을 출력하는 것이 오히려 사용자에게 도움이 되지 않는 경우라면, 응답을 수정할 수 있다. 도 11을 참조하면, 먼저, 1110 단계에서, 음성 인식 장치는 적절성 판단 데이터 베이스를 기초로 생 성한 응답의 보편 적절성을 분석할 수 있다. 적절성 판단 데이터 베이스는 보편타당성을 기초로 적절하다 고 생각되는 기준과 관련된 데이터를 저장하는 것으로, 인공지능 기술을 이용하여 학습되고 업데이트 될 수 있 다. 적절성 판단 데이터 베이스는 음성 인식 장치에 저장될 수도 있고, 외부 장치에 저장되어 있어 음성 인식 장치가 통신부를 통해 외부 장치에 접속하여 이용하는 것도 가능하다. 예를 들어, \"타인을 억압하는 방법은?\" 과 같은 질문에 대한 응답은 사회적, 윤리적 관점에서 보편타당하지 않 으므로, 적절하지 않다고 분석할 수 있다. 또한, 영화 감상 중인 사용자의 질문에 대한 응답이 이후 줄거리에 대한 정보를 담고 있어 스포일러가 될 수 있다면, 응답을 출력하는 것이 사용자의 영화 감상을 오히려 방해할 수도 있어 일반적인 관점에서 적절하지 않다고 분석할 수 있다. 또한, 일 실시예에서, 음성 인식 장치는 응답에 대한 보편 적절성 분석 수행 시, 해당 응답에 대해서 기 설정된 기준에 따라 스코어링(scoring) 할 수 있다. 해당 응답의 스코어는 1130 단계에서 적절성 판단에 사용될 수 있다. 1120 단계에서, 음성 인식 장치는 사용자 프로파일를 기초로 생성한 응답의 개인 적절성을 분석할 수 있다. 상술한 바와 같이 사용자 프로파일은 음성 인식 장치를 사용하고 있는 사용자에 대한 정보로, 사용자의 개인적인 기준과 과련된 데이터를 포함할 수 있다. 사용자 프로파일 역시 인공지능 기술을 이용 하여 학습되고 업데이트 될 수 있다. 예를 들어, 상술한 예에서, 스포일러는 일반적인 관점에서 적절하지 않다고 분석할 수 있으나, 전체 줄거리를 알고 영화를 감상하기를 원하는 사용자의 경우, 응답에 스포일러가 포함되더라도 무방하다. 또한, 일 실시예에서, 음성 인식 장치는 응답에 대한 개인 적절성 분석 수행 시, 해당 응답에 대해서 기 설정된 기준에 따라 스코어링(scoring) 할 수 있다. 해당 응답의 스코어는 1130 단계에서 적절성 판단에 사용될 수 있다. 도 11에서는 1110 단계가 수행되고 1120 단계가 수행되도록 도시하고 있으나, 1110 단계와 1120 단계는 순차적 또는 병렬적으로 수행될 수 있으며, 순차적으로 수행되는 경우, 1120 단계가 먼저 수행되고, 그 후, 1110 단계 가 수행될 수도 있다. 1130 단계에서, 음성 인식 장치는 이전 단계에서의 분석 결과를 기초로 생성한 응답의 적절성을 판단한다. 일 실시예에서, 음성 인식 장치는 보편 적절성 분석과 개인 적절성 분석 수행 시, 스코어링된 응답의 스코 어에 따라 해당 응답이 적절한지 여부를 판단할 수 있다. 이때, 음성 인식 장치는 기 설정된 기준을 가지 고 있을 수 있으며, 해당 기준은 스코어 일 수 있다. 생성한 응답의 적절하다고 판단하는 경우, 음성 인식 장치는 생성한 응답을 출력하고, 생성한 응답이 적절 하지 않다고 판단하는 경우, 음성 인식 장치는 1140 단계로 진행하여 응답을 수정하여 수정된 응답을 출력 할 수 있다. 일 실시예에서, 음성 인식 장치는 기 설정된 기준을 만족하는 방향, 즉, 설정된 스코어를 만 족하는 방향으로 응답을 수정할 수 있다. 또한, 일 실시예에 따른 음성 인식 장치는 응답이 적절하지 않다고 판단하는 경우나, 응답을 수정하는 경 우, 생성한 응답을 그대로 출력할 것인지 아니면 수정된 응답을 출력할 것인지 여부를 사용자에게 선택하도록 하여, 사용자의 선택에 따라 응답을 출력할 수도 있다. 음성 인식 장치는 인공지능 기술을 이용하여 최적의 응답을 생성할 수 있다. 예를 들어, 음성 인식 장치 는 지식 관리를 통해 데이터 베이스를 활용함으로써 응답의 적절성을 판단할 수 있다. 도 12는 일 실시예에 따른 음성 인식 장치에서 응답의 출력 형태를 결정하는 방법을 설명하기 위한 도면이다. 일 실시예에 따른 음성 인식 장치는 응답의 출력 형태를 결정할 수 있다. 보다 구체적으로, 음성 인식 장 치는 음성 인식 장치는 실행 중인 컨텐츠의 내용 정보와 실행 정보를 포함하는 컨텐츠 정 보를 기초로 응답의 출력 형태를 결정할 수 있다. 또한, 음성 인식 장치는, 음성 인식 장치가 상황 정보을 기초로 응답 형태를 결정할 수도 있다. 예를 들어, 생성된 응답이 폭력적인 내용을 포함하고 있거나, 선정적인 내용을 포함하고 있어, 공공장소에서 공 개적으로 출력하기 적절하지 않은 경우, 음성 인식 장치는 사용자가 이어폰을 사용하는 경우에만 음성으로 응답을 출력하거나, 응답을 이미지 또는 영상으로 출력하는 경우, 크기를 줄여 출력하는 등 응답의 출력 형태를 결정할 수 있다. 또한, 응답을 출력하는 시점에 실행 중인 컨텐츠에서 팬더의 생활에 대한 해설이 출력되는 중 이거나, 음성 인식 장치 주변이 시끄러워 사용자가 응답을 제대로 들을 수 없는 환경인 경우, 음성 인식 장치는 음성이 아닌 자막으로 응답을 출력할 수도 있다. 음성 인식 장치는 인공지능 기술을 이용하여 응답의 출력 형태를 결정할 수 있다. 예를 들어, 음성 인식 장치는 감지되는 외부 정보들로부터 음성 인식 장치가 동작하는 상황을 인지하고 그에 따른 적절한 출력 형태를 결정할 수 있다. 도 13은 일 실시예에 따른 음성 인식 장치를 나타내는 블럭도이고, 도 14는 일 실시예에 따른 음성 인식 장치를 보다 구체적으로 나타하는 블럭도이다. 도 13에 도시된 바와 같이, 일 실시예에 따른 음성 인식 장치는, 수신부, 프로세서, 및 출력 부를 포함할 수 있다. 그러나, 음성 인식 장치는 도 13에 도시된 구성 요소 모두보다 많은 구성 요 소에 의해 구현될 수도 있다. 예를 들어, 도 14에 도시된 바와 같이, 일 실시예에 따른 음성 인식 장치는, 메모리, 통신부, 사용자 입력부 및 감지부 중 적어도 하나 이상의 구성 요소를 더 포함할 수 있다. 본 발명의 일 실시예에 따른 음성 인식 장치는, 예를 들어, 비모바일 컴퓨팅 디바이스, 모바일 컴퓨팅 디 바이스, 자동차의 전자 제어 장치 및 서버 중 적어도 하나에 포함되거나, 비모바일 컴퓨팅 디바이스, 모바일 컴 퓨팅 디바이스, 자동차의 전자 제어 장치 및 서버 중 적어도 하나에 유, 무선으로 연결되도록 구현될 수 있다. 일 실시예에 따른 수신부는, 오디오 신호를 수신할 수 있다. 예를 들어, 수신부는, 마이크로폰 (Microphone)에 의해 외부의 소리를 전기적인 음향 데이터로 변환함으로써 오디오 신호를 직접 수신할 수 있다. 또는, 수신부는, 외부 장치로부터 송신된 오디오 신호를 수신할 수 있다. 도 13에는, 수신부가, 음 성 인식 장치의 내부에 포함되는 것으로 도시되었으나, 다른 일 실시예에 따른 수신부는 별도의 장 치 내에 포함되고 음성 인식 장치와는 유, 무선으로 연결되는 형태로 구현될 수도 있다. 일 실시예에 따른 프로세서는, 음성 인식 장치의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로 세서는, 수신부, 및 출력부를 제어할 수 있다. 또한, 프로세서는 인공지능 기술을 이 용하여 음성 인식 장치의 동작을 제어할 수도 있다. 일 실시예에 따른 프로세서는, 실행 중인 컨텐츠에 기초하여 사용자 명령을 분석하고, 그에 따른 적절한 응답을 적절한 형태로 제공할 수 있다. 보다 구체적으로, 프로세서는 오디오 신호에 대한 음성 인식을 수 행하고, 실행 중인 컨텐츠에 대한 컨텐츠 정보를 획득하며, 음성 인식을 수행하여 인식한 음성으로부터 컨텐츠 정보에 기초하여 사용자 명령을 분석하고, 분석된 사용자 입력과 컨텐츠 정보에 기초하여 응답을 생성할 수 있 다. 또한, 프로세서는 출력부를 통해 생성한 응답을 적절한 형태로 출력할 수 있다. 컨텐츠 정보는, 실행 중인 컨텐츠의 내용 정보와 실행 정보를 포함할 수 있다. 예를 들어, 컨텐츠의 내용 정보 는, 컨텐츠의 줄거리, 컨텐츠에 포함된 객체의 상태, 객체 간의 관계 등과 같이 컨텐츠 자체에 관한 정보 등을 포함할 수 있다. 또한, 컨텐츠의 실행 정보는 컨텐츠의 명칭, 컨텐츠의 진행 정도 등 컨텐츠의 실행 상태를 나 타내는 정보 등을 포함할 수 있다. 프로세서는 실행 중인 컨텐츠를 분석 및 처리하여 컨텐츠 정보를 획득 할 수도 있고, 외부 장치로부터 컨텐츠 정보를 획득할 수도 있다. 따라서, 도 14에 도시한 바와 같이 음성 인식 장치는, 외부 장치와 통신하는 통신부를 더 포함할 수 있다. 일 실시예에 따른 프로세서는, 컨텐츠 정보에 기초하여 인식한 음성에 대한 자연어 이해를 수행할 수 있 다. 또한, 프로세서는, 인식한 음성에 대한 자연어 이해를 수행하고, 컨텐츠 정보에 기초하여 인식한 음 성에 대한 자연어 이해를 수정할 수 있다. 일 실시예에 따른 프로세서는, 응답의 적절성을 판단하고, 응답이 적절하지 않다고 판단하는 경우, 응답 을 수정할 수 있다. 이때, 프로세서는, 응답의 보편 적절성 및 사용자 적절성 중 적어도 하나 이상을 판 단할 수 있다. 일 실시예에 따른 프로세서는, 감지부를 제어하여 음성 인식 장치가 동작하는 상황과 관련된 상황 정보를 획득하며, 상황 정보에 기초하여 응답을 생성할 수 있다. 상황 정보는, 음성 인식 장치의 위치, 움 직임, 주변 환경, 상기 음성 인식 장치가 다른 전자 장치와 연결되었는지 여부 및 음성 인식 장치를 사용하는 사용자의 특성과 관련된 정보 등을 포함할 수 있다. 또한, 프로세서는, 상황 정보에 기초하여 사용자 입력을 분석할 수 있다. 일 실시예에 따른 프로세서는, 컨텐츠 정보 및 상황 정보 중 적어도 하나 이상의 정보에 기초하여 응답의 출력 형태를 결정할 수 있다. 한편, 일 실시예에 따른 프로세서는, 특정 기능을 실행하는 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 프로세서는, 실행 중인 컨텐츠에 대한 컨텐츠 정보를 획득하는 컨텐츠 정보 획득 부(미도시), 오디오 신호에 대한 음성 인식을 수행하는 음성 인식부(미도시), 컨텐츠 정보에 기초해 오디오 신 호에 포함된 사용자 명령을 인식하는 사용자 명령 인식부(미도시), 컨텐츠 정보에 기초하여 사용자 명령에 따른 응답을 생성하는 하는 응답 생성부(미도시) 중 적어도 하나를 포함할 수 있다. 일 실시예에 따른 프로세서가 수행하는 기능들은, 적어도 하나의 마이크로프로세서에 의해 구현되거나, 해당 기능을 위한 회로 구성들에 의해 구현될 수 있다. 프로세서가 수행하는 기능들의 일부 또는 전부는, 프로세서에서 실행되는 다양한 프로그래밍 언어 또는 스크립트 언어로 구성된 소프트웨어 모듈에 의해 구 현될 수 있다. 도 13 및 도 14는 음성 인식 장치가 하나의 프로세서를 포함하는 것으로 도시하였지 만, 이에 제한되지 않고. 음성 인식 장치는, 복수의 프로세서들을 포함할 수 있다.일 실시예에 따른 출력부는, 오디오 신호에 대해서 음성 인식이 수행된 결과를 출력 할 수 있다. 출력부 는, 음성 인식이 수행된 결과를 사용자에게 알리거나, 외부 디바이스(예를 들어, 스마트 폰, 스마트 TV, 스마트 와치, 서버 등)에게 전송할 수 있다. 보다 구체적으로, 일 실시예에 따른 출력부는, 음성 인식이 수행된 결과에 대응하는 응답을 출력할 수 있 다. 예를 들어, 음성 인식 장치는, 사용자의 질문에 대한 답을 출력부를 통해 출력할 수 있다. 또한, 음성 인식 장치는 음성 인식이 수행된 결과에 대응하는 음성 인식 장치의 기능을 결정하고, 해 당 기능을 수행하는 화면을 출력부를 통해 출력할 수 있다. 또는, 음성 인식 장치는, 음성 인식이 수행된 결과에 대응하는 키워드를 외부 서버로 전송하고, 전송된 키워드에 관련된 정보를 서버로부터 수신하여 출력부를 통해 화면 상에 출력할 수 있다. 일 실시예에 따른 출력부는, 외부로부터 수신되거나, 프로세서에서 처리되거나, 저장된 정보를 빛, 소리, 영상 및 진동 중 적어도 하나의 형태로 출력한다. 예를 들어, 출력부는, 텍스트 또는 영상을 출력 하는 디스플레이, 소리를 출력하는 음향 출력부 및 진동을 출력하는 진동 모터 중 적어도 하나를 더 포함할 수 있다. 도 14에 도시된 바와 같이, 일 실시예에 따른 음성 인식 장치는, 메모리, 통신부, 사용자 입 력부 및 감지부 중 적어도 하나 이상의 구성 요소를 더 포함할 수 있다. 일 실시예에 따른 메모리는, 음성 인식 장치를 제어하기 위해서 프로세서에서 실행되는 명령 들 및 데이터를 저장할 수 있다. 예를 들어, 메모리는 컨텐츠 정보, 음성 인식 장치가 상황 정보 등 을 획득하기 위한 데이터 베이스를 저장할 수 있다. 일 실시예에 따른 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모 리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 일 실시예에 따른 사용자 입력부는, 음성 인식 장치를 제어하기 위한 사용자 입력을 수신할 수 있다. 사용자 입력부는 사용자의 터치를 수신하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용 자의 회전 조작을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch) 등을 포함하는 사용자 입력 디 바이스를 포함할 수 있으나 이에 제한되지 않는다. 일 실시예에 따른 통신부는, 유선 통신 또는 무선 통신을 통해 외부의 전자 장치 또는 서버와 통신할 수 있다. 통신부는, 외부 장치로부터 컨텐츠 정보, 음성 인식 장치가 상황 정보 등을 획득 할 수 있다. 예를 들어, 통신부는, 컨텐츠 정보, 음성 인식 장치가 상황 정보 등을 획득하기 위한 데이터 베이스 를 저장하는 외부 장치와 통신할 수 있다. 일 실시예에 따른 통신부는, 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈, 방송 수신 모듈 등을 포함할 수 있다. 감지부는, 하나 이상의 센서를 포함하고, 음성 인식 장치가 동작하는 상황을 판단하기 위한 다양한 정보를 수신하고 감지할 수 있다. 예를 들어, 감지부는, 음성 인식 장치의 위치, 움직임과 관련된 정보, 음성 인식 장치를 사용하고 있는 사용자에 대한 정보, 음성 인식 장치의 주변 환경 정보 등을 수신하거나 감지할 수 있다. 예를 들어, 감지부는, 조도 센서, 바이오 센서, 기울기 센서, 위치 센서, 근접 센서, 지자기 센서, 자이 로스코프 센서, 온도/습도 센서, 적외선 센서, 및 속도/가속도 센서 중 적어도 하나 또는 이들의 조합을 포함할 수 있다. 일 실시예에 따르면, 실행 중인 컨텐츠에 기초하여 음성 인식을 수행하고, 그에 따른 적절한 응답을 적절한 형 태로 제공할 수 있다. 지금까지 일 실시예에 따른 음성 인식 방법 또는 음성 인식 장치에 대해서 설명하였다. 아래에서는 도 15 내지 도 20를 참조하여 일 실시예에 따른 음성 인식 방법 또는 음성 인식 장치를 사용하는 예시를 설명하도록 한다. 도 15는 실행 중인 컨텐츠에 따라 다른 응답을 출력하는 예시를 나타내는 도면이다. 도 15에 도시된 바와 같이 음성 인식 장치는 사용자의 음성 신호에 대하여 실행 중인 컨텐츠에 따라 다른 응답을 출력할 수 있다. 도 15를 참조하면, 예를 들어, 사용자가 \"11번이 뭐야\"라는 질문을 하는 경우, 음 성 인식 장치는 실행 중인 컨텐츠에 따라 질문의 의미를 다르게 해석하고 이해할 수 있다. 사용자가 야구 경기를 시청하고 있는경우, 음성 인식 장치는 등번호 11번의 야구 선수에 대한 정보를 획득 하여 \"A 야구팀 11번 선수는 X 입니다\" 라는 응답을 출력할 수 있다. 또한, 사용자가 축구 경기를 시청하고 있 는경우, 음성 인식 장치는 등번호 11번의 축구 선수에 대한 정보를 획득하여 \"A 야구팀 11번 선수는 Y 입 니다\" 라는 응답을 출력할 수 있다. 또한, 사용자가 채널 편성표를 보고 있거나, 채널을 변경하고 있는 경우, 음성 인식 장치는 11번 채널에 대한 정보를 획득하여, \"11번 채널은 C 방송국이며, 현재 D 프로그램을 방송하고 있습니다\"라는 응답을 출력할 수도 있다. 나아가, 사용자가 음악 프로그램에서 특정 가수의 뮤직비디오나 공연을 보고 있는 경우, 해당 가수 앨범의 11번 트랙에 대한 정보를 획득하여 \"11번 트랙은 E 입니다. 들어보시겠습니까?\"라는 응답을 출력하고 있 다. 즉, 일 실시예에 따르면, 실행 중인 컨텐츠에 기초하여 음성 인식을 수행하고, 그에 따른 적절한 응답을 제공할 수 있다. 도 16는 음성 인식 장치가 상황 정보에 따라 다른 응답을 출력하는 예시를 나타내는 도면이다. 도 16를 참조하면, 사용자가 실행 중인 컨텐츠의 줄거리에 대해 질문하고 있다. 일반적으로, 사용자는 시청한 부분에 대한 줄거리는 알고 있을 것이므로, 사용자의 의도는 시청하지 못했던 부분에 대한 내용을 묻는 것일 가능성이 높다. 이러한 경우에도, 종래의 음성 인식 장치는 \"좀 늦었네. 무슨 내용이었어?\" 라 는 사용자 질문을 획일적으로 이해하여, \"2098년 여름에, 주인공 'X'가?\"이라는 실행 중인 컨텐츠의 전체 줄거 리를 응답으로 출력한다. 따라서, 사용자는 다시 \"아니, 본 거 이후부터 지금까지.만\"이라고 다시 지시하여 야 한다. 이와 비교하여 일 실시예에 따른 음성 인식 장치는 음성 인식 장치가 상황 정보에 포함된 사용 자 특성 정보를 이용하여, 사용자가 시청한 시점 이후의 내용만을 획득하여 , \"'X'의 결혼식이 있었습니다.\"라 고 사용자 의도에 맞는 응답을 출력할 수 있다. 일 실시예에 따르면, 음성 인식 장치는 사용자 의도에 맞는 응답을 빠르고 간편하게 출력할 수 있다. 도 17은 실행 중인 컨텐츠에 따라 다른 응답을 출력하는 예시를 나타내는 다른 도면이다. 도 17을 참조하면, 사용자는 Dialog 1 및 2의 상황에서 각각 다른 컨텐츠를 시청하는 도중 동일한 질문을 하고 있다. Dialog 1의 상황에서 사용자는 희귀동물 다큐멘터리를 시청하고 있고, Dialog 2의 상황에서 사 용자는 동물원 관련 프로그램을 시청하고 있다. 일 실시예에 따른 음성 인식 장치는 사용자로부터 동일한 질문을 수신하더라도, 실행 중인 컨텐츠에 따라 다른 응답을 출력할 수 있다. 사용자가 희귀동물 다큐멘터리를 시청하고 있는 Dialog 1의 상황에서 음성 인식 장치는 희귀동물 다큐멘터리라는 컨텐츠에 맞게 팬더의 주 서식지에 대한 정보를 획득하여 \"팬더는 보통 중국에 분포합니다.\"라는 응답을 출력할 수 있다. 또한, 사용자가 동물원 관련 프로그램을 시청하고 있는 Dialog 2의 상황에서 음성 인식 장치는 동물원 관련 프로그램이라는 컨텐츠에 맞게 사용자가 시청하는 시 점에 재생되는 팬더가 사육되는 동물원 정보를 획득하여 \"Y 동물원에 살고 있습니다.\"라는 응답을 출력할 수 있 다. 일 실시예에 따르면, 음성 인식 장치는 실행 중인 컨텐츠에 적합한 응답을 출력할 수 있다. 도 18는 응답의 적절성을 판단하는 예시를 나타내는 도면이다. 도 18을 참조하면, 사용자가 추리 영화를 시청하고 있는 상황에서 등장 인물에 대해 질문하고 있다. 일반적 으로, 추리 영화를 시청할 때, 사용자가 미리 결론을 알고 시청하기를 원하지는 않을 것이다. 따라서, 응답 이 결론에 대한 정보를 담고 있어 스포일러가 될 수 있다면, 음성 인식 장치가 응답을 출력하는 것이 사용 자의 영화 감상을 오히려 방해할 수도 있다. 이러한 경우, 음성 인식 장치는 적절히 응답을 수정하거나, 사용자에게 확인 후 응답 출력 여부를 결정할 수도 있다. Dialog 3의 상황에서 종래의 음성 인식 장치는 \"저 남자가 왜 갑자기 찾아온거야?\" 라는 사용자 질문을 획 일적으로 이해하여, 영화 장르 및 내용과 관계없이, \"저 남자가 범인이기 때문입니다.\"라는 결론에 대한 정보를포함하는 응답을 출력한다. 이와 비교하여, 일 실시예에 따른 음성 인식 장치는 Dialog 14의 상황에서 컨텐츠 정보를 정보를 기초로, 응답이 결론에 대한 정보를 담고 있어 스포일러가 될 수 있다는 것을 이해하고, \"스포일러 가능성이 있는 질문 인데, 들으실건가요?\" 라고 사용자에게 응답 출력 여부를 확인하여 보다 적절한 응답을 출력할 수 있다. 일 실시예에 따르면, 음성 인식 장치는 응답을 적절성을 판단하여 최적의 응답을 출력할 수 있다. 도 19는 응답 출력의 형태의 예시를 나타내는 도면이다. 도 19을 참조하면, 사용자가 영화를 시청하고 있는 상황에서 영화 속에 등장하는 차의 이름에 대해 질문하 고 있다. 음성 인식 장치는 컨텐츠 정보, 음성 인식 장치가 상황 정보 등을 고려하여 적절한 형태의 응답을 출력할 수 있다. 예를 들어, 영화속 등장 인물들이 대사를 하는 시점에 응답을 음성으로 출력하는 경우, 출력되는 응답이 영화속 대사와 겹쳐 사용자가 응답을 제대로 들을 수 없을 뿐 아니라, 오히려 영화 감상에 방해가 될 수 있다. 따라서, 이러한 경우, 음성이 아닌 자막으로 응답을 출력할 수도 있다. 일 실시예에 따르면, 음성 인식 장치는 컨텐츠에 따라 적절한 형태로 응답을 출력할 수 있다. 도 20는 음성 인식 장치가 상황 정보에 따라 다른 응답을 출력하는 예시를 나타내는 다른 도면이다. 도 20를 참조하면, 음성 인식 장치는 음성 인식 장치가 상황 정보에 포함된 사용자 특성 정보를 이용하여 사용자 적응적 응답을 생성할 수 있다. 예를 들어, 사용자가 축구 경기를 시청하는 경우, 음성 인식 장치는 음성 인식 장치가 상황 정보 에 포함된 사용자 특성 정보를 이용하여 사용자가 응원하는 팀, 선호하는 목소리(성별에 따른 선호도), 선 호하는 해설가 등에 대한 정보를 획득할 수 있다. 사용자가 팀 A를 응원하고, 여성의 목소리를 선호하는 경우, 음성 인식 장치는 사용자의 특성 정보에 따라 팀 A에 편향된 해설을 찾아 여성의 목소리로 출력할 수 있다. 또한, 선호하는 해설가가 있는 경우에 해당 해설가의 해설을 찾아 출력할 수도 있다. 일 실시예에 따르면, 음성 인식 장치는 음성 인식 장치가 동작하는 상황, 특히, 음성 인식 장치(10 0)의 사용자 특성에 따라 적절한 형태로 응답을 출력할 수 있다. 한편, 상술한 실시예는, 컴퓨터에서 실행될 수 있는 프로그램으로 작성 가능하고, 컴퓨터에 의해 판독 가능한 매체를 이용하여 상기 프로그램을 동작시키는 범용 디지털 컴퓨터에서 구현될 수 있다. 또한, 상술한 실시예에 서 사용된 데이터의 구조는 컴퓨터 판독 가능 매체에 여러 수단을 통하여 기록될 수 있다. 또한, 상술한 실시예 는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매체의 형 태로 구현될 수 있다. 예를 들어, 소프트웨어 모듈 또는 알고리즘으로 구현되는 방법들은 컴퓨터가 읽고 실행할 수 있는 코드들 또는 프로그램 명령들로서 컴퓨터가 읽을 수 있는 기록 매체에 저장될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 기록 매체일 수 있고, 휘발성 및 비휘발성 매 체, 분리형 및 비분리형 매체를 포함할 수 있다. 컴퓨터 판독 가능 매체는 마그네틱 저장매체, 예를 들면, 롬, 플로피 디스크, 하드 디스크 등을 포함하고, 광학적 판독 매체, 예를 들면, 시디롬, DVD 등과 같은 저장 매체를 포함할 수 있으나, 이에 제한되지 않는다. 또한, 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포 함할 수 있다. 또한, 컴퓨터가 읽을 수 있는 복수의 기록 매체가 네트워크로 연결된 컴퓨터 시스템들에 분산되어 있을 수 있으 며, 분산된 기록 매체들에 저장된 데이터, 예를 들면 프로그램 명령어 및 코드가 적어도 하나의 컴퓨터에 의해 실행될 수 있다. 본 개시에서 설명된 특정 실행들은 일 실시예 일 뿐이며, 어떠한 방법으로도 본 개시의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 및 상기 시스템들의 다 른 기능적인 측면들의 기재는 생략될 수 있다."}
{"patent_id": "10-2017-0167775", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 음성 인식 방법을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 음성 인식 방법을 보다 구체적으로 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 음성 인식 장치의 동작 방법을 나타내는 흐름도이다. 도 4 내지 6은 일 실시예에 따른 음성 인식 시스템을 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 음성 인식 장치에서 컨텐츠 정보를 획득하는 방법을 설명하기 위한 도면이다. 도 8은 일 실시예에 따른 음성 인식 장치에서 사용자 명령을 인식하는 방법을 설명하기 위한 도면이다. 도 9는 일 실시예에 따른 음성 인식 장치에서 음성 인식 장치가 상황 정보를 획득하는 방법을 설명하기 위한 도 면이다. 도 10은 일 실시예에 따른 음성 인식 장치에서 응답 생성 방법을 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 음성 인식 장치에서 적절성 판단 방법을 설명하기 위한 도면이다. 도 12는 일 실시예에 따른 음성 인식 장치에서 응답의 출력 형태를 결정하는 방법을 설명하기 위한 도면이다. 도 13은 일 실시예에 따른 음성 인식 장치를 나타내는 블럭도이다. 도 14는 일 실시예에 따른 음성 인식 장치를 보다 구체적으로 나타하는 블럭도이다. 도 15는 실행 중인 컨텐츠에 따라 다른 응답을 출력하는 예시를 나타내는 도면이다. 도 16은 음성 인식 장치가 상황 정보에 따라 다른 응답을 출력하는 예시를 나타내는 도면이다. 도 17은 실행 중인 컨텐츠에 따라 다른 응답을 출력하는 예시를 나타내는 다른 도면이다. 도 18은 응답의 적절성을 판단하는 예시를 나타내는 도면이다. 도 19는 응답 출력의 형태의 예시를 나타내는 도면이다. 도 20은 음성 인식 장치가 상황 정보에 따라 다른 응답을 출력하는 예시를 나타내는 다른 도면이다."}
