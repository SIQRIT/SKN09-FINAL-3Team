{"patent_id": "10-2020-0009316", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0095431", "출원번호": "10-2020-0009316", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "김수필"}}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,대화 내용을 포함하는 녹음 데이터 및 적어도 하나의 인스트럭션을 저장하는 메모리; 및상기 적어도 하나의 인스트럭션을 실행함으로써,상기 대화 내용 중 제1 음성에 대응되는 제1 데이터를 제1 신경망 모델에 입력하여 상기 제1 데이터의 카테고리정보를 획득하고, 상기 대화 내용 중 제2 음성에 대응되는 제2 데이터의 카테고리 정보를 획득하는 프로세서;를포함하고, 상기 프로세서는, 상기 제1 데이터 및 상기 제2 데이터의 카테고리 정보가 상이하면, 상기 제2 데이터의 카테고리 정보와 상기 제1 데이터에 기초하여 상기 제1 신경망 모델을 학습시키는, 전자 장치."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 메모리는, 상기 제2 음성에 대응되는 데이터와 관련된 음성 프로파일 정보를 저장하며, 상기 프로세서는, 상기 저장된 음성 프로파일 정보에 기초하여 상기 녹음 데이터에서 상기 제2 음성을 식별하는, 전자 장치."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 프로세서는, 상기 제2 음성에 대응되는 데이터를 제2 신경망 모델에 입력하여 상기 제2 음성에 대응되는 데이터의 카테고리정보를 획득하는, 전자 장치."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 프로세서는, 상기 제2 음성에 대응되는 데이터에 포함된 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장을 상기 제2 신경망 모델에 입력하여 상기 제2 음성에 대응되는 데이터의 카테고리 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 프로세서는, 상기 제2 음성에 대응되는 데이터에 포함된 복수의 문장 각각에 대응되는 텍스트 데이터를 상기 제2 신경망 모델에 순차적으로 입력하고, 상기 제2 신경망 모델로부터 상기 복수의 문장 각각에 대응되는 적어도 하나의 카테고리 정보 및 상기 적어도 하나의 카테고리 정보에 대응되는 제1 확률 값을 획득하고, 상기 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 대응되는 텍스트 데이터를 상기 제2 신경망 모델에 입력하고, 상기 제2 신경망 모델로부터 상기 획득된 문장에 대응되는 적어도 하나의 카테고리 정보 및 상기 적어도 하나의 카테고리 정보에 대응되는 제2 확률 값을 획득하고,공개특허 10-2021-0095431-3-상기 제1 확률 값 및 상기 제2 확률 값에 기초하여 선택된 문장 및 상기 선택된 문장에 대응되는 제 1카테고리정보에 기초하여 상기 제1 신경망 모델을 학습시키는, 전자 장치."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 프로세서는, 상기 제1 확률 값 및 상기 제2 확률 값 중 임계값 이상의 확률 값을 가지는 문장을 선택하고, 상기 선택된 문장및 선택된 문장에 대응되는 제1카테고리 정보에 기초하여 상기 제1 신경망 모델을 학습시키는, 전자 장치."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 프로세서는, 상기 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 연결어가 포함된 경우, 상기 연결어의 타입 또는 횟수 중 적어도 하나에 기초하여 상기 획득된 문장에 대응되는 확률 값에 가중치를 적용하는, 전자 장치."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항에 있어서, 상기 프로세서는, 동영상 데이터, 이미지 데이터 또는 텍스트 데이터 중 적어도 하나에서 상기 제2 음성과 관련된 동영상 데이터,텍스트 데이터 또는 이미지 데이터 중 적어도 하나가 획득되면, 상기 획득된 데이터를 상기 제2 신경망 모델에입력하여 상기 제2 음성에 대응되는 데이터의 카테고리 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 프로세서는, 사용자 음성 데이터가 입력되면, 상기 학습된 제1 신경망 모델에 상기 사용자 음성 데이터에 대응되는 텍스트데이터를 입력하여, 상기 사용자 음성 데이터에 대응되는 카테고리 정보를 획득하고, 상기 카테고리 정보에 기초하여 상기 사용자 음성 데이터에 대응되는 응답 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 녹음 데이터는, 고객 및 상담사 간 상담 내용을 포함하는 데이터이며, 상기 제1 음성은, 상기 고객의 음성이고, 상기 제2 음성은, 상기 상담사의 음성인, 전자 장치."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "대화 내용을 포함하는 녹음 데이터가 저장된 전자 장치의 제어 방법에 있어서,상기 대화 내용 중 제1 음성에 대응되는 제1 데이터를 제1 신경망 모델에 입력하여 상기 제1 데이터의 카테고리정보를 획득하는 단계;상기 대화 내용 중 제2 음성에 대응되는 제2 데이터의 카테고리 정보를 획득하는 단계; 및상기 제1 데이터 및 상기 제2 데이터의 카테고리 정보가 상이하면, 상기 제2 데이터의 카테고리 정보와 상기 제1 데이터에 기초하여 상기 제1 신경망 모델을 학습시키는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2021-0095431-4-제11항에 있어서, 기 저장된 상기 제2 음성에 대응되는 데이터와 관련된 음성 프로파일 정보에 기초하여 상기 녹음 데이터에서 상기 제2 음성을 식별하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 제2 데이터의 카테고리 정보를 획득하는 단계는, 상기 제2 음성에 대응되는 데이터를 제2 신경망 모델에 입력하여 상기 제2 음성에 대응되는 데이터의 카테고리정보를 획득하는, 제어 방법."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 제2 데이터의 카테고리 정보를 획득하는 단계는, 상기 제2 음성에 대응되는 데이터에 포함된 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장을 상기 제2 신경망 모델에 입력하여 상기 제2 음성에 대응되는 데이터의 카테고리 정보를 획득하는, 제어 방법."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 제1 신경망 모델을 학습시키는 단계는, 상기 제2 음성에 대응되는 데이터에 포함된 복수의 문장 각각에 대응되는 텍스트 데이터를 상기 제2 신경망 모델에 순차적으로 입력하고, 상기 제2 신경망 모델로부터 상기 복수의 문장 각각에 대응되는 적어도 하나의 카테고리 정보 및 상기 적어도 하나의 카테고리 정보에 대응되는 제1 확률 값을 획득하고, 상기 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 대응되는 텍스트 데이터를 상기 제2 신경망 모델에 입력하고, 상기 제2 신경망 모델로부터 상기 획득된 문장에 대응되는 적어도 하나의 카테고리 정보 및 상기 적어도 하나의 카테고리 정보에 대응되는 제2 확률 값을 획득하고,상기 제1 확률 값 및 상기 제2 확률 값에 기초하여 선택된 문장 및 상기 선택된 문장에 대응되는 제1 카테고리정보에 기초하여 상기 제1 신경망 모델을 학습시키는, 제어 방법."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제1 신경망 모델을 학습시키는 단계는, 상기 제1 확률 값 및 상기 제2 확률 값 중 임계값 이상의 확률 값을 가지는 문장을 선택하고, 상기 선택된 문장및 선택된 문장에 대응되는 카테고리 정보에 기초하여 상기 제1 신경망 모델을 학습시키는, 제어 방법."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 연결어가 포함된 경우, 상기 연결어의 타입 또는 횟수 중 적어도 하나에 기초하여 상기 획득된 문장에 대응되는 확률 값에 가중치를 적용하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서, 상기 제2 데이터의 카테고리 정보를 획득하는 단계는,동영상 데이터, 이미지 데이터 또는 텍스트 데이터 중 적어도 하나에서 상기 제2 음성과 관련된 동영상 데이터,공개특허 10-2021-0095431-5-텍스트 데이터 또는 이미지 데이터 중 적어도 하나가 획득되면, 상기 획득된 데이터를 상기 제2 신경망 모델에입력하여 상기 제2 음성에 대응되는 데이터의 카테고리 정보를 획득하는, 제어 방법."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 사용자 음성 데이터가 입력되면, 상기 학습된 제1 신경망 모델에 상기 사용자 음성 데이터에 대응되는 텍스트데이터를 입력하여, 상기 사용자 음성 데이터에 대응되는 카테고리 정보를 획득하고, 상기 카테고리 정보에 기초하여 상기 사용자 음성 데이터에 대응되는 응답 정보를 획득하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0009316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서, 상기 녹음 데이터는, 고객 및 상담사 간 상담 내용을 포함하는 데이터이며, 상기 제1 음성은, 상기 고객의 음성이고, 상기 제2 음성은, 상기 상담사의 음성인, 제어 방법."}
{"patent_id": "10-2020-0009316", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개신된다. 전자 장치는 대화 내용을 포함하는 녹음 데이터 및 적어도 하나의 인스트럭션을 저장하는 메모리 및 적어도 하나의 인스트럭션을 실행함으로써, 대화 내용 중 제1 음성에 대응되는 제1 데이터를 제1 신경 망 모델에 입력하여 제1 데이터의 카테고리 정보를 획득하고, 대화 내용 중 제2 음성에 대응되는 제2 데이터의 카테고리 정보를 획득하는 프로세서를 포함한다. 프로세서는 제1 데이터 및 제2 데이터의 카테고리 정보가 상이 하면, 제2 데이터의 카테고리 정보와 제1 데이터에 기초하여 제1 신경망 모델을 학습시키는 것을 특징으로 한다."}
{"patent_id": "10-2020-0009316", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 고객의 음성에 대한 카테고리를 식별하는 전자 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0009316", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래에는 로봇 분야의 발달로 서비스 로봇이 고객을 상담하고 응대하는 기술이 발전하고 있다. 예를 들어, 콜센터의 챗봇(chatbot)은 인간 상담사를 대신하여 고객의 문의에 대한 답변을 제공하고 있다. 종래에는 이러한 챗봇을 학습시키기 위해 관리자가 챗봇이 고객의 문의를 잘못 인식한 케이스를 찾아 직접 학습 데이터를 추출하여 챗봇을 업데이트시켜야 했다. 이 경우, 챗봇을 학습시키고 유지하는데 필요한 관리자의 노력과 소용되는 시간이 매우 큰 문제가 있었다."}
{"patent_id": "10-2020-0009316", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 따른 것으로, 본 개시의 목적은, 고객 및 상담사 간 대화 내용이 포함된 음성 데이 터를 이용하여 자동으로 챗봇에 포함된 인공지능 모델을 학습시키는 전자 장치 및 그 제어 방법을 제공함에 있 다."}
{"patent_id": "10-2020-0009316", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 전자 장치는, 대화 내용을 포함하는 녹음 데이터 및 적어도 하나의 인스트럭션을 저장하는 메모리 및 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 대화 내 용 중 제1 음성에 대응되는 제1 데이터를 제1 신경망 모델에 입력하여 상기 제1 데이터의 카테고리 정보를 획득 하고, 상기 대화 내용 중 제2 음성에 대응되는 제2 데이터의 카테고리 정보를 획득하는 프로세서를 포함한다. 상기 프로세서는 상기 제1 데이터 및 상기 제2 데이터의 카테고리 정보가 상이하면, 상기 제2 데이터의 카테고 리 정보와 상기 제1 데이터에 기초하여 상기 제1 신경망 모델을 학습시킬 수 있다. 상기 메모리는 상기 제2 음성에 대응되는 데이터와 관련된 음성 프로파일 정보를 저장할 수 있다. 상기 프로세서는 상기 저장된 음성 프로파일 정보에 기초하여 상기 녹음 데이터에서 상기 제2 음성을 식별할 수 있다. 상기 프로세서는 상기 제2 음성에 대응되는 데이터를 제2 신경망 모델에 입력하여 상기 제2 음성에 대응되는 데 이터의 카테고리 정보를 획득할 수 있다.상기 프로세서는 상기 제2 음성에 대응되는 데이터에 포함된 복수의 문장 각각의 적어도 일부를 조합하여 획득 된 문장을 상기 제2 신경망 모델에 입력하여 상기 제2 음성에 대응되는 데이터의 카테고리 정보를 획득할 수 있 다. 상기 프로세서는 상기 제2 음성에 대응되는 데이터에 포함된 복수의 문장 각각에 대응되는 텍스트 데이터를 상 기 제2 신경망 모델에 순차적으로 입력하고, 상기 제2 신경망 모델로부터 상기 복수의 문장 각각에 대응되는 적 어도 하나의 카테고리 정보 및 상기 적어도 하나의 카테고리 정보에 대응되는 제1 확률 값을 획득하고, 상기 복 수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 대응되는 텍스트 데이터를 상기 제2 신경망 모델에 입 력하고, 상기 제2 신경망 모델로부터 상기 획득된 문장에 대응되는 적어도 하나의 카테고리 정보 및 상기 적어 도 하나의 카테고리 정보에 대응되는 제2 확률 값을 획득하고, 상기 제1 확률 값 및 상기 제2 확률 값에 기초하 여 선택된 문장 및 상기 선택된 문장에 대응되는 제1 카테고리 정보에 기초하여 상기 제1 신경망 모델을 학습시 킬 수 있다. 상기 프로세서는 상기 제1 확률 값 및 상기 제2 확률 값 중 임계값 이상의 확률 값을 가지는 문장을 선택하고, 상기 선택된 문장 및 선택된 문장에 대응되는 카테고리 정보에 기초하여 상기 제1 신경망 모델을 학습시킬 수 있다. 상기 프로세서는 상기 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 연결어가 포함된 경우, 상기 연결어의 타입 또는 횟수 중 적어도 하나에 기초하여 상기 획득된 문장에 대응되는 확률 값에 가중치를 적용할 수 있다. 상기 프로세서는 동영상 데이터, 이미지 데이터 또는 텍스트 데이터 중 적어도 하나에서 상기 제2 음성과 관련 된 텍스트 데이터 또는 이미지 데이터, 동영상 데이터 중 적어도 하나가 획득되면, 상기 획득된 데이터를 상기 제2 신경망 모델에 입력하여 상기 제2 음성에 대응되는 데이터의 카테고리 정보를 획득할 수 있다. 상기 프로세서는 사용자 음성 데이터가 입력되면, 상기 학습된 제1 신경망 모델에 상기 사용자 음성 데이터에 대응되는 텍스트 데이터를 입력하여, 상기 사용자 음성 데이터에 대응되는 카테고리 정보를 획득하고, 상기 카 테고리 정보에 기초하여 상기 사용자 음성 데이터에 대응되는 응답 정보를 획득할 수 있다. 상기 녹음 데이터는 고객 및 상담사 간 상담 내용을 포함하는 데이터이며, 상기 제1 음성은 상기 고객의 음성이 고, 상기 제2 음성은 상기 상담사의 음성일 수 있다. 한편, 상술한 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 대화 내용을 포함하는 녹음 데이터가 저장된 전자 장치의 제어 방법은 상기 대화 내용 중 제1 음성에 대응되는 제1 데이터를 제1 신경망 모델에 입력하여 상 기 제1 데이터의 카테고리 정보를 획득하는 단계 상기 대화 내용 중 제2 음성에 대응되는 제2 데이터의 카테고 리 정보를 획득하는 단계 및 상기 제1 데이터 및 상기 제2 데이터의 카테고리 정보가 상이하면, 상기 제2 데이 터의 카테고리 정보와 상기 제1 데이터에 기초하여 상기 제1 신경망 모델을 학습시키는 단계를 포함한다. 상기 제어 방법은 기 저장된 상기 제2 음성에 대응되는 데이터와 관련된 음성 프로파일 정보에 기초하여 상기 녹음 데이터에서 상기 제2 음성을 식별하는 단계를 더 포함할 수 있다. 상기 제2 데이터의 카테고리 정보를 획득하는 단계는 상기 제2 음성에 대응되는 데이터를 제2 신경망 모델에 입 력하여 상기 제2 음성에 대응되는 데이터의 카테고리 정보를 획득할 수 있다. 상기 제2 데이터의 카테고리 정보를 획득하는 단계는 상기 제2 음성에 대응되는 데이터에 포함된 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장을 상기 제2 신경망 모델에 입력하여 상기 제2 음성에 대응되는 데 이터의 카테고리 정보를 획득할 수 있다. 상기 제1 신경망 모델을 학습시키는 단계는 상기 제2 음성에 대응되는 데이터에 포함된 복수의 문장 각각에 대 응되는 텍스트 데이터를 상기 제2 신경망 모델에 순차적으로 입력하고, 상기 제2 신경망 모델로부터 상기 복수 의 문장 각각에 대응되는 적어도 하나의 카테고리 정보 및 상기 적어도 하나의 카테고리 정보에 대응되는 제1 확률 값을 획득하고, 상기 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 대응되는 텍스트 데이터 를 상기 제2 신경망 모델에 입력하고, 상기 제2 신경망 모델로부터 상기 획득된 문장에 대응되는 적어도 하나의 카테고리 정보 및 상기 적어도 하나의 카테고리 정보에 대응되는 제2 확률 값을 획득하고, 상기 제1 확률 값 및 상기 제2 확률 값에 기초하여 선택된 문장 및 상기 선택된 문장에 대응되는 제1 카테고리 정보에 기초하여 상기 제1 신경망 모델을 학습시킬 수 있다. 상기 제1 신경망 모델을 학습시키는 단계는 상기 제1 확률 값 및 상기 제2 확률 값 중 임계값 이상의 확률 값을 가지는 문장을 선택하고, 상기 선택된 문장 및 선택된 문장에 대응되는 카테고리 정보에 기초하여 상기 제1 신 경망 모델을 학습시킬 수 있다. 상기 제어 방법은 상기 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 연결어가 포함된 경우, 상기 연결어의 타입 또는 횟수 중 적어도 하나에 기초하여 상기 획득된 문장에 대응되는 확률 값에 가중치를 적용하 는 단계를 더 포함할 수 있다. 상기 제2 데이터의 카테고리 정보를 획득하는 단계는 동영상 데이터, 이미지 데이터 또는 텍스트 데이터 중 적 어도 하나에서 상기 제2 음성과 관련된 동영상 데이터, 텍스트 데이터 또는 이미지 데이터 중 적어도 하나가 획 득되면, 상기 획득된 데이터를 상기 제2 신경망 모델에 입력하여 상기 제2 음성에 대응되는 데이터의 카테고리 정보를 획득할 수 있다. 상기 제어 방법은 사용자 음성 데이터가 입력되면, 상기 학습된 제1 신경망 모델에 상기 사용자 음성 데이터에 대응되는 텍스트 데이터를 입력하여, 상기 사용자 음성 데이터에 대응되는 카테고리 정보를 획득하고, 상기 카 테고리 정보에 기초하여 상기 사용자 음성 데이터에 대응되는 응답 정보를 획득하는 단계를 더 포함할 수 있다. 상기 녹음 데이터는 고객 및 상담사 간 상담 내용을 포함하는 데이터이며, 상기 제1 음성은 상기 고객의 음성이 고, 상기 제2 음성은 상기 상담사의 음성일 수 있다."}
{"patent_id": "10-2020-0009316", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 개시의 다양한 실시 예에 따르면, 챗봇이 학습되는 프로세스가 자동화됨에 따라 챗봇을 학 습시키고 유지하는데 소요되는 비용이 절감되고 시간이 단축된다. 고객 및 상담사 간 대화 내용이 포함된 음성 데이터에서 고객 및 상담사의 음성을 구분하여 챗봇을 학습시키므 로 챗봇이 고객의 질의 내용을 파악하는 정확도가 개선된다. 또한, 상담사의 음성이 구분된 답변인지 또는 결합 된 답변인지 판단하는 프로세스가 포함되므로 답변 내용에 대한 카테고리 정보의 정확도가 개선될 수 있다. 이 에 따라, 챗봇이 고객의 질의 내용을 파악하는 정확도가 개선된다."}
{"patent_id": "10-2020-0009316", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 개시의 실시 예들은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정 하려는 것이 아니며, 개시된 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 실시 예들을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. A 및/또는 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 명세서에서, 사용자라는 용어는 단말 장치(또는 단말 장치)를 사용하는 사람 또는 단말 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 본 개시의 일 실시 예에 따른 상담사를 대신하는 전자 장치를 간략하게 설명하기 위한 도면이다. 전자 장치는 단말 장치 등으로부터 전송되는 사용자 음성을 이해하고 응답하는 장치일 수 있다. 예를 들어, 전자 장치는 챗봇(chatbot), 스마트폰, 서버 등으로 구현될 수 있다. 여기서, 챗봇이란 사용자 음성 을 이해하고 응답하는 장치로서 인간을 모사하는 장치이며, 예를 들어 콜센터 상담원을 대신하는 챗봇일 수 있 다. 전자 장치는 챗봇(chatbot)으로 구현되는 경우, 챗봇을 통해 단말 장치로 고객의 질의 내용에 대응되 는 음성 형태의 대답 정보 또는 시각적인 UI 형태의 대답 정보를 제공할 수 있다. 한편, 전자 장치는 고객의 질의 내용에 올바른 답변을 제공하기 위해 정확하게 질의 내용을 식별하는 것이 중요하다. 이하에서는 본 개시의 다양한 실시 예에 따른 도면을 참조하여 전자 장치가 질의 내용을 식별하 는데 이용하는 신경망 모델을 학습시키는 방법에 대해 자세히 설명하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 신경망 모델의 학습을 설명하기 위한 도면이다. 본 개시의 일 실시 예에 따른 질의 내용의 카테고리를 분류하는 신경망 모델의 학습은 전자 장치에서 이루 어질 수 있다. 도 2에 따르면, 전자 장치에 음성 데이터가 입력될 수 있다(S205). 여기서, 음성 데이터는 대화 내용을 포 함하는 녹음 데이터일 수 있다. 예를 들어, 녹음 데이터는, 고객 및 상담사 간 대화 내용이 포함된 녹음 데이터 로서 고객의 음성 및 상담사의 음성을 포함할 수 있다. 일 예로, 녹음 데이터에 포함된 고객의 음성은 질의 내 용을 주로 포함할 수 있고 상담사의 음성은 답변 내용을 주로 포함할 수 있다. 일 예에 따르면, 녹음 데이터는 고객 및 상담사 간 하나의 통화의 모든 대화 내용이 포함된 데이터일 수 있다. 다만, 이에 한정되는 것은 아니며, 녹음 데이터는 고객의 질의 내용 및 이에 대응되는 답변 내용이 포함된 데이 터일 수 있다. 이를 위해, 전자 장치는 고객의 음성 또는 고객의 음성에 대응되는 텍스트 데이터에서 질의 형태를 식별하고, 상담사의 음성 또는 상담사의 음성에 대응되는 텍스트 데이터에서 대답 형태를 식별할 수 있다. 여기서, 질의 형태는 일반적인 의문문 형식뿐만 아니라 상대방에게 대답을 요청하는 다양한 경우를 포함하 고, 대답 형태는 일반적인 평서문 형식뿐만 아니라 정보를 제공하는 다양한 경우를 포함할 수 있다. 다시 말해, 녹음 데이터는 고객의 질의 형태의 음성 및 상담사의 대답 형태의 음성이 포함되도록 편집된 데이터일 수 있다. 이에 따라, 질의 내용의 카테고리를 분류하는 신경망 모델을 학습하는데 불필요한 인사말, 고객 정보 등에 관한 정보는 녹음 데이터에서 제외될 수 있다. 다만, 이하에서는 설명의 편의를 위해 녹음 데이터는 고객 및 상담사 간 하나의 통화의 모든 대화 내용이 포함된 데이터를 상정한다. 또한, 녹음 데이터는 이전에 고객 및 상담사 간 대화 내용이 녹음된 데이터이거나 또는 실시간으로 고객 및 상 담사 간 대화 내용이 녹음되는 데이터일 수 있다. 녹음 데이터는, 외부 장치(외부 서버, 외부 데이터베이스 등)로부터 입력될 수 있다. 전자 장치는 입력된 녹음 데이터에 포함된 서로 다른 음성을 구분할 수 있다. 다시 말해, 전자 장치는 입력된 녹음 데이터에 포함된 제1 음성 및 제2 음성을 구분할 수 있다(S210). 예를 들어 제1 음성은 고객의 음성에 대응되며, 제2 음 성은 상담사의 음성에 대응될 수 있다. 이하에서는 설명의 편의를 위하여 제1 음성은 고객의 음성이고, 제2 음 성은 상담사의 음성인 것으로 예를 들어 설명하도록 한다. 일 실시 예에 따라 전자 장치는 기 저장된 제2 음성과 관련된 음성 프로파일 정보에 기초하여 녹음 데이터 에서 제2 음성을 식별할 수 있다. 예를 들어, 음성 프로파일 정보는, 상담사의 음성에 대한 파형 정보, 삼당사 의 이름 등을 포함하는 음성 식별 정보 등을 포함할 수 있다. 예를 들어, 전자 장치는 음성 프로파일 정보에 포함된 음성의 주파수 파형 정보 및 녹음 데이터에 포함된 음성의 주파수 파형 정보를 비교하여 녹음 데이터에서 제2 음성을 식별할 수 있다. 전자 장치는 녹음 데이 터에 포함된 음성 중 제2 음성과 상이한 나머지 음성을 고객의 음성인 제1 음성으로 식별할 수 있다. 다만, 이 에 한정되는 것은 아니며 음성의 내용에 기초하여 상담사의 음성인 제2 음성이 식별될 수도 있다. 예를 들어, \"무엇을 도와드릴까요\" 등과 같이 질의를 유도하는 내용 또는 개인 정보를 확인하는 내용에 대응되는 음성은 상담사의 음성인 제2 음성으로 식별될 수도 있다. 이와 같이 제2 음성을 식별하기 위한 내용에 대한 정보는 전 자 장치에 기 저장되어 있거나, 외부로부터 수신될 수 있다. 또는, 전자 장치는 녹음 데이터의 내용 에 기초하여 적어도 일부의 제2 음성이 식별되면, 식별된 제2 음성의 특징 정보에 기초하여 상담사 음성에 대응 되는 음성 프로파일 정보를 획득하는 것도 가능하다. 전자 장치는 제1 음성에 대한 음성 인식을 수행하여 제1 음성에 대응되는 텍스트 데이터(이하, 제1 텍스트 데이터)를 획득할 수 있다(S215). 예를 들어 전자 장치는 음성 인식을 위한 신경망 모델을 이용하여 제1 음성에 대한 음성 인식을 수행할 수 있다. 다만, 이에 한정되는 것은 아니며, 제1 음성에 대한 음성 인식은 외 부 장치, 외부 서버 등에서 수행되고, 전자 장치는 외부로부터 제1 음성에 대응되는 제1 텍스트 데이터를 수신하는 것도 가능하다. 전자 장치는 제1 텍스트 데이터가 질의 형태인지 여부를 식별할 수 있다(S220). 여기서, 질의 형태는 일반 적인 의문문 형식뿐만 아니라 상대방에게 대답을 요청하는 다양한 경우를 포함한다. 제1 텍스트 데이터가 질의 형태가 아닌 경우(S220-N), 전자 장치는 다른 제1 음성에 대한 음성 인식을 수행할 수 있다. 또한, 전자 장치는 제2 음성에 대한 음성 인식을 수행하여 제2 음성에 대응되는 텍스트 데이터(이하, 제2 텍스트 데이터)를 획득할 수 있다(S225). 제2 음성에 대한 음성 인식은 제1 음성에 대한 음성 인식과 동일/유사 한 방식으로 수행될 수 있다. 전자 장치는 제2 텍스트 데이터가 대답 형태인지 여부를 식별할 수 있다(S230). 여기서, 대답 형태는 일반 적인 평서문 형식뿐만 아니라 정보를 제공하는 다양한 경우를 포함한다. 제2 텍스트 데이터가 대답 형태가 아닌 경우(S230-N), 전자 장치는 다른 제2 음성에 대한 음성 인식을 수행할 수 있다. 제1 텍스트 데이터가 질의 형태이고(S220-Y), 제2 텍스트 데이터가 대답 형태인 경우(S230-Y), 전자 장치 는 제1 텍스트 데이터에 대응되는 제1 음성 이후에 제2 텍스트 데이터에 대응되는 제2 음성이 발화되었는지 여 부를 식별할 수 있다(S235). 고객의 질의에 해당되는 제1 음성 이후에 발화되는 상담사의 제2 음성이 해당 고객 의 질의에 대응되는 대답일 수 있기 때문이다. 이에 관하여는 도 4에서 자세히 설명하도록 한다. 제1 음성 이후에 제2 음성이 발화되지 않은 경우(S235-N), 다시 말해 제1 음성 이전에 제2 음성이 발화된 경우, 전자 장치는 해당 제1 텍스트 데이터 및 제2 텍스트 데이터가 매칭되지 않는 것으로 식별할 수 있다. 이에 따라, 전자 장치는 매칭되는 제1 텍스트 데이터 및 제2 텍스트 데이터를 식별하도록 기존과 다른 제1 음성및 제2 음성에 대한 음성 인식을 수행할 수 있다. 한편, 전자 장치는 제1 텍스트 데이터에 대응되는 제1 음성 이후에 제2 텍스트 데이터에 대응되는 제2 음 성이 발화된 것으로 식별되면(S235-Y), 제1 텍스트 데이터를 제1 신경망 모델에 입력할 수 있다. 제1 텍스트 데 이터가 제1 신경망 모델에 입력되면, 제1 신경망 모델은 제1 텍스트 데이터의 적어도 하나 이상의 카테고리 정 보 및 확률 값을 출력할 수 있다(S240). 여기서, 확률 값은 제1 음성의 데이터가 해당 카테고리 정보로 분류되 는 정확도에 대한 확률 값일 수 있다. 일 예에 따라 제1 신경망 모델은, 제1 음성에 대응되는 텍스트 데이터 및 해당 텍스트 데이터의 카테고리 정보를 입출력 데이터 쌍으로 이용하여 학습될 수 있다. 예를 들어, 제1 신경망 모델은 제1 음성에 대응되는 제1 텍스트 데이터가 입력되면, 기 정의된 복수의 카테고리 각각에 대응되는 확률 정보를 출력하도록 학습될 수 있다. 예를 들어, 제1 신경망 모델은 \"에어컨 냉방이 약해요\"라는 제1 음성에 대응되는 제1 텍스트 데이터에 기초하여 제1 음성에 대응되는 제1 텍스트 데이터의 카테고리 정보 및 확률 값을 \"에어컨 냉방 고장(카테고리 ID: 2000), 확률 값 0.9\", \"창문 열림(카테고리 ID: 1010), 확률 값 0.1\" 등으로 출력할 수 있다. 이 경우, 전자 장치는 가장 높은 확률 값에 기초하여 제1 음성에 대응되는 데이터의 카테고리 정보(제1 카 테고리 정보)를 획득할 수 있다(S245). 예를 들어, 전자 장치는 \"에어컨 냉방 고장(카테고리 ID: 2000)\"을 획득할 수 있다. 여기서, 카테고리 정보는 자주 묻는 질문들(Frequently Asked Questions, FAQ)에 기초하여 분류된 정보이며, 동 일한 성질을 갖는 범주는 하나의 카테고리 정보로 분류될 수 있다. 성질은 장치의 타입, 기능 등을 포함할 수 있다. 또한, 카테고리 정보는 기설정된 뎁스에 따라 구분될 수 있다. 예를 들어, 넓게는 에어컨에 관한 문제가 동일한 카테고리 정보로 분류될 수 있으며, 좁게는 에어컨의 서로 다른 기능들이 별도의 카테고리 정보로 분류 될 수 있다. 이러한 카테고리 정보는 각 사업자 별로 카테고리 정보는 상이할 수 있다. 한편, 전자 장치는 제1 텍스트 데이터에 대응되는 제1 음성 이후에 제2 텍스트 데이터에 대응되는 제2 음 성이 발화이 발화된 것으로 식별되면(S235-Y), 제2 텍스트 데이터를 제2 신경망 모델에 입력할 수 있다. 제2 텍스트 데이터가 제2 신경망 모델에 입력되면, 제2 신경망 모델은 제2 텍스트 데이터의 적어도 하나 이상의 카테고리 정보 및 확률 값을 출력할 수 있다(S250). 일 예에 따라 제2 신경망 모델은, 제2 음성에 대응되는 텍 스트 데이터 및 해당 텍스트 데이터의 카테고리 정보를 입출력 데이터 쌍으로 이용하여 학습될 수 있다. 예를 들어, 제2 신경망 모델은 제2 음성에 대응되는 제2 텍스트 데이터가 입력되면, 기 정의된 복수의 카테고리 각각 에 대응되는 확률 정보를 출력하도록 학습될 수 있다. 예를 들어,\"희망 온도를 최저로 선택해주세요\"라는 제2 음성에 대응되는 데이터에 기초하여 제2 신경망 모델은 제2 음성에 대응되는 데이터의 카테고리 정보 및 확률 값을 \"에어컨 냉방 고장(카테고리 ID: 2000), 확률 값 0.9\", \"창문 열림(카테고리 ID: 1010), 확률 값 0.1\" 등으로 출력할 수 있다. 이 경우, 전자 장치는 가장 높은 확률 값에 기초하여 제2 음성에 대응되는 데이터의 카테고리 정보(제2 카 테고리 정보)를 획득할 수 있다(S255). 예를 들어, 전자 장치는 \"에어컨 냉방 고장(카테고리 ID: 2000)\"을 획득할 수 있다. 제2 음성에 대응되는 데이터의 카테고리 정보를 획득하는 S255 단계에 대하여는 도 3에서 자세 히 설명하도록 한다. 이하에서는 설명의 편의를 위하여 제1 음성에 대응되는 데이터의 카테고리 정보를 제1 카테고리 정보, 제2 음성 에 대응되는 데이터의 카테고리 정보를 제2 카테고리 정보라고 명명하도록 한다. 전자 장치는 제1 신경망 모델 및 제2 신경망 모델로부터 출력된 제1 카테고리 정보 및 제2 카테고리 정보 를 비교할 수 있다(S260). 여기서, 제1 신경망 모델의 입력 데이터는, 제1 음성에 대응되는 제1 텍스트 데이터 이고, 제2 신경망 모델의 입력 데이터는 제2 음성에 대응되는 제2 텍스트 데이터이므로, 제1 신경망 모델 및 제 2 신경망 모델로부터 출력되는 카테고리 정보는 별개의 독립적인 정보일 수 있다. 제1 카테고리 정보 및 제2 카테고리 정보가 동일한 경우(S260-Y), 제1 신경망 모델이 해당 녹음 데이터에 대응 되는 올바른 카테고리 정보를 출력한 것으로 식별하여 해당 녹음 데이터를 제1 신경망 모델의 학습 데이터로 이 용할 필요가 없다. 이에 따라, 전자 장치는 해당 녹음 데이터를 제1 신경망 모델의 학습에서 제외할 수 있 다(S265). 하지만, 제1 카테고리 정보 및 제2 카테고리 정보가 상이한 경우(S260-N), 제1 신경망 모델이 해당 녹음 데이터 에 기초한 적절한 학습이 수행되지 않은 것으로 판단하여 해당 녹음 데이터를 제1 신경망 모델의 학습에 이용할수 있다(S270). 구체적으로, 전자 장치는 제1 음성에 대응되는 제1 텍스트 데이터 및 제2 카테고리 정보에 기초하여 제1 신경망 모델을 학습시킬 수 있다. 다시 말해, 제2 신경망 모델은 이미 학습이 잘 이루어져 제1 신경망 모델보다 정확한 카테고리 정보를 출력한다는 전제 하에 제2 카테고리 정보가 제1 신경망 모델로부터 출력된 제1 카테고 리 정보에 비해 상대적으로 정확도가 높은 것으로 판단하고, 제1 음성에 대응되는 제1 텍스트 데이터 및 제2 카 테고리 정보를 각각 입출력 데이터로 하여 제1 신경망 모델을 학습시킬 수 있다. 예를 들어, 녹음 데이터에 \"갑 자기 에어컨에서 찬바람이 안나와요\"라는 질의 내용 및 \"희망 온도를 최저로 선택해주세요\"라는 답변 내용이 포 함된 경우를 상정하도록 한다. 이 경우, 제1 음성에 대응되는 데이터는 \"갑자기 에어컨에서 찬바람이 안나와 요\"이고, 제2 음성에 대응되는 데이터는 \"희망 온도를 최저로 선택해주세요\"일 수 있다. 상기와 같은 예시에서, \"갑자기 에어컨에서 찬바람이 안나와요\"라는 제1 음성에 대응되는 텍스트 데이터를 제1 신경망 모델에 입력하여 \"에어컨 팬(fan) 문제(카테고리 ID: 2050)\"라는 카테고리 정보를 획득하고, \"희망 온도 를 최저로 선택해주세요\"라는 제1 음성에 대응되는 텍스트 데이터를 제2 신경망 모델에 입력하여 \"에어컨 냉방 고장(카테고리 ID: 2000)\"이라는 카테고리 정보를 획득하였다고 가정한다. 이 경우, 질의 내용에 대한 제1 카테 고리 정보 및 답변 내용에 대한 제2 카테고리 정보가 상이한 경우에 해당될 수 있다. 이 경우, 제2 신경망 모델 은 답변 내용의 카테고리를 잘 분류하도록 기 학습되어, 녹음 데이터에 포함된 답변 내용에 대해서도 신뢰도가 높은 카테고리 정보를 출력하는 것으로 가정하고, 제1 신경망 모델 및 제2 신경망 모델로부터 획득된 카테고리 정보가 상이한 경우, 제2 카테고리 정보에 기초하여 제1 신경망 모델을 학습시킬 수 있다. 다시 말해, 전자 장치는 제1 음성에 대응되는 데이터 및 제2 카테고리 정보에 기초하여 제1 신경망 모델을 학습시켜, 이후에는 제1 음성에 \"갑자기 에어컨에서 찬바람이 안나와요\"라는 음성이 포함되는 경우 제1 신경망 모델은 \"에어컨 팬(fan) 문제(카테고리 ID: 2050)\"에 해당되는 카테고리 정보가 아닌 \"에어컨 냉방 고장(카테고 리 ID: 2000)\"에 해당되는 카테고리 정보를 출력할 수 있다. 이에 따라, 고객이 \"에어컨 냉방에 문제가 있어 요\"라고 \"에어컨 냉방 문제(카테고리 ID: 2000)\"에 대응되는 키워드를 직접적으로 언급하는 질의뿐만 아니라 \" 갑자기 에어컨에서 찬바람이 안나와요\"라고 질의하는 경우에도 해당 질의가 \"에어컨 냉방 문제(카테고리 ID: 2000)\"로 분류되도록 제1 신경망 모델이 학습될 수 있으므로, \"갑자기 에어컨에서 찬바람이 안나와요\"라는 질의 에 대해 에어컨 냉방 문제(카테고리 ID: 2000)\"에 대응되는 답변을 제공할 수 있게 된다. 한편, 상술한 제1 신경망 모델 및 제2 신경망 모델 각각은 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중 치들은 신경망 모델의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 신경망 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 업데이트될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네 트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 한편, 제1 신경망 모델 및 제2 신경망 모델의 출력 부분은 softmax 처리가 가능하도록 구현될 수 있다. 여기서, softmax 는 입력받은 값을 0 ~ 1 사이 값으로 모두 정규화하며 출력 값들의 총합을 항상 1로 만드는 함수로, 각 class 별 확률 값을 출력하는 기능을 할 수 있다. 또한, 제1 신경망 모델 및 제2 신경망 모델의 출력 부분은 Argmax 처리가 가능하도록 구현될 수 있다. Argmax 는 다수의 label 중에서 가장 가능성 높은 것을 선택해 주는 함수로, 여기에서는 각 class 별 확률 값을 확률 값 중 가장 큰 값을 가지는 비율을 선택해주는 기능을 할 수 있다. 즉, 제1 신경망 모델 및 제2 신경망 모델 각각의 출력 부분이 Argmax 처리되어 있는 경우, 가장 높은 확 률 값을 가지는 하나의 카테고리 정보 만이 출력될 수 있게 된다. 또한, 제1 신경망 및 제2 신경망 모델은 다양한 학습 알고리즘을 통해 전자 장치 또는 별도의 서버/시스템 을 통해 학습된 것일 수 있다. 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기를 훈련시 켜 소정의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 방법이다. 학습 알고리즘의 예로는, 지 도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으며, 본 개시에서의 학습 알고리즘은 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 한편, 상술한 실시 예들을 통해 제1 신경망 모델이 충분하게 학습된 이후에는, 제1 신경망 모델은 일 예로 챗봇 (chatbot) 기능에 이용될 수 있다. 구체적으로, 챗봇(chatbot) 기능을 수행하는 장치는, 제1 신경망 모델을 통 해 고객의 질의 내용에 대응되는 카테고리 정보를 식별하고, 식별된 카테고리 정보에 대응되는 답변 내용을 메 모리로부터 획득하여 제공할 수 있다. 이 경우, 메모리에는 각 카테고리 정보에 대응되는 답변 내용의 샘플들이 기 저장되어 있을 수 있다. 상술한 바와 같이 일 실시 예에 따라 학습된 제1 신경망 모델은 챗봇 기능에 포함되어 이용되지만, 제2 신경망 모델은 챗봇(chatbot) 기능에 이용되지 않을 수 있다. 이하에서는 도 3을 참고하여 제2 신경망 모델을 이용하여 제2 카테고리 정보를 획득하는 구체적 방법에 대해 설명하도록 한다. 도 3은 본 개시의 일 실시 예에 따른 제2 카테고리 정보를 획득하는 과정을 설명하기 위한 도면이다. 도 3은 도 2의 제2 카테고리 정보를 획득하는 S255 단계를 구체적으로 설명하기 위한 도면이다. 상술한 바와 같이, 본 개시의 다양한 실시 예들은 제2 음성(예를 들어, 상담사의 음성)에 대응되는 제2 텍스트 데이터에 포함된 답변 내용은 질의 내용에 대한 올바른 정답으로 전제하고 제2 음성에 대한 제2 카테고리 정보 또한 제1 카테고리 정보에 비해 정확도가 높은 정보라고 전제하는 것에 기초한다. 이는 고객 별로 질의를 하는 형태, 질의를 하기 위한 표현 등이 매우 다양한 반면, 상담사의 답변 내용은 기설정된 매뉴얼(manual) 데이터에 따라 제공되므로 답변 내용의 형태 또는 답변 내용에 대한 표현의 다양성이 질의에 비해 상대적으로 작기 때문 에 제2 카테고리 정보가 제1 카테고리 정보에 비해 정확도가 높은 정보라고 전제할 수 있다. 다시 말해, 제1 신 경망 모델은 제2 카테고리 정보에 기초하여 학습되므로 정확한 제2 카테고리 정보를 획득하는 것이 중요하다. 제2 카테고리 정보는 하기의 다양한 단계를 통해 획득될 수 있다. 전자 장치는 제2 음성에 대응되는 제2 텍스트 데이터가 획득되면(S305), 제2 텍스트 데이터에 포함된 문장 을 구분할 수 있다(S310). 여기서, 문장이란 완결된 내용을 나타내는 최소 단위를 의미한다. 다만, 이에 한정되 는 것은 아니며, 의도를 기준으로 제2 텍스트 데이터가 구분되는 등 다양한 기준에 의해 구분될 수 있음은 물론 이다. 이하에서는 설명의 편의를 위해 제2 텍스트 데이터가 문장을 기준으로 구분된 것으로 설명한다. 전자 장치는 제2 음성에 대응되는 제2 텍스트 데이터에 포함된 복수의 문장 각각에 대응되는 텍스트 데이 터를 제2 신경망 모델에 순차적으로 입력할 수 있다. 구분된 각 문장이 제2 신경망 모델에 입력되면, 제2 신경망 모델은 각 문장 별 카테고리 정보 및 카테고리 정보 에 대응되는 확률 값을 출력할 수 있다(S315). 예를 들어, 제2 텍스트 데이터에 \"환기해주세요\", \"송풍을 켜세요\"가 포함된 경우를 상정한다. 전자 장치 는 제2 텍스트 데이터에 포함된 \"환기해주세요\", \"송풍을 켜세요\" 각각을 제2 신경망 모델에 입력하여 각각에 대한 카테고리 정보 및 확률 값을 획득할 수 있다. 예를 들어, \"환기해주세요\"라는 문장의 카테고리 정보 및 확 률 값은 \"가스 누출 문제(카테고리 ID: 3000), 확률 값 0.78\", \"에어컨 냄새 문제, 확률 값 0.19\" 등으로 분류 될 수 있다. 이 경우, 전자 장치는 가장 높은 확률 값에 기초하여 \"환기해주세요\"라는 문장의 카테고리 정 보를 \"가스 누출 문제(카테고리 ID: 3000)\"로 획득할 수 있다. 이와 같이, 획득된 각 문장의 카테고리 정보 및 확률 값에 기초하여, 전자 장치는 각 문장에 대응되는 카 테고리 정보의 확률 값이 임계값 이상인지 여부를 식별할 수 있다(S320). 전자 장치는 획득된 각 확률 값 이 임계값 이상이면(S320-Y), 획득된 각 카테고리 정보를 대응되는 각 문장의 제2 카테고리 정보로 획득할 수 있다(S325). 다시 말해, 전자 장치는 획득된 카테고리 정보를 제2 카테고리 정보로 식별할 수 있다. 일 예로, 임계값이 0.7이며, \"환기해주세요\"는 \"가스 누출 문제\"에 대한 카테고리 정보로 분류되고 확률 값이 0.78이고 \"송풍을 켜세요\"는 \"에어컨 팬(fan)문제\"에 대한 카테고리 정보로 분류되고 확률 값이 0.9인 경우를 상정한다. 이 경우, 각 문장의 확률 값이 모두 임계값 이상이므로 전자 장치는 \"환기해주세요\"는 \"가스 누 출 문제(카테고리 ID: 3000)\"에 대한 카테고리 정보이고 \"송풍을 켜세요\"는 \"에어컨 팬(fan)문제(카테고리 ID: 2050)\"에 대한 카테고리 정보로 식별하여 서로 다른 카테고리 정보로 식별할 수 있다. 또는, 획득된 각 문장에 대응되는 카테고리 정보의 확률 값이 임계값 미만이면(S320-N), 전자 장치는 복수 의 문장 중 적어도 일부를 조합하고(S330), 조합된 문장을 제2 신경망 모델에 입력할 수 있다. 예를 들어, 제2 텍스트 데이터에 포함된 \"환기해주세요\"는 \"에어컨 냄새 문제\"에 대한 카테고리 정보로 분류되 고 확률 값이 0.5이고, \"송풍을 켜세요\"도 \"에어컨 냄새 문제\"에 대한 카테고리 정보로 분류되고 확률 값이 0.65인 경우를 상정한다. 이 경우, 각 문장의 확률 값이 모두 임계값 미만이므로 전자 장치는 \"환기해주세요. 송풍을 켜세요\"와 같이 문장을 조합하고 조합된 문장을 제2 신경망 모델에 입력할 수 있다. 제2 신경망 모델은 조합된 문장에 대응되는 카테고리 정보 및 확률 값을 출력할 수 있다(S335). 전자 장치는 조합된 문장에 대응되는 카테고리 정보의 확률 값이 임계값 이상인지 여부를 식별할 수 있다 (S340). 조합된 문장에 대한 확률 값이 임계값 이상이면, 획득된 카테고리 정보를 조합된 문장의 제2 카테고리 정보로 획득할 수 있다(S345). 다시 말해, 전자 장치는 획득된 카테고리 정보를 제2 카테고리 정보로 식별 할 수 있다. 예를 들어, 조합된 문장인 \"환기해주세요. 송풍을 켜세요\"는 \"에어컨 냄새 문제(카테고리 ID: 1500)\"에 대한 카 테고리 정보로 분류되고 확률 값이 0.85인 경우를 상정한다. 이 경우, 조합된 문장에 대한 확률 값이 임계값(예 를 들어, 0.7) 이상이므로, 전자 장치는 획득된 카테고리 정보(에어컨 냄새 문제(카테고리 ID: 1500))를 제2 카테고리 정보로 식별할 수 있다. 다시 말해, \"환기해주세요. 송풍을 켜세요\"는 각 문장이 결합된 것으로서 하나의 질의 내용에 대응되는 하나의 답변 내용으로 식별될 수 있다. 일 실시 예에 따라 전자 장치는 S325 단계에서 획득된 카테고리 정보가 동일한 문장들만 조합을 하고 조합 된 문장을 제2 신경망 모델에 입력하여 확률 값을 획득할 수 있다. 예를 들어, \"환기해주세요\"라는 문장의 카테 고리 정보가 \"가스 누출 문제(카테고리 ID: 3000)\"로 분류되고, \"송풍을 켜세요\"라는 문장의 카테고리 정보는 \"에어컨 팬(fan)문제(카테고리 ID: 2050)\"로 분류되어 각 문장이 서로 다른 카테고리 정보인 경우, 해당 문장 들은 조합 대상이 되지 않을 수 있다. 상술한 바와 같이 서로 다른 문장의 카테고리 정보가 동일하나 각 문장의 카테고리 정보의 확률 값이 임계값 미만이어서 해당 텍스트 데이터가 학습에서 제외된 경우에도, 해당 문장들이 조합된 문장의 카테고리 정보의 확률 값이 임계값 이상이 되는 경우, 해당 조합된 문장에 대한 카테고리 정보와 관련된 제1 카테고리를 이용해 제1 신경망 모델의 학습에 이용될 수 있다. 다만, 경우에 따라 각 문장에 대한 카테고리 정보가 상이한 경우에도 해당 문장들을 조합할 수 있고, 조합된 문 장의 카테고리 정보의 확률 값이 조합하기 전의 각 문장의 카테고리 정보의 확률 값보다 큰 경우, 전자 장치 는 조합된 문장에 대한 카테고리 정보와 관련된 제1 카테고리를 이용해 제1 신경망 모델의 학습에 이용할 수 있다. 한편, 전자 장치는 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 연결어가 포함된 경우, 연 결어의 타입 또는 횟수 중 적어도 하나에 기초하여 획득된 문장에 대응되는 카테고리 정보의 확률 값에 가중치 를 적용할 수 있다. 여기서, 연결어란 각 문장을 자연스럽게 이어주는 역할을 하는 어구이며, 예를 들어 연결어 는 접속어로 표현될 수 있다. 또한, 연결어의 타입이란 \"따라서, 그래서\"와 같은 순접 연결어, \"다만, 그러나\" 와 같은 역접 연결어가 포함될 수 있다. 다시 말해, 연결어는 두 문장이 서로 연관되어 있음을 나타내는 것이므 로 두 문장이 조합된 경우, 전자 장치는 두 문장에 대응되는 카테고리 정보에 대한 확률 값에 가중치를 부 여하는 것이 바람직하다. 또한, 경우에 따라서 제2 텍스트 데이터에 연결어로 연결된 복수의 문장이 포함된 경우, 전자 장치는 각 문장의 카테고리 정보 및 확률 값을 획득하지 않고 바로 연결어로 연결된 복수의 문장 즉, 조합된 문장에 대한 카테고리 정보 및 확률 값을 획득할 수도 있다. 한편, 전자 장치는 답변 정보에 대한 고객의 피드백 정보에 기초하여 해당 답변 정보와 연관된 제1 음성 또는 텍스트 데이터를 학습 데이터로 이용하여 제1 신경망 모델을 학습시킬지 여부를 결정할 수 있다. 예를 들 어, 제1 음성 또는 제1 텍스트 데이터와 매칭되는 제2 음성 또는 제2 텍스트 데이터의 제2 카테고리 정보가 제2 신경망 모델을 통해 출력되고 제2 카테고리 정보에 따른 답변 정보가 제공되었으나, 고객이 답변 정보에 대해 부정적인 피드백이 있는 경우 전자 장치는 제1 음성 또는 제1 텍스트 데이터에 제2 카테고리 정보가 대응 되지 않는 것으로 식별하여 제1 음성 또는 제1 텍스트 데이터, 및 제2 카테고리 정보에 기초하여 제1 신경망 모 델을 학습시키지 않을 수 있다. 다시 말해, 전자 장치는 고객의 피드백 정보에 기초하여 제1 신경망 모델 을 학습시킬 학습 데이터를 결정할 수 있다. 도 4는 본 개시의 일 실시 예에 따른 제1 음성과 제2 음성의 대응 관계를 설명하기 위한 도면이다. 상술한 바와 같이, 본 개시의 다양한 실시 예에 따르면, 전자 장치는 제1 음성에 대응되는 제1 카테고리 정보 및 제2 음성에 대응되는 제2 카테고리 정보를 비교하여 제1 신경망 모델을 학습시킨다. 이 경우, 제1 카테 고리 정보의 제1 음성 및 제2 카테고리 정보의 제2 음성은 서로 매칭되는 질의 내용 및 대답 내용이어야 한다. 다시 말해, 비교의 대상이 되는 제2 음성은 제1 음성에 대응되는 답변 정보가 포함된 음성인 경우에 제1 음성 및 텍스트가 제1 신경망 모델을 학습시키기 위한 학습 데이터로 이용될 수 있다. 이하에서는 전자 장치가제1 음성과 매칭되는 제2 음성을 식별하는 실시 예에 대해 설명한다. 도 4는 녹음 데이터에 포함된 제1 음성 및 제2 음성이 구분되어 표시된 도면이다. 시간의 흐름에 따라 표시되고, 각 음성이 발화되는 시간 동안은 실선으로 표시되며, 제1 음성은 질의 형태이고 제2 음성은 대답 형 태로 필터링된 경우를 상정한다. 일 실시 예에 따르면, 전자 장치는 각 음성의 발화 시점에 기초하여 제1 음성 및 제2 음성을 매칭할 수 있 다. 구체적으로, 전자 장치는 제1 음성 이후에 발화된 제2 음성을 제1 음성에 매칭되는 후보 군으로 식별 할 수 있다. 상담사의 대답 정보는 고객의 질의 이후에 발화되기 때문이다. 일 실시 예에 따르면, 전자 장치는 도 4의 첫번째 제1 음성 및 두번째 제1 음성 사이에 발화된 복수의 제2 음성(411, 412, 413)을 첫번째 제1 음성에 매칭되는 음성으로 식별할 수 있다. 또한, 전자 장 치는 도 4의 두번째 제1 음성 이후에 발화된 복수의 제2 음성(421, 422)을 두번째 제1 음성에 매칭되는 음성으로 식별할 수 있다. 이후, 전자 장치는 도 3의 단계와 같이 복수의 제2 음성(411, 412, 413)이 하나의 카테고리 정보를 갖는 결합된 것으로서 하나의 답변 내용인지 각각의 카테고리 정보를 갖는 별개 인지 여부를 식별할 수 있다. 다른 실시 예에 따르면, 전자 장치는 각 음성의 발화 시점 및 각 음성의 관련성 여부를 식별하여 매칭되는 제1 음성 및 제2 음성을 획득할 수 있다. 예를 들어, 전자 장치는 도 4의 첫번째 제1 음성 및 두번째 제1 음성 사이에 발화된 복수의 제2 음성(411, 412, 413)을 첫번째 제1 음성에 매칭되는 제2 음성의 후보 군으로 식별할 수 있다. 전자 장치는 제1 음성 및 제2 음성 후보 군(411, 412, 413)의 관련성 여부를 식별할 수 있다. 일 예 로, 전자 장치는 제1 음성또는 제1 음성에 대응되는 제1 텍스트 데이터에 포함된 키워드를 추출하고, 제2 음성 후보 군(411, 412, 413) 또는 제2 음성 후보 군에 대응되는 텍스트 데이터에 포함된 키워드를 추출하 여, 두 키워드가 관련성이 있는지 여부를 식별할 수 있다. 예를 들어, 제1 음성의 키워드는 \"냄새\"이고 제2 음 성 후보 군 중 적어도 하나의 키워드가 \"환기\"인 경우, 전자 장치는 \"냄새\"와 \"환기\"는 관련된 키워드로 식별하여 제1 음성 및 제2 음성이 매칭되는 것으로 판단할 수 있다. 키워드 간 관련성은 인공지능 모델을 통해 식별되거나, 외부 서버를 통해 식별될 수 있다. 또는, 전자 장치는 메모리에 저장된 단어 간 관련성 정보 에 기초하여 키워드 간 관련성 여부를 식별할 수도 있다. 마찬가지로, 전자 장치는 도 4의 두번째 제1 음성 및 두번째 제1 음성 이후에 발화된 복수의 제 2 음성(421, 422)을 두번째 제1 음성에 매칭되는 제2 음성의 후보 군으로 식별할 수 있다. 전자 장치(10 0)는 두번째 제1 음성 및 제2 음성 후보 군(421, 422)의 관련성이 없는 것으로 식별되면, 두번째 제1 음성 및 제2 음성 후보 군(421, 422)을 제1 신경망 모델을 학습시키기 위한 학습 데이터에서 제외할 수 있다. 한편, 두번째 제1 음성이 질의 형태가 아닌 것으로 식별되면, 전자 장치는 첫번째 제1 음성 이 후에 발화된 복수의 제2 음성(411, 412, 413, 421, 422)을 첫번째 제1 음성에 매칭되는 후보 군으로 식별 할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 전자 장치는 메모리 및 프로세서를 포함할 수 있다. 메모리는 프로세서와 전기적으로 연결되며, 본 개시의 다양한 실시 예를 위해 필요한 데이터를 저장 할 수 있다. 메모리는 데이터 저장 용도에 따라 전자 장치에 임베디드된 메모리 형태로 구현되거나, 전자 장치 에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 전자 장치의 구동을 위한 데이터의 경우 전자 장치에 임베디드된 메모리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드된 메모리의 경우 휘 발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이 브(solid state drive(SSD)) 중 적어도 하나로 구현되고, 전자 장치에 탈부착이 가능한 메모리의 경우 메 모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결 가능한 외부 메 모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 일 실시 예에 따라, 메모리는 제1 신경망 모델, 제2 신경망 모델, 음성 인식 모델을 저장할 수 있다. 여기서, 제1 신경망 모델은 제1 음성 또는 제1 음성에 대응되는 제1 텍스트 데이터의 적어도 하나 이상의 카테 고리 정보 및 확률 값을 출력하는 모델이며, 제2 신경망 모델은 제2 음성 또는 제2 음성에 대응되는 제2 텍스트 데이터의 적어도 하나 이상의 카테고리 정보 및 확률 값을 출력하는 모델일 수 있다. 제1 신경망 모델과 제 2신 경망 모델은 카테고리 정보를 알 수 없다고 출력할 수도 있다. 이 때 카테고리 정보는 \"알 수 없음\"이다. 또한, 음성 인식 모델은 사용자의 음성을 인식하여 텍스트로 출력하는 모델로 ASR(Automatic Speech Recognition) 모 델로 구현될 수 있다. 구체적으로, 음성 인식 모델은 제1 음성을 제1 음성에 대응되는 제1 텍스트 데이터로 출 력하며, 제2 음성을 제2 음성에 대응되는 제2 텍스트 데이터로 출력할 수 있다. 다만, 이에 한정되는 것은 아니 며, 음성 인식 모델이 메모리에 구비되지 않은 경우, 제1 음성 및 제2 음성에 대한 음성 인식은 외부 장치, 외부 서버 등에서 수행되고, 전자 장치는 외부로부터 제1 음성 및 제2 음성에 대응되는 제1 텍스트 데이터 및 제2 텍스트 데이터를 수신하는 것도 가능하다. 또한, 메모리는 제2 음성과 관련된 음성 프로파일 정보를 저장할 수 있다. 여기서, 음성 프로파일 정보는 상담사의 음성에 대한 파형 정보, 삼당사의 이름 등을 포함하는 음성 식별 정보 등을 포함할 수 있다. 또한, 메모리는 각 카테고리 정보에 대응되는 답변 내용의 샘플 정보를 저장할 수 있다. 구체적으로, 학습 된 제1 신경망 모델을 통해 제1 음성의 카테고리 정보가 식별되는 경우, 프로세서의 제어에 따라 메모리 에 저장된 답변 내용이 단말 장치의 스피커를 통해 제공될 수 있다. 프로세서는 메모리와 전기적으로 연결되며, 전자 장치의 전반적인 동작을 제어한다. 프로세서 는 메모리에 저장된 각종 명령어 또는 프로그램을 이용하여 전자 장치의 동작을 전반적으로 제 어한다. 특히, 일 실시 예에 따르면, 메인 CPU가 ROM에 저장된 명령어에 따라 프로그램을 RAM에 복사하고, RAM 에 액세스하여 해당 프로그램을 실행시킬 수 있다. 여기서, 프로그램은 인공지능 모델 등을 포함할 수 있다. 프로세서는 메모리에 저장된 제1 신경망 모델, 제2 신경망 모델, 음성 인식 모델 등을 프로세서(12 0)로 로드(Load)할 수 있다. 예를 들어, 프로세서는 제1 신경망 모델을 학습시키기 위해 프로세서 외 부의 메모리에 저장된 제1 신경망 모델을 프로세서 내부 메모리(미도시)로 로드할 수 있다. 또한, 프 로세서는 메모리에 저장된 음성 인식 모델을 프로세서 내부 메모리에 로드하고, 로드된 음성 인 식 모델에 액세스하여 음성 인식을 수행할 수 있다. 도 6은 본 개시의 일 실시 예에 따른 제2 신경망 모델을 학습시키는 과정을 설명하기 위한 도면이다. 제2 신경망 모델은 제2 텍스트 데이터의 적어도 하나 이상의 카테고리 정보 및 확률 값을 출력하는 모델이다. 다시 말해, 제2 신경망 모델은 상담사의 음성(제2 음성)에 대응되는 텍스트 데이터의 카테고리 정보를 출력하는 모델이므로, 제2 신경망 모델은 상담사의 음성과 관련된 데이터에 기초하여 학습될 수 있다. 구체적으로, 전자 장치는 제2 음성에 대응되는 제2 텍스트 데이터에 포함된 짧은 텍스트, 긴 텍스트 등에 기초하여 제2 신경망 모델을 학습시킬 수 있다. 예를 들어, 전자 장치가 \"에어컨 냄새 문제(카테고리 ID: 1500)\"의 카테고리 정보에 관하여 제2 신경망 모 델을 학습시키는 경우를 상정한다. 일 예로, 전자 장치는 제2 텍스트 데이터에 포함된 짧은 텍스트인 \"환기 후 사용하세요\"를 입력 데이터로 이용하고, 이에 따른 출력 데이터를 \"에어컨 냄새 문제(카테고리 ID: 1500)\"로 하여 제2 신경망 모델을 학습시 킬 수 있다. 또는, 전자 장치는 제2 텍스트 데이터에 포함된 긴 텍스트인 \"에어컨은 실내 공기를 흡입하여 시원한 공기로 교환한 후 다시 배출하는 공기 순환 방식을 이용합니다. 때문에 배출되는 공기에쪋\"를 입력 데이 터로 이용하고, 이에 따른 출력 데이터를 \"에어컨 냄새 문제(카테고리 ID: 1500)\"로 하여 제2 신경망 모델을 학 습시킬 수 있다. 이에 따라, 제2 신경망 모델은 입력되는 제2 텍스트 데이터에 \"환기 후 사용하세요\" 또는 \"에 어컨은 실내 공기를 흡입하여 시원한 공기로 교환한 후 다시 배출하는 공기 순환 방식을 이용합니다. 때문에 배 출되는 공기에쪋\"가 포함된 경우, 이에 대응되는 카테고리 정보로서 \"에어컨 냄새 문제(카테고리 ID: 1500)\"를 출력하도록 학습될 수 있다. 다른 예로, 전자 장치는 제2 음성에 대응되는 제2 텍스트 데이터가 아니더라도 상담사가 대답 정보로서 제 공한 다양한 형태의 데이터를 이용하여 제2 신경망 모델을 학습시킬 수 있다. 예를 들어, 전자 장치는 에어컨 필터 교체 방법에 관한 이미지를 입력 데이터로 이용하고, 이에 따른 출력 데이터를 \"에어컨 냄새 문제(카 테고리 ID: 1500)\"로 하여 제2 신경망 모델을 학습시킬 수 있다. 이에 따라, 제2 신경망 모델은 입력 데이터가 에어컨 필터 교체 방법에 관한 이미지인 경우, 이에 대응되는 카테고리 정보로서 \"에어컨 냄새 문제(카테고리 ID: 1500)\"를 출력할 수 있다. 또 다른 예로, 상담사가 고객의 질의에 대응하여 에어컨 냄새 문제의 대응 방법에 관한 동영상을 제공한 경우, 전자 장치는 동영상 데이터를 이용하여 제2 신경망 모델을 학습시킬 수 있다. 구체적으로, 전자 장치(10 0)는 동영상에서 자막(텍스트)을 추출할 수 있다. 예를 들어, 동영상에 \"에어컨 운전을 종료하셨다가 실내 환기 후 사용하시면 냄새 발생을 줄일 수 있는 점 기억해 주세요\"와 같은 텍스트가 포함된 경우, 전자 장치는 이러한 텍스트를 추출하여 제2 신경망 모델의 입력 데이터로서 이용할 수 있다. 이에 따라, 제2 신경망 모델은 입력 데이터로서 \"에어컨 운전을 종료하셨다가 실내 환기 후 사용하시면 냄새 발생을 줄일 수 있는 점 기억해 주세요\"와 같은 텍스트 또는 이러한 텍스트가 포함된 동영상이 입력되면, 이에 대응되는 카테고리 정보로서 \"에 어컨 냄새 문제(카테고리 ID: 1500)\"를 출력할 수 있다. 다시 말해, 제2 신경망 모델에 입력되는 데이터가 텍스트 데이터의 형태가 아닌 이미지, 또는 동영상인 경우에 도, 제2 신경망 모델은 이에 대응되는 카테고리 정보를 출력할 수 있다. 따라서, 제2 신경망 모델에 \"환기 후 사용하세요\", \"에어컨은 실내 공기를 흡입하여 시원한 공기로 교환한 후 다시 배출하는 공기 순환 방식을 이용합니다. 때문에 배출되는 공기에쪋\", 에어컨 필터 교체 방법에 관한 이미 지 또는 \"에어컨 운전을 종료하셨다가 실내 환기 후 사용하시면 냄새 발생을 줄일 수 있는 점 기억해 주세요\"와 같은 텍스트가 포함된 동영상이 입력되는 경우, 제2 신경망 모델은 대응되는 카테고리 정보로서 \"에어컨 냄새 문제(카테고리 ID: 1500)\"를 출력할 수 있도록 학습될 수 있다. 한편, 제2 신경망 모델은 상담사의 음성과 관련된 데이터 이외에도 답변에 대한 기설정된 매뉴얼 데이터 또는 FAQ(Frequently Asked Questions) 데이터 중 적어도 하나에 기초하여도 학습될 수 있다. 기설정된 매뉴얼 데이 터 또는 FAQ 데이터는 이미 카테고리 정보가 분류된 데이터이므로, 별도로 카테고리 정보를 획득하는 단계를 수 행할 필요가 없다. 따라서, 전자 장치는 답변 매뉴얼 데이터를 입력 데이터로 이용하고, 이에 대한 카테고 리 정보를 출력 데이터로 이용하여 제2 신경망 모델을 학습시킬 수 있다. 상술한 바와 같이, 매뉴얼 데이터 또 는 FAQ 데이터는 이미 카테고리 정보가 획득된 상태이므로 별도로 답변 내용과 카테고리 정보를 매칭시키는 과 정없이 제2 신경망 모델이 학습될 수 있다. 도 7은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 전자 장치는 녹음 데이터에 포함된 대화 내용 중 제1 음성에 대응되는 제1 데이터를 제1 신경망 모델에 입 력하여 제1 데이터의 카테고리 정보를 획득할 수 있다(S710). 여기서, 녹음 데이터는 고객 및 상담사 간 상담 내용을 포함하는 데이터이며, 제1 음성은 고객의 음성이고, 후술하는 제2 음성은 상담사의 음성일 수 있다. 전자 장치는 기 저장된 상기 제2 음성에 대응되는 데이터와 관련된 음성 프로파일 정보에 기초하여 녹음 데이터에서 제2 음성을 식별할 수 있다. 전자 장치는 대화 내용 중 제2 음성에 대응되는 제2 데이터의 카테고리 정보를 획득할 수 있다(S720). 전자 장치는 제2 음성에 대응되는 데이터를 제2 신경망 모델에 입력하여 제2 음성에 대응되는 데이터의 카 테고리 정보를 획득할 수 있다. 구체적으로, 전자 장치는 제2 음성에 대응되는 데이터에 포함된 복수의 문장 각각의 적어도 일부를 조합하 여 획득된 문장을 제2 신경망 모델에 입력하여 제2 음성에 대응되는 데이터의 카테고리 정보를 획득할 수 있다. 또한, 전자 장치는 동영상 데이터, 이미지 데이터 또는 텍스트 데이터 중 적어도 하나에서 제2 음성과 관 련된 텍스트 데이터 또는 이미지 데이터 중 적어도 하나가 획득되면, 획득된 데이터를 제2 신경망 모델에 입력 하여 제2 음성에 대응되는 데이터의 카테고리 정보를 획득할 수 있다. 전자 장치는 제1 데이터 및 제2 데이터의 카테고리 정보가 상이하면, 제2 데이터의 카테고리 정보와 제1 데이터에 기초하여 제1 신경망 모델을 학습시킬 수 있다(S730). 전자 장치는 제2 음성에 대응되는 데이터에 포함된 복수의 문장 각각에 대응되는 텍스트 데이터를 제2 신 경망 모델에 순차적으로 입력하고, 제2 신경망 모델로부터 복수의 문장 각각에 대응되는 적어도 하나의 카테고 리 정보 및 적어도 하나의 카테고리 정보에 대응되는 제1 확률 값을 획득하고, 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 대응되는 텍스트 데이터를 제2 신경망 모델에 입력하고, 제2 신경망 모델로부터 획 득된 문장에 대응되는 적어도 하나의 카테고리 정보 및 적어도 하나의 카테고리 정보에 대응되는 제2 확률 값을 획득하고, 제1 확률 값 및 제2 확률 값에 기초하여 선택된 문장 및 선택된 문장에 대응되는 카테고리 정보에 기 초하여 제1 신경망 모델을 학습시킬 수 있다. 일 예로, 전자 장치는 제1 확률 값 및 제2 확률 값 중 임계값 이상의 확률 값을 가지는 문장을 선택하고, 선택된 문장 및 선택된 문장에 대응되는 카테고리 정보에 기초하여 제1 신경망 모델을 학습시킬 수 있다. 또한, 전자 장치는 복수의 문장 각각의 적어도 일부를 조합하여 획득된 문장에 연결어가 포함된 경우, 연 결어의 타입 또는 횟수 중 적어도 하나에 기초하여 획득된 문장에 대응되는 확률 값에 가중치를 적용할 수 있다. 상술한 단계에 따라 제1 신경망 모델이 학습된 이후, 전자 장치는 사용자 음성 데이터가 입력되면, 학습된 제1 신경망 모델에 사용자 음성 데이터에 대응되는 텍스트 데이터를 입력하여, 사용자 음성 데이터에 대응되는 카테고리 정보를 획득하고, 카테고리 정보에 기초하여 사용자 음성 데이터에 대응되는 응답 정보를 획득할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 어플리케이션 형태 로 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또 는 하드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치 중 적어도 하 나의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기 기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프로세 서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인 터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않 으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어 (hardware) 또는 이들의 조합을 이용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있 다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨 어 모듈들로 구현될 수 있다. 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 다양한 실시 예들에 따른 기기의 프로세싱 동작을 수행하기 위한 컴퓨터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium) 에 저장될 수 있 다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의해 실행되었 을 때 상술한 다양한 실시 예에 따른 기기에서의 처리 동작을 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2020-0009316", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2020-0009316", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 상담사를 대신하는 전자 장치를 간략하게 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 신경망 모델의 학습을 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시 예에 따른 제2 카테고리 정보를 획득하는 과정을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시 예에 따른 제1 음성과 제2 음성의 대응 관계를 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 6은 본 개시의 일 실시 예에 따른 제2 신경망 모델을 학습시키는 과정을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
