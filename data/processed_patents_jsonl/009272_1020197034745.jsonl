{"patent_id": "10-2019-7034745", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0033874", "출원번호": "10-2019-7034745", "발명의 명칭": "변환 방법, 장치, 컴퓨터 장치 및 저장 매체", "출원인": "캠브리콘 테크놀로지스 코퍼레이션 리미티드", "발명자": "리우 샤올리"}}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "모델 변환 방법으로서,초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보를 획득하는 단계;상기 초기 오프라인 모델 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 초기 오프라인 모델의 모델속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는지 여부를 판단하는 단계;상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는 경우,상기 컴퓨터 장치의 하드웨어 속성 정보 및 기설정된 모델 변환 규칙에 따라, 상기 초기 오프라인 모델을 상기컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환하는 단계를 포함하는 것을 특징으로하는 모델 변환 방법."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 컴퓨터 장치의 하드웨어 속성 정보 및 기설정된 모델 변환 규칙에 따라, 상기 초기 오프라인 모델을 상기컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환하는 단계는:상기 컴퓨터 장치의 하드웨어 속성 정보에 따라 상기 목표 오프라인 모델의 모델 속성 정보를 확정하는 단계;상기 초기 오프라인 모델의 모델 속성 정보 및 상기 목표 오프라인 모델의 모델 속성 정보에 따라, 복수의 상기기설정된 모델 변환 규칙에서 하나를 목표 모델 변환 규칙으로서 선택하는 단계;상기 초기 오프라인 모델의 모델 속성 정보 및 상기 목표 모델 변환 규칙에 따라, 상기 초기 오프라인 모델을상기 목표 오프라인 모델로 변환시키는 단계를 포함하는 것을 특징으로 하는 모델 변환 방법."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 초기 오프라인 모델의 모델 속성 정보 및 상기 목표 오프라인 모델의 모델 속성 정보에 따라, 복수의 상기기설정된 모델 변환 규칙 중 하나를 목표 모델 변환 규칙으로서 선택하는 단계는:상기 초기 오프라인 모델의 모델 속성 정보 및 상기 목표 오프라인 모델의 모델 속성 정보에 따라, 복수의 상기기설정된 모델 변환 규칙으로부터 하나 이상의 가용 모델 변환 규칙을 선택하는 단계;상기 하나 이상의 가용 모델 변환 규칙에 대해 우선 순위를 부여하고, 우선 순위가 가장 높은 가용 모델 변환규칙을 목표 변환 규칙으로 사용하는 단계를 포함하는 것을 특징으로 하는 모델 변환 방법."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 공개특허 10-2021-0033874-3-상기 하나 이상의 가용 모델 변환 규칙에 대해 우선 순위를 부여하는 단계는:상기 가용 모델 변환 규칙을 각각 획득하고 사용하여, 상기 초기 오프라인 모델을 상기 목표 오프라인 모델의프로세스 파라미터로 변환시키는 단계;상기 가용 모델 변환 규칙 각각의 프로세스 파라미터에 따라, 하나 이상의 상기 가용 모델 변환 규칙에 대해 우선 순위를 부여하는 단계를 포함하며,상기 프로세스 파라미터는 변환 속도, 소비전력, 메모리 사용율 및 디스크 I/O 점유율로 이루어진 군으로부터선택된 하나 이상을 포함하는 것을 특징으로 하는 모델 변환 방법."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 초기 오프라인 모델의 모델 속성 정보, 상기 목표 오프라인 모델의 모델 속성 정보 및 상기 가용 모델 변환 규칙은 각각 서로 대응되게 저장되는 것을 특징으로 하는 모델 변환 방법."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1~5항 중 어느 한 항에 있어서, 상기 초기 오프라인 모델 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 초기 오프라인 모델의 모델속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는지 여부를 판단하는 상기 단계는:상기 초기 오프라인 모델의 모델 속성 정보 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 실행을 지원할 수 있다고 확정할 경우, 상기 초기 오프라인 모델의 모델 속성정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭된다고 판단하는 단계;상기 초기 오프라인 모델의 모델 속성 정보 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 실행을 지원할 수 없다고 확정할 경우, 상기 초기 오프라인 모델의 모델 속성정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는다고 판단하는 단계를 포함하는 것을 특징으로하는 모델 변환 방법."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1~5항 중 어느 한 항에 있어서, 상기의 초기 오프라인 모델을 획득하는 단계는:상기 컴퓨터 장치의 응용 소프트웨어를 통해 상기 초기 오프라인 모델 및 상기 컴퓨터 장치의 하드웨어 속성 정보를 획득하는 단계를 포함하는 것을 특징으로 하는 모델 변환 방법."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1~5항 중 어느 한 항에 있어서, 상기 방법은,공개특허 10-2021-0033874-4-상기 목표 오프라인 모델을 상기 컴퓨터 장치의 제1 메모리 또는 제2 메모리에 저장하는 단계를 더 포함하는 것을 특징으로 하는 모델 변환 방법."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 방법은,상기 목표 오프라인 모델을 획득하고 실행하는 단계를 더 포함하며,상기 목표 오프라인 모델은 오리지널 네트워크에서 오프라인 노드 각각에 대응하는 네트워크 가중치, 명령 및각 오프라인 노드와 상기 오리지널 네트워크에 있는 기타 컴퓨팅 노드 간의 인터페이스 데이터를 포함하는 것을특징으로 하는 모델 변환 방법."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "모델 변환 장치로서,초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보를 획득하도록 구성되는 획득 모듈;상기 초기 오프라인 모델 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 초기 오프라인 모델의 모델속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는지 여부를 판단하도록 구성되는 판단 모듈;상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보에 매칭되지 않을 경우,상기 컴퓨터 장치의 하드웨어 속성 정보와 기설정된 모델 변환 규칙에 따라, 상기 초기 오프라인 모델을 상기컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환하도록 구성되는 변환 모듈을 포함하는 것을 특징으로 하는 모델 변환 장치."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "프로그램을 내장한 메모리 및 프로세서를 포함하는 컴퓨터 장치로서,상기 프로세서가 상기 컴퓨터 프로그램을 실행하는 경우, 청구항 1~7 중 어느 한 항에 따른 방법의 단계를 수행하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 프로세서는 연산 유닛 및 제어기 유닛을 포함하고, 상기 연산 유닛은 메인 프로세싱 회로 및 복수의 슬레이브 프로세싱 회로를 포함하며;상기 제어기 유닛은 데이터, 기계 학습 모델 및 계산 명령을 획득하도록 구성되며;상기 제어기 유닛은 추가로 상기 계산 명령을 분석하여 복수의 연산 명령을 획득하고, 상기 복수의 연산 명령및 상기 데이터를 상기 메인 프로세싱 회로에 전송하도록 구성되며;상기 메인 프로세싱 회로는 상기 데이터, 및 상기 메인 프로세싱 회로와 상기 복수의 슬레이브 프로세싱 회로공개특허 10-2021-0033874-5-사이에서 전송되는 데이터 및 연산 명령들에 대해 전처리를 수행하도록 구성되며;상기 복수의 슬레이브 프로세싱 회로는 상기 메인 프로세싱 회로에서 전송된 데이터 및 연산 명령에 따라 중간연산을 병렬 수행하여 복수의 중간 결과를 얻고, 복수의 중간 결과를 메인 프로세싱 회로에 전송하도록 구성되며;상기 메인 프로세싱 회로는 추가로 상기 복수의 중간 결과에 대한 후속처리를 수행하여 상기 계산 명령의 계산결과를 얻도록 사용되는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2019-7034745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨터 프로그램을 내장한 컴퓨터 판독 가능 저장 매체로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행되는 경우, 청구항 1~7 중 어느 한 항에 따른 방법의 단계를 수행하는 것을 특징으로 하는 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2019-7034745", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 모델 변환 방법, 장치, 컴퓨터 장치 및 저장 매체에 관한 것으로서, 상기 방법은 초기 오프라인 모델 을 목표 오프라인 모델로 변환할 수 있다. 상기 모델 변환 방법, 장치, 컴퓨터 장치 및 저장 매체는 컴퓨터 장치 의 데이터 입력량을 크게 감소시키고, 변환 과정이 간단하여, 상기 컴퓨터 장치의 데이터 처리량을 감소시킬 수 있고, 처리 효율을 개선하고 소비전력을 감소시킬 수 있다."}
{"patent_id": "10-2019-7034745", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원 본 개시는 2018년 8월 10일자, 중국 특허 출원 제 201810913895.6호, 명칭 \"변환 방법, 장치, 컴퓨터 장치 및 저장 매체”에 기초한 우선권의 이익을 주장하며, 해당 중국 특허 출원의 문헌에 개시된 모든 내용은 본 명세서 의 일부로서 포함하고자 한다. 본 출원은 컴퓨터 기술 분야에 관한 것으로서, 구체적으로 변환 방법, 장치, 컴퓨터 장치 및 저장 매체에 관한 것이다"}
{"patent_id": "10-2019-7034745", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술의 발전으로 현재 심층 학습은 보편적이며 필수적이 되었고, 따라서 TensorFlow, MXNet, Caffe 및 PyTorch 등과 같은 확장 가능한 심층 학습 시스템이 많이 개발되었으며, 상기 심층 학습 시스템은 CPU 또는 GPU 등과 같은 프로세서에서 실행할 수 있는 다양한 신경망 모델 또는 기타 기계 학습 모델을 제공하도록 구성될 수 있다. 신경망 모델 등과 같은 기계 학습 모델을 다양한 프로세서에서 실행할 필요가 있을 경우, 신경망 모델 등 과 같은 기계 학습 모델에 대한 변환이 종종 필요하다. 종래의 변환 방법으로서, 개발자는 동일한 신경망 모델에 대해 복수의 상이한 변환 모델을 구성할 수 있고, 복 수의 변환 모델은 상이한 프로세서에 적용할 수 있으며, 실제 응용에서, 컴퓨터 장치는 상기 신경망 모델 및 그 에 대응하는 복수의 변환 모델을 동시에 수신할 필요가 있고, 사용자는 현재 컴퓨터 장치의 유형에 따라 상기 다양한 모델 중에서 하나의 모델을 선택함으로써, 상기 신경망 모델이 현재 컴퓨터 장치에서 실행될 수 있다. 하지만, 상기 변환 방법의 데이터 입력량 및 데이터 처리량은 모두 크며, 상술한 보다 큰 데이터 입력량 및 데 이터 처리량은 컴퓨터 장치의 저장 용량 및 처리 한계를 쉽게 초과하여, 컴퓨터 장치의 처리 속도가 느리게 되 거나, 심지어 정상적으로 작동하지 못하게 된다. 관련 기술의 문제점을 어느 정도 극복하기 위해, 본 출원은 변환 방법, 장치, 컴퓨터 장치 및 저장 매체를 제공 한다. 본 출원은, 초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보를 획득하는 단계; 상기 초기 오프라인 모델 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는지 여부를 판단하는 단계; 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않을 경우, 상기 컴퓨터 장치의 하드웨어 속성 정보 및 기설정된 모델 변환 규칙에 따라, 상기 초기 오프라인 모델을 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환하는 단계를 포함하는 모델 변환 방법 을 제공한다. 일 실시예에서, 상기 컴퓨터 장치의 하드웨어 속성 정보 및 기설정된 모델 변환 규칙에 따라, 상기 초기 오프라 인 모델을 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환하는 단계는: 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라 상기 목표 오프라인 모델의 모델 속성 정보를 확정하는 단계; 상기 초기 오프라인 모델의 모델 속성 정보 및 상기 목표 오프라인 모델의 모델 속성 정보에 따라, 복수의 상기 기설정된 모델 변환 규칙 중에서 하나를 목표 모델 변환 규칙으로서 선택하는 단계; 상기 초기 오프라인 모델의 모델 속성 정보 및 상기 목표 모델 변환 규칙에 따라, 상기 초기 오프라인 모델을 상기 목표 오프라인 모델로 변환시키는 단계를 포함한다. 일 실시예에서, 상기 초기 오프라인 모델의 모델 속성 정보 및 상기 목표 오프라인 모델의 모델 속성 정보에 따 라, 상기 복수의 기설정된 모델 변환 규칙 중에서 하나를 목표 모델 변환 규칙으로서 선택하는 상기 단계는: 상기 초기 오프라인 모델의 모델 속성 정보 및 상기 목표 오프라인 모델의 모델 속성 정보에 따라, 상기 복수의 기설정된 모델 변환 규칙으로부터 하나 이상의 가용 모델 변환 규칙을 선택하는 단계; 상기 하나 이상의 가용 모델 변환 규칙에 대해 우선 순위를 부여하고, 우선 순위가 가장 높은 가용 모델 변환 규칙을 목표 변환 규칙으로 사용하는 단계를 포함한다. 일 실시예에서, 상기 하나 이상의 가용 모델 변환 규칙에 대해 우선 순위를 부여하는 상기 단계는: 상기 가용 모델 변환 규칙을 각각 획득하고 사용하여, 상기 초기 오프라인 모델을 상기 목표 오프라인 모델의 프로세스 파라미터로 변환하는 단계; 여기서, 상기 프로세스 파라미터는 변환 속도, 소비전력, 메모리 사용율 및 디스크 I/O 점유율로 이루어진 군으로부터 선택된 하나 이상을 포함하며, 상기 가용 모델 변환 규칙 각각의 프로세스 파라미터에 따라, 하나 이상의 가용 모델 변환 규칙에 대해 우선 순 위를 부여하는 단계를 포함한다. 일 실시예에서, 상기 초기 오프라인 모델의 모델 속성 정보, 상기 목표 오프라인 모델의 모델 속성 정보 및 상 기 가용 모델 변환 규칙은 각각 서로 대응되게 저장된다. 일 실시예에서, 상기 초기 오프라인 모델 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 초기 오프라 인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는지 여부를 판단하는 단계는: 상기 초기 오프라인 모델의 모델 속성 정보 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 컴퓨터 장 치가 상기 초기 오프라인 모델의 실행을 지원할 수 있다고 확정할 경우, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭된다고 판단하는 단계; 상기 초기 오프라인 모델의 모델 속성 정보 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 컴퓨터 장 치가 상기 초기 오프라인 모델의 실행을 지원할 수 없다고 확정할 경우, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는다고 판단하는 단계를 포함한다. 일 실시예에서, 상기 초기 오프라인 모델을 획득하는 단계는: 상기 컴퓨터 장치의 응용 소프트웨어에 의해, 상기 초기 오프라인 모델 및 상기 컴퓨터 장치의 하드웨어 속성 정보를 획득하는 단계를 포함한다. 일 실시예에서, 상기 방법은: 상기 목표 오프라인 모델을 상기 컴퓨터 장치의 제 1 메모리 또는 제 2 메모리에 저장하는 단계를 더 포함한다. 일 실시예에서, 상기 방법은: 상기 목표 오프라인 모델을 획득하고 실행하는 단계를 더 포함하며, 여기서 상기 목표 오프라인 모델은 오리지 널 네트워크의 오프라인 노드 각각에 대응하는 네트워크 가중치, 명령 및 각 오프라인 노드와 상기 오리지널 네트워크에 있는 기타 컴퓨팅 노드 간의 인터페이스 데이터를 포함한다. 본 출원은 모델 변환 장치를 제공하며, 상기 장치는: 초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보를 획득하도록 구성되는 획득 모듈; 상기 초기 오프라인 모델 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는지 여부를 판단하도록 구성되는 판단 모듈; 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보에 매칭되지 않을 경우, 상기 컴퓨터 장치의 하드웨어 속성 정보와 기설정된 모델 변환 규칙에 따라, 상기 초기 오프라인 모델을 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환하도록 구성되는 변환 모듈을 포함한 다. 본 출원은 메모리 및 프로세서를 포함하는 컴퓨터 장치를 제공하며, 상기 메모리에는 컴퓨터 프로그램이 내장되 어 있으며, 상기 프로세서가 상기 컴퓨터 프로그램을 실행하는 경우, 상기 변환 방법의 단계들을 수행한다. 일 실시예에서, 상기 프로세서는 연산 유닛 및 제어기 유닛을 포함하고, 상기 연산 유닛은 메인 프로세싱 회로 및 복수의 슬레이브 프로세싱 회로를 포함하며; 상기 제어기 유닛은 데이터, 기계 학습 모델 및 계산 명령을 획득하도록 구성되고; 상기 제어기 유닛은 추가로 상기 계산 명령을 분석하여 복수의 연산 명령을 획득하고, 상기 복수의 연산 명령 및 상기 데이터를 상기 메인 프로세싱 회로에 전송하도록 구성되며; 상기 메인 프로세싱 회로는 상기 데이터, 및 상기 메인 프로세싱 회로와 상기 복수의 슬레이브 프로세싱 회로 사이에서 전송된 데이터, 및 연산 명령에 대해 전처리를 수행하도록 구성되며; 상기 복수의 슬레이브 프로세싱는 상기 메인 프로세싱 회로로부터 전송된 데이터 및 연산 명령에 따라 중간 연 산을 병렬 수행하여 복수의 중간 결과를 얻고, 복수의 중간 결과를 메인 프로세싱 회로에 전송하도록 구성되며; 메인 프로세싱 회로는 추가로 상기 복수의 중간 결과에 대한 후속처리를 수행하여 상기 계산 명령의 계산 결과 를 얻도록 구성된다. 컴퓨터 프로그램을 내장한 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행되는 경우, 상기 변환 방법의 단계들을 수행한다. 전술한 통상적인 설명과 하기의 상세한 설명은 예시 및 해석을 위한 것이며, 본 출원을 제한하는 것이 아니다."}
{"patent_id": "10-2019-7034745", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "여기서 예시적인 실시예에 대해 상세하게 설명될 것이며, 그 예는 첨부된 도면에 도시되어 있다. 이하의 설명에 는 첨부된 도면에 관한 경우, 별다른 표시가 없는 한, 다른 도면에서의 동일한 수자는 동일하거나 유사한 요소 를 표시한다. 이하의 예시적인 실시예에서 설명되는 실시 방법은 본 출원과 일치되는 모든 실시 방법을 나타내 는 것은 아니다. 반대로, 이들은 첨부된 청구범위에 상세히 기술되는 바와 같이, 본 출원의 일부 측면과 일치한 장치와 방법의 예일뿐이다. 도 1은 일 실시예에 따른 컴퓨터 장치의 구조 블록도이며, 상기 컴퓨터 장치는 휴대폰 또는 태블릿 컴퓨터 등과 같은 모바일 단말기, 데스크탑 컴퓨터, 태블릿 카드 또는 클라우드 서버 등과 같은 단말기로 이루어진 군으로부 터 선택된 것일 수 있다. 상기 컴퓨터 장치는 로봇, 프린터, 스캐너, 블랙박스, 네비게이터, 카메라, 비디오 카 메라, 프로젝터, 손목 시계, 모바일 스토리지, 웨어러블 설비, 교통수단, 가전제품 및/또는 의료기기로 이루어 진 군으로부터 선택된 것에 적용될 수 있다. 여기서, 교통수단은 비행기, 선박 및/또는 차량을 포함할 수 있고, 가전제품은 에어컨, 텔레비전, 전자 레인지, 냉장고, 전기 밥솥, 가습기, 세탁기, 전기 램프, 가스 스토브, 레 인지 후드를 포함할 수 있고; 의료기기는 핵자기 공명기, 초음파 기기 및/또는 심전도 기기를 포함할 수 있다. 상기 컴퓨터 장치는 프로세서, 상기 프로세서에 연결된 제1 메모리 및 제2 메모리를 포함 할 수 있다. 선택적으로, 프로세서는 CPU (Central Processing Unit, 중앙 처리 장치), GPU (Graphics Processing Unit，그래픽 처리 장치) 또는 DSP (Digital Signal Processing, 디지털 신호 처리)와 같은 범용 프로세서일 수 있으며, 상기 프로세서는 IPU (Intelligence Processing Unit, 지능 프로세서)와 같은 네 트워크 모델 프로세서일 수도 있다. 물론, 상기 프로세서는 명령 세트 프로세서, 관련 칩셋, 전용 마이크 로 프로세서(예: 전용 직접 회로(ASIC)), 또는 캐시용 온보드 메모리 등 일 수도 있다. 선택적으로, 도 2에 도시된 바와 같이, 상기 프로세서는 제어기 유닛 및 연산 유닛을 포함할 수 있다. 여기서, 제어기 유닛은 연산 유닛에 연결되고, 상기 연산 유닛은 하나의 메인 프로세싱 회로 및 복수의 슬레이브 프로세싱 회로를 포함할 수 있다. 제어기 유닛은 데이터, 기계 학습 모델 및 계산 명령을 획득하도록 구성된다. 상기 기계 학습 모델은 구체적으로 네트워크 모델을 포함할 수 있고, 상기 네트워크 모델은 신경망 모델 및/또는 비 신경망 모델일 수 있다. 또한, 제어기 유닛은 획득한 계산 명령을 분석하여 연산 명령을 얻고, 복수의 연산 명령 및 데이터를 메인 프로세싱 회로에 전송하도록 구성 된다. 메인 프로세싱 회로는 데이터, 및 상기 메인 프로세싱 회로와 복수의 슬레이브 프로세싱 회로 사이에서 전송되는 데이터 및 연산 명령들에 대해 전처리를 수행하도록 구성된다. 복수의 슬레이브 프로세싱 회로는 메인 프로세싱 회로로부터 전송된 데이터 및 연산 명령에 따라 중간 연산을 병렬 수행하여 복수의 중간 결과를 얻고, 복수의 중간 결과를 메인 프로세싱 회로에 전송하도록 구성되며; 또한 메인 프로세싱 회로는 복수의 중간 결과 에 대한 후속처리를 수행하여 계산 명령의 계산 결과를 얻도록 구성된다. 선택적으로, 상기 제어기 유닛은 명령 저장 유닛, 명령 프로세싱 유닛 및 저장 큐 유닛을 포함할 수 있으며; 명령 저장 유닛은 기계 학습 모델에 관련된 계산 명령을 저장하도록 구성되며; 명령 프 로세싱 유닛은 계산 명령을 분석하여 복수의 연산 명령을 얻도록 구성되며; 저장 큐 유닛은 명령 큐 를 저장하도록 구성된다. 상기 명령 큐는 상기 큐의 앞뒤 순서에 따라 실행하고자 하는 복수의 연산 명령 또는 계산 명령을 포함한다. 선택적으로, 상기 제어기 유닛은 의존 관계 프로세싱 유닛을 더 포함할 수 있 다. 상기 제어기 유닛은, 복수의 연산 명령이 있을 경우, 제1 연산 명령이 그 전의 제0 연산 명령과 연관 되는지 여부를 확정하고; 제1 연산 명령과 제0 연산 명령 사이에 연관 관계가 존재할 경우, 제 1 연산 명령을 명령 저장 유닛에 버퍼링시켜, 제0 연산 명령의 실행 이후에 명령 저장 유닛으로부터 제 1 연산 명령을 추출하 여 연산 유닛으로 전송하도록 구성된다. 구체적으로, 의존 관계 프로세싱 유닛이 제 1 연산 명령에 따라 제 1 연산 명령에서 필요한 데이터(예: 매트릭스)의 제 1 저장 주소 구간을 추출하고, 제 0 연산 명령에 따라 제0 연산 명령에서 필요한 매트릭스의 제0 저장 주소 구간을 추출하며; 제 1 저장 주소 구간과 제 0 저장 주소 구간이 중첩되는 영역을 갖는 경우, 제 1 연산 명령과 제 0 연산 명령 사이에 연관 관계가 있다고 확정하며; 제 1 저장 주소 구간과 제 0 저장 주소 구간이 중첩되는 영역이 없을 경우, 제 1 연산 명령과 제 0 연산 명령 사이 에 연관 관계가 없다고 확정한다. 일 실시예에서, 도3에 도시된 바와 같이, 연산 유닛은 브랜치 프로세싱 회로를 더 포함할 수 있으며, 메인 프로세싱 회로와 브랜치 프로세싱 회로는 연결되고, 브랜치 프로세싱 회로와 복수의 슬레 이브 프로세싱 회로는 연결되고; 브랜치 프로세싱 회로는 메인 프로세싱 회로와 슬레이브 프로 세싱 회로 사이의 데이터 또는 명령의 전달을 수행하도록 구성된다. 본 실시예에서, 메인 프로세싱 회로 는 구체적으로 하나의 입력 신경원을 복수의 데이터 블록으로 분할하고, 복수의 데이터 블록 중 적어도 하 나의 데이터 블록, 가중치 및 복수의 연산 명령 중 적어도 하나의 연산 명령을 브랜치 프로세싱 회로에 전송하도록 구성되며; 브랜치 프로세싱 회로는 메인 프로세싱 회로와 복수의 슬레이브 프로세싱 회로 사이의 데이터 블록, 가중치 및 연산 명령을 전달하도록 구성되며; 복수의 슬레이브 프로세싱 회로는 상기 연산 명령에 따라 수신된 데이터 블록 및 가중치에 대해 연산을 실행하여 중간 결과를 획득하고, 중간 결과를 브랜치 프로세싱 회로로 전송하도록 구성되며; 메인 프로세싱 회로는 추가로 브랜치 프로세싱 회로에 의해 전송된 중간 결과에 대해 후속처리를 수행하여 상기 계산 명령의 결과를 얻고, 상기 계산 명령의 결과를 상기 제어기 유닛으로 전송하도록 구성된다. 다른 선택적인 실시예에서, 도 4에 도시된 바와 같이, 연산 유닛은 하나의 메인 프로세싱 회로 및 복 수의 슬레이브 프로세싱 회로를 포함할 수 있다. 여기서, 복수의 슬레이브 프로세싱 회로는 어레이식으로 배열되고; 각 슬레이브 프로세싱 회로는 인접한 다른 슬레이브 프로세싱 회로에 연결되고, 메인 프로세싱 회로 는 복수의 슬레이브 프로세싱 회로 중의 k개의 슬레이브 프로세싱 회로와 연결된다. k개의 슬레이브 프로세싱 회로는, 제1 행에서 n 개의 슬레이브 프로세싱 회로, 제m 행에서 n 개의 슬레이브 프로세싱 회로 및 제1열에서 의 m 개의 슬레이브 프로세싱 회로를 포함한다. 도 1C에 도시된 바와 같이, k개의 슬레이브 프로세싱 회로는 제 1 행에서의 n개의 슬레이브 프로세싱 회로, 제m 행에서의 n 개의 슬레이브 프로세싱 회로 및 제1열에서의 m 개 의 슬레이브 프로세싱 회로만 포함하며, 즉 상기 k개의 슬레이브 프로세싱 회로는 복수의 슬레이브 프로세싱 회 로에서 메인 프로세싱 회로에 직접적으로 연결되는 슬레이브 프로세싱 회로이다. k개의 슬레이브 프로세싱 회로 는 메인 프로세싱 회로와 복수의 슬레이브 프로세싱 회로 사이의 명령 및 데이터를 전달하도록 구성된다. 선택적으로, 상기 메인 프로세싱 회로는 변환 프로세싱 회로, 활성화 프로세싱 회로 및 덧셈 프로세싱 회 로로 이루어진 군으로부터 선택된 하나 또는 임의의 조합을 포함할 수 있으며; 변환 프로세싱 회로는 메인 프로 세싱 회로에 의해 수신된 데이터 블록 또는 중간 결과에 대해 제1 데이터 구조와 제2 데이터 구조 사이의 교환 을 실행하도록 구성되고 (예를 들어, 연속 데이터와 이산 데이터의 변환); 또는 메인 프로세싱 회로에 의해 수 신된 데이터 블록 또는 중간 결과에 대해 제1 데이터 유형과 제2 데이터 유형 사이의 교환을 실행하도록 구성되 며(예를 들어, 고정 소수점 유형과 부동 소수점 유형의 변환); 활성화 프로세싱 회로는 메인 프로세싱 회로 내 의 데이터의 활성화 연산을 수행하도록 구성되며; 덧셈 프로세싱 회로는 덧셈 연산 또는 누적 연산을 수행하도 록 구성된다. 상기 제1 메모리 또는 제2 메모리는 컴퓨터 프로그램을 내장할 수 있으며, 상기 컴퓨터 프로그램은 본 출원의 실시예에 의해 제공되는 모델 변환 방법을 구현하도록 하기 위한 것이다. 구체적으로, 상기 모델 변 환 방법은, 컴퓨터 장치가 수신한 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않을 경우, 상기 초기 오프라인 모델을 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목 표 오프라인 모델로 변환하여, 상기 컴퓨터 장치가 상기 초기 오프라인 모델을 실행할 수 있도록 한다. 상기 모 델 변환 방법에서, 컴퓨터 장치의 데이터 입력량은 적으며, 인간의 개입없이 초기 오프라인 모델에서 목표 오프 라인 모델로의 변환이 자동으로 진행될 수 있음으로 하여, 변환 과정은 간단하고 변환 효율은 높다. 또한, 제 1 메모리 또는 제 2 메모리에 저장된 컴퓨터 프로그램은 본 출원의 실시예에 의해 제공되는 오프라인 모델의 생성 방법을 구현하도록 구성될 수도 있다. 선택적으로, 제 1 메모리는 네트워크 입력 데이터, 네트워크 출력 데이터, 네트워크 가중치 및 명령과 같 은 네트워크 모델의 실행과정에서의 관련 데이터를 저장하도록 사용될 수 있다. 상기 제 1 메모리는 내장 메모리일 수 있고, 예를 들어 캐시와 같은 휘발성 메모리이다. 상기 제 2 메모리는 네트워크 모델에 대응 하는 오프라인 모델을 저장하도록 사용될 수 있으며, 예를 들어 제 2 메모리는 비휘발성 메모리일 수 있다. 상기 컴퓨터 장치의 동작 원리는 다음과 같은 모델 변환 방법 중 각 단계의 실행 과정과 일치하며, 상기 컴퓨터 장치의 프로세서가 제2 메모리의 컴퓨터 프로그램을 실행할 경우, 모델 변환 방법 중의 각 단계가 구 현되며, 상세한 설명은 아래 내용을 참조할 수 있다. 물론, 다른 실시예들에서, 상기 컴퓨터 장치는 프로세서 및 하나의 메모리도 포함할 수 있으며, 상기 컴퓨터 장 치는 프로세서와 상기 프로세서에 연결된 메모리를 포함할 수 있다. 상기 프로세서는 도 2-4에 도시된 프로세서 를 채택할 수 있고, 구체적인 구조는 전술한 설명에서의 프로세서에 대한 설명을 참조할 수 있다. 상기 메 모리는 복수의 저장 유닛을 포함할 수 있고, 예를 들어, 상기 메모리는 제 1 저장 유닛, 제 2 저장 유닛 및 제 3 저장 유닛을 포함할 수 있다. 여기서, 상기 제 1 저장 유닛은 본 출원의 실시예에서 제공되는 모델 변환 방법 을 구현하기 위한 컴퓨터 프로그램을 저장하도록 사용될 수 있다. 상기 제2 저장 유닛은 오리지널 네트워크의 실행 과정에서의 관련 데이터를 저장하도록 구성될 수 있으며, 상기 제3 저장 유닛은 오리지널 네트워크에 대응하는 오프라인 모델 및 상기 오프라인 모델에 대응하는 목표 오프라인 모델, 기설정된 모델 변환 규칙 등을 저 장하도록 사용될 수 있다. 또한, 상기 메모리에 포함되는 저장 유닛의 수량은 3 개를 초과할 수 있으며, 여기서 특별히 제한하지는 않는다. 도 5를 참조하면, 본 출원의 실시예는 상기 컴퓨터 장치에 적용될 수 있는 모델 변환 방법을 제공한다. 상기 모 델 변환 방법은 컴퓨터 장치가 수신한 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속 성 정보와 매칭되지 않을 경우, 상기 초기 오프라인 모델을 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환시켜, 상기 컴퓨터 장치가 상기 초기 오프라인 모델을 실행할 수 있도록 한다. 구체 적으로, 상기 방법은 다음 단계들을 포함할 수 있다. S100단계: 초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보를 획득한다. 구체적으로, 상기 초기 오프라인 모델은 컴퓨터 장치에 의해 직접적으로 획득된 오프라인 모델을 의미하며, 상 기 초기 오프라인 모델은 제 2 메모리에 저장될 수 있다. 여기서, 오프라인 모델은 하나의 오리지널 네트 워크에서 각 컴퓨팅 노드의 네트워크 가중치 및 명령 등과 같은 필요한 네트워크 구조 정보를 포함할 수 있으며, 명령은 상기 컴퓨팅 노드가 어떤 계산 기능을 수행하는지를 나타내도록 사용될 수 있고, 구체적으로 상 기 명령은 상기 오리지널 네트워크에서 각 컴퓨팅 노드의 계산 속성 및 각 컴퓨팅 노드 간의 연결 관계 등 정보 를 포함할 수 있다. 상기 오리지널 네트워크는 신경망 모델 등과 같은 네트워크 모델일 수 있으며, 도9에 도시 된 바와 같다. 따라서, 컴퓨터 장치는 상기 오리지널 네트워크에 대응하는 오프라인 모델을 실행함으로써 상기 오리지널 네트워크의 연산 기능을 구현할 수 있고, 동일한 오리지널 네트워크에 대해 컴파일 등의 동작을 반복 적으로 수행할 필요가 없기에, 프로세서가 상기 네트워크를 실행하는 시간을 단축시켜 프로세서의 처리 속도와 효율을 향상시킬 수 있다. 선택적으로, 본 출원의 실시예에 따른 초기 오프라인 모델은 오리지널 네트워크에 의 해 직접 생성된 오프라인 모델이거나, 또는 다른 모델 속성 정보를 갖는 오프라인 모델이 1회 이상의 변환을 거 친 후 획득한 오프라인 모델일 수 있으며, 이에 구체적인 제한을 하지 않는다. S200단계: 초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보에 따라, 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는지를 판단한다. 구체적으로, 상기 초기 오프라인 모델의 모델 속성 정보는 상기 초기 오프라인 모델의 데이터 구조, 데이터 유 형 등을 포함할 수 있다. 예를 들어, 상기 모델 속성 정보는 초기 오프라인 모델에서 각 네트워크 가중치 및 명 령의 배열 방식, 각 네트워크 가중치의 유형 및 각 명령의 유형 등이다. 상기 컴퓨터 장치의 하드웨어 속성 정 보는 상기 컴퓨터 장치의 모델 번호, 상기 컴퓨터 장치가 처리할 수 있는 데이터 유형 (예: 고정 소수점 또는 부동 소수점 등), 및 데이터 구조 등을 포함한다. 컴퓨터 장치는 상기 초기 오프라인 모델의 모델 속성 정보 및 컴퓨터 장치의 하드웨어 속성 정보에 따라, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 실행을 지원할 수 있는지 (즉, 상기 컴퓨터 장치가 상기 초기 오프라인 모델을 실행할 수 있는지)를 판단함으로써, 상기 초기 오 프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는지 여부를 판단할 수 있다. 선택적으로, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 실행을 지원할 수 있는 경우, 상기 초기 오프라인 모델의 모델 속성 정보는 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 것으로 판정한다. 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 실행을 지원할 수 없는 경우, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴 퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는 것으로 판정한다. 예를 들어, 상기 컴퓨터 장치는 자체의 하드웨어 속성 정보에 따라 상기 컴퓨터 장치가 처리할 수 있는 데이터 유형 및 데이터 구조를 확정할 수 있고, 상기 초기 오프라인 모델의 모델 속성 정보에 따라 상기 초기 오프라인 모델의 데이터 유형 및 데이터 구조를 확정할 수 있다. 상기 컴퓨터 장치가 자체의 하드웨어 속성 정보 및 상기 초기 오프라인 모델의 모델 속성 정보에 따라, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 데이터 유형 및 데이터 구조를 지원할 수 있다고 확정되는 경우, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장 치의 하드웨어 속성 정보와 매칭된다고 판정할 수 있다. 상기 컴퓨터 장치가 자체의 하드웨어 속성 정보 및 상 기 초기 오프라인 모델의 모델 속성 정보에 따라, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 데이터 유형 및 데이터 구조를 지원할 수 없다고 확정되는 경우, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는다고 판정할 수 있다. 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않을 경우, 컴퓨터 장치 의 하드웨어 속성 정보 및 기설정된 모델 변환 규칙에 따라 초기 오프라인 모델을 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환하는 S300단계를 실행한다.구체적으로, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는 경우, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 실행을 지원할 수 없음을 의미하고, 이때 상기 초기 오프라인 모델에 대한 변환처리가 필요하며, 상기 컴퓨터 장치는 상기 초기 오프라인 모델를 사용하여 대응된 연산을 구현할 수 있도록 한다. 즉, 상기 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는 경우, 컴퓨터 장치의 하드웨어 속성 정보 및 기설정된 모델 변환 규칙에 따라, 상기 초기 오프라인 모델을 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환할 수 있다. 여 기서, 상기 목표 오프라인 모델의 모델 속성 정보는 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되며, 상기 컴퓨터 장치는 상기 목표 오프라인 모델의 실행을 지원할 수 있다. 전술한 바와 같이, 상기 목표 오프라인 모델 도 하나의 오리지널 네트워크에서 각 컴퓨팅 노드의 네트워크 가중치 및 명령 등과 같은 필요한 네트워크 구조 정보를 포함한다. 선택적으로, 상기 기설정된 모델 변환 규칙은 컴퓨터 장치의 제 1 메모리 또는 제2 메모리에 미리 저장될 수 있 다. 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는 경우, 컴퓨터 장치는 제 1 메모리 또는 제 2 메모리로부터 대응하는 모델 변환 규칙을 획득하여 초기 오프라인 모델을 목표 오프라인 모델로 변환시킬 수 있다. 선택적으로, 상기 기설정된 모델 변환 규칙은 하나 이상일 수 있고, 하나 이상의 모델 변환 규칙은 상기 초기 오프라인 모델 및 목표 오프라인 모델과 일대일로 대응하여 저장될 수 있다. 예를 들어, 상기 초기 오프라인 모델, 목표 오프라인 모델 및 기설정된 모델 변환 규칙은 매핑 테이블의 방식으로 대응되게 저장될 수 있다. 선택적으로, 초기 오프라인 모델의 모델 속성 정보, 목표 오프라인 모델의 모델 속성 정보 및 가용 모델 변환 규칙은 각각 서로 대응되게 저장된다. 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 경우, 컴퓨터 장치는 수 신된 초기 오프라인 모델을 직접 실행하는, 즉 컴퓨터 장치는 상기 초기 오프라인 모델에 포함된 네트워크 가중 치 및 명령에 따라 연산을 수행하여 오리지널 네트워크의 연산 기능을 구현하는 S400단계를 수행할 수 있다. 구 체적으로, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 경 우, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 실행을 지원할 수 있음을 의미하고, 이때 상기 초기 오프라 인 모델을 변환할 필요가 없으며, 컴퓨터 장치는 상기 초기 오프라인 모델을 실행할 수 있다. 본 실시예에서, 상기 초기 오프라인 모델을 직접 실행한다는 것은, 상기 초기 오프라인 모델을 이용하여 상기 오리지널 네트워 크에 대응하는 기계 학습 알고리즘(예: 신경망 알고리즘)을 실행함으로써, 포워드 연산에 의해 알고리즘의 목표 응용(예: 음성인식 등의 인공지능에서의 응용)을 구현하는 것을 의미한다. 본 출원의 실시예에 따른 모델 변환 방법에서, 컴퓨터 장치는 하나의 초기 오프라인 모델만 수신할 필요가 있고, 즉 기설정된 모델 변환 규칙 및 상기 컴퓨터 장치의 하드웨어 속성 정보에 따라 상기 초기 오프라인 모델 을 목표 오프라인 모델로 변환할 수 있으며, 복수의 상이한 모델 데이터를 획득할 필요가 없으므로, 컴퓨터 장 치의 데이터 입력량을 대폭 줄이고, 과도한 데이터 입력으로 인해 컴퓨터 장치의 저장 용량을 초과하는 문제를 피함으로써 컴퓨터 장치의 정상적인 실행을 보장할 수 있다. 한편, 상기 모델 변환 방법은 상기 컴퓨터 장치의 데이터 처리량을 감소시킴으로써 처리 효율을 개선하고 소비전력을 감소시킬 수 있다. 또한, 상기 모델 변환 과 정에서, 인간의 개입이 필요없고, 자동화 정도가 높으며, 사용이 편리하다. 선택적으로, 도 6에 도시된 바와 같이, 상기 S300단계는 다음과 같은 단계를 포함한다. S310단계: 컴퓨터 장치의 하드웨어 속성 정보에 따라 목표 오프라인 모델의 모델 속성 정보를 확정한다.구체적 으로, 상기 컴퓨터 장치는 자체의 하드웨어 속성 정보에 따라 상기 컴퓨터 장치에 의해 지원 가능한 데이터 유 형 및 데이터 구조 등을 확정할 수 있고, 따라서 목표 오프라인 모델의 데이터 유형 및 데이터 구조 등과 같은 모델 속성 정보를 확정할 수 있다. 즉, 상기 컴퓨터 장치는 자체의 하드웨어 속성 정보에 따라 목표 오프라인 모델의 모델 속성 정보를 확정할 수 있으며, 상기 목표 오프라인 모델의 모델 속성 정보는 목표 오프라인 모델 의 데이터 유형 및 데이터 구조 등 정보를 포함할 수 있다. S320단계: 초기 오프라인 모델의 모델 속성 정보 및 목표 오프라인 모델의 모델 속성 정보에 따라, 복수의 기설 정된 모델 변환 규칙에서 하나를 목표 모델 변환 규칙으로서 선택한다. 구체적으로, 초기 오프라인 모델, 목표 오프라인 모델 및 기설정된 모델 변환 규칙은 각각 서로 대응하는 매핑 관계를 가지므로, 상기 초기 오프라인 모델의 모델 속성 정보 및 목표 오프라인 모델의 모델 속성 정보에 따라 목표 모델 변환 규칙을 확정할 수 있다. 여기서, 모델 변환 규칙은 데이터 유형의 변환 방법, 데이터 구조의 변 환 방법 등을 포함할 수 있다.S330단계: 초기 오프라인 모델의 모델 속성 정보 및 목표 모델 변환 규칙에 따라, 초기 오프라인 모델을 목표 오프라인 모델로 변환시킨다. 구체적으로, 컴퓨터 장치는 상기 목표 모델 변환 규칙에 의해 제공된 변환 방법에 따라, 초기 오프라인 모델을 목표 오프라인 모델로 변환함으로써, 상기 컴퓨터 장치가 상기 목표 오프라인 모델에 대한 실행에 의해 연산을 수행하도록 한다. 선택적으로, 초기 오프라인 모델과 목표 오프라인 모델 사이에 복수의 가용 모델 변환 규칙이 있는 경우, 컴퓨 터 장치는 기설정된 알고리즘에 따라 목표 오프라인 모델을 자동으로 선택할 수 있다. 구체적으로, 전술한 S320 단계는: 초기 오프라인 모델의 모델 속성 정보 및 목표 오프라인 모델의 모델 속성 정보에 따라, 복수의 기설정된 모델 변환에서 하나 이상의 가용 모델 변환 규칙을 선택하는 단계; 하나 이상의 가용 모델 변환 규칙에 대해 우선 순위를 부여하고, 우선 순위가 가장 높은 가용 모델 변환 규칙을 목표 변환 규칙으로 사용하는 단계를 추가로 포함한다. 구체적으로, 상기 가용 모델 변환 규칙은 초기 오프라인 모델을 목표 오프라인 모델로 변환할 수 있는 변환 규 칙을 말한다. 가용 모델 변환 규칙이 하나 이상인 경우, 초기 오프라인 모델을 목표 오프라인 모델로 변환하는 방법에는 여러 가지가 있다는 것을 의미한다. 상기 우선 순위 배열 방법은 미리 설정되거나 사용자가 정의할 수 있다. 선택적으로, 컴퓨터 장치는 가용 모델 변환 규칙 각각에 대응하는 프로세스 파라미터를 획득할 수 있고, 가용 모델 변환 규칙 각각에 대응하는 프로세스 파라미터에 따라 하나 이상의 가용 모델 변환 규칙에 대해 우선 순위 를 부여할 수 있다. 여기서, 상기 프로세스 파라미터는 상기 가용 모델 변환 규칙을 이용하여 초기 오프라인 모 델을 목표 오프라인 모델로 변환할 때 관련된 컴퓨터 장치의 성능 파라미터일 수 있다. 선택적으로, 상기 프로 세스 파라미터는 변환 속도, 소비전력, 메모리 사용율 및 디스크 I/O 점유율로 이루어진 군으로부터 선택된 하 나 이상을 포함할 수 있다. 예를 들어, 컴퓨터 장치는 초기 오프라인 모델을 목표 오프라인 모델로 변환하는 과정에서의 변환 속도, 변환 소비전력, 메모리 사용율 및 디스크 I/O 점유율 등으로 이루어진 군으로부터 선택된 하나 이상의 프로세스 파라 미터의 조합에 따라, 상기 가용 모델 변환 규칙 각각에 대해 평점을 부여하고(예: 각 참고 요소에 대해 가중치 연산을 수행하여 평점을 얻는다), 평점이 가장 높은 가용 모델 변환 규칙을 우선 순위가 가장 높은 가용 모델 변환 규칙으로 사용할될 수 있다. 즉, 평점이 가장 높은 가용 모델 변환 규칙을 상기 목표 변환 규칙으로 사용 할 수 있다. 그 후, 초기 오프라인 모델의 모델 속성 정보 및 목표 모델 변환 규칙에 따라, 초기 오프라인 모델 을 목표 오프라인 모델로 변환시키는 상기 S330단계를 실행할 수 있다. 이러한 방식으로, 모델 변환 과정에서의 장치 성능 요소를 결합하여 보다 바람직한 모델 변환 규칙을 선택함으로써, 컴퓨터 장치의 처리 속도 및 효율을 향상시킬 수 있다. 선택적으로, 도 3에 도시된 바와 같이, 상기 방법은 다음과 같은 단계를 더 포함한다. S500단계: 목표 오프라인 모델을 컴퓨터 장치의 제1 메모리 또는 재2 메모리에 저장한다. 구체적으로, 컴퓨터 장치는 획득한 목표 오프라인 모델을 상기 컴퓨터 장치의 로컬 메모리(예: 제 1 메모리)에 저장할 수 있다. 선택적으로, 컴퓨터 장치는 또한 그에 의해 획득된 목표 오프라인 모델을 상기 컴퓨터 장치에 연결된 외장 메모리(예: 제2메모리)에도 저장할 수 있고, 상기 외장 메모리는 클라우드 메모리 또는 다른 메모 리 등일 수 있다. 이러한 방식으로, 상기 컴퓨터 장치가 상기 목표 오프라인 모델을 반복적으로 사용할 필요가 있는 경우, 전술한 변환 동작을 반복적으로 수행할 필요 없이, 상기 목표 오프라인 모델을 직접 판독하여 대응 하는 연산을 구현할 수 있다. 선택적으로, 컴퓨터 장치가 목표 오프라인 모델을 실행하는 상기 과정은: 목표 오프라인 모델을 획득하고 실행하여 오리지널 네트워크를 실행되는 단계를 포함할 수 있다. 여기서, 목표 오프라인 모델은 오리지널 네트워크에서 오프라인 노드 각각에 대응하는 네트워크 가중치, 명령 및 각 오프라인 노드와 오리지널 네트워크에 있는 기타 컴퓨팅 노드 간의 인터페이스 데이터 등 필요한 네트워크 구조 정보를 포함한다. 구체적으로, 컴퓨터 장치가 상기 목표 오프라인 모델을 이용하여 연산을 구현해야 하는 경우, 상기 컴퓨터 장치 는 제 1 메모리 또는 제 2 메모리로부터 직접 상기 목표 오프라인 모델을 획득할 수 있고, 목표 오프라인 모델 에 있는 네트워크 가중치 및 명령에 따라 연산을 수행함으로써 오리지널 네트워크의 연산 기능을 구현할 수 있 다. 이러한 방식으로, 상기 컴퓨터 장치가 상기 목표 오프라인 모델을 반복적으로 사용할 필요가 있는 경우, 전 술한 변환 동작을 반복적으로 수행할 필요 없이, 상기 목표 오프라인 모델을 직접 판독하여 대응하는 연산을 구 현할 수 있다. 본 실시예에서, 상기 목표 오프라인 모델을 직접 실행한다는 것은, 상기 목표 오프라인 모델을 이용하여 상기 오리지널 네트워크에 대응하는 기계 학습 알고리즘(예: 신경망 알고리즘)을 실행함으로써, 포워드 연산을 수행 하여 알고리즘의 목표 응용(예: 음성인식 등 인공지능 응용)을 구현하는 것을 의미한다. 선택적으로, 상기 컴퓨터 장치에 응용 소프트웨어 (Application)가 설치되어 있고, 컴퓨터 장치 상의 응용 소프 트웨어를 통하여 초기 오프라인 모델을 얻을 수 있다. 상기 응용 소프트웨어(Application)는 메모리 또는 외장 메모리로부터 초기 오프라인 모델을 판독하기 위한 인터페이스를 제공할 수 있기에, 상기 응용 소프트웨어 를 통해 상기 초기 오프라인 모델을 얻을 수 있다. 선택적으로, 상기 응용 소프트웨어는 컴퓨터 장치의 하드웨 어 속성 정보를 판독하기 위한 인터페이스도 제공할 수 있기에, 상기 응용 소프트웨어를 통해 상기 컴퓨터 장치 의 하드웨어 속성 정보를 얻을 수 있다. 선택적으로, 상기 응용 소프트웨어는 기설정된 모델 규칙을 판독할 수 있는 인터페이스도 제공할 수 있기에, 상기 응용 소프트웨어를 통해 기설정된 모델 변환 규칙을 얻을 수 있다. 물론, 다른 실시예에서, 상기 컴퓨터 장치는 입력/출력 인터페이스 (예: I/O 인터페이스)도 제공할 수 있고, 상 기 입력/출력 인터페이스는 초기 오프라인 모델을 획득하거나 목표 오프라인 모델을 출력하도록 사용된다. 상기 컴퓨터 장치의 하드웨어 속성 정보는 상기 컴퓨터 장치에 미리 설정하여 저장할 수 있는 것이다. 일 실시예에서, 도 7에 도시된 바와 같이, 본 출원의 실시예는 오리지널 네트워크 모델에 따라 오프라인 모델을 생성하는 방법을 제공하고, 획득한 오리지널 네트워크에 관련된 데이터에 따라 상기 오리지널 네트워크의 오프 라인 모델을 생성 및 저장함으로써, 프로세서에 의해 상기 오리지널 네트워크를 재실행 할 경우, 동일한 오리지 널 네트워크를 다시 컴파일할 필요없이, 상기 오리지널 네트워크에 대응하는 오프라인 모델을 직접적으로 실행 하여, 프로세서가 상기 네트워크를 실행하는 동작 시간을 단축하여 프로세서의 처리 속도와 효율을 향상시키도 록 구성된다. 여기서, 오리지널 네트워크는 신경망 또는 비 신경망 등과 같은 네트워크 모델일 수 있으며, 예를 들어, 오리지널 네트워크는 도9에 도시된 네트워크일 수 있다. 구체적으로, 상기 방법에는 다음과 같은 단계가 포함된다. S010단계: 오리지널 네트워크의 모델 데이터 세트 및 모델 구조 파라미터를 획득한다. 구체적으로, 컴퓨터 장치의 프로세서는 오리지널 네트워크의 모델 데이터 세트 및 모델 구조 파라미터를 획득할 수 있으며, 상기 오리지널 네트워크의 모델 데이터 세트 및 모델 구조 파라미터를 통해 상기 오리지널 네트워크 의 네트워크 구조도를 획득할 수 있다. 여기서, 모델 데이터 세트는 오리지널 네트워크에 있는 컴퓨팅 노드 각 각에 대응하는 네트워크 가중치 등과 같은 데이터를 포함하고, 도9에 도시된 신경망에서 W1~W6은 컴퓨팅 노드의 네트워크 가중치를 나타내도록 사용된다. 모델 구조 파라미터는 오리지널 네트워크에 있는 복수의 컴퓨팅 노드 의 연결 관계 및 각 컴퓨팅 노드의 계산 속성을 포함한다. 여기서, 컴퓨팅 노드 간의 연결 관계는 컴퓨팅 노드 사이에 데이터 전송이 있는지 여부를 나타내도록 구성되고, 예를 들어, 복수의 컴퓨팅 노드 사이에 데이터 스트 림의 전송이 있을 경우, 복수의 컴퓨팅 노드 간에 연결 관계가 있다고 말할 수 있다. 또한, 컴퓨팅 노드의 연결 관계는 입력 관계 및출력 관계 등을 포함할 수 있다. 도9에 도시된 바와 같이, 컴퓨팅 노드 F1의 출력은 컴퓨팅 노드 F4, F5의 입력으로서, 이는 컴퓨팅 노드 F1과 컴퓨팅 노드 F4 사이에는 연결 관계가 있고, 컴퓨팅 노드 F1 과 컴퓨팅 노드 F5 사이에도 연결 관계가 있다는 것을 말해 준다. 다른 예시로, 컴퓨팅 노드F1과 컴퓨팅 노드 F2 사이에는 데이터 전송이 없기에, 컴퓨팅 노드 F1과 컴퓨팅 노드 F2 사이에는 연결 관계가 없다고 말할 수 있 다. 각 컴퓨팅 노드의 계산 속성은 대응하는 컴퓨팅 노드의계산 유형 및 계산 파라미터를 포함할 수 있다. 여기서, 컴퓨팅 노드의 계산 유형은 상기 컴퓨팅 노드가 어떤 계산을 완료되도록 구성되는지를 의미하며, 예를 들어, 컴 퓨팅 노드의 계산 유형은 덧셈 연산, 뺄셈 연산 및 컨벌루션 연산 등을 포함할 수 있고, 따라서 상기 컴퓨팅 노 드는 덧셈 연산을 구현하기 위한 컴퓨팅 노드일 수 있고, 뺄셈 연산을 구현하기 위한 컴퓨팅 노드 또는 컨벌루 션 연산을 구현하기 위한 컴퓨팅 노드일 수 있다. 컴퓨팅 노드의 계산 파라미터는 상기 컴퓨팅 노드에 대응하는 계산 유형이 완료되기 위해 필요한 필수 파라미터일 수 있다. 예를 들어, 컴퓨팅 노드의 계산 유형은 덧셈 연산 을 구현하기 위한 컴퓨팅 노드일 수 있고, 따라서 상기 컴퓨팅 노드의 계산 파라미터는 덧셈 연산 중의 가수일 수 있으며, 상기 덧셈 연산 중의 피가수는 입력 데이터로서 획득 모듈에 의해 얻거나, 상기 덧셈 연산 중의 피가수는 상기 컴퓨팅 노드의 이전 컴퓨팅 노드의 출력 데이터일 수도 있다. S020단계: 오리지널 네트워크의 모델 데이터 세트 및 모델 구조 파라미터에 따라 오리지널 네트워크를 실행하고, 오리지널 네트워크에 있는 컴퓨팅 노드 각각에 대응하는 명령을 획득한다. 구체적으로, 컴퓨터 장치의 프로세서는 오리지널 네트워크의 모델 데이터 세트 및 모델 구조 파라미터에 따라 상기 오리지널 네트워크를 실행하고, 오리지널 네트워크에 있는 컴퓨팅 노드 각각에 대응하는 명령을 얻을 수 있다. 구체적으로, 프로세서는 상기 오리지널 네트워크의 입력 데이터를 획득할 수 있고, 오리지널 네트워크의 입력 데이터, 네트워크 모델 데이터 세트 및 모델 구조 파라미터에 따라서 오리지널 네트워크을 실행하여, 상기 오리지널 네트워크에 있는 컴퓨팅 노드 각각에 대응하는 명령을 얻을 수 있다. 또한, 전술한 상기 오리지널 네 트워크를 실행하여 각 컴퓨팅 노드의 명령을 얻는 과정은 본질적으로 컴파일 과정이고, 상기 컴파일 과정은 컴 퓨터 장치의 프로세서 또는 가상 장치를 통해 구현될 수 있다. 즉, 컴퓨터 장치의 프로세서 또는 가상 장치는 오리지널 네트워크의 모델 데이터 세트 및 모델 구조 파라미터에 따라 오리지널 네트워크를 실행한다. 여기서, 가상 장치는 메모리의 메모리 공간에서 프로세서의 실행공간을 가상화하는 것을 말한다. 본 실시예에서, 오리지널 네트워크를 실행한다는 것은, 프로세서가 인공 신경망 모델 데이터를 이용하여 어떤 기계 학습 알고리즘(예: 신경망 알고리즘)을 실행함으로써, 포워드 연산을 수행하여 알고리즘의 목표 응용(예: 음성인식 등 인공지능 응용)을 구현하는 것을 의미한다. S030단계: 오리지널 네트워크의 각 컴퓨팅 노드에 대응하는 네트워크 가중치 및 명령에 따라, 오리지널 네트워 크에 대응하는 오프라인 모델을 생성하고, 오리지널 네트워크에 대응하는 오프라인 모델을 비휘발성 메모리 (예: 데이터베이스)에 저장한다. 구체적으로, 상기 프로세서의 제어 모듈은 오리지널 네트워크의 컴퓨팅 노드 각각에 대응하는 네트워크 가중치 및 명령에 따라, 상기 오리지널 네트워크에 대응하는 오프라인 모델을 생성할 수 있으며, 예를 들어 상기 프로 세서의 제어 모듈은 오리지널 네트워크의 컴퓨팅 노드 각각에 대응하는 네트워크 가중치 및 명령을 비휘발성 메 모리에 저장하여, 오프라인 모델의 생성 및 저장을 구현할 수 있다. 여기서, 오리지널 네트워크의 컴퓨팅 노드 각각에 대해, 상기 컴퓨팅 노드의 네트워크 가중치 및 명령은 일대일로 대응하여 저장된다. 따라서, 상기 오리 지널 네트워크를 재실행 할 경우, 직접 비휘발성 메모리로부터 상기 오리지널 네트워크에 대응하는 오프라인 모 델을 획득하고, 상기 오프라인 모델에 따라 오리지널 네트워크를 실행할 수 있음으로써, 상기 오리지널 네트워 크의 컴퓨팅 노드 각각에 대해 온라인 상으로 컴파일하여 명령을 획득할 필요가 없어지므로, 프로세서의 처리 속도와 효율을 향상시킨다. 본 실시예에서, 상기 오리지널 네트워크에 대응하는 오프라인 모델을 직접 실행한다는 것은, 오프라인 모델을 이용하여 상기 오리지널 네트워크에 대응하는 기계 학습 알고리즘(예: 신경망 알고리즘)을 실행함으로써, 포워 드 연산을 수행하여 알고리즘의 목표 응용(예: 음성인식 등 인공지능 응용)을 구현하는 것을 의미한다. 선택적으로, 도 8에 도시된 바와 같이, 상기 S200단계는 다음과 같은 단계를 포함할 수 있다. S021단계: 오리지널 네트워크의 모델 구조 파라미터에 따라, 오리지널 네트워크의 각 컴퓨팅 노드의 실행 순서 를 획득한다. 구체적으로, 프로세서는 오리지널 네트워크의 모델 구조 파라미터에 따라 오리지널 네트워크에 있 는 각 컴퓨팅 노드의 실행 순서를 획득할 수 있고, 즉 오리지널 네트워크의 각 컴퓨팅 노드의 연결 관계에 따라, 오리지널 네트워크에서 각 컴퓨팅 노드의 실행 순서를 획득할 수 있다. 예를 들어, 도9에 도시된 바와 같 이, 컴퓨팅 노드 F4의 입력 데이터는 컴퓨팅 노드 F1 의 출력 데이터 및 컴퓨팅 노드 F2의 출력 데이터이고, 컴 퓨팅 노드 F6의 입력 데이터는 컴퓨팅 노드 F4 의 출력 데이터 및 컴퓨팅 노드 F5의 출력 데이터이다. 따라서, 도9에 도시된 신경망에서 각 컴퓨팅 노드의 실행 순서는 F1-F2-F3-F4-F5-F6 또는 F1-F3-F2-F5-F4-F6 등일 수 있다. 물론, 컴퓨팅 노드 F1, F2, 및F3은 병렬로 실행될 수 있고, 컴퓨팅 노드 F4, F5도 병렬로 실행될 수 있다. 하지만, 이는 예시일뿐이며, 실행 순서는 여기에서 특별히 제한되지 않는다. S022단계: 오리지널 네트워크의 각 컴퓨팅 노드의 실행 순서에 따라 오리지널 네트워크를 실행하고, 오리지널 네트워크에 있는 컴퓨팅 노드 각각에 대응하는 명령을 획득한다. 구체적으로, 프로세서는 오리지널 네트워크의 각 컴퓨팅 노드의 실행 순서에 따라 상기 오리지널 네트워크를 실 행하여, 오리지널 네트워크에 있는 컴퓨팅 노드 각각에 대응하는 명령을 획득할 수 있고, 즉 프로세서는 오리지 널 네트워크의 모델 데이터 세트 등 데이터를 컴파일하여 컴퓨팅 노드 각각에 대응하는 명령을 얻을 수 있으며, 컴퓨팅 노드 각각에 대응하는 명령을 통해 상기 컴퓨팅 노드가 어떤 계산 기능을 구현하도록 구성되는지를 알수 있고, 즉 상기 컴퓨팅 노드의 계산 유형과 계산 파라미터 등의 계산 속성을 획득할 수 있다. 보다 상세하게, 도 8에 도시된 바와 같이, 상기 단계 S300은 다음과 같은 단계를 더 포함한다. S031단계: 오리지널 네트워크의 모델 데이터 세트 및 모델 구조 파라미터에 따라 오리지널 네트워크의 메모리 할당 방식을 획득한다. 구체적으로, 프로세서는 오리지널 네트워크의 모델 데이터 세트 및 모델 구조 파라미터에 따라 오리지널 네트워 크의 메모리 할당 방식을 획득할 수 있으며, 오리지널 네트워크의 모델 구조 파라미터에 따라 오리지널 네트워 크에 있는 각 컴퓨팅 노드의 실행 순서를 획득하고; 오리지널 네트워크에 있는 각 컴퓨팅 노드의 실행 순서에 따라 현재 네트워크의 메모리 할당 방식을 확정한다. 예를 들어, 각 컴퓨팅 노드의 실행 순서에 따라 각 컴퓨팅 노드의 실행 과정에서의 관련 데이터를 하나의 스택에 저장한다. 그 중에서, 메모리 할당 방식은 메모리 공간 (예: 제1 메모리)에서 오리지널 네트워크의 각 컴퓨팅 노드에 관련된 데이터 (입력 데이터, 출력 데이터, 네트 워크 가중치 데이터, 중간 결과 데이터 등을 포함함)의 저장 위치를 확정하는 것을 지칭한다. 예를 들어, 데이 터 테이블을 이용하여 각 컴퓨팅 노드에 관련된 데이터 (입력 데이터, 출력 데이터, 네트워크 가중치 데이터, 중간 결과 데이터 등)와 메모리 공간 사이의 매핑 관계를 저장할 수 있다. S032단계: 오리지널 네트워크의 메모리 할당 방식에 따라, 오리지널 네트워크의 실행 과정에서의 관련 데이터를 제 1 메모리에 저장한다. 여기서, 오리지널 네트워크의 실행 과정에서의 관련 데이터는 오리지널 네트워크에 있 는 컴퓨팅 노드 각각에 대응하는 네트워크 가중치, 명령, 입력 데이터, 중간 계산 결과 및 출력 데이터 등을 포 함한다. 예를 들어, 도9에 도시된 바와 같이, X1 및 X2는 상기 신경망의 입력 데이터를 나타내고, Y는 상기 신 경망의 출력 데이터를 나타내며, 프로세서는 상기 신경망의 출력 데이터를 로봇 또는 다른 디지털 인터페이스를 제어하기 위한 제어 명령으로 변환할 수 있다. W1~W6은 컴퓨팅 노드 F1, F2, F3에 대응하는 네트워크 가중치를 나타내도록 구성되고, 컴퓨팅 노드 F1~F5의 출력 데이터는 중간 계산 결과로 사용될 수 있다. 프로세서는 결정 된 메모리 할당 방식에 따라, 오리지널 네트워크의 실행 과정에서의 관련 데이터를 제 1 메모리에 저장할 수 있 고, 예를 들어 내장 메모리 또는 캐시 등과 같은 휘발성 메모리이며, 상세한 저장 방식은 도10의 좌측에 도시된 저장 공간을 참조할 수 있다. S033단계: 제1 메모리로부터 오리지널 네트워크에 있는 컴퓨팅 노드 각각에 대응하는 네트워크 가중치 및 명령 을 획득하고, 오리지널 네트워크에 있는 컴퓨팅 노드 각각에 대응하는 네트워크 가중치 및 명령을 제 2 메모리 에 저장하여 오프라인 모델을 생성한다. 여기서, 제 2 메모리는 외장 메모리 등과 같은 비휘발성 메모리일 수 있다. 상기 오프라인 모델의 생성 과정은 도 10에 도시된 바를 참조할 수 있고, 도 10 중 우측에 도시된 저장 공간에 저장된 것이 오리지널 네트워크에 대응하는 오프라인 모델이다. 도9 및 도10에 도시된 바와 같이, 이하에서 첨부된 도면을 결합하여 상기 오프라인 모델의 생성 과정을 설명한 다. 우선, 프로세서는 상기 오리지널 네트워크의 모델 데이터 세트와 모델 구조 파라미터 및 입력 데이터를 획득할 수 있음으로써, 상기 오리지널 네트워크의 모델 데이터 세트와 모델 구조 파라미터에 따라 상기 오리지널 네트 워크의 네트워크 구조도를 획득할 수 있으며, 도9에 도시된 바와 같다. 다음으로, 프로세서는 오리지널 네트워크의 모델 구조 파라미터에 따라 오리지널 네트워크에 있는 각 컴퓨팅 노 드의 연결 관계를 획득하고, 각 컴퓨팅 노드의 연결 관계에 따라 오리지널 네트워크에 있는 각 컴퓨팅 노드의 실행 순서, 및 오리지널 네트워크의 실행 과정에서의 메모리 할당 방법을 획득하고, 따라서 오리지널 네트워크 의 실행 과정에서의 관련 데이터의 저장 위치를 얻을 수 있다. 도10의 좌측 부분에 도시된 저장 공간을 참조하 면, 오리지널 네트워크의 실행 과정에서의 관련 데이터는 각 컴퓨팅 노드의 실행 순서로 하나의 스택에 저장될 수 있다. 마지막으로, 프로세서는 오리지널 네트워크에 있는 컴퓨팅 노드 각각에 대응하는 네트워크 가중치 및 명령을 비 휘발성인 제 2 메모리에 저장하여 오프라인 모델을 생성할 수 있으며, 상기 오프라인 모델의 저장 방법은 도10 의 우측에 도시된 저장 공간을 참조할 수 있다. 또한 상기 오프라인 모델은 상기 오리지널 네트워크를 실행하기 위해 필요한 네트워크 가중치 및 명령 등 데이터만 포함하고, 오리지널 네트워크가 실행하는 과정의 입력 데이 터, 출력 데이터 또는 중간 계산 결과를 저장할 필요가 없으므로 제2메모리의 저장 공간의 소모를 감소시킬 수 있다. 추가 개선 방안으로서, 오프라인 모델 내에 노드 인터페이스 데이터도 포함되고, 노드 인터페이스 데이터는 오 리지널 네트워크에 있는 각 컴퓨팅 노드의 연결 관계를 나타내도록 사용된다. 구체적으로, 노드 인터페이스 데이터는 각 컴퓨팅 노드의 입력 데이터 소스 및 출력 데이터 소스를 포함할 수 있다. 예를 들어, 도9에 도시된 바와 같이, 노드 인터페이스 데이터는 초기 컴퓨팅 노드인 컴퓨팅 노드 F1, F2 및 F3을 포함할 수 있고, 상기 초기 컴퓨팅 노드의 입력 각각이 기설정된 입력 데이터이며, 컴퓨팅 노드 F1의 출력 데이터가 컴퓨팅 노드F4와 컴퓨팅 노드 F5의 입력 데이터 등으로 사용된다. 이와 같이 상기 오리지널 네트워크가 재실행되는 경우, 오리지 널 네트워크의 초기 컴퓨팅 노드와 입력 데이터만 획득할 필요가 있어, 다음으로 상기 오리지널 네트워크에 대 응하는 오프라인 모델에 따라 상기 오리지널 네트워크를 실행할 수 있다. 도5~8의 흐름도 중에서, 각 단계는 화살표로 표시된 바와 같이에 따라 순차적으로 표시되었지만, 이러한 단계들 이 반드시 화살표가 표시한 순서로 수행되는 것은 아니라는 점에 유의해야 한다. 본 명세서에서 명확하게 언급 한 경우를 제외하고, 이러한 단계의 수행은 엄격한 순서 제한이 없으며, 이러한 단계는 다른 순서로 수행될 수 도 있다. 또한, 도 5~8 중의 적어도 일부 단계는 복수의 서브 단계 또는 복수의 절차를 포함할 수 있으며, 해당 서브 단계 또는 절차는 반드시 동시에 수행되는 것은 아니며, 상이한 시간에 수행될 수도 있고, 해당 서브 단계 또는 절차의 수행 순서는 반드시 순차적으로 수행되는 것은 아니며, 다른 단계 또는 다른 단계의 서브 단계 또 는 절차의 적어도 일부와 번갈아서 또는 교대로 수행될 수도 있다. 당업자는 상기 실시예을 구현하는 방법의 전부 또는 일부 단계는, 컴퓨터 프로그램에 의해 관련 하드웨어를 명 령하는 것으로 완성될 수 있음을 이해할 것이고, 상기 컴퓨터 프로그램은 비휘발성 컴퓨터 판독 가능 저장 매체 에 저장될 수 있고, 상기 컴퓨터 프로그램이 실행될 때 전술한 각 방법의 실시 예의 단계를 포함 할 수 있다. 여기서, 본 출원에 의해 제공된 다양한 실시예에서 사용된 메모리, 저장, 데이터베이스 또는 다른 매체에 대한 임의의 인용는 모두 비휘발성 및/또는 휘발성 메모리를 포함할 수 있다. 비휘발성 메모리는 읽기 전용 메모리 (ROM), 프로그래머블 ROM(PROM), 전기적 프로그래머블 ROM(EPROM), 전기적 소거 가능 프로그래머블 ROM(EEPROM) 또는 플래시 메모리로 이루어진 군으로부터 선택된 것을 포함할 수 있다. 휘발성 메모리는 랜덤 액 세스 메모리(RAM) 또는 외부 고속 버퍼 메모리를 포함할 수 있다. 설명으로 제한적인 것은 아니며, RAM은, 예를 들어, 정적 RAM(SRAM), 동적 RAM(DRAM), 동기식 DRAM(SDRAM), 더블 데이터 레이트 SDRAM (DDRSDRAM), 향상형 SDRAM(ESDRAM), 싱링크(Synchlink) DRAM (SLDRAM), 메모리 버스(Rambus) 다이렉트 RAM (RDRAM), 다이렉트 메모 리 버스 DRAM (DRDRAM) 및 메모리 버스 DRAM (RDRAM) 등 다양한 형태으로 사용 가능하지만, 이에 제한되는 것은 아니다. 본 출원의 실시예는 모델 변환 장치도 제공하며, 상기 모델 변환 장치는 획득 모듈, 판단 모듈 및 변환 모듈을 포함하며, 여기서, 획득 모듈은 초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보를 획득하도록 구성되며; 판단 모듈은 초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보에 따라, 초기 오프라인 모델의 모델 속 성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는지 여부를 판단하도록 구성되며; 변환 모듈은 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보에 매칭되지 않을 경우, 컴퓨터 장치의 하드웨어 속성 정보와 기설정된 모델 변환 규칙에 따라, 초기 오프라인 모델을 컴퓨터 장치의 하 드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환하도록 구성된다. 선택적으로, 상기 모델 변환 장치는 상기 컴퓨터 장치에 설치되어 있는 응용 소프트웨어(Application)일 수 있 다. 상기 응용 소프트웨어(Application)는 메모리 또는 외장 메모리로부터 초기 오프라인 모델을 판독하기 위한 인터페이스를 제공할 수 있기에, 상기 응용 소프트웨어를 통해 상기 초기 오프라인 모델을 얻을 수 있다. 선택적으로, 상기 응용 소프트웨어는 컴퓨터 장치의 하드웨어 속성 정보를 판독하기 위한 인터페이스도 제공할 수 있기에, 상기 응용 소프트웨어를 통해 상기 컴퓨터 장치의 하드웨어 속성 정보를 얻을 수 있다. 선택적으로, 상기 응용 소프트웨어는 기설정된 모델 규칙을 판독할 수 있는 인터페이스도 제공할 수 있기에, 상기 응용 소프 트웨어를 통해 기설정된 모델 변환 규칙을 얻을 수 있다. 또한, 상기 응용 소프트웨어는 초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보 및 기설정된 모델 변환 규칙에 따라, 상기 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않을 경우, 상기 초기 오프라인 모델을 상기 컴퓨터 장치 의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환할 수 있고, 상기 목표 오프라인 모델을 제1 메모 리 또는 제2 메모리에 저장할 수 있다. 모델 변환 장치에 대한 구체적인 제한은 상술한 모델 변환 방법의 제한을 참조 할 수 있으며, 세부 사항은 여기 서 생략한다. 상기 모델 변환 장치에 있는 각 모듈 전체 또는 일부는 소프트웨어, 하드웨어 및 이들의 조합을 통해 구현될 수 있다. 상기 각 모듈은 컴퓨터 장치의 프로세서에 하드웨어 형태로 내장되거나 독립되어 설치될수 있으며, 또한 소프트웨어 형태로 컴퓨터 장치의 메모리에 저장될 수도 있어, 프로세서가 상기 모듈 각각에 대응하는 동작을 호출하여 실행할 수 있도록 하는 것에 유리한다. 또한, 본 출원의 실시예는 컴퓨터 프로그램을 내장한 컴퓨터 판독 가능 저장 매체도 제공하며, 상기 컴퓨터 프 로그램이 프로세서에 의해 실행될 경우, 청구 범위에 따른 상기 임의 한 실시예의 방법의 단계가 구현된다. 선 택적으로, 상기 컴퓨터 판독 가능 저장 매체는 비휘발성 및/또는 휘발성 메모리를 포함할 수 있다. 비휘발성 메 모리는 읽기 전용 메모리(ROM), 프로그래머블 ROM (PROM), 전기적 프로그래머블 ROM (EPROM), 전기적 소거 가능 프로그래머블 ROM (EEPROM) 또는 플래시 메모리로 이루어진 군으로부터 선택된 것을 포함할 수 있다. 휘발성 메 모리는 랜덤 액세스 메모리(RAM) 또는 외부 고속 버퍼 메모리를 포함할 수 있다. RAM은, 예를 들어 정적 RAM (SRAM), 동적 RAM (DRAM), 동기식 DRAM (SDRAM), 더블 데이터 레이트 SDRAM (DDRSDRAM), 향상형 SDRAM (ESDRAM), 싱링크 (Synchlink) DRAM (SLDRAM), 메모리 버스 (Rambus) 다이렉트 RAM (RDRAM), 다이렉트 메모리 버스 DRAM (DRDRAM) 및 메모리 버스 DRAM (RDRAM) 등 다양한 형태으로 사용 가능하지만, 이에 제한되는 것은 아 니다. 구체적으로, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 다음과 같은 단계이 구현된다: S100 단계: 초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보를 획득한다. 구체적으로, 상기 초기 오프라인 모델은 컴퓨터 장치에 의해 직접적으로 획득된 오프라인 모델을 의미하며, 상 기 초기 오프라인 모델은 제 2 메모리에 저장될 수 있다. 여기서, 오프라인 모델은 오리지널 네트워크에 있는 각 컴퓨팅 노드의 네트워크 가중치 및 명령 등과 같은 필요한 네트워크 구조 정보를 포함할 수 있으며, 명 령은 상기 컴퓨팅 노드가 어떤 계산 기능을 수행하도록 사용되는지를 나타낼 수 있고, 구체적으로 상기 오리지 널 네트워크에 있는 각 컴퓨팅 노드의 계산 속성 및 각 컴퓨팅 노드 간의 연결 관계 등 정보를 포함할 수 있다. 선택적으로, 본 출원 실시예에서의 초기 오프라인 모델은 오리지널 네트워크에 따라 직접적으로 생성된 오프라 인 모델일 수 있고, 또는 다른 모델 속성 정보를 갖는 오프라인 모델이 1회 이상의 변환된 후 획득한 오프라인 모델일 수도 있있지만, 여기서 특별히 제한하지 않는다. S200단계: 초기 오프라인 모델 및 컴퓨터 장치의 하드웨어 속성 정보에 따라, 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는지 여부를 판단한다. 구체적으로, 상기 초기 오프라인 모델의 모델 속성 정보는 상기 초기 오프라인 모델의 데이터 구조, 데이터 유 형 등을 포함할 수 있다. 예를 들어, 초기 오프라인 모델에 있는 각 네트워크 가중치 및 명령의 배열 방식, 각 네트워크 가중치의 유형 및 각 명령의 유형 등이다. 상기 컴퓨터 장치의 하드웨어 속성 정보는 상기 컴퓨터 장 치의 모델 번호, 상기 컴퓨터 장치에 의해 처리하고자 하는 데이터 유형(예: 고정 소수점 또는 부동 소수점 등), 및 데이터 구조 등을 포함한다. 예를 들어, 상기 컴퓨터 장치는 그의 하드웨어 속성 정보에 따라 상기 컴퓨터 장치에 의해 처리될 수 있는 데이 터 유형 및 데이터 구조를 확정할 수 있고, 상기 초기 오프라인 모델의 모델 속성 정보에 따라 상기 초기 오프 라인 모델의 데이터 유형 및 데이터 구조를 확정할 수 있다. 상기 컴퓨터 장치가 자체의 하드웨어 속성 정보 및 상기 초기 오프라인 모델의 모델 속성 정보에 따라, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 데이터 유 형 및 데이터 구조를 지원할 수 있다고 확정되는 경우, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨 터 장치의 하드웨어 속성 정보와 매칭된다고 판정할 수 있다. 상기 컴퓨터 장치가 자체의 하드웨어 속성 정보 및 상기 초기 오프라인 모델의 모델 속성 정보에 따라, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 데이터 유형 및 데이터 구조를 지원할 수 없다고 확정되는 경우, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴 퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는다고 판정할 수 있다. 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는 경우, 컴퓨터 장치 의 하드웨어 속성 정보 및 기설정된 모델 변환 규칙에 따라 초기 오프라인 모델을 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환하는 S300단계를 실행한다. 구체적으로, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는 경우, 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 실행을 지원할 수 없음을 의미하고, 이때 상기 초기 오프라인 모델에 대해 변환 처리를 수행하여, 상기 컴퓨터 장치가 상기 초기 오프라인 모델를 사용하여 대응된 연산을 구현할 수 있다. 즉, 상기 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되지 않는 경우, 컴퓨터 장치의 하드웨어 속성 정보 및 기설정된 모델 변환 규칙에 따라, 상기 초기 오프라 인 모델을 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 목표 오프라인 모델로 변환할 수 있다. 여기서,상기 목표 오프라인 모델의 모델 속성 정보는 상기 컴퓨터 장치의 하드웨어 속성 정보와 매칭되며 상기 컴퓨터 장치는 상기 목표 오프라인 모델의 실행을 지원할 수 있다. 전술한 바와 같이, 상기 목표 오프라인 모델도 오리 지널 네트워크에 있는 각 컴퓨팅 노드의 네트워크 가중치 및 명령 등과 같은 필요한 네트워크 구조 정보를 포함 한다. 초기 오프라인 모델의 모델 속성 정보가 컴퓨터 장치의 하드웨어 속성 정보와 매칭되는 경우, 컴퓨터 장치는 그 에 의해 수신된 초기 오프라인 모델을 직접적으로 실행하며, 즉 컴퓨터 장치는 상기 초기 오프라인 모델에 포함 된 네트워크 가중치 및 명령에 따라 연산을 진행하여 오리지널 네트워크의 연산 기능을 구현하는 S400단계를 수 행할 수 있다. 구체적으로, 상기 초기 오프라인 모델의 모델 속성 정보가 상기 컴퓨터 장치의 하드웨어 속성 정 보와 매칭되는 경우, 이는 상기 컴퓨터 장치가 상기 초기 오프라인 모델의 실행을 지원할 수 있음을 의미하고, 이때 상기 초기 오프라인 모델에 대해 변환 처리를 수행할 필요가 없고, 컴퓨터 장치는 상기 초기 오프라인 모 델을 실행할 수 있다. 프로세서가 상기 컴퓨터 프로그램을 실행하는 과정은, 상기 실시예의 모델 변환 방법의 실행 과정과 일치하다. 자세한 내용은 상기 설명을 참조할 수 있고, 여기서 설명은 생략한다. 상기 각 실시예에서 동일하거나 유사한 부분은 서로 참조될 수 있고, 일부 실시예에서 상세하게 설명되지 않은 부분은 다른 실시예에서의 동일하거나 유사한 내용을 참조할 수 있다. 본 출원의 설명에서, 용어 \"제1\", \"제2\" 등은 설명의 목적으로만 사용되며, 상대적 중요도를 나타내거나 암시하 는 것으로 해석되어서는 안된다. 또한, 본 출원의 설명에서, \"복수의\"의 의미는 달리 언급되지 않는 한 최소 2 개를 의미한다.흐름도 또는 본 명세서에서 다른 방법으로 설명된 모든 과정 또는 방법 설명은, 특정 논리 기능 또는 과정의 단계를 구현하기 위한 하나 이상의 실행 가능한 명령을 포함한는 코드의 모듈, 세그먼트 또는 일부 를 나타내고, 또한 본 출원의 선택적인 실시예의 범위는 추가적인 구현을 포함하며, 여기서 도시된 또는 논의된 순서에 따르지 않을 수 있으며, 관련된 기능에 따라 대체로 동시적인 방식, 또는 반대 순서에 따라 기능을 수행 하는 것을 포함하며, 이는 본 출원의 실시예이 속하는 기술 분야의 당업자가 이해할 수 있다. 본 출원의 각 부분은 하드웨어, 소프트웨어, 펌웨어 또는 이들의 조합으로 구현될 수 있음을 이해해야 한다. 상 기 실시예에서, 복수의 단계 또는 방법은 메모리에 저장되고, 적절한 명령 실행 시스템에 의해 실행되는 소프트 웨어 또는 펌웨어를 사용함으로써 구현될 수 있다. 예를 들어, 하드웨어로 구현되는 경우, 다른 실시예에서와 같이, 데이터 신호에 대해 논리 기능을 구현하기 위한 논리 게이트 회로가 있는 이산 논리 회로, 적합한 조합 논리 게이트 회로가 있는 전용 집적 회로, 프로그램 가능 게이트 어레이 (PGA), 필드 프로그램 가능 게이트 어 레이 (FPGA) 등 당업계의 공지 기술으로 이루어진 군으로부터 선택된 임의 하나 또는 이들의 조합을 사용하여 구현될 수 있다. 당업자는 상기 실시예의 방법에 포함된 전부 또는 일부 단계의 구현은, 컴퓨터 프로그램에 의해 관련 하드웨어 를 명령하는 것으로 완성될 수 있음을 이해할 것이고, 상기 프로그램은 컴퓨터 판독 가능 저장 매체에 저장될 수 있고, 상기 프로그램이 실행될 경우, 실시예의 방법의 단계 중 하나 또는 조합을 포함한다. 또한, 본 출원의 각 실시예에서의 각 기능 유닛은 하나의 처리 모듈에 집적될 수 있고, 또는 각각의 유닛이 단 독 물리적인 존재일 수도 있고, 또는 2개 이상의 유닛이 하나의 모듈에 집적될 수도 있다. 상기 집적된 모듈은 하드웨어 형태로 구현할 수 있고, 또는 소프트웨어 기능 모듈의 형태로 구현될 수도 있다. 상기 집적된 모듈은 소프트웨어 기능 모듈의 형태로 구현되고 독립형 제품으로 판매되거나 사용되는 경우, 컴퓨터 판독 가능 저장 매체에 저장될 수도 있다. 상술한 저장 매체는 읽기 전용 메모리, 자기 디스크 또는 광 디스크 등일 수 있다. 본 명세서의 설명에서, \"일 실시예\", \"일부 실시예\", \"예\", \"구체적인 예\" 또는 \"일부 예\" 등의 용어를 사용한 설명은, 해당 실시예 또는 예시를 결합하여 설명된 특정 특징, 구조, 재료 또는 특성은 본 출원의 최소 하나의 실시예 또는 예시에 포함됨을 의미한다. 본 명세서에서, 상기 용어의 개략적인 표현은 반드시 동일한 실시예 또 는 예시를 의미하는 것은 아니다. 또한, 설명된 구체적인 특징, 구조, 재료 또는 특성은 임의의 하나 이상의 실 시예 또는 예시에서 적절한 방식으로 결합될 수 있다. 몰론, 본 출원의 실시예들을 위에서 도시하고 설명햐였지만, 상기 실시예들은 예시적인 것이며 본 출원의 범위 를 제한하는 것으로 해석되지 말아야 하며, 당업자는 본 출원의 범위내에서 상기 실시예에 대해 변화, 수정, 대 체 및 변형을 할 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2019-7034745", "section": "도면", "subsection": "도면설명", "item": 1, "content": "여기서 제시된 도면은 본 명세서의 일부로서 본 명세서에포함되며, 본 출원을 설명하기 위한 실시예를 제시하였 으며, 명세서와 함께 본 출원의 원리를 설명하고자 한다. 도 1은 일 실시예에 따른 컴퓨터 장치의 구조 블록도이다. 도 2는 도 1의 프로세서의 일 실시예에 따른 구조 블록도이다. 도 3은 도 1의 프로세서의 일 실시예에 따른 구조 블록도이다. 도 4는 도 1의 프로세서의 일 실시예에 따른 구조 블록도이다. 도 5는 일 실시예에 따른 모델 변환 방법의 흐름도이다. 도 6은 일 실시예에 따른 모델 변환 방법의 흐름도이다. 도 7은 일 실시예에 따른 오프라인 모델 생성 방법의 흐름도이다. 도 8은 일 실시예에 따른 오프라인 모델 생성 방법의 흐름도이다. 도 9는 일 실시예에 따른 네트워크 모델의 네트워크 구조도이다. 도 10은 도 9의 네트워크 모델의 오프라인 모델 생성 과정의 흐름도이다."}
