{"patent_id": "10-2024-0136134", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0150749", "출원번호": "10-2024-0136134", "발명의 명칭": "웹 브라우저 기반의 비대면 학습에서 인공지능을 사용한 주의집중 학습 시스템 및 방법", "출원인": "(주)엔에스데블", "발명자": "박기남"}}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비대면 온라인 강의 학습 콘텐츠를 제공하는 학습 콘텐츠 서버; 상기 학습 콘텐츠 서버에 접속하여 교육 콘텐츠 viewer를 구동하며, 비대면 온라인 학습에서 사용자 단말의 정면 카메라 영상 데이터의 AI 안면인식/동작인식 소리 재생 기술을 사용하여 학습 콘텐츠를 인공지능 주의 집중학습하도록 상기 교육 콘텐츠 viewer가 설치된 사용자 단말; 및 강사가 사용하는 감독관의 단말을 포함하고, 상기 강사가 사용하는 감독관의 단말은 상기 학습 콘텐츠 서버를 통해 1:N 방식으로 복수의 학습자 단말들로 질의 응답 채팅 데이터를 송수신하며, 상기 사용자 단말은 비대면 강의 학습 콘텐츠를 재생하는 VOD 미디어 플레이어; 강사와 학습자와의 채팅 데이터를 송수신하는 채팅 모듈; 상기 사용자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하고 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도들을 인식하는 안면인식 모듈; 및 화면으로부터 일정 각도 이상으로벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의거리가 일정 기준치를 넘는 경우) 또는 학습자의 음성을 인식한 경우 주의집중 학습되도록 해당 학습자의 사용자 단말로 알람을 발생하거나 또는 경고 메시지를 출력하는 학습자의 알람 발생부를 포함하며, 상기 사용자 단말은 학습자의 음성을 인식하는 음성인식 모듈을 더 포함하고, 상기 안면인식 모듈은 AI 기반 안면윤곽선 인식 기술로써 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 측정하고 눈과 귀의 거리, 코와 귀의 거리를 측정하는 posenet 알고리즘을 사용하며, 상기 교육 콘텐츠 viewer는 VOD 미디어 플레이어와 채팅 화면, 온라인 학습 메모 공간을 구비하며, 비대면 온라인 학습에서, 강사의 단말은 상기 학습 콘텐츠 서버를 통해 1:N 방식으로 복수의 학습자 단말들로질의 응답 채팅 데이터를 송수신하는, 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 시스템."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 학습 콘텐츠 서버는 스마트폰을 사용시에 인식 코드로써 QR 코드를 인식하는 기능을 제공하는, 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 시스템."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 사용자 단말은 정면 카메라를 구비하는 태블릿 PC, 스마트폰, PC 중 어느 하나의 단말을 사용하며, 상기학습 콘텐츠 서버로부터 다운로드된 상기 교육 콘텐츠 viewer가 설치되는, 웹 브라우저 기반의 비대면 학습에서주의집중 학습 시스템."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 안면인식 모듈은 비대면 온라인 학습 시에 크기 보정/회전/각도 보정된 표준 크기의 학습자의 정면 얼굴사진에 대하여 얼굴인식 알고리즘을 사용하여 얼굴 객체를 추출하고 얼굴 행동 패턴을 인식하여 학습자의 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점들을 추출하며, 눈2/코/귀2의 얼굴의 특징점들의 각각 좌측/우측 귀와좌측/우측 눈의 중심점(동공)과의 유클리디안 거리(d)와 유사도(similarity)를 계산하고, 얼굴사진 DB의 사용자의 얼굴 사진의 특정점들과 비교하여 시선 이탈 여부를 확인하며, 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에따라 오른쪽/왼쪽으로 머리 이동을 감지하고 시선 이탈과 관련된 얼굴 패턴을 검출하며, 얼굴 인식시에 안면윤곽선 인식이 안되는 경우, 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 사용자 단말의공개특허 10-2024-0150749-3-카메라로 촬영되는 얼굴 행동 패턴을 인식하여 전면 얼굴이 좌우로 돌아간 각도에 따라 우측 눈과 우측 귀의 거리와 좌측 눈과 좌측 귀의 거리가 달라지므로 해당 사용자 단말로 알람을 발생하거나 또는 경고 메시지를 출력하는, 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 시스템."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 학습 콘텐츠 서버는 WWW 서버; 상기 사용자 단말로 온라인 학습 콘텐츠를 제공하도록 제어하는 제어부; 상기 제어부에 연결되며, 회원 정보를 등록받아 ID/Passwd를 저장하여 관리하는 회원 등록부; 상기 제어부에 연결되며, QR 코드/Passwd 또는 ID/Passwd 또는 개인 인증서를 사용하여 인증하는 사용자인증부; 상기 제어부에 연결되며, 상기 사용자 단말로 상기 온라인 학습(Learning) 콘텐츠를 제공하는 학습 콘텐츠 제공부; 상기 제어부에 연결되며, 사용자 정보에 대응하는 QR 코드를 발급하고 관리하는 QR 코드 관리부; 상기 제어부에 연결되며, 강사와 학습자의 채팅 데이터를 송수신하는 채팅 서버; 상기 제어부에 연결되며, 사용자 단말로부터 카메라의 응시자의 촬영 사진을 수신받아 표준 크기로 크기 보정/회전/각도 보정을 통해 정면 얼굴 사진으로 변환하고 서버의 데이터베이스에 기 저장된 사용자 정보와 정면 얼굴 사진을 비교하여 감독관 단말에서 감독관이 확인하여 온라인 학습 자격을 확인하는 감독관 확인부; 상기 제어부에 연결되며, 상기 사용자 단말의 안면인식 모듈을 사용하여 학습자의 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점들을 인식하고, 사용자 단말로부터 얼굴 인식 결과를 수신받는 얼굴 인식부; 및응시자 단말들의 시험지와 작성 답안, 채점 결과를 저장하는 시험 정보DB; 응시자 정보와 표준 크기의 정면 얼굴 사진을 저장하는 응시자DB와 얼굴 DB; 를 포함하는 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 시스템."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 응시자 단말과 감독관 단말로 시험 프로그램(App)과 시험지를 제공하며, 응시자 정보들과 응시자의 현장 얼굴사진, 감독관 정보를 관리하며, 온라인 시험 또는 UBT 시험시에 일정 시험 시간 이내에 각각의 응시자 단말에시험지 작성 답안을 저장후 시험 종료시 시험관리부를 구비하는 상기 학습 콘텐츠 서버로 전송되며, 응시자들의시험지 작성 답안, 채점 결과, 감독관 정보와 응시자 현황 정보를 저장하여 관리하는 시험 관리부를 더 포함하는 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 시스템."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "(a) 사용자 단말로부터 학습자 정보와 표준 크기의 정면 얼굴 사진을 학습 콘텐츠 서버가 등록받아 저장하는 단계; (b) 상기 학습 콘텐츠 서버가 사용자 정보와 정면 얼굴 사진에 대응하는 QR 코드를 발급하는 단계; (c) 교육 콘텐츠 viewer와 안면인식 모듈을 구비하는 사용자 단말에서 정면 카메라 영상의 정면 얼굴인식 알고리즘을 사용하여 카메라의 전면 얼굴 사진의 인식 결과를 상기 학습 콘텐츠 서버로 수신받아 기 등록된 학습자정보와 표준 크기의 정면 얼굴 사진과 그 얼굴 특징점들을 비교하여 학습자 본인 여부를 확인하는 단계; (d) 상기 학습 콘텐츠 서버로부터 학습 콘텐츠를 기 등록된 회원의 사용자 단말로 제공하는 단계; 및 (e) 상기 학습 콘텐츠 서버는 각 학습자의 사용자 단말에서 카메라로 검출된 온라인 학습자의 얼굴 영상을 분석하여 시선이 일정 각도로 벗어난 경우 또는 학습자의 사용자 단말에서 학습자의 음성을 인식한 경우 주의집중공개특허 10-2024-0150749-4-학습되도록 해당 학습자의 사용자 단말로 경고 메시지 또는 알람을 발생하는 단계를 포함하고, 비대면 온라인 학습에서, 상기 사용자 단말에 설치된 상기 교육 콘텐츠 viewer는 VOD 미디어 플레이어와 채팅화면, 온라인 학습 메모 공간을 구비하며, 강사가 사용하는 감독관의 단말은 상기 학습 콘텐츠 서버를 통해 1:N방식으로 복수의 학습자 단말들로 질의 응답 채팅 데이터를 송수신하는 단계를 더 포함하며,상기 사용자 단말은 비대면 강의 학습 콘텐츠를 재생하는 VOD 미디어 플레이어; 강사와 학습자와의 채팅 데이터를 송수신하는 채팅 모듈; 상기 사용자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하고 얼굴의 윤곽선과 눈2/코/귀2의 5점 척도 얼굴의 특징점들을 인식하는 안면인식 모듈; 및 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의거리가 일정 기준치를 넘는 경우) 또는 학습자의 음성을 인식한 경우 주의집중 학습되도록 해당 사용자 단말로알람을 발생하거나 또는 경고 메시지를 출력하는 학습자의 알람 발생부를 포함하며, 상기 사용자 단말은 학습자의 음성을 인식하는 음성인식 모듈을 더 포함하고, 상기 안면인식 모듈은 AI 기반 안면윤곽선 인식 기술로써 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 측정하고 눈과 귀의 거리, 코와 귀의 거리를 측정하는 posenet 알고리즘을 사용하는, 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 방법."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 학습 콘텐츠 서버는 스마트폰을 사용시에 인식 코드로써 QR 코드를 인식하는 기능을 제공하는 단계를 더포함하는 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 방법."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 사용자 단말은 정면 카메라를 구비하는 태블릿 PC, 스마트폰, PC 중 어느 하나의 단말을 사용하며, 상기학습 콘텐츠 서버로부터 다운로드된 상기 교육 콘텐츠 viewer가 설치되는, 웹 브라우저 기반의 비대면 학습에서주의집중 학습 방법."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 상기 안면인식 모듈은 비대면 온라인 학습 시에 크기 보정/회전/각도 보정된 표준 크기의 학습자의 얼굴 사진에대하여 정면 얼굴인식 알고리즘을 사용하여 얼굴 객체를 추출하고 얼굴 행동 패턴을 인식하여 학습자의 얼굴의윤곽선과 눈2/코/귀2의 얼굴의 특징점들을 추출하며, 눈2/코/귀2의 얼굴의 특징점들의 각각 좌측/우측 귀와 좌측/우측 눈의 중심점(동공)과의 유클리디안 거리(d)와 유사도(similarity)를 계산하고, 얼굴사진 DB의 사용자의정면 얼굴 사진의 특정점들과 비교하여 시선 이탈 여부를 확인하며, 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 시선 이탈과 관련된 얼굴 패턴을 검출하며, 얼굴 인식시에 안면윤곽선 인식이 안되는 경우, 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 사용자 단말의 카메라로 촬영되는 얼굴 행동 패턴을 인식하여 전면 얼굴이 좌우로 돌아간 각도에 따라 우측 눈과 우측 귀의거리와 좌측 눈과 좌측 귀의 거리가 달라지므로 해당 사용자 단말에서 알람을 발생하거나 또는 경고 메시지를출력하는, 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 방법."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서, 상기 학습 콘텐츠 서버는 WWW 서버; 상기 사용자 단말로 온라인 학습 콘텐츠를 제공하도록 제어하는 제어부; 상기 제어부에 연결되며, 회원 정보를 등록받아 ID/Passwd를 저장하여 관리하는 회원 등록부; 공개특허 10-2024-0150749-5-상기 제어부에 연결되며, QR 코드/Passwd 또는 ID/Passwd 또는 개인 인증서를 사용하여 인증하는 사용자인증부; 상기 제어부에 연결되며, 상기 사용자 단말로 상기 온라인 학습(Learning) 콘텐츠를 제공하는 학습 콘텐츠 제공부; 상기 제어부에 연결되며, 사용자 정보에 대응하는 QR 코드를 발급하고 관리하는 QR 코드 관리부; 상기 제어부에 연결되며, 사용자 단말로부터 카메라의 응시자의 촬영 사진을 수신받아 표준 크기로 크기 보정/회전/각도 보정을 통해 정면 얼굴 사진으로 변환하고 서버의 데이터베이스에 기 저장된 사용자 정보와 정면 얼굴 사진을 비교하여 감독관 단말에서 감독관이 확인하여 온라인 학습 자격을 확인하는 감독관 확인부; 상기 제어부에 연결되며, 사용자 단말에서 안면인식 모듈을 사용하여 학습자의 얼굴의 윤곽선과 눈2/코/귀2 특징점들을 인식하고 사용자 단말로부터 얼굴 인식 결과를 수신받는 얼굴 인식부; 및응시자 단말들의 시험지와 작성 답안, 채점 결과를 저장하는 시험 정보DB; 응시자 정보와 표준 크기의 정면 얼굴 사진을 저장하는 응시자DB와 얼굴 DB;를 포함하는 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 방법."}
{"patent_id": "10-2024-0136134", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 학습 콘텐츠 서버가 응시자 정보들과 응시자의 현장 얼굴 사진, 감독관 정보를 시험 서버의 데이터베이스에 저장하여 관리하며, 온라인 시험 또는 UBT 시험 시에 일정 시험시간 동안 각각의 응시자 단말에 시험지 작성답안을 저장후 시험 종료 시 응시자 단말로부터 시험관리부를 구비하는 상기 학습 콘텐츠 서버로 전송받아 저장하며, 응시자들의 시험지 작성 답안의 채점 결과를 응시자 단말로 제공하는 단계를 더 포함하는 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 방법."}
{"patent_id": "10-2024-0136134", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "웹 브라우저 기반의 비대면 학습에서 주의집중 학습 시스템 및 방법이 개시된다. 상기 웹 브라우저 기반의 비대 면 학습에서 주의집중 학습 시스템은 비대면 강의 학습 콘텐츠를 제공하는 학습 콘텐츠 서버; 및 상기 학습 콘텐 츠 서버에 접속하여 교육 콘텐츠 viewer를 구동하며, 비대면 학습에서 사용자 단말의 정면 카메라 영상 데이터의 (뒷면에 계속)"}
{"patent_id": "10-2024-0136134", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 비대면 학습(ubcloud)에서 인공지능을 사용한 주의집중 학습 시스템 및 방법에 관한 것으로, 보다 상 세하게는 온라인 강의 비대면 학습에서 사용자 단말의 교육 콘텐츠 viewer는 미디어 재생부와 안면윤곽선 인식 부 모듈을 구비하고, 학습 콘텐츠 서버(ubcloud 서버)에 연동된 사용자 단말의 정면 카메라에 포커싱된 학습 콘 텐츠에 시선을 바로 보고 주의 집중교육되도록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도 안면윤곽 선 인식을 통해 일정 각도로 사용자 단말을 바라보는 시선이 빗나갈 경우 소리와 메시징 기술을 사용하여 해당 사용자 단말로 알람/경고 메시지를 발생하며, 비대면 학습에서 웹브라우저 기반의 ubcloud 인공지능 사용한 주 의집중 학습을 제공하는, 웹 브라우저 기반의 비대면 학습(ubcloud)에서 인공지능을 사용한 주의집중 학습 시스 템 및 방법에 관한 것이다."}
{"patent_id": "10-2024-0136134", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "얼굴 인식(Face Recognition) 기술은 형상 기반 매칭 방법(appearance based matching method), 및 특징 (feature) 기반의 얼굴 인식이 주로 사용된다. 얼굴 인식은 카메라의 촬영 각도, 조명의 방향, 자세(pose), 표 정의 변화 및 시간에 따른 얼굴의 변화에 따라 다르게 인식된다. 특징(feature) 기반의 얼굴 인식은 디지털 카메라, IoT 디바이스의 카메라 또는 스마트폰의 카메라로 촬영된 영 상 데이터를 Haar-like feature를 이용한 검출 방법과 MCT(Modified Census Transform) 영상을 이용한 검출 방 법이 사용된다. 스마트폰의 카메라의 입력 영상에서 Haar-like feature로 학습된 얼굴 및 눈 검출기를 사용하여 얼굴의 윤곽선과 이마/눈/코/입 특징점들을 검출하고, 원형의 눈동자를 검출하기 위해 관심 영역(ROI, Region of Interest)으로 설정된 눈 영역을 grayscale로 변환하며, 눈 영역에서 눈동자와 눈의 외곽선 영역이 추출되는 실험에 의한 통계적인 임계값(threshold)을 사용하여 눈 이미지의 histogram [x축 각 픽셀의 화소값, y축 해당 화소 값의 갯수]을 구하고 눈의 이미지를 이진화(binarization)한 후, 히스토그램 평활화(histogram equalization)를 통해 눈 영역의 사진의 전처리를 수행하며, 얼굴 영역에서 눈썹과 눈, 코, 입, 윤곽선의 얼굴 특징점을 갖는 얼굴데이터를 검출하고, 텍스처 특징(texture features)과 형상 특징(shape features)을 추출하여 얼굴 인식 DB에 저장된 얼굴 사진의 특징점들과 유사도를 비교하여 얼굴이 인식된다. 얼굴 영역의 눈썹과 눈, 코, 입, 턱의 특징 값은 Haar-like feature의 흰 영역에서 포함되는 픽셀들의 합에서 검은 영역에서 포함되는 픽셀의 합의 차로 표현된다. 예를들면, 가로와 세로 표준 크기의 얼굴 영역 사진에서 검출된 눈 영역에서 오른쪽과 왼쪽 눈의 양쪽 끝점 까 지의 거리, 허프 원 변환(hough circle transform) 알고리즘을 사용하여 추출된 눈동자(iris)의 크기 값이 특징 값으로 사용된다. 도 1a는 기존 얼굴 인식 장치의 구성도이다. 얼굴 인식 장치는 영상 표시 장치, 영상 촬영 장치, 얼굴 인식 서버, 태블릿 PC, 랩톱(Laptop), 개인용 PC, 스마트폰, 개인 휴대용 정보 단말기(Personal Digital Assistant, PDA), 이동통신 단말기, 및 지능형 로봇 (Intelligence Robot) 등 중 어느 하나일 수 있다. 얼굴 인식 장치는 카메라로부터 입력 영상을 획득하는 입력 영상 획득부; 상기 입력 영상에서 얼굴 영역을 검출하여 얼굴 포즈(Pose)를 정규화함으로써 정면 포즈 영상을 생성하고, 상기 카메라와 피사체 간의 거 리에 따른 원근왜곡(Perspective Distortion)을 제거하기 위하여 상기 정면 포즈 영상의 원근감(Perspective) 을 정규화하여 정규화 영상을 생성하는 정규화부; 상기 정규화 영상으로부터 상기 피사체의 얼굴을 표현하 는 특징 벡터(feature vector)를 추출하는 특징 벡터 추출부; 및 기 학습된 분류 모델에 상기 특징 벡터를 적용하여 상기 입력 영상에 포함된 상기 피사체의 얼굴을 인식하는 얼굴 인식부를 포함한다. 입력 영상 획득부는 카메라로부터 입력 영상을 획득한다. 카메라는 깊이 인식 카메라, 스테레오 카메라, 및 컬러 카메라일 수 있다(예를 들면, 키넥트(Kinect) 카메라 등). 또한, 입력 영상은 인식 대상이 되는 피사체 의 얼굴이 포함된 영상으로서 2차원 정지 영상 및 동영상을 포함한다. 입력 영상은 컬러 영상, 깊이영상, 및 컬 러-깊이(RGB-D) 영상을 포함할 수 있다. 정규화부는 입력 영상으로부터 얼굴 영역을 검출하고 얼굴 포즈(Pose) 및 원근감(Perspective)을 정규화하 여 정규화 영상을 생성한다. 얼굴 포즈에 변화가 있는 경우, 그레이 스케일, 형상, 특징점의 위치 등이 달라지 기 때문에 얼굴인식률이 저하된다. 또한, 카메라와 피사체 간의 거리가 달라지면 동일한 피사체라 하더라도 촬 영된 위치마다 원근 왜곡(Perspective Distortion, 뒤틀림)이 다르게 발생하므로, 다른 피사체를 촬영한 것처럼 보이기도 한다. 따라서, 얼굴인식률을 향상시키기 위해 입력 영상의 얼굴 포즈 및 원근감을 정규화할 필요가 있 다. 정규화부는, 다양한 포즈의 학습용 얼굴 영상을 제1 인공신경망의 입력층에 입력하고, 정면포즈의 학습용 얼굴 영상이 상기 제1 인공신경망의 출력층에서 출력되도록 상기 제1 인공신경망을 학습시키는 얼굴포즈 정규화 학습부; 및 상기 제1 인공신경망의 출력층에서 출력된 데이터를 제 2 인공신경망의 입력층에 입력하고, 원근왜 곡이 없는 학습용 얼굴영상이 상기 제 2 인공신경망의 출력층에서 출력되도록 상기 제2 인공신경망을 학습시키 는 원근감 정규화 학습부를 포함한다. 상기 정규화부는, 학습이 완료된 상기 제1 인공신경망과 상기 제2 인공신경망을 통합한 통합 인공신경망의 입력 층에 다양한 원근 왜곡이 있는 다양한 포즈의 학습용 얼굴영상을 입력하고, 정면 포즈의 원근왜곡이 없는 학습 용 얼굴영상이 상기통합 인공신경망의 출력층에서 출력되도록 상기 통합 인공신경망을 학습시킨다. 특징 벡터 추출부는 기계학습(Machine Learning)을 통해 결정되며, 정규화 영상으로부터 피사체의 얼굴을 표현하는 특징 벡터(feature vector)를 추출한다. 특징 벡터는 얼굴 인식에 사용되는 특징값들을 원소로 가지는 벡터이다. 특징 벡터를 추출하는데 사용되는 필터 로써 Gabor 필터, Haar 필터, LBP(Local Binary Pattern) - DLBP(Discriminative LBP), ULBP(Uniform LBP), NLBP(Number LBP) 등을 포함 - 등이 있으나, 반드시 이에 한정되지 않으며 그 밖의 다른 필터가 사용될 수 있다. 얼굴 인식부는 기 학습된 분류 모델에 특징벡터 추출부에서 추출된 특징벡터를 적용하여 입력 영상에 포함된 피사체의 얼굴을 인식한다. 기 학습된 분류 모델은 서포트 벡터 머신(Support Vector Machine, SVM), 선 형판별분석(Linear Discriminant Analysis, LDA), 및 Softmax 등을 포함할 수 있으나, 반드시 이에 한정되지 않는다. 가상 얼굴영상 생성부는 정규화부, 특징벡터 추출부, 및 얼굴 인식부가 학습하는데 사용되 는 복수의 가상 얼굴 영상을 생성할 수 있다. 복수의 가상 얼굴영상은 가상 얼굴영상 생성부가 카메라로부터 획득된 하나 이상의 2차원 기준 영상을 이 용하여 합성한 3차원 얼굴 모델을 변형시킴으로써생성되는 얼굴 영상을 의미한다. 이와 관련된 선행기술1로써, 특허 등록번호 10-2103521에서는 “인공지능 심층학습 기반의 영상물 인식 시스템 및 방법“이 등록되어 있다. 도 1b는 종래의 인공지능 심층학습 기반의 영상물 인식 시스템의 구성도이다. 인공지능의 심층 학습(Deep Learning)으로 다양한 이미지를 사전 학습하고, 상기 사전 학습 결과를 반영하여 유통되는 영상물에 대해 프레 임 단위로 이미지를 분석하고, 경우에 따라 영상물의 음성 정보도 함께 분석하여 시간순으로 키워드를 도출해 낸 후, 사전에 축적되어 있던 영상물 대본의 시계열적 키워드와 비교하는 방식의 인공지능 심층 학습 기반의 영 상물 인식 시스템 및 방법을 제공한다. 인공지능에 의해 구현되는 시스템은, 다수의 오브젝트 이미지를 키워드로 심층학습(DeepLearning)하는 데이터셋 학습부; 영상물 대본에서 키워드를 추출하여 시계열적으로 나열, 저장하는 DB부; 영상물을 프레임 단위 이미지 분석을 통해, 이미지 상의 오브젝트들과 오브젝트 간의 관계를 키워드로 추출하여 시계열적으로 나열하는 영상 물 분석부; 및 상기 DB부와 영상물 분석부의 키워드를 비교하여 유사성을 판단하는 비교판단부를 포함한다. 그러나, 기존의 이러닝 또는 유러닝 시스템은 단순히 온라인 학습 콘텐츠를 제공하였으나, 얼굴 인식 기술과 소 리와 메시징 기술을 사용하여 학습자의 부주의하게 얼굴 시선이 이탈하면, 알람을 발생하고 주의집중 학습이 되 도록 하는 기능을 제공하지 않았다. 선행기술문헌 특허문헌 (특허문헌 0001) 특허 등록번호 10-2103521 (등록일자 2020년 04월 16일), \" 인공지능 심층학습 기반의 영상물 인식 시스템 및 방법\", 상명대학교 산학협력단"}
{"patent_id": "10-2024-0136134", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기 문제점을 해결하기 위한 본 발명의 목적은 온라인 강의 비대면 학습에서 사용자 단말의 교육 콘텐츠 viewer는 미디어 재생부와 안면윤곽선 인식부 모듈을 구비하고, 학습 콘텐츠 서버(ubcloud 서버)에 연동된 사용 자 단말의 정면 카메라에 포커싱 된 학습 콘텐츠에 시선을 바로보고 비대면 강의 학습 콘텐츠를 주의 집중교육 되도록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도 안면윤곽선 인식을 통해 일정 각도로 시선이 빗 나갈 경우 소리와 메시징 기술을 사용하여 해당 사용자 단말로 알람/경고 메시지를 발생하며, 비대면 학습에서 웹브라우저 기반의 ubcloud 인공지능 사용한 주의집중 학습을 제공하는, 웹 브라우저 기반의 비대면 학습에서 인공지능을 사용한 주의집중 학습 시스템을 제공한다. 본 발명의 다른 목적은 웹 브라우저 기반의 비대면 학습에서 인공지능을 사용한 주의집중 학습 방법을 제공한다."}
{"patent_id": "10-2024-0136134", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 목적을 달성하기 위해, 웹 브라우저 기반의 비대면 학습에서 인공지능을 사용한 주의집중 학습 시스 템은 비대면 온라인 강의 학습 콘텐츠를 제공하는 학습 콘텐츠 서버; 상기 학습 콘텐츠 서버에 유무선 통신망을 통해 접속하여 교육 콘텐츠 viewer를 구동하며, 비대면 온라인 학습에서 사용자 단말의 정면 카메라 영상 데이 터의 AI 안면인식/동작인식 소리 재생 기술을 사용하여 학습 콘텐츠를 인공지능 주의 집중 학습하도록 교육 콘 텐츠 viewer가 설치된 사용자 단말; 및 강사가 사용하는 감독관의 단말을 포함하고, 상기 강사가 사용하는 감독관의 단말은 상기 학습 콘텐츠 서버를 통해 1:N 방식으로 복수의 학습자 단말들로 질 의 응답 채팅 데이터를 송수신하며, 상기 사용자 단말은 비대면 강의 학습 콘텐츠를 재생하는 VOD 미디어 플레이어; 강사와 학습자와의 채팅 데이터 를 송수신하는 채팅 모듈; 상기 사용자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하고 눈2/코/귀2의 얼굴의 특징점 5점 척도를 인식하는 안면인식 모듈; 및 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3 점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준치 를 넘는 경우) 또는 학습자의 음성을 인식한 경우 주의집중 학습되도록 해당 학습자의 사용자 단말로 알람을 발 생하거나 또는 경고 메시지를 출력하는 학습자의 알람 발생부를 포함하며, 상기 사용자 단말은 학습자의 음성을 인식하는 음성인식 모듈을 더 포함하고, 상기 안면인식 모듈은 AI 기반 안면윤곽선 인식 기술로써 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 측정 하고 눈과 귀의 거리, 코와 귀의 거리를 측정하는 posenet 알고리즘을 사용하며, 상기 교육 콘텐츠 viewer는 VOD 미디어 플레이어와 채팅 화면, 온라인 학습 메모 공간을 구비하고, 비대면 온라인 학습에서, 강사의 단말은 상기 학습 콘텐츠 서버를 통해 1:N 방식으로 복수의 학습자 단말들로 질의 응답 채팅 데이터를 송수신한다. 상기 사용자 단말의 정면 카메라에 포커싱된 비대면 온라인 강의 학습 콘텐츠에 시선을 바로보고 주의 집중교육 되도록 눈2/코/귀2의 얼굴의 특징점 5점 척도 안면윤곽선 인식을 통해 일정 각도로 시선이 빗나갈 경우 소리와 메시징 기술을 사용하여 알람/경고 메시지를 발생한다. 본 발명의 다른 목적을 달성하기 위해, 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 방법은 (a) 사용자 단말로부터 학습자 정보와 표준 크기의 정면 얼굴 사진을 학습 콘텐츠 서버가 등록받아 저장하는 단계; (b) 상 기 학습 콘텐츠 서버가 사용자 정보와 정면 얼굴 사진에 대응하는 QR 코드를 발급하는 단계; (c) 교육 콘텐츠 viewer와 안면인식 모듈을 구비하는 사용자 단말에서 정면 카메라 영상의 정면 얼굴인식 알고리즘을 사용하여 카메라의 전면 얼굴 사진의 인식 결과를 상기 학습 콘텐츠 서버로 수신받아 기 등록된 학습자 정보와 표준 크기 의 정면 얼굴 사진과 그 얼굴 특징점들을 비교하여 학습자 본인 여부를 확인하는 단계; (d) 상기 학습 콘텐츠 서버로부터 학습 콘텐츠를 기 등록된 회원의 사용자 단말로 제공하는 단계; 및 (e) 상기 학습 콘텐츠 서버는 각 학습자의 사용자 단말에서 카메라로 검출된 온라인 학습자의 얼굴 영상을 분석하여 시선이 일정 각도로 벗어난 경우 또는 학습자의 음성을 인식한 경우 주의집중 학습되도록 해당 사용자 단말로 경고 메시지 또는 알람을 발 생하는 단계를 포함하고, 비대면 온라인 학습에서, 상기 사용자 단말에 설치된 상기 교육 콘텐츠 viewer는 VOD 미디어 플레이어와 채팅 화면, 온라인 학습 메모 공간을 구비하며, 강사가 사용하는 감독관의 단말은 상기 학습 콘텐츠 서버를 통해 1:N 방식으로 복수의 학습자 단말들로 질의 응답 채팅 데이터를 송수신하는 단계를 더 포함하며, 상기 사용자 단말은 비대면 강의 학습 콘텐츠를 재생하는 VOD 미디어 플레이어; 강사와 학습자와의 채팅 데이터 를 송수신하는 채팅 모듈; 상기 사용자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하고 눈2/코/귀2의 5점 척도 얼굴의 특징점들을 인식하는 안면인식 모듈; 및 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준 치를 넘는 경우) 또는 학습자의 음성을 인식한 경우 주의집중 학습되도록 해당 학습자의 사용자 단말로 알람을 발생하거나 또는 경고 메시지를 출력하는 학습자의 알람 발생부를 포함하며, 상기 사용자 단말은 학습자의 음성 을 인식하는 음성인식 모듈을 더 포함하고, 상기 안면인식 모듈은 AI 기반 안면윤곽선 인식 기술로써 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 측정 하고 눈과 귀의 거리, 코와 귀의 거리를 측정하는 posenet 알고리즘을 사용한다."}
{"patent_id": "10-2024-0136134", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 웹 브라우저 기반의 비대면 학습에서 인공지능을 사용한 주의집중 학습 시스템 및 방법은 비대면 학 습에서 사용자 단말의 교육 콘텐츠 viewer는 미디어 재생부와 안면윤곽선 인식부 모듈을 구비하고, 학습 콘텐츠 서버(ubcloud 서버)에 연동된 사용자 단말의 정면 카메라에 포커싱 된 비대면 강의 학습 콘텐츠에 시선을 바로 보고 주의 집중교육되도록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도 안면윤곽선 인식을 통해 일정 각도로 시선이 빗나갈 경우 소리와 메시징 기술을 사용하여 해당 사용자 단말로 알람/경고 메시지를 발생하며, 비대면 학습에서 웹브라우저 기반의 ubcloud 인공지능 사용한 주의집중 학습을 제공하는 효과가 있다."}
{"patent_id": "10-2024-0136134", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부된 도면을 참조하여 발명의 구성 및 동작을 상세하게 설명한다. 본 발 명의 설명에 있어서 관련된 공지의 기술 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 자세한 설명을 생략한다. 또한, 첨부된 도면 번호는 동일한 구성을 표기할 때에 다 른 도면에서 동일한 도면 번호를 부여한다. 본 발명의 웹 브라우저 기반의 비대면 학습에서 인공지능을 사용한 주의집중 학습 시스템 및 방법은 비대면 학 습에서 사용자 단말의 교육 콘텐츠 viewer는 미디어 재생부와 안면윤곽선 인식부 모듈을 구비하고, 학습 콘텐츠 서버(ubcloud 서버)에 연동된 사용자 단말의 정면 카메라에 포커싱된 비대면 강의 학습 콘텐츠에 시선을 바로보 고 주의 집중교육되도록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도 안면윤곽선 인식을 통해 일정 각도로 시선이 빗나갈 경우 소리와 메시징 기술을 사용하여 해당 사용자 단말로 알람/경고 메시지를 발생하며, 비대면 학습에서 웹브라우저 기반의 ubcloud 인공지능 사용한 주의집중 학습을 제공한다. * 안면 특징점 및 윤곽선 인식 기술 동일(ubcloud) * 학습 콘텐츠 서버와 시험 시버 기능 추가됨 * 브라우저 기반인 점과, 온라인(학습 데이터 기반 온라인에서 읽어오고 온라인에 저장)/오프 라인(라이브러리 브라우저 내장과 웹페이지에 내장하고 인식 데이터를 사용자 기기에 저장)을 모두 활용 가능한 점이 특징 * 소리와 메시징을 활용하여 주의집중을 시킴 본 발명의 웹 브라우저 기반의 비대면 학습에서 인공지능을 사용한 주의집중 학습 시스템 및 방법은 비대면 온 라인 학습 시에, 사용자 단말(태블릿 PC, 스마트폰, PC)은 학습 콘텐츠 서버와 연동되는 교육 콘텐츠 viewer가 설치되고, AI 안면인식/동작인식/소리와 메시징 기술을 사용하여 사용자 단말의 정면 카메라를 사용한 AI 기반 안면 인식(posenet 알고리즘, machine learning model which allows for real-time face pose estimation) 기 술을 사용하는 얼굴의 윤곽선과 눈2/코/귀2의 5점 척도 얼굴의 특징점들을 인식하는 안면인식 모듈이 탑재되며, 얼굴 인식 시에 응시자 단말의 정면 카메라(C)를 사용하여 촬영된 정면 얼굴 사진을 학습 콘텐츠 서버의 얼굴 사진 DB의 표준 크기의 학습자의 정면 얼굴 사진의 얼굴특징점들과 비교하여 학습자의 출석 여부를 검출하고, 비대면 온라인 학습에서, 사용자 단말의 정면 카메라 영상 데이터를 사용하여 실시간으로 AI 기반 안면윤곽선을 인식하여 학습자의 영상의 얼굴의 행동 패턴을 검출하여 학습 콘텐츠 서버(ubcloud 서버)에 연동된 사용자 단말 의 정면 카메라에 포커싱 된 비대면 온라인 강의 학습 콘텐츠에 시선을 바로보고 주의 집중교육되도록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도 안면윤곽선 인식을 통해 일정 각도로 시선이 빗나갈 경우 해당 학습자의 사용자 단말로 알람/경고메시지를 발생하며, 소리와 메시징 기술을 사용하여 주의 집중되도록 한다. 사용자 단말은 학습 콘텐츠 서버로부터 유무선 통신망을 통해 온라인 학습 콘텐츠를 제공받는 스마트폰, 태블릿 PC 뿐만 아니라, 인터넷 접속이 가능한 노트북을 포함한다. 사용자 단말은 학습 콘텐츠 서버와 연동되는 교육 콘텐츠 viewer가 설치되며, AI 안면 인식/동작 인식/소리와 메시징 기술을 사용하여 학습자 얼굴의 윤곽선과 눈2/코/귀2의 5점 척도 얼굴의 특징점을 인식하는 안면인식 모 듈을 구비한다. 도 2a, 2b는 비대면 온라인 학습에서 웹 브라우저 기반 ubcloud 인공지능을 사용한 주의 집중 학습 시스템의 구 현 예이다. 도 3a는 온라인 학습 시에, 태블릿 PC, 스마트폰, PC 기반 학습 콘텐츠 서버를 구비하는 안면윤곽선 인식 인공 지능 플랫폼 개념을 보인 도면이다. 도 3b는 유비쿼터스 기반 NSDAI 플랫폼 상의 얼굴 인식 기능을 보인 도면이다. 도 3c, 3d는 비대면 온라인 학습과 시험 시에 태블릿 PC, 스마트폰, PC에서 사용하는 UBI cloud App, NS facere platform의 목표와 User Experience(1. 사용자 등록->2. 학습-> 3. QR 코드 생성 -> 4. UBT App/Web 로 그인(QR code/passwd, ID/passwd) -> 5. 감독자 확인과 시험-> 6.7 UBT App/Web 카메라의 얼굴의 안면윤곽선 인식 8. 시험 종료)를 보인 그림이다. 도 4는 학습자/시험 응시자 등록부터 시험 응시부의 과정, 1) 응시자 등록, 2) 학습, 3) QR 코드 발급, 4) QR 코드 및 얼굴 인식, 5) 감독관 확인(응사자 얼굴/응시자 정보), 6) 시험응시 - 프로세스를 보인 그림이다. 도 5는 등록된 응시자 얼굴 기계학습 및 학습 결과를 바탕으로 응시자-얼굴 매칭 코드 발급부 - 온라인 시험 /UBT 시험시에 응시자 등록/학습/QR 코드 발급 화면이다. 도 6은 시험 응시자 얼굴의 AI 기반 안면윤곽선 인식을 통해 코의 정점을 기준으로 표준 크기의 정면 얼굴 사진 의 얼굴 특징점들의 거리와 유사도(similarity)를 측정한 UBT 시스템에서 응시자 확인부 화면이다. 도 7은 학습자 판정시 규칙 사용자 정의부, 프로그램 테스트 화면이다. 도 8은 비대면 온라인 학습시에 학습 콘텐츠 서버 접속/로그인/왼쪽- QR 코드 인식/QR 코드 인식 시에 인사말 들림(TTS)/오른쪽-얼굴 인식(스마트폰/태블릿PC 전면 카메라)/배경에서 얼굴 영역 인식 시작/인식율 표시 과정 을 포함하는 시연 화면 - 생성된 사용자 코드 활용 UBT 인증 프로세스 사용자 정의부 -이다. 사용자 단말은 교육 콘텐츠 viewer가 설치되고, 교육 콘텐츠 viewer는 인공지능 안면인식을 사용하여 학습 자 얼굴 영상의 눈2/코/귀2의 얼굴 특징점들을 인식하는 5점 척도 안면인식 모듈이 탑재되었다. 온라인 학습과 시험을 위한 인식 코드로써 QR 코드를 사용하였다. 실시예에서는, 사용자 단말은 태블릿 PC를 사용하고, 인식 코드는 QR 코드를 사용하였다. 학습자/시험응시자의 등록 사진을 학습한 인공지능이 사용자별 인식코드(QR 코드)를 생성하고, 응시자는 해당 인식 코드(QR 코드)가 부착된 응시표를 시험장 PC 또는 태블릿 PC의 카메라에 비춘 후, 사용자 인식한 AI 모듈 이 해당 응시자 정보와 정면 얼굴 사진(코를 정점으로 한 표준 크기의 정면 얼굴 사진)을 학습 콘텐츠 서버의 얼굴 DB의 기 등록된 응시자 정보와 표준 크기의 정면 얼굴 사진을 미리 학습한 결과모델을 비교하고, 얼굴의 특징점들의 유사도(similarity)를 계산하여 일정 수치가 넘으면 본인으로 인식하고, 학습 화면으로 이동, 학습자가 비대면 온라인 학습하게 된다. 얼굴의 특징점들의 유사도가 일정 수치 미만인 경우(완전 미달, 판정 보 류)의 경우, 서버를 통해 감독관 단말에 정보를 전달하여 감독관이 실제 얼굴 확인과 개인 정보 확인을 거쳐 온 라인 학습을 실시한다. <시스템 구성> 1) 비대면 온라인 학습 : 응시자 단말(PC/스마트폰/태블릿) 사용자 프로그램 -> 유무선 통신망(WAN, LTE 4G/5G) 및 내부망(LAN, Wi-Fi) -> 학습 콘텐츠 서버(학습 커리큘럼 정보/학습자 정보)로 각 사용자 단말의 정면 얼굴 사진과 학습자 정보를 전송하여 감독관 단말이 학습 참여 여부를 결정한다. 2) 오프 라인 활용시 : 사용자 프로그램 (PC/스마트폰/태블릿)에 인공지능 안면인식 모듈 탑재, 자체적으로 응 시자 얼굴의 안면윤곽선 인식 후, 최종 얼굴 안면인식 결과만 학습 콘텐츠 서버로 전송한다. <학습자 단말의 앱 프로토타입 일부 APK - 안드로이드용 첨부> https://we.tl/t-wFdXexsors 파일 다운로드 암호: nsdevil 안드로이드 스마트폰 또는 태블릿 PC에 앱(App)을 설치 <웹 버전 기능 주소> 1) 안면인식 모듈 : https://facere.nsdai.org (id: nsdevil, passwd: nsdevil) > QR 코드를 스마트폰으로 찍어 PC 카메라에 인식 화면에 대면 동작됨. 2) 얼굴의 윤곽선과 5점 척도 얼굴의 특징점들의 안면윤곽선 인식 모듈 : https://headpos.ublrandd.com.np (id: nsdevil, passwd: nsdevil), 학습자 얼굴의 눈2/코/귀2의 5점 척도 얼굴의 특징점들의 안면인식 3) 음성 인식 모듈 음성인식(Speech Recognition)은 man-machine 인터페이스 기술로써, 마이크로 입력된 음향 신호(Acoustic speech signal)에 대하여 잡음을 제거하고 음성 신호의 특징을 추출하여 단어의 집합 또는 문장의 텍스트로 변 환하는(mapping) 과정이며, 마이크-> AMP -> LPF -> ADC -> 음성 데이터베이스에 저장된다. 음성인식 모듈은 벡터 양자화(Vector Quantization)를 이용하는 방법, 동적 시간 정합(Dynamic Time Warping, DTW)을 이용하는 방법, 신경회로망(Neural Network)을 이용하는 방법, HMM(Hidden Markov Model, 은닉 마르코 프 모델)을 이용하는 방법이 사용된다. 음성 인식 모듈은 하드웨어와 소프트웨어가 모듈화된 음성인식기와 STT(Speech To Text) 기술의 음성인식 API를 사용하였다. 도 9는 본 발명에 따른 웹 브라우저 기반의 비대면 학습에서 안면윤곽선 인식 인공지능을 사용한 태블릿 PC, 스 마트폰, PC 기반 웹 브라우저 기반의 비대면 학습에서 인공지능을 사용한 주의집중 학습 시스템 구성도이다. 도 10은 온라인 학습과 시험시에, AI 기반 안면윤곽선 인식 모듈의 기능을 설명한 도면이다. 시험관리부를 구비하는 학습 콘텐츠 서버는 WWW 서버, 제어부, 회원 등록부, 사용자 인증 부, 학습 콘텐츠 제공부, QR 코드 관리부, 감독자 확인부, 얼굴 인식부, 시험 관리부 , 시험 정보DB, 응시자DB, 및 얼굴사진 DB를 포함한다. 본 발명의 웹 브라우저 기반의 비대면 학습에서 주의집중 학습 시스템은 저작 도구(authoring tool)에 의해 저작된 비대면 온라인 강의 학습 콘텐츠를 제공하는 학습 콘텐츠 서버; 상기 학습 콘텐츠 서버에 유무선 통신망을 통해 접속하여 교육 콘텐츠 viewer를 구동하며, 비대면 온라인 학습에서 사용자 단말의 정면 카메라 영상 데이터의 AI 안면인식/동작인식 소리 재생 기술을 사용하여 학습 콘 텐츠를 인공지능 주의 집중 학습하도록 교육 콘텐츠 viewer가 설치된 사용자 단말(300,310,311); 및 강사가 사 용하는 감독관의 단말을 포함하고, 상기 강사가 사용하는 감독관의 단말은 상기 학습 콘텐츠 서버를 통해 1:N 방식으로 복수의 학습자 단말들 로 질의 응답 채팅 데이터를 송수신하며, 상기 사용자 단말(300,310,311)은 비대면 강의 학습 콘텐츠를 재생하는 VOD 미디어 플레이어; 강사와 학습자와 의 채팅 데이터를 송수신하는 채팅 모듈; 상기 사용자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하 고 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도들을 인식하는 안면인식 모듈; 및 화면으로부터 일정각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리 의 해당 방향의 거리가 일정 기준치를 넘는 경우) 또는 학습자의 사용자 단말에서 학습자의 음성을 인식한 경우 주의집중 학습되도록 해당 학습자의 사용자 단말로 알람을 발생하거나 또는 경고 메시지를 출력하는 학습자의 알람 발생부를 포함하고, 상기 사용자 단말은 학습자의 음성을 마이크로 인식하는 STT(Speech To Text) 기술을 사용하는 음성인식 모듈을 더 포함하며, 상기 안면인식 모듈은 AI 기반 안면윤곽선 인식 기술로써 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 측정 하고 눈과 귀의 거리, 코와 귀의 거리를 측정하는 posenet 알고리즘을 사용하며, 사용자 단말의 정면 카메라에 포커싱된 비대면 온라인 강의 학습 콘텐츠에 시선을 바로보고 주의 집중교육되도 록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도 안면인식을 통해 일정 각도로 시선이 빗나갈 경우 또 는 학습자의 사용자 단말에서 학습자의 음성이 인식된 경우 주의집중 학습되도록 소리와 메시징 기술을 사용하 여 해당 사용자 단말로 알람/경고 메시지를 발생하고, 상기 교육 콘텐츠 viewer는 VOD 미디어 플레이어와 채팅 화면, 온라인 학습 메모 공간을 구비하며, 비대면 온라 인 학습에서, 강사의 단말(감독관 단말)은 학습 콘텐츠 서버를 통해 1:N 방식으로 복수의 학습자 단말들로 질의 응답 채팅 데이터를 송수신한다. 학습 콘텐츠 서버는, 비대면 온라인 학습 시에, 시간과 장소에 상관 없이 강사가 학습 콘텐츠를 제공하고 교육 콘텐츠 viewer의 온라인 학습 메모 공간(shared workspace)에 밑줄을 긋거나 텍스트, 그림, 사진, 음성 녹 음을 통해 강사의 발언권 제어(floor control)에 따라 강사의 단말(감독관 단말)과 복수의 학습자 단말들로 리 포트/학습 파일이 첨부된 파일 보내기/받기, 쪽지 보내기/받기를 제공하며, 비대면 강의 시에 강사의 단말(감독관 단말)은 학습 콘텐츠 서버를 통해 1:N 방식으로 복수의 학습자 단말 들로 교육 콘텐츠 viewer의 공유 작업 공간(shared workspace)에 글씨/그래픽 필기/메모 쓰기가 표시된다. 비대면 온라인 학습에서, 강사는 강사의 단말(감독관 단말)은 학습 콘텐츠 서버를 통해 1:N 방식으로 복수 의 학습자 단말들로 질의 응답 채팅 데이터를 송수신한다. 비대면 온라인 학습에서, 시간과 장소에 상관 없이 학습 콘텐츠 서버를 통해 온라인 학습 시에 강사는 학습 콘 텐츠를 제공하고 교육 콘텐츠 viewer의 온라인 학습 메모 공간(shared workspace)에 밑줄을 긋거나 텍스트, 그 림, 사진, 음성 녹음을 통해 강사의 발언권 제어(floor control)에 따라 강사의 단말(감독관 단말)과 복수의 학 습자 단말들로 리포트/학습 파일이 첨부된 파일 보내기/받기, 쪽지 보내기/받기를 제공한다. 비대면 온라인 학습에서, 비대면 강의 시에 강사의 단말(감독관 단말)은 학습 콘텐츠 서버를 통해 1:N 방 식으로 복수의 학습자 단말들로 교육 콘텐츠 viewer의 공유 작업 공간(shared workspace)에 글씨/그래픽 필기/ 메모 쓰기가 표시된다. 상기 학습 콘텐츠 서버는 스마트폰을 사용시에 인식 코드로써 QR 코드를 인식하는 기능을 제공한다. 상기 사용자 단말은 정면 카메라를 구비하는 태블릿 PC, 스마트폰, PC 중 어느 하나의 단말을 사용하며, 상기 학습 콘텐츠 서버로부터 다운로드된 상기 교육 콘텐츠 viewer가 설치되며, 상기 교육 콘텐츠 viewer는 VOD 미디어 플레이어와 채팅 화면을 구비한다. 상기 사용자 단말은 비대면 강의 학습 콘텐츠를 재생하는 VOD 미디어 플레이어; 강사와 학습자와의 채팅 데이터를 송수신하는 채팅 모듈; 및 상기 사용자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하고, 얼굴의 윤곽선과 눈2/코/귀2의 5점 척도 얼굴의 특징점들을 인식하는 안면인식 모듈; 및 화면으로부터 시선이 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 학습자의 사용자 단말로 알람을 발 생하거나 또는 경고 메시지를 출력하는 학습자의 알람 발생부를 포함한다. 상기 사용자 단말의 안면인식 모듈은 AI 기반 안면윤곽선 인식 기술로써 posenet 알고리즘을 사용한다. 상기 안면인식 모듈은 비대면 온라인 학습 시에 크기 보정/회전/각도 보정된 표준 크기의 학습자의 정면 얼굴 사진에 대하여 얼굴인식 알고리즘을 사용하여 얼굴 객체를 추출하고 얼굴 행동 패턴을 인식하여 학습자의 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점들을 추출하며, 눈2/코/귀2의 얼굴의 특징점들의 각각 좌측/우측 귀와 좌측/우측 눈의 중심점(동공)과의 유클리디안 거리(d)와 유사도(similarity)를 계산하고, 얼굴사진 DB의 사용자 의 얼굴 사진의 특정점들과 비교하여 시선 이탈 여부를 확인하며, 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 시선 이탈과 관련된 얼굴 패턴을 검출하며, 얼굴 인식시에 안면윤 곽선 인식이 안되는 경우, 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지 는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 사용자 단말의 카메라로 촬영되는 얼굴 행동 패턴을 인식하여 정면 얼굴이 좌우로 돌아간 각도에 따라 우측 눈과 우측 귀의 거 리와 좌측 눈과 좌측 귀의 거리가 달라지므로 해당 학습자 사용자 단말에서 알람을 발생하거나 또는 경고 메시 지를 출력하여 주의집중 학습되도록 한다. 상기 학습 콘텐츠 서버는 WWW 서버; 상기 사용자 단말로 온라인 학습 콘텐츠를 제공하도록 제어하는 제어부; 상기 제어부에 연결되며, 회원 정보를 등록받아 ID/Passwd를 저장하여 관리하는 회원 등록부; 상기 제어부에 연결되며, QR 코드/Passwd 또는 ID/Passwd 또는 개인 인증서를 사용하여 인증하는 사용자 인증부; 상기 제어부에 연결되며, 사용자 정보에 대응하는 QR 코드를 발급하고 관리하는 QR 코드 관리부; 상기 제어부에 연결되며, 상기 사용자 단말로 상기 온라인 학습(Learning) 콘텐츠를 제공하는 학습 콘텐츠 제공부; 상기 제어부에 연결되며, 강사와 학습자의 채팅 데이터를 송수신하는 채팅 서버; 상기 제어부에 연결되며, 사용자 단말로부터 카메라의 학습자/응시자의 정면 얼굴 사진을 수신받아 표준 크기의 크기 보정/회전/각도 보정을 통해 표준 크기의 정면 얼굴 사진으로 변환하고 서버의 데이터베이스에 기 저장된 사용자 정보와 표준 크기의 정면 얼굴 사진을 비교하여 감독관 단말에서 감독관이 확인하여 온라인 학습 /온라인 시험 자격을 확인하는 감독관 확인부; 상기 제어부에 연결되며, 사용자 단말에서 안면인식 모듈을 사용하여 학습자의 얼굴의 윤곽선과 눈2/코/귀 2의 얼굴의 특징점들을 인식하고, 사용자 단말로부터 얼굴 인식 결과를 수신받는 얼굴 인식부; 및 사용자 단말들의 시험지와 작성 답안, 채점 결과를 저장하는 시험 정보DB; 응시자 정보와 표준 크기의 정면 얼 굴 사진을 저장하는 응시자DB와 얼굴 DB를 포함한다. 추가적으로, 학습 콘텐츠 서버는 상기 제어부에 연결되며, 강사와 학습자의 채팅 데이터를 송수신하 는 채팅 서버를 더 포함한다. 추가적으로, 학습 콘텐츠 서버는 상기 제어부에 연결되며, 강사와 학습자의 리포트 파일 첨부가 가능 한 쪽지 데이터를 송수신하는 쪽지 보내기/받기 제공부를 더 포함한다. 추가적으로, 학습 콘텐츠 서버는 상기 제어부에 연결되며, 학습 데이터 파일을 송수신하는 FTP 서버 를 더 포함한다. 추가적으로, 온라인 시험 또는 UBT 시험 시에, 응시자 단말과 감독관 단말로 시험 프로그램(App)과 시험지를 제 공하며, 응시자 정보들과 응시자의 현장 얼굴 사진, 감독관 정보를 관리하며, 온라인 시험 또는 UBT 시험시에 일정 시험 시간 이내에 각각의 응시자 단말에 시험지 작성 답안을 저장한 후, 시험 종료시 시험 서버로 전송되 며, 응시자들의 시험지 작성 답안, 채점 결과, 감독관 정보와 응시자 현황 정보를 저장하여 관리하는 시험 관리 부를 더 포함한다. 추가적으로, 응시자 단말의 안면인식 모듈과 눈2/코/귀2 얼굴의 특징점 5점 척도 활용 부정행위 방지 모듈에서 사용하는 AI 기반 안면인식 기술은 태블릿 PC의 카메라 영상의 안면윤곽선과 얼굴의 특징점들을 인식하기 위해 posenet 알고리즘을 사용하였다. 온라인 시험 또는 UBT 시험시에, AI 기반 얼굴인식 기술을 사용하여 시험 서버 에 연동된 감독관 단말을 통해 태블릿 PC 응시자 본인을 확인하고, 온라인 학습 시에 주의 집중 학습하게 하거 나 또는 시험 시에 대리 시험을 방지하며, 온라인 학습, 온라인 시험 또는 UBT 시험에서 서버를 통해 응시자 얼 굴 인식과 음성 인식 기술에 의해 주의 집중 학습 또는 시험 시에 대리 시험이나 시각적인/청각적인 부정 행위를 방지한다. 시험 프로그램(App)의 시험지 문항은 주관식 및/또는 객관식 시험 문항을 포함하며, 각 문항마다 텍스트 및 이 미지 뿐만 아니라 텍스트, 이미지, VR/AR 콘텐츠, 음성과 동영상이 포함된 멀티미디어 시험 문항이 출제되어 서 버를 통해 사용자 단말로 디스플레이된다. 1. 인공지능 허브 플랫폼 ㆍ NSD-AI (NSDevil's Artificial intelligence) 플랫폼 기반 인공지능 허브플랫폼 ㆍ 어학, 의학교육 부문 구문 인식을 통한 교수자 채점 가이드(인제대학교 의과대학 외 공동연구) ㆍ 사물 인식을 통한 체험 학습 지원 시스템(펀에듀랩 및 한국민속촌 외) ㆍ 치아 이미지 분석을 통한 치과 교육 부문 질병 분석(연세대학교 치과대학 외 3개국 기관 공동 연구) ㆍ UBT connect platform 기반 ㆍ 태블릿 PC 기반 평가 플랫폼 ㆍ 어학평가 부문(말하기/듣기/읽기/쓰기) ㆍ 보건의료평가 부문(듣기/읽기/쓰기) ㆍ 기타 직무평가 부문(읽기/쓰기) 추가적으로, 시험 관리부를 구비하는 학습 콘텐츠 서버는 사용자 단말로부터 유무선 통신망을 통해 시험 응시자 정보와 정면 얼굴 사진을 등록받아 저장하고, 응시자들에게 응시표에 부착하는 QR 코드를 발급하며, 응 시자별 QR 코드 인식 후 TTS 변환 기술을 통해 인사말을 제공하며, 온라인 시험지와 온라인 시험 또는 UBT 시험 을 실시하기 위한 시험 프로그램을 응시자 단말들로 제공한다. 추가적으로, 온라인 시험 또는 UBT 시험은 2지/3지/4지/5지 선다 객관식 시험 뿐만 아니라 주관식 시험을 제공 하며. 주관식 시험 문항은 터치 센서와 디스플레이를 구비하는 응시자 단말의 필기체 인식부를 사용하여 스타일 러스 펜의 필기체를 인식하여 문자들로 변환하여 필기체 문자를 인식하는 주관식 시험을 제공한다. 온라인 시험지는 전체 객관식, 객관식/주관식 혼용하여 출제될 수 있다. 응시자 단말(300,310,311)은 시험 관리부를 구비하는 학습 콘텐츠 서버에 유무선 통신망(LAN, Wi-Fi, LTE 4G/5G)을 통해 연결되며, 시험 프로그램을 구동하며, AI 안면 인식/동작 인식/소리 인식 기술을 사용하여 응시 자 단말의 정면 카메라(C)를 사용하여 응시자 얼굴의 영상의 안면 인식/동작 인식, 응시자 단말의 마이크와 음 성인식 모듈을 통해 소리 인식을 통해 청각적인 부정행위를 감시하도록 응시자 단말의 정면 카메라(C)에 의해 촬영되는 응시자의 정면 얼굴 사진의 인공지능 안면인식 모듈과, 응시자 단말의 정면 카메라(C)로 촬영되는 얼 굴 행동 패턴을 인식하여 얼굴의 특징점을 구성하는 얼굴의 윤곽선과 눈2/코/귀2의 5점 척도 부정행위 방지 모 듈, 응시자의 음성 인식을 통해 청각적인 부정행위를 검출하는 음성인식 모듈을 구비하며, 시험관리부를 구비하 는 학습 콘텐츠 서버와 연동되는 응시자 단말에 녹음/녹화 프로그램이 설치된다. 감독관 단말은 온라인 시험 또는 UBT 시험 시에, 시험 관리부를 구비하는 학습 콘텐츠 서버를 통해 복수의 응시자 단말의 얼굴 사진과 부정행위 정보를 수신받고, 이를 확인하여 시험관리부를 구비하는 학습 콘텐츠 서버 를 통해 해당 응시자 단말로 부정행위 방지 알람 또는 메시지를 전송한다. 사용자 단말의 안면인식 모듈에 사용된 AI 기반 안면윤곽선 인식 기술은 posenet 알고리즘(machine learning model which allows for real-time face pose estimation)을 사용한다. 실시예에서는, 온라인 학습/온라인 시험 또는 UBT 시험 시에, 사용자 단말은 태블릿 PC를 사용하였다. 응시자 단말(300,310,311)은 학습자 얼굴 영상의 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점 5점 척도 안면인식 모듈이 구비된다. 추가적으로, 응시자 단말은 주관식 시험 문항을 위해 스타일러스 펜의 필기체를 인식하여 문자로 변환하여 필기 체 문자를 인식하는 터치 센서와 디스플레이를 구비하는 응시자 단말의 필기체 인식부를 더 포함한다. 응시자 단말(300,310,311)은 온라인 학습/온라인 시험 시에, 상기 안면인식 모듈에 사용된 AI 기반 안면윤곽선 인식 기술은 posenet 알고리즘을 사용한다. 온라인 시험 또는 UBT 시험 시에, 상기 눈2/코/귀2 얼굴의 특징점 5점 척도 안면인식 모듈은 응시자 단말의 정 면 카메라로 실시간으로 촬영된 얼굴 영상의 관심영역(ROI)을 검출하여 코의 정점을 기준으로 가로x세로 표준 크기로 크기 보정/회전/각도 보정을 통해 생성된 표준 크기의 정면 얼굴 사진에 대하여 얼굴인식 알고리즘을 사 용하여 얼굴 객체를 추출하고, 얼굴 행동 패턴을 인식하여 응시자의 얼굴의 윤곽선과 눈2/코/귀2의 얼굴특징점 들을 추출하며, 특징 추출과 분류를 통해 눈2/코/귀2의 얼굴의 특징점들의 각각 좌측/우측 귀와 좌측/우측 눈의 중심점(동공)과의 유클리디안 거리(d)와 유사도(similarity)를 계산하고, 온라인 시험 또는 UBT 시험 서버의 얼 굴사진 DB의 사진와 비교하여 대리 시험 여부를 확인하며, 온라인 시험 또는 UBT 시험시에 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 부정 행위와 관련된 얼굴의 이상 행동 패턴을 검출하며, 얼굴 인식시에 안면윤곽선 인식이 안되는 경우, 시험 화면으로부터 일정 각도 이상으로 벗어 난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거 리가 일정 기준치를 넘는 경우) 부정행위를 방지하도록 응시자 단말의 카메라로 촬영되는 얼굴 행동 패턴을 인 식하여 전면 얼굴이 좌우로 돌아간 각도에 따라 우측 눈과 우측 귀의 거리와 좌측 눈과 좌측 귀의 거리가 달라 지므로 시각적인 부정행위를 판단하여 시각적인 부정행위 이미지 또는 영상 데이터를 상기 시험관리부를 구비하 는 학습 콘텐츠 서버로 전송하고, 상기 시험 관리부를 구비하는 학습 콘텐츠 서버에 연동된 감독관 단말이 확인 후 상기 시험관리부를 구비하는 학습 콘텐츠 서버를 통해 해당 응시자 단말로 경고 메시 지 또는 알람을 발생한다."}
{"patent_id": "10-2024-0136134", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "(실시예) Posenet 알고리즘 모델을 사용하여 태블릿 PC의 Android에서 사람의 얼굴의 포즈 추정을 위해 TensorFlow를 사 용하였다. 참고로, Posenet 알고리즘은 행위 인식을 위해 사람의 얼굴과 몸체와 팔과 다리의 위치 주요 인체의 부위의 위치를 감지하여 이미지나 동영상으로부터 사람의 포즈(pose)를 추정하는 비전 모델이다. 얼굴 인식 시 에, TensorFlow Lite는 응시자 단말의 정면 카메라를 활용하여 얼굴 인식 시에 실시간으로 얼굴의 윤곽선과 눈 2/코/귀2의 얼굴의 특징점들을 식별하고, 얼굴의 안면안곽선 포즈 추정 모델을 구현하였다. 인공지능 안면인식 모듈에 사용된 posenet 알고리즘은 좌측 눈(leftEye), 우측 눈(rightEye), 코(nose), 왼쪽 귀(leftEar), 오른쪽 귀(rightEar)의 5점 척도 부정행위 방지 모듈을 사용하여 구현하였으며, leftEar의 x,y좌표와 rightEar의 x,y좌표를 구한 후 이를 기반으로 원의 직경(diameter)을 구하고 ellipse( ) 로 천사 고리를 만들 수 있다. diameter는 피타고라스 정리를 굳이 쓰지 않아도 p5js에서 dist( )로 쉽게 구할 수 있다. <ml5js 및 웹캠 연결하기> <script src=\"https://unpkg.com/ml5@0.3.1/dist/ml5.min.js\"></script> let video; let poseNet; function setup( ) { createCanvas(400, 400); video = createCapture(VIDEO); //비디오가 2번 안나오게 해주는 용도 video.hide( ); poseNet = ml5.poseNet(video,modelLoaded); poseNet.on('pose',gotPoses); console.log(ml5); } // 포즈 관련 콜백들이 들어감 function gotPoses(poses) { } // 로딩이 잘됐는지 확인하는 용도 function modelLoaded( ) { console.log('Model Loaded'); } function draw( ) { //0,0 위치에 웹캠을 그려준다. image(video,0,0); } 응시자 단말의 전면 카메라 얼굴 영상으로부터 실시간으로 얼굴 영역을 추출하고, 코의 꼭지점을 기준으로 표준 크기로 크기 보정/회전/각도 보정을 통해 정면 얼굴 사진의 표준 크기로 맞추며, 시험 서버의 기 저장된 표준 크기의 얼굴 사진 DB의 학습 데이터와 비교 -> 얼굴 사진의 학습 모델 -> 얼굴의 윤곽선과 눈2/코/귀2의 특징 점들을 추출하고 분류하며, 얼굴 인식 데이터의 얼굴의 윤곽선, 눈2/코/귀2 얼굴의 특징점들의 그룹 clustering(클러스터의 중심 k-means 알고리즘) density estimation하며, 얼굴의 특징점들의 거리(유클리디안 거리)와 유사도(similarity)를 계산하여 온라인 시험 또는 UBT 시험 서버의 얼굴 사진 DB에 저장된 표준 크기의 응시자의 정면 얼굴 사진의 얼굴 특징점들의 거리(d)와 유사도(similarity)를 비교하여 응시자 사진의 본인 여 부를 확인하여 대리 시험이 방지되며, 온라인 시험 또는 UBT 시험 시에 시각적인 부정행위를 판단하게 된다."}
{"patent_id": "10-2024-0136134", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "예를들면, 응시자 단말(태블릿 PC)의 시험 화면으로 응시자 단말의 전면 카메라로 촬영되는 얼굴이 향하는 방향 이 바뀌거나 응시자가 일정 각도로 얼굴을 돌리면 얼굴 사진의 눈2/코/귀2와 윤곽선의 얼굴의 특징점들이 인식 이 안되거나 사용자의 얼굴과 스마트폰의 유효 거리(20~30cm)내에서 학습 콘텐츠 또는 시험 프로그램을 향하는 각도가 달라지게 되면, 주의집중 학습을 안하거나 시험 시에 부정행위로 인식하며, 부정행위 감지 결과를 온라 인 시험 또는 UBT 시험관리부를 구비하는 학습 콘텐츠 서버로 전송하고, 이를 감독관 단말로 전송하 여 감독관이 확인 후 시험관리부를 구비하는 학습 콘텐츠 서버를 통해 해당 응시자 단말로 알람을 발생하 거나 경고 메시지를 전송하여 해당 응시자가 부정행위를 방지하게 한다. 또한, [텍스트 A] 데이터 참조 미리 정의된 응시자 프로그램에서 설정된 경고 임계치가 0이 되는 순간 서버 연 결 없이 응시자에게 경고 메시지를 표시하고, 감독관/부정행위 검출 서버/기타 시험 관리 서버로 역 전송할 수 있고, 또는 시험 종료 후 해당 raw data의 후처리를 위해 부정행위 검출 서버/기타 시험 관리 서버로 전송한다. 또한, 응시자 단말은 안면 인식 모듈, 눈2/코/귀2 얼굴의 특징점 5점 척도 부정행위 방지 모듈, 및 상기 부정행 위 방지 모듈은 응시자의 시각적인 부정행위를 방지하기 위해 응시자의 말소리를 인식하는 음성 인식 모듈을 더 구비하며, 온라인 학습, 온라인 시험 또는 UBT 시험 시에, 음성 인식 모듈은 응시자 단말의 마이크를 통해 입력된 부정행 위와 관련된 응시자의 말소리가 들리는 경우, 음성인식하고 이를 즉시 시험관리부를 구비하는 학습 콘텐츠 서버 로 전송하여 저장하며, 이를 감독관 단말로 부정행위 알림을 전송하여 감독관이 확인 후 학습 콘텐츠 서버를 통해 해당 응시자 단말로 알람을 발생하거나 경고 메시지를 전송하며, 부정행위를 방지하게 한다. 또는, 눈과 귀의 거리, 코와 귀의 거리의 표준 크기의 정면 얼굴 사진의 미리 정의된 거리의 임계치를 참조하여 서버 명령 없이 응시자 프로그램 자체에서 직접 해당 학습자/응시자 단말로 알람 또는 경고 메시지를 표시하고, 부정 행위를 정보를 시험 서버와 감독관 단말로 전송한다. 도 11은 본 발명에 따른 웹 브라우저 기반의 비대면 학습에서 안면윤곽선 인식 인공지능을 사용한 태블릿 PC, 스마트폰, PC 기반 주의집중 학습 방법을 나타낸 순서도이다. 본 발명의 웹 브라우저 기반의 비대면 학습에서 안면윤곽선 인식 인공지능을 사용한 태블릿 PC, 스마트폰, PC 기반 주의집중 학습 방법은 (a) 학습자 정보와 표준 크기의 정면 얼굴 사진을 학습 콘텐츠 서버로 등록받아 저 장하는 단계; (b) 상기 학습 콘텐츠 서버가 사용자 정보와 표준 크기의 정면 얼굴 사진에 대응하는 QR 코드를발급하는 단계; (c) 교육 콘텐츠 viewer와 안면인식 모듈을 구비하는 사용자 단말에서 정면 카메라 영상의 정면 얼굴 인식 알고리즘을 사용하여 카메라의 전면 얼굴 사진의 인식 결과를 상기 학습 콘텐츠 서버로 수신받아 표 준 크기의 크기의 보정/회전/각도 보정을 통해 표준 크기의 정면 얼굴 사진을 생성하고 서버의 데이터베이스에 기 등록된 학습자 정보와 표준 크기의 정면 얼굴 사진과 그 얼굴 특징점들을 비교하여 학습자 본인 여부를 확인 하는 단계; (d) 상기 학습 콘텐츠 서버로부터 학습 콘텐츠를 기 등록된 회원의 사용자 단말로 제공하는 단계; 및 (e) 상기 학습 콘텐츠 서버는 각 학습자의 사용자 단말에서 카메라로 검출된 온라인 학습자의 얼굴 영상을 분석하여 사용자 단말의 화면을 바라보는 시선이 일정 각도로 벗어난 경우 또는 학습자의 사용자 단말에서 학습 자의 음성을 인식한 경우 주의집중 학습되도록 해당 학습자의 사용자 단말로 경고 메시지 또는 알람을 발생하는 단계를 포함하고, 상기 방법은, 비대면 온라인 학습에서, 상기 사용자 단말에 설치된 상기 교육 콘텐츠 viewer는 VOD 미디어 플레 이어와 채팅 화면, 온라인 학습 메모 공간을 구비하며, 강사가 사용하는 감독관 단말은 교육 콘텐츠 viewer를 사용하여 상기 학습 콘텐츠 서버를 통해 1:N 방식으로 복수의 학습자 단말들로 질의 응답 채팅 데이터를 송수신하는 단계를 더 포함하며, 상기 사용자 단말은 비대면 강의 학습 콘텐츠를 재생하는 VOD 미디어 플레이어; 강사와 학습자와의 채팅 데이터 를 송수신하는 채팅 모듈; 상기 사용자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하고 얼굴의 윤곽 선과 눈2/코/귀2의 5점 척도 얼굴의 특징점들을 인식하는 안면인식 모듈; 및 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 또는 학습자의 음성을 인식한 경우 주의집중 학습되도록 해당 사용자 단말로 알람을 발생하거나 또는 경고 메시지를 출력하는 학습자의 알람 발생부를 포함하며, 상기 사용자 단말은 학습자 의 음성을 마이크로부터 인식하는 STT 기술을 사용하는 음성인식 모듈을 더 포함하고, 상기 안면인식 모듈은 AI 기반 안면윤곽선 인식 기술로써 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 측정 하고 눈과 귀의 거리, 코와 귀의 거리를 측정하는 posenet 알고리즘을 사용한다. 상기 학습 콘텐츠 서버는 비대면 온라인 학습에서, 시간과 장소에 상관없이, 온라인 학습 시에 강사는 학 습 콘텐츠를 제공하고 교육 콘텐츠 viewer의 온라인 학습 메모 공간(shared workspace)에 밑줄을 긋거나 텍스트, 그림, 사진, 음성 녹음을 통해 강사의 발언권 제어(floor control)에 따라 강사의 단말(감독관 단말)과 복수의 학습자 단말들로 리포트/학습 파일이 첨부된 파일 보내기/받기, 쪽지 보내기/받기를 제공하고, 비대면 강의 시에 강사의 단말(감독관 단말)은 학습 콘텐츠 서버를 통해 1:N 방식으로 복수의 학습자 단말 들로 교육 콘텐츠 viewer의 공유 작업 공간(shared workspace)에 글씨/그래픽 필기/메모 쓰기가 표시된다. 상기 학습 콘텐츠 서버는 스마트폰을 사용시에 인식 코드로써 QR 코드를 인식하는 기능을 제공한다. 상기 사용자 단말은 정면 카메라를 구비하는 태블릿 PC, 스마트폰, PC 중 어느 하나의 단말을 사용하며, 상기 학습 콘텐츠 서버로부터 다운로드된 상기 교육 콘텐츠 viewer가 설치되며, 상기 교육 콘텐츠 viewer는 VOD 미디 어 플레이어와 채팅 화면과 온라인 학습 메모 공간을 구비한다. 상기 사용자 단말은 비대면 강의 학습 콘텐츠를 재생하는 VOD 미디어 플레이어; 강사와 학습자와의 채팅 데이터를 송수신하는 채팅 모듈; 및 상기 사용자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하고 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징 점들을 인식하는 안면인식 모듈; 사용자 단말의 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따 라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 알람을 발생하거나 또는 경고 메시지를 출력하는 학습자의 알람 발생부를 포함한다. 상기 안면인식 모듈은 AI 기반 안면윤곽선 인식 기술로써 posenet 알고리즘을 사용한다. 상기 안면인식 모듈은 비대면 온라인 학습 시에 크기 보정/회전/각도 보정된 표준 크기의 학습자의 얼굴 사진에 대하여 정면 얼굴인식 알고리즘을 사용하여 얼굴 객체를 추출하고 얼굴 행동 패턴을 인식하여 학습자의 얼굴의 윤곽선과 눈2/코/귀2의 특징점들을 추출하며, 눈2/코/귀2의 얼굴의 특징점들의 각각 좌측/우측 귀와 좌측/우측 눈의 중심점(동공)과의 유클리디안 거리(d)와 유사도(similarity)를 계산하고, 얼굴사진 DB의 사용자의 표준 크기의 정면 얼굴 사진의 얼굴특정점들과 비교하여 시선 이탈 여부를 확인하며, 눈/코 3점이 양 끝 귀 2점에 가까 워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 시선 이탈과 관련된 얼굴 패턴을 검출하며, 얼굴 인식 시에 안면윤곽선 인식이 안되는 경우, 사용자 딘말의 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점 이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 사용자 단말의 카메라로 촬영되는 얼굴 행동 패턴을 인식하여 전면 얼굴이 좌우로 돌아간 각도에 따 라 우측 눈과 우측 귀의 거리와 좌측 눈과 좌측 귀의 거리가 달라지므로 해당 사용자 단말로 알람을 발생하거나 또는 경고 메시지를 출력한다. 상기 학습 콘텐츠 서버는 WWW 서버; 상기 사용자 단말로 온라인 학습 콘텐츠를 제공하도록 제어하는 제어부; 상기 제어부에 연결되며, 회원 정보를 등록받아 ID/Passwd를 저장하여 관리하는 회원 등록부; 상기 제어부에 연결되며, QR 코드/Passwd 또는 ID/Passwd 또는 개인 인증서를 사용하여 인증하는 사용자 인증부; 상기 제어부에 연결되며, 사용자 정보에 대응하는 QR 코드를 발급하고 관리하는 QR 코드 관리부; 상기 제어부에 연결되며, 상기 사용자 단말로 상기 온라인 학습(Learning) 콘텐츠를 제공하는 학습 콘텐츠 제공 부; 상기 제어부에 연결되며, 강사와 학습자의 채팅 데이터를 송수신하는 채팅 서버; 상기 제어부에 연결되며, 사용자 단말로부터 카메라의 응시자의 촬영 사진을 수신받아 표준 크기로 크기 보정/ 각도 보정/회전을 통해 표준 크기의 정면 얼굴 사진을 생성하고, 서버의 데이터베이스에 기 저장된 사용자 정보 와 정면 얼굴 사진을 비교하여 감독관 단말에서 감독관이 확인하여 온라인 학습 자격을 확인하는 감독관 확인부; 상기 제어부에 연결되며, 사용자 단말에서 안면인식 모듈을 사용하여 학습자의 얼굴의 윤곽선과 눈2/코/귀2의 얼굴 특징점을 인식하고 사용자 단말로부터 얼굴 인식 결과를 수신받는 얼굴 인식부; 및 응시자 단말들의 시험지와 작성 답안, 채점 결과를 저장하는 시험 정보DB; 응시자 정보와 표준 크기의 정면 얼 굴 사진을 저장하는 응시자DB와 얼굴 DB를 포함한다. 추가적으로, 학습 콘텐츠 서버는 상기 제어부에 연결되며, 강사와 학습자의 채팅 데이터를 송수신하 는 채팅 서버를 더 포함한다. 추가적으로, 학습 콘텐츠 서버는 상기 제어부에 연결되며, 강사와 학습자의 리포트 파일 첨부가 가능 한 쪽지 데이터를 송수신하는 쪽지 보내기/받기 제공부를 더 포함한다. 추가적으로, 학습 콘텐츠 서버는 상기 제어부에 연결되며, 학습 데이터 파일을 송수신하는 FTP 서버 를 더 포함한다. 비대면 온라인 학습에서, 강사는 강사의 단말(감독관 단말)은 학습 콘텐츠 서버를 통해 1:N 방식으로 복수 의 학습자 단말들로 질의 응답 채팅 데이터를 송수신한다. 비대면 온라인 학습에서, 시간과 장소에 상관없이, 학습 콘텐츠 서버를 통해 온라인 학습 시에 강사는 학 습 콘텐츠를 제공하고 교육 콘텐츠 viewer의 온라인 학습 메모 공간(shared workspace)에 밑줄을 긋거나 텍스트, 그림, 사진, 음성 녹음을 통해 강사의 발언권 제어(floor control)에 따라 강사의 단말(감독관 단말)과 복수의 학습자 단말들로 리포트/학습 파일이 첨부된 파일 보내기/받기, 쪽지 보내기/받기를 제공하며, 비대면 온라인 학습에서, 비대면 강의 시에 강사의 단말(감독관 단말)은 학습 콘텐츠 서버를 통해 1:N 방 식으로 동시에 복수의 학습자 단말들로 교육 콘텐츠 viewer의 공유 작업 공간(shared workspace)에 글씨/그래픽 필기/메모 쓰기가 표시된다. 추가적으로, 온라인 시험 또는 UBT 시험 시에, 응시자 정보들과 응시자의 현장의 정면 얼굴 사진, 감독관 정보 를 시험 관리부를 구비하는 학습 콘텐츠 서버의 데이터베이스에 저장하여 관리하며, 온라인 시험 또는 UBT 시험 시에 일정 시험시간 동안 각각의 응시자 단말에 시험지 작성 답안을 저장한 후, 시험 종료시 응시자 단말로부터시험관리부를 구비하는 학습 콘텐츠 서버로 전송받아 저장하며, 응시자들의 시험지 작성 답안의 채점 결과 를 응시자 단말로 제공하는 단계를 더 포함한다. 추가적으로, 온라인 및 UBT 시험은 2지/3지/4지/5지 선다 객관식 시험 및 응시자 단말의 필기체 인식부를 사용 하여 스타일러스 펜의 필기체를 인식하여 문자들로 변환하여 필기체 문자를 인식하는 주관식 시험을 포함한다. 또한, 상기 방법은 사용자 단말의 카메라 영상의 사용자의 얼굴 움직임을 [텍스트 A]와 같이 프레임 단위로 저 장하면서 정의된 일정 프레임 또는 시간 또는 횟수를 차감하다가 0이 되는 시점에 학습자/응시자 단말로 경고 메시지를 표출/노출하거나, 감독관 기기 또는 부정행위 검출 이미지를 서버로 보낸 후, 경고 트리거 횟수를 초 기화하여 다음 움직임부터 다시 차감을 시작하는 단계를 포함한다. [텍스트 A] - 응시자 단말의 태블릿 PC에 저장되는 얼굴의 행동 패턴 정보 (예시. 서울대학교 치과대학 학습자 의 얼굴 패턴 데이터): 일자, 시간, 움직인 각도/거리 및 위상(좌우) 등의 정보를 매 프레임 또는 시간당 저장 하고, 이를 바탕으로 사용자 단말로 알람 또는 경고 메시지를 출력하고, 감독관 확인 및 응시자 얼굴인식 부정 행위 검출 - 학습 콘텐츠 서버의 시스템에 해당 RAW Data를 전송하여 후처리 한다. 200519094106,0.02,R 200519094111,0.03,R 200519094120,0.42,R 200519094148,0.01,R 200519094150,0.21,R 200519094155,0.22,R 200519094158,0.09,R 200519094209,0.11,L 200519094214,0.09,R 200519094216,0.10,R 200519094219,0.09,R 200519094224,0.01,L 본 발명의 웹 브라우저 기반의 비대면 학습에서 인공지능을 사용한 주의집중 학습 시스템 및 방법은 비대면 온 라인 학습에서 사용자 단말의 교육 콘텐츠 viewer는 미디어 재생부와 안면윤곽선 인식부 모듈을 구비하고, 학습 콘텐츠 서버(ubcloud 서버)에 연동된 사용자 단말의 정면 카메라에 포커싱 된 비대면 강의 학습 콘텐츠에 시선 을 바로보고 주의 집중 교육되도록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도 안면윤곽선 인식을 통해 일정 각도로 시선이 빗나갈 경우 소리와 메시징 기술을 사용하여 해당 사용자 단말로 알람/경고 메시지를 발생하며, 비대면 온라인 학습에서 웹브라우저 기반의 ubcloud 인공지능 사용한 주의집중 학습/시험을 제공한다. 본 발명에 따른 실시예들은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현되고, 컴퓨터 판독 가능 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 기록 매체는 프로그램 명령, 데이터 파일, 데이 터 구조를 단독으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능 기록 매체는 서버 스토리지, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체 (optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬 (ROM), 램(RAM), 플래시 메모리 등과 같은 저장 매체에 프로그램 명령을 저장하고 수행하도록 구성된 하드웨어 장치가 포함될 수 있다. 프로그램 명령의 예는 컴파일러에 의해 만들어지는 것과, 기계어 코드 뿐만 아니라 인 터프리터를 사용하여 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 상기 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로써 작동하도록 구성될 수 있다. 이상에서 설명한 바와 같이, 본 발명의 방법은 프로그램으로 구현되어 컴퓨터의 소프트웨어를 이용하여 읽을 수 있는 형태로 기록매체(CD-ROM, RAM, ROM, 메모리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등)에 저장될 수 있다. 본 발명의 구체적인 실시예를 참조하여 설명하였지만, 본 발명은 상기와 같이 기술적 사상을 예시하기 위해 구 체적인 실시 예와 동일한 구성 및 작용에만 한정되지 않고, 본 발명의 기술적 사상과 범위를 벗어나지 않는 한 도 내에서 다양하게 변형하여 실시될 수 있으며, 본 발명의 범위는 후술하는 특허청구범위에 의해 결정되어야 한다."}
{"patent_id": "10-2024-0136134", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 기존 얼굴 인식 장치의 구성도이다. 도 1b는 종래의 인공지능 심층학습 기반의 영상물 인식 시스템의 구성도이다. 도 2a, 2b는 비대면 온라인 학습에서 웹 브라우저 기반 ubcloud 인공지능을 사용한 주의 집중 학습 시스템의 구 현 예이다. 도 3a는 온라인 학습 시에, 태블릿 PC, 스마트폰, PC 기반 학습 콘텐츠 서버를 구비하는 안면윤곽선 인식 인공 지능 플랫폼 개념을 보인 도면이다. 도 3b는 유비쿼터스 기반 NSDAI 플랫폼 상의 얼굴 인식 기능을 보인 도면이다. 도 3c, 3d는 비대면 온라인 학습과 시험 시에 태블릿 PC, 스마트폰, PC에서 사용하는 UBI cloud App, NS facere platform의 목표와 User Experience(1.사용자 등록->2.학습-> 3. QR 코드 생성 -> 4. UBT App/Web 로그 인(QR code/passwd, ID/passwd) -> 5. 감독자 확인과 시험-> 6.7 UBT App/Web 카메라의 얼굴의 안면윤곽선 인 식 8. 시험 종료)를 보인 그림이다. 도 4는 학습자/시험 응시자 등록부터 시험 응시부의 과정, 1)응시자 등록, 2)학습, 3)QR 코드 발급, 4) QR 코드 및 얼굴 인식, 5) 감독관 확인(응사자 얼굴/응시자 정보), 6) 시험응시 - 프로세스를 보인 그림이다. 도 5는 등록된 응시자 얼굴 기계학습 및 학습 결과를 바탕으로 응시자-얼굴 매칭 코드 발급부 - 온라인 시험 /UBT 시험시에 응시자 등록/학습/QR 코드 발급 화면이다. 도 6은 시험 응시자 얼굴의 AI 기반 안면윤곽선 인식을 통해 코의 정점을 기준으로 표준 크기의 정면 얼굴 사진 의 얼굴 특징점들의 거리와 유사도(similarity)를 측정한 UBT 시스템에서 응시자 확인부 화면이다. 도 7은 학습자 판정시 규칙 사용자 정의부, 프로그램 테스트 화면이다. 도 8은 비대면 온라인 학습시에 학습 콘텐츠 서버 접속/로그인/왼쪽- QR 코드 인식/QR 코드 인식 시에 인사말 들림(TTS)/오른쪽-얼굴 인식(스마트폰/태블릿PC 전면 카메라)/배경에서 얼굴 영역 인식 시작/인식율 표시 과정 을 포함하는 시연 화면 - 생성된 사용자 코드 활용 UBT 인증 프로세스 사용자 정의부 -이다. 도 9는 본 발명에 따른 웹 브라우저 기반의 비대면 학습에서 안면윤곽선 인식 인공지능을 사용한 태블릿 PC, 스 마트폰, PC 기반 웹 브라우저 기반의 비대면 학습에서 인공지능을 사용한 주의집중 학습 시스템 구성도이다. 도 10은 온라인 학습과 시험시에, AI 기반 안면윤곽선 인식 모듈의 기능을 설명한 도면이다. 도 11은 본 발명에 따른 웹 브라우저 기반의 비대면 학습에서 안면윤곽선 인식 인공지능을 사용한 태블릿 PC, 스마트폰, PC 기반 주의집중 학습 방법을 나타낸 순서도이다."}
