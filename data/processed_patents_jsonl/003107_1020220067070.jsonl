{"patent_id": "10-2022-0067070", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0082790", "출원번호": "10-2022-0067070", "발명의 명칭": "오디오 신호를 처리하는 방법과 장치, 모델의 훈련 방법과 장치, 전자 기기, 저장 매체, 및", "출원인": "아폴로 인텔리전트 커넥티비티", "발명자": "저우 이"}}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "오디오 신호를 처리하는 방법으로서,소정의 텍스트에 기반하여 획득된 처리될 오디오 신호를 인식하여, 상기 처리될 오디오 신호 중의 목표 음성 세그먼트 및 상기 목표 음성 세그먼트와 관련되는 제1 어구를 획득하는 동작;상기 소정의 텍스트 중 상기 목표 음성 세그먼트와 관련되는 제2 어구를 결정하는 동작;상기 제1 어구와 상기 제2 어구를 비교하여, 제1 비교 결과를 획득하는 동작; 및상기 제2 어구와 상기 제1 비교 결과에 기반하여, 상기 목표 음성 세그먼트를 라벨링하여, 제1 라벨링 데이터를갖는 음성 세그먼트를 획득하는 동작을 포함하되, 상기 제1 라벨링 데이터는 상기 제2 어구 및 상기 제1 비교 결과를 지시하는 제1 데이터를 포함하는 오디오 신호를 처리하는 방법."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "의 방법을 실행할 수 있게 하는, 전자 기기."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1 또는 청구항 2에 있어서,처리될 오디오 신호를 인식하는 동작은,파일 스트림의 형식으로 상기 처리될 오디오 신호를 읽는 과정에서 목표 음성 세그먼트의 시작점이 검출되는 것에 응답하여, 읽은 오디오 신호를 인식하는 동작;상기 목표 음성 세그먼트의 종료점이 검출되는 것에 응답하여, 상기 오디오 신호의 인식을 정지하여, 상기 목표음성 세그먼트와 관련되는 제1 어구를 획득하는 동작; 및상기 시작점과 상기 종료점 사이의 오디오 신호를 추출하여, 상기 목표 음성 세그먼트를 획득하는 동작을 포함하는 오디오 신호를 처리하는 방법."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 소정의 텍스트는 순서대로 배열되는 복수의 자연 어구를 포함하고, 상기 처리될 오디오 신호는 복수의 목표 음성 세그먼트를 포함하며, 공개특허 10-2022-0082790-3-상기 소정의 텍스트 중 상기 목표 음성 세그먼트와 관련되는 제2 어구를 결정하는 동작은,파일 스트림의 형식으로 상기 처리될 오디오 신호를 읽는 과정에서, 복수의 상기 목표 음성 세그먼트와 각각 관련되는 복수의 어구의 획득에 대한, 상기 제1 어구의 획득의 순서를 결정하는 동작; 및상기 복수의 자연 어구 중 상기 순서에 배열되는 자연 어구를 상기 제2 어구로 결정하는 동작을 포함하는 오디오 신호를 처리하는 방법."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 3에 있어서,상기 목표 음성 세그먼트를 라벨링하는 동작은,상기 시작점 및 상기 종료점에 기반하여, 상기 목표 음성 세그먼트를 라벨링하는 동작을 더 포함하며,상기 제1 라벨링 데이터는 상기 시작점 및 상기 종료점을 지시하는 제3 데이터를 더 포함하는 오디오 신호를 처리하는 방법."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1 또는 청구항 2에 있어서,상기 처리될 오디오 신호의 저장 용량을 결정하는 동작;상기 저장 용량에 기반하여, 상기 처리될 오디오 신호를 처리하는 예측 시간을 결정하는 동작; 및상기 처리될 오디오 신호를 처리하는 과정에서, 상기 처리될 오디오 신호를 처리하는 시작 시점, 현재 시점 및상기 예측 시간에 기반하여, 상기 처리될 오디오 신호를 처리하는 데 필요한 나머지 시간을 결정하는 동작을 더 포함하는 오디오 신호를 처리하는 방법."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "음성 인식 모델의 훈련 방법으로서,실제 어구 및 제1 샘플 음성 세그먼트의 제1 샘플 유형을 지시하는 제4 데이터를 포함하는 제2 라벨링 데이터를갖는 상기 제1 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 상기 제1 샘플 음성 세그먼트와 관련되는 제1 예측 어구를 획득하는 동작; 및상기 실제 어구, 상기 제1 예측 어구 및 상기 제1 샘플 유형에 기반하여, 상기 음성 인식 모델을 훈련시키는 동작을 포함하되, 상기 제1 샘플 음성 세그먼트는 청구항 1 또는 청구항 2의 방법을 적용하여 획득한 것이며, 상기제1 샘플 유형은 상기 제1 비교 결과와 관련되는, 음성 인식 모델의 훈련 방법."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "시맨틱 인식 모델의 훈련 방법으로서,실제 시맨틱 정보 및 제2 샘플 음성 세그먼트의 제2 샘플 유형을 지시하는 제5 데이터를 포함하는 제3 라벨링데이터를 갖는 상기 제2 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 상기 제2 샘플 음성 세그먼트와 관련되는 제2 예측 어구를 획득하는 동작;상기 제2 예측 어구를 시맨틱 인식 모델의 입력으로 하여, 상기 제2 예측 어구의 예측 시맨틱 정보를 획득하는동작; 및상기 예측 시맨틱 정보, 상기 실제 시맨틱 정보 및 상기 제2 샘플 유형에 기반하여, 상기 시맨틱 인식 모델을훈련시키는 동작을 포함하되, 상기 제2 샘플 음성 세그먼트는 청구항 2의 방법을 적용하여 획득한 것이며, 상기 제2 샘플 유형은 상기 제2 비교 결과와 관련되는, 시맨틱 인식 모델의 훈련 방법.공개특허 10-2022-0082790-4-청구항 9 오디오 신호를 처리하는 장치로서,소정의 텍스트에 기반하여 획득된 처리될 오디오 신호를 인식하여, 상기 처리될 오디오 신호 중의 목표 음성 세그먼트 및 상기 목표 음성 세그먼트와 관련되는 제1 어구를 획득하기 위한 오디오 인식 모듈;상기 소정의 텍스트 중 상기 목표 음성 세그먼트와 관련되는 제2 어구를 결정하기 위한 관련 어구 결정 모듈;상기 제1 어구와 상기 제2 어구를 비교하여, 제1 비교 결과를 획득하기 위한 어구 비교 모듈; 및상기 제2 어구와 상기 제1 비교 결과에 기반하여, 상기 목표 음성 세그먼트를 라벨링하여, 제1 라벨링 데이터를갖는 음성 세그먼트를 획득하기 위한 음성 라벨링 모듈을 포함하되, 상기 제1 라벨링 데이터는 상기 제2 어구 및 상기 제1 비교 결과를 지시하는 제1 데이터를 포함하는, 오디오 신호를 처리하는 장치."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 소정의 텍스트는 상기 제2 어구의 제2 시맨틱 정보를 더 포함하고,상기 장치는,상기 제1 어구의 시맨틱 정보를 추출하여, 제1 시맨틱 정보를 획득하기 위한 시맨틱 추출 모듈; 및상기 제1 시맨틱 정보와 상기 제2 시맨틱 정보를 비교하여, 제2 비교 결과를 획득하기 위한 시맨틱 비교 모듈을 더 포함하며,상기 음성 라벨링 모듈은 상기 제2 어구, 상기 제2 시맨틱 정보, 상기 제1 비교 결과 및 상기 제2 비교 결과에기반하여, 상기 목표 음성 세그먼트를 라벨링하기 위한 것이고,상기 제1 라벨링 데이터는 상기 제2 시맨틱 정보 및 상기 제2 비교 결과를 지시하는 제2 데이터를 더 포함하는오디오 신호를 처리하는 장치."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 9 또는 청구항 10에 있어서,상기 오디오 인식 모듈은,파일 스트림의 형식으로 상기 처리될 오디오 신호를 읽기 위한 오디오 읽기 서브 모듈;상기 오디오 읽기 서브 모듈이 상기 처리될 오디오 신호를 읽는 과정에서, 목표 음성 세그먼트의 시작점 및 종료점을 검출하기 위한 음성 검출 서브 모듈;목표 음성 세그먼트의 시작점이 상기 음성 검출 서브 모듈에 의해 검출되는 것에 응답하여, 읽은 오디오 신호를인식하고, 또한 상기 목표 음성 세그먼트의 종료점이 상기 음성 검출 서브 모듈에 의해 검출되는 것에응답하여, 상기 오디오 신호의 인식을 정지하여, 상기 목표 음성 세그먼트와 관련되는 제1 어구를 획득하기 위한 인식 서브 모듈; 및상기 시작점과 상기 종료점 사이의 오디오 신호를 추출하여, 상기 목표 음성 세그먼트를 획득하기 위한 음성 추출 서브 모듈을 포함하는 오디오 신호를 처리하는 장치."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 소정의 텍스트는 순서대로 배열되는 복수의 자연 어구를 포함하고, 상기 처리될 오디오 신호는 복수의 목표 음성 세그먼트를 포함하며,공개특허 10-2022-0082790-5-상기 관련 어구 결정 모듈은,상기 오디오 읽기 서브 모듈이 파일 스트림의 형식으로 상기 처리될 오디오 신호를 읽는 과정에서, 복수의 상기목표 음성 세그먼트와 각각 관련되는 복수의 어구를 획득하는 것에 대한, 상기 인식 서브 모듈이 상기 제1 어구를 획득하는 순서를 결정하기 위한 순서 결정 서브 모듈; 및상기 복수의 자연 어구 중 상기 순서에 배열되는 자연 어구를 상기 제2 어구로 결정하기 위한 어구 결정 서브모듈을 포함하는 오디오 신호를 처리하는 장치."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 11에 있어서,상기 음성 라벨링 모듈은,상기 시작점 및 상기 종료점에 기반하여, 상기 목표 음성 세그먼트를 라벨링하는 데에도 사용되며, 상기 제1 라벨링 데이터는 상기 시작점 및 상기 종료점을 지시하는 제3 데이터를 더 포함하는 오디오 신호를 처리하는 장치."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 9 또는 청구항 10에 있어서,상기 처리될 오디오 신호의 저장 용량을 결정하기 위한 저장 용량 결정 모듈;상기 저장 용량에 기반하여, 상기 처리될 오디오 신호를 처리하는 예측 시간을 결정하기 위한 예측 시간 결정모듈; 및상기 장치가 상기 처리될 오디오 신호를 처리하는 과정에서, 상기 처리될 오디오 신호를 처리하는 시작 시점,현재 시점 및 상기 예측 시간에 기반하여, 상기 처리될 오디오 신호를 처리하는 데 필요한 나머지 시간을 결정하기 위한 나머지 시간 결정 모듈을 더 포함하는 오디오 신호를 처리하는 장치."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "음성 인식 모델의 훈련 장치로서,실제 어구 및 제1 샘플 음성 세그먼트의 제1 샘플 유형을 지시하는 제4 데이터를 포함하는 제2 라벨링 데이터를갖는 상기 제1 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 상기 제1 샘플 음성 세그먼트와 관련되는 제1 예측 어구를 획득하기 위한 제1 어구 예측 모듈; 및상기 실제 어구, 상기 제1 예측 어구 및 상기 제1 샘플 유형에 기반하여, 상기 음성 인식 모델을 훈련시키기 위한 제1 모델 훈련 모듈을 포함하되, 상기 제1 샘플 음성 세그먼트는 청구항 9 또는 청구항 10의 장치를 적용하여 획득한 것이며, 상기제1 샘플 유형은 상기 제1 비교 결과와 관련되는, 음성 인식 모델의 훈련 장치."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "시맨틱 인식 모델의 훈련 장치로서,실제 시맨틱 정보 및 제2 샘플 음성 세그먼트의 제2 샘플 유형을 지시하는 제5 데이터를 포함하는 제3 라벨링데이터를 갖는 상기 제2 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 상기 제2 샘플 음성 세그먼트와 관련되는 제2 예측 어구를 획득하기 위한 제2 어구 예측 모듈;상기 제2 예측 어구를 시맨틱 인식 모델의 입력으로 하여, 상기 제2 예측 어구의 예측 시맨틱 정보를 획득하기위한 시맨틱 예측 모듈; 및상기 예측 시맨틱 정보, 상기 실제 시맨틱 정보 및 상기 제2 샘플 유형에 기반하여, 상기 시맨틱 인식 모델을공개특허 10-2022-0082790-6-훈련시키기 위한 제2 모델 훈련 모듈을 포함하되, 상기 제2 샘플 음성 세그먼트는 청구항 10의 장치를 적용하여 획득한 것이며, 상기 제2 샘플 유형은 상기 제2 비교 결과와 관련되는, 시맨틱 인식 모델의 훈련 장치."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "전자 기기로서,적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하되, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어가 저장되어 있고, 상기명령어는 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서로 하여금 청구항 1 또는"}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "컴퓨터로 하여금 청구항 1 또는 청구항 2의 방법을 실행하게 하기 위한 컴퓨터 명령어가 저장된 비휘발성 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2022-0067070", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "프로세서에 의해 실행될 경우, 청구항 1 또는 청구항 2의 방법을 실현하는, 저장 매체에 저장되어 있는 컴퓨터프로그램 제품."}
{"patent_id": "10-2022-0067070", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 오디오 신호를 처리하는 방법과 자치, 음성 인식 모델의 훈련 방법과 장치, 시맨틱 인식 모델의 훈련 방법과 장치, 전자 기기 및 저장 매체를 제공하며, 인공 지능 분야에 관한 것이며, 구체적으로는 음성 인식, 자 연 언어 처리 및 딥 러닝 분야에 관한 것이다. 오디오 신호를 처리하는 방법은, 소정의 텍스트에 기반하여 획득 된 처리될 오디오 신호를 인식하여, 처리될 오디오 신호 중의 목표 음성 세그먼트 및 목표 음성 세그먼트와 관련 되는 제1 어구를 획득하는 동작; 소정의 텍스트 중 목표 음성 세그먼트와 관련되는 제2 어구를 결정하는 동작; 제1 어구와 제2 어구를 비교하여, 제1 비교 결과를 얻는 동작; 제2 어구와 제1 비교 결과에 기반하여, 목표 음성 세그먼트를 라벨링하여, 제1 라벨링 데이터를 갖는 음성 세그먼트를 획득하는 동작을 포함하며, 제1 라벨링 데이 터는 제2 어구 및 제1 비교 결과를 지시하는 제1 데이터를 포함한다."}
{"patent_id": "10-2022-0067070", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공 지능 분야에 관한 것으로, 구체적으로는 음성 인식, 자연 언어 처리 및 딥 러닝 분야에 관한 것 이며, 더 구체적으로는 오디오 신호를 처리하는 방법과 장치, 음성 인식 모델의 훈련 방법과 장치, 시맨틱 인식 모델의 훈련 방법과 장치, 전자 기기 및 저장 매체에 관한 것이다."}
{"patent_id": "10-2022-0067070", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 기술의 발전에 따라, 사용자에게 지능화 서비스를 제공하는 지능형 음성 기술이 빠르게 발전하고 있다. 우 수한 지능형 음성 모델을 얻기 위해, 정확한 어구가 라벨링된 대량의 음성 세그먼트에 의존해야 한다. 하지만, 하나의 오디오에는 일반적으로 복수의 음성 세그먼트가 포함되며, 이 복수의 음성 세그먼트를 얻기 위해, 이 오 디오를 분할하고, 분할된 음성 세그먼트에 정확한 어구를 라벨링해야 한다. 관련 기술에서는 상기 오디오를 인 공으로 분할 및 라벨링하고 있지만, 오디오는 일반적으로 연속으로 녹음되는 길이가 비교적 긴 오디오이므로, 상기 인공 방식은 효율이 낮고 인건비가 높은 문제가 존재한다. 본 개시는 라벨링 효율 및 라벨링 정보의 다양성을 향상시키는 오디오 신호를 처리하는 방법을 제공하며, 얻은 라벨링 데이터를 갖는 음성 세그먼트에 기반하여, 음성 인식 모델의 훈련 방법 및 시맨틱 인식 모델의 훈련 방 법을 제공한다. 본 개시의 일 측면에 따르면, 소정의 텍스트에 기반하여 획득된 처리될 오디오 신호를 인식하여, 처리될 오디오 신호 중의 목표 음성 세그먼트 및 목표 음성 세그먼트와 관련되는 제1 어구를 획득하는 동작; 소정의 텍스트 중 목표 음성 세그먼트와 관련되는 제2 어구를 결정하는 동작; 제1 어구와 제2 어구를 비교하여, 제1 비교 결과를 획득하는 동작; 제2 어구와 제1 비교 결과에 기반하여, 목표 음성 세그먼트를 라벨링하여, 제1 라벨링 데이터를 갖는 음성 세그먼트를 획득하는 동작을 포함하며, 제1 라벨링 데이터는 제2 어구 및 제1 비교 결과를 지시하는 제1 데이터를 포함하는 오디오 신호를 처리하는 방법을 제공한다. 본 개시의 다른 일 측면에 따르면, 실제 어구 및 제1 샘플 음성 세그먼트의 제1 샘플 유형을 지시하는 제4 데이 터를 포함하는 제2 라벨링 데이터를 갖는 제1 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 제1 샘플음성 세그먼트와 관련되는 제1 예측 어구를 획득하는 동작; 및 실제 어구, 제1 예측 어구 및 제1 샘플 유형에 기반하여, 음성 인식 모델을 훈련시키는 동작을 포함하며, 제1 샘플 음성 세그먼트는 상기 오디오 신호를 처리 하는 방법을 적용하여 획득한 것이며, 제1 샘플 유형은 제1 비교 결과와 관련되는 음성 인식 모델의 훈련 방법 을 제공한다. 본 개시의 다른 일 측면에 따르면, 실제 시맨틱 정보 및 제2 샘플 음성 세그먼트의 제2 샘플 유형을 지시하는 제5 데이터를 포함하는 제3 라벨링 데이터를 갖는 제2 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 제2 샘플 음성 세그먼트와 관련되는 제2 예측 어구를 획득하는 동작; 제2 예측 어구를 시맨틱 인식 모델의 입력 으로 하여, 제2 예측 어구의 예측 시맨틱 정보를 획득하는 동작; 및 예측 시맨틱 정보, 실제 시맨틱 정보 및 제 2 샘플 유형에 기반하여, 시맨틱 인식 모델을 훈련시키는 동작을 포함하며, 제2 샘플 음성 세그먼트는 상기 오 디오 신호를 처리하는 방법을 적용하여 획득한 것이며, 제2 샘플 유형은 제2 비교 결과와 관련되는 시맨틱 인식 모델의 훈련 방법을 제공한다. 본 개시의 다른 일 측면에 따르면, 소정의 텍스트에 기반하여 획득된 처리될 오디오 신호를 인식하여, 처리될 오디오 신호 중의 목표 음성 세그먼트 및 목표 음성 세그먼트와 관련되는 제1 어구를 획득하기 위한 오디오 인 식 모듈; 소정의 텍스트 중 목표 음성 세그먼트와 관련되는 제2 어구를 결정하기 위한 관련 어구 결정 모듈; 제 1 어구와 제2 어구를 비교하여, 제1 비교 결과를 획득하기 위한 어구 비교 모듈; 및 제2 어구와 제1 비교 결과 에 기반하여, 목표 음성 세그먼트를 라벨링하여, 제1 라벨링 데이터를 갖는 음성 세그먼트를 획득하기 위한 음 성 라벨링 모듈을 포함하며, 제1 라벨링 데이터는 제2 어구 및 제1 비교 결과를 지시하는 제1 데이터를 포함하 는 오디오 신호를 처리하는 장치를 제공한다. 본 개시의 다른 일 측면에 따르면, 실제 어구 및 제1 샘플 음성 세그먼트의 제1 샘플 유형을 지시하는 제4 데이 터를 포함하는 제2 라벨링 데이터를 갖는 제1 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 제1 샘플 음성 세그먼트와 관련되는 제1 예측 어구를 획득하기 위한 제1 어구 예측 모듈; 및 실제 어구, 제1 예측 어구 및 제1 샘플 유형에 기반하여, 음성 인식 모델을 훈련시키기 위한 제1 모델 훈련 모듈을 포함하며, 제1 샘플 음 성 세그먼트는 상기 오디오 신호를 처리하는 장치를 적용하여 획득한 것이며, 제1 샘플 유형은 제1 비교 결과와 관련되는 음성 인식 모델의 훈련 장치를 제공한다. 본 개시의 다른 일 측면에 따르면, 실제 시맨틱 정보 및 제2 샘플 음성 세그먼트의 제2 샘플 유형을 지시하는 제5 데이터를 포함하는 제3 라벨링 데이터를 갖는 제2 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 제2 샘플 음성 세그먼트와 관련되는 제2 예측 어구를 획득하기 위한 제2 어구 예측 모듈; 제2 예측 어구를 시맨 틱 인식 모델의 입력으로 하여, 제2 예측 어구의 예측 시맨틱 정보를 획득하기 위한 시맨틱 예측 모듈; 및 예측 시맨틱 정보, 실제 시맨틱 정보 및 제2 샘플 유형에 기반하여, 시맨틱 인식 모델을 훈련시키기 위한 제2 모델 훈련 모듈을 포함하며, 제2 샘플 음성 세그먼트는 상기 오디오 신호를 처리하는 장치를 적용하여 획득한 것이며, 제2 샘플 유형은 제2 비교 결과와 관련되는 시맨틱 인식 모델의 훈련 장치를 제공한다. 본 개시의 다른 일 측면에 따르면, 적어도 하나의 프로세서; 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하며, 메모리에는 적어도 하나의 프로세서에 의해 실행 가능한 명령어가 저장되어 있고, 명령어는 적어도 하나의 프로세서에 의해 실행되어, 적어도 하나의 프로세서로 하여금 본 개시에 의해 제공되는 오디오 신호를 처리하는 방법, 음성 인식 모델의 훈련 방법 및 시맨틱 인식 모델의 훈련 방법 중 적어도 한가지 방법을 실행할 수 있게 하는 전자 기기를 제공한다. 본 개시의 다른 일 측면에 따르면, 컴퓨터로 하여금 본 개시에 의해 제공되는 오디오 신호를 처리하는 방법, 음 성 인식 모델의 훈련 방법 및 시맨틱 인식 모델의 훈련 방법 중 적어도 한가지 방법을 실행하게 하기 위한 컴퓨 터 명령어가 저장된 비휘발성 컴퓨터 판독가능 저장 매체를 제공한다. 본 개시의 다른 일 측면에 따르면, 컴퓨터 프로그램을 포함하며, 상기 컴퓨터 프로그램은 프로세서에 의해 실행 될 경우, 본 개시에 의해 제공되는 오디오 신호를 처리하는 방법, 음성 인식 모델의 훈련 방법 및 시맨틱 인식 모델의 훈련 방법 중 적어도 한가지 방법을 실현하는 컴퓨터 프로그램 제품을 제공한다. 이해해야 할 것은, 본 부분에서 설명되는 내용은 본 개시의 실시예의 핵심적인 특징 또는 중요한 특징을 표시하 기 위한 것이 아니며, 본 개시의 범위를 한정하기 위한 것도 아니다. 본 개시의 다른 특징은 아래의 명세서를 통해 쉽게 이해하게 될 것이다."}
{"patent_id": "10-2022-0067070", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래, 도면을 결합하여 본 개시의 예시적인 실시예에 대해 설명한다. 이해를 돕기 위해, 상기 설명에는 본 개시 실시예의 다양한 세부사항을 포함하며, 이를 단지 예시적인 것으로 간주해야 한다. 따라서, 당업자는 본 개시의 범위 및 사상을 벗어나는 것이 없이, 여기에서 설명되는 실시예에 대해 다양한 변경 및 수정을 진행할 수 있음 을 인식해야 한다. 마찬가지로, 명확하고 간명한 설명을 위해, 아래의 설명에서 공지의 기능 및 구조에 대한 설 명은 생략한다. 본 개시는 오디오 신호를 처리하는 방법을 제공한다. 상기 방법은 오디오 인식 단계, 어구 결정 단계, 어구 비 교 단계 및 음성 라벨링 단계를 포함한다. 오디오 인식 단계에서, 처리될 오디오 신호를 인식하여, 처리될 오디 오 신호 중의 목표 음성 세그먼트 및 목표 음성 세그먼트와 관련되는 제1 어구를 획득한다. 여기서, 처리될 오 디오 신호는 소정의 텍스트에 기반하여 획득한 것이다. 어구 결정 단계에서, 소정의 텍스트 중 목표 음성 세그 먼트와 관련되는 제2 어구를 결정한다. 어구 비교 단계에서, 제1 어구와 제2 어구를 비교하여 제1 비교 결과를 획득한다. 음성 레벨링 단계에서, 제2 어구 및 제1 비교 결과에 기반하여, 목표 음성 세그먼트를 라벨링하여, 제1 라벨링 데이터를 갖는 음성 세그먼트를 획득한다. 여기서, 제1 라벨링 데이터는 제2 어구 및 제1 비교 결과 를 지시하는 제1 데이터를 포함한다. 아래 도 1을 결합하여 본 개시에 의해 제공되는 방법 및 장치의 적용 장면을 설명한다. 도 1은 본 개시의 실시예에 따른 오디오 신호를 처리하는 방법, 모델 훈련 방법, 장치, 기기 및 매체의 적용 장 면 예시도이다. 도 1에 도시된 바와 같이, 상기 적용 장면은 단말 기기를 포함하고, 상기 단말 기기는 처리 기능을 갖는 임의의 전자 기기일 수 있으며, 스마트폰, 태블릿 PC, 휴대용 랩톱 컴퓨터, 데스크톱 컴퓨터 및 서버 등을 포함하되 이에 한정되지는 않는다. 상기 단말 기기는, 예를 들면, 입력되는 오디오 신호를 처리할 수 있으며, 구체적으로 오디오 신호 중의 음성 세그먼트를 인식할 수 있고, 인식 결과에 따라 오디오 신호 중 음성 세그먼트와 관련되는 어구 를 예측할 수 있으며, 예측된 어구에 따라 음성 세그먼트를 녹음하는 데 의거하는 자연 어구를 결정할 수 있다. 상기 단말 기기는 어구 세그먼트에 상기 자연 어구를 라벨링하여, 라벨링 음성 세그먼트를 얻을 수도 있다. 이 라벨링 음성 세그먼트는 훈련 샘플로서 지능형 음성 시스템을 훈련시키는 데 사용될 수 있다. 본 개시의 실시예에 따르면, 도 1에 도시된 바와 같이, 상기 적용 장면은 서버를 더 포함할 수 있다. 단말 기기는 네트워크를 통해 서버와 통신 연결될 수 있고, 네트워크는 유선 또는 무선 통신 링크를 포함할 수 있다. 예시적으로, 서버는 지능형 음성 시스템을 훈련시키는 데 사용될 수 있다. 훈련 전에, 단말 기기로부 터 라벨링 음성 세그먼트를 취득하여 훈련 샘플로 할 수 있다. 여기서, 지능형 음성 시스템은, 예를 들면, 음성 인식 기능 및 시맨틱 인식 기능을 포함함으로써, 사용자 음성에 대한 시맨틱 이해를 실현할 수 있다. 예시적으로, 서버가 훈련하여 얻은 지능형 음성 시스템은, 예를 들면, 스마트 폰, 스마트 스피 커 및 스마트 차량 등 스마트 기기에 장착되어, 사용자와의 음성 인터랙션을 실현할 수 있으며, 사용 자의 체험을 향상시킬 수 있다. 예시적으로, 서버는, 예를 들면, 다양한 서비스를 제공하는 서버일 수 있고, 예를 들면, 단말 기기에서 실 행되는 애플리케이션에 지원을 제공하는 백그라운드 관리 서버일 수 있다. 예를 들면, 이 서버는 클라우드 서버 일 수 있으며, 분산 시스템의 서버, 또는 블록체인을 결합한 서버일 수도 있다. 일 실시예에서, 예를 들면, 단말 기기와 서버는 동일한 기기일 수 있으며, 이 기기는 복수의 처리 모 듈을 구비하여, 어느 한 처리 모듈에 의해 오디오 신호를 인식하여 라벨링 음성 세그먼트를 얻고, 상기 어 느 한 처리 모듈을 제외한 다른 처리 모듈은 지능형 음성 시스템을 훈련시킨다. 이해해야 할 것은, 도 1에서의 단말 기기, 서버 및 스마트 기기의 개수와 유형은 단지 예시적인 것일 뿐이다. 실현 수요에 따라, 임의의 개수와 유형의 단말 기기, 서버 및 스마트 기기를 가질 수 있다. 아래 도 2 내지 도 6을 결합하여 본 개시 실시예의 분류 모델의 훈련 방법을 상세하게 설명한다. 도 2는 본 개시의 실시예에 따른 오디오 신호를 처리하는 방법의 흐름 예시도이다. 도 2에 도시된 바와 같이, 본 실시예의 오디오 신호를 처리하는 방법은 동작 S210 내지 동작 S240을 포함 할 수 있다. 동작 S210에서, 처리될 오디오 신호를 인식하여, 처리될 오디오 신호 중의 목표 음성 세그먼트 및 목표 음성 세 그먼트와 관련되는 제1 어구를 획득하며, 여기서, 처리될 오디오 신호는 소정의 텍스트에 기반하여 획득된 것이다. 본 개시의 실시예에 따르면, 처리될 오디오 신호는, 예를 들면, 소정의 텍스트를 낭독하는 음성에 대한 녹음을 통해 얻을 수 있다. 이 소정의 텍스트에는 적어도 하나의 자연 어구가 포함되며, 처리될 오디오 신호 중의 목표 음성 세그먼트는 적어도 하나의 자연 어구 중 임의의 한 자연 어구를 낭독하여 얻은 오디오일 수 있다. 본 실시 예는 기존의 오디오 분할 툴을 적용하여 처리될 오디오 신호를 분할하여, 적어도 하나의 목표 음성 세그먼트를 획득할 수 있다. 그 다음, 기존의 음성 인식 기술을 적용하여 분할하여 얻은 목표 음성 세그먼트를 인식함으로 써, 목표 음성 세그먼트와 각각 대응되는 어구를 얻어, 목표 음성 세그먼트와 관련되는 제1 어구로 한다. 여기 서, 기존의 음성 인식 기술은, 예를 들면, 합성곱 신경망과 연결주의 시간 분류(Connectionist Temporal Classification, CTC) 방법으로 구성된 기술, 음성 텍스트 변환(Speech-to-Text, STT) 기술 등을 포함할 수 있 다. 일 실시예에서, 음성 끝점 검출 방법에 기반하여, 처리될 오디오 신호에 대해 어구를 끊어 분할할 수도 있다. 여기서, 음성 끝점 검출(Voice Activity Detection, VAD)은 음성 액티비티 검출, 음성 경계 검출이라고도 칭하 며, 소음 환경에서 음성의 존재 여부를 검출할 수 있다. 구체적으로 오디오 신호로부터 음성 신호와 비음성 신 호를 분리하여, 음성 신호의 시작점과 종료점에 대해 위치 결정할 수 있으며, 시작점과 종료점을 끝점이라 칭할 수 있다. 본 개시의 실시예에 따르면, 처리될 오디오 신호는 사전에 녹음되어 소정의 저장 공간에 저장되는 오디오 신호 일 수 있다. 일 실시예에서, 상기 처리될 오디오 신호는 처리 시 쉽게 호출될 수 있도록, 음성 처리 기능을 갖 는 애플리케이션 패키지의 어느 한 디렉토리에 저장될 수도 있다. 또는, 상기 처리될 오디오 신호는 실시간으로 녹음하여 얻을 수 있으며, 본 개시는 이에 대해 한정하지 않는다. 이해해야 할 것은, 상기 목표 음성 세그먼트 및 제1 어구를 획득하는 방법은 단지 본 개시의 이해를 돕기 위한 예시일 뿐이며, 본 개시는 이에 대해 한정하지 않는다. 동작 S220에서, 소정의 텍스트 중 목표 음성 세그먼트와 관련되는 제2 어구를 결정한다. 본 개시의 실시예에 따르면, 소정의 텍스트 중 제1 어구와의 유사도가 가장 높은 어구를 목표 음성 세그먼트와 관련되는 제2 어구로 할 수 있다. 여기서, 유사도는, 예를 들면, 단어 빈도 - 역 문서 빈도(Term Frequency- inverse Document Frequency, TF-IDF) 알고리즘, 편집 거리(Levenshtein) 알고리즘 등을 적용하여 결정될 수있다. 이해해야 할 것은, 상기 제2 어구를 결정하는 방법은 단지 본 개시의 이해를 돕기 위한 예시일 뿐이며, 본 개시 는 이에 대해 한정하지 않는다. 동작 S230에서, 제1 어구와 제2 어구를 비교하여 제1 비교 결과를 얻는다. 본 개시의 실시예에 따르면, 예를 들면, 동작 S220에서 얻은 제1 어구와 제2 어구 사이의 유사도를 제1 비교 결 과로 할 수 있다. 또는, 유사도와 제1 임계값 사이의 크기 관계에 따라 제1 비교 결과를 결정할 수 있다. 예를 들면, 유사도가 제1 임계값보다 낮을 경우, 제1 비교 결과를 제1 어구가 정확하지 않는 것으로 결정할 수 있고, 유사도가 제1 임계값보다 낮지 않을 경우, 제1 비교 결과를 제1 어구가 정확한 것으로 결정할 수 있다. 여기서, 제1 임계값은 실제 수요에 따라 설정될 수 있으며, 본 개시는 이에 대해 한정하지 않는다. 일 실시예에서, 제1 어구와 제2 어구를 문자 부호별로 비교할 수도 있으며, 제1 어구와 제2 어구가 완전히 동일 할 경우, 제1 비교 결과를 제1 어구가 정확한 것으로 결정하고, 그렇지 않을 경우, 제1 어구가 정확하지 않은 것으로 결정한다. 이해해야 할 것은, 상기 제1 비교 결과를 획득하는 방법은 단지 본 개시의 이해를 돕기 위한 예시일 뿐이며, 본 개시는 이에 대해 한정하지 않는다. 동작 S240에서, 제2 어구와 제1 비교 결과에 기반하여, 목표 음성 세그먼트를 라벨링하여, 제1 라벨링 데이터를 갖는 음성 세그먼트를 획득한다. 본 개시의 실시예에 따르면, 제2 어구와 제1 비교 결과를 지시하는 제1 데이터를 음성 세그먼트의 라벨로 하여, 제1 라벨링 데이터를 갖는 음성 세그먼트를 얻을 수 있다. 여기서, 제1 비교 결과가 제1 어구는 정확하지 않은 것일 경우, 상기 제1 비교 결과를 지시하는 제1 데이터는 0일 수 있고, 그렇지 않을 경우 1일 수 있다. 상기 제 1 라벨링 데이터를 갖는 음성 세그먼트를 훈련 샘플로 할 경우, 상기 제1 데이터는 제1 비교 결과와 관련되는 샘플 유형을 표현하는 데 사용될 수 있으며, 이 샘플 유형은 음성 인식 모델에 대한 제1 샘플 유형이다. 예를 들면, 제1 비교 결과는 제1 어구가 정확하지 않은 것일 경우, 제1 데이터는 샘플 유형이 부정적 샘플임을 표현 할 수 있고, 그렇지 않을 경우, 제1 데이터는 샘플 유형이 긍정적 샘플임을 표현할 수 있다. 이해해야 할 것은, 상기 제1 데이터는 단지 본 개시의 이해를 돕기 위한 예시일 뿐이며, 본 개시는 이에 대해 한정하지 않는다. 본 실시예의 오디오 신호를 처리하는 방법은 처리될 오디오 신호 중 음성 세그먼트의 자동 분할 및 자동 라벨링을 실현할 수 있으며, 관련 기술에서 인공에 의존하는 방법과 비교하면, 오디오 신호의 처리 효율을 향상 시킬 수 있으며, 일정한 정도에서 인공 피로로 인한 정확하지 않은 분할 또는 라벨링을 피할 수 있다. 또한, 본 실시예의 오디오 신호를 처리하는 방법은, 제1 어구와 제2 어구를 비교하고, 비교 결과에 기반하여 오디오 세그먼트를 라벨링함으로써, 긍정적 샘플로서의 음성 세그먼트와 부정적 샘플로서의 음성 세그먼트를 효과적으 로 구분할 수 있다. 따라서, 상기 라벨링 데이터를 갖는 오디오 세그먼트를 사용하여 지능형 음성 시스템에서의 음성 인식 모델을 훈련시킬 경우, 부정적 샘플을 별도로 수집하는 과정을 생략할 수 있어, 지능형 음성 시스템 에서의 음성 인식 모델을 훈련시킬 시 샘플 준비 단계의 코스트를 감소할 수 있다. 또는, 지능형 음성 시스템에 서의 음성 인식 모델을 훈련시킬 경우, 라벨링 데이터를 갖는 목표 음성 세그먼트로부터 긍정적 샘플로 할 수 있는 음성 세그먼트만 선택하여, 모델을 훈련시킬 수 있다. 도 3은 본 개시의 실시예에 따른 처리될 오디오 신호를 인식하는 원리 예시도이다. 일 실시예에서, 처리될 오디오 신호를 인식할 경우, 파일 스트림(stream)의 형식을 적용하여 처리될 오디오 신 호를 읽을 수 있으며, 읽은 오디오 신호를 실시간으로 검출 및 인식할 수 있다. 상기 방식을 통해, 본 개시의 오디오 신호를 처리하는 방법이 실시간으로 오디오 신호를 수집하는 장면에 적용되도록 할 수 있고, 이와 동시 에 시스템 장애 등으로 인해 모델 훈련에 제공되는 훈련 샘플량이 적은 상황을 최대한 완화시킬 수 있다. 예시적으로, 도 3에 도시된 바와 같이, 본 실시예는 처리될 오디오 신호를 인식할 경우, 파일 스트림 의 형식으로 처리될 오디오 신호를 읽어, 처리될 오디오 신호 중 목표 음성 세그먼트의 시작점과 종 료점을 검출할 수 있다. 예를 들면, 읽은 처리될 오디오 신호를 음성 끝점 검출 모델에 입력하 여, 목표 음성 세그먼트의 시작점과 종료점을 검출할 수 있다. 목표 음성 세그먼트의 시작점이 검출되었을 경우, 목표 음성 세그먼트의 종료점이 검출될 때까지 후속적으로 읽 어지는 오디오 신호를 인식할 수 있다. 상기 후속적으로 읽어지는 오디오 신호를 인식하여, 목표 음성 세그먼트 와 관련되는 제1 어구를 획득할 수 있다. 목표 음성 세그먼트의 시작점과 종료점이 검출된 다음, 이 시작점과 종료점에 기반하여 처리될 오디 오 신호로부터 목표 음성 세그먼트를 추출할 수 있다. 예를 들면, 시작점과 종료점 사이에서 읽 은 오디오 신호를 목표 음성 세그먼트로 할 수 있다. 예를 들면, 시작점이 검출된 다음, 새로운 파일을 만 들어, 시작점 이후로 읽은 오디오 신호를 상기 새로운 파일에 기입하며, 종료점이 검출된 다음, 이 새로운 파일 에 대한 기입 동작을 정지할 수 있다. 그러면, 새로운 파일에 기입된 데이터가 바로 목표 오디오 세그먼트이다. 목표 오디오 세그먼트를 라벨링할 경우, 예를 들면, 제1 라벨링 데이터를 상기 새로운 파일의 파일명으로 하여, 목표 오디오 세그먼트에 대한 라벨링을 완성할 수 있다. 일 실시예에서, 목표 음성 세그먼트를 얻은 다음, 목표 음성 세그먼트를 음성 인식 모델에 입력 하고, 상기 음성 인식 모델의 처리를 거친 후, 제1 어구를 얻을 수도 있다. 여기서, 상기 음성 인식 모델은 사전에 훈련된 모델일 수 있으며, 예를 들면, 상기 합성곱 신경망 및 CTC 방법에 기반하여 구축된 음향 모델 또는 어텐션 메커니즘에 기반하는 순환 신경망 모델 등일 수 있다. 여기서, 순환 신경망 모델은, 예 를 들면, 시퀀스투시퀀스(Sequence to Sequence, seq2seq) 모델 등일 수 있으며, 본 개시는 이에 대해 한정하지 않는다. 이해해야 할 것은, 상기 음성 인식 모델은 지능형 음성 시스템과 별도인 다른 모델이지만, 지능형 음성 시스템에서의 음성 인식 모델과 유사한 아키텍처를 가질 수 있다. 일 실시예에서, 목표 음성 세그먼트를 라벨링할 시, 시작점 및 종료점에 기반하여, 목표 음성 세그먼트 를 라벨링할 수도 있다. 구체적으로, 목표 음성 세그먼트에 시작점 및 종료점을 지시하는 제3 데이터 를 라벨링할 수 있다. 예를 들면, 제3 데이터는 시작점 및 종료점 각각과 처리될 오디오 신호의 시작점 사이의 시간 간격을 포함할 수 있다. 상기 제3 데이터의 라벨링을 통해, 후속적인 사용에서, 상기 제3 데이터에 기반하 여, 빠르고 편리하게 목표 음성 세그먼트를 위치 결정할 수 있다. 본 개시의 실시예에 따르면, 소정의 텍스트에 복수의 자연 어구가 포함될 경우, 처리될 오디오 신호는 상응하게 복수의 목표 음성 세그먼트를 포함할 수 있다. 파일 스트림의 형식으로 처리될 오디오 신호를 읽으면, 상기 처 리될 오디오 신호를 인식하는 방법을 통해 복수의 어구를 순서대로 얻을 수 있다. 여기서, 복수의 자연 어구가 순서대로 배열될 경우, 일반적으로 처리될 오디오는 상기 순서대로 배열되는 복수의 자연 어구를 순서대로 낭독 하여 얻은 오디오이므로, 상기 순서대로 얻은 복수의 어구는 복수의 자연 어구와 일일이 대응되어야 한다. 본 실시예는 소정의 텍스트 중, 목표 음성 세그먼트와 관련되는 제2 어구를 결정할 시, 우선 파일 스트림의 형식으 로 처리될 오디오 신호를 읽는 과정에서, 획득된 복수의 목표 음성 세그먼트 각각과 관련되는 복수의 어구에 대 한, 획득된 제1 어구의 획득 순서를 결정하여, 복수의 자연 어구 중 상기 획득 순서에 배열되는 자연 어구를 제 1 어구에 대응되는 제2 어구, 즉 목표 음성 세그먼트와 관련되는 제2 어구로 결정할 수 있다. 도 4는 본 개시의 실시예에 따른 오디오 신호를 처리하는 원리 예시도이다. 본 개시의 실시예에 따르면, 소정의 텍스트에는 자연 어구가 포함되는 외에, 예를 들면, 자연 어구의 시맨틱 정 보가 기재될 수도 있다. 본 실시예는 제2 어구의 시맨틱 정보를 적용하여 목표 오디오 세그먼트를 라벨링할 수 있어, 라벨링 데이터를 갖는 목표 오디오 세그먼트가 지능형 음성 시스템 중 시맨틱 인식 모델의 훈련 샘플로 될 수도 있다. 이로써, 지능형 음성 시스템을 훈련시켜야 할 경우, 음성 인식 모델 및 시맨틱 인식 모델의 훈련 샘플을 각각 준비할 필요가 없다. 예시적으로, 도 4에 도시된 바와 같이, 본 실시예는 오디오 신호를 처리할 시, 파일 스트림의 형식으로 처 리될 오디오 신호를 읽을 수 있으며, 읽은 오디오 신호를 음성 끝점 검출 모델에 입력하여, 목표 음 성 세그먼트의 시작점 및 종료점을 검출함으로써, 시작점과 종료점 간에서 읽은 오디오 신호를 목표 음성 세그 먼터로 할 수 있다. 음성 끝점 검출 모델에 의해 목표 음성 세그먼트의 시작점이 검출되었을 경우, 목표 음성 세그먼트의 종료점이 검출될 때까지 후속적으로 읽어진 오디오 신호를 음성 인식 모델에 입력하 여 인식한다. 음성 인식 모델이 입력된 오디오 신호를 기반으로 인식하여 얻은 정보를 제1 어구로 한다. 제1 어구를 얻은 다음, 소정의 텍스트에서 대응되는 어구를 찾아, 목표 음성 세그먼트와 관련되는 제 2 어구로 할 수 있다. 제2 어구를 얻은 다음, 소정의 텍스트로부터 상기 제2 어구의 제2 시맨틱 정보를 취득할 수 있다. 이와 동시에 제1 어구와 제2 어구를 비교하여, 제1 비교 결과를 얻을 수도 있다. 목표 오디 오 세그먼트를 라벨링할 시, 상기 취득한 제2 시맨틱 정보에 기반하여 목표 오디오 세그먼트를 라벨링할 수도 있다. 따라서, 목표 오디오 세그먼트의 제1 라벨링 데이터가 상기 제2 시맨틱 정보를 더 포함하도록 하여, 라벨링하여 얻은 목표 오디오 세그먼트가 지능형 음성 시스템에서의 시맨틱 인식 모델의 훈련 샘플로 될 수 있 도록 한다.일 실시예에서, 제1 어구를 얻은 후, 제1 어구의 시맨틱 정보를 추출하여, 제1 시맨틱 정보를 획득할 수도 있다. 일 실시예에서, 제1 어구를 시맨틱 인식 모델에 입력하고, 상기 시맨틱 인식 모델의 처리를 거쳐 제1 시맨틱 정보를 얻을 수 있다. 여기서, 시맨틱 인식 모델은, 예를 들면, fastText 모델, TextCNN 모델, TextRNN 모델, 어텐션 메커니즘 의 TextRNN 모델, 또는 TextRCNN 모델 등과 같은 사전에 훈련된 딥 러닝 텍스트 분류 모델일 수 있으며, 본 개 시는 이에 대해 한정하지 않는다. 설명해야 할 것은, 상기 시맨틱 인식 모델은 지능형 음성 시스템과 별도 인 모델이며, 상기 시맨틱 인식 모델은 지능형 음성 시스템 중의 시맨틱 인식 모델과 유사한 아키텍처를 가질 수 있다. 소정의 텍스트 중의 자연 어구의 시맨틱 정보는 상기 시맨틱 인식 모델을 적용하여 자연 어 구를 인식하여 얻은 것일 수 있다. 제1 시맨틱 정보를 얻은 다음, 본 실시예는 제1 시맨틱 정보와 제2 시맨틱 정보를 비교하여, 제 2 비교 결과를 획득할 수 있다. 구체적으로 제1 시맨틱 정보와 제2 시맨틱 정보 사이의 유사도 를 계산할 수 있다. 상기 유사도와 제2 임계값 사이의 크기 관계에 따라 제2 비교 결과를 결정한다. 예를 들면, 제1 시맨틱 정보와 제2 시맨틱 정보 사이의 유사도가 제2 임계값보다 낮으면, 제2 비교 결과를 제1 시맨 틱 정보가 정확하지 않은 것으로 결정할 수 있고, 제1 시맨틱 정보와 제2 시맨틱 정보 사이의 유사도가 제2 임 계값보다 낮지 않으면, 제2 비교 결과를 제1 시맨틱 정보가 정확한 것으로 결정할 수 있다. 여기서, 제2 임계값 은 실제 수요에 따라 설정될 수 있으며, 본 개시는 이에 대해 한정하지 않는다. 이러한 경우, 제2 비교 결과에 기반하여 목표 음성 세그먼트를 라벨링할 수도 있다. 구체적으로, 전술한 목표 음성 세그먼트를 라벨링하는 동작은 다음과 같을 수 있다. 즉, 제2 어구, 제2 시맨틱 정보, 제1 비교 결과 및 제2 비교 결과에 기반하여, 목표 음성 세그먼트를 라벨링한다. 따라서 목표 음성 세그먼트의 제1 라벨링 데이터 가 제2 시맨틱 정보 및 제2 비교 결과를 지시하는 제2 데이터를 더 포함하도록 한다. 여기서, 제2 비교 결과는 제1 시맨틱 정보가 정확하지 않은 것이면, 상기 제2 비교 결과를 지시하는 제2 데이터는 0일 수 있고, 그렇지 않으면, 1일 수 있다. 상기 제1 라벨링 데이터를 갖는 음성 세그먼트를 훈련 샘플로 할 경우, 이 제2 데이터는 제2 비교 결과와 관련되는 샘플 유형을 표현하는 데 사용될 수도 있으며, 상기 샘플 유형은 시맨틱 인식 모델에 대한 제2 샘플 유형이다. 예를 들면, 제2 비교 결과는 제1 시맨틱 정보가 정확하지 않은 것이면, 제2 데이터는 제2 샘플 유형이 부정적 샘플인 것을 표현할 수 있으며, 그렇지 않으면 제2 데이터는 제2 샘플 유형이 긍정적 샘플인 것을 표현할 수 있다. 이해해야 할 것은, 상기 제2 데이터의 형식은 단지 본 개시의 이해를 돕기 위한 예시일 뿐이며, 본 개시는 이에 대해 한정하지 않는다. 본 실시예의 오디오 신호를 처리하는 방법은, 제1 시맨틱 정보와 제2 시맨틱 정보를 비교하고, 비교 결과 에 기반하여 오디오 세그먼트를 라벨링하는 것을 통해, 긍정적 샘플로서의 음성 세그먼트와 부정적 샘플로서의 음성 세그먼트를 효과적으로 구분할 수 있다. 따라서 상기 라벨링 데이터를 갖는 오디오 세그먼트를 사용하여 지능형 음성 시스템 중의 시맨틱 인식 모델을 훈련시킬 시, 부정적 샘플을 별도로 수집하는 과정을 생략할 수 있어, 지능형 음성 시스템 중 시맨틱 인식 모델을 훈련시킬 시 샘플 준비 단계의 코스트를 감소할 수 있다. 도 5는 본 개시의 다른 일 실시예에 따른 오디오 신호를 처리하는 방법의 흐름 예시도이다. 도 5에 도시된 바와 같이, 일 실시예에서, 본 실시예의 오디오 신호를 처리하는 방법은 위에서 설명된 동 작 S210 내지 동작 S240 외에, 동작 S550 내지 동작 S570을 더 포함할 수 있다. 여기서, 동작 S550 내지 동작 S560은 임의의 시기에 실행될 수 있다. 동작 S570은 동작 S210 내지 동작 S240이 실행되는 과정에서 주기적으로 실행될 수 있다. 동작 S550에서, 처리될 오디오 신호의 저장 용량을 결정한다. 본 개시의 실시예에 따르면, 처리될 오디오 신호를 저장하는 저장 장치에 의해 제공되는 API 인터페이스를 호출 하여 상기 처리될 오디오 신호를 저장하는 저장 용량을 읽을 수 있다. 이해해야 할 것은, 상기 저장 용량의 결 정 방법은 단지 본 개시의 이해를 돕기 위한 예시일 뿐이며, 본 개시는 이에 대해 한정하지 않는다. 동작 S560에서, 저장 용량에 기반하여, 처리될 오디오 신호를 처리하는 예측 시간을 결정한다. 본 개시의 실시예에 따르면, 저장 용량에 상기 오디오 신호를 처리하는 방법을 실행하는 기기의 데이터 소모 속 도를 나눗셈하여 얻은 값을 예측 시간으로 할 수 있다. 여기서, 데이터 소모 속도는 단위 시간 내에 처리할 수 있는 데이터량을 가리킨다. 동작 S570에서, 처리될 오디오 신호를 처리하는 과정에서, 처리될 오디오 신호를 처리하는 시작 시점, 현재 시 점 및 상기 예측 시간에 기반하여, 처리될 오디오 신호를 처리하는 데 필요한 나머지 시간을 결정한다. 본 개시의 실시예에 따르면, 우선 현재 시점과 시작 시점 사이의 시간을 결정하여, 기 사용된 시간으로 하고, 예측 시간과 기 사용된 시간 사이의 차이값을 처리될 오디오 신호를 처리하는 데 필요한 나머지 시간으로 할 수 있다. 나머지 시간을 얻은 다음, 본 실시예는 기술자가 오디오 신호의 처리 진척을 실시간으로 알 수 있도록, 상기 나 머지 시간을 표시할 수도 있으며, 따라서, 기술자가 다른 작업을 위해 스케줄 짜는 데 도움이 될 수 있다. 제1 라벨링 데이터를 갖는 목표 오디오 세그먼트를 얻은 후, 상기 라벨링된 목표 오디오 세그먼트를 훈련 샘플 로 하여, 음성 인식 모델 및/또는 시맨틱 인식 모델을 훈련시킬 수 있다. 이에 기반하여, 본 개시는 음성 인식 모델의 훈련 방법을 더 제공하며, 아래 도 6을 결합하여 상기 방법을 상세하게 설명한다. 도 6은 본 개시의 실시예에 따른 음성 인식 모델의 훈련 방법의 흐름 예시도이다. 도 6에 도시된 바와 같이, 본 실시예의 음성 인식 모델의 훈련 방법은 동작 S610 내지 동작 S620을 포함할 수 있다. 동작 S610에서, 제1 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 제1 샘플 음성 세그먼트와 관련되 는 제1 예측 어구를 획득한다. 여기서, 제1 샘플 음성 세그먼트는 제2 라벨링 데이터를 갖고, 상기 제2 라벨링 데이터는 실제 어구 및 제1 샘 플 음성 세그먼트의 제1 샘플 유형을 지시하는 제4 데이터를 포함한다. 일 실시예에서, 상기 제1 샘플 음성 세 그먼트는 위에서 라벨링하여 얻은 제1 라벨링 데이터를 갖는 목표 음성 세그먼트일 수 있다. 여기서 제2 라벨링 데이터는 바로 위에서 설명된 제1 라벨링 데이터이고, 실제 어구는 위에서 설명된 제2 어구이며, 제4 데이터는 위에서 설명된 제1 데이터이다. 제1 샘플 유형과 위에서 설명된 제1 비교 결과는 관련되고, 관련 관계는 위에서 설명된 바와 같으며, 여기에서 반복하여 설명하지 않는다. 여기서, 음성 인식 모델은 지능형 음성 시스템에서의 모델일 수 있다. 상기 음성 인식 모델은 위에서 설명된 지 능형 음성 시스템과 별도인 음성 인식 모델의 구조와 유사하며, 여기에서 반복하여 설명하지 않는다. 동작 S620에서, 실제 어구, 제1 예측 어구 및 제1 샘플 유형에 기반하여, 음성 인식 모델을 훈련시킨다. 본 실시예는 우선 실제 어구, 제1 예측 어구 및 제1 샘플 유형에 기반하여, 음성 인식 모델의 손실함수의 값을 결정할 수 있다. 이어서, 상기 음성 인식 모델의 손실함수의 값에 따라, 경사하강 알고리즘 또는 역전파 알고리 즘을 적용하여 음성 인식 모델을 훈련시킨다. 이해할 수 있는 것은, 음성 인식 모델을 훈련시키는 방법은 기존 의 기술과 유사하며, 여기에서 반복하여 설명하지 않는다. 본 개시는 시맨틱 인식 모델의 훈련 방법을 더 제공하며, 아래에 도 7을 결합하여 상기 방법을 상세하게 설명한 다. 도 7은 본 개시의 실시예에 따른 시맨틱 인식 모델의 훈련 방법의 흐름 예시도이다. 도 7에 도시된 바와 같이, 본 실시예의 시맨틱 인식 모델의 훈련 방법은 동작 S710 내지 동작 S730을 포함 할 수 있다. 동작 S710에서, 제2 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 제2 샘플 음성 세그먼트와 관련되 는 제2 예측 어구를 획득한다. 여기서, 제2 샘플 음성 세그먼트는 제3 라벨링 데이터를 갖고, 제3 라벨링 데이터는 실제 시맨틱 정보 및 제2 샘플 음성 세그먼트의 제2 샘플 유형을 지시하는 제5 데이터를 포함한다. 일 실시예에서, 제2 샘플 음성 세그먼 트는 위에서 제2 시맨틱 정보, 제2 어구, 제1 비교 결과 및 제2 비교 결과에 기반하여 라벨링하여 얻은 목표 음 성 세그먼트일 수 있다. 상기 제3 라벨링 데이터는 위에서 설명된 제2 시맨틱 정보 및 제2 데이터를 포함하는 제1 라벨링 데이터이다. 상응하게, 실제 시맨틱 정보는 제2 시맨틱 정보이며, 제5 데이터는 제2 비교 결과를 지 시하는 제2 데이터이다. 제2 샘플 유형은 위에서 설명된 제2 비교 결과와 관련되고, 관련 관계는 위에서 설명된 바와 같으며, 여기에서 반복하여 설명하지 않는다. 상기 동작 S710은 위에서 설명된 제1 예측 어구를 획득하는 동작과 유사하며, 여기에서 반복하여 설명하지 않는 다. 동작 S720에서, 제2 예측 어구를 시맨틱 인식 모델의 입력으로 하여, 제2 예측 어구의 예측 시맨틱 정보를 획득 한다. 여기서, 시맨틱 인식 모델은 지능형 음성 시스템에서의 모델일 수 있다. 이 시맨틱 인식 모델은 위에서 설명된 지능형 음성 시스템과 별도인 시맨틱 인식 모델의 구조와 유사하며, 여기에서 반복하여 설명하지 않는다. 상기 제2 예측 어구는 시맨틱 인식 모델의 처리를 거쳐, 시맨틱 인식 모델에 의해 예측 시맨틱 정보가 출력될 수 있 다. 동작 S730에서, 예측 시맨틱 정보, 실제 시맨틱 정보 및 제2 샘플 유형에 기반하여, 시맨틱 인식 모델을 훈련시 킨다. 본 실시예는 우선 실제 시맨틱 정보, 예측 시맨틱 정보 및 제2 샘플 유형에 기반하여, 시맨틱 인식 모델의 손실 함수의 값을 결정할 수 있다. 이어서, 상기 시맨틱 인식 모델의 손실함수의 값에 따라, 경사하강 알고리즘 또는 역전파 알고리즘을 적용하여 시맨틱 인식 모델을 훈련시킨다. 이해할 수 있는 것은, 시맨틱 인식 모델을 훈련시 키는 방법은 기존의 기술과 유사하며, 여기에서 반복하여 설명하지 않는다. 본 개시에 의해 제공되는 오디오 신호를 처리하는 방법에 기반하면, 본 개시는 오디오 신호를 처리하는 장치를 더 제공하며, 아래에 도 8을 결합하여 상기 장치를 상세하게 설명한다. 도 8은 본 개시의 실시예에 따른 오디오 신호를 처리하는 장치의 구조 블록도이다. 도 8에 도시된 바와 같이, 본 실시예의 오디오 신호를 처리하는 장치는 오디오 인식 모듈, 관련 어구 결정 모듈, 어구 비교 모듈 및 음성 라벨링 모듈을 포함할 수 있다. 오디오 인식 모듈은, 처리될 오디오 신호를 인식하여, 처리될 오디오 신호 중의 목표 음성 세그먼트 및 목 표 음성 세그먼트와 관련되는 제1 어구를 획득하기 위한 것이다. 여기서, 처리될 오디오 신호는 소정의 텍스트 에 기반하여 획득된 것이다. 일 실시예에서, 오디오 인식 모듈은 위에서 설명된 동작 S210을 실행하는 데 사용될 수 있으며, 여기에서 반복하여 설명하지 않는다. 관련 어구 결정 모듈은, 소정의 텍스트 중 목표 음성 세그먼트와 관련되는 제2 어구를 결정하기 위한 것이다. 일 실시예에서, 관련 어구 결정 모듈은 위에서 설명된 동작 S220을 실행하는 데 사용될 수 있으며, 여 기에서 반복하여 설명하지 않는다. 어구 비교 모듈은, 제1 어구와 제2 어구를 비교하여, 제1 비교 결과를 획득하기 위한 것이다. 일 실시예에 서, 어구 비교 모듈은 위에서 설명된 동작 S230을 실행하는 데 사용될 수 있으며, 여기에서 반복하여 설명 하지 않는다. 음성 라벨링 모듈은, 제2 어구와 제1 비교 결과에 기반하여, 목표 음성 세그먼트를 라벨링하여, 제1 라벨 링 데이터를 갖는 음성 세그먼트를 획득하기 위한 것이다. 여기서, 제1 라벨링 데이터는 제2 어구 및 제1 비교 결과를 지시하는 제1 데이터를 포함한다. 일 실시예에서, 음성 라벨링 모듈은 위에서 설명된 동작 S240을 실행하는 데 사용될 수 있으며, 여기에서 반복하여 설명하지 않는다. 본 개시의 실시예에 따르면, 소정의 텍스트는 제2 어구의 제2 시맨틱 정보를 더 포함한다. 상기 오디오 신호를 처리하는 장치는 시맨틱 추출 모듈 및 시맨틱 비교 모듈을 더 포함할 수 있다. 시맨틱 추출 모듈은 제1 어 구의 시맨틱 정보를 추출하여, 제1 시맨틱 정보를 획득하기 위한 것이다. 시맨틱 비교 모듈은 제1 시맨틱 정보 와 제2 시맨틱 정보를 비교하여, 제2 비교 결과를 획득하기 위한 것이다. 상기 음성 라벨링 모듈은 구체적 으로 제2 어구, 제2 시맨틱 정보, 제1 비교 결과 및 제2 비교 결과에 기반하여, 목표 음성 세그먼트를 라벨링하 는 데 사용될 수 있다. 여기서, 제1 라벨링 데이터는 제2 시맨틱 정보 및 제2 비교 결과를 지시하는 제2 데이터 를 더 포함한다. 본 개시의 실시예에 따르면, 상기 오디오 인식 모듈은 오디오 읽기 서브 모듈, 음성 검출 서브 모듈, 인식 서브 모듈 및 음성 추출 서브 모듈을 포함할 수 있다. 오디오 읽기 서브 모듈은 파일 스트림의 형식으로 처리될 오디오 신호를 읽기 위한 것이다. 음성 검출 서브 모듈은 오디오 읽기 서브 모듈이 처리될 오디오 신호를 읽는 과정에서, 목표 음성 세그먼트의 시작점 및 종료점을 검출하기 위한 것이다. 인식 서브 모듈은 목표 음성 세그 먼트의 시작점이 음성 검출 서브 모듈에 의해 검출되는 것에 응답하여 읽은 오디오 신호를 인식하고, 또한 목표 음성 세그먼트의 종료점이 음성 검출 서브 모듈에 의해 검출되는 것에 응답하여 오디오 신호의 인식을 정지하여, 목표 음성 세그먼트와 관련되는 제1 어구를 획득하기 위한 것이다. 음성 추출 서브 모듈은 시작점과 종료점 사이의 오디오 신호를 추출하여, 목표 음성 세그먼트를 획득하기 위한 것이다.본 개시의 실시예에 따르면, 소정의 텍스트는 순서대로 배열되는 복수의 자연 어구를 포함하며, 처리될 오디오 신호는 복수의 목표 음성 세그먼트를 포함한다. 관련 어구 결정 모듈은 순서 결정 서브 모듈 및 어구 결정 서브 모듈을 포함할 수 있다. 순서 결정 서브 모듈은 오디오 읽기 서브 모듈이 파일 스트림의 형식으로 처리될 오디오 신호를 읽는 과정에서, 복수의 목표 음성 세그먼트와 각각 관련되는 복수의 어구를 획득하는 것에 대한 인식 서브 모듈이 제1 어구를 획득하는 순서를 결정하기 위한 것이다. 어구 결정 서브 모듈은 복수의 자연 어구 중 상기 순서에 배열되는 자연 어구를 제2 어구로 결정하기 위한 것이다. 본 개시의 실시예에 따르면, 음성 라벨링 모듈은 시작점 및 종료점에 기반하여, 목표 음성 세그먼트를 라벨링하 는 데에도 사용된다. 여기서, 제1 라벨링 데이터는 시작점 및 종료점을 지시하는 제3 데이터를 더 포함한다. 본 개시의 실시예에 따르면, 상기 오디오 신호를 처리하는 장치는 저장 용량 결정 모듈, 예측 시간 결정 모듈 및 나머지 시간 결정 모듈을 더 포함할 수 있다. 저장 용량 결정 모듈은 처리될 오디오 신호의 저장 용량 을 결정하기 위한 것이다. 예측 시간 결정 모듈은 저장 용량에 기반하여 처리될 오디오 신호를 처리하는 예측 시간을 결정하기 위한 것이다. 나머지 시간 결정 모듈은 장치가 처리될 오디오 신호를 처리하는 과정에서, 처리 될 오디오 신호를 처리하는 시작 시점, 현재 시점 및 예측 시간에 기반하여, 처리될 오디오 신호를 처리하는 데 필요한 나머지 시간을 결정하기 위한 것이다. 본 개시에 의해 제공되는 음성 인식 모델의 훈련 방법에 기반하여, 본 개시는 음성 인식 모델의 훈련 장치를 더 제공하며, 아래에, 도 9를 결합하여 상기 장치를 상세하게 설명한다. 도 9는 본 개시의 실시예에 따른 음성 인식 모델 훈련 장치의 구조 블록도이다. 도 9에 도시된 바와 같이, 본 실시예의 음성 인식 모델의 훈련 장치는 제1 어구 예측 모듈 및 제1 모 델 훈련 모듈을 포함할 수 있다. 제1 어구 예측 모듈은 제1 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 제1 샘플 음성 세그먼 트와 관련되는 제1 예측 어구를 획득하기 위한 것이며, 상기 제1 샘플 음성 세그먼트는 제2 라벨링 데이터를 갖 고, 제2 라벨링 데이터는 실제 어구 및 제1 샘플 음성 세그먼트의 제1 샘플 유형을 지시하는 제4 데이터를 포함 한다. 여기서, 제1 샘플 음성 세그먼트는 위에서 설명된 오디오 신호를 처리하는 장치를 적용하여 획득된 것일 수 있으며, 제1 샘플 유형은 제1 비교 결과와 관련될 수 있다. 일 실시예에서, 상기 제1 어구 예측 모듈은 위에서 설명된 동작 S610을 실행하는 데 사용될 수 있으며, 여기에서 반복하여 설명하지 않는다. 제1 모델 훈련 모듈은 실제 어구, 제1 예측 어구 및 제1 샘플 유형에 기반하여, 음성 인식 모델을 훈련시 키기 위한 것이다. 일 실시예에서, 상기 제1 모델 훈련 모듈은 위에서 설명된 동작 S620을 실행하는 데 사 용될 수 있으며, 여기에서 반복하여 설명하지 않는다. 본 개시에 의해 제공되는 시맨틱 인식 모델의 훈련 방법에 기반하여, 본 개시는 시맨틱 인식 모델의 훈련 장치 를 더 제공하며, 아래에, 도 10을 결합하여 상기 장치를 상세하게 설명한다. 도 10은 본 개시의 실시예에 따른 시맨틱 인식 모델 훈련 장치의 구조 블록도이다. 도 10에 도시된 바와 같이, 본 실시예의 시맨틱 인식 모델의 훈련 장치는 제2 어구 예측 모듈, 시 맨틱 예측 모듈 및 제2 모델 훈련 모듈을 포함할 수 있다. 제2 어구 예측 모듈은 제2 샘플 음성 세그먼트를 음성 인식 모델의 입력으로 하여, 제2 샘플 음성 세그먼 트와 관련되는 제2 예측 어구를 획득하기 위한 것이며, 제2 샘플 음성 세그먼트는 제3 라벨링 데이터를 갖고, 제3 라벨링 데이터는 실제 시맨틱 정보 및 제2 샘플 음성 세그먼트의 제2 샘플 유형을 지시하는 제5 데이터를 포함한다. 여기서, 제2 샘플 음성 세그먼트는 위에서 설명된 오디오 신호를 처리하는 장치를 적용하여 획득된 것일 수 있으며, 제2 샘플 유형은 제2 비교 결과와 관련될 수 있다. 일 실시예에서, 상기 제2 어구 예측 모듈 은 위에서 설명된 동작 S710을 실행하는 데 사용될 수 있으며, 여기에서 반복하여 설명하지 않는다. 시맨틱 예측 모듈은 제2 예측 어구를 시맨틱 인식 모델의 입력으로 하여, 제2 예측 어구의 예측 시맨틱 정보를 획득하기 위한 것이다. 일 실시예에서, 상기 시맨틱 예측 모듈은 위에서 설명된 동작 S720을 실행 하는 데 사용될 수 있으며, 여기에서 반복하여 설명하지 않는다. 제2 모델 훈련 모듈은 예측 시맨틱 정보, 실제 시맨틱 정보 및 제2 샘플 유형에 기반하여, 시맨틱 인식 모델을 훈련시키기 위한 것이다. 일 실시예에서, 상기 제2 모델 훈련 모듈은 위에서 설명된 동작 S730을 실행하는 데 사용될 수 있으며, 여기에서 반복하여 설명하지 않는다.설명해야 할 것은, 본 개시의 기술방안에서, 언급되는 사용자 개인 정보의 취득, 저장 및 응용 등은, 모두 관련 법률 법규의 규정에 부합되며, 또한 공서양속에 어긋나지 않는다. 본 개시의 실시예에 따라, 본 개시는 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램 제품을 더 제공한다. 도 11은 본 개시의 실시예의 각 방법을 실현할 수 있는 전자 기기의 블록도를 예시적으로 도시하는 것이다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 워크 스테이션, 개인 휴대 정보 단말기, 서버, 블레이드 서버, 메인 프레임 컴퓨터 및 다른 적합한 컴퓨터 등 다양한 형태의 디지털 컴퓨터를 의미한다. 전자 기기는 개인 디 지털 프로세서, 셀룰러 전화, 스마트 폰, 웨어러블 디바이스 및 다른 유형의 컴퓨팅 장치 등 다양한 형태의 이 동 장치를 의미할 수도 있다. 본 문장에 개시되는 부품, 이들의 연결과 관계 및 이들의 기능은 오직 예시일 뿐 이고, 본 문장에서 설명 및/또는 요구되는 본 개시의 실현을 제한하는 것은 아니다. 도 11에 도시된 바와 같이, 전자 기기에는 리드 온리 메모리(ROM)에 저장된 컴퓨터 프로그램 또는 저장 유닛으로부터 랜덤 액세스 메모리(RAM)로 로딩되는 컴퓨터 프로그램에 근거하여 여러가지 적 합한 동작과 처리를 실행할 수 있는 컴퓨팅 유닛이 포함된다. RAM에는, 전자 기기의 동작에 필요한 다양한 프로그램 및 데이터가 더 저장될 수 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스 를 통해 서로 연결된다. 입력/출력(I/O) 인터페이스도 버스에 연결된다. 전자 기기에서의 복수의 부품은 I/O 인터페이스에 연결되며, 상기 부품에는, 예를 들면 키보드, 마 우스 등과 같은 입력 유닛, 예를 들면 다양한 유형의 디스플레이, 스피커 등과 같은 출력 유닛, 예 를 들면 디스크, 광 디스크 등과 같은 저장 유닛; 및 예를 들면 네트워크 카드, 모뎀(modem), 무선통신 송수신기 등과 같은 통신 유닛이 포함된다. 통신 유닛은 전자 기기가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 텔레콤 네트워크를 통해 기타 기기와 정보/데이터를 교환할 수 있도록 허용한다. 컴퓨팅 유닛은 처리 능력과 컴퓨팅 능력을 갖는 다양한 범용 및/또는 전용 처리 컴포넌트일 수 있다. 컴 퓨팅 유닛의 일부 예시에는, 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공지능(AI) 컴 퓨팅 칩, 머신 러닝 모델 알고리즘을 실행하는 다양한 컴퓨팅 유닛, 디지털 신호 프로세서(DSP) 및 임의의 적합 한 프로세서, 컨트롤러, 마이크로 컨트롤러 등이 포함되지만 이에 한정되는 것은 아니다. 컴퓨팅 유닛은, 예를 들면, 오디오 신호를 처리하는 방법, 음성 인식 모델의 훈련 방법 및 시맨틱 인식 모델의 훈련 방법 중의 적어도 한가지 방법과 같은 위에서 설명된 각 방법과 처리를 실행한다. 예를 들면, 일부 실시예에서, 오디오 신 호를 처리하는 방법, 음성 인식 모델의 훈련 방법 및 시맨틱 인식 모델의 훈련 방법 중의 적어도 한가지 방법은 컴퓨터 소프트웨어 프로그램으로 구현되어, 저장 유닛과 같은 기계 판독가능 매체에 유형적으로 포함될 수 있다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛을 거쳐 전 자 기기에 로딩 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되어 컴퓨팅 유닛에 의해 실행될 경우, 위에서 설명한 오디오 신호를 처리하는 방법, 음성 인식 모델의 훈련 방법 및 시맨틱 인식 모델의 훈련 방법 중의 적어도 한가지 방법의 하나 이상의 단계를 실행할 수 있다. 선택적으로, 기타 실시예에 서, 컴퓨팅 유닛은 기타 임의의 적합한 방식(예를 들면, 펌웨어를 이용함)을 통해 오디오 신호를 처리하 는 방법, 음성 인식 모델의 훈련 방법 및 시맨틱 인식 모델의 훈련 방법 중의 적어도 한가지 방법을 실행하도록 구성될 수 있다. 본 문에서 상기 설명한 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 현장 프로그래밍 가능 게이트 어레이(FPGA), 전용 집적 회로(ASIC), 전용 표준 제품(ASSP), 시스템 온 칩 시스템 (SOC), 복합 프로그래밍 가능 로직 디바이스(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합 에서 실현될 수 있다. 상기 다양한 실시형태는 다음과 같은 내용을 포함할 수 있다. 하나 이상의 컴퓨터 프로그 램에서 실시되고, 상기 하나 이상의 컴퓨터 프로그램은 적어도 하나의 프로그래밍 가능 프로세서를 포함하는 프 로그래밍 가능 시스템에서 실행 및/또는 해석될 수 있다. 상기 프로그래밍 가능 프로세서는 전용 또는 범용 프 로그래밍 가능 프로세서일 수 있으며, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부 터 데이터 및 명령어를 수신하며, 또한 상기 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장 치에 데이터 및 명령어를 전송할 수 있다. 본 발명의 방법을 실시하기 위한 프로그램 코드는 하나 이상의 프로그래밍 언어의 임의의 조합을 적용하여 작성 할 수 있다. 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 시 흐름도 및/또는 블록도에서 규정된 기 능/동작이 실시되도록, 이러한 프로그램 코드를 범용 컴퓨터, 전용 컴퓨터 또는 기타 프로그래밍 가능 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공할 수 있다. 프로그램 코드는 완전히 기계에서 실행되거나, 부분적 으로 기계에서 실행되거나, 개별적인 소프트웨어 패키지(Software Package)로서 부분적으로 기계에서 실행되며,부분적으로 원격 기계에서 실행되거나, 완전히 원격 기계 또는 서버에서 실행될 수 있다. 본 발명의 문맥에서, 기계 판독가능 매체는 유형적인 매체일 수 있다. 상기 기계 판독가능 매체에는, 명령어 실 행 시스템, 장치 또는 기기에 사용되거나 또는 명령어 실행 시스템, 장치 또는 기기와 결합하여 사용되도록 제 공되는 프로그램이 포함되거나 저장될 수 있다. 기계 판독가능 매체는 기계 판독가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독가능 매체에는, 전자, 자성, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적합한 조합이 포함될 수 있지만 이에 한정되는 것은 아니다. 기계 판독가능 저장 매체의 더 구체적인 예시에는 하나 이상의 와이어에 의한 전기적인 연결, 휴대용 컴퓨터 디스크, 하드디스크, 랜덤 액세스 메모리(RAM), 리드 온리 메모리(ROM), 소거 가능 및 프로그램 가능 리드 온리 메모리 (EPROM 또는 플래시 메모리), 광섬유，휴대용 콤팩트 디스크 리드 온리 메모리(CD-ROM), 광학 저장 장치, 자기 저장 장치 또는 상기 내용의 임의의 적합한 조합이 포함될 수 있다. 사용자와의 인터랙션을 제공하기 위해, 여기에서 설명하는 시스템과 기술을 컴퓨터에서 실행할 수 있다. 상기 컴퓨터는 사용자에게 정보를 표시하기 위한 디스플레이 장치(예를 들면, CRT(음극선관) 또는 LCD(액정 디스플레 이) 모니터) 및 키보드, 포인팅 장치(예를 들면, 마우스 또는 트랙 볼)를 포함한다. 사용자는 상기 키보드 및 포인팅 장치를 통해 입력을 컴퓨터에 제공한다. 기타 종류의 장치는 사용자와의 인터랙션을 제공하기 위해 사용 될 수도 있다. 예를 들면, 사용자에게 제공하는 피드백은 임의의 형태의 센싱 피드백(예를 들면, 시각 피드백, 청각 피드백 또는 촉각 피드백)일 수 있으며, 또한 사용자로부터의 입력은 임의의 형태(소리 입력, 음성 입력 또는 촉각 입력을 포함)로 수신될 수 있다. 여기에서 설명하는 시스템 및 기술을 백그라운드 부품을 포함하는 컴퓨팅 시스템(예를 들면, 데이터 서버), 또 는 미들웨어 부품을 포함하는 컴퓨팅 시스템(예를 들면, 애플리케이션 서버), 또는 프론트 부품을 포함하는 컴 퓨팅 시스템(예를 들면, 그래픽 유저 인터페이스 또는 웹 브라우저를 구비하는 사용자 컴퓨터, 사용자는 상기 그래픽 유저 인터페이스 또는 웹 브라우저를 통해 여기에서 설명하는 시스템 및 기술의 실시형태와 인터랙션을 진행할 수 있음), 또는 상기 백그라운드 부품, 미들웨어 부품 또는 프론트 부품의 임의의 조합을 포함하는 컴퓨 팅 시스템에서 실행할 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들면, 통신 네트워크)을 통 해 시스템의 부품을 서로 연결할 수 있다. 통신 네트워크의 예시는 근거리 통신망（LAN）, 광대역 통신망(WAN) 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함한다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있으며, 통신망을 통해 인터랙션을 진행한다. 해당 컴퓨터에서 실행되고, 또한 서로 클라이언트-서버 관계를 갖는 컴퓨 터 프로그램을 통해 클라이언트 및 서버의 관계를 생성한다. 여기서, 서버는 클라우드 컴퓨팅 서버 또는 클라우 드 호스트라고 칭할 수도 있는 클라우드 서버일 수 있으며, 클라우드 컴퓨팅 서비스 체계에서의 호스트 제품으 로서, 기존의 물리적 호스트와 가상 사설 서버 서비스(\"Virtual Private Server\", 또는 \"VPS\"으로 약칭)에 존재 하는 관리 난이도가 크고, 트랜잭션 확장성이 약한 결함을 해결하였다. 서버는 분산 시스템의 서버, 또는 블록 체인을 결합한 서버일 수도 있다. 상기의 다양한 형태의 프로세스를 이용하여, 단계를 다시 순서 배열, 추가 또는 삭제할 수 있음을 이해해야 한 다. 예를 들면, 본 발명에 기재된 각 단계는 병행하여 실행할 수 있고, 순서대로 실행할 수도 있으며, 서로 다 른 순서로 실행할 수도 있는데, 본 발명에 의해 개시되는 기술방안이 기대하는 결과를 실현할 수만 있다면, 이 에 대해 제한하지 않는다. 상기 구체적인 실시형태는 본 발명의 보호 범위에 대해 제한하지 않는다. 당업자는 설계 요구와 기타 요인에 따 라 다양한 수정, 조합, 서브 조합 및 대체를 진행할 수 있음을 이해해야 한다. 본 발명의 사상 및 원칙 내에서 진행되는 수정, 균등한 교체 및 개선 등은 모두 본 발명의 보호 범위에 포함되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2022-0067070", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 본 기술방안을 더 잘 이해하기 위한 것이며, 본 개시를 한정하기 위한 것은 아니다. 여기서, 도 1은 본 개시의 실시예에 따른 오디오 신호를 처리하는 방법, 모델 훈련 방법, 장치, 기기 및 매체의 적용 장 면 예시도이고; 도 2는 본 개시의 실시예에 따른 오디오 신호를 처리하는 방법의 흐름 예시도이고; 도 3은 본 개시의 실시예에 따른 처리될 오디오 신호를 인식하는 원리 예시도이고; 도 4는 본 개시의 실시예에 따른 오디오 신호를 처리하는 원리 예시도이고; 도 5는 본 개시의 다른 일 실시예에 따른 오디오 신호를 처리하는 방법의 흐름 예시도이고; 도 6은 본 개시의 실시예에 따른 음성 인식 모델 훈련 방법의 흐름 예시도이고; 도 7은 본 개시의 실시예에 따른 시맨틱 인식 모델 훈련 방법의 흐름 예시도이고; 도 8은 본 개시의 실시예에 따른 오디오 신호를 처리하는 장치의 구조 블록도이고; 도 9는 본 개시의 실시예에 따른 음성 인식 모델의 훈련 장치의 구조 블록도이고; 도 10은 본 개시의 실시예에 따른 시맨틱 인식 모델의 훈련 장치의 구조 블록도이며; 및 도 11은 본 개시 실시예의 각 방법을 실현하기 위한 전자 기기의 블록도이다."}
