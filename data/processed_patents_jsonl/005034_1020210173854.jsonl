{"patent_id": "10-2021-0173854", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0085562", "출원번호": "10-2021-0173854", "발명의 명칭": "선내 음성 디지털화 시스템 및 방법, 및 동 방법을 컴퓨터에서 실행하기 위한 컴퓨터 프로그", "출원인": "한화오션 주식회사", "발명자": "문상훈"}}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "선내 브릿지 내부의 대화 내용을 이용하여 제1 음성신호를 형성하는 하나 이상의 마이크;선박의 외부와 통신 시 무선통신 내용을 이용하여 제2 음성신호를 형성하는 하나 이상의 VHF 장치;상기 제1 음성신호 및 상기 제2 음성신호를 텍스트 데이터로 변환하는 텍스트 변환 장치; 및상기 텍스트 데이터를 이용하여 상기 선박의 운항에 필요한 운항 정보를 형성하는 자율 운항 플랫폼을포함하는,선내 음성 디지털화 시스템."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 텍스트 데이터를 상기 선박의 외부로 전송하는 통신부를 더 포함하는,선내 음성 디지털화 시스템."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 텍스트 변환 장치는,항해 기록 장치(VDR: Voyage Data Recorder)와 일체로 형성되는 것을 특징으로 하는,선내 음성 디지털화 시스템."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 텍스트 변환 장치는,항해 기록 장치(VDR: Voyage Data Recorder)와 별도 구비되는 것을 특징으로 하는,선내 음성 디지털화 시스템."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 텍스트 변환 장치는,상기 제1 음성신호 및 상기 제2 음성신호를 입력 받는 오디오 입력부,인공지능 기술이 적용되어 학습시킬 수 있으며, 입력 받은 상기 제1 음성신호 및 상기 제2 음성신호의 텍스트정보를 형성하는 음성인식 AI, 및 형성된 상기 텍스트 정보로 상기 텍스트 데이터를 형성하는 텍스트 변환부를 포함하는,선내 음성 디지털화 시스템."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 음성인식 AI는,공개특허 10-2023-0085562-3-트레이닝 음성신호들을 획득하고, 상기 트레이닝 음성신호들로부터 트레이닝 텍스트 객체들을 추출하며, 상기트레이닝 텍스트 객체들에 대응하는 단어 정보인 제1 레이블들을 획득하고, 상기 트레이닝 텍스트 객체들을 뉴럴 네트워크로 적용하여, 상기 트레이닝 텍스트 객체들에 대응하는 트레이닝 출력들을 생성하며, 상기 트레이닝출력들 및 상기 제1 레이블들에 기초하여, 상기 뉴럴 네트워크를 학습시키는,선내 음성 디지털화 시스템."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 자율 운항 플랫폼에서 형성된 상기 운항 정보를 이용하여 상기 선박의 자율 운항을 제어하는 자율 운항 제어 장치를 더 포함하는,선내 음성 디지털화 시스템."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 2 항에 있어서,상기 통신부를 통하여 상기 텍스트 데이터를 수신하는 육상 관제 센터를 더 포함하는,선내 음성 디지털화 시스템."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "선내 브릿지 내부의 대화 내용을 이용하여 제1 음성신호를 형성하는 단계;선박의 외부와 통신 시 무선통신 내용을 이용하여 제2 음성신호를 형성하는 단계;상기 제1 음성신호 및 상기 제2 음성신호를 텍스트 데이터로 변환하는 단계; 및상기 텍스트 데이터를 이용하여 상기 선박의 운항에 필요한 운항 정보를 형성하는 단계를 포함하는,선내 음성 디지털화 방법."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 텍스트 데이터로 변환하는 단계 이후,상기 텍스트 데이터를 상기 선박의 외부로 전송하는 단계를 더 포함하는,선내 음성 디지털화 방법."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 9 항에 있어서,상기 제1 음성신호 및 상기 제2 음성신호를 텍스트 데이터로 변환하는 단계는,상기 제1 음성신호 및 상기 제2 음성신호를 입력 받는 단계,인공지능 기술이 적용되어 학습시킬 수 있으며, 입력 받은 상기 제1 음성신호 및 상기 제2 음성신호의 텍스트정보를 형성하는 단계, 및형성된 상기 텍스트 정보로 상기 텍스트 데이터를 형성하는 단계를 포함하는,선내 음성 디지털화 방법."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 인공지능 기술이 적용된 학습은,공개특허 10-2023-0085562-4-트레이닝 음성신호들을 획득하는 단계,상기 트레이닝 음성신호들로부터 트레이닝 텍스트 객체들을 추출하는 단계,상기 트레이닝 텍스트 객체들에 대응하는 단어 정보인 제1 레이블들을 획득하는 단계,상기 트레이닝 텍스트 객체들을 뉴럴 네트워크로 적용하여, 상기 트레이닝 텍스트 객체들에 대응하는 트레이닝출력들을 생성하는 단계, 및상기 트레이닝 출력들 및 상기 제1 레이블들에 기초하여, 상기 뉴럴 네트워크를 학습시키는 단계를 포함하여 수행되는,선내 음성 디지털화 방법."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 9 항에 있어서,상기 선박의 운항에 필요한 운항 정보를 형성하는 단계 이후,상기 운항 정보를 이용하여 상기 선박의 자율 운항을 제어하는 단계를 더 포함하는,선내 음성 디지털화 방법."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10 항에 있어서,상기 텍스트 데이터를 상기 선박의 외부로 전송하는 단계는,상기 텍스트 데이터를 육상 관제 센터로 전송하는 단계를 포함하는,선내 음성 디지털화 방법."}
{"patent_id": "10-2021-0173854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 9 항 내지 제 14 항 중 어느 한 항에 따른 선내 음성 디지털화 방법을 컴퓨터에서 실행하기 위한 컴퓨터 프로그램이 기록된, 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2021-0173854", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 브릿지 내부의 대화, VHF 장치를 통해 수신되는 무선통신 등을 텍스트로 변환할 수 있는 선내 음성 디 지털화 시스템 및 방법, 동 방법을 컴퓨터에서 실행하기 위한 컴퓨터 프로그램이 기록된 컴퓨터 판독 가능한 기 록 매체에 관한 것이다. 본 발명의 실시예에 따른 선내 음성 디지털화 시스템은, 선내 브릿지 내부의 대화 내용 을 이용하여 제1 음성신호를 형성하고, 선박 외부와의 통신 시 무선통신 내용을 이용하여 제2 음성신호를 형성하 며, 제1 및 제2 음성신호를 텍스트 데이터로 변환하고, 텍스트 데이터를 이용하여 선박의 운항에 필요한 운항 정 보를 형성한다."}
{"patent_id": "10-2021-0173854", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 선내 음성 디지털화 시스템 및 방법, 및 동 방법을 컴퓨터에서 실행하기 위한 컴퓨터 프로그램이 기 록된, 컴퓨터 판독 가능한 기록 매체에 관한 것으로, 보다 구체적으로는 브릿지 내부의 대화, VHF 장치를 통해 수신되는 무선통신 등을 텍스트로 변환할 수 있는 선내 음성 디지털화 시스템 및 방법, 및 동 방법을 컴퓨터에 서 실행하기 위한 컴퓨터 프로그램이 기록된, 컴퓨터 판독 가능한 기록 매체에 관한 것이다."}
{"patent_id": "10-2021-0173854", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 규칙 (Rule) 기반의 스마트 시스템과 달리 기계가 스스로 학습하고 판단하는 시스템이다. 인공지능 시스템은 사용할 수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 규칙 기반의 스마트 시스템은 점차 심층 학습(Deep Learning) 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계 학습 및 기계 학습을 활용한 요소기술들로 구성된다. 기계 학습은 입력 데이터들의 특징 을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 심층 학습 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제 어 등의 기술 분야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조 작 제어(행동 제어) 등을 포함한다. 일반적으로 기계 학습 알고리즘을 실생활에 적용하기 위해서는 기계 학습의 기본 방법론의 특성상 Trial and Error 방식으로 학습을 수행하게 된다. 특히, 심층 학습의 경우 수십만 번의 반복 실행을 필요로 한다. 이를 실 제 물리적인 외부 환경에서 실행하기는 불가능하여 대신 실제 물리적인 외부 환경을 컴퓨터상에서 가상으로 구 현하여 시뮬레이션을 통해 학습을 수행한다. 한편, 선박의 운항에 관련된 주요 정보 중 하나인 브릿지 내부의 대화, VHF(Very High Frequency) 장치를 통해 수신되는 무선통신 내용 등을 오디오 파일 형태로 저장할 경우 엄청난 용량 때문에 장기간 보관이 불가능하고, 인공위성 등 통신망을 이용한 육상 전송이 불가능한 문제점이 있다. 따라서, 브릿지 내부의 대화나 VHF 장치를 통해 수신되는 무선통신 내용 등을 상대적으로 용량이 작은 텍스트 파일 형태로 변환할 필요가 있고, 인공지능 시스템을 통해 오디오 파일을 자동으로 텍스트화 하는 것에 대한 기 술적 요구가 늘어나고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록특허공보 제10-0568621호 (선박 항해기록 자동보고시스템 및 그 방법, 2006.04.07. 공고)"}
{"patent_id": "10-2021-0173854", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 브릿지 내부의 대화, VHF 장치를 통해 수신되는 무선통신 등을 텍스트로 변환할 수 있는 선내 음성 디지털화 시스템 및 방법, 및 동 방법을 컴퓨터에서 실행하기 위한 컴퓨터 프로그램이 기록된, 컴퓨터 판독 가 능한 기록 매체를 제공한다."}
{"patent_id": "10-2021-0173854", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 선내 음성 디지털화 시스템은, 선내 브릿지 내부의 대화 내용을 이용하여 제1 음성 신호를 형성하는 하나 이상의 마이크; 선박의 외부와 통신 시 무선통신 내용을 이용하여 제2 음성신호를 형성하 는 하나 이상의 VHF 장치; 상기 제1 음성신호 및 상기 제2 음성신호를 텍스트 데이터로 변환하는 텍스트 변환 장치; 및 상기 텍스트 데이터를 이용하여 상기 선박의 운항에 필요한 운항 정보를 형성하는 자율 운항 플랫폼을 포함한다. 또한, 상기 텍스트 데이터를 상기 선박의 외부로 전송하는 통신부를 더 포함할 수 있다. 또한, 상기 텍스트 변환 장치는, 항해 기록 장치(VDR: Voyage Data Recorder)와 일체로 형성될 수 있다. 또한, 상기 텍스트 변환 장치는, 항해 기록 장치(VDR: Voyage Data Recorder)와 별도 구비될 수 있다. 또한, 상기 텍스트 변환 장치는, 상기 제1 음성신호 및 상기 제2 음성신호를 입력 받는 오디오 입력부, 인공지 능 기술이 적용되어 학습시킬 수 있으며, 입력 받은 상기 제1 음성신호 및 상기 제2 음성신호의 텍스트 정보를 형성하는 음성인식 AI, 및 형성된 상기 텍스트 정보로 상기 텍스트 데이터를 형성하는 텍스트 변환부를 포함할 수 있다. 또한, 상기 음성인식 AI는, 트레이닝 음성신호들을 획득하고, 상기 트레이닝 음성신호들로부터 트레이닝 텍스트 객체들을 추출하며, 상기 트레이닝 텍스트 객체들에 대응하는 단어 정보인 제1 레이블들을 획득하고, 상기 트레 이닝 텍스트 객체들을 뉴럴 네트워크로 적용하여, 상기 트레이닝 텍스트 객체들에 대응하는 트레이닝 출력들을 생성하며, 상기 트레이닝 출력들 및 상기 제1 레이블들에 기초하여, 상기 뉴럴 네트워크를 학습시킬 수 있다.또한, 상기 자율 운항 플랫폼에서 형성된 상기 운항 정보를 이용하여 상기 선박의 자율 운항을 제어하는 자율 운항 제어 장치를 더 포함할 수 있다. 또한, 상기 통신부를 통하여 상기 텍스트 데이터를 수신하는 육상 관제 센터를 더 포함할 수 있다. 한편, 본 발명의 다른 실시예에 따른 선내 음성 디지털화 방법은, 선내 브릿지 내부의 대화 내용을 이용하여 제 1 음성신호를 형성하는 단계; 선박의 외부와 통신 시 무선통신 내용을 이용하여 제2 음성신호를 형성하는 단계; 상기 제1 음성신호 및 상기 제2 음성신호를 텍스트 데이터로 변환하는 단계; 및 상기 텍스트 데이터를 이용하여 상기 선박의 운항에 필요한 운항 정보를 형성하는 단계를 포함한다. 또한, 상기 텍스트 데이터로 변환하는 단계 이후, 상기 텍스트 데이터를 상기 선박의 외부로 전송하는 단계를 더 포함할 수 있다. 또한, 상기 제1 음성신호 및 상기 제2 음성신호를 텍스트 데이터로 변환하는 단계는, 상기 제1 음성신호 및 상 기 제2 음성신호를 입력 받는 단계, 인공지능 기술이 적용되어 학습시킬 수 있으며, 입력 받은 상기 제1 음성신 호 및 상기 제2 음성신호의 텍스트 정보를 형성하는 단계, 및 형성된 상기 텍스트 정보로 상기 텍스트 데이터를 형성하는 단계를 포함할 수 있다. 또한, 상기 인공지능 기술이 적용된 학습은, 트레이닝 음성신호들을 획득하는 단계, 상기 트레이닝 음성신호들 로부터 트레이닝 텍스트 객체들을 추출하는 단계, 상기 트레이닝 텍스트 객체들에 대응하는 단어 정보인 제1 레 이블들을 획득하는 단계, 상기 트레이닝 텍스트 객체들을 뉴럴 네트워크로 적용하여, 상기 트레이닝 텍스트 객 체들에 대응하는 트레이닝 출력들을 생성하는 단계, 및 상기 트레이닝 출력들 및 상기 제1 레이블들에 기초하여, 상기 뉴럴 네트워크를 학습시키는 단계를 포함하여 수행될 수 있다. 또한, 상기 선박의 운항에 필요한 운항 정보를 형성하는 단계 이후, 상기 운항 정보를 이용하여 상기 선박의 자 율 운항을 제어하는 단계를 더 포함할 수 있다. 또한, 상기 텍스트 데이터를 상기 선박의 외부로 전송하는 단계는, 상기 텍스트 데이터를 육상 관제 센터로 전 송하는 단계를 포함할 수 있다. 한편, 본 발명의 또 다른 실시예에 따른 컴퓨터 판독 가능한 기록매체는, 전술한 선내 음성 디지털화 방법을 컴 퓨터에서 실행하기 위한 컴퓨터 프로그램이 기록된다."}
{"patent_id": "10-2021-0173854", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면, 음성을 상대적으로 용량이 작은 텍스트 파일로 변환함으로써 장기간 보관이 가능 하고, 인공위성 등을 통하여 실시간 또는 주기적으로 육상의 관제 센터로 전송이 가능하며, 자율 운항 선박의 경우 선박의 운항과 관련된 서버에 통신 내용을 제공하여 선박의 운항을 돕도록 할 수 있다. 또한, 본 발명의 실시예들에 따르면, 스마트쉽(Smart Ship) 플랫폼을 통하여 선내/외 어디서나 언제든지 대화 및 통신 내용을 용이하게 확인할 수 있어 선박의 유지관리에 유용하게 사용될 수 있다."}
{"patent_id": "10-2021-0173854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 실시예들은 본 발명의 기술적 사상을 설명하기 위한 목적으로 예시된 것이다. 본 발명에 따른 권리범 위가 이하에 제시되는 실시예들이나 이들 실시예들에 대한 구체적인 설명으로 한정되는 것은 아니다. 이하, 첨부한 도면들을 참조하여, 본 발명의 실시예들을 설명한다. 첨부된 도면에서, 동일하거나 대응하는 구성 요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예들의 설명에 있어서, 동일하거나 대응하는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나, 구성요소에 관한 기술이 생략되어도, 그러한 구성요 소가 어떤 실시예에 포함되지 않는 것으로 의도되지 않는다. 도 1은 본 발명의 일 실시예에 따른 선내 음성 디지털화 시스템의 구성을 보이는 예시도이다. 도 1에 도시한 바와 같이, 선내 음성 디지털화 시스템은, 하나 이상의 마이크(110-1, 110-2, 110-3,…, 110-n), 하나 이상의 VHF(Very High Frequency) 장치(120-1, 120-2), 텍스트 변환 장치, 자율 운항 플랫 폼, 자율 운항 제어 장치, 육상 관제 센터, 케이블, 통신부 및 데이터베이스를 포함할 수 있다. 일 실시예에 따르면, 텍스트 변환 장치는, 오디오 입력부, 음성인식 AI(Artificial Intelligence) 및 텍스트 변환부를 포함할 수 있다. 예를 들어, 하나 이상의 마이크(110-1, 110-2, 110-3,…, 110-n), 하나 이상의 VHF(Very High Frequency) 장치(120-1, 120-2), 텍스트 변환 장치, 자율 운항 플랫폼, 자율 운항 제어 장치, 육상 관제 센터, 케이블, 통신부 및 데이터베이스는 상호간 통신이 가능하도록 선내 네트워크를 통하여 연결될 수 있다. 하나 이상의 마이크(110-1, 110-2, 110-3,…, 110-n)는 선내 브릿지 내부의 대화 내용을 이용하여 제1 음성신호 를 형성할 수 있다. 선교(船橋) 또는 브릿지(bridge)는 하나의 선박 안에서 전체 선박을 지휘할 수 있는 공간을 말한다. 일 실시예에 따르면, 하나 이상의 마이크(110-1, 110-2, 110-3,…, 110-n)는 선내 브릿지 내부의 대화 내용을 녹음할 수 있도록 다양한 위치에 설치될 수 있다. 하나 이상의 VHF(Very High Frequency) 장치(120-1, 120-2)는 선박 외부와의 통신 시 무선통신 내용을 이용하 여 제2 음성신호를 형성할 수 있다. 일 실시예에 따르면, VHF 장치(120-1, 120-2)는 초단파 신호를 이용하여 선 박 외부와의 무선통신을 수행하도록 할 수 있다. VHF 장치(120-1, 120-2)는 선박 외부와의 통신 시 무선통신 내 용을 녹음하여 제2 음성신호를 형성할 수 있다. 텍스트 변환 장치는 제1 및 제2 음성신호를 텍스트 데이터로 변환할 수 있다. 일 실시예에 따르면, 텍스트 변환 장치는 기존의 항해 기록 장치(VDR: Voyage Data Recorder)에 포함되는 것을 특징으로 할 수 있다. 즉, 기존의 항해 기록 장치에 텍스트 변환 장치의 기능이 추가된 차세대 항해 기록 장치가 될 수 있다. 항 해 기록 장치는 선박 위치, 속도, 침로, 선교 근무자 음성, 통신기 음성, 레이더 자료, 수심, 타 조작 내역, 엔 진 사용 내역, 풍향, 풍속, 선박 자동 식별 장치(AIS) 등 관련자료를 저장한다. 비상시에는 선박의 비상전원으 로 작동하고, 선박 비상전원이 차단될 경우 항해 기록 장치는 일정 시간 동안 예비 전원(축전지)을 사용하여 선 교 교신 내용을 지속적으로 기록할 수 있다. 이러한 항해 기록 장치는 선박이 침몰하면 자동으로 해수면 위로 올라오도록 설계될 수 있다. 오디오 입력부는, 하나 이상의 마이크(110-1, 110-2, 110-3,…, 110-n)에서 형성된 제1 음성신호 및 하나 이상의 VHF(Very High Frequency) 장치(120-1, 120-2)에서 형성된 제2 음성신호를 케이블을 통해 입력 받 을 수 있다. 음성인식 AI(Artificial Intelligence)는 제1 및 제2 음성신호에 인공지능 기술을 적용하여 실시간으로 텍 스트 정보를 형성할 수 있다. 일 실시예에 따르면, 음성인식 AI는 트레이닝 음성신호들을 획득하고, 트레 이닝 음성신호들로부터 트레이닝 텍스트 객체들을 추출하며, 트레이닝 텍스트 객체들에 대응하는 단어 정보인 제1 레이블들을 획득하고, 트레이닝 텍스트 객체들을 뉴럴 네트워크로 적용하여, 트레이닝 텍스트 객체들에 대 응하는 트레이닝 출력들을 생성하며, 트레이닝 출력들 및 제1 레이블들에 기초하여, 뉴럴 네트워크를 학습시킬 수 있다. 텍스트 변환부는 음성인식 AI에서 형성된 텍스트 정보를 이용하여 텍스트 데이터를 형성할 수 있다. 자율 운항 플랫폼은 텍스트 변환 장치에서 형성된 텍스트 데이터를 이용하여 선박의 운항에 필요한 운항 정보를 형성할 수 있다. 자율 운항 제어 장치는 자율 운항 플랫폼에서 형성된 운항 정보를 이용하여 선박의 자율 운항이 가능 하도록 제어할 수 있다. 육상 관제 센터는 선박의 통신부를 통하여 주기 또는 비주기적으로 텍스트 데이터를 수신하고 이를 저장할 수 있다. 통신부는 텍스트 변환 장치에서 형성된 텍스트 데이터를 선박 외부로 전송할 수 있다. 데이터베이스는, 다양한 데이터를 저장할 수 있다. 데이터베이스에 저장되는 데이터는, 선내 음성 디지털화 시 스템의 적어도 하나의 구성요소에 의해 획득되거나, 처리되거나, 사용되는 데이터로서, 소프트웨어(예를 들어: 프로그램)를 포함할 수 있다. 데이터베이스는, 휘발성 및/또는 비휘발성 메모리를 포함할 수 있다. 일 실 시예로서, 데이터베이스는, 제1 및 제2 음성신호, 텍스트 데이터, 운항 정보 등을 저장할 수 있다. 본 발명에서, 프로그램은 데이터베이스에 저장되는 소프트웨어로서, 하나 이상의 마이크(110-1, 110-2, 110- 3,…, 110-n), 하나 이상의 VHF(Very High Frequency) 장치(120-1, 120-2), 텍스트 변환 장치, 자율 운항 플랫폼, 자율 운항 제어 장치, 육상 관제 센터, 케이블, 통신부 및 데이터베이스의 리소스 를 제어하기 위한 운영체제, 어플리케이션 및/또는 하나 이상의 마이크(110-1, 110-2, 110-3,…, 110-n), 하나 이상의 VHF(Very High Frequency) 장치(120-1, 120-2), 텍스트 변환 장치, 자율 운항 플랫폼, 자율 운항 제어 장치, 육상 관제 센터, 케이블, 통신부 및 데이터베이스의 리소스들을 활용할 수 있 도록 다양한 기능을 어플리케이션에 제공하는 미들 웨어 등을 포함할 수 있다. 본 발명에서, 인공지능(Artificial Intelligence, AI)은 인간의 학습능력, 추론능력, 지각능력 등을 모방하고, 이를 컴퓨터로 구현하는 기술을 의미하고, 기계 학습, 심볼릭 로직 등의 개념을 포함할 수 있다. 기계 학습 (Machine Learning, ML)은 입력 데이터들의 특징을 스스로 분류 또는 학습하는 알고리즘 기술이다. 인공지능의 기술은 기계 학습의 알고리즘으로써 입력 데이터를 분석하고, 그 분석의 결과를 학습하며, 그 학습의 결과에 기 초하여 판단이나 예측을 할 수 있다. 또한, 기계 학습의 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기 능을 모사하는 기술들 역시 인공지능의 범주로 이해될 수 있다. 예를 들어, 언어적 이해, 시각적 이해, 추론/예 측, 지식 표현, 동작 제어 등의 기술 분야가 포함될 수 있다. 기계 학습은 데이터를 처리한 경험을 이용해 신경망 모델을 훈련시키는 처리를 의미할 수 있다. 기계 학습을 통 해 컴퓨터 소프트웨어는 스스로 데이터 처리 능력을 향상시키는 것을 의미할 수 있다. 신경망 모델은 데이터 사 이의 상관 관계를 모델링하여 구축된 것으로서, 그 상관 관계는 복수의 파라미터에 의해 표현될 수 있다. 신경 망 모델은 주어진 데이터로부터 특징들을 추출하고 분석하여 데이터 간의 상관 관계를 도출하는데, 이러한 과정 을 반복하여 신경망 모델의 파라미터를 최적화 해나가는 것이 기계 학습이라고 할 수 있다. 예를 들어, 신경망 모델은 입출력 쌍으로 주어지는 데이터에 대하여, 입력과 출력 사이의 매핑(상관 관계)을 학습할 수 있다. 또는, 신경망 모델은 입력 데이터만 주어지는 경우에도 주어진 데이터 사이의 규칙성을 도출하여 그 관계를 학 습할 수도 있다. 인공지능 학습모델 또는 신경망 모델은 인간의 뇌 구조를 컴퓨터 상에서 구현하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하며 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워 크 노드들은 뉴런이 시냅스(synapse)를 통하여 신호를 주고받는 뉴런의 시냅틱(synaptic) 활동을 모의하여, 서 로 간의 연결 관계를 가질 수 있다. 인공지능 학습모델에서 복수의 네트워크 노드들은 서로 다른 깊이의 레이어 에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고받을 수 있다. 인공지능 학습모델은, 예 를 들어, 인공 신경망 모델(Artificial Neural Network), 컨볼루션 신경망 모델(Convolution Neural Network: CNN) 등일 수 있다. 일 실시예로서, 인공지능 학습모델은, 지도학습(Supervised Learning), 비지도 학습 (Unsupervised Learning), 강화 학습(Reinforcement Learning) 등의 방식에 따라 기계 학습될 수 있다. 기계 학습을 수행하기 위한 기계 학습 알고리즘에는, 의사결정트리(Decision Tree), 베이지안 망(Bayesian Network), 서포트 벡터 머신(Support Vector Machine), 인공 신경망(Artificial Neural Network), 에이다부스트 (Adaboost), 퍼셉트론(Perceptron), 유전자 프로그래밍(Genetic Programming), 군집화(Clustering) 등이 사용 될 수 있다. 이중, CNN은 최소한의 전처리(preprocess)를 사용하도록 설계된 다계층 퍼셉트론(multilayer perceptrons)의 한 종류이다. CNN은 하나 또는 여러 개의 합성곱 계층과 그 위에 올려진 일반적인 인공 신경망 계층들로 이루어 져 있으며, 가중치와 통합 계층(pooling layer)들을 추가로 활용한다. 이러한 구조 덕분에 CNN은 2차원 구조의 입력 데이터를 충분히 활용할 수 있다. 다른 딥러닝 구조들과 비교해서, CNN은 영상, 음성 분야 모두에서 좋은 성능을 보여준다. CNN은 또한 표준 역전달을 통해 훈련될 수 있다. CNN은 다른 피드포워드 인공신경망 기법들보 다 쉽게 훈련되는 편이고 적은 수의 매개변수를 사용한다는 이점이 있다. 컨볼루션 네트워크는 묶인 파라미터들을 가지는 노드들의 집합들을 포함하는 신경 네트워크들이다. 사용 가능한 트레이닝 데이터의 크기 증가와 연산 능력의 가용성이, 구분적 선형 단위 및 드롭아웃 트레이닝과 같은 알고리 즘 발전과 결합되어, 많은 컴퓨터 비전 작업들이 크게 개선되었다. 오늘날 많은 작업에 사용할 수 있는 데이터 세트들과 같은 엄청난 양의 데이터 세트에서는 초과 맞춤(outfitting)이 중요하지 않으며, 네트워크의 크기를 늘리면 테스트 정확도가 향상된다. 컴퓨팅 리소스들의 최적 사용은 제한 요소가 된다. 이를 위해, 심층 신경 네트워크들의 분산된, 확장 가능한 구현 예가 사용될 수 있다. 도 2는 본 발명의 다른 실시예에 따른 선내 음성 디지털화 시스템의 구성을 보이는 예시도이다. 도 2에 도시한 바와 같이, 선내 음성 디지털화 시스템은, 하나 이상의 마이크(210-1, 210-2, 210-3,…, 210-n), 하나 이상의 VHF 장치(220-1, 220-2), 텍스트 변환 장치, 항해 기록 장치, 자율 운항 플랫 폼, 육상 관제 센터, 자율 운항 제어 장치, 케이블, 통신부 및 데이터베이스를 포함할 수 있다. 일 실시예에 따르면, 텍스트 변환 장치는, 오디오 입력부, 음성인식 AI 및 텍스트 변환부 를 포함할 수 있다. 예를 들어, 하나 이상의 마이크(210-1, 210-2, 210-3,…, 210-n), 하나 이상의 VHF 장치(220-1, 220-2), 텍스트 변환 장치, 항해 기록 장치, 자율 운항 플랫폼, 육상 관제 센터 , 자율 운항 제어 장치, 케이블, 통신부 및 데이터베이스는 상호간 통신이 가능하도록 선내 네 트워크를 통하여 연결될 수 있다. 하나 이상의 마이크(210-1, 210-2, 210-3,…, 210-n)는 선내 브릿지 내부의 대화 내용을 이용하여 제1 음성신호 를 형성할 수 있다. 하나 이상의 VHF 장치(220-1, 220-2)는 선박 외부와의 통신 시 무선통신 내용을 이용하여 제2 음성신호를 형성 할 수 있다. 텍스트 변환 장치는 제1 및 제2 음성신호를 텍스트 데이터로 변환할 수 있다. 본 실시예에 따르면, 텍스트 변환 장치는 항해 기록 장치와는 별도로 구비되는 것을 특징으로 할 수 있다. 오디오 입력부는, 하나 이상의 마이크(210-1, 210-2, 210-3,…, 210-n)에서 형성된 제1 음성신호 및 하나 이상의 VHF 장치(220-1, 220-2)에서 형성된 제2 음성신호를 케이블을 통해 입력 받을 수 있다. 음성인식 AI는 제1 및 제2 음성신호에 인공지능 기술을 적용하여 실시간으로 텍스트 정보를 형성할 수 있 다. 텍스트 변환부는 음성인식 AI에서 형성된 텍스트 정보를 이용하여 텍스트 데이터를 형성할 수 있다. 항해 기록 장치는 하나 이상의 마이크(210-1, 210-2, 210-3,…, 210-n)에서 형성된 제1 음성신호 및 하나 이상의 VHF 장치(220-1, 220-2)에서 형성된 제2 음성신호를 케이블을 통해 입력 받아 저장할 수 있다. 자율 운항 플랫폼은 텍스트 변환 장치에서 형성된 텍스트 데이터를 이용하여 선박의 운항에 필요한 운항 정보를 형성할 수 있다. 육상 관제 센터는 선박의 통신부를 통하여 주기 또는 비주기적으로 텍스트 데이터를 수신하고 이를 저장할 수 있다. 자율 운항 제어 장치는 자율 운항 플랫폼에서 형성된 운항 정보를 이용하여 선박의 자율 운항이 가능 하도록 제어할 수 있다. 통신부는 텍스트 변환 장치에서 형성된 텍스트 데이터를 선박 외부로 전송할 수 있다. 데이터베이스는, 다양한 데이터를 저장할 수 있다. 데이터베이스에 저장되는 데이터는, 선내 음성 디지털화 시 스템의 적어도 하나의 구성요소에 의해 획득되거나, 처리되거나, 사용되는 데이터로서, 소프트웨어(예를 들어: 프로그램)를 포함할 수 있다. 데이터베이스는, 휘발성 및/또는 비휘발성 메모리를 포함할 수 있다. 일 실 시예로서, 데이터베이스는, 제1 및 제2 음성신호, 텍스트 데이터, 운항 정보 등을 저장할 수 있다. 본 발명에서, 프로그램은 데이터베이스에 저장되는 소프트웨어로서, 하나 이상의 마이크(210-1, 210-2, 210- 3,…, 210-n), 하나 이상의 VHF(Very High Frequency) 장치(220-1, 220-2), 텍스트 변환 장치, 항해 기록 장치, 자율 운항 플랫폼, 육상 관제 센터, 자율 운항 제어 장치, 케이블, 통신부 및 데이터베이스의 리소스를 제어하기 위한 운영체제, 어플리케이션 및/또는 하나 이상의 마이크(210-1, 210-2, 210-3,…, 210-n), 하나 이상의 VHF(Very High Frequency) 장치(220-1, 220-2), 텍스트 변환 장치, 항해 기록 장치, 자율 운항 플랫폼, 육상 관제 센터, 자율 운항 제어 장치, 케이블, 통신 부 및 데이터베이스의 리소스들을 활용할 수 있도록 다양한 기능을 어플리케이션에 제공하는 미들 웨어 등을 포 함할 수 있다. 도 3은 본 발명의 일 실시예에 따른 텍스트 변환 장치의 구성을 보이는 예시도이다. 도 3에 도시한 바와 같이, 텍스트 변환 장치(130, 230)는 하나 이상의 프로세서, 하나 이상의 메모리 및/또는 송수신기를 포함할 수 있다. 일 실시예로서, 텍스트 변환 장치(130, 230)의 이 구성요소들 중 적 어도 하나가 생략되거나, 다른 구성요소가 텍스트 변환 장치에 추가될 수 있다. 추가적으로(additionally) 또는 대체적으로(alternatively), 일부의 구성요소들이 통합되어 구현되거나, 단수 또는 복수의 개체로 구현될 수 있다. 텍스트 변환 장치(130, 230) 내, 외부의 구성요소들 중 적어도 일부의 구성요소들은 버스, GPIO(general purpose input/output), SPI(serial peripheral interface) 또는 MIPI(mobile industry processor interface) 등을 통해 서로 연결되어, 데이터 및/또는 시그널을 주고받을 수 있다. 하나 이상의 프로세서는 소프트웨어(예: 명령, 프로그램 등)를 구동하여 프로세서에 연결된 텍스트 변환 장치(130, 230)의 적어도 하나의 구성요소를 제어할 수 있다. 여기서, 텍스트 변환 장치(130, 230)의 적어 도 하나의 구성요소는 오디오 입력부, 음성인식 AI, 텍스트 변환부 일 수 있다. 또한, 프로세서 는 본 발명과 관련된 다양한 연산, 처리, 데이터 생성, 가공 등의 동작을 수행할 수 있다. 또한, 프로세서 는 데이터 등을 하나 이상의 메모리로부터 로드하거나, 하나 이상의 메모리에 저장할 수 있다. 전술한 바와 같이, 하나 이상의 프로세서는, 송수신기을 통하여 하나 이상의 마이크(110-1, 110-2, 110-3,…, 110-n)(210-1, 210-2, 210-3, …, 210-n)로부터 제1 음성신호를 디지털 패킷의 형태로 실시간 또는 비실시간으로 수신하고, 하나 이상의 VHF(Very High Frequency) 장치(120-1, 120-2)(220-1, 220-2)로부터 제2 음성신호를 디지털 패킷의 형태로 실시간 또는 비실시간으로 수신할 수 있다. 일 실시예에 따르면, 수신된 제1 및 제2 음성신호는 디지털 패킷의 형태로 메모리에 저장될 수 있다. 하나 이상의 프로세서는, 송수신기를 통해서 수신된 제1 및 제2 음성신호를 텍스트 데이터로 변환할 수 있다. 일 실시예에 따르면, 프로세서는 트레이닝 음성신호들을 획득하고, 트레이닝 음성신호들로부터 트레이닝 텍스트 객체들을 추출하며, 트레이닝 텍스트 객체들에 대응하는 단어 정보인 제1 레이블들을 획득하고, 트레이닝 텍스트 객체들을 뉴럴 네트워크로 적용하여, 트레이닝 텍스트 객체들에 대응하는 트레이닝 출력들을 생성하며, 트레이닝 출력들 및 제1 레이블들에 기초하여, 뉴럴 네트워크를 학습시킬 수 있다. 하나 이상의 프로세서는, 형성된 텍스트 데이터를 송수신기를 통하여 자율 운항 플랫폼(140, 250)으 로 전송하도록 제어할 수 있다. 하나 이상의 메모리는 다양한 데이터를 저장할 수 있다. 메모리에 저장되는 데이터는, 텍스트 변환 장치(130, 230)의 적어도 하나의 구성요소에 의해 획득되거나, 처리되거나, 사용되는 데이터로서, 소프트웨어 (예: 명령, 프로그램 등)를 포함할 수 있다. 메모리는 휘발성 및/또는 비휘발성 메모리를 포함할 수 있다. 본 발명에서, 명령 내지 프로그램은 메모리에 저장되는 소프트웨어로서, 텍스트 변환 장치(130, 230)의 리 소스를 제어하기 위한 운영체제, 어플리케이션 및/또는 어플리케이션이 텍스트 변환 장치(130, 230)의 리소스들 을 활용할 수 있도록 다양한 기능을 어플리케이션에 제공하는 미들 웨어 등을 포함할 수 있다. 하나 이상의 메모리는 상술한 제1 및 제2 음성신호, 텍스트 데이터, 운항 정보 등을 저장할 수 있다. 또한, 하나 이상의 메모리는, 하나 이상의 프로세서에 의한 실행 시, 하나 이상의 프로세서가 연산을 수행하도록 하는 명령들을 저장할 수 있다. 일 실시예로서, 텍스트 변환 장치(130, 230)는 송수신기를 더 포함할 수 있다. 송수신기는, 하나 이 상의 마이크(110-1, 110-2, 110-3,…, 110-n)(210-1, 210-2, 210-3, …, 210-n), 하나 이상의 VHF(Very High Frequency) 장치(120-1, 120-2)(220-1, 220-2), 텍스트 변환 장치(130, 230), 자율 운항 플랫폼(140, 250), 자 율 운항 제어 장치(150, 270), 육상 관제 센터(160, 260), 통신부, 데이터베이스 및/또는 기타 다른 장치 간의 무선 또는 유선 통신을 수행할 수 있다. 예를 들어, 송수신기는 eMBB(enhanced Mobile Broadband), URLLC(Ultra Reliable Low-Latency Communications), MMTC(Massive Machine Type Communications), LTE(long- term evolution), LTE-A(LTE Advance), UMTS(Universal Mobile Telecommunications System), GSM(Global System for Mobile communications), CDMA(code division multiple access), WCDMA(wideband CDMA), WiBro(Wireless Broadband), WiFi(wireless fidelity), 블루투스(Bluetooth), NFC(near field communication), GPS(Global Positioning System) 또는 GNSS(global navigation satellite system) 등의 방식 에 따른 무선 통신을 수행할 수 있다. 예를 들어, 송수신기는 USB(universal serial bus), HDMI(high definition multimedia interface), RS-232(recommended standard232) 또는 POTS(plain old telephone service) 등의 방식에 따른 유선 통신을 수행할 수 있다. 일 실시예로서, 하나 이상의 프로세서는 송수신기를 제어하여 하나 이상의 마이크(110-1, 110-2, 110-3,…, 110-n)(210-1, 210-2, 210-3, …, 210-n), 하나 이상의 VHF(Very High Frequency) 장치(120-1,120-2)(220-1, 220-2), 텍스트 변환 장치(130, 230), 자율 운항 플랫폼(140, 250), 자율 운항 제어 장치(150, 270), 육상 관제 센터(160, 260), 통신부로부터 정보를 획득할 수 있다. 하나 이상의 마이크(110-1, 110-2, 110-3,…, 110-n)(210-1, 210-2, 210-3, …, 210-n), 하나 이상의 VHF(Very High Frequency) 장치(120-1, 120-2)(220-1, 220-2), 텍스트 변환 장치(130, 230), 자율 운항 플랫폼(140, 250), 자율 운항 제어 장치(150, 270), 육상 관제 센터(160, 260), 통신부로부터 획득된 정보는 하나 이상의 메모리에 저장될 수 있다. 일 실시예로서, 텍스트 변환 장치(130, 230)는 다양한 형태의 장치가 될 수 있다. 예를 들어, 텍스트 변환 장치 (130, 230)는 휴대용 통신 장치, 컴퓨터 장치, 또는 상술한 장치들 중 하나 또는 그 이상의 조합에 따른 장치일 수 있다. 본 발명의 텍스트 변환 장치(130, 230)는 전술한 장치들에 한정되지 않는다. 본 발명에 따른 텍스트 변환 장치(130, 230)의 다양한 실시예들은 서로 조합될 수 있다. 각 실시예들은 경우의 수에 따라 조합될 수 있으며, 조합되어 만들어진 텍스트 변환 장치(130, 230)의 실시예 역시 본 발명의 범위에 속한다. 또한 전술한 본 발명에 따른 텍스트 변환 장치(130, 230)의 내/외부 구성 요소들은 실시예에 따라 추가, 변경, 대체 또는 삭제될 수 있다. 또한 전술한 텍스트 변환 장치(130, 230)의 내/외부 구성 요소들은 하 드웨어 컴포넌트로 구현될 수 있다. 도 4는 본 발명의 일 실시예에 따른 뉴럴 네트워크의 기계 학습을 설명하기 위한 도면이다. 도 4에 도시한 바와 같이, 학습 장치는 선박내에서 수집된 음성신호들로부터 텍스트 데이터를 형성하기 위하여 뉴럴 네트워크를 학습시킬 수 있다. 일 실시예에 따르면, 학습 장치는 텍스트 변환 장치(130, 230)의 음성 인식 AI(134, 234)와 일체로 구성될 수 있으나, 이에 한정되는 것은 아니며 별개로 구성될 수도 있다. 뉴럴 네트워크는 트레이닝 샘플들이 입력되는 입력 레이어와 트레이닝 출력들을 출력하는 출력 레이 어를 포함하고, 트레이닝 출력들과 레이블들 사이의 차이에 기초하여 학습될 수 있다. 여기서, 레이블들은 특징점 객체에 대응하는 신체 부위 정보에 기초하여 정의될 수 있다. 뉴럴 네트워크는 복수의 노드들의 그 룹으로 연결되어 있고, 연결된 노드들 사이의 가중치들과 노드들을 활성화시키는 활성화 함수에 의해 정의된다. 학습 장치는 GD(Gradient Decent) 기법 또는 SGD(Stochastic Gradient Descent) 기법을 이용하여 뉴럴 네트워 크를 학습시킬 수 있다. 학습 장치는 뉴럴 네트워크의 출력들 및 레이블들 의해 설계된 손실 함수(Loss Function)를 이용할 수 있다. 학습 장치는 미리 정의된 손실 함수를 이용하여 트레이닝 에러를 계산할 수 있다. 손실 함수는 레이블, 출력 및 파라미터를 입력 변수로 미리 정의될 수 있고, 여기서 파라미터는 뉴럴 네트워크 내 가중치들에 의해 설정 될 수 있다. 예를 들어, 손실 함수는 MSE(Mean Square Error) 형태, 엔트로피(entropy) 형태 등으로 설계될 수 있는데, 손실 함수가 설계되는 실시예에는 다양한 기법 또는 방식이 채용될 수 있다. 학습 장치는 역전파(Backpropagation) 기법을 이용하여 트레이닝 에러에 영향을 주는 가중치들을 찾아낼 수 있 다. 여기서, 가중치들은 뉴럴 네트워크 내 노드들 사이의 관계들이다. 학습 장치는 역전파 기법을 통해 찾 아낸 가중치들을 최적화시키기 위해 레이블들 및 출력들을 이용한 SGD 기법을 이용할 수 있다. 예를 들어, 학습 장치는 레이블들, 출력들 및 가중치들에 기초하여 정의된 손실 함수의 가중치들을 SGD 기법을 이용하여 갱신할 수 있다. 일 실시예에 따르면, 학습 장치는 트레이닝 음성신호들을 획득하고, 트레이닝 음성신호들로부터 트레이닝 텍스 트 객체들을 추출할 수 있다. 학습 장치는 트레이닝 텍스트 객체들에 대해서 각각 미리 레이블링 된 정보(제1 레이블들)를 획득할 수 있는데, 트레이닝 텍스트 객체들에 미리 정의된 단어 정보를 나타내는 제1 레이블들을 획득할 수 있다. 일 실시예에 따르면, 학습 장치는 트레이닝 음성신호들의 외관 특징들, 패턴 특징들 및 색상 특징들에 기초하여 제1 트레이닝 특징 벡터들을 생성할 수 있다. 트레이닝 음성신호들의 특징을 추출하는 데는 다양한 방식이 채용 될 수 있다. 일 실시예에 따르면, 학습 장치는 제1 트레이닝 특징 벡터들을 뉴럴 네트워크에 적용하여 트레이닝 출력들 을 획득할 수 있다. 학습 장치는 트레이닝 출력들과 제1 레이블들에 기초하여 뉴럴 네트워크를 학습시킬 수 있다. 학습 장치는 트레이닝 출력들에 대응하는 트레이닝 에러들을 계산하고, 그 트레이닝 에러들을 최소화 하기 위해 뉴럴 네트워크 내 노드들의 연결 관계를 최적화하여 뉴럴 네트워크를 학습시킬 수 있다. 텍스트 변환 장치(130, 230)는 학습이 완료된 뉴럴 네트워크를 이용하여 제1 및 제2 음성신호로부터 텍스 트 데이터를 형성할 수 있다.도 5는 본 발명의 일 실시예에 따른 선내 음성 디지털화 방법의 절차를 보이는 흐름도이다. 도 5의 흐름도에서 프로세스 단계들, 방법 단계들, 알고리즘들 등이 순차적인 순서로 설명되었지만, 그러한 프로세스들, 방법들 및 알고리즘들은 임의의 적합한 순서로 작동하도록 구성될 수 있다. 다시 말하면, 본 발명의 다양한 실시예들에서 설명되는 프로세스들, 방법들 및 알고리즘들의 단계들이 본 발명에서 기술된 순서로 수행될 필요는 없다. 또한, 일부 단계들이 비동시적으로 수행되는 것으로서 설명되더라도, 다른 실시예에서는 이러한 일부 단계들이 동시에 수행될 수 있다. 또한, 도면에서의 묘사에 의한 프로세스의 예시는 예시된 프로세스가 그에 대한 다른 변화들 및 수정들을 제외하는 것을 의미하지 않으며, 예시된 프로세스 또는 그의 단계들 중 임의의 것이 본 발명의 다 양한 실시예들 중 하나 이상에 필수적임을 의미하지 않으며, 예시된 프로세스가 바람직하다는 것을 의미하지 않 는다. 도 5에 도시한 바와 같이, 단계(S510)에서, 예를 들어, 도 1 내지 도 4를 참조하면, 하나 이상의 마이크(110-1, 110-2, 110-3,…, 110-n)(210-1, 210-2, 210-3, …, 210-n)는 선내 브릿지 내부의 대화 내용을 이용하여 제1 음성신호를 형성할 수 있다. 단계(S520)에서, 제2 음성신호가 형성된다. 예를 들어, 도 1 내지 도 4를 참조하면, 하나 이상의 VHF(Very High Frequency) 장치(120-1, 120-2)(220-1, 220-2)는 선박 외부와의 통신 시 무선통신 내용을 이용하여 제2 음성신 호를 형성할 수 있다. 단계(S530)에서, 텍스트 데이터로 변환된다. 예를 들어, 도 1 내지 도 4를 참조하면, 텍스트 변환 장치(130, 230)는 케이블(170, 280)을 통해 입력된 제1 및 제2 음성신호를 텍스트 데이터로 변환할 수 있다. 단계(S540)에서, 운항 정보가 형성된다. 예를 들어, 도 1 내지 도 4를 참조하면, 자율 운항 플랫폼(140, 250)은 텍스트 변환 장치(130, 230)에서 형성된 텍스트 데이터를 이용하여 선박의 운항에 필요한 운항 정보를 형성할 수 있다. 상기 방법은 특정 실시예들을 통하여 설명되었지만, 상기 방법은 또한 컴퓨터로 읽을 수 있는 기록매체에 컴퓨 터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체의 예로 는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광데이터 저장 장치 등이 있다. 또한, 컴퓨터가 읽을 수 있 는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장 되고 실행될 수 있다. 그리고, 상기 실시예들을 구현하기 위한 기능적인(functional) 프로그램, 코드 및 코드"}
{"patent_id": "10-2021-0173854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "세그먼트들은 본 발명이 속하는 기술분야의 프로그래머들에 의해 용이하게 추론될 수 있다. 이상, 본 발명을 도면에 도시된 실시예를 참조하여 설명하였다. 그러나, 본 발명은 이에 한정되지 않고 본 발명"}
{"patent_id": "10-2021-0173854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 본 발명과 균등한 범위에 속하는 다양한 변형예 또는 다 른 실시예가 가능하다. 따라서, 본 발명의 진정한 보호범위는 이어지는 특허청구범위에 의해 정해져야 할 것이다."}
{"patent_id": "10-2021-0173854", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 선내 음성 디지털화 시스템의 구성을 보이는 예시도이다. 도 2는 본 발명의 다른 실시예에 따른 선내 음성 디지털화 시스템의 구성을 보이는 예시도이다. 도 3은 본 발명의 일 실시예에 따른 텍스트 변환 장치의 구성을 보이는 예시도이다. 도 4는 본 발명의 일 실시예에 따른 뉴럴 네트워크의 기계 학습을 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시예에 따른 선내 음성 디지털화 방법의 절차를 보이는 흐름도이다."}
