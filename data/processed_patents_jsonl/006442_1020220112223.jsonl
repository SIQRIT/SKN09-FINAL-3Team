{"patent_id": "10-2022-0112223", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0033502", "출원번호": "10-2022-0112223", "발명의 명칭": "도메인 지식을 활용하여 인공지능 기반의 표적 지정 능력을 향상시키는 방법 및 장치", "출원인": "엘아이지넥스원 주식회사", "발명자": "엄태원"}}
{"patent_id": "10-2022-0112223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비행체의 표적 지정 방법에 있어서,복수의 화면 모드 중에서 하나의 화면 모드를 선택하는 단계; 상기 선택된 화면 모드에서 획득한 동영상 내에서 존슨 기준에 따라 유효 화면 영역을 결정하는 단계;딥러닝 추론 모델을 기반으로 상기 유효 화면 영역 내에서 관심 객체를 추론하는 단계; 및상기 딥러닝 추론 모델의 학습에 사용한 데이터를 고려하여 상기 관심 객체의 유효성을 평가하는 단계를 포함하는 비행체의 표적 지정 방법."}
{"patent_id": "10-2022-0112223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 화면 모드는 주 모드로 전체 화면 모드, 고정 유효 화면 모드, 또는 적응형 유효 화면 모드 간에하나로 전환되고,상기 적응형 유효 화면 모드는 서브 모드로 기본 운용 모드 또는 적응 운용 모드 간에 하나로 전환되는 것을 특징으로 하는 비행체의 표적 지정 방법."}
{"patent_id": "10-2022-0112223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 화면 모드를 선택하는 단계는,상기 적응형 유효 화면 모드에서,(i) 제1 기준 시간 동안 상기 비행체에 관한 고도 변화율 절대값 평균이 제1 기준 조건 이하를 만족하는 제1 조건,(ii) 제2 기준 시간 동안 상기 비행체에 관한 헤딩 각도 변화율 절대값 평균이 제2 기준 조건 이하를 만족하는제2 조건,(iii) 제3 기준 시간 동안 상기 비행체에 관한 속력 평균이 제3 기준 조건 범위 이내를 만족하는 제3 조건,(iv) 제4 기준 시간 동안 상기 비행체에 장착된 센서의 팬 각도 변화율 절대값 평균이 제4 기준 조건 이하를 만족하는 제4 조건,(v) 제5 기준 시간 동안 상기 비행체에 장착된 센서의 틸팅 각도 변화율 절대값 평균이 제5 기준 조건 이하를만족하는 제5 조건,(vi) 제6 기준 시간 동안 상기 비행체에 장착된 센서의 줌 레벨 변화율 절대값 평균이 제6 기준 조건 이하를 만족하는 제6 조건을 모두 만족하면 상기 적응 운용 모드를 활성화하는 것을 특징으로 하는 비행체의 표적 지정방법."}
{"patent_id": "10-2022-0112223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 유효 화면 영역을 결정하는 단계는,상기 적응 운용 모드에서,상기 비행체에 장착된 센서의 풋프린트를 계산하고,공개특허 10-2024-0033502-3-상기 풋프린트 내에서 화면 좌표계 영역별로 한 픽셀이 표현하는 픽셀 거리를 도출하고,상기 픽셀 거리를 이용하여 관심 객체의 크기를 픽셀 수로 변환하고,상기 존슨 기준을 기반으로 상기 관심 객체의 상한 기준 픽셀 수 및 하한 기준 픽셀 수를 설정하고,상기 상한 기준 픽셀 수 및 상기 하한 기준 픽셀 수에 따른 화면 유효 영역 후보에 대해서 최소 유효 영역과 비교하고 현재 유효 영역과 비교한 결과를 기반으로 상기 현재 유효 영역을 갱신하여 유효 화면 영역을 확정하고,상기 확정된 유효 화면 영역을 분할하는 것을 특징으로 하는 비행체의 표적 지정 방법."}
{"patent_id": "10-2022-0112223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 관심 객체의 유효성을 평가하는 단계는,상기 딥러닝 추론 모델의 학습에 사용한 정답 클래스의 화면비 통계치를 기준으로 제1 표준화 점수를 계산하고,상기 정답 클래스의 경계 박스 대각선 길이 통계치를 기준으로 제2 표준화 점수를 계산하고,상기 제1 표준화 점수 및 상기 제2 표준화 점수를 기준으로 제1 유효 범위를 벗어나는 이상치를 제거하고,상기 제1 유효 범위를 만족하는 객체에 대해서 상기 정답 클래스의 경계 박스의 가로 픽셀 수와 세로 픽셀 수를기준으로 상기 관심 객체와의 마할라노비스 거리를 계산하고,상기 마할라노비스 거리를 기준으로 제2 유효 범위를 벗어나는 이상치를 제거하고 상기 제2 유효 범위를 만족하는 객체를 대상 표적으로 제시하는 것을 특징으로 하는 비행체의 표적 지정 방법."}
{"patent_id": "10-2022-0112223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "비행체의 표적 지정 장치에 있어서,복수의 화면 모드 중에서 하나의 화면 모드를 선택하는 화면 모드 선택부;상기 선택된 화면 모드에서 획득한 동영상 내에서 존슨 기준에 따라 유효 화면 영역을 결정하는 유효 화면 영역결정부;딥러닝 추론 모델을 기반으로 상기 유효 화면 영역 내에서 관심 객체를 추론하는 관심 객체 추론부; 및상기 딥러닝 추론 모델의 학습에 사용한 데이터를 고려하여 상기 관심 객체의 유효성을 평가하는 추론 유효성평가부를 포함하는 비행체의 표적 지정 장치."}
{"patent_id": "10-2022-0112223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 화면 모드 선택부는,상기 복수의 화면 모드를 주 모드로 전체 화면 모드, 고정 유효 화면 모드, 또는 적응형 유효 화면 모드 간에하나로 전환하고,상기 적응형 유효 화면 모드를 서브 모드로 기본 운용 모드 또는 적응 운용 모드 간에 하나로 전환하는 것을 특징으로 하는 비행체의 표적 지정 장치."}
{"patent_id": "10-2022-0112223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 화면 모드 선택부는,상기 적응형 유효 화면 모드에서,(i) 제1 기준 시간 동안 상기 비행체에 관한 고도 변화율 절대값 평균이 제1 기준 조건 이하를 만족하는 제1 조건,공개특허 10-2024-0033502-4-(ii) 제2 기준 시간 동안 상기 비행체에 관한 헤딩 각도 변화율 절대값 평균이 제2 기준 조건 이하를 만족하는제2 조건,(iii) 제3 기준 시간 동안 상기 비행체에 관한 속력 평균이 제3 기준 조건 범위 이내를 만족하는 제3 조건,(iv) 제4 기준 시간 동안 상기 비행체에 장착된 센서의 팬 각도 변화율 절대값 평균이 제4 기준 조건 이하를 만족하는 제4 조건,(v) 제5 기준 시간 동안 상기 비행체에 장착된 센서의 틸팅 각도 변화율 절대값 평균이 제5 기준 조건 이하를만족하는 제5 조건,(vi) 제6 기준 시간 동안 상기 비행체에 장착된 센서의 줌 레벨 변화율 절대값 평균이 제6 기준 조건 이하를 만족하는 제6 조건을 모두 만족하면 상기 적응 운용 모드를 활성화하는 것을 특징으로 하는 비행체의 표적 지정장치."}
{"patent_id": "10-2022-0112223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 유효 화면 영역 결정부는,상기 적응 운용 모드에서,상기 비행체에 장착된 센서의 풋프린트를 계산하고,상기 풋프린트 내에서 화면 좌표계 영역별로 한 픽셀이 표현하는 픽셀 거리를 도출하고,상기 픽셀 거리를 이용하여 관심 객체의 크기를 픽셀 수로 변환하고,상기 존슨 기준을 기반으로 상기 관심 객체의 상한 기준 픽셀 수 및 하한 기준 픽셀 수를 설정하고,상기 상한 기준 픽셀 수 및 상기 하한 기준 픽셀 수에 따른 화면 유효 영역 후보에 대해서 최소 유효 영역과 비교하고 현재 유효 영역과 비교한 결과를 기반으로 상기 현재 유효 영역을 갱신하여 유효 화면 영역을 확정하고,상기 확정된 유효 화면 영역을 분할하는 것을 특징으로 하는 비행체의 표적 지정 장치."}
{"patent_id": "10-2022-0112223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 추론 유효성 평가부는,상기 딥러닝 추론 모델의 학습에 사용한 정답 클래스의 화면비 통계치를 기준으로 제1 표준화 점수를 계산하고,상기 정답 클래스의 경계 박스 대각선 길이 통계치를 기준으로 제2 표준화 점수를 계산하고,상기 제1 표준화 점수 및 상기 제2 표준화 점수를 기준으로 제1 유효 범위를 벗어나는 이상치를 제거하고,상기 제1 유효 범위를 만족하는 객체에 대해서 상기 정답 클래스의 경계 박스의 가로 픽셀 수와 세로 픽셀 수를기준으로 상기 관심 객체와의 마할라노비스 거리를 계산하고,상기 마할라노비스 거리를 기준으로 제2 유효 범위를 벗어나는 이상치를 제거하고 상기 제2 유효 범위를 만족하는 객체를 대상 표적으로 제시하는 것을 특징으로 하는 비행체의 표적 지정 장치."}
{"patent_id": "10-2022-0112223", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 실시예들은 지도 학습 기반의 딥러닝 네트워크로 관심 객체를 추론하는 동작에 선행하여 선택된 적응적 화면 모드에서 획득한 동영상 내에서 존슨 기준(Johnson's criteria)에 따라 유효 화면 영역을 결정한 후 관심 객체를 추론하고, 추론한 관심 객체에 대해서 지도 학습에 사용한 대상 범주의 픽셀 크기 분포, 관심 객체의 물리적 크 기와 현재 촬영 구도에서의 분포 가능한 픽셀 크기를 조합하여 유효성을 평가하고 보정하는 방식을 통해 150m 이 상의 고도로 운영하면서 직사각형이 아닌 센서 풋프린트 상황에서 표적 지정 성능을 향상시키는 비행체의 표적 지정 방법 및 장치를 제공한다."}
{"patent_id": "10-2022-0112223", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명이 속하는 기술 분야는 비행체의 표적 지정 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0112223", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 실시예에 대한 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아니다. 무인기를 활용한 감시정찰 임무의 주요 목적은 정보 요구 사항에 포함된 관심 객체를 찾고, 관심 객체의 최신 위치를 확보하는 것이다. 정찰 중 관심 객체를 발견하여 확인이 완료된 경우, 관심 객체를 표적으로 지정하여 추적을 수행한다. 표적 추적 능력이 입증된 시스템의 경우에도 화면에 존재하는 관심 객체를 표적으로 지정(designation)하기 위 해서는 운용자의 수동 조작을 필요로 한다. 도 1은 전자광학 센서를 통해 획득한 동영상에 위치하는 관심 객체를 예시한 도면이다. 도 1과 같이 사선 (slant) 거리를 기준으로 1km 밖에서 관심 객체를 인지할 수 있는 성능을 보유한 센서(Electro-Optic, EO)의 경 우에도 실제로 촬영된 관심 객체의 크기가 매우 작음을 확인할 수 있다. 이는 운용자가 제한된 시간 내에 한정 된 수단으로 관심 객체를 지정하는 것에 큰 제약이 있음을 의미한다. 인공지능의 발전으로 비전(vision) 분야에서 지도학습 기반의 객체 인식 능력은 데이터가 충분한 경우, 인간의 능력을 능가하는 것으로 널리 알려져 있다. 임베디드 시스템에서 실시간(soft real-time)으로 객체를 분류하고 추적할 수 있는 YOLO, Deep SORT 등의 프레임워크를 조합하여 현실의 문제를 해결하고 있다. 예를 들면, CCTV와 같이 고정된 카메라나 저속, 저고도에서 운용되는 (비행 중 호버링이 가능한) 멀티콥터에서는 인공지능을 활용 한 종래의 접근법이 효과가 있다. 하지만, 운용 고도가 150m 이상이고 센서의 풋프린트(foot print)가 직사각형이 아닌 경우, 소형 객체를 인식해 야 하는 상황에서는 기존의 딥러닝 기반의 객체 추론 모델을 그대로 적용하면 오탐율(false positive), 미탐율 (false negative)이 두드러지게 증가하는 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허공보 제10-2022-0046854호 (2022.04.15) (특허문헌 0002) 한국등록특허공보 제10-1914281호 (2018.10.26) (특허문헌 0003) 한국등록특허공보 제10-2349854호 (2022.01.06)"}
{"patent_id": "10-2022-0112223", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들은 지도 학습 기반의 딥러닝 네트워크로 관심 객체를 추론하는 동작에 선행하여 선택된 적응 적 화면 모드에서 획득한 동영상 내에서 존슨 기준(Johnson's criteria)에 따라 유효 화면 영역을 결정한 후 관 심 객체를 추론하고, 추론한 관심 객체에 대해서 지도 학습에 사용한 대상 범주의 픽셀 크기 분포, 관심 객체의 물리적 크기와 현재 촬영 구도에서의 분포 가능한 픽셀 크기를 조합하여 유효성을 평가하고 보정하는 방식을 통 해 150m 이상의 고도로 운영하면서 직사각형이 아닌 센서 풋프린트 상황에서 표적 지정 성능을 향상시키는데 주 된 목적이 있다. 본 발명의 명시되지 않은 또 다른 목적들은 하기의 상세한 설명 및 그 효과로부터 용이하게 추론할 수 있는 범 위 내에서 추가적으로 고려될 수 있다."}
{"patent_id": "10-2022-0112223", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 실시예의 일 측면에 의하면, 비행체의 표적 지정 방법에 있어서, 복수의 화면 모드 중에서 하나의 화면 모드 를 선택하는 단계; 상기 선택된 화면 모드에서 획득한 동영상 내에서 존슨 기준에 따라 유효 화면 영역을 결정 하는 단계; 딥러닝 추론 모델을 기반으로 상기 유효 화면 영역 내에서 관심 객체를 추론하는 단계; 및 상기 딥 러닝 추론 모델의 학습에 사용한 데이터를 고려하여 상기 관심 객체의 유효성을 평가하는 단계를 포함하는 비행 체의 표적 지정 방법을 제공한다. 상기 복수의 화면 모드는 주 모드로 전체 화면 모드, 고정 유효 화면 모드, 또는 적응형 유효 화면 모드 간에 하나로 전환되고, 상기 적응형 유효 화면 모드는 서브 모드로 기본 운용 모드 또는 적응 운용 모드 간에 하나로전환될 수 있다. 상기 화면 모드를 선택하는 단계는, 상기 적응형 유효 화면 모드에서, (i) 제1 기준 시간 동안 상기 비행체에 관한 고도 변화율 절대값 평균이 제1 기준 조건 이하를 만족하는 제1 조건, (ii) 제2 기준 시간 동안 상기 비행 체에 관한 헤딩 각도 변화율 절대값 평균이 제2 기준 조건 이하를 만족하는 제2 조건, (iii) 제3 기준 시간 동 안 상기 비행체에 관한 속력 평균이 제3 기준 조건 범위 이내를 만족하는 제3 조건, (iv) 제4 기준 시간 동안 상기 비행체에 장착된 센서의 팬 각도 변화율 절대값 평균이 제4 기준 조건 이하를 만족하는 제4 조건, (v) 제5 기준 시간 동안 상기 비행체에 장착된 센서의 틸팅 각도 변화율 절대값 평균이 제5 기준 조건 이하를 만족하는 제5 조건, (vi) 제6 기준 시간 동안 상기 비행체에 장착된 센서의 줌 레벨 변화율 절대값 평균이 제6 기준 조건 이하를 만족하는 제6 조건을 모두 만족하면 상기 적응 운용 모드를 활성화할 수 있다. 상기 유효 화면 영역을 결정하는 단계는, 상기 적응 운용 모드에서, 상기 비행체에 장착된 센서의 풋프린트를 계산하고, 상기 풋프린트 내에서 화면 좌표계 영역별로 한 픽셀이 표현하는 픽셀 거리를 도출하고, 상기 픽셀 거리를 이용하여 관심 객체의 크기를 픽셀 수로 변환하고, 상기 존슨 기준을 기반으로 상기 관심 객체의 상한 기준 픽셀 수 및 하한 기준 픽셀 수를 설정하고, 상기 상한 기준 픽셀 수 및 상기 하한 기준 픽셀 수에 따른 화 면 유효 영역 후보에 대해서 최소 유효 영역과 비교하고 현재 유효 영역과 비교한 결과를 기반으로 상기 현재 유효 영역을 갱신하여 유효 화면 영역을 확정하고, 상기 확정된 유효 화면 영역을 분할할 수 있다. 상기 관심 객체의 유효성을 평가하는 단계는, 상기 딥러닝 추론 모델의 학습에 사용한 정답 클래스의 화면비 통 계치를 기준으로 제1 표준화 점수를 계산하고, 상기 정답 클래스의 경계 박스 대각선 길이 통계치를 기준으로 제2 표준화 점수를 계산하고, 상기 제1 표준화 점수 및 상기 제2 표준화 점수를 기준으로 제1 유효 범위를 벗어 나는 이상치를 제거하고, 상기 제1 유효 범위를 만족하는 객체에 대해서 상기 정답 클래스의 경계 박스의 가로 픽셀 수와 세로 픽셀 수를 기준으로 상기 관심 객체와의 마할라노비스 거리를 계산하고, 상기 마할라노비스 거 리를 기준으로 제2 유효 범위를 벗어나는 이상치를 제거하고 상기 제2 유효 범위를 만족하는 객체를 대상 표적 으로 제시할 수 있다. 본 실시예의 다른 측면에 의하면, 비행체의 표적 지정 장치에 있어서, 복수의 화면 모드 중에서 하나의 화면 모 드를 선택하는 화면 모드 선택부; 상기 선택된 화면 모드에서 획득한 동영상 내에서 존슨 기준에 따라 유효 화 면 영역을 결정하는 유효 화면 영역 결정부; 딥러닝 추론 모델을 기반으로 상기 유효 화면 영역 내에서 관심 객 체를 추론하는 관심 객체 추론부; 및 상기 딥러닝 추론 모델의 학습에 사용한 데이터를 고려하여 상기 관심 객 체의 유효성을 평가하는 추론 유효성 평가부를 포함하는 비행체의 표적 지정 장치를 제공한다. 상기 화면 모드 선택부는, 상기 복수의 화면 모드를 주 모드로 전체 화면 모드, 고정 유효 화면 모드, 또는 적 응형 유효 화면 모드 간에 하나로 전환하고, 상기 적응형 유효 화면 모드를 서브 모드로 기본 운용 모드 또는 적응 운용 모드 간에 하나로 전환할 수 있다. 상기 화면 모드 선택부는, 상기 적응형 유효 화면 모드에서, (i) 제1 기준 시간 동안 상기 비행체에 관한 고도 변화율 절대값 평균이 제1 기준 조건 이하를 만족하는 제1 조건, (ii) 제2 기준 시간 동안 상기 비행체에 관한 헤딩 각도 변화율 절대값 평균이 제2 기준 조건 이하를 만족하는 제2 조건, (iii) 제3 기준 시간 동안 상기 비 행체에 관한 속력 평균이 제3 기준 조건 범위 이내를 만족하는 제3 조건, (iv) 제4 기준 시간 동안 상기 비행체 에 장착된 센서의 팬 각도 변화율 절대값 평균이 제4 기준 조건 이하를 만족하는 제4 조건, (v) 제5 기준 시간 동안 상기 비행체에 장착된 센서의 틸팅 각도 변화율 절대값 평균이 제5 기준 조건 이하를 만족하는 제5 조건, (vi) 제6 기준 시간 동안 상기 비행체에 장착된 센서의 줌 레벨 변화율 절대값 평균이 제6 기준 조건 이하를 만 족하는 제6 조건을 모두 만족하면 상기 적응 운용 모드를 활성화할 수 있다. 상기 유효 화면 영역 결정부는, 상기 적응 운용 모드에서, 상기 비행체에 장착된 센서의 풋프린트를 계산하고, 상기 풋프린트 내에서 화면 좌표계 영역별로 한 픽셀이 표현하는 픽셀 거리를 도출하고, 상기 픽셀 거리를 이용 하여 관심 객체의 크기를 픽셀 수로 변환하고, 상기 존슨 기준을 기반으로 상기 관심 객체의 상한 기준 픽셀 수 및 하한 기준 픽셀 수를 설정하고, 상기 상한 기준 픽셀 수 및 상기 하한 기준 픽셀 수에 따른 화면 유효 영역 후보에 대해서 최소 유효 영역과 비교하고 현재 유효 영역과 비교한 결과를 기반으로 상기 현재 유효 영역을 갱 신하여 유효 화면 영역을 확정하고, 상기 확정된 유효 화면 영역을 분할할 수 있다. 상기 추론 유효성 평가부는, 상기 딥러닝 추론 모델의 학습에 사용한 정답 클래스의 화면비 통계치를 기준으로 제1 표준화 점수를 계산하고, 상기 정답 클래스의 경계 박스 대각선 길이 통계치를 기준으로 제2 표준화 점수를 계산하고, 상기 제1 표준화 점수 및 상기 제2 표준화 점수를 기준으로 제1 유효 범위를 벗어나는 이상치를 제거하고, 상기 제1 유효 범위를 만족하는 객체에 대해서 상기 정답 클래스의 경계 박스의 가로 픽셀 수와 세로 픽 셀 수를 기준으로 상기 관심 객체와의 마할라노비스 거리를 계산하고, 상기 마할라노비스 거리를 기준으로 제2 유효 범위를 벗어나는 이상치를 제거하고 상기 제2 유효 범위를 만족하는 객체를 대상 표적으로 제시할 수 있다. 본 실시예의 또 다른 측면에 의하면, 컴퓨터에 의해 실행 가능한 컴퓨터 프로그램을 저장하는 컴퓨터 판독 가능 한 저장 매체에 있어서, 표적 지정 방법을 실행할 수 있는 컴퓨터 프로그램을 기록한 컴퓨터 판독 가능한 저장 매체를 제공한다. 본 실시예의 또 다른 측면에 의하면, 프로세서에 의해 실행 가능한 컴퓨터 프로그램 명령어들을 포함하는 컴퓨 터 판독 가능한 저장 매체에 기록된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램 명령어들이 프로세서에 의해 실행되는 경우에, 표적 지정 방법을 수행하는 것을 특징으로 하는 컴퓨터 프로그램을 제공한다."}
{"patent_id": "10-2022-0112223", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이 본 발명의 실시예들에 의하면, 관심 객체 추론에 활용되는 화면이 기존 화면 대비 작아지기 때문에 신호대잡음비가 개선되고, 화면에서 활용되는 관심 객체의 특징이 증가하므로 딥러닝 네트워크 의 추론 능력(정답률)이 향상되고, 이로 인해 운용자가 표적을 지정하기가 용이해지는 효과가 있다. 본 발명의 실시예들에 의하면, 존슨 기준(Johnson's criteria)을 적용하므로 딥러닝에서 활용된 영상을 사람이 크로스체크(운용 중 또는 사후 강평시) 가능하고 딥러닝 추론 결과를 평가할 수 있어 기계-인간의 신뢰(trust) 를 향상시킬 수 있는 효과가 있다. 본 발명의 실시예들에 의하면, 임무 계획과 현재의 비행 상태에서 도출될 수 없는 결론을 배제하여 실질적인 추 론 정확도와 유효성을 향상시킬 수 있다. 예를 들면, 300m 고도에서 45도 틸트 각도로 영상 센서를 운용하는데 세로 크기 5 픽셀 또는 100 픽셀의 버스가 추론된 경우, 추론 결과를 합리적 근거를 바탕으로 스크리닝할 수 있 어 통계적 유의미성 또는 베이즈 추론과 같이 근거를 제시하여 운용자에게 설명할 수 있는 효과가 있다. 여기에서 명시적으로 언급되지 않은 효과라 하더라도, 본 발명의 기술적 특징에 의해 기대되는 이하의 명세서에 서 기재된 효과 및 그 잠정적인 효과는 본 발명의 명세서에 기재된 것과 같이 취급된다."}
{"patent_id": "10-2022-0112223", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명을 설명함에 있어서 관련된 공지기능에 대하여 이 분야의 기술자에게 자명한 사항으로서 본 발명 의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하고, 본 발명의 일부 실시예들 을 예시적인 도면을 통해 상세하게 설명한다. 도 1은 전자광학 센서를 통해 획득한 동영상에 위치하는 관심 객체를 예시한 도면이다. 인공지능과 신호 처리를 통해 배경에서 관심 객체를 추출하는 기존의 방식들은 크게 3가지 측면에서 한계가 있 다. 첫번째 한계는 소형 객체로 인한 낮은 신호대잡음비를 갖고 동일 객체의 화면 내 특징 불균일성을 나타낸다. 운 용 고도가 150m 이상으로 상승됨에 따라 관심 객체의 촬영 결과가 매우 작게 된다. 소형 객체는 신호대잡음비가 상대적으로 낮고, 관심 객체의 특징(feature)이 적다. 비스듬한 촬영 기하 구도에 의해 물리적으로 동일한 관심 객체가 FOV 중심에서는 n개의 픽셀 (pixel)로 표현되나, 화면의 먼 쪽에서는 0.5 x n개의 픽셀로 표현될 수 있 다. 화면의 가까운 쪽에서는 1.5 x n개의 픽셀로 표현될 수 있다. 즉, 동일한 클래스의 관심 객체에 대한 특징 분포가 한 화면내에서도 매우 불균일하게 나타난다. 두번째 한계는 지도 학습 기반의 딥러닝 방식의 근본적인 한계이다. 학습 데이터의 증가가 딥러닝 네트워크의 추론 결과 향상으로 이어지지 않는 한계점이 존재한다. 잘 학습된 딥러닝 네트워크의 추론 결과는 통계적으로 매우 정확하나, 운용자가 이해할 수 없을 정도로 매우 잘못된 추론 결과를 제시하는 경우가 발생할 수 있다. 예 컨대, 영상에서 깨진 픽셀의 조합을 차량으로 분류하면서 신뢰도를 0.98 이상으로 출력할 때가 있다. 세번째 한계는 서버/데스크탑이 아닌 임베디드 환경에서 실시간(soft real-time) 동작이 요구된다. 제한된 하드 웨어 처리성능으로 신뢰성 있는 추론 결과를 실시간으로 출력하는 상대적으로 가벼운(lightweight) 아키텍처를 적용하여야 한다. 고성능 연산을 통한 접근법이 제한된다. 본 실시예에 따른 지도 학습 기반의 딥러닝 네트워크로 관심 객체를 추론하는 동작에 선행하여 선택된 적응적 화면 모드에서 획득한 동영상 내에서 존슨 기준(Johnson's criteria)에 따라 유효 화면 영역을 결정한 후 관심 객체를 추론하고, 추론한 관심 객체에 대해서 지도 학습에 사용한 대상 범주의 픽셀 크기 분포, 관심 객체의 물 리적 크기와 현재 촬영 구도에서의 분포 가능한 픽셀 크기를 조합하여 유효성을 평가하고 보정하는 방식을 통해 150m 이상의 고도로 운영하면서 직사각형이 아닌 센서 풋프린트 상황에서 표적 지정 성능을 향상시킨다. 도 2는 본 발명의 일 실시예에 따른 비행체의 표적 지정 장치를 예시한 블록도이다. 비행체의 표적 지정 장치는 화면 모드 선택부, 유효 화면 영역 결정부, 관심 객체 추론부, 추론 유효성 평가부를 포함한다. 화면 모드 선택부는 복수의 화면 모드 중에서 하나의 화면 모드를 선택한다. 유효 화면 영역 결정부 는 선택된 화면 모드에서 획득한 동영상 내에서 존슨 기준에 따라 유효 화면 영역을 결정한다. 관심 객체 추론 부는 딥러닝 추론 모델을 기반으로 유효 화면 영역 내에서 관심 객체를 추론한다. 추론 유효성 평가부 는 딥러닝 추론 모델의 학습에 사용한 데이터를 고려하여 관심 객체의 유효성을 평가한다. 화면 모드 선택부는 복수의 화면 모드를 주 모드로 전체 화면 모드, 고정 유효 화면 모드, 또는 적응형 유 효 화면 모드 간에 하나의 화면 모드로 전환한다. 화면 모드 선택부는 적응형 유효 화면 모드를 서브 모드 로 기본 운용 모드 또는 적응 운용 모드 간에 하나의 화면 모드로 전환한다.화면 모드 선택부는 적응형 유효 화면 모드에서, (i) 제1 기준 시간 동안 비행체에 관한 고도 변화율 절대 값 평균이 제1 기준 조건(최대 고도 변화율) 이하를 만족하는 제1 조건, (ii) 제2 기준 시간 동안 비행체에 관 한 헤딩 각도 변화율 절대값 평균이 제2 기준 조건(최대 헤딩 각도 변화율) 이하를 만족하는 제2 조건, (iii) 제3 기준 시간 동안 비행체에 관한 속력 평균이 제3 기준 조건 범위(기준 평균 속력 오차 범위) 이내를 만족하 는 제3 조건, (iv) 제4 기준 시간 동안 비행체에 장착된 센서의 팬 각도 변화율 절대값 평균이 제4 기준 조건 (최대 팬 각도 변화율) 이하를 만족하는 제4 조건, (v) 제5 기준 시간 동안 비행체에 장착된 센서의 틸팅 각도 변화율 절대값 평균이 제5 기준 조건(최대 틸팅 각도 변화율) 이하를 만족하는 제5 조건, (vi) 제6 기준 시간 동안 비행체에 장착된 센서의 줌 레벨 변화율 절대값 평균이 제6 기준 조건(최대 줌 레벨 변화율) 이하를 만족 하는 제6 조건을 모두 만족하면 적응 운용 모드를 활성화할 수 있다. 유효 화면 영역 결정부는 적응 운용 모드에서, 비행체에 장착된 센서의 풋프린트를 계산하고, 풋프린트 내 에서 화면 좌표계 영역별로 한 픽셀이 표현하는 픽셀 거리를 도출하고, 픽셀 거리를 이용하여 관심 객체의 크기 를 픽셀 수로 변환하고, 존슨 기준을 기반으로 관심 객체의 상한 기준 픽셀 수 및 하한 기준 픽셀 수를 설정하 고, 상한 기준 픽셀 수 및 하한 기준 픽셀 수에 따른 화면 유효 영역 후보에 대해서 최소 유효 영역과 비교하고 현재 유효 영역과 비교한 결과를 기반으로 현재 유효 영역을 갱신하여 유효 화면 영역을 확정하고, 확정된 유효 화면 영역을 분할할 수 있다. 추론 유효성 평가부는 딥러닝 추론 모델의 학습에 사용한 정답 클래스의 화면비 통계치를 기준으로 제1 표 준화 점수(z-score)를 계산하고, 정답 클래스의 경계 박스 대각선 길이 통계치를 기준으로 제2 표준화 점수(z- score)를 계산하고, 제1 표준화 점수 및 제2 표준화 점수를 기준으로 제1 유효 범위를 벗어나는 이상치를 제거 하고, 제1 유효 범위를 만족하는 객체에 대해서 정답 클래스의 경계 박스의 가로 픽셀 수와 세로 픽셀 수를 기 준으로 관심 객체와의 마할라노비스 거리를 계산하고, 마할라노비스 거리를 기준으로 제2 유효 범위를 벗어나는 이상치를 제거하고 제2 유효 범위를 만족하는 객체를 대상 표적으로 제시할 수 있다. 도 2에서 예시적으로 도시한 다양한 구성요소들 중에서 일부 구성요소를 생략하거나 다른 구성요소를 추가로 포 함할 수 있다. 비행체의 표적 지정 장치에 포함된 구성요소들이 도 2에서는 분리되어 도시되어 있으나, 복수의 구성요소들은 상호 결합되어 적어도 하나의 모듈로 구현될 수 있다. 구성요소들은 장치 내부의 소프트웨어적인 모듈 또는 하 드웨어적인 모듈을 연결하는 통신 경로에 연결되어 상호 간에 유기적으로 동작한다. 이러한 구성요소들은 하나 이상의 통신 버스 또는 신호선을 이용하여 통신한다. 비행체의 표적 지정 장치는 하드웨어, 펌웨어, 소프트웨어 또는 이들의 조합에 의해 로직회로 내에서 구현될 수 있고, 범용 또는 특정 목적 컴퓨터를 이용하여 구현될 수도 있다. 장치는 고정배선형(Hardwired) 기기, 필드 프 로그램 가능한 게이트 어레이(Field Programmable Gate Array, FPGA), 주문형 반도체(Application Specific Integrated Circuit, ASIC) 등을 이용하여 구현될 수 있다. 또한, 장치는 하나 이상의 프로세서 및 컨트롤러를 포함한 시스템온칩(System on Chip, SoC)으로 구현될 수 있다. 비행체의 표적 지정 장치는 하드웨어적 요소가 마련된 컴퓨팅 디바이스 또는 서버에 소프트웨어, 하드웨어, 또 는 이들의 조합하는 형태로 탑재될 수 있다. 컴퓨팅 디바이스 또는 서버는 각종 기기 또는 유무선 통신망과 통 신을 수행하기 위한 통신 모뎀 등의 통신장치, 프로그램을 실행하기 위한 데이터를 저장하는 메모리, 프로그램 을 실행하여 연산 및 명령하기 위한 마이크로프로세서 등을 전부 또는 일부 포함한 다양한 장치를 의미할 수 있 다. 도 3은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법을 예시한 흐름도이다. 비행체의 표적 지정 방법은 컴퓨팅 디바이스 또는 비행체의 표적 지정 장치에 의해 수행될 수 있다. 도 3을 참조하면, 단계 S210에서는 복수의 화면 모드 중에서 하나의 화면 모드를 선택하는 단계를 수행할 수 있 다. 복수의 화면 모드는 주 모드로 전체 화면 모드, 고정 유효 화면 모드, 또는 적응형 유효 화면 모드 간에 하 나로 전환되고, 적응형 유효 화면 모드는 서브 모드로 기본 운용 모드 또는 적응 운용 모드 간에 하나로 전환될 수 있다. 단계 S220에서는 선택된 화면 모드에서 획득한 동영상 내에서 존슨 기준에 따라 유효 화면 영역을 결정하는 단 계를 수행할 수 있다. 무인기의 임무 계획과 현재 상태를 활용하여 촬영된 동영상 내에서 유효한 화면 영역을 결정할 수 있다.단계 S230에서는 딥러닝 추론 모델을 기반으로 상기유효 화면 영역 내에서 관심 객체를 추론하는 단계를 수행할 수 있다. 기존의 방법론 적용이 가능하며, 지도 학습 기반의 딥러닝 네트워크로 관심 객체를 추론할 수 있다. 단계 S240에서는 딥러닝 추론 모델의 학습에 사용한 데이터를 고려하여 관심 객체의 유효성을 평가하는 단계를 수행할 수 있다. 추론 결과를 (i) 지도 학습에 사용한 대상 범주의 픽셀 가로, 세로 크기 분포, (ii) 관심 객체 의 물리적 크기와 현재 촬영 기하 구도에서의 분포 가능한 픽셀 가로, 세로 크기를 조합하여 추론 결과의 유효 성을 평가할 수 있다. 유효한 화면 영역을 판단할 때, 사람의 인지 능력을 고려한 존슨 기준(Johnson's criteria)을 판단 기준으로 활 용한다. 존슨 기준은 군사 원칙 DCRI (탐지/분류/인지/식별)를 적용할 때, 관심 객체를 50% 정확도로 인식하기 위해 필요한 최대 주사선 (현재는 픽셀) 수량에 대한 연구 결과이다. 도 4 및 도 5는 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 전환하는 화면 모드를 예시한 도면이 다. 비행체의 표적 지정 방법은 유효 화면 영역을 결정하기 위해 3개의 주 모드 (전체 화면 모드, 고정 유효화면 모 드, 적응형 유효 화면 모드)와 2개의 서브 모드 (기본 운용 모드, 적응 운용 모드)를 제공한다. 도 6은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 적용하는 유효 화면 영역을 예시한 도면이다. 주 모드 간의 전환은 운용자의 모드 선택에 의해 이루어진다. 예를 들어, 최초 운용 시 전체 화면 모드가 기본 모드가 된다. 운용자가 고정 유효 화면 모드를 선택하면, 사전에 정의된 기본값으로 화면의 특정 영역을 고정적 으로 유효 화면으로 결정한다. 고정 유효 화면은 고정 유효 화면 영역의 좌 상단 좌표와 우 하단 좌표로 결정된 다. 사용자의 입력에 고정 유효 화면 영역은 의해 변경될 수 있다. 도 6을 참조하면, 전체 화면의 가로 비율 0.8, 세로 비율 0.8 영역이 고정 유효 화면인 경우의 예를 나타낸다. 운용자가 고정 유효화면에서 적응형 유효 화면 모드로 전환하는 경우, 초기 모드는 기본 운용 모드가 된다. 적 응형 유효 화면 모드의 서브 모드로, 기본 운용 모드는 현 모드에 진입하기 이전에 설정된 유효 화면 영역을 유 효한 영역으로 결정한다. 이전 모드에서 설정된 값을 기본값으로 사용한다. 예를 들면, 전체 화면 모드에서 진입한 경우, 전체 화면이 유효한 화면 영역의 기본값이 된다. 고정 유효 화면 모드에서 진입한 경우 고정 유효 화면 설정값이 기본값이 된다. 적응형 유효 화면 모드에서 도메인의 지식을 활 용할 때, 무인기의 기동, 센서의 운용이 급격한 상황에서 안정성을 보장하기 위한 모드이다. 도 7은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 기본 운용 모드 및 적응 운용 모드 간에 전환 판단하는 것을 예시한 도면이다. 시스템이 적응형 유효 화면 모드의 기본 운용 모드에서 운용되면, 적응 운용 모드를 활성화할지 여부를 판단한 다. 무인기와 센서가 정보 획득에 정해진 기준에 따라 운용되는 것을 확인하여 적응 운용 모드로 전환한다. 그 이외의 경우, 예를 들면 무인기의 급선회 및 상승, 센서의 급격한 김발(gimbal) 구동 등이 이루어질 때에는 기 본 운용 모드로 운용한다. 왜냐하면 획득한 영상에서 높은 품질의 정보를 획득하기 어렵고, 촬영 영상에서 유의 미한 정보가 연속적으로 등장하지 않기 때문에 효과적인 처리가 제한되기 때문이다. 판단 조건은 시스템의 특성과 도메인 지식을 적용하여 추가 및 변경할 수 있다. 도 7을 참조하면 활성화, 비활 성화 판단 기준을 제시한다. 운용자가 적응형 유효 화면 모드로 진입했을 때, 적응 운용 모드 활성화에 대한 판 단 권한을 시스템에 위임한 것으로 간주하고, 시스템은 판단 기준에 따라 기본 운용 모드와 적응 운용 모드를 스스로 전환한다. 적응 운용 모드에서 운용 중 예를 들어 속력 평균이 기준값을 벗어나면, 시스템은 적응형 유 효 화면 모드 내에서 비활성화를 결정하고 기본 운용 모드로 동작한다. 조건이 충족되는 경우 자동적으로 적응 운용 모드로 전환한다. 화면 모드를 선택하는 동작은 적응형 유효 화면 모드에서, 제1 기준 시간(t1) 동안 비행체에 관한 고도 변화율 절대값 평균이 제1 기준 조건(최대 고도 변화율) 이하를 만족하는 제1 조건을 판단한다(S310). 제2 기준 시간(t2) 동안 비행체에 관한 헤딩 각도 변화율 절대값 평균이 제2 기준 조건(최대 헤딩 각도 변화율) 이하를 만족하는 제2 조건을 판단한다(S320). 제3 기준 시간(t3) 동안 비행체에 관한 속력 평균이 제3 기준 조건(기준 평균 속력 오차 범위) 범위 이내를 만 족하는 제3 조건을 판단한다(S330). 제4 기준 시간(t-4) 동안 상기 비행체에 장착된 센서의 팬 각도 변화율 절대값 평균이 제4 기준 조건(최대 팬 각도 변화율) 이하를 만족하는 제4 조건을 판단한다(S340). 제5 기준 시간(t5) 동안 비행체에 장착된 센서의 틸팅 각도 변화율 절대값 평균이 제5 기준 조건(최대 틸팅 각 도 변화율) 이하를 만족하는 제5 조건을 판단한다(S350). 제6 기준 시간(t6) 동안 비행체에 장착된 센서의 줌 레벨 변화율 절대값 평균이 제6 기준 조건(최대 줌 레벨 변 화율) 이하를 만족하는 제6 조건을 판단한다(S360). 제1 조건, 제2 조건, 제3 조건, 제4 조건, 제5 조건, 및 제6 조건의 만족여부를 판단한다(S370). 어느 하나의 조건이라도 만족하지 않으면 적응 운용 모드를 비활성화한다(S380). 모든 조건을 만족하면 적응 운용 모드를 활 성화한다(S390). 도 8은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 적응 운용 모드에서 유효 화면 영역을 결정하 는 것을 예시한 도면이다. 유효 화면 영역을 결정하는 동작은 적응 운용 모드에서, 비행체에 장착된 센서의 풋프린트를 계산한다(S410). 풋프린트 내에서 화면 좌표계 영역별로 한 픽셀이 표현하는 픽셀 거리를 도출한다(S420). 픽셀 거리를 이용하여 관심 객체의 크기를 픽셀 수로 변환한다(S430). 존슨 기준을 기반으로 관심 객체의 상한 기준 픽셀 수 및 하한 기준 픽셀 수를 설정한다(S440). 상한 기준 픽셀 수 및 하한 기준 픽셀 수에 따른 화면 유효 영역 후보에 대해서 최소 유효 영역과 비교하고 현 재 유효 영역과 비교한 결과를 기반으로 현재 유효 영역을 갱신하여 유효 화면 영역을 확정한다(S450). 확정된 유효 화면 영역을 분할할 수 있다. 시스템은 적응 운용 모드에서 센서 풋프린트를 계산하기 위해 다음의 도메인 지식을 활용한다. 임무 계획으로 관심 지역(위도, 경도, 고도), 관심 객체(범주, 크기)를 활용한다. 무인기의 비행 상태로 적응 운용 모드를 활성화할 때 사용한 파라미터를 활용한다. 센서 상태로 팬(pan) 각도, 틸팅(tilt) 각도를 활용한다. 도 9 및 도 10은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 처리하는 센서 풋프린트를 예시한 도면이다. 도 9를 참조하면, 임무 계획, 무인기의 비행 상태 및 센서 상태와 관련된 지식을 활용한다. 정찰 임무에는 관심 지역 (Area Of Interest, AOI)이 있고, 무인기는 관심 지역을 촬영할 수 있도록 고도 (특히 Target Above Height), 속력, 센서의 틸팅 각도, 줌 레벨을 결정한다. 이러한 계획에 따라 임무 수행하면 동적인 환경 변화에 서 발명의 목표를 달성하기 위해 무인기를 운용한다. 센서 풋프린트의 중심이 관심 지역을 지향하게 된다. 되는 것이다. 도 10을 참조하면, 임무 계획 및 비행 상태의 지식을 적용하여 센서 풋프린트를 계산한다. 적응 운용 모드에서 동작하기 때문에 시스템은 안정적으로 운용되고 있다고 가정한다. 센서 풋프린트 기하 구도는 삼각함수를 이용 한 일반적인 방식으로 계산할 수 있다. 센서 풋프린트 계산 과정에서 TAH(Target Above Height)는 임무 계획에서 촬영의 목표로 삼은 관심 지역의 평균 고도에서 현재 무인기의 운용 고도의 차이로 설정하여 센서 풋프린트를 계산한다. 센서 VFOV (vertical FOV)를 n개로 구분한다. n개로 구분된 영역의 크로스 그라운드 레인지(cross ground range)와 폭(width)를 계산한다. 각 영역별 평균 크로스 레인지(cross range)와 평균 폭(width)을 계산한다. n이 16인 경우로 가정하여 계산 과정을 설명한다. TAH, 틸팅 각도, HFOV, VFOV는 각각 350m, 18도, 14.5도, 8.156도 이다. 크로스 그라운드 레인지는 cross ground range n = TAH / tan ( tilt + VFOV / 2 ) 계산식을 통해 산출할 수 있다. 이 때, tilt + VFOV / 2를 - VFOV / n만큼 감소시키며 반복적으로 크로스 그라운드 레인지(cross ground range)를 계산한다. 0번째 크로스 그라운드 레인지(cross ground range)는 862.89m, 1번째 크로스 그라운드 레인지(cross ground range)는 885.43m 이다. 16번째 크로스 그라운드 레인지(cross ground range)는 1411.92m 이다. 폭은 width n = 2 * cross ground range n * tan (HFOV / 2) 계산식을 통해 산출할 수 있다. 제시한 기하 구도 에서 0번째 폭(width)은 219.55m, 1번째 폭(width)은 225.28m 이다. 16번째 폭(width)은 359.25m이다. 도 11은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법에 의해 n = 16으로 균일하게 분할된 화면 좌표 계를 예시한 도면이다. 화면 좌표계 영역별로 한 픽셀이 표현하는 픽셀 거리(m)를 도출하는 과정을 설명하면, n개로 분할된 화면 영역 에 대한 가로, 세로 m/pixel을 다음 순서로 계산한다(n = 16). 각 영역별 cross range를 (vertical pixel 수 / n)로 나눈다. 각 영역별 평균 width를 horizontal pixel 수로 나눈다. 각 영역별로 픽셀이 표현하는 지면의 가 로 길이와 세로 길이를 저장한다. 수평 픽셀(horizontal pixel) 수, 수직 픽셀(vertical pixel) 수가 1280 pixel, 720 pixel인 경우로 가정하여 설명한다. 크로스 레인지는 cross range 1 = cross ground range 1 - cross ground range 0 계산식을 통해 산출할 수 있 다. cross range 1 = 885.43 - 862.89 = 약 22.54 m 이다. 화면 영역 1의 1 픽셀이 표현하는 세로 거리 = 22.52 / (720 / 16) = 약 0.5 m / pixel 이다. 평균 width 1 = (width 1 + width 0) / 2 = (219.55 + 225.28) / 2 = 약 222.41 m 이다. 화면 영역 1의 1 픽셀이 표현하는 가로 거리 = 222.41 / 1280 = 약 0.174 m / pixel 이다. 화면 영역 1의 가로, 세로 m/pixel (0.174, 0.5)을 저장한다. 도 12는 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법에 의해 16 등분된 화면 영역에서의 관심 객체 픽셀 수를 계산한 결과를 예시한 도면이다. 관심 객체의 크기를 픽셀 수로 변환하는 과정을 설명하면, 관심 객체의 가로, 세로 길이로 대각선 길이를 구한 다. 관심 객체의 대각선 길이를 기준으로 화면 영역 별 관심 객체의 픽셀 수를 계산한다. 관심 객체를 차량이라고 가정하면, 차는 4.4 m x 1.7 m (d x w) (아반떼 예) 크기를 가진다. 관심 객체의 대각선 길이 = sqrt (4.4 * 4.4 + 1.7 * 1.7) = 4.717 m 이다. 관심 객체의 픽셀 수 (영역 1) = min (4.717 / 0.174, 4.717 / 0.5) = min (27.15, 9.42) = 약 9.42 픽셀 이 다. 도 13은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 적용하는 존슨 기준을 예시한 도면이다. 존슨 기준(Johnson's Criteria)은 DRI (Detection, Recognition, Identification) 즉 탐지, 인식, 식별의 군사 원리를 충족하기 위한 센서의 최소 라인 페어 수를 제시한다. 현재는 센서의 촬영 결과를 주사선 방식으로 시현 하지 않기 때문에 픽셀로 변환하여 기준을 적용한다. 존슨 기준은 사람이 50%의 정확도로 대상을 인식할 수 있 는 정도를 측정의 기준을 제시한다(100% 아님). 도 13을 참조하면, Johnson's Criteria를 pixel로 변환한 다양한 기준을 예시한다. 다음과 같은 방식으로 Johnson's Criteria를 활용한다. Johnson's Criteria가 적용된 임무 계획에서 이상적인 관심 객체 촬영 픽셀 수(가로, 세로)를 로드한다. 하한 가중치를 적용하여 하한 기준 픽셀 수를 계산한다. 상한 가중치를 적용하여 상한 기준 픽셀 수를 계산한다. 각 화면 영역에서의 관심 객체 가로, 세로 픽셀 수를 기준 값으로 변환한다. 도 14는 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법에 의해 16 등분된 화면 영역에서의 기준 픽셀 수를 계산한 결과를 예시한 도면이다. 임무 계획 상 현재 고도에서 차량(예컨대, 아반떼)를 촬영하는 경우 (20, 8) pixel이 기준이 된다. 하한 가중치를 적용한 하한 기준 픽셀 수 = (w1 * 20) + (w2 * 8) = 10 + 4 = 14 pixel이다. w1 = 0.5, w2 = 0.5로 가정한다. 상한 가중치를 적용한 상한 기준 픽셀 수 = w3 * 하한 기준 = 1.8 * 14 = 약 25 pixel이다. w3 = 1.8으로 가정 한다. 화면 영역 1 ~ 16의 기준 pixel 수 = (w1 * car horizontal pixel) + (w2 * car vertical pixel) 계산식을 통 해 산출할 수 있다. w1, w2, w3은 조정 파라미터로 테스트 등을 통해 적합한 값으로 갱신할 수 있다. 도 15는 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 유효 화면 영역을 확정하는 동작을 예시한 도면이다. 도 14의 표를 참조하면, 가정된 상황은 현재 화면 유효 영역 하단은 3, 상단은 15 이다. 본 실시예에 의해 결정 된 유효 화면 후보 하단은 1, 상단은 12 이다. 사전에 설정된 화면 모드에서 최소 유효 영역의 크기는 8 (n/2, 즉 16/2) 이다. 기본값은 설정되고 운용자에 의해 설정 가능하다. 최소 유효 화면의 크기 8과 유효 화면 영역 후보(candidate)의 크기 (12-1+1, 12)를 비교한다(S510). 만약 비교 결과 유효 영역 후보의 크기가 작은 경우 8을 중심으로 하단 4 (8/2) 영역을 선택(8, 7, 6, 5)한다. 9를 중심으 로 상단 4 (8/2) 영역을 선택(9, 10, 11, 12)한다. 유효 영역 후보로 5~12 영역을 선택한다. 현재 유효 영역과 유효 영역 후보를 비교하는 절차를 따른다. 본 예시에서는 유효 영역 후보의 크기가 (12 > 8) 크다. 현재 유효 영역과 하단 영역을 비교한다(S520). 예시에서 현재 유효 영역의 하단은 3이고, 유효 영역 후보의 하 단은 1이므로, 후보의 하단이 더 넓다. 더 넓은 경우, 현재 유효 영역의 하단을 1 확장하여 2로 설정한다. 만약 유효 영역 후보와 하단이 같은 경우, 하단 영역을 유지한다. 만약 유효 영역 후보의 하단이 더 좁은 경우, 하단 영역을 1 축소한다. 현재 유효 영역과 상단 영역을 비교한다(S530). 예시에서 현재 유효 영역의 상단은 15이고, 후보의 상단은 12이 므로, 후보의 상단이 더 좁다. 더 좁은 경우, 현재 유효 영역의 상단을 1 축소하여 14로 설정한다. 만약 후보의 상단이 같은 경우, 상단 영역을 유지한다. 만약 후보의 상단이 더 넓은 경우, 상단 영역을 1 확장한다. 현재의 유효 영역을 기준으로 단위(예컨대, 1 영역)씩 만을 업데이트하는 이유는 시스템이 유효 화면을 급격하 게 변경하는 것을 제한하기 위한 목적이다. 확정된 유효 영역을 기준으로 화면 (예: 1280 x 720)을 분할한다(S540). 현재의 가로 대 세로 비율을 (16:9) 확인한다. 확정된 세로 영역 2 ~14를 기준으로 16:9가 되도록 화면을 분할한다. 분할된 화면의 좌상단, 우하단 좌표를 저장한다. 분할된 화면을 다음 단 (기존의 관심 객체 추론)으로 전송한다. 도 16은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법에 의해 16 등분된 화면 영역에서의 확정된 유 효 화면 영역을 예시한 도면이다. 비행체의 표적 지정 방법은 확정된 유효 화면 영역에서 관심 객체 추론을 진행한다. 기존의 지도 학습을 기반으 로 하는 인공지능 방법론 등을 적용할 수 있다. 예컨대, YOLO + Deep SORT 등을 적용할 수 있다. 도 17은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 추론한 관심 객체의 유효성을 평가하는 동작 을 예시한 도면이다. 가정사항으로 관심 객체 추론 결과는 객체의 범주, 경계 박스 좌표 (좌상단, 우하단), 신뢰도 등이 제공된다. 딥러닝을 활용하는 경우, 학습 데이터에서 관심 객체의 정답에 관한 통계 정보를 안다. (분포, 평균, 표준편차 등) 만약 학습 데이터의 통계가 없는 경우 운용 개념과 존슨 기준(Johnson's criteria)를 활용하여 설정된 통계 정보를 활용한다. 관심 객체의 유효성을 평가하는 단계는, 딥러닝 추론 모델의 학습에 사용한 정답 클래스의 화면비 통계치를 기 준으로 제1 표준화 점수를 계산한다(S610). 정답 클래스의 화면비(aspect ratio) 통계치를 기준으로 추론된 객 체의 z-score를 계산한다. 정답 클래스의 aspect ratio 통계치는 평균 1, 표준 편차 1.1에 해당한다. 추론된 객 체의 aspect ratio 값은 1.3에 해당한다. aspect ratio에 대한 z-score = (1.3 - 1) / 1.1 = 0.3909에 해당한 다. 이는 약 65 % 에 해당하는 샘플이다. 정답 클래스의 경계 박스 대각선 길이 통계치를 기준으로 제2 표준화 점수를 계산한다(S620). 정답 클래스의 경 계 박스 대각선 길이 통계치를 기준으로 추론된 객체의 z-score를 계산한다. 정답 클래스의 경계 박스 대각선 길이 통계치는 평균 21.54, 표준 편차 4.5에 해당한다. 추론된 객체의 경계 박스 대각선 길이 값은 19.4에 해당 한다. 경계 박스 대각선 길에 대한 z-score = (19.4 - 21.54) / 4.5 = -0.4756에 해당한다. 이는 약 32%에 해당하는 샘플이다. 제1 표준화 점수 및 제2 표준화 점수를 기준으로 제1 유효 범위를 벗어나는 이상치를 제거한다(S630, S660). z- score에서 도출한 분포에 가중치를 적용하고 기준값과 비교한다. 가중치가 적용된 % = w1 * 65% + w2 * 32% = 48.5%에 해당한다. w1 = 0.5, w2 = 0.5로 설정될 수 있다. 설정된 스크리닝 기준 5%, 95%인 경우 인식된 결과를 무효화하고 제거한다. 유효 범위에 있는 경우, 다음을 진행한다. 제1 유효 범위를 만족하는 객체에 대해서 클래스의 경계 박스의 가로 픽셀 수와 세로 픽셀 수를 기준으로 관심 객체와의 마할라노비스 거리를 계산한다. 정답 데이터 경계 박스의 가로 픽셀과 세로 픽셀 각각을 랜덤 변 수로 고려하여, 공 분산 (covariance matrix) 값을 로드한 후, 추론된 객체의 가로, 세로 픽셀 크기와의 마할라 노비스(Mahalanobis) 거리를 계산한다. 정답 데이터 경계 박스의 가로 픽셀 수, 세로 픽셀 수의 랜덤변수(X)를 예시하면, X: 가로 평균(mean)(μXY)은 20이고, 세로 평균(mean)(μY)은 8이고, 공분산 매트릭스(covariance matrix) (∑) = [4.5 0.5; 0.5 3.5]에 해당한다. 추론된 객체의 가로, 세로 픽셀 크기(Y) 예시하면 (4개의 경 우) Y = [20 8; 17 6; 25 18; 21 7]에 해당한다. 마할라노비스 거리는 다음 계산식(수학식 1)으로 표현된다. 수학식 1"}
{"patent_id": "10-2022-0112223", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "계산 예로 d = (0.0, 3.002, 33.109, 0.542)을 산출할 수 있다. 마할라노비스 거리를 기준으로 제2 유효 범위를 벗어나는 이상치를 제거한다(S650, S660). 제2 유효 범위를 만 족하는 객체를 대상 표적으로 제시할 수 있다(S670). d가 dlimit보다 크면 outlier이므로 제거하고, 아닌 경우 운 용자 지정 대상 표적으로 설정한다. 운용자가 화면에서 표적을 지정하는 경우, 운용자에 의해 입력된 화면 x, y 좌표와 표적 설정 단계에서 설정된 대상 간의 픽셀 중심과의 거리를 계산하여 가까운 순으로 표적을 지정한다. 도 18은 본 발명의 실시예들을 실시하는 컴퓨팅 디바이스를 예시한 블록도이다. 컴퓨팅 디바이스는 적어도 하나의 프로세서, 컴퓨터 판독 가능한 저장매체 및 통신 버스 를 포함한다. 프로세서는 컴퓨팅 디바이스를 동작하도록 제어할 수 있다. 예컨대, 프로세서는 컴퓨터 판독 가능한 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있다. 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 컴퓨터 실행 가능 명령어는 프로세서에 의해 실행 되는 경우 컴퓨팅 디바이스로 하여금 예시적인 실시예에 따른 동작들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능한 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능한 저장 매체에 저장된 프로그램 은 프로세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독한 가능 저장 매체는 메모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조 합), 하나 이상의 자기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 디바이스에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이 들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능한 저장 매체를 포함하여 컴퓨팅 디바이스의 다른 다양한 컴포넌트들을 상호 연결한다. 컴퓨팅 디바이스는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인 터페이스 및 하나 이상의 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 통신 인 터페이스는 통신 버스에 연결된다. 입출력 장치(미도시)는 입출력 인터페이스를 통해 컴퓨팅 디바이스의 다른 컴포넌트들에 연결될 수 있다. 도 3, 도 7, 도 8, 도 15, 도 17에서는 각각의 과정을 순차적으로 실행하는 것으로 기재하고 있으나 이는 예시 적으로 설명한 것에 불과하고, 이 분야의 기술자라면 본 발명의 실시예의 본질적인 특성에서 벗어나지 않는 범 위에서 도 3, 도 7, 도 8, 도 15, 도 17에 기재된 순서를 변경하여 실행하거나 또는 하나 이상의 과정을 병렬적으로 실행하거나 다른 과정을 추가하는 것으로 다양하게 수정 및 변형하여 적용 가능할 것이다. 본 실시예들에 따른 동작은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨 터 판독 가능한 매체에 기록될 수 있다. 컴퓨터 판독 가능한 매체는 실행을 위해 프로세서에 명령어를 제공하는 데 참여한 임의의 매체를 나타낸다. 컴퓨터 판독 가능한 매체는 프로그램 명령, 데이터 파일, 데이터 구조 또는 이들의 조합을 포함할 수 있다. 예를 들면, 자기 매체, 광기록 매체, 메모리 등이 있을 수 있다. 컴퓨터 프로그 램은 네트워크로 연결된 컴퓨터 시스템 상에 분산되어 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 본 실시예를 구현하기 위한 기능적인(Functional) 프로그램, 코드, 및 코드 세그먼트들은 본"}
{"patent_id": "10-2022-0112223", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "실시예가 속하는 기술분야의 프로그래머들에 의해 용이하게 추론될 수 있을 것이다. 본 실시예들은 본 실시예의 기술 사상을 설명하기 위한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상 의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0112223", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 전자광학 센서를 통해 획득한 동영상에 위치하는 관심 객체를 예시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 비행체의 표적 지정 장치를 예시한 블록도이다. 도 3은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법을 예시한 흐름도이다. 도 4 및 도 5는 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 전환하는 화면 모드를 예시한 도면이 다. 도 6은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 적용하는 유효 화면 영역을 예시한 도면이다. 도 7은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 기본 운용 모드 및 적응 운용 모드 간에 전환 판단하는 것을 예시한 도면이다. 도 8은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 적응 운용 모드에서 유효 화면 영역을 결정하 는 것을 예시한 도면이다. 도 9 및 도 10은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 처리하는 센서 풋프린트를 예시한 도면이다. 도 11은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법에 의해 n = 16으로 균일하게 분할된 화면 좌표 계를 예시한 도면이다. 도 12는 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법에 의해 16 등분된 화면 영역에서의 관심 객체 픽셀 수를 계산한 결과를 예시한 도면이다. 도 13은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 적용하는 존슨 기준을 예시한 도면이다. 도 14는 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법에 의해 16 등분된 화면 영역에서의 기준 픽셀수를 계산한 결과를 예시한 도면이다. 도 15는 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 유효 화면 영역을 확정하는 동작을 예시한 도면이다. 도 16은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법에 의해 16 등분된 화면 영역에서의 확정된 유 효 화면 영역을 예시한 도면이다. 도 17은 본 발명의 다른 실시예에 따른 비행체의 표적 지정 방법이 추론한 관심 객체의 유효성을 평가하는 동작 을 예시한 도면이다. 도 18은 본 발명의 실시예들을 실시하는 컴퓨팅 디바이스를 예시한 블록도이다."}
