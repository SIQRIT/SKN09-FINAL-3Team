{"patent_id": "10-2020-0037299", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0120508", "출원번호": "10-2020-0037299", "발명의 명칭": "인공지능 기반의 이상음원 인식 장치, 그 방법 및 이를 이용한 관제시스템", "출원인": "아이브스 주식회사", "발명자": "배영훈"}}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "임의음원 데이터셋의 데이터량을 토대로 수행된 기계학습 결과를 이용하여 이상음원을 분류하기 위한 이상음원용 모델을 생성하기 위한 모델 생성부;외부로부터 입력된 음원신호를 시간차를 두고 인식하기 위해 음원구간을 시분할하여 추출하기 위한 음원구간 추출부;상기 음원구간의 음원특징을 추출하기 위한 음원특징 추출부;상기 이상음원용 모델을 이용하여 상기 음원특징을 미리 정해진 이상음원 종류별로 분류하기 위한 이상음원 분류부; 및상기 음원특징의 시간차 분류결과에 따라 상기 음원신호의 이상음원 인식결과를 알려주기 위한 이상음원인식부;를 포함하는 인공지능 기반의 이상음원 인식 장치."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 음원구간 추출부는,상기 음원신호를 첫번째 최고점이 확인되는 제1 음원구간과, 상기 제1 음원구간에 연속하여 미리 정해진 시간동안에 확인되는 제2 음원구간으로 추출하는 것인 인공지능 기반의 이상음원 인식 장치."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 제1 음원구간은,싱기 첫번째 최고점을 기준으로 좌우 각각 1초의 구간 길이를 나타내고,상기 제2 음원구간은,상기 제1 음원구간 보다 4배의 구간 길이를 나타내는 것인 인공지능 기반의 이상음원 인식 장치."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 제2 음원구간은, 한 번 이상의 최고점이 나타나는 것인 인공지능 기반의 이상음원 인식 장치."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 2 항에 있어서,상기 이상음원 인식부는,상기 제1 음원구간을 통해 상기 음원신호에 대해 1차 이상음원 인식결과를 알려준 다음, 상기 제2 음원구간을공개특허 10-2021-0120508-3-통해 상기 음원신호에 대해 2차 이상음원 인식결과를 알려주는 것인 인공지능 기반의 이상음원 인식 장치."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 이상음원 인식부는,상기 1차 이상음원 인식결과와 상기 2차 이상음원 인식결과에서 복수의 이상음원을 인식하는 경우에, 복수의 이상음원 인식결과를 종합하여 이상음원 시나리오에 따른 이벤트 정보를 알려주는 것인 인공지능 기반의 이상음원인식 장치."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 이상음원 시나리오는,복수의 이상음원이 인식될 때 개별 이상음원의 발생 순서에 대응되어 특정 이벤트 발생을 알려주는 것인 인공지능 기반의 이상음원 인식 장치."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 이상음원용 모델은,컨볼루션 신경망(Convolutional Neural Network) 기반의 모델인 인공지능 기반의 이상음원 인식 장치."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 음원특징 추출부는,상기 음원신호를 주파수영역으로 나타내는 스펙트럼(spectrum)으로 구한 후, 상기 스펙트럼에 멜 스케일(melscale)에 기반한 필터뱅크(filter bank)를 적용하여 멜 스펙트럼(mel spectrum)을 도출하고, 상기 멜 스펙트럼에 대한 캡스트럼(cepstrum) 분석을 통해 로그 멜 스펙트로그램(log mel spectrogram) 기반의 음원 특징을 추출하는 로그 멜 스펙트로그램(log mel spectrogram) 기반의 추출 기법을 이용하는 것인 인공지능 기반의 이상음원인식 장치."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "(a) 임의음원 데이터셋의 데이터량을 토대로 수행된 기계학습 결과를 이용하여 이상음원을 분류하기 위한 이상음원용 모델을 생성하는 단계;(b) 외부로부터 입력된 음원신호를 시간차를 두고 인식하기 위해 음원구간을 시분할하여 추출하는 단계;(c) 상기 음원구간의 음원특징을 추출하는 단계;(d) 상기 이상음원용 모델을 이용하여 상기 음원특징을 미리 정해진 이상음원 종류별로 분류하는 단계; 및(e) 상기 음원특징의 시간차 분류결과에 따라 상기 음원신호의 이상음원 인식결과를 알려주는 단계;공개특허 10-2021-0120508-4-를 포함하는 인공지능 기반의 이상음원 인식 방법."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 (b) 단계는,상기 음원신호를 첫번째 최고점이 확인되는 제1 음원구간과, 상기 제1 음원구간에 연속하여 미리 정해진 시간동안에 확인되는 제2 음원구간으로 추출하는 것인 인공지능 기반의 이상음원 인식 방법."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 제1 음원구간은,싱기 첫번째 최고점을 기준으로 좌우 각각 1초의 구간 길이를 나타내고,상기 제2 음원구간은,상기 제1 음원구간 보다 4배의 구간 길이를 나타내는 것인 인공지능 기반의 이상음원 인식 방법."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 제2 음원구간은, 한 번 이상의 최고점이 나타나는 것인 인공지능 기반의 이상음원 인식 방법."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11 항에 있어서,상기 (e) 단계는,상기 제1 음원구간을 통해 상기 음원신호에 대해 1차 이상음원 인식결과를 알려준 다음, 상기 제2 음원구간을통해 상기 음원신호에 대해 2차 이상음원 인식결과를 알려주는 것인 인공지능 기반의 이상음원 인식 방법."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 (e) 단계는,상기 1차 이상음원 인식결과와 상기 2차 이상음원 인식결과에서 복수의 이상음원을 인식하는 경우에, 복수의 이상음원 인식결과를 종합하여 이상음원 시나리오에 따른 이벤트 정보를 알려주는 것인 인공지능 기반의 이상음원인식 방법."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 이상음원 시나리오는,복수의 이상음원이 인식될 때 개별 이상음원의 발생 순서에 대응되어 특정 이벤트 발생을 알려주는 것인 인공지공개특허 10-2021-0120508-5-능 기반의 이상음원 인식 방법."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 10 항에 있어서,상기 이상음원용 모델은,컨볼루션 신경망(Convolutional Neural Network) 기반의 모델인 인공지능 기반의 이상음원 인식 방법."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 10 항에 있어서,상기 (c) 단계는,상기 음원신호를 주파수영역으로 나타내는 스펙트럼(spectrum)으로 구한 후, 상기 스펙트럼에 멜 스케일(melscale)에 기반한 필터뱅크(filter bank)를 적용하여 멜 스펙트럼(mel spectrum)을 도출하고, 상기 멜 스펙트럼에 대한 캡스트럼(cepstrum) 분석을 통해 로그 멜 스펙트로그램(log mel spectrogram) 기반의 음원 특징을 추출하는 로그 멜 스펙트로그램(log mel spectrogram) 기반의 추출 기법을 이용하는 것인 인공지능 기반의 이상음원인식 방법."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "사건/사고 발생 가능성이 예상되는 관제구역을 모니터링하는 관제시스템에 있어서,상기 관제구역에서 발생된 음원신호로부터 이상음원을 인식하기 위한 이상음원 인식 장치; 및상기 이상음원 인식 장치로부터 전달된 이상음원 인식정보에 따라 상기 관제구역을 집중 관제하도록 제어하기위한 관제서버;를 포함하되,상기 이상음원 인식 장치는,임의음원 데이터셋의 데이터량을 토대로 수행된 기계학습 결과를 이용하여 이상음원을 분류하기 위한 이상음원용 모델을 생성하기 위한 모델 생성부;상기 음원신호를 시간차를 두고 인식하기 위해 음원구간을 시분할하여 추출하기 위한 음원구간 추출부;상기 음원구간의 음원특징을 추출하기 위한 음원특징 추출부;상기 이상음원용 모델을 이용하여 상기 음원특징을 미리 정해진 이상음원 종류별로 분류하기 위한 이상음원 분류부; 및상기 음원특징의 시간차 분류결과에 따라 상기 음원신호의 이상음원 인식결과를 알려주기 위한 이상음원인식부;를 포함하는 관제시스템."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19 항에 있어서,상기 음원구간 추출부는,상기 음원신호를 첫번째 최고점이 확인되는 제1 음원구간과, 상기 제1 음원구간에 연속하여 미리 정해진 시간동안에 확인되는 제2 음원구간으로 추출하는 것인 관제시스템.공개특허 10-2021-0120508-6-청구항 21 제 20 항에 있어서,상기 이상음원 인식부는,상기 제1 음원구간을 통해 상기 음원신호에 대해 1차 이상음원 인식결과를 알려준 다음, 상기 제2 음원구간을통해 상기 음원신호에 대해 2차 이상음원 인식결과를 알려주는 것인 관제시스템."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 21 항에 있어서,상기 이상음원 인식부는,상기 1차 이상음원 인식결과와 상기 2차 이상음원 인식결과에서 복수의 이상음원을 인식하는 경우에, 복수의 이상음원 인식결과를 종합하여 이상음원 시나리오에 따른 이벤트 정보를 알려주는 것인 관제시스템."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 22 항에 있어서,상기 이상음원 시나리오는,복수의 이상음원이 인식될 때 개별 이상음원의 발생 순서에 대응되어 특정 이벤트 발생을 알려주는 것인 관제시스템."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제 19 항에 있어서,상기 이상음원 인식정보는,상기 관제구역의 위치정보와 상기 이상음원이 발생되는 방향정보가 포함되는 것인 관제시스템."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제 24 항에 있어서,상기 방향정보는,상기 관제구역에 설치된 음원감지기에 의해 탐지되는 것인 관제시스템."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제 25 항에 있어서,상기 관제서버는,상기 관제구역에 설치된 CCTV의 카메라 방향을 상기 방향정보에 따라 제어하는 것인 관제시스템."}
{"patent_id": "10-2020-0037299", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제 26 항에 있어서,공개특허 10-2021-0120508-7-상기 관제서버에 의해 제어되는 상기 CCTV의 촬영영상을 실시간으로 재생하기 위한 관제단말기;를 더 포함하는 관제시스템."}
{"patent_id": "10-2020-0037299", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반의 이상음원 인식 장치, 그 방법 및 이를 이용한 관제시스템에 관한 것으로, 본 발명의 실시예에 따른 인공지능 기반의 이상음원 인식 장치는, 임의음원 데이터셋의 데이터량을 토대로 수행된 기계학습 결과를 이용하여 이상음원을 분류하기 위한 이상음원용 모델을 생성하기 위한 모델 생성부; 외부로부터 입력된 음원신호를 시간차를 두고 인식하기 위해 음원구간을 시분할하여 추출하기 위한 음원구간 추출부; 상기 음원구간 의 음원특징을 추출하기 위한 음원특징 추출부; 상기 이상음원용 모델을 이용하여 상기 음원특징을 미리 정해진 이상음원 종류별로 분류하기 위한 이상음원 분류부; 및 상기 음원특징의 시간차 분류결과에 따라 상기 음원신호 의 이상음원 인식결과를 알려주기 위한 이상음원 인식부;를 포함한다."}
{"patent_id": "10-2020-0037299", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반의 이상음원 인식 장치, 그 방법 및 이를 이용한 관제시스템에 관한 것으로서, 보다 상 세하게는 임의의 음원신호에 대해 음원구간을 시분할하여 추출한 후 인공지능 기반으로 하여 음원구간에 대해 이상음원을 추출 및 분류함으로써 정확하게 이상음원을 인식하기 위한, 인공지능 기반의 이상음원 인식 장치, 그 방법 및 이를 이용한 관제시스템에 관한 것이다."}
{"patent_id": "10-2020-0037299", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 규칙 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 이러한 인공지능 시스템은 사용할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 규칙 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학습 알고리즘을 활용하는 기술 로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 최근에는 인공지능 기술이 발달함에 따라 다양한 기술이 쏟아져 나오고 있다. 특히, 음성과 음향 등의 오디오 데이터 인식과 관련된 분야는 오디오 데이터로부터 비정상 상황을 인식하는 연구들이 활발하게 진행되고 있다. 이는 감시 카메라로 촬영된 영상 데이터를 통해 비정상 상황 인식하는 방법의 한계를 벗어나서 오디오 데이터에 서 이상음원을 감지하여 감시자에게 알려줌으로써 보다 효과적으로 해당 상황에 따른 조치를 취하는 방안일 수 있다. 한편, 기존에는 SVM(Support Vector Machine)을 이용하여 이상음원을 분류하였다. 이 경우에는 관측되지 않은 영역을 포함하여 결정 경계면을 생성할 수 있기 때문에 새로운 오디오 데이터에 대한 오분류 가능성이 높다는 한계가 있다. 더욱이, 이상음원을 분류하기 위해서는 학습 데이터량이 제한적이므로 이상음원을 빠르고 정확하게 분류하기 위 한 모델을 생성하기 위한 방안이 마련될 필요가 있고, 이상음원의 음향 특성을 고려한 모델을 구성하여 필요없 는 구간을 분석함에 따라 발생할 수 있는 오분류 가능성을 줄일 필요가 있다. 따라서, 이상음원을 분류하기 위해서는 인공지능 기반으로 하여 이상음원을 추출 및 분류하여 정확하게 이상음 원을 인식할 수 있는 방안을 구현할 필요가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록특허공보 제10-1718073호 (2017.03.14 등록)"}
{"patent_id": "10-2020-0037299", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 임의의 음원신호에 대해 음원구간을 시분할하여 추출한 후 인공지능 기반으로 하여 음원구간 에 대해 이상음원을 추출 및 분류함으로써 정확하게 이상음원을 인식하기 위한, 인공지능 기반의 이상음원 인식 장치, 그 방법 및 이를 이용한 관제시스템을 제공하는데 있다."}
{"patent_id": "10-2020-0037299", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 인공지능 기반의 이상음원 인식 장치는, 임의음원 데이터셋의 데이터량을 토대로 수행 된 기계학습 결과를 이용하여 이상음원을 분류하기 위한 이상음원용 모델을 생성하기 위한 모델 생성부; 외부로 부터 입력된 음원신호를 시간차를 두고 인식하기 위해 음원구간을 시분할하여 추출하기 위한 음원구간 추출부; 상기 음원구간의 음원특징을 추출하기 위한 음원특징 추출부; 상기 이상음원용 모델을 이용하여 상기 음원특징 을 미리 정해진 이상음원 종류별로 분류하기 위한 이상음원 분류부; 및 상기 음원특징의 시간차 분류결과에 따 라 상기 음원신호의 이상음원 인식결과를 알려주기기 위한 이상음원 인식부;를 포함할 수 있다. 상기 음원구간 추출부는, 상기 음원신호를 첫번째 최고점이 확인되는 제1 음원구간과, 상기 제1 음원구간에 연 속하여 미리 정해진 시간 동안에 확인되는 제2 음원구간으로 추출하는 것일 수 있다. 상기 제1 음원구간은, 싱기 첫번째 최고점을 기준으로 좌우 각각 1초의 구간 길이를 나타내고, 상기 제2 음원구 간은, 상기 제1 음원구간 보다 4배의 구간 길이를 나타내는 것일 수 있다. 상기 제2 음원구간은, 한 번 이상의 최고점이 나타나는 것일 수 있다. 상기 이상음원 인식부는, 상기 제1 음원구간을 통해 상기 음원신호에 대해 1차 이상음원 인식결과를 알려준 다 음, 상기 제2 음원구간을 통해 상기 음원신호에 대해 2차 이상음원 인식결과를 알려주는 것일 수 있다. 상기 이상음원 인식부는, 상기 1차 이상음원 인식결과와 상기 2차 이상음원 인식결과에서 복수의 이상음원을 인 식하는 경우에, 복수의 이상음원 인식결과를 종합하여 이상음원 시나리오에 따른 이벤트 정보를 알려주는 것일 수 있다. 상기 이상음원 시나리오는, 복수의 이상음원이 인식될 때 개별 이상음원의 발생 순서에 대응되어 특정 이벤트 발생을 알려주는 것일 수 있다. 상기 이상음원용 모델은, 컨볼루션 신경망(Convolutional Neural Network) 기반의 모델일 수 있다. 상기 음원특징 추출부는, 상기 음원신호를 주파수영역으로 나타내는 스펙트럼(spectrum)으로 구한 후, 상기 스 펙트럼에 멜 스케일(mel scale)에 기반한 필터뱅크(filter bank)를 적용하여 멜 스펙트럼(mel spectrum)을 도 출하고, 상기 멜 스펙트럼에 대한 캡스트럼(cepstrum) 분석을 통해 로그 멜 스펙트로그램(log mel spectrogram) 기반의 음원 특징을 추출하는 로그 멜 스펙트로그램(log mel spectrogram) 기반의 추출 기법을 이용하는 것일 수 있다. 또한, 본 발명의 실시예에 따른 (a) 임의음원 데이터셋의 데이터량을 토대로 수행된 기계학습 결과를 이용하여 이상음원을 분류하기 위한 이상음원용 모델을 생성하는 단계; (b) 외부로부터 입력된 음원신호를 시간차를 두고 인식하기 위해 음원구간을 시분할하여 추출하는 단계; (c) 상기 음원구간의 음원특징을 추출하는 단계; (d) 상 기 이상음원용 모델을 이용하여 상기 음원특징을 미리 정해진 이상음원 종류별로 분류하는 단계; 및 (e) 상기 음원특징의 시간차 분류결과에 따라 상기 음원신호의 이상음원 인식결과를 알려주는 단계;를 포함할 수 있다. 상기 (b) 단계는, 상기 음원신호를 첫번째 최고점이 확인되는 제1 음원구간과, 상기 제1 음원구간에 연속하여 미리 정해진 시간 동안에 확인되는 제2 음원구간으로 추출하는 것일 수 있다. 상기 (e) 단계는, 상기 제1 음원구간을 통해 상기 음원신호에 대해 1차 이상음원 인식결과를 알려준 다음, 상기 제2 음원구간을 통해 상기 음원신호에 대해 2차 이상음원 인식결과를 알려주는 것일 수 있다. 상기 (e) 단계는, 상기 1차 이상음원 인식결과와 상기 2차 이상음원 인식결과에서 복수의 이상음원을 인식하는 경우에, 복수의 이상음원 인식결과를 종합하여 이상음원 시나리오에 따른 이벤트 정보를 알려주는 것일 수 있다. 상기 (c) 단계는, 상기 음원신호를 주파수영역으로 나타내는 스펙트럼(spectrum)으로 구한 후, 상기 스펙트럼에 멜 스케일(mel scale)에 기반한 필터뱅크(filter bank)를 적용하여 멜 스펙트럼(mel spectrum)을 도출하고, 상기 멜 스펙트럼에 대한 캡스트럼(cepstrum) 분석을 통해 로그 멜 스펙트로그램(log mel spectrogram) 기반의 음 원 특징을 추출하는 로그 멜 스펙트로그램(log mel spectrogram) 기반의 추출 기법을 이용하는 것일 수 있다. 또한, 본 발명의 실시예에 따른 관제시스템은, 사건/사고 발생 가능성이 예상되는 관제구역을 모니터링하는 관 제시스템에 있어서, 상기 관제구역에서 발생된 음원신호로부터 이상음원을 인식하기 위한 이상음원 인식 장치; 및 상기 이상음원 인식 장치로부터 전달된 이상음원 인식정보에 따라 상기 관제구역을 집중 관제하도록 제어하 기 위한 관제서버;를 포함하되, 상기 이상음원 인식 장치는, 임의음원 데이터셋의 데이터량을 토대로 수행된 기 계학습 결과를 이용하여 이상음원을 분류하기 위한 이상음원용 모델을 생성하기 위한 모델 생성부; 상기 음원신 호를 시간차를 두고 인식하기 위해 음원구간을 시분할하여 추출하기 위한 음원구간 추출부; 상기 음원구간의 음 원특징을 추출하기 위한 음원특징 추출부; 상기 이상음원용 모델을 이용하여 상기 음원특징을 미리 정해진 이상 음원 종류별로 분류하기 위한 이상음원 분류부; 및 상기 음원특징의 시간차 분류결과에 따라 상기 음원신호의 이상음원 인식결과를 알려주기 위한 이상음원 인식부;를 포함할 수 있다. 상기 이상음원 인식정보는, 상기 관제구역의 위치정보와 상기 이상음원이 발생되는 방향정보가 포함되는 것일 수 있다. 상기 방향정보는, 상기 관제구역에 설치된 음원감지기에 의해 탐지되는 것일 수 있다. 상기 관제서버는, 상기 관제구역에 설치된 CCTV의 카메라 방향을 상기 방향정보에 따라 제어하는 것일 수 있다. 실시예에 따르면, 상기 관제서버에 의해 제어되는 상기 CCTV의 촬영영상을 실시간으로 재생하기 위한 관제단말 기;를 더 포함할 수 있다."}
{"patent_id": "10-2020-0037299", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 임의의 음원신호에 대해 음원구간을 시분할하여 추출한 후 인공지능 기반으로 하여 음원구간에 대해 이상음원을 추출 및 분류함으로써 정확하게 이상음원을 인식할 수 있다. 또한, 본 발명은 이상음원 데이터셋의 데이터량이 제한적이더라도 기계학습을 빠르게 하고 이상음원 분류 결과 의 정확도를 더욱 높여줄 수 있다. 또한, 본 발명은 이상음원의 음향 특성과 사람이 소리를 인식하는 심리음향 특성을 반영하여 이상음원을 분류하 기 위한 모델을 구성할 수 있다. 또한, 본 발명은 CCTV의 사각지대를 최소화하고 능동적으로 CCTV를 운영할 수 있다."}
{"patent_id": "10-2020-0037299", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 본 발명의 바람직한 실시 예를 첨부한 도면을 참조하여 상세히 설명한다. 다만, 하기의 설명 및 첨부된 도 면에서 본 발명의 요지를 흐릴 수 있는 공지 기능 또는 구성에 대한 상세한 설명은 생략한다. 또한, 도면 전체 에 걸쳐 동일한 구성 요소들은 가능한 한 동일한 도면 부호로 나타내고 있음에 유의하여야 한다.이하에서 설명되는 본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정해서 해 석되어서는 아니 되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위한 용어로 적절하게 정의 할 수 있다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시 예와 도면에 도시된 구성은 본 발명의 가장 바람직한 일 실시 예에 불과할 뿐 이고, 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원시점에 있어서 이들을 대체할 수 있는 다 양한 균등물과 변형 예들이 있을 수 있음을 이해하여야 한다. 첨부 도면에 있어서 일부 구성요소는 과장되거나 생략되거나 또는 개략적으로 도시되었으며, 각 구성요소의 크 기는 실제 크기를 전적으로 반영하는 것이 아니다. 본 발명은 첨부한 도면에 그려진 상대적인 크기나 간격에 의 해 제한되어지지 않는다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 어떤 부분이 다른 부 분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이 에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. \"포함하다\" 또는 \"가지다\" 등 의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정 하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 또한, 명세서에서 사용되는 \"부\"라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소를 의미하며, \"부\"는 어떤 역할들을 수행한다. 그렇지만 \"부\"는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니 다. \"부\"는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생 시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\"는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소 들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 \"부\"들 안에서 제공되는 기능은 더 작 은 수의 구성요소들 및 \"부\"들로 결합되거나 추가적인 구성요소들과 \"부\"들로 더 분리될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예를 설명한다. 도 1은 본 발명의 실시예에 따른 인공지능 기반의 이상음원 인식 장치를 나타낸 도면이고, 도 2는 도 1의 CNN 모델 생성부를 나타낸 도면이며, 도 3은 이상음원 파형을 나타낸 도면이고, 도 4는 도 3의 이상음원을 확장한 음원구간의 추출을 설명하는 도면이며, 도 5는 전체 음원구간을 분석하는 경우와 제1 및 제2 음원구간을 분할하 여 분석하는 경우에 대한 비교 결과를 설명하는 도면이다. 도 1에 도시된 바와 같이, 본 발명의 실시예에 따른 인공지능 기반의 이상음원 인식 장치(이하 '이상음원 인식 장치'라 함, 100)는, 임의의 음원신호에 대해 음원구간을 시분할하여 추출한 후 인공지능 기반으로 하여 음원구 간에 대해 이상음원을 추출 및 분류함으로써 정확하게 이상음원을 인식할 수 있다. 여기서, 이상음원(abnormaly sound)이라 함은, 특정 위험 상황에서 발생하여 단어로 표현되지 않으나 특정 위험 상황을 직관적으로 알려줄 수 있는 비정형적 음원으로서, 예를 들어, 비명소리, 유리창 파손음, 차량경적소리, 차량급정거소리, 차량사고소리, 폭발소리, 총소리 등의 종류로 구분할 수 있다. 이러한 이상음원의 음향 특성은 일정 데시벨(db) 이상으로 소리크기가 크고 소리구간이 짧은 특징을 나타낸다. 즉, 이상음원은 음향학적 신호를 의미를 갖는 단어나 문장으로 인식되지 않고 특정 위험 상황을 나타낸다. 이러 한 이상음원은 음원 구간에 대해 라벨되어 있는 데이터셋이 아닌 파일 단위에서 음원 구간의 유무로만 라벨링되 는 약한 라벨(weak label) 음원에 해당한다. 또한, 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성되고, 구체적으로 이상음원 을 분류하기 위한 딥러닝 모델로서 컨볼루션 신경망(Convolutional Neural Network, 이하 'CNN'이라 함) 모델 을 적용하는 경우에 대하여 설명하기로 한다. 한편, 이상음원 인식 장치는 CNN 모델 생성부, 음원구간 추출부, 음원특징 추출부, 이상음 원 분류부, 이상음원 인식부, 음원구간 저장부를 포함하여 구성할 수 있다. 먼저, CNN 모델 생성부는 이상음원을 분류하기 위한 CNN 모델을 생성한다. 이 경우, CNN 모델 생성부는 이상음원 데이터셋에 대해 기계학습을 수행하여 CNN 모델을 생성하기 위한 데 이터량이 제한적이기 때문에 이상음원 데이터셋을 이용하여 곧바로 이상음원을 분류하기 위한 CNN 모델을 생성 하지 않는다. 즉, CNN 모델 생성부는 우선 다양한 종류의 음원이 약하게 라벨링이 되어 있는 임의음원 데이터셋의 충분 한 학습 데이터량을 토대로 기계학습을 수행하여 CNN 모델을 생성한 이후, 이를 이용하여 이상음원을 분류하기 위한 CNN 모델을 생성한다. 여기서는 설명의 편의상 이상음원을 분류하기 위한 CNN 모델을 이하 '이상음원용 CNN 모델'이라 하고, 임의음원 을 분류하기 위한 CNN 모델을 이하 '임의음원용 CNN 모델'이라 한다. 이와 같이, CNN 모델 생성부는 미리 만들어진 임의음원용 CNN 모델을 사용하여 이상음원용 CNN 모델을 만 들시 이상음원 데이터셋의 데이터량이 제한적이더라도 기계학습을 빠르게 하고 이상음원 분류 결과의 정확도를 더욱 높여줄 수 있다. 여기서, 임의음원용 CNN 모델은 임의음원의 분류 정확도가 일반적으로 요구되는 수준에 이르지 않더라도 충분한 학습 데이터량을 확보하여 만들어진 모델이라면 사용할 수 있다. 이는 이상음원 데이터셋이 모델 생성을 위해 충분한 학습 데이터량을 확보하기 어렵기 때문에 이를 보완하는 방안으로 임의음원용 CNN 모델을 이용하여 이상 음원용 CNN 모델을 생성하기 위함이다. 구체적으로, CNN 모델 생성부는 임의음원용 CNN 모델을 다음과 같이 생성한다. 즉, CNN 모델 생성부는 임의음원 데이터셋의 각 음원신호를 프레임별로 나누어 단시간 푸리에 변환(Short- Time Fourier Transformer, STFT)을 적용하여 각 음원신호를 시간영역(time domain) 대신 주파수영역 (frequency domain)으로 나타내는 스펙트럼(spectrum)을 구한다. 그리고, CNN 모델 생성부는 고주파수(high frequency) 보다 저주파수(low frequency) 대역에서 더욱 민감 하게 나타나는 사람의 청각기관의 특성을 반영하기 위해, 물리적인 주파수와 실제 사람이 인식하는 주파수의 관 계를 나타내는 멜 스케일(mel scale)에 기반한 필터뱅크(filter bank)를 스펙트럼에 적용해 멜 스펙트럼(mel spectrum)을 도출한다. 그런 다음, CNN 모델 생성부는 사람의 청각기관의 특성을 반영하여 얻은 멜 스펙트럼에 로그(log)와 역푸 리에변환(inverse fourier transformer)을 통해 캡스트럼(cepstrum) 분석을 수행한다. 이를 통해, CNN 모델 생성부는 임의음원 데이터셋의 각 음원신호에 대한 로그 멜 스펙트로그램(log mel spectrogram)으로 임의음원 특징을 추출한다(S1). 이는 CNN 모델을 활용하여 각 음원신호를 분류하기 위해 음원 신호를 이미지 형태로 변환하는 신호처리 과정이다. 또한, CNN 모델 생성부는 임의음원 특징에 대한 CNN 기반의 기계학습을 수행하여 임의음원용 CNN 모델을 생성한다(S2, S3). 이때, CNN 모델 생성부는 합성곱 계층(Convolutional Layer)에서 연산을 위한 가중치 (weight)와 바이어스(bias)를 결정하여 분류 특징을 추출하고, 풀링 계층(pooling layer)에서 맥스 풀링(max- pooling)을 사용하여 분류 특징에 대해 미리 정해진 이상음원 종류별로 분류할 수 있다. 한편, CNN 모델 생성부는 이상음원용 CNN 모델을 다음과 같이 생성한다. 이 경우, CNN 모델 생성부는 이미 사전에 기계학습이 완료된 임의음원용 CNN 모델을 가지고 이상음원을 분 류하려는 기계학습에 미세 조정을 수행하여 학습시켜 이상음원용 CNN 모델을 생성하게 된다. 즉, CNN 모델 생성부는 임의음원용 CNN 모델의 합성곱 계층에서 연산을 위한 가중치와 바이어스를 이상음 원에 맞게 미세 조정하여 이상음원용 CNN 모델을 생성한다. 이때, CNN 모델 생성부는 임의음원용 CNN 모델 에서 마지막 완전 연결층(fully connected layer)에 대해서만 미세 조정을 수행할 수 있다. 도 2를 참조하면, CNN 모델 생성부는 임의음원 데이터셋에서 임의음원 특징을 추출하는 바와 같이, 이상음 원 데이터셋의 각 음원신호에 대한 로그 멜 스펙트로그램(log mel spectrogram)으로 이상음원 특징을 추출한다 (S11). 그리고, CNN 모델 생성부는 임의음원용 CNN 모델에서 이상음원 특징을 재학습시켜 이상음원에 맞게 미세 조정을 통한 이상음원용 CNN 모델을 생성한다(S12, S13). 즉, CNN 모델 생성부는 임의음원용 CNN 모델을 이상음원용 CNN 모델로 재튜닝함으로써 이상음원에 대한 분류 특징을 추출하고, 분류 특징을 토대로 미리 정해 진 이상음원 종류별로 분류하는 이상음원용 CNN 모델을 마련하게 된다. 이처럼 CNN 모델 생성부는 임의음원 데이터셋의 데이터랑을 토대로 수행된 기계학습 결과를 이용하여 이상 음원을 분류하기 위한 이상음원용 CNN 모델을 생성한다. 다음으로, 음원구간 추출부는 외부로부터 임의의 음원신호가 입력되면, 해당 음원신호에서 이상음원의 음 향 특성과 사람이 소리를 인식하는 심리음향 특성을 반영하는 음원구간을 추출한다. 이때, 음원구간 추출부는 외부로부터 입력된 음원신호를 시간차를 두고 인식하기 위해 시분할하여 추출한 다. 여기서, 이상음원의 음향 특성은 전술한 바와 같이 일정 데시벨(db) 이상으로 소리의 크기가 크고 구간이 짧은 특징을 나타낸다. 즉, 이상음원은 도 3을 참조하면 음원구간의 최고점(peak audio)을 형성하는 모양을 나타낸다. 사람이 소리를 인식하는 심리음향 특성은 사람의 반사신경과 소리에 대한 민감도 또는 학습 여부에 따라 달라질 수 있으나 사람이 소리를 인식하는데 필요한 소리의 길이가 평균 2초 정도를 나타낸다. 이에 따라, 음원구간 추출부는 임의의 음원신호에서 음원구간의 최고점을 기준으로 미리 정해진 선/후 구 간을 음원구간으로 추출한다. 이러한 음원구간은 도 3과 같이 심리음향 특성에 따라 시간 영역에서 최고점을 기 준으로 선/후 구간 각각 1초씩 전체 2초의 구간으로 추출될 수 있다. 그런데, 전체 2초의 음원구간은 분석결과가 100% 정확하지 않을 수도 있다. 그래서, 음원구간 추출부는 2 초의 음원구간에 대해 선 인식 과정을 실시한 후, 해당 이상음원의 전후상황을 판단 가능한 정도의 길이로 연속 하여 이어진 8초의 음원구간에 대해 후 인식 과정을 실시한다. 여기서, 도 4와 같이 선 인식 과정을 실시하는 음원구간으로서, 가장 먼저 나타나는 첫번째 최고점이 확인되는 구간을 이하 '제1 음원구간'으로 통칭하고, 후 인식 과정을 실시하는 음원구간으로서, 제1 음원구간에 연속하여 미리 정해진 시간 동안에 확인되는 구간을 이하 '제2 음원구간'으로 통칭하기로 한다. 제1 음원구간은 첫번째 최고점 기준으로 좌우 1초의 구간인 총 2초의 구간 길이를 나타내고, 제2 음원구간은 제 1 음원구간에 연속하여 미리 정해진 시간인 총 8초의 구간 길이로 나타낼 수 있다. 제1 음원구간 및 제2 음원구 간은 소리의 특성에 따라 구간 길이를 변경할 수 있다. 그리고, 제1 음원구간은 하나의 최고점(첫번째 최고점, W1)이 나타나지만, 제2 음원구간은 한 번 이상의 최고점 (두번째 최고점 W2, 세번째 최고점 W3)이 나타날 수 있다. 이때, 제2 음원구간은 제1 음원구간 보다 4배의 구간 길이를 나타낼 수 있다. 이와 같이, 제2 음원구간은 적어도 하나 이상의 이상음원을 포함하는 경우에, 복수의 이상음원이 인식될 때 개 별 이상음원의 발생 순서에 대응되어 특정 이벤트 발생을 알려주는 시나리오(이하 '이상음원 시나리오'라 함)를 나타낼 수 있다. 예를 들어, 이상음원 시나리오는 이상음원1이 '경적소리', 이상음원2가 '차량 급정지음', 이상음원3이 '차량 충 돌음'이라 할 때, 이상음원1-이상음원2-이상음원3의 발생 순서에 대응되는 '차량 교통 사고 발생'이라는 특정 이벤트를 의미할 수 있다. 이와 같이 이상음원 시나리오는 다양한 케이스를 고려하여 미리 정하여 음원구간 저 장부에 미리 저장할 수 있다. 여기서, 복수 개의 이상음원이 인식되는 경우라 함은 제2 음원구간에서 복수 개의 이상음원이 인식되는 경우와 제1 및 제2 음원구간에서 복수 개의 이상음원이 인식되는 경우가 해당한다. 한편, 이상음원은 전술한 바와 같이 특정 위험 상황을 직관적으로 알려줄 수 있는 음원에 해당하므로, 신속하고 누락 없이 인식되는 것이 중요하다. 그런데 도 5를 참조하면, 전체 음원구간을 한번에 인식하는 경우는 제1 및 제2 음원구간을 시분할하여 인식하는 경우와 마찬가지로 이상음원을 누락없이 인식하는 것이 가능할지라도, 제1 및 제2 음원구간을 시분할하여 인식 하는 경우에 비해 이상음원을 신속하게 인식하기 곤란할 수 있다. 즉, 전체 음원구간을 한번에 인식하는 경우는 전체 음원구간을 모두 추출한 후에 비로서 전체 음원구간에 대해 인식을 실시하여 이상음원 발생을 알려줄 수 있다. 반면에, 제1 및 제2 음원구간을 시분할하여 인식하는 경우는 제1 음원구간을 추출한 후에 곧바로 제1 음원구간 에 대해 선 인식 과정을 실시하여 외부로부터 입력된 음원신호에 대해 1차로 이상음원 발생을 신속하게 알려줄 수 있을 뿐만 아니라, 제1 음원구간과 별개로 전체 음원구간 보다 짧은 제2 음원구간에 대해 후 인식 과정을 실 시하여 음원신호에 대해 2차로 이상음원 발생을 정확하게 알려줄 수 있다. 물론, 제2 음원구간에 대해 후 인식 과정을 실시하는 경우에는 제1 음원구간에 대한 인식 과정이 제외되므로 인식 시간이 짧아지게 된다. 도 5와 같이 시간축상에서 임의의 음원신호에 대한 이상음원 인식에 있어서, 전체 음원구간을 한번에 인식하는 경우와 제1 및 제2 음원구간을 시분할하여 인식하는 경우는 이상음원의 인식 속도에 있어서 서로 상이한 것을 쉽게 이해할 수 있다. 이러한 차이는 제1 및 제2 음원구간의 길이가 길어질수록 더욱 분명하게 나타날 수 있다. 다시 도 1을 참조하면, 음원구간 추출부는 제1 음원구간과 제2 음원구간을 추출하되, 제1 음원구간에 대해 선 인식 과정을 실시하기 위해 음원특징 추출부로 전달하고(①), 제2 음원구간에 대해 후 인식 과정을 실 시하기 위해 음원구간 저장부에 저장한다(ⓐ). 즉, 음원구간 추출부는 제1 음원구간을 추출하여 음원특징 추출부로 전달하면서, 제2 음원구간을 미 리 정해진 구간 길이 만큼 추출 및 녹음하여 음원구간 저장부에 저장한다. 다음으로, 음원특징 추출부는 음원구간 추출부에 의해 추출된 임의의 음원신호의 제1 음원구간에 대 한 로그 멜 스펙트로그램 기반의 음원 특징을 추출한다(②). 이에 대한 자세한 설명은 앞서 언급한 바와 동일하 므로 생략하기로 한다. 마찬가지로, 음원특징 추출부는 음원구간 저장부에 저장된 제2 음원구간에 대한 로그 멜 스펙트로그 램 기반의 음원 특징을 추출한다(ⓑ, ⓓ). 이때, 음원특징 추출부는 이상음원 분류부 간 요청이 있는 경우에 음원구간 저장부로부터 제2 음원구간을 전달받는다(ⓒ). 다음으로, 이상음원 분류부는 CNN 모델 생성부에 의해 생성된 이상음원용 CNN 모델을 기반으로 하여 음원특징 추출부에 의해 추출된 제1 음원구간의 음원 특징에 대해 분류 특징을 추출하고, 이러한 분류 특 징에 대해 미리 정해진 이상음원 종류별로 분류한다(③). 마찬가지로, 이상음원 분류부는 CNN 모델 생성부에 의해 생성된 이상음원용 CNN 모델을 기반으로 하 여 음원특징 추출부에 의해 추출된 제2 음원구간의 음원 특징에 대해 분류 특징을 추출하고, 이러한 분류 특징에 대해 미리 정해진 이상음원 종류별로 분류한다(ⓔ). 이와 같이, 이상음원 분류부는 이상음원용 CNN 모델의 합성곱 계층에서 제1 음원구간 또는 제2 음원구간의 음원 특징에 대한 분류 특징을 추출하고, 풀링 계층에서 분류에 대한 특징점을 간소화(sub-sampling)시키며, 최 종 완전 연결층을 통하여 분류 특징에 대해 미리 정해진 이상음원 종류별로 분류한다. 다음으로, 이상음원 인식부는 제1 음원구간과 제2 음원구간 각각에 대한 분류결과를 이용하여 임의의 음원 신호에서 이상음원 인식결과를 알려준다. 구체적으로, 이상음원 인식부는 제1 음원구간과 제2 음원구간에서 하나의 이상음원을 인식하는 경우에, 하 나의 이상음원 인식결과로서 이상음원 분류결과를 알려준다. 또한, 이상음원 인식부는 제1 음원구간과 제2 음원구간에서 복수의 이상음원을 인식하는 경우에, 복수의 이상음원 인식결과 각각에 대해 개별로 이상음원 분류결과를 알려주거나, 복수의 이상음원 인식결과를 종합하여 이상음원 시나리오에 따른 이벤트(예, 교통사고 이벤트 등) 정보를 알려줄 수 있다. 여기서, 이상음원 인식부는 제1 음원구간에서만 이상음원을 인식하는 경우를 제외하고, 제2 음원구간에서 이상음원을 인식하는 경우 또는 제1 및 제2 음원구간에서 이상음원을 인식하는 경우에 이상음원 시나리오에 따 른 이벤트 정보를 알려주는 경우가 발생할 수 있다. 한편, 이상음원 인식 장치는 임의의 음원신호를 입력받고, 임의의 음원신호에 대한 분류결과에 따라 이상 음원 인식결과를 출력하기 위한 인터페이스부(미도시)를 더 포함할 수 있다. 예를 들어, 인터페이스부는 임의의음원신호를 입력받기 위해 마이크로폰(microphone) 등을 구비하고, 임의의 음원신호에 대한 분류결과에 따라 이 상음원 인식결과를 출력하기 위해 디스플레이 장치(display device)나 스피커(speaker) 등을 구비할 수 있다. 아울러, 이상음원 인식 장치는 적어도 하나 이상의 프로세서(processor)와 컴퓨터 판독 가능한 명령들을 저장하기 위한 메모리(memory)를 포함한다. 적어도 하나 이상의 프로세서는 메모리에 저장된 컴퓨터 판독 가능한 명령들을 실행할 때, 본 발명의 실시예에 따른 인공지능 기반의 이상음원 인식 방법을 수행하게 된다. 즉, 프로세서는 메모리에 저장된 컴퓨터 판독 가능한 명령들을 실행할 때, 이상음원 인식 장치에 포함된 CNN 모델 생성부, 음원구간 추출부, 음원특징 추출부, 이상음원 분류부, 이상음원 인식부 의 기능을 수행할 수 있게 된다. 여기서, 프로세서는 적어도 하나 이상의 프로세서로서, 컨트롤러(controller), 마이크로 컨트롤러 (microcontroller), 마이크로 프로세서(microprocessor), 마이크로 컴퓨터(microcomputer) 등으로도 호칭될 수 있다. 그리고, 프로세서는 하드웨어(hardware) 또는 펌웨어(firmware), 소프트웨어, 또는 이들의 결합에 의해 구현될 수 있다. 또한, 메모리는 하나의 저장 장치일 수 있거나, 또는 복수의 저장 엘리먼트의 집합적인 용어일 수 있다. 메모리 에 저장된 컴퓨터 판독 가능한 명령들은 실행가능한 프로그램 코드 또는 파라미터, 데이터 등일 수 있다. 그리고, 메모리는 RAM(Random Access Memory)을 포함할 수 있거나, 또는 자기 디스크 저장장치 또는 플래시 (flash) 메모리와 같은 NVRAM(Non-Volatile Memory)을 포함할 수 있다. 여기서, 메모리는 음원구간 저장부 의 기능을 수행할 수 있다. 도 6 및 도 7은 본 발명의 실시예에 따른 인공지능 기반의 이상음원 인식 방법을 나타낸 도면이다. 도 6에 도시된 바와 같이, 이상음원 인식 장치는 외부로부터 입력된 음원신호를 시간차를 두고 인식하기 위해 제1 음원구간과 제2 음원구간을 시분할하여 추출한다. 먼저, 이상음원 인식 장치는 음원신호에서 제1 음원구간을 추출한다(S201). 그리고, 이상음원 인식 장치는 제1 음원구간의 음원특징을 추출하고, 이상음원용 모델을 이용하여 음원특 징을 미리 정해진 이상음원 종류별로 분류한다(S202). 그런 다음, 이상음원 인식 장치는 제1 음원구간에서 하나의 이상음원을 인식하는지를 확인한다(S203). 이때, 이상음원 인식 장치는 제1 음원구간에서 하나의 이상음원을 인식하지 않는 경우(S203), 음원신호에 서 제2 음원구간을 추출하면(S203-1), 제2 음원구간의 음원특징을 추출하고, 이상음원용 모델을 이용하여 음원 특징을 미리 정해진 이상음원 종류별로 분류한다(S204). 이후, 이상음원 인식 장치는 제2 음원구간에서 하나 이상의 이상음원을 인식하는지를 확인한다(S205). 이때, 이상음원 인식 장치는 복수의 이상음원을 인식할 때 복수의 이상음원을 종합하여 이상음원 시나리오 에 해당하는지를 확인한다(S206). 즉, 이상음원 인식 장치는 복수의 이상음원을 구성하는 개별 이상음원의 발생 순서에 대응되는 이상음원 시나리오를 조회하여 확인할 수 있다. S206 단계에서는 제2 음원구간에서 이상 음원 인식결과만 고려하여 이상음원 시나리오에 해당하는지를 확인한다. 여기서, 이상음원 인식 장치는 이상음원 시나리오에 해당하면(S206), 이상음원 시나리오에 따른 특정 이벤 트 정보를 알려준다(S207). 이때, 이상음원 인식 장치는 제2 음원구간에서 복수의 이상음원을 인식한다. 그렇지 않으면, 이상음원 인식 장치는 개별 이상음원 인식결과를 알려준다(S208). 이때, 이상음원 인식 장 치는 제2 음원구간에서 하나의 이상음원을 인식하거나 제2 음원구간에서 복수의 이상음원을 인식하더라도 이상음원 시나리오에 해당하지 않으면, 개별 이상음원 인식결과를 알려준다. 한편, 도 6의 S203 단계에서, 이상음원 인식 장치는 제1 음원구간에서 하나의 이상음원을 인식하면(S203), 도 7에 도시된 바와 같이 후속 단계를 진행한다.도 6은 제2 음원구간에서 이상음원을 인식하는 경우를 나타내는 것이고, 도 7은 먼저 제1 음원구간에서 이상음 원을 인식하는 경우를 나타내고, 다음 제1 및 제2 음원구간에서 이상음원을 인식하는 경우를 나타내는 것이다. 도 7을 참조하면, 이상음원 인식 장치는 제1 음원구간에서 하나의 이상음원을 인식하면(S251), 하나의 이 상음원 인식결과를 알려준다(S252). 이와 같이, 이상음원 인식 장치는 제1 음원구간에 대해 선 분석을 실 시하여 제1 음원구간에 대한 이상음원 발생을 신속하게 알려줄 수 있다. 이와 동시에, 이상음원 인식 장치는 음원신호에서 제2 음원구간을 추출하면(S252), 제2 음원구간의 음원특 징을 추출하고, 이상음원용 모델을 이용하여 음원특징을 미리 정해진 이상음원 종류별로 분류한다(S253). 이후, 이상음원 인식 장치는 제2 음원구간에서 하나 이상의 이상음원을 인식하는지를 확인한다(S254). 이때, 이상음원 인식 장치는 제2 음원구간에서 하나 이상의 이상음원을 인식하면(S254), 제1 음원구간에서 이상음원 인식결과를 확인하고(S255), 제2 음원구간에서 하나 이상의 이상음원 인식결과를 종합하여 이상음원 시나리오에 해당하는지를 확인한다(S256). S256 단계에서는 제1 음원구간에서 하나의 이상음원 인식결과와 제2 음원구간에서 하나 이상의 이상음원 인식결과를 종합적으로 고려하여 이상음원 시나리오에 해당하는지를 확인한 다. 여기서, 이상음원 인식 장치는 이상음원 시나리오에 해당하면(S256), 이상음원 시나리오에 따른 특정 이벤 트 정보를 알려준다(S257). 이때, 이상음원 인식 장치는 제1 음원구간에서 하나의 이상음원 인식결과와 제 2 음원구간에서 하나 이상의 이상음원 인식결과를 토대로 구성하는 이상음원 시나리오에 따른 특정 이벤트 정보 를 알려준다. 그렇지 않으면, 이상음원 인식 장치는 개별 이상음원 인식결과를 알려준다(S258). 이때, 이상음원 인식 장 치는 제2 음원구간에서 하나의 이상음원을 인식하거나 제2 음원구간에서 복수의 이상음원을 인식하더라도 이상음원 시나리오에 해당하지 않으면, 개별 이상음원 인식결과를 알려준다. S258 단계에서는 제1 음원구간에서 이상음원 인식결과를 다시 알려주지는 않는다. 도 8은 본 발명의 실시예에 따른 인공지능 기반의 이상음원 인식 장치를 이용한 관제시스템을 나타낸 도면이다. 도 8을 참조하면, 관제시스템은 이상음원 인식 장치, 관제서버 및 관제단말기를 포함한다. 이러한 관제시스템은 사건/사고 발생 가능성이 예상되는 다수 개의 관제구역(즉, 제1 관제구역 내지 제N 관제구 역)을 모니터링한다. 그리고, 다수 개의 관제구역 각각에는 CCTV(10-1 내지 10-N)와 음원감지기(20-1 내지 20- N)가 설치되어 있다. 이때, 음원감지기(20-1 내지 20-N)는 음원이 발생되는 방향 탐지가 가능하며, 이에 대한 자세한 설명은 통상의 기술자라면 쉽게 이해할 수 있는 것이므로 생략하기로 한다. 한편, 이상음원 인식 장치는 음원감지기(20-1 내지 20-N)와 연결되어 있고, 음원감지기(20-1 내지 20-N)에 의해 수집된 음원신호를 입력받아 이상음원을 추출 및 분류함으로써 이상음원을 인식한다. 이에 대한 자세한 설 명은 전술한 도 1 내지 도 3에 대한 설명을 통해 이해 가능하므로 생략하기로 한다. 이때, 이상음원 인식 장치는 특정 관제구역의 이상음원 분류결과를 관제서버로 전달한다. 이때, 이상 음원 인식 장치는 특정 관제구역의 이상음원 인식결과를 알려주는 것과 동시에, 특정 관제구역의 위치정보 와 음원감지기(20-1 내지 20-N)에 의해 탐지된 음원이 발생되는 방향정보를 관제서버로 함께 전달한다. 그러면, 관제서버는 이상음원 인식 장치로부터 전달된 특정 관제구역의 위치정보와 음원 방향정보를 이용하여 특정 관제구역에 설치된 해당 CCTV의 카메라 방향을 이상음원이 발생한 위치로 향하여 집중 관제하도 록 제어할 수 있다. 이때, CCTV는 PTZ(Pan/Tilt/Zoom) 제어된다. 또한 관제단말기는 관제서버에 의해 제어되는 CCTV의 촬영영상을 실시간으로 재생하여 관리자가 확인 할 수 있게 한다. 이와 같이, 관제시스템은 CCTV의 사각지대를 최소화하고 능동적으로 CCTV를 운영할 수 있게 된다. 일부 실시 예에 의한 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨 터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CDROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 비록 상기 설명이 다양한 실시예들에 적용되는 본 발명의 신규한 특징들에 초점을 맞추어 설명되었지만, 본 기 술 분야에 숙달된 기술을 가진 사람은 본 발명의 범위를 벗어나지 않으면서도 상기 설명된 장치 및 방법의 형태 및 세부 사항에서 다양한 삭제, 대체, 및 변경이 가능함을 이해할 것이다. 따라서, 본 발명의 범위는 상기 설명 에서보다는 첨부된 특허청구범위에 의해 정의된다. 특허청구범위의 균등 범위 안의 모든 변형은 본 발명의 범위 에 포섭된다."}
{"patent_id": "10-2020-0037299", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 인공지능 기반의 이상음원 인식 장치를 나타낸 도면, 도 2는 도 1의 CNN 모델 생성부를 나타낸 도면, 도 3은 이상음원 파형을 나타낸 도면, 도 4는 도 3의 이상음원을 확장한 음원구간의 추출을 설명하는 도면, 도 5는 전체 음원구간을 분석하는 경우와 제1 및 제2 음원구간을 분할하여 분석하는 경우에 대한 비교 결과를 설명하는 도면, 도 6 및 도 7은 본 발명의 실시예에 따른 인공지능 기반의 이상음원 인식 방법을 나타낸 도면, 도 8은 본 발명의 실시예에 따른 인공지능 기반의 이상음원 인식 장치를 이용한 관제시스템을 나타낸 도면이다."}
