{"patent_id": "10-2019-0103031", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0104936", "출원번호": "10-2019-0103031", "발명의 명칭": "통화 음질 향상 시스템, 통화 음질 향상 장치 및 방법", "출원인": "엘지전자 주식회사", "발명자": "서재필"}}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "립리딩(lip-reading)을 이용하는 통화 음질 향상 시스템으로서,근단화자(near-end speaker)의 음성 신호를 포함한 음향 신호를 수집하는 마이크로폰;원단화자(far-end speaker)로부터의 음성 신호를 출력하기 위한 스피커;입술을 포함한 상기 근단화자의 안면부를 촬영하기 위한 카메라; 및상기 마이크로폰으로부터 수집된 음향 신호에서 상기 근단화자의 음성 신호를 추출하기 위한 음향 처리부를 포함하고,상기 음향 처리부는,상기 스피커로 입력되는 신호에 기초하여 상기 마이크로폰을 통해 수집된 음향 신호에서의 에코 성분을 필터링(filter out)하기 위한 적응 필터 및 상기 적응 필터를 제어하는 필터 제어부를 포함하는 에코 감소 모듈을 포함하며,상기 필터 제어부는, 상기 근단화자의 입술 움직임 정보에 기초하여 상기 적응 필터의 파라미터를 변화시키는,통화 음질 향상 시스템."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 음향 처리부는,상기 에코 감소 모듈로부터의 음향 신호에서 노이즈 신호를 감소시키기 위한 노이즈 감소(noise reduction) 모듈; 및상기 근단화자의 입술 움직임 정보에 기초하여, 상기 노이즈 감소 모듈을 통한 노이즈 감소 처리 시 훼손된 상기 근단화자의 음성 신호를 복원하기 위한 음성 복원부를 더 포함하는,통화 음질 향상 시스템."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 카메라를 통해 촬영된 이미지에 기초하여 상기 근단화자의 입술 움직임을 판독하기 위한 립리딩(lip-reading)부를 더 포함하고,상기 립리딩부는,상기 근단화자의 입술의 움직임이 제 1 크기 이상인 경우, 상기 근단화자의 발화가 존재하는 것으로 판단하고,상기 근단화자의 입술의 움직임이 제 2 크기 미만인 경우, 상기 근단화자의 발화가 부존재하는 것으로 판단하여상기 근단화자의 발화 여부에 대한 신호를 생성하며,상기 제 2 크기는 상기 제 1 크기 이하의 값인,통화 음질 향상 시스템.공개특허 10-2019-0104936-3-청구항 4 제 3 항에 있어서,상기 립리딩부는,상기 근단화자의 입술의 움직임이 제 1 크기 미만, 상기 제 2 크기 이상인 경우, 상기 음향 신호에 대해 추정된SNR(Signal-to-Noise Ratio) 값을 기초로 상기 근단화자의 발화 존재 여부를 판단하도록 구성되는,통화 음질 향상 시스템."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서,상기 필터 제어부는,상기 립리딩부로부터의 상기 근단화자의 발화 여부에 대한 신호 및 상기 스피커로 입력되는 신호에 기초하여,상기 근단화자만 발화하는 경우에는 상기 적응 필터의 파라미터 값을 제 1 값으로,상기 원단화자만 발화하는 경우에는 상기 적응 필터의 파라미터 값을 제 2 값으로,상기 근단화자 및 원단화자 모두 발화하는 경우에는 상기 적응 필터의 파라미터 값을 제 3 값으로,상기 근단화자 및 원단화자 모두 발화하지 않는 경우에는 상기 적응 필터의 파라미터 값을 제 4 값으로 제어하도록 구성되는,통화 음질 향상 시스템."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 음성 복원부는,상기 근단화자만 발화하는 경우의 음향 신호에서 상기 근단화자의 피치 정보를 추출하고, 상기 피치 정보에 기초하여 상기 근단화자의 발화 특징을 판단하며, 상기 발화 특징에 기초하여 상기 노이즈 감소 모듈을 통한 노이즈 감소 처리 시 훼손된 상기 근단화자의 음성 신호를 복원하는,통화 음질 향상 시스템."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 카메라를 통해 촬영된 이미지에 기초하여 상기 근단화자의 입술 움직임을 판독하기 위한 립리딩(lip-reading)부를 더 포함하고,상기 립리딩부는,사람의 입술의 특징점들의 위치 변화에 따라 사람의 발화 여부 및 발화에 따른 음성 신호를 추정하도록 기훈련된 독순(讀脣, lip-reading)용 신경망 모델을 이용하여 상기 촬영된 이미지를 기초로 상기 근단화자의 발화 여부 및 발화에 따른 음성 신호를 추정하도록 구성되는,통화 음질 향상 시스템."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2019-0104936-4-제 7 항에 있어서,상기 음향 처리부는,상기 립리딩부로부터 추정된 상기 근단화자의 발화 여부 및 발화에 따른 음성 신호를 기초로 상기 마이크로폰으로부터 수집된 음향 신호에서 상기 근단화자의 음성 신호를 추출하는,통화 음질 향상 시스템."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 2 항에 있어서,상기 통화 음질 향상 시스템은 차량 내에 배치되고,상기 통화 음질 향상 시스템은,상기 차량의 주행 정보를 수신하여 주행 동작에 따라 차량 내부에서 발생되는 노이즈 정보를 추정하는 주행 노이즈 추정부를 더 포함하며,상기 노이즈 감소 모듈은 상기 주행 노이즈 추정부로부터 추정된 노이즈 정보에 기초하여 상기 에코 감소 모듈로부터의 음향 신호에서 노이즈 신호를 감소시키도록 구성되는,통화 음질 향상 시스템."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 주행 노이즈 추정부는,차량의 모델에 따라 차량 주행 동작 중에 차량 내부에서 발생하는 노이즈를 추정하도록 기훈련된 노이즈 추정용신경망 모델을 이용하여 상기 차량의 주행 동작에 따라 차량 내부에서 발생되는 노이즈 정보를 추정하도록 구성되는,통화 음질 향상 시스템."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "립리딩(lip-reading)을 이용하는 통화 음질 향상 장치로서,원단화자로부터의 음성 신호를 수신하는 통화 수신부;근단화자로부터의 음성 신호를 포함하는 음향 신호를 수신하는 음향 입력부;입술을 포함한 상기 근단화자의 안면부에 대한 이미지를 수신하는 영상 수신부; 및상기 음향 입력부를 통해 수신된 음향 신호에서 상기 근단화자의 음성 신호를 추출하기 위한 음향 처리부를 포함하고,상기 음향 처리부는,상기 통화 수신부에 의해 수신된 음성 신호를 기초하여 상기 음향 신호에서의 에코 성분을 필터링(filter out)하기 위한 적응 필터를 포함하고,상기 적응 필터의 파라미터는 상기 근단화자의 입술 움직임 정보에 기초하여 변화되는,통화 음질 향상 장치. 공개특허 10-2019-0104936-5-청구항 12 제 11 항에 있어서,상기 음향 처리부는,상기 에코 감소 모듈로부터의 음향 신호에서 노이즈 신호를 감소시키기 위한 노이즈 감소(noise reduction) 모듈; 및상기 근단화자의 입술 움직임 정보에 기초하여, 상기 노이즈 감소 모듈을 통한 노이즈 감소 처리 시 훼손된 상기 근단화자의 음성 신호를 복원하기 위한 음성 복원부를 더 포함하는,통화 음질 향상 장치."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 영상 수신부로부터 수신된 이미지에 기초하여 상기 근단화자의 입술 움직임을 판독하기 위한 립리딩(lip-reading)부를 더 포함하고,상기 립리딩부는,상기 근단화자의 입술의 움직임이 제 1 크기 이상인 경우, 상기 근단화자의 발화가 존재하는 것으로 판단하고,상기 근단화자의 입술의 움직임이 제 2 크기 미만인 경우, 상기 근단화자의 발화가 부존재하는 것으로 판단하여상기 근단화자의 발화 여부에 대한 신호를 생성하며,상기 제 2 크기는 상기 제 1 크기 이하의 값인,통화 음질 향상 장치."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 립리딩부는,상기 근단화자의 입술의 움직임이 제 1 크기 미만, 상기 제 2 크기 이상인 경우, 상기 음향 신호에 대해 추정된SNR(Signal-to-Noise Ratio) 값을 기초로 상기 근단화자의 발화 존재 여부를 판단하도록 구성되는,통화 음질 향상 장치."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 13 항에 있어서,상기 적응 필터의 파라미터는, 상기 립리딩부로부터의 상기 근단화자의 발화 여부에 대한 신호 및 상기 통화 수신부에 수신된 음성 신호에 기초하여 결정되는,통화 음질 향상 장치."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 음성 복원부는,상기 립리딩부로부터의 상기 근단화자의 발화 여부에 대한 신호 및 상기 통화 수신부에 수신된 음성 신호에 기공개특허 10-2019-0104936-6-초하여, 상기 근단화자만 발화하는 경우를 판단하고, 상기 근단화자만 발화하는 음향 신호에서 상기 근단화자의피치 정보를 추출하고, 상기 피치 정보에 기초하여 상기 근단화자의 발화 특징을 판단하며, 상기 발화 특징에기초하여 상기 노이즈 감소 모듈을 통한 노이즈 감소 처리 시 훼손된 상기 근단화자의 음성 신호를 복원하는,통화 음질 향상 장치."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "립리딩(lip-reading)을 이용하는 통화 음질 향상 방법으로서,원단화자로부터의 음성 신호를 수신하는 단계;근단화자로부터의 음성 신호를 포함하는 음향 신호를 수신하는 단계;입술을 포함한 상기 근단화자의 안면부에 대한 이미지를 수신하는 단계; 및상기 수신된 음향 신호에서 상기 근단화자의 음성 신호를 추출하는 단계를 포함하고,상기 음성 신호를 추출하는 단계는,상기 근단화자의 입술 움직임에 따라 적응 필터의 파라미터 값을 결정하는 단계; 및상기 원단화자로부터의 음성 신호에 기초하여 상기 음향 신호에서의 에코 성분을 상기 적응 필터를 이용하여 필터링(filter out)하는 단계를 포함하는,통화 음질 향상 방법."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 음성 신호를 추출하는 단계는,상기 필터링하는 단계로부터 출력되는 음향 신호에서 노이즈 신호를 감소시키는 단계; 및상기 원단화자는 발화하지 않고, 상기 근단화자가 발화하는 경우의 음향 신호에 기초하여 상기 노이즈 신호를감소시키는 단계에서 훼손된 상기 근단화자의 음성 신호를 복원하는 단계를 더 포함하는,통화 음질 향상 방법."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서,상기 이미지를 수신하는 단계 이후에, 상기 수신된 이미지에 기초하여 상기 근단화자의 입술 움직임을 판독하는단계를 더 포함하고,상기 판독하는 단계는, 상기 근단화자의 입술의 움직임이 제 1 크기 이상인 경우, 상기 근단화자의 발화가 존재하는 것으로 판단하고, 상기 근단화자의 입술의 움직임이 제 2 크기 미만인 경우, 상기 근단화자의 발화가 부존재하는 것으로 판단하여 상기 근단화자의 발화 여부에 대한 신호를 생성하는 단계를 포함하는,통화 음질 향상 방법."}
{"patent_id": "10-2019-0103031", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19 항에 있어서,상기 근단화자의 음성 신호를 복원하는 단계는,공개특허 10-2019-0104936-7-상기 근단화자만 발화하는 경우의 음향 신호에서 상기 근단화자의 피치 정보를 추출하는 단계;상기 피치 정보에 기초하여 상기 근단화자의 발화 특징을 판단하는 단계; 및상기 발화 특징에 기초하여 상기 노이즈 신호를 감소시키는 단계에서 훼손된 상기 근단화자의 음성 신호를 복원하는 단계를 포함하는,통화 음질 향상 방법."}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사물 인터넷을 위해 연결된 5G 환경에서 인공지능(artificial intelligence, AI) 알고리즘 및/또는 기계학습 (machine learning) 알고리즘을 실행하여 통화 음질 향상 시스템 및 장치를 동작시키는 통화 음질 향상 방법이 개시된다. 본 발명의 일 실시 예에 따른 통화 음질 향상 방법은, 원단화자로부터의 음성 신호를 수신하는 단계와, 근단화자로부터의 음성 신호를 포함하는 음향 신호를 수신하는 단계와, 입술을 포함한 근단화자의 안면 부에 대한 이미지를 수신하는 단계와, 수신된 음향 신호에서 근단화자의 음성 신호를 추출하는 단계를 포함할 수 있다."}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 통화 음질 향상 시스템, 통화 음질 향상 장치 및 방법에 관한 것으로, 더욱 상세하게는 립리딩(lip- reading)을 기반으로 에코 제거 및 잡음 제거를 수행하여 통화 음질을 개선할 수 있도록 하는 통화 음질 향상 시스템, 통화 음질 향상 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 전자장치의 발달로 인하여 자동차의 성능향상을 위해 많은 부분에서 전자장치의 제어에 의존하고 있으며, 이러한 전자장치의 발달은 운전자의 안전을 도모하기 위한 안전장치나 운전자의 편의를 위한 여러 가지 부가장 치 및 주행장치 등에 적용되고 있다. 특히 휴대폰 보급이 일반화되어 운전 중에 통화를 하게 되는 경우가 빈번 히 발생함에 따라, 핸즈프리 장치가 차량 내에 필수적으로 설치되어 있으며, 이러한 핸즈프리의 성능 향상을 위 한 다양한 기술이 개발되고 있다. 특히, 차량 내 핸즈프리 통화 신(scene)에서 에코 제거 및 잡음 제거 기술 (EC/NR, Echo cancellation/Noise reduction)은 핵심 기술 요소이다. 이러한 기술이 없으면 통화 시 운전자 (Near-end speaker)의 음성 신호에 에코 및 차량 내 잡음(주행잡음, 풍잡음 등)이 혼재 되어 상대방(Far-end speaker)에게 상당한 불쾌감을 줄 수 있다. 선행기술 1은 차량용 핸즈프리를 통해 입력되는 음성신호에 대해 차량의 현재 주행속도를 감안하여 노이즈를 처 리함으로써 정차, 저속주행 및 고속주행과 같은 각각의 상황에서 최적의 통화음질을 제공할 수 있도록 하는 차 량용 핸즈프리의 노이즈 저감 방법에 대한 기술을 개시하고 있다. 또한, 선행기술 2는 수신된 제1 음성 신호를 변조시키고, 변조된 제1 음성 신호를 기초로 입력된 제2 음성 신호 로부터 에코 성분을 제거하여 출력함으로써, 상관관계가 있는 에코와 더블 토크 성능을 향상시킬 수 있도록 하 는 차량용 핸즈프리 제어 방법에 대한 기술을 개시하고 있다. 즉, 선행기술 1 및 선행기술 2는 핸즈프리를 통해 입력되는 음성신호에 대해 적응적으로 노이즈 처리 및 에코 성분을 제거하여 통화 음질을 향상시킬 수 있도록 하는 것은 가능하다. 그러나 선행기술 1 및 선행기술 2는 마 이크를 통해 들어오는 신호를 기반으로 노이즈 처리 및 에코 성분을 제거하여, 실제 풍잡음, 주행잡음이 심한 차량 환경에서는 이론과 달리 그 성능이 매우 떨어지게 된다. 또한, 운전자의 발화보다 더 크게 마이크로 들어 오는 잡음들을 제거하려 잡음제거 강도를 키우게 되면 운전자의 발화가 심각(Speech distortion)하게 훼손될 수 있어, 통화 음질이 현저히 떨어지게 되는 문제가 있다."}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내 공개특허공보 제10-2014-0044708호(2014.04.15. 공개) (특허문헌 0002) 국내 공개특허공보 제10-2017-0044393호(2017.04.25. 공개)"}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "발명의 내용"}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 실시 예의 일 과제는, 립리딩(lip-reading)을 기반으로 에코 제거 및 잡음 제거(EC/NR, Echo cancellation / Noise reduction)를 수행하여 통화 음질을 개선할 수 있도록 하는데 있다. 본 개시의 실시 예의 일 과제는, 영상 정보를 이용한 립리딩 기술을 에코 제거 및 잡음 제거 기술에 적용하여 에코 제거 및 잡음 제거의 정확도를 향상시키고 성능을 향상시키는데 있다. 본 개시의 실시 예의 일 과제는, 근단화자(운전자)의 발화 유무와 원단화자(상대방)의 발화 유무에 따른 4가지 경우에 대한 상태를 립리딩을 적용하여 정확하게 판별 가능하도록 함으로써, 상황에 따라 적절한 파라미터를 적 용하여 에코 제거 성능을 향상시키는데 있다. 본 개시의 실시 예의 일 과제는, 과도한 노이즈 제거로 인해 훼손된 근단화자의 음성 신호를, 정확한 근단화자 의 하모닉(harmonic) 추정을 통해 복원하여, 통화 음질 향상 장치의 성능을 향상시키는데 있다. 본 개시의 실시 예의 일 과제는, 기훈련된 독순(讀脣, lip-reading)용 신경망 모델을 이용하여, 근단화자의 입 술의 특징점들의 위치 변화에 따라 근단화자의 발화 여부 및 발화에 따른 음성 신호를 추정함으로써, 통화 음질 향상 시스템의 신뢰도를 향상시키는데 있다. 본 개시의 실시 예의 일 과제는, 기훈련된 노이즈 추정용 신경망 모델을 이용하여, 차량의 모델에 따라 차량 내 부에서 발생하는 노이즈 정보를 추정함으로써, 통화 음질 향상 시스템의 신뢰도를 향상시키는데 있다. 본 개시의 실시예의 목적은 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 통화 음질 향상 방법은, 립리딩(lip-reading)을 기반으로 에코 제거 및 잡음 제거 를 수행하여 통화 음질을 개선할 수 있도록 제어하는 단계를 포함할 수 있다. 구체적으로 본 개시의 일 실시 예에 따른 통화 음질 향상 시스템은, 근단화자(near-end speaker)의 음성 신호를 포함한 음향 신호를 수집하는 마이크로폰과, 원단화자(far-end speaker)로부터의 음성 신호를 출력하기 위한 스 피커와, 입술을 포함한 근단화자의 안면부를 촬영하기 위한 카메라와, 마이크로폰으로부터 수집된 음향 신호에 서 근단화자의 음성 신호를 추출하기 위한 음향 처리부를 포함하고, 음향 처리부는, 스피커로 입력되는 신호에 기초하여 마이크로폰을 통해 수집된 음향 신호에서의 에코 성분을 필터링(filter out)하기 위한 적응 필터 및 적응 필터를 제어하는 필터 제어부를 포함하는 에코 감소 모듈을 포함하며, 필터 제어부는, 근단화자의 입술 움 직임 정보에 기초하여 상기 적응 필터의 파라미터를 변화시킬 수 있다. 본 개시의 일 실시 예에 따른 통화 음질 향상 시스템을 통하여, 립리딩(lip-reading)을 기반으로 에코 제거 및 잡음 제거(EC/NR, Echo cancellation / Noise reduction)를 수행하여 통화 음질을 개선함으로써, 원단화자(상 대방)에게 향상된 통화 품질을 제공할 수 있다. 또한, 음향 처리부는, 에코 감소 모듈로부터의 음향 신호에서 노이즈 신호를 감소시키기 위한 노이즈 감소 (noise reduction) 모듈과, 근단화자의 입술 움직임 정보에 기초하여, 노이즈 감소 모듈을 통한 노이즈 감소 처 리 시 훼손된 근단화자의 음성 신호를 복원하기 위한 음성 복원부를 더 포함할 수 있다. 또한, 본 개시의 일 실시 예에 따른 통화 음질 향상 시스템은, 카메라를 통해 촬영된 이미지에 기초하여 상기 근단화자의 입술 움직임을 판독하기 위한 립리딩(lip-reading)부를 더 포함하고, 립리딩부는, 근단화자의 입술 의 움직임이 제 1 크기 이상인 경우, 근단화자의 발화가 존재하는 것으로 판단하고, 근단화자의 입술의 움직임 이 제 2 크기 미만인 경우, 근단화자의 발화가 부존재하는 것으로 판단하여 근단화자의 발화 여부에 대한 신호 를 생성하며, 제 2 크기는 제 1 크기 이하의 값일 수 있다. 또한, 립리딩부는, 근단화자의 입술의 움직임이 제 1 크기 미만, 제 2 크기 이상인 경우, 음향 신호에 대해 추 정된 SNR(Signal-to-Noise Ratio) 값을 기초로 근단화자의 발화 존재 여부를 판단하도록 구성될 수 있다. 본 개시의 일 실시 예에 따른 음향 처리부와 립리딩부를 통하여, 영상 정보를 이용한 립리딩 기술을 에코 제거 및 잡음 제거 기술에 적용하여 에코 제거 및 잡음 제거의 정확도를 향상시키고, 에코 제거 및 잡음 제거의 성능을 향상시킬 수 있다. 또한, 필터 제어부는, 립리딩부로부터의 근단화자의 발화 여부에 대한 신호 및 스피커로 입력되는 신호에 기초 하여, 근단화자만 발화하는 경우에는 적응 필터의 파라미터 값을 제 1 값으로, 원단화자만 발화하는 경우에는 적응 필터의 파라미터 값을 제 2 값으로, 근단화자 및 원단화자 모두 발화하는 경우에는 적응 필터의 파라미터 값을 제 3 값으로, 근단화자 및 원단화자 모두 발화하지 않는 경우에는 적응 필터의 파라미터 값을 제 4 값으로 제어하도록 구성될 수 있다. 본 개시의 일 실시 예에 따른 필터 제어부를 통하여, 근단화자(운전자)의 발화 유무와 원단화자(상대방)의 발화 유무에 따른 4가지 경우에 대한 상태를 립리딩을 적용하여 정확하게 판별 가능하도록 함으로써, 상황에 따라 적 절한 파라미터를 적용하여 에코 제거 성능을 향상시킬 수 있다. 또한, 음성 복원부는, 근단화자만 발화하는 경우의 음향 신호에서 근단화자의 피치 정보를 추출하고, 피치 정보 에 기초하여 근단화자의 발화 특징을 판단하며, 발화 특징에 기초하여 노이즈 감소 모듈을 통한 노이즈 감소 처 리 시 훼손된 근단화자의 음성 신호를 복원할 수 있다. 본 개시의 일 실시 예에 따른 음성 복원부를 통하여, 과도한 노이즈 제거로 인해 훼손된 근단화자의 음성 신호 를, 정확한 근단화자의 하모닉(harmonic) 추정을 통해 복원함으로써, 통화 음질 향상 장치의 성능을 향상시킬 수 있다. 또한, 본 개시의 일 실시 예에 따른 통화 음질 향상 시스템은, 카메라를 통해 촬영된 이미지에 기초하여 상기 근단화자의 입술 움직임을 판독하기 위한 립리딩(lip-reading)부를 더 포함하고, 립리딩부는, 사람의 입술의 특 징점들의 위치 변화에 따라 사람의 발화 여부 및 발화에 따른 음성 신호를 추정하도록 기훈련된 독순(讀脣, lip-reading)용 신경망 모델을 이용하여 촬영된 이미지를 기초로 근단화자의 발화 여부 및 발화에 따른 음성 신 호를 추정하도록 구성될 수 있다. 본 개시의 일 실시 예에 따른 통화 음질 향상 시스템을 통하여, 기훈련된 독순(讀脣, lip-reading)용 신경망 모 델을 이용하여, 근단화자의 입술의 특징점들의 위치 변화에 따라 근단화자의 발화 여부 및 발화에 따른 음성 신 호를 추정함으로써, 통화 음질 향상 시스템의 신뢰도를 향상시킬 수 있다. 또한, 음향 처리부는, 립리딩부로부터 추정된 근단화자의 발화 여부 및 발화에 따른 음성 신호를 기초로 마이크 로폰으로부터 수집된 음향 신호에서 근단화자의 음성 신호를 추출할 수 있다. 본 개시의 일 실시 예에 따른 음향 처리부를 통하여, 5G 네트워크 기반 통신을 통해 차량 내 핸즈프리 통화 시 에코 제거 및 노이즈 제거를 수행함으로써, 신속한 데이터 처리가 가능하므로 통화 음질 향상 시스템의 성능을 보다 향상시킬 수 있다. 또한, 본 개시의 일 실시 예에 따른 통화 음질 향상 시스템은, 차량 내에 배치되고, 차량의 주행 정보를 수신하 여 주행 동작에 따라 차량 내부에서 발생되는 노이즈 정보를 추정하는 주행 노이즈 추정부를 더 포함하며, 노이 즈 감소 모듈은 주행 노이즈 추정부로부터 추정된 노이즈 정보에 기초하여 에코 감소 모듈로부터의 음향 신호에 서 노이즈 신호를 감소시키도록 구성될 수 있다. 또한, 주행 노이즈 추정부는, 차량의 모델에 따라 차량 주행 동작 중에 차량 내부에서 발생하는 노이즈를 추정 하도록 기훈련된 노이즈 추정용 신경망 모델을 이용하여 차량의 주행 동작에 따라 차량 내부에서 발생되는 노이 즈 정보를 추정하도록 구성될 수 있다. 본 개시의 일 실시 예에 따른 주행 노이즈 추정부를 통하여, 기훈련된 노이즈 추정용 신경망 모델을 이용하여, 차량의 모델에 따라 차량 내부에서 발생하는 노이즈 정보를 추정함으로써, 통화 음질 향상 시스템의 신뢰도를 향상시킬 수 있다. 본 개시의 일 실시 예에 따른 통화 음질 향상 장치는, 원단화자로부터의 음성 신호를 수신하는 통화 수신부와, 근단화자로부터의 음성 신호를 포함하는 음향 신호를 수신하는 음향 입력부와, 입술을 포함한 근단화자의 안면 부에 대한 이미지를 수신하는 영상 수신부와, 음향 입력부를 통해 수신된 음향 신호에서 근단화자의 음성 신호 를 추출하기 위한 음향 처리부를 포함하고, 음향 처리부는, 통화 수신부에 의해 수신된 음성 신호를 기초하여 음향 신호에서의 에코 성분을 필터링(filter out)하기 위한 적응 필터를 포함하고, 적응 필터의 파라미터는 근 단화자의 입술 움직임 정보에 기초하여 변화될 수 있다. 또한, 음향 처리부는, 에코 감소 모듈로부터의 음향 신호에서 노이즈 신호를 감소시키기 위한 노이즈 감소 (noise reduction) 모듈과, 근단화자의 입술 움직임 정보에 기초하여, 노이즈 감소 모듈을 통한 노이즈 감소 처 리 시 훼손된 근단화자의 음성 신호를 복원하기 위한 음성 복원부를 더 포함할 수 있다. 본 개시의 일 실시 예에 따른 통화 음질 향상 장치를 통하여, 영상 정보를 이용한 립리딩(lip-reading)을 기반 으로 에코 제거 및 잡음 제거(EC/NR, Echo cancellation / Noise reduction)를 수행하여 통화 음질을 개선함으 로써, 에코 제거 및 잡음 제거의 성능을 향상시켜 원단화자(상대방)에게 향상된 통화 품질을 제공할 수 있다. 또한, 본 개시의 일 실시 예에 따른 통화 음질 향상 장치는, 영상 수신부로부터 수신된 이미지에 기초하여 근단 화자의 입술 움직임을 판독하기 위한 립리딩(lip-reading)부를 더 포함하고, 립리딩부는, 근단화자의 입술의 움 직임이 제 1 크기 이상인 경우, 근단화자의 발화가 존재하는 것으로 판단하고, 근단화자의 입술의 움직임이 제 2 크기 미만인 경우, 근단화자의 발화가 부존재하는 것으로 판단하여 근단화자의 발화 여부에 대한 신호를 생성 하며, 제 2 크기는 상기 제 1 크기 이하의 값일 수 있다. 또한, 립리딩부는, 근단화자의 입술의 움직임이 제 1 크기 미만, 상기 제 2 크기 이상인 경우, 음향 신호에 대 해 추정된 SNR(Signal-to-Noise Ratio) 값을 기초로 근단화자의 발화 존재 여부를 판단하도록 구성될 수 있다. 또한, 적응 필터의 파라미터는, 립리딩부로부터의 근단화자의 발화 여부에 대한 신호 및 통화 수신부에 수신된 음성 신호에 기초하여 결정될 수 있다. 본 개시의 일 실시 예에 따른 립리딩부를 통하여, 근단화자(운전자)의 발화 유무와 원단화자(상대방)의 발화 유 무에 따른 4가지 경우에 대한 상태를 립리딩을 적용하여 정확하게 판별 가능하도록 함으로써, 상황에 따라 적절 한 파라미터를 적용하여 에코 제거 성능을 향상시킬 수 있다. 또한, 음성 복원부는, 립리딩부로부터의 근단화자의 발화 여부에 대한 신호 및 통화 수신부에 수신된 음성 신호 에 기초하여, 근단화자만 발화하는 경우를 판단하고, 근단화자만 발화하는 음향 신호에서 근단화자의 피치 정보 를 추출하고, 피치 정보에 기초하여 근단화자의 발화 특징을 판단하며, 발화 특징에 기초하여 노이즈 감소 모듈 을 통한 노이즈 감소 처리 시 훼손된 근단화자의 음성 신호를 복원할 수 있다. 본 개시의 일 실시 예에 따른 음성 복원부를 통하여, 과도한 노이즈 제거로 인해 훼손된 근단화자의 음성 신호 를, 정확한 근단화자의 하모닉(harmonic) 추정을 통해 복원함으로써, 통화 음질 향상 장치의 성능을 향상시킬 수 있다. 본 개시의 일 실시 예에 따른 통화 음질 향상 방법은, 원단화자로부터의 음성 신호를 수신하는 단계와, 근단화 자로부터의 음성 신호를 포함하는 음향 신호를 수신하는 단계와, 입술을 포함한 근단화자의 안면부에 대한 이미 지를 수신하는 단계와, 수신된 음향 신호에서 근단화자의 음성 신호를 추출하는 단계를 포함하고, 음성 신호를 추출하는 단계는, 근단화자의 입술 움직임에 따라 적응 필터의 파라미터 값을 결정하는 단계와, 원단화자로부터 의 음성 신호에 기초하여 음향 신호에서의 에코 성분을 적응 필터를 이용하여 필터링(filter out)하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 통화 음질 향상 방법을 통하여, 영상 정보를 이용한 립리딩(lip-reading)을 기반 으로 에코 제거 및 잡음 제거(EC/NR, Echo cancellation / Noise reduction)를 수행하여 통화 음질을 개선함으 로써, 에코 제거 및 잡음 제거의 성능을 향상시켜 원단화자(상대방)에게 향상된 통화 품질을 제공할 수 있다. 또한, 음성 신호를 추출하는 단계는, 필터링하는 단계로부터 출력되는 음향 신호에서 노이즈 신호를 감소시키는 단계와, 원단화자는 발화하지 않고, 근단화자가 발화하는 경우의 음향 신호에 기초하여 노이즈 신호를 감소시키 는 단계에서 훼손된 근단화자의 음성 신호를 복원하는 단계를 더 포함할 수 있다. 본 개시의 일 실시 예에 따른 음성 신호를 추출하는 단계를 통하여, 근단화자(운전자)의 발화 유무와 원단화자 (상대방)의 발화 유무에 따른 4가지 경우에 대한 상태를 립리딩을 적용하여 정확하게 판별 가능하도록 함으로써, 상황에 따라 적절한 파라미터를 적용하여 에코 제거 성능을 향상시킬 수 있다. 또한, 본 개시의 일 실시 예에 따른 통화 음질 향상 방법은, 이미지를 수신하는 단계 이후에, 수신된 이미지에 기초하여 근단화자의 입술 움직임을 판독하는 단계를 더 포함하고, 판독하는 단계는, 근단화자의 입술의 움직임 이 제 1 크기 이상인 경우, 근단화자의 발화가 존재하는 것으로 판단하고, 근단화자의 입술의 움직임이 제 2 크 기 미만인 경우, 근단화자의 발화가 부존재하는 것으로 판단하여 근단화자의 발화 여부에 대한 신호를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 통화 음질 향상 방법을 통하여, 기훈련된 독순(讀脣, lip-reading)용 신경망 모델 을 이용하여, 근단화자의 입술의 특징점들의 위치 변화에 따라 근단화자의 발화 여부 및 발화에 따른 음성 신호 를 추정함으로써, 통화 음질 향상 시스템의 신뢰도를 향상시킬 수 있다. 또한, 근단화자의 음성 신호를 복원하는 단계는, 근단화자만 발화하는 경우의 음향 신호에서 근단화자의 피치 정보를 추출하는 단계와, 피치 정보에 기초하여 근단화자의 발화 특징을 판단하는 단계와, 발화 특징에 기초하 여 노이즈 신호를 감소시키는 단계에서 훼손된 근단화자의 음성 신호를 복원하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 근단화자의 음성 신호를 복원하는 단계를 통하여, 과도한 노이즈 제거로 인해 훼 손된 근단화자의 음성 신호를, 정확한 근단화자의 하모닉(harmonic) 추정을 통해 복원함으로써, 통화 음질 향상 장치의 성능을 향상시킬 수 있다. 이 외에도, 본 발명의 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램이 저장된 컴퓨터로 판독 가능한 기록매체가 더 제공될 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시 예에 의하면, 립리딩(lip-reading)을 기반으로 에코 제거 및 잡음 제거(EC/NR, Echo cancellation / Noise reduction)를 수행하여 통화 음질을 개선함으로써, 원단화자(상대방)에게 향상된 통화 품 질을 제공할 수 있다. 또한, 영상 정보를 이용한 립리딩 기술을 에코 제거 및 잡음 제거 기술에 적용하여 에코 제거 및 잡음 제거의 정확도를 향상시키고, 에코 제거 및 잡음 제거의 성능을 향상시킬 수 있다. 또한, 근단화자(운전자)의 발화 유무와 원단화자(상대방)의 발화 유무에 따른 4가지 경우에 대한 상태를 립리딩 을 적용하여 정확하게 판별 가능하도록 함으로써, 상황에 따라 적절한 파라미터를 적용하여 에코 제거 성능을 향상시킬 수 있다. 또한, 과도한 노이즈 제거로 인해 훼손된 근단화자의 음성 신호를, 정확한 근단화자의 하모닉(harmonic) 추정을 통해 복원함으로써, 통화 음질 향상 장치의 성능을 향상시킬 수 있다. 또한, 기훈련된 독순(讀脣, lip-reading)용 신경망 모델을 이용하여, 근단화자의 입술의 특징점들의 위치 변화 에 따라 근단화자의 발화 여부 및 발화에 따른 음성 신호를 추정함으로써, 통화 음질 향상 시스템의 신뢰도를 향상시킬 수 있다. 또한, 기훈련된 노이즈 추정용 신경망 모델을 이용하여, 차량의 모델에 따라 차량 내부에서 발생하는 노이즈 정 보를 추정함으로써, 통화 음질 향상 시스템의 신뢰도를 향상시킬 수 있다. 또한, 5G 네트워크 기반 통신을 통해 차량 내 핸즈프리 통화 시 에코 제거 및 노이즈 제거를 수행함으로써, 신 속한 데이터 처리가 가능하므로 통화 음질 향상 시스템의 성능을 보다 향상시킬 수 있다. 또한, 통화 음질 향상 장치 자체는 대량 생산된 획일적인 제품이지만, 사용자는 통화 음질 향상 장치를 개인화 된 장치로 인식하므로 사용자 맞춤형 제품의 효과를 낼 수 있다."}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시 예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시 예들로 한정되는 것이 아니라, 서로 다른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발"}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, 포함하 다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 본 명세서에서 기술되는 차량은, 자동차, 오토바이를 포함하는 개념일 수 있다. 이하에서는, 차량에 대해 자동 차를 위주로 기술한다. 본 명세서에서 기술되는 차량은, 동력원으로서 엔진을 구비하는 내연기관 차량, 동력원으로서 엔진과 전기 모터 를 구비하는 하이브리드 차량, 동력원으로서 전기 모터를 구비하는 전기 차량 등을 모두 포함하는 개념일 수 있 다. 이하, 본 발명에 따른 실시 예들을 첨부된 도면을 참조하여 상세히 설명하기로 하며, 첨부 도면을 참조하여 설 명함에 있어, 동일하거나 대응하는 구성요소는 동일한 도면번호를 부여하고 이에 대한 중복되는 설명은 생략하 기로 한다. 도 1은 본 발명의 일 실시 예에 따른 AI 서버, 자율 주행 차량, 로봇, XR 장치, 스마트폰 또는 가전과, 이들 중 에서 적어도 하나 이상을 서로 연결하는 클라우드 네트워크를 포함하는 AI 시스템 기반 통화 음질 향상 시스템 환경의 예시도이다. 도 1을 참조하면, AI 시스템 기반 통화 음질 향상 시스템 환경은 AI 서버(AI Server, 20), 로봇(Robot, 30a), 자율 주행 차량(Self-Driving Vehicle, 30b), XR 장치(XR Device, 30c), 스마트폰(Smartphone, 30d) 또는 가전 (Home Appliance, 30e) 및 클라우드 네트워크(Cloud Network, 10)를 포함할 수 있다. 이때, AI 시스템 기반 통화 음질 향상 시스템 환경에서는, AI 서버, 로봇(30a), 자율 주행 차량(30b), XR 장치(30c), 스마트폰 (30d) 또는 가전(30e) 중에서 적어도 하나 이상이 클라우드 네트워크와 연결될 수 있다. 여기서, AI 기술이 적용된 로봇(30a), 자율 주행 차량(30b), XR 장치(30c), 스마트폰(30d) 또는 가전(30e) 등을 AI 장치(30a 내지 30e)라 칭할 수 있다. 이때, 로봇(30a)은 스스로 보유한 능력에 의해 주어진 일을 자동으로 처리하거나 작동하는 기계를 의미할 수 있 다. 특히, 환경을 인식하고 스스로 판단하여 동작을 수행하는 기능을 갖는 로봇을 지능형 로봇이라 칭할 수 있 다. 로봇(30a)은 사용 목적이나 분야에 따라 산업용, 의료용, 가정용, 군사용 등으로 분류할 수 있다. 로봇 (30a)은 액츄에이터 또는 모터를 포함하는 구동부를 구비하여 로봇 관절을 움직이는 등의 다양한 물리적 동작을 수행할 수 있다. 또한, 이동 가능한 로봇은 구동부에 휠, 브레이크, 프로펠러 등이 포함되어, 구동부를 통해 지 상에서 주행하거나 공중에서 비행할 수 있다. 자율 주행 차량(30b)은 사용자의 조작 없이 또는 사용자의 최소한의 조작으로 주행하는 차량(Vehicle)을 의미하 며, AutonomousDriving Vehicle이라고도 할 수 있다. 예컨대, 자율 주행에는 주행중인 차선을 유지하는 기술, 어댑티브 크루즈 컨트롤과 같이 속도를 자동으로 조절하는 기술, 정해진 경로를 따라 자동으로 주행하는 기술, 목적지가 설정되면 자동으로 경로를 설정하여 주행하는 기술 등이 모두 포함될 수 있다. 이때, 자율 주행 차량 은 자율 주행 기능을 가진 로봇으로 볼 수 있다. XR 장치(30c)는 확장 현실(XR: eXtended Reality)을 이용하는 장치로, 확장 현실은 가상 현실(VR: Virtual Reality), 증강 현실(AR: Augmented Reality), 혼합 현실(MR: Mixed Reality)을 총칭한다. VR 기술은 현실 세 계의 객체나 배경 등을 CG 영상으로만 제공하고, AR 기술은 실제 사물 영상 위에 가상으로 만들어진 CG 영상을 함께 제공하며, MR 기술은 현실 세계에 가상 객체들을 섞고 결합시켜서 제공하는 컴퓨터 그래픽 기술이다. MR 기술은 현실 객체와 가상 객체를 함께 보여준다는 점에서 AR 기술과 유사하다. 그러나, AR 기술에서는 가상 객 체가 현실 객체를 보완하는 형태로 사용되는 반면, MR 기술에서는 가상 객체와 현실 객체가 동등한 성격으로 사 용된다는 점에서 차이점이 있다. XR 기술은 HMD(Head-Mount Display), HUD(Head-Up Display), 휴대폰, 태블릿 PC, 랩탑, 데스크탑, TV, 디지털 사이니지 등에 적용될 수 있고, XR 기술이 적용된 장치를 XR 장치(XR Device) 라 칭할 수 있다. 스마트폰(30d)은 실시 예로, 사용자 단말기 중 하나를 의미할 수 있다. 이러한 사용자 단말기는 통화 음질 향상 시스템 작동 어플리케이션 또는 통화 음질 향상 시스템 작동 사이트에 접속한 후 인증 과정을 통하여 통화 음질 향상 시스템의 작동 또는 제어를 위한 서비스를 제공받을 수 있다. 본 실시 예에서 인증 과정을 마친 사용자 단 말기는 통화 음질 향상 시스템을 작동시키고, 통화 음질 향상 장치의 동작을 제어할 수 있다. 본 실시 예에서 사용자 단말기는 사용자가 조작하는 데스크 탑 컴퓨터, 스마트폰, 노트북, 태블릿 PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라, 가전기기 및 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 또한, 사용 자 단말기는 통신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 단말 기 일 수 있다. 사용자 단말기는 상술한 내용에 제한되지 아니하며, 웹 브라우징이 가능한 단말기는 제한 없이 차용될 수 있다. 가전(30e)은 가정 내 구비되는 모든 전자 디바이스 중 어느 하나를 포함할 수 있으며, 특히 음성인식, 인공지능 등이 구현 가능한 단말, 오디오 신호 및 비디오 신호 중 하나 이상을 출력하는 단말 등을 포함할 수 있다. 또한 가전(30e)은 특정 전자 디바이스에 국한되지 않고 다양한 홈 어플라이언스(예를 들어, 세탁기, 건조기, 의류 처 리 장치, 에어컨, 김치 냉장고 등)를 포함할 수 있다. 클라우드 네트워크는 클라우드 컴퓨팅 인프라의 일부를 구성하거나 클라우드 컴퓨팅 인프라 안에 존재하는 네트워크를 의미할 수 있다. 여기서, 클라우드 네트워크는 3G 네트워크, 4G 또는 LTE(Long Term Evolution) 네트워크 또는 5G 네트워크 등을 이용하여 구성될 수 있다. 즉, AI 시스템 기반 통화 음질 향상 시 스템 환경을 구성하는 각 장치들(30a 내지 30e, 20)은 클라우드 네트워크를 통해 서로 연결될 수 있다. 특 히, 각 장치들(30a 내지 30e, 20)은 기지국을 통해서 서로 통신할 수도 있지만, 기지국을 통하지 않고 직접 서 로 통신할 수도 있다. 이러한 클라우드 네트워크는 예컨대 LANs(local area networks), WANs(Wide area networks), MANs(metropolitan area networks), ISDNs(integrated service digital networks) 등의 유선 네트워크나, 무선LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 발명의 범위가 이에 한정되는 것 은 아니다. 또한 클라우드 네트워크는 근거리 통신 및/또는 원거리 통신을 이용하여 정보를 송수신할 수 있 다. 여기서 근거리 통신은 블루투스(bluetooth), RFID(radio frequency identification), 적외선 통신(IrDA, infrared data association), UWB(ultra-wideband), ZigBee, Wi-Fi(Wireless fidelity) 기술을 포함할 수 있 고, 원거리 통신은 CDMA(code division multiple access), FDMA(frequency division multiple access), TDMA(time division multiple access), OFDMA(orthogonal frequency division multiple access), SC- FDMA(single carrier frequency division multiple access) 기술을 포함할 수 있다. 또한, 클라우드 네트워크는 허브, 브리지, 라우터, 스위치 및 게이트웨이와 같은 네트워크 요소들의 연결을 포함할 수 있다. 클라우드 네트워크는 인터넷과 같은 공용 네트워크 및 안전한 기업 사설 네트워크와 같은 사설 네트워크를 비롯한 하나 이상의 연결된 네트워크들, 예컨대 다중 네트워크 환경을 포함할 수 있다. 클라우 드 네트워크에의 액세스는 하나 이상의 유선 또는 무선 액세스 네트워크들을 통해 제공될 수 있다. 더 나아 가 클라우드 네트워크는 사물 등 분산된 구성 요소들 간에 정보를 주고받아 처리하는 IoT(Internet of Things, 사물인터넷) 망 및/또는 5G 통신을 지원할 수 있다. AI 서버는 AI 프로세싱을 수행하는 서버와 빅 데이터에 대한 연산을 수행하는 서버를 포함할 수 있다. 또한, AI 서버는 각종 인공 지능 알고리즘을 적용하는데 필요한 빅데이터와, 통화 음질 향상 시스템을 동작시키는 데이터를 제공하는 데이터베이스 서버일 수 있다. 그 밖에 AI 서버는 스마트폰(30d)에 설치된 통화 음질 향상 시스템 작동 어플리케이션 또는 통화 음질 향상 시스템 작동 웹 브라우저를 이용하여 차량의 동 작을 원격에서 제어할 수 있도록 하는 웹 서버 또는 어플리케이션 서버를 포함할 수 있다. 또한, AI 서버는 AI 시스템 기반 통화 음질 향상 시스템 환경을 구성하는 AI 장치들인 로봇(30a), 자율 주 행 차량(30b), XR 장치(30c), 스마트폰(30d) 또는 가전(30e) 중에서 적어도 하나 이상과 클라우드 네트워크(1 0)를 통하여 연결되고, 연결된 AI 장치들(30a 내지 30e)의 AI 프로세싱을 적어도 일부를 도울 수 있다. 이때, AI 서버는 AI 장치(30a 내지 30e)를 대신하여 머신 러닝 알고리즘에 따라 인공 신경망을 학습시킬 수 있고, 학습 모델을 직접 저장하거나 AI 장치(30a 내지 30e)에 전송할 수 있다. 이때, AI 서버는 AI 장치(30a 내지 30e)로부터 입력 데이터를 수신하고, 학습 모델을 이용하여 수신한 입력 데이터에 대하여 결과 값을 추론하고, 추론한 결과 값에 기초한 응답이나 제어 명령을 생성하여 AI 장치(30a 내지 30e)로 전송할 수 있다. 또는, AI 장치(30a 내지 30e)는 직접 학습 모델을 이용하여 입력 데이터에 대하여 결과 값을 추론하고, 추론한 결과 값에 기초한 응답이나 제어 명령을 생성할 수도 있다. 여기서 인공 지능(artificial intelligence, AI)은, 인간의 지능으로 할 수 있는 사고, 학습, 자기계발 등을 컴 퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보기술의 한 분야로, 컴퓨터가 인간의 지능적인 행동을 모방할 수 있도록 하는 것을 의미할 수 있다. 또한, 인공 지능은 그 자체로 존재하는 것이 아니라, 컴퓨터 과학의 다른 분야와 직간접적으로 많은 관련을 맺 고 있다. 특히 현대에는 정보기술의 여러 분야에서 인공 지능적 요소를 도입하여, 그 분야의 문제 풀이에 활용 하려는 시도가 매우 활발하게 이루어지고 있다. 머신 러닝(machine learning)은 인공 지능의 한 분야로, 컴퓨터에 명시적인 프로그램 없이 배울 수 있는 능력을 부여하는 연구 분야를 포함할 수 있다. 구체적으로 머신 러닝은, 경험적 데이터를 기반으로 학습을 하고 예측을 수행하고 스스로의 성능을 향상시키는 시스템과 이를 위한 알고리즘을 연구하고 구축하는 기술이라 할 수 있다. 머신 러닝의 알고리즘들은 엄격하게 정해진 정적인 프로그램 명령들을 수행하는 것이라기보다, 입력 데이터를 기반으로 예측이나 결정을 이끌어내기 위해 특정한 모델을 구축하는 방식을 취할 수 있다. 본 실시 예는, 특히 자율 주행 차량(30b)에 관한 것으로, 이하에서는, 상술한 기술이 적용되는 AI 장치 중 자율 주행 차량(30b)의 실시 예를 설명한다. 다만, 본 실시 예에서, 차량(도 2의 1000)은 자율 주행 차량(30b)에 한 정되는 것은 아니며, 자율 주행 차량(30b) 및 일반 차량 등 모든 차량을 의미할 수 있다. 이하에서는, 통화 음 질 향상 시스템이 배치된 차량에 대해 설명하도록 한다. 도 2는 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 통신 환경을 개략적으로 설명하기 위하여 도시한 도면이다 도 1에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 2를 참조하면, 통화 음질 향상 시스템은 차량과, 근단화자(Near-end speaker), 예를 들어 운전자의 스마트폰과, 원단화자(Far-end speaker), 예를 들어 통화 상대방의 스마트폰(2000a)과, 서버를 필 수적으로 포함하고, 그 외 네트워크 등의 구성요소를 더 포함할 수 있다. 이때 근단화자는 차량 내에서 통화하는 사용자를 의미하고, 원단화자는 상기 근단화자와 통화하는 상대방 사용자를 의미할 수 있다. 예를 들어, 차량 내에서 통화하는 사용자는 운전자일 수 있으나, 이에 한정되 는 것은 아니며 차량 내의 핸즈프리 기능을 통해 통화하는 차량 내 다른 사용자를 의미할 수도 있 다. 즉 근단화자의 스마트폰은 예를 들어, 핸즈프리 기능 등 차량 내 통화 기능을 위해 차량과 연 결된 스마트폰을 의미할 수 있다. 이때 근단화자의 스마트폰은 차량과 근거리 무선 통신을 통해 연 결될 수 있고, 원단화자의 스마트폰(2000a)은 근단화자의 스마트폰과 모바일 통신을 통해 연결될 수 있다. 본 실시 예에서 서버는 상술한 AI 서버, MEC(Mobile Edge Computing) 서버 등을 포함할 수 있으며, 이들 을 통칭하는 의미일 수도 있다. 다만, 본 실시예에서, 도 2에 도시된 서버는 AI 서버를 나타낼 수 있다. 그러나 서버가 본 실시 예에서 명시되지 않은 다른 서버인 경우 도 2에 도시된 연결관계 등은 달라질 수 있다. AI 서버는 차량으로부터 통화 음질 향상을 위한 데이터를 수신하고, 근단화자 스마트폰으로부터 근 단화자 정보 데이터를 수신하며, 원단화자 스마트폰(2000a)으로부터 원단화자 정보 데이터를 수신할 수 있다. 즉 AI 서버는 차량으로부터의 통화 음질 향상을 위한 데이터, 근단화자 정보 데이터 및 원단화자 정보 데 이터 중 적어도 하나 이상에 기초하여 통화 음질 향상을 위한 학습을 수행할 수 있다. 그리고 AI 서버는 통화 음질 향상을 위한 학습 결과를 차량에 송신하여 차량에서 통화 음질 향상을 위한 동작을 수행할 수 있도록 할 수 있다. MEC 서버는 일반적인 서버의 역할을 수행할 수 있음은 물론, 무선 액세스 네트워크(RAN: Radio Access Networ k)내에서 도로 옆에 있는 기지국(BS)과 연결되어, 유연한 차량 관련 서비스를 제공하고 네트워크를 효율적으로 운용할 수 있게 해준다. 특히 MEC 서버에서 지원되는 네트워크-슬라이싱(network-slicing)과 트래픽 스케줄링 정책은 네트워크의 최적화를 도와줄 수 있다. MEC 서버는 RAN내에 통합되고, 3GPP 시스템에서 S1-User plane interface(예를 들어, 코어 네트워크(Core network)와 기지국 사이)에 위치할 수 있다. MEC 서버는 각각 독립적 인 네트워크 요소로 간주될 수 있으며, 기존에 존재하는 무선 네트워크의 연결에 영향을 미치지 않는다. 독립적 인 MEC 서버는 전용 통신망을 통해 기지국에 연결되며, 당해 셀(cell)에 위치한, 여러 엔드-유저(end-user)들에 게 특정 서비스들을 제공할 수 있다. 이러한 MEC 서버와 클라우드 서버는 인터넷-백본(internet-backbone)을 통 해 서로 연결되고 정보를 공유할 수 있다. 또한, MEC 서버는 독립적으로 운용되고, 복수개의 기지국을 제어할 수 있다. 특히 자율주행차량을 위한 서비스, 가상머신(VM : virtual machine)과 같은 어플리케이션 동작과 가상 화 플랫폼을 기반으로 하는 모바일 네트워크 엣지(edge)단에서의 동작을 수행할 수 있다. 기지국(BS : Base Station)은 MEC 서버들과 코어 네트워크 모두에 연결되어, 제공되는 서비스 수행에서 요구되는 유연한 유저 트 래픽 스케쥴링을 가능하게 할 수 있다. 특정 셀에서 대용량의 유저 트래픽이 발생하는 경우, MEC 서버는 인접한 기지국 사이의 인터페이스에 근거하여, 테스크 오프로딩(offloading) 및 협업 프로세싱을 수행 할 수 있다. 즉, MEC 서버는 소프트웨어를 기반으로하는 개방형 동작환경을 갖으므로, 어플리케이션 제공 업체의 새로운 서비스 들이 용이하게 제공될 수 있다. 또한, MEC 서버는 엔드-유저(end-user) 가까이에서 서비스가 수행되므로, 데이 터 왕복시간이 단축되며 서비스 제공 속도가 빠르기 때문에 서비스 대기 시간을 감소시킬 수 있다. 또한 MEC 어 플리케이션과 가상 네트워크 기능(VNF: Virtual Network Functions)은 서비스 환경에 있어서, 유연성 및 지리적 분포성을 제공할 수 있다. 이러한 가상화 기술을 사용하여 다양한 어플리케이션과 네트워크 기능이 프로그래밍 될 수 있을 뿐 아니라 특정 사용자 그룹만이 선택되거나 이들만을 위한 컴파일(compile)이 가능할 수 있다. 그 러므로, 제공되는 서비스는 사용자 요구 사항에 보다 밀접하게 적용될 수 있다. 그리고 중앙 통제 능력과 더불 어 MEC 서버는 기지국간의 상호작용을 최소화할 수 있다. 이는 셀 간의 핸드오버(handover)와 같은 네트워크의 기본 기능 수행을 위한 프로세스를 간략하게 할 수 있다. 이러한 기능은 특히 이용자가 많은 자율주행시스템에 서 유용할 수 있다. 또한, 자율주행시스템에서 도로의 단말들은 다량의 작은 패킷을 주기적으로 생성할 수 있다. RAN에서 MEC 서버는 특정 서비스를 수행함으로써, 코어 네트워크로 전달되어야 하는 트래픽의 양을 감소 시킬 수 있으며, 이를 통해 중앙 집중식 클라우드 시스템에서 클라우드의 프로세싱 부담을 줄일 수 있고, 네트 워크의 혼잡을 최소화할 수 있다. 그리고 MEC 서버는 네트워크 제어 기능과 개별적인 서비스들을 통합하며, 이 를 통해 모바일 네트워크 운영자(MNOs: Mobile Network Operators)의 수익성을 높일 수 있으며, 설치 밀도 조정 을 통해 신속하고 효율적인 유지관리 및 업그레이드가 가능하도록 할 수 있다. 도 3은 본 발명의 일 실시 예에 따른 차량의 개략적인 블록도이다. 이하의 설명에서 도 1 및 도 2에 대한 설명 과 중복되는 부분은 그 설명을 생략하기로 한다. 도 3을 참조하면, 통화 음질 향상 시스템이 배치된 차량은, 차량 통신부, 차량 제어부, 차량 사용자 인터페이스부, 운전 조작부, 차량 구동부, 운행부, 센싱부, 차량 저장부 및 처리부를 포함할 수 있다. 실시 예에 따라 차량은 도 3에 도시되고 이하 설명되는 구성요소 외에 다른 구성요소를 포함하거나, 도 3 에 도시되고 이하 설명되는 구성요소 중 일부를 포함하지 않을 수 있다. 본 실시 예에서, 통화 음질 향상 시스템은 동력원에 의해 회전하는 바퀴 및 진행 방향을 조절하기 위한 조향 입력 장치를 구비한 차량에 탑재될 수 있다. 여기서, 차량은 자율 주행 차량일 수 있으며, 차량 사 용자 인터페이스부를 통하여 수신되는 사용자 입력에 따라 자율 주행 모드에서 매뉴얼 모드로 전환되거나 매뉴얼 모드에서 자율 주행 모드로 전환될 수 있다. 아울러, 차량은 주행 상황에 따라 자율 주행 모드에 서 매뉴얼 모드로 전환되거나 매뉴얼 모드에서 자율 주행 모드로 전환될 수 있다. 여기서, 주행 상황은 차량 통 신부에 의해 수신된 정보, 센싱부에 의해 검출된 외부 오브젝트 정보 및 내비게이션부(미도시)에 의해 획득된 내비게이션 정보 중 적어도 어느 하나에 의해 판단될 수 있다. 한편, 본 실시 예에서 차량은 제어를 위해 사용자로부터 서비스 요청(사용자 입력)을 수신할 수 있다. 차 량에서 사용자로부터 서비스 제공 요청을 수신하는 방법은, 사용자로부터 차량 사용 자 인터페이스부에 대한 터치(또는 버튼 입력) 신호를 수신하는 경우, 사용자로부터 서비스 요청에 대응 하는 발화 음성을 수신하는 경우 등을 포함할 수 있다. 이때, 사용자로부터의 터치 신호 수신, 발화 음성 수신 등은 스마트폰(도 1의 30d)에 의해서도 가능할 수 있다. 또한 발화 음성 수신은, 별도 마이크가 구비되어 음성 인식 기능이 실행될 수 있다. 이때 마이크는 본 실시 예의 마이크로폰(도 5의 2)일 수 있다. 차량이 자율 주행 모드로 운행되는 경우, 차량은 주행, 출차, 주차 동작을 제어하는 운행부 의 제어에 따라 운행될 수 있다. 한편, 차량이 매뉴얼 모드로 운행되는 경우, 차량은 운전자의 운 전 조작부를 통한 입력에 의해 운행될 수 있다. 차량 통신부는 외부 장치와 통신을 수행하기 위한 모듈이다. 차량 통신부는 복수 개의 통신 모드에 의한 통신을 지원하고, 서버(도 2의 3000)로부터 서버 신호를 수신하며, 서버로 신호를 송신할 수 있다. 또한 차량 통신부는 타 차량으로부터 신호를 수신하고, 타 차량으로 신호를 송신할 수 있으며, 스마트폰으로부 터 신호를 수신하고, 스마트폰으로 신호를 송신할 수 있다. 즉 외부 장치는 타 차량, 스마트폰, 그리고 서버 시 스템 등을 포함할 수 있다. 또한 여기서, 복수 개의 통신 모드는 타 차량과의 통신을 수행하는 차량 간 통신 모 드, 외부 서버와 통신을 수행하는 서버 통신 모드, 차량 내 스마트폰 등 사용자 단말과 통신을 수행하는 근거리 통신 모드 등을 포함할 수 있다. 즉, 차량 통신부는 무선 통신부(미도시), V2X 통신부(미도시) 및 근거리 통신부(미도시) 등을 포함할 수 있다. 그 외에 차량 통신부는 자차의 위치 정보를 포함하는 신호를 수신하는 위치 정보부를 포함할 수 있다. 위치 정보부는, GPS(Global Positioning System) 모듈 또는 DGPS(Differential Global Positioning System) 모듈을 포함할 수 있다. 무선 통신부는 이동 통신망을 통하여 스마트폰 또는 서버와 상호 신호를 송수신할 수 있다. 여기서, 이동 통신 망은 사용한 시스템 자원(대역폭, 전송 파워 등)을 공유하여 다중 사용자의 통신을 지원할 수 있는 다중 접속 (Multiple access) 시스템이다. 다중 접속 시스템의 예로는, CDMA(Code Division Multiple Access) 시스템, FDMA(Frequency Division Multiple Access) 시스템, TDMA(Time Division Multiple Access) 시스템, OFDMA(Orthogonal Frequency Division Multiple Access) 시스템, SC-FDMA(Single Carrier Frequency Division Multiple Access) 시스템, MC-FDMA(Multi Carrier Frequency Division Multiple Access) 시스템 등이 있다. 또 한 무선 통신부는 차량이 자율 주행 모드로 운행되는 경우, 특정 정보를 5G 네트워크로 전송할 수 있다. 이 때, 특정 정보는 자율 주행 관련 정보를 포함할 수 있다. 자율 주행 관련 정보는, 차량의 주행 제어와 직접 적으로 관련된 정보일 수 있다. 예를 들어, 자율 주행 관련 정보는 차량 주변의 오브젝트를 지시하는 오브젝트 데이터, 맵 데이터(map data), 차량 상태 데이터, 차량 위치 데이터 및 드라이빙 플랜 데이터(driving plan data) 중 하나 이상을 포함할 수 있다. 자율 주행 관련 정보는 자율 주행에 필요한 서비스 정보 등을 더 포함할 수 있다. 예를 들어, 특정 정보는, 스마트폰을 통해 입력된 목적지와 차량의 안정 등급에 관한 정보를 포함할 수 있다. 그리고, 5G 네트워크는 차량의 원격 제어 여부를 결정할 수 있다. 여기서, 5G 네트워크는 자율 주행 관련 원격 제어를 수행하는 서버 또는 모듈을 포함할 수 있다. 그리고, 5G 네트워크는 원격 제어와 관련된 정보 (또는 신호)를 자율 주행 차량으로 전송할 수 있다. 전술한 바와 같이, 원격 제어와 관련된 정보는 자율 주행 차량에 직접적으로 적용되는 신호일 수도 있고, 나아가 자율 주행에 필요한 서비스 정보를 더 포함할 수 있다. V2X 통신부는, 무선 방식으로 V2I 통신 프로토콜을 통해 RSU와 상호 신호를 송수신하고, V2V 통신 프로토콜을 통해 타 차량, 즉 차량으로부터 일정 거리 이내에 근접한 차량과 상호 신호를 송수신하며, V2P 통신 프로토콜을 통해 스마트폰, 즉 보행자 또는 사용자와 상호 신호를 송수신할 수 있다. 즉 V2X 통신부는, 인프라와의 통신(V2I), 차량간 통신(V2V), 스마트폰과의 통신(V2P) 프로토콜이 구현 가능한 RF 회로를 포함할 수 있다. 즉, 차량 통신부는 통신을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 그리고 근거리 통신부는, 예를 들어 운전자의 사용자 단말기와 근거리 무선 통신 모듈을 통해 연결되도록 할 수 있다. 이때 근거리 통신부는 사용자 단말기와 무선 통신뿐만 아니라 유선 통신으로 연결되도록 할 수도 있다. 예를 들어 근거리 통신부는 운전자의 사용자 단말기가 사전에 등록된 경우, 차량으로부터 일정 거리 내 (예를 들어, 차량 내)에서 등록된 사용자 단말기가 인식되면 자동으로 차량과 연결할 수 있다. 즉, 차량 통신부는 근거리 통신(Short range communication), GPS 신호 수신, V2X 통신, 광통신, 방송 송수신 및 ITS(Intelligent Transport Systems) 통신 기능을 수행할 수 있다. 실시 예에 따라, 차량 통신부는 설명 되는 기능 외에 다른 기능을 더 지원하거나, 설명되는 기능 중 일부를 지원하지 않을 수 있다. 차량 통신부 는, 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless- Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 근 거리 통신을 지원할 수 있다. 실시 예에 따라, 차량 통신부의 각 모듈은 차량 통신부 내에 구비된 별도의 프로세서에 의해 전반 적인 동작이 제어될 수 있다. 차량 통신부는 복수 개의 프로세서를 포함하거나, 프로세서를 포함하지 않 을 수도 있다. 차량 통신부에 프로세서가 포함되지 않는 경우, 차량 통신부는, 차량 내 다른 장치의 프로세서 또는 차량 제어부의 제어에 따라, 동작될 수 있다. 또한 차량 통신부는 차량 사용 자 인터페이스부와 함께 차량용 디스플레이 장치를 구현할 수 있다. 이 경우, 차량용 디스플레이 장치는, 텔레매틱스(telematics) 장치 또는 AVN(Audio Video Navigation) 장치로 명명될 수 있다. 한편, 본 실시 예에서 차량 통신부는 통화 음질 향상 시스템이 배치된 차량을 자율주행 모드로 운행하기 위해 연결된 5G 네트워크의 하향 링크 그랜트에 기초하여, 사람의 입술의 특징점들의 위치 변화에 따 라 사람의 발화 여부 및 발화에 따른 음성 신호를 추정하도록 기훈련된 독순(讀脣, lip-reading)용 신경망 모델 을 이용하여 차량 내의 임의의 위치(예를 들어, 근단화자의 위치)를 촬영한 이미지를 기초로 추정한 근단화자의 발화 여부 및 발화에 따른 음성 신호 정보를 수신할 수 있다. 또한 차량 통신부는 5G 네트워크의 하향 링 크 그랜트에 기초하여, 차량의 모델에 따라 차량 주행 동작 중에 차량 내부에서 발생하는 노이즈를 추정 하도록 기훈련된 노이즈 추정용 신경망 모델을 이용하여 추정한 차량의 주행 동작에 따라 차량 내부에서 발생되는 노이즈 정보를 수신할 수 있다. 이때 차량 통신부는 근단화자의 발화 여부 및 발화에 따른 음성 신호 정보와, 차량의 주행 동작에 따라 차량 내부에서 발생되는 노이즈 정보를 5G 네트워크에 연결된 AI 서버로부터 수신할 수 있다. 한편, 도 4는 5G 통신 시스템에서 자율주행 차량과 5G 네트워크의 기본동작의 일 예를 나타낸 도면이다. 차량 통신부는 차량이 자율주행 모드로 운행되는 경우, 특정 정보를 5G 네트워크로 전송할 수 있다 (S1). 이 때, 특정 정보는 자율주행 관련 정보를 포함할 수 있다. 자율주행 관련 정보는, 차량의 주행 제어와 직접적으로 관련된 정보일 수 있다. 예를 들어, 자율주행 관련 정보 는 차량 주변의 오브젝트를 지시하는 오브젝트 데이터, 맵 데이터(map data), 차량 상태 데이터, 차량 위치 데 이터 및 드라이빙 플랜 데이터(driving plan data) 중 하나 이상을 포함할 수 있다. 자율주행 관련 정보는 자율주행에 필요한 서비스 정보 등을 더 포함할 수 있다. 예를 들어, 특정 정보는, 차량 사용자 인터페이스부를 통해 입력된 목적지와 차량의 안전 등급에 관한 정보를 포함할 수 있다. 또한, 5G 네트워크는 차량의 원격 제어 여부를 결정할 수 있다(S2). 여기서, 5G 네트워크는 자율주행 관련 원격 제어를 수행하는 서버 또는 모듈을 포함할 수 있다. 또한, 5G 네트워크는 원격 제어와 관련된 정보(또는 신호)를 자율주행 차량으로 전송할 수 있다(S3). 전술한 바와 같이, 원격 제어와 관련된 정보는 자율주행 차량에 직접적으로 적용되는 신호일 수도 있고, 나아가 자율주행에 필요한 서비스 정보를 더 포함할 수 있다. 본 발명의 일 실시예에서 자율주행 차량은, 5G 네트워크 에 연결된 서버를 통해 주행 경로 상에서 선택된 구간별 보험과 위험 구간 정보 등의 서비스 정보를 수신함으로써, 자율주행과 관련된 서비스를 제공할 수 있다. 이하, 도 5 내지 도 9를 참조하여 자율주행 가능 차량과 5G 네트워크 간의 5G 통신을 위한 필수 과정(예 를 들어, 차량과 5G 네트워크 간의 초기 접속 절차 등)을 개략적으로 설명하면 다음과 같다. 먼저, 5G 통신 시스템에서 수행되는 자율주행 가능 차량과 5G 네트워크를 통한 응용 동작의 일 예는 다음 과 같다. 차량은 5G 네트워크와 초기 접속(Initial access) 절차를 수행한다(초기 접속 단계, S20). 이때, 초기 접 속 절차는 하향 링크(Downlink, DL) 동기 획득을 위한 셀 서치(Cell search) 과정 및 시스템 정보(System information)를 획득하는 과정 등을 포함한다. 또한, 차량은 5G 네트워크와 임의 접속(Random access) 절차를 수행한다(임의 접속 단계, S21). 이때, 임 의 접속 절차는 상향 링크(Uplink, UL) 동기 획득 과정 또는 UL 데이터 전송을 위한 프리엠블 전송 과정, 임의 접속 응답 수신 과정 등을 포함한다. 한편, 5G 네트워크는 자율주행 가능 차량으로 특정 정보의 전송을 스케쥴링 하기 위한 UL 그랜트(Uplink grant)를 전송한다(UL 그랜트 수신 단계, S22). 차량이 UL 그랜트를 수신하는 절차는 5G 네트워크로 UL 데이터의 전송을 위해 시간/주파수 자원을 배정받 는 스케줄링 과정을 포함한다. 또한, 자율주행 가능 차량은 UL 그랜트에 기초하여 5G 네트워크로 특정 정보를 전송할 수 있다(특정 정보 전송 단계, S23). 한편, 5G 네트워크는 차량으로부터 전송된 특정 정보에 기초하여 차량의 원격 제어 여부를 결정할 수 있다(차량의 원격 제어 여부 결정 단계, S24). 또한, 자율주행 가능 차량은 5G 네트워크로부터 기 전송된 특정 정보에 대한 응답을 수신하기 위해 물리 하향링크 제어 채널을 통해 DL 그랜트를 수신할 수 있다(DL 그랜트 수신 단계, S25). 이후에, 5G 네트워크는 DL 그랜트에 기초하여 자율주행 가능 차량으로 원격 제어와 관련된 정보(또는 신 호)를 전송할 수 있다(원격 제어와 관련된 정보 전송 단계, S26). 한편, 앞서 자율주행 가능 차량과 5G 네트워크의 초기 접속 과정 및/또는 임의 접속 과정 및 하향링크 그 랜트 수신 과정이 결합된 절차를 예시적으로 설명하였지만, 본 발명은 이에 한정되지 않는다. 예를 들어, 초기 접속 단계, UL 그랜트 수신 단계, 특정 정보 전송 단계, 차량의 원격 제어 여부 결정 단계 및 원격 제어와 관련된 정보 전송 단계를 통해 초기 접속 과정 및/또는 임의접속 과정을 수행할 수 있다. 또한, 예 를 들어 임의 접속 단계, UL 그랜트 수신 단계, 특정 정보 전송 단계, 차량의 원격 제어 여부 결정 단계, 원격 제어와 관련된 정보 전송 단계를 통해 초기접속 과정 및/또는 임의 접속 과정을 수행할 수 있다. 또한, 특정 정 보 전송 단계, 차량의 원격 제어 여부 결정 단계, DL 그랜트 수신 단계, 원격 제어와 관련된 정보 전송 단계를 통해, AI 동작과 DL 그랜트 수신 과정을 결합한 방식으로 자율주행 가능 차량의 제어가 이루어질 수 있다. 또한, 앞서 기술한 자율주행 가능 차량의 동작은 예시적인 것이 불과하므로, 본 발명은 이에 한정되지 않 는다. 예를 들어, 자율주행 가능 차량의 동작은, 초기 접속 단계, 임의 접속 단계, UL 그랜트 수신 단계 또는 DL 그랜트 수신 단계가, 특정 정보 전송 단계 또는 원격 제어와 관련된 정보 전송 단계와 선택적으로 결합되어 동작할 수 있다. 아울러, 자율주행 가능 차량의 동작은, 임의 접속 단계, UL 그랜트 수신 단계, 특정 정 보 전송 단계 및 원격 제어와 관련된 정보 전송 단계로 구성될 수도 있다. 한편, 자율주행 가능 차량의 동작은, 초기 접속 단계, 임의 접속 단계, 특정 정보 전송 단계 및 원격 제어와 관련된 정보 전송 단계로 구성 될 수 있다. 또한, 자율주행 가능 차량의 동작은, UL 그랜트 수신 단계, 특정 정보 전송 단계, DL 그랜트 수신 단계 및 원격 제어와 관련된 정보 전송 단계로 구성될 수 있다. 도 6에 도시된 바와 같이, 자율주행 모듈을 포함하는 차량은 DL 동기 및 시스템 정보를 획득하기 위해 SSB(Synchronization Signal Block)에 기초하여 5G 네트워크와 초기 접속 절차를 수행할 수 있다(초기 접속 단 계, S30).또한, 자율주행 가능 차량은 UL 동기 획득 및/또는 UL 전송을 위해 5G 네트워크와 임의 접속 절차를 수행 할 수 있다(임의 접속 단계, S31). 한편, 자율주행 가능 차량은 특정 정보를 전송하기 위해 5G 네트워크로부터 UL 그랜트를 수신할 수 있다 (UL 그랜트 수신 단계, S32). 또한, 자율주행 가능 차량은 UL 그랜트에 기초하여 특정 정보를 5G 네트워크로 전송한다(특정 정보 전송 단계, S33). 또한, 자율주행 가능 차량은 특정 정보에 대한 응답을 수신하기 위한 DL 그랜트를 5G 네트워크로부터 수 신한다(DL 그랜트 수신 단계, S34). 또한, 자율주행 가능 차량은 원격 제어와 관련된 정보(또는 신호)를 DL 그랜트에 기초하여 5G 네트워크로 부터 수신한다(원격 제어 관련 정보 수신 단계, S35). 초기 접속 단계에 빔 관리(Beam Management, BM) 과정이 추가될 수 있으며, 임의 접속 단계에 PRACH(Physical Random Access CHannel) 전송과 관련된 빔 실패 복구(Beam failure recovery) 과정이 추가될 수 있으며, UL 그 랜트 수신 단계에 UL 그랜트를 포함하는 PDCCH(Physical Downlink Control CHannel)의 빔 수신 방향과 관련하 여 QCL(Quasi Co-Located) 관계가 추가될 수 있으며, 특정 정보 전송 단계에 특정 정보를 포함하는 PUCCH/PUSCH(Physical Uplink Shared CHannel)의 빔 전송 방향과 관련하여 QCL 관계가 추가될 수 있다. 또한, DL 그랜트 수신 단계에 DL 그랜트를 포함하는 PDCCH의 빔 수신 방향과 관련하여 QCL 관계가 추가될 수 있다. 도 7에 도시된 바와 같이, 자율주행 가능 차량은 DL 동기 및 시스템 정보를 획득하기 위해 SSB에 기초하 여 5G 네트워크와 초기 접속 절차를 수행한다(초기 접속 단계, S40). 또한, 자율주행 가능 차량은 UL 동기 획득 및/또는 UL 전송을 위해 5G 네트워크와 임의 접속 절차를 수행 한다(임의 접속 단계, S41). 또한, 자율주행 가능 차량은 설정된 그랜트(Configured grant)에 기초하여 특정 정보를 5G 네트워크로 전 송한다(UL 그랜트 수신 단계, S42). 즉, 상기 5G 네트워크로부터 UL 그랜트를 수신하는 과정 대신, 설정된 그랜 트를 수신할 수 있다. 또한, 자율주행 가능 차량은 원격 제어와 관련된 정보(또는 신호)를 설정 그랜트에 기초하여 5G 네트워크 로부터 수신한다(원격 제어 관련 정보 수신 단계, S43). 도 8에 도시된 바와 같이, 자율주행 가능 차량은 DL 동기 및 시스템 정보를 획득하기 위해 SSB에 기초하 여 5G 네트워크와 초기 접속 절차를 수행할 수 있다(초기 접속 단계, S50). 또한, 자율주행 가능 차량은 UL 동기 획득 및/또는 UL 전송을 위해 5G 네트워크와 임의 접속 절차를 수행 한다(임의 접속 단계, S51). 또한, 자율주행 가능 차량은 5G 네트워크로부터 DL 선점(Downlink Preemption) IE(Information Elemen t)를 수신한다(DL 선점 IE 수신, S52). 또한, 자율주행 가능 차량은 DL 선점 IE에 기초하여 선점 지시를 포함하는 DCI(Downlink Control Information) 포맷 2_1을 5G 네트워크로부터 수신한다(DCI 포맷 2_1 수신 단계, S53). 또한, 자율주행 가능 차량은 선점 지시(Pre-emption indication)에 의해 지시된 자원(PRB 및/또는 OFDM 심볼)에서 eMBB 데이터의 수신을 수행(또는 기대 또는 가정)하지 않는다(eMBB 데이터의 수신 미수행 단계, S54). 또한, 자율주행 가능 차량은 특정 정보를 전송하기 위해 5G 네트워크로 UL 그랜트를 수신한다(UL 그랜트 수신 단계, S55). 또한, 자율주행 가능 차량은 UL 그랜트에 기초하여 특정 정보를 5G 네트워크로 전송한다(특정 정보 전송 단계, S56). 또한, 자율주행 가능 차량은 특정 정보에 대한 응답을 수신하기 위한 DL 그랜트를 5G 네트워크로부터 수 신한다(DL 그랜트 수신 단계, S57). 또한, 자율주행 가능 차량은 원격제어와 관련된 정보(또는 신호)를 DL 그랜트에 기초하여 5G 네트워크로 부터 수신한다(원격 제어 관련 정보 수신 단계, S58). 도 9에 도시된 바에 의하면, 자율주행 가능 차량은 DL 동기 및 시스템 정보를 획득하기 위해 SSB에 기초 하여 5G 네트워크와 초기 접속 절차를 수행한다(초기 접속 단계, S60). 또한, 자율주행 가능 차량은 UL 동기 획득 및/또는 UL 전송을 위해 5G 네트워크와 임의 접속 절차를 수행 한다(임의 접속 단계, S61). 또한, 자율주행 가능 차량은 특정 정보를 전송하기 위해 5G 네트워크로 UL 그랜트를 수신한다(UL 그랜트 수신 단계, S62). UL 그랜트는 특정 정보의 전송이 반복적으로 이루어지는 경우, 그 반복 횟수에 대한 정보를 포함하고, 특정 정 보는 반복 횟수에 대한 정보에 기초하여 반복하여 전송된다(특정 정보 반복 전송 단계, S63). 또한, 자율주행 가능 차량은 UL 그랜트에 기초하여 특정 정보를 5G 네트워크로 전송한다. 또한, 특정 정보의 반복 전송은 주파수 호핑을 통해 수행되고, 첫 번째 특정 정보의 전송은 제 1 주파수 자원에 서, 두 번째 특정 정보의 전송은 제 2 주파수 자원에서 전송될 수 있다. 특정 정보는 6RB(Resource Block) 또는 1RB(Resource Block)의 협대역(Narrowband)을 통해 전송될 수 있다. 또한, 자율주행 가능 차량은 특정 정보에 대한 응답을 수신하기 위한 DL 그랜트를 5G 네트워크로부터 수 신한다(DL 그랜트 수신 단계, S64). 또한, 자율주행 가능 차량은 원격제어와 관련된 정보(또는 신호)를 DL 그랜트에 기초하여 5G 네트워크로 부터 수신한다(원격 제어 관련 정보 수신 단계, S65). 앞서 기술한 5G 통신 기술은 도 1 내지 도 17에서 후술할 본 명세서에서 제안하는 실시예와 결합되어 적용될 수 있으며, 또는 본 명세서에서 제안하는 실시예의 기술적 특징을 구체화하거나 명확하게 하는데 보충될 수 있다. 차량은 통신망을 통해 외부 서버에 연결되고, 자율주행 기술을 이용하여 운전자 개입 없이 미리 설정된 경로를 따라 이동 가능하다. 본 실시 예에서, 사용자는 운전자, 탑승자 또는 스마트폰(사용자 단말기)의 소유자 로 해석될 수 있다. 차량 사용자 인터페이스부는 차량과 차량 이용자와의 소통을 위한 것으로, 이용자의 입력 신호를 수신하고, 수신된 입력 신호를 차량 제어부로 전달하며, 차량 제어부의 제어에 의해 이용자에게 차 량이 보유하는 정보를 제공할 수 있다. 차량 사용자 인터페이스부는 입력모듈, 내부 카메라, 생체 감지 모듈 및 출력 모듈을 포함할 수 있으나 이에 한정되지 않는다. 입력 모듈은, 사용자로부터 정보를 입력 받기 위한 것으로, 입력 모듈에서 수집한 데이터는, 차량 제어부(120 0)에 의해 분석되어, 사용자의 제어 명령으로 처리될 수 있다. 입력 모듈은, 사용자로부터 차량의 목적지 를 입력 받아 차량 제어부로 제공할 수 있다. 또한 입력 모듈은, 사용자의 입력에 따라 센싱부의 복수 개의 센서 모듈 중 적어도 하나의 센서 모듈을 지정하여 비활성화하는 신호를 차량 제어부로 입력할 수 있다. 입력 모듈은, 차량 내부에 배치될 수 있다. 예를 들면, 입력 모듈은, 스티어링 휠(Steering wheel)의 일 영역, 인스투루먼트 패널(Instrument panel)의 일 영역, 시트(Seat)의 일 영역, 각 필러(Pillar)의 일 영역, 도어(Door)의 일 영역, 센타 콘솔(Center console)의 일 영역, 헤드 라이닝(Head lining)의 일 영역, 썬 바이저(Sun visor)의 일 영역, 윈드 쉴드(Windshield)의 일 영역 또는 창문(Window)의 일 영역 등에 배치될 수 있다. 특히 본 실시 예에서, 입력 모듈은 차량에 연결된 스마트폰으로 통화 시, 차량 내 음향 신호 를 수집하는 마이크로폰(도 12의 2)과, 차량 내부, 특히 근단화자의 안면부를 촬영하기 위한 카메라(도 12의 4)를 포함할 수 있다. 이때 마이크로폰 및 카메라의 위치 및 구현 방법은 한정되지 않는다. 출력 모듈은, 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것이다. 출력 모듈은, 음향 또는 이미 지를 출력할 수 있다. 또한 출력 모듈은, 디스플레이 모듈, 음향 출력 모듈 및 햅틱 출력 모듈 중 적어도 어느 하나를 포함할 수 있다. 디스플레이 모듈은, 다양한 정보에 대응되는 그래픽 객체를 표시할 수 있다. 디스플레이 모듈은 액정 디스플레 이(Liquid Crystal Display, LCD), 박막 트랜지스터 액정 디스플레이(Thin Film Transistor Liquid Crystal Display, TFT LCD), 유기 발광 다이오드(Organic Light-Emitting Diode, OLED), 플렉서블 디스플레이(Flexible display), 삼차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할수 있다. 디스플레이 모듈은 터치 입력 모듈과 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스 크린을 구현할 수 있다. 또한 디스플레이 모듈은 HUD(Head Up Display)로 구현될 수 있다. 디스플레이 모듈이 HUD로 구현되는 경우, 디스플레이 모듈은 투사 모듈을 구비하여 윈드 쉴드 또는 창문에 투사되는 이미지를 통해 정보를 출력할 수 있다. 디스플레이 모듈은, 투명 디스플레이를 포함할 수 있다. 투명 디스플레이는 윈드 쉴드 또는 창문에 부착될 수 있다. 투명 디스플레이는 소정의 투명도를 가지면서, 소정의 화면을 표시할 수 있다. 투 명 디스플레이는, 투명도를 가지기 위해, 투명 디스플레이는 투명 TFEL(Thin Film Elecroluminescent), 투명 OLED(Organic Light-Emitting Diode), 투명 LCD(Liquid Crystal Display), 투과형 투명디스플레이, 투명 LED(Light Emitting Diode) 디스플레이 중 적어도 하나를 포함할 수 있다. 투명 디스플레이의 투명도는 조절될 수 있다. 차량 사용자 인터페이스부는 복수 개의 디스플레이 모듈을 포함할 수 있다. 디스플레이 모듈은, 스티어링 휠의 일 영역, 인스투루먼트 패널의 일 영역, 시트의 일 영역, 각 필러의 일 영역, 도어의 일 영역, 센타 콘솔의 일 영역, 헤드 라이닝의 일 영역, 썬 바이저의 일 영역에 배치되거나, 윈드 쉴드의 일영역, 창문의 일영역에 구현될 수 있다. 음향 출력 모듈은, 차량 제어부로부터 제공되는 전기 신호를 오디오 신호로 변환하여 출력할 수 있다. 이 를 위해, 음향 출력 모듈은, 하나 이상의 스피커를 포함할 수 있다. 특히 본 실시 예에서, 음향 출력 모듈은 차 량에 연결된 스마트폰으로 통화 시, 원단화자로부터의 음성 신호를 출력하기 위한 스피커(도 12의 3)를 포함할 수 있다. 이때 스피커의 위치 및 구현 방법은 한정되지 않는다. 햅틱 출력 모듈은, 촉각적인 출력을 발생시킨다. 예를 들면, 햅틱 출력 모듈은, 스티어링 휠, 안전 벨트, 시트 를 진동시켜, 사용자가 출력을 인지할 수 있게 동작할 수 있다. 운전 조작부는 운전을 위한 사용자 입력을 수신할 수 있다. 메뉴얼 모드인 경우, 차량은 운전 조작 부에 의해 제공되는 신호에 기초하여 운행될 수 있다. 즉, 운전 조작부는 매뉴얼 모드에 있어서 차 량의 운행을 위한 입력을 수신하고, 조향 입력 모듈, 가속 입력 모듈 및 브레이크 입력 모듈을 포함할 수 있으나 이에 한정되지 않는다. 차량 구동부는 차량 내 각종 장치의 구동을 전기적으로 제어하고, 파워 트레인 구동 모듈, 샤시 구 동 모듈, 도어/윈도우 구동 모듈, 안전 장치 구동 모듈, 램프 구동 모듈 및 공조 구동 모듈을 포함할 수 있으나 이에 한정되지 않는다. 운행부는 차량의 각종 운행을 제어할 수 있으며, 특히 자율 주행 모드에서 차량의 각종 운행 을 제어할 수 있다. 운행부는 주행 모듈, 출차 모듈 및 주차 모듈을 포함할 수 있으나, 이에 한정되지 않 는다. 운행부는 차량 제어부의 제어를 받는 프로세서를 포함할 수 있다. 운행부의 각 모듈은, 각각 개별적으로 프로세서를 포함할 수 있다. 실시 예에 따라, 운행부가 소프트웨어적으로 구현 되는 경우, 차량 제어부의 하위 개념일 수도 있다. 이때, 주행 모듈은 차량의 주행을 수행할 수 있다. 주행 모듈은, 센싱부로부터 오브젝트 정보를 제 공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량의 주행을 수행할 수 있다. 주행 모듈은 차량 통신 부를 통해, 외부 디바이스로부터 신호를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량 의 주행을 수행할 수 있다. 출차 모듈은 차량의 출차를 수행할 수 있다. 출차 모듈은 내비게이션 모듈로 부터 내비게이션 정보를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량의 출차를 수행할 수 있 다. 또한 출차 모듈은, 센싱부로부터 오브젝트 정보를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량의 출차를 수행할 수 있다. 그리고 출차 모듈은 차량 통신부를 통해, 외부 디바이스 로부터 신호를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량의 출차를 수행할 수 있다. 주차 모듈은 차량의 주차를 수행할 수 있다. 주차 모듈은 내비게이션 모듈로부터 내비게이션 정보를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량의 주차를 수행할 수 있다. 또한 주차 모듈은 센싱부(170 0)로부터 오브젝트 정보를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량의 주차를 수행할 수 있다. 그리고 주차 모듈은 차량 통신부를 통해, 외부 디바이스로부터 신호를 제공받아, 차량 구동 모듈에 제어 신호를 제공하여, 차량의 주차를 수행할 수 있다. 내비게이션 모듈은 차량 제어부에 내비게이 션 정보를 제공할 수 있다. 내비게이션 정보는 맵(map) 정보, 설정된 목적지 정보, 목적지 설정 따른 경로 정보, 경로 상의 다양한 오브젝트에 대한 정보, 차선 정보 및 차량의 현재 위치 정보 중 적어도 어느 하나를 포 함할 수 있다. 내비게이션 모듈은, 차량이 진입한 주차장의 주차장 지도를 차량 제어부에 제공할 수 있다. 차량 제어부는, 차량이 주차장에 진입한 경우, 내비게이션 모듈로부터 주차장 지도를 제 공받고, 산출된 이동 경로 및 고정 식별 정보를 제공된 주차장 지도에 투영하여 지도 데이터를 생성할 수 있다.내비게이션 모듈은, 메모리를 포함할 수 있다. 메모리는 내비게이션 정보를 저장할 수 있다. 내비게이션 정보는 차량 통신부를 통해 수신된 정보에 의하여 갱신될 수 있다. 내비게이션 모듈은, 내장 프로세서에 의해 제 어될 수도 있고, 외부 신호, 예를 들면, 차량 제어부로부터 제어 신호를 입력 받아 동작할 수 있으나 이 에 한정되지 않는다. 운행부의 주행 모듈은 내비게이션 모듈로부터 내비게이션 정보를 제공받아, 차량 구 동 모듈에 제어 신호를 제공하여, 차량의 주행을 수행할 수 있다. 센싱부는 차량에 장착된 센서를 이용하여 차량의 상태를 센싱, 즉, 차량의 상태에 관 한 신호를 감지하고, 감지된 신호에 따라 차량의 이동 경로 정보를 획득할 수 있다. 센싱부는, 획 득된 이동 경로 정보를 차량 제어부에 제공할 수 있다. 또한 센싱부는 차량에 장착된 센서를 이용하여 차량 주변의 오브젝트 등을 센싱 할 수 있다. 또한, 센싱부는 차량 외부에 위치하는 오브젝트를 검출하기 위한 것으로, 센싱 데이터에 기초하여 오브젝트 정보를 생성하고, 생성된 오브젝트 정보를 차량 제어부로 전달할 수 있다. 이때, 오브젝트는 차 량의 운행과 관련된 다양한 물체, 예를 들면, 차선, 타 차량, 보행자, 이륜차, 교통 신호, 빛, 도로, 구 조물, 과속 방지턱, 지형물, 동물 등을 포함할 수 있다. 센싱부는 복수 개의 센서 모듈로서, 복수개의 촬 상부로서의 카메라 모듈, 라이다(LIDAR: Light Imaging Detection and Ranging), 초음파 센서, 레이다(RADAR: Radio Detection and Ranging) 및 적외선 센서를 포함할 수 있다. 센싱부는 복수 개의 센서 모듈을 통하여 차량 주변의 환경 정보를 센싱 할 수 있다. 실시 예에 따 라, 센싱부는 설명되는 구성 요소 외에 다른 구성 요소를 더 포함하거나, 설명되는 구성 요소 중 일부를 포함하지 않을 수 있다. 레이다는, 전자파 송신 모듈, 수신 모듈을 포함할 수 있다. 레이다는 전파 발사 원리상 펄스 레이다(Pulse Radar) 방식 또는 연속파 레이다(Continuous Wave Radar) 방식으로 구현될 수 있다. 레이다 는 연속파 레이다 방식 중에서 신호 파형에 따라 FMCW(Frequency Modulated Continuous Wave)방식 또는 FSK(Frequency Shift Keying) 방식으로 구현될 수 있다. 레이다는 전자파를 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오 브젝트와의 거리 및 상대 속도를 검출할 수 있다. 레이다는, 차량의 전방, 후방 또는 측방에 위치하는 오브젝트 를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 라이다는, 레이저 송신 모듈, 수신 모듈을 포함할 수 있다. 라이다는, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식으로 구현될 수 있다. 라이다는, 구동식 또는 비구동식으로 구현될 수 있다. 구동식으 로 구현되는 경우, 라이다는, 모터에 의해 회전되며, 자차 주변의 오브젝트를 검출할 수 있고, 비구동식 으로 구현되는 경우, 라이다는, 광 스티어링에 의해, 차량을 기준으로 소정 범위 내에 위치하는 오브젝트 를 검출할 수 있다. 차량은 복수 개의 비구동식 라이다를 포함할 수 있다. 라이다는, 레이저 광 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오 브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 라이다는, 차량의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 촬상부는 차량 외부 이미지를 획득하기 위해, 차량의 외부의 적절한 곳, 예를 들면, 차량의 전방, 후방, 우측 사이드 미러, 좌측 사이드 미러에 위치할 수 있다. 촬상부는, 모노 카메라일 수 있으나, 이에 한정되지 않으며, 스테레오 카메라, AVM(Around View Monitoring) 카메라 또는 360도 카메라일 수 있다. 촬상부는, 차량 전방의 이미지를 획득하기 위해, 차량의 실내에서, 프런트 윈드 쉴드에 근접하게 배치될 수 있다. 또는, 촬상부는, 프 런트 범퍼 또는 라디에이터 그릴 주변에 배치될 수 있다. 촬상부는, 차량 후방의 이미지를 획득하기 위해, 차량 의 실내에서, 리어 글라스에 근접하게 배치될 수 있다. 또는, 촬상부는, 리어 범퍼, 트렁크 또는 테일 게이트 주변에 배치될 수 있다. 촬상부는, 차량 측방의 이미지를 획득하기 위해, 차량의 실내에서 사이드 창문 중 적어 도 어느 하나에 근접하게 배치될 수 있다. 또한, 촬상부는 휀더 또는 도어 주변에 배치될 수 있다. 초음파 센서는, 초음파 송신 모듈, 수신 모듈을 포함할 수 있다. 초음파 센서는, 초음파를 기초로 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 초음파 센서는, 차량의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 적외선 센서는, 적외선 송신 모듈, 수신 모듈을 포함할 수 있다. 적외선 센서는, 적외선 광을 기초로 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 적 외선 센서는, 차량의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 차량 제어부는 센싱부의 각 모듈의 전반적인 동작을 제어할 수 있다. 차량 제어부는, 레이다, 라이다, 초음파 센서 및 적외선 센서에 의해 센싱된 데이터와 기 저장된 데이터를 비교하여, 오브젝트 를 검출하거나 분류할 수 있다. 차량 제어부는 획득된 이미지에 기초하여, 오브젝트를 검출하고, 트래킹 할 수 있다. 차량 제어부는 이미지 처리 알고리즘을 통해, 오브젝트와의 거리 산출, 오브젝트와의 상대 속도 산출 등의 동작을 수행할 수 있다. 예를 들면, 차량 제어부는 획득된 이미지에서, 시간에 따른 오브 젝트 크기의 변화를 기초로, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 또한 예를 들면, 차 량 제어부는 핀홀(pin hole) 모델, 노면 프로파일링 등을 통해, 오브젝트와의 거리 정보 및 상대 속도 정 보를 획득할 수 있다. 차량 제어부는 송신된 전자파가 오브젝트에 반사되어 되돌아오는 반사 전자파에 기 초하여, 오브젝트를 검출하고, 트래킹할 수 있다. 차량 제어부는 전자파에 기초하여, 오브젝트와의 거리 산출, 오브젝트와의 상대 속도 산출 등의 동작을 수행할 수 있다. 차량 제어부는 송신된 레이저가 오브젝트에 반사되어 되돌아오는 반사 레이저 광에 기초하여, 오브젝트를 검출하고, 트래킹 할 수 있다. 차량 제어부는 레이저 광에 기초하여, 오브젝트와의 거리 산출, 오브젝트 와의 상대 속도 산출 등의 동작을 수행할 수 있다. 그리고 차량 제어부는 송신된 초음파가 오브젝트에 반 사되어 되돌아오는 반사 초음파에 기초하여, 오브젝트를 검출하고, 트래킹 할 수 있다. 차량 제어부는 초 음파에 기초하여, 오브젝트와의 거리 산출, 오브젝트와의 상대 속도 산출 등의 동작을 수행할 수 있다. 또한 차 량 제어부는 송신된 적외선 광이 오브젝트에 반사되어 되돌아오는 반사 적외선 광에 기초하여, 오브젝트 를 검출하고, 트래킹 할 수 있다. 차량 제어부는 적외선 광에 기초하여, 오브젝트와의 거리 산출, 오브젝 트와의 상대 속도 산출 등의 동작을 수행할 수 있다. 실시 예에 따라, 센싱부는 차량 제어부와 별 도의 프로세서를 내부에 포함할 수 있다. 또한, 레이다, 라이다, 초음파 센서 및 적외선 센서 각각 개별적으로 프로세서를 포함할 수 있다. 센싱부에 프로세서가 포함된 경우, 센싱부는 차량 제어부의 제 어를 받는 프로세서의 제어에 따라, 동작될 수 있다. 한편, 센싱부는 자세 센서(예를 들면, 요 센서(yaw sensor), 롤 센서(roll sensor), 피치 센서(pitch sensor)), 충돌 센서, 휠 센서(wheel sensor), 속도 센서, 경사 센서, 중량 감지 센서, 헤딩 센서(heading sensor), 자이로 센서(gyro sensor), 포지션 모듈(position module), 차량 전진/후진 센서, 배터리 센서, 연료 센서, 타이어 센서, 핸들 회전에 의한 스티어링 센서, 차량 내부 온도 센서, 차량 내부 습도 센서, 초음파 센서, 조도 센서, 가속 페달 포지션 센서, 브레이크 페달 포지션 센서, 등을 포함할 수 있다. 센싱부는, 차량 자세 정보, 차량 충돌 정보, 차량 방향 정보, 차량 위치 정보(GPS 정보), 차량 각도 정보, 차량 속도 정보, 차량 가속도 정보, 차량 기울기 정보, 차량 전진/후진 정보, 배터리 정보, 연료 정보, 타이어 정보, 차량 램프 정보, 차량 내부 온도 정보, 차량 내부 습도 정보, 스티어링 휠 회전 각도, 차량 외부 조도, 가속 페달에 가해지는 압력, 브레이크 페달에 가해지는 압력 등에 대한 센싱 신호를 획득할 수 있다. 센싱부는, 그 외, 가속페달센서, 압력센서, 엔진 회전 속도 센서(engine speed sensor), 공기 유량 센서(AFS), 흡기 온도 센 서(ATS), 수온 센서(WTS), 스로틀 위치 센서(TPS), TDC 센서, 크랭크각 센서(CAS), 등을 더 포함할 수 있다. 센 싱부는, 센싱 데이터를 기초로, 차량 상태 정보를 생성할 수 있다. 차량 상태 정보는, 차량 내부에 구비 된 각종 센서에서 감지된 데이터를 기초로 생성된 정보일 수 있다. 차량 상태 정보는, 차량의 자세 정보, 차량 의 속도 정보, 차량의 기울기 정보, 차량의 중량 정보, 차량의 방향 정보, 차량의 배터리 정보, 차량의 연료 정 보, 차량의 타이어 공기압 정보, 차량의 스티어링 정보, 차량 실내 온도 정보, 차량 실내 습도 정보, 페달 포지 션 정보 및 차량 엔진 온도 정보 등을 포함할 수 있다. 차량 저장부는 차량 제어부와 전기적으로 연결된다. 차량 저장부는 통화 음질 향상 시스템 의 각 부에 대한 기본 데이터, 통화 음질 향상 시스템의 각 부의 동작 제어를 위한 제어 데이터, 입출력 되는 데이터를 저장할 수 있다. 본 실시 예에서, 차량 저장부는 차량 제어부가 처리하는 데이터를 일시적 또는 영구적으로 저장하는 기능을 수행할 수 있다. 여기서, 차량 저장부는 자기 저장 매체 (magnetic storage media) 또는 플래시 저장 매체(flash storage media)를 포함할 수 있으나, 본 발명의 범위 가 이에 한정되는 것은 아니다. 이러한 차량 저장부는 내장 메모리 및/또는 외장 메모리를 포함할 수 있 으며, DRAM, SRAM, 또는 SDRAM 등과 같은 휘발성 메모리, OTPROM(one time programmable ROM), PROM, EPROM, EEPROM, mask ROM, flash ROM, NAND 플래시 메모리, 또는 NOR 플래시 메모리 등과 같은 비휘발성 메모리, SSD, CF(compact flash) 카드, SD 카드, Micro-SD 카드, Mini-SD 카드, Xd 카드, 또는 메모리 스틱(memory stick) 등과 같은 플래시 드라이브, 또는 HDD와 같은 저장 장치를 포함할 수 있다. 차량 저장부는 차량 제어부 의 처리 또는 제어를 위한 프로그램 등, 차량 전반의 동작을 위한 다양한 데이터, 특히, 운전자 성 향 정보를 저장할 수 있다. 이때, 차량 저장부는 차량 제어부와 일체형으로 형성되거나, 차량 제어 부의 하위 구성 요소로 구현될 수 있다. 처리부는 근단화자의 음성 신호를 포함한 음향 신호를 수집하고, 입술을 포함한 근단화자의 안면부를 촬 영한 이미지를 획득할 수 있다. 그리고 처리부는 수집된 음향 신호에서 근단화자의 음성 신호를 추출할 수 있는데, 이때 처리부는 스피커로 입력되는 신호에 기초하여 수집된 음향 신호에서의 에코 성분을 필터 링(filter out)할 수 있다. 특히 처리부는 카메라를 통해 촬영된 이미지에 기초하여 근단화자의 입술 움 직임을 판독하여 근단화자의 입술의 움직임에 따라 근단화자의 발화 여부에 대한 신호를 생성할 수 있다. 따라 서 본 실시 예에서는 근단화자의 발화 여부에 대한 신호에 기초하여 최적의 에코 제거 및 노이즈 제거가 가능하 도록 하여 통화 음질을 향상시킬 수 있다. 본 실시 예에서 처리부는 도 3에 도시된 바와 같이 차량 제어 부의 외부에 구비될 수도 있고, 차량 제어부 내부에 구비될 수도 있으며, 도 1의 AI 서버 내부 에 구비될 수도 있다. 차량 제어부는 차량의 전체적인 제어를 수행하는 것으로, 차량 통신부, 차량 사용자 인터페 이스부, 운전 조작부, 센싱부 등을 통해 입력된 정보, 데이터 들을 분석하고 처리하거나, 처 리부에서 분석하고 처리한 결과를 입력 받아 차량 구동부, 운행부를 제어할 수 있다. 또한 차량 제어부는 일종의 중앙처리장치로서 차량 저장부에 탑재된 제어 소프트웨어를 구동하여 차량 주행 제어 장치 전체의 동작을 제어할 수 있다. 도 10은 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템을 설명하기 위한 예시도이다. 이하의 설명에서 도 1 내지 도 9에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 10을 참조하면, 본 실시 예에서, 차량 제어부는 차량 통신부를 통해 차량과 근단화자 (Near-end Speaker), 예를 들어 운전자(Driver)의 스마트폰을 연결하고, 원단화자(Far-end Speaker)의 스마트폰(2000a)과의 통화 연결 시, 차량 사용자 인터페이스부의 음향 출력 모듈, 예를 들어 스피커(Car Speaker)를 통해 원단화자 스마트폰(2000a)에서 출력되는 통화 상대방의 음성(Far-end Speech)을 출력할 수 있 다. 그리고 차량 제어부는 차량 사용자 인터페이스부의 마이크로폰(Car Mic)을 통해 근단화자의 음 성 신호(Near-end Speech)를 포함한 음향 신호(Near-end Speech, Echo, Other Noise Sources)를 수집할 수 있 다. 이때 차량 제어부는 차량 사용자 인터페이스부의 스피커로부터 입력되는 신호에 기초하여 마이 크로폰을 통해 수집된 음향 신호에서의 에코 성분을 필터링 하여 에코를 감소시킬 수 있다. 또한 차량 제어부 는 차량 사용자 인터페이스부의 입력 모듈(예를 들어, 카메라)을 통해 근단화자의 안면부를 촬영하 여 입술 움직임 정보를 획득할 수 있다. 그리고 차량 제어부는 근단화자의 입술 움직임 정보에 기초하여 노이즈 감소 및 노이즈 감소 처리 시 훼손된 근단화자의 음성 신호를 복원하는 과정을 통해 음질이 향상된 음성 (EC/NR output ≒ Near-end Speech)을 원단화자의 스마트폰(2000a)에 출력할 수 있다. 여기서, 차량 제어부 는 프로세서(processor)와 같이 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있다. 여기서, '프로세서(processor)'는, 예를 들어 프로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어 에 내장된 데이터 처리 장치의 일 예로써, 마이크로프로세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application- specific integrated circuit), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 프로세서(Processors), 제어기(Controllers), 마이크로 컨트롤 러(Micro-controllers), FPGA(field programmable gate array) 등의 처리 장치를 망라할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 본 실시 예에서 차량 제어부는 통화 음질 향상 시스템의 근단화자 음성 신호 추출(에코 성분 필터링, 노이즈 감소), 근단화자의 입술 움직임 정보에 기초한 근단화자 발화 여부 추출, 금단화자 음성 신호 복원, 차 량의 모델에 따라 차량 주행 동작 중에 차량 내부에서 발생하는 노이즈 추정, 음성 명령어 획득, 음성 명령어에 대응하는 통화 음질 향상 시스템의 동작 및 사용자 맞춤 동작 등에 대하여 딥러닝(Deep Learning) 등 머신 러닝(machine learning)을 수행할 수 있고, 차량 저장부는, 머신 러닝에 사용되는 데이터, 결과 데이터 등을 저장할 수 있다. 머신 러닝의 일종인 딥러닝(deep learning) 기술은 데이터를 기반으로 다단계로 깊은 수준까지 내려가 학습할 수 있다. 딥러닝은 단계를 높여갈수록 복수의 데이터들로부터 핵심적인 데이터를 추출하는 머신 러닝 알고리즘 의 집합을 나타낼 수 있다. 딥러닝 구조는 인공신경망(ANN)을 포함할 수 있으며, 예를 들어 딥러닝 구조는 CNN(convolutional neural network), RNN(recurrent neural network), DBN(deep belief network) 등 심층신경망(DNN)으로 구성될 수있다. 본 실시 예에 따른 딥러닝 구조는 공지된 다양한 구조를 이용할 수 있다. 예를 들어, 본 발명에 따른 딥 러닝 구조는 CNN, RNN, DBN 등을 포함할 수 있다. RNN은, 자연어 처리 등에 많이 이용되고 있으며, 시간의 흐름 에 따라 변하는 시계열 데이터(time-series data) 처리에 효과적인 구조로 매 순간마다 레이어를 쌓아올려 인공 신경망 구조를 구성할 수 있다. DBN은 딥러닝 기법인 RBM(restricted boltzman machine)을 다층으로 쌓아 구성 되는 딥러닝 구조를 포함할 수 있다. RBM 학습을 반복하여, 일정 수의 레이어가 되면 해당 개수의 레이어를 가 지는 DBN을 구성할 수 있다. CNN은 사람이 물체를 인식할 때 물체의 기본적인 특징들을 추출한 다음 뇌 속에서 복잡한 계산을 거쳐 그 결과를 기반으로 물체를 인식한다는 가정을 기반으로 만들어진 사람의 뇌 기능을 모사한 모델을 포함할 수 있다. 한편, 인공신경망의 학습은 주어진 입력에 대하여 원하는 출력이 나오도록 노드간 연결선의 웨이트(weight)를 조정(필요한 경우 바이어스(bias) 값도 조정)함으로써 이루어질 수 있다. 또한, 인공신경망은 학습에 의해 웨이 트(weight) 값을 지속적으로 업데이트시킬 수 있다. 또한, 인공신경망의 학습에는 역전파(back propagation) 등 의 방법이 사용될 수 있다. 즉 차량 주행 제어 장치에는 인공신경망(artificial neural network)이 탑재될 수 있으며, 즉 차량 제어부 는 인공신경망, 예를 들어, CNN, RNN, DBN 등 심층신경망(deep neural network: DNN)을 포함할 수 있다. 따라서 차량 제어부는 근단화자 음성 신호 추출(에코 성분 필터링, 노이즈 감소), 근단화자의 입술 움직 임 정보에 기초한 근단화자 발화 여부 추출, 금단화자 음성 신호 복원, 차량의 모델에 따라 차량 주행 동작 중 에 차량 내부에서 발생하는 노이즈 추정, 음성 명령어 획득, 음성 명령어에 대응하는 통화 음질 향상 시스템 의 동작 및 사용자 맞춤 동작 등을 위해 심층신경망을 학습할 수 있다. 이러한 인공신경망의 머신 러닝 방법 으로는 자율학습(unsupervised learning)과 지도학습(supervised learning)이 모두 사용될 수 있다. 차량 제어 부는 설정에 따라 학습 후 인공신경망 구조를 업데이트시키도록 제어할 수 있다. 한편, 본 실시 예에서는 미리 훈련된 심층 신경망 학습을 위한 파라미터를 수집할 수 있다. 이때, 심층 신경망 학습을 위한 파라미터는 마이크로폰으로부터 수집된 음향 신호 데이터, 근단화자의 입술 움직임 정보 데이터, 근단화자의 음성신호 데이터, 스피커로부터 입력되는 신호 데이터, 적응 필터 제어 데이터, 차량 모델에 따른 노이즈 정보 데이터 등을 포함할 수 있다. 또한 음성 명령어, 음성 명령어에 대응하는 통화 음질 향상 시스템의 동작 및 사용자 맞춤 동작 데이터를 포함할 수 있다. 다만 본 실시 예에서는 심층 신경망 학습을 위한 파라미터 가 이에 한정되는 것은 아니다. 이때 본 실시 예에서는, 학습 모델을 정교화하기 위해서 실제 사용자가 사용한 데이터를 수집할 수 있다. 즉 본 실시 예에서는 차량 통신부 및 차량 사용자 인터페이스부 등을 통 해 사용자로부터 사용자 데이터를 입력 받을 수 있다. 사용자로부터 사용자 데이터를 입력 받는 경우, 본 실시 예에서는 학습 모델의 결과와 상관없이 입력 데이터를 서버 및/또는 메모리에 저장할 수 있다. 즉 본 실시 예에 서, 통화 음질 향상 시스템은 차량 내 핸즈프리 기능 사용 시 발생되는 데이터를 서버에 저장하여 빅데이터를 구성하고, 서버단에서 딥러닝을 실행하여 관련 파라미터를 통화 음질 향상 시스템 내부에 업데이트하여 점차 정 교해지도록 할 수 있다. 다만 본 실시 예에서는 통화 음질 향상 시스템 또는 차량의 엣지(edge) 단에서 자체적 으로 딥러닝을 실행하여 업데이트를 수행할 수도 있다. 즉 본 실시 예는, 통화 음질 향상 시스템의 초기 설정 또는 차량의 초기 출시 시에는 실험실 조건의 딥러닝 파라미터를 내장하고, 사용자가 차량을 주행할 수록, 즉 사용자가 차량 내 핸즈프리 기능을 사용할수록 누적되는 데이터를 통해 업데이트를 수행할 수 있다. 따라서 본 실시 예에서는 수집한 데이터를 라벨링하여 지도학습을 통한 결과물을 얻을 수 있도록 하며, 이를 통화 음질 향 상 시스템 자체 메모리에 저장하여 진화하는 알고리즘이 완성되도록 할 수 있다. 즉, 통화 음질 향상 시스템은 통화 음질 향상을 위한 데이터들을 수집하여 학습 데이터 세트를 생성하고, 학습 데이터 세트를 기계학습 알고 리즘을 통해 학습시켜서 학습된 모델을 결정할 수 있다. 그리고 통화 음질 향상 시스템은 실제 사용자가 사용한 데이터를 수집하여 서버에서 재 학습시켜서 재 학습된 모델을 생성할 수 있다. 따라서 본 실시 예는, 학습된 모 델로 판단한 후에도 계속 데이터를 수집하고, 기계학습모델을 적용하여 재 학습시켜서, 재 학습된 모델로 성능 을 향상시킬 수 있다. 도 11은 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 학습 방법을 설명하기 위한 개략적인 블록도이 다. 이하의 설명에서 도 1 내지 도 10에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 11을 참조하면, 본 실시 예에서는, 처리부에서 학습을 수행할 수 있다. 처리부는 입력부, 출력부, 러닝 프로세서 및 메모리를 포함할 수 있다. 처리부는 머신 러닝 알고리즘을 이용하여 인공 신경망을 학습시키거나 학습된 인공 신경망을 이용하는 장치, 시스템 또는 서버를 의미할 수 있 다. 여기서, 처리부는 복수의 서버들로 구성되어 분산 처리를 수행할 수도 있고, 5G 네트워크로 정의될 수 있다. 이때, 처리부는 통화 음질 향상 시스템의 일부의 구성으로 포함되어, AI 프로세싱 중 적어도 일부를 함께 수행할 수도 있다. 입력부는 마이크로폰으로부터 수집된 음향 신호 데이터, 근단화자의 입술 움직임 정보 데이터, 근단화자 의 음성신호 데이터, 스피커로부터 입력되는 신호 데이터, 적응 필터 제어 데이터, 차량 모델에 따른 노이즈 정 보 데이터를 입력 데이터로 수신할 수 있다. 러닝 프로세서는 수신된 입력 데이터를, 통화 음질 향상을 위한 제어 데이터를 추출하기 위한 학습 모델 에 적용할 수 있다. 학습 모델은 예를 들어, 사람의 입술의 특징점들의 위치 변화에 따라 사람의 발화 여부 및 발화에 따른 음성 신호를 추정하도록 기훈련된 독순(讀脣, lip-reading)용 신경망 모델, 차량의 모델에 따라 차 량 주행 동작 중에 차량 내부에서 발생하는 노이즈를 추정하도록 기훈련된 노이즈 추정용 신경망 모델 등을 포 함할 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망을 학습시킬 수 있다. 학습 모델은 인공 신경망의 AI 서버(도 1의 20)에 탑재된 상태에서 이용되거나, 외부 장치에 탑재되어 이용될 수도 있다. 출력부는 학습 모델로부터 통화 음질 향상을 위한 에코 제거 데이터, 노이즈 제거 데이터, 근단화자 음성 복원 데이터, 적응필터 제어 데이터 등을 출력할 수 있다. 메모리는 모델 저장부를 포함할 수 있다. 모델 저장부는 러닝 프로세서를 통하여 학습 중인 또는 학습된 모델(또는 인공 신경망)을 저장할 수 있다. 학습 모델은 하드웨어, 소프트웨어 또는 하드웨어 와 소프트웨어의 조합으로 구현될 수 있다. 학습 모델의 일부 또는 전부가 소프트웨어로 구현되는 경우 학습 모 델을 구성하는 하나 이상의 명령어(instruction)는 메모리에 저장될 수 있다. 도 12는 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 개략적인 블록도이고, 도 13은 본 발명의 일 실 시 예에 따른 통화 음질 향상 시스템을 보다 구체적으로 설명하기 위한 블록도이다. 이하의 설명에서 도 1 내지 도 11에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 12를 참조하면, 통화 음질 향상 시스템은 마이크로폰, 스피커, 카메라와, 통화 음질 향상 장치 를 포함할 수 있다. 본 실시 예는, 차량 내 핸즈프리 통화 신(scene)에서 에코 제거 및 노이즈 제어를 수행하여 차량 내 통화 음질 을 개선하고자 하는 것이다. 차량 내 통화 시 에코 제거 및 노이즈 제거가 제대로 수행되지 않으면, 운전자(근 단화자)의 음성 신호에 에코 및 차량 내 잡음(주행잡음, 풍잡음 등)이 혼재되어 상대방(원단화자)에게 상당한 불쾌감을 줄 수 있다. 이에, 본 실시 예에서는 카메라를 통한 립리딩(lip-reading) 기술을 적용하여 에코 제 거 및 노이즈 제거를 수행하여 통화 음질을 향상시킬 수 있도록 할 수 있다. 마이크로폰은 근단화자의 음성 신호를 포함한 음향 신호를 수집하고, 스피커는 원단화자로부터의 음성 신 호를 출력할 수 있다. 그리고 카메라는 입술을 포함한 근단화자의 안면부를 촬영할 수 있다. 이때 마이크로 폰, 스피커 및 카메라는 차량에 기존에 구비된 장치들로 구현 가능할 수 있다. 이때 마이크로폰 , 스피커 및 카메라의 위치는 한정되지 않으나, 마이크로폰 및 스피커는 운전석 측에 구비될 수 있고, 카메라는 운전자의 얼굴을 촬영하기 용이한 위치에 구비될 수 있다. 또한 본 실시 예에서는 근단화자 의 스마트폰에 장착된 마이크로폰 모듈을 통해서도 근단화자의 음성 신호를 포함한 음향 신호를 수집할 수 있으며, 스피커 모듈을 통해서 원단화자로부터의 음성 신호를 출력할 수 있고, 카메라 모듈을 통해서 근단화 자의 안면부를 촬영할 수도 있다. 통화 음질 향상 장치를 보다 구체적으로 살펴보면, 통화 음질 향상 장치는 음향입력부, 통화수신 부, 음향처리부, 영상수신부, 립리딩부 및 주행 노이즈 추정부를 포함할 수 있다. 음향입력부는 마이크로폰을 통해 수집된 근단화자로부터의 음성 신호를 포함하는 음향 신호를 수신할 수 있다. 통화수신부는 스피커를 통해 출력된 원단화자로부터의 음성 신호를 수신할 수 있다. 음향처리부는 음향입력부를 통해 수신된 음향 신호에서 근단화자의 음성 신호를 추출할 수 있다. 그 리고 음향처리부는 통화수신부에 의해 수신된 음성 신호를 기초하여 음향입력부를 통해 수신한 음향 신호에서의 에코 성분을 필터링(filter out)하기 위한 적응 필터 및 적응 필터를 제어하는 필터 제어부를 포함하는 에코 감소 모듈을 포함할 수 있다. 여기서, 필터제어부는 근단화자의 입술 움직임 정보에 기초하여 적응 필터의 파라미터를 변화시킬 수 있으며, 이때 영상수신부는 카메라를 통해 촬영한 입술을 포함한 근단화자의 안면부에 대한 이미지를수신할 수 있다. 즉 필터제어부는 근단화자의 안면부에 대한 이미지에서 추출된 근단화자의 입술 움직임 정보에 기초하여, 근단화자 및 원단화자의 발화 여부에 따라 적응 필터의 파라미터를 변화시킬 수 있다. 이를 보다 구체적으로 설명하기 위하여 도 13을 참조하면, 음향처리부의 에코 감소 모듈은 스피커 에 출력되기 전의 원단화자의 음성 신호(Far-end speech 신호)를 기준 신호(Reference 신호, x)로 하여, 적 응 필터를 통해 차량 내 마이크로폰에서 수집되는 음향 신호에서 에코를 제거(Adaptive Echo Cancellation)할 수 있다. 즉 음향처리부는 스피커에 입력되는 신호(Far-end speech Reference)에 기 초하여 마이크로폰을 통해 수집된 음향 신호(Near-end speech Input)에서의 에코 성분을 필터링하기 위하여 필터제어부로 적응 필터(Adaptive filter, 312)의 파라미터를 변화시킬 수 있다. 이때의 적응 필터 학습방법( )은 다음과 같다."}
{"patent_id": "10-2019-0103031", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이때, 는 적응 필터의 입력 값이고, 는 에러 값(error signal)이며, 는 적응 필터(31 2)의 적응 속도를 조절하는 스텝 사이즈(Step size) 값일 수 있다. 여기서, 는 추정된 에코(echo)와 실제 에코와의 오차일 수 있다. 또한, 는 가변되는 값으로, 의 값에 따라 에코 제거 성능이 달라질 수 있다. 즉, 이때 적응 필터의 파라미터, 즉 적응 속도를 조절하는 스텝 사이즈 값의 설정이 에코 제거 성능에 아 주 큰 영향을 미칠 수 있다. 즉, 음향처리부는 근단화자 및 원단화자의 발화 여부에 대한 4가지의 경우(근 단화자만 발화하는 경우, 원단화자만 발화하는 경우, 근단화자 및 원단화자가 모두 발화하는 경우, 근단화자 및 원단화자가 모두 발화하지 않는 경우)에 따라 적응 필터의 파라미터를 다르게 제어하여 보다 효과적인 에 코 제거가 가능하도록 할 수 있다. 또한 적응 필터의 파라미터 뿐만 아니라 잔여 에코를 제거하는 기술 (Residual Echo Suppression)에서도 근단화자 및 원단화자의 발화 여부에 대한 4가지의 경우에 따라 제거 강도 를 다르게 적용하여야 하므로, 근단화자 및 원단화자의 발화 여부를 정확하게 아는 것은 매우 중요하다. 즉 음 향처리부는 음성 확률 추정(SNR, Speech-to-Noise Ratio)을 통한 VAD(Voice activity detection)와 DTD(Double-talk detector) 두 가지를 혼합하여 AEC(Adaptive Echo Cancellation)를 수행할 때, 마이크로폰 으로 수집되는 음향 신호뿐만 아니라, 카메라를 통한 영상 정보(예를 들어, 립리딩)에 기초하여 근단화자 및 원단화자의 발화 여부를 정확하게 파악(Near-end Speaker VAD)하여야 한다. 또한, 음향처리부는 에코 감소 모듈로부터의 음향 신호에서 노이즈 신호를 감소시키기 위한 노이즈 감소(noise reduction) 모듈과, 근단화자의 입술 움직임 정보에 기초하여, 노이즈 감소 모듈을 통한 노이즈 감소 처리 시 훼손된 근단화자의 음성 신호를 복원(Speech Reconstruction)하기 위한 음성복원부를 포함할 수 있다. 이는 실제 차량 환경에서는 풍잡음과 주행잡음이 매우 심하여, 운전자의 발화보다 더 크게 마 이크로폰으로 들어오는 잡음들을 제거하려 잡음제거 강도를 키우게 되면 운전자의 발화가 심각(Speech distortion)하게 훼손될 수 있기 때문에 근단화자의 음성 신호를 복원하기 위함이다. 즉, 본 실시 예에서는 에 코 감소 모듈로부터의 음향 신호(Echo cancelled signal)에서 노이즈를 판단(Noise Estimation)하고, 노 이즈 감소 처리 시 훼손된 근단화자의 음성 신호(NR Output)를 복원하여, 발화 훼손에 따른 통화 중 불편함을 해소할 수 있도록 할 수 있다. 도 14는 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 입술 움직임 판독 방법을 설명하기 위한 예시도 이다. 이하의 설명에서 도 1 내지 도 13에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 14를 참조하면, 립리딩(lip-reading)부는 카메라를 통해 촬영된 이미지에 기초하여 근단화자의 입술 움직임을 판독하기 위한 립리딩을 수행할 수 있다. 상술한 바와 같이, 통화 음질 향상을 위해서는, 근단화자의 발화 여부를 파악하는 것이 매우 중요하다. 이러한 근단화자의 발화 여부를 마이크로폰으로 수집한 음향 신 호만을 통해 SNR(Speech-to-Noise Ratio)을 추정하여 검출하는 경우, 차량 내 잡음이 우세한 상황에서는 그 성 능이 현저하게 떨어지게 되므로, 본 실시 예에서는 카메라를 활용하여 근단화자의 입술 움직임을 판독하기 위한 이미지를 통해 근단화자의 발화 여부를 정확하게 추정할 수 있다. 즉 립리딩부는 도 14(c)와 같이, 근단화자의 입술의 움직임이 제 1 크기 이상인 경우, 근단화자의 발화가 존재하는 것으로 판단하고, 도 14(a)와 같이, 근단화자의 입술의 움직임이 제 2 크기 미만인 경우, 근단화자의발화가 부존재하는 것으로 판단하여 근단화자의 발화 여부에 대한 신호를 생성할 수 있다. 이때 제 2 크기는 제 1 크기 이하의 값으로 설정될 수 있다. 그리고 립리딩부는 도 14(b)와 같이, 근단화자의 입술의 움직임이 제 1 크기 미만이고 제 2 크기 이상인 경우, 음향 신호에 대해 추정된 SNR(Signal-to-Noise Ratio) 값을 기초로 근단화자의 발화 존재 여부를 판단할 수 있다. 즉 립리딩부는 카메라를 통해 촬영된 이미지(근단화자의 안면부 이미지)에서 입술 부분을 검출하고, 입 술의 특징점(Feature point)들을 매핑한 뒤 미리 학습해 둔 특징점들의 위치에 대한 모델을 사용하여 근단화자 가 발화한지 아닌지 1차적으로 판별할 수 있다. 하지만 상기 도 14(b)와 같이 립리딩 결과가 애매한 경우, 음향 신호에 대해 추정된 SNR 값을 기초로 근단화자의 발화 여부를 최종적으로 판별할 수 있다. 이때 입술 움직임의 크기는 윗입술의 중심 지점과 아랫입술의 중심 지점을 잇는 선의 길이로 산출하거나, 윗입술의 특정 지점들과 이에 대응되는 아랫입술의 특정 지점들을 잇는 복수의 선의 길이의 평균 값으로 산출할 수 있으나, 이에 한정되 지는 않는다. 한편, 립리딩부는 사람의 입술의 특징점들의 위치 변화에 따라 사람의 발화 여부 및 발화에 따른 음성 신 호를 추정하도록 기훈련된 독순(讀脣, lip-reading)용 신경망 모델을 이용하여 카메라를 통해 촬영된 이미지 를 기초로 근단화자의 발화 여부 및 발화에 따른 음성 신호를 추정할 수 있다. 필터제어부는 립리딩부로부터의 근단화자의 발화 여부에 대한 신호 및 스피커로부터 입력되는 신 호에 기초하여, 근단화자만 발화하는 경우에는 적응 필터의 파라미터 값을 제 1 값으로 제어할 수 있다. 또한 필터제어부는 립리딩부로부터의 근단화자의 발화 여부에 대한 신호 및 스피커로부터 입력되 는 신호에 기초하여, 원단화자만 발화하는 경우에는 적응 필터의 파라미터 값을 제 2 값으로 제어할 수 있 다. 또한 필터제어부는 립리딩부로부터의 근단화자의 발화 여부에 대한 신호 및 스피커로부터 입 력되는 신호에 기초하여, 근단화자 및 원단화자 모두 발화하는 경우에는, 적응 필터의 파라미터 값을 제 3 값으로 제어할 수 있고, 근단화자 및 원단화자 모두 발화하지 않는 경우에는 적응 필터의 파라미터 값을 제 4 값으로 제어할 수 있다. 이때, 제 1 내지 제 4 값은 미리 설정될 수 있다. 즉, 음향처리부는 립리딩부로부터 추정된 근단화자의 발화 여부 및 발화에 따른 음성 신호를 기초로 마이크로폰으로부터 수집된 음향 신호에서 근단화자의 음성 신호를 추출할 수 있다. 도 15는 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 음성 복원 방법을 설명하기 위한 개략적인 도면 이다. 이하의 설명에서 도 1 내지 도 14에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 15를 참조하면, 음성복원부는 근단화자만 발화하는 경우의 음향 신호에서 근단화자의 피치 정보를 추출 하고, 피치 정보에 기초하여 근단화자의 발화 특징을 판단할 수 있고, 발화 특징에 기초하여 노이즈 감소 모듈 을 통한 노이즈 감소 처리 시 훼손된 근단화자의 음성 신호를 복원할 수 있다. 즉 음성복원부는 립리 딩부를 통해 근단화자의 발화만 있는 경우를 정확히 알 수 있으므로, 이때의 마이크로폰을 통해 수집된 음향 신호에서 근단화자의 피치 정보를 추출(Pitch Detection)할 수 있다. 즉 본 실시 예에서, 음성복원부(33 0)는 근단화자의 피치 정보를 정확하게 알 수 있으므로, 근단화자의 피치 정보에 기초하여 근단화자의 음성 주 파수(harmonic)들의 주파수 대역(F0)을 파악(Harmonic Estimation)할 수 있다. 이때 음성복원부는 근단화 자 음성의 하모닉 정보에 기초하여, 과도하게 노이즈 제거가 되어 손실된 음성 신호에서 근단화자의 하모닉이 형성되는 주파수 대역만 부스팅(boosting)하여 근단화자의 훼손된 음성 신호를 복원할 수 있다. 이때 본 실시 예에서는, 이러한 기능을 이용하여, 이퀄라이저(Equalizer) 기능도 구현할 수 있도록 하여 차량 내 통화 시 원 단화자가 보다 듣기 편하도록 튜닝(tunning) 할 수 있도록 할 수도 있다. 한편, 통화 음질 향상 시스템은 차량 내에 배치될 수 있으며, 차량의 주행 정보를 수신하여 주행 동작에 따 라 차량 내부에서 발생되는 노이즈 정보를 추정하는 주행 노이즈 추정부를 포함할 수 있다. 이때 노이즈 감소 모듈은 주행 노이즈 추정부로부터 추정된 노이즈 정보에 기초하여 에코 감소 모듈 로부터의 음향 신호에서 노이즈 신호를 감소시킬 수 있다. 주행 노이즈 추정부는 차량의 모델에 따라 차량 주행 동작 중에 차량 내부에서 발생하는 노이즈를 추정하 도록 기훈련된 노이즈 추정용 신경망 모델을 이용하여 차량의 주행 동작에 따라 차량 내부에서 발생되는 노이즈 정보를 추정할 수 있다. 도 16은 본 발명의 일 실시 예에 따른 통화 음질 향상 방법을 도시한 흐름도이다. 이하의 설명에서 도 1 내지 도 15에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다.도 16을 참조하면, S1610단계에서, 통화 음질 향상 장치는 원단화자로부터 음성 신호를 수신한다. 즉 통화 음질 향상 장치는 스피커를 통해 출력된 원단화자로부터의 음성 신호를 수신할 수 있다. S1620단계에서, 통화 음질 향상 장치는 근단화자로부터 음향 신호를 수신한다. 즉 통화 음질 향상 장치(1 1)는 마이크로폰을 통해 수집된 근단화자로부터의 음성 신호를 포함하는 음향 신호를 수신할 수 있다. S1630단계에서, 통화 음질 향상 장치는 근단화자의 안면부 이미지를 수신한다. 즉, 통화 음질 향상 장치 는 카메라를 통해 촬영한 입술을 포함한 근단화자의 안면부에 대한 이미지를 수신할 수 있다. S1640단계에서, 통화 음질 향상 장치는 근단화자의 입술 움직을 판독한다. 즉 통화 음질 향상 장치는 카메라를 통해 촬영된 이미지에 기초하여 근단화자의 입술 움직임을 판독하기 위한 립리딩을 수행할 수 있다. 예를 들어, 통화 음질 향상 장치는 근단화자의 입술의 움직임이 제 1 크기 이상인 경우, 근단화자의 발화가 존재하는 것으로 판단하고, 근단화자의 입술의 움직임이 제 2 크기 미만인 경우, 근단화자의 발화가 부 존재하는 것으로 판단하여 근단화자의 발화 여부에 대한 신호가 생성되도록 할 수 있다. 이때 제 2 크기는 제 1 크기 이하의 값으로 설정될 수 있다. 그리고 통화 음질 향상 장치는 근단화자의 입술의 움직임이 제 1 크기 미만이고 제 2 크기 이상인 경우, 음향 신호에 대해 추정된 SNR(Signal-to-Noise Ratio) 값을 기초로 근단화자 의 발화 존재 여부를 판단할 수 있다. 즉, 통화 음질 향상 장치는 카메라를 통해 촬영된 이미지(근단화 자의 안면부 이미지)에서 입술 부분을 검출하고, 입술의 특징점(Feature point)들을 매핑한 뒤 미리 학습해 둔 특징점들의 위치에 대한 모델을 사용하여 근단화자가 발화한지 아닌지 1차적으로 판별할 수 있다. 하지만 립리 딩 결과가 애매한 경우, 음향 신호에 대해 추정된 SNR 값을 기초로 근단화자의 발화 여부를 최종적으로 판별할 수 있다. 이때 입술 움직임의 크기는 윗입술의 중심 지점과 아랫입술의 중심 지점을 잇는 선의 길이로 산출하거 나, 윗입술의 특정 지점들과 이에 대응되는 아랫입술의 특정 지점들을 잇는 복수의 선의 길이의 평균 값으로 산 출할 수 있으나, 이에 한정되지는 않는다. 한편, 본 실시 예에서 통화 음질 향상 장치는 사람의 입술의 특 징점들의 위치 변화에 따라 사람의 발화 여부 및 발화에 따른 음성 신호를 추정하도록 기훈련된 독순(讀脣, lip-reading)용 신경망 모델을 이용하여 카메라를 통해 촬영된 이미지를 기초로 근단화자의 발화 여부 및 발 화에 따른 음성 신호를 추정할 수 있다. S1650단계에서, 통화 음질 향상 장치는 근단화자의 음성신호를 추출한다. 즉, 통화 음질 향상 장치는 마이크로폰을 통해 수집된 음향 신호를 수신하여, 음향 신호에서 근단화자의 음성 신호를 추출할 수 있다. 그리고 통화 음질 향상 장치는 스피커로 출력되는 음성 신호를 수신하여, 음성 신호를 기초하여 상기 음 향 신호에서의 에코 성분을 필터링(filter out)할 수 있다. 즉 통화 음질 향상 장치는 S1640단계에서 추정 된 근단화자의 발화 여부 및 발화에 따른 음성 신호를 기초로 마이크로폰으로부터 수집된 음향 신호에서 근 단화자의 음성 신호를 추출할 수 있다. 도 17은 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 음성 신호 추출 방법을 설명하기 위해 도시한 흐름도이다. 이하의 설명에서 도 1 내지 도 16에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 17을 참조하면, S1710단계에서, 통화 음질 향상 장치는 근단화자의 입술 움직임에 따라 적응 필터 의 파라미터 값을 결정한다. 즉, 통화 음질 향상 장치는 근단화자의 입술 움직임 정보에 기초하여 적응 필 터의 파라미터를 변화시킬 수 있으며, 근단화자의 안면부에 대한 이미지에서 추출된 근단화자의 입술 움직 임 정보에 기초하여, 근단화자 및 원단화자의 발화 여부에 따라 적응 필터의 파라미터를 변화시킬 수 있다. S1720단계에서, 통화 음질 향상 장치는 원단화자로부터의 음성 신호를 기초로 음향 신호에서의 에코 성분을 필터링 한다. 즉, 통화 음질 향상 장치는 립리딩을 통한 근단화자의 발화 여부에 대한 신호, 및 스피커 로부터 입력되는 신호에 기초하여, 근단화자만 발화하는 경우에는 적응 필터의 파라미터 값을 제 1 값으로 제어할 수 있다. 또한 통화 음질 향상 장치는 립리딩을 통한 근단화자의 발화 여부에 대한 신호, 및 스피커 로부터 입력되는 신호에 기초하여, 원단화자만 발화하는 경우에는 적응 필터의 파라미터 값을 제 2 값 으로 제어할 수 있다. 또한 통화 음질 향상 장치는 립리딩을 통한 근단화자의 발화 여부에 대한 신호, 및 스피커로부터 입력되는 신호에 기초하여, 근단화자 및 원단화자 모두 발화하는 경우에는, 적응 필터의 파라미터 값을 제 3 값으로 제어할 수 있고, 근단화자 및 원단화자 모두 발화하지 않는 경우에는 적응 필터 의 파라미터 값을 제 4 값으로 제어할 수 있다. 즉 통화 음질 향상 장치는 스피커에 입력되는 신호 (Far-end speech Reference)에 기초하여 마이크로폰을 통해 수집된 음향 신호(Near-end speech Input)에서 의 에코 성분을 필터링하기 위하여 필터제어부로 적응 필터(Adaptive filter, 312)의 파라미터를 변화시킬 수 있다. 따라서, 통화 음질 향상 장치는 스피커에 출력되기 전의 원단화자의 음성 신호(Far-end speech신호)를 기준 신호(Reference 신호, x)로 하여, 적응 필터를 통해 차량 내 마이크로폰에서 수집되는 음 향 신호에서 에코를 제거(Adaptive Echo Cancellation)할 수 있다. S1730단계에서, 통화 음질 향상 장치는 필터링 후 출력되는 음향신호에서 노이즈 신호를 감소시킨다. 즉 통 화 음질 향상 장치는 립리딩을 통한 근단화자의 발화 여부에 대한 신호에 기초하여, 근단화자 및/또는 원단 화자의 발화 여부를 확인하고, 근단화자 및/또는 원단화자의 발화가 아닌 노이즈라고 판단되는 음향신호의 노이 즈를 제거할 수 있다. 한편, 본 실시 예는 차량의 주행 정보를 수신하여 주행 동작에 따라 차량 내부에서 발생 되는 노이즈 정보를 추정할 수 있다. 이때 통화 음질 향상 장치는 추정된 노이즈 정보에 기초하여 에코 감 소 모듈로부터의 음향 신호에서 노이즈 신호를 감소시킬 수 있다. 또한 통화 음질 향상 장치는 차량의 모델에 따라 차량 주행 동작 중에 차량 내부에서 발생하는 노이즈를 추정하도록 기훈련된 노이즈 추정용 신경망 모델을 이용하여 차량의 주행 동작에 따라 차량 내부에서 발생되는 노이즈 정보를 추정할 수 있다. S1740단계에서, 통화 음질 향상 장치는 근단화자만 발화하는 경우의 음향 신호에 기초하여 노이즈 신호 감 소 시 훼손된 근단화자의 음성 신호를 복원한다. 즉 실제 차량 환경에서는 풍잡음과 주행잡음이 매우 심하여, 운전자의 발화보다 더 크게 마이크로폰으로 들어오는 잡음들을 제거하려 잡음제거 강도를 키우게 되면 운전 자의 발화가 심각(Speech distortion)하게 훼손될 수 있기 때문에, 본 실시 예에서는 근단화자의 음성 신호를 복원할 수 있다. 다시 말해, 통화 음질 향상 장치는 음향 신호(Echo cancelled signal)에서 노이즈를 판단 (Noise Estimation)하고, 노이즈 감소 처리 시 훼손된 근단화자의 음성 신호(NR Output)를 복원하여, 발화 훼손 에 따른 통화 중 불편함을 해소할 수 있도록 할 수 있다. 이때 통화 음질 향상 장치는 근단화자만 발화하는 경우의 음향 신호에서 근단화자의 피치 정보를 추출하고, 피치 정보에 기초하여 근단화자의 발화 특징을 판단할 수 있고, 발화 특징에 기초하여 노이즈 감소 모듈을 통한 노이즈 감소 처리 시 훼손된 근단화자의 음성 신 호를 복원할 수 있다. 즉 통화 음질 향상 장치는 립리딩을 통해 근단화자의 발화만 있는 경우를 정확히 알 수 있으므로, 이때의 마이크로폰을 통해 수집된 음향 신호에서 근단화자의 피치 정보를 추출(Pitch Detection)할 수 있다. 즉 본 실시 예에서, 음성복원부는 근단화자의 피치 정보를 정확하게 알 수 있으므 로, 근단화자의 피치 정보에 기초하여 근단화자의 음성 주파수(harmonic)들의 주파수 대역(F0)을 파악(Harmonic Estimation)할 수 있다. 이때 통화 음질 향상 장치는 근단화자 음성의 하모닉 정보에 기초하여, 과도하게 노이즈 제거가 되어 손실된 음성 신호에서 근단화자의 하모닉이 형성되는 주파수 대역만 부스팅(boosting)하여 근단화자의 훼손된 음성 신호를 복원할 수 있다. 이상 설명된 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매 체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메 모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 \"상기\"의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하 는 각 개별적인 값을 기재한 것과 같다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다.부호의 설명 1 : AI 시스템 기반 통화 음질 향상 시스템 환경 10 : 클라우드 네트워크(Cloud Network) 20 : AI 서버(AI Server) 30a : 로봇(Robot) 30b : 자율 주행 차량(Self-Driving Vehicle) 30c : XR 장치(XR Device) 30d : 스마트폰(Smartphone) 30e : 가전(Home Appliance )"}
{"patent_id": "10-2019-0103031", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 AI 서버, 자율 주행 차량, 로봇, XR 장치, 스마트폰 또는 가전과, 이들 중 에서 적어도 하나 이상을 서로 연결하는 클라우드 네트워크를 포함하는 AI 시스템 기반 통화 음질 향상 시스템 환경의 예시도이다. 도 2는 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 통신 환경을 개략적으로 설명하기 위하여 도시한 도면이다. 도 3은 본 발명의 일 실시 예에 따른 자율 주행 차량의 개략적인 블록도이다. 도 4는 5G 통신 시스템에서 자율 주행 차량과 5G 네트워크의 기본동작의 일 예를 나타낸다.도 5는 5G 통신 시스템에서 자율 주행 차량과 5G 네트워크의 응용 동작의 일 예를 나타낸다. 도 6 내지 도 9는 5G 통신을 이용한 자율 주행 차량의 동작의 일 예를 나타낸다. 도 10은 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템을 설명하기 위한 예시도이다. 도 11은 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 학습 방법을 설명하기 위한 개략적인 블록도이 다. 도 12는 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 개략적인 블록도이다. 도 13은 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템을 보다 구체적으로 설명하기 위한 블록도이다. 도 14는 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 입술 움직임 판독 방법을 설명하기 위한 예시도 이다. 도 15는 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 음성 복원 방법을 설명하기 위한 개략적인 도면 이다. 도 16은 본 발명의 일 실시 예에 따른 통화 음질 향상 방법을 도시한 흐름도이다. 도 17은 본 발명의 일 실시 예에 따른 통화 음질 향상 시스템의 음성 신호 추출 방법을 설명하기 위해 도시한 흐름도이다."}
