{"patent_id": "10-2017-0167829", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0067663", "출원번호": "10-2017-0167829", "발명의 명칭": "웨어러블 수화통역장치", "출원인": "한국생산기술연구원", "발명자": "최동운"}}
{"patent_id": "10-2017-0167829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자의 몸에 장착되도록 구비된 몸체부;상기 몸체부와 연결된 마이크를 통해 외부에서 발생되는 음성을 인식하는 마이크부;상기 몸체부와 연결된 입력장치를 통해 텍스트를 인식하는 입력장치부;상기 마이크부 또는 입력장치부로부터 인식된 음성 또는 텍스트를 인공지능을 통해 분석하는 음성텍스트분석부;상기 음성텍스트분석부에서 분석된 음성 또는 텍스트를 기반으로 음성 또는 텍스트와 대응되는 수화를 출력하는수화출력부;상기 몸체부에 구비된 카메라를 통해 사용자의 손 움직임을 감지하고, 감지되는 수화를 인식하는 카메라부;상기 카메라부로부터 인식된 수화를 인공지능을 통해 분석하는 수화분석부;상기 수화분석부를 통해 분석된 수화를 기반으로 수화에 대응되는 음성 또는 텍스트를 출력하는 음성텍스트출력부;상기 음성텍스트출력부로부터 수화에 대응되는 음성을 스피커로 출력하는 스피커부; 및상기 음성텍스트출력부로부터 수화에 대응되는 텍스트를 모니터로 출력하는 모니터부;를 포함하는 것을 특징으로 하는 웨어러블 수화통역장치."}
{"patent_id": "10-2017-0167829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 음성텍스트분석부는,상기 마이크부를 통해 인식된 음성에 포함된 잡음을 제거하는 잡음제거부; 및상기 잡음제거부를 통해 잡음이 제거된 음성에 대응되는 수화로 변환하도록 인공지능을 통해 음성을 알고리즘화하는 제 1 음성알고리즘부;상기 입력장치부를 통해 입력된 텍스트와 대응되는 수화로 변환하도록 인공지능을 통해 텍스트를 알고리즘화하는 제 1 텍스트알고리즘부;를 포함하는 것을 특징으로 하는 웨어러블 수화통역장치."}
{"patent_id": "10-2017-0167829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 수화출력부는,상기 제 1 음성알고리즘부 및 상기 제 1 텍스트알고리즘부를 통해 알고리즘화된 음성 또는 텍스트에 기초하여음성 또는 텍스트와 대응되는 수화를 인공지능을 통해 알고리즘화하는 제 1 수화알고리즘부가 구비되고, 상기수화출력부는 상기 제 1 수화알고리즘부를 통해 알고리즘화된 수화를 주위 다수에게 전달하도록 모니터로 출력하는 것을 특징으로 하는 것을 특징으로 하는 웨어러블 수화통역장치."}
{"patent_id": "10-2017-0167829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 수화분석부는,카메라를 통해 감지된 수화에 대응되는 음성 또는 텍스트로 변환하도록 인공지능을 통해 수화를 알고리즘화하는공개특허 10-2019-0067663-3-제 2 수화알고리즘부가 구비된 것을 특징으로 하는 웨어러블 수화통역장치."}
{"patent_id": "10-2017-0167829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 음성텍스트출력부는,상기 제 2 수화알고리즘부를 통해 알고리즘화된 수화에 기초하여 수화내용과 대응되는 음성을 인공지능을 통해알고리즘화하는 제 2 음성알고리즘부; 및상기 제 2 수화알고리즘부를 통해 알고리즘화된 수화에 기초하여 수화내용과 대응되는 텍스트를 인공지능을 통해 알고리즘화하는 제 2 텍스트알고리즘부;를 포함하는 것을 특징으로 하는 웨어러블 수화통역장치."}
{"patent_id": "10-2017-0167829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 제 2 음성알고리즘부는 알고리즘화된 음성을 상기 스피커부를 통해 출력하고, 상기 제2 텍스트알고리즘부는 알고리즘화된 텍스트를 상기 모니터부를 통해 출력하는 것을 특징으로 하는 웨어러블 수화통역장치."}
{"patent_id": "10-2017-0167829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 웨어러블 수화통역장치에 사용되는 인공지능이 딥러닝을 통해 수화 및 음성 또는 텍스트를 군집화하고 분류하여 알고리즘화하도록 딥러닝부가 구비된 것을 특징으로 하는 웨어러블 수화통역장치."}
{"patent_id": "10-2017-0167829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항 내지 제 7항에 따른, 웨어러블 수화통역장치를 통해 사용자의 눈 앞에 장비하여 수화를 인식하고, 통역을 수행하도록 구비된 것을 특징으로 하는 수화통역안경."}
{"patent_id": "10-2017-0167829", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항 내지 제 7항에 따른, 웨어러블 수화통역장치를 통해 사용자의 목이나 귀에 걸어 수화를 인식하고, 통역을 수행하도록 구비된 것을 특징으로 하는 수화통역팬던트."}
{"patent_id": "10-2017-0167829", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 수화통역장치에 관한 것으로, 더욱 상세하게는 음성을 수화로 통역하고, 수화를 음성 또는 텍스트로 통역함으로써, 수화자와 일반인의 의사소통의 불편함을 해소하고, 음성 또는 수화를 인공지능에 의해서 알고리즘 화함으로써, 통역의 정확도를 향상시킬 수 있으며, 소수의 수화자가 착용하여 다수의 일반인에게 통역을 수행하 는 웨어러블 수화통역장치에 관한 것이다."}
{"patent_id": "10-2017-0167829", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 수화통역장치에 관한 것으로, 더욱 상세하게는, 수화통역장치를 사용하여 인공지능을 통한 통역을 수 행함으로써, 소수의 수화자가 착용하여 다수의 일반인에게 통역을 수행할 수 있는 웨어러블 수화통역장치에 관 한 것이다."}
{"patent_id": "10-2017-0167829", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "청각장애는 육체, 정서, 지적 발달에 결정적 영향을 주는 청각 기능이 손상되어, 언어 능력 발달에 지장을 받게 되고, 그 결과 언어의 개념 형성 부족으로 교육, 문화, 다양한 정보의 혜택을 정상인과 동등하게 받기가 어려운 현실이다. 뿐만 아니라 인간으로써의 “삶의 질 저하”를 겪고 있는 게 현실이다.따라서, 청각장애를 갖고 있는 사람들은 의사를 전달하기 위해서 수화를 많이 사용하게 된다. 일반적으로 이러 한 수화는 음성언어와는 달리 손으로 표현되는 비음성언어로서, 음성언어가 청각적으로 이해되고 음성으로 표현 되는 청각음성체계임에 반하여 수화는 시각적으로 이해되고 손동작으로 표현되는 시각 운동체계이다. 그러나 상기 수화는 일반 청력장애가 없는 사람(이하, 일반인)이 이용하기 위해서는 별도의 학습이 필요하므로 이를 일반인이 이용하기에는 상당한 노력이 필요하게 되어 비효율적이었다. 따라서, 수화이용자(이하, 수화자) 와 일반인의 자연스런 의사소통은 상당한 노력이 필요하게 된다. 이에 따라, 일반인과 수화이용자는 문자로 서 로의 의사를 전달하는 방법이 있을 수 있으나, 이는 수화이용자나 일반 청력인 모두에게 문자를 일일이 기록해 야 하는 불편함을 주게 되었다. 또한, 수화자와 일반인의 의사소통의 불편함을 해소하기 위해 실시간으로 음성 또는 수화를 통역하는 방법이 필 요하게 되었고, 기계를 통해 음성 또는 수화를 번역할 때, 사람이 음성 또는 수화를 입력하게 되므로 사람마다 입력의 차이가 발생되고 이에 따른 통역의 차이가 발생하게 되었다. 이러한 불편을 해소하기 위한 일반적으로 사용되는 수화통역장치는 일반인의 음성 또는 텍스트를 입력하여 통역 된 수화를 수화자에게 전달하는 방식을 사용하여 다수의 일반인이 한명의 수화자에게 의사를 전달하기 위해서는 다수의 일반인이 각각 수화통역장치를 구비해야 되는 불편함이 발생되었다. 따라서, 이러한 수화자와 일반인 간의 양방향 통역이 가능하고, 입력하는 사람에 따른 차이를 보정하여 통역차 이가 발생되지 않으며, 소수의 수화자가 착용하여 다수의 일반인에게 통역을 수행하는 수화통역장치에 대한 필 요성이 대두되고 있는 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10- 0698942호(2007.03.16.)"}
{"patent_id": "10-2017-0167829", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는 수화자와 일반인 간의 양방향 통역이 가능하고, 입력하는 사람에 따른 차이를 보정하여 통역차이가 발생되지 않으며, 소수의 수화자가 착용하여 다수의 일반인에게 통역을 수행하는 웨어러블 수화통역장치를 제공하는 것이다. 본 발명이 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다 른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2017-0167829", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 달성하기 위하여, 본 발명에 따른 웨어러블 수화통역장치는 사용자의 몸에 장착되도록 구비 된 몸체부, 상기 몸체부와 연결된 마이크를 통해 외부에서 발생되는 음성을 인식하는 마이크부, 상기 몸체부와 연결된 입력장치를 통해 텍스트를 인식하는 입력장치부, 상기 마이크부 또는 입력장치부로부터 인식된 음성 또 는 텍스트를 인공지능을 통해 분석하는 음성텍스트분석부, 상기 음성텍스트분석부에서 분석된 음성 또는 텍스트 를 기반으로 음성 또는 텍스트와 대응되는 수화를 출력하는 수화출력부, 상기 몸체부에 구비된 카메라를 통해 사용자의 손 움직임을 감지하고, 감지되는 수화를 인식하는 카메라부, 상기 카메라부로부터 인식된 수화를 인공 지능을 통해 분석하는 수화분석부, 상기 수화분석부를 통해 분석된 수화를 기반으로 수화에 대응되는 음성 또는 텍스트를 출력하는 음성텍스트출력부, 상기 음성텍스트출력부로부터 수화에 대응되는 음성을 스피커로 출력하는 스피커부 및 상기 음성텍스트출력부로부터 수화에 대응되는 텍스트를 모니터로 출력하는 모니터부를 제공한다. 본 발명의 실시예에 있어서, 음성텍스트분석부는 상기 마이크부를 통해 인식된 음성에 포함된 잡음을 제거하는 잡음제거부 및 상기 잡음제거부를 통해 잡음이 제거된 음성에 대응되는 수화로 변환하도록 인공지능을 통해 음 성을 알고리즘화하는 제 1 음성알고리즘부, 상기 입력장치부를 통해 입력된 텍스트와 대응되는 수화로 변환하도 록 인공지능을 통해 텍스트를 알고리즘화하는 제 1 텍스트알고리즘부를 포함한 것일 수 있다. 본 발명의 실시예에 있어서, 상기 수화출력부는 상기 제 1 음성알고리즘부 및 제 1 텍스트알고리즘부를 통해 알 고리즘화된 음성 또는 텍스트에 기초하여 음성 또는 텍스트와 대응되는 수화를 인공지능을 통해 알고리즘화하는 제 1 수화알고리즘부가 구비되고, 상기 수화출력부는 상기 제 1 수화알고리즘부를 통해 알고리즘화된 수화를 주 위 다수에게 전달하도록 모니터로 출력하는 것일 수 있다. 본 발명의 실시예에 있어서, 상기 수화분석부는 카메라를 통해 감지된 수화에 대응되는 음성 또는 텍스트로 변 환하도록 인공지능을 통해 수화를 알고리즘화하는 제 2 수화알고리즘부가 구비된 것도 가능하다. 본 발명의 실시예에 있어서, 상기 음성텍스트출력부는 상기 제 2 수화알고리즘부를 통해 알고리즘화된 수화에 기초하여 수화내용과 대응되는 음성을 인공지능을 통해 알고리즘화하는 제 2 음성알고리즘부 및 상기 제 2 수화 알고리즘부를 통해 알고리즘화된 수화에 기초하여 수화내용과 대응되는 텍스트를 인공지능을 통해 알고리즘화하 는 제 2 텍스트알고리즘부 포함하는 것일 수 있다. 본 발명의 실시예에 있어서, 상기 제 2 음성알고리즘부는 알고리즘화된 음성을 스피커부를 통해 출력하고, 상기 제 2 텍스트알고리즘부는 알고리즘화된 텍스트를 모니터부를 통해 출력하는 것일 수 있다. 본 발명의 실시예에 있어서, 상기 웨어러블 수화통역장치에 사용되는 인공지능이 딥러닝을 통해 수화 및 음성 또는 텍스트를 군집화하고 분류하여 알고리즘화하도록 딥러닝부가 구비된 것일 수 있다. 본 발명의 실시예에 있어서, 웨어러블 수화통역장치를 통해 사용자의 눈 앞에 장비하여 수화를 인식하고, 통역 을 수행하도록 수화통역안경이 구비된 것 일 수 있다. 본 발명의 실시예에 있어서, 웨어러블 수화통역장치를 통해 사용자의 목이나 귀에 걸어 수화를 인식하고, 통역 을 수행하도록 수화통역팬던트가 구비된 것 일 수 있다."}
{"patent_id": "10-2017-0167829", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 웨어러블 수화통역장치는 음성을 수화로 통역하고, 수화를 음성 또는 텍스트로 통 역함으로써, 수화자와 일반인의 의사소통의 불편함을 해소하고, 음성 또는 수화를 인공지능에 의해서 알고리즘 화하여 매칭시킴으로써, 입력하는 사람에 따른 차이를 보정하여 통역차이가 발생되지 않고, 통역의 정확도를 향 상시킬 수 있으며, 소수의 수화자가 착용하여 다수의 일반인에게 통역을 수행할 수 있는 효과가 있다."}
{"patent_id": "10-2017-0167829", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2017-0167829", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여 본 발명을 설명하기로 한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며, 따라서 여기에서 설명하는 실시예로 한정되는 것은 아니다. 그리고 도면에서 본 발명을 명확 하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결(접속, 접촉, 결합)\"되어 있다고 할 때, 이는 \"직접적으로 연 결\"되어 있는 경우뿐 아니라, 그 중간에 다른 부재를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 구비할 수 있다는 것을 의미한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하 첨부된 도면을 참고하여 본 발명의 실시예를 상세히 설명하기로 한다. 도 1은 본 발명의 일실시예에 따른 웨어러블 수화통역장치의 개략적인 구성도이고, 도 2는 본 발명의 일실시예 에 따른 웨어러블 수화통역장치의 블럭도이다. 도 1내지 도 2를 참조하면, 본 실시예에 따른 웨어러블 수화통역장치는 사용자의 몸에 장착되도록 구비되 도록 몸체부가 구비된다. 보다 상세하게는, 사용자가 수화자일 경우, 상기 몸체부는 목걸이나, 귀걸이, 안경 등과 같이 사람의 몸에 착용가능하도록 구비된다. 상기 몸체부에는 사용자의 손 움직임을 감지할 수 있는 카메라가 장착된 카메라 부가 구비된다. 또한, 사용자는 안경형상으로 제조된 몸체부를 착용하고, 상기 몸체부에 장착된 카메라부에 구 비된 카메라를 통해서 수화를 위한 손 움직임을 감지하게 된다. 이러한 손 움직임을 감지하면, 수화통역시스템에 구비된 수화분석부에서 카메라부를 통해 인식 된 수화의 내용을 알고리즘화하고, 상기 수화내용과 대응되는 음성을 출력하게 된다. 이때, 상기 수화내용과 대응되는 음성을 알고리즘화하여 상기 알고리즘화된 수화내용과 매칭하고, 매칭 시 알고 리즘화된 음성을 웨어러블 수화통역장치와 유선 또는 무선으로 연결된 스피커가 구비된 스피커부를 통해 출력하게 된다. 상기 사용자는 웨어러블 수화통역장치를 사용하는 사람을 뜻하며, 상황에 따라 수화를 행하는 수화자일 수 있고, 음성 또는 텍스트를 입력하는 일반인일 수 있다. 또한, 상기 수화내용과 대응되는 텍스트를 알고리즘화하여 상기 알고리즘화된 수화내용과 매칭하고, 매칭 시 알 고리즘화된 텍스트를 웨어러블 수화통역장치와 유선 또는 무선으로 연결된 모니터가 구비된 모니터부(16 0)를 통해 출력하게 된다. 상기 알고리즘화된 수화와 상기 알고리즘화된 음성 및 텍스트를 매칭시켜 매칭불가 시 수화를 다시 인식시켜 음 성 및 텍스트와 매칭시키도록 한다. 이와 반대로, 사용자가 일반인일 경우, 사용자는 안경형상으로 제조된 몸체부를 착용하고, 상기 몸체부 에 장착되어 있거나 또는 상기 몸체부와 유무선으로 연결된 마이크가 구비된 마이크부를 통해 음성을 인식시키게 된다. 상기 마이크부는 사용자의 음성을 인식하고 인식된 음성을 음성텍스트분석부를 통해 분석하게 된다. 따라서, 사용자가 마이크부를 통해 음성을 인식시키면 음성텍스트분석부에서 상기 음성을 알고리즘화 하고, 음성의 내용과 대응되는 수화를 알고리즘화하게 된다. 상기 알고리즘화된 음성 및 알고리즘화된 수화를 매칭시켜 매칭 시 상기 수화의 내용을 모니터가 구비된 모니터부를 통해 출력하게 된다. 또한, 사용자는 안경형상으로 제조된 몸체부를 착용하고, 상기 몸체부와 유무선으로 연결된 입력장치 가 구비된 입력장치부를 통해 텍스트를 인식시키게 된다. 상기 입력장치부는 사용자의 텍스트 입력을 인식하고 인식된 텍스트를 음성텍스트분석부를 통해 분석 하게 된다. 따라서, 사용자가 입력장치를 통해 텍스트를 인식시키면 음성텍스트분석부에서 상기 텍스트를 알고리즘화하고, 텍스트의 내용과 대응되는 수화를 알고리즘화하게 된다. 상기 알고리즘화된 텍스트 및 알고리즘화된 수화를 매칭시켜 매칭 시 상기 수화의 내용을 모니터가 구비된 모니터부를 통해 출력하게 된다. 한편, 상기 알고리즘화된 음성 및 텍스트와 상기 알고리즘화된 수화를 매칭시켜 매칭불가 시 음성 및 텍스트를 다시 인식시켜 수화와 매칭시키도록 한다. 도 2를 참조하면, 본 실시예에 따른 웨어러블 수화통역장치는 마이크부를 통해 외부에서 발생되는 음 성 또는 입력장치를 통해 텍스트를 인식하는 음성텍스트인식부를 포함한다. 보다 상세하게는, 음성을 인식할 수 있도록 마이크로 구성된 마이크부가 구비되고, 상기 마이크는 사용자 가 음성을 통해 이야기하는 바를 음성으로 인식하는 장치이다. 상기 마이크는 웨어러블 수화통역장치에 장 착되거나, 개별적으로 사용되어 무선으로 웨어러블 수화통역장치와 연동될 수 있다. 또한, 휴대폰과 같은 스마트 단말기를 통해 마이크로 사용되는 것도 가능하다. 상기 마이크는 일반적으로 사용되는 음성이나 소리를 전기 펄스로 바꾸는 장치로 마이크에 대한 구체적인 구성은 생략하기로 한다. 또한, 웨어러블 수화통역장치와 연결되어 텍스트를 입력하도록 입력장치부가 구비된다. 상기 입력장 치부는 키보드, 스크린패드 또는 휴대폰과 같이 유선 및 무선으로 웨어러블 수화통역장치와 연동되어 입력된 텍스트를 웨어러블 수화통역장치에 전달한다. 한편, 음성텍스트인식부로부터 인식된 음성 또는 텍스트를 인공지능을 통해 분석하는 음성텍스트분석부 가 구비된다. 보다 상세하게는, 상기 음성텍스트분석부는 마이크부를 통해 인식된 음성 또는 입력장치부를 통 해 입력된 텍스트를 상기 음성텍스트인식부를 통해 인식하고, 인공지능을 통해서 이를 분석한다. 마이크나 입력장치부를 통해 입력된 음성 또는 텍스트와 같은 정보들은 표현하는 사람에 따라 차이가 발생하게 되고, 인공지능을 통해 이러한 차이점을 보정하여 공통적으로 표현하는 정보를 분석한다. 즉, 같은 표현이라도 입력하는 사람마다 차이가 존재하고, 이러한 차이에도 입력하는 사람이 표현하고자 하는 의사를 구분하여 웨어 러블 수화통역장치가 통역을 수행할 수 있도록 음성텍스트분석부가 마이크를 통해 인식된 음성 또는 입력장치부를 통해 입력된 텍스트를 분석한다. 또한, 음성텍스트분석부에서 분석된 음성 또는 텍스트를 기반으로 웨어러블 수화통역장치를 통해 수 화를 출력하도록 수화출력부가 구비된다. 보다 상세하게는, 상기 수화출력부는 상기 음성텍스트분석부를 통해서 분석된 음성 또는 텍스트를 인 공지능을 통해 분석하여 이와 대응되는 수화를 출력할 수 있다. 수화내용을 출력하기 위해서 웨어러블 수화통역 장치가 이용되고, 상기 웨어러블 수화통역장치는 사람의 손과 동일한 형상으로 구비되어 수화내용을 정확하게 전달할 수 있다. 또한, 이러한 수화내용을 로봇과 연결된 모니터를 통해 출력하는 것도 가능하다. 따 라서, 근거리 대상에게는 웨어러블 수화통역장치를 통해서 전달하고, 원거리 대상에게는 모니터를 통해 수 화내용을 전달할 수 있다. 한편, 음성텍스트분석부는 잡음제거부, 제 1 음성알고리즘부 및 제 1 텍스트알고리즘부를 포함한다. 보다 상세하게는, 상기 잡음제거부는 상기 마이크를 통해 인식된 음성에 포함된 잡음을 제거하도록 구비된 다. 따라서, 마이크를 통해 보다 정확하게 음성을 인식할 수 있다. 또한, 상기 잡음제거부를 통해 잡음이 제거된 음성에 대응되는 수화로 번역하도록 인공지능을 통해 음성을 알고리즘화하는 제 1 음성알고리즘부 가 구비된다. 상기 제 1 음성알고리즘부에 적용되는 상기 인공지능은 다양하게 적용가능하나 바람직하게는 딥러닝을 이용한 딥러닝부를 통해 인식된 정보를 군집화하고 분류하여 알고리즘화한다. 또한, 상기 제 1 텍스트알고리즘부는 입력장치부를 통해 입력된 텍스트와 대응되는 수화 번역하도록 인공지능을 통해 텍스트를 알고리즘화한다. 상기 인공지능은 다양하게 적용가능하나 바람직하게는 딥러닝부 를 이용하여 인식된 정보를 군집화하고 분류하여 알고리즘화한다. 또한, 수화출력부는 제 1 수화알고리즘부를 통해 알고리즘화된 수화를 웨어러블 수화통역장치로 출력한다. 보다 상세하게는, 상기 제 1 수화알고리즘부 는 상기 제 1 음성알고리즘부 및 제 1 텍스트알고리즘부 를 통해 알고리즘화된 음성 또는 텍스트에 기초하여, 상기 음성 또는 텍스트와 대응되는 수화를 딥러닝을 이용한 딥러닝부를 통해 알고리즘화하고, 이를 웨어러블 수화통역장치를 통해 출력하게 된다. 즉, 인식된 음성 또는 텍스트는 상기 제 1 음성알고리즘부 및 상기 제 1 텍스트알고리즘부에서 딥러 닝부를 통해 알고리즘화하고, 이러한 알고리즘화된 음성 또는 텍스트와 대응되는 수화를 도출하여 이를 딥 러닝부를 통해 제 1 수화알고리즘부 에서 알고리즘화한다. 따라서, 음성 또는 텍스트를 알고리즘화하 고, 이와 대응되는 수화를 알고리즘화함으로써, 웨어러블 수화통역장치 사용자에 따른 차이를 보완하고, 통역의 오류를 방지할 수 있다. 한편, 웨어러블 수화통역장치에 카메라가 구비된 카메라부를 통해 움직임을 감지하고, 감지되는 수화 를 인식하는 수화인식부가 구비된다. 보다 상세하게는, 상기 수화인식부는 웨어러블 수화통역장치에 카메라가 구비된 카메라부를 통 해 수화자의 손을 촬영하고, 이를 통해 수화를 인식하게 된다. 또한, 상기 수화인식부는 수화자의 수화를 인식할 수 있도록 수화자가 센서가 구비된 장갑을 착용한 상태에서 수화를 수행하고 상기 장갑과 연결된 웨어러 블 수화통역장치가 센서로부터 신호를 받아 수화를 인식하는 것도 가능하다. 또한, 수화인식부로부터 인식된 수화를 인공지능을 통해 분석하는 수화분석부가 구비된다. 보다 상세하게는, 상기 수화분석부는 상기 수화인식부로부터 수화를 인식하고, 인식된 수화를 인공지 능을 통해 분석한다. 즉, 수화를 수행하는 수화자마다 동일한 수화내용을 수행하여도 손의 위치나 속도, 습관 등에 의해서 차이가 발생하게 되는데 이러한 차이를 포함하고 일정한 수화내용을 전달할 수 있도록 인공지능을 통해 수화내용을 분석한다. 따라서, 이러한 수화내용은 수화자마다 차이가 발생되더라도 정확하고 일정한 수화 내용을 분석할 수 있도록 한다. 한편, 수화분석부를 통해 분석된 수화를 기반으로 수화에 대응되는 음성 또는 텍스트를 출력하는 음성텍스 트출력부가 구비된다. 보다 상세하게는, 상기 음성텍스트출력부는 상기 수화분석부를 통해 분석된 수화와 대응되도록 음성 또는 텍스트를 출력할 수 있다. 상기 음성은 웨어러블 수화통역장치에 장착된 마이크 또는 상기 웨어러블 수화통역장치와 연결된 마이크를 통해 출력되고, 텍스트는 웨어러블 수화통역장치에 구비된 모니터 또는 외부 모니터를 통해서 출력 가능하다. 또한, 상기 웨어러블 수화통역장치를 휴대폰과 연동시켜 휴대 폰에 구비된 스피커나 화면을 통해서 출력하는 것 또한 가능하다. 또한, 수화분석부는 인공지능을 통해 수화를 알고리즘화하는 제 2 수화알고리즘부가 구비된다. 보다 상세하게는, 상기 제 2 수화알고리즘부는 카메라를 통해 감지된 수화에 대응되는 음성 또는 텍스트로 번역하도록 인공지능을 통해 수화를 알고리즘화한다. 상기 인공지능은 다양하게 적용가능하나 바람직하게는 딥 러닝을 이용한 딥러닝부를 통해 인식된 정보를 군집화하고 분류하여 알고리즘화한다. 한편, 음성텍스트출력부는 제 2 수화알고리즘부를 통해 알고리즘화된 음성 또는 텍스트를 웨어러블 수화통역장치로 출력하도록 제 2 음성알고리즘부 또는 제 2 텍스트알고리즘부가 구비된다. 보다 상세하게는, 상기 제 2 수화알고리즘부를 통해 알고리즘화된 수화에 기초하여 수화내용과 대응되는 음성을 인공지능을 통해 알고리즘화하는 제 2 음성알고리즘부가 구비되고, 상기 제 2 수화알고리즘부(25 1)를 통해 알고리즘화된 수화에 기초하여 수화내용과 대응되는 텍스트를 인공지능을 통해 알고리즘화하는 제 2 텍스트알고리즘부가 구비된다. 즉, 수화자에 의해서 수화내용을 알고리즘화하고, 상기 수화내용에 대응되는 음성 또는 텍스트를 알고리즘화하 여 웨어러블 수화통역장치를 통해 출력하게 된다. 상기 인공지능은 다양하게 적용가능하나 바람직하게는 딥러닝을 이용한 딥러닝부를 통해 인식된 정보를 군집화하고 분류하여 알고리즘화한다. 또한, 딥러닝부는 알고리즘화된 수화와 알고리즘화된 음성 또는 텍스트를 군집화하고 분류하여 매칭시키도 록 매칭부가 구비될 수 있다. 보다 상세하게는, 상기 매칭부는 상기 제 1 및 제 2 수화알고리즘부(231, 251)를 통해 알고리즘화된 수화 와 상기 제 1 및 제 2 음성알고리즘부(222, 261) 또는 제1 및 제 2 텍스트알고리즘부(223, 262)를 통해 알고리 즘화된 음성 또는 텍스트를 군집화하고 분류하여 각각 매칭시키도록 한다. 따라서, 수화와 음성 또는 텍스트가 각각 매칭되므로, 보다 용이하게 수화와 음성 또는 텍스트의 통역이 가능하고, 또한 사용자에 따른 편차를 매칭 을 통해 감소시킬 수 있다. 이러한 음성텍스트출력부는 수화에 대응되는 음성 및 텍스트를 각각 출력할 수 있고, 또는 음성 및 텍스트 를 동시에 출력하는 것도 가능하다. 도 3은 본 발명의 또 하나의 실시예에 따른 웨어러블 수화통역장치의 개략적인 구성도이다. 도 2 내지 도 3을 참조하면, 본 실시예에 따른 웨어러블 수화통역장치는 사용자의 몸에 장착되도록 구비되 도록 몸체부가 구비된다. 사용자는 펜던트로 사용하도록 제조된 몸체부를 목에 걸어 착용하고, 상기 몸체부에 장착된 카메라부에 구비된 카메라를 통해서 수화를 위한 손 움직임을 감지하게 된다. 도 3에 도시된 웨어러블 수화통역장치는 몸체부가 펜던트로 제조된 것을 제외하고 도 1 의 웨어러블 수화 통역장치와 동일하므로 이에 대한 자세한 설명은 생략하기로 한다. 상기 몸체부는 카메라를 통해 사용자의 손 움직임을 인식하기 위해 사용자의 몸에 착용되는 것으로써, 손 움직임을 용이하게 인식할 수 있다면 착용위치 및 형상에 있어서 제약되지 않는다. 따라서, 상기 몸체부는 다양한 형상으로 제조가능하고 바람직하게는 안경, 목걸이, 귀걸이 등으로 제조된 것이다. 도 4는 본 발명의 일실시예에 따른 수화통역방법의 흐름도이다. 도 1 내지 도 4를 참조하면, 본 실시예에 따른 웨어러블 수화통역장치는 상기 웨어러블 수화통역장치를 사 용하는 사용자의 음성이나 텍스트를 웨어러블 수화통역장치에 구비된 마이크나 입력장치를 통해 인식하는 단계(S410)를 포함한다. 보다 상세하게는, 사용자는 마이크가 구비된 마이크부를 통해서 음성을 입력하거나 입력장치부를 통 해서 텍스트를 웨어러블 수화통역장치에 인식시킬 수 있다. 상기 마이크부, 입력장치부는 상기 웨어러블 수화통역장치에 장착되어 있는 구조일 수 있고, 또는 웨어러블 수화통역장치와 유무선으로 연결되어 외부에서 실행될 수 있다. 또한, 마이크부나 입력장치부를 통해 인식된 음성이나 텍스트를 인공지능을 통해 알고리즘화시키는 단계(S420)를 포함할 수 있다. 보다 상세하게는, 마이크부를 통해 인식된 음성을 인공지능을 통해 알고리즘화하거나 또는, 입력장치부 를 통해 인식된 텍스트를 인공지능을 통해 알고리즘화하고, 인식된 음성의 내용 또는 인식된 텍스트의 내 용과 대응되는 수화로 변환한다. 또한, 음성 또는 텍스트와 대응되는 수화를 알고리즘화 시키는 단계(S430)를 포함할 수 있다. 상기 인식된 음성 또는 텍스트를 인공지능을 통해 알고리즘화시키는 단계(S420)에서 인식된 음성의 내용 또는 인식된 텍스트의 내용과 대응되는 수화를 도출하고 상기 수화를 알고리즘화한다. 또한, 음성 또는 텍스트를 알고리즘화 시키고 이와 대응되는 수화를 알고리즘화시켜 서로 매칭시키는 단계 (S440)를 포함할 수 있다. 마이크부를 통해 인식된 음성을 인공지능을 통해 알고리즘화하고, 이와 대응되는 수화를 알고리즘화하여 서로 매칭시킴으로써, 음성에 대응되는 수화를 표준화할 수 있고, 음성에 대응되는 수화의 출력 시 발생되는 오 류를 감소시킬 수 있다. 입력장치부를 통해 인식된 텍스트를 인공지능을 통해 알고리즘화하고, 이와 대응되는 수화를 알고리즘화하 여 서로 매칭시킴으로써, 텍스트에 대응되는 수화를 표준화할 수 있고, 텍스트에 대응되는 수화의 출력 시 발생 되는 오류를 감소시킬 수 있다. 한편, 상기 인공지능은 여러가지가 적용가능하지만 바람직하게는 인식된 수화 및 음성 또는 텍스트를 군집화하 고 분류하여 사용하도록 딥러닝을 통해서 알고리즘화시키는 것이다. 또한, 상기 알고리즘화된 음성 또는 텍스트와 알고리즘화된 수화를 매칭하는 단계에서 매칭이 불가능할 경우 음 성이나 텍스트를 인식하는 단계를 다시 수행하는 단계(S441)를 추가로 포함 할 수 있다. 또한, 알고리즘화된 음성이나 텍스트를 알고리즘화된 수화와 매칭시키는 단계를 수행하고 매칭이 가능할 경우 웨어러블 수화통역장치를 통해 수화내용을 출력하는 단계(S450)를 포함할 수 있다. 보다 상세하게는, 마이크부를 통해 인식된 음성을 알고리즘화하고, 상기 음성의 내용과 대응되는 수화를 알고리즘화하여 서로 매칭시킨다. 이때, 음성의 내용과 수화의 내용이 매칭될 때, 상기 수화의 내용을 웨어러블 수화통역장치를 통해서 출력하게 된다.또한, 입력장치부를 통해 인식된 텍스트를 알고리즘화하고, 상기 텍스트의 내용과 대응되는 수화를 알고리 즘화하여 서로 매칭시킨다. 이때, 텍스트의 내용과 수화의 내용이 매칭될 때, 상기 수화의 내용을 웨어러블 수 화통역장치를 통해서 출력하게 된다. 도 5는 본 발명의 또 하나의 실시예에 따른 수화통역방법의 흐름도이다. 도 1 내지 도 5를 참조하면, 본 실시예에 따른 수화통역방법은 상기 수화통역시스템을 사용하는 수화자의 수화를 웨어러블 수화통역장치에 구비된 카메라부를 통해 인식하는 단계(S510)를 포함한다. 보다 상세하게는, 사용자는 카메라가 구비된 카메라부를 통해 수화를 웨어러블 수화통역장치에 인식 시킬 수 있다. 상기 카메라부는 상기 웨어러블 수화통역장치에 장착되어 있는 구조일 수 있고, 또는 웨어러블 수화통역장치와 유무선으로 연결되어 외부에서 실행될 수 있다. 또한, 카메라를 통해 인식된 수화를 인공지능을 통해 알고리즘화시키는 단계(S520)를 포함할 수 있다. 보다 상세하게는, 카메라부부에 구비된 카메라를 통해 인식된 수화를 인공지능을 통해 알고리즘화하고, 인 식된 수화의 내용과 대응되는 음성 또는 텍스트로 변환한다. 또한, 수화와 대응되는 음성 또는 텍스트로 알고리즘화 시키는 단계(S530)를 포함할 수 있다. 상기 인식된 수화를 인공지능을 통해 알고리즘화시키는 단계(S520)에서 인식된 음성의 내용 또는 인식된 텍스트 의 내용과 대응되는 수화를 도출하고 상기 수화를 알고리즘화한다. 또한, 음성 또는 텍스트를 알고리즘화 시키고 이와 대응되는 수화를 알고리즘화시켜 서로 매칭시키는 단계 (S540)를 포함할 수 있다. 마이크부를 통해 인식된 음성을 인공지능을 통해 알고리즘화하고, 이와 대응되는 수화를 알고리즘화하여 서로 매칭시킴으로써, 음성에 대응되는 수화를 표준화할 수 있고, 음성에 대응되는 수화의 출력 시 발생되는 오 류를 감소시킬 수 있다. 즉, 카메라부를 통해 인식된 수화를 알고리즘화하고, 상기 수화의 내용과 대응되는 음성 또는 텍스트를 알 고리즘화하여 서로 매칭시킨다. 이 때, 수화의 내용과 음성 또는 텍스트의 내용이 매칭될 때, 상기 음성의 내용 을 웨어러블 수화통역장치에 구비된 스피커부를 통해서 출력하거나, 상기 텍스트의 내용을 웨어러블 수화통역장치와 연결된 모니터부를 통해 출력할 수 있다. 상기 스피커부 및 모니터부는 각 각 음성내용 및 텍스트내용을 출력할 수 있고, 필요에 따라 동시에 출력하는 것도 가능하다. 또한, 알고리즘화된 수화와 상기 알고리즘화된 음성 또는 텍스트를 매칭하는 단계에서 매칭이 불가능할 경우, 수화를 인식하는 단계를 다시 수행하는 단계(S541)를 추가로 포함 할 수 있다. 또한, 알고리즘화된 수화를 알고리즘화된 음성이나 텍스트와 매칭시키는 단계를 수행하고 매칭이 가능할 경우 웨어러블 수화통역장치에 구비된 스피커부를 통해서 음성을 출력하거나 모니터부를 통해서 텍스 트를 출력하는 단계(S550)를 포함할 수 있다. 보다 상세하게는, 카메라부를 통해 인식된 수화를 알고리즘화하고, 상기 수화의 내용과 대응되는 음성을 알고리즘화하여 서로 매칭시킨다. 이때, 수화의 내용과 음성의 내용이 매칭될 때, 상기 수화의 내용을 웨어러블 수화통역장치에 구비된 스피커부를 통해서 음성을 출력하게 된다. 또한, 카메라부를 통해 인식된 수화를 알고리즘화하고, 상기 수화의 내용과 대응되는 텍스트를 알고리즘화 하여 서로 매칭시킨다. 이때, 수화의 내용과 텍스트의 내용이 매칭될 때, 상기 텍스트의 내용을 웨어러블 수화 통역장치와 연결된 모니터부를 통해서 텍스트를 출력하게 된다. 따라서, 매칭이 가능할 때만 스피커부 또는 모니터부를 통해 수화의 내용을 출력하므로 사용자간의 차이에 따른 보정을 통해 수화의 내용과 음성 및 텍스트의 내용 간의 오류를 감소시킬 수 있다. 도 6은 본 발명의 또 하나의 실시예에 따른 웨어러블 수화통역장치의 블럭도이다. 도 6을 참조하면, 본 발명에 따른 웨어러블 수화통역장치는 제 1 사용자인식부를 포함할 수 있다. 보다 상세하게는, 상기 제 1 사용자인식부는 웨어러블 수화통역장치를 사용하는 사용자를 인식하고 사용자의 특징들을 분류하여 데이터베이스화한다. 상기 제 1 사용자인식부는 사용자를 다양한 방식으로 인 식할 수 있고, 바람직하게는 카메라부를 통해 사용자의 얼굴을 감지하여 인식하거나, 마이크부를 통해 사용자의 음성을 감지하여 인식할 수 있고, 또는 입력장치부를 통해 사용자가 입력하여 사용자를 인식 시킬 수 있다. 또한, 제 1 사용자인식부를 통해 인식된 사용자의 음성 또는 텍스트를 인식하는 음성텍스트인식부가 구비된다. 보다 상세하게는, 음성을 인식할 수 있도록 마이크로 구성된 마이크부가 구비되고, 상기 마이크는 사용자 가 음성을 통해 이야기하는 바를 음성으로 인식하는 장치이다. 상기 마이크는 웨어러블 수화통역장치에 장 착되거나, 개별적으로 사용되어 무선으로 연동될 수 있다. 또한, 휴대폰과 같은 스마트 단말기를 통해 마이크로 사용되는 것도 가능하다. 또한, 웨어러블 수화통역장치와 연결되어 텍스트를 입력하도록 입력장치부가 구비된다. 상기 입력장 치부는 키보드, 스크린패드 또는 휴대폰과 같이 유선 및 무선으로 웨어러블 수화통역장치와 연동되어 입력된 텍스트를 전달한다. 따라서, 제 1 사용자인식부를 통해 사용자를 인식하고, 사용자가 웨어러블 수화통역장치에 음성 또는 텍스트를 인식시키면, 상기 음성텍스트인식부를 통해 음성 또는 텍스트가 인식된다. 한편, 음성텍스트인식부를 통해 인식된 음성 또는 텍스트는 음성텍스트분석부를 통해 음성 또는 텍스 트를 분석하게 되고, 상기 음성텍스트분석부는 잡음제거부, 제 1 음성알고리즘부 및 제 1 텍스 트알고리즘부를 구비한다. 상기 잡음제거부, 제 1 음성알고리즘부 및 제 1 텍스트알고리즘부 의 구성은 도 1의 구성과 동일하므로, 자세한 설명은 생략하기로 한다. 사용자가 음성텍스트인식부를 통해 음성 또는 텍스트를 인식시키면, 상기 음성텍스트분석부에 구비된 제 1 음성알고리즘부 및 제 1 텍스트알고리즘부에서 이를 알고리즘화시킨다. 이때, 사용자 마다 습관 이나 버릇 등으로 인한 음성의 차이가 발생되고, 이러한 차이로 인한 오류를 감지하도록 제 1 오류감지부가 구 비된다. 상기 제 1 오류감지부는 사용자의 음성 또는 텍스트의 내용에 오류가 발생될 경우, 오류를 감지하도록 구 비된다. 따라서, 사용자가 특정한 음성 또는 텍스트에 대해 반복적으로 오류가 발생될 경우, 이를 보정하여 표 준화된 수화로 통역 가능하도록 구비된다. 즉, 상기 제 1 사용자인식부를 통해 인식된 사용자의 정보를 저장하고, 이를 통해 사용자의 습관 또는 버 릇 등으로 인해 발생되는 반복적인 음성 또는 텍스트의 오류를 표준화된 수화로 통역시키도록 오류가 발생된 음 성 또는 텍스트를 감지하도록 한다. 따라서, 제 1 오류감지부를 통해 감지된 음성 또는 텍스트의 오류는 딥러닝부에 구비된 변환부(79 2)를 통해 표준화된 음성 또는 텍스트로 변환된다. 결과적으로, 변환부를 통해 변환된 음성 또는 텍스트는 이와 대응되는 수화로 통역되어 수화출력부를 통해 출력하게된다. 하나의 예로, 사용자가 제 1 사용자인식부를 통해 사용자를 인식시키면 데이터베이스화된 제 1 사용자인식 부에서 사용자를 인식하고, 음성텍스트인식부를 통해 음성을 인식시키면, 음성텍스트분석부를 통해 음성을 분석하게 된다. 이때, 제 1 사용자인식부에서 사용자의 습관 또는 버릇을 데이터베이스화하고, 사용자가 “A”에 대해 습관적으로 “B”로 인식시킬 경우 입력된 음성의 문맥 등을 파악 하여 음성에 오류가 있음을 제 1 오류감지부를 통해 파악하게 된다. 따라서, 오류가 발생된 음성은 변환부 를 통해서 사용자가 입력시킨 “B”로 인식되는 것이 아닌 “A”로 변환되어 인식하게 되고, 최종적으로 통역된 수화는 오류 없이 표준화된 수화로 통역된다. 본 발명에 따른 웨어러블 수화통역장치는 제 2 사용자인식부를 포함할 수 있다. 보다 상세하게는, 상기 제 2 사용자인식부는 웨어러블 수화통역장치를 사용하는 사용자를 인식하고 사용자의 특징들을 분류하여 데이터베이스화한다. 상기 제 2 사용자인식부는 사용자를 다양한 방식으로 인 식할 수 있고, 바람직하게는 웨어러블 수화통역장치에 구비된 카메라부를 통해 사용자의 얼굴이나 수 화를 감지하여 인식하거나, 입력장치를 통해 사용자가 입력하여 사용자를 인식시킬 수 있다. 또한, 제 2 사용자인식부를 통해 인식된 사용자의 수화를 인식하는 수화인식부가 구비된다. 보다 상세하게는, 수화를 인식할 수 있도록 카메라로 구성된 카메라부가 구비되고, 상기 카메라는 사용자 가 입력하는 수화를 통해 사용자의 의사를 인식하는 장치이다. 상기 카메라는 웨어러블 수화통역장치에 장착되거나, 개별적으로 사용되어 무선으로 연동될 수 있다. 또한, 휴대폰과 같은 스마트 단말기를 통해 카메라로 사용되는 것도 가능하다. 따라서, 제 2 사용자인식부를 통해 사용자를 인식하고, 사용자가 웨어러블 수화통역장치에 수화를 인 식시키면, 상기 수화인식부를 통해 수화가 인식된다. 한편, 수화인식부를 통해 인식된 수화는 수화분석부를 통해 수화를 분석하게 되고, 상기 수화분석부 는 제 2 수화알고리즘부를 구비한다. 상기 제 2 수화알고리즘부의 구성은 도 1의 구성과 동일하 므로, 자세한 설명은 생략하기로 한다. 사용자가 수화인식부를 통해 수화를 인식시키면, 제 2 수화알고리즘부에서 이를 알고리즘화시킨다. 이때, 사용자 마다 습관이나 버릇 등으로 인한 수화의 차이가 발생되고, 이러한 차이로 인한 수화의 오류를 감 지하도록 제 2 오류감지부가 구비된다. 상기 제 2 오류감지부는 사용자의 수화의 내용에 오류가 발생될 경우, 오류를 감지하도록 구비된다. 따라 서, 사용자가 특정한 수화에 대해 반복적으로 오류가 발생될 경우, 이를 보정하여 표준화된 수화로 통역 가능하 도록 구비된다. 즉, 상기 제 2 사용자인식부를 통해 인식된 사용자의 정보를 저장하고, 이를 통해 사용자의 습관 또는 버 릇 등으로 인해 발생되는 반복적인 수화의 오류를 표준화된 음성 또는 텍스트로 통역시키도록 오류가 발생된 수 화를 감지하도록 한다. 따라서, 제 2 오류감지부를 통해 감지된 수화의 오류는 딥러닝부에 구비된 변환부를 통해 표준 화된 수화로 변환된다. 결과적으로, 변환부를 통해 변환된 수화는 이와 대응되는 음성 또는 텍스트로 통역 되어 음성텍스트출력부를 통해 출력하게 된다."}
{"patent_id": "10-2017-0167829", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2017-0167829", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 웨어러블 수화통역장치의 개략적인 구성도이다. 도 2는 본 발명의 일실시예에 따른 웨어러블 수화통역장치의 블럭도이다. 도 3은 본 발명의 또 하나의 실시예에 따른 웨어러블 수화통역장치의 개략적인 구성도이다. 도 4는 본 발명의 일실시예에 따른 수화통역방법의 흐름도이다. 도 5는 본 발명의 또 하나의 실시예에 따른 수화통역방법의 흐름도이다. 도 6은 본 발명의 또 하나의 실시예에 따른 수화통역시스템의 블럭도이다."}
