{"patent_id": "10-2020-0146191", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0060322", "출원번호": "10-2020-0146191", "발명의 명칭": "뉴럴 네트워크를 이용한 빔포밍 방법 및 빔포밍 시스템", "출원인": "주식회사 딥히어링", "발명자": "안강헌"}}
{"patent_id": "10-2020-0146191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 마이크와, 상기 제1 마이크로부터 미리 정해진 거리만큼 이격되어 배치된 제2 마이크를 이용하여 제1 소리신호 및 제2 소리 신호를 각각 수신하는 단계;상기 제1 소리 신호 및 상기 제2 소리 신호 각각에 대한 푸리에 변환 결과를 획득하는 단계;상기 푸리에 변환 결과로부터 상기 제1 소리 신호와 상기 제2 소리 신호의 위상차를 획득하는 단계;뉴럴 프로세서를 이용하여 상기 위상차를 빔포밍 모델에 입력하여 연산하는 단계;상기 뉴럴 프로세서의 연산 결과와 상기 제1 소리 신호에 대한 푸리에 변환 결과에 대해 원소곱을 수행하는 단계; 및상기 원소곱 결과를 출력하는 단계를 포함하는빔포밍 방법."}
{"patent_id": "10-2020-0146191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 원소곱을 수행하는 단계는,상기 원소곱을 수행하기 전에 상기 연산 결과에 대해 마스크(mask)를 적용하는 단계를 더 포함하는 빔포밍방법."}
{"patent_id": "10-2020-0146191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 원소곱을 수행하는 단계는,상기 원소곱을 수행한 후에 이득 제어(gain control)를 수행하는 단계를 더 포함하는 빔포밍 방법."}
{"patent_id": "10-2020-0146191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 미리 정해진 거리는 10 cm 내지 14 cm인, 빔포밍 방법."}
{"patent_id": "10-2020-0146191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 위상차를 이용하여 상기 빔포밍 모델을 학습시키는 단계를 더 포함하는 빔포밍 방법."}
{"patent_id": "10-2020-0146191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 소리 신호를 수신하는 제1 마이크;상기 제1 마이크로부터 미리 정해진 거리만큼 이격되어 배치되어 제2 소리 신호를 수신하는 제2 마이크;상기 제1 소리 신호에 대한 푸리에 변환 결과를 획득하는 제1 STFT 모듈;상기 제2 소리 신호에 대한 푸리에 변환 결과를 획득하는 제2 STFT 모듈;상기 푸리에 변환 결과로부터 상기 제1 소리 신호와 상기 제2 소리 신호의 위상차를 획득하는 위상차 획득모듈;공개특허 10-2022-0060322-3-상기 위상차를 입력받아 빔포밍 모델을 이용하여 뉴럴 네트워크 연산을 수행하는 뉴럴 프로세서;상기 뉴럴 프로세서의 연산 결과와 상기 제1 소리 신호에 대한 푸리에 변환 결과에 대해 원소곱을 수행하는 원소곱 모듈; 및상기 원소곱 결과를 출력하는 출력 모듈을 포함하는빔포밍 시스템."}
{"patent_id": "10-2020-0146191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 원소곱을 수행하기 전에 상기 연산 결과에 대해 마스크를 적용하는 마스킹 모듈을 더 포함하는 빔포밍 시스템."}
{"patent_id": "10-2020-0146191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 원소곱을 수행한 후에 이득 제어를 수행하는 이득 제어 모듈을 더 포함하는 빔포밍 시스템."}
{"patent_id": "10-2020-0146191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 미리 정해진 거리는 10 cm 내지 14 cm인, 빔포밍 시스템."}
{"patent_id": "10-2020-0146191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 위상차를 이용하여 상기 빔포밍 모델을 학습시키는 학습 모델을 더 포함하는 빔포밍 시스템."}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "빔포밍 방법 및 빔포밍 시스템이 제공된다. 빔포밍 방법은, 제1 마이크와, 상기 제1 마이크로부터 미리 정해진 거리만큼 이격되어 배치된 제2 마이크를 이용하여 제1 소리 신호 및 제2 소리 신호를 각각 수신하는 단계; 상기 제1 소리 신호 및 상기 제2 소리 신호 각각에 대한 푸리에 변환 결과를 획득하는 단계; 상기 푸리에 변환 결과로 부터 상기 제1 소리 신호와 상기 제2 소리 신호의 위상차를 획득하는 단계; 뉴럴 프로세서를 이용하여 상기 위상 차를 빔포밍 모델에 입력하여 연산하는 단계; 상기 뉴럴 프로세서의 연산 결과와 상기 제1 소리 신호에 대한 푸 리에 변환 결과에 대해 원소곱을 수행하는 단계; 및 상기 원소곱 결과를 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 뉴럴 네트워크를 이용한 빔포밍 방법 및 빔포밍 시스템에 관한 것이다."}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "칵테일 파티 효과(cocktail party effect)는 파티의 참석자들이 시끄러운 주변 소음이 있는 방에 있음에도 불구 하고 대화자와의 이야기를 선택적으로 집중하여 잘 받아들이는 현상을 말한다. 기계에서 이러한 능력, 즉 빔포 밍(beamforming)을 구현하는 것은 칵테일 파티 문제로 알려져 왔으며 최근에는 칵테일 파티 문제 해결을 위해 뉴럴 네트워크를 이용하려는 시도가 늘어나고 있다. 빔포밍 기법의 성능을 높이는 것은 오디오 관련 전자 제품 의 성능과 밀접한 관계가 있으며, 특히 보청기와도 관련이 있기 때문에 매우 중요한 사회 문제라는 의미도 가질 수 있다. 빔포밍은 2 개 이상의 마이크를 이용하여 획득한 소리를 분석해 대상 신호를 재구성하는 과정을 의미할 수 있다. 이를 위해, 각 마이크에서 오는 신호에 대해 인위적인 지연 시간을 만들어 합치는 것과 같이, 주어진 제 한조건을 만족시키면서 들어오는 소리의 크기를 최소화하는 기법이 오래전부터 사용되어 왔다. 최근에는 뉴럴 네트워크를 이용한 MVDR(minimum variance distortionless response) 빔포머의 성능 향상에 관한 연구 또는 빔 포머를 구현하는 뉴럴 네트워크 모델의 훈련방법 등이 활발히 연구되고 있다."}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 규칙기반 빔포밍에서 공간정보를 얻기위해 많은 양의 연산이 요구되는 한계 를 극복하기 위해 뉴럴 네트워크를 사용하되, 빔포밍에 최적화되도록 뉴럴 네트워크 구조를 설계함으로써 파라 미터량 및 연산량을 최소화할 수 있는, 뉴럴 네트워크를 이용한 빔포밍 방법 및 빔포밍 시스템을 제공하기 위한것이다."}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 빔포밍 방법은, 제1 마이크와, 상기 제1 마이크로부터 미리 정해진 거리만큼 이격 되어 배치된 제2 마이크를 이용하여 제1 소리 신호 및 제2 소리 신호를 각각 수신하는 단계; 상기 제1 소리 신 호 및 상기 제2 소리 신호 각각에 대한 푸리에 변환 결과를 획득하는 단계; 상기 푸리에 변환 결과로부터 상기 제1 소리 신호와 상기 제2 소리 신호의 위상차를 획득하는 단계; 뉴럴 프로세서를 이용하여 상기 위상차를 빔포 밍 모델에 입력하여 연산하는 단계; 상기 뉴럴 프로세의 연산 결과와 상기 제1 소리 신호에 대한 푸리에 변환 결과에 대해 원소곱을 수행하는 단계; 및 상기 원소곱 결과를 출력하는 단계를 포함할 수 있다. 상기 원소곱을 수행하는 단계는, 상기 원소곱을 수행하기 전에 상기 연산 결과에 대해 마스크(mask)를 적용하는 단계를 더 포함할 수 있다. 상기 원소곱을 수행하는 단계는, 상기 원소곱을 수행한 후에 이득 제어(gain control)를 수행하는 단계를 더 포 함할 수 있다. 상기 미리 정해진 거리는 10 cm 내지 14 cm일 수 있다. 상기 빔포밍 방법은, 상기 위상차를 이용하여 상기 빔포밍 모델을 학습시키는 단계를 더 포함할 수 있다. 본 발명의 일 실시 예에 따른 빔포밍 시스템은, 제1 소리 신호를 수신하는 제1 마이크; 상기 제1 마이크로부터 미리 정해진 거리만큼 이격되어 배치되어 제2 소리 신호를 수신하는 제2 마이크; 상기 제1 소리 신호에 대한 푸 리에 변환 결과를 획득하는 제1 STFT 모듈; 상기 제2 소리 신호에 대한 푸리에 변환 결과를 획득하는 제2 STFT 모듈; 상기 푸리에 변환 결과로부터 상기 제1 소리 신호와 상기 제2 소리 신호의 위상차를 획득하는 위상차 획 득 모듈; 상기 위상차를 입력받아 빔포밍 모델을 이용하여 뉴럴 네트워크 연산을 수행하는 뉴럴 프로세서; 상기 뉴럴 프로세서의 연산 결과와 상기 제1 소리 신호에 대한 푸리에 변환 결과에 대해 원소곱을 수행하는 원소곱 모듈; 및 상기 원소곱 결과를 출력하는 출력 모듈을 포함할 수 있다. 상기 빔포밍 시스템은, 상기 원소곱을 수행하기 전에 상기 연산 결과에 대해 마스크를 적용하는 마스킹 모듈을 더 포함할 수 있다. 상기 빔포밍 시스템은, 상기 원소곱을 수행한 후에 이득 제어를 수행하는 이득 제어 모듈을 더 포함할 수 있다. 상기 미리 정해진 거리는 10 cm 내지 14 cm일 수 있다. 상기 빔포밍 시스템은, 상기 위상차를 이용하여 상기 빔포밍 모델을 학습시키는 학습 모델을 더 포함할 수 있다."}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예들에 따르면, 다양한 소음 환경에 대한 조향 벡터와 공간상관행렬을 연산할 필요없이 위상차 만을 이용하여 마이크에서 수신되는 음성을 복원할 수 있어, 빔포밍을 효율적으로 구현할 수 있다. 또한, 경량 화된 오토인코더의 적용이 가능하여 경량화 및 소형화를 가능하게 할 수 있다."}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명의 실시 예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 및 청구범위 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재 가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 \"...부\", \"...기\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미 하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 아래에서 설명되는 실시 예들에 따른 빔포밍 방법, 빔포밍 장치 및 빔포밍 시스템 중 적어도 일부는 프로그램 또는 소프 트웨어로 구현될 수 있고, 프로그램 또는 소프트웨어는 컴퓨터로 판독 가능한 매체에 저장될 수 있다. 도 1은 본 발명의 일 실시 예에 따른 빔포밍 시스템을 설명하기 위한 도면이다. 도 1을 참조하면, 본 발명의 일 실시 예에 따른 빔포밍 시스템은 제1 마이크(M1), 제2 마이크(M2) 및 연결 단자(T)를 포함하는 빔포밍 장치와 모니터를 포함할 수 있다. 빔포밍 장치는 모니터에 부착되어 마이크(M1, M2)를 이용하여 소리를 수신할 수 있다. 예를 들어, 빔포 밍 장치는 마이크(M1, M2)를 이용하여 모니터 앞에서 화상 회의에 참여하는 사람의 목소리를 수신할 수 있다. 특히, 빔포밍 장치는 주변 소음이 많은 환경에서 화상 회의를 참여하는 사람의 목소리를 수신할 수 있다. 빔포밍 장치는, 마이크(M1, M2)를 이용하여 수신한 소리 신호에 대해 빔포밍을 수행한 후, 그 결과로서 획 득한 빔포밍된 소리 신호를 출력할 수 있다. 예를 들어, 빔포밍 장치는 주변 소음이 많은 환경에서 화상 회 의에 참여하는 사람의 목소리를 분별하여 다른 컴퓨팅 장치(예컨대 모니터가 연결된 개인용 컴퓨터)에 제공 할 수 있다. 그러면 해당 컴퓨터 장치는 분별된 사람의 목소리를, 예컨대 다른 화상 회의 참여자에게 제공할 수 있다. 빔포밍 장치가 사람의 목소리를 분별한 출력 신호를 다른 컴퓨팅 장치에 제공하기 위해 연결 단자 (T)가 사용될 수 있으며, 본 실시 예에서 연결 단자(T)는 USB(Universal Serial Bus) 단자일 수 있으나, 본 발 명의 범위가 이에 제한되는 것은 아니다. 본 실시 예에서, 제1 마이크(M1)와 제2 마이크(M2)는 미리 정해진 거리(D)만큼 이격되어 배치될 수 있다. 예를 들어, 제1 마이크(M1)는 제1 측(예를 들어 좌측)에서 화상 회의에 참여하는 사람의 목소리와 주변 소음(즉, 제1 소리 신호)을 수신할 수 있고, 제2 마이크(M2)는, 제1 마이크(M1)로부터 미리 정해진 거리(D)만큼 떨어진 제2 측(예를 들어 우측)에서 화상 회의에 참여하는 사람의 목소리와 주변 소음(즉, 제2 소리 신호)을 수신할 수 있 다. 본 실시 예에서, 제1 마이크(M1)와 제2 마이크(M2) 사이의 미리 정해진 거리(D)는 10 cm 내지 14 cm, 바람직하 게는 12 cm일 수 있으나, 본 발명의 범위가 이에 제한되는 것은 아니다. 도 2는 본 발명의 실시 예들에 따른 빔포밍 장치를 구현하기 위한 컴퓨팅 장치를 설명하기 위한 도면이다. 도 2를 참조하면, 본 발명의 실시 예들에 따른 빔포밍 장치를 구현하기 위한 컴퓨팅 장치는 프로세서, 뉴럴 프로세서, 메모리, 출력 모듈, 제1 마이크(M1) 및 제2 마이크(M2)를 포함할 수 있으며, 해 당 컴퓨팅 장치는 본 발명의 실시 예들에 따른 빔포밍 방법을 수행하기 위해 동작할 수도 있다. 프로세서, 뉴럴 프로세서, 메모리, 출력 모듈, 제1 마이크(M1) 및 제2 마이크(M2)는 버스를 통해 서 로 데이터를 주고 받을 수 있다. 프로세서는 빔포밍 장치에 대한 전반적인 제어를 수행하며, 뉴럴 프로세서와 함께 또는 뉴럴 프 로세서와 독립적으로, 본 명세서에서 설명하는 기능들 및 방법들을 수행할 수 있다. 프로세서는, AP(Application Processor), CPU(Central Processing Unit), GPU(Graphic Processing Unit) 등과 같은 다양 한 종류의 프로세서로 구현될 수 있으며, 본 발명의 범위는 특정 프로세서로 제한되지 않는다.뉴럴 프로세서는 본 명세서에서 설명하는 기능들 및 방법들 중 특히 뉴럴 네트워크 연산을 수행할 수 있다. 예를 들어, 뉴럴 프로세서는 본 명세서에서 설명하는 빔포밍 모델을 이용한 연산을 수행할 수 있다. 여기서 뉴럴 네트워크는 CNN(Convolutional Neural Network)를 포함할 수 있으나, 본 발명의 범위가 이에 제한 되는 것은 아니다. 메모리는 프로세서 또는 뉴럴 프로세서가 연산을 위해 필요로 하는 데이터 또는 구동되는 애플 리케이션을 적재할 수 있다. DRAM(Dynamic Random Access Memory), SRAM(Static Random Access Memory)를 비롯 한 다양한 종류의 휘발성 메모리를 포함할 수 있거나, 플래시 메모리와 같은 비휘발성 메모리를 포함할 수 있거 나, 휘발성 메모리와 비휘발성 메모리의 조합을 포함할 수도 있다. 출력 모듈은 빔포밍 장치가 마이크(M1, M2)를 이용하여 수신한 소리 신호에 대해 빔포밍을 수행한 후, 그 결과로서 획득한 빔포밍된 소리 신호를 출력하기 위한 임의의 입출력 인터페이스 장치를 포함할 수 있다. 또한, 본 발명의 실시 예들에 따른 빔포밍 방법, 빔포밍 장치 및 빔포밍 시스템 중 적어도 일부는 키 제어 방법, 키 제어 장치 및 사용자 기기 중 적어도 일부는 컴퓨팅 장치에서 실행되는 프로그램 또는 소프트웨어로 구현될 수 있고, 프로그램 또는 소프트웨어는 컴퓨터로 판독 가능한 매체에 저장될 수 있다. 또한, 본 발명의 실시 예들에 따른 빔포밍 방법, 빔포밍 장치 및 빔포밍 시스템 중 적어도 일부는 컴퓨팅 장치와 전기적으로 접 속될 수 있는 하드웨어로 구현될 수도 있다. 도 1에서 설명한 바와 같은 빔포밍 장치는 모니터에 부착되도록 구현되며, 사람의 목소리를 분별한 출 력 신호를 제공하기 위해 다른 컴퓨팅 장치에 연결될 수 있다. 여기서 특히 주목할 점은, 빔포밍 장치는 뉴 럴 프로세서를 자체적으로 보유하고 있어, 다른 컴퓨팅 장치의 연산 자원을 사용하지 않고도, 자신의 뉴럴 프로세서를 이용하여 주변 소음이 많은 환경에서 화상 회의에 참여하는 사람의 목소리를 분별하기 위해 뉴 럴 네트워크 연산을 수행할 수 있다는 점이다. 이제 도 3 내지 도 5를 참조하여, 도 3은 본 발명의 실시 예들에 따른 빔포밍 방법에 대해 설명하도록 한다. 도 3은 본 발명의 일 실시 예에 따른 빔포밍 방법을 설명하기 위한 도면이다. 도 3을 참조하면, 본 발명의 일 실시 예에 따른 빔포밍 방법에서, 제1 마이크(M1)는 제1 측으로부터 제1 소 리 신호(S1)를 수신할 수 있다. 예를 들어, 제1 마이크(M1)는 제1 측으로부터 화상 회의에 참여하는 사람의 목 소리와 주변 소음을 포함하는 제1 소리 신호(S1)를 수신하여, 이를 제1 STFT 모듈(도면 상에서는 L_STFT 모듈로 표시함)에 전달할 수 있다. 제1 STFT 모듈은, 제1 마이크(M1)로부터 수신한 제1 소리 신호(S1)에 대해 푸리에 변환 연산을 수행하고, 제1 소리 신호(S1)에 대한 푸리에 변환 결과(P1)를 획득할 수 있다. 한편, 제1 마이크(M1)로부터 미리 정해진 거리(D)만큼 이격되어 배치되는 제2 마이크(M2)는 제2 측으로부터 제2 소리 신호(S2)를 수신할 수 있다. 예를 들어, 제2 마이크(M2)는 제2 측으로부터 화상 회의에 참여하는 사람의 목소리와 주변 소음을 포함하는 제2 소리 신호(S2)를 수신하여, 이를 제2 STFT 모듈(도면 상에서는 R_STFT 모듈로 표시함)에 전달할 수 있다. 제2 STFT 모듈은, 제2 마이크(M2)로부터 수신한 제2 소리 신호(S2)에 대해 푸리에 변환 연산을 수행하고, 제2 소리 신호(S2)에 대한 푸리에 변환 결과(P2)를 획득할 수 있다. 위상차 획득 모듈은, 제1 STFT 모듈로부터 제공받은 푸리에 변환 결과(P1) 및 제2 STFT 모듈로 부터 제공받은 푸리에 변환 결과(P2)로부터, 제1 소리 신호(S1)와 제2 소리 신호(S2)의 위상차(dP)를 획득할 수 있다. 학습 모듈은, 제1 소리 신호(S1)와 제2 소리 신호(S2)의 위상차(dP)를 이용하여 빔포밍 모델를 학습 시킬 수 있다. 이에 따라, 빔포밍 모델은, 제1 마이크(M1)와 제2 마이크(M2)를 통해 수신되는 2 가지 소리 신호의 위상차만으로 빔포밍을 수행할 수 있도록 학습될 수 있다. 학습 시, 제1 마이크(M1)와 제2 마이크(M2) 사이의 미리 정해진 거리(D)는 10 cm 내지 14 cm, 바람직하게는 12 cm일 수 있으나, 본 발명의 범위가 이에 제한되는 것은 아니다. 미리 정해진 거리(D)가 12 cm일 때 학습된 빔포 밍 모델의 성능은, 추론 시 제1 마이크(M1)와 제2 마이크(M2) 사이의 거리가 10 cm 내지 14 cm인 경우에까 지 성능을 발휘할 수 있다.도 4는 본 발명의 일 실시 예에 따른 빔포밍 방법을 설명하기 위한 도면이다. 도 4를 참조하면, 본 발명의 일 실시 예에 따른 빔포밍 방법에서, 제1 마이크(M1)는 제1 측으로부터 제1 소 리 신호(S1)를 수신할 수 있다. 예를 들어, 제1 마이크(M1)는 제1 측으로부터 화상 회의에 참여하는 사람의 목 소리와 주변 소음을 포함하는 제1 소리 신호(S1)를 수신하여, 이를 제1 STFT 모듈(도면 상에서는 L_STFT 모듈로 표시함)에 전달할 수 있다. 제1 STFT 모듈은, 제1 마이크(M1)로부터 수신한 제1 소리 신호(S1)에 대해 푸리에 변환 연산을 수행하고, 제1 소리 신호(S1)에 대한 푸리에 변환 결과(P1)를 획득할 수 있다. 한편, 제1 마이크(M1)로부터 미리 정해진 거리(D)만큼 이격되어 배치되는 제2 마이크(M2)는 제2 측으로부터 제2 소리 신호(S2)를 수신할 수 있다. 예를 들어, 제2 마이크(M2)는 제2 측으로부터 화상 회의에 참여하는 사람의 목소리와 주변 소음을 포함하는 제2 소리 신호(S2)를 수신하여, 이를 제2 STFT 모듈(도면 상에서는 R_STFT 모듈로 표시함)에 전달할 수 있다. 제2 STFT 모듈은, 제2 마이크(M2)로부터 수신한 제2 소리 신호(S2)에 대해 푸리에 변환 연산을 수행하고, 제2 소리 신호(S2)에 대한 푸리에 변환 결과(P2)를 획득할 수 있다. 위상차 획득 모듈은, 제1 STFT 모듈로부터 제공받은 푸리에 변환 결과(P1) 및 제2 STFT 모듈로 부터 제공받은 푸리에 변환 결과(P2)로부터, 제1 소리 신호(S1)와 제2 소리 신호(S2)의 위상차(dP)를 획득할 수 있다. 도 3에서 설명한 바와 같이 학습이 완료된 빔포밍 모델은 제1 소리 신호(S1)와 제2 소리 신호(S2)의 위상 차(dP)을 입력으로 받아 뉴럴 네트워크 연산(즉, 추론 연산)을 수행할 수 있다. 마스킹 모듈은 추론 연산 결과에 대해 마스크를 적용할 수 있으며, 이어서 원소곱 모듈은, 추론 연산 결과(또는 마스크가 적용된 결과)와 제2 STFT 모듈로부터 제공받은 제2 소리 신호(S2)에 대한 푸리에 변환 결과(P2)에 대해 원소곱을 수행할 수 있다. 여기서 원소곱은 동일한 크기의 2 개 행렬의 각 성분을 곱하는 연산 일 수 있다. 출력 모듈은 원소곱 모듈로부터 제공받은 원소곱 결과(S3)를 출력할 수 있다. 예를 들어, 출력 모듈 은, 빔포밍 모델를 이용하여 마이크(M1, M2)를 이용하여 수신한 소리 신호에 대해 빔포밍을 수행한 결과로서 획득한 빔포밍된 소리 신호(S3)를 출력할 수 있다. 예를 들어, 빔포밍된 소리 신호(S3)는 주변 소음이 많은 환경에서 화상 회의에 참여하는 사람의 목소리를 분별한 것일 수 있고, 다른 컴퓨팅 장치(예컨대 모니터 가 연결된 개인용 컴퓨터)에 제공되고, 이어서 다른 화상 회의 참여자에게 제공될 수 있다. 도 5는 본 발명의 일 실시 예에 따른 빔포밍 방법에 대한 일 구현 예를 설명하기 위한 도면이다. 방향성 청력을 위해서는 기본적으로 2 개 이상의 마이크가 필요하다. 마이크 배열의 기하학적 형태는 각 마이크 에 의해 수신되는 신호가 정렬되는 공간적 특성을 가지고 있다. 빔포밍을 위한 마스크를 획득하는 과정은 다음 과 같이 공식화할 수 있다. 우선, 다수의 마이크으로부터 수신된 각각의 신호를 STFT(short time Fourier transform)하여 스펙트로그램을 얻을 수 있다고 하자. 는 얻고자 하는 음성이고 아래와 같이 표현된다."}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또 는 잡음이라고 할때, 음성과 잡음이 동시에 들어오는 마이크 배열의 입력은 로 나타낼 수 있다.는 각도에 따른 마이크 배열의 특성을 나타낸다. 이 때 입력된 스펙트로그램에 필터 를 취해준다고 하면, 그 결과는 가 된다. 따라서 입력 신호의 크기를 최소화하되 얻고자 하는 신호는 남기는 방향으로 를 디자인할 수 있다. 굵은 문자로 표시한 것이 벡터라 하면 일 때"}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "가 되고 이때 해는"}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "로 구해질 수 있다. 여기서, 윗첨자 는 켤레 복소수를 취해준 뒤 전치한 행렬을 말한다. 따라서 구해진 필터를 이용해서 얻고자 하는 음성의 스팩트로그램은 와 같이 얻을 수 있다. 이러한 방식을 사 용하여 빔포밍을 구현하는 경우에 가장 중요한 부분은 바로 조향벡터 와 공간상관행렬 를 정확하게 구 하는 것이다. 이와 같이, 뉴럴 네트워크를 사용하지 않는 MVDR 방식에서, MVDR을 정확하게 만족하기 위해서는 음원에서 발생 한 소리가 각각의 마이크에 도달하기까지의 경로를 수학적으로 모델링하는 조향벡터가 필요한데, 화상대화와 같 이 마이크와 사용자의 입이 가까운 거리, 예를 들어 1m 내외에 위치하고, 마이크의 간격 또한 근접한 거리, 예 를 들어 수cm 또는 십 수cm 정도인 경우에는 수학적 모델링이 매우 어렵다. 또한, 실제 화상대화 환경에서와 같 이 사용자가 불규칙하게 움직이는 경우, 조향벡터를 고정 값을 둘 경우 사용자의 불편도는 더욱 올라가게 되는 한계점들이 있다. 이러한 한계점들을 극복하기 위해, 조향벡터가 아닌 뉴럴 네트워크를 이용할 수 있다. 또 본 방식에서 뉴럴 네트워크의 입력으로 사용하는 위상차 행렬은 기존의 방식에서 음원의 위치 정보를 얻기 위해 사용하는 공간상관행렬보다 구하는 과정이 간단하여 더욱 쉽게 음원의 위치정보를 얻을 수 있다. 본 발명 의 일 실시 예에 따른 빔포밍 방법에서는, 단지 2 개의 마이크에서 공간 정보를 위한 뉴럴 네트워크를 훈련시키 고 이를 통해 미리 정해진 방향으로 소리를 획득할 수 있다. 따라서 아래와 같은 이점을 가진다. 1. 실제 상황에서 고정된 마이크로 측정할 때 움직이는 대상에 대한 조향벡터를 정확하게 정의할 필요가 없다. 2. 선형 필터를 구하는 과정에서 발생하는 특이점(Singular point)의 발산이 사라진다. 이는 정면 이외에서 의 파워인 사이드 로브(side lobe)를 줄여주어 자동으로 사이드 로브 제거(side lobe cancelation) 효과 를 가져온다. 3. 정면 이외의 각도에서 복원되는 음성의 STOI값으로 볼 때 여러 방향에서 음성 신호가 들어올 경우 MVDR의 측 면 STOI가 뉴럴 네트워크의 STOI보다 더 크게 나타나며, 즉, 뉴럴 네트워크를 이용할 때 정면의 음성신호를 더 정확히 구분해 낸다. 음원과 마이크 사이에 장애물이 없을 때는 음원의 각도에 의해서만 음의 이동 경로가 영향을 받는다. 양쪽 마이 크와 음원의 거리가 같기 때문에 앞에서 들려오는 소리는 서로 같다. 즉, 전방 소스의 도착 시간 차이(TDOA)는 0에 근접한다. 이 점을 이용하면 앞에서 들려오는 소리를 그대로 남길 수 있다.임의의 위치에 있는 음원에서 발생하여 두 마이크에 도달한 소리를 라 하면 각각의 신호로부터 2 개의 위상행렬 를 구할 수 있다. 이 위상행렬간의 차이가 0에 가까울수록 정면에서 가까운 음원이 만들어낸 소리를 의미한다. 이것을 구분하기 위하여 입력이 0에서 멀어질 수록 0에 가까운 출력을 내고 입력이 0에 가까울 수록 1을 출력으로 내는 함수를 생각해 본다면 정면에서 오는 신호만을 남기는 마스크를 만 드는 것이 가능하다. 따라서 아래의 오차 을 최소화하는 마스크 을 찾으면 정면에서 오는 신호를 복원할 수 있다."}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "푸리에 변환을 사용할 때 신호는 각 주파수의 단순한 퓨어 톤(pure tone)의 합이라고 생각할 수 있지만 동일한 주파수의 두 퓨어 톤은 위상 지연을 통해 합쳐질 경우 전혀 새로운 퓨어 톤 신호를 만든다. 이 문제는 양쪽 마 이크의 위상 차이가 음원의 각도에 정확히 비례하지 않는 상황을 만들 수 있으므로 단순히 위상차에만 의존하는 규칙에 기반하여 마스크를 만드는 것은 부정확하다. 음성을 얻는 일은 광범위한 주파수를 처리하는 필터가 필요 하므로 이 문제를 해결해야 한다. 이를 극복하기 위한 방안으로 본 발명의 실시 예들은 뉴럴 네트워크와 기준 마이크의 스펙트로그램 패턴을 통해 위상 차이를 인식하는 방법을 제공한다. 도 6을 참조하면, 설계하고자 하는 마스크는 실수로 정의된 0과 1 사이의 마스크이기 때문에 IBM(Ideal Binary Mask)와 유사한 기능을 수행할 수 있다. 다만 그 사이값이 있기 때문에 SBM(Soft Binary Mask)가 될 수 있다. 기존 IBM를 이용한 뉴럴 네트워크에 대한 연구를 보면, 시끄러운 위상을 그대로 사용했다. 이로부터, 노이즈가 있는 스펙트로그램으로 스피치를 재구성할 때, 스피치의 구성과 관련된 주파수 영역을 남겨두는 것만으로 신호 의 스피치 재구성이 가능하다. 그러므로 SBM 방식의 뉴럴 네트워크로 구한 마스크는 위상차로부터 매그니튜드에 적용되는 방향성 청각 마스크를 만들어 내는데, 이는 위상차가 나는 원소더라도 신호를 남기는 기능을 수행한다. 한편, TDOA로부터 방향 정보를 보다 명확하게 얻기 위해 가정된 시간 지연을 최적화하는 것을 제시하 는 방법이 있으나, 본 발명의 다양한 실시 예에서는 CNN을 사용한다. CNN은 이미지와 같은 2D 행렬에 더 효율적 이고, 계산 능력이 덜 필요하기 때문이다. 또한, 콘볼루션 필터는 이상적인 마스크의 위상차에 따른 감소폭에 최적화되어 있다. 한편, 뉴럴 네트워크에 위상차만이 입력으로 들어가는 경우 목표하는 음성의 패턴을 학습할 수 없다는 문제점을 방지하기 위해 역전파를 이용할 수 있다. 시간 영역에서 구해지는 MSE(mean squared erro r)는 위상 정보가 있는 마스크를 훈련시키는 손실 함수(loss function)로 사용되는데 앞서 말한 방식은 이 방법 과 비슷한 방식이다. 역 STFT(ISTFT)로 마스크된 스펙트로그램을 복원함으로써, 손실 함수를 이용하여 시간 영 역의 깨끗한 표적 소리와 비교할 수 있다. 이 경우 업데이트할 그레디언트값은 기준 마이크에 대한 음성 패턴 정보를 포함할 수 있다. 다양한 상황의 데이터로 모델을 훈련시키기 위해, 시뮬레이션 방법을 사용하여 소정의 데이터 세트를 생성하고, 뉴럴 네트워크를 이용하여 대상의 음성을 재구성하였으며, 스테레오 채널 음원은 10x10x10m 공간 시뮬레이션을 통해 생성되었다. 마이크의 높이는 2m로 좌우 6cm 간격으로 2 개 위치(9, 5.06, 2)와 (9, 4.94, 2)로 지정된다. 음원은 지름 1미터의 반원 상에 위치하며 이때 반원의 중심은 마이크의 중심과 동일하다. 얻고자 하는 음원의 위치는 정면인 , (7, 5, 2)에 위치한다. 그리고 반원 상의 4개의 구간 을 나누어 각 구간별 무작위 위치에 잡음의 음원을 배치한다. 음성 데이터 세트 중 일부는 훈련 데이터에 사용되었으며, 다른 일부는 시험 데이터로 사용되었다. 소음 데이터 세트 는 두 개의 인공 소음(speech shape noise 및 babble noise)과 DEMAND database를 사용했으며, 이는 13개의 녹 음된 소음이다. 훈련 데이터는 2개의 인공 소음과 8개의 녹음된 소음(카페, 자동차, 키친, 미팅, 메트로, 레스 토랑, 역, 교통)으로 구성된다. 시험 데이터는 5개의 녹음된 소음(버스, 카페테리아, 거실, 사무실 및 공용 광 장)으로 구성된다. 소음을 내기 위해 동일한 소음 신호의 무작위 지점 4개에서 음성의 길이만큼 소음이 추출되었다. 그 후 네 군데의 음원으로 부터 소리가 나오는 것으로 시뮬레이션 하여, 마이크 2 개로 수용하는 방식을 채택했다. 훈련 데이터의 경우 40가지 조건 즉 소음 상황 10개와 SNR 4개(0dB, 5dB, 10dB, 15dB)의 조합을 사용했다. 시험 데이터는 20개의 다른 조건 즉 5개의 소음 상황과 4개의 SNR(2.5dB, 7.5dB, 12.5dB, 17.5dB)의 조합을 사용했 다. 이때는 image-source method의 Room impulse response를 이용하여 거리에 따른 에너지 감소만을 시뮬레이 션 하였다. 잔향은 고려하지 않기 위하여 잔향시간( )은 0으로 설정했다. 2 개의 마이크가 수신한 각 신호는 STFT를 통해 푸리에 영역으로 변환되었다. STFT는 16kHz 샘플 레이트(sample rate)의 신호에 256 포인트 해밍 윈도우(hamming window)를 사용한다. 윈도우 시프트(window shift)는 128 포 인트(128 포인트의 겹쳐짐)을 사용한다. 뉴럴 네트워크 조작이 완료된 후 ISTFT 작업을 수행할 때도 동일한 조 건이 사용된다. 모델 구조는 표 1의 구조를 따른다. 입력 값은 STFT 결과 중 낮은 주파수 128 개만 포함한 것이다. 뉴럴 네트워크의 결과로 얻어진 마스크와 입력된 128 개 주파수의 스펙트로그램을 곱하고, 129번째 주파수를 0으로 채워서 ISTFT하여 복원된 신호를 얻는다. 표 1"}
{"patent_id": "10-2020-0146191", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 입력은 (batch, frequency, time step, channel)로 이루어진다. 그리고 컨벌루션 레이어는 (filter height, filter width),(stride height, stride width),(padding height, padding width) 로 구성된다. 출력 은 (batch, frequency, time step, channel)로 구성된다. 활성함수는 모두 PReLU가 사용되었다. 가장 마지막 레이어의 활성함수는 시그모이드 함수를 사용하여 1채널과 2채널을 각각 마스크의 실수부, 허수부로 사용했다. 본 발명의 실시 예들에 따른 유리한 효과는 도 9 및 도 10과 관련하여 후술하도록 한다. 도 6은 본 발명의 일 실시 예에 따른 빔포밍 시스템을 설명하기 위한 도면이고, 도 7은 본 발명의 일 실시 예에 따른 빔포밍 시스템을 설명하기 위한 도면이고, 도 8은 본 발명의 일 실시 예에 따른 빔포밍 시스템을 설명하기위한 도면이다. 도 6을 참조하면, 본 발명의 일 실시 예에 따른 빔포밍 시스템은, 제1 마이크(M1) 및 제2 마이크(M2)를 구비 하는 모니터로 구현될 수 있다. 도 7을 참조하면, 본 발명의 일 실시 예에 따른 빔포밍 시스템은, 스마트 폰을 비롯한 포터블 컴퓨팅 장치 를 거치할 수 있는 거치대형 장치를 포함하도록 구현될 수 있다. 그리고 마이크(M1, M2)를 이용하여 수 신한 소리 신호에 대해 빔포밍을 수행한 후, 그 결과로서 획득한 빔포밍된 소리 신호는 임의의 접속 수단을 통 해 포터블 컴퓨팅 장치에 제공될 수 있다. 그러면 컴퓨터 장치는 분별된 사람의 목소리를, 예컨대 다른 화상 회의 참여자에게 제공할 수 있다. 도 8을 참조하면, 본 발명의 일 실시 예에 따른 빔포밍 시스템은, 스마트 폰을 비롯한 포터블 컴퓨팅 장치 에 부착할 수 있는 부착형 장치로 구현될 수 있다. 그리고 마이크(M1, M2)를 이용하여 수신한 소리 신 호에 대해 빔포밍을 수행한 후, 그 결과로서 획득한 빔포밍된 소리 신호는 임의의 접속 수단을 통해 포터블 컴 퓨팅 장치에 제공될 수 있다. 그러면 컴퓨터 장치는 분별된 사람의 목소리를, 예컨대 다른 화상 회의 참여자에게 제공할 수 있다. 도 9 및 도 10은 본 발명의 실시 예들에 따른 빔포밍 방법 및 빔포밍 시스템의 유리한 효과를 설명하기 위한 도 면이다. 제1 마이크(M1)와 제2 마이크(M2) 사이의 미리 정해진 거리(D)가 12 cm인 경우의 빔포밍 알고리즘에 8, 10, 12, 14, 16 cm의 마이크 거리로 시뮬레이션한 데이터를 넣어서 측정한 결과로, 도 9는 고전적인 방식(MVDR)을 이용 한 빔포밍의 각도별 소리 크기(윗줄)와 STOI(short-time objective intelligibility) 점수(아래줄)를 나타낸 것이고, 도 10은 본 발명의 다양한 실시 예들에 따른 뉴럴 네트워크를 이용한 빔포밍의 각도별 소리 크기(윗 줄)와 STOI점수(아래줄)를 나타낸 것이다. STOI는 소리의 크기와 무관하게 소리의 복원된 정도와 관련 있는 지표로써 고전적인 방식의 경우 듣고자 하는 방향이 아닌 방향에서 STOI가 높게 나타나는 반면, 본 발명의 다양한 실시 예들에 따른 뉴럴 네트워크 방식의 측면에서는 낮게 나타나며, 이를 통해, 본 발명의 다양한 실시 예들에 따른 뉴럴 네트워크 방식이, 원하는 방향 이 아닌 곳의 발화자가 말한 음성을 더 확실하게 분리하며 더 적게 방해를 받는다는 것을 알 수 있다. 이제까지 설명한 본 발명의 실시 예들에 따르면, 다양한 소음 환경에 대한 조향 벡터를 연산할 필요없이 위상차 만을 이용하여 마이크에서 수신되는 음성을 복원할 수 있어, 빔포밍을 효율적으로 구현할 수 있다. 기존 MVDR의 경우 잔향이 심한 환경에서는 조향벡터를 얻기 힘들고 잔향이 없는 환경이라 하더라도 화상대화의 경우 원거리의 음원을 가정한 꼴을 구할 수 없어 간단한 꼴의 조향벡터를 구하는 것이 힘들어진다. 또 실재 상 황에서는 화자가 움직이는 경우가 많은데 조향벡터를 정확하게 예측할수록 이러한 환경에서 사용하는 것이 어려 워진다. 또한 위에서 로 표현한 공간상관행렬을 구할 때 잡음이 섞인 소리를 이용하므로 정확한 예측이 불 가능하다. 하지만, 본 방식은 뉴럴 네트워크를 사용하여 많은 양의 데이터로부터 공간정보를 학습하므로 조향벡 터를 계산하지 않고 깨끗한 음성신호를 표적음성으로 하여 학습하는 방법을 사용하기 때문에, 정확한 학습이 가 능하다. 본 방법을 통해서 훈련한 인공지능 모델과 기존의 방식인 MVDR방식으로 824개의 시험데이터를 계산하고 구해진 정면 소리의 평균 SSNR(Segmented Signal to Noise Ratio)지표를 보면 잡음이 포함된 소리는 -1.557, MVDR을 이용한 소리는 -0.120, 뉴럴 네트워크를 통과한 모델은 2.165으로 뉴럴 네트워크 모델이 가장 높은 것을 알 수 있다. 이상에서 본 발명의 실시 예에 대하여 상세하게 설명하였지만 본 발명의 권리 범위는 이에 한정되는 것은 아니 고, 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한, 본 발명이 속하는 기술 분야에서 통상 의 지식을 가진 자의 여러 변형 및 개량 형태 또한 본 발명의 권리 범위에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2020-0146191", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 빔포밍 시스템을 설명하기 위한 도면이다. 도 2는 본 발명의 실시 예들에 따른 빔포밍 장치를 구현하기 위한 컴퓨팅 장치를 설명하기 위한 도면이다. 도 3은 본 발명의 일 실시 예에 따른 빔포밍 방법을 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시 예에 따른 빔포밍 방법을 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시 예에 따른 빔포밍 방법에 대한 일 구현 예를 설명하기 위한 도면이다. 도 6은 본 발명의 일 실시 예에 따른 빔포밍 시스템을 설명하기 위한 도면이다. 도 7은 본 발명의 일 실시 예에 따른 빔포밍 시스템을 설명하기 위한 도면이다. 도 8은 본 발명의 일 실시 예에 따른 빔포밍 시스템을 설명하기 위한 도면이다.도 9 및 도 10은 본 발명의 실시 예들에 따른 빔포밍 방법 및 빔포밍 시스템의 유리한 효과를 설명하기 위한 도 면이다."}
