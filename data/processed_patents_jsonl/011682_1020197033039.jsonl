{"patent_id": "10-2019-7033039", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0138834", "출원번호": "10-2019-7033039", "발명의 명칭": "자연어 기반 컴퓨터 애니메이션", "출원인": "라운드파이어, 인크.", "발명자": "볼든, 알렌"}}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법으로서,입력을 수신하는 단계 ― 상기 입력은 텍스트, 음성, 또는 제스처 중 적어도 하나를 포함함 ―; 상기 입력에 기초하여, 하나 이상의 커맨드 명령어들을 결정하는 단계 ― 상기 하나 이상의 커맨드 명령어들을결정하는 단계는:상기 입력을 복수의 라인 세그먼트들로 파싱하는 단계,자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 처리하는 단계 ― 상기 처리는 상기 라인 세그먼트들각각을 자연어 커맨드 데이터베이스와 비교하는 단계를 포함함 ―, 및상기 비교에 기초하여 적어도 하나의 인식된 라인 세그먼트를 결정하는 단계를 포함하고, 상기 하나 이상의 커맨드 명령어들은 상기 적어도 하나의 인식된 라인 세그먼트에 기초함 ―;상기 하나 이상의 커맨드 명령어들에 기초하여 장면 레이아웃을 결정하는 단계; 및 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 제공하는 단계를 포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 하나 이상의 커맨드 명령어들의 각각은 상기 장면 레이아웃의 적어도 하나의 요소에 대응하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 입력은 텍스트를 포함하고, 상기 입력을 수신하는 단계는 상기 텍스트를 그래픽 사용자 인터페이스에서의텍스트 엔트리를 통해 수신하는 단계를 포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 입력은 음성을 포함하고, 상기 입력을 수신하는 단계는 상기 음성을 마이크로폰을 통해 수신하는 단계를포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 입력은 제스처를 포함하고, 상기 입력을 수신하는 단계는 상기 제스처를 카메라를 통해 수신하는 단계를포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 처리하는 단계는 상기 복수의 라인 세그먼트들이 상기 자연어 인식 알고리즘으로 순차적으로 처리되는 것을 포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 공개특허 10-2019-0138834-3-자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 처리하는 단계는 상기 복수의 라인 세그먼트들 중 적어도 일부가 상기 자연어 인식 알고리즘으로 동시에 처리되는 것을 포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 방법은: 상기 하나 이상의 커맨드 명령어들의 각각을 객체 커맨드 명령어, 언어 커맨드 명령어, 또는 환경 커맨드 명령어 중 적어도 하나로 분류하는 단계; 및각각의 분류된 커맨드 명령어를 적어도 하나의 대응하는 데이터베이스에 저장하는 단계 ― 상기 대응하는 데이터베이스는 객체 데이터베이스, 언어 데이터베이스, 또는 환경 데이터베이스 중 적어도 하나를 포함함 ―를 추가로 포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 장면 레이아웃을 결정하는 단계는:각각의 객체 커맨드 명령어에 대해, 적어도 하나의 객체 및 적어도 하나의 대응하는 객체 위치를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 장면 레이아웃을 결정하는 단계는:각각의 환경 커맨드 명령어에 대해, 적어도 하나의 환경 요소 및 적어도 하나의 대응하는 환경 요소 위치를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 방법은 난수 생성기로 의사 랜덤 시드를 생성하는 단계를 추가로 포함하고, 상기 하나 이상의 커맨드 명령어들 또는 상기 장면 레이아웃 중 적어도 하나를 결정하는 단계는 상기 의사 랜덤 시드와 연관된 각각의 커맨드명령어 또는 각각의 장면 레이아웃을 선택하는 것에 더 기초하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 렌더링된 장면을 제공하는 단계는, 전용 그래픽 프로세서를 사용하여, 상기 결정된 장면 레이아웃에 기초하여렌더링된 장면을 렌더링하는 단계를 포함하고, 상기 전용 그래픽 프로세서는 그래픽 처리 유닛(GPU)을포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 방법은 출력을 HTML 호환 가능 포맷으로 제공하는 단계를 추가로 포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서, 상기 방법은 출력을 제공하는 단계를 추가로 포함하고, 상기 출력은 가상 현실 디스플레이 또는 증강 현실 디스플레이 중 적어도 하나와 호환 가능한 포맷을 포함하는, 방법.공개특허 10-2019-0138834-4-청구항 15 제1항에 있어서, 상기 방법은 거의 실시간으로 수행되며, 상기 거의 실시간은 상기 하나 이상의 커맨드 명령어들을 50 밀리 초마다 적어도 1회 결정하는 것 또는 상기 장면 레이아웃을 50 밀리 초마다 적어도 1회 결정하는 것 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항에 있어서, 상기 방법의 하나 이상의 단계들은 머신 학습을 이용하는 지능형 에이전트 또는 인공 지능 구성물에 의해 수행되는, 방법."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "시스템으로서,입력 디바이스;렌더 처리 유닛;디스플레이; 및적어도 하나의 메모리 및 적어도 하나의 프로세서를 포함하는 제어기를 포함하고, 상기 제어기는 명령어들을 실행하여 동작들을 수행하고, 상기 동작들은: 상기 입력 디바이스를 통해, 텍스트, 음성, 또는 제스처 중 적어도 하나를 나타내는 입력 정보를 수신하는 것;상기 수신된 입력 정보에 기초하여, 하나 이상의 커맨드 명령어들을 결정하는 것 ― 상기 하나 이상의 커맨드명령어들을 결정하는 것은: 상기 수신된 입력 정보를 복수의 라인 세그먼트들로 파싱하는 것;자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 처리하는 것 ― 상기 처리는 상기 라인 세그먼트들각각을 자연어 커맨드 데이터베이스와 비교하는 것을 포함함 ―; 및상기 비교에 기초하여 적어도 하나의 인식된 라인 세그먼트를 결정하는 것을 포함하고, 적어도 하나의 커맨드명령어는 상기 적어도 하나의 인식된 라인 세그먼트에 기초함 ―; 상기 하나 이상의 커맨드 명령어들에 기초하여 장면 레이아웃을 결정하는 것; 상기 렌더 처리 유닛을 사용하여, 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 렌더링하는 것; 및상기 렌더링된 장면을 상기 디스플레이를 통해 디스플레이하는 것을 포함하는, 시스템."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 동작들은:각각의 커맨드 명령어를 객체 커맨드 명령어, 언어 커맨드 명령어, 또는 환경 커맨드 명령어 중 적어도 하나로분류하는 것; 및각각의 분류된 커맨드 명령어를 적어도 하나의 대응하는 데이터베이스에 저장하는 것 ― 상기 대응하는 데이터베이스는 객체 데이터베이스, 언어 데이터베이스, 또는 환경 데이터베이스 중 적어도 하나를 포함함 ―을 추가로 포함하는, 시스템."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서, 공개특허 10-2019-0138834-5-상기 디스플레이는 가상 현실 디스플레이 또는 증강 현실 디스플레이 중 적어도 하나를 포함하는, 시스템."}
{"patent_id": "10-2019-7033039", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨팅 디바이스에 의해 실행될 때 상기 컴퓨팅 디바이스로 하여금 동작들을 수행하게 하는 명령어들을 저장한비 일시적 컴퓨터 판독가능 매체로서, 상기 동작들은: 입력을 수신하는 것 ― 상기 입력은 텍스트, 음성, 또는 제스처 중 적어도 하나를 포함함 ―; 상기 입력에 기초하여, 적어도 하나의 커맨드 명령어를 결정하는 것 ― 상기 적어도 하나의 커맨드 명령어를 결정하는 것은:상기 입력을 복수의 라인 세그먼트들로 파싱하는 것,자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 처리하는 것 ― 상기 처리는 상기 라인 세그먼트들각각을 자연어 커맨드 데이터베이스와 비교하는 것을 포함함 ―, 및 상기 비교에 기초하여 적어도 하나의 인식된 라인 세그먼트를 결정하는 것을 포함하고, 상기 적어도 하나의 커맨드 명령어는 상기 적어도 하나의 인식된 라인 세그먼트에 기초함 ―;상기 적어도 하나의 커맨드 명령어에 기초하여 장면 레이아웃을 결정하는 것;상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 제공하는 것 ― 각각의 커맨드 명령어는 상기 장면 레이아웃의 적어도 하나의 요소에 대응함 ―;각각의 커맨드 명령어를 객체 커맨드 명령어, 언어 커맨드 명령어, 또는 환경 커맨드 명령어 중 적어도 하나로분류하는 것; 각각의 분류된 커맨드 명령어를 적어도 하나의 대응하는 데이터베이스에 저장하는 것 ― 상기 대응하는 데이터베이스는 객체 데이터베이스, 언어 데이터베이스, 또는 환경 데이터베이스 중 적어도 하나를 포함함 ―; 및출력을 HTML 호환 가능 포맷으로 제공하는 것을 포함하는, 비 일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2019-7033039", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시 내용은 오디오, 텍스트, 또는 제스처 입력에 기초하여 그래픽 콘텐츠의 거의 실시간 동적 생성을 가능하 게 하는 시스템들, 방법들, 및 비 일시적 컴퓨터 판독가능 매체에 관한 것이다. 일 예시적인 방법은 마이크로폰, 키보드, 또는 카메라와 같은 입력 디바이스로부터 입력을 수신하는 단계를 포함한다. 이와 같이, 입력은 텍스트, 음성, 및/또는 제스처를 포함할 수 있다. 상기 방법은 입력에 기초하여 하나 이상의 커맨드 명 령어들을 결정하는 단계를 포함한다. 상기 방법은 또한 하나 이상의 커맨드 명령어들에 기초하여 장면 레이아웃 을 결정하는 단계를 포함한다. 하나 이상의 커맨드 명령어들의 각각은 장면 레이아웃의 적어도 하나의 요소에 대응한다. 상기 방법은 또한 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 제공하는 단계를 포함한다. 공개특허10-2019-0138834 CPC특허분류 G06F 3/011 (2013.01) G06F 3/017 (2013.01) G06F 3/0484 (2013.01) G06F 3/167 (2013.01) G06T 19/00 (2013.01) G10L 15/22 (2013.01)명 세 서 청구범위 청구항 1 방법으로서, 입력을 수신하는 단계 ― 상기 입력은 텍스트, 음성, 또는 제스처 중 적어도 하나를 포함함 ―; 상기 입력에 기초하여, 하나 이상의 커맨드 명령어들을 결정하는 단계 ― 상기 하나 이상의 커맨드 명령어들을 결정하는 단계는: 상기 입력을 복수의 라인 세그먼트들로 파싱하는 단계, 자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 처리하는 단계 ― 상기 처리는 상기 라인 세그먼트들 각각을 자연어 커맨드 데이터베이스와 비교하는 단계를 포함함 ―, 및 상기 비교에 기초하여 적어도 하나의 인식된 라인 세그먼트를 결정하는 단계를 포함하고, 상기 하나 이상의 커 맨드 명령어들은 상기 적어도 하나의 인식된 라인 세그먼트에 기초함 ―; 상기 하나 이상의 커맨드 명령어들에 기초하여 장면 레이아웃을 결정하는 단계; 및 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 제공하는 단계 를 포함하는, 방법. 청구항 2 제1항에 있어서, 상기 하나 이상의 커맨드 명령어들의 각각은 상기 장면 레이아웃의 적어도 하나의 요소에 대응하는, 방법. 청구항 3 제1항에 있어서, 상기 입력은 텍스트를 포함하고, 상기 입력을 수신하는 단계는 상기 텍스트를 그래픽 사용자 인터페이스에서의 텍스트 엔트리를 통해 수신하는 단계를 포함하는, 방법. 청구항 4 제1항에 있어서, 상기 입력은 음성을 포함하고, 상기 입력을 수신하는 단계는 상기 음성을 마이크로폰을 통해 수신하는 단계를 포함하는, 방법. 청구항 5 제1항에 있어서, 상기 입력은 제스처를 포함하고, 상기 입력을 수신하는 단계는 상기 제스처를 카메라를 통해 수신하는 단계를 포함하는, 방법. 청구항 6 제1항에 있어서, 자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 처리하는 단계는 상기 복수의 라인 세그먼트들이 상 기 자연어 인식 알고리즘으로 순차적으로 처리되는 것을 포함하는, 방법. 청구항 7 제1항에 있어서, 자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 처리하는 단계는 상기 복수의 라인 세그먼트들 중 적 어도 일부가 상기 자연어 인식 알고리즘으로 동시에 처리되는 것을 포함하는, 방법. 청구항 8 제1항에 있어서, 상기 방법은: 상기 하나 이상의 커맨드 명령어들의 각각을 객체 커맨드 명령어, 언어 커맨드 명령어, 또는 환경 커맨드 명령 어 중 적어도 하나로 분류하는 단계; 및 각각의 분류된 커맨드 명령어를 적어도 하나의 대응하는 데이터베이스에 저장하는 단계 ― 상기 대응하는 데이 터베이스는 객체 데이터베이스, 언어 데이터베이스, 또는 환경 데이터베이스 중 적어도 하나를 포함함 ―를 추 가로 포함하는, 방법. 청구항 9 제8항에 있어서, 상기 장면 레이아웃을 결정하는 단계는: 각각의 객체 커맨드 명령어에 대해, 적어도 하나의 객체 및 적어도 하나의 대응하는 객체 위치를 결정하는 단계 를 포함하는, 방법. 청구항 10 제8항에 있어서, 상기 장면 레이아웃을 결정하는 단계는: 각각의 환경 커맨드 명령어에 대해, 적어도 하나의 환경 요소 및 적어도 하나의 대응하는 환경 요소 위치를 결 정하는 단계를 포함하는, 방법. 청구항 11 제1항에 있어서, 상기 방법은 난수 생성기로 의사 랜덤 시드를 생성하는 단계를 추가로 포함하고, 상기 하나 이상의 커맨드 명령 어들 또는 상기 장면 레이아웃 중 적어도 하나를 결정하는 단계는 상기 의사 랜덤 시드와 연관된 각각의 커맨드 명령어 또는 각각의 장면 레이아웃을 선택하는 것에 더 기초하는, 방법. 청구항 12 제1항에 있어서, 렌더링된 장면을 제공하는 단계는, 전용 그래픽 프로세서를 사용하여, 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 렌더링하는 단계를 포함하고, 상기 전용 그래픽 프로세서는 그래픽 처리 유닛(GPU)을 포함하는, 방법. 청구항 13 제1항에 있어서, 상기 방법은 출력을 HTML 호환 가능 포맷으로 제공하는 단계를 추가로 포함하는, 방법. 청구항 14 제1항에 있어서, 상기 방법은 출력을 제공하는 단계를 추가로 포함하고, 상기 출력은 가상 현실 디스플레이 또는 증강 현실 디스 플레이 중 적어도 하나와 호환 가능한 포맷을 포함하는, 방법.청구항 15 제1항에 있어서, 상기 방법은 거의 실시간으로 수행되며, 상기 거의 실시간은 상기 하나 이상의 커맨드 명령어들을 50 밀리 초마 다 적어도 1회 결정하는 것 또는 상기 장면 레이아웃을 50 밀리 초마다 적어도 1회 결정하는 것 중 적어도 하나 를 포함하는, 방법. 청구항 16 제1항에 있어서, 상기 방법의 하나 이상의 단계들은 머신 학습을 이용하는 지능형 에이전트 또는 인공 지능 구성물에 의해 수행 되는, 방법. 청구항 17 시스템으로서, 입력 디바이스; 렌더 처리 유닛; 디스플레이; 및 적어도 하나의 메모리 및 적어도 하나의 프로세서를 포함하는 제어기를 포함하고, 상기 제어기는 명령어들을 실 행하여 동작들을 수행하고, 상기 동작들은: 상기 입력 디바이스를 통해, 텍스트, 음성, 또는 제스처 중 적어도 하나를 나타내는 입력 정보를 수신하는 것; 상기 수신된 입력 정보에 기초하여, 하나 이상의 커맨드 명령어들을 결정하는 것 ― 상기 하나 이상의 커맨드 명령어들을 결정하는 것은: 상기 수신된 입력 정보를 복수의 라인 세그먼트들로 파싱하는 것; 자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 처리하는 것 ― 상기 처리는 상기 라인 세그먼트들 각각을 자연어 커맨드 데이터베이스와 비교하는 것을 포함함 ―; 및 상기 비교에 기초하여 적어도 하나의 인식된 라인 세그먼트를 결정하는 것을 포함하고, 적어도 하나의 커맨드 명령어는 상기 적어도 하나의 인식된 라인 세그먼트에 기초함 ―; 상기 하나 이상의 커맨드 명령어들에 기초하여 장면 레이아웃을 결정하는 것; 상기 렌더 처리 유닛을 사용하여, 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 렌더링하는 것; 및 상기 렌더링된 장면을 상기 디스플레이를 통해 디스플레이하는 것 을 포함하는, 시스템. 청구항 18 제17항에 있어서, 상기 동작들은: 각각의 커맨드 명령어를 객체 커맨드 명령어, 언어 커맨드 명령어, 또는 환경 커맨드 명령어 중 적어도 하나로 분류하는 것; 및 각각의 분류된 커맨드 명령어를 적어도 하나의 대응하는 데이터베이스에 저장하는 것 ― 상기 대응하는 데이터 베이스는 객체 데이터베이스, 언어 데이터베이스, 또는 환경 데이터베이스 중 적어도 하나를 포함함 ―을 추가 로 포함하는, 시스템. 청구항 19 제17항에 있어서, 상기 디스플레이는 가상 현실 디스플레이 또는 증강 현실 디스플레이 중 적어도 하나를 포함하는, 시스템. 청구항 20 컴퓨팅 디바이스에 의해 실행될 때 상기 컴퓨팅 디바이스로 하여금 동작들을 수행하게 하는 명령어들을 저장한 비 일시적 컴퓨터 판독가능 매체로서, 상기 동작들은: 입력을 수신하는 것 ― 상기 입력은 텍스트, 음성, 또는 제스처 중 적어도 하나를 포함함 ―; 상기 입력에 기초하여, 적어도 하나의 커맨드 명령어를 결정하는 것 ― 상기 적어도 하나의 커맨드 명령어를 결 정하는 것은: 상기 입력을 복수의 라인 세그먼트들로 파싱하는 것, 자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 처리하는 것 ― 상기 처리는 상기 라인 세그먼트들 각각을 자연어 커맨드 데이터베이스와 비교하는 것을 포함함 ―, 및 상기 비교에 기초하여 적어도 하나의 인식된 라인 세그먼트를 결정하는 것을 포함하고, 상기 적어도 하나의 커 맨드 명령어는 상기 적어도 하나의 인식된 라인 세그먼트에 기초함 ―; 상기 적어도 하나의 커맨드 명령어에 기초하여 장면 레이아웃을 결정하는 것; 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 제공하는 것 ― 각각의 커맨드 명령어는 상기 장면 레 이아웃의 적어도 하나의 요소에 대응함 ―; 각각의 커맨드 명령어를 객체 커맨드 명령어, 언어 커맨드 명령어, 또는 환경 커맨드 명령어 중 적어도 하나로 분류하는 것; 각각의 분류된 커맨드 명령어를 적어도 하나의 대응하는 데이터베이스에 저장하는 것 ― 상기 대응하는 데이터 베이스는 객체 데이터베이스, 언어 데이터베이스, 또는 환경 데이터베이스 중 적어도 하나를 포함함 ―; 및 출력을 HTML 호환 가능 포맷으로 제공하는 것 을 포함하는, 비 일시적 컴퓨터 판독가능 매체. 발명의 설명"}
{"patent_id": "10-2019-7033039", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원에 대한 상호 참조 본 출원은 2017년 4월 11일자로 출원된 미국 특허 출원 제62/484,116호의 우선권을 주장하며, 이 미국 출원은 그 전체가 본원에 참고로 포함된다."}
{"patent_id": "10-2019-7033039", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래의 3D 애니메이션은 처리 주기 및 비용 측면에서 부담이 클 수 있다. 즉, 수백 개의 프로세서를 사용하여 애니메이션 영화의 3D 장면들을 렌더링하는 데에는 몇 주, 몇 달 또는 몇 년이 소요될 수 있다. 또한, 종래의 3D 애니메이션은 컴퓨터 프로그래밍에 대한 전문 지식을 가진 운영자들에게 유리한 고비용의 그리고 종종 복잡 한 소프트웨어에 기반을 두고 있다. 즉, 종래의 3D 장면 생성, 수정 및 영화 내보내기는 아마추어 사용자들이 광범위하게 수용하기에는 너무 복잡할 수 있다. 따라서, 그래픽 콘텐츠를 동적으로 생성하기 위한 직관적이고, 프로세서 주기 효율이 높고, 보다 저렴한 방식이 필요하다."}
{"patent_id": "10-2019-7033039", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시 내용은 일반적으로 자연어(예를 들어, 음성 또는 텍스트), 제스처 입력, 및/또는 다른 타입들의 입력, 가령, 감각 또는 머신 기반 입력들(예를 들어, 인공 지능 구성물로부터의 통신 또는 다른 컴퓨터 시스템들로부 터의 입력)에 기초한 2D 및 3D 그래픽 컴퓨터 애니메이션의 생성에 관한 것이다. 예를 들어, 본 개시 내용은 3 차원 그래픽 콘텐츠의 동적 생성을 위한 시스템들 및 방법들에 관한 것일 수 있다. 본 개시 내용은 또한 이러 한 콘텐츠를 종래의 디스플레이들 및/또는 증강 현실 또는 가상 현실 디스플레이들, 또는 다른 타입의 시각적 매체(예를 들어, 홀로그램) 상에 디스플레이하기 위해 수정 및 내보내기 위한 시스템들 및 방법들을 제공할 수 있다. 제 1 양태에서, 시스템이 제공된다. 상기 시스템은 입력 디바이스, 렌더 처리 유닛(render processing unit), 디스플레이 및 제어기를 포함한다. 상기 제어기는 적어도 하나의 메모리 및 적어도 하나의 프로세서를 포함한 다. 상기 제어기는 명령어들을 실행하여 동작들을 수행한다. 상기 동작들은 입력 디바이스를 통해, 텍스트, 음성 또는 제스처 중 적어도 하나를 나타내는 입력 정보를 수신하는 것을 포함한다. 상기 동작들은 또한 수신 된 입력 정보에 기초하여 하나 이상의 커맨드 명령어들을 결정하는 것을 포함한다. 상기 동작들은 하나 이상의 커맨드 명령어들에 기초하여 장면 레이아웃을 결정하는 것을 추가로 포함한다. 상기 동작들은 렌더 처리 유닛 을 사용하여, 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 렌더링하는 것을 추가로 포함한다. 상기 동작들은 또한 디스플레이를 통해, 상기 렌더링된 장면을 디스플레이하는 것을 포함한다. 제 2 양태에서, 방법이 제공된다. 상기 방법은 입력을 수신하는 단계를 포함한다. 상기 입력은 텍스트, 음성 또는 제스처 중 적어도 하나를 포함한다. 상기 방법은 또한 상기 입력에 기초하여 하나 이상의 커맨드 명령어 들을 결정하는 단계를 포함한다. 상기 방법은 상기 하나 이상의 커맨드 명령어들에 기초하여 장면 레이아웃을 결정하는 단계를 추가로 포함한다. 상기 방법은 또한 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 제공하는 단계를 포함한다. 제 3 양태에서, 비 일시적 컴퓨터 판독가능 매체가 제공된다. 상기 비 일시적 컴퓨터 판독가능 매체는 컴퓨팅 디바이스에 의해 실행될 때 컴퓨팅 디바이스로 하여금 동작들을 수행하게 하는 명령어들을 저장하고 있다. 상 기 동작들은 입력을 수신하는 것을 포함하며, 상기 입력은 텍스트, 음성 또는 제스처 중 적어도 하나를 포함한 다. 상기 동작들은 또한 상기 입력에 기초하여 하나 이상의 커맨드 명령어를 결정하는 것을 포함한다. 상기 동작들은 상기 하나 이상의 커맨드 명령어에 기초하여 장면 레이아웃을 결정하는 것을 추가로 포함한다. 상기 동작들은 또한 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 제공하는 것을 포함한다. 다른 양태들, 실시예들, 및 구현예들은 적절한 경우 첨부 도면들을 참조하여 다음의 상세한 설명을 읽음으로써 본 기술 분야의 통상의 기술자들에게는 명백해질 것이다."}
{"patent_id": "10-2019-7033039", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "예시적인 방법들, 디바이스들, 및 시스템들이 본원에 기술된다. 본원에서 \"예\" 및 \"예시적인\"이라는 단어는 \" 예, 사례 또는 실례로서 기능하는\"을 의미하기 위해 사용되는 것으로 이해되어야 한다. 본원에서 \"예\" 또는 \"예시적인\"것으로서 기술되는 임의의 실시예 또는 특징은 반드시 다른 실시예들 또는 특징들보다 바람직하거나 유리한 것으로 해석될 필요는 없다. 본원에 제시된 요지의 범위를 벗어나지 않고, 다른 실시예들이 이용될 수 있고 다른 변경이 행해질 수 있다. 따라서, 본원에 기술된 예시적인 실시예는 제한적인 것으로 의도되는 것은 아니다. 본원에서 일반적으로 설명 되고 도면에 도시된 바와 같이 본 개시 내용의 양태는 매우 다양한 상이한 구성으로 배열, 대체, 조합, 분리 및 설계될 수 있으며, 이들 모두는 본원에서 고려된다. 또한, 문맥이 달리 제시하지 않는 한, 각각의 도면에 도시된 특징들은 서로 조합하여 사용될 수 있다. 따라서, 도면들은 일반적으로 하나 이상의 전체 실시예들의 구성 요소 양태들로서 간주되어야 하며, 도시된 모든 특징들 이 각 실시예에 필요한 것은 아니라는 것을 이해해야 한다. Ⅰ. 개관 동적 시청각 콘텐츠 생성(dynamic audio-visual content generation)과 관련된 실시예들이 본원에 기술된다. 예를 들어, 오디오, 텍스트, 제스처, 또는 머신 기반 입력 디스크립션들은 주어진 장면 레이아웃 내에서 특정 좌표들로 배열된 벡터 객체들(vector objects)로 변환될 수 있다. 주어진 장면 레이아웃은 거의 실시간으로(예 를 들어, 사용자가 텍스트/음성/제스처 입력을 제공할 수 있을 정도의 속도로) 렌더링되어 동적 시청각 콘텐츠 (예를 들어, 영화, 스틸 이미지, 비디오 클립들 등)를 제공할 수 있다. 일 예시적인 실시예에서, 사용자는 텍스트 입력을 입력된 텍스트 문서(imported text document)(예를 들어, Word, PDF 문서)의 형태로 또는 그래픽 사용자 인터페이스 내로 타이핑된 입력으로서 제공할 수 있다. 추가적 으로 또는 대안적으로, 사용자는 오디오 입력(예를 들어, 음성)을 제공할 수 있다. 일부 실시예들에서, 발성된 오디오 입력(spoken audio input)은 먼저 음성-텍스트 인터페이스(speech-to-text interface)를 사용하여 텍스 트로 변환될 수 있다. 다른 대안으로서, 입력은 제스처(예를 들어, 손 신호(hand signal), 신체 움직임(body movement) 등)을 통해 제공될 수 있다. 또 다른 대안으로서, 입력은 인간 또는 동물로부터의 뇌 신호와 같은 감각 입력(sensory input)을 포함할 수 있 다. 추가적으로 또는 대안적으로, 입력은, 예를 들어, 인공 지능 구성물 또는 다른 컴퓨터로부터의 머신 입력 을 포함할 수 있다. 텍스트/오디오/제스처 입력들은 라인 세그먼트들로 파싱(parsed)되고, 텍스트/음성/ 제스처 인식 알고리즘들에 의해 분석된다. 텍스트/음성/제스처 인식 알고리즘들은 다양한 인공 지능 구성물들을 포함할 수 있고, 이 인공 지능 구성물들은 1) 각 단어를 로컬화된 언어 어휘집과 비교하여 의미를 결정하도록 구성된 단어 구성물(word construct); 2) 마침표(punctuation)에 기반하여 짧은 문장들 또는 문구들을 분석하도록 구성된 문구 구성물 (phrase construct); 3) 단어들과 장황환 말(verbiage)이 사용되는 방식으로부터 의미를 결정하도록 구성된 구 조 구성물(structure construct); 및 4) 의미에 대한 정량적, 정성적 및 상관 특성들을 분석하도록 구성된 상관 구성물(relational construct)을 포함하지만 이에 국한되는 것은 아니다. 다양한 인공 지능 구성물들이 비교 및/또는 분석을 위해 하나 이상의 데이터베이스들에 액세스할 수 있다는 것 이 이해될 것이다. 또한, 이러한 데이터베이스는 제스처 형태뿐만 아니라 다양한 문자 언어 및 발성 언어(예를 들어, 영어, 스페인어, 프랑스어, 독일어, 만다린, 한국어, 미국 수화, HTML, 또는 머신-기반 통신 언어 등)에 대한 지원을 제공할 수 있다. 또한, 데이터베이스(들)는 그러한 지역에서의 사람들, 장소들, 관습들, 및/또는 선호도들과 관련된 도시, 지역, 및/또는 국가-특정 정보를 제공할 수 있다. 인식된 라인 세그먼트들은, 예를 들어, 각각의 데이터베이스로부터의 특정 객체, 언어 요소, 또는 환경 요소와 관련될 수 있는 커맨드 명령어들로 변환된다. 이러한 객체들, 언어 요소들, 또는 환경 요소들은 장면 레이아웃 내에 거의 실시간으로 또는 실시간으로 배치될 수 있다. 장면 레이아웃 내의 객체들 및 환경 요소들은 그 후 광선 추적 알고리즘 또는 다른 타입의 렌더링 알고리즘 또는 엔진을 사용하여 고품질 그래픽 포맷으로 렌더링될 수 있다. 일 예로서, 렌더링 알고리즘은 실시간 렌더링(real-time rendering), 입자 모델링(particle modeling), 입자 렌더링(particle rendering), 라이트 필드 렌더링(light field rendering), 디스패리티 렌더 링(disparity rendering), 및/또는 무차별 렌더링(brute force rendering) 중 하나 이상을 포함할 수 있다. 일부 실시예들에서, 하나 이상의 커맨드 명령어들은 객체 커맨드 명령어, 언어 커맨드 명령어, 또는 환경 커맨 드 명령어 중 적어도 하나로 분류될 수 있다. 또한, 상기 하나 이상의 커맨드 명령어들은 하나 이상의 객체에 적용될 수 있는 액션 커맨드 명령어를 포함할 수 있다. 예를 들어, \"볼링 공\"의 텍스트 엔트리(text entry)에 응답하여, 본원의 시스템들 및 방법들은 중립 회색 배경 의 초기 위치에서 정지된 것으로 디스플레이되는 블랙 볼링 공의 그래픽 렌더링을 제공할 수 있다. 이러한 시 나리오에서, 텍스트 엔트리를 편집하여 \"볼링 공이 낙하한다\"를 나열하게 되면 \"낙하하는\" 액션을 볼링 공과 연 관시킬 수 있다. 따라서, 볼링 공이 초기 위치에서 아래로 떨어지는 것을 나타내기 위해 볼링 공에 애니메이션 을 적용할 수 있다. 일부 실시예들에서, 애니메이션은 한 번 이상 루핑(loop)되거나 반복될 수 있다. 일부 예들에서, 객체들에는 디폴트 애니메이션이 제시될 수 있다. 예를 들어, \"사람들\"의 텍스트 엔트리에 응 답하여, 본원에 기술된 시스템들 및 방법들은 정상적으로 호흡하는 (예를 들어, 흉부가 상승 및 하강하는) 일반 적인 인간(예를 들어, 막대기 그림(stick figure), 전형적인 인체, 전형적인 남자 또는 여자, 랜덤한 인체 등) 을 제시할 수 있다. 다른 타입의 디폴트 애니메이션들은 다양한 객체들과 연관될 수 있다. 다른 가능성들 중에서, 장면 레이아웃은 일련의 if/then/else 진술문들(statements)을 포함하는 알고리즘에 기 초하여 결정될 수 있다. 이러한 진술문들은 다른 가능성들 중에서도: 1) 장면 레이아웃의 대상(예를 들어, 사 람들, 동물들, 인물들(personalities), 유기체들(organisms) 등); 2) 장면 레이아웃의 기간(예를 들어, 시각, 날짜, 역사적 시대 등); 3) 장면 레이아웃의 물리적 위치(예를 들어, 장소, 지역, 카메라 각도, 객체들의 블로 킹 등)를 결정할 수 있다. 각각의 커맨드 명령어들에 대응하는 객체들, 환경 요소들, 또는 액션들은 각각의 데이터베이스로부터 호출될 수 있다. 예를 들어, 사람들, 빌딩들, 사물들 등의 그래픽 표현들은 객체 데이터베이스로부터 검색될 수 있다. 또한, 하늘, 구름, 대륙, 수괴, 우주 및 행성의 그래픽 표현들은 환경 요소 데이터베이스로부터 검색될 수 있다. 또한, 움직임들, 모션 캡처들, 또는 액션들과 같은 다양한 액션들(예를 들어, 달리기, 걷기, 싸움 등)이 액션 데이터베이스로부터 검색될 수 있다. 각각의 데이터베이스 내의 객체들 또는 환경 요소들은 각각의 객체를 x 축을 따라 1000 개의 층으로, 및 y, z 평면에서 1000 x 1000의 픽셀들로 분할하는 포맷의 벡터 객체들을 포함하도록 포맷화될 수 있다. 이러한 방식 으로, 각각의 객체 또는 환경 요소의 3D 표현이 제공될 수 있다. 객체들은 상이한 수의 층 및/또는 픽셀 범위 로 분할될 수 있다. 고해상도의 3D 표현들이 본원에 기술되어 있지만, 다른 타입의 그래픽 표현들을 저장 및/또는 리콜하는 것이 바 람직할 수 있음이 이해될 것이다. 예를 들어, 흑백, 그레이스케일, 만화 스타일, 셀 음영, 2 차원, 다른 고해 상도 포맷들, 및/또는 저해상도(예를 들어, 8-비트의 블록)의 표현들이 본원에서 또한 가능하고 고려된다. 객체들, 환경들, 및/또는 액션들의 검색은 압축된 벡터 객체들의 형태로 제공될 수 있다. 이러한 벡터 객체들 은 압축 해제되어 \"스테이지\" 또는 장면 레이아웃 상에 배치될 수 있다. 주어진 객체 또는 환경 요소가 주어진 데이터베이스로부터 검색될 때, 벡터 객체는 장면 레이아웃 상에서 어디에 위치되는지에 기초하여 압축 해제될 수 있다. 예를 들어, 벡터 객체는 시야각, 조명 각도, 및 장면 레이아웃 내의 다른 객체들과의 공간 관계에 기 초하여 (예를 들어, 전경/배경 요소들, 폐쇄 요소들 등을 고려하여) 압축 해제될 수 있다. 대안적으로, 객체들, 환경들, 및/또는 액션들은 압축 해제된 벡터 객체들의 형태로 제공될 수 있다. 객체들은 객체 데이터베이스로부터 검색될 수 있지만, 본원에 기술된 시스템 및 방법은 사전 정의(dictionary definition)에만 기초하여 객체들을 생성할 수 있는 것도 고려된다. 예를 들어, 텍스트 입력이 객체 데이터베 이스에 제공되지 않은 객체를 포함하는 경우, 본원에 기술된 시스템 및 방법은 텍스트 엔트리의 사전 정의 (dictionary definition)에 기초하여 객체에 대한 \"최상의 추측\"을 생성할 수 있다. 본 개시 내용의 다양한 양태는 인공 지능 시스템들 및 방법들에 관한 것이고/이거나 이를 활용할 수 있다. 예 를 들어, 본원에 기술된 지능형 에이전트들 또는 구성물들은 사용자 입력(예를 들어, 텍스트, 음성, 제스처 등)을 나타내는 정보를 수신할 수 있다. 이에 응답하여, 지능형 에이전트 또는 구성물은 성공 가능성을 최대화 하기 위한 노력(예를 들어, 동적 그래픽 콘텐츠를 제공하기 위해 사용자 입력을 적절히 식별하고 그에 따라 작 용하는) 액션을 취할 수 있다. 일부 실시예들에서, 본원에 기술된 지능형 에이전트들 또는 구성물들은 인간의 \"학습\" 및 \"문제 해결\"과 연관될 수 있는 \"인지(cognitive)\" 기능들을 모방할 수 있다. 다시 말해서, 본원에 기술된 하나 이상의 기능들은 머신 학습(machine learning)을 이용할 수 있다. 예를 들어, 머신 학습은 적절한 커맨드 명령어들, 객체들, 액션들, 장면 레이아웃들 등을 정확하게 예측하기 위해 본원에 기술된 하나 이상의 기능들에 적용될 수 있다. 예를 들어, 인공 지능 구성물은 움직임들 및 액션들로 객체들을 조정할 수 있고, 렌더링 정보(rendering information)를 동적 렌더 엔진(dynamic render engine) 및 전체 타임 라인(overall timeline)에 제공할 수 있다. 벡터 객체 위치들은 장면 레이아웃 내에 그려질 수 있고, 광선 추적 알고리즘을 사용하여 렌더링이 수행될 수 있다. 추가적으로 또는 대안적으로, 다른 타입들의 렌더 엔진들이 가능하고 고려된다. 렌더링된 장면은 다 양한 상이한 조명 모델들을 통합할 수 있다. 또한, 렌더링된 버전의 장면 레이아웃은 출력으로서 제공될 수 있 다. 일부 실시예들에서, 렌더링된 버전을 통해 입력된 각각의 데이터가 반복될 수 있다. 본원에 기술된 바와 같이, 출력은 5 가지의 인간 감각(human senses)과 관련된 다양한 방식으로 사용자에게 제공될 수 있다. 즉, 출력은 시각적, 오디오, 터치/햅틱, 후각, 및/또는 미각 피드백을 포함할 수 있다. 일부 실시예들에서, 방법 또는 시스템은, 예를 들어, 사용자가 이전에 적용된 요소들을 제거하는(예를 들어, 장 면 레이아웃에 대한 변경들을 \"복원\"하는) 옵션을 제공할 수 있는 버전 제어를 포함할 수 있다. 일부 실시예들 에서, 사용자 인터페이스는 거의 실시간으로 텍스트 및/또는 다른 입력 변경들을 가능하게 함으로써 온-더-플라 이 편집(on-the-fly editing)을 포함할 수 있다. 예를 들어, 사용자는 캐릭터들, 위치들, 액션들, 카메라 각도 들, 캐릭터 음성 등에 대한 세부 사항들을 조정할 수 있다. 디스플레이는 조정된 세부 사항들로 거의 실시간으 로 업데이트될 수 있다. 다른 실시예들에서, 사용자 인터페이스는 사용자 검토, 편집, 및/또는 승인을 위해 \" 초안(draft)\" 장면을 재생할 수 있다. II. 예시적인 시스템들 도 1은 일 예시적인 실시예에 따른 시스템을 도시한다. 시스템은 입력 디바이스, 렌더 처리 유 닛, 디스플레이, 및 제어기를 포함한다. 시스템의 요소들 중 일부 또는 전부는 컴퓨팅 디 바이스에 제공될 수 있다. 예를 들어, 컴퓨팅 디바이스는 스마트폰, 시계, 태블릿 컴퓨터, 랩톱 컴퓨터, 헤드 장착 가능 디스플레이, 가상 현실 헤드셋, 증강 현실 헤드셋, 데스크탑 컴퓨터, 클라우드 컴퓨팅 네트워크, 또 는 다른 타입의 컴퓨팅 디바이스를 포함할 수 있다. 선택적으로, 시스템은 그래픽 출력 유닛, 오디 오 출력 유닛, 햅틱 출력 유닛, 후각 출력 유닛, 및/또는 미각 출력 유닛을 포함할 수 있 다. 입력 디바이스는 마이크로폰, 키보드, 마우스, 트랙 패드, 터치 패드, 트랙볼, 터치 스크린, 조이스틱, 다 축 제어기(예를 들어, 3D 제어기), 및/또는 카메라를 포함할 수 있다. 일부 실시예들에서, 입력 디바이스(11 0)는 증강 현실 헤드셋/제어기 또는 가상 현실 헤드셋/제어기를 포함할 수 있다. 이러한 시나리오에서, AR 또 는 VR 헤드셋의 사용자는 주어진 장면을 보고, 음성 입력, 제어기 입력(예를 들어, 3D 조이스틱), 및/또는 제스 처 입력을 사용하여 시스템과 상호 작용할 수 있다. 추가적으로 또는 대안적으로, 입력 디바이스는 시선 추적 시스템을 포함할 수 있다. 예를 들어, 시스템으로의 하나 이상의 입력들은 사용자의 눈(들) 중 하나 또는 둘 모두의 포지션 및/또는 시야각을 나타내는 정보를 포함할 수 있다. 일부 예시적인 실시예들에서, 입력 디바이스는 정보를 수신하도록 구성된 통신 인터페이스를 포함할 수 있 다. 예를 들어, 통신 인터페이스는 포인트 클라우드(point cloud) 및/또는 라이트 필드 정보(light field information)를 수신하도록 구성될 수 있다. 이러한 포인트 클라우드 및/또는 라이트 필드 정보는 본원의 다른 곳에 기술된 바와 같이, 장면 레이아웃 및/또는 하나 이상의 환경 요소들을 생성하는 데 사용될 수 있다. 시스 템에 입력 정보를 제공하는 다른 방식들이 본 개시 내용에서 고려된다. 일부 실시예들에서, 입력 디바이스는 사용자의 두뇌와 시스템 사이에 직접적인 통신 경로를 제공하도 록 구성된 디바이스들을 포함할 수 있다. 이러한 시나리오들에서, 입력 디바이스는, 예를 들어, 두뇌-컴 퓨터 인터페이스(brain-computer interface)(BCI), 마인드-머신 인터페이스(mind-machine interface)(MMI), 직 접 신경 인터페이스(direct neural interface)(DNI), 또는 두뇌-머신 인터페이스(brain-machine interface)(BMI)를 포함할 수 있다. 일 예로서, BMI는 사용자의 손 제스처를 시스템에 대한 입력 커맨드 로 직접 변환할 수 있는 모터 뉴로프로스테틱(motor neuroprosthetic)을 포함할 수 있다. 추가적으로 또는 대 안적으로, 전기 생리학적 신호들(예를 들어, 로컬 전계 전위들(local field potentials)(LFPs))을 변환하도록 구성된 디바이스들이 고려된다. 이러한 시나리오들에서, 이러한 디바이스들은 정보를 입력 디바이스에 제 공할 수 있다. 이러한 정보는, 예를 들어, 사용자의 두뇌의 특정 영역으로부터의 사용자의 LFP를 나타낼 수 있 다. 일부의 경우들에서, LFP 신호들은 물리적 전극 임플란트들(physical electrode implants) 또는 무선 수단 을 통해 획득될 수 있다. 사용자의 모터 또는 감각 피질로부터 시스템으로 입력을 직접 제공하는 다른 방 식들이 본원에서 가능하고 고려된다는 것이 이해될 것이다. 부가적으로 또는 대안적으로, 그래픽 출력 유닛, 오디오 출력 유닛, 햅틱 출력 유닛, 후각 출력 유닛, 및/또는 미각 출력 유닛에 의해 제공되는 출력들의 일부 또는 전부는 전술한 두뇌-머신 인터페 이스들을 통해 사용자에게 제공될 수 있다. 일 예로서, BMI는 시스템의 그래픽 출력이 사용자의 시각 피질에 직접 제공될 수 있도록 시각 뉴로프로스테틱(visual neuroprosthetic)을 포함할 수 있다. 추가적으로 또 는 대안적으로, 오디오 뉴로프로스테틱(예를 들어, 청각 신경을 자극하도록 구성된 마이크로전극 디바이스 (microelectrode device))은 사용자의 감각 피질에 직접적인 청각 출력을 제공할 수 있다. 시스템으로부 터 사용자의 감각 피질로의 출력을 직접 제공하는 다른 방식들이 본원에서 가능하고 고려된다는 것이 이해될 것 이다. 또한, 본원에 기술된 예들은 입력 디바이스를 통해 입력을 제공하는 인간 사용자를 포함하지만, 입력 디바 이스에 입력을 제공하는 데 다른 컴퓨터들 또는 디바이스들이 동작 가능할 수 있다. 예를 들어, 인공 지 능 구성물 또는 다른 타입의 컴퓨팅 디바이스가 입력 디바이스를 통해 입력들을 제공할 수 있다. 또한, 본원의 실시예들은 인간 사용자에게 출력을 제공하는 것을 포함하지만, 출력이 다른 컴퓨팅 디바이스 및/또는 인공 지능 구성물에 제공될 수 있음을 이해할 것이다. 다시 말해서, 일부의 경우들에서, 본원에 기술된 방법들 및 시스템들은 인간 사용자로부터의 입력 또는 인간 사용자로의 출력을 포함할 필요가 없다. 렌더 처리 유닛은 중앙 처리 유닛(CPU) 또는 그래픽 처리 유닛(GPU) 중 적어도 하나를 포함한다. 일 예시 적인 실시예에서, 렌더 처리 유닛은 하드웨어 가속 그래픽 계산들을 제공하도록 구성된 GPU들을 갖는 하나 이상의 전용 그래픽 카드들을 포함할 수 있다. 예를 들어, 렌더 처리 유닛은 광선 추적, 텍스처 매핑, 다 각형 렌더링, 정점 회전 및 변환, 프로그램 가능 쉐이더들, 비디오 디코딩 및 인코딩, 물리적 처리, 포인트 클 라우드, 라이트 필드, 및 모션 보상과 같은 그래픽 기능들을 제공하도록 구성될 수 있지만 이에 국한되는 것은 아니다. 디스플레이는 시각 정보를 제공하도록 구성된 컴퓨터 모니터 또는 다른 시각 출력 매체를 포함할 수 있다. 예를 들어, 디스플레이는 액정 디스플레이(LCD), 발광 다이오드(LED) 디스플레이, 홀로그램 디스플레이, 라이트 필드 디스플레이, 단거리 또는 장거리 투사 디바이스들, 또는 음극선관(CRT) 디스플레이를 포함할 수 있 다. 디스플레이는 스마트폰, 랩탑 등과 같은 다른 타입의 디스플레이일 수 있다. 디스플레이는 그 래픽 사용자 인터페이스를 디스플레이하도록 구성될 수 있다. 추가적으로 또는 대안적으로, 디스플레이는 본원에 기술된 동적 콘텐츠 생성 방법들에 의해 생성된 이미지들을 디스플레이하도록 구성될 수 있다. 일 예시적인 실시예에서, 디스플레이는 가상 현실 디스플레이(예를 들어, VR 헤드셋) 또는 증강 현실 디스 플레이(예를 들어, Microsoft Hololens 또는 Google Glass)를 포함할 수 있다. 그래픽 출력 유닛은 그래픽 엔진 및/또는 출력 타겟(예를 들어, 하드 드라이브, 서버, 모바일 디바이스)에 대한 통신 링크를 포함할 수 있다. 그래픽 출력 유닛은 렌더링된 장면을 원하는 그래픽 포맷 및/또는 원 하는 타입의 디바이스로의 출력을 위해 제공하도록 구성될 수 있다. 예를 들어, 그래픽 출력 유닛은 디스 플레이 상에 디스플레이될 수 있는 3D 비디오 또는 다른 타입의 그래픽 콘텐츠를 생성할 수 있다. 일부 실시예들에서, 출력은 HTML 호환 가능 포맷(예를 들어, HTML5) 또는 (브라우저에서 보기에 적합한) 다른 타입의 인터넷 호환 가능 웹페이지 포맷으로 제공될 수 있다. 추가적으로 또는 대안적으로, 그래픽 출력 유닛은 애플리케이션 프로그래밍 인터페이스(application programming interface)(API)를 사용하여 출력을 제공할 수 있다. 예를 들어, API는 Open GL, Direct 3D, Glide API, Mantle, Metal, RenderMan, RenderWare, 또는 Vulkan 중 적어도 하나를 포함할 수 있다. 일부 실 시예들에서, API는 커스텀 API일 수 있다. 선택적으로, 그래픽 출력 유닛은 그래픽 엔진을 사용하여 출력을 제공할 수 있다. 그래픽 엔진은 Unity Game Engine, Cry Engine, Unreal Engine, id Tech 4, id Tech 5, 또는 Source 중 적어도 하나를 포함할 수 있 다. 일부 실시예들에서, 그래픽 엔진은 커스텀 그래픽 엔진을 포함할 수 있다. 도 1에 도시된 바와 같이, 시스템은 다른 타입의 출력을 포함할 수 있다. 예를 들어, 다른 출력 유닛들은 비 시각적 감각들에 대한 출력을 제공하는 데 사용될 수 있다. 일 예시적인 실시예에서, 시스템은 오디오 출력 유닛, 햅틱 출력 유닛, 후각 출력 유닛, 및 미각 출력 유닛을 포함할 수 있다. 오디오 출력 유닛은 사용자에게 오디오 출력을 제공하도록 구성될 수 있다. 예를 들어, 오디오 출력 유닛 은 시스템의 사용자에게 음악, 발성된 오디오, 및/또는 다른 사운드 효과들(예를 들어, Foley 효과들)을 제공할 수 있다. 또한, 오디오 출력 유닛은 장면 내의 액터들에 의해 또는 보이스 오버(voice- over)에 의해 발성될 수 있는 오디오 다이얼로그(audio dialog)를 제공할 수 있다. 햅틱 출력 유닛은 터치 감각과 관련된 출력을 사용자에게 제공하도록 구성될 수 있다. 일부 예시적인 실 시예들에서, 햅틱 출력 유닛은 사용자의 손끝들 또는 사용자 신체의 다른 부분들에 터치감들(touch sensations)을 제공할 수 있다. 일부 실시예들에서, 햅틱 출력 유닛은 열감 및/또는 냉감을 제공할 수 있 다. 예를 들어, 햅틱 출력 유닛은 VR 제어기 또는 사용자 시트(예를 들어, 의자)를 통해 \"럼블(rumble)” 피드백을 제공할 수 있다. 일부 실시예들에서, 햅틱 출력 유닛은 쉐이커 매스(shaker mass) 및 상기 쉐이 커 매스를 이동시키도록 구성된 하나 이상의 액추에이터들(예를 들어, 모터들)을 포함할 수 있다. 햅틱 피드백 을 제공하는 다른 방식들이 고려된다. 후각 출력 유닛은 사용자의 후각 감각과 관련된 출력을 제공하도록 구성될 수 있다. 예를 들어, 후각 출 력 유닛은 주어진 장면, 객체, 장소, 환경, 및/또는 캐릭터와 연관될 수 있는 다양한 향기들을 제공하도록 구성된 물리적 미스터 또는 분무기(physical mister or sprayer)를 포함할 수 있다. 비 제한적인 예들로서, 후 각 출력 유닛은 장미 향기, 향수(perfume), 콜로뉴(cologne), 신선한 산 공기(fresh mountain air), 짠 바다 스프레이(salty ocean spray), 신선한 컷 잔디(fresh-cut grass), 신차 냄새(new-car smell), 불타는 캠 프 파이어(burning camp fire), 악취 나는 쓰레기(foul-smelling garbage), 하수 가스(sewer gas) 등과 같은 임의의 수의 향기들을 제공하도록 구성될 수 있다. 미각 출력 유닛은 사용자의 미각 감각과 관련된 출력을 제공하도록 구성될 수 있다. 미각 출력 유닛(14 8)은 사용자의 미각 감각 기관(예를 들어, 사용자의 혀)과 상호 작용하도록 구성된 마우스피스 또는 다른 타입 의 디바이스를 포함할 수 있다. 일 예시적인 실시예에서, 미각 출력 유닛은 미리 결정된 양의 미각 재료 를 사용자의 입/혀에 제공할 수 있다. 미각 출력 유닛은 단맛, 신맛, 짠맛, 쓴맛, 및 감칠맛과 같은, 그 러나 이에 국한되지 않는 여러 가지 다른 미각감을 제공할 수 있다. 일부 예들에서, 온도(열 또는 추위), 매운 맛, 전분, 비만, 무감각 등과 같이 미각과 직접 또는 간접적으로 관련된 다른 감각들이 본원에서 가능하고 고려 된다. 제어기는 적어도 하나의 메모리 및 적어도 하나의 프로세서를 포함한다. 제어기는 명령어 들을 실행하여 동작들을 수행한다. 상기 동작들은 입력 디바이스를 통해, 텍스트, 음성 또는 제스처 중 적어도 하나를 나타내는 입력 정보를 수신하는 것을 포함한다. 상기 동작들은 또한 수신된 입력 정보에 기초하여 하나 이상의 커맨드 명령어들을 결정하는 것을 포함한다. 일 예시적인 실시예에서, 하나 이상의 커맨드 명령어들을 결정하는 것은 수신된 입력 정보를 복수의 라인 세그먼트 들로 파싱하는 것을 포함한다. 일단 수신된 입력 정보가 파싱되면, 복수의 라인 세그먼트들은 자연어 인식 알 고리즘으로 병렬 또는 순차적으로 처리될 수 있다. 이러한 시나리오에서, 순차적 처리는 라인 세그먼트들 각각 을 자연어 커맨드 데이터베이스와 비교하는 것을 포함한다. 동작들은 이러한 비교에 기초하여 적어도 하나의 인식된 라인 세그먼트를 결정하는 것을 포함한다. 커맨드 명 령어(들)는 적어도 하나의 인식된 라인 세그먼트에 기초할 수 있다. 상기 동작들은 하나 이상의 커맨드 명령어들에 기초하여 장면 레이아웃을 결정하는 것을 더 포함한다. 각 커맨 드 명령어는 장면 레이아웃의 적어도 하나의 요소에 대응한다. 일 예시적인 실시예에서, 하나 이상의 커맨드 명령어들을 결정하는 것은 수신된 입력 정보를 복수의 라인 세그먼트들로 파싱하는 것을 포함한다. 하나 이상 의 커맨드 명령어들을 결정하는 것은 또한 자연어 인식 알고리즘으로 상기 복수의 라인 세그먼트들을 순차적으 로 또는 병렬 처리하는 것을 포함한다. 순차적 또는 병렬 처리는 라인 세그먼트들 각각을 자연어 커맨드 데이 터베이스와 비교하는 것을 포함한다. 일부 실시예들에서, 장면 레이아웃을 결정하는 것은 각각의 객체 커맨드 명령어에 대해, 적어도 하나의 객체 및 적어도 하나의 대응하는 객체 위치를 결정하는 것을 포함할 수 있다. 즉, 객체들이 객체 데이터베이스로부터 풀링(pulled)될 때, 이러한 객체들은 \"월드 공간(world space)\"과 함께 위치될 수 있는 2 차원 또는 3 차원 좌 표로 할당될 수 있다. 객체들은 월드 공간 내의 좌표에 물리적으로 보여질 수 있고 및/또는 할당될 수 있는 임 의의 \"사물\"을 포함할 수 있다. 객체들은, 예를 들어, 사람, 동물, 자동차, 빌딩, 웅덩이, 구름 등을 포함할 수 있다. 객체들은 데이터베이스로부터 리콜될 수 있으며, 벡터들 또는 픽셀들로 표현된 2D 또는 3D 객체들일 수 있다. 또한, 일부 실시예들에 있어서, 장면 레이아웃을 결정하는 것은 각각의 환경 커맨드 명령어에 대해, 적어도 하 나의 환경 요소 및 적어도 하나의 대응하는 환경 요소 위치를 결정하는 것을 포함할 수 있다. 환경 요소들은 배경들, 조명 효과들/소스들(예를 들어, 램프들, 양초들, 별들 및 태양), 비, 안개, 엷은 안개, 눈, 렌즈 블러 (lens blur)/보케(bokeh), 렌즈 플레어(lens flare) 등과 같은 장면 효과들을 포함할 수 있지만, 이에 국한되는것은 아니다. 동작들은 또한 이러한 비교에 기초하여 적어도 하나의 인식된 라인 세그먼트를 결정하는 것을 포함한다. 커맨 드 명령어들은 상기 적어도 하나의 인식된 라인 세그먼트에 기초하여 결정될 수 있다. 상기 동작들은 렌더 처리 유닛을 사용하여, 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 렌더 링하는 것을 추가로 포함한다. 상기 동작들은 또한 디스플레이를 통해, 상기 렌더링된 장면을 디스플레이하는 것을 포함한다. 일부 실시예들에서, 상기 동작들은 각각의 커맨드 명령어를 객체 커맨드 명령어, 언어 커맨드 명령어, 또는 환 경 커맨드 명령어 중 적어도 하나로 분류하는 것을 포함할 수 있다. 동작들은 각각의 분류된 커맨드 명령어를 적어도 하나의 대응하는 데이터베이스에 저장하는 것을 추가로 포함할 수 있다. 이러한 시나리오들에서, 대응 하는 데이터베이스는 객체 데이터베이스, 언어 데이터베이스, 또는 환경 데이터베이스 중 적어도 하나를 포함할 수 있다. 일부 실시예들에서, 상기 결정된 커맨드 명령어들은 복수의 가능한 커맨드 명령어들 중에서 랜덤화된 선택을 포 함할 수 있다. 일 예로서, \"사람\"의 텍스트 입력은 \"사람\"에 대한 복수의 수백 또는 수천의 상이한 가능한 해 석들을 초래할 수 있다. 이러한 일부 시나리오들에서, 난수 생성기는 의사 난수를 생성할 수 있으며, 이 난수 는 사람에 대한 하나의 가능한 해석과 연관될 수 있다. 다시 말해서, 시스템은 주어진 단어 또는 문구에 대한 많은 다른 가능성들 중에서 \"선택\"하는 데 사용될 수 있는 의사 난수를 생성할 수 있다. 제어기는 거의 실시간으로 동작들을 수행할 수 있다. 즉, 동작들은 커맨드 명령어들의 결정을 수행하는 것 및/또는 상기 장면 레이아웃을 50 밀리 초마다 적어도 1회 결정하는 것을 포함할 수 있다. 다른 예들에서, 이러한 \"새로 고침\" 동작들은 100 마이크로 초 내지 100 밀리 초의 범위 내에서 적어도 1 회 발생할 수 있다. 일부 실시예들에서, 커맨드 명령어들 및/또는 장면 레이아웃의 결정은 주기적으로 또는 비 주기적으로 발생할 수 있다. 일부 실시예들에서, 동작들은 필요에 따라 발생할 수 있거나, \"새로 고침 레이트\"는, 예를 들어, 주 어진 장면에서의 객체들, 환경들, 및/또는 액션들에 기초하여 동적으로 조정될 수 있다. 다른 시간 스케일들이 가능하고 고려된다는 것이 이해될 것이다. 예를 들어, 장면 레이아웃은 초당 100 회 또는 10 밀리 초마다 한 번씩 결정될 수 있다. 제어기는 온보드 컴퓨터(on-board computer), 외부 컴퓨터, 또는 모바일 컴퓨팅 플랫폼, 가령, 스마트폰, 태블릿 디바이스, 퍼스널 컴퓨터, 웨어러블 디바이스 등을 포함할 수 있다. 부가적으로 또는 대안적으로, 제어 기는 클라우드 서버와 같은 원격으로 위치된 컴퓨터 시스템을 포함하거나 이에 (예를 들어, 유선 또는 무 선 연결을 통해) 통신 가능하게 연결될 수 있다. 일 예시적인 실시예에서, 제어기는 본원에 기술된 일부 또는 모든 방법 블록들 또는 단계들을 수행하도록 구성될 수 있다. 제어기는 하나 이상의 프로세서들 및 적어도 하나의 메모리를 포함할 수 있다. 프로세서 는, 예를 들어, 주문형 집적 회로(ASIC) 또는 필드 프로그래머블 게이트 어레이(field-programmable gate array)(FPGA)를 포함할 수 있다. 소프트웨어 명령어들을 수행하도록 구성된 다른 타입들의 프로세서들, 컴퓨터 들, 또는 디바이스들이 본원에서 고려된다. 메모리는 판독 전용 메모리(read-only memory)(ROM), 프로그 래머블 판독 전용 메모리(programmable read-only memory)(PROM), 소거 가능 프로그래머블 판독 전용 메모리 (erasable programmable read-only memory)(EPROM), 전기 소거 가능 프로그래머블 판독 전용 메모리 (electrically erasable programmable read-only memory)(EEPROM), 비휘발성 랜덤 액세스 메모리(non-volatile random-access memory)(예를 들어, 플래시 메모리), 솔리드 스테이트 드라이브(solid state drive)(SSD), 하드 디스크 드라이브(hard disk drive)(HDD), 컴팩트 디스크(Compact Disc)(CD), 디지털 비디오 디스크(Digital Video Disk)(DVD), 디지털 테이프(digital tape), 판독/기입(read/write)(R/W) CD들, R/W DVD들 등과 같은 비 일시적 컴퓨터 판독가능 매체를 포함할 수 있지만, 이에 국한되는 것은 아니다. III. 예시적인 방법들 도 2는 일 예시적인 실시예에 따른 방법을 도시한다. 방법은 도 1을 참조하여 도시되고 기술된 바와 같이 시스템의 하나 이상의 컴포넌트들에 의해 수행될 수 있는 블록들, 단계들, 또는 요소들을 포함할 수 있다. 방법은 본원에서 명시적으로 기술된 것보다 더 적거나 더 많은 단계들 또는 블록들을 포함할 수 있 다는 것이 이해될 것이다. 또한, 방법의 각각의 단계들 또는 블록들은 임의의 순서로 수행될 수 있고, 각 단계 또는 블록은 하나 이상의 횟수로 수행될 수 있다. 블록은 입력을 수신하는 단계를 포함한다. 상기 입력은 텍스트, 음성 또는 제스처 중 적어도 하나를 포함 할 수 있다. 일부 실시예들에서, 텍스트는 키보드 또는 터치 스크린을 통해 수신될 수 있다. 일 예로서, 입력 은 그래픽 사용자 인터페이스에서 텍스트 엔트리를 통해 수신된 텍스트를 포함할 수 있다. 일 예시적인 실시예에서, 음성은 마이크로폰 또는 다른 타입의 오디오 변환기를 통해 수신될 수 있다. 추가적 으로 또는 대안적으로, 일부 실시예들에서, 제스처들은 카메라를 통해 수신될 수 있고, 제스처 인식은 이미지 인식 방법들을 통해 수행될 수 있다. 블록은 상기 입력에 기초하여 하나 이상의 커맨드 명령어들을 결정하는 단계를 포함한다. 일부 실시예들 에서, 하나 이상의 커맨드 명령어들을 결정하는 단계는 입력을 복수의 라인 세그먼트들로 파싱하는 단계를 포함 할 수 있다. 이러한 시나리오들에서, 각각의 단어 또는 문구는 (예를 들어, AI1 과 같은 인공 지능 (artificial intelligence)(AI) 구성물에 의해) 파싱되어, 그 사전 의미 및/또는 그 집합적인 맥락 의미를 결정 할 수 있다. 예를 들어, AI1 은 각각의 단어를 파싱하고, 의미를 위해 로컬화된 언어 어휘집 또는 사전에 대해 단어를 체킹할 수 있다. 일부의 경우들에서, 제 2 AI 구성물(예를 들어, AI2 )이 전체 문장들 및/또는 단락들을 분석하는 데 사용 되어, 입력의 의미를 결정할 수 있다. 일부 실시예들에서, AI2 는 마침표를 고려한 의미를 위해 각 문장, 문구, 질문, 또는 진술문을 파싱 및 분석할 수 있다. 부가적으로 또는 대안적으로, 제 3 AI 구성물(예를 들어, AI3 )은 주어진 문구, 문장, 또는 단락의 구조 (예를 들어, 단어 순서, 단어 선택, 구어, 능동/수동 음성, 마침표)로부터 의미를 결정하는 데 사용될 수 있다. AI3 은 문맥에서 단어들이 사용되는 방식으로부터 구조 및 의미에 대한 입력을 분석할 수 있다. 또한, 다른 AI 구성물(예를 들어, AI4 )이 사이즈, 전경/배경 배치, 스케일링, 상대 움직임 등과 같은 객 체들 간의 특정의 정성적 또는 정량적 관계를 분석하는 데 사용될 수 있다. AI4 는 텍스트 박스에 입력된 텍스트의 전체 본문에 걸쳐 모든 단어의 정량적, 정성적 및 상관 특성들을 분석할 수 있다. 예를 들어, AI4는 주어진 월드 공간 내에서 두 객체 간의 공간 관계 또는 객체의 움직임을 결정할 수 있다. AI 구성물들이 특정의 분석 특성들을 갖는 것으로 기술되어 있지만, 상이한 분석 방법들 또는 타입들을 갖는 다 른 AI 구성물들이 가능하다. 예를 들어, 하나 이상의 AI 구성물들은 형태학적 세분화를 적용하여 단어들의 특 정 구조를 분석할 수 있다. 추가적으로 또는 대안적으로, AI 구성물은 품사를 분석하여 각 단어를 명사, 동사, 형용사 등으로 라벨링할 수 있다. 또한, AI 구성물은 명명된 엔티티 인식 방법을 사용하여 입력 텍스트를 분석 하도록 구성될 수 있다. 즉, 구성물은 단어들 및 문구들을 적절한 명칭, 장소, 및/또는 위치 등에 매핑시킬 수 있다. 다른 타입들의 AI 구성물들이 본원에서 가능하고 고려된다. 하나 이상의 커맨드 명령어들을 결정하는 것은 자연어 인식 알고리즘으로 복수의 라인 세그먼트들을 처리 하는 것을 포함할 수 있다. 자연어 인식 알고리즘은 머신 학습 언어 처리 방법, 통계적/확률적 언어 모델, 결정 트리 언어 모델, 또는 다른 타입의 자연어 처리(NLP) 방법을 포함할 수 있다. 복수의 라인 세그먼 트들의 처리는 하나 이상의 라인 세그먼트들을 자연어 명령어 데이터베이스와 비교하는 것을 포함할 수 있 다. 일부 실시예들에서, 자연어 인식 알고리즘은 주어진 장면 내에서 캐릭터들/객체들에 의해 발성될 수 있는 오디오 다이얼로그를 제공할 수 있다. 이러한 일부 시나리오들에서, 이러한 오디오 다이얼로그의 엔트리는 객 체(예를 들어, 사람)가 애니메이션되도록 할 수 있다. 즉, 사람의 입술 및/또는 신체(예를 들어, 신체 언어)는 오디오 다이얼로그와 동기하여 움직일 수 있다. 따라서, 제시된 장면은 입력 다이얼로그를 실제로 발성하는 그 래픽 사람을 시뮬레이션할 수 있다. 또한, 다이얼로그는 발성된 오디오 출력으로서 사용자에게 제시될 수 있다. 또한, 일부 실시예들은 자연어 명령어 데이터베이스와의 비교에 기초하여 적어도 하나의 인식된 라인 세그 먼트를 결정하는 것을 포함한다. 따라서, 하나 이상의 커맨드 명령어들은 적어도 하나의 인식된 라인 세그먼트 에 기초할 수 있다. 파싱 및 분석의 순서는 순차적으로 및/또는 병렬로 수행될 수 있다. 예를 들어, 자연어 인식 알고리즘으 로 복수의 라인 세그먼트들을 처리하는 것은 자연어 인식 알고리즘으로 복수의 라인 세그먼트들을 순차적으로 처리하는 것을 포함할 수 있다. 추가적으로 또는 대안적으로, 자연어 인식 알고리즘으로 복수의 라인 세그먼트 들을 처리하는 것은 자연어 인식 알고리즘으로 복수의 라인 세그먼트들 중 적어도 일부를 동시에 처리하는 것을포함할 수 있다. 달리 말하자면, 일부 실시예들에서, 주어진 입력은 먼저 AI1 에 의해, 이어서 AI2 , 이어서 AI3 등에 의해 분석될 수 있다. 다른 실시예들에서, 주어진 입력은 다수의 AI 구성물들에 의해 동시에 또는 동시적 방식으로 분석될 수 있다. 일부 실시예들에서, 재귀적 루프들은 분석 사이클들을 반복하는 데 사용될 수 있음을 이해할 것이다. 예를 들어, 주어진 AI 구성물에 의한 분석 결과가 주어진 입력의 추정적 의미와 관 련하여 불확실성 임계치 레벨보다 큰 불확실성 레벨을 초래하는 경우, 이 분석은 동일한 AI에 의해 재차 수행될 수 있거나, 또는 불확실한 분석의 결과는 다른 AI 구성물에 의해 분석될 수 있다. 이러한 재귀적 분석은 주어 진 입력의 의미와 관련하여 궁극적으로 보다 높은 확실성을 제공할 수 있다. 다른 양태들 중에서, AI 구성물들은 객체들, 환경들, 및/또는 언어학의 다양한 특성들을 결정할 수 있다. 예를 들어, AI는 주어진 입력 문장에서 대상(예를 들어, \"누구를\")을 평가하고, 그것이 주어진 사람, 동물, 인물, 유 기체 등을 나타내는 것으로 결정할 수 있다. 추가적으로 또는 대안적으로, AI는 주어진 입력의 시간적 특성(예를 들어, \"때\")을 평가할 수 있다. 예를 들어, 텍스트 및/또는 상황 분석에 기초하여, AI는 입력으로부터 주어진 연도, 기간, 시대 등을 결정할 수 있다. 또한, AI는 주어진 입력의 위치(\"장소\")를 평가할 수 있다. 일 예로서, AI는 주어진 입력에 의해 기술된 바와 같이 장소들, 지역들, 및/또는 카메라 각도들을 결정할 수 있다. 선택적으로, 방법은 하나 이상의 커맨드 명령어들의 각각을 객체 커맨드 명령어, 언어 커맨드 명령어 , 또는 환경 커맨드 명령어 중 적어도 하나로 분류하는 단계를 포함할 수 있다. 분류시, 각각의 분 류된 커맨드 명령어는 적어도 하나의 대응하는 데이터베이스(236a-c)에 저장될 수 있다. 일 예로서, 대응하는 데이터베이스(236a-c)는 객체 데이터베이스(236a), 언어 데이터베이스(236b), 및/또는 환경 데이터베이스(236c) 중 적어도 하나를 포함할 수 있다. 객체 데이터베이스(236a)는 월드 공간 장면 레이아웃에서 사용하기 위해 사 람들, 장소들, 사물들, 빌딩들, 또는 다른 타입의 객체들의 벡터 표현들을 포함할 수 있다. 언어 데이터베이스 (236b)는 텍스트-음성 오디오 클립들, 사운드 녹음들(예를 들어, 새들의 지저귀는 소리, 자동차 경적 소리 등), 인공 사운드 효과들(예를 들어, Foley 사운드 아트 등), 및/또는 오디오 사운드 스테이지 파라미터들(예를 들어, 에코, 지연, 룸 사이즈 등)을 포함할 수 있다. 환경 데이터베이스(236c)는 월드 공간 장면 레이아웃에서 사용하기 위해 하늘, 구름들, 대륙들 및 대양들, 공간 환경들, 행성들, 또는 다른 타입들의 그래픽 장면들의 벡 터 표현들을 포함한다. 블록은 하나 이상의 커맨드 명령어들에 기초하여 장면 레이아웃을 결정하는 단계를 포함한다. 하나 이상 의 커맨드 명령어들의 각각은 장면 레이아웃의 적어도 하나의 요소에 대응한다. 일 예시적인 실시예에서, 장면 레이아웃을 결정하는 단계는 각각의 객체 커맨드 명령어에 대해, 적어도 하나의 객체(예를 들어, 벡터 객체) 및 상기 객체가 배치되는 월드 스테이지 내의 적어도 하나의 대응하는 위치를 결정 하는 단계를 포함할 수 있다. 추가적으로 또는 대안적으로, 장면 레이아웃을 결정하는 단계는 각각의 환경 커 맨드 명령어에 대해, 적어도 하나의 환경 요소 및 적어도 하나의 대응하는 환경 요소 위치를 결정하는 단계를 포함할 수 있다. 일부의 경우들에서, 장면 레이아웃에 통합될 객체들은 연관된 애니메이션(예를 들어, 우산 개 폐, 사람의 산책 등)을 가질 수 있다. 이러한 시나리오들에서, 장면 레이아웃을 결정하는 단계는 애니메이션이 어떠한 순서로 및/또는 어떠한 시간에 시작 및 정지할지 등을 결정하는 단계를 포함할 수 있다. 본원의 다른 부분에서 기술되는 바와 같이, 벡터 객체들 및/또는 환경 요소들은 복수의 가능한 요소들로부터 랜 덤하게 선택될 수 있다. 이러한 시나리오에서, 난수 생성기는 의사 랜덤 시드(pseudo-random seed)를 생성할 수 있다. 하나 이상의 커맨드 명령어들을 결정하는 단계는 의사 랜덤 시드와 연관된 복수의 커맨드 명령어들 중에서 선택하는 것에 더 기초한다. 다른 실시예에서, 장면 레이아웃을 결정하는 단계는 의사 랜덤 시드와 연 관된 복수의 장면 레이아웃 중에서 선택하는 것에 더 기초한다. 블록은 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 제공하는 단계를 포함한다. 이러한 시나 리오들에서, 렌더링된 장면은 전용 그래픽 프로세서를 사용하여 제공될 수 있다. 렌더링된 장면은 결정된 장면 레이아웃에 기초할 수 있다. 전용 그래픽 프로세서는 그래픽 처리 유닛(GPU)을 포함할 수 있다. 추가적으로 또는 대안적으로, 렌더링된 장면을 제공하는 단계는 중앙 처리 유닛(CPU)을 사용하여 렌더링된 장면 을 렌더링하는 단계를 포함할 수 있다. 블록은 출력을 HTML5 호환 가능 포맷으로 제공하는 단계를 포함할 수 있다. 추가적으로 또는 대안적으로, 출력은 애플리케이션 프로그래밍 인터페이스를 사용하여 제공될 수 있다. 이러한 시나리오들에서, 애플리케이션 프로그래밍 인터페이스는 Open GL, Direct 3D, Glide API, Mantle, Metal, RenderMan, RenderWare, 또는 Vulkan 중 적어도 하나를 포함할 수 있다. 또한, 출력은 그래픽 엔 진을 사용하여 제공될 수 있다. 그래픽 엔진은 Unity Game Engine, Cry Engine, Unreal Engine, id Tech 4, id Tech 5, 또는 Source 중 적어도 하나를 포함할 수 있다. 전술한 바와 같이, 방법의 블록들의 일부 또는 전부가 반복될 수 있다. 또한, 일부 실시예들에서, 방법 은 거의 실시간으로 수행된다. 일 예시적인 실시예에서, 거의 실시간은 하나 이상의 커맨드 명령어들을 0.1 내지 100 밀리 초마다 적어도 1회 결정하는 것 및/또는 장면 레이아웃을 0.1 내지 100 밀리 초마다 적어도 1회 결정하는 것을 포함할 수 있다. 방법은 주기적 간격들(예를 들어, 60 Hz, 600 Hz 등) 또는 비 주기적 간격들로 수행될 수 있다. 도 3a는 일 예시적인 실시예에 따른 동적 그래픽 생성 시나리오를 도시한다. 시나리오는 텍스트 엔 트리 윈도우, 수 개의 데이터베이스들(304a-d), 툴바, 3D 툴바, 및 장면 디스플레이를 포 함하여, 수 개의 요소들을 갖는 그래픽 사용자 인터페이스를 도시한다. 텍스트 엔트리 윈도우는 단어들, 문구들, 문장들, 및/또는 단락들을 수용할 수 있다. 본원에 기술된 바와 같이, 이러한 입력은 다양한 AI 구성 물들에 의해 파싱 및/또는 분석되어, 그 입력으로부터의 의미를 결정할 수 있다. 텍스트 엔트리 윈도우가 도 3a에 도시되어 있지만, 텍스트 엔트리 윈도우에 디스플레이하기 위해 음성 입력이 텍스트로 변환될 수 있다는 것이 이해된다. 또한, 제스처 입력들이 마찬가지로 변환될 수 있거나 또는 이와는 달리 텍스트 엔트리 윈도우에 통합될 수 있다. 추가적으로 또는 대안적으로, 음성 입력 및/또는 제스처 입력들은 다른 곳에서 처리되거나 디스플레이될 수 있다. 데이터베이스들(304a-d)은 객체 데이터베이스, 대기 데이터베이스, 언어학/언어 데이터베이스, 속성 데이터베이 스 등을 포함할 수 있다. 다른 타입들의 데이터베이스들은 본원에서 가능하고 고려된다. 데이터베이스들 (304a-d)은 장면 디스플레이에 디스플레이하기 위해 선택될 수 있는 가능한 객체들, 속성들, 대기 효과들 등을 제공할 수 있다. 일부의 경우들에서, 선택된 속성들은 장면 디스플레이에 직접 디스플레이될 필요는 없으며, 오히려 그러한 속성들(예를 들어, 중력, 시각, 화이트 밸런스 등)은 현재 장면 디스플레이에 객체 들 또는 대기 효과들이 어떻게 나타나는지에 영향을 줄 수 있다. 도 3a에 도시된 바와 같이, 사용자는 다음의 텍스트를 텍스트 엔트리 윈도우로 가져 오거나 타이핑할 수 있다: EXT. RODEO DRIVE - BEVERLY HILLS CA - MORNING 와이드 샷(WIDE SHOT) 유명한 로데오(Rodeo) 및 비아 로데오(Via Rodeo) 드라이브의 모퉁이에 접한 텅빈 자갈 및 콘크리트 스트리트 (cobblestone and concrete streets)는 아침 햇살이 춤추듯 비추면 화려한 빛을 발산한다(Empty cobblestone and concrete streets cast a brilliant glow as the morning rays dance off them on the corner of the famous Rodeo and Via Rodeo drive). 독특하면서도 화려한 웅덩이가 비아 로데오(Via Rodeo)의 중앙에서 끝을 향해 지면을 뒤덮으며, 기안 프랑코 페 레(GianFranco Ferre) 빌딩의 어두운 그림자가 드리워지면서 이상하고 쓸쓸해진다(A peculiar yet colorful puddle covers the ground from the middle of Via Rodeo back towards the end, oddly and lonely placed as it's draped in the dark shadow of the GianFranco Ferre building). 엔드 장면 입력된 텍스트에 응답하여, 컴퓨터(예를 들어, 제어기)는 방법을 수행하여 장면 디스플레이를 제공할 수 있다. 예를 들어, AI 구성물은 그 텍스트를 분석하여 그의 의미를 도출할 수 있다. 예를 들어, 축 약형 \"ext.\"는 위치 속성(\"외부\" 또는 \"바깥쪽\")으로 분류될 수 있다. \"Rodeo Drive-Beverly Hills CA\"는 AI 구성물에 의해 대기 커맨드로 해석될 것이다(\"위치는 캘리포니아 주 비벌리 힐스의 로데오 드라이브\"이다). 또 한, \"와이드 샷(Wide Shot)\"은 다른 대기 커맨드(\"광각 카메라 렌즈를 사용/시뮬레이션\")로 해석될 수 있다. 또한, \"자갈 및 콘크리트 스트리트\"는 특정 텍스처들(\"자갈 패턴의 표면 및 콘크리트의 표면\")을 갖는 객체들로 해석될 수 있다. 다른 단어들은 유사하게 파싱될 수 있다. 결과적으로, 장면 디스플레이는 비벌리 힐스의 로데오 드라이브의 외관도 및 GianFranco 빌딩의 그림자에 드리워진 적-청-녹의 웅덩이를 포함한다. 도 3b는 일 예시적인 실시예에 따른 다른 동적 그래픽 생성 시나리오를 도시한다. 즉, 텍스트 윈도우 에 입력된 텍스트는 다른 구문 및 문장 구조를 포함한다. \"유명하지만 불가사의하게 텅빈 로데오 스트리 트와 비아 로데오 드라이브가 만나는 밝은 아침이었다(It was a bright morning where the famous but eerily empty streets of Rodeo and Via Rodeo Drive meet). 기안 프랑코 페레(GianFranco Ferre) 빌딩으로부터의 강 력한 그림자가 무언가를 일부만 가릴 정도로 사실상 너무 밝았다(So bright in fact that the hard shadows from the GianFranco Ferre building partially hid something). 웅덩이와 같은 형태의 다채롭고 우화한 몸체 가 비아 로데오의 절반을 지나 멀리까지 구불구불하게 보였다(Puddle-like in form, its colorful fluid body seemed to squiggle through half of Via Rodeo into the distance).\" 2 개의 입력이 다르기 때문에, 장면 디스플레이의 일부 요소들은 시나리오와 다르게 해석될 수 있다. 도 3c는 일 예시적인 실시예에 따른 동적 그래픽 생성 시나리오의 자연어 인식 페이즈를 도시한다. 즉, 자연어 인식 페이즈는 AI1 , AI2 , AI3 및 AI4 와 관련하여 기술되고 도 2에 도시된 바와 같은 의미를 결정하기 위해 개별 단어/문장/문단 파싱을 포함할 수 있다. 또한, 자연어 인식 페이 즈는 인식된 커맨드들을 수 개의 그룹들(예를 들어, 객체 커맨드, 언어 커맨드, 및 환경 커맨드 )로 분류하는 것을 포함할 수 있다. 도 3d는 일 예시적인 실시예에 따른 동적 그래픽 생성 시나리오를 도시한다. 텍스트 윈도우에 도시 된 바와 같이, 사용자는 기존 텍스트를 편집하여 장면 디스플레이를 직접 조정할 수 있다. 추가적으로 또 는 대안적으로, 사용자는 입력 텍스트로부터 특정의 단어들을 선택함으로써, 선택된 텍스트와 연관된 객체 또는 효과를 조정할 수 있다. 이 경우, \"어두운 그림자(dark shadow)\"가 선택된다. 이러한 시나리오에서, 장면 디 스플레이에 적용되는 그림자를 연하게 하거나 진하게 하는 옵션이 사용자에게 제공될 수 있다. 일 예로서, 입력 텍스트에서 \"진하게(dark)\"라는 단어를 제거하거나 \"그림자(shadow)\" 변경자를 \"연하게\" 하거나 심지어는 \"투명하게(transparent)\" 조정함으로써 빌딩의 그림자를 밝게 할 수 있다. 장면 디스플레이에 도시된 바와 같이, 그림자는 약간 밝아져서 웅덩이를 보다 보다 가시적으로 만들었다. 도 3e는 일 예시적인 실시예에 따른 추가적인 동적 그래픽 생성 시나리오를 도시한다. 시나리오에 도시된 바와 같이, 장면 디스플레이를 변경하는 다른 방식은 입력 텍스트를 \"아침(morning)\"에서 \"저 녁(evening)\"으로 조정하는 것이다. \"저녁(evening)\"이라는 단어는 AI 구성물에 의해 시각을 변경하는 것으로 분석될 수 있다. 이와 같이, 장면 디스플레이에 도시된 바와 같이, 조명이 어두워질 수 있고, 그림자가 진해질 수 있고, 광 소스의 화이트 밸런스가 조정될 수 있다. 따라서, 웅덩이는 이전 장면 디스플레이들에서보 다 훨씬 덜 가시적일 수 있다. 도 4a는 일 예시적인 실시예에 따른 벡터 객체 프로세스를 도시한다. 주어진 객체(이 경우 구)가 벡 터 객체 데이터베이스에 로딩될 때, 그 객체는 x 방향으로 1000 개의 층으로 분할되어 벡터 객체를 형성한 다. 구체적으로, 벡터 객체는 주어진 객체가 1000x1000x1000 3 차원(예를 들어, x, y, z) 그리드와 교차하는 포인트들을 기록하고 x 방향으로 각 층에 대한 (y, z) 좌표들을 저장함으로써 생성된다. 벡터 객체 는 상이한 사이즈의 그리드(예를 들어, 2000x2000x1000)를 사용하여 정의될 수 있다는 것이 이해될 것이다. 따라서, 다음의 압축/압축 해제 방법은 이용되는 그리드에 기초하여 상이한 수의 층들을 포함할 수 있 다. 벡터 객체가 벡터 객체 데이터베이스에 저장될 때, 1000 개의 층들의 각각은 단일 층으로 압축 다운되어 교차 포인트들이 벡터들로서 서로 중첩된다. 벡터 내의 각 교차 포인트는 그 관련 층 및 공간 좌표들(예를 들 어, y 위치, z 위치, 및 x 층)에 대한 정보를 포함한다. 이와 같이, 벡터 객체가 벡터 객체 데이터베이스 에 저장될 때, 압축된 버전을 저장하기 위한 효과적인 메모리 사용량은 주어진 객체의 \"전체\" 표현에 대해 전체 1000x1000x1000 그리드가 저장되는 경우보다 실질적으로 적을 수 있다. 따라서, 유사한 수의 객체들에 대 해, 이러한 벡터 객체 데이터베이스는 객체들의 완전한 3D 표현들을 포함하는 데이터베이스보다 훨씬 적은 메모 리/디스크 공간을 차지할 수 있다. 도 4b는 일 예시적인 실시예에 따른 벡터 객체 프로세스를 도시한다. 즉, 벡터 객체가 벡터 객체 데 이터베이스로부터 호출될 때, 벡터 객체는 x 방향으로 1000 개의 층으로 객체를 다시 확장함으로써 압축 해제된다. 따라서, 벡터 객체는 주어진 객체의 전체 표현보다 훨씬 더 빠르게 로딩할 수 있다. 예를 들어, 압축된 벡터 객체는 압축 해제된 객체의 메모리의 1/1000을 차지할 수 있다. 또한, 벡터들 및 벡터 객체들을 특히 효율적으로 처리할 수 있는 GPU들을 이용함으로써, 이러한 벡터 객체들의 로딩, 배치 및 애니메 이션이 동적의 거의 실시간 방식으로 제공될 수 있다. 본원에 기술된 벡터 객체들 및 대기 요소들은 유사한 압축/압축 해제 방법들을 사용하는 별개의 벡터 데이터베 이스들에 저장될 수 있다. 이와 같이, 객체들 및 대기 효과들은 거의 실시간으로 월드 스테이지에 동적으로 통 합될 수 있다. 예를 들어, 객체들 및 대기 효과들은 본질적으로 사용자가 타이핑, 발성, 및/또는 제스처에 의 해 입력들을 입력할 수 있는 정도의 속도로, 호출, 디스플레이, 및 일부의 경우들에서 애니메이션될 수 있다. 도 5는 일 예시적인 실시예에 따른 방법을 도시한다. 방법은 도 1을 참조하여 도시되고 기술된 바와 같이 시스템의 하나 이상의 컴포넌트들에 의해 수행될 수 있는 블록들, 단계들, 또는 요소들을 포함할 수 있다. 방법은 본원에서 명시적으로 기술된 것보다 더 적거나 더 많은 단계들 또는 블록들을 포함할 수 있 다는 것이 이해될 것이다. 또한, 방법의 각각의 단계들 또는 블록들은 임의의 순서로 수행될 수 있고, 각 단계 또는 블록은 하나 이상의 횟수로 수행될 수 있다. 방법의 일부 블록들 또는 단계들은 도 2를 참조하 여 도시되고 기술된 바와 같이, 방법의 하나 이상의 블록들 또는 단계들과 유사하거나 동일할 수 있다. 블록은 입력을 수신하는 단계를 포함하며, 상기 입력은 텍스트, 음성, 또는 제스처 중 적어도 하나를 포함 한다. 블록은 상기 입력에 기초하여 하나 이상의 커맨드 명령어들을 결정하는 단계를 포함한다. 블록은 상기 하나 이상의 커맨드 명령어들에 기초하여 장면 레이아웃을 결정하는 단계를 포함한다. 블록은 상기 결정된 장면 레이아웃에 기초하여 렌더링된 장면을 제공하는 단계를 포함한다. 도면들에 도시된 특정의 배열들은 제한적인 것으로 간주되어서는 안된다. 다른 실시예들은 주어진 도면에 도시 된 각각의 요소를 많거나 적게 포함할 수 있음을 이해해야 한다. 또한, 도시된 요소들 중 일부는 결합되거나 생략될 수 있다. 또한, 예시적인 실시예는 도면들에 도시되지 않은 요소들을 포함할 수 있다. 정보 처리를 나타내는 단계 또는 블록은 본원에 기술된 방법 또는 기술의 특정 논리 기능들을 수행하도록 구성 될 수 있는 회로에 대응할 수 있다. 대안적으로 또는 추가적으로, 정보의 처리를 나타내는 단계 또는 블록은 모듈, 세그먼트, 물리적 컴퓨터(예를 들어, 필드 프로그래머블 게이트 어레이(FPGA) 또는 주문형 집적 회로 (ASIC)), 또는 프로그램 코드의 일부(관련 데이터를 포함)에 대응할 수 있다. 프로그램 코드는 방법 또는 기술 에서 특정 논리 기능들 또는 액션들을 구현하기 위해 프로세서에 의해 실행 가능한 하나 이상의 명령어들을 포 함할 수 있다. 프로그램 코드 및/또는 관련 데이터는 디스크, 하드 드라이브, 또는 다른 저장 매체를 포함하는 저장 디바이스와 같은 임의의 타입의 컴퓨터 판독가능 매체에 저장될 수 있다. 컴퓨터 판독가능 매체는 또한 레지스터 메모리, 프로세서 캐시, 및 랜덤 액세스 메모리(RAM)와 같은 짧은 시간 기간 동안 데이터를 저장하는 컴퓨터 판독가능 매체와 같은 비 일시적 컴퓨터 판독가능 매체를 포함할 수 있다. 컴퓨터 판독가능 매체는 또한 프로그램 코드 및/또는 데이터를 더 오랜 시간 기간 동안 저장하는 비 일시적 컴 퓨터 판독가능 매체를 포함할 수 있다. 따라서, 컴퓨터 판독가능 매체는, 예를 들어, 판독 전용 메모리(ROM), 광학 또는 자기 디스크, CD-ROM (Compact-Disc Read Only Memory)과 같은 2 차 또는 영구적 장기 저장 디바이 스를 포함할 수 있다. 컴퓨터 판독가능 매체는 또한 임의의 다른 휘발성 또는 비휘발성 저장 시스템들일 수 있 다. 컴퓨터 판독가능 매체는, 예를 들어, 컴퓨터 판독가능 저장 매체, 또는 유형적인 저장 디바이스로 간주될 수 있다. 다양한 예들 및 실시예들이 개시되었지만, 다른 예들 및 실시예들이 본 기술 분야의 기술자들에게 명백할 것이다. 다양한 개시된 예들 및 실시예들은 예시를 위한 것이며, 제한하려는 것이 아니며, 진정한 범위는 다음의 청구범위에 의해 표시된다. 도면 도면1 도면2 도면3a 도면3b 도면3c 도면3d 도면3e 도면4a 도면4b 도면5"}
{"patent_id": "10-2019-7033039", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1는 일 예시적인 실시예에 따른 시스템을 도시한다. 도 2는 일 예시적인 실시예에 따른 방법을 도시한다. 도 3a는 일 예시적인 실시예에 따른 동적 그래픽 생성 시나리오를 도시한다. 도 3b는 일 예시적인 실시예에 따른 다른 동적 그래픽 생성 시나리오를 도시한다. 도 3c는 일 예시적인 실시예에 따른 동적 그래픽 생성 시나리오의 자연어 인식 페이즈(natural language recognition phase)를 도시한다. 도 3d는 일 예시적인 실시예에 따른 동적 그래픽 생성 시나리오를 도시한다. 도 3e는 일 예시적인 실시예에 따른 추가적인 동적 그래픽 생성 시나리오를 도시한다. 도 4a는 일 예시적인 실시예에 따른 벡터 객체 프로세스를 도시한다. 도 4b는 일 예시적인 실시예에 따른 벡터 객체 프로세스를 도시한다. 도 5는 일 예시적인 실시예에 따른 방법을 도시한다."}
