{"patent_id": "10-2021-0181699", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0092371", "출원번호": "10-2021-0181699", "발명의 명칭": "공진화 신경 상미분 방정식 기반의 인공지능 신경망 장치 및 방법", "출원인": "연세대학교 산학협력단", "발명자": "박노성"}}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "다운스트림 기계학습 태스크를 제공하는 메인 NODE (Neural Ordinary Differential Equation) 모듈; 및상기 다운스트림 기계학습 태스크를 수신하고 상기 메인 NODE 모듈에 어텐션을 제공하는 어텐션 NODE 모듈;을포함하며,상기 메인 NODE 모듈 및 상기 어텐션 NODE 모듈은 시간의 경과에 따라 서로 영향을 주어 상기 메인 NODE 모듈이입력 샘플(x)에 대하여 주어진 시간에서의 다변수 시계열 변수(multivariate time-series value at a giventime)을 출력하도록 하는 공진화 신경 상미분 방정식 (Neural Ordinary Differential Equation) 기반의 인공지능 신경망 장치."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 입력 샘플(x)에 대한 특징을 추출하여 초기 시간에서 초기 특징 벡터를 생성하고, 상기 초기 특징 벡터를상기 메인 NODE 모듈에 제공하는 특징 추출 모듈;을 더 포함하는 것을 특징으로 하는 공진화 신경 상미분 방정식 기반의 인공지능 신경망 장치."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 초기 특징 벡터를 입력받아 초기 어텐션을 생성하고 상기 초기 어텐션을 상기 어텐션 NODE 모듈에 제공하여 다음 시간에서의 다변수 시계열 변수의 산출을 지원하는 초기 어텐션 생성 모듈;을 더 포함하는 것을 특징으로 하는 공진화 신경 상미분 방정식 기반의 인공지능 신경망 장치."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 메인 NODE 모듈은인접한 시간들에 대한 ODE (Ordinary Differential Equation) 함수의 적분을 수행하고, 상기 ODE 함수는 상기주어진 시간의 1) 다변수 시계열 변수 및 2) 어텐션을 입력받는 것을 특징으로 하는 공진화 신경 상미분 방정식기반의 인공지능 신경망 장치."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 어텐션 NODE 모듈은상기 ODE 함수로서, 상기 다변수 시계열 변수와 상기 시간 진화 매트릭스의 시그모이드 활성화 함수 간의 구성요소 곱 연산(element-wise multiplication)을 수행하는 것을 특징으로 하는 공진화 신경 상미분 방정식 기반의인공지능 신경망 장치."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0092371-3-제4항에 있어서, 상기 어텐션 NODE 모듈은상기 인접한 시간들에 대한 어텐션 생성 함수의 적분을 수행하고, 상기 어텐션 생성 함수는 상기 주어진 시간의1) 상기 어텐션의 로지트 값(logit value)을 나타내는 시간 진화 매트릭스 및 2) 상기 다변수 시계열 변수를 입력받는 것을 특징으로 하는 공진화 신경 상미분 방정식 기반의 인공지능 신경망 장치."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 주어진 시간에서의 다변수 시계열 변수를 입력받아 상기 입력 샘플에 대한 예측을 수행하는 분류 모듈;을더 포함하는 것을 특징으로 하는 공진화 신경 상미분 방정식 기반의 인공지능 신경망 장치."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "메인 NODE (Neural Ordinary Differential Equation) 모듈을 통해 다운스트림 기계학습 태스크를 제공하는 단계; 및어텐션 NODE 모듈을 통해 상기 다운스트림 기계학습 태스크를 수신하고 상기 메인 NODE 모듈에 어텐션을 제공하는 단계;를 포함하며,상기 메인 NODE 모듈 및 상기 어텐션 NODE 모듈은 시간의 경과에 따라 서로 영향을 주어 상기 메인 NODE 모듈이입력 샘플(x)에 대하여 주어진 시간에서의 다변수 시계열 변수(multivariate time-series value at a giventime)을 출력하도록 하는 공진화 신경 상미분 방정식 (Neural Ordinary Differential Equation) 기반의 인공지능 신경망 방법."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,특징 추출 모듈을 통해 상기 입력 샘플(x)에 대한 특징을 추출하여 초기 시간에서 초기 특징 벡터를 생성하고,상기 초기 특징 벡터를 상기 메인 NODE 모듈에 제공하는 단계;를 더 포함하는 것을 특징으로 하는 공진화 신경상미분 방정식 기반의 인공지능 신경망 방법."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,초기 어텐션 생성 모듈을 통해 상기 초기 특징 벡터를 입력받아 초기 어텐션을 생성하고 상기 초기 어텐션을 상기 어텐션 NODE 모듈에 제공하여 다음 시간에서의 다변수 시계열 변수의 산출을 지원하는 단계;를 더 포함하는것을 특징으로 하는 공진화 신경 상미분 방정식 기반의 인공지능 신경망 방법."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 메인 NODE 모듈은인접한 시간들에 대한 ODE (Ordinary Differential Equation) 함수의 적분을 수행하고, 상기 ODE 함수는 상기주어진 시간의 1) 다변수 시계열 변수 및 2) 어텐션을 입력받는 것을 특징으로 하는 공진화 신경 상미분 방정식기반의 인공지능 신경망 방법."}
{"patent_id": "10-2021-0181699", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2023-0092371-4-제1항에 있어서,분류 모듈을 통해 상기 주어진 시간에서의 다변수 시계열 변수를 입력받아 상기 입력 샘플에 대한 예측을 수행하는 단계;를 더 포함하는 것을 특징으로 하는 공진화 신경 상미분 방정식 기반의 인공지능 신경망 방법."}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 공진화 신경 상미분 방정식 (Neural Ordinary Differential Equation) 기반의 인공지능 신경망 장치 및 방법에 관한 것으로, 상기 장치는 다운스트림 기계학습 태스크를 제공하는 메인 NODE (Neural Ordinary Differential Equation) 모듈; 및 상기 다운스트림 기계학습 태스크를 수신하고 상기 메인 NODE 모듈에 어텐션을 제공하는 어텐션 NODE 모듈;을 포함하고, 상기 메인 NODE 모듈 및 상기 어텐션 NODE 모듈은 시간의 경과에 따라 서로 영향을 주어 상기 메인 NODE 모듈이 입력 샘플(x)에 대하여 주어진 시간에서의 다변수 시계열 변수 (multivariate time-series value at a given time)을 출력하도록 할 수 있다."}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 신경망 구성 기술에 관한 것으로, 보다 상세하게는 뉴럴 ODE를 기반으로 머신 러닝 작업을 위한 뉴럴 ODE와 어텐션 제공을 위한 뉴럴 ODE를 구성하여 주의 깊은 이중 공동 진화 NODE를 구현하는 공진화 신경 상미분 방정식 기반의 인공지능 신경망 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "레이어(또는 시간) 에서 은닉 벡터(hidden layer)를 의미하는 에 대해 와 같이 표현되는 잔차 연결(residual connection)은 ODE를 풀기 위한 오일러 양해법(explicit Euler method)과 동일한 것으로 알려져 있다. 이와 관련하여, 신경 상미분 방정식(NODE)은 연속 시간 변수 를 사용하여 잔차 연결을 일 반화할 수 있다. 즉, NODE에서 는 임의의 실수에 해당할 수 있는 반면, 기존의 잔차 네트워크에서 는 음이 아닌 정수에 해당하 여야 한다. 따라서, NODE는 다양한 작업들에서 효율성을 제공할 수 있다. 예를 들어, NODE는 기존보다 더 나은 정확도(accuracy)를 제공할 수 있을 뿐만 아니라 기존의 신경망과 비교하여 더 작은 수의 매개변수들을 포함할 수 있다. 더 나은 개선을 위하여, 많은 연구들은 ODE 상태 증강(ODE state augmentation)에서 NODE에 특화된 새로운 정형 화(regularization)에 이르는 NODE에 대한 향상 방안들을 제안하고 있다. ODE 상태 증강은 NODE의 동형 특성 (homeomorphic characteristic)을 극복하기 위해 제안되었고, 다양한 정형화 개념은 풀기 쉽다고 여겨지는 직선 ODE를 학습하기 위해 제안되었다. 다만, NODE에 어텐션(attention)의 개념을 결합하기 위한 작업은 이전에 제안된 바가 없다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2021-0031197호 (2021.03.19)"}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는 뉴럴 ODE를 기반으로 머신 러닝 작업을 위한 뉴럴 ODE와 어텐션 제공을 위한 뉴럴 ODE를 구성하여 주의 깊은 이중 공동 진화 NODE를 구현하는 공진화 신경 상미분 방정식 기반의 인공지능 신경망 장치 및 방법을 제공하고자 한다."}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예들 중에서, 공진화 신경 상미분 방정식 (Neural Ordinary Differential Equation) 기반의 인공지능 신경 망 장치는 다운스트림 기계학습 태스크를 제공하는 메인 NODE (Neural Ordinary Differential Equation) 모듈; 및 상기 다운스트림 기계학습 태스크를 수신하고 상기 메인 NODE 모듈에 어텐션을 제공하는 어텐션 NODE 모듈; 을 포함하고, 상기 메인 NODE 모듈 및 상기 어텐션 NODE 모듈은 시간의 경과에 따라 서로 영향을 주어 상기 메 인 NODE 모듈이 입력 샘플(x)에 대하여 주어진 시간에서의 다변수 시계열 변수(multivariate time-series value at a given time)을 출력하도록 할 수 있다. 상기 장치는 상기 입력 샘플(x)에 대한 특징을 추출하여 초기 시간에서 초기 특징 벡터를 생성하고, 상기 초기 특징 벡터를 상기 메인 NODE 모듈에 제공하는 특징 추출 모듈;을 더 포함할 수 있다. 상기 장치는 상기 초기 특징 벡터를 입력받아 초기 어텐션을 생성하고 상기 초기 어텐션을 상기 어텐션 NODE 모 듈에 제공하여 다음 시간에서의 다변수 시계열 변수의 산출을 지원하는 초기 어텐션 생성 모듈;을 더 포함할 수 있다. 상기 메인 NODE 모듈은 인접한 시간들에 대한 ODE (Ordinary Differential Equation) 함수의 적분을 수행하고, 상기 ODE 함수는 상기 주어진 시간의 1) 다변수 시계열 변수 및 2) 어텐션을 입력받을 수 있다. 상기 어텐션 NODE 모듈은 상기 ODE 함수로서, 상기 다변수 시계열 변수와 상기 시간 진화 매트릭스의 시그모이 드 활성화 함수 간의 구성요소 곱 연산(element-wise multiplication)을 수행할 수 있다. 상기 어텐션 NODE 모듈은 상기 인접한 시간들에 대한 어텐션 생성 함수의 적분을 수행하고, 상기 어텐션 생성 함수는 상기 주어진 시간의 1) 상기 어텐션의 로지트 값(logit value)을 나타내는 시간 진화 매트릭스 및 2) 상 기 다변수 시계열 변수를 입력받을 수 있다. 상기 장치는 상기 주어진 시간에서의 다변수 시계열 변수를 입력받아 상기 입력 샘플에 대한 예측을 수행하는 분류 모듈;을 더 포함할 수 있다. 실시예들 중에서, 공진화 신경 상미분 방정식 (Neural Ordinary Differential Equation) 기반의 인공지능 신경 망 방법은 메인 NODE (Neural Ordinary Differential Equation) 모듈을 통해 다운스트림 기계학습 태스크를 제 공하는 단계; 및 어텐션 NODE 모듈을 통해 상기 다운스트림 기계학습 태스크를 수신하고 상기 메인 NODE 모듈에 어텐션을 제공하는 단계;를 포함하고, 상기 메인 NODE 모듈 및 상기 어텐션 NODE 모듈은 시간의 경과에 따라 서 로 영향을 주어 상기 메인 NODE 모듈이 입력 샘플(x)에 대하여 주어진 시간에서의 다변수 시계열 변수 (multivariate time-series value at a given time)을 출력하도록 할 수 있다. 상기 방법은 특징 추출 모듈을 통해 상기 입력 샘플(x)에 대한 특징을 추출하여 초기 시간에서 초기 특징 벡터 를 생성하고, 상기 초기 특징 벡터를 상기 메인 NODE 모듈에 제공하는 단계;를 더 포함할 수 있다. 상기 방법은 초기 어텐션 생성 모듈을 통해 상기 초기 특징 벡터를 입력받아 초기 어텐션을 생성하고 상기 초기 어텐션을 상기 어텐션 NODE 모듈에 제공하여 다음 시간에서의 다변수 시계열 변수의 산출을 지원하는 단계;를 더 포함할 수 있다. 상기 메인 NODE 모듈은 인접한 시간들에 대한 ODE (Ordinary Differential Equation) 함수의 적분을 수행하고, 상기 ODE 함수는 상기 주어진 시간의 1) 다변수 시계열 변수 및 2) 어텐션을 입력받을 수 있다. 상기 방법은 분류 모듈을 통해 상기 주어진 시간에서의 다변수 시계열 변수를 입력받아 상기 입력 샘플에 대한 예측을 수행하는 단계;를 더 포함할 수 있다."}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 기술은 다음의 효과를 가질 수 있다. 다만, 특정 실시예가 다음의 효과를 전부 포함하여야 한다거나 다 음의 효과만을 포함하여야 한다는 의미는 아니므로, 개시된 기술의 권리범위는 이에 의하여 제한되는 것으로 이 해되어서는 아니 될 것이다. 본 발명에 따른 공진화 신경 상미분 방정식 기반의 인공지능 신경망 장치 및 방법은 뉴럴 ODE를 기반으로 머신 러닝 작업을 위한 뉴럴 ODE와 어텐션 제공을 위한 뉴럴 ODE를 구성하여 주의 깊은 이중 공동 진화 NODE를 구현 할 수 있다."}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에 관한 설명은 구조적 내지 기능적 설명을 위한 실시예에 불과하므로, 본 발명의 권리범위는 본문에 설 명된 실시예에 의하여 제한되는 것으로 해석되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가 지 형태를 가질 수 있으므로 본 발명의 권리범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로 이해되어야 한다. 또한, 본 발명에서 제시된 목적 또는 효과는 특정 실시예가 이를 전부 포함하여야 한다거나 그러한 효과만을 포함하여야 한다는 의미는 아니므로, 본 발명의 권리범위는 이에 의하여 제한되는 것으로 이해 되어서는 아니 될 것이다. 한편, 본 출원에서 서술되는 용어의 의미는 다음과 같이 이해되어야 할 것이다. \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로, 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\"있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결될 수 도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\"있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃 하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 것으로 이해되어야 하고, \"포함 하다\"또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 각 단계들에 있어 판별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용되는 것으로 판별부호는 각 단 계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순 서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수 행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 본 발명은 컴퓨터가 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현될 수 있고, 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함 한다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한 이상적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다. 먼저, 뉴럴 ODE(Neural ODE, NODE)에 대해 설명한다. NODE는 다음의 수학식 1과 같이 표현되는 로부터 를 계산하는 적분 문제(integral problem)를 해결 할 수 있다. [수학식 1]"}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기에서, 는 ODE 함수(ODE function)이고, 의 시간 도함수(time-derivative), 즉 에 근사하는 신경망에 해당할 수 있다. 적분 문제를 해결하기 위하여, NODE는 오일러 양해법(explicit Euler method), Dormand-Prince(DOPRI) 방법 등과 같은 기존의 ODE 솔버들을 활용할 수 있다. 일반적으로, ODE 솔버는 시간 변수 를 이산화(discretize)하고 적분을 여러 단계의 덧셈으로 변환할 수 있다. 예를 들어, 오일러 양해법은 특정 단계에서 다음의 수학식 2와 같이 표현될 수 있다. [수학식 2]"}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기에서, 는 일반적으로 1보다 작으며 사전 결정된 오일러 방법의 단계 크기(step size)이다. 상기 수학식 2 는 일 때 잔차 연결과 동일할 수 있다. DOPRI 방법은 로부터 를 업데이트하기 위해 훨씬 더 복잡한 방법을 사용할 수 있고, 동적으로 단계 크기 를 조절할 수 있다. 그러나, 이러한 ODE 솔버들은 예상치 못한 수치적 불안정성(numerical instabilit y)을 제공할 수 있다. 예를 들어, DOPRI 방법은 단계 크기 를 계속 줄임으로써 결과적으로 언더플로우 오류 (underflow error)를 발생시킬 수 있다. 이러한 예상치 못한 문제를 방지하기 위해 몇 가지 방법이 제안되었다. NODE의 한가지 구별되는 특징은 NODE 매개변수들에 관한 손실 기울기(gradient of loss)를 계산할 수 있다는 것 이며, 손실 기울기는 이 태스크 종속적 손실 함수일 때 와 같이 표현될 수 있고 공간 복잡도(space complexity)가 인 역모드 적분(reverse-mode integration)에 의해 산출될 수 있다. 상기의 방법은 인접 민 감도 방법(adjoint sensitivity method)에 해당할 수 있다. 도 5의 그림 (a)는 NODE의 일반적인 아키텍처를 나타낼 수 있다. 해당 아키텍처에서 다운스트림 분류 작업 (downstream classification task)을 가정하면, 상기의 방법에 의해 산출되는 (이때, ) 및 (이때, )를 제공하는 특징 추출 레이어(feature extraction layer)가 존재할 수 있다. 그 다음에 존재하 는 분류 레이어(classification layer)는 입력 에 대한 예측을 출력할 수 있다. 는 적분 문제의 해결 이후 NODE에 의해 생성되는 에서 으로의 매핑 함수 (mapping function)로 정의될 수 있다. 는 위상동형 매핑(homeomorphic mapping)에 해당할 수 있으며, 는연속적(continuous)이고 전단사(bijective)이며 도 모든 에 대해 연속적일 수 있다. 이때, 는 시 간 영역(time domain)의 마지막 시점이다. 해당 특징으로부터 다음과 같은 명제가 도출될 수 있다. 즉, 의 입력 공간의 토폴로지는 출력 공간에 보존되므로 서로 교차하는 궤적(trajectory)은 NODE에 의해 표현될 수 없 다(도 6 참조). NODE는 토폴로지를 유지하면서 머신러닝 작업(machine learning task)을 수행할 수 있으며, 적대적 공격 (adversarial attack)에 대한 표현 학습(representation learning)의 견고성(robustness)을 향상시킬 수 있다. 그러나, 동시에 NODE의 표현 학습 능력은 동일한 이유로 기대만큼 높지 않을 수 있으며, NODE의 동형 매핑 제한 을 극복할 수 있는 방법이 제안되었다. 이때, 해당 방법은 증강된 NODE(augmented NODE)에 해당할 수 있다. 증 강 방법(augmentation method)은 여러 개의 0을 추가하여 을 더 높은 차원의 공간으로 옮길 수 있다. 즉, 과 같이 표현될 수 있고, 여기에서 는 연결(concatenation)이고 0은 특정 차원(certain dimensionality)에서 제로 벡터(zero vector)이다. 이하, 어텐션(attention)에 대해 설명한다. 유용한 정보를 포착하기 위한 어텐션은 딥러닝의 가장 성공적인 개념 중 하나에 해당할 수 있다. 어텐션은 초기 에 자연어 처리 및 컴퓨터 비전에 대해 연구되었으며, 다른 분야로 빠르게 확산되어 왔다. 어텐션 메커니즘은 관련 없는 부분은 무시하고 입력의 선택적인 부분에 초점을 맞추는 인간의 시각적 인식 시스템을 통해 쉽게 설 명될 수 있다. 여기에는 몇 가지 서로 다른 유형의 어텐션과 그 응용이 존재할 수 있다. 그러나, NODE는 신경망 설계의 비교적 새로운 패러다임이고 어텐션을 통합하는 방법이 간단하지 않기 때문에 NODE에 대해 아직 활발히 연구되지 않고 있다. ETN-ODE는 NODE 레이어 이전에 특징 추출 레이어에서 어텐션을 사용할 수 있으며, 내부적으로 어텐션과 결합하는 새로운 NODE 모델을 소개하고 있지 않다. 다시 말해, ETN-ODE 는 특징 추출 레이어에서 을 유도하기 위해 어텐션을 사용한 다음 표준 NODE 레이어를 사용하여 을 진 화시킬 수 있다. ETN-ODE에서 어텐션을 포함하는 레이어는 특징 추출 레이어일 수 있다. 그런 면에서 ETN- NODE가 어텐션 기반의 NODE 모델이라고 말하기에는 충분하지 않을 수 있다. 그러나, NODE에서 는 시간 에서 은닉 벡터(hidden vector)에 해당할 수 있다. 어텐션이 있는 다운스트림 작업을 돕기 위해, 시간 에서 어텐션을 의미하는 를 정의할 수 있다. 그 후, 는 의 도움을 받 아 로부터 도출될 수 있다. 또, 다른 하나는 그들은 서로 독립적이기보다는 자연스럽게 공진화(co- evolve)한다 점일 수 있다. 본 발명에 따른 ACE-NODE(Attentive Co-Evolving Neural Ordinary Differential Equations)는 이러한 개념에 해당할 수 있다. 이하, 도 1 내지 8을 통해 본 발명에 따른 인공지능 신경망 장치 및 방법에 대해 보다 자세히 설명한다. 도 1은 본 발명에 따른 인공지능 신경망 시스템을 설명하는 도면이다. 도 1을 참조하면, 인공지능 신경망 시스템은 본 발명에 따른 공진화 신경 상미분 방정식 기반의 인공지능 신경망 방법을 실행하도록 구현될 수 있다. 이를 위해, 인공지능 신경망 시스템은 사용자 단말, 인공 지능 신경망 장치 및 데이터베이스를 포함할 수 있다. 사용자 단말은 사용자에 의해 운용되는 단말 장치에 해당할 수 있다. 예를 들어, 사용자는 사용자 단말 을 통해 데이터 생성 및 학습에 관한 동작을 처리할 수 있다. 본 발명의 실시예에서 사용자는 하나 이상의 사용자로 이해될 수 있으며, 복수의 사용자들은 하나 이상의 사용자 그룹으로 구분될 수 있다. 또한, 사용자 단말은 인공지능 신경망 시스템을 구성하는 하나의 장치로서 인공지능 신경망 장치 와 연동하여 동작하는 컴퓨팅 장치에 해당할 수 있다. 예를 들어, 사용자 단말은 인공지능 신경망 장 치와 연결되어 동작 가능한 스마트폰, 노트북 또는 컴퓨터로 구현될 수 있으며, 반드시 이에 한정되지 않 고, 태블릿 PC 등 포함하여 다양한 디바이스로도 구현될 수 있다. 또한, 사용자 단말은 인공지능 신경망 장치와 연동하기 위한 전용 프로그램 또는 어플리케이션(또는 앱, app)을 설치하여 실행할 수 있다.인공지능 신경망 장치는 본 발명에 따른 공진화 신경 상미분 방정식 기반의 인공지능 신경망 방법을 수행 하는 컴퓨터 또는 프로그램에 해당하는 서버로 구현될 수 있다. 또한, 인공지능 신경망 장치는 사용자 단 말과 유선 네트워크 또는 블루투스, WiFi, LTE 등과 같은 무선 네트워크로 연결될 수 있고, 네트워크를 통 해 사용자 단말과 데이터를 송·수신할 수 있다. 또한, 인공지능 신경망 장치는 관련 동작을 수행하 기 위하여 독립된 외부 시스템(도 1에 미도시함)과 연결되어 동작하도록 구현될 수 있다. 데이터베이스는 인공지능 신경망 장치의 동작 과정에서 필요한 다양한 정보들을 저장하는 저장장치에 해당할 수 있다. 예를 들어, 데이터베이스는 학습 과정에 사용되는 학습 데이터에 관한 정보를 저장할 수 있고, 학습을 위한 모델이나 학습 알고리즘에 관한 정보를 저장할 수 있으며, 반드시 이에 한정되지 않고, 인공 지능 신경망 장치가 본 발명에 따른 공진화 신경 상미분 방정식 기반의 인공지능 신경망 방법을 수행하는 과정에서 다양한 형태로 수집 또는 가공된 정보들을 저장할 수 있다. 한편, 도 1에서, 데이터베이스는 인공지능 신경망 장치와 독립적인 장치로서 도시되어 있으나, 반드 시 이에 한정되지 않고, 논리적인 저장장치로서 인공지능 신경망 장치에 포함되어 구현될 수 있음은 물론 이다. 도 2는 본 발명에 따른 인공지능 신경망 장치의 시스템 구성을 설명하는 도면이다. 도 2를 참조하면, 인공지능 신경망 장치는 프로세서, 메모리, 사용자 입출력부 및 네트워 크 입출력부를 포함할 수 있다. 프로세서는 본 발명에 따른 공진화 신경 상미분 방정식 기반의 인공지능 신경망 프로시저를 실행할 수 있 고, 이러한 과정에서 읽혀지거나 작성되는 메모리를 관리할 수 있으며, 메모리에 있는 휘발성 메모리 와 비휘발성 메모리 간의 동기화 시간을 스케줄 할 수 있다. 프로세서는 인공지능 신경망 장치의 동 작 전반을 제어할 수 있고, 메모리, 사용자 입출력부 및 네트워크 입출력부와 전기적으로 연결 되어 이들 간의 데이터 흐름을 제어할 수 있다. 프로세서는 인공지능 신경망 장치의 CPU(Central Processing Unit)로 구현될 수 있다. 메모리는 SSD(Solid State Disk) 또는 HDD(Hard Disk Drive)와 같은 비휘발성 메모리로 구현되어 인공지 능 신경망 장치에 필요한 데이터 전반을 저장하는데 사용되는 보조기억장치를 포함할 수 있고, RAM(Random Access Memory)과 같은 휘발성 메모리로 구현된 주기억장치를 포함할 수 있다. 또한, 메모리는 전기적으로 연결된 프로세서에 의해 실행됨으로써 본 발명에 따른 공진화 신경 상미분 방정식 기반의 인공지능 신경망 방법을 실행하는 명령들의 집합을 저장할 수 있다. 사용자 입출력부은 사용자 입력을 수신하기 위한 환경 및 사용자에게 특정 정보를 출력하기 위한 환경을 포함하고, 예를 들어, 터치 패드, 터치 스크린, 화상 키보드 또는 포인팅 장치와 같은 어댑터를 포함하는 입력 장치 및 모니터 또는 터치 스크린과 같은 어댑터를 포함하는 출력장치를 포함할 수 있다. 일 실시예에서, 사용 자 입출력부은 원격 접속을 통해 접속되는 컴퓨팅 장치에 해당할 수 있고, 그러한 경우, 인공지능 신경망 장치는 독립적인 서버로서 수행될 수 있다. 네트워크 입출력부은 네트워크를 통해 사용자 단말과 연결되기 위한 통신 환경을 제공하고, 예를 들 어, LAN(Local Area Network), MAN(Metropolitan Area Network), WAN(Wide Area Network) 및 VAN(Value Added Network) 등의 통신을 위한 어댑터를 포함할 수 있다. 또한, 네트워크 입출력부는 데이터의 무선 전송을 위해 WiFi, 블루투스 등의 근거리 통신 기능이나 4G 이상의 무선 통신 기능을 제공하도록 구현될 수 있다. 도 3은 본 발명에 따른 인공지능 신경망 장치의 기능적 구성을 설명하는 도면이다. 도 3을 참조하면, 인공지능 신경망 장치는 주의 깊은 뉴럴 ODE(attentive neural ODE)를 포함하여 구현될 수 있다. 이를 위한 구성으로서, 인공지능 신경망 장치는 메인 NODE 모듈 및 어텐션 NODE 모듈 을 포함할 수 있다. 메인 NODE 모듈은 다운스트림 기계학습 태스크를 제공하는 동작을 수행할 수 있고, 어 텐션 NODE 모듈은 다운스트림 기계학습 태스크를 수신하여 메인 NODE 모듈에 어텐션을 제공할 수 있 다. 여기에서, 메인 NODE 모듈 및 어텐션 NODE 모듈은 시간의 경과에 따라 서로 영향을 주어 메인 NODE 모듈이 입력 샘플(x)에 대하여 주어진 시간에서의 다변수 시계열 변수(multivariate time-seriesvalue at a given time)을 출력하도록 할 수 있다. 일 실시예에서, 메인 NODE 모듈은 인접한 시간들에 대한 ODE (Ordinary Differential Equation) 함수의 적분을 수행하고, ODE 함수는 주어진 시간의 1) 다변수 시계열 변수 및 2) 어텐션을 입력받을 수 있다. 일 실시예에서, 어텐션 NODE 모듈은 ODE 함수로서, 다변수 시계열 변수와 시간 진화 매트릭스의 시그모이 드 활성화 함수 간의 구성요소 곱 연산(element-wise multiplication)을 수행할 수 있다. 일 실시예에서, 어텐션 NODE 모듈은 인접한 시간들에 대한 어텐션 생성 함수의 적분을 수행하고, 어텐션 생성 함수는 주어진 시간의 1) 어텐션의 로지트 값(logit value)을 나타내는 시간 진화 매트릭스 및 2) 다변수 시계열 변수를 입력받을 수 있다. 일 실시예에서, 인공지능 신경망 장치는 특징 추출 모듈, 초기 어텐션 생성 모듈, 분류 모듈 및 제어 모듈(도 3에 미도시함) 중 적어도 하나를 더 포함할 수 있다. 보다 구체적으로, 특징 추출 모듈 은 입력 샘플(x)에 대한 특징을 추출하여 초기 시간에서 초기 특징 벡터를 생성하고, 초기 특징 벡터를 메 인 NODE 모듈에 제공하는 동작을 수행할 수 있다. 초기 어텐션 생성 모듈은 초기 특징 벡터를 입력받 아 초기 어텐션을 생성하고 초기 어텐션을 어텐션 NODE 모듈에 제공하여 다음 시간에서의 다변수 시계열 변수의 산출을 지원하는 동작을 수행할 수 있다. 또한, 분류 모듈은 주어진 시간에서의 다변수 시계열 변 수를 입력받아 입력 샘플에 대한 예측을 수행하는 동작을 수행할 수 있다. 한편, 도 5를 참조하면, 인공지능 신경망 장치는 ACE-NODE(Attentive Dual Co-Evolving NODE)의 새로운 모델을 구축할 수 있고, 이를 위한 학습 알고리즘을 실행할 수 있다. 도 5의 그림 (b)에서 하나의 NODE는 로 표시된 은닉 벡터의 시간 진화 과정을 설명하기 위한 것이며, 다른 하나는 로 표시된 시간에 따라 진화 하는 어텐션 과정을 위한 것이다. 즉, 해당 모델에서 및 는 다운스트림 머신 러닝 작업(예를들어, 이 미지 분류, 시계열 예측 등)을 수행하기 위해 함께 진화할 수 있다. 도 5에서, 본 발명에 관한 설계는 특징 추출기(feature extractor)와 분류기(classifier)를 포함하는 원래의 NODE 아키텍처에 기초할 수 있다. 일반성을 잃지 않으면서 단순함을 위해 해당 아키텍처에서 분류를 가정할 수 있다. 으로 표시된 초기 어텐션을 생성한 후, 본 발명의 경우 이중 공진화 NODE를 포함할 수 있으며, 이는 원래 설계보다 더 정교할 수 있다. 즉, 결과적으로 이에 관한 학습 알고리즘도 더 복잡해질 수 있다. 본 발명의 경우, 에 의해 생성된 어텐션은 두 가지 유형으로 분류될 수 있다. 즉, i) 페어와이즈(pairwise) 어텐션 및 ii) 엘리먼트와이즈(elementwise) 어텐션이다. 전자는 시계열 예측에서 자주 발생하고 후자는 이미지 분류에서 발생할 수 있다. 이미지 분류의 경우 는 연속 시간 특징 맵(continuous-time feature map)을 의미 할 수 있다. 예를 들어, 도 5의 그림 (a)의 아키텍처를 따르는 ODE-Net은 이미지 컨볼루션 연산을 사용하여 NODE 레이어를 정의할 수 있다. 따라서, 는 모든 에 대한 컨볼루션 피쳐 맵을 의미할 수 있다. 이러한 경 우, 본 발명에 따른 어텐션 NODE 는 엘리먼트와이즈 어텐션을 생성하며, 이는 와 요소별로 곱해질 (elementwise multiplied) 수 있다. 이하, 주의 깊은 뉴럴 ODE에 대해 설명한다. 여기에서는 본 발명에 따른 어텐션의 정의와 공진화 이중 NODE 학습 방법(co-evolving dual NODE training method)을 설명한다. 도 5의 그림 (b)는 본 발명에 따른 일반적인 아키텍처를 도시하고 있다. 초기 어텐션 생성 함수(initial attention generation function) 는 이다. 이후, 본 발명 에 따른 이중 공진화 NODE(dual co-evolving NODE)가 개시될 수 있다. 즉, 와 는 본 발명에 따른 프레 임워크 상에서 시간에 따라 함께 진화할 수 있고, 입력 샘플 에 대한 안정된 은닉 표현(reliable hidden representation) 을 생성하기 위해 상호 간에 영향을 줄 수 있다. 또한, 을 처리하고 에 대한 예측을 생성하는 분류기(classifier)가 존재할 수 있다.일 실시예에서, 본 발명에 따른 페어와이즈 어텐션 정의(pairwise attention definition)는 다음의 수학식 3과 같이 표현되는 공진화 이중 NODEs에 의해 설명될 수 있다. [수학식 3]"}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기에서, 이다. 즉, 는 모든 및 쌍에 대해 의 번째 차원에서 번째 차 원까지의 어텐션의 로지트 값(logit value)을 나타내는 시간 진화 매트릭스이다. 한편, 로지트를 어텐션으로 변 환하기 위해 소프트맥스 활성화(softmax activation)가 사용될 수 있다(하기의 수학식 4 참조). 해당 설정은 다변수 시계열 예측(multivariate time-series forecasting)에서 빈번하게 나타날 수 있으며, 여 기에 는 시간 에서 다변수 시계열의 스냅샷(snapshot)을 나타낼 수 있다. 예를 들어, 도 7은 뉴욕의 세 지 역의 교통 상황을 설명하는 ODE 예제를 나타낼 수 있다. 시간 에서 의 각 요소에는 각 지역의 평균 차량 속도가 포함될 수 있다. 또한, 도 7에서 각 영역이 자신과 인접 영역에 강한 어텐션을 갖는 어텐션 매트릭스가 도시되어 있다. 따라서, 본 발명의 경우 다음의 수학식 4와 같이 의 시작 부분에서 에 어텐션을 적용할 수 있다. [수학식 4]"}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기에서, 는 소프트맥스 활성화이고, “ ”는 전치(transpose)를 나타낸다. 즉, 본 발명의 경우 에 기반 하여 ODE 함수 를 로 재정의할 수 있다. 특히, 일 수 있다. 다른 ODE 함수 또한 로 정의될 수 있다. 및 의 정의는 데이터세트 및 작업마다 상이할 수 있다. 따라서, 여기에서는 일반적인 형태를 설명하고, 이 후 실험 평가 부분에서 특정 디자인에 대해 설명한다. 그러나, 에 대해서는 다른 작업에서 잘 정의된 ODE 함수 를 적용할 수 있다. 예를 들어, GRU-ODE는 GRU(Gated recurrent unit)의 연속적인 일반화(continuous generalization)일 수 있다. GRU-ODE의 저자(author)는 GRU가 시간 종속적인 ODE(time-dependent ODE)에 의해 이론적으로 모델링될 수 있음을 증명하였다. 따라서, 연속 시간 GRU(continuous-time GRU)를 모델링하는 GRU- ODE의 ODE 함수에 본 발명의 ODE 함수 를 적용할 수 있으며, 이에 따라 본 발명의 추가적인 주의 깊은 NODE(attentive NODE)를 포함하는 주의 깊은 GRU-ODE(attentive GRU-ODE)가 될 수 있다. 또한, ODE 함수 도 설계될 필요가 있다. 그러나, 각 작업 또는 각 데이터가 자체적으로 최적화된 어텐션 메커 니즘을 가지고 있음을 발견한 결과, 실험 평가 부분에서 각 작업 또는 각 데이터에 대한 의 특정 설계를 설명 한다. 일 실시예에서, 본 발명에 따른 엘리먼트와이즈 어텐션 정의(elementwise attention definition)는 의 다른 정의를 포함하는 상기의 수학식 3에 의해 설명될 수 있다. 해당 설정은 기존의 합성 곱 신경망(convolution neural network)들에서 빈번하게 나타날 수 있으며, 여기에 는 합성곱 (convolution)에 의해 생성된 피처맵(feature map)을 나타낼 수 있다. 본 발명의 경우, 피처맵에 어텐션을 적용하기 위해 다음의 수학식 5와 같이 표현되는 요소별 곱셈(elementwise multiplication)을 수행할 수 있다. [수학식 5]"}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기에서, 는 에 요소별 어텐션 값(elementwise attention value)이 포함되어 있기 때문에 요소별 곱 셈(elementwise multiplicaton)이다. 이때, 는 시그모이드 활성화(sigmoid activation)이다. 다른 ODE 함수 또한 를 사용할 수 있다. 해당 정의는 물체 감지(object detection), 이미지 분류(image classification) 등과 같이 이미지의 하위 영역 (sub-region)에 집중하는 이미지 프로세싱에서의 어텐션 메커니즘에 대응될 수 있다. 를 사용하면 ODE 함 수 를 로 재정의할 수 있다. 본 발명에 관한 실험에서는 에 대한 다른 작 업에서 잘 정의된 ODE 함수가 적용될 수 있다. 각 작업 또는 각 데이터에는 자체적으로 최적화된 어텐션 설계가 있으므로 실험 평가 부분에서 에 대한 설계를 설명한다. 이하, 본 발명에 따른 학습 알고리즘(training algorithm)을 설명한다. 이중 공진화 NODE를 학습하기 위해서는 정교한 학습 알고리즘이 필요할 수 있다. 여기에서는 본 발명에 따른 모 델을 학습하는 방법을 설명한다. 여러 연구에서 NODE를 학습할 때 수치적 불안정성(예를 들어, 적응적인 단계 크기 ODE 솔버의 언더플로우 오 류)이 나타난다는 점이 보고되었다. 이에 따라, 몇 가지 고급 정형화 개념(NODE의 수치적 안정성 향상에 특화된)이 제안되었다. 즉, i) 운동 에너지 정형화(kinetic energy regularization), ii) 고차 도함수 정형화 (high-order derivative regularization) 및 iii) DOPRI의 단계 크기 정형화이다. 그러나, 이러한 정형화 방법들은 NODE가 에서 까지의 직선 경로(straight line path)를 학습하도록 하며, 이 는 에 적합하지 않을 수 있다. 예를 들어, 도 5의 아키텍처에서 다운스트림 분류 작업에는 오직 만이 필요할 수 있고, 따라서 에 대해 직선을 적용하는 것이 합리적일 수 있다. 그러나, 어텐션의 궤적 (trajectory)은 항상 직선에 해당하지 않을 수 있다. 어텐션 값은 시간에 따라 변동할 수 있으므로 또는 정형화와 같은 기존 정형화 방법이 적용될 수 있다. 에 대한 기존의 NODE 설계를 채택하고 를 추가하여 이중 공진화 NODE로 확장하기 때문에, 에 대한 원래의 설정을 재사용할 수 있다. 이때, 손실 함수는 에 해당할 수 있다. 예를 들어, 는 로 표시되는 작업 특화 손실(task-specific loss) 및 적절한 정형화 항(regularization term)으로 구성될 수 있다. 본 발명 에 관한 실험을 위해 는 수정되지 않고 어텐션 메커니즘을 추가하는 효과를 확인하기 위해 원래의 실험 설정 이 엄격히 적용될 수 있다. 그런 다음 본 발명에 따른 어텐션 메커니즘을 학습하기 위해 다음의 수학식 6과 같 이 표현되는 손실 함수가 적용될 수 있다.[수학식 6]"}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기에서, 는 작업 특화 손실 함수(task-specific loss function)(예를 들어, 교차 엔트로피 손실(cross- entropy loss))이고, 은 정형화 계수(coefficient of regularization)이다. 학습 알고리즘은 도 8에 도시되어 있다. 본 발명의 경우 상기의 손실 함수 및 를 사용하여 두 개의 NODE 를 교대로 학습할 수 있다. 또한, (resp. )를 적용하여 (resp. )를 학습하는 동안 다른 NODE (resp. ())는 고정될 수 있다. 이하, 알고리즘에서 를 제외한 모든 기울기(gradient)를 계산하는 방법을 간단히 설명한다. 본 발명에 따른 학습을 위해, NODE 매개변수 및 에 관한 손실 기울기(gradient of loss)를 산출할 수 있 다. 여기에서는 공간 효율적으로(space-efficiently) 계산하는 방법을 설명한다. 첫째, 가 고정되고 가 상수로 간주될 수 있기 때문에, NODE의 표준 인접 민감도 방법(standard adjoint sensitivity method)을 사용하여 을 학습할 수 있다. 따라서, 에 관한 의 기울기는 다음의 수학식 7에 따라 산출될 수 있다. [수학식 7]"}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기에서, 는 로 정의된 인접 상태(adjoin state)이다. 둘째, 가 를 통해 에 연결되어 있기 때문에 를 학습하는 이전의 경우보다 더 복잡할 수 있다."}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "에 관한 의 기울기는 다음의 수학식 8과 같이 정의될 수 있다. [수학식 8]"}
{"patent_id": "10-2021-0181699", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기에서, 는 로 정의된 인접 상태(adjoint state)이고, 는 로 정의된 또 다른 인접 상태이 다. 코시-코발렙스카야 정리(Cauchy-Kowalevski theorem)에 따르면, 주어진 에 대해, 가 분 석적(또는 지역적으로 Lipschitz 연속적인)인 경우 의 고유한 솔루션이 존재할 수 있다. 즉, ODE 함수가 분석 적일 때 ODE 문제가 잘 제기될 수 있다. 본 발명의 경우, 다른 NODE를 고정한 후 하나의 NODE를 교대로 학습할 수 있다. NODE를 학습할 때, 분석적 ODE 함수에 관한 소정의 조건을 가정할 수 있다. 예를 들어, 본 발명에 따른 실험에서 행렬 곱셈(matrixmultiplication), 행렬 덧셈(matrix addition), 쌍곡선 탄젠트(hyperbolic tangent) 등과 같은 분석 연산자 (analytic operator)로 구성된 에 대해 연속적인 GRU 함수가 적용될 수 있다. 따라서, 연속적인 GRU cell들 에 관한 본 발명에 따른 실험에 있어 Cauchy-Kowalevski 정리가 적용될 수 있다. 그러나, 이미지 분류 실험에서 는 분석적이지 않은 ReLU(Rectified Linear Unit) 활성화를 사용할 수 있다. 그러나, 본 발명에 따른 실험 결과 는 이중 공진화 NODE가 잘 학습될 수 있음을 나타낼 수 있다. 도 4는 본 발명에 따른 공진화 신경 상미분 방정식 기반의 인공지능 신경망 방법을 설명하는 순서도이다. 도 4를 참조하면, 인공지능 신경망 장치는 메인 NODE (Neural Ordinary Differential Equation) 모듈 을 통해 입력 샘플을 수신할 수 있다(단계 S410). 이후, 인공지능 신경망 장치는 메인 NODE (Neural Ordinary Differential Equation) 모듈을 통해 다운스트림 기계학습 태스크를 실행할 수 있으며(단계 S430), 그 결과로서 다변수 시계열 변수를 출력할 수 있다(단계 S450). 이때, 인공지능 신경망 장치는 어텐션 NODE 모듈을 통해 이중 공진화 NODE 프로세스에 따른 어텐션을 메인 NODE 모듈에 제공할 수 있으며, 이에 따라 메인 NODE 모듈과 어텐션 NODE 모듈은 시간의 경과에 따라 상호 영향을 줄 수 있다. 이하, 도 9 내지 12를 참조하여 본 발명에 따른 인공지능 신경망 장치 및 방법에 관한 실험 내용을 설명한다. 구체적으로, 도 9에서 그림 (a)는 MNIST 이미지 분류를 위한 ODE-Net의 네트워크 의 아키텍처를 나타내고, 그 림 (b)는 MNIST 실험 결과들이며, 그림 (c)는 SVHN 실험 결과들이다. 또한, 도 10에서 그림 (a)는 CIFAR10 실 험 결과들이고, 그림 (b)는 이미지 특징 실루엣 점수(Image Feature Silhouette Score)이며, 그림 (c)는 USHCN-DAILY 시계열 예측 실험 결과들이다. 또한, 도 11에서 그림 (a)는 PhysioNet 시계열 분류 결과들이고, 그 림 (b)는 PhysioNet 시계열 회귀 결과들(MSE)이다. 또한, 도 12에서 그림 (a)는 인간 활동 시계열 분류 결과들 이고, 그림 (b)는 모델 크기에 따른 이미지 분류 결과들이며, 그림 (c)는 어텐션 유형에 따른 시계열 분류 결과 들이다. 먼저 여기에서는 이미지 분류 및 시계열 예측 실험을 수행한다. 모든 실험은 다음 소프트웨어 및 하드웨어 환경 에서 수행될 수 있다. 즉, Ubuntu 18.04 LTS, Python 3.6.6, Numpy 1.18.5, Scipy 1.5, Matplotlib 3.3.1, PyTorch 1.2.0, CUDA 10.0 및 NVIDIA Driver 417.22, i9 CPU, 및 NVIDIA RTX 타이탄. 5개의 서로 다른 임의의 시드(seed)를 사용하여 학습 및 테스트 동작을 반복적으로 수행하고 평균 및 표준 편차 정확도를 관찰한다. 실험 1) 이미지 분류(Image Classification) 데이터셋 및 베이스라인(Datasets and Baselines): 여기에서, 벤치마크 데이터셋인 MNIST, SVHN, CIFAR10을 사 용한다. 소정의 평가 프로토콜에 따라 본 발명에 따른 방법(ACEODE-Net)을 ResNet, RKNet, ODE-Net 및 Augmented-ODENet과 비교한다. ResNet에는 6개의 표준 잔차 블록들이 연결되는 다운샘플링 레이어가 적용될 수 있다. RK-Net 및 ODE-Net의 경우 잔차 블록을 NODE 레이어로 대체할 수 있으며, ODE 솔버 선택에 따라 상이할 수 있다. RK-Net은 4차 Runge-Kutta 방법을 사용할 수 있고, ODE-Net은 순방향 패스 추론(forward-pass inference)에 적응적인 Dormand-Prince 방법을 사용할 수 있다. 두 경우 모두 NODE에 관한 표준 역방향 패스 기 울기 계산 방법인 인접 민감도 방법으로 학습될 수 있다. Augmented-ODE-Net의 경우 소정의 증강(Augmentation) 방법이 사용될 수 있다. 따라서, ACE-ODE-Net을 구축하기 위해 ODE-Net의 NODE 레이어를 다른 레이어의 수정없 이 본 발명에 따른 이중 공진화 NODE로 대체할 수 있다. 초매개변수 및 ODE 함수(Hyperparameters and ODE Functions): 방법 및 기타 베이스라인에 대해 다음 하이퍼파 라미터를 테스트한다. RKNet 및 ODE-Net의 경우 ODE 함수 는 도 9의 그림 (a)와 같다. 해당 두 모델에는 어텐션이 없다. Augmented-ODE-Net의 경우 상기에서 설명된 것처럼 5개의 추가 차원으로 ODE-Net의 를 확장한다. ACE-ODE-Net과 Augmented-ODENet 간의 공정한 비교를 위해 ACE-ODE-Net에 대한 증강을 사용하지 않는다. ACE-ODE-Net의 ODE 함수 에 대해 가능한 한 모델을 가볍게 만들기 위해 도 9의 그림 (a)에서 두 번째 레 이어를 제거한다. ACE-ODE-Net의 ODE 함수 에 대해 도 9의 그림 (a)와 동일한 아키텍처를 사용한다. ACE-ODE-Net의 초기 어텐션 생성기 에 대해 유사한 두 개의 컨볼루션 레이어를 적용한다. 전반적으로 본 발명에 따른 모델은 공진화 어텐션을 제외하고는 ODE-Net과 동일하다. 학습률이 {1.0e-3, 5.0e-2, 1.0e-2}이고, 계수 가 {1.0e-3, 1.0e-4}인 배치 크기 128로 160 에포크를 학 습한다. 훈련하는 동안 검증 데이터셋으로 검증한다. 기본 ODE 솔버는 DOPRI이다. 각 데이터셋은 이미지 크기가 다르고, 각 데이터셋의 매개변수 수는 전체 아키텍처가 동일하더라도 다를 수 있다. 즉, 입력 및 출력 크기는 데이터 세트마다 다르다. 실험 결과(Experimental Resuls): MNIST에 대한 도 9의 그림 (b)와 같이, ACEODE-Net은 가장 작은 표준 편차로 최고의 평균 정확도를 보여준다. ODE-Net은 모든 경우에 ResNet을 능가하지 않는다. ODE-Net이 ResNet보다 적은 수의 매개변수를 갖는다는 점을 고려할 때 이는 수용할 수 있다. 그러나 놀랍게도 본 발명에 따른 방법은 훨씬 적은 수의 매개변수(예를 들어, ResNet 0.58M 대 ACE-ODENet 0.28M)로 대부분의 경우 ResNet보다 성능이 뛰어 나다. 이 결과는 NODE에 대한 어텐션 메커니즘의 효율성을 보여준다. RKNet은 높은 표준편차를 고려할 때 다른 방법보 다 신뢰할 수 없는 성능을 보이는 경우가 있다. CIFAR10에서 본 발명에 따른 방법은 ResNet에 이어 두 번째로 높은 정확도를 보여준다. 그러나, ResNet은 매개변수 수 측면에서 본 발명에 따른 모델의 거의 두 배이다. SVHN 에서 본 발명에 따른 방법은 다시 최고의 정확도를 보여준다. 이미지 표현 학습에서 어텐션 메커니즘의 효율성을 분석하기 위해 다양한 방법으로 생성된 은닉 표현(hidden representation)으로 K-Means 클러스터링 알고리즘을 실행하고 실루엣 점수(silhouette score)로 클러스터링 품질을 평가한다. 도 10의 그림 (b)와 같이 본 발명에 따른 방법은 가장 높은 점수를 보여 클러스터링의 품질이 가장 높다는 것을 의미한다. Augmented-ODE-Net은 ODE-Net의 클러스터링 품질을 약간 향상시킨다. 다른 데이터 세트에서도 유사한 패턴이 관찰된다. 실험 2) USHCN 기후 예측(USHCN Climate Forecasting) 데이터셋 및 베이스라인(Datasets and Baselines): 여기에서, 시계열 예측을 위한 최첨단 NODE 모델인 GRU- ODE-Bayes의 실험 환경을 재사용한다. 지역 온도 값이 포함된 USHCN(미국 역사 기후 네트워크) 데이터를 사용한 다. ACE-GRU-ODE-Bayes를 GRU-ODE-Bayes, Augmented-GRU-ODE-Bayes, NODE-VAE, Sequential VAE 및 다양한 GRU 및 LSTM 기반 모델과 비교한다. NODE-VAE는 ODE 함수로서 2-레이어 MLP를 사용한다. Sequential-VAE는 심층 칼만 필터 아키텍처를 기반으로 한다. GRU-Simple, GRU-D 및 TLSTM은 모두 순환 신경망 기반 모델이다. NODE 레이어 를 ACE-GRU-ODE-Bayes로 표시된 이중 공진화 NODE로 교체하여 GRU-ODE-Bayes를 확장한다. 초매개변수 및 ODE 함수(Hyperparameters and ODE Functions): 방법 및 기타 베이스라인에 대해 다음 하이퍼파 라미터를 테스트한다. Augmented-GRU-ODE-Bayes의 경우 상기에서 설명된 것처럼 5개의 추가 차원으로 GRUODE-Bayes의 를 확 장한다. Augmented-GRU-ODE-Bayes와의 공정한 비교를 위해 ACE-GRU-ODE-Bayes에 대한 증강을 사용하지 않다. ACE-GRU-ODE-Bayes의 ODE 함수 및 에 대해 상기의 수학식 3을 통해 ODE로 GRU 셀을 모델링하는 연속적 인 GRU 셀을 사용한다. ACE-GRU-ODE-Bayes의 초기 어텐션 생성기 에 대해 신경망을 사용하지 않고 의 상관 행렬(correlation matirx)을 계산하고 으로 설정한다. 해당 접근 방식은 정확도 향상뿐만 아니라 경량화(lightweightness)를 가져온다. 전체적으로 본 발명에 따른 모델은 공진화하는 어텐션을 제외하고는 GRU-ODE-Bayes와 동일하다. 학습률(learning rate)이 {1.0e-5, 1.0e-4, 1.0e-3}이고 탈락률(dropout rate)이 {0, 0.1, 0.2, 0.3}이며 {0.1, 0.03, 0.01, 0.003, 0.001, 0.0001, 0}의 계수 를 기초로 배치 크기 300을 가진 300 에포크를 학습한다. 훈련하는 동안 5중 교차 검증(5-fold cross validation)을 사용한다. 실험 결과(Experimental Resuls): 모든 결과는 도 10의 그림 (c)에 도시되어 있다. 각 방법을 평가하기 위해 평 균 제곱 오차(MSE)와 음의 로그 가능성(NegLL)을 사용한다. 모든 베이스라인 중에서 GRUODE-Bayes는 두 가지 평 가 지표에서 최고의 성능을 보여준다. 본 발명에 따른 방법은 GRU-ODE-Bayes보다 상당한 성능을 제공하며, 이는 어텐션 메커니즘의 효율성을 보여준다. 실험 3) PhysioNet 사망률 분류(PhysioNet Mortality Classification) 데이터셋 및 베이스라인(Datasets and Baselines): 여기에서는 2012년에 발표된 심장학 챌린지 데이터셋 (cardiology challenge dataset)의 PhysioNet 컴퓨팅이 사용된다. 즉, 중환자실(ICU) 인구의 사망률을 예측하 는 것이다. 데이터셋은 12,000 ICU 입원에서 수집되었으며, 48시간 미만의 단기 체류를 제거하고 최대 42개의 변수를 기록했다. 각 기록에는 ICU에 입원한 후 경과된 시간을 나타내는 타임스탬프가 있다. 실험에서는 기록이 주어지면 환자가 죽을지 여부를 예측한다. 해당 데이터셋의 최신 베이스라인은 다양한 RNN 모델과 NODE 모델이며, 주로 불규칙한 시계열 데이터셋에 특화 된 LatentODE와 비교한다. 초매개변수 및 ODE 함수(Hyperparameters and ODE Functions): 방법 및 기타 베이스라인에 대해 다음 하이퍼파 라미터를 테스트한다. 인코더-디코더(encoder-decoder) 베이스라인에서, 생성 모델(generative model)에서 20개의 잠재 차원, 인 식 모델(recognition model)에서 40개 차원 및 배치 크기 50을 사용한다. 다양한 NODE 기반 베이스라인의 ODE 함수에는 50개의 유닛들(units)을 가진 3개의 완전 연결(FC) 레이어가 있다. 자기회귀 베이스라인 (autoregressive baseline)에서 20차원 은닉 상태를 사용한다. Augmented-Latent-ODE의 경우 상기에서 설명된 것처럼 5개의 추가 차원으로 LatentODE의 를 확장한다. ACE-Latent-ODE와 Augmented-Latent-ODE의 공정한 비교를 위해 ACE-Latent-ODE에 대한 증강을 사용하지 않 는다. ACE-Latent-ODE의 ODE 함수 및 에 대해 50개의 유닛들을 가진 동일한 3개의 완전 연결(FC) 레이어를 사용한다. ACE-ODE-Net의 초기 어텐션 생성기 의 경우 신경망을 사용하지 않고 의 상관 행렬을 계산하여 으 로 설정한다다. 대체로 본 발명에 따른 모델은 공진화 어텐션을 제외하고는 Latent-ODE와 동일하다. 학습률이 {1.0e-5, 1.0e-4, 1.0e-3}이고 계수 가 {0.1, 0.03, 0.01, 0.003, 0.001, 0.0001, 0}인 배치 크기 50으로 30 Epoch 동안 학습한다. 학습하는 동안 검증 데이터 세트로 검증한다. 실험 결과(Experimental Resuls): ACE-Latent-ODE로 표시된 본 발명에 따른 이중 공진화 NODE가 있는 Latent- ODE는 최고의 AUC 점수를 보여준다. 그 다음에는 ODE-RNN과 Latent-ODE가 위치한다. 원래 설정에서 Latent- ODE(ODE Enc.)는 ODE-RNN보다 열등하다. 그러나, 본 발명에 따른 어텐션을 추가한 후에는 본 발명에 따른 어텐 션 메커니즘의 효율성을 보여주는 ODE-RNN보다 성능이 뛰어나다. 실험 4) PhysioNet 사망률 회귀(Mortality Regression) 데이터셋 및 베이스라인(Datasets and Baselines): 여기에서는 회귀 작업(regression task)에 동일한 PhysioNet 데이터 세트를 사용한다. 해당 작업에서 환자의 활력 징후 데이터를 보간(interpolate)하고 외삽 (extrapolate)한다. 여기에서는 각 환자 기록을 훈련, 검증, 보간 테스트 및 외삽 테스트 기간으로 구분한다. 초매개변수 및 ODE 함수(Hyperparameters and ODE Functions): 이전 분류에 사용한 인코더-디코더 아키텍처에 서 디코더를 수정한다. 디코더의 마지막 활성화 레이어는 출력 크기가 42, 즉 센서의 개수인 완전 연결 계층으 로 변경되고 예측할 목표 시점 집합에 따라 NODE 기반 디코더의 적분 문제를 여러 번 해결한다. - 이전 분류에 서는 하나의 시그모이드 활성화만 존재한다. 여기에서는 동일한 하이퍼파라미터 세트를 사용하여 테스트한다. 실험 결과(Experimental Resuls): Augmented-Latent-ODE는 외삽을 위해 Latent-ODE를 약간 개선하고 ACE- Latent ODE는 외삽에 대해 최고의 정확도를 보여준다. 도 10의 그림 (c)에서 외삽 기간 동안 다양한 방법의 MSE 를 표시한다. Latent ODE와 Augmented-Latent-ODE가 상대적으로 더 높은 오류를 나타내는 일부 시점의 경우 ACE-Latent-ODE가 오류를 성공적으로 줄일 수 있다. 실험 5) 인간 활동 분류(Human Activity Classification) 데이터셋 및 베이스라인(Datasets and Baselines): 인간 활동 데이터셋(Human Activity dataset)에는 왼쪽 발 목, 오른쪽 발목, 벨트 및 가슴에 4개의 센서가 있는 5명의 사람이 여러 활동(걷기, 넘어지기, 눕기, 누워서 일 어서기 등)을 수행하는 데이터가 포함되어 있다. 원본 데이터 작성자는 신뢰할 수 있는 데이터를 수집하기 위해 각 동작(performance)에 대해 5번 반복하도록 한다. 여기에서는 사람의 각 시점을 7가지 활동 중 하나로 분류한 다. 해당 데이터셋의 최신 베이스라인은 Latent-ODE이다. 초매개변수 및 ODE 함수(Hyperparameters and ODE Functions): 방법 및 기타 베이스라인에 대해 다음 하이퍼파 라미터를 테스트한다. 인코더-디코더 베이스라인에서 생성 모델에서 15개의 잠재 차원, 인식 모델에서 100개 차원 및 배치 크기 50을 사용한다. 다양한 NODE 기반 베이스라인의 ODE 함수에는 50개의 유닛들이 있는 3개의 완전 연결(FC) 레이 어가 존재한다. 자기회귀 베이스라인에서 15차원 은닉 상태를 사용한다. ACE-Latent-ODE의 ODE 함수 및 에 대해 50개의 유닛들이 있는 동일한 3개의 완전 연결(FC) 레이어를 사용한다. ACE-ODE-Net의 초기 어텐션 생성기 의 경우 신경망을 사용하지 않고 의 상관 행렬을 계산하여 으 로 설정한다. 전반적으로 본 발명에 따른 모델은 공진화 어텐션을 제외하고는 Latent-ODE와 동일하다. 학습률이 {1.0e-5, 1.0e-4, 1.0e-3}이고 계수 가 {0.1, 0.03, 0.01, 0.003, 0.001, 0.0001, 0}인 배치 크기 50으로 70 에포크(Epoch) 동안 학습한다. 학습하는 동안 검증 데이터 세트로 검증한다. 실험 결과(Experimental Resuls): 본 발명에 따른 ACE-Latent-ODE는 Augmented-ODE 및 LatentODE를 포함한 다 른 방법보다 성능이 훨씬 뛰어날 수 있다. 놀랍게도 Augmented-ODE는 때때로 발생하는 Latent-ODE를 개선하지 않을 수 있다. PhysioNet에서 좋은 성능을 보인 ODE-RNN은 해당 데이터셋에서 좋은 정확도를 보여주지 않을 수 있다. 본 발명에 따른 공진화 신경 상미분 방정식 기반의 인공지능 신경망 장치는 은닉 벡터와 어텐션의 교차 진화 과 정(cross-evolutionary process)을 설명하기 위해 이중 공진화 NODE 방법을 구현할 수 있다. 또한, 본 발명에 따른 방법의 효율성을 보여주기 위해 이미지 분류에서 시계열 예측에 이르는 다양한 다운스트림 작업에 대해 다 양한 최신 NODE 모델을 사용하여 심층 실험을 수행하였다. 본 발명에 따른 방법은 기존 NODE 기반 베이스라인보 다 지속적인 성능 향상을 제공할 수 있다. 또한, 페어와이즈 어텐션(pairwise attention)에서 으로 표시된 초기 어텐션을 초기화하는 방법이 중요할 수 있으며, 본 발명에 따른 공진화 신경 상미분 방정식 기반의 인공지 능 신경망 장치는 의 상관 행렬을 사용하는 방법을 구현할 수 있다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2021-0181699", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 인공지능 신경망 시스템을 설명하는 도면이다. 도 2는 본 발명에 따른 인공지능 신경망 장치의 시스템 구성을 설명하는 도면이다. 도 3은 본 발명에 따른 인공지능 신경망 장치의 기능적 구성을 설명하는 도면이다. 도 4는 본 발명에 따른 공진화 신경 상미분 방정식 기반의 인공지능 신경망 방법을 설명하는 순서도이다. 도 5는 본 발명에 따른 아키텍처를 설명하는 도면이다. 도 6은 본 발명에 관한 동형 매핑을 설명하는 도면이다. 도 7은 본 발명에 따른 ODE 상태와 페어와이즈 어텐션의 일 실시예를 설명하는 도면이다. 도 8은 본 발명에 따른 학습 알고리즘을 설명하는 도면이다. 도 9 내지 12는 본 발명에 관한 실험 결과를 설명하는 도면이다."}
