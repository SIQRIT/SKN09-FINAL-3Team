{"patent_id": "10-2020-0092552", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0013235", "출원번호": "10-2020-0092552", "발명의 명칭": "영상 통화 수행 방법, 그 방법을 수행하는 디스플레이 기기, 및 그 방법을 수행하는 프로그램", "출원인": "삼성전자주식회사", "발명자": "이종인"}}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디스플레이; 외부 기기와 통신을 수행하는 통신부; 사용자 입력을 수신하는 사용자 인터페이스; 및 적어도 하나의 인스트럭션을 실행하는 프로세서를 포함하며, 상기 프로세서는 영상 통화 수행을 위하여 획득된 제1 이미지에 포함되는 적어도 하나의 객체를 인식하고, 인식된 적어도 하나의 객체 중 적어도 하나를 선택하는 사용자 입력에 근거하여, 상기 제1 이미지에서 포함되는적어도 하나의 객체 중 선택된 객체를 포함하는 제2 이미지를 획득하고, 상기 제2 이미지가 상대방 기기로 전송되도록 상기 통신부를 제어하는, 디스플레이 기기."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 프로세서는 영상 통화 화면에 포함될 이미지를 상기 상대방 기기로 전송하기 이전에, 상기 제1 이미지에 포함되는 적어도하나의 객체를 각각 선택하기 위한 사용자 인터페이스 화면이 상기 디스플레이를 통하여 출력되도록 제어하는,디스플레이 기기."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 프로세서는 상기 사용자 입력에 의해서 선택된 적어도 하나의 객체를 포함하고 상기 사용자 입력에 의해서 선택되지 않은적어도 하나의 객체는 포함하지 않는 상기 제2 이미지를 획득하는, 디스플레이 기기."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 프로세서는 상기 사용자 입력이 수신된 이후에 상기 제2 이미지의 전송을 개시하는 디스플레이 기기."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 프로세서는 상기 사용자 입력이 수신되기 전까지 영상 통화 화면에 포함될 이미지의 송출을 중단하는, 디스플레이 기기."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 프로세서는 상기 카메라가 갱신된 상기 제1 이미지를 획득할 때, 갱신된 상기 제1 이미지에 새로운 객체가 인식되는지 판단하고, 상기 새로운 객체가 인식되면, 상기 새로운 객체를 선택하기 위한 사용자 인터페이스 화면이 상기 디스플레이를통하여 출력되도록 제어하며, 상기 새로운 객체를 선택하는 사용자 입력에 근거하여, 상기 새로운 객체가 포함되도록 상기 제2 이미지를 갱신하는, 디스플레이 기기. 공개특허 10-2022-0013235-3-청구항 7 제1항에 있어서, 상기 프로세서는 상기 제2 이미지에 포함되는 적어도 하나의 객체 중 상기 사용자 입력에 의하여 선택되지 않은 객체가존재하면, 상기 제1 이미지에서 상기 선택되지 않은 객체를 삭제하여 상기 제2 이미지를 생성하는, 디스플레이기기."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 프로세서는 상기 제1 이미지에 포함되는 적어도 하나의 객체 중 상기 사용자 입력에 의하여 선택되지 않은 객체가존재하면, 상기 제1 이미지에 상기 선택되지 않은 객체에 대응되는 가상 객체가 포함되도록 영상 처리하여 상기제2 이미지를 생성하는, 디스플레이 기기."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 카메라를 더 포함하며, 상기 프로세서는 영상 통화 요청에 응답하여 상기 카메라를 활성화키고, 상기 활성화된 카메라를 통하여 상기 제1 이미지를 획득하는, 디스플레이 기기."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 프로세서는 상기 제1 이미지에 포함되는 적어도 하나의 사람, 공간의 배경, 및 공간 내에 포함되는 사물을 인식하고, 인식된 적어도 하나의 사람, 공간의 배경, 및 공간 내에 포함되는 사물 각각을 선택 또는 해제하기 위한 사용자 인터페이스 화면이 상기 디스플레이를 통하여 출력되도록 제어하는, 디스플레이 기기."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 프로세서는 상기 제1 이미지를 입력받은 신경망이 객체 인식을 위한 연산을 수행하여 제1 이미지에 포함되는 적어도 하나의객체를 추출하여 출력할 때, 상기 신경망에서 출력되는 적어도 하나의 객체를 획득함으로써 상기 객체 인식을수행하는, 디스플레이 기기."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "디스플레이 기기를 통하여 수행되는 영상 통화 수행 방법에 있어서, 영상 통화 수행을 위하여 획득된 제1 이미지에 포함되는 적어도 하나의 객체를 인식하는 단계; 인식된 적어도 하나의 객체 중 적어도 하나를 선택하는 사용자 입력을 수신하는 단계; 상기 사용자 입력에 근거하여, 상기 제1 이미지에서 포함되는 적어도 하나의 객체 중 선택된 객체를 포함하는제2 이미지를 획득하는 단계; 및 상기 제2 이미지가 상대방 기기로 전송하는 단계를 포함하는, 영상 통화 수행 방법."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 영상 통화 화면에 포함될 이미지를 상기 상대방 기기로 전송하기 이전에, 상기 제1 이미지에 포함되는 적어도하나의 객체를 각각 선택하기 위한 사용자 인터페이스 화면을 출력하는 단계를 더 포함하는, 영상 통화 수행 방법. 공개특허 10-2022-0013235-4-청구항 14 제12항에 있어서, 상기 제2 이미지를 획득하는 단계는 상기 사용자 입력에 의해서 선택된 적어도 하나의 객체를 포함하고 상기 사용자 입력에 의해서 선택되지 않은적어도 하나의 객체는 포함하지 않는 상기 제2 이미지를 획득하는 단계를 포함하는, 영상 통화 수행 방법."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서, 상기 전송하는 단계는 상기 사용자 입력이 수신된 이후에, 상기 제2 이미지가 상대방 기기로 전송하기 시작하는 단계를 포함하는, 영상 통화 수행 방법."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 제1 이미지가 갱신되면, 갱신된 상기 제1 이미지에 새로운 객체가 인식되는지 판단하는 단계; 상기 새로운 객체가 인식되면, 상기 새로운 객체를 선택하기 위한 사용자 인터페이스 화면을 출력하는 단계; 및 상기 새로운 객체를 선택하는 사용자 입력에 근거하여, 상기 새로운 객체가 포함되도록 상기 제2 이미지를 갱신하는 단계를 더 포함하는, 영상 통화 수행 방법."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서, 상기 제2 이미지를 획득하는 단계는 상기 제2 이미지에 포함되는 적어도 하나의 객체 중 상기 사용자 입력에 의하여 선택되지 않은 객체가존재하면, 상기 제1 이미지에서 상기 선택되지 않은 객체를 삭제하여 상기 제2 이미지를 생성하는 단계를 포함하는, 영상 통화 수행 방법."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서, 상기 제2 이미지를 획득하는 단계는 상기 제1 이미지에 포함되는 적어도 하나의 객체 중 상기 사용자 입력에 의하여 선택되지 않은 객체가존재하면, 상기 제1 이미지에 상기 선택되지 않은 객체에 대응되는 가상 객체가 포함되도록 영상 처리하여 상기제2 이미지를 생성하는 단계를 포함하는, 영상 통화 수행 방법."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서, 상기 객체를 인식하는 단계는 상기 제1 이미지를 입력받은 신경망이 객체 인식을 위한 연산을 수행하여 제1 이미지에 포함되는 적어도 하나의객체를 추출하여 출력할 때, 상기 신경망의 출력을 수신하는 단계; 및 상기 신경의 출력을 상기 인식된 객체로 획득하는 단계를 포함하는, 영상 통화 수행 방법."}
{"patent_id": "10-2020-0092552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "디스플레이 기기를 통하여 수행되는 영상 통화 수행 방법을 수행하기 위한 적어도 하나의 인스트럭션을 포함하는 프로그램이 기록된 비일시적(non-transitory) 컴퓨터 판독 가능 저장 매체에 있어서,상기 영상 통화 수행 방법은영상 통화 수행을 위하여 획득된 제1 이미지에 포함되는 적어도 하나의 객체를 인식하는 단계; 인식된 적어도 하나의 객체 중 적어도 하나를 선택하는 사용자 입력을 수신하는 단계; 상기 사용자 입력에 근거하여, 상기 제1 이미지에서 포함되는 적어도 하나의 객체 중 선택된 객체를 포함하는제2 이미지를 획득하는 단계; 및 공개특허 10-2022-0013235-5-상기 제2 이미지가 상대방 기기로 전송하는 단계를 포함하는, 저장 매체."}
{"patent_id": "10-2020-0092552", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "개시된 실시예에 따른 디스플레이 기기를 통하여 수행되는 영상 통화 수행 방법은, 영상 통화 수행을 위하여 획 득된 제1 이미지에 포함되는 적어도 하나의 객체를 인식하는 단계; 인식된 적어도 하나의 객체 중 적어도 하나를 선택하는 사용자 입력을 수신하는 단계; 상기 사용자 입력에 근거하여, 상기 제1 이미지에서 포함되는 적어도 하 나의 객체 중 선택된 객체를 포함하는 제2 이미지를 획득하는 단계; 및 상기 제2 이미지가 상대방 기기로 전송하 는 단계를 포함한다."}
{"patent_id": "10-2020-0092552", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 실시예는 영상 통화 수행 방법, 그 방법을 수행하는 디스플레이 기기, 및 그 방법을 수행하는 프로그램 이 저장된 컴퓨터 판독 가능 저장 매체에 대한 것이다."}
{"patent_id": "10-2020-0092552", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "유무선의 통신 네트워크 및 통신 기술이 발달됨에 따라서, 전자 기기 간의 영상 통화 서비스의 이용이 증가하고 있다. 구체적으로, 전자 기기 간의 영상 통화 서비스는, 원격지에 위치하는 서로 다른 사용자들이 비 대면으로 상호 통신하기 위해서 널리 이용되고 있다. 구체적으로, 영상 통화 서비스를 위해서, 일 전자 기기와 다른 전자 기기는 유무선 통신 네트워크를 통하여 상 호 연결될 수 있다. 여기서, 전자 기기는 영상 통화 화면을 제공할 수 있도록 디스플레이를 포함하며 유무선의 통신 네트워크에 접속하여 원격지에 있는 다른 전자 기기와 통신을 수행할 수 있는 모든 전자 기기가 될 수 있 다. 예를 들어, 전자 기기로는, 노트북, 넷북 또는 태블릿 PC 등과 같은 휴대용 컴퓨터, 스마트 폰 또는 PDA와 같은 휴대용 단말기, TV 등을 예로 들 수 있다. 복수개의 전자 기기들, 예를 들어, 제1 전자 기기 및 제2 전자 기기 간의 영상 통화가 수행되는 경우, 제1 전자 기기는 사용자에 대한 이미지를 획득하고, 획득된 이미지를 제2 전자 기기로 전송한다. 그에 따라서, 제2 전자 기기는 제1 전자 기기의 사용자에 대한 이미지를 보면서 통화를 할 수 있다. 또한, 제2 전자 기기는 사용자에 대한 이미지를 획득하고, 획득된 이미지를 제1 전자 기기로 전송한다. 그에 따라서, 제1 전자 기기는 제2 전자 기기의 사용자에 대한 이미지를 보면서 통화를 할 수 있다. 또한, 제1 전자 기기 또는 제2 전자 기기는 복수의 사용자들에 의해서 사용될 수 있다. 이렇게, 복수개의 전자 기기들을 상호 연결하여 영상 통화를 수행하는 경우, 사용자의 만족도 및 편리성을 높이는 방향의 기기 및 방법 을 제공할 필요가 있다. 또한, 전자 기기를 통하여 서비스를 제공하는 경우, 사용자에 대한 개인 정보 또는 프라이버시를 보호하는 방향 으로 전자 기기 및 전자 기기의 동작 방법을 제공할 필요가 있다. 그러므로, 사용자의 만족도 및 편리성을 높이면서도, 사용자의 프라이버시를 사용자의 의도에 맞춰서 보호할 수 있는 전자 기기 및 방법을 제공할 필요가 있다."}
{"patent_id": "10-2020-0092552", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 실시예는, 복수개의 전자 기기들이 상호 연결되어 이용되는 경우, 이를 이용하는 사용자의 프라이버시를 보호할 수 있도록 하는, 영상 통화 수행 방법, 그 방법을 수행하는 디스플레이 기기, 및 그 방법을 수행하는 프 로그램이 저장된 컴퓨터 판독 가능 저장 매체의 제공을 목적으로 한다."}
{"patent_id": "10-2020-0092552", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "개시된 실시예에 따른 디스플레이 기기는 디스플레이; 외부 기기와 통신을 수행하는 통신부; 사용자 입력을 수 신하는 사용자 인터페이스; 및 적어도 하나의 인스트럭션을 실행하는 프로세서를 포함한다. 상기 프로세서는 영 상 통화 수행을 위하여 획득된 제1 이미지에 포함되는 적어도 하나의 객체를 인식하고, 인식된 적어도 하나의 객체 중 적어도 하나를 선택하는 사용자 입력에 근거하여, 상기 제1 이미지에서 포함되는 적어도 하나의 객체 중 선택된 객체를 포함하는 제2 이미지를 획득하고, 상기 제2 이미지가 상대방 기기로 전송되도록 상기 통신부 를 제어한다. 또한, 상기 프로세서는 영상 통화 화면에 포함될 이미지를 상기 상대방 기기로 전송하기 이전에, 상기 제1 이미 지에 포함되는 적어도 하나의 객체를 각각 선택하기 위한 사용자 인터페이스 화면이 상기 디스플레이를 통하여출력되도록 제어할 수 있다. 또한, 상기 프로세서는 상기 사용자 입력이 수신된 이후에 상기 제2 이미지의 전송을 개시할 수 있다. 또한, 상기 프로세서는 상기 사용자 입력이 수신되기 전까지 영상 통화 화면에 포함될 이미지의 송출을 중단할 수 있다. 또한, 상기 프로세서는 상기 카메라가 갱신된 상기 제1 이미지를 획득할 때, 갱신된 상기 제1 이미지에 새로운 객체가 인식되는지 판단하고, 상기 새로운 객체가 인식되면, 상기 새로운 객체를 선택하기 위한 사용자 인터페 이스 화면이 상기 디스플레이를 통하여 출력되도록 제어하며, 상기 새로운 객체를 선택하는 사용자 입력에 근거 하여, 상기 새로운 객체가 포함되도록 상기 제2 이미지를 갱신할 수 있다. 또한, 상기 프로세서는 상기 제2 이미지에 포함되는 적어도 하나의 객체 중 상기 사용자 입력에 의하여 선택되 지 않은 객체가 존재하면, 상기 제1 이미지에서 상기 선택되지 않은 객체를 삭제하여 상기 제2 이미지를 생성할 수 있다. 또한, 상기 프로세서는 상기 제1 이미지에 포함되는 적어도 하나의 객체 중 상기 사용자 입력에 의하여 선택되 지 않은 객체가 존재하면, 상기 제1 이미지에 상기 선택되지 않은 객체에 대응되는 가상 객체가 포함되도록 영 상 처리하여 상기 제2 이미지를 생성할 수 있다. 또한, 개시된 실시예에 따른 디스플레이 기기는 카메라를 더 포함할 수 있다. 그리고, 상기 프로세서는 영상 통 화 요청에 응답하여 상기 카메라를 활성화키고, 상기 활성화된 카메라를 통하여 상기 제1 이미지를 획득할 수 있다. 또한, 상기 프로세서는 상기 제1 이미지에 포함되는 적어도 하나의 사람, 공간의 배경, 및 공간 내에 포함되는 사물을 인식하고, 인식된 적어도 하나의 사람, 공간의 배경, 및 공간 내에 포함되는 사물 각각을 선택 또는 해 제하기 위한 사용자 인터페이스 화면이 상기 디스플레이를 통하여 출력되도록 제어할 수 있다. 또한, 상기 프로세서는 상기 제1 이미지를 입력받은 신경망이 객체 인식을 위한 연산을 수행하여 제1 이미지에 포함되는 적어도 하나의 객체를 추출하여 출력할 때, 상기 신경망에서 출력되는 적어도 하나의 객체를 획득함으 로써 상기 객체 인식을 수행할 수 있다. 개시된 실시예는 디스플레이 기기를 통하여 수행되는 영상 통화 수행 방법이다. 상기 영상 통화 수행 방법은 영 상 통화 수행을 위하여 획득된 제1 이미지에 포함되는 적어도 하나의 객체를 인식하는 단계; 인식된 적어도 하 나의 객체 중 적어도 하나를 선택하는 사용자 입력을 수신하는 단계; 상기 사용자 입력에 근거하여, 상기 제1 이미지에서 포함되는 적어도 하나의 객체 중 선택된 객체를 포함하는 제2 이미지를 획득하는 단계; 및 상기 제2 이미지가 상대방 기기로 전송하는 단계를 포함한다."}
{"patent_id": "10-2020-0092552", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 실시예에 따른 영상 통화 수행 방법, 그 방법을 수행하는 디스플레이 기기, 및 그 방법을 수행하는 프로 그램이 저장된 컴퓨터 판독 가능 저장 매체는 디스플레이 기기의 전면 공간 내에 존재하는 복수의 사용자들 각 각의 의도에 맞춰서 복수의 사용자들 각각에 프라이버시를 보호할 수 있다. 그에 따라서, 디스플레이 기기의 사 용자 만족도를 높일 수 있다."}
{"patent_id": "10-2020-0092552", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 또한, 도면 전체에 있어서, 동일한 구성에 대하여는 동일한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시예에서\" 또는 \"일 실시예에서\" 등의 어구는 반드시 모두 동일한 실시예를 가리키는 것은 아니다. 일부 실시예는 기능적인 박스 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 박스들의 일 부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현될 수 있다. 예를 들어, 본 개시의 기능 박스들은 하나 이상의 프로세서 또는 마이크로프로세서들에 의해 구현되거나, 의도하는 기능을 수행하기 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 박스들은 다양한 프로그래밍 또는 스크립트 언어로 구현될 수 있다. 기능 박스들은 하나 이상의 프로세서 들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데 이터 처리 등을 위하여 종래 기술을 채용할 수 있다. 모듈 및 구성등과 같은 용어는 넓게 사용될 수 있으며, 기 계적이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 'A, B, 및 C 중 적어도 하나'라는 기재는 'A', 'B', 'C', 'A 및 B', 'A 및 C', 'B 및 C', 및 'A, B, 및 C' 중 어느 하나가 될 수 있음을 의미한다. 개시된 실시예는, 영상 통화 수행 방법, 그 방법을 수행하는 디스플레이 기기, 및 그 방법을 수행하는 프로그램 이 저장된 컴퓨터 판독 가능 저장 매체이다. 구체적으로, 개시된 실시예는, 복수개의 전자 기기들 간에 영상 통 화가 수행될 때 사용자의 의도에 맞춰 사용자의 프라이버시를 보호할 수 있도록 하는 영상 통화 수행 방법, 그 방법을 수행하는 디스플레이 기기, 및 그 방법을 수행하는 프로그램이 저장된 컴퓨터 판독 가능 저장 매체에 대 한 것이다. 개시된 실시예에서, 영상 통화를 수행하는 전자 기기는 영상 통화 화면을 디스플레이하는 디스플레이를 포함하 며, 유무선의 통신 네트워크에 접속하여 원격지에 있는 다른 전자 기기와 통신을 수행할 수 있는 모든 전자 기 기가 될 수 있다. 또한, 전자 기기는 디스플레이를 포함하여 영상 통화 서비스를 제공할 수 있는 컴퓨팅 장치로, 매우 다양한 형태로 존재할 수 있다. 예를 들어, 전자 기기는 웨어러블 디바이스, 스마트 폰,PDA(personal digital assistant), 미디어 플레이어, 태블릿 PC, 랩탑 컴퓨터, 미디어 플레이어, TV, 디지털 TV, 스마트 TV, 디지털 간판(digital signage), 디지털 표지판 등을 예로 들 수 있으며, 이에 한정되지 않는다. 이하에서, '모바일 기기' 및 '디스플레이 기기'는 각각 디스플레이로 영상 통화 화면을 디스플레이하여 영상 통 화를 수행할 수 있는 전자 기기가 될 수 있다. 즉, '모바일 기기' 및 '디스플레이 기기'는 각각 웨어러블 디바 이스, 스마트 폰, PDA(personal digital assistant), 미디어 플레이어, 태블릿 PC, 랩탑 컴퓨터, 미디어 플레 이어, TV, 디지털 TV, 스마트 TV, 디지털 간판(digital signage), 디지털 표지판 등이 될 수 있다. 다만, 설명의 편의 상, '모바일 기기' 및 '디스플레이 기기'를 구별하여 기재하였다. 예를 들어, 상대적으로 큰 디스플레이를 포함하거나 상대적으로 넓은 화각으로 영상 통화 화면을 촬영할 수 있는 전자 기기를 '디스플 레이 기기'로 지칭하고, 상대적으로 작은 디스플레이를 포함하거나 상대적으로 좁은 화각으로 영상 통화 화면을 촬영할 수 있는 전자 기기를 '모바일 기기'로 지칭할 수 있다. 이하에서는, 설명의 편의 상 휴대 가능한 형태를 갖는 전자 기기를 '모바일 기기'로 칭하도록 한다. 그리고, 모 바일 기기에 비하여 큰 디스플레이를 통하여 큰 화면을 제공하거나, 모바일 기기에 비하여 넓은 화각으로 영상 통화 화면을 획득할 수 있는 전자기기를, '디스플레이 기기'로 칭할 수 있다. 또한, 모바일 기기는 사용자가 휴대 가능한 형태를 가질 수 있다. 그리고, 디스플레이 기기는 휴대 가능한 형태 를 가질 수도 있고, 고정된 위치에 설치되는 형태를 가질 수 있다. 또는 디스플레이 기기는, 휴대 가능하면서도 고정된 위치에 설치가 가능한 형태를 가질 수 있다. 이하에는 첨부되는 도면들에 있어서, 모바일 기기가 스마트 폰이며 디스플레이 기기가 TV 인 경우를 예로 들어 도시 및 설명하였다. 또한, 첨부된 도면들에 있어서, 동일한 구성 요소는 동일한 도면 기호를 이용하여 도시하 였다. 또한, 상세한 설명 전체적으로, 동일한 구성은 동일한 용어로 기재하였다. 이하에서는, 첨부된 도면들을 참조하며, 개시된 실시예에 따른 영상 통화 수행 방법, 그 방법을 수행하는 디스 플레이 기기, 및 그 방법을 수행하는 프로그램이 저장된 컴퓨터 판독 가능 저장 매체를 상세히 설명하도록 한다. 도 1은 복수개의 전자 기기들 간에 수행되는 영상 통화 서비스를 설명하기 위한 도면이다. 개시된 실시예에서, 영상 통화는 서로 원격지에 위치하는 복수의 사용자들 각각이 복수개의 전자 기기들을 통하 여 화면으로 상대방의 얼굴을 보면서 통화를 하는 것을 의미한다. 또한, 개시된 실시예에서 언급되는 '영상 통 화'는 화상 회의, 비대면 통신, 비대면 교육 등과 같이 원격지에 위치하는 사용자들이 서로에 대한 이미지를 제 공받으면서 통신을 수행하는 모든 분야에 응용될 수 있으며, 서로 원격에 위치하는 복수의 사용자들이 상대방에 대한 이미지를 보면서 통신을 수행하는 경우를 모두 지칭할 수 있다. 여기서, 영상 통화를 통하여 전자 기기에 서 출력되는 이미지는, 꼭 영상 통화를 이용하는 사용자의 얼굴일 필요는 없으며, 영상 통화를 이용하는 사용자 가 위치한 환경을 나타내는 이미지, 또는 사용자가 제공하는 이미지 등이 될 수도 있을 것이다. 일반적으로, 영상 통화는 서로 다른 두 개의 전자 기기 간에 수행될 수 있다. 또는, 상호 원격지에 위치하는 3 명 이상의 사용자들이 3개 이상의 전자 기기를 통하여 영상 통화를 수행할 수 도 있다. 이하에서는, 상호 원격에 위치하는 두 개의 전자 기기를 통하여 일 사용자(이하, '사용자')와 다른 사용자(이하, '상대방')가 영상 통화를 하는 경우를 예로 들어 설명 및 도시하도록 한다. 여기서, 사용자는 1명 의 사람을 지칭하는 것이 아니며 복수가 될 수 있으며, 상대방 또한 복수가 될 수 있다. 도 1을 참조하면, 원격지에 위치하는 전자 기기들인 디스플레이 기기와 상대방 기기 간에 영상 통화 가 수행될 수 있다(S191). 또한, 영상 통화는, 3G, 4G, 또는 5G 등과 같은 통신 네트워크를 이용하여 영상 통화 에 필요한 데이터를 송수신함으로써 수행될 수 있다. 또는, 영상 통화는 통신사의 통화 서비스를 통하여 수행될 수 있다. 또한, 영상 통화는 서비스 제공자의 서버를 통하여 제공되는 소정 어플리케이션(예를 들어, 영상 통화 어플리케이션, 비대면 통신 어프리케이션, 화상 교육 어플리케이션, 화상 회의 어플리케이션 등)을 통하여 수행 될 수 있다. 도 1을 포함하여 이하에서는, 사용자의 전자 기기는 디스플레이 기기이며, 사용자와 영상 통화를 하고자 하는 상대방의 전자 기기를 상대방 기기라 칭하도록 한다. 도 1에서는 상대방 기기가 스마트 폰인 경 우를 예로 들어 도시하였다. 그리고, 디스플레이 기기 및 모바일 기기는 사용자 A2가 소유한 전 자 기기가 될 수 있으며, 상대방 기기는 상대방인 사용자 B가 소유한 전자 기기가 될 수 있다. 도 1을 참조하면, 디스플레이 기기는 원격지에 위치하는 상대방의 전자 기기인 상대방 기기와 영상 통화를 수행할 수 있다(S191). 디스플레이 기기는 자체의 통화 기능 또는 비대면 통신을 위한 어플리케이 션을 수행하여 영상 통화를 수행할 수 있다. 또는, 모바일 기기에서 실행된 영상 통화가 기기 전환을 통하여 디스플레이 기기에서 수행될 수도 있 다. 구체적으로, 모바일 기기와 상대방 기기간에 영상 통화가 수행될 수 있다(S181). 후속하여, 영상 통화의 실행 기기를 모바일 기기에서 디스플레이 기기로 기기 전환 또는 기기 변경할 수 있을 것이다 (S182). 예를 들어, 사용자 A2가 상호 통신 연결이 가능한 복수개의 전자 기기들인 모바일 기기와 디 스플레이 기기을 소유할 수 있다. 그러면, 사용자 A2는 영상 통화를 보다 큰 화면으로 편리하게 이용 하기 위해서, 영상 통화를 실행하는 전자 기기가 모바일 기기에서 디스플레이 기기로 변경 또는 전환 되기를 원할 수 있다. 영상 통화의 실행 기기가 모바일 기기에서 디스플레이 기기로 전환되면, 사용 자 A2는 더 큰 화면을 제공하는 디스플레이 기기의 디스플레이을 통하여 영상 통화 화면을 제공받을 수 있다. 도 1에서는, 영상 통화 화면이 영상 통화의 준비를 알리는 메시지를 포함하는 경우를 예로 들어 도시하였으나, 영상 통화 화면은 모바일 기기에서 출력되는 영상 통화 화면에서와 같 이 상대방인 사용자 B에 대한 이미지를 메인 화면으로 포함하고 사용자A2에 대한 이미지(예를 들어, 113)을 서브 화면으로 포함하는 화면이 될 수 있다. 도 1에서 설명한 바와 같이, 디스플레이 기기를 통하여 영상 통화가 수행되면, 디스플레이 기기에 포 함되는(또는, 디스플레이 기기와 연결되는) 카메라를 통하여 사용자에 대한 이미지를 촬영하게 된다. 구체적으로, 영상 통화가 시작되면, 영상 통화 화면에 포함되는 사용자에 대한 이미지를 획득하기 위해서, 디스 플레이 기기의 카메라는 디스플레이 기기의 전면을 촬영한다. 디스플레이 기기는 모바일 기기에 비하여 큰 화면을 제공할 수 있는 디스플레이가 전면에 배치 되며, 일반적으로 카메라는 디스플레이 기기의 전면의 공간을 전체적으로 촬영한다. 따라서, 디스플 레이 기기의 전면의 공간에 복수의 사람들이 있는 경우, 카메라는 복수의 사람들을 모두 촬영하게 된 다. 예를 들어, 디스플레이 기기의 전면의 공간에 사용자 A1, 사용자 A2 및 사용자 A3이 위치하는 경우, 카메라가 촬영한 이미지에는 사용자 A1, 사용자 A2 및 사용자 A3가 모두 이미징 될 수 있다. 여기서, '이미징'은 촬영 또는 스캔을 통하여 시각적으로 표현 또는 표시되는 것을 의미할 수 있다. 구체적으로, 카메라가 촬영한 이미지에는 사용자 A1, 사용자 A2 및 사용자 A3가 모두 표시될 수 있을 것이다. 카메라에서 촬영되는 이미지는 이하에서 도 2를 참조하여 상세히 설명한다. 도 2는 디스플레이 기기에서 수행되는 영상 통화 서비스를 설명하기 위한 도면이다. 도 2에 있어서, 도 1에서와 동일한 구성은 동일한 도면 기호를 이용하여 도시하였다. 도 2를 참조하면, 개시된 실시예에 따라서 영상 통화를 수행할 수 있는 디스플레이 기기는 가정 내에 위치 할 수 있다. 디스플레이 기기는 카메라를 자체적으로 포함할 수 있다. 또는, 디스플레이 기기가 카메라를 포함하지 않는 경우, 카메라는 디스플레이 기기와 전기적으로 연결될 수 있는 외장 카 메라로 형성될 수 있다. 이하에서는, 카메라가 디스플레이 기기는 포함되는 형태로 구비되는 경 우를 예로 들어 설명하도록 한다. 디스플레이 기기는 모바일 기기에 비하여 큰 크기의 디스플레이(즉, 대화면 디스플레이)를 가지며, 기기의 전체 크기 또한 크다. 또한, 디스플레이 기기에 포함 또는 연결되어 이용되는 카메라는 일반 적으로 모바일 기기에 포함되는 카메라(미도시)에 비하여 큰 화각을 가진다. 따라서, 카메라는 모바일 기기에 포함되는 카메라(미도시)에 비하여 넓은 공간을 촬영할 수 있다. 예를 들어, 모바일 기기는 해당 기기를 손에 들고 있는 사용자 A2의 얼굴과 상체 일체 일부만을 촬영 할 수 있다. 이에 비하여, 카메라는 디스플레이 기기의 전면의 공간을 전체적으로 촬영할 수 있다. 따라서, 디스플레이 기기가 획득하는 이미지는 디스플레이 전면의 공간에 위치하는 복수의 사용자들(116, 117, 118) 및 공간을 전체적으로 나타낼 수 있다. 즉, 디스플레이 기기에서 영상 통화를 수행하기 위해서 카메라가 이미지를 촬영할 경우, 촬영된 이미 지에는 복수의 사용자들(116, 117, 118) 및 공간이 모두 나타날 수 있다. 전술한 바와 같이, 디스플레이 기기의 촬영 공간 내에 여러 명의 사람들이 존재하는 경우, 영상 통화 화면 에 자신이 포함되는 것을 원하지 않는 사람이 존재할 수 있다. 예를 들어, 사용자 A1 은 상대방 기기(도 1 의 102)와 영상 통화를 요청하지 않은 사람으로, 자신의 모습을 상대방 기기(도 1의 102)의 사용자B(도 1의 127)가 보는 것을 원하지 않을 수 있다. 또한, 상대방 기기(도 1의 102)와 영상 통화를 요청한 사용자 A2 는, 자신이 있는 공간을 사용자B(도 1의 127)가 보는 것을 원하지 않을 수 있다. 따라서, 개시된 실시예는, 디스플레이 기기가 배치되는 공간 내에 존재하는 복수의 사용자들 각각의 의도 에 맞춰서 복수의 사용자들 각각에 프라이버시를 보호할 수 있도록 하는 기기 및 방법을 제공한다. 도 3은 개시된 실시예에 따른 디스플레이 기기를 나타내는 일 박스도이다. 도 3에 도시된 디스플레이 기기(30 0)는 도 1 및 도 2에서 도시한 디스플레이 기기에 대응될 수 있다. 따라서, 디스플레이 기기의 동작 들을 설명하는데 있어서, 도 1 내지 도 2에서와 중복되는 설명은 생략한다. 도 3을 참조하면, 디스플레이 기기는 프로세서, 디스플레이, 통신부 및 사용자 인터페이스 를 포함한다. 개시된 실시예에서, 프로세서는 적어도 하나의 인스트럭션을 실행하여, 영상 통화 수행을 위하여 획득된 제1 이미지에 포함되는 적어도 하나의 객체를 인식한다. 그리고, 인식된 적어도 하나의 객체 중 적어도 하나를 선택하는 사용자 입력에 근거하여, 상기 제1 이미지에서 포함되는 적어도 하나의 객체 중 선택된 객체를 포함하 는 제2 이미지를 획득한다. 계속하여, 상기 제2 이미지가 상대방 기기로 전송되도록 상기 통신부를 제어한 다. 개시된 실시예에서, ‘제1 이미지’는 디스플레이 기기가 영상 통화를 위하여 획득된 이미지가 될 수 있다. 구체적으로, 디스플레이 기기가 내부적으로 또는 외부적으로 카메라(예를 들어, 도 2의 105)를 포함 하는 경우, 제1 이미지는 카메라를 통하여 영상 통화 화면에 포함될 사용자에 대한 이미지를 촬영하는 경우, 제 1 이미지는 카메라가 촬영한 이미지의 원본이 될 수 있다. 또는, 제1 이미지는 카메라에서 촬영된 이미지에 포 함되는 객체들이 편집되지 않은 이미지가 될 수 있다. 예를 들어, 디스플레이 기기가 내부적으로 카메라(미도시)를 포함하는 경우, 디스플레이 기기의 프로 세서는 영상 통화가 요청되면, 카메라(미도시)를 활성화시킬 수 있다. 그에 따라서, 카메라(미도시)는 디 스플레이 기기의 전면 공간을 촬영하여 제1 이미지를 획득할 수 있다. 또 다른 예로, 디스플레이 기기가 외장 카메라(미도시)와 연결되어 외장 카메라(미도시)에서 획득되는 제1 이미지를 수신할 수 있다. 구체적으로, 프로세서는 영상 통화가 요청되면, 외장 카메라(미도시)로 활성화 를 요청하는 제어 신호를 송신하고, 외장 카메라(미도시)에서 획득되는 제1 이미지를 통신부를 통하여 수 신할 수 있다. 그리고, ‘제2 이미지’는 제1 이미지에서 표시된 객체들 중 사용자 입력에 의해서 선택된 객체만을 포함(또는, 표시)하도록 생성한 이미지가 될 수 있다. 구체적으로, 디스플레이 기기가 내부적으로 또는 외부적으로 카 메라(예를 들어, 도 2의 105)를 포함하는 경우, ‘제2 이미지’는 카메라에서 획득된 제1 이미지를 편집하여 사 용자 입력에 의해서 선택된 객체만이 표시되도록 처리하여 생성한 이미지가 될 수 있다. 다만, 제1 이미지에 포 함되는 객체들이 사용자 입력에 의하여 모두 선택된 객체들인 경우, 제2 이미지는 제1 이미지와 동일할 수 있다. 구체적으로, 프로세서는 적어도 하나의 인스트럭션을 수행하여, 의도하는 동작이 수행되도록 제어한다. 여 기서, 적어도 하나의 인스트럭션은 프로세서 내에 포함되는 내부 메모리(미도시) 또는 프로세서와 별 도로 디스플레이 기기 내에 포함되는 메모리(미도시)에 저장되어 있을 수 있다. 구체적으로, 프로세서는 적어도 하나의 인스트럭션을 수행하여, 의도하는 동작이 수행되도록 디스플레이 기기 내부에 포함하는 적어도 하나의 구성들을 제어할 수 있다. 따라서, 프로세서가 소정 동작들을 수행하는 경우를 예로 들어 설명하더라도, 프로세서가 소정 동작들이 수행되도록 디스플레이 기기 내 부에 포함하는 적어도 하나의 구성들을 제어하는 것을 의미할 수 있을 것이다. 또한, 디스플레이 기기가 소정 동작을 수행하는 것으로 설명하더라도, 이는 프로세서의 제어에 따라서 수행되는 것을 의미할 수 있 을 것이다. 또한, 프로세서는 하나의 프로세서로 형성되는 경우를 예로 들어 설명 및 도시하였으나, 복수 개의 프로세서들이 포함되는 형태로 형성될 수도 있다. 구체적으로, 프로세서는 디스플레이 기기의 외부에서부터 입력되는 신호 또는 데이터를 저장하거나, 디스플레이 기기에서 수행되는 다양한 작업에 대응되는 저장 영역으로 사용되는 RAM(미도시), 디스플레이기기의 제어를 위한 제어 프로그램 및/또는 복수개의 인스트럭션이 저장된 ROM(미도시) 및 적어도 하나의 프로세서 (Processor)(미도시)를 포함할 수 있다. 프로세서(미도시)는 비디오에 대응되는 그래픽 처리를 위한 그래픽 프로세서(Graphic Processing Unit, 미도시)를 포함할 수 있다. 프로세서(미도시)는 코어(core, 미도 시)와 GPU(미도시)를 통합한 SoC(System On Chip)로 구현될 수 있다. 또한, 프로세서는 싱글 코어 이상의 멀티 코어를 포함할 수 있다. 예를 들어, 프로세서는 듀얼 코어, 트리플 코어, 쿼드 코어, 헥사 코어, 옥 타 코어, 데카 코어, 도데카 코어, 헥사 다시 벌 코어 등을 포함할 수 있다. 개시된 실시예에서, 프로세서는 영상 통화 요청에 응답하여 상대방 기기(예를 들어, 도 1의 102)와의 영상 통화를 수행할 수 있다. 여기서, 영상 통화는 디스플레이 기기 자체의 영상 통화 기능, 또는 영상 통화 서 비스를 제공하기 위한 어플리케이션을 통하여 수행될 수 있다. 예를 들어, 영상 통화 서비스를 제공하기 위한 어플리케이션을 영상 통화 어플리케이션이라 칭할 수 있다. 이 경우, 프로세서는 영상 통화 어플리케이션을 저장하고 있을 수 있다. 영상 통화 어플리케이션은 어플리 케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 기기들(예: 스마트 폰, 및 또는 스마트 TV 등) 각각에 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 제조사의 서버, 어 플리케이션 스토어의 서버, 또는 중계 서버 등을 통하여 배포될 수 있을 것이다. 개시된 실시예에 있어서, 모바일 기기, 상대방 기기 및 디스플레이 기기 중 적어도 두 개에 영 상 통화 어플리케이션을 설치하고, 영상 통화 어플리케이션을 이용하여 설치된 두 개의 기기들 간의 영상 통화 를 수행할 수 있다. 디스플레이는 이미지를 화면 상으로 출력한다. 구체적으로, 디스플레이는 비디오 데이터를 사용자가 시각적으로 인식할 수 있도록, 내부적으로 포함되는 디스플레이 패널(미도시)을 통하여, 비디오 데이터에 대응 되는 이미지를 출력할 수 있다. 개시된 실시예에서, 영상 통화의 수행을 위하여, 디스플레이는 영상 통화 화면을 출력할 수 있다. 통신부는 적어도 하나의 유선 또는 무선 통신 네트워크를 통해서 다른 전자 기기(미도시)와 통신을 수행한 다. 개시된 실시예에서, 통신부는 모바일 기기 및 상대방 기기 중 적어도 하나와 통신한다. 또 한, 통신부는 모바일 기기 및 상대방 기기 중 적어도 하나와 소정 데이터를 송수신하기 위해서 서버(도 3에 미도시 됨)(예를 들어, 도 5에 도시된 서버)와 통신을 수행할 수 있다. 통신부는 유무선의 통신 네트워크를 통하여 외부 기기(예를 들어, 모바일 기기, 상대방 기기 및 서버(미도시) 중 적어도 하나)와 통신할 수 있다. 구체적으로, 통신부는 적어도 하나의 통신 모 듈, 통신 회로 등을 포함하는 형태로 형성될 수 있으며, 통신 모듈 및/또는 통신 회로를 통하여 외부 기기와 데 이터를 송수신할 수 있다. 구체적으로, 통신부는 블루투스, 와이파이, BLE(Bluetooth Low Energy), NFC/RFID, 와이파이 다이렉트 (Wifi Direct), UWB, 또는 ZIGBEE 등의 통신 규격에 따른 통신을 수행하는 적어도 하나의 근거리 통신 모듈(미 도시)를 포함할 수 있다. 여기서, 근거리 통신 모듈(미도시)은 '근거리 통신부(미도시)'로 호칭될 수도 있다. 또한, 통신부는 원거리 통신 규격에 따라서 원거리 통신을 지원하기 위한 서버(미도시)와 통신을 수행하는 원거리 통신 모듈(미도시)를 더 포함할 수 있다. 구체적으로, 통신부는 인터넷 통신을 위한 네트워크를 통 하여 통신을 수행하는 원거리 통신 모듈(미도시)를 포함할 수 있다. 또한, 통신부는 3G, 4G, 및/또는 5G 등의 통신 규격에 따르는 통신 네트워크를 포함할 수 있다. 또한, 원거리 통신 모듈(미도시)는 '원거리 통신부 (미도시)'로 호칭될 수도 있다. 또한, 통신부는 모바일 기기와 유선으로 통신하기 위해서, 모바일 기기와 유선 케이블로 연결되 기 위한 적어도 하나의 포트(미도시)를 포함할 수 있다. 예를 들어, 통신부는 HDMI 포트(미도시) 등과 같 이 케이블 연결 포트를 포함할 수 있다. 사용자 인터페이스는 디스플레이 기기를 제어하기 위한 사용자 입력을 수신할 수 있다. 구체적으로, 사용자 인터페이스는 제1 이미지에 포함되는 적어도 하나의 객체 중 적어도 하나를 선택하기 위한 입력을 수신할 수 있다. 또는, 사용자 인터페이스는 제1 이미지에 포함되는 적어도 하나의 객체 중 적어도 하나를 제외하도록 하는 입력을 수신할 수 있다. 구체적으로, 사용자 인터페이스가 제1 이미지에 포함되는 적어도 하나의 객체 중 적어도 하나를 제외하도 록 하는 입력을 수신하는 경우, 프로세서는 제1 이미지에 포함되는 적어도 하나의 객체 중 사용자 입력에의해서 제외된 객체를 뺀 나머지 객체들은 선택된 것으로 간주될 수 있다. 예를 들어, 제1 이미지에 제1, 제2 및 제3 객체가 포함되고, 사용자 입력에 의해서 제2 객체가 제외된 경우, 제1 및 제3 객체가 사용자에 의해서 선택된 것으로 간주할 수 있다. 사용자 인터페이스는 사용자의 터치를 감지하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용자 의 회전 조작을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch) 등을 포함하는 사용자 입력 디바 이스를 포함할 수 있으나 이에 제한되지 않는다. 또한, 사용자 인터페이스는 음성 인식을 위한 음성 인식 장치(미도시)를 포함할 수 있다. 예를 들어, 음성 인식 장치(미도시)는 마이크가 될 수 있으며, 음성 인식 장치는 사용자의 음성 명령 또는 음성 요청을 수신할 수 있다. 그에 따라서, 프로세서는 음성 명령 또는 음성 요청에 대응되는 동작이 수행되도록 제어할 수 있 다. 또한, 사용자 인터페이스는 모션 감지 센서(미도시)를 포함할 수도 있다. 예를 들어, 모션 감지 센서(미도 시)는 디스플레이 기기의 움직임을 감지하고, 감지된 움직임을 사용자 입력으로 수신할 수 있다. 또한, 전술한 음성 인식 장치(미도시) 및 모션 감지 센서(미도시)는 사용자 인터페이스 내에 포함되는 형태가 아 니라, 사용자 인터페이스와는 독립적인 모듈로 디스플레이 기기 내에 포함될 수 있을 것이다. 또한, 사용자 인터페이스는 원격 제어 기기(remote controller) 등을 통하여 사용자 입력을 수신할 수 있 다. 이 경우, 사용자 인터페이스는 원격 제어 기기(미도시)로부터 사용자 입력에 대응되는 신호를 수신하 기 위한 통신 모듈을 포함할 수 있다. 예를 들어, 원격 제어 기기(미도시)가 사용자 입력에 대응되는 IR 신호를 전송하는 경우, 사용자 인터페이스는 IR 신호를 수신할 수 있는 통신 모듈(미도시)을 포함할 수 있을 것이다. 또한, 디스플레이 기기와 외부의 모바일 기기가 상호 무선 연결되어 있는 경우, 사용자 인터페이스 는 모바일 기기의 터치 패널(미도시)를 통하여 수신되는 사용자 입력을 전송 받을 수 있다. 또는, 모바일 기기의 터치 패널(미도시)를 통하여 수신되는 사용자 입력은 디스플레이 기기의 통신부 를 통하여 수신되어 프로세서로 전달될 수도 있을 것이다. 예를 들어, 디스플레이 기기와 외부 의 모바일 기기가 와이파이 네트워크 또는 블루투스 네트워크를 통하여 상호 무선 연결되어 있는 경우, 모 바일 기기의 터치 패널(미도시)를 통하여 수신되는 사용자 입력은 통신부의 와이파이 통신 모듈(미도 시) 또는 블루투스 통신 모듈(미도시)를 통하여 수신될 수 있다. 도 4는 개시된 실시예에 따른 디스플레이 기기를 나타내는 다른 박스도이다. 도 4에 도시된 디스플레이 기기 는 도 3에 도시된 디스플레이 기기에 동일 대응될 수 있다. 도 4를 참조하면, 디스플레이 기기 는 디스플레이 기기에 비하여, 카메라, 메모리, 및 오디오 입출력부 중 적어도 하나를 더 포함할 수 있다. 카메라는 이미지 센서(미도시)를 포함하여, 영상 통화 모드 또는 촬영 모드에서 이미지 센서를 통해 정지 영상 또는 동영상 등의 영상 프레임을 얻을 수 있다. 개시된 실시예에서, 카메라는 영상 통화 요청의 수신 에 근거하여 활성화 될 수 있다. 그에 따라서, 활성화 된 카메라는 영상 통화를 요청한 사용자에 대한 이 미지를 획득하기 위한 촬영을 수행할 수 있다. 구체적으로, 카메라는 설정된 FPS(Frame per second)에 따라서 소정 시간 간격으로 영상 프레임을 획득할 수 있다. 예를 들어, 카메라는 1초에 30장의 영상 프레임을 획득할 수 있다. 따라서, 카메라에서 획 득되는 제1 이미지는 연속적으로 획득 및 갱신되는 이미지들의 집합 또는 이미지들 각각을 의미할 수 있다. 또한, 디스플레이 기기는 하나의 카메라를 포함할 수 있다. 또한, 디스플레이 기기는 서로 다른 위 치에 배치되는 복수개의 카메라를 포함할 수 있을 것이다. 디스플레이 기기가 복수개의 카메라를 포함하는 경우, 디스플레이 기기는 자체 설정 또는 사용자 입력에 근거하여, 영상 통화를 위하여 사용자는 복수개의 카메라들 중 어느 하나를 선택할 수 있다. 또한, 사용자에 대한 이미지를 획득하기 위한 카메라는 디스플레이 기기 내에 포함되는 형태가 아닌, 디스 플레이 기기와 별도로 구비될 수 있다. 예를 들어, 디스플레이 기기의 전면을 촬영할 수 있도록, 디 스플레이 기기의 일 측면 또는 인접하여 배치되는 외장 카메라(미도시)가 될 수 있다. 이 경우, 외장 카메 라(미도시)와 디스플레이 기기는 유무선의 신호 선을 통하여 연결될 수 있으며, 외장 카메라(미도시)는 디 스플레이 기기의 제어에 따라서 영상 통화의 사용자에 대한 이미지를 획득할 수 있다.이하에서는 설명의 편의 상, 영상 통화를 위하여 사용자에 대한 영상을 획득하기 위한 카메라가 디스플레이 기 기 내에 포함되는 형태로 구비되는 경우를 예로 들어 도시 및 설명하도록 한다. 메모리는 적어도 하나의 인스트럭션을 저장할 수 있다. 또한, 메모리는 프로세서가 실행하는 적 어도 하나의 인스트럭션을 저장하고 있을 수 있다. 또한, 메모리는 프로세서가 실행하는 적어도 하나 의 프로그램을 저장하고 있을 수 있다. 또한, 메모리는 소정 서비스를 제공하기 위한 어플리케이션을 저장 하고 있을 수 있다. 예를 들어, 메모리는 영상 통화 어플리케이션을 저장하고 있을 수 있다. 구체적으로, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티 미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 사용자 인터페이스는 디스플레이 기기를 제어하기 위한 사용자 입력을 수신할 수 있다. 사용자 인터 페이스는 사용자의 터치를 감지하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용자의 회전 조작 을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch) 등을 포함하는 사용자 입력 디바이스를 포함 할 수 있으나 이에 제한되지 않는다. 또한, 사용자 인터페이스는 음성 인식을 위한 음성 인식 장치(미도시)를 포함할 수 있다. 예를 들어, 음성 인식 장치(미도시)는 마이크가 될 수 있으며, 음성 인식 장치는 사용자의 음성 명령 또는 음성 요청을 수신할 수 있다. 그에 따라서, 프로세서는 음성 명령 또는 음성 요청에 대응되는 동작이 수행되도록 제어할 수 있 다. 또한, 사용자 인터페이스는 모션 감지 센서(미도시)를 포함할 수도 있다. 예를 들어, 모션 감지 센서(미도 시)는 디스플레이 기기의 움직임을 감지하고, 감지된 움직임을 사용자 입력으로 수신할 수 있다. 또한, 전술한 음성 인식 장치(미도시) 및 모션 감지 센서(미도시)는 사용자 인터페이스 내에 포함되는 형태가 아 니라, 사용자 인터페이스와는 독립적인 모듈로 디스플레이 기기 내에 포함될 수 있을 것이다. 또한, 사용자 인터페이스는 원격 제어 기기(remote controller) 등을 통하여 사용자 입력을 수신할 수 있 다. 이 경우, 사용자 인터페이스는 원격 제어 기기(미도시)로부터 사용자 입력에 대응되는 신호를 수신하 기 위한 통신 모듈을 포함할 수 있다. 예를 들어, 원격 제어 기기(미도시)가 사용자 입력에 대응되는 IR 신호를 전송하는 경우, 사용자 인터페이스는 IR 신호를 수신할 수 있는 통신 모듈(미도시)을 포함할 수 있을 것이다. 오디오 입출력부는 사용자가 청각적으로 인식할 수 있는 오디오를 출력하거나, 오디오를 감지 및/또는 수 신할 수 있다. 구체적으로, 오디오 입출력부는 오디오 출력부 및 오디오 입력부를 포함할 수 있 다. 오디오 출력부는 프로세서의 제어에 따라서 오디오를 출력한다. 구체적으로, 오디오 출력부는 통신부를 통해 입력되는 오디오(예를 들어, 음성, 사운드)를 출력할 수 있다. 개시된 실시예에서, 프로세서는 영상 통화 모드 동안에 영상 통화의 상대방 기기로부터 수신되는 오 디오가 오디오 출력부를 통하여 출력되도록 제어할 수 있다. 또한, 오디오 출력부는 프로세서의 제어에 의해 메모리에 저장된 오디오를 출력할 수 있다. 오 디오 출력부는 스피커(미도시), 헤드폰 출력 단자(미도시) 또는 S/PDIF(Sony/Philips Digital Interface) 출력 단자(미도시) 중 적어도 하나를 포함할 수 있다. 오디오 출력부는 스피커(미도시), 헤드폰 출력 단자 (미도시) 및 S/PDIF(Sony/Philips Digital Interface) 출력 단자(미도시)의 조합을 포함할 수 있다. 오디오 입력부은 오디오를 수신한다. 구체적으로, 오디오 입력부는 외부의 음향 신호인 오디오를 입 력 받아 전기적인 음성 데이터로 처리하는 마이크(구체적으로, 마이크로폰)(미도시)를 포함할 수 있다. 예를 들 어, 오디오 입력부에 포함되는 마이크(미도시)는 외부기기 또는 화자, 예를 들어, 영상 통화 중인 사용자 로부터 음향 신호를 수신할 수 있다. 또한, 오디오 입력부에 포함되는 마이크(미도시)는 외부의 음향 신호 를 입력 받는 과정에서 발생 되는 잡음(noise)를 제거하기 위한 다양한 잡음 제거 알고리즘을 이용할 수 있다. 개시된 실시예에서, 프로세서의 제어에 따라서 오디오 입력부은 영상 통화 모드 동안에, 사용자의 음 성을 포함하는 음향 신호를 수신하고, 수신된 음향 신호에서 잡음을 제거하여 사용자의 음성이 인식되도록 처리 할 수 있다. 도 5는 개시된 실시예에 따른 영상 통화 서비스를 수행하기 위해서 이용되는 복수개의 전자 기기들을 설명하기 위한 도면이다. 도 5에 도시된 구성들에 있어서, 도 1 내지 도 4와 동일한 구성은 동일한 도면 기호를 이용하여 도시하였다. 또한, 도 5에 도시된 디스플레이 기기는 도 1 내지 도 3에 도시된 디스플레이 기기(103, 또는 300)에 동일 대응될 수 있다. 도 5를 참조하면, 서버는 모바일 기기, 상대방 기기 및 디스플레이 기기와 무선 통신 네트 워크를 통하여 상호 통신할 수 있다. 예를 들어, 서버는 영상 통화 또는 영상 통화 서비스를 제공하거나, 영상 통화 서비스에 필요한 통신을 지 원하는 서버가 될 수 있다. 예를 들어, 모바일 기기, 상대방 기기 및 디스플레이 기기 중 적어 도 두 개의 기기가 3G, 4G, 5G 등과 같은 이동 통신 네트워크를 통하여 연결되며, 모바일 기기 또는 디스 플레이 기기와 상대방 기기 간에 영상 통화를 수행할 수 있다. 이 경우, 서버는 3G, 4G, 5G 등 과 같은 통신 규격에 따른 이통 통신을 지원하는 통신 서버가 될 수 있다. 또한, 모바일 기기, 상대방 기기 및 디스플레이 기기가 인터넷 통신 네트워크로 연결될 수 있다. 그리고, 모바일 기기, 상대방 기기 및 디스플레이 기기 중 적어도 두 개의 기기 각각이, 기기 내의 영상 통화 서비스를 제공하는 어플리케이션을 통하여, 영상 통화를 수행할 수 있다. 그러면, 모바일 기기, 상대방 기기 및 디스플레이 기기 상호간은 상기 어플리케이션을 통하여 영상 통화 및/또 는 기기 전환에 따른 영상 통화를 수행할 수 있을 것이다. 이 경우, 서버는 상기 어플리케이션을 지원하는 서버가 될 수 있을 것이다. 구체적으로, 서버는 어플레케이션을 제작 및/또는 배포하는 사용자의 서버가 될 수 있다. 전술한 바와 같이, 서버의 통신 중계를 이용하여, 전술한 영상 통화 수행 방법의 동작들이 수행될 수 있다. 도 3에서는 서버의 통신 중계 동작이 도시되지 않았으나, 서로 다른 두 기기들 간의 데이터 또는 신 호를 송수신하는데 있어서, 전술한 서버의 통신 중계 동작이 포함될 수 있다. 구체적으로, 서버는 영 상 통화 서비스의 실행(또는, 전환 실행)을 지원하기 위해서, 데이터 또는 신호의 전달을 담당할 수 있다. 예를 들어, 서버는 디스플레이 기기에서 생성된 제2 이미지를 상대방 기기로 전송하는 중계 동작을 수행할 수 있다. 또한, 서버는 영상 통화 서비스를 수행하기 위해서 이용되는 각종 데이터 및 신호를 모바 일 기기, 상대방 기기 및 디스플레이 기기 중 적어도 하나로 전송 또는 전달할 수 있다. 이하의 설명에 있어서, 일 기기(예를 들어, 디스플레이 기기)에서 다른 기기(예를 들어, 상대방 기기)로 소정 데이터 또는 신호를 전송하였다고 기재하더라도, 이는 일 기기(예를 들어, 디스플레이 기기)에서 다른 기기(예 를 들어, 상대방 기기)로 소정 데이터 또는 신호를 직접 전송되는 경우뿐만 아니라, 서버의 통신 중계를 통하여 일 기기(예를 들어, 디스플레이 기기)에서 다른 기기(예를 들어, 상대방 기기)로 소정 데이터 또는 신호 를 전송되는 것을 포함한다고 할 것이다. 이하에서는, 도 6 내지 도 16을 참조하여, 개시된 실시예에 따른 디스플레이 기기(103, 300 또는 400)를 통하여 수행되는 동작들을 상세하게 설명하도록 한다. 도 6은 개시된 실시예에 따른 영상 통화 수행 방법을 나타내는 일 흐름도이다. 도 6을 참조하면, 영상 통화 수 행 방법은 개시된 실시예에 따른 디스플레이 기기, 예를 들어, 디스플레이 기기(103, 300 또는 400)를 통 하여 수행되는 영상 통화 수행 방법을 도시한다. 또한, 개시된 실시예에 따른 디스플레이 기기(103, 300 또는 400)에서 수행되는 동작들을 나타내는 흐름도가 될 수 있다. 그러므로, 개시된 실시예에 따른 영상 통화 수행 방법에 포함되는 동작들에 있어서, 전술한 디스플레이 기기(103, 300 또는 400)의 동작들과 중복되는 설명 은 생략한다. 이하에서는, 영상 통화 수행 방법이 도 4에서 설명한 디스플레이 기기를 통하여 수행되는 경우를 예 로 들어 설명하도록 하겠다. 도 6을 참조하면, 영상 통화 수행 방법은 영상 통화 수행을 위하여 획득된 제1 이미지에 포함되는 적어도 하나의 객체를 인식한다(S610). S610 단계는 프로세서에서 수행될 수 있다. 객체 인식 동작은 이하에서 도 7을 참조하여 상세히 설명한다. 그리고, 영상 통화 수행 방법은 S610 단계에서 인식된 적어도 하나의 객체 중 적어도 하나를 선택하는 사 용자 입력을 수신한다(S620). S620 단계는 사용자 인터페이스에서 사용자 입력을 수신하여 수행될 수 있다. 또는, S620 단계는 통신부에서 사용자 입력을 수신하여 수행될 수 있다. 여기서, 사용자 입력은 S610 단계에서 인식된 적어도 하나의 객체들 각각에 대한 선택 여부를 나타내는 사용자 의 의사가 반영되는 신호가 될 수 있다. 구체적으로, 사용자 입력은 사용자 인터페이스 화면에 대응하여 수신될 수 있다. 사용자 인터페이스 화면에 대응하여 수신되는 사용자 입력의 예들은 이하에서 도 8 내지 도 10을 참조 하여 상세히 설명한다. 또한, 사용자 입력은 제1 이미지 내에 표시된 사용자들 각각의 제스처(gesture) 인식에 대응되어 수신될 수 있 다. 예를 들어, 디스플레이 기기는 카메라에서 촬영되는 이미지에 근거하여 제스처 인식을 수행할 수 있다. 예를 들어, 카메라가 사용자 A1, 사용자 A2 및 사용자 A3를 촬영할 경우, 사용자 A1은 팔로 ‘X’ 형태를 표시하고, 사용자 A2 및 사용자 A3는 팔로 ‘O’ 형태를 표시하는 경우, 프로세서는 카메라에서 촬영된 이미지에 근거하여 제스처 인식을 할 수 있다. 그리고, 제스처 인식 결과에 근거하여, 프로세서는 사용자 A1는 선택되고, 사용자 A2 및 사용자 A3는 선택 되지 않은 것을 않은 것으로 판단할 수 있다. 또한, 사용자 입력은 제1 이미지 내에 표시된 사용자들 각각의 음성 인식에 대응되어 수신될 수 있다. 예를 들 어, 디스플레이 기기의 오디오 입력부에서 수신되는 음성 신호에 근거하여, 프로세서는 음성 인 식을 수행할 수 있다. 그리고, 음성 인식 결과에 근거하여 제1 이미지 내에 표시된 사용자들 각각에 대한 선택 또는 미선택을 판단할 수 있을 것이다. 계속하여, 영상 통화 수행 방법은 S620 단계에서 수신된 사용자 입력에 근거하여, 상기 제1 이미지에서 포 함되는 적어도 하나의 객체 중 선택된 객체를 포함하는 제2 이미지를 획득한다(S630). S630 단계는 프로세서 에서 수행될 수 있다. 제2 이미지의 획득 동작은 이하에서 도 11 내지 도 13을 참조하여 상세히 설명한다. 그리고, 영상 통화 수행 방법은 S630 단계에서 획득된 제2 이미지가 상대방 기기로 전송되도록 제어 한다(S640). S640 단계는 프로세서의 제어에 따라서 통신부에서 수행될 수 있다. 개시된 실시예에 따른 영상 통화 수행 방법은 이하에서 도 7 내지 도 16을 참조하여, 더욱 상세하게 설명 하도록 하겠다. 또한, 도 7 내지 도 16을 설명하는데 있어서, 도 4에 도시한 디스플레이 기기를 참조하여 설명하도록 한다. 또한, 도 7 내지 도 16에 있어서, 도 1 내지 도 6에 도시된 구성과 동일한 구성은 동일한 도 면 기호로 표시하였다. 그러므로, 상호 중복되는 설명은 생략한다. 도 7은 개시된 실시예에 따른 객체 인식 동작을 설명하기 위한 도면이다. 구체적으로, 도 7은 제1 이미지 의 일 예를 도시한다. 도 7을 참조하면, 프로세서의 제어에 따라서 활성화된 카메라는 디스플레이 기기의 전면의 공간 을 촬영하여 제1 이미지를 획득할 수 있다. 제1 이미지은 사용자 A1, 사용자 A2 및 사용자 A3을 포함하여 디스플레이 기기의 전 면의 공간을 전체적으로 이미징할 수 있다. 카메라는 일반적으로 디스플레이 기기의 전면의 공간을 전체적으로 촬영할 수 있도록, 모바일 기기 에 비하여 넓은 화각을 가진다. 또한, 카메라가 줌(zoom) 기능을 가지는 경우, 카메라의 렌즈가 촬영의 대상을 확대하여 촬영하거나 촬영 대상을 축소하여 촬영할 수 있을 것이다. 예를 들어, 카메라의 렌즈가 촬영 대상을 축소하도록 설정된 경우, 카메라에서 획득된 제1 이미지는 더 넓은 공간을 이미징할 수 있을 것이다. 도 7에서는, 카메라가 사용자 A1, 사용자 A2 및 사용자 A3의 상반신 정도 를 촬영하여 제1 이미지를 획득한 경우를 경우를 예로 들어 도시하였다. S610 단계에 있어서, 프로세서는 제1 이미지에 포함되는 객체를 인식할 수 있다. 구체적으로, 프로세 서는 제1 이미지에 포함되는 적어도 하나의 객체를 인식할 수 있다. 제1 이미지에서 인식되는 객체는 제1 이미지에 포함되는 적어도 하나의 사람, 적어도 하나의 사물, 및 배경이 될 수 있을 것이다. 여기서, 사람은 사람의 개별적으로 식별 가능한 얼굴이 될 수 있다. 또한, 사물은 제1 이미지 내에서 식별 가능한 가구, 물건, 동물 등이 될 수 있다. 또한, 배경은 제1 이미지가 나타내는 공간을 나타내는 환경을 나타낼 수 있다. 구체적으로, 객체 인식은 얼굴 감지(face detection) 기법, 보행자 감지(pedestrian detection), 얼굴 인식 (face recognition) 등과 같이, 객체를 개별적으로 구별하여 인식할 수 있는 다양한 기법들에 의해서 수행될 수 있다. 또한, 객체 인식을 위하여 딥 러닝(deep learning) 에 따른 객체 인식 기법이 이용될 수 있다. 구체적으로, 신 경망(neural network)을 통한 연산을 수행하는 인공지능(AI: Artificial Intelligence) 기술을 이용하여, 객체 인식, 객체 추적 및 객체 구별 등을 수행하는 방법이 개발 및 이용되고 있다. 이하에서는 설명의 편의 상, 이미 지를 분석하여 객체 인식, 객체 추적 및 객체 구별 등을 수행하는 동작들을 ‘객체 인식’ 이라 통칭하도록 한 다. 구체적으로, 인공 지능 기술은 신경망(Neural Network)을 통한 연산을 수행하여 입력된 이미지 또는 데이터를 분석하여 목적하는 결과를 획득하는 기술이다. 여기서, 신경망은 학습 데이터(예를 들어, 서로 다른 복수의 이 미지들)를 학습(training)하여 신경망 내부의 가중치 값들을 최적화하여 설정할 수 있다. 그리고, 최적화된 가 중치 값을 가지는 신경망을 통하여, 입력된 데이터를 스스로 학습(learning)함으로써, 목적하는 결과를 출력한 다. 구체적으로, 신경망은 심층 신경망(DNN: Deep Neural Network)이 될 수 있다. 또한, 심층 신경망(DNN) 연산은 컨볼루션 신경망(CNN: Convolution Neural Network) 연산 등을 포함할 수 있다. 구체적으로, 예시된 신경망을 통하여 객체 인식을 위한 데이터 인식 모델을 구현하고, 구현된 인식 모델을 학습 데이터를 이용하여 학습 (training)시킬 수 있다. 그리고, 학습된 데이터 인식 모델을 이용하여 입력되는 데이터, 예를 들어, 카메라에 서 촬영된 이미지들을 분석 또는 분류하여, 입력된 이미지들 각각에서 객체를 인식하고 인식된 객체를 출력 데 이터로써 출력할 수 있다. 또한, 컨볼루션 신경망(CNN)은 이미지를 분석하여 패턴을 찾는 알고리즘을 수행하는 신경망을 모두 지칭하는 것으로, 다양한 종류들의 신경망들이 존재할 수 있다. 즉, 개시된 실시예에서, 신경망은 이미지를 입력받고 이미지 내의 객체를 추출하도록 학습된 신경망이 될 수 있 다. 개시된 실시예에서, 객체 인식을 위한 신경망은 프로세서 내에 구현될 수 있다. 이 경우, 프로세서는 신경망(미도시)으로 제1 이미지을 입력하면, 신경망(미도시)는 제1 이미지를 분석하여 포함되는 객체 들인 사용자 A1, 사용자 A2 및 사용자 A3 각각을 분리 및 추출할 수 있다. 신경망(미도시)에서 출력된 결과인 제1 이미지내에서 인식된 객체들은 710, 720, 730 박스와 같이 표시될 수 있다. 즉, 신경망(미도시)는 제1 이미지내에서 인식된 서로 다른 얼굴들을 인식하고, 인식된 서로 다른 얼굴들을 710, 720, 730 박스와 같이 구별하여 출력할 수 있을 것이다. 또한, 신경망(미도시)는 디스플레이 기기의 외부의 서버 또는 외부 기기에 구현될 수 있다. 이 경우, 디스 플레이 기기는 외부의 서버 또는 외부 기기에 구현된 신경망(미도시)로 제1 이미지를 전송하고, 신경 망(미도시)에서 출력되는 결과를 통신부를 통하여 수신할 수 있다. 도 8은 개시된 실시예에 따른 영상 통화 수행 방법을 나타내는 다른 흐름도이다. 도 8에 있어서, 도 6에 도시된 동작들과 동일한 동작은 동일한 도면기호를 이용하여 도시하였으므로, 상세 설명은 생략한다. 또한, 영상 통화 수행 방법이 도 4에서 설명한 디스플레이 기기를 통하여 수행되는 경우를 예로 들어 설명하도록 하겠 다. 도 8을 참조하면, 영상 통화 수행 방법은 영상 통화 수행 방법에 비하여 S615 단계를 더 포함할 수 있다. 영상 통화 수행 방법은 S610 단계에 후속하여, 제1 이미지에 포함되는 적어도 하나의 객체를 각각 선 택하기 위한 사용자 인터페이스 화면을 출력하는 단계(S615)를 더 포함할 수 있다. 여기서, S615 단계는 프로세 서의 제어에 따라서 디스플레이가 사용자 인터페이스 화면을 디스플레이 함으로써 수행될 수 있다. S615 단계에서 출력되는 사용자 인터페이스 화면은 이하에서 도 9 및 도 10을 참조하여 상세히 설명한다. 도 9는 개시된 실시예에서 출력되는 사용자 인터페이스 화면을 일 예를 나타내는 도면이다. 도 9를 참조하면, S615 단계에서 출력되는 사용자 인터페이스 화면의 일 예가 도시된다. 예를 들어, 사용 자 인터페이스 화면은 도 7에서 도시한 제1 이미지를 포함하며, 제1 이미지에서 인식된 적어도 하나의 객체를 개별적으로 선택하기 위해서 사용자 인터페이스 메뉴를 포함할 수 있다. 예를 들어, 사용자 인터페이스 화면은 제1 이미지에서 인식된 적어도 하나의 객체를 제시하는 표시 (예를 들어, 710, 720, 730 박스 표시 등) 및 적어도 하나의 객체를 개별적으로 선택하기 위한 포인터를 포함할 수 있다. 디스플레이 기기의 사용자는 포인터를 이용하여, 제1 이미지에서 인식된 적어도 하나의 객체인 사용자 A1, 사용자 A2 및 사용자 A3 각각을 선택 또는 해제 할 수 있다. 여기서, 해제는 선택하 지 않는 것을 의미한다. 구체적으로, 사용자는 영상 통화 화면에 포함시키고 싶지 않은 객체에 대하여 해당 객 체를 해제(또는, 비선택)할 수 있다. 또한, 디스플레이 기기의 사용자는 영상 통화를 요청한 사람, 또는 디스플레이 기기의 적법한 이용 권한을 가진 사람(예를 들어, 디스플레이 기기의 소유자 등)이 될 수 있으며, 객체인 사용자 A1, 사 용자 A2 및 사용자 A3 중 적어도 한 명이 될 수 있다. 도 9를 참조하면, 디스플레이 기기의 사용자는 포인터를 조작하여, 객체인 사용자 A1, 사용자 A2 및 사용자 A3 각각을 선택하거나 선택하지 않을 수 있다. 또한, 선택 동작 또는 해제 동작은 설정 된 방식으로 이뤄질 수 있다. 예를 들어, 사용자가 포인터를 조작하여 선택하고자 하는 객체를 나타내는 박스 내의 일 지점을 더블 클릭하거나, 소정 시간 이상 포인팅 하면, 프로세서는 해당 객체(예를 들어, 박스에 대응되는 사용자 A1)는 선택된 것으로 인식할 수 있다. 또 다른 예로, 사용자가 포인터를 조작하여 선택하고자 하는 객체를 나타내는 박스 내의 일 지점에서 박스 외의 지점으로 포인터를 경로에 따라서 이동시키면, 해당 객체(예를 들어, 박스에 대 응되는 사용자 A1)는 해제된 것으로(또는, 선택되지 않은 것으로) 인식할 수 있다. 또 다른 예로, 사용자가 포인터를 조작하여 박스 내의 일 지점을 1회 클릭하면, 프로세서는 해 당 객체(예를 들어, 박스에 대응되는 사용자 A1)는 선택된 것으로 인식하고, 사용자가 포인터를 조작하여 박스 내의 일 지점을 1회 클릭하면, 프로세서는 해당 객체(예를 들어, 박스에 대응되 는 사용자 A1)는 선택되지 않은 것으로 인식할 수 있다. 또 다른 예로, 사용자가 포인터를 조작하여 선택하자 하는 객체에 대응하는 박스만을 포인터로 클릭 할 수 있다. 이 경우, 프로세서는 포인터에 의해서 클릭된 박스에 대한 객체(예를 들어, 박스에 대응되는 사용자 A1)는 선택된 것으로 인식하고, 포인터에 의해서 클릭되지 않은 박스에 대한 객체는 선택되지 않은 것으로 인식할 수 있다. 또 다른 예로, 사용자 인터페이스 화면이 출력된 후, 소정 시간(예를 들어, 10초 등) 동안에 객체 선택을 위한 사용자 입력이 수신되지 않은 경우, 프로세서는 사용자 인터페이스 화면 내에 제시된 모든 객체 들(구체적으로, 610 단계에서 인식된 적어도 하나의 객체들)이 모두 선택된 것으로 판단할 수 있다. 또한, 사용자는 영상 통화를 수행하는 공간이 어디인지를 상대방이 모르는 것을 원할 수 있다. 이러한 경우, 사 용자는 포인터를 조작하여 배경이 되는 부분을 해제할 수 있을 것이다. 예를 들어, 사용자에 의해서 배경 이 선택되지 않은 경우(즉, 해제 된 경우) 프로세서는 배경을 블러링 처리하거나 모자이크 처리하거나 배 경을 모두 지우거나 하는 영상 처리를 통하여, 제1 이미지에서 촬영된 배경을 알 수 없도록 처리하여 제2 이미지를 생성할 수 있을 것이다. 도 10은 개시된 실시예에서 출력되는 사용자 인터페이스 화면을 다른 예를 나타내는 도면이다. 도 10을 참조하 면, S615 단계에서 출력되는 사용자 인터페이스 화면의 다른 예가 도시된다. 예를 들어, 사용자 인터페이스 화면은 도 7에서 도시한 제1 이미지를 포함하며, 제1 이미지에 서 인식된 적어도 하나의 객체를 개별적으로 선택하기 위해서 선택 메뉴(예를 들어, 1011) 및 해제 메뉴(예를 들어, 1012) 중 적어도 하나를 포함할 수 있다. 디스플레이 기기의 사용자는 포인터를 이용하여 선택 메뉴(예를 들어, 1011) 및 해제 메뉴(예를 들어, 1012)를 클릭함으로써, 제1 이미지에서 인식된 적어도 하나의 객체인 사용자 A1, 사용자 A2 및 사용자 A3 각각을 선택 또는 해제 할 수 있다. 도 9 내지 도 10에서 도시된 예시 이외에도, 인식된 적어도 하나의 객체를 개별적으로 선택하기 위한 사용자 인 터페이스 화면은 다양한 형태로 변형 또는 생성될 수 있을 것이다. 개시된 실시예에서, 프로세서는 사용자 입력에 의해서 선택된 적어도 하나의 객체를 포함하고 사용자 입력 에 의해서 선택되지 않은 적어도 하나의 객체는 포함하지 않는 제2 이미지를 획득할 수 있다. 제2 이미지의 획 득 동작은 이하에서 도 11 내지 도 13을 참조하여 상세히 설명한다. 도 11은 개시된 실시예에 따른 디스플레이 기기에서 생성되는 이미지의 일 예를 나타내는 도면이다. 도 11을 참조하면, 제1 이미지에서 인식된 객체들인 사용자 A1, 사용자 A2 및 사용자 A3이 모두 선택되면(S1110), 프로세서는 제1 이미지를 그대로 제2 이미지로 획득할 수 있다. 또는, 제1 이미지에서 인식된 객체들인 사용자 A1, 사용자 A2 및 사용자 A3 중 일부만이 선택되면(S1120), 선택된 객체만이 포함되도록 제1 이미지를 편집하여 제2 이미지를 생성할 수 있다. 예를 들어, 사용자 입력에 의하여 사용자 A2가 선택되지 않은 경우, 프로세서는 제1 이미지에서 선택되지 않은 사용자 A2를 제거, 블러링, 모자이크, 가상 객체를 나타내는 이미지로 표시 등과 같이 편집 처리하여, 제2 이미지을 생성할 수 있다. 도 11에서는, 프로세서는 제1 이미지에서 선택되지 않은 사용자 A2를 제거 또는 삭제하여 제2 이미지을 생성한 경우를 예로 들어 도시하였다. 또한, 프 로세서(3100는 A2가 제거 또는 삭제된 영역은, 배경 복원을 수행하여, 자연스러운 제2 이미지이 생 성되도록 할 수 있다. 도 12는 개시된 실시예에 따른 디스플레이 기기에서 생성되는 이미지의 다른 예를 나타내는 도면이다. 도 12를 참조하면, 제1 이미지에서 사용자 A2가 선택되지 않은 경우에 생성되는 제2 이미지가 예시된다. 도 12를 참조하면, 프로세서는 제1 이미지에서 선택되지 않은 사용자 A2가 이미징 되었던 영역 에 대체 이미지를 표시하여 제2 이미지을 생성할 수 있다. 여기서, 대체 이미지는 가상 객체 를 나타내는 이미지로, 프로세서 자체적으로 생성된 이미지가 될 수 있다. 또는, 대체 이미지는 사용자가 사전에 설정 또는 선택한 이미지가 될 수 있다. 도 13은 개시된 실시예에 따른 디스플레이 기기에서 생성되는 이미지의 또 다른 예를 나타내는 도면이다. 도 13 을 참조하면, 제1 이미지에서 사용자 A2가 선택되지 않은 경우에 생성되는 제2 이미지가 예시 된다. 도 13을 참조하면, 프로세서는 제1 이미지에서 선택되지 않은 사용자 A2가 이미징 되었던 영역 을 삭제하고, 나머지 객체들인 사용자 A1 및 사용자 A3의 위치, 크기, 및 배율 중 적어도 하나 를 변경하여 제2 이미지을 생성할 수 있다. 구체적으로, 제1 이미지에서 선택되지 않은 사용자 A2가 이미징 되었던 영역을 삭제되면, 제1 이미지의 공간 이용 효율이 떨어지며 사용자 A1 및 사용자 A3가 너무 떨어져 있어서 어색해 보 일 수 있다. 따라서, 제2 이미지 내에 포함되는 객체들의 공간 이용 효율이 높아지고 객체들이 어색하게 표현되지 않도록, 프로세서는 선택된 객체들인 사용자 A1 및 사용자 A3의 위치, 크기, 및 배율 중 적어도 하나를 변경하여 제2 이미지을 생성할 수 있다. 제2 이미지에는 위치 변경된 사용자 A1(116a) 및 위치 변경된 사용자 A3(118a)가 포함될 수 있다. 또한, 선택된 객체들인 사용자 A1 및 사용자 A3의 위치, 크기, 및 배율 중 적어도 하나를 변경하여 제2 이미지을 생성하는데 있어서, 인공 지능 기술에 근거한 이미지 생성 기술을 이용할 수 있을 것이다. 다시 도 6을 참조하면, S630 단계에서 생성된 제2 이미지(예를 들어, 1300)는 상대방 기기로 전송된다 (S640). S640 단계는 프로세서의 제어에 따라서 통신부에서 수행될 수 있다. 구체적으로, 제2 이미지 는 디스플레이 기기의 통신부에서 상대방 기기로 직접 전송될 수 있다. 또는, 서버(예를 들어, 도 5의 500)의 통신 중계를 이용하여 제2 이미지를 상대방 기기로 전송할 수 있다. 디스플레이 기기의 통신부는 서버(예를 들어, 도 5의 500)로 제2 이미지를 전송하고, 서버(예를 들어, 도 5의 500)는 제2 이미지를 다시 상대방 기기로 전송될 수 있다. 구체적으로, 프로세서는 인식된 객체를 선택 또는 해제하기 위한 사용자 입력이 수신된 이후에, 제2 이미 지의 전송이 개시되도록, 통신부를 제어할 수 있다. 또는, 프로세서는 인식된 객체를 선택 또는 해제 하기 위한 사용자 입력이 수신되기 전까지, 영상 통화 화면에 포함될 이미지의 송출을 중단할 수 있다. 여기서, 영상 통화 화면에 포함될 이미지는, 제1 이미지에서 식별된 모든 객체들이 선택된 경우에는 제1 이미지가 될 수있으며, 제1 이미지에서 식별된 객체들 중 일부만이 선택된 경우에는 제2 이미지가 될 수 있다. 또한, 개시된 실시예에서, 영상 통화가 수행되는 동안에 객체 인식은 반복적으로 수행될 수 있다. 예를 들어, 카메라가 소정 FPS(frame per second)로 동작하여 1초에 복수개의 프레임을 획득하는 경우, 객체 인식은 프레임마다 수행될 수 있다. 또는, 객체 인식은 일정한 프레임 간격으로 수행될 수 있다. 예를 들어, 1 내지 100 프레임이 순차적으로 획득될 때, 10개의 프레임마다 객체 인식을 수행할 수 있다. 또는, 객체 인식은 소정 시간, 예를 들어, 1초 등의 간격으로 수행될 수 있다. 구체적으로, 영상 통화가 개시될 때 인식된 복수개의 객체들 각각에 식별 번호를 부여하고, 부여된 식별 번호 별로 인식된 객체를 트래킹(tracking)할 수 있다. 그에 따라서, 식별된 객체가 영상 통화 동안에 계속하여 유지 되는지, 또는 식별되지 않은 새로운 객체가 인식되는지를 주기적으로 판단할 수 있을 것이다. 여기서, 인식된 객체를 트레킹하는데 있어서, 인식된 객체의 시각적 특징(visual feature) 및 인식된 객체에 대응되는 위치 정 보 중 적어도 하나가 이용될 수 있다. 인식된 객체를 트레킹하는데 있어서, 인식된 객체 전체의 이미지 데이터값을 이용하여, 매 프레임 마다 인식된 객체가 유지되는지 또는 새로운 객체가 나타났는지 판단하면 연산량이 많아질 수 있다. 따라서, 빠른 연산을 위 하여, 이미지 내의 시각적 특징(visual feature), 예를 들어, 이미지 내에서 추출되는 특정 화소들의 밝기, 음 영 정보, 에지 정보, 및/또는 꼭지점 정보 등을 추출하고, 추출된 시각적 특징에 근거하여 인식된 객체가 유지 되는지 또는 새로운 객체가 나타났는지 판단할 수 있다. 또는, 객체가 인식된 위치를 기준으로, 해당 위치에서 일정 오프셋 범위 내에서 인식된 객체가 계속적으로 존재하는지 판단함으로써, 인식된 객체가 유지되는지 또는 새로운 객체가 나타났는지 판단할 수 있다. 전술한 바와 같이, 시각적 특징 및 인식된 객체의 최종적인 위치 정보에 근거하여 객체 트래킹을 수행하면, 인 식된 객체가 유지되는지 또는 새로운 객체가 나타났는지 판단하기 위한 연산량을 감소시킬 수 있다. 또한, 개시된 실시예에서, 카메라에서 획득된 제1 이미지에서 인식된 객체들에 대한 선택 및 선택 해제는 소정 시간 간격으로 또는 사용자 요청이 있는 경우에, 재 수행될 수 있다. 예를 들어, 사용자 A1 가 자신 에 대한 이미지가 영상 통화 화면에 포함되길 원하였다가, 다시 영상 통화 화면에서 자신에 대한 이미지가 제외 되길 원할 수 있다. 이 경우, 사용자 A1의 요청에 근거하여, 프로세서는 제1 이미지에서 인식된 사용 자 A1에 대한 선택을 해제할 수 있을 것이다. 도 14는 개시된 실시예에 따른 영상 통화 수행 방법을 나타내는 또 다른 흐름도이다. 도 14에 있어서, 도 8에 도시된 동작들과 동일한 동작은 동일한 도면기호를 이용하여 도시하였으므로, 상세 설명은 생략한다. 또한, 영 상 통화 수행 방법이 도 4에서 설명한 디스플레이 기기를 통하여 수행되는 경우를 예로 들어 설명하 도록 하겠다. 도 14을 참조하면, 영상 통화 수행 방법은 영상 통화 수행 방법에 비하여 S650, S655, S660, S670, 및 S680 단계를 더 포함할 수 있다. 구체적으로, 영상 통화 수행 방법은 카메라가 갱신된 제1 이미지를 획득할 때, 갱신된 제1 이미지에 새로운 객체가 인식되는지 판단할 수 있다(S650). 여기서, S650 단계는 프로세서에서 수행될 수 있다. 구체적으로, 카메라의 프레임 레이트를 고려하여 소정 프레임 간격으로, 또는 소정 시간 간격으로, 갱신된 제1 이미지에 새로운 객체가 인식되는지, 또는 기존에 인식된 객체가 제외되는지 여부를 판단할 수 있다. 즉, 도 14의 S650 단계에 도시된 ‘새로운 객체 인식’은 기존에 인식되지 않은 객체가 추가적으로 인식되는 경우, 및/또는 기존에 인식되었던 객체가 사라진 경우를 모두 포함하는 의미를 가질 수 있다. S650 의 판단 결과, 새로운 객체가 인식되면, 새로운 객체를 선택하기 위한 사용자 인터페이스 화면을 디스플레 이로 출력할 수 있다(S660). 그리고, S650 의 판단 결과, 인식된 객체에 변화가 없으면, S655 단계에 따라 서 S650 단계로 회귀할 수 있다. 여기서, S655 및 S660 단계는 프로세서의 제어에 따라서 수행될 있다. 객 체 선택을 위한 사용자 인터페이스 화면의 출력 동작은 전술한 S615 단계에 대응되므로, 상세 설명은 생략한다. 계속하여, 영상 통화 수행 방법은 새로운 객체를 선택하는 사용자 입력에 근거하여, 상기 새로운 객체가 포함되도록 상기 제2 이미지를 갱신할 수 있다(S670). 여기서, S670 단계는 프로세서에서 수행될 수 있다. 그리고, 영상 통화 수행 방법은 S670에서 생성된 갱신된 제2 이미지를 상대방 기기로 전송할 수 있 다(S680). 여기서, S680 단계는 프로세서의 제어에 따라서 통신부에서 수행될 수 있다. 도 15는 도 14에 도시된 동작들을 설명하기 위한 일 도면이다. 도 16은 개시된 실시예에 따른 디스플레이 기기에서 생성되는 이미지의 다른 예를 나타내는 도면이다. 도 15 및 도 16에 있어서, 도 1 및 도 4에 도시된 구성들과 동일한 구성은 동일한 도면 기호를 이용하여 도시하 였다. 따라서, 중복되는 설명은 생략한다. 도 15를 참조하면, t1 시점에서 카메라에서 영상 통화를 위하여 획득된 제1 이미지에는 사용자 A1, 사용자 A2 및 사용자 A3가 포함된 경우게 예시된다. 즉, 디스플레이 기기의 전면에 공 간에는 사용자 A1, 사용자 A2 및 사용자 A3가 있었다. 제1 이미지에서 인식된 객체인 사용자 A1, 사용자 A2 및 사용자 A3가 모두 선택된 경우, 제2 이미지는 제1 이미지와 동 일할 수 있으며, 사용자 A1, 사용자 A2 및 사용자 A3를 포함한 이미지가 된다. t1 시점에 후속하는 t2 에서, 카메라는 영상 통화를 위하여 새로운 제1 이미지을 촬영할 수 있다. 예를 들어, 디스플레이 기기의 전면에 공간에는 t1 시점에 후속하는 t2 시점에 새로운 사용자인 사용자 A4가 추가적으로 위치하고 있다. 따라서, t2 시점에 획득된 제1 이미지는 t1 시점에 획득된 제1 이 미지에 비하여 새로운 객체인 사용자 A4를 포함하며, 프로세서는 S650 단계에서 새로운 객체인 사용자 A4를 인식할 수 있다. 도 16을 참조하면, S660 단계에서, 프로세서는 새롭게 인식된 객체, 예를 들어, 사용자 A4의 선택 또 는 해제를 위한 사용자 인터페이스 화면이 디스플레이 상으로 출력되도록 제어할 수 있다. 그에 따라서, 사용자는 새롭게 인식된 객체에 대하여 선택 또는 비선택을 나타내는 사용자 입력을 디스플레이 기기로 입력할 수 있다. 그러면, 프로세서는 사용자 입력에 근거하여, 갱신된 제2 이미지 생성할 수 있다(S670). 예를 들어, 새롭게 인식된 객체, 예를 들어, 사용자 A4가 선택된 경우(S1621), 프로세서는 사용자 A4와 기존에 선택되었던 객체들인 사용자 A1, 사용자 A2 및 사용자 A3가 모두 포함되도록, 제2 이미지을 생성할 수 있다. 또한, 새롭게 인식된 객체, 예를 들어, 사용자 A4가 선택되지 않은 경우(S1622), 프로세서는 사용자 A4는 제외되고 기존에 선택되었던 객체들인 사용자 A1, 사용자 A2 및 사용자 A3만이 포함 되도록, 제2 이미지을 생성할 수 있다. 또한, 개시된 실시예는, 영상 통화 화면에 포함되는 객체들의 포함 여부를 변경하기 위한 사용자 입력에 대응하 여, 영상 통화 화면에 포함될 객체를 선택하기 위한 사용자 인터페이스 화면(예를 들어, 도 9의 900 또는 도 10 의 1000)를 출력할 수 있다. 예를 들어, 영상 통화 화면에 포함되는 복수의 사용자들 중 적어도 한명이, 자신의 모습이 더 이상 영상 통화 화면에 포함되는 것을 원하지 않는 경우, 이를 요청하는 사용자 입력을 디스플레이 기기로 전송할 수 있다. 그러면, 디스플레이 기기는 사용자 입력의 수신에 대응하여, 영상 통화 화면에 포함될 객체를 선택하기 위한 사용자 인터페이스 화면(예를 들어, 도 9의 900 또는 도 10의 1000)를 출력할 수 있을 것 이다. 또는, 개시된 실시예는, 영상 통화 화면을 출력한 이후에, 소정 시간 간격으로 영상 통화 화면에 포함될 객체를 선택하기 위한 사용자 인터페이스 화면(예를 들어, 도 9의 900 또는 도 10의 1000)를 출력할 수 있다. 그에 따 라서, 영상 통화 화면에 포함되기를 원하지 않는 사용자가 영상 통화 개시 이후에 발생한 경우, 해당 사용자의 의도를 반영하여 제2 이미지를 갱신할 수 있을 것이다. 전술한 바와 같이, 도 1 내지 도 16을 참조하여 설명한 개시된 실시예는, 대화면을 이용하여 영상 통화를 수행 하는 디스플레이 기기에 있어서, 영상 통화 시, 적어도 하나의 사용자들 각각의 의도에 부합하여 프라이버시가 보호될 수 있도록, 영상 통화 화면을 구성하는 이미지(구체적으로, 전술한 제2 이미지)를 제공할 수 있다. 그에 따라서, 영상 통화 시 사용자의 프라이버시를 탄력적으로 보호함으로써, 사용자 만족도를 증가시킬 수 있다. 본 개시의 일 실시예에 따른 영상 통화 수행 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명 령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 또한, 본 개시의 실시예는, 영상 통화 수행 방법 을 실행하는 명령어들을 포함하는 하나 이상의 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체가 될 수 있 다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스 크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체 (optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬 (ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치 가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리 터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 여기서, 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기 서, ‘비일시적’은 저장매체'는 가 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않 는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되 는 경우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있 다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 영상 통화 수행 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배 포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어 플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저 장되거나, 임시적으로 생성될 수 있다. 구체적으로, 개시된 실시예에 따른 영상 통화 수행 방법을 수행하도록 하는 프로그램이 저장된 기록매체를 포함 하는 컴퓨터 프로그램 제품으로 구현될 수 있다. 이상에서 실시예들에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다."}
{"patent_id": "10-2020-0092552", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 복수개의 전자 기기들 간에 수행되는 영상 통화 서비스를 설명하기 위한 도면이다. 도 2는 디스플레이 기기에서 수행되는 영상 통화 서비스를 설명하기 위한 도면이다. 도 3은 개시된 실시예에 따른 디스플레이 기기를 나타내는 일 박스도이다. 도 4는 개시된 실시예에 따른 디스플레이 기기를 나타내는 다른 박스도이다. 도 5는 개시된 실시예에 따른 영상 통화 서비스를 수행하기 위해서 이용되는 복수개의 전자 기기들을 설명하기 위한 도면이다. 도 6은 개시된 실시예에 따른 영상 통화 수행 방법을 나타내는 일 흐름도이다. 도 7은 개시된 실시예에 따른 객체 인식 동작을 설명하기 위한 도면이다.도 8은 개시된 실시예에 따른 영상 통화 수행 방법을 나타내는 다른 흐름도이다. 도 9는 개시된 실시예에서 출력되는 사용자 인터페이스 화면을 일 예를 나타내는 도면이다. 도 10은 개시된 실시예에서 출력되는 사용자 인터페이스 화면을 다른 예를 나타내는 도면이다. 도 11은 개시된 실시예에 따른 디스플레이 기기에서 생성되는 이미지의 일 예를 나타내는 도면이다. 도 12는 개시된 실시예에 따른 디스플레이 기기에서 생성되는 이미지의 다른 예를 나타내는 도면이다. 도 13은 개시된 실시예에 따른 디스플레이 기기에서 생성되는 이미지의 또 다른 예를 나타내는 도면이다. 도 14는 개시된 실시예에 따른 영상 통화 수행 방법을 나타내는 또 다른 흐름도이다. 도 15는 도 14에 도시된 동작들을 설명하기 위한 일 도면이다. 도 16은 개시된 실시예에 따른 디스플레이 기기에서 생성되는 이미지의 다른 예를 나타내는 도면이다."}
