{"patent_id": "10-2021-0094768", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0013826", "출원번호": "10-2021-0094768", "발명의 명칭": "인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 장치 및 방법", "출원인": "울산과학기술원", "발명자": "이희승"}}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법에 있어서,사용자 음성 신호를 포함하는 오디오 신호를 획득하는 단계;상기 획득된 오디오 신호를 전처리하는 단계;상기 전처리된 오디오 신호가 입력되면 상기 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에 상기전처리된 오디오 신호를 입력함으로써, 상기 음성 신호에 대응되는 문자열을 획득하는 단계;상기 인공 지능 모델로부터 획득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상기 문자열에 대한 신뢰도수준을 결정하는 단계; 및상기 문자열 및 상기 신뢰도 수준을 함께 출력하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 방법은상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 기 설정된 범위를 벗어나는지 여부를 식별하는 단계; 및상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대한 후순위 인식 문자열을 더 출력하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 방법은상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대응되는 타임 라인을 더 출력하는 단계; 및상기 타임 라인에 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대응되는 신뢰도 유의 구간을 표시하는 단계; 를 더 포함하는, 방법."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 방법은상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열을 시각적으로 변환하는 단계; 및상기 시각적으로 변환된 문자열을 출력하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 방법은상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대한 맞춤법 제안 정보를 더 출력하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 전처리하는 단계는상기 인공 지능 모델의 특성에 기초하여 상기 획득된 오디오 신호의 포맷을 미리 설정된 포맷으로 변환하는 단계; 및공개특허 10-2023-0013826-3-상기 오디오 신호 내 노이즈 강도를 식별하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 인공 지능 모델은상기 오디오 신호 내 상기 사용자 음성 신호의 기 설정된 단위로 음성 정보를 출력하는 음향 모델; 및상기 음성 정보가 단어 시퀀스에 해당할 확률에 기초하여, 상기 음성 정보에 대응되는 소정의 후보 문자열을 출력하는 적어도 하나의 언어 모델; 을 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 문자열을 획득하는 단계는상기 사용자 음성 신호에 대응되는 음성 정보를 상기 적어도 하나의 언어 모델에 입력함으로써, 상기 적어도 하나의 언어 모델 각각에서 출력되는 후보 문자열들을 획득하는 단계; 및상기 적어도 하나의 언어 모델에서 출력된 후보 문자열들의 빈도수에 기초하여, 상기 후보 문자열들 중, 하나의후보 문자열을 획득하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서, 상기 신뢰도 수준을 결정하는 단계는상기 인공 지능 모델 내 음향 모델로부터, 상기 음향 모델 내로 입력된 사용자 음성 신호가 상기 음향 모델로부터 출력되는 상기 음성 정보에 해당할 확률 값을 획득하는 단계;상기 노이즈 강도 및 상기 음성 정보에 해당할 확률 값을 상기 정확도 정보로 획득하는 단계; 및상기 정확도 정보에 기초하여 상기 문자열에 대한 신뢰도 수준을 결정하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제2항에 있어서, 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 기 설정된 범위를 벗어나는지 여부를 식별하는 단계는상기 문자열에 대한 신뢰도 수준이 상기 기 설정된 범위를 벗어나거나, 상기 인공 지능 모델로부터 출력된 인접한 문자열에 대한 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는지 여부를 식별하는 단계; 를포함하는, 방법."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 전자 장치에 있어서,하나 이상의 인스트럭션을 저장하는 메모리; 및상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서; 를 포함하고,상기 적어도 하나의 프로세서는사용자 음성 신호를 포함하는 오디오 신호를 획득하고,상기 획득된 오디오 신호를 전처리하고,상기 전처리된 오디오 신호가 입력되면 상기 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에 상기전처리된 오디오 신호를 입력함으로써, 상기 음성 신호에 대응되는 문자열을 획득하고,상기 인공 지능 모델로부터 획득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상기 문자열에 대한 신뢰도수준을 결정하고,상기 문자열 및 상기 신뢰도 수준을 함께 출력하는, 전자 장치."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2023-0013826-4-제11항에 있어서, 상기 적어도 하나의 프로세서는상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 기 설정된 범위를 벗어나는지 여부를 식별하고,상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대한 후순위 인식 문자열을 더 출력하는, 전자 장치."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 적어도 하나의 프로세서는상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대응되는 타임 라인을 더 출력하고,상기 타임 라인에 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대응되는 신뢰도 유의 구간을 표시하는, 전자 장치."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 적어도 하나의 프로세서는상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열을 시각적으로 변환하고,상기 시각적으로 변환된 문자열을 출력하는, 전자 장치."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서, 상기 적어도 하나의 프로세서는상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대한 맞춤법 제안 정보를 더 출력하는, 전자 장치."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서, 상기 적어도 하나의 프로세서는상기 인공 지능 모델의 특성에 기초하여 상기 획득된 오디오 신호의 포맷을 미리 설정된 포맷으로 변환하고,상기 오디오 신호 내 노이즈 강도를 식별하는, 전자 장치."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서, 상기 인공 지능 모델은상기 오디오 신호 내 상기 사용자 음성 신호의 음절 단위로 음성 정보를 출력하는 음향 모델; 및상기 음성 정보가 단어 시퀀스에 해당할 확률에 기초하여, 상기 음성 정보에 대응되는 소정의 후보 문자열을 출력하는 적어도 하나의 언어 모델; 을 포함하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 적어도 하나의 프로세서는상기 사용자 음성 신호에 대응되는 음성 정보를 상기 적어도 하나의 언어 모델에 입력함으로써, 상기 적어도 하나의 언어 모델 각각에서 출력되는 후보 문자열들을 획득하고,상기 적어도 하나의 언어 모델들에서 출력된 후보 문자열들의 빈도수에 기초하여, 상기 후보 문자열들 중, 하나의 후보 문자열을 획득하는, 전자 장치."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서, 상기 적어도 하나의 프로세서는상기 음향 모델로부터 상기 사용자 음성 신호가 상기 음성 정보에 해당할 확률 값을 획득하고,공개특허 10-2023-0013826-5-상기 노이즈 강도 및 상기 음성 정보에 해당할 확률 값을 상기 정확도 정보로 획득하고,상기 정확도 정보에 기초하여 상기 문자열에 대한 신뢰도 수준을 결정하는, 전자 장치."}
{"patent_id": "10-2021-0094768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "전자 장치가 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법에 있어서,사용자 음성 신호를 포함하는 오디오 신호를 획득하는 단계;상기 획득된 오디오 신호를 전처리하는 단계;상기 전처리된 오디오 신호가 입력되면 상기 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에 상기전처리된 오디오 신호를 입력함으로써, 상기 음성 신호에 대응되는 문자열을 획득하는 단계;상기 인공 지능 모델로부터 획득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상기 문자열에 대한 신뢰도수준을 결정하는 단계; 및상기 문자열 및 상기 신뢰도 수준을 함께 출력하는 단계; 를 포함하는, 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2021-0094768", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법 및 이를 수행하는 전자 장치에 관한 것 이다. 일 실시 예에 의하면, 전자 장치가 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법은 사용 자 음성 신호를 포함하는 오디오 신호를 획득하는 단계; 상기 획득된 오디오 신호를 전처리하는 단계; 상기 전처 리된 오디오 신호가 입력되면 상기 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에 상기 전처리된 오 디오 신호를 입력함으로써, 상기 음성 신호에 대응되는 문자열을 획득하는 단계; 상기 인공 지능 모델로부터 획 득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상기 문자열에 대한 신뢰도 수준을 결정하는 단계; 및 상기 문자열 및 상기 신뢰도 수준을 함께 출력하는 단계; 를 포함할 수 있다."}
{"patent_id": "10-2021-0094768", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "융합디자인전문인력 양성사업"}
{"patent_id": "10-2021-0094768", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "연구과제명 신기술분야 융합디자인전문인력 양성사업 기 여 율 1/2 과제수행기관명 울산과학기술 연구기간 2021.03.01 ~ 2022.02.28 이 발명을 지원한 국가연구개발사업 과제고유번호 1711118431 과제번호 2020R1F1A106639711 부처명 과학기술정보통신부 과제관리(전문)기관명 한국연구재단 연구사업명 기본연구(개인) 연구과제명 인공지능 시스템과 사람과의 효과적인 상호 작용을 위한 동적 감정 모델 연구 및 개 발 기 여 율 1/2 과제수행기관명 울산과학기술원 연구기간 2021.03.01 ~ 2022.02.28명 세 서 청구범위 청구항 1 전자 장치가 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법에 있어서, 사용자 음성 신호를 포함하는 오디오 신호를 획득하는 단계; 상기 획득된 오디오 신호를 전처리하는 단계; 상기 전처리된 오디오 신호가 입력되면 상기 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에 상기 전처리된 오디오 신호를 입력함으로써, 상기 음성 신호에 대응되는 문자열을 획득하는 단계; 상기 인공 지능 모델로부터 획득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상기 문자열에 대한 신뢰도 수준을 결정하는 단계; 및 상기 문자열 및 상기 신뢰도 수준을 함께 출력하는 단계; 를 포함하는, 방법. 청구항 2 제1항에 있어서, 상기 방법은 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 기 설정된 범위를 벗어나는지 여부를 식별하는 단계; 및 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위 를 벗어나는 것으로 식별되는 문자열에 대한 후순위 인식 문자열을 더 출력하는 단계; 를 포함하는, 방법. 청구항 3 제2항에 있어서, 상기 방법은 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위 를 벗어나는 것으로 식별되는 문자열에 대응되는 타임 라인을 더 출력하는 단계; 및 상기 타임 라인에 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대응되는 신뢰도 유의 구간을 표 시하는 단계; 를 더 포함하는, 방법. 청구항 4 제3항에 있어서, 상기 방법은 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위 를 벗어나는 것으로 식별되는 문자열을 시각적으로 변환하는 단계; 및 상기 시각적으로 변환된 문자열을 출력하는 단계; 를 포함하는, 방법. 청구항 5 제3항에 있어서, 상기 방법은 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위 를 벗어나는 것으로 식별되는 문자열에 대한 맞춤법 제안 정보를 더 출력하는 단계; 를 포함하는, 방법. 청구항 6 제1항에 있어서, 상기 전처리하는 단계는 상기 인공 지능 모델의 특성에 기초하여 상기 획득된 오디오 신호의 포맷을 미리 설정된 포맷으로 변환하는 단 계; 및상기 오디오 신호 내 노이즈 강도를 식별하는 단계; 를 포함하는, 방법. 청구항 7 제1항에 있어서, 상기 인공 지능 모델은 상기 오디오 신호 내 상기 사용자 음성 신호의 기 설정된 단위로 음성 정보를 출력하는 음향 모델; 및 상기 음성 정보가 단어 시퀀스에 해당할 확률에 기초하여, 상기 음성 정보에 대응되는 소정의 후보 문자열을 출 력하는 적어도 하나의 언어 모델; 을 포함하는 것을 특징으로 하는, 방법. 청구항 8 제7항에 있어서, 상기 문자열을 획득하는 단계는 상기 사용자 음성 신호에 대응되는 음성 정보를 상기 적어도 하나의 언어 모델에 입력함으로써, 상기 적어도 하 나의 언어 모델 각각에서 출력되는 후보 문자열들을 획득하는 단계; 및 상기 적어도 하나의 언어 모델에서 출력된 후보 문자열들의 빈도수에 기초하여, 상기 후보 문자열들 중, 하나의 후보 문자열을 획득하는 단계; 를 포함하는, 방법. 청구항 9 제6항에 있어서, 상기 신뢰도 수준을 결정하는 단계는 상기 인공 지능 모델 내 음향 모델로부터, 상기 음향 모델 내로 입력된 사용자 음성 신호가 상기 음향 모델로부 터 출력되는 상기 음성 정보에 해당할 확률 값을 획득하는 단계; 상기 노이즈 강도 및 상기 음성 정보에 해당할 확률 값을 상기 정확도 정보로 획득하는 단계; 및 상기 정확도 정보에 기초하여 상기 문자열에 대한 신뢰도 수준을 결정하는 단계; 를 포함하는, 방법. 청구항 10 제2항에 있어서, 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 기 설정된 범위를 벗어나는지 여부를 식별 하는 단계는 상기 문자열에 대한 신뢰도 수준이 상기 기 설정된 범위를 벗어나거나, 상기 인공 지능 모델로부터 출력된 인접 한 문자열에 대한 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는지 여부를 식별하는 단계; 를 포함하는, 방법. 청구항 11 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 전자 장치에 있어서, 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서; 를 포함하고, 상기 적어도 하나의 프로세서는 사용자 음성 신호를 포함하는 오디오 신호를 획득하고, 상기 획득된 오디오 신호를 전처리하고, 상기 전처리된 오디오 신호가 입력되면 상기 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에 상기 전처리된 오디오 신호를 입력함으로써, 상기 음성 신호에 대응되는 문자열을 획득하고, 상기 인공 지능 모델로부터 획득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상기 문자열에 대한 신뢰도 수준을 결정하고, 상기 문자열 및 상기 신뢰도 수준을 함께 출력하는, 전자 장치. 청구항 12 제11항에 있어서, 상기 적어도 하나의 프로세서는 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 기 설정된 범위를 벗어나는지 여부를 식별하고, 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위 를 벗어나는 것으로 식별되는 문자열에 대한 후순위 인식 문자열을 더 출력하는, 전자 장치. 청구항 13 제12항에 있어서, 상기 적어도 하나의 프로세서는 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위 를 벗어나는 것으로 식별되는 문자열에 대응되는 타임 라인을 더 출력하고, 상기 타임 라인에 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대응되는 신뢰도 유의 구간을 표 시하는, 전자 장치. 청구항 14 제13항에 있어서, 상기 적어도 하나의 프로세서는 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위 를 벗어나는 것으로 식별되는 문자열을 시각적으로 변환하고, 상기 시각적으로 변환된 문자열을 출력하는, 전자 장치. 청구항 15 제13항에 있어서, 상기 적어도 하나의 프로세서는 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나는 경우, 상기 기 설정된 범위 를 벗어나는 것으로 식별되는 문자열에 대한 맞춤법 제안 정보를 더 출력하는, 전자 장치. 청구항 16 제11항에 있어서, 상기 적어도 하나의 프로세서는 상기 인공 지능 모델의 특성에 기초하여 상기 획득된 오디오 신호의 포맷을 미리 설정된 포맷으로 변환하고, 상기 오디오 신호 내 노이즈 강도를 식별하는, 전자 장치. 청구항 17 제11항에 있어서, 상기 인공 지능 모델은 상기 오디오 신호 내 상기 사용자 음성 신호의 음절 단위로 음성 정보를 출력하는 음향 모델; 및 상기 음성 정보가 단어 시퀀스에 해당할 확률에 기초하여, 상기 음성 정보에 대응되는 소정의 후보 문자열을 출 력하는 적어도 하나의 언어 모델; 을 포함하는 것을 특징으로 하는, 전자 장치. 청구항 18 제17항에 있어서, 상기 적어도 하나의 프로세서는 상기 사용자 음성 신호에 대응되는 음성 정보를 상기 적어도 하나의 언어 모델에 입력함으로써, 상기 적어도 하 나의 언어 모델 각각에서 출력되는 후보 문자열들을 획득하고, 상기 적어도 하나의 언어 모델들에서 출력된 후보 문자열들의 빈도수에 기초하여, 상기 후보 문자열들 중, 하나 의 후보 문자열을 획득하는, 전자 장치. 청구항 19 제16항에 있어서, 상기 적어도 하나의 프로세서는 상기 음향 모델로부터 상기 사용자 음성 신호가 상기 음성 정보에 해당할 확률 값을 획득하고,상기 노이즈 강도 및 상기 음성 정보에 해당할 확률 값을 상기 정확도 정보로 획득하고, 상기 정확도 정보에 기초하여 상기 문자열에 대한 신뢰도 수준을 결정하는, 전자 장치. 청구항 20 전자 장치가 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법에 있어서, 사용자 음성 신호를 포함하는 오디오 신호를 획득하는 단계; 상기 획득된 오디오 신호를 전처리하는 단계; 상기 전처리된 오디오 신호가 입력되면 상기 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에 상기 전처리된 오디오 신호를 입력함으로써, 상기 음성 신호에 대응되는 문자열을 획득하는 단계; 상기 인공 지능 모델로부터 획득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상기 문자열에 대한 신뢰도 수준을 결정하는 단계; 및 상기 문자열 및 상기 신뢰도 수준을 함께 출력하는 단계; 를 포함하는, 방법을 컴퓨터에서 실행시키기 위한 프 로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체. 발명의 설명 기 술 분 야 본 개시는 음성 인식 서비스를 제공하는 장치 및 방법에 관한 것이다. 보다 상세하게는, 음성 인식 정확도를 기 반으로 음성 인식 서비스를 제공하는 전자 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0094768", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능 시스템은 인공 지능 학습 알고리즘에 의해 기계가 스스로 학습하고 판단하는 시스템이다. 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하기 위한 기술들이 활발하게 연구되고 있다. 일반적으로 음성 인식 문자열 변환 과정에서 오탈자를 검토하는 과정은 불완전한 음성 인식 기술 때문에 불가피 하다. 따라서, 음성 인식 문자열 변환 결과에 대한 정확도를 향상하기 위한 기술 개발이 연구되고 있다. 일부 음성 인식 서비스 기술들은 음성 인식 결과에 대한 문법 또는 맞춤법적 수정안을 제안하나, 그 정확도에 한계가 있으며, 음성 인식 결과의 정확도를 기반으로 음성 인식 결과에 대한 문법 또는 맞춤법적 수정안을 제안 하지 않는다. 따라서, 음성 인식 결과의 정확도를 기반으로 음성 인식 서비스를 제공하는 기술 개발이 요구되고 있다."}
{"patent_id": "10-2021-0094768", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시 예에 따르면, 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법 및 이를 수행하는 전자 장 치가 제공될 수 있다. 또한, 일 실시 예에 의하면, 음성 인식 결과의 정확도에 기초하여 음성 인식 결과에 대한 신뢰도 수준을 결정하 고, 결정된 신뢰도 수준을 음성 인식 결과와 함께 제공하는 음성 인식 서비스를 제공하는 방법 및 이를 수행하 는 전자 장치가 제공될 수 있다."}
{"patent_id": "10-2021-0094768", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 일 실시 예에 의하면, 전자 장치가 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법은 사용자 음성 신호를 포함하는 오디오 신호를 획득하는 단계; 상 기 획득된 오디오 신호를 전처리하는 단계; 상기 전처리된 오디오 신호가 입력되면 상기 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에 상기 전처리된 오디오 신호를 입력함으로써, 상기 음성 신호에 대응되는 문자열을 획득하는 단계; 상기 인공 지능 모델로부터 획득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상 기 문자열에 대한 신뢰도 수준을 결정하는 단계; 및 상기 문자열 및 상기 신뢰도 수준을 함께 출력하는 단계;를 포함할 수 있다. 상술한 기술적 과제를 달성하기 위한 또 다른 실시 예에 의하면, 인공 지능 모델을 이용하여 음성 인식 서비스 를 제공하는 전자 장치에 있어서, 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 하나 이상의 인스트럭션 을 실행하는 적어도 하나의 프로세서; 를 포함하고, 상기 적어도 하나의 프로세서는 사용자 음성 신호를 포함하 는 오디오 신호를 획득하고, 상기 획득된 오디오 신호를 전처리하고, 상기 전처리된 오디오 신호가 입력되면 상 기 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에 상기 전처리된 오디오 신호를 입력함으로써, 상 기 음성 신호에 대응되는 문자열을 획득하고, 상기 인공 지능 모델로부터 획득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상기 문자열에 대한 신뢰도 수준을 결정하고, 상기 문자열 및 상기 신뢰도 수준을 함께 출력 하는, 전자 장치가 제공될 수 있다. 또한, 상술한 기술적 과제를 달성하기 위한 또 다른 실시 예에 의하면, 전자 장치가 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법에 있어서, 사용자 음성 신호를 포함하는 오디오 신호를 획득하는 단계; 상기 획득된 오디오 신호를 전처리하는 단계; 상기 전처리된 오디오 신호가 입력되면 상기 음성 신호에 대응되는 문 자열을 출력하는 인공 지능 모델에 상기 전처리된 오디오 신호를 입력함으로써, 상기 음성 신호에 대응되는 문 자열을 획득하는 단계; 상기 인공 지능 모델로부터 획득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상기 문자열에 대한 신뢰도 수준을 결정하는 단계; 및 상기 문자열 및 상기 신뢰도 수준을 함께 출력하는 단계; 를 포함하는, 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체가 제공될 수 있다."}
{"patent_id": "10-2021-0094768", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다.아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 일 실시 예에 따른, 전자 장치가 음성 인식 정확도에 기초하여 음성 인식 서비스를 제공하는 방법을 개 략적으로 나타내는 도면이다. 일 실시 예에 의하면, 전자 장치는 사용자로부터 사용자 음성 신호를 포함하는 오디오 신호 를 획득하고, 인공 지능 모델을 이용하여, 상기 획득된 오디오 신호에 대한 음성 인식을 수행함 으로써, 문자열을 출력할 수 있다. 본 개시에 따른 전자 장치는 음성 인식 서비스를 제공하기 위해 인공 지능 모델을 이용할 수 있다. 일 실시 예에 의하면, 전자 장치가 이용하는 인공 지능 모델은 자동 음성 인식 ASR(Automatic Speech Recognition) 모델, 음향 모델, 또는 언어 모델 중 적어도 하나를 포함할 수 있다. 예를 들어, 전자 장치가 이용하는 인공 지능 모델은 자동 음성 인식 모델로써 입력된 사용자 음성 을 텍스트 문자열로 변환할 수 있다. 또한, 일 실시 예에 의하면, 음향 모델은 입력된 사용자 음성 신호의 기 설정된 단위(예컨대 음절 또는 음소 (phonemes) 단위)가 나타내는 음향(acoustic) 특징을 식별함으로써 사용자 음성 신호에 대응되는 음성 정보를 출력한다. 전자 장치는 음향 모델에서 음성 정보를 획득함과 함께, 음향 모델로부터 상기 사용자 음성 신 호가 상기 출력된 음성 정보에 대응될 확률 값을 출력할 수 있다. 또한, 일 실시 예에 의하면 언어 모델은 상기 음향 모델에서 출력된 음성 정보들 중 적어도 하나를 이용하여, 복수의 단어 시퀀스들 중, 가장 높은 확률 값에 대응되는 후보 문자열을 출력할 수 있다. 일 실시 예에 의하면, 전자 장치가 이용하는 언어 모델은 적어도 하나의 모델을 포함할 수도 있다. 예를 들어, 전자 장치(100 0)가 이용하는 인공 지능 모델이 적어도 하나의 언어 모델을 포함하는 경우, 전자 장치는 각 언어 모델에 서 출력된 후보 문자열들 중, 가장 빈도수가 높은 후보 문자열을, 음성 인식 결과값으로써 출력할 수도 있다. 일 실시 예에 의하면, 전자 장치는 하나 이상의 인스트럭션을 저장하는 메모리 및 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함하고, 상기 하나 이상의 인스트럭션을 실행하는 상 기 프로세서의 제어에 의해 음성 인식 서비스를 제공할 수 있다. 또한, 일 실시 예에 의하면, 전자 장치 가 이용하는 인공 지능 모델은 CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks)를 더 포함할 수도 있으나, 이에 한정되는 것은 아니며, 기타 오디오 신호를 학습하기 위한 신경망 모델일 수도 있다. 전자 장치가 이용하는 인공 지능 모델은 사용자 음성을 포함하는 오디오 신호에 포함된 사용자 음성을 인 식함으로써 사용자 음성을 텍스트 문자열로 변환할 수 있다. 그러나, 또 다른 실시 예에 의하면 전자 장치 는 사용자 음성 신호에 대응되는 문자열을 출력함과 함께 음성 인식 결과에 대한 신뢰도 수준, 타임 라인, 맞춤법 제안 정보 또는 부가 정보 중 적어도 하나를 출력할 수 있다. 예를 들어, 전자 장치는 인공 지능 모델로부터 음성 인식 결과에 대한 문자열 정보를 획득함과 함께 음성 인식 결과인 문자열에 대한 정확도 정보를 더 획득하고, 획득된 정확도 정보에 기초하여 문자열에 대한 신 뢰도 수준을 문자열과 함께 출력할 수 있다. 본 개시에 따른 전자 장치는 사용자 음성에 대한 음성 인식 결과로써 문자열만을 출력하는 것이 아니라, 문자열과 함께 신뢰도 수준에 대한 정보를 함께 출력함으로써, 음 성 인식 결과의 품질을 향상시킬 수 있다. 본 개시에 따른 전자 장치를 사용하는 사용자는 음성 인식 결 과에 대한 신뢰도 수준에 더하여, 타임 라인, 맞춤법 제안 정보 또는 부가 정보 중 적어도 하나 를 더 획득함으로써 음성 인식 서비스를 사용하는 사용자의 편의를 향상시킬 수 있다. 예를 들어, 전자 장치 화면를 참조하면, 본 개시에 따른 전자 장치는 사용자와 담당자의 음성을 인 식함으로써 소정의 문자열들을 출력할 수 있다. 전자 장치는 사용자에 대한 음성 인식 결과로써 '안녕하 세요. 클로바노트 서비스는 언제 사용하면 좋은 서비스인가요'와 같은 문자열을 출력함과 함께 '언제'와 같은 문자열의 인접한 위치에 신뢰도 수준을 함께 표시함으로써 음성 인식 수준에 대한 신뢰도 정보를 사용자에 게 제공할 수 있다. 또한, 전자 장치는 담당자의 음성을 인식함으로써 '특히 배경 소음이 적고 3명 이하 의 대화 같은 정확하게 기록할 수 있어요'라는 문자열을 출력함과 함께 '대화 같은' 부분 문자열과 '정확하게'라는 부분 문자열 사이에 낮은 신뢰도 수준을 함께 표시함으로써, 사용자로 하여금 해당 부분에 음성 인식이 신 뢰할 만한 수준으로 수행되지 않았음을 나타낼 수 있다. 일 실시 예에 의하면, 전자 장치는 서버와 연동함으로써 사용자 음성 인식 서비스를 제공할 수 있 다. 예를 들어, 전자 장치는 사용자 음성을 포함하는 오디오 신호를 획득하고, 획득된 오디오 신호를 서 버로 전송하며, 서버에 의해 수행된 음성 인식 결과에 대한 정보를 수신할 수도 있다. 그러나, 상 술한 예에 한정되는 것은 아니며, 전자 장치는 서버와 연동함으로써 본 명세서에서 기재되는 음성 인식 서비스 중 적어도 일부를 수행할 수 있다. 일 실시 예에 따른 전자 장치는 AI 프로그램이 탑재되고 음성 인식 기능을 포함하는 스마트폰, PC, 휴대 폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 또한, 일 실시 예에 의하면, 전자 장치와 연동되는 서버는 네트워 크를 통하여 전자 장치와 연결될 수 있으며, 상기 네트워크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 이동 통신망(mobile radio communication network), 위성 통신망 및 이들의 상호 조합을 포함할 수 있다. 전자 장치와 네트 워크를 통하여 연결되는 서버는 본원 전자 장치와 통신 가능한 적어도 하나의 다른 전자 장치를 포 함할 수 있다. 도 2는 일 실시 예에 따른 전자 장치가 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법의 흐름도 이다. S210에서, 전자 장치는 사용자 음성 신호를 포함하는 오디오 신호를 획득할 수 있다. 예를 들어, 전자 장 치는 적어도 하나의 마이크를 포함하고, 마이크를 통하여 사용자 음성을 포함하는 오디오 신호를 획득할 수 있다. S220에서, 전자 장치는 오디오 신호를 전처리할 수 있다. 일 실시 예에 의하면, 전자 장치 는 인공 지능 모델의 특성에 맞도록 획득된 오디오 신호의 포맷을 변환함으로써, 오디오 신호를 전처리할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 오디오 신호를 소정의 시퀀스로 분할함으로써, 오디오 신호를 전처리할 수도 있다. S230에서, 전자 장치는 전처리된 오디오 신호가 입력되면 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에, 상기 전처리된 오디오 신호를 입력함으로써 음성 신호에 대응되는 문자열을 획득할 수 있다. 일 실시 예에 의하면, 전자 장치가 이용하는 인공 지능 모델은 적어도 하나의 언어 모델을 포함할 수 있다. 전자 장치는 전처리된 음성 신호에 대한 음성 정보들을 각 언어 모델에 입력하고, 각 언어 모델들로부터 후보 문자열들을 획득할 수 있다. 전자 장치는 적어도 하나의 언어 모델에서 출력된 후보 문자열들의 빈 도수에 기초하여, 후보 문자열들 중 하나의 후보 문자열을, 최종 음성 인식 결과로써의 문자열로 획득할 수 있 다. S240에서, 전자 장치는 인공 지능 모델로부터 획득되는 문자열에 대한 정확도 정보에 기초하여, 문자열 에 대한 신뢰도 수준을 결정할 수 있다. 일 실시 예에 의하면, 전자 장치가 인공 지능 모델로부터 획득하 는 정확도 정보는 인공 지능 모델의 음성 인식 과정에서 발생한 정보일 수 있다. 일 실시 예에 의하면, 전자 장 치가 획득하는 문자열에 대한 정확도 정보는, 입력된 사용자 음성 신호가, 인공 지능 모델 내 음향 모델 에서 출력된 음성 정보에 해당할 확률 값을 의미할 수 있다. 일 실시 예에 의하면, 전자 장치는 오디오 신호 내 사용자 음성 신호를 제외한 신호들의 강도에 관한 노 이즈 강도를 측정할 수 있다. 또한, 전자 장치는 음향 모델로부터 상기 사용자 음성 신호가 음성 정보에 해당할 확률 값을 획득할 수 있다. 본 개시에 따른 전자 장치는 노이즈 강도 및 음성 정보에 해당할 확률 값을 정확도 정보로 획득할 수도 있다. 전자 장치는 정확도 정보에 기초하여 문자열에 대한 신뢰도 수준 을 결정할 수 있다. S250에서, 전자 장치는 인공 지능 모델로부터 획득된 문자열 및 상기 결정된 신뢰도 수준을 함께 출력할 수 있다. 예를 들어, 전자 장치는 인공 지능 모델로부터 획득되는 문자열 및 신뢰도 수준을 전자 장치의 화면상에 함께 표시할 수 있다. 일 실시 예에 의하면, 전자 장치는 다양한 시각적 컨텐츠 또는 청각적 컨 텐츠를 활용하여, 음성 인식 결과인 문자열과 함께 신뢰도 수준을 제공할 수 있다. 도 3은 일 실시 예에 따른 전자 장치가 음성 인식 결과에 대한 신뢰도 수준에 기초하여 후순위 인식 문자열을 출력하는 방법의 흐름도이다. S310에서, 전자 장치는 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 기 설정된 범위를 벗어나는지 여부 를 식별할 수 있다. S320에서, 전자 장치는 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 기 설정된 범위 를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대한 후순위 인식 문자열을 더 출력할 수 있다. 예를 들어, 전자 장치는 획득된 오디오 신호 내 사용자 음성 시퀀스 각각에 대한 문자열을 획득함과 함께 각 음성 시퀀스에 대한 음성 인식 수행 과정에서의 신뢰도 수준을 결정할 수 있다. 전자 장치는 음성 시 퀀스 각각에 대한 신뢰도 수준이 기 설정된 제1 신뢰도 범위를 벗어나는 경우, 제1 신뢰도 범위를 벗어나는 것으로 식별된 음성 시퀀스에 대한 문자열을 표시함과 함께 상기 표시된 문자열에 인접한 위치에 후순위 인식 문 자열들을 함께 출력할 수 있다. 그러나, 또 다른 실시 예에 의하면, 전자 장치는 음성 시퀀스 각각에 대한 신뢰도 수준이 아닌, 음성 시 퀀스 각각에 대해 결정된 신뢰도 수준의 변화량을 식별하고, 식별된 변화량이 제2 신뢰도 범위를 벗어나는 경우, 상기 제2 신뢰도 범위를 벗어나는 것으로 식별되는 인접한 문자열들 각각에 대해, 후순위 인식 문자열들 을 더 출력할 수도 있다. 도 4는 일 실시 예에 따른 전자 장치가 음성 인식 결과로써 문자열, 타임라인 및 후순위 인식 문자열을 출력하 는 예를 설명하기 위한 도면이다. 도 4를 참조하면 일 실시 예에 따른 전자 장치가 제공하는 음성 인식 결과에 대한 컨텐츠가 도시된다. 예 를 들어, 전자 장치는 사용자로부터 '음성 인식 하면 다 꺼'라는 음성 신호를 포함하는 오디오 신호를 획 득할 수 있다. 전자 장치는 인공 지능 모델을 이용하여 '음성 인식 하면 다꺼'와 같은 문자열을 출력할 수 있다. 보다 상세하게는, 전자 장치는 인공 지능 모델 내 음향 모델에서 출력되는 사용자 음성이 음성 정보에 대 응될 확률 값을 정확도 정보로 획득하고, 획득된 정확도 정보에 기초하여, 언어 모델의 출력 값(예컨대 문자 열)에 대한 신뢰도 수준을 결정할 수 있다. 예를 들어, 전자 장치는 출력된 문자열 '하면'과 '다 꺼' 각각에 대해 제1 신뢰도 수준 및 제2 신뢰도 수준을 결정하고, 결정된 제1 신뢰도 수준 및 제2 신뢰도 수준이 소정의 임계치 이하인 경우, 신뢰도 수준이 낮은 것으로 결정할 수 있다. 전자 장치는 신뢰도 수 준이 낮은 것으로 식별되는 문자열 '하면'에 대한 타임 라인을 표시함과 함께, '하면'에 대한 후순위 인식 문자열들 (예컨대 '화면' 또는 '관련')을 신뢰도 수준이 낮은 것으로 식별되는 문자열 '하 면'에 인접한 위치에 출력할 수 있다. 또한, 전자 장치는 신뢰도 수준이 낮은 것으로 식별되는 문자 열 '다 꺼'에 대한 타임 라인을 표시함과 함께, '다 꺼'에 대한 후순위 인식 문자열들 (예 컨대 '특허')을 신뢰도 수준이 낮은 것으로 식별되는 문자열 '다 꺼' 에 인접한 위치에 출력할 수 있다. 본 개시에 따른 전자 장치가 표시하는 타임 라인은 오디오 신호를 시각화한 그래프일 수 있다. 또한, 전 자 장치는 타임라인에 신뢰도 수준이 낮은 것으로 식별되는 문자열에 대응되는 신뢰도 유의 구간 을 더 표시할 수도 있다. 예를 들어, 신뢰도 유의 구간은 타임 라인 내 신뢰도 수준이 낮은 것으로 식별되 는 문자열에 해당하는 부분 오디오 신호에 대응될 수 있다. 일 실시 예에 의하면, 전자 장치가 출력하는 후순위 인식 문자열들(406, 408)들은, 인공 지능 모델 내 적어도 하나의 언어 모델들에서 출력된 문자열들 중, 가장 빈도수가 높은 문자열 다음으로 빈도수가 높은 문자열들일 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 '하면'과 '다 꺼' 각각에 대한 제1 신뢰도 수준 및 제 2 신뢰도 수준을 결정하고, 상기 결정된 제1 신뢰도 수준 및 제2 신뢰도 수준의 변화량을 식별할 수도 있다. 전 자 장치는 제1 신뢰도 수준 및 제2 신뢰도 수준의 변화량이 소정의 임계 변화량 보다 크게 식별되는 경우, '하면' 및 '다 꺼' 문자열 모두가 신뢰도가 낮은 것으로 식별하고, '하면' 및 '다 꺼' 각각에 대한 타임라인과 함께 후순위 인식 문자열들을 출력할 수도 있다. 도 4에서는 전자 장치가 신뢰도 수준 또는 신뢰도 수준의 변화가 기 설정된 범위를 벗어나는 경우, 기 설 정된 범위를 벗어나는 것으로 식별된 문자열에 대응되는 타임 라인 및 후순위 인식 문자열들을 함께 출력하는 것으로 설명하였으나, 또 다른 실시 예에 의하면, 전자 장치는 신뢰도 수준 또는 신뢰도 수준의 변화가 기 설정된 범위를 벗어나는 경우, 해당 문자열에 인접한 위치에 타임 라인만을 표시할 수도 있음은 물론이다. 또 다른 실시 예에 의하면, 전자 장치는 신뢰도 수준 또는 신뢰도 수준의 변화가 기 설정된 범위를 벗어 나는 경우, 해당 문자열을 시각적으로 변환(예컨대 문자열에 밑줄 또는 기타 강조 표시 등) 하고, 시각적으로 변환된 문자열을 전자 장치의 화면상에 출력할 수도 있다. 또 다른 실시 예에 의하면, 전자 장치는 신뢰도 수준 또는 신뢰도 수준의 변화가 기 설정된 범위를 벗어 나는 경우, 해당 문자열에 대한 맞춤법 제안 정보를 더 출력할 수도 있다. 일 실시 예에 의하면, 맞춤법 제안 정보는 해당 문자열에 대한 맞춤법 수정 과정을 수행함에 따라 맞춤법에 맞도록 변환된 문자열을 포함할 수 있 다. 도 5는 일 실시 예에 따른 전자 장치가 음성 인식 서비스를 제공하는 다양한 예를 설명하기 위한 도면이다. 도 5를 참조하여 전자 장치가 사용자 음성 인식 서비스를 제공하는 예를 설명하기로 한다. 일 실시 예에 의하면, 전자 장치는 사용자로부터 '음성 인식 하면 다 꺼'라는 음성 신호를 포함하는 오디오 신호를 획 득할 수 있다. 일 실시 예에 의하면, 전자 장치는 오디오 신호 내 사용자 음성 신호를 소정의 음성 시퀀 스들로 분할할 수 있다. 예를 들어, 전자 장치는 '음성 인식 하면 다 꺼'라는 음성 신호를 전처리함으로 써 제1 음성 시퀀스, 제2 음성 시퀀스, 제3 음성 시퀀스 및 제4 음성 시퀀스로 분할할 수 있다. 일 실시 예에 의하면, 전자 장치가 생성한 제1 내지 제4 음성 시퀀스들은 인접하는 시퀀스 간에 적어도 일부 시퀀스가 중첩될 수 있다. 예를 들어, 제1 음성 시퀀스 및 제2 음성 시퀀스는 '음성 인식' 중 '인'부분에 대한 시퀀스가 중첩될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 사용자 음성 신호를 적어도 일부 시퀀스가 중첩되는 소정의 시퀀스들로 분할하고, 분할된 시 퀀스들에 대해 실시간으로 음성 인식을 수행할 수 있다. 전자 장치는 분할된 시퀀스들에 실시간 음성 인 식을 수행함과 함께, 음성 인식 결과에 대한 정확도를 측정할 수 있다. 예를 들어, 전자 장치는 제1 음성 시퀀스를 음향 모델에 입력함에 따라 음향 모델로부터 제1 음성 시퀀스에 대응되는 음성 정보 및 제1 음성 시퀀스가 해당 음성 정보에 대응할 확률 값을 정확도 정보로 획득할 수 있다. 일 실시 예에 의하면, 전자 장치는 메모리 내 정확도 측정부에 대응되는 인스트럭션을 수행함으로써, 제1 음성 시퀀스에 대응되는 음성 정보에 대한 정확도를 식별할 수도 있다. 일 실시 예에 의하면, 전자 장치는 각 음성 시퀀스에 대한 정확도를 측정하고, 측정된 각 음성 시퀀스에 대한 정확도 정보에 기초하여 신뢰도 수준을 결정할 수 있다. 전자 장치는 인접한 음성 시퀀스들 각각에 대해 결정된 신뢰도 수준의 차이 값이 소정의 유의 수준을 벗어나는 경우, 신뢰도 수준 차이 값이 소정의 유의 수준을 벗어난, 음성 시퀀스들(예컨대 '음성' '인식' '하면' '다 꺼') 각각에 대한 후순위 인식 문자열들(509, 510)을 인식 문자열과 함께 출력할 수 있다. 또한, 일 실시 예에 의하면 전자 장치는 문자열들에 대한 신 뢰도 수준 차이값이 유의 수준을 벗어나는 정도에 기초하여, 후순위 인식 문자열들을 다른 시각적인 방법으로 표시할 수도 있다. 예를 들어, 전자 장치는 '음성' 및 '인식'에 대한 제1 신뢰도 수준 차이 값이, '하면' 및 '다 꺼'에 대한 제2 신뢰도 수준 차이 값 보다 작은 경우, 제1 신뢰도 수준 차이 값에 대한 제1 후순위 인식 문자열들보다, 제2 신뢰도 수준 차이 값에 대한 제2 후순위 인식 문자열들을 시각적으로 더 강조하여 표시할 수도 있다. 이하에서는 또 다른 실시 예에 따라 전자 장치가 오디오 신호 내 사용자 음성 신호에 대한 음성 인식 과 정을 수행하는 예를 설명하기로 한다. 예를 들어, 전자 장치는 '음성 인식 하면 다 꺼'라는 사용자 음성 신호를 포함하는 오디오 신호를 획득하고, 획득된 오디오 신호 내 사용자 음성 신호를 소정의 음성 시퀀스들로 분할할 수 있다. 일 실시 예에 의하면, 전자 장치는 '음성'에 대한 제1 음성 시퀀스를 생성하고, ' 음성의'에 대한 제2 음성 시퀀스를 생성하며, '음성 인식 하면'에 대한 제3 음성 시퀀스를 생성하고, '음성 인식 하면 다 꺼'에 대한 제4 음성 시퀀스를 생성할 수 있다. 전자 장치는 인공 지능 모델을 이용하여 상기 각 음성 시퀀스에 대한 음성 인식을 수행할 수 있다. 또한, 전자 장치는 인공 지능 모델을 이용하여 각 음성 시퀀스에 대한 음성 인식을 수행함과 함께, 각 음성 시 퀀스에 대한 잡음 정보, 정확도 정보(예컨대 신경망 정확도) 또는 후순위 인식 문자열(예컨대 후순위 결과값)을 결정할 수 있다. 전자 장치는 각 음성 시퀀스에 대한 잡음 정보, 정확도 정보 또는 후순위 인식 문자열에 대한 정보 중 적어도 하나에 기초하여 각 음성 시퀀스에 대한 신뢰도 수준을 결정하고, 결정된 신뢰도 수준 각 각이 소정의 유의 수준 이상인지 여부를 식별할 수 있다. 전자 장치는 신뢰도 수준이 유의 수준 이상으로 식별되는 문자열(예컨대 '하면' 다 꺼')을 식별하고, 식별된 문자열 각각에 대한 후순위 인식 문자열들(예컨대 '화면' '관련' 또는 '특허')을 더 출력할 수도 있다. 도 6은 일 실시 예에 따른 전자 장치가 음성 인식결과로써 문자열, 타임라인 및 후순위 인식 문자열을 출력하는 예를 설명하기 위한 도면이다. 전자 장치는 도 5에서 상술한 바와 같이, 신뢰도 수준이 낮은 것으로 식별되는 문자열들에 후순위 인식 문자열들을 표시함과 함께 타임 라인들(602, 604, 622, 624)들을 더 표시할 수도 있다. 또한, 전자 장치는 문자열들에 대한 신뢰도 수준 값이 소정의 유의 수준을 벗어나는 정도에 기초하여, 소정의 유의 수준을 더 많이 벗어나는 문자열들에 대한 후순위 문자열들(610, 612)을, 유의 수준을 덜 벗어나는 문자열들에 대한 후순 위 문자열(606, 608)들 보다 시각적으로 더 강조(예컨대 볼드라인을 그리거나, 더 채도가 높은 경계를 후순위 문자열들 주변에 표시)하여 표시할 수도 있다. 도 7은 일 실시 예에 따른 전자 장치의 블록도이다. 도 8은 또 다른 실시 예에 따른 전자 장치의 블록도이다. 도 7에 도시된 바와 같이, 일 실시 예에 따른 전자 장치는 프로세서 및 메모리를 포함할 수 있다. 그러나 도시된 구성 요소가 모두 필수구성요소인 것은 아니다. 도시된 구성요소보다 많은 구성요소에 의 해 전자 장치가 구현될 수도 있고, 그보다 적은 구성요소에 의해서도 전자 장치는 구현될 수 있다. 예를 들어, 도 8에 도시된 바와 같이, 일 실시 예에 따른 전자 장치는 사용자 입력 인터페이스, 네 트워크 인터페이스, 마이크, 디스플레이, 스피커를 더 포함할 수도 있다. 프로세서는 메모리내 하나 이상의 인스트럭션을 실행함으로써 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써 사용자 입력 인터페이스, 네트워크 인터페이스, 마이크, 디스플레이, 스피커 등을 전반 적으로 제어할 수 있다. 또한, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으 로써 도 1 내지 도 6에 기재된 전자 장치의 기능을 수행할 수 있다. 일 실시 예에 의하면, 프로세서는 사용자 음성 신호를 포함하는 오디오 신호를 획득하고, 상기 획득된 오 디오 신호를 전처리하고, 상기 전처리된 오디오 신호가 입력되면 상기 음성 신호에 대응되는 문자열을 출력하는 인공 지능 모델에 상기 전처리된 오디오 신호를 입력함으로써, 상기 음성 신호에 대응되는 문자열을 획득하고, 상기 인공 지능 모델로부터 획득되는 상기 문자열에 대한 정확도 정보에 기초하여, 상기 문자열에 대한 신뢰도 수준을 결정하고, 상기 문자열 및 상기 신뢰도 수준을 함께 출력할 수 있다. 일 실시 예에 의하면, 프로세서는 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 기 설정된 범위를 벗어나는지 여부를 식별하고, 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설정된 범위를 벗어나 는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대한 후순위 인식 문자열을 더 출력할 수 있다. 일 실시 예에 의하면, 적어도 하나의 프로세서는 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설 정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대응되는 타임 라인을 더 출력할 수 있다. 일 실시 예에 의하면, 적어도 하나의 프로세서는 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설 정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열을 시각적으로 변환하고, 상기 시각적으로 변환된 문자열을 출력할 수 있다. 일 실시 예에 의하면, 적어도 하나의 프로세서는 상기 신뢰도 수준 또는 상기 신뢰도 수준의 변화가 상기 기 설 정된 범위를 벗어나는 경우, 상기 기 설정된 범위를 벗어나는 것으로 식별되는 문자열에 대한 맞춤법 제안 정보 를 더 출력할 수 있다. 일 실시 예에 의하면, 적어도 하나의 프로세서는 상기 인공 지능 모델의 특성에 기초하여 상기 획득된 오디오 신호의 포맷을 미리 설정된 포맷으로 변환할 수 있다. 일 실시 예에 의하면, 상기 적어도 하나의 프로세서는 상기 사용자 음성 신호에 대응되는 음성 정보를 상기 적 어도 하나의 언어 모델에 입력함으로써, 상기 적어도 하나의 언어 모델 각각에서 출력되는 후보 문자열들을 획 득하고, 상기 적어도 하나의 언어 모델들에서 출력된 후보 문자열들의 빈도수에 기초하여, 상기 후보 문자열들 중, 하나의 후보 문자열을 획득할 수 있다. 일 실시 예에 의하면, 상기 적어도 하나의 프로세서는 상기 오디오 신호 내 노이즈 강도를 식별하고, 상기 음향 모델로부터 상기 사용자 음성 신호가 상기 음성 정보에 해당할 확률 값을 획득하고, 상기 노이즈 강도 및 상기 음성 정보에 해당할 확률 값을 상기 정확도 정보로 획득하고, 상기 정확도 정보에 기초하여 상기 문자열에 대한 신뢰도 수준을 결정할 수 있다. 메모리는 전자 장치의 동작을 제어하기 위한 하나 이상의 인스트럭션(instruction)을 포함할 수 있 다. 또한, 메모리는 음성 인식 서비스를 활성화 하기 위해 하나 이상의 언어 모델, 음향 모델, 자동 음성 인식 모델을 포함할 수 있다. 또한, 메모리 음성 인식을 위해 필요한 인공 지능 모델 또는 신경망 모델에 대한 정보를 저장할 수 있다. 일 실시 예에 의하면, 메모리는 예를 들어, 플래시 메모리 타입(flash memory type), 하드디스크 타입 (hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들 어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있으 나, 이에 제한되지 않는다. 사용자 입력 인터페이스는 전자 장치의 동작을 제어하기 위한 사용자 입력을 수신할 수 있다. 예를 들어, 사용자 입력 인터페이스는, 키 패드(key pad), 돔 스위치(dome switch), 터치 패드(접촉식 정전 용량 방 식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 네트워크 인터페이스는 서버와의 통신을 위한 하나 이상의 통신 모듈을 포함할 수 있다. 예를 들어, 네트워크 인터페이스는, 근거리 통신부 또는 이동 통신부 중 적어도 하나를 포함할 수 있다. 예를 들어, 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부등을 포함할 수 있으나, 이에 제한되는 것은 아 니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한다. 여 기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다양한 형 태의 데이터를 포함할 수 있다. 마이크는 사용자의 음성을 포함하는 오디오 신호를 수신할 수 있다. 또한, 마이크는 사용자의 음성 외에 복수의 집음 원들로부터 발생된 잡음 신호를 포함하는 오디오 신호를 수신할 수도 있다. 마이크는 획득한 오디오 신호를 프로세서로 전달함으로써, 사용자 음성 신호에 대응되는 문자열을 출력하도록 할 수 있다. 스피커는 오디오 신호 내 사용자의 음성을 인식한 결과를 오디오 신호로 출력할 수 있다. 예를 들어, 스 피커는 전자 장치에서 수행되는 기능(예를 들어, 호신호 수신음, 메시지 수신음, 알림음)과 관련된 신호를 소리로 출력할 수 있다. 디스플레이는 전자 장치에서 처리되는 정보를 표시 출력할 수 있다. 예를 들어, 디스플레이 는, 오디오 신호 내 사용자의 음성을 인식한 결과를 텍스트 문자열로 표시할 수 있다. 또한, 디스플레이 는 문자열 외에, 신뢰도 수준, 타임 라인, 맞춤법 제안 정보, 부가 정보(예컨대 잡음 정보, 정확도 정보, 후순 위 인식 문자열)에 대한 정보를 더 표시할 수도 있다. 도 9는 또 다른 실시 예에 따른 전자 장치가 음성 인식 서비스를 제공하는 과정을 설명하기 위한 도면이다. 일 실시 예에 의하면, 전자 장치는 오디오 신호 내 사용자 음성 신호에 대응되는 사용자 음성 입력 을 식별할 수 있다. 전자 장치는 음성 입력을 신호 전처리기를 이용하여 전처리할 수 있다. 신 호 전처리기에 의해 전처리된 음성 입력은 음향 모델에 입력됨으로써, 음성 입력에 대한 음성 정보로 출력될 수 있다. 음향 모델에서 출력된 음성 정보는 언어 모델로 입력되고, 언어 모델을 통하여 복수의 후보 문자열들이 출력될 수 있다. 전자 장치는 후보 문자열들 중 빈도수에 기초하여 선택되는 하 나의 문자열을 텍스트 문자열로 출력할 수 있다. 도 9에 도시된 신호 전처리기, 음향 모델 및 언어 모델은 전자 장치의 메모리 내 하나 이상의 인스트럭션의 형태로 저장될 수 있으며, 프로세서에 의해 액세스됨으로써, 신호 전처리, 음성 정보 출력 및 텍 스트 문자열 출력과 같은 기능을 수행하는데 사용될 수 있다. 일 실시 예에 의하면, 전자 장치는 정확도 측정부를 더 포함할 수 있다. 예를 들어, 정확도 측정부는 전자 장치의 메모리에 인스트럭션으로 저 장되어 정확도를 측정하는 기능을 수행하는 모듈일 수 있다. 일 실시 예에 의하면, 정확도 측정부는 노이 즈 강도 측정기, 정확도 정보 획득기 및 n순위 출력 값 획득기을 포함할 수 있다. 일 실시 예에 의하면, 전자 장치는 노이즈 강도 측정기를 이용하여 음성 입력 에 대한 노이즈 의 강도를 측정할 수 있다. 전자 장치는 정확도 정보 획득기를 이용하여, 음향 모델에서 사용 자 음성 신호에 대응되는 음성 정보와 함께 출력되는, 음성 정보에 대응될 확률 값을 정확도 정보로 획득할 수 있다. 또한, 전자 장치는 n 순위 출력 값 획득기를 이용하여 언어 모델로부터 복수의 후보 문 자열들을 획득하고, 후보 문자열들에 대한 n순위 랭크 내에 포함되는 소정의 후보 문자열들에 대한 정보를 획득 할 수 있다. 전자 장치는 정확도 측정부에서 측정되는 정확도 정보에 기초하여, 음성 인식 결과에 대한 신뢰도 수준을 결정할 수 있다. 전자 장치는 신뢰도 수준을 함께 표시함으로써 사용자로 하여금, 음 성 인식 결과가 얼마나 신뢰도 있게 수행되었는지 여부를 나타낼 수 있다. 일 실시예에 따른 전자 장치가 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있 다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프 트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같 은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함 한다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매 체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체 를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2021-0094768", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따른, 전자 장치가 음성 인식 정확도에 기초하여 음성 인식 서비스를 제공하는 방법을 개 략적으로 나타내는 도면이다. 도 2는 일 실시 예에 따른 전자 장치가 인공 지능 모델을 이용하여 음성 인식 서비스를 제공하는 방법의 흐름도 이다. 도 3은 일 실시 예에 따른 전자 장치가 음성 인식 결과에 대한 신뢰도 수준에 기초하여 후순위 인식 문자열을 출력하는 방법의 흐름도이다. 도 4는 일 실시 예에 따른 전자 장치가 음성 인식 결과로써 문자열, 타임라인 및 후순위 인식 문자열을 출력하 는 예를 설명하기 위한 도면이다. 도 5는 일 실시 예에 따른 전자 장치가 음성 인식 서비스를 제공하는 다양한 예를 설명하기 위한 도면이다. 도 6은 일 실시 예에 따른 전자 장치가 음성 인식결과로써 문자열, 타임라인 및 후순위 인식 문자열을 출력하는 예를 설명하기 위한 도면이다. 도 7은 일 실시 예에 따른 전자 장치의 블록도이다. 도 8은 또 다른 실시 예에 따른 전자 장치의 블록도이다. 도 9는 또 다른 실시 예에 따른 전자 장치가 음성 인식 서비스를 제공하는 과정을 설명하기 위한 도면이다."}
