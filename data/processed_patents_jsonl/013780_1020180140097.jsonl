{"patent_id": "10-2018-0140097", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0056137", "출원번호": "10-2018-0140097", "발명의 명칭": "영상 및 오디오 처리 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "조석환"}}
{"patent_id": "10-2018-0140097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디스플레이;오디오 출력부;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서; 를 포함하고, 상기 프로세서는, 상기 하나 이상의 인스럭션을 실행함으로써, 장면 단위로 컨텐트의 영상 신호를 분석하여 상기 영상 신호의 특성 정보를 검출하고, 상기 장면 단위로 상기 컨텐트의 오디오 신호를 분석하여 상기 오디오 신호의 특성 정보를 검출하고, 상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보를 이용하여 상기 장면 단위로 영상 신호를 제어하여 상기 디스플레이로 출력하고, 상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보를 이용하여 상기 장면 단위로 오디오 신호를 제어하여 상기 오디오 출력부로 출력하는, 영상 및 오디오 처리 장치."}
{"patent_id": "10-2018-0140097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보에 기초하여 상기 장면 단위로 상기 영상 신호에대한 블랙 이퀄라이저 기능, 명암비 및 색상 채도 기능 중 적어도 하나를 제어하고, 상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보에 기초하여 상기 장면 단위로 상기 오디오 신호에대한 고도감 생성 및 스테이지 확장 기능 및 사운드 이퀄라이저 적용 기능 중 적어도 하나를 제어하는, 영상 및 오디오 처리 장치."}
{"patent_id": "10-2018-0140097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 영상 신호의 특성 정보는 상기 영상 신호의 밝기 정보, 색상 정보, 명암비 정보 및 모션 정보 중 적어도 하나를 포함하고, 상기 오디오 신호의 특성 정보는 오디오 객체의 위치 정보, 음성 정보, 음악 정보, 및 효과 음 정보 중 적어도 하나를 포함하는 영상 및 오디오 처리 장치."}
{"patent_id": "10-2018-0140097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 영상 및 오디오 처리 장치는, 상기 영상 및 오디오 처리 장치의 외부의 조도 정보를 검출하는 조도 센서를 더 포함하고, 상기 프로세서는, 상기 하나의 이상의 인스트럭션을 실행함으로써, 상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보에 따라 상기 영상 신호를 제어할 때, 상기 조도정보를 더 이용하여 상기 영상 신호의 밝기, 명암비 및 색상의 채도 중 적어도 하나를 제어하는 것을 특징으로하는 영상 및 오디오 처리 장치."}
{"patent_id": "10-2018-0140097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 하나 이상의 뉴럴 네트워크를 이용한 학습 모델을 이용하여, 상기 장면 단위로 상기 컨텐트의 영상 신호와 오디오 신호를 각각 분석하고, 상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보를 각각 검출하고, 상기공개특허 10-2020-0056137-3-영상 신호 및 오디오 신호를 제어하는 영상 및 오디오 처리 장치."}
{"patent_id": "10-2018-0140097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "영상 및 오디오 처리 장치의 동작 방법에 있어서, 상기 영상 및 오디오 처리 장치에 의해 하나 이상의 인스트럭션을 실행하여, 장면 단위로 컨텐트의 영상 신호를분석하여 상기 영상 신호의 특성 정보를 검출하는 단계; 상기 영상 및 오디오 처리 장치에 의해 상기 장면 단위로 상기 컨텐트의 오디오 신호를 분석하여 상기 오디오신호의 특성 정보를 검출하는 단계; 상기 영상 및 오디오 처리 장치에 의해 상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보를 이용하여 상기 장면 단위로 영상 신호를 제어하여 상기 영상 및 오디오 처리 장치의 디스플레이를 통해 출력하는단계; 및상기 영상 및 오디오 처리 장치에 의해 상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보를 이용하여 상기 장면 단위로 오디오 신호를 제어하여 상기 영상 및 오디오 처리 장치의 오디오 출력부를 통해 출력하는단계를 포함하는. 영상 및 오디오 처리 장치의 동작 방법."}
{"patent_id": "10-2018-0140097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 상기 영상 및 오디오 처리 장치의 동작 방법은, 상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보에 기초하여 상기 장면 단위로 상기 영상 신호에대한 블랙 이퀄라이저 기능, 명암비 및 색상 채도 기능 중 적어도 하나를 제어하는 단계; 및 상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보에 기초하여 상기 장면 단위로 상기 오디오 신호에대한 고도감 생성 및 스테이지 확장 기능 및 사운드 이퀄라이저 적용 기능 중 적어도 하나를 제어하는 단계를더 포함하는, 영상 및 오디오 처리 장치의 동작 방법."}
{"patent_id": "10-2018-0140097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6 항에 있어서, 상기 영상 신호의 특성 정보는 상기 영상 신호의 밝기 정보, 색상 정보, 명암비 정보 및 모션 정보 중 적어도 하나를 포함하고, 상기 오디오 신호의 특성 정보는 오디오 객체의 위치 정보, 음성 정보, 음악 정보, 및 효과 음 정보 중 적어도 하나를 포함하는 영상 및 오디오 처리 장치의 동작 방법."}
{"patent_id": "10-2018-0140097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 6 항에 있어서, 상기 영상 및 오디오 처리 장치의 동작 방법은,상기 영상 신호의 특성 정보와 상기 오디오 신호의 특성 정보에 따라 상기 영상 신호를 제어할 때, 상기 영상및 오디오 처리 장치에 의해 검출된 영상 및 오디오 처리 장치의 외부의 조도 정보를 더 이용하여 상기 영상 신호의 밝기, 명암비 및 색상의 채도중 적어도 하나를 제어하는 것을 특징으로 하는 영상 및 오디오 처리 장치."}
{"patent_id": "10-2018-0140097", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 6 항에 기재된 영상 및 오디오 처리 장치의 동작 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2018-0140097", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 장면 단위로 컨텐트의 영상 신호와 오디오 신호를 각각 분석하여 얻은 특성 정보를 이용하여 장면의 화질 및 사운드를 동적으로 제어할 수 있는 영상 및 오디오 처리 장치 및 그 동작 방법에 관련된 것이다. 일 실시예에 따른 영상 및 오디오 처리 장치는, 디스플레이, 오디오 출력부, 하나 이상의 인스트럭션을 저장하는 (뒷면에 계속)"}
{"patent_id": "10-2018-0140097", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 다양한 실시예들은 영상 및 오디오 처리 장치 및 그 동작 방법에 관한 것으로서, 보다 상세하게는, 컨텐 트의 특성에 따라 화질과 사운드를 적응적으로 제공할 수 있는 영상 및 오디오 처리 장치 및 그 동작 방법에 관 한 것이다."}
{"patent_id": "10-2018-0140097", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "티브이(TV)와 같은 영상 및 오디오 처리 장치의 기능이 스마트해지면서, 영상 및 오디오 처리 장치를 이용하여 다양한 컨텐트를 즐기려는 사용자가 증가하고 있다. 그러나, 게임과 같은 컨텐트를 즐기려는 사용자들은 게임을 보다 더 잘하기 위하여, 게임 컨텐트에 따라 화질 및 사운드를 적응적으로 지원할 수 있는 영상 및 오디오 처리 장치가 필요하다. 예를 들어, FPS(First Person Shooter) 게임의 경우에, 사용자는 어두운 영역에 숨어 있는 적이나 게임 아이템을 빨리 발견하기 위해 영상이 왜곡되더라고 시인성을 향상시키면서 미세한 발자국 사운드 등과 같은 효과음을 크게 들을 수 있는 기능을 제공 하는 영상 및 오디오 처리 장치가 필요하다. 스포츠 게임의 경우에, FPS 게임에서와 같이 영상을 왜곡시켜 시인 성을 향상시킬 경우에, 오히려 화질이 저하되기 때문에 사용자는 영상을 왜곡시키지 않으면서 제작자가 의도하 는 사운드를 충실하게 전달할 수 있는 기능을 제공하는 영상 및 오디오 처리 장치가 필요하다. 이와 같이 게임 컨텐트에 따라 사용자가 원하는 화질과 사운드의 조건이 다른 것은 게임 컨텐트에 따라 사용자의 몰입감을 극대 화할 수 있는 화질 및 사운드 조건이 상이하기 때문이다. 따라서, 컨텐트의 특성에 따라 화질 및 사운드를 동적으로 제공할 수 있는 영상 및 오디오 처리 장치가 요구되 고 있다."}
{"patent_id": "10-2018-0140097", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 다양한 실시 예들은 장면(scene) 단위로 컨텐트의 영상 신호 및 오디오 신호를 분석한 결과를 이용하여 컨텐트의 영상 신호 및 오디오 신호를 동적으로 제어함으로써, 컨텐트에 대한 사용자의 몰입감을 극대화 할 수 있는 화질 및 사운드를 제공할 수 있는 영상 및 오디오 처리 장치와 그 동작 방법을 제공하기 위한 것이다. 개시된 다양한 실시 예들은 주변 환경 정보와 장면 단위로 컨텐트의 영상 신호 및 오디오 신호를 분석한 결과를 이용하여 컨텐트의 영상 신호 및 오디오 신호를 동적으로 제어함으로써, 컨텐트에 대한 사용자의 몰입감을 극대 화 할 수 있는 화질 및 사운드를 제공할 수 있는 영상 및 오디오 처리 장치와 그 동작 방법을 제공하기 위한 것 이다."}
{"patent_id": "10-2018-0140097", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시 예에 따른 영상 및 오디오 처리 장치는, 디스플레이; 오디오 출력부; 하나 이상의 인스트럭션을 저장하 는 메모리; 및 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 프로세서; 를 포함하고, 프로세서는, 하나 이상의 인스럭션을 실행함으로써, 장면 단위로 컨텐트의 영상 신호를 분석하여 영상 신호의 특성 정보를 검출하 고, 장면 단위로 컨텐트의 오디오 신호를 분석하여 오디오 신호의 특성 정보를 검출하고, 영상 신호의 특성 정 보와 오디오 신호의 특성 정보를 이용하여 장면 단위로 영상 신호를 제어하여 디스플레이로 출력하고, 영상 신 호의 특성 정보와 오디오 신호의 특성 정보를 이용하여 장면 단위로 오디오 신호를 제어하여 오디오 출력부로 출력할 수 있다. i 일 실시 예에 따른 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 영상 신호의 특성 정보와 오디오 신호 의 특성 정보에 기초하여 장면 단위로 영상 신호에 대한 블랙 이퀄라이저 기능, 명암비 및 색상 채도 기능중 적 어도 하나를 제어하고, 영상 신호의 특성 정보와 오디오 신호의 특성 정보에 기초하여 장면 단위로 오디오 신호 에 대한 고도감 생성 및 스테이지 확장 기능 및 사운드 이퀄라이저 적용 기능 중 적어도 하나를 제어할 수 있다. 일 실시 예에 따른 영상 신호의 특성 정보는 영상 신호의 밝기 정보, 색상 정보, 명암비 정보 및 모션 정보 중 적어도 하나를 포함하고, 일 실시 예에 따른 오디오 신호의 특성 정보는 오디오 객체의 위치 정보, 음성 정보, 음악 정보, 및 효과 음 정보 중 적어도 하나를 포함할 수 있다. 일 실시 예에 따른 영상 및 오디오 처리 장치는 영상 및 오디오 처리 장치의 외부의 조도 정보를 검출하는 조도 센서를 더 포함하고, 일 실시 예에 따른 프로세서는, 하나의 이상의 인스트럭션을 실행함으로써, 영상 신호의 특성 정보와 오디오 신호의 특성 정보에 따라 영상 신호를 제어할 때, 조도 정보를 더 이용하여 영상 신호의 밝 기, 명암비 및 색상의 채도중 적어도 하나를 제어할 수 있다. 일 실시 예에 따른 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 하나 이상의 뉴럴 네트워크를 이용한 학습 모델을 이용하여, 장면 단위로 컨텐트의 영상 신호와 오디오 신호를 각각 분석하고, 영상 신호의 특성 정 보와 오디오 신호의 특성 정보를 각각 검출하고, 영상 신호 및 오디오 신호를 제어할 수 있다. 일 실시 예에 따른 영상 및 오디오 처리 장치의 동작 방법은, 영상 및 오디오 처리 장치에 의해 하나 이상의 인 스트럭션을 실행하여, 장면 단위로 컨텐트의 영상 신호를 분석하여 영상 신호의 특성 정보를 검출하는 단계; 영 상 및 오디오 처리 장치에 의해 장면 단위로 컨텐트의 오디오 신호를 분석하여 오디오 신호의 특성 정보를 검출 하는 단계; 영상 및 오디오 처리 장치에 의해 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 이용하여 장 면 단위로 영상 신호를 제어하여 영상 및 오디오 처리 장치의 디스플레이를 통해 출력하는 단계; 및 영상 및 오 디오 처리 장치에 의해 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 이용하여 장면 단위로 오디오 신호 를 제어하여 영상 및 오디오 처리 장치의 오디오 출력부를 통해 출력하는 단계를 포함할 수 있다. 일 실시 예에 따른 컴퓨터로 판독 가능한 기록매체는, 상술된 방법을 실행시키기 위한 프로그램을 기록한 컴퓨 터로 읽을 수 있는 기록매체일 수 있다."}
{"patent_id": "10-2018-0140097", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 또한, 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에서 사용되는 용어는, 본 개시에서 언급되는 기능을 고려하여 현재 사용되는 일반적인 용어로 기재되었 으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 다양한 다른 용어를 의미할 수 있다. 따라서 본 개시에서 사용되는 용어는 용어의 명칭만으로 해석되어서는 안되며, 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 해석되어야 한다. 또한, 본 개시에서 사용된 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것이며, 본 개시를 한정하려는 의도로 사용되는 것이 아니다. 단수의 표현은 문맥상 명백하게 단수를 뜻하지 않는 한, 복수의 의미를 포함한다. 또한, 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연 결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본 명세서, 특히, 특허 청구 범위에서 사용된 “상기” 및 이와 유사한 지시어는 단수 및 복수 모두를 지시하는 것일 수 있다. 또한, 본 개시에 따른 방법을 설명하는 단계들의 순서를 명백하게 지정하는 기재가 없다면, 기재 된 단계들은 적당한 순서로 행해질 수 있다. 기재된 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아니 다.본 명세서에서 다양한 곳에 등장하는 \"일부 실시예에서\" 또는 \"일 실시예에서\" 등의 어구는 반드시 모두 동일한 실시예를 가리키는 것은 아니다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기 술을 채용할 수 있다. “매커니즘”, “요소”, “수단” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 일 실시예에 따른 영상 및 오디오 처리 장치가 장면 단위로 컨텐트의 영상 신호 및 오디오 신호를 각각 분석하여 얻은 장면 특성에 따라 특화된 영상 신호와 오디오 신호를 출력하는 예시를 나타내는 도면이다. 도 1을 참조하면, 영상 및 오디오 처리 장치는 대화면 TV일 수 있으나, 이에 한정되지 않으며, 디스플레이 를 포함하는 전자 장치로 구현될 수 있다. 예를 들어, 영상 및 오디오 처리 장치는 휴대폰, 태블릿 PC, 디 지털 카메라, 캠코더, 노트북 컴퓨터(laptop computer), 태블릿 PC, 데스크탑, 전자책 단말기, 디지털 방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, MP3 플레이어, 웨 어러블 디바이스(wearable device), 게이밍 디스플레이 모니터 등과 같은 다양한 전자 장치로 구현될 수 있다. 또한, 영상 및 오디오 처리 장치는 고정형 또는 이동형일 수 있으며, 디지털 방송 수신이 가능한 디지털 방송 수신기일 수 있다. 영상 및 오디오 처리 장치는 평면(flat) 디스플레이 장치뿐만 아니라, 곡률을 가지는 화면인 곡면(curved) 디스플레이 장치 또는 곡률을 조정 가능한 가변형(flexible) 디스플레이 장치로 구현될 수 있다. 영상 및 오디 오 처리 장치의 출력 해상도는 예를 들어, HD(High Definition), Full HD, Ultra HD, 또는 Ultra HD 보다 더 선명한 해상도를 포함할 수 있다. 영상 및 오디오 처리 장치는 제어 장치에 의해 제어될 수 있다. 제어 장치는 리모컨, 휴대폰, 또는 게임 패드와 같이 영상 및 오디오 처리 장치를 제어하기 위한 다양한 형태의 장치로 구현될 수 있다. 또한, 제어 장치는 적외선(infrared) 또는 블루투스(bluetooth)를 포함하는 근거리 무선 통신을 이용하여 영상 및 오디오 처리 장치를 제어할 수 있다. 제어 장치는 유선 통신을 이용하여 영상 및 오디오 처 리 장치를 제어할 수 있다. 제어 장치는 구비된 키(버튼을 포함), 터치 패드(touchpad), 사용자의 음성을 수신할 수 있는 마이크(도시 되지 아니함), 제어 장치의 모션 인식이 가능한 센서(도시되지 아니함) 중 적어도 하나를 이용하여 영상 및 오디오 처리 장치의 기능을 제어할 수 있다. 제어 장치는 게임 전용 패드 형태로 구성될 수 있다. 제어 장치는 영상 및 오디오 처리 장치의 전원을 온(on)시키거나 오프(off)시키기 위한 전원 온/오프 버튼을 포함할 수 있다. 또한, 제어 장치는 사용자 입력에 의해 영상 및 오디오 처리 장치의 채널 변 경, 음량 조정, 지상파 방송/케이블 방송/위성 방송 선택, 또는 환경 설정(setting)을 할 수 있다. 또한, 제어 장치가 게임 전용 패드 또는 휴대폰인 경우에, 제어 장치는 게임 컨텐트를 영상 및 오디 오 처리 장치로 전송할 수 있고, 영상 및 오디오 처리 장치의 게임 컨텐트에 대한 재생 동작을 제어 할 수 있다. 본 명세서의 실시예에서 “사용자”라는 용어는 제어 장치를 이용하여 영상 및 오디오 처리 장치의 기능 또는 동작을 제어하는 사람을 의미하며, 게이머, 시청자, 관리자 또는 설치 기사를 포함할 수 있으나 이로 제한되지 않는다. 일 실시예에 따른, 영상 및 오디오 처리 장치는, 제어 장치의 제어와 관계없이 장면(scene) 단위로 재생되고 있는 컨텐트의 영상 신호와 오디오 신호를 각각 분석하여 영상 신호의 특성 정보와 오디오 신호의 특 성 정보를 검출한다. 영상 및 오디오 처리 장치에 의해 검출된 영상 신호의 특성 정보는 예를 들어, 밝기 정보, 색상 정보, 명 암비 정보 및 모션 정보 중 적어도 하나를 포함할 수 있으나 이로 제한되지 않는다. 영상 및 오디오 처리 장치 에 의해 검출된 오디오 신호의 특성 정보는 오디오 객체의 위치 정보, 음성 정보, 음악 정보 및 효과음 정 보 중 적어도 하나를 포함할 수 있으나 이로 제한되지 않는다. 영상 및 오디오 처리 장치는 검출된 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 이용하여 장면 단위로 영상 신호를 제어하고, 제어된 영상 신호를 영상 및 오디오 처리 장치에 디스플레이한다. 상술한 처리에 의해 영상 및 오디오 처리 장치에 디스플레이되는 영상 신호는 장면 특성에 따라 특화된 화질을 갖 는 영상 신호를 의미한다. 영상 및 오디오 처리 장치는 검출된 영상 신호와 오디오 정보를 이용하여 장면 단위로 오디오 신호를 제어 하고, 제어된 오디오 신호를 영상 및 오디오 처리 장치를 통해 출력한다. 상술한 처리에 의해 영상 및 오 디오 처리 장치를 통해 출력되는 오디오 신호는 장면 특성에 따라 특화된 사운드를 갖는 오디오 신호를 의 미한다. 또한, 영상 및 오디오 처리 장치는 영상 및 오디오 처리 장치의 외부의 주변 조명으로부터 검출 된 조도 정보를 이용하여 장면 단위의 영상 신호의 밝기, 명암비 및 색상의 채도 중 적어도 하나를 제어할 수 있다. 이를 위하여, 영상 및 오디오 처리 장치는 조도 센서를 포함할 수 있다. 도 2는 일 실시예에 따른 영상 및 오디오 처리 장치의 구성을 나타내는 블록도이다. 도 2에 도시된 영상 및 오디오 처리 장치는 도 1에 도시된 영상 및 오디오 처리 장치의 일 실시예일 수 있다. 도 2를 참조하면, 일 실시예에 따른 영상 및 오디오 처리 장치는 메모리, 프로세서, 디스플레이, 및 오디오 출력부를 포함할 수 있다. 그러나, 영상 및 오디오 처리 장치는, 도시된 구성요소보다 많은 구성요소에 의해 구현될 수 있으며, 전술한 예에 한정되지 않는다. 예를 들어, 영상 및 오디 오 처리 장치는 컨텐트를 수신할 수 있는 컨텐트 수신부 또는/및 사용자의 입력을 수신할 수 있는 사용자 입력 수신부를 더 포함할 수 있다. 일 실시예에 따른 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있다. 메모리 는 영상 및 오디오 처리 장치로 입력되거나 영상 및 오디오 처리 장치로부터 출력되는 데이터 (예를 들어, 컨텐트)를 저장할 수 있다. 메모리는 프로세서의 처리 및 제어시 사용될 정보를 저장할 수 있다. 프로세서의 처리 및 제어시 사용될 정보는, 예를 들어, 장면 단위로 특화된 화질 및 사운드를 제 공하기 위한 영상 및 오디오 처리 장치의 설정 정보(setting information)를 포함할 수 있다. 상술한 영상 및 오디오 처리 장치의 설정 정보는, 예를 들어, 영상 신호의 밝기 정보, 영상 신호의 명암비 및 색상의 채도 정보, 및 영상 신호의 모션 정보와 오디오 신호에 포함되어 있는 오디오 객체의 위치 정보, 오 디오 신호에 포함되어 있는 음성 정보, 오디오 신호에 포함되어 있는 음악 정보 및 오디오 신호에 포함되어 있 는 효과음 정보 각각 또는/및 조합에 기초하여 장면의 영상 신호와 오디오 신호를 제어할 수 있는 정보를 포함 할 수 있다. 영상 및 오디오 처리 장치의 설정 정보는, 예를 들어, 장면의 오디오 신호에 포함되어 있는 효과음(예를 들어, 총소리, 관중 소리, 자동차 엔진 소리 등)의 종류를 판단할 수 있는 정보, 장면의 영상 신호의 밝기를 판 단할 수 있는 정보(예를 들어, 어두운 영상으로 판단되는 픽셀 수의 문턱 값), 장면의 오디오 신호의 특성 정보 와 영상 신호의 특성 정보에 기초하여 장면의 영상 신호와 오디오 신호를 제어하는 방법에 관한 정보를 포함할 수 있으나, 설정 정보는 이로 제한되지 않는다. 장면의 영상 신호와 오디오 신호를 제어하는 방법에 대한 정보는, 예를 들어, 장면의 영상 신호의 특성 정보가 영상 신호가 어둡다는 것을 나타내는 정보를 포함하고, 장면의 오디오 신호의 특성 정보가 총소리 효과음을 포 함하는 경우에(예를 들어, FPS(First Person Shooters, 이하 FPS라고 약함) 게임의 장면으로 인식되는 경우에), 장면의 영상 신호의 시인성을 향상시키기 위하여 프로세서가 영상 신호에 대한 블랙 이퀄라이저의 이득 함 수의 이득을 높이면서 명암비 및 색상 채도를 부각시키도록 영상 신호를 제어하고, 사운드 이퀄라이저를 적용하 여 주변 배경 소리를 더욱 크게 들리도록 오디오 신호를 제어할 수 있는 정보를 포함할 수 있다. 장면의 영상 신호와 오디오 신호를 제어하는 방법에 대한 정보는, 예를 들어, 장면의 영상 신호의 특성 정보가 영상 신호가 밝다는 것을 나타내는 정보를 포함하고, 장면의 오디오 신호의 특성 정보가 총소리 효과음을 포함 하는 경우에(예를 들어, FPS 게임의 장면으로 인식되는 경우에), 프로세서가 장면의 영상 신호에 대한 블 랙 이퀄라이저의 이득 함수의 이득을 최소화시키면서 명암비 및 색상 채도만을 부각시키도록 영상 신호를 제어 하고, 사운드 이퀄라이저를 적용하여 장면의 주변 배경 소리가 생생하게 들리도록 오디오 신호를 제어할 수 있 는 정보를 포함할 수 있다. 장면의 영상 신호와 오디오 신호를 제어하는 방법에 대한 정보는, 예를 들어, 장면의 영상 신호의 특성 정보가 영상 신호가 밝다는 것을 나타내는 정보를 포함하고, 장면의 오디오 신호의 특성 정보가 1인의 음성 신호를 포 함하는 경우에(예를 들어, 일반 게임의 장면으로 인식되는 경우에), 프로세서가 장면의 영상 신호에 대한 블랙 이퀄라이저 기능을 수행하지 않고 명암비 및 색상 채도를 부각시키는 정도를 낮추도록 영상 신호를 제어하 고, 사운드 이퀄라이저를 적용하여 효과음이나 배경 음을 강조할 수 있도록 오디오 신호를 제어하기 위한 정보 를 포함할 수 있다. 장면의 영상 신호와 오디오 신호를 제어하는 방법에 대한 정보는, 예를 들어, 장면의 영상 신호의 특성 정보가 운동장 잔디 색깔을 나타내는 색상 정보를 포함하고, 장면의 오디오 신호의 특성 정보가 관중 소리를 포함하는 경우에(예를 들어, 스포츠 게임의 장면으로 인식되는 경우에), 프로세서가 장면의 영상 신호에 대한 블랙 이퀄라이저 기능을 수행하지 않고 명암비 및 색상의 채도를 부각시켜 잔디 색깔을 생생하게 해주면서 유니폼 구 분력을 키워줄 수 있도록 영상 신호를 제어하고, 관중들의 함성에 둘러싸인 듯한 사운드 경험을 제공할 수 있도 록 수평면 음상 확장, 스테이지 확장, 및 사운드 이퀄라이저를 적용하여 오디오 신호를 제어하기 위한 정보를 포함할 수 있다. 장면의 영상 신호와 오디오 신호를 제어하는 방법에 대한 정보는, 예를 들어, 장면의 영상 신호의 특성 정보가 많은 모션 정보와 밝은 화면을 나타내는 정보를 포함하고, 장면의 오디오 신호의 특성 정보가 자동차 엔진 소리 를 포함하는 경우에(예를 들어, 레이싱 게임의 장면으로 인식되는 경우에), 프로세서가 장면의 영상 신호 에 대한 블랙 이퀄라이저 기능을 수행하지 않고 명암비 및 색상 채도를 부각시켜 자동차와 트랙 배경이 생생하 다고 느낄 수 있도록 영상 신호를 제어하고, 자동차 엔진 음과 같은 저대역 신호를 강화할 수 있도록 사운드 이 퀄라이저를 적용하여 오디오 신호를 제어하기 위한 정보를 포함할 수 있다. 장면의 영상 신호와 오디오 신호를 제어하는 방법에 대한 정보는, 예를 들어, 장면의 영상 신호의 특성 정보가 많은 모션 정보와 어두운 화면(예를 들어, 터널을 통과하는 장면)을 나타내는 정보를 포함하고, 장면의 오디오 신호의 특성 정보가 자동차 엔진 소리를 포함하는 경우에(예를 들어, 레이싱 게임의 장면으로 인식되는 경우 에), 프로세서가 장면의 영상 신호에 대한 블랙 이퀄라이저 기능을 적용하여 화면을 밝게 해주면서(또는 시인성을 향상시키면서), 명암비 및 색상의 채도를 부각시켜 자동차와 트랙 배경이 생생하다고 느낄수 있도록 영상 신호를 제어하고, 자동차 엔진 음과 같은 저대역 신호를 강화할 수 있도록 사운드 이퀄라이저를 적용하여 오디오 신호를 제어하기 위한 정보를 포함할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory), SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 일 실시예에 따른 프로세서는, 메모리에 저장된 하나 이상의 인스트럭션을 실행하여, 디스플레이 와 오디오 출력부를 통해 재생될 컨텐트에 대해 장면 단위로 컨텐트의 영상 신호와 오디오 신호를 각 각 분석하여 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 검출한다. 영상 신호의 특성 정보와 오디오 신호의 특성 정보는 도 1에서 언급한 바와 같다. 프로세서는 검출된 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 이용하여 해당 장면의 영상 신호 를 제어하여 특화된 영상 신호가 디스플레이에 디스플레이 되도록 한다. 프로세서는 검출된 영상 신 호의 특성 정보와 오디오 특성 정보를 이용하여 해당 장면의 오디오 신호를 제어하여 특화된 오디오 신호가 오 디오 출력부를 통해 출력되도록 한다. 예를 들어, 프로세서는 장면 단위로 분석된 오디오 신호에 총 소리가 포함되고, 분석된 영상 신호가 어두 운 장면으로 판단되면, 장면의 영상 신호와 오디오 신호를 FPS 게임 컨텐트에 특화된 화질 및 사운드로 제어한 다. 예를 들어, 장면에 포함된 게임 아이템의 높은 시인성을 제공하면서, 발자국 소리 같은 특정 효과음의 대역을 강화할 수 있도록, 프로세서는 장면의 영상 신호와 오디오 신호를 제어할 수 있다. 프로세서는 장면 단위로 분석된 오디오 신호에 자동차의 엔진 소리가 포함되고, 영상 신호에 많은 모션 정 보가 검출된 것으로 판단되면, 장면의 영상 신호와 오디오 신호를 레이싱 게임 컨텐트에 특화된 화질 및 사운드 로 제어한다. 예를 들어, 영상 신호의 색상의 채도를 향상시키면서 자동차의 엔진 소리에 대한 효과음 대역을 강화할 수 있도록 프로세서는 장면의 영상 신호와 오디오 신호를 제어할 수 있다. 프로세서는 장면 단위로 분석된 오디오 신호에 음성 신호가 포함되고, 영상 신호가 밝은 것으로 판단되면, 장면의 영상 신호와 오디오 신호를 일반 게임 컨텐트에 특화된 화질 및 사운드로 제어한다. 예를 들어, 장면의 영상 신호의 명암비와 색상의 채도를 제어하지 않고, 장면에 포함된 효과음 또는/및 배경음에 대한 대역을 강화 하도록 프로세서는 장면의 영상 신호와 오디오 신호를 제어할 수 있다. 본 개시의 실시예에서, 프로세서는 내부적으로 구비되는 메모리(미도시)에 하나 이상의 인스트럭션을 저장 하고, 내부적으로 구비되는 메모리(미도시)에 저장된 하나 이상의 인스트럭션을 실행하여 전술한 동작들을 수행 할 수 있다. 즉, 프로세서는 프로세서의 내부에 구비되는 내부 메모리(미도시) 또는 메모리에 저장된 적어도 하나의 인스트럭션 또는 프로그램을 실행하여 소정 동작을 수행할 수 있다. 또한, 본 개시의 실시예에서, 프로세서는 영상에 대응되는 그래픽 처리를 위한 그래픽 프로세서(Graphic Processing Unit, 미도시)를 포함할 수 있다. 프로세서(미도시)는 코어(core, 미도시)와 GPU(미도시)를 통합한 SoC(System On Chip)로 구현될 수 있다. 프로세서(미도시)는 싱글 코어, 듀얼 코어, 트리플 코어, 쿼드 코어 및 그 배수의 코어를 포함할 수 있다. 프로세서는 영상 및 오디오 처리 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메 모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 디스플레이와 오디오 출력부를 제어할 수 있다. 또한, 도 2에서는 하나의 프로세서를 도시하였으나, 복수개의 프로세서(미도시)가 구비될 수도 있을 것이다. 이 경우, 본 개시의 실시예에 따른 영상 및 오디오 처리 장치에서 수행되는 동작들 각각은 복수개의 프로세서(미도시) 중 적어도 하나를 통하여 수행될 수 있다. 프로세서는, 메모리에 저장된 하나 이상의 인스트럭션을 실행하여, 메모리에 저장된 하나 이상 의 뉴럴 네트워크(neural network)를 이용한 학습 모델을 이용하여 장면 단위의 컨텐트의 영상 신호와 오디오 신호를 각각 분석하여 영상 신호의 특징 정보와 오디오 신호의 특징 정보를 검출하고, 검출된 영상 신호의 특징 정보와 오디오 신호의 특징 정보를 이용하여 장면의 영상 신호와 오디오 신호를 제어할 수 있다. 뉴럴 네트워크는, 인공지능(Artificial Intelligence)에 기초하여 뉴럴 네트워크에 입력된 영상 신호와 오디오 신호로부터 각각의 특성 정보를 검출하고, 검출된 특성 정보에 기초하여 장면 단위로 영상 신호와 오디오 신호 를 제어하는 방법을 학습하는 알고리즘의 집합일 수 있다. 예를 들어, 뉴럴 네트워크는, 장면 단위의 영상 신호 와 오디오 신호를 입력 값으로 하는 지도 학습(supervised learning), 별다른 지도 없이 영상 신호와 오디오 신 호로부터 각각 특성 정보를 검출하기 위해 필요한 데이터의 종류를 스스로 학습함으로써, 영상 신호와 오디오 신호로부터 특성 정보를 인식하기 위한 패턴을 발견하는 비지도 학습(unsupervised learning)에 기초하여, 영상 신호와 오디오 신호로부터 각각의 특성 정보를 인식하고, 제어하는 방법을 학습할 수 있다. 또한, 예를 들어, 뉴럴 네트워크는, 학습에 따라 검출된 영상 신호의 특성 정보와 오디오 신호의 특성 정보에 기초한 영상 신호와 오디오 신호의 제어가 올바른 지에 대한 피드백을 이용하는 강화 학습(reinforcement learning)을 이용하여, 장 면 단위의 영상 신호와 오디오 신호로부터 각각의 특성 정보를 검출하고, 장면 단위의 영상 신호와 오디오 신호 를 제어하는 방법을 학습할 수 있다. 또한, 뉴럴 네트워크는 인공 지능(AI) 기술에 따른 추론 및 예측을 위한 연산을 수행한다. 구체적으로, 뉴럴 네 트워크는 복수의 계층들을 통한 연산을 수행하는 딥 뉴럴 네트워크(DNN: Deep Neural Network)가 될 수 있다. 뉴럴 네트워크는 연산을 수행하는 내부의 계층(layer)의 개수에 따라서 계층의 개수가 복수일 경우, 즉 연산을 수행하는 뉴럴 네트워크의 심도(depth)가 증가하는 경우, 딥 뉴럴 네트워크(DNN)로 분류될 수 있다. 또한, 딥 뉴럴 네트워크(DNN) 연산은 컨볼루션 뉴럴 네트워크(CNN: Convolution Neural Network) 연산 등을 포함할 수 있다. 즉, 프로세서는 예시된 뉴럴 네트워크를 통하여 영상 신호와 오디오 신호의 특성 정보를 검출하기 위한 모델을 구현하고, 구현된 모델을 학습 데이터를 이용하여 학습시킬 수 있다. 그리고, 학습된 모델을 이용 하여 재생될 컨텐트의 장면 단위의 영상 신호와 오디오 신호를 분석 또는 분류하여, 장면 내의 영상 신호와 오 디오 신호의 특성 정보를 검출할 수 있다.예를 들어, 프로세서는, 하나 이상의 뉴럴 네트워크를 이용한 학습 모델을 이용하여, 장면 단위로 재생될 컨텐트의 영상 신호와 오디오 신호를 각각 분석하여 특성 정보를 검출할 수 있다. 예를 들어, 프로세서는 딥 뉴럴 네트워크를 통한 연산을 수행하여, 하나의 장면의 영상 신호의 밝기 정보, 명암비 정보 및 색상 정보 중 적어도 하나를 검출하고, 오디오 신호의 오디오 객체의 위치 정보, 음성 정보, 음악 정보, 및 효과음 정보 중 적어도 하나를 검출할 수 있다. 프로세서는 뉴럴 네트워크를 이용하여 검출된 영상 신호의 특성 정보와 검출된 오디오 신호의 특성 정보에 기초하여 장면 단위로 영상 신호와 오디오 신호를 제어할 수 있다. 예를 들어, 프로세서는 뉴럴 네트워크 를 이용하여 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 이용하여 장면 단위로 영상 신호에 대한 블랙 이퀄라이저 기능, 명암비 및 색상의 채도 중 적어도 하나를 제어하고, 오디오 신호에 대한 고도감 생성 및 스테 이지 확장 기능 및 사운드 이퀄라이저 기능 중 적어도 하나를 제어할 수 있다. 프로세서는 장면 단위로 제어되는 영상 신호가 출력하도록 디스플레이를 제어할 수 있다. 또한, 실시 예에 따라, 프로세서는, 장면 단위로 제어되는 오디오 신호가 출력되도록 오디오 출력부를 제어할 수 있다. 일 실시예에 따른 디스플레이는, 장면 단위로 제어되는 영상 신호를 디스플레이할 수 있다. 예를 들어, 장 면이 FPS 게임의 장면으로서 어두운 영상 신호를 포함하는 경우에, 디스플레이는 장면에 포함되어 있는 게 임 아이템의 높은 시인성을 제공하는 영상 신호를 디스플레이 할 수 있다. 장면이 스포츠 게임의 장면인 경우에, 디스플레이는 팀간의 유니폼이 명확하게 구분될 수 있도록 명암비와 색상의 채도를 강조하는 방향 으로 제어된 영상 신호를 디스플레이 할 수 있다. 디스플레이가 터치 스크린으로 구현되는 경우, 디스플레이는 출력 장치 이외에 입력 장치로 사용될 수 있다. 예를 들어, 디스플레이는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스 플레이(thin film transistor-liquid crystal display), 유기 발광 다이오드(organic light-emitting diode), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기 영동 디스플레이 (electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고, 영상 및 오디오 처리 장치의 구현 형태에 따라, 영상 및 오디오 처리 장치는 디스플레이를 2개 이상 포함할 수 있다. 오디오 출력부는 프로세서의 제어에 의해 장면 단위로 제어된 오디오 신호를 출력할 수 있다. 오디오 출력부는 스피커, 헤드폰 출력 단자 또는 S/PDIF(Sony/Philips Digital Interface) 출력 단자 중 적어도 하나를 포함할 수 있으나 이로 제한되지 않는다. 일 실시예에 따른 오디오 출력부는, 예를 들어, 장면이 FPS 게임의 장면으로서 어두운 영상 신호를 포함하 는 경우에, 오디오 출력부는 장면에 포함되어 있는 오디오 신호(예를 들어, 발자국 소리)의 고도감을 생성 하거나 사운드 스테이지를 확장한 오디오 신호를 출력할 수 있다. 또한, 장면이 스포츠 게임의 장면인 경우에, 오디오 출력부는 장면에 포함되어 있는 오디오 신호에 포함된 효과음(예를 들어, 함성 소리)의 고도감을 생성하고, 수평면 음상을 확장한(서라운드 이펙트를 강조하는 방향으로 제어한) 오디오 신호를 출력할 수 있다. 도 3은 도 2에 도시된 프로세서의 구성을 나타내는 블록도이다. 도 3에 있어서, 도 2에 도시된 프로세서는 영상 신호 분석부, 오디오 신호 분석부, 영상 신호 제어부, 및 오디오 신호 제어부를 포함하나 프로세서에 포함되는 구성 요소는 이로 제한되지 않 는다. 영상 신호 분석부는 장면 단위로 영상 신호를 분석한다. 예를 들어, 영상 신호 분석부는 블랙 영역 히스토그램 분포에 따라 장면이 어두운 장면인지 밝은 장면인지를 판단하고, 판단 결과를 영상 신호 제어부 와 오디오 신호 제어부로 제공할 수 있다. 영상 신호 분석부는 블랙 영역 히스토그램 분포에 따 라 장면이 어두운 장면인지 밝은 장면인지를 판단하기 위해 메모리에 저장된 어두운 영역을 나타내는 픽셀 수의 문턱 값을 이용할 수 있다. 영상 신호 분석부는 장면 단위로 영상 신호를 보다 더 정확하게 분석하기 위하여 상술한 하나의 장면에 대 한 프레임 단위의 블랙 영역의 히스토그램 분석뿐 아니라 로컬 영역별 블랙 영역의 히스토그램 분석 및 디테일 분석을 수행할 수 있다. 오디오 신호 분석부는 장면 단위로 오디오 신호를 분석한다. 예를 들어, 오디오 신호 분석부는 장면 단위로 오디오 신호에 포함된 오디오 객체의 위치 정보, 음성 정보, 음악 정보, 및 효과음 중 적어도 하나를 검출한다. 오디오 신호 분석부는 효과음을 검출하기 위하여 메모리에 저장된 효과음에 관한 정보를 이 용할 수 있다. 메모리에 저장된 효과음에 관한 정보는 효과음의 종류를 판단할 수 있는 정보를 포함할 수 있다. 오디오 신호 분석부는 오디오 신호에 대한 분석 결과를 영상 신호 제어부와 오디오 신호 제어 부로 제공한다. 영상 신호 제어부는 영상 신호 분석부로부터 제공된 영상 신호 분석 결과와 오디오 신호 분석부(32 0)로부터 제공된 오디오 신호 분석 결과를 이용하여 장면 단위로 영상 신호에 대한 블랙 이퀄라이저 기능, 명암 비 및 색상 채도 기능중 적어도 하나를 제어한다. 이에 따라 영상 신호 제어부는 장면에 특화된 화질을 갖 는 영상 신호를 출력한다. 도 4는 도 3에 도시된 영상 신호 제어부의 구성을 나타내는 블럭도이다. 도 4를 참조하면, 영상 신호 제어부는 블랙 이퀄라이저 동적 제어부, 및 명암비/색상 채도 제어부 를 포함한다. 블랙 이퀄라이저 동적 제어부는 입력되는 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 이용하여 입력되는 영상 신호의 어두운 영역의 블랙 시인성을 개선하기 위해 영상 신호의 밝기를 제어한다. 명암비/색상 채도 제어부는 입력되는 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 이용하여 입력 되는 영상 신호의 명암비 및/또는 색상의 채도를 제어한다. 예를 들어, 오디오 신호 분석부로부터 총소리에 대한 효과음을 나타내는 정보가 제공되고, 영상 신호 분석 부로부터 장면이 어두운 장면이라는 것을 나타내는 정보가 제공되면, 영상 신호 제어부는 어두운 장 면이 밝아지도록 블랙 이퀄라이저 동적 제어부의 이득값(블랙 이퀄라이저의 이득 값)을 높여서 영상 신호 의 밝기를 제어하고, 영상 신호의 명암비 및 색상의 채도가 부각되도록 명암비/색상 채도 제어부를 이용하 여 영상 신호를 제어한다. 오디오 신호 분석부로부터 자동차 엔진 소리를 나타내는 효과음에 대한 정보가 제공되고, 영상 신호 분석 부로부터 빠르게 움직이는 장면을 나타내는 모션 정보(많은 량의 모션 정보) 및 밝은 장면을 나타내는 정 보가 제공되면, 영상 신호 제어부는 블랙 이퀄라이저 동적 제어부를 사용하지 않고, 명암비/색상의 채도를 부각시키도록 명암비/색상 채도 제어부를 사용하여 영상 신호를 제어한다. 오디오 신호 분석부로부터 자동차 엔진 소리를 나타내는 효과음에 대한 정보가 제공되고, 영상 신호 분석 부로부터 빠르게 움직이는 장면을 나타내는 모션 정보 및 어두운 장면을 나타내는 정보가 제공되면, 영상 신호 제어부는 블랙 이퀄라이저 동적 제어부를 이용하여 화면이 밝아지도록 영상 신호를 제어하면서, 명암비/색상 채도 제어부를 이용하여 영상 신호의 색상이 부각되도록 영상 신호를 제어한다. 오디오 신호 분석부로부터 제공되는 효과음과 배경음이 일반 게임 컨텐트로 인식되고, 영상 신호 분석부 로부터 어두운 장면을 나타내는 정보가 제공되면, 영상 신호 제어부는 블랙 이퀄라이저 기능을 사용 하지 않고, 명암비 및 색상의 채도를 지나치게 강조하지 않도록 영상 신호를 제어한다. 도 3에 도시된 오디오 신호 제어부는 영상 신호 분석부로부터 제공된 영상 신호 분석 결과와 오디오 신호 분석부로부터 제공된 오디오 신호 분석 결과를 이용하여 장면 단위로 오디오 신호에 대한 고도감 생 성 및 스테이지 확장 기능 및 사운드 이퀄라이저 기능중 적어도 하나를 제어한다. 이에 따라 오디오 신호 제어 부는 장면에 특화된 사운드를 갖는 오디오 신호를 출력한다. 도 5는 도 3에 도시된 오디오 신호 제어부의 구성을 나타내는 블록도이다. 도 5를 참조하면, 오디오 신호 제어부는 고도감 생성 및 스테이지 확장부와 사운드 이퀄라이저 적용 부를 포함하나 이로 제한되지 않는다. 고도감 생성 및 스테이지 확장부는 오디오 객체의 움직임을 강화하거나 사운드 스테이지를 확장한다. 예를 들어, 장면의 오디오 신호에 효과음이 포함된 경우에, 고도감 생성 및 스테이지 확장부는 효과음의 고도감 을 생성하고, 수평면 음상을 확장한다. 예를 들어, 장면의 오디오 신호에 경기장에서의 함성 소리가 포함되어 있는 경우에, 고도감 생성 및 스테이지 확장부는 함성 소리에 대해 수평음상 확장과 스테이지 확장을 수행 하여 사용자에게 함성에 둘러싸인 듯한 사운드 경험을 제공한다. 고도감 생성과 수평면 음상 확장은 오디오 신 호 처리에서 널리 사용되고 있는 HRTF(Head-Related Transfer Function)를 통해 구현할 수 있으나 이로 제한되 지 않는다. 스테이지 확장은 서로 다른 오디오 채널의 정반대 위상 신호를 각 채널에 더해주는 방식으로 구현할수 있으나 이로 제한되지 않는다. 사운드 이퀄라이저 적용부는 입력된 오디오 신호를 이용하여 장면별로 차별적인 이퀄라이저를 적용하기 위 한 것이다. 예를 들어, 장면의 오디오 신호에 자동차의 엔진 소리가 포함된 경우에, 저역 성분이 강화되도록 사 운드 이퀄라이저 적용부를 제어하여 보다 실감나게 자동차 엔진 소리를 사용자에게 전달한다. 예를 들어, 장면의 오디오 신호에 음악 소리가 포함된 경우에, 저역 성분과 고역 성분 모두 강화되도록 사운드 이퀄라이저 적용부를 제어하여 사용자에게 전 대역에 넑게 퍼져 있는 악기음을 전달한다. 또한, 예를 들어, 오디오 신호 분석부로부터 총소리에 대한 효과음을 나타내는 정보가 제공되고, 영상 신 호 분석부로부터 장면이 어두운 장면이라는 것을 나타내는 정보가 제공되면, 오디오 신호 제어부는 주변 배경 소리가 강화되도록 사운드 이퀄라이저 적용부를 이용하여 오디오 신호를 제어한다. 오디오 신호 분석부로부터 자동차 엔진 소리를 나타내는 효과음에 대한 정보가 제공되고, 영상 신호 분석 부로부터 빠르게 움직이는 장면을 나타내는 모션 정보 및 밝은 장면을 나타내는 정보가 제공되면, 오디오 신호 제어부는 자동자 엔진 음과 같은 저역 성분이 강화되도록 사운드 이퀄라이저 적용부를 이용하여 오디오 신호를 제어한다. 오디오 신호 분석부로부터 자동차 엔진 소리를 나타내는 효과음에 대한 정보가 제공되고, 영상 신호 분석 부로부터 빠르게 움직이는 장면을 나타내는 모션 정보 및 어두운 장면을 나타내는 정보가 제공되면, 오디 오 신호 제어부는 엔진 음과 같은 저역 성분을 강화하기 위해 사운드 이퀄라이저 적용부를 사용하여 오디오 신호를 제어한다. 오디오 신호 분석부로부터 음성 소리 검출을 나타내는 정보가 제공되고, 영상 신호 분석부로부터 어 두운 장면을 나타내는 정보가 제공되면, 오디오 신호 제어부는 고도감 생성 및 스테이지 확장부를 이 용하여 효과음과 배경음을 확장하여 효과음과 배경음을 강조하고, 저역 성분과 고역 성분을 모두 강화할 수 있 도록 사운드 이퀄라이저 적용부를 이용하여 오디오 신호를 제어한다. 또한, 예를 들어, 수신되는 영상 신호의 특성 정보가 어두운 장면을 나타내고, 수신되는 오디오 신호의 특성 정 보에 발자국 소리가 포함되어 있으면, 사운드 이퀄라이저 적용부는 발자국 소리 같은 특정 효과음의 대역 을 강화하여 사용자에게 발자국 소리를 보다 명확하게 전달해 줄 수 있다. 예를 들어, 수신되는 영상 신호의 특성 정보에 많은 모션 정보가 포함되어 있을 경우에, 오디오 신호 제어부 는 고도감 생성 및 스테이지 확장부를 이용하여 수신되는 오디오 신호에 포함된 오디오 객체의 음상 을 확장하고, 사운드 이퀄라이저 적용부를 이용하여 오디오 신호에 포함되어 있는 효과음이 강화되도록 오 디오 신호를 제어할 수 있다. 도 6은 일 실시 예에 따른 영상 및 오디오 처리 장치의 동작 흐름도이다. 도 6에 도시된 영상 및 오디오 처리 장치의 동작 방법은 도 1 및 도 2를 참조하여 설명한 본 개시의 일 실시예에 따른 영상 및 오디오 처리 장 치(100, 200)에서 수행되는 동작들을 포함할 수 있다. 따라서 영상 및 오디오 처리 장치의 동작 방법의 상 세 동작들에 있어서, 본 개시의 일 실시 예에 따른 영상 및 오디오 처리 장치(100, 200)에서 수행되는 동작들과 중복되는 상세 설명은 생략한다. 도 6에 도시된 영상 및 오디오 처리 장치의 동작 방법은 장면 단위로 컨 텐트의 영상 신호와 오디오 신호를 각각 분석하여 영상 신호와 오디오 신호를 제어하는 경우이다. 도 6을 참조하면, S610 단계에서, 영상 및 오디오 처리 장치는 장면 단위로 컨텐트의 영상 신호를 분석하 여 영상 신호의 특성 정보를 검출한다. S610 단계에서 수행되는 영상 신호의 분석 처리 및 영상 신호의 특성 정 보를 검출하는 처리는 상술한 도 1 내지 도 5에서 설명한 바와 같다. 영상 신호의 특성 정보는 도 1에서 설명한 바와 같다. S620 단계에서, 영상 및 오디오 처리 장치는 장면 단위로 컨텐트의 오디오 신호를 분석하여 오디오 신호의 특성 정보를 검출한다. S620 단계에서 수행되는 오디오 신호의 분석 처리 및 오디오 신호의 특성 정보를 검출하 는 처리는 상술한 도 1 내지 도 5에서 설명한 바와 같다. 오디오 신호의 특성 정보는 도 1에서 설명한 바와 같 다. S630 단계에서, 영상 및 오디오 처리 장치는 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 이용하 여 영상 신호를 제어한다. S630 단계에서 수행되는 영상 신호의 제어는 도 1 내지 도 5에서 설명한 바와 같다. S640 단계에서, 영상 및 오디오 처리 장치는 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 이용하 여 오디오 신호를 제어한다. S640 단계에서 수행되는 오디오 신호의 제어는 도 1 내지 도 5에서 설명한 바와 같다. 도 7은 다른 실시 예에 따른 영상 및 오디오 처리 장치의 구성을 나타내는 블록도이다. 도 7에 있어서, 도 2에서와 동일한 구성은 동일한 도면 기호를 이용하여 도시하였다. 따라서 영상 및 오디오 처 리 장치를 설명하는데 있어서 도 1 내지 도 5에서와 중복되는 설명은 생략한다. 도 7를 참조하면, 영상 및 오디오 처리 장치는 도 2에 도시된 영상 및 오디오 처리 장치에 비하여 조 도 센서를 더 포함한다. 조도 센서는 영상 및 오디오 처리 장치의 외부의 주변 조도 정보를 검출한다. 주변 조도 정보는 영상 및 오디오 처리 장치의 주변 환경 정보를 의미한다. 영상 및 오디오 처리 장치의 주변 환경 정보는 조도 정보로 제한되지 않는다. 예를 들어, 영상 및 오디오 처리 장치에서 사용되는 오디오 출력부가 스피커인 경우에, 주변 환경 정보는 영상 및 오디오 처리 장치의 주변 소리(예를 들어, 잡음)을 포함할 수 있다. 조도 센서는 밝기 정보를 크기 값으로 나타내 주는 센서이므로, 검출된 주변 조도 정보는 영상 및 오디오 처리 장치의 외부의 조명의 밝기 정보를 크기 값으로 검출할 수 있다. 메모리는 블랙 이퀄라이저의 이득 값과 조도 값의 관계 정보를 저장할 수 있다. 영상 및 오디오 처리 장치 는 메모리에 저장된 블랙 이퀄라이저의 이득 값과 조도 값간의 관계 정보를 이용하여 영상 및 오디오 처리 장치의 주변 조도에 따라 블랙 이퀄라이저 강도를 보정하여 컨텐트에 대해 일관된 시인성을 제공할 수 있다. 즉, 영상 및 오디오 처리 장치는 영상 신호의 특성 정보 및 오디오 신호의 특성 정보에 의해 결 정된 블랙 이퀄라이저의 이득 값, 검출된 조도 정보, 및 메모리에 저장된 상술한 관계 정보를 이용하여 최 종적으로 적용할 블랙 이퀄라이저의 이득 값을 결정할 수 있다. 도 8은 일 실시 예에 따른 블랙 이퀄라이저(Black Equalizer)의 이득 값(BE_GAIN, 또는 이득 조정 값)과 조도 정보에 기초한 블랙 이퀄라이저의 최종 이득 값에 대한 예시도이다. 도 8의 경우에, 조도 정보가 150룩스(Lux) 시 블랙 이퀄라이저의 이득 값이 선형식으로 표현된다. 프로세서는 컨텐트에 대해 장면 단위로 영상 신호와 오디오 신호를 각각 분석하여 검출된 영상 신호의 특 성 정보 및 오디오 신호의 특성 정보에 기초하여 영상 신호를 제어할 때, 조도 센서에서 검출된 조도 정보 와 메모리에 저장된 상술한 블랙 이퀄라이저의 이득 값와 조도 정보간의 관계에 기초한 블랙 이퀄라이저의 최종 이득 값을 이용하여 블랙 이퀄라이저를 제어할 수 있다. 또한, 프로세서는 컨텐트에 대해 장면 단위로 영상 신호와 오디오 신호를 각각 분석하여 검출된 영상 신호 의 특성 정보 및 오디오 신호의 특성 정보에 기초하여 오디오 신호를 제어할 때, 조도 센서에서 검출된 조 도 정보와 메모리에 저장된 상술한 블랙 이퀄라이저의 이득 값와 조도 정보간의 관계에 기초한 블랙 이퀄 라이저의 최종 이득 값을 이용하여 제어될 영상 신호의 밝기에 기초하여 오디오 신호를 제어할 수 있다. 도 9는 다른 실시 예에 따른 영상 및 오디오 처리 장치의 동작 흐름도이다. 도 9는 도시된 영상 및 오디오 처리 장치의 동작 방법은 도 1 또는 도 7를 참조하여 설명한 본 개시의 다른 실시 예에 따른 영상 및 오디오 처 리 장치(100, 700)에서 수행되는 동작들을 포함할 수 있다. 따라서 영상 및 오디오 처리 장치의 동작 방법(90 0)의 상세 동작에 있어서, 본 개시의 다른 실시 예에 따른 영상 및 오디오 처리 장치(100, 700)에서 수행되는 동작들과 중복되는 상세 설명은 생략한다. S910 단계에서, 영상 및 오디오 처리 장치는 장면 단위로 컨텐트의 영상 신호를 분석하여 영상 신호의 특 성 정보를 검출한다. S910 단계에서 수행되는 컨텐트의 영상 신호를 분석하는 것과 영상 신호의 특성 정보를 검 출하는 것은, S610 단계와 같이 수행될 수 있다. S910 단계에서 언급되는 영상 신호의 특성 정보는 도 1에서 언 급한 바와 같다. S920 단계에서, 영상 및 오디오 처리 장치는 장면 단위로 컨텐트의 오디오 신호를 분석하여 오디오 신호의 특성 정보를 검출한다. S920 단계에서 수행되는 컨텐트의 오디오 신호를 분석하는 것과 오디오 신호의 특성 정 보를 검출하는 것은 S620 단계와 같이 수행될 수 있다. S920 단계에서 언급되는 오디오 신호의 특성 정보는 도 1에서 언급한 바와 같다. S930 단계에서, 영상 및 오디오 처리 장치는 영상 및 오디오 처리 장치의 주변 조도 정보를 검출한다. S930 단계에서 주변 조도 정보를 검출하는 것은 도 7에서 설명한 바와 같다. S940 단계에서, 영상 및 오디오 처리 장치는 영상 신호의 특성 정보, 오디오 신호의 특성 정보 및 조도 정 보를 이용하여 영상 신호를 제어한다. S940 단계에서 수행되는 영상 신호를 제어하는 것은 도 7에서 설명한 바 와 같다. S950 단계에서, 영상 및 오디오 처리 장치는 영상 신호의 특성 정보, 오디오 신호의 특성 정보 및 조도 정 보를 이용하여 오디오 신호를 제어한다. S950 단계에서 수행되는 오디오 신호를 제어하는 것은 도 7에서 설명한 바와 같다. 도 10은 다른 실시예에 따른 영상 및 오디오 처리 장치의 구성을 나타내는 블록도이다. 도 10에 도시된 바와 같이, 영상 및 오디오 처리 장치는, 디스플레이, 오디오 출력부 이외에, 튜너부, 프로세서, 통신부, 감지부, 입/출력부, 영상 신호 처리부, 오디 오 신호 처리부, 및 사용자 입력부를 더 포함할 수 있다. 디스플레이 및 오디오 출력부에 대하여, 도 2에서 설명한 내용과 동일한 내용은 도 10에서 생략한다. 튜너부는 유선 또는 무선으로 수신되는 방송 신호를 증폭(amplification), 혼합(mixing), 공진 (resonance)등을 통하여 많은 전파 성분 중에서 영상 및 오디오 처리 장치에서 수신하고자 하는 채널의 주파수만을 튜닝(tuning)시켜 선택할 수 있다. 방송 신호는 오디오(audio), 비디오(video) 및 부가 정보(예를 들어, EPG(Electronic Program Guide))를 포함한다. 튜너부를 통해 수신된 방송 신호는 디코딩(decoding, 예를 들어, 오디오 디코딩, 비디오 디코딩 또는 부 가 정보 디코딩)되어 오디오, 비디오 및/또는 부가 정보로 분리된다. 분리된 오디오, 비디오 및/또는 부가 정보 는 프로세서에 의해 제어되어 메모리에 저장될 수 있다. 영상 및 오디오 처리 장치의 튜너부는 하나이거나 복수일 수 있다. 튜너부는 영상 및 오디오 처리 장치와 일체형(all-in-one)으로 구현되거나 또는 영상 및 오디오 처리 장치와 전기적으로 연 결되는 튜너부를 가지는 별개의 장치(예를 들어, 셋탑박스(set-top box, 도시되지 아니함), 입/출력부에 연결되는 튜너부(도시되지 아니함))로 구현될 수 있다. 통신부는 프로세서의 제어에 의해 영상 및 오디오 처리 장치를 외부 장치(예를 들어, 오디오 장치, 서버, 컨텐트 제공 장치 등)와 연결할 수 있다. 프로세서는 통신부를 통해 연결된 외부 장치 로 컨텐트를 송/수신, 외부 장치로부터 어플리케이션(application)을 다운로드하거나 또는 웹 브라우징을 할 수 있다. 통신부는 영상 및 오디오 처리 장치의 성능 및 구조에 대응하여 무선 랜, 블루투스, 및 유선 이더 넷 중 하나를 포함할 수 있다. 또한, 통신부는 무선랜, 블루투스, 및 유선 이더넷(Ethernet)의 조합을 포 함할 수 있다. 통신부는 프로세서의 제어에 의해 제어 장치의 제어 신호를 수신할 수 있다. 제어 신호는 블루투스 타입, RF 신호 타입 또는 와이파이 타입으로 구현될 수 있다. 통신부는 블루투스 외에 다른 근거리 통신(예를 들어, NFC(Near Field Communication, 도시되지 아니 함), BLE(Bluetooth Low Energy, 도시되지 아니함)를 더 포함할 수 있다. 일 실시예에 따른 통신부는, 외부 서버로부터 하나 이상의 뉴럴 네트워크를 이용한 학습 모델을 수신할 수 있다. 또한, 통신부는, 메모리에 저장된 영상 신호 및 오디오 신호를 분석하기 위해 사용되는 정보를 갱신하기 위하여, 외부 서버로부터 기설정된 주기마다 새로운 정보를 수신할 수 있다. 감지부는 사용자의 음성, 사용자의 영상, 사용자의 인터랙션 및 영상 및 오디오 처리 장치의 주변 의 조도를 감지하며, 마이크, 카메라부, 광 수신부 및 조도 센서를 포함할 수 있다. 마이크는 사용자의 발화(utterance)된 음성을 수신한다. 마이크는 수신된 음성을 전기 신호로 변환 하여 프로세서로 출력할 수 있다. 카메라부는 카메라 인식 범위에서 제스처를 포함하는 사용자의 모션에 대응되는 영상(예를 들어, 연속되 는 프레임)을 수신할 수 있다. 광 수신부는, 제어 장치에서부터 수신되는 광 신호(제어 신호를 포함)를 수신한다. 광 수신부(104 3)는 제어 장치로부터 사용자 입력(예를 들어, 터치, 눌림, 터치 제스처, 음성, 또는 모션)에 대응되는 광 신호를 수신할 수 있다. 수신된 광 신호로부터 프로세서는 제어 신호를 검출할 수 있다. 일 실시예에 따른 광 수신부는, 컨텐트 재생에 관련된 사용자 입력에 대응되는 광 신호를 제어 장치(10 1)로부터 수신할 수 있다. 조도 센서는 도 7의 조도 센서와 같이 영상 및 오디오 처리 장치의 외부의 조명의 밝기 에 기초한 조도 정보를 검출할 수 있으나 조도 센서의 검출 범위는 이로 제한되지 않는다. 예를 들어, 조 도 센서는 영상 및 오디오 처리 장치의 주변의 빛(예를 들어, 햇빛)의 밝기를 검출할 수 있다. 입/출력부는 프로세서에 의해 제어되어 영상 및 오디오 처리 장치의 외부에서부터 비디오(예 를 들어, 동영상 등), 오디오(예를 들어, 음성, 음악 등) 및 부가 정보(예를 들어, EPG 등) 등을 수신한다. 입/ 출력부는 HDMI 포트(High-Definition Multimedia Interface port, 1051), 컴포넌트 잭(component jack, 1052), PC 포트(PC port, 1053), 및 USB 포트(USB port, 1054) 중 적어도 하나를 포함할 수 있다. 입/출력부 는 HDMI 포트, 컴포넌트 잭, PC 포트, 및 USB 포트의 조합을 포함할 수 있다. 일 실시예에 따른 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 영상 및 오디오 처리 장치로 입력되거나 영상 및 오디오 처리 장치로부터 출력되는 데이터를 저장할 수 있 다. 또한, 메모리는 영상 및 오디오 처리 장치의 동작에 필요한 데이터들을 저장할 수 있다. 영상 및 오디오 처리 장치의 동작에 필요한 데이터들은 도 2에서 설명한 메모리에 저장되어 있는 정보를 포함할 수 있다. 또한, 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있다. 구체적으로, 메모리는 뉴럴 네트워크를 이용하여 소정 동작을 수행하기 위한 하나 이상의 프로그램을 저장할 수 있다. 예를 들어, 메모리에 저장되는 하나 이상의 프로그램은 학습 모듈과 제어 모듈 등으로 분류 될 수 있다. 학습 모듈은, 하나 이상의 뉴럴 네트워크에 컨텐트가 입력된 것에 응답하여 장면 단위로 컨텐트의 영상 신호와 오디오 신호를 분석하여 각각의 특성 정보를 검출하고, 검출된 특성 정보를 이용하여 장면의 영상 신호 와 오디오 신호를 제어하는 방법을 학습하여 결정되는 학습 모델을 포함할 수 있다. 학습 모델은 외부 서버로부 터 수신될 수 있으며, 수신된 학습 모델은 학습 모듈에 저장될 수 있다. 제어 모듈은, 프로세서가 하나 이상의 인스트럭션을 수행함으로써, 장면 단위의 컨텐트의 영상 신 호와 오디오 신호를 분석할 때 사용되는 정보와 분석 결과에 따라 얻어진 영상 신호의 특성 정보 및 오디오 신 호의 특성 정보에 따라 영상 신호와 오디오 신호의 제어를 수행하도록 하는 프로그램을 저장할 수 있다. 예를 들어, 제어 모듈은, 프로세서가 입력되는 컨텐트에 응답하여, 영상 신호와 오디오 신호를 각각 분 석한 결과와 저장된 정보를 비교하여 영상 신호의 특성 정보와 오디오 신호의 특성 정보를 검출하고, 검출된 영 상 신호의 특성 정보와 오디오 신호의 특성 정보에 따라 영상 신호를 제어하기 위한 동작 조건 정보 및 오디오 신호를 제어하기 위한 동작 조건 정보를 프로세서로 제공하여 프로세서가 장면 단위로 제어된 영상 신호가 출력되도록 영상 신호 처리부와 디스플레이를 제어하고, 장면 단위로 제어된 오디오 신호가 출력되도록 오디오 신호 처리부와 오디오 출력부를 제어하는 프로그램을 저장할 수 있다. 또한, 뉴럴 네트워크를 이용하여 소정 동작들을 수행하기 위한 하나 이상의 프로그램, 또는 뉴럴 네트워크를 이 용하여 소정 동작들을 수행하기 위한 하나 이상의 인스트럭션은 프로세서에 포함되는 내부 메모리(미도시)에 저장될 수도 있을 것이다. 프로세서는 영상 및 오디오 처리 장치의 전반적인 동작 및 영상 및 오디오 처리 장치의 내부 구성 요소들 사이의 신호 흐름을 제어하고, 데이터를 처리하는 기능을 수행한다. 프로세서는 사용자의 입 력이 있거나 기설정되어 저장된 조건을 만족하는 경우, 메모리에 저장된 OS(Operation System) 및 다양한 애플리케이션을 실행할 수 있다. 또한, 프로세서는 내부 메모리(미도시)를 포함할 수 있을 것이다. 이 경우, 메모리에 저장되는 데 이터, 프로그램, 및 인스트럭션 중 적어도 하나가 프로세서의 내부 메모리(미도시)에 저장될 수 있다. 예 를 들어, 프로세서의 내부 메모리(미도시)는 뉴럴 네트워크를 이용하여 소정 동작들을 수행하기 위한 하 나 이상의 프로그램, 또는 뉴럴 네트워크를 이용하여 소정 동작들을 수행하기 위한 하나 이상의 인스트럭션을 저장할 수 있다. 영상 신호 처리부는, 디스플레이에 의해 표시될 영상 데이터를 처리하며, 영상 데이터에 대한 디코 딩, 렌더링, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 및 해상도 변환 등과 같은 다양한 영상 처리 동작 을 수행할 수 있다. 특히, 영상 신호 처리부는 프로세서에 의해 제어되어 도 4에 도시된 블랙 이퀄라이저 동적 제어부 및 명암비 및 색상 채도 제어부에 대응되는 기능을 수행할 수 있다. 디스플레이는 프로세서에 의해 제어되어 튜너부를 통해 수신된 방송 신호에 포함된 비디오를 화면에 디스플레이 할 수 있다. 또한, 디스플레이는 통신부 또는 입/출력부를 통해 입력되는 컨텐트(예를 들어, 동영상)를 표시할 수 있다. 디스플레이는 프로세서의 제어에 의해 메모리 에 저장된 영상을 출력할 수 있다. 디스플레이는 프로세서에 의해 제어되어 영상 신호 처리부(106 0)에서 처리된 영상 신호를 디스플레이 할 수 있다. 오디오 신호 처리부는 오디오 데이터에 대한 처리를 수행한다. 오디오 신호 처리부에서는 오디오 데이터에 대한 디코딩이나 증폭, 노이즈 필터링 등과 같은 다양한 처리가 수행될 수 있다. 또한, 오디오 신호 처리부는 프로세서에 의해 제어되어 도 5에 도시된 고감도 생성 및 스테이지 확장부 및 사운 드 이퀄라이저 적용부에 대응되는 기능을 수행할 수 있다. 오디오 출력부는 프로세서에 의해 제어되어 튜너부를 통해 수신된 방송 신호에 포함된 오디오 신호, 통신부 또는 입/출력부를 통해 입력되는 오디오 신호, 메모리에 저장된 오디오 신호를 출력할 수 있다. 오디오 출력부는 스피커, 헤드폰 출력 단자 또는 S/PDIF(Sony/Philips Digital Interface) 출력 단자 중 적어도 하나를 포함할 수 있다. 오디오 출력부는 프로세서에 의해 제어되 어 오디오 신호 처리부에서 처리된 오디오 신호를 출력할 수 있다. 사용자 입력부는, 사용자가 영상 및 오디오 처리 장치를 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들어, 사용자 입력부는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드, 조그 휠, 조그 스위치 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 또한, 사용자 입력부는, 전술한 제어 장치의 구성요소일 수 있고, 영상 및 오디오 처리 장치 의 구성요소일 수 있다. 사용자 입력부는 제어 장치로부터 전송되는 사용자 입력을 수신할 수 있는 기능을 포함할 수 있다. 한편, 도 2, 도 7, 및 도 10에 도시된 영상 및 오디오 처리 장치(100, 700, 1000)의 블록도는 일 실시예를 위한 블록도이다. 블록도의 각 구성요소는 실제 구현되는 영상 및 오디오 처리 장치(100, 700, 1000)의 사양에 따라 통합, 추가, 또는 생략될 수 있다. 예를 들어, 필요에 따라 2 이상의 구성요소가 하나의 구성요소로 합쳐지거나, 혹은 하나의 구성요소가 2 이상의 구성요소로 세분화되어 구성될 수 있다. 또한, 각 블록에서 수행 하는 기능은 실시예들을 설명하기 위한 것이며, 그 구체적인 동작이나 장치는 본 발명의 권리범위를 제한하지 아니한다. 전술한 바와 같이, 본 개시의 일 또는 다른 실시예는 사용자가 컨텐트를 재생할 때, 컨텐트의 화질과 사운드를 장면단위의 영상 신호와 오디오 신호를 모두 고려하여 자동적으로 제어함으로써, 컨텐트의 특성에 기초하여 시 인성을 개선하고, 렌더링된 사운드를 제공하여 컨텐트에 대한 사용자의 몰임감을 높일 수 있다. 또한, 본 개시 의 일 또는 다른 실시예는, 영상 신호와 오디오 신호에 대한 각각의 분석결과를 영상 신호와 오디오 신호를 제 어할 때 서로 이용함으로써, 제작자가 의도한 컨텐트를 사용자에게 충실하게 전달할 수 있다. 또한, 본 개시의 일 또는 다른 실시예는, 주변 조도에 따라 일관된 컨텐트에 대한 시인성을 제공할 수 있다. 또한, 본 개시의 일 또는 다른 실시 예는, 주변 환경에 따라 일관된 컨텐트에 대한 시인성 및 사운드를 제공할 수 있다. 일부 실시예에 따른 영상 및 오디오 처리 장치 및 그 동작 방법은 컴퓨터에 의해 실행되는 프로그램 모듈과 같 은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매 체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분 리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보 의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한 다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전달 매체를 포함한다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 또한, 전술한 본 개시의 실시예에 따른 영상 및 오디오 처리 장치 및 그 동작 방법은 다중언어로 구성된 문장을 획득하는 동작; 및 다중언어 번역 모델을 이용하여, 상기 다중언어로 구성된 문장에 포함되는 단어들 각각에 대 응하는 벡터 값들을 획득하고, 상기 획득한 벡터 값들을 목표 언어에 대응하는 벡터 값들로 변환하며, 상기 변환된 벡터 값들에 기초하여, 상기 목표 언어로 구성된 문장을 획득하는 동작을 수행하도록 하는 프로그램이 저 장된 기록매체를 포함하는 컴퓨터 프로그램 제품으로 구현될 수 있다."}
{"patent_id": "10-2018-0140097", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2018-0140097", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 영상 및 오디오 처리 장치를 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 영상 및 오디오 처리 장치의 구성을 나타내는 블록도이다. 도 3은 도 2에 도시된 프로세서의 구성을 나타내는 블록도이다. 도 4는 도 3에 도시된 영상 신호 제어부의 구성을 나타내는 블럭도이다. 도 5는 도 3에 도시된 오디오 신호 제어부의 구성을 나타내는 블록도이다. 도 6은 일 실시 예에 따른 영상 및 오디오 처리 장치의 동작 흐름도이다. 도 7은 다른 실시 예에 따른 영상 및 오디오 처리 장치의 구성을 나타내는 블록도이다. 도 8은 일 실시 예에 따른 블랙 이퀄라이저의 이득 값과 조도 정보에 기초한 블랙 이퀄라이저의 최종 이득 값에 대한 예시도이다. 도 9는 다른 실시 예에 따른 영상 및 오디오 처리 장치의 동작 흐름도이다. 도 10은 다른 실시예에 따른 영상 및 오디오 처리 장치의 구성을 나타내는 블록도이다."}
