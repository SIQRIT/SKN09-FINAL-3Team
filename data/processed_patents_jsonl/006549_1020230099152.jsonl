{"patent_id": "10-2023-0099152", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0018000", "출원번호": "10-2023-0099152", "발명의 명칭": "소실점 GT 생성 방법과 이를 이용한 소실점 추정 방법 및 장치", "출원인": "현대자동차주식회사", "발명자": "이중현"}}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력 영상을 수신하는 단계; 및실제 영상 데이터 기반에 의해 생성된 소실점 GT(Ground Truth) 데이터에 의해 미리 학습된 인공지능 네트워크를 이용하여, 상기 입력 영상에 대한 소실점을 추정하는 단계를 포함하고,상기 소실점을 추정하는 단계는,상기 입력 영상에 대한 깊이 맵(depth map) 또는 광학 흐름 맵(optical flow map)을 추정하는 단계;상기 깊이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵(gradient map)을 추정하는 단계; 및상기 그래디언트 맵과 미리 설정된 기준 그래디언트 맵을 기반으로 상기 입력 영상에 대한 소실점을 추정하는단계를 포함하는, 소실점 추정 방법."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 소실점을 추정하는 단계는,상기 그래디언트 맵과 상기 기준 그래디언트 맵을 기반으로 정적 객체에 대한 히트 맵을 추정하고, 상기 히트맵을 기반으로 상기 소실점을 추정하는, 소실점 추정 방법."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 소실점을 추정하는 단계는,상기 정적 객체에 대한 히트 맵의 2D 가우시안 피팅을 수행하고, 상기 2D 가우시안의 중앙점을 상기 소실점으로추정하는, 소실점 추정 방법."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 인공지능 네트워크는,상기 히트 맵에서 상기 소실점에 대응하는 키포인트를 추정하는 네트워크를 포함하는, 소실점 추정 방법."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 깊이 맵 또는 광학 흐름 맵을 추정하는 단계는,공개특허 10-2025-0018000-3-상기 깊이 맵을 추정하는 경우, 상기 입력 영상에서 미리 설정된 적어도 하나 이상의 동적 객체를 검출하고, 상기 검출된 동적 객체의 영역을 제외한 정적 객체의 깊이 맵을 추정하는, 소실점 추정 방법."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 인공지능 네트워크는,CenterNet을 포함하는, 소실점 추정 방법."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 기준 그래디언트 맵을 생성하는 단계를 더 포함하고,상기 기준 그래디언트 맵을 생성하는 단계는,정적 객체만 있는 기준 공간과 기준 소실점을 생성하는 단계;상기 기준 공간과 상기 기준 소실점을 기반으로 기준 깊이 맵 또는 기준 광학 흐름 맵을 생성하는 단계; 및상기 기준 깊이 맵 또는 상기 광학 흐름 맵에 대한 그래디언트 맵을 생성함으로써, 상기 기준 그래디언트 맵을생성하는 단계를 포함하는, 소실점 추정 방법."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 소실점 GT 데이터는,영상에 대한 깊이 맵 또는 광학 흐름 맵을 생성하고,상기 깊이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵을 생성하며,상기 그래디언트 맵의 가우시안 피팅을 통해 상기 그래디언트 맵에 대한 히트 맵을 생성하고, 상기 가우시안 피팅에 의한 가우시안 중앙점을 이용하여 키포인트를 생성하며,상기 가우시안 중앙점에 대한 좌표와 미리 설정된 적어도 하나 이상의 소실점 검출 기법에 의해 검출된 소실점의 좌표가 일치하는 경우, 상기 히트 맵과 상기 키포인트에 기반하여 생성되는, 소실점 추정 방법."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "입력 영상을 수신하는 수신부; 및실제 영상 데이터 기반에 의해 생성된 소실점 GT 데이터에 의해 미리 학습된 인공지능 네트워크를 이용하여, 상기 입력 영상에 대한 소실점을 추정하는 추정부를 포함하고,상기 추정부는,상기 입력 영상에 대한 깊이 맵 또는 광학 흐름 맵을 추정하고,공개특허 10-2025-0018000-4-상기 깊이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵을 추정하며,상기 그래디언트 맵과 미리 설정된 기준 그래디언트 맵을 기반으로 상기 입력 영상에 대한 소실점을 추정하는,소실점 추정 장치."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 추정부는,상기 그래디언트 맵과 상기 기준 그래디언트 맵을 기반으로 정적 객체에 대한 히트 맵을 추정하고, 상기 히트맵을 기반으로 상기 소실점을 추정하는, 소실점 추정 장치."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 추정부는,상기 정적 객체에 대한 히트 맵의 2D 가우시안 피팅을 수행하고, 상기 2D 가우시안의 중앙점을 상기 소실점으로추정하는, 소실점 추정 장치."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 인공지능 네트워크는,상기 히트 맵에서 상기 소실점에 대응하는 키포인트를 추정하는 네트워크를 포함하는, 소실점 추정 장치."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 추정부는,상기 깊이 맵을 추정하는 경우, 상기 입력 영상에서 미리 설정된 적어도 하나 이상의 동적 객체를 검출하고, 상기 검출된 동적 객체의 영역을 제외한 정적 객체의 깊이 맵을 추정하는, 소실점 추정 장치."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 인공지능 네트워크는,CenterNet을 포함하는, 소실점 추정 장치."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서,상기 기준 그래디언트 맵을 생성하는 생성부를 더 포함하고,공개특허 10-2025-0018000-5-상기 생성부는,정적 객체만 있는 기준 공간과 기준 소실점을 생성하고,상기 기준 공간과 상기 기준 소실점을 기반으로 기준 깊이 맵 또는 기준 광학 흐름 맵을 생성하며,상기 기준 깊이 맵 또는 기준 광학 흐름 맵에 대한 그래디언트 맵을 생성함으로써, 상기 기준 그래디언트 맵을생성하는, 소실점 추정 장치."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 소실점 GT 데이터는,영상에 대한 깊이 맵 또는 광학 흐름 맵을 생성하고,상기 깊이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵을 생성하며,상기 그래디언트 맵의 가우시안 피팅을 통해 상기 그래디언트 맵에 대한 히트 맵을 생성하고, 상기 가우시안 피팅에 의한 가우시안 중앙점을 이용하여 키포인트를 생성하며,상기 가우시안 중앙점에 대한 좌표와 미리 설정된 적어도 하나 이상의 소실점 검출 기법에 의해 검출된 소실점의 좌표가 일치하는 경우, 상기 히트 맵과 상기 키포인트에 기반하여 생성되는, 소실점 추정 장치."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "입력 영상에 대한 깊이 맵 또는 광학 흐름 맵을 생성하는 단계;상기 깊이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵을 생성하는 단계;상기 그래디언트 맵의 가우시안 피팅을 통해 상기 그래디언트 맵에 대한 히트 맵을 생성하고, 상기 가우시안 피팅에 의한 가우시안 중앙점을 이용하여 키포인트를 생성하는 단계; 및상기 가우시안 중앙점에 대한 좌표와 미리 설정된 적어도 하나 이상의 소실점 검출 기법에 의해 검출된 소실점의 좌표가 일치하는 경우, 상기 히트 맵과 상기 키포인트에 기반하여 소실점 GT를 생성하는 단계를 포함하는, 소실점 GT 생성 방법."}
{"patent_id": "10-2023-0099152", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 입력 영상은, 실제 영상 데이터를 포함하는, 소실점 GT 생성 방법."}
{"patent_id": "10-2023-0099152", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 소실점 추정 방법은, 입력 영상을 수신하는 단계; 및 실제 영상 데이터 기반에 의 해 생성된 소실점 GT(Ground Truth) 데이터에 의해 미리 학습된 인공지능 네트워크를 이용하여, 상기 입력 영상 에 대한 소실점을 추정하는 단계를 포함하고, 상기 소실점을 추정하는 단계는, 상기 입력 영상에 대한 깊이 맵 (depth map) 또는 광학 흐름 맵(optical flow map)을 추정하는 단계; 상기 깊이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵(gradient map)을 추정하는 단계; 및 상기 그래디언트 맵과 미리 설정된 기준 그래디언트 맵을 기 반으로 상기 입력 영상에 대한 소실점을 추정하는 단계를 포함한다."}
{"patent_id": "10-2023-0099152", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 소실점 GT(Ground Truth) 생성 및 이를 이용한 소실점 추정 기술에 관한 것으로, 보다 구체적으로 실 제 데이터(또는 실제 영상 데이터)의 소실점 GT를 생성하고, 이를 이용한 인공지능 네트워크 학습을 통해 입력 영상에 대한 소실점의 추정 정확도를 향상시킬 수 있는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0099152", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율주행 차량의 운행을 위해서는 여러가지 영상 인식 기술이 필요하다. 일 예로 주행 중의 차선을 파악하고, 소실점(vanishing point)을 파악하는 것도 중요한 요소 중 하나이다. 소실점이란 3차원 공간상에서 평행하는 직선들을 무한히 연장하고 이를 2차원 평면으로 투영하였을 때 그 평면 상의 한 점에서 만나게 되는 지점을 가리킨다. 소실점 검출을 활용한 예로는, 세 개의 서로 직교하는 방향의 소 실점과 소실선을 구함으로써, 인공구조물(architectural)을 해석하여 건물을 재해석할 수도 있다. 인공 구조물 이 포함된 2차원 영상의 3차원 변환에서는 소실점을 검출함으로써 깊이 맵(depth map)를 생성할 수 있다. 이는 3차원 공간이 2차원 영상으로 변하면서 소실점이 위치하는 부분은 일반적으로 영상 내에서 가장 먼 곳에 해당하 므로 상대적인 깊이 추정이 가능하기 때문이다. 그리고, 소실점 정보는 자율주행 차량에 있어서 차선 검출(lane detection)의 기준 또는 로봇 등의 자율 주행 시스템에서 위치 정보 분석에 중요한 기반이 된다. 이는 소실점에서 이어지는 주요한 에지(edge)를 연결하여 도 로를 검출할 수 있기 때문이다. 종래 일 실시 예에 따른 소실점과 소실선 검출 기법은, 컴퓨터 비전(Computer Vision, CV) 기법을 이용하여 소 실점과 소실선을 검출하였다. 하지만, CV 기법을 이용하는 경우 직선 검출이 필요하기 때문에 주행 환경에 영향 을 받는 제약조건이 있다."}
{"patent_id": "10-2023-0099152", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 과제는, 실제 데이터의 소실점 GT를 생성하고, 이를 이용한 인공지능 네트워크 학습을 통해 입력 영상에 대한 소실점의 추정 정확도를 향상시킬 수 있는 방법 및 장치를 제공하는데 그 목적이 있다. 본 개시의 기술적 과제는, 실제 데이터의 소실점 GT를 생성하는 기술을 제공하는데 그 목적이 있다. 본 개시의 기술적 과제는, 실제 데이터의 소실점 GT를 이용하여 인공지능 네트워크 예를 들어, CenterNet을 학 습시키고, CenterNet을 이용하여 입력 영상에 대한 소실점을 추정할 수 있는 기술을 제공하는데 그 목적이 있다. 본 개시에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2023-0099152", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0099152", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 소실점 추정 방법은, 입력 영상을 수신하는 단계; 및 실제 영상 데이터 기반에 의 해 생성된 소실점 GT(Ground Truth) 데이터에 의해 미리 학습된 인공지능 네트워크를 이용하여, 상기 입력 영상 에 대한 소실점을 추정하는 단계를 포함하고, 상기 소실점을 추정하는 단계는, 상기 입력 영상에 대한 깊이 맵 (depth map) 또는 광학 흐름 맵(optical flow map)을 추정하는 단계; 상기 깊이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵(gradient map)을 추정하는 단계; 및 상기 그래디언트 맵과 미리 설정된 기준 그래디언트 맵을 기 반으로 상기 입력 영상에 대한 소실점을 추정하는 단계를 포함한다. 일 실시 예에 따르면, 상기 소실점을 추정하는 단계는, 상기 그래디언트 맵과 상기 기준 그래디언트 맵을 기반 으로 정적 객체에 대한 히트 맵을 추정하고, 상기 히트 맵을 기반으로 상기 소실점을 추정할 수 있다. 일 실시 예에 따르면, 상기 소실점을 추정하는 단계는, 상기 정적 객체에 대한 히트 맵의 2D 가우시안 피팅을 수행하고, 상기 2D 가우시안의 중앙점을 상기 소실점으로 추정할 수 있다. 일 실시 예에 따르면, 상기 인공지능 네트워크는, 상기 히트 맵에서 상기 소실점에 대응하는 키포인트를 추정하 는 네트워크를 포함할 수 있다. 일 실시 예에 따르면, 상기 깊이 맵 또는 광학 흐름 맵을 추정하는 단계는, 상기 깊이 맵을 추정하는 경우, 상 기 입력 영상에서 미리 설정된 적어도 하나 이상의 동적 객체를 검출하고, 상기 검출된 동적 객체의 영역을 제 외한 정적 객체의 깊이 맵을 추정할 수 있다. 일 실시 예에 따르면, 상기 인공지능 네트워크는, CenterNet을 포함할 수 있다. 나아가, 본 개시의 일 실시 예에 따른 소실점 추정 방법은, 상기 기준 그래디언트 맵을 생성하는 단계를 더 포 함하고, 상기 기준 그래디언트 맵을 생성하는 단계는, 정적 객체만 있는 기준 공간과 기준 소실점을 생성하는 단계; 상기 기준 공간과 상기 기준 소실점을 기반으로 기준 깊이 맵 또는 기준 광학 흐름 맵을 생성하는 단계; 및 상기 기준 깊이 맵 또는 상기 광학 흐름 맵에 대한 그래디언트 맵을 생성함으로써, 상기 기준 그래디언트 맵 을 생성하는 단계를 포함할 수 있다. 일 실시 예에 따르면, 상기 소실점 GT 데이터는, 영상에 대한 깊이 맵 또는 광학 흐름 맵을 생성하고, 상기 깊 이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵을 생성하며, 상기 그래디언트 맵의 가우시안 피팅을 통해 상기 그래디언트 맵에 대한 히트 맵을 생성하고, 상기 가우시안 피팅에 의한 가우시안 중앙점을 이용하여 키포인트를 생성하며, 상기 가우시안 중앙점에 대한 좌표와 미리 설정된 적어도 하나 이상의 소실점 검출 기법에 의해 검출 된 소실점의 좌표가 일치하는 경우, 상기 히트 맵과 상기 키포인트에 기반하여 생성될 수 있다. 본 개시의 다른 실시 예에 따른 소실점 추정 장치는, 입력 영상을 수신하는 수신부; 및 실제 영상 데이터 기반 에 의해 생성된 소실점 GT 데이터에 의해 미리 학습된 인공지능 네트워크를 이용하여, 상기 입력 영상에 대한 소실점을 추정하는 추정부를 포함하고, 상기 추정부는, 상기 입력 영상에 대한 깊이 맵 또는 광학 흐름 맵을 추 정하고, 상기 깊이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵을 추정하며, 상기 그래디언트 맵과 미리 설정된 기준 그래디언트 맵을 기반으로 상기 입력 영상에 대한 소실점을 추정하는 것을 특징으로 한다. 일 실시 예에 따르면, 상기 추정부는, 상기 그래디언트 맵과 상기 기준 그래디언트 맵을 기반으로 정적 객체에 대한 히트 맵을 추정하고, 상기 히트 맵을 기반으로 상기 소실점을 추정할 수 있다. 일 실시 예에 따르면, 상기 추정부는, 상기 정적 객체에 대한 히트 맵의 2D 가우시안 피팅을 수행하고, 상기 2D 가우시안의 중앙점을 상기 소실점으로 추정할 수 있다. 일 실시 예에 따르면, 상기 인공지능 네트워크는, 상기 히트 맵에서 상기 소실점에 대응하는 키포인트를 추정하 는 네트워크를 포함할 수 있다. 일 실시 예에 따르면, 상기 추정부는, 상기 깊이 맵을 추정하는 경우, 상기 입력 영상에서 미리 설정된 적어도 하나 이상의 동적 객체를 검출하고, 상기 검출된 동적 객체의 영역을 제외한 정적 객체의 깊이 맵을 추정할 수 있다. 일 실시 예에 따르면, 상기 인공지능 네트워크는, CenterNet을 포함할 수 있다. 나아가, 본 개시의 다른 실시 예에 따른 소실점 추정 장치는, 상기 기준 그래디언트 맵을 생성하는 생성부를 더 포함하고, 상기 생성부는, 정적 객체만 있는 기준 공간과 기준 소실점을 생성하고, 상기 기준 공간과 상기 기준 소실점을 기반으로 기준 깊이 맵 또는 기준 광학 흐름 맵을 생성하며, 상기 기준 깊이 맵 또는 기준 광학 흐름 맵에 대한 그래디언트 맵을 생성함으로써, 상기 기준 그래디언트 맵을 생성할 수 있다. 일 실시 예에 따르면, 상기 소실점 GT 데이터는, 영상에 대한 깊이 맵 또는 광학 흐름 맵을 생성하고, 상기 깊 이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵을 생성하며, 상기 그래디언트 맵의 가우시안 피팅을 통해 상기 그래디언트 맵에 대한 히트 맵을 생성하고, 상기 가우시안 피팅에 의한 가우시안 중앙점을 이용하여 키포인트를 생성하며, 상기 가우시안 중앙점에 대한 좌표와 미리 설정된 적어도 하나 이상의 소실점 검출 기법에 의해 검출 된 소실점의 좌표가 일치하는 경우, 상기 히트 맵과 상기 키포인트에 기반하여 생성될 수 있다. 본 개시의 또 다른 실시 예에 따른 소실점 GT 생성 방법은, 입력 영상에 대한 깊이 맵 또는 광학 흐름 맵을 생 성하는 단계; 상기 깊이 맵 또는 광학 흐름 맵에 대한 그래디언트 맵을 생성하는 단계; 상기 그래디언트 맵의 가우시안 피팅을 통해 상기 그래디언트 맵에 대한 히트 맵을 생성하고, 상기 가우시안 피팅에 의한 가우시안 중 앙점을 이용하여 키포인트를 생성하는 단계; 및 상기 가우시안 중앙점에 대한 좌표와 미리 설정된 적어도 하나 이상의 소실점 검출 기법에 의해 검출된 소실점의 좌표가 일치하는 경우, 상기 히트 맵과 상기 키포인트에 기반 하여 소실점 GT를 생성하는 단계를 포함한다. 일 실시 예에 따르면, 상기 입력 영상은, 실제 영상 데이터를 포함할 수 있다."}
{"patent_id": "10-2023-0099152", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시에 대하여 위에서 간략하게 요약된 특징들은 후술하는 본 개시의 상세한 설명의 예시적인 양상일 뿐이며, 본 개시의 범위를 제한하는 것은 아니다."}
{"patent_id": "10-2023-0099152", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 실제 데이터의 소실점 GT를 생성하고, 이를 이용하여 인공지능 네트워크 예를 들어, 키포인 트 추정 네트워크인 CenterNet을 학습시킨 후 CenterNet을 이용하여 입력 영상에 대한 소실점을 추정함으로써, 입력 영상에 대한 소실점의 추정 정확도를 향상시키고, 주행 환경에 따른 제약 조건을 해소할 수 있다. 본 개시에 따르면, 입력 영상에 대한 소실점을 정확하게 추정함으로써, 차량에 구비된 카메라의 자세에 대한 추 정 정확도를 향상시킬 수 있다. 본 개시에 따르면, 실제 데이터에 대한 소실점 GT를 생성하여 네트워크를 학습시킴으로써, 실제 필드에서 소실 점을 추정하는데 적용할 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0099152", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 있어서, 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\" 또는 \"접속\"되어 있다고 할 때, 이는 직접 적인 연결 관계 뿐만 아니라, 그 중간에 또 다른 구성요소가 존재하는 간접적인 연결관계도 포함할 수 있다. 또 한 어떤 구성요소가 다른 구성요소를 \"포함한다\" 또는 \"가진다\"고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 배제하는 것이 아니라 또 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 있어서, 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용되 며, 특별히 언급되지 않는 한 구성요소들 간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 개시의 범 위 내에서 일 실시 예에서의 제1 구성요소는 다른 실시 예에서 제2 구성요소라고 칭할 수도 있고, 마찬가지로 일 실시 예에서의 제2 구성요소를 다른 실시 예에서 제1 구성요소라고 칭할 수도 있다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위한 것일 뿐, 구성요소들이 반드시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 개시의 범위에 포함된 다. 본 개시에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들을 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 개시의 범위에 포함된다. 또한, 다양한 실시 예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 본 명세서에 사용되는 위치 관계의 표현, 예컨대 상부, 하부, 좌측, 우측 등은 설명의 편의 를 위해 기재된 것이고, 본 명세서에 도시된 도면을 역으로 보는 경우에는, 명세서에 기재된 위치 관계는 반대 로 해석될 수도 있다. 본 개시에 있어서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. 본 개시의 실시 예들은, 실제 영상 데이터 기반의 소실점 GT 데이터를 생성하고, 이를 이용하여 인공지능 네트 워크 예를 들어, 키포인트 추정 네트워크인 CenterNet을 학습시킨 후 CenterNet을 이용하여 입력 영상에 대한 소실점을 추정함으로써, 입력 영상에 대한 소실점의 추정 정확도를 향상시키는 것을 그 요지로 한다. 본 개시의 실시 예들은, 실제 영상 데이터를 기반으로 생성된 소실점 GT 데이터를 이용하여 키포인트를 추정하 는 키포인트 추정 네트워크를 학습시키기 때문에, 실제 필드에서 영상의 소실점을 추정 정확도를 향상시킬 수 있다. 본 개시에서의 소실점 추정 기법은, 실제 영상 데이터를 기반으로 생성된 소실점 GT 데이터에 의해 학습된 키포 인트 추정 네트워크를 이용하는 것으로, 이하 상세한 설명에서는 설명의 편의를 위하여 CenterNet으로 설명하지 만, 키포인트 추정 네트워크가 CenterNet으로 제한되거나 한정되지 않으며, 키포인트를 추정할 수 있는 모든 종 류의 키포인트 추정 네트워크를 포함할 수 있다. 먼저, CenterNet에 대하여 간략하게 설명하면, CenterNet은 두 쌍의 특징점으로 바운딩 박스를 예측하는 CornerNet의 단점을 개선하기 위해 세 쌍의 특징점을 활용하는 네트워크로, 좌측 상단, 우측 하단, 중앙점 정보 를 활용하여 바운딩 박스를 예측한다. 예컨대, 도 1a에 도시된 바와 같이, CenterNet은 바운딩 박스(bounding box)와 중앙점으로 구성된다. 그리고, 바운딩 박스와 중앙점은 도 1b에 도시된 바와 같이, 가우시안 커널(Gaussian Kernel)로 표현 될 수 있다. 예컨대, 바운딩 박스는 가우시안 커널로 표현되고, 중앙점은 가우시안 커널의 피크점으 로 표현될 수 있다. 따라서, CenterNet을 학습시키기 위해서는 바운딩 박스를 2D 가우시안으로 변경하여야 한다. 소실점은 바운딩 박스의 개념이 없기 때문에 소실점이 중앙점인 2D 가우시안을 생성하고, 이를 이용하여 CenterNet을 학습시킴으 로써, CenterNet을 이용하여 소실점을 추정할 수 있다. 기존에는 네트워크를 학습시키기 위한 학습 데이터 즉, 소실점 GT 데이터가 시뮬레이션 데이터를 활용하여 생성 되기 때문에 사실상 실제 필드에 적용시키기 어려운 문제가 있다. 본 개시의 실시 예에 따른 기술은, 실제 영상 데이터를 기반으로 소실점 GT 데이터를 생성한 후 실제 영상 데이 터 기반의 소실점 GT 데이터를 학습 데이터로 CenterNet을 학습시킴으로써, 실제 필드에 적용하여 소실점을 추 정할 수 있다. 즉, 본 개시의 실시 예에서의 CenterNet은 소실점 GT 데이터의 2D 가우시안을 학습시킴으로써, 입력 영상에 대 한 소실점을 추정할 수 있다. 실제 영상 데이터를 기반으로 소실점 GT 데이터를 생성하는 과정에 대하여 도 2를 참조하여 설명하면 다음과 같 다. 도 2는 본 개시의 일 실시 예에 따른 소실점 GT 생성 방법에 대한 동작 흐름도를 나타낸 것이다. 도 2를 참조하면, 본 개시의 일 실시 예에 따른 소실점 GT 생성 방법은, 실제 영상 데이터인 입력 영상을 수신 하고, 수신된 입력 영상에 대한 깊이 맵(depth map) 또는 깊이 영상을 생성한다(S210, S220). 여기서, 단계 S220은, 입력 영상을 깊이 맵으로 변환하는 다양한 방식을 통해 깊이 맵을 생성할 수 있으며, 깊 이 맵을 생성하는 과정은 이 기술 분야에 종사하는 당업자에게 있어서 자명하기에 그 상세한 설명한다. 실시 예에 따라, 단계 S220은 입력 영상에 포함된 객체들 중 동적 객체를 검출하고, 검출된 동적 객체에 대한 영역을 제외한 나머지 영역 즉, 정적 객체에 대한 영역만으로 깊이 맵을 생성할 수 있다. 이때, 동적 객체는 미 리 설정된 동적 객체를 검출하기 위한 영상 분석 또는 동적 객체 검출 네트워크에 의해 검출될 수 있다. 단계 S220에 의해 입력 영상에 대한 깊이 맵이 생성되면, 깊이 맵에 대한 그래디언트 맵(gradient map)을 생성 한다(S230). 실시 예에 따라, 단계 S230은 깊이 맵을 메쉬(mesh)로 분할하여 각 메쉬마다 그래디언트를 생성함으로써, 깊이 맵에 대한 그래디언트 맵을 생성할 수 있다. 본 개시에서 깊이 맵에 대한 그래디언트 맵을 생성하는 것은, 깊이 맵을 이용한 연산의 경우 픽셀 단위(pixel by pixel) 연산량이 많기 때문에 이러한 연산량을 줄이기 위한 것이다. 여기서, 깊이 맵에서 그래디언트 맵 생성하는 과정은 다양한 방식에 의해 수행될 수 있으며, 이러한 방식은 이 기술 분야에 종사하는 당업자에게 있어서 자명하기에 그 상세한 설명한다. 단계 S230에 의해 그래디언트 맵이 생성되면, 그래디언트 맵에 대한 가우시안 피팅을 통해 히트 맵(heat map)과 키포인트를 생성한다(S240). 여기서, 단계 S240은 2D 가우시안의 중앙점을 소실점에 대응하는 키포인트로 생성할 수 있다. 그리고, 입력 영상에 대하여, 미리 설정되거나 정의된 다양한 소실점 검출 기법 또는 소실점 트래킹 기법을 통 해 입력 영상에 대한 소실점을 검출한다(S250). 실시 예에 따라, 단계 S250은, TM(Template Machign)-VDC 기법, LI(Line Inference)-VDC 기법과 광학 흐름 (optical flow) 기법 각각을 통해 입력 영상에 대한 소실점을 검출할 수 있다. TM-VDC 기법은, 소실점 트래킹 기법으로, 소실점이 존재하는 영역을 크랍(crop)하고, 다음 프레임에서 크랍 (crop)된 영역과 일치하는 영역을 찾을 수 있다. 여기서, 해당 기법은 일치하는 영역을 찾기 위해 TM을 사용하 고, 크랍된 영역이 움직인 만큼, 소실점이 이동했다고 가정할 수 있다. LI-VDC 기법은 평행한 두 직선이 영상에서 교차하며, 이 교차점을 소실점으로 가정하는 기법으로, 차선을 검출 한 후 이를 직선으로 피팅하고 직선이 교차하는 지점을 소실점으로 검출할 수 있다. 광학 흐름 기법은, 이전 프레임과 다음 프레임 간의 RT를 추정하고, R에 의해 소실점이 이동되었다고 가정하는 기법으로, 광학 흐름을 검출하고, RT를 추정(Epipolar Geometry)한 후 R을 활용하여 소실점 이동량을 계산한다. 비록, 단계 S250이 단계 S240 이후에 수행되는 것으로 도시하였지만, 단계 S250은 입력 영상을 수신한 후 병렬 적으로 수행될 수도 있다. 단계 S240과 S250을 통해, 가우시안 중앙점과 각 기법에 의해 소실점이 검출되면, 가우시안 중앙점의 좌표와 각 기법에 의해 검출된 소실점의 좌표가 모두 일치하는지 판단하고, 모든 좌표가 일치하는 것으로 판단되면 단계 S240에 의해 생성된 히트 맵과 키포인트를 이용하여 소실점 GT 데이터를 생성한다(S260, S270). 상술한 과정이, 실제 영상 데이터 각각에 대하여 이루어지고, 이를 통해 실제 영상 기반 소실점 GT 데이터가 수 집되면 수집된 소실점 GT 데이터를 CenterNet을 학습시키기 위한 학습 데이터로 사용한다. 비록, 도 2에서 입력 영상에 대한 깊이 맵을 이용하여 실제 영상 기반 소실점 GT 데이터를 생성하는 것으로 설 명하였지만, 입력 영상에 대한 깊이 맵을 이용하여 소실점 GT 데이터를 생성하는 것으로 제한되거나 한정되지 않으며, 입력 영상에 대한 광학 흐름(optical flow) 맵을 생성하고, 광학 흐름 맵에 대한 그래디언트 맵을 생성 하는 과정을 통해 소실점 GT 데이터를 생성할 수도 있다. 이하, 도 3 내지 도 8은 도 2의 과정을 통해 생성된 실제 영상 기반 소실점 GT 데이터를 이용한 2D 가우시안 학 습을 통해 학습된 CenterNet을 이용하여 영상에 대한 소실점을 추정하는 방식을 설명한다.도 3은 본 개시의 다른 실시 예에 따른 소실점 추정 방법에 대한 동작 흐름도를 나타낸 것이다. 도 3을 참조하면, 본 개시의 다른 실시 예에 따른 소실점 추정 방법은, 실제 영상 데이터인 입력 영상을 수신하 는 과정(S310)과 실제 영상 기반의 소실점 GT 데이터에 의해 학습된 CenterNet을 이용하여 입력 영상에 대한 소 실점을 추정하는 과정(S320, S330, S340, S350)을 포함한다. 실시 예에 따라, 단계 S310은 차량 예를 들어, 자율 주행 차량 또는 첨단 운전자보조 시스템(Advanced Driver Assistant Systems, ADAS)를 탑재한 차량 등에 구비된 카메라에 의해 실시간으로 촬영되는 영상을 입력 영상으 로 수신할 수 있다. CenterNet을 이용하여 입력 영상에 대한 소실점을 추정하는 과정은, CenterNet을 이용하여 단계 S310을 통해 수 신되는 입력 영상에 대한 깊이 맵을 추정하고, 추정된 깊이 맵에 대한 그래디언트 맵을 추정한다(S320, S330). 실시 예에 따라, 단계 S320은 도 5a에 도시된 바와 같이, 입력 영상이 수신되면 수신된 입력 영상에 대한 깊이 맵(도 5b)을 추정할 수 있다. 본 개시의 기술에서, 깊이 맵에서 노면과 벽면 영역(화살표)을 2D 가우시안으로 가정하면, 그 중앙점이 소실점(X)이 될 수 있으며, 따라서, 깊이 맵을 추정하는 것은 2D 가우시안을 통해 소실 점을 추정하기 위한 것이다. 실시 예에 따라, 단계 S320은 깊이 맵을 추정하는데 있어서, 동적 객체에 의해 발생될 수 있는 소실점의 추정 오차를 줄이고, 소실점의 추정 정확도를 향상시키기 위하여, 입력 영상에서 동적 객체를 검출한 후 검출된 동적 객체 영역을 제외한 나머지 영역의 깊이 맵을 추정할 수 있다. 예컨대, 깊이 맵에서 동적 객체 영역을 제외시키 기 위하여, 도 6a에 도시된 바와 같이, 입력 영상에서 동적 객체를 검출하여 검출된 동적 객체 영역을 제 외한 후 도 6b에 도시된 바와 같이, 동적 객체 영역이 제외된 정적 객체만의 깊이 맵을 추정할 수 있다. 여기서, 동적 객체는, 동적 객체를 검출하기 위한 객체 검출 네트워크에 의해 검출될 수도 있고, 동적 객체에 대한 세그먼테이션 마스크(segmentation mask)를 기반으로 검출될 수도 있다. 물론, 동적 객체를 검출하는 방식 이 상술한 방식으로 제한되거나 한정되지 않는다. 상기 단계 S330에 의해 입력 영상에 대한 그래디언트 맵이 추정되면, CenterNet에서 추정된 그래디언트 맵과 미 리 설정되거나 정의된 기준 그래디언트 맵을 기반으로 입력 영상의 정적 객체에 대한 히트 맵을 추정하고, 추정 된 히트 맵을 이용하여 입력 영상의 소실점을 추정한다(S340, S350). 실시 예에 따라, 단계 S350은, 정적 객체에 대한 히트 맵의 2D 가우시안 피팅을 수행하고, 가우시안 피팅을 통 해 가우시안의 중앙점을 소실점으로 추정할 수 있다. 나아가, 단계 S340에서 비교되는 기준 그래디언트 맵은 다양한 방식에 의해 미리 설정되거나 생성되어, CenterNet에서 이용할 수 있으며, 이러한 기준 그래디언트 맵 예를 들어, 앵커 그래디언트 맵을 생성하는 과정 에 대하여 도 4를 참조하여 설명한다. 깊이 맵에 대한 기준 그래디언트 맵을 생성하는 과정은, 도 4에 도시된 바와 같이, 사각형 터널과 같은 정적 객 체만 있는 기준 공간을 생성하고, EOD(End-Of-Line) 카메라 캘리브레이션을 수행한 후 기준 소실점을 생성한다. 상술한 과정을 통해 생성된 기준 공간과 기준 소실점을 기반으로 기준 깊이 맵을 생성한 후 기준 깊이 맵에 대 한 기준 그래디언트 맵을 생성함으로써, 깊이 맵 기반 기준 그래디언트 맵(depth map-based anchor)를 생성할 수 있다. 이와 같이, 본 개시의 실시 예에 따른 소실점 추정 방법은, 실제 영상 데이터의 소실점 GT를 생성하고, 이를 이 용하여 인공지능 네트워크 예를 들어, 키포인트 추정 네트워크인 CenterNet을 학습시킨 후 CenterNet을 이용하 여 입력 영상에 대한 소실점을 추정함으로써, 입력 영상에 대한 소실점의 추정 정확도를 향상시키고, 이를 통해 주행 환경에 따른 제약 조건을 해소할 수 있다. 또한, 본 개시의 실시 예에 따른 소실점 추정 방법은, 입력 영상에 대한 소실점을 정확하게 추정함으로써, 차량 에 구비된 카메라의 자세에 대한 추정 정확도를 향상시킬 수 있다. 또한, 본 개시의 실시 예에 따른 소실점 추정 방법은, 실제 영상 데이터에 대한 소실점 GT를 생성하여 CenterNet 등과 같은 키포인트 추정 네트워크를 학습시킴으로써, 실제 필드에서 영상의 소실점을 추정하는데 적용할 수 있다. 나아가, 본 개시의 실시 예에 따른 소실점 추정 방법은, 깊이 맵 기반으로 제한되거나 한정되지 않으며, 도 7에 도시된 바와 같이 입력 영상(도 7a)에 대한 광학 흐름 맵(도 7b)을 기반으로 입력 영상에 대한 소실점을 추정할 수도 있다. 이때, 입력 영상에 대한 광학 흐름 맵은 도 7b에 도시된 바와 같이, 광학 흐름의 벡터 방향이 색상 으로 표현되고 광학 흐름의 강도가 농도로 표현될 수 있으며, 이러한 광학 흐름 맵 또한 깊이 맵과 마찬가지로 CenterNet을 이용하여 소실점을 추정할 수 있다. 물론, 광학 흐름 맵 기반으로 소실점을 추정하기 위해서는, 실 제 영상 데이터에 대한 광학 흐름 맵 기반으로 소실점 GT 데이터를 생성하고, 이렇게 생성된 소실점 GT 데이터 를 이용하여 CenterNet을 학습시키는 것이 바람직하다. 또한, CenterNet에서 광학 흐름 맵 기반으로 소실점을 추정하기 위해서는, 기준 그래디언트 맵을 깊이 맵 기반 앵커를 사용하는 것이 아니라, 광학 흐름 맵 기반 앵커를 사용하는 것이 바람직하다. 즉, CenterNet을 이용하여 입력 영상에 대한 광학 흐름 맵을 추정한 후 광학 흐름 맵 기반 그래디언트 맵을 추정하는 경우에는, 기준 그래 디언트 맵이 광학 흐름 맵 기반 앵커일 수 있다. 이때, 광학 흐름 맵 기반 앵커를 생성하는 과정은, 기준 공간 과 기준 소실점을 기반으로 기준 광학 흐름 맵을 생성한 후 기준 광학 흐름 맵에 대한 기준 그래디언트 맵을 생 성함으로써, 광학 흐름 맵 기반 앵커(optical flow map-based anchor)를 생성할 수 있다. 상술한 바와 같이, 본 개시의 실시 예에 따른 방법은, 깊이 맵 기반으로 입력 영상에 대한 소실점을 추정할 수 있을 뿐만 아니라 광학 흐름 맵 기반으로 입력 영상에 대한 소실점을 추정할 수도 있다. 즉, 본 개시의 방법은, 깊이 맵 기반 영상에도 적용할 수도 있으며, 광학 흐름 맵 기반 영상에도 적용할 수도 있다. 도 8은 본 개시의 또 다른 실시 예에 따른 소실점 추정 장치에 대한 블록도를 나타낸 것으로, 도 3 내지 도 7의 소실점 추정 방법을 수행하는 장치에 대한 블록도를 나타낸 것이다. 도 8을 참조하면, 본 개시의 또 다른 실시 예에 따른 소실점 추정 장치는, 수신부, 추정부, 생 성부와 저장부를 포함한다. 저장부는, 본 개시의 기술과 관련된 모든 데이터를 저장하는 구성 수단으로, CenterNet, 기준 그래디언트 맵 등과 같은 데이터를 저장할 수 있다. 수신부는, 소실점을 추정하고자 하는 입력 영상을 수신한다. 실시 예에 따라, 수신부는, 차량 예를 들어, 자율 주행 차량 또는 첨단 운전자보조 시스템(ADAS)를 탑재한 차량 등에 구비된 카메라에 의해 실시간으로 촬영되는 영상을 입력 영상으로 수신할 수 있다. 추정부는, 실제 영상 기반의 소실점 GT 데이터에 의해 학습된 CenterNet을 이용하여 입력 영상에 대한 소 실점을 추정한다. 실시 예에 따라, 추정부는, CenterNet을 이용하여 수신부로 수신되는 입력 영상에 대한 깊이 맵을 추 정하고, 추정된 깊이 맵에 대한 그래디언트 맵을 추정하며, 추정된 그래디언트 맵과 미리 설정된 기준 그래디언 트 맵을 기반으로 입력 영상의 정적 객체에 대한 히트 맵을 추정하고, 추정된 히트 맵을 이용하여 입력 영상의 소실점을 추정할 수 있다. 실시 예에 따라, 추정부는, 동적 객체에 의해 발생될 수 있는 소실점의 추정 오차를 줄이고, 소실점의 추 정 정확도를 향상시키기 위하여, 입력 영상에서 동적 객체를 검출한 후 검출된 동적 객체 영역을 제외한 나머지 영역의 깊이 맵을 추정할 수 있다. 생성부는, 기준 그래디언트 맵을 생성하는 구성 수단으로, 사각형 터널과 같은 정적 객체만 있는 기준 공 간을 생성하고, 기준 소실점을 생성한 후 기준 공간과 기준 소실점을 기반으로 기준 깊이 맵 또는 기준 광학 흐 름 맵을 생성하고, 기준 깊이 맵 또는 기준 광학 흐름 맵에 대한 기준 그래디언트 맵을 생성함으로써, 깊이 맵 기반 기준 그래디언트 맵 또는 광학 흐름 맵 기반 기준 그래디언트 맵을 생성한다. 여기서, 생성부는 CenterNet에서 사용하는 기준 그래디언트 맵을 생성하는 구성 수단이기에, 기준 그래디 언트 맵이 생성되어 이미 저장되거나 CenterNet에 적용된 경우에는 해당 구성 수단이 생략되거나 제거될 수도 있다. 비록, 본 개시의 다른 실시 예에 따른 장치에서 그 설명이 생략되더라도, 본 개시의 다른 실시 예에 따른 장치 는 도 3 내지 도 7의 방법에서 설명한 모든 내용을 포함할 수 있으며, 이는 본 개시의 기술 분야에 종사하는 당 업자에게 있어서 자명하다. 마찬가지로, 도 2에 도시된 소실점 GT 생성 방법 또한 소실점 생성 장치로 구현될 수도 있다. 도 9는 본 개시의 다른 실시 예에 따른 소실점 추정 방법을 실행하기 위한 컴퓨팅 시스템의 블록도를 나타낸 것 이다. 도 9를 참조하면, 상술한 본 개시의 다른 실시 예에 따른 소실점 추정 방법은 컴퓨팅 시스템을 통해서도 구현될 수 있다. 컴퓨팅 시스템은 시스템 버스를 통해 연결되는 적어도 하나의 프로세서, 메모리 , 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치, 스토리지, 및 네트워 크 인터페이스를 포함할 수 있다. 프로세서는 중앙 처리 장치(CPU) 또는 메모리 및/또는 스토리지에 저장된 명령어들에 대한 처리를 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 다양한 종류의 휘발성 또는 비휘발 성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM(Read Only Memory) 및 RAM(Random Access Memory)을 포함할 수 있다. 물론, 본 개시의 일 실시 예에 따른 소실점 GT 생성 방법 또한 도 9의 컴퓨팅 시스템을 통해 구현될 수도 있다. 따라서, 본 명세서에 개시된 실시 예들과 관련하여 설명된 방법 또는 알고리즘의 단계는 프로세서에 의해 실행되는 하드웨어, 소프트웨어 모듈, 또는 그 2 개의 결합으로 직접 구현될 수 있다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 디스크, 착탈형 디스크, CD-ROM과 같은 저장 매체(즉, 메모리 및/또는 스토리지)에 상주할 수도 있다. 예시적인 저장 매체 는 프로세서에 커플링되며, 그 프로세서는 저장 매체로부터 정보를 판독할 수 있고 저장 매체에 정 보를 기입할 수 있다. 다른 방법으로, 저장 매체는 프로세서와 일체형일 수도 있다. 프로세서 및 저장 매체는 주문형 집적회로(ASIC) 내에 상주할 수도 있다. ASIC는 사용자 단말기 내에 상주할 수도 있다. 다 른 방법으로, 프로세서 및 저장 매체는 사용자 단말기 내에 개별 컴포넌트로서 상주할 수도 있다. 이상의 설명은 본 개시의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 개시가 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 개시의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 개시에 개시된 실시 예들은 본 개시의 기술 사상을 한정하기 위한 것이 아니라 설명하 기 위한 것이고, 이러한 실시 예에 의하여 본 개시의 기술 사상의 범위가 한정되는 것은 아니다. 본 개시의 보 호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 개시 의 권리범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2023-0099152", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 CenterNet을 설명하기 위한 일 예시도를 나타낸 것이다. 도 2는 본 개시의 일 실시 예에 따른 소실점 GT 생성 방법에 대한 동작 흐름도를 나타낸 것이다. 도 3은 본 개시의 다른 실시 예에 따른 소실점 추정 방법에 대한 동작 흐름도를 나타낸 것이다. 도 4는 기준 그래디언트 맵을 생성하는 과정에 대한 일 실시 예의 동작 흐름도를 나타낸 것이다. 도 5는 깊이 맵에서의 소실점을 추정하는 방식을 설명하기 위한 일 예시도를 나타낸 것이다. 도 6은 정적 객체의 깊이 맵을 생성하는 방식을 설명하기 위한 일 예시도를 나타낸 것이다. 도 7은 광학 흐름 맵에서의 소실점을 추정하는 방식을 설명하기 위한 일 예시도를 나타낸 것이다. 도 8은 본 개시의 또 다른 실시 예에 따른 소실점 추정 장치에 대한 블록도를 나타낸 것이다. 도 9는 본 개시의 다른 실시 예에 따른 소실점 추정 방법을 실행하기 위한 컴퓨팅 시스템의 블록도를 나타낸 것 이다."}
