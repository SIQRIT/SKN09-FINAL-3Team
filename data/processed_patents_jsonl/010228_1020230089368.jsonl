{"patent_id": "10-2023-0089368", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0009286", "출원번호": "10-2023-0089368", "발명의 명칭": "얇은 객체를 검출하기 위한 방법", "출원인": "주식회사 룰루랩", "발명자": "김세민"}}
{"patent_id": "10-2023-0089368", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "검출 대상인 객체를 포함하는 분석 이미지를 습득하는 단계; 및객체를 검출하도록 훈련된 객체 검출 모델을 이용하여 분석 이미지에서 객체를 검출하는 단계를 포함하며,상기 객체 검출 모델은,GT를 이용한 심층 지도를 수행함에 있어서, 공간 차원이 감소한 디코더에서 도출된 특성맵 대해서는, 공간 차원감소 비율인 1/s의 s를 스케일 팩터로 적용하여 객체에 대한 가중치가 조절된 가중치 맵을 생성하여 손실 함수를 적용하며,상기 가중치 맵을 생성하는 과정이,GT를 공간 차원 감소 비율인 1/s에 맞춰 다운 샘플링하는 단계 1;다운 샘플링된 이미지를 업스케일링 하는 단계 2;업스케일링된 이미지에서 0값을 가지는 부분을 0초과 1미만인 소정의 값으로 교체하는 단계 3; 및GT에서 값이 1이었던 곳과 같은 위치에 대한 업스케일링된 이미지의 값을 1로 설정하는 단계 4를 포함하는 것을특징으로 하는 얇은 객체를 검출하기 위한 방법."}
{"patent_id": "10-2023-0089368", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 단계 1은, GT를 hd × wd 그리드 포맷으로 분할( )한 뒤에, 각 그리드에서 평균값을 계산하여 다운 샘플링된 이미지를 도출하는 것을 특징으로 하는 얇은 객체를 검출하기 위한 방법."}
{"patent_id": "10-2023-0089368", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 단계 2는, 다운 샘플링된 이미지에 최근접 보간법을 적용하여 업스케일링된 이미지를 도출하는 것을 특징으로 하는 얇은객체를 검출하기 위한 방법."}
{"patent_id": "10-2023-0089368", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 단계 3은, 업스케일링된 이미지에 대한 평균을 계산하고, 업스케일링된 이미지에서 0의 값을 가지는 부분을 계산된 평균값으로 교체하여 수행되는 것을 특징으로 하는 얇은 객체를 검출하기 위한 방법."}
{"patent_id": "10-2023-0089368", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0009286-3-청구항 1에 있어서,공간 차원 손실이 없는 디코더에서 추출된 특성맵에 적용되는 손실함수는 다음과 같고, 여기서 pn,i는 n번째 특성맵의 i번째 값이고, q는 GT이며,공간 차원 손실이 있는 디코더에서 추출된 특성맵에 적용되는 손실함수는 다음과 같고,여기서 wn,i는 n번째 가중치 맵의 i번째 값인 것을 특징으로 하는 얇은 객체를 검출하기 위한 방법."}
{"patent_id": "10-2023-0089368", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,검출 대상인 객체가 얼굴 주름인 것을 특징으로 하는 얇은 객체를 검출하기 위한 방법."}
{"patent_id": "10-2023-0089368", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,검출 대상인 객체가 망막 혈관인 것을 특징으로 하는 얇은 객체를 검출하기 위한 방법."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 얇은 객체를 검출하기 위한 방법에 관한 것으로, 검출 대상인 객체를 포함하는 분석 이미지를 습득하 는 단계; 및 객체를 검출하도록 훈련된 객체 검출 모델을 이용하여 분석 이미지에서 객체를 검출하는 단계를 포 함하며, 상기 객체 검출 모델은, GT를 이용한 심층 지도를 수행함에 있어서, 공간 차원이 감소한 디코더에서 도 (뒷면에 계속)"}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝을 기반으로 하여 이미지에 포함된 얇은 객체를 검출하는 기술에 관한 것으로, 더욱 자세하게 는 피부 이미지에서 주름과 같이 얇은 객체를 검출하기 위한 검출 기술에 관한 것이다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "얼굴 주름은 나이 예측 및 감정 식별과 같이 다양한 응용 분야에서 폭넓게 활용된다. 얼굴 피부 분석 분야에서, 주름 감지는 사용자의 피부 상태를 측정하거나, 개인 피부에 적합한 화장품들을 추천하는 데 활용될 수 있다. 많은 사람이 미용에 관심을 갖고 있는 최근의 경우, 얼굴 주름을 해결하기 위한 다양한 화장품이나 기타 치료 또는 처치 수단이 연구되고 있다. 그런데, 이러한 얼굴 주름 문제를 해결하기 위해서는 얼굴의 주름을 검출하는 것이 선결 과제에 해당하기 때문에, 얼굴 주름을 검출하기 위한 연구도 활발하게 이루어지고 있다. 다양한 연구들 중 대다수는 얼굴 주름의 연결성이나 방향과 같은 구조적 특징을 이용하여 얼굴 주름 검출을 시 도하고 있으며, 최근 연구에서는 헤시안 필터(Hessian filter) 또는 가버 필터(Gabor filter)를 이용한 얼굴 주 름 검출 기법이 제안되고 있다. 헤시안 필터를 이용한 기법은 구체적으로, 그 원소로 2차 편미분 값을 갖는 헤시안 매트릭스가 사용되며, 그 헤 시안 매트릭스의 고유값(eigenvalue)과 같은 고유 정보를 이용하여 2차원 이미지의 특징을 결정함과 함께 고유 정보의 수정을 통해 얼굴 검출을 수행하도록 구성된다. 가버 필터를 이용한 기법은, 사인 함수로 변조된 가우시안 커널의 형태를 갖는 선형 필터인 가버 필터를 이용한 컨볼루션을 통해, 해당 이미지에서 특정 주파수 성분의 크기와 방향이 강조되는 것을 활용하며, 얼굴 주름 검출 은 가버 필터를 적용한 이미지에 대한 전처리 또는 후처리 필터를 적용함으로써 이루어진다.전술한 기법들의 경우, 이마와 같이 특정 영역에서만 유효한 검출 성능을 제공하고 얼굴 전체에 대해 고른 검출 성능을 보장하지 못하는 문제가 있고, 필터 파라미터가 주름 검출 성능을 향상시키기 위해서 분석 대상 이미지 마다 개별적으로 미세 조정되어야 하기 때문에, 해상도, 밝기, 주름의 두께 등이 다양한 형태의 이미지들에 대 해 일관된 성능을 보장하기 어려운 문제가 있다. 최근 인공지능(AI)에 대한 연구가 크게 확대되면서, 영상 인식 분야에서 특히 그 성능을 인정받고 있는 딥러닝 기반의 영상 분석을 통해서 이미지 내에서 특정의 객체를 검출하는 기술을 기반으로 하는 영상 식별 기술을 얼 굴 주름 검출에 적용하려는 노력이 이어지고 있다. 선행기술문헌 비특허문헌 (비특허문헌 0001) A. F. Frangi, \"Three-dimensional model-based analysis of vascular and cardiac images,\" Ph.D. dissertation, Univ. Med. Center Utrecht, Utrecht, The Netherlands, 2001. (비특허문헌 0002) C.-C. Ng, M. H. Yap, N. Costen, and B. Li, \"Automatic wrinkle detection using hybrid Hessian filter,\" in Proc. 12th Asian Conf. Comput. Vis., 2014, pp. 609-622. (비특허문헌 0003) C.-C. Ng, M. H. Yap, N. Costen, and B. Li, \"Wrinkle detection using hessian line tracking,\" IEEE Access, vol. 3, pp. 1079-1088, 2015. (비특허문헌 0004) O. G. Cula, P. R. A. BargoNkengne, and N.Kollias, \"Assessing facial wrinkles: Automatic detection and quantification,\" Skin Res. Technol., vol. 19, no. 1, pp. e 243-e251, 2013 (비특허문헌 0005) N. Batool and R. Chellappa, \"Fast detection of facial wrinkles based on gabor features using image morphology and geometric constraints,\" Pattern Recognit., vol. 48, no. 3, pp. 642-658, 2015."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서 딥러닝 기술을 이용하여 얇은 객체에 대한 검 출 정확도가 향상되는 새로운 방법을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명에 의한 얇은 객체를 검출하기 위한 방법은, 검출 대상인 객체를 포함하는 분석 이미지를 습득하는 단계; 및 객체를 검출하도록 훈련된 객체 검출 모델을 이용하여 분석 이미지에서 객체 를 검출하는 단계를 포함하며, 상기 객체 검출 모델은, GT를 이용한 심층 지도를 수행함에 있어서, 공간 차원이 감소한 디코더에서 도출된 특성맵 대해서는, 공간 차원 감소 비율인 1/s의 s를 스케일 팩터로 적용하여 객체에 대한 가중치가 조절된 가중치 맵을 생성하여 손실 함수를 적용하며, 상기 가중치 맵을 생성하는 과정이, GT를 공간 차원 감소 비율인 1/s에 맞춰 다운 샘플링하는 단계 1; 다운 샘플링된 이미지를 업스케일링 하는 단계 2; 업스케일링된 이미지에서 0값을 가지는 부분을 0초과 1미만인 소정의 값으로 교체하는 단계 3; 및 GT에서 값이 1이었던 곳과 같은 위치에 대한 업스케일링된 이미지의 값을 1로 설정하는 단계 4를 포함하는 것을 특징으로 한 다. 상기 단계 1은, GT를 hd × wd 그리드 포맷으로 분할( )한 뒤에, 각 그리드에서 평균값을 계 산하여 다운 샘플링된 이미지를 도출하는 것일 수 있다. 상기 단계 2는, 다운 샘플링된 이미지에 최근접 보간법을 적용하여 업스케일링된 이미지를 도출하는 것일 수 있 다. 상기 단계 3은, 업스케일링된 이미지에 대한 평균을 계산하고, 업스케일링된 이미지에서 0의 값을 가지는 부분 을 계산된 평균값으로 교체하여 수행되는 것일 수 있다.공간 차원 손실이 없는 디코더에서 추출된 특성맵에 적용되는 손실함수는 다음과 같고, 여기서 pn,i는 n번째 특성맵의 i번째 값이고, q는 GT이며, 공간 차원 손실이 있는 디코더에서 추출된 특성맵에 적용되는 손실함수는 다음과 같고,"}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "여기서 wn,i는 n번째 가중치 맵의 i번째 값인 것일 수 있다. 검출 대상인 객체가 얼굴 주름일 수 있다. 검출 대상인 객체가 망막 혈관일 수 있다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 구성된 본 발명은, 공간 차원의 감소에 따른 객체의 가중치를 반영한 가중치 맵을 생성하여 심층 지도를 수행함으로써, 얇은 객체에 대한 검출 성능이 향상되는 뛰어난 효과가 있다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부된 도면을 참조하여 본 발명에 따른 실시예를 상세히 설명한다. 그러나 본 발명의 실시형태는 여러 가지의 다른 형태로 변형될 수 있으며, 본 발명의 범위가 이하 설명하는 실 시형태로만 한정되는 것은 아니다. 도면에서의 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있으며, 도면상의 동일한 부호로 표시되는 요소는 동일한 요소이다. 그리고 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때 이는 \"직접적으로 연결\"되어 있는 경우뿐만 아니라 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한, 어 떤 부분이 어떤 구성요소를 \"포함\" 또는 \"구비\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성요소를 더 포함하거나 구비할 수 있는 것을 의미 한다.또한, \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하 게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 본 발명은 검출 객체를 포함하는 분석 이미지에서 객체를 검출하는 방법에 대한 것이다. 분석 이미지는 기존에 다른 촬영 장치에 의해서 촬영된 이미지일 수도 있고, 분석을 위하여 실시간으로 촬영된 이미지일 수도 있다. 실시간으로 이미지를 촬영할 수 있는 수단이 제한 없이 적용될 수 있으며, 촬영을 위한 카 메라와 무선(또는유선)으로 전원을 공급하는 전원 공급부, 사용자의 제어 입력을 수신하도록 물리적인 버튼 또 는 터치 디스플레이 등으로 구현된 사용자 입력부, 객체를 검출하기 위한 장치와 유무선 네트워크를 이용하여 통신하기 위한 통신 모듈 등의 일반적인 구성을 포함할 수 있다. 분석 이미지에서 객체를 검출하는 동작을 수행하는 장치는 아래에 설명할 검출 모델을 적용할 수 있는 구성이면 특별히 제한되지 않으며, 통신 가능한 데스크탑 컴퓨터(desktop computer), 랩탑 컴퓨터(laptop computer), 노 트북(notebook), 스마트폰(smart phone), 태블릿 PC(tablet PC), 모바일폰(mobile phone), 스마트 워치(smart watch), 스마트 글래스(smart glass), e-book 리더기, PMP(portable multimedia player), 휴대용 게임기, 네비 게이션(navigation) 장치, 디지털 카메라(digital camera), DMB(digital multimedia broadcasting) 재생기, 디 지털 음성 녹음기(digital audio recorder), 디지털 음성 재생기(digital audio player), 디지털 동영상 녹화 기(digital video recorder), 디지털 동영상 재생기(digital video player), PDA(Personal Digital Assistant) 등일 수 있다. 도 1은 본 발명의 일 실시예에 따른 얇은 객체를 검출하기 위한 방법에서 적용되는 객체 분할 모델의 구조를 도 시한 개념도이다. 도시된 실시예는 얼굴 촬영 이미지에서 주름을 검출하는 과정이며, 본 실시예에서 적용된 객체 분할 모델 (object segmentation model)은 U-Net 구조에 기반하고, 각 디코더(D1, D2, D3, D4)에서 특성맵(Feature Map) 을 추출하고 여러 가지 손실을 계산하는 심층 지도(Deep Supervision)를 기반으로 구성된다. U-Net은 현미경 영상에서 세포의 의미 분할을 위하여 제안되었으며, 이후로 생체 의학 영상에 대한 의미 분할을 위하여 사용되 고 있다. U-Net은 CNN(Convolutional Neural Network) 기반의 인공신경망으로서 입력 영상에서 적은 수의 다운 샘플링을 통해 얻어지는 얕은 층의 특성맵들을 다수의 다운 샘플링을 통해 얻어진 깊은 층의 특성맵들과 결합하 여 예측결과를 출력하는 모델이다. U-Net은 축소경로에 따른 여러 개의 인코더와 확장경로에 따른 여러 개의 디 코더로 구성되며 각 인코더는 스킵 연결을 통해 디코더에 연결된다. 이때, 본 실시예는 첫 번째 특성맵(F1)을 제외하고 가중 심층 지도(Weighted Deep Supervision)를 적용하는 점 에 특징이 있다. 원본 이미지(I)와 텍스처 맵(T)을 연결하여 입력으로 사용한다. 'Conv'는 컨볼루션 레이어(convolution layer s)이고, 'BN'은 배치놈 레이어(batchnorm layers)이며, 리키 ReLU(Leaky ReLU)는 활성화 함수이다. 각 특성맵 의 왼쪽 하단에 있는 숫자는 너비 또는 높이를 나타내고, 위의 숫자는 채널 수를 나타낸다. 오른쪽에는 GT(Ground Truth)와 가중 주름 맵(Weighted Wrinkle Map)이 있으며, 붉은색으로 표시된 부분은 본 실시예에 따 른 가중치가 적용된 심층 지도(Deep Supervision)를 나타낸다. 이때, 원본 이미지는 얼굴에서 이마와 눈 주위를 중심으로 추출된 분석 영역을 사용한다. 이마에는 자주 움직이 는 표정 근육이 많고, 눈 주위는 피부가 얇고 표정 근육이 많기 때문에 주름이 많이 생기며, 이 두 영역은 얼굴 의 전반적인 노화를 추정할 수도 있다. 이마와 눈 주위를 중심으로 분석 영역을 추출하는 방법은 특별히 제한되지 않고 다양한 방법이 적용될 수 있다. 본 실시예에서는 랜드마크 포인트 검출 방법을 적용하였으며, 랜드마크 포인트 검출 방법은 눈, 눈썹, 코, 입, 턱선 등의 특징점을 추출하는 방식이다. 도 2는 본 발명의 일 실시예에 따른 얇은 객체를 검출하기 위한 방법에서 적용된 분석 영역을 추출하는 과정을 도시한 도면이다. 도시된 그림에서 빨간색 점은 눈, 눈썹, 코, 입, 턱선 등에 대한 랜드마크이며, 이들을 이용하여 녹색 상자 부 분을 크롭하여 분석 영역으로 추출할 수 있다. 이를 위하여 랜드마크 각각의 좌표(x, y)를 이용하여 가장 왼쪽 점을 P1, 가장 오른쪽 점을 P2, 눈 사이의 중간 점을 P3로 정의한다. 그리고 이마에 대해서는 가상의 랜드마크를 생성하여 P4로 정의하며, P4의 y좌표는 아래표 1의 y1과 같으며 P1, P2, P3을 이용하여 계산된다. 최종적으로 녹색 상자를 나타내는 두 점인 (x1, y1) 과 (x2, y2)는 표 1과 같이 계산되며, 이를 이용하여 얼굴 전체 이미지에서 녹색 상자 부분을 크롭하여 분석 영역 으로 추출할 수 있다. 표 1"}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "그리고 심층 지도를 위한 GT를 작성하기 위하여 반자동 라벨링에 의해서 주름에 대한 GT를 작성하였다. 얼굴 주름은 모양과 길이가 매우 다양하고 그 경계가 모호하기 때문에 수동으로 라벨링하기가 어렵기 때문에, 본 실시예에서는 반자동 라벨링을 적용하였으나 이에 한정되는 것은 아니다. 도 3은 본 발명의 일 실시예에 따른 얇은 객체를 검출하기 위한 방법에서 반자동 라벨링에 의해서 GT를 생성하 기 위한 개념도이다. 도시된 것과 같이 원본 이미지(I)에서 러프 주름 표지(Rough Wrinkle Annotation) 맵을 생성한다. 러프 주름 표 지 맵은 정확하게 주름이 표지되어 있는 영상이 아니라, 원본 이미지(I)를 대상으로 사람이 직접 주름 위치를 대략적으로 표지한 영상이거나 기타 다양한 방법으로(또는 가능한 쉽고 빠른 방법으로) 통상의 기술자가 주름 위치를 표지한 영상일 수 있다. 러프 주름 표지 맵은 원본 이미지와 함께 미리 얼굴 주름을 검출하기 위한 장치 에 입력되어 사용될 수 있다. 러프 주름 표지 맵은 이진 마스크(M)로 변환되며, 러프 주름 표지 맵에서 주름이 표지된 위치에 해당하는 픽셀값과 주름이 표지되지 않은 위치에 해당하는 픽셀값을 각각 픽셀 최댓값(예를 들어, 255 또는 흰색)과 픽셀 최솟값(예를 들어, 0 또는 검은색)으로 설정하여 이진 마스크(M)를 생성할 수 있 다. 그리고 다음의 수식 1을 적용하여 원본 이미지(I)에서 텍스처 맵(T)을 추출한다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 G는 가우시안 커널, σ는 시그마 값, IG(σ)는 가우시안 필터링 이미지, x와 y는 좌표이다. 수식 1은 동일 한 영상 내 좌표(x, y)를 대상으로 수행되며, 수식 2에서 255는 8비트 영상을 기준으로 28을 적용한 결과이고 경우에 따라 영상 내 픽셀을 구성하는 비트를 2의 지수로 적용한 변수로 이해되어야 한다. 가우시안 필터에서 가우시안 커널의 크기는 21X21일 수 있으며, 가우시안 필터의 시그마(σ)값은 5로 설정될 수 있으나, 이는 예시적인 것이고 통상의 기술자에 따라 가우시안 커널의 크기와 시그마 값은 달리 설정될 수 있다. 가우시안 필터는 가우시안 커널의 크기와 시그마 값을 파라미터로 적용하는 것으로 통상의 기술자 누구나 수행 가능하므로 자세한 설명은 생략한다. 텍스처 맵(T)에서 비-주름 텍스처를 제거하여, 주름 텍스처 맵(T`)을 생성하기 위하여 다음의 수식 2를 사용한 다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수식 2에서 M(x, y)은 이진 마스크(M)의 좌표(x, y)에 대응하는 픽셀값이고, T(x, y)는 좌표(x, y)에 대응하는 텍스처 맵(T)의 픽셀값이며, T`(x, y)는 주름 텍스처 맵의 좌표(x, y)에 대응하는 픽셀값일 수 있다. 마지막으로 적응적 임계와 방법(adaptive thermohaline method)을 통해서 GT를 생성하며, 도 3에서 주름 텍스처 맵(T`)의 주름 표지가 GT에서 더욱 뚜렷하게 나타난 것을 확인할 수 있다. 구체적으로 주름 텍스처 맵(T`)을 구성하는 일부 영역마다 개별적으로 산출된 경곗값(threshold)을 이용하여 픽셀 최댓값(또는 흰색)으로 표지된 픽 셀을 픽셀 최솟값(또는 검은색)으로 바꾸거나, 픽셀 최솟값(또는 검은색)으로 표지된 픽셀을 픽셀 최댓값(또는 흰색)으로 바꾸거나, 또는 기존 픽셀값을 유지하면서 임계화를 수행하는 동작으로서, 통상의 기술자는 공지된 다양한 방식의 적응적 임계계화 방법을 적용할 수 있다. 예를 들어, D. Bradley and G. Roth, \"Adaptive thresholding using the integral image,\" Journal of graphics tools, vol. 12, no. 2, pp. 13-21, 2007 를 참조할 수 있다. 한편, 일반적인 심층 지도 방법으로 학습된 객체 분할 모델에 비하여 얇은 객체에 대한 정확도를 향상시키기 위 한 방법으로 본 실시예에서는 가중 주름 맵(weighted wrinkle map)을 생성하여 사용하였다. U-Net을 이용한 일반적인 심층 지도에서는 다운 샘플링으로 인하여 적어도 일부의 디코더에서 공간의 크기가 감 소하였고, 이로부터 생성된 특성맵은 이미지가 더 흐려지는 문제가 있다. 도 4는 도 1에 도시된 모델에서 특성맵 F1과 F4의 주름 표현을 비교하기 위한 도면이다. 도 1의 디코더 D1에서 추출된 특성맵 F1과 디코더 D4에서 추출된 F4를 비교하면, F4는 공간 차원이 1/8로 감소 하였고 이를 다시 8배로 업스케일링하는 과정에서 이미지가 흐려진다. 그 결과 F4에서는 주름의 형태가 정확하 게 표현되지 않았으며, F1에서는 F4에 비하여 주름의 형태가 명확하다. 따라서 F4에 대한 훈련 손실이 F1에 대 한 훈련 손실보다 지속적으로 높아지며, 최종적인 성능은 F1을 통해서 결정되기 때문에 주름 검출 성능이 저하 되는 문제가 생긴다. 본 실시예는 디코더 D2 내지 D4에서 추출된 특성맵 F2 내지 F4에 대하여 가중 주름 맵을 이용한 손실 함수를 적 용하고, 디코더 D1에서 추출된 특성맵 F1에 대해서만 GT를 이용한 손실 함수를 적용하여 상기한 문제를 해결하 였다. 본 실시예에서 적용된 가중 주름 맵의 생성 알고리즘(Algorithm 1)은 다음과 같다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 5, "content": "도 5는 본 발명의 일 실시예에 따른 얇은 객체를 검출하기 위한 방법에서 가중 주름 맵을 생성하는 과정을 도시 한 도면이다. 스케일 팩터 s는 공간 차원의 감소 비율인 1/s에서 도출되며, 공간 차원의 감소 비율을 반영하여 GT를 그리드 포맷으로 분할하고 각 그리드에서 평균값을 구함으로써 GT에서 다운 샘플링된 WWMdown 을 생성(단계 1)하고, 다시 최근접 보간법(nearest interpolation)으로 업스케일링(단계 2)하면, 도 5의 첫 번째 열과 같은 이미지가 생성 된다. 다음으로 업스케일링된 이미지에서 평균을 계산하여 업스케일링된 이미지에서 0값을 가지는 부분을 계산된 평균 값으로 교체(단계 3)하여, 이미지 전반에서 주름을 제대로 표현할 수 없는 부분의 가중치를 낮춘 도 5의 두 번 째 열과 같은 이미지를 생성한다. 이때, 주름을 제대로 표현할 수 없는 부분인 업스케일링된 이미지에서 0값을 가지는 부분을 값은 다른 수치로 변경될 수도 있다. 마지막으로 GT 값이 1인 곳과 같은 위치에 WWV의 값을 1로 설정(단계 3)하여, 주름이 불가피한 부분의 가중치를 높게 유지한 도 5의 세 번째 열과 같은 이미지를 생성한다. 최종적으로 주름을 제대로 표현할 수 없는 부분의 가중치는 낮추면서도 주름이 불가피한 부분의 가중치는 높게 유지되도록 조정된 가중치를 가지는 가중 주름 맵이 도출되며, 조정된 가중치를 이용하여 손실을 계산하면 주름 감지 성능이 향상된다. 본 실시예에서는 가중 주름 맵(weighted wrinkle map)을 이용하여 주름 분할 모델을 훈련시키기 위하여 다음 2 개의 손실 함수를 적용하였다. 예측값과 GT 사이의 다이스(dice) 계수를 이용하여 오차를 계산하는 다이스 손실(dice loss)을 적용하였으며, 마지막 디코드 레이어에 대한 다이스 손실은 다음의 수식 3과 같이 정의된다. ' 여기서 pn,i는 n번째 예측 출력(특성맵 Fn)의 i번째 값이고, q는 GT이다. 나머지 디코더 레이어에 대한 다이스 손실은 다음의 수식 4와 같이 정의된다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 wn,i는 n번째 WWM의 i번째 값이다. 도 1에 도시된 실시예에 따르면 마지막 디코더 레이어는 D1이고 나머지 디코더 레이어는 D2 내지 D4이므로, 최 종 손실은 다음의 수식 5와 같이 계산할 수 있다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "딥러닝 모델을 교육하는 과정에서 학습 속도 스케줄러를 사용할 수 있으며, 본 실시예에서는 다음의 수식 6으로 정의되는 CALRS(cosine annealing learning rate scheduler)를 사용하였다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서 γi min 와 γi max는 i번째 실행의 학습률 범위이고, Tcur는 마지막 재시작 이후에 진행된 에포크(epoch)의 수이며, t는 배치 반복이다. CALRS를 사용하여 주름 분할 모델의 가중치 업데이트에 따라서 학습률을 조정하였 다. 이하에서는 본 실시예에 따른 검출 방법의 효과를 기존 모델과 비교한 결과를 설명한다. 특수 피부 진단 장비인 Lumini KIOSK v2를 사용하여 얼굴 영상 300장을 획득하였다. 획득한 이미지는 1,280(H) ×960(W)이며, 모든 이미지에 정면 얼굴이 포함되어 있다. 획득한 모든 이미지는 앞서 설명한 랜드마크 포인트 검출 방법을 적용한 뒤에 640(H) × 640(W)로 자르고 크기를 조정하였다. 이후 반자동 라벨링 기법을 통해 주름 에 대한 GT(ground truths)를 얻었다. 텍스처 맵 T를 생성하기 위해 시그마 값을 5로 설정하고 가우시안 커널의 크기를 21 × 21로 설정하였다. 학습 단계에서 학습 이미지가 로드될 때 스케일링, 이동, 회전, 밝기, 색상 변경 및 뒤집기를 위한 데이터 증대 기술이 무작위로 사용되었다. 본 실시예에서 사용된 주름 분할 모델의 가중치를 업데이트하기 위한 옵티마이저 로서 Adam을 사용하였다. CALRS의 주기와 훈련 단계의 최대 에포크는 200으로 설정되었다. 초기 학습률은 0.01 로 설정되었고 최소 학습률은 0.000001로 설정되었다. 가중치 감쇠는 값이 0.0001인 L2-norm을 기반으로 정의되 었으며, 배치 크기(batch size)는 4이다. 모든 실험 결과는 Ubuntu 20.04에서 NVIDIA RTX 3090 GPU와 PyTorch 를 사용하여 도출되었다. 본 실시예의 방법을 평가하기 위하여 JSI(Jaccard Similarity Index), 정확도, 특이도 및 민감도를 평가하였다. JSI는 이전 주름 분할 방법에서 자주 사용되었으며 다음의 수식 7과 같이 정의된다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서 A는 예측이고 B는 실측값이다. 정확도(Accuracy), 민감도(Sensitivity) 및 특이도(specificity)는 다음의 수식 8 내지 10과 같이 정의된다."}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서 TP는 참 양성, TN은 참 음성, FP는 거짓 양성, FN은 거짓 음성을 나타낸다. 먼저, 일반 U-Net을 기준선으로 선택하고, 종래의 심층 지도와 본 실시예에 따른 가중 심층 지도를 별도로 적용 하여 주름 분할 성능을 비교하였다. 도 6은 본 발명의 실시예와 비교예에 따른 주름 검출 결과를 도시한 도면이다. (a)는 원본 이미지, (b)는 GT, (c)는 단순 U-Net을 적용한 결과, (d)는 U-Net에 기존의 심층 지도를 적용한 결 과, (e)는 본 실시예에 따른 가중 심층 지도를 적용한 결과이다. 여러 가지 메트릭스에 대한 평균 및 분산을 기반으로 한 통계적 결과를 표 2에 정리하였다. 표 2"}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "U-Net을 적용한 경우(U-Net)와 U-Net에 기존의 심층 지도를 적용한 경우(U-Net + DS) 및 본 실시예에 따른 가중 심층 지도를 적용한 경우((U-Net + WDS)를 비교한 결과, 본 실시예에 따른 가중 심층 지도를 적용한 경우가 네 가지 지표 모두에서 가장 좋은 성능을 보여주었다. JSI의 경우 기존의 심층 지도를 적용하였을 때에 0.68% 개선되었으나, 본 실시예에 따른 가중 심층 지도를 적용 한 경우에 2.05% 개선되었다. 주름에 대한 판별력이 높아져 정확도가 향상되고 민감도와 특이도가 향상되었기 때문이며, 이는 본 실시예에 따른 가중 심층 지도가 기존의 심층 지도보다 주름 분할 성능을 향상시키는 데 더 효과적임을 보여준다. 이러한 결과를 손실 관점에서 확인하기 위하여, 기존의 심층 지도를 적용한 경우와 본 실시예에 따른 가중 심층 지도를 적용한 경우의 교육 손실을 비교하였다. 도 7은 기존의 심층 지도를 적용한 경우와 본 실시예에 따른 가중 심층 지도를 적용한 경우의 교육 손실을 비교 한 결과이다. 가중 주름 맵을 사용하지 않은 기존의 심층 지도를 적용한 경우에는 수식 3에 따른 손실 함수가 특성맵 F1과 F2 에 모두 적용되었고, Loss_DICE4(DS)의 훈련 손실은 Loss_DICE1(DS)에 비해 상대적으로 높게 나타나기 때문에 Loss_DICE4(DS)의 손실이 전체 모델 훈련에 상당한 영향을 미친다. 그러나 F1이 최종 예측 결과이기 때문에, 이 러한 손실 차이는 검출의 정확도가 낮아지는 원인이 된다.본 실시예에 따른 가중 심층 지도를 적용한 경우, 특성맵 F1에 대해서는 수식 3에 따른 손실 함수가 적용되고, 특성맵 F4에 대해서는 수식 4에 따른 손실 함수가 적용되기 때문에, Loss_DICE4(WDS)의 훈련 손실이 Loss_DICE1(WDS)에 비해 상대적으로 낮게 나타나며, 최종적으로 Loss_DICE1(WDS)가 Loss_DICE1(DS) 보다 낮아 진 것을 확인할 수 있다. 이로부터 본 실시예에 따른 가중 심층 지도를 적용하는 경우에 기존의 심층 지도를 적 용한 경우에 비하여 훈련 성과가 향상되는 것을 알 수 있다. 다음으로 헤시안(Hessian) 방법이나 가버(Gabor) 필터와 같은 기존의 주름 검출 방법과 비교하였다. 다만, 헤시 안 방법과 가버 필터는 눈, 눈썹, 머리카락과 같은 다른 특징도 주름으로 검출되어 성능이 매우 낮아지기 때문 에, 안면 이미지에서 이마와 눈가만을 수동으로 크롭하고 피부가 아닌 부분을 검은색으로 채워서 성능을 측정하 였다. 도 8은 본 발명의 실시예와 비교예에 따른 이마의 주름 검출 결과를 도시한 도면이고, 도 9는 본 발명의 실시예 와 비교예에 따른 눈가의 주름 검출 결과를 도시한 도면이다. (a)는 원본 이미지, (b)는 GT, (c)는 헤시안 방식의 결과, (d)는 가버 필터 방식의 결과, (e)는 단순 U-Net을 적용한 결과, (f)는 U-Net에 기존의 심층 지도를 적용한 결과, (g)는 본 실시예에 따른 가중 심층 지도를 적용 한 결과이다. 표 3은 이마와 눈가에 대한 각 방법에 대한 JSI 성능을 비교한 결과를 나타낸다. 표 3"}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "헤시안 방법과 가버 필터에 의한 결과는 단순히 U-Net을 사용하는 경우보다 낮은 검출 결과를 나타내었으며, 본 실시예에 따른 가중 심층 지도를 적용한 경우가 가장 좋은 성능을 보여주었다. 본 발명의 다른 실시예로서 망막 촬영 이미지에서 혈관을 검출하였다. 망막 혈관 분야에서 사용되는 AG-Net에 심층 지도를 적용한 경우를 기준으로 하여, AG-Net에 가중 혈관 맵을 적 용한 가중 심층 지도를 적용하여 결과를 비교하였다. 그리고 추가적인 비교를 위하여 ASPP(Atrous Spatial Pyramid Pooling)를 최종 인코더에 추가하였다. 성능 비교를 위하여 혈관 분할에 널리 사용되는 20개의 훈련 이미지와 20개의 테스트 이미지로 구성된 DRIVE 데 이터 세트를 선택하였다. 각 이미지의 해상도는 가로축을 584(H)×565(W)로 제로 패딩하여 584(H)×584(W)로 조 정했다. 그리고 본 실시예에 따른 가중 심층 지도에 의한 훈련은 앞서 살펴본 주름 분할의 경우와 동일하게 구 성하였다. 표 4"}
{"patent_id": "10-2023-0089368", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "S. Zhang 등에 의해서 수행된 기존 결과(AG-Net*)와 AG-Net으로 새롭게 수행된 혈관 검출 결과(AG-Net)는 유사 하게 나타났으나, 본 실시예에 따른 가중 심층 지도를 적용한 결과(AG-Net+WDS)는 기존의 심층 지도를 적용한 경우에 비하여 향상된 결과를 나타내었다. 이로부터 디코더의 공간 차원 감소 비율인 1/s의 s를 스케일 팩터로 적용하여, 혈관이 불가피한 부분의 가중치를 높게 유지하면서 혈관을 제대로 표현할 수 없는 부분의 가중치를낮춘 가중치 맵을 함께 적용하여 심층 지도를 수행한 본 발명에 따른 가중 심층 지도를 적용하는 경우에 주름 뿐만 아니라 망막 혈관과 같은 얇은 객체의 검출 성능이 모두 향상되는 것을 알 수 있다. 그리고 본 발명에 따른 가중 심층 지도에 ASPP까지 추가하는 경우(AG-Net+WDS+ASPP)는 더욱 성능이 향상되는 것 을 확인할 수 있다. 이상 본 발명을 바람직한 실시예를 통하여 설명하였는데, 상술한 실시예는 본 발명의 기술적 사상을 예시적으로 설명한 것에 불과하며, 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 다양한 변화가 가능함은 이 분야에 서 통상의 지식을 가진 자라면 이해할 수 있을 것이다. 따라서 본 발명의 보호범위는 특정 실시예가 아니라 특 허청구범위에 기재된 사항에 의해 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술적 사상도 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0089368", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 얇은 객체를 검출하기 위한 방법에서 적용되는 객체 분할 모델의 구조를 도 시한 개념도이다. 도 2는 본 발명의 일 실시예에 따른 얇은 객체를 검출하기 위한 방법에서 적용된 분석 영역을 추출하는 과정을 도시한 도면이다. 도 3은 본 발명의 일 실시예에 따른 얇은 객체를 검출하기 위한 방법에서 반자동 라벨링에 의해서 GT를 생성하 기 위한 개념도이다. 도 4는 도 1에 도시된 모델에서 특성맵 F1과 F4의 주름 표현을 비교하기 위한 도면이다. 도 5는 본 발명의 일 실시예에 따른 얇은 객체를 검출하기 위한 방법에서 가중 주름 맵을 생성하는 과정을 도시 한 도면이다. 도 6은 본 발명의 실시예와 비교예에 따른 주름 검출 결과를 도시한 도면이다. 도 7은 기존의 심층 지도를 적용한 경우와 본 실시예에 따른 가중 심층 지도를 적용한 경우의 교육 손실을 비교 한 결과이다. 도 8은 본 발명의 실시예와 비교예에 따른 이마의 주름 검출 결과를 도시한 도면이다. 도 9는 본 발명의 실시예와 비교예에 따른 눈가의 주름 검출 결과를 도시한 도면이다."}
