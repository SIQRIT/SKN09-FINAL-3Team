{"patent_id": "10-2024-0074371", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0093407", "출원번호": "10-2024-0074371", "발명의 명칭": "인공신경망의 비트 양자화 방법 및 합성곱 처리장치", "출원인": "주식회사 딥엑스", "발명자": "김녹원"}}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공신경망을 구성하는 복수의 레이어 중 어느 하나의 레이어를 순착적으로 선택하여 비트 양자화를 수행하되,상기 인공신경망의 정확도 및 목표값을 비교하여 상기 선택된 레이어에 대해 실행된 상기 비트 양자화에 의해상기 인공신경망의 정확도가 저하되었는지 여부를 판단하고, 판단 결과에 따라 최종 비트 수를 결정하여 양자화된 인공신경망을 저장하도록 구성된 메모리; 및상기 양자화된 인공신경망을 처리하도록 구성된 복수의 곱셈기 또는 복수의 가산기를 포함하는 프로세싱 유닛을포함하고,상기 어느 하나의 레이어는 배열 순서, 연산량 및 각각에 대한 정확도 변동 지점의 탐색 여부 중 어느 하나를기반으로 상기 복수의 레이어 중에서 선택되고,상기 메모리는,상기 인공신경망의 정확도가 상기 목표값 이상인 경우에는 상기 선택된 레이어의 파라미터를 저장하기 위한 데이터 표현의 크기를 1비트 단위로 감소시킨 후 추가의 비트 양자화를 실행하고, 상기 인공신경망의 정확도가 상기 목표값 미만인 경우에는 상기 비트 양자화의 결과를 무시하고, 이전의 비트 양자화에서 상기 목표값을 만족시켰던 최소의 비트 수를 상기 선택된 레이어의 파라미터에 대한 최종 비트 수로 결정하도록 구성되고,상기 목표값은,상기 인공신경망의 비트 양자화 후에 유지해야 할 최소한의 정확도를 나타내는, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 양자화된 인공신경망은 연산량 또는 메모리양을 기준으로 상기 복수의 레이어 각각에 대한 특징맵 데이터및 활성화맵 데이터 중 적어도 하나가 순차적으로 양자화된, 인공신경망의 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 프로세싱 유닛은 연산량 비트 양자화 방식, 순방향 비트 양자화 방식, 및 역방향 비트 양자화 방식 중 적어도 하나의 방식으로 양자화된 인공신경망을 처리하도록 구성된, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 양자화된 인공신경망의 연산량 및 메모리량은 양자화 전보다 상대적으로 저감되고, 상기 메모리에 저장되는 상기 복수의 레이어 각각에 대한 특징맵 데이터 및 활성화맵 데이터 중 적어도 하나의 데이터의 비트 수도저감된, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 메모리는 버퍼 메모리, 레지스터 메모리 및 캐쉬 메모리 중 적어도 하나를 포함하는, 인공신경망하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,공개특허 10-2024-0093407-3-상기 복수의 레이어 중 특정 레이어의 데이터가 전송되는 데이터 경로의 데이터 비트의 크기는 비트 단위로 감소된, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 양자화된 인공신경망은 상기 복수의 레이어 각각에 대한 특징맵 데이터 및 활성화맵 데이터 중 적어도 하나가 저장하도록 구성된 상기 메모리의 저장 크기 감소를 위해서 비트 양자화된 것을 특징으로 하는, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 메모리는 특징맵 캐쉬를 더 포함하는, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 프로세싱 유닛은 상기 복수의 곱셈기에 의한 다중 곱의 결과 값들을 합산하도록 구성된 트리 가산기를 더포함하는, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 프로세싱 유닛과 연결된 가산기 및 상기 가산기와 연결된 누산기를 더 포함하는, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서,상기 프로세싱 유닛의 합성곱 결과 값을 저장하도록 구성된 출력 활성화 맵 캐쉬를 더 포함하는, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1 항에 있어서,상기 프로세싱 유닛은 복수의 합성곱 처리 유닛을 더 포함하는, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 프로세싱 유닛은 상기 복수의 합성곱 처리 유닛 각각의 합성곱 결과 값을 합산하도록 구성된 트리 가산기를 더 포함하는, 인공신경망 하드웨어."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "인공신경망을 구성하는 복수의 레이어 중 어느 하나의 레이어를 순차적으로 선택하여 비트 양자화를 수행하되,상기 인공신경망의 정확도 및 목표값을 비교하여 상기 선택된 레이어에 대해 실행된 상기 비트 양자화에 의해상기 인공신경망의 정확도가 저하되었는지 여부를 판단하고, 판단 결과에 따라 최종 비트 수를 결정하여 양자화된 인공신경망을 저장하고, 상기 양자화된 특징맵을 저장하도록 구성된 메모리; 및가중치 커널과 상기 양자화된 특징맵을 입력 받아 합성곱을 처리하도록 구성된 프로세싱 유닛을 포함하고,상기 어느 하나의 레이어는 배열 순서, 연산량 및 각각에 대한 정확도 변동 지점의 탐색 여부 중 어느 하나를기반으로 상기 복수의 레이어 중에서 선택되고,상기 메모리는,공개특허 10-2024-0093407-4-상기 인공신경망의 정확도가 상기 목표값 이상인 경우에는 상기 선택된 레이어의 파라미터를 저장하기 위한 데이터 표현의 크기를 1비트 단위로 감소시킨 후 추가의 비트 양자화를 실행하고, 상기 인공신경망의 정확도가 상기 목표값 미만인 경우에는 상기 비트 양자화의 결과를 무시하고, 이전의 비트 양자화에서 상기 목표값을 만족시켰던 최소의 비트 수를 상기 선택된 레이어의 파라미터에 대한 최종 비트 수로 결정하도록 구성되고,상기 목표값은,상기 인공신경망의 비트 양자화 후에 유지해야 할 최소한의 정확도를 나타내는, 합성곱 처리장치."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서, 상기 프로세싱 유닛은 곱셈기 및 가산기를 더 포함하고,상기 곱셈기 및 상기 가산기의 비트 크기는 상기 양자화된 특징맵의 비트 수에 맞추어 설계된, 합성곱 처리 장치."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항에 있어서,상기 양자화된 특징맵은 연산량 또는 메모리양을 기준으로 상기 복수의 레이어 각각에 대하여 특징맵이 순차적으로 양자화된, 합성곱 처리 장치."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 14 항에 있어서,상기 복수의 레이어 각각에 대하여, 상기 양자화된 특징맵의 비트 수는 상기 복수의 레이어 각각의 정확도 변동지점 직전의 비트 수로 설정된, 합성곱 처리 장치."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 14 항에 있어서,상기 복수의 레이어 각각에 대하여, 상기 양자화된 특징맵은은 상기 복수의 레이어 각각에 대한 정확도 변동 지점을 탐색하여 비트 양자화된, 합성곱 처리 장치."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 14 항에 있어서,상기 가중치 커널의 비트 수에 맞추어 상기 특징맵에 대해 비트 양자화가 실행되는, 합성곱 처리 장치."}
{"patent_id": "10-2024-0074371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "인공신경망을 구성하는 복수의 레이어 중 어느 하나의 레이어를 순차적으로 선택하여 비트 양자화를 수행하되,상기 인공신경망의 정확도 및 목표값을 비교하여 상기 선택된 레이어에 대해 실행된 상기 비트 양자화에 의해상기 인공신경망의 정확도가 저하되었는지 여부를 판단하고, 판단 결과에 따라 최종 비트 수를 결정하여 양자화된 인공신경망을 저장하는 메모리;가중치 커널과 상기 양자화된 특징맵을 입력 받아 합성곱을 처리하도록 구성된 프로세싱 유닛;상기 인공신경망의 가중치 커널 데이터를 저장하도록 구성된 가중치 커널 캐쉬;상기 양자화된 인공신경망의 특징맵 데이터를 저장하도록 구성된 입력 특징맵 캐쉬; 및상기 양자화된 인공신경망의 출력 활성화맵 데이터를 저장하도록 구성된 출력 활성화맵 캐쉬를 포함하고,상기 어느 하나의 레이어는 배열 순서, 연산량 및 각각에 대한 정확도 변동 지점의 탐색 여부 중 어느 하나를기반으로 상기 복수의 레이어 중에서 선택되고,상기 메모리는,공개특허 10-2024-0093407-5-상기 인공신경망의 정확도가 상기 목표값 이상인 경우에는 상기 선택된 레이어의 파라미터를 저장하기 위한 데이터 표현의 크기를 1비트 단위로 감소시킨 후 추가의 비트 양자화를 실행하고, 상기 인공신경망의 정확도가 상기 목표값 미만인 경우에는 상기 비트 양자화의 결과를 무시하고, 이전의 비트 양자화에서 상기 목표값을 만족시켰던 최소의 비트 수를 상기 선택된 레이어의 파라미터에 대한 최종 비트 수로 결정하도록 구성되고,상기 목표값은,상기 인공신경망의 비트 양자화 후에 유지해야 할 최소한의 정확도를 나타내는, 장치."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는, 인공신경망의 비트 양자화 방법을 제공한다. 이 방법은, (a) 인공신경망에서 양자화할 하나의 파라 미터 또는 하나의 파라미터 그룹을 선택하는 단계; (b) 상기 선택된 파라미터 또는 파라미터 그룹에 대한 데이터 표현 크기를 비트 단위로 감소시키는 비트 양자화 단계; (c) 상기 인공신경망의 정확도가 사전 결정된 목표값을 이상인지 여부를 결정하는 단계; (d) 상기 인공신경망의 정확도가 상기 목표값 이상인 경우, 상기 (a) 단계 내지 상기 (c) 단계를 반복 실행하는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공신경망의 하드웨어, 및 합성곱 처리장치에 관한 것으로, 보다 상세하게는, 인공신경망의 실질적 인 정확성을 유지하면서 성능과 메모리 사용량을 감소시킬 수 있는 인공신경망의 하드웨어, 및 합성곱 처리장치 에 관한 것이다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공신경망(artificial neural network)은 생물학적 뇌를 모델링한 컴퓨터 구조이다. 인공신경망에서는 뇌의 뉴런들에 해당되는 노드들이 상호 연결되어 있고, 뉴런들 사이의 시냅스 결합의 세기를 가중치(weight)로 표현 한다. 인공신경망은 인공 뉴런들(노드들)이 학습을 통해 노드들 사이의 시냅스 결합의 세기를 변화시켜, 주어 진 문제 해결 능력을 갖는 모델을 구성한다. 인공신경망은, 좁은 의미에서 전방 전달 신경망(feedforward neural network)의 일종인 다층 퍼셉트론(multi- layered perceptron)을 지칭할 수 있으나, 이에 한정되는 것은 아니며, 방사 신경망(radial basis function network), 자기조직 신경망(self-organizing network), 순환 신경망(recurrent neural network) 등 다양한 종 류의 신경망을 포함할 수 있다. 최근에는 영상 인식을 위한 기술로 다층 구조의 심층 신경망(deep neural network)이 많이 사용되고 있고, 다 층 구조의 심층 신경망의 대표적인 예가 컨볼루션 신경망(convolutional neural network: CNN)이다. 일반적인 다층 구조의 전방 전달 신경망의 경우는, 입력 데이터가 1차원의 형태로 한정되는데, 2차원 내지 3차원으로 구 성되는 영상 데이터를 1차원 데이터로 평면화하면 공간 정보가 손실되어, 영상의 공간 정보를 유지한 상태로 신 경망의 학습이 어려울 수 있다. 그러나, 컨볼루션 신경망은 2차원 또는 3차원의 공간 정보를 유지한 상태로 시 각 정보에 대한 학습이 가능하다. 구체적으로, 컨볼루션 신경망은, 이미지의 공간 정보를 유지하면서 인접 이미지와의 특징을 효과적으로 인식하 고, 추출한 이미지의 특징을 모으고 강화하는 맥스 풀링(Max Pooling) 과정을 포함하고 있어, 시각적 데이터의 패턴 인식에 효과적이다. 하지만 이러한 컨볼루션 신경망과 같은 다층 구조의 심층 신경망은, 높은 인식 성능 을 제공하기 위해 깊은 레이어 구조가 사용되지만, 그 구조가 매우 복잡하고 큰 연산량과 많은 양의 메모리를 요구한다. 다층 구조의 심층 신경망에서, 내부적으로 발생하는 대부분의 연산은 곱셈과 덧셈(또는 누산)을 사 용하여 실행되는데, 인공신경망 내의 노드 간의 연결 수가 많고 곱셈을 요구하는 파라미터(예를 들어, 가중치 데이터, 특징맵 데이터, 활성화맵 데이터 등)의 수가 많기 때문에 학습과정이나 인식과정에서 큰 연산량이 필요 하다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이상 살펴본 바와 같이, 컨볼루션 신경망과 같은 다층 구조의 심층 신경망의 학습과 인식과정에서 많은 연산량 과 메모리량을 필요로 한다. 다층 구조의 심층 신경망의 연산량과 메모리량을 줄이는 방법으로는, 인공신경망 의 연산에 사용되는 파라미터의 데이터 표현 크기를 비트 단위로 감소시키는 비트 양자화 방법이 사용될 수 있 다. 기존의 비트 양자화 방법은, 인공신경망의 모든 파라미터를 동일한 비트 수로 양자화 하는 균일 비트 양자 화(Uniform bit quantization)가 사용되지만, 기존의 균일 비트 양자화 방법은 인공 신경망에서 사용되는 각각 의 파라미터에 대한 비트 수의 변경이 전체 성능에 미치는 영향을 정확히 반영하지 못하는 문제가 있다. 본 명세서에서 개시되는 실시예들은, 인공신경망에 있어서 전체 성능을 개선하면서 인공지능 정확도를 유지할 수 있도록, 인공신경망을 구성하는 각각의 파라미터 데이터 또는 특정 기준에 따라 그룹 지어진 파라미터 데이 터를 특정의 비트 수로 양자화하는 방법 및 시스템을 제공하고자 한다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 인공신경망의 비트 양자화 방법이 제공된다. 이 방법은, (a) 인공신경망에서 사용되는 복수의 파라미터 중의 적어도 하나의 파라미터를 선택하는 단계; (b) 상기 선택된 파라미터 에 대한 연산에 요구되는 데이터의 크기를 비트 단위로 감소시키는 비트 양자화 단계; (c) 인공신경망의 정확도가 사전 결정된 목표값 이상인지 여부를 결정하는 단계; (d) 상기 인공신경망의 정확도가 상기 목표값 이상인 경우, 상 기 파라미터에 대해 (b) 단계 내지 상기 (c) 단계를 반복 실행하여 상기 파라미터의 데이터 표현에서 비트 수를 더 감소시키는 단계를 포함할 수 있다. 또한, 이 방법은, (e) 상기 인공신경망의 정확도가 상기 목표값 미만인 경우, 상기 파라미터의 비트 수를 상기 인공신경망의 정확도가 상기 목표값을 이상이었을 때의 비트 수로 복원 한 후, (a) 단계 내지 (d) 단계를 반복하는 단계를 더 포함한다. 본 개시의 일 실시예에 따르면, 인공신경망의 비트 양자화 방법이 제공된다. 이 방법은, (a) 파라미터 선택 모 듈에 의해, 상기 복수의 레이어 중의 적어도 하나의 레이어를 선택하는 단계; (b) 비트 양자화 모듈에 의해, 상 기 선택된 레이어의 파라미터에 대한 데이터 표현의 크기를 비트 단위로 감소시키는 비트 양자화 단계; (c) 정 확도 판단 모듈에 의해, 상기 인공신경망의 정확도가 사전 결정된 목표값 이상인지 여부를 결정하는 단계; 및 (d)상기 인공신경망의 정확도가 상기 목표값 이상인 경우, 상기 (a) 단계 내지 상기 (c) 단계를 반복 실행하는 단계를 포함한다. 본 개시의 일 실시예에 따르면, 인공신경망의 비트 양자화 방법이 제공된다. 이 방법은, (a) 파라미터 선택 모 듈에 의해, 상기 인공신경망에서 가중치, 특징맵, 활성화맵 데이터 중에서 하나 이상의 데이터 또는 하나 이상 의 그룹의 데이터를 선택하는 단계; (b) 비트 양자화 모듈에 의해, 상기 선택된 데이터에 대한 데이터 표현 크 기를 비트 단위로 감소시키는 비트 양자화 단계; (c) 상기 인공신경망의 인공지능 정확도가 목표값 이상인지 여 부를 측정하는 단계; 및 (d) 상기 인공신경망의 데이터 중에서 더 이상 양자화할 데이터가 존재하지 않을 때까 지, 상기 (a) 단계 내지 상기 (c) 단계를 반복 실행하는 단계를 포함한다. 본 개시의 일 실시예에 따르면, 인공신경망의 비트 양자화 방법이 제공된다. 이 방법은, 상기 인공신경망의 하 나 이상의 파라미터에 따라 상기 인공신경망을 학습시키는 단계; 상기 실시예들에 따르는 인공신경망의 비트 양 자화 방법에 따라 상기 인공신경망의 하나 이상의 파라미터에 대한 비트 양자화를 실행하는 단계; 및 상기 비트 양자화가 실행된 상기 인공신경망의 하나 이상의 파라미터에 따라 상기 인공신경망을 학습시키는 단계를 포함한 다. 본 개시의 다른 실시예에 따르면, 인공신경망의 비트 양자화 시스템이 제공된다. 이 시스템은, 상기 인공신경 망 내에서 적어도 하나의 파라미터를 선택하는 파라미터 선택 모듈; 상기 선택된 파라미터의 데이터 표현의 크 기를 비트 단위로 감소시키는 비트 양자화 단계; 인공신경망의 정확도가 사전 결정된 목표값 이상인지 여부를 결정하는 정확도 판단 모듈을 포함할 수 있다. 상기 정확도 판단 모듈은, 상기 인공신경망의 정확도가 상기 목 표값 이상인 경우, 상기 파라미터 선택 모듈과 상기 비트 양자화 모듈을 제어하여, 상기 인공신경망의 정확도를 목표값 이상으로 유지하면서, 상기 복수의 파라미터 각각이 최소 비트 수를 가지도록 양자화를 실행할 수 있다. 본 개시의 일 실시예에 따르면, 인공신경망의 비트 양자화 시스템이 제공된다. 이 시스템은, 상기 인공신경망을 구성하는 복수의 레이어 중의 적어도 하나의 레이어를 선택하는 파라미터 선택 모듈; 상기 선택된 레이어의 파 라미터에 대한 데이터 표현의 크기를 비트 단위로 감소시키는 비트 양자화 모듈; 및 상기 인공신경망의 정확도 가 사전 결정된 목표값 이상인지 여부를 결정하는 정확도 판단 모듈을 포함하며, 상기 정확도 판단 모듈은, 상 기 인공신경망의 정확도가 상기 목표값 이상인 경우, 상기 파라미터 선택 모듈과 상기 비트 양자화 모듈을 제어 하여, 상기 복수의 레이어 중의 다른 하나의 레이어에 대한 비트 양자화가 실행되도록 하며, 상기 비트 양자화 모듈은, 상기 복수의 레이어의 모든 가중치에 대해서 n비트(단, n은 n>0인 정수)를 설정하고, 상기 복수의 레이 어의 출력 데이터에 대해서 m비트(단, m은 m>0인 정수)를 설정한다. 본 개시의 일 실시예에 따르면, 인공신경망의 비트 양자화 시스템이 제공된다. 이 시스템은, 상기 인공신경망을 구성하는 복수의 레이어 중의 적어도 하나의 레이어를 선택하는 파라미터 선택 모듈; 상기 선택된 레이어의 파 라미터에 대한 데이터 표현의 크기를 비트 단위로 감소시키는 비트 양자화 모듈; 및 상기 인공신경망의 정확도 가 사전 결정된 목표값 이상인지 여부를 결정하는 정확도 판단 모듈을 포함하며, 상기 정확도 판단 모듈은, 상기 인공신경망의 정확도가 상기 목표값 이상인 경우, 상기 파라미터 선택 모듈과 상기 비트 양자화 모듈을 제어 하여, 상기 복수의 레이어 중의 다른 하나의 레이어에 대한 비트 양자화가 실행되도록 하며, 상기 비트 양자화 모듈은, 상기 복수의 레이어의 가중치와 출력 데이터에 대해서 n비트(단, n은 n>0인 정수)를 할당하되, 상기 복 수의 레이어 각각에 할당되는 비트의 수를 상이하게 설정한다. 본 개시의 일 실시예에 따르면, 인공신경망의 비트 양자화 시스템이 제공된다. 이 시스템은, 상기 인공신경망을 구성하는 복수의 레이어 중의 적어도 하나의 레이어를 선택하는 파라미터 선택 모듈; 상기 선택된 레이어의 파 라미터에 대한 데이터 표현의 크기를 비트 단위로 감소시키는 비트 양자화 모듈; 및 상기 인공신경망의 정확도 가 사전 결정된 목표값 이상인지 여부를 결정하는 정확도 판단 모듈을 포함하며, 상기 정확도 판단 모듈은, 상 기 인공신경망의 정확도가 상기 목표값 이상인 경우, 상기 파라미터 선택 모듈과 상기 비트 양자화 모듈을 제어 하여, 상기 복수의 레이어 중의 다른 하나의 레이어에 대한 비트 양자화가 실행되도록 하며, 상기 비트 양자화 모듈은, 상기 복수의 레이어의 가중치와 출력 데이터의 비트의 수를 개별적으로 상이하게 할당한다. 본 개시의 일 실시예에 따르면, 인공신경망의 비트 양자화 시스템을 제공한다. 이 시스템은, 상기 인공신경망을 구성하는 복수의 레이어 중의 적어도 하나의 레이어를 선택하는 파라미터 선택 모듈; 상기 선택된 레이어의 파 라미터를 저장하기 위한 메모리의 크기를 비트 단위로 감소시키는 비트 양자화 모듈; 및 상기 인공신경망의 정 확도가 사전 결정된 목표값 이상인지 여부를 결정하는 정확도 판단 모듈을 포함하며, 상기 정확도 판단 모듈은, 상기 인공신경망의 정확도가 상기 목표값 이상인 경우, 상기 파라미터 선택 모듈과 상기 비트 양자화 모듈을 제 어하여, 상기 복수의 레이어 중의 다른 하나의 레이어에 대한 비트 양자화가 실행되도록 하며, 상기 비트 양자 화 모듈은, 상기 복수의 레이어에서 사용되는 가중치 별로 상이한 수의 비트를 할당한다. 본 개시의 일 실시예에 따르면, 인공신경망의 비트 양자화 시스템이 제공된다. 이 시스템은, 상기 인공신경망을 구성하는 복수의 레이어 중의 적어도 하나의 레이어를 선택하는 파라미터 선택 모듈; 상기 선택된 레이어의 파 라미터에 대한 데이터 표현의 크기를 비트 단위로 감소시키는 비트 양자화 모듈; 및 상기 인공신경망의 정확도 가 사전 결정된 목표값 이상인지 여부를 결정하는 정확도 판단 모듈을 포함하며, 상기 정확도 판단 모듈은, 상 기 인공신경망의 정확도가 상기 목표값 이상인 경우, 상기 파라미터 선택 모듈과 상기 비트 양자화 모듈을 제어 하여, 상기 복수의 레이어 중의 다른 하나의 레이어에 대한 비트 양자화가 실행되도록 하며, 상기 비트 양자화 모듈은, 상기 복수의 레이어에서 출력되는 출력 데이터의 특정 단위로 개별적으로 상이한 수의 비트를 할당한다. 본 개시의 일 실시예에 따르면, 인공신경망의 비트 양자화 시스템이 제공된다. 이 시스템은, 상기 인공신경망을 구성하는 복수의 레이어 중의 적어도 하나의 레이어를 선택하는 파라미터 선택 모듈; 상기 선택된 레이어의 파 라미터에 대한 데이터 표현의 크기를 비트 단위로 감소시키는 비트 양자화 모듈; 및 상기 인공신경망의 정확도 가 사전 결정된 목표값 이상인지 여부를 결정하는 정확도 판단 모듈을 포함하며, 상기 정확도 판단 모듈은, 상 기 인공신경망의 정확도가 상기 목표값 이상인 경우, 상기 파라미터 선택 모듈과 상기 비트 양자화 모듈을 제어 하여, 상기 복수의 레이어 중의 다른 하나의 레이어에 대한 비트 양자화가 실행되도록 하며, 상기 비트 양자화 모듈은, 상기 복수의 레이어에서 출력되는 출력 데이터의 개별적 값에 각각 다른 비트를 할당한다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시예들에 따르면, 인공신경망에 있어서 학습 또는 추론 등의 연산에 필요한 데이터들의 비 트 수를 양자화 함으로써, 전체 연산 성능을 개선할 수 있다. 또한, 인공신경망을 구현하는데 필요한 하드웨어 리소스는 절감하고, 전력 소모와 메모리 필요 사용량을 감소시키면서, 인공지능 정확도의 열화가 없는 인공신경 망을 구현하는 것이 가능하다. 본 개시의 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 다른 효과들은 청국범위의 기재로부 터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 실시를 위한 구체적인 내용을 첨부된 도면을 참조하여 상세히 설명한다. 다만, 이하의 설명에 서는 본 개시의 요지를 불필요하게 흐릴 우려가 있는 경우, 널리 알려진 기능이나 구성에 관한 구체적 설명은 생략하기로 한다. 첨부된 도면에서, 동일하거나 대응하는 구성요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예 들의 설명에 있어서, 동일하거나 대응하는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나 구성요 소에 관한 기술이 생략되어도, 그러한 구성요소가 어떤 실시예에 포함되지 않는 것으로 의도되지는 않는다. 본 개시에서, \"파라미터\"는, 인공신경망 또는 인공신경망을 구성하는 각 레이어의 가중치 데이터, 특징맵 데이 터, 활성화맵 데이터 중 어느 하나 이상을 의미할 수 있다. 또한, \"파라미터\"는, 이와 같은 데이터로 표현되는 인공신경망 또는 인공신경망을 구성하는 각 레이어를 의미할 수도 있다. 또한, 본 개시에서, \"비트 양자화\"는, 파라미터 또는 파라미터들의 그룹을 나타내는 데이터 표현의 비트 수를 감소시키는 연산 또는 동작을 의미할 수있다. 본 개시는 디지털 하드웨어 시스템의 연산량과 메모리 사용량 및 전력소모를 감소시키기 위해, 관련 연산에 사 용 되는 파라미터의 데이터 표현 크기를 비트 단위로 감소시키는 양자화 방법과 시스템의 다양한 실시예들을 제 공한다. 일부 실시예에서, 본 개시의 비트 양자화 방법과 시스템은, 인공신경망의 연산에 사용되는 파라미터의 크기를 비트 단위로 감소시킬 수 있다. 일반적으로 인공신경망의 연산에는 32비트, 16비트, 또는 8 비트 단위 의 데이터구조(예를 들어, CPU, GPU, 메모리, 캐쉬, 버퍼 등)를 사용한다. 따라서, 본 개시의 양자화 방법과 시스템은 인공신경망의 연산에 사용되는 파라미터의 크기를 32, 16, 8 비트 이외의 다른 비트로 감소시킬 수 있 다. 더욱이 인공신경망의 각각의 파라미터 또는 각각의 파라미터의 그룹에게 특정 비트 수를 개별적으로 상이하 게 할당할 수 있다. 일부 실시예에서, 본 개시의 비트 양자화 방법과 시스템은, 인공 신경망 모델에 대하여, 모든 가중치를 위해 n 비트(n은 n > 0인 정수)를 설정하고, 각 레이어의 출력 데이터를 m 비트(m은 m > 0인 정수)를 설정할 수 있다. 다른 실시예에서, 본 개시의 비트 양자화 방법과 시스템은, 인공 신경망 모델의 각 레이어의 가중치와 출력 데 이터에 n비트를 할당할 수 있으며, 여기서 n은 각 레이어 마다 다른 수로 설정될 수 있다. 또 다른 실시예에서, 본 개시의 비트 양자화 방법과 시스템은, 인공 신경망 모델의 각 레이어의 가중치와 출력 데이터에 서로 다른 비트를 할당하며, 또한 각 레이어 마다 가중치와 해당 레이어에서 출력 특징맵 파라미터에 대해 다른 수의 비트를 할당할 수 있다. 본 개시의 비트 양자화 방법과 시스템은, 다양한 종류의 인공 신경망에 적용될 수 있다. 예를 들어, 본 개시의 비트 양자화 방법과 시스템이 컨볼루션 인공 신경망(CNN: convolution neural network)에 적용되는 경우, 이 인 공신경망의 각 레이어 내에서 사용하는 가중치 커널들에 개별적으로 다른 비트를 할당할 수 있다. 또 다른 실시예에서, 본 개시의 비트 양자화 방법과 시스템은, 다층 구조의 인공 신경망 모델의 각 레이어 내에 서 사용되는 각 가중치 별로 다른 비트를 할당하거나, 각 레이어의 출력 데이터의 특정 단위로 개별적인 비트를 할당하거나, 각 레이어의 출력 데이터의 개별적 값에 다른 비트를 할당할 수 있다. 이상 설명한 본 개시의 다양한 실시예들에 따른 비트 양자화 방법과 시스템은, 이상 설명한 실시예들 중의 어느 하나를 인공 신경망 모델에 적용할 수 있으나, 이에 한정되는 것은 아니며, 이 실시예들 중 하나 이상을 결합하 여 인공 신경망 모델에 적용할 수도 있다. 도 1은 본 개시의 일 실시예에 따른 복수의 레이어와 복수의 레이어 가중치를 이용하여 입력 데이터에 대한 출 력 데이터를 획득하는 인공신경망의 예를 보여주는 도면이다. 일반적으로, 인공신경망과 같은 다층 구조의 인공 신경망은, 머신러닝(Machine Learning) 기술과 인지과학 에서, 생물학적 신경망의 구조에 기초하여 구현된 통계학적 학습 알고리즘 또는 그 알고리즘을 실행하는 구조를 포함한다. 즉, 인공신경망은, 생물학적 신경망에서 와 같이 시냅스의 결합으로 네트워크를 형성한 인공 뉴런인 노드(node)들이 시냅스의 가중치를 반복적으로 조정하여, 특정 입력에 대응한 올바른 출력과 추론된 출 력 사이의 오차가 감소되도록 학습함으로써, 문제 해결 능력을 가지는 머신러닝 모델을 생성할 수 있다. 일 예에서, 인공신경망은 하나 이상의 노드들이 포함된 레이어들과 이들 사이의 연결로 구성된 다층 퍼셉 트론(MLP: multilayer perceptron)으로 구현될 수 있다. 그러나, 본 실시예에 따른 인공신경망은 MLP의 구조에 한정되는 것은 아니며, 다층 구조를 갖는 다양한 인공신경망 구조들 중의 하나를 이용하여 구현될 수 있 다. 도 1에 도시된 바와 같이, 인공신경망은, 외부로부터 입력 데이터를 입력하면, 각각 하나 이상의 노드로 구성된 복수의 레이어(110_1, 110_2, ..., 110_N)를 거쳐 입력 데이터에 대응한 출력 데이터를 출력하도록 구성 된다. 일반적으로, 인공신경망의 학습 방법에는, 교사 신호(정답)의 입력에 의해서 문제의 해결에 최적화되도록 학습하는 지도 학습(Supervised Learning)방법, 교사 신호를 필요로 하지 않는 비지도 학습(Unsupervised Learning)방법, 지도 학습과 비지도 학습을 함께 이용하는 준 지도 학습(Semi-supervised Learning)방법이 있 다. 도 1에 도시된 인공신경망은, 사용자의 선택에 따라 지도 학습(Supervised Learning)방법, 비지도 학 습(Unsupervised Learning)방법, 준 지도 학습(Semi-supervised Learning)방법 중 적어도 하나 이상의 방법을이용하여, 출력 데이터를 생성하는 인공신경망을 학습시킬 수 있다. 도 2 내지 도 3은, 본 개시의 일 실시예에 따른 도 1에 도시된 인공신경망의 구체적인 구현예들을 설명하 기 위한 도면이다. 도 2를 참조하면, 인공신경망은, 입력 데이터가 입력되는 입력 노드( , ... , ), 입 력 데이터에 대응하는 출력 데이터를 출력하는 출력 노드( , ... , ), 입력 노드와 출력 노 드 사이에 위치하는 은닉 노드 및 다수의 파라미터를 포함할 수 있다. 입력 노드( , ... , )는, 입력층을 구성하는 노드로서, 외부로부터 입력 데이터(예를 들어, 이미지)를 수신하고, 출력 노드( , ... , )는 출력층을 구성하는 노드로서, 외부로 출력데이터를 출력할 수 있다. 입 력 노드와 출력 노드 사이에 위치한 은닉 노드는, 은닉층을 구성하는 노드로서, 입력 노드의 출력 데이터 를 출력 노드의 입력 데이터로 연결할 수 있다. 입력층의 각 노드는, 도 2에 도시된 바와 같이, 출력층 의 각 출력 노드와 완전 연결될 수 있고, 불완전 연결될 수 있다. 또한, 입력 노드는, 외부로부터 입력 데이터를 수신하여 은닉 노드로 전달해주는 역할을 할 수 있다. 이때, 은닉 노드와 출력 노드에서는, 데이터에 대한 계산을 수행할 수 있는데, 수신한 입력 데이터에 파라미터(또는 가중치)를 곱하여 계산을 수행할 수 있다. 각 노드의 계산이 완료되면, 계산 결과값을 모두 합한 후, 미리 설정된 활성화 함수를 이용하여 출력 데이터를 출력할 수 있다. 은닉 노드와 출력 노드( , ... , )는 활성화 함수를 갖는다. 활성화 함수는 계단 함수(step function), 부호 함수(sign function), 선형 함수(linear function), 로지스틱 시그모이드 함수(logistic sigmoid function), 하이퍼탄젠트 함수(hyper tangent function), ReLU 함수, 소프트맥스(softmax) 함수 중 어 느 하나일 수 있다. 활성화 함수는 통상의 기술자라면 인공 신경망의 학습 방법에 따라 적절히 결정될 수 있다. 인공 신경망은 가중치 값들을 반복적으로 적절한 값으로 갱신(또는 수정)하는 과정으로 기계 학습한다. 인 공 신경망이 기계 학습하는 방법에는 대표적으로 지도 학습과 비지도 학습이 있다. 지도 학습은 입력 데이터에 대해 임의의 신경망이 계산해내기를 바라는 목표 출력 데이터가 명확히 정해져 있는 상태에서, 상기 입력 데이터를 상기 신경망에 넣어서 얻은 출력 데이터를 상기 목표 데이터에 비슷해질 수 있도 록 가중치 값들을 갱신시키는 학습 방법이다. 도 2의 다층 구조의 인공신경망은 지도 학습에 기반하여 생 성될 수 있다. 도 3을 참조하면, 다층 구조의 인공 신경망의 다른 예로서, 심층 신경망(DNN, Deep Neural Network)의 한 종류 인 컨볼루션 신경망(CNN, Convolutional Neural Network)이 있다. 컨벌루션 신경망(CNN)은 하나 또는 여 러 개의 컨벌루션 계층(convolutional layer)과 통합 계층(pooling layer), 완전하게 연결된 계층(fully connected layer)들로 구성된 신경망이다. 컨벌루션 신경망(CNN)은 2차원 데이터의 학습에 적합한 구조를 가지 고 있으며, 역전달(Backpropagation algorithm)을 통해 학습될 수 있다. 영상 내 객체 분류, 객체 탐지 등 다 양한 응용 분야에 폭넓게 활용되는 DNN의 대표적 모델 중 하나이다. 여기서, 본 발명의 다층 구조의 인공 신경망이 도 2 및 도 3에 도시된 인공 신경망으로 한정되는 것은 아니며, 기타 다양한 인공 신경망에 다른 종류의 데이터를 기계 학습시켜 학습된 모델을 얻을 수도 있음에 유의해야 한 다. 도 4는 본 개시의 일 실시예에 따른 복수의 레이어를 포함하는 인공신경망의 다른 예를 보여주는 도면이다. 도 1에 도시된 인공신경망은, 도 3에 개시되어 있는 복수의 컨볼루션 레이어(convolution layer: CONV), 복수의 서브샘플링 레이어(subsampling layer: SUBS), 및 복수의 완전 연결 레이어(fully- connected layer: FC)를 포함하는 컨볼루션 인공 신경망(convolution neural network: CNN)이다. CNN의 CONV은 입력 데이터에 대해 컨볼루션 가중치 커널을 적용하여 특징맵(feature map)을 생 성한다. 여기서, CONV은 고차원의 입력 데이터(예를 들어, 이미지 또는 영상)에 대해서 특징을 추출하는 일종의 템플릿 역할을 할 수 있다. 구체적으로, 하나의 컨볼루션은 입력데이터의 부분을 대상으로 위치를 변경하면서 여러 번 반복하여 적용되어 전체 입력데이터에 대해 특징을 추출할 수 있다. 또한, SUBS(43 0)은 CONV에 의해 생성된 특징맵에 대해서 공간적 해상도를 감소하는 역할을 한다. 서브샘플링은 입력데 이터(예를 들어, 특징맵)의 차원을 축소하는 기능을 하며, 이를 통해 입력 데이터의 분석 문제의 복잡도를감소시킬 수 있다. SUBS은 특징맵의 부분의 값들에 대해 최대치를 취하는 맥스풀링(max pooling) 연산자 나 평균치를 취하는 평균풀링(average pooling) 연산자를 사용할 수 있다. 이와 같은 SUBS은 풀링 연산을 통해 특징맵의 차원을 감소시킬 뿐 아니라, 특징맵이 이동(shift)과 왜곡(distortion)에 대해 강인하도록 하는 효과를 갖는다. 마지막으로 FC은 특징맵에 기초하여 입력 데이터를 분류하는 기능을 수행할 수 있다. CNN은, CONV, SUBS, FC의 레이어 수 또는 연산자의 종류에 따라 다양한 구성과 기능을 실 행할 수 있다. 예를 들어, CNN은, AlexNet, VGGNet, LeNet, ResNet 등과 같은 다양한 CNN의 구성 중 어 느 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 이상 설명한 구성을 갖는 CNN의 CONV은, 이미지 데이터가 입력 데이터로 입력되면, 입력 데이터 에 가중치를 적용하여 합성곱 연산을 통해 특징맵을 생성할 수 있는데, 이때, 사용되는 가중치들의 그룹을 가중치 커널(kernel)이라고 지칭할 수 있다. 가중치 커널은, n x m x d의 3차원 행렬(여기서, n은 입력 이미지 데이터와 마찬가지로 특정 크기의 행을 나타내고, m은 특정 크기의 열을 나타내며, d는 입력 이미지 데이터의 채널 등을 나타내는 것으로, 이들 차원의 수는 1이상의 정수임)로 구성되는데, 입력 데이터를 지정된 간격 으로 순회하며 합성곱 연산을 통해 특징맵을 생성할 수 있다. 이때, 입력 데이터가 복수의 채널(예를 들 어, RGB의 3개의 채널)을 갖는 컬러 이미지라면, 가중치 커널은 입력 데이터의 각 채널을 순회하며 합성곱 을 계산한 후, 채널 별 특징맵을 생성할 수 있다. 도 5는 본 개시의 일 실시예에 따른 컨볼루션 레이어의 입력 데이터와 합성곱 연산에 사용되는 가중치 커널을 나타내는 도면이다. 도시된 바와 같이, 입력 데이터는, 특정 크기의 행과 특정 크기의 열로 구성된 2차원적 행렬로 표시되는 이미지 또는 영상일 수 있다. 앞서 설명한 바와 같이, 입력 데이터는 복수의 채널을 가질 수 있는데, 여기서 채널은 입력 데이터 이미지의 컬러 성분의 수를 나타낼 수 있다. 한편, 가중치 커널 은, 입력 데이터의 일정 부분을 스캐닝하면서 해당 부분의 특징을 추출하기 위한 합성곱에 사용되는 가중치 커널일 수 있다. 가중치 커널은, 입력 데이터 이미지와 마찬가지로 특정 크기의 행, 특정 크 기의 열, 특정 수의 채널을 갖도록 구성될 수 있다. 일반적으로 가중치 커널의 행, 열 의 크기는 동일하도록 설정되며, 채널의 수는 입력 데이터 이미지의 채널의 수와 동일할 수 있 다. 도 6은 본 개시의 일 실시예에 따른 입력 데이터에 대해 제1 커널을 사용하여 합성곱을 실행하여 제1 활성화 맵 을 생성하는 절차를 설명하는 도면이다. 제1 가중치 커널은, 도 2의 가중치 커널의 제1채널을 나타내는 가중치 커널일 수 있다. 제1 가중치 커널은, 입력 데이터를 지정된 간격으로 순회하며 합성곱을 실행함으로써, 최종적으로 제1 활성화 맵(63 0)을 생성할 수 있다. 합성곱은, 입력 데이터의 일 부분에 제1 가중치 커널을 적용하였을 때, 그 부 분의 특정 위치의 입력 데이터 값들과 가중치 커널의 해당 위치의 값들을 각각 곱한 뒤 생성된 값들을 모두 더 하여 실행된다. 이러한 합성곱 과정을 통해, 제1 결과값이 생성되며, 제1 가중치 커널이 입력 데이 터를 순회할 때마다 이러한 합성곱의 결과값들이 생성되어 특징맵을 구성한다. 특징맵의 각 구성요소 값 들은 컨볼루션 레이어의 활성화 함수를 통해 제1 활성화 맵으로 변환된다. 도 7은 본 개시의 일 실시예에 따른 입력 데이터에 대해 제2 가중치 커널을 사용하여 합성곱을 실행하여 제2 활 성화 맵을 생성하는 절차를 설명하는 도면이다. 도 6에 도시된 바와 같이 제1 가중치 커널을 이용하여 입력 데이터에 대해 합성곱을 실행하여 제1 활 성화 맵을 생성한 후, 도 7에 도시된 바와 같이 제2 가중치 커널을 이용하여 입력 데이터에 대 해 합성곱을 실행함으로써 제2 활성화 맵을 생성할 수 있다. 제2 가중치 커널은, 도 5의 가중치 커널의 제2채널을 나타내는 가중치 커널일 수 있다. 제2 가중치 커널은, 입력 데이터를 지정된 간격으로 순회하며 합성곱을 실행함으로써, 최종적으로 제2 활성화 맵(73 0)을 생성할 수 있다. 도 6과 마찬가지로, 합성곱은, 입력 데이터의 일 부분에 제2 가중치 커널을 적용하였을 때, 그 부분의 특정 위치의 입력 데이터 값들과 가중치 커널의 해당 위치의 값들을 각각 곱한 뒤 생 성된 값들을 모두 더하여 실행된다. 이러한 합성곱 과정을 통해, 제2 결과값이 생성되며, 제2 가중치 커 널이 입력 데이터를 순회할 때마다 이러한 합성곱의 결과값들이 생성되어 특징맵을 구성한다. 특징 맵의 각 구성요소 값들은 컨볼루션 레이어의 활성화 함수를 통해 제2 활성화 맵으로 변환된다. 도 8은 본 개시의 일 실시예에 따른 입력 특징맵이 하나의 채널을 가지는 경우의 컨볼루션 레이어의 연산 과정 을 행렬로 표현한 도면이다. 도 8에 도시된 콘볼루션 레이어는 도 4에 도시된 CONV에 대응될 수 있다. 도 8에서 콘볼루션 레이어 에 입력되는 입력 데이터는 6 x 6의 크기를 갖는 2차원적 행렬로 표시되며, 가중치 커널은 3 x 3 크기를 갖는 2차원적 행렬로 표시된다. 그러나, 컨볼루션 레이어의 입력 데이터 및 가중치 커널 의 크기는, 이에 한정되는 것은 아니며, 컨볼루션 레이어가 포함되는 인공신경망의 성능 및 요구사항 에 따라 다양하게 변경될 수 있다. 도시된 바와 같이, 컨볼루션 레이어에 입력 데이터가 입력되면, 가중치 커널이 입력 데이터 상에서 사전 결정된 간격(예를 들어, 1)으로 순회하며, 입력 데이터와 가중치 커널의 동일 위 치의 값들을 각각 곱하는 다중 곱(elementwise multiplication)을 실행할 수 있다. 가중치 커널은, 일정 간격으로 입력 데이터를 순회하며, 다중 곱을 통해 획득한 값을 합산(summation)한다. 구체적으로, 가중치 커널이 입력 데이터의 특정 위치에서 계산한 다중 곱의 값(예를 들어, \" 3\")을 특징맵의 대응 요소에 배정한다. 다음으로, 가중치 커널이 입력 데이터의 다음 위 치에서 계산한 다중 곱의 값(예를 들어, \"1\")을 특징맵의 대응 요소에 배정한다. 이와 같이 가 중치 커널이 입력 데이터 상을 순회하면서 계산한 다중 곱의 값들을 특징맵에 모두 배정하면, 4 x 4 크기의 특징맵이 완성된다. 이때, 입력 데이터가 예를 들어 3가지 채널(R채널, G채널, B채널)로 구성된다면, 동일 가중치 커널 또는 채널 별 상이한 채널을 각각 입력 데이터의 각 채널 별 데이터 상을 순회하며 다중 곱과 합을 진행하는 합성곱을 통해 채널 별 특징맵들을 생성할 수 있다. 다시 도 4을 참조하면, CONV는, 도 25내지 도 8를 참조하여 설명한 방법에 따라 생성된 특징맵에 대해 활 성화 함수를 적용하여 콘볼루션 레이어의 최종 출력 결과인 활성화 맵(activation map)을 생성할 수 있다. 여 기서, 활성화 함수는 시그모이드 함수((sigmoid function), 방사기저 함수(radial basis function: RBF), 정류 선형 함수(rectified linear unit: ReLU) 등 다양한 활성화 함수 중의 어느 하나이거나 또는 이들 중 변형된 함 수 이거나 다른 함수 일 수 있다. 한편, SUBS는, CONV의 출력 데이터인 활성화 맵을 입력 데이터로 수신한다. SUBS은, 활성화 맵 의 크기를 줄이거나 특정 데이터를 강조하는 기능을 수행한다. SUBS가 맥스 풀링을 사용하는 경우, 활성 화 맵의 특정 영역 안 값의 최댓값을 선택하여 출력한다. 이와 같이 SUBS의 풀링 과정을 통해 입력 데이 터의 노이즈를 제거할 수 있고, 그 데이터의 크기를 줄일 수 있다. 또한, FC는 SUBS의 출력 데이터를 수신하여 최종 출력 데이터를 생성할 수 있다. SUBS에 서 추출된 활성화 맵은, 완전 연결 레이어에 입력되기 위해 1차원적으로 평면화된다. 도 9는 본 개시의 일 실시예에 따른 완전 연결 레이어의 연산 과정을 행렬로 표현한 도면이다. 도 9에 도시된 완전 연결 레이어는 도 4의 FC에 대응될 수 있다. 이상 설명한 바와 같이, 맥스 풀링 레이어에서 추출된 활성화 맵은 완전 연결 레이어로 입력되기 위해 1차원으로 평명화 될 수 있다. 1 차원으로 평명화된 활성화 맵은, 완전 연결 레이어에서 입력 데이터로 수신될 수 있다. 완전 연결 레이어에서는, 1차원의 가중치 커널을 이용하여 입력 데이터와 가중치 커널의 다중 곱 을 실행할 수 있다. 이와 같은 입력 데이터와 가중치 커널의 다중 곱의 결과값은 합산되 어 출력 데이터로 출력될 수 있다. 이때, 출력 데이터는, CNN에 입력된 입력 데이터에 대 한 추론 값을 나타낼 수 있다. 이상 설명한 구성을 갖는 CNN은, 복수의 레이어 각각에 대해 2차원 또는 1차원 행렬의 입력 데이터가 입력 되고, 입력 데이터에 대해 가중치 커널의 다중 곱과 합산과 같은 복잡한 연산을 통해 학습과 추론 과정을 실행 한다. 따라서, CNN의 구성하는 레이어의 수나 연산의 복잡도에 따라 데이터의 학습 및 추론에 소요되는 자원(예를 들어, 연산자의 수나 메모리의 양)이 상당히 증가할 수 있다. 따라서, CNN과 같이 복수의 레이 어를 갖는 인공 신경망의 연산량과 메모리를 줄이기 위하여 레이어 별로 사용되는 입출력 데이터에 대한 비트 양자화가 실행될 수 있다. 일 실시예에서, 복수의 레이어를 갖는 CNN의 비트 양자화는, 많은 연산량과 메 모리량이 필요한 CONV와 FC에 대해 실행될 수 있다. 도 10은 본 개시의 일 실시예에 따른 콘볼루션 레이어의 비트 양자화 과정을 행렬로 표현한 도면이다. 콘볼루션 레이어에서 실행되는 비트 양자화는, 합성곱 연산에 사용되는 가중치 커널의 각 요소 값의 비트 수를 감소시키는 가중치 또는 가중치 커널 양자화, 및/또는 특징맵 또는 활성화 맵의 각 요소 값의 비트 수를감소시키는 특징맵 양자화 또는 활성화 맵 양자화를 포함할 수 있다. 일 실시예에 따른 콘볼루션 레이어의 비트 양자화 과정은, 다음과 같이 실행될 수 있다. 콘볼루션 레이어의 입 력 데이터에 가중치 커널을 적용하여 합성곱을 실행하기 전에, 가중치 커널에 대한 양자화 과정을 실행하여 양자화된 가중치 커널을 생성한다. 또한, 입력 데이터에 대해 양자화된 가 중치 커널을 적용하여 다중 곱과 합산을 실행하여 합성곱의 값들을 출력하여 특징맵을 생성 한 뒤 활성화 함수를 통해 활성화 맵을 생성할 수 있다. 다음으로, 활성화 맵에 대해 양자화를 통 해 최종 양자화 활성화 맵을 생성할 수 있다. 이상 설명한 콘볼루션 레이어의 비트 양자화 과정에서, 가중치 커널 양자화는 다음 수식을 이용하여 실행 될 수 있다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 는 양자화될 가중치 값(예를 들어, 실수의 가중치 및 가중치 커널 내의 각 가중치)을 나타내고, 는 양자화할 비트 수를 나타내고, 는 가k비트 만큼 양자화된 결과를 나타낸다. 즉, 위 수식에 따르면, 먼저 에 대해, 사전 결정된 이진수 를 곱하여 , 가 k 비트만큼 자리수가 증가된다(이하 \"제1 값\"이라고 함). 다음으로, 제1 값에 대해 라운딩(rounding) 또는 트렁케이션(truncation) 연산을 실행함으로써, 의 소수점 이하 숫자가 제거된다(이하 \"제2 값\"이라고 함). 제2 값은 이진수 으로 나누어, k 비트만큼 자리수 가 다시 감소됨으로써, 최종 양자화된 가중치 커널의 요소 값이 계산될 수 있다. 이와 같은 가중치 또는 가중 치 커널 양자화는 가중치 또는 가중치 커널의 모든 요소 값에 대해 반복 실행되어, 양자화 된 가중 치 값들이 생성된다. 한편, 특징맵 또는 활성화 맵 양자화는, 다음 수식에 의해 실행될 수 있다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "특징맵 또는 활성화 맵 양자화에서는, 가중치 또는 가중치 커널 양자화 방법과 동일한 수식이 이용 될 수 있다. 다만, 특징맵 또는 활성화 맵 양자화에서 특징맵 또는 활성화 맵의 각 요소 값( ) (예를 들어, 실수의 계수)에 대한 양자화가 적용되기 전에, 클립핑(clipping)이 적용하여 특징맵 또는 활성화 맵의 각 요소 값을 0에서 1의 사이 값으로 정규화 시키는 과정을 추가할 수 있다. 다음으로, 정규화된 에 대해, 사전 결정된 이진수 를 곱하여, 가 k 비트만큼 자리수가 증가된다(\"제1 값\"). 다음으로, 제1 값에 대해 라운딩 또는 트렁케이션 연산을 실행함으로써, 의 소수점 이하 숫자가 제거 된다(\"제2 값\"). 제2 값은 이진수 으로 나누어, k 비트만큼 자리수가 다시 감소됨으로써, 최종 양자화된 특 징맵 또는 활성화 맵의 요소 값이 계산될 수 있다. 이와 같은 특징맵 또는 활성화 맵의 양자화는 특징맵 또는 활성화 맵의 모든 요소 값에 대해 반복 실행되어, 양자화된 특징맵 또는 활성화 맵이 생성된다. 이상 설명한 가중치 또는 가중치 커널 양자화와 특징맵 또는 활성화 맵 양자화를 통해, 콘볼루션 신경망의 콘볼루션 레이어의 합성곱 연산 등에 소요되는 메모리 크기와 연산량을 비트 단위로 감소시킬 수 있다. 도 11은 본 개시의 일 실시예에 따른 인공신경망의 비트 양자화 방법을 나타내는 순서도이다. 이 실시예는, 인 공신경망에서 양자화할 수 있는 데이터 그룹의 단위를, 인공신경망을 구성하는 각 레이어에 속한 모든 파라미터로 가정한 예이다. 도시된 바와 같이, 인공신경망의 비트 양자화 방법은, 인공신경망에 포함된 복수의 레이어 중의 적어도 하나의 레이어를 선택하는 단계(S1110)로 개시될 수 있다. 인공신경망에 포함된 복수의 레이어 중에서 어떤 레 이어를 선택할지는, 인공신경망의 전체 성능 또는 연산량(또는 메모리양)에 선택될 레이어가 미치는 영향에 따 라 결정될 수 있다. 일 실시예에서, 앞서 설명한 도 1 내지 도 3를 참조하여 설명한 다층 구조의 인공 신경망 에서는, 인공신경망의 전체 성능 또는 연산량 등에 미치는 영향이 큰 레이어가 임의로 선택될 수 있다. 또한, 도 4 내지 도 10을 참조하여 설명한 콘볼루션 인공신경망(CNN)의 경우에는, 콘볼루션 레이어 및/또는 완전 연결 레이어가 CNN의 전체 성능 또는 연산량 등에 미치는 영향이 크기 때문에, 이들 레이어 (420, 440) 중 적어도 하나의 레이어가 선택될 수 있다. 인공신경망에 포함된 복수의 레이어 중 적어도 하나를 선택하는 방법은, 선택된 레이어가 인공신경망의 전체 성 능 또는 연산량 등에 미치는 영향에 따라 결정될 수 있으나, 이에 한정되는 것은 아니고, 다양한 방법들 중에 하나를 포함할 수 있다. 예를 들어, 인공신경망에 포함된 복수의 레이어 중 적어도 하나의 레이어의 선택은, (i) 인공신경망을 구성하는 복수의 레이어의 배열 순서에 따라 입력 데이터가 수신되는 제1 레이어부터 이후 레 이어로 순차적으로 선택하는 방법, (ii) 인공신경망을 구성하는 복수의 레이어의 배열 순서에 따라 최종 출력 데이터가 생성되는 가장 마지막 레이어부터 이전 레이어로 순차적으로 선택하는 방법, (iii) 인공신경망을 구성 하는 복수의 레이어 중에서 가장 연산량이 높은 레이어부터 선택하는 방법, 또는 (iv) 인공신경망을 구성하는 복수의 레이어 중에서 가장 연산량이 작은 레이어부터 선택하는 방법에 따라 실행될 수도 있다. 단계(S1110)에서 인공신경망의 레이어 선택이 완료되면, 선택된 레이어의 파라미터(예를 들어, 가중치)에 대한 데이터 표현 크기를 비트 단위로 감소시키는 단계(S1120)로 진행될 수 있다. 일 실시예에서, 선택된 레이어의 파라미터들 중 가중치 또는 출력 데이터의 크기를 비트 단위로 감소시키는 경 우, 도 4내지 도 10을 참조하여 설명한 가중치 커널 양자화와 활성화 맵 양자화가 실행될 수 있다. 예를 들어, 가중치 커널 양자화는, 다음 수식에 의해 산출될 수 있다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 양자화될 가중치 커널의 요소 값(예를 들어, 실수의 가중치 커널 계수)을 나타내고, 는 양자화 할 비트 수를 나타내고, 는 가k비트 만큼 양자화된 결과를 나타낸다. 즉, 위 수식에 따르면, 먼저 에 대해, 사전 결정된 이진수 를 곱하여 , 가 k 비트만큼 자리수가 증가된다(\"제1 값\"). 다음으로, 제1 값 에 대해 라운딩 또는 트렁케이션 연산을 실행함으로써, 의 소수점 이하 숫자가 제거된다(\"제2 값\"). 제2 값 은 이진수 으로 나누어, k 비트만큼 자리수가 다시 감소됨으로써, 최종 양자화된 가중치 커널의 요소 값이 계산될 수 있다. 이와 같은 가중치 커널 양자화는 가중치 커널의 모든 요소 값에 대해 반복 실행 되어, 양자화 가중치 커널이 생성된다. 한편, 활성화 맵 양자화는, 다음 수식에 의해 실행될 수 있다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "활성화 맵 양자화에서는, 활성화 맵의 각 요소 값( )(예를 들어, 실수의 계수)에 대한 양자화가 적용되기 전에, 클립핑(clipping)이 적용하여 활성화 맵의 각 요소 값을 0에서 1의 사이 값으로 정규화 시키는 과정을 추가할 수 있다. 다음으로, 정규화된 에 대해, 사전 결정된 이진수 를 곱하여, 가 k 비트만큼 자리수가 증가된다(\"제1 값\"). 다음으로, 제1 값에 대해 라운딩 또는 트렁케이션 연산을 실행함으로써, 의 소수점 이하 숫자가 제거된다(\"제2 값\"). 제2 값은 이진수 으로 나누어, k 비트만큼 자리수가 다 시 감소됨으로써, 최종 양자화된 활성화 맵의 요소 값이 계산될 수 있다. 이와 같은 활성화 맵의 양자화 는 활성화 맵의 모든 요소 값에 대해 반복 실행되어, 양자화 활성화 맵이 생성된다. 이상 설명한 실시예들에서는, 인공신경망에서 선택된 레이어의 파라미터에 대한 데이터 표현의 크기를 감소하기 위해, 그 가중치 값 또는 활성화 맵 데이터의 비트 수를 감소하는 예를 설명하였으나, 본 개시의 비트 양자화 방법은 이에 한정되지 않는다. 다른 실시예에서, 인공신경망에서 선택된 레이어에 포함된 다양한 데이터에 대 한 여러 연산 단계들 사이에 존재하는 중단 단계의 데이터에 대해 각각 다른 비트를 할당할 수도 있다. 이에 따 라서 인공신경망의 하드웨어로 구현 시 각 데이터가 저장되는 메모리(예를 들어, 버퍼, 레지스터, 또는 캐쉬)의 크기를 감소하기 위해, 해당 메모리에 저장되는 각 데이터의 비트 수를 감소하고 해당 메모리의 비트 수를 감소 할 수도 있다. 또 다른 실시예에서, 인공신경망에서 선택된 레이어의 데이터가 전송되는 데이터 경로의 데이터 비트의 크기를 비트 단위로 감소할 수도 있다. 단계(S1120)의 실행 후에, 인공신경망의 정확도가 사전 결정된 목표값 이상인지 여부를 결정하는 단계(S1130)를 진행할 수 있다. 인공신경망에서 선택된 레이어의 파라미터의 데이터 표현 크기를 비트 단위로 감소한 후, 해 당 인공신경망의 출력 결과(예를 들어, 인공신경망의 학습 결과 또는 추론 결과)의 정확도가 사전에 결정된 목 표값 이상이라면, 추가적으로 해당 데이터의 비트를 감소시켜도 인공신경망의 전체 성능을 유지할 수 있다고 예 상할 수 있다. 따라서, 단계(S1130)에서 인공신경망의 정확도가 목표값 이상이라고 결정되는 경우, 단계(S1120)로 진행하여, 선택된 레이어의 데이터 표현 크기를 비트 단위로 추가로 감소시킬 수 있다. 또한, 해당 인공신경망의 출력 결 과(예를 들어, 인공신경망의 학습 결과 또는 추론 결과)의 정확도가 사전에 결정된 목표값 이상인지 여부를 다 시 판단할 수 있다(단계 S1130). 단계(S1130)에서, 인공신경망의 정확도가 목표값 이상이 아니라면, 현재 실행된 비트 양자화에 의해 인공신경망 의 정확도가 저하되었다고 판단할 수 있다. 따라서, 이 경우, 바로 이전에 실행된 비트 양자화에서 정확도 목 표값을 만족시켰던 최소의 비트 수를 선택된 레이어의 파라미터에 대한 최종 비트 수로 결정할 수 있다(단계 S1140). 다음으로, 인공신경망의 모든 레이어에 대한 비트 양자화가 완료되었는지를 결정한다(단계 S1150). 이 단계에 서, 인공 신경망의 모든 레이어에 대한 비트 양자화가 완료되었다고 판단되면, 전체 프로세스를 종료한다. 반 면, 인공 신경망의 레이어들 중에서 아직 비트 양자화가 되지 않은 레이어가 남아 있다면, 해당 레이어에 대한 비트 양자화를 실행하기 위해 단계(S1110)를 실행한다. 여기서, 단계(S1110)에서 인공신경망에 포함된 복수의 레이어 중에서 다른 하나의 레이어를 선택하는 방법은, (i) 인공신경망을 구성하는 복수의 레이어의 배열 순서에 따라, 이전 선택된 레이어의 다음 레이어를 순차적으 로 선택하는 방법(\"순방향 비트 양자화\", forward bit quantization), (ii) 인공신경망을 구성하는 복수의 레이 어의 배열 순서에 따라, 이전 선택된 레이어의 이전 레이어를 역방향으로 선택하는 방법(\"역방향 비트 양자화\", backward bit quantization), (iii) 인공신경망을 구성하는 복수의 레이어 중에서 연산량의 순서에 따라, 이전 선택된 레이어 다음으로 연산량이 많은 레이어를 선택하는 방법(\"고 연산량 비트 양자화\", high computational cost bit quantization), 또는 (iv) 인공신경망을 구성하는 복수의 레이어 중에서 연산량의 순서에 따라, 이전 선택된 레이어 다음으로 연산량이 작은 레이어를 선택하는 방법(\"저 연산량 비트 양자화\", low computational cost bit quantization)에 따라 실행될 수도 있다. 일 실시예에서, 인공신경망의 정확도는, 인공신경망이 주어진 문제의 해결 방법(예를 들어, 입력 데이터인 이미 지에 포함된 물체의 인식)을 학습 후에, 추론 단계에서 해당 문제의 해결방법을 제시할 확률을 의미할 수 있다. 또한, 이상 설명한 비트 양자화 방법에서 사용되는 목표치는, 인공신경망의 비트 양자화 후에 유지해야할 최소 한의 정확도를 나타낼 수 있다. 예를 들어, 목표치가 90%의 정확도라고 가정하면, 비트 양자화에 의해 선택된 레이어의 파라미터를 비트 단위로 감소시킨 후에도, 해당 인공신경망의 정확도가 90% 이상이라면 , 추가의 비트 양자화를 실행할 수 있다. 예를 들어, 첫 번째 비트 양자화를 실행한 후에, 인공신경망의 정확도가 94%로 측정 되었다면, 추가의 비트 양자화를 실행할 수 있다. 두 번째 비트 양자화의 실행 후에, 인공신경망의 정확도가 88%로 측정되었다면, 현재 실행된 비트 양자화의 결과를 무시하고, 첫번째 비트 양자화에 의해 결정된 비트 수 (즉, 해당 데이터를 표현하기 위한 비트 수)를 최종의 비트 양자화 결과로 확정할 수 있다. 일 실시예에서, 연산량 비트 양자화(computational cost bit quantization) 방식에 따라, 복수의 레이어를 포 함하는 인공 신경망에서, 복수의 레이어 중에서 연산량을 기준으로 비트 양자화를 실행할 레이어를 선택하는 경 우, 각 레이어의 연산량은 다음과 같이 결정될 수 있다. 즉, 인공 신경망의 특정 레이어에서 하나의 덧셈 연산 이 n 비트와 m 비트의 덧셈을 실행하는 경우, 해당 연산의 연산량은 (n+m)/2로 산정한다. 또한, 인공 신경망의 특정 레이어가 n 비트와 m 비트의 곱셈을 실행하는 경우, 해당 연산의 연산량은 n x m으로 산정할 수 있다. 따 라서, 인공 신경망의 특정 레이어의 연산량은, 그 레이어가 실행하는 모든 덧셈과 곱셈의 연산량들을 합산한 결 과가 될 수 있다. 또한, 연산량 비트 양자화(computational cost bit quantization) 방식에 따라, 인공 신경망에서 복수의 레이 어 중에서 연산량을 기준으로 레이어를 선택하여 비트 양자화를 실행하는 방법은, 도 11에 도시된 것에 한정되 는 것은 아니고, 다양한 변형이 가능하다. 다른 실시예에서, 도 11에 도시된 실시예에서 각 레이어 별 파라미터의 비트 양자화는, 가중치와 활성화맵 각각 에 대해 분리하여 실행될 수 있다. 예를 들어, 먼저, 선택된 레이어의 가중치에 대해서 양자화를 실행하고 이에 대한 결과로 가중치가 n 비트를 가지게 된다. 이와는 개별적으로, 선택된 레이어의 출력 활성화 데이터에 대하 여 비트 양자화를 실행하여 활성화 맵 데이터의 표현 비트 수를 m비트로 결정할 수 있다. 대안적으로, 해당 레 이어의 가중치와 활성화 맵 데이터에 대해 동일한 비트를 할당하면서 양자화 진행을 하고, 결과적으로 가중치와 활성화 맵 데이터 모두에 대해 동일한 n비트로 표현될 수도 있다. 도 12는 본 개시의 다른 실시예에 따른 인공신경망의 비트 양자화 방법을 나타내는 순서도이다. 도시된 바와 같이, 인공신경망의 비트 양자화 방법은, 인공신경망에 포함된 복수의 레이어 중에서 연산량 이 가장 높은 레이어를 선택하는 단계(S1210)로 개시될 수 있다. 단계(S1210)에서 인공신경망의 레이어 선택이 완료되면, 선택된 레이어의 파라미터에 대한 데이터 표현의 크기 를 비트 단위로 감소시키는 단계(S1220)로 진행될 수 있다. 일 실시예에서, 선택된 레이어의 데이터의 크기를 비트 단위로 감소시키는 경우, 도 4 내지 도 10을 참조하여 설명한 가중치 커널 양자화와 활성화 맵 양자 화가 실행될 수 있다. 단계(S1220)의 실행 후에, 지금까지의 비트 양자화 결과를 반영한 인공신경망의 정확도가 사전 결정된 목표값 이상인지 여부를 결정하는 단계(S1230)를 진행할 수 있다. 단계(S1230)에서 인공신경망의 정확도가 목표값 이 상이라고 결정되는 경우, 해당 레이어의 데이터의 크기를 현재의 비트 양자화 결과로 설정하고, 단계(S1210)로 진행하여 단계(S1210 내지 S1230)를 반복 실행할 수 있다. 즉, 단계(S1210)으로 진행하여, 인공신경망 내의 모 든 레이어에 대해 연산량을 다시 계산하고, 이를 바탕으로 연산량이 가장 높은 레이어를 다시 선택한다. 단계(S1230)에서, 인공신경망의 정확도가 목표치 이상이 아니라면, 현재 선택된 레이어에 대한 비트 감소 양자 화를 취소하고, 해당 레이어는 레이어 선택 단계(S1210)에서 선택할 수 있는 레이어 대상에서 제외 시킨다. 그 런 다음에 해당 레이어의 다음으로 연산량이 높은 레이어를 선택할 수 있다(단계 S1240). 다음으로, 선택된 레 이어의 데이터의 크기를 비트 단위로 감소할 수 있다(단계 S1250). 단계(S1260)에서, 지금까지의 비트 양자화 결과를 반영한 인공신경망의 정확도가 목표치 이상인지를 결정한다. 만약 인공신경망의 정확도가 목표치 이상이 아니라면, 인공신경망의 모든 레이어에 대한 비트 양자화가 완료되 었는지를 결정한다(S1270). 단계(S1270)에서 인공신경망의 모든 레이어에 대한 비트 양자화가 완료되었다고 판 단되면, 전체 비트 양자화 절차를 종료한다. 반면, 단계(S1270)에서 인공신경망의 모든 레이어에 대한 비트 양 자화가 완료되지 않았다고 판단되면, 단계(S1240)로 진행할 수 있다. 단계(S1260)에서 인공신경망의 정확도가 목표치 이상이라고 판단되면, 단계로 진행하여 이후 절차를 진행 할 수 있다. 도 13은 본 개시의 또 다른 실시예에 따른 복수의 레이어를 갖는 인공신경망의 비트 양자화 방법을 나타내는 순 서도이다. 도시된 바와 같이, 복수의 레이어를 갖는 인공신경망의 비트 양자화 방법은, 인공 신경망에 포함되는 모 든 레이어 각각에 대한 정확도 변동 지점을 탐색하는 단계들(S1310 내지 S1350)을 포함한다. 방법은, 초 기에 인공신경망에 포함되는 모든 레이어의 데이터의 비트 크기를 최대로 고정하고, 정확도 변동 지점의 탐색이 진행되지 않은 하나의 레이어를 선택하는 단계(S1310)로 개시된다. 단계(S1310)에서 임의의 인공신경망의 레이어 선택이 완료되면, 선택된 레이어의 데이터의 크기를 비트 단위로 감소시키는 단계(S1320)로 진행될 수 있다. 일 실시예에서, 선택된 레이어의 데이터의 크기를 비트 단위로 감소시키는 경우, 도 4 내지 도 10을 참조하여 설명한 가중치 커널 양자화와 활성화 맵 양자화가 실행 될 수 있다. 단계(S1320)의 실행 후에, 선택된 레이어에 대해 지금까지의 비트 양자화 결과를 반영한 인공신경망의 정확도가 사전 결정된 목표값 이상인지 여부를 결정하는 단계(S1330)를 진행할 수 있다. 단계(S1330)에서 인공신경망의 정확도가 목표값 이상이라고 결정되는 경우, 단계(S1320)로 진행하여 현재 선택된 레이어에 대한 추가의 비트 감소 양자화를 실행한다. 단계(S1330)에서, 인공신경망의 정확도가 목표치 이상이 아니라면, 현재 선택된 레이어의 데이터 비트 수를 가 장 최근에 목표치를 만족했었던 최소 비트 수로 설정한다. 이후에, 인공신경망의 모든 레이어에 대한 정확도 변 동 지점의 탐색이 완료되었는지를 결정한다(S1340). 이 단계에서, 모든 레이어에 대한 정확도 변동 지점의 탐 색이 완료되지 않은 경우에는, 단계(S1310)로 진행할 수 있다. 단계(S1310)에서는 인공신경망에 포함되는 모든 레이어의 데이터의 비트 크기가 최대이고, 성능 변동 지점의 탐색이 진행되지 않은 다른 하나의 레이어를 선택 한다. 만약, 단계(S1340)에서, 인공신경망의 모든 레이어에 대한 정확도 변동 지점의 탐색이 완료되었다고 결정되면, 인공 신경망의 각 레이어에 대한 정확도 변동 지점에 대응하는 비트 양자화 결과를 인공 신경망에 반영할 수 있 다(S1350). 일 실시예에서, 단계(S1350)에서는, 이상 설명한 단계들(S1310 내지 S1340)에 따라 결정된 인공신 경망의 각 레이어의 정확도 변동 지점(예를 들어, 각 레이어에 있어서 인공신경망의 정확도의 열화가 발생되는 지점) 직전의 데이터의 비트 크기로 해당 레이어를 설정한다. 다른 실시예에서, 단계(S1350)에서는, 이상 설명한 단계들(S1310 내지 S1340)에 따라 결정된 인공신경망의 각 레이어의 정확도 변동 지점 직전의 파라미터에 대한 연산에 요구되는 자원의 크기보다 크게 해당 레이어를 설정 한다. 예를 들어, 인공 신경망의 각 레이어의 파라미터의 비트 수를 정확도 변동 지점 직전의 비트 수보다 2 비트 크게 설정할 수 있다. 그 다음에, 단계에서 설정된 각 레이어의 데이터의 크기를 갖는 인공신경망에 대해 비트 양자화 방법을 실행한다(S1360). 단계(S1360)에서 실행되는 비트 양자화 방법은, 예를 들어, 도 11 또는 도 12에 도시된 방법을 포함할 수 있다. 이상 설명한 다양한 실시예들에 따른 인공신경망의 비트 양자화 방법은, 인공신경망의 복수의 레이어 각각의 가 중치 커널 및 특징맵(또는 활성화맵)에 대해 실행되는 것에 한정되지 않는다. 일 실시예에서, 본 개시의 비트 양자화 방법은, 인공신경망의 모든 레이어의 가중치 커널(또는 가중치)에 대해 먼저 실행되고, 이와 같은 가중 치 커널 양자화가 반영된 인공신경망의 모든 레이어의 특징맵에 대해 다시 비트 양자화가 실행될 수도 있다. 다른 실시예에서, 인공신경망의 모든 레이어의 특징맵에 대해 먼저 비트 양자화가 실행되고, 이와 같은 특징맵 양자화가 반영된 인공신경망의 모든 레이어의 커널에 대해 다시 비트 양자화가 실행될 수도 있다. 또한, 본 개시의 인공신경망의 비트 양자화 방법은, 인공신경망의 각 레이어의 가중치 커널들에 대해 동일한 수 준의 비트 양자화가 적용되는 것에 한정되지 않는다. 일 실시예에서, 본 개시의 비트 양자화 방법은, 인공신경 망의 각 레이어의 가중치 커널 단위로 비트 양자화를 실행할 수도 있고, 또는 각 가중치 커널의 요소가 되는 각 가중치 단위로 다른 비트를 가질 수 있도록 개별적인 비트 양자화를 실행할 수도 있다. 이하에서는, 본 개시의 다양한 실시예들에 따른 인공신경망의 비트 양자화 방법의 실행 결과의 예들을 도면을 참조하여 설명한다. 도 14는 본 개시의 일 실시예에 따른 인공신경망의 레이어 별 연산량의 예시를 나타내는 그래프이다. 도 14에 도시된 인공신경망은 16개의 레이어를 포함하고 있는 VGG-16 모델의 컨볼루션 인공신경망의 예이며, 이 인공신 경망의 각 레이어는 다른 연산량을 갖고 있다. 예를 들어, 제2 레이어, 제4 레이어, 제6 레이어, 제7 레이어, 제9 레이어, 제10 레이어는 가장 높은 연산량을 갖고 있기 때문에, 고 연산량 비트 양자화(high computational cost bit quantization) 방법에 따를 경우, 가 장 먼저 비트 양자화가 적용될 수 있다. 또한, 제2, 제4, 제6, 제7, 제9 및 제10 레이어에 대한 비트 양자화가 실행된 후, 다음으로 연산량이 높은 제14 레이어에 대한 비트 양자화가 실행될 수 있다. 도 15는 본 개시의 일 실시예에 따른 순방향 양자화(forward bit quantization) 방법에 의해 비트 양자화가 실 행된 인공신경망의 레이어 별 비트 수를 나타내는 그래프이다. 앞서 설명한 바와 같이, 순방향 양자화는, 인공신경망에 포함된 복수의 레이어의 배열 순서를 기준으로 가장 앞 의 레이어부터(예를 들어, 입력 데이터가 처음 수신되는 레이어부터) 순차적으로 비트 양자화를 실행하는 방법이다. 도 15는, 도 14에 도시된 VGG-16 모델의 인공신경망에 대해 순방향 양자화를 적용한 후 각 레이어별 비 트 수와, 순방향 양자화에 의해 인공신경망의 연산량의 감소율을 나타낸다. 예를 들어, n 비트와 m 비트의 덧 셈을 실행하는 경우, 해당 연산의 연산량은 (n+m)/2로 계산한다. 또한, n 비트와 m 비트의 곱셈을 실행하는 경 우, 해당 연산의 연산량은 n x m으로 계산할 수 있다. 따라서, 인공 신경망의 전체 연산량은, 해당 인공 신경 망에서 실행하는 모든 덧셈과 곱셈의 연산량들을 합산한 결과가 될 수 있다. 도시된 바와 같이, 순방향 양자화를 이용하여 VGG-16 모델의 인공신경망에 대해 비트 양자화를 실행하였을 경우, 상대적으로 인공신경망의 앞에 배열된 레이어들의 비트 수가 많이 감소하였고, 인공신경망의 뒤에 배열된 레이어들의 비트 수는 작게 감소하였다. 예를 들어, 인공신경망의 제1레이어의 비트 수는 12비트까지 감소하였 고, 제2 레이어 및 제3 레이어의 비트 수는 각각 9 비트까지 감소한 반면, 제16레이어의 비트 수는 13 비트까지 감소하고, 제15레이어의 비트 수는 15비트까지만 감소하였다. 이와 같이 순방향 양자화를 인공신경망의 제1레 이어부터 제16 레이어까지 순차적으로 적용하였을 때, 인공신경망 전체의 연산량의 감소율은 56%로 계산되었다. 도 16은 본 개시의 일 실시예에 따른 역방향 양자화(backward bit quantization) 방법에 의해 비트 양자화가 실 행된 인공신경망의 레이어 별 비트 수를 나타내는 그래프이다. 역방향 양자화는, 인공신경망에 포함된 복수의 레이어의 배열 순서를 기준으로 가장 뒤의 레이어부터(예를 들어, 출력 데이터가 최종 출력되는 레이어부터) 순차적으로 비트 양자화를 실행하는 방법이다. 도 16은, 도 14에 도시된 VGG-16 모델의 인공신경망에 대해 역방향 양자화를 적용한 후 각 레이어별 비트 수와, 역방향 양자 화에 의해 인공신경망의 연산량의 감소율을 나타낸다. 도시된 바와 같이, 역방향 양자화를 이용하여 VGG-16 모델의 인공신경망에 대해 비트 양자화를 실행하였을 경우, 인공신경망의 뒤에 배열된 레이어들의 비트 수가 상대적으로 많이 감소한 반면, 인공신경망의 앞에 배열 된 레이어들의 비트 수는 작게 감소하였다. 예를 들어, 제1레이어, 제2 레이어, 제3 레이어의 비트 수는 각각 15비트까지 감소하였고, 제4 레이어의 비트 수는 14비트까지 감소한 반면, 제16 레이어의 비트 수는 9비트까지 감소하고, 제15레이어의 비트 수는 15비트까지 감소하였다. 이와 같이 역방향 양자화를 인공신경망의 제1 레이 어부터 제16레이어까지 순차적으로 적용하였을 때, 인공신경망 전체의 연산량의 감소율은 43.05%로 계산되었다. 도 17은 본 개시의 일 실시예에 따른 고 연산량 레이어 우선 양자화(high computational cost layer first bit quantization) 방법에 의해 비트 양자화가 실행된 인공신경망의 레이어 별 비트 수를 나타내는 그래프이다. 고 연산량 레이어 우선 양자화(또는 고 연산량 양자화)는, 인공신경망에 포함된 복수의 레이어 중에서 연산량이 높은 레이어부터 순차적으로 비트 양자화를 실행하는 방법이다. 도 17는, 도 14에 도시된 VGG-16 모델의 인공 신경망에 대해 고 연산량 양자화를 적용한 후 각 레이어별 비트 수와, 고 연산량 양자화에 의해 인공신경망의 연산량의 감소율을 나타낸다. 도시된 바와 같이, 고 연산량 양자화를 이용하여 VGG-16 모델의 인공신경망에 대해 비트 양자화를 실행하였을 경우, 인공신경망의 복수의 레이어들 중에서 연산량이 높은 레이어들의 비트 수가 상대적으로 많이 감소하였다. 예를 들어, 제2레이어 및 제10 레이어의 비트 수는 각각 5비트 및 6 비트까지 감소한 반면, 제1 레이어의 비트 수는 14비트까지 감소하였다. 이와 같이 고 연산량 양자화를 인공신경망의 레이어들에 대해 연산량의 순서대로 적용하였을 때, 인공신경망 전체의 연산량의 감소율은 70.70%로 계산되었다. 도 18은 본 개시의 일 실시예에 따른 저 연산량 레이어 우선 양자화(low computational cost bit quantization) 방법에 의해 비트 양자화가 실행된 인공신경망의 레이어 별 비트 수를 나타내는 그래프이다. 저 연산량 레이어 우선 양자화(또는 저 연산량 양자화)는, 인공신경망에 포함된 복수의 레이어 중에서 연산량이 낮은 레이어부터 순차적으로 비트 양자화를 실행하는 방법이다. 도 18은, 도 14에 도시된 VGG-16 모델의 인공 신경망에 대해 저 연산량 양자화를 적용한 후 각 레이어별 비트 수와, 저 연산량 양자화에 의해 인공신경망의 연산량의 감소율을 나타낸다. 도시된 바와 같이, 저 연산량 양자화를 이용하여 VGG-16 모델의 인공신경망에 대해 비트 양자화를 실행하였을 경우에도, 인공신경망의 복수의 레이어들 중에서 연산량이 높은 레이어들의 비트 수가 상대적으로 많이 감소하 였다. 예를 들어, 제6레이어 및 제7 레이어의 비트 수는 각각 6비트 및 5 비트까지 감소한 반면, 제1 레이어의 비트 수는 13비트까지 감소하였다. 이와 같이 저 연산량 양자화를 인공신경망의 레이어들에 대해 연산량의 순 서대로 적용하였을 때, 인공신경망 전체의 연산량의 감소율은 49.11%로 계산되었다.이하에서는, 이상 설명한 본 개시의 다양한 실시예들에 따른 비트 양자화가 적용된 인공신경망의 하드웨어 구현 예들에 대해 상세히 설명한다. 복수의 레이어를 포함하는 컨볼루션 인공신경망을 하드웨어로 구현하는 경우, 가중치 커널은, 컨볼루션 레이어의 합성곱을 실행하기 위한 프로세싱 유닛의 외부 및/또는 내부에 배열될 수 있 다. 일 실시예에서, 가중치 커널은 컨볼루션 레이어의 합성곱을 실행하기 위한 프로세싱 유닛과 분리된 메모리(예를 들어, 레지스터, 버퍼, 캐쉬 등)에 저장될 수 있다. 이 경우, 가중치 커널에 대해 비트 양자화를 적용하여 가 중치 커널의 요소 값들의 비트 수를 감소시킨 후, 가중치 커널의 비트 수에 따라 메모리의 크기를 결정할 수 있 다. 또한, 메모리에 저장된 가중치 커널의 요소 값들과 입력 특징맵의 요소 값들을 입력 받아 곱셈 및/또는 덧 셈 연산을 실행하는 프로세싱 유닛 내에 배열되는 곱셈기(multiplier) 또는 가산기(adder)의 비트 크기(bit width)도 비트 양자화의 결과에 따른 비트 수에 맞추어 설계될 수 있다. 다른 실시예에서, 가중치 커널은 컨볼루션 레이어의 합성곱을 실행하기 위한 프로세싱 유닛 내에 하드와이어된 (hard-wired) 형태로 구현될 수도 있다. 이 경우, 가중치 커널에 대해 비트 양자화를 적용하여 가중치 커널의 요소 값들의 비트 수를 감소시킨 후, 가중치 커널의 비트 수에 따라 가중치 커널의 요소 값들 각각을 나타내는 하드와이어를 프로세싱 유닛 내에 구현할 수 있다. 또한, 하드와이어된 가중치 커널의 요소 값들과 입력 특징 맵의 요소 값들을 입력 받아 곱셈 및/또는 덧셈 연산을 실행하는 프로세싱 유닛 내에 배열되는 곱셈기 또는 가 산기의 비트 크기도 비트 양자화의 결과에 따른 비트 수에 맞추어 설계될 수 있다. 이하에서 설명되는 도 19 내지 도 21는, 본 개시의 또 다른 실시예에 따른 복수의 레이어를 포함하는 인공신경 망의 하드웨어 구현 예를 도시하는 도면이다. 본 개시인 복수의 레이어를 포함하는 인공신경망의 비트 양자화 방법 및 시스템은, CPU, GPU, FPGA, ASIC 등 어떠한 ANN(Artificial neural network) 연산 시스템에도 본 개시 를 적용하여 필요 연산량, 연산기의 비트 크기, 메모리를 감소시킬 수 있다. 또한, 본 예시에서는 정수 (Integer)를 기준으로 실시 예를 보였지만, 부동 소수점(Floating Point) 연산으로도 실시될 수도 있다. 도 19는 본 개시의 일 실시예에 따른 인공신경망의 하드웨어 구현 예를 도시하는 도면이다. 도시된 인공신경망 은 컨볼루션 인공신경망의 컨볼루션 레이어의 합성곱 처리 장치를 하드웨어로 구현한 예를 나타낸다. 여 기서, 컨볼루션 레이어는, 3x3x3 크기의 가중치 커널을 입력 특징맵 상의 일 부분(3x3x3 크기의 데이터)에 적용 하여 합성곱을 실행하는 것으로 가정하여 설명한다. 각 레이어의 가중치 커널의 크기와 개수는, 응용분야와 입 출력의 특징맵 채널 수에 따라 상이할 수 있다. 도시된 바와 같이, 가중치 커널은 컨볼루션 레이어의 합성곱을 실행하기 위한 프로세싱 유닛과 분리된 가 중치 커널 캐쉬에 저장될 수 있다. 이 경우, 가중치 커널에 대해 비트 양자화를 적용하여 가중치 커널의 요소 값들(w1, w2, ..., w9)의 비트 수를 감소시킨 후, 가중치 커널의 비트 수에 따라 캐쉬의 크기를 결정할 수 있다. 또한, 메모리에 저장된 가중치 커널의 요소 값들과 입력 특징맵의 요소 값들을 입력 받아 곱셈 및/또는 덧셈 연산을 실행하는 프로세싱 유닛 내에 배열되는 곱셈기 또는 가산기의 비트 크기도 비트 양자화의 결 과에 따른 가중치 커널 요소 값의 비트 수에 맞추어 설계될 수 있다. 일 실시예에 따르면, 입력 특징맵 캐쉬는, 입력 데이터 상의 일부분(가중치 커널의 크기에 대응되는 부분)을 입력 받아 저장할 수 있다. 가중치 커널은 입력 데이터 상을 순회하며, 입력 특징맵 캐쉬는 해 당 가중치 커널의 위치에 대응되는 입력 데이터의 일부분을 순차적으로 입력 받아 저장할 수 있다. 입력 특징 맵 캐쉬에 저장된 입력 데이터의 일부분(x1, x2, ..., x9)과 가중치 커널 캐쉬에 저장된 가중치 커 널의 일부 요소 값들(w1, w2, ..., w9)은 각각 대응되는 곱셈기에 입력되어 다중 곱이 실행된다. 곱셈기 에 의한 다중 곱의 결과값들은 트리 가산기에 의해 합산되어 가산기로 입력된다. 입력 데이 터가 다채널로 구성된 경우(예를 들어, 입력 데이터가 RGB 컬러 영상인 경우), 가산기는, 누산기에 저장된 값(초기값은 0)과 입력된 특정 채널의 합산값을 더하여 다시 누산기에 저장할 수 있다. 누산기 에 저장된 합산값은 다음 채널에 대한 가산기의 합산값과 다시 더해서 누산기로 입력될 수 있다. 이러한 가산기와 누산기의 합산 과정은, 입력 데이터의 모든 채널에 대해 실행되어 그 총 합산값은 출력 활성화 맵 캐쉬로 입력될 수 있다. 이상 설명한 합성곱의 절차는, 가중치 커널과 해당 가 중치 커널의 입력 데이터 상의 순회 위치에 대응되는 입력 데이터의 일부분에 대해 반복될 수 있다. 이상 설명한 바와 같이, 가중치 커널의 요소값들이 프로세싱 유닛의 외부에 배열된 가중치 커널 캐쉬 에 저장될 경우, 본 개시에 따른 비트 양자화에 의해 가중치 커널 요소값들의 비트 수를 감소할 수 있으 며, 이에 따라 가중치 커널 캐쉬의 크기와 프로세싱 유닛의 곱셈기와 가산기의 크기를 감소할 수있는 효과가 있다. 또한, 프로세싱 유닛의 크기가 감소함에 따라, 프로세싱 유닛의 전력 소비량도 감소될 수 있다. 도 20은 본 개시의 다른 실시예에 따른 인공신경망의 하드웨어 구현 예를 도시하는 도면이다. 도시된 인공신경망은 컨볼루션 인공신경망의 컨볼루션 레이어의 합성곱 처리 장치를 하드웨어로 구현한 예를 나타낸다. 여기서, 컨볼루션 레이어는, 3x3x3 크기의 가중치 커널을 입력 활성화 맵 상의 일 부분(3x3x3 크기의 데이터)에 적용하여 합성곱을 실행한다. 도시된 바와 같이, 가중치 커널은 컨볼루션 레이어의 합성곱을 실행하기 위한 프로세싱 유닛과 분리된 가 중치 커널 캐쉬에 저장될 수 있다. 이 경우, 가중치 커널에 대해 비트 양자화를 적용하여 가중치 커널의 요소 값들(w1, w2, ..., w9)의 비트 수를 감소시킨 후, 가중치 커널의 비트 수에 따라 캐쉬의 크기를 결정할 수 있다. 또한, 메모리에 저장된 가중치 커널의 요소 값들과 입력 활성화 맵(또는 특징맵)의 요소 값들을 입력 받 아 곱셈 및/또는 덧셈 연산을 실행하는 프로세싱 유닛 내에 배열되는 곱셈기 또는 가산기의 비트 크기도 비트 양자화의 결과에 따른 가중치 커널 요소 값의 비트 수에 맞추어 설계될 수 있다. 일 실시예에 따르면, 입력 활성화맵 캐쉬는, 다채널(예를 들어, 3개의 RGB 채널)로 구성된 입력 데이터 상의 일부분(가중치 커널의 크기에 대응되는 부분)을 입력 받아 저장할 수 있다. 가중치 커널은 입력 데이터 상을 순회하며, 입력 활성화맵 캐쉬는 해당 가중치 커널의 위치에 대응되는 입력 데이터의 일부분을 순차 적으로 입력 받아 저장할 수 있다. 입력 활성화맵 캐쉬에 저장된 입력 데이터의 일부분(x1, x2, ..., x27)과 가중치 커널 캐쉬에 저장된 가중치 커널의 요소값들(w1, w2, ..., w27)은 각각 대응되는 곱셈기에 입력되어 다중 곱이 실행된다. 이 때, 가중치 커널 캐쉬의 커널 요소값들(w1, w2, ..., w9)과 입력 활성 화맵 가중치 캐쉬에 저장된 입력 데이터의 제1채널의 부분(x1, x2, ..., x9)은 제1 합성곱 처리 유닛 로 입력된다. 또한, 가중치 커널 캐쉬의 가중치 커널 요소값들(w10, w11, ..., w18)과 입력 활성화 맵 캐쉬에 저장된 입력 데이터의 제2채널의 부분(x10, x11, ..., x18)은 제2 합성곱 처리 유닛로 입 력된다. 또한, 가중치 커널 캐쉬의 가중치 커널 요소값들(w19, w20, ..., w27)과 입력 활성화맵 캐쉬 에 저장된 입력 데이터의 제3채널의 부분(x19, x20, ..., x27)은 제3 합성곱 처리 유닛로 입력된다. 제1 합성곱 처리 유닛, 제2 합성곱 처리 유닛 및 제3 합성곱 처리 유닛 각각은, 도 19에 도 시된 프로세싱 유닛과 동일하게 동작할 수 있다. 제1 합성곱 처리 유닛, 제2 합성곱 처리 유닛 및 제3 합성곱 처리 유닛 각각에 의해 계산된 합성곱의 결과값은 트리 가산기에 의해 합산 되어 출력 활성화 맵 캐쉬에 입력될 수 있다. 이상 설명한 바와 같이, 가중치 커널의 요소값들이 프로세싱 유닛의 외부에 배열된 가중치 커널 캐쉬 에 저장될 경우, 본 개시에 따른 비트 양자화에 의해 가중치 커널 요소값들의 비트 수를 감소할 수 있으 며, 이에 따라 가중치 커널 캐쉬의 크기와 프로세싱 유닛의 곱셈기와 가산기의 크기를 감소할 수 있는 효과가 있다. 또한, 프로세싱 유닛의 크기가 감소함에 따라, 프로세싱 유닛의 전력 소비량도 감소될 수 있다. 도 21은 본 개시의 또 다른 실시예에 따른 인공신경망의 하드웨어 구현 예를 도시하는 도면이다. 도시된 인공신경망은 컨볼루션 인공신경망의 컨볼루션 레이어의 합성곱 처리 장치를 하드웨어로 구현한 예를 나타낸다. 여기서, 컨볼루션 레이어는, 3x3x3 크기의 가중치 커널을 입력 활성화 맵 상의 일 부분(3x3x3 크기의 데이터)에 적용하여 합성곱을 실행한다. 도시된 바와 같이, 가중치 커널은 컨볼루션 레이어의 합성곱을 실행하기 위한 프로세싱 유닛 내에 하드와 이어된 형태로 구현될 수 있다. 이 경우, 가중치 커널에 대해 비트 양자화를 적용하여 가중치 커널의 요소값들 (w1_K, w2_K, ..., w27_K)의 비트 수를 감소시킨 후, 가중치 커널의 비트 수에 따라 캐쉬의 크기를 결정할 수 있다. 또한, 프로세싱 유닛 내에 와이어로 구현된 가중치 커널의 요소값들과 입력 활성화 맵(또는 특징 맵)의 요소 값들을 입력 받아 곱셈 및/또는 덧셈 연산을 실행하는 프로세싱 유닛 내에 배열되는 곱셈기 또는 가산기의 비트 크기도 비트 양자화의 결과에 따른 가중치 커널 요소 값의 비트 수에 맞추어 설계될 수 있 다.일 실시예에 따르면, 입력 활성화맵 캐쉬는, 다채널(예를 들어, 3개의 RGB 채널)로 구성된 입력 데이터 상의 일부분(가중치 커널의 크기에 대응되는 부분)을 입력 받아 저장할 수 있다. 가중치 커널은 입력 데이터 상을 순회하며, 입력 활성화맵 캐쉬는 해당 가중치 커널의 위치에 대응되는 입력 데이터의 일부분을 순차 적으로 입력 받아 저장할 수 있다. 입력 활성화맵 캐쉬에 저장된 입력 데이터의 일부분(x1, x2, ..., x27)과 프로세싱 유닛 내에 와이어로 구현된 가중치 커널의 요소값들(w1_K, w2_K, ... w27_K)은 각각 대응되 는 곱셈기에 입력되어 다중 곱이 실행된다. 이 때, 프로세싱 유닛 내에 와이어로 구현된 가중치 커널 요 소값들(w1_K, w2_K, ..., w9_K)과 입력 활성화맵 캐쉬에 저장된 입력 데이터의 제1채널의 부분(x1, x2, ..., x9)은 제1 합성곱 처리 유닛로 입력된다. 또한, 프로세싱 유닛 내에 와이어로 구현된 가중치 커널 요소값들(w10_K, w11_K, ..., w18_K)과 입력 활성화맵 캐쉬에 저장된 입력 데이터의 제2채널의 부분(x10, x11, ..., x18)은 제2 합성곱 처리 유닛로 입력된다. 또한, 가중치 커널 캐쉬의 가중치 커널 요소값들 (w19_K, w20_K, ..., w27_K)과 입력 활성화맵 캐쉬에 저장된 입력 데이터의 제3채널의 부분(x19, x20, ..., x27)은 제3 합성곱 처리 유닛로 입력된다. 제1 합성곱 처리 유닛, 제2 합성곱 처리 유닛 및 제3 합성곱 처리 유닛 각각에 의해 계산된 합성곱의 결과값은 트리 가산기에 의해 합산되어 출력 활성화 맵 캐쉬에 입력될 수 있다. 이상 설명한 바와 같이, 가중치 커널의 요소값들이 프로세싱 유닛 내에 하드와이어된 형태로 구현될 경우, 본 개시에 따른 비트 양자화에 의해 가중치 커널 요소값들의 비트 수를 감소할 수 있으며, 이에 따라 프 로세싱 유닛의 내부에 구현된 와이어의 수와 프로세싱 유닛의 곱셈기와 가산기의 크기를 감소할 수 있는 효과가 있다. 또한, 프로세싱 유닛의 크기가 감소함에 따라, 프로세싱 유닛의 전력 소비량도 감소될 수 있다. 도 22는 본 개시의 일 실시예에 따른 인공신경망에 대해 비트 양자화를 실행하는 시스템의 구성을 도시하는 도 면이다. 도시된 바와 같이, 시스템은, 파라미터 선택 모듈, 비트 양자화 모듈 및 정확도 판단 모듈 을 포함할 수 있다. 파라미터 선택 모듈은, 입력되는 인공신경망의 구성 정보를 분석할 수 있다. 인공신경망의 구성 정보에는, 인공신경망에 포함되는 레이어의 수, 각 레이어의 기능과 역할, 각 레이어의 입출 력 데이터에 관한 정보, 각 레이어에 의해 실행되는 곱셈과 덧셈의 종류와 수, 각 레이어에 의해 실행되는 활 성화 함수의 종류, 각 레이어가 입력되는 가중치 커널의 종류와 구성, 각 레이어에 속한 가중치 커널의 크기와 개수, 출력 특징맵의 크기, 가중치 커널의 초기값(예를 들어, 실수로 설정된 가중치 커널의 요소값들) 등이 포 함될 수 있으나, 이에 한정되는 것은 아니다. 인공신경망의 구성 정보는, 인공신경망의 종류(예를 들어, 콘볼 루션 인공신경망, 순환 인공신경망, 다층 퍼셉트론 등)에 따라 다양한 구성요소들의 정보를 포함할 수 있다. 파라미터 선택 모듈은, 입력된 인공신경망 구성 정보를 참조하여, 해당 인공신경망에서 적어도 하나의 양 자화할 파라미터 또는 파라미터 그룹을 선택할 수 있다. 인공신경망에서 어떻게 하나의 파라미터(또는 데이터) 또는 파라미터 그룹을 선택할지는, 인공신경망의 전체 성능 또는 연산량(또는 하드웨어 구현시 요구되는 자원량)에 선택될 파라미터 미치는 영향에 따라 결정될 수 있다. 파라미터의 선택은, 하나의 가중치, 하나의 특징맵 및 활성화 맵, 하나의 가중치 커널, 한 레이어 속한 모든 가중치, 한 레이어에 속한 모든 특징맵 또는 활성화 맵 중의 어느 하나의 선택으로 실행될 수 있다. 일 실시예에서, 앞서 설명한 도 4내지 도 10을 참조하여 설명한 콘볼루션 인공신경망(CNN)의 경우에는, 콘 볼루션 레이어 및/또는 완전 연결 레이어가 CNN의 전체 성능 또는 연산량 등에 미치는 영향이 크기 때문에, 이들 레이어(420, 440) 중 적어도 하나의 레이어의 가중치 커널 또는 특징맵/활성화 맵이 하나의 양자화할 파라미터로 선택될 수 있다. 일 실시예에서, 인공신경망에 포함된 복수의 레이어 중 적어도 하나를 선택하여 그 레이어 내의 전체 가중치 커 널 또는 그 레이어의 전체 활성화맵 데이터를 하나의 파라미터 그룹으로 설정할 수 있는데, 그 선택 방법은, 선 택된 레이어가 인공신경망의 전체 성능 또는 연산량 등에 미치는 영향에 따라 결정될 수 있으나, 이에 한정되는 것은 아니고, 다양한 방법들 중에 하나를 포함할 수 있다. 예를 들어, 인공신경망에 포함된 복수의 레이어 중 적어도 하나의 레이어의 선택은, (i) 인공신경망을 구성하는 복수의 레이어의 배열 순서에 따라 입력 데이터가 수신되는 제1 레이어부터 이후 레이어로 순차적으로 선택하는 방법, (ii) 인공신경망을 구성하는 복수의 레이어 의 배열 순서에 따라 최종 출력 데이터가 생성되는 가장 마지막 레이어부터 이전 레이어로 순차적으로 선택하는방법, (iii) 인공신경망을 구성하는 복수의 레이어 중에서 가장 연산량이 높은 레이어부터 선택하는 방법, 또는 (iv) 인공신경망을 구성하는 복수의 레이어 중에서 가장 연산량이 작은 레이어부터 선택하는 방법에 따라 실행 될 수도 있다. 파라미터 선택 모듈에 의해 인공신경망의 양자화 할 데이터 대상의 선택이 완료되면, 선택된 데이터의 정 보는 비트 양자화 모듈에 입력된다. 비트 양자 화 모듈은, 입력된 선택된 파라미터의 정보를 참조 하여, 해당 파라미터에 대한 데이터 표현 크기를 비트 단위로 감소시킬 수 있다. 선택된 파라미터의 연산에 요 구되는 자원은, 그 선택된 파라미터를 저장하기 위한 메모리, 또는 그 선택된 파라미터를 전송하기 위한 데이터 경로(data path) 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 비트 양자화 모듈이, 선택된 파라미터의 데이터 크기를 비트 단위로 감소시키는 경우, 도 4 내지 도 13을 참조하여 설명한 가중치 커널 양자화 및/또는 활성화 맵 양자화가 실행될 수 있다. 비트 양자화 모듈이, 선택된 파라미터에 대한 비트 양자화를 완료하면, 비트 양자화된 인공신경망의 정보 를 정확도 판단 모듈로 전송한다. 정확도 판단 모듈은, 시스템에 입력된 인공신경망의 구성 정보에 비트 양자화된 인공신경망의 정보를 반영할 수 있다. 비트 양자화 모듈은, 비트 양자화된 인공신 경망의 정보가 반영된 인공신경망의 구성 정보에 기초하여, 인공신경망의 정확도가 사전 결정된 목표값 이상인 지 여부를 결정할 수 있다. 예를 들어, 정확도 판단 모듈은, 인공신경망에서 선택된 파라미터의 데이터 를 표현하는 크기를 비트 단위로 감소한 후, 해당 인공신경망의 출력 결과(예를 들어, 인공신경망의 추론 결과)의 정확도가 사전에 결정된 목표값 이상이라면, 추가의 비트 양자화를 실행하여도 인공신경망의 전체 성능 을 유지할 수 있다고 예측할 수 있다. 따라서, 정확도 판단 모듈이 인공신경망의 정확도가 목표값 이상이라고 결정하는 경우, 파라미터 선택 모 듈에 제어 신호를 전송하여, 파라미터 선택 모듈이 인공신경망에 포함된 다른 하나의 파라미터 또 는 파라미터 그룹을 선택하도록 한다. 여기서, 인공신경망에서 하나의 파라미터를 선택하는 방법은, (i) 인공 신경망을 구성하는 각 파라미터 또는 파라미터 그룹의 배열 순서에 따라, 이전 선택된 파라미터의 다음 파라미 터를 순차적으로 선택하는 방법(\"순방향 비트 양자화\", forward bit quantization), (ii) 인공신경망을 구성하 는 파라미터 또는 파라미터 그룹의 배열 순서에 따라, 이전 선택된 파라미터의 이전 파라미터를 역방향으로 선 택하는 방법(\"역방향 비트 양자화\", backward bit quantization), (iii) 인공신경망을 구성하는 복수의 파라미 터 중에서 연산량의 순서에 따라, 이전 선택된 파라미터 다음으로 연산량이 많은 파라미터를 선택하는 방법(\"고 연산량 비트 양자화\", high computational cost bit quantization), 또는 (iv) 인공신경망을 구성하는 복수의 파라미터 중에서 연산량의 순서에 따라, 이전 선택된 파라미터 다음으로 연산량이 작은 파라미터를 선택하는 방 법(\"저 연산량 비트 양자화\", low computational cost bit quantization)에 따라 실행될 수도 있다. 다른 한편, 정확도 판단 모듈이, 인공신경망의 정확도가 목표치 이상이 아니라고 판단하면, 현재 선택된 파라미터에 대해 실행된 비트 양자화에 의해 인공신경망의 정확도가 저하되었다고 판단할 수 있다. 따라서, 이 경우, 바로 이전에 실행된 비트 양자화에 의해 결정된 비트 수를 최종 비트 수로 결정할 수 있다. 일 실시예에 서, 인공신경망의 정확도는, 인공신경망이 주어진 문제의 해결 방법(예를 들어, 입력 데이터인 이미지에 포함된 물체의 인식)을 학습 후에, 추론 단계에서 해당 문제의 정답을 제시할 확률을 의미할 수 있다. 또한, 이상 설 명한 비트 양자화 방법에서 사용되는 목표치는, 인공신경망의 비트 양자화 후에 유지해야할 최소한의 정확도로 나타낼 수 있다. 예를 들어, 임계치가 90퍼센트라고 가정하면, 비트 양자화에 의해 선택된 레이어의 파라미터 를 저장하기 위한 메모리 크기를 비트 단위로 감소시킨 후에도, 해당 인공신경망의 정확도가 90퍼센트 이상이라 면, 추가의 비트 양자화를 실행할 수 있다. 예를 들어, 첫 번째 비트 양자화를 실행한 후에, 인공신경망의 정 확도가 94퍼센트로 측정되었다면, 추가의 비트 양자화를 실행할 수 있다. 두 번째 비트 양자화의 실행 후에, 인공신경망의 정확도가 88퍼센트로 측정되었다면, 현재 실행된 비트 양자화의 결과를 무시하고, 첫번째 비트 양 자화에 의해 결정된 데이터 표현 비트 수를 최종의 비트 양자화 결과로 확정할 수 있다. 일 실시예에서, 연산량 비트 양자화(computational cost bit quantization) 방식에 따라, 연산량을 기준으로 비트 양자화를 실행할 파라미터 또는 파라미터 그룹을 선택하는 경우, 각 파라미터의 연산량은 다음과 같이 결 정될 수 있다. 즉, 인공 신경망의 특정 연산에서 n 비트와 m 비트의 합산을 실행하는 경우, 해당 연산의 연산 량은 (n+m)/2로 계산한다. 또한, 인공 신경망의 특정 연산에서 n 비트와 m 비트의 곱셈을 실행하는 경우, 해당 연산의 연산량은 n x m으로 계산할 수 있다. 따라서, 인공 신경망의 특정 파라미터에 대한 연산량은, 그 파라 미터에 대해 실행하는 모든 덧셈과 곱셈의 연산량들을 합산한 결과가 될 수 있다. 이러한 비트 양자화에서 특정 파라미터 또는 파라미터 그룹을 선택하는 방법은, 각 레이어에 속한 가중치 데이 터 또는 특징맵 및 활성화맵 데이터, 또는 하나의 레이어에 속한 각각의 가중치 커널, 또는 하나의 가중치 커널 내에 각각의 가중치 데이터 들을 개별적인 파라미터 그룹으로 선택할 수 있다. 참고로, 본 개시의 실시예에 따른 도 22에 도시된 구성 요소들은 소프트웨어 또는 FPGA(Field Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)와 같은 하드웨어 구성 요소로 구현될 수 있 다. 그러나, '구성 요소들'은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니며, 각 구성 요소는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 구성 요소는 소프트웨어 구성 요소들, 객체지향 소프트웨어 구성 요소들, 클래스 구성 요소 들 및 태스크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로 그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테 이블들, 어레이들 및 변수들을 포함한다. 구성 요소들과 해당 구성 요소들 안에서 제공되는 기능은 더 작은 수의 구성 요소들로 결합되거나 추가적인 구 성 요소들로 더 분리될 수 있다. 본 개시의 실시예들은, 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함 하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판 독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령 어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전달 매체를 포함한다."}
{"patent_id": "10-2024-0074371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "본 명세서에서는 본 개시가 일부 실시예들과 관련하여 설명되었지만, 본 발명이 속하는 기술분야의 통상의 기술 자가 이해할 수 있는 본 개시의 범위를 벗어나지 않는 범위에서 다양한 변형 및 변경이 이루어질 수 있다는 점 을 알아야 할 것이다. 또한, 그러한 변형 및 변경은 본 명세서에 첨부된 특허청구의 범위 내에 속하는 것으로 생각되어야 한다."}
{"patent_id": "10-2024-0074371", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 실시예들은, 이하 설명하는 첨부 도면들을 참조하여 설명될 것이며, 여기서 유사한 참조 번호는 유사 한 요소들을 나타내지만, 이에 한정되지는 않는다. 도 1은 본 개시의 일 실시예에 따른 복수의 레이어와 복수의 레이어 가중치를 이용하여 입력 데이터에 대한 출 력 데이터를 획득하는 인공신경망의 예를 보여주는 도면이다. 도 2 내지 도 3은, 본 개시의 일 실시예에 따른 도 1에 도시된 인공신경망의 구체적인 구현예들을 설명하기 위 한 도면이다. 도 4는 본 개시의 일 실시예에 따른 복수의 레이어를 포함하는 인공신경망의 다른 예를 보여주는 도면이다. 도 5는 본 개시의 일 실시예에 따른 컨볼루션 레이어에서 입력 데이터와 합성곱 연산에 사용되는 가중치 커널을 나타내는 도면이다. 도 6은 본 개시의 일 실시예에 따른 입력 데이터에 대해 제1 가중치 커널을 사용하여 합성곱을 실행하여 제1 활 성화 맵을 생성하는 절차를 설명하는 도면이다. 도 7은 본 개시의 일 실시예에 따른 입력 데이터에 대해 제2 가중치 커널을 사용하여 합성곱을 실행하여 제2 활 성화 맵을 생성하는 절차를 설명하는 도면이다. 도8은 본 개시의 일 실시예에 따른 컨볼루션 레이어의 연산 과정을 행렬로 표현한 도면이다. 도 9는 본 개시의 일 실시예에 따른 완전 연결 레이어의 연산 과정을 행렬로 표현한 도면이다. 도 10은 본 개시의 일 실시예에 따른 콘볼루션 레이어의 비트 양자화 과정을 행렬로 표현한 도면이다. 도 11은 본 개시의 일 실시예에 따른 인공신경망의 비트 양자화 방법을 나타내는 순서도이다. 도 12는 본 개시의 다른 실시예에 따른 인공신경망의 비트 양자화 방법을 나타내는 순서도이다. 도 13은 본 개시의 또 다른 실시예에 따른 인공신경망의 비트 양자화 방법을 나타내는 순서도이다. 도 14는 본 개시의 일 실시예에 따른 인공신경망의 레이어 별 연산량의 예시를 나타내는 그래프이다. 도 15는 본 개시의 일 실시예에 따른 순방향 양자화(forward bit quantization) 방법에 의해 비트 양자화가 실 행된 인공신경망의 레이어 별 비트 수를 나타내는 그래프이다. 도 16은 본 개시의 일 실시예에 따른 역방향 양자화(backward bit quantization) 방법에 의해 비트 양자화가 실 행된 인공신경망의 레이어 별 비트 수를 나타내는 그래프이다. 도 17은 본 개시의 일 실시예에 따른 고 연산량 레이어 우선 양자화(high computational cost layer first bit quantization) 방법에 의해 비트 양자화가 실행된 인공신경망의 레이어 별 비트 수를 나타내는 그래프이다. 도 18은 본 개시의 일 실시예에 따른 저 연산량 레이어 우선 양자화(low computational cost layer first bit quantization) 방법에 의해 비트 양자화가 실행된 인공신경망의 레이어 별 비트 수를 나타내는 그래프이다. 도 19는 본 개시의 일 실시예에 따른 인공신경망의 하드웨어 구현 예를 도시하는 도면이다. 도 20은 본 개시의 다른 실시예에 따른 인공신경망의 하드웨어 구현 예를 도시하는 도면이다. 도 21은 본 개시의 또 다른 실시예에 따른 인공신경망의 하드웨어 구현 예를 도시하는 도면이다. 도 22은 본 개시의 일 실시예에 따른 인공신경망에 대해 비트 양자화를 실행하는 시스템의 구성을 도시하는 도 면이다."}
