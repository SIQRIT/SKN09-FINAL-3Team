{"patent_id": "10-2020-0113210", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0061258", "출원번호": "10-2020-0113210", "발명의 명칭": "기준 이미지 프레임의 동적 선택을 위한 시스템 및 방법", "출원인": "삼성전자주식회사", "발명자": "셰이크흐 라힘 하미드"}}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 기기의 적어도 하나의 이미지 센서를 이용하여, 한 장면(scene)에 대해, 제1노출 레벨에서의 복수의 짧은이미지 프레임들과, 상기 제1노출 레벨보다 긴 제2노출 레벨에서의 복수의 긴 이미지 프레임들을 포함하는 다수의 이미지 프레임들을 획득하는 단계;상기 다수의 이미지 프레임들을 이용하여 짧은 기준 이미지 프레임 및 긴 기준 이미지 프레임을 생성하는 단계;상기 전자 기기의 프로세서를 이용하여, 상기 짧은 기준 이미지 프레임 또는 상기 긴 기준 이미지 프레임을 기준 프레임으로서 선택하되, 상기 선택은 상기 긴 기준 이미지 프레임 내 포화된 모션(saturated motion)의 양및 상기 짧은 기준 이미지 프레임 내 섀도우(shadow) 영역의 크기에 기반하는 단계; 및상기 기준 프레임을 이용하여 상기 장면의 최종 이미지를 생성하는 단계를 포함하는 방법."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 짧은 기준 이미지 프레임 또는 상기 긴 기준 이미지 프레임을 상기 기준 프레임으로 선택하는 단계는,상기 긴 기준 이미지 프레임에 기반하여 채도(saturation) 맵을 생성하고;상기 채도 맵과 상기 긴 기준 이미지 프레임의 모션 맵을 곱하여 포화된(saturated) 모션 맵을 획득하고;상기 포화된 모션 맵을 이용하여 포화된 모션 사이즈 값을 결정하고;상기 포화된 모션 사이즈 값을 기결정된 문턱치와 비교함으로써, 상기 긴 기준 이미지 프레임 내 상기 포화된모션의 양을 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 짧은 기준 이미지 프레임 또는 상기 긴 기준 이미지 프레임을 상기 기준 프레임으로 선택하는 단계는,상기 짧은 기준 이미지 프레임의 휘도 값들의 중앙(median)값을 결정하고;상기 중앙값을 제1 기결정된 문턱치와 비교하여 상기 짧은 기준 이미지 프레임이 너무 어두운지를 판단하고;상기 짧은 기준 이미지 프레임의 ISO 값을 제2 기결정된 문턱치와 비교하여 상기 짧은 기준 이미지 프레임에 노이즈가 너무 많은지를 판단함으로써, 상기 짧은 기준 이미지 프레임 내 큰 섀도우 영역의 존재를 판단하는 단계를 포함하는 방법."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 다수의 이미지 프레임들을 이용하여 상기 짧은 기준 이미지 프레임 및 상기 긴 기준 이미지 프레임을 생성하는 단계는,상기 다수의 이미지 프레임들의 밝기 레벨들을 균등화시키는 단계;상기 다수의 이미지 프레임들을 디고스팅(deghosting)하는 단계;상기 복수의 짧은 이미지 프레임들을 블렌딩하여 블렌딩된 짧은 이미지 프레임을 생성하고, 상기 복수의 긴 이미지 프레임들을 블렌딩하여 블렌딩된 긴 이미지 프레임을 생성하는 단계;상기 블렌딩된 짧은 이미지 프레임 및 상기 블렌딩된 긴 이미지 프레임을 디고스팅하는 단계;상기 블렌딩된 짧은 이미지 프레임을 일차 이미지로서 이용해 상기 블렌딩된 짧은 이미지 프레임 및 상기 블렌딩된 긴 이미지 프레임을 블렌딩하여, 상기 짧은 기준 이미지 프레임을 획득하는 단계; 및공개특허 10-2021-0061258-3-상기 블렌딩된 긴 이미지 프레임을 일차 이미지로서 이용해 상기 블렌딩된 짧은 이미지 프레임 및 상기 블렌딩된 긴 이미지 프레임을 블렌딩하여, 상기 긴 기준 이미지 프레임을 획득하는 단계를 포함하는 방법."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 짧은 기준 이미지 프레임의 노출 레벨을 A 배 증가시킴으로써 상기 짧은 기준 이미지 프레임의 모션 노이즈를 줄이는 단계; 및상기 짧은 기준 이미지 프레임의 ISO 이득을 1/A 배 줄이는 단계를 더 포함하고,상기 A는 2의 멱수인 방법."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 기준 프레임을 이용하여 상기 장면의 상기 최종 이미지를 생성하는 단계는상기 최종 이미지에 톤(tone) 매핑 동작을 수행하는 단계를 포함하고, 상기 톤 매핑 동작은 상기 최종 이미지의휘도 압축(compression)을 포함하는 방법."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 다수의 이미지 프레임들은 로우(raw) 포맷으로 촬영되는 방법."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 다수의 이미지 프레임들은 YUV 포맷으로 촬영되고,상기 방법은상기 복수의 짧은 이미지 프레임들 및 상기 복수의 긴 이미지 프레임들을 이용한 히스토그램 매칭을 수행하여복수의 긴 합성 이미지 프레임들을 생성하는 단계; 및상기 복수의 긴 합성 이미지 프레임들과 상기 복수의 짧은 이미지 프레임들을 블렌딩하여 블렌딩된 짧은 이미지프레임을 생성하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 이미지 센서; 및상기 적어도 하나의 이미지 센서를 이용하여, 한 장면에 대해, 제1노출 레벨에서의 복수의 짧은 이미지 프레임들과, 상기 제1노출 레벨보다 긴 제2노출 레벨에서의 복수의 긴 이미지 프레임들을 포함하는 다수의 이미지 프레임들을 획득하고;상기 다수의 이미지 프레임들을 이용하여 짧은 기준 이미지 프레임 및 긴 기준 이미지 프레임을 생성하고;상기 짧은 기준 이미지 프레임 또는 상기 긴 기준 이미지 프레임을 기준 프레임으로서 선택하되, 상기 선택은상기 긴 기준 이미지 프레임 내 포화된 모션의 양 및 상기 짧은 기준 이미지 프레임 내 섀도우 영역의 크기에기반하고;상기 기준 프레임을 이용하여 상기 장면의 최종 이미지를 생성하도록 구성된 적어도 하나의 프로세서를 포함하는 전자 기기."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 짧은 기준 이미지 프레임 또는 상기 긴 기준 이미지 프레임을 상기 기준 프레임으로 선택하기 위해, 상기적어도 하나의 프로세서는 상기 긴 기준 이미지 프레임 내 상기 포화된 모션의 양을 결정하고;상기 긴 기준 이미지 프레임 내 상기 포화된 모션의 양을 결정하기 위해, 상기 적어도 하나의 프로세서는공개특허 10-2021-0061258-4-상기 긴 기준 이미지 프레임에 기반하여 채도 맵을 생성하고;상기 채도 맵과 상기 긴 기준 이미지 프레임의 모션 맵을 곱하여 포화된 모션 맵을 획득하고;상기 포화된 모션 맵을 이용하여 포화된 모션 사이즈 값을 결정하고;상기 포화된 모션 사이즈 값을 기결정된 문턱치와 비교하도록 구성되는 전자 기기."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 짧은 기준 이미지 프레임 또는 상기 긴 기준 이미지 프레임을 상기 기준 프레임으로 선택하기 위해, 상기적어도 하나의 프로세서는 상기 짧은 기준 이미지 프레임 내 큰 섀도우 영역의 존재를 판단하고;상기 짧은 기준 이미지 프레임 내 상기 큰 섀도우 영역의 존재를 판단하기 위해, 상기 적어도 하나의 프로세서는상기 짧은 기준 이미지 프레임의 휘도 값들의 중앙값을 결정하고;상기 중앙값을 제1 기결정된 문턱치와 비교하여 상기 짧은 기준 이미지 프레임이 너무 어두운지를 판단하고;상기 짧은 기준 이미지 프레임의 ISO 값을 제2 기결정된 문턱치와 비교하여 상기 짧은 기준 이미지 프레임에 노이즈가 너무 많은지를 판단하도록 구성되는 전자 기기."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 다수의 이미지 프레임들을 이용하여 상기 짧은 기준 이미지 프레임 및 상기 긴 기준 이미지 프레임을 생성하기 위해, 상기 적어도 하나의 프로세서는,상기 다수의 이미지 프레임들의 밝기 레벨들을 균등화시키고;상기 다수의 이미지 프레임들을 디고스팅하고;상기 복수의 짧은 이미지 프레임들을 블렌딩하여 블렌딩된 짧은 이미지 프레임을 생성하고, 상기 복수의 긴 이미지 프레임들을 블렌딩하여 블렌딩된 긴 이미지 프레임을 생성하고;상기 블렌딩된 짧은 이미지 프레임 및 상기 블렌딩된 긴 이미지 프레임을 디고스팅하고;상기 블렌딩된 짧은 이미지 프레임을 일차 이미지로서 이용해 상기 블렌딩된 짧은 이미지 프레임 및 상기 블렌딩된 긴 이미지 프레임을 블렌딩하여, 상기 짧은 기준 이미지 프레임을 획득하고;상기 블렌딩된 긴 이미지 프레임을 일차 이미지로서 이용해 상기 블렌딩된 짧은 이미지 프레임 및 상기 블렌딩된 긴 이미지 프레임을 블렌딩하여, 상기 긴 기준 이미지 프레임을 획득하도록 구성되는 전자 기기."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서, 상기 적어도 하나의 프로세서는상기 짧은 기준 이미지 프레임의 노출 레벨을 A 배 증가시킴으로써 상기 짧은 기준 이미지 프레임의 모션 노이즈를 줄이고;상기 짧은 기준 이미지 프레임의 ISO 이득을 1/A 배 줄이도록 구성되고,상기 A는 2의 멱수인 전자 기기."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 기준 프레임을 이용하여 상기 장면의 상기 최종 이미지를 생성하기 위해, 상기 프로세서는 상기 최종 이미지에 대해 톤 매핑 동작을 수행하도록 구성되고,상기 톤 매핑 동작은 상기 최종 이미지의 휘도 압축을 포함하는 전자 기기.공개특허 10-2021-0061258-5-청구항 15 제9항에 있어서, 상기 다수의 이미지 프레임들은 로우 포맷의 이미지 프레임들을 포함하는 전자 기기."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 다수의 이미지 프레임들은 YUV 포맷의 이미지 프레임들을 포함하고;상기 적어도 하나의 프로세서는,상기 복수의 짧은 이미지 프레임들 및 상기 복수의 긴 이미지 프레임들을 이용한 히스토그램 매칭을 수행하여복수의 긴 합성 이미지 프레임들을 생성하고;상기 복수의 긴 합성 이미지 프레임들과 상기 복수의 짧은 이미지 프레임들을 블렌딩하여 블렌딩된 짧은 이미지프레임을 생성하도록 더 구성되는 전자 기기."}
{"patent_id": "10-2020-0113210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1항 내지 제8항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "방법은 전자 기기의 적어도 하나의 이미지 센서를 이용하여 어떤 장면에 대한 다수의 이미지 프레임들을 획득하 는 단계를 포함한다. 다수의 이미지 프레임들은 제1노출 레벨에서의 복수의 짧은 이미지 프레임들과, 상기 제1노 출 레벨보다 긴 제2노출 레벨에서의 복수의 긴 이미지 프레임들을 포함한다. 이 방법은 다수의 이미지 프레임들 을 이용하여 짧은 기준 이미지 프레임 및 긴 기준 이미지 프레임을 생성하는 단계를 또한 포함한다. 이 방법은 전자 기기의 프로세서를 사용하여, 짧은 기준 이미지 프레임 또는 긴 기준 이미지 프레임을 기준 프레임으로서 선택하는 단계를 더 포함하며, 그 선택은 긴 이미지 프레임에서의 포화된 모션(saturated motion)의 양 및 짧은 이미지 프레임에서의 섀도우(shadow) 영역의 크기에 기반한다. 또한, 이 방법은 기준 프레임을 사용하여 장면 (scene)의 최종 이미지를 생성하는 단계를 포함한다."}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 일반적으로 이미지 촬영 시스템에 관한 것이다. 보다 구체적으로, 본 개시는 참조 이미지 프레임의 동적 선택을 위한 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스마트 폰들 및 태블릿 컴퓨터들과 같은 많은 모바일 장치들은 정지 영상 및 비디오 영상을 촬영하는데 사용될 수 있는 카메라들을 포함한다. 모바일 전자 기기들 상의 카메라들은 편리한 반면에, 통상적으로 많은 단점들을 가진다. 예를 들어, 모바일 전자 기기들 상의 카메라들은 모션과 높은 채도(saturation)를 가진 이미지들을 촬 영할 때와 같이, 보통 고스트 아티팩트들(ghost artifacts)이 있거나 선명도가 제한된 이미지들을 촬영한다. 이 는 통상적으로, 카메라들 내 이미지 센서들이 제한된 동적 범위를 가지기 때문이다. 어떤 장면(scene)의 다수의 이미지 프레임들을 촬영한 후, 그 이미지 프레임들 중 “가장 좋은” 부분들을 결합하여 블렌딩(blended) 이미 지를 생성하는 것이 가능하다. 그러나, 서로 다른 노출을 가진 이미지 프레임들의 집합에서 블렌딩 이미지를 생 성하는 것은 어려운 절차이며, 특히 동적 장면들에 있어서 더욱 그러하다."}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 참조 이미지 프레임의 동적 선택을 위한 시스템 및 방법을 제공한다."}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제1실시예의 방법은 전자 기기의 적어도 하나의 이미지 센서를 이용하여 어떤 장면에 대한 다수의 이미지 프레 임들을 획득하는 단계를 포함한다. 상기 다수의 이미지 프레임들은 제1노출 레벨에서의 복수의 짧은 이미지 프 레임들과, 제1노출 레벨보다 긴 제2노출 레벨에서의 복수의 긴 이미지 프레임들을 포함한다. 이 방법은 상기 다 수의 이미지 프레임들을 이용하여 짧은 기준 이미지 프레임 및 긴 기준 이미지 프레임을 생성하는 단계를 또한 포함한다. 이 방법은 전자 기기의 프로세서를 이용하여, 상기 짧은 기준 이미지 프레임 또는 상기 긴 기준 이미 지 프레임을 기준 프레임으로서 선택하는 단계를 더 포함하며, 상기 선택은 상기 긴 이미지 프레임에서의 포화 된 모션(saturated motion)의 양 및 상기 짧은 이미지 프레임에서의 섀도우(shadow) 영역의 크기에 기반한다. 또한, 이 방법은 상기 기준 프레임을 사용하여 장면(scene)의 최종 이미지를 생성하는 단계를 포함한다.제2실시예에서, 전자 기기는 적어도 하나의 이미지 센서 및 적어도 하나의 프로세싱 기기를 포함한다. 상기 적 어도 하나의 프로세싱 기기는 상기 적어도 하나의 이미지 센서를 이용하여 어떤 장면에 대한 다수의 이미지 프 레임들을 획득하도록 구성된다. 상기 다수의 이미지 프레임들은 제1노출 레벨에서의 복수의 짧은 이미지 프레임 들과, 제1노출 레벨보다 긴 제2노출 레벨에서의 복수의 긴 이미지 프레임들을 포함한다. 상기 적어도 하나의 프 로세싱 기기는 또한, 상기 다수의 이미지 프레임들을 이용하여 짧은 기준 이미지 프레임 및 긴 기준 이미지 프 레임을 생성하도록 구성된다. 상기 적어도 하나의 프로세싱 소자는 상기 짧은 기준 이미지 프레임 또는 상기 긴 기준 이미지 프레임을 기준 프레임으로서 선택하도록 더 구성되며, 상기 선택은 상기 긴 이미지 프레임에서의 포화된 모션의 양 및 상기 짧은 이미지 프레임에서의 섀도우 영역의 크기에 기반한다. 또한, 상기 적어도 하나 의 프로세싱 기기는 상기 기준 프레임을 사용하여 장면(scene)의 최종 이미지를 생성하도록 구성된다. 제3실시예의 비일시적(non-transitory) 기계 판독가능 매체는, 실행 시 전자 기기의 적어도 한 프로세서가 상기 전자 기기의 적어도 하나의 이미지 센서를 사용하여 촬영되는 어떤 장면의 여러 이미지 프레임들을 획득하도록 하는 명령어들을 포함한다. 상기 다수의 이미지 프레임들은 제1노출 레벨에서의 복수의 짧은 이미지 프레임들과, 제1노출 레벨보다 긴 제2노출 레벨에서의 복수의 긴 이미지 프레임들을 포함한다. 상기 매체는 실 행 시 상기 적어도 하나의 프로세서가, 상기 다수의 이미지 프레임들을 이용하여 짧은 기준 이미지 프레임 및 긴 기준 이미지 프레임을 생성하도록 하는 명령어들을 또한 포함한다. 상기 매체는 실행 시 상기 적어도 하나의 프로세서가 상기 짧은 기준 이미지 프레임 또는 상기 긴 기준 이미지 프레임을 기준 프레임으로서 선택하도록 하는 명령어들을 더 포함하며, 상기 선택은 상기 긴 이미지 프레임에서의 포화된 모션의 양 및 상기 짧은 이미 지 프레임에서의 섀도우 영역의 크기에 기반한다. 또한, 상기 매체는 실행 시 상기 적어도 하나의 프로세서가 상기 기준 프레임을 사용하여 상기 장면의 최종 이미지를 생성하도록 하는 명령어들을 포함한다. 다른 기술적 특징들은 이하의 도면, 상세한 설명 및 청구범위로부터 당업자에게 쉽게 자명해 보일 것이다. 이하의 상세한 설명을 수행하기 전에, 이 특허 문서 전체에 걸쳐 사용된 소정 단어들과 어구들의 정의를 설명하 는 것이 바람직하다. \"전송한다\", \"수신한다\", 그리고 \"통신한다\" 라는 용어들뿐 아니라 그 파생어들은 직간접 적 통신 모두를 포함한다. \"포함하다\" 및 \"구비한다\"는 용어들 및 그 파생어들은 제한 없는 포함을 의미한다. \"또는\"이라는 말은 '및/또는'을 의미하는 포괄적인 말이다 \"~와 관련된다\" 및 그 파생어들은 포함한다, ~ 안에 포함된다, ~와 상호연결한다, 내포한다, ~안에 내포된다, ~에/와 연결한다, ~에/와 결합한다, ~와 통신할 수 있 다, ~와 협력한다, 개재한다, 나란히 놓는다, ~에 근사하다, ~에 속박된다, 가진다, ~의 특성을 가진다, ~와 관 계를 가진다는 등의 의미이다. 또한, 이하에 기술되는 다양한 기능들은 하나 이상의 컴퓨터 프로그램들에 의해 구현되거나 지원될 수 있으며, 그 프로그램들 각각은 컴퓨터 판독가능 프로그램 코드로 구성되고 컴퓨터 판독가능 매체에서 실시된다. \"애플리 케이션\" 및 \"프로그램\"이라는 용어는 하나 이상의 컴퓨터 프로그램, 소프트웨어 성분, 명령어 집합, 절차, 함수, 객체, 클래스, 인스턴스, 관련 데이터, 또는 적합한 컴퓨터 판독가능 프로그램 코드의 구현에 적합한 그 들의 일부를 일컫는다. \"컴퓨터 판독가능 프로그램 코드\"라는 말은 소스 코드, 객체 코드, 및 실행 코드를 포함 하는 모든 타입의 컴퓨터 코드를 포함한다. \"컴퓨터 판독가능 매체\"라는 말은 ROM(read only memory), RAM(random access memory), 하드 디스크 드라이브, 컴팩트 디스크(CD), 디지털 비디오 디스크(DVD), 또는 어 떤 다른 유형의 메모리와 같이, 컴퓨터에 의해 액세스될 수 있는 모든 유형의 매체를 포함한다. \"비일시적\" 컴 퓨터 판독가능 매체는 일시적인 전기 또는 기타 신호들을 전송하는 유선, 무선, 광학, 또는 기타 통신 링크들을 제외한다. 비일시적 컴퓨터 판독가능 매체는 데이터가 영구적으로 저장될 수 있는 매체, 및 재기록가능 광학 디 스크나 삭제가능 메모리 장치와 같이 데이터가 저장되고 나중에 덮어 쓰일 수 있는 매체를 포함한다. 여기 사용된 바와 같이, 어떤 특성(숫자, 기능, 동작, 또는 부품과 같은 구성요소 등)을 “가진다”, “가질 수 있다”, “포함한다”, 또는 “포함할 수 있다는 용어들과 문구들은 그 특징의 존재를 나타내는 것으로, 다른 특징들의 존재를 배제하는 것이 아니다. 또한, 여기 사용된 바와 같은 문구들인 “A 또는 B”, “A 및/또는 B 중 적어도 하나”, 또는 “A 및/또는 B의 하나 이상”은 A 및 B의 모든 가능한 조합들을 포함할 수 있다. 예를 들어, “A 또는 B”, “A 및 B 중 적어도 하나”, 그리고 “A 또는 B 중 적어도 하나”는 적어도 하나의 A 를 포함하거나, 적어도 하나의 B를 포함하거나, 적어도 하나의 A 및 적어도 하나의 B를 포함하는 것 모 두를 나타낼 수 있다. 또한, 여기 사용된 바와 같은 용어들인 “제1” 및 “제2”는 중요도와 무관하게 다양한 구성요소들을 변경시킬 수 있고, 그 구성요소들을 한정하지 않는다. 그러한 용어들은 단지 하나의 구성요소를 다른 구성요소와 구별하기 위해 사용된다. 예를 들어, 제1사용자 장치와 제2사용자 장치는 그 장치들의 순서나 중요도와 관계없이 서로 다른 사용자 장치들을 나타낼 수 있다. 본 개시의 범위에서 벗어나지 않고 제1구성요소가 제2구성요소로 표기될 수 있고, 그 반대의 경우도 있을 수 있다. 어떤 구성요소(가령, 제1구성요소)가 (동작적인 면에서나 통신적인 면에서) 다른 구성요소(가령, 제2구성요소) 와 “결합되거나” “연결된다”고 언급되면, 그것은 다른 구성요소에 직접적으로, 또는 제3의 구성요소를 통해 결합되거나 연결되는 것일 수 있다. 이와 달리, 어떤 구성요소(가령, 제1구성요소)가 다른 구성요소(가령, 제2 구성요소)와 “직접적으로 결합되거나” “직접적으로 연결된다”고 언급되면, 다른 구성요소(가령, 제3의 구성 요소)가 그 구성요소 및 다른 구성요소 사이에 개재되지 않는다. 여기 사용된 바와 같이, \"~하는 것으로 구성(또는 설정)된다\"라는 문구는 상황에 따라 \"~에 적합하다\", \"~하는 기능을 가진다\", \"~ 하도록 설계된다\", \"~ 하도록 적응된다\", \"~ 하는 것으로 만들어진다\", \"~할 수 있다\"와 같 은 다른 말들과 혼용하여 사용될 수 있다. “~하는 것으로 구성(설정)된다”는 말이 반드시 하드웨어 적으로 특 정하게 설계된다는 것을 의미하는 것은 아니다. 오히려, “~ 하는 것으로 구성된다”는 말은 어떤 장치가 다른 장치나 부품들과 함께 동작을 수행할 수 있다는 것을 의미할 수 있다. 예를 들어, “A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서”라는 말은 메모리 소자에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함 으로써 동작들을 수행할 수 있는 범용 프로세서(가령, CPU 또는 애플리케이션 프로세서), 또는 상기 동작들을 수행하기 위한 전용 프로세서(내장 프로세서 등)를 의미한다. 여기 사용된 용어들과 문구들은 다만 일부 실시예들을 설명하기 위해 제공된 것이며, 본 개시의 다른 실시예들 의 범위를 제한하지 않는다. 본 개시에서, 단수의 표현은 문맥상 명백하게 예외가 있지 않은 한, 복수의 표현을 포함한다. 여기에 사용되는 모든 용어들 및 문구들(기술 및/또는 과학 용어들과 문구들을 포함함)은 본 개시의 실시예들이 속하는 기술 분야의 숙련자들에게 전형적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사 용되는 사전들에서 정의되는 것들과 같은 용어들과 문구들은 관련 기술과 관련되어 그들의 의미와 일치되는 의 미를 가진 것으로 해석되어야 하며, 여기에서 명백히 그렇게 정의되는 것이 아니라면 이상적이거나 과도하게 형 식적인 의미로 해석되어서는 안될 것이다. 일부의 경우, 여기에서 정의되는 용어들과 문구들은 본 개시의 실시 예들을 배제하는 것으로 해석될 수 있다. 본 개시의 실시예들에 따른 “전자 기기”의 예들에는 스마트 폰, 태블릿 PC(Personal Computer), 모바일 폰, 비디오 폰, 전자북 리더, 데스크탑 PC, 랩탑 컴퓨터, 넷북 컴퓨터, 워크스테이션, PDA(Personal Digital Assistant), 휴대형 멀티미디어 재생기(PMP), MP3 플레이어, 모바일 의료 장치, 카메라, 또는 웨어러블 (wearable) 장치(스마트 안경, HMD(Head-Mounted Device), 전자 의복, 전자 팔찌, 전자 목걸이, 전자 액세서리, 전자 문신, 스마트 미러, 또는 스마트 와치 등) 중 적어도 하나가 포함될 수 있다. 전자 기기의 다른 예들에는 스마트 가전 기기가 포함된다. 스마트 가전 기기의 예들로는, 텔레비전, 디지털 비디오 디스크(DVD) 플레이어, 오디오 플레이어, 냉장고, 에어컨, 청소기, 오븐, 마이크로웨이브 오븐, 세탁기, 드라이어, 공기 청 정기, 세톱 박스, 홈 오토메이션 제어 패널, 보안 제어 패널, TV 박스(삼성 HomeSync, 애플 TV, 또는 구글 TV 등), 스마트 스피커 또는 통합 디지털 보조장치(삼성 갤럭시 홈, 애플 홈팟(homepod), 또는 아마존 에코 등), 게임 콘솔(XBOX 또는 플레이 스테이션, 또는 닌텐도 등), 전자 사전, 전자 키, 캠코더, 또는 전자 사진 프레임 중 적어도 하나가 포함될 수 있다. 전자 기기의 또 다른 예들에는, 다양한 의료 기기들(가령, 다양한 휴대형 의 료 측정기기(혈당 측정기, 심박 측정기, 또는 체온 측정기, MRA(magnetic resource angiography) 장치, MRI(magnetic resource imaging) 장치, CT(computed tomography) 장치, 영상 기기, 또는 초음파 기기 등), 네 비게이션 기기, GPS(global positioning system) 수신기, EDR(event data recorder), FDR(flight data recorder), 차량의 인포테인먼트(infotainment) 장치, 항해 전자 기기(항해 네비게이션 장치나 자이로 나침반 등), 항공 전자 기기, 보안 기기, 차량 관련 헤드 유닛, 산업용 혹은 가정용 로봇, ATM(automatic teller's machine), POS(point of sales) 기기들 또는 사물 인터넷(IoT) 장치들(전구, 다양한 센서들, 전기 또는 자기 미터, 스프링클러, 화재 경보기, 온도계, 가로등, 토스터, 피트니스 장비, 온수 탱크, 히터, 또는 보일러 등) 중 적어도 하나가 포함될 수 있다. 전자 기기의 다른 예들로는 가구나 빌딩/구조물, 전자 보드, 전자 서명 수신 장치, 프로젝터, 또는 다양한 계측 기기들(물, 전기, 가스 또는 전자기파 계측 기기들 등) 중 적어도 하나가 포 함된다. 본 개시의 다양한 실시예들에 따르면, 전자 기기는 위에서 나열한 장치들 중 하나이거나 그들의 한 조 합일 수 있다는 것을 알아야 한다. 본 개시의 일부 실시예들에 따르면, 전자 기기는 플렉시블(flexible) 전자 기기일 수 있다. 여기 개시되는 전자 기기는 위에서 나열한 장치들에 국한되지 않으며, 기술 발전에 따른 새로 운 전자 기기들을 포함할 수 있다. 이하의 설명에서는, 본 개시의 다양한 실시예들에 따른 전자 기기들이, 첨부된 도면들을 참조하여 기술될 것이다. 여기서 사용되는 “사용자(user)”라는 용어는 전자 기기를 사용하는 사람이나 다른 장치(인공지능 전자 기기 등)를 나타낼 수 있다. 다른 소정 단어들 및 어구들에 대한 정의가 이 특허 문서 전체에 걸쳐 제공될 수 있다. 당업자는 대부분의 경우 들은 아니어도 많은 경우, 그러한 정의들이 그렇게 정의된 단어들 및 어구들의 이전 사용뿐 아니라 이후 사용에 도 적용된다는 것을 알 수 있을 것이다. 본 출원의 내용은 어떤 특정 요소, 단계, 또는 기능이 청구범위에 포함되어야 하는 필수 구성 요소를 의미한다 고 파악되어서는 안된다. 본 개시의 특허 범위는 오직 청구범위에 의해서만 한정된다."}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서 논의되는 도 1 내지 4, 그리고 본 개시의 다양한 실시예들은 첨부된 도면들을 참조하여 설명된다. 그 러나, 본 개시가 그 실시예들에만 국한되는 것은 아니며, 그에 대한 모든 변경 및/또는 균등물 또는 치환물들 역시 본 개시의 범주에 속한다는 것을 알아야 한다. 명세서 및 도면 전체에 걸쳐 동일하거나 유사한 구성요소들 을 나타내기 위해 동일하거나 유사한 참조 부호들이 사용될 수 있다. 상술한 바와 같이, 스마트 폰들 및 태블릿 컴퓨터들과 같은 많은 모바일 장치들은 정지 영상 및 비디오 영상을 촬영하는데 사용될 수 있는 카메라들을 포함한다. 그러나 모바일 전자 기기들 상의 카메라들은 통상적으로 많은 단점들을 가진다. 예를 들어, HDR(high dynamic range)은 휴대형 장치들 상의 동적 범위를 확장시키는 중요한 카메라 특성이다. 공교롭게도, 높은 채도의 영역들에서, HDR은 어떤 장면(scene)이 흔드는 손과 같이 움직이는 객체를 포함할 때 고스트 아티팩트(ghost artifacts)를 보이는 이미지들을 파생할 수 있다. 또한, 일부 HDR 장 면들에서는, 하나의 이미지 프레임을 기준으로 사용하는 탓에, 어떤 장면의 특정 요소들에 대한 복구가 제한될 수 있다. 본 개시는 HDR 이미징(imaging)과 같은 다양한 이미지 프로세싱 애플리케이션들에서 사용될 수 있는 기준 이미 지 프레임에 대한 동적 선택을 위한 기법들을 제공한다. 이하에서 보다 상세히 기술하는 바와 같이, “짧은” 기준 이미지 프레임과 “긴” 기준 이미지 프레임 사이를 동적으로 스위칭하기 위한 강력한 프레임워크가 제공 되며, 여기서 “짧다”와 “길다”는 노출을 의미한다. 무엇보다, 짧은 기준 이미지 프레임의 사용은 포화된 (saturated) 모션 고스트들을 없앨 수 있다. 그러나, 포화된 모션이 문제가 아니고 노이즈의 최소화가 요망될 때, 긴 기준 이미지 프레임이 사용될 수 있다. 또한, 개시된 실시예들은 노출을 증가시키고 일반적인 짧은 이미 지 프레임과 비교해 짧은 기준 이미지 프레임의 이득을 줄임으로써 모션 노이즈를 줄일 수 있다. 노출 시간을 늘리고 짧은 기준 이미지 프레임의 이득을 줄이는 것이, 노출 수준을 동일하게 유지하면서 보다 낮은 노이즈를 도모한다. 이하에서 설명되는 기법들은 주로 모바일 전자 기기를 사용하여 수행되는 것으로 기술되나, 다른 전자 기기들 역시 그러한 기법들을 수행하거나 지원하기 위해 사용될 수 있다는 것을 알아야 한다. 따라서, 그러한 기법들은 다양한 유형의 전자 기기들에서 사용될 수 있을 것이다. 또한, 이하에서 설명되는 기법들은 주로 어떤 장면의 정지 영상들을 촬영할 때의 이미지 프레임들을 처리하는 것으로서 기술되겠지만, 동일하거나 유사한 접근 방식 들이 비디오 이미지들의 촬영을 지원하는데 사용될 수도 있을 것이다. 도 1은 본 개시에 따른 전자 기기를 포함하는 예시적 네트워크 구성을 도시한다. 도 1에 도시된 네트워크 구성의 실시예는 단지 예시를 위한 것이다. 상기 네트워크 구성의 다른 실시예들이 본 개시의 범위를 벗어나지 않고 이용될 수 있다.본 개시의 실시예들에 따르면, 전자 기기는 네트워크 구성에 포함된다. 전자 기기는 버스, 프로세서, 메모리, 입출력(I/O) 인터페이스, 디스플레이, 통신 인터페이스, 또는 센 서 중 적어도 하나를 포함할 수 있다. 일부 실시예들에서 전자 기기는 상기 구성요소들 중 적어도 하 나를 제외하거나 적어도 하나의 다른 구성요소를 추가할 수 있다. 버스는 구성요소들(120 내지 180)을 서 로 연결하고 그 구성요소들간의 통신들(예를 들어, 제어 메시지들 및/또는 데이터 등)을 전달하기 위한 회로를 포함한다. 프로세서는 중앙 처리부(CPU), 애플리케이션 프로세서(AP), 또는 통신 프로세서(CP) 중 하나 이상을 포함 한다. 프로세서는 전자 기기의 다른 구성요소들 중 적어도 하나에 대한 제어를 수행하고/하거나 통신 과 관련한 동작 또는 데이터 처리를 수행할 수 있다. 일부 실시예들에서, 프로세서는 그래픽 프로세서 유 닛(GPU)일 수 있다. 예를 들어, 프로세서는 이미지 데이터를 수신할 수 있고, (이하에서 보다 상세히 논의 되는 바와 같이) 추가 이미지 처리를 위해 사용될 수 있는 기준 이미지 프레임을 동적으로 선택하기 위해 이미 지 데이터를 처리할 수 있다. 메모리는 휘발성 및/또는 비휘발성 메모리를 포함할 수 있다. 예를 들어, 메모리는 전자 장치의 적어도 하나의 다른 구성요소와 관련된 명령들 또는 데이터를 저장할 수 있다. 본 개시의 실시예들에 따르면, 메모리는 소프트웨어 및/또는 프로그램을 저장할 수 있다. 프로그램은 예컨대, 커널, 미들 웨어, API(application programming interface), 및/또는 애플리케이션 프로그램(또는 “애플리케이 션”)을 포함한다. 커널, 미들웨어 및 API 중 적어도 일부는 운영체제(OS)라고 칭할 수 있 다. 커널은 다른 프로그램들(예를 들어, 미들웨어, API 또는 애플리케이션)에서 구현되는 동작 들이나 기능들을 수행하기 위해 사용되는 시스템 자원들(예를 들어, 버스, 프로세서나 메모리 등)를 제어하거나 관리할 수 있다. 커널은 미들웨어, API, 또는 애플리케이션이 전자 장치 의 개별 구성요소들에 액세스하여 시스템 자원들을 제어하거나 관리하도록 할 수 있게 하는, 인터페이스를 제공한다. 애플리케이션은 이하에 기술되는 바와 같이 이미지 촬영 및 이미지 처리를 위한 하나 이상의 애 플리케이션들을 포함한다. 이러한 기능들은, 각각이 그 기능들 중 하나 이상을 실행하는 다수의 애플리케이션들 이나 단일한 애플리케이션에 의해 수행될 수 있다. 미들웨어는 API 또는 애플리케이션이, 예를 들어, 커널과 데이터 통신할 수 있게 하는 릴레이(relay)로서 기능할 수 있다. 복수의 애플리케이션들 이 제공될 수 있다. 미들웨어는 복수의 애플리케이션들 중 적어도 하나에 전자 장치의 시 스템 자원들(버스, 프로세서, 또는 메모리 등)을 이용하는 우선순위를 할당하는 것과 같이, 애 플리케이션으로부터 수신된 작업 요청들을 제어할 수 있다. API는 애플리케이션이 커널이 나 미들웨어로부터 제공되는 기능들을 제어할 수 있게 하는 인터페이스이다. 예컨대, API는 파일 제 어, 윈도우 제어, 비디오 처리 또는 텍스트 제어를 위한 적어도 하나의 인터페이스나 기능(명령 등)을 포함한다. I/O 인터페이스는 사용자나 다른 외부 장치들로부터 입력된 명령들이나 데이터를 전자 장치의 다른 구성요소(들)로 전달할 수 있는 인터페이스 역할을 한다. I/O 인터페이스는 전자 장치의 다른 구성요 소(들)로부터 수신된 명령들이나 데이터를 사용자나 다른 외부 장치로 출력할 수도 있다. 디스플레이는, 예를 들면, 액정 디스플레이(LCD), 발광 다이오드(LED) 디스플레이, 유기 발광 다이오드 (OLED) 디스플레이, 퀀텀 닷 발광 다이오드(QLED) 디스플레이, 마이크로 전자기계 시스템 (MEMS) 디스플레이, 또는 전자종이(electronic paper) 디스플레이를 포함한다. 디스플레이는 다초점 디스플레이와 같은 깊이 인식(depth-aware) 디스플레이일 수 있다. 디스플레이는, 예를 들면, 사용자에게 다양한 콘텐츠(텍스트, 이미지, 비디오, 아이콘, 또는 심볼 등)을 표시할 수 있다. 디스플레이는, 터치 스크린을 포함할 수 있으 며, 전자 펜 또는 사용자의 신체의 일부를 이용한 터치, 제스쳐, 근접, 또는 호버링(hovering) 입력 등을 수신 할 수 있다. 예를 들어, 통신 인터페이스는 전자 장치 및 외부 전자 장치(가령, 제1전자 장치, 제2전자 장치 , 또는 서버) 사이에 통신을 설정할 수 있다. 예를 들어, 통신 인터페이스는 무선 또는 유선 통 신을 통해 외부 전자 장치와 통신하기 위해 네트워크(162 또는 164)와 연결될 수 있다. 통신 인터페이스는 유선 또는 무선 송수신기(transceiver)이거나, 이미지들과 같은 신호를 송수신하기 위한 어떤 다른 구성요소일 수 있다. 무선 통신은 예를 들어, 셀룰러 무선 프로토콜로서 LTE(long term evolution), LTE-A(long term evolution- advanced), 5세대 무선 시스템(5G), mm(millimeter)-wave 또는 60 Ghz 무선 통신, 무선 USB, CDMA(code division multiple access), WCDMA(wideband code division multiple access), UMTS(universal mobile telecommunication system), WiBro(wireless broadband), 또는 GSM(global system for mobile communication) 중 적어도 하나를 사용할 수 있다. 유선 통신은 예를 들어, USB(Universal Serial Bus), HDMI(High Definition Multimedia Interface), RS-232(Recommended Standard 232) 또는 POTS(Plain Old Telephone Service) 중 적어 도 하나를 포함할 수 있다. 네트워크(162 또는 164)는 컴퓨터 네트워크(LAN(local area network) 또는 WAN(wide area network) 등), 인터넷, 또는 전화 네트워크와 같은 적어도 하나의 통신 네트워크를 포함한다. 전자 기기는 물리량을 계측하거나 전자 기기의 활성화 상태를 검출할 수 있고, 측정되거나 검출된 정 보를 전기적 신호로 변환할 수 있는 하나 이상의 센서들을 더 포함한다. 예를 들어, 하나 이상의 센서들 은 장면들에 대한 이미지들을 촬영하기 위해 하나 이상의 카메라들 또는 다른 이미징(imaging) 센서들을 포함할 수 있다. 센서(들)은 터치 입력을 위한 하나 이상의 버튼들, 제스처 센서, 자이로스코프 또는 자이 로 센서, 공기압 센서, 자기 센서 또는 자력계, 가속 센서 또는 가속계, 그립 센서, 근접 센서, 컬러 센서 (RGB(Red Green Blue) 센서 등), 생체 물리학적 센서, 온도 센서, 습도 센서, 광 센서, 자외선(UV) 센서, 근전 도 검사(EMG) 센서, 뇌전도(EEG) 센서, 심전도(ECG) 센서, 적외선(IR) 센서, 초음파 센서, 홍채 센서, 또는 손 지문 센서를 포함할 수 있다. 센서(들)은 하나 이상의 가속계, 자이로스코프, 및 기타 구성요소들을 포함 할 수 있는 관성 측정부를 더 포함할 수 있다. 또한, 센서(들)은 그 안에 포함된 센서들 중 적어도 하나를 제어하기 위한 제어 회로를 포함할 수 있다. 이 센서(들) 중 어느 하나가 전자 기기 내에 위치될 수 있다. 제1외부 전자 기기나 제2외부 전자 기기는 웨어러블 장치이거나 전자 기기-탑재형 착용 장치(예를 들 어, HMD)일 수 있다. 전자 기기가 전자 기기(예를 들어, HMD) 내에 탑재될 때, 전자 기기는 통 신 인터페이스를 통해 전자 기기와 통신할 수 있다. 전자 기기는 전자 기기와 직접 연결되 어, 별도의 네트워크 개입 없이 전자 장치와 통신할 수 있다. 전자 기기는 또한, 하나 이상의 카메라 들을 포함하는 눈 안경과 같은 증강 현실(augmented reality) 웨어러블 장치일 수도 있다. 제1 및 제2외부 전자 기기들(102 및 104)과 서버는 각각 전자 기기와 동일하거나 상이한 타입의 장치 일 수 있다. 본 개시의 소정 실시예들에 따르면, 서버는 하나 이상의 서버들의 그룹을 포함한다. 또한, 본 개시의 소정 실시예들에 따르면, 전자 기기 상에서 실행되는 동작들 전체 또는 일부는 하나 또는 여러 개 의 다른 장치들(가령, 전자 기기들(102 및 104) 또는 서버) 상에서 실행될 수도 있다. 또한, 본 개시의 소 정 실시예들에 따르면, 전자 기기가 자동적으로, 혹은 요청에 의해 어떤 기능이나 서비스를 수행해야 할 때, 전자 기기는 그 기능이나 서비스를 자체적으로나 추가적으로 실행하는 대신에, 다른 장치(가령, 전자 기기들(102 및 104) 또는 서버)에 요청하여 그와 관련된 적어도 일부 기능들을 수행하도록 할 수 있다. 다 른 전자 기기(가령, 전자 기기들(102 및 104) 또는 서버)는 요청된 기능들 또는 추가 기능들을 실행하고 실행 결과를 전자 기기로 전송할 수 있다. 전자 기기는 수신된 결과를 그대로, 또는 추가적으로 처리 함으로써 요청된 기능이나 서비스를 제공할 수 있다. 이러한 목적으로, 예를 들어 클라우드 컴퓨팅, 분산 컴퓨 팅, 또는 클라이언트-서버 컴퓨팅 기법이 사용될 수 있다. 도 1은 전자 기기가 네트워크(162 또는 164)를 통해 외부 전자 기기나 서버와 통신하는 통신 인터페이스를 포함함을 보여주지만, 전자 기기 는 본 개시의 일부 실시예에 따라 별도의 통신 기능 없이 독립적으로 동작될 수도 있다. 서버는 전자 기기(또는 그것의 적절한 부분집합)과 동일하거나 유사한 구성요소들(110 내지 180)을 포함할 수 있다. 서버는 전자 기기 상에서 구현되는 동작들(또는 기능들) 중 적어도 하나를 수행함으 로써 전자 기기 구동을 지원할 수 있다. 예를 들어, 서버는 전자 기기에서 구현되는 프로세서 를 지원할 수 있는 프로세싱 모듈이나 프로세서를 포함할 수 있다. 일부 실시예들에서, 서버는 이하 에 기술되는 것과 같이 데이터를 이용하는 많은 작업들을 수행하기 위한 멀티 태스크 융합(fusion) 신경망을 사 용하여 데이터를 처리한다. 특정 실시예들에서, 서버는 이미지 데이터를 이용하는 다수의 작업들을 수행하 여 장면들에 대한 이미지들을 생성하기 위해 멀티 태스크 융합(fusion) 신경망을 사용하여 이미지 데이터를 처 리한다. 도 1는 예시적 전자 기기를 포함하는 네트워크 구성의 일 예를 도시하고 있으나, 도 1에 대해 다양한 변형이 있을 수 있다. 예를 들어, 네트워크 구성은 임의의 적절한 배열로 임의의 개수의 각각의 구성요소 를 포함할 수 있다. 일반적으로, 컴퓨팅 및 통신 시스템들은 광범위한 구성들로 나타나며, 도 1은 본 개시의 범 위를 어떤 특정 구성으로 한정하지 않는다. 또한, 도 1은 본 특허 문서에서 개시된 다양한 특성들이 사용될 수있는 하나의 동작 환경을 도시하고 있지만, 그러한 특성들은 어떤 다른 적절한 시스템에서 사용될 수도 있다. 도 2a, 2b, 2c, 2d, 2e, 2f, 2g, 2h, 및 2i는 본 개시에 따른 기준 이미지 프레임의 동적 선택을 위한 예시적 프로세스를 예시한다. 설명의 편의를 위해, 프로세스는 도 1에 도시된 전자 기기를 사용하여 수행되 는 것으로 기술된다. 그러나 이 프로세스는 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스 템 내에서도 사용될 수 있을 것이다. 도 2a에 도시된 바와 같이, 전자 기기는 버스트(burst) 촬영 동작 시, 한 장면에 대한 다수의 이미지 프레임들을 촬영한다. 촬영 동작은 사용자가 셔터 컨트롤을 활성화하는 등의 이벤트에 응하여 수행될 수 있다. 일부 실시예들에서, 다수의 이미지 프레임들은 카메라와 같은, 전자 기기의 하나의 이미지 센서 를 사용하여 촬영된다. 다른 실시예들에서, 다수의 이미지 프레임들은 다수의 카메라들과 같은, 전자 기기 의 다수의 이미지 센서들을 사용하여 촬영되며, 이 경우 각각의 이미지 센서는 하나의 이미지 또는 다수의 이미지들을 촬영할 수 있다. 일부 실시예들에서, 촬영된 이미지 프레임들은 다른 유형의 이미지 프레임들(가령, YUV 이미지 프레임들)이 아 닌 바이에르(Bayer) 이미지 프레임들을 나타낸다. 이 실시예들에서, Bayer 이미지 프레임들은, 이미지 프레임들 이 이미지 신호 프로세서(ISP)를 통해 처리된 후 YUV 이미지 프레임들에서 상실될 수 있는 선형 특성들 (linearity properties)을 유지할 수 있고, 이러한 선형성(linearity)은 후속 처리 시 유용할 수 있다. 촬영된 이미지 프레임들은 서로 다른 노출을 사용하여 촬영된 프레임들을 포함한다. 예를 들어, 이미지 프레임들 중 일 부는 상대적으로 짧은 노출(EV-3 또는 EV-2 등)로 촬영될 수 있어, 짧은(쇼트) 이미지 프레임들이라 불린다. 다 른 이미지 프레임들은 상대적으로 긴 노출(EV+0 등)로 촬영될 수 있어, 긴(롱) 이미지 프레임들이라 불린다. 짧은 이미지 프레임들 중 일부는 바람직하지 않은 노이즈 양을 가진 영역들을 보일 수 있다. 한 장면의 정적 영 역들에 있어서, 노이즈를 줄이기 위한 흔한 전략은 다수의 짧은 이미지 프레임들을 함께 블렌딩하는 것이다. 그 러나, 장면의 동적이거나 모션이 있는 영역들에 있어서, 블렌딩은 “고스트” 아티팩트들을 생성한다는 위험으 로 인해 (로컬 정렬(local alignment)의 도움이 있더라도) 일반적으로 덜 바람직하다. 어그레시브(aggressive) 공간 필터링은 노이즈를 줄일 수 있으나, 본질적으로 어두운 디테일들(dark details)을 숨기기도 한다. 최소한 의 디테일 손실로 노이즈가 있는 모션 영역들을 다루기 위하여(모션 노이즈 감소), 전자 기기는 짧은 이미 지 프레임들 중 하나를 선택하고, 선택된 짧은 이미지 프레임의 ISO 이득을 1/A 배로 줄이면서, 그 선택된 짧은 이미지 프레임의 노출 시간을 A 배만큼 증가시킬 수 있다. 이것이 짧은 노출 레벨을 유지시키는데 도움을 준다. 일부 실시예들에서, A는 2의 멱수(예를 들어, 2, 4, 8 등)를 나타낼 수 있다. 이 기능이 표 1에 정리되어 있다. 표 1 파라미터 선택된 짧은 이미지 프레임 일반적인(regular) 짧은 이미지 프레임 노출 시간 ISO 이득 모션 영역 내 노이즈를 줄이기 위한, 선택된 짧은 프레임 조정, 여기서 A = 2, 4, 8,. . . .를 의미할 수 있다. 이러한 동작들은 선택된 짧은 이미지 프레임의 화질을 개선하기 위해 수행될 수 있다. 개선된 화질을 가진 선택 된 짧은 이미지 프레임은 이하에서 보다 상세하게 논의되는 디고스팅(deghosting) 및 블렌딩을 위해 나중에 짧 은 기준 이미지 프레임으로서 사용될 수 있다. 이미지 촬영 동작 후, 전자 기기는 촬영된 이미지 프레임들을 정렬(align)하기 위해 정합 (registration) 동작을 수행한다. 정합은 일반적으로, 이미지 프레임들 내 공통 포인트들이 정렬되도록 상이한 이미지 프레임들을 정렬하는 것을 의미한다. 이것은 이미지 프레임들이 잘 정렬되어 있을 때 이후의 블렌딩 동 작들이 가장 성공적일 수 있으므로, 유용하거나 바람직할 수 있다. 따라서, 정합 동작의 한 가지 목표는 카메라 모션의 존재 시에도 이미지 프레임들이 정렬될 수 있게 하는 것이다. 이것을 행하기 위해, 전자 기기 는 촬영된 이미지 프레임들에서 이미지 프레임들 사이에 공통되는 정적 요소들을 검사하여, 그러한 정적 요소들의 특성들에 따라 이미지 프레임들을 정렬한다. 일부 실시예들에서, 정합 동작은 다음과 같이 수행될 수 있다. 전자 기기는 EV+0와 같이, 동일한 노 출 수준으로 다중 노출 이미지 프레임들을 균등화(equalize) 할 수 있다. 이것은 이미지 프레임들 사이에 매칭 된 주요(key) 포인트들의 수를 증가시키고 그에 따라 추후 단계들에서 보다 안정적인 호모그래피(homography) 추정을 제공하기 위해 수행될 수 있다. Bayer 이미지 프레임들이 선형이므로, 여기서의 노출 균등화 (equalization)는 단순히 스케일링(scaling) 동작을 수행하는 것을 포함할 수 있고, 여기서 스케일링 팩터는 EV 스탑(stop)들의 개수에 의해 결정된다. 스케일링 후 적절한 캐핑(capping)이, 매치가 없거나 틀린 매치들을 가 진 주요 포인트들의 개수를 줄이기 위해 사용될 수 있다. 그런 다음 전자 기기는 이미지 프레임들에서 휘 도(luminance) 성분들을 추출하고, 휘도 성분들 상에서 주요 포인트 검출 및 디스크립터(descriptor) 추출을 수 행한다. 획득된 주요 포인트들에 기반하여, 전자 기기는 다른 이미지 프레임들을 선택된 베이스 이미지 프 레임으로 와핑(warp)하기 위해 호모그래피를 추정한다. 정합 동작의 목적이 카메라 모션 등으로 인해 정렬 되지 않을 가능성이 있는 프레임들을 정렬시키기 위한 것이므로, 임의의 이미지 프레임이 여기서 베이스 이미지 프레임으로 선택될 수 있다. 정합 동작 후, 전자 기기는 정렬된 이미지 프레임들을 두 그룹(즉, 짧은 것과 긴 것)으로 구분하고, 도 2a에 도시된 것과 같이 그 두 이미지 그룹들에 대해 각각의 경로로 다수의 후속 동작들을 수행한다. 일반적 으로, 짧은 이미지 프레임들은 한 장면의 포화된 영역들에서 보다 나은 명료성을 보여줄 것이고, 긴 이미지 프 레임들은 그 장면의 어두운 영역들에서 보다 나은 디테일들을 가질 것이다. 이 예에서, 전자 기기는 짧은 이미지 프레임들 상에서 균등화 동작(210a)을 수행하고, 긴 이미지 프레임들 상에서 균등화 동작(210b)을 수행한다. 균등화 동작(210a-210b)은 짧은 이미지 프레임들 및 긴 이미지 프레임들 을 동일한 밝기 수준으로 가져오기 위해 수행된다. 일부 실시예들에서, 균등화 동작(210a)은 짧은 이미지 프레 임들을 긴 이미지 프레임들의 밝기 레벨로 가져오는 동작을 포함한다. 예를 들어, 긴 이미지 프레임들이 EV+0의 노출 레벨을 가지고 짧은 이미지 프레임들이 EV-3의 노출 레벨을 가지는 경우, 노출 차이는 로 정의될 수 있다. 따라서, 각각의 짧은 이미지 프레임의 밝기 레벨은 8 배 곱해져서, 짧은 이미지 프레임들의 밝 기 레벨을 긴 이미지 프레임들의 밝기 레벨에 보다 가깝게 가져올 수 있다. 짧은 이미지 프레임들이 긴 이미지 프레임들의 밝기 레벨로 될 때, 긴 이미지 프레임들의 밝기 레벨은 균등화될 필요가 없으며, 긴 이미지 프레임 들을 위한 균등화 동작(210b)은 사소하거나(가령 “1로 곱함”) 생략될 수 있다. 다른 실시예들에서, 균등화 동 작(210a-210b)은 짧고 긴 이미지 프레임들을 중간 밝기 레벨이 되게 수행될 수도 있다. 균등화 동작들(210a-210b) 후, 전자 기기는 디고스팅(deghosting) 동작들(220a-220b)을 수행한다. 디고스 팅 동작들(220a-220b)은 이미지 프레임들 사이에서 모션 영역들을 식별함으로써 그 영역들에서의 블렌딩이 억제 될 수 있도록 하기 위해 수행된다. 이것은 모션 영역들에서의 블렌딩이 고스트 아티팩트들을 일으킬 수 있기 때 문에 유용하다. 디고스팅 동작들(220a-220b)은 임의의 적절한 방식으로 수행될 수 있다. 도 2b는 디고스팅 동작 들(220a-220b)의 한 예시적 구현을 보다 상세하게 도시한다. 도 2b에 도시된 프로세스가 디고스팅을 위한 한 예 를 나타내나, 다른 디고스팅 프로세스가 사용될 수도 있으며 본 개시의 범위 내에 있다. 도 2b에 도시된 바와 같이, 각각의 디고스팅 동작(220a-220b)로의 입력들은 두 개의 균등화된 이미지 프레임들 을 포함한다. 디고스팅 동작(220a)에 있어서, 균등화된 이미지 프레임들 은 균등화 동작(210a)에서 균등 화된 짧은 이미지 프레임들을 포함한다. 디고스팅 동작(220b)에 있어서, 균등화된 이미지 프레임들 은 균등 화 동작(210b)에서 균등화된 긴 이미지 프레임들을 포함한다. 각각의 경우에서, 이미지 프레임들 중 하나가 기준 이미지 프레임 으로서 선택되고, 다른 이미지 프레임 또는 프레임들은 비기준(non-reference) 이미지 프레임들 으로 지정된다. 동일 노출 이미지 프레임들(모두 긴 이미지 프레임들이거나 모두 짧은 이미지 프레 임들)에 있어서, 일반성의 상실 없이 임의의 이미지 프레임이 기준 이미지 프레임 으로서 선택될 수 있다. 디고스팅 동작들(220a-220b)의 출력들은 가중된 모션 맵들 이며, 이것은 일부 실시예들에서 [0,1] 범위 내 값들을 가진다. 기준 이미지 프레임 에 있어서, 모션 맵은 모든 픽셀들 p에 대해 일 때와 같이 간 단한 것일 수 있다. 비기준 이미지 프레임들 에 있어서, 모션 맵은 일부 실시예들에서 다음과 같이 결정될 수 있다. 전자 기기 는 비기준 이미지 프레임 및 기준 이미지 프레임 간 차이를 계산하기 위해 이미지 차이 기능(22 1)을 수행하여, 두 프레임들이 포화된 곳의 픽셀들을 무시하는데, 이는 모션 분석 상 그곳에서는 신뢰할 수 있 는 정보가 존재하지 않기 때문이다. 어떤 경우, 차이(difference) 신호는 다음과 같이 계산될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 기준 및 비기준 포화된 영역들 Sn 및 Sr은, 여러 채널들(Bayer 채널들 Gr, Gb, R, B 등)에 걸친 최대 값 이 기설정된 채도 문턱치 를 초과할 때, 픽셀 단위로 선언된다. 이것은 다음과 같이 표현될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "연산자 은 여러 채널들에 걸친 총 절대 차이(absolute difference)를 나타낸다. 이것은 다음과 같이 표현될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이미지 프레임들 내 어두운 영역들에서의 모션은, 그곳에서의 차이 신호가 작은 경향이 있어 누락될 수 있다. 모션 검출의 누락율(miss rate)을 줄이기 위해, 위치(locality) 정보가 사용될 수 있다. 즉, 이동 픽셀들은 국 지적으로 유사한 것으로 관측된다. 따라서, 이웃하는 유사 픽셀들로부터 강한 차이 신호들을 전파함으로써 보다 강한 차이 신호(보다 높은 모션의 가능성을 나타냄)가 획득될 수 있다. 이를 위해, 전자 기기는 양방향 (bilateral) 필터 기능을 적용하여 필터링된 차이 이미지를 생성할 수 있다. 필터링은 기준 이미지 프레임 에 의해 가이드되고 수학식 의 차이 신호에 대해 적용될 수 있다. 어떤 경우, 차이 신호는 다음과 같이 표현될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, N은 필터 가중치들의 합이 1이 되도록 하기 위해 사용되는 정규화 인수를 나타내고, 는 픽셀 p의 이 미지 좌표를 나타내고, q는 p의 이웃 픽셀을 나타내고, 및 는 도메인 및 범위 표준 편차들을 나타낸다. 기준 이미지 프레임 은 모션 픽셀들이 기준 이미지 프레임 으로부터 꺼내지기 때문에 가이드하 기 위해 사용된다. 필터링된 차이 이미지가 결정된 후, 전자 기기는 문턱치 추정 기능을 수행하여 모션과 비모션을 분류 하기 위한 CFAR(constant false-alarm rate) 차이 문턱치 를 산출한다. 차이 신호의 값이 장면에 종속 (scene-dependent)될 수 있기 때문에, 신뢰할 수 있는 고정 문턱치를 설정하는 것은 어려울 수 있다. 대신, 버 스트(burst) 촬영 시 프레임들 간 이동 픽셀들의 비율은 상대적으로 작다는 것이 관찰된다. 따라서, 그 문턱치 는 차이가 0인 픽셀들을 제외하고 장면 내 모든 차이 신호들 의 백분위수에 기반하여 자동으로 설정될 수있다. 문턱치에 대한 표준 편차 는 이어지는 소프트 모션 맵으로의 변환을 위해 문턱치 미만의 소수 의 백분위수인 차이 값으로 설정될 수 있다. 전자 기기는 문턱치 억제 기능을 또한 수행하여 기준 및 비기준 이미지 프레임들 모두의 섀도우 영역 들에서의 문턱치를 더 줄임으로써 모션 검출을 향상시킬 수 있다. 예를 들어, 문턱치 억제 기능에 있어서, 전자 기기는 기준 및 비기준 이미지 프레임들 모두에 대해 다수의 채널 값들(Gr, Gb, R 및 B 값들 등)을 평균내고, 휘도 맵을 생성하며, 그 휘도 맵을 차이 문턱치로 곱하여 문턱치 억제를 결정할 수 있다. 어떤 경우, 문턱치 억제는 다음과 같이 표현될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서 는 섀도우 문턱치를 나타낸다. 전자 기기는 이후 모션 맵 결정 기능을 수행하여 각각의 비기준 이미지 프레임에 대한 비기준 모션 맵 을 결정할 수 있다. 일부 실시예들에서, 이것은 차이 신호를 S자형(sigmoid) 모델 등에 기반하여 모션 /비모션에 대한 연판정(soft decision)으로 변환함으로써 일어난다. 어떤 경우, 모션 맵들은 다음과 같이 결정 될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "구현예에 따라, 작은 픽셀 값들(예를 들어, 0에 가까운 값)은 모션을 나타내고, 큰 픽셀 값들(예를 들어, 1에 가까운 값)은 정적 영역들을 나타낸다. 물론 이것은 단지 한 예일 뿐이다. 다른 실시예들에서, 보다 작은 값들 은 정적 영역들을 지시하고, 보다 큰 값들은 모션을 지시할 수도 있다. 다시 도 2a를 참조하면, 디고스팅 동작들(220a-220b) 후, 전자 기기는 동일 노출(SE) 블렌딩 동작들(230a- 230b)을 수행하여 동일 노출 블렌딩 이미지 프레임들을 생성할 수 있다. 예를 들어, 전자 기기는 SE 블렌 딩 동작(230a)을 이용하여 다수의 짧은 이미지 프레임들을 블렌딩하여 단일의 블렌딩된 짧은 이미지 프레임을 생성할 수 있다. 마찬가지로, 전자 기기는 SE 블렌딩 동작(230b)을 이용하여 다수의 긴 이미지 프레임들을 블렌딩하여 단일의 블렌딩된 긴 이미지 프레임을 생성할 수 있다. 블렌딩 동작들(230a-230b)에서, 전자 기기 는 블렌딩을 가이드하기 위해 디고스팅 동작들(220a-220b)로부터 각각의 모션 맵들 Wi을 사용한다. 어떤 경우, 블렌딩은 다음과 같이 표현될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, 은 단일 노출의 블렌딩된 짧고 긴 이미지 프레임들을 각각 나타낸다. 블렌딩 동작들(230a-230b)에서 블렌딩된 짧고 긴 이미지 프레임들이 생성되었으면, 전자 기기는 디고스팅 동작들(240a-240b)을 수행하여, 짧은 블렌딩 이미지 프레임 및 긴 블렌딩 이미지 프레임에 대한 블렌딩 모션 맵 들 및 을 각각 생성할 수 있다. 디고스팅 동작들(240a-240b)은 디고스팅 동작들(220a-220b)과 동일하 거나 유사할 수 있으며, 일부 실시예들에서 프로세스의 추가 세부사항들을 위해 도 2b를 참조할 수 있다. 그러 나, 디고스팅 동작들(240a-240b)은 디고스팅 동작들(220a-220b)과 입력들에 있어 차이가 있다. 즉, 디고스팅 동 작들(220a-220b)은 동일한 노출을 가진 이미지 프레임들(짧은 이미지 프레임들 또는 긴 이미지 프레임들)을 입 력들로서 수신한다. 반대로, 디고스팅 동작들(240a-240b)은 상이한 노출들을 가진 이미지 프레임들(긴 이미지 프레임들 및 짧은 이미지 프레임들)을 입력들로서 수신한다. 특히, 디고스팅 동작들(240a-240b)은 입력들로서, SE 블렌딩 동작(230a)으로부터의 블렌딩된 짧은 이미지 프레임 및 SE 블렌딩 동작(230b)로부터의 블렌딩된 긴 이미지 프레임 둘 모두를 수신한다. 디고스팅 동작(240a)의 출력은 짧은 블렌딩된 모션 맵 이고, 디고스팅동작(240b)의 출력은 긴 블렌딩된 모션 맵 이다. 디고스팅 동작들(240a-240b)에서 블렌딩된 모션 맵들이 생성된 후, 전자 기기는 다중 노출(ME) 블렌딩 동 작들(250a-250b)을 수행할 수 있다. ME 블렌딩 시 노이즈 레벨에 차이가 존재하는데, 이는 긴 블렌딩 이미지 프 레임이 짧은 블렌딩 이미지 프레임보다 통상적으로 낮은 노이즈를 가진다는 것을 의미한다. 따라서, 그 둘 간의 믹싱(mixing)을 최소화하는 것이 바람직할 수 있다. 또한, ME 블렌딩의 블렌딩 정책은 모션 맵들뿐 아니라 포화 영역들도 고려할 수 있다. 일차 이미지(또는 기준 이미지)로서, SE 블렌딩 동작들(230a-230b)로부터 동일 노출 된 블렌딩된 짧은 이미지 프레임이 선택되는지 또는 동일 노출된 블렌딩된 긴 이미지 프레임이 선택되는지 여부 에 따라, 블렌딩 정책이 달라질 수 있다. 따라서, 전자 기기는 동일 노출된 블렌딩된 짧은 이미지 프레임이 일차 이미지이고 동일 노출된 블렌딩된 긴 이미지 프레임이 이차 이미지인 ME 블렌딩 동작(250a)을 수행할 수 있다. ME 블렌딩 동작(250a)의 출력은 ME 블렌딩된 짧은 기준 이미지 프레임이다. 일부 실시예들에서, ME 블렌딩 동작(250a)은 다음과 같이 수행될 수 있 다."}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서 는 ME 블렌딩된 짧은 기준 이미지 프레임을 나타내고, 는 동일 노출된 블렌딩된 짧은 이미지 프레임을 나타내고, 는 동일 노출된 블렌딩된 긴 이미지 프레임을 나타내고, 는 블렌딩 가중치를 나타 낸다. 어떤 경우, 블렌딩 가중치 는 다음과 같이 계산될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "은 긴 블렌딩된 긴 이미지 프레임에 대한 모션 맵을 나타내고, SL은 긴 블렌딩된 긴 이미지에 대한 채도 (saturation) 맵을 나타낸다. 짧은 기준 시스템에서 , 임을 알아야 한다. 수학식에 따르면, 는 의 모션 및 포화 영역들 모두에서 작으므로, 그 영역들에서 짧은 블렌딩 이미지 프레임 으로부터 의 콘텐츠를 가져올 수 있다. 마찬가지로, 전자 기기는 동일 노출된 블렌딩된 긴 이미지 프레임이 일차 이미지이고 동일 노출된 블렌딩 된 짧은 이미지 프레임이 이차 이미지인 ME 블렌딩 동작(250b)을 수행할 수 있다. ME 블렌딩 동작(250b)의 출력 은 ME 블렌딩된 긴 기준 이미지 프레임이다. 일부 실시예들에서, ME 블렌딩 동작(250b)은 다음과 같이 수행될 수 있다."}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "는 ME 블렌딩된 긴 기준 이미지 프레임을 나타내고, 는 동일 노출된 블렌딩된 짧은 이미지 프레임을 나타내고, 는 동일 노출된 블렌딩된 긴 이미지 프레임을 나타내고, 는 블렌딩 가중치를 나타내고, 은 긴 블렌딩 이미지에 대한 채도 맵을 나타내고, C는 이하에 설명되는 것과 같이 선택되는 상수를 나타낸다. 어떤 경우, 블렌딩 가중치 는 다음과 같이 계산될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "은 블렌딩된 짧은 이미지 프레임에 대한 모션 맵을 나타내고, 은 블렌딩된 긴 이미지 프레임에 대한 채 도 맵을 나타낸다. 긴 기준 시스템에서 , 임을 알아야 한다. 연산자 는 여기서 비선형 필터 링 연산을 나타내고, 일부의 경우들에서 다음과 같이 정의될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "여기서"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "그리고 이며, 이는 U에 대한 오픈 모폴로지(open morphology) 필터링을 의미한다. 수학식 12에 따라, 그리고 해당 순간에 대한 비선형 필터링 을 무시하면, 블렌딩 가중치 는 의 정적 포화 영역 들에서만 커서, 그 영역들에서만 블렌딩된 짧은 이미지 프레임 으로부터의 콘텐츠를 가져올 수 있다. 그러므 로, 수학식 에서 U로 표기되는, 모션들로 인해 에 의해 채워지지 않는 안의 포화 영역들이 존재한 다. 그러한 영역들을 채울 정보가 존재하지 않으므로, 그것들은 만들어질 수 있는데, 단순한 선택이 상수 C이다. 또한, U 영역들은 모폴로지 필터링 등을 통해 최소화되어, 필요한 생성 정보의 양을 줄일 수 있다. 위에서 논의된 바와 같이, 전자 기기는 ME 블렌딩 동작들(250a-250b)를 수행하여 ME 블렌딩된 짧은 기준 이미지 프레임 및 ME 블렌딩된 긴 기준 이미지 프레임 을 각각 생성한다. 전자 기기는 이때 기 준 선택 동작을 수행하여, 추가 이미지 프로세싱을 위한 기준 프레임으로서 사용될 기준 이미지 프레임들 및 중 하나를 선택한다. 기준 선택 동작을 수행하기 위해 다양한 기법들이 사용될 수 있다. 도 2c 및 2d는 기준 선택기 동작으로서 수행될 수 있는 두 가지 예시적 프로세스들(260a 및 260b)을 보다 상세히 도시한다. 도 2c에 도시된 바와 같이, 전자 기기는 짧고 긴 기준 이미지 프레임들 및 을 획득함으로써 프 로세스(260a)를 시작한다. 전자 기기는 짧은 기준 이미지 프레임 내 큰 섀도우 영역들의 존재를 체 크하기 위해 큰 섀도우 영역 테스트를 수행한다. 큰 섀도우 영역 테스트를 수행하기 위해 다양한 기 법들이 사용될 수 있다. 도 2e는 큰 섀도우 영역 테스트의 한 예시적 구현예를 보다 상세하게 도시한다. 도 2e에 도시된 바와 같이, 전자 기기는 짧은 기준 이미지 프레임 을 택하고, 단계 2611에서 전체 프 레임 으로부터 휘도 값들을 계산한다. 어떤 경우, 이것은 다음과 같이 수행될 수 있다: Luma = 0.213 * R + 0.715 * G + 0.072 * B 여기서, R, G 및 B는 각각의 픽셀의 적, 녹 및 청 채널들을 각각 나타낸다. 일부 실시예들에서, 이것은 0-255 범위 안에 있는 휘도 값들을 제공한다. 물론 이것은 다만 예일 뿐이며, 다른 휘도 식들이 다른 범위들 내 휘도 값들을 생성하기 위해 사용될 수 있다. 단계 2612에서, 전자 기기는 이미지 프레임에 걸친 휘도 값들의 중앙(median) 휘도 값을 결정한다. 여기서, 중앙 휘도 값은 휘도 값들의 50%가 그 위에 있고 휘도 값들의 50%는 그 아래에 있는 값에 해당한다. 단 계 2613에서, 전자 기기는 중앙 휘도 값이 기결정된 문턱치(가령 50) 미만인지를 판단한다. 그 경우, 짧은 기준 이미지 프레임 이 너무 어둡다고 간주된다. 그렇지 않은 경우, 짧은 기준 이미지 프레임 이 너무 어둡지는 않다고 간주된다. 단계 2614에서, 전자 기기는 짧은 기준 이미지 프레임 의 ISO 값을 취 하고, 그 ISO 값이 기결정된 문턱치(가령, 4000) 보다 큰지 여부를 판단한다. ISO 값이 문턱치보다 큰 경우, 짧 은 기준 이미지 프레임 은 노이즈가 너무 많다고 간주된다. 그렇지 않은 경우, 짧은 기준 이미지 프레임 은 노이즈가 너무 많다고는 간주되지 않는다. 단계 2615에서, 전자 기기는 단계들(2613 및 2614)로부터의 결정들의 논리합(OR)을 취하여 짧은 기준 이미 지 프레임 이 너무 어두운지 또는 노이즈가 너무 많은지 여부를 판단한다. 단계 2616에서, 짧은 기준 이미 지 프레임 이 너무 어둡지 않고 노이즈가 너무 많은 것이 아닌 경우, 큰 섀도우 영역이 짧은 기준 이미지 프레임 내에 존재하지 않는다고 간주되고, 그에 따라 짧은 기준 이미지 프레임 이 기준 이미지 프레 임으로서 사용될 수 있다. 이와 달리, 짧은 기준 이미지 프레임 이 너무 어둡거나 노이즈가 너무 많거나, 둘 모두인 경우, 큰 섀도우 영역이 짧은 기준 이미지 프레임 안에 존재한다고 간주되므로, 짧은 기준 이 미지 프레임 은 기준 이미지 프레임으로 사용되기에 적합하지 않다. 다음 동작은 프로세스(260a) 또는 프 로세스(260b)가 기준 선택 동작을 위해 수행되는지 여부에 따라 달라진다. 도 2c로 돌아가면, 프로세스(260a)에서, 큰 섀도우 영역이 짧은 기준 이미지 프레임 내에 존재하지 않으 면, 짧은 기준 이미지 프레임 이 기준 이미지 프레임으로서 사용될 수 있다. 그렇지 않은 경우, 큰 섀도우 영역이 짧은 기준 이미지 프레임 안에 존재한다면, 전자 기기는 잔차(residual) 포화된 모션 테스트 를 수행하여 긴 기준 이미지 프레임 내 포화된 모션의 존재를 검사한다. 잔차 포화된 모션 테스트 를 수행하기 위해 다양한 기법들이 사용될 수 있다. 도 2f는 잔차 포화된 모션 테스트의 한 예시적 구현예를 보다 상세하게 도시한다. 도 2f에 도시된 바와 같이, 전자 기기는 긴 기준 이미지 프레임 을 취하고, 단계 2621에서 긴 기준 이미지 프레임 에 대한 채도 분석을 수행하여 채도 맵을 생성한 다. 채도 맵은 긴 기준 이미지 프레임 의 어느 부분들이 너무 밝은지를 나타낸다. 채도 분석을 수행 하기 위해 다양한 기법들이 사용될 수 있다. 도 2g는 단계의 채도 분석에 대한 한 예시적 구현예를 보다 상세하게 도시한다. 도 2g에 도시된 바와 같 이, 단계 26211에서, 전자 기기는 긴 기준 이미지 프레임 내 각각의 픽셀에 대한 다양한 채널들(가 령, R, G, 또는 B) 사이에서 최대값을 취한다. 일반적으로, 이미지의 포화된 영역들에서, R, G, 및 G 값들은 모 두 높고, 단계 26211은 최대값을 선택한다. 단계 26212에서, 전자 기기는 각각의 픽셀에 대한 최대값에 비 선형 매핑 함수를 적용한다. 일부 실시예들에서, 매핑 기능은 다음과 같이 주어질 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "전자 기기는 각각의 픽셀에 매핑 함수를 적용함으로써 채도 맵을 생성한다. 도 2f로 돌아가면, 전자 기기는 또한, 디고스팅 동작(240b)으로부터 긴 블렌딩된 모션 맵 을 획득하고 1이라는 값에서 각각의 값을 감산함으로써 그 모션 맵 을 반전시킨다. 이것이 모션 맵 WL을 채도 맵 의 수치적 관례(numerical convention)에 따라 정렬하도록 돕는다. 예를 들어, 0은 모션을 나타낼 수 있고 1은 모션 맵 안에 모션이 없음을 나타낼 수 있어, 모션 맵 을 반전시켜 1이 모션을 나타내고 0이 모션이 없 음을 나타내게 한다. 채도 맵에서, 1은 채도를 나타낼 수 있고, 0은 채도가 없음을 나타낼 수 있다. 단계 2623에서, 전자 기기는 모션 맵 과 채도 맵을 픽셀 단위로 곱하여 포화된 모션 맵을 획득 한다. 포화된 모션 맵에서, 1에 가까운 값들은 포화된 영역 내에 모션이 있음을 나타낼 수 있고, 0에 가까운 값 들은 포화된 영역 내에 모션이 없음을 나타낼 수 있다. 단계 2625에서, 전자 기기는 포화된 모션 맵에 대해, 노이즈를 줄이기 위한 필터링 동작인 모폴로지 오픈 기능을 수행한다. 단계 2626에서, 전자 기기는 소정 문턱값에 기반하여 포화된 모션 맵을 이진 화(binarize)한다. 이진화 시, 포화된 모션 맵 내에서 문턱치 미만인 값들에는 0이라는 새로운 값이 할당 되고, 포화된 모션 맵 내에서 문턱치를 넘는 값들에는 1이라는 새 값이 할당된다. 단계 2627에서, 이진화 된 포화된 모션 맵의 값들이 함께 더해져서, 긴 기준 이미지 프레임 중 얼마나 많은 영역이 포화된 모션을 포함하는지를 나타내는 포화된 모션 사이즈 값을 획득한다. 단계 2629에서, 전자 기기는 포화된 모션 사이즈 값이 기결정된 문턱값(가령, 20)보다 큰지를 판단 한다. 포화된 모션 사이즈 값이 문턱치보다 크지 않으면, 긴 기준 이미지 프레임 안에 많은 양의 잔차 포화된 모션은 존재하지 않는다고 간주하고, 따라서 긴 기준 이미지 프레임 이 기준 이미지 프레임으 로서 사용될 수 있다. 그와 달리, 포화된 모션 사이즈 값이 문턱치보다 큰 경우, 긴 기준 이미지 프레임 안에 많은 양의 잔차 포화된 모션은 존재한다고 간주하고, 따라서 긴 기준 이미지 프레임 은 기준 이미지 프레임으로 사용하기에 적합하지 않다. 다음 동작은 프로세스(260a) 또는 프로세스(260b)가 기준 선택 동작을 위해 수행되는지 여부에 따라 달라진다. 다시 도 2c로 돌아가서, 전자 기기가 잔차 포화된 모션 테스트에서 긴 기준 이미지 프레임 안 에 많은 양의 잔차 포화된 모션이 존재한다고 판단한 경우, 짧은 기준 이미지 프레임 이나 긴 기준 이미지 프레임 은 기준 이미지 프레임으로서 사용하기 적합하지 않다. 따라서, 전자 기기는 SE 블렌딩 동작 (230b) 후 출력되는 단일 노출된 블렌딩된 긴 이미지 프레임 을 기준 이미지 프레임으로서 선택할 수 있고, 이때 단일 노출된 블렌딩된 긴 이미지 프레임 은 기준 이미지 프레임으로서 사용하기 적합한 EV+0 노출 레 벨을 가진 블렌딩된 이미지 프레임이다. 도 2d는 기준 선택 동작의 다른 예시적 프로세스(260b)를 보다 상세히 도시한다. 두 프로세스들(260a- 260b)이 모두 큰 섀도우 영역 테스트 및 잔차 포화된 모션 테스트를 포함한다는 점에서, 프로세스 (260b)는 프로세스(260a)와 유사하다. 그러나, 도 2d에서, 잔차 포화된 모션 테스트는 도 2c에서와 같이 큰 섀도우 영역 테스트 이후가 아닌 이전에 수행된다. 프로세스(260b)의 결과는 프로세스(260a)의 결과와 동일할 수 있다: 기준 이미지 프레임은 짧은 기준 이미지 프레임 , 긴 기준 이미지 프레임 , 또는 단 일 노출된 블렌딩된 긴 이미지 프레임 으로부터 선택된다. 도 2a로 돌아가면, 기준 이미지 프레임이 선택된 후, 전자 기기는 엣지(edge) 노이즈 필터링 동작을 수행한다. 엣지 노이즈 필터링은 전자 기기가 공간적 노이즈 제거 및 엣지 개선을 수행하여 기준 이미지프레임에서 노이즈를 제거하고 엣지의 모양을 개선하도록 하는 포스트 프로세싱 동작이다. 엣지 노이즈 필터링 에 대한 다양한 기법들은 이 기술 분야에 알려져 있다. 전자 기기는 또한, 기준 이미지 프레임을 사용하여 하나 이상의 이미지 신호 처리(ISP) 동작들을 수행할 수 있다. 예를 들어, ISP 동작들은 렌즈 셰이딩(shading) 정정, 화이트 밸런싱, 모자이크 제거, RGB 매트릭스 정정, 감마 정정, YUV 변환, RGB 변환 등과 같은 다양한 이미지 처리 기능들을 포함할 수 있다. 일부 실시예들 에서, ISP 동작들은 톤(tone) 매핑 동작을 포함할 수 있다. LDR 장치들 상에서 HDR 이미지들을 표시하기 위해, 톤 매핑 동작은 오리지널 실제 장면의 시각적 인상들(impressions)과 디테일들이 충실하게 재생되는 방식 으로, 상위 비트 Bayer 데이터(예를 들어, 래디언스(radiance) 맵)를 표준 하위 비트 정수 Bayer 데이터(예를 들어, 10 비트 데이터)로 변환하기 위해 사용될 수 있다. 톤 매핑 동작을 수행하기 위해 다양한 기법들이 사용 될 수 있다. 도 2h는 톤 매핑 동작의 한 예시적 구현예를 보다 상세하게 도시한다. 도 2h에 도시된 바와 같이, 톤 매핑 동작은 휘도 압축 단계 및 콘트라스트(contrast) 개선 단계를 포함한다. 휘도 압축 단계의 일부 실시예들에서, 전자 기기는 휘도 데이터를 압축하고 HDR 디테일들을 보존하기 위해 다음과 같은 함수를 사용할 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "및 는 장면의 최소 및 최대 휘도들을 나타내고, 및 는 최대 및 최소 타깃 레벨들을 나타내고, 는 매핑된 이미지의 전반적 밝기를 제어한다. 어떤 경우, 는 로그 평균(log-average) 휘도가 다음과 같이 주요 값 k로 매핑될 것이라는 전제에 기반하여 자동으로 선택될 수 있다."}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "여기서 주요 값은 다음과 같이 계산될 수 있다:"}
{"patent_id": "10-2020-0113210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "수학식 에서, k1 및 k2의 값들은 경험적으로 결정될 수 있고, 주요 값 k는 (0.2와 0.8 사이 등에서) 가변될 수 있다. 주요 값이 알려지면, 비선형 함수의 해를 구하는 식으로 값 가 결정될 수 있다. 휘도 압축 단계 를 통해, 전반적 밝기가 10 비트나 다른 하위 비트 범위로 압축된다. 어떤 시스템들에서, 표시하기 위해 압축된 휘도 데이터를 바로 렌더링하는 것은, 선형 양자화(quantization)를 사용하는 경우 콘트라스트 부족을 가져올 것이다. 선형 양자화는 이미지의 픽셀 분포를 고려하지 않고 실제 픽 셀 값들에 기반하여 픽셀들을 그룹짓는다. 픽셀 분포를 고려한 전통적 기법은 픽셀 집단 밀도를 동등하게 분포 시켜 픽셀들을 클러스터링하는 히스토그램 평활화이다. 그러나, 히스토그램 평활화는 콘트라스트나 일반적인 영 역들에 대한 과장을 일으킬 수 있다. 이러한 문제를 해결하기 위해, 선형 양자화 및 히스토그램 매칭으로부터 잘린 점들(cutting points)을 이용하여 양자화 시 잘린 점들을 보간(interpolate)하기 위해 콘트라스트 개선 동 작이 수행될 수 있다. 일부 실시예들에서, 콘트라스트 개선 동작은 매우 효율적인 회귀 이진 컷 (recursive binary cut) 방식을 이용한다. 콘트라스트 개선 동작은 선형 양자화 및 히스토그램 평활화 사 이에서 절충을 행한다. 상술한 바와 같이, 프로세스는 두 노출 레벨에서 촬영된 이미지 프레임들, 즉 짧고 긴 이미지 프레임들을 사용하여 수행된다. 일부 실시예들에서, 촬영된 이미지 프레임들에서 재현된 노출 레벨들의 수는 두 노출 레벨 을 넘을 수 있다. 그러한 경우, 동작들(210a-210b, 220a-220b, 230a-230b, 240a-240b, 250a-250b, 및 260)에 대한 반복 프로세스가 사용될 수 있다. 예를 들어, 도 2i는 동작들(210-260)이 다수의 노출 레벨들에서 촬영된 이미지 프레임들에 대해 반복적으로 수행되는 한 예시적 구현을 도시한다. 도 2i에 도시된 바와 같이, 이미지 프레임들은 초기에 4 개의 노출 레벨(가령, EV-3, EV-2, EV+0, 및 EV+1)로 촬영된다. 짧고 긴 노출 레벨들로서 노출 레벨 쌍들이 선택되고, 그 노출 레벨들의 쌍으로 이미지 프레임들에 대한 일회 반복으로 동작들(210- 260)이 수행된다. 반복의 결과들은 다른 노출 레벨의 이미지 프레임들과 짝을 이루며, 또 한번의 반복으로 동작들(210-260)이 수행된다. 이러한 프로세스는 마지막 반복이 기준 이미지 프레임의 최종 선택을 가져올 때까지 반복된다. 도 2a, 2b, 2c, 2d, 2e, 2f, 2g, 2h, 및 2i는 기준 이미지 프레임의 동적 선택을 위한 프로세스의 일 예를 도 시하나, 이 도면들에 대해 다양한 변경이 이루어질 수 있다. 예를 들어, 프로세스가 하나의 기준 이미지 프레임을 선택하는 것으로서 보여지고 있으나, 다른 실시예들은 하나를 이상의 기준 이미지 프레임의 선택을 가 져올 수도 있다. 또한, 프로세스의 동작들은 전자 기기의 프로세서를 포함하는 전자 기기 또는 다른 장치의 어떤 적절한 구성요소(들) 또는 전자 기기의 이미지 센서에 의해 수행될 수 있다. 프로세스는 Bayer(“로우(raw) 포맷”) 도메인에서 촬영된 이미지 프레임들과 관련하여 위에서 기술되었다. YUV(“비주얼 포맷”) 도메인과 같은 다른 도메인들에서의 이미지 프레임들에 대해 동일하거나 유 사한 프로세싱이 수행될 수 있다. 그러나, Bayer 도메인에서와는 달리, 균등화 동작(210a)을 이용한 밝기 매칭 은 YUV 도메인에서의 선형성 부족으로 인해 간단한 곱셈 연산을 이용해서는 수행될 수 없을 것이다. 그 대신, 히스토그램 매칭(긴 프레임을 가짐) 동작이 이용될 수 있다. 도 3a 및 3b는 본 개시에 따른 기준 이미지 프레임의 동적 선택을 이용하여 구현될 수 있는 효과들의 예들을 도 시한다. 특히, 도 3a 및 3b는 종래의 이미지 처리 기법들을 사용하여 촬영된 장면의 이미지와 위에서 개시 된 실시예들 중 하나를 이용하여 촬영된 동일 장면의 이미지를 비교한 것을 도시한다. 도 3a에 도시된 바와 같이, 이미지는 종래의 HDR 동작을 이용하여 촬영 및 처리되었다. 도 3a에서 알 수 있다시피, 이미지는 포화된 영역 안에서 움직이는 손으로부터 비롯된 상당한 고스트 아티팩트들을 포함한 다. 반대로, 도 3b의 이미지는 상술한 바와 같은 프로세스를 이용하여 선택된 짧은 기준 이미지 프레 임을 사용하여 촬영 및 처리되었다. 결과적으로 이미지는 우수한 HDR 결과들을 제공하며 움직이는 손에서 어떠한 고스트 아티팩트들도 보이지 않는다. 도 3a 및 3b는 기준 이미지 프레임의 동적 선택을 이용하여 구현될 수 있는 효과들의 일 예를 도시하였으나, 도 3a 및 3b에 대한 다양한 변형이 있을 수 있다. 예를 들어, 도 3a 및 3b는 단지, 기준 이미지 프레임의 동적 선 택을 이용하여 획득될 수 있는 효과들의 유형에 대한 일 예를 도시했을 뿐이다. 장면들에 대한 이미지들은 매우 다양하며, 장면 및 그 구현에 따라 다른 결과들이 얻어질 수 있다. 도 4는 본 개시에 따른 기준 이미지 프레임의 동적 선택을 위한 예시적 방법을 도시한다. 설명의 편의를 위해, 상기 방법은 도 1에 도시된 전자 기기를 사용한 프로세스의 수행을 수반하는 것으로 기술 된다. 그러나 도 4에 도시된 방법이 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스템 내에 서도 사용될 수 있을 것이다. 도 4에 도시된 바와 같이, 단계 402에서 전자 기기의 적어도 하나의 이미지 센서를 사용하여 한 장면에 대한 여 러 이미지 프레임들이 획득된다. 이것은 예를 들어, 전자 기기의 프로세서가 촬영 요청을 수신한 후 적어도 하나의 카메라(센서)로 하여금 촬영 동작에서와 같이 짧고 긴 이미지 프레임들을 촬영하도록 하는 것을 포함할 수 있다. 상기 다수의 이미지 프레임들은 제1노출 레벨에서의 복수의 짧은 이미지 프레임들과, 제1노출 레벨보다 긴 제2노출 레벨에서의 복수의 긴 이미지 프레임들을 포함한다. 단계 404에서 짧은 기준 이미지 프레임 및 긴 기준 이미지 프레임은 다수의 이미지 프레임들을 이용하여 생성된 다. 이것은 예를 들어, 전자 기기의 프로세서가 균등화 동작들(210a-210b), 디고스팅 동작들(220a- 220b), SE 블렌딩 동작들(230a-230b), 디고스팅 동작들(240a-240b), 및 ME 블렌딩 동작들(250a-250b)을 수행하 여 짧은 기준 이미지 프레임 및 긴 기준 이미지 프레임 을 생성하는 것을 포함할 수 있다. 단계 406 에서 짧은 기준 이미지 프레임 또는 긴 기준 이미지 프레임이 기준 프레임으로서 선택된다. 이것은 예를 들어, 전자 기기의 프로세서가 프로세스(260a) 또는 프로세스(260b)를 포함할 수 있는 기준 선택 동작(26 0)을 수행함으로써 기준 프레임을 선택하는 것을 포함할 수 있다. 그러한 선택은 긴 이미지 프레임의 포화된 모 션의 양 및 짧은 이미지 프레임의 섀도우 영역의 크기에 기반할 수 있다. 장면의 최종 이미지가 단계 408에서 기준 프레임을 이용하여 생성된다. 이것은 예를 들어, 전자 기기의 프 로세서가 톤 매핑 동작을 포함할 수 있는 하나 이상의 ISP 동작들을 수행하는 것을 포함할 수 있다. 장면의 최종 이미지를 생성하기 위해 임의의 다른 바람직한 이미지 처리 동작들 역시 여기서 일어날 수 있다는 것을 알아야 한다. 장면의 최종 이미지는 단계 410에서 어떤 방식에 따라 저장, 출력, 또는 사용될 수 있다. 그것은 예를 들어, 전자 기기의 프로세서가 전자 기기의 디스플레이 상에 해당 장면의 최종 이미지를 표시하는 것을 포함할 수 있다. 그것은 예를 들어, 전자 기기의 프로세서가 전자 기기의 메모리 에 저장된 카메라 롤(roll)에 해당 장면의 최종 이미지를 저장하는 것을 포함할 수 있 다. 그것은 예를 들어, 전자 기기의 프로세서가 전자 기기로부터 전송될 텍스트 메시지, 이메일, 또는 다른 통신문에 상기 장면의 최종 이미지를 첨부하는 것을 포함할 수 있다. 물론, 장면의 최종 이 미지가 임의의 다른 방식이나 추가적 방식으로 사용될 수도 있다. 도 4는 기준 이미지 프레임의 동적 선택을 위한 방법의 일 예를 도시하고 있으나, 도 4에 대해 다양한 변 형이 있을 수 있다. 예를 들어 일련의 단계들이 도시되었지만, 도 4의 다양한 단계들이 중복되거나 나란히 발생 하거나, 상이한 순서로 일어나거나 여러 번 발생할 수도 있다. 위에서 다양한 동작들은 하나 이상의 장치들을 사용하여 수행되는 것이라고 기술하였으나, 그 동작들이 어떤 적 절한 방식으로 구현될 수도 있다는 것을 알아야 한다. 예를 들어, 전자 기기나 서버 내 기능들 각각 은 전자 기기나 서버의 적어도 하나의 프로세서에 의해 실행되는 하나 이상의 소프트웨어 애플 리케이션들이나 다른 소프트웨어 명령어들을 이용하여 구현 또는 지원될 수 있다. 다른 실시예들에서, 전자 기 기나 서버 내 기능들 중 적어도 일부는 전용 하드웨어 구성요소들을 사용하여 구현 또는 지원될 수 있다. 일반적으로 각각의 장치의 동작들은 어떤 적절한 하드웨어나 어떤 적절한 하드웨어 및 소프트웨어/펌웨어 명령어들의 조합을 이용하여 수행될 수 있다. 본 개시는 다양한 실시예들을 참조하여 기술되었지만, 당업자에게 다양한 변경 및 수정안이 제안될 수 있다. 본 개시는 그러한 변경 및 수정이 첨부된 청구범위 안에 드는 것으로 포괄하도록 되어 있다.도면 도면1 도면2a 도면2b 도면2c 도면2d 도면2e 도면2f 도면2g 도면2h 도면2i 도면3a 도면3b 도면4"}
{"patent_id": "10-2020-0113210", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시 및 그 이점들에 대한 보다 완전한 이해를 위해, 지금부터 첨부된 도면과 함께 이하의 설명이 이루어지 며, 도면에서 동일 참조 번호는 동일 부품을 나타낸다. 도 1은 본 개시에 따른 전자 기기를 포함하는 예시적 네트워크 구성을 도시한다. 도 2a, 2b, 2c, 2d, 2e, 2f, 2g, 2h, 및 2i는 본 개시에 따른 기준 이미지 프레임의 동적 선택을 위한 예시적 프로세스를 예시한다. 도 3a 및 3b는 본 개시에 따른 기준 이미지 프레임의 동적 선택을 이용하여 구현될 수 있는 효과들의 예들을 도 시한다. 도 4는 본 개시에 따른 기준 이미지 프레임의 동적 선택을 위한 예시적 방법을 도시한다."}
