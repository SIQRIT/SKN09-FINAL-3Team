{"patent_id": "10-2021-0058325", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0053864", "출원번호": "10-2021-0058325", "발명의 명칭": "이미지 다중 캡션 자동 생성 방법 및 시스템", "출원인": "한국전자기술연구원", "발명자": "김보은"}}
{"patent_id": "10-2021-0058325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지 다중 캡션 자동 생성 시스템이, 이미지를 이용하여 캡션주의지도(Caption Attention Map)를 생성하는 단계;이미지 다중 캡션 자동 생성 시스템이, 생성된 캡션주의지도를 잠재 공간(latent space)에 프로젝션하여 잠재변수(latent variable)로 변환하는 단계;이미지 다중 캡션 자동 생성 시스템이, 잠재 변수를 샘플링하는 단계; 이미지 다중 캡션 자동 생성 시스템이, 샘플링된 잠재 변수를 이용하여 이미지의 특성을 추출하는 단계;이미지 다중 캡션 자동 생성 시스템이, 추출된 특성으로부터 도출된 문장과 ground truth 문장 간의 loss를 계산하는 단계;이미지 다중 캡션 자동 생성 시스템이, loss를 줄이는 방향으로 이미지의 캡션 생성을 학습하는 단계;를 포함하는 이미지 다중 캡션 자동 생성 모델 학습 방법."}
{"patent_id": "10-2021-0058325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,생성 단계는,이미지를 CNN에 입력하여 이미지 특성을 추출하는 단계;추출된 이미지 특성을 이용하여 단어를 생성할 때 영향을 주는 이미지의 부분을 나타낸 제1 지도와 이미지 정보가 영향을 주는 정도를 나타낸 제2 지도를 생성하는 단계; 및제1 지도와 제2 지도를 가중합하여, 캡션주의지도를 생성하는 단계;를 포함하는 것을 특징으로 하는 이미지 다중 캡션 자동 생성 모델 학습 방법."}
{"patent_id": "10-2021-0058325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,제1 지도와 제2 지도 생성 단계는,추출된 이미지 특성을 RNN에 입력하여 제1 지도와 제2 지도를 생성하는 것을 특징으로 하는 이미지 다중 캡션자동 생성 모델 학습 방법."}
{"patent_id": "10-2021-0058325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "에 있어서,잠재 변수는,벡터 크기를 설정 가능하며,레이어는,종류와 개수를 설정 가능한 것을 특징으로 하는 이미지 다중 캡션 자동 생성 모델 학습 방법."}
{"patent_id": "10-2021-0058325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "이미지를 입력받는 획득부; 및이미지를 이용하여 캡션주의지도(Caption Attention Map)를 생성하고, 생성된 캡션주의지도를 잠재 공간(latentspace)에 프로젝션하여 잠재 변수(latent variable)로 변환하며, 잠재 변수를 샘플링하고, 샘플링된 잠재 변수를 이용하여 이미지의 특성을 추출하며, 추출된 특성으로부터 도출된 문장과 ground truth 문장 간의 loss를 계산하고 loss를 줄이는 방향으로 이미지의 캡션 생성을 학습하는 프로세서;를 포함하는 것을 특징으로 하는 이미지 다중 캡션 자동 생성 시스템."}
{"patent_id": "10-2021-0058325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "이미지 다중 캡션 자동 생성 시스템이, 잠재 공간에서 잠재 변수를 샘플링하는 단계;이미지 다중 캡션 자동 생성 시스템이, 샘플링된 잠재 변수를 이용하여 이미지의 특성을 추출하는 단계;이미지 다중 캡션 자동 생성 시스템이, 추출된 특성으로부터 문장을 도출하여 캡션을 생성하는 단계;를 포함하는 것을 특징으로 하는 이미지 다중 캡션 자동 생성 방법."}
{"patent_id": "10-2021-0058325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "이미지를 입력받는 획득부; 및잠재 공간에서 잠재 변수를 샘플링하고, 샘플링된 잠재 변수를 이용하여 이미지의 특성을 추출하고, 추출된 특성으로부터 문장을 도출하여 캡션을 생성하는 프로세서;를 포함하는 것을 특징으로 하는 이미지 다중 캡션 자동생성 시스템."}
{"patent_id": "10-2021-0058325", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이미지 다중 캡션 자동 생성 방법 및 시스템이 제공된다. 본 발명의 실시예에 따른 이미지 다중 캡션 자동 생성 모델 학습 방법은, 이미지를 이용하여 캡션주의지도를 생성하고, 생성된 캡션주의지도를 잠재 공간에 프로젝션하 여 잠재 변수로 변환하며, 잠재 변수를 이용하여 가이드 맵을 도출하고, 가이드맵과 이미지를 이용하여 이미지의 캡션 생성을 학습한다. 이에 의해, 이미지가 가지는 다양한 특징을 설명하고, 다양한 표현을 포함하는 다수의 캡 션을 자동으로 생성할 수 있게 된다."}
{"patent_id": "10-2021-0058325", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 관련 기술에 관한 것으로, 더욱 상세하게는 인공지능 모델을 활용하여 이미지의 캡션을 자 동으로 생성하여 주는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2021-0058325", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어 인공지능 기술을 활용한 이미지 캡션 자동 생성 기술이 등장하였다. 이 기술은 이미지 당 한 개의 캡 션을 정확하게 생성하는데 초점이 맞추어져 있다. 이 기술은 캡션 생성의 정확도를 높이는 것을 기준으로 학습되는 것을 지향하여, 유사한 이미지에 동일한 일반 적이고 개략적인 내용의 캡션이 생성되는 경우가 빈번하다.이에 따라, 한 개의 이미지에 대해 다양한 표현을 포함하는 여러 개의 캡션을 생성하거나, 이미지가 가지는 다 양한 특징을 설명하는 여러 개의 캡션을 생성하는 데는 한계가 있다. 선행기술문헌 비특허문헌 (비특허문헌 0001) Lu, Jiasen, et al. \"Knowing when to look: Adaptive attention via a visual sentinel for image captioning.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017. (비특허문헌 0002) Xu, Kelvin, et al. \"Show, attend and tell: Neural image caption generation with visual attention.\" International conference on machine learning. PMLR, 2015. (비특허문헌 0003) Chen, Hui, et al. \"Show, Observe and Tell: Attribute-driven Attention Model for Image Captioning.\" IJCAI. 2018."}
{"patent_id": "10-2021-0058325", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 목적은, 이미지가 가지는 다양한 특징을 설명하고, 다양한 표현을 포함하는 다수의 캡션을 생성할 수 있는 방법 및 시스템을 제공함에 있다."}
{"patent_id": "10-2021-0058325", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른, 이미지 다중 캡션 자동 생성 모델 학습 방법은, 이미 지를 이용하여 캡션주의지도(Caption Attention Map)를 생성하는 단계; 생성된 캡션주의지도를 잠재 공간 (latent space)에 프로젝션하여 잠재 변수(latent variable)로 변환하는 단계; 잠재 변수를 이용하여 가이드 맵 을 도출하는 단계; 가이드맵과 이미지를 이용하여 이미지의 캡션 생성을 학습하는 단계;를 포함한다. 생성 단계는, 이미지를 CNN에 입력하여 이미지 특성을 추출하는 단계; 추출된 이미지 특성을 이용하여 단어를 생성할 때 영향을 주는 이미지의 부분을 나타낸 제1 지도와 이미지 정보가 영향을 주는 정도를 나타낸 제2 지도 를 생성하는 단계; 및 제1 지도와 제2 지도를 가중합하여, 캡션주의지도를 생성하는 단계;를 포함할 수 있다. 제1 지도와 제2 지도 생성 단계는, 추출된 이미지 특성을 RNN에 입력하여 제1 지도와 제2 지도를 생성할 수 있 다. 변환 단계는, 캡션주의지도를 레이어에 통과시켜, 평균과 분산에 해당하는 잠재 변수로 변환할 수 있다. 잠재 변수는, 벡터 크기를 설정 가능하며, 레이어는, 종류와 개수를 설정 가능할 수 있다. 도출 단계는, 잠재 변수을 샘플링하는 단계; 및 샘플링된 잠재 변수를 레이어에 통과시켜, 가이드맵을 도출하는 단계;를 포함할 수 있다. 샘플링 단계는, 평균으로부터 일정 범위 이내에서 잠재 변수을 샘플링하고, 레이어는, 종류와 개수를 설정 가능 할 수 있다. 학습 단계는, 이미지에 가이드맵을 결합하는 단계; 가이드맵이 결합된 이미지의 특성을 추출하는 단계; 추출된 특성으로부터 도출된 문장과 ground truth 문장 간의 loss를 계산하는 단계; loss를 줄이는 방향으로 학습하는 단계;를 포함할 수 있다. 결합 단계는, 행렬의 concatenation 또는 multiply를 이용하여, 이미지에 가이드맵을 결합할 수 있다. 한편, 본 발명의 다른 실시예에 따른, 이미지 다중 캡션 자동 생성 시스템은, 이미지를 입력받는 획득부; 및 이 미지를 이용하여 캡션주의지도(Caption Attention Map)를 생성하고, 생성된 캡션주의지도를 잠재 공간(latentspace)에 프로젝션하여 잠재 변수(latent variable)로 변환하며, 잠재 변수를 이용하여 가이드 맵을 도출하고, 가이드맵과 이미지를 이용하여 이미지의 캡션 생성을 학습하는 프로세서;를 포함한다. 한편, 본 발명의 다른 실시예에 따른, 이미지 다중 캡션 자동 생성 방법은, 잠재 공간에서 잠재 변수을 샘플링 하는 단계; 샘플링된 잠재 변수를 레이어에 통과시켜, 가이드맵을 도출하는 단계; 가이드맵과 이미지를 학습된 인공지능 모델에 입력하여, 캡션을 생성하는 단계;를 포함한다. 한편, 본 발명의 다른 실시예에 따른, 이미지 다중 캡션 자동 생성 시스템은, 이미지를 입력받는 획득부; 및 잠 재 공간에서 잠재 변수을 샘플링하고, 샘플링된 잠재 변수를 레이어에 통과시켜 가이드맵을 도출하며, 가이드맵 과 이미지를 학습된 인공지능 모델에 입력하여 캡션을 생성하는 프로세서;를 포함한다."}
{"patent_id": "10-2021-0058325", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상 설명한 바와 같이, 본 발명의 실시예들에 따르면, 이미지가 가지는 다양한 특징을 설명하고, 다양한 표현 을 포함하는 다수의 캡션을 자동으로 생성할 수 있게 된다. 특히, 본 발명의 실시예들에 따르면, 매우 많은 양의 영상(동영상, 이미지) 컨텐츠에서 원하는 영상이나 영상의 일부분을 검색 할 때, 사용자들이 다양한 표현을 이용해 검색하는 것이 가능하며, 사용자가 검색하고자 하는 내 용이 이미지의 일부분에 속해있거나 특징 중의 하나여도 검색이 가능하게 된다. 또한, 본 발명의 실시예들에 따르면, 영상 자막 생성이나 시각장애인 상황 설명 서비스에서 유사한 이미지에 대 해 다양한 다른 캡션을 생성하여, 시청자가 동일한 설명을 계속 접할 때 느끼는 지루함을 저감시킬 수 있게 된 다."}
{"patent_id": "10-2021-0058325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 본 발명의 실시예에서는, 이미지의 다양한 특징을 설명하고, 다양한 표현을 포함하는 여러 개의 캡션을 생성할 수 있는 딥러닝 모델을 활용한 이미지 다중 캡션 자동 생성 방법 및 시스템을 제시한다. 본 발명의 실시예에서 사용하는 딥러닝 모델은 VAE(Variational Autoencoder) 기반의 모델이다. VAE의 기본 구 조를 도 1에 제시하였다. 본 발명의 실시예에서는, VAE 구조에서 encoder의 출력, 즉 잠재 공간(latent space)으로 캡션주의지도(Caption Attention Map, CAM)를 프로젝션하는데, 이를 통해 캡션 추론을 위한 문장 생성 시 영상 영역 정보에 랜덤성을 추가하여 영상의 더욱 다양한 특징을 표현하는 문장들을 생성할 수 있게 된다. 이와 같은 기능을 수행하는 본 발명의 실시예에서 사용하는 딥러닝 모델의 전체 구조를 도 2에 제시하였고, 도 3에는 학습 프로세스의 각 단계를 흐름도로 나타내었다. 학습 과정에서는, 먼저 VAE의 encoder에서 학습 데이터(이미지-캡션 쌍)를 입력 받아(S110), 이미지를 이용하여 캡션주의지도를 생성한다.구체적으로, VAE의 encoder는 이미지를 CNN 구조(ResNet 등)에 입력하여 이미지 특성을 추출하고(S120), encoder에 사용되는 RNN 구조의 각 step에서는 이미지 특성을 입력받고 아래의 두 지도를 생성한 후 가중합 (weighted sum)하여, 캡션주의지도(Caption Attention Map, CAM)를 생성한다(S130). - 해당 step의 단어를 생성할 때 이미지의 어느 부분이 영향을 주는지를 나타내는 영역 지도(α) - 해당 step의 단어를 생성할 때 이미지 정보가 영향을 주는 정도를 나타내는 영향 지도(1-β)"}
{"patent_id": "10-2021-0058325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "(k = 이미지 영역 분할 수) 도 4에는 캡션주의지도 생성 방법을, 도 5에는 캡션주의지도 생성 결과를, 각각 예시하였다. 다음, S130단계에서 생성된 캡션주의지도를 잠재 공간(latent space)에 프로젝션하여, 잠재 변수(latent variable)로 변환한다(S140). 구체적으로, 캡션주의지도를 레이어에 통과시켜, 평균과 분산에 해당하는 잠재 변 수로 변환한다. 여기서, 잠재 변수의 벡터 크기는 필요와 사양에 따라 적절하게 설정 가능하고, 레이어의 종류와 개수는 필요와 사양에 따른 변형이 가능하다. 이후, 잠재 공간에서 잠재 변수(z)를 샘플링하고, 샘플링된 잠재 변수를 레이어에 통과시켜 가이드맵(guide map, G)을 도출한다. 잠재 변수(z)의 샘플링은 평균값 근처(평균으로부터 일정 범위 이내)에서 수행되며, 가이드맵 도출을 위한 레이 어의 종류와 개수는 필요와 사양에 따른 변형이 가능하다. 다음, VAE의 decoder에서 가이드맵과 이미지를 입력받아 이미지의 캡션 생성을 학습한다(S150~S170). 구체적으로, 학습 과정은 이미지에 가이드맵을 결합하고, 가이드맵이 결합된 이미지가 CNN의 입력으로 들어가 이미지 영역 정보에 영향을 받은 이미지의 특성을 추출한다. 그리고, RNN 구조에 이미지 특성을 조건으로 입력하여 문장을 도출하고, \"ground truth 문장 - 도출된 문장\" 간 의 loss를 계산하면서, loss를 줄이는 방향으로 학습하게 된다. 여기서, 가이드맵과 이미지의 결합 방법은 행렬의 concatenation, multiply 등 여러 가지를 포함할 수 있다. 지금까지, 이미지의 다양한 특징을 설명하고, 다양한 표현을 포함하는 여러 개의 캡션을 생성할 수 있는 딥러닝 모델을 학습하는 과정에 대해 상세히 설명하였다. 이하에서는, 학습된 딥러닝 모델을 이용하여, 캡션을 추론하는 과정에 대해, 도 6을 참조하여 상세히 설명한다. 도 6은 추론 프로세스의 각 단계를 나타낸 흐름도이다. 추론 과정에서는, 먼저 잠재 공간에서 잠재 변수을 샘플링하고, 샘플링된 잠재 변수를 레이어에 통과시켜, 가이 드맵을 도출한다(S210). 구체적으로, 목적에 따라 잠재 변수(z)를 샘플링하는데, 1) 잠재 공간 안에서 거리가 멀리 떨어진 변수를 샘플 링하면, 서로 크게 다른 문장셋이 생성되도록 하고, 2) 잠재 공간 안에서 원점에 가까운 변수를 샘플링하면, 정 확도가 높은 문장이 생성되도록 할 수 있다. 다음, VAE의 decoder에서 가이드맵과 이미지를 입력받아, 문장을 생성하여 캡션으로 출력한다(S220~S230). 구체적으로, 가이드맵과 이미지를 결합하고, 가이드맵이 결합된 이미지가 CNN의 입력으로 들어가 이미지 영역 정보에 영향을 받은 이미지의 특성을 추출한다. 그리고, RNN 구조에 이미지 특성을 조건으로 입력하여 문장을 도출한다. 여기서, 가이드맵과 이미지의 결합 방법은 행렬의 concatenation, multiply 등 여러 가지를 포함할 수 있다. 지금까지, 이미지가 가지는 다양한 특징을 설명하고, 다양한 표현을 포함하는 다수의 캡션을 생성하는 방법에 대해 바람직한 실시예를 들어 상세히 설명하였다. 본 발명의 실시예에 따른 이미지 다중 캡션 자동 생성 방법은, 매우 많은 양의 영상(동영상, 이미지) 컨텐츠에 서 원하는 영상이나 영상의 일부분을 검색 할 때, 사용자들이 다양한 표현을 이용해 검색하는 것이 가능하고, 사용자가 검색하고자 하는 내용이 이미지의 일부분에 속해있거나 특징 중의 하나여도 검색을 가능하게 한다. 또한, 영상 자막 생성이나 시각장애인 상황 설명 서비스에서 유사한 이미지에 대해 다양한 다른 캡션을 생성하 여 시청자가 동일한 설명을 계속 접할 때 느끼는 지루함을 저감시킬 수 있다. 본 발명의 실시예에 따른 이미지 다중 캡션 자동 생성 방법은, 정지 영상, 녹화 동영상, 실시간으로 촬영하는 동영상 등에 모두 적용될 수 있으며, 구체적인 적용 분야의 예시는 다음과 같다. 문장 기반 영상 검색 다량의 영상/동영상 클립에서 원하는 영상 또는 영상의 일부를 문장을 통해 검색 비전 정보기반 상황 설명 (2-1) 시각 장애인용 스마트 글래스 (2-2) 자동차 주행 중 측/후면 상황 설명 (2-3) 가정용/보안용 CCTV영상-음성 변환 (2-4) 영상 컨텐츠 자막 자동 생성"}
{"patent_id": "10-2021-0058325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "(2-5) 영상 컨텐츠 줄거리 요약 이미지 태깅 (3-1) 대량의 이미지 데이터셋 자동 생성 ex. 뉴럴 네트워크용 데이터셋 (3-2) 데일리 로그 자동 생성(얼굴 인식, 메타데이터(gps,촬영 시간 등) 정보를 함께 이용하여 촬영 영상의 설명을 자동 저장) 도 7은 본 발명의 다른 실시예에 따른 이미지 다중 캡션 자동 생성 시스템의 블럭도이다. 본 발명의 다른 실시예에 따른 이미지 다중 캡션 자동 생성 시스템은, 도 7에 도시된 바와 같이, 통신부, 출력부, 프로세서, 입력부 및 저장부를 포함하는 컴퓨팅 시스템으로 구현할 수 있다. 통신부는 외부 기기와 외부 네트워크로부터 학습 데이터, 추론 데이터를 입력받기 위한 통신 수단이다. 입 력부는 사용자 명령을 입력받기 위한 입력 수단이고, 출력부는 이미지 다중 캡션 자동 생성 과정 및 결과를 표시하기 위한 디스플레이이다. 프로세서는 전술한 이미지 다중 캡션 자동 생성을 위한 딥러닝 모델을 학습시키고, 학습된 딥러닝 모델을 이용하여 다중 캡션을 자동으로 생성하기 위한 CPU와 GPU들이다. 저장부는 프로세서가 동작함에 있어 필요한 저장 공간을 제공한다. 한편, 본 실시예에 따른 장치와 방법의 기능을 수행하게 하는 컴퓨터 프로그램을 수록한 컴퓨터로 읽을 수 있는 기록매체에도 본 발명의 기술적 사상이 적용될 수 있음은 물론이다. 또한, 본 발명의 다양한 실시예에 따른 기 술적 사상은 컴퓨터로 읽을 수 있는 기록매체에 기록된 컴퓨터로 읽을 수 있는 코드 형태로 구현될 수도 있다. 컴퓨터로 읽을 수 있는 기록매체는 컴퓨터에 의해 읽을 수 있고 데이터를 저장할 수 있는 어떤 데이터 저장 장 치이더라도 가능하다. 예를 들어, 컴퓨터로 읽을 수 있는 기록매체는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광디스크, 하드 디스크 드라이브, 등이 될 수 있음은 물론이다. 또한, 컴퓨터로 읽을 수 있는 기록매체 에 저장된 컴퓨터로 읽을 수 있는 코드 또는 프로그램은 컴퓨터간에 연결된 네트워크를 통해 전송될 수도 있다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2021-0058325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다.부호의 설명 310 : 통신부 320 : 출력부 330 : 프로세서 340 : 입력부 350 : 저장부"}
{"patent_id": "10-2021-0058325", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에서 사용하는 VAE의 기본 구조, 도 2는 본 발명의 실시예에서 사용하는 다중 캡션 생성을 위한 딥러닝 모델의 전체 구조, 도 3은 학습 프로세스의 단계 별 흐름도, 도 4는 캡션주의지도 생성 방법, 도 5는 캡션주의지도 생성 결과, 도 6은 추론 프로세스의 단계 별 흐름도, 그리고, 도 7은 본 발명의 다른 실시예에 따른 이미지 다중 캡션 자동 생성 시스템의 블럭도이다."}
