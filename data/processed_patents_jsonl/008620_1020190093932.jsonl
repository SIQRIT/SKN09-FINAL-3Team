{"patent_id": "10-2019-0093932", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0015299", "출원번호": "10-2019-0093932", "발명의 명칭": "기기의 운전상태 분석 시스템", "출원인": "단국대학교 산학협력단", "발명자": "최덕기"}}
{"patent_id": "10-2019-0093932", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기기의 운전상태 분석 시스템에 있어서,상기 기기의 동작에 따라 감지되는 센싱데이터가 획득되는 감지부;상기 센싱데이터에 대하여 주파수 변환을 수행하고, 상기 주파수 변환 결과에 기초하여 이미지데이터가 생성되는 이미지생성부;상기 이미지데이터에 대한 전처리를 통해 학습데이터셋이 획득되는 전처리부;인공신경망(Artificial neural network, ANN)을 이용하여 상기 인공신경망에 입력된 상기 학습데이터셋에 대하여, 상기 기기의 운전상태에 대한 정량화데이터가 출력되도록 학습이 수행되는 학습부; 및상기 학습 결과에 따라 생성된 분석모델을 이용하여 상기 기기의 운전상태가 분석되는 분석부;가 포함되는 기기의 운전상태 분석 시스템."}
{"patent_id": "10-2019-0093932", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 센싱데이터에는 상기 기기에 대한 x축 가속도 데이터, y축 가속도 데이터 및 사운드데이터 중 적어도 어느하나가 포함되는 기기의 운전상태 분석 시스템."}
{"patent_id": "10-2019-0093932", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 전처리부에서는 상기 이미지데이터에 대한 크기조정이 수행되며, 상기 크기가 조정된 이미지데이터에 대한그레이스케일 이미지가 획득되며, 상기 그레이스케일 이미지에 대하여 가로 방향 및 세로 방향으로 수행되는 이미지시프팅에 기초하여 상기 학습데이터셋이 생성되는 기기의 운전상태 분석 시스템."}
{"patent_id": "10-2019-0093932", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 인공신경망에는 입력 레이어, 다수의 필터들이 구비되어 특징 맵 생성을 위한 컨볼루션 레이어, 상기 컨볼루션 레이어로부터 생성된 특징 맵에 대한 풀링 연산이 수행되는 풀링 레이어, 차원 축소를 위한 플래튼 레이어및 출력 레이어가 포함되는 기기의 운전상태 분석 시스템."}
{"patent_id": "10-2019-0093932", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 인공신경망은 상기 입력 레이어, 제 1 컨볼루션 레이어, 제 2 컨볼루션 레이어, 제 1 풀링 레이어, 제 2풀링 레이어, 제 3 컨볼루션 레이어, 제 3 풀링 레이어, 제 4 컨볼루션 레이어, 제 4 풀링 레이어, 플래튼 레이어 및 출력 레이어가 순차적으로 연결된 구조로 형성되며,상기 제 1 컨볼루션 레이어의 필터 크기와 상기 제 2 컨볼루션 레이어 내지 제 4 컨볼루션 레이어의 필터 크기는 서로 상이하고, 상기 컨볼루션 레이어 각각에는 ReLU(Rectified linear unit) 활성화 함수가 적용되는 기기의 운전상태 분석 시스템."}
{"patent_id": "10-2019-0093932", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템은 기기의 동작에 따라 감지되는 센싱데이터가 획득되 는 감지부, 센싱데이터에 대하여 주파수 변환을 수행하고, 주파수 변환 결과에 기초하여 이미지데이터가 생성되 는 이미지생성부, 이미지데이터에 대한 전처리를 통해 학습데이터셋이 획득되는 전처리부, 인공신경망 (Artificial neural network, ANN)을 이용하여 인공신경망에 입력된 학습데이터셋에 대하여, 기기의 운전상태에 대한 정량화데이터가 출력되도록 학습이 수행되는 학습부 및 학습 결과에 따라 생성된 분석모델을 이용하여 기기 의 운전상태가 분석되는 분석부가 포함될 수 있다."}
{"patent_id": "10-2019-0093932", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 기기의 운전상태 분석 시스템에 관한 것으로, 더욱 상세하게는 기기로부터 센싱된 데이터를 주파수 변환에 따라 이미지 형태로 추출하고, 추출된 이미지를 학습된 인공신경망에 입력시킴으로써 기기의 운전상태가 분석될 수 있는 기기의 운전상태 분석 시스템에 관한 것이다."}
{"patent_id": "10-2019-0093932", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "4차 산업혁명의 진전에 따라 각종 센서가 장착된 스마트 기기가 급속도로 증가하고 있으며 그에 대한 관리와 감 독이 중요하고도 시급한 문제로 떠오르고 있다. 각종 센서 또는 측정기기의 조합으로 대변되는 산업, 주거 시설, 및 신재생 에너지 산업 등에서 사용되는 스마트 기기는 대부분 직접 관리하기 어려운 곳에 설치되어 있거 나 다수의 센서가 장착된 복잡한 시스템으로 제작되고 있다. 따라서 기기의 운전상태를 파악하기 위해 종래의 기술에서는 다양한 센서로부터 나오는 자료와 CCTV 등에서 송출하는 영상 자료 등을 관리자가 지속해서 관찰해 야 하므로 시간과 경비가 많이 들고, 관리자의 능력에 따라 판정 결과의 통계적 편차가 크게 나타날 수도 있었 다. 한편, 인공지능의 사용에서조차도 종래기술에서는 센서로부터 얻은 시계열 자료를 그대로 이용하거나 시계열 자 료를 단순 주파수 자료로 변환하여 사용한다. 이러한 경우에는 자료가 단순히 수치 자료로 변환되기 때문에 양 이 너무 많고, 숫자로만 표시된 내용을 인간 관리자가 이해할 수 없다는 단점이 있다. 따라서 인공지능에 의해 서 결정된 기기의 운전상태를 파악하기 위해서 인간 관리자가 각종 수치에 관한 확인을 반복해야 하는 한계점이 노출된다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 대한민국 공개특허공보 제10-2007-0077227호 (2007.07.26 공개)"}
{"patent_id": "10-2019-0093932", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 바와 같은 기술 개발 요구에 따라 안출된 것으로서, 상세하게는 별도의 감독자나 관리자에 대 한 과중한 업무를 경감시키고 감독자 혹은 관리자 별로 상이한 관리능력 차이로 인한 오류로 인하여 생길 수 있 는 경제적 손실을 최소화하고자 함에 그 목적이 있다. 또한, 기기로부터 센싱을 통해 획득된 데이터를 주파수 변환한 결과에 기초하여 생성된 이미지 형태의 데이터를 이용함으로써 학습 속도 및 정확성을 향상시키고자 함에 그 목적이 있다. 본 발명에서 이루고자 하는 기술적 목적들은 이상에서 언급한 사항들로 제한되지 않으며, 언급하지 않은 또 다"}
{"patent_id": "10-2019-0093932", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "른 기술적 과제들은 이하 설명할 본 발명의 실시 예들로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에 의해 고려될 수 있다."}
{"patent_id": "10-2019-0093932", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예로써, 기기의 운전상태 분석 시스템이 제공될 수 있다. 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템은 기기의 동작에 따라 감지되는 센싱데이터가 획득 되는 감지부, 센싱데이터에 대하여 주파수 변환을 수행하고, 주파수 변환 결과에 기초하여 이미지데이터가 생성 되는 이미지생성부, 이미지데이터에 대한 전처리를 통해 학습데이터셋이 획득되는 전처리부, 인공신경망 (Artificial neural network, ANN)을 이용하여 인공신경망에 입력된 학습데이터셋에 대하여, 기기의 운전상태에 대한 정량화데이터가 출력되도록 학습이 수행되는 학습부 및 학습 결과에 따라 생성된 분석모델을 이용하여 기 기의 운전상태가 분석되는 분석부가 포함될 수 있다. 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 센싱데이터에는 기기에 대한 x축 가속도 데이터, y축 가속도 데이터 및 사운드데이터 중 적어도 어느 하나가 포함될 수 있다. 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 전처리부에서는 이미지데이터에 대한 크 기조정이 수행되며, 크기가 조정된 이미지데이터에 대한 그레이스케일 이미지가 획득되며, 그레이스케일 이미지에 대하여 가로 방향 및 세로 방향으로 수행되는 이미지시프팅에 기초하여 학습데이터셋이 생성될 수 있다. 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 인공신경망에는 입력 레이어, 다수의 필 터들이 구비되어 특징 맵 생성을 위한 컨볼루션 레이어, 컨볼루션 레이어로부터 생성된 특징 맵에 대한 풀링 연 산이 수행되는 풀링 레이어, 차원 축소를 위한 플래튼 레이어 및 출력 레이어가 포함될 수 있다. 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 인공신경망은 입력 레이어, 제 1 컨볼루 션 레이어, 제 2 컨볼루션 레이어, 제 1 풀링 레이어, 제 2 풀링 레이어, 제 3 컨볼루션 레이어, 제 3 풀링 레 이어, 제 4 컨볼루션 레이어, 제 4 풀링 레이어, 플래튼 레이어 및 출력 레이어가 순차적으로 연결된 구조로 형 성되며, 제 1 컨볼루션 레이어의 필터 크기와 제 2 컨볼루션 레이어 내지 제 4 컨볼루션 레이어의 필터 크기는 서로 상이하고, 컨볼루션 레이어 각각에는 ReLU(Rectified linear unit) 활성화 함수가 적용될 수 있다."}
{"patent_id": "10-2019-0093932", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시 예로서 제공되는 기기의 운전상태 분석 시스템에 따르면, 별도의 감독자나 관리자에 대한 과 중한 업무를 경감시키고 감독자 혹은 관리자 별로 상이한 관리능력 차이로 인한 오류로 인하여 생길 수 있는 경 제적 손실을 최소화할 수 있는 효과가 있다. 또한, 기기로부터 센싱을 통해 획득된 데이터를 주파수 변환한 결과에 기초하여 생성된 이미지 형태의 데이터를 이용함으로써 학습 속도 및 정확성을 향상시킬 수 있는 효과가 있다."}
{"patent_id": "10-2019-0093932", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 명세서 전체에서 어떤 부분 이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, \"그 중간에 다른 구성을 사이에 두고\" 연결되어 있는 경우도 포함한다. 아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시 예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 본 발명의 일 실시 예로써, 기기의 운전상태 분석 시스템이 제공될 수 있다. 본 명세서에서 운전상태의 분석 대 상이 되는 기기의 종류에는 제한이 없다. 즉, 기기의 동작에 따른 동작정보 혹은 기기 자체에 관한 정보를 센서 혹은 측정장비를 이용하여 획득할 수 있는 장치이면 모두 상기 기기에 해당될 수 있다. 예를 들면, 상기 기기는 풍력발전기일 수 있다. 도 10에 도시된 바와 같이 풍력발전기의 발전에 따라 발생되는 진동을 측정하기 위 해서는 풍력발전기의 발전부, 기어부 주위의 축 방향과 반경 방향에 소정의 센서가 부착될 수 있으며, 뿐만 아니라 기어부와 블레이드를 연결하는 베어링 에도 센서가 부착될 수 있다. 상기 기 어부는 블레이드의 회전력을 발전부로 전달하기 위한 것으로, 상기 기어부에는 저속축(low- speed shaft), 기어박스(gear box), 브레이크(brake) 등이 포함될 수 있다. 즉, 풍력발전기의 진동을 측정 하기 위한 곳이면 어떠한 부분에도 상기 센서가 부착될 수 있다. 다만, 상기 도 10은 예시적인 것으로 본 발명의 분석 시스템을 통해 운전상태의 분석 대상이 되는 기기는 전술한 바와 같이 풍력발전기에 제한되는 것은 아니다. 도 1은 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템을 나타낸 개념도이다. 도 1을 참조하면, 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템은 기기의 동작에 따라 감지되는 센싱데이터가 획득되는 감지부, 센싱데이터에 대하여 주파수 변환을 수행하고, 주파수 변환 결과에 기초하 여 이미지데이터가 생성되는 이미지생성부, 이미지데이터에 대한 전처리를 통해 학습데이터셋이 획득되는 전처리부, 인공신경망(Artificial neural network, ANN)을 이용하여 인공신경망에 입력된 학습데이터셋에 대하여, 기기의 운전상태에 대한 정량화데이터가 출력되도록 학습이 수행되는 학습부 및 학습 결과에 따라 생성된 분석모델을 이용하여 기기의 운전상태가 분석되는 분석부가 포함될 수 있다. 또한, 본원의 기기의 운전상태 분석 시스템 내의 구성요소 간 통신은 물론 기기 및 타 디바이스와의 통신이 수행될 수 있는 통신부 (미도시)가 더 포함될 수 있다. 상기 통신부의 통신 방식은 다양한 유선 혹은 무선 통신방법이 사용될 수 있고, 특정 통신 방법에 제한되는 것은 아니다. 또한, 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에는 상기 센싱데이터, 이미지데이터 등의 데이터들이 저장되고 관리될 수 있는 데이터베이스(미도시)가 더 포함될 수 있다. 감지부는 기기에 직접 부착되어 센싱데이터를 획득할 수 있고, 이와는 달리 기기에 부착되어 있지 않고 상 기 통신부를 통해 기기로부터 수신한 데이터를 변환하여 상기 센싱데이터를 획득할 수도 있다. 상기 감지부에서 획득되는 센싱데이터에는 기기에 대한 x축 가속도 데이터, y축 가속도 데이터 및 사운드 데이터 중 적어도 어느 하나가 포함될 수 있다. 즉, 기기 내 회전장치와 같은 구성요소 혹은 부품의 동작(Ex. 회전 등)에 따라 발생되는 기기 자체의 진동을 파악하기 위하여 상기 기기에 대한 x축 가속도 데이터, y축 가속 도 데이터가 사용될 수 있다. 또한, 상기와 같은 동작에 따라 발생되는 기기 자체의 소음을 파악하기 위하여 상 기와 같이 사운드데이터가 사용될 수 있다. 예를 들면, 기기가 흔들리는 경우에도 기기가 흔들리는 원인이 기기 의 동작에 따른 기기 자체의 진동에 의한 것인지 아니면 외부 요인(Ex. 충돌, 바람 등)에 따라 흔들리는 것인지 등을 파악하기 위하여 상기 x축 가속도 데이터 및 y축 가속도 데이터가 상기 센싱데이터로써 획득될 수 있다. 또한, 기기의 소음이 발생된 경우에도 상기 소음 발생의 원인이 기기 자체의 진동에 의한 것인지 아니면 기기 내부의 부품(Ex. fan)이 부러짐으로써 발생된 것인지 등을 파악하기 위하여 상기 사운드데이터가 상기 센싱데이 터로써 획득될 수 있다. 도 3 내지 도 5는 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 센싱데이터를 나타낸 예시도이다. 도 3은 기기의 동작에 따른 x축 가속도 데이터를 나타낸 예시도이며, 도 4는 기기의 동작에 따른 y 축 가속도 데이터를 나타낸 예시도이며, 도 5는 기기의 동작에 따른 사운드데이터를 나타낸 예시도이다. 도 3 내지 도 5의 (a)는 기기가 정상적으로 동작하는 경우에 나타나는 데이터를 나타내며, 도 3 내지 도 5의 (b)는 기계적 결함이 있는 경우 나타나는 데이터를 나타내며, 도 3 내지 도 5의 (c)는 기계적 결함 외의 영향이 있는 경우 나타나는 데이터의 상태를 나타낸 예시도이다. 즉, 도 3 내지 도 5에 도시된 바와 같이 상기 센싱데이터는 시계열(time-series) 데이터로써, 일종의 로우(raw) 데이터에 해당된다. 이미지생성부에서는 센싱데이터에 대한 주파수 변환이 수행되고, 주파수 변환 결과에 기초하여 이미지데이 터가 생성될 수 있다. 상기 이미지생성부에서 센싱데이터에 대한 주파수 변환은 다양한 방식이 사용될 수 있으나, 상기 주파수 변환은 고속푸리에변환(Fast fourier transform, FFT) 방식이 사용되는 것이 바람직하다.즉, FFT 방식에 따라 센싱데이터가 주파수 변환됨에 따라 각 주파수 성분의 강도를 주파수 스펙트럼으로 나타낼 수 있고, 이를 이미지 형태로 변환함으로써 상기 이미지데이터가 생성될 수 있다. 도 6 내지 도 8은 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 이미지데이터를 나타낸 예시도이다. 도 6은 기기의 동작에 따른 x축 가속도 데이터에 대하여 주파수 변환한 결과에 따라 생성된 이미지 데이터를 나타낸 예시도이며, 도 7은 기기의 동작에 따른 y축 가속도 데이터에 대하여 주파수 변환한 결과에 따 라 생성된 이미지 데이터를 나타낸 예시도이며, 도 8은 기기의 동작에 따른 사운드데이터에 대하여 주파수 변환 한 결과에 따라 생성된 이미지데이터를 나타낸 예시도이다. 도 6 내지 도 8의 (a)는 기기가 정상적으로 동작하 는 경우의 이미지데이터를 나타내며, 도 6 내지 도 8의 (b)는 기계적 결함이 있는 경우의 이미지데이터를 나타 내며, 도 6 내지 도 8의 (c)는 기계적 결함 외의 영향이 있는 경우 이미지데이터의 상태를 나타낸 예시도이다. 즉, 도 6 내지 도 8에 도시된 바와 같이 상기 이미지데이터는 주파수 변환 이미지일 수 있다. 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 전처리부에서는 이미지데이터에 대 한 크기조정이 수행되며, 크기가 조정된 이미지데이터에 대한 그레이스케일 이미지가 획득되며, 그레이스케일 이미지에 대하여 가로 방향 및 세로 방향으로 수행되는 이미지시프팅(image shifting)에 기초하여 학습데이터셋 이 생성될 수 있다. 즉, 전처리부에서는 먼저 이미지데이터의 크기가 조정될 수 있다. 예를 들어, 333 X 215 크기의 이미지데 이터가 90 X 50 크기로 변환될 수 있다. 상기 변환되는 이미지데이터의 크기는 다양하게 설정될 수 있다. 즉, 전처리부에서는 상기와 같이 90 X 50 크기는 물론 110 X 70 크기 또는 55 X 35 크기로도 조정될 수 있다. 상기 조정되는 이미지데이터의 크기는 학습 목표, 분석대상이 되는 기기의 종류 등에 따라 상이하게 설정될 수 있다. 다음으로, 전처리부에서는 크기가 조정된 이미지데이터가 그레이스케일(grayscale) 이미지로 변환될 수 있 다. 상기 그레이스케일 이미지는 단순히 검정과 흰색 두 가지 색만으로 표현될 수도 있지만, 이와는 달리 검정 과 흰색 사이의 점진적인 단계 범위로 명도 차이가 설정되도록 표현된 이미지일 수도 있다. 상기 그레이스케일 이미지는 이미지시프팅 처리될 수 있다. 즉, 전처리부에서는 가로 방향 및 세로 방향으 로 이미지시프팅 처리를 통해 이미지데이터를 확장(augmentation)할 수 있다. 이미지시프팅은 상기 가로 방향 및 세로 방향 외에도 다양한 방향으로 진행할 수 있지만, 주파수 변환에 따라 생성된 이미지데이터의 특성(예를 들면, x축을 기준으로 주파수 강도가 y축에 표시됨) 상 가로 방향 및 세로 방향으로만 이미지시프팅 처리를 하 는 것이 바람직하다. 즉, 이미지에 대한 이미지시프팅된 상태를 나타낸 도 9에서와 같이 이미지 분석 성능을 높 이기 위하여 상기와 같이 가로 방향 및 세로 방향으로만 이미지시프팅 처리가 수행될 수 있다. 시프팅 처리되는 가로 방향 및 세로 방향의 범위는 학습 목표, 분석대상의 기기 종류 등에 따라 상이하게 설정될 수 있다. 상기 학습부에서는 인공신경망(Artificial neural network, ANN)을 이용하여 인공신경망에 입력된 상기 학 습데이터셋에 대하여, 상기 기기의 운전상태에 대한 정량화데이터가 출력되도록 학습이 수행될 수 있다. 상기 인공신경망에는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network) 및 LSTM(Long Short-Term Memomory) 중 어느 하나가 포함될 수 있다. 뿐만 아니라, 상기 인공신경망은 CNN, RNN 및 LSTM 중 적어도 하나 이상이 결합되어 생성될 수 있다. 또한, 상기 학습부는 전술한 인공신경망 외에도 다양한 딥 러닝 알고리즘이 적용될 수 있다. 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 인공신경망에는 입력 레이어, 다수의 필 터들이 구비되어 특징 맵 생성을 위한 컨볼루션 레이어, 컨볼루션 레이어로부터 생성된 특징 맵에 대한 풀링 연 산이 수행되는 풀링 레이어, 차원 축소를 위한 플래튼 레이어 및 출력 레이어가 포함될 수 있다. 상기 컨볼루션 레이어(convolutional layer)는 컨볼루션 연산을 통해 객체의 특징을 나타내는 특징 맵을 생성하 는 필터에 해당될 수 있다. 즉, 상기 인공신경망은 컨볼루션 레이어에 입력된 이미지데이터 혹은 학습데이터셋 에 대하여 상기 이미지데이터를 형성하는 국부적인 패턴(local pattern)이 어떠한 형태로 존재하는지 검출함으 로써 이미지데이터의 특징을 검출할 수 있다. 상기 패턴은 이미지데이터 내에서 파형의 형태, 파고, 주기 등과 같이 인접 픽셀들 사이에 존재하는 특징(feature)에 해당될 수 있다. 상기 이미지데이터 내의 특징을 찾기 위해 스트라이드(stride)가 수행될 수 있는데, 상기 컨볼루션 레이어에서 사용되는 스트라이드 사이즈는 다양하게 설 정될 수 있다. 상기 인공신경망에는 적어도 하나 이상의 풀링 레이어(pooling layer)이 더 포함될 수 있다. 상기 풀링 레이어 에서는 컨볼루션 레이어의 출력 데이터의 크기를 줄이거나 특정 데이터를 강조하는 풀링연산이 수행될 수 있다.상기 풀링 레이어에는 맥스풀링 레이어(max pooling layer) 및 평균풀링 레이어(average pooling layer)가 포 함될 수 있다. 도 2는 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 인공신경망의 구조를 나타낸 예시 도이다. 도 2를 참조하면, 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 인공신경망은 입력 레 이어, 제 1 컨볼루션 레이어, 제 2 컨볼루션 레이어, 제 1 풀링 레이어, 제 2 풀링 레이어 , 제 3 컨볼루션 레이어, 제 3 풀링 레이어, 제 4 컨볼루션 레이어, 제 4 풀링 레이어 , 플래튼 레이어 및 출력 레이어가 순차적으로 연결된 구조로 형성되며, 제 1 컨볼루션 레이어 의 필터 크기와 제 2 컨볼루션 레이어 내지 제 4 컨볼루션 레이어의 필터 크기는 서로 상이하고, 컨볼루션 레이어 각각에는 ReLU(Rectified linear unit) 활성화 함수가 적용될 수 있다. 상기 ReLU(Rectified Linear Unit) 함수에는 Leaky-ReLU 활성화 함수가 포함될 수 있으며, ReLU 활성화 함수의 계수 는 다양한 값으로 실험을 통해 결정될 수 있다. 더욱 상세하게는 상기 인공신경망은 입력 레이어로부터 제 1 컨볼루션 레이어가 연결되고, 상기 제 1 컨볼루션 레이어의 출력이 제 2 컨볼루션 레이어에 입력되도록 순차적으로 연결되어 있다. 제 2 컨볼 루션 레이어의 출력은 제 1 풀링 레이어으로 입력되고, 제 1 풀링 레이어의 출력은 제 2 풀링 레이어로 입력되도록 연결된다. 제 2 풀링 레이어의 출력으로부터 제 3 컨볼루션 레이어가 연결 되고, 제 3 컨볼루션 레이어의 출력으로부터 제 3 풀링 레이어로 연결되며, 제 3 풀링 레이어의 출력으로부터 제 4 컨볼루션 레이어로 연결되며, 제 4 컨볼루션 레이어의 출력으로부터 제 4 풀링 레 이어로 연결되는 구조로 상기 인공신경망은 형성된다. 또한, 제 4 풀링 레이어의 출력은 플레튼 레이 어(flatten layer) 로 입력되고, 플레튼 레이어의 출력은 출력 레이어으로 입력된다. 제 1 컨볼루션 레이어의 필터 크기와 제 2 컨볼루션 레이어 내지 제 4 컨볼루션 레이어의 필터 크기는 서로 상이한데, 예를 들면 제 1 컨볼루션 레이어의 필터 크기는 (5, 5)일 수 있고, 제 2 컨볼루션 레이어 내지 제 4 컨볼루션 레이어의 필터 크기는 (2, 2)일 수 있다. 다만, 상기 필터 크기는 예시적 인 것에 불과하고 이에 제한되는 것은 아니다. 또한, 제 1 컨볼루션 레이어 및 제 2 컨볼루션 레이어(42 2)의 필터 개수는 32개, 제 3 컨볼루션 레이어의 필터 개수는 64개 및 제 4 컨볼루션 레이어의 필터 개수는 128개로 설정될 수 있다. 상기 필터 개수는 예시적인 것에 불과하며 학습 목적 및 기기의 종류 등에 따 라 달라질 수 있다. 즉, 제 1 컨볼루션 레이어 내지 제 4 컨볼루션 레이어의 필터 개수 및 필터의 크 기는 각각 상이하게 설정될 수 있다. 또한, 또한, 상기 제 1 컨볼루션 레이어 내지 제 4 컨볼루션 레이어 에 패딩(padding)이 적용될 수 있다. 상기 패딩 값은 모두 동일하게 설정될 수 있다. 상기 출력 레이어는 제 1 덴스 레이어(dense layer) (미도시), 제 2 덴스 레이어(미도시) 및 제 3 출력 레 이어(미도시)로 형성될 수 있다. 예를 들면, 상기 제 1 덴스 레이어는 플래튼 레이어로부터 연결되고, 출력 뉴 런 수가 1000개가 되고 활성화 함수로써 ReLU가 적용되도록 설정될 수 있다. 또한, 제 2 덴스 레이어는 제 1 덴 스 레이어의 출력이 입력되고, 출력 뉴런 수 500개, 활성화 함수로써 ReLU가 적용될 수 있다. 또한, 제 3 출력 레이어는 제 2 덴스 레이어의 출력이 입력되며, 출력 뉴런 수 2개 및 활성화 함수로써 softmax 함수가 적용될 수 있다. 상기 분석부에서는 학습부에서의 학습 결과에 기초하여 생성된 분석모델을 이용하여 입력된 이미지데 이터에 대한 정량화데이터가 출력될 수 있다. 또한, 출력된 정량화데이터에 기초하여 기기의 운전상태가 '정 상'인지 혹은 '비정상'인지가 출력될 수 있다. 상기 분석부에서의 출력 결과는 사용자 단말로 제공될 수 있다. 사용자는 기기의 운전상태를 감시하는 관리자 혹은 감독자일 수 있으며, 사용자 단말은 상기 사용자가 기 기의 운전상태 감시 혹은 관리를 위해 사용하는 장치를 지칭할 수 있다. 상기 사용자 단말에는 기기의 운전상태 분석 결과를 사용자에게 디스플레이나 사운드 신호 등을 통해서 제공할 수 있는 장치이면 모두 포함될 수 있다."}
{"patent_id": "10-2019-0093932", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성요소는 분산되어 실시될 수도 있으며, 마찬가지 로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상세한 설명보다는 후술하는 청구범위에 의하여 나타내어지며, 청구범위의 의미 및 범위 그리 고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어 야 한다."}
{"patent_id": "10-2019-0093932", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템을 나타낸 개념도이다. 도 2는 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 인공신경망의 구조를 나타낸 예시 도이다. 도 3 내지 도 5는 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 센싱데이터를 나타낸 예시도이다. 도 6 내지 도 8은 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 이미지데이터를 나타낸 예시도이다. 도 9는 본 발명의 일 실시 예에 따른 기기의 운전상태 분석 시스템에 있어서, 이미지에 대한 이미지시프팅된 상 태를 나타낸 예시도이다. 도 10은 기기의 일 예로써, 풍력발전기에 센서가 부착된 상태를 나타낸 예시도이다."}
