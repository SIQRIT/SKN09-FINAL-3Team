{"patent_id": "10-2022-0156747", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0074553", "출원번호": "10-2022-0156747", "발명의 명칭": "인공지능 알고리즘을 이용하여 화면해설방송을 자동으로 생성하는 방법 및 이를 위한 시스템", "출원인": "씨제이올리브네트웍스 주식회사", "발명자": "황중수"}}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "화면해설방송을 자동으로 생성하는 방법에 있어서,스크립트를 파싱하여 복수 개의 해설문장들 및 각 해설문장에 대응되는 타임코드를 추출하는 단계;추출한 해설문장을 기초로 해설음성을 생성하는 단계;원본영상 내 음성구간 및 무음구간을 추출하는 단계;상기 무음구간과 상기 타임코드를 매핑시키는 단계; 및상기 무음구간 내 상기 타임코드에 대응되는 해설음성을 합성하는 단계;를 포함하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 해설음성을 합성하는 단계 이전, 상기 해설음성의 재생길이가 상기 무음구간 내에 포함되도록 상기 해설음성의 재생길이를 조정하는 단계;를 더 포함하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 해설음성의 재생길이를 조정하는 단계는,상기 해설음성의 스케일을 축소시키는 방식 또는 상기 해설음성 내 포함된 무음구간 중 일부를 삭제하는 방식으로 이루어지는 것을 특징으로 하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 해설음성을 생성하는 단계는,텍스트 및 오디오 쌍으로 구성된 학습용 데이터셋을 기초로 기 학습된 인공지능 알고리즘이 상기 해설문장을 구성하는 텍스트로부터 해설음성을 생성하는 단계인 것을 특징으로 하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0074553-3-제1항에 있어서,상기 음성구간 및 무음구간을 추출하는 단계는,상기 원본영상의 믹스드 오디오로부터 음성 오디오만 추출하는 단계;상기 음성 오디오 중 음성이 포함된 구간 및 음성이 미포함된 구간을 구별하는 단계;를 포함하는 것을 특징으로 하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 무음구간과 상기 타임코드를 매핑시키는 단계는,상기 스크립트로부터 추출된 해설문장들 별 타임코드, 및 상기 원본영상으로부터 추출된 무음구간들의 순서를매핑하는 단계; 및상기 각 타임코드에 대응되는 각 해설음성이 각 무음구간 내에 삽입이 가능한지 여부를 확인하는 단계;를 포함하는 것을 특징으로 하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 스크립트로부터 추출된 해설문장들 별 타임코드, 및 상기 원본영상으로부터 추출된 무음구간들의 순서를매핑하는 단계는,각 타임코드의 시작시점 또는 종료시점 중 적어도 하나가, 상기 무음구간들 중 어느 임의의 무음구간 내에 포함되는지 여부를 확인함으로써 이루어지는 단계인 것을 특징으로 하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 스크립트로부터 추출된 해설문장들 별 타임코드, 및 상기 원본영상으로부터 추출된 무음구간들의 순서를매핑하는 단계는,각 타임코드의 시작시점 또는 종료시점과 상기 무음구간들 간의 유사도를 확인함으로써 이루어지는 단계인 것을특징으로 하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 각 타임코드에 대응되는 각 해설음성이 각 무음구간 내에 삽입이 가능한지 여부를 확인하는 단계는,임의의 무음구간 길이와, 상기 무음구간에 대응되는 해설음성의 길이를 비교하고, 상기 무음구간의 길이가 상기해설음성의 길이에 비해 더 큰 값을 가지는지 여부를 확인하는 단계인 것을 특징으로 하는,공개특허 10-2024-0074553-4-화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 각 타임코드에 대응되는 각 해설음성이 각 무음구간 내에 삽입이 가능한지 여부를 확인하는 단계는,임의의 해설음성의 시작시점과 상기 해설음성에 대응되는 무음구간의 시작시점 간 선후를 비교하거나, 또는 임의의 해설음성의 종료시점과 상기 해설음성에 대응되는 무음구간의 종료시점 간 선후를 비교함으로써 이루어지는 것을 특징으로 하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "화면해설방송을 자동으로 생성하는 방법에 있어서,스크립트를 파싱하여 복수 개의 해설문장들 및 각 해설문장에 대응되는 타임코드를 추출하는 단계;원본영상 내 음성구간 및 무음구간을 추출하는 단계;상기 무음구간과 상기 타임코드를 매핑시키는 단계;상기 추출한 무음구간에 대한 정보를 참고하여 각 무음구간에 대응되는 해설문장을 편집하는 단계;편집된 해설문장을 기초로 해설음성을 생성하는 단계; 및상기 무음구간 내 상기 해설음성을 합성하는 단계;를 포함하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 해설문장을 편집하는 단계는,상기 해설문장 중 일부 단어를 배제시키는 편집, 상기 해설문장 중 일부 조사를 생략하는 편집, 또는 상기 해설문장에 포함된 단어들 중 일부를 다른 단어로 대체하는 편집 중 적어도 하나를 실행하는 단계인 것을 특징으로하는,화면해설방송 생성 방법."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "화면해설방송을 생성하는 서비스 서버에 있어서, 상기 서비스 서버는 중앙처리유닛 및 메모리를 포함하며,상기 중앙처리유닛은, 상기 메모리에 저장되어 있는 화면해설방송 생성 방법을 실행시키기 위한 명령어들을 실행시키는 것을 특징으로 하되,상기 화면해설방송 생성 방법은,스크립트를 파싱하여 복수 개의 해설문장들 및 각 해설문장에 대응되는 타임코드를 추출하는 단계;추출한 해설문장을 기초로 해설음성을 생성하는 단계;공개특허 10-2024-0074553-5-원본영상 내 음성구간 및 무음구간을 추출하는 단계;상기 무음구간과 상기 타임코드를 매핑시키는 단계; 및상기 무음구간 내 상기 타임코드에 대응되는 해설음성을 합성하는 단계;를 포함하는,서비스 서버."}
{"patent_id": "10-2022-0156747", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "화면해설방송을 생성하는 서비스 서버에 있어서, 상기 서비스 서버는 중앙처리유닛 및 메모리를 포함하며,상기 중앙처리유닛은, 상기 메모리에 저장되어 있는 화면해설방송 생성 방법을 실행시키기 위한 명령어들을 실행시키는 것을 특징으로 하되,상기 화면해설방송 생성 방법은,스크립트를 파싱하여 복수 개의 해설문장들 및 각 해설문장에 대응되는 타임코드를 추출하는 단계;원본영상 내 음성구간 및 무음구간을 추출하는 단계;상기 무음구간과 상기 타임코드를 매핑시키는 단계;상기 추출한 무음구간에 대한 정보를 참고하여 각 무음구간에 대응되는 해설문장을 편집하는 단계;편집된 해설문장을 기초로 해설음성을 생성하는 단계; 및상기 무음구간 내 상기 해설음성을 합성하는 단계;를 포함하는,서비스 서버."}
{"patent_id": "10-2022-0156747", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 화면해설방송을 자동으로 생성하는 방법 및 시스템에 관한 것이다. 구체적으로, 본 발명은 원본영상과 스크립트를 입력시켰을 때 원본영상의 음성구간 및 무음구간을 탐색하고, 스크립트를 기초로 생성된 음성데이터 를 상기 원본영상의 무음구간 내에 삽입시키는 과정들을 인공지능 알고리즘을 활용하여 자동화시킴으로써 궁극적 으로는 그 동안 많은 비용과 사람의 노력이 소요되었던 화면해설방송 생성을 쉽게 할 수 있도록 하는 방법 및 시 스템에 관한 것이다."}
{"patent_id": "10-2022-0156747", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 화면해설방송을 자동으로 생성하는 방법 및 시스템에 관한 것이다. 구체적으로, 본 발명은 원본영상 과 스크립트를 입력시켰을 때 원본영상의 음성구간 및 무음구간을 탐색하고, 스크립트를 기초로 생성된 음성데 이터를 상기 원본영상의 무음구간 내에 삽입시키는 과정들을 인공지능 알고리즘을 활용하여 자동화시킴으로써 궁극적으로는 그 동안 많은 비용과 사람의 노력이 소요되었던 화면해설방송 생성을 쉽게 할 수 있도록 하는 방 법 및 시스템에 관한 것이다."}
{"patent_id": "10-2022-0156747", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "화면해설방송이란 시각 장애인들을 위하여 해설자가 화면의 내용을 음성으로 설명해 주는 방송을 일컫는 것으로, 장면의 전환, 등장인물의 표정이나 몸짓, 대사 없이 처리되는 영상 등을 해설하기 위한 음성이 영상에 합성되어 있는 상태의 콘텐츠로 이해될 수 있다. 종래에는 화면해설방송을 제작하기 위해 화면해설작가가 스크립트를 작성하고, 이 스크립트를 보고 성우가 원본 영상의 음성과 중첩되지 않게 녹음을 하는 과정들을 거쳤는데, 종래에는 화면해설방송을 제작하는 과정이 성우 의 스케쥴에 크게 의존할 뿐만 아니라 많은 시간과 비용이 소요되었기 때문에 화면해설방송이 최소한으로만 제 작되어 온 것이 현실이었다. 본 발명은 이러한 문제점에 착안하여 제안된 것으로, 스크립트와 원본영상이 입력되었을 때에 인공지능 알고리 즘을 이용하여 자동적으로 화면해설방송이 생성될 수 있게 함으로써 성우의 녹음 과정이나 오디오 믹싱 과정들 이 생략된 채 빠르고 쉽게 화면해설방송을 획득할 수 있게 한 방법 및 시스템에 관한 것이다. 또한 본 발명은"}
{"patent_id": "10-2022-0156747", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "위의 기술적 문제점을 해소시키는 것 외에도 본 기술분야에서 통상의 지식을 가진 자가 용이하게 발명할 수 없는 추가적인 기술요소들을 제공하기 위해 발명되었다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-2160117호(2020.09.21. 등록)"}
{"patent_id": "10-2022-0156747", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 화면해설작가의 스크립트가 입력되면 곧바로 각 해설문장에 대응되는 해설음성을 생성해 낼 수 있으 므로 성우의 스케쥴과 상관없이 화면해설방송의 제작이 가능하게 하는 것을 목적으로 한다. 또한 본 발명은 화면해설방송을 제작하는 일련의 과정들을 자동화함으로써 다수의 원본영상들에 대해 쉽고 빠르 게 화면해설방송을 만들어낼 수 있게 하는 것을 목적으로 하며, 이를 통해 많은 시각 장애인들이 더 많은 방송 콘텐츠를 시청할 수 있게 하는 것을 목적으로 한다. 또한 본 발명은 원본영상으로부터 무음구간을 자동으로 찾고, 찾아진 무음구간의 길이에 맞도록 해설음성의 길 이 또는 속도를 자동적으로 조정하게 함으로써 높은 퀄리티의 화면해설방송이 제작될 수 있게 하는 것을 목적으 로 한다. 한편, 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0156747", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 위와 같은 문제점을 해결하기 위한 것으로, 본 발명에 따라 화면해설방송을 자동으로 생성하는 방법 은 스크립트를 파싱하여 복수 개의 해설문장들 및 각 해설문장에 대응되는 타임코드를 추출하는 단계; 추출한 해설문장을 기초로 해설음성을 생성하는 단계; 원본영상 내 음성구간 및 무음구간을 추출하는 단계; 상기 무음 구간과 상기 타임코드를 매핑시키는 단계; 및 상기 무음구간 내 상기 타임코드에 대응되는 해설음성을 합성하는 단계;를 포함할 수 있다. 또한, 상기 화면해설방송 생성 방법은, 상기 해설음성을 합성하는 단계 이전, 상기 해설음성의 재생길이가 상기 무음구간 내에 포함되도록 상기 해설음성의 재생길이를 조정하는 단계;를 더 포함할 수 있다. 또한, 상기 화면해설방송 생성 방법에 있어서 상기 해설음성의 재생길이를 조정하는 단계는, 상기 해설음성의 스케일을 축소시키는 방식 또는 상기 해설음성 내 포함된 무음구간 중 일부를 삭제하는 방식으로 이루어지는 것 을 특징으로 할 수 있다. 또한, 상기 화면해설방송 생성 방법에 있어서 상기 해설음성을 생성하는 단계는, 텍스트 및 오디오 쌍으로 구성 된 학습용 데이터셋을 기초로 기 학습된 인공지능 알고리즘이 상기 해설문장을 구성하는 텍스트로부터 해설음성 을 생성하는 단계인 것을 특징으로 할 수 있다. 또한, 상기 화면해설방송 생성 방법에 있어서 상기 음성구간 및 무음구간을 추출하는 단계는, 상기 원본영상의 믹스드 오디오로부터 음성 오디오만 추출하는 단계; 상기 음성 오디오 중 음성이 포함된 구간 및 음성이 미포함 된 구간을 구별하는 단계;를 포함할 수 있다. 또한, 상기 화면해설방송 생성 방법에 있어서 상기 무음구간과 상기 타임코드를 매핑시키는 단계는, 상기 스크 립트로부터 추출된 해설문장들 별 타임코드, 및 상기 원본영상으로부터 추출된 무음구간들의 순서를 매핑하는 단계; 및 상기 각 타임코드에 대응되는 각 해설음성이 각 무음구간 내에 삽입이 가능한지 여부를 확인하는 단계;를 포함할 수 있다. 또한, 상기 화면해설방송 생성 방법에 있어서 상기 스크립트로부터 추출된 해설문장들 별 타임코드, 및 상기 원 본영상으로부터 추출된 무음구간들의 순서를 매핑하는 단계는, 각 타임코드의 시작시점 또는 종료시점 중 적어 도 하나가, 상기 무음구간들 중 어느 임의의 무음구간 내에 포함되는지 여부를 확인함으로써 이루어지는 단계인것을 특징으로 할 수 있다. 또한, 상기 화면해설방송 생성 방법에 있어서 상기 스크립트로부터 추출된 해설문장들 별 타임코드, 및 상기 원 본영상으로부터 추출된 무음구간들의 순서를 매핑하는 단계는, 각 타임코드의 시작시점 또는 종료시점과 상기 무음구간들 간의 유사도를 확인함으로써 이루어지는 단계인 것을 특징으로 할 수 있다. 또한, 상기 화면해설방송 생성 방법에 있어서 상기 각 타임코드에 대응되는 각 해설음성이 각 무음구간 내에 삽 입이 가능한지 여부를 확인하는 단계는, 임의의 무음구간 길이와, 상기 무음구간에 대응되는 해설음성의 길이를 비교하고, 상기 무음구간의 길이가 상기 해설음성의 길이에 비해 더 큰 값을 가지는지 여부를 확인하는 단계인 것을 특징으로 할 수 있다. 또한, 상기 화면해설방송 생성 방법에 있어서 상기 각 타임코드에 대응되는 각 해설음성이 각 무음구간 내에 삽 입이 가능한지 여부를 확인하는 단계는, 임의의 해설음성의 시작시점과 상기 해설음성에 대응되는 무음구간의 시작시점 간 선후를 비교하거나, 또는 임의의 해설음성의 종료시점과 상기 해설음성에 대응되는 무음구간의 종 료시점 간 선후를 비교함으로써 이루어지는 것을 특징으로 할 수 있다. 한편, 본 발명의 또 다른 실시예에 따라 화면해설방송을 자동으로 생성하는 방법은, 스크립트를 파싱하여 복수 개의 해설문장들 및 각 해설문장에 대응되는 타임코드를 추출하는 단계; 원본영상 내 음성구간 및 무음구간을 추출하는 단계; 상기 무음구간과 상기 타임코드를 매핑시키는 단계; 상기 추출한 무음구간에 대한 정보를 참고 하여 각 무음구간에 대응되는 해설문장을 편집하는 단계; 편집된 해설문장을 기초로 해설음성을 생성하는 단계; 및 상기 무음구간 내 상기 해설음성을 합성하는 단계;를 포함할 수 있다. 또한, 상기 화면해설방송 생성 방법에 있어서 상기 해설문장을 편집하는 단계는, 상기 해설문장 중 일부 단어를 배제시키는 편집, 상기 해설문장 중 일부 조사를 생략하는 편집, 또는 상기 해설문장에 포함된 단어들 중 일부 를 다른 단어로 대체하는 편집 중 적어도 하나를 실행하는 단계인 것을 특징으로 할 수 있다. 한편, 본 발명의 또 다른 실시예에 따라 화면해설방송을 생성하는 서비스 서버에 있어서, 상기 서비스 서버는 중앙처리유닛 및 메모리를 포함하며, 상기 중앙처리유닛은, 상기 메모리에 저장되어 있는 화면해설방송 생성 방 법을 실행시키기 위한 명령어들을 실행시키는 것을 특징으로 하되, 상기 화면해설방송 생성 방법은, 스크립트를 파싱하여 복수 개의 해설문장들 및 각 해설문장에 대응되는 타임코드를 추출하는 단계; 추출한 해설문장을 기초 로 해설음성을 생성하는 단계; 원본영상 내 음성구간 및 무음구간을 추출하는 단계; 상기 무음구간과 상기 타임 코드를 매핑시키는 단계; 및 상기 무음구간 내 상기 타임코드에 대응되는 해설음성을 합성하는 단계;를 포함할 수 있다. 한편, 본 발명의 또 다른 실시예에 따라 화면해설방송을 생성하는 서비스 서버에 있어서, 상기 서비스 서버는 중앙처리유닛 및 메모리를 포함하며, 상기 중앙처리유닛은, 상기 메모리에 저장되어 있는 화면해설방송 생성 방 법을 실행시키기 위한 명령어들을 실행시키는 것을 특징으로 하되, 상기 화면해설방송 생성 방법은, 스크립트를 파싱하여 복수 개의 해설문장들 및 각 해설문장에 대응되는 타임코드를 추출하는 단계; 원본영상 내 음성구간 및 무음구간을 추출하는 단계; 상기 무음구간과 상기 타임코드를 매핑시키는 단계; 상기 추출한 무음구간에 대 한 정보를 참고하여 각 무음구간에 대응되는 해설문장을 편집하는 단계; 편집된 해설문장을 기초로 해설음성을 생성하는 단계; 및 상기 무음구간 내 상기 해설음성을 합성하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2022-0156747", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 그 동안 많은 비용과 시간, 사람의 노력이 소요되었던 화면해설방송 제작과정이 크게 간소화 지는 효과가 있으며, 특히 실질적으로 대부분의 방송콘텐츠를 대상으로 화면해설방송을 생성해 낼 수 있어 많은 시각 장애인들에게 방송콘텐츠를 쉽게 접할 수 있는 환경을 제공할 수 있게 되는 효과가 있다. 또한 본 발명에 따르면, 원본영상의 무음구간을 탐색하고, 해당 무음구간의 길이에 맞도록 해설음성의 속도 또 는 길이를 조정함으로써 높은 품질의 화면해설방송을 생성할 수 있는 효과가 있다. 한편, 본 발명에 의한 효과는 이상에서 언급한 것들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 효과들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0156747", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적과 기술적 구성 및 그에 따른 작용 효과에 관한 자세한 사항은 본 발명의 명세서에 첨부된 도면 에 의거한 이하의 상세한 설명에 의해 보다 명확하게 이해될 것이다. 첨부된 도면을 참조하여 본 발명에 따른 실시예를 상세하게 설명한다. 본 명세서에서 개시되는 실시예들은 본 발명의 범위를 한정하는 것으로 해석되거나 이용되지 않아야 할 것이다. 이 분야의 통상의 기술자에게 본 명세서의 실시예를 포함한 설명은 다양한 응용을 갖는다는 것이 당연하다. 따 라서, 본 발명의 상세한 설명에 기재된 임의의 실시예들은 본 발명을 보다 잘 설명하기 위한 예시적인 것이며 본 발명의 범위가 실시예들로 한정되는 것을 의도하지 않는다. 도면에 표시되고 아래에 설명되는 기능 블록들은 가능한 구현의 예들일 뿐이다. 다른 구현들에서는 상세한 설명 의 사상 및 범위를 벗어나지 않는 범위에서 다른 기능 블록들이 사용될 수 있다. 또한, 본 발명의 하나 이상의 기능 블록이 개별 블록들로 표시되지만, 본 발명의 기능 블록들 중 하나 이상은 동일 기능을 실행하는 다양한 하드웨어 및 소프트웨어 구성들의 조합일 수 있다. 또한, 어떤 구성요소들을 포함한다는 표현은 “개방형”의 표현으로서 해당 구성요소들이 존재하는 것을 단순히 지칭할 뿐이며, 추가적인 구성요소들을 배제하는 것으로 이해되어서는 안 된다. 나아가 어떤 구성요소가 다른 구성요소에 “연결되어” 있다거나 “접속되어” 있다고 언급될 때에는, 그 다른 구성요소에 직접적으로 연결 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 한다. 도 1은 본 발명에 따른 화면해설방송 생성 방법을 개념적으로 이해하기 위한 도면이다. 도면을 참고할 때, 본 발명은 스크립트(s)와 원본영상(v)이 수신 또는 입력되었음을 전제로, 스크립트 및 원본영상 각각에 인공지능 알고리즘을 이용한 데이터 처리를 하고, 스크립트를 데이터 처리한 것으로부터 얻은 해설음성, 그리고상기 원본 영상으로부터 추출된 구간정보, 그 중에서도 무음구간정보를 참고하여 상기 무음구간 내에 상기 해설음성을 합 성시킴으로써 최종적으로 화면해설방송을 생성해 내는 과정을 포함한다. 스크립트(s)란, 원본영상의 어느 시점에서 어떤 해설이 삽입되어야 하는지를 기록한 일종의 텍스트 데이터로 이 해될 수 있으며, 이 스크립트는 바람직하게는 화면해설작가가 원본영상을 직접 보면서 각각의 해설 시간대 별로 해설문장들을 기록한 내용들을 포함할 수 있다. 경우에 따라 상기 스크립트(s) 역시 원본영상의 프레임 별 이미 지 분석 및 음성 분석으로부터 자동으로 생성할 수 있으나, 본 발명은 스크립트(s)의 자동 생성에 초점이 맞추 어져 있는 것은 아니므로, 이 상세한 설명 내에서는 스크립트(s)가 어떤 방식에 의해서든 완성이 된 상태로 존 재하는 것을 전제로 후속 설명을 이어가기로 한다. 원본영상(v)이란, 화면해설방송의 작업 대상이 되는 영상 데이터로 이해될 수 있으며, 원본영상은 디스플레이 화면을 통해 출력될 수 있는 복수 개의 프레임들을 포함하고 있는 한 여타의 형식에는 제한이 없다 할 것이다. 도면을 참고할 때, 화면해설방송 생성 과정은 크게 스크립트를 처리하는 과정, 그리고 원본영상을 처리하는 과 정, 이렇게 두 가지로 나뉘어 설명될 수 있는데, 각각의 처리 과정은 모두 동일한 연산장치(예. 후술하게 될 서 비스 서버)에 의해 이루어지거나, 각각의 처리 과정들이 서로 상이한 연산장치들에 의해 이루어진 뒤 마지막 합 성만 하나의 연산장치에서 이루어지도록 구현될 수도 있다. 예를 들어, 스크립트를 파싱하거나 스크립트로부터 해설음성을 합성해 내는 작업은 제1 연산장치에서, 원본영상을 분석하여 무음구간을 탐색하는 작업은 제2 연산 장치에서 이루어지고, 최종적으로 원본영상에 해설음성을 믹싱하는 작업은 제3 연산장치에서 이루어지는 등의 시스템적 환경이 구현될 수 있다. 참고로, 본 상세한 설명에서는 스크립트 처리 과정, 원본영상 처리 과정, 이들을 합성시키는 과정들이 서로 구별된 연산장치들에 의해 각각 작업실행이 된다 하더라도 발명의 이해를 돕기 위해 전체가 하나의 연산시스템, 즉 서비스 서버에 의해 실행되는 것으로 전제하여 설명하기로 한다. 도 2는 본 발명에 따른 화면해설방송 생성 방법을 구현해 내기 위한 시스템적 환경을 도시한 것이다. 도면을 참 고할 때, 전체 시스템적 환경은 필요한 소스(스크립트, 원본영상)를 수신하고, 인공지능 알고리즘을 이용한 데 이터 처리를 하여 최종적으로 화면해설방송을 생성해 내는 서비스 서버, 네트워크를 통해 스크립트를 제공 하는 스크립트 제공자 단말기, 네트워크를 통해 원본영상을 제공하는 콘텐츠 서버를 포함할 수 있다. 먼저 서비스 서버와 관련하여, 도면에서도 볼 수 있듯 서비스 서버는 네트워크를 통해 스크립트 제공 자 단말기, 및 콘텐츠 서버와 연결되어 있을 수 있으며, 각 구성들로부터 본 발명을 구현시키기 위해 필요한 소스들, 즉 스크립트 및 원본영상을 전달받을 수 있다. 서비스 서버는 상기 스크립트 제공자 단말 기 또는 콘텐츠 서버를 상대로 전용 인터페이스(전용 웹 또는 모바일페이지)를 제공할 수 있으며, 이 를 통해 복수의 주체들로부터 스크립트 및 원본영상을 쉽게 업로드 받을 수 있다. 상기 서비스 서버의 형 태는, 어느 특정 운영자가 관리하는 적어도 하나의 서버 컴퓨터일 수 있으며, 또는 타 업체에서 제공하는 클라 우드 서버의 형태, 즉 운영자가 회원가입하여 사용할 수 있는 클라우드 서버의 형태일 수도 있다. 특히 서비스 서버가 서버용 PC로 구현된 경우, 해당 서비스 서버는 중앙처리유닛 및 메모리를 포함할 수 있다. 이 때 중앙처리유닛은 컨트롤러(controller), 마이크로 컨트롤러(microcontroller), 마이크로 프로세서 (microprocessor), 마이크로 컴퓨터(microcomputer) 등으로도 불릴 수 있다. 또한 중앙처리유닛은 하드웨어 (hardware) 또는 펌웨어(firmware), 소프트웨어, 또는 이들의 결합에 의해 구현될 수 있는데, 하드웨어를 이용 하여 구현하는 경우에는 ASIC(application specific integrated circuit) 또는 DSP(digital signal processor), DSPD(digital signal processing device), PLD(programmable logic device), FPGA(field programmable gate array) 등으로, 펌웨어나 소프트웨어를 이용하여 구현하는 경우에는 위와 같은 기능 또는 동 작들을 수행하는 모듈, 절차 또는 함수 등을 포함하도록 펌웨어나 소프트웨어가 구성될 수 있다. 또한, 메모리 는 ROM(Read Only Memory), RAM(Random Access Memory), EPROM(Erasable Programmable Read Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), 플래쉬(flash) 메모리, SRAM(Static RAM), HDD(Hard Disk Drive), SSD(Solid State Drive) 등으로 구현될 수 있다. 스크립트 제공자 단말기는, 화면해설방송을 위해 각 해설장면 별로 해설 시간대 및 해설문장들을 기록한 스크립트를 전송하는 구성으로, 예를 들어 화면해설을 전문적으로 하는 작가가 사용하는 단말기, 또는 그 밖에 온라인 상에서 화면해설을 위한 스크립트를 작성하는 자가 보유하고 있는 단말기 등을 포함할 수 있다. 일 예로, 스크립트 제공자는 화면해설방송의 제작을 맡은 자로부터 외주용역을 받아 원본영상을 시청하면서 해설이 필요한 장면을 기록하고 그 장면에 맞는 해설문장을 작성할 수 있다. 스크립트 제공자 단말기는 네트워크를 통해 스크립트를 전송할 수 있는 한 그 종류에는 제한이 없다 할 것 이며, 예를 들어 스마트폰, 태블릿, 랩탑 컴퓨터, 데스크탑 컴퓨터 등의 것들이 포함될 수 있다. 스크립트 제공 자는, 바람직하게는 자신의 스크립트 제공자 단말기에 설치된 어플리케이션을 실행시켜 회원가입 및 로그 인 하고, 자신이 직접 작성 및 편집한 스크립트를 서비스 서버 측에 공유할 수 있다. 한편, 상기 스크립트 제공자 단말기는 반드시 작가 또는 작업자 개인의 단말기는 아닐 수 있으며, 스크립 트 제공자가 일종의 기업 형태인 경우에는 스크립트 제공자 서버(200a)로 그 명칭이 달리 불릴 수도 있다. 스크 립트 제공자가 기업 형태라 함은, 다수의 작가들을 보유하고 있는 업체의 형태를 의미하며, 스크립트 제공자 서 버(200a)란 이와 같은 업체에서 운영하는 서버를 의미할 수 있다. 다음으로 콘텐츠 서버는, 원본영상을 서비스 서버 측에 제공하는 구성으로, 예를 들어 방송용 콘텐츠 를 제작하는 업체, 또는 제작을 의뢰하여 방송용 콘텐츠를 소유하는 업체 등이 운영하는 서버로 이해될 수 있다. 상기 콘텐츠 서버는 경우에 따라 하드웨어적으로는 서비스 서버와 동일한 시스템 내에 포함된 것일 수 있으며, 가령 콘텐츠 제작사 내에 영상을 제작하기 위한 서버 장치와 화면해설방송을 제작하기 위한 서 버 장치가 함께 존재하는 경우 등이 그러한 경우가 될 수 있다. 또는, 하드웨어적으로 상기 콘텐츠 서버는 서비스 서버와 동일한 서버일 수 있는데, 예를 들어 하나의 서버 내에서 원본영상을 제작할 수 있는 프로 그램이 설치되어 있고, 동시에 본 발명에 따른 화면해설방송 생성을 위한 프로그램도 설치가 되어 있는 경우 등 이 그러한 경우가 될 수 있다. 한편, 콘텐츠 서버는 반드시 영상을 제작하거나 영상제작을 의뢰하는 업체가 아닌 개인이 운영하는 장치일 수도 있음을 이해한다. 예를 들어, 콘텐츠를 자체적으로 제작할 수 있는 개인 크리에이터 등이 사용하는 서버로, 상기 개인 크리에이터는 서비스 서버 측에 접속하여 자신이 제작한 영상을 업로드 함으로써 화면 해설방송 생성을 요청할 수 있다. 이상 도 2를 참고하여 본 발명에 따른 화면해설방송 생성 방법이 구현될 수 있는 시스템적 환경에 대해 살펴보 았으며, 특히 도 2에 도시되어 있는 각 구성들이 용어에 따라 제한 해석되지 않음에 대해 알아보았다. 도 3은 본 발명의 일 실시예에 따른 화면해설방송 생성 방법을 순서에 따라 도시한 것이다. 도면을 참고할 때, 화면해설방송 생성 방법은 크게 두 가지 작업, 즉 스크립트를 처리하는 작업과 원본영상을 처리하는 작업을 포 함하게 되는데, 이 두 가지의 작업들은 순서에 관계없이 서비스 서버에 의해 처리될 수 있는 것임을 이해 한다. 본 상세한 설명에서는 편의상 스크립트를 처리하는 과정부터 설명하기로 한다. 가장 먼저 서비스 서버는 외부로부터 수신된 스크립트를 로드하는 단계(S101)부터 실시할 수 있다. 서비스 서버는 스크립트 제공자 단말기로부터 사전에 스크립트를 수신하여 저장해 둘 수 있는데, 본격적인 데이터 처리를 위하여 메모리 상에 스크립트가 로딩되는 단계가 존재할 수 있다. S101단계 후에는 상기 스크립트를 파싱(parsing)하는 단계(S102)가 수행될 수 있다. 스크립트란, 바람직하게는 화면해설작가가 원본영상을 직접 보면서 각각의 해설 시간대 별로 해설문장들을 기록한 내용들을 포함할 수 있 다고 앞서에서 언급하였었는데, 서비스 서버는 위 파싱단계를 거침으로써 스크립트로부터 각각의 타임코드 및 이에 대응되는 해설문장들을 추출해 낼 수 있다. 파싱이란, 스크립트 내 일련의 토큰들의 열을 받아들여 기 정해진 규칙에 따라 구문을 분석하는 과정을 의미할 수 있는데, 이를 위해 상기 스크립트는 애초 작성 단계에서 부터 일부 규칙에 따라 작성된 것일 수 있다. 도 4는 스크립트가 파싱 단계를 거친 후 타임코드 및 해설문장들이 추출되어 정렬된 모습을 도시한 것이다. 도 면을 참고할 때, 파싱 단계에 의해서는 각 해설들 별 식별번호(순번), 각 해설들의 타임코드(시작시점 및 종료 시점), 각 해설들의 해설문장이 추출될 수 있다. 해설번호는 스크립트 내 포함되어 있는 개별 해설들을 구분하 고 그 순서를 정하기 위한 것으로, 도면 상에서는 숫자로 기재되어 있으나 각 해설번호는 다른 문자, 숫자, 또 는 문자/숫자의 조합에 의해 대체될 수 있다. 타임코드는 시작시점 및 종료시점을 모두 포함하는 것으로, 도면 상에서는 시작시점과 종료시점을 각각 열을 나누어 표기하였으나 해설번호1에 대응되는 타임코드는 0003250_0006250, 해설번호 4에 대응되는 타임코드는 0085374_0088507, 해설번호7에 대응되는 타임코드는 0137000_0140996과 같이 규칙에 따라 조합되어 표시될 수도 있다. 해설문장은 각 해설들에 대응하여 스크립트 제공자(작가)가 직접 작성한 텍스트이다. 파싱 단계에 의해 추출된 위와 같은 정보들은 도면에 도시된 것과 같이 정제된 문서데이터의 형태로 저장될 수 있는데, 반드시 도면의 형식을 따르지는 않아도 됨을 이해한다. S102단계 후에는 서비스 서버가 각 해설 별로 해설음성을 생성하는 단계(S103)가 실행될 수 있다. 본 단계 에서는 텍스트데이터로부터 음성데이터를 생성해 내는 TTS 알고리즘을 활용할 수 있으며, 위 해설문장들로부터 개별 해설음성을 생성해 낼 수 있는 이상 알고리즘의 종류에는 제한이 없다 할 것이다. 다만, 바람직하게는 Variational Auto Encoder(VAE) 구조 기반의 VITS 알고리즘이 활용될 수 있다. 참고로, 위 VITS 알고리즘은 텍스트 데이터와 음성 데이터 간의 관계를 학습하고 이렇게 학습된 내용을 바탕으 로 음성 데이터를 생성해 내는 인공지능 알고리즘으로, 텍스트와 음성 간의 관계성을 더 많이 학습할수록 더 정 교한 음성 데이터를 생성해 낼 수 있는 것으로 알려져 있다. 상기 인공지능 알고리즘은 [텍스트-오디오]와 같이 구성된 학습용 데이터 세트를 통하여 학습될 수 있는데, 이 때 텍스트는 문장단위로 구분되어 있을 수 있으며, 오디오는 상기 텍스트를 임의의 목소리(서비스 운영자가 선택한 목소리)로 읽은 것일 수 있다. 또한, 상기 VITS알고리즘은, 기존의 TTS 알고리즘들이 텍스트로부터 Mel-spectrogram을 생성하고, 다시 Mel- spectrogram으로부터 음성 데이터(wav)를 생성해 내는 등 두 단계(2 stage)에 걸쳐 발화 음성을 생성하던 것과 달리 parallel end-to-end 방식으로 한 단계(1 stage)만으로 음성 데이터를 생성해 내는 것을 특징으로 한다. 본 발명에 따른 서비스 서버는 이와 같은 인공지능 알고리즘을 이용하여 스크립트로부터 추출된 각각의 해 설문장들을 해설음성들로 생성할 수 있다. 이상 S101 단계 내지 S103 단계까지의 스크립트 처리 과정에 대해 살펴보았다. 다음으로는 S201 단계 내지 S203 단계까지의 원본영상 처리 과정에 대해 먼저 설명한 후, 결과물들을 합성하는 S301 단계 내지 S303 단계에 대해설명하기로 한다. S201 단계는 서비스 서버가 원본영상을 로드하는 단계(S201)이다. 서비스 서버는 콘텐츠 서버로 부터 원본영상이 수신되면 이를 저장해 둘 수 있는데, 본격적인 데이터 처리를 위하여 상기 원본영상이 메모리 상에 로딩되는 단계가 포함될 수 있다. S201 단계 이후에는 서비스 서버가 상기 원본영상으로부터 오디오를 추출하는 단계(S202)가 실행될 수 있 다. 본 단계에서는 원본영상으로부터 오디오를 분리해 낼 수 있는 알고리즘이 활용될 수 있으며, 바람직하게는 Wave-U-Net 알고리즘이 활용될 수 있다. 참고로 상기 알고리즘은 믹스드 오디오로부터 음성만 분리하여 추출할 수 있으며, 오디오로부터 음성이 출력되는 구간과 그렇지 않은 구간을 구분하는 데에 활용되는 것으로 알려져 있다. S202 단계 후에는 서비스 서버가 원본영상 내 음성구간과 무음구간을 추출하는 단계(S203)가 실행될 수 있 다. 본 단계는 앞서 설명한 S202 단계와 구별하여 소개하고 있으나 실질적으로는 S202 단계에 이어 하나의 단계 처럼 진행될 수 있음을 이해한다. 한편, 본 단계에서 상기 서비스 서버는 음성구간, 또는 무음구간을 앞서 설명하였던 타임코드, 즉 스크립트 내 해설의 시작시점과 종료시점을 구분하기 위한 타임코드의 형식을 빌려 추 출할 수 있다. 이렇게 함으로써 후속 단계에서 무음구간 내에 해설음성을 매핑시키는 데에 효율성을 꾀할 수 있 다. 원본영상에 대한 처리까지 모두 마쳐진 이후에는 서비스 서버가 상기 원본영상의 무음구간과 각 해설들의 타임코드를 매핑하는 단계(S301)가 실행될 수 있다. 이 단계에서는 서비스 서버가 앞서 추출하였던 해설들 의 타임코드, 그리고 원본영상으로부터 추출되었던 무음구간의 순서를 매핑하고, 나아가 각 해설들의 타임코드 에 대응되는 해설음성이 각 무음구간 내에 삽입이 될 수 있는지를 확인하는 과정이 포함될 수 있다. 매핑과 관련하여, 서비스 서버는 각 해설들의 타임코드로부터 알 수 있는 시간을 기반으로 상기 무음구간 중 상기 타임코드와 매핑이 되는 구간을 탐색하며, 매핑이 되는 구간이 탐색되었다면 해당 해설을 탐색된 무음 구간과 연계시킴으로써 추후 해당 무음구간에 상기 해설이 삽입될 것임을 정할 수 있다. 이 때, 서비스 서버 는 각 해설의 타임코드로부터 시작시점에 대한 정보 및 종료시점에 대한 정보를 모두 참조하여 상기 무음 구간과 비교할 수 있으며, 시작시점 및 종료시점이 모두 상기 무음구간 내에 포함되거나 혹은 상기 시작시점 또 는 종료시점이 무음구간 내에 포함되는지를 보아 매핑 여부를 결정할 수 있다. 한편, 경우에 따라서는 각 해설 들의 타임코드가 정확한 시작 또는 종료 시점을 가리키는 것이 아닐 수 있고, 또는 무음구간에 대한 정보 역시 정확한 지점을 가리키는 것이 아닐 수 있는데, 이 경우 서비스 서버는 각 해설의 타임코드로부터 알 수 있 는 시작시점 또는 종료시점과 무음구간들 간의 유사도를 확인함으로써 서로 상응하는 해설 및 무음구간 쌍을 결 정할 수 있다. 또는, 서비스 서버는 각 해설의 타임코드로부터 알 수 있는 해설구간과 무음구간들 간 구간 이 중첩되는 정도(구간중첩도)를 확인함으로써 가장 중첩율이 높은 해설 및 무음구간을 매핑시킬 수 있다. 또한, 해설음성이 무음구간 내에 삽입이 가능할 지 확인하는 과정과 관련하여, 서비스 서버는 무음구간의 길이와 해설음성의 길이를 비교하여 무음구간의 길이가 해설음성의 길이에 비해 더 큰 값을 가진다면 삽입이 가 능한 것으로 판단할 수 있으며, 반대로 해설음성의 길이가 더 큰 값을 가진다면 삽입이 불가능한 것으로 판단할 수 있다. 다른 한편, 서비스 서버는 해설음성의 시작시점이 무음구간의 시작시점보다 더 빠르거나, 또는 해설음성의 종료시점이 무음구간의 종료시점보다 더 느리다면 이 경우 역시 해설음성이 무음구간 내에 삽입이 불가능한 경우로 판단할 수 있다. 즉, 서비스 서버는 해설음성이 원본영상의 음성구간과 중복되는 구간이 존재한다면 무음구간 내에 해설음성의 삽입이 불가능한 상황으로 판단할 수 있다. 도 5에는 음성구간들 및 무음 구간들이 타임라인 상에 표시된 모습이 도시되어 있으며, 각 무음구간들에는 매핑되는 해설음성들이 표시되어 있음을 확인할 수 있다. 도면을 참고할 때, 일 예로 서비스 서버는 T2와 T3 사이의 무음구간 길이와 해설 음성#1의 S1과 S2 사이 길이를 비교할 수 있으며, 또 다른 예로 서비스 서버는 T2와 S1의 선후 비교, T3와 S2의 선후 비교를 함으로써 해설음성#1이 무음구간 내에 삽입 가능한지 여부를 판단할 수 있다. S301 단계 이후, 만일 해설음성이 무음구간 내에 삽입이 불가능한 것으로 판단된 경우, 서비스 서버는 상 기 해설음성의 길이를 조정(S302)할 수 있다. 본 단계에서 서비스 서버는 무음구간의 길이, 즉 상기 해설 음성이 삽입될 구간보다 앞선 시점의 음성구간, 그리고 해설음성이 삽입될 구간 뒤의 음성구간을 탐색한 뒤 앞 선 음성구간의 종료시점, 그리고 뒤에 올 음성구간의 시작시점 사이 시간을 계산하여 무음구간의 길이를 산출하 고, 이 길이와 동일하거나 이보다 짧은 길이가 되도록 상기 해설음성의 길이를 조정할 수 있다. 해설음성의 길이를 조정하는 방식과 관련하여, 서비스 서버는 삽입하고자 하는 해설음성의 스케일을 축소 시킴으로써 길이를 조정할 수 있으며, 또는 해설음성에 대한 별도의 음성구간 및 무음구간 탐색을 실시함으로써 해설음성 내 무음구간 중 일부를 삭제하는 방식으로 길이를 조정할 수도 있다. 도 5에는 해설음성#1의 S1 내지 S2까지의 길이가 S1'내지 S2'로 스케일이 축소된 예시, 그리고 해설음성#2 중 무음구간인 X1 및 X2 구간이 삭제 됨으로써 S3' 내지 S4' 로 축소된 예시가 도시되어 있다. 한편, S301 단계에서 해설음성이 무음구간 내에 삽입이 가능한 것으로 판단되었거나 S302 단계에서 해설음성의 길이가 조정된 이후, 서비스 서버는 상기 무음구간 내에 해설음성을 합성 또는 삽입(S303)시킬 수 있다. 서비스 서버는 모든 해설들에 대하여 위 과정을 반복함으로써 최종적으로 화면해설방송을 생성해 낼 수 있 다. 이상 도 3 내지 도 5를 참고하여 제1 실시예에 따른 화면해설방송 생성 방법에 대해 알아보았다. 도 6은 제2 실시예에 따른 화면해설방송 생성 방법을 도시한 것이다. 제2 실시예에 따른 방법은 앞서 설명한 제 1 실시예와 달리 해설음성을 생성하기 전에 원본영상으로부터 추출된 무음구간에 대한 정보를 먼저 분석하고, 무음구간에 삽입될 수 있도록 해설문장을 선 편집한 후 해설음성을 생성하게 한 것을 특징으로 한다. 즉, 제1 실시예에서는 스크립트로부터 추출된 해설문장을 먼저 해설음성으로 생성하고, 이후 무음구간에 삽입시키기 위 해 조정하는 과정을 거쳤다면, 제2 실시예에서는 무음구간에 대한 정보를 먼저 획득한 후 해설문장을 편집하고, 이렇게 편집된 해설문장을 해설음성으로 생성함으로써 조정 과정을 생략하였다. 도면을 참고하여 비교할 때 S401 내지 S402 단계까지는 S101 내지 S102 단계와 실질적으로 동일하고, S501 내지 S503 단계는 S201 내지 S203 단계와 실질적으로 동일한 반면, S403 단계 및 S404 단계에 있어서 차이가 있다. 이하에서는 S403 단계에서부터 설명을 이어가기로 한다. S403 단계는 서비스 서버가 스크립트를 파싱(S402)하여 해설문장 및 타임코드를 추출한 이후에 이루어지는 단계로, 앞선 파싱 단계에서 추출된 해설문장을 편집하는 단계이다. 본 단계에서는 S503 단계에서 추출한 무음 구간에 대한 정보를 활용할 수 있다. 즉, 해설음성을 생성해 내기 전, 무음구간의 길이에 대한 정보를 미리 참 고하여 해당 무음구간에 삽입될 수 있을 정도의 해설음성을 생성시키고자 해설문장의 적어도 일부를 편집하도록 한 것이다. 서비스 서버는 종전 해설문장 중 일부 단어를 배제시키는 편집, 해설문장 중 일부 조사를 생략하는 편집, 또는 해설문장에 포함된 단어들 중 일부를 다른 단어(글자수가 다른 단어)로 대체하는 편집 중 적어도 하나의 편집을 함으로써 해설문장의 편집을 실행할 수 있다. 한편, 상기 스크립트 제공자(작가)는 애초에 스크립트를 제작할 시 필요에 따라 대체할 수 있는 단어군들을 미리 입력해 놓음으로써 서비스 서버가 해설문장을 편 집할 시 활용 가능하게 할 수 있다. S403 단계에서 편집된 해설문장은 무음구간의 길이에 맞추어져 있는 것이므로, 이후 S404 단계에서는 편집된 해 설문장을 기초로 해설음성을 곧바로 생성해 낼 수 있게 된다. 마지막으로 서비스 서버는 S404 단계에서 생성된 해설음성을 상기 S503 단계에서 추출된 무음구간 내에 삽 입 내지 합성(S601)시킴으로써 최종적으로 화면해설방송을 생성할 수 있다. 이상 본 발명에 따른 화면해설방송 생성 방법 및 이를 위한 시스템에 대해 살펴보았다. 한편, 본 발명은 상술한 특정의 실시예 및 응용예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해"}
{"patent_id": "10-2022-0156747", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 구별되어 이해되어서는 안 될 것이다."}
{"patent_id": "10-2022-0156747", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 화면해설방송 생성 과정을 개념적으로 도시한 것이다. 도 2는 본 발명에 따른 화면해설방송 생성을 위한 시스템을 간략히 도시한 것이다. 도 3은 본 발명의 일 실시예에 따른 화면해설방송 생성 방법을 순서에 따라 도시한 것이다. 도 4는 스크립트를 로드한 후 파싱(parsing)한 결과물을 예시적으로 나타낸 것이다. 도 5는 원본영상으로부터 음성구간 및 무음구간을 탐색해 내고, 각 무음구간에 해설음성을 매핑하는 과정을 도 시한 것이다. 도 6은 본 발명의 또 다른 실시예에 따른 화면해설방송 생성 방법을 도시한 것이다."}
