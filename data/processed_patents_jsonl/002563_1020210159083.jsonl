{"patent_id": "10-2021-0159083", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0071116", "출원번호": "10-2021-0159083", "발명의 명칭": "자동차의 차체의 움직임을 인식하기 위한 방법, 시스템, 및 컴퓨터 프로그램 제품", "출원인": "독터. 인제니어. 하.체. 에프. 포르쉐 악티엔게젤", "발명자": "피터스 야니크"}}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "데이터 분석 장치(40)를 이용하여 자동차(10)의 차체(12)의 움직임을 인식하기 위한 방법으로서,제2 자동차(20)의 카메라 및 센서 장치(30)에 의해 이미지 및 센서 데이터(32)를 기록하는 단계(S10); -이미지및 센서 데이터(32)는 적어도 제1 자동차(10)를 포함하는 제2 자동차(20)의 환경을 나타냄-상기 이미지 및 센서 데이터(32)를 데이터 분석 장치(40)에 전달하는 단계(S20); -데이터 분석 장치(40)는 제1자동차(10)의 차체(12)의 움직임을 인식하기 위한 인식 시스템(400)을 포함하고, 인식 시스템은 인공 지능(AI)및 머신 이미지 분석 분야의 알고리즘을 사용함-상기 차체의 있을 수 있는 움직임을 분류하기 위해 인식 시스템(400)에 의해 데이터 분석 장치(40)에서 이미지및 센서 데이터(32)를 처리하는 단계(S30);차체(12)의 분류된 움직임을 정의된 상태들(S1, S2, ..., Sn)의 세트 중 적어도 하나의 상태(Sj)에 할당하는 단계(S40);상기 결정된 상태(Sj)로부터 자동화된 주행 기능에서의 추가 사용을 위해 그리고/또는 사용자 인터페이스(70)를위해 출력 데이터(450)를 생성하는 단계(S50);를 포함하는, 차체 움직임 인식 방법."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 이미지 및 센서 데이터(32)의 처리 및 출력 데이터(450)의 생성이 실시간으로 수행되는, 차체움직임 인식 방법."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 인식 시스템(400)은 분석 모듈(410) 및 분류 모듈(430)을 포함하는, 차체 움직임인식 방법."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 인식 시스템(400)은 신경망을 이용한 딥 러닝을 사용하는, 차체 움직임 인식 방법."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 신경망은 합성곱 신경망으로서 구성되는, 차체 움직임 인식 방법."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항 내지 제5항 중 어느 한 항에 있어서, 분류 모듈(430)은, 상기 분류 모듈(430)의 훈련 단계에서 결정되었거나 사전 정의된, 차량의 차체 움직임의 특징들(M1, M2, ..., Mn)을 포함하는, 차체 움직임 인식 방법."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 이미지 및 센서 데이터(32)는 무선 이동 연결에 의해 데이터 분석 장치(40)에 전송되고, 특히5G 무선 모듈이 사용되는, 차체 움직임 인식 방법."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서, 이미지 및 센서 장치(30)는 액션 카메라(35) 및/또는 음향 센서(37)및/또는 LiDAR 시스템 및/또는 초음파 시스템 및/또는 레이더 시스템(39)을 포함하는, 차체 움직임 인식 방법."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2022-0071116-3-자동차(10)의 차체(12)의 움직임을 인식하기 위한 시스템(100)으로서, 이 시스템은,제2 자동차(20)의 이미지 및 센서 장치(30); -이미지 및 센서 데이터(32)는 적어도 제1 자동차(10)를 포함하는제2 자동차(20)의 환경을 나타냄; 및데이터 분석 장치(40);를 포함하며, 이 데이터 분석 장치(20)는 제1 자동차(10)의 차체(12)의 움직임을 인식하기 위한 인식 시스템(400)을 포함하고, 상기 인식 시스템은 인공 지능(AI) 및 머신 이미지 분석 분야의 알고리즘을 사용하며, 상기 데이터 분석 장치(40)는, 인식 시스템(400)에 의해 상기 이미지 및 센서 데이터(32)를 처리하고, 상기 차체(12)의 가능한 움직임을 분류하며, 상기 차체(12)의 분류된 움직임에 정의된 상태들(S1, S2,..., Sn)의 세트 중 적어도 하나의 상태(Sj)를 할당하고, 상기 결정된 상태(Sj)로부터 자동화된 주행 기능에서의추가 사용을 위해 그리고/또는 사용자 인터페이스(70)를 위해 출력 데이터(450)를 생성하도록 구성되는, 차체움직임 인식 시스템(100)."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 이미지 및 센서 데이터(32)의 처리 및 출력 데이터(450)의 생성이 실시간으로 수행되는, 차체움직임 인식 시스템(100)."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항 또는 제10항에 있어서, 인식 시스템(400)은 분석 모듈(410) 및 분류 모듈(430)을 포함하는, 차체 움직임인식 시스템(100)."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 인식 시스템(400)은, 특히 합성곱 신경망으로서 구성된 신경망을 이용한 딥 러닝을 사용하는,차체 움직임 인식 시스템(100)."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항 또는 제12항에 있어서, 분류 모듈(430)은, 상기 분류 모듈(430)의 훈련 단계에서 결정되었거나 사전 정의된, 차량 차체(12)의 움직임의 특징들(M1, M2, ..., Mn)을 포함하는, 차체 움직임 인식 시스템(100)."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항 내지 제13항 중 어느 한 항에 있어서, 이미지 및 센서 데이터(32)는 무선 이동 연결에 의해 데이터 분석장치(40)에 전송되며, 특히 5G 무선 모듈이 사용되고 그리고/또는 이미지 및 센서 장치(30)가 액션 카메라(35)및/또는 음향 센서(37) 및/또는 LiDAR 시스템 및/또는 초음파 시스템 및/또는 레이더 시스템(39)을 포함하는,차체 움직임 인식 시스템(100)."}
{"patent_id": "10-2021-0159083", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "실행 시, 제1항 내지 제8항 중 어느 한 항에 따른 방법을 수행하도록 구성되는 실행 가능한 프로그램 코드(550)를 포함하는 컴퓨터 프로그램 제품(500)."}
{"patent_id": "10-2021-0159083", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 데이터 분석 장치를 이용하여 자동차의 차체의 움직임을 인식하기 위한 방법에 관한 것으로, 이 방법은: 제2 자동차의 카메라 및 센서 장치에 의해 이미지 및 센서 데이터를 기록하는 단계(S10); -이미지 (뒷면에 계속)"}
{"patent_id": "10-2021-0159083", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자동차에서 차체의 움직임을 인식하기 위한 방법, 시스템 및 컴퓨터 프로그램 제품에 관한 것이다."}
{"patent_id": "10-2021-0159083", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자동차가 인간에 의해 제어되는 경우, 차량 운전자는 주행 경로 상에 임의의 가능한 위험원이 존재하는지 매우 정확하게 직관적으로 관찰한다. 특히, 예를 들어 전방 주행 차량의 속도 또는 추월 동작의 예정 여부와 같은 다양한 정보를 얻기 위해, 전방 주행 차량이 면밀하게 관찰된다. 이 경우, 차량의 차체가 직선으로 이동하는지, 또는 (도로상의 요철 또는 장애물을 암시할 수 있는) 진동하는 측방향 움직임 또는 상향 및 하향 움직임이 발생하는지도 관찰된다. 인간 운전자는 주행 중에 이러한 관찰을 직관적으로 수행하며, 자신이 어떻게 정보를 처리하여 이를 가능한 위험 상황에 할당하고, 그에 따라 차량을 제어할지를 완전히 인식하고 있다. 부분 자율 방식 및 자율 방식으로 주행하는 차량의 경우, 카메라 시스템 및 센서는 차량의 환경에 관한 정보를 얻기 위해 사용된다. 따라서, 고도 자동화 주행(HAD)의 개발은 특히 이미지 데이터와 같은 적합한 센서 데이터 를 기록하기 위한 차량 센서 시스템에 부과되는 요건의 증대와 연관이 있다. 또한, 기록된 센서 데이터는 가능 한 위험 상황에 대해 올바른 결론을 내리기 위해 주의 깊게 해석되어야 한다. DE 102018104011 A1호에는, 안내 경로 설정 유닛, 주행 환경 정보 결정 유닛, 목표 주행 경로 설정 유닛, 차간 거리 유지를 위한 제어 유닛, 횡방향 움직임 범위 계산 유닛, 장애물 회피 과정 검출 유닛 및 전방 주행 차량을 추종하기 위한 추종 제어기(following controller)를 구비한 운전 지원 장치가 기술되어 있다. 횡방향 움직임 범위 계산 유닛은 전방 주행 차량의 횡방향 움직임 범위를 계산한다. 장애물 회피 과정 검출 유닛은 전방 주행 차량의 장애물 회피 과정을 검출한다."}
{"patent_id": "10-2021-0159083", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명의 과제는 높은 신뢰성 및 컴퓨팅 용량의 효율적 사용을 특징으로 하는, 자동차에서 차체의 움 직임을 인식하기 위한 방법, 시스템 및 컴퓨터 프로그램 제품을 제공하는 것이다."}
{"patent_id": "10-2021-0159083", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따라, 상기 방법 관련 과제는 청구항 제1항의 특징들에 의해, 시스템 관련 과제는 청구항 제9항의 특 징들에 의해, 컴퓨터 프로그램 제품 관련 과제는 청구항 제15항의 특징들에 의해 해결된다. 다른 청구항들은 본 발명의 바람직한 구성과 관련이 있다. 제1 양태에 따르면, 본 발명은 자동차에서 데이터 분석 장치에 의해 차체의 움직임을 인식하기 위한 방법에 관 한 것이다. 이 방법은: 제2 자동차의 카메라 및 센서 장치에 의해 이미지 및 센서 데이터를 기록하는 단계; -이미지 및 센서 데이터는 적어도 제1 자동차를 포함하는 제2 자동차의 환경을 나타냄- 상기 이미지 및 센서 데이터를 데이터 분석 장치에 전달하는 단계; -데이터 분석 장치는 제1 자동차의 차체의 움직임을 인식하기 위한 인식 시스템을 포함하고, 인식 시스템은 인공 지능(AI) 및 머신 이미지 분석 분야의 알 고리즘을 사용함- 차체의 가능한 움직임을 분류하기 위해 인식 시스템에 의해 데이터 분석 장치에서 이미지 및 센서 데이터를 처 리하는 단계; 차체의 분류된 움직임을 정의된 상태들(S1, S2, ..., Sn)의 세트 중 적어도 하나의 상태(Sj)에 할당하는 단계; 상기 결정된 상태(Sj)로부터 자동화된 주행 기능에서의 추가 사용을 위해 및/또는 사용자 인터페이스를 위해 출 력 데이터를 생성하는 단계;를 포함한다. 본 발명의 일 개선예에서는, 이미지 및 센서 데이터의 처리 및 출력 데이터의 생성이 실시간으로 수행된다. 일 실시예에서, 인식 시스템은 분석 모듈 및 분류 모듈을 포함한다. 인식 시스템은 유리하게는 신경망을 이용한 딥 러닝을 사용한다. 특히, 신경망은 합성곱 신경망(convolutional neural network)으로서 구성된다. 일 개선예에서는, 분류 모듈이, 이 분류 모듈의 훈련 단계에서 결정되었거나 사전 정의된, 자동차의 차체 움직 임의 특징들(M1, M2, ..., Mn)을 포함한다. 이미지 및 센서 데이터는 유리하게는 무선 이동 연결에 의해 데이터 분석 장치에 전송되고, 특히 5G 무선 모듈 이 사용된다. 일 실시예에서는 이미지 및 센서 장치가 액션 카메라 및/또는 음향 센서 및/또는 LiDAR 시스템 및/또는 초음파 시스템 및/또는 레이더 시스템을 포함한다.제2 양태에 따르면, 본 발명은 자동차에서 차체의 움직임을 인식하기 위한 시스템에 관한 것이다. 이 시스템은 이미지 및 센서 데이터를 기록하기 위한 제2 자동차의 이미지 및 센서 장치와 데이터 분석 장치를 포함한다. 이미지 및 센서 데이터는 적어도 제1 자동차를 포함하는 제2 자동차의 환경을 나타낸다. 데이터 분석 장치는 제1 자동차에서 차체의 움직임을 인식하기 위한 인식 시스템을 포함한다. 인식 시스템은 인공 지능(AI) 및 머 신 이미지 분석 분야의 알고리즘을 사용한다. 데이터 분석 장치는, 인식 시스템에 의해 이미지 및 센서 데이터 를 처리하고, 차체의 가능한 움직임을 분류하며, 차체의 분류된 움직임에 정의된 상태들(S1, S2, ..., Sn)의 세 트 중 적어도 하나의 상태(Sj)를 할당하고, 상기 결정된 상태(Sj)로부터 자동화된 주행 기능에서의 추가 사용을 위해 그리고/또는 사용자 인터페이스를 위해 출력 데이터를 생성하도록 구성된다. 본 발명의 일 개선예에서는 이미지 및 센서 데이터의 처리와 출력 데이터의 생성이 실시간으로 수행된다. 일 실시예에서, 인식 시스템은 분석 모듈 및 분류 모듈을 포함한다. 유리하게는 인식 시스템이 특히 합성곱 신경망으로서 구성된 신경망을 이용한 딥 러닝을 사용한다. 특히, 분류 모듈은, 분류 모듈의 훈련 단계에서 결정되었거나 사전 정의된, 자동차의 차체의 움직임의 특징들 (M1, M2, ..., Mn)을 포함한다. 일 개선예에서, 이미지 및 센서 데이터는 무선 이동 연결에 의해 데이터 분석 장치에 전송되고, 이 경우 특히 5G 무선 모듈이 사용된다. 특히, 이미지 및 센서 장치는 액션 카메라 및/또는 음향 센서 및/또는 LiDAR 시스템 및/또는 초음파 시스템 및/ 또는 레이더 시스템을 포함한다. 제3 양태에 따라 본 발명은, 실행 시 제1 양태에 따른 방법을 수행하도록 구성된 실행 가능한 프로그램 코드를 포함하는 컴퓨터 프로그램 제품에 관한 것이다. 이하에서 본 발명은 도면에 도시된 실시예에 기반하여 더 상세히 설명된다."}
{"patent_id": "10-2021-0159083", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 본 발명에 따른 시스템을 도시한다. 전방 주행하는 자동차는 차체를 구비하며, 이를 뒤따 르는 자동차에 의해 관찰된다. 제2 자동차는 기록 영역 내에서 이미지 및 센서 데이터를 기록하기 위한 카메라 및 센서 장치를 구비한다. 카메라 및 센서 장치는 기록 영역 내에서 자동차의 주변을 기록하며, 이 기록 영역은 특히 자동차의 전방에 놓이고 제1 자동차가 위치해 있는 도로를 향해 정 렬된다. 이 경우, 차량의 차체는 직선으로 이동할 수 있거나, (도로상의 요철 또는 장애물을 암시할 수 있는) 진동하는 측방향 움직임 또는 상향 및 하향 움직임이 발생할 수 있다. 또한, 제동 및 가속 과정이 일 어날 수 있고, 그 결과 차체는 변화된 속도로 이동한다. 카메라 및 센서 장치는 기록된 이미지 및 센 서 데이터를 추가 처리를 위해 데이터 분석 장치에 전달한다. 카메라 및 센서 장치는 특히 청색, 녹색, 적색의 기본 색상을 가진 가시 범위의 RGB 카메라를 포함한다. 그러나 자외선 범위의 UV 카메라 및/또는 적외선 범위의 IR 카메라도 추가로 제공될 수 있다. 이로 써, 기록 스펙트럼이 상이한 카메라들이 기록 영역에서 상이한 광 조건을 이미징할 수 있다. 카메라 및 센서 장치의 카메라의 기록 빈도는 전방 주행 차량의 빠른 속도에 맞추어 설계되며, 높은 이 미지 기록 빈도로 이미지 데이터를 기록할 수 있다. 또한, 카메라 및 센서 장치에는, 마이크와 같은, 음향 신호를 캡처하기 위한 음향 센서가 장착될 수 있다. 이를 통해, 타이어의 롤링 소음 또는 엔진 소음 이 기록될 수 있다. 아울러, 이미지 및 센서 장치는 예를 들어 전방 주행 자동차와 후행하는 자동차 사이의 거리 또는 전방 주행 자동차의 속도를 측정하기 위해 LiDAR 시스템, 초음파 시스템, 및/또는 레이더 시스템을 구비할 수 있다. 특히 이는 3차원 공간에서의 정보를 캡처하는 것을 가능하게 한다. 또한, 카메라 및 센서 장치의 기록 영역에서 상당한 면적 변화가 있을 때, 예를 들어 차량이 카메라 및 센서 장치의 기록 영역 내에 나타나는 경우, 카메라 및 센서 장치가 이미지 기록 과정을 자동으로 시작 할 수 있다. 이를 통해 선택적 데이터 캡처 과정이 가능해지며, 관련 이미지 및 센서 데이터만 데이터 분 석 장치에 의해 처리된다. 이는 컴퓨팅 용량을 더 효율적으로 사용할 수 있게 한다. 또한, 지리적 위치를 결정하여 이를 기록된 이미지 및 센서 데이터에 할당하기 위해, 유리하게는 GPS(Global Positioning System) 연결이 제공된다. 특히, 카메라로서 내후성 액션 카메라가 사용되며, 액션 카메라는 특히 차량의 외부 영역에 배치될 수 있다. 액션 카메라는 광각 어안 렌즈를 구비하고, 그로 인해 약 180°의 가시 반경을 달성할 수 있다. 액션 카메라는 일반적으로 Full HD(1920 x 1080 픽셀)로 비디오를 기록할 수 있지만, Ultra HD 또는 4K(적어도 3840 x 2160 픽셀) 사양의 액션 카메라도 사용될 수 있으며, 이로써 이미지 품질이 상당히 향상된다. 이미지 기록 빈도는 일반적으로 4K에서는 초당 60개 이미지, Full HD에서는 초당 240개 이하의 이미지이다. 또한, 통합된 이미지 안정화기도 제공될 수 있다. 그 밖에도 액션 카메라에는 종종 내장 마이크가 장착되어 있다. 배경 잡 음을 의도적으로 차단하기 위해, 차동 신호 처리 방법도 사용될 수 있다. 카메라 및 센서 장치에 의해 기록된 이미지 및 센서 데이터는 바람직하게 와이어리스 무선 이동 연결을 통해 데이터 분석 장치에 전달된다. 데이터 분석 장치는 바람직하게 인식 시스템에 의해 이미지 및 센서 데이터를 처리하는 프로세서 를 구비한다. 프로세서 또는 또 다른 프로세서는 카메라 및 센서 장치를 제어하기 위해서도 구성 된다. 또는, 이미지 및 센서 데이터가 우선 메모리 유닛 또는 소프트웨어 모듈에 저장된 다음, 차 후에 데이터 분석 장치에 의해 처리되는 것도 고려될 수 있다. 데이터 분석 장치 및 프로세서는 차량에 통합될 수 있거나, 무선 이동 연결을 통해 차량에 연결된 클라우드 컴퓨팅 인프라 구조를 가진 클라우드 기반 솔루션으로서 구성될 수 있다. 또한, 데이터 분석 장치는 하나 이상의 다른 데이터베이스에 액세스할 수 있다. 데이터베이스는 예를 들어 기록된 이미지 및 센서 데이터 또는 다른 이미지를 분석하기 위한 분류 파라미터 및/또는 특성 변수를 저장할 수 있다. 나아가 안전 표준을 정의하는 목표 변수 및 목표 값이 데이터베이스에 저장될 수 있다. 또한, 추가 데이터를 입력하고, 데이터 분석 장치에 의해 생성되는 계산 결과를 표시하기 위한 사용 자 인터페이스가 제공될 수 있다. 특히 사용자 인터페이스는 터치스크린을 가진 디스플레이로서 구성 된다. 본 발명과 관련하여, \"프로세서\"는 예를 들어 기계 또는 전자 회로 또는 고성능 컴퓨터로 이해될 수 있다. 프 로세서는, 가능하게는 프로그램 명령 등을 저장하기 위한 메모리 유닛과 결합되는, 특히 메인 프로세서(Central Processing Unit, CPU), 마이크로프로세서 또는 마이크로컨트롤러, 예를 들어 주문형 집적 회로 또는 디지털 신 호 프로세서일 수 있다. 프로세서는 또한 가상화된 프로세서, 가상 머신 또는 소프트 CPU로 이해될 수 있다. 이는 또한 예를 들어, 본 발명에 따른 방법을 수행하기 위한 구성 단계들이 구비되거나; 프로그래밍 가능 프로 세서가 상기 방법, 구성요소, 모듈, 또는 본 발명의 다른 양태 및/또는 부분 양태의 본 발명에 따른 특징들을 구현하도록 구성된 구성 단계들을 가진; 프로그래밍 가능 프로세서일 수 있다. 또한, 고도의 병렬 컴퓨팅 유닛 및 고성능 그래픽 모듈이 제공될 수 있다. 본 발명과 관련하여, \"메모리 유닛\" 또는 \"메모리 모듈\" 등은 예를 들어 랜덤 액세스 메모리(RAM) 형태의 휘발 성 메모리, 또는 하드 디스크나 데이터 저장 매체와 같은 영구 메모리, 또는 예를 들어 교체 가능 메모리 모듈 로 이해될 수 있다. 메모리 모듈은 또한 클라우드 기반 메모리 솔루션일 수도 있다. 본 발명과 관련하여 \"모듈\"은 예를 들어, 프로그램 명령을 저장하기 위한 메모리 유닛 및/또는 프로세서로 이해 될 수 있다. 예를 들어, 프로세서는 특별히, 상기 프로세서가 본 발명에 따른 방법 또는 본 발명에 따른 방법 의 단계를 실시하거나 구현하는 기능을 수행하도록 프로그램 명령을 실행하도록 구성된다. 본 발명과 관련하여 기록된 이미지 및 센서 데이터는 이미지 및 센서 장치의 기록 결과로부터 이미 처 리된 데이터와 미가공 데이터 모두를 의미하는 것으로 이해되어야 한다. 특히, 이미지 및 센서 장치는 5G 표준의 무선 이동 모듈을 구비할 수 있다. 5G는 5세대 무선 이동 표준으 로서, 4G 무선 이동 표준과 비교하여, 10Gbit/초 이하의 더 높은 데이터 속도, 예를 들어 2100, 2600 또는 3600MHz의 더 높은 주파수 범위의 사용, 주파수 용량의 증가, 그리고 그에 따른 데이터 처리량의 증가 및 실시 간 데이터 전송을 특징으로 하는데, 이는 평방 킬로미터당 100만 개 이하의 장치가 동시에 처리될 수 있기 때문 이다. 대기 시간(latency time)은 수 밀리초에서 1ms 미만이며, 그 결과 데이터 및 계산 결과의 실시간 전송이 가능하다. 이미지 및 센서 장치에 의해 기록되는 이미지 및 센서 데이터는 상응하는 분석 및 계산이 수행되는 클라우드 컴퓨팅 플랫폼에 실시간으로 전송된다. 분석 및 계산 결과는 다시 차량에 실시간으로 전송되고, 그에 따라 신속하게 운전자를 위한 조작 안내에 또는 자동화된 주행 기능에 통합될 수 있다. 상기 속도는, 이미지 및 센서 데이터를 처리하기 위해 클라우드 기반 솔루션이 사용되어야 하는 경우에, 데이터 전송 시 필요하다. 클라우드 기반 솔루션은 고성능이고 그에 따라 빠른 컴퓨팅 능력의 이점을 제공한다. 데이터 분석 장치가 차량에 통합되는 경우, 실시간 처리를 가능하게 하기 위해, 유리하게는 Coral Dev Board와 같은 AI 하드웨어 가속이 프로세서를 위해 사용된다. 이는 텐서 처리 장치(TPU)를 갖는 마이크로 컴퓨터이며, 그 결과 사전 훈련된 소프트웨어 애플리케이션이 초당 최대 70개 이미지를 평가할 수 있다. 도 2에는, 차량에서 차체의 움직임 변화를 인식하기 위해 캡쳐되고 그리고/또는 저장된 이미지 및 센서 데이터를 분석하고 처리하기 위한 소프트웨어 애플리케이션으로서 구성된 본 발명에 따른 인식 시스템(40 0)이 도시되어 있다. 특히, 인식 시스템은 캡쳐된 이미지 및 센서 데이터를 선택하고 분류하기 위해 인공 지능 및 머신 이미지 분석 알고리즘에 의해 상기 데이터를 처리한다. 인식 시스템은 유리하게는 캡 쳐된 이미지 및 센서 데이터를 분석하기 위해, 예를 들어 머신 러닝, 바람직하게는 합성곱 신경망을 이용한 딥 러닝 분야의 알고리즘을 사용한다. 또한, 주행 상황의 포괄적 이미지를 얻기 위해, 광학, 음향, 및 거리 측 정과 같은 다양한 센서원으로부터의 이미지 및 센서 데이터가 서로 결합될 수 있다. 신경망은, 복수의 층으로 배치되고 서로 상이하게 연결되는 뉴런들을 포함한다. 뉴런은 입력부에서 외부로부터 또는 다른 뉴런으로부터 정보를 수신하고, 특정 방식으로 정보를 평가하며, 뉴런 출력부에서 변경된 형태로 다 른 뉴런에 정보를 전달하거나 최종 결과로서 정보를 출력할 수 있다. 입력 뉴런들과 출력 뉴런들 사이에 은폐 된 뉴런이 배치된다. 망 유형에 따라, 복수의 은폐 뉴런 층이 존재할 수 있다. 이들은 정보의 전달 및 처리를 담당한다. 출력 뉴런들은 최종적으로 결과를 제공하고 이를 외부 세계로 출력한다. 뉴런들의 배치 및 연결을 통해, 피드-포워드 망, 재순환 망, 또는 합성곱 신경망과 같은 상이한 유형의 신경망들이 형성된다. 이들 망은 자율 러닝(unsupervised learning) 또는 지도 러닝(supervised learning)에 의해 훈련될 수 있다. 특히, 인식 시스템은 합성곱 신경망(convolutional neural network, CNN)으로 구성된 분석 모듈을 구비한다. 분석 모듈의 입력 데이터로서 카메라 및 센서 장치로부터의 이미지 및 센서 데이터가 사용된다. 추가로 데이터베이스로부터의 데이터도 사용될 수 있다. 입력 데이터의 데이터 포맷은 바람직 하게 텐서(tensor)의 형태이다. 또한, 상이한 이미지 포맷들이 유리하게 사용될 수 있다. 합성곱 신경망은 인공 신경망의 특수한 형태이다. 이는 복수의 합성곱층을 구비하며, 이미지 및 음성 인식 분 야에서 인공 지능(AI)을 갖는 머신 러닝 및 애플리케이션에 매우 적합하다. 합성곱 신경망의 작동 방법은 어느 정도 생물학적 과정에서 모델링되고, 구조는 뇌의 시각 피질과 유사하다. 합성곱 신경망의 훈련은 일반적으로 지도 방식으로(in a supervised manner) 실시된다. 종래의 신경망은 복수의 레벨에서 완전 메쉬형(fully meshed) 또는 부분 메쉬형(partially meshed) 뉴런을 포함한다. 그러나 이러한 구조는 이미지 처리 시, 픽셀 수에 상응하는 수의 입력이 존재해야 하기 때문에, 한계에 도달한다. 합성곱 신경망은 상이한 층들로 구성되며, 기본 원리의 측면에서 로컬 메쉬형 피드-포워드 신경망이다. CNN의 개별 층들은 합성곱층 (covolutional layer), 풀링층(pooling layer) 및 완전 메쉬 층이다. 풀링층은 합성곱층을 따르며, 이러한 조 합으로 여러 번 연이어 존재할 수 있다. 풀링층 및 합성곱층은 로컬 메쉬 서브망이기 때문에, 이러한 층들에서 의 연결 수는 입력량이 많은 경우에도 제한적으로, 관리 가능한 프레임워크 내에 유지되된다. 완전 메쉬층이 종단(termination)을 형성한다. 합성곱층은 실제 합성곱 레벨이며, 입력 데이터의 개별 특징을 인식하고 추출 할 수 있다. 이미지 처리 시, 이들은 라인, 에지, 또는 특정 형상과 같은 특징일 수 있다. 입력 데이터는 행 렬 또는 벡터와 같은 텐서의 형태로 처리된다. 서브샘플링층으로도 지칭되는 풀링층은 인식된 특징들의 해상도 를 적합한 필터 기능을 통해 압축하고 감소시킨다. 특히, 이를 위해 데이터의 (일반적으로) 겹치지 않는 서브 영역에 대한 최대값을 각각 계산하는 최대 풀 함수(max pool function)가 사용된다. 그러나 최대 풀링(maximum pooling) 외에 평균값 풀링도 사용될 수 있다. 풀링은 불필요한 정보를 폐기하고 데이터량을 줄인다. 그 결과, 머신 러닝 시 성능이 저하되지 않는다. 데이터량의 감소로 인해 계산 속도가 빨라진다. 완전 연결층(fully connected layer)이 합성곱 신경망의 종단을 형성한다. 완전 연결층은 합성곱층 및 풀링층 의 반복된 시퀀스의 결과이다. 상위층들의 모든 특징 및 요소가 각각의 출력 특징과 연결된다. 완전 연결 뉴 런은 복수의 레벨로 배치될 수 있다. 뉴런의 수는 합성곱 신경망에 의해 처리되도록 의도된 입력 데이터에 좌 우된다. 따라서, 합성곱 신경망(CNN)은 종래의 비합성곱 신경망에 비해 많은 이점을 제공한다. 이는 이미지 인식에서와 같이 다량의 입력 데이터를 이용하는 머신 러닝 및 인공 지능 애플리케이션에 적합하다. 망은 신뢰성 있게 동 작하고, 왜곡 또는 여타의 광학적 변화에 둔감하다. CNN은 상이한 광 조건 및 상이한 관점에서 기록되는 이미 지를 처리할 수 있다. 그럼에도 이미지의 전형적인 특징을 인식한다. CNN은 복수의 로컬 서브 메쉬층으로 나 뉘기 때문에, 완전 메쉬 신경망보다 훨씬 더 적은 메모리 공간 수요를 갖는다. 합성곱층들은 메모리 요구를 상 당히 줄인다. 이는 합성곱 신경망의 훈련 시간도 상당히 단축한다. CNN은 최신 그래픽 프로세서를 사용하여 매우 효율적으로 훈련될 수 있다. CNN은 필터의 도움으로 입력 이미지의 특징들을 인식하여 추출한다. CNN은 먼저 제1 층에서 라인, 색상 특징, 또는 에지와 같은 간단한 구조를 인식한다. 다른 층에서 합성곱 신경망은 간단한 형상 또는 곡선과 같은, 상기 구조들의 조합을 학습한다. 각각의 레벨에 의해 더 복잡한 구조들이 식별 될 수 있다. 데이터는 레벨들에서 반복하여 다시 샘플링되고 필터링된다. 따라서, 분석 모듈에서 이미지 및 센서 데이터는 바람직하게 합성곱 신경망에 의해 처리된다. 또한, 차량의 차체의 움직임의 특징들(M1, M2, ..., Mn)을 포함하는 분류 모듈이 제공된다. 또한, 상기 특징 들(M1, M2, ..., Mn)에 차량 환경의 특정 상태들(S1, S2, ..., Sn)이 할당될 수 있다. 즉, 차체의 특정 의 빠른 상향 및 하향 움직임은 도로의 노면에 있을 수 있는 요철 및/또는 손상을 암시할 수 있다. 차체 의 측방향 움직임은, 도로 상에 존재하며 전방 주행 차량에 의해 회피된 장애물을 암시할 수 있다. 전방 주행 차량과의 너무 짧은 거리가 검출될 수 있고, 이는 위험한 주행 상황을 가리킬 수 있다. 상태들 (S1, S2, ..., Sn)에는 다시 낮음(low)에서 높음(high)까지와 같은 안전 단계가 할당될 수 있다. 상기 특징들 (M1, M2, ..., Mn) 및/또는 차량 환경의 상태들(S1, S2, ..., Sn)은 바람직하게 훈련 단계에서 CNN에 의해 결 정되었거나 사전 정의되어 분류 모듈에 전송된 것들이다. 이러한 방식으로 처리된 이미지 및 센서 데이터는 출력 데이터로서 자동화된 주행 기능에 통합되고 그 리고/또는 사용자 인터페이스에 전송된다. 상기 데이터는 거기서 차량 운전자에게 추천된 조치 (recommended actions) 또는 경고로서 출력될 수 있다. 예를 들어, 운전자가 운전 거동을 바꾸도록 유도하기 위한 경고음 또는 시각적 안내가 사용자 인터페이스를 통해 출력될 수 있다. 자동화된 주행 기능의 경우, 예를 들어 자동으로 주행 속도가 감소할 수 있다. 게다가, 차량의 전방 차축 및/또는 후방 차축을 위한 댐 핑 유닛의 자동 조정이 수행될 수 있고, 그 결과 예를 들어 댐핑이 더 부드럽게 조정됨에 따라 차량은 도로 요철 또는 도로 손상부 위를 지날 때 더 안전하게 그리고 탑승자에게 더 편안함을 느낄수 있게 주행할 수 있다. 따라서 본 발명에 따라 전방 주행 자동차의 차체 움직임을 인식하기 위한 방법은 하기 단계를 포함한다: 단계(S10)에서는, 제2 자동차의 카메라 및 센서 장치에 의해 이미지 및 센서 데이터를 기록하고, 여기서 이미지 및 센서 데이터는 적어도 제1 자동차를 포함하는 차량의 환경을 나타낸다. 단계(S20)에서는, 이미지 및 센서 데이터를 데이터 분석 장치에 전달하고, 여기서 데이터 분석 장치 는 제1 자동차의 차체의 움직임을 인식하기 위한 인식 시스템을 포함하며, 이 인식 시스템은 인공 지능(AI) 및 머신 이미지 분석 분야의 알고리즘을 사용한다. 단계(S30)에서는, 데이터 분석 장치에서 차체의 가능한 움직임을 분류하기 위해 인식 시스템을 이 용하여 이미지 및 센서 데이터를 처리한다. 단계(S40)에서는, 분류된 움직임에 정의된 상태들(S1, S2, ..., Sn)의 세트 중 적어도 하나의 상태(Sj)를 할당한 다. 단계(S50)에서는, 상기 결정된 상태(Sj)로부터, 자동화된 주행 기능에서의 추가 사용을 위해 그리고/또는 사용 자 인터페이스를 위해 출력 데이터를 생성한다. 이로써, 인공 지능(AI) 및 머신 이미지 분석 분야의 알고리즘을 사용하는 인식 시스템에 의해, 제2 자동차 의 환경으로부터의 이미지가 전방 주행 차량의 차체 움직임과 관련하여 실시간으로 분석될 수 있다. 본 발명은 차량의 차체 움직임의 자동 캡처를 가능하게 한다. 상기 분류된 움직임으로부터 도 로 표면의 손상 또는 요철의 발생과 같은 도로 상황이 유추될 수 있다. 전방 주행 차량의 차체 움직임이 제2 차량에 위험한 주행 상황을 가리키는 경우, 분석 결과는 예를 들어 시각적 및/또는 청각적 경고 신 호로서 제2 차량의 사용자 인터페이스로 출력된다. 또한, 자동 또는 반자동 주행 기능을 통해, 전방 및/또는 후방 차축에 대한 댐핑 정도와 같은 차량 구성요소들 의 설정 또는 주행 거동의 조정이 수행될 수 있다. 전방 주행 차량까지 지나치게 짧은 거리가 검출되는 경 우, 차량의 주행 속도가 자동으로 감소할 수 있거나 제동 과정이 개시될 수 있다. 데이터가 실시간으로 전 송되고 평가되기 때문에, 밀리초 범위의 빠른 응답이 가능하다. 이는 특히 차량의 주행 속도가 빠른 경우 에 매우 중요한데, 그 이유는 이 방식으로만 자동 주행 기능이 현재 주행 상황에 적절하게 반응하는 것을 보장 할 수 있기 때문이다. 따라서, 본 발명은 주행 중 안전성을 더욱 향상시킬 수 있게 해 준다."}
{"patent_id": "10-2021-0159083", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 자동차에서 차체의 움직임을 인식하기 위한 본 발명에 따른 시스템의 개략도이다. 도 2는 본 발명에 따른 인식 시스템의 실시예를 도시한 도면이다. 도 3은 본 발명에 따른 방법의 개별 방법 단계들을 설명하기 위한 흐름도이다. 도 4는 본 발명의 제3 양태의 일 실시예에 따른 컴퓨터 프로그램 제품을 도시한 도면이다. 본 발명의 추가 특징들, 양태들 및 이점들 또는 실시예들은 청구항들과 연계된 상세한 설명을 통해 명확해진다."}
