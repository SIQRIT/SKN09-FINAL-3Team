{"patent_id": "10-2023-0138219", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0054959", "출원번호": "10-2023-0138219", "발명의 명칭": "가상 인프라 기반 인공지능 서비스 실행 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "최현화"}}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 서버 클러스터를 이용하여 가상 인프라 기반 인공지능 서비스 실행을 지원하는 방법에 있어서,연산 처리 장치의 공유 타입을 설정하는 단계;인공지능 서비스의 요구사항 및 상기 연산 처리 장치의 공유 타입 정보를 이용하여 가상 인프라 기반 인공지능서비스를 실행하는 단계; 및인공지능 서비스에 대한 최적화를 수행하는 단계;를 포함하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 연산 처리 장치의 공유 타입은연산 처리 장치의 자원을 복수의 가상 인프라가 공유하는 타입; 및 연산 처리 장치의 자원을 분할하여 가상 연산 처리 장치를 생성하는 타입;을 포함하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 연산 처리 장치의 공유 타입은연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하는 제1 타입;연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하되, 상기 복수 가상 인프라의 AI 서비스는 단일 컨텍스트로 통합되는 제2 타입;연산 처리 장치의 메모리를 분할하여 복수의 가상 연산 처리 장치를 생성하는 제3 타입; 및연산 처리 장치의 메모리 및 코어를 분할하여 복수의 가상 연산 처리 장치를 생성하는 제4 타입을 포함하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 인공지능 서비스의 요구사항은연산 처리 장치 자원 정보, 인공지능 서비스의 모델 정보, 가상 인프라 타입 정보 및 독립 실행 필요 여부를 포함하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 가상 인프라의 타입은 가상 머신 또는 컨테이너를 포함하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2025-0054959-3-청구항 1에 있어서,상기 최적화를 수행하는 단계는연산 처리 장치 분할, 배치 크기, 인공지능 모델 간 동시 실행 조합 및 연산 처리 장치의 공유 타입에 대한 최적화를 수행하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 인공지능 서비스를 실행하는 단계는인공지능 서비스의 요구사항을 만족하는 연산 처리 장치 자원이 존재하지 않으면, 상기 인공지능 서비스를 대기큐에 삽입하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 최적화를 수행하는 단계는상기 연산 처리 장치의 활용률 또는 상기 대기 큐에 대기 중인 인공지능 서비스가 존재하는지 여부에 기반하여최적화 수행 여부를 결정하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 6에 있어서,상기 최적화를 수행하는 단계는인공지능 서비스 마이그레이션을 수행하되, 필요한 경우 상기 연산 처리 장치의 공유 타입을 변경하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 7에 있어서,상기 최적화를 수행하는 단계는상기 연산 처리 장치의 활용률이 제1 임계값을 초과하면, 상기 연산 장치에서 실행중인 인공지능 서비스를 다른연산 처리 장치에 재배치하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 1에 있어서,상기 최적화를 수행하는 단계는상기 연산 처리 장치에서 동시에 실행중인 인공지능 서비스의 처리량이 제2 임계값 미만이면 인공지능 서비스의마이그레이션을 수행하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "연산 처리 장치의 공유 타입을 설정하는 타입 설정부;인공지능 서비스의 요구사항 및 상기 연산 처리 장치의 공유 타입 정보를 이용하여 가상 인프라 기반으로 인공지능 서비스를 실행하는 서비스 실행부; 및실행 중인 인공지능 서비스에 대한 최적화를 수행하는 최적화부;를 포함하는 가상 인프라 기반 인공지능 서비스 실행 장치."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2025-0054959-4-청구항 12에 있어서,상기 연산 처리 장치의 공유 타입은연산 처리 장치의 자원을 복수의 가상 인프라가 공유하는 타입; 및 연산 처리 장치의 자원을 분할하여 가상 연산 처리 장치를 생성하는 타입;을 포함하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 장치."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 12에 있어서,상기 연산 처리 장치의 공유 타입은연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하는 제1 타입;연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하되, 상기 복수 가상 인프라의 AI 서비스는 단일 컨텍스트로 통합되는 제2 타입;연산 처리 장치의 메모리를 분할하여 복수의 가상 연산 처리 장치를 생성하는 제3 타입; 및연산 처리 장치의 메모리 및 코어를 분할하여 복수의 가상 연산 처리 장치를 생성하는 제4 타입을 포함하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 장치."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 12에 있어서,상기 인공지능 서비스의 요구사항은연산 처리 장치 자원 정보, 인공지능 서비스의 모델 정보, 가상 인프라 타입 정보 및 독립 실행 필요 여부를 포함하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 장치."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 12에 있어서,상기 가상 인프라의 타입은 가상 머신 또는 컨테이너를 포함하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 장치."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 12에 있어서,상기 최적화부는연산 처리 장치 분할, 배치 크기, 인공지능 모델 간 동시 실행 조합 및 연산 처리 장치의 공유 타입에 대한 최적화를 수행하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 장치."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 12에 있어서,상기 서비스 실행부는인공지능 서비스의 요구사항을 만족하는 연산 처리 장치 자원이 존재하지 않으면, 상기 인공지능 서비스를 대기큐에 삽입하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 장치."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 18에 있어서,상기 최적화부는공개특허 10-2025-0054959-5-상기 연산 처리 장치의 활용률 또는 상기 대기 큐에 대기 중인 인공지능 서비스가 존재하는지 여부에 기반하여최적화 수행 여부를 결정하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 장치."}
{"patent_id": "10-2023-0138219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨팅 서버 클러스터를 이용하여 가상 인프라 기반 인공지능 서비스 실행을 지원하는 방법에 있어서,인공지능 서비스의 요구사항 및 인공지능 모델 간 동시 실행 조합 정보를 이용하여 가상 인프라 기반 인공지능서비스를 실행하는 단계; 및인공지능 서비스에 대한 최적화를 수행하는 단계;를 포함하고,상기 인공지능 모델 간 동시 실행 조합 정보는 복수의 인공지능 모델을 동시에 실행하는 경우 각각의 인공지능모델에 대한 처리량 정보를 포함하는 것을 특징으로 하는 가상 인프라 기반 인공지능 서비스 실행 방법."}
{"patent_id": "10-2023-0138219", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 방법은 연산 처리 장치의 공유 타입을 설정 하는 단계; 인공지능 서비스의 요구사항 및 상기 연산 처리 장치의 공유 타입 정보를 이용하여 가상 인프라 기반 인공지능 서비스를 실행하는 단계; 및 인공지능 서비스에 대한 최적화를 수행하는 단계를 포함한다."}
{"patent_id": "10-2023-0138219", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컴퓨팅 서버에 설치된 GPU를 사용하여 다수의 AI 서비스를 실행하는 기술에 관한 것이다. 구체적으로, 본 발명은 GPU의 활용도를 높이기 위하여 가상 머신 혹은 컨테이너 기반한 AI 서비스들이 GPU를 공 유하고 동시 실행의 최적 조합으로 배치하는 기술에 관한 것이다."}
{"patent_id": "10-2023-0138219", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, GPU의 사양이 고사양화 되면서 GPU의 자원(메모리, Compute cores) 들이 해당 AI 서비스에 의해 모두 활 용되지 못하는 경우가 발생하고 있다. 한 예로, NVIDIA에서 H100 PCIe 사양을 살펴보면, 메모리 80GB, 2TB의 메 모리 bandwidth를 제공하며, TF32는 756TFLOPS (Tera FLOPS)를 제공한다. 알리바바 데이터센터 내의 PCIe 기반 P100(초대 18.7 TFLOPS, 메모리 16G, 대역폭 732GB/s)을 대상으로 DjiNN and Tonic workload suite의 DNN inference queries를 수행하였을 경우 1개의 추론 (inference queries)은 GPU 메모리의 10%, 128개의 추론 시 에 GPU 메모리의 50% 만을 소비한 것으로 알려져 있다. 이러한 이유로, GPU를 공유하여 다수의 AI 서비스를 실행하는 기술이 주목받고 있다. 먼저, GPU도 CPU와 같이 time-sharing의 스케줄러가 지원되고 있으나, GPU 컨텍스트(context)가 보통 CPU보다 훨씬 크다 보니 컨텍스트 스위칭(context switching)의 비용이 커서 많이 활용되지 못했다. 한편, 1개의 GPU를 다수의 virtual GPUs로 구성하는 가상화 기술도 개발되어 그 활용이 증대되고 있다. 이러한 GPU 공유 기술들은 보통 AI 서비스의 가상 인프라를 배치(실행)하기 이전에 컴퓨팅 서버에 장착된 GPU를 공유하는 방법을 미리 규정하고 환경을 설정한 후 에 활용되는 정적인 형태로 이뤄지고 있다 1개 이상의 컴퓨팅 서버들로 구성되는 클러스터에서 다수의 사용자 요청에 의해 AI 서비스를 실행하기 위해서는 서비스 성능을 보장하면서 GPU 활용도(utility)를 높이기 위해서 GPU의 공유 방법을 설정하고 변경함으로써 AI 서비스의 가상 인프라의 최적 배치 및 실행할 수 있는 동적 방법과 장치가 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내 등록특허공보 제10-2032521호(발명의 명칭: 컨테이너 기반의 gpu 가상화 방법 및 시스템)"}
{"patent_id": "10-2023-0138219", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 인공지능 서비스 실행을 위한 자원 요구량을 파악하여 최적의 GPU 공유 정책을 수립하여 활용 률을 높이는 것이다. 또한, 본 발명의 목적은 다수의 인공지능 서비스를 실행할 때, 최적 조합을 구축하여 GPU의 활용률을 높이는 것 이다."}
{"patent_id": "10-2023-0138219", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 방법은 연산 처리 장치의 공유 타입을 설정하는 단계; 인공지능 서비스의 요구사항 및 상기 연산 처리 장치의 공유 타입 정 보를 이용하여 가상 인프라 기반 인공지능 서비스를 실행하는 단계; 및 인공지능 서비스에 대한 최적화를 수행 하는 단계를 포함한다. 이때, 상기 연산 처리 장치의 공유 타입은 연산 처리 장치의 자원을 복수의 가상 인프라가 공유하는 타입; 및 연산 처리 장치의 자원을 분할하여 가상 연산 처리 장치를 생성하는 타입을 포함할 수 있다. 이때, 상기 연산 처리 장치의 공유 타입은 연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하는 제1 타입; 연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하되, 상기 복수 가상 인프라의 AI 서비스는 단일 컨텍스트로 통합되는 제2 타입; 연산 처리 장치의 메모리를 분할하여 복수의 가상 연산 처리 장 치를 생성하는 제3 타입; 연산 처리 장치의 메모리 및 코어를 분할하여 복수의 가상 연산 처리 장치를 생성하는 제4 타입을 포함할 수 있다. 이때, 상기 인공지능 서비스의 요구사항은 연산 처리 장치 자원 정보, 인공지능 서비스의 모델 정보, 가상 인프 라 타입 정보 및 독립 실행 필요 여부를 포함할 수 있다. 이때, 상기 가상 인프라의 타입은 가상 머신 또는 컨테이너를 포함할 수 있다. 이때, 상기 최적화를 수행하는 단계는 연산 처리 장치 분할, 배치 크기, 인공지능 모델 간 동시 실행 조합 및 연산 처리 장치의 공유 타입에 대한 최적화를 수행할 수 있다. 이때, 상기 인공지능 서비스를 실행하는 단계는 인공지능 서비스의 요구사항을 만족하는 연산 처리 장치 자원이 존재하지 않으면, 상기 인공지능 서비스를 대기 큐에 삽입할 수 있다. 이때, 상기 최적화를 수행하는 단계는 상기 연산 처리 장치의 활용률 또는 상기 대기 큐에 대기 중인 인공지능 서비스가 존재하는지 여부에 기반하여 최적화 수행 여부를 결정할 수 있다. 이때, 상기 최적화를 수행하는 단계는 인공지능 서비스 마이그레이션을 수행하되, 필요한 경우 상기 연산 처리 장치의 공유 타입을 변경할 수 있다. 이때, 상기 최적화를 수행하는 단계는 상기 연산 처리 장치의 활용률이 제1 임계값을 초과하면, 상기 연산 장치 에서 실행중인 인공지능 서비스를 다른 연산 처리 장치에 재배치할 수 있다. 이때, 상기 최적화를 수행하는 단계는 상기 연산 처리 장치에서 동시에 실행중인 인공지능 서비스의 처리량이 제2 임계값 미만이면 인공지능 서비스의 마이그레이션을 수행할 수 있다. 또한, 상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 장치 는 연산 처리 장치의 공유 타입을 설정하는 타입 설정부; 인공지능 서비스의 요구사항 및 상기 연산 처리 장치 의 공유 타입 정보를 이용하여 가상 인프라 기반으로 인공지능 서비스를 실행하는 서비스 실행부; 및 실행 중인 인공지능 서비스에 대한 최적화를 수행하는 최적화부를 포함한다. 이때, 상기 연산 처리 장치의 공유 타입은 연산 처리 장치의 자원을 복수의 가상 인프라가 공유하는 타입; 및 연산 처리 장치의 자원을 분할하여 가상 연산 처리 장치를 생성하는 타입을 포함한다. 이때, 상기 연산 처리 장치의 공유 타입은 연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하는 제1 타입; 연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하되, 상기 복수 가상 인프라의 AI 서비스는 단일 컨텍스트로 통합되는 제2 타입; 연산 처리 장치의 메모리를 분할하여 복수의 가상 연산 처리 장 치를 생성하는 제3 타입; 및 연산 처리 장치의 메모리 및 코어를 분할하여 복수의 가상 연산 처리 장치를 생성 하는 제4 타입을 포함할 수 있다. 이때, 상기 인공지능 서비스의 요구사항은 연산 처리 장치 자원 정보, 인공지능 서비스의 모델 정보, 가상 인프 라 타입 정보 및 독립 실행 필요 여부를 포함할 수 있다. 이때, 상기 가상 인프라의 타입은 가상 머신 또는 컨테이너를 포함할 수 있다. 이때, 상기 최적화부는 연산 처리 장치 분할, 배치 크기, 인공지능 모델 간 동시 실행 조합 및 연산 처리 장치 의 공유 타입에 대한 최적화를 수행할 수 있다. 이때, 상기 서비스 실행부는 인공지능 서비스의 요구사항을 만족하는 연산 처리 장치 자원이 존재하지 않으면, 상기 인공지능 서비스를 대기 큐에 삽입할 수 있다. 이때, 상기 최적화부는 상기 연산 처리 장치의 활용률 또는 상기 대기 큐에 대기 중인 인공지능 서비스가 존재 하는지 여부에 기반하여 최적화 수행 여부를 결정할 수 있다. 이때, 상기 최적화부는 인공지능 서비스 마이그레이션을 수행하되, 필요한 경우 상기 연산 처리 장치의 공유 타 입을 변경할 수 있다. 이때, 상기 최적화부는 상기 연산 처리 장치의 활용률이 제1 임계값을 초과하면, 상기 연산 장치에서 실행중인 인공지능 서비스를 다른 연산 처리 장치에 재배치할 수 있다. 이때, 상기 최적화부는 상기 연산 처리 장치에서 동시에 실행중인 인공지능 서비스의 처리량이 제2 임계값 미만 이면 인공지능 서비스의 마이그레이션을 수행할 수 있다. 또한, 상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행을 지 원하는 방법은, 인공지능 서비스의 요구사항 및 인공지능 모델 간 동시 실행 조합 정보를 이용하여 가상 인프라 기반 인공지능 서비스를 실행하는 단계; 및 인공지능 서비스에 대한 최적화를 수행하는 단계;를 포함한다."}
{"patent_id": "10-2023-0138219", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 인공지능 서비스 실행을 위한 자원 요구량을 파악하여 최적의 GPU 공유 정책을 수립하여 활 용률을 높일 수 있다. 또한, 본 발명은 본 발명의 목적은 다수의 인공지능 서비스를 실행할 때, 최적 조합을 구축하여 GPU의 활용률을 높일 수 있다."}
{"patent_id": "10-2023-0138219", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로"}
{"patent_id": "10-2023-0138219", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 비록 \"제1\" 또는 \"제2\" 등이 다양한 구성요소를 서술하기 위해서 사용되나, 이러한 구성요소는 상기와 같은 용 어에 의해 제한되지 않는다. 상기와 같은 용어는 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용될 수 있다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있다. 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세 서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 또는 \"포함하는(comprising)\"은 언급된 구성요소 또는 단계가 하나 이상의 다른 구성요소 또는 단 계의 존재 또는 추가를 배제하지 않는다는 의미를 내포한다. 본 명세서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함 께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다."}
{"patent_id": "10-2023-0138219", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 해석될 수 있다. 또한, 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 도 1은 가상 인프라 기반 인공지능 서비스 실행의 일 예이다. 도 1을 참조하면, 영상 분석을 통한 상황 인지, 주변 감시 등의 AI 서비스의 실행을 위한 가상 인프라(컨테이너, 가상머신)에 하나의 GPU가 할당되어 전용 사용될 수 있다. 사용자로부터 AI 서비스 실행 요청 을 받은 전역 스케줄러(Global Scheduler)는 1개 이상의 컴퓨팅 서버 노드들로 구성된 클러스터에서 자원 할당 정보와 각 컴퓨팅 노드 내의 지역 모니터(Local Monitor)로부터 수집된 자원과 서비스의 상태 정보를 바탕으로 노드 셀렉터가 여유 자원을 가진 컴퓨팅 서버 노드를 선정한다. 해당 컴퓨팅 서버 노드의 자원 할당자(Resource Allocator)는 노드 셀렉터로부터 AI 서비스 실행 요청을 받아, 지역 자원(local resource)를 할당하여 실행한다. 이때, AI 서비스 실행은 컨테이너 혹은 가상 머신의 가상 인 프라를 바탕으로 실행될 수 있으며, 가상 인프라의 이미지는 클러스터 내 공용 저장소(storage) 나 외부 저장소 를 통해 접근할 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 본 발명의 일 실시예에 따른 방법은 하나의 GPU를 대상으로 다수의 AI 서비스를 실행하는 데 있어, GPU 활용률 및 서비스 처리량이 낮은 경우 클러스터내 GPU의 전역 최적화를 수행할 수 있다. 전역 최적화는 GPU 내부 자원 의 분리(isolation) 형태를 4가지 타입으로 분류하여 GPU 공유 정책을 동적으로 변경하고 서비스 마이그레이션 및 추가 AI 서비스를 실행할 수 있다. 또한, AI 서비스 마이그레이션(즉, 가상 인프라 마이그레이션)을 통해 다수의 GPU 자원의 여유 파편을 수집하고 GPU의 공유 정책 변경을 통해, AI 서비스를 추가로 실행할 수 있는 환경을 구축함으로써 컴퓨팅 서버 클러스터 의 GPU 활용률을 높일 수 있다. 이때, 컴퓨팅 서버 내의 GPU별 공유 정책을 동적으로 변경하고 AI 서비스를 실 행할 수 있다. 도 2는 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 방법을 나타낸 흐름도이다. 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 방법은 컴퓨팅 디바이스 또는 서버와 같은 인공지능 서비스 실행 장치에 의해 수행될 수 있다. 또한, 본 발명의 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 방법은 컴퓨팅 서버 클러스터를 이용하여 수행될 수 있다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 방법은 연산 처리 장치 의 공유 타입을 설정하는 단계(S110), 인공지능 서비스의 요구사항 및 상기 연산 처리 장치의 공유 타입 정보를 이용하여 가상 인프라 기반 인공지능 서비스를 실행하는 단계(S120) 및 인공지능 서비스에 대한 최적화를 수행 하는 단계(S130)를 포함한다. 이때, 상기 연산 처리 장치의 공유 타입은 연산 처리 장치의 자원을 복수의 가상 인프라가 공유하는 타입 및 연 산 처리 장치의 자원을 분할하여 가상 연산 처리 장치를 생성하는 타입을 포함할 수 있다. 이때, 상기 연산 처리 장치의 공유 타입은 연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하는 제1 타입, 연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하되, 상기 복수 가상 인프라의 AI 서비스는 단일 컨텍스트로 통합되는 제2 타입, 연산 처리 장치의 메모리를 분할하여 복수의 가상 연산 처리 장 치를 생성하는 제3 타입 및 연산 처리 장치의 메모리 및 코어를 분할하여 복수의 가상 연산 처리 장치를 생성하 는 제4 타입을 포함할 수 있다. 이때, 상기 인공지능 서비스의 요구사항은 연산 처리 장치 자원 정보, 인공지능 서비스의 모델 정보, 가상 인프 라 타입 정보 및 독립 실행 필요 여부를 포함할 수 있다. 이때, 상기 가상 인프라의 타입은 가상 머신 또는 컨테이너를 포함할 수 있다. 이때, 상기 최적화를 수행하는 단계(S130)는 연산 처리 장치 분할, 배치 크기, 인공지능 모델 간 동시 실행 조 합 및 연산 처리 장치의 공유 타입에 대한 최적화를 수행할 수 있다. 이때, 상기 인공지능 서비스를 실행하는 단계(S120)는 인공지능 서비스의 요구사항을 만족하는 연산 처리 장치 자원이 존재하지 않으면, 상기 인공지능 서비스를 대기 큐에 삽입할 수 있다. 이때, 상기 최적화를 수행하는 단계(S130)는 상기 연산 처리 장치의 활용률 또는 상기 대기 큐에 대기 중인 인 공지능 서비스가 존재하는지 여부에 기반하여 최적화 수행 여부를 결정할 수 있다. 이때, 상기 최적화를 수행하는 단계(S130)는 인공지능 서비스 마이그레이션을 수행하되, 필요한 경우 상기 연산 처리 장치의 공유 타입을 변경할 수 있다. 이때, 상기 최적화를 수행하는 단계(S130)는 상기 연산 처리 장치의 활용률이 제1 임계값을 초과하면, 상기 연 산 장치에서 실행중인 인공지능 서비스를 다른 연산 처리 장치에 재배치할 수 있다. 이때, 상기 최적화를 수행하는 단계(S130)는 상기 연산 처리 장치에서 동시에 실행중인 인공지능 서비스의 처리 량이 제2 임계값 미만이면 인공지능 서비스의 마이그레이션을 수행할 수 있다. 도 3은 본 발명의 일 실시예에 따른 GPU 활용 강화 장치를 나타낸 블록도이다. 도 3을 참조하면, 본 발명에 따른 GPU 활용 강화 장치(시스템)은 전역 GPU-서빙 컨트롤러(Global GPU-Serving Controller, 100)와 지역 GPU-서빙 컨트롤러 (Local GPU-Serving Controller, 200), AI 서비스 프로파일러(AI Service Profiler, 300)로 구성된다. 이때, 전역 GPU-서빙 컨트롤러와 AI 서비스 프로파일러는 같은 컴퓨팅 서버에 배치되거나, 각각 서로 다른 컴퓨팅 서버에 배치되어 실행될 수 있다. 지역 GPU-서빙 컨트롤러는 AI 서비스를 실행하는 클러스터 내 각 컴퓨팅 서버에 배치되어 실행될 수 있다. 도 4는 전역 GPU-서빙 컨트롤러를 상세히 나타낸 블록도이다. 도 4를 참조하면, 사용자(Client)는 전역 GPU-서빙 컨트롤러(Global GPU-Serving Controller) 블록의 AI 서비 스 서빙 게이트웨이 유닛 을 통해 AI 서비스 제어(AI service control), 전역 최적화(Global Optimization), 전역 모니터링(Global Monitoring), AI 서비스 실행 정책 관리(AI Service Execution Policy Management) 를 요청할 수 있다. AI 서비스 제어(AI Service control) 유닛은 컨테이너, 가상 머신과 같은 가상 인프라를 기반으로 AI 서비 스를 실행할 수 있다. 또한, AI 서비스 제어 유닛은 인공지능 서비스의 중지 및 재시작, 삭제의 기능을 가 질 수 있다. AI 서비스의 실행은 전역 최적화 유닛을 통해 서비스를 배치할 컴퓨팅 서버 내 특정 GPU를 선정하 고, 해당 컴퓨팅 서버 노드의 지역 GPU-서빙 컨트롤러에게 AI 서비스의 실행을 요청할 수 있다. 그리고, AI 서 비스의 실행 정보를 인공지능 서비스 실행 정책 관리 유닛을 통해 저장한다. 마찬가지로, AI 서비스의 중지 및 재실행, 삭제 요청은 해당 AI 서비스가 실행되고 있는 컴퓨팅 서버의 지역 GPU-서빙 컨트롤러에 요청하여 처리한 후, AI 서비스 실행 정책 관리를 통해 관련 정보를 반영할 수 있다. 한편, 현재 AI 서비스를 실행할 수 있는 가용 자원을 가지는 GPU는 없으나, 추후 여유 자원을 가지는 GPU가 생 길 시에 AI 서비스를 실행하기 위해 AI 서비스 실행 정책 관리 유닛을 통해 준비 큐(ready queue) 에 추가 할 수 있다. 전역 최적화(Global Optimization) 유닛은 AI 서비스 제어 유닛으로부터 AI 서비스를 배치할 컴퓨팅 서버 와 GPU 선정 요청을 받아 처리하고 결과값을 반환할 수 있다. 배치할 컴퓨팅 서버와 GPU 선정 시에는 AI 서비스 실행의 요구사항(Execution Requirement Specification)을 필요로 하며, 반환하는 결과값에는 GPU의 공유 정책 타입을 포함할 수 있다. AI 서비스 실행 요구사항은 사용자로부터 입력, AI 서비스 실행 정책 관리 유닛과 AI 서비스 프로파일러를 통해 도출될 수 있다. AI 서비스 실행 요구사항에는 CPU cores 수, 메모리양, GPU의 메모리양 등의 자원 정보를 포함할 수 있으며, AI 서비스에서 사용되는 AI 모델, 가상 인프라 타입, 독립실행 보장 여부, 배치 크기, 지연시간, 동시 실행 시 최 적의 AI 모델 등의 정보를 더 포함할 수 있다. 여기서 가상 인프라 타입에는 컨테이너, 가상머신 중의 하나의 타입을 지정할 수 있으며, 독립실행 보장 여부는 GPU내 메모리, compute core와 같은 자원의 독립 분리를 통한 가상 GPU 인스턴스를 할당을 여부를 포함할 수 있다. 전역 최적화 유닛은 1) 실행하고자 하는 AI 서비스 실행 요구사항, 2) AI 서비스 실행 정책 관리 유닛을 통해 얻은 현재 클러스터에서 실행 중인 AI 서비스 정보, 3) 전역 모니터링 유닛을 통해 얻는 자원 사용량 정보 등을 이용하여 여유 자원을 가지면서 실행 요구사항에 부합하는 특정 컴퓨팅 서버의 GPU를 선정할 수 있다. 한편, 전역 최적화 유닛은 사용자의 요청이 있거나 사전에 설정된 특정 시간 혹은 특정 조건을 만족하는 시점에 클러스터 내 컴퓨팅 서버들의 GPU 자원의 사용률을 높이기 위해 실행 중에 있는 AI 서비스를 마이그레이 션할 수 있다. 상기 특정 조건의 일 예로는 AI 서비스 기반 분석 및 추론 요청이나 GPU 사용률이 특정 임계치보 다 낮은 경우, 실행해야 할 AI 서비스가 존재하는 경우(준비 큐에 서비스 존재 시) 등으로 사용자나 서비스 맞 춰 다양하게 정의될 수 있다. AI 서비스의 마이그레이션은 여러 GPU의 파편화된 GPU 자원을 수집하고 GPU의 공유 정책 타입을 변경을 통해 더 큰 규모의 GPU 가용 자원을 구성할 수 있어, AI 서비스 실행 정책 관리 유닛의 준비 큐에 존재하는 AI 서비스 중에서 실행 요구사항을 만족하는 AI 서비스를 추가로 실행할 수 있다. 이를 통해 클러스터 내의 GPU의 전체 활 용률을 향상시킬 수 있다. 전역 모니터링(Global Monitoring) 유닛은 지역 GPU-서빙 컨트롤러 블록을 통해 각각의 컴퓨팅 서버 내의 자원 사용량과 서비스의 상태에 대한 모니터링 정보를 수집하고 관리한다. AI 서비스 실행 정책 관리(AI Service Execution Policy Management) 유닛은 AI 서비스에 대한 실행 요구 사항 정보, AI 서비스의 현재 실행 정보를 관리한다. 뿐만 아니라 사용자의 요청에 의해 AI 서비스에 대한 실행 요구사항을 도출할 수 있으며 이는 AI 서비스 프로파일러를 통해 수행될 수 있다. 도출되는 요구사항에는 CPU cores 수, 메모리양, GPU의 메모리양 등의 실행에 필요한 최적 자원 정보를 포함할 수 있으며, AI 서비스 실행 을 위한 최적 배치 크기와 그에 따른 지연시간, 동시 실행 시 최적의 AI 모델 등의 정보를 더 포함할 수 있다. 도 5는 지역 GPU-서빙 컨트롤러를 상세히 나타낸 블록도이다. 도 5를 참조하면, 지역 GPU-서빙 컨트롤러는 크게 6개의 기능 유닛을 가진다. AI 서비스 제어(AI Service Control) 유닛은 전역 GPU-서빙 컨트롤러 블록으로부터 요청되는 AI 서비스 실 행을 제어한다. 먼저 AI 서비스 실행은 전역 GPU-서빙 컨트롤러로부터 전달 받은 AI service의 가상 인프라 이 미지, GPU 공유 정책 및 자원 정보를 포함한 CPU, memory 등의 자원 관련 정보를 바탕으로 가상 인프라 엔진 (Virtual Infra Engine, 250)을 통해 가상 인프라 인스턴스를 구성하고 실행한다. 실행중인 AI 서비스의 중지, 중지된 AI 서비스의 재시작 혹은 삭제 역시 가상 인프라 엔진을 통해 처리한다. 특히 AI 서비스 실행 시에 AI 서비스 제어 유닛은 GPU 공유 설정 유닛을 통해 요청된 GPU의 공유 정책과 현재 공유 정책을 조회하고 다른 경우 공유 정책을 변경 즉, 재설정한다. 그리고, AI 자원 할당(Resource Allocation) 유닛을 통해 AI 서비스 실행을 위한 GPU 이외의 자원들을 선정하고 할당한다. GPU 공유 설정(GPU Share Configuration) 유닛은 AI 서비스 제어 유닛 혹은 AI 서비스 마이그레이션 유닛 을 통해 요청이 오는 경우 해당 GPU의 공유 정책을 설정하고 관리한다. GPU 공유 정책에 대해서는 도 6을 참조 하여 자세히 설명한다. 자원 할당(Resource Allocation) 유닛은 GPU 이외의 AI 서비스를 위한 CPU, memory, storage 등의 자원을 선정하고 할당한다. 이때 자원/서비스 모니터링(Resource/Service Monitoring) 유닛을 통해 자원 활용률과 서비스 모니터링 정보를 참고할 수 있다. 자원/서비스 모니터링(Resource/Service Monitoring) 유닛은 자원별 활용률, 서비스의 평균 서비스 요청 수 및 지연 시간 등의 성능 요소를 실시간 모니터링한다. 자원할당 유닛의 요청에 따라 특정 시간 단위의평균값, 최대값, 최소값 등을 전달할 수 있으며, 전역 GPU-서빙 컨트롤러에게 자원과 서비스 모니터링 정 보를 실시간으로 전달한다. 가상 인프라 엔진(Virtual Infra Engine) 유닛은 가상 머신 혹은 컨테이너를 동적으로 구성하여 AI 서비스 를 실행하고 제어한다. AI 서비스 마이그레이션(AI Service Migration) 유닛은 전역 GPU-서빙 컨트롤러의 요청에 의해 이동시킬 서비스의 정보 및 데이터를 추출하고 변환 및 저장, 이동될 서비스의 실행을 위해 서비스의 정보 및 데이터를 로드하는 작업을 진행한다. AI 서비스 마이그레이션은 서비스의 중단 혹은 비중단(live) 상태에서 지원될 수 있 다. AI 서비스 마이그레이션 과정에서 GPU 공유 설정 유닛을 통해 특정 GPU의 공유 정책 변경이 필요할 수 있다. 도 6은 GPU 공유 정책을 나타내는 도면이다. 도 6을 참조하면, GPU 공유 정책은 각 GPU 마다 1종류의 공유 타입으로 설정될 수 있으며, 크게 내부 자원인 메 모리와 Compute Cores 전체를 공유하는 방법, GPU 내부 자원을 더 작게 부분으로 독립 분리하여 가상 GPU 인스 턴스를 구성하는 방법이 있다. 각 방법도 2가지의 세부 공유 방법이 다르며, 도 6의 왼쪽에서부터 GPU 공유 타 입 1, GPU 공유 타입 2, GPU 공유 타입 3 및 GPU 공유 타입 4라 명명한다. GPU 공유 타입 1은 다수의 컨테이너가 동일한 GPU를 대상으로 AI 서비스를 실행하는 구조로, GPU 내부의 스케줄러에 의해서 GPU 메모리와 Compute Cores를 사용하는 AI 서비스가 결정되는 구조이다. 즉, AI 서비스를 실행하는 컨테이너별로 GPU 자원을 점유하는 시간이 다르기 때문에, 컨테이너가 변경될 때마다 컨텍스트 스위치 (context switch)가 발생한다. GPU 공유 타입 2는 다수의 컨테이너가 동일한 GPU를 대상으로 AI 서비스를 실행되는 구조로 GPU 공유 타입 1과 개념은 같으나 다수의 컨테이너에서 수행되는 CUDA context 를 하나의 컨텍스트 통합(Context Integration) 후 GPU 스케줄러에게 전달된다는 점이 다르다. 따라서, GPU 스케줄러는 하나의 컨텍스트로 인지하여 컨텍스트 스위칭이 발생하지 않는다. 따라서 GPU 공유 타입 1과 비교하여 GPU 공유 타입 2는 AI 서비스의 대기 시간 및 처리량이 향상된다. GPU 공유 타입 3은 GPU의 메모리를 작은 조각으로 분할하여 다수 개의 가상 GPU 생성한다. 이때, 가상의 GPU는 가상 머신에 할당할 수 있으며, 가상 GPU는 기본적으로 물리적인 실제 GPU의 메모리 크기에 비례한 만큼 의 Compute Cores가 기본적으로 할당될 수 있다. 그러나 가상 머신에서 수행되는 AI 서비스가 더 많은 Cores를 요청하는 경우에도 가상머신 통합(VM Integration)에 의해 더 많은 Compute cores가 할당되어 실행될 수 있다. 여기서 가상머신 통합은 다수의 가상머신의 compute cores의 요청에 대하여 시간 분배 형태로 할당할 수 있다. 즉, 가상 GPU의 메모리는 독립적으로 분리하여 격리되나, compute cores는 다수의 가상 GPU가 시간 분배를 방식 으로 공유될 수 있다. GPU 공유 타입 4는 GPU 메모리와 Compute core에 대해 작은 조각으로 분할하고 격리된 다수개의 가상 GPU 를 생성한다. 하나의 가상 GPU에는 1개의 가상머신 할당되어 사용되거나, 다수의 컨테이너가 함께 할당되어 공 유하여 사용할 수 있다. GPU 공유 타입은 지역 GPU-서빙 컨트롤러의 GPU 공유 설정 유닛에 의해서 설정되고 변경될 수 있으며, 가상 인프라 엔진은 GPU 공유 타입에 맞춰 가상 머신 혹은 컨테이너를 생성 및 실행, 중지, 재시작, 삭제할 수 있다. 도 7은 AI 서비스 프로파일러를 상세히 나타낸 블록도이다. AI 서비스 프로파일러는 4가지 분석을 수행할 수 있다. 최적 GPU 사용 분석(Optimal GPU Usage Analysis) 유닛은 하나의 GPU 메모리와 Compute core들을 25%, 50%, 100% 등과 같이 분할 및 할당하여, AI 서비스 지연시간을 측정한다. 측정된 지연시간이 가장 짧을 때의 최소 GPU 자원 크기를 결정한다. 최적 배치 크기 분석(Optimal Batch Size Analysis) 유닛은 AI 서비스 추론 요청들을 모아 배치 처리를 통해 SLO (service level object)를 만족시키는 지연시간(latency)과 처리량(throughput)을 부합시키는 배치 크기를 분석한다. SLO가 없는 경우에는 최소 지연시간, 최대 처리량에 대한 배치 크기 정보를 찾는다. AI 모델 동시 실행 분석(AI Model Co-Execution Analysis) 유닛은 서로 다른 AI 모델을 가지는 두 AI 서 비스를 동시 실행했을 때 각 AI 서비스 처리량이 25% 이상 저하되거나, 즉 전체 처리량이 150%이상으로 높아지 는 서비스의 조합을 분석한다. 예를 들어, LSTM의 경우 VGG과 동시 실행할 경우, VGG는 18% 정도, LSTM 65% 정도 처리량이 떨어지면서 전체 10% 처리량이 향상된다. 반면, LSTM과 SR 모델의 동시 실행은 LSTM이 17%, SR은 0% 저하로 총 183%의 처리량을 보인다. 이는 GPU가 서로 다른 모델을 처리하는 과정에서 발생하는 간섭 현상의 정도를 알 수 있다. 따라서, 하나의 GPU를 공유하여 LSTM 모델과 다른 모델을 동시 실행해야 하는 경우, VGG 보 다는 SR 모델을 함께 실행하는 것이 더 좋은 실행 조합임을 알 수 있다. 마지막으로 GPU 공유 타입 분석 유닛에서는 AI 모델 동시 실행 분석 결과에서 최적의 실행 조합으로 결정 된 두 AI 서비스를 4가지 GPU 공유 타입을 바탕으로 실행하여 서비스 성능을 분석한다. 상기 4가지 분석은 이종 가상 인프라 실행(Heterogeneous Virtual Infra Execution) 유닛을 바탕으로 가 상머신, 컨테이너 형태의 AI 서비스 실행할 수 있다. 이종 가상 인프라 실행은 GPU 공유 타입 설정 및 GPU 자원 할당을 포함한 서비스 실행을 위한 환경을 동적으로 구성한다. AI 서비스 성능 수집(AI Service Performance Collection) 유닛은 이종 가상 인프라 실행을 통해 실행된 AI 서비스 성능 정보를 수집한다. 여기서 AI 서 비스는 따로 구축된 AI 서비스 분석 클러스터(AI Service Analysis Cluster) 내 컴퓨팅 서버에서 실행될 수 있 으며, 경우에 따라서는 지역 GPU-서빙 컨트롤러가 실행되는 컴퓨팅 서버 중의 일부를 사용할 수도 있다. 즉 클 러스터의 운영 방침에 따라 다양하게 구성될 수 있다. 도 8은 GPU 공유 기반 인공지능 서비스 실행의 일 예이다. 도 8을 참조하면, AI 서비스의 실행의 요청이 들어오면 GPU 자원 요구사항에 맞춰 GPU 공유 타입을 설정한다. 본 발명에서 지역 GPU-서빙 컨트롤러는 특정 GPU 기반 AI 서비스를 실행하기 전에 GPU 공유 타입의 설정한다. GPU 공유 타입의 설정에는 가상 GPU 생성을 포함한다. 특히, AI 서비스가 가상 머신(vInfra = VM)에서 실행되거 나, 컨테이너 기반 실행되더라도 독립 실행 보장이 요구되는 경우(Isolated =Y) 에는 GPU의 공유 타입은 3 혹은 4로 GPU 내부 자원을 분할한 후 더 작은 가상 GPU를 생성할 수 있다. 도 8에서 GPU 메모리 20G (Giga bytes)를 필요로 한 AI Service A를 실행하기 위하여 컴퓨팅 서버 #1에 장착된 GPU #1의 공유 타입은 4로 설정하여 20G 메모리를 가지는 두개의 가상 GPU, vGPU 1, vGPU 2를 생성하고 VM 기반의 AI Service A을 위해 vGPU 1을 할당 하였다. 마찬가지로, AI Service B가 컨테이너 기반으로 실행되나 독립 실행 보장이 요구되어 (Isolated=Y) 가 상 GPU를 할당해야 하므로, 컴퓨팅 서버 #1 내의 vGPU 2가 할당되었다. AI 서비스 C (GPU Memory = 5G) 와 D(GPU Memory =5G) 는 독립 실행 보장에 대한 요구사항이 없기에 컴퓨팅 서버 #2의 10G의 메모리를 가지는 GPU #1를 대상으로 컨테이너를 생성하여 AI 서비스를 실행한다. 즉 컴퓨팅 서버 #2의 GPU #1의 공유 타입은 1이다. AI 서비스 E는 독립 실행 보장이 요구되나 여유 가상 GPU가 없어 AI 서비스 실행 정책 관리 유닛의 준비 큐에 삽입되고, AI 서비스 F 의 실행 요구사항인 GPU 메모리 5G의 여유가 없이 준비 큐에 삽입되었다. 전역 GPU-서빙 컨트롤러 블록의 전역 최적화 유닛은 클러스터 내 GPU의 활용률을 높이기 위하여 전역 최적화 작 업을 수행한다. 전역 최적화는 AI service 정책 관리 유닛의 준비 큐에 AI 서비스가 존재하는데 여유 GPU 자원 이 없는 경우에 발생한다. 전역 최적화는 특정 GPU의 공유 타입을 변경하거나 상세 설정을 변경하고, AI 서비스 마이그레션을 포함한다. 특히, GPU 여유 자원은 없으나 클러스터 내에 GPU 활용률이 90%이상 혹은 50%이하를 나 타내는 GPU를 공유해서 실행(GPU 공유 타입 1, 2) 중인 AI 서비스가 마이그레이션의 대상이 될 수 있다. AI 서 비스 마이그레이션은 AI 모델 간 최적의 동시 실행 조합을 가지는 AI 서비스들이 동일 GPU를 공유해서 실행될 수 있도록 하는 것이 목적이다. 전역 최적화 많은 시간이 요구되는 관계로, 보통 서비스 요청이 적은 시간에 수 행될 수 있다. 도 9는 전역 최적화 이 후 GPU 공유 기반 인공지능 서비스 실행의 일 예이다. 도 9는 도 8의 상태에서 본 발명에 따른 전역 최적화 후 AI 서비스 실행 모습을 나타낸다. 먼저, 가상 GPU 를 대상으로 실행되어야 하는 Service E를 실행하기 위하여 컴퓨팅 서버 #1의 GPU #1의 GPU 공유 타입을 재설정한 다. 도 9에서는 AI 서비스 A, B, E 의 실행을 보장하기 위하여 20G, 10G, 5G, 5G를 가지는 vGPU 1, 2, 3, 4를 생성하였다. 그리고 vGPU 1 에는 AI 서비스 A, vGPU 2에는 AI 서비스 B, vGPU 3에는 AI 서비스 C를 할당하고 실행하였다. AI 서비스 F를 실행하기 위해서 5G 메모리를 가지는 GPU가 필요하다. 이때, GPU 공유 타입이 1 혹 은 2 에서 동시 실행되고 있는 AI 서비스들의 GPU 활용률이 너무 높거나 낮은 경우, 서비스 처리량의 50% 이하 로 떨어진 경우 등을 살핀다. LSTM과 VGG 모델은 동시 실행 시 간섭이 많아 동시 실행 시 LSTM의 처리량이 65% 로 저하된다. LSTM 모델은 SR 모델과 동시 실행의 최적 조합을 가지므로, VGG 모델의 AI 서비스 D를 컴퓨팅 서 버 #2에서 컴퓨팅 서버 #1로 마이그레이션한다. 따라서, AI 서비스 D는 컴퓨팅 서버 #1의 vGPU 4에서 실행되고, AI 서비스 F는 컴퓨팅 서버 #2에서 AI 서비스 C가 동시 실행된다. 본 발명에 따르면, 이종의 AI 추론 모델 타입의 AI 서비스의 동시 실행 시에 성능의 저하를 최소화하고 처리량 을 높일 수 있는 최적 조합을 AI 서비스 프로파일러를 통해 구축하고, 최적 조합의 AI 서비스들을 동일한 GPU를 공유하여 실행할 수 있도록 배치 및 실행할 수 있다. 이때, AI 서비스는 가상 머신 혹은 컨테이너와 같은 이종 의 가상 인프라 타입일 수 있다. 또한, 본 발명에 따르면, 컴퓨팅 서버 내에 장착된 GPU별로 4가지의 공유 타입 중 하나로 동적 설정하고 다수의 AI 서비스가 GPU를 공유하여 실행할 수 있다. 뿐만 아니라, GPU 활용 강화 시스템의 전역 최적화는 AI 서비스에 서 요구되는 GPU자원을 최적 크기로 재분할하고, GPU 공유타입을 재설정하여 더 많은 AI 서비스를 실행할 수 있 다. 또한, 본 발명에 따르면, 전역 최적화 작업 중의 하나인 AI 서비스 마이그레이션을 통해 파편화된 GPU 자원을 수집하여 더 큰 여유자원으로 동적 재구성할 수 있다. 이를 바탕으로 AI 서비스의 최적 조합으로 재배치 및 실 행 하여 GPU의 활용률 혹은 서비스의 처리량을 향상시킬 수 있다. 도 10은 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 장치를 나타낸 블록도이다. 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 장치는 연산 처리 장치의 공유 타입을 설 정하는 타입 설정부, 인공지능 서비스의 요구사항 및 상기 연산 처리 장치의 공유 타입 정보를 이용하여 가상 인프라 기반으로 인공지능 서비스를 실행하는 서비스 실행부 및 실행 중인 인공지능 서비스에 대한 최적화를 수행하는 최적화부를 포함한다. 이때, 상기 연산 처리 장치의 공유 타입은 연산 처리 장치의 자원을 복수의 가상 인프라가 공유하는 타입; 및 연산 처리 장치의 자원을 분할하여 가상 연산 처리 장치를 생성하는 타입을 포함한다. 이때, 상기 연산 처리 장치의 공유 타입은 연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하는 제1 타입; 연산 처리 장치 전체로서, 복수 가상 인프라의 AI 서비스를 지원하되, 상기 복수 가상 인프라의 AI 서비스는 단일 컨텍스트로 통합되는 제2 타입; 연산 처리 장치의 메모리를 분할하여 복수의 가상 연산 처리 장 치를 생성하는 제3 타입; 및 연산 처리 장치의 메모리 및 코어를 분할하여 복수의 가상 연산 처리 장치를 생성 하는 제4 타입을 포함할 수 있다. 이때, 상기 인공지능 서비스의 요구사항은 연산 처리 장치 자원 정보, 인공지능 서비스의 모델 정보, 가상 인프 라 타입 정보 및 독립 실행 필요 여부를 포함할 수 있다. 이때, 상기 가상 인프라의 타입은 가상 머신 또는 컨테이너를 포함할 수 있다. 이때, 상기 최적화부는 연산 처리 장치 분할, 배치 크기, 인공지능 모델 간 동시 실행 조합 및 연산 처리 장치의 공유 타입에 대한 최적화를 수행할 수 있다. 이때, 상기 서비스 실행부는 인공지능 서비스의 요구사항을 만족하는 연산 처리 장치 자원이 존재하지 않 으면, 상기 인공지능 서비스를 대기 큐에 삽입할 수 있다. 이때, 상기 최적화부는 상기 연산 처리 장치의 활용률 또는 상기 대기 큐에 대기 중인 인공지능 서비스가 존재하는지 여부에 기반하여 최적화 수행 여부를 결정할 수 있다. 이때, 상기 최적화부는 인공지능 서비스 마이그레이션을 수행하되, 필요한 경우 상기 연산 처리 장치의 공유 타입을 변경할 수 있다. 이때, 상기 최적화부는 상기 연산 처리 장치의 활용률이 제1 임계값을 초과하면, 상기 연산 장치에서 실 행중인 인공지능 서비스를 다른 연산 처리 장치에 재배치할 수 있다. 이때, 상기 최적화부는 상기 연산 처리 장치에서 동시에 실행중인 인공지능 서비스의 처리량이 제2 임계 값 미만이면 인공지능 서비스의 마이그레이션을 수행할 수 있다. 도 11은 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다. 실시예에 가상 인프라 기반 인공지능 서비스 실행 장치는 컴퓨터로 읽을 수 있는 기록매체와 같은 컴퓨터 시스 템에서 구현될 수 있다. 컴퓨터 시스템은 버스를 통하여 서로 통신하는 하나 이상의 프로세서, 메모리, 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치 및 스토리지를 포함할 수 있다. 또한, 컴퓨터 시스템은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있다. 프로세서 는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로그램 또는 프로세싱 인스트럭션들을 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 휘발성 매체, 비휘발성 매체, 분리형 매체, 비분리형 매체, 통신 매체, 또는 정보 전달 매체 중에서 적어도 하나 이상을 포함하는 저장 매체일 수 있 다. 예를 들어, 메모리는 ROM이나 RAM을 포함할 수 있다. 본 발명에서 설명하는 특정 실행들은 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어시스템들, 소프트웨어, 상기 시스템들의 다른 기능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재 들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “ 필수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요 소가 아닐 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐만 아 니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한다 고 할 것이다."}
{"patent_id": "10-2023-0138219", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 가상 인프라 기반 인공지능 서비스 실행의 일 예이다. 도 2는 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 방법을 나타낸 흐름도이다. 도 3은 본 발명의 일 실시예에 따른 GPU 활용 강화 장치를 나타낸 블록도이다. 도 4는 전역 GPU-서빙 컨트롤러를 상세히 나타낸 블록도이다. 도 5는 지역 GPU-서빙 컨트롤러를 상세히 나타낸 블록도이다. 도 6은 GPU 공유 정책을 나타내는 도면이다. 도 7은 AI 서비스 프로파일러를 상세히 나타낸 블록도이다. 도 8은 GPU 공유 기반 인공지능 서비스 실행의 일 예이다. 도 9는 전역 최적화 이 후 GPU 공유 기반 인공지능 서비스 실행의 일 예이다. 도 10은 본 발명의 일 실시예에 따른 가상 인프라 기반 인공지능 서비스 실행 장치를 나타낸 블록도이다. 도 11은 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다."}
