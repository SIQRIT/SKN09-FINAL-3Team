{"patent_id": "10-2023-0081991", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0000305", "출원번호": "10-2023-0081991", "발명의 명칭": "3차원 이미지 기반의 과수원 과실정보 측정장치 및 방법", "출원인": "전남대학교산학협력단", "발명자": "이경환"}}
{"patent_id": "10-2023-0081991", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "과수원의 과수들을 촬영하고 3D 이미지로 재구성하여 상기 과수원의 3D 이미지 모델을 생성하는 과수원 이미지생성부;인스턴스 분할(Instance Segmentation) 딥러닝 네트워크로 기구축된 개체 분할 모델을 통해 상기 과수원의 3D이미지 모델에서 과실 객체를 추출하는 과실 객체 추출부; 구형 피팅(sphere fitting)을 통해 상기 과실 객체의 모양을 보완하고 과실 개수, 크기 및 과수에서의 개별 과실 위치를 포함하는 과실정보를 측정하는 과실정보 측정부; 및상기 과실정보를 기초로 상기 과수원의 과실 수확량을 지도화하는 수확량 지도화부를 포함하는 3차원 이미지 기반의 과수원 과실정보 측정장치."}
{"patent_id": "10-2023-0081991", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 과수원 이미지 생성부는드론 또는 차량의 이동체에 장착되는 카메라 모듈을 포함하고 상기 이동체의 이동에 의해 상기 카메라 모듈이이동하면서 상기 과수원의 2D 이미지를 획득하고 포인트 클라우드로 표현되는 상기 3D 이미지 모델로 재구성하는 것을 특징으로 하는 3차원 이미지 기반의 과수원 과실정보 측정장치."}
{"patent_id": "10-2023-0081991", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 과수원 이미지 생성부는상기 카메라 모듈로서 이미지들이 서로 오버랩 영역을 가지도록 배치되는 다수 카메라로 구성되고,상기 과수원에 지상 기준점(Ground Control Point)들과 로컬 정합 마커들을 배치하고 상기 카메라 모듈을 통해획득한 2D 이미지들 내에 상기 지상 기준점 및 상기 로컬 정합 마커들의 GPS 위치 정보를 특정하고 사진측량(Photogrammetry)을 사용하여 상기 2D 이미지들을 3D로 재구성하여 상기 3D 이미지 모델을 생성하는 것을 특징으로 하는 3차원 이미지 기반의 과수원 과실정보 측정장치."}
{"patent_id": "10-2023-0081991", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 과실 객체 추출부는상기 개체 분할 모델로서, 일반화된 희소 합성곱 신경망, 가중 판별 손실 함수 및 3D 클러스터링을 포함하는 것을 특징으로 하는 3차원 이미지 기반의 과수원 과실정보 측정장치."}
{"patent_id": "10-2023-0081991", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 과실 객체 추출부는상기 과수원의 3D 이미지 모델의 포인트 클라우드를 복셀화하여 복셀로 변환하고 상기 복셀을 상기 희소 합성곱신경망의 입력으로 하여 색상 및 3D 좌표를 포함하는 특징을 추출하고 추출한 특징을 임베딩 공간에 매핑하는것을 특징으로 하는 3차원 이미지 기반의 과수원 과실정보 측정장치.공개특허 10-2025-0000305-3-청구항 6 제5항에 있어서, 상기 과실 객체 추출부는상기 가중 판별 손실 함수로서 거리 손실과 분산 손실을 포함하고 인스턴스 크기에 따라 가중치를 추가하여 상기 임베딩 공간의 3D 포인트 집합을 인스턴스 분할하는 것을 특징으로 하는 3차원 이미지 기반의 과수원 과실정보 측정장치."}
{"patent_id": "10-2023-0081991", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 과실 객체 추출부는상기 인스턴스 분할된 3D 포인트 집합을 3D HDBSCAN(Hierarchical Density-Based Spatial Clustering ofApplication with Noise) 클러스터링 알고리즘을 사용하여 개별 과실 클러스터를 추출하는 것을 특징으로 하는3차원 이미지 기반의 과수원 과실정보 측정장치."}
{"patent_id": "10-2023-0081991", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 과실정보 측정부는피팅된 구의 중심 위치와 직경으로 상기 과실의 위치와 크기를 각각 계산하고 피팅 포인트를 상기 과실의 원래3D 포인트 클라우드와 병합하고 컨벡스 헐(convex hull) 알고리즘을 사용하여 부피를 계산하는 것을 특징으로하는 3차원 이미지 기반의 과수원 과실정보 측정장치."}
{"patent_id": "10-2023-0081991", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 수확량 지도화부는상기 과실정보를 기초로 과수원 맵에 각 과수의 과실 분포를 투영하여 수확량을 지도화하고 과실 수확량 지도를기초로 각 과수의 수확량 분포를 분석하는 것을 특징으로 하는 3차원 이미지 기반의 과수원 과실정보 측정장치."}
{"patent_id": "10-2023-0081991", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "과수원의 과수들을 촬영하고 3D 이미지로 재구성하여 상기 과수원의 3D 이미지 모델을 생성하는 단계;인스턴스 분할(Instance Segmentation) 딥러닝 네트워크로 기구축된 개체 분할 모델을 통해 상기 과수원의 3D이미지 모델에서 과실 객체를 추출하는 단계; 구형 피팅(sphere fitting)을 통해 상기 과실 객체의 모양을 보완하고 과실 개수, 크기 및 과수에서의 개별 과실 위치를 포함하는 과실정보를 측정하는 단계; 및상기 과실정보를 기초로 상기 과수원의 과실 수확량을 지도화하는 단계를 포함하는 3차원 이미지 기반의 과수원과실정보 측정방법."}
{"patent_id": "10-2023-0081991", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 3차원 이미지 기반의 과수원 과실정보 측정장치 및 방법에 관한 것으로, 상기 장치는 과수원의 과수들 을 촬영하고 3D 이미지로 재구성하여 상기 과수원의 3D 이미지 모델을 생성하는 과수원 이미지 생성부; 인스턴스 분할(Instance Segmentation) 딥러닝 네트워크로 기구축된 개체 분할 모델을 통해 상기 과수원의 3D 이미지 모델 에서 과실 객체를 추출하는 과실 객체 추출부; 구형 피팅(sphere fitting)을 통해 상기 과실 객체의 모양을 보완 하고 과실 개수, 크기 및 과수에서의 개별 과실 위치를 포함하는 과실정보를 측정하는 과실정보 측정부; 및 상기 과실정보를 기초로 상기 과수원의 과실 수확량을 지도화하는 수확량 지도화부를 포함한다. 따라서, 본 발명은 과수원 3차원 이미지 모델 생성과 수확량 지도화를 제공하여 과수원의 수확량 모니터링 및 재배 관리를 지원할 수 있으며 디지털 농업의 과수원 데이터 수집 분야에 일조할 수 있다."}
{"patent_id": "10-2023-0081991", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 과수원 과실정보 측정 기술에 관한 것으로, 보다 상세하게는 과수원의 3차원 이미지 모델을 통해 과 실 개수, 크기, 위치를 측정하여 과수원의 과실정보를 정량화할 수 있는 3차원 이미지 기반의 과수원 과실정보 측정장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0081991", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "디지털농업은 기존의 정밀농업이나 스마트농업보다 생산, 유통, 소비 등 농업활동의 전과정에서 데이터를 적극 활용하며, 활용방식도 수집된 데이터를 인간이 분석, 모델화하여 작업을 자동화하는 것에서 수집된 빅데이터를 사람이 아닌 인공지능(AI)가 분석하여 의사결정을 내리는 방식으로 변화하고 있다. 다시말해, 사물인터넷 (IoT), 센서 등에서 생산되는 생산데이터, 유통데이터와 소비데이터가 농업데이터 플랫폼으로 수집되고, 플랫폼 상에서 AI 등이 데이터를 분석하여 도출된 최적의 의사결정이 다시 현장에 적용되는 것이다. 최근 디지털농업 기술은 노지재배 작물로 적용이 확장되고 있다. 나무에 있는 과실의 수량, 부피 및 공간적 분 포에 관한 정보는 과수 관리에 중요하다. 이 정보를 통해 수확 및 생산 예측을 할 수 있고 수확, 저장 및 마케 팅 작업 계획을 개선할 수 있다. 또한, 과실의 공간적 분포와 수확량은 비료, 관개, 전정 전략, 나무의 크기 및 구조와 같은 과수원 관리에 영향을 미치는 다른 요인 및 변수와 연관시킬 수 있다. 게다가, 수확 로봇이 각 과실의 공간 좌표를 가지고 작업에 집중하여 수확 효율성과 속도를 향상시킬 수 있으므로 과실의 지리적 분포에 대한 정보는 로봇 수확의 목표 지점이 될 수 있다. 하지만, 과실의 수량, 부피 및 공간적 분포 등 과실정보는 수확량에 영향을 미치는 중요한 매개변수를 구성하지만 수동으로 정량화하는 데 어려움이 있다. 따라서, 디지털 농업 기술의 하나로 과수원의 과실 수확량을 모니터링하고 더 나은 관리 시스템을 지원하기 위 해 과실정보를 효과적이고 효율적으로 정량화하는 기술이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2019-0084154호 (2019.07.16)"}
{"patent_id": "10-2023-0081991", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는 과수원의 3차원 이미지 모델을 통해 과실 개수, 크기, 위치를 측정하여 과수원의 과실정 보를 정량화할 수 있는 3차원 이미지 기반의 과수원 과실정보 측정장치 및 방법을 제공하고자 한다. 본 발명의 일 실시예는 드론 또는 차량 등의 이동체에 다수의 카메라를 장착하고 이동 경로를 따라 이동하면서 과수들의 이미지들을 획득하여 과수원의 3차원 이미지 모델을 생성하고 과수원의 지리정보시스템(Geographic Information System)을 기반으로 과수 위치 및 과수에서의 과실 위치를 GPS 좌표화 및 지도화할 수 있는 3차원 이미지 기반의 과수원 과실정보 측정장치 및 방법을 제공하고자 한다. 본 발명의 일 실시예는 과실정보의 측정을 기초로 과수원의 과실 수확량을 모니터링하고 효과적이고 효율적으로 과수원을 관리할 수 있도록 하는 3차원 이미지 기반의 과수원 과실정보 측정장치 및 방법을 제공하고자 한다."}
{"patent_id": "10-2023-0081991", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예들 중에서, 3차원 이미지 기반의 과수원 과실정보 측정장치는 과수원의 과수들을 촬영하고 3D 이미지로 재구성하여 상기 과수원의 3D 이미지 모델을 생성하는 과수원 이미지 생성부; 인스턴스 분할(Instance Segmentation) 딥러닝 네트워크로 기구축된 개체 분할 모델을 통해 상기 과수원의 3D 이미지 모델에서 과실 객 체를 추출하는 과실 객체 추출부; 구형 피팅(sphere fitting)을 통해 상기 과실 객체의 모양을 보완하고 과실 개수, 크기 및 과수에서의 개별 과실 위치를 포함하는 과실정보를 측정하는 과실정보 측정부; 및 상기 과실정보 를 기초로 상기 과수원의 과실 수확량을 지도화하는 수확량 지도화부를 포함한다. 상기 과수원 이미지 생성부는 드론 또는 차량의 이동체에 장착되는 카메라 모듈을 포함하고 상기 이동체의 이동 에 의해 상기 카메라 모듈이 이동하면서 상기 과수원의 2D 이미지를 획득하고 포인트 클라우드로 표현되는 상기 3D 이미지 모델로 재구성할 수 있다.상기 과수원 이미지 생성부는 상기 카메라 모듈로서 이미지들이 서로 오버랩 영역을 가지도록 배치되는 다수 카 메라로 구성되고, 상기 과수원에 지상 기준점(Ground Control Point)들과 로컬 정합 마커들을 배치하고 상기 카 메라 모듈을 통해 획득한 2D 이미지들 내에 상기 지상 기준점 및 상기 로컬 정합 마커들의 GPS 위치 정보를 특 정하고 사진측량(Photogrammetry)을 사용하여 상기 2D 이미지들을 3D로 재구성하여 상기 3D 이미지 모델을 생성 할 수 있다. 상기 과실 객체 추출부는 상기 개체 분할 모델로서, 일반화된 희소 합성곱 신경망, 가중 판별 손실 함수 및 3D 클러스터링을 포함할 수 있다. 상기 과실 객체 추출부는 상기 과수원의 3D 이미지 모델의 포인트 클라우드를 복셀화하여 복셀로 변환하고 상기 복셀을 상기 희소 합성곱 신경망의 입력으로 하여 색상 및 3D 좌표를 포함하는 특징을 추출하고 추출한 특징을 임베딩 공간에 매핑할 수 있다. 상기 과실 객체 추출부는 상기 가중 판별 손실 함수로서 거리 손실과 분산 손실을 포함하고 인스턴스 크기에 따 라 가중치를 추가하여 상기 임베딩 공간의 3D 포인트 집합을 인스턴스 분할할 수 있다. 상기 과실 객체 추출부는 상기 인스턴스 분할된 3D 포인트 집합을 3D HDBSCAN(Hierarchical Density-Based Spatial Clustering of Application with Noise) 클러스터링 알고리즘을 사용하여 개별 과실 클러스터를 추출 할 수 있다. 상기 과실정보 측정부는 피팅된 구의 중심 위치와 직경으로 상기 과실의 위치와 크기를 각각 계산하고 피팅 포 인트를 상기 과실의 원래 3D 포인트 클라우드와 병합하고 컨벡스 헐(convex hull) 알고리즘을 사용하여 부피를 계산할 수 있다. 상기 수확량 지도화부는 상기 과실정보를 기초로 과수원 맵에 각 과수의 과실 분포를 투영하여 수확량을 지도화 하고 과실 수확량 지도를 기초로 각 과수의 수확량 분포를 분석할 수 있다. 실시예들 중에서, 3차원 이미지 기반의 과수원 과실정보 측정방법은 과수원의 과수들을 촬영하고 3D 이미지로 재구성하여 상기 과수원의 3D 이미지 모델을 생성하는 단계; 인스턴스 분할(Instance Segmentation) 딥러닝 네 트워크로 기구축된 개체 분할 모델을 통해 상기 과수원의 3D 이미지 모델에서 과실 객체를 추출하는 단계; 구형 피팅(sphere fitting)을 통해 상기 과실 객체의 모양을 보완하고 과실 개수, 크기 및 과수에서의 개별 과실 위 치를 포함하는 과실정보를 측정하는 단계; 및 상기 과실정보를 기초로 상기 과수원의 과실 수확량을 지도화하는 단계를 포함한다."}
{"patent_id": "10-2023-0081991", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 기술은 다음의 효과를 가질 수 있다. 다만, 특정 실시예가 다음의 효과를 전부 포함하여야 한다거나 다 음의 효과만을 포함하여야 한다는 의미는 아니므로, 개시된 기술의 권리범위는 이에 의하여 제한되는 것으로 이 해되어서는 아니 될 것이다. 본 발명의 일 실시예에 따른 3차원 이미지 기반의 과수원 과실정보 측정장치 및 방법은 과수원의 3차원 이미지 모델을 통해 과실 개수, 크기, 위치를 측정하여 과수원의 과실정보를 정량화할 수 있다. 본 발명의 일 실시예에 따른 3차원 이미지 기반의 과수원 과실정보 측정장치 및 방법은 드론 또는 차량 등의 이 동체에 다수의 카메라를 장착하고 이동 경로를 따라 이동하면서 과수들의 이미지들을 획득하여 과수원의 3차원 이미지 모델을 생성하고 과수원의 지리정보시스템(Geographic Information System)을 기반으로 과수 위치 및 과 수에서의 과실 위치를 GPS 좌표화 및 지도화할 수 있다. 본 발명의 일 실시예에 따른 3차원 이미지 기반의 과수원 과실정보 측정장치 및 방법은 과실정보의 측정을 기초 로 과수원의 과수 수확량을 모니터링하고 효과적이고 효율적으로 과수원을 관리할 수 있다."}
{"patent_id": "10-2023-0081991", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에 관한 설명은 구조적 내지 기능적 설명을 위한 실시예에 불과하므로, 본 발명의 권리범위는 본문에 설 명된 실시예에 의하여 제한되는 것으로 해석되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가 지 형태를 가질 수 있으므로 본 발명의 권리범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로 이해되어야 한다. 또한, 본 발명에서 제시된 목적 또는 효과는 특정 실시예가 이를 전부 포함하여야 한다거나 그러한 효과만을 포함하여야 한다는 의미는 아니므로, 본 발명의 권리범위는 이에 의하여 제한되는 것으로 이해 되어서는 아니 될 것이다. 한편, 본 출원에서 서술되는 용어의 의미는 다음과 같이 이해되어야 할 것이다. \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로, 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\"있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결될 수 도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\"있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃 하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 것으로 이해되어야 하고, \"포함 하다\"또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 각 단계들에 있어 식별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단 계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순 서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수 행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 본 발명은 컴퓨터가 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현될 수 있고, 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함 한다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한 이 상적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다.도 1은 본 발명의 일 실시예에 따른 3차원 이미지 기반의 과수원 과실정보 측정 시스템을 설명하는 도면이다. 도 1을 참조하면, 과수원 과실정보 측정 시스템은 카메라 모듈, 과수원 과실정보 측정장치 및 데이터베이스를 포함할 수 있다. 카메라 모듈은 이동체에 장착되며 다수의 고정밀 RGB 카메라로 구성될 수 있다. 카메라 모듈은 계획 한 이동경로를 따라 이동하면서 과수들의 이미지들을 획득할 수 있다. 여기에서, 이동체는 무인 비행체인 드론 (drone) 또는 지상 이동체인 차량(vehicle) 등에 해당할 수 있다. 일 실시예에서, 카메라 모듈은 카메라 들이 과수원의 과수를 향하도록 이동체에 장착된다. 카메라 모듈은 드론에 장착되는 경우에 카메라들이 수직 하방을 향해 일정 각도로 경사지게 장착되고, 차량에 장착되는 경우에 카메라들이 차량 상에 등간격으로 수직되게 일렬 장착될 수 있다. 여기에서, 카메라 모듈은 드론 또는 차량 등의 이동체에 의해 과수 배열 방향을 따라 일정속도로 이동하면서 과수원의 모든 나무를 촬영하여 2차원 과수 이미지를 획득할 수 있다. 카 메라 모듈은 과수 이미지들을 과수원 과실정보 측정장치에게 제공할 수 있다. 카메라 모듈은 과수원 과실정보 측정장치와 네트워크를 통해 연결될 수 있으며, 도 1과 달리 과수원 과실정보 측정장치 에 포함되어 구현될 수 있고, 이 경우 카메라 모듈은 과수원 과실정보 측정장치를 구성하는 과 수원 이미지 생성부의 역할을 수행할 수 있다. 과수원 과실정보 측정장치는 카메라 모듈을 통해 획득한 과수들의 이미지들을 과수원의 3차원 이미지 모델로 재구성하여 과실 위치, 부피, 공간분포 등의 과실정보를 측정하고 수확량을 모니터링하는 컴퓨터 또는 프로그램에 해당하는 서버로 구현될 수 있다. 과수원 과실정보 측정장치는 카메라 모듈 및 카메라 모듈이 장착된 이동체와 유선 또는 무선 네트워크를 통해 연결될 수 있고 상호 간에 데이터를 주고받을 수 있다. 한편, 과수원 과실정보 측정장치는 본 발명에 따른 3차원 이미지 기반의 과수원 과실정보 측정을 수행하는 과정에서 다양한 외부 시스템(또는 서버)과 연동하여 동작할 수 있다. 과수원 과실정보 측정장치 는 카메라 모듈로부터 과수원에 있는 과수들의 이미지를 획득하고 과수원의 3차원 이미지 모델로 생 성하고 개체 분할을 통해 과실 객체를 인식 및 추출하여 과실정보를 측정할 수 있다. 과수원 과실정보 측정장 치는 측정된 과실정보를 기초로 수확량을 지도화하여 모니터링할 수 있다. 데이터베이스는 과수원 과실정보 측정장치의 동작 과정에서 필요한 다양한 정보들을 저장하는 저장장 치에 해당할 수 있다. 예를 들어, 데이터베이스는 카메라 모듈로부터 촬영된 다수의 과수 이미지들을 저장할 수 있고, 3차원으로 재구성된 과수원의 이미지 모델을 저장할 수 있고, 과실 객체 인식 및 추출을 위한 딥러닝 개체 분할 모델 구축을 위한 학습 알고리즘 및 데이터셋을 저장할 수 있으며, 반드시 이에 한정되지 않 고, 과수원 과실정보 측정장치가 본 발명에 따른 3차원 이미지 기반의 과수원 과실정보 측정을 시행하는 과정에서 다양한 형태로 수집 또는 가공된 정보들을 저장할 수 있다. 도 2는 도 1의 과수원 과실정보 측정장치의 시스템 구성을 설명하는 도면이다. 도 2를 참조하면, 과수원 과실정보 측정장치는 프로세서, 메모리, 사용자 입출력부 및 네 트워크 입출력부를 포함할 수 있다. 프로세서는 과수원 과실정보 측정장치가 동작하는 과정에서의 각 단계들을 처리하는 프로시저를 실행 할 수 있고, 그 과정 전반에서 읽혀지거나 작성되는 메모리를 관리할 수 있으며, 메모리에 있는 휘발 성 메모리와 비휘발성 메모리 간의 동기화 시간을 스케줄할 수 있다. 프로세서는 과수원 과실정보 측정장 치의 동작 전반을 제어할 수 있고, 메모리, 사용자 입출력부 및 네트워크 입출력부와 전기 적으로 연결되어 이들 간의 데이터 흐름을 제어할 수 있다. 프로세서는 과수원 과실정보 측정장치의 CPU(Central Processing Unit)로 구현될 수 있다. 메모리는 SSD(Solid State Drive) 또는 HDD(Hard Disk Drive)와 같은 비휘발성 메모리로 구현되어 과수원 과실정보 측정장치에 필요한 데이터 전반을 저장하는데 사용되는 보조기억장치를 포함할 수 있고, RAM(Random Access Memory)과 같은 휘발성 메모리로 구현된 주기억장치를 포함할 수 있다. 사용자 입출력부는 사용자 입력을 수신하기 위한 환경 및 사용자에게 특정 정보를 출력하기 위한 환경을 포함할 수 있다. 예를 들어, 사용자 입출력부는 터치 패드, 터치 스크린, 화상 키보드 또는 포인팅 장치 와 같은 어댑터를 포함하는 입력장치 및 모니터 또는 터치스크린과 같은 어댑터를 포함하는 출력장치를 포함할수 있다. 일 실시예에서, 사용자 입출력부는 원격 접속을 통해 접속되는 컴퓨팅 장치에 해당할 수 있고, 그러한 경우, 과수원 과실정보 측정장치는 독립적인 서버로서 수행될 수 있다. 네트워크 입출력부은 네트워크를 통해 외부 장치 또는 시스템과 연결하기 위한 환경을 포함하고, 예를 들 어, LAN(Local Area Network), MAN(Metropolitan Area Network), WAN(Wide Area Network) 및 VAN(Value Added Network) 등의 통신을 위한 어댑터를 포함할 수 있다. 도 3은 도 1의 과수원 과실정보 측정장치의 기능적 구성을 설명하는 도면이다. 도 3을 참조하면, 과수원 과실정보 측정장치는 과수원 이미지 생성부, 과실 객체 추출부, 과실 정보 측정부, 수확량 지도화부 및 제어부를 포함할 수 있다. 과수원 이미지 생성부는 과수원의 과수들을 촬영하여 과수원 이미지를 생성할 수 있다. 일 실시예에서, 과수원 이미지 생성부는 카메라 모듈로부터 과수들의 2D 이미지를 획득하고 2D 이미지를 3D로 재구성 하여 과수원의 3D 이미지 모델을 생성할 수 있다. 과수원 이미지 생성부는 2D로 촬영된 다수의 과수 이미 지들을 3D 포인트 클라우드로 표현되는 3D 이미지 모델로 재구성할 수 있다. 여기에서, 과수원 이미지 생성부 는 드론 또는 차량 등의 이동체에 장착된 카메라 모듈을 통해 과수원의 과수들을 촬영하여 과수들의 이미지들을 획득할 수 있다. 카메라 모듈은 과수에 관한 보다 높은 정확도를 가진 이미지를 획득하기 위 하여 다수 고정밀 RGB 카메라가 주로 활용될 수 있으나, 반드시 이에 한정되지 않음은 물론이다. 카메라 모듈 은 다중 카메라로 구성되며 일정 간격으로 드론 또는 차량 등의 이동체에 장착되고 이동체의 이동 과정 동 안 복수의 정지 지점들 각각에서 과수의 배열 방향을 향해 촬영하여 다수의 과수 부분 이미지들을 생성할 수 있 다. 이때, 카메라 모듈은 인접한 정지 지점들 간에 있는 해당 과수 부분 이미지들이 서로 오버랩 영역을 가지도록 배치될 수 있다. 일 실시예에서, 카메라 모듈은 이동체로 드론에 장착될 수 있다. 이 경우, 카메라 모듈은 카메라들 을 수직 아래를 기준으로 특정 기울기 각도로 대칭되게 설치하여 인접한 이미지 간의 충분한 중첩을 보장하여 3D 재구성을 최적화할 수 있다. 일 실시예에서, 카메라 모듈은 이동체로 차량에 장착될 수 있다. 이 경 우, 카메라 모듈은 카메라들을 수직선상에 일정간격으로 설치하여 이미지뷰가 수직 및 동작방향에서 각각 겹쳐지도록 하여 3D 재구성을 최적화할 수 있다. 과수원 이미지 생성부는 GCP(Ground Control Point)들과 로컬 정합 마커들을 과수원에 배치하고 카메라 모 듈로 과수원 과수들의 이미지들을 획득할 수 있다. 여기에서, GCP는 지상기준점으로, 정해진 좌표를 가진 지표면 위의 인공 또는 자연 점을 의미한다. 과수원 이미지 생성부는 획득한 다수 이미지들과 이미지 내 에 GCP들의 위치 정보 및 로컬 정합 마커들의 위치를 특정하고 사진측량(Photogrammetry) 방법을 기반으로 3D 포인트 클라우드 이미지로 재구성하여 3차원 이미지 모델을 복원할 수 있다. 과수원 이미지 생성부는 드 론 촬영의 경우 GCP를 기준점으로 삼아 이미지의 위치값을 실제 위치값과 일치시킬 수 있으며, 차량 촬영의 경 우 로컬 정합 마커의 위치를 기준점으로 삼아 이미지의 위치값을 실제 위치값과 일치시킬 수 있다. 사진측량은 최소한 두 곳의 서로 다른 위치에서 사진을 찍어서 각 카메라에서 대상 지점까지 수학적으로 교차되어 관심 지 점의 3차원 좌표를 생성하는 방식이다. 일 실시예에서, 과수원 이미지 생성부는 다시점 SFM(Multi-View Structure From Motion) 알고리즘을 사용 하여 2D로 촬영한 과수 이미지를 3D로 재구성할 수 있다. SFM은 2차원으로 촬영한 이미지의 모션정보를 이용해 촬영된 이미지의 카메라 위치와 방향을 역추적한 후 이미지들과 카메라들의 관계를 구조화하는 알고리즘이다. SFM을 이용해, 각 촬영 이미지의 고유한 특징점(Feature Point)을 얻고 각 촬영 장면마다 특징점들과 관계를 서 로 매칭하고 계산해 카메라의 위치를 얻을 수 있다. 과수원 이미지 생성부는 GCP 및 마커 각각을 이미지 에 마스킹하고 원래 좌표를 대상 좌표로 변환하여 3D 포인트 클라우드 이미지를 생성할 수 있다. 과실 객체 추출부는 과수원 이미지에 대해 과실 객체를 추출할 수 있다. 일 실시예에서, 과실 객체 추출 부는 기구축된 딥러닝 개체 분할 모델을 기반으로 과수원 3D 이미지 모델에서 과실들을 객체 인식 및 추출 하고 추출된 과실 객체의 포인트 클라우드를 클러스터링(clustering)을 통해 개체별 과실 영역을 구분할 수 있 다. 여기에서, 딥러닝 개체 분할 모델은 일반화된 희소 합성곱 신경망, 가중 판별 손실 함수 및 다양한 밀도 기반 3D 클러스터링 방법을 포함할 수 있다. 일 실시예에서, 과실 객체 추출부는 인스턴스 분할(Instance segmentation)로 과수원 이미지 내에 있는 과 실(열매) 객체들을 개체 인식 및 추출할 수 있다. 먼저, 과실 객체 추출부는 일반화된 희소 합성곱 신경망을 통해 과수원 이미지 내의 개별 과수들의 특징을 추출할 수 있다. 과실 개체 추출부는 과수원 이미지 에서 개별 과수를 추출하고 추출한 과수의 3D 포인트 클라우드를 복셀(vocel)로 변환한 후 일반화된 희소 합성 곱 신경망의 입력으로 하여 과수의 3D 복셀을 고차원 특징 임베딩 공간에 매핑할 수 있다. 여기에서, 일반화된 희소 합성곱 신경망은 U-Net 기반 네트워크 구조를 사용한다. 다음으로, 과실 객체 추출부는 가중 판별 손실 함수를 통해 임베딩 공간의 3D 포인트 집합을 인스턴스 분 할할 수 있다. 여기에서, 판별 손실은 분산 및 거리 손실로 구성된다. 분산 손실은 동일한 인스턴스의 픽셀 임베딩을 해당 인스턴스 임베딩의 평균으로 끌어당기는 클래스 내 장력이고, 거리 손실은 서로 다른 인스턴스의 임베딩 중심을 서로 멀리 밀어내는 인스턴스 간 추력이다. 과실 객체 추출부는 인스턴스의 크기에 따라 손실 함수에 가중치를 추가할 수 있다. 과실 객체 추출부는 임베딩 공간에서 가중 판별 손실 함수를 적용 한 후 클러스터링 알고리즘을 사용하여 개별 클러스터를 분할할 수 있다. 여기에서, 과실 객체 추출부는 다양한 밀도 클러스터를 효율적이고 견고하게 처리하게 위해 3D HDBSCAN(Hierarchical Density-Based Spatial Clustering of Applications with Noise) 클러스터링 알고리즘을 사용할 수 있다. 과실 객체 추출부는 클러스터링을 통해 개별 과실 클러스터, 배경 클러스터 및 노이즈 클러스터의 세가지 클러스터 유형을 출력할 수 있다. 노이즈 클러스터는 희소하며 밀도 필터를 사용하여 제거할 수 있다. 배경 클러스터는 과수와 지면의 3D 포인트 클라우드를 포함하므로 개별 과실 클러스터 간의 크기에 상당한 차이가 있 다. 크기 필터를 사용하여 개별 과실 클러스터를 추출할 수 있으며 각 과실 클러스터의 포인트는 원래 3D 포인 트 클라우드의 3D 포인트에 매핑될 수 있다. 과실정보 측정부는 개체 분할 과정에서 가려진 시야로 3D 모델 정보가 없는 과실의 부분을 구형 피팅 (sphere fitting) 방법을 이용하여 보완하고 과실 개수, 과수에서의 개별 과실의 위치, 크기 등의 과실 특성을 나타내는 과실정보를 측정할 수 있다. 사과 등의 과실 특성은 기하학적 정보와 공간 분포로 구성된다. 과실의 3D 포인트 클라우드는 과실의 물리적 크기 및 모양 정보를 제공한다. 그러나 과수의 잎과 가지로 인한 폐색으 로 인해 3D 과실 모델이 불완전할 수 있다. 이에, 과실정보 측정부는 피팅된 구의 직경을 사용하여 과실 의 크기를 보완하고 과실의 부피를 계산하여 과실정보를 측정할 수 있다. 과실정보 측정부는 피팅된 구의 중심 위치와 직경 각각을 사용하여 과실의 위치와 크기를 측정할 수 있다. 일 실시예에서, 과실정보 측정부 는 구의 부피 공식을 사용하여 과실의 부피를 계산할 경우 과실의 모양이 정확히 구형으로 간주될 수 없어 과실의 크기 측정에 정확도가 떨어질 수 있다. 이에, 과실정보 측정부는 정확한 부피 계산을 위해 과실의 원래 3D 포인트 클라우드 근처에 있는 피팅된 구의 포인트를 제거한 후 피팅 포인트를 과실의 원래 3D 포인트 클라우드와 병합하고 컨벡스 헐(convex hull) 알고리즘을 사용하여 부피를 계산한다. 컨벡스 헐 알고리즘은 2 차원 평면상에 여러 개의 점이 있을 때 그 점 중에서 일부를 이용하여 볼록 다각형을 만들되 볼록 다각형 내부 에 모든 점을 포함시키는 것을 의미한다. 수확량 지도화부는 과실정보를 기초로 과수원 맵에 각 과수의 과실 분포를 투영하여 수확량을 지도화할 수 있다. 일 실시예에서, 수확량 지도화부는 과수원의 과실 수확량 지도를 통해 각 과수의 수확량 분산을 분 석할 수 있다. 과수원의 과실 수확량 지도는 과수원의 조성이나 식재계획에 중요한 참고자료가 될 수 있다. 제어부는 과수원 과실정보 측정장치의 전체적인 동작을 제어하고, 과수원 이미지 생성부, 과실 객체 추출부, 과실정보 측정부 및 수확량 지도화부 간의 제어 흐름 또는 데이터 흐름을 관리할 수 있다. 도 4는 본 발명에 따른 3차원 이미지 기반의 과수원 과실정보 측정 과정의 일 실시예를 설명하는 순서도이다. 도 4를 참조하면, 과수원 과실정보 측정장치는 과수원 이미지 생성부를 통해 과수원의 과수들을 촬영 하여 2D 이미지를 획득하고 2D 이미지를 기초로 과수원의 3D 이미지 모델을 생성할 수 있다(단계 S410). 과수 원 이미지 생성부는 과수원에 GCP(Ground Control Point)들과 로컬 정합 마커들을 배치하고, 다수 고정밀 RGB 카메라를 장착시킨 드론 또는 지상 이동체를 계획한 이동경로를 따라 이동하면서 과수원 과수들을 촬영한 2D 이미지를 획득할 수 있다. 과수들의 2D 이미지에는 GCP들과 정합 마커들이 포함될 수 있다. 과수원 이미지 생성부는 2D 이미지 내에 GCP의 GPC 위치정보와 정합 마커들의 위치정보를 특정하고 사진측량 (Photogrammetry) 방식을 통해 3D로 재구성하여 포인트 클라우드 기반 3D 이미지 모델을 생성할 수 있다. 과수원 과실정보 측정장치는 과실 객체 추출부를 통해 과수원의 3D 이미지 모델에서 딥러닝 개체 분 할을 이용하여 과실 객체를 인식 및 추출할 수 있다(단계 S430). 과실 객체 추출부는 과실의 3차원 이미지 모델의 표현형에 대해 일반화된 희소 합성곱 신경망, 가중 판별 손실 함수 및 다양한 밀도 기반 3D 클러스터 링 방법을 포함하는 딥러닝 기반의 인스턴스 분할(Instance Segmentation)을 학습시켜 기구축한 개체 분할 모델 을 기반으로 과수원 3D 이미지 모델에서 과실들을 개체 인식 및 추출하고 추출된 포인트 클라우드를 크럴스터링 을 통해 개별 과실 단위로 구분할 수 있다. 과수원 과실정보 측정장치는 과실정보 측정부를 통해 과실 개수, 크기 및 과수에서의 개별 과실 위치 를 포함하는 과실정보를 측정할 수 있다(단계 S450). 과실정보 측정부는 가려진 시야로 3D 모델 정보가 없는 과실의 부분을 구형 피팅(sphere fitting)하여 보완한 후 각 과실을 계수하여 수량을 구하고 구의 중심 위 치를 과실 위치로 구하며 컨벡스 헐(convex hull) 알고리즘을 사용하여 각 과실의 부피를 계산하여 크기를 구할 수 있다. 과수원 과실정보 측정장치는 수확량 지도화부를 통해 과실정보를 기초로 과수원의 과실 수확량을 지 도화할 수 있다(단계 S470). 수확량 지도화부는 과수에서의 개별 과실의 부피를 과수원 맵에 투영하여 수 확량을 지도화하여 각 과수의 수확량 분산을 분석하여 과수원의 조성 및 식재계획을 세울 수 있다. 도 5 및 도 6은 과수원 3D 이미지 모델 생성 구성을 설명하는 도면으로, 도 5은 이미지 획득을 위한 구성을 나 타내고, 도 6은 3D 재구성 후 과수원의 3D 모델을 나타낸다. 도 5의 (a)를 참조하면, 카메라 모듈은 드론 등의 이동체에 장착될 수 있다. 카메라 모듈은 3대의 카메라(C1,C2,C3)가 45° 간격으로 배치되어 드론에 장착되었으며, 카메라 구성 및 레이아웃은 반드시 이에 한 정되지 않고 다양하게 구성될 수 있다. 카메라 모듈은 과수의 이미지를 캡쳐하도록 드론에 제2 카메라 (C2)를 수직 아래를 향하도록 중앙에 배치하고 제1 및 제3 카메라들(C1,C3)을 제2 카메라(C2)를 기준으로 양측 에 수직 아래 방향에 대해 45° 기울기 각도로 대칭되게 배치한다. 카메라 모듈은 중앙에 배치된 제2 카 메라(C2)의 GSD(Ground Sampled Distance)가 약 2㎜가 되도록 드론의 비행 높이를 10m로 설정하여 고해상도 3D 모델을 재구성할 수 있다. 도 5의 (b)를 참조하면, 3D 포인트 클라우드 이미지를 재구성하기 위해 지상 기준점(GCP) 및 체크포인트(CP)를 과수원에 배치할 수 있다. 여기에서, 지상 기준점(GCP)는 고르게 분포되며, 체크포인트(CP)는 각 열의 중앙과 가장자리에 있는 필드 주변에 분포될 수 있다. 도 5의 (c)를 참조하면, 카메라 모듈은 드론 비행 경로를 따라 이동하면서 과수들의 이미지를 획득할 수 있다. 여기에서, 드론 비행 경로는 동서 및 남북의 두가지 유형으로 계획될 수 있다. 예를 들어, 카메라 모듈 이 장착된 드론은 동서 방향으로 24개 라인, 남북 방향으로 20개 라인을 스캔할 경우 각 비행 라인에 대해 각각 75개 및 120개의 이미지를 획득할 수 있다. 카메라 모듈은 제1 내지 제3 카메라들(C1,C2,C3)에서 동 시에 촬영하여 인접한 이미지 간에 충분히 오버랩되도록 하여 3D 재구성을 최적화할 수 있다. 도 6을 참조하면, 과수원 과실정보 측정장치는 다시점 SFM(Multi-View Structure from Motion) 알고리즘 을 사용하여 2D로 촬영한 과수들의 이미지들을 3D로 재구성할 수 있다. SFM은 2차원으로 촬영한 이미지의 모션 정보를 이용해 촬영된 이미지의 카메라 위치와 방향을 역추적한 후 이미지들과 카메라들의 관계를 구조화하는 알고리즘이다. SFM을 이용해, 각 촬영 이미지의 고유한 특징점(Feature Point)을 얻고 각 촬영 장면마다 특징 점들과의 관계를 서로 매칭하고 계산해 카메라의 위치를 얻을 수 있다. 과수원 과실정보 측정장치는 이미 지 정렬을 위해 각 이미지에 대한 특징점과 매칭점의 상한을 각각 설정하고 GCP를 이미지에 표시하여 원래 좌표 를 대상 좌표로 변환하여 도 6의 (a)와 같이 과수원의 3D 포인트 클라우드 이미지를 획득할 수 있다. 도 6의 (b) 내지 (d)는 도 6의 (a)에 대해 다축(Multi-axis), 8개 과수열의 수직축 및 4개 과수열의 수직벽 필드의 3D 과수 이미지이다. 도 7은 본 발명에 따른 3차원 이미지 기반의 과수원 과실정보 측정 처리 구조를 설명하는 도면이고, 도 8은 도 7에 있는 3D 인스턴스 분할 모델을 설명하는 도면이고, 도 9는 도 7에 있는 과실 특성 추출 알고리즘을 설명하 는 도면이고, 도 10은 구형 피팅(Sphere fitting) 방법을 적용한 과실 부피 보완을 설명하는 도면이다. 도 7을 참조하면, 과수원 과실정보 측정장치는 드론 또는 차량 등의 이동체에 장착된 다중 카메라를 이용 하여 과수원의 과수 이미지를 획득할 수 있다. 과수 이미지는 다시점의 2D 이미지들을 포함할 수 있다. 과수 원 과실정보 측정장치는 획득된 과수의 2D 이미지들을 기반으로 각각의 3D 이미지 모델을 생성할 수 있다.이를 위해, 과수원 과실정보 측정장치는 사진측량(photogrammetry) 방식을 통해 2D 이미지를 3D로 재구성 할 수 있다. 3D 이미지 모델은 포인트 클라우드(point cloud) 형식으로 표현될 수 있다. 여기에서, 3D 이미지 모델은 도 6의 (b) 내지 (d)에 나타낸 바와 같은 각 필드의 이미지들을 포함할 수 있다. 과수원 과실정보 측정 장치는 3D 인스턴스 분할 딥러닝 알고리즘을 이용하여 과실 객체를 추출하고 과실 개수, 부피 및 공간 분 포 등의 과실 특성을 측정할 수 있다. 본 발명에 따른 과수원 과실정보 측정장치는 도 8와 같이, 일반화된 희소 합성곱 신경망에 의한 특징 추출 하는 과정, 원본 3D 포인트 클라우드를 고차원 공간에 임베딩하는 과정, 임베딩 공간에서 가중 판별 손실 함수 적용 과정 및 3D 클러스터링 과정을 통해 과실 객체를 인식 및 추출할 수 있다. 여기에서, 희소 합성곱 레이어는 Identity SparseConv ResNet 블록, SparseConv ResNet 블록, SparseConv 다운 샘플링, SparseConv Transpose의 네가지 유형의 구조 블록으로 구성될 수 있다. Identity SparseConv ResNet 블록과 SparseConv ResNet 블록은 입력 텐서에서 커널 크기가 3×3×3인 희소 합성곱 연산을 두번 수행하고, Identity SparseConv ResNet 블록은 특징 채널의 수를 저장하는 ReLU 함수의 활성화 전에 텐서 추가를 통해 결 과 텐서와 원래 입력 텐서를 병합한다. SparseConv ResNet 블록은 1×1×1의 커널 크기로 희소 합성곱 연산을 병합하여 특징 채널 수를 두배로 확장한다. SparseConv 다운샘플링은 커널 크기가 2×2×2 이고, 보폭이 2×2 ×2인 희소 합성곱 레이어를 적용하여 특징 맵을 절반으로 줄인다. 이러한 아키텍처에서 U-Net 구조의 후반부 는 동일한 하이퍼파라미터를 사용하는 SparseConv Transpose에 의해 반전된다. 희소 신경망은 인코더와 디코더 를 포함하는 종단간(end-to-end) 구조이다. 인코더는 일반적으로 특징 맵을 두배로 늘리는 동안 입력 텐서를 가져와 샘플링한다. 신경망 구조에 대한 입력은 과수의 원래 3D 포인트 클라우드에서 변환된 복셀이다. 즉, 과수원 과실정보 측정장치는 과수원의 3D 이미지 모델에 대해 개별 과수만을 분할하고 분할된 개별 과수의 3D 포인트 클라우드를 복셀화(voxelization)하여 3D 복셀 모델로 변환할 수 있다. 과수원 과실정보 측정장치 는 과수의 원래 3D 포인트 클라우드에서 변환된 복셀을 일반화된 희소 합성곱 신경망에 입력하여 특징을 추출할 수 있다. 각 복셀에는 색상(r,g,b) 및 3D 좌표(x,y,z)와 같은 의 특징이 있다. 먼저, 네트워크는 32 채널 커널과 3×3×3의 커널 크기를 가진 희소 합성곱 레이어로 입력 복셀을 처리한 다음, SparseConv 다운샘플 링하여 특징 맵을 절반으로 줄인다. 특징 맵은 다운샘플링되고 채널 수의 두배 증가는 Identity SparseConv ResNet 블록의 수가 증가하면서 인코더 처리에서 4번 반복되며, 인코더의 마지막 SparseConv ResNet 블록은 특 징 맵의 수를 128에서 256으로 두배 증가시킨다. 디코더는 일반적으로 특징 맵의 채널 수를 줄이면서 텐서를 가져와 업샘플링한다. 디코더의 첫번째 레이어는 커널 크기가 2×2×2이고 보폭이 2×2×2인 첫번째 SparseConv Transpose 레이어로, 텐서의 크기를 두배로 늘리고 특징 맵의 채널 수를 256으로 유지한다. 이 결 과 텐서는 인코더의 최종 SparseConv 다운샘플링 레이어의 출력 텐서와 병합되어 특징 맵의 수에 대해 합계 384(=256+128)를 생성한다. 그런 다음, 디코더의 첫번째 SparseConv ResNet 블록은 특징 맵의 수를 256개로 줄인 다음, 특징 맵에서 Identity SparseConv ResNet 블록이 수행되고 SparseConv Transpose 레이어가 특징 맵 의 수를 128개로 줄인다. 병합, SparseConv ResNet 블록, Identity SparseConv ResNet 블록 및 SparseConv Transpose의 이러한 시퀀스는 디코더 부분에서 4번 반복되며, 마지막 SparseConv Transpose 레이어는 특징 맵의 채널 수를 절반으로 줄일 수 있도록 수행되지 않는다. 따라서, 과수원 과실정보 측정장치는 일반화된 희 소 합성곱 신경망 아키텍처를 기반으로 과수의 3D 복셀을 고차원 특징 임베딩 공간에 매핑할 수 있다. 특징 임 베딩 공간의 각 지점은 과수의 원래 복셀에 해당하며 레이블이 지정될 수 있다. 임베딩 공간의 차원은 가중 판 별 손실 함수에 의해 임의적이며 클래스 수에 따라 출력 차원이 결정되는 시맨틱 분할과 다르다. 가중 판별 손실 함수 적용 과정은 손실 함수를 통해 이미지의 모든 픽셀을 특징 공간의 n차원 벡터로 변환 할 수 있으며 동일한 인스턴스에 속하는 픽셀 벡터는 밀접하게 인접하고 다양한 인스턴스에 속하는 픽셀 벡터는 분리될 수 있다. 판별 손실은 분산 및 거리 손실로 구성된다. 각 인스턴스 의 레이블이 주어지면, 임 베딩 공간의 3D 포인트 집합은 으로 명명된 각 인스턴스로 나뉜다. 여기서, N은 인스턴스의 수 이고 각 인스턴스 에서 임베딩된 포인트 로, 는 각 인스턴스 에 포함된 포인트 수이다. 손실 함수는 분산 및 거리 손실의 병합으로, 임베딩 공간에서 수행되어 임베딩 포인트를 연산하며 하 기 수학식 1로 표현될 수 있다. [수학식 1] 거리 손실 및 분산 손실 의 계수는 각각 및 이며, 거리 손실 및 분산 손실은 하기 수학식 2 및 3 으로 표현될 수 있다. [수학식 2]"}
{"patent_id": "10-2023-0081991", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[수학식 3]"}
{"patent_id": "10-2023-0081991", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "및 는 각각 인스턴스 및 에 포함된 포인트의 평균값이다. 거리 손실은 인스턴스 의 평균값 을 인스턴스 의 에서 멀리 밀어내며, 분산 손실은 동일한 인스턴스 에 속하는 임베딩된 포인트 를 가져온다. 거리 손실 및 분산 손실의 수렴 정도를 제어하기 위해 두개의 거리 임계값 및 를 각각 설정한다. 여기에서, 는 ReLU 함수이다. 상기 수학식 2에서 함수는 인스턴스 중심 사이의 거리가 주어진 거리 임계값 미만일 때 미는 힘을 무효화하 며, 인스턴스 중심 사이의 거리가 이상인 경우 임베딩된 포인트에 미는 힘을 적용한다. 상기 수학식 2의 ReLU 함수와 유사하게, 상기 수학식 3에서 모든 인스턴스의 분산 손실은 인스턴스 의 평균값 와의 거리가 주어진 거리 임계값 보다 큰 임베딩된 포인트 에 대해서만 수행된다. 본 발명의 손실 함수는 인스턴스 크기에 따라 가중치 를 추가할 수 있다. 특히, 나무와 땅을 포함하여 과실 과 배경 사이의 3D 포인트의 수가 크게 다르기 때문에, 을 제어하여 크기가 다른 인스턴스의 서로 다른 임베딩된 포인트에 대한 끌어당기는 장력을 다르게 할 수 있다. 2D 이미지와 비교하여 3D 포인트 클라우드는 실제 세계에서 스케일과 실제 크기가 하나 더 있다. 따라서, 분산 손실이 임베딩된 포인트마다 균등하게 작용 하도록 를 1로 설정할 수 있다. 과수원 과실정보 측정장치는 임베딩 공간에서 가중 판별 손실 함수를 적용한 후 클러스터링 알고리즘을 사 용하여 개별 클러스터를 분할할 수 있다. 클러스터링 과정은 다양한 밀도 클러스터를 효율적이고 견고하 게 처리하게 위해 3D HDBSCAN 클러스터링 알고리즘을 사용할 수 있다. 3D HDBSCAN 클러스터링 알고리즘의 여러 매개변수는 동일한 인스턴스의 임베딩된 포인트를 동일한 클러스터에 할당하도록 적용될 수 있다. 결과 클러스 터링에 영향을 미치는 기본 매개변수는 각 클러스터에 임베딩된 최소 포인트 수로, 가장 작은 크기의 그룹화를 결정한다. 이 매개변수가 증가하면 클러스터의 수가 감소한다. 결과 클러스터링에 영향을 미치는 또 다른 매 개변수는 거리가 임계값 미만인 클러스터를 병합하기 위한 거리 임계값이다. 클러스터링 알고리즘의 출력에는 개별 과실 클러스터, 배경 클러스터 및 노이즈 클러스터의 세가지 유형의 클러스터가 있다. 노이즈 클러스터는 희소하며 밀도 필터를 사용하여 제거할 수 있다. 배경 클러스터는 과수와 땅의 3D 포인트 클라우드를 포함하므 로 개별 과실 클러스터 간의 크기에 상당한 차이가 있다. 개별 과실 클러스터는 크기 필터를 사용하여 추출할 수 있으며 각 과실 클러스터의 포인트는 원래 3D 포인트 클라우드의 3D 포인트에 매핑된다. 과수원 과실정보 측정장치는 도 9에 제시된 알고리즘을 통해 과실 개수, 부피, 위치 등의 과실 특성을 나 타내는 과실정보를 측정할 수 있다. 과실의 3D 포인트 클라우드는 3D 물리적 크기 및 모양 정보를 제공한다. 그러나 잎과 가지로 인한 폐색으로 인해 3D 과실 모델이 불완전할 수 있다. 과수원 과실정보 측정장치는 도 9의 알고리즘을 따라 과실의 불완전한 3D 포인트 클라우드를 보완하여 과실 부피 계산의 오류를 최소화할 수있다. 과수원 과실정보 측정장치는 도 10과 같이, 과실의 부피를 계산할 수 있다. 여기서는 사과를 예로 하였다. 신경망의 훈련된 모델(도 8)과 알고리즘의 후처리(도 9의 step 2, 3, 4, 5)로 개별 사과를 분할한 후, 을 개별 사과의 3D 포인트 클라우드 집합으로 설정한다. 3D 포인트 클라우드 는 (x,y,z)의 좌표정보를 갖는다. 구형 피팅 알고리즘은 도 10의 (a)와 같이 개별 사과의 3D 포인트 클라우드에 적용될 수 있다. 이는 하기 수학식 4로 정의될 수 있다. [수학식 4]"}
{"patent_id": "10-2023-0081991", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 은 피팅된 구의 중심 위치 을 나타내고, r은 피팅된 구의 반경이다. 구형 피팅은 매개변수 및 r을 설정하여 상기 수학식 4를 최소화하도록 수행한다. 피팅된 구의 중심 위치와 직경은 각각 사과의 위치와 크기를 나타내는 데 사용할 수 있다. 사과는 정확히 구형이 아니기 때문에 피팅된 구형 포인트 클라우드는 일부 부피 평가 오류로 이어질 수 있다. 정확한 부피 추정을 위해 사과의 원래 3D 포인트 클라우드를 유지해야 한다. 사과의 원래 3D 포인트 클라우드 근처에 있는 도 10의 (b)에서 노란색 점으로 표시된 피팅된 구의 포인트는 도 9의 알고리즘(step 10, 11, 12, 13)을 수행하여 제거될 수 있다. 처리 된 피팅 포인트는 사과의 원래 3D 포인트 클라우드와 병합되어 도 10의 (c)와 같이 컨벡스 헐(convex hull) 알 고리즘을 사용하여 부피를 계산할 수 있다. 도 11은 과실의 공간 밀도 분포의 수확량 지도를 나타내는 예시도이다. 도 11을 참조하면, 과수원 과실정보 측정장치는 과실정보를 기초로 과실의 공간 밀도 분포를 과수원 맵에 투영하여 과실의 수확량을 지도화할 수 있다. 과수원의 과실 수확량 지도는 각 나무의 수확량 분포를 분석하는 데 사용할 수 있다. 도 11의 수확량 지도를 보면, MAAS 필드에 있는 나무는 매우 어렸고 수확량이 가장 적은 것을 알 수 있다. 또한, VAAS 필드에 있는 과실의 분포는 심하게 고르지 않았고 외쪽 상단과 오른쪽 하단 부분 에 고수확 영역(나무당 160개 이상의 과실)이 있는 것을 알 수 있다. 건물 음영으로 인해 VWAS 필드의 왼쪽 하 단에 있는 나무는 더 낮은 수확량을 보이고 건물과의 거리가 멀어질수록 줄당 수확량이 크게 증가하는 것을 알 수 있다. 과수원 과실정보 측정장치는 과수원의 과실 수확량 지도를 과수원 조성이나 식재계획에 활용할 수 있다. 일 실시예에 따른 3차원 이미지 기반의 과수원 과실정보 측정장치 및 방법은 드론과 다중 카메라를 이용하여 과 수원의 3D 이미지 모델을 재구성하여 고품질을 생성할 수 있으며, 일반화된 희소 합성곱 신경망, 가중 판별 손 실 함수 및 3D HDBSCAN 클러스터링을 포함하는 딥러닝 기반의 인스턴스 분할 알고리즘을 통해 개별 과실 객체를 추출하고 추출한 과실 객체의 모양을 구형 피팅 방법으로 보완하여 과실 개수, 위치 및 부피와 같은 과실 특성 을 계산하여 정확하게 과실정보를 측정할 수 있으며 과실의 2D 및 3D 공간 분포 매핑을 통해 지도화하여 과실 분포와 공간적 변동성을 직관적으로 보여줄 뿐만 아니라 정확한 수확량 분석과 디지털 농업 운영에 일조할 수 있다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 부호의 설명100: 3차원 이미지 기반의 과수원 과실정보 측정 시스템 110: 카메라 모듈 130: 과수원 과실정보 측정장치 150: 데이터베이스 210: 프로세서 230: 메모리 250: 사용자 입출력부 270: 네트워크 입출력부 310: 과수원 이미지 생성부 330: 과실 객체 추출부 350: 과실정보 측정부 370: 수확량 지도화부 390: 제어부"}
{"patent_id": "10-2023-0081991", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 3차원 이미지 기반의 과수원 과실정보 측정 시스템을 설명하는 도면이다. 도 2는 도 1의 과수원 과실정보 측정장치의 시스템 구성을 설명하는 도면이다. 도 3은 도 1의 과수원 과실정보 측정장치의 기능적 구성을 설명하는 도면이다. 도 4는 본 발명에 따른 3차원 이미지 기반의 과수원 과실정보 측정 과정의 일 실시예를 설명하는 순서도이다. 도 5 및 도 6은 과수원 3D 이미지 모델 생성 구성을 설명하는 도면이다. 도 7은 본 발명에 따른 3차원 이미지 기반의 과수원 과실정보 측정 처리 구조를 설명하는 도면이다. 도 8은 도 7에 있는 3D 인스턴스 분할 모델을 설명하는 도면이다. 도 9는 도 7에 있는 과실 특성 추출 알고리즘을 설명하는 도면이다. 도 10은 구형 피팅(Sphere fitting) 방법을 적용한 과실 부피 보완을 설명하는 도면이다. 도 11은 과실의 공간 밀도 분포의 수확량 지도를 나타내는 도면이다."}
