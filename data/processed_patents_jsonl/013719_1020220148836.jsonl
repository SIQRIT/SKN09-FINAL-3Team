{"patent_id": "10-2022-0148836", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0067617", "출원번호": "10-2022-0148836", "발명의 명칭": "학습 모델 운영 방법 및 장치", "출원인": "주식회사 누비랩", "발명자": "김대훈"}}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학습 모델 운영 장치에 의해 수행되는 학습 모델 운영 방법에 있어서, 기 훈련 데이터 및 새로운 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별하는 단계; 및 상기 선별된 적어도 하나의 훈련 데이터를 이용하여 기 학습 모델을 새롭게 학습시키는 단계를 포함하는, 학습모델 운영 방법."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 적어도 하나의 훈련 데이터를 선별하는 단계는, 상기 기 학습 모델을 통해 상기 선별된 적어도 하나의 훈련 데이터를 평가하고, 상기 선별된 적어도 하나의 훈련 데이터에서 기설정된 평가 지표의 비율이 가장 높은 훈련 데이터를 선택하는, 학습 모델 운영 방법."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 새롭게 학습된 학습 모델을 상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나와 비교하는 단계; 및 상기 새롭게 학습된 학습 모델이 상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 미만이면 나머지 선별된 훈련 데이터를 이용하여 상기 기 학습 모델을 새롭게 학습시키고, 상기 새롭게 학습된 학습 모델이상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 이상이면 상기 기 학습 모델을 상기 새롭게 학습된 학습 모델로 업데이트하는 단계를 더 포함하는, 학습 모델 운영 방법."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 적어도 하나의 훈련 데이터를 선별하는 단계는, 기 훈련 데이터에서 조건적 샘플링을 통해 선별된 제1 훈련 데이터, 새로운 훈련 데이터에서 기 학습 모델의 액티브 학습(Active learning)으로 라벨링된 제2 훈련 데이터 및 상기 제1 훈련 데이터 및 상기 제2 훈련 데이터를 통합한 통합 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별하는, 학습 모델 운영 방법."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 적어도 하나의 훈련 데이터를 선별하는 단계는, 기 훈련 데이터에서 기설정된 예측 오류값을 초과하는 훈련 데이터를 샘플링하여 조건적 샘플링 조건을 만족하는 제1 훈련 데이터를 선별하는, 학습 모델 운영 방법."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 적어도 하나의 훈련 데이터를 선별하는 단계는, F1 점수(F1-score), 정확도(Accuracy), mAP(mean Average Precision) 및 mIOU(mean Intersection Over Union)중에서 적어도 하나의 성능 지표를 이용하여 상기 기 학습 모델에서의 특정 훈련 데이터에 대한 성능을 판단하공개특허 10-2024-0067617-3-는 성능 지표값을 산출하는, 학습 모델 운영 방법."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서, 상기 적어도 하나의 훈련 데이터를 선별하는 단계는, 상기 새로운 훈련 데이터에서 스코어 모델(Score model)을 통해 불확실 점수를 산출하고 상기 산출된 불확실 점수가 기설정된 임계치를 초과한 새로운 훈련 데이터를 상기 제2 훈련 데이터로 라벨링하는, 학습 모델 운영 방법."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제4항에 있어서, 상기 기 학습 모델을 새롭게 학습시키는 단계는, 메모리 맵핑(Memory Mapping) 방식, 선택적 재훈련(Selective Re-training) 방식, 동적 확장(DynamicExpansion) 방식 및 분할 및 복제(Split and Duplication) 방식 중에서 어느 하나의 방식을 이용하여 지속적학습 동작을 수행하는, 학습 모델 운영 방법."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 기 학습 모델을 새롭게 학습시키는 단계는, 상기 제1 훈련 데이터와 이전 학습시 사용된 이전 훈련 데이터에서 기설정된 비율만큼 샘플링하여 메모리에 업로드하고 상기 메모리에 상기 라벨링된 제2 훈련 데이터를 통합시키는, 메모리 맵핑(Memory-mapping) 방식을 이용하여 상기 기 학습된 학습 모델을 학습시키는, 학습 모델 운영 방법."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "기 학습 모델 및 기 훈련 데이터를 저장하는 데이터베이스; 하나 이상의 프로그램을 저장하는 메모리; 및 상기 저장된 하나 이상의 프로그램을 실행하는 프로세서를 포함하고, 상기 프로세서는, 기 훈련 데이터 및 새로운 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별하고, 상기 선별된 적어도 하나의 훈련 데이터를 이용하여 기 학습 모델을 새롭게 학습시키는, 학습 모델 운영 장치."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 프로세서는, 상기 기 학습 모델을 통해 상기 선별된 적어도 하나의 훈련 데이터를 평가하고, 상기 선별된 적어도 하나의 훈련 데이터에서 기설정된 평가 지표의 비율이 가장 높은 훈련 데이터를 선택하는, 학습 모델 운영 장치."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 프로세서는, 상기 새롭게 학습된 학습 모델을 상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나와 비교하고, 상기 새롭게 학습된 학습 모델이 상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 미만이면 나머지 선별된 훈련 데이터를 이용하여 상기 기 학습 모델을 새롭게 학습시키고, 상기 새롭게 학습된 학습 모델이공개특허 10-2024-0067617-4-상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 이상이면 상기 기 학습 모델을 상기 새롭게 학습된 학습 모델로 업데이트하는, 학습 모델 운영 장치."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 프로세서는, 기 훈련 데이터에서 조건적 샘플링을 통해 선별된 제1 훈련 데이터, 새로운 훈련 데이터에서 기 학습 모델의 액티브 학습(Active learning)으로 라벨링된 제2 훈련 데이터 및 상기 제1 훈련 데이터 및 상기 제2 훈련 데이터를 통합한 통합 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별하는, 학습 모델 운영 장치."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 프로세서는, 기 훈련 데이터에서 기설정된 예측 오류값을 초과하는 훈련 데이터를 샘플링하여 조건적 샘플링 조건을 만족하는 제1 훈련 데이터를 선별하는, 학습 모델 운영 장치."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서, 상기 프로세서는, F1 점수(F1-score), 정확도(Accuracy), mAP(mean Average Precision) 및 mIOU(mean Intersection Over Union)중에서 적어도 하나의 성능 지표를 이용하여 상기 기 학습 모델에서의 특정 훈련 데이터에 대한 성능을 판단하는 성능 지표값을 산출하는, 학습 모델 운영 장치."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서, 상기 프로세서는, 상기 새로운 훈련 데이터에서 스코어 모델(Score model)을 통해 불확실 점수를 산출하고 상기 산출된 불확실 점수가 기설정된 임계치를 초과한 새로운 훈련 데이터를 상기 제2 훈련 데이터로 라벨링하는, 학습 모델 운영 장치."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서, 상기 프로세서는, 메모리 맵핑(Memory Mapping) 방식, 선택적 재훈련(Selective Re-training) 방식, 동적 확장(DynamicExpansion) 방식 및 분할 및 복제(Split and Duplication) 방식 중에서 어느 하나의 방식을 이용하여 지속적학습 동작을 수행하는, 학습 모델 운영 장치."}
{"patent_id": "10-2022-0148836", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 프로세서는, 상기 제1 훈련 데이터와 이전 학습시 사용된 이전 훈련 데이터에서 기설정된 비율만큼 샘플링하여 메모리에 업로드하고 상기 메모리에 상기 라벨링된 제2 훈련 데이터를 통합시키는, 메모리 맵핑(Memory-mapping) 방식을 이용하여 상기 기 학습된 학습 모델을 학습시키는, 학습 모델 운영 장치. 공개특허 10-2024-0067617-5-"}
{"patent_id": "10-2022-0148836", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 학습 모델 운영 방법 및 장치에 관한 것으로, 본 발명의 일 실시예에 따른 학습 모델 운영 방법은, 기 훈련 데이터 및 새로운 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별하는 단계, 및 상기 선별된 적어도 하나의 훈련 데이터를 이용하여 상기 기 학습 모델을 새롭게 학습시키는 단계를 포함한다."}
{"patent_id": "10-2022-0148836", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 학습 모델 운영 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0148836", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어 건강에 대한 관심이 높아지고 있으나 반면에 과체중이나 비만으로 고통받는 사람들도 점차 증가하고 있다. 이러한 과체중이나 비만은 당뇨, 고혈압 등 각종 질환의 원인이 되는 심각한 문제이다. 따라서, 이와 같은 과체중이나 비만을 해결하기 위해서는 자신의 식습관을 분석하는 것이 선행되어야 한다. 일 반적으로 본인의 호불호 음식에 대해 알고 있지만 실제로 섭취하는 음식의 종류와 횟수를 기억하지는 못한다. 따라서 자신의 식습관을 분석하기 위해 실제로 섭취하는 음식을 파악하고, 파악한 음식에 대한 정보에 따라 개 인의 식습관을 분석할 필요가 있다. 하지만, 현재 공개된 대부분의 기술들은 카메라를 통해 촬영된 음식 이미지를 단순 이미지 검색하는데 그치고 있기 때문에 그 정확도가 현저하게 떨어진다. 또한, 이미지 검색에서 음식 종류 식별의 정확도가 떨어지다 보니 칼로리 계산 등과 같은 다음 단계들에서는 더 큰 오차가 발생한다는 문제점이 있다. 이러한 문제점을 해결하기 위해, 인공지능 모델을 이용한 딥 러닝 기술이 이미지 식별 분야에 적용되고 있다. 한번 학습이 된 인공지능 모델은 그 상태(state)에 멈춰 있다. 시간이 지남에 따라 인공지능 모델은 과거의 상 태에 멈춰 있기에 도태되며 인공지능 모델에 대한 성능 또한 떨어지게 된다. 한번 학습이 된 인공지능 모델은 이전에 학습한 이미지 분류 동작에만 능숙하다. 즉, 이전에 학습되지 않은 새로운 이미지에 대한 분류 작업은 사전 학습이 완료된 이미지에 비해 정확도가 떨어지고 있다. 그렇기에 인공지능 모델은 지속적인 학습이 필요하 다. 이를 위해, 인공지능 모델을 지속적으로 학습하기 위해서는 새로운 훈련 데이터를 추가해서 학습을 해야한 다. 하지만, 학습에 걸리는 시간은 훈련 데이터의 양에 비례한다고 볼 수 있다. 그런데, 인공지능 모델을 업데이트 하기 위해 지속적으로 훈련 데이터를 추가하여 학습을 진행하다보면 인공지능 모델을 학습하기 위해 필요한 학 습 시간, 인공지능 모델의 업데이트 주기, 인공지능 모델의 학습에 사용되었던 중복 데이터가 점차 늘어나게 된 다."}
{"patent_id": "10-2022-0148836", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들은 학습 모델의 셀프 진단 및 학습 모델의 인식 성능을 향상시키기 위한, 학습 모델 운영 방 법 및 장치를 제공하고자 한다. 다만, 본 발명의 해결하고자 하는 과제는 이에 한정되는 것이 아니며, 본 발명의 사상 및 영역으로부터 벗어나 지 않는 범위의 환경에서도 다양하게 확장될 수 있을 것이다."}
{"patent_id": "10-2022-0148836", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 학습 모델 운영 장치에 의해 수행되는 학습 모델 운영 방법에 있어서, 기 훈련 데이터 및 새로운 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별하는 단계; 및 상기 선별된 적어도 하 나의 훈련 데이터를 이용하여 기 학습 모델을 새롭게 학습시키는 단계를 포함하는, 학습 모델 운영 방법이 제공 될 수 있다. 상기 적어도 하나의 훈련 데이터를 선별하는 단계는, 상기 기 학습 모델을 통해 상기 선별된 적어도 하나의 훈 련 데이터를 평가하고, 상기 선별된 적어도 하나의 훈련 데이터에서 기설정된 평가 지표의 비율이 가장 높은 훈 련 데이터를 선택할 수 있다. 상기 방법은, 상기 새롭게 학습된 학습 모델을 상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 와 비교하는 단계; 및 상기 새롭게 학습된 학습 모델이 상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어 도 하나 미만이면 나머지 선별된 훈련 데이터를 이용하여 상기 기 학습 모델을 새롭게 학습시키고, 상기 새롭게 학습된 학습 모델이 상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 이상이면 상기 기 학습 모델을 상기 새롭게 학습된 학습 모델로 업데이트하는 단계를 더 포함할 수 있다. 상기 적어도 하나의 훈련 데이터를 선별하는 단계는, 기 훈련 데이터에서 조건적 샘플링을 통해 선별된 제1 훈 련 데이터, 새로운 훈련 데이터에서 기 학습 모델의 액티브 학습(Active learning)으로 라벨링된 제2 훈련 데이 터 및 상기 제1 훈련 데이터 및 상기 제2 훈련 데이터를 통합한 통합 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별할 수 있다. 상기 적어도 하나의 훈련 데이터를 선별하는 단계는, 기 훈련 데이터에서 기설정된 예측 오류값을 초과하는 훈 련 데이터를 샘플링하여 조건적 샘플링 조건을 만족하는 제1 훈련 데이터를 선별할 수 있다. 상기 적어도 하나의 훈련 데이터를 선별하는 단계는, F1 점수(F1-score), 정확도(Accuracy), mAP(mean Average Precision) 및 mIOU(mean Intersection Over Union) 중에서 적어도 하나의 성능 지표를 이용하여 상기 기 학습 모델에서의 특정 훈련 데이터에 대한 성능을 판단하는 성능 지표값을 산출할 수 있다. 상기 적어도 하나의 훈련 데이터를 선별하는 단계는, 상기 새로운 훈련 데이터에서 스코어 모델(Score model)을 통해 불확실 점수를 산출하고 상기 산출된 불확실 점수가 기설정된 임계치를 초과한 새로운 훈련 데이터를 상기 제2 훈련 데이터로 라벨링할 수 있다. 상기 기 학습 모델을 새롭게 학습시키는 단계는, 메모리 맵핑(Memory Mapping) 방식, 선택적 재학습(Selective Re-training) 방식, 동적 확장(Dynamic Expansion) 방식 및 분할 및 복제(Split and Duplication) 방식 중에서 어느 하나의 방식을 이용하여 지속적 학습 동작을 수행할 수 있다. 상기 기 학습 모델을 새롭게 학습시키는 단계는, 상기 제1 훈련 데이터와 이전 학습시 사용된 이전 훈련 데이터 에서 기설정된 비율만큼 샘플링하여 메모리에 업로드하고 상기 메모리에 상기 라벨링된 제2 훈련 데이터를 통합 시키는, 메모리 맵핑(Memory-mapping) 방식을 이용하여 상기 기학습된 학습 모델을 학습시킬 수 있다. 한편, 본 발명의 다른 실시예에 따르면, 기 학습 모델 및 기 훈련 데이터를 저장하는 데이터베이스; 하나 이상 의 프로그램을 저장하는 메모리; 및 상기 저장된 하나 이상의 프로그램을 실행하는 프로세서를 포함하고, 상기 프로세서는, 기 훈련 데이터 및 새로운 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별하고, 상기 선별 된 적어도 하나의 훈련 데이터를 이용하여 기 학습 모델을 새롭게 학습시키는, 학습 모델 운영 장치가 제공될 수 있다. 상기 프로세서는, 상기 기 학습 모델을 통해 상기 선별된 적어도 하나의 훈련 데이터를 평가하고, 상기 선별된 적어도 하나의 훈련 데이터에서 기설정된 평가 지표의 비율이 가장 높은 훈련 데이터를 선택할 수 있다. 상기 프로세서는, 상기 새롭게 학습된 학습 모델을 상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나와 비교하고, 상기 새롭게 학습된 학습 모델이 상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 미만이면 나머지 선별된 훈련 데이터를 이용하여 상기 기 학습 모델을 새롭게 학습시키고, 상기 새롭게 학 습된 학습 모델이 상기 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 이상이면 상기 기 학습 모델 을 상기 새롭게 학습된 학습 모델로 업데이트할 수 있다. 상기 프로세서는, 기 훈련 데이터에서 조건적 샘플링을 통해 선별된 제1 훈련 데이터, 새로운 훈련 데이터에서 기 학습 모델의 액티브 학습(Active learning)으로 라벨링된 제2 훈련 데이터 및 상기 제1 훈련 데이터 및 상기 제2 훈련 데이터를 통합한 통합 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별할 수 있다. 상기 프로세서는, 기 훈련 데이터에서 기설정된 예측 오류값을 초과하는 훈련 데이터를 샘플링하여 조건적 샘플 링 조건을 만족하는 제1 훈련 데이터를 선별할 수 있다. 상기 프로세서는, F1 점수(F1-score), 정확도(Accuracy), mAP(mean Average Precision) 및 mIOU(mean Intersection Over Union) 중에서 적어도 하나의 성능 지표를 이용하여 상기 기 학습 모델에서의 특정 훈련 데 이터에 대한 성능을 판단하는 성능 지표값을 산출할 수 있다. 상기 프로세서는, 상기 새로운 훈련 데이터에서 스코어 모델(Score model)을 통해 불확실 점수를 산출하고 상기 산출된 불확실 점수가 기설정된 임계치를 초과한 새로운 훈련 데이터를 상기 제2 훈련 데이터로 라벨링할 수 있 다. 상기 프로세서는, 메모리 맵핑(Memory Mapping) 방식, 선택적 재학습(Selective Re-training) 방식, 동적 확장 (Dynamic Expansion) 방식 및 분할 및 복제(Split and Duplication) 방식 중에서 어느 하나의 방식을 이용하여 지속적 학습 동작을 수행할 수 있다.상기 프로세서는, 상기 제1 훈련 데이터와 이전 학습시 사용된 이전 훈련 데이터에서 기설정된 비율만큼 샘플링 하여 메모리에 업로드하고 상기 메모리에 상기 라벨링된 제2 훈련 데이터를 통합시키는, 메모리 맵핑(Memory- mapping) 방식을 이용하여 상기 기학습된 학습 모델을 학습시킬 수 있다."}
{"patent_id": "10-2022-0148836", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 기술은 다음의 효과를 가질 수 있다. 다만, 특정 실시예가 다음의 효과를 전부 포함하여야 한다거나 다 음의 효과만을 포함하여야 한다는 의미는 아니므로, 개시된 기술의 권리범위는 이에 의하여 제한되는 것으로 이 해되어서는 아니 될 것이다. 본 발명의 실시예들은 학습 모델의 셀프 진단 및 학습 모델의 인식 성능을 향상시킬 수 있다. 본 발명의 실시예들은 학습 모델의 셀프 진단 동작을 통해 자체적으로 필요한 훈련 데이터를 판단하여 샘플링 및 라벨링 동작을 통한 지속적 학습을 수행하는, 조건적 샘플링(Hard-negative-sampling), 액티브 학습(Active- learning) 및 지속적 학습(Continual-learning) 방식을 이용함으로써, 학습 모델이 자체적으로 셀프 진단을 수 행하고 학습 모델의 인식 성능을 최적으로 향상시킬 수 있다. 본 발명의 실시예들은 학습 모델의 다음 학습시, 현재 학습 모델에 취약한 데이터를 취약하지 않은 데이터에 비 해 상대적으로 많이 샘플링하여 학습에 신속하게 반영할 수 있다. 본 발명의 실시예들은 메모리 맵핑(Memory-mapping) 방식을 사용하여, 조건적 샘플링된 훈련 데이터, 이전에 학 습했던 훈련 데이터 및 새로 라벨링된 훈련 데이터에 대해 필요한 훈련 데이터만을 메모리에 통합하여 학습 모 델을 학습함으로써, 훈련 데이터 수가 증가해도 일정 수량의 훈련 데이터로만 학습을 수행하여 학습 시간, 학습 모델의 업데이터 주기, 또는 중복 데이터를 감소시킬 수 있다."}
{"patent_id": "10-2022-0148836", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세한 설명에 구체적으로 설명하고자 한다. 그러나 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 기술적 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이 해될 수 있다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들이 용어들에 의해 한정되 는 것은 아니다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 본 발명에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 본 발명에서 사용한 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용 어들을 선택하였으나 이는 당 분야에 종사하는 기술자의 의도, 판례, 또는 새로운 기술의 출현 등에 따라 달라 질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분 에서 상세히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 발명에서, \"포함하다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명의 실시예들에서 객체는 실세계에 존재하고 카메라로 촬영하여 인식 가능한 것을 나타낸다. 예를 들어, 객체에는 급식소 또는 식당에서의 음식, 카페테리아 또는 슈퍼마켓의 식품, 일반적인 물체, 이동수단 등이 포함 될 수 있다. 이하, 본 발명의 실시예들을 첨부 도면을 참조하여 상세히 설명하기로 하며, 첨부 도면을 참조하여 설명함에 있 어, 동일하거나 대응하는 구성요소는 동일한 도면번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 도 1은 본 발명의 일 실시예에 따른 학습 모델 운영 방법을 나타낸 흐름도이다. 단계 S101에서, 본 발명의 일 실시예에 따른 학습 모델 운영 장치는 기 훈련(training) 데이터 또는 새로운 훈 련 데이터에서 적어도 하나의 훈련 데이터를 선별한다. 학습 모델 운영 장치는 기 훈련 데이터에서 조건적 샘플 링을 통해 선별된 제1 훈련 데이터, 새로운 훈련 데이터에서 기 학습 모델(learning model)의 액티브 학습 (Active learning)으로 라벨링된 제2 훈련 데이터, 및 제1 훈련 데이터와 제2 훈련 데이터를 통합한 통합 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별할 수 있다. 여기서, 학습 모델 운영 장치는 기 훈련 데이터에 서 조건적 샘플링을 통해 제1 훈련 데이터를 선별할 수 있다. 학습 모델 운영 장치는 새로운 훈련 데이터에서 기 학습 모델의 액티브 학습(Active learning)으로 라벨링된 제2 훈련 데이터를 선별할 수 있다. 학습 모델 운 영 장치는 제1 훈련 데이터 및 제2 훈련 데이터를 통합한 통합 훈련 데이터를 선별할 수 있다. 단계 S102에서, 학습 모델 운영 장치는 선별된 적어도 하나의 훈련 데이터에서 학습 대상인 적어도 하나의 훈련 데이터를 선택한다. 여기서, 학습 모델 운영 장치는 기 학습 모델을 통해 적어도 하나의 훈련 데이터를 평가하 고, 평가 결과를 기초로 선별된 적어도 하나의 훈련 데이터에서 기설정된 평가 지표의 비율이 가장 높은 훈련 데이터를 선택할 수 있다. 예를 들어, 기설정된 평가 지표에는 불확실성, 아웃라이어(outlier) 및 거짓 네거티 브(false negative) 중에서 적어도 하나가 포함될 수 있다. 단계 S103에서, 학습 모델 운영 장치는 적어도 하나의 훈련 데이터를 이용하여 기 학습 모델을 새롭게 학습 (learning) 시킨다. 학습 모델 운영 장치는 새롭게 학습시킨 학습 모델을 검증하고 기 학습 모델을 업데이트할 수 있다. 검증 및 기 학습 모델의 업데이트 과정을 살펴보면, 학습 모델 운영 장치는 적어도 하나의 훈련 데이터로 기 학 습 모델을 학습시킨다. 학습 모델 운영 장치는 새롭게 학습된 학습 모델과 기 학습 모델과의 성능을 비교한다. 여기서, 학습 모델 운영 장치는 새롭게 학습된 학습 모델이 기 학습 모델보다 성능이 좋지 못한 경우 나머지 2 가지의 선별된 훈련 데이터들에 대해서 위의 기 학습 모델의 학습 과정 및 성능 비교 과정을 실행한다. 반대로, 학습 모델 운영 장치는 새롭게 학습된 학습 모델이 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 이상이면, 기 학습 모델을 새롭게 학습된 학습 모델로 업데이트할 수 있다. 학습 모델 운영 장치는 새롭게 학습 된 학습 모델이 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 미만이면, 기 학습 모델을 사용하고 단계 S101의 데이터 취합 과정, 단계 S102의 데이터 선택 과정, 단계 S103의 검증 및 모델 업데이트 과정을 다 시 수행할 수 있다. 다양한 음식을 학습하는 학습 모델을 일 실시예로 살펴보면, 학습 모델 운영 장치는 음식 종류, 군, 또는 카테 고리(예컨대, 곡류, 육류, 메인 반찬류 등)별로 별도로 음식 인식의 정확도를 비교해서 그 학습 모델이 어디에 더 강하고 어디에 더 약한지를 분석하여 음식 종류, 군, 또는 카테고리별로 더 강한 학습 모델을 선별할 수 있 다. 이후, 학습 모델 운영 장치는 신규 모델이 업데이트가 되고 난 이후, 수집된 신규 데이터로 신규 모델의 성능을 지속적으로 체크한다. 학습 모델 운영 장치는 신규 모델의 성능이 일정 수준이 떨어지면 다시 훈련 데이터를 선 별하여 학습 모델을 학습하는 과정을 반복할 수 있다. 도 2는 본 발명의 일 실시예에 따른 학습 모델 운영 장치의 운영 동작을 나타낸 도면이다. 우선, 학습 모델 운영 장치는 학습 모델의 학습시에 성능을 측정하기 위해, 훈련 데이터(train_set), 검증 데이터(valid_set), 테스트 데이터(test_set)와 같이 3개의 데이터 세트를 나누어서 학습 모델의 학습 동작과검증 동작 그리고 테스트 동작을 수행한다. 여기서, 훈련 데이터(train_set)는 학습 모델의 학습(learning)을 위해 필요한 데이터를 나타낸다. 검증 데이터 (valid_set)는 학습 모델의 검증을 수행하기 위한 데이터를 나타낸다. 테스트 데이터(test_set)는 학습 모델의 최종 성능을 측정하기 위한 데이터를 나타낸다. 도 2에 도시된 바와 같이, 학습 모델 운영 장치는 조건적 샘플링(Hard-negative sampling) 동작, 액 티브 학습(Active-learning) 동작 및 지속적 학습(Continual-learning) 동작 중에서 적어도 하나의 동작을 수행할 수 있다. 조건적 샘플링 동작에 대해 살펴보면 다음과 같다. 학습 모델 운영 장치는 지금까지 학습했던 기 훈 련 데이터를 입력받고 조건적 샘플링 동작을 수행한다. 학습 모델 운영 장치는 학습 모델의 학습을 수행하면서 지속적으로 틀리거나 불확실(Uncertainty) 점수가 기설정된 예측 오류값 대비 높은 훈련 데이터들을 샘플링(Sampling)하여 제1 훈련 데이터를 샘플링한다. 여기서, 학습 모델 운영 장치는 샘플링된 제1 훈련 데이터를 학습 모델이 학습하기 어려운 훈련 데이터로 분류를 해둔다. 이후, 학습 모델 운영 장치는 샘플 링된 제1 훈련 데이터를 지속적 학습 동작을 수행하는 경우 사용하게 된다. 액티브 학습 동작에 대해 살펴보면 다음과 같다. 학습 모델 운영 장치는 지금까지 학습했던 훈련 데 이터와 상이한 새로운 훈련 데이터를 입력받아 액티브 학습 동작을 수행한다. 학습 모델 운영 장치는 지금까지 학습했던 학습 모델을 사용해서 새로운 훈련 데이터가 들어왔을 때, 액티브 학습 동작을 통해 학 습 모델을 기준으로 의미 있는 제2 훈련 데이터들을 샘플링하고 샘플링된 제2 훈련 데이터들만 라벨링을 진행한 다. 여기서, 학습 모델을 기준으로 의미 있는 제2 훈련 데이터는 입력된 새로운 훈련 데이터 중에서 확실하지 않은 제2 훈련 데이터 즉, 학습 모델이 정확히 예측하지 못하는 가능성이 높은 제2 훈련 데이터들만 라벨링을 진행한다. 지속적 학습 동작에 대해 살펴보면 다음과 같다. 학습 모델 운영 장치는 조건적 샘플링된 제1 훈련 데이터, 라벨링된 제2 훈련 데이터 및 이전 학습시 사용했던 훈련 데이터를 전달받는다. 학습 모델 운영 장치 는 전달받은 조건적 샘플링된 제1 훈련 데이터와, 이전 학습시 사용했던 훈련 데이터를 버전별로 기설정된 비율(예컨대, 20% 등)의 훈련 데이터를 추출하여 메모리에 업로드한다. 그리고 학습 모델 운영 장치는 메 모리에 업로드된 샘플링된 제1 훈련 데이터 및 기설정된 비율만큼 추출된 훈련 데이터와, 새로 추가된 제2 훈련 데이터들과 합쳐서 학습 모델의 학습을 수행한다. 도 3은 본 발명의 일 실시예에 따른 훈련 데이터 선별 방법을 나타낸 흐름도이다. 도 3에 도시된 바와 같이, 단계 S201에서, 학습 모델 운영 장치는 훈련 데이터 중에서 기설정된 샘플링 조 건을 만족하는 제1 훈련 데이터를 샘플링한다. 단계 S202에서, 학습 모델 운영 장치는 기학습된 학습 모델을 통해 훈련 데이터와 상이한 새로운 훈련 데 이터에 대한 불확실(Uncertainty) 점수에 따라 제2 훈련 데이터를 선택적으로 라벨링한다. 단계 S203에서, 학습 모델 운영 장치는 샘플링된 제1 훈련 데이터와 라벨링된 제2 훈련 데이터를 통합하여 기학습된 학습 모델을 학습시킨다. 한편, 학습 모델 운영 장치는 학습 모델의 성능을 정량적으로 측정하기 위해서, F1 점수(F1-score), 정확 도(Accuracy), mAP(mean Average Precision) 및 mIOU(mean Intersection Over Union) 중에서 적어도 하나의 성 능 지표를 사용할 수 있다. 성능 지표에 대해 살펴보면, F1 점수(F1-score)는 정밀도(Precision)와 재현율(Recall)의 조화 평균으로 정밀도 와 재현율이 비슷할 수록 F1 점수도 높아진다. F1 점수는 0 내지 1의 값을 가지며 일반적으로 F1 점수가 높을수 록 성능이 좋다고 할 수 있다. 정확도(Accuracy)는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표이다. 즉, 정확도(Accurac y)는 예측 결과가 동일한 데이터 건수를 전체 예측 데이터 건수로 나눈 값이 될 있다. 정확도(Accuracy)는 직관 적으로 학습 모델 예측 성능을 나타내는 평가 지표일 수 있다. mAP(mean Average Precision)는 객체 검출 및 이미지 분류 알고리즘의 성능을 평가할 수 있다. mAP(mean Average Precision)는 객체 클래스가 여러 개인 경우 각 클래스당 AP(Average Precision)를 구하고 그것을 모 두 합한 다음에 객체 클래스의 개수로 나눠줌으로써 알고리즘의 성능을 평가할 수 있다. 여기서, AP(AveragePrecision)의 계산은 재현율(Recall)을 0부터 0.1 단위로 증가시켜서 1까지 (총 11개의 값) 증가시킬 때 필연적 으로 정밀도(Precision)가 감소하게 되는데 각 단위 마다 정밀도(Precision) 값을 계산하여 평균을 내어 계산한 다. 즉 11가지의 재현율(Recall) 값에 따른 정밀도(Precision) 값들의 평균을 AP라고 한다. 하나의 클래스 마다 AP 값을 계산 할 수 있으며 전체 클래스 갯수에 대해 AP를 계산하여 평균을 낸 값이 바로 mAP이다. IOU(Intersection Over Union)는 두 경계 상자간의 겹침을 평가하는 자카드 지수(Jaccard index)를 기반으로 하는 측정 기법이다. 여기서 두 경계 상자간이라 함은 GT 박스와 검출된(예측된) 박스를 뜻한다. IOU 를 적용하 면 탐지 결과가 유효한지 아닌지를 알 수 있다. 객체 검출에서 바운딩 박스를 얼마나 잘 예측했는지는 IOU 지표 를 통해 측정하게 된다. 이는 객체 검출 문제뿐만 아니라 이미지 분할(Image Segmentation)에서도 사용될 수 있 다. 즉, 객체 검출에서는 GT 와 예측 값 간의 교집합과 합집합을 통해 IoU를 측정하게 된다. mIOU는 세그먼테이 션(Segmentation)과 객체 검출(Object detection)에서 가장 빈번하게 사용되는 성능 지표로서, IOU 값에 대한 평균값이다. 즉, 세그먼테이션된 한 장의 이미지에 대해 성능 평가 지표는 IOU 값이고, 여러 장의 이미지에 대 해 성능 평가 지표는 한 장마다의 IOU 값을 평균낸 mIOU 값이다. 학습 모델 운영 장치는 가장 우선적으로 매크로 F1 점수를 이용하여 학습 모델의 성능을 정량적으로 측정 할 수 있다. 매크로 F1 점수는 각각의 클래스(class)마다 점수를 계산하기 때문에 어떤 클래스에서 점수가 낮게 나오는지 알 수 있고, 어떤 클래스에 대해서 모델이 강인한지 또는 어려워하는지를 알 수 있다. 또한, 이를 바 탕으로 취약한 클래스에 대해서 훈련 데이터를 추가하는 등의 방법을 사용하고 있다. 한편, 학습 모델 운영 장치는 이러한 성능 지표를 통해 학습 모델이 어떤 데이터에 대해서 취약한지 혹은 강인한지를 판단할 수 있다. 그리고 학습 모델 운영 장치는 이러한 성능 지표를 통해 다음에 학습할 때, 현재 취약한 훈련 데이터를 취약하지 않은 훈련 데이터에 비해 상대적으로 많이 샘플링하여 학습 모델의 학습에 반영할 수 있다. 그러면, 학습 모델 운영 장치는 취약한 훈련 데이터를 상대적으로 많이 학습함으로써, 학 습 모델을 해당 훈련 데이터에 대해 강인하게 만들 수 있다. 음식을 학습하는 학습 모델을 실시예로 살펴보면, 학습 모델 운영 장치는 음식의 상태(예컨대, 식사전, 식 사후, 대량의 음식, 1인분의 음식, 잔식(배식후 남은 음식의 양), 식재료, 음식물 쓰레기 등) 별로 정확도를 고 려하여 학습 모델의 성능을 측정할 수 있다. 학습 모델 운영 장치는 학습 모델 선택시, 정확도뿐만 아니라 분석 속도를 고려하여 학습 모델의 성능을 측정할 수 있다. 만약, 학습 모델 운영 장치는 2개의 학습 모델이 정확도에서 큰 차이가 없으면, 2개의 학 습 모델 중에서 학습 모델의 분석 속도가 빠른 학습 모델을 선택할 수 있다. 도 4는 본 발명의 일 실시예에 따른 학습 모델 운영 방법에서 조건적 샘플링 동작을 나타낸 도면이다. 단계 S301에서, 학습 모델 운영 장치는 검출된 타겟에 기초하여 네거티브 샘플을 탐색한다. 단계 S302에서, 학습 모델 운영 장치는 네거티브 샘플을 클러스터링한다. 단계 S303에서, 학습 모델 운영 장치는 각 클러스터로부터 하드 네거티브 샘플을 선택한다. 도 4에 도시된 바와 같이, 학습 모델 운영 장치는 이전에 학습한 모델에서 학습과정 중에 네거티브 (negative)를 포지티브(positive)로 분류한 하드 네거티브(hard negative) 샘플들을 선택해서 저장한다. 학습 모델 운영 장치는 하드 네거티브 샘플의 선택시에 분류 스코어(score)가 가장 높은 기준으로 고르게 된다. 도 5는 본 발명의 일 실시예에 따른 액티브 학습 동작을 나타낸 도면이다. 도 5에 도시된 바와 같이, 액티브 학습 동작에 대해 살펴보면, 우선 새로운 훈련 데이터는 라벨링이 지정되지 않은 풀(Unlabeled pool)에 저장된다. 단계 S401에서, 학습 모델 운영 장치는 라벨링이 지정되지 않은 풀에 저장된 새로운 훈련 데이터에 대해서 이전에 학습했던 학습 모델을 통해서 추론(Inference)을 수행한다. 단계 S402에서, 학습 모델 운영 장치는 추론 결과를 통해 제2 훈련 데이터를 라벨링할지 안할지를 판단할 수 있다. 즉, 학습 모델 운영 장치는 추론 결과를 통해서 제2 훈련 데이터가 불확실한지(If uncertain)를 판단할 수 있다. 이러한 것을 불확실 샘플링(Uncertainty Sampling)이라고도 하며 확실하지 않은 샘플, 즉 이 샘플에 대해서 학습 모델이 정확히 예측하기 애매하다라고 판단되면 해당 샘플을 라벨링할 수 있다. 일반적으로 추론 결과에서, 학습 모델 운영 장치는 스코어 모델(Score model)이 판단하는 스코어(Score)에 서 사용자에 의해 설정된 임계치(threshold)를 통해 불확실 스코어가 기설정된 임계치 보다 초과할 경우 불확실 성(Uncertainty)이 높다고 판단하고 라벨링해야 할 제2 훈련 데이터로 판단할 수 있다. 단계 S403에서, 학습 모델 운영 장치는 제2 훈련 데이터가 불확실하다고 판단되면 불확실하다고 판단된 제 2 훈련 데이터를 라벨링을 수행한다. 그리고 라벨링된 제2 훈련 데이터는 라벨링된 훈련 데이터가 저장된 풀 (Labeled)에 저장된다. 단계 S404에서, 학습 모델 운영 장치는 풀(Labeled)에 저장된 라벨링된 제2 훈련 데이터를 이용하여 이전 에 학습했던 학습 모델을 재학습하게 된다. 그리고 학습 모델 운영 장치는 제2 훈련 데이터에 대해 불확실 여부를 판단하는 단계 S402, 불확실한다고 판단된 제2 훈련 데이터를 라벨링하는 단계 S403, 라벨링된 제2 훈련 데이터를 이용하여 학습 모델을 재학습하는 단계 S404를 반복적으로 수행할 수 있다. 상기와 같이, 학습 모델 운영 장치는 학습한 학습 모델을 통해 새로운 데이터에 대해서 추론을 하고 추론 시 불확실(Uncertainty)이 높은 데이터들을 샘플링한다. 이때, 기준은 모델에서 예측한 스코어(score)를 기반으 로 한다. 여기서, 학습 모델 운영 장치는 객체인지 아닌지를 판단하고 검출(Detection)을 수행하는 학습 모델(Learning model) 또는 객체 분류 모델(Object classification model)에 대해 액티브 학습 동작을 수행할 수 있다. 학습 모델 운영 장치는 불확실한(uncertain) 데이터들을 샘플링하고 사용자가 라벨링을 진행한 뒤 라벨링된 데이터를 이용하여 학습 모델 또는 객체 분류 모델을 다시 학습시킬 수 있다. 한편, 도 3의 단계 S203와 관련된 지속적 학습 동작에 대해 살펴보면, 학습 모델 운영 장치는 학습 모델이 도태되지 않기 위해서는 지속적인 학습과 새로운 데이터들로 학습을 수행한다. 하지만, 이전에 학습했던 훈련 데이터를 사용하지 않고 새로운 훈련 데이터로만 학습을 하게 되면, 학습 모델은 이전에 학습했던 훈련 데이터 에 대해서 잊게 되는 문제가 발생한다. 그렇다고 모든 훈련 데이터를 다 합쳐서 새로운 학습 모델의 학습을 시 작하면, 학습 시간이 길어지는 문제가 발생한다. 그래서 학습 모델 운영 장치는 지속적 학습(Continual- learning)을 학습 모델에 대해 수행한다. 학습 모델 운영 장치는 지속적 학습 방식인 메모리 맵핑(Memory Mapping) 방식, 선택적 재훈련(Selective Re-training) 방식, 동적 확장(Dynamic Expansion) 방식 및 분할 및 복제(Split and Duplication) 방식 중에서 어느 하나의 방식을 이용하여 지속적 학습 동작을 수행할 수 있다. 도 6은 본 발명의 일 실시예에 적용되는 메모리 맵핑 방식을 나타낸 도면이다. 학습 모델에 새로운 데이터를 추가하게 되면 처음부터 모든 데이터를 학습할지 추가한 데이터만 학습할지 선택 을 해야하는데, 전자는 시간이 오래 걸리고, 후자는 기존에 학습했던 이전 데이터에 대한 성능 하락이 문제가 된다. 따라서, 학습 모델 운영 장치는 기존에 학습했던 성능을 유지하면서 새로운 데이터를 추가하는 지속 적 학습 동작을 수행할 수 있다. 도 6에 도시된 바와 같이, 학습 모델 운영 장치는 이전 작업(Previous task)에서 제1 훈련 데이터를 샘플 링하여 에피소딕 메모리(Episodic Memory)에 올려두고 학습을 수행한다. 그리고 학습 모델 운영 장치는 현 재 작업(Current task)에서 이전 작업에서 샘플링된 제1 훈련 데이터와 현재 작업에서의 제2 훈련 데이터를 샘 플링하여 에피소딕 메모리에 올려두고 학습을 다시 수행한다. 이와 같이, 학습 모델 운영 장치는 지속적 학습 방식 중에서 메모리 맵핑 방식을 사용할 수 있다. 학습 모 델 운영 장치는 이전에 학습했던 훈련 데이터들을 몇개의 태스크(task)로 분류할 수 있다. 예를 들어, 학 습 모델에 대해 1월, 2월, 3월에 학습했던 훈련 데이터들을 태스크 1(task1), 태스크 2(task2), 태스크 3(task3)으로 분류하고 각각의 태스크에서 기설정된 비율(예컨대, 20% 등)의 데이터만을 샘플링하여 새로 학습 할 제2 훈련 데이터와 합치고 학습 모델의 학습을 진행할 수 있다. 이렇게 하면 훈련 데이터 수가 훈련 데이터, 제1 훈련 데이터 및 제2 훈련 데이터의 전체 데이터 수가 증가해도 전체 데이터 수의 일부인 훈련 데이터를 일 정 수량의 훈련 데이터로만 학습을 할 수 있게 된다. 도 7은 본 발명의 일 실시예에 적용되는 메모리 맵핑 방식의 어그멘테이션 동작을 나타낸 도면이다. 도 7에 도시된 바와 같이, 학습 모델 운영 장치는 이전 작업에서 제1 훈련 데이터를 샘플링하고(S501), 이 전에 학습했던 객체 이미지에서 여러 어그멘테이션(augmentation) 동작을 수행한 후(S502), 학습을 수행할 수 있다. 그리고 학습 모델 운영 장치는 불확실(uncertainty) 점수를 측정하여 확실성 (certainty)이 낮은 객 체 이미지들을 추출하여 다시 학습을 수행할 수 있다(S503). 한편, 선택적 재훈련(Selective Re-training) 방식을 설명하기로 한다. 학습 모델 운영 장치는 지속적 학 습 방식인 선택적 재훈련(Selective Re-training) 방식을 이용하여 지속적 학습 동작을 수행할 수 있다. 학습 모델 운영 장치는 선택적 재훈련(Selective Re-training) 방식을 통해 재훈련을 수행할 주요한 가중치 (weight)를 선별해서 업데이트(update)할 수 있다. 이때, 주요한 가중치들이 많이 업데이트되면, 기존의 작업을 잊어먹는 파괴적 망각(Catastrophic forgetting) 현상이 생길 수 있기 때문에, 학습 모델 운영 장치는 기 존의 가중치들을 저장했다가 다시 살려준 후 재훈련을 수행할 수 있다. 이러한 과정이 3단계인 분할 및 복제 (Split and Duplication) 방식에서 이루어질 수 있다. 도 8은 본 발명의 일 실시예에 적용되는 동적 확장가능 네트워크를 나타낸 도면이다. 동적 확장가능 네트워크(Dynamically expandable networks, DEN) 방식을 설명하기로 한다. 학습 모델 운영 장 치는 지속적 학습 방식인 메모리 맵핑 방식 이외에 동적 확장가능 네트워크(Dynamically expandable networks, DEN)를 이용하여 지속적 학습 동작을 수행할 수 있다. 즉, 학습 모델 운영 장치는 동적으로 학 습 가능한 파라미터 개수를 늘리면서 새로운 작업에 적응해 나갈 수 있다. 이러한 동적 확장가능 네트워크 방식 은 선택적 재훈련 동작을 거쳤는데 타겟 작업(Target Task)에 대한 충분한 성능이 안 나올 경우, 학습 모델 운 영 장치는 학습 모델의 용량(Capacity)이 부족하기 때문에, 동적 확장가능 네트워크에서 노드를 추가하여 지속적 학습 동작을 수행할 수 있다. 다음으로, 분할 및 복제(Split and Duplication) 방식을 설명하기로 한다. 전술된 바와 같이, 파괴적 망각 (Catastrophic forgetting) 현상을 막기 위해, 기존의 가중치가 임계치(Threshold) 이상으로 바뀌었으면, 학습 모델 운영 장치는 기존의 가중치를 복사해서 옆에 붙여 넣어준다. 만약, 선택적 재훈련(Selective Re- training) 방식에서 업데이트할 가중치를 적절히 뽑지 않으면, 분할 및 복제(Split and Duplication) 방식에서 복사해서 추가될 노드가 너무 많아져서 비효율적이거나, 파괴적 망각 현상이 발생할 수 있다. 따라서, 선택적 재훈련(Selective Re-training) 방식에서 적절한 가중치를 선별 과정이 필요하다. 도 9는 본 발명의 일 실시예에 따른 학습 모델 운영 장치의 구성을 나타낸 구성도이다. 도 9에 도시된 바와 같이, 본 발명의 일 실시예에 따른 학습 모델 운영 장치는 데이터베이스, 메모리 및 프로세서를 포함한다. 그러나 도시된 구성요소 모두가 필수 구성요소인 것은 아니다. 도시된 구 성요소보다 많은 구성요소에 의해 본 발명의 일 실시예에 따른 학습 모델 운영 장치가 구현될 수도 있고, 그보다 적은 구성요소에 의해서도 본 발명의 일 실시예에 따른 학습 모델 운영 장치가 구현될 수 있다. 이하, 도 9의 본 발명의 일 실시예에 따른 학습 모델 운영 장치의 각 구성요소들의 구체적인 구성 및 동작 을 설명한다. 데이터베이스는 학습 모델 운영과 관련된 기 학습된 학습 모델, 훈련 데이터, 제1 훈련 데이터 및 제2 훈 련 데이터를 저장한다. 메모리는 학습 모델 운영과 관련된 하나 이상의 프로그램을 저장한다. 프로세서는 메모리에 저장된 하나 이상의 프로그램을 실행한다. 프로세서는 기 훈련 데이터 및 새로운 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별하고, 선별된 적어도 하나의 훈련 데이터를 이용 하여 기 학습 모델을 새롭게 학습시킬 수 있다. 실시예들에 따르면, 프로세서는 기 학습 모델을 통해 선별된 적어도 하나의 훈련 데이터를 평가하고, 선별 된 적어도 하나의 훈련 데이터에서 기설정된 평가 지표의 비율이 가장 높은 훈련 데이터를 선택할 수 있다. 실시예들에 따르면, 프로세서는 기 학습 모델과 새롭게 학습된 학습 모델의 성능을 비교하고, 새롭게 학습 된 학습 모델이 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 미만이면 나머지 선별된 훈련 데이터 를 이용하여 기 학습 모델을 새롭게 학습시키고, 새롭게 학습된 학습 모델이 기 학습 모델의 성능, 정확도 및 속도 중에서 적어도 하나 이상이면 기 학습 모델을 새롭게 학습된 학습 모델로 업데이트할 수 있다. 실시예들에 따르면, 프로세서는 기 훈련 데이터에서 조건적 샘플링을 통해 선별된 제1 훈련 데이터, 새로 운 훈련 데이터에서 기 학습 모델의 액티브 학습(Active learning)으로 라벨링된 제2 훈련 데이터 및 제1 훈련 데이터 및 제2 훈련 데이터를 통합한 통합 훈련 데이터 중에서 적어도 하나의 훈련 데이터를 선별할 수 있다. 실시예들에 따르면, 프로세서는 기 훈련 데이터에서 기설정된 예측 오류값을 초과하는 훈련 데이터를 샘플 링하여 조건적 샘플링 조건을 만족하는 제1 훈련 데이터를 선별할 수 있다. 실시예들에 따르면, 프로세서는 F1 점수(F1-score), 정확도(Accuracy), mAP(mean Average Precision) 및 mIOU(mean Intersection Over Union) 중에서 적어도 하나의 성능 지표를 이용하여 기 학습 모델에서의 특정 훈 련 데이터에 대한 성능을 판단하는 성능 지표값을 산출할 수 있다. 실시예들에 따르면, 프로세서는 새로운 훈련 데이터에서 스코어 모델(Score model)을 통해 불확실 점수를 산출하고 산출된 불확실 점수가 기설정된 임계치를 초과한 새로운 훈련 데이터를 제2 훈련 데이터로 라벨링할 수 있다. 실시예들에 따르면, 프로세서는 메모리 맵핑(Memory Mapping) 방식, 선택적 재훈련(Selective Re- training) 방식, 동적 확장(Dynamic Expansion) 방식 및 분할 및 복제(Split and Duplication) 방식 중에서 어 느 하나의 방식을 이용하여 지속적 학습 동작을 수행할 수 있다. 실시예들에 따르면, 프로세서는 제1 훈련 데이터와 이전 학습시 사용된 이전 훈련 데이터에서 기설정된 비 율만큼 샘플링하여 메모리에 업로드하고 메모리에 라벨링된 제2 훈련 데이터를 통합시키는, 메모리 맵핑 (Memory-mapping) 방식을 이용하여 기학습된 학습 모델을 학습시킬 수 있다. 한편, 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 방법을 실행하게 하는 명령어들을 저장하기 위한 비 일시적 컴퓨터 판독가능 저장 매체로서, 상기 방법은: 기 훈련 데이터 및 새로운 훈련 데이터 중에서 적어도 하 나의 훈련 데이터를 선별하는 단계; 및 상기 선별된 적어도 하나의 훈련 데이터를 이용하여 상기 기 학습 모델 을 새롭게 학습시키는 단계를 포함하는, 비일시적 컴퓨터 판독 가능한 저장 매체가 제공될 수 있다. 한편, 본 발명의 일 실시예에 따르면, 이상에서 설명된 다양한 실시예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개 시된 실시예들에 따른 전자 장치(예: 전자 장치(A))를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있 는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체 가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 또한, 본 발명의 일 실시예에 따르면, 이상에서 설명된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 본 발명의 일 실시예에 따르면, 이상에서 설명된 다양한 실시예들은 소프트웨어(software), 하드웨어 (hardware) 또는 이들의 조합을 이용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우에 있어 본 명세서에서 설명되는 실시예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시예들은 별도의 소프트 웨어 모듈들로 구현될 수 있다. 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 다양한 실시예들에 따른 기기의 프로세싱 동작을 수행하기 위한 컴퓨터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저장될 수 있 다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의해 실행되었 을 때 상술한 다양한 실시예에 따른 기기에서의 처리 동작을 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판 독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반영구적 으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매 체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등이 있을 수 있다. 또한, 상술한 다양한 실시예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는유사하게 수행할 수 있다. 다양한 실시예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작 들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생 략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시예에 한"}
{"patent_id": "10-2022-0148836", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통 상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2022-0148836", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 학습 모델 운영 방법을 나타낸 흐름도이다. 도 2는 본 발명의 일 실시예에 따른 학습 모델 운영 장치의 운영 동작을 나타낸 도면이다. 도 3은 본 발명의 일 실시예에 따른 훈련 데이터 선별 방법을 나타낸 흐름도이다. 도 4는 본 발명의 일 실시예에 따른 학습 모델 운영 방법에서 조건적 샘플링 동작을 나타낸 도면이다. 도 5는 본 발명의 일 실시예에 따른 액티브 학습 동작을 나타낸 도면이다. 도 6은 본 발명의 일 실시예에 적용되는 메모리 맵핑 방식을 나타낸 도면이다. 도 7은 본 발명의 일 실시예에 적용되는 메모리 맵핑 방식의 어그멘테이션 동작을 나타낸 도면이다. 도 8은 본 발명의 일 실시예에 적용되는 동적 확장가능 네트워크를 나타낸 도면이다. 도 9는 본 발명의 일 실시예에 따른 학습 모델 운영 장치의 구성을 나타낸 구성도이다."}
