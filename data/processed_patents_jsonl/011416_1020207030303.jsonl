{"patent_id": "10-2020-7030303", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0133787", "출원번호": "10-2020-7030303", "발명의 명칭": "이동중인 1차 물체의 궤적과 교차할 수 있는 2차 물체들의 고속 검출", "출원인": "로베르트 보쉬 게엠베하", "발명자": "페이페르, 마이클"}}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이동중인 1차 물체(moving primary object)(50)의 궤적(trajectory)(51)과 교차할(intersect) 잠재력이 있는동적 2차 물체들(dynamic secondary objects)(55)을 검출하고(detecting),이벤트-기반 픽셀들(event-based pixels)(21)을 포함하는 광-민감 영역(light-sensitive area)(20)이 있는 비전 센서(vision sensor)(2)를 포함하여, 상기 비전 센서(2)의 이벤트-기반 픽셀(21)에 적어도 미리 결정된 백분율(predetermined percentage)만큼 영향을 미치는(impinging onto) 상기 광 강도(light intensity)의 상대적인 변화(relative change)로 인해 상기 비전 센서(2)가 상기 이벤트-기반 픽셀(21)과 관련된 이벤트(event)(21a)를 방출하는 시스템(1)에 있어서,상기 시스템(1)은,상기 비전 센서(2)로부터 상기 이벤트들(21a)의 스트림(stream)과 상기 1차 물체(50)의 모션의 방향 및/또는 속도에 대한 정보(52)를 둘다 입력들로 획득하고, 상기 정보(52)에 적어도 부분적으로 기초하여 상기 1차 물체(50)의 모션에 의해서보다는 상기 2차 물체(55)의 모션에 의해 야기될 가능성이 있는 이벤트들(21b)을 상기 이벤트들(21a)의 스트림으로부터 식별하도록 구성되는 판별 모듈(discriminator module)(3);을 추가 포함하는,시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 판별 모듈(3)은,상기 비전 센서(2)의 시야(field of view)(23)에 미리 결정된 시간 프레임(predetermined time frame) 내에 방출되는 미리 결정된 수 이상(more than a predetermined number)의 이벤트들(21a)을 발생시키는 제한 영역(restricted region)(23a)이 존재한다는 결정에 응답하여, 상기 영역(23a)과 관련된 상기 이벤트들(21a)을 상기 2차 물체(55)의 모션에 의해 야기되는 이벤트들(21b)로 식별하도록 추가 구성되는, 시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항 또는 제 2 항에 있어서,상기 판별 모듈(3)은,상기 이벤트들(21a)의 스트림이 적어도 하나의 특정 방향(21d)으로 일관되게 이동하는 상기 비전 센서의 상기시야(23)에 있는 위치들(A, B, C)에 관련된 이벤트들(21a)의 시퀀스(21c)를 포함한다는 결정에 응답하여,상기 특정 방향(21d)이 상기 1차 물체(50)의 모션과 일치하지 않는 경우 상기 시퀀스(21c) 내의 상기 이벤트들(21a)을 상기 2차 물체(55)의 모션에 인해 야기되는 이벤트들(21b)로 식별하도록 추가 구성되는, 시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 1차 물체(50)의 모션은 하나 이상의 정적 물체들(static objects)에 대한 상기 1차 물체(50)의 모션인, 공개특허 10-2020-0133787-3-시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항 또는 제 4 항에 있어서,상기 판별 모듈(3)은,상기 특정 방향(21d)을 상기 1차 물체(50)의 상기 궤적(51)과 비교하고, 상기 특정 방향(21d)이 상기 1차 물체(50)의 상기 궤적(51)과 교차하는 경우에만, 상기 시퀀스(21c) 내의 상기 이벤트들(21a)을 상기 2차 물체의 모션에 의해 야기되는 이벤트들(21b)로서 식별하도록 추가 구성되는, 시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항 내지 제 5 항 중 어느 한 항에 있어서,상기 시스템(1)은,상기 판별 모듈(3)이 상기 2차 물체(55)의 모션에 의해 야기되는 이벤트들(21b)로서 식별되던 이벤트들(21a)로부터, 및/또는 상기 식별된 이벤트들(21b)을 발생시킨 상기 비전 센서(2)의 상기 시야(23) 내의 영역(23a, 23b)에 관련된 이미지 정보(22b)로부터, 상기 2차 물체(55)를 다수 카테고리들(41a-41c) 중 적어도 하나로 분류하도록 구성되는 분류 모듈(classifier module)(4);을 추가 포함하는,시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 분류 모듈(4)은, 입력 정보(input information)의 학습 샘플들(learning samples) 및 원하는 분류 결과들(41a-41c)의 대응하는학습 샘플들을 사용하여 훈련 가능하고(trainable)/하거나 훈련된 인공 지능 모듈(artificial intelligencemodule), 컴퓨터 비전 모듈(computer vision module) 및/또는 통계 분류 모듈(statistical classifier module)을 포함하는,시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 인공 지능 모듈은,식별된 이벤트들(21b)의 스트림을 입력으로 직접 수신하도록 구성되는 스파이킹 신경망(spiking neuralnetwork)을 포함하는, 시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 6 항 내지 제 8 항 중 어느 한 항에 있어서,상기 분류 모듈(4)은,상기 비전 센서(2)의 상기 시야(23)에서 상기 분류된 2차 물체(55)의 상기 위치(55a)를 결정하도록 구성되는 추적 모듈(tracker module)(6)에 통신 가능하게 결합되는, 시스템(1).공개특허 10-2020-0133787-4-청구항 10 제 9 항에 있어서,상기 추적 모듈(6)은,상기 판별 모듈(3)에 통신 가능하게 결합되고, 상기 분류된 2차 물체(55)의 상기 위치(55a)를 상기 판별 모듈(3)로 피드백 하도록 구성되는, 시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항 내지 제 10 항 중 어느 한 항에 있어서,상기 시스템(1)은, 상기 2차 물체(55)의 존재가 검출되는 것에 응답하여 및/또는 2차 물체(55)가 미리 결정된 카테고리(41a-41c)로분류되는 것에 응답하여, 상기 시스템(1)의 사용자가 들을 수 있거나 볼 수 있는 경보를 물리적으로 방출하도록 구성되는 경보 장치(alarm device)(7);를 추가 포함하는, 시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1 항 내지 제 11 항 중 어느 한 항에 있어서,상기 시스템(1)은, 1차 물체(50)로 기능하는 육상 또는 항공 차량의 동력 전달 장치(power-train), 제동 시스템(braking system)및/또는 조향 시스템(steering system)에 통신 가능하게 연결된 완화 모듈(mitigation module)(8);을 추가 포함하고,상기 완화 모듈(8)은,상기 2차 물체(55)의 존재가 검출되는 것에 응답하여 및/또는 2차 물체(55)가 미리 결정된 카테고리(41a-41c)로분류되는 것에 응답하여, 상기 동력 전달 장치, 상기 제동 시스템 및/또는 상기 조향 시스템을 작동시켜 1차 물체(50)로서 작용하는 상기차량과 상기 2차 물체(55)의 충돌을 방지하도록 구성되는, 시스템(1)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 1 항 내지 제 11 항 중 어느 한 항에 따른 시스템(1)에 사용되고, 개별 픽셀들(individual pixels)(21, 22)로 분할되는 광-민감 영역(light-sensitive area)(20)을 포함하고, 각각의 픽셀(21, 22)은 광 강도 및/또는 광 강도의 변화를 전기 신호로 변환하도록 구성되는 검출기(detector)에 연결되고,상기 픽셀들(21, 22)의 제1비-제로 부분(first nonzero fraction)은 이벤트-기반 픽셀(event-based pixel)(21)로 구성되어, 이벤트-기반 픽셀(21)에 적어도 미리 결정된 백분율(predetermined percentage)만큼 영향을 미치는(impinging onto) 상기 광 강도의 상대적인 변화로 인해, 상기 비전 센서(2)는 상기 픽셀(21)과 관련된 이벤트(21a)를 방출하게 하고(emit),상기 픽셀들(21, 22)의 제2비-제로 부분(second nonzero fraction)은 이미지 픽셀들(image pixels)(22)로 구성되어 상기 비전 센서(2)는 상기 이미지 픽셀들(22)의 강도 값들(intensity values)(22a)로 구성되는 이미지공개특허 10-2020-0133787-5-(22b)를 제공하는, 비전 센서(2)에 있어서,상기 이벤트-기반 픽셀들(21)의 로컬 밀도(local density) 및 상기 이미지 픽셀들(22)의 로컬 밀도 사이의 비율은 상기 광-민감 영역(20)의 중앙부(20a)로부터 상기 광-민감 영역의 경계(20b, 20d)까지의 경로 상에서 증가하는(increase), 비전 센서(2)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 광-민감 영역(20)의 상기 중앙부(20a)는 실질적으로 이미지 픽셀들(22)만을 포함하고,상기 광-민감 영역(20)의 경계(20b, 20d)에 인접한 적어도 하나의 경계부(20c, 20e)는 실질적으로 이벤트-기반픽셀들(21)만을 포함하는, 비전 센서(2)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 1 항 내지 제 11 항 중 어느 한 항에 따른 시스템(1)에 사용되고, 개별 픽셀들(individual pixels)(21, 22)로 분할되는 광-민감 영역(light-sensitive area)(20)을 포함하며,각각의 픽셀(21, 22)은 광 강도 및/또는 광 강도의 변화를 전기 신호로 변환하도록 구성되는 검출기(detector)에 연결되고,상기 픽셀들(21, 22)의 제1비-제로 부분(first nonzero fraction)은 이벤트-기반 픽셀(21)로 구성되어 이벤트-기반 픽셀(21)에 적어도 미리 결정된 백분율만큼 영향을 미치는 상기 광 강도의 상대적인 변화로 인해 상기 비전 센서(2)는 상기 픽셀(21)과 관련된 이벤트(21a)를 방출하게 하고,상기 픽셀들(21, 22)의 제2비-제로 부분(second nonzero fraction)은 이미지 픽셀들(22)로 구성되어 상기 비전센서(2)는 상기 이미지 픽셀들(22)의 강도 값들(22a)로 구성되는 이미지(22b)를 제공하는, 비전 센서(2)에 있어서,상기 광-감도 영역(20)에서, 이벤트-기반 픽셀들(21)은 일정한 비율(constant ratio)로 이미지 픽셀들(22)과 인터리빙되는(interleaved), 비전 센서(2)."}
{"patent_id": "10-2020-7030303", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "컴퓨터(computer) 및/또는 제어 유닛(control unit)에 의해 실행될 때, 상기 컴퓨터 및/또는 상기 제어 유닛에제 1 항 내지 제 12 항 중 어느 한 항에 따른 시스템(1) 또는 판별 모듈(3)의 기능을 제공하거나, 상기 컴퓨터 및/또는 상기 제어 유닛은 상기 비전 센서(2)가 제 13 항 내지 제 15 항 중 어느 한 항에 따른 비전 센서(2)가 되는 방식으로 비전 센서(2)를 작동시키는, 머신-판독가능 명령어(machine-readableinstructions)를 포함하는,컴퓨터 프로그램(computer program)."}
{"patent_id": "10-2020-7030303", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이동중인 1차 물체(moving primary object)의 궤적(trajectory)과 교차할(intersect) 잠재력이 있는 동 적 2차 물체들(dynamic secondary objects)을 검출하고(detecting), 이벤트-기반 픽셀들(event-based pixels)을 포함하는 광-민감 영역(light-sensitive area)이 있는 비전 센서(vision sensor)를 포함 (뒷면에 계속)"}
{"patent_id": "10-2020-7030303", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이동중인 1차 물체(moving primary object)와 충돌할 수 있는 2차 물체들(secondary objects)을 가 급적 빨리 검출하여, 경고를 발령하거나 충돌 방지 조치를 취할 수 있는 시스템에 관한 것이다."}
{"patent_id": "10-2020-7030303", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "과거 도로 사고들(road accidents)을 분석한 결과, 충돌 회피 조치(collision avoiding action)가 충분히 이뤄 지지 않아, 상기 사고들이 발생했던 비율이 상당 부분인 것으로 나타났다. 시간이 조금만 더 있었다면, 많은 경 우에 1 초도 걸리지 않고, 사고를 피할 수 있었을 것이다. 이러한 중요한 시간을 확보하기 위해, 자동 비상 브레이크 보조 장치들(automatic emergency brake assistants)이 개발되었다. 이들 보조 장치들은, 이동 차량(moving vehicle)이 충돌할 수 있는 물체들을 빠르고 안정적으로 검출해야 한다. 상기 차량의 불필요한 비상 제동(needless emergency braking)은 뒤따르는 운전자들 에게 놀라움으로 다가올 수 있고, 후방 추돌(rear-end collision)을 유발할 수 있으므로, 거짓 양성들(false positives)을 피해야 한다. 그러나 상기 처리가 더 정교하다면(sophisticated), 너무 오래 걸릴 수도 있다. 비전 센서(vision sensor)로 시각 정보(visual information)를 수집하는데 시간이 절약될 수 있다. 기존 비전 센서들은 이미지 프레임들(image frames)을 출력한다. 이들 센서들을 사용하여 획득 가능한 검출 속도 (detection speed)는 초당 프레임들 속도(rate of frames per second)의 함수이며, 대량의 이미지 데이터를 처 리하는데 사용할 수 있는 처리 대역폭(processing bandwidth)의 함수이다. US 2016/096 477 A1은 이벤트-기반 광 감지 소자들(event-based photosensing elements)로 종래 비전 센서를 보강할 것을 제안한다. 이러한 이벤 트-기반 광 감지 소자에 영향을 미치는(impinging on) 상기 광 강도(light intensity)가 특정 상대 량 이상 변 경될 때마다, 상기 센서는 즉시 대응하는 이벤트(event)를 방출한다(emit). 다음 이미지 프레임(next image frame)의 획득을 기다릴 필요가 없다."}
{"patent_id": "10-2020-7030303", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명자들은 이동중인 1차 물체(moving primary object)의 궤적과 교차할 가능성이 있는 동적 2차 물체들 (dynamic secondary objects)을 검출하기 위한 시스템을 개발했다. 상기 이동중인 1차 물체는, 예를 들어, 일반 승용차(normal passenger car), 적어도 부분적으로 자율-주행차(self-driving car), 다용도 차량(utility vehicle), 철도 차량(railway vehicle), 무인 항공기(unmanned aerial vehicle)(\"드론\"), 작업 또는 감시를 수 행하기 위해 돌아다니는 로봇(robot), 또는 직원이 피해야 하는 위험 영역으로 둘러싸인 산업용 로봇(industry robot)과 같은 유인(manned) 또는 무인(unmanned) 육상 또는 항공 차량일 수 있다. 상기 이동중인 1차 물체는 또한, 예를 들어, 증강 현실(augmented reality)을 그 사용자에게 전달하는 장치와 같이, 사람이 착용할 수 있 는(wearable) 장치일 수 있다. 상기 시스템은 이벤트-기반 픽셀들(event-based pixels)로 구성되는 광-민감 영역(light-sensitive area)이 있 는 비전 센서(vision sensor)를 포함하고, 이에 따라 적어도 미리 결정된 백분율만큼 상기 비전 센서의 이벤트- 기반 픽셀에 영향을 미치는 상기 광 강도(light intensity)의 상대적 변화(relative change)로 인해 상기 비전 센서가 이러한 이벤트-기반 픽셀과 관련된 이벤트를 방출한다. 상기 시스템은 상기 비전 센서로부터 상기 이벤트들(events)의 스트림(stream)과 상기 1차 물체의 모션(motio n)의 방향(heading) 및/또는 속도(speed)에 대한 정보를 입력들로 획득하는 판별 모듈(discriminator module) 을 추가 포함한다. 이러한 정보에 적어도 부분적으로 기초하여, 상기 판별 모듈은 상기 이벤트들의 스트림으로 부터 상기 1차 물체의 모션에 의해서가 아니라 상기 2차 물체의 모션에 의해 발생할 가능성이 있는 이벤트들을 식별할 수 있다. 상기 1차 물체의 모션의 상기 방향 및/또는 속도에 대한 상기 정보는 임의의 적절한 방식으로 획득할 수 있다. 예를 들어, 차량에서 다른 차량 제어 시스템들(other vehicle control systems)에 사용되는 기존 가속 센서들 (existing acceleration sensors)의 데이터는 CAN 버스 또는 다른 버스를 통해 액세스할 수 있다. 또한, 속도 계 정보(speedometer information)와 상기 조향 각도(steering angle)는 이러한 버스를 통해 액세스할 수 있다. 사용자가 착용할 수 있는 장치에서는 기울기 센서들(tilt sensors), 가속도계들(accelerometers), GPS와 같은 센서들이 사용될 수 있다. 본 발명가들은 상기 1차 물체 자체의 모션이 많은 이벤트들을 생성한다는 것을 발견했다. 상기 비전 센서의 상 기 시야에 대비가 풍부한 정적 물체(contrast-rich static object)가 있는 경우, 상기 1차 물체의 상기 모션으로 인해 이러한 물체는 이러한 시야를 돌아다니며, 이벤트들의 스트림을 트리거한다. 그러나 정상적인 상황들에 서, 이러한 정적 물체는 상기 1차 물체의 상기 궤적과 교차하지 않을 것이다. 즉, 운전자는 일반적으로 이러한 물체로 운전하지 않을 것이다. 따라서 정적 물체들에 의해 야기되는 이벤트들은 당면한 작업과 관련이 없다. 즉, 상기 시야에 빠르고 놀랍게도 들어오는 물체들을 검출한다. 상기 2차 물체의 모션으로 인해 야기되는 그들 이벤트를 식별하면, 상기 1차 물체의 상기 모션으로 인해 야기되는 많은 이벤트들을 안전하게 무시할 수 있다. 그런 다음 상기 데이터 전송 대역폭 및 처리 기능들은 더 중요한 상기 식별된 이벤트들에 집중할 수 있다. 또한 예기치 않은 비상 제동 이벤트들을 초래할 수 있는 잘못된 검출들의 가능성이 감소된다. 특히 유리한 실시 예에서, 상기 판별 모듈은 미리 결정된 시간 프레임 내에 방출되는 미리 결정된 수 이상의 이 벤트들을 발생시키는 상기 비전 센서의 상기 시야에 제한된 영역(restricted region)이 있다는 결정에 응답하여, 이러한 영역과 관련된 상기 이벤트들을 상기 2차 물체의 모션으로 인해 야기되는 이벤트들로 식별하 도록 추가 구성된다. 상기 1차 물체의 모션으로 인해 상기 비전 센서의 전체 시야가 움직이기 때문에, 이러한 모션에 의해 생성된 상기 이벤트들은 이러한 시야에 다소 흩어져 있을 것이다. 이와는 대조적으로, 물체가 예기 치 않게 상기 시야에 들어오면, 상기 대응하는 이벤트들이 작은 영역에 집중될 것이다. 강력한 텍스처링된 정적 물체(strongly textured static object)가 이벤트 활동들이 높은 영역들을 만드는 경우 가 있을 수 있지만, 그러한 활동 피크들은 주어진 기간 동안 상기 시야에 남아, 예측 가능한 궤적을 따라 이동 하므로 예기치 않게 진입하는 물체와 구별된다. 특히, 더욱 특별하게 유리한 실시 예에서, 상기 판별 모듈은 상기 이벤트들의 스트림이 적어도 하나의 특정 방 향으로 일관되게 주행하는 상기 비전 센서의 상기 시야에 있는 위치들에 관련된 이벤트들의 시퀀스를 포함한다 는 결정에 응답하여, 상기 특정 방향이 상기 1차 물체의 모션과 일치하지 않는 경우 상기 시퀀스 내의 상기 이 벤트들을 상기 2차 물체의 모션에 인해 야기되는 이벤트들로 식별하도록 추가 구성된다. 예를 들어, 도로변 (curbside)에 대비가 풍부한 자동차들(contrast-rich cars)이 주차되어 있다면, 상기 시야를 통한 대응하는 이 벤트들의 모션은 1차 물체 역할을 하며 상기 시스템에 맞는 상기 자동차의 모션과 일치한다. 그러나 상기 주차 된 자동차들 사이의 공간을 지나 도로로 걸어가는 보행자는 상기 1차 물체의 모션에 수직인 방향으로 이동하는 이벤트들의 시퀀스를 생성한다. 추가적인 유리한 실시 예에서, 상기 판별 모듈은 상기 시퀀스 내의 상기 이벤트들이 이동하는 특정 방향을 상기 1차 물체의 상기 궤적과 비교하고, 상기 특정 방향이 상기 1차 물체의 상기 궤적과 교차하는(intersect) 경우에 만 상기 2차 물체의 모션에 의해 야기되는 이벤트들로서 상기 시퀀스 내의 상기 이벤트들을 식별하도록 추가 구 성된다. 예를 들어, 보행자가 상기 도로변에 움직이지 않는 동안 팔을 흔들거나 도로에서 포장 도로를 걸어 가 면, 상기 도로 상에서 1차 물체의 궤적과 교차할 위험이 없다. 따라서 이러한 보행자를 검출한다고 해서 비상 제동이 발생하는 것은 아니다. 더욱 특별하게 유리한 실시 예에서, 상기 시스템은 상기 판별 모듈이 상기 2차 물체의 모션에 의해 야기되는 이 벤트들로서 식별되던 이벤트들로부터, 및/또는 상기 식별된 이벤트들을 발생시킨 상기 비전 센서의 상기 시야 내의 영역에 관련된 이미지 정보로부터 상기 2차 물체를 다수 카테고리들 중 적어도 하나로 분류하도록 구성되 는 분류 모듈(classifier module)을 추가 포함한다. 상기 분류 모듈이 상기 이벤트들을 직접 처리하는 경우, 상 기 2차 물체의 모션으로 인해 발생하지 않는 이벤트들을 선택적으로 컬링하면(culling), 처리될 이벤트들의 수 가 크게 감소된다. 상기 분류 모듈이 상기 이벤트들과 관련된 영역에 대한 이미지 정보를 처리하면, 이러한 영 역은 전체 시야의 전체 이미지 크기에 비해 작아지므로 처리해야 하는 이미지 정보가 훨씬 적다. 어느 쪽이든 관련성이 낮은 정보를 컬링하면 분류 속도가 빨라지고 잘못된 분류들의 위험도 줄어 든다: 처음에 분류되지 않 은 것은 잘못 분류될 수 없다. 더욱 특별하게 유리한 실시 예에서, 상기 분류 모듈은, 입력 정보의 학습 샘플들 및 원하는 분류 결과들의 대응 하는 학습 샘플들을 사용하여 훈련 가능하고/하거나 훈련된 인공 지능 모듈(artificial intelligence module), 컴퓨터 비전 모듈(computer vision module) 및/또는 통계 분류 모듈(statistical classifier module)을 포함한 다. 예를 들어, 상기 인공 지능 모듈은 신경망(neural network)을 포함할 수 있다. 상기 시스템에는 유리한 업 무(duties) 분리가 있다: 상기 판별 모듈은 잠재적으로 관련성이 있는 방식으로 이동하는 \"무엇\"을 검출하는데 전적으로 책임이 있는 반면, 상기 분류 모듈은 이러한 \"무엇\"이 무엇인지를 결정하는데 전적으로 책임이 있다. 이는 기존 분류 모듈을 수정 없이 사용할 수 있음을 의미한다: 상기 분류 모듈은 상기 판별 모듈이 앞에 추가될 수 있다. 훈련 가능한 분류 모듈에 대한 수정은 상기 모듈의 적어도 부분적인 재-학습을 수반할 수 있다. 이러 한 학습은 일반적으로 시간과 비용이 많이 든다. 예를 들어, 어떤 물체들을 포함하는지 이미지들을 분류하는데사용되는 분류 모듈들은 수십만개의 학습 이미지들과 대응하는 원하는 분류 결과들로 학습될 수 있다. 또한 상 기 분류 모듈은 공공 교통(public traffic)에서 사용하기 위한 공식 인증(official certification)을 이미 보 유할 수 있고, 수정 시 이러한 인증이 무효화될 수 있다. 현재의 업무 분리를 통해 이러한 문제를 피할 수 있고, 상기 시스템 전체(상기 판별 모듈 포함)의 인증이 용이 해진다. 바람직하게는, 상기 인공 지능 모듈은 식별된 이벤트들의 스트림을 입력으로 직접 수신하도록 구성된 스파이킹 신경망(spiking neural network)을 포함한다. 다음 이미지 프레임이 상기 비전 센서에 의해 전달되기 전에 이미 상기 이벤트들의 스트림이 분류에 충분할 수 있기 때문에, 상기 분류 속도가 더욱 빨라진다. 또한, 이벤트들의 시퀀스로서의 2차 물체의 표현은 이미지 정보로서의 표현에 비해 고도로 압축된 데이터 세트(highly compressed data set)일 수 있다. 상기 분류 모듈이 이벤트들을 입력으로 처리하는 경우, 예를 들어, 특정 기간 동안 특정 지역의 모든 이벤트들 을 처리할 수 있다. 상기 이벤트들은 추가 정보, 예를 들어, 옵티컬 플로우(optical flow)를 제공하기 위해 전 처리될 수 있거나, 평균 이벤트 활동의 프레임을 생성하기 위해 주어진 시간에 걸쳐 처리될 수 있다. 상기 분류 모듈이 이미지 정보를 입력으로 처리하면, 상기 식별된 이벤트들의 상기 위치들은, 예를 들어, 상기 이벤트들에 대응하는 상기 이미지 정보를 획득하기 위해 별도의 이미징 센서의 좌표들로 변환될 수 있다. 예를 들어, 하나의 동일한 비전 센서는 충분히 큰 상대 강도 변화 시 즉시 이벤트를 생성하는 종래의 이미지 및 이벤 트-기반 픽셀들에 기여하는 이미지 픽셀들의 인터리빙된 혼합물을 포함한다면, 이러한 변환은 저장될 수 있다. 운전 지원 시스템(driving assistance system)에서, 상기 분류 모듈의 역할은 일반적으로 상기 판별 모듈에서 잠재적으로 위험한 것으로 식별된 2차 물체의 정확한 특성(exact nature)을 결정하는 것이다. 여기에는 물, 눈, 그림자들 또는 낙엽들과 같은 상기 1차 물체의 상기 궤적과 교차할 때 해를 끼치지 않는 물체들 및 실제로 위험 하지 않은 (가령, 관련 없는 검출들) 2차 물체들을 식별하는 것이 포함된다. 더욱 특별하게 유리한 실시 예에서, 상기 분류 모듈은 상기 비전 센서의 상기 시야에서 상기 분류된 2차 물체의 상기 위치를 결정하도록 구성되는 추적 모듈(tracker module)에 통신적으로 결합된다. 일단 물체들이 상기 비전 센서의 상기 시야에 들어오면 주어진 시간 동안 거기에 유지된다. 그것들을 반복해서 감지하고 분류하는 대신, 앞서 확인된 해당 지역의 내부 및 주변 이벤트들로 표시된 상기 이동 방향을 사용하여 시간이 지남에 따라 원활 하게 추적하는 것이 경제적이다. 위치들이 변경되는 순간에 이벤트들이 생성되기 때문에, 새로운 이미지 프레임 에서 동일한 물체를 찾는 것보다 작은 시프트들(small shifts)만 수행하면 된다. 추적은 전체 물체가 아닌 물체 의 일부(가령, 보행자의 다리 또는 팔)에도 적용될 수 있다. 상기 추적 모듈은 상기 판별 모듈에 통신 가능하게 결합(communicatively coupled)될 수 있고, 상기 분류된 2차 물체의 상기 위치를 상기 판별 모듈로 피드백 하도록 구성될 수 있다. 이를 통해 상기 분류 모듈을 통해 얻은 정보를 재-사용하여 관련성이 낮은 이벤트들의 초기 컬링을 미세 조정할 수 있다. 예를 들어, 물체가 위험하지 않은 것으로 분류된 경우, 이러한 물체의 추가 모션으로 인해 야기되는 모든 후속 이벤트들이 선별될(culled) 수 있다. 또한 관련 물체들이 이미 추적되고 있다면 더 이상 상기 판별 모듈에 놀라지 않는다. 예를 들면, 갑작 스럽고 예기치 않게 상기 비전 센서의 시야에 들어왔을 수 있는 새로운 물체들이 상기 1차 물체와 충돌할 가능 성이 가장 높기 때문에, 상기 물체들의 처리에 최우선 순위(top priority)가 부여될 수 있다. 더욱 특별하게 유리한 실시 예에서, 상기 시스템은, 상기 2차 물체의 존재가 검출되는 것에 응답하여 및/또는 2 차 물체가 미리 결정된 카테고리로 분류되는 것에 응답하여, 상기 시스템의 사용자가 들을 수 있거나 볼 수 있 는 경보를 물리적으로 방출하도록 구성되는 경보 장치(alarm device)를 추가 포함한다. 예를 들어, 걷는 사람이나 상기 차량 운전자에게 새로운 2차 물체를 주의하도록 경고하는 경보가 울릴 수 있다. 증강 현실을 제공하는 헤드-업 디스플레이 또는 기타 장치에서는, 시야에서 2차 물체가 검출되었던 영역이 강조 표시될(highlighted) 수 있다. 상기 2차 물체가 분류되었던 경우 이러한 분류 결과도 알람에 포함될 수 있다. 더욱 특별하게 유리한 실시 예에서, 상기 시스템은, 1차 물체로 기능하는 육상 또는 항공 차량의 동력 전달 장 치(power-train), 제동 시스템(braking system) 및/또는 조향 시스템(steering system)에 통신 가능하게 연결 된 완화 모듈(mitigation module)을 추가 포함한다. 상기 완화 모듈은 상기 2차 물체의 존재가 감지되는 것에 응답하여 및/또는 2차 물체가 미리 결정된 카테고리로 분류되는 것에 응답하여, 상기 동력 전달 장치, 상기 제 동 시스템 및/또는 상기 조향 시스템을 작동시켜 1차 물체로서 작용하는 상기 차량과 상기 2차 물체의 충돌을 방지한다. 상기 2차 물체들의 검출에 대한 이러한 자동 반응을 통해 상기 불가피한 인간 반응 시간(inevitable human reaction time)을 상기 루프에서 줄일 수 있다. 동시에 상기 반응은 검출된 상기 2차 물체의 구체적 유형과 적 절하게 일치할 수 있다. 예를 들어, 후방 추돌(rear-end collision)을 야기할 위험이 없도록, 작은 동물(small animal)을 검출하는 것에 응답하여 상기 자동차의 비상 제동을 일으키는 것은 바람직하지 않을 수 있다. 그러나 상기 2차 물체가 사람(human)이거나 충돌 시 상기 차량에 상당한 손상을 줄 수 있는 더 큰 동물(larger animal) 인 경우, 상기 차량을 긴급 제동해야 한다. 버스들 또는 기차들과 같은 대중 교통 차량들에도 유사한 고려 사항 이 적용되며, 갑작스러운 제동 이벤트 또는 회피 기동으로 서있는 승객들에게 부상을 입힐 수 있고, 이것은 잠 재적인 충돌의 위험과 저울질 되어야 한다. 상기 비전 센서의 상기 \"시야(field of view)\"와 이러한 시야에 갑자기 \"들어가는(entering)\" 물체들에 대해 말 할 때, 이들 용어는 빛이 원칙적으로 상기 비전 센서에 도달할 수 있는 영역의 상기 물리적 차원에 제한되지 않 는다. 오히려 상기 \"시야\"는 상기 비전 센서가 현재 상황과 조건들에 따라 이벤트들이나 물체들을 검출할 수 있 는 영역으로 광범위하게 해석되어야 한다. 예를 들어, 도로변에 주차된 자동차들과 해당 자동차들 사이를 걷는 보행자의 언급된 예에서, 정적 물체(static object)에 의해 가려진(obscured) 영역은 상기 비전 센서가 해당 영 역에서 일어나는 어떤 일에도 반응하지 않기 때문에 해당 상황에서 상기 \"시야\"의 일부를 형성하지 않는다. 또 한 야간에 상기 \"시야\"는 이벤트들이나 물체들을 등록하기에 충분한 조명(sufficient lighting)이 가능한 그들 영역으로 제한될 수 있다. 예를 들어, 정지된 조명이 설치되지 않은 도로를 주행할 때, 상기 \"시야\"는 상기 차 량 헤드라이트(vehicle's headlights)가 비추는 영역으로 제한되며, 이는 다시 하향 등(low-beam) 또는 상향 등 (high-beam)이 현재 사용 중인지 여부에 따라 달라진다. 예를 들어, 상기 차량이 처음에 하향 등에 있었다가 상 기 운전자가 다가오는 운전자를 눈부시게 하지 않는 상황에서 나중에 상향 등으로 전환하는 경우, 상기 상향 등 의 범위가 증가하면 새로운 물체들이 갑자기 눈에 띄게 되어, 그 순간 상기 비전 센서의 상기 시야에 들어갈 수 있다. 본 발명은 또한 전술한 시스템에서 사용하기 위한 비전 센서(vision sensor)의 제1실시 예를 제공한다. 이러한 비전 센서는 개별 픽셀들(individual pixels)로 분할된 광-민감 영역(light-sensitive area)을 포함하고, 각 픽셀은 광 강도 및/또는 광 강도의 변화를 전기 신호로 변환하도록 구성되는 검출기(detector)에 연결된다. 상 기 픽셀들의 제1비-제로 부분(first nonzero fraction)은 이벤트-기반 픽셀(event- based pixels)로 구성되어 이벤트-기반 픽셀에 영향을 미치는 상기 광 강도의 상대적인 변화로 인해 상기 비전 센서는 적어도 미리 결정된 백분율만큼 상기 픽셀과 관련된 이벤트를 방출한다. 상기 픽셀들의 제2비-제로 부분(second nonzero fraction) 은 이미지 픽셀들(image pixels)로 구성되어, 상기 비전 센서는 상기 이미지 픽셀들의 강도 값들로 구성되는 이 미지를 제공한다. 상기 이벤트-기반 픽셀들의 로컬 밀도(local density) 및 상기 이미지 픽셀들의 로컬 밀도 사 이의 비율은 상기 광-민감 영역의 중앙부로부터 상기 광-민감 영역까지의 경로 상에서 증가한다. 본 발명가들은 이것이 육로 또는 항공 교통에서 차량 또는 로봇을 항해하기(navigating) 위해 특별히 두 유형의 센서들의 장점을 최적으로 결합한다는 것을 발견했다. 대부분의 상황에서 상기 광-민감 영역의 상기 중앙부에 해당하는 상기 시야의 상기 중앙 영역에는 상기 시스템에 이미 알려진 물체들이 포함된다. 이들 물체들과 관련 하여, 그들의 행동이 어떻게 변하는지 추적하는 것이 바람직하다. 이미 알려진 물체들로 인해 즉각적인 위험이 발생하지 않기 때문에, 가능한 최대 속도로 정보를 얻는 것보다 정확한 정보를 얻는 것이 더 중요하다. 이러한 점에서, 상기 광-민감 영역의 상기 중앙부에 더 높은 밀도의 이미지 픽셀들을 가지는 것이 유리하다. 반면에, 갑자기 그리고 예기치 않게 상기 시야에 들어오는 새로운 물체들은 어느 시점에서 상기 시야의 경계 영역 (boundary area)을 가로질러 이동할 가능성이 매우 높다. 따라서, 상기 비전 센서의 상기 광-민감 영역의 대응 하는 경계부에 더 많은 이벤트-기반 픽셀들을 가지는 것이 유리하다. 상기 이벤트-기반 픽셀들을 사용하면 가능 한 최대 속도로 어딘 가에 적어도 일부 물체의 존재를 등록할 수 있다. 따라서, 가장 바람직하게는 상기 광-민감 영역의 상기 중앙부는 실질적으로 이미지 픽셀들만을 포함하고, 상기 광-민감 영역의 경계에 인접한 적어도 하나의 경계부는 실질적으로 이벤트-기반 픽셀들만을 포함한다. 실질적으로 이미지 픽셀들만 있는 상기 중앙부는, 예를 들어, 실질적으로 이벤트-기반 픽셀들만 있는 상기 경계 부에 인접하여, 둘 사이에 급격한 전이(sharp transition)가 있을 수 있다. 그러나 상기 전이는 점진적일 수도 있다. 후자는 급격한 전이에서 발생할 수 있는 아티팩트들(artifacts)을 감소시킨다. 이미지 픽셀들과 이벤트- 기반 픽셀들이 모두 존재하는 영역에서는 두 가지 유형들의 픽셀들이 모두 인터리빙될(interleaved) 수 있다. 본 발명은 또한 상기 비전 센서의 제2실시 예를 제공한다. 본 실시 예에서, 상기 제1실시 예와 비교하여, 상기 광-민감 영역에서, 이벤트-기반 픽셀들은 일정한 비율로 이미지 픽셀들과 인터리빙된다. 이것은 상기 이벤트들 의 획득과 이미지들의 획득이 정확히 동일한 공간 해상도((same spatial resolution))에서 일어난다는 이점을제공한다. 특히, 2차 물체들이 처음에 그들의 모션 원인에 기초하여 검출되었지만, 이들 이벤트가 발생한 지역 의 이미지 정보에 기초하여 분류된 경우, 좌표 변환(coordinate translation)이나 크기 조정(scaling)이 필요하 지 않다. 상기 시스템의 일부 또는 모든 기능, 특히 상기 판별 모듈은 소프트웨어(software)로 구현될 수 있다. 또한 비 전 센서는 작동 방식에 따라 이벤트-기반 픽셀들 또는 이미지 픽셀들로 작동할 수 있는 개별 픽셀들(individual pixels)을 가질 수 있다. 따라서, 상기 비전 센서의 상기 광-민감 영역에서 상기 이벤트-기반 픽셀들과 상기 이 미지 픽셀들이 분포하는 상기 패턴은 소프트웨어에서도 구현될 수 있다. 예를 들어, 상기 소프트웨어는 기존 검 출 시스템에 대한 추가 기능, 업데이트 또는 업그레이드로 판매될 수 있다. 따라서 본 발명은 또한 컴퓨터 (computer) 및/또는 제어 유닛(control unit)에 의해 실행될 때 상기 컴퓨터 및/또는 상기 제어 유닛에 본 발명 이 제공하는 시스템 또는 판별 모듈의 기능을 제공하거나, 상기 컴퓨터 및/또는 상기 제어 유닛은 비전 센서가 본 발명에 의해 제공되는 비전 센서가 되는 방식으로 비전 센서를 작동시키도록 하는 머신-판독가능 명령어 (machine-readable instructions)를 가지는 컴퓨터 프로그램(computer program)에 관한 것이다. 본 발명은 또 한 비-일시적 저장 매체 또는 상기 컴퓨터 프로그램을 구비한 다운로드 제품에 관한 것이다."}
{"patent_id": "10-2020-7030303", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 시스템의 예시 적인 실시 예를 보여준다. 측정 데이터의 물리적 수집은 광-민감 영역(light- sensitive area)을 가지는 비전 센서(vision sensor)에 의해 수행되며, 이는 차례로 개별 픽셀들 (individual pixels)로 분할된다. 이벤트-기반 픽셀(event-based pixel)에 영향을 미치는 상기 광 강도 (light intensity)가 적어도 특정 백분율(certain percentage)만큼 변경될 때마다, 상기 비전 센서는 대응 하는 이벤트(event)(21a)를 방출한다(emit). 상기 판별 모듈(discriminator module)은 상기 비전 센서로부터 상기 이벤트들(21a)뿐만 아니라 상기 1차 물체의 모션 방향 및/또는 속도에 대한 상기 정보를 수집한다. 이러한 정보는 임의의 적절한 수단 들, 예를 들어, 전용 센서들(dedicated sensors)에 의해, 또는 상기 센서들이 연결된 버스 시스템(bus system)(가령, CAN 버스)을 통해 차량의 어딘 가에 이미 존재하는 센서들에 액세스함으로써 획득될 수 있다. 상기 판별 모듈은 상기 이벤트들(21b)이 발생하는 상기 비전 센서의 상기 시야 내의 영역들(23a, 23b)뿐만 아니라 상기 2차 물체의 모션에 의해 야기될 가능성이 있는 그들 이벤트들(21b)을 식별한다. 대응 하는 이미지 정보(22b)와 선택적으로 결합된 이러한 정보는, 상기 분류 모듈(classifier module)에 의해 분 석되어 상기 2차 물체를 여러 카테고리들(본 명세서에서는 41a-41c로 표시됨) 중 적어도 하나로 분류한다. 예를 들어, 카테고리(category)(41a)는 사람들(humans)과 같은 2차 객체들을 포함할 수 있고, 이는 무엇이 든지 1차 객체와의 충돌로부터 보호되어야 한다. 카테고리(41b)는 작은 동물들(small animals)과 같은 2차 물체들을 포함할 수 있고, 이러한 사고로 인해 다른 사고가 발생되지 않을 경우에만, 1차 물체에 의한과감한 충돌 회피 조치(drastic collision avoidance action)를 보장한다. 카테고리(41c)는 비(rain) 또는 낙 엽들(leaves)과 같은 2차 물체들을 포함할 수 있고, 1차 물체에 의해 안전하게 넘어갈 수 있다. 상기 판별 모듈 및 상기 분류 모듈 중 하나 또는 둘 모두에 의해 생성된 2차 물체들에 대한 정보는 경보 장치(alarm device) 및/또는 완화 모듈(mitigation module)에 공급될 수 있다. 선택적으로, 추적 모듈(tracker module)은 이미 알려진 2차 물체들의 위치들(positions)(55a)을 결정할 수 있다. 상기 위 치들(55a)은 상기 진행중인 검출을 돕기 위해 상기 판별 모듈로 전달될 수 있고, 및/또는 상기 경보 장치 및/또는 상기 완화 모듈로 전달될 수 있다. 도 2는 상기 시스템이 순전히 이미지-기반 비전 시스템(purely image-based vision system)보다 먼저 2차 물체를 검출할 수 있는 도로 시나리오를 보여준다. 자동차는 1차 물체의 역할을 하고, 운전자(driver) 및/또는 전자 제어 유닛(electronic control unit)에 의해 조향되는 궤적(trajectory)을 따른다. 상기 궤 적은 주차된 자동차들(91, 92, 93) 사이를 달린다. 주차된 자동차들(91, 92) 사이에는 작은 간격이 있다. 본 시나리오에서 상기 2차 물체 역할을 하는 보행자가 이러한 작은 간격(gap)에서 방금 나타났다. 상기 1차 물체는 시야를 가지는 비전 센서를 탑재한다(carry). 이러한 시야는 주차된 자동차들 (91, 92)에 의해 부분적으로 가려진다(obscured). 상기 비전 센서의 상기 시야 어딘 가에 상기 광 강도 가 변할 때마다, 이벤트들(21a)은 상기 비전 센서에 의해 방출된다. 상기 2차 물체는 그러한 이벤트들(21a)이 시야 내의 위치들(A, B 및 C)에 대해 발사되도록(fired)한다. 이와는 별도로, 상기 주차된 자동차들(91, 93)의 대비가 풍부한 특징들(contrast-rich features)과 그 궤적 을 따라 상기 1차 물체의 모션이 더해져 위치들(D 및 E)에 대해 이러한 이벤트들(21a)이 발사되도록 한 다. 위치들(A, B 및 C)은 영역(23a = 23b)에 있다. 도 3은 상기 2차 물체의 모션에 의해 야기되는 이벤트들(21a)의 시퀀스(21c)가 어떻게 설정되는지를 도시한 다. 도 3a는 상기 시야에서 위치들(A-E)에 대응하는 상기 이벤트-기반 픽셀들에 영향을 미치는 상기 광 강 도의 상당한 변화들이 있을 때 방출되는 상기 이벤트들(21a)을 도시한다. 상기 위치들(A-E)은 도 2에 도시되어 있다. 상기 시간(t)은 왼쪽에서 오른쪽으로 진행된다. 상기 광 강도가 상기 미리 결정된 백분율만큼 증가하면, \"+\"로 라벨링된 이벤트(21a)가 방출된다. 상기 광 강도가 상기 미리 결정된 백분율만큼 감소하면, \"-\"로 라벨링 된 이벤트(21a)가 방출된다. 위치들(D 및 E)에 대응하는 상기 픽셀들에 대해 도 3a에 예시 적으로 도시된 바와 같이, 더 큰 총량만큼 광 강도의 온고잉 변화(ongoing change)가 있을 때, 상기 광 강도의 상대적 변화가 상기 미리 결정된 백분율을 충족할 때마다 새로운 이벤트(21a)가 방출될 것이다. 따라서, 하나의 온고잉 광 강 도 변화는 2개 이상의 이벤트들(21a)을 발생시킬 수 있다. 원칙적으로, 각 픽셀에서 방출되는 상기 이벤트들의 스트림은 상기 비전 센서에서 독립적으로 접근 가능 하다. 이것은 상이한 픽셀들로부터 동시에 발생하는 이벤트들(21a)이 동시에 판독되고 처리될 수 있음을 의 미한다. 따라서, 상기 비전 센서에 의해 전체적으로 방출되는 상기 이벤트들의 스트림(21a)은 특정 시점들에 대해 다수의 이벤트들(21a)을 포함할 수 있다. 도 3b에서, 상기 개별 픽셀들에 관한 상기 이벤트들의 스트림(21a)은 전체로서 상기 비전 센서로부터 방 출되는 하나의 단일 이벤트들의 스트림(21a)으로 결합되었다. 본 예에서는 동시에 발생하는 이벤트들이 없으므 로 상기 결합된 스트림에는 임의의 주어진 시점에 대해 하나의 이벤트만 포함된다. 도 3b에서, 각 이벤트는 그 것과 관련된 상기 시야의 위치, 및 광 강도의 증가 또는 감소에 해당하는지 여부에 따라, \"+\"로 라벨링된다. 상기 판별 모듈을 통해, 넓게 이격되고 상기 궤적을 따라 상기 1차 물체의 모션에 따라 상기 1차 물 체의 상기 궤적과 일치하는 방향으로 주행하는 위치들(D 및 E)에 속하는 이벤트들이 선별된다(culled). 이에 의해, 상기 2차 물체의 모션에 의해 야기되는 이벤트들(21b)의 시퀀스(21c)가 결정된다. 도 4는 상기 시스템에서 사용될 수 있는 비전 센서의 제1실시 예를 도시한다. 상기 비전 센서의 상기 광-민감 영역은 이미지 픽셀들(image pixels)만을 포함하는 중앙부(central portion)(20a)를 포함한다. 이러한 중앙부는 상기 광-민감 영역의 경계들(borders)(20b 및 20d)에 각각 인접한 2개의 경계부 들(boundary portions)(20c 및 20e)로 둘러싸여 있다. 상기 경계부들(20c 및 20e)은 이벤트-기반 픽셀들 (event-based pixels)만을 포함한다. 각각의 개별 이벤트-기반 픽셀은 광 강도의 적절한 변화에 의해 트리거될 때 대응하는 이벤트(21a)를 방출 한다. 이와는 대조적으로, 모든 이미지 픽셀들로부터의 강도 값들(intensity values)(22a)은 합쳐져 (aggregated) 이미지(22b)를 형성한다. 개별 이미지 픽셀들에 대한 즉각적인 랜덤-액세스(immediate random-access)는 불가능하다: 오히려, 상기 비전 센서가 다음 이미지 프레임(22b)을 방출할 때까지 기다려 야 한다. 도 5는 도 4에 도시된 상기 비전 센서의 상기 제1실시 예의 변형을 도시한다. 상기 차이점은 상기 중앙부 (20a) 및 상기 경계부들(20c, 20e) 사이의 전이들이 점진적(gradual)이라는 것이다: 각 열의 픽셀들을 가지는 이미지 픽셀들만을 포함하는 상기 중앙부(20a)로부터 시작하여, 이벤트-기반 픽셀들 및 이미지 픽셀들 이 인터리빙되는(interleaved) 비율은 상기 이벤트-기반 픽셀들 쪽으로 조금 더 시프트한다(shifts). 도 6은 상기 비전 센서의 제2실시 예를 보여준다. 도 4 및 도 5에 도시된 상기 제1실시 예와 마찬가지로, 이 벤트-기반 픽셀들(event-based pixels) 및 이미지 픽셀들(image pixels)이 있다. 각 이벤트-기반 픽셀 은 트리거될 때 자신의 이벤트들(21a)을 방출하고, 이들 이벤트(21a)는 즉시 액세스 가능하다. 이와는 대조 적으로, 전체 이미지(complete image)(22b)는 개별 이미지 픽셀들의 상기 강도 값들을 얻기 위해 상기 비전 센서로부터 다운로드 되어야 한다. 상기 제1실시 예와 비교할 때, 상기 차이점은 상기 이벤트-기반 픽셀들과 이미지 픽셀들이 일정한 비율 (constant ratio)로 인터리빙된다는 점이다.도면 도면1 도면2 도면3a 도면3b 도면4 도면5 도면6"}
{"patent_id": "10-2020-7030303", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하에서, 본 발명을 더욱 개선하는 추가 조치들은 도면들을 사용한 본 발명의 바람직한 실시 예의 설명과 함께 더 상세히 설명될 것이다. 바람직한 실시예들 상기 도면들은 다음과 같다. 도 1은 상기 시스템의 예시 적인 실시 예이다. 도 2는 2차 물체가 1차 물체의 궤적과 교차할 수 있는 예시 적인 상황이다. 도 3은 2차 물체의 상기 모션과 관련된 이벤트들(21b)의 시퀀스(21c)를 설정한 것이다. 도 4는 광-민감 영역의 중앙부(20a)와 경계부들(20c, 20e) 사이의 급격한 전이(sharp transition)를 가지 는 비전 센서의 제1실시 예이다. 도 5는 중앙부(20a) 및 경계부들(20c, 20e) 사이의 점진적인 전이(gradual transition)를 가지는 도 4에 도시 된 제1실시 예의 변형이다. 도 6은 이벤트-기반 픽셀들 및 이미지 픽셀들이 일정한 비율로 인터리빙된 비전 센서의 제2실시 예 이다."}
