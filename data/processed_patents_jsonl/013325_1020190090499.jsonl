{"patent_id": "10-2019-0090499", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0021400", "출원번호": "10-2019-0090499", "발명의 명칭": "음성 인식을 수행하는 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "최원종"}}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에서 음성 인식을 수행하는 방법에 있어서,제1 음성 신호에 대하여 음성 인식을 수행함으로써, 화자 인식을 수행하기 위해 기 설정된 제1 텍스트를 검출하는 단계; 상기 제1 텍스트가 검출됨에 따라, 상기 제1 음성 신호 이후 획득된 제2 음성 신호에 대해 화자 인식을 수행하는 단계; 및상기 제2 음성 신호에 대해 상기 화자 인식을 수행한 결과, 상기 제2 음성 신호의 화자가 상기 제1 텍스트를 등록한 제1 화자와 대응되는 경우, 상기 제2 음성 신호로부터 획득된 음성 명령을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 화자 인식을 수행하는 단계는상기 제1 음성 신호로부터 상기 제1 텍스트가 발화된 음성 신호 구간을 획득하는 단계;상기 음성 신호 구간에 대해 화자 인식을 수행하는 단계; 및상기 음성 신호 구간에 대해 화자 인식을 수행한 결과, 상기 음성 신호 구간의 화자가 상기 제1 화자와 대응되는 경우, 상기 제2 음성 신호에 대해 화자 인식을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제2 음성 신호의 화자가 상기 제1 화자와 대응되는 정도가 제1 기준값 이상인지에 기초하여, 상기 제2 음성 신호로부터 획득된 상기 음성 명령이 수행되고,상기 음성 신호 구간의 화자가 상기 제1 화자와 대응되는 정도가 제2 기준값 이상인지에 기초하여, 상기 제2 음성 신호에 대해 화자 인식이 수행되고,상기 제1 기준값은, 상기 제2 기준값보다 높은, 방법."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 제1 텍스트를 검출하는 단계는상기 제1 음성 신호에 대하여 음성 인식을 수행함으로써 획득된 텍스트에 대하여, 명칭 인식(Named EntityRecognition)을 수행하는 단계;상기 명칭 인식을 수행함으로써, 상기 텍스트로부터 상기 제1 화자를 나타내는 명칭을 추출하는 단계; 및상기 제1 화자를 나타내는 명칭을 상기 제1 텍스트로서 검출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 제2 음성 신호는상기 제1 음성 신호 이후 기 설정된 시간 동안 획득된 음성 신호를 포함하는, 방법."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 공개특허 10-2020-0021400-3-상기 제2 음성 신호에 대해 상기 화자 인식을 수행한 결과, 상기 제2 음성 신호의 화자가 상기 제1 텍스트를 등록한 제1 화자와 대응되지 않는 경우, 상기 제2 음성 신호의 음성 명령을 무시하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 제1 음성 신호 이후 획득된 제3 음성 신호에 대하여 음성 인식을 수행함으로써, 화자 인식을 수행하기 위해 기 설정된 제2 텍스트를 검출하는 단계;상기 제3 음성 신호 이후 획득된 제4 음성 신호에 대해 상기 화자 인식을 수행한 결과, 상기 제4 음성 신호의화자가 상기 제2 텍스트를 등록한 제2 화자와 대응되는 경우, 상기 제1 화자 및 상기 제2 화자의 우선 순위를결정하는 단계; 및상기 결정된 우선 순위에 기초하여, 상기 제4 음성 신호로부터 획득된 음성 명령을 수행하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "음성 인식을 수행하는 전자 장치에 있어서, 상기 전자 장치는제1 음성 신호 및 제2 음성 신호를 수신하는 마이크로폰; 및상기 제1 음성 신호에 대하여 음성 인식을 수행함으로써, 화자 인식을 수행하기 위해 기 설정된 제1 텍스트를검출하고, 상기 제1 텍스트가 검출됨에 따라, 상기 제1 음성 신호 이후 획득된 상기 제2 음성 신호에 대해 화자인식을 수행하고, 상기 제2 음성 신호에 대해 상기 화자 인식을 수행한 결과, 상기 제2 음성 신호의 화자가 상기 제1 텍스트를 등록한 제1 화자와 대응되는 경우, 상기 제2 음성 신호로부터 획득된 음성 명령을 수행하는,적어도 하나의 프로세서를 포함하는, 전자 장치."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는상기 제1 음성 신호로부터 상기 제1 텍스트가 발화된 음성 신호 구간을 획득하고, 상기 음성 신호 구간에 대해화자 인식을 수행하고, 상기 음성 신호 구간에 대해 화자 인식을 수행한 결과, 상기 음성 신호 구간의 화자가상기 제1 화자와 대응되는 경우, 상기 제2 음성 신호에 대해 화자 인식을 수행하는, 전자 장치."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 제2 음성 신호의 화자가 상기 제1 화자와 대응되는 정도가 제1 기준값 이상인지에 기초하여, 상기 제2 음성 신호로부터 획득된 상기 음성 명령이 수행되고,상기 음성 신호 구간의 화자가 상기 제1 화자와 대응되는 정도가 제2 기준값 이상인지에 기초하여, 상기 제2 음성 신호에 대해 화자 인식이 수행되고,상기 제1 기준값은, 상기 제2 기준값보다 높은, 전자 장치."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 적어도 하나의 프로세서는상기 제1 음성 신호에 대하여 음성 인식을 수행함으로써 획득된 텍스트에 대하여, 명칭 인식을 수행하고, 상기명칭 인식을 수행함으로써, 상기 텍스트로부터 상기 제1 화자를 나타내는 명칭을 추출하고, 상기 제1 화자를 나타내는 명칭을 상기 제1 텍스트로서 검출하는, 전자 장치."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 제2 음성 신호는상기 제1 음성 신호 이후 기 설정된 시간 동안 획득된 음성 신호를 포함하는, 전자 장치.공개특허 10-2020-0021400-4-청구항 13 제9항에 있어서, 상기 적어도 하나의 프로세서는상기 제2 음성 신호에 대해 상기 화자 인식을 수행한 결과, 상기 제2 음성 신호의 화자가 상기 제1 텍스트를 등록한 제1 화자와 대응되지 않는 경우, 상기 제2 음성 신호의 음성 명령을 무시하는, 전자 장치."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 상기 적어도 하나의 프로세서는상기 제1 음성 신호 이후 획득된 제3 음성 신호에 대하여 음성 인식을 수행함으로써, 화자 인식을 수행하기 위해 기 설정된 제2 텍스트를 검출하고, 상기 제3 음성 신호 이후 획득된 제4 음성 신호에 대해 상기 화자 인식을수행한 결과, 상기 제4 음성 신호의 화자가 상기 제2 텍스트를 등록한 제2 화자와 대응되는 경우, 상기 제1 화자 및 상기 제2 화자의 우선 순위를 결정하고, 상기 결정된 우선 순위에 기초하여, 상기 제4 음성 신호로부터획득된 음성 명령을 수행하는, 전자 장치."}
{"patent_id": "10-2019-0090499", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1 음성 신호에 대하여 음성 인식을 수행함으로써, 화자 인식을 수행하기 위해 기 설정된 제1 텍스트를 검출하는 동작; 상기 제1 텍스트가 검출됨에 따라, 상기 제1 음성 신호 이후 획득된 제2 음성 신호에 대해 화자 인식을 수행하는 동작; 및상기 제2 음성 신호에 대해 상기 화자 인식을 수행한 결과, 상기 제2 음성 신호의 화자가 상기 제1 텍스트를 등록한 제1 화자와 대응되는 경우, 상기 제2 음성 신호로부터 획득된 음성 명령을 수행하는 동작을 수행하도록 하는 프로그램이 저장된 기록매체를 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2019-0090499", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제1 음성 신호에 대하여 음성 인식을 수행함으로써, 화자 인식을 수행하기 위해 기 설정된 제1 텍스트를 검출하 고, 제1 텍스트가 검출됨에 따라, 제1 음성 신호 이후 획득된 제2 음성 신호에 대해 화자 인식을 수행하고, 제2 음성 신호에 대해 상기 화자 인식을 수행한 결과, 제2 음성 신호의 화자가 상기 제1 텍스트를 등록한 제1 화자와 대응되는 경우, 제2 음성 신호로부터 획득된 음성 명령을 수행하는, 전자 장치에서 음성 인식을 수행하는 방법이 제공된다."}
{"patent_id": "10-2019-0090499", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는, 음성 인식을 수행하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2019-0090499", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 음성 인식 분야에 있어서, 사용자의 음성 명령으로부터, 사용자의 의도를 파악하고 사용자가 원하는 서비 스를 제공하는 음성 인식 장치에 대한 연구가 요구되고 있다. 특히, 인공 지능 스피커는 인공 지능 기술을 이용하여, 사용자의 음성을 인식하고 음성에 포함된 명령을 추출하 여 명령에 따른 동작을 실행하고 그 결과를 음성으로 출력함으로써 인공지능 비서와 같은 역할을 수행할 수 있 다. 또한, 인공 지능 스피커는, 화자의 대화에 대해 음성 인식뿐만 아니라 화자 인식을 더 수행함으로써, 화자 를 식별하고, 식별된 화자에 적합한 기능을 수행할 수 있다. 그러나, 모든 발화에 대하여 음성 인식과 화자 인식이 함께 수행되는 경우, 연산량이 과도하게 증가되는 문제점 이 존재한다. 또한, 인공지능 스피커는 목소리를 기초로 사용자를 식별할 수 밖에 없기 때문에 지문이나 홍채 인식과 같은 생체 정보를 이용한 사용자 식별 또는 인증 방법에 비해 정확도가 떨어진다. 따라서, 음성 인식 시 화자 인식이 함께 수행되는 방법에 있어서, 화자 인식의 정확도를 높이고, 연산량을 저하시킬 수 있는 기술이 필요하다."}
{"patent_id": "10-2019-0090499", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시가 해결하고자 하는 과제는 전술한 문제를 해결하기 위한 것으로서, 음성 인식을 수행하는 전자 장치 및 그 동작 방법을 제공하기 위한 것이다. 또한, 상기 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨 터로 읽을 수 있는 기록매체를 포함하는 컴퓨터 프로그램 제품을 제공하는 데 있다. 해결하려는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2019-0090499", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 전자 장치에서 음성 인식을 수 행하는 방법은 제1 음성 신호에 대하여 음성 인식을 수행함으로써, 화자 인식을 수행하기 위해 기 설정된 제1 텍스트를 검출하는 단계; 상기 제1 텍스트가 검출됨에 따라, 상기 제1 음성 신호 이후 획득된 제2 음성 신호에 대해 화자 인식을 수행하는 단계; 및 상기 제2 음성 신호에 대해 상기 화자 인식을 수행한 결과, 상기 제2 음성 신호의 화자가 상기 제1 텍스트를 등록한 제1 화자와 대응되는 경우, 상기 제2 음성 신호로부터 획득된 음성 명 령을 수행하는 단계를 포함한다. 또한, 본 개시의 제2 측면은, 음성 인식을 수행하는 전자 장치는 제1 음성 신호 및 제2 음성 신호를 수신하는 마이크로폰; 및 상기 제1 음성 신호에 대하여 음성 인식을 수행함으로써, 화자 인식을 수행하기 위해 기 설정된 제1 텍스트를 검출하고, 상기 제1 텍스트가 검출됨에 따라, 상기 제1 음성 신호 이후 획득된 상기 제2 음성 신 호에 대해 화자 인식을 수행하고, 상기 제2 음성 신호에 대해 상기 화자 인식을 수행한 결과, 상기 제2 음성 신 호의 화자가 상기 제1 텍스트를 등록한 제1 화자와 대응되는 경우, 상기 제2 음성 신호로부터 획득된 음성 명령 을 수행하는, 적어도 하나의 프로세서를 포함한다. 또한, 본 개시의 제 3 측면은, 제 1 측면의 방법을 수행하도록 하는 프로그램이 저장된 기록매체를 포함하는 컴 퓨터 프로그램 제품을 제공할 수 있다."}
{"patent_id": "10-2019-0090499", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예에 의하면, 음성 인식 수행 시 모든 발화에 대해 화자 인식을 수행하는 대신, 미리 설정된 텍스트가 검출된 이후의 발화에 대해 화자 인식을 수행함으로써, 연산량이 저하될 수 있다. 또한, 일 실시 예에 의하면, 모든 화자에 대해 화자 인식을 수행하는 대신, 미리 설정된 텍스트가 검출된 이후, 상기 텍스트를 등록한 화자에 대해 화자 인식을 수행함으로써, 화자 인식의 정확도가 높아질 수 있다."}
{"patent_id": "10-2019-0090499", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 일 실시 예에 의한 음성 인식 시스템의 예시적인 네트워크 구성도이다. 도 1을 참조하면, 음성인식 시스템의 네트워크 환경은 전자 장치, 서버 및 네트워크를 포함 하는 것으로 예시적으로 도시된다. 후술될 음성인식 기능은 사용자의 음성을 포함하는 음성 신호를 문자열(또는 텍스트)로 변환하는 것을 말한다. 음성 인식 기능에 의해 음성 신호가 변환된 문자열(또는 텍스트)은 음성인식 결과로 지칭될 수 있다. 사용자의 음성 신호는 음성 명령을 포함할 수 있으며, 음성인식 결과 역시 음성 명령에 대응하는 명령을 포함할 수 있다. 음성 명령은 음성 인식 시스템에 포함된 특정 기능을 실행할 수 있다. 음성 인식 결과 획득된 텍스트 및 음성 명령은 자연어 형태의 문장 형태, 워드 형태, 또는 구 형태를 가질 수 있다. 또한, 이하에서 \"등록된(registered)\"이라는 표현은 음성인식 시스템에 사용자 또는 이의 관련 정보로서 등록되 어 있음을 의미한다. \"등록된 사용자\"는 음성인식 시스템에 사용자 등록을 마친 사용자를 의미한다. 어느 한 사 람은 본 개시에 따른 음성인식 시스템에 사용자로 등록할 수 있으며, 사용자로 등록할 때 본인의 음성을 입력할 수 있다. 전자 장치는 음성 인식을 수행하는 장치의 일 예로서, 음성 제어 기능이 탑재되어 특정 기능을 수행하는 음성 인식 스피커 장치일 수 있다. 또한, 전자 장치는 음성 인식 기능을 수행하는 장치로 구현될 수 있다. 예를 들어, 전자 장치는, 스마트 TV, 셋탑 박스, 휴대폰, 태블릿 PC, 디지털 카메라, 노트북 컴퓨터(laptop computer), 데스크탑, 전자책 단말기, 디지털 방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게 이션, MP3 플레이어, 착용형 기기(wearable device) 등과 같은 다양한 장치로 구현될 수 있다. 일 실시 예에 의 한 전자 장치는 상술한 예에 한하지 않고, 화자의 음성에 대해 음성 인식 및 화자 인식을 수행할 수 있는 다양한 종류의 장치로 구현될 수 있다. 일 실시 예에 의한 전자 장치는 화자의 음성을 수신하면 음성과 화자를 인식하고 음성에 포함된 명령을 추출하여 명령에 따른 동작을 실행하고 그 결과를 음성으로 출력할 수 있다. 또한, 일 실시 예에 의한 전자 장치는, 수신된 음성 신호에 대해 화자 인식 및 음성 인식을 수행하기 위 하여 학습된 하나 이상의 데이터 인식 모델을 이용할 수 있다. 예를 들면, 전자 장치는, DNN(Deep Neural Network), RNN(Recurrent Neural Network) 등의 뉴럴 네트워크(Neural Network)를 기반으로 하는 데이터 인식 모델을 이용할 수 있다. 전자 장치는 뉴럴 네트워크(Neural Network)를 기반으로 하는 하나 이상의 데이터 인식 모델을 이용하여, 마이크로폰(1620, 도 2, 3 참조)(이하, 마이크로폰)을 통해 입력되는 음성 신호를 분석함으로써 음성 특 성 데이터를 생성하고, 음성 특성 데이터에 기초하여 음성 인식 및 화자 인식을 수행할 수 있다. 일 실시 예에 따른, 음성 특성 데이터는, 음성 신호의 파형, 주파수, 진폭 등의 음성 신호 특성을 분석함으로써 생성된 정보를 포함할 수 있다. 전자 장치는 음성 신호의 음성 신호 특성을 분석함으로써, 제1 음성 신호에 대하여 음성인식을 수행할 수 있다. 예를 들면, 전자 장치는, 기 저장된 텍스트와 대응되는 음성 신호 특성과, 상기 분석된 음성 신호 특성을 이용하여, 음성 신호와 대응되는 텍스트를 획득할 수 있다. 전자 장치는 음성 인식을 수행한 결과, 제1 음성 신호를 문자열(또는 텍스트)로 변환할 수 있다. 전자 장치는 변환된 문자열로부터 화자에 의해 미리 등록된 텍스트를 검출함으로써, 제1 음성 신호 이후에 수신된 제2 음성 신호에 대해, 상기 텍스트를 등록한 화자를 인식하기 위한 화자 인식을 수행할 수 있다. 반면, 전자 장치는 수신된 음성 신호로부터 상기 미리 등록된 텍스트가 검출되지 않는 경우, 제1 음성 신호 이후에 수신된 제2 음성 신호에 대해, 화자 인 식을 수행하지 않고, 음성 신호에 포함된 화자의 음성 명령을 추출하여, 음성 명령에 따른 동작을 실행할 수 있 다. 전자 장치는 제2 음성 신호의 음성 신호 특성을 분석함으로써, 제2 음성 신호의 화자가 미리 등록된 화자 와 대응되는지 여부를 판단할 수 있다. 예를 들면, 전자 장치는, 미리 등록된 화자의 음성 신호 특성과, 제2 음성 신호의 음성 신호 특성을 이용하여, 음성 신호의 화자가 미리 등록된 화자와 대응되는지 여부를 판단 할 수 있다. 전자 장치는 일 실시 예에 따라 음성 인식 및 화자 인식이 수행되기 전에, 전자 장치의 화자를 미 리 등록해둠으로써, 상기 미리 등록된 화자의 음성 신호 특성을 저장해둘 수 있다. 예를 들면, 전자 장치(100 0)는 화자를 등록할 때, 상기 화자의 음성을 입력 받고, 입력된 음성을 분석함으로써, 화자의 음성 신호 특성을 미리 저장해둘 수 있다. 미리 등록된 화자의 음성 신호 특성은 화자 인식에 필요한 정보를 포함할 수 있고, 예 를 들면, 화자의 음성 신호에 대한 파형, 주파수, 진폭 정보 등을 포함할 수 있다. 전자 장치는, 화자 인식이 수행된 결과에 따라 제2 음성 신호에 대해 음성 인식을 수행함으로써, 음성 명 령을 획득하고 수행할 수 있다. 예를 들면, 전자 장치는 음성 신호의 주파수 특성을 추출하고, 음향 모델 과 언어 모델을 이용하여 음성 인식을 수행할 수 있다. 전자 장치는 제2 음성 신호의 화자의 음성을 문자 열(또는 텍스트)로 변환하고, 변환된 문자열(또는 텍스트)을 자연어 처리하여 음성 신호에 포함된 화자의 음성 명령을 추출할 수 있다. 음성인식 결과는 화자의 음성 명령을 포함하며, 음성인식 결과에 대응하는 동작은 화자 의 음성 명령에 따른 동작을 의미할 수 있다. 전자 장치는 음성 인식을 수행한 결과 음성에 포함된 명령 을 추출할 수 있고, 화자 인식을 수행한 결과에 따라 명령에 따른 동작을 실행할 수 있다. 전자 장치가 음성 인식 결과 추출된 음성 명령에 따라 실행할 수 있는 동작은 예컨대 음성 정보 제공, 음 악 재생, 인터넷 쇼핑, 금융 거래, 전화 연결, 메시지 전송, 알람 설정 및 전자 장치에 네트워크를 통해 접속된 전자 또는 기계 장치의 제어 등을 포함할 수 있다. 예를 들면, 전자 장치가 네트워크를 통해 스마트 TV(television)에 접속된 경우, 전자 장치는 채널 시청, 채널 검색, 동영상 재생, 및 프로그램 검색 등을 포함한 동작을 수행할 수 있다. 예를 들어, 전자 장치 가 스마트 냉장고와 같은 가전 기기에 접속된 경우, 전자 장치는 냉장 및 냉동 상태 점검 및 온도 설정 등을 포함한 동작을 수행할 수 있다. 그러나, 본 개시에서 전자 장치가 실행할 수 있는 동작은 상술 한 바로 제한되지 않는다. 전자 장치는 화자 인식을 수행하거나 음성 명령에 따른 동작을 실행하는 경우, 화자 인식 결과 또는 동작 의 실행 결과를 보고하기 위한 합성음 신호를 생성할 수 있다. 전자 장치는 제1 음성 신호로부터 제1 텍 스트가 검출되는 경우, 이후 제1 화자에 대한 화자 인식이 수행됨을 보고하기 위한 합성음 신호를 생성할 수 있 다. 또한, 전자 장치는 제2 음성 신호의 화자가 제1 텍스트를 등록한 화자가 아니라고 판단함에 따라 음 성인식 결과에 대응하는 동작이 실행되지 않은 경우, 동작이 실행되지 않았음을 보고하기 위한 합성음 신호를 생성할 수 있다. 전자 장치는 무선 또는 유선 통신을 통해 네트워크를 통해 서버 및 외부 장치(미도시)와 통 신할 수 있다.네트워크의 통신 방식은 제한되지 않으며, 네트워크에 포함될 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용한 통신 방식뿐만 아니라, 전자 장치와의 근거리 무선 통신이 포함될 수 있다. 예를 들어, 네트워크는 PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 네트워크는 버스 네 트워크, 스타 네트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네 트워크 등을 포함하는 네트워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 서버는 네트워크를 통해 전자 장치와 통신하며, 적어도 하나의 컴퓨터 장치로 구현될 수 있 다. 서버는 클라우드 형태로 분산될 수 있으며, 명령, 코드, 파일, 컨텐츠 등을 제공할 수 있다. 서버는 전자 장치로부터 수신되는 음성 신호를 문자열(또는 텍스트)로 변환하여 음성인식 결과를 생성할 수 있다. 서버는 전자 장치에서 재생될 음성을 합성하여 합성음 신호를 생성하고 합성음 신 호를 전자 장치에 송신할 수 있다. 서버는 전자 장치가 실행할 수 있는 동작들을 수행할 수 있다. 예컨대, 음성 정보 제공 기능의 경 우, 서버는 전자 장치로부터 수신된 음성 신호에 포함된 정보 요청을 인식하고, 이에 대한 결과를 생성하여, 합성음 신호의 형태로 전자 장치로 송신할 수 있다. 전화 연결 기능의 경우, 서버는 전 자 장치로부터 수신된 음성 신호에 포함된 전화 연결 요청을 인식하고, 요청에 따라 전화 연결을 수행하 며, 전화 연결 시 송신 신호와 수신 신호를 중계할 수 있다. 또한, 일 실시 예에 의한 서버는 전자 장치에 의해 수행될 수 있는 음성 인식 및 화자 인식을 수행 할 수 있다. 예를 들면, 서버는 전자 장치로부터 제1 음성 신호에 대해 음성 인식이 수행된 결과 검출된 제1 텍스트와 대응되는 음성 신호 구간을 수신할 수 있다. 서버는 제1 텍스트와 대응되는 음성 신 호 구간에 대해, 제1 텍스트를 등록한 제1 화자에 대한 화자 인식을 수행할 수 있다. 서버는 화자 인식이 수행된 결과를 전자 장치로 전송할 수 있다. 전자 장치는 서버로부터 수신한 화자 인식 결과 에 기초하여, 제1 음성 신호 이후 획득된 제2 음성 신호에 대해 제1 화자를 인식하기 위한 화자 인식을 수행하 고, 그 결과에 따라 제2 음성 신호로부터 획득된 음성 명령을 수행할 수 있다. 서버는 네트워크를 통해 외부 장치(미도시)에도 접속될 수 있으며, 서버는 전자 장치 로부터 수신된 음성 신호에 포함된 제어 명령에 따라 외부 장치(미도시)를 제어할 수 있다. 서버는 네트워크를 통해 외부 장치(미도시)에 접속될 수 있다. 서버와 전자 장치를 연 결하는 네트워크와 서버와 외부 장치(미도시)를 연결하는 네트워크는 서로 다른 종류일 수도 있다. 예컨 대, 서버와 전자 장치를 연결하는 네트워크는 LAN 또는 인터넷일 수 있으며, 서버와 외부 장 치(미도시)를 연결하는 네트워크는 이동통신망일 수 있다. 외부 장치(미도시)는 전자 장치에서 수신된 음성 명령에 따라 제어될 수 있는 장치일 수 있다. 예컨대, 외부 장치(미도시)는 사용자가 휴대하고 다닐 수 있는 휴대 전화, 스마트폰, 태블릿, 또는 노트북 등이나, 스마 트 TV, PC(personal computer), 냉장고, 세탁기 등의 가전 기기일 수 있다. 도 1에는 전자 장치가 네트워크를 통해 음성인식 기능을 수행하는 서버에 접속되는 것으로 도시되어 있지만, 이는 예시적이며, 전자 장치는 독립적으로 음성인식 기능을 수행할 수도 있다. 도 2 및 도 3은 일 실시 예에 의한 전자 장치의 내부 구성을 설명하기 위한 블록도이다. 도 2를 참조하면, 전자 장치는, 프로세서 및 마이크로폰을 포함할 수 있다. 그러나, 도 2에 도시된 구성 요소 모두가 전자 장치의 필수 구성 요소인 것은 아니다. 도 2에 도시된 구성 요소보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 도 2에 도시된 구성 요소보다 적은 구성 요소에 의해 전자 장치가 구현될 수도 있다. 예를 들면, 전자 장치는 도 3에 도시된 바와 같이, 일부 실시예에 따른 전자 장치는, 카메라 , 메모리, 디스플레이부 및 프로세서 이외에 사용자 입력부, 통신부, 출 력부, 센싱부 및 A/V 입력부를 더 포함할 수도 있다. 사용자 입력부는, 사용자가 전자 장치를 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들어, 사용자 입력부에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방 식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 일 실시 예에 의하면, 사용자 입력부는, 음성 인식을 수행하기 위한 사용자 입력을 수신할 수 있다. 출력부는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레 이부, 음향 출력부, 및 진동 모터를 포함할 수 있다. 디스플레이부는 전자 장치에서 처리되는 정보를 표시 출력한다. 일 실시 예에 의하면, 디스플레이 부는 화자 인식 및 음성 인식이 수행된 결과를 출력할 수 있다. 한편, 디스플레이부와 터치패드가 레이어 구조를 이루어 터치 스크린으로 구성되는 경우, 디스플레이부 는 출력 장치 이외에 입력 장치로도 사용될 수 있다. 디스플레이부는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발 광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이(electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고 전자 장치의 구현 형태에 따라 전자 장치는 디스플레이부를 2개 이상 포함할 수도 있다. 음향 출력부는 통신부로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력한다. 일 실 시 예에 의하면, 음향 출력부는 화자 인식 및 음성 인식이 수행된 결과를 나타내는 문자열을 합성음으로 출력할 수 있다. 예를 들면, 음향 출력부는, 음성 인식 결과 기 설정된 텍스트가 검출됨에 따라 화자 인 식이 수행됨을 알리는 문자열을 합성음으로 출력할 수 있다. 또한, 음향 출력부는, 음성 인식 및 화자 인 식이 수행됨에 따라, 음성 명령이 수행된 결과를 나타내는 문자열을 합성음으로 출력할 수 있다. 진동 모터는 진동 신호를 출력할 수 있다. 또한, 진동 모터는 터치스크린에 터치가 입력되는 경우 진동 신호를 출력할 수도 있다. 일 실시 예에 의하면, 진동 모터는 음성 인식 및 화자 인식이 수행됨을 알리기 위한 진동 신호를 출력할 수 있다. 프로세서는, 통상적으로 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메 모리에 저장된 프로그램들을 실행함으로써, 사용자 입력부, 출력부, 센싱부, 통신부 , A/V 입력부 등을 전반적으로 제어할 수 있다. 전자 장치는 적어도 하나의 프로세서 를 포함할 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리로부터 프로세서에 제공되거나, 통신부를 통해 수신되어 프로 세서로 제공될 수 있다. 예를 들면 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드 에 따라 명령을 실행하도록 구성될 수 있다. 일 실시 예에 의한 프로세서는 마이크로폰에서 생성된 오디오 신호로부터 화자의 음성에 대응하는 제1 음성 신호 및 제2 음성 신호를 획득할 수 있다. 제2 음성 신호는 제1 음성 신호 이후에 획득된 것일 수 있 다. 프로세서는 제1 음성 신호에 대해 음성 인식을 수행함으로써 화자 인식을 수행하기 위해 기 설정된 제1 텍스트를 검출하면, 제2 음성 신호에 대해 화자 인식을 수행할 수 있다. 일 실시 예에 의하면, 프로세서 는, 제1 텍스트가 발화된 음성 신호 구간에 대해 화자 인식을 수행한 결과, 음성 신호 구간의 화자가 제1 텍스트를 등록한 제1 화자와 대응되는 경우에 한하여, 제2 음성 신호에 대해 화자 인식을 수행할 수 있다. 프로 세서는 제2 음성 신호에 대해 화자 인식을 수행한 결과, 제2 음성 신호의 화자가 제1 화자와 대응되는 경 우, 제2 음성 신호로부터 획득된 음성 명령을 수행할 수 있다. 반면, 프로세서는 제2 음성 신호에 대해 상기 화자 인식을 수행한 결과, 제2 음성 신호의 화자가 제1 화 자와 대응되지 않는 경우, 제2 음성 신호로부터 획득된 음성 명령을 무시할 수 있다. 또한, 프로세서는 음성 신호로부터 기 설정된 복수 개의 텍스트를 검출하고, 각 텍스트와 대응되는 복수 의 화자에 대해 화자 인식을 수행할 수 있다. 프로세서는 각 화자의 우선 순위에 기초하여, 각 화자와 대 응되는 음성 신호에서 획득된 음성 명령을 수행할 수 있다. 예를 들면, 프로세서는 제1 음성 신호 이후 획득된 제3 음성 신호에 대해 음성 인식을 수행함으로써, 제2 텍스트를 검출하면, 제3 음성 신호 이후 획득된 제4 음성 신호에 대해 화자 인식을 수행할 수 있다. 프로세서는 화자 인식 결과, 제4 음성 신호의 화자가 제2 텍스트를 등록한 제2 화자와 대응되는 경우, 제1 음성 신호에서 검출된 제1 텍스트를 등록한 제1 화자와 제2 화자의 우선 순위를 결정할 수 있다. 제1 화자의 우선 순위가 더 높은 경우, 프로세서는, 제4 음성 신 호로부터 획득된 음성 명령을 수행하지 않을 수 있다. 반면, 제2 화자의 우선 순위가 더 높은 경우, 프로세서 는, 제4 음성 신호로부터 획득된 음성 명령을 수행할 수 있다. 센싱부는, 전자 장치의 상태 또는 전자 장치 주변의 상태를 감지하고, 감지된 정보를 프로세 서로 전달할 수 있다. 센싱부는, 지자기 센서(Magnetic sensor), 가속도 센서(Acceleration sensor), 온/습도 센 서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서, 근 접 센서, 및 RGB 센서(illuminance sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 통신부는, 전자 장치가 서버 또는 외부 장치(미도시)와 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부, 이동 통신부, 방송 수신부 를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비 (Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한 다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다 양한 형태의 데이터를 포함할 수 있다. 방송 수신부는, 방송 채널을 통하여 외부로부터 방송 신호 및/또는 방송 관련된 정보를 수신한다. 방송 채널은 위성 채널, 지상파 채널을 포함할 수 있다. 구현 예에 따라서 전자 장치가 방송 수신부를 포함하지 않을 수도 있다. 일 실시 예에 의한, 통신부는, 서버로부터 송신된 음성 인식 및 화자 인식 결과를 수신하거나, 외 부 장치(미도시)로부터 송신된 음성 신호를 수신할 수 있다. A/V(Audio/Video) 입력부는 오디오 신호 또는 비디오 신호 입력을 위한 것으로, 이에는 카메라와 마이크로폰 등이 포함될 수 있다. 카메라는 화상 통화모드 또는 촬영 모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 화상 프레임을 얻을 수 있다. 이미지 센서를 통해 캡쳐된 이미지는 프로세서 또는 별도의 이미지 처리부(미도시)를 통해 처리될 수 있다. 마이크로폰은, 외부의 음향 신호를 입력 받아 전기적인 음성 데이터로 처리한다. 예를 들어, 마이크로폰 은 화자의 음성 신호를 수신할 수 있다. 또 다른 예로, 마이크로폰은 복수의 화자에 의한 발화를 포함하는 음성 신호를 수신할 수 있다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되 거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 일 실시 예에 의한 메모리는 화자 인 식에 필요한 정보, 예를 들면, 음성 신호로부터 미리 등록된 화자를 인식하는데 필요한 정보를 저장할 수 있다. 또한, 메모리는 음성 인식에 필요한 정보, 예를 들면, 음향 모델, 언어 모델 등을 저장할 수 있다. 일 실시 예에 따라, 서버에 의해 화자 인식 및 음성 인식이 수행되는 경우, 상기 화자 인식 및 음성 인식 에 필요한 정보는, 메모리 대신 서버에 저장될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, UI 모 듈, 터치 스크린 모듈, 알림 모듈 등으로 분류될 수 있다. UI 모듈은, 애플리케이션 별로 전자 장치와 연동되는 특화된 UI, GUI 등을 제공할 수 있다. 터치 스크린 모듈은 사용자의 터치 스크린 상의 터치 제스처를 감지하고, 터치 제스처에 관한 정보를 프로세서 로 전달할 수 있다. 일부 실시예에 따른 터치 스크린 모듈은 터치 코드를 인식하고 분석할 수 있다. 터치 스크린 모듈은 컨트롤러를 포함하는 별도의 하드웨어로 구성될 수도 있다. 터치스크린의 터치 또는 근접 터치를 감지하기 위해 터치스크린의 내부 또는 근처에 다양한 센서가 구비될 수 있다. 터치스크린의 터치를 감지하기 위한 센서의 일례로 촉각 센서가 있다. 촉각 센서는 사람이 느끼는 정도로 또는 그 이상으로 특정 물체의 접촉을 감지하는 센서를 말한다. 촉각 센서는 접촉면의 거칠기, 접촉 물체의 단 단함, 접촉 지점의 온도 등의 다양한 정보를 감지할 수 있다. 사용자의 터치 제스처에는 탭, 터치&홀드, 더블 탭, 드래그, 패닝, 플릭, 드래그 앤드 드롭, 스와이프 등이 있 을 수 있다. 알림 모듈은 전자 장치의 이벤트 발생을 알리기 위한 신호를 발생할 수 있다. 도 4는 일 실시 예에 의한 음성 인식을 수행하는 일 예를 나타낸 도면이다. 일 실시 예에 의한 음성 인식을 수행하는 전자 장치는, 특정 공간에 고정되어 설치될 수 있어, 복수의 화 자에 의해 발화된 음성을 동시에 수신할 수 있다. 도 4의 401은, 일 실시 예에 따라 화자 인식 없이 음성 인식을 수행하는 일 예를 나타낸 것이고, 402는, 일 실 시 예에 따라 화자 인식에 기초하여 음성 인식을 수행하는 일 예를 나타낸 것이다. 도 4의 401을 참조하면, 일 실시 예에 의한 음성 인식을 수행하는 전자 장치는, 제1 화자 및 제2 화 자의 발화를 수신하여 음성 인식을 수행할 수 있다. 예를 들면, 전자 장치는, 제1 화자의 제1 발화 및 제2 화자의 제2 발화에 대해 음성 인식을 수행할 수 있다. 음성 인식 수행 결과, 전자 장치는, 제1 발화 및 제2 발화와 대응되는 텍스트로서, 각각 \"Hi 스피커, 음소거\", \"Hi 스피커, 노래재생\"을 획득할 수 있다. 제1 화자 및 제2 화자는, 핫 워드인 \"Hi 스피커\"를 포함한 음성 명령을 발화함에 따라, 전자 장치 는 \"Hi 스피커\" 이후 발화된 음성에 대해 음성 인식을 수행할 수 있다. 핫 워드란, 사용자가 음성 명령을 말하기 전 전자 장치를 인보크(invoke)하기 위해 사용자가 말할 수 있는 특정 단어를 의미할 수 있다. 전자 장치는 음성 인식을 통해 제1 발화로부터 미리 정의된 핫 워드(hot word)인 \"Hi 스피커\"를 인 식함으로써, \"Hi 스피커\" 이후 발화된 음성인 \"음소거\"를 음성 명령으로 획득할 수 있다. 마찬가지로, 전자 장 치는 음성 인식을 통해 제2 발화로부터 \"Hi 스피커\"를 인식함으로써, \"노래재생\"을 음성 명령으로 획득할 수 있다. 전자 장치는 획득된 음성 명령에 따라 동작을 수행할 수 있다. 그러나, 101에 도시된 예에 의하면, 두 화자의 발화인, \"음소거\" 및 \"노래재생\" 모두 음성 명령으로 획득됨에 따라, 서로 모순된 음성 명령인 \"음소거\" 및 \"노래 재생\"이 함께 처리될 수 있다. 반면, 도 4의 402에 도시된 예에 의하면, 화자 인식이 수행됨에 따라, 두 화자(430, 440)에 의한 음성 명령 중 미리 등록된 화자의 음성 명령이 우선적으로 처리될 수 있다. 도 4의 402을 참조하면, 일 실시 예에 의한 음성 인식을 수행하는 전자 장치는, 제3 화자 및 제4 화 자의 발화를 수신하여 음성 인식을 수행할 수 있다. 예를 들면, 전자 장치는, 제3 화자의 제3 발화 및 제4 화자의 제4 발화에 대해 음성 인식을 수행할 수 있다. 음성 인식 수행 결과, 전자 장치는, 제3 발화 및 제4 발화와 대응되는 텍스트로서, 각각 \"Hi 스피커, 나 엄마야, 음소거\", \"Hi 스피커, 노래재생\"을 획득할 수 있다. 일 실시 예에서, 제3 발화의 \"나 엄마야\"의 발화가 수신된 이후, 제3 발화의 \"음소거\" 및 제4 발화의 \"Hi 스피커, 노래재생\"의 발화가 전자 장치에서 수 신될 수 있다. 전자 장치는, 음성 인식 수행 결과, 제3 화자의 발화로부터 미리 등록된 텍스트인 \"나 엄마 야\"가 인식됨에 따라서, 이후 전자 장치로 수신된 발화인, \"음소거\" 및 \"Hi 스피커, 노래재생\"에 대해, 음성 인식뿐만 아니라 화자 인식을 함께 수행할 수 있다. 따라서, 전자 장치는, \"나 엄마야\"를 등록한 화 자에 의한 음성 명령인 \"음소거\"를 다른 화자의 음성 명령인 \"Hi 스피커, 노래재생\" 보다 우선적으로 처리할 수 있다. 일 실시 예에 의하면, 전자 장치는, 입력된 음성 신호에 대해 화자 인식 없이 음성 인식만을 수행하다가, 음성 인식 결과 미리 등록된 텍스트인 \"나 엄마야\"를 인식할 수 있다. 전자 장치는 \"나 엄마야\"가 인식된 이후, 미리 설정된 소정 시간 구간 동안, 수신된 음성 신호에 대하여, 화자 인식과 음성 인식을 함께 수행할 수 있다. 전자 장치는, 입력된 음성 신호의 발화자가 \"나 엄마야\"를 등록한 제3 화자에 의한 발화인지 를 판단할 수 있다. 전자 장치는, 화자 인식 결과, 제3 화자에 의한 음성 명령인 \"음소거\"를 처리할 수 있다. 또한, 전자 장치는, 화자 인식 결과, 제4 화자에 의한 음성 명령인 \"노래재생\"은 처리하지 않을 수 있다. 도 5는 일 실시 예에 의한 음성 인식을 수행하는 일 예를 나타낸 도면이다. 도 5를 참조하면, 전자 장치는 제1 화자에 의한 발화 및 제2 화자에 의한 발화를 포함한 음성 신호를 입력 받을 수 있다. 도 5에서, 화살표로 표시된 구간은 각 화자가 발화 중인 음성 신호 구간을 나타낸 것이다. 각 구간에서 획득된 음성 신호는, 제1 화자에 의한 발화 및 제2 화자에 의한 발화를 포함할 수 있다. 예를 들면, 제1 음성 신호는, 제1 구간에서의 제1 화자에 의한 발화 및 제2 화자에 의한 발화를 포함할 수 있다. 또한, 제2 음성 신호는, 제2 구간에서의 제1 화자에 의한 발화 및 제2 화자에 의한 발화를 포함할 수 있다. 전자 장치는 제1 구간에 대한 제1 음성 신호에 대해 음성 인식을 수행할 수 있다. 제1 구간에 대한 제1 음성 신호에 대해 음성 인식이 수행된 결과, 제1 화자의 발화 및 제2 화자의 발화와 각각 대응되는 제3 텍스트 및 제4 텍스트가 획득될 수 있다. 전자 장치는, 제3 텍스트로부터 미리 등록된 텍스트인 제1 텍스트를 검출함에 따라, 제2 구간에 대한 제2 음성 신호에 대해 음성 인 식과 화자 인식을 함께 수행할 수 있다. 예를 들면, 제1 텍스트가 검출됨에 따라, 제1 텍스트를 등록한 제1 화자에 대해 화자 인식이 수행될 수 있다. 전자 장치는 제1 텍스트가 검출됨에 따라, 제1 화자에 대한 화자 인식을 수행하기 위하여 필요한 정보를 획득할 수 있다. 또한, 전자 장치는, 제3 텍스트로부터 미리 등록된 텍스트인 제1 텍스트를 검출하면, 제1 텍스 트가 발화된 음성 신호 구간에 대하여, 제1 화자에 대한 화자 인식을 수행할 수 있다. 상기 음성 신호 구 간에 대한 화자 인식 결과에 따라, 전자 장치는 제2 구간에서 획득된 음성 신호에 대하여, 음성 인 식과 함께 제1 화자에 대한 화자 인식을 수행할지 여부를 결정할 수 있다. 화자 인식 결과, 제1 텍스트가 제1 화자에 의해 발화된 것으로 판단되면, 전자 장치는, 제2 구간 에서 획득된 제2 음성 신호에 대해 음성 인식과 화자 인식을 함께 수행할 수 있다. 반면, 제1 텍스트(51 1)가 제1 화자에 의한 발화가 아닌 것으로 판단되면, 전자 장치는, 제2 구간에서 획득된 제2 음성 신호에 대해 화자 인식 없이 음성 인식만을 수행할 수 있다. 제1 화자에 대한 화자 인식과 음성 인식이 수행되는 구간인, 제2 구간은, 제1 구간의 음성 신호가 획 득된 이후, 기 설정된 시간 구간으로 설정될 수 있다. 상술한 예에 한하지 않고, 제2 구간은, 다양한 방법 으로 설정될 수 있다. 제2 구간에서 획득된 제2 음성 신호에 대해 음성 인식과 화자 인식이 함께 수행되는 것으로 결정되면, 전 자 장치는 제2 구간에서 획득된 제1 화자의 발화 및 제2 화자의 발화에 대해 음성 인식과 화자 인식을 함께 수행할 수 있다. 음성 인식이 수행된 결과, 제5 텍스트 및 제6 텍스트가 획득될 수 있다. 전자 장치는, 화자 인식을 수행함으로써, 제5 텍스트가 제1 화자에 의해 발화된 것으로 판단 할 수 있다. 따라서, 전자 장치는, 제5 텍스트로부터 음성 명령을 추출하고, 추출된 음성 명령에 따 른 동작을 수행할 수 있다. 또한, 전자 장치는 화자 인식을 수행한 결과, 제6 텍스트는, 제1 화자에 의해 발화되지 않은 것으로 판단함에 따라, 제6 텍스트의 음성 명령은 수행하지 않고 무시할 수 있다. 도 6은 일 실시 예에 의한 음성 인식을 수행하는 방법을 나타낸 순서도이다. 도 6을 참조하면, 단계 601에서, 전자 장치는, 제1 음성 신호에 대해 음성 인식을 수행할 수 있다. 전자 장치는 음성 인식 결과 제1 음성 신호와 대응되는 텍스트를 획득할 수 있다. 단계 602에서, 전자 장치는, 단계 601에서 음성 인식을 수행한 결과, 제1 음성 신호와 대응되는 텍스트로 부터 화자 인식을 수행하기 위해 기 설정된 제1 텍스트를 검출할 수 있다. 제1 텍스트는 화자 인식을 위해 제1 화자에 의해 전자 장치에 미리 등록될 수 있다. 예를 들면, 제1 텍스 트는, 제1 화자의 신분, 이름, 별명 등을 나타내는 단어 또는 구를 포함할 수 있다. 전자 장치는 제1 화자로부터 제1 텍스트를 발화하는 음성을 수신 받음으로써, 제1 텍스트를 화자 인식을 위한 텍스트로 설정할 수 있다. 전자 장치는, 제1 음성 신호에 대하여 음성 인식을 수행함으로써 획득된 텍스트에 대하여, 명칭 인식 (Named Entity Recognition)을 수행함으로써, 제1 텍스트를 검출할 수도 있다. 명칭 인식이란, 미리 정의해 둔 사람, 회사, 장소, 시간, 단위 등에 해당하는 명칭을 소정의 텍스트로부터 인식하고, 인식된 명칭에 대해 태그 를 달아주는 기술을 의미한다. 예를 들면, 전자 장치는, 미리 정의해 둔 사람에 해당하는 명칭을 텍스트 에서 인식하고, 인식된 명칭에 대해 상기 미리 정의해 둔 사람을 나타내는 태그를 달 수 있다. 일 실시 예에 의하면, 전자 장치는, 명칭 인식을 수행함으로써, 제1 음성 신호와 대응되는 텍스트로부터 미리 등록된 제1 화자를 나타내는 명칭을 추출할 수 있다. 명칭 인식을 통해 추출될 수 있는 제1 화자를 나타내 는 명칭은, 인공지능 기술을 통해 미리 학습된 것일 수 있다. 일 실시 예에 따라, 전자 장치는, 음성 인식 결과 획득된 텍스트에 대해 명칭 인식을 수행하기 위하여 학 습된 하나 이상의 데이터 인식 모델을 이용할 수 있다. 일 실시 예에 따라, 전자 장치는, DNN(Deep Neural Network), RNN(Recurrent Neural Network) 등의 뉴럴 네트워크(Neural Network)를 기반으로 하는 데이터 인식 모델을 이용할 수 있다. 전자 장치는 뉴럴 네트워크(Neural Network)를 기반으로 하는 하나 이상의 데이터 인식 모델을 이용하여, 음성 인식 결과 획득된 텍스트에 대해 명칭 인식을 수행할 수 있다. 예를 들면, 전자 장치는, 데이터 인 식 모델을 이용하여, 상기 텍스트에 화자 인식을 위해 미리 등록된 화자를 나타내는 명칭이 포함되어 있는지 여 부를 판단할 수 있다. 전자 장치는 미리 등록된 제1 화자를 나타내는 명칭을 추출하면, 상기 제1 화자를 나타내는 명칭을 상기 제1 텍스트로서 검출할 수 있다. 음성 인식 결과 기 설정된 제1 텍스트가 검출되지 않은 경우, 전자 장치는 이후 획득되는 음성 신호에 대 해, 단계 601과 같이 음성 인식만을 수행할 수 있다. 단계 602에서, 제1 텍스트가 검출되면, 단계 603에서, 전자 장치는 제1 음성 신호 이후 획득되는 제2 음 성 신호에 대해 화자 인식을 수행할 수 있다. 일 실시 예에 의해 화자 인식이 수행되는 제2 음성 신호는, 제1 음성 신호 이후 기 설정된 시간 동안 획득된 음성 신호를 포함할 수 있다. 단계 604에서, 전자 장치는 단계 603에서 화자 인식을 수행한 결과, 제2 음성 신호의 화자가 제1 텍스트 를 등록한 제1 화자와 대응되는 경우, 제2 음성 신호로부터 획득된 음성 명령을 수행할 수 있다. 반면, 제2 음 성 신호의 화자가 제1 텍스트를 등록한 제1 화자와 대응되지 않는 경우, 제2 음성 신호로부터 획득된 음성 명령 은 무시될 수 있다. 또한, 전자 장치는 음성 신호로부터 기 설정된 복수 개의 텍스트를 검출하고, 각 텍스트와 대응되는 복수 의 화자에 대해 화자 인식을 수행할 수 있다. 전자 장치는 각 화자의 우선 순위에 기초하여, 각 화자와 대응되는 음성 신호에서 획득된 음성 명령을 수행할 수 있다. 예를 들면, 전자 장치는 제1 음성 신호 이 후 획득된 제3 음성 신호에 대해 음성 인식을 수행함으로써, 제2 텍스트를 검출하면, 제3 음성 신호 이후 획득 된 제4 음성 신호에 대해 화자 인식을 수행할 수 있다. 전자 장치는 화자 인식 결과, 제4 음성 신호의 화 자가 제2 텍스트를 등록한 제2 화자와 대응되는 경우, 제1 음성 신호에서 검출된 제1 텍스트를 등록한 제1 화자 와 제2 화자의 우선 순위를 결정할 수 있다. 제1 화자의 우선 순위가 더 높은 경우, 전자 장치는, 제4 음 성 신호로부터 획득된 음성 명령을 수행하지 않을 수 있다. 반면, 제2 화자의 우선 순위가 더 높은 경우, 전자 장치는, 제4 음성 신호로부터 획득된 음성 명령을 수행할 수 있다.도 7은 일 실시 예에 의한 음성 인식을 수행하는 방법을 나타낸 순서도이다. 도 7의 단계 701, 702, 707은, 각각 도 6의 단계 601, 602, 603과 대응될 수 있다. 도 7을 참조하면, 단계 701에서, 전자 장치는, 제1 음성 신호에 대해 음성 인식을 수행할 수 있다. 전자 장치는 음성 인식 결과 제1 음성 신호와 대응되는 텍스트를 획득할 수 있다. 단계 702에서, 전자 장치는, 단계 701에서 음성 인식을 수행한 결과, 제1 음성 신호와 대응되는 텍스트로 부터 화자 인식을 수행하기 위해 기 설정된 제1 텍스트를 검출할 수 있다. 제1 텍스트는, 제1 화자에 의해 미리 등록된 것일 수 있다. 또한, 제1 텍스트는, 명칭 인식을 통해 검출될 수도 있다. 단계 703에서, 전자 장치는, 제1 텍스트를 등록한 제1 화자에 대해 화자 인식을 수행하는데 필요한 정보 를 획득할 수 있다. 제1 화자에 대한 화자 인식을 수행하는데 필요한 정보는, 제1 화자가 제1 텍스트를 등록할 때 수집된 정보를 포함할 수 있다. 또한, 제1 화자에 대한 화자 인식을 수행하는데 필요한 정보는, 인공 지능 기술을 통해, 제1 화자의 음성 정보로부터 미리 학습된 정보를 포함할 수 있다. 단계 704에서, 전자 장치는, 제1 텍스트에 대응하는 음성 신호에 대해 화자 인식을 수행할 수 있다. 예를 들면, 전자 장치는 제1 음성 신호로부터 제1 텍스트가 발화된 음성 신호 구간을 획득하고, 상기 음성 신 호 구간에 대해 화자 인식을 수행할 수 있다. 단계 705에서, 전자 장치는, 단계 704에서 수행된 화자 인식을 수행한 결과, 제1 텍스트를 발화한 화자가 제1 화자와 대응되는지 여부를 판단할 수 있다. 전자 장치는, 등록된 제1 화자에 대해 화자 인식을 수행 하는데 필요한 정보를 이용하여 화자 인식을 수행할 수 있다. 예를 들면, 전자 장치는, 상기 제1 텍스트가 발화된 음성 신호 구간의 음성에 대한 특징 정보를 추출할 수 있다. 전자 장치는, 추출된 특징 정보와 미리 저장된 제1 화자에 대한 특징 정보를 비교함으로써, 화 자 인식을 수행할 수 있다. 제1 텍스트가 발화된 음성 신호 구간의 특징 정보와 미리 저장된 제1 화자에 대한 특징 정보가 대응되는 정도가 제1 기준값 이상인 경우, 전자 장치는 제1 텍스트를 발화한 화자가 제1 화 자와 대응되는 것으로 판단할 수 있다. 단계 706에서, 전자 장치는, 화자 인식을 수행한 결과, 제1 텍스트를 발화한 화자가 제1 화자와 대응되는 것으로 판단한 경우, 화자 인식이 수행됨을 나타내는 정보를 출력할 수 있다. 예를 들면, 전자 장치는, 화자 인식이 수행됨을 알리는 합성음을 스피커를 통해 출력할 수 있다. 제1 음성 신호 이후 획득되는 제2 음성 신호의 화자는, 전자 장치에 의해 출력된 정보를 통해, 화자 인식이 수행됨을 인식할 수 있다. 반면, 전자 장치는, 화자 인식을 수행한 결과, 제1 텍스트를 발화한 화자가 제1 화자와 대응되지 않는 것으로 판단한 경우, 제1 음성 신호 이후 획득되는 음성 신호에 대해 화자 인식 수행 없이 음성 인식을 수행할 수 있다. 단계 707에서, 전자 장치는, 제1 음성 신호 이후 획득되는 제2 음성 신호에 대해 화자 인식을 수행할 수 있다. 예를 들면, 전자 장치는, 상기 제2 음성 신호의 음성에 대한 특징 정보를 추출할 수 있다. 전자 장 치는, 추출된 특징 정보와 미리 저장된 제1 화자에 대한 특징 정보를 비교함으로써, 화자 인식을 수행할 수 있다. 제2 음성 신호의 음성에 대한 특징 정보와 미리 저장된 제1 화자에 대한 특징 정보가 대응되는 정도가 제2 기준값 이상인 경우, 전자 장치는 제2 음성 신호의 화자가 제1 화자와 대응되는 것으로 판단할 수 있 다. 일 실시 예에 따라, 제1 텍스트 검출에 의해 특정된 화자에 대해 화자 인식이 수행되는 것으로 결정되면, 특정 된 화자에 대하여만 화자 인식이 수행되므로, 전자 장치는 높은 정확도로 화자 인식을 수행할 수 있다. 단계 704의 화자 인식 시 이용되는 제1 기준값과 단계 707의 화자 인식 시 이용되는 제2 기준값은 미리 설정된 값일 수 있으며, 두 값은 서로 다른 값으로 설정될 수 있다. 예를 들면, 제1 기준값은 제2 기준값보다 낮은 값 으로 설정될 수 있다. 따라서, 단계 704의 화자 인식보다 단계 707의 화자 인식이 더 높은 정확도로 수행될 수 있다. 전자 장치는 단계 707의 화자 인식 시 더 높은 기준값을 이용함으로써, 제2 음성 신호에서의 화자 인식의 정확도를 높일 수 있다. 단계 708에서, 전자 장치는, 제2 음성 신호에 대해 화자 인식을 수행한 결과, 제2 음성 신호의 화자가 제 1 텍스트를 등록한 제1 화자와 대응되는 경우, 단계 709에서, 제2 음성 신호로부터 획득된 음성 명령을 수행할 수 있다. 예를 들면, 전자 장치는, 제2 음성 신호에 대한 음성 인식 결과, 텍스트를 추출하고, 추출된 텍스트로부터 사용자의 의도에 맞는 음성 명령을 획득할 수 있다. 반면, 전자 장치는, 제2 음성 신호에 대해 화자 인식을 수행한 결과, 제2 음성 신호의 화자가 제1 텍스트 를 등록한 제1 화자와 대응되지 않는 경우, 단계 710에서, 제2 음성 신호로부터 획득된 음성 명령을 수행하지 않고, 무시할 수 있다. 또는, 전자 장치는, 화자 인식을 수행한 결과, 제2 음성 신호의 화자가 제1 텍스 트를 등록한 제1 화자와 대응되지 않는 경우, 제2 음성 신호에 대해 음성 인식을 수행하지 않고, 무시할 수 있 다. 일 실시 예에 의하면, 전자 장치는, 화자 인식을 수행한 결과, 제2 음성 신호의 음성 명령을 무시하는 경 우, 제1 화자에 대한 화자 인식을 계속 수행할지 판단하기 위한 시간을 카운트할 수 있다. 전자 장치는, 기 설정된 시간 이내에, 화자 인식을 수행한 결과, 제1 화자에 의한 발화로 판단되는 음성 신호가 획득되지 않 는 경우, 이후 획득되는 음성 신호에 대해 제1 화자에 대한 화자 인식을 수행하지 않을 수 있다. 전자 장치 는 이후 획득되는 음성 신호에 대해 단계 701 이후의 동작을 수행할 수 있다. 단계 711에서, 전자 장치는 제2 음성 신호의 음성 명령이 무시됨을 나타내는 정보를 출력할 수 있다. 예 를 들면, 전자 장치는, 제2 음성 신호의 음성 명령이 무시됨을 알리는 합성음을 스피커를 통해 출력할 수 있다. 제1 음성 신호 이후 획득되는 제2 음성 신호의 화자는, 전자 장치에 의해 출력된 정보를 통해, 화 자 자신에 의한 음성 명령은 무시됨을 인식할 수 있다. 도 8은 일 실시 예에 의한 복수의 화자에 의한 발화를 포함하는 음성 신호에 대해 음성 인식을 수행하는 일 예 를 나타낸 도면이다. 도 8을 참조하면, 전자 장치는 제1 화자에 의한 발화 및 제2 화자에 의한 발화를 포함한 음성 신호를 입력 받을 수 있다. 화살표로 표시된 구간은 각 화자가 발화하는 음성 신호 구간을 나타낸 것이다. 각 구간에서 획득된 음성 신호는, 제1 화자에 의한 발화 및 제2 화자에 의한 발화를 포함할 수 있다. 전자 장치는 제1 구간에서 획득된 음성 신호에 대해 음성 인식을 수행할 수 있다. 제1 구간에 서 획득된 제1 음성 신호에 대해 음성 인식이 수행된 결과, 제1 화자의 발화 및 제2 화자의 발화와 각각 대응되는 제3 텍스트 및 제4 텍스트가 획득될 수 있다. 전자 장치는, 제3 텍스트로 부터 미리 설정된 텍스트인 제1 텍스트를 검출함에 따라, 제2 구간에서 획득된 음성 신호에 대해 음 성 인식과 제1 화자에 대한 화자 인식을 함께 수행할 수 있다. 예를 들면, 제1 텍스트가 검출됨에 따라, 제1 텍스트를 등록한 제1 화자에 대해 화자 인식이 수행될 수 있다. 전자 장치는 제1 텍스트가 검출됨에 따라, 제1 화자에 대한 화자 인식을 수행하기 위하여 필요한 정보를 획득할 수 있다. 또한, 전자 장치는, 제3 텍스트로부터 미리 설정된 텍스트인 제1 텍스트를 검출하면, 제1 텍스 트가 발화된 음성 신호 구간에 대하여, 화자 인식을 수행할 수 있다. 상기 음성 신호 구간에 대한 화자 인 식 결과에 따라, 전자 장치는 제2 구간에서 획득된 음성 신호에 대하여, 음성 인식과 함께 제1 화자 에 대한 화자 인식을 수행할지 여부를 결정할 수 있다. 화자 인식 결과, 제1 텍스트가 제1 화자에 의해 발화된 것으로 판단되면, 전자 장치는, 제2 구간 에서 획득된 음성 신호에 대해 음성 인식과 화자 인식을 함께 수행할 수 있다. 반면, 제1 텍스트가 제1 화자에 의한 발화가 아닌 것으로 판단되면, 전자 장치는, 제2 구간에서 획득된 제2 음성 신호에 대해 화자 인식 없이 음성 인식만을 수행할 수 있다. 제1 화자에 대한 화자 인식과 음성 인식이 수행되는 구간인, 제2 구간은, 제1 구간의 음성 신호가 획 득된 이후, 기 설정된 시간 구간으로 설정될 수 있다. 제2 구간에서 획득된 제2 음성 신호에 대해 음성 인식과 화자 인식이 함께 수행되는 것으로 결정되면, 전 자 장치는 제2 구간에서 획득된 화자의 발화 및 제2 화자의 발화에 대해 음성 인식과 화 자 인식을 함께 수행할 수 있다. 전자 장치는, 음성 인식을 수행한 결과, 제2 구간에서, 제5 텍스트 및 제6 텍스트를 획득할 수 있다. 전자 장치는, 화자 인식을 수행함으로써, 제5 텍스트 가 제1 화자에 의해 발화된 것으로 판단할 수 있다. 따라서, 전자 장치는, 제5 텍스트로부터 음성 명령을 추출하고, 추출된 음성 명령에 따른 동작을 수행할 수 있다. 또한, 전자 장치는 제6 텍스트는, 제1 화자에 의해 발화되지 않은 것으로 판단함에 따라, 제6 텍스트의 음성 명령은 수행하지 않고 무시 할 수 있다. 다만, 전자 장치는, 제6 텍스트로부터, 제2 화자에 대해 화자 인식을 수행하기 위하여 미리 설정된 텍스트인 제2 텍스트를 검출할 수 있다. 제2 텍스트는 제2 화자에 의해 미리 등록된 것일 수 있다. 제2 텍스트가 검출됨에 따라, 전자 장치는 이후 획득되는 음성 신호인 제3 구간에 대한 음성 신호에 대해 음성 인식과 제2 화자에 대한 화자 인식을 함께 수행할 수 있다. 예를 들면, 제2 텍스트가 검출됨에 따라, 제2 텍스트를 등록한 제2 화자에 대해 화자 인식이 수행될 수 있다. 전자 장치는 제2 텍스트가 검출됨에 따라, 제2 화자에 대한 화자 인식을 수행하기 위하여 필요한 정보를 획득할 수 있다. 또한, 전자 장치는, 제6 텍스트로부터, 제2 화자에 대해 화자 인식을 수행하기 위하여 미리 설정된 텍스트인 제2 텍스트를 검출하면, 제2 텍스트가 발화된 음성 신호 구간에 대하여, 제2 화자에 대한 화자 인식을 수행할 수 있다. 상기 음성 신호 구간에 대한 화자 인식 결과에 따라, 전자 장치는 제3 구간 에서 획득된 음성 신호에 대하여, 음성 인식과 함께 제2 화자에 대한 화자 인식을 수행할지 여부를 결정할 수 있다. 화자 인식 결과, 제2 텍스트가 제2 화자에 의해 발화된 것으로 판단되면, 전자 장치는, 제3 구간 에서 획득된 음성 신호에 대해 음성 인식과 화자 인식을 함께 수행할 수 있다. 반면, 제2 텍스트가 제2 화자에 의한 발화가 아닌 것으로 판단되면, 제3 구간에서 획득된 음성 신호에 대해 제2 화자에 대한 화자 인식은 수행되지 않고 음성 인식만 수행될 수 있다. 제1 화자에 대한 화자 인식과 음성 인식이 수행되는 구간인, 제2 구간은, 제1 구간의 음성 신호가 획 득된 후, 기 설정된 시간 구간으로 설정될 수 있다. 또한, 제2 화자에 대한 화자 인식과 음성 인식이 수행되는 구간인, 제3 구간은, 제2 텍스트의 음성 신호가 획득된 이후, 기 설정된 시간 구간으로 설정될 수 있 다. 상술한 예에 한하지 않고, 제2 구간 및 제3 구간은, 다양한 방법으로 설정될 수 있다. 제3 구간에서 획득된 음성 신호에 대해 음성 인식과 제2 화자에 대한 화자 인식이 함께 수행되는 것으로 결정되면, 전자 장치는 제3 구간에서 획득된 제1 화자의 발화 및 제2 화자의 발화에 대해 음성 인식과 제2 화자에 대한 화자 인식을 함께 수행할 수 있다. 또한, 전자 장치는, 제2 구간과 제 3 구간이 겹치는 제4 구간에서 획득된 음성 신호에 대하여, 음성 인식, 제1 화자에 대한 화자 인식 및 제2 화자에 대한 화자 인식을 함께 수행할 수 있다. 제4 구간에서는, 음성 인식이 수행된 결과, 제7 텍스트 및 제8 텍스트가 획득될 수 있다. 전자 장치는, 화자 인식을 수행함으로써, 제7 텍스트 및 제8 텍스트는 각각 제1 화자 및 제2 화자에 의해 발화된 것으로 판단할 수 있다. 전자 장치는, 제1 화자 및 제2 화자의 우선 순위를 결정하고, 결정 된 우선 순위에 따라, 제7 텍스트 또는 제8 텍스트 중 하나의 음성 명령에 따른 동작을 수행할 수 있 다. 예를 들어, 제1 화자의 우선 순위가 더 높은 경우, 전자 장치는, 제1 화자에 의해 발화된 제7 텍스트 의 음성 명령에 따른 동작을 먼저 수행할 수 있다. 또한, 전자 장치는, 제2 화자에 의해 발화된 제8 텍스트의 음성 명령에 따른 동작은 수행하지 않을 수 있다. 제4 구간 이후, 제3 구간 중 T1 및 T2 사이의 구간에서, 전자 장치는 제2 화자에 대한 화자 인 식 및 음성 인식을 수행할 수 있다. 제1 화자에 대한 화자 인식은 수행되지 않을 수 있다. 음성 인식 결과, 제9 텍스트 및 제10 텍스트가 획득될 수 있다. 전자 장치는, 제2 화자에 대한 화자 인식을 수행함 으로써, 제10 텍스트는 제2 화자에 의해 발화된 것으로 판단할 수 있다. 따라서, 전자 장치는, 제10 텍스트로부터 음성 명령을 추출하고, 추출된 음성 명령에 따른 동작을 수행할 수 있다. 또한, 전자 장치 는 제9 텍스트는, 제2 화자에 의해 발화되지 않은 것으로 판단함에 따라, 제9 텍스트의 음성 명령은 수행하지 않고 무시할 수 있다. 일 실시 예에 의하면, 음성 인식 수행 시 모든 발화에 대해 화자 인식을 수행하는 대신, 미리 설정된 텍스트가 검출된 이후의 발화에 대해 화자 인식을 수행함으로써, 연산량이 저하될 수 있다. 또한, 일 실시 예에 의하면, 모든 화자에 대해 화자 인식을 수행하는 대신, 미리 설정된 텍스트가 검출된 이후, 상기 텍스트를 등록한 화자에 대해 화자 인식을 수행함으로써, 화자 인식의 정확도가 높아질 수 있다.일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체 일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체 는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이 터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령어, 데 이터 구조, 또는 프로그램 모듈을 포함하며, 임의의 정보 전달 매체를 포함한다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다."}
{"patent_id": "10-2019-0090499", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2019-0090499", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 의한 음성 인식 시스템의 예시적인 네트워크 구성도이다. 도 2 및 도 3은 일 실시 예에 의한 전자 장치의 내부 구성을 설명하기 위한 블록도이다. 도 4 및 도 5는 일 실시 예에 의한 음성 인식을 수행하는 일 예를 나타낸 도면이다. 도 6 및 도 7은 일 실시 예에 의한 음성 인식을 수행하는 방법을 나타낸 순서도이다. 도 8은 일 실시 예에 의한 복수의 화자에 의한 발화를 포함하는 음성 신호에 대해 음성 인식을 수행하는 일 예 를 나타낸 도면이다."}
