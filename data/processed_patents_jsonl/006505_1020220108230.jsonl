{"patent_id": "10-2022-0108230", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0031457", "출원번호": "10-2022-0108230", "발명의 명칭": "위기 대응 애플리케이션, 위기 대응 관제 시스템 및 위기 대응 관제 방법", "출원인": "서봉진", "발명자": "서봉진"}}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자를 촬영한 제1 영상데이터와 현장을 촬영한 제2 영상데이터를 제공받는 입력모듈;상기 사용자의 위치와 상기 사용자의 위치를 기준으로 미리 설정된 범위 이내의 적어도 하나의 위기대응관리자의 위치를 추출하는 위치모듈; 및 상기 적어도 하나의 위기대응관리자 중 어느 하나의 위기대응관리자와 상기 사용자를 매칭하여 상기 위기대응관리자의 단말로 상기 제1 및 제2 영상데이터를 전송하고 상기 사용자의 위치로 출동하도록 출동신호를 제공하는제어모듈을 포함하는,위기 대응 관제 시스템."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 제1 영상데이터는 상기 사용자의 단말기에서 위기 대응 애플리케이션이 실행된 상태에서 상기 사용자의 단말기에 구비된 전면카메라를 이용하여 획득되고,상기 제2 영상데이터는 상기 사용자의 단말기에서 상기 위기 대응 애플리케이션이 실행된 상태에서 상기 사용자의 단말기에 구비된 후면카메라를 이용하여 획득되는,위기 대응 관제 시스템."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서, 상기 위기 대응 관제 시스템은,상기 제1 및 제2 영상데이터를 인공지능에 기반한 영상처리하여 상기 현장에서 사고를 유발한 객체의 인상착의,형태 및 도주여부와 상기 사용자의 부상종류 및 부상정도를 판단하는 상황판단 인공지능 모듈을 더 포함하는,위기 대응 관제 시스템."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 제어모듈은, 상기 미리 설정된 범위 이내이고 상기 사용자와 최인접거리에 위치하는 상기 위기대응관리자의 단말에 상기 제1및 제2 영상데이터와 상기 인상착의, 상기 형태, 상기 도주여부, 상기 부상종류, 및 상기 부상정도에 대한 데이터를 전송하고 상기 사용자의 위치로 출동하도록 제어하는,위기 대응 관제 시스템."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3 항에 있어서,상기 제어모듈은, 상기 사용자와 최인접거리에 위치하는 상기 위기대응관리자의 단말로부터 상기 사용자의 위치로 출동할 수 없는출동불가신호를 제공받은 경우,상기 미리 설정된 범위 이내이고 상기 사용자와 차인접거리에 위치하는 상기 위기대응관리자의 단말에 상기 제1공개특허 10-2024-0031457-3-및 제2 영상데이터와 상기 인상착의, 상기 형태, 상기 도주여부, 상기 부상종류, 및 상기 부상정도에 대한 데이터를 전송하고 상기 사용자의 위치로 출동하도록 제어하는,위기 대응 관제 시스템."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 제어모듈은, 상기 사용자와 상기 매칭된 상기 위기대응관리자의 단말기에 상기 위기 대응 애플리케이션을 통해 상기 제1 영상데이터를 디스플레이하는 제1 윈도우와 상기 제2 영상데이터를 디스플레이하는 제2 윈도우와 상기 사용자의위치에 해당하는 제1 위치핀과 상기 적어도 하나 이상의 위기대응관리자의 위치에 해당하는 제2 위치핀을 디스플레이하는 제3 윈도우와 상기 사용자와 상기 현장을 녹화하여 상기 제1 및 제2 영상데이터를 저장할 수 있는제1 버튼과 상기 적어도 하나 이상의 위기대응관리자에게 구조요청을 위한 전화를 할 수 있는 제2 버튼과 위기대응 애플리케이션에 상기 사용자가 미리 지정한 지정자에게 상기 구조요청을 위한 전화를 할 수 있는 제3 버튼이 디스플레이되도록 제어하는,위기 대응 관제 시스템."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 위기 대응 관제 시스템은, 상기 사용자의 운전가능여부 또는 보행가능여부에 기초하여 상기 현장에서 미리 설정된 안전장소로 이동하는 경로를 생성하는 경로생성모듈을 더 포함하는,위기 대응 관제 시스템."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서, 상기 경로생성모듈은, 상기 사용자가 운전이 가능한 경우 상기 현장에서 상기 안전장소로 차량을 통해 이동하기 위한 차량이동경로를생성하고,상기 사용자가 보행이 가능한 경우 상기 현장에서 상기 안전장소로 미리 저장된 안심보행경로를 통해 이동하기위한 보행이동경로를 생성하는,위기 대응 관제 시스템."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 제어모듈은,상기 사용자가 운전이 가능한 경우 상기 사용자의 단말에서 상기 차량이동경로를 디스플레이하고 상기 안전장소로 이동하는 이동방법을 음성을 출력하도록 제어하는, 위기 대응 관제 시스템."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8 항에 있어서,상기 제어모듈은,상기 사용자가 보행이 가능한 경우 상기 사용자의 단말에 상기 보행이동경로를 디스플레이하고 상기 안전장소로공개특허 10-2024-0031457-4-이동하는 과정을 음성을 출력하도록 제어하는,위기 대응 관제 시스템."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "사용자의 단말과 적어도 하나의 위기대응관리자의 단말의 양방향통신을 통해 범죄를 대응하기 위한 위기 대응애플리케이션에 있어서, 상기 사용자를 촬영한 제1 영상데이터를 디스플레이하는 제1 윈도우;상기 범죄가 발생된 현장을 촬영한 제2 영상데이터를 디스플레이하는 제2 윈도우;상기 사용자의 위치에 해당하는 제1 위치핀과 상기 사용자의 위치를 기준으로 미리 설정된 범위 이내의 적어도하나의 위기대응관리자의 위치에 해당하는 제2 위치핀을 디스플레이하는 제3 윈도우;상기 사용자의 단말 또는 상기 적어도 하나의 위기대응관리자의 단말 중 어느 하나의 단말로부터 입력된 신호에의해 상기 사용자와 상기 현장을 녹화하여 상기 제1 및 제2 영상데이터를 저장할 수 있는 제1 버튼; 상기 적어도 하나 이상의 위기대응관리자에게 구조요청을 위한 전화를 할 수 있는 제2 버튼; 및상기 사용자가 미리 지정한 지정자에게 상기 구조요청을 위한 전화를 할 수 있는 제3 버튼이 실행되는위기 대응 애플리케이션."}
{"patent_id": "10-2022-0108230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "입력모듈에 의해 사용자를 촬영한 제1 영상데이터와 현장을 촬영한 제2 영상데이터를 제공받는 단계;위치모듈에 의해 상기 사용자의 위치 및 상기 사용자의 위치를 기준으로 미리 설정된 범위 이내의 적어도 하나의 위기대응관리자의 위치를 추출하는 단계; 및 제어모듈에 의해 상기 적어도 하나의 위기대응관리자 중 어느 하나의 위기대응관리자와 상기 사용자를 매칭하여상기 위기대응관리자의 단말로 상기 제1 및 제2 영상데이터를 전송하고 상기 사용자의 위치로 출동하도록 출동신호를 제공하는 단계를 포함하는,위기 대응 관제 방법."}
{"patent_id": "10-2022-0108230", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명인 위기 대응 관제 시스템은, 사용자를 촬영한 제1 영상데이터와 현장을 촬영한 제2 영상데이터를 제공받 는 입력모듈, 사용자의 위치와 사용자의 위치를 기준으로 미리 설정된 범위 이내의 적어도 하나의 위기대응관리 자의 위치를 추출하는 위치모듈 및 적어도 하나의 위기대응관리자 중 어느 하나의 위기대응관리자와 사용자를 매 칭하여 위기대응관리자의 단말로 제1 및 제2 영상데이터를 전송하고 사용자의 위치로 출동하도록 출동신호를 제 공하는 제어모듈을 포함한다."}
{"patent_id": "10-2022-0108230", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 위기 대응 애플리케이션, 위기 대응 관제 시스템 및 위기 대응 관제 방법에 관한 것이다."}
{"patent_id": "10-2022-0108230", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에는 1인 가구의 비중이 급격하게 늘어나고 있으며, 이에 따라 1인 가구에 해당하는 여성, 어린이, 노약자 에 대한 주거침입, 절도, 폭행, 성폭력, 및 강도 등의 강력범죄가 늘어나고 있다. 한편, 현장에서 도주 등 다양한 원인으로 인해 가해자를 신속하게 체포하기에 많은 어려움이 존재하며, 사건 발 생 건수에 비해 검거율이 낮다. 위와 같은 범죄사건에서는 피해자에게 입증책임이 존재할 뿐만 아니라 흔히 발생되는 극심한 트라우마, 피로감, 진술의 모호성이 범죄 가해자의 기소율을 감소시키는 요인으로 작용한다. 또한, 심리적 또는 상황적 요인으로 인해 범죄현장에서 즉시 신고를 하기에는 어려우며, 경찰관이 피해자에게 배정되기까지 접수 지연 등 다양한 외부적인 요인이 존재한다. 이에, 범죄현장에서 발생된 사건에 대해 증거를 객관적으로 채증할 수 있을 뿐만 아니라 경찰관 등을 신속하게 배정하여 범죄를 예방하고 피해자를 보호하기 위한 기술이 필요한 실정이다."}
{"patent_id": "10-2022-0108230", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2022-0108230", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는 범죄현장에서 발생된 범죄사건에 대해서 영상을 통해 증거를 객관적 으로 채증하기 위함이다. 또한, 본 발명이 해결하고자 하는 기술적 과제는 범죄현장을 실시간으로 공유함으로써 심리적 또는 상황적 요인 으로 인해 즉각적인 대응을 할 수 없는 피해자를 대신해 경찰관 등을 신속하게 배정하고 출동시키기 위함이다. 또한, 본 발명이 해결하고자 하는 기술적 과제는 현재 위치 또는 범죄현장에서 피해자가 신속하게 탈출 또는 이 동하기 위한 이동경로를 제공하여 피해자에게 안전을 즉각적으로 보장하기 위함이다."}
{"patent_id": "10-2022-0108230", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 한 실시예에 따른 위기 대응 관제 시스템은, 사용자를 촬영한 제1 영상데이터와 현장을 촬영한 제2 영상데이터를 제공받는 입력모듈, 사용자의 위치와 사용자의 위치를 기준으로 미리 설정된 범위 이내의 적어도 하나의 위기대응관리자의 위치를 추출하는 위치모듈 및 적어도 하나의 위기대응관리자 중 어느 하나의 위기대응 관리자와 사용자를 매칭하여 위기대응관리자의 단말로 제1 및 제2 영상데이터를 전송하고 사용자의 위치로 출동 하도록 출동신호를 제공하는 제어모듈을 포함한다. 또한, 본 발명의 한 실시예에 따른 제1 영상데이터는 사용자의 단말기에서 위기 대응 애플리케이션이 실행된 상 태에서 사용자의 단말기에 구비된 전면카메라를 이용하여 획득되고, 제2 영상데이터는 사용자의 단말기에서 위 기 대응 애플리케이션이 실행된 상태에서 사용자의 단말기에 구비된 후면카메라를 이용하여 획득된다. 또한, 본 발명의 한 실시예에 따른 위기 대응 관제 시스템은, 제1 및 제2 영상데이터를 인공지능에 기반한 영상 처리하여 현장에서 사고를 유발한 객체의 인상착의, 형태 및 도주여부와 사용자의 부상종류 및 부상정도를 판단 하는 상황판단 인공지능 모듈을 더 포함한다. 또한, 본 발명의 한 실시예에 따른 제어모듈은, 미리 설정된 범위 이내이고 사용자와 최인접거리에 위치하는 위 기대응관리자의 단말에 제1 및 제2 영상데이터와 인상착의, 형태, 도주여부, 부상종류, 및 부상정도에 대한 데 이터를 전송하고 사용자의 위치로 출동하도록 제어한다. 또한, 본 발명의 한 실시예에 따른 제어모듈은, 사용자와 최인접거리에 위치하는 위기대응관리자의 단말로부터 사용자의 위치로 출동할 수 없는 출동불가신호를 제공받은 경우, 미리 설정된 범위 이내이고 사용자와 차인접거 리에 위치하는 위기대응관리자의 단말에 제1 및 제2 영상데이터와 인상착의, 형태, 도주여부, 부상종류, 및 부 상정도에 대한 데이터를 전송하고 사용자의 위치로 출동하도록 제어한다. 또한, 본 발명의 한 실시예에 따른 제어모듈은, 사용자와 매칭된 위기대응관리자의 단말기에 위기 대응 애플리 케이션을 통해 제1 영상데이터를 디스플레이하는 제1 윈도우와 제2 영상데이터를 디스플레이하는 제2 윈도우와 사용자의 위치에 해당하는 제1 위치핀과 적어도 하나 이상의 위기대응관리자의 위치에 해당하는 제2 위치핀을 디스플레이하는 제3 윈도우와 사용자와 현장을 녹화하여 제1 및 제2 영상데이터를 저장할 수 있는 제1 버튼과 적어도 하나 이상의 위기대응관리자에게 구조요청을 위한 전화를 할 수 있는 제2 버튼과 위기 대응 애플리케이 션에 사용자가 미리 지정한 지정자에게 구조요청을 위한 전화를 할 수 있는 제3 버튼이 디스플레이되도록 제어 한다. 또한, 본 발명의 한 실시예에 따른 위기 대응 관제 시스템은, 사용자의 운전가능여부 또는 보행가능여부에 기초 하여 현장에서 미리 설정된 안전장소로 이동하는 경로를 생성하는 경로생성모듈을 더 포함한다. 또한, 본 발명의 한 실시예에 따른 경로생성모듈은, 사용자가 운전이 가능한 경우 현장에서 안전장소로 차량을 통해 이동하기 위한 차량이동경로를 생성하고, 사용자가 보행이 가능한 경우 현장에서 안전장소로 미리 저장된 안심보행경로를 통해 이동하기 위한 보행이동경로를 생성한다. 또한, 본 발명의 한 실시예에 따른 제어모듈은, 사용자가 운전이 가능한 경우, 사용자의 단말에서 차량이동경로 를 디스플레이하고 안전장소로 이동하는 이동방법을 음성을 출력하도록 제어한다. 또한, 본 발명의 한 실시예에 따른 제어모듈은, 사용자가 보행이 가능한 경우, 사용자의 단말에 보행이동경로를 디스플레이하고 안전장소로 이동하는 과정을 음성을 출력하도록 제어한다. 또한, 본 발명의 한 실시예에 따른 사용자의 단말과 적어도 하나의 위기대응관리자의 단말의 양방향통신을 통해 범죄를 대응하기 위한 위기 대응 애플리케이션에 있어서, 위기 대응 애플리케이션은 사용자를 촬영한 제1 영상 데이터를 디스플레이하는 제1 윈도우, 범죄가 발생된 현장을 촬영한 제2 영상데이터를 디스플레이하는 제2 윈도 우, 사용자의 위치에 해당하는 제1 위치핀과 사용자의 위치를 기준으로 미리 설정된 범위 이내의 적어도 하나의 위기대응관리자의 위치에 해당하는 제2 위치핀을 디스플레이하는 제3 윈도우, 사용자의 단말 또는 적어도 하나 의 위기대응관리자의 단말 중 어느 하나의 단말로부터 입력된 신호에 의해 사용자와 현장을 녹화하여 제1 및 제 2 영상데이터를 저장할 수 있는 제1 버튼, 적어도 하나 이상의 위기대응관리자에게 구조요청을 위한 전화를 할 수 있는 제2 버튼 및 사용자가 미리 지정한 지정자에게 구조요청을 위한 전화를 할 수 있는 제3 버튼이 실행한 다. 또한, 본 발명의 한 실시예에 따른 위기 대응 관제 방법은, 입력모듈에 의해 사용자를 촬영한 제1 영상데이터와 현장을 촬영한 제2 영상데이터를 제공받는 단계, 위치모듈에 의해 사용자의 위치 및 사용자의 위치를 기준으로 미리 설정된 범위 이내의 적어도 하나의 위기대응관리자의 위치를 추출하는 단계 및 제어모듈에 의해 적어도 하 나의 위기대응관리자 중 어느 하나의 위기대응관리자와 사용자를 매칭하여 위기대응관리자의 단말로 제1 및 제2 영상데이터를 전송하고 사용자의 위치로 출동하도록 출동신호를 제공하는 단계를 포함한다."}
{"patent_id": "10-2022-0108230", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 위기 대응 애플리케이션, 위기 대응 관제 시스템 및 위기 대응 관제 방법은, 범죄현장에서 발생 된 범죄사건에 대하여 영상을 통해 증거를 객관적으로 채증할 수 있어 범죄사건에 대한 피해자의 입증책임을 최 소화시킬 수 있다. 또한, 본 발명에 따른 위기 대응 애플리케이션, 위기 대응 관제 시스템 및 위기 대응 관제 방법은, 범죄현장을 피해자 뿐만 아니라 관리자 및/또는 경찰관 등이 서로 공유함으로써 심리적 또는 상황적 요인으로 인해 즉각적 인 대응을 할 수 없는 피해자를 대신해 경찰관 등을 신속하게 배정하고 출동시킬 수 있다. 또한, 본 발명에 따른 위기 대응 애플리케이션, 위기 대응 관제 시스템 및 위기 대응 관제 방법은, 현재 위치 또는 범죄현장에서 피해자가 신속하게 탈출 또는 이동하기 위한 이동경로를 다양한 방법으로 제공하여 피해자에 게 안전을 즉각적으로 보장할 수 있다."}
{"patent_id": "10-2022-0108230", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참고로 하여 본 발명의 여러 실시 예들에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예들에 한정되지 않는다. 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조 부호를 붙이도록 한다. 따라서 앞서 설명한 참조 부호는 다른 도면에 서도 사용할 수 있다. 또한, 도면에서 나타난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나타내었으므로, 본 발명이 반드 시 도시된 바에 한정되지 않는다. 도면에서 여러 층 및 영역을 명확하게 표현하기 위하여 두께를 과장되게 나 타낼 수 있다. 또한, 설명에서 \"동일하다\"라고 표현한 것은, \"실질적으로 동일하다\"는 의미일 수 있다. 즉, 통상의 지식을 가 진 자가 동일하다고 납득할 수 있을 정도의 동일함일 수 있다. 그 외의 표현들도 \"실질적으로\"가 생략된 표현들 일 수 있다. 또한, 설명에서 어떤 부분이 어떤 구성요소를 '포함'한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 사용되는 '~부'는 적어도 하나의 기능이나 동작을 처리하는 단위로서, 예를 들어 소프트웨어, FPGA 또는 하드웨어 구성요 소를 의미할 수 있다. '~부'에서 제공하는 기능은 복수의 구성요소에 의해 분리되어 수행되거나, 다른 추가적인 구성요소와 통합될 수도 있다. 본 명세서의 '~부'는 반드시 소프트웨어 또는 하드웨어에 한정되지 않으며, 어드 레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고, 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 이하에서는 도면을 참조하여 본 발명의 실시예에 대해서 구체적으로 설명하기로 한다. 도 1은 본 발명의 한 실시예에 따른 위기 대응 관제 시스템, 사용자의 단말, 및 위기대응관리자의 단말에 관한 도면이다. 사용자의 단말은 사용자(예를 들어, 범죄현장의 피해자)가 소유한 휴대폰, 스마트 워치 등에 해당할 수 있다. 사용자의 단말에는 네트워크를 통해서 위기대응관제시스템이 제공하는 위기 대응 애플리케이션 (도 2 참고)이 다운로드 되어 설치될 수 있다. 사용자의 단말에서 상기 위기 대응 애플리케이션이 실행될 수 있으며, 위기대응관리자(예를 들어, 경찰, 방 범순찰대, 경비원, 구급대원, 서비스 관리자 등)로부터 위기 대응을 위한 서비스를 제공받을 수 있다. 위기대응관리자의 단말은 위기대응관리자가 소유한 휴대폰, 스마트 워치 등에 해당할 수 있다. 위기대응관리 자의 단말에는 네트워크를 통해서 위기대응관제시스템이 제공하는 위기 대응 애플리케이션이 다운로드 되어 설치될 수 있다. 위기대응관리자의 단말에서 위기 대응 애플리케이션이 실행될 수 있으며, 위기 대응 애플리케이션을 통해 사 용자에게 위기 대응을 위한 서비스를 제공할 수 있다. 본 발명의 한 실시예에 따른 위기대응관제시스템은 입력모듈, 위치모듈, 상황판단 인공지능모듈 , 제어모듈, 및 경로생성모듈을 포함할 수 있다. 본 발명의 한 실시예에 따른 위기대응관제시스템을 구동시키기 위해 도 1에 도시된 구성요소 보다 더 적은 구성요소 또는 더 많은 구성요소를 포함할 수 있다. 위기대응관제시스템은 네트워크를 통해 사용자의 단말 및 적어도 하나 이상의 위기대응관리자의 단말 과 무선 데이터 송수신을 수행할 수 있다. 입력모듈은 사용자의 단말로부터 사용자를 촬영한 영상데이터(이하, 제1 영상데이터라 명명함)를 제공받 을 수 있다. 입력모듈은 사용자의 단말로부터 현장을 촬영한 영상데이터(이하, 제2 영상데이터라 명명함)를 제공받을 수 있다. 위치모듈은 GPS 기술 등을 이용하여 사용자의 위치를 추출할 수 있다. 위치모듈은 GPS 기술 등을 이용 하여 사용자의 위치를 기준으로 미리 설정된 범위 이내의 적어도 하나의 위기대응관리자의 위치를 추출할 수 있 다. 이때, 미리 설정된 범위는 서비스 관리자 등에 의해 다양하게 설정될 수 있다. 예를 들어, 미리 설정된 범위는 100m, 200m, 500m, 800m, 1km, 쪋 등으로 설정될 수 있다. 상황판단 인공지능모듈에는 상황을 판단하고 감지하기 위한 인공지능 프로그램이 설치되어 있을 수 있다. 예를 들어, 상황판단 인공지능모듈에 설치된 인공지능 프로그램은 DCGAN(Deep Convolutional Generative Adversarial Network)에 해당할 수 있다. 이때, DCGAN이란, GAN(Generative Adversarial Network)의 대표적인 모델로서, GAN에 컨볼루션망을 적용하여 노이즈를 제거하고 성능을 향상된 고화질의 이미지를 생성하는 인공지능모델을 의미한다. 상황판단 인공지능모듈은 입력모듈로부터 제1 및 제2 영상데이터를 제공받을 수 있다. 상황판단 인공지 능모듈은 DCGAN을 이용하여 제1 및 제2 영상데이터를 영상처리하여 노이즈를 제거하고 고화질의 이미지를 생성할 수 있다. 상황판단 인공지능모듈은 영상처리된 제1 및 제2 영상데이터를 이용하여 사고를 유발한 객체의 인상착의, 형태 및 도주여부와 사용자의 부상종류 및 부상정도를 판단할 수 있다. 예를 들어, 상황판단 인공지능모듈은 DCGAN을 이용하여 제2 영상데이터를 영상처리하여 노이즈를 제거하고, 사고를 유발한 객체(예를 들어, 범인)의 얼굴 및 인상착의 등을 판단할 수 있다. 또는, 상황판단 인공지능모듈은 DCGAN을 이용하여 제2 영상데이터를 영상처리하여 노이즈를 제거하고, 사고 를 유발한 객체(예를 들어, 차량)의 종류, 형태, 속도, 이동방향, 번호판 등을 판단할 수 있다. 또는, 상황판단 인공지능모듈은 DCGAN을 이용하여 제2 영상데이터를 영상처리하여 노이즈를 제거하고, 사고 를 유발한 객체(예를 들어, 범인, 차량)의 도주여부를 판단할 수 있다. 또는, 상황판단 인공지능모듈은 DCGAN을 이용하여 제1 영상데이터를 영상처리하여 노이즈를 제거하고, 사용 자의 부상종류 및 부상정도를 판단할 수 있다. 또는, 상황판단 인공지능모듈은 DCGAN을 이용하여 제2 영상데이터를 영상처리하여 노이즈를 제거하고, 현장 의 부상종류(예를 들어, 차량충돌) 및 부상정도(예를 들어, 차량의 파손정도)를 판단할 수 있다. 제어모듈은 사용자와 적어도 하나의 위기대응관리자 중 어느 하나의 위기대응관리자를 매칭할 수 있다. 제 어모듈은 매칭된 위기대응관리자의 단말로 사용자의 단말로부터 제공된 제1 및 제2 영상데이터를 전 송할 수 있다. 제어모듈은 매칭된 위기대응관리자가 사용자의 위치로 출동할 수 있도록 출동신호를 제공할 수 있다. 제어모듈은 후술할 경로생성모듈에서 생성된 차량이동경로 또는 보행이동경로가 사용자의 단말에서 실행된 위기 대응 애플리케이션에서 디스플레이되도록 제어할 수 있다. 또한, 제어모듈은 후술할 경로생성모듈에서 생성된 차량이동경로 또는 보행이동경로에 따라 안전장소로 이동하는 이동방법을 음성을 통해 사용자의 단말에서 출력되도록 제어할 수 있다. 경로생성모듈은 사용자의 운전가능여부 또는 보행가능여부에 기초하여 현장에서 미리 설정된 안전장소로 이 동하는 경로를 생성할 수 있다. 경로생성모듈은 사용자가 운전이 가능한 경우 현장에서 미리 설정된 안전장소로 차량을 통해 이동하기 위한 차량이동경로를 생성할 수 있다. 또한, 경로생성모듈은 사용자가 보행이 가능한 경우 현장에서 미리 설정된 안전장소로 안심보행경로를 통해 이동하기 위한 보행이동경로를 생성할 수 있다. 이때, 미리 설정된 안전장소란 사용자 또는 서비스 관리자에 의해 미리 설정된 장소로서 경찰서, 파출소, 병원, 부모님 집, 친구 집 등 현장에서 신속하게 탈출하여 안전을 즉각적으로 보장할 수 있는 장소에 해당한다. 또한, 안심보행경로란 차도와 보도가 분리되지 않은 도로로써 보행자의 안전과 편의를 보장하기 위해 보행자의 통행이 차량 등의 통행에 우선하도록 지정된 도로를 의미한다. 이때, 국내의 경우 상술한 안심보행경로는 보행자 우선도로를 의미할 수 있다. 해외의 경우 상술한 안심보행경 로는 보행전용도로를 의미할 수 있다. 도 2는 본 발명의 한 실시예에 따른 위기 대응 애플리케이션에 관한 도면이다. 도 2(a)에는 위기 대응 애플리케이션이 실행된 사용자의 단말 및 위기대응관리자의 단말의 일 예가 도시 된다. 도 2(a)를 참고하면, 위기 대응 애플리케이션이 실행된 상태에서 사용자의 단말에 구비된 전면카메라를 이용 하여 사용자를 촬영한 경우, 사용자의 영상에 해당하는 제1 영상데이터가 제1 윈도우(WD1)에 디스플레이될 수 있다. 한편, 사용자와 매칭된 위기대응관리자의 단말에는 위기 대응 애플리케이션이 실행된 상태에서 사용자를 촬 영한 제1 영상데이터가 제1 윈도우(WD1)에 공유되어 실시간으로 디스플레이될 수 있다. 위기 대응 애플리케이션이 실행된 상태에서 사용자의 단말에 구비된 후면카메라를 이용하여 현장을 촬영한 경우, 현장의 영상에 해당하는 제2 영상데이터가 제2 윈도우(WD2)에 디스플레이될 수 있다. 한편, 사용자와 매칭된 위기대응관리자의 단말에는 위기 대응 애플리케이션이 실행된 상태에서 현장을 촬영 한 제2 영상데이터가 제2 윈도우(WD2)에 공유되어 실시간으로 디스플레이될 수 있다. 상술한 과정을 통해 위기대응관리자는 사용자의 현재 상태, 부상 종류, 부장 정도를 실시간으로 확인할 수 있을 뿐만 아니라, 현장의 상황 등을 손쉽게 인지하고 판단할 수 있다. 위기 대응 애플리케이션이 실행된 상태에서 사용자의 단말의 제3 윈도우(WD3)에는 사용자의 위치에 해당하는 제1 위치핀(PINuser)과 사용자의 위치를 기준으로 미리 설정된 범위 이내의 적어도 하나의 위기대응관리자의 위 치에 해당하는 제2 위치핀(PINmanager1, PINmanager2, PINmanager3, 쪋)이 디스플레이될 수 있다. 제3 윈도우(WD3)에 디스플레이된 제1 위치핀(PINuser)을 이용하여 사용자는 현재 위치를 판단할 수 있다. 제3 윈도우(WD3)에 디스플레이된 제2 위치핀(PINmanager1, PINmanager2, PINmanager3, 쪋)을 이용하여 사용자의 위 치를 기준으로 미리 설정된 범위 이내에 적어도 하나의 위기대응관리자의 위치를 판단할 수 있다. 위기대응관제시스템의 제어모듈은 자동적으로 사용자와 어느 하나의 위기대응관리자(예를 들어, 사용자 와 최인접거리에 위치하는 위기대응관리자)와 매칭될 수 있을 뿐만 아니라, 제3 윈도우(WD3)에 디스플레이된 제 2 위치핀(PINmanager1, PINmanager2, PINmanager3, 쪋) 중 어느 하나를 선택하여 사용자가 원하는 위기대응관 리자와 사용자를 매칭할 수 있다. 사용자와 매칭된 위기대응관리자의 단말에는 위기 대응 애플리케이션이 실행된 상태에서 사용자의 위치에 해 당하는 제1 위치핀(PINuser)과 매칭된 위기대응관리자의 위치에 해당하는 제2 위치핀(예를 들어, PINmanager3) 및 매칭된 위기대응관리자를 제외한 다른 위기대응관리자의 위치에 해당하는 제2 위치핀(예를 들어, PINmanager1, PINmanager2)이 디스플레이될 수 있다. 상술한 과정을 통해 사용자는 사용자의 현재위치 뿐만 아니라 주변에 위치하는 위기대응관리자의 위치를 손쉽게 확인할 수 있을 뿐만 아니라, 매칭된 위기대응관리자의 위치를 실시간으로 공유받을 수 있다. 또한, 위기대응관제시스템에 의해 위기대응관리자를 자동적으로 매칭받을 수 있을 뿐만 아니라 사용자 본인 이 원하는 위기대응관리자를 직접 선택할 수 있다. 사용자의 단말 및 위기대응관리자의 단말에는 사용자와 현장을 녹화하여 제1 및 제2 영상데이터를 저장할 수 있는 제1 버튼(BT1)이 디스플레이될 수 있다. 사용자의 단말에서 제1 버튼(BT1)이 클릭되는 경우, 사용자와 현장을 녹화하여 제1 및 제2 영상데이터를 저 장할 수 있다. 또한, 위기대응관리자의 단말에 제1 버튼(BT1)이 클릭되는 경우, 사용자와 현장을 녹화하여 제1 및 제2 영상 데이터를 저장할 수 있다. 상술한 과정을 통해 범죄현장에서 발생된 범죄사건에 대해 영상을 통해 증거를 객관적으로 채증할 수 있어 범죄 사건에 대한 피해자의 입증책임을 감소시킬 수 있다. 또한, 심리적 또는 상황적 요인으로 인해 녹화 등 즉각적인 대응을 할 수 없는 사용자를 대신하여 위기대응관리 자가 사용자와 현장을 녹화하여 제1 및 제2 영상데이터를 저장할 수 있도록 하고, 이를 통해 극심한 트라우마에 빠진 사용자를 대신하여 위기대응관리자가 증거를 채증하게 할 수 있다. 위기 대응 애플리케이션이 실행된 사용자의 단말 및 위기대응관리자의 단말에는 적어도 하나 이상의 위기 대응관리자에게 구조요청을 위한 전화를 할 수 있는 제2 버튼(BT2, SOS)이 디스플레이될 수 있다. 사용자의 단말에서 제2 버튼(BT2)이 클릭되는 경우, 위기대응관리자(예를 들어, 112, 119, 또는 위기대응관 리자 등)에게 구조요청을 위한 전화를 할 수 있다. 위기대응관리자(예를 들어, 서비스 제공자, 매칭된 위기대응관리자)의 단말에서 제2 버튼(BT2)이 클릭되는 경우, 다른 위기대응관리자(예를 들어, 112, 119, 또는 다른 위기대응관리자)에게 구조요청을 위한 전화를 할 수 있다. 한편, 사용자의 단말 또는 위기대응관리자의 단말에서 제2 버튼(BT2)이 클릭되는 경우, 다른 위기 대응관 리자(예를 들어, 112, 119)에게 사용자의 단말의 화면을 공유할 수 있는 URL링크 주소가 전송될 수 있다. 이때, 위기대응관리자가 전송된 URL링크 주소를 클릭하여 여는 경우 사용자와 매칭될 수 있으며, 사용자의 단말 로 URL링크 주소를 클릭하여 연 위기대응관리자의 출동메세지를 전송할 수 있다. 상술한 과정을 통해 범죄사건이 발생된 경우, 사용자는 위기대응관리자에게 전화를 걸어 즉각적인 구조를 요청 할 수 있을 뿐만 아니라 통화를 통해 심리적인 안정감 또는 다양한 구조 서비스 등을 제공받을 수 있다. 또한, 매칭된 위기대응관리자가 출동이 불가능한 경우, 사용자를 대신하여 다른 위기대응관리자에게 전화를 걸 어 사용자의 즉각적인 구조를 대신 요청할 수 있다. 또한, 사용자가 제2 버튼(BT2)을 클릭함과 동시에 사용자의 단말의 화면을 공유할 수 있는 URL링크를 위기대 응관리자의 단말로 전송할 수 있으며, URL링크를 클릭하여 여는 경우 사용자와 매칭시켜 사용자에게 즉각적 으로 출동하도록 할 수 있다. 사용자의 단말에서 제3 버튼(BT3)이 클릭되는 경우, 미리 지정된 지정자(예를 들어, 가족, 친구, 보호자 등)에게 구조요청을 위한 전화를 할 수 있다. 또한, 위기대응관리자(예를 들어, 서비스 제공자, 적어도 하나의 위기대응관리자)의 단말에서 제3 버튼(BT 3)이 클릭되는 경우, 미리 지정된 지정자(예를 들어, 가족, 친구, 보호자 등)에게 구조요청을 위한 전화를 할 수 있다. 상술한 과정을 통해 범죄사건이 발생된 경우, 사용자는 미리 지정된 지정자에게 전화를 걸어 즉각적인 구조를 요청할 수 있을 뿐만 아니라, 통화를 통해 심리적인 안정감 또는 다양한 구조 서비스 등을 제공받을 수 있다. 또한, 사용자를 대신하여 위기대응관리자가 미리 지정된 지정자에게 전화를 걸어 사용자의 위험상황을 알리고 즉각적인 구조를 요청할 수 있다. 도 2(b)에는 위기 대응 애플리케이션이 실행된 사용자의 단말 및 위기대응관리자의 단말의 다른 예가 도 시된다. 도 2(b)를 참고하면, 위기 대응 애플리케이션이 실행된 상태에서 사용자 또는 위기대응관리자가 사용자의 단말 또는 위기대응관리자의 단말의 측면에 구비된 전원버튼을 누르는 경우(예를 들어, 7초 이상 누르는 경우), 제3 윈도우(WD3)에 디스플레이된 모든 위치핀에 대응하는 단말(3, 4)로 URL링크가 전송될 수 있다. 즉, 위기상황에 처한 사용자가 사용자의 단말의 측면에 구비된 전원버튼을 클릭하는 경우, 위기대응관제시스 템에 미리 등록되어 있으며, 사용자의 위치에 해당하는 제1 위치핀(PINuser)을 기준으로 미리 설정된 범위 이내인 제2 위치핀((PINmanager1, PINmanager2, PINmanager3, 쪋)에 대응하는 위기대응관리자의 단말 모두 와 다른 사용자의 단말에 URL링크를 송부할 수 있다. URL링크를 송부받은 위기대응관리자 또는 다른 사용자가 URL링크를 클릭하는 경우 위기 대응 애플리케이션이 실 행될 수 있으며, 위기대응관리자의 단말 또는 다른 사용자의 단말의 제1 윈도우(WD1)에는 사용자의 영상에 해당하는 제1 영상데이터가 디스플레이될 수 있다. 또한, 위기대응관리자의 단말 또는 다른 사용자의 단말의 제2 윈도우(WD2)에는 현장의 영상에 해당하는 제2 영상데이터가 디스플레이될 수 있다. 또한, 위기대응관리자의 단말 또는 다른 사용자의 단말의 제3 윈도우(WD3)에는 URL을 전송한 사용자의 위치 에 해당하는 제1 위치핀(PINuser), 적어도 하나 이상의 위기대응관리자의 위치에 해당하는 제2 위치핀 ((PINmanager1, PINmanager2, PINmanager3, 쪋), 및 URL을 전송받은 다른 사용자의 위치에 해당하는 위치핀이 디스플레이될 수 있다. 상술한 과정을 통해 위기상황에 처한 사용자는 사용자의 위치를 기준으로 미리 설정된 범위 이내에 위치하는 다 수에게 구조요청(이하, 스프레드 확산 모드라 명명함)을 할 수 있으며, 범인이 도주하는 경우 도주 중인 범인을 기준으로 전방위에서 포위하여 추적할 수 있다. 또한, 위기 대응 애플리케이션이 실행된 상태에서 사용자 또는 위기대응관리자가 사용자의 단말 또는 위기대 응관리자의 단말의 측면에 구비된 음량버튼을 누르는 경우(예를 들어, 3초 이상 누르는 경우), 사용자의 단 말의 화면은 꺼지는 동시에 위기 대응 애플리케이션은 백그라운드 실행(이하, 스텔스 모드라 명명함)될 수있다. 상술한 과정을 통해, 위기상황에 처한 사용자 또는 위기대응관리자가 사용자를 대신하여 사용자의 단말의 화 면을 끌 수 있으며, 이를 통해, 현장에 위치하는 범인으로부터 증거를 채증하는 사용자를 보호할 수 있다. 한편, 스텔스 모드가 실행되더라도 위기 대응 애플리케이션은 백그라운드 실행될 수 있으므로 사용자의 영상에 해당하는 제1 영상데이터와 현장의 영상에 해당하는 제2 영상데이터를 확보할 수 있다. 또한, 사용자 또는 위기대응관리자는 단말(3, 4)의 측면에 구비된 음량버튼을 다시 눌러 사용자의 단말의 화 면을 다시 켤 수 있으므로, 사용자의 편이성을 극대화시킬 수 있다. 도 3(a)는 본 발명의 한 실시예에 따른 범죄사건에서 영상을 통해 증거를 획득하고 위기대응관리자를 배정하는 과정에 관한 흐름도이다. 단계(S10)에서 사용자와 현장이 촬영될 수 있다. 구체적으로, 사용자의 단말에서 위기 대응 애플리케이션이 실행된 상태에서 사용자의 단말에 구비된 전면 카메라를 이용하여 사용자를 촬영하고 제1 영상데이터를 획득할 수 있다. 또한, 사용자의 단말에서 위기 대응 애플리케이션이 실행된 상태에서 사용자의 단말에 구비된 후면카메라 를 이용하여 현장을 촬영하고 제2 영상데이터를 획득할 수 있다. 이때, 사용자의 단말의 제1 윈도우(WD1)에는 사용자를 촬영한 제1 영상데이터가 디스플레이될 수 있으며, 제 2 윈도우(WD2)에는 현장을 촬영한 제2 영상데이터가 디스플레이될 수 있다. 단계(S11)에서 제1 및 제2 영상데이터를 전송할 수 있다. 구체적으로, 단계(S10)에서 획득된 제1 및 제2 영상데이터는 네트워크를 통해 위기대응관제시스템의 입력 모듈로 제공될 수 있다. 단계(S12)에서 사용자 및 위기대응관리자의 위치를 판단할 수 있다. 구체적으로, 위치모듈은 GPS 기술 등을 이용하여 사용자의 위치 및 위기대응관리자의 위치를 판단할 수 있 다. 이때, 위치모듈은 사용자의 단말의 제3 윈도우(WD3)에 사용자의 위치에 해당하는 제1 위치핀(PINuser)과 미리 설정된 범위 이내의 적어도 하나의 위기대응관리자의 위치에 해당하는 제2 위치핀(PINmanager1, PINmanager2, PINmanager3, 쪋)을 디스플레이할 수 있다. 단계(S13)에서 사용자와 위치대응관리자를 매칭할 수 있다. 구체적으로, 제어모듈은 사용자의 위치를 기준으로 미리 설정된 범위 이내이고 사용자와 최인접거리에 위치 하는 위기대응관리자와 사용자를 매칭할 수 있다. 단계(S14)에서 제1 및 제2 영상데이터와 사용자의 위치를 전송할 수 있다. 구체적으로, 제어모듈은 매칭된 위기대응관리자의 단말에 제1 및 제2 영상데이터와 사용자의 위치를 전 송할 수 있다. 단계(S15)에서 사용자의 위치, 사용자와 현장을 판단할 수 있다. 구체적으로, 매칭된 위기대응관리자의 단말의 제1 윈도우(WD1)에는 사용자를 촬영한 제1 영상데이터가 디스 플레이될 수 있다. 또한, 매칭된 위기대응관리자의 단말의 제2 윈도우(WD2)에는 현장을 촬영한 제2 영상데이터가 디스플레이될 수 있다. 또한, 매칭된 위기대응관리자의 단말의 제3 윈도우(WD3)에는 사용자의 위치에 해당하는 제1 위치핀(PINuse r)과 매칭된 위기대응관리자의 위치에 해당하는 제2 위치핀(예를 들어, PINmanager3)과 사용자의 위치를 중심으 로 미리 설정된 범위 이내에 위치하는 다른 위기대응관리자의 위치에 해당하는 제2 위치핀(예를 들어, PINmanager1, PINmanager2, 쪋)이 디스플레이될 수 있다. 단계(S16)에서 출동신호를 전송할 수 있다. 구체적으로, 매칭된 위기대응관리자의 단말에서 출동신호가 위기대응관제시스템으로 제공될 수 있으며, 위기대응관제시스템의 제어모듈은 매칭된 위기대응관리자의 단말로부터 제공된 출동신호를 사용자의 단말로 제공할 수 있다. 단계(S17)에서 사용자의 단말은 위기대응관리자의 위치를 디스플레이할 수 있다. 구체적으로, 사용자의 단말의 제3 윈도우(WD3)에는 매칭된 위기대응관리자의 현재 위치에 해당하는 제2 위치 핀(예를 들어, PINmanager3)이 디스플레이될 수 있다. 상술한 과정을 통해, 범죄현장에서 발생된 범죄사건에 대해 영상을 통해 증거를 객관적으로 채증할 수 있고, 위 기대응관리자가 범죄현장을 함께 공유할 수 있다. 또한, 심리적 또는 상황적 요인으로 인해 즉각적인 대응을 할 수 없는 피해자를 대신해 위기대응관리자를 신속하게 배정하고 출동시킬 수 있다. 도 3(b)는 본 발명의 한 실시예에 따른 범죄사건에서 영상을 통해 증거를 획득하고 위기대응관리자를 배정하는 과정에 관한 흐름도이다. 이하, 도 3(b)에서는 상술한 도 3(a)와 실질적으로 동일하거나 유사하여 중복되는 설명은 생략하기로 한다. 단계(S20)에서 사용자의 단말에서 위기 대응 애플리케이션을 통해 사용자를 촬영한 제1 영상데이터 및 현장 을 촬영한 제2 영상데이터가 획득될 수 있다. 단계(S21)에서 사용자의 단말에서 네트워크를 통해 위기대응관제시스템의 입력모듈로 제1 및 제2 영상데이터가 제공될 수 있다. 단계(S22)에서 위치모듈은 GPS 기술 등을 이용하여 사용자의 위치 및 사용자의 위치를 기준으로 미리 설정 된 범위 이내에 위치하는 위기대응관리자의 위치를 판단할 수 있다. 단계(S23)에서 제어모듈은 사용자의 위치에서 미리 설정된 범위 이내이고 사용자와 최인접거리에 위치하는 위기대응관리자와 사용자를 매칭할 수 있다. 단계(S24)에서 제어모듈은 매칭된 위기대응관리자의 단말에 제1 및 제2 영상데이터와 사용자의 위치를 전송할 수 있다. 단계(S25)에서 매칭된 위기대응관리자는 단말을 통해 제1 영상데이터 및 제2 영상데이터를 이용하여 사용자 와 현장을 확인할 수 있다. 구체적으로, 위기대응관리자의 단말의 제3 윈도우(WD3)에는 사용자의 위치에 해당하는 제1 위치핀(PINuser) 과 매칭된 위기대응관리자의 위치에 해당하는 제2 위치핀(예를 들어, PINmanager3)과 사용자의 위치를 중심으로 미리 설정된 범위 이내에 위치하는 다른 위기대응관리자의 위치에 해당하는 제2 위치핀(예를 들어, PINmanager1, PINmanager2, 쪋)이 디스플레이될 수 있다. 단계(S26)에서 출동불가신호를 제공할 수 있다. 구체적으로, 매칭된 위기대응관리자가 사용자의 위치로 출동할 수 없는 경우에 출동불가신호가 위기대응관제시 스템으로 제공될 수 있다. 단계(S27)에서 사용자와 위기대응관리자를 매칭할 수 있다. 구체적으로, 제어모듈은 미리 설정된 범위 이내이고, 사용자와 차인접거리에 위치하는 위기대응관리자와 사 용자를 매칭할 수 있다. 단계(S28)에서 제1 및 제2 영상데이터와 사용자의 위치를 전송할 수 있다. 구체적으로, 제어모듈은 매칭된 위기대응관리자의 단말에 제1 및 제2 영상데이터와 사용자의 위치를 전 송할 수 있다. 단계(S29)에서 사용자의 위치, 사용자와 현장을 판단할 수 있다. 구체적으로, 매칭된 위기대응관리자의 단말의 제1 윈도우(WD1)에는 사용자를 촬영한 제1 영상데이터가 디스 플레이될 수 있다. 또한, 매칭된 위기대응관리자의 단말의 제2 윈도우(WD2)에는 현장을 촬영한 제2 영상데이터가 디스플레이될 수 있다. 또한, 매칭된 위기대응관리자의 단말의 제3 윈도우(WD3)에는 사용자의 위치에 해당하는 제1 위치핀(PINuse r)과 매칭된 위기대응관리자의 위치에 해당하는 제2 위치핀(예를 들어, PINmanager2)과 사용자의 위치를 중심으 로 미리 설정된 범위 이내에 위치하는 다른 위기대응관리자의 위치에 해당하는 제2 위치핀(예를 들어, PINmanager1, PINmanager3, 쪋)이 디스플레이될 수 있다. 단계(S30)에서 출동신호를 전송할 수 있다. 구체적으로, 출동신호가 위기대응관제시스템으로 제공될 수 있으며, 위기대응관제시스템의 제어모듈 은 매칭된 위기대응관리자의 단말로부터 제공된 출동신호를 사용자의 단말로 제공할 수 있다. 단계(S31)에서 사용자의 단말은 위기대응관리자의 위치를 디스플레이할 수 있다. 구체적으로, 위기 대응 애플리케이션이 실행된 사용자의 단말의 제3 윈도우(WD3)에는 매칭된 위기대응관리자 의 현재 위치에 해당하는 제2 위치핀(예를 들어, PINmanager2)이 디스플레이될 수 있다. 상술한 과정을 통해, 사용자와 최인접거리에 위치하는 위기대응관리자가 출동이 불가능한 경우, 자동적으로 차 인접거리에 위치하는 위기대응관리자와 사용자를 자동적으로 매칭시키고 신속하게 출동하게 할 수 있다. 도 3(c)는 본 발명의 한 실시예에 따른 범죄사건에서 영상을 통해 증거를 획득하고 위기대응관리자를 배정하는 과정에 관한 흐름도이다. 이하, 도 3(c)에서는 상술한 도 3(a) 및 도 3(b)와 실질적으로 동일하거나 유사하여 중복되는 설명은 생략하기 로 한다. 단계(S40)에서 사용자의 단말에서 위기 대응 애플리케이션을 통해 사용자를 촬영한 제1 영상데이터 및 현장 을 촬영한 제2 영상데이터가 획득될 수 있다. 단계(S41)에서 사용자의 단말에서 입력모듈로 제1 및 제2 영상데이터가 제공될 수 있다. 단계(S42)에서 위치모듈은 GPS 기술 등을 이용하여 사용자의 위치 및 사용자의 위치를 기준으로 미리 설정 된 범위 이내에 위치하는 위기대응관리자의 위치를 추출할 수 있다. 단계(S43)에서 위치모듈은 사용자의 위치 및 사용자의 위치를 기준으로 미리 설정된 범위 이내에 위치하는 적어도 하나의 위기대응관리자의 위치를 사용자의 단말로 제공할 수 있다. 단계(S44)에서 위기대응관리자를 선택할 수 있다. 구체적으로, 사용자의 단말의 제3 윈도우(WD3)에는 사용자의 위치에 해당하는 제1 위치핀(PINuser) 및 사용 자의 위치를 기준으로 미리 설정된 범위 이내에 위치하는 적어도 하나의 위기대응관리자의 위치에 해당하는 제2 위치핀(PINmanager1, PINmanager2, PINmanager3, 쪋)이 디스플레이될 수 있다. 사용자는 제3 윈도우(WD3)에 디스플레이된 제2 위치핀(PINmanager1, PINmanager2, PINmanager3, 쪋) 중 어느 하나를 클릭하여 어느 하나의 제2 위치핀(예를 들어, PINmanager1)에 해당하는 위기대응관리자를 선택할 수 있 다. 단계(S45)에서 제1 및 제2 영상데이터와 사용자의 위치를 전송할 수 있다. 구체적으로, 제어모듈은 사용자의 선택에 기초하여 매칭된 위기대응관리자의 단말에 제1 및 제2 영상데 이터와 사용자의 위치를 전송할 수 있다. 단계(S46)에서 사용자의 위치, 사용자와 현장을 판단할 수 있다. 구체적으로, 매칭된 위기대응관리자의 단말을 통해 제1 영상데이터 및 제2 영상데이터를 이용하여 사용자와 현장을 확인할 수 있으며, 사용자의 위치에 해당하는 제1 위치핀(PINuser)과 매칭된 위기대응관리자의 위치에 해당하는 제2 위치핀(예를 들어, PINmanager1)과 사용자의 위치를 중심으로 미리 설정된 범위 이내에 위치하는 다른 위기대응관리자의 위치에 해당하는 제2 위치핀(예를 들어, PINmanager2, PINmanager3, 쪋)이 디스플레이될수 있다. 단계(S47)에서 출동신호를 전송할 수 있다. 구체적으로, 출동신호가 위기대응관제시스템으로 제공될 수 있으며, 위기대응관제시스템의 제어모듈 은 매칭된 위기대응관리자의 단말로부터 제공된 출동신호를 사용자의 단말로 제공할 수 있다. 단계(S48)에서 사용자의 단말은 위기대응관리자의 위치를 디스플레이할 수 있다. 구체적으로, 위기 대응 애플리케이션이 실행된 사용자의 단말의 제3 윈도우(WD3)에는 매칭된 위기대응관리자 의 현재 위치에 해당하는 제2 위치핀(예를 들어, PINmanager1)이 디스플레이될 수 있다. 상술한 과정을 통해, 사용자가 구조요청을 위한 위기대응관리자를 직접 선택할 수 있으며 접수 지연 등 발생될 수 있는 외부적인 요인들을 미연에 방지할 수 있을 뿐만 아니라 심리적 안정감을 얻을 수 있다. 도 4는 본 발명의 한 실시예에 따른 현재 위치 또는 범죄현장에서 피해자가 탈출 또는 이동하기 위한 이동경로 를 제공하는 과정에 관한 흐름도이다. 단계(S50)에서 사용자를 촬영한 제1 영상데이터와 현장을 촬영한 제2 영상데이터를 제공받을 수 있다. 구체적으로, 입력모듈은 사용자의 단말로부터 사용자를 촬영한 제1 영상데이터와 현장을 촬영한 제2 영 상데이터를 제공받을 수 있다. 단계(S51)에서 제1 및 제2 영상데이터를 영상처리하여 상황을 판단할 수 있다. 구체적으로, 상황판단 인공지능모듈은 입력모듈로부터 제1 및 제2 영상데이터를 제공받을 수 있으며 미 리 설치된 인공지능 프로그램(DCGAN)을 이용하여 영상처리하여 노이즈를 제거하고 고화질의 이미지를 생성할 수 있다. 또한, 상황판단 인공지능모듈은 상기 고화질의 이미지를 이용하여 현장에서 사고를 유발한 객체의 인상착의, 형태 및 도주여부와 사용자의 부상종류 및 부상정도를 판단할 수 있다. 한편, 상황판단 인공지능모듈에 의해 가해자가 범죄현장에서 도주한 것으로 판단된 경우, 제어모듈은 사용자와 최인접거리 또는 차인접거리에 위치하는 위기대응관리자(예를 들어, 경찰관)와 사용자를 매칭하고, 사 용자의 위치로 즉시 출동하도록 제어할 수 있다. 또한, 상황판단 인공지능모듈에 의해 사용자의 부상정도가 심한 것으로 판단된 경우, 제어모듈은 사용 자와 최인접거리 또는 차인접거리에 위치하는 위기대응관리자(예를 들어, 구급대원)와 사용자를 매칭하고, 사용 자의 위치로 즉시 출동하도록 제어할 수 있다. 단계(S52)에서 사용자의 운전가능여부를 판단할 수 있다. 이때, 사용자의 운전가능여부는 위기 대응 애플리케이션에 사용자의 기본정보로써 미리 저장될 수 있으며 경로 생성모듈은 상기 사용자의 기본정보를 이용하여 사용자의 운전가능여부를 판단할 수 있다. 또는, 경로생성모듈은 매칭된 위기대응관리자와 사용자의 의사소통에 의해서 입력된 사용자의 현재정보를 기초로 사용자의 운전가능여부를 판단할 수 있다. 단계(S53)에서 사용자가 운전이 가능한 것으로 판단된 경우 차량으로 이동하기 위한 차량이동경로를 생성할 수 있다. 구체적으로, 경로생성모듈은 현장에서 미리 설정된 안전장소로 차량을 이용하여 이동하기 위한 차량이동경 로를 생성할 수 있다. 단계(S54)에서 차량이동경로를 디스플레이하고 이동방법을 음성으로 출력할 수 있다. 구체적으로, 제어모듈은 사용자의 단말에 경로생성모듈에 의해 생성된 차량이동경로를 디스플레이하 고, 상기 안전장소로 이동하기 위한 이동방법을 음성으로 출력하도록 제어할 수 있다. 단계(S55)에서 사용자가 운전이 불가능한 것으로 판단된 경우 보행이동경로를 생성할 수 있다. 구체적으로, 경로생성모듈은 현장에서 미리 설정된 안전장소로 안심보행경로를 이용하여 이동하기 위한 보 행이동경로를 생성할 수 있다. 단게(S56)에서 보행이동경로를 디스플레이하고 이동방법을 음성으로 출력할 수 있다. 구체적으로, 제어모듈은 사용자의 단말에 보행이동경로를 디스플레이하고, 상기 안전장소로 이동하기 위 한 이동방법을 음성으로 출력하도록 제어할 수 있다. 상술한 과정을 통해, 현재 위치 또는 범죄현장에서 피해자가 신속하게 탈출 또는 이동하기 위한 이동경로를 다 양한 방법으로 제공하여 피해자의 안전을 즉각적으로 보장할 수 있는 효과가 있다. 지금까지 참조한 도면과 기재된 발명의 상세한 설명은 단지 본 발명의 예시적인 것으로서, 이는 단지 본 발명을 설명하기 위한 목적에서 사용된 것이지 의미 한정이나 특허청구범위에 기재된 본 발명의 범위를 제한하기 위하 여 사용된 것은 아니다. 그러므로 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 특허청구 범위의 기술적 사상에 의해 정해져야 할 것이다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(Arithmetic Logic Unit), 디지털 신호 프로세서(Digital Signal Processor), 마 이크로컴퓨터, FPGA(Field Programmable Gate Array), PLU(Programmable Logic Unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있 다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해당 기술 분야에서 통 상의 지식을 가진 자는 처리 장치가 복수 개의 처리 요소(Processing Element) 및/또는 복수 유형의 처리요소를 포함할 수 있음을 이해할 것이다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(Parallel Processor) 와 같은, 다른 처리 구성(Processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(Computer Program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하 여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody) 될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분 산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체 에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CDROM, DVD와 같은 광기록 매체(optical media) 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로 그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러 에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트 웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2022-0108230", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속 한다"}
{"patent_id": "10-2022-0108230", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 한 실시예에 따른 위기 대응 관제 시스템, 사용자의 단말, 및 위기대응관리자의 단말에 관한 도면이다. 도 2는 본 발명의 한 실시예에 따른 위기 대응 애플리케이션에 관한 도면이다. 도 3(a)는 본 발명의 한 실시예에 따른 범죄사건에서 영상을 통해 증거를 획득하고 위기대응관리자를 배정하는 과정에 관한 흐름도이다. 도 3(b)는 본 발명의 한 실시예에 따른 범죄사건에서 영상을 통해 증거를 획득하고 위기대응관리자를 배정하는 과정에 관한 흐름도이다. 도 3(c)는 본 발명의 한 실시예에 따른 범죄사건에서 영상을 통해 증거를 획득하고 위기대응관리자를 배정하는 과정에 관한 흐름도이다. 도 4는 본 발명의 한 실시예에 따른 현재 위치 또는 범죄현장에서 피해자가 탈출 또는 이동하기 위한 이동경로 를 제공하는 과정에 관한 흐름도이다."}
