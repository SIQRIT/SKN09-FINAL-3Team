{"patent_id": "10-2022-0167967", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0083941", "출원번호": "10-2022-0167967", "발명의 명칭": "멀티모달 기반의 사용자 응대형 메타 휴먼 시스템", "출원인": "주식회사 솔트룩스", "발명자": "이경일"}}
{"patent_id": "10-2022-0167967", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메모리를 포함하는 컴퓨팅 장치로 구현되는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템에 있어서,키오스크의 디스플레이를 통해 메타 휴먼이 출력되는 상태에서, 사용자로부터 요청 사항이 포함된 언어 신호 및사용자에 대한 영상 정보를 포함하는 요청 사항 정보를 수신하는 경우, 멀티모달 분석 프로세스를 시작하는 멀티모달 분석 프로세스 시작부;상기 멀티모달 분석 프로세스가 시작되면, 상기 수신된 요청 사항 정보에 포함된 언어 신호에 대응되는 문장에대한 분석을 시작하여, 상기 문장을 구성하는 복수 개의 키워드를 추출해 상기 추출된 복수 개의 키워드 각각에문장 속성이 매칭된 문장 정보를 생성하는 문장 정보 생성부;상기 문장 정보의 생성이 완료되면, 상기 수신된 요청 사항 정보에 포함된 영상 정보에 대한 분석을 시작하여,사용자의 감성 상태를 식별 가능한 감성 속성 정보를 생성한 후, 상기 문장 정보 및 상기 감성 속성 정보를 통해 사용자의 감성 상태가 반영된 요청 사항을 포함하는 감성 반영 요청 정보를 생성하는 감성 반영 요청 정보생성부; 및상기 감성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보를 기반으로, 사용자의 감성 상태가 반영된 요청 사항에 응답하는 감성 반영 응답 정보를 생성하여, 상기 메타 휴먼을 통해 상기 생성된 감성 반영 응답 정보에 기반한 감성 응답을 수행하도록 하는 감성 응답 출력부;를 포함하는 것을 특징으로 하는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템."}
{"patent_id": "10-2022-0167967", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 문장 정보 생성부는,상기 멀티모달 분석 프로세스가 시작되는 경우, 상기 키오스크에 설치된 복수 개의 모듈 중 스피커 모듈을 통해수신한 언어 신호에 대응되는 문장에 포함된 복수 개의 형태소를 식별하여, 상기 문장을 형태소 별로 분해하는문장 분해부; 및상기 문장 분해부의 기능 수행에 의해 상기 문장이 형태소 별로 분해되면, 상기 형태소 별로 분해된 문장에서키워드를 추출해 기 저장된 문장 속성 부여 조건을 통해 상기 추출된 키워드 각각에 문장 속성을 부여하여, 상기 문장 속성이 부여된 키워드를 포함하는 문장에 기반한 문장 정보를 생성하는 문장 속성 부여부;를 포함하는것을 특징으로 하는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템."}
{"patent_id": "10-2022-0167967", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 감성 반영 요청 정보 생성부는,상기 문장 정보의 생성이 완료되면, 상기 키오스크에 설치된 복수 개의 모듈 중 카메라 모듈을 통해 수신한 영상 정보를 기 저장된 영상인식 알고리즘을 통해 분석하여, 상기 분석 결과를 통해 상기 요청 사항 정보 수신 당시 사용자 제스처 및 사용자 표정 중 적어도 하나를 식별하는 사용자 감성 요소 식별부;상기 사용자 감성 요소 식별부의 기능 수행이 완료되면, 기 저장된 감성분석 알고리즘을 통해 상기 사용자 제스처 및 상기 사용자 표정 중 적어도 하나를 분석하여, 분석 결과를 통해 상기 사용자 제스처 및 사용자 표정 중공개특허 10-2024-0083941-3-적어도 하나에 대한 감성 수치를 산출하는 감성 수치 산출부; 및상기 감성 수치의 산출이 완료되면, 기 저장된 감성 상태 테이블을 통해 상기 산출된 감성 수치를 포함하는 감성 범위를 식별하여, 상기 식별된 감성 범위에 대응되는 감성 상태를 상기 요청 사항 정보 수신 당시 사용자의감성 상태로 판단해 상기 식별된 감성 범위에 대응되는 감성 상태에 기반한 감성 속성 정보를 생성하는 감성 속성 정보 생성부;를 포함하는 것을 특징으로 하는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템."}
{"patent_id": "10-2022-0167967", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 감성 반영 요청 정보 생성부는,상기 감성 속성 정보의 생성이 완료되면, 상기 생성된 문장 정보에 상기 생성된 감성 속성 정보를 매칭하여, 사용자의 감성 상태가 반영된 요청 사항에 대한 문장 정보인 감성 반영 요청 정보를 생성하는 것을 특징으로 하는멀티모달 기반의 사용자 응대형 메타 휴먼 시스템."}
{"patent_id": "10-2022-0167967", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 감성 응답 출력부는,상기 감성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보에 포함된 문장 정보를 식별하여, 상기식별된 문장 정보를 구성하는 복수 개의 키워드 각각에 대한 문장 속성을 식별하는 문장 속성 식별부; 및상기 문장 속성 식별부의 기능 수행이 완료되면, 상기 식별된 문장 속성 및 상기 복수 개의 키워드 각각을 기반으로, 지식 베이스에 저장된 복수 개의 질의 응답 정보 중 상기 사용자의 요청 사항에 대응되는 질의 응답 정보를 추출하는 질의 응답 추출부;를 포함하는 것을 특징으로 하는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템."}
{"patent_id": "10-2022-0167967", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 감성 응답 출력부는,상기 질의 응답 정보의 생성이 완료되면, 상기 감성 반영 요청 정보에 포함된 감성 속성 정보를 식별하여, 상기식별된 감성 속성 정보를 기반으로 상기 감성 수치 및 사용자의 감성 상태를 식별하는 감성 속성 식별부;상기 감성 속성 식별부의 기능 수행이 완료되면, 기 저장된 액션 정보 테이블에 저장된 복수 개의 액션 정보 중상기 사용자 제스처 및 상기 사용자 표정 중 적어도 하나에 대응되는 긍정 액션 정보 및 부정 액션 정보를 식별하는 액션 정보 식별부; 및상기 액션 정보 식별부의 기능 수행이 완료되면, 식별된 긍정 액션 정보 및 부정 액션 정보 중 상기 식별된 감성 수치에 대응되는 하나를 감성 대응 액션 정보로 추출하는 감성 대응 액션 정보 추출부;를 더 포함하는 것을특징으로 하는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템."}
{"patent_id": "10-2022-0167967", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 기 저장된 액션 정보 테이블은,긍정 액션 카테고리 및 부정 액션 카테고리로 구성된 데이터테이블로써, 상기 긍정 액션 카테고리 및 상기 부정액션 카테고리 각각마다 사용자 제스처 및 상기 사용자 표정 중 적어도 하나에 대응되는 액션 정보를 포함하고공개특허 10-2024-0083941-4-있는 것을 특징으로 하는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템."}
{"patent_id": "10-2022-0167967", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 감성 응답 출력부는,상기 질의 응답 추출부 및 상기 감성 대응 액션 정보 추출부의 기능 수행이 완료되면, 상기 질의 응답 정보 및상기 감성 대응 액션 정보를 통해 사용자의 요청 사항에 응답하는 감성 반영 응답 정보를 생성하는 감성 반영응답 정보 생성부; 및상기 감성 반영 응답 정보의 생성이 완료되면, 상기 디스플레이를 통해 출력 중인 메타 휴먼에게 상기 감성 반영 응답 정보를 반영하여, 상기 메타 휴먼으로 하여금 상기 감성 반영 응답 정보의 질의 응답 정보에 기반한 응답을 출력하도록 하고, 상기 감성 반영 응답 정보의 감성 대응 액션 정보에 기반한 감성 액션을 수행하도록 하는 메타 휴먼 응답 출력부;를 더 포함하는 것을 특징으로 하는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템."}
{"patent_id": "10-2022-0167967", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메모리를 포 함하는 컴퓨팅 장치로 구현되는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템에 있어서, 키오스크의 디스플 레이를 통해 메타 휴먼이 출력되는 상태에서, 사용자로부터 요청 사항이 포함된 언어 신호 및 사용자에 대한 영 (뒷면에 계속)"}
{"patent_id": "10-2022-0167967", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템에 관한 것으로서, 구체적으로는 메타 휴먼이 출력 되는 키오스크를 통해 사용자로부터 요청 사항이 포함된 언어 신호 및 사용자에 대한 영상 정보를 포함하는 요 청 사항 정보를 수신 시, 요청 사항 정보에 포함된 언어 신호에 대한 분석을 시작해 언어 신호에 대응되는 문장 에 대응되는 문장 정보를 획득하고, 요청 사항 정보에 포함된 영상 정보에 대한 분석을 시작해 사용자의 제스처 및 표정에 기반한 감성 속성 정보를 생성해 문장 정보와 감성 속성 정보를 통해 사용자의 감성 상태가 반영된 요청 사항을 포함하는 감성 반영 요청 정보를 생성하고, 생성된 감성 반영 요청 정보를 분석해 사용자의 감성 상태가 반영된 요청 사항에 응답하는 감성 반영 응답 정보를 생성해 메타 휴먼을 통해 출력하도록 하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0167967", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "\"멀티모달\"은 인터넷 환경에서 센서 정보 등 다양한 입력 요소를 통해 상호 간 통신하는 인간 중심형 인터페이 스 기술로써, 다양한 자원으로부터 수집된 데이터로 하나의 정보를 표현하는 기술을 의미한다. 이러한 멀티모달 기술은 다양한 영역에서 활용되고 있는데, 대표적으로 정보 전달을 위한 커뮤니케이션 영역에서 적극적으로 도 입을 추진하고 있다. 일반적으로 정보 전달을 위한 커뮤니케이션에서 언어가 차지하는 비율은 7%로 그 영향이 매우 미비하다. 이에 따라, 업계에서는 멀티모달 기술을 활용해 언어뿐만 아니라 사용자의 제스처, 시선 교환, 표정 등을 복합적으로 분석해 사용자의 감성에 기반한 커뮤니케이션을 수행하도록 하기 위한 다양한 기술들을 개발하고 있다. 일 예로서, 한국공개특허 10-2022-0063816(멀티모달 감성 분석 시스템 및 방법)에는 멀티모달 기반의 기술을 통 해 사용자의 감성을 분석하는 기술이 개시되어 있다. 그러나, 상술한 선행기술에서는 단순히 사용자 동영상을 통해 사용자의 얼굴 이미지를 분석하여 사용자의 감성 상태를 판단하는 기술만이 개시되어 있을 뿐, 메타 휴먼이 출력되는 키오스크를 통해 사용자로부터 요청 사항이 포함된 언어 신호 및 사용자에 대한 영상 정보를 포함하는 요청 사항 정보를 수신 시, 요청 사항 정보에 포함된 언어 신호에 대한 분석을 시작해 언어 신호에 대응되는 문장에 대응되는 문장 정보를 획득하고, 요청 사항 정보 에 포함된 영상 정보에 대한 분석을 시작해 사용자의 제스처 및 표정에 기반한 감성 속성 정보를 생성해 문장 정보와 감성 속성 정보를 통해 사용자의 감성 상태가 반영된 요청 사항을 포함하는 감성 반영 요청 정보를 생성 하고, 생성된 감성 반영 요청 정보를 분석해 사용자의 감성 상태가 반영된 요청 사항에 응답하는 감성 반영 응 답 정보를 생성해 메타 휴먼을 통해 출력하도록 하는 기술은 개시되어 있지 않아, 이를 해결할 수 있는 기술의"}
{"patent_id": "10-2022-0167967", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "필요성이 대두되고 있다.발명의 내용"}
{"patent_id": "10-2022-0167967", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에 본 발명은, 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템을 통해 메타 휴먼이 출력되는 키오스크를 통 해 사용자로부터 요청 사항이 포함된 언어 신호 및 사용자에 대한 영상 정보를 포함하는 요청 사항 정보를 수신 시, 요청 사항 정보에 포함된 언어 신호에 대한 분석을 시작해 언어 신호에 대응되는 문장에 대응되는 문장 정 보를 획득하고, 요청 사항 정보에 포함된 영상 정보에 대한 분석을 시작해 사용자의 제스처 및 표정에 기반한 감성 속성 정보를 생성해 문장 정보와 감성 속성 정보를 통해 사용자의 감성 상태가 반영된 요청 사항을 포함하 는 감성 반영 요청 정보를 생성하고, 생성된 감성 반영 요청 정보를 분석해 사용자의 감성 상태가 반영된 요청 사항에 응답하는 감성 반영 응답 정보를 생성해 메타 휴먼을 통해 출력하도록 함으로써, 사용자의 감성 상태에 적합한 제스처나 표정을 메타 휴먼이 취하도록 해 사용자의 집중도 및 효율성이 향상된 커뮤니케이션 서비스를 제공하는 것에 그 목적이 있다."}
{"patent_id": "10-2022-0167967", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메모리를 포함하는 컴퓨팅 장치로 구현되는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템에 있어서, 키오스크의 디스플레이를 통해 메타 휴먼이 출력되는 상태에서, 사용자로부터 요청 사항이 포함된 언어 신호 및 사용자에 대한 영상 정보를 포함하는 요청 사항 정보를 수신하는 경우, 멀티모달 분석 프로세스를 시작하는 멀 티모달 분석 프로세스 시작부; 상기 멀티모달 분석 프로세스가 시작되면, 상기 수신된 요청 사항 정보에 포함된 언어 신호에 대응되는 문장에 대한 분석을 시작하여, 상기 문장을 구성하는 복수 개의 키워드를 추출해 상기 추 출된 복수 개의 키워드 각각에 문장 속성이 매칭된 문장 정보를 생성하는 문장 정보 생성부; 상기 문장 정보의 생성이 완료되면, 상기 수신된 요청 사항 정보에 포함된 영상 정보에 대한 분석을 시작하여, 사용자의 감성 상 태를 식별 가능한 감성 속성 정보를 생성한 후, 상기 문장 정보 및 상기 감성 속성 정보를 통해 사용자의 감성 상태가 반영된 요청 사항을 포함하는 감성 반영 요청 정보를 생성하는 감성 반영 요청 정보 생성부; 및 상기 감 성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보를 기반으로, 사용자의 감성 상태가 반영된 요 청 사항에 응답하는 감성 반영 응답 정보를 생성하여, 상기 메타 휴먼을 통해 상기 생성된 감성 반영 응답 정보 에 기반한 감성 응답을 수행하도록 하는 감성 응답 출력부;를 포함하는 것을 특징으로 한다. 상기 문장 정보 생성부는, 상기 멀티모달 분석 프로세스가 시작되는 경우, 상기 키오스크에 설치된 복수 개의 모듈 중 스피커 모듈을 통해 수신한 언어 신호에 대응되는 문장에 포함된 복수 개의 형태소를 식별하여, 상기 문장을 형태소 별로 분해하는 문장 분해부; 및 상기 문장 분해부의 기능 수행에 의해 상기 문장이 형태소 별로 분해되면, 상기 형태소 별로 분해된 문장에서 키워드를 추출해 기 저장된 문장 속성 부여 조건을 통해 상기 추 출된 키워드 각각에 문장 속성을 부여하여, 상기 문장 속성이 부여된 키워드를 포함하는 문장에 기반한 문장 정 보를 생성하는 문장 속성 부여부;를 포함하는 것이 바람직하다. 상기 감성 반영 요청 정보 생성부는, 상기 문장 정보의 생성이 완료되면, 상기 키오스크에 설치된 복수 개의 모 듈 중 카메라 모듈을 통해 수신한 영상 정보를 기 저장된 영상인식 알고리즘을 통해 분석하여, 상기 분석 결과 를 통해 상기 요청 사항 정보 수신 당시 사용자 제스처 및 사용자 표정 중 적어도 하나를 식별하는 사용자 감성 요소 식별부; 상기 사용자 감성 요소 식별부의 기능 수행이 완료되면, 기 저장된 감성분석 알고리즘을 통해 상 기 사용자 제스처 및 상기 사용자 표정 중 적어도 하나를 분석하여, 분석 결과를 통해 상기 사용자 제스처 및 사용자 표정 중 적어도 하나에 대한 감성 수치를 산출하는 감성 수치 산출부; 및 상기 감성 수치의 산출이 완료 되면, 기 저장된 감성 상태 테이블을 통해 상기 산출된 감성 수치를 포함하는 감성 범위를 식별하여, 상기 식별 된 감성 범위에 대응되는 감성 상태를 상기 요청 사항 정보 수신 당시 사용자의 감성 상태로 판단해 상기 식별 된 감성 범위에 대응되는 감성 상태에 기반한 감성 속성 정보를 생성하는 감성 속성 정보 생성부;를 포함하는 것이 가능하다. 상기 감성 반영 요청 정보 생성부는, 상기 감성 속성 정보의 생성이 완료되면, 상기 생성된 문장 정보에 상기 생성된 감성 속성 정보를 매칭하여, 사용자의 감성 상태가 반영된 요청 사항에 대한 문장 정보인 감성 반영 요 청 정보를 생성하는 것이 가능하다. 상기 감성 응답 출력부는, 상기 감성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보에 포함된 문장 정보를 식별하여, 상기 식별된 문장 정보를 구성하는 복수 개의 키워드 각각에 대한 문장 속성을 식별하는문장 속성 식별부; 및 상기 문장 속성 식별부의 기능 수행이 완료되면, 상기 식별된 문장 속성 및 상기 복수 개 의 키워드 각각을 기반으로, 지식 베이스에 저장된 복수 개의 질의 응답 정보 중 상기 사용자의 요청 사항에 대 응되는 질의 응답 정보를 추출하는 질의 응답 추출부;를 포함하는 것이 가능하다. 상기 감성 응답 출력부는, 상기 질의 응답 정보의 생성이 완료되면, 상기 감성 반영 요청 정보에 포함된 감성 속성 정보를 식별하여, 상기 식별된 감성 속성 정보를 기반으로 상기 감성 수치 및 사용자의 감성 상태를 식별 하는 감성 속성 식별부; 상기 감성 속성 식별부의 기능 수행이 완료되면, 기 저장된 액션 정보 테이블에 저장된 복수 개의 액션 정보 중 상기 사용자 제스처 및 상기 사용자 표정 중 적어도 하나에 대응되는 긍정 액션 정보 및 부정 액션 정보를 식별하는 액션 정보 식별부; 및 상기 액션 정보 식별부의 기능 수행이 완료되면, 식별된 긍정 액션 정보 및 부정 액션 정보 중 상기 식별된 감성 수치에 대응되는 하나를 감성 대응 액션 정보로 추출하 는 감성 대응 액션 정보 추출부;를 더 포함하는 것이 가능하다. 상기 기 저장된 액션 정보 테이블은, 긍정 액션 카테고리 및 부정 액션 카테고리로 구성된 데이터테이블로써, 상기 긍정 액션 카테고리 및 상기 부정 액션 카테고리 각각마다 사용자 제스처 및 상기 사용자 표정 중 적어도 하나에 대응되는 액션 정보를 포함하고 있는 것이 가능하다. 상기 감성 응답 출력부는, 상기 질의 응답 추출부 및 상기 감성 대응 액션 정보 추출부의 기능 수행이 완료되면, 상기 질의 응답 정보 및 상기 감성 대응 액션 정보를 통해 사용자의 요청 사항에 응답하는 감성 반영 응답 정보를 생성하는 감성 반영 응답 정보 생성부; 및 상기 감성 반영 응답 정보의 생성이 완료되면, 상기 디 스플레이를 통해 출력 중인 메타 휴먼에게 상기 감성 반영 응답 정보를 반영하여, 상기 메타 휴먼으로 하여금 상기 감성 반영 응답 정보의 질의 응답 정보에 기반한 응답을 출력하도록 하고, 상기 감성 반영 응답 정보의 감 성 대응 액션 정보에 기반한 감성 액션을 수행하도록 하는 메타 휴먼 응답 출력부;를 더 포함하는 것이 가능하 다."}
{"patent_id": "10-2022-0167967", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명인 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템은 키오스크를 사용하는 사용자의 감정에 적합한 감 성 표현을 메타 휴먼을 통해 출력하여, 사용자에게 집중도 있는 커뮤니케이션 서비스를 제공할 수 있다."}
{"patent_id": "10-2022-0167967", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는, 다양한 실시 예들 및/또는 양상들이 이제 도면들을 참조하여 개시된다. 하기 설명에서는 설명을 목 적으로, 하나이상의 양상들의 전반적 이해를 돕기 위해 다수의 구체적인 세부사항들이 개시된다. 그러나, 이러 한 양상(들)은 이러한 구체적인 세부사항들 없이도 실행될 수 있다는 점 또한 본 발명의 기술 분야에서 통상의 지식을 가진 자에게 인식될 수 있을 것이다. 이후의 기재 및 첨부된 도면들은 하나 이상의 양상들의 특정한 예 시적인 양상들을 상세하게 기술한다. 하지만, 이러한 양상들은 예시적인 것이고 다양한 양상들의 원리들에서의다양한 방법들 중 일부가 이용될 수 있으며, 기술되는 설명들은 그러한 양상들 및 그들의 균등물들을 모두 포함 하고자 하는 의도이다. 본 명세서에서 사용되는 \"실시 예\", \"예\", \"양상\", \"예시\" 등은 기술되는 임의의 양상 또는 설계가 다른 양상 또는 설계들보다 양호하다거나, 이점이 있는 것으로 해석되지 않을 수도 있다. 또한, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 해당 특징 및/또는 구성요소가 존재함을 의미하지만, 하나 이상의 다른 특징, 구성요소 및/또는 이들의 그룹의 존재 또는 추가를 배제하지 않는 것으로 이해되어야 한다. 또한, 제 1, 제 2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성요소는 제 2 구 성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 또한, 본 발명의 실시 예들에서, 별도로 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여 기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해 되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기 술의 문맥 상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 발명의 실시 예에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 도 1은 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템을 설명하기 위한 블록도 이다. 도 1을 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치에서 구현되는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템(이하, 메타 휴먼 시스템으로 칭함)은 멀티모달 분석 프로세스 시작부, 문장 정보 생성부, 감성 반영 요청 정보 생성부 및 감성 응답 출력부를 포함할 수 있다. 일 실시예에 따르면, 상기 멀티모달 분석 프로세스 시작부는 키오스크의 디스플레이를 통해 메타 휴먼이 출력되는 상태에서, 사용자로부터 요청 사항이 포함된 언어 신호 및 사용자에 대한 영상 정보를 포함하는 요청 사항 정보를 수신하는 경우, 멀티모달 분석 프로세스를 시작할 수 있다. 본 발명에 대한 기술적 특징을 개시하기 이전에, 일반적으로 인터넷 환경에서 수행되는 커뮤니케이션에서 언어 가 차지하는 비율은 7%로 그 영향이 극히 미비하다. 이에 따라, 본 발명은 사용자의 제스처 및 표정 등을 분석 해 사용자의 감성 상태를 파악하여, 사용자의 요청 사항에 적합한 응답과 이에 따른 행동 및 표정을 메타 휴먼 을 통해 출력하여, 사용자에게 인터넷 환경에서 수행되는 커뮤니케이션에 대한 높은 집중도 및 높은 효율성을 제공하도록 하기 위한 기술일 수 있다. 일 실시예에 따르면, 상기 키오스크는 복수 개의 센서를 포함하는 구성일 수 있다. 이에 따라, 상기 키오스크는 복수 개의 센서 중 마이크 모듈(또는 터치 스크린)을 통해 사용자의 음성에 기반한 언어 신호를 획득할 수 있으 며, 카메라 모듈을 통해 사용자가 촬영된 영상 정보를 획득할 수 있다. 일 실시예에 따르면, 상기 멀티모달 분석 프로세스 시작부는 상기 요청 사항 정보를 수신하는 경우, 상기 요청 사항 정보에 기반한 언어 신호 및 영상 정보를 통해 사용자의 감성 상태가 반영된 요청 사항에 적합한 응 답을 메타 휴먼을 통해 제공하기 위한 멀티모달 분석 프로세스를 수행할 수 있다. 일 실시예에 따르면, 상기 문장 정보 생성부는 상기 멀티모달 분석 프로세스가 시작되면, 상기 수신된 요 청 사항 정보에 포함된 언어 신호에 대응되는 문장에 대한 분석을 시작하여, 상기 문장을 구성하는 복수 개의 키워드를 추출해 상기 추출된 복수 개의 키워드 각각에 문장 속성이 매칭된 문장 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 문장 정보 생성부는 사용자의 음성에 기반한 언어 신호가 입력되는 경우, 상기 입력된 언어 신호에 대응되는 문장을 구성하는 복수 개의 키워드로 분해할 수 있다. 이 때, 사용자로부터 입력 되는 언어 신호는 사용자의 음성을 통해 입력되거나 사용자에 의해 입력되는 텍스트에 기반한 구성으로, 상기 문장 정보 생성부에 의해 인식될 수 있다. 일 실시예에 따르면, 상기 문장 속성은 상기 복수 개의 키워드마다 부여되는 속성 정보로써, 이 후에 후술할 지 식 데이터베이스에서 사용자의 요구 사항에 대응되는 응답(질의 응답)을 도출하기 위해 활용되는 구성으로, 기설정된 문장 속성 부여 사전을 통해 상기 복수 개의 키워드마다 부여될 수 있다. 일 실시예에 따르면, 상기 문장 정보 생성부는 상기 복수 개의 키워드마다 상기 문장 속성을 부여를 완료 한 경우, 상기 문장 속성이 부여된 복수 개의 키워드로 구성된 문장에 기반한 문장 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 감성 반영 요청 정보 생성부는 상기 문장 정보의 생성이 완료되면, 상기 수신된 요청 사항 정보에 포함된 영상 정보에 대한 분석을 시작하여, 사용자의 감성 상태를 식별 가능한 감성 속성 정 보를 생성한 후, 상기 문장 정보 및 상기 감성 속성 정보를 통해 사용자의 감성 상태가 반영된 요청 사항을 포 함하는 감성 반영 요청 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 감성 반영 요청 정보 생성부는 상기 문장 정보의 생성이 완료되면, 기 저장된 영상분석 알고리즘을 통해 상기 영상 정보를 분석할 수 있다. 상기와 관련하여, 상기 기 저장된 영상분석 알고 리즘은 상기 영상 정보에 기반한 영상 내에서 사용자의 신체 및 얼굴에 대한 특징점을 선별하고, 선별된 특징점 간의 깊이 및 움직임 관계에 기반해 사용자의 제스처 및 표정을 식별하기 위한 알고리즘일 수 있다. 일 실시예에 따르면, 상기 감성 반영 요청 정보 생성부는 상기 기 저장된 영상분석 알고리즘을 통해 사용 자의 제스처 및 사용자의 표정을 식별하면, 상기 식별된 사용자의 제스처 및 사용자의 표정을 통해 사용자의 감 성 상태를 판단할 수 있다. 예를 들어, 상기 감성 반영 요청 정보 생성부는 사용자의 표정이 지정된 횟수 이상으로 웃는 것을 확인한 경우, 사용자의 감성 상태가 즐거움 상태, 행복 상태, 기분 좋음 상태인 것으로 판 단할 수 있다. 이에 따라, 상기 감성 반영 요청 정보 생성부는 상기 판단됨 감성 상태에 기반한 감성 속성 정보를 생성할 수 있다. 상기와 관련하여, 상기 감성 속성 정보는 상기 키오스크를 통해 요구 사항 정보 수신 당시, 사용자의 요구 사항에 반영된 감성 상태에 대한 정보일 수 있다. 일 실시예에 따르면, 상기 감성 반영 요청 정보 생성부는 상기 감성 속성 정보의 생성되면, 상기 감성 속 성 정보를 상기 문장 정보와 매칭 완료하여, 상기 감성 반영 요청 정보를 생성할 수 있다. 상기 감성 반영 요청 정보는 사용자의 감성 상태가 반영된 요청 사항을 포함하는 문장 정보일 수 있다. 일 실시예에 따르면, 상기 감성 응답 출력부는 상기 감성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보를 기반으로, 사용자의 감성 상태가 반영된 요청 사항에 응답하는 감성 반영 응답 정보를 생성하 여, 메타 휴먼을 통해 상기 생성된 감성 반영 응답 정보에 기반한 감성 응답을 수행하도록 할 수 있다. 일 실시예에 따르면, 상기 감성 응답 출력부는 상기 감성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보에 포함된 문장 정보를 분석하여, 상기 분석 결과를 통해 지식 베이스에 저장된 복수 개의 질의 응답 정보 중 하나를 추출할 수 있다. 이 때, 상기 추출되는 질의응답 정보는 사용자의 요구 사항에 응답하는 내용으로 구성된 정보일 수 있다. 일 실시예에 따르면, 상기 감성 응답 출력부는 상기 감성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보에 포함된 감성 속성 정보를 분석하여, 상기 분석 결과를 통해 감성 대응 액션 정보를 기 저장된 액션 정보 테이블에서 추출할 수 있다. 이 때, 추출되는 감성 대응 액션 정보는 상기 요구 사항에 반영된 사용 자의 감성 상태에 대응되는 감성을 표현 가능한 제스처 및 표정을 메타 휴먼(107a)을 통해 출력하도록 하는 정 보일 수 있다. 이에 따라, 상기 감성 응답 출력부는 상기 질의응답 정보에 상기 감성 대응 액션 정보를 매칭하여, 상기 감성 반영 응답 정보를 생성할 수 있다. 즉, 상기 감성 반영 응답 정보는 사용자의 감성 상태가 반영된 요구 사 항에 대응하는 응답(메타 휴먼을 통해 출력되는 요구 사항에 기반한 응답 문구) 및 감성 표현(메타 휴면이 출력 하는 제스처 및 표정)을 포함하는 정보일 수 있다. 도 2는 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템의 문장 정보 생성부를 설명하기 위한 블록도이다. 도 2를 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치에서 구현되는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템(예: 도 1의 멀티 모달 기반의 사용자 응대형 메타 휴먼 시스템)(이하, 메타 휴먼 시스템으로 칭함)은 문장 정보 생성부 (예: 도 1의 문장 정보 생성부)를 포함할 수 있다. 일 실시예에 다르면, 상기 문장 정보 생성부는 멀티모달 분석 프로세스가 시작되면, 수신된 요청 사항 정 보에 포함된 언어 신호에 대응되는 문장(200a)에 대한 분석을 시작하여, 상기 문장(200a)을 구성하는 복수 개의 키워드를 추출해 상기 추출된 복수 개의 키워드 각각에 문장 속성이 매칭된 문장 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 문장 정보 생성부는 사용자의 음성에 기반한 언어 신호가 입력되는 경우, 상기 입력된 언어 신호에 대응되는 문장(200a)을 구성하는 복수 개의 키워드로 분해할 수 있다. 이 때, 사용자로부터 입력되는 언어 신호는 사용자의 음성을 통해 입력되거나 사용자에 의해 입력되는 텍스트에 기반한 구성으로, 상 기 문장 정보 생성부에 의해 인식될 수 있다. 일 실시예에 따르면, 상기 문장 속성은 상기 복수 개의 키워드마다 부여되는 속성 정보로써, 이 후에 후술할 지 식 데이터베이스에서 사용자의 요구 사항에 대응되는 응답(질의 응답)을 도출하기 위해 활용되는 구성으로, 기 설정된 문장 속성 부여 사전을 통해 상기 복수 개의 키워드마다 부여될 수 있다. 일 실시예에 따르면, 상기 문장 정보 생성부는 상술한 기능을 수행하기 위한 세부 구성으로, 문장 분해부 및 문장 속성 부여부를 포함할 수 있다. 일 실시예에 따르면, 상기 문장 분해부는 멀티모달 분석 프로세스가 시작되는 경우, 키오스크에 설치된 복 수 개의 모듈 중 스피커 모듈을 통해 수신한 언어 신호에 대응되는 문장(200a)에 포함된 복수 개의 형태소를 식 별하여, 상기 문장을 형태소 별로 분해할 수 있다. 일 실시예에 따르면, 상기 문장 분해부는 상기 언어 신호에 대응되는 자연어에 기반한 문장(200a)을 식별 할 수 있다. 예를 들어, 상기 문장 분해부는 상기 언어 신호에 대응되는 자연어인 \"가까운 짬뽕집을 추천 해줘\"를 식별할 수 있다. 일 실시예에 따르면, 상기 문장 분해부는 상기 문장에 포함된 복수 개의 형태소를 식별하여, 상기 문장을 형태소 별로 분해할 수 있다. 예를 들어, 상기 문장 분해부는 상기 문장(200a)인\"가까운 짬뽕집을 추천해 줘\"를 형태소 별로 분해할 수 있다. 상기 문장 분해부는 \"가까운 짬뽕집 추천해줘\"의 문장을 \"가까운(가깝다)\" v \"짬뽕\" v \"집\" v\"을\" v \"추천\" v \"해줘(~해주세요)\" 로 분해하여, 총 6개의 형태소(201a)로 분해할 수 있다. 일 실시예에 따르면, 상기 문장 속성 부여부는 상기 문장 분해부의 기능 수행에 의해 상기 문장이 형 태소 별로 분해되면, 형태소 별로 분해된 문장에서 키워드를 추출해 기 저장된 문장 속성 부여 사전을 통해 상 기 추출된 키워드 각각에 문장 속성을 부여하여, 상기 문장 속성이 부여된 키워드를 포함하는 문장에 기반한 문 장 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 문장 속성 부여부는 상기 분해된 형태소 각각이 어떤 형태소인지를 구분할 수 있다. 상기 형태소의 종류는 자립 형태소(혼자 쓰일 수 있는 형태소(예: 짬뽕, 집, 추천)), 의존 형태소(다른 말에 의존하여 쓰이는 형태소(예: ~을, ~해주세요)), 실질 형태소(실질적인 의미를 갖는 형태소(예: 자립 형태 소와 동일)) 및 형식 형태소(문법적 관계나 형식적 의미를 더해주는 형태소(예: 조사, 어미, 접사))로 구분되는 데, 상기 문장 속성 부여부는 상기 분해된 형태소 각각의 종류를 분석할 수 있다. 이 때, 상기 문장 속성 부여부는 기 저장된 형태소 정보를 기반으로, 상기 분해된 형태소 각각의 종류를 구분하여 확인할 수 있다. 상기와 관련하여, 상기 문장 속성 부여부는 상기 형태소 각각의 종류의 구분을 완료하면, 상기 형태소 별 로 분해된 문장에서 키워드를 추출해 기 저장된 문장 속성 부여 조건을 통해 상기 추출된 키워드 각각에 문장 속성을 부여할 수 있다. 이 때, 상기 키워드는 상기 자립 형태소, 의존 형태소 및 실질 형태소에 해당하는 구성 일 수 있다. 일 실시예에 따르면, 상기 문장 속성 부여부는 상기 문장에서 키워드의 식별이 완료되면, 상기 기 저장된 문장 속성 부여 조건에 따라 상기 키워드에 문장 속성을 부여할 수 있다. 상기와 관련하여, 상기 기 저장된 문 장 속성 부여 조건은 문장의 품사 조합 관계에 따라 상이할 수 있다. 상기 기 저장된 문장 속성 부여 조건은 상 기 메타 휴먼 시스템을 관리하는 관리자 계정에 의해 변경될 수 있다. 예를 들어, 상기 문장 속성 부여부는 \"가까운(가깝다)\" v \"짬뽕\" v \"집\" v\"을\" v \"추천\" v \"해줘(~해주세 요)\"에서 자립 형태소에 해당하는 \"가깝다\", \"짬뽕\", \"집\", \"추천\"과 의존 형태소인 \"해줘\"를 키워드로 식별할 수 있다. 이에 따라, 상기 문장 속성 부여부는 상기 기 저장된 문장 속성 부여 조건에 따라 상기 문장의 품사에 기반해 \"가까운(가깝다)\"에 거리 속성, \"짬뽕\"에 음식 속성, \"집\"에 음식점 속성, \"추천해줘\"에 요청 속성인 문장 속성을 부여할 수 있다. 이에 따라, 상기 문장 속성 부여부는 상기 문장 속성이 부여된 키워드를 포함하는 문장에 기반해 상기 문 장 정보를 생성할 수 있다. 다른 실시예에 따르면, 상기 문장 생성부는 상기 문장을 통해 사용자의 감성 상태를 판단할 수 있다. 예를 들어, 상기 문장 생성부는 멀티모달 신경망(multimodal NN) 및 한국어 기반의 버트(BERT, Bidirectional Encoder Representations from Transformers) 모델의 감성분석 알고리즘을 통해, 상기 문장에 대한 감성분석 프로세스를 실시할 수 있다. 예를 들어, 상기 멀티모달 신경망은 영상 정보에 대한 알고리즘 처리가 아닌, 텍스트를 포함하는 멀티미디어에 대해서 처리가 가능한, 즉 텍스트 처리 알고리즘 및 이미지 처리 알고리즘이 포함된 신경망 처리를 위한 구성이 다. 해당 신경망은 특히 다종의 생체 신호를 이용한 딥러닝 기반 감정 분류 등에 사용되어, 다종의 데이터를 기 반으로 일 결과를 도출하기 위해서 사용되는 모델로 이해된다. 예를 들어, 상기 문장 생성부는 상기 문장을 기반으로 한 감성분석 알고리즘으로써, 예를 들어 상술한 버 트 모델을 통해 상기 문장에 대한 감성분석 프로세스를 수행할 수 있다. 이 때의 감성분석 알고리즘은 머신 러 닝 및 단어(keyword) 기반 분석 알고리즘일 수 있다. 상기와 관련하여, 머신러닝 기반의 감성분석은 예를 들어, 회귀 분석을 통한 사전 구축 방식이 있다. 일반적으 로 키워드에는 평점을 부여하는데, 이렇게 평점을 레이블링 된 데이터에 회귀 분석 모델을 적용하여 각 단어에 대한 감성 사전을 구축하며, 구축한 이후에는 교차 검증을 통해 감성 사전으로서의 타당한 성능을 지니는지를 평가된 감성분석의 한 종류일 수 있다. 상기 문장 생성부는 상기 머신러닝 기반의 감성분석을 통해 상기 문장을 분석 시, 검증을 통해 구축된 사전의 성능이 확보된 상태에서 문장에 대한 감성 분석을 수행할 수 있게 된다. 한편 Semi-supervised 방식이 있다. 지도 학습과 비지도 학습의 중간인 준지도 학습(Semi-supervised Learning)을 통해 상기 감성 사전을 구축하기도 한다. 준지도 학습 기반의 방법은 2가지 세부 방법으로 나뉘게 된다. 첫 번째는 감 성 그래프(Sentiment graph)를 이용하는 방식이다. 고차원 단어를 저차원으로 임베딩한 후 에 거리를 기반으로 각 단어 사이의 네트워크를 구축한다. 감성 점수가 확실한 수 개의 단어를 미리 레이블링 (Pre-labeled sentiment words)한 뒤에 공간 상의 위치에 따라 나머지 단어의 감성 점수를 측정한다. 보다 자세하게, \"좋다\", \"짱\", \"재밌다\", \"훌륭하다\" 등을 긍정으로 \"거슬리다\", \"억지\", \"지루\", \"아쉬움\" 등 을 부정으로, 그리고 \"보다\", \"감독\", \"주인공\", \"친구\", \"카메라\" 와 같이 중립으로 미리 레이블링 하고 그리 고 이들과의 관계로부터 나머지 단어의 감정 점수를 매기게 되어 감성분석을 수행하게 된다. 준지도 학습을 통한 두 번째 접근 방식은 자가 학습(self-training)이다. 이 방법 역시 상기 감성 그래프 방법 과 같이, 복수 갱의 특정 단어는 미리 레이블링 된 상태이다. 이 어휘로만 분류기를 학습한 뒤에 정답이 없는 어휘에 분류기를 적용하여 결과의 신뢰도가 높으면 정답으로 지정한 후, 학습기를 재학습하는 방식이다. 반복 학습 횟수가 늘어날수록 레이블링 되는 단어가 더 많아질 수 있다. RNTN(Recursive Neural Tensor Network) 방법 역시 사용될 수 있다. 여기서의 R은 Recursive(재귀적인)를 나타 내는 단어로 RNN에서 사용되는 Recurrent(순환하는)와는 다른 의미를 가지고 있다. RNTN은 두 가지 벤치마크 모 델이 있다. 첫 번째는 RecursiveNN으로서, 각 단어를 아래와 같이 구조적으로 나타낸 이후 각 단어를 구 (Phrase)로 하나씩 결합하면서 감성이 어떻게 나타내는 지를 계속해서 학습한다. 일 논문에서는 긍정과 부정을 25단계로 구분하였으며, 동일한 구에 대해서는 3명이 평가한 결과물의 평균을 사용하여 레이블링 한다. 여기서 재귀적(Recursive)이라는 수식어를 사용하는 이유는 각 단어 혹은 구마다 동일한 가중치를 적용하기 때문이다. 두 번째는 MV-RNN(Matrix-Vector Recursive Neural Network) 이다. 이 방법은 더 긴 문장의 문맥을 행렬에 저 장하여 기존 RecursiveNN의 한계점을 해결하고자 한다. 그리고 두 벤치마크 모델을 결합하여 텐서로 쌓아 나타 낸 것이 바로 아래의 RNTN이다. RNTN은 일반적으로 각각의 벤치마크 모델보다 성능이 더 좋다. 특히 \"but\"등의 단어로 두 문장이 이어져 있거나 복잡한 부정 표현(High-level Negation)이 문장에 존재하는 경우에 기존 모델 보다 훨씬 더 좋은 성능을 나타낸다. 한편 버트 모델은, 구글에서 개발한 NLP(자연어처리) 사전 훈련 기술이며, 특정 분야에 국한된 기술이 아니라 모든 자연어 처리 분야에서 좋은 성능을 내는 범용 랭귀지 모델(Language Model)이다. 11개 이상의 자연어처리 과제에서 BERT가 최첨단 성능을 발휘하고 있어, 최근 언어처리에 매우 적합한 모델로 각광받고 있는 모델일 수있다. 특정 과제를 수행하기 위한 모델의 성능은, 데이터가 충분히 많다면 Embedding이 큰 영향을 미치게 되며, 단어 의 의미를 잘 표현하는 벡터로 표현하는 Embedding된 단어들이 훈련과정에서 당연히 좋은 성능을 낼 것이다. 이 임베딩 과정에서 BERT를 사용하는 것이고, BERT는 특정 과제를 하기 전 사전 훈련 Embedding을 통해 특정 과제 의 성능을 더 좋게 할 수 있는 언어모델로 이해될 수 있다. BERT등장 이전에는 데이터의 전처리 임베딩을 Word2Vec, GloVe, Fasttext 방식을 많이 사용했지만, 요즘의 고성 능을 내는 대부분의 모델에서 BERT를 많이 사용하고 있다. 버트 모델에서는 인풋 텍스트 데이터를 Token Embedding, Segment Embedding 및 Position Embedding을 통해 처 리한다. Token Embedding은 Word Piece 임베딩 방식으로서 각 Char(문자) 단위로 임베딩을 하고, 자주 등장하면 서 가장 긴 길이의 sub-word를 하나의 단위로 만든다. 자주 등장하지 않는 단어는 다시 sub-word로 만든다. 이 는 이전에 자주 등장하지 않았던 단어를 모조리 'OOV'처리하여 모델링의 성능을 저하했던 'OOV'문제도 해결할 수 있다. Segment Embedding에서는 토큰 시킨 단어들을 다시 하나의 문장으로 만드는 작업을 수행한다. BERT에서는 두개 의 문장을 구분자([SEP])를 넣어 구분하고 그 두 문장을 하나의 Segment로 지정하여 입력한다. BERT에서는 이 한 세그먼트를 512 sub-word 길이로 제한하는데, 한국어는 보통 20 sub-word가 한 문장을 이룬다고 하며 대부분 의 문장은 60 sub-word가 넘지 않는다고 하니 BERT를 사용할 때, 하나의 세그먼트에 128로 제한하여도 충분히 학습이 가능하다. Position Embedding에 있어서 버트는 Transformer 모델의 일부만을 사용한다. Transformer란 CNN, RNN 과 같은 모델 대신 Self-Attention 이라는 모델을 사용하는 모델이다. BERT는 Transformer의 인코더, 디코더 중 인코더 만 사용합니다. Self Attention은 입력의 위치를 고려하지 않고 입력 토큰의 위치 정보를 고려한다. 그래서 Transformer모델에 서는 Sinusoid 함수를 이용하여 Positional encoding을 사용하고 BERT는 이를 따서 Position Encoding을 사용 한다. 즉 Token의 순서대로 임베딩을 수행하는 것이다. BERT는 위 세가지 임베딩을 합치고 이에 Layer정규화와 Dropout을 적용하여 입력으로 사용한다. 데이터들을 임베딩하여 훈련시킬 데이터를 모두 인코딩 하였으면, 사전훈련(Pre-Training)을 시킨다. 즉 본 발 명에서 문장 생성부는, 버트 모델을 적용하여, 버트 모델은 기존의 특정 스페시픽(Specific)한 분야의 분 석 모델을 사용하지 않고, 제너럴(General)한 모델을 먼저 제시한 뒤 이를 Fine Tuning하여 해당 태스크를 수행 하는 알고리즘을 도출한다. 즉, 버트 모델에 대한 프리 트레이닝(Pre-training)을 진행하고, 복수의 의료기관에 대한 제1 컨텐츠를 이용하여 상기 버트 모델에 대한 파인 튜닝(Fine tuning)을 통해 상기 버트 모델을 지속적으 로 학습시키는 것이다. 기존의 방법들은 보통 문장을 왼쪽에서 오른쪽으로 학습하여 다음 단어를 예측하는 방식이거나, 예측할 단어의 좌우 문맥을 고려하여 예측하는 방식을 사용한다. 하지만 BERT는 언어의 특성을 잘 학습하도록, MLM(Masked Language Model) 및 NSP(Next Sentence Prediction) 두가지 방식을 사용한다. MLM은 입력 문장에서 임의로 토큰을 버리고(Mask처리) 해당 토큰을 맞추는 방식으로 학습을 진행하게 되고, NSP 는 두 문장이 주어졌을 때, 두 문장의 순서를 예측하는 방식으로서, 두 문장 간 관련이 고려되야 하는 NLI와 QA 의 파인 튜닝을 위해 두 문장의 연관을 맞추는 학습을 진행한다. 프리 트레이닝 이후에는 상기와 같이 학습된 언어모델을 전이학습시키는 Fine tuning 과정이 수행된다. 즉 프리 트레인을 마친 단어 임베딩(문장임베딩)은 말뭉치의 의미적 문법적 정보를 충분히 담고 있고, 다운스트림 태스 크를 수행하기 위한 파인튜닝 추가학습을 통해 임베딩을 다운스트림 태스크에 맞게 업데이트 하게 된다. 전이학 습은 BERT의 언어 모델의 출력에 추가적인 모델을 쌓아 만든다. 일반적으로 복잡한 CNN, LSTM, Attention을 쌓 지 않고 간단한 DNN만 쌓아도 성능이 잘 나오며 별 차이가 없다고 알려져 있다. ERT를 각 Task에 쓰기위해서는 먼저 문장 쌍 분류 문제로 두 문장을 하나의 입력으로 넣고 두 문장간 관계를 구 하거나, 한 문장을 입력으로 넣고 문장의 종류를 분류하거나, 문장이나 문단 내에서 원하는 정답 위치의 시작과 끝을 구하거나, 입력 문장 Token들의 개체명(Named entity recognigion)을 구하거나 품사(Part-of-speech tagging) 를 구한다.이때, 상기 문장 생성부는 해당 파인튜닝을 이용하여 입력 문장에 대한 긍부정 분류를 수행하게 되는데, 파인튜닝으로 입력 문장의 종류(긍/부정)를 분류하는 task의 경우 classification layer가 추가되어 문장에 대 한 수치나 단어 등의 키워드에 따라서 긍부정을 분류하고, 이때 파라미터로서, Batch Size, Epoch, Max Sequence Length, Dropout Rate, Learning Rate 등이 설정되어 사용될 수 있다. 이에 따라, 상기 문장 생성부는 상기 문장에 대하여 수행된 감성분석 프로세스의 결과에 기반해 사용자의 감성 상태를 판단할 수 있다. 도 3은 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템의 감성 반영 요청 정보 생성부를 설명하기 위한 블록도이다. 도 3을 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치에서 구현되는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템(예: 도 1의 멀티 모달 기반의 사용자 응대형 메타 휴먼 시스템)(이하, 메타 휴먼 시스템으로 칭함)은 감성 반영 요청 정보 생성부(예: 도 1의 감성 반영 요청 정보 생성부)를 포함할 수 있다. 일 실시예에 따르면, 상기 감성 반영 요청 정보 생성부는 문장 정보의 생성이 완료되면, 수신된 요청 사항 정보에 포함된 영상 정보(301a)에 대한 분석을 시작하여, 사용자의 감성 상태를 식별 가능한 감성 속성 정보를 생성한 후, 문장 정보 및 감성 속성 정보를 통해 사용자의 감성 상태가 반영된 요청 사항을 포함하는 감성 반영 요청 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 감성 반영 요청 정보 생성부는 상술한 기능을 수행하기 위한 세부 구성으로, 사 용자 감성 요소 식별부, 감성 수치 산출부 및 감성 속성 정보 생성부를 포함할 수 있다. 일 실시예에 따르면, 상기 사용자 감성 요소 식별부는 상기 문장 정보의 생성이 완료되면, 키오스크에 설 치된 복수 개의 모듈 중 카메라 모듈을 통해 수신한 영상 정보(301a)를 기 저장된 영상인식 알고리즘(301b)을 통해 분석하여, 상기 분석 결과를 통해 상기 요청 사항 정보 수신 당시 사용자 제스처 및 사용자 표정 중 적어 도 하나를 식별할 수 있다. 일 실시예에 따르면, 상기 기 저장된 영상인식 알고리즘(301b)은 상기 영상 정보(301a)에 기반한 영상 내에서 사용자의 얼굴 또는 신체 부위를 식별하고, 상기 식별된 얼굴 내에서의 특징점을 선별해 상기 특징점 간의 위치 관계 및 상기 특징점이 구성하는 형태에 따라 사용자의 표정을 식별하거나 신체 부위의 제스처를 식별하는 알고 리즘일 수 있다. 일 실시예에 따르면, 상기 감성 수치 산출부는 상기 사용자 감성 요소 식별부의 기능 수행이 완료되 면, 기 저장된 감성분석 알고리즘(303a)을 통해 사용자 제스처 및 사용자 표정 중 적어도 하나를 분석하여, 분 석 결과를 통해 사용자 제스처 및 사용자 표정 중 적어도 하나에 대한 감성 수치를 산출할 수 있다. 일 실시예에 따르면, 상기 기 저장된 감성분석 알고리즘(303a)은 상기 사용자 감성 요소 식별부에 의해 식 별된 사용자 표정 및 사용자 제스처를 분석하여, 사용자의 감성 상태를 판단하기 위한 알고리즘일 수 있다. 상기와 관련하여, 상기 기 저장된 감성분석 알고리즘(303a)은 상기 식별된 사용자 표정이 행복, 우울, 분노, 공 포, 놀람, 경멸, 놀라움 중 적어도 하나에 대응되는 표정인지를 확인하고, 상기 표정이 지속되는 시간 및 횟수 에 기반해 상기 감성 수치(예: 제1 감성 수치)를 산출하는 알고리즘일 수 있다. 상기 기 저장된 감성분석 알고 리즘이 상기 사용자 표정이 지속되는 시간 및 횟수에 기반해 제1 감성 수치를 산출하는 기준은 상기 메타 휴먼 시스템을 관리하는 관리자 계정에 의해 설정될 수 있다. 일 실시예에 따르면, 상기 기 저장된 감성분석 알고리즘(303a)은 상기 식별된 사용자 제스처가 놀람, 지시, 설 명, 행복, 분노 중 적어도 하나에 대응되는 제스처인지를 확인하고, 상기 제스처가 지속되는 시간 및 횟수에 기 반해 상기 감성 수치(예: 제2 감성 수치)를 산출하는 알고리즘일 수 있다. 상기 기 저장된 감성분석 알고리즘이 상기 사용자 제스처가 지속되는 시간 및 횟수에 기반해 제2 감성 수치를 산출하는 기준은 상기 메타 휴먼 시스 템을 관리하는 관리자 계정에 의해 설정될 수 있다. 일 실시예에 따르면, 상기 감성 수치는 사용자의 감성 상태의 정도에 기반한 수치로써, 이 후에 후술할 메타 휴 먼을 통해 출력하는 액션 정보를 기 저장된 액션 정보 테이블에서 추출하기 위해 활용되는 구성일 수 있다. 일 실시예에 따르면, 상기 감성 속성 정보 생성부는 상기 감성 수치의 산출이 완료되면, 기 저장된 감성 상태 테이블을 통해 상기 산출된 감성 수치를 포함하는 감성 범위를 식별하여, 상기 식별된 감성 범위에 대응되는 감성 상태를 요청 사항 정보 수신 당시 사용자의 감성 상태로 판단해 상기 식별된 감성 범위에 대응되는 감 성 상태에 기반한 감성 속성 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 감성 속성 정보 생성부는 상기 제1 감성 수치 및 제2 감성 수치의 산출이 완료 되면, 상기 제1 감성 수치 및 제2 감성 수치를 합산한 최종 감성 수치를 산출할 수 있다. 상기와 관련하여, 상기 감성 속성 정보 생성부는 상기 최종 감성 수치의 산출이 완료되면, 기 저장된 감성 상태 테이블을 통해 상기 산출된 최종 감성 수치를 포함하는 감성 범위를 식별하여, 상기 식별된 감성 범위에 대응되는 감성 상태에 기반한 감성 속성 정보를 생성할 수 있다. 예를 들어, 상기 감성 속성 정보 생성부는 상기 제1 감성 수치에 기반한 점수가 30점의 행복 수치고, 상기 제2 감성 수치에 기반한 점수가 10점의 행복 수치인 것을 확인한 경우, 상기 제1 감성 수치 및 제2 감성 수치를 합산해 40점의 행복 수치인 최종 감성 수치를 산출할 수 있다. 상기와 관련하여, 상기 감성 속성 정보 생성부는 기 저장된 감성 상태 테이블을 통해 행복 상태에 기반한 감성 범위를 식별하고, 상기 40점의 행복 수치가 상기 식별된 행복 상태에 기반한 감성 범위 중 2단계 범위에 포함되는지를 확인할 수 있다. 이에 따라, 상기 감성 속성 정보 생성부는 요청 사항 정보 수신 당시 사용 자의 감성 상태를 2단계 행복 상태로 판단하여, 2단계 행복 상태에 기반한 감성 속성 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 감성 속성 정보는 문장 정보에 매칭되는 구성으로써, 사용자로부터 정보 신 당시 사 용자의 감성 상태 및 정도에 따라 결정되는 정보일 수 있다. 일 실시예에 따르면, 상기 감성 반영 요청 정보 생성부는 상기 감성 속성 정보의 생성이 완료되면, 문장 속성 부여부(예: 도 2의 문장 속성 부여부)의 기능 수행에 의해 생성된 문장 정보에 상기 감성 속성 정보 를 매칭하여, 사용자의 감성 상태가 반영된 요청 사항에 대한 문장 정보인 감성 반영 요청 정보를 생성할 수 있 다. 도 4는 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템의 감성 응답 출력부를 설명하기 위한 블록도이다. 도 4를 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치에서 구현되는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템(예: 도 1의 멀티 모달 기반의 사용자 응대형 메타 휴먼 시스템)(이하, 메타 휴먼 시스템으로 칭함)은 감성 응답 출력부 (예: 도 1의 감성 응답 출력부)를 포함할 수 있다. 일 실시예에 따르면, 상기 감성 응답 출력부는 감성 반영 요청 정보 생성부(예: 도 3의 감성 반영 요청 정 보 생성부)의 기능 수행에 의해 감성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보를 기 반으로, 사용자의 감성 상태가 반영된 요청 사항에 응답하는 감성 반영 응답 정보를 생성하여, 상기 메타 휴먼 을 통해 상기 생성된 감성 반영 응답 정보에 기반한 감성 응답을 수행하도록 할 수 있다. 일 실시예에 따르면, 상기 감성 응답 출력부는 상술한 기능을 수행하기 위한 세부 구성으로, 문장 속성 식 별부 및 질의 응답 추출부를 포함할 수 있다. 일 실시예에 따르면, 상기 문장 속성 식별부는 상기 감성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보에 포함된 문장 정보(401a)를 식별하여, 상기 식별된 문장 정보(401a)를 구성하는 복수 개의 키 워드 각각에 대한 문장 속성을 식별할 수 있다. 예를 들어, 상기 문장 속성 식별부는 상기 문장 정보(401a)에 기반한 문장인 \"가까운 짬뽕집을 추천해줘\" 에서 복수 개의 키워드인 \"가까운(가깝다)\", \"짬뽕\", \"집, \"추천해줘\"을 식별하고, 상기 복수 개의 키워드 각각 에 부여된 문장 속성인 \"가까운(가깝다)\"에 거리 속성, \"짬뽕\"에 음식 속성, \"집\"에 음식점 속성, \"추천해줘\"에 요청 속성인 문장 속성을 식별할 수 있다. 일 실시예에 따르면, 상기 질의 응답 추출부는 상기 문장 속성 식별부의 기능 수행이 완료되면, 식별 된 문장 속성 및 복수 개의 키워드 각각을 기반으로, 지식 베이스(403b)에 저장된 복수 개의 질의 응답 정보 중 사용자의 요청 사항에 대응되는 질의 응답 정보(403a)를 추출할 수 있다. 일 실시예에 따르면, 상기 지식 베이스(knowledge base)(403b)는 전문가 시스템의 구성 요소의 하나로써, 인공 지능 에이전트가 사용될 분야와 관련된 지적 활동과 경험을 통해서 축적한 전문지식 및 문제 해결에 필요한 사 실과 규칙이 저장되어 있는 데이터베이스로, 타 플랫폼(예: 구글 맵, 네이버 날씨)과 연동되는 구성일 수 있다.일 실시예에 따르면, 상기 질의 응답 추출부는 거리 속성인 가까운의 키워드, 음식 속성인 짬뽕 키워드, 음식점 속성인 집 키워드, 요청 속성인 추천에 대응하여, 상기 지식 베이스(403b)에서 키오스크가 설치된 위치 를 기준으로 500m 이내에 위치한 중식을 판매하는 음식점을 추천하는 질의 응답 정보(403b)를 추출할 수 있다. 상기와 관련하여, 상기 질의 응답 정보(403b)는 사용자의 요청 사항에 대응되는 응답에 기반한 정보로써, 단순 히 텍스트 및 음성 출력뿐만 아니라 응답에 기반한 멀티 미디어 컨텐츠 정보(예: 글자, 소리, 영상 매체의 복합 컨텐츠 정보)를 포함할 수 있다. 즉, 상기 질의 응답 추출부는 질의응답(knowledge base question answering) 방식을 통해 식별된 문장 속 성 및 복수 개의 키워드 각각을 기반으로 지식 베이스에서 사용자의 요청 사항에 대응되는 응답 정보인 질의 응 답 정보(403b)를 추출할 수 있다. 이에 따라, 복수 개의 키워드 각각에 부여된 문장 속성은 사용자의 요청 사항 에 대한 의미를 판단하도록 하는 구성일 수 있다. 도 5는 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템의 감성 응답 출력부를 설명하기 위한 다른 블록도이다. 도 5를 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치에서 구현되는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템(예: 도 1의 멀티 모달 기반의 사용자 응대형 메타 휴먼 시스템)(이하, 메타 휴먼 시스템으로 칭함)은 감성 응답 출력부 (예: 도 1의 감성 응답 출력부)를 포함할 수 있다. 일 실시예에 따르면, 상기 감성 응답 출력부는 감성 반영 요청 정보 생성부(예: 도 3의 감성 반영 요청 정 보 생성부)의 기능 수행에 의해 감성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보를 기 반으로, 사용자의 감성 상태가 반영된 요청 사항에 응답하는 감성 반영 응답 정보를 생성하여, 상기 메타 휴먼 을 통해 상기 생성된 감성 반영 응답 정보에 기반한 감성 응답을 수행하도록 할 수 있다. 일 실시예에 따르면, 상기 감성 응답 출력부는 상술한 기능을 수행하기 위한 세부 구성으로, 감성 속성 식 별부, 액션 정보 식별부 및 감성 대응 액션 정보 추출부를 포함할 수 있다. 일 실시예에 따르면, 상기 감성 속성 식별부는 질의 응답 추출부에 의해 지식 베이스에서 질의 응답 정보의 추출(또는 생성)이 완료되면, 상기 감성 반영 요청 정보에 포함된 감성 속성 정보를 식별하여, 상기 식 별된 감성 속성 정보를 기반으로 상기 감성 수치 및 사용자의 감성 상태를 식별할 수 있다. 예를 들어, 상기 감성 속성 식별부는 상기 식별된 감성 속성 정보를 기반으로, 사용자의 감성 상태가 2단 계의 행복 상태인 것을 식별하고, 사용자의 감성 수치가 40점의 행복 수치인 것을 식별할 수 있다. 이 때, 상기 감성 속성 식별부는 40점의 행복 수치가 30점의 제1 감성 수치와 10점의 제2 감성 수치가 합산된 최종 감 성 수치인 것을 확인할 수 있다. 일 실시예에 따르면, 상기 액션 정보 식별부는 상기 감성 속성 식별부의 기능 수행이 완료되면, 기 저장된 액션 정보 테이블에 저장된 복수 개의 액션 정보 중 사용자 제스처 및 사용자 표정 중 적어도 하나에 대 응되는 긍정 액션 정보(503a) 및 부정 액션 정보(503b)를 식별할 수 있다. 일 실시예에 따르면, 상기 기 저장된 액션 정보 테이블은 긍정 액션 카테고리 및 부정 액션 카테고리로 구성된 데이터테이블로써, 긍정 액션 카테고리 및 부정 액션 카테고리 각각마다 사용자 제스처 및 사용자 표정 중 적어 도 하나에 대응되는 액션 정보를 포함할 수 있다. 상기와 관련하여, 상기 긍정 액션 카테고리에 포함된 액션 정보인 긍정 액션 정보(503a)는 메타 휴먼으로 하여 금 사용자의 감성 상태가 반영된 요구 사항에 대응하는 응답 출력 시 그에 적절한 표정 및 제스처(긍정 표정 및 긍정 제스처)를 출력하도록 하는 정보일 수 있다. 또한, 부정 액션 카테고리에 포함된 액션 정보인 부정 액션 정보(503b)는 메타 휴먼으로 하여금 사용자의 감성 상태가 반영된 요구 사항에 대응하는 응답 출력 시 그에 적 절한 표정 및 제스처(부정 표정 및 부정 제스처)를 출력하도록 하는 정보일 수 있다. 일 실시예에 따르면, 상기 액션 정보 식별부는 상기 감성 속성 식별부의 기능 수행에 의해 사용자의 감성 상태가 확인된 경우, 상기 기 저장된 액션 정보 테이블의 복수 개의 대분류 카테고리 중 상기 확인된 감성 상태에 대응되는 대분류 카테고리를 식별하고, 상기 식별된 대분류 카테고리에 포함된 긍정 액션 카테고리 및 부정 액션 카테고리를 식별할 수 있다. 이 후, 상기 액션 정보 식별부는 상기 식별된 긍정 액션 카테고리 에 저장된 복수 개의 긍정 액션 정보 및 부정 액션 카테고리에 저장된 복수 개의 부정 액션 정보를 식별할 수 있다.예를 들어, 상기 액션 정보 식별부는 상기 감성 속성 식별부의 기능 수행에 의해 사용자의 감성 상태 가 2단계의 행복 상태인 것을 식별한 경우, 상기 기 저장된 액션 정보 테이블의 복수 개의 대분류 카테고리 중 2단계 대분류 카테고리를 식별할 수 있다. 상기와 관련하여 복수 개의 대분류 카테고리는 감성 상태의 단계를 기준으로 복수 개의 액션 정보를 구분해 저장하기 위한 저장소일 수 있다. 상기와 관련하여, 상기 액션 정보 식별부는 상기 2단계 대분류 카테고리에 포함된 긍정 액션 카테고리에 저장된 긍정 액션 정보(503a) 및 부정 액션 카테고리에 저장된 부정 액션 정보(503b)를 식별해 사용자 제스처 및 사용자 표정에 대응되는 액션 정보를 식별할 수 있다. 일 실시예에 따르면, 상기 감성 대응 액션 정보 추출부는 상기 액션 정보 식별부의 기능 수행이 완료 되면, 식별된 긍정 액션 정보(503a) 및 부정 액션 정보(503b) 중 상기 식별된 감성 수치에 대응되는 하나를 감 성 대응 액션 정보로 추출할 수 있다. 예를 들어, 상기 감성 대응 액션 정보 추출부는 상기 액션 정보 식별부의 기능 수행이 완료됨에 따라, 2단계 대분류 카테고리에 포함된 긍정 액션 카테고리에 저장된 복수 개의 긍정 액션 정보와 부정 액션 카 테고리에 저장된 복수 개의 부정 액션 정보 중 상기 식별된 40점의 행복 수치에 대응되는 긍정 액션 정보(503 a)를 상기 감성 대응 액션 정보로 추출할 수 있다. 이 때, 상기 감성 대응 액션 정보 추출부는 상기 40점의 행복 수치가 30점의 제1 감성 수치 및 10점의 제2 감성 수치로 구성됨에 따라, 상기 긍정 액션 카테고리에 저장된 복수 개의 긍정 액션 정보에서 사용자 표정에 대응되되 30점의 제1 감성 수치에 대응되는 제1 긍정 액션 정보(긍정 표정 정보)와 사용자 제스처에 대응되되 10점의 제2 감성 수치에 대응되는 제2 긍정 액션 정보(긍정 제스처 정보)를 상기 감성 대응 액션 정보로 추출할 수 있다. 도 6은 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템의 감성 응답 출력부를 설명하기 위한 또 다른 블록도이다. 도 6을 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치에서 구현되는 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템(예: 도 1의 멀티 모달 기반의 사용자 응대형 메타 휴먼 시스템)(이하, 메타 휴먼 시스템으로 칭함)은 감성 응답 출력부 (예: 도 1의 감성 응답 출력부)를 포함할 수 있다. 일 실시예에 따르면, 상기 감성 응답 출력부는 감성 반영 요청 정보 생성부(예: 도 3의 감성 반영 요청 정 보 생성부)의 기능 수행에 의해 감성 반영 요청 정보의 생성이 완료되면, 상기 감성 반영 요청 정보를 기 반으로, 사용자의 감성 상태가 반영된 요청 사항에 응답하는 감성 반영 응답 정보를 생성하여, 상기 메타 휴먼을 통해 상기 생성된 감성 반영 응답 정보에 기반한 감성 응답을 수행하도록 할 수 있다. 일 실시예에 따르면, 상기 감성 응답 출력부는 상술한 기능을 수행하기 위한 세부 구성으로, 감성 반영 응 답 정보 생성부 및 메타 휴먼 응답 출력부를 포함할 수 있다. 일 실시예에 따르면, 상기 감성 반영 응답 정보 생성부는 질의 응답 추출부(예: 도 4의 질의 응답 추출부 ) 및 감성 대응 액션 정보 추출부(예: 도 5의 감성 대응 액션 정보 추출부)의 기능 수행이 완료되면, 질의 응답 정보(605a) 및 감성 대응 액션 정보(605b)를 통해 사용자의 요청 사항에 응답하는 감성 반영 응답 정 보를 생성할 수 있다. 즉, 상기 감성 반영 응답 정보 생성부는 상기 질의 응답 정보(605a)에 상기 감성 대응 액션 정보(605b)를 매칭시킴으로써, 사용자의 감성 상태가 반영된 요청 사항에 대응하는 응답을 제공 가능한 감성 반영 응답 정보 를 생성할 수 있다. 예를 들어, 상기 감성 반영 응답 정보 생성부는 사용자의 요청 사항인 \"가까운 짬뽕집을 추천해줘\"에 대응 하는 응답인 \"500m 이내에 위치한 중식집의 맵 이미지 및 약도 설명에 대한 질의 응답 정보(605a)에 사용자의 감성 상태에 대응하는 감성 액션인 웃으며 맵 이미지 상에서 목적지 지시를 수행 가능한 감성 대응 액션 정보 (605b)를 매칭해 상기 감성 반영 응답 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 메타 휴먼 응답 출력부는 상기 감성 반영 응답 정보의 생성이 완료되면, 디스플 레이를 통해 출력 중인 메타 휴먼에게 상기 감성 반영 응답 정보를 반영하여, 메타 휴먼으로 하여금 감성 반영 응답 정보의 질의 응답 정보(605a)에 기반한 응답을 출력하도록 하고, 상기 감성 반영 응답 정보의 감성 대응 액션 정보(605b)에 기반한 감성 액션을 수행하도록 할 수 있다. 예를 들어, 상기 메타 휴먼 응답 출력부는 상기 감성 반영 응답 정보를 상기 메타 휴먼에게 반영함으 로써, 상기 메타 휴먼이 일 영역에 출력되는 맵 지도 상에서 500m 이내에 위치한 중식집의 위치를 가이드하는 응답과 웃는 상태로 중식집의 위치를 맵 이미지 상에서 지시하도록 하는 감성 액션을 출력하도록 할 수 있다. 도 7은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 내부 구성의 일 예를 설명하기 위한 도면이다. 도 7은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 내부 구성의 일 예를 도시하였으며, 이하의 설명에 있어서, 상술한 도 1 내지 6에 대한 설명과 중복되는 불필요한 실시 예에 대한 설명은 생략하기로 한다. 도 7에 도시한 바와 같이, 컴퓨팅 장치은 적어도 하나의 프로세서(processor), 메모리 (memory), 주변장치 인터페이스(peripheral interface), 입/출력 서브시스템(I/O subsystem), 전력 회로 및 통신 회로를 적어도 포함할 수 있다. 이때, 컴퓨팅 장치 은 촉각 인터페이스 장치에 연결된 유저 단말이기(A) 혹은 전술한 컴퓨팅 장치(B)에 해당될 수 있다. 메모리는, 일례로 고속 랜덤 액세스 메모리(high-speed random access memory), 자기 디스크, 에스램 (SRAM), 디램(DRAM), 롬(ROM), 플래시 메모리 또는 비휘발성 메모리를 포함할 수 있다. 메모리는 컴퓨팅 장치의 동작에 필요한 소프트웨어 모듈, 명령어 집합 또는 그밖에 다양한 데이터를 포함할 수 있다. 이때, 프로세서나 주변장치 인터페이스 등의 다른 컴포넌트에서 메모리에 액세스하는 것 은 프로세서에 의해 제어될 수 있다. 주변장치 인터페이스는 컴퓨팅 장치의 입력 및/또는 출력 주변장치를 프로세서 및 메모리 에 결합시킬 수 있다. 프로세서는 메모리에 저장된 소프트웨어 모듈 또는 명령어 집합을 실행하여 컴퓨팅 장치을 위한 다양한 기능을 수행하고 데이터를 처리할 수 있다. 입/출력 서브시스템은 다양한 입/출력 주변장치들을 주변장치 인터페이스에 결합시킬 수 있다. 예를 들어, 입/출력 서브시스템은 모니터나 키보드, 마우스, 프린터 또는 필요에 따라 터치스크린이나 센서 등의 주변장치를 주변장치 인터페이스에 결합시키기 위한 컨트롤러를 포함할 수 있다. 다른 측면에 따르면, 입/출력 주변장치들은 입/출력 서브시스템을 거치지 않고 주변장치 인터페이스에 결합될 수도 있다. 전력 회로는 단말기의 컴포넌트의 전부 또는 일부로 전력을 공급할 수 있다. 예를 들어 전력 회로 는 전력 관리 시스템, 배터리나 교류(AC) 등과 같은 하나 이상의 전원, 충전 시스템, 전력 실패 감지 회 로(power failure detection circuit), 전력 변환기나 인버터, 전력 상태 표시자 또는 전력 생성, 관리, 분배 를 위한 임의의 다른 컴포넌트들을 포함할 수 있다. 통신 회로는 적어도 하나의 외부 포트를 이용하여 다른 컴퓨팅 장치와 통신을 가능하게 할 수 있다. 또는 상술한 바와 같이 필요에 따라 통신 회로는 RF 회로를 포함하여 전자기 신호(electromagnetic signal)라고도 알려진 RF 신호를 송수신함으로써, 다른 컴퓨팅 장치와 통신을 가능하게 할 수도 있다. 이러한 도 7의 실시 예는, 컴퓨팅 장치의 일례일 뿐이고, 컴퓨팅 장치은 도 7에 도시된 일부 컴 포넌트가 생략되거나, 도 7에 도시되지 않은 추가의 컴포넌트를 더 구비하거나, 2개 이상의 컴포넌트를 결합시 키는 구성 또는 배치를 가질 수 있다. 예를 들어, 모바일 환경의 통신 단말을 위한 컴퓨팅 장치는 도 7에 도시 된 컴포넌트들 외에도, 터치스크린이나 센서 등을 더 포함할 수도 있으며, 통신 회로에 다양한 통신방식 (WiFi, 3G, LTE, Bluetooth, NFC, Zigbee 등)의 RF 통신을 위한 회로가 포함될 수도 있다. 컴퓨팅 장치(1000 0)에 포함 가능한 컴포넌트들은 하나 이상의 신호 처리 또는 어플리케이션에 특화된 집적 회로를 포함하는 하드 웨어, 소프트웨어, 또는 하드웨어 및 소프트웨어 양자의 조합으로 구현될 수 있다. 본 발명의 실시 예에 따른 방법들은 다양한 컴퓨팅 장치를 통하여 수행될 수 있는 프로그램 명령(instruction) 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 특히, 본 실시 예에 따른 프로그램은 PC 기반의 프 로그램 또는 모바일 단말 전용의 어플리케이션으로 구성될 수 있다. 본 발명이 적용되는 애플리케이션은 파일 배포 시스템이 제공하는 파일을 통해 이용자 단말에 설치될 수 있다. 일 예로, 파일 배포 시스템은 이용자 단말 이기의 요청에 따라 상기 파일을 전송하는 파일 전송부(미도시)를 포함할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어구 성요소의 조합으로 구현될 수 있다. 예를 들어, 실시 예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨 터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경 우도 있지만, 해당 기술 분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상장 치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨팅 장치상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시 예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시 예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광 기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 이상과 같이 실시 예들이 비록 한정된 실시 예와 도면에 의해 설명되었으나, 해당 기술 분야에서 통상의 지식을 가진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형 태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성 될 수 있다. 그러므로, 다른 구현들, 다른 실시 예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위 의 범위에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2022-0167967", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템을 설명하기 위한 블록도 이다. 도 2는 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템의 문장 정보 생성부를 설명하기 위한 블록도이다. 도 3은 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템의 감성 반영 요청 정보 생성부를 설명하기 위한 블록도이다. 도 4는 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템의 감성 응답 출력부를 설명하기 위한 블록도이다. 도 5는 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템의 감성 응답 출력부를 설명하기 위한 다른 블록도이다. 도 6은 본 발명의 일 실시 예에 따른 멀티모달 기반의 사용자 응대형 메타 휴먼 시스템의 감성 응답 출력부를 설명하기 위한 또 다른 블록도이다. 도 7은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 내부 구성의 일 예를 설명하기 위한 도면이다."}
