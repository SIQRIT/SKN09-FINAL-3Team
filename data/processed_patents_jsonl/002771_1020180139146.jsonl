{"patent_id": "10-2018-0139146", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0055467", "출원번호": "10-2018-0139146", "발명의 명칭": "인공지능 기반의 목걸이 타입 웨어러블 기기", "출원인": "엘지전자 주식회사", "발명자": "최우현"}}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "단말기 또는 서버와 연결하기 위한 통신부;착용자로부터 발생하는 음향을 획득하는 적어도 하나의 마이크로폰;음향에 포함된 적어도 하나의 부분 음향 각각에 대한 인식 결과를 출력하는 음향 인식 모듈; 및상기 적어도 하나의 마이크로폰 각각으로부터 획득된 음향을 처리하고, 처리된 음향을 상기 음향 인식 모듈로제공하고,상기 음향 인식 모듈로부터 출력된 인식 결과에 기초하여, 설정된 동작 모드와 관련된 정보를 생성하는 컨트롤러를 포함하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 음향 인식 모듈은,상기 음향의 주파수 특성에 기초하여 상기 적어도 하나의 부분 음향 각각을 인식하는 인식 모델을 갖는 음향 인식기를 포함하고,상기 인식 결과는 상기 적어도 하나의 부분 음향 각각의 식별 정보 및 특성 정보를 포함하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 음향 인식기는,상기 적어도 하나의 부분 음향 각각의 주파수 특성과, 상기 적어도 하나의 부분 음향 각각의 인식 결과를 이용하여 상기 인식 모델을 업데이트하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 설정된 동작 모드는 식사 모드이고,상기 컨트롤러는,상기 적어도 하나의 마이크로폰으로부터 획득된 음향에 기초하여 상기 착용자의 식사 개시 시점 및 식사 완료시점을 인식하고,상기 식사 개시 시점과 상기 식사 완료 시점 사이에 획득되는 음향을 처리하고, 처리된 음향을 상기 음향 인식모듈로 제공하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 컨트롤러는,상기 음향에 포함된 적어도 하나의 부분 음향 각각에 대한 인식 결과에 기초하여, 상기 착용자에 대한 식습관정보를 생성하고,생성된 식습관 정보를 상기 단말기 또는 상기 서버로 전송하도록 상기 통신부를 제어하는 목걸이 타입 웨어러블공개특허 10-2020-0055467-3-기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 식습관 정보는 상기 착용자의 식사 상태 또는 식사 중 행위와 관련된 적어도 하나의 항목에 대한 정보를포함하고,상기 적어도 하나의 항목은 식사 시간, 식사 중 대화 시간, 식사 중 수분 섭취 횟수 및 섭취량, 음식물을 삼키기까지의 씹는 횟수 및 소요 시간 중 적어도 하나를 포함하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 생성된 식습관 정보에 기초한 알림을 출력하는 음향 출력부를 더 포함하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 설정된 동작 모드는 식사 외 모드이고,상기 컨트롤러는,상기 적어도 하나의 마이크로폰으로부터 획득된 음향에 기초하여 상기 착용자가 식사 중이 아닌 상태를 인식하고,인식 결과에 따라 소정 시간동안 획득되는 음향을 처리하고, 처리된 음향을 상기 음향 인식 모듈로 제공하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 컨트롤러는,상기 음향에 포함된 적어도 하나의 부분 음향 각각에 대한 인식 결과에 기초하여, 상기 착용자에 대한 호흡기관리 정보를 생성하고,생성된 호흡기 관리 정보를 상기 단말기 또는 상기 서버로 전송하도록 상기 통신부를 제어하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 호흡기 관리 정보는 상기 착용자의 호흡기 상태 또는 수분 첩취와 관련된 적어도 하나의 항목에 대한 정보를 포함하고,상기 적어도 하나의 항목은 기침 또는 객담의 횟수, 빈도, 또는 발생 시간대, 및 수분 섭취량 중 적어도 하나를포함하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 설정된 동작 모드는 수유 모니터링 모드이고,상기 컨트롤러는,상기 적어도 하나의 마이크로폰으로부터 획득된 음향에 기초하여 수유의 개시 시점 및 완료 시점을 인식하고,상기 수유의 개시 시점과 완료 시점 사이에 획득되는 음향을 처리하고, 처리된 음향을 상기 음향 인식 모듈로공개특허 10-2020-0055467-4-제공하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 컨트롤러는,상기 음향에 포함된 적어도 하나의 부분 음향 각각에 대한 인식 결과에 기초하여, 상기 착용자에 대한 수유 모니터링 정보를 생성하고,생성된 수유 모니터링 정보를 상기 단말기 또는 상기 서버로 전송하도록 상기 통신부를 제어하는 목걸이 타입웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 수유 모니터링 정보는 상기 착용자의 수유 상태와 관련된 적어도 하나의 항목에 대한 정보를 포함하고,상기 적어도 하나의 항목은 모유 섭취량, 삼킴 횟수, 수유 시간, 사레 걸림 횟수와 주기 중 적어도 하나를 포함하는 목걸이 타입 웨어러블 기기."}
{"patent_id": "10-2018-0139146", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능 기반의 목걸이 타입 웨어러블 기기는, 단말기 또는 서버와 연결하기 위한 통 신부, 착용자로부터 발생하는 음향을 획득하는 적어도 하나의 마이크로폰, 음향에 포함된 적어도 하나의 부분 음 향 각각에 대한 인식 결과를 출력하는 음향 인식 모듈, 및 상기 적어도 하나의 마이크로폰 각각으로부터 획득된 음향을 처리하고, 처리된 음향을 상기 음향 인식 모듈로 제공하고, 상기 음향 인식 모듈로부터 출력된 인식 결과 에 기초하여, 설정된 동작 모드와 관련된 정보를 생성하는 컨트롤러를 포함한다."}
{"patent_id": "10-2018-0139146", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 웨어러블 기기에 관한 것으로서, 특히 착용자의 목에서 발생하는 각종 음향을 인식하는 인공지능 기 반의 목걸이 타입 웨어러블 기기에 관한 것이다."}
{"patent_id": "10-2018-0139146", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사회 전반적으로 삶의 질에 대한 관심이 높아지면서, 사람들은 각자의 건강 관리에 대해 주의 및 노력을 기울이 고 있다. 이러한 트렌드에 부합하여, 최근에는 사람들이 의료 기관을 방문하지 않고도 스스로 건강 상태를 확인 할 수 있도록 하는 다양한 기기들이 등장하고 있다. 특히, 사람의 신체 부위 일부에 착용되어 착용자의 건강 상태와 관련된 정보를 감지 및 제공하는 웨어러블 기기 들이 발매되거나, 이와 관련된 컨셉들이 등장하고 있다. 이와 관련하여 종래기술 1(등록특허공보 제10-1607548호, 2016.03.24. 등록)에는 위치 감지 센서와 가속도 센서 를 이용하여 식사 소요 시간, 손의 왕복 횟수나 이동 궤적을 이용하여 식습관과 관련된 정보를 제공하는 손목 시계형 웨어러블 통신 단말기가 개시되어 있다. 그러나, 종래기술 1의 경우 손의 움직임과 같은 간접적인 정보 를 통해 상기 식습관과 관련된 정보를 제공하므로, 정확한 정보의 제공이 어려울 수 있고, 제공 가능한 정보의 항목들이 한정적일 수 있다. 한편, 최근에는 인공지능(artificial intelligence) 기술에 대한 관심이 증가하고 있다. 상기 인공지능 기술의 여러 분야 중 인간의 학습 능력을 컴퓨터 상에서 실현하기 위한 기술로서 머신 러닝이 존재한다. 종래의 머신 러닝은 통계학 기반의 분류, 회귀, 군집 모델이 중심이었다. 특히, 분류, 회귀 모델의 지도 학습에 서는 학습 데이터의 특성과 이러한 특성을 기반으로 새로운 데이터를 구별하는 학습 모델이 사전에 정의되었다. 이와 달리, 최근 빅데이터 개념의 등장과 함께 관심도가 증가하는 딥러닝은, 방대한 양의 데이터를 이용하여 컴 퓨터가 스스로 특성을 찾아내고 판별하는 것이다. 최근 이러한 딥러닝과 관련되어 오픈소스로 제공되는 딥러닝 프레임워크들이 등장하였고, 이에 따라 효과적인 학습 및 인식을 위해, 딥러닝 알고리즘 외에 학습 과정, 학습 방법, 학습에 사용되는 데이터의 추출 및 선정과 관련된 기술이 더욱 중요해지고 있다. 또한, 머신 러닝을 다양한 제품이나 서비스에 이용하기 위한 연구가 증가 하고 있다. 선행기술문헌특허문헌 (특허문헌 0001) 1. 등록특허공보 제10-1607548호 (2016.03.24. 등록)"}
{"patent_id": "10-2018-0139146", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 착용자의 목이나 입으로부터 발생하는 음향을 보다 정확히 인식하여, 착용 자의 식습관이나 건강 등과 관련된 유용한 정보를 제공할 수 있는 웨어러블 기기를 제공하는 것이다."}
{"patent_id": "10-2018-0139146", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능 기반의 목걸이 타입 웨어러블 기기는, 단말기 또는 서버와 연결하기 위한 통신부, 착용자로부터 발생하는 음향을 획득하는 적어도 하나의 마이크로폰, 음향에 포함된 적어도 하나의 부분 음향 각각에 대한 인식 결과를 출력하는 음향 인식 모듈, 및 상기 적어도 하나의 마이크로폰 각각으로부터 획득 된 음향을 처리하고, 처리된 음향을 상기 음향 인식 모듈로 제공하고, 상기 음향 인식 모듈로부터 출력된 인식 결과에 기초하여, 설정된 동작 모드와 관련된 정보를 생성하는 컨트롤러를 포함한다. 상기 음향 인식 모듈은, 상기 음향의 주파수 특성에 기초하여 상기 적어도 하나의 부분 음향 각각을 인식하는 인식 모델을 갖는 음향 인식기를 포함하고, 상기 인식 결과는 상기 적어도 하나의 부분 음향 각각의 식별 정보 및 특성 정보를 포함할 수 있다. 상기 음향 인식기는, 상기 적어도 하나의 부분 음향 각각의 주파수 특성과, 상기 적어도 하나의 부분 음향 각각 의 인식 결과를 이용하여 상기 인식 모델을 업데이트할 수 있다. 실시 예에 따라, 상기 설정된 동작 모드가 식사 모드인 경우, 상기 컨트롤러는, 상기 적어도 하나의 마이크로폰 으로부터 획득된 음향에 기초하여 상기 착용자의 식사 개시 시점 및 식사 완료 시점을 인식하고, 상기 식사 개 시 시점과 상기 식사 완료 시점 사이에 획득되는 음향을 처리하고, 처리된 음향을 상기 음향 인식 모듈로 제공 할 수 있다. 상기 컨트롤러는, 상기 음향에 포함된 적어도 하나의 부분 음향 각각에 대한 인식 결과에 기초하여, 상기 착용 자에 대한 식습관 정보를 생성하고, 생성된 식습관 정보를 상기 단말기 또는 상기 서버로 전송하도록 상기 통신 부를 제어할 수 있다. 상기 식습관 정보는 상기 착용자의 식사 상태 또는 식사 중 행위와 관련된 적어도 하나의 항목에 대한 정보를 포함하고, 상기 적어도 하나의 항목은 식사 시간, 식사 중 대화 시간, 식사 중 수분 섭취 횟수 및 섭취량, 음식 물을 삼키기까지의 씹는 횟수 및 소요 시간 중 적어도 하나를 포함할 수 있다. 상기 목걸이 타입 웨어러블 기기는, 상기 생성된 식습관 정보에 기초한 알림을 출력하는 음향 출력부를 더 포함 할 수 있다. 실시 예에 따라, 상기 설정된 동작 모드가 식사 외 모드인 경우, 상기 컨트롤러는, 상기 적어도 하나의 마이크 로폰으로부터 획득된 음향에 기초하여 상기 착용자가 식사 중이 아닌 상태를 인식하고, 인식 결과에 따라 소정 시간동안 획득되는 음향을 처리하고, 처리된 음향을 상기 음향 인식 모듈로 제공할 수 있다. 상기 컨트롤러는, 상기 음향에 포함된 적어도 하나의 부분 음향 각각에 대한 인식 결과에 기초하여, 상기 착용 자에 대한 호흡기 관리 정보를 생성하고, 생성된 호흡기 관리 정보를 상기 단말기 또는 상기 서버로 전송하도록 상기 통신부를 제어할 수 있다. 상기 호흡기 관리 정보는 상기 착용자의 호흡기 상태 또는 수분 첩취와 관련된 적어도 하나의 항목에 대한 정보 를 포함하고, 상기 적어도 하나의 항목은 기침 또는 객담의 횟수, 빈도, 또는 발생 시간대, 및 수분 섭취량 중 적어도 하나를 포함할 수 있다. 실시 예에 따라, 상기 설정된 동작 모드가 수유 모니터링 모드인 경우, 상기 컨트롤러는, 상기 적어도 하나의 마이크로폰으로부터 획득된 음향에 기초하여 수유의 개시 시점 및 완료 시점을 인식하고, 상기 수유의 개시 시 점과 완료 시점 사이에 획득되는 음향을 처리하고, 처리된 음향을 상기 음향 인식 모듈로 제공할 수 있다.상기 컨트롤러는, 상기 음향에 포함된 적어도 하나의 부분 음향 각각에 대한 인식 결과에 기초하여, 상기 착용 자에 대한 수유 모니터링 정보를 생성하고, 생성된 수유 모니터링 정보를 상기 단말기 또는 상기 서버로 전송하 도록 상기 통신부를 제어할 수 있다. 상기 수유 모니터링 정보는 상기 착용자의 수유 상태와 관련된 적어도 하나의 항목에 대한 정보를 포함하고, 상 기 적어도 하나의 항목은 모유 섭취량, 삼킴 횟수, 수유 시간, 사레 걸림 횟수와 주기 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2018-0139146", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따르면, 목걸이 타입 웨어러블 기기는 다양한 상황에서 착용자로부터 발생하는 음향을 획 득하고, 인공지능 기반의 음향 인식 모듈을 통해 상기 음향으로부터 상기 상황과 관련된 다양한 부분 음향 을 정확히 식별할 수 있다. 웨어러블 기기는 식별된 부분 음향 및 부분 음향의 특성에 기초한 정보를 생성하여 착용자에게 제공할 수 있다. 즉, 착용자는 웨어러블 기기를 착용하는 것 만으로도 각종 유용한 정보를 편리하게 획득할 수 있다."}
{"patent_id": "10-2018-0139146", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명한다. 첨부된 도면은 본 명세서에 개 시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사 상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 도 1은 본 발명의 일 실시 예에 따른 웨어러블 기기 및 이와 연결되는 단말기와 서버를 포함하는 시스템의 개념 도이다. 도 1을 참조하면, 웨어러블 기기는 사용자의 신체의 특정 부위에 착용가능한 전자 기기로 구현될 수 있다. 예컨대, 웨어러블 기기는 사용자의 목에 착용되는 목걸이 타입 웨어러블 기기일 수 있다. 상기 목걸이 타입 웨어러블 기기는 음향을 출력하는 무선 헤드셋 등을 포함할 수 있다. 한편, 웨어러블 기기는 사용자의 목에 착용되므로, 착용 시 사용자의 목과 접촉되거나 목과 인접하게 위치 할 수 있다.이에 따라, 웨어러블 기기는 사용자의 목(기도나 식도)이나 입에서 발생하는 음향(소리)를 효과적으로 획득 할 수 있다. 웨어러블 기기는 획득된 음향을 이용하여, 착용자의 식습관이나 호흡기 상태 등의 정보를 제공 할 수 있다. 또한, 웨어러블 기기는 유아에 착용되어 유아의 모유 섭취 시 수유 상태의 모니터링 정보를 부 모에게 제공할 수도 있다. 특히, 웨어러블 기기는 인공지능 기반의 인식 모듈을 이용하여 상기 획득된 음향을 인식함으로써, 음향의 식별 정보나 특성 정보를 포함하는 인식 결과를 획득할 수 있다. 웨어러블 기기는 상기 인식 결과에 기초하 여 상기 다양한 정보를 제공할 수 있다. 예컨대, 상기 인식 모듈은 딥러닝(deep learning)으로 학습된 인공신경 망을 포함할 수 있다. 이러한 웨어러블 기기의 구성 및 동작에 대해서는 추후 도 2 내지 도 11을 통해 보다 상세히 설명한다. 단말기는 웨어러블 기기와 연결되어, 웨어러블 기기와 다양한 데이터를 송수신할 수 있다. 단말기 는 스마트폰, 태블릿 PC 등의 이동 단말기를 의미할 수 있으나, 실시 예에 따라서는 PC와 같은 고정형 단말 기를 포함할 수 있다. 특히, 웨어러블 기기는 상기 음향의 인식 결과에 기초한 다양한 정보를 단말기로 전송할 수 있다. 단말 기는 웨어러블 기기로부터 수신된 정보를 디스플레이나 스피커 등의 출력 수단을 통해 출력함으로써, 상기 정보를 사용자에게 제공할 수 있다. 서버는 웨어러블 기기 또는 단말기와 연결되어, 웨어러블 기기로부터 상기 음향의 인식 결과에 기초한 각종 정보를 수신할 수 있다. 서버는 수신된 정보를 저장하는 데이터베이스 서버를 포함할 수 있다. 실시 예에 따라, 서버는 수신된 정보에 기초하여 사용자의 홈 어플라이언스의 동작을 자동으로 제어하는 제 어 서버를 포함할 수도 있다. 또는, 서버는 수신된 정보에 기초하여 사용자의 건강 상태를 모니터링하거나 관리하는 의료 서비스 제공자의 서버를 포함할 수도 있다. 또는, 서버는 웨어러블 기기로부터 획득되는 다양한 음향을 학습하고, 학습 결과에 따라 생성되는 학습 데이터를 웨어러블 기기로 제공하여 상기 웨어러 블 기기의 인식 모듈을 업데이트하는 학습 서버를 포함할 수도 있다. 도 2는 본 발명의 일 실시 예에 따른 웨어러블 기기의 개략적인 블록도이고, 도 3은 본 발명의 일 실시 예에 따 른 목걸이 타입 웨어러블 기기의 예시도이다. 도 2를 참조하면, 웨어러블 기기는 통신부, 입력부, 센서부, 출력부, 메모리, 및 컨트롤러를 포함할 수 있다. 도 2에 도시된 구성요소들은 웨어러블 기기를 구현하는 데 있어서 필 수적인 것은 아닌 바, 웨어러블 기기는 도 2에 도시된 구성 요소들보다 많거나 적은 구성 요소들을 포함할 수도 있다. 통신부는 웨어러블 기기를 단말기나 서버 등과 연결시키는 적어도 하나의 통신 모듈을 포함할 수 있다. 예컨대, 통신부는 와이파이(Wi-Fi) 등과 같은 무선 인터넷 모듈이나, 블루투스(Bluetooth) 등과 같은 근거리 무선 통신 모듈 등을 포함할 수 있다. 입력부는 사용자의 조작 등의 행위에 기초하여 웨어러블 기기의 동작과 관련된 제어 명령이나 정보를 웨어러블 기기로 입력하는 적어도 하나의 입력 수단을 포함할 수 있다. 예컨대, 상기 입력 수단은 버튼, 터 치 패드, 다이얼 등을 포함할 수 있다. 특히, 사용자는 입력부를 통해 도 7에서 후술할 동작 모드를 설정하는 입력 동작을 수행할 수 있다. 예컨 대, 상기 동작 모드는 식사 모드, 식사 외 모드, 수유 모니터링 모드 중 어느 하나에 해당할 수 있으나, 이에 한정되는 것은 아니다. 웨어러블 기기는 설정된 동작 모드에 기초하여, 음향의 인식 동작 및 인식 결과에 기초한 정보의 생성 동작을 수행할 수 있다. 센서부는 웨어러블 기기의 착용자의 목(기도 또는 식도)이나 입 등으로부터 발생하는 음향(소리)를 감 지하는 복수의 마이크로폰(131~133)을 포함할 수 있다. 제어부는 복수의 마이크로폰(131~133) 각각으로부 터 음향을 획득하고, 획득된 음향의 합성 및 노이즈 제거를 통해 보다 정확한 음향을 획득할 수 있다. 상기 획 득된 음향에는 다양한 종류의 부분 음향이 포함될 수 있다. 도 3을 참조하면, 웨어러블 기기의 하우징은 착용자의 목에 착용가능한 형태(예컨대, 목걸이 형태)로 형성될 수 있다. 하우징 내에 구비되는 복수의 마이크로폰(131~133)은 서로 이격된 위치에 배치될 수 있다. 예컨대, 제1 마이크로폰과 제2 마이크로폰은 착용 시 착용자의 성대와 인접하도록 배치될 수 있고, 제3 마이크로폰은 착용 시 착용자의 목덜미에 인접하도록 배치될 수 있다. 즉, 복수의 마이크로폰(131~133)은 착용자의 목과 인접하도록 배치됨으로써, 착용자의 목이나 입으로부터 발생하는 음향을 정확히 획 득할 수 있다. 또한, 복수의 마이크로폰(131~133)은 상기 음향을 다양한 위치에서 획득할 수 있고, 제어부(16 0)는 다양한 위치에서 획득된 음향의 합성 및 노이즈 제거를 통해 보다 정확한 음향의 획득이 가능하다. 한편, 사용자가 마이크로폰(131~133)을 통해 음성 형태의 제어 명령이나 정보를 입력 가능한 경우, 마이크로폰 (131~133)은 상기 입력부로서 기능할 수도 있다. 비록 도시되지는 않았으나, 센서부는 마이크로폰(131~133) 외의 추가적인 센서들(예컨대, 근접 센서 등)을 더 포함할 수도 있다. 출력부는 웨어러블 기기가 제공하는 기능과 관련된 정보나 데이터 등을 출력하거나, 웨어러블 기기 의 상태에 관한 정보를 출력하는 출력 수단을 구비할 수 있다. 예컨대, 웨어러블 기기가 무선 헤드셋으로 구현되어 사운드 출력 기능을 제공하는 경우, 출력부는 사 운드를 출력하기 위한 음향 출력부를 포함할 수 있다. 또한, 출력부는 웨어러블 기기의 전원 상 태, 동작 상태 등을 표시하는 광 출력부를 더 포함할 수 있다. 메모리는 웨어러블 기기에 포함된 구성들의 동작을 위한 제어 데이터나 알고리즘 등을 저장할 수 있다. 또한, 메모리는 음향 출력부를 통해 출력되기 위해 단말기나 서버로부터 수신되는 사 운드 데이터를 저장할 수 있다. 컨트롤러는 웨어러블 기기의 전반적인 동작을 제어할 수 있다. 컨트롤러는 사용자에게 웨어러블 기기가 지원하는 기능을 제공하기 위해, 웨어러블 기기에 포함된 적어도 하나의 구성을 제어할 수 있다. 이러한 컨트롤러는 적어도 하나의 CPU, AP(application processor), 컨트롤러, 마이크로컴퓨터, 집적회로 등을 포함할 수 있다. 한편, 본 발명의 실시 예에 따른 컨트롤러는, 복수의 마이크로폰(131~133)으로부터 획득되는 음향을 인공 지능 기반의 음향 인식 모듈로 입력하여, 상기 음향을 인식할 수 있다. 음향 인식 모듈은 음향의 인 식 결과로서, 상기 음향에 포함된 적어도 하나의 부분 음향 각각의 식별 정보나, 상기 적어도 하나의 부분 음향 각각의 특성 정보를 출력할 수 있다. 상기 식별 정보는 사용자의 목이나 입에서 발생하는 음향의 종류를 식별하는 정보로서, 예컨대 음식물을 씹는 음향, 음식물을 삼키는 음향, 대화 음향, 수분을 섭취하는 음향, 기침 음향 등에 해당할 수 있다. 또한, 상기 특성 정보는 식별된 부분 음향 각각에 대한 특성으로서, 부분 음향의 발생 시각, 지속 시간, 횟수, 간격 등을 포함할 수 있다. 예컨대, 음향 인식 모듈은 머신 러닝(machine learning)으로 기학습된 인공신경망(artificial neural network; ANN)을 갖는 음향 인식기를 포함하여, 입력된 음향을 인식하여 상기 식별 정보나 특성 정보를 포함하 는 인식 결과를 출력할 수 있다. 컨트롤러는 음향 인식 모듈의 인식 결과에 기초한 각종 정보를 생성하고, 생성된 정보를 출력부(14 0)를 통해 출력하거나, 통신부를 통해 단말기 또는 서버로 전송할 수 있다. 이하, 도 4 내지 도 6을 참조하여 음향 인식 모듈에 적용되는 인공지능 기술의 일례로서 딥러닝에 대해 보 다 상세히 설명한다. 도 4와 도 5는 본 발명의 실시 예에 따른 웨어러블 기기의 음향 인식 모듈에 적용되는 인공지능의 일례로서 딥 러닝(deep learning)을 설명하기 위한 도면들이다. 인공지능이란 인간의 지능으로 할 수 있는 사고, 학습, 자기 개발 등을 컴퓨터가 할 수 있도록 하는 방법을 연 구하는 컴퓨터 공학 및 정보기술의 일 분야에 해당한다. 이러한 인공지능의 연구 분야 중 하나인 머신 러닝은 경험적 데이터를 기반으로 예측을 수행하고, 학습을 통해 스스로의 성능을 향상시키는 시스템을 의미할 수 있다. 머신 러닝의 일종인 딥러닝 기술은 데이터를 기반으로 다단계로 깊은 수준까지 내려가 학습하는 것이다. 딥러닝은 단계를 높여갈수록 복수의 데이터로부터 핵심적인 데이터를 추출하는 머신 러닝 알고리즘의 집합을 나 타낼 수 있다. 딥러닝 구조는 인공신경망(artificial neural network(ANN))을 포함할 수 있고, 예를 들어 딥러닝 구조는 CNN(convolutional neural network), RNN(recurrent neural network), DBN(deep belief network) 등 심층신경 망(deep neural network)으로 구성될 수 있다. 도 4를 참조하면, 인공신경망은 입력 레이어(Input Layer), 히든 레이어(Hidden Layer), 및 출력 레이어 (Output Layer)를 포함할 수 있다. 각 레이어는 복수의 노드들을 포함하고, 각 레이어는 다음 레이어와 연결된 다. 인접한 레이어 사이의 노드들은 웨이트(weight)를 가지고 서로 연결될 수 있다. 도 5를 참조하면, 컴퓨팅 장치(머신)는 투입된 입력 데이터로부터 일정한 패턴을 발견해 특징맵(feature map)을 형성할 수 있다. 예컨대, 컴퓨팅 장치(머신)는 하위레벨 특징부터, 중간레벨 특징, 및 상위레 벨 특징을 추출하여, 대상을 인식하고 그 결과를 출력할 수 있다. 인공신경망은 다음 순서의 레이어로 갈수록 더욱 상위레벨의 특징으로 추상화할 수 있다. 도 4와 도 5를 참조하면, 각 노드들은 활성화 모델에 기초하여 동작할 수 있고, 활성화 모델에 따라 입력값에 대응하는 출력값이 결정될 수 있다. 임의의 노드, 예를 들어, 하위레벨 특징의 출력값은 해당 노드와 연결된 다음 레이어, 예를 들어, 중간레 벨 특징의 노드로 입력될 수 있다. 다음 레이어의 노드, 예를 들어, 중간레벨 특징의 노드는 하위레 벨 특징의 복수의 노드들로부터 출력되는 값들을 입력받을 수 있다. 이 때, 각 노드의 입력값은 이전 레이어의 노드의 출력값에 웨이트(weight)가 적용된 값일 수 있다. 웨이트는 노드 간의 연결 강도를 의미할 수 있다. 또한, 딥러닝 과정은 적절한 웨이트를 찾아내는 과정으로도 볼 수 있다. 한편, 임의의 노드, 예를 들어, 중간레벨 특징의 출력값은 해당 노드와 연결된 다음 레이어, 예를 들어, 상위레벨 특징의 노드로 입력될 수 있다. 다음 레이어의 노드, 예를 들어, 상위레벨 특징의 노드는 중간레벨 특징의 복수의 노드로부터 출력되는 값들을 입력받을 수 있다. 인공신경망은 각 레벨에 대응하는 학습된 레이어(layer)를 이용하여, 각 레벨에 대응하는 특징 정보를 추출할 수 있다. 인공신경망은 순차적으로 추상화하여, 가장 상위 레벨의 특징 정보를 활용하여 소정 대상을 인식할 수 있다. 예를 들어, 딥러닝에 의한 얼굴인식 과정을 살펴보면, 컴퓨터는 입력 영상으로부터, 픽셀의 밝기에 따라 밝은 픽셀과 어두운 픽셀을 구분하고, 테두리, 에지 등 단순한 형태를 구분한 후, 조금 더 복잡한 형태와 사물을 구 분할 수 있다. 최종적으로 컴퓨터는 인간의 얼굴을 규정하는 형태를 파악할 수 있다. 본 발명에 따른 딥러닝 구조는 공지된 다양한 구조를 이용할 수 있다. 예를 들어, 본 발명에 따른 딥러닝 구조 는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network) 등일 수 있다. RNN(Recurrent Neural Network)은, 자연어 처리 등에 많이 이용되고 있으며, 시간의 흐름에 따라 변하는 시계열 데이터(Time-series data) 처리에 효과적인 구조로 매 순간마다 레이어를 쌓아올려 인공신경망 구조를 구성할 수 있다. DBN(Deep Belief Network)은 딥러닝 기법인 RBM(Restricted Boltzman Machine)을 다층으로 쌓아 구성되는 딥러 닝 구조이다. RBM(Restricted Boltzman Machine) 학습을 반복하여, 일정 수의 레이어가 되면 해당 개수의 레이 어를 가지는 DBN(Deep Belief Network)를 구성할 수 있다. CNN(Convolutional Neural Network)은 사람이 물체를 인식할 때 물체의 기본적인 특징들을 추출한 다음 뇌 속에 서 복잡한 계산을 거쳐 그 결과를 기반으로 물체를 인식한다는 가정을 기반으로 만들어진 사람의 뇌 기능을 모 사한 모델이다. 한편, 인공신경망의 학습은 주어진 입력에 대하여 원하는 출력이 나오도록 노드간 연결선의 웨이트(weight)를 조정(필요한 경우 바이어스(bias) 값도 조정)함으로써 이루어질 수 있다. 또한, 인공신경망은 학습에 의해 웨이 트(weight) 값을 지속적으로 업데이트시킬 수 있다. 또한, 인공신경망의 학습에는 역전파(Back Propagation) 등 의 방법이 사용될 수 있다. 한편, 메모리 또는 서버에는 상기 인공신경망을 학습하기 위한 데이터가 저장될 수 있다. 또한, 실시 예에 따라서는, 메모리에는 인공신경망 구조를 이루는 웨이트, 바이어스들이 저장될 수 있다. 또는, 실시예에 따라서는, 상기 인공신경망 구조를 이루는 웨이트, 바이어스들은 음향 인식 모듈의 임베디드 메모리 에 저장될 수도 있다. 한편, 음향 인식 모듈은 복수의 마이크로폰(131~133)으로부터 획득되는 음향이 인식될 때마다, 획득된 음 향과 인식 결과를 이용하여 음향 인식기의 학습 과정을 수행할 수 있다. 상기 학습 과정이 수행됨에 따라, 웨이 트 등 인공신경망 구조가 업데이트될 수 있다. 이를 위해, 웨어러블 기기는 학습 모듈을 포함할 수 있다. 상기 학습 모듈은 음향 인식 모듈 내에 구현되거나, 별도로 구현될 수 있다. 도 6은 음향 인식 모듈의 인식 동작 및 학습 동작을 설명하기 위한 도면이다. 도 6을 참조하면, 음향 인식 모듈의 음향 인식기는 음향이 입력되면, 입력된 음향을 인식하여 인식 결과를 출력할 수 있다. 실시 예에 따라, 음향 인식기는 1회의 인식 결과를 최종 인식 결과로서 출력할 수 있으나, 복 수 회의 인식 동작을 반복 또는 연속 수행하고, 복수 회의 인식 결과에 기초하여 최종 인식 결과를 출력함으로 써, 입력된 음향에 대한 인식 정확도를 보다 향상시킬 수도 있다. 한편, 음향 인식기는 수신된 음향을 수집하여 데이터베이스를 구축하고, 획득된 음향에 포함된 부분 음향 각각 으로부터 추출된 특징점들과, 부분 음향 각각의 인식 결과를 이용하여 음향 인식기의 학습을 수행할 수 있다. 예컨대, 음향 인식기는 수집된 음향에 포함된 부분 음향 각각의 주파수 특성을 추출할 수 있다. 음향 인식기는 MFCC(mel-frequency cepstral coefficient) 등의 공지된 알고리즘을 이용하여 상기 부분 음향 각각의 주파수 특성을 추출할 수 있다. 음향 인식기는 상기 부분 음향 각각의 주파수 특성에 기초하여 상기 음향 인식기의 학 습 및 인식 동작을 수행할 수 있다. 구체적으로, 음향 인식기는 입력된 음향을 일정 구간씩 분할하고, 분할된 구간 각각에 대한 주파수 스펙트럼을 분석함으로써 구간들 각각의 주파수 특성을 추출할 수 있다. 음향 인식기는 구간들 각각의 주파수 특성(주파수 특징 벡터)을 인공신경망에 입력함으로써, 각 구간의 음향을 인식할 수 있다. 음향 인식기는 인식 결과에 기초 하여, 획득된 음향에 포함된 부분 음향들을 구분하고, 부분 음향들 각각의 인식 결과를 출력할 수 있다. 부분 음향들 각각은 적어도 하나의 구간을 포함할 수 있다. 음향 인식기는 획득된 음향에 포함된 부분 음향들 각각의 주파수 특성과, 상기 부분 음향들 각각의 인식 결과에 기초하여 음향 인식기의 학습을 수행할 수 있다. 이러한 음향 인식기는 시간의 흐름에 따라 변화하는 주파수 패턴을 갖는 음향을 인식하므로, 상기 인공신경망은 RNN(recurrent neural network), CNN(convolutional neural network), 또는 이들의 조합으로 구성될 수 있다. 음향 인식기의 학습을 통해, 상기 음향 인식기에 포함된 인공신경망의 파라미터들(웨이트 및 바이어스)이 업데 이트될 수 있다. 상기 데이터베이스는 웨어러블 기기의 메모리 또는 음향 인식 모듈의 임베디드 메모리에 저장되거나, 서버의 메모리에 저장될 수 있다. 이하 도 7 내지 도 11을 참조하여, 본 발명의 실시 예에 따른 웨어러블 기기가 인공지능 기반의 음향 인식 을 통해 다양한 정보를 제공하는 동작을 설명하기로 한다. 도 7은 본 발명의 실시 예에 따른 웨어러블 기기의 동작을 설명하기 위한 플로우차트이다. 도 7을 참조하면, 웨어러블 기기는 사용자에게 제공할 정보와 관련된 동작 모드를 설정할 수 있다(S100). 본 발명의 실시 예와 관련하여, 웨어러블 기기는 복수의 모드들을 포함할 수 있고, 모드들에 따라 서로 다 른 정보를 제공할 수 있다. 도 2에서 상술한 바와 같이, 상기 모드들은 식사 모드, 식사 외 모드, 수유 모니터 링 모드 등을 포함할 수 있다. 컨트롤러는 입력부 또는 단말기 등을 통해 상기 복수의 모드들 중 어느 하나의 모드를 선택하는 입력을 수신하고, 웨어러블 기기의 동작 모드를 상기 선택된 모드로 설정할 수 있다. 웨어러블 기기는 복수의 마이크로폰(131~133)을 통해 음향을 획득할 수 있다(S110). 컨트롤러는 복수의 마이크로폰(131~133) 각각으로부터 음향을 획득할 수 있다. 복수의 마이크로폰 (131~133) 각각은 배치 위치가 서로 다르므로, 복수의 마이크로폰(131~133) 각각에 의해 획득된 음향의 신호 특 성이 서로 다를 수 있다. 컨트롤러는 획득된 각각의 음향에 대해 합성 및 노이즈 제거 등의 처리 동작을 수행할 수 있다. 상기 처리 동작에 의해, 보다 정확한 음향의 획득이 가능하다. 한편, 상기 음향은 상기 설정된 동작 모드와 관련된 사용자의 행위가 수행되는 시간 동안, 상기 사용자로부터 발생하는 적어도 하나의 부분 음향을 포함한다. 웨어러블 기기는, 인공지능 기반의 음향 인식 모듈을 통해, 상기 획득된 음향을 인식할 수 있다 (S120). 컨트롤러는 상기 획득된 음향(또는 처리된 음향)을 음향 인식 모듈로 입력할 수 있다. 상술한 바와 같이, 음향 인식 모듈은 인공지능의 일 분야인 머신 러닝 기반의 인공신경망이 적용된 음향 인식기를 포함 할 수 있다. 음향 인식 모듈은 상기 음향 인식기를 통해, 상기 입력된 음향에 포함된 적어도 하나의 부분 음향 각각의 식별 정보 및 특성 정보를 인식하고, 상기 인식된 정보를 포함하는 인식 결과를 출력할 수 있다. 상기 식별 정보와 특성 정보는 S100 단계에서 설정된 동작 모드에 따라 서로 다를 수 있다. 이 경우, 상기 음향 인식기는 복수의 모드들 각각에 대해 구축된 인공신경망 구조를 포함할 수 있으나, 실시 예에 따라서는 복수의 모드들에 대해 통합된 하나의 인공신경망 구조를 포함할 수도 있다. 웨어러블 기기는 인식된 음향에 기초하여, S100 단계에서 설정된 동작 모드와 관련된 정보를 생성할 수 있 다(S130). 웨어러블 기기는 생성된 정보를 단말기 또는 서버로 전송할 수 있다(S140). 컨트롤러는 상기 인식 결과에 포함된 적어도 하나의 부분 음향 각각의 식별 정보와 특성 정보로부터, S100 단계에서 설정된 동작 모드와 관련된 정보를 생성할 수 있다. 컨트롤러는 생성된 정보를 통신부를 통 해 단말기 또는 서버로 전송할 수 있다. 실시 예에 따라, 컨트롤러는 생성된 정보를 출력부를 통해 출력할 수도 있다. 즉, 본 발명의 실시 예에 따르면, 웨어러블 기기는 다양한 상황에서 사용자로부터 발생하는 음향을 획득하 고, 인공지능 기반의 음향 인식 모듈을 통해 상기 음향으로부터 상기 상황과 관련된 다양한 부분 음향을 정확히 식별할 수 있다. 웨어러블 기기는 식별된 부분 음향 및 부분 음향의 특성에 기초한 정보를 생성하여 사용자에게 제공할 수 있다. 즉, 사용자는 웨어러블 기기를 착용하는 것 만으로도 각종 유용한 정보를 편리 하게 획득할 수 있다. 이하, 도 8 내지 도 11을 참조하여, 웨어러블 기기가 다양한 동작 모드에 따라 음향을 인식하고, 인식된 음 향에 기초한 정보를 제공하는 실시 예들을 설명한다. 도 8은 도 7에 도시된 웨어러블 기기의 동작과 관련하여, 웨어러블 기기가 인식된 음향으로부터 식습관 정보를 제공하는 실시 예를 나타내는 예시도이다. 도 8의 실시 예는, 도 7의 S100 단계에서 설정되는 동작 모드가 식사 모드인 경우에 해당한다. 도 8을 참조하면, 웨어러블 기기는 사용자의 목이나 입으로부터 발생하는 음향을 획득할 수 있다 (S800). 도 7의 S110 단계에서 상술한 바와 같이, 컨트롤러는 복수의 마이크로폰(131~133) 각각으로부터 음향을 획 득하고, 획득된 음향을 처리하여 상기 음향을 획득할 수 있다. 한편, 상기 음향은 사용자의 식사 개시 시점부터 완료 시점 동안 지속적으로 획득될 수 있다. 이와 관련하 여, 컨트롤러는 입력부를 통해 식사 개시 입력과 완료 입력을 수신하여 상기 식사 개시 시점과 완료 시점을 인식할 수 있다. 또는, 컨트롤러는 복수의 마이크로폰(131~133)으로부터 수신되는 음향의 특성으로 부터 상기 식사 개시 시점과 완료 시점을 인식할 수도 있고, 기타 다양한 방식으로 상기 식사 개시 시점과 완료 시점을 인식할 수 있다. 웨어러블 기기는 인공지능 기반의 음향 인식 모듈을 통해, 상기 획득된 음향의 인식 동작을 수행 할 수 있다(S810). 예컨대, 설정된 모드가 식사 모드인 경우, 음향 인식 모듈은 상기 음향으로부터 식사와 관련된 부분 음향 및 부분 음향의 특성을 인식할 수 있다. 도 8에 도시된 바와 같이, 음향 인식 모듈은 음향에 포함된 적어도 하나의 부분 음향 각각의 식별 정 보(예컨대, “딱딱한 음식물을 씹는 음향”, “음식물을 삼키는 음향”, “대화 음향”, 및 “물을 삼키는 음향 ”), 및 식별된 부분 음향의 특성 정보(예컨대, 각 음향의 빈도 수나 지속 시간)를 포함하는 인식 결과를 획득할 수 있다. 웨어러블 기기는 음향 인식 모듈의 인식 결과에 기초하여, 사용자의 식습관 정보를 생성할 수 있다(S820). 식습관 정보는, 사용자의 식사 상태나 식사 중 행위 등 식사 모드와 관련된 복수의 항목들에 대한 정보를 포함할 수 있다. 예컨대, 복수의 항목들은 분당 음식물의 씹는 횟수, 음식물의 종류별(딱딱한 음식/부드러운 음 식)로 삼키는 데까지의 씹는 횟수 및 시간, 식사 중 대화시간, 식사 중 수분 섭취 횟수 및 섭취량, 및 전체 식 사 시간을 포함할 수 있으나, 이에 한정되는 것은 아니다. 상기 인식 결과로부터 상기 복수의 항목들에 대한 정보를 생성하기 위해, 메모리에는 상기 복수의 항 목들 각각에 대한 정보를 생성하기 위한 알고리즘이 저장될 수 있다. 웨어러블 기기는 생성된 식습관 정보를 사용자에게 제공할 수 있다(S830). 예컨대, 컨트롤러는 생성된 식습관 정보에 기초한 알림을 생성하고, 생성된 알림을 음향 출력부 등을 통해 출력할 수 있다. 또는, 컨트롤러는 생성된 식습관 정보 또는 알림을 단말기나 서버로 전송할 수 있다. 단말기는 수신된 식습관 정보에 기초한 알림 또는 수신된 알림을 디스플레이나 스피커 등을 통해 출력할 수 있다. 서버는 수신된 식습관 정보를 저장하거나, 의료 서비스 서버 등으로 제공할 수 있다. 즉, 도 8에 도시된 실시 예에 따르면, 웨어러블 기기는 사용자의 식사 중 발생하는 음향을 획득하고, 인공 지능 기반의 음향 인식 모듈을 통해 상기 음향으로부터 사용자의 식사 상태나 식사 습관 등과 관련된 다양 한 부분 음향을 정확히 식별할 수 있다. 웨어러블 기기는 식별된 부분 음향 및 부분 음향의 특성 정보에 기 초하여 식습관 정보를 생성하고, 생성된 식습관 정보를 사용자에게 제공할 수 있다. 즉, 사용자는 식사 중 웨어 러블 기기를 착용하는 것 만으로도 정확한 식습관 정보를 편리하게 획득할 수 있다. 도 9는 도 7에 도시된 웨어러블 기기의 동작과 관련하여, 웨어러블 기기가 인식된 음향으로부터 호흡기 관리 정 보를 제공하는 실시 예를 나타내는 예시도이다. 도 9의 실시 예는, 도 7의 S100 단계에서 설정된 동작 모드가 식사 외 모드인 경우에 해당할 수 있다. 도 9를 참조하면, 웨어러블 기기는 사용자의 목이나 입으로부터 발생하는 음향을 획득할 수 있다 (S900). 도 7의 S110 단계에서 상술한 바와 같이, 컨트롤러는 복수의 마이크로폰(131~133) 각각으로부터 음향을 획 득하고, 획득된 음향을 처리하여 상기 음향을 획득할 수 있다. 한편, 상기 음향은 사용자의 식사 완료 후부터 소정 시간 동안, 또는 사용자가 식사 중이지 않은 소정 시 간 동안 지속적으로 획득될 수 있다. 컨트롤러는 복수의 마이크로폰(131~133)으로부터 수신되는 음향의 특 성으로부터 사용자의 식사가 완료되었음을 인식하거나, 사용자가 식사 중이지 않은 상태임을 인식하여, 음향을 복수의 마이크로폰(131~133)으로부터 획득할 수 있다. 웨어러블 기기는 인공지능 기반의 음향 인식 모듈을 통해, 상기 획득된 음향의 인식 동작을 수행 할 수 있다(S910). 설정된 모드가 식사 외 모드인 경우, 음향 인식 모듈은 상기 음향으로부터 사용자의 호흡기 상태나, 수분 섭취 등과 관련된 부분 음향 및 부분 음향의 특성을 인식할 수 있다. 도 9에 도시된 바와 같이, 음향 인식 모듈은 음향에 포함된 적어도 하나의 부분 음향 각각의 식별 정 보(예컨대, “기침”, “객담(가래)” 등), 및 식별된 부분 음향의 특성 정보(예컨대, 각 음향의 빈도 수나 지 속 시간 등)를 포함하는 인식 결과를 획득할 수 있다. 웨어러블 기기는 음향 인식 모듈의 인식 결과에 기초하여, 사용자의 호흡기 관리 정보를 생 성할 수 있다(S920). 호흡기 관리 정보는, 사용자의 호흡기 상태나 수분 섭취 상태 등과 관련된 복수의 항목들에 대한 정보를 포함할 수 있다. 예컨대, 복수의 항목들은 기침 횟수, 객담의 배출 횟수, 기침 또는 객담의 주 발생 시간대, 수 분 섭취량 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 상기 인식 결과로부터 상기 복수의 항목들에 대한 정보를 생성하기 위해, 메모리에는 상기 복수의 항 목들 각각에 대한 정보를 생성하기 위한 알고리즘이 저장될 수 있다. 웨어러블 기기는 생성된 호흡기 관리 정보를 사용자에게 제공할 수 있다(S930). S930 단계는 도 8의 S830 단계와 유사할 수 있다. 추가로, 컨트롤러는 호흡기 관리 정보를, 사용자의 가정 내의 홈 어플라이언스를 제어하는 제어 서버 로 전송할 수 있다. 상기 제어 서버는 수신된 호흡기 관리 정보에 기초하여 공기청정기, 공기조화기, 가습 기 등의 공기 환경을 조절하는 홈 어플라이언스의 동작을 제어할 수 있다. 예컨대, 제어 서버는 호흡기 관리 정 보에 기초하여, 사용자의 기침 또는 객담의 주 발생 시간대에서 공기청정기의 공기청정 기능을 활성화하도 록 공기청정기를 제어할 수 있다. 즉, 도 9에 도시된 실시 예에 따르면, 웨어러블 기기는 사용자의 식사 외 상황에서 발생하는 음향을 획득하 고, 인공지능 기반의 음향 인식 모듈을 통해 상기 음향으로부터 사용자의 호흡기 상태나 수분 섭취와 관련 된 다양한 부분 음향을 정확히 식별할 수 있다. 웨어러블 기기는 식별된 부분 음향 및 부분 음향의 특성 정 보에 기초하여 호흡기 관리 정보를 생성하고, 생성된 호흡기 관리 정보를 사용자에게 제공할 수 있다. 즉, 사용 자는 평소에 웨어러블 기기를 착용하는 것 만으로도 호흡기와 관련된 정보나 수분 섭취와 관련된 정보를 편 리하게 획득할 수 있다. 도 10은 도 7에 도시된 웨어러블 기기의 동작과 관련하여, 웨어러블 기기가 인식된 음향으로부터 수유 모니터링 정보를 제공하는 실시 예를 나타내는 예시도이다. 도 10의 실시 예는, 도 7의 S100 단계에서 설정된 동작 모드가 유아에 대한 수유 모니터링 모드인 경우에 해당 할 수 있다. 도 10을 참조하면, 웨어러블 기기는 사용자(유아)의 목이나 입으로부터 발생하는 음향을 획득할 수 있다(S1000). 도 7의 S110 단계에서 상술한 바와 같이, 컨트롤러는 복수의 마이크로폰(131~133) 각각으로부터 음향을 획 득하고, 획득된 음향을 처리하여 상기 음향을 획득할 수 있다. 한편, 상기 음향은 유아에 대한 수유가 이루어지는 동안 지속적으로 획득될 수 있다. 예컨대, 컨트롤러 는 복수의 마이크로폰(131~133)으로부터 수신되는 음향의 특성으로부터 상기 수유가 개시/완료됨을 인식하 여, 음향을 복수의 마이크로폰(131~133)으로부터 획득할 수 있다. 웨어러블 기기는 인공지능 기반의 음향 인식 모듈을 통해, 상기 획득된 음향의 인식 동작을 수 행할 수 있다(S1010). 설정된 모드가 수유 모니터링 모드인 경우, 음향 인식 모듈은 상기 음향으로부터 유아의 모유 삼킴 횟수, 삼킴 주기, 총 수유 시간 등 유아에 대한 수유와 관련된 부분 음향 및 부분 음향의 특성을 인식할 수 있 다. 도 10에 도시된 바와 같이, 음향 인식 모듈은 음향에 포함된 적어도 하나의 부분 음향 각각의 식별 정보(예컨대, “삼킴” 등), 및 식별된 부분 음향의 특성 정보(예컨대, 각 부분 음향의 빈도 수나 지속 시간, 주기 등)를 포함하는 인식 결과를 획득할 수 있다. 웨어러블 기기는 음향 인식 모듈의 인식 결과에 기초하여, 유아에 대한 수유 모니터링 정보 를 생성할 수 있다(S1020). 수유 모니터링 정보는, 유아의 모유 섭취량, 모유 삼킴 횟수, 총 수유 시간 등과 관련된 복수의 항목들에 대한 정보를 포함할 수 있다. 상기 인식 결과로부터 상기 복수의 항목들에 대한 정보를 생성하기 위해, 메모리에는 상기 복수의 항목들 각각에 대한 정보를 생성하기 위한 알고리즘이 저장될 수 있다. 웨어러블 기기는 생성된 수유 모니터링 정보를 부모 등에게 제공할 수 있다(S1030). S1030 단계는 도 8의 S830 단계와 유사한 바, 이에 대한 구체적인 설명은 생략하기로 한다. 즉, 도 10에 도시된 실시 예에 따르면, 웨어러블 기기는 유아에 대한 수유 중 유아로부터 발생하는 음향을 획득하고, 인공지능 기반의 음향 인식 모듈을 통해 상기 음향으로부터 유아의 모유 섭취 상태와 관련된 다 양한 부분 음향을 정확히 식별할 수 있다. 웨어러블 기기는 식별된 부분 음향 및 부분 음향의 특성 정보에 기초하여 수유 모니터링 정보를 생성하고, 생성된 수유 모니터링 정보를 부모 등에게 제공할 수 있다. 즉, 부모 는 유아에게 웨어러블 기기를 착용하여, 유아에 대한 수유와 관련된 정보를 편리하게 획득할 수 있다. 도 11은 도 7에 도시된 웨어러블 기기의 동작과 관련하여, 웨어러블 기기가 인식된 음향으로부터 수유 모니터링 정보를 제공하는 다른 실시 예를 나타내는 예시도이다. 도 11의 S1100 단계는 도 10의 S1000 단계와 유사할 수 있다. 다만, 본 실시 예의 경우 웨어러블 기기는 복 수 회의 수유가 수행되는 동안 음향을 획득할 수 있다. 웨어러블 기기는 인공지능 기반의 음향 인식 모듈을 통해, 획득된 음향의 인식 동작을 수행할 수 있다(S1110). 음향 인식 모듈은 상기 음향으로부터 유아의 사레 걸림과 관련된 부분 음향 및 부분 음향의 특성을 인식한 인식 결과를 획득할 수 있다. 웨어러블 기기는 음향 인식 모듈의 인식 결과에 기초하여, 유아에 대한 수유 모니터링 정보 를 생성할 수 있다(S1120). 수유 모니터링 정보는 유아에 대한 수유 중 사레 걸림 횟수나 주기 등에 대한 정보를 포함할 수 있다. 웨어러블 기기는 생성된 수유 모니터링 정보를 부모 등에게 제공할 수 있다(S1130). S1130 단계는 도 8의 S830 단계와 유사한 바, 이에 대한 구체적인 설명은 생략하기로 한다. 실시 예에 따라, 웨어러블 기기, 단말기, 또는 서버는, 상기 수유 모니터링 정보에 기초하여 유아의 수유 시 수유 자세를 교정하기 위한 가이드를 더 제공할 수 있다. 예컨대, 수유 모니터링 정보로 부터 사레 걸림 횟수가 기준횟수보다 많은 경우, 웨어러블 기기, 단말기, 또는 서버는 사레 걸림 횟수의 감소를 위한 가이드를 제공할 수 있다. 즉, 도 11에 도시된 실시 예에 따르면, 웨어러블 기기는 소정 횟수의 수유 중 유아로부터 발생하는 음향을 획득하고, 인공지능 기반의 음향 인식 모듈을 통해 상기 음향으로부터 유아의 사레 걸림 횟수와 관련된 부 분 음향을 정확히 식별할 수 있다. 웨어러블 기기는 식별된 부분 음향 및 부분 음향의 특성 정보에 기초하 여 수유 모니터링 정보를 생성하고, 생성된 수유 모니터링 정보를 부모 등에게 제공할 수 있다. 즉, 부모는 유 아에게 웨어러블 기기를 착용하여, 유아에 대한 수유 자세가 올바른지 여부와 관련된 정보를 편리하게 획득 할 수 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시 예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이 고, 이러한 실시 예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사 상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2018-0139146", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 웨어러블 기기 및 이와 연결되는 단말기와 서버를 포함하는 시스템의 개념 도이다. 도 2는 본 발명의 일 실시 예에 따른 웨어러블 기기의 개략적인 블록도이다. 도 3은 본 발명의 일 실시 예에 따른 목걸이 타입 웨어러블 기기의 예시도이다. 도 4와 도 5는 본 발명의 실시 예에 따른 웨어러블 기기의 음향 인식 모듈에 적용되는 인공지능의 일례로서 딥 러닝(deep learning)을 설명하기 위한 도면들이다. 도 6은 음향 인식 모듈의 인식 동작 및 학습 동작을 설명하기 위한 도면이다. 도 7은 본 발명의 실시 예에 따른 웨어러블 기기의 동작을 설명하기 위한 플로우차트이다. 도 8은 도 7에 도시된 웨어러블 기기의 동작과 관련하여, 웨어러블 기기가 인식된 음향으로부터 식습관 정보를 제공하는 실시 예를 나타내는 예시도이다. 도 9는 도 7에 도시된 웨어러블 기기의 동작과 관련하여, 웨어러블 기기가 인식된 음향으로부터 호흡기 관리 정 보를 제공하는 실시 예를 나타내는 예시도이다. 도 10은 도 7에 도시된 웨어러블 기기의 동작과 관련하여, 웨어러블 기기가 인식된 음향으로부터 수유 모니터링 정보를 제공하는 실시 예를 나타내는 예시도이다. 도 11은 도 7에 도시된 웨어러블 기기의 동작과 관련하여, 웨어러블 기기가 인식된 음향으로부터 수유 모니터링 정보를 제공하는 다른 실시 예를 나타내는 예시도이다."}
