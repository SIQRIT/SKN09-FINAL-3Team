{"patent_id": "10-2022-0157677", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0077537", "출원번호": "10-2022-0157677", "발명의 명칭": "인공지능을 이용한 잡초 제거 자율 주행 이동체 및 그 제어 방법", "출원인": "한국광기술원", "발명자": "주재영"}}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라를 통해 촬영된 이미지를 이용하여 자율 주행과 잡초를 제거하는 인공지능을 이용한 잡초 제거 자율 주행이동체(100)를 포함하고,상기 잡초 제거 자율 이동체(100)는 촬영된 이미지로부터 두둑(200) 및 고랑(210)의 이미지를 분석하여 주행 정보 및 조향정보를 설정하되, 상기 두둑(200) 및 고랑(210)의 이미지를 기반으로 두둑(200)의 폭과 높이를 분석하여 이동체 몸체부(110)의 폭과 높이가 상기 분석된 두둑(200)의 폭과 높이에 따라 가변되도록 조절하여 주행하고,상기 촬영된 이미지로부터 작물(300)과 잡초(310)를 인공지능 기반의 분석 모델을 이용하여 인식하고, 상기 인식된 잡초(310)에 레이저를 조사하여 제거하되, 상기 레이저의 조사 위치는 잡초 제거 자율 주행 이동체(100)의위치 정보와 촬영된 이미지 상의 잡초(310) 위치 정보를 기반으로 두둑(200)에 위치한 잡초(310)의 타겟 좌표정보를 산출하여 잡초를 제거하는 것을 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 잡초 제거 자율 주행 이동체(100)는 수평방향 및 수직방향으로 가변 가능하게 구성된 몸체부 수평 플랫폼(111), 몸체부 수직 플랫폼(112), 복수의 바퀴(113)를 구비한 이동체 몸체부(110);상기 이동체 몸체부(110)가 경로를 따라 주행하도록 구동력을 제공하는 이동체 구동부(120);상기 이동체 몸체부(110)가 주행하는 동안 촬영한 농작물 이미지를 인공지능 기반의 분석 모델을 이용하여 작물(300)과 잡초(310)를 구분하여 인식하는 영상 인식부(130);상기 이동체 몸체부(110)에 설치되어 인식된 잡초(310)로 위한 레이저를 조사하여 상기 잡초(310)를 제거하는레이저 모듈부(140);상기 이동체 몸체부(110)가 주행되도록 주행 및 조향 제어 신호를 상기 이동체 구동부(120)로 출력하되, 촬영된주행환경 이미지로부터 두둑(200) 및 고랑(210)의 이미지를 분석하여 상기 두둑(200)의 폭과 높이를 추출하고,상기 추출된 두둑(200)의 폭과 높이에 따라 이동체 몸체부(110)의 폭과 높이가 가변되도록 플랫폼 가변부(170)로 제어 신호를 출력하며, 상기 영상 인식부(130)에서 구분된 잡초(310)로 레이저가 조사되도록 제어 신호를 출력하는 이동체 제어부(150);상기 이동체 몸체부(110)에 설치되어 주행방향의 두둑(200)과 고랑(210)을 포함한 주행환경 이미지를 촬영하는주행환경 감지부(160); 및상기 이동체 몸체부(110)의 플랫폼(111. 112)이 수평방행과 수직방향으로 가변되도록 구동하는 플랫폼 가변부(170);를 포함하는 것을 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 잡초 제거 자율 주행 이동체(100)는 이동체 몸체부(110)의 위치, 속도 및 자세의 보정을 위한 주행 환경부하 정보로, 온도, 습도 및 조도를 포함한 환경 정보를 감지하는 환경정보 감지부(180);를 더 포함하는 것을특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 이동체 구동부(120)는 이동체 제어부(150)의 제어 신호에 따라 이동체 몸체부(110)의 주행 속도를 제어하공개특허 10-2024-0077537-3-는 속도 제어부(121);상기 이동체 제어부(150)의 제어 신호에 따라 이동체 몸체부(110)가 임의의 방향으로 주행하도록 제어하는 구동부(122); 및GNSS(Global Navigation Satellite System)의 위치 정보와 지도 정보를 이용하여 상기 이동체 몸체부(110)가이동하는 주행 경로와 위치 정보를 관리하는 내비게이션부(123);를 포함하는 것을 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서,상기 영상 인식부(130)는 두둑(200)을 촬영하는 제1 카메라부(131);상기 두둑(200)으로 조명을 조사하는 조명부(132); 및상기 제1 카메라부(131)가 촬영한 이미지를 기계 학습을 통해 학습한 인공지능 기반의 분석 모델을 이용하여 작물(300)과 잡초(310)를 분류하되, 분류된 잡초(310)의 위치 정보를 포함하여 이동체 제어부(150)로 출력하는 잡초 분석부(133);를 포함하는 것을 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 3 항에 있어서,상기 레이저 모듈부(140)는 분류된 잡초(310)로 레이저를 조사하는 레이저부(141); 및상기 이동체 제어부(150)의 제어 신호에 따라 상기 레이저부(141)가 임의의 위치로 이동되도록 제어하는 매니플레이터부(142);를 포함하는 것을 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 3 항에 있어서,상기 이동체 제어부(150)는 이동체 구동부(120)가 GNSS를 통해 수신한 위치 정보를 기반으로 이동체 몸체부(110)의 주행과 조향을 위한 제어 신호를 생성하여 상기 이동체 구동부(120)로 출력하고, 주행환경 감지부(160)에서 분류된 두둑(200)과 고랑(210)으로부터 상기 두둑(200)의 폭과 높이를 산출하여 산출된 폭과 높이에 따라 상기 이동체 몸체부(110)의 폭과 높이가 가변되도록 플랫폼 가변부(170)로 제어 신호를 출력하며, 상기 GNSS를 통해 수신한 이동체 몸체부(110)의 실제 위치 정보와 영상 인식부(130)에서 구분된 잡초(310)의 이미지 상의 위치 정보를 기반으로 잡초(310)의 타겟 좌표 정보를 생성하고, 생성된 타겟 좌표 정보를 레이저 모듈부(140)로 전송하여 레이저가 잡초(310)에 조사되도록 제어 신호를 출력하는 것을 특징으로 하는 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 3 항에 있어서,상기 주행환경 감지부(160)는 3차원 이미지를 촬영하는 제2 카메라(161);상기 제2 카메라(161)의 3차원 이미지 정보에서 추출되는 객체 별로 깊이(Depth) 정보를 계산하되, 상기 계산된객체 별 깊이에 따라 ROI(Region of Interest)에 대응하는 서로 다른 명암 대비로 구분하여 두둑(200)과 고랑(210)으로 분류하는 영상 분석부(162);를 포함하는 것을 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행이동체."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 3 항에 있어서,상기 플랫폼 가변부(170)는 몸체부 수평 플랫폼(111)이 수평방향으로 가변되도록 동작하는 폭 가변부(171); 및공개특허 10-2024-0077537-4-몸체부 수직 플랫폼(112)이 수직방향으로 가변되도록 동작하는 높이 가변부(172)를 포함하는 것을 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "a) 두둑(200) 및 고랑(210)의 크기에 따라 잡초 제거 자율 주행 이동체(100)가 이동체 몸체부(110)의 플랫폼(111, 112) 형상을 조정하고, 미리 설정된 작업 정보에 따라 주행 정보 및 조향 정보를 설정하여 주행하는단계;b) 상기 잡초 제거 자율 주행 이동체(100)가 주행하는 동안 두둑(200)의 작물(300)과 잡초(310)를 포함한 농작물을 촬영하는 단계;c) 상기 잡초 제거 자율 주행 이동체(100)가 촬영한 농작물의 이미지를 인공지능 기반의 분석 모델을 이용하여작물(300)과 잡초(310)로 구분하여 분류하는 단계; 및d) 상기 잡초 제거 자율 주행 이동체(100)가 잡초 제거 자율 주행 이동체(100)의 위치 정보와 촬영된 이미지 상의 잡초(310) 위치 정보를 기반으로 두둑(200)에 위치한 잡초(310)의 타겟 좌표 정보를 산출하고, 산출된 타겟좌표 정보에 따라 레이저를 조사하여 잡초(310)를 제거하는 단계;를 포함하는 인공지능을 이용한 잡초 제거 자율 주행 이동체의 제어 방법."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 a)단계의 이동체 몸체부(110)의 플랫폼(111, 112) 형상은 잡초 제거 자율 주행 이동체(100)가 주변환경을3차원 카메라를 이용하여 촬영한 이미지로부터 두둑(200)과 고랑(210)을 분류하고, 상기 분류된 두둑(200)과 고랑(210)을 기반으로 두둑(200)의 폭과 높이를 분석하여 분석 결과에 따라 플랫폼(111, 112)의 폭과 높이를 조절하는 것을 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체의 제어 방법."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 잡초 제거 자율 주행 이동체(100)는 3차원 이미지 정보에서 추출되는 객체 별로 깊이(Depth) 정보를 계산하되, 상기 계산된 객체 별 깊이에 따라 ROI(Region of Interest)에 대응하는 서로 다른 명암 대비로 구분하여 두둑(200)과 고랑(210)으로 분류하는 것을 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체의 제어 방법."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,상기 d)단계의 타겟 좌표 정보는 잡초 제거 자율 주행 이동체(100)가 GNSS를 통해 수신한 이동체 몸체부(110)의실제 위치 정보와, 영상 인식부(130)에서 구분된 잡초(310)의 이미지 상의 위치 정보를 기반으로 두둑(200)에위치한 잡초(310)의 실제 타겟 좌표 정보를 생성하는 것을 특징으로 하는 인공지능을 이용한 잡초 제거 자율 주행 이동체의 제어 방법."}
{"patent_id": "10-2022-0157677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10 항 내지 제 13 항 중 어느 한 항에 있어서,e) 상기 잡초 제거 자율 주행 이동체(100)가 주행에 따른 주행 정보와 잡초 제거 정보를 모니터링하고, 상기 모니터링 정보를 원격지의 관리서버(400) 또는 관리자 단말(500)로 전송하는 단계를 더 포함하는 것을 특징으로하는 인공지능을 이용한 잡초 제거 자율 주행 이동체의 제어 방법."}
{"patent_id": "10-2022-0157677", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능을 이용한 잡초 제거 자율 주행 이동체와 그 제어 시스템 및 방법을 개시한다. 본 발명은 밭고랑을 따라 자율 주행하며 두둑의 작물 사이에서 잡초를 인식하여 제거하고, 두둑의 크기에 상관없이 잡초 제거를 수행할 수 있다."}
{"patent_id": "10-2022-0157677", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 잡초 제거 자율 주행 이동체 및 그 제어 방법에 관한 발명으로서, 더욱 상세하게 는 밭고랑을 따라 자율 주행하며 두둑의 작물 사이에서 잡초를 인식하여 제거하는 인공지능을 이용한 잡초 제거 자율 주행 이동체 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2022-0157677", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "잡초는 농업시스템에서 수율을 감소시키는 가장 중요한 요인 중의 하나로서, 잡초 제거가 농업 그 자체라고도 할 만큼 가장 오래된 과제이기도 하다. 종래의 잡초 제거방법으로는, 잡초를 직접 자르는 방법, 잡초에 화학적 약품을 살포하는 방법, 잡초의 뿌리를 뽑는 방법 등이 있다. 이러한 종래의 잡초 제거방법은 주기적으로 작업자를 투입하여 인력으로 제초작업을 진행해야만 하고, 이로 인 해 많은 비용과 인력이 요구되는 문제점이 있다. 최근에는 잡초 제거를 위한 인력의 수급 문제와, 인건비의 절양을 위해 작업자가 아닌 제초 작업용 로봇이나 제 초 작업차량이 도입되고 있다. 그러나, 논농사를 통해 재배되는 벼는 경지 정리가 잘 이루어진 논에서 제초 작업용 로봇이나 제초 작업 차량을 이용하여 이루어지고 있지만, 밭농사를 통해 생산되는 농작물은 작물에 따라 서로 다른 크기의 두둑과 고랑으로 이루어진 밭에서는 제초 작업을 위한 로봇이나 작업차량의 이동이 어려운 문제점이 있다. 또한, 불규칙한 지형이나 경사도로 인해 제초작업을 수행하는데 많은 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개특허공보 공개번호 제10-2020-0095225호(발명의 명칭: 영상기반의 선별적 잡초제거로 봇)"}
{"patent_id": "10-2022-0157677", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이러한 문제점을 해결하기 위하여, 본 발명은 밭고랑을 따라 자율 주행하며 두둑의 작물 사이에서 잡초를 인식 하여 제거하는 인공지능을 이용한 잡초 제거 자율 주행 이동체 및 그 제어 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0157677", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위하여 본 발명의 일 실시 예는 인공지능을 이용한 잡초 제거 자율 주행 이동체로서, 카메라를 통해 촬영된 이미지를 이용하여 자율 주행과 잡초를 제거하는 인공지능을 이용한 잡초 제거 자율 주행 이동체를 포함하고, 상기 잡초 제거 자율 이동체는 촬영된 이미지로부터 두둑 및 고랑의 이미지를 분석하여 주 행 정보 및 조향정보를 설정하되, 상기 두둑 및 고랑의 이미지를 기반으로 두둑의 폭과 높이를 분석하여 이동체 몸체부의 폭과 높이가 상기 분석된 두둑의 폭과 높이에 따라 가변되도록 조절하여 주행하고, 상기 촬영된 이미 지로부터 작물과 잡초를 인공지능 기반의 분석 모델을 이용하여 인식하고, 상기 인식된 잡초에 레이저를 조사하 여 제거하되, 상기 레이저의 조사 위치는 잡초 제거 자율 주행 이동체의 위치 정보와 촬영된 이미지 상의 잡초 위치 정보를 기반으로 두둑에 위치한 잡초의 타겟 좌표 정보를 산출하여 잡초를 제거하는 것을 특징으로 한다. 또한, 상기 실시 예에 따른 잡초 제거 자율 주행 이동체는 수평방향 및 수직방향으로 가변 가능하게 구성된 몸 체부 수평 플랫폼, 몸체부 수직 플랫폼, 복수의 바퀴를 구비한 이동체 몸체부; 상기 이동체 몸체부가 경로를 따 라 주행하도록 구동력을 제공하는 이동체 구동부; 상기 이동체 몸체부가 주행하는 동안 촬영한 농작물 이미지를 인공지능 기반의 분석 모델을 이용하여 작물과 잡초를 구분하여 인식하는 영상 인식부; 상기 이동체 몸체부에 설치되어 인식된 잡초로 위한 레이저를 조사하여 상기 잡초를 제거하는 레이저 모듈부; 상기 이동체 몸체부가 주행되도록 주행 및 조향 제어 신호를 상기 이동체 구동부로 출력하되, 촬영된 주행환경 이미지로부터 두둑 및고랑의 이미지를 분석하여 상기 두둑의 폭과 높이를 추출하고, 상기 추출된 두둑의 폭과 높이에 따라 이동체 몸 체부의 폭과 높이가 가변되도록 플랫폼 가변부로 제어 신호를 출력하며, 상기 영상 인식부에서 구분된 잡초로 레이저가 조사되도록 제어 신호를 출력하는 이동체 제어부; 상기 이동체 몸체부에 설치되어 주행방향의 두둑과 고랑을 포함한 주행환경 이미지를 촬영하는 주행환경 감지부; 및 상기 이동체 몸체부의 플랫폼이 수평방행과 수 직방향으로 가변되도록 구동하는 플랫폼 가변부;를 포함하는 것을 특징으로 한다. 또한, 상기 실시 예에 따른 잡초 제거 자율 주행 이동체는 이동체 몸체부의 위치, 속도 및 자세의 보정을 위한 주행 환경 부하 정보로, 온도, 습도 및 조도를 포함한 환경 정보를 감지하는 환경정보 감지부;를 더 포함하는 것을 특징으로 한다. 또한, 상기 실시 예에 따른 이동체 구동부는 이동체 제어부의 제어 신호에 따라 이동체 몸체부의 주행 속도를 제어하는 속도 제어부; 상기 이동체 제어부의 제어 신호에 따라 이동체 몸체부가 임의의 방향으로 주행하도록 제어하는 구동부; 및 GNSS(Global Navigation Satellite System)의 위치 정보와 지도 정보를 이용하여 상기 이 동체 몸체부가 이동하는 주행 경로와 위치 정보를 관리하는 내비게이션부;를 포함하는 것을 특징으로 한다. 또한, 상기 실시 예에 따른 영상 인식부는 두둑을 촬영하는 제1 카메라부; 상기 두둑으로 조명을 조사하는 조명 부; 및 상기 제1 카메라부가 촬영한 이미지를 기계 학습을 통해 학습한 인공지능 기반의 분석 모델을 이용하여 작물과 잡초를 분류하되, 분류된 잡초의 위치 정보를 포함하여 이동체 제어부로 출력하는 잡초 분석부;를 포함 하는 것을 특징으로 한다. 또한, 상기 실시 예에 따른 레이저 모듈부는 분류된 잡초로 레이저를 조사하는 레이저부; 및 상기 이동체 제어 부의 제어 신호에 따라 상기 레이저부가 임의의 위치로 이동되도록 제어하는 매니플레이터부;를 포함하는 것을 특징으로 한다. 또한, 상기 실시 예에 따른 이동체 제어부는 이동체 구동부가 GNSS를 통해 수신한 위치 정보를 기반으로 이동체 몸체부의 주행과 조향을 위한 제어 신호를 생성하여 상기 이동체 구동부로 출력하고, 주행환경 감지부에서 분류 된 두둑과 고랑으로부터 상기 두둑의 폭과 높이를 산출하여 산출된 폭과 높이에 따라 상기 이동체 몸체부의 폭 과 높이가 가변되도록 플랫폼 가변부로 제어 신호를 출력하며, 상기 GNSS를 통해 수신한 이동체 몸체부의 실제 위치 정보와 영상 인식부에서 구분된 잡초의 이미지 상의 위치 정보를 기반으로 잡초의 타겟 좌표 정보를 생성 하고, 생성된 타겟 좌표 정보를 레이저 모듈부로 전송하여 레이저가 잡초에 조사되도록 제어 신호를 출력하는 것을 특징으로 한다. 또한, 상기 실시 예에 따른 주행환경 감지부는 3차원 이미지를 촬영하는 제2 카메라; 상기 제2 카메라의 3차원 이미지 정보에서 추출되는 객체 별로 깊이(Depth) 정보를 계산하되, 상기 계산된 객체 별 깊이에 따라 ROI(Region of Interest)에 대응하는 서로 다른 명암 대비로 구분하여 두둑과 고랑으로 분류하는 영상 분석부; 를 포함하는 것을 특징으로 한다. 또한, 상기 실시 예에 따른 플랫폼 가변부는 몸체부 수평 플랫폼이 수평방향으로 가변되도록 동작하는 폭 가변 부; 및 몸체부 수직 플랫폼이 수직방향으로 가변되도록 동작하는 높이 가변부를 포함하는 것을 특징으로 한다. 또한, 본 발명의 일 실시 예는 인공지능을 이용한 잡초 제거 자율 주행 이동체의 제어 방법으로서, a) 두둑 및 고랑의 크기에 따라 잡초 제거 자율 주행 이동체가 이동체 몸체부의 플랫폼 형상을 조정하고, 미리 설정된 작업 정보에 따라 주행 정보 및 조향 정보를 설정하여 주행하는 단계; b) 상기 잡초 제거 자율 주행 이동체가 주행하 는 동안 두둑의 작물과 잡초를 포함한 농작물을 촬영하는 단계; c) 상기 잡초 제거 자율 주행 이동체가 촬영한 농작물의 이미지를 인공지능 기반의 분석 모델을 이용하여 작물과 잡초로 구분하여 분류하는 단계; 및 d) 상기 잡초 제거 자율 주행 이동체가 잡초 제거 자율 주행 이동체의 위치 정보와 촬영된 이미지 상의 잡초의 위치 정 보를 기반으로 두둑에 위치한 잡초의 타겟 좌표 정보를 산출하고, 산출된 타겟 좌표 정보에 따라 레이저를 조사 하여 잡초를 제거하는 단계;를 포함한다. 또한, 상기 실시 예에 따른 a)단계의 이동체 몸체부의 플랫폼 형상은 잡초 제거 자율 주행 이동체가 주변환경을 3차원 카메라를 이용하여 촬영한 이미지로부터 두둑과 고랑을 분류하고, 상기 분류된 두둑과 고랑을 기반으로 두둑의 폭과 높이를 분석하여 분석 결과에 따라 플랫폼의 폭과 높이를 조절하는 것을 특징으로 한다. 또한, 상기 실시 예에 따른 잡초 제거 자율 주행 이동체는 3차원 이미지 정보에서 추출되는 객체 별로 깊이 (Depth) 정보를 계산하되, 상기 계산된 객체 별 깊이에 따라 ROI(Region of Interest)에 대응하는 서로 다른 명 암 대비로 구분하여 두둑과 고랑으로 분류하는 것을 특징으로 한다.또한, 상기 실시 예에 따른 d)단계의 타겟 좌표 정보는 잡초 제거 자율 주행 이동체가 GNSS를 통해 수신한 이동 체 몸체부의 실제 위치 정보와, 영상 인식부에서 구분된 잡초의 이미지 상의 위치 정보를 기반으로 두둑에 위치 한 잡초의 실제 타겟 좌표 정보를 생성하는 것을 특징으로 한다. 또한, 상기 실시 예는 e) 상기 잡초 제거 자율 주행 이동체가 주행에 따른 주행 정보와 잡초 제거 정보를 모니 터링하고, 상기 모니터링 정보를 원격지의 관리서버 또는 관리자 단말로 전송하는 단계를 더 포함하는 것을 특 징으로 한다."}
{"patent_id": "10-2022-0157677", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 밭고랑을 따라 자율 주행하며 두둑의 작물 사이에서 잡초를 인식하여 제거할 수 있고, 두둑의 크기에 상관없이 잡초 제거를 수행할 수 있는 장점이 있다."}
{"patent_id": "10-2022-0157677", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 발명의 바람직한 실시 예 및 첨부하는 도면을 참조하여 본 발명을 상세히 설명하되, 도면의 동일 한 참조부호는 동일한 구성요소를 지칭함을 전제하여 설명하기로 한다. 본 발명의 실시를 위한 구체적인 내용을 설명하기에 앞서, 본 발명의 기술적 요지와 직접적 관련이 없는 구성에 대해서는 본 발명의 기술적 요지를 흩뜨리지 않는 범위 내에서 생략하였음에 유의하여야 할 것이다. 또한, 본 명세서 및 청구범위에 사용된 용어 또는 단어는 발명자가 자신의 발명을 최선의 방법으로 설명하기 위 해 적절한 용어의 개념을 정의할 수 있다는 원칙에 입각하여 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야 할 것이다. 본 명세서에서 어떤 부분이 어떤 구성요소를 \"포함\"한다는 표현은 다른 구성요소를 배제하는 것이 아니라 다른 구성요소를 더 포함할 수 있다는 것을 의미한다. 또한, \"‥부\", \"‥기\", \"‥모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어, 또는 그 둘의 결합으로 구분될 수 있다. 또한, \"적어도 하나의\" 라는 용어는 단수 및 복수를 포함하는 용어로 정의되고, 적어도 하나의 라는 용어가 존 재하지 않더라도 각 구성요소가 단수 또는 복수로 존재할 수 있고, 단수 또는 복수를 의미할 수 있음은 자명하 다 할 것이다. 이하, 첨부된 도면을 참조하여 본 발명의 일 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체 및 그 제어 방법의 바람직한 실시예를 상세하게 설명한다. 도 1은 본 발명의 일 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체와 그 제어 시스템을 설명 하기 위해 나타낸 블록도이고, 도 2 내지 도 10은 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주 행 이동체를 설명하기 위해 나타낸 블록도이다. 도1 내지 도10을 참조하면, 본 발명의 일 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체 는 카메라를 통해 촬영된 이미지를 이용하여 자율 주행과 잡초를 제거할 수 있다. 또한, 잡초 제거 자율 주행 이동체는 네트워크를 통해 연결된 관리서버 또는 관리자 단말로부터 작업 정보, 예를 들어 잡초 제거 대상 밭의 위치, 잡초 정보, 이동 경로 등의 정보를 수신하고, 수신된 정보들 을 기반으로 자율 주행을 수행할 수 있다. 또한, 잡초 제거 자율 주행 이동체는 작업 정보에 따라 작업을 수행한 결과, 예를 들어 이동 경로 및 주행 에 따른 주행 정보와 잡초를 제거한 결과에 따른 모니터링 정보를 관리서버 또는 관리자 단말로 전송 할 수도 있다. 또한, 잡초 제거 자율 주행 이동체는 관리서버 또는 관리자 단말로부터 전송되는 원격 주행 정 보에 따라 수동 주행을 수행할 수도 있다. 또한, 잡초 제거 자율 주행 이동체는 촬영된 이미지로부터 두둑 및 고랑의 이미지를 분석하여 주행 정보 및 조향정보를 설정하고, 두둑 및 고랑의 이미지를 기반으로 두둑의 폭과 높이를 분 석하여 이동체 몸체부의 폭과 높이가 분석된 두둑의 폭과 높이에 따라 가변되도록 조절하여 주행할 수도 있다. 또한, 잡초 제거 자율 주행 이동체는 촬영된 이미지로부터 작물과 잡초를 인공지능 기반의 분석 모델을 이용하여 인식하고, 인식된 잡초에 레이저를 조사하여 제거할 수 있다. 또한, 잡초 제거 자율 주행 이동체는 잡초 제거 자율 주행 이동체의 위치 정보와 촬영된 이미지 상의 잡초 위치 정보를 기반으로 산출되는 두둑에 위치한 잡초의 타겟 좌표 정보를 레이저의 조사 위 치로 산출할 수 있다. 이를 위해, 잡초 제거 자율 주행 이동체는 이동체 몸체부와, 이동체 구동부와, 영상 인식부 와, 레이저 모듈부와, 이동체 제어부와, 주행환경 감지부와, 플랫폼 가변부와, 환경 정보 감지부를 포함하여 구성될 수 있다. 이동체 몸체부는 이동체 구동부와, 영상 인식부와, 레이저 모듈부와, 이동체 제어부 와, 주행환경 감지부와, 플랫폼 가변부와, 환경정보 감지부가 설치되는 구성으로서, 수평방향과 수직방향으로 가변 가능하게 구성된 몸체부 수평 플랫폼과. 몸체부 수직 플랫폼과, 몸체부 수직 플랫 폼의 하부에 조향 가능하게 구성된 복수의 바퀴를 포함하여 구성될 수 있다. 즉, 이동체 몸체부는 도11에 도시된 바와 같이, 두둑과 고랑의 크기에 따라 몸체부 수평 플랫폼 이 일정 크기를 유지하고, 작물과 잡초가 있는 다른 크기의 두둑(200a)과 고랑(210a)으로 주행하는 경우, 폭방향으로 몸체부 수평 플랫폼(111a)의 크기가 확장되도록 한다. 여기서, 두둑(200, 200a)의 크기는 작물의 종류에 따라 다른 크기로 구성될 수 있다. 예를 들어, 콩, 마늘, 양파 등의 작물은 두둑의 크기가 120㎝로 구성될 수 있고, 배추, 고추 등의 작물은 두둑 의 크기가 75㎝로 구성될 수 있으며, 두둑의 크기는 설명을 위한 예시일 뿐, 이에 한정되는 것은 아니다. 이동체 구동부는 이동체 몸체부에 설치되어 이동체 몸체부가 경로를 따라 주행할 수 있도록 구 동력을 제공하는 구성으로서, 속도 제어부와, 구동부와, 내비게이션부를 포함하여 구성될 수 있 다. 속도 제어부는 이동체 제어부의 제어 신호에 따라 이동체 몸체부의 주행 속도를 제어하는 구성 으로서, 구동부로 일정한 속도를 유지하기 위한 제어 신호를 출력할 수 있다. 또한, 속도 제어부는 레이저를 이용한 잡초 제거가 이루어지는 경우, 이동체 몸체부의 속도를 일정 속도로 감속하거나 또는 일정 시간동안 정지하도록 제어함으로써, 레이저가 잡초에 충분히 조사될 수 있도록 한 다. 구동부는 이동체 제어부로부터 제어 신호에 따라 속도 제어부의 제어를 통해 이동체 몸체부 가 주행하도록 바퀴에 구동력을 제공한다. 또한, 구동부는 이동체 몸체부가 임의의 방향으로 주행할 수 있도록 바퀴에 조향력을 제공할 수 있다. 내비게이션부는 GNSS(Global Navigation Satellite System)의 위치 정보와 지도 정보를 이용하여 이동체 몸체부가 이동하는 주행 경로와 위치 정보를 관리한다. 즉, 내비게이션부는 GPS(Global Positioning System)를 이용한 현재 위치를 확인하고, 작업 정보에 따른 주행 경로를 계산하여 GIS(geographic information system)에 기반한 지도 정보를 따라 이동체 몸체부가 이동할 수 있도록 안내한다. 또한, 내비게이션부는 GPS를 이용한 위치 정보를 통해 이동체 몸체부의 현재 위치를 확인하고, 이동 체 몸체부가 주행중인 주변 환경에 따른 주행 정보에 반영하여 정확한 현재 위치 정보를 산출하여 제공할 수 있다. 영상 인식부는 이동체 몸체부가 주행하는 동안 촬영한 농작물의 이미지를 인공지능 기반의 분석 모델 을 이용하여 작물과 잡초를 구분하여 분류하는 구성으로서, 제1 카메라부와, 조명부와, 잡 초 분석부를 포함하여 구성될 수 있다. 제1 카메라부는 이동체 몸체부의 하부에 설치되어 두둑을 촬영하는 구성으로서, 도12에 나타낸 바와 같이, 복수의 카메라를 이용하여 임의의 촬영 영역(P)에서 작물과 잡초를 촬영한다. 또한, 제1 카메라부는 깊이(Depth) 정보를 포함한 3차원 이미지를 촬영하는 구성으로서, 촬영한 객체의 깊 이 정보를 통해 정확한 공간 위치 정보를 획득할 수 있도록 한다. 조명부는 제1 카메라부의 일측에 설치되어 두둑으로 조명을 조사한다. 잡초 분석부는 제1 카메라부가 촬영한 이미지를 기계 학습을 통해 학습한 인공지능 기반의 분석 모델 을 이용하여 작물과 잡초를 분류할 수 있다. 작물은 국내의 주요 작물인, 콩, 옥수수, 감자, 고구마, 배추, 무, 마늘, 고추, 양파 등을 포함할 수 있다. 인공지능 기반의 분석 모델은 CNN(Convolutional Neural Network) 기반의 딥러닝 모델을 이용하여 작물의 이미 지와 잡초의 이미지를 포함한 학습 데이터를 기반으로 잡초의 분류를 학습한 분석 모델이다. 여기서, 인공지능 기반의 분석 모델은 머신 러닝중에서 딥러닝(Deep learning)이라는 방법을 통해 만들어진 분 석 모델들의 종류라고 볼 수 있다. 따라서, 인공지능 기반의 분석 모델은 딥러닝 모델 또는 딥러닝 분석 모델의 표현으로 사용될 수도 있다. 또한, 머신 러닝은 복잡한 시스템이 명시적으로 프로그래밍되지 않고서, 경험으로부터 자동으로 학습하고 개선 할 수 있게 하는 인공 지능의 응용이다. 또한, 머신 러닝 모델들의 정확도 및 유효성은 그들 모델들을 훈련시키는 데 사용되는 데이터에 부분적으로 의 존할 수 있다. 또한, 인공지능 기반의 분석 모델은 제1 카메라부로부터 촬영된 작물의 이미지와 잡초의 이미지를 기반으 로 인공지능 분석 모델의 추가 학습을 수행할 수도 있다. 또한, 인공지능 기반의 분석 모델은 다양한 환경, 예를 들어, 촬영각도, 촬영시 흔들림, 촬영구도, 사진 해상도 등 다양한 여건에서 촬영될 수 있는 이미지를 감안하여 원본 이미지에 대하여 다양한 변화를 준 추가 이미지들 을 사전에 학습함으로써, 실제 환경에서 촬영되는 이미지들에 대한 인식율을 향상시킬 수도 있다. 또한, 잡초 분석부는 분류된 잡초의 촬영 이미지 상에서의 잡초의 위치 정보를 추출하고, 추출 된 잡초의 위치 정보와 촬영된 잡초의 이미지를 이동체 제어부로 제공할 수 있다. 잡초의 위치 정보는 잡초 분석부가 촬영된 이미지의 데이터 중에서 작물 또는 잡초가 아닐 가능성이 높은 영역의 픽셀의 이미지 데이터는 제외하여 3차원 클라우드 데이터를 생성할 수 있다. 또한, 잡초 분석부는 3차원 포인트 클라우드를 생성한 후 픽셀 강도가 낮은 영역을 제외하고, 촬영된 데이 터 중에서 관심 영역(ROI, Region of Interest) 즉, 잡초가 위치할 것으로 예상되는 영역에 해당하는 촬영 데이터를 이용하여 3차원 포인트 클라우드를 생성할 수 있다. 또한, 잡초 분석부는 3차원 포인트 클라우드가 배치된 좌표를 기반으로 잡초의 위치 좌표 정보를 산 출하고, 3차원 포인트 클라우드가 배치된 좌표들의 중심 좌표를 기반으로 3차원 포인트 클라우드가 배치된 영역 의 크기를 계산하여 잡초의 크기를 산출할 수 있으며, 산출된 결과는 이동체 제어부로 제공할 수 있 다. 여기서, 산출된 잡초의 크기는 레이저를 이용한 잡초 제거시 제거 시간의 산출 정보에 반영될 수 있다. 레이저 모듈부는 이동체 몸체부의 하부에 설치되어 영상 인식부에서 인식 또는 분류된 잡초 로 위한 레이저를 조사하여 잡초를 제거하는 구성으로서, 레이저부와 매니플레이터부로 구 성될 수 있다. 레이저부는 이동체 제어부에서 출력된 제어 신호에 따라 분류된 잡초로 일정 파장 범위의 레이 저를 조사하는 구성으로서, 0.4㎛ ~ 0.49㎛ 범위의 청색 레이저와 1.0㎛ ~ 2.0㎛ 파장 범위의 툴륨 레이저 중 하나 이상으로 구성될 수 있다. 매니플레이터부는 이동체 제어부의 제어 신호에 따라 제거 대상 잡초의 타겟 좌표 정보에 레이 저가 조사될 수 있도록 레이저부를 이동하여 위치시키는 구성으로서, 레이저부가 평면상의 수평방향 으로 이동되도록 제어하는 수평 구동부와, 레이저부가 수직방향으로 이동되도록 제어하는 수직 구동부로 구성될 수 있다. 또한, 레이저 모듈부는 레이저부의 양측 말단에 설치되어 두둑의 측면에서 감지되는 잡초를 제 거하기 위한 레이저를 출력하는 보조 레이저 모듈부가 추가 구성될 수 있다. 즉, 도13과 같이 레이저 모듈부는 촬영 영역(P) 중에서, 제1 영역(P1)은 레이저부를 이용하여 잡초를 제거하고, 제2 영역(P2) 즉 두둑의 양측은 보조 레이저부를 이용하여 잡초를 제거할 수도 있다. 본 실시 예에서는 레이저를 이용한 보조 레이저부로 설명하지만, 이에 한정되는 것은 아니고, 커팅기와 같 은 물리적인 장치를 이용하여 잡초를 제거할 수도 있다. 이동체 제어부는 이동체 몸체부가 미리 저장된 작업 정보에 따라 주행되도록 주행 및 조향 제어 신호 를 이동체 구동부로 출력할 수 있다. 즉, 이동체 제어부는 이동체 구동부가 GNSS를 통해 수신한 위치 정보를 기반으로 현재의 위치를 분석 하고, 분석된 결과와 작업 정보에 기반하여 이동체 몸체부의 주행과 조향을 위한 제어 신호를 생성하며, 생성된 제어 신호를 이동체 구동부로 출력한다. 또한, 이동체 제어부는 주행환경 감지부에서 촬영된 주행환경 이미지로부터 두둑과 고랑의 이미지를 분석하여 상기 두둑의 폭과 높이를 추출하고, 상기 추출된 두둑의 폭과 높이에 따라 이동체몸체부의 폭과 높이가 가변되도록 플랫폼 가변부로 제어 신호를 출력할 수 있다. 또한, 이동체 제어부는 영상 인식부에서 구분된 잡초로 레이저가 조사되도록 제어 신호를 출력 할 수 있다. 이때, 이동체 제어부는 이동체 구동부가 수신한 GNSS 기반의 현재 위치 정보(위치 좌표 정보)를 이용 하여 이동체 몸체부의 실제 위치 정보와, 영상 인식부에서 구분된 이미지의 잡초로부터 이미지 상에 위치한 잡초의 위치 정보(위치 좌표 정보)를 산출하고, 산출된 이동체 몸체부의 실제 위치 좌표 와 이미지 상에 위치한 잡초의 위치 좌표를 글로벌 좌표계(Global Coordinate System)로 좌표 변환하여 제 거 대상 잡초의 타겟 좌표 정보를 생성할 수 있다. 또한, 이동체 제어부는 생성된 타겟 좌표 정보를 레이저 모듈부로 전송하여 메니플레이터부를 통해 레이저부의 위치가 가변되도록 하여 레이저부에서 출력된 레이저가 잡초에 조사되도록 제 어 신호를 출력한다. 주행환경 감지부는 이동체 몸체부에 설치되어 주행방향 전측에서 두둑과 고랑을 포함한 3 차원의 주행환경 이미지를 촬영하는 구성으로서, 제2 카메라와, 영상 분석부를 포함하여 구성될 수 있다. 제2 카메라는 3차원 이미지를 촬영하는 구성으로서, 두둑과 고랑을 촬영한다. 영상 분석부는 제2 카메라가 촬영한 3차원 이미지 정보에서 추출되는 객체 별로 깊이(Depth) 정보를 계산하고, 객체 별로 계산된 깊이에 따라 ROI(Region of Interest)에 대응하는 서로 다른 명암 대비로 구분하여 두둑과 고랑으로 분류한다. 플랫폼 가변부는 이동체 제어부의 제어 신호에 따라 이동체 몸체부의 몸체부 수평 플랫폼 과. 몸체부 수직 플랫폼이 수평방행과 수직방향으로 가변되도록 구동하는 구성으로서, 몸체부 수평 플랫폼 이 수평방향으로 가변되도록 동작하는 폭 가변부와, 몸체부 수직 플랫폼이 수직방향으로 가변되 도록 동작하는 높이 가변부로 구성될 수 있다. 환경정보 감지부는 잡초 제거 자율 주행 이동체가 이동체 몸체부의 위치, 속도 및 자세의 보정 등에 반영하기 위한 주행 환경 부하 정보로서, 주변 온도를 감지하는 온도 센서부와, 주변 습도를 감지하 는 습도 센서부와, 주변 조도를 감지하는 조도 센서부를 포함하여 구성될 수 있다. 즉, 이동체 주변의 온도 및 습도를 반영하여 레이저의 출력, 레이저의 조사량, 레이저의 조사 시간 등이 가변될 수 있도록 하거나, 주변 조도에 따른 조명의 온/오프가 이루어질 수 있도록 한다. 다음은 본 발명의 일 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 제어 방법을 설명한다. 도 14는 본 발명의 일 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 제어 방법을 설명하기 위해 나타낸 흐름도이다. 도1 내지 도10, 도14를 참조하면, 본 발명의 일 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체 의 제어 방법은 잡초 제거 자율 주행 이동체가 두둑 및 고랑의 크기에 따라 이동체 몸체부 의 플랫폼(111, 112) 형상을 조정하고, 미리 설정된 작업 정보에 따라 주행 정보 및 조향 정보를 설정하여 주행(S100)한다. S100 단계는 잡초 제거 자율 주행 이동체가 카메라를 통해 깊이 정보를 포함하여 촬영한 3차원 이미지 정 보에서, 추출되는 두둑과 고랑의 깊이(Depth) 정보를 계산하고, 객체 별로 계산된 두둑과 고랑 의 깊이에 따라 ROI(Region of Interest)에 대응하는 서로 다른 명암 대비로 구분하여 두둑과 고랑 으로 분류할 수 있다. 또한, S100 단계에서 잡초 제거 자율 주행 이동체는 분류된 두둑과 고랑을 기반으로 두둑 의 폭과 높이를 분석하고, 분석된 두둑의 폭과 높이에 따라 몸체부 수평 플랫폼과, 몸체부 수직 플랫 폼의 폭과 높이를 조절한 후, 작업 정보에 기반한 이동 경로를 따라 주행한다. 계속해서, 잡초 제거 자율 주행 이동체는 주행하는 동안 두둑의 작물과 잡초를 포함한 농 작물을 촬영(S200)한다.또한, 잡초 제거 자율 주행 이동체는 촬영한 농작물의 이미지를 인공지능 기반의 분석 모델을 이용하여 작 물과 잡초로 구분하여 분류(S300)한다. S300 단계에서, 잡초 제거 자율 주행 이동체는 촬영된 이미지의 데이터 중에서 작물 또는 잡초 가 아닐 가능성이 높은 영역의 픽셀의 이미지 데이터는 제외한 3차원 클라우드 데이터를 생성하고, 생성된 3차 원 클라우드에서 픽셀 강도가 낮은 영역을 제외하며, 촬영된 데이터 중에서 잡초가 위치할 것으로 예상되 는 관심 영역(ROI, Region of Interest)에 해당하는 촬영 데이터를 이용하여 3차원 포인트 클라우드를 생성한다. 또한, 3차원 포인트 클라우드가 배치된 좌표를 기반으로 잡초의 위치 좌표 정보를 산출하여 제거 대상인 잡초를 인식 및 분류한다. 또한, S300 단계에서 잡초 제거 자율 주행 이동체는 3차원 포인트 클라우드가 배치된 좌표들의 중심 좌표 를 기반으로 3차원 포인트 클라우드가 배치된 영역의 크기를 계산하여 잡초의 크기를 산출할 수도 있다. S300 단계를 수행한 후, 잡초 제거 자율 주행 이동체는 잡초 제거 자율 주행 이동체의 위치 정보와 촬영된 이미지 상의 잡초 위치 정보를 기반으로 두둑에 위치한 잡초의 타겟 좌표 정보를 산출하 고, 산출된 타겟 좌표 정보에 따라 레이저를 조사하여 잡초를 제거(S400)한다. S400 단계에서, 잡초의 타겟 좌표 정보는 잡초 제거 자율 주행 이동체가 GNSS를 통해 수신한 이동체 몸체부의 실제 위치 정보와, S300 단계에서 구분된 잡초의 이미지 상의 위치 정보를 기반으로 두둑 에 위치한 잡초의 실제 타겟 좌표 정보를 생성한다. 즉, 수신한 GNSS 기반의 현재 위치 정보(위치 좌표 정보)를 이용하여 잡초 제거 자율 이동체의 실제 위치 정보와, S300 단계에서 구분된 이미지의 잡초로부터 이미지 상에 위치한 잡초의 위치 정보(위치 좌표 정보)를 산출하고, 산출된 잡초 제거 자율 이동체의 실제 위치 좌표와 이미지 상에 위치한 잡초의 위 치 좌표를 글로벌 좌표계(Global Coordinate System)로 좌표 변환하여 제거 대상 잡초의 타겟 좌표 정보를 생성한다. 또한, S400 단계에서 잡초에 레이저가 조사되는 동안 잡초 제거 자율 이동체는 주행을 일시 정지하고, 분류된 잡초의 크기에 따라 미리 설정된 레이저 출력, 레이저 조사량, 레이저 조사 시간에 기반하여 레이저를 설정하며, 설정된 값에 따라 레이저를 잡초에 조사하여 잡초가 완전히 제거될 수 있도록 한 다. 레이저의 조사가 완료되면, 잡초 제거 자율 이동체는 설정된 이동 경로를 따라 주행하고, 주행에 따른 주 행 정보와 잡초 제거 정보를 모니터링하여 모니터링한 정보를 원격지의 관리서버 또는 관리자 단말로 전송(S500)할 수 있다. 또한, 잡초 제거 자율 이동체는 관리서버 또는 관리자 단말로부터 수동 조작 신호가 입력되면, 입력 신호에 따라 동작할 수도 있다. 따라서, 밭고랑을 따라 자율 주행하며 두둑의 작물 사이에서 잡초를 인식하여 제거할 수 있고, 두둑의 크기에 상관없이 잡초 제거를 수행할 수 있다. 상기와 같이, 본 발명의 바람직한 실시 예를 참조하여 설명하였지만 해당 기술 분야의 숙련된 당업자라면 하기 의 특허청구범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수 정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 또한, 본 발명의 특허청구범위에 기재된 도면번호는 설명의 명료성과 편의를 위해 기재한 것일 뿐 이에 한정되 는 것은 아니며, 실시예를 설명하는 과정에서 도면에 도시된 선들의 두께나 구성요소의 크기 등은 설명의 명료 성과 편의상 과장되게 도시되어 있을 수 있다. 또한, 상술된 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관 례에 따라 달라질 수 있으므로, 이러한 용어들에 대한 해석은 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다."}
{"patent_id": "10-2022-0157677", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, 명시적으로 도시되거나 설명되지 아니하였다 하여도 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명의 기재사항으로부터 본 발명에 의한 기술적 사상을 포함하는 다양한 형태의 변형을 할 수 있음은자명하며, 이는 여전히 본 발명의 권리범위에 속한다. 또한, 첨부하는 도면을 참조하여 설명된 상기의 실시예들은 본 발명을 설명하기 위한 목적으로 기술된 것이며 본 발명의 권리범위는 이러한 실시예에 국한되지 아니한다."}
{"patent_id": "10-2022-0157677", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체를 설명하기 위해 나타낸 블록도. 도 2는 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체를 나타낸 예시도. 도 3은 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 구성을 나타낸 블록도. 도 4는 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 동작을 설명하기 위해 나타낸 예시도. 도 5는 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 이동체 구동부 구성을 나타낸 블록도. 도 6은 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 영상 인식부 구성을 나타낸 블 록도. 도 7은 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 레이저 모듈부 구성을 나타낸 블록도. 도 8은 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 주변환경 감지부 구성을 나타 낸 블록도. 도 9는 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 플랫폼 가변부 구성을 나타낸 블록도. 도 10은 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 환경정보 감지부 구성을 나타 낸 블록도. 도 11은 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 플랫폼 가변을 설명하기 위해 나타낸 예시도. 도 12는 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 영상 인식 과정을 설명하기 위해 나타낸 예시도. 도 13은 도 1의 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 잡초 제거 과정을 설명하기 위해 나타낸 예시도. 도 14는 본 발명의 일 실시 예에 따른 인공지능을 이용한 잡초 제거 자율 주행 이동체의 제어 방법을 설명하기 위해 나타낸 흐름도."}
