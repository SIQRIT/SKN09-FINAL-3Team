{"patent_id": "10-2023-0129726", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0046443", "출원번호": "10-2023-0129726", "발명의 명칭": "인공지능에 기반하여 학습자의 댄스 동작을 평가하는 방법 및 이를 이용한 분석 서버", "출원인": "테크빌교육 주식회사", "발명자": "박기현"}}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능에 기반하여 학습자의 댄스 동작을 평가하는 방법에 있어서,(a) 상기 학습자의 상기 댄스 동작을 촬영한 제1 댄스 동영상과 상기 학습자의 상기 댄스 동작의 비교 기준을제공하는 교습자의 댄스 동작을 촬영한 제2 댄스 동영상이 획득되면, 분석 서버가, (i) 상기 제1 댄스 동영상으로부터 복수의 제1 프레임 이미지들을 추출하고 상기 제2 댄스 동영상으로부터 복수의 제2 프레임 이미지들을추출하며, (ii) 상기 제1 댄스 동영상으로부터 제1 오디오 데이터를 획득하고 상기 제2 댄스 동영상으로부터 제2 오디오 데이터를 획득하는 단계;(b) 상기 분석 서버가, (i) (i-1) 상기 제1 프레임 이미지들과 상기 제2 프레임 이미지들 각각으로부터 상기 학습자의 신체 부위와 상기 교습자의 신체 부위를 각각 식별하여, 상기 제1 프레임 이미지들 상에서 식별된 상기학습자의 신체 부위를 복수의 관절 단위들로 나누어, 상기 관절 단위들마다 복수의 주요 포인트들 - 상기 주요포인트들은 손, 발, 어깨, 팔꿈치, 무릎, 고관절, 무게중심점, 눈, 코, 입 중 적어도 일부를 포함함 - 에 대한제1 위치 데이터를 획득하고, 상기 제2 프레임 이미지들 상에서 식별된 상기 교습자의 신체 부위 각각을 복수의관절 단위들로 나누어, 상기 관절 단위들마다 복수의 상기 주요 포인트들에 대한 제2 위치 데이터를 획득하며,(i-2) 상기 제1 오디오 데이터의 제1 시작 지점과 상기 제2 오디오 데이터의 제2 시작 지점을 동기화하여 동기화된 제1 오디오 데이터 및 동기화된 제2 오디오 데이터를 획득하고, (ii) 상기 동기화된 제1 오디오 데이터 및상기 동기화된 제2 오디오 데이터로부터 획득한 마디 정보와 박자 정보 및 상기 제1 위치 데이터와 상기 제2 위치 데이터를 참조하여 상기 제1 댄스 동영상과 상기 제2 댄스 동영상을 서로 대응되는 복수의 동작 구간들로 분할하는 단계; (c) 상기 분석 서버가, 상기 복수의 동작 구간들 각각마다, 상기 동작 구간들 각각에 속하는 특정 제1 프레임이미지들과 특정 제2 프레임 이미지들 각각에 대해, 상기 학습자의 신체 부위 상의 이웃하는 관절에 대응되는제1 특정 위치 데이터의 공간 좌표 정보를 참조하여 상기 학습자의 신체 부위 상의 이웃하는 관절들 사이의 각도들에 대한 제1 각도 데이터를 획득하고, 상기 교습자의 신체 부위 상의 이웃하는 관절에 대응되는 제2 특정위치 데이터의 공간 좌표 정보를 참조하여 상기 교습자의 신체 부위 상의 이웃하는 관절들 사이의 각도들에 대한 제2 각도 데이터를 획득하는 단계; 및(d) 상기 분석 서버가, 상기 복수의 동작 구간들 각각마다, (i) 상기 특정 제1 프레임 이미지들에 대응되는 상기 제1 위치 데이터와 상기 제1 각도 데이터를 제1 포즈 데이터로 이용하고, 상기 특정 제2 프레임 이미지들에대응되는 상기 제2 위치 데이터와 상기 제2 각도 데이터를 제2 포즈 데이터로 이용하여, 상기 제1 포즈 데이터와 상기 제2 포즈 데이터를 각각 제1 시계열 데이터와 제2 시계열 데이터로 변환하고, (ii) 상기 제1 시계열 데이터와 상기 제2 시계열 데이터를 서로 비교하여 상기 학습자의 상기 댄스 동작과 상기 교습자의 상기 댄스 동작에 대한 일치 정확도를 계산함으로써 상기 학습자의 상기 댄스 동작에 대한 예측 평가 점수를 획득하는 단계;를 포함하는 방법."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 (c) 단계에서,상기 분석 서버가, 상기 복수의 동작 구간들 각각마다, 이웃하는 프레임 이미지 간의 시간 차이를 참조로 하여프레임 속도를 획득하여, 상기 동작 구간들 각각에 속하는 상기 특정 제1 프레임 이미지들과 상기 특정 제2 프레임 이미지들 각각에 대해, 상기 제1 각도 데이터 및 상기 제2 각도 데이터와 함께 (i) 상기 프레임 속도와 상기 각 주요 포인트들에 대한 상기 제1 위치 데이터 및 상기 제2 위치 데이터 각각을 참조하여 상기 각 주요 포인트들의 위치가 변화하는 속도에 대한 제1 가속도 데이터 및 제2 가속도 데이터를 추출하고, (ii) 상기 프레임속도와 상기 제1 각도 데이터 및 상기 제2 각도 데이터 각각을 참조하여 상기 관절들 사이의 상기 각도들의 변화량에 대한 제1 각속도 데이터 및 제2 각속도 데이터를 추출하는 것을 특징으로 하는 방법.공개특허 10-2025-0046443-3-청구항 3 제2항에 있어서, 상기 (d) 단계에서,상기 분석 서버는, 상기 복수의 동작 구간들 각각마다, (i) 상기 특정 제1 프레임 이미지들에 대응되는 상기 제1 가속도 데이터와 상기 제1 각속도 데이터를 추가적으로 상기 제1 포즈 데이터로 이용하고, 상기 특정 제2 프레임 이미지들에 대응되는 상기 제2 가속도 데이터 및 상기 제2 각속도 데이터를 추가적으로 상기 제2 포즈 데이터로 이용하여, 상기 제1 포즈 데이터와 상기 제2 포즈 데이터를 각각 상기 제1 시계열 데이터와 상기 제2 시계열 데이터로 변환하고, (ii) 상기 제1 시계열 데이터와 상기 제2 시계열 데이터를 평가 RNN(Recurrent NeuralNetwork) 모델에 입력하여, 상기 평가 RNN 모델로 하여금, (ii-1) 상기 제1 시계열 데이터와 상기 제2 시계열데이터에 DTW(Dynamic Time Warping) 기법을 적용하여 상기 제1 시계열 데이터와 상기 제2 시계열 데이터 간의유사성을 측정함으로써 상기 제1 시계열 데이터와 상기 제2 시계열 데이터 상에서 서로 매칭되는 제1 포즈 패턴데이터와 제2 포즈 패턴 데이터를 획득하며, (ii-2) 상기 제1 포즈 패턴 데이터의 상기 제1 위치 데이터와 상기제1 각도 데이터 및 상기 제2 포즈 패턴 데이터의 상기 제2 위치 데이터와 상기 제2 각도 데이터 간의 일치 정도를 평가하여 자세 정확도를 산출하고, 상기 제1 포즈 패턴 데이터와 상기 제2 포즈 패턴 데이터 간의 시간 차이를 분석하여 박자 정확도를 산출하며, 상기 제1 포즈 패턴 데이터의 상기 제1 가속도 데이터와 상기 제1 각속도 데이터 및 상기 제2 포즈 패턴 데이터 상기 제2 가속도 데이터와 상기 제2 각속도 데이터 간의 일치 정도를평가하여 힘 정확도를 산출함으로써 상기 일치 정확도를 계산하여 상기 예측 평가 점수를 획득하도록 하는 것을특징으로 하는 방법."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 분석 서버는, 상기 복수의 동작 구간들 각각마다, (i) 상기 자세 정확도, 상기 박자 정확도 및 상기 힘 정확도 중 적어도 일부에 가중치를 부여하는 제1 프로세스, (ii) 상기 학습자의 특정 신체 부위에 대해 생성된 특정 예측 평가 점수에 가중치를 부여하는 제2 프로세스, (iii) 상기 교습자의 추가 평가 점수를 반영하는 제3 프로세스, 및 (iv) 상기 예측 평가 점수를 상기 학습자 또는 상기 교습자가 선택한 척도에 맞추어 변환하는 제4프로세스 중 적어도 하나를 수행하여 상기 예측 평가 점수를 추가로 조정하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 분석 서버는, 상기 평가 RNN 네트워크가 생성한 상기 예측 평가 점수와 레퍼런스 평가 점수 간의 차이 값을 계산하고, 상기 차이 값의 분포를 분석하여 상기 예측 평가 점수와 상기 레퍼런스 평가 점수 간의 불일치를나타내는 이상점과 점수별 분포 관계를 파악하여 상기 평가 RNN 네트워크의 학습을 수행하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 (b) 단계에서,상기 분석 서버는, (i) 상기 주요 포인트들 중 특정 주요 포인트들에 대한 특정 제1 위치 데이터와 특정 제2 위치 데이터의 프레임 간 변화값을 획득하여, 기설정된 평균 변화값보다 큰 변화값을 가지는 복수의 지점들을 참조하여 후보 동작 구분 지점들로 선정하고, (ii) 상기 동기화된 제1 오디오 데이터 및 상기 동기화된 제2 오디오 데이터에 FFT(Fast Fourier Transform)를 적용하여 상기 마디 정보와 상기 박자 정보를 획득하며, (iii) 상기 후보 동작 구분 지점들과 상기 마디 정보 및 상기 박자 정보를 참조하여 상기 후보 동작 구분 지점들 중 박자에 맞게 기설정된 임계 속도 이상의 동작 변화가 이루어진 특정 동작 구분 지점들을 획득하고, (iv) 상기 특정 동작 구분 지점들을 기준으로 상기 제1 댄스 동영상과 상기 제2 댄스 동영상을 서로 대응되는 복수의 상기동작 구간들로 분할하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2025-0046443-4-제1항에 있어서, 상기 (b) 단계에서,상기 분석 서버는, 상기 제1 프레임 이미지들과 상기 제2 프레임 이미지들을 포즈 추정 CNN(Convolution NeuralNetwork) 모델에 입력하여, 상기 포즈 추정 CNN 모델로 하여금, (i) 상기 제1 프레임 이미지들로부터 획득한 제1 바운딩 박스들과 상기 제2 프레임 이미지들로부터 획득한 제2 바운딩 박스들에 CNN 연산을 적용하여 (i-1) 상기 주요 포인트들에 대한, 상기 제1 바운딩 박스들과 상기 제2 바운딩 박스들 각각에 대응되는 제1 히트맵들과제2 히트맵들을 획득하고, (i-2) 상기 주요 포인트들의 위치 및 방향에 대한 벡터 공간을 추정하는, 상기 제1바운딩 박스들과 상기 제2 바운딩 박스들 각각에 대응되는 제1 포지션맵들과 제2 포지션맵들을 획득하며, (ii)상기 제1 바운딩 박스들에 대응되는 상기 제1 히트맵들과 상기 제1 포지션맵들 및 상기 제2 바운딩 박스들에 대응되는 상기 제2 히트맵들과 상기 제2 포지션맵들에 포즈 추정 알고리즘을 적용하여 상기 주요 포인트들 각각에대한 위치 좌표 및 위치 좌표에 대한 제1 신뢰도 점수과 제2 신뢰도 점수를 획득함으로써, 상기 주요 포인트들에 대한, 상기 제1 프레임 이미지들의 상기 제1 위치 데이터와 상기 제2 프레임 이미지들의 상기 제2 위치 데이터를 획득하도록 하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 분석 서버는, 상기 위치 데이터로서 상기 제1 프레임 이미지들에 대응되는 제1 위치 데이터와 상기 제2 이미지 프레임 이미지들에 대응되는 제2 위치 데이터에 대해, (i) 서로 이웃하는 상기 제1 프레임 이미지들간의상기 제1 위치 데이터를 비교하고, 서로 이웃하는 상기 제2 프레임 이미지들간의 상기 제2 위치데이터를 비교하여 상기 제1 위치 데이터와 상기 제2 위치 데이터 각각에 대해 기설정된 연속성 - 상기 기설정된 연속성은 연속되는 프레임 간에서 상기 각 주요 포인트들의 상기 위치 데이터 각각에 대해 허용되는 변화값을 의미함 - 을 초과하는 아웃라이어 위치 데이터를 제거하는 노이즈 제거 프로세스, (ii) 상기 제1 위치 데이터와 상기 제2 위치데이터를 정규화하는 인물 크기 정규화 프로세스, 및 (iii) 상기 제1 위치 데이터 각각을 참조로 하여 획득된제1 중심점과 상기 제2 위치 데이터 각각을 참조로 하여 획득된 제2 중심점을 정렬하는 중심점 정렬 프로세스중 적어도 하나를 수행하여 상기 위치 데이터에 대한 전처리를 수행하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 분석 서버는, (i) 상기 노이즈 제거 프로세스로서 상기 제1 위치 데이터와 상기 제2 위치 데이터 각각에선형 보간법을 적용하여 상기 아웃라이어 위치 데이터를 제거한 후, 상기 제1 위치 데이터와 상기 제2 위치 데이터 각각에 대해 상기 주요 포인트들의 주요 움직임 - 상기 주요 움직임은 기설정된 구간의 연속되는 프레임들상의 상기 제1 위치 데이터와 상기 제2 위치 데이터의 최대값, 최소값에 대응되는 움직임임 - 에 대응되는 특정위치 데이터 외의 나머지 위치 데이터를 간략화하는 프로세스를 수행하고, (ii) 상기 인물 크기 정규화 프로세스로서 상기 교습자의 관절과 관절 간의 뼈 길이와 상기 학습자의 관절과 관절 간의 뼈 길의의 비율을 길이 비율로서 획득하여 상기 길이 비율을 참조로 상기 제1 위치 데이터를 수정하는 프로세스를 수행하며, (iii) 상기중심점 정렬 프로세스로서 상기 상기 제1 위치 데이터 각각을 참조로 하여 획득된 상기 제1 중심점을 상기 제2위치 데이터 각각을 참조로 하여 획득된 상기 제2 중심점으로 이동시켜 정렬하는 프로세스를 수행하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 분석 서버는, (i) 상기 분석 서버가 상기 제1 프레임 이미지들과 상기 제2 프레임 이미지들을 획득한 후상기 제1 프레임 이미지들의 상기 제1 위치 데이터와 상기 제2 프레임 이미지들의 상기 제2 위치 데이터가 획득되기까지 소요된 시간을 각각 측정하여 평균을 계산함으로써 동작인식 레이턴시(latency) 시간을 측정하고,(ii) 상기 분석 서버가 상기 제1 프레임 이미지들에 대해 획득한 상기 제1 위치 데이터 및 상기 제2 프레임 이미지들에 대해 획득한 상기 제2 위치 데이터와 정답 위치 데이터를 비교하여 차이값을 계산함으로써 동작인식정확도를 측정하며, (ii) 상기 동작인식 레이턴시 시간과 상기 동작인식 정확도를 참조하여 상기 분석 서버의동작인식 및 분석평가 기능의 정량적 평가를 수행하는 것을 특징으로 하는 방법. 공개특허 10-2025-0046443-5-청구항 11 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 분석 서버에 있어서,인스트럭션들을 저장하는 적어도 하나의 메모리; 및상기 인스트럭션들을 실행하기 위해 구성된 적어도 하나의 프로세서;를 포함하되,상기 프로세서가, (I) 상기 학습자의 상기 댄스 동작을 촬영한 제1 댄스 동영상과 상기 학습자의 상기 댄스 동작의 비교 기준을 제공하는 교습자의 댄스 동작을 촬영한 제2 댄스 동영상이 획득되면, (i) 상기 제1 댄스 동영상으로부터 복수의 제1 프레임 이미지들을 추출하고 상기 제2 댄스 동영상으로부터 복수의 제2 프레임 이미지들을 추출하며, (ii) 상기 제1 댄스 동영상으로부터 제1 오디오 데이터를 획득하고 상기 제2 댄스 동영상으로부터제2 오디오 데이터를 획득하는 프로세스, (II) (i) (i-1) 상기 제1 프레임 이미지들과 상기 제2 프레임 이미지들 각각으로부터 상기 학습자의 신체 부위와 상기 교습자의 신체 부위를 각각 식별하여, 상기 제1 프레임 이미지들 상에서 식별된 상기 학습자의 신체 부위를 복수의 관절 단위들로 나누어, 상기 관절 단위들마다 복수의 주요 포인트들 - 상기 주요 포인트들은 손, 발, 어깨, 팔꿈치, 무릎, 고관절, 무게중심점, 눈, 코, 입 중 적어도일부를 포함함 - 에 대한 제1 위치 데이터를 획득하고, 상기 제2 프레임 이미지들 상에서 식별된 상기 교습자의신체 부위 각각을 복수의 관절 단위들로 나누어, 상기 관절 단위들마다 복수의 상기 주요 포인트들에 대한 제2위치 데이터를 획득하며, (i-2) 상기 제1 오디오 데이터의 제1 시작 지점과 상기 제2 오디오 데이터의 제2 시작지점을 동기화하여 동기화된 제1 오디오 데이터 및 동기화된 제2 오디오 데이터를 획득하고, (ii) 상기 동기화된 제1 오디오 데이터 및 상기 동기화된 제2 오디오 데이터로부터 획득한 마디 정보와 박자 정보 및 상기 제1위치 데이터와 상기 제2 위치 데이터를 참조하여 상기 제1 댄스 동영상과 상기 제2 댄스 동영상을 서로 대응되는 복수의 동작 구간들로 분할하는 프로세스, (III) 상기 복수의 동작 구간들 각각마다, 상기 동작 구간들 각각에 속하는 특정 제1 프레임 이미지들과 특정 제2 프레임 이미지들 각각에 대해, 상기 학습자의 신체 부위 상의이웃하는 관절에 대응되는 제1 특정 위치 데이터의 공간 좌표 정보를 참조하여 상기 학습자의 신체 부위 상의이웃하는 관절들 사이의 각도들에 대한 제1 각도 데이터를 획득하고, 상기 교습자의 신체 부위 상의 이웃하는관절에 대응되는 제2 특정 위치 데이터의 공간 좌표 정보를 참조하여 상기 교습자의 신체 부위 상의 이웃하는관절들 사이의 각도들에 대한 제2 각도 데이터를 획득하는 프로세스; 및 (IV) 상기 복수의 동작 구간들 각각마다, (i) 상기 특정 제1 프레임 이미지들에 대응되는 상기 제1 위치 데이터와 상기 제1 각도 데이터를 제1 포즈데이터로 이용하고, 상기 특정 제2 프레임 이미지들에 대응되는 상기 제2 위치 데이터와 상기 제2 각도 데이터를 제2 포즈 데이터로 이용하여, 상기 제1 포즈 데이터와 상기 제2 포즈 데이터를 각각 제1 시계열 데이터와 제2 시계열 데이터로 변환하고, (ii) 상기 제1 시계열 데이터와 상기 제2 시계열 데이터를 서로 비교하여 상기 학습자의 상기 댄스 동작과 상기 교습자의 상기 댄스 동작에 대한 일치 정확도를 계산함으로써 상기 학습자의 상기 댄스 동작에 대한 예측 평가 점수를 획득하는 프로세스를 포함하는 분석 서버."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 (III) 프로세스에서, 상기 프로세서가, 상기 복수의 동작 구간들 각각마다, 이웃하는 프레임 이미지 간의 시간 차이를 참조로 하여프레임 속도를 획득하여, 상기 동작 구간들 각각에 속하는 상기 특정 제1 프레임 이미지들과 상기 특정 제2 프레임 이미지들 각각에 대해, 상기 제1 각도 데이터 및 상기 제2 각도 데이터와 함께 (i) 상기 프레임 속도와 상기 각 주요 포인트들에 대한 상기 제1 위치 데이터 및 상기 제2 위치 데이터 각각을 참조하여 상기 각 주요 포인트들의 위치가 변화하는 속도에 대한 제1 가속도 데이터 및 제2 가속도 데이터를 추출하고, (ii) 상기 프레임속도와 상기 제1 각도 데이터 및 상기 제2 각도 데이터 각각을 참조하여 상기 관절들 사이의 상기 각도들의 변화량에 대한 제1 각속도 데이터 및 제2 각속도 데이터를 추출하는 것을 특징으로 하는 분석 서버."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 (IV) 프로세스에서,상기 프로세서는, 상기 복수의 동작 구간들 각각마다, (i) 상기 특정 제1 프레임 이미지들에 대응되는 상기 제1가속도 데이터와 상기 제1 각속도 데이터를 추가적으로 상기 제1 포즈 데이터로 이용하고, 상기 특정 제2 프레공개특허 10-2025-0046443-6-임 이미지들에 대응되는 상기 제2 가속도 데이터 및 상기 제2 각속도 데이터를 추가적으로 상기 제2 포즈 데이터로 이용하여, 상기 제1 포즈 데이터와 상기 제2 포즈 데이터를 각각 상기 제1 시계열 데이터와 상기 제2 시계열 데이터로 변환하고, (ii) 상기 제1 시계열 데이터와 상기 제2 시계열 데이터를 평가 RNN(Recurrent NeuralNetwork) 모델에 입력하여, 상기 평가 RNN 모델로 하여금, (ii-1) 상기 제1 시계열 데이터와 상기 제2 시계열데이터에 DTW(Dynamic Time Warping) 기법을 적용하여 상기 제1 시계열 데이터와 상기 제2 시계열 데이터 간의유사성을 측정함으로써 상기 제1 시계열 데이터와 상기 제2 시계열 데이터 상에서 서로 매칭되는 제1 포즈 패턴데이터와 제2 포즈 패턴 데이터를 획득하며, (ii-2) 상기 제1 포즈 패턴 데이터의 상기 제1 위치 데이터와 상기제1 각도 데이터 및 상기 제2 포즈 패턴 데이터의 상기 제2 위치 데이터와 상기 제2 각도 데이터 간의 일치 정도를 평가하여 자세 정확도를 산출하고, 상기 제1 포즈 패턴 데이터와 상기 제2 포즈 패턴 데이터 간의 시간 차이를 분석하여 박자 정확도를 산출하며, 상기 제1 포즈 패턴 데이터의 상기 제1 가속도 데이터와 상기 제1 각속도 데이터 및 상기 제2 포즈 패턴 데이터 상기 제2 가속도 데이터와 상기 제2 각속도 데이터 간의 일치 정도를평가하여 힘 정확도를 산출함으로써 상기 일치 정확도를 계산하여 상기 예측 평가 점수를 획득하도록 하는 것을특징으로 하는 분석 서버."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 프로세서는, 상기 복수의 동작 구간들 각각마다, (i) 상기 자세 정확도, 상기 박자 정확도 및 상기 힘 정확도 중 적어도 일부에 가중치를 부여하는 제1 프로세스, (ii) 상기 학습자의 특정 신체 부위에 대해 생성된 특정 예측 평가 점수에 가중치를 부여하는 제2 프로세스, (iii) 상기 교습자의 추가 평가 점수를 반영하는 제3 프로세스, 및 (iv) 상기 예측 평가 점수를 상기 학습자 또는 상기 교습자가 선택한 척도에 맞추어 변환하는 제4프로세스 중 적어도 하나를 수행하여 상기 예측 평가 점수를 추가로 조정하는 것을 특징으로 하는 분석 서버."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서, 상기 프로세서는, 상기 평가 RNN 네트워크가 생성한 상기 예측 평가 점수와 레퍼런스 평가 점수 간의 차이 값을계산하고, 상기 차이 값의 분포를 분석하여 상기 예측 평가 점수와 상기 레퍼런스 평가 점수 간의 불일치를 나타내는 이상점과 점수별 분포 관계를 파악하여 상기 평가 RNN 네트워크의 학습을 수행하는 것을 특징으로 하는분석 서버."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 (II) 프로세스에서,상기 프로세서는, (i) 상기 주요 포인트들 중 특정 주요 포인트들에 대한 특정 제1 위치 데이터와 특정 제2 위치 데이터의 프레임 간 변화값을 획득하여, 기설정된 평균 변화값보다 큰 변화값을 가지는 복수의 지점들을 참조하여 후보 동작 구분 지점들로 선정하고, (ii) 상기 동기화된 제1 오디오 데이터 및 상기 동기화된 제2 오디오 데이터에 FFT(Fast Fourier Transform)를 적용하여 상기 마디 정보와 상기 박자 정보를 획득하며, (iii) 상기 후보 동작 구분 지점들과 상기 마디 정보 및 상기 박자 정보를 참조하여 상기 후보 동작 구분 지점들 중 박자에 맞게 기설정된 임계 속도 이상의 동작 변화가 이루어진 특정 동작 구분 지점들을 획득하고, (iv) 상기 특정 동작 구분 지점들을 기준으로 상기 제1 댄스 동영상과 상기 제2 댄스 동영상을 서로 대응되는 복수의 상기동작 구간들로 분할하는 것을 특징으로 하는 분석 서버."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서, 상기 (II) 프로세스에서,상기 프로세서는, 상기 제1 프레임 이미지들과 상기 제2 프레임 이미지들을 포즈 추정 CNN(Convolution NeuralNetwork) 모델에 입력하여, 상기 포즈 추정 CNN 모델로 하여금, (i) 상기 제1 프레임 이미지들로부터 획득한 제1 바운딩 박스들과 상기 제2 프레임 이미지들로부터 획득한 제2 바운딩 박스들에 CNN 연산을 적용하여 (i-1) 상기 주요 포인트들에 대한, 상기 제1 바운딩 박스들과 상기 제2 바운딩 박스들 각각에 대응되는 제1 히트맵들과공개특허 10-2025-0046443-7-제2 히트맵들을 획득하고, (i-2) 상기 주요 포인트들의 위치 및 방향에 대한 벡터 공간을 추정하는, 상기 제1바운딩 박스들과 상기 제2 바운딩 박스들 각각에 대응되는 제1 포지션맵들과 제2 포지션맵들을 획득하며, (ii)상기 제1 바운딩 박스들에 대응되는 상기 제1 히트맵들과 상기 제1 포지션맵들 및 상기 제2 바운딩 박스들에 대응되는 상기 제2 히트맵들과 상기 제2 포지션맵들에 포즈 추정 알고리즘을 적용하여 상기 주요 포인트들 각각에대한 위치 좌표 및 위치 좌표에 대한 제1 신뢰도 점수과 제2 신뢰도 점수를 획득함으로써, 상기 주요 포인트들에 대한, 상기 제1 프레임 이미지들의 상기 제1 위치 데이터와 상기 제2 프레임 이미지들의 상기 제2 위치 데이터를 획득하도록 하는 것을 특징으로 하는 분석 서버."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 프로세서는, 상기 위치 데이터로서 상기 제1 프레임 이미지들에 대응되는 제1 위치 데이터와 상기 제2 이미지 프레임 이미지들에 대응되는 제2 위치 데이터에 대해, (i) 서로 이웃하는 상기 제1 프레임 이미지들간의상기 제1 위치 데이터를 비교하고, 서로 이웃하는 상기 제2 프레임 이미지들간의 상기 제2 위치데이터를 비교하여 상기 제1 위치 데이터와 상기 제2 위치 데이터 각각에 대해 기설정된 연속성 - 상기 기설정된 연속성은 연속되는 프레임 간에서 상기 각 주요 포인트들의 상기 위치 데이터 각각에 대해 허용되는 변화값을 의미함 - 을 초과하는 아웃라이어 위치 데이터를 제거하는 노이즈 제거 프로세스, (ii) 상기 제1 위치 데이터와 상기 제2 위치데이터를 정규화하는 인물 크기 정규화 프로세스, 및 (iii) 상기 제1 위치 데이터 각각을 참조로 하여 획득된제1 중심점과 상기 제2 위치 데이터 각각을 참조로 하여 획득된 제2 중심점을 정렬하는 중심점 정렬 프로세스중 적어도 하나를 수행하여 상기 위치 데이터에 대한 전처리를 수행하는 것을 특징으로 하는 분석 서버."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 프로세서는, (i) 상기 노이즈 제거 프로세스로서 상기 제1 위치 데이터와 상기 제2 위치 데이터 각각에 선형 보간법을 적용하여 상기 아웃라이어 위치 데이터를 제거한 후, 상기 제1 위치 데이터와 상기 제2 위치 데이터 각각에 대해 상기 주요 포인트들의 주요 움직임 - 상기 주요 움직임은 기설정된 구간의 연속되는 프레임들상의 상기 제1 위치 데이터와 상기 제2 위치 데이터의 최대값, 최소값에 대응되는 움직임임 - 에 대응되는 특정위치 데이터 외의 나머지 위치 데이터를 간략화하는 프로세스를 수행하고, (ii) 상기 인물 크기 정규화 프로세스로서 상기 교습자의 관절과 관절 간의 뼈 길이와 상기 학습자의 관절과 관절 간의 뼈 길의의 비율을 길이 비율로서 획득하여 상기 길이 비율을 참조로 상기 제1 위치 데이터를 수정하는 프로세스를 수행하며, (iii) 상기중심점 정렬 프로세스로서 상기 상기 제1 위치 데이터 각각을 참조로 하여 획득된 상기 제1 중심점을 상기 제2위치 데이터 각각을 참조로 하여 획득된 상기 제2 중심점으로 이동시켜 정렬하는 프로세스를 수행하는 것을 특징으로 하는 분석 서버."}
{"patent_id": "10-2023-0129726", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 프로세서는, (i) 상기 프로세서가 상기 제1 프레임 이미지들과 상기 제2 프레임 이미지들을 획득한 후 상기 제1 프레임 이미지들의 상기 제1 위치 데이터와 상기 제2 프레임 이미지들의 상기 제2 위치 데이터가 획득되기까지 소요된 시간을 각각 측정하여 평균을 계산함으로써 동작인식 레이턴시(latency) 시간을 측정하고, (ii)상기 프로세서가 상기 제1 프레임 이미지들에 대해 획득한 상기 제1 위치 데이터 및 상기 제2 프레임 이미지들에 대해 획득한 상기 제2 위치 데이터와 정답 위치 데이터를 비교하여 차이값을 계산함으로써 동작인식 정확도를 측정하며, (ii) 상기 동작인식 레이턴시 시간과 상기 동작인식 정확도를 참조하여 상기 프로세서의 동작인식및 분석평가 기능의 정량적 평가를 수행하는 것을 특징으로 하는 분석 서버."}
{"patent_id": "10-2023-0129726", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따르면, 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 방법에 있어서, (a) 상기 학습자의 상기 댄스 동작을 촬영한 제1 댄스 동영상과 상기 학습자의 상기 댄스 동작의 비교 기준을 제공하는 교습자의 댄스 동 작을 촬영한 제2 댄스 동영상이 획득되면, 분석 서버가, (i) 상기 제1 댄스 동영상으로부터 복수의 제1 프레임 (뒷면에 계속)"}
{"patent_id": "10-2023-0129726", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 방법 및 이를 이용한 분석 서버에 관한 것으로, 보다 상세하게는, 학습자와 교습자의 댄스 영상에서 추출한 프레임 이미지들과 오디오 데이터를 이용하여 인공 지능을 기반으로 학습자와 교습자의 댄스 동작을 비교 분석함으로써 학습자의 댄스 동작에 대한 평가 점수를 예측하는 방법 및 이를 이용한 분석 서버에 관한 것이다."}
{"patent_id": "10-2023-0129726", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재 교육 분야에서는 정보통신기술(ICT)의 발전과 4차 산업혁명의 도래로 새로운 가능성이 열리고 있다. 이에 따라, VR·AR, 인공지능(AI), 빅데이터 등의 첨단 기술이 교육 분야에 접목되며, 에듀테크 분야에서의 성장이 두드러지게 나타나고 있다. 또한, 코로나19의 범유행으로 인해 비대면 교육의 필요성이 강조되면서, 온라인 교 육 서비스의 중요성은 크게 부각되었다. 그러나, 비대면 환경에서 제공되는 원격 교육은 그 특성상 학습자와 교습자 간의 상호작용이 제한될 수 밖에 없 다. 이에 따라, 예체능과 실험 등의 실습과 체험 분야에서는 교습자와 학습자 간의 소통, 학습 관리 및 평가 등의 측면에서 원격 교육이 다양한 한계를 보이며, 변화와 개선이 필요한 상황이다. 특히 예체능을 원격 교육으로 제공하는 비대면 예체능 교육의 경우, 개인의 음악, 댄스, 체육 등의 예체능 학습 정도를 비대면 영상으로 평가하기에는 각 영상의 음질 및 화질 등의 품질 차이로 인해 정확하고 객관적인 평가 가 어려울 수 있다. 또한, 대면 교육과 비교하였을 때, 비대면 교육이 가지고 있는 시각적 한계와 소통의 한계는 교습자가 효과적인 실시간 피드백을 제공함에 있어서 큰 제약으로 작용하고 있다. 따라서, 상기 문제점들을 해결하기 위한 개선 방안이 요구되는 실정이다."}
{"patent_id": "10-2023-0129726", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 모두 해결하는 것을 그 목적으로 한다. 또한, 본 발명은 영상 분석과 인공지능을 결합하여 영상 데이터에서 자동으로 인물을 식별하고 포즈를 분석하여 실시간으로 학습자의 댄스 동작에 대한 평가와 피드백을 제공하는 것을 목적으로 한다. 또한, 본 발명은 영상 데이터로부터 추정한 포즈와 레퍼런스 영상 데이터의 포즈를 비교하여 자세, 타이밍, 힘 의 정확도 점수를 계산함으로써 개별 학생의 동작을 정확하게 분석하고 개인 맞춤형 평가와 지도가 가능하도록 하는 것을 또 다른 목적으로 한다. 또한, 본 발명은 영상 데이터로부터 획득한 프레임 이미지와 오디오 데이터를 함께 분석함으로써 영상 데이터를 평가가 필요한 동작이 포함된 복수의 동작 구간들로 분할하여 평가를 수행함으로써 보다 효율적이고 정확한 평 가가 가능하도록 하는 것을 또 다른 목적으로 한다. 또한, 본 발명은 자세, 박자, 힘 등의 다양하고 객관적인 평가요소를 결합하여 종합적인 평가점수를 생산하고 구체적이고 전문적인 피드백 제공 가능하도록 하는 것을 또 다른 목적으로 한다. 또한, 본 발명은 영상 데이터로부터 획득한 포즈 데이터에 대한 시계열 데이터에 대해 데이터 패턴 매칭 알고리 즘을 적용하여 포즈 데이터의 시간적 패턴을 비교함으로써 분석의 정확도를 향상시키는 것을 또 다른 목적으로 한다. 또한, 본 발명은 학습자가 선택한 평가 척도에 맞게 점수를 변환하여 제공함으로써 개인화된 평가 결과 제공을 통해 학습자가 댄스 동작의 품질을 자신의 기준에 맞추어 이해하고 개선 가능하도록 하는 것을 또 다른 목적으 로 한다."}
{"patent_id": "10-2023-0129726", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 바와 같은 본 발명의 목적을 달성하고, 후술하는 본 발명의 특징적인 효과를 실현하기 위한, 본 발명의 특징적인 구성은 하기와 같다. 본 발명의 일 태양에 따르면, 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 방법에 있어서, a) 상기 학 습자의 상기 댄스 동작을 촬영한 제1 댄스 동영상과 상기 학습자의 상기 댄스 동작의 비교 기준을 제공하는 교 습자의 댄스 동작을 촬영한 제2 댄스 동영상이 획득되면, 분석 서버가, (i) 상기 제1 댄스 동영상으로부터 복수 의 제1 프레임 이미지들을 추출하고 상기 제2 댄스 동영상으로부터 복수의 제2 프레임 이미지들을 추출하며, (ii) 상기 제1 댄스 동영상으로부터 제1 오디오 데이터를 획득하고 상기 제2 댄스 동영상으로부터 제2 오디오데이터를 획득하는 단계; (b) 상기 분석 서버가, (i) (i-1) 상기 제1 프레임 이미지들과 상기 제2 프레임 이미 지들 각각으로부터 상기 학습자의 신체 부위와 상기 교습자의 신체 부위를 각각 식별하여, 상기 제1 프레임 이 미지들 상에서 식별된 상기 학습자의 신체 부위를 복수의 관절 단위들로 나누어, 상기 관절 단위들마다 복수의 주요 포인트들 - 상기 주요 포인트들은 손, 발, 어깨, 팔꿈치, 무릎, 고관절, 무게중심점, 눈, 코, 입 중 적어 도 일부를 포함함 - 에 대한 제1 위치 데이터를 획득하고, 상기 제2 프레임 이미지들 상에서 식별된 상기 교습 자의 신체 부위 각각을 복수의 관절 단위들로 나누어, 상기 관절 단위들마다 복수의 상기 주요 포인트들에 대한 제2 위치 데이터를 획득하며, (i-2) 상기 제1 오디오 데이터의 제1 시작 지점과 상기 제2 오디오 데이터의 제2 시작 지점을 동기화하여 동기화된 제1 오디오 데이터 및 동기화된 제2 오디오 데이터를 획득하고, (ii) 상기 동 기화된 제1 오디오 데이터 및 상기 동기화된 제2 오디오 데이터로부터 획득한 마디 정보와 박자 정보 및 상기 제1 위치 데이터와 상기 제2 위치 데이터를 참조하여 상기 제1 댄스 동영상과 상기 제2 댄스 동영상을 서로 대 응되는 복수의 동작 구간들로 분할하는 단계; (c) 상기 분석 서버가, 상기 복수의 동작 구간들 각각마다, 상기 동작 구간들 각각에 속하는 특정 제1 프레임 이미지들과 특정 제2 프레임 이미지들 각각에 대해, 상기 학습자의 신체 부위 상의 이웃하는 관절에 대응되는 제1 특정 위치 데이터의 공간 좌표 정보를 참조하여 상기 학습자의 신체 부위 상의 이웃하는 관절들 사이의 각도들에 대한 제1 각도 데이터를 획득하고, 상기 교습자의 신체 부위 상의 이웃하는 관절에 대응되는 제2 특정 위치 데이터의 공간 좌표 정보를 참조하여 상기 교습자의 신체 부위 상의 이웃하는 관절들 사이의 각도들에 대한 제2 각도 데이터를 획득하는 단계; 및 (d) 상기 분석 서버가, 상기 복수의 동작 구간들 각각마다, (i) 상기 특정 제1 프레임 이미지들에 대응되는 상기 제1 위치 데이터와 상기 제 1 각도 데이터를 제1 포즈 데이터로 이용하고, 상기 특정 제2 프레임 이미지들에 대응되는 상기 제2 위치 데이 터와 상기 제2 각도 데이터를 제2 포즈 데이터로 이용하여, 상기 제1 포즈 데이터와 상기 제2 포즈 데이터를 각 각 제1 시계열 데이터와 제2 시계열 데이터로 변환하고, (ii) 상기 제1 시계열 데이터와 상기 제2 시계열 데이 터를 서로 비교하여 상기 학습자의 상기 댄스 동작과 상기 교습자의 상기 댄스 동작에 대한 일치 정확도를 계산 함으로써 상기 학습자의 상기 댄스 동작에 대한 예측 평가 점수를 획득하는 단계;를 포함하는 방법이 개시된다. 일례로서, 상기 (c) 단계에서, 상기 분석 서버가, 상기 복수의 동작 구간들 각각마다, 이웃하는 프레임 이미지 간의 시간 차이를 참조로 하여 프레임 속도를 획득하여, 상기 동작 구간들 각각에 속하는 상기 특정 제1 프레임 이미지들과 상기 특정 제2 프레임 이미지들 각각에 대해, 상기 제1 각도 데이터 및 상기 제2 각도 데이터와 함 께 (i) 상기 프레임 속도와 상기 각 주요 포인트들에 대한 상기 제1 위치 데이터 및 상기 제2 위치 데이터 각각 을 참조하여 상기 각 주요 포인트들의 위치가 변화하는 속도에 대한 제1 가속도 데이터 및 제2 가속도 데이터를 추출하고, (ii) 상기 프레임 속도와 상기 제1 각도 데이터 및 상기 제2 각도 데이터 각각을 참조하여 상기 관절 들 사이의 상기 각도들의 변화량에 대한 제1 각속도 데이터 및 제2 각속도 데이터를 추출하는 것을 특징으로 하 는 방법이 개시된다. 일례로서, 상기 (d) 단계에서, 상기 분석 서버는, 상기 복수의 동작 구간들 각각마다, (i) 상기 특정 제1 프레 임 이미지들에 대응되는 상기 제1 가속도 데이터와 상기 제1 각속도 데이터를 추가적으로 상기 제1 포즈 데이터 로 이용하고, 상기 특정 제2 프레임 이미지들에 대응되는 상기 제2 가속도 데이터 및 상기 제2 각속도 데이터를 추가적으로 상기 제2 포즈 데이터로 이용하여, 상기 제1 포즈 데이터와 상기 제2 포즈 데이터를 각각 상기 제1 시계열 데이터와 상기 제2 시계열 데이터로 변환하고, (ii) 상기 제1 시계열 데이터와 상기 제2 시계열 데이터 를 평가 RNN(Recurrent Neural Network) 모델에 입력하여, 상기 평가 RNN 모델로 하여금, (ii-1) 상기 제1 시 계열 데이터와 상기 제2 시계열 데이터에 DTW(Dynamic Time Warping) 기법을 적용하여 상기 제1 시계열 데이터 와 상기 제2 시계열 데이터 간의 유사성을 측정함으로써 상기 제1 시계열 데이터와 상기 제2 시계열 데이터 상 에서 서로 매칭되는 제1 포즈 패턴 데이터와 제2 포즈 패턴 데이터를 획득하며, (ii-2) 상기 제1 포즈 패턴 데 이터의 상기 제1 위치 데이터와 상기 제1 각도 데이터 및 상기 제2 포즈 패턴 데이터의 상기 제2 위치 데이터와 상기 제2 각도 데이터 간의 일치 정도를 평가하여 자세 정확도를 산출하고, 상기 제1 포즈 패턴 데이터와 상기 제2 포즈 패턴 데이터 간의 시간 차이를 분석하여 박자 정확도를 산출하며, 상기 제1 포즈 패턴 데이터의 상기 제1 가속도 데이터와 상기 제1 각속도 데이터 및 상기 제2 포즈 패턴 데이터 상기 제2 가속도 데이터와 상기 제 2 각속도 데이터 간의 일치 정도를 평가하여 힘 정확도를 산출함으로써 상기 일치 정확도를 계산하여 상기 예측 평가 점수를 획득하도록 하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 분석 서버는, 상기 복수의 동작 구간들 각각마다, (i) 상기 자세 정확도, 상기 박자 정확도 및 상기 힘 정확도 중 적어도 일부에 가중치를 부여하는 제1 프로세스, (ii) 상기 학습자의 특정 신체 부위에 대해 생성된 특정 예측 평가 점수에 가중치를 부여하는 제2 프로세스, (iii) 상기 교습자의 추가 평가 점수를 반영하 는 제3 프로세스, 및 (iv) 상기 예측 평가 점수를 상기 학습자 또는 상기 교습자가 선택한 척도에 맞추어 변환 하는 제4 프로세스 중 적어도 하나를 수행하여 상기 예측 평가 점수를 추가로 조정하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 분석 서버는, 상기 평가 RNN 네트워크가 생성한 상기 예측 평가 점수와 레퍼런스 평가 점수 간 의 차이 값을 계산하고, 상기 차이 값의 분포를 분석하여 상기 예측 평가 점수와 상기 레퍼런스 평가 점수 간의 불일치를 나타내는 이상점과 점수별 분포 관계를 파악하여 상기 평가 RNN 네트워크의 학습을 수행하는 것을 특 징으로 하는 방법이 개시된다. 일례로서, 상기 (b) 단계에서, 상기 분석 서버는, (i) 상기 주요 포인트들 중 특정 주요 포인트들에 대한 특정 제1 위치 데이터와 특정 제2 위치 데이터의 프레임 간 변화값을 획득하여, 기설정된 평균 변화값보다 큰 변화값 을 가지는 복수의 지점들을 참조하여 후보 동작 구분 지점들로 선정하고, (ii) 상기 동기화된 제1 오디오 데이 터 및 상기 동기화된 제2 오디오 데이터에 FFT(Fast Fourier Transform)를 적용하여 상기 마디 정보와 상기 박 자 정보를 획득하며, (iii) 상기 후보 동작 구분 지점들과 상기 마디 정보 및 상기 박자 정보를 참조하여 상기 후보 동작 구분 지점들 중 박자에 맞게 기설정된 임계 속도 이상의 동작 변화가 이루어진 특정 동작 구분 지점 들을 획득하고, (iv) 상기 특정 동작 구분 지점들을 기준으로 상기 제1 댄스 동영상과 상기 제2 댄스 동영상을 서로 대응되는 복수의 상기 동작 구간들로 분할하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 (b) 단계에서, 상기 분석 서버는, 상기 제1 프레임 이미지들과 상기 제2 프레임 이미지들을 포 즈 추정 CNN(Convolution Neural Network) 모델에 입력하여, 상기 포즈 추정 CNN 모델로 하여금, (i) 상기 제1 프레임 이미지들로부터 획득한 제1 바운딩 박스들과 상기 제2 프레임 이미지들로부터 획득한 제2 바운딩 박스들 에 CNN 연산을 적용하여 (i-1) 상기 주요 포인트들에 대한, 상기 제1 바운딩 박스들과 상기 제2 바운딩 박스들 각각에 대응되는 제1 히트맵들과 제2 히트맵들을 획득하고, (i-2) 상기 주요 포인트들의 위치 및 방향에 대한 벡터 공간을 추정하는, 상기 제1 바운딩 박스들과 상기 제2 바운딩 박스들 각각에 대응되는 제1 포지션맵들과 제2 포지션맵들을 획득하며, (ii) 상기 제1 바운딩 박스들에 대응되는 상기 제1 히트맵들과 상기 제1 포지션맵 들 및 상기 제2 바운딩 박스들에 대응되는 상기 제2 히트맵들과 상기 제2 포지션맵들에 포즈 추정 알고리즘을 적용하여 상기 주요 포인트들 각각에 대한 위치 좌표 및 위치 좌표에 대한 제1 신뢰도 점수과 제2 신뢰도 점수 를 획득함으로써, 상기 주요 포인트들에 대한, 상기 제1 프레임 이미지들의 상기 제1 위치 데이터와 상기 제2 프레임 이미지들의 상기 제2 위치 데이터를 획득하도록 하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 분석 서버는, 상기 위치 데이터로서 상기 제1 프레임 이미지들에 대응되는 제1 위치 데이터와 상기 제2 이미지 프레임 이미지들에 대응되는 제2 위치 데이터에 대해, (i) 서로 이웃하는 상기 제1 프레임 이 미지들간의 상기 제1 위치 데이터를 비교하고, 서로 이웃하는 상기 제2 프레임 이미지들간의 상기 제2 위치데이 터를 비교하여 상기 제1 위치 데이터와 상기 제2 위치 데이터 각각에 대해 기설정된 연속성 - 상기 기설정된 연 속성은 연속되는 프레임 간에서 상기 각 주요 포인트들의 상기 위치 데이터 각각에 대해 허용되는 변화값을 의 미함 - 을 초과하는 아웃라이어 위치 데이터를 제거하는 노이즈 제거 프로세스, (ii) 상기 제1 위치 데이터와 상기 제2 위치 데이터를 정규화하는 인물 크기 정규화 프로세스, 및 (iii) 상기 제1 위치 데이터 각각을 참조로 하여 획득된 제1 중심점과 상기 제2 위치 데이터 각각을 참조로 하여 획득된 제2 중심점을 정렬하는 중심점 정 렬 프로세스 중 적어도 하나를 수행하여 상기 위치 데이터에 대한 전처리를 수행하는 것을 특징으로 하는 방법 이 개시된다. 일례로서, 상기 분석 서버는, (i) 상기 노이즈 제거 프로세스로서 상기 제1 위치 데이터와 상기 제2 위치 데이 터 각각에 선형 보간법을 적용하여 상기 아웃라이어 위치 데이터를 제거한 후, 상기 제1 위치 데이터와 상기 제 2 위치 데이터 각각에 대해 상기 주요 포인트들의 주요 움직임 - 상기 주요 움직임은 기설정된 구간의 연속되는 프레임들 상의 상기 제1 위치 데이터와 상기 제2 위치 데이터의 최대값, 최소값에 대응되는 움직임임 - 에 대응 되는 특정 위치 데이터 외의 나머지 위치 데이터를 간략화하는 프로세스를 수행하고, (ii) 상기 인물 크기 정규 화 프로세스로서 상기 교습자의 관절과 관절 간의 뼈 길이와 상기 학습자의 관절과 관절 간의 뼈 길의의 비율을 길이 비율로서 획득하여 상기 길이 비율을 참조로 상기 제1 위치 데이터를 수정하는 프로세스를 수행하며, (iii) 상기 중심점 정렬 프로세스로서 상기 상기 제1 위치 데이터 각각을 참조로 하여 획득된 상기 제1 중심점 을 상기 제2 위치 데이터 각각을 참조로 하여 획득된 상기 제2 중심점으로 이동시켜 정렬하는 프로세스를 수행 하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 분석 서버는, (i) 상기 분석 서버가 상기 제1 프레임 이미지들과 상기 제2 프레임 이미지들을 획득한 후 상기 제1 프레임 이미지들의 상기 제1 위치 데이터와 상기 제2 프레임 이미지들의 상기 제2 위치 데 이터가 획득되기까지 소요된 시간을 각각 측정하여 평균을 계산함으로써 동작인식 레이턴시(latency) 시간을 측 정하고, (ii) 상기 분석 서버가 상기 제1 프레임 이미지들에 대해 획득한 상기 제1 위치 데이터 및 상기 제2 프레임 이미지들에 대해 획득한 상기 제2 위치 데이터와 정답 위치 데이터를 비교하여 차이값을 계산함으로써 동 작인식 정확도를 측정하며, (ii) 상기 동작인식 레이턴시 시간과 상기 동작인식 정확도를 참조하여 상기 분석 서버의 동작인식 및 분석평가 기능의 정량적 평가를 수행하는 것을 특징으로 하는 방법이 개시된다. 본 발며의 다른 태양에 따르면, 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 분석 서버에 있어서, 인스 트럭션들을 저장하는 적어도 하나의 메모리; 및 상기 인스트럭션들을 실행하기 위해 구성된 적어도 하나의 프로 세서;를 포함하되, 상기 프로세서가, (I) 상기 학습자의 상기 댄스 동작을 촬영한 제1 댄스 동영상과 상기 학습 자의 상기 댄스 동작의 비교 기준을 제공하는 교습자의 댄스 동작을 촬영한 제2 댄스 동영상이 획득되면, (i) 상기 제1 댄스 동영상으로부터 복수의 제1 프레임 이미지들을 추출하고 상기 제2 댄스 동영상으로부터 복수의 제2 프레임 이미지들을 추출하며, (ii) 상기 제1 댄스 동영상으로부터 제1 오디오 데이터를 획득하고 상기 제2 댄스 동영상으로부터 제2 오디오 데이터를 획득하는 프로세스, (II) (i) (i-1) 상기 제1 프레임 이미지들과 상 기 제2 프레임 이미지들 각각으로부터 상기 학습자의 신체 부위와 상기 교습자의 신체 부위를 각각 식별하여, 상기 제1 프레임 이미지들 상에서 식별된 상기 학습자의 신체 부위를 복수의 관절 단위들로 나누어, 상기 관절 단위들마다 복수의 주요 포인트들 - 상기 주요 포인트들은 손, 발, 어깨, 팔꿈치, 무릎, 고관절, 무게중심점, 눈, 코, 입 중 적어도 일부를 포함함 - 에 대한 제1 위치 데이터를 획득하고, 상기 제2 프레임 이미지들 상에서 식별된 상기 교습자의 신체 부위 각각을 복수의 관절 단위들로 나누어, 상기 관절 단위들마다 복수의 상기 주요 포인트들에 대한 제2 위치 데이터를 획득하며, (i-2) 상기 제1 오디오 데이터의 제1 시작 지점과 상기 제2 오디 오 데이터의 제2 시작 지점을 동기화하여 동기화된 제1 오디오 데이터 및 동기화된 제2 오디오 데이터를 획득하 고, (ii) 상기 동기화된 제1 오디오 데이터 및 상기 동기화된 제2 오디오 데이터로부터 획득한 마디 정보와 박 자 정보 및 상기 제1 위치 데이터와 상기 제2 위치 데이터를 참조하여 상기 제1 댄스 동영상과 상기 제2 댄스 동영상을 서로 대응되는 복수의 동작 구간들로 분할하는 프로세스, (III) 상기 복수의 동작 구간들 각각마다, 상기 동작 구간들 각각에 속하는 특정 제1 프레임 이미지들과 특정 제2 프레임 이미지들 각각에 대해, 상기 학 습자의 신체 부위 상의 이웃하는 관절에 대응되는 제1 특정 위치 데이터의 공간 좌표 정보를 참조하여 상기 학 습자의 신체 부위 상의 이웃하는 관절들 사이의 각도들에 대한 제1 각도 데이터를 획득하고, 상기 교습자의 신 체 부위 상의 이웃하는 관절에 대응되는 제2 특정 위치 데이터의 공간 좌표 정보를 참조하여 상기 교습자의 신 체 부위 상의 이웃하는 관절들 사이의 각도들에 대한 제2 각도 데이터를 획득하는 프로세스; 및 (IV) 상기 복수 의 동작 구간들 각각마다, (i) 상기 특정 제1 프레임 이미지들에 대응되는 상기 제1 위치 데이터와 상기 제1 각 도 데이터를 제1 포즈 데이터로 이용하고, 상기 특정 제2 프레임 이미지들에 대응되는 상기 제2 위치 데이터와 상기 제2 각도 데이터를 제2 포즈 데이터로 이용하여, 상기 제1 포즈 데이터와 상기 제2 포즈 데이터를 각각 제 1 시계열 데이터와 제2 시계열 데이터로 변환하고, (ii) 상기 제1 시계열 데이터와 상기 제2 시계열 데이터를 서로 비교하여 상기 학습자의 상기 댄스 동작과 상기 교습자의 상기 댄스 동작에 대한 일치 정확도를 계산함으 로써 상기 학습자의 상기 댄스 동작에 대한 예측 평가 점수를 획득하는 프로세스를 포함하는 분석 서버가 개시 된다. 일례로서, 상기 (III) 프로세스에서, 상기 프로세서가, 상기 복수의 동작 구간들 각각마다, 이웃하는 프레임 이 미지 간의 시간 차이를 참조로 하여 프레임 속도를 획득하여, 상기 동작 구간들 각각에 속하는 상기 특정 제1 프레임 이미지들과 상기 특정 제2 프레임 이미지들 각각에 대해, 상기 제1 각도 데이터 및 상기 제2 각도 데이 터와 함께 (i) 상기 프레임 속도와 상기 각 주요 포인트들에 대한 상기 제1 위치 데이터 및 상기 제2 위치 데이 터 각각을 참조하여 상기 각 주요 포인트들의 위치가 변화하는 속도에 대한 제1 가속도 데이터 및 제2 가속도 데이터를 추출하고, (ii) 상기 프레임 속도와 상기 제1 각도 데이터 및 상기 제2 각도 데이터 각각을 참조하여 상기 관절들 사이의 상기 각도들의 변화량에 대한 제1 각속도 데이터 및 제2 각속도 데이터를 추출하는 것을 특 징으로 하는 분석 서버가 개시된다. 일례로서, 상기 (IV) 프로세스에서, 상기 프로세서는, 상기 복수의 동작 구간들 각각마다, (i) 상기 특정 제1 프레임 이미지들에 대응되는 상기 제1 가속도 데이터와 상기 제1 각속도 데이터를 추가적으로 상기 제1 포즈 데 이터로 이용하고, 상기 특정 제2 프레임 이미지들에 대응되는 상기 제2 가속도 데이터 및 상기 제2 각속도 데이 터를 추가적으로 상기 제2 포즈 데이터로 이용하여, 상기 제1 포즈 데이터와 상기 제2 포즈 데이터를 각각 상기 제1 시계열 데이터와 상기 제2 시계열 데이터로 변환하고, (ii) 상기 제1 시계열 데이터와 상기 제2 시계열 데 이터를 평가 RNN(Recurrent Neural Network) 모델에 입력하여, 상기 평가 RNN 모델로 하여금, (ii-1) 상기 제1 시계열 데이터와 상기 제2 시계열 데이터에 DTW(Dynamic Time Warping) 기법을 적용하여 상기 제1 시계열 데이 터와 상기 제2 시계열 데이터 간의 유사성을 측정함으로써 상기 제1 시계열 데이터와 상기 제2 시계열 데이터 상에서 서로 매칭되는 제1 포즈 패턴 데이터와 제2 포즈 패턴 데이터를 획득하며, (ii-2) 상기 제1 포즈 패턴 데이터의 상기 제1 위치 데이터와 상기 제1 각도 데이터 및 상기 제2 포즈 패턴 데이터의 상기 제2 위치 데이터와 상기 제2 각도 데이터 간의 일치 정도를 평가하여 자세 정확도를 산출하고, 상기 제1 포즈 패턴 데이터와 상 기 제2 포즈 패턴 데이터 간의 시간 차이를 분석하여 박자 정확도를 산출하며, 상기 제1 포즈 패턴 데이터의 상 기 제1 가속도 데이터와 상기 제1 각속도 데이터 및 상기 제2 포즈 패턴 데이터 상기 제2 가속도 데이터와 상기 제2 각속도 데이터 간의 일치 정도를 평가하여 힘 정확도를 산출함으로써 상기 일치 정확도를 계산하여 상기 예 측 평가 점수를 획득하도록 하는 것을 특징으로 하는 분석 서버가 개시된다. 일례로서, 상기 프로세서는, 상기 복수의 동작 구간들 각각마다, (i) 상기 자세 정확도, 상기 박자 정확도 및 상기 힘 정확도 중 적어도 일부에 가중치를 부여하는 제1 프로세스, (ii) 상기 학습자의 특정 신체 부위에 대해 생성된 특정 예측 평가 점수에 가중치를 부여하는 제2 프로세스, (iii) 상기 교습자의 추가 평가 점수를 반영하 는 제3 프로세스, 및 (iv) 상기 예측 평가 점수를 상기 학습자 또는 상기 교습자가 선택한 척도에 맞추어 변환 하는 제4 프로세스 중 적어도 하나를 수행하여 상기 예측 평가 점수를 추가로 조정하는 것을 특징으로 하는 분 석 서버가 개시된다. 일례로서, 상기 프로세서는, 상기 평가 RNN 네트워크가 생성한 상기 예측 평가 점수와 레퍼런스 평가 점수 간의 차이 값을 계산하고, 상기 차이 값의 분포를 분석하여 상기 예측 평가 점수와 상기 레퍼런스 평가 점수 간의 불 일치를 나타내는 이상점과 점수별 분포 관계를 파악하여 상기 평가 RNN 네트워크의 학습을 수행하는 것을 특징 으로 하는 분석 서버가 개시된다. 일례로서, 상기 (II) 프로세스에서, 상기 프로세서는, (i) 상기 주요 포인트들 중 특정 주요 포인트들에 대한 특정 제1 위치 데이터와 특정 제2 위치 데이터의 프레임 간 변화값을 획득하여, 기설정된 평균 변화값보다 큰 변화값을 가지는 복수의 지점들을 참조하여 후보 동작 구분 지점들로 선정하고, (ii) 상기 동기화된 제1 오디오 데이터 및 상기 동기화된 제2 오디오 데이터에 FFT(Fast Fourier Transform)를 적용하여 상기 마디 정보와 상기 박자 정보를 획득하며, (iii) 상기 후보 동작 구분 지점들과 상기 마디 정보 및 상기 박자 정보를 참조하여 상 기 후보 동작 구분 지점들 중 박자에 맞게 기설정된 임계 속도 이상의 동작 변화가 이루어진 특정 동작 구분 지 점들을 획득하고, (iv) 상기 특정 동작 구분 지점들을 기준으로 상기 제1 댄스 동영상과 상기 제2 댄스 동영상 을 서로 대응되는 복수의 상기 동작 구간들로 분할하는 것을 특징으로 하는 분석 서버가 개시된다. 일례로서, 상기 (II) 프로세스에서, 상기 프로세서는, 상기 제1 프레임 이미지들과 상기 제2 프레임 이미지들을 포즈 추정 CNN(Convolution Neural Network) 모델에 입력하여, 상기 포즈 추정 CNN 모델로 하여금, (i) 상기 제1 프레임 이미지들로부터 획득한 제1 바운딩 박스들과 상기 제2 프레임 이미지들로부터 획득한 제2 바운딩 박 스들에 CNN 연산을 적용하여 (i-1) 상기 주요 포인트들에 대한, 상기 제1 바운딩 박스들과 상기 제2 바운딩 박 스들 각각에 대응되는 제1 히트맵들과 제2 히트맵들을 획득하고, (i-2) 상기 주요 포인트들의 위치 및 방향에 대한 벡터 공간을 추정하는, 상기 제1 바운딩 박스들과 상기 제2 바운딩 박스들 각각에 대응되는 제1 포지션맵 들과 제2 포지션맵들을 획득하며, (ii) 상기 제1 바운딩 박스들에 대응되는 상기 제1 히트맵들과 상기 제1 포지 션맵들 및 상기 제2 바운딩 박스들에 대응되는 상기 제2 히트맵들과 상기 제2 포지션맵들에 포즈 추정 알고리즘 을 적용하여 상기 주요 포인트들 각각에 대한 위치 좌표 및 위치 좌표에 대한 제1 신뢰도 점수과 제2 신뢰도 점 수를 획득함으로써, 상기 주요 포인트들에 대한, 상기 제1 프레임 이미지들의 상기 제1 위치 데이터와 상기 제2 프레임 이미지들의 상기 제2 위치 데이터를 획득하도록 하는 것을 특징으로 하는 분석 서버가 개시된다. 일례로서, 상기 프로세서는, 상기 위치 데이터로서 상기 제1 프레임 이미지들에 대응되는 제1 위치 데이터와 상 기 제2 이미지 프레임 이미지들에 대응되는 제2 위치 데이터에 대해, (i) 서로 이웃하는 상기 제1 프레임 이미 지들간의 상기 제1 위치 데이터를 비교하고, 서로 이웃하는 상기 제2 프레임 이미지들간의 상기 제2 위치데이터 를 비교하여 상기 제1 위치 데이터와 상기 제2 위치 데이터 각각에 대해 기설정된 연속성 - 상기 기설정된 연속 성은 연속되는 프레임 간에서 상기 각 주요 포인트들의 상기 위치 데이터 각각에 대해 허용되는 변화값을 의미 함 - 을 초과하는 아웃라이어 위치 데이터를 제거하는 노이즈 제거 프로세스, (ii) 상기 제1 위치 데이터와 상 기 제2 위치 데이터를 정규화하는 인물 크기 정규화 프로세스, 및 (iii) 상기 제1 위치 데이터 각각을 참조로 하여 획득된 제1 중심점과 상기 제2 위치 데이터 각각을 참조로 하여 획득된 제2 중심점을 정렬하는 중심점 정 렬 프로세스 중 적어도 하나를 수행하여 상기 위치 데이터에 대한 전처리를 수행하는 것을 특징으로 하는 분석 서버가 개시된다. 일례로서, 상기 프로세서는, (i) 상기 노이즈 제거 프로세스로서 상기 제1 위치 데이터와 상기 제2 위치 데이터 각각에 선형 보간법을 적용하여 상기 아웃라이어 위치 데이터를 제거한 후, 상기 제1 위치 데이터와 상기 제2 위치 데이터 각각에 대해 상기 주요 포인트들의 주요 움직임 - 상기 주요 움직임은 기설정된 구간의 연속되는 프레임들 상의 상기 제1 위치 데이터와 상기 제2 위치 데이터의 최대값, 최소값에 대응되는 움직임임 - 에 대응되는 특정 위치 데이터 외의 나머지 위치 데이터를 간략화하는 프로세스를 수행하고, (ii) 상기 인물 크기 정규 화 프로세스로서 상기 교습자의 관절과 관절 간의 뼈 길이와 상기 학습자의 관절과 관절 간의 뼈 길의의 비율을 길이 비율로서 획득하여 상기 길이 비율을 참조로 상기 제1 위치 데이터를 수정하는 프로세스를 수행하며, (iii) 상기 중심점 정렬 프로세스로서 상기 상기 제1 위치 데이터 각각을 참조로 하여 획득된 상기 제1 중심점 을 상기 제2 위치 데이터 각각을 참조로 하여 획득된 상기 제2 중심점으로 이동시켜 정렬하는 프로세스를 수행 하는 것을 특징으로 하는 분석 서버가 개시된다. 일례로서, 상기 프로세서는, (i) 상기 프로세서가 상기 제1 프레임 이미지들과 상기 제2 프레임 이미지들을 획 득한 후 상기 제1 프레임 이미지들의 상기 제1 위치 데이터와 상기 제2 프레임 이미지들의 상기 제2 위치 데이 터가 획득되기까지 소요된 시간을 각각 측정하여 평균을 계산함으로써 동작인식 레이턴시(latency) 시간을 측정 하고, (ii) 상기 프로세서가 상기 제1 프레임 이미지들에 대해 획득한 상기 제1 위치 데이터 및 상기 제2 프레 임 이미지들에 대해 획득한 상기 제2 위치 데이터와 정답 위치 데이터를 비교하여 차이값을 계산함으로써 동작 인식 정확도를 측정하며, (ii) 상기 동작인식 레이턴시 시간과 상기 동작인식 정확도를 참조하여 상기 프로세서 의 동작인식 및 분석평가 기능의 정량적 평가를 수행하는 것을 특징으로 하는 분석 서버가 개시된다. 이 외에도, 본 발명의 방법을 실행하기 위한 컴퓨터 프로그램을 기록하기 위한 컴퓨터 판독 가능한 기록 매체가 더 제공된다."}
{"patent_id": "10-2023-0129726", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 본 발명은 영상 분석과 인공지능을 결합하여 영상 데이터에서 자동으로 인물을 식별하고 포즈를 분석 하여 실시간으로 학습자의 댄스 동작에 대한 평가와 피드백을 제공하는 효과가 있다. 또한, 본 발명은 영상 데이터로부터 추정한 포즈와 레퍼런스 영상 데이터의 포즈를 비교하여 자세, 타이밍, 힘 의 정확도 점수를 계산함으로써 개별 학생의 동작을 정확하게 분석하고 개인 맞춤형 평가와 지도가 가능하도록 하는 효과가 있다. 또한, 본 발명은 영상 데이터로부터 획득한 프레임 이미지와 오디오 데이터를 함께 분석함으로써 영상 데이터를 평가가 필요한 동작이 포함된 복수의 동작 구간들로 분할하여 평가를 수행함으로써 보다 효율적이고 정확한 평 가가 가능하도록 하는 효과가 있다. 또한, 본 발명은 자세, 박자, 힘 등의 다양하고 객관적인 평가요소를 결합하여 종합적인 평가점수를 생산하고 구체적이고 전문적인 피드백 제공 가능하도록 하는 효과가 있다. 또한, 본 발명은 영상 데이터로부터 획득한 포즈 데이터에 대한 시계열 데이터에 대해 데이터 패턴 매칭 알고리 즘을 적용하여 포즈 데이터의 시간적 패턴을 비교함으로써 분석의 정확도를 향상시키는 효과가 있다. 또한, 본 발명은 학습자가 선택한 평가 척도에 맞게 점수를 변환하여 제공함으로써 개인화된 평가 결과 제공을 통해 학습자가 댄스 동작의 품질을 자신의 기준에 맞추어 이해하고 개선 가능하도록 하는 효과가 있다."}
{"patent_id": "10-2023-0129726", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명의 목적들, 기술적 해법들 및 장점들을 분명하게 하기 위하여 본 발명이 실시될 수 있는 특정 실시예를 예시로서 도시하는 첨부 도면을 참조한다. 이들 실시예는 통상의 기 술자가 본 발명을 실시할 수 있기에 충분하도록 상세히 설명된다. 또한, 본 발명의 상세한 설명 및 청구항들에 걸쳐, \"포함하다\"라는 단어 및 그것의 변형은 다른 기술적 특징들, 부가물들, 구성요소들 또는 단계들을 제외하는 것으로 의도된 것이 아니다. 통상의 기술자에게 본 발명의 다른 목적들, 장점들 및 특성들이 일부는 본 설명서로부터, 그리고 일부는 본 발명의 실시로부터 드러날 것이다. 아 래의 예시 및 도면은 실례로서 제공되며, 본 발명을 한정하는 것으로 의도된 것이 아니다. 더욱이 본 발명은 본 명세서에 표시된 실시예들의 모든 가능한 조합들을 망라한다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있는 특정 형상, 구조 및 특성은 일 실시예에 관련하여 본 발명의 정신 및 범위를 벗어나지 않으면서 다른 실시예로 구현될 수 있다. 또한, 각각의 개시된 실시예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 정신 및 범위를 벗어나 지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미로서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모든 범위와 더불 어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하거나 유사한 기능을 지칭한다."}
{"patent_id": "10-2023-0129726", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이하, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실시할 수 있도록 하기 위 하여, 본 발명의 바람직한 실시예들에 관하여 첨부된 도면을 참조하여 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따라 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 분석 서버를 개 략적으로 도시한 것이다. 도 1을 참조하면, 분석 서버는 인공지능에 기반하여 학습자의 댄스 동작을 평가하기 위한 인스트럭션들을 저장하는 메모리와 메모리에 저장된 인스트럭션들에 대응하여 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 프로세서를 포함할 수 있다. 구체적으로, 분석 서버는 전형적으로 컴퓨팅 장치(예컨대, 컴퓨터 프로세서, 메모리, 스토리지, 입력 장 치 및 출력 장치, 기타 기존의 컴퓨팅 장치의 구성요소들을 포함할 수 있는 장치; 라우터, 스위치 등과 같은 전 자 통신 장치; 네트워크 부착 스토리지(NAS) 및 스토리지 영역 네트워크(SAN)와 같은 전자 정보 스토리지 시스 템)와 컴퓨터 소프트웨어(즉, 컴퓨팅 장치로 하여금 특정의 방식으로 기능하게 하는 인스트럭션들)의 조합을 이용하여 원하는 시스템 성능을 달성하는 것일 수 있다. 또한, 컴퓨팅 장치의 프로세서는 MPU(Micro Processing Unit) 또는 CPU(Central Processing Unit), 캐쉬 메모 리(Cache Memory), 데이터 버스(Data Bus) 등의 하드웨어 구성을 포함할 수 있다. 또한, 컴퓨팅 장치는 운영체 제, 특정 목적을 수행하는 애플리케이션의 소프트웨어 구성을 더 포함할 수도 있다. 그러나, 컴퓨팅 장치가 본 발명을 실시하기 위한 미디엄, 프로세서 및 메모리가 통합된 형태인 integrated 프로 세서를 포함하는 경우를 배제하는 것은 아니다. 한편, 분석 서버는 댄스 동영상 상에서의 인물의 각 댄스 동작에 대한 자세를 추정하기 위한 포즈 추정 CNN(Convolution Neural Network) 모델과 인물의 댄스 동작에 대한 자세의 정확도를 평가하기 위한 평가 RNN(Recurrent Neural Network) 모델을 포함하거나 이들 모델과 통신할 수 있도록 연동된 상태일 수 있다. 이와 같이 구성된 분석 서버를 이용하여 본 발명의 일 실시예에 따른 인공지능에 기반하여 학습자의 댄스 동작을 평가하기 위한 방법을 도 2 내지 도 13을 참조하여 설명하면 다음과 같다. 먼저, 도 2는 본 발명의 일 실시예에 따라 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 과정을 개략적 으로 도시한 것이다. 도 2를 참조하면, 우선, 분석 서버는, 학습자의 댄스 동작을 촬영한 제1 댄스 동영상과 학습자의 댄스 동 작의 비교 기준을 제공하는 교습자의 댄스 동작을 촬영한 제2 댄스 동영상이 획득되면, 제1 댄스 동영상으로부 터 복수의 제1 프레임 이미지들을 추출하고 제2 댄스 동영상으로부터 복수의 제2 프레임 이미지들을 추출하며, 제1 댄스 동영상으로부터 제1 오디오 데이터를 획득하고 제2 댄스 동영상으로부터 제2 오디오 데이터를 획득할 수 있다. 여기서, 학습자는 댄스 동영상만을 촬영하여 서버로 업로드하거나, 비교적 가벼운 연산을 요구하는 자세 추출 과정을 거쳐 해당 데이터를 분석 서버로 업로드하여 분석 서버로 하여금 데이터 분석 등 의 과정을 수행하도록 할 수 있을 것이나, 본 발명이 이에 한정되지는 않는다. 또한, 분석 서버는 학습 자의 댄스 동영상을 분석하기에 앞서 교습자의 댄스 동영상에 대한 자세 추정 및 데이터 분석을 이미 수행하여 데이터베이스에 저장한 상태일 수 있을 것이나, 본 발명이 이에 한정되지는 않는다. 덧붙여, 학습자와 교습자 는 각각 복수의 인물을 지칭할 수 있으나 설명의 편의를 위해 상설에서는 단수로 표현하였으며, 본 발명의 댄스 동작 평가 방법이 복수의 학습자와 복수의 교습자를 대상으로 수행될 수 있음은 당연한 사실이다. 그런 다음, 분석 서버는 제1 프레임 이미지들과 제2 프레임 이미지들 각각으로부터 학습자의 신체 부위와 교습자의 신체 부위를 각각 식별하여, 제1 프레임 이미지들 상에서 식별된 학습자의 신체 부위를 복수의 관절 단위들로 나누어, 관절 단위들마다 복수의 주요 포인트들에 대한 제1 위치 데이터를 획득하고, 제2 프레임 이미 지들 상에서 식별된 교습자의 신체 부위 각각을 복수의 관절 단위들로 나누어, 관절 단위들마다 복수의 주요 포 인트들에 대한 제2 위치 데이터를 획득할 수 있다. 여기서, 주요 포인트들은 학습자 또는 교습자의 손, 발, 어 깨, 팔꿈치, 무릎, 고관절, 무게중심점, 눈, 코, 입 중 적어도 일부를 포함할 수 있다. 이때, 분석 서버(100 0)는 포즈 추정 CNN(Convolution Neural Network) 모델을 사용하여 제1 프레임 이미지들과 제2 프레임 이 미지들 각각에 대한 학습자와 교습자의 신체 부위 각각에 대한 위치 데이터를 획득할 수 있을 것이며, 이에 대 한 구체적인 설명은 도 3 내지 도 6을 참조하여 후술하기로 한다. 위치 데이터를 획득하는 한편, 분석 서버는 제1 오디오 데이터의 제1 시작 지점과 제2 오디오 데이터의 제2 시작 지점을 동기화하여 동기화된 제1 오디오 데이터 및 동기화된 제2 오디오 데이터를 획득하고, 동기화된 제1 오디오 데이터 및 동기화된 제2 오디오 데이터로부터 획득한 마디 정보와 박자 정보 및 제1 위치 데이터와 제2 위치 데이터를 참조하여 제1 댄스 동영상과 제2 댄스 동영상을 서로 대응되는 복수의 동작 구간들로 분할할 수 있다. 여기서, 분석 서버는 제1 시작 시점과 제2 시작 시점 뿐만 아니라 제1 오디오 데이터의 제1 끝 시점과 제2 오디오 데이터의 제2 끝 지점 또한 동기화할 수 있을 것이나, 본 발명이 이에 한정되지는 않는다. 제1 댄스 동영상과 제2 댄스 동영상을 서로 대응되는 복수의 동작 구간들로 분할하는 방법은 도 7 및 도 8을 참 조하여 보다 상세하게 후술하기로 한다. 다음으로, 분석 서버는 복수의 동작 구간들 각각마다, 동작 구간들 각각에 속하는 특정 제1 프레임 이미 지들과 특정 제2 프레임 이미지들 각각에 대해, 학습자의 신체 부위 상의 이웃하는 관절에 대응되는 제1 특정 위치 데이터의 공간 좌표 정보를 참조하여 학습자의 신체 부위 상의 이웃하는 관절들 사이의 각도들에 대한 제1 각도 데이터를 획득하고, 교습자의 신체 부위 상의 이웃하는 관절에 대응되는 제2 특정 위치 데이터의 공간 좌 표 정보를 참조하여 교습자의 신체 부위 상의 이웃하는 관절들 사이의 각도들에 대한 제2 각도 데이터를 획득할 수 있다. 여기서, 분석 서버는 각도 데이터와 함께 각 주요 포인트들의 가속도 데이터 및 관절의 각속도데이터도 함께 획득할 수 있으며, 이에 대한 구체적인 설명은 도 9 및 도 10을 참조하여 후술하기로 한다. 이어서, 분석 서버는 특정 제1 프레임 이미지들에 대응되는 제1 위치 데이터와 제1 각도 데이터를 제1 포 즈 데이터로 이용하고, 특정 제2 프레임 이미지들에 대응되는 제2 위치 데이터와 제2 각도 데이터를 제2 포즈 데이터로 이용하여, 제1 포즈 데이터와 제2 포즈 데이터를 각각 제1 시계열 데이터와 제2 시계열 데이터로 변환 하고, 제1 시계열 데이터와 제2 시계열 데이터를 서로 비교하여 학습자의 댄스 동작과 교습자의 댄스 동작에 대 한 일치 정확도를 계산함으로써 학습자의 댄스 동작에 대한 예측 평가 점수를 획득할 수 있다. 여기서, 분석 서버는 앞서 설명한 바와 같이 위치 데이터와 각도 데이터 뿐만 아니라 가속도 데이터와 각속도 데이터 또한 포즈 데이터로서 추가로 활용하여 시계열 데이터로의 변환 및 예측 평가 점수 산출을 수행할 수 있다. 이 때, 분석 서버는 제1 시계열 데이터와 제2 시계열 데이터를 평가 RNN(Recurrent Neural Network) 모델 에 입력하여 예측 평가 점수를 산출할 수 있을 것이며, 예측 평가 점수를 산출하는 구체적인 방법은 도 11 및 도 12를 참조하여 후술하기로 한다. 위와 같은 바, 아래에서는 도 3 내지 도 13을 참조로 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 방법 에 대해 보다 구체적으로 설명하기로 한다. 우선, 도 3은 본 발명의 일 실시예에 따라 댄스 동영상에서 학습자와 교습자의 자세를 추정하는 방법을 개략적 으로 도시한 것이다. 도 3에 따르면, 분석 서버는, 제1 프레임 이미지들과 제2 프레임 이미지들을 포즈 추정 CNN 모델에 입력하여, 포즈 추정 CNN 모델로 하여금, 제1 프레임 이미지들로부터 획득한 제1 바운딩 박스들과 제2 프 레임 이미지들로부터 획득한 제2 바운딩 박스들에 CNN 연산을 적용하여 주요 포인트들에 대한, 제1 바운딩 박스 들과 제2 바운딩 박스들 각각에 대응되는 제1 히트맵들과 제2 히트맵들을 획득하고, 주요 포인트들의 위치 및 방향에 대한 벡터 공간을 추정하는, 제1 바운딩 박스들과 제2 바운딩 박스들 각각에 대응되는 제1 포지션맵들과 제2 포지션맵들을 획득하도록 할 수 있다. 여기서, 제1 바운딩 박스들과 제2 바운딩 박스들을 통해 포즈 추정 CNN 모델은 각각 학습자와 교습자의 전체 신체 또는 신체 부위에 집중한 미니멈 바운딩 박스(minimum bounding box)를 추출하여 신체 상에 위치한 주요 포인트들을 효율적으로 추출할 수 있다. 이어서, 포즈 추정 CNN 모델은 제1 바운딩 박스들에 대응되는 제1 히트맵들과 제1 포지션맵들 및 제2 바운 딩 박스들에 대응되는 제2 히트맵들과 제2 포지션맵들에 포즈 추정 알고리즘을 적용하여 주요 포인트들 각각에 대한 위치 좌표 및 위치 좌표에 대한 제1 신뢰도 점수과 제2 신뢰도 점수를 획득함으로써, 주요 포인트들에 대 한, 제1 프레임 이미지들의 제1 위치 데이터와 제2 프레임 이미지들의 제2 위치 데이터를 획득할 수 있다. 여 기서, 히트맵들과 포즈맵들에 적용되는 포즈 추정 알고리즘으로서 통상의 인공지능 기반 자세 추정 라이브러리 들에 공개된 OpenPose나 MediaPipe 라이브러리 등이 사용될 수 있을 것이나, 본 발명이 이에 한정되지는 않는다. 이에 따라, 도 4는 본 발명의 일 실시예에 따라 포즈 추정 CNN 모델을 통해 획득된 댄스 동영상의 프레임 이미 지 상에서의 주요 포인트들의 예시를 개략적으로 도시하고 있다. 도 4에 따르면 포즈 추정 과정에서 학습자 또는 교습자에 대응되는 사용자의 손, 발, 팔꿈치, 무릎, 어깨, 눈, 코, 입 등의 신체 부위를 주요 포인트들로 이용하는 것을 볼 수 있다. 또한, 도 4와 같이 분석 서버는 주요 관절의 위치를 선으로 이어 사용자의 이미지 위에 겹쳐 표시함으로써 포즈 추정이 올바르게 진행되고 있는 지 확인하여 테스트를 진행할 수도 있을 것이다. 참고로, 이러한 포즈 추정은 사용자의 환경을 상정하여 PC 애플리케이션, 안드로이드 모바일 애플리케이션, 유 니티 애플리케이션 등 여러 플랫폼에서 수행할 수 있을 것이다. 다만, 어플리케이션의 구현 환경, 연산량 등의 물리적인 제한에 따라 포즈 추정에 대한 연산은 어플리케이션 내에서 진행하지 않고 별도의 분석 서버 내 지 제3의 연산 서버를 구현하여 해당 서버에서 연산을 수행하고 어플리케이션과 데이터를 주고받는 형식으로 구 현될 수도 있을 것이다. 한편, 위와 같이 획득된 제1 위치 데이터와 제2 위치 데이터는 노이즈나 오류 등이 발생하기도 하며, 실제 주요 포인트의 위치와 일치하지 않는 정확도가 떨어지는 데이터일 수 있다. 따라서, 이와 같이 포즈 추정 CNN 모델 을 통해 획득된 위치 데이터는 신뢰도 점수(confidence score)를 함께 산출하여 획득된 위치 데이터의 정 확도를 평가할 필요가 있다. 이에 따라, 본 발명의 일 실시예에 따라 댄스 동영상으로부터 학습자와 교습자의 신체 부위의 주요 포인트들에 대한 위치 데이터를 획득하는 과정을 개략적으로 도시한 도 5와 같이, 최종적으로, 분석 서버의 데이터베이스 또는 사용자 어플리케이션의 데이터베이스에는 각 주요 포인트들에 대한 2차원 혹은 3차원의 위치 벡터와 이에 대한 신뢰도 점수를 함께 가지고 있는 일련의 행렬을 위치 데이터로 저장할 수 있을 것이다. 이에 따라, 상대적으로 신뢰도 점수가 낮은 주요 포인트들에 대해서는 추가적인 위치 데이터 교정 프로세스를 수행하거나 후에 해당 주요 포인트들의 위치 데이터를 참고하여 획득된 학습자 내지 교습자의 예측 평가 점수는 제거하거나 낮은 가중치를 적용하여 최종 예측 평가 점수를 생성하는 프로세스 등을 수행할 수 있을 것이나, 본 발명이 이 에 한정되지는 않는다. 참고로, 포즈 벡터 행렬 형식의 위치 데이터를 다른 인터페이스에서 사용하기 위한 호환성을 높이기 위해 BVH 포맷에 맞게 변환할 수도 있을 것이며, 여기서 BVH 포맷은 각 주요 포인트가 가지는 위치 및 회전 값을 Bone 계 층 정보와 모션 데이터로 저장할 수 있다. BVH 포맷은 다양한 개발 환경에서 널리 사용되는 포맷이며, 대부분 의 3D 작업 소프트웨어에서 임포트가 가능하므로 향후 연구의 확장에 용이할 수 있다. 또한, 위와 같이 획득한 제1 위치 데이터와 제2 위치 데이터에 노이즈와 오류가 포함되어 있거나 학습자와 교습 자 간의 신장 및 관절 간 길이 등의 차이로 인해 바로 평가가 어려운 경우, 아래와 같이 제1 위치 데이터 및 제 2 위치 데이터에 대한 전처리를 수행할 수 있다. 우선, 본 발명에 따르면, 분석 서버는, 위치 데이터로서 제1 프레임 이미지들에 대응되는 제1 위치 데이 터와 제2 이미지 프레임 이미지들에 대응되는 제2 위치 데이터에 대해, 서로 이웃하는 제1 프레임 이미지들간의 제1 위치 데이터를 비교하고, 서로 이웃하는 제2 프레임 이미지들간의 제2 위치데이터를 비교하여 제1 위치 데 이터와 제2 위치 데이터 각각에 대해 기설정된 연속성을 초과하는 아웃라이어 위치 데이터를 제거하는 노이즈 제거 프로세스를 수행할 수 있다. 여기서, 기설정된 연속성은 연속되는 프레임 간에서 각 주요 포인트들의 위 치 데이터 각각에 대해 허용되는 변화값을 의미한다. 이때, 분석 서버는 노이즈 제거 프로세스로서 제1 위치 데이터와 제2 위치 데이터 각각에 선형 보간법을 적용하여 아웃라이어 위치 데이터를 제거한 후, 제1 위치 데이터와 제2 위치 데이터 각각에 대해 주요 포인트들 의 주요 움직임에 대응되는 특정 위치 데이터 외의 나머지 위치 데이터를 간략화하는 프로세스를 수행할 수 있 다. 여기서, 주요 움직임은 기설정된 구간의 연속되는 프레임들 상의 제1 위치 데이터와 제2 위치 데이터의 최 대값, 최소값에 대응되는 움직임이다. 구체적으로, 분석 서버는 보간을 위한 최적의 피팅곡선을 찾기 위해 NumPy의 Ployfit 함수를 사용하여 피 팅 알고리즘을 적용하여 현재 관절의 움직임에 가장 적합함 n차 다항식의 계수를 구하고, 해당 계수를 모델로 변환하기 위해 poly1d로 다항식을 계산하여 노이즈가 제거된 데이터를 획득할 수 있다. 또한, 이같이 노이즈를 제거하더라도 위치 데이터는 미세한 떨림을 가지고 있고, 이러한 미세한 움직임을 평가에 모두 고려할 필요가 있는 경우는 많지 않다. 따라서, 위에서 설명한 바와 같이 주요 포인트들의 최대, 최소 및 일정 변위 이하의 움직임 등에 대응되는 주요 움직임을 제외한 미세 움직임 데이터는 간략화하여 연산량을 줄일 수 있다. 덧붙여, 분석 서버는 위와 같은 노이즈 제거 프로세스 외에도 제1 위치 데이터와 제2 위치 데이터를 정규 화하는 인물 크기 정규화 프로세스, 및 제1 위치 데이터 각각을 참조로 하여 획득된 제1 중심점과 제2 위치 데 이터 각각을 참조로 하여 획득된 제2 중심점을 정렬하는 중심점 정렬 프로세스를 수행하여 위치 데이터에 대한 전처리를 수행할 수 있다. 즉, 분석 서버는 노이즈 제거 프로세스, 인물 크기 정규화 프로세스 및 중심 점 정렬 프로세스 중 적어도 하나를 수행하여 앞서 획득한 제1 위치 데이터 및 제2 위치 데이터에 대한 전처리 를 수행할 수 있다. 이때, 분석 서버는 본 발명의 일 실시예에 따라 위치 데이터를 정규화하는 방법을 개략적으로 도시한 도 6과 같이 인물 크기 정규화 프로세스로서 교습자의 관절과 관절 간의 뼈 길이와 학습자의 관절과 관절 간의 뼈 길의의 비율을 길이 비율로서 획득하여 길이 비율을 참조로 제1 위치 데이터를 수정하는 프로세스를 수행할 수 있다. 즉, 도 6과 같이 교습자(A)와 학습자(B) 간의 신장 차이에서 비롯된 주요 포인트 간의 신체 길이 차이가 있는 경우, 교습자와 학습자 간의 길이 비율을 참조하여 학습자(B)의 신체 길이가 교습자(A)의 신체 길이와 유 사해지도록 조정하는 위치 데이터에 대한 전처리를 수행할 수 있다. 이와 함께, 분석 서버는 중심점 정렬 프로세스로서 제1 위치 데이터 각각을 참조로 하여 획득된 제1 중심 점을 제2 위치 데이터 각각을 참조로 하여 획득된 제2 중심점으로 이동시켜 정렬하는 프로세스를 수행할 수 있 다. 이같은 전처리 프로세스들 외에도, 분석 서버는 사용한 포즈 추정 알고리즘에 따라 획득한 위치 데이터의 포맷 차이로 인해 주요 포인트의 위치 및 개수가 상이한 경우, 각기 다른 위치 데이터를 하나로 통일하여 비교가 용이하도록 하는 다양한 retargeting 기술을 수행할 수 있을 것이다. 위와 같이 설명한 바에 따라 위치 데이터를 획득하고 위치 데이터에 대한 전처리를 수행하는 한편, 분석 서버 는 학습자의 제1 댄스 동영상에 대응되는 제1 오디오 데이터 및 교습자의 제2 댄스 동영상에 대응되는 제 2 오디오 데이터에 대한 동기화를 수행하여 이로부터 획득한 마디 정보 및 박자 정보와 함께 위치 데이터를 참 조로 하여 동기화된 제1 댄스 동영상과 제2 댄스 동영상을 복수의 동작 구간들로 분할하여 각 동작 구간들을 구 분하여 댄스 동작들을 평가함으로써 평가에 대한 정확성과 효율을 높일 수 있다. 이와 같은 동작 구간 분할 과 정은 도 7과 도 8을 참조로 아래와 같이 설명할 수 있다. 우선 도 7에 따르면, 분석 서버는 획득된 제1 오디오 데이터와 제2 오디오 데이터에 대해 노이즈 제거 및 동기화를 수행하여 동기화된 제1 오디오 데이터 및 동기화된 제2 오디오 데이터를 획득할 수 있다. 여기서, 학 습자의 제1 댄스 동영상이나 교습자의 제2 댄스 동영상은 상이한 길이를 가지거나 서로 다른 댄스 시작 타이밍 을 가질 수 있으므로, 댄스 동영상 간의 동기화가 필요한 것이다. 그러나, 학습자마다 댄스 동작을 틀리거나 잊는 경우가 발생하는 경우가 있으므로, 단순히 댄스 동작만을 단서로 댄스 동영상 간의 동기화를 수행하기에는 무리가 있다. 따라서, 댄스 동영상에서 평가가 필요한 구간들에 대한 분할 및 추출을 수행하기 위해서는 댄스 동영상 간의 일관되고 공통적인 특징이 필요한 바, 댄스 연습곡은 모든 학습자와 교습자의 영상에 함께 녹음되 게 되므로 댄스 평가 구간의 시작 지점과 끝 지점을 정하는 단서로서 활용할 수 있다. 위와 같은 이유로 오디오 데이터 간의 동기화가 필요한 한편, 학습자와 교습자의 댄스 동영상 녹화 환경은 모두 제각기 다르고, 음질과 음량이 고르지 못한 경우가 통상적이다. 따라서, 댄스 동영상으로부터 획득한 오디오 데이터에 대해서도 노이즈 제거 등의 전처리를 수행하여 보다 정확한 동기화가 가능하도록 할 수 있다. 이를 위한 일 실시예로, 분석 서버는 Python의 Pydub 모듈 등을 활용하여 댄스 동영상으로부터 추출한 배 경음악이 포함된 로우(raw) 오디오 데이터에 Python의 디지털 신호처리를 위한 SciPy 모듈을 사용하여 Butterworth filter를 구현할 수 있다. 아래의 식은 Butterworth filter의 일반식을 보여주고 있다."}
{"patent_id": "10-2023-0129726", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "분석 서버는 Butterworth filter를 사용하여 오디오의 고주파 대역을 제거하여 잡음을 제거할 수 있으며, 추가로 최대 음량이 각기 다른 raw 오디오 데이터를 일정한 음량으로 통일하기 위해 기준 데이터인 교습자의 제 2 오디오 데이터에 대해 측정된 dBFS(db Full Scale)에 학습자의 제1 오디오 데이터의 dbFS를 일치시켜 서로 동 일한 음량을 확보할 수 있다. 위와 같이 제1 오디오 데이터 및 제2 오디오 데이터에 대한 전처리를 수행한 후, 분석 서버는 제1 오디오 데이터와 제2 오디오 데이터의 비교를 통해 일치하는 구간을 판별하여 제1 오디오 데이터의 제1 시작 시점과 제 2 오디오 데이터의 제2 시작 시점을 매칭하여 제1 오디오 데이터와 제2 오디오 데이터를 동기화할 수 있다. 여 기서, 분석 서버는 제1 시작 시점과 제2 시작 시점을 매칭하는 것 뿐만 아니라 제1 오디오 데이터의 제1 끝 지점과 제2 오디오 데이터의 제2 끝 지점도 매칭하여 동기화를 수행할 수도 있을 것이다. 이에 더하여, 분석 서버는 도 7과 같이 곡 전체 길이에 대한 댄스 동영상과 오디오 데이터를 더 작은 단 위로 구분하기 위한 작업의 일환으로 동기화된 제1 오디오 데이터 및 동기화된 제2 오디오 데이터에 FFT(Fast Fourier Transform)를 적용하여 마디 정보와 박자 정보를 획득할 수 있다. 동시에, 분석 서버는 주요 포 인트들 중 특정 주요 포인트들에 대한 특정 제1 위치 데이터와 특정 제2 위치 데이터의 프레임 간 변화값을 획 득하여, 기설정된 평균 변화값보다 큰 변화값을 가지는 복수의 지점들을 참조하여 후보 동작 구분 지점들로 선 정할 수 있다. 여기서, 특정 주요 포인트들은 도 7과 같이 학습자 내지 교습자의 손, 발, 무게 중심점 등이 될 수 있으며, 이들 위치 좌표로서 획득된 위치 데이터를 이용하여 위치 데이터의 변화값을 계산할 수 있다. 이어서, 분석 서버는 후보 동작 구분 지점들과 마디 정보 및 박자 정보를 참조하여 후보 동작 구분 지점 들 중 박자에 맞게 기설정된 임계 속도 이상의 동작 변화가 이루어진 특정 동작 구분 지점들을 획득하여, 특정 동작 구분 지점들을 기준으로 제1 댄스 동영상과 제2 댄스 동영상을 서로 대응되는 복수의 동작 구간들로 분할 할 수 있다. 이에 따라, 분석 서버는 분할된 복수의 동작 구간들 각각을 하나의 댄스 동작 액션으로 상정하여 각 구간 끼리 제1 댄스 동영상의 제1 프레임 이미지들과 제2 댄스 동영상의 제2 프레임 이미지들간을 매칭하여 평가를 수행할 수 있다. 이와 같이 본 발명의 일 실시예에 따라 댄스 동영상을 복수의 동작 구간들로 분할하여 각 동작 구간들에 대한 평가를 수행하는 과정은 도 8에 개략적으로 개시되어 있다. 도 8에 따르면, 원본 댄스 동영상으로서 제1 댄스 동영상(t)와 제2 댄스 동영상(r)이 획득되면, 분석 서버 는 이들에 대한 포즈 추정을 통해 제1 위치 데이터와 제2 위치 데이터를 획득하고, 오디오 동기화를 통해 동기화된 제1 오디오 데이터와 동기화된 제2 위치 데이터를 획득할 수 있다. 이후, 위치 데이터와 오디오 데이 터로부터 획득된 마디 정보 및 박자 정보를 참조로 동기화된 댄스 동영상들로부터 복수의 동작 구간들을 분할할 수 있다. 그런 다음, 분석 서버는 제1 댄스 동영상에 대응되는 복수의 동작 구간(t0, t1, t2, ..., tn) 및 제2 댄스 동영상에 대응되는 복수의 동작 구간(r0, r1, r2, ..., rn)을 각각 비교함으로써 댄스 동작에 대한 평가를 수행하여 각 동작 구간에 대해 예측 평가 점수(e0, e1, e2, ..., en)를 획득하고, 이들 예측 평가 점수를 종합하여 최종 점수(e)를 획득할 수 있다. 한편, 본 발명에 따르면, 프레임 이미지 상의 학습자 내지 교습자에 대한 주요 포인트들에 대한 위치 데이터를 이용하여 보다 정확한 평가를 수행하기 위해 위치 데이터 뿐만 아니라, 학습자 내지 교습자 각각의 이웃하는 각 관절 간의 위치, 즉, 위치 좌표를 기준으로 관절들 사이의 각도를 도출한 각도 데이터를 댄스 동작을 평가하기 위한 포즈 데이터로서 생성할 수 있다. 일 예로서, 도 9는 본 발명의 일 실시예에 따라 댄스 동영상의 프레임 이미지로부터 신체 부위 상의 이웃하는 관절들의 특정 위치 데이터를 참조하여 획득한 관절들의 각도들에 대한 각도 데이터의 예시를 개략적으로 도시 하고 있다. 도 9의 예시에서 볼 수 있듯이 분석 서버는 각 프레임 이미지에서 관절들 사이의 각도를 도 출할 수 있으며, 여기서 관절의 각도는 연산량 감소를 위해 3차원에 대한 각도를 단일 각도로 차원을 줄이고, 팔꿈치, 어깨, 고관절, 무릎 등 주요 관절을 선정하여 데이터의 수를 줄여 정리할 수 있을 것이나, 본 발명이 이에 한정되지는 않는다. 추가로, 분석 서버는 복수의 동작 구간들 각각마다, 이웃하는 프레임 이미지 간의 시간 차이를 참조로 하 여 프레임 속도를 획득하여, 동작 구간들 각각에 속하는 특정 제1 프레임 이미지들과 특정 제2 프레임 이미지들 각각에 대해, 제1 각도 데이터 및 제2 각도 데이터와 함께 프레임 속도와 각 주요 포인트들에 대한 제1 위치 데 이터 및 제2 위치 데이터 각각을 참조하여 각 주요 포인트들의 위치가 변화하는 속도에 대한 제1 가속도 데이터 및 제2 가속도 데이터를 추출하고, 프레임 속도와 제1 각도 데이터 및 제2 각도 데이터 각각을 참조하여 관절들 사이의 각도들의 변화량에 대한 제1 각속도 데이터 및 제2 각속도 데이터를 추출할 수 있다. 즉, 분석 서버 는 연속된 프레임 이미지에 대한 위치 데이터는 프레임 속도를 통해 프레임 이미지 사이의 시간 차이를 알 수 있고, 이를 통해 각 주요 포인트의 위치가 변화하는 속력과 방향을 도출할 수 있고, 유사한 원리로 각 관 절 각도의 변화량을 토대로 각속도를 도출할 수 있다. 참고로, 분석 서버는 위에서 위치 데이터에 대해 수행한 노이즈 제거 프로세스 등의 전처리를 각도 데이터, 가속도 데이터 및 각속도 데이터에 대해서도 수행할 수 있을 것이다. 위와 같은 바, 도 10은 본 발명의 일 실시예에 따라 관절 위치와 프레임 속도로부터 파생될 수 있는 정보들을 개략적으로 도시하고 있다. 도 10에 따르면, 주요 포인트들 중 관절 위치를 파악하여 프레임 간 변화하는 관절 위치의 궤적을 파악하여 히 트맵이나 방향벡터를 생성할 수 있고, 프레임 속도와 관절 위치 변화를 토대로 각 관절의 위치가 변하는 속력을 파악할 수 있을 뿐만 아니라, 위치상 이웃하는 관절들에 대응되는 위치 데이터들의 상대적인 위치를 파악하면 각 주요 관절의 각도에 대한 각도 데이터를 획득할 수 있으며, 이러한 각도 데이터와 프레임 속도를 이용하면 각 관절의 각도가 변하는 속도에 대한 각속도 데이터 또한 획득할 수 있다. 참고로, 본 발명의 도 2에서는 위치 데이터와 프레임 속도로부터 파생되는 각도 데이터, 가속도 데이터 및 각속 도 데이터는 댄스 동영상을 복수의 동작 구간들로 분할한 후에 복수의 동작 구간들 각각에 속하는 특정 제1 프 레임 이미지들에 대응되는 특정 제1 위치 데이터와 특정 제2 프레임 이미지들에 대응되는 특정 제2 위치 데이터 를 이용하여 획득하였으나, 본 발명은 이에 한정되지 않고 댄스 동영상을 복수의 동작 구간들로 분할하기에 앞 서 위치 데이터 뿐만 아니라 획득한 위치 데이터 및 프레임 속도를 이용하여 각도 데이터, 가속도 데이터 및 각 속도 데이터를 먼저 일괄적으로 구할 수도 있을 것이다. 위와 같이 학습자 내지 교습자 신체 상의 주요 포인트들에 대한 위치 데이터와 함께 위치 데이터 및 프레임 속 도로부터 파생된 각도 데이터, 가속도 데이터 및 각속도 데이터를 획득한 후, 분석 서버는 위치 데이터, 각도 데이터, 가속도 데이터 및 각속도 데이터 중 적어도 일부를 시계열 데이터로 변환하여 학습자의 댄스 동작 과 교습자의 댄스 동작에 대한 일치 정확도를 계산함으로써 학습자의 댄스 동작에 대한 예측 평가 점수를 획득할 수 있다. 구체적으로, 분석 서버는 복수의 동작 구간들 각각마다, 제1 위치 데이터 및 제1 각도 데이터와 함께 특 정 제1 프레임 이미지들에 대응되는 제1 가속도 데이터와 제1 각속도 데이터를 추가적으로 제1 포즈 데이터로 이용하고, 제2 위치 데이터 및 제2 각도 데이터와 함께 특정 제2 프레임 이미지들에 대응되는 제2 가속도 데이 터 및 제2 각속도 데이터를 추가적으로 제2 포즈 데이터로 이용하여, 제1 포즈 데이터와 제2 포즈 데이터를 각 각 제1 시계열 데이터와 제2 시계열 데이터로 변환할 수 있다. 이어서, 분석 서버는 제1 시계열 데이터와 제2 시계열 데이터를 평가 RNN(Recurrent Neural Network) 모 델에 입력하여, 평가 RNN 모델로 하여금, 제1 시계열 데이터와 제2 시계열 데이터에 DTW(Dynamic Time Warping) 기법을 적용하여 제1 시계열 데이터와 제2 시계열 데이터 간의 유사성을 측정함으로써 제1 시계 열 데이터와 제2 시계열 데이터 상에서 서로 매칭되는 제1 포즈 패턴 데이터와 제2 포즈 패턴 데이터를 획득할 수 있다. 이때, DTW 알고리즘은 곡 전체에 대응되는 댄스 동영상 전체에 대한 시계열 데이터에 적용하는 대신, 분할된 복수의 동작 구간마다 각각 적용될 수 있으며, 각 동작 구간별로 일정 유사성 측정시 시계열 데이터 상 의 최대 x축 이동 거리를 조절하여 유사한 포즈 패턴이 발견될 것으로 예상되는 동작 구간을 벗어나지 않는 한 도 내에서 탐색을 진행하도록 조절할 수 있다. 또한, 시계열 데이터 패턴 매칭 시에 발생할 수 있는 뭉침 현상 을 줄이기 위해 제1 시계열 데이터와 제2 시계열 데이터 간에 연결될 수 있는 노드의 개수를 조정하여 매칭된 포드 패턴 데이터 결과가 비교적 고르게 분포하도록 할 수 있다. 그런 다음, 평가 RNN 모델은 제1 포즈 패턴 데이터의 제1 위치 데이터와 제1 각도 데이터 및 제2 포즈 패 턴 데이터의 제2 위치 데이터와 제2 각도 데이터 간의 일치 정도를 평가하여 자세 정확도를 산출하고, 제1 포즈 패턴 데이터와 제2 포즈 패턴 데이터 간의 시간 차이를 분석하여 박자 정확도를 산출하며, 제1 포즈 패턴 데이 터의 제1 가속도 데이터와 제1 각속도 데이터 및 제2 포즈 패턴 데이터 제2 가속도 데이터와 제2 각속도 데이터 간의 일치 정도를 평가하여 힘 정확도를 산출함으로써 일치 정확도를 계산하여 예측 평가 점수를 획득할 수 있 다. 일 예로서, 도 11은 본 발명의 일 실시예에 따라 힘 정확도를 평가하는 그래프의 예시를 개략적으로 도시하고 있다. 도 11에 따르면, 시간에 따라 변하는 학습자와 교습자의 위치 데이터의 순간속도의 변화를 비교하여 학습자의 힘 정확도를 평가할 수 있다. 여기서, 댄스 동작에 힘이 있다는 표현은 움직임에 절도가 있다는 것이며 이는 움직임을 시작할 때와 움직임을 멈출 때의 순간적인 속도 변화가 크다는 것을 의미하고, 반대로 동작이 부드럽 다는 것은 움직임의 시작과 끝의 순간적인 속도 변화가 적다는 것을 의미할 수 있다. 즉, 높은 각속도와 가속 도는 강력하고 에너지 넘치는 동작을 나타내며, 낮은 각속도와 가속도는 부드럽고 우아한 동작을 나타낼 수 있 다. 따라서, 본 발명은 힘 정확도를 평가함으로써 동작의 힘 배분에 대한 정확도를 측정할 수 있으며, 이는 즉, 동작 내에서 속도 변화를 측정하여 근력 및 지구력에 대한 점수화를 수행함을 의미할 수 있다. 참고로, 도 11과 같은 정화도 평가 그래프는 힘 정확도 뿐만 아니라 자세 정확도 및 박자 정확도에 대해서도 생 성될 수 있으며, 각 댄스 동작 구간마다 각 신체 부위로 나누어 생성된 정확도 평가 그래프에 대해 각각의 예측 평가 점수가 생성될 수 있다. 일 예로서, 도 12는 본 발명의 일 실시예에 따라 학습자가 제출한 댄스 동영상으로부터 획득한 프레임 이미지의 예시와 해당 프레임 이미지 상에서 각 신체 부위별 자세에 대해 생성된 예측 평가 점수 그래프의 예시를 개략적 으로 도시하고 있다. 도 12를 보면, 특정 학습자의 댄스 동작에 대해 좌측과 우측의 신체 부위에 대해 각각 어깨, 팔꿈치, 다리, 무 릎 등에 대한 별도의 예측 평가 점수를 생성한 것을 볼 수 있으며, 통상적인 숫자나 막대그래프 형식의 최종 합 산점수 외에 본 발명과 같이 구간별, 신체 부위별로 점수를 세분화하여 보여줌으로써 학습자가 평가 결과와 본 인의 제출 영상을 함께 보면서 스스로 반성점을 찾아 개선하고 학습할 수 있는 효과를 기대할 수 있을 것이다. 이후, 분석 서버는 복수의 동작 구간들 각각마다, 자세 정확도, 박자 정확도 및 힘 정확도 중 적어도 일 부에 가중치를 부여하는 제1 프로세스, 학습자의 특정 신체 부위에 대해 생성된 특정 예측 평가 점수에 가중치 를 부여하는 제2 프로세스, 교습자의 추가 평가 점수를 반영하는 제3 프로세스, 및 예측 평가 점수를 학습자 또 는 교습자가 선택한 척도에 맞추어 변환하는 제4 프로세스 중 적어도 하나를 수행하여 예측 평가 점수를 추가로 조정하여 최종 예측 평가 점수를 생성할 수 있다. 예를 들어, 본 발명의 분석 서버는 특정 댄스 동작에 있어서 교습자가 어느 부위가 더욱 강조되어야 하는 지에 대한 지정을 진행한 경우, 최종 예측 평가 점수를 생성할 때에는 가령, 신체의 상체 부위에 해당되는 상체 점수에 대해 신체의 하체 부위에 해당되는 하체 점수보다 높은 가중치를 줄 수도 있을 것이다. 또 다른 예시로, 본 발명은 정확도 요소를 고려하여 가중치를 부여하거나, 학습자 또는 교습자가 설정한 점수 척도(예: 5점 척도)에 맞게 변환되어 최종 예측 점수를 제공할 수도 있을 것이다. 한편, 분석 서버는 평가 RNN 네트워크가 생성한 예측 평가 점수와 레퍼런스 평가 점수 간의 차이 값 을 계산하고, 차이 값의 분포를 분석하여 예측 평가 점수와 레퍼런스 평가 점수 간의 불일치를 나타내는 이상점 과 점수별 분포 관계를 파악하여 평가 RNN 네트워크의 학습을 수행할 수 있다. 여기서, 레퍼런스 평가 점 수는 교습자가 사전에 학습 가이드로서 댄스 동작에 대해 생성한 점수일 수 있으며, 평가 RNN 네트워크가 생성한 평가 결과에 대해 각 점수 분포별 관계를 파악하고 새롭게 추가되는 평가 결과에 대해 수준별로 구별해 낼 수 있도록 Segmentation Machine Learning 알고리즘을 적용하여 결과값 분류기능을 적용할 수 있다. 뿐만 아니라, 분석 서버는 회귀 분석을 통한 AI기반 평가점수 추정방법을 통한 이상점(outlier)을 제거하 거나 평균제곱오차(Mean Squared Error)를 사용한 정확성 측정 및 에러값 최소화 구현을 통해 포즈 분석 및 평 가결과의 정확성을 향상시킬 수 있을 것이다. 한편, 분석 서버는 분석 서버 자체에 대한 성능 평가 또한 정기적으로 수행할 수 있다. 이에 따라, 도 13은 본 발명의 일 실시예에 따라 분석 서버의 동작인식 레이턴시(latency) 시간과 동작인식 정확도를 측정하는 방법을 개략적으로 도시하고 있다. 도 13에 따르면, 분석 서버는 분석 서버가 제1 프레임 이미지들과 제2 프레임 이미지들을 획득한 후 제1 프레임 이미지들의 제1 위치 데이터와 제2 프레임 이미지들의 제2 위치 데이터가 획득되기까지 소요된 시간을 각각 측정하여 평균을 계산함으로써 동작인식 레이턴시(latency) 시간을 측정하고, 분석 서버가 제1 프레임 이미지들에 대해 획득한 제1 위치 데이터 및 제2 프레임 이미지들에 대해 획득한 제2 위치 데이터와 정답 위치 데이터를 비교하여 차이값을 계산함으로써 동작인식 정확도를 측정할 수 있다. 이에 따라, 분석 서버는 동작인식 레이턴시 시간과 동작인식 정확도를 참조하여 분석 서버의 동작인식 및 분석평가 기능의 정량적 평가를 수행할 수 있다. 참고로, 분석 서버의 동작인식 및 분석평가 기능을 평 가할 때 사용하는 제1 프레임 이미지와 제2 프레임 이미지는 학습자와 교습자로부터 획득하여 사용할 수도 있을 것이나, 별도의 테스트용 데이터베이스로부터 획득한 제1 프레임 이미지와 제2 프레임 이미지일수도 있을 것이다. 이상 설명된 본 발명에 따른 실시예들은 다양한 컴퓨터 구성요소를 통하여 수행될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로 그램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능 한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프 트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하 드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM, DVD와 같은 광기록 매체, 플롭티컬 디스 크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프 로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령어의 예에는, 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치는 본 발명에 따른 처리를 수행하기 위해 하나 이상 의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상에서 본 발명이 구체적인 구성요소 등과 같은 특정 사항들과 한정된 실시예 및 도면에 의해 설명되었으나, 이는 본 발명의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 발명이 상기 실시예들에 한정되는 것은"}
{"patent_id": "10-2023-0129726", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "아니며, 본 발명이 속하는 기술분야에서 통상적인 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변형 을 꾀할 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등하게 또는 등가적으로 변형된 모든 것들은 본 발명의 사상의 범주에 속한다고 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13"}
{"patent_id": "10-2023-0129726", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 실시예의 설명에 이용되기 위하여 첨부된 아래 도면들은 본 발명의 실시예들 중 단지 일부일 뿐이며,"}
{"patent_id": "10-2023-0129726", "section": "도면", "subsection": "도면설명", "item": 2, "content": "본 발명이 속한 기술분야에서 통상의 지식을 가진 자(이하 \"통상의 기술자\")에게 있어서는 발명적 작업이 이루 어짐 없이 이 도면들에 기초하여 다른 도면들이 얻어질 수 있다. 도 1은 본 발명의 일 실시예에 따라 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 분석 서버를 개략적으 로 도시한 것이고, 도 2는 본 발명의 일 실시예에 따라 인공지능에 기반하여 학습자의 댄스 동작을 평가하는 과정을 개략적으로 도 시한 것이며, 도 3은 본 발명의 일 실시예에 따라 댄스 동영상에서 학습자와 교습자의 자세를 추정하는 방법을 개략적으로 도 시한 것이고, 도 4는 본 발명의 일 실시예에 따라 댄스 동영상의 프레임 이미지 상에서의 주요 포인트들의 예시를 개략적으로 도시한 것이며, 도 5는 본 발명의 일 실시예에 따라 댄스 동영상으로부터 학습자와 교습자의 신체 부위의 주요 포인트들에 대한위치 데이터를 획득하는 과정을 개략적으로 도시한 것이고, 도 6은 본 발명의 일 실시예에 따라 위치 데이터를 정규화하는 방법을 개략적으로 도시한 것이며, 도 7은 본 발명의 일 실시예에 따라 댄스 동영상을 복수의 동작 구간들로 분할하는 방법을 개략적으로 도시한 것이고, 도 8은 본 발명의 일 실시예에 따라 댄스 동영상을 복수의 동작 구간들로 분할하여 각 동작 구간들에 대한 평가 를 수행하는 과정을 개략적으로 도시한 것이며, 도 9는 본 발명의 일 실시예에 따라 댄스 동영상의 프레임 이미지로부터 신체 부위 상의 이웃하는 관절들의 특 정 위치 데이터를 참조하여 획득한 관절들의 각도들에 대한 각도 데이터의 예시를 개략적으로 도시한 것이고, 도 10은 본 발명의 일 실시예에 따라 관절 위치와 프레임 속도로부터 파생될 수 있는 정보들을 개략적으로 도시 한 것이며 도 11은 본 발명의 일 실시예에 따라 힘 정확도를 평가하는 그래프의 예시를 개략적으로 도시한 것이고, 도 12는 본 발명의 일 실시예에 따라 학습자가 제출한 댄스 동영상으로부터 획득한 프레임 이미지의 예시와 해 당 프레임 이미지 상에서 각 신체 부위별 자세에 대해 생성된 예측 평가 점수 그래프의 예시를 개략적으로 도시 한 것이며, 도 13은 본 발명의 일 실시예에 따라 분석 서버의 동작인식 레이턴시(latency) 시간과 동작인식 정확도를 측정 하는 방법을 개략적으로 도시한 것이다."}
