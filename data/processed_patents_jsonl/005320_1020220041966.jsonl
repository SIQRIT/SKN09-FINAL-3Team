{"patent_id": "10-2022-0041966", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0100543", "출원번호": "10-2022-0041966", "발명의 명칭": "인공지능에 기초한 대화상황예측과 의도분류 시스템 및 그 방법", "출원인": "경북대학교 산학협력단", "발명자": "정호영"}}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "어느 한 시점에서 다른 시점까지의 사용자의 요청발화에 기초하여 상기 사용자의 성별 및 연령을 판단하는 음성판단부;상기 사용자의 요청발화를 텍스트로 변환하여 상기 사용자의 발화의도를 판단하고 상기 다른 시점 이후의 상기사용자의 예측발화를 판단하는 음성처리부; 및 상기 사용자의 발화의도와 상기 예측된 상기 예측발화에 기초하여 상기 사용자의 요청발화에 대한 응답을 생성하는 응답생성부를 포함하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 음성판단부는, 상기 어느 한 시점에서의 상기 요청발화에 기초하여 제1 음성데이터를 추출하는 음성추출부;상기 제1 음성데이터를 미리 저장된 제1 판단알고리즘의 입력값으로하여 상기 사용자의 성별 및 연령을 제1 확률값으로 산출하고 상기 제1 확률값에 기초하여 상기 사용자의 성별 및 연령을 결정하는 제1 딥러닝부; 및상기 결정된 성별 및 연령에 기초하여 상기 어느 한 시점에서 상기 다른 시점까지 상기 사용자의 요청발화를 인식하고 제2 음성데이터를 추출하는 음성인식기분배부를 포함하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 제1 딥러닝부는,상기 제1 확률값 중 가장 높은 확률값에 대응하는 성별 및 연령을 상기 사용자의 성별 및 연령으로 결정하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 음성인식기분배부는,상기 결정된 성별 및 연령에 대응하여 상기 사용자의 요청발화를 인식하고 상기 제2 음성데이터를 생성하는 서로 다른 복수의 음성인식기를 포함하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 항에 있어서,상기 음성처리부는,상기 제2 음성데이터를 제1 변환텍스트로 변환하는 음성-텍스트변환부;상기 제1 변환텍스트를 미리 저장된 제1 딥러닝알고리즘의 입력값으로 입력하여 상기 사용자의 요청발화에 상응공개특허 10-2023-0100543-3-하는 제1 요청텍스트를 결정하는 제2 딥러닝부;상기 제1 요청텍스트를 미리 저장된 의도분류알고리즘의 입력값으로 입력하여 상기 발화의도에 대한 발화의도데이터를 생성하는 발화의도분류부; 및상기 발화의도데이터를 미리 저장된 의도예측알고리즘의 입력값으로 입력하여 상기 예측발화에 대한 예측발화데이터를 생성하는 발화의도예측부를 포함하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 제2 딥러닝부는,상기 제1 변환텍스트를 입력받는 변환텍스트입력부;상기 제1 변환텍스트를 상기 미리 저장된 제1 딥러닝알고리즘의 입력값으로 입력하여 상기 제1 요청텍스트를 생성하는 제1 음성모델딥러닝부; 및상기 제1 요청텍스트를 출력하는 요청텍스트출력부를 포함하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 제2 딥러닝부는,상기 사용자의 요청발화에 상응하는 제1 기준텍스트를 저장하는 기준텍스트저장부; 및상기 제1 변환텍스트와 상기 제1 요청텍스트 사이의 제1 오류율값을 산출하는 제1 오류율산출부를 더 포함하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 제2 딥러닝부는,상기 제1 기준텍스트를 미리 저장된 제2 딥러닝알고리즘의 입력값으로 입력하여 딥러닝을 수행하는 제2 음성모델딥러닝부;상기 제1 기준텍스트와 상기 제2 음성모델딥러닝부의 출력값인 제2 기준텍스트 사이의 제2 오류율값을 산출하는제2 오류율산출부; 및상기 제1 오류율값과 상기 제2 오류율값에 기초하여 상기 제1 음성모델딥러닝부를 딥러닝하기 위한 가중치값을산출하는 가중치값산출부를 더 포함하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 제1 음성모델딥러닝부는,상기 가중치값을 상기 미리 저장된 제1 딥러닝알고리즘의 가중치값으로 하고, 상기 제1 변환텍스트를 입력값으로 입력하여 딥러닝을 수행하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2023-0100543-4-제9 항에 있어서,상기 발화의도분류부는,상기 제1 요청텍스트를 상기 미리 저장된 의도분류알고리즘의 입력값으로 입력하여 상기 발화의도를 제2 확률값으로 산출한 상기 발화의도데이터를 생성하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 발화의도분류부는,상기 제2 확률값 중 가장 높은 확률값을 가지는 발화의도를 상기 사용자의 발화의도로 결정하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10 항에 있어서,상기 발화의도예측부는,상기 발화의도데이터를 상기 미리 저장된 의도예측알고리즘의 입력값으로 입력하여 상기 예측발화를 제3 확률값으로 산출한 상기 예측발화데이터를 생성하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항에 있어서,상기 발화의도분류부는,상기 제3 확률값 중 가장 높은 확률값을 가지는 예측발화를 상기 사용자의 예측발화로 판단하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제6 항에 있어서,상기 응답생성부는,상기 발화의도데이터 및 상기 예측발화데이터를 미리 저장된 응답알고리즘의 입력값으로하여 상기 사용자의 요청발화에 대한 응답텍스트를 생성하는 응답텍스트생성부; 및상기 응답텍스트를 음성데이터로 변환하는 텍스트-음성변환부를 포함하는,인공지능에 기초한 음성 처리 시스템."}
{"patent_id": "10-2022-0041966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "음성판단부에 의해 어느 한 시점에서 다른 시점까지의 사용자의 요청발화에 기초하여 상기 사용자의 성별 및 연령을 판단하는 단계; 음성처리부에 의해 상기 사용자의 요청발화를 텍스트로 변환하여 상기 사용자의 발화의도를 판단하고 상기 다른시점 이후의 상기 사용자의 예측발화를 판단하는 단계; 및응답생성부에 의해 상기 사용자의 발화의도와 상기 예측된 상기 예측발화에 기초하여 상기 사용자의 요청발화에대한 응답을 생성하는 단계를 포함하는,인공지능에 기초한 음성 처리 방법.공개특허 10-2023-0100543-5-청구항 16 제1 항의 인공지능에 기초한 음성 처리 시스템을 실행시키는 프로그램이 기록된 컴퓨터로 판독 가능한 비일시적기록매체."}
{"patent_id": "10-2022-0041966", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명인 인공지능에 기초한 대화상황예측과 의도분류 시스템은, 어느 한 시점에서 다른 시점까지의 사용자의 요청발화에 기초하여 사용자의 성별 및 연령을 판단하는 음성판단부, 사용자의 요청발화를 텍스트로 변환하여 사 용자의 발화의도를 판단하고 다른 시점 이후의 사용자의 예측발화를 예측하는 음성처리부 및 사용자의 발화의도 와 예측된 예측발화에 기초하여 사용자의 요청발화에 대한 응답을 생성하는 응답생성부를 포함한다."}
{"patent_id": "10-2022-0041966", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능에 기초한 대화상황예측과 의도분류 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2022-0041966", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에 인공지능을 이용한 기술이 발달함에 따라서 인공지능스피커에 대한 수요가 늘어나고 있다. 일반적으로, 인공지능스피커는 사용자로부터 제공된 음성을 인식하고 내장된 알고리즘에 기초하여 응답을 생성 하고 출력할 수 있다. 사용자는 인공지능스피커를 이용하여 다양한 정보에 대해서 편리하게 접근할 수 있다. 한편, 잡음이 존재하는 환경 또는, 다양한 외부/내부 요인으로 인해서 인공지능스피커는 사용자의 음성을 정확 하게 인식할 수 없고 사용자에게 부정확한 정보를 제공할 수 있다. 또한, 사용자의 발화에 기초하여 응답을 생성하므로 사용자에게 제공할 수 있는 정보는 제한적일 수 있다. 이에, 사용자는 원하는 응답을 얻기 위해 여러 번 인공지능스피커를 사용하여야 하므로 정보획득의 측면에서 효 율성이 떨어질 수 있다. 이에, 다양한 환경에서 작동 가능하며 사용자에게 효율적으로 다양한 정보를 제공할 수 있는 기술이 필요한 실 정이다."}
{"patent_id": "10-2022-0041966", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는 사용자의 성별 및 연령에 따라서 사용자의 음성을 인식하는 인공지능 에 기초한 대화상황예측과 의도분류 시스템 및 그 방법을 제공하기 위함이다. 또한, 본 발명이 해결하고자 하는 기술적 과제는 사용자의 음성에 기초하여 사용자의 발화의도를 판단하는 인공 지능에 기초한 대화상황예측과 의도분류 시스템 및 그 방법을 제공하기 위함이다. 또한, 본 발명이 해결하고자 하는 기술적 과제는 사용자의 발화의도에 기초하여 사용자의 발화 이후의 사용자의 발화를 예측하는 인공지능에 기초한 대화상황예측과 의도분류 시스템 및 그 방법을 제공하기 위함이다. 또한, 본 발명이 해결하고자 하는 기술적 과제는 사용자의 발화의도와 예측된 사용자의 발화에 기초하여 응답을 생성하는 인공지능에 기초한 대화상황예측과 의도분류 시스템 및 그 방법을 제공하기 위함이다."}
{"patent_id": "10-2022-0041966", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 한 실시예에 따른 인공지능에 기초한 대화상황예측과 의도분류 시스템은, 어느 한 시점에서 다른 시 점까지의 사용자의 요청발화에 기초하여 사용자의 성별 및 연령을 판단하는 음성판단부, 사용자의 요청발화를 텍스트로 변환하여 사용자의 발화의도를 판단하고 다른 시점 이후의 사용자의 예측발화를 판단하는 음성처리부 및 사용자의 발화의도와 예측된 예측발화에 기초하여 사용자의 요청발화에 대한 응답을 생성하는 응답생성부를 포함한다. 또한, 본 발명의 한 실시예에 따른 음성판단부는, 어느 한 시점에서의 요청발화에 기초하여 제1 음성데이터를 추출하는 음성추출부, 제1 음성데이터를 미리 저장된 제1 판단알고리즘의 입력값으로 입력하여 사용자의 성별 및 연령을 제1 확률값으로 산출하고 제1 확률값에 기초하여 사용자의 성별 및 연령을 결정하는 제1 딥러닝부 및 결정된 성별 및 연령에 기초하여 어느 한 시점에서 다른 시점까지 사용자의 요청발화를 인식하고 제2 음성데이 터를 추출하는 음성인식기분배부를 포함한다. 또한, 본 발명의 한 실시예에 따른 제1 딥러닝부는, 제1 확률값 중 가장 높은 확률값에 대응하는 성별 및 연령 을 사용자의 성별 및 연령으로 결정한다. 또한, 본 발명의 한 실시예에 따른 음성인식기분배부는, 결정된 성별 및 연령에 대응하여 사용자의 요청발화를 인식하고 제2 음성데이터를 생성하는 서로 다른 복수의 음성인식기를 포함한다. 또한, 본 발명의 한 실시예에 따른 음성처리부는, 제2 음성데이터를 제1 변환텍스트로 변환하는 음성-텍스트변 환부, 제1 변환텍스트를 미리 저장된 제1 딥러닝알고리즘의 입력값으로 입력하여 사용자의 요청발화에 상응하는 제1 요청텍스트를 결정하는 제2 딥러닝부, 제1 요청텍스트를 미리 저장된 의도분류알고리즘의 입력값으로 입력 하여 발화의도에 대한 발화의도데이터를 생성하는 발화의도분류부 및 발화의도데이터를 미리 저장된 의도예측알 고리즘의 입력값으로 입력하여 예측발화에 대한 예측발화데이터를 생성하는 발화의도예측부를 포함한다. 또한, 본 발명의 한 실시예에 따른 제2 딥러닝부는, 제1 변환텍스트를 입력받는 변환텍스트입력부, 제1 변환텍 스트를 미리 저장된 제1 딥러닝알고리즘의 입력값으로 입력하여 제1 요청텍스트를 생성하는 제1 음성모델딥러닝 부 및 제1 요청텍스트를 출력하는 요청텍스트출력부를 포함한다. 또한, 본 발명의 한 실시예에 따른 제2 딥러닝부는, 사용자의 요청발화에 상응하는 제1 기준텍스트를 저장하는 기준텍스트저장부 및 제1 변환텍스트와 제1 요청텍스트 사이의 제1 오류율값을 산출하는 제1 오류율산출부를 더 포함한다. 또한, 본 발명의 한 실시예에 따른 제2 딥러닝부는, 제1 기준텍스트를 미리 저장된 제2 딥러닝알고리즘의 입력 값으로 입력하여 딥러닝을 수행하는 제2 음성모델딥러닝부, 제1 기준텍스트와 제2 음성모델딥러닝부의 출력값인 제2 기준텍스트 사이의 제2 오류율값을 산출하는 제2 오류율산출부 및 제1 오류율값과 제2 오류율값에 기초하여 제1 음성모델딥러닝부를 딥러닝하기 위한 가중치값을 산출하는 가중치값산출부를 더 포함한다. 또한, 본 발명의 한 실시예에 따른 제1 음성모델딥러닝부는, 가중치값을 미리 저장된 제1 딥러닝알고리즘의 가 중치값으로 하고, 제1 변환텍스트를 입력값으로 입력하여 딥러닝을 수행한다. 또한, 본 발명의 한 실시예에 따른 발화의도분류부는, 제1 요청텍스트를 미리 저장된 의도분류알고리즘의 입력 값으로 입력하여 발화의도를 제2 확률값으로 산출한 발화의도데이터를 생성한다. 또한, 본 발명의 한 실시예에 따른 발화의도분류부는, 제2 확률값 중 가장 높은 확률값을 가지는 발화의도를 사 용자의 발화의도로 결정한다. 또한, 본 발명의 한 실시예에 따른 발화의도예측부는, 발화의도데이터를 미리 저장된 의도예측알고리즘의 입력 값으로 입력하여 예측발화를 제3 확률값으로 산출한 예측발화데이터를 생성한다. 또한, 본 발명의 한 실시예에 따른 발화의도분류부는, 제3 확률값 중 가장 높은 확률값을 가지는 예측발화를 사 용자의 예측발화로 판단한다. 또한, 본 발명의 한 실시예에 따른 응답생성부는, 발화의도데이터 및 예측발화데이터를 미리 저장된 응답알고리 즘의 입력값으로하여 사용자의 요청발화에 대한 응답텍스트를 생성하는 응답텍스트생성부 및 응답텍스트를 음성 데이터로 변환하는 텍스트-음성변환부를 포함한다. 또한, 본 발명의 한 실시예에 따른 인공지능에 기초한 대화상황예측과 의도분류 방법은, 음성판단부에 의해 어 느 한 시점에서 다른 시점까지의 사용자의 요청발화에 기초하여 사용자의 성별 및 연령을 판단하는 단계, 음성 처리부에 의해 사용자의 요청발화를 텍스트로 변환하여 사용자의 발화의도를 판단하고 다른 시점 이후의 사용자 의 예측발화를 판단하는 단계 및 응답생성부에 의해 사용자의 발화의도와 예측된 예측발화에 기초하여 사용자의 요청발화에 대한 응답을 생성하는 단계를 포함한다. 또한, 본 발명의 한 실시예에 따른 인공지능에 기초한 음성 처리 시스템을 실행시키는 프로그램이 기록된 컴퓨 터로 판독 가능한 비일시적 기록매체를 포함한다."}
{"patent_id": "10-2022-0041966", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 인공지능에 기초한 대화상황예측과 의도분류 시스템은 사용자의 성별 및 연령에 따라서 사용자 의 음성을 정확하게 인식할 수 있다. 또한, 본 발명에 따른 인공지능에 기초한 대화상황예측과 의도분류 시스템은 사용자의 음성에 기초하여 사용자 의 발화의도를 판단할 수 있다.또한, 본 발명에 따른 인공지능에 기초한 대화상황예측과 의도분류 시스템은 사용자의 발화의도에 기초하여 사 용자의 발화 이후의 사용자의 발화를 예측할 수 있다. 또한, 본 발명에 따른 인공지능에 기초한 대화상황예측과 의도분류 시스템은 사용자의 발화의도와 예측된 사용 자의 발화에 기초하여 응답을 생성할 수 있다."}
{"patent_id": "10-2022-0041966", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참고로 하여 본 발명의 여러 실시 예들에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예들에 한정되지 않는다. 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조 부호를 붙이도록 한다. 따라서 앞서 설명한 참조 부호는 다른 도면에 서도 사용할 수 있다. 또한, 도면에서 나타난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나타내었으므로, 본 발명이 반드 시 도시된 바에 한정되지 않는다. 도면에서 여러 층 및 영역을 명확하게 표현하기 위하여 두께를 과장되게 나 타낼 수 있다. 또한, 설명에서 \"동일하다\"라고 표현한 것은, \"실질적으로 동일하다\"는 의미일 수 있다. 즉, 통상의 지식을 가 진 자가 동일하다고 납득할 수 있을 정도의 동일함일 수 있다. 그 외의 표현들도 \"실질적으로\"가 생략된 표현들 일 수 있다. 또한, 설명에서 어떤 부분이 어떤 구성요소를 '포함'한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 사용되는 '~부'는 적어도 하나의 기능이나 동작을 처리하는 단위로서, 예를 들어 소프트웨어, FPGA 또는 하드웨어 구성요 소를 의미할 수 있다. '~부'에서 제공하는 기능은 복수의 구성요소에 의해 분리되어 수행되거나, 다른 추가적인 구성요소와 통합될 수도 있다. 본 명세서의 '~부'는 반드시 소프트웨어 또는 하드웨어에 한정되지 않으며, 어드 레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고, 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 이하에서는 도면을 참조하여 본 발명의 실시예에 대해서 구체적으로 설명하기로 한다. 도 1은 본 발명의 한 실시예에 따른 인공지능에 기초한 대화상황예측과 의도분류 시스템을 나타내는 도면이다. 본 발명의 한 실시예에 따른 인공지능에 기초한 대화상황예측과 의도분류 시스템은 음성판단부, 음성처 리부, 및 응답생성부를 포함할 수 있다. 음성판단부는 음성추출부, 제1 딥러닝부 및 음성인식기분배부를 포함할 수 있다. 음성처리 부는 음성-텍스트변환부, 제2 딥러닝부, 발화의도분류부, 및 발화의도예측부를 포함할 수 있다. 응답생성부는 응답텍스트생성부 및 텍스트-음성변환부를 포함할 수 있다. 인공지능스피커는 사용자의 발화에 기초한 음성을 인식할 수 있다. 인공지능스피커는 사용자의 발 화에 대응하는 응답을 출력할 수 있다. 이를 통해, 사용자는 인공지능스피커로부터 다양한 정보를 획득할 수 있다. 이하, 인공지능스피커에 입력되는 사용자의 발화를 '요청발화'라 명명하기로 한다. 음성판단부는 어느 한 시점에서 다른 시점까지의 사용자의 요청발화를 인식할 수 있다. 이하, 도 1에서 어느 한 시점에서 사용자가 요청발화를 시작하며, 어느 한 시점에서 다른 한 시점까지 인공 지능스피커에 '에어야 오늘 날씨 알려줘'라는 요청발화를 한 것으로 가정하기로 한다. 이때, '에어야'는 인 공지능스피커를 동작시키기 위한 초기 명령어로 가정하기로 한다. 음성추출부는 사용자의 요청발화에 기초하여 어느 한 시점에서의 음성데이터를 추출할 수 있다. 이하, 어느 한 시점에서 음성추출부에서 추출되는 사용자의 음성데이터를 제1 음성데이터라 명명하기로 한다. 구체적으로, 음성추출부는 어느 한 시점에서의 사용자의 요청발화인 '에어야'를 포함하는 제1 음성데이 터를 추출할 수 있다. 제1 딥러닝부는 제1 음성데이터를 미리 저장된 제1 판단알고리즘의 입력값으로하여 사용자의 성별 및 연령을 확률값으로 산출할 수 있다. 제1 딥러닝부는 확률값에 기초하여 사용자의 성별 및 연령을 결정할 수 있다. 구체적으로, 제1 딥러닝부는 제1 음성데이터를 미리 저장된 제1 판단알고리즘의 입력값으로 입력하여 사용 자의 성별이 남성 또는 여성 중 어느 하나이고 연령이 성인, 노인 또는 어린이 중 어느 하나에 해당할 확률 을 확률값으로 산출할 수 있다. 이하, 제1 딥러닝부에서 제1 음성데이터를 미리 저장된 제1 판단알고리즘의 입력값으로 입력하여 산출된 확률값을 제1 확률값이라 명명하기로 한다. 이때, 제1 딥러닝부는 산출된 제1 확률값 중 가장 높은 확률값에 대응하는 성별 및 연령을 사용자의 성 별 및 연령으로 결정할 수 있다. 제1 딥러닝부가 제1 음성데이터를 미리 저장된 판단알고리즘의 입력값으로 입력하여 사용자의 성별 및 연령을 결정하는 과정은 아래, 도 2에서 구체적으로 설명하기로 한다. 음성인식기분배부는 사용자의 성별 및 연령에 따라서 어느 한 시점에서 다른 시점까지 사용자의 요 청발화를 인식하고, 사용자의 요청발화에 기초하여 음성데이터를 생성하는 서로 다른 복수의 음성인식기를 포함할 수 있다. 음성인식기분배부는 사용자의 성별 및 연령에 대응하는 어느 하나의 음성인식기를 결정하고, 상기 어느 하 나의 음성인식기를 이용하여 어느 한 시점에서 다른 시점까지의 사용자의 요청발화를 인식할 수 있다. 어느 하나의 음성인식기는 사용자의 요청발화를 인식하고 이에 기초하여 음성데이터를 추출할 수 있다. 이하, 음성인식기분배부에 포함된 어느 하나의 음성인식기에서 인식되어 추출된 음성데이터를 제2 음성데 이터라 명명하기로 한다. 구체적으로, 제1 딥러닝부에서 사용자의 성별이 남성이고 연령이 성인으로 결정된 경우, 음성인식기분 배부는 성인남성의 요청발화를 인식하기 위한 어느 하나의 음성인식기를 결정할 수 있다. 어느 하나의 음 성인식기는 성인남성의 요청발화를 인식하고 제2 음성데이터를 생성할 수 있다. 제1 딥러닝부에서 사용자의 성별이 여성이고 연령이 성인으로 결정된 경우, 음성인식기분배부는 성인여성의 요청발화를 인식하기 위한 어느 하나의 음성인식기를 선택할 수 있다. 어느 하나의 음성인식기는 성 인여성의 요청발화를 인식하고 제2 음성데이터를 생성할 수 있다. 제1 딥러닝부에서 사용자의 성별이 남성이고 연령이 노인으로 결정된 경우, 음성인식기분배부는 노인남성의 요청발화를 인식하기 위한 어느 하나의 음성인식기를 선택할 수 있다. 어느 하나의 음성인식기는 노 인남성의 요청발화를 인식하고 제2 음성데이터를 생성할 수 있다. 제1 딥러닝부에서 사용자의 성별이 여성이고 연령이 노인으로 결정된 경우, 음성인식기분배부는 노인여성의 요청발화를 인식하기 위한 어느 하나의 음성인식기를 선택할 수 있다. 어느 하나의 음성인식기는 노 인여성의 요청발화를 인식하고 제2 음성데이터를 생성할 수 있다. 제1 딥러닝부에서 사용자의 성별이 남성이고 연령이 어린이로 결정된 경우, 음성인식기분배부는 남자어린이의 요청발화를 인식하기 위한 어느 하나의 음성인식기를 선택할 수 있다. 어느 하나의 음성인식기는 남자어린이의 요청발화를 인식하고 제2 음성데이터를 생성할 수 있다. 제1 딥러닝부에서 사용자의 성별이 여성이고 연령이 어린이로 결정된 경우, 음성인식기분배부는 여자어린이의 요청발화를 인식하기 위한 어느 하나의 음성인식기를 선택할 수 있다. 어느 하나의 음성인식기는 여자어린이의 요청발화를 인식하고 제2 음성데이터를 생성할 수 있다. 즉, 음성인식기분배부는 남성 또는 여성 중 어느 하나의 성별에 해당하고, 노인, 성인, 어린이 중 어느 하 나의 연령에 해당하는 사용자의 요청발화를 인식하기 위한 어느 하나의 음성인식기를 결정할 수 있다. 또한, 어느 하나의 음성인식기는 어느 한 시점에서 다른 시점까지의 사용자의 요청발화를 인식할 수 있다. 어느 하나의 음성인식기는 사용자의 요청발화에 기초하여 제2 음성데이터를 추출할 수 있다. 음성처리부는 어느 한 시점에서 다른 시점까지의 사용자의 요청발화를 텍스트로 변환하여 사용자의 발화의 도를 판단할 수 있다. 음성처리부는 다른 시점 이후의 사용자의 예측발화를 판단할 수 있다. 음성-텍스트변환부는 음성인식기분배부에 포함된 어느 하나의 음성인식기에서 추출된 제2 음성데이터 를 텍스트로 변환할 수 있다. 이때, 텍스트는 오류를 포함할 수 있다. 이하, 음성-텍스트변환부에서 변환 되며, 오류를 포함하는 텍스트를 제1 변환텍스트라 명명하기로 한다. 구체적으로, 어느 하나의 음성인식기가 사용자의 요청발화를 인식하는 과정에서 외부잡음이 포함되는 등, 다 양한 외부요인 또는 내부요인에 의해서 사용자의 요청발화를 잘못 인식할 수 있다. 예를 들어, 성인남성의 요청발화를 인식하는 어느 하나의 음성인식기는 성인남성의 요청발화인 '에어야 오늘날 씨 알려줘'에 기초하여 '에어야 오월의 일정을 알려줘'로 잘못 인식할 수 있다. 또한, 어느 하나의 음성인식기 는 이에 기초하여 '에어야 오월의 일정을 알려줘'로 구성된 제2 음성데이터를 추출할 수 있다. 이때, 음성-텍스트변환부는 제2 음성데이터를 제1 변환텍스트로 변환할 수 있으며, 제1 변환텍스트는 오류 를 포함한'에어야 오월의 일정을 알려줘'로 구성될 수 있다. 제2 딥러닝부는 제1 변환텍스트를 미리 저장된 제1 딥러닝알고리즘의 입력값으로 입력하여 제1 요청텍스트 를 생성할 수 있다. 구체적으로, 제1 변환텍스트가 제2 딥러닝부의 미리 저장된 제1 딥러닝알고리즘의 입력값으로 입력되는 경 우, 제1 딥러닝알고리즘은 출력값으로 사용자의 발화요청에 상응하는 요청텍스트를 생성할 수 있다. 이하, 제2 딥러닝부에서 미리 저장된 제1 딥러닝알고리즘에 의해 생성된 요청텍스트를 제1 요청텍스트라 명명하기로 한다. 제2 딥러닝부는 입력층, 은닉층, 및 출력층으로 구성되며, 제1 딥러닝알고리즘은 제1 변환텍스트를 입력층 의 입력값으로 입력하여 출력층에서 제1 요청텍스트를 출력하는 일련의 프로세스를 의미할 수 있다. 이때, 입력층에 입력된 제1 변환텍스트는 은닉층에서 소정의 가중치값들이 가산되어 출력값인 제1 요청텍스트로 변환될 수 있다. 제2 딥러닝부의 은닉층에서 가산되는 소정의 가중치값들은 아래 도 4에서 서술할 제1 오류율 및 제2 오류 율을 포함하는 가중치값에 의해서 재설정될 수 있으며, 위 과정을 통해서 제1 딥러닝알고리즘은 조정될 수 있다. 제2 딥러닝부는 제1 변환텍스트와 제1 딥러닝알고리즘에서 출력된 제1 요청텍스트 사이의 오류율(또는, 손 실값)을 산출할 수 있다. 이하, 제2 딥러닝부에서 제1 변환텍스트와 제1 딥러닝알고리즘에서 출력된 제1 요청텍스트 사이에 산출되 는 오류율(또는, 손실값)을 제1 오류율(또는, 제1 손실값)이라 명명하기로 한다. 구체적으로, 제2 딥러닝부의 제1 딥러닝알고리즘의 입력값으로 제1 변환텍스트가 입력된 경우, 제1 딥러닝 알고리즘에서 출력된 제1 요청텍스트는 사용자의 '발화요청'에 정확히 상응하지 않을 수 있다. 따라서, 이후 서술할 제1 딥러닝알고리즘을 미세조정하기 위해서 제2 딥러닝부는 제1 딥러닝알고리즘에서 출력된 제1 요청텍스트와 제1 딥러닝알고리즘의 입력값으로 입력된 제1 변환텍스트 사이의 제1 오류율(또는, 제 1 손실값)을 산출할 수 있다. 제2 딥러닝부의 제2 딥러닝알고리즘은 제1 기준텍스트(또는, 제1 전사텍스트)를 미리 저장된 제2 딥러닝알 고리즘의 입력값하여 출력값이 제1 기준텍스트(또는, 제1 전사텍스트)와 동일한 제2 기준텍스트(또는, 제2 전사텍스트)를 출력하도록 제2 딥러닝알고리즘을 미세조정할 수 있다. 이때, 제1 기준텍스트(또는, 전사텍스트)는 사용자의 발화의도에 정확히 상응하는 텍스트에 해당하며 오류가 포함되지 않은 '에어야 오늘 날씨를 알려줘'에 해당한다. 구체적으로, 제2 딥러닝부는 제1 기준텍스트(또는, 제1 전사텍스트)와 미리 저장된 제2 딥러닝알고리즘의 출력값으로 출력된 제2 기준텍스트(또는, 제2 전사텍스트) 사이의 제2 오류율(또는, 제2 손실값)을 산출할 수 있다. 또한, 제2 딥러닝부의 제2 딥러닝알고리즘은 제2 오류율(또는, 제2 손ㅅ실값)에 기초하여 제2 딥러닝알고 리즘을 미세조정하고 딥러닝을 수행할 수 있다. 제2 딥러닝부는 제1 오류율(또는, 제1 손실값)과 제2 오류율(또는, 제2 손실값)을 이용하여 가중치값을 산 출할 수 있다. 제2 딥러닝부는 생성된 가중치값을 이용하여 미리 저장된 제1 딥러닝알고리즘을 미세조정할 수 있다. 위 과정을 통해서, 잡음이 존재하는 환경 또는 음성인식기가 사용자의 사용발화를 잘못인식한 경우에도 제2 딥 러닝부의 제1 딥러닝알고리즘은 사용자의 요청발화를 정확하게 인식하고 텍스트(또는, 제1 요청텍스트)로 변환할 수 있다. 발화의도분류부는 제1 요청텍스트를 미리 저장된 의도분류알고리즘의 입력값으로 입력하여 사용자의 발화 의도에 대한 발화의도데이터를 생성할 수 있다. 구체적으로, 발화의도분류부는 제1 요청텍스트인 '에어야 오늘 날씨를 알려줘'를 미리 저장된 의도분류알 고리즘의 입력값으로 입력하여 사용자의 발화의도를 확률값으로 산출할 수 있다. 이하, 발화의도분류부에서 산출된 확률값을 제2 확률값이라 명명하기로 한다. 이때, 발화의도분류부는 산출된 제2 확률값 중 가장 높은 확률값에 대응하는 발화의도를 사용자의 발화의 도로 결정할 수 있다. 예를 들어, 발화의도분류부는 사용자의 발화의도를 '오늘'의 '날씨'인 것으로 판단 할 수 있다. 발화의도분류부에 제1 요청텍스트를 미리 저장된 의도분류알고리즘의 입력값으로하여 사용자의 발화의도를 확률값으로 산출하고, 이에 기초하여 사용자의 발화의도를 결정하는 과정은 아래 도 5에서 구체적으로 서술하기 로 한다. 발화의도예측부는 발화의도데이터를 미리 저장된 의도예측알고리즘의 입력값으로 입력하여 사용자의 예측 발화에 대한 예측발화데이터를 생성할 수 있다. 구체적으로, 발화의도예측부는 발화의도데이터인 '오늘' 및 '날씨'를 미리 저장된 의도예측알고리즘의 입 력값으로 입력하여 사용자의 예측발화를 확률값으로 산출할 수 있다. 이하, 발화의도예측부에서 산출된 확 률값을 제3 확률값이라 명명하기로 한다. 이때, 발화의도예측부는 산출된 제3 확률값 중 가장 높은 확률값에 대응하는 예측발화를 사용자의 예측발 화로 결정할 수 있다. 예를 들어, 발화의도예측부는 사용자의 요청발화가 끝난 다른 시점 이후인 제1 시점의 사용자의 예측발 화를 '옷'으로 결정할 수 있다. 또한, 발화의도예측부는 제1 시점 이후인 제2 시점의 사용자의 예측발화를 '장소'로 결정할 수 있다. 발화의도예측부에 발화의도데이터를 미리 저장된 의도예측알고리즘의 입력값으로하여 사용자의 예측발화를 확률값으로 산출하고, 이에 기초하여 사용자의 예측발화를 결정하는 과정은 아래, 도 5에서 구체적으로 서술하 기로 한다. 즉, 상술한 바와 같이, 발화의도분류부는 제1 요청텍스트에 기초하여 어느 한 시점에서 다른 시점까지의 사용자의 발화의도를 판단하고 발화의도데이터를 생성할 수 있다. 발화의도예측부는 발화의도데이터에 기 초하여 사용자의 발화요청이 끝난 다른 시점 이후의 사용자의 예측발화를 판단하고 예측발화데이터를 생성할 수 있다. 응답생성부는 발화의도분류부에서 판단된 사용자의 발화의도와 발화의도예측부에서 판단된 사용 자의 예측발화에 기초하여 사용자의 요청발화에 대한 응답을 생성할 수 있다. 구체적으로, 응답텍스트생성부는 발화의도데이터 및 예측발화데이터를 미리 저장된 응답알고리즘의 입력값 으로 입력하여 사용자의 요청발화에 대한 응답을 생성할 수 있다. 예를 들어, 사용자의 발화의도는 '오늘'의 '날씨'에 대한 것이고, 사용자의 예측발화는 '옷' 및 '장소'에 대한 것으로 판단되므로, 응답텍스트생성부는 '오늘'및 '날씨'를 포함하는 발화의도데이터와 '옷', 및 '장소'를 포함하는 예측발화데이터를 미리 저장된 응답알고리즘의 입력값으로 입력할 수 있다. 이에 기초하여, 미리 저장된 응답알고리즘의 출력값으로 '오늘의 날씨는 덥습니다. 냉방병 예방을 위해 얇고 긴 옷을 입고 밖으로 나가실 것을 추천드립니다.'라는 응답텍스트를 출력값으로 생성할 수 있다. 즉, 응답텍스트생성부는 '오늘의 날씨는 덥습니다. 냉방병 예방을 위해 얇고 긴 옷을 입고 밖으로 나가실 것을 추천드립니다.'라는 응답텍스트를 생성할 수 있다. 텍스트-음성변환부는 응답텍스트생성부에서 생성된 응답텍스트를 음성데이터로 변환할 수 있다. 텍스 트-음성변환부는 음성데이터를 인공지능스피커에 전달하고, 이에 기초하여 사용자의 요청발화에 대 한 응답으로 출력할 수 있다. 도 2는 본 발명의 한 실시예에 따른 사용자의 성별 및 연령을 판단하고 제2 음성데이터를 추출하는 과정을 설명 하는 도면이다. 음성추출부는 사용자의 요청발화에 기초하여 어느 한 시점에서의 제1 음성데이터('에어야')를 추출할 수 있다. 제1 딥러닝부는 제1 음성데이터('에어야')를 미리 저장된 제1 판단알고리즘의 입력값으로하여 사 용자의 성별 및 연령을 확률값으로 산출할 수 있다. 이하, 도 2에서 음성추출부는 사용자의 요청발화에 기초하여 제1 음성데이터('에어야')를 추출하고, 제 1 딥러닝부에서 제1 음성데이터('에어야')가 미리 저장된 제1 판단알고리즘의 입력값으로 입력된 것으로 가정하기로 한다. 제1 음성데이터('에어야')가 미리 저장된 제1 판단알고리즘의 입력값으로 입력된 경우, 출력값으로 사용자의 성별이 남성이고 연령이 성인일 제1 확률값을 0.9로 산출할 수 있다. 즉, 제1 딥러닝부는 사용자의 성 별이 남성이고 연령이 성인일 제1 확률값을 0.9로 판단할 수 있다. 제1 음성데이터('에어야')가 미리 저장된 제1 판단알고리즘의 입력값으로 입력된 경우, 출력값으로 사용자의 성별이 여성이고 연령이 성인일 제1 확률값을 0.02로 산출할 수 있다. 즉, 제1 딥러닝부는 사용자의 성 별이 여성이고 연령이 성인일 제1 확률값을 0.02로 산출할 수 있다. 제1 음성데이터('에어야')가 미리 저장된 제1 판단알고리즘의 입력값으로 입력된 경우, 출력값으로 사용자의 성별이 남성이고 연령이 노인일 제1 확률값을 0.03으로 산출할 수 있다. 즉, 제1 딥러닝부는 사용자의 성별이 남성이고 연령이 노인일 제1 확률값을 0.03으로 산출할 수 있다. 제1 음성데이터('에어야')가 미리 저장된 제1 판단알고리즘의 입력값으로 입력된 경우, 출력값으로 사용자의 성별이 여성이고 연령이 노인일 제1 확률값을 0.02으로 산출할 수 있다. 즉, 제1 딥러닝부는 사용자의 성별이 여성이고 연령이 노인일 제1 확률값을 0.02으로 산출할 수 있다. 제1 음성데이터('에어야')가 미리 저장된 제1 판단알고리즘의 입력값으로 입력된 경우, 출력값으로 사용자의 성별이 남성이고 연령이 어린이일 제1 확률값을 0.02으로 산출할 수 있다. 즉, 제1 딥러닝부는 사용자 의 성별이 남성이고 연령이 어린이일 제1 확률값을 0.02으로 산출할 수 있다. 제1 음성데이터('에어야')가 미리 저장된 제1 판단알고리즘의 입력값으로 입력된 경우, 출력값으로 사용자의 성별이 여성이고 연령이 어린이일 제1 확률값을 0.01으로 산출할 수 있다. 즉, 제1 딥러닝부는 사용자 의 성별이 여성이고 연령이 어린이일 제1 확률값을 0.01으로 산출할 수 있다. 이때, 제1 딥러닝부는 제1 확률값 중 가장 높은 확률값(0.9)에 대응하는 성별(남성) 및 연령(성인)을 사용 자의 성별 및 연령으로 결정할 수 있다. 음성인식기분배부는 성인남성의 요청발화를 인식하기 위한 어느 하나의 음성인식기를 결정할 수 있다. 음 성인식기분배부에 의해 선택된 어느 하나의 음성인식기는 어느 한 시점부터 다른 시점까지의 사용자의 요 청발화를 인식하고 이에 기초하여 제2 음성데이터를 추출할 수 있다. 즉, 제1 딥러닝부에서 사용자의 성별 및 연령이 성인남성으로 결정된 경우, 어느 하나의 음성인식기는 성인남성인 사용자의 요청발화를 인식하고 이에 기초하여 제2 음성데이터를 추출할 수 있다. 도 3은 본 발명의 한 실시예에 따른 사용자의 요청발화와 제1 변환텍스트를 설명하는 도면이다. 사용자의 성별 및 연령에 기초하여 음성인식기분배부는 사용자의 요청발화를 인식하기 위한 어느 하 나의 음성인식기를 결정할 수 있다. 어느 하나의 음성인식기는 사용자의 요청발화를 인식하고 이에 기초하여 제1 변환텍스트로 변할 수 있다. 이때, 어느 하나의 음성인식기가 사용자의 요청발화를 인식하는 과정에서 외부잡음이 포함되는 등, 다양한 외부요인 또는 내부요인에 의해서 사용자의 요청발화를 잘못 인식할 수 있다. 도 3을 참고하면, 성인남성인 사용자의 요청발화가 '에어야 오늘 날씨 알려줘'인 경우, 어느 하나의 음성인 식기는 사용자의 요청발화를 '에어야 오월의 일정을 예약해줘'로 잘못 인식할 수 있다. 어느 하나의 음성인식기는 이에 기초하여 '에어야 오월의 일정을 예약해줘'를 포함하는 제2 음성데이터를 추출 할 수 있다. 어느 하나의 음성인식기는 제2 음성데이터를 '에어야 오월의 일정을 예약해줘'로 구성된 제1 변환 텍스트로 변환할 수 있다. 또는, 성인 여성인 사용자의 요청발화가 '에어야 우리딸 진희에게 전화해줘'인 경우, 어느 하나의 음성인식 기는 사용자의 요청발화를 '에어야 ## 지니에게 전해줘'로 잘못 인식할 수 있다. 어느 하나의 음성인식기는 이에 기초하여 '에어야 ## 지니에게 전해줘'를 포함하는 제2 음성데이터를 추출할 수 있다. 어느 하나의 음성인식기는 제2 음성데이터를 '에어야 ## 지니에게 전해줘'로 구성된 제1 변환텍스트로 변 환할 수 있다. 또는, 어린이 남성인 사용자의 요청발화가 '에어야 뽀로로 6시에 재방송 틀어줘'인 경우, 어느 하나의 음성 인식기는 사용자의 요청발화를 '에어야 뽑기놀이 6시에 틀어줘'로 잘못 인식할 수 있다. 어느 하나의 음성인식기는 이에 기초하여 '에어야 뽑기놀이 6시에 틀어줘'를 포함하는 제2 음성데이터를 추출할 수 있다. 어느 하나의 음성인식기는 제2 음성데이터를 '에어야 뽑기놀이 6시에 틀어줘'로 구성된 제1 변환텍스 트로 변환할 수 있다. 또는, 어린이 여성인 사용자의 요청발화가 '에어야 영어공부하는 유투브 재생목록에 넣어줘'인 경우, 어느 하나의 음성인식기는 사용자의 요청발화를 '에어야 ##공부하는 유투브 재생하지마'로 잘못 인식할 수 있다. 어느 하나의 음성인식기는 이에 기초하여 '에어야 ##공부하는 유투브 재생하지마'를 포함하는 제2 음성데이터를 추출할 수 있다. 어느 하나의 음성인식기는 제2 음성데이터를 '에어야 ##공부하는 유투브 재생하지마'로 구성된 제1 변환텍스트로 변환할 수 있다. 상술한 바와 같이, 어느 하나의 음성인식기가 사용자의 요청발화를 인식하는 과정에서 외부잡음이 포함되는 등, 다양한 외부요인 또는 내부요인에 의해서 사용자의 요청발화를 잘못 인식할 수 있다. 이에 기초하여 제2 음성데이터를 추출하고 제1 변환텍스트를 생성할 수 있다. 도 4는 본 발명의 한 실시예에 따른 제2 딥러닝부를 설명하는 도면이다. 이하, 도 4 및 도 5에서 사용자의 성별 및 연령은 남성 및 성인이고, 사용자의 요청발화는 '에어야 오늘 날씨 알려줘'인 것으로 가정하고 설명하기로 한다. 제2 딥러닝부는 변환텍스트입력부, 제1 음성모델딥러닝부, 요청텍스트출력부, 기준텍스트 저장부, 제2 음성모델딥러닝부, 가중치값산출부, 제1 오류율산출부, 및 제2 오류율값산출 부를 포함할 수 있다. 변환텍스트입력부는 어느 하나의 음성인식기에서 변환된 제1 변환텍스트를 입력받을 수 있다. 구체적으로, 변환텍스트입력부는 '에어야 오월의 일정을 예약해줘'로 구성된 제1 변환텍스트를 입력받을 수 있다. 제1 음성모델딥러닝부에서 제1 변환텍스트는 미리 저장된 제1 딥러닝알고리즘의 입력값으로 입력될 수 있 다. 제1 음성모델딥러닝부에 미리 저장된 제1 딥러닝알고리즘은 출력값으로 제1 요청텍스트를 생성할 수 있다. 제1 음성모델딥러닝부는 이하 서술할 가중치값산출부에서 제공된 가중치값을 이용하여 제1 딥러닝알 고리즘을 조정할 수 있다. 제1 음성모델딥러닝부는 제1 변환텍스트를 조정된 제1 딥러닝알고리즘의 입력값 으로 입력하고 제1 요청텍스트를 출력하여 딥러닝을 수행할 수 있다. 제1 오류율산출부는 제1 음성모델딥러닝부에서 생성된 제1 음성모델딥러닝부에 입력된 제1 변 환텍스트와 제1 딥러닝알고리즘에서 출력된 제1 요청텍스트사이의 제1 오류율(또는, 제1 손실값)을 산출할 수 있다. 제1 오류율산출부는 가중치값산출부에 제1 오류율(또는, 제1 손실값)을 제공할 수 있다. 요청텍스트출력부는 제1 음성모델딥러닝부에 미리 저장되며 미세조정된 제1 딥러닝알고리즘에서 생성 된 제1 요청텍스트('에어야 오늘 날씨 알려줘')를 응답생성부(30, 도 1 참고)에 제공할 수 있다. 기준텍스트저장부는 제1 기준텍스트(또는, 제1 전사텍스트)를 미리 저장할 수 있다. 구체적으로, 기준텍스트저장부는 사용자의 요청발화에 상응하며 오류를 포함하지 않는'에어야 오월의 일정 을 예약해줘'로 구성된 제1 기준텍스트(또는, 제1 전사텍스트)를 미리 저장할 수 있다. 제2 음성모델딥러닝부는 기준텍스트저장부로부터 제1 기준텍스트(또는, 제1 전사텍스트)를 제공받을 수 있다. 제2 음성모델딥러닝부는 제1 기준텍스트(또는, 제1 전사텍스트)를 미리 저장된 제2 딥러닝알고리 즘의 입력값으로 입력하고, 제1 기준텍스트(또는, 제1 전사텍스트)와 동일한 제2 기준텍스트(또는, 제2 전사텍 스트)를 출력하도록 제2 딥러닝알고리즘을 미세조정하고 딥러닝을 수행할 수 있다. 구체적으로, 제2 음성모델딥러닝부는 기준텍스트저장부로부터 제공받은 제1 기준텍스트(또는, 제1 전 사텍스트)를 미리 저장된 제2 딥러닝알고리즘의 입력값으로하고, 제1 기준텍스트(또는, 제1 전사텍스트)와 동일 한 제2 기준텍스트(또는, 제2 전사텍스트)를 미리 저장된 제2 딥러닝알고리즘의 출력값으로하여 딥러닝을 수행 할 수 있다. 제2 오류율산출부는 제2 음성모델딥러닝부의 미리 저장된 제2 딥러닝알고리즘에 입력된 제1 기준텍 스트(또는, 제1 전사텍스트)와 제1 기준텍스트(또는, 제1 전사텍스트)가 입력되어 미리 저장된 제2 딥러닝알고 리즘에서 출력된 제2 기준텍스트(또는, 제2 전사텍스트) 사이의 제2 오류율을 산출할 수 있다. 제2 오류율산출부는 제2 오류율을 가중치값산출부에 제공할 수 있다. 가중치값산출부는 제1 오류율값과 제2 오류율값에 기초하여 제1 음성모델딥러닝부의 제1 딥러닝알고 리즘을 미세조정하기 위한 가중치값을 산출할 수 있다. 구체적으로, 가중치값은 하기 [수학식 1]로 표현될 수 있다. 가중치값 = a*제1 오류율값 + b* 제2 오류율값 단, a, b는 0.5 가중치값산출부는 가중치값을 제1 음성모델딥러닝부로 제공할 수 있다. 가중치값산출부에서 제 공된 가중치값을 제1 음성모델딥러닝부의 가중치값으로 결정하여 제1 딥러닝알고리즘을 조정하고, 제1 변 환텍스트를 조정된 제1 딥러닝알고리즘의 입력값으로 입력하여 제1 음성모델딥러닝부를 딥러닝시킬 수 있 다. 즉, 가중치값산출부로부터 제공된 가중치값은 은닉층에서 가산되는 가중치값들로 결정될 수 있다. 위 과정 을 통해서 제1 딥러닝알고리즘을 미세조정할 수 있다. 상술한 바와 같이 도 5를 참고하면, 본 발명의 한 실시예에 따른 제1 음성모델딥러닝부는 오류가 포함된 제1 변환텍스트를 미리 저장된 제1 딥러닝알고리즘의 입력값으로 입력하여 오류가 제거되어 사용자의 요청발화 에 정확히 상응하는 제1 요청텍스트를 결정할 수 있다. 추가로, 본 발명의 한 실시예에 따른 제1 음성모델딥러닝부는 오류가 포함된 제1 변환텍스트와 제1 요청텍 스트 사이에 산출된 제1 오류율값(또는, 제1 손실값) 및 제1 기준텍스트(또는, 제1 전사텍스트)를 입력값 및 제 2 기준텍스트(또는, 제2 전사텍스트)를 출력값으로 하여 산출된 제2 오류율값을 포함하는 가중치값을 제1 음성 모델딥러닝부의 가중치값으로 하여 제1 딥러닝알고리즘을 미세조정할 수 있다. 또한, 제1 음성모델딥러닝부는 제1 변환테스트를 조정된 제1 딥러닝알고리즘의 입력값으로 입력하고 사용 자의 요청발화에 정확히 상응하는 제1 요청텍스트를 생성할 수 있다. 이를 통해, 제1 딥러닝알고리즘의 정확도를 높일 수 있으며, 오류가 포함된 제1 변환텍스트가 입력되더라도, 오 류가 제거되어 사용자의 요청발화에 정확하게 대응하는 제1 요청텍스트를 결정할 수 있다. 도 5는 본 발명의 한 실시예에 따른 사용자의 발화의도 및 예측발화를 판단하고 응답을 생성하는 과정을 설명하 는 도면이다. 발화의도분류부는 사용자의 요청발화에 상응하는 제1 요청텍스트를 입력받을 수 있다. 발화의도분류부 는 제1 요청텍스트를 미리 저장된 의도분류알고리즘의 입력값으로 입력하여 사용자의 발화의도를 제2 확률 값으로 산출할 수 있다. 발화의도분류부는 제2 확률값에 기초하여 사용자의 발화요청에 기초한 발화의도를 결정할 수 있다. 도 5를 참고하면, 발화의도분류부는 제1 요청텍스트('에어야 오늘 날씨 알려줘')를 미리 저장된 의도분류 알고리즘의 입력값으로 입력하여 사용자의 발화의도를 제2 확률값으로 산출할 수 있다. 구체적으로, 제1 요청텍스트가 미리 저장된 의도분류알고리즘의 입력값으로 입력된 경우, 발화의도분류부 는 사용자의 발화의도가 '날씨'일 제2 확률값을 0.9로 산출할 수 있다. 발화의도분류부는 사용자의 발화의 도가 '옷'일 제2 확률값을 0.1로 산출할 수 있다. 발화의도분류부는 제2 확률값 중 가장 높은 확률값(0.9)에 대응하는 발화의도('날씨')를 사용자의 발화요 청에 기초한 발화의도로 결정할 수 있다. 발화의도분류부는 사용자의 발화의도에 기초하여 '날씨'를 포함 하는 발화의도데이터를 생성할 수 있다. 발화의도예측부는 사용자의 발화의도에 대응하는 발화의도데이터를 입력받을 수 있다. 발화의도예측부 는 발화의도데이터를 미리 저장된 의도예측알고리즘의 입력값으로 입력하여 사용자의 예측발화를 제3 확률 값으로 산출할 수 있다. 발화의도예측부는 제3 확률값에 기초하여 사용자의 예측발화를 결정할 수 있다. 도 5를 참고하면, 발화의도예측부는 발화의도데이터('날씨')를 미리 저장된 의도예측알고리즘의 입력값으 로 입력하여 다음 시점 이후의 제1 시점에서 사용자의 예측발화를 제3 확률값으로 산출할 수 있다. 구체적으로, 발화의도데이터가 미리 저장된 의도예측알고리즘의 입력값으로 입력된 경우, 발화의도예측부 는 제1 시점에서 사용자의 예측발화가 '옷'일 제3 확률값을 0.6으로 산출할 수 있다. 발화의도예측부는 다 음 시점 이후의 제1 시점에서 사용자의 예측발화가 '장소'일 제3 확률값을 0.4로 산출할 수 있다. 발화의도예측부는 제3 확률값 중 가장 높은 확률값(0.6)에 대응하는 예측발화('옷')를 제1 시점에서 사용 자의 예측발화로 결정할 수 있다. 발화의도예측부는 사용자의 예측발화에 기초하여 '옷'을 포함하는 제1 예측발화데이터를 생성할 수 있다. 또한, 발화의도예측부는 제1 예측발화데이터('옷')를 미리 저장된 의도예측알고리즘의 입력값으로 입력하 여 제1 시점 이후의 제2 시점에서 사용자의 예측발화를 제3 확률값으로 산출할 수 있다. 구체적으로, 제1 예측발화데이터가 미리 저장된 의도예측알고리즘의 입력값으로 입력된 경우, 발화의도예측부 는 제2 시점에서 사용자의 예측발화가 '노래'일 제3 확률값을 0.3으로 산출할 수 있다. 발화의도예측부 는 제2 시점에서 사용자의 예측발화가 '장소'일 제3 확률값을 0.7로 산출할 수 있다. 발화의도예측부는 제3 확률값 중 가장 높은 확률값(0.7)에 대응하는 예측발화('장소')를 제2 시점에서 사 용자의 예측발화로 결정할 수 있다. 발화의도예측부는 사용자의 예측발화에 기초하여 '장소'를 포함하는 제2 예측발화데이터를 생성할 수 있다. 발화의도분류부는 발화의도데이터('날씨') 및 예측발화데이터('옷', '장소')를 응답생성부에 제공할 수 있다. 응답텍스트생성부는 발화의도데이터 및 예측발화데이터를 미리 저장된 응답알고리즘의 입력값으로 입력하 여 사용자의 요청발화에 대한 응답텍스트를 생성할 수 있다. 구체적으로, 발화의도데이터('날씨') 및 예측발화데이터('옷', '장소')가 미리 저장된 응답알고리즘의 입력값으 로 입력된 경우, '오늘 날씨는 덥습니다. 냉방병 예방을 위해 얇고 긴 옷을 추천드립니다.'로 구성된 응답텍스 트가 출력으로 생성될 수 있다. 즉, 응답텍스트생성부는 '오늘 날씨는 덥습니다. 냉방병 예방을 위해 얇고 긴 옷을 추천드립니다.'로 구성 된 응답텍스트를 생성할 수 있다. 텍스트-음성변환부는 응답텍스트('오늘 날씨는 덥습니다. 냉방병 예방을 위해 얇고 긴 옷을 추천드립니 다.')를 음성데이터로 변환할 수 있다. 텍스트-음성변환부는 음성데이터를 인공지능스피커에 전달할 수 있다. 인공지능스피커는 음성데이터('오늘 날씨는 덥습니다. 냉방병 예방을 위해 얇고 긴 옷을 추천드립니다.')를 사용자의 요청발화에 대한 응답으로 출력할 수 있다. 도 6은 본 발명의 한 실시예에 따른 인공지능에 기초한 음성 처리 방법을 설명하는 도면이다. 단계(S10)에서 음성추출부가 어느 한 시점에서의 사용자의 요청발화에 기초하여 제1 음성데이터를 추출할 수 있 다. 구체적으로, 사용자가 인공지능스피커에 어느 한 시점에서 다른 한 시점까지 요청발화를 하는 경우, 음성 추출부는 어느 한 시점에서의 사용자의 요청발화에 기초하여 제1 음성데이터를 추출할 수 있다. 단계(S11)에서 제1 딥러닝부가 제1 음성데이터를 미리 저장된 제1 판단알고리즘의 입력값으로 입력하여 사용자 의 성별 및 연령을 판단할 수 있다. 구체적으로, 제1 딥러닝부는 제1 음성데이터를 미리 저장된 제1 판단알고리즘의 입력값으로 하여 사용자 의 성별 및 연령을 제1 확률값으로 산출할 수 있다. 이때, 제1 딥러닝부는 산출된 제1 확률값 중 가장 높은 확률값에 대응하는 성별 및 연령을 사용자의 성별 및 연령으로 결정할 수 있다. 단계(S12)에서 음성인식기분배부가 사용자의 성별 및 연령에 대응하는 어느 하나의 음성인식기를 결정할 수 있 다. 구체적으로, 음성인식기분배부는 사용자의 성별 및 연령에 따라서 어느 한 시점에서 다른 시점까지 사 용자의 요청발화를 인식하고, 음성데이터를 생성하는 서로 다른 복수의 음성인식기를 포함할 수 있다. 음 성인식기분배부는 사용자의 성별 및 연령에 대응하는 어느 하나의 음성인식기를 결정할 수 있다. 단계(S13)에서 어느 하나의 음성인식기가 어느 한 시점에서 다른 시점 까지의 사용자의 요청발화에 기초하여 제 2 음성데이터를 추출할 수 있다. 구체적으로, 사용자의 성별 및 연령에 대응하는 어느 하나의 음성인식기를 이용하여 어느 한 시점에서 다른 시 점까지의 사용자의 요청발화를 인식할 수 있다. 어느 하나의 음성인식기는 사용자의 요청발화를 인식하 고 이에 기초하여 제2 음성데이터를 추출할 수 있다. 단계(S14)에서 음성-텍스트변환부가 제2 음성데이터를 제1 변환텍스트로 변환할 수 있다. 구체적으로, 음성-텍스트변환부는 음성인식기분배부에 포함된 어느 하나의 음성인식기에서 추출된 제 2 음성데이터를 제1 변환텍스트로 변환할 수 있다. 단계(S15)에서 제1 음성모델딥러닝부에 미리 저장된 제1 딥러닝알고리즘의 입력값으로 제1 변환텍스트를 입력하 여 제1 요청텍스트를 생성할 수 있다. 단계(S16)에서 발화의도분류부에 미리 저장된 의도분류알고리즘의 입력값으로 제1 요청텍스트를 입력하여 발화 의도를 판단하고, 발화의도데이터를 생성할 수 있다. 구체적으로, 발화의도분류부는 제1 요청텍스트를 미리 저장된 의도분류알고리즘의 입력값으로 입력하여 사 용자의 발화의도를 제2 확률값으로 산출할 수 있다. 발화의도분류부는 산출된 제2 확률값 중 가장 높은 확 률값에 대응하는 발화의도를 사용자의 발화의도로 결정할 수 있다. 단계(S17)에서 발화의도예측부에 미리 저장된 의도예측알고리즘의 입력값으로 발화의도데이터를 입력하여 예측 발화를 판단하고, 예측발화데이터를 생성할 수 있다. 구체적으로, 발화의도예측부는 발화의도데이터를 미리 저장된 의도예측알고리즘의 입력값으로 입력하여 사 용자의 예측발화를 제3 확률값으로 산출할 수 있다. 이때, 발화의도예측부는 산출된 제3 확률값 중 가장 높은 확률값에 대응하는 예측발화를 사용자의 예측발화로 결정할 수 있다. 단계(S18)에서 응답텍스트생성부에 미리 저장된 응답알고리즘의 입력값으로 발화의도데이터와 예측발화데이터를 입력하여 응답을 생성할 수 있다. 구체적으로, 응답텍스트생성부는 발화의도데이터 및 예측발화데이터를 미리 저장된 응답알고리즘의 입력값 으로 입력하여 사용자의 요청발화에 대한 응답을 생성할 수 있다. 도 7은 본 발명의 한 실시예에 다른 제1 딥러닝알고리즘을 조정하는 방법을 설명하는 도면이다. 단계(S20)에서 요청텍스트출력부는 제1 변환텍스트 및 제1 요청텍스트를 제1 오류율산출부에 제공할 수 있다. 구체적으로, 제1 음성모델딥러닝부에 미리 학습되어 저장된 제1 음성딥러닝부의 입력값인 제1 변환텍 스트와 출력값인 제1 요청텍스트는 요청텍스트출력부에 제공될 수 있다. 이때, 요청텍스트출력부는 제1 변환텍스트 및 제1 요청텍스트를 제1 오류율산출부에 제공할 수 있다. 단계(S21)에서 제1 오류율산출부가 제1 변환텍스트와 제1 요청텍스트 사이의 제1 오류율(또는, 제1 손실 값)을 산출할 수 있다. 단계(S22)에서 기준텍스트저장부는 제1 기준텍스트(또는, 제1 전사텍스트)를 제2 음성모델딥러닝부에 제공할 수 있다. 단계(S23)에서 제2 음성모델딥러닝부에 미리 저장된 제2 딥러닝알고리즘의 입력값으로 제1 기준텍스트(또 는, 제1 전사텍스트)를 입력하고, 출력값을 출력할 수 있다. 단계(S24)에서 제2 오류율산출부에서 제1 기준텍스트(또는, 제1 전사텍스트)와 제2 기준텍스트(또는, 제2 전사텍스트) 사이의 제2 오류율을 산출할 수 있다. 구체적으로, 제2 음성모델딥러닝부는 제1 기준텍스트(또는, 제1 전사텍스트)와 동일한 제2 기준텍스트(또 는, 제2 전사텍스트)를 출력하도록 제2 음성모델딥러닝부를 미세조정하고 딥러닝할 수 있다. 구체적으로, 제2 오류율산출부는 기준텍스트저장부로부터 제공받은 제1 기준텍스트(또는, 제1 전사 텍스트)를 미리 저장된 제2 딥러닝알고리즘의 입력값으로하고, 출력값 사이의 제2 오류율(또는, 제2 손실값)을 산출할 수 있다. 제2 음성모델딥러닝부는 제2 오류율(또는, 제2 손실값)을 이용하여 제2 딥러닝알고리즘의 출력값이 제1 기 준텍스트(또는, 제1 전사텍스트)와 동일한 제2 기준텍스트(또는, 제2 전사텍스트)가 될 때까지 제2 딥러닝알고 리즘을 미세조정할 수 있다. 단계(S25)에서 가중치값산출부에서 제1 오류율(또는, 제1 손실값)과 제2 오류율(또는, 제2 손실값)을 이용 하여 가중치값을 산출할 수 있다. 구체적으로, 가중치값산출부는 제1 오류율값(또는, 제1 손실값)과 제2 오류율값(또는, 제2 손실값)에 기초 하여 제1 음성모델딥러닝부를 미세조정하기 위한 가중치값을 산출할 수 있다. 단계(S26)에서 가중치값산출부가 가중치값을 제1 음성모델딥러닝부에 제공할 수 있다. 단계(S27)에서 제1 음성모델딥러닝부는 가중치값에 기초하여 미리 저장된 제1 딥러닝알고리즘을 미세조정할 수 있다. 구체적으로, 가중치값산출부에서 제공된 가중치값을 제1 음성모델딥러닝부의 가중치값으로 하여 제1 딥러닝알고리즘을 조정하고, 제1 변환텍스트를 미세조정된 제1 딥러닝알고리즘의 입력값으로 입력하여 제1 음성 모델딥러닝부를 딥러닝시킬 수 있다. 지금까지 참조한 도면과 기재된 발명의 상세한 설명은 단지 본 발명의 예시적인 것으로서, 이는 단지 본 발명을 설명하기 위한 목적에서 사용된 것이지 의미 한정이나 특허청구범위에 기재된 본 발명의 범위를 제한하기 위하 여 사용된 것은 아니다. 그러므로 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 특허청구 범위의 기술적 사상에 의해 정해져야 할 것이다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(Arithmetic Logic Unit), 디지털 신호 프로세서(Digital Signal Processor), 마 이크로컴퓨터, FPGA(Field Programmable Gate Array), PLU(Programmable Logic Unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다.처리 장치는 운영 체제 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있 다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해당 기술 분야에서 통 상의 지식을 가진 자는 처리 장치가 복수 개의 처리 요소(Processing Element) 및/또는 복수 유형의 처리요소를 포함할 수 있음을 이해할 것이다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(Parallel Processor) 와 같은, 다른 처리 구성(Processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(Computer Program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하 여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody) 될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분 산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체 에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CDROM, DVD와 같은 광기록 매체(optical media) 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로 그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러 에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트 웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2022-0041966", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속 한다."}
{"patent_id": "10-2022-0041966", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 한 실시예에 따른 인공지능에 기초한 대화상황예측과 의도분류 시스템을 나타내는 도면이다. 도 2는 본 발명의 한 실시예에 따른 사용자의 성별 및 연령을 판단하고 제2 음성데이터를 추출하는 과정을 설명 하는 도면이다. 도 3은 본 발명의 한 실시예에 따른 사용자의 요청발화와 제1 변환텍스트를 설명하는 도면이다. 도 4는 본 발명의 한 실시예에 따른 제2 딥러닝부를 설명하는 도면이다. 도 5는 본 발명의 한 실시예에 따른 사용자의 발화의도 및 예측발화를 판단하고 응답을 생성하는 과정을 설명하 는 도면이다. 도 6은 본 발명의 한 실시예에 따른 인공지능에 기초한 대화상황예측과 의도분류 방법을 설명하는 도면이다. 도 7은 본 발명의 한 실시예에 다른 제1 딥러닝알고리즘을 조정하는 방법을 설명하는 도면이다."}
