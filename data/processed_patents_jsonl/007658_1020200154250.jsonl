{"patent_id": "10-2020-0154250", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0067719", "출원번호": "10-2020-0154250", "발명의 명칭": "딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치 및 그 방법", "출원인": "한국기술교육대학교 산학협력단", "발명자": "유승열"}}
{"patent_id": "10-2020-0154250", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "그리핑대상 물체의 마커 인식 위치에서 촬영한 영상으로부터 마커를 인식하는 마커 인식부;피수용대상 물체의 인식 위치에서 촬영한 영상을 기 설정된 딥러닝 학습모델에 적용하여 피수용대상 물체를 인식하는 피수용대상 물체 인식부; 및상기 마커의 인식 및 상기 피수용대상 물체의 인식을 토대로, 상기 그리핑대상 물체를 그리핑하여 상기 피수용대상 물체로 드롭하도록 제어하는 로봇팔 제어부;를 포함하며,상기 마커와 피수용대상 물체를 비전인식을 통해서 인식하는 것을 특징으로 하는 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치."}
{"patent_id": "10-2020-0154250", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 마커는,흰색 셀과 검정색 셀을 조합한 n*n 2차원 패턴의 ArUco 마커, 또는체크보드와 4개의 ArUco 마커가 다이아몬드 형태로 배열된 chArUco 마커를 사용하는 것을 특징으로 하는 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치."}
{"patent_id": "10-2020-0154250", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 로봇 제어장치는,상기 피수용대상 물체에 대하여 복수의 각도에서 촬영하여 획득한 데이터세트를 학습하여 피수용대상 물체의 위치와 자세를 추정하기 위한 딥러닝 학습모델을 생성하는 학습부;를 더 포함하며,상기 데이터세트는, 상기 피수용대상 물체를 적어도 4개 이상의 서로 다른 각도에서 상기 피수용대상 물체를 포함하도록 촬영한 영상과, 상기 촬영한 영상을 3차원 모델링한 후 상기 3차원 모델링한 영상을 상기 촬영한 영상에 역투영하여 이진화 처리한 마스크를 토대로 생성되며,상기 학습부는, 상기 생성한 데이터세트의 피수용대상 물체를 촬영한 영상과 이진화 처리한 마스크의 매핑관계를 Mask R-CNN 모델로 학습하여 딥러닝 학습모델을 생성하는 것을 더 포함하는 것을 특징으로 하는 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치."}
{"patent_id": "10-2020-0154250", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 마커 인식부는,상기 그리핑대상 물체에 부착된 마커를 인식하기 위한 마커 인식 위치에서, 로봇의 베이스에서 상기 인식한 마커로의 변환행렬과 상기 로봇의 베이스에서 로봇팔로의 변환행렬을 곱하여 상기 마커에서 상기 로봇팔로의 변환행렬을 구하고;상기 로봇팔의 좌표계를 기준으로 상기 로봇팔에서 상기 그리핑대상 물체까지의 X, Y, Z축 거리정보를 참조하여상기 로봇팔에서 상기 그리핑대상 물체로의 변환행렬을 구하고;상기 로봇이 상기 그리핑대상 물체를 그리핑하기 위한 실행 위치로 이동함에 따라 변경된 로봇의 베이스에서 상기 인식한 마커로의 변환행렬과 상기 마커 인식 위치에서 구한 상기 마커에서 상기 로봇팔로의 변환행렬을 곱하공개특허 10-2022-0067719-3-여 최종적인 상기 로봇의 베이스에서 상기 로봇팔로의 변환행렬을 구하고;상기 실행 위치에서 구한 상기 로봇의 베이스에서 상기 로봇팔로의 변환행렬과 상기 마커 인식 위치에서 구한상기 로봇팔에서 상기 그리핑대상 물체로의 변환행렬을 곱하여 최종적인 상기 로봇의 베이스에서 상기 그리핑대상 물체로의 변환행렬을 구함으로써, 상기 그리핑대상 물체의 좌표를 추출하며;상기 로봇의 베이스와 상기 마커의 위치가 변경되더라도 상기 로봇팔을 상기 그리핑대상 물체로 이동시킬 수 있는 것을 특징으로 하는 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치."}
{"patent_id": "10-2020-0154250", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 피수용대상 물체 인식부는,상기 피수용대상 물체의 인식 위치에서, 로봇의 베이스에서 상기 피수용대상 물체로의 변환행렬과 상기 로봇의베이스에서 로봇팔로의 변환행렬을 곱하여 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬을 구하고;상기 구한 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬에서 회전행렬을 추출하여 위치 벡터를 삭제한새로운 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬을 구하고;상기 구한 새로운 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬과 상기 구한 로봇의 베이스에서 상기 피수용대상 물체로의 변환행렬을 곱하여 최종적인 상기 로봇의 베이스에서 상기 피수용대상 물체로의 변환행렬을구함으로써, 상기 피수용대상 물체의 좌표를 추출하며;상기 구한 최종적인 상기 로봇의 베이스에서 상기 피수용대상 물체로의 변환행렬을 통해서, 상기 로봇팔이 상기피수용대상 물체의 좌표축을 따라가지 않도록 하는 것을 특징으로 하는 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치."}
{"patent_id": "10-2020-0154250", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "로봇 제어장치에서, 그리핑대상 물체의 마커 인식 위치에서 촬영한 영상으로부터 마커를 인식하는 마커 인식 단계;상기 로봇 제어장치에서, 피수용대상 물체의 인식 위치에서 촬영한 영상을 기 설정된 딥러닝 학습모델에 적용하여 피수용대상 물체를 인식하는 피수용대상 물체 인식 단계; 및상기 로봇 제어장치에서, 상기 마커의 인식 및 상기 피수용대상 물체의 인식을 토대로, 상기 그리핑대상 물체를그리핑하여 상기 피수용대상 물체로 드롭하도록 제어하는 로봇팔 제어 단계;를 포함하며,상기 마커와 피수용대상 물체를 비전인식을 통해서 인식하는 것을 특징으로 하는 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어방법."}
{"patent_id": "10-2020-0154250", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 로봇 제어방법은,상기 로봇 제어장치에서, 상기 피수용대상 물체에 대하여 복수의 각도에서 촬영한 데이터세트를 학습하여 피수용대상 물체의 위치와 자세를 추정하기 위한 딥러닝 학습모델을 생성하는 학습 단계;를 더 포함하며,상기 데이터세트는, 상기 피수용대상 물체를 적어도 4개 이상의 서로 다른 각도에서 상기 피수용대상 물체를 포함하도록 촬영한 영상과, 상기 촬영한 영상을 3차원 모델링한 후 상기 3차원 모델링한 영상을 상기 촬영한 영상에 역투영하여 이진화 처리한 마스크를 토대로 생성되며,상기 학습 단계는, 상기 생성한 데이터세트의 피수용대상 물체를 촬영한 영상과 이진화 처리한 마스크의 매핑관계를 Mask R-CNN 모델로 학습하여 딥러닝 학습모델을 생성하는 것을 더 포함하는 것을 특징으로 하는 딥러닝과마커를 이용한 비전인식을 통한 로봇 제어방법."}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치 및 그 방법에 관한 것으로, 자동화된 생산공 정에서 로봇을 이용하여 특정 위치에 구비된 그리핑대상 물체를 다른 위치에 구비된 피수용대상 물체로 이동시킬 때, 상기 그리핑대상 물체에 부착된 마커를 인식하여 좌표를 추출하고, 미리 생성해둔 딥러닝 학습모델을 통해 상기 피수용대상 물체를 인식하여 좌표를 추출하며, 상기 추출한 그리핑 대상물체와 피수용대상 물체의 좌표에 대한 정보를 토대로 로봇의 그리핑과 드롭을 정밀하게 제어함으로써, 딥러닝과 마커를 이용한 비전인식을 통해서 상기 그리핑대상 물체를 상기 피수용대상 물체로 정확하게 이동시킬 수 있는 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치 및 그 방법에 관한 것으로, 더욱 상세하게는 자동화된 생산공정에서 로봇을 이용하여 특정 위치에 구비된 그리핑대상 물체를 다른 위치에 구비된 피수용대상 물체로 이동시킬 때, 상기 그리핑대상 물체에 부착된 마커를 인식하여 좌표를 추출하고, 미리 생성해둔 딥러닝 학습모델을 통해 상기 피수용대상 물체를 인식하여 좌표를 추출하며, 상기 추출한 그리핑 대상물체와 피수용대 상 물체의 좌표에 대한 정보를 토대로 로봇의 그리핑과 드롭을 정밀하게 제어함으로써, 딥러닝과 마커를 이용한 비전인식을 통해서 상기 그리핑대상 물체를 상기 피수용대상 물체로 정확하게 이동시킬 수 있는 장치 및 그 방 법에 관한 것이다."}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "4차 산업혁명은 정보통신기술과 기존 산업 분야의 융합을 통해, 지능화, 자동화 및 연결성이 극대화된 산업 환 경의 변화를 의미하는 것으로서, 인공지능, 사물인터넷, 빅데이터, 로봇, 자율주행, 클라우드 컴퓨팅 등이 주요 기술 동력으로 알려져 있다. 이 중에서 로봇 분야는 인공지능 기술과 정보통신기술의 발달을 바탕으로 새로운 제품과 시장을 모색하고 있으 며, 저출산과 고령화로 인한 노동 인구 감소와 생산성 혁신에 대한 사회적 요구, 제4차 산업혁명의 기술적 토대 를 바탕으로 로봇에 대한 대중과 시장의 관심이 점점 커지고 있다. 상기 로봇을 물류나 배송에 적용하는 경우, 상기 로봇을 원하는 위치로 이동한 후 로봇팔을 통해 물건을 그리핑 하여 적재나 집하, 분류, 포장을 하는 조작을 수행하게 되는데, 이때 컴퓨터 비전의 역할이 매우 중요하다. 상기 컴퓨터 비전은 인공지능의 한 분야로 컴퓨터를 사용하여 인간의 시각적인 인식 능력 일반을 재현하는 것으 로서, 상기 물류나 배송 등에 사용하는 로봇에 적용할 경우 카메라를 통해 촬영한 영상으로부터 특정 물건의 위 치나 자세를 확인하는 작업에 사용된다. 그러나, 상기 로봇을 원하는 위치로 이동시킨 후 로봇팔을 통해 소정의 물건을 그리핑하거나, 혹은 상기 그리핑 한 물건을 특정 위치에 구비된 다른 물건에 드롭하여 결합 등의 작업을 수행하고자 할 때, 카메라나 센서를 통 해 물건의 위치나 자세를 정확하게 인식하지 못하면, 그리핑이나 드롭 작업이 부정확해지는 문제가 발생한다. 따라서 본 발명에서는 특정 위치에 구비된 그리핑대상 물체에 부착된 마커를 인식하여 좌표를 추출하고, 미리 생성해둔 딥러닝 학습모델을 통해 다른 위치에 구비된 피수용대상 물체를 인식하여 좌표를 추출하며, 상기 추출 한 그리핑 대상물체와 피수용대상 물체의 좌표정보를 토대로 로봇의 그리핑과 드롭을 정밀하게 제어함으로써, 상기 그리핑대상 물체를 상기 피수용대상 물체로 이송할 때 정확도를 높일 수 있는 방안을 제시하고자 한다."}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "다음으로 본 발명의 기술분야에 존재하는 선행기술에 대하여 간단하게 설명하고, 이어서 본 발명이 상기 선행기 술에 비해서 차별적으로 이루고자 하는 기술적 사항에 대해서 기술하고자 한다. 먼저 한국공개특허 제2020-0069713호(2020.06.17.)는 용접로봇의 작업 경로 생성방법에 관한 것으로, 작업 대상 물 각 면 임의의 위치에 마커를 부착하고, 교시 조작기로 마커가 부착된 작업 대상물을 촬영하며, 교시 조작기 가 촬영된 마커와 비전(vision)인식을 통해 작업 경로를 생성하는 용접로봇의 작업 경로 생성방법에 관한 것이다. 즉, 상기 선행기술은 작업 대상물의 형상을 인식하고, 용접선의 방향 및 용접선의 길이를 추출하여 용접로봇의 작업 경로를 생성하고자 한 용접로봇의 작업 경로를 생성하는 방법에 대해 기재하고 있다. 하지만, 본 발명은 상기 그리핑대상 물체에 부착된 마커를 통해서 추출한 상기 그리핑대상 물체의 좌표와 미리 생성해둔 딥러닝 학습모델을 이용하여 추정한 상기 피수용대상 물체의 위치와 자세를 통해서 추출한 상기 피수 용대상 물체의 좌표에 대한 정보를 토대로 로봇의 그리핑과 드롭을 정밀하게 제어하는 것이므로, 상기 선행기술 과 본 발명은 현저한 구성상 차이점이 있다. 또한 한국공개특허 제2018-0114698호(2018.10.19.)는 다관절 로봇의 작업 궤적 생성을 위한 효율적인 학습 모델 및 학습 기법에 관한 것으로, 로봇의 센싱 데이터가 처리된 인지 정보를 바탕으로 작업을 완료하기 위한 로봇 관절 궤적을 효율적으로 생성하는 기법에 대한 것이다. 즉, 상기 선행기술은 다관절 로봇의 궤적을 생성하기 위한 학습 모델을 제안하며, 실시간성을 보장할 수 있도록 연산량을 줄이고, 작업을 완료할 수 있는 최적의 궤적에 근사화할 수 있는 학습 알고리즘을 제공하는 시스템 및그 방법을 기재하고 있다. 반면에 본 발명은, 마커를 이용하여 추출한 상기 그리핑대상 물체의 좌표와 미리 생성해둔 딥러닝 학습모델을 이용하여 추출한 상기 피수용대상 물체의 좌표에 대한 정보를 토대로 로봇의 그리핑과 드롭을 정밀하게 제어하 는 것이므로, 상기 선행기술과 본 발명은 기술적 구성의 차이점이 분명하다."}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위해 창작된 것으로서, 딥러닝과 마커를 이용한 비전인식을 통해서, 특정 위치에 구비된 그리핑대상 물체를 다른 위치에 구비된 피수용대상 물체로 이동시킬 때, 로봇의 그리핑과 드롭을 정밀하게 제어할 수 있는 장치 및 그 방법을 제공하는 것을 목적으로 한다. 또한 본 발명은 로봇에 구비된 카메라로 촬영한 영상으로부터 상기 그리핑대상 물체에 부착된 마커를 인식하고, 상기 인식한 마커를 통해서 상기 그리핑대상 물체의 좌표를 추출할 수 있는 장치 및 그 방법을 제공하는 것을 다른 목적으로 한다. 또한 본 발명은 상기 피수용대상 물체에 대하여 여러 각도에서 촬영한 데이터세트를 학습하여 딥러닝 학습모델 을 생성하고, 로봇에 구비된 카메라로 촬영한 영상을 상기 생성한 딥러닝 학습모델에 입력하여 상기 피수용대상 물체의 위치와 자세를 추출하며, 상기 추출한 피수용대상 물체의 위치와 자세를 통해서 상기 피수용대상 물체의 좌표를 추출할 수 있는 장치 및 그 방법을 제공하는 것을 또 다른 목적으로 한다. 또한 본 발명은 상기 그리핑대상 물체에 부착된 마커를 통해서 추출한 상기 그리핑대상 물체의 좌표와 미리 생 성해둔 딥러닝 학습모델을 이용하여 추정한 상기 피수용대상 물체의 위치와 자세를 통해서 추출한 상기 피수용 대상 물체의 좌표에 대한 정보를 토대로 로봇의 그리핑과 드롭을 정밀하게 제어할 수 있는 장치 및 그 방법을 제공하는 것을 또 다른 목적으로 한다."}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치는, 그리핑대상 물체의 마 커 인식 위치에서 촬영한 영상으로부터 마커를 인식하는 마커 인식부; 피수용대상 물체의 인식 위치에서 촬영한 영상을 기 설정된 딥러닝 학습모델에 적용하여 피수용대상 물체를 인식하는 피수용대상 물체 인식부; 및 상기 마커의 인식 및 상기 피수용대상 물체의 인식을 토대로, 상기 그리핑대상 물체를 그리핑하여 상기 피수용대상 물체로 드롭하도록 제어하는 로봇팔 제어부;를 포함하며, 상기 마커와 피수용대상 물체를 비전인식을 통해서 인 식하는 것을 특징으로 한다. 또한 상기 마커는, 흰색 셀과 검정색 셀을 조합한 n*n 2차원 패턴의 ArUco 마커, 또는 체크보드와 4개의 ArUco 마커가 다이아몬드 형태로 배열된 chArUco 마커를 사용하는 것을 특징으로 한다. 또한 상기 로봇 제어장치는, 상기 피수용대상 물체에 대하여 복수의 각도에서 촬영하여 획득한 데이터세트를 학 습하여 피수용대상 물체의 위치와 자세를 추정하기 위한 딥러닝 학습모델을 생성하는 학습부;를 더 포함하며, 상기 데이터세트는, 상기 피수용대상 물체를 적어도 4개 이상의 서로 다른 각도에서 상기 피수용대상 물체를 포 함하도록 촬영한 영상과, 상기 촬영한 영상을 3차원 모델링한 후 상기 3차원 모델링한 영상을 상기 촬영한 영상 에 역투영하여 이진화 처리한 마스크를 토대로 생성되며, 상기 학습부는, 상기 생성한 데이터세트의 피수용대상 물체를 촬영한 영상과 이진화 처리한 마스크의 매핑관계를 Mask R-CNN 모델로 학습하여 딥러닝 학습모델을 생성 하는 것을 더 포함하는 것을 특징으로 한다. 또한 상기 마커 인식부는, 상기 그리핑대상 물체에 부착된 마커를 인식하기 위한 마커 인식 위치에서, 로봇의 베이스에서 상기 인식한 마커로의 변환행렬과 상기 로봇의 베이스에서 로봇팔로의 변환행렬을 곱하여 상기 마커 에서 상기 로봇팔로의 변환행렬을 구하고; 상기 로봇팔의 좌표계를 기준으로 상기 로봇팔에서 상기 그리핑대상 물체까지의 X, Y, Z축 거리정보를 참조하여 상기 로봇팔에서 상기 그리핑대상 물체로의 변환행렬을 구하고; 상 기 로봇이 상기 그리핑대상 물체를 그리핑하기 위한 실행 위치로 이동함에 따라 변경된 로봇의 베이스에서 상기 인식한 마커로의 변환행렬과 상기 마커 인식 위치에서 구한 상기 마커에서 상기 로봇팔로의 변환행렬을 곱하여 최종적인 상기 로봇의 베이스에서 상기 로봇팔로의 변환행렬을 구하고; 상기 실행 위치에서 구한 상기 로봇의 베이스에서 상기 로봇팔로의 변환행렬과 상기 마커 인식 위치에서 구한 상기 로봇팔에서 상기 그리핑대상 물체 로의 변환행렬을 곱하여 최종적인 상기 로봇의 베이스에서 상기 그리핑대상 물체로의 변환행렬을 구함으로써,상기 그리핑대상 물체의 좌표를 추출하며; 상기 로봇의 베이스와 상기 마커의 위치가 변경되더라도 상기 로봇팔 을 상기 그리핑대상 물체로 이동시킬 수 있는 것을 특징으로 한다. 또한 상기 피수용대상 물체 인식부는, 상기 피수용대상 물체의 인식 위치에서, 로봇의 베이스에서 상기 피수용 대상 물체로의 변환행렬과 상기 로봇의 베이스에서 로봇팔로의 변환행렬을 곱하여 상기 피수용대상 물체에서 상 기 로봇팔로의 변환행렬을 구하고; 상기 구한 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬에서 회전행 렬을 추출하여 위치 벡터를 삭제한 새로운 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬을 구하고; 상기 구한 새로운 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬과 상기 구한 로봇의 베이스에서 상기 피수용 대상 물체로의 변환행렬을 곱하여 최종적인 상기 로봇의 베이스에서 상기 피수용대상 물체로의 변환행렬을 구함 으로써, 상기 피수용대상 물체의 좌표를 추출하며; 상기 구한 최종적인 상기 로봇의 베이스에서 상기 피수용대 상 물체로의 변환행렬을 통해서, 상기 로봇팔이 상기 피수용대상 물체의 좌표축을 따라가지 않도록 하는 것을 특징으로 한다. 아울러, 본 발명의 일 실시예에 따른 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어방법은, 로봇 제어장치 에서, 그리핑대상 물체의 마커 인식 위치에서 촬영한 영상으로부터 마커를 인식하는 마커 인식 단계; 상기 로봇 제어장치에서, 피수용대상 물체의 인식 위치에서 촬영한 영상을 기 설정된 딥러닝 학습모델에 적용하여 피수용 대상 물체를 인식하는 피수용대상 물체 인식 단계; 및 상기 로봇 제어장치에서, 상기 마커의 인식 및 상기 피수 용대상 물체의 인식을 토대로, 상기 그리핑대상 물체를 그리핑하여 상기 피수용대상 물체로 드롭하도록 제어하 는 로봇팔 제어 단계;를 포함하며, 상기 마커와 피수용대상 물체를 비전인식을 통해서 인식하는 것을 특징으로 한다. 또한 상기 로봇 제어방법은, 상기 로봇 제어장치에서, 상기 피수용대상 물체에 대하여 복수의 각도에서 촬영한 데이터세트를 학습하여 피수용대상 물체의 위치와 자세를 추정하기 위한 딥러닝 학습모델을 생성하는 학습 단계;를 더 포함하며, 상기 데이터세트는, 상기 피수용대상 물체를 적어도 4개 이상의 서로 다른 각도에서 상기 피수용대상 물체를 포함하도록 촬영한 영상과, 상기 촬영한 영상을 3차원 모델링한 후 상기 3차원 모델링한 영 상을 상기 촬영한 영상에 역투영하여 이진화 처리한 마스크를 토대로 생성되며, 상기 학습 단계는, 상기 생성한 데이터세트의 피수용대상 물체를 촬영한 영상과 이진화 처리한 마스크의 매핑관계를 Mask R-CNN 모델로 학습하 여 딥러닝 학습모델을 생성하는 것을 더 포함하는 것을 특징으로 한다. 또한 상기 마커 인식 단계는, 상기 그리핑대상 물체에 부착된 마커를 인식하기 위한 마커 인식 위치에서, 로봇 의 베이스에서 상기 인식한 마커로의 변환행렬과 상기 로봇의 베이스에서 로봇팔로의 변환행렬을 곱하여 상기 마커에서 상기 로봇팔로의 변환행렬을 구하는 단계; 상기 로봇팔의 좌표계를 기준으로 상기 로봇팔에서 상기 그 리핑대상 물체까지의 X, Y, Z축 거리정보를 참조하여 상기 로봇팔에서 상기 그리핑대상 물체로의 변환행렬을 구 하는 단계; 상기 로봇이 상기 그리핑대상 물체를 그리핑하기 위한 실행 위치로 이동함에 따라 변경된 로봇의 베 이스에서 상기 인식한 마커로의 변환행렬과 상기 마커 인식 위치에서 구한 상기 마커에서 상기 로봇팔로의 변환 행렬을 곱하여 최종적인 상기 로봇의 베이스에서 상기 로봇팔로의 변환행렬을 구하는 단계; 및 상기 실행 위치 에서 구한 상기 로봇의 베이스에서 상기 로봇팔로의 변환행렬과 상기 마커 인식 위치에서 구한 상기 로봇팔에서 상기 그리핑대상 물체로의 변환행렬을 곱하여 최종적인 상기 로봇의 베이스에서 상기 그리핑대상 물체로의 변환 행렬을 구하는 단계;를 수행함으로써, 상기 그리핑대상 물체의 좌표를 추출하는 것이며, 상기 로봇의 베이스와 상기 마커의 위치가 변경되더라도 상기 로봇팔을 상기 그리핑대상 물체로 이동시킬 수 있는 것을 특징으로 한다. 또한 상기 피수용대상 물체 인식 단계는, 상기 피수용대상 물체의 인식 위치에서, 로봇의 베이스에서 상기 피수 용대상 물체로의 변환행렬과 상기 로봇의 베이스에서 로봇팔로의 변환행렬을 곱하여 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬을 구하는 단계; 상기 구한 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬에서 회전행렬을 추출하여 위치 벡터를 삭제한 새로운 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬을 구하는 단계; 및 상기 구한 새로운 상기 피수용대상 물체에서 상기 로봇팔로의 변환행렬과 상기 구한 로봇의 베이스에 서 상기 피수용대상 물체로의 변환행렬을 곱하여 최종적인 상기 로봇의 베이스에서 상기 피수용대상 물체로의 변환행렬을 구하는 단계;를 수행함으로써, 상기 피수용대상 물체의 좌표를 추출하는 것이며, 상기 구한 최종적 인 상기 로봇의 베이스에서 상기 피수용대상 물체로의 변환행렬을 통해서, 상기 로봇팔이 상기 피수용대상 물체 의 좌표축을 따라가지 않도록 하는 것을 특징으로 한다."}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같이 본 발명의 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치 및 그 방법에 따르면, 특정 위치에 구비된 그리핑대상 물체에 부착된 마커를 인식하여 좌표를 추출하고, 미리 생성해둔 딥러닝 학습모델을 통해 다른 위치에 구비된 피수용대상 물체를 인식하여 좌표를 추출하며, 상기 추출한 그리핑 대상물체와 피수용 대상 물체의 좌표에 대한 정보를 토대로 로봇의 그리핑과 드롭을 정밀하게 제어함으로써, 딥러닝과 마커를 이용 한 비전인식을 통해서 상기 그리핑대상 물체를 상기 피수용대상 물체로 정확하게 이동시킬 수 있는 효과가 있다."}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참조하여 본 발명의 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치 및 그 방법에 대한 바람직한 실시 예를 상세히 설명한다. 각 도면에 제시된 동일한 참조부호는 동일한 부재를 나타낸다. 또한 본 발명의 실시 예들에 대해서 특정한 구조적 내지 기능적 설명들은 단지 본 발명에 따른 실시 예를 설명하기 위한 목적으로 예시된 것으로, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용"}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "되는 모든 용어들은 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는 것이 바람직하다. 도 1은 본 발명의 일 실시예에 따른 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치의 전체 구성을 설 명하기 위한 도면이다. 도 1에 도시된 바와 같이, 본 발명은 로봇 제어장치, 로봇, 소정 위치에 마커가 구비된 그리핑 대상 물체, 피수용대상 물체, 데이터베이스 등을 포함하여 구성된다. 상기 로봇 제어장치는 다양한 생산공정에서 딥러닝 학습모델과 마커를 이용한 비전인식을 통해서, 특정 작 업공간에 위치한 상기 그리핑대상 물체를 상기 로봇을 통해 그리핑하는 것을 제어하며, 상기 그리핑 대상 물체를 다른 작업공간에 위치한 상기 피수용대상 물체로 드롭하도록 제어한다. 이때 상기 로봇 제어장치는 상기 로봇에 구비된 카메라로 촬영한 영상으로부터 상기 그리핑대상 물체 에 부착된 마커를 인식하고, 상기 마커의 방향이나 위치를 통해서 상기 그리핑대상 물체의 좌표를 추출할 수 있다. 또한 상기 로봇 제어장치는 상기 피수용대상 물체에 대하여 여러 각도에서 촬영한 데이터세트를 학습 하여 딥러닝 학습모델을 생성하여 상기 데이터베이스에 저장하여 관리하고, 상기 로봇에 구비된 카메 라로 촬영한 영상을 상기 생성한 딥러닝 학습모델에 입력하여 상기 피수용대상 물체의 위치와 자세를 추정 하며, 이를 토대로 상기 피수용대상 물체의 좌표를 추출할 수 있다. 이때 상기 딥러닝 학습모델은 지속적으로 업데이트하여 관리할 수 있다. 즉 상기 로봇 제어장치는 상기 마커를 통해서 추출한 상기 그리핑대상 물체의 좌표와 딥러닝 학 습모델을 이용하여 추정한 상기 피수용대상 물체의 위치와 자세를 통해서 확인한 좌표에 대한 정보를 토대 로 상기 로봇의 그리핑과 드롭을 정밀하게 제어하는 것이다. 이를 구체적으로 설명하면, 상기 로봇 제어장치는 상기 로봇의 구동을 제어하여 로봇팔을 상기 그리 핑대상 물체가 구비된 작업공간 #1로 이동시키고(①), 카메라로 촬영한 영상을 통해서 상기 그리핑대상 물 체의 특정 위치에 구비된 마커를 인식하여 구체적인 좌표를 확인한다(②). 또한 상기 로봇 제어장치는 상기 마커의 인식에 따라 확인된 상기 그리핑대상 물체의 좌표로 상 기 로봇을 이동시켜 상기 그리핑대상 물체를 그리핑하도록 제어한다(③). 이어서, 상기 로봇 제어장치는 상기 로봇을 통해 그리핑한 상기 그리핑대상 물체를 상기 피수용 대상 물체가 구비된 작업공간 #2로 이동시키고(④), 카메라로 촬영한 영상을 미리 생성해둔 딥러닝 학습모 델에 적용하여 상기 피수용대상 물체의 구체적인 좌표를 확인한다(⑤). 또한 상기 로봇 제어장치는 상기 확인한 피수용대상 물체의 좌표를 토대로 상기 로봇을 상기 피 수용대상 물체상으로 이동시켜 그리핑한 상기 그리핑대상 물체를 상기 피수용대상 물체에 드롭 하도록 제어한다(⑥). 도 2는 본 발명의 일 실시예에 따른 로봇 제어장치의 구성을 보다 상세하게 나타낸 도면이다. 도 2에 도시된 바와 같이, 본 발명의 일 실시예에 따른 로봇 제어장치는 학습부, 영상 수신부, 마커 인식부, 피수용대상 물체 인식부, 로봇팔 제어부, 메모리 등을 포함하여 구성된다. 상기 학습부는 상기 피수용대상 물체에 대하여 복수의 각도에서 촬영하여 획득한 데이터세트를 학습 하여, 상기 피수용대상 물체의 위치와 자세를 추정하기 위한 딥러닝 학습모델을 생성하고, 상기 생성한 딥 러닝 학습모델을 상기 데이터베이스에 저장하여 관리한다. 이때 상기 딥러닝 학습모델 생성과정이나 데이 터세트의 설정은 도 7과 도 8에서 상세하게 설명하기로 한다. 상기 영상 수신부는 상기 로봇에 구비된 카메라로부터 촬영한 영상을 수신하고, 상기 수신한 영상을 전처리하여 상기 마커 인식부와 상기 피수용대상 물체 인식부로 전달한다. 상기 마커 인식부는 상기 그리핑대상 물체의 마커 인식 위치에서 촬영한 영상으로부터 마커를 인식하는 기능을 수행한다. 즉 상기 마커 인식부는 상기 영상 수신부로부터 제공받은 영상으로부터 상기 그리핑대상 물체에 부착된 마커를 확인하고, 상기 확인한 마커의 방향이나 회전을 통해서 상기 그리핑대상 물체의 좌표를 인식하는 것이다. 이때 상기 그리핑대상 물체의 좌표 인식에 대한 과정은 도 12와 도 13에서 구체 적으로 설명하기로 한다. 상기 피수용대상 물체 인식부는 상기 피수용대상 물체의 인식 위치에서 촬영한 영상을 상기 학습부를 통해 미리 생성해둔 딥러닝 학습모델에 적용하여 상기 피수용대상 물체를 인식하는 기능을 수행한다. 즉 상기 피수용대상 물체 인식부는 상기 영상 수신부로부터 제공받은 영상을 상기 딥러닝 학습모델에 입력하여, 확률이 가장 높은 방향과 자세를 추정하고, 상기 추정한 방향과 자세를 통해서 상기 그리핑대상 물체 의 좌표를 인식하는 것이다. 이때 상기 피수용대상 물체의 좌표 인식에 대한 과정은 도 14에서 구체 적으로 설명하기로 한다. 상기 로봇팔 제어부는 상기 마커의 인식 및 상기 피수용대상 물체의 인식을 토대로, 상기 그리 핑대상 물체를 그리핑하여 상기 피수용대상 물체로 드롭하도록 제어한다.즉 상기 로봇팔 제어부는 상기 마커 인식부에서 비전인식을 통해 확인한 상기 그리핑대상 물체 의 좌표에 대한 정보를 토대로 상기 로봇의 로봇팔을 이동시켜 상기 그리핑대상 물체를 그리핑하도록 제어하고, 상기 피수용대상 물체 인식부에서 비전인식을 통해 인식한 상기 피수용대상 물체의 좌표에 대한 정보를 토대로 상기 로봇의 로봇팔을 이동시켜 상기 그리핑대상 물체를 상기 피수용대상 물체 로 드롭하도록 제어하는 것이다. 상기 메모리는 상기 로봇 제어장치에서 사용하는 각종 동작프로그램을 저장하고 있다. 한편, 본 발명에서는 상기 그리핑대상 물체에 구비된 마커를 정확하게 인식할 수 있도록 여러 가지 형태의 마커를 사용할 수 있다. 이에 대해서 도 3 내지 도 6을 참조하여 구체적으로 설명하면 다음과 같다. 도 3과 도 4는 본 발명에 적용되는 마커의 일 예를 각각 나타낸 도면이다. 도 3은 ArUco 마커의 일 예를 나타낸 것으로서, n*n 크기의 2차원 패턴과 이를 둘러싸고 있는 검은색 테두리 영 역으로 구성되어 있다. 상기 검은색 테두리 영역은 마커를 빠르게 인식하기 위하여 형성된 것이며, 내부의 2차원 패턴은 흰색 셀과 검 정색 셀을 조합하여 마커의 고유 ID를 표현한 것으로 마커를 식별하는데 사용된다. 도 4는 chArUco 마커의 일 예를 나타낸 것으로서, 체크보드와 4개의 ArUco 마커가 다이아몬드 형태로 배열되어 있다. 상기 chArUco 마커는 색상구분이 뚜렷한 체크보드 사이에 ArUco 마커가 위치하기 때문에 감지가 수월하며, 4개 의 ArUco 마커의 상대적 위치를 계산하여 체크보드 중심에 3차원 축을 생성하며, 상기 생성한 3차원 축을 기반 으로 자세 추출을 수행한다. 도 5는 본 발명에 적용되는 ArUco 마커의 인식 과정을 상세하게 설명하기 위한 도면이다. 도 5에 도시된 바와 같이, 상기 ArUco 마커를 감지하기 위해서는 카메라로 촬영한 영상을 그레이 스케일로 변환 하여 이진화하고, 윤곽선을 추출한다. 이어서, 상기 ArUco 마커의 ID를 분석하기 위해서 비스듬하게 촬영된 이미지는 정면에서 바라본 형태로 변환하 고, 이후 검은색 픽셀을 제외한 흰색 픽셀의 개수를 카운트하여 ArUco 마커의 ID를 추출한다. 또한 상기 ArUco 마커의 각 코너의 4개 꼭지점과 고유 ID를 통해서 상기 ArUco 마커의 중심에 3차원 좌표축이 생성된다. 상기 ArUco 마커의 3차원 좌표축은 상기 꼭지점이 회전을 해도 일정하게 유지되므로, 이를 이용해서 카메라에서 마커까지 이동벡터와 회전을 확인할 수 있게 된다. 한편, 상기 ArUco 마커는 감지가 빠르고 크기가 작다는 장점이 있지만, 밝기 등의 주변 환경에 의해서 모서리의 경계가 흐려지면 카메라가 이를 인지하지 못하며, 단일의 ArUco 마커를 사용할 경우 노이즈로 인해 축이 흔들려 정확한 3차원 좌표축을 세우기 어려운 단점이 있다. 도 6은 본 발명에 적용되는 chArUco 마커의 인식 과정을 상세하게 설명하기 위한 도면이다. 도 6에 도시된 바와 같이, 카메라로 촬영한 영상으로부터 상기 chArUco 마커가 인식되어, 4개의 ArUco 마커와 체크보드 중심이 추출된다. 이에 따라 4개의 ArUco 마커의 상대적 위치 계산을 통해서 체크보드 중심에 3차원 좌표축이 생성되며, 이를 이용해서 카메라에서 마커까지 이동벡터와 회전을 확인할 수 있게 된다. 한편, 상기 chArUco 마커는 색상구분이 뚜렷한 체크보드 사이에 ArUco 마커가 위치하기 때문에 상기 ArUco 마커 에 비해 감지가 수월하고, 밝기 등의 주변 환경에 큰 영향을 받지 않기 때문에, 본 발명에서는 상기 chArUco 마 커를 사용하는 것이 바람직하다. 다음에는, 딥러닝 학습모델의 생성과 데이터세트의 설정과 관련하여 도 7과 도 8을 참조하여 보다 상세하게 설 명한다. 도 7은 본 발명에 적용되는 Mask R-CNN 모델의 진행과정을 설명하기 위한 도면이다. 도 7에 도시된 바와 같이, 본 발명에서는 상기 피수용대상 물체를 인식하기 위한 딥러닝 학습모델로 Mask R-CNN 모델의 ResNet을 사용한다. 상기 Mask R-CNN 모델은 Faster R-CNN 모델에 FPN(Feature Pyramid Network)과 RoI(Region of Interest) align이 추가된 형태이다. 상기 FPN은 레이어를 통과하면서 단계별로 특징 맵(feature map)을 생성하여, 가장 상위에 있는 레이어부터 내 려오면서 특징을 합쳐 감지를 수행함으로써, CNN 모델 진행에서 각각의 레이어를 통과할 때마다 생략되는 특징 을 방지하는 기능을 수행한다. 또한 상기 RoI align은 한 픽셀에 선형 보간법을 이용하여 위치 정보에 대한 세그먼테이션을 뚜렷하게 함으로써, 이전의 바운딩 박스 형태로 물체 감지를 수행하던 것을 마스크 형태로 물체를 보다 확실하게 구분지 을 수 있도록 하는 역할을 수행한다. 한편, 본 발명에서는 Mask R-CNN 모델을 통해 피수용대상 물체를 인식하는 딥러닝 학습모델을 생성하는 것을 예 로 하여 설명하였지만 이에 한정되는 것은 아니며, 그 이외에 다양한 모델을 적용할 수 있음을 밝혀둔다. 도 8은 본 발명에 적용되는 Mask R-CNN 모델을 이용한 학습에 사용되는 데이터세트를 생성하는 과정을 설명하기 위한 도면이다. 도 8에 도시된 바와 같이, 피수용대상 물체의 인식을 위한 딥러닝 학습모델을 생성하기 위해서 상기 Mask R-CNN 모델에 적용하는 데이터세트는 다음과 같이 생성된다. 상기 데이터세트를 생성하기 위해서는, 먼저 실제 피수용대상 물체를 다양한 각도로 촬영하여야 한다. 이처럼 검출 범위를 설정하기 위해서, 본 발명에서는 적어도 4개 이상의 서로 다른 각도에서 상기 피수용대상 물체를 포함하도록 촬영 범위를 선정하고, 상기 선정한 적어도 4개 이상의 서로 다른 각도로 상기 피수용대상 물체를 촬영(예: 100장)한다. 또한 상기 촬영한 영상을 3차원 모델링한 후 상기 3차원 모델링한 영상을 상기 촬영한 영상에 역투영하여 이진 화 마스크 처리하고, 서로 다른 각도에서 각각 촬영한 상기 피수용대상 물체의 영상과 이진화 마스크로 데이터 세트를 생성한다. 이에 따라 상기 로봇 제어장치는 상기 생성한 데이터세트의 촬영한 영상과 이진화 처리한 마스크의 매핑관 계를 Mask R-CNN 모델을 통해 학습하여 딥러닝 학습모델을 생성한다. 다음에는, 이와 같이 구성된 본 발명에 따른 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어방법의 일 실시 예를 도 9 내지 도 14를 참조하여 상세하게 설명한다. 이때 본 발명의 방법에 따른 각 단계는 사용 환경이나 당 업자에 의해 순서가 변경될 수 있다. 도 9는 본 발명의 일 실시예에 따른 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어방법의 동작과정을 상세 하게 나타낸 순서도이다. 도 9에 도시된 바와 같이, 본 발명의 일 실시예에 따른 로봇 제어장치는 피수용대상 물체에 대하여 복수의 각도에서 촬영한 데이터세트를 학습하여, 피수용대상 물체의 위치와 자세를 추정하기 위한 딥러닝 학습모델을 생성하는 학습 단계를 수행한다(S100). 이때 상기 데이터세트는 상기 피수용대상 물체를 적어도 4개 이상의 서로 다른 각도에서 상기 피수용대상 물체 를 포함하도록 촬영한 영상과, 상기 촬영한 영상을 3차원 모델링한 후 상기 3차원 모델링한 영상을 상기 촬영한 영상에 역투영하여 이진화 처리한 마스크를 토대로 생성된 것이며, 상기 로봇 제어장치는 상기 생성한 데 이터세트의 피수용대상 물체를 촬영한 영상과 이진화 처리한 마스크의 매핑관계를 Mask R-CNN 모델을 통해 학습 하여 딥러닝 학습모델을 생성한다. S100 단계를 통해 피수용대상 물체의 인식을 위한 딥러닝 학습모델을 생성한 이후, 상기 로봇 제어장치는 생산공정에서의 로봇을 이용한 작업을 시작한다(S200). 이어서, 상기 로봇 제어장치는 그리핑대상 물체의 마커 인식 위치에서 촬영한 영상으로부터 상기 그 리핑대상 물체의 소정 위치에 구비된 마커를 인식하는 마커 인식 단계를 수행하고, 상기 인식한 마커 의 좌표에 대한 정보를 토대로 상기 로봇의 로봇팔을 구동하여 상기 그리핑대상 물체의 그리핑 을 수행한다(S300). 즉 상기 로봇 제어장치는 상기 마커의 인식을 토대로, 상기 그리핑대상 물체를 그리핑하도록 제어하는 것이다. 이때 상기 S300 단계를 통해 상기 로봇 제어장치에서 상기 그리핑대상 물체를 그리핑하는 과정을 도 10을 참조하여 보다 상세하게 설명하면 다음과 같다.도 10은 본 발명의 일 실시예에 따른 로봇 제어방법의 그리핑 수행에 대한 동작과정을 상세하게 나타낸 순서도 이다. 도 10에 도시된 바와 같이, 작업이 실행되면 상기 로봇 제어장치는 마커 인식 위치로 상기 로봇의 이 동을 제어하고(S301), 해당 마커 인식 위치에서 상기 그리핑대상 물체에 부착된 특정 마커가 감지되 는지를 판단한다(S302). 상기 S302 단계의 판단결과 마커가 감지되면, 상기 로봇 제어장치는 상기 감지한 마커의 좌표로 상기 로봇 의 로봇팔을 움직여 상기 그리핑대상 물체를 그리핑한다(S303). 또한 상기 로봇 제어장치는 상기 S303 단계에서의 그리핑 실행 과정에서 에러가 발생하는지를 판단하고 (S304), 상기 S304 단계의 판단결과 에러가 발생하지 않으면 그리핑한 물체를 드롭하는 상기 S400 단계를 진행 하며, 상기 S304 단계의 판단결과 에러가 발생하면 상기 로봇을 리셋하고(S305), 마커 인식 위치로 로봇팔 을 이동시켜 마커를 찾는 상기 S301 단계를 다시 수행한다. 그러나 상기 S302 단계에서 판단한 결과 마커가 감지되지 않으면, 상기 로봇 제어장치는 상기 로봇에 구비된 카메라를 회전시킨 다음(S306), 마커를 다시 찾고(S307), 그 결과에 따라 마커가 감지되었는지를 판단한 다(S308). 상기 S308 단계의 판단결과 마커가 감지되면 그리핑 작업을 위한 상기 S303 단계를 수행하고, 상기 S308 단계의 판단결과 마커가 감지되지 않으면 로봇팔의 위치 변경 및 움직임 횟수에 따라 변수를 증가시킨다(S309). 이어서 상기 변수가 사전에 설정된 특정 수(예: 9)에 도달하는지를 판단하고(S309), 상기 S309 단계의 판단결과 상기 변수가 사전에 설정된 특정 수에 도달되면 로봇팔의 z축값을 수정한 다음(S310), 마커 인식 위치로 로봇팔 을 이동시켜 마커를 찾는 상기 S301 단계를 다시 수행하며, 상기 S309 단계의 판단결과 상기 변수가 사전에 설 정된 특정 수에 도달되지 않으면 카메라를 회전시켜 마커를 찾는 상기 S306 단계를 다시 수행한다. 다시 도 9를 다시 참조하면, 상기 S300 단계를 통해 마커 인식과 그리핑 작업이 이루어진 후, 상기 로봇 제어장 치는 상기 그리핑대상 물체를 그리핑한 상기 로봇을 피수용대상 물체의 인식 위치로 이동 한 다음, 상기 피수용대상 물체의 인식 위치에서 촬영한 영상을 상기 S100 단계에서 생성한 딥러닝 학습모 델에 적용하여 상기 피수용대상 물체를 인식하는 피수용대상 물체 인식 단계를 수행하고, 상기 인식한 상 기 피수용대상 물체의 좌표에 대한 정보를 토대로 상기 로봇의 로봇팔을 구동하여 상기 그리핑대상 물체를 상기 피수용대상 물체로 드롭한다(S400). 즉 상기 로봇 제어장치는 상기 피수용대상 물 체의 인식을 토대로, 그리핑된 상기 그리핑대상 물체를 상기 피수용대상 물체로 드롭하도록 제 어하는 것이다. 이때 상기 S400 단계를 통해 상기 로봇 제어장치에서 상기 그리핑대상 물체를 상기 피수용대상 물체 에 드롭하는 과정을 도 11을 참조하여 보다 상세하게 설명하면 다음과 같다. 도 11은 본 발명의 일 실시예에 따른 로봇 제어방법의 드롭 수행에 대한 동작과정을 상세하게 나타낸 순서도이 다. 도 11에 도시된 바와 같이, 상기 S300 단계를 통해 그리핑한 상기 그리핑대상 물체를 드롭 위치로 이동한 상기 로봇 제어장치는 피수용대상 물체 인식 위치로 상기 로봇의 이동을 제어하고(S401), 해당 물체 인식 위치에서 피수용대상 물체가 감지되는지를 판단한다(S402). 상기 S402 단계의 판단결과 피수용대상 물체가 감지되면, 상기 로봇 제어장치는 상기 감지한 피수용 대상 물체의 좌표로 상기 로봇의 로봇팔을 움직여 그리핑한 상기 그리핑대상 물체를 상기 피수 용대상 물체로 드롭한다(S403). 또한 상기 로봇 제어장치는 상기 S403 단계에서의 드롭 실행 과정에서 에러가 발생하는지를 판단하고 (S404), 상기 S404 단계의 판단결과 에러가 발생하지 않으면 드롭 작업을 종료하고 다음 S500 단계를 진행하며, 상기 S404 단계의 판단결과 에러가 발생하면 상기 로봇을 리셋하고(S405), 물체 인식 위치로 로봇팔을 이 동시켜 피수용대상 물체를 찾는 상기 S401 단계를 다시 수행한다. 그러나 상기 S402 단계에서 판단한 결과 마커가 감지되지 않으면, 상기 로봇 제어장치는 상기 로봇의 로봇팔을 움직이고, 로봇팔의 위치 변경 및 움직임 횟수에 따라 변수를 증가시킨 다음(S406), 물체가 감지되었 는지를 판단한다(S407).상기 S407 단계의 판단결과 물체가 감지되면 드롭 작업을 위한 상기 S403 단계를 수행하고, 상기 S407 단계의 판단결과 물체가 감지되지 않으면 로봇팔의 위치 변경 및 움직임 횟수에 따라 변수가 사전에 설정된 특정 수(예: 9)에 도달하는지를 판단한다(S408). 상기 S408 단계의 판단결과 상기 변수가 사전에 설정된 특정 수에 도달되면 로봇팔의 z축값을 수정한 다음 (S409), 물체 인식 위치로 로봇팔을 이동시켜 물체를 인식하는 상기 S401 단계를 다시 수행하며, 상기 S408 단 계의 판단결과 상기 변수가 사전에 설정된 특정 수에 도달되지 않으면 로봇팔을 움직이고 로봇팔의 위치 변경 및 움직임 횟수에 따라 변수를 증가하는 상기 S406 단계를 다시 수행한다. 다시 도 9를 참조하면, 상기 마커와 피수용대상 물체를 비전인식을 통해서 인식하여, 상기 그리핑대 상 물체를 그리핑하여 상기 피수용대상 물체로 드롭한 이후, 상기 로봇 제어장치는 작업이 모두 종료되는지를 판단하여(S500), 작업이 모두 종료될 때가지 상기 S200 단계 내지 S400 단계를 반복하여 수행한다. 한편, 상기 S300 단계에서 그리핑을 수행할 때 그리핑대상 물체의 좌표 추출에 대한 동작과정을 도 12와 도 13을 참조하여 보다 상세하게 설명하면 다음과 같다. 도 12와 도 13은 본 발명에 적용된 마커 인식을 통한 그리핑대상 물체의 좌표추출의 과정을 설명하기 위한 도면 이다. 도 12에 도시된 바와 같이, 상기 로봇 제어장치는 상기 그리핑대상 물체에 부착된 마커를 인식 하기 위한 마커 인식 위치에서, 로봇의 베이스에서 상기 마커 인식 위치에서 인식한 마커로의 변환행렬(RTM), 및 로봇의 베이스에서 로봇팔로의 변환행렬(RTT)을 각각 구한다. 이어서 상기 로봇 제어장치는 수학식 1에서와 같이 마커에서 로봇팔로의 변환행렬(MTT)을 구한다. 즉 로봇 의 베이스에서 상기 마커 인식 위치에서 인식한 마커로의 변환행렬(RTM)과 로봇의 베이스에서 로봇팔로의 변환행 렬(RTT)을 곱하여, 마커에서 로봇팔로의 변환행렬(MTT)을 구하는 것이다. [수학식 1]"}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이때 상기 로봇의 로봇팔에서 상기 마커까지의 위치를 고정한다. 예를 들어 상기 로봇의 로봇팔에서 상기 마커 가 X축으로 0.07m, Y축으로 0.26m, Z축으로 0.05m 이동한 위치로 설정되면, 로봇의 로봇팔에서 그리핑대상 물체 로의 변환행렬(TTC)은 수학식 2와 같이 구해진다. 즉 상기 로봇팔의 좌표계를 기준으로 상기 로봇팔에서 상기 그 리핑대상 물체까지의 X, Y, Z축 거리정보를 참조하여 로봇팔에서 그리핑대상 물체로의 변환행렬을 구 할 수 있다. 이때 상기 거리에 대한 수치는 그리핑대상 물체의 위치에 따라 변경할 수 있다. [수학식 2]"}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이와 같이, 마커 인식 위치에서 로봇팔의 축 각도, 마커에서 로봇팔로의 변환행렬(MTT), 및 로봇팔에서 그리핑대 상 물체로의 변환행렬(TTC)을 구한 후, 상기 로봇 제어장치는 그리핑을 수행하기 위한 실행 위치로 상기 로 봇의 로봇팔을 이동시킨다. 이때 상기 로봇이 상기 그리핑대상 물체를 그리핑하기 위한 위치로 이동하였을 때, 상기 로봇의 위치는 상기 마커 인식 위치와 변경될 수 있으므로, 상기 로봇 제어장치는 도 13에 도시된 바와 같이, 변 경된 실행 위치에서 마커를 찾은 다음, 변경된 로봇의 베이스에서 상기 인식한 마커로의 변환행렬(RTM`)을 구한다. 이어서, 상기 로봇 제어장치는 수학식 3에서와 같이 상기 변경된 로봇의 베이스에서 상기 인식한 마커로의 변환행렬(RTM`)과 상기 마커 인식 위치에서 구한 마커에서 로봇팔로의 변환행렬(MTT)을 곱하여 최종적인 로봇의 베이스에서 로봇팔로의 변환행렬(RTT`)을 구한다. [수학식 3]"}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "또한 상기 로봇 제어장치는 수학식 4에서와 같이 상기 실행 위치에서 구한 로봇의 베이스에서 로봇팔로의 변환행렬(RTT`)과 상기 마커 인식 위치에서 구한 로봇팔에서 그리핑대상 물체로의 변환행렬(TTC)을 곱하여 최종적 인 로봇의 베이스에서 그리핑대상 물체로의 변환행렬(RTC)을 구한다. [수학식 4]"}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이에 따라 상기 그리핑대상 물체의 좌표가 추출되어, 상기 로봇의 베이스와 상기 마커의 위치가 변경 되더라도 상기 로봇팔을 상기 그리핑대상 물체로 이동시킬 수 있게 된다. 한편, 상기 S400 단계를 통해 상기 그리핑대상 물체가 드롭되는 상기 피수용대상 물체의 좌표 추출에 대한 동작과정을 도 14를 참조하여 보다 상세하게 설명하면 다음과 같다. 도 14는 본 발명에 적용된 피수용대상 물체의 인식을 통한 피수용대상 물체의 좌표추출의 과정을 설명하기 위한 도면이다. 14에 도시된 바와 같이, 상기 로봇 제어장치는 상기 피수용대상 물체의 인식 위치에서, 로봇의 베이스에서 피수용대상 물체로의 변환행렬(RTO)과 로봇의 베이스에서 로봇팔로의 변환행렬(RTT)을 각각 구한다. 이이서, 상기 로봇 제어장치는 수학식 5에서와 같이 로봇의 베이스에서 피수용대상 물체로의 변환행렬(RT O)과 로봇의 베이스에서 로봇팔로의 변환행렬(RTT)을 곱하여, 피수용대상 물체에서 로봇팔로의 변환행렬(OTT)을 구한다. [수학식 5]"}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "또한 상기 로봇 제어장치는 수학식 6에서와 같이 피수용대상 물체에서 로봇팔로의 변환행렬(OTT)에서 회전 행렬만 추출하고 위치벡터를 삭제한 새로운 피수용대상 물체에서 로봇팔로의 변환행렬(OTT`)을 생성한다. [수학식 6]"}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "또한 상기 로봇 제어장치는 수학식 7에서와 같이 생성한 새로운 피수용대상 물체에서 로봇팔로의 변환행렬 (OTT`)과 로봇의 베이스에서 피수용대상 물체로의 변환행렬(RTO)을 곱하여 최종적인 로봇의 베이스에서 피수용대 상 물체로의 변환행렬(RTO`)을 구한다.[수학식 7]"}
{"patent_id": "10-2020-0154250", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이에 따라 상기 피수용대상 물체의 좌표가 추출되며, 상기 구한 최종적인 로봇의 베이스에서 피수용대상 물체로의 변환행렬(RTO`)을 통해서, 상기 로봇팔이 상기 피수용대상 물체의 좌표축을 따라가지 않도록 할 수 있 다. 즉 상기 로봇팔의 좌표축으로 변환시켜 상기 피수용대상 물체를 움직일 때, 상기 로봇팔이 수직으로 보는 형태를 유지할 수 있도록, 상기 구한 최종적인 로봇의 베이스에서 피수용대상 물체로의 변환행렬(RTO`)을 통해서, 상기 로봇팔이 상기 피수용대상 물체의 좌표축을 따라가지 않도록 하는 것이다. 이처럼, 본 발명은 특정 위치에 구비된 그리핑대상 물체에 부착된 마커를 인식하여 좌표를 추출하고, 미리 생성 해둔 딥러닝 학습모델을 통해 다른 위치에 구비된 피수용대상 물체를 인식하여 좌표를 추출하며, 상기 추출한 그리핑 대상물체와 피수용대상 물체의 좌표에 대한 정보를 토대로 로봇의 그리핑과 드롭을 정밀하게 제어하기 때문에, 상기 그리핑대상 물체를 상기 피수용대상 물체로 정확하게 이동시킬 수 있다. 이상에서와 같이 본 발명은 도면에 도시된 실시예를 참고로 하여 설명되었으나, 이는 예시적인 것에 불과하며, 당해 기술이 속하는 분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하 다는 점을 이해할 것이다. 따라서 본 발명의 기술적 보호범위는 아래의 특허청구범위에 의해서 판단되어야 할 것이다."}
{"patent_id": "10-2020-0154250", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어장치의 전체 구성을 설 명하기 위한 도면이다. 도 2는 본 발명의 일 실시예에 따른 로봇 제어장치의 구성을 보다 상세하게 나타낸 도면이다. 도 3과 도 4는 본 발명에 적용되는 마커의 일 예를 각각 나타낸 도면이다. 도 5는 본 발명에 적용되는 ArUco 마커의 인식 과정을 상세하게 설명하기 위한 도면이다. 도 6은 본 발명에 적용되는 chArUco 마커의 인식 과정을 상세하게 설명하기 위한 도면이다. 도 7은 본 발명에 적용되는 Mask R-CNN 모델의 진행과정을 설명하기 위한 도면이다. 도 8은 본 발명에 적용되는 Mask R-CNN 모델을 이용한 학습에 사용되는 데이터세트를 생성하는 과정을 설명하기 위한 도면이다. 도 9는 본 발명의 일 실시예에 따른 딥러닝과 마커를 이용한 비전인식을 통한 로봇 제어방법의 동작과정을 상세 하게 나타낸 순서도이다. 도 10은 본 발명의 일 실시예에 따른 로봇 제어방법의 그리핑 수행에 대한 동작과정을 상세하게 나타낸 순서도 이다. 도 11은 본 발명의 일 실시예에 따른 로봇 제어방법의 드롭 수행에 대한 동작과정을 상세하게 나타낸 순서도이 다. 도 12와 도 13은 본 발명에 적용된 마커 인식을 통한 그리핑대상 물체의 좌표추출의 과정을 설명하기 위한 도면 이다. 도 14는 본 발명에 적용된 피수용대상 물체의 인식을 통한 피수용대상 물체의 좌표추출의 과정을 설명하기 위한 도면이다."}
