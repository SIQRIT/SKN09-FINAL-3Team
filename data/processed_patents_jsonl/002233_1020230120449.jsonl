{"patent_id": "10-2023-0120449", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0135550", "출원번호": "10-2023-0120449", "발명의 명칭": "전자 장치 및 그의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "임현택"}}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇에 있어서, 복수의 마이크;구동부; 상기 로봇 주변의 객체와의 거리 정보를 감지하기 위한 센서; 및상기 거리 정보에 기초하여 상기 로봇 주변의 객체를 감지하고,상기 복수의 마이크를 통해 수신된 사용자의 음성 신호에 기초하여 음원의 위치를 식별하고,상기 로봇 주변의 객체 및 상기 음원의 위치에 기초하여 상기 로봇의 방향을 제어하도록 상기 구동부를 제어하는 프로세서;를 포함하는 로봇."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 마이크를 통해 음향 신호가 수신되면, 상기 음향 신호로부터 상기 음성 신호를 획득하는 로봇."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 로봇 주변의 객체의 위치에 기초하여 상기 음원에 대한 적어도 하나의 후보 위치를 식별하고,상기 음성 신호에 기초하여 상기 적어도 하나의 후보 공간 중 상기 음원의 위치를 식별하는 로봇."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,카메라;를 더 포함하고, 상기 프로세서는,상기 음성 신호에 기초하여 상기 적어도 하나의 후보 공간 중 제1 후보 공간이 상기 음원의 위치인 것으로 식별되면, 상기 로봇이 상기 제1 후보 공간을 향하도록 상기 구동부를 제어하고,상기 로봇이 상기 제1 후보 공간을 향하는 상태에서 상기 카메라를 통해 촬영을 수행하여 이미지를 획득하고,상기 획득된 이미지에 기초하여 상기 제1 후보 공간에 상기 사용자가 존재하지 않는 것으로 식별되면, 상기 음성 신호에 상기 적어도 하나의 후보 공간 중 제2 후보 공간을 식별하고, 상기 로봇이 상기 제2 후보 공간을 향하도록 상기 구동부를 제어하는 로봇."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 프로세서는,상기 복수의 마이크의 개수 및 상기 복수의 마이크의 배치 방향 중 적어도 하나에 기초하여 상기 음성 신호가공개특허 10-2023-0135550-3-상기 복수의 마이크에 수신되는 방향을 식별하고, 상기 음성 신호가 수신되는 방향에 기초하여 상기 적어도 하나의 후보 공간 중 상기 음원의 위치를 식별하는 로봇."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,카메라;를 더 포함하고,상기 프로세서는,상기 로봇이 상기 음원이 위치한 방향을 향한 후 상기 카메라를 통해 촬영을 수행하여 이미지를 획득하고, 상기 이미지에 포함된 상기 사용자의 기설정된 신체 부위를 식별하고, 상기 로봇의 헤드가 상기 기설정된 신체 부위를 향하도록 상기 구동부를 통해 상기 로봇의 헤드를 회전시키며, 상기 기설정된 신체 부위는, 상기 사용자의 얼굴 또는 입을 포함하는 로봇."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 프로세서는,상기 로봇 및 상기 음원 간의 거리가 기설정된 값을 초과하는 것으로 식별되면, 상기 로봇이 상기 음원의 위치로부터 기설정된 거리만큼 떨어진 지점까지 이동하도록 상기 구동부를 제어하는 로봇."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는,상기 음원의 위치 및 상기 거리 정보에 기초하여 상기 음원의 위치가 이동된 것으로 식별되면, 상기 이동된 위치에 기초하여 상기 로봇이 상기 이동된 음원이 위치하는 방향을 향하도록 상기 구동부를 제어하는 로봇."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "로봇의 제어 방법에 있어서, 상기 로봇의 센서를 통해 획득된 거리 정보에 기초하여 상기 로봇 주변의 객체를 감지하는 단계;상기 로봇의 복수의 마이크를 통해 수신된 사용자의 음성 신호에 기초하여 음원의 위치를 식별하는 단계; 및 상기 로봇 주변의 객체 및 상기 음원의 위치에 기초하여 상기 로봇의 방향을 제어하는 단계;를 포함하는 제어방법."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 복수의 마이크를 통해 음향 신호가 수신되면, 상기 음향 신호로부터 상기 음성 신호를 획득하는 단계:를더 포함하는 제어 방법."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 식별하는 단계는,상기 로봇 주변의 객체의 위치에 기초하여 상기 음원에 대한 적어도 하나의 후보 위치를 식별하는 단계; 및 상기 음성 신호에 기초하여 상기 적어도 하나의 후보 공간 중 상기 음원의 위치를 식별하는 단계;를 포함하는공개특허 10-2023-0135550-4-제어 방법."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 음성 신호에 기초하여 상기 적어도 하나의 후보 공간 중 제1 후보 공간이 상기 음원의 위치인 것으로 식별되면, 상기 로봇이 상기 제1 후보 공간을 향하도록 제어하는 단계; 상기 로봇이 상기 제1 후보 공간을 향하는 상태에서 상기 로봇의 카메라를 통해 촬영을 수행하여 이미지를 획득하는 단계; 상기 획득된 이미지에 기초하여 상기 제1 후보 공간에 상기 사용자가 존재하지 않는 것으로 식별되면, 상기 음성 신호에 상기 적어도 하나의 후보 공간 중 제2 후보 공간을 식별하는 단계; 및 상기 로봇이 상기 제2 후보 공간을 향하도록 제어하는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 식별하는 단계는,상기 복수의 마이크의 개수 및 상기 복수의 마이크의 배치 방향 중 적어도 하나에 기초하여 상기 음성 신호가상기 복수의 마이크에 수신되는 방향을 식별하는 단계; 및상기 음성 신호가 수신되는 방향에 기초하여 상기 적어도 하나의 후보 공간 중 상기 음원의 위치를 식별하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 로봇이 상기 음원이 위치한 방향을 향한 후 상기 로봇의 카메라를 통해 촬영을 수행하여 이미지를 획득하는 단계; 상기 이미지에 포함된 상기 사용자의 기설정된 신체 부위를 식별하는 단계; 및상기 로봇의 헤드가 상기 기설정된 신체 부위를 향하도록 상기 로봇의 헤드를 회전시키는 단계;를 더 포함하며,상기 기설정된 신체 부위는, 상기 사용자의 얼굴 또는 입을 포함하는 제어 방법."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서,상기 로봇 및 상기 음원 간의 거리가 기설정된 값을 초과하는 것으로 식별되면, 상기 로봇을 상기 음원의 위치로부터 기설정된 거리만큼 떨어진 지점까지 이동하시키는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2023-0120449", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 음원의 위치 및 상기 거리 정보에 기초하여 상기 음원의 위치가 이동된 것으로 식별되면, 상기 로봇이 상기 이동된 위치에 기초하여 상기 이동된 음원이 위치하는 방향을 향하도록 제어하는 단계;를 더 포함하는 제어방법."}
{"patent_id": "10-2023-0120449", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에서는 전자 장치 및 그 제어 방법이 제공된다. 본 개시의 전자 장치는, 복수의 마이크, 디스플레이, 구 동부, 및 전자 장치 주변의 객체와의 거리를 센싱하기 위한 센서 및 복수의 마이크를 통해 음향 신호가 수신되면, 센서에서 센싱된 거리 정보에 기초하여 전자 장치 주변의 공간에서 음원에 대한 적어도 하나의 후보 공간을 식별하고, 식별된 후보 공간에 대해 음원 위치 추정을 수행하여 음향 신호가 출력된 음원의 위치를 식별 하고, 식별된 음원의 위치에 기초하여 디스플레이가 음원을 향하도록 구동부를 제어하는 프로세서를 포함할 수 있다."}
{"patent_id": "10-2023-0120449", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그의 제어 방법에 관한 것으로, 보다 상세하게는 음원의 위치를 식별하는 전자 장치 및 그의 제어 방법에 관한 것이다."}
{"patent_id": "10-2023-0120449", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 대화를 통해 사용자와 의사 소통할 수 있는 로봇과 같은 형태의 전자 장치가 개발되고 있다. 전자 장치는 마이크로폰(이하, 마이크)을 통해 수신된 사용자의 음성을 인식하여 동작(예: 사용자를 향한 이동 동작 또는 방향 회전 동작 등)을 수행하기 위해, 음성을 발화하는 사용자의 위치를 정확히 탐색할 필요가 있다. 여기서, 음성을 발화하는 사용자의 위치는 음성이 발화되어 나오는 위치 즉, 음원의 위치를 통해 추정될 수 있 다. 다만, 마이크만으로 정확한 음원의 위치를 실시간으로 파악하는 것은 어려운 일이다. 마이크를 통해 수신되는 음향 신호를 처리하여, 주변 공간을 구분한 블록 단위로 음원의 위치를 탐색하는 방법 등은 많은 계산량이 요구 된다는 문제가 있다. 실시간으로 음원의 위치를 파악해야 할 경우에는 계산량이 시간에 비례하여 증가하게 된다. 이는 곧 전력 소모의 증가와 리소스의 낭비로 이어질 수 있다. 또한, 노이즈 또는 반향 등이 발생하는 등 과 같이 주변 공간의 환경에 따라 탐색된 음원의 위치에 대한 정확도가 저하된다는 문제가 있다."}
{"patent_id": "10-2023-0120449", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은 실시간으로 탐색된 음원의 위치에 기반하여 음성 인식 서비스에 대한 사용자 경험을 향상시키 는 전자 장치 및 그의 제어 방법을 제공함에 있다."}
{"patent_id": "10-2023-0120449", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 전자 장치는, 복수의 마이크, 디스플레이, 구동부 및 전자 장치 주변의 객체와의 거리를 센싱하기 위한 센서 및 복수의 마이크를 통해 음향 신호가 수신되면, 센서에서 센싱된 거리 정보에 기초 하여 전자 장치 주변의 공간에서 음원에 대한 적어도 하나의 후보 공간을 식별하고, 식별된 후보 공간에 대해 음원 위치 추정을 수행하여 음향 신호가 출력된 음원의 위치를 식별하고, 식별된 음원의 위치에 기초하여 디스 플레이가 음원을 향하도록 구동부를 제어하는 프로세서를 포함할 수 있다. 프로세서는 센서에서 센싱된 거리 정보에 기초하여 전자 장치 주변에서 기설정된 형상을 갖는 적어도 하나의 객 체를 식별하고, 식별된 객체의 위치에 기초하여 적어도 하나의 후보 공간을 식별할 수 있다. 프로세서는 센서에서 센싱된 거리 정보에 기초하여 전자 장치 주변의 XY 축의 공간에서 기설정된 형상을 갖는 적어도 하나의 객체를 식별하고, XY 축의 공간에서 식별된 객체가 위치한 영역에 대해, Z 축으로 기설정된 높이 를 갖는 적어도 하나의 공간을 적어도 하나의 후보 공간으로 식별할 수 있다. 기설정된 형상은 사용자의 발의 형상일 수 있다. 프로세서는 음원이 위치하는 후보 공간에 대응되는 객체에 식별된 음원의 Z 축 상의 높이 정보를 맵핑시키고, 센서에서 센싱된 거리 정보에 기초하여 XY 축의 공간에서 객체의 이동 궤적을 추적하고, 음향 신호와 동일한 음 원에서 출력된 후속 음향 신호가 복수의 마이크를 통해 수신되면, 객체의 이동 궤적에 따른 객체의 XY 축의 공 간 상의 위치 및 객체에 맵핑된 Z 축 상의 높이 정보에 기초하여 후속 음향 신호가 출력된 음원의 위치를 식별 할 수 있다. 음원은 사용자의 입일 수 있다. 전자 장치는 카메라를 더 포함할 수 있다. 프로세서는 식별된 음원의 위치에 기초하여 카메라를 통해 음원이 위 치하는 방향으로 촬영을 수행하고, 카메라를 통해 촬영된 이미지에 기초하여 이미지에 포함된 사용자의 입의 위 치를 식별하고, 입의 위치에 기초하여 디스플레이가 입을 향하도록 구동부를 제어할 수 있다. 프로세서는 식별된 후보 공간 각각을 복수의 블록으로 구분하고, 각 블록에 대해 빔포밍 파워를 산출하는 음원 위치 추정을 수행하여, 산출된 빔포밍 파워가 가장 큰 블록의 위치를 음원의 위치로 식별할 수 있다. 전자 장치는 카메라를 더 포함할 수 있다. 프로세서는 복수의 블록 중 가장 큰 빔포밍 파워를 갖는 제1 블록의 위치를 음원의 위치로 식별하고, 식별된 음원의 위치에 기초하여 카메라를 통해 음원이 위치하는 방향으로 촬영 을 수행하고, 카메라를 통해 촬영된 이미지에 사용자가 존재하지 않는 경우, 제1 블록 다음으로 큰 빔포밍 파워를 갖는 제2 블록의 위치를 음원의 위치로 식별하고, 식별된 음원의 위치에 기초하여 디스플레이가 음원을 향하 도록 구동부를 제어할 수 있다. 디스플레이는 전자 장치를 구성하는 헤드 및 바디 중 헤드에 위치하며, 프로세서는 전자 장치와 음원 간의 거리 가 기설정된 값 이하인 경우, 디스플레이가 음원을 향하도록, 구동부를 통해 전자 장치의 방향 및 헤드의 각도 중 적어도 하나를 조정하고, 전자 장치와 음원 간의 거리가 기설정된 값을 초과하는 경우, 디스플레이가 음원을 향하도록, 구동부를 통해 음원으로부터 기설정된 거리만큼 떨어진 지점까지 전자 장치를 이동시키고 헤드의 각 도를 조정할 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 복수의 마이크를 통해 음향 신호가 수신되면, 센 서에서 센싱된 거리 정보에 기초하여 전자 장치 주변의 공간에서 음원에 대한 적어도 하나의 후보 공간을 식별 하는 단계, 식별된 후보 공간에 대해 음원 위치 추정을 수행하여 음향 신호가 출력된 음원의 위치를 식별하는 단계, 식별된 음원의 위치에 기초하여 디스플레이가 음원을 향하도록 구동부를 제어하는 단계를 포함할 수 있다. 후보 공간을 식별하는 단계는 센서에서 센싱된 거리 정보에 기초하여 전자 장치 주변에서 기설정된 형상을 갖는 적어도 하나의 객체를 식별하고, 식별된 객체의 위치에 기초하여 적어도 하나의 후보 공간을 식별할 수 있다. 후보 공간을 식별하는 단계는 센서에서 센싱된 거리 정보에 기초하여 전자 장치 주변의 XY 축의 공간에서 기설 정된 형상을 갖는 적어도 하나의 객체를 식별하고, XY 축의 공간에서 식별된 객체가 위치한 영역에 대해, Z 축 으로 기설정된 높이를 갖는 적어도 하나의 공간을 적어도 하나의 후보 공간으로 식별할 수 있다. 기설정된 형상은 사용자의 발의 형상일 수 있다. 음원의 위치를 식별하는 단계는 음원이 위치하는 후보 공간에 대응되는 객체에 식별된 음원의 Z 축 상의 높이 정보를 맵핑시키는 단계, 센서에서 센싱된 거리 정보에 기초하여 XY 축의 공간에서 객체의 이동 궤적을 추적하 는 단계, 음향 신호와 동일한 음원에서 출력된 후속 음향 신호가 복수의 마이크를 통해 수신되면, 객체의 이동 궤적에 따른 객체의 XY 축의 공간 상의 위치 및 객체에 맵핑된 Z 축 상의 높이 정보에 기초하여 후속 음향 신호 가 출력된 음원의 위치를 식별하는 단계를 포함할 수 있다. 음원은 사용자의 입일 수 있다. 식별된 음원의 위치에 기초하여 카메라를 통해 음원이 위치하는 방향으로 촬영을 수행하는 단계, 카메라를 통해 촬영된 이미지에 기초하여 이미지에 포함된 사용자의 입의 위치를 식별하는 단계 및 디스플레이가 식별된 입의 위치를 향하도록 구동부를 제어하는 단계를 더 포함할 수 있다. 음원의 위치를 식별하는 단계는 식별된 후보 공간 각각을 복수의 블록으로 구분하여, 각 블록에 대해 빔포밍 파 워를 산출하는 음원 위치 추정을 수행하는 단계 및 산출된 빔포밍 파워가 가장 큰 블록의 위치를 음원의 위치로 식별하는 단계를 포함할 수 있다. 복수의 블록 중 가장 큰 빔포밍 파워를 갖는 제1 블록의 위치를 음원의 위치로 식별하는 단계, 식별된 음원의 위치에 기초하여 카메라를 통해 음원이 위치하는 방향으로 촬영을 수행하는 단계, 카메라를 통해 촬영된 이미지 에 사용자가 존재하지 않는 경우, 제1 블록 다음으로 큰 빔포밍 파워를 갖는 제2 블록의 위치를 음원의 위치로 식별하는 단계 및 식별된 음원의 위치에 기초하여 디스플레이가 음원을 향하도록 구동부를 제어하는 단계를 포 함할 수 있다. 디스플레이는 전자 장치를 구성하는 헤드 및 바디 중 헤드에 위치하며, 전자 장치와 음원 간의 거리가 기설정된 값 이하인 경우, 디스플레이가 음원을 향하도록, 구동부를 통해 전자 장치의 방향 및 헤드의 각도 중 적어도 하 나를 조정하는 단계 및 전자 장치와 음원 간의 거리가 기설정된 값을 초과하는 경우, 디스플레이가 음원을 향하 도록, 구동부를 통해 음원으로부터 기설정된 거리만큼 떨어진 지점까지 전자 장치를 이동시키고 헤드의 각도를 조정하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-0120449", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 음원의 위치에 기반하여 음성 인식 서비스에 대한 사용자 경 험을 향상시키는 전자 장치 및 그의 제어 방법을 제공할 수 있다. 또한, 음원의 위치를 보다 정확하게 탐색하여 음성 인식에 대한 정확도를 향상시키는 전자 장치 및 그의 제어 방법을 제공할 수 있다."}
{"patent_id": "10-2023-0120449", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그에 대한 상세한 설명은 생략한다. 덧붙여, 하기 실시 예는 여러 가지 다른 형 태로 변형될 수 있으며, 본 개시의 기술적 사상의 범위가 하기 실시 예에 한정되는 것은 아니다. 오히려, 이들 실시 예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본 개시의 기술적 사상을 완전하게 전달하기 위 하여 제공되는 것이다. 본 개시에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시의 실시 예의 다양한 변경 (modifications), 균등물(equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 상기 구성요소들을 한정하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \" 포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 상기 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메 모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 상기 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 개시의 다양한 실시 예들에 따른 전자 장치는, 예를 들면, 스마트폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전화기(mobile phone), 영상 전화기, 전자책 리더기(e-book reader), 데스크탑 PC(desktop personal computer), 랩탑 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 워크 스테이션(workstation), 서버, PDA(personal digital assistant), PMP(portable multimedia player), MP3 플 레이어, 모바일 의료기기, 카메라(camera), 또는 웨어러블 장치(wearable device) 중 적어도 하나를 포함할 수 있다. 다양한 실시 예에 따르면, 웨어러블 장치는 액세서리형(예: 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택 트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD)), 직물 또는 의류 일체형(예: 전자 의복), 신체 부 착형(예: 스킨 패드(skin pad) 또는 문신), 또는 생체 이식형(예: implantable circuit) 중 적어도 하나를 포 함할 수 있다. 또한, 일 실시 예들에서, 전자 장치는 가전 제품(home appliance)일 수 있다. 가전 제품은, 예를 들면, 텔레비 전, DVD(digital video disk) 플레이어, 오디오, 냉장고, 에어컨, 청소기, 오븐, 전자레인지, 세탁기, 공기 청 정기, 셋톱 박스(set-top box), 홈 오토매이션 컨트롤 패널(home automation control panel), 보안 컨트롤 패 널(security control panel), TV 박스(예: 삼성 HomeSync™, 애플TV™, 또는 구글 TV™), 게임 콘솔(예: Xbox ™, PlayStation™), 전자 사전, 전자 키, 캠코더(camcorder), 또는 전자 액자 중 적어도 하나를 포함할 수 있 다. 다른 실시 예에서, 전자 장치는, 각종 의료기기(예: 각종 휴대용 의료측정기기(혈당 측정기, 심박 측정기, 혈압 측정기, 또는 체온 측정기 등), MRA(magnetic resonance angiography), MRI(magnetic resonance imaging), CT(computed tomography), 촬영기, 또는 초음파기 등), 네비게이션(navigation) 장치, 위성 항법 시스템 (GNSS(global navigation satellite system)), EDR(event data recorder), FDR(flight data recorder), 자동 차 인포테인먼트(infotainment) 장치, 선박용 전자 장비(예: 선박용 항법 장치, 자이로 콤파스 등), 항공 전자 기기(avionics), 보안 기기, 차량용 헤드 유닛(head unit), 산업용 또는 가정용 로봇, 금융 기관의 ATM(automatic teller's machine), 상점의 POS(point of sales), 또는 사물 인터넷 장치(internet of things) (예: 전구, 각종 센서, 전기 또는 가스 미터기, 스프링클러 장치, 화재경보기, 온도조절기(thermostat), 가로등, 토스터(toaster), 운동기구, 온수탱크, 히터, 보일러 등) 중 적어도 하나를 포함할 수 있다. 또 다른 실시 예에 따르면, 전자 장치는 가구(furniture) 또는 건물/구조물의 일부, 전자 보드(electronic board), 전자 사인 수신 장치(electronic signature receiving device), 프로젝터(projector), 또는 각종 계측 기기(예: 수도, 전기, 가스, 또는 전파 계측 기기 등) 중 적어도 하나를 포함할 수 있다. 다양한 실시 예에서, 전자 장치는 전술한 다양한 장치들 중 하나 또는 그 이상의 조합일 수 있다. 어떤 실시 예에 따른 전자 장치는 플렉서블 전자 장치일 수 있다. 또한, 본 문서의 실시 예에 따른 전자 장치는 전술한 기기들에 한정되지 않으며, 기술 발전에 따른 새로운 전자 장치를 포함할 수 있다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 도면이다. 도 1에 도시된 바와 같이, 본 개시의 일 실시 예에 따른 전자 장치는 로봇 장치로 구현될 수 있다. 전자 장치는 고정된 위치에서 회전 구동되는 고정형 로봇 장치로 구현되거나, 주행 또는 비행을 통해 위치를 이 동시킬 수 있는 이동형 로봇 장치로 구현될 수 있다. 나아가, 이동형 로봇 장치는 회전 구동이 가능할 수도 있 다. 전자 장치의 외관은 인간, 동물 또는 캐릭터 등 다양한 형상을 가질 수 있다. 또한, 전자 장치의 외 관은 헤드 및 바디로 구성될 수 있다. 여기서, 헤드는 바디의 전면부 또는 바디의 상단부 에 위치되어, 바디와 결합될 수 있다. 바디는 헤드와 결합되어 헤드를 지지할 수 있다. 또한, 바디에는 주행 또는 비행을 위한 주행 장치 또는 비행 장치가 구비될 수 있다. 다만, 상술한 실시 예는 일 실시 예에 불과할 뿐, 전자 장치의 외관은 다양한 형상으로 변형될 수 있으며, 또한 전자 장치는 스마트 폰, 태블릿 PC 등의 휴대용 단말, 또는 TV, 냉장고, 세탁기, 에어컨, 로봇 청소 기 등의 가전 제품 등과 같이 다양한 형태의 전자 장치로 구현될 수 있다. 전자 장치는 음성 인식 서비스를 사용자에게 제공할 수 있다. 구체적으로, 전자 장치는 음향 신호를 수신할 수 있다. 이때, 음향 신호(또는 오디오 신호라 함)는 매질 (예: 공기, 물 등)을 통해 전달되는 음파(Sound Wave)를 의미하며, 진동수, 진폭, 파형 등의 정보를 포함할 수 있다. 그리고, 음향 신호는 사용자가 신체(예: 성대, 입 등)를 통해 특정한 단어 또는 문장에 대한 음성을 발화함으로써 발생될 수 있다. 즉, 음향 신호에는 진동수, 진폭, 파형 등의 정보로 표현되는 사용자의 음 성이 포함될 수 있다. 예를 들어, 도 1과 같이 음향 신호는 사용자가 “오늘 날씨 알려줘”와 같은 음성을 발화함으로써 발생될 수 있다. 한편, 특별한 설명이 없는 한, 사용자는 음성 인식 서비스를 제공받기 위해 음성을 발화한 사용자인 것으로 가정하여 설명하도록 한다. 그리고, 전자 장치는 다양한 방식의 음성 인식 모델(Speech Recognition Model)을 통해 음향 신호를 해석 하여, 음향 신호에 포함된 음성에 대응되는 텍스트를 획득할 수 있다. 여기서, 음성 인식 모델은 특정한 단어 또는 단어의 일부를 이루는 음절을 발화한 발성 정보 및 단위 음소 정보에 대한 정보를 포함할 수 있다. 한편, 음향 신호는 오디오 데이터 형식이며, 텍스트는 컴퓨터가 이해할 수 있는 언어로서 문자 데이터 형식일 수 있다. 그리고, 전자 장치는 획득된 텍스트에 기반하여 다양한 동작을 수행할 수 있다. 예를 들어, 전자 장치 는 “오늘 날씨 알려줘”와 같은 텍스트가 획득된 경우, 현 위치 및 오늘 날짜에 대한 날씨 정보를 전자 장치의 디스플레이 및/또는 전자 장치의 스피커를 통해 출력할 수 있다. 한편, 전자 장치에서 디스플레이 또는 스피커를 통해 정보를 출력하는 음성 인식 서비스의 제공을 위해서 는, 전자 장치는 사용자의 현재 위치를 기초로 사용자와 근접한 거리(예: 사용자의 시각 또는 청각 범위 등)에 위치할 것이 요구될 수 있다. 또한, 사용자의 위치를 기반으로 하는 동작(예: 물건 을 사용자에게 가져다 주는 동작 등)을 수행하는 음성 인식 서비스의 제공을 위해서는, 전자 장치는 사용자의 현재 위치가 요구될 수 있다. 또한, 사용자와 대화하는 음성 인식 서비스의 제공을 위해서 는, 전자 장치는 음성을 발화하는 사용자의 위치를 향해 헤드를 구동할 것이 요구될 수 있다. 이 는 전자 장치의 헤드가 사용자의 얼굴을 향하지 않는다면(즉, 아이컨택을 하지 않는 경우) 음성 인식 서비스를 제공하는 사용자에게 심리적인 불편함을 야기할 수 있기 때문이다. 이와 같이, 다양한 상황 에서 음성을 발화한 사용자의 위치를 실시간으로 정확하게 파악하는 것이 요구될 수 있다. 본 개시의 일 실시 예에 따른 전자 장치는 음향 신호가 출력되는 음원의 위치를 이용하여, 다양한 음성 인 식 서비스를 사용자에게 제공할 수 있다. 전자 장치는 전자 장치 주변의 객체와의 거리를 센싱하고, 센싱된 거리 정보에 기초하여 전자 장치 주변의 공간에서 후보 공간을 식별할 수 있다. 이는 후술하는 음원 위치 추정이 수행되는 대상을 전자 장 치 주변의 모든 공간이 아닌, 전자 장치 주변의 공간 중에서 특정한 객체가 존재하는 후보 공간으로 한정함으로써 음원 위치 추정의 계산량을 줄일 수 있다. 또한, 이로 인해 실시간으로 음원의 위치를 파악하는 것이 가능해지며, 리소스의 효율화를 도모할 수 있다. 그리고, 전자 장치는 음향 신호가 수신되면, 후보 공간에 대해 음원 위치 추정을 수행하여 음향 신호가 출 력된 음원의 위치를 식별할 수 있다. 여기서, 음원은 사용자의 입을 나타낼 수 있다. 즉, 음원의 위치는 음향 신호가 출력되는 사용자의 입(또는 얼굴)의 위치를 나타내며, 3차원 공간 좌표 등의 다양한 방식으로나타낼 수 있다. 여기서, 음원의 위치는 다른 사용자와 구별하기 위한 사용자의 위치로 이용될 수 있다. 그리고, 전자 장치는 식별된 음원의 위치에 기초하여 디스플레이가 음원을 향하도록 구동할 수 있다. 예를 들어, 전자 장치는 식별된 음원의 위치에 기초하여 디스플레이가 음원을 향하도록 회전하거나 이동할 수 있다. 여기서, 디스플레이는 전자 장치의 외관을 형성하는 헤드 및 바디 중에서 적어도 하나에 배 치되거나 형성될 수 있다. 이와 같이, 전자 장치는 사용자의 가시 범위 내 디스플레이가 위치하도록 디스플레이를 구동함으로써, 디스플레이를 통해 표시되는 다양한 정보를 사용자에게 편리하게 전달할 수 있다. 즉, 사용 자는 별도의 움직임 없이도 가시 범위 내 위치하는 전자 장치의 디스플레이를 통해 정보를 전달받을 수 있으며, 이로 인해 사용자 편의성이 향상될 수 있다. 또한, 전자 장치의 헤드에 디스플레이가 배치된 경우, 전자 장치는 사용자를 응시하도록 헤 드와 함께 디스플레이를 회전 구동시킬 수 있다. 예를 들어, 전자 장치는 사용자의 입(또는 얼굴)의 위치를 향하도록 헤드와 함께 디스플레이를 회전 구동시킬 수 있다. 이때, 헤드에 배치된 디스 플레이는 눈 또는 입을 나타내는 오브젝트를 표시할 수도 있다. 이에 따라, 보다 자연스러운 의사 소통과 관련 된 사용자 경험을 사용자에게 제공할 수 있다. 이하에서는 첨부된 도면을 참조하여, 본 개시를 상세히 설명하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 2를 참조하면, 전자 장치는 복수의 마이크, 디스플레이, 구동부, 센서 및 프로세 서를 포함할 수 있다. 복수의 마이크는 각각 음향 신호를 수신하기 위한 구성이다. 여기서, 음향 신호에는 진동수, 진폭, 파형 등의 정보로 표현되는 사용자의 음성이 포함될 수 있다. 복수의 마이크는 제1 마이크(110-1), 제2 마이크(110-2), ..., 제n 마이크(110-n)를 포함할 수 있다. 여 기서, n은 2 이상의 자연수일 수 있다. 복수의 마이크의 개수는 증가할수록 음원의 위치 추정에 대한 성능 이 높아질 수 있으나, 복수의 마이크의 개수와 비례하여 계산량이 증가되는 단점이 있다. 본 개시의 복수 의 마이크의 개수는 4개 내지 8개의 범위 내일 수 있으나, 다만 이에 제한되지 아니하고 다양한 개수로 변 형될 수 있다. 복수의 마이크는 각각 서로 다른 위치에 배치되어 음향 신호를 수신할 수 있다. 예를 들어, 복수의 마이크 는 직선 상에 배치되거나, 다각형 또는 다면체의 꼭지점 상에 배치될 수 있다. 여기서, 다각형은 삼각형, 사각형, 오각형 등 다양한 평면 도형을 지칭하는 것이며, 다면체는 사면체(삼각뿔 등), 오면체, 육면체 등 다양 한 입체 도형을 지칭하는 것이다. 다만 이는 일 실시 예일 뿐, 복수의 마이크의 적어도 일부는 다각형 또 는 다면체의 꼭지점에 배치되며, 나머지 일부는 다각형 또는 다면체의 내부에 배치될 수도 있다. 복수의 마이크는 서로 기설정된 거리만큼 이격되어 배치될 수 있다. 복수의 마이크 중에서 인접한 마 이크 간의 거리는 동일할 수 있으나, 이는 일 실시 예일 뿐 인접한 마이크 간의 거리는 다를 수도 있다. 또한, 복수의 마이크 각각은 전자 장치의 상측이나 전면 방향, 측면 방향 등에 일체화된 일체형으로 구현될 수도 있고, 별도의 수단으로 마련되어 전자 장치와 유선 또는 무선 인터페이스로 연결될 수도 있다. 디스플레이는 각종 사용자 인터페이스(User Interface; UI), 아이콘, 도형, 문자, 영상 등을 표시할 수 있 다. 이를 위해, 디스플레이는 별도의 백라이트 유닛(예: LED(light emitting diode) 등)을 광원으로 이용하고 액정(Liquid Crystal)의 분자 배열을 제어함으로써 백라이트 유닛에서 방출된 빛이 액정을 통해 투과되는 정도 (빛의 밝기 또는 빛의 세기)를 조절하는 LCD(Liquid Crystal Display), 별도의 백라이트 유닛 또는 액정 없이 자발광 소자(예: 크기가 100-200um인 mini LED, 크기가 100um이하인 micro LED, OLED(Organic LED), QLED(Quantum dot LED) 등)를 광원으로 이용하는 디스플레이 등과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 한편, 디스플레이는 사용자의 터치 조작을 감지할 수 있는 터치스크린 형태로 구현될 수 있으며, 또 한 디스플레이는 일정 부분이 휘거나 접히고 다시 펼 수 있는 특성을 갖는 플렉서블 디스플레이(flexible display)의 형태로 구현되거나, 디스플레이는 디스플레이의 후방에 위치한 사물을 투과시켜 보이게하는 특성을 갖는 투명 디스플레이로 구현될 수 있다. 한편, 전자 장치는 하나 이상의 디스플레이를 포함할 수 있다. 디스플레이는 헤드 및 바디 중에서 적어도 하나에 배치될 수 있다. 디스플레이가 헤드에 배치된 경우, 헤드가 회전 구동 할 경우 결과적으로 헤드에 배치된 디스플레이가 함께 회전될 수 있다. 또한, 헤드와 결합된 바디 가 이동 구동할 경우, 결과적으로 헤드 또는 바디에 배치된 디스플레이가 함께 이동될 수 있 다. 구동부는 전자 장치를 이동시키거나 회전시키기 위한 구성이다. 예를 들어, 구동부는 전자 장치 의 헤드 및 바디 사이에 결합되어 회전 장치로서 기능하며, 헤드를 Z축과 수직한 축을 중심으 로 회전시키거나 Z축을 중심으로 회전시킬 수 있다. 또는, 구동부는 전자 장치의 바디에 배치되 어 주행 장치 또는 비행 장치로서 기능하며, 주행 또는 비행을 통해 전자 장치를 이동시킬 수 있다. 이를 위해, 구동부는 전기, 유압, 압축 공기 등을 이용하여 동력을 발생시키는 전동모터, 유압장치, 공압 장치 중에서 적어도 하나를 포함할 수 있다. 또는, 구동부는 주행을 위한 바퀴 또는 비행을 위한 에어 분 사기 등을 더 포함할 수 있다. 센서는 전자 장치 주변의 객체와의 거리(또는 깊이)를 센싱할 수 있다. 이를 위해, 센서는 TOF(Time of Flight) 방식 또는 phase-shift 방식 등의 다양한 방식을 통해 센서 또는 전자 장치의 주변 공간 내 존재하는 객체와의 거리를 센싱할 수 있다. TOF 방식은 센서가 레이저 등의 펄스 신호를 방출하고, 전자 장치 주변의 공간(측정 범위 내)에서 존 재하는 객체로부터 반사되어 되돌아 오는 펄스 신호가 센서에 도착하는 시간을 측정함으로써 거리를 센싱 할 수 있다. Phase-shift 방식은 센서가 특정 주파수를 가지고 연속적으로 변조되는 레이저 등의 펄스 신 호를 방출하고, 객체로부터 반사되어 되돌아 오는 펄스 신호의 위상 변화량을 측정하여 거리를 센싱할 수 있다. 이때, 센서는 펄스 신호의 종류에 따라 라이다(Light Detection And Ranging, LiDAR) 센서, 초음파 센서 등으로 구현될 수 있다. 프로세서는 전자 장치의 전반적인 동작을 제어할 수 있다. 이를 위해, 프로세서는 CPU(Central Processing Unit), AP(Application Processor) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit) 등과 같은 그래픽 전용 프로세서, NPU(Neural Processing Unit)와 같은 인공지능 전용 프로세서 등으로 구현될 수 있다. 또한, 프로세서는 적어도 하나의 인스트럭션 또는 모듈을 로드하기 위한 휘발성 메모리를 포함할 수 있다. 프로세서는 복수의 마이크를 통해 음향 신호가 수신되면, 센서에서 센싱된 거리 정보에 기초하 여 전자 장치 주변의 공간에서 음원에 대한 적어도 하나의 후보 공간을 식별하고, 식별된 후보 공간에 대 해 음원 위치 추정을 수행하여 음향 신호가 출력된 음원의 위치를 식별하고, 식별된 음원의 위치에 기초하여 디 스플레이가 음원을 향하도록 구동부를 제어할 수 있다. 구체적인 내용은 도 3을 참조하여 함께 설명 하도록 한다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 도 3을 참조하면, 프로세서는 센서를 통해 전자 장치 주변의 공간에 존재하는 객체와의 거리를 센싱할 수 있다(S310). 구체적으로, 프로세서는 센서를 통해 전자 장치 주변의 공간에 대해 일정 거리 내 존재하는 객 체와의 거리를 감지할 수 있다. 여기서, 전자 장치 주변의 공간은 센서를 통해 센싱할 수 있는 거리 내의 XY 축의 공간일 수 있다. 다만, 이는 일 실시 예일 뿐이며, 주변의 공간은 센서를 통해 센싱할 수 있는 거리 내의 XYZ 축의 공간일 수도 있다. 예를 들어, 도 4와 같이 센서를 통해 전자 장치 주변의 공간에 대해 전방, 측방, 후방 등 의 전 방향으로 일정 거리 내 존재하는 객체와의 거리를 감지할 수 있다. 그리고, 프로세서는 센서에서 센싱된 거리 정보에 기초하여 적어도 하나의 후보 공간을 식별할 수 있 다(S315). 구체적으로, 프로세서는 센서에서 센싱된 거리 정보에 기초하여 전자 장치 주변에서 기설정된 형상을 갖는 적어도 하나의 객체를 식별할 수 있다. 보다 구체적인 일 실시 예로서, 프로세서는 센서에서 센싱된 거리 정보에 기초하여 전자 장치 주변의 XY 축의 공간에서 기설정된 형상을 갖는 적어도 하나의 객체를 식별할 수 있다. 일 실시 예로서, 기설정된 형상은 사용자의 발의 형상일 수 있다. 여기서, 형상은 XY 축의 공간에서 객체 의 굴곡, 모양, 크기 등을 나타내는 것이다. 또한, 사용자의 발의 형상은 기등록된 특정 사용자의 발의 형 상 또는 등록되지 않은 일반적인 사용자의 발의 형상일 수도 있다. 다만, 이는 일 실시 예일 뿐이며, 기설정된 형상은 사용자의 신체 일부의 형상(예를 들어, 얼굴의 형상, 상반신 또는 하반신의 형상) 또는 사용자 의 전신의 형상 등 다양한 형상으로 설정될 수 있다. 예를 들어, 프로세서는 공간 좌표 별 센싱된 거리 정보에 기초하여, 거리 차가 기설정된 값 이하가 되는 인접한 공간 좌표를 합쳐 하나의 객체(또는 클러스터)로 분류하고, 분류된 객체의 공간 좌표 별 거리에 따라 객 체의 형상을 식별할 수 있다. 그리고, 프로세서는 히스토그램 비교, 템플릿 매칭, 피처 매칭 등의 다양한 방식을 통해 식별된 각 객체의 형상과 기설정된 형상의 유사도를 비교하고, 유사도가 기설정된 값을 초과하는 객체를 기설정된 형상을 갖는 객체로서 식별할 수 있다. 이 경우, 프로세서는 식별된 객체의 위치에 기초하여 적어도 하나의 후보 공간을 식별할 수 있다. 여기서, 후보 공간은 음성을 발화한 사용자가 존재할 가능성이 높은 것으로 추정되는 공간을 나타낼 수 있다. 후보 공간은 음원 위치 추정의 계산의 대상이 되는 공간을 줄여 음원 위치 추정의 계산량을 감소시키고 리소스의 효 율성을 도모하기 위한 목적에서 도입된 것이다. 또한, 마이크만을 이용할 경우에 비해 물리적인 객체를 감지하 는 센서를 이용함으로써 보다 정확하게 음원의 위치를 탐색할 수 있다. 보다 구체적인 일 실시 예로서, 프로세서는 XY 축의 공간에서 식별된 객체가 위치한 영역에 대해, Z 축으 로 기설정된 높이를 갖는 적어도 하나의 공간을 적어도 하나의 후보 공간으로 식별할 수 있다. 여기서, Z 축으 로 기설정된 높이는 사용자의 키를 고려한 값일 수 있다. 예를 들어, Z 축으로 기설정된 높이는 100cm 내 지 250cm 범위 내에 대응되는 값일 수 있다. 또한, Z 축으로 기설정된 높이는 기등록된 특정 사용자의 키의 높 이 또는 등록되지 않은 일반적인 사용자의 높이일 수도 있다. 다만, 이는 일 실시 예일 뿐이며 Z 축으로 기설정 된 높이는 다양한 값을 갖도록 변형될 수 있다. 후보 공간을 식별하는 구체적인 일 실시 예로서, 도 5 및 도 6을 참조하여 함께 설명하도록 한다. 도 5 및 도 6은 본 개시의 일 실시 예에 따른 후보 공간을 식별하는 방법을 설명하기 위한 도면이다. 도 5 및 도 6을 참조하면, 프로세서는 센서를 통해 전자 장치의 주변 공간인 XY 축의 공간(또는 전 방위의 수평 공간)(H) 내에 존재하는 객체와의 거리를 감지할 수 있다. 이 경우, 프로세서는 센서를 통해 사용자 A(200A)와의 거리 da를 센싱할 수 있다. 그리고, 프로세서 는 거리 da와 거리의 차이가 기설정된 값 이하를 갖는 인접한 공간 좌표를 하나의 영역으로 합치고, 합쳐 진 영역(예: A1(xa, ya))을 하나의 객체 A로 분류할 수 있다. 프로세서는 객체 A의 각 지점 별 거리(예: da 등)에 기초하여 객체 A의 형상을 식별할 수 있다. 여기서, 객체 A의 형상이 발의 형상을 갖는 것으로 식별된 경 우를 가정하면, 프로세서는 식별된 객체 A가 위치한 영역(예: A1(xa, ya))에 대해 Z 축으로 기설정된 높이 를 갖는 공간(예: A1(xa, ya, za))을 후보 공간으로 식별할 수 있다. 이와 마찬가지로 프로세서는 사용자 B(200B)와의 거리 db를 센싱하여 하나의 후보 공간(예: B1(xb, yb, zb))을 식별할 수 있다. 그리고, 프로세서는 복수의 마이크를 통해 음향 신호를 수신할 수 있다(S320). 일 실시 예로서, 음향 신호는 사용자가 음성을 발화함으로써 발생될 수 있다. 이때, 음원은 음향 신호가 출력되는 사용자의 입일 수 있다. 음향 신호를 수신하는 구체적인 일 실시 예로서, 도 7 및 도 8을 참조하여 함께 설명하도록 한다. 도 7은 음향 신호를 수신하는 복수의 마이크를 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시 예에 따른 복수의 마이크를 통해 수신된 음향 신호를 설명하기 위한 도면이다. 도 7 및 도 8을 참조하면, 복수의 마이크는 서로 다른 위치에 배치될 수 있다. 설명의 편의를 위해, 복수 의 마이크는 x축으로 배치된 제1 마이크(110-1) 및 제2 마이크(110-2)를 포함하는 것으로 가정하여 설명하 도록 한다. 여기서, 사용자 A(200A)가 “오늘 날씨 알려줘”와 같은 음성을 발화할 경우에 발생된 음향 신호가 복수의 마이 크로 수신될 수 있다. 이때, 사용자 A(200A)와 보다 근접한 위치에 배치된 제1 마이크(110-1)가 도 8의 과 같은 음향 신호를 제2 마이크(110-2) 보다 먼저인 t1 초부터 수신하며, 사용자 A(200A)와 보다 먼 위치에 배치된 제2 마이크(110-2)가 도 8의 와 같은 음향 신호를 제1 마이크(110-1) 보다 나중인 t2 초부터 수신할 수 있다. 이때, t1과 t2의 차이는 제1 마이크(110-1) 및 제2 마이크(110-2) 간의 거리 d와 음파의 속도에 대한 비로 나타날 수 있다. 한편, 프로세서는 복수의 마이크를 통해 수신된 음향 신호에 대해 VAD(Voice Activity Detection) 또는 EPD(End Point Detection) 등의 다양한 방식을 통해 음성 구간을 추출할 수도 있다. 한편, 프로세서는 복수의 마이크를 통해 수신된 음향 신호에 대해 DOA(Direction of Arrival) 알고 리즘 등을 통해 음향 신호의 방향을 식별할 수 있다. 예를 들어, 프로세서는 복수의 마이크의 배치 관계를 고려하여, 복수의 마이크로 수신되는 음향 신호의 순서를 통해 음향 신호의 진행 방향(또는 진행 각도)을 식별할 수 있다. 그리고, 프로세서는 복수의 마이크를 통해 음향 신호가 수신되면(S320), 식별된 후보 공간에 대해 음 원 위치 추정을 수행할 수 있다(S330). 여기서, 음원 위치 추정은 SRP(Steered Response Power) 또는 SRP- PHAT(Steered Response Power - phase transform) 등의 다양한 알고리즘일 수 있다. 이때, SRP-PHAT 등은 음원 의 위치를 찾기 위해 블록 단위로 모든 공간을 검색하는 그리드(grid) 검색 방식일 수 있다. 구체적인 일 실시 예로서, 프로세서는 식별된 후보 공간 각각을 복수의 블록으로 구분할 수 있다. 각 블록 은 공간 내에서 고유한 xyz 좌표 값을 가질 수 있다. 예를 들어, 각 블록은 음향 신호에 대한 가상의 공간 내에 존재할 수 있다. 이때, 가상의 공간은 센서에 의해 센싱되는 공간과 서로 매칭될 수 있다. 이 경우, 프로세서는 각 블록에 대해 빔포밍 파워를 산출하는 음원 위치 추정을 수행할 수 있다. 예를 들어, 프로세서는 각 블록에 기설정된 지연 값을 복수의 마이크를 통해 수신된 음향 신호에 적 용하고, 음향 신호를 서로 합칠 수 있다. 즉, 프로세서는 블록 단위로 기설정된 지연 시간(또는 주파수 등)에 따라 지연된 복수의 음향 신호를 더하여 하나의 음향 신호로 생성할 수 있다. 이때, 프로세서는 음 향 신호 중에서 음성 구간 내의 신호만을 추출하고, 추출된 복수의 신호에 지연 값을 적용하여 하나의 음향 신 호로 합칠 수도 있다. 이 경우, 빔포밍 파워는 합쳐진 음향 신호의 음성 구간 내에서 가장 큰 값(예: 가장 큰 진폭 값)일 수 있다. 각 블록에 대해 기설정된 지연 값은 실제 음원의 정확한 위치에 대해 가장 높은 빔포밍 파워를 산출할 수 있도 록 복수의 마이크가 배치된 방향 및 복수의 마이크 간의 거리 등을 고려하여 설정된 값일 수 있다. 이에 따라, 각 블록에 대해 기설정된 지연 값은 마이크 단위로 동일하거나 다를 수 있다. 그리고, 프로세서는 음향 신호가 출력된 음원의 위치를 식별할 수 있다(S340). 이때, 음원의 위치는 음성 을 발화한 사용자의 입의 위치일 수 있다. 구체적인 일 실시 예로서, 프로세서는 산출된 빔포밍 파워가 가장 큰 블록의 위치를 음원의 위치로 식별할 수 있다. 음원의 위치를 식별하는 구체적인 일 실시 예로서, 도 9 내지 도 11을 참조하여 함께 설명하도록 한다. 도 9는 본 개시의 일 실시 예에 따른 블록 별 기설정된 지연 값을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 빔포밍 파워를 산출하는 방법을 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시 예에 따른 음원의 위치를 식별하는 방법을 설명하기 위한 도면이다. 여기서, 식별된 후보 공간은 도 6과 같이 A1(xa, ya, za)이고, 복수의 마이크를 통해 수신된 음향 신호는 도 8과 같은 신호인 것으로 가정하여 설명하도록 한다. 또한, 설명의 편의를 위해 제2 마이크(110-2)를 통해 수 신된 음향 신호에 대해 지연 값이 적용되는 것으로 가정하여 설명하도록 한다. 도 9를 참조하여, 프로세서는 식별된 후보 공간 A1(xa, ya, za)을 (xa1, ya1, za1) 내지 (xa2, ya2, za2) 등의 복수의 블록(예: 도 9의 경우 8개의 블록)으로 구분할 수 있다. 이때, 블록은 기설정된 크기 단위를 가질 수 있 다. 각 블록은 센서를 통해 감지되는 공간 좌표와 대응될 수 있다. 그리고, 프로세서는 복수의 블록 각각에 매칭된 기설정된 지연 값을 제2 마이크(110-2)를 통해 수신된 음 향 신호에 적용할 수 있다. 이때, 기설정된 지연 값 τ는 블록의 xyz 값에 따라 달라질 수 있다. 예를 들어, 도 9와 같이 (xa1, ya1, za1) 블 록에 기설정된 지연 값은 0.95이며, (xa2, ya2, za2) 블록에 기설정된 지연 값은 1.15일 수 있다. 이 경우, 도 8 의 와 같은 형태의 음향 신호 mic2(t)는 도 10의 와 같은 형태의 음향 신호 mic2(t-τ) 로 기설정된 지연 값 τ 만큼 쉬프팅(shifting)될 수 있다. 도 10을 참조하여, 프로세서는 도 10의 과 같은 형태의 음향 신호 mic1(t) 및 기설정된 지연 값 τ이 적용된 도 10의 과 같은 형태의 음향 신호 mic2(t-τ)를 합산하면(또는 합성하면), 도 10의 과 같은 형태 의 음향 신호 sum을 산출할 수 있다. 이때, 프로세서는 합산된 음향 신호 내 음성 구간에서 가장 큰 진폭 값을 빔포밍 파워라고 결정할 수 있다. 프로세서는 이와 같은 산출 과정을 각 블록마다 수행할 수 있다. 즉, 블록의 수와 연산량 또는 연산 횟수 는 비례하는 관계일 수 있다. 도 11을 참조하여, 프로세서가 후보 공간 내 전체 블록에 대해 빔포밍 파워를 산출하면, 일 예로서 도 11 과 같은 형태의 데이터를 산출할 수 있다. 여기서, 프로세서는 빔포밍 파워가 가장 큰 블록의 위치인 (xp, yp, zp)를 음원의 위치로서 식별할 수 있다. 또한, 본 개시의 일 실시 예에 따른 프로세서는 합성된 음향 신호 중에서 빔포밍 파워가 가장 큰 블록의 위치를 음원의 위치로 식별하고, 식별된 음원의 위치에 해당하는 합성된 음향 신호 내의 음성 구간을 통해 음성 인식을 수행할 수도 있다. 이에 따라, 노이즈는 억제하고, 음성 구간에 해당하는 신호만을 강화할 수 있다. 또한, 수신된 음향 신호에 복수의 사용자가 발화한 음성이 포함된 경우에는, 후보 공간 단위로 지연 값을 적용 하여 음향 신호를 합성시키고, 후보 공간 단위에서 가장 큰 빔포밍 파워를 갖는 블록의 위치를 음원의 위치로 식별하여, 식별된 음원의 위치 별로 음성 구간을 분리하여 음성 인식을 수행할 수 있다. 이에 따라, 화자가 복 수인 경우에도 각 음성을 정확하게 인식할 수 있게 되는 효과가 있다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 도 3과 같이 객체와의 거리를 센싱하는 S310 단계 이후에 곧바로 후보 공간을 식별하는 S315 단계를 수행할 수 있다. 다만, 이는 일 실시 예일 뿐이며, 프로세서는 음향 신호가 수신된 이후에 후보 공간을 식별하는 S315 단계를 수행하고, 식별된 후보 공간에 대해 음원 위치 추정의 S330 단계를 수행할 수도 있다. 특히, 프로세서는 음향 신호가 수신된 이후에 후보 공간을 식별할 경우에는, 기설정된 형상을 갖는 객체 중에서 음향 신호의 진행 방향에 위치한 객체가 존재하는 공간을 후보 공간으로 식별할 수도 있다. 예를 들어, 도 5와 같이 프로세서는 센서를 통해 센싱된 거리 정보에 기초하여 전자 장치의 좌 측에 위치하는 사용자 A(200A) 및 전자 장치의 우측에 위치하는 사용자 B(200AB)를 기설정된 형상의 객체 로 식별할 수 있다. 여기서, 전자 장치의 좌측 방향에 위치한 사용자 A(200A)가 “오늘 날씨 알려줘”와 같은 음성을 발화한 경우라면, 복수의 마이크 중에서 좌측 방향에 위치한 마이크에 음향 신호가 먼저 수신 되고 이후 우측 방향에 위치한 마이크에 음향 신호가 수신될 수 있다. 이 경우, 프로세서는 복수의 마이크 의 배치 관계 및 복수의 마이크 각각에 수신되는 음향 신호의 시간에 기초해, 음향 신호의 진행 방향 은 좌측에서 우측이라는 것을 파악할 수 있다. 그리고, 프로세서는 사용자 A(200A)가 위치하는 공간 및 사 용자 B(200B)가 위치하는 공간 중에서, 사용자 A(200A)가 위치하는 공간을 후보 공간으로 식별할 수 있다. 이와 같이, 후보 공간의 수를 줄일 수 있어 계산량이 보다 감소되는 효과가 있다. 그리고, 프로세서는 식별된 음원의 위치에 기초하여 디스플레이가 음원을 향하도록 구동부를 제 어할 수 있다(S350). 일 실시 예로서, 디스플레이는 전자 장치를 구성하는 헤드 및 바디 중 헤드에 위치할 수 있다. 여기서, 프로세서는 전자 장치와 음원 간의 거리가 기설정된 값 이하인 경우, 디스플레이가 음 원을 향하도록, 구동부를 통해 전자 장치의 방향 및 헤드의 각도 중 적어도 하나를 조정할 수 있 다. 이 경우, 프로세서는 헤드에 위치하는 디스플레이가 식별된 음원의 위치를 향하도록 구동부(13 0)를 제어할 수 있다. 예를 들어, 프로세서는 헤드를 회전시켜 디스플레이가 함께 회전되도록 구 동부를 제어할 수 있다. 이때, 헤드 및 디스플레이는 Z 축과 수직한 축을 중심으로 회전할 수 있으나, 이는 일 실시 예일 뿐이며 Z 축을 중심으로 회전할 수도 있다. 또한, 프로세서는 눈을 나타내는 오브젝트 또는 입을 나타내는 오브젝트를 표시하도록 헤드의 디스플 레이를 제어할 수도 있다. 이때, 오브젝트는 눈의 깜박임 및/또는 입의 움직임 등의 효과를 주는 오브젝트 일 수도 있다. 다른 예로서, 헤드에는 디스플레이를 대신하여, 눈 및/또는 입을 나타내는 구조물이 형 성되거나 부착될 수도 있다. 이와 달리, 프로세서는 전자 장치와 음원 간의 거리가 기설정된 값을 초과하는 경우, 디스플레이 가 음원을 향하도록, 구동부를 통해 음원으로부터 기설정된 거리만큼 떨어진 지점까지 전자 장치 를 이동시키고 헤드의 각도를 조정할 수 있다. 전자 장치가 구동하는 구체적인 일 실시 예로서, 도 12 및 도 13을 참조하여 함께 설명하도록 한다. 도 12 및 도 13은 본 개시의 일 실시 예에 따른 음원의 위치에 따라 구동되는 전자 장치를 설명하기 위한 도면 이다. 도 12의 경우 식별된 음원의 위치의 Z 값이 도 13에 비해 더 큰 것을 나타낸 것이며, 도 13의 경우 식별 된 음원의 위치의 Z 값이 도 12에 비해 더 작은 것을 나타낸 도면이다. 도 12 및 도 13을 참조하면, 프로세서는 사용자 A(200A)가 발화한 음성을 포함하는 음향 신호가 수신되면, 전술한 내용에 따라 음원의 위치를 식별할 수 있다. 이때, 음원의 위치는 사용자 A(200A)의 위치로 추정될 수 있다. 예를 들어, 프로세서는 헤드의 전면에 배치된 디스플레이(120-1) 및 바디의 전면에 배치된 디스플 레이(120-2)의 위치가 음원의 위치를 향하도록 구동부를 제어할 수 있다. 여기서, 현재 전자 장치의 헤드 및 바디의 전면에 배치된 디스플레이(120-1, 120-2)가 음원의 위치를 향하지 않는 경우를 가정하 면, 프로세서는 전자 장치의 헤드 및 바디의 전면에 배치된 디스플레이(120-1, 120-2)가 음 원의 위치를 향하도록 구동부를 제어하여 전자 장치를 회전시킬 수 있다. 그리고, 프로세서는 헤드가 음원의 위치를 향하도록 구동부를 통해 헤드의 각도를 조정할 수 있다. 예를 들어, 도 12와 같이 헤드의 Z축 상 높이가 음원의 위치(예: 사용자 A(200A)의 얼굴의 위치)인 Z축 상 높이보다 작은 경우에는 XY 축 상의 평면을 기준으로 하는 각도가 증가되는 방향으로 헤드의 각도를 조정할 수 있다. 또 다른 예를 들어, 도 13과 같이 헤드의 Z축 상 높이가 음원의 위치(예: 사용자 A(200A)의 얼굴 의 위치)인 Z축 상 높이보다 큰 경우에는 XY 축 상의 평면을 기준으로 하는 각도가 감소되는 방향으로 헤드(1 0)의 각도를 조정할 수 있다. 이때, 전자 장치와 음원 간의 거리가 가까울수록 조정되는 헤드의 각도 가 커질 수 있다. 또한, 프로세서는 전자 장치와 음원 간의 거리가 기설정된 값을 초과하는 경우, 디스플레이가 음원을 향하도록, 구동부를 통해 음원으로부터 기설정된 거리만큼 떨어진 지점까지 전자 장치를 이동 시킬 수 있다. 또한, 프로세서는 전자 장치가 이동되는 동안 디스플레이가 음원을 향하도록, 구 동부를 통해 헤드의 각도를 조정할 수 있다. 한편 본 개시의 일 실시 예에 따른 전자 장치는 카메라(160, 도 17 참조)를 더 포함할 수 있다. 카메라는 특정한 방향의 촬영 영역에 대한 촬영을 통해 이미지를 획득할 수 있다. 예를 들어, 카메라(16 0)는 특정한 방향에서 들어오는 빛을 픽셀 단위로 센싱하여 픽셀의 집합인 이미지를 획득할 수 있다. 일 실시 예로서, 프로세서는 식별된 음원의 위치에 기초하여 카메라를 통해 음원이 위치하는 방향으 로 촬영을 수행할 수 있다. 이는, 제한되는 복수의 마이크의 개수 및 배치, 주변 공간의 소음 또는 공간 특징(예: 반향)으로 인해 복수의 마이크를 통해 수신되는 음향 신호만으로 음원의 위치를 정확히 파악하는 것은 어려움이 있기 때문에, 센서 및/또는 카메라를 이용하여 음원의 위치를 보다 정확하게 파악하기 위함이다. 구체적인 일 실시 예로서, 프로세서는 복수의 블록 중 가장 큰 빔포밍 파워를 갖는 제1 블록의 위치를 음 원의 위치로 식별할 수 있다. 이 경우, 프로세서는 식별된 음원의 위치에 기초하여 카메라를 통해 음 원이 위치하는 방향으로 촬영을 수행할 수 있다. 여기에서, 프로세서는 카메라를 통해 촬영된 이미지에 기초하여 이미지에 포함된 사용자의 입의 위치를 식별할 수 있다. 예를 들어, 프로세서는 영상 인식 알고리즘을 이용하여 이미지에 포함된 사용자의 입(또는 눈, 코 등)을 식별하고 입의 위치를 식별할 수 있다. 구체적으로, 프로세서는 이미지에 포함된 복수의 픽셀 중에 서 색상(또는 계조)이 제1 기설정된 범위 이내의 값을 갖는 픽셀의 색상 값을 블랙에 해당하는 색상 값으로 처 리하고, 색상 값이 제2 기설정된 범위 이내의 값을 갖는 픽셀의 색상 값을 화이트에 해당하는 색상 값으로 처리 할 수 있다. 이 경우, 프로세서는 블랙의 색상 값을 갖는 픽셀을 연결하여 윤곽선으로 식별하고, 화이트의 색상 값을 갖는 픽셀을 배경으로 식별할 수 있다. 이 경우, 프로세서는 데이터베이스에 기저장된 오브젝트 (예: 눈, 코 또는 입 등)의 형상과 검출된 윤곽선이 일치하는 정도를 확률 값(또는 스코어)으로 계산할 수 있다. 그리고, 프로세서는 해당 윤곽선에 대해 계산된 확률 값 중에서 가장 확률 값이 높은 형상의 오브젝 트로서 식별할 수 있다. 이 경우, 프로세서는 이미지를 통해 식별된 입의 위치에 기초하여 디스플레이가 입을 향하도록 구동 부를 제어할 수 있다. 이와 달리, 프로세서는 카메라를 통해 촬영된 이미지에 사용자가 존재하지 않는 경우, 제1 블록 다음으로 큰 빔포밍 파워를 갖는 제2 블록의 위치를 음원의 위치로 식별하고, 식별된 음원의 위치에 기초하여 디스플레이가 음원을 향하도록 구동부를 제어할 수 있다. 이에 따라, 본 개시의 일 실시 예에 따른 전자 장치는 제한되는 하드웨어 또는 소프트웨어 상의 한계를 극 복하고 음원의 위치를 실시간으로 정확하게 식별할 수 있다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 음원이 위치하는 후보 공간에 대응되는 객체에 식별된 음 원의 Z 축 상의 높이 정보를 맵핑시키고, 센서에서 센싱된 거리 정보에 기초하여 XY 축의 공간에서 객체의 이동 궤적을 추적하고, 음향 신호와 동일한 음원에서 출력된 후속 음향 신호가 복수의 마이크를 통해 수신 되면, 객체의 이동 궤적에 따른 객체의 XY 축의 공간 상의 위치 및 객체에 맵핑된 Z 축 상의 높이 정보에 기초 하여 후속 음향 신호가 출력된 음원의 위치를 식별할 수 있다. 이에 대해서는 도 14 및 도 15를 참조하여 구체적으로 설명하도록 한다. 도 14 및 도 15는 본 개시의 일 실시 예에 따른 이동 궤적을 통한 음원의 위치를 식별하는 방법을 설명하기 위 한 도면이다. 도 14를 참조하면, 도 14의 과 같이 사용자는 음성을 발화함으로써 음향 신호(예: “오늘 날씨 알려줘 ”)를 발생시킬 수 있다. 이 경우, 도 14의 와 같이 프로세서는 음향 신호(예: “오늘 날씨 알려줘”)가 복수의 마이크를 통해 수신되면, 센서에서 센싱된 거리 정보에 기초하여 전자 장치 주변의 공간에서 음원에 대한 적어 도 하나의 후보 공간(예: (x1:60, y1:80))을 식별하고, 식별된 후보 공간에 대해 음원 위치 추정을 수행하여 음 향 신호가 출력된 음원의 위치(예: (x1:60, y1:80, z1:175))를 식별할 수 있다. 그리고, 프로세서는 디스플 레이가 음원의 위치를 향하도록 구동부를 제어할 수 있다. 전술한 내용과 중복된다는 점에서 이에 대 한 구체적인 설명은 생략하기로 한다. 이때, 프로세서는 음원이 위치하는 후보 공간에 대응되는 객체에 식별된 음원의 Z 축 상의 높이 정보를 맵 핑시킬 수 있다. 예를 들어, 프로세서는 음원의 위치(예: (x1:60, y1:80, z1:175))가 식별된 이후에, 음원 의 위치 중 Z 축 상의 높이 정보(예: (z1:175))를 음원이 위치하는 후보 공간(예: (x1:60, y1:80))에 대응되는 객체(예: 사용자)에 맵핑시킬 수 있다. 이후, 도 14의 과 같이 사용자는 위치를 이동할 수 있다. 한편, 프로세서는 센서에서 센싱된 거리 정보에 기초하여 XY 축의 공간에서 객체의 이동 궤적을 추적 할 수 있다. 여기서, 이동 궤적을 추적하는 대상에는 음성을 발화한 사용자뿐만 아니라 다른 사용자 등의 객체까지도 포함될 수 있다. 즉, 프로세서는 센서에서 센싱된 거리 정보에 기초해 복수의 객체가 위 치를 변경하거나 이동하더라도 이동 궤적을 통해 복수의 객체들을 구별할 수 있다. 예를 들어, 프로세서는 XY 축의 공간에서 센서에서 센싱된 거리 정보를 기설정된 시간 주기마다 측정 함으로써 시간에 따른 객체의 위치를 추적할 수 있다. 이때, 프로세서는 연속된 시간 동안 기설정된 값 이 하를 갖는 객체의 위치 변화를 하나의 이동 궤적으로 추적할 수 있다. 도 15를 참조하여, 도 15의 와 같이 사용자는 음성을 발화함으로써 후속의 음향 신호(예: “영화 추천 해 줘”)를 발생시킬 수 있다. 이 경우, 프로세서는 도 15의 와 같이 음향 신호와 동일한 음원에서 출력된 후속 음향 신호가 복수의 마이크를 통해 수신되면, 객체의 이동 궤적에 따른 객체의 XY 축의 공간 상의 위치(예: (x2:-10, y2:30)) 및 객체에 맵핑된 Z 축 상의 높이 정보(예: (z1:175))에 기초하여 후속 음향 신호가 출력된 음원의 위치(예: (x2:-10, y2:30, z1:175))를 식별할 수 있다. 이후, 프로세서는 디스플레이가 후속 음향 신호가 출력 된 음원의 위치를 향하도록 구동부를 제어할 수 있다. 즉, 프로세서는 디스플레이가 후속 음향 신호가 출력된 음원의 위치를 향하도록 전자 장치를 이동시키거나 전자 장치를 회전시킬 수 있다. 또 한, 프로세서는 후속 음향 신호에 응답한 정보(예: TOP 10 영화 리스트 등)를 표시하도록 디스플레이(12 0)를 제어할 수 있다. 이와 같이, 프로세서는 센서를 통해 센싱되는 이동 궤적을 통해 식별되는 객체 및 객체와의 거리, 객 체에 맵핑된 Z 축상의 높이 정보에 기초하여 음원의 위치를 식별할 수 있다. 즉, 빔포밍 파워를 산출하지 않고 서도 음원의 위치를 식별할 수 있다는 점에서 음원의 위치를 산출하기 위한 계산량을 보다 감소시킬 수 있다. 이상과 같은 본 개시의 다양한 실시 예에 따르면, 음원의 위치에 기반하여 음성 인식 서비스에 대한 사용자 경 험을 향상시키는 전자 장치 및 그의 제어 방법을 제공할 수 있다. 또한, 음원의 위치를 보다 정확하게 탐색하여 음성 인식에 대한 정확도를 향상시키는 전자 장치 및 그의 제어 방법을 제공할 수 있다. 도 16은 본 개시의 일 실시 예에 따른 음성 인식을 설명하기 위한 도면이다. 도 16을 참조하면, 가상의 인공지능 에이전트와 자연어를 통해 대화를 수행하거나 전자 장치를 제어하기 위한 구성으로서, 전자 장치는 전처리 모듈, 대화 시스템 및 출력 모듈을 포함할 수 있다. 이때, 대화 시스템에는 웨이크-업 워드 인식 모듈, 음성 인식 모듈, 자연어 이해 모듈, 대 화 매니저 모듈, 자연어 생성 모듈, TTS 모듈을 포함할 수 있다. 한편, 본 개시의 일 실시 예에 따르면, 대화 시스템에 포함된 모듈은 전자 장치의 메모리(170, 도 17 참조) 내에 저장될 수 있으나, 이는 일 실시 예에 불과할 뿐, 하드웨어와 소프트웨어의 결합된 형태로 구현될 수 있다. 또한, 대화 시스템 에 포함된 적어도 하나의 모듈은 외부의 적어도 하나의 서버에 포함될 수 있다. 전처리 모듈은 복수의 마이크를 통해 수신된 음향 신호에 대한 전처리를 수행할 수 있다. 구체적으로, 전처리 모듈은 사용자가 발화한 음성을 포함하는 아날로그 형태의 음향 신호를 수신할 수 있으며, 아날로그 형태의 음향 신호를 디지털 형태의 음향 신호로 변환할 수 있다. 그리고, 전처리 모듈 은 변환된 디지털 신호의 에너지를 계산하여 사용자의 음성 구간을 추출할 수 있다. 구체적으로, 전처리 모듈은 디지털 신호의 에너지가 기설정된 값 이상인지 여부를 판단할 수 있다. 디지털 신호의 에너지가 기설정된 값 이상인 경우, 전처리 모듈는 음성 구간으로 판단하여 입력된 디지털 신호에 대한 노이즈를 제거하여 사용자의 음성을 강화할 수 있다. 또는, 디지털 신호의 에너지가 기설정된 값 미 만인 경우, 전처리 모듈은 입력된 디지털 신호에 대한 신호 처리를 수행하지 않고, 다른 입력을 기다릴 수 있다. 이에 의해, 사용자의 음성이 아닌 다른 소리에 의해 전체 오디오 처리 과정이 활성화되지 않아, 불 필요한 전력 소모를 방지할 수 있다. 웨이크-업 워드 인식 모듈은 웨이크-업 모델을 통해 사용자의 음성에 웨이크-업 워드가 포함되었는지 여부를 판단할 수 있다. 이때, 웨이크-업 워드(또는 트리거 워드, 또는 호출어)라 함은 사용자가 음성 인식을 시작하는 것을 알리는 명령어(예: 빅스비, 갤럭시 등)로서, 전자 장치가 대화 시스템을 실행시킬 수 있다. 이때, 웨이크-업 워드는 제조시부터 기 설정될 수 있으나, 이는 일 실시 예에 불과할 뿐 사용자 설정에 의해 변 경될 수 있다. 음성 인식 모듈은 전처리로부터 수신된 오디오 데이터 형태의 사용자의 음성을 텍스트 데이터로 변환할 수 있다. 이때, 음성 인식 모듈은 사용자의 특성 별로 학습된 복수의 음성 인식 모델을 포함 할 수 있으며, 복수의 음성 인식 모델 각각은 음향(acoustic) 모델 및 언어(language) 모델을 포함할 수 있다. 음향 모델은 발성에 관련된 정보를 포함할 수 있고, 언어 모델은 단위 음소 정보 및 단위 음소 정보의 조합에 대한 정보를 포함할 수 있다. 음성 인식 모듈은 발성에 관련된 정보 및 단위 음소 정보에 대한 정보를 이 용하여 사용자의 음성을 텍스트 데이터로 변환할 수 있다. 음향 모델 및 언어 모델에 대한 정보는, 예를들어, 자동 음성 인식 데이터베이스(automatic speech recognition database)(ASR DB)에 저장될 수 있다. 자연어 이해 모듈은 음성 인식을 통해 획득된 사용자의 음성에 대한 텍스트 데이터를 바탕으로 문법 적 분석(syntactic analyze) 또는 의미적 분석(semantic analyze)을 수행하여 사용자의 음성에 대한 도메 인 및 사용자의 의도를 파악할 수 있다. 이때, 문법적 분석은 사용자 입력을 문법적 단위(예: 단어, 구, 형태소 등)로 나누고, 나누어진 단위가 어떤 문법적인 요소를 갖는지 파악할 수 있다. 의미적 분석은 의미 (semantic) 매칭, 룰(rule) 매칭, 포뮬러(formula) 매칭 등을 이용하여 수행할 수 있다. 대화 매니저 모듈은 자연어 이해 모듈에 획득된 사용자 의도 및 슬롯을 바탕으로 사용자 음성에 대한 응답 정보를 획득할 수 있다. 이때, 대화 매니저 모듈은 지식 DB를 기반으로 사용자 음성에 대한 응답을 제공할 수 있다. 이때, 지식 DB는 전자 장치 내에 포함될 수 있으나, 이는 일 실시 예에 불과할 뿐, 외부 서버에 포함될 수 있다. 또한, 대화 매니저 모듈은 사용자 특성 별로 복수의 지식 DB를 포함할 수 있으며, 복수의 지식 DB 중 사용자 정보에 대응되는 지식 DB를 이용하여 사용자 음성에 대한 응답 정보를 획득할 수 있 다. 예를 들어, 사용자 정보를 바탕으로 사용자가 어린이라고 판단되면, 대화 매니저 모듈은 어린이에 대 응되는 지식 DB를 이용하여 사용자 음성에 대한 응답 정보를 획득할 수 있다. 또한, 대화 매니저 모듈은 자연어 이해 모듈에 의해 파악된 사용자의 의도가 명확한지 여부를 판단할 수 있다. 예를 들어, 대화 매니저 모듈은 슬롯에 대한 정보가 충분하지 여부에 기초하여 사용자 의도가 명 확한지 여부를 판단할 수 있다. 또한, 대화 매니저 모듈은 자연어 이해 모듈에서 파악된 슬롯이 태스 크를 수행하는데 충분한지 여부를 판단할 수 있다. 일 실시 예에 따르면, 대화 매니저 모듈은 사용자의 의 도가 명확하지 않은 경우 사용자에게 필요한 정보를 요청하는 피드백을 수행할 수 있다. 자연어 생성 모듈은 대화 매니저 모듈를 통해 획득된 응답 정보 또는 지정된 정보를 텍스트 형태로 변경할 수 있다. 텍스트 형태로 변경된 정보는 자연어 발화의 형태일 수 있다. 지정된 정보는, 예를 들어, 추가 입력에 대한 정보, 사용자 입력에 대응되는 동작의 완료를 안내하는 정보 또는 사용자의 추가 입력을 안내하는 정보(예: 사용자 입력에 대한 피드백 정보)일 수 있다. 텍스트 형태로 변경된 정보는 전자 장치의 디스플 레이에 표시되거나, TTS 모듈에 의해 음성 형태로 변경될 수 있다. TTS 모듈은 텍스트 형태의 정보를 음성 형태의 정보로 변경할 수 있다. 이때, TTS 모듈은 다양한 목 소리로 응답을 생성하기 위한 복수의 TTS 모델을 포함할 수 있다. 출력 모듈은 TTS 모듈로부터 수신된 음성 데이터 형태의 정보를 출력할 수 있다. 이때, 출력 모듈 은 스피커 또는 음성 출력 단자를 통해 음성 데이터 형태의 정보를 출력할 수 있다. 또는 출력 모듈 은 자연어 생성 모듈을 통해 획득된 텍스트 데이터 형태의 정보를 디스플레이 또는 영상 출력 단자를 통해 출력할 수 있다. 도 17은 본 개시의 일 실시 예에 따른 전자 장치의 부가적인 구성을 설명하기 위한 블록도이다. 도 17을 참조하면, 전자 장치는 복수의 마이크, 디스플레이, 구동부, 센서 및 프로세 서 외에도, 카메라, 스피커, 메모리, 통신 인터페이스, 입력 인터페이스 중에서 적어도 하나를 더 포함할 수 있다. 여기서 전술한 내용과 중복되는 설명은 생략하기로 한다. 센서는 거리를 센싱하기 위한 라이다 센서, 초음파 센서 등의 다양한 센서를 포함할 수 있다. 또한, 센서는 이외에도 근접 센서, 조도 센서, 온도 센서, 습도 센서, 모션 센서, GPS 센서 등 중에서 적 어도 하나를 포함할 수 있다. 여기서, 근접 센서(proximity sensor)는 주변 물체의 존재를 감지하여, 주변 물체의 존재 여부 또는 주변 물체 의 근접 여부에 대한 데이터를 획득할 수 있다. 조도 센서는 전자 장치의 주변 환경에 대한 광량(또는 밝 기)을 감지하여, 조도에 대한 데이터를 획득할 수 있다. 온도 센서는 열복사(또는 광자)에 따라 대상 오브젝트 의 온도 또는 전자 장치의 주변 환경의 온도(예: 실내 온도 등)를 감지할 수 있다. 이때, 온도 센서는 적 외선 카메라 등으로 구현될 수 있다. 습도 센서는 공기 중의 화학 반응에 의한 색 변화, 이온량 변화, 기전력, 전류변화 등 다양한 방식을 통해 공기 중의 수증기의 양을 감지하여 습도에 대한 데이터를 획득할 수 있다. 모 션 센서는 전자 장치의 이동 거리, 이동 방향, 기울기 등을 감지할 수 있다. 이를 위해, 모션 센서는 가속 도 센서, 자이로(gyro) 센서, 지자기 센서 등의 결합으로 구현될 수 있다. GPS(Global Positioning System) 센 서는 복수의 위성으로부터 전파 신호를 수신하고, 수신된 신호의 전달 시간을 이용하여 각 위성과의 거리를 각 각 산출하고, 산출된 거리를 삼각측량을 이용하여 전자 장치의 현재 위치에 대한 데이터를 획득할 수있다. 다만, 상술한 센서의 구현 예는 일 실시 예일 뿐이며, 이에 제한되지 아니하고 다양한 유형의 센서로 구현 되는 것이 가능하다 할 것이다. 카메라는 빛을 픽셀 단위로 센싱하여 픽셀의 집합인 이미지를 획득할 수 있다. 각 픽셀은 R(Red), G(Green), B(Blue) 값의 조합을 통해 색상, 형상, 명암, 밝기 등을 표현하는 정보를 포함할 수 있다. 이를 위해, 카메라는 RGB 카메라, RGB-D(Depth) 카메라, 적외선 카메라 등 다양한 카메라로 구현될 수 있다. 스피커는 다양한 음향 신호를 출력할 수 있다. 예를 들어, 스피커는 사용자의 가청주파수 범위 내의 주파수를 갖는 진동을 발생시킬 수 있다. 이를 위해, 스피커는 아날로그 오디오 신호를 디지털 오디 오 신호로 변환하는 아날로그-디지털 변환기(Analog to Digital Converter; ADC), 디지털 오디오 신호를 아날로 그 오디오 신호로 변환하는 디지털-아날로그 변환기(Digital to Analog Converter; DAC), 아날로그 형태의 음파 (Sound Wave or Acoustic Wave)를 발생시키는 진동판 등을 포함할 수 있다. 메모리는 다양한 정보(또는 데이터)가 저장될 수 있는 구성이다. 예를 들어, 메모리는 전기적인 형태 또는 자기적인 형태로 정보를 저장할 수 있다. 구체적으로, 메모리에는 전자 장치 또는 프로세서의 동작에 필요한 적어도 하나의 명령어 (instruction), 모듈 또는 데이터가 저장될 수 있다. 여기서, 명령어는 전자 장치 또는 프로세서의 동작을 지시하는 단위로서 전자 장치 또는 프로세서가 이해할 수 있는 기계어로 작성된 것일 수 있다. 모듈은 소프트웨어적인 프로그램(또는 운영체제, 어플리케이션, 동적 라이브러리, 런타임 라이브러리 등)을 구성하는 하위 단위의 명령어의 집합(instruction set)일 수 있으나, 이는 일 실시 예일 뿐, 모듈은 프로 그램 그 자체일 수 있다. 데이터는 문자, 숫자, 소리, 영상 등의 정보를 나타내기 위해 전자 장치 또는 프 로세서가 처리할 수 있는 비트(bit) 또는 바이트(byte) 등의 단위의 자료일 수 있다. 통신 인터페이스는 다양한 유형의 통신 방식에 따라 다양한 유형의 외부 장치와 통신을 수행하여 다양한 유형의 데이터를 송수신할 수 있다. 통신 인터페이스는 다양한 방식의 무선 통신을 수행하는 회로로서 블 루투스 모듈(블루투스 방식), 와이파이 모듈(와이파이 방식), 무선 통신 모듈(3G, 4G, 5G 등의 셀룰러 방식), NFC 모듈(NFC 방식), IR 모듈(적외선 방식), Zigbee 모듈(Zigbee 방식) 및 초음파 모듈(초음파 방식) 등과 유선 통신을 수행하는 이더넷 모듈, USB 모듈, HDMI(High Definition Multimedia Interface), DP(DisplayPort), D- SUB(D-subminiature), DVI(Digital Visual Interface), 썬더볼트(Thunderbolt) 및 컴포넌트 중 적어도 하나를 포함할 수 있다. 이 경우, 유선 통신을 수행하는 모듈은 입출력포트를 통하여 외부 장치와 통신을 수행할 수 있 다. 입력 인터페이스는 다양한 사용자 명령을 수신하여 프로세서로 전달할 수 있다. 즉, 프로세서는 입력 인터페이스를 통해 사용자로부터 입력된 사용자 명령을 인지할 수 있다. 여기서, 사용자 명령은 사용 자의 터치 입력(터치 패널), 키(키보드) 또는 버튼(물리 버튼 또는 마우스 등) 입력, 사용자 음성(마이크) 등 다양한 방식으로 구현될 수 있다. 구체적으로, 입력 인터페이스는 예를 들면, 터치 패널(미도시), 펜 센서(미도시), 버튼(미도시) 및 마이크 (미도시) 중에서 적어도 하나를 포함할 수 있다. 터치 패널은, 예를 들면, 정전식, 감압식, 적외선 방식, 또는 초음파 방식 중 적어도 하나의 방식을 사용할 수 있으며, 이를 위해 터치 패널은 제어 회로를 포함할 수도 있다. 터치 패널은 택타일 레이어(tactile layer)를 더 포함하여, 사용자에게 촉각 반응을 제공할 수 있다. 펜 센서는 예를 들면, 터치 패널의 일부이거나, 별도의 인식용 쉬트를 포함할 수 있다. 버튼은 예를 들면, 사용자 등의 접촉을 감지하는 버튼, 눌려진 상태를 감지하는 버튼, 광학식 키 또는 키패드를 포함할 수 있다. 마이크는 사용자의 음성을 직접 수신할 수 있으며, 디지털 변환부(미도시)에 의해 아날로그 신호인 사용자의 음성을 디지 털로 변환하여 오디오 신호를 획득할 수 있다. 도 18은 본 개시의 일 실시 예에 따른 흐름도를 설명하기 위한 도면이다. 도 18을 참조하면, 전자 장치의 제어 방법은, 복수의 마이크를 통해 음향 신호가 수신되면, 센서 에서 센싱된 거리 정보에 기초하여 전자 장치 주변의 공간에서 음원에 대한 적어도 하나의 후보 공간 을 식별하는 단계(S1810), 식별된 후보 공간에 대해 음원 위치 추정을 수행하여 음향 신호가 출력된 음원의 위 치를 식별하는 단계(S1820), 식별된 음원의 위치에 기초하여 디스플레이가 음원을 향하도록 구동부를 제어하는 단계(S1830)를 포함할 수 있다.구체적으로, 복수의 마이크를 통해 음향 신호가 수신되면, 센서에서 센싱된 거리 정보에 기초하여 전 자 장치 주변의 공간에서 음원에 대한 적어도 하나의 후보 공간을 식별할 수 있다(S1810). 여기서, 후보 공간을 식별하는 단계는 센서에서 센싱된 거리 정보에 기초하여 전자 장치 주변에서 기 설정된 형상을 갖는 적어도 하나의 객체를 식별할 수 있다. 이 경우, 식별된 객체의 위치에 기초하여 적어도 하 나의 후보 공간을 식별할 수 있다. 보다 구체적인 일 실시 예로서, 후보 공간을 식별하는 단계는 센서에서 센싱된 거리 정보에 기초하여 전자 장치 주변의 XY 축의 공간에서 기설정된 형상을 갖는 적어도 하나의 객체를 식별할 수 있다. 이 경우, XY 축의 공간에서 식별된 객체가 위치한 영역에 대해, Z 축으로 기설정된 높이를 갖는 적어도 하나의 공간을 적어 도 하나의 후보 공간으로 식별할 수 있다. 일 실시 예로서, 기설정된 형상은 사용자의 발의 형상일 수 있다. 여기서, 형상은 XY 축의 공간에서 객체 의 굴곡, 모양, 크기 등을 나타내는 것이다. 다만, 이는 일 실시 예일 뿐이며, 기설정된 형상은 사용자의 얼굴의 형상, 사용자의 상반신 또는 하반신의 형상, 사용자의 전신의 형상 등 다양한 형상으로 설정 될 수 있다. 그리고, 식별된 후보 공간에 대해 음원 위치 추정을 수행하여 음향 신호가 출력된 음원의 위치를 식별할 수 있 다(S1820). 일 실시 예로서, 음원은 사용자의 입일 수 있다. 일 실시 예로서, 음원의 위치를 식별하는 단계는 식별된 후보 공간 각각을 복수의 블록으로 구분하여, 각 블록 에 대해 빔포밍 파워를 산출하는 음원 위치 추정을 수행할 수 있다. 이 경우, 산출된 빔포밍 파워가 가장 큰 블 록의 위치를 음원의 위치로 식별할 수 있다. 구체적인 일 실시 예로서, 복수의 블록 중 가장 큰 빔포밍 파워를 갖는 제1 블록의 위치를 음원의 위치로 식별 할 수 있다. 이 경우, 식별된 음원의 위치에 기초하여 카메라를 통해 음원이 위치하는 방향으로 촬영을 수 행할 수 있다. 이 경우, 카메라를 통해 촬영된 이미지에 사용자가 존재하지 않는 경우, 제1 블록 다 음으로 큰 빔포밍 파워를 갖는 제2 블록의 위치를 음원의 위치로 식별할 수 있다. 이 경우, 식별된 음원의 위치 에 기초하여 디스플레이가 음원을 향하도록 구동부를 제어할 수 있다. 그리고, 식별된 음원의 위치에 기초하여 디스플레이가 음원을 향하도록 구동부를 제어할 수 있다 (S1830). 일 실시 예로서, 디스플레이는 전자 장치를 구성하는 헤드 및 바디 중 헤드에 위치할 수 있다. 이 경우, 디스플레이가 식별된 음원의 위치를 향하도록 구동부를 통해 헤드의 각도를 조정 할 수 있다. 여기서, 전자 장치와 음원 간의 거리가 기설정된 값 이하인 경우, 디스플레이가 음원을 향하도록, 구 동부를 통해 전자 장치의 방향 및 헤드의 각도 중 적어도 하나를 조정할 수 있다. 이와 달리, 전 자 장치와 음원 간의 거리가 기설정된 값을 초과하는 경우, 디스플레이가 음원을 향하도록, 구동부 를 통해 음원으로부터 기설정된 거리만큼 떨어진 지점까지 전자 장치를 이동시키고 헤드의 각도 를 조정할 수 있다. 한편, 일 실시 예로서, 본 개시의 전자 장치의 제어 방법은 식별된 음원의 위치에 기초하여 카메라를 통해 음원이 위치하는 방향으로 촬영을 수행할 수 있다. 이 경우, 카메라를 통해 촬영된 이미지에 기초하 여 이미지에 포함된 사용자의 입의 위치를 식별할 수 있다. 이 경우, 디스플레이가 식별된 입의 위치 를 향하도록 구동부를 제어할 수 있다. 한편, 일 실시 예로서, 음원이 위치하는 후보 공간에 대응되는 객체에 식별된 음원의 Z 축 상의 높이 정보를 맵 핑시킬 수 있다. 이 경우, 센서에서 센싱된 거리 정보에 기초하여 XY 축의 공간에서 객체의 이동 궤적을 추적할 수 있다. 이 경우, 음향 신호와 동일한 음원에서 출력된 후속 음향 신호가 복수의 마이크를 통해 수신되면, 객체의 이동 궤적에 따른 객체의 XY 축의 공간 상의 위치 및 객체에 맵핑된 Z 축 상의 높이 정보에 기초하여 후속 음향 신호가 출력된 음원의 위치를 식별할 수 있다. 이상과 같은 본 개시의 다양한 실시 예에 따르면, 음원의 위치에 기반하여 음성 인식 서비스에 대한 사용자 경 험을 향상시키는 전자 장치 및 그의 제어 방법을 제공할 수 있다.또한, 음원의 위치를 보다 정확하게 탐색하여 음성 인식에 대한 정확도를 향상시키는 전자 장치 및 그의 제어 방법을 제공할 수 있다. 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는 저장 매체로부터 저장된 명령 어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치(예: 전자 장치)를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세 서의 제어 하에 다른 구성요소들을 이용하여 상기 명령에 상기하는 기능을 수행할 수 있다. 명령은 컴파일러 또 는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는 비일시적 (non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하 지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분 하지 않는다. 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽 을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 상기 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 상기 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행 할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다."}
{"patent_id": "10-2023-0120449", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시 예에 따른 거리 정보를 센싱하는 센서를 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 후보 공간을 식별하는 방법을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시 예에 따른 후보 공간을 식별하는 방법을 설명하기 위한 도면이다. 도 7은 음향 신호를 수신하는 복수의 마이크를 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시 예에 따른 복수의 마이크를 통해 수신된 음향 신호를 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시 예에 따른 블록 별 기설정된 지연 값을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 빔포밍 파워를 산출하는 방법을 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시 예에 따른 음원의 위치를 식별하는 방법을 설명하기 위한 도면이다. 도 12는 본 개시의 일 실시 예에 따른 음원의 위치에 따라 구동되는 전자 장치를 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시 예에 따른 음원의 위치에 따라 구동되는 전자 장치를 설명하기 위한 도면이다. 도 14는 본 개시의 일 실시 예에 따른 이동 궤적을 통한 음원의 위치를 식별하는 방법을 설명하기 위한 도면이 다. 도 15는 본 개시의 일 실시 예에 따른 이동 궤적을 통한 음원의 위치를 식별하는 방법을 설명하기 위한 도면이 다. 도 16은 본 개시의 일 실시 예에 따른 음성 인식을 설명하기 위한 도면이다. 도 17은 본 개시의 일 실시 예에 따른 전자 장치의 부가적인 구성을 설명하기 위한 블록도이다. 도 18은 본 개시의 일 실시 예에 따른 흐름도를 설명하기 위한 도면이다."}
