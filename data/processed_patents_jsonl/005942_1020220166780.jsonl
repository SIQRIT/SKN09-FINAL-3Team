{"patent_id": "10-2022-0166780", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0083254", "출원번호": "10-2022-0166780", "발명의 명칭": "3D 뎁스 카메라를 이용한 옥수수 생육 자동 측정 방법", "출원인": "대한민국", "발명자": "권동원"}}
{"patent_id": "10-2022-0166780", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(a) 데이터 수집 모듈(100)이 3D 뎁스 카메라가 옥수수 군락를 촬영한 데이터를 이용하여 3차원 영상 RGB 데이터를 획득하는 단계;(b) 인공지능 모델 생성 모듈(200)이 상기 데이터 수집 모듈(100)에서 획득된 3차원 영상 RGB 데이터를 입력데이터로 하고, 이에 대응되도록 측정한 측정 데이터인 옥수수의 초장, 임관층, 엽면적, 및 잡초량을 출력데이터로 하는 학습 데이터를 학습시켜 옥수수 생육 자동 측정을 위한 인공지능 모델을 생성하는 단계; 및(c) 상기 생성된 인공지능 모델에, 3D 뎁스 카메라가 옥수수 군락을 촬영한 데이터를 입력하면 옥수수의 초장,임관층, 엽면적, 및 잡초량이 출력되는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0166780", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 (b) 단계에 있어서,전처리 모듈(300)이 상기 데이터 수집 모듈(100)에서 상기 3D 뎁스 카메라가 옥수수 군락을 촬영한 데이터를 입력받고, 상기 전처리 모듈(300)의 노이즈 제거부(320)에서 상기 입력된 데이터를 ExGR지수로 필터링하고, 상기 전처리 모듈(300)의 좌표 보정부(330)에서 상기 입력된 데이터의 좌표를 RANSAC 알고리즘으로 보정함으로써, 3차원 영상 RGB 데이터를 획득하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0166780", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 (a)단계에 있어서,(a1) 상기 데이터 수집 모듈(100)은 3m 높이에서 3D 뎁스 카메라가 옥수수 군락을 촬영한 데이터를 수집하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0166780", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "컴퓨터에 제 1 항 내지 제 3 항 중 어느 한 항에 따른 방법을 실행시키기 위한 컴퓨터 프로그램을 기록한, 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2022-0166780", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "컴퓨터에 제 1 항 내지 제 3 항 중 어느 한 항에 따른 방법을 실행시키기 위하여 기록매체에 저장된, 컴퓨터프로그램.공개특허 10-2024-0083254-3-"}
{"patent_id": "10-2022-0166780", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, (a) 데이터 수집 모듈이 3D 뎁스 카메라가 옥수수 군락를 촬영한 데이터를 이용하여 3차원 영상 RGB 데이터를 획득하는 단계; (b) 인공지능 모델 생성 모듈이 상기 데이터 수집 모듈에서 획득된 3차 원 영상 RGB 데이터를 입력데이터로 하고, 이에 대응되도록 측정한 측정 데이터인 옥수수의 초장, 임관층, 엽면 적, 및 잡초량을 출력데이터로 하는 학습 데이터를 학습시켜 옥수수 생육 자동 측정을 위한 인공지능 모델을 생 성하는 단계; 및 (c) 상기 생성된 인공지능 모델에, 3D 뎁스 카메라가 옥수수 군락을 촬영한 데이터를 입력하면 옥수수의 초장, 임관층, 엽면적, 및 잡초량이 출력되는 단계;를 포함하는 방법을 제공한다."}
{"patent_id": "10-2022-0166780", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 옥수수 생육 자동 측정 방법에 관한 것으로, 3D 뎁스 카메라를 이용하는 옥수수 생육 자동 측정 방법 에 관한 것이다."}
{"patent_id": "10-2022-0166780", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "옥수수의 생육을 측정하는 데 있어, 초장이나 엽면적 및 임관층의 변화는 옥수수의 생산량을 예측하는데 중요한 지표들이지만 이를 측정하기 위한 기존의 방식들은 작물과 접촉하거나 파괴적인 방법이며 노동력 또한 많이 투 입되어야 하는 문제점이 있다. 드론을 통한 촬영 및 2차원 영상을 이용한 측정 방법은 옥수수 군락이 차지하는 면적은 측정할 수 있지만 작물 의 초장을 측정하지 못하며, 작물의 초장을 측정하기 위한 측면 카메라는 반대로 밭 면적에서 옥수수 군락이 차 지하는 면적은 측정하지 못하는 한계점이 존재한다. 이와 같은 종래의 옥수수 생육 측정 방법의 문제점을 극복하기 위한 기술이 개발되고 있다. 미국공개특허 제2022-0138925호는 노지에서 재배하는 작물의 광학 수율 측정을 위한 시스템 및 방법에 관한 것으로, 획득된 이미지 데이터에서 하나 이상의 대상 식물이 차지하는 픽셀의 공간 영역 및 수확 가능한 식물의 픽셀을 추정할 수 있으며, 잡초와 인접한 작물을 식별할 수 있고 대상 작물로서 옥수수 등을 포함하는 작물의 수율 측정을 위한 시스템 및 방법을 개시한다. 잡초의 픽셀을 포함하는 배경 픽셀로부터 수확 가능한 식물 픽셀을 차별화하거나 분류할 수 있는 점이 개시된다. 미국등록특허 제10891482호는 식물 영역에서 성장 단계1 및 작물 수확량 예측을 위한 현장 진단 방법, 장치 및 시스템을 개시한다. 본 종래기술에서는, 특정되지 않은 작물 수확량 예측을 위한 방법이 개시되나, 불특정 다수 의 작물을 대상으로 한 것이어서 옥수수에 특화된 측정 방법을 제공할 순 없었다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2017-0114065 A (특허문헌 0002) US 2022-0138925 A1 (특허문헌 0003) US 2021-0133443 A1 (특허문헌 0004) US 10891482 B2"}
{"patent_id": "10-2022-0166780", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것이다. 옥수수의 생육과 관련된 지표를 측정할 경우 발생했던 직접 접촉 등의 작물 파괴적인 측정 문제를 해결하기 위 해, 직접 접촉에 의한 측정 없이 옥수수의 생육 관련 지표들을 비접촉으로 측정할 수 있는 방법을 제공하고자 한다."}
{"patent_id": "10-2022-0166780", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 과제를 해결하기 위한 본 발명의 일 실시예는, (a) 데이터 수집 모듈이 3D 뎁스 카메라가 옥 수수 군락를 촬영한 데이터를 이용하여 3차원 영상 RGB 데이터를 획득하는 단계; (b) 인공지능 모델 생성 모듈 이 상기 데이터 수집 모듈에서 획득된 3차원 영상 RGB 데이터를 입력데이터로 하고, 이에 대응되도록 측정한 측정 데이터인 옥수수의 초장, 임관층, 엽면적, 및 잡초량을 출력데이터로 하는 학습 데이터를 학습시켜 옥수수 생육 자동 측정을 위한 인공지능 모델을 생성하는 단계; 및 (c) 상기 생성된 인공지능 모델에, 3D 뎁스 카메라가 옥수수 군락을 촬영한 데이터를 입력하면 옥수수의 초장, 임관층, 엽면적, 및 잡초량이 출력되는 단계;를 포함하는, 방법을 제공한다. 또한, 상기 (b) 단계에 있어서, 전처리 모듈이 상기 데이터 수집 모듈에서 상기 3D 뎁스 카메라가 옥 수수 군락을 촬영한 데이터를 입력받고, 상기 전처리 모듈의 노이즈 제거부에서 상기 입력된 데이터 를 ExGR지수로 필터링하고, 상기 전처리 모듈의 좌표 보정부에서 상기 입력된 데이터의 좌표를 RANSAC 알고리즘으로 보정함으로써, 3차원 영상 RGB 데이터를 획득하는 단계;를 포함하는 것이 바람직하다. 또한, 상기 (a)단계에 있어서, (a1) 상기 데이터 수집 모듈은 3m 높이에서 3D 뎁스 카메라가 옥수수 군락 을 촬영한 데이터를 수집하는 단계;를 포함하는 것이 바람직하다. 본 발명의 다른 실시예는, 컴퓨터에 상기 실시예에 따른 방법을 실행시키기 위한 컴퓨터 프로그램을 기록한, 컴 퓨터로 읽을 수 있는 기록매체를 제공한다. 본 발명의 또 다른 실시예는, 컴퓨터에 상기 실시예에 따른 방법을 실행시키기 위하여 기록매체에 저장된, 컴퓨 터프로그램을 제공한다."}
{"patent_id": "10-2022-0166780", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기와 같은 과제 해결을 통해 본 발명은 다음과 같은 효과를 얻는다. 첫째, 직접 측정 등의 파괴적인 방법을 사용하지 않고 옥수수의 생육 측정이 가능하다. 기존에 직접 측정과 함 께 수기를 활용하여야 했던 초장, 임관층, 엽면적 등 옥수수의 생육 관련 지표들을 자동이자 비접촉 방식으로 측정할 수 있다. 둘째, 기존 2차원 사진 데이터만으로는 측정이 어렵거나 불가했던 옥수수의 생육 지표를 측정하여 제공할 수 있 다. 셋째, 비접촉 방식으로 측정된 측정 값을 일일 생장량, 캐노피 평가, 엽면적 변화 등과 같은 분석 결과로서 높 은 정확도로 제공할 수 있다."}
{"patent_id": "10-2022-0166780", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 상기와 같은 목적, 특징 및 다른 장점들은 첨부도면을 참조하여 본 발명의 바람직한 실시예를 상세히 설명함으로써 더욱 명백해질 것이다. 이 과정에서 도면에 도시된 선들의 두께나 구성요소의 크기 등은 설명의 명료성과 편의상 과장되게 도시되어 있을 수 있다. 또한, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정 의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례에 따라 달라질 수 있다. 그러므로 이러한 용어들에 대 한 정의는 본 명세서 전반에 걸친 내용을 토대로 기술되어야 할 것이다. 또한, 기술되는 실시예는 발명의 설명을 위해 예시적으로 제공되는 것이며, 본 발명의 기술적 범위를 한정하는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예에 따른 옥수수 생육 자동 측정 방법을 상세히 설명한 다. 3D 뎁스 카메라의 설명 본 발명에 필수 구성인 3D 뎁스 카메라를 먼저 설명한다. 본 발명에 따른 방법을 수행하기 위한 모델을 구축하기 위해 3D 뎁스 카메라를 이용하여 옥수수 군락을 촬영하 는 것이 선행될 것이다, 3D 뎁스 카메라는 적외선을 이용해 3차원 영상 및 이미지를 촬영하는 카메라는 무엇이든 사용 가능하다. 3D 뎁 스 카메라에 의해 촬영된 3D 영상 및 이미지 데이터는 도 4와 같이 RGB 이미지 데이터를 포함하는 다수의 데이 터 파일로 추출될 수 있다. 3D 뎁스 카메라는 바람직하게는 Microsoft Corporation의 Azure kinect를 이용할 수 있으나, 이 밖에도 본 발 명에서 설명하는 옥수수 군락의 촬영에 적합할 경우 제한되지 않는다. 3D 뎁스 카메라를 이용해 옥수수 군락을 촬영하는데 있어 바람직하게는 옥수수 군락으로부터 약 3m의 수평 높이 에서 측정할 수 있다. 이를 통해 모델 생성을 위한 학습 데이터가 획득된다. 생성된 모델을 이용할 경우 3D 뎁 스 카메라에 의해 촬영된 이미지만을 가지고도 작물의 초장, 임관층, 잡초량 등을 분석할 수 있다. 상세한 내용 은 후술한다. 시스템의 설명 도 1을 참고하여 본 발명에 따른 옥수수 생육 측정 방법을 수행하기 위한 시스템을 설명한다. 본 발명에 따른 방법을 수행하기 위한 본 발명의 시스템은 3D 뎁스 카메라의 데이터를 이용하는 시스템으로써, 데이터 수집 모듈, 인공지능 모델 생성 모듈 및 데이터 전처리 모듈을 포함한다. 데이터 수집 모듈은 3D 뎁스 카메라와 연결되어 3D 뎁스 카메라의 데이터를 수집할 수 있으며, 측정 데이 터를 수집하는 측정 데이터 수집부와, 3D 뎁스 카메라의 데이터를 수집하는 3차원 영상 데이터부, 및 RGB 데이터부를 포함한다. 측정 데이터 수집부는 자동 또는 수동으로 입력한 데이터를 수집하는 것으로, 옥수수 생육을 위한 데이터 라면 한정되지 않을 것이다. 그 예로, 옥수수의 초장, 엽면적, 임관층 등일 수 있다. 자동 입력 방식에 특별한 제한은 없으며, 수동 입력 방식으로 예를 들어 수기 입력이 사용될 수 있다. 3차원 영상 데이터부에 추출되지 않은 3D 뎁스 카메라의 이미지 데이터가 수집된다. RGB 데이터부는 3D 뎁스 카메라의 이미지 데이터에서 RGB 데이터를 추출하고 수집한다. 인공지능 모델 생성 모듈은 데이터 수집 모듈의 데이터와 데이터 전처리 모듈의 데이터를 학습 데이터로 하여 학습됨으로써 구축된 인공지능 모델을 생성할 수 있다. 인공지능 모델 생성 모듈에서 이용되는 인공지능 모델은 바람직하게는 U-net 모델과 Adam 함수를 이용할 수 있다. U-net은 이미지 분할 및 분석에 사용되는 인공지능 모델로 학습 데이터가 적어도 우수한 성능을 보였 다, 실제로, 본 발명에서 노지에서 촬영된 이미지에서 옥수수와 잡초를 구분하고 픽셀 정보를 분석하기 위해 해 당 모델을 사용하였을 때, 직접 측정한 결과 값과 거의 차이가 없는 성능으로 나타났다. 데이터 전처리 모듈은 데이터 수집 모듈의 데이터가 인공지능 모델 생성 모듈이 학습데이터로써 사용할 수 있도록 데이터를 전처리할 수 있다. 데이터 전처리 모듈은 데이터 분석부, 노이즈 제거부, 좌표 보정부 및 라벨링부를 포 함한다. 데이터 분석부는 3D 뎁스 카메라의 3차원 영상 및 이미지 데이터를 분석할 수 있으며, 분석을 위한 라이브 러리를 제공할 수 있다. 데이터 분석부는, 파이썬(Python), 판다스(Pandas), 매트랩(matplotlib), opencv2 등을 사용할 수 있으나 이에 제한되지 않는다. 예를 들어, Pandas는 텍스트 파일 기반의 3차원 좌표 데이터 분석에 사용하고, matplotlib는 3차원 이미지 시각화 및 그래프 작성에 사용하고, opencv2는 RGB 이미지 전처리에 사용하고, Python이 이미지 분석 및 인공지능 모델 개발에 사용될 수 있다. 노이즈 제거부는 3D 뎁스 카메라가 적외선이 반사되는 것을 이용함에 따라 특성상 출력 데이터에 노이즈가 생기는 경우가 있는데, 이로 인한 노이즈를 제거하기 위해 3차원 영상 데이터를 ExGR 지수로 필터링하는 것이다.(도 6 및 도 7) 좌표 보정부는 3D 뎁스 카메라로 측정된 데이터와 실제 측정 값의 좌표 값을 일치시키기 위한 것으로, RANSAC(Random Sample consensus) 알고리즘을 이용하여 좌표를 보정할 수 있다. 라벨링부는 3D 뎁스 카메라의 영상 데이터를 인공지능 모델 생성 모듈의 학습데이터로써 제공하기 위 해 영상 데이터를 라벨링할 수 있다. 데이터 전처리 모듈에 의해 이와 같은 전처리들이 완료되면, 데이터 수집 모듈에서 수집한 3D 뎁스 카메라로부터의 데이터가 3차원 영상 RGB 데이터로 변환될 것이다. 방법의 설명 도 2 내지 도 3을 더 참조하여 옥수수 생육 측정 방법을 구체적으로 설명한다. 먼저, 데이터 수집 모듈이 3D 뎁스 카메라가 옥수수 군락를 촬영한 데이터를 이용하여 3차원 영상 RGB 데 이터를 획득한다, 이때, 데이터 수집 모듈은 3m 높이에서 3D 뎁스 카메라가 옥수수 군락을 촬영한 데이터를 수집하는 것이 바람직하다. 다음, 인공지능 모델 생성 모듈이 데이터 수집 모듈에서 획득된 3차원 영상 RGB 데이터를 입력데이터 로 하고, 이에 대응되도록 측정한 측정 데이터인 옥수수의 초장, 임관층, 엽면적, 및 잡초량을 출력데이터로 하 는 학습 데이터를 학습시켜 옥수수 생육 자동 측정을 위한 인공지능 모델을 생성한다. 이때, 인공지능 모델 생성 모듈이 획득한 데이터는 전처리 모듈에 의해 전처리된 데이터이다. 구체적으로, 전처리 모듈이 데이터 수집 모듈에서 3D 뎁스 카메라가 옥수수 군락을 촬영한 데이터를 입력받고, 전처리 모듈의 노이즈 제거부에서 입력된 데이터를 ExGR지수로 필터링하고, 전처리 모듈 의 좌표 보정부에서 입력된 데이터의 좌표를 RANSAC 알고리즘으로 보정함으로써, 3차원 영상 RGB 데 이터를 획득할 것이다.마지막으로, 생성된 인공지능 모델에, 3D 뎁스 카메라가 옥수수 군락을 촬영한 데이터를 입력하면 옥수수의 초 장, 임관층, 엽면적, 및 잡초량이 출력된다. 이하 본 방법을 이용해 옥수수의 생육 평가를 위해 측정 값을 사용하는 경우를 설명한다. 옥수수의 초장을 측정하는 방법을 설명한다. 출력된 옥수수 초장의 측정 값을 평가하기 위해 3차원 데이터를 가시화 시켜주는 cloudcompare 등의 프로그램을 더 이용할 수 있다. 구축된 인공지능 모델은 옥수수의 각 주당 가장 높은 점을 선택하여 좌표 값을 저장하고, 저장된 좌표 값들에 대해 평균 값이 측정될 것이다. 본 방법에 따르면, 3D 뎁스 카메라의 영상 데이터를 이용한 옥수수 초장의 정확한 측정을 위해서 ExGR 지수로 옥수수 군락의 포인트 데이터만 추출 후 옥수수 군락 전체 포 인트에서 Z축 좌표의 상위 1%, 10%의 포인트에 있는 좌표들의 평균값을 옥수수 군락의 평균 초장으로 측정할 수 있기 때문에, 실제 측정하지 않은 측정 값이지만 실제 측정한 데이터 값과 유사한 결과 값을 가질 것이다(도 2 참고). 옥수수 군락의 임관층을 평가하는 방법을 설명한다. 3D 뎁스 카메라의 영상 데이터에서 X,Z 또는 Y,Z의 좌표값 의 포인트를 고정시켜서 히스토그램 형식으로 2차원 평면에 도면화 시켜서 작성한 후에 Z축에서의 포인트의 밀 도를 평가함으로써 옥수수 군락의 임관층을 평가할 수 있다(도 5 참고) 옥수수 군락이 차지하는 면적을 측정하는 방법을 설명한다. 3D 뎁스 카메라에서 촬영한 영상 데이터를 데이터 전처리 모듈을 이용해 처리한 후, 옥수수를 나타내는 픽셀수를 전체 이미지 픽셀 수로 나누어서 밭 토양에 서 옥수수 군락이 차지하는 면적(Coverage)를 측정할 수 있다. 군락에서 잡초가 차지하는 면적을 측정하는 방법을 설명한다. 미리 학습된 인공지능 모델에 3D 뎁스 카메라에서 촬영한 영상 데이터를 입력할 경우 군락에서 잡초가 차지하는 면적이 자동으로 측정되어 제공된다. 도 6은 그 예시를 도시하며, 여기에서는 인공지능 모델에서 연산된 옥수수의 엽면적을 전체 면적에서 제외함으로써 잡초량 을 산출한 결과를 도시한다. 옥수수 군락의 엽면적 평가 방법을 설명한다. 노이즈 제거부에 의해, 영상 RGB 데이터에서 red, blue, green의 값을 추출할 수 있고, ExGR 지수로 영상 RGB 데이터에서 옥수수 군락이 차지하는 면적을 추출할 수 있 다. 다른 실시예에서, 영상 RGB 데이터의 전체 픽셀수와 옥수수만 추출된 영상의 픽셀수의 비율을 퍼센트로 표 시할 수 있다. 이 때, python언어의 opencv2에서 제공하는 bitwise 함수를 이용할 수 있으나, 이에 한정되는 것 은 아니다. 도 7과 같이 이미지로 제공된 측정 결과를 도 8과 같이 시계열로 작성된 그래프로 제공할 수도 있다. 그 외에도, 도 9에 도시된 바와 같이 생장 속도 분석 그래프도 제공할 수 있다. 본 발명에 따라 측정된 값을 이 용하여, 각 날짜의 밤에서의 옥수수 초장에서 낮에서의 옥수수 초장을 뺀 값과, 밤에서의 옥수수 초장에서 그 다음날 낮에서의 옥수수 초장을 뺀 값으로 측정한 결과를 이용하여 제공할 것이다. 또한, 본 발명에 따른 방법은 컴퓨터에 본 발명에 따른 방법을 실행시키기 위한 컴퓨터 프로그램을 기록한, 컴 퓨터로 읽을 수 있는 기록매체 및 컴퓨터프로그램 형태로 제공될 수 있음은 물론이다. 검증 도 10 내지 도 11을 더 참조하여 본 발명에 따른 방법을 이용한 옥수수 생육 측정의 효과를 검증하였다. 먼저, 도 10을 참고하여 설명한다. 도 10은 대상 옥수수를 실제 측정한 값과 본 발명을 이용하여 측정한 값을 비교 분석한 그래프이다. 매 30분 간격으로 2022년 6월 8일부터 7월 26일까지 촬영되어진 옥수수 군락의 3차원 영상 및 이미지 데이터를 이용하여 모델을 생성하였다. 생성된 모델 평가를 위해 대조군으로 사용된 측정 데이터는 위 데이터 수집일의 매일 오전 5시에서 7시 사이의 데이터와 오후 5시에서 7시 사이의 데이터 각각 하나씩으로 하였다. 대조군으로서 상위 10%포인트와 1%포인트의 값으로 측정된 옥수수의 초장을 각 주에서 육안으로 확인한 후 가장 높은 포인트를 선택하여 직접 측정하였으며, 그 값과 본 발명에 따른 방법에서의 결과값을 비교 분석하였다. 분 석 결과 본 발명에 따른 결과값과 직접 측정한 대조군의 측정 값은 높은 상관관계를 보이는 것을 알 수 있었다 (1% R2=0.9959, 10% R2=0.9974). 즉, 본 발명에 따른 방법으로 도출된 옥수수의 초장의 값과 직접 측정한 옥수수의 초장의 측정값이 높은 상관관 계를 나타냈으며, 본 발명에 따른 방법의 정확도는 높음이 검증되었다. 다음, 도 11을 이용해 인공지능 모델 검증 결과를 설명한다. 사용된 영상은 총 234장으로 각 이미지에서 옥수수 픽셀 영역을 제외한 부분의 RGB값을 0으로 만든 데이터를 학 습에 사용하였다. 분석에 사용된 입력 이미지의 크기는 512 * 512 로 하였다. 학습과정에서 사용한 U-net 모델의 옵티마이저는 Adam이며 학습 횟수는(epoch) 50번으로 하였다. 학습 결과는 전반적으로 99% 이상의 높은 정확도(Accuracy)와 0.02%미만의 낮은 손실값(Loss)을 나타내었다."}
{"patent_id": "10-2022-0166780", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상, 본 명세서에는 본 발명을 당업자가 용이하게 이해하고 재현할 수 있도록 도면에 도시한 실시예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 당업자라면 본 발명의 실시예로부터 다양한 변형 및 균등한 타 실 시예가 가능하다는 점을 이해할 것이다. 따라서 본 발명의 보호범위는 특허청구범위에 의해서 정해져야 할 것이다."}
{"patent_id": "10-2022-0166780", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은, 본 발명에 따른 방법을 수행하기 위한 시스템을 설명하기 위한 도면이다. 도 2는, 본 발명에 따른 방법을 이용한, 3D 뎁스 카메라에서 추출된 포인트의 데이터 처리 과정을 설명하기 위 한 도면이다. 도 3은, 본 발명에 따른 방법을 이용한, 3D 뎁스 카메라에서 추출된 RGB 영상 데이터의 처리 과정을 설명하기 위한 도면이다. 도 4는, 3D 뎁스 카메라에서 추출되어진 데이터 파일을 설명하기 위한 도면이다. 도 5는, 본 발명에 따른 방법에 의해 옥수수 군락의 임관층을 평가하는 방법을 설명하기 위한 도면이다. 도 6 내지 도 7은, 본 발명에 따른 방법을 위해 노이즈 제거부에 의해 필터링된 영상 데이터를 설명하기 위한도면이다. 도 8은, 본 발명에 따른 방법에 의해 측정된 옥수수 군락의 엽면적 그래프이다. 도 9는, 본 발명에 따른 방법에 의해 산출된 생장 속도 분석 그래프이다. 도 10 내지 도 11은, 본 발명에 따른 인공지능 모델의 검증을 위한 도면이다."}
