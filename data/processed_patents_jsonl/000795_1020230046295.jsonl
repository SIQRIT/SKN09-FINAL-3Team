{"patent_id": "10-2023-0046295", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0150245", "출원번호": "10-2023-0046295", "발명의 명칭": "자율주행 차량의 객체 인식 장치 및 그 방법", "출원인": "현대자동차주식회사", "발명자": "최종현"}}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "에 있어서, 상기 프로세서는,상기 적어도 하나의 왜곡된 이미지 각각으로부터 추출된 피쳐를 상기 보정된 이미지로부터 추출된 피쳐와 동일하게 만들어주도록 상기 피쳐 전이 모듈을 학습시키도록 설정된, 자율주행 차량의 객체 인식 장치."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 프로세서는,상기 보정된 이미지에 지정된 왜곡 값 및 지정된 회전 값을 입력하여 왜곡 및 회전이 발생한 상기 적어도 하나의 왜곡된 이미지를 생성하도록 설정된, 자율주행 차량의 객체 인식 장치."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서, 상기 보정된 이미지는 상기 자율주행 차량의 카메라의 내부 파라미터 또는 외부 파라미터 중 적어도 하나를 이용하여 보정되고,상기 프로세서는,상기 보정에 대응하는 연산의 역변환을 이용하여 상기 적어도 하나의 왜곡된 이미지를 생성하도록 설정된, 자율주행 차량의 객체 인식 장치."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 상기 프로세서는,상기 역변환의 관계를 나타내는 맵핑(mapping) 함수를 저장하고,왜곡된 이미지에서 맵핑되지 않는 영역을 나타내는 마스크(mask) 이미지를 생성하여 상기 맵핑 함수와 함께 저장하도록 설정된, 자율주행 차량의 객체 인식 장치.공개특허 10-2024-0150245-3-청구항 5"}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서, 상기 피쳐 전이 모듈은 피쳐 전이 네트워크 모델을 포함하고,상기 피쳐 전이 네트워크 모델은 모양 손실, 맵핑 손실, 상관성 손실, 및 감별 손실을 포함하는 손실함수를 기반으로 학습되도록 설정된, 자율주행 차량의 객체 인식 장치."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서, 상기 프로세서는,왜곡된 이미지에서 맵핑되지 않는 영역에 대한 손실에는 0을 곱하고, 맵핑된 영역에 대한 손실에는 1을 곱하여상기 손실함수의 값을 계산하도록 설정된, 자율주행 차량의 객체 인식 장치."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 6에 있어서, 상기 피쳐 전이 네트워크 모델의 최초 3개의 층의 인코더의 커널(kernel)의 크기는 상기 피쳐 전이 네트워크 모델에 입력되는 피쳐의 크기에 기반하여 결정되도록 설정된, 자율주행 차량의 객체 인식 장치."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서, 상기 프로세서는,상기 자율주행 차량의 주행 중에 상기 자율주행 차량의 카메라를 통해 획득되는 이미지를 수신하고,상기 수신된 이미지를 상기 제2 네트워크 모델에 입력하고,상기 제2 네트워크 모델로부터 객체 인식 결과를 획득하도록 설정된, 자율주행 차량의 객체 인식 장치."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서, 상기 객체 인식 결과는, 3차원 공간에 존재하는 객체의 위치 및 종류를 포함하는, 자율주행 차량의 객체 인식장치."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2024-0150245-4-자율주행 차량의 객체 인식 장치에 의해 수행되는 객체 인식 방법에 있어서,왜곡 및 회전이 보정된 이미지를 기반으로 제1 네트워크 모델을 학습시키는 단계;상기 보정된 이미지를 기반으로 적어도 하나의 왜곡된 이미지를 생성하는 단계;상기 보정된 이미지로부터 추출된 피쳐(feature) 및 상기 적어도 하나의 왜곡된 이미지 각각으로부터 추출된 피쳐를 기반으로 피쳐 전이 모듈(feature transfer module)을 학습시키는 단계;상기 피쳐 전이 모듈을 상기 제1 네트워크 모델에 삽입하는 단계; 및상기 적어도 하나의 왜곡된 이미지를 기반으로 상기 피쳐 전이 모듈을 포함하는 제2 네트워크 모델에 대한 파인튜닝(fine tuning)을 수행하는 단계를 포함하고,상기 제1 네트워크 모델 및 상기 제2 네트워크 모델은 이미지를 기반으로 객체 인식을 수행하는 딥러닝(deep-learning) 네트워크 모델인, 객체 인식 방법."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 적어도 하나의 왜곡된 이미지를 생성하는 단계는,상기 보정된 이미지에 지정된 왜곡 값 및 지정된 회전 값을 입력하여 왜곡 및 회전이 발생한 상기 적어도 하나의 왜곡된 이미지를 생성하는 단계를 포함하는, 객체 인식 방법."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 11에 있어서,상기 보정된 이미지는 상기 자율주행 차량의 카메라의 내부 파라미터 또는 외부 파라미터 중 적어도 하나를 이용하여 보정되고,상기 적어도 하나의 왜곡된 이미지를 생성하는 단계는,상기 보정에 대응하는 연산의 역변환을 이용하여 상기 적어도 하나의 왜곡된 이미지를 생성하는 단계를 포함하는, 객체 인식 방법."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13에 있어서,상기 역변환의 관계를 나타내는 맵핑(mapping) 함수를 저장하는 단계; 및왜곡된 이미지에서 맵핑되지 않는 영역을 나타내는 마스크(mask) 이미지를 생성하여 상기 맵핑 함수와 함께 저장하는 단계를 더 포함하는, 객체 인식 방법."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "에 있어서,상기 피쳐 전이 모듈은 피쳐 전이 네트워크 모델을 포함하고,상기 피쳐 전이 네트워크 모델은 모양 손실, 맵핑 손실, 상관성 손실, 및 구별 손실을 포함하는 손실함수를 기반으로 학습되는, 객체 인식 방법."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 16에 있어서, 상기 피쳐 전이 모듈을 학습시키는 단계는,왜곡된 이미지에서 맵핑되지 않는 영역에 대한 손실에는 0을 곱하고, 맵핑된 영역에 대한 손실에는 1을 곱하여상기 손실함수의 값을 계산하는 단계를 포함하는, 객체 인식 방법."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 16에 있어서, 상기 피쳐 전이 네트워크 모델의 최초 3개의 층의 인코더의 커널(kernel)의 크기는 상기 피쳐 전이 네트워크 모델에 입력되는 피쳐의 크기에 기반하여 결정되는, 객체 인식 방법."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 11에 있어서,상기 자율주행 차량의 주행 중에 상기 자율주행 차량의 카메라를 통해 획득되는 이미지를 수신하는 단계;상기 수신된 이미지를 상기 제2 네트워크 모델에 입력하는 단계; 및상기 제2 네트워크 모델로부터 객체 인식 결과를 획득하는 단계를 더 포함하는, 객체 인식 방법."}
{"patent_id": "10-2023-0046295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "청구항 19에 있어서,상기 객체 인식 결과는, 3차원 공간에 존재하는 객체의 위치 및 종류를 포함하는, 객체 인식 방법."}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 자율주행 차량의 객체 인식 장치 및 그 방법에 관한 것으로, 자율주행 차량의 객체 인식 장치는 프로 세서 및 저장부를 포함할 수 있다. 상기 프로세서는, 왜곡 및 회전이 보정된 이미지를 기반으로 제1 네트워크 모 델을 학습시키고, 상기 보정된 이미지를 기반으로 적어도 하나의 왜곡된 이미지를 생성하고, 상기 보정된 이미지 로부터 추출된 피쳐(feature) 및 상기 적어도 하나의 왜곡된 이미지 각각으로부터 추출된 피쳐를 기반으로 피쳐 전이 모듈(feature transfer module)을 학습시키고, 상기 피쳐 전이 모듈을 상기 제1 네트워크 모델에 삽입하고, 상기 적어도 하나의 왜곡된 이미지를 기반으로 상기 피쳐 전이 모듈을 포함하는 제2 네트워크 모델에 대한 파인 튜닝(fine tuning)을 수행하도록 설정될 수 있다."}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자율주행 차량의 객체 인식 장치 및 그 방법에 관한 것으로, 보다 상세하게는 딥러닝(deep-learning) 네트워크 모델을 이용하여 이미지를 기반으로 객체를 인식하는 기술에 관한 것이다."}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술은, 인간의 학습능력, 추론능력, 지각능력 등 인간의 지능이 필요한 작업을 할 수 있는 컴퓨터 시 스템을 구현하는 기술이다. 인공지능 기술의 일 분야로 입력 데이터의 특징(feature)을 스스로 학습하는 알고리 즘 기술인 기계학습(machine learning)이 있다. 딥러닝은 인공신경망을 기반으로 하는 기계학습일 수 있다. 인공지능 기술이 자율주행 분야에 적용됨에 따라, 딥러닝 네트워크 모델을 이용하여 주행 중인 차량 주변의 3차"}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "원 공간에 존재하는 객체를 인식하고, 객체 인식 결과에 기반한 제어를 수행하는 기술이 개발되고 있다.발명의 내용"}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는 차량에 탑재된 카메라의 파라미터 변화에 강건한 이미지 기반의 3차원 객체 인식 장치 및 그 방법을 제공하고자 한다. 본 발명의 실시예는 차량의 주행 중에 획득된 이미지에 대해 실시간으로 카메라의 파라미터를 기반으로 보정해 야 함에 따른 과도한 연산량을 감소시키고, 실시간 보정 과정에 의해 처리가 지연됨에 따른 성능 열화를 감소시 킬 수 있는 자율주행 차량의 객체 인식 장치 및 그 방법을 제공하고자 한다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재들로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 자율주행 차량의 객체 인식 장치는, 프로세서 및 저장부를 포함할 수 있다. 상기 프로 세서는, 왜곡 및 회전이 보정된 이미지를 기반으로 제1 네트워크 모델을 학습시키고, 상기 보정된 이미지를 기 반으로 적어도 하나의 왜곡된 이미지를 생성하고, 상기 보정된 이미지로부터 추출된 피쳐(feature) 및 상기 적 어도 하나의 왜곡된 이미지 각각으로부터 추출된 피쳐를 기반으로 피쳐 전이 모듈(feature transfer module)을 학습시키고, 상기 피쳐 전이 모듈을 상기 제1 네트워크 모델에 삽입하고, 상기 적어도 하나의 왜곡된 이미지를 기반으로 상기 피쳐 전이 모듈을 포함하는 제2 네트워크 모델에 대한 파인 튜닝(fine tuning)을 수행하도록 설 정될 수 있다. 일 실시예에 있어서, 상기 프로세서는, 상기 보정된 이미지에 지정된 왜곡 값 및 지정된 회전 값을 입력하여 왜 곡 및 회전이 발생한 상기 적어도 하나의 왜곡된 이미지를 생성하도록 설정될 수 있다. 일 실시예에 있어서, 상기 보정된 이미지는 상기 자율주행 차량의 카메라의 내부 파라미터 또는 외부 파라미터 중 적어도 하나를 이용하여 보정될 수 있다. 상기 프로세서는, 상기 보정에 대응하는 연산의 역변환을 이용하여 상기 적어도 하나의 왜곡된 이미지를 생성하도록 설정될 수 있다. 일 실시예에 있어서, 상기 프로세서는, 상기 역변환의 관계를 나타내는 맵핑(mapping) 함수를 저장하고, 왜곡된 이미지에서 맵핑되지 않는 영역을 나타내는 마스크(mask) 이미지를 생성하여 상기 맵핑 함수와 함께 저장하도록 설정될 수 있다. 일 실시예에 있어서, 상기 프로세서는, 상기 적어도 하나의 왜곡된 이미지 각각으로부터 추출된 피쳐를 상기 보 정된 이미지로부터 추출된 피쳐와 동일하게 만들어주도록 상기 피쳐 전이 모듈을 학습시키도록 설정될 수 있다. 일 실시예에 있어서, 상기 피쳐 전이 모듈은 피쳐 전이 네트워크 모델을 포함할 수 있다. 상기 피쳐 전이 네트 워크 모델은 모양 손실, 맵핑 손실, 상관성 손실, 및 감별 손실을 포함하는 손실함수를 기반으로 학습되도록 설 정될 수 있다. 일 실시예에 있어서, 상기 프로세서는, 왜곡된 이미지에서 맵핑되지 않는 영역에 대한 손실에는 0을 곱하고, 맵 핑된 영역에 대한 손실에는 1을 곱하여 상기 손실함수의 값을 계산하도록 설정될 수 있다. 일 실시예에 있어서, 상기 피쳐 전이 네트워크 모델의 최초 3개의 층의 인코더의 커널(kernel)의 크기는 상기 피쳐 전이 네트워크 모델에 입력되는 피쳐의 크기에 기반하여 결정되도록 설정될 수 있다. 일 실시예에 있어서, 상기 프로세서는, 상기 자율주행 차량의 주행 중에 상기 자율주행 차량의 카메라를 통해 획득되는 이미지를 수신하고, 상기 수신된 이미지를 상기 제2 네트워크 모델에 입력하고, 상기 제2 네트워크 모 델로부터 객체 인식 결과를 획득하도록 설정될 수 있다. 일 실시예에 있어서, 상기 객체 인식 결과는, 3차원 공간에 존재하는 객체의 위치 및 종류를 포함할 수 있다. 본 발명의 다른 일 실시예에 따른 자율주행 차량의 객체 인식 장치에 의해 수행되는 객체 인식 방법은, 왜곡 및 회전이 보정된 이미지를 기반으로 제1 네트워크 모델을 학습시키는 단계, 상기 보정된 이미지를 기반으로 적어 도 하나의 왜곡된 이미지를 생성하는 단계, 상기 보정된 이미지로부터 추출된 피쳐(feature) 및 상기 적어도 하 나의 왜곡된 이미지 각각으로부터 추출된 피쳐를 기반으로 피쳐 전이 모듈(feature transfer module)을 학습시 키는 단계, 상기 피쳐 전이 모듈을 상기 제1 네트워크 모델에 삽입하는 단계, 및 상기 적어도 하나의 왜곡되 이미지를 기반으로 상기 피쳐 전이 모듈을 포함하는 제2 네트워크 모델에 대한 파인 튜닝(fine tuning)을 수행하 는 단계를 포함할 수 있다. 상기 제1 네트워크 모델 및 상기 제2 네트워크 모델은 이미지를 기반으로 객체 인식 을 수행하는 딥러닝(deep-learning) 네트워크 모델일 수 있다. 일 실시예에 있어서, 상기 적어도 하나의 왜곡된 이미지를 생성하는 단계는, 상기 보정된 이미지에 지정된 왜곡 값 및 지정된 회전 값을 입력하여 왜곡 및 회전이 발생한 상기 적어도 하나의 왜곡된 이미지를 생성하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 보정된 이미지는 상기 자율주행 차량의 카메라의 내부 파라미터 또는 외부 파라미터 중 적어도 하나를 이용하여 보정될 수 있다. 상기 적어도 하나의 왜곡된 이미지를 생성하는 단계는, 상기 보정 에 대응하는 연산의 역변환을 이용하여 상기 적어도 하나의 왜곡된 이미지를 생성하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 객체 인식 방법은, 상기 역변환의 관계를 나타내는 맵핑(mapping) 함수를 저장하는 단계, 및 왜곡된 이미지에서 맵핑되지 않는 영역을 나타내는 마스크(mask) 이미지를 생성하여 상기 맵핑 함수와 함께 저장하는 단계를 더 포함할 수 있다. 일 실시예에 있어서, 상기 피쳐 전이 모듈을 학습시키는 단계는, 상기 적어도 하나의 왜곡된 이미지 각각으로부 터 추출된 피쳐를 상기 보정된 이미지로부터 추출된 피쳐와 동일하게 만들어주도록 상기 피쳐 전이 모듈을 학습 시키는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 피쳐 전이 모듈은 피쳐 전이 네트워크 모델을 포함할 수 있다. 상기 피쳐 전이 네트 워크 모델은 모양 손실, 맵핑 손실, 상관성 손실, 및 구별 손실을 포함하는 손실함수를 기반으로 학습될 수 있 다. 일 실시예에 있어서, 상기 피쳐 전이 모듈을 학습시키는 단계는, 왜곡된 이미지에서 맵핑되지 않는 영역에 대한 손실에는 0을 곱하고, 맵핑된 영역에 대한 손실에는 1을 곱하여 상기 손실함수의 값을 계산하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 피쳐 전이 네트워크 모델의 최초 3개의 층의 인코더의 커널(kernel)의 크기는 상기 피쳐 전이 네트워크 모델에 입력되는 피쳐의 크기에 기반하여 결정될 수 있다. 일 실시예에 있어서, 상기 객체 인식 방법은, 상기 자율주행 차량의 주행 중에 상기 자율주행 차량의 카메라를 통해 획득되는 이미지를 수신하는 단계, 상기 수신된 이미지를 상기 제2 네트워크 모델에 입력하는 단계, 및 상 기 제2 네트워크 모델로부터 객체 인식 결과를 획득하는 단계를 더 포함할 수 있다. 일 실시예에 있어서, 상기 객체 인식 결과는, 3차원 공간에 존재하는 객체의 위치 및 종류를 포함할 수 있다."}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 기술은 차량에 탑재된 카메라의 파라미터 변화에 강건한 이미지 기반의 3차원 객체 인식 장치 및 그 방법을 제공할 수 있다. 또한, 본 기술은 차량의 주행 중에 획득된 이미지에 대해 실시간으로 카메라의 파라미터를 기반으로 보정해야 하는 과정을 필요로 하지 않아, 객체 인식 장치의 과도한 연산량을 감소시키고, 성능 열화를 감소시킬 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시예를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 실시예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생략한 다. 본 발명의 실시예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소 의 본질이나 차례 또는 순서 등이 한정되지 않는다. 또한, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용 어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들 은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정 의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 도 1 내지 도 9를 참조하여, 본 발명의 실시예들을 구체적으로 설명하기로 한다. 도 1은 본 발명의 일 실시 예에 따른 객체 인식 장치의 구성을 나타내는 블록도이다. 도 1을 참조하면, 본 발명의 일 실시 예에 따른 객체 인식 장치는 프로세서 및 저장부를 포함할 수 있다. 객체 인식 장치는 차량(예: 자율주행 차량)의 내부에 구현될 수 있다. 객체 인식 장치는 차 량의 내부 제어 유닛들과 일체로 형성될 수 있으며, 별도의 장치로 구현되어 별도의 연결 수단에 의해 차량의 제어 유닛들과 연결될 수도 있다. 프로세서는 저장부와 작동적으로(operatively) 연결될 수 있다. 프로세서는 저장부에 저장 된 명령어들을 실행함으로써, 후술하는 동작들을 수행할 수 있다. 예를 들어, 프로세서는 이미지를 기반으 로 객체를 인식하기 위한 네트워크 모델을 학습시키고, 학습된 네트워크 모델을 기반으로 객체를 인식할 수 있 다. 네트워크 모델은, 예를 들어, 딥러닝 네트워크 모델일 수 있다. 프로세서는 왜곡 및 회전이 보정된 이미지를 기반으로 네트워크 모델을 학습시킬 수 있다. 네트워크 모델 은 이미지를 기반으로 3차원 공간에 존재하는 객체를 인식하는 3차원 객체 인식기일 수 있다. 예를 들어, 네트 워크 모델은 피쳐 추출기(feature extractor) 및 디코더(decoder)로 구성될 수 있다. 프로세서는 왜곡 및 회전이 보정된 이미지를 학습 데이터로 하여 네트워크 모델을 사전 학습시킬 수 있다. 왜곡 및 회전이 보정된 이미지는, 예를 들어, 차량에 탑재된 카메라가 차량의 주행 중에 획득한 이미지의 왜곡 및 회전이 보정된 이미지일 수 있다. 예를 들어, 왜곡은 카메라의 렌즈의 형태에 의해 발생할 수 있다. 예를 들 어, 회전은 이미지 획득 시점에 발생한 차량의 회전에 의해 발생할 수 있다. 프로세서는 왜곡 및 회전이 보정된 이미지를 학습 데이터로 하여 네트워크 모델을 학습시킴으로써, 방향 또는 왜곡이 다른 카메라들의 데이터를 이용하여 네트워크 모델을 학습시킬 수 있다. 프로세서는 왜곡 및 회전이 보정된 이미지를 학습 데이터로 하여 네트워크 모델을 학습시킴으로써, 2차원 이미지 공간과 3차원 공간 사이의 관계를 하나로 학습시킬 수 있어, 왜곡 및 회전이 보정된 이미지에 대한 네트워크 모델의 성능을 향상시 킬 수 있다. 프로세서는 보정된 이미지를 기반으로 적어도 하나의 왜곡된 이미지를 생성할 수 있다. 본 문서에서 보정 된 이미지는 네트워크 모델의 사전 학습에 이용된 학습 데이터로 참조될 수 있다. 예를 들어, 프로세서는 보정된 이미지에 지정된 왜곡 값(K) 및 지정된 회전 값(R)을 입력하여 왜곡 및 회전이 발생한 적어도 하나의 왜 곡된 이미지를 생성할 수 있다. 지정된 회전 값은, 예를 들어, 요(yaw), 피치(pitch), 및 롤(roll)을 포함할 수있다. 요는 이동 방향에 대해 수직의 수직면에 있는 축을 기준으로 한 회전을 의미한다. 피치는 이동 방향에 대 해 수직의 수평면에 있는 축을 기준으로 한 회전을 의미한다. 롤은 이동 방향에 대해 평행한 수평면에 있는 축 을 기준으로 한 회전을 의미한다. 예를 들어, 보정된 이미지는 사전에 설정된 각 카메라의 왜곡 파라미터를 이용하여 보정된 것일 수 있다. 예를 들어, 보정된 이미지는 차량의 카메라의 내부 파라미터 또는 외부 파라미터 중 적어도 하나를 이용하여 보정된 것일 수 있다. 카메라의 내부 파라미터는, 예를 들어, 카메라의 회전과 관련된 파라미터를 포함할 수 있다. 카 메라의 외부 파라미터는, 예를 들어, 차체 자세 제어(vehicle dynamic control, VDC) 장치와 관련된 파라미터 및 차량의 구배 등을 자동으로 교정해주는 자동 교정(automatic calibration, AOC) 장치와 관련된 파라미터를 포함할 수 있다. 예를 들어, 프로세서는 보정에 대응하는 연산의 역변환을 이용하여 적어도 하나의 왜곡된 이미지를 생성할 수 있다. 보정에 대응하는 연산은, 예를 들어, 호모그래피(homography) 연산일 수 있다. 프로세서는 보정 에 대응하는 연산의 역변환을 이용하여 보정된 이미지에 지정된 왜곡 값(K) 및 지정된 회전 값(R)을 입력하여 적어도 하나의 왜곡된 이미지를 생성할 수 있다. 예를 들어, 프로세서는 왜곡 값(K)을 사전에 설정된 각 카메라의 왜곡 파라미터를 기반으로 설정할 수 있다. 예를 들어, 프로세서는 회전 값(R)을 차량의 거동과 유사하도록 미세하게 조정하여 복수의 서로 다른 회전 값을 입력하여 복수의 왜곡된 이미지를 생성할 수 있다. 프로세서는 보정된 이미지와 보정된 이미지로부터 생성된 적어도 하나의 왜곡된 이미지를 포함하는 이미지 셋(set)을 구성할 수 있다. 예를 들어, 프로세서는 역변환 관계를 나타내는 맵핑(mapping) 함수를 저장부에 저장할 수 있다. 맵 핑 함수는 보정된 이미지를 왜곡된 이미지로 변환하는 함수일 수 있다. 예를 들어, 프로세서는 왜곡된 이 미지에서 맵핑되지 않는 영역을 나타내는 마스크(mask) 이미지를 생성하여 맵핑 함수와 함께 저장할 수 있다. 예를 들어, 마스크 이미지는 회전에 의해 발생하는 왜곡된 이미지 상의 빈 공간을 나타낼 수 있다. 예를 들어, 빈 공간은 이미지의 외곽 부분을 포함할 수 있다. 프로세서는 보정된 이미지로부터 추출된 피쳐(feature) 및 적어도 하나의 왜곡된 이미지 각각으로부터 추 출된 피쳐를 기반으로 피쳐 전이 모듈(features transfer module)을 학습시킬 수 있다. 프로세서는 적어도 하나의 왜곡된 이미지 각각으로부터 추출된 피쳐를 보정된 이미지로부터 추출된 피쳐와 동일하게 만들어주도록 피쳐 전이 모듈을 학습시킬 수 있다. 네트워크 모델은 이미지로부터 추출된 피쳐를 기반으로 3차원 객체 인식을 수행할 수 있다. 예를 들어, 왜곡된 이미지와 보정된 이미지 각각에서 추출된 피쳐가 동일하다면, 보정 여부와 상관없이 동일한 장면에 대한 3차원 객체 인식 결과가 동일하게 획득될 수 있다. 프로세서는 왜곡된 이미 지로부터 추출된 피처를 보정된 이미지로부터 추출된 피처와 동일하게 만들어주도록 피쳐 전이 모듈을 학습시킴 으로써, 학습된 피쳐 전이 모듈을 이용하여, 이미지를 보정하지 않고도 보정된 이미지에서 추출된 피쳐와 동일 한 피쳐를 추출할 수 있다. 예를 들어, 피쳐 전이 모듈은 피쳐 전이 네트워크 모델을 포함할 수 있다. 피쳐 전이 네트워크 모델은, 예를 들 어, 딥러닝 네트워크 모델일 수 있다. 피쳐 전이 네트워크 모델은 후술하는 형태에 한정되지 않으며, 예를 들어, 트랜스포머(transformer) 또는 다층 퍼셉트론(multi-layer perceptron, MLP)의 형태를 가질 수도 있다. 피쳐 전이 네트워크 모델은 각 피쳐에 대응하는 층(layer)별로 인코더(encoder) 및 디코더를 포함할 수 있다. 예를 들어, 피쳐 전이 네트워크 모델의 최초 3개의 층의 인코더의 커널(kernel)의 크기는 피쳐 전이 네트워크 모델에 입력되는 피쳐의 크기에 기반하여 결정(또는, 설정)될 수 있다. 예를 들어, 피쳐 전이 네트워크 모델의 최초 3개의 층의 인코더의 커널의 크기는 피쳐 전이 네트워크 모델에 입력되는 피쳐의 1/4 크기로 결정될 수 있 다. 피쳐 전이 네트워크 모델은 인코더의 커널의 크기가 입력 피쳐의 1/4 크기로 설정된 경우, 커널의 크기가 3x3 또는 5x5로 설정된 경우와 달리, 이미지 공간 상에서 서로 먼 지점들 간의 맵핑 관계도 학습할 수 있다. 예를 들어, 프로세서는 보정된 이미지와 그로부터 생성된 적어도 하나의 왜곡된 이미지를 포함하는 이미지 셋을 이용하여 피쳐 전이 네트워크 모델을 학습시킬 수 있다. 예를 들어, 피쳐 전이 네트워크 모델은 모양 손실 (Lshape), 맵핑 손실(Lmap), 상관성 손실(Lcontra), 및 감별 손실(Ldisc)을 포함하는 손실함수(loss function)(Ltotal) 를 기반으로 학습될 수 있다. 프로세서는 아래 수학식 1에 기반하여 손실함수(Ltotal)를 계산할 수 있다.수학식 1"}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "프로세서는 적어도 하나의 왜곡된 이미지로부터 추출된 피쳐와 보정된 이미지로부터 추출된 피쳐를 기반으 로 각 손실을 계산할 수 있다. 모양 손실(Lshape)은 각 왜곡된 이미지로부터 추출된 피쳐의 출력 결과의 모양과 보정된 이미지로부터 추출된 피쳐의 출력 결과의 모양의 차이의 평균을 나타낼 수 있다. 맵핑 손실(Lmap)은 각 왜곡된 이미지로부터 추출된 피쳐와 보정된 이미지로부터 추출된 피쳐 간의 맵핑 오차의 평균을 나타낼 수 있다. 상관성 손실(Lcontra)은 각 왜곡된 이미지로부터 추출된 피쳐의 통계적 분포와 보정된 이미지로부터 추출된 피쳐의 통계적 분포의 차이의 평균을 나타낼 수 있다. 감별 손실(Ldisc)은 각 왜곡된 이미지로부터 추출된 피쳐를 보정된 이미지로부터 추출된 피쳐라고 판별하는 정도의 평균을 나타낼 수 있다. 수학식 1에 따르면, 감별 손실 (Ldisc)은 클수록, 모양 손실(Lshape), 맵핑 손실(Lmap) 및 상관성 손실(Lcontra)은 작을수록, 손실함수의 값이 작아 질 수 있다. 예를 들어, 프로세서는 왜곡된 이미지에서 맵핑되지 않는 영역에 대한 손실에는 0을 곱하고, 맵핑된 영역 에 대한 손실에는 1을 곱하여 손실함수의 값을 계산할 수 있다. 예를 들어, 프로세서는 맵핑 함수와 함께 저장된 마스크 이미지에 기반하여 왜곡된 이미지에서 맵핑되지 않는 영역을 식별할 수 있다. 프로세서는 맵핑되지 않는 영역에 대한 손실을 0으로 처리하고, 맵핑된 영역에 대한 손실만을 계산함으로써, 피쳐 전이 모 듈이 맵핑 관계 자체를 모사하도록 할 수 있다. 프로세서는 수학식 1에 기반하여 계산된 손실함수의 값이 최소화되도록 피쳐 전이 네트워크 모델을 학습시 킴으로써, 감별자가 보정된 이미지로부터 추출된 피쳐와 왜곡된 이미지로부터 추출된 피쳐를 구분할 수 없고, 피쳐의 출력 결과의 모양이 같으며 피쳐의 통계적 분포가 같고, 피쳐 간의 맵핑 관계가 이미지 간의 맵핑 관계 와 유사하도록, 피쳐 전이 네트워크 모델을 학습시킬 수 있다. 예를 들어, 프로세서는 사용자 입력에 기반하여 손실함수를 변경하거나, 손실함수를 구성하는 적어도 하나 의 항(예: 모양 손실(Lshape), 맵핑 손실(Lmap), 상관성 손실(Lcontra), 또는 감별 손실(Ldisc))에 대해 가중치를 부 여할 수 있다. 프로세서는 피쳐 전이 모듈을 네트워크 모델에 삽입할 수 있다. 예를 들어, 프로세서는 피쳐 전이 모 듈을 사전 학습된 네트워크 모델에 삽입할 수 있다. 프로세서가 피쳐 전이 모듈을 사전 학습된 네트워크 모델에 삽입합으로써, 네트워크 모델은 피쳐 추출기, 피쳐 전이 모듈, 및 디코더로 구성될 수 있다. 예를 들어, 네트워크 모델은 사전 학습 전 네트워크 모델에서 피쳐 전이 모듈을 더 포함할 수 있다. 프로세서는 적어도 하나의 왜곡된 이미지를 기반으로 피쳐 전이 모듈을 포함하는 네트워크 모델에 대한 파 인 튜닝(fine tuning)을 수행할 수 있다. 본 문서에서 파인 튜닝은 적은 에포크(epoch)(예: 학습 횟수)로 전체 네트워크 모델(예: 피쳐 전이 모듈을 포함하는 네트워크 모델)을 한 번 더 학습시키는 것을 의미할 수 있다. 프로세서는 차량의 주행 중에 자율주행 차량의 카메라를 통해 획득되는 이미지를 수신할 수 있다. 예를 들 어, 프로세서는 자율주행 차량의 카메라로부터 이미지를 수신할 수 있다. 프로세서는 카메라로부터 수신된 이미지를 피쳐 전이 모듈을 포함하는 네트워크 모델에 입력할 수 있다. 프로세서는 카메라로부터 수신된 이미지에 대해 보정을 수행하지 않고 원본 그대로 네트워크 모델에 입력할 수 있다. 프로세서는 피쳐 전이 모듈을 포함하는 네트워크 모델로부터 객체 인식 결과를 획득할 수 있다. 프로세서 는 카메라로부터 수신된 이미지에 대해 왜곡 및 회전을 보정한 이후, 보정된 이미지에 대해 객체 인식을 수행한 결과와 동일한 객체 인식 결과를 획득할 수 있다. 객체 인식 결과는, 예를 들어, 3차원 공간에 존재하는 객체의 위치 및 종류를 포함할 수 있다. 예를 들어, 프로세서는 객체 인식 결과를 자율주행 차량의 차량 제어 장치로 송신할 수 있다. 자율주행 차 량의 차량 제어 장치는 객체 인식 결과를 기반으로 자율주행 차량을 제어할 수 있다. 프로세서는 왜곡된 이미지의 원본을 그대로 사용하여 객체 인식을 수행하더라도 실시간으로 보정된 이미지에 기반하여 객체 인식 결과를 수행한 것과 동일한 성능의 객체 인식 결과를 제공함으로써, 객체 인식에 기반한 자율주행 차량의 자율주행 성능을 향상시킬 수 있다. 저장부는 프로세서에 의해 실행되는 명령어들을 저장할 수 있다. 저장부는 프로세서가 동 작을 수행함에 있어 필요한 데이터를 저장할 수 있다. 예를 들어, 저장부는 이미지를 기반으로 객체를 인 식하기 위한 네트워크 모델을 저장할 수 있다. 예를 들어, 저장부는 네트워크 모델의 학습 데이터로서 보 정된 이미지 및 보정된 이미지를 기반으로 생성된 왜곡된 이미지를 저장할 수 있다. 예를 들어, 저장부는 학습 데이터로 학습하기 전의 네트워크 모델을 저장할 수 있다. 저장부는 프로세서에 의해 처리된 데이터 또는 정보를 저장할 수 있다. 예를 들어, 저장부는 학 습 데이터로 학습한 이후의 네트워크 모델을 저장할 수 있다. 예를 들어, 저장부는 보정된 이미지 및 왜곡 된 이미지로부터 추출된 피쳐를 저장할 수 있다. 예를 들어, 저장부는 차량의 카메라를 통해 획득된 이미 지의 원본(예: 로 데이터(raw data) 또는 보정 전 이미지)을 학습된 네트워크 모델에 입력하여 획득한 객체 인 식 결과(예: 객체의 위치 및/또는 종류)를 저장할 수 있다. 상술한 실시예는 3차원 객체 인식 장치를 구현하고 있으나, 다양한 실시예에 따르면, 상술한 네트워크 모델의 학습 및 동작 방법은 깊이를 추정하거나 점유(occupancy)를 예측하는 등의 이미지를 기반으로 3차원 정보를 출 력하는 다른 네트워크 모델들에 적용될 수 있다. 도 2는 본 발명의 일 실시 예에 따른 객체 인식 장치의 네트워크 모델의 구성을 나타내는 블록도이다. 도 2에 도시된 네트워크 모델은, 예를 들어, 도 1의 객체 인식 장치의 네트워크 모델일 수 있다. 후술하는 네트워크 모델의 동작들은 도 1의 객체 인식 장치 또는 객체 인식 장치의 프로세서에 의해 수행될 수 있다. 도 2를 참조하면, 네트워크 모델은 피쳐 추출기, 피쳐 전이 모듈, 및 디코더를 포함할 수 있다. 피쳐 추출기는 보정된 이미지 또는 왜곡된 이미지로부터 피쳐를 추출할 수 있다. 디코더는 이 미지로부터 추출된 피쳐에 기반하여 3차원 객체 인식을 수행할 수 있다. 디코더는 3차원 객체 인식 결과를 출력할 수 있다. 피쳐 전이 모듈은 왜곡된 이미지로부터 추출된 피쳐를 보정된 이미지로부터 추출된 피쳐와 동일하게 만들 어주도록 학습될 수 있다. 네트워크 모델은 학습된 피쳐 전이 모듈이 피쳐 추출기 및 디코더 사이에 삽입된 것일 수 있다. 피쳐 전이 모듈이 삽입되기 전에, 피쳐 추출기 및 디코더로 구성된 네트워크 모델은 보정된 이 미지를 기반으로 사전 학습될 수 있다. 피쳐 전이 모듈이 삽입된 이후, 네트워크 모델에 대하여 왜곡된 이미지를 기반으로 파인 튜닝이 수행 될 수 있다. 파인 튜닝까지 완료된 네트워크 모델은 차량의 카메라를 통해 획득되는 보정되지 않은(또는 왜곡된) 이미지를 입력 받아, 입력된 이미지의 보정된 이미지에 대해 객체 인식을 수행한 결과와 동일한 객체 인식 결과를 출력할 수 있다. 피쳐 전이 모듈은 왜곡된 이미지로부터 추출된 피쳐를 기반으로 학습되고, 왜곡된 이미지는 롤, 피치, 및/ 또는 요를 다양하게 조정한 회전 값을 이용하여 생성되므로, 피쳐 전이 모듈을 포함하는 네트워크 모델 은 차량의 움직임에 의한 롤, 피치 및 요의 변화에 강건해질 수 있다. 피쳐 전이 모듈이 네트워크 모델에 임베딩 되므로, 객체 인식 프로세스가 신경망 처리 장치에 의해 처음부 터 끝까지(end-to-end) 처리될 수 있으며, 왜곡 보정과 같은 이미지 신호 처리(image signal processing)에 비 해 처리 속도가 빠를 수 있다. 네트워크 모델은 피쳐 수준(feature level)에서 보정을 수행하므로, 카메라별 왜곡 및 회전을 고려하여 카 메라별로 학습 데이터를 구분할 필요가 없어 네트워크 모델의 성능이 향상되고, 카메라의 뷰(view) 변화에 의한 오버피팅(overfitting) 현상이 감소될 수 있다. 도 3은 본 발명의 일 실시 예에 따른 객체 인식 장치의 학습 방법을 설명하기 위한 순서도이다. 이하에서는 도 1의 객체 인식 장치가 도 3의 프로세스를 수행하는 것을 가정한다. 또한, 도 3의 설명에서, 장치에 의해 수행되는 것으로 기술된 동작은 객체 인식 장치의 프로세서에 의해 수행되는 것으로 이해될 수 있다.동작 310에서, 객체 인식 장치는 보정된 이미지를 기반으로 네트워크 모델을 학습시킬 수 있다. 객체 인식 장치는 왜곡 및 회전이 보정된 이미지를 기반으로 제1 네트워크 모델을 학습시킬 수 있다. 왜곡 및 회전이 보정된 이미지는, 예를 들어, 차량에 탑재된 카메라가 차량의 주행 중에 획득한 이미지의 왜곡 및 회전이 보정 된 이미지일 수 있다. 제1 네트워크 모델은 객체 인식 장치의 저장부에 저장된, 이미지를 기반으로 객체 인식을 수행하는 딥러닝 네트워크 모델일 수 있다. 예를 들어, 제1 네트워크 모델은 피쳐 추출기 및 디코 더로 구성될 수 있다. 동작 310에서 객체 인식 장치가 제1 네트워크 모델을 학습시키는 것은 객체 인식 장 치의 사전 학습 동작으로 참조될 수 있다. 동작 320에서, 객체 인식 장치는 왜곡된 이미지를 생성할 수 있다. 객체 인식 장치는 보정된 이미지 를 기반으로 적어도 하나의 왜곡된 이미지를 생성할 수 있다. 예를 들어, 객체 인식 장치는 보정된 이미지 에 지정된 왜곡 값 및 지정된 회전 값을 입력하여 왜곡 및 회전이 발생한 적어도 하나의 왜곡된 이미지를 생성 할 수 있다. 예를 들어, 객체 인식 장치는 회전 값을 차량의 거동과 유사하도록 미세하게 조정하여 복수의 서로 다른 회전 값을 입력하여 복수의 왜곡된 이미지를 생성할 수 있다. 객체 인식 장치는 보정된 이미지 와 보정된 이미지로부터 생성된 적어도 하나의 왜곡된 이미지를 포함하는 이미지 셋을 구성할 수 있다. 예를 들어, 보정된 이미지는 사전에 설정된 각 카메라의 왜곡 파라미터를 이용하여 보정된 것일 수 있다. 예를 들어, 보정된 이미지는 차량의 카메라의 내부 파라미터 또는 외부 파라미터 중 적어도 하나를 이용하여 보정된 것일 수 있다. 예를 들어, 카메라의 내부 파라미터는 카메라 자체의 회전을 나타내는 파라미터를 포함할 수 있 다. 예를 들어, 카메라의 외부 파라미터는 차체의 회전을 나타내는 파라미터를 포함할 수 있다. 객체 인식 장치 는 원본 이미지에 사전에 설정된 왜곡 파라미터와 카메라의 내부 파라미터 및/또는 외부 파라미터를 반영 함으로써 보정을 수행할 수 있다. 예를 들어, 객체 인식 장치는 보정에 대응하는 연산의 역변환을 이용하여 적어도 하나의 왜곡된 이미지를 생성할 수 있다. 예를 들어, 객체 인식 장치는 역변환에 대응하는 왜곡 값 및 회전 값을 결정할 수 있다. 객체 인식 장치는 사전에 설정된 왜곡 파라미터를 기반으로 왜곡 값을 결정할 수 있다. 객체 인식 장치 는 카메라의 내부 파라미터 및/또는 외부 파라미터를 기반으로 회전 값을 결정할 수 있다. 예를 들어, 객 체 인식 장치는 회전 값을 서로 차이가 크지 않은 수준(예: 차이가 임계 값 미만)에서 복수 개 선택할 수 있다. 객체 인식 장치는 복수의 서로 다른 회전 값에 기반하여 복수의 왜곡된 이미지를 생성할 수 있다. 예를 들어, 객체 인식 장치는 역변환 관계를 나타내는 맵핑 함수를 저장부에 저장할 수 있다. 맵핑 함수는 보정된 이미지를 왜곡된 이미지로 변환하는 함수일 수 있다. 객체 인식 장치는 왜곡된 이미지에서 맵핑되지 않는 영역을 나타내는 마스크 이미지를 생성하여 맵핑 함수와 함께 저장할 수 있다. 동작 330에서, 객체 인식 장치는 보정된 이미지로부터 추출된 피쳐 및 왜곡된 이미지로부터 추출된 피쳐를 기반으로 피쳐 전이 모듈을 학습시킬 수 있다. 객체 인식 장치는 보정된 이미지로부터 추출된 피쳐 및 적 어도 하나의 왜곡된 이미지 각각으로부터 추출된 피쳐를 기반으로 피쳐 전이 모듈을 학습시킬 수 있다. 객체 인 식 장치는 적어도 하나의 왜곡된 이미지 각각으로부터 추출된 피쳐를 보정된 이미지로부터 추출된 피쳐와 동일하게 만들어주도록 피쳐 전이 모듈을 학습시킬 수 있다. 피쳐 전이 모듈은 피쳐 전이 네트워크 모델을 포함 할 수 있다. 객체 인식 장치가 피쳐 전이 모듈을 학습시키는 것은 피쳐 전이 네트워크 모델을 학습시키는 것일 수 있다. 피쳐 전이 네트워크 모델은, 예를 들어, 딥러닝 네트워크 모델일 수 있다. 피쳐 전이 네트워크 모델은 각 피쳐 에 대응하는 층별로 인코더 및 디코더를 포함할 수 있다. 예를 들어, 피쳐 전이 네트워크 모델의 최초 3개의 층 의 인코더의 커널의 크기는 피쳐 전이 네트워크 모델에 입력되는 피쳐의 크기에 기반하여 결정될 수 있다. 예를 들어, 객체 인식 장치는 모양 손실, 맵핑 손실, 상관성 손실, 및 감별 손실을 포함하는 손실함수를 기반으로 피쳐 전이 네트워크 모델을 학습시킬 수 있다. 손실함수는 모양 손실, 맵핑 손실, 상관성 손실이 작을 수록, 그리고 감별 손실이 클수록 값이 작아지도록 구성될 수 있다. 객체 인식 장치는 손실함수의 값이 최 소화되도록 피쳐 전이 네트워크 모델을 학습시킬 수 있다. 예를 들어, 객체 인식 장치는 왜곡된 이미지에서 맵핑되지 않는 영역에 대한 손실에는 0을 곱하고, 맵핑된 영역에 대한 손실에는 1을 곱하여 손실함수의 값을 계산할 수 있다. 객체 인식 장치는 마스크 이미지에 기 반하여 왜곡된 이미지에서 맵핑되지 않는 영역을 식별할 수 있다. 동작 340에서, 객체 인식 장치는 피쳐 전이 모듈을 네트워크 모델에 삽입할 수 있다. 객체 인식 장치(10 0)는 피쳐 전이 모듈을 동작 310에서 사전 학습된 제1 네트워크 모델에 삽입할 수 있다. 이하, 피쳐 전이 모듈이 삽입된 제1 네트워크 모델은 제2 네트워크 모델로 참조될 수 있다. 제2 네트워크 모델은 피쳐 추출기, 피쳐 전이 모듈, 및 디코더로 구성될 수 있다. 동작 350에서, 객체 인식 장치는 왜곡된 이미지를 기반으로 피쳐 전이 모듈을 포함하는 네트워크 모델에 대한 파인 튜닝을 수행할 수 있다. 객체 인식 장치는 적어도 하나의 왜곡된 이미지를 기반으로 피쳐 전이 모듈을 포함하는 제2 네트워크 모델에 대한 파인 튜닝을 수행할 수 있다. 객체 인식 장치는 동작 310 내지 동작 350을 수행함으로써 이미지를 기반으로 3차원 공간에 존재하는 객체 를 인식하는 네트워크 모델을 학습시킬 수 있다. 객체 인식 장치는 학습된 네트워크 모델을 이용하여 자율 주행 차량의 카메라를 통해 획득되는 이미지를 기반으로 실시간으로 왜곡 및 회전을 보정하지 않고도 3차원 객 체 인식을 수행할 수 있다. 객체 인식 장치가 학습된 네트워크 모델을 이용하여 객체 인식을 수행하는 프 로세스에 대하여는 도 8을 참조하여 보다 상세히 후술하도록 한다. 이하, 도 4 내지 도 7을 참조하여 일 실시 예에 따른 객체 인식 장치의 학습 방법에 대하여 설명한다. 도 4는 본 발명의 일 실시 예에 따른 객체 인식 장치의 사전 학습 방법을 설명하기 위한 도면이다. 후술하는 동 작들은 도 1의 객체 인식 장치가 수행하는 것으로 가정한다. 또한, 도 4의 설명에서, 장치에 의해 수행되 는 것으로 기술된 동작은 객체 인식 장치의 프로세서에 의해 수행되는 것으로 이해될 수 있다. 도 4를 참조하면, 객체 인식 장치는 차량의 주행 중에 차량에 탑재된 카메라를 통해 획득되는 원본 이미지 를 보정할 수 있다. 원본 이미지는, 예를 들어, 로 나타낼 수 있다. 객체 인식 장치는 원 본 이미지의 왜곡 및 회전을 보정하여 보정된 이미지를 획득할 수 있다. 보정된 이미지는, 예를 들어, 로 나타낼 수 있다. 객체 인식 장치는 보정된 이미지를 기반으로 네트워크 모델을 학습시킬 수 있다. 네트워크 모델 은 객체 인식 장치의 학습 전 네트워크 모델일 수 있다. 학습 전 네트워크 모델은, 예를 들어, 피쳐 추출기 및 디코더를 포함할 수 있다. 네트워크 모델은 보정된 이미지를 입력 받아 3차원 객체 인식 결과를 출력할 수 있다. 3차원 객 체 인식 결과는, 예를 들어, 로 나타낼 수 있다. 객체 인식 장치가 보정된 이미지를 기반으로 네트워크 모델을 사전 학습시키는 동작은, 아래 수 학식 2와 같이 수식으로 표현될 수 있다. 수학식 2에서 f는 디코더를 의미하고, g는 피쳐 추출기를 의미할 수 있다. 수학식 2"}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 5는 본 발명의 일 실시 예에 따른 객체 인식 장치의 왜곡된 이미지를 생성하는 방법을 설명하기 위한 도면이 다. 후술하는 동작들은 도 1의 객체 인식 장치가 수행하는 것으로 가정한다. 또한, 도 5의 설명에서, 장치 에 의해 수행되는 것으로 기술된 동작은 객체 인식 장치의 프로세서에 의해 수행되는 것으로 이해될 수 있다. 도 5를 참조하면, 객체 인식 장치는 보정된 이미지를 기반으로 적어도 하나의 왜곡된 이미지를 생성할 수 있다. 적어도 하나의 왜곡된 이미지는, 예를 들어, 제1 왜곡된 이미지 및 제2 왜곡된 이미 지를 포함할 수 있다. 객체 인식 장치는 보정된 이미지에 지정된 왜곡 값(K1) 및 지정된 회전 값(R1)을 입력하여 제1 왜곡된 이미지를 생성할 수 있다. 제1 왜곡된 이미지는, 예를 들어, 로나타낼 수 있다. 객체 인식 장치는 보정된 이미지에 지정된 왜곡 값(K2) 및 지정된 회전 값(R2)을 입 력하여 제2 왜곡된 이미지를 생성할 수 있다. 제2 왜곡된 이미지는, 예를 들어, 로 나타낼 수 있다. 예를 들어, 지정된 왜곡 값(K1 및 K2)은 사전에 설정된 왜곡 파라미터인 K로 설정될 수 있다. 예를 들어, 지정된 회전 값(R1 또는 R2)은 각각 요, 피치, 또는 롤 중 적어도 하나를 미세하게 조정한 서로 다른 회전 값으 로 설정될 수 있다. 객체 인식 장치는 보정된 이미지를 적어도 하나의 왜곡된 이미지로 변환하는 함수인 맵핑 함수 를 저장할 수 있다. 맵핑 함수는 보정에 대응하는 연산과 역변환 관계일 수 있다. 보정된 이미지를 제1 왜 곡된 이미지로 변환하는 제1 맵핑 함수는, 예를 들어, 로 나타낼 수 있다. 보정된 이미지를 제2 왜곡된 이미지로 변환하는 제2 맵핑 함수는, 예를 들어, 로 나타낼 수 있다. 객체 인식 장치 가 보정된 이미지를 기반으로 적어도 하나의 왜곡된 이미지를 생성하는 동작은, 아래 수학식 3 과 같이 수식으로 표현될 수 있다. 수학식 3에서 는 왜곡된 이미지를 의미하고, 는 맵핑 함수를 의 미할 수 있다. 수학식 3"}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "객체 인식 장치는 왜곡된 이미지에서 맵핑되지 않는 영역을 나타내는 마스크 이미지를 생성하여 맵핑 함수 와 함께 저장할 수 있다. 예를 들어, 마스크 이미지는 회전에 의해 발생하는 왜곡된 이미지 상의 빈 공간을 나 타낼 수 있다. 예를 들어, 빈 공간은 이미지의 외곽 부분을 포함할 수 있다. 객체 인식 장치는 제1 왜곡된 이미지에 대응하는 제1 마스크 이미지를 제1 맵핑 함수와 함께 저장할 수 있다. 제1 마스크 이미지 는, 예를 들어, 로 나타낼 수 있다. 객체 인식 장치는 제2 왜곡된 이미지에 대응하는 제 2 마스크 이미지를 제2 맵핑 함수와 함께 저장할 수 있다. 제2 마스크 이미지는, 예를 들어, 로 나타낼 수 있다. 도 6은 본 발명의 일 실시 예에 따른 객체 인식 장치의 피쳐 전이 모듈을 학습시키는 방법을 설명하기 위한 도 면이다. 후술하는 동작들은 도 1의 객체 인식 장치가 수행하는 것으로 가정한다. 또한, 도 6의 설명에서, 장치에 의해 수행되는 것으로 기술된 동작은 객체 인식 장치의 프로세서에 의해 수행되는 것으로 이 해될 수 있다. 도 6을 참조하면, 객체 인식 장치는 보정된 이미지로부터 추출된 피쳐 및 적어도 하나의 왜곡된 이미 지 각각으로부터 추출된 피쳐를 기반으로 피쳐 전이 모듈을 학습시킬 수 있다. 예를 들어, 적어도 하 나의 왜곡된 이미지는 로 나타낼 수 있다. 객체 인식 장치는 적어도 하나의 왜곡된 이미지 각각 으로부터 추출된 피쳐를 보정된 이미지로부터 추출된 피쳐와 동일하게 만들어주도록 피쳐 전이 모듈 을 학습시킬 수 있다. 예를 들어, 객체 인식 장치는 모양 손실, 맵핑 손실, 상관성 손실, 및 감별 손실을 포함하는 손실함수의 값이 최소화되도록 피쳐 전이 모듈을 학습시킬 수 있다. 모양 손실, 맵핑 손실, 및 상관성 손실이 작을수 록, 감별 손실이 클수록 손실함수의 값은 작아질 수 있다. 객체 인식 장치는 왜곡된 이미지에서 맵핑되지 않는 영역에 대한 손실에는 0을 곱하고, 맵핑된 영역에 대한 손실에는 1을 곱하여 손실함수의 값을 계산할 수 있다. 객체 인식 장치는 사전에 획득(또는 연산)된 마스크 이미지(예: 도 5의 제1 마스크 이미지 또 는 제2 마스크 이미지)를 이용하여 왜곡된 이미지의 맵핑되지 않는 영역을 식별할 수 있다. 예를 들어, 객체 인식 장치는 피쳐 추출기를 통해 보정된 이미지로부터 제1 피쳐를 추출할 수 있다. 객체 인식 장치는 피쳐 추출기를 통해 적어도 하나의 왜곡된 이미지 각각의 피쳐를 추출하고, 이를 학습된 피쳐 전이 모듈에 입력하여 제2 피쳐를 추출할 수 있다. 제1 피쳐와 제2 피쳐는 동일할 수 있다. 객체 인식 장치는 학습된 피쳐 전이 모듈을 네트워크 모델에 삽입할 수 있다. 예를 들어, 객체 인식 장치는 학습된 피쳐 전이 모듈을 피쳐 추출기 및 디코더 사이에 삽입할 수 있다. 학 습이 완료된 피쳐 전이 모듈은 아래 수학식 4와 같이 수식으로 표현될 수 있다. 수학식 4에서 T는 피쳐 전 이 모듈 또는 피쳐 전이 함수를 의미하고, g는 피쳐 추출기를 의미할 수 있다. 수학식 4"}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 5, "content": "도 7은 본 발명의 일 실시 예에 따른 객체 인식 장치의 파인 튜닝 방법을 설명하기 위한 순서도이다. 후술하는 동작들은 도 1의 객체 인식 장치가 수행하는 것으로 가정한다. 또한, 도 7의 설명에서, 장치에 의해 수행 되는 것으로 기술된 동작은 객체 인식 장치의 프로세서에 의해 수행되는 것으로 이해될 수 있다. 도 7을 참조하면, 객체 인식 장치는 적어도 하나의 왜곡된 이미지를 기반으로 피쳐 전이 모듈을 포함하는 네트워크 모델에 대한 파인 튜닝을 수행할 수 있다. 객체 인식 장치는 피쳐 전이 모듈(22 0)을 포함하는 네트워크 모델에 적어도 하나의 왜곡된 이미지를 입력하여 보정된 이미지를 입력 한 경우와 동일한 결과(예: 도 4의 3차원 객체 인식 결과)를 출력하도록 파인 튜닝을 수행할 수 있다. 객체 인식 장치가 파인 튜닝을 수행하는 동작은, 아래 수학식 5와 같이 수식으로 표현될 수 있다. 수학식 5에서 f는 디코더를 의미하고, T는 피쳐 전이 모듈을 의미하고, g는 피쳐 추출기를 의미할 수 있다. 수학식 5"}
{"patent_id": "10-2023-0046295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 6, "content": "도 8은 본 발명의 일 실시 예에 따른 객체 인식 장치의 동작 방법을 설명하기 위한 순서도이다. 이하에서는 도 1의 객체 인식 장치가 도 3의 프로세스를 수행하는 것을 가정한다. 또한, 도 8의 설명에서, 장치에 의해 수행되는 것으로 기술된 동작은 객체 인식 장치의 프로세서에 의해 수행되는 것으로 이해될 수 있다. 동작 810에서, 객체 인식 장치는 차량의 카메라를 통해 획득되는 이미지를 수신할 수 있다. 예를 들어, 객 체 인식 장치는 자율주행 차량의 카메라로부터 이미지를 수신할 수 있다. 동작 820에서, 객체 인식 장치는 수신된 이미지를 학습된 네트워크 모델에 입력할 수 있다. 객체 인식 장 치는 수신된 이미지를 피쳐 전이 모듈을 포함하는 네트워크 모델에 입력할 수 있다. 동작 830에서, 객체 인식 장치는 학습된 네트워크 모델로부터 3차원 객체 인식 결과를 획득할 수 있다. 객 체 인식 장치는 피쳐 전이 모듈을 포함하는 네트워크 모델로부터 3차원 객체 인식 결과를 획득할 수 있다 객체 인식 장치는 자율주행 차량의 카메라로부터 수신된 이미지에 대해 왜곡 및 회전을 보정한 이후, 보정된 이미지에 대해 3차원 객체 인식을 수행한 결과와 동일한 결과를 획득할 수 있다. 획득된 3차원 객체 인 식 결과는 3차원 공간에 존재하는 객체의 위치 및 종류를 포함할 수 있다.도 9는 본 발명의 일 실시 예에 따른 컴퓨팅 시스템을 도시한다. 도 9를 참조하면, 컴퓨팅 시스템은 버스를 통해 연결되는 적어도 하나의 프로세서, 메모리 , 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치, 스토리지, 및 네트워 크 인터페이스를 포함할 수 있다. 프로세서는 중앙 처리 장치(CPU) 또는 메모리 및/또는 스토리지에 저장된 명령어들에 대한 처리를 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 다양한 종류의 휘발성 또는 불휘발 성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM(Read Only Memory) 및 RAM(Random Access Memory)을 포함할 수 있다. 따라서, 본 명세서에 개시된 실시예들과 관련하여 설명된 방법 또는 알고리즘의 단계는 프로세서에 의해 실행되는 하드웨어, 소프트웨어 모듈, 또는 그 2 개의 결합으로 직접 구현될 수 있다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 디스크, 착탈형 디스크, CD-ROM과 같은 저장 매체(즉, 메모리 및/또는 스토리지)에 상주할 수도 있다. 예시적인 저장 매체는 프로세서에 커플링되며, 그 프로세서는 저장 매체로부터 정보를 판독할 수 있고 저장 매체에 정보를 기입할 수 있다. 다른 방법으로, 저장 매체는 프로세서와 일체형일 수도 있다. 프로세서 및 저장 매체는 주문형 집적회로(ASIC) 내에 상주할 수도 있다. ASIC는 사용자 단말기 내에 상주할 수 도 있다. 다른 방법으로, 프로세서 및 저장 매체는 사용자 단말기 내에 개별 컴포넌트로서 상주할 수도 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위 에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0046295", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 객체 인식 장치의 구성을 나타내는 블록도이다. 도 2는 본 발명의 일 실시 예에 따른 객체 인식 장치의 네트워크 모델의 구성을 나타내는 블록도이다. 도 3은 본 발명의 일 실시 예에 따른 객체 인식 장치의 학습 방법을 설명하기 위한 순서도이다. 도 4는 본 발명의 일 실시 예에 따른 객체 인식 장치의 사전 학습 방법을 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시 예에 따른 객체 인식 장치의 왜곡된 이미지를 생성하는 방법을 설명하기 위한 도면이 다. 도 6은 본 발명의 일 실시 예에 따른 객체 인식 장치의 피쳐 전이 모듈을 학습시키는 방법을 설명하기 위한 도면이다. 도 7은 본 발명의 일 실시 예에 따른 객체 인식 장치의 파인 튜닝 방법을 설명하기 위한 순서도이다. 도 8은 본 발명의 일 실시 예에 따른 객체 인식 장치의 동작 방법을 설명하기 위한 순서도이다. 도 9는 본 발명의 일 실시 예에 따른 컴퓨팅 시스템을 도시한다."}
