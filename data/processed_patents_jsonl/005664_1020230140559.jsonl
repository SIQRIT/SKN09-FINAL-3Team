{"patent_id": "10-2023-0140559", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0056632", "출원번호": "10-2023-0140559", "발명의 명칭": "개인화 영상 분할 장치 및 그 방법", "출원인": "한국전자통신연구원", "발명자": "정치윤"}}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 외부 장치로부터 수신한 제1 포맷의 사용자 입력에 기초하여 제2 포맷의 입력 정보를 출력하는 사용자 입력수집기;제2 외부 장치로부터 수신한 센싱 정보에 기초하여 상황 정보를 출력하는 센싱 정보 분석기;상기 입력 정보, 및 상기 상황 정보에 기초하여 개인화된 의미 정보를 분석하고, 상기 개인화된 의미 정보에 기초하여 개인화된 사용자 입력 정보를 출력하는 사용자 의미 정보 생성기;영상 데이터 및 텍스트 정보 각각을 인코딩하여 상기 영상 데이터에 대응하는 특징 정보를 생성하는 멀티모달인공지능 모델; 및상기 특징 정보 및 상기 개인화된 사용자 입력 정보에 기초하여 상기 영상 데이터 상에서 상기 사용자 입력에대응하는 객체를 검출하는 영상-입력 디코더를 포함하는 개인화 영상 분할 장치."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 사용자 의미 정보 생성기는,상기 개인화된 의미 정보를 저장하는 개인화 의미 모델;상기 개인화 의미 모델을 업데이트하는 개인화 의미 모델 관리기; 및상기 개인화된 의미 정보, 상기 입력 정보, 및 상기 상황 정보에 기초하여 상기 개인화된 사용자 입력 정보를생성하는 개인화 의미 생성기를 포함하는 개인화 영상 분할 장치."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 개인화 의미 모델 관리기는, 상기 입력 정보와 이전 입력 정보 사이의 유사도를 결정하고,상기 유사도가 미리 설정된 임계 보다 클 때, 상기 입력 정보에 기초하여 상기 개인화된 의미 정보를 업데이트하는 개인화 영상 분할 장치."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 개인화 의미 모델 관리기는,상기 유사도가 상기 임계와 같거나 작을 때, 상기 입력 정보에 기초한 개인화된 의미 정보를 생성하는 개인화영상 분할 장치."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 유사도는 상기 입력 정보와 상기 이전 입력 정보 사이의 단어 유사도 및 문맥 유사도에 기초하여 결정되는개인화 영상 분할 장치."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2025-0056632-3-제2항에 있어서,상기 개인화 의미 모델 관리기는,미리 설정된 주기마다 사용자 프로파일링을 수행하고, 상기 사용자 프로파일링에 기초하여 상기 개인화된 의미정보를 업데이트하는 개인화 영상 분할 장치."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 센싱 정보는 위치 정보, 관성 정보 중 적어도 하나를 포함하는 개인화 영상 분할 장치."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 사용자 입력 수집기는 음성-텍스트 변환기를 포함하고,상기 제1 포맷은 음성 포맷을 포함하고 상기 제2 포맷은 텍스트 포맷을 포함하는 개인화 영상 분할 장치."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 사용자 입력 수집기는 필기-텍스트 변환기를 포함하고,상기 제1 포맷은 이미지 포맷을 포함하고 상기 제2 포맷은 텍스트 포맷을 포함하는 개인화 영상 분할 장치."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 포맷의 사용자 입력을 수신하였는지 판단하는 단계;상기 사용자 입력에 기초하여 제2 포맷의 입력 정보를 생성하는 단계;상기 사용자 입력에 대응하여, 영상 데이터를 수집하는 단계;상기 사용자 입력에 대응하여, 수집한 센싱 정보의 분석에 기초하여 상황 정보를 생성하는 단계;개인화된 의미 정보, 상기 입력 정보, 및 상기 상황 정보에 기초하여 개인화된 사용자 입력 정보를 생성하는 단계;영상 데이터에 대응하는 특징 정보를 생성하는 단계; 및상기 특징 정보 및 상기 개인화된 사용자 입력 정보에 기초하여 상기 영상 데이터 상에서 상기 사용자 입력에대응하는 객체를 검출하는 단계를 포함하는 개인화 영상 분할 방법."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 입력 정보와 이전 입력 정보 사이의 유사도를 결정하는 단계; 및상기 입력 정보와 상기 이전 입력 정보의 유사도가 임계 보다 클 때, 상기 입력 정보에 기초하여 상기 개인화된의미 정보를 업데이트하는 단계를 포함하는 개인화 영상 분할 방법."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 입력 정보와 상기 이전 입력 정보 유사도가 임계와 같거나 작을 때, 상기 입력 정보에 기초한 개인화된 의미 정보를 생성하는 단계;생성된 상기 개인화된 의미 정보를 저장하는 단계를 포함하는 개인화 영상 분할 방법."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2025-0056632-4-제 11항에 있어서,상기 유사도는 상기 입력 정보 및 상기 이전 입력 정보 사이의 단어 유사도 및 문맥 유사도에 기초하여 결정되는 개인화 영상 분할 방법."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,미리 설정된 주기마다 사용자 프로파일링을 수행하는 단계; 및상기 사용자 프로파일링에 기초하여 상기 개인화된 의미 정보를 업데이트하는 단계를 더 포함하는 개인화 영상분할 방법"}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 센싱 정보는 위치 정보 및 관성 정보 중 적어도 하나를 포함하는 개인화 영상 분할 방법."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,상기 제1 포맷은 음성 포맷을 포함하고, 상기 제2 포맷은 텍스트 포맷을 포함하고,상기 사용자 입력은 음성 입력인 개인화 영상 분할 방법."}
{"patent_id": "10-2023-0140559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,상기 제1 포맷은 이미지 포맷을 포함하고, 상기 제2 포맷은 텍스트 포맷을 포함하고,상기 사용자 입력은 필기 입력인 개인화 영상 분할 방법."}
{"patent_id": "10-2023-0140559", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 실시예에 따른 개인화 영상 분할 장치는, 제1 외부 장치로부터 수신한 제1 포맷의 사용자 입력에 기초하여 제2 포맷의 입력 정보를 출력하는 사용자 입력 수집기, 제2 외부 장치로부터 수신한 센싱 정보에 기초 하여 상황 정보를 출력하는 센싱 정보 분석기, 입력 정보, 및 상황 정보에 기초하여 개인화된 의미 정보를 분석 하고, 개인화된 의미 정보에 기초하여 개인화된 사용자 입력 정보를 출력하는 사용자 의미 정보 생성기, 영상 데 이터 및 텍스트 정보 각각을 인코딩하여 영상 데이터에 대응하는 특징 정보를 생성하는 멀티모달 인공지능 모델, 및 특징 정보 및 개인화된 사용자 입력 정보에 기초하여 영상 데이터 상에서 사용자 입력에 대응하는 객체를 검 출하는 영상-입력 디코더를 포함할 수 있다."}
{"patent_id": "10-2023-0140559", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 영상 분할에 관한 것으로, 보다 구체적으로는, 개인화 영상 분할 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0140559", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상 분할(image segmentation)은 디지털 영상의 표현을 의미 있고 해석하기 쉽도록 단순화하거나 변환하기 위 해 영상을 여러 개의 픽셀 집합으로 나누는 과정을 의미한다. 영상 분할은 영상에서 객체의 경계를 찾는데 사용 된다. 최근 딥 러닝(deep learning)을 사용하여 영상 분할의 성능을 향상시키는 방법들이 연구되고 있다. 기존 의 영상 분할 방법들은 지도 학습을 기반으로 하며, 딥 러닝 모델을 학습시키는 단계에서 정의되지 않은 객체 정보를 분류하는 것이 제한된다. 영상 데이터와 텍스트 정보를 동일한 잠재 공간(latent space)에 매핑하여 학습한 멀티모달 인공지능 모델 (multi-modal artificial intelligence model)을 기반으로 사용자가 텍스트를 입력하는 경우, 텍스트에 해당하 는 객체 정보를 검출할 수 있는 RIS(Referring Image Segmentation) 기술이 연구되고 있다. RIS 기술의 경우 사용자의 입력 정보와 관련된 영상의 특징 정보를 영상 분할(image segmentation) 과정에 활용함으로써 사전에 학습되지 않은 객체 정보를 검출할 수 있다는 장점이 있다. 다만, RIS의 경우 객체 검출 성능이 사용자가 입력 하는 정보의 구체적인 정도에 의존한다. 따라서, 사용자는 영상에서 객체를 검출하기 위해 동일한 내용을 반복 적으로 입력해야 하는 제한이 있다."}
{"patent_id": "10-2023-0140559", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2023-0140559", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 목적은 상대적으로 단순한 입력만으로 영상 객체 정보의 검출 성능을 증가시킬 수 있는 개인화 영상 분할 장치 및 그 방법을 제공하는 데 그 목적이 있다."}
{"patent_id": "10-2023-0140559", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 목적을 달성하기 위해 본 개시의 일 실시예에 따른 개인화 영상 분할 장치는, 제1 외부 장치로부 터 수신한 제1 포맷의 사용자 입력에 기초하여 제2 포맷의 입력 정보를 출력하는 사용자 입력 수집기, 제2 외부 장치로부터 수신한 센싱 정보에 기초하여 상황 정보를 출력하는 센싱 정보 분석기, 입력 정보, 및 상황 정보에 기초하여 개인화된 의미 정보를 분석하고, 개인화된 의미 정보에 기초하여 개인화된 사용자 입력 정보를 출력하 는 사용자 의미 정보 생성기, 영상 데이터 및 텍스트 정보 각각을 인코딩하여 영상 데이터에 대응하는 특징 정 보를 생성하는 멀티모달 인공지능 모델, 및 특징 정보 및 개인화된 사용자 입력 정보에 기초하여 영상 데이터 상에서 사용자 입력에 대응하는 객체를 검출하는 영상-입력 디코더를 포함할 수 있다. 본 개시의 일 목적을 달성하기 위해 본 개시의 실시 예에 따른 개인화 이미지 분할 방법은, 제1 포맷의 사용자 입력을 수신하였는지 판단하고, 사용자 입력에 기초하여 제2 포맷의 입력 정보를 생성하고, 사용자 입력에 대응 하여, 영상 데이터를 수집하고, 사용자 입력에 대응하여, 수집한 센싱 정보의 분석에 기초하여 상황 정보를 생 성하고, 개인화된 의미 정보, 입력 정보, 및 상황 정보에 기초하여 개인화된 사용자 입력 정보를 생성하고, 영 상 데이터에 대응하는 특징 정보를 생성하고, 특징 정보 및 개인화된 사용자 입력 정보에 기초하여 영상 데이터 상에서 사용자 입력에 대응하는 객체를 검출한다."}
{"patent_id": "10-2023-0140559", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시 예들에 따른 개인화 영상 분할 장치는 사용자 입력을 상황 정보 및 개인화된 의미 정보에 기초 하여 개인화된 사용자 입력 정보로 변환함으로써, 상대적으로 단순한 사용자 입력을 개인화된 사용자 입력 정보 로 구체화할 수 있다. 개인화 영상 분할 장치는 개인화된 사용자 입력 정보를 사용하여 영상 데이터 상의 객체 를 검출함으로써, 상대적으로 단순한 입력만으로 영상 분할 시 객체 검출 성능을 증가시킬 수 있다."}
{"patent_id": "10-2023-0140559", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는, 본 개시의 기술 분야에서 통상의 지식을 가진 자가 본 개시를 쉽게 실시할 수 있을 정도로, 본 개 시의 실시예들이 명확하고 상세하게 기재될 것이다. 도 1은 본 개시의 실시 예에 따른 개인화 영상 분할 장치를 나타내는 블록도다. 도 1을 참조하면, 개인화 영상 분할 장치는 멀티모달 인공지능 모델, 사용자 입력 정보 수집기, 센싱 정보 분석기, 사용자 의미 정보 생성기 및 영상-입력 정보 디코더를 포함할 수 있다. 멀티모달 인공지능 모델은 영상 데이터 또는 텍스트 데이터 등 상이한 모달리티 데이터를 통합한 인공지능 모델이다. 멀티모달 인공지능 모델은 다양한 모달리티 데이터를 원본 데이터의 중요한 특징이 압축되어 표 현되는 공간인 잠재 공간(latent space)에 매핑하여 사전에 학습될 수 있다. 즉, 멀티모달 인공지능 모델 의 사전 학습에서 다양한 모달리티 데이터가 동일한 잠재 공간에 매핑될 수 있다. 멀티모달 인공지능 모델(11 0)은 CLIP(Contrastive Language-Image Pre-training), DALL·E GLIDE(Guided Language Diffusion for Generation and Editing) 등과 같이 텍스트, 영상 등 상이한 모달리티 데이터를 통합한 인공지능 모델을 포함할 수 있다. 멀티모달 인공지능 모델에 영상 데이터가 입력되면, 멀티모달 인공지능 모델은 영상 데이터에 대한 특징 정보를 생성한다. 예를 들어, 멀티모달 인공지능 모델은 수집된 영상 데이터와 텍스트 데이 터 각각을 인코딩하여 단일 모달리티에서 특징을 추출할 수 있다. 일 실시 예에서, 멀티모달 인공지능 모델 은 영상 데이터와 텍스트 데이터에 관한 정보를 특징 공간(feature space)으로 매핑할 수 있다. 텍스트 데 이터에 관한 정보는 적어도 하나 이상의 단어(word)를 포함할 수 있다. 일 예로, 텍스트 데이터에 관한 정보는 구((phrase) 내지 문장(sentence)에 관한 정보에 해당할 수 있다. 이 경우, 멀티모달 인공지능 모델은 구 내지 문장에 관한 정보를 특징 공간(feature space)으로 매핑할 수 있다. 구 내지 문장에 관한 정보는 텍스트 데이터를 구성하는 각각의 단어에 대응하는 단어 정보 또는 복수의 단어들을 통해 구성되는 문장 정보를 포함할 수 있다. 사용자 입력 정보 수집기는 적어도 하나의 외부 장치(예를 들어, 사용자 인터페이스 장치)로부터 수신한 제1 포맷의 사용자 입력에 기초하여 제2 포맷의 입력 정보를 출력할 수 있다. 이때, 사용자 입력 정보 수집기 는 제1 포맷의 사용자 입력을 제2 포맷으로의 변환을 통하여 제2 포맷의 입력 정보를 생성할 수 있다. 일 예로, 사용자 입력 정보 수집기는 포맷 변환기를 포함할 수 있다. 예를 들어, 사용자 입력 정보 수집기 는 음성 포맷을 텍스트 포맷으로 변환하는 음성-텍스트 변환기를 포함할 수 있다. 이때, 제1 포맷은 음성 포맷을 포함할 수 있고, 제2 포맷은 텍스트 포맷을 포함할 수 있다. 음성-텍스트 변환기는 STT(speech-to-text) 변환 동작을 수행할 수 있다. 음성-텍스트 변환기는 STT(speech-to-text) 변환 동작을 수행하기 위한 음성 인식 모델을 포함할 수 있다. 즉, 사용자 입력 정보 수집기는 사용자 인터페이스 장치를 통해 음성 입력을 수신 하면, 음성-텍스트 변환기를 통해 음성 포맷의 사용자 입력에 대응하는 텍스트 포맷의 입력 정보를 생성할 수 있다. 사용자 인터페이스 장치는 사용자의 음성 입력을 위한 마이크 등의 음성 수신 장치를 포함할 수 있다. 사용자 입력 정보 수집기는 필기 입력을 텍스트 포맷으로 변환하는 필기-텍스트 변환기를 포함할 수 있다. 이때, 제1 포맷은 이미지 포맷을 포함할 수 있고, 제2 포맷은 텍스트 포맷을 포함할 수 있다. 사용자 인터페이 스 장치는 사용자의 필기 입력을 위한 터치 스크린을 포함할 수 있다. 필기-텍스트 변환기는 문자 인식(text recognition) 동작을 수행할 수 있다. 필기-텍스트 변환기는 필기 인식 모델을 포함할 수 있다. 즉, 사용자 입 력 정보 수집기는 사용자 인터페이스 장치를 통해 필기된 이미지 입력을 수신하면, 필기-텍스트 변환기를 통해 이미지 포맷의 사용자 입력에 대응하는 텍스트 포맷의 입력 정보를 생성할 수 있다. 사용자 인터페이스 장 치는 사용자의 필기 입력을 위한 터치 스크린 등의 입력 장치를 포함할 수 있다. 한편, 제1 포맷은 사용자의 필 기 입력에 대한 벡터 궤적을 포함하는 벡터 포맷을 포함할 수도 있다. 필기-텍스트 변환기는 벡터 포맷의 사용 자 입력에 대응하는 텍스트 포맷의 입력 정보를 생성할 수도 있다. 한편, 제1 포맷은 제2 포맷과 동일한 포맷일 수 있다. 사용자 입력 정보 수집기는 제1 포맷과 제2 포맷 각 각이 텍스트 포맷인 경우, 사용자 입력을 별도로 변환하지 않고, 출력할 수도 있다. 예를 들어, 사용자가 사용 자 인터페이스 장치를 통해 직접 텍스트 정보를 입력하는 경우, 별도의 포맷 변환 없이 사용자 입력을 그대로 입력 정보로 출력할 수 있다. 센싱 정보 분석기는 적어도 하나의 외부 장치(예를 들어, 센서 장치)로부터 수신한 센싱 정보에 기초하여 상황 정보를 출력할 수 있다. 센서 장치는 관성 측정 장치(IMUs; Inertial Measurement Units), GNSS(Global Navigation Satellite System) 수신기 등을 포함할 수 있다. 관성 측정 장치는 가속도 센서(acceleration sensor), 자이로스코프(Gyroscope), 자기 센서(magnetometer) 등 을 포함할 수 있다. 관성 측정 장치는 각종 센서들을 통해 수집된 관성 정보를 센싱 정보 분석기로 전송할 수 있다. GNSS 수신기는 인공 위성 등의 복수의 GNSS 신호 발생 장치로부터 GNSS 신호를 수신할 수 있고, GNSS 신호를 분 석하여 GNSS 위치 정보를 생성할 수 있다. GNSS 위치 정보는 GNSS 수신기의 현재 위치에 관한 정보를 포함할 수 있다. GNSS 수신기는 GPS(Global Positioning System), GLONASS, Beidou, Galileo, IRNSS, QZSS 등의 위성 항법 시스 템 중 적어도 하나의 시스템을 이용하여 위치 정보를 생성할 수 있다. 센서 장치는 관성 측정 장치 및 GNSS 수신기에 더하여 기압 센서, 온도 센서, 조도 센서, 근접 센서, 터치 센서 등 다양한 센서를 포함할 수도 있다. 센싱 정보 분석기는 상황 정보를 생성할 때, 센서 장치로부터 수신한 다양한 센싱 정보를 이용할 수 있다. 센싱 정보는 관성 정보, 위치 정보, 기압 정보, 조도 정보, 근접 정보, 터 치 정보 등 다양한 정보 중 적어도 하나를 포함할 수 있다. 센싱 정보 분석기는 외부 장치로부터 수신한 센싱 정보를 분석할 수 있다. 센싱 정보 분석기는 수신 한 센싱 정보를 분석하기 위해 기계 학습 알고리즘 또는 딥 러닝 모델 등을 사용할 수 있다. 센싱 정보 분석기 는 센싱 정보를 분석하여 생성된 상황 정보를 생성할 수 있다. 상황 정보는 사용자의 현재 행동, 위치, 상 태 등을 나타낼 수 있다. 사용자 의미 정보 생성기는 개인화된 의미 정보, 입력 정보, 및 상황 정보에 기초하여 개인화된 사용자 입 력 정보를 생성할 수 있다. 입력 정보는 사용자 입력 정보 수집기를 통해 제2 포맷으로 변환된 사용자 입력이다. 상황 정보는 센싱 정 보 분석기를 통해 생성된 사용자의 현재 행동, 위치, 상태 등에 관한 정보이다. 개인화된 의미 정보는 사용자의 고유한 특징에 관한 정보이다. 예를 들어, 사용자가 소유한 물건에 대한 정보, 사용자가 자주 방문하는 공간에 대한 정보, 사용자의 취향에 관한 정보 등을 포함할 수 있다. 개인화된 사용자 입력 정보는 입력 정보를 기반으로 개인화된 의미 정보를 분석하여, 사용자 입력을 더 구체화 한 것이다. 사용자 의미 정보 생성기는 입력 정보를 개인화된 사용자 입력 정보로 구체화할 때, 앞서 설명 한 바와 같이 센싱 정보 분석기로부터 수신한 상황 정보를 이용할 수 있다. 이를 통해 현재 사용자의 상황 을 반영한 개인화된 사용자 입력 정보를 생성할 수 있다. 영상-입력 정보 디코더는 멀티모달 인공지능 모델이 생성한 영상 데이터에 관한 특징 정보 및 사용자 의미 정보 생성기가 생성한 개인화된 사용자 입력 정보에 기초하여 영상 데이터 상에서 사용자 입력에 대 응하는 객체를 검출할 수 있다. 영상-입력 정보 디코더는 사용자 입력에 대응하는 객체를 검출하기 위하여 특징 공간에서의 영상 데이터, 구 내지 문장을 포함하는 텍스트의 단어 정보, 문장 정보를 활용할 수 있다. 이 를 통해, 영상-입력 정보 디코더는 영상 데이터 상에서 사용자가 의도한 객체 영역을 검출할 수 있다. RIS(Referring Image Segmentation) 기술은 영상 데이터 및 텍스트 데이터를 동일한 잠재공간에 매핑하여 학습 한 멀티모달 인공지능 모델을 사용한다. RIS 기술은 사용자가 입력한 텍스트 데이터와 영상 데이터를 각각 인코딩한 후, 사용자가 입력한 객체 영역을 검출한다. 이때, 정확한 객체 검출을 위해서는 상대적으로 구체적이 고 복잡한 라벨 정보를 텍스트 형태로 입력할 것이 요구된다. 또한, 사용자가 자주 검색하는 객체 또는 사용자 에게 종속된 객체들도 동일한 사용자 입력을 반복적으로 입력할 것이 요구된다. 본 개시의 실시 예에 따른 개인화 영상 분할 장치는 상대적으로 단순한 사용자의 입력을 사용자가 놓인 상 황과 상용자의 개인화된 의미 정보에 기초하여 구체적인 정보를 생성할 수 있다. 개인화 영상 분할 장치는 사용자 입력으로부터 구체화된 개인화된 사용자 입력 정보를 통해 RIS 적용 시, 상대적으로 단순한 사용자 입력 이 제공되더라도 사용자의 의도에 부합하는 객체를 검출할 수 있고, 객체 검출 성능을 증가시킬 수 있다. 도 2는 도 1의 사용자 의미 정보 생성기가 생성하는 개인화된 사용자 의미 정보의 일 예를 설명하기 위한 도면 이다. 도 2를 참조하면, 사용자 의미 정보 생성기는 개인화된 의미 정보, 상기 입력 정보, 및 상기 상황 정보에 기초 하여 개인화된 사용자 입력 정보를 생성할 수 있다. 사용자가 사용자 인터페이스 장치에 “My computer”라고 발화하면, 사용자 인터페이스 장치는 음성 정보 “My computer”를 생성할 수 있다. 제1 포맷(예를 들어, 음성 포맷)의 음성 정보 “My computer”는 사용자 입력 정 보 수집기로 전달된다. 사용자 입력 정보 수집기는 음성 정보 “My computer”를 제2 포맷의 텍스트 정보 “computer”로 변환할 수 있다. 한편, 사용자가 사용자 인터페이스 장치를 통해 “My computer”를 필기하면, 사용자 인터페이스 장치는 필기 정보 “My computer”를 생성할 수 있다. 제1 포맷(예를 들어, 이미지 포맷)의 필기 정보 “My computer”가 사 용자 입력 정보 수집기로 전달될 수도 있다. 사용자 입력 정보 수집기는 이미지 포맷의 필기 정보 “ My computer”를 제2 포맷의 텍스트 정보 “My computer”로 변환할 수 있다. 사용자 입력 정보 수집기는 텍스트 정보 “My computer”를 사용자 의미 정보 생성기로 출력할 수 있다. 센싱 정보 분석기는 사용자 입력에 대응하여 센서 장치로부터 위치 정보를 수신할 수 있다. 센싱 정보 분 석기는 수신한 위치 정보에 기초하여 사용자의 현재 공간적인 정보를 식별할 수 있다. 예를 들어, 센싱 정 보 분석기는 수신한 위치 정보에 기초하여 사용자의 현재 위치가 “Office”에 해당하는 것을 식별할 수 있다. 센싱 정보 분석기는 사용자의 현재 위치를 포함하는 상황 정보를 생성할 수 있다. 예를 들어, 센싱 정보 분석기는 사용자의 현재 위치에 해당하는 상황 정보 “Office”를 생성할 수 있다. 사용자 의미 정보 생성기는 제2 포맷으로 변환된 텍스트 정보 ”My computer”및 센싱 정보 분석기를 통해 생성된 공간적인 상황 정보 “Office”에 기초하여 개인화된 의미 정보를 분석할 수 있다. 예를 들어, 사 용자 의미 정보 생성기는 개인화된 의미 정보의 분석을 통해 텍스트 정보 “computer”에 대응하는 컴퓨터 정보 “Blue laptop” 및 컴퓨터의 위치 정보”White desk”를 수집할 수 있다. 사용자 의미 정보 생성기 는 수집되거나 생성된 각종 정보에 기초하여 상용자 입력을 구체화하는 개인화된 사용자 입력 정보를 생성할 수 있다. 개인화된 사용자 입력 정보는 텍스트 데이터로서, 복수의 단어들의 집합인 구 내지 문장을 포함할 수 있 다. 예를 들어, 사용자 의미 정보 생성기는 텍스트 정보 \"My computer\"상황 정보 \"Office\"컴퓨터 정보 \"laptop\" 및 컴퓨터 위치 정보 \"desk\"에 기초하여 단어 집합인 구 \"Blue laptop on the white desk in the office\"를 포함하는 개인화된 사용자 입력 정보를 생성할 수 있다. 즉, 사용자 의미 정보 생성기는 사용자가 입력한 음성 정보 \"My computer\"에 대응하는 구 \"Blue laptop on the white desk in the office\"를 생성함으로써 상대적으로 단순한 입력을 상대적으로 구체적인 단어 집합으 로 변환할 수 있다. 사용자가 음성을 통해 \"My computer\"를 입력하는 경우, 개인화된 사용자 입력 정보 없이 영상 분할이 수행된다 면, 영상 데이터 상에 존재하는 컴퓨터에 해당하는 객체 모두를 검출하게 되는 결과가 도출될 수 있다. 영상 데 이터 상에 복수의 컴퓨터들이 존재하는 경우, 사용자가 의도한 객체를 정확하게 검출할 수 없다는 제한이 있다. 또한, 개인화된 사용자 입력 정보 없이 영상 분할이 수행된다면, 사용자는 의도한 객체를 검출하기 위해 상대적 으로 구체적인 정보를 제공하야 하므로, 입력 정보가 복잡하게 된다는 제한이 있다. 한편, 본 개시의 실시 예에 따른 개인화된 영상 분할 장치를 사용하면, 사용자가 상대적으로 간단한 정보를 입 력하더라도, 사용자의 개인화 의미 데이터를 이용하여 영상 데이터 상에서 사용자의 의도에 부합하는 객체를 검 출할 수 있다. 도 3은 도 1의 사용자 의미 정보 생성기를 설명하기 위한 블록도다. 도 3을 참조하면, 사용자 의미 정보 생성기는 개인화 의미 모델, 개인화 의미 모델 관리기, 및 개인화 의미 생성기를 포함할 수 있다. 개인화 의미 모델은 개인화된 의미 정보를 저장할 수 있다. 구체적으로, 개인화 의미 모델은 사용자 와 관련된 정보를 체계적으로 구성한 모델이다. 개인화 의미 모델은 사용자가 소유한 물건에 대한 특징 정 보, 사용자가 높은 빈도로 방문하는 공간에 관한 정보, 또는 사용자의 취향에 관한 정보 등 사용자에 관련된 각 종 정보에 해당하는 개인화된 의미 정보를 저장할 수 있다. 개인화 의미 모델은 개인화된 의미 정보를 저 장하기 위한 저장 장치를 포함할 수 있다. 개인화 의미 모델 관리기는 개인화 의미 모델을 업데이트할 수 있다. 구체적으로, 개인화 의미 모델 관리기는 사용자에 관련된 각종 정보를 생성할 수 있다. 개인화 의미 모델 관리기는 생성된 각종 정 보에 기초하여 개인화 의미 모델을 업데이트할 수 있다. 개인화 의미 생성기는 개인화된 의미 정보, 입력 정보 및 상황 정보에 기초하여 개인화된 사용자 입력 정 보를 생성할 수 있다. 개인화 의미 생성기는 개인화 의미 모델에 저장된 개인화된 의미 정보, 사용자 입력 정보 수집기로부터 수신한 입력 정보, 센싱 정보 분석기로부터 수신한 상황 정보를 분석할 수 있다. 개인화 의미 생성기는 분석에 기초하여 개인화된 사용자 입력 정보를 생성할 수 있다. 사용자 입력 정보 수집기는 제1 포맷의 음성 정보 \"My computer\"를 수신하여 제2 포맷의 입력 정보 \"My computer\"로 변환할 수 있다. 사용자 입력 정보 수집기는 입력 정보 \"My computer\"를 출력할 수 있다. 센 싱 정보 분석기는 GPS 신호 수신기로부터 위치 정보를 수신할 수 있고, 위치 정보를 분석하여 상황 정보 \"Office\"를 생성할 수 있다. 센싱 정보 분석기는 상황 정보 \"Office\"를 출력할 수 있다. 사용자 의미 정보 생성기는 사용자 입력에 해당하는 음성 정보 \"My computer\"에 대응하여 입력 정보 \"My computer\"및 상황 정보 \"Office\"를 수신할 수 있다. 개인화 의미 생성기는 개인화 의미 모델에 입력 정보 \"My computer\"및 상황 정보 \"Office\"를 개인화 의미 모델에 저장된 개인화된 의미 정보에 기초하여 분석할 수 있다. 개인화 의미 생성기는 입력 정보 \"My computer\", 상황 정보 \"Office\"및 개인화 의미 모델에 저장된 개인화된 의미 정보에 기초하여 컴퓨터 정보 \"Blue laptop\"및 컴퓨터의 위치 정보 \"White desk\"를 구성 할 수 있다. 개인화 의미 생성기는 사용자의 음성 입력 \"My computer\"를 구체화하는 구 \"blue laptop on a white desk in the office\"를 생성할 수 있다. 즉, 사용자 의미 정보 생성기는 개인화 의미 모델, 개인화 의미 모델 관리기, 및 개인화 의미 생성기를 통해 사용자 입력 정보 수집기로부터 수신한 입력 정보 및 센싱 정보 분석기로부터 수 신한 상황 정보에 기초하여 개인화된 사용자 입력 정보를 출력할 수 있다. 한편, 개인화 의미 모델 관리기는 사용자의 피드백에 기초하여 개인화 의미 모델을 업데이트할 수 있 다. 예를 들어, 개인화 의미 모델 관리기는 현재 입력 정보와 이전 입력 정보 사이의 유사도를 결정할 수 있다. 개인화 의미 모델 관리기는 현재 입력 정보와 이전 입력 정보 사이의 유사도가 미리 설정된 임계보 다 클 때, 현재 입력 정보에 기초하여 개인화된 의미 정보를 업데이트할 수 있다. 개인화 의미 모델 관리기는 유사도가 미리 설정된 임계와 같거나 작을 때, 현재 입력 정보에 기초한 개인 화된 의미 정보를 생성할 수 있다. 개인화 의미 모델 관리기는 새롭게 생성된 개인화된 의미 정보를 개인 화 의미 모델에 저장할 수 있다. 개인화 의미 모델 관리기가 현재 입력 정보와 이전 입력 정보 사이의 유사도를 결정할 때, 유사도는 현재 입력 정보와 이전 입력 정보 사이의 단어 유사도(word similarity) 및 문맥 유사도(contextual similarity)에 기초하여 결정될 수 있다. 단어 유사도는 현재 입력 정보의 구 내지 문장에 포함된 단어들과 이전 입력 정보의 구 내지 문장에 포함된 개 별 단어의 유사도를 나타낸다. 일 예로, 단어 유사도를 산출하기 위해서 단어를 고차원 벡터로 매핑하는 기술인 단어 임베딩(word embeddings) 방법이 사용될 수 있다. 다른 예로, 코사인 유사도(cosine similarity) 또는 자 카드 유사도(Jaccard similarity)와 같은 유사도 메트릭(similarity metric)을 사용하여 현재 입력 정보와 이 전 입력 정보 사이의 단어 유사도를 산출할 수 있다. 문맥 유사도는 단어가 사용된 문맥을 고려하여 둘 이상의 텍스트의 유사한 정도를 평가하는 것이다. 현재 입력 정보와 이전 입력 정보를 비교할 때 벡터 공간 모델(vector space model)을 사용하여 단어 벡터를 조합하여 구 내지 문장의 벡터를 생성하고, 이를 통해 문맥 유사도를 정량화할 수 있다. 개인화 의미 모델 관리기는 현재 입력 정보와 이전 입력 정보 사이의 유사도를 결정하기 위해 미리 학습된 기계 학습 모델 또는 딥러닝 모델을 사용할 수 있다. 현재 입력 정보와 이전 입력 정보 사이의 유사도가 미리 설정된 임계보다 클 때, 현재 입력 정보는 이전 입력 정보를 구체화하는 사용자의 피드백으로 판단될 수 있다. 따라서, 현재 입력 정보에 기초하여 개인화 의미 모델 에 저장된 개인화된 의미 정보를 업데이트할 수 있다. 현재 입력 정보와 이전 입력 정보 사이의 유사도가 미리 설정된 임계와 같거나 작을 때, 현재 입력 정보는 새로운 사용자 입력으로 판단될 수 있다. 따라서, 현재 입력 정보에 기초하여 새롭게 생성된 개인화된 의미 정보를 개인화 의미 모델에 저장할 수 있다. 개인화 의미 모델 관리기는 현재 입력 정보와 이전 입력 정보를 비교하여 현재 입력 정보와 이전 입력 정 보 사이의 유사도를 결정함으로써 입력 정보로 전달되는 사용자의 피드백을 개인화 의미 모델에 반영할 수 있다. 한편, 개인화 의미 모델 관리기는 미리 설정된 주기마다 사용자 프로파일링을 수행할 수 있다. 개인화 의 미 모델 관리기는 사용자 프로파일링에 기초하여 개인화된 의미 정보를 업데이트할 수 있다. 사용자 프로파일링은, 사용자 데이터를 활용해 사용자의 행동 특성을 분석하고, 행동을 예측할 수 있도록 정보 를 다양하게 가공 및 분류하는 동작이다. 개인화 의미 모델 관리기는 프로파일링 동작을 주기적으로 수행 하여 사용자에 관한 정보에 해당하는 개인화된 의미 정보를 생성할 수 있고, 생성된 개인화된 의미 정보를 개인 화 의미 모델에 저장할 수 있다. 예를 들어, 개인화 의미 모델 관리기는 사용자 프로파일링을 수행하여, 사용자 입력에 해당하는 입력 정보 \"My computer\"및 상황 정보 \"Office\"에 대응하는 개인화된 의미 정보인 컴퓨터 정보 \"Blue laptop\"을 개인화 의미 모델에 저장할 수 있다. 개인화 의미 모델 관리기는 사용자 프로파일링을 수행하여 개인화된 의 미 정보인 컴퓨터의 위치 정보 \"White desk\"를 개인화 의미 모델에 저장할 수 있다. 앞서 설명한 바와 같 이, 개인화 의미 생성기는 사용자 입력을 구체화할 때, 사용자 프로파일링의 수행을 통해 개인화 의미 모 델에 저장된 컴퓨터 정보 \"Blue laptop\"및 컴퓨터 위치 정보 \"White desk\"를 사용할 수 있다. 도 4는 본 개시의 실시 예에 따른 개인화 영상 분할 방법을 나타내는 흐름도다. 도 4를 참조하면, 본 개시의 실시 예에 따른 개인화 영상 분할 방법은, 제1 포맷의 사용자 입력을 수신하였는지 판단할 수 있다(S110). S110 단계는 사용자 입력 정보 수집기에 의해 수행될 수 있다. 제1 포맷의 사용자 입력을 수신하지 않았다고 판단되는 경우(S110-아니오), 개인화 영상 분할 방법은, 사용자 입력을 수신하기 위 해 대기할 수 있다. 수신된 제1 포맷의 사용자 입력은 제2 포맷으로 변환될 수 있고, 변환 결과로 제2 포맷의 입력 정보가 생성될 수 있다. 일 예로, 제1 포맷은 음성 포맷을 포함할 수 있고, 제2 포맷은 텍스트 포맷을 포함할 있다. 이때, 음성 포맷의 음성 입력은 텍스트 포맷의 입력 정보로 변환될 수 있다. 다른 예로, 제2 포맷은 이미지 포맷을 포함할 수 있다. 이때, 이미지 포맷의 필기 입력은 텍스트 포맷의 입력 정보로 변환될 수 있다. 제1 포맷의 사용자 입력을 수신하였다고 판단되는 경우(S110-예), 개인화 영상 분할 방법은, 사용자 입력에 대 응하여 영상 데이터를 수집할 수 있다(S120). S120 단계는 멀티모달 인공지능 모델에 의해 수행될 수 있다. 개인화 영상 분할 방법은, 사용자의 입력에 대응하여 센싱 정보를 수집하고, 수집한 센싱 정보를 분석할 수 있 다(S130). S130 단계는 센싱 정보 분석기에 의해 수행될 수 있다. 센싱 정보의 분석에 기초하여 상황 정보 가 생성될 수 있다. 상황 정보는 사용자의 현재 행동, 위치 또는 상태 등을 나타낼 수 있다. 한편, 센싱 정보는 위치 정보 및 관성 정보 중 적어도 하나를 포함할 수 있다. 개인화 영상 분할 방법은, 개인화된 의미 정보, 입력 정보 및 상황 정보에 기초하여 개인화된 사용자 입력 정보 를 생성할 수 있다(S140). S140 단계는 개인화 의미 정보 생성기에 의해 수행될 수 있다. 개인화 영상 분할 방법은, 수집한 영상 데이터 및 개인화된 입력 정보를 인코딩하여 단일 모달리티에서 특징을 추출할 수 있다(S150). 이를 통해, 개인화 영상 분할 방법은 영상 데이터에 대응하는 특징 정보를 생성할 수 있 다. 개인화 영상 분할 방법은, 영상-입력 매핑 정보를 생성할 수 있다(S160). 개인화 영상 분할 방법은, 추출된 특 징을 융합할 수 있고, 사용자 입력에 해당하는 영상 데이터를 분할할 수 있다. 즉, 특징 정보 및 개인화된 사용 자 입력 정보에 기초하여 영상 데이터 상에서 사용자 입력에 대응하는 객체를 검출할 수 있다. 개인화 영상 분할 방법은, 검출 정보를 전달할 수 있다.(S170). 검출 정보는 분할된 객체에 대한 거리, 위치, 형태 등의 정보를 포함할 수 있다. 개인화 영상 분할 방법은, 영상 데이터 상에서 분할된 객체에 대한 거리, 위 치, 형태 등의 정보를 청각, 촉각, 시각 등의 다양한 감각 정보로 변환하고, 감각 정보의 형태로 변환된 검출 정보를 개인화 영상 분할 장치 외부의 표시 장치로 전달할 수 있다. 표시 장치는 수신한 감각 정보에 기초하여 영상 데이터 상에서 분할된 객체를 각종 방식으로 표시할 수 있다. 예를 들어, 청각, 촉각, 또는 시각적인 방법 을 통해 영상 데이터 상에서 분할된 객체를 표시할 수 있다. 도 5는 도 3의 개인화 의미 모델의 업데이트를 설명하기 위한 흐름도이다. 도 5를 참조하면, 개인화 의미 모델의 업데이트를 위해, 개인화 영상 분할 방법은 사용자 입력을 수신하였 는지 판단할 수 있다(S210). 사용자 입력을 수신하지 않았다고 판단되는 경우(S210-아니오), 개인화 영상 분할 방법은, 사용자 입력을 수신하기 위해 대기할 수 있다. S210 단계는 도 4의 S110 단계에 대응할 수 있다. 사용자 입력을 수신하였다고 판단된 경우(S210-예), 개인화 영상 분할 방법은, 현재 사용자 입력과 이전 사용자 입력의 유사도를 결정할 수 있다(S220). 이때, 현재 사용자 입력에 대응하는 현재 입력 정보와 이전 사용자 입 력에 대응하는 이전 입력 정보를 비교하여 현재 입력 정보와 이전 입력 정보 사이의 유사도를 결정할 수 있다. S220 단계는 개인화 의미 모델 관리기에 의해 수행될 수 있다. 이때, 현재 입력 정보와 이전 입력 정보 사이의 유사도는 단어 유사도 및 문맥 유사도에 기초하여 결정될 수 있 다. 개인화 영상 분할 방법은, 유사도가 미리 설정된 임계보다 큰지 판단할 수 있다(S230). S230 단계는 개인화 의 미 모델 관리기에 의해 수행될 수 있다. 유사도가 미리 설정된 임계보다 클 때(S230-예), 개인화 영상 분할 방법은, 현재 입력 정보에 기초하여 개인화 된 의미 정보를 업데이트할 수 있다(S240). 즉, 개인화 영상 분할 방법은 현재 입력 정보와 이전 입력 정보 사 이의 유사도에 기초하여 개인화 의미 모델에 저장된 개인화 의미 정보를 업데이트할 수 있다. S240 단계는 개인 화 의미 모델 관리기에 의해 수행될 수 있다.유사도가 미리 설정된 임계와 같거나 작을 때(S230-아니오), 개인화 영상 분할 방법은, 개인화된 의미 정보를 업데이트하지 않을 수 있다. 한편, 개인화 영상 분할 방법은, 현재 입력 정보에 기초한 개인화된 의미 정보를 생성할 수 있고, 새롭게 생성된 개인화된 의미 정보는 개인화 의미 모델에 저장될 수 있다. 한편, 개인화 영상 분할 방법은, 미리 설정된 주기마다 사용자 프로파일링을 수행할 수 있다. 개인화 영상 분할 방법은, 사용자 프로파일링에 기초하여 개인화된 의미 정보를 업데이트할 수 있다. 이상 설명한 바와 같이, 본 개시의 실시 예들에 따른 개인화 영상 분할 장치는 사용자 입력을 상황 정보 및 개 인화된 의미 정보에 기초하여 개인화된 사용자 입력 정보로 변환함으로써, 상대적으로 단순한 사용자 입력을 개 인화된 사용자 입력 정보로 구체화할 수 있다. 개인화 영상 분할 장치는 개인화된 사용자 입력 정보를 사용하여 영상 데이터 상의 객체를 검출함으로써, 상대적으로 단순한 입력만으로 영상 분할의 객체를 검출하는 성능을 증 가시킬 수 있다. 상술된 내용은 본 개시를 실시하기 위한 구체적인 실시 예들이다. 본 개시는 상술된 실시 예들뿐만 아니라, 단 순하게 설계 변경되거나 용이하게 변경할 수 있는 실시 예들 또한 포함할 것이다. 또한, 본 개시는 실시 예들을 이용하여 용이하게 변형하여 실시할 수 있는 기술들도 포함될 것이다. 따라서, 본 개시의 범위는 상술된 실시 예들에 국한되어 정해져서는 안 되며 후술하는 특허 청구범위뿐만 아니라 본 개시의 특허청구범위와 균등한 것 들에 의해 정해져야 할 것이다."}
{"patent_id": "10-2023-0140559", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시 예에 따른 개인화 영상 분할 장치를 나타내는 블록도다. 도 2는 도 1의 사용자 의미 정보 생성기가 생성하는 개인화된 사용자 의미 정보의 일 예를 설명하기 위한 도면 이다. 도 3은 도 1의 사용자 의미 정보 생성기를 설명하기 위한 블록도다. 도 4는 본 개시의 실시 예에 따른 개인화 영상 분할 방법을 나타내는 흐름도다. 도 5는 도 3의 개인화 의미 모델의 업데이트를 설명하기 위한 흐름도이다."}
