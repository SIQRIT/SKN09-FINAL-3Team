{"patent_id": "10-2020-0122785", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0040054", "출원번호": "10-2020-0122785", "발명의 명칭": "전자장치 및 그 제어방법", "출원인": "삼성전자주식회사", "발명자": "김태환"}}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서, 비디오프레임을 출력하는 비디오처리부;그래픽프레임을 출력하는 그래픽처리부;믹서; 및상기 비디오프레임 및 상기 그래픽프레임에 기초한 제1합성프레임을 생성하여 출력하도록 상기 믹서를제어하고,영상 효과 처리의 이벤트에 대응하여, 표시되는 영상 내 상기 비디오프레임에 대응하는 비디오영역 및 상기 그래픽프레임에 대응하는 그래픽영역을 포함하며, 상기 비디오영역 및 상기 그래픽영역에 상기 영상 효과 처리가수행된 제2합성프레임을 생성하고, 상기 제2합성프레임이 상기 믹서를 통해 출력되도록 제어하는 프로세서를 포함하는 전자장치."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 프로세서는, 상기 그래픽프레임 또는 상기 제1합성프레임 중 적어도 하나를 버퍼메모리에 저장하고, 상기저장된 그래픽프레임 또는 제1합성프레임에 다음 순서의 비디오프레임을 합성하고, 상기 영상 효과 처리를 수행하여 상기 제2합성프레임을 생성하는 전자장치."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는, 상기 비디오프레임에 대응하는 비디오컨텐츠 및 상기 그래픽프레임에 대응하는 메뉴항목을 동시에 표시하는 이벤트에 대응하여 상기 제2합성프레임이 출력되도록 제어하는 전자장치."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는, 상기 메뉴항목의 표시를 종료하는 이벤트에 대응하여 상기 제1합성프레임이 출력되도록 제어하는 전자장치."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 프로세서는, 상기 비디오컨텐츠 및 상기 메뉴항목이 각각 동시에 표시되는 상기 비디오영역 및 상기 그래픽영역 상에 상기 그래픽프레임과 다른 그래픽프레임에 대응하는 제2메뉴항목을 표시하는 이벤트에 대응하여 상기 제2합성프레임이 출력되도록 제어하는 전자장치."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서,상기 프로세서는, 상기 그래픽프레임의 업데이트 이벤트에 대응하여, 새로운 그래픽프레임으로 상기 저장된 그래픽프레임 또는 제1합성프레임이 업데이트되도록 제어하는 전자장치.공개특허 10-2022-0040054-3-청구항 7 전자장치의 제어방법에 있어서, 비디오프레임 및 그래픽프레임에 기초한 제1합성프레임을 생성하여 출력하는 단계;영상 효과 처리의 이벤트에 대응하여, 표시되는 영상 내 상기 비디오프레임에 대응하는 비디오영역 및 상기 그래픽프레임에 대응하는 그래픽영역을 포함하며, 상기 비디오영역 및 상기 그래픽영역에 상기 영상 효과 처리가수행된 제2합성 프레임을 생성하는 단계; 및상기 제2합성프레임을 출력하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 제1합성프레임을 생성하여 출력하는 단계는, 상기 그래픽프레임 또는 상기 제1합성프레임 중 적어도 하나를 저장하는 단계를 포함하고,상기 제2합성 프레임을 생성하는 단계는, 상기 저장된 그래픽프레임 또는 제1합성프레임에 다음 순서의 비디오프레임을 합성하고, 상기 영상 효과 처리를 수행하여 상기 제2합성프레임을 생성하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 제2합성프레임을 출력하는 단계는, 상기 비디오프레임에 대응하는 비디오컨텐츠 및 상기 그래픽프레임에대응하는 메뉴항목을 동시에 표시하는 이벤트에 대응하여 상기 제2합성프레임이 출력하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 메뉴항목의 표시를 종료하는 이벤트에 대응하여 상기 제1합성프레임을 출력하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 비디오컨텐츠 및 상기 메뉴항목이 각각 동시에 표시되는 상기 비디오영역 및 상기 그래픽영역 상에 상기그래픽프레임과 다른 그래픽프레임에 대응하는 제2메뉴항목을 표시하는 이벤트에 대응하여 상기 제2합성프레임을 출력하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,상기 그래픽프레임의 업데이트 이벤트에 대응하여, 새로운 그래픽프레임으로 상기 저장된 그래픽프레임 또는 제1합성프레임을 업데이트하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0122785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된기록매체에 있어서, 상기 전자장치의 제어방법은, 비디오프레임 및 그래픽프레임에 기초한 제1합성프레임을 생성하여 출력하는 단계;영상 효과 처리의 이벤트에 대응하여, 표시되는 영상 내 상기 비디오프레임에 대응하는 비디오영역 및 상기 그래픽프레임에 대응하는 그래픽영역을 포함하며, 상기 비디오영역 및 상기 그래픽영역에 상기 영상 효과 처리가공개특허 10-2022-0040054-4-수행된 제2합성 프레임을 생성하는 단계; 및상기 제2합성프레임을 출력하는 단계를 포함하는 것을 특징으로 하는 컴퓨터가 읽을 수 있는 프로그램이 기록된기록매체."}
{"patent_id": "10-2020-0122785", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 비디오프레임 및 그래픽프레임에 기초한 제1합성프레임을 생성하여 출력하고, 영상 효과 처리의 이벤 트에 대응하여, 표시되는 영상 내 비디오프레임에 대응하는 비디오영역 및 그래픽프레임에 대응하는 그래픽영역 을 포함하며, 비디오영역 및 그래픽영역에 영상 효과 처리가 수행된 제2합성 프레임을 생성하고, 제2합성프레임 을 출력하는 전자장치에 관한 발명이다."}
{"patent_id": "10-2020-0122785", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 전자장치 및 그 제어방법에 관한 것으로서, 상세하게는, 비디오프레임 및 그래픽프레임에 기초하여 합성프레임을 출력하는 전자장치 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2020-0122785", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자장치는 그래픽프레임에 비디오프레임을 합성한 합성프레임을 생성하여 표시할 수 있다. 일 예로, 전자장치 는 그래픽프레임에 대응하는 방송 프로그램 채널 번호 선택을 위한 EPG(Electric Program Guide)를 표시하고, 비디오프레임에 대응하는 선택된 채널의 방송 프로그램을 EPG에 합성한 합성프레임을 생성하여 표시함으로써, 선택된 채널의 방송 프로그램이 EPG와 함께 표시되도록 할 수 있다. 전자장치는 그래픽프레임에 대한 영상 효과 처리의 이벤트가 수신되면, 그래픽프레임에 대한 영상 효과 처리를 수행할 수 있다. 일 예로, 방송 프로그램 채널 번호 선택을 위한 EPG에 대하여 블러(blur) 수행이 필요한 이벤 트가 수신되면, 전자장치는 EPG에 블러를 수행하고, 블러가 수행된 EPG을 출력할 수 있다. 그러나, 그래픽프레임에 대한 영상 효과 처리가, 비디오프레임과의 합성 이전에 수행되는 장치 구성에서는, 그 래픽프레임에 대한 영상 효과 처리만 수행되므로, 비디오프레임에 대해서는 영상 효과 처리가 수행되지 않는다. 사용자는 비디오프레임 및 그래픽프레임 간에 영상 효과 처리가 동일하지 않은 합성프레임에 의해 시각적 불안 정감을 느낄 수 있고, 이러한 시각적 불안감은, 영상 품질을 전반적으로 떨어뜨리는 원인이 된다. 따라서, 비디오프레임과의 합성 이전에 그래픽프레임에 대한 영상 효과 처리가 수행되는 장치 구성에서, 합성프 레임에 대한 영상 효과 처리가 필요한 이벤트에 대응하여, 영상 효과 처리가 동일하게 수행된 비디오프레임 및 그래픽프레임에 기초하여 합성프레임을 출력함으로써, 영상 효과 처리가 수행된 합성프레임에 대한 영상 품질을 향상시킬 수 있는 방안이 요청되고 있다."}
{"patent_id": "10-2020-0122785", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 비디오프레임과의 합성 이전에 그래픽프레임에 대한 영상 효과 처리가 수행되는 장치 구성에 서, 합성프레임에 대한 영상 효과 처리가 필요한 이벤트에 대응하여, 영상 효과 처리가 동일하게 수행된 비디오 프레임 및 그래픽프레임에 기초하여 합성프레임을 출력함으로써, 영상 효과 처리가 수행된 합성프레임에 대한 영상 품질을 향상시킬 수 있는 전자장치 및 그 제어방법을 제공하는 것이다."}
{"patent_id": "10-2020-0122785", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 본 발명의 목적은, 비디오프레임을 출력하는 비디오처리부; 그래픽프레임을 출력하는 그래픽처리부; 믹 서; 및 상기 비디오프레임 및 상기 그래픽프레임에 기초한 제1합성프레임을 생성하여 출력하도록 상기 믹서를 제어하고, 영상 효과 처리의 이벤트에 대응하여, 표시되는 영상 내 상기 비디오프레임에 대응하는 비디오영역 및 상기 그래픽프레임에 대응하는 그래픽영역을 포함하며, 상기 비디오영역 및 상기 그래픽영역에 상기 영상 효 과 처리가 수행된 제2합성프레임을 생성하고, 상기 제2합성프레임이 상기 믹서를 통해 출력되도록 제어하는 프 로세서를 포함하는 전자장치에 의해 달성될 수 있다. 상기 프로세서는, 상기 그래픽프레임 또는 상기 제1합성프레임 중 적어도 하나를 버퍼메모리에 저장하고, 상기 저장된 그래픽프레임 또는 제1합성프레임에 다음 순서의 비디오프레임을 합성하고, 상기 영상 효과 처리를 수행 하여 상기 제2합성프레임을 생성한다. 상기 프로세서는, 상기 비디오프레임에 대응하는 비디오컨텐츠 및 상기 그래픽프레임에 대응하는 메뉴항목을 동 시에 표시하는 이벤트에 대응하여 상기 제2합성프레임이 출력되도록 제어한다. 상기 프로세서는, 상기 메뉴항목의 표시를 종료하는 이벤트에 대응하여 상기 제1합성프레임이 출력되도록 제어 한다. 상기 프로세서는, 상기 비디오컨텐츠 및 상기 메뉴항목이 각각 동시에 표시되는 상기 비디오영역 및 상기 그래 픽영역 상에 상기 그래픽프레임과 다른 그래픽프레임에 대응하는 제2메뉴항목을 표시하는 이벤트에 대응하여 상 기 제2합성프레임이 출력되도록 제어한다. 상기 프로세서는, 상기 그래픽프레임의 업데이트 이벤트에 대응하여, 새로운 그래픽프레임으로 상기 저장된 그 래픽프레임 또는 제1합성프레임이 업데이트되도록 제어한다. 상기한 본 발명의 목적은, 비디오프레임 및 그래픽프레임에 기초한 제1합성프레임을 생성하여 출력하는 단계; 영상 효과 처리의 이벤트에 대응하여, 표시되는 영상 내 상기 비디오프레임에 대응하는 비디오영역 및 상기 그 래픽프레임에 대응하는 그래픽영역을 포함하며, 상기 비디오영역 및 상기 그래픽영역에 상기 영상 효과 처리가 수행된 제2합성 프레임을 생성하는 단계; 및 상기 제2합성프레임을 출력하는 단계를 포함하는 전자장치의 제어 방법에 의해 달성될 수도 있다. 상기 제1합성프레임을 생성하여 출력하는 단계는, 상기 그래픽프레임 또는 상기 제1합성프레임 중 적어도 하나 를 저장하는 단계를 포함하고, 상기 제2합성 프레임을 생성하는 단계는, 상기 저장된 그래픽프레임 또는 제1합 성프레임에 다음 순서의 비디오프레임을 합성하고, 상기 영상 효과 처리를 수행하여 상기 제2합성프레임을 생성 하는 단계를 포함한다. 상기 제2합성프레임을 출력하는 단계는, 상기 비디오프레임에 대응하는 비디오컨텐츠 및 상기 그래픽프레임에 대응하는 메뉴항목을 동시에 표시하는 이벤트에 대응하여 상기 제2합성프레임이 출력하는 단계를 포함한다. 상기 메뉴항목의 표시를 종료하는 이벤트에 대응하여 상기 제1합성프레임을 출력하는 단계를 더 포함한다. 상기 비디오컨텐츠 및 상기 메뉴항목이 각각 동시에 표시되는 상기 비디오영역 및 상기 그래픽영역 상에 상기 그래픽프레임과 다른 그래픽프레임에 대응하는 제2메뉴항목을 표시하는 이벤트에 대응하여 상기 제2합성프레임 을 출력하는 단계를 더 포함한다. 상기 그래픽프레임의 업데이트 이벤트에 대응하여, 새로운 그래픽프레임으로 상기 저장된 그래픽프레임 또는 제 1합성프레임을 업데이트하는 단계를 더 포함한다. 상기한 본 발명의 목적은, 컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된 기록매체에 있어서, 비디오프레임 및 그래픽프레임에 기초한 제1합성프레임을 생성하 여 출력하는 단계; 영상 효과 처리의 이벤트에 대응하여, 표시되는 영상 내 상기 비디오프레임에 대응하는 비디 오영역 및 상기 그래픽프레임에 대응하는 그래픽영역을 포함하며, 상기 비디오영역 및 상기 그래픽영역에 상기 영상 효과 처리가 수행된 제2합성 프레임을 생성하는 단계; 및 상기 제2합성프레임을 출력하는 단계를 포함하는 것을 특징으로 하는 컴퓨터가 읽을 수 있는 프로그램이 기록된 기록매체에 의해서도 달성될 수 있다."}
{"patent_id": "10-2020-0122785", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 비디오프레임과의 합성 이전에 그래픽프레임에 대한 영상 효과 처리가 수행되는 장치 구성에 서, 합성프레임에 대한 영상 효과 처리가 필요한 이벤트에 대응하여, 영상 효과 처리가 동일하게 수행된 비디오 프레임 및 그래픽프레임에 기초하여 합성프레임을 출력할 수 있는 전자장치 및 그 제어방법을 제공한다."}
{"patent_id": "10-2020-0122785", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 전자장치를 도시한다. 도 1에 도시된 바와 같이, 전자장치는 TV, 태블릿, 휴대용 미디어 플레이어, 웨어러블 디바이스, 비디오 월, 전자액자 등과 같이 영상표시장치뿐만 아니라, 디스플레이를 구비하지 않는 셋탑박스 등의 영상처리장치, 냉장고, 세탁기 등의 생활가전, 컴퓨터본체와 같은 정보처리장치 등 다양한 종류의 장치로 구현된다. 또한, 전 자장치는 인공지능 기능을 탑재한 인공지능(Artificial Intelligence, AI) 스피커, AI 로봇 등으로 구현된 다. 전자장치의 종류는 이에 한정되는 것은 아니며, 이하에서는 설명의 편의를 위해 전자장치가 TV로 구현되는 경우를 가정한다. 전자장치는 비디오프레임 또는 그래픽프레임을 표시한다. 비디오프레임은 시간 흐름에 따라 화면 속의 객체가 연속적으로 움직이는 영상을 구성하는 동적 프레임으로서, 복수의 비디오프레임을 포함한다. 반 면에, 그래픽프레임은 정적 프레임을 의미한다. 전자장치는 비디오프레임에 대응하는 비디오컨텐츠, 예컨대, 스포츠 프로그램을 표시하거나, 그래픽프레 임에 대응하는 EPG를 표시할 수 있다. EPG는 방송 프로그램에 관련된 안내 정보로서, 방송 프로그램의 제목, 방송 프로그램의 채널 번호, 방송 프로그램의 방송 시간, 방송 프로그램에 대한 상세 설명, 방송 프로그램의 녹 화, 기타 컨텐츠 등으로 구성된 정보를 포함할 수 있다. 전자장치는 그래픽프레임에 비디오프레임을 합성하고, 합성된 비디오프레임 및 그래픽프레임에 기초한 제1합성프레임을 생성하여 출력할 수 있다. 일 예로, 그래픽프레임이 방송 프로그램 채널 번호 선 택을 위한 EPG에 대응하는 경우, 방송 프로그램 채널 번호 선택을 위한 EPG를 통해 \"20번 스포츠\" 채널이 선택 되면, 전자장치는 비디오프레임에 대응하는 \"20번 스포츠\" 채널의 방송 프로그램을 방송 프로그램 채널 번호 선택을 위한 EPG에 합성함으로써, 제1합성프레임을 생성하여 출력할 수 있다. 만일, \"19번 드라마\" 채 널이 선택되면, 비디오프레임에 대응하는 \"19번 드라마\" 채널의 드라마 프로그램이 그래픽프레임에 대응 하는 EPG에 합성되어, 제1합성프레임이 생성될 수 있다. 제1합성프레임의 생성 및 출력 과정에 대해서는, 도 5를 참조하여 자세히 설명하기로 한다. 전자장치는 제2합성프레임을 생성하여 출력할 수 있다. 제2합성프레임은 영상 효과 처리가 동일하게 수행된 비디오프레임 및 그래픽프레임을 포함한다. 일 예로, 영상 효과 처리가 블러인 경우, 전자장치 는 \"20번 스포츠\" 채널의 방송 프로그램 및 방송 프로그램 채널 번호 선택을 위한 EPG 모두에 대하여 블러 가 수행된 제2합성프레임을 생성하여 출력할 수 있다. 특히, 그래픽프레임에 대한 영상 효과 처리가, 앞서 설명한 비디오프레임과의 합성 이전에 수행되는 구조 를 가지더라도, 전자장치는 영상 효과 처리가 동일하게 수행된 비디오프레임 및 그래픽프레임에 기초 하여 제2합성프레임을 생성하여 출력할 수 있다. 제2합성프레임의 생성 및 출력 과정에 대해서는 도 7을 참조하여 자세히 설명하기로 한다. 한편, 영상 효과는 블러에 한정되는 것은 아니므로, 샤프닝(sharpening), 필터링(filtering) 등을 포함할 수 있 다. 다만, 이하에서는 설명의 편의를 위해 영상 효과 처리가 블러인 경우를 가정하여 설명한다. 제2합성프레임의 생성 및 출력은 영상 효과 처리의 이벤트에 대응하여 수행될 수 있다. 영상 효과 처리의 이 벤트는 본체에 마련된 내부 사용자입력부(도 3을 참조) 또는 본체와 분리된 리모트 컨트롤러를 통해 수 신될 수 있다. 이벤트는 사용자로부터의 수신된 사용자입력에 기초한 것일 수 있으며, 사용자입력은 음성 명령에 따라 수행된 음성 인식 처리에 기초할 수 있다. 리모트 컨트롤러를 활용하는 경우, 리모트 컨트롤러로부터 음성 명령에 대응하는 음성 신호를 전달받고, 전달받은 음성 신호에 대한 음성 인식 처리를 수행한다. 음성 인식 처리는 음성 명령을 텍스트 데이터로 변환하는 STT(Speech-to-Text) 처리 과정과, 텍스트 데이터가 나타내는 커맨드를 식별하여, 식별된 커맨드가 지시하는 동작을 수행하는 커맨드 식별 및 수행 과정을 포함한다. 음성 인식 처리는 전자장치에서 모두 실행될 수 있으나, 시스템 부하 및 소요 저장용량을 고려하 여, 적어도 일부의 과정은 네트워크를 통해 전자장치와 통신 가능하게 접속되는 적어도 하나의 서버에 의해 수행된다. 일 예로, 적어도 하나의 서버가 STT 처리 과정을 수행하고, 전자장치가 커맨드 식별 및 수행 과 정을 수행한다. 또는, 적어도 하나의 서버가 STT 처리 과정과, 커맨드 식별 및 수행 과정을 모두 수행하고, 전 자장치는 단지 적어도 하나의 서버로부터 결과를 수신하기만 할 수도 있다. 이와 같이, 비디오프레임과의 합성 이전에 그래픽프레임에 영상 효과 처리가 수행되는 장치 구성에서, 전 자장치는 영상 효과 처리의 이벤트에 대응하여, 영상 효과 처리가 동일하게 수행된 비디오프레임 및 그 래픽프레임에 기초하여 제2합성프레임을 생성하여 출력할 수 있다. 영상 효과 처리의 이벤트에 대응하여, 그래픽프레임에만 영상 효과 처리가 수행되면, 비디오프레임 및 그 래픽프레임 간에 영상 효과 처리가 동일하지 않은 합성프레임으로 인해, 사용자에게 시각적 불안정감을 줄 수 있으며, 이러한 시각적 불안감은 영상 품질을 전반적으로 떨어뜨리는 원인이 된다. 이에 대해, 전자장치는 영상 효과 처리가 동일하게 수행된 비디오프레임 및 그래픽프레임에 기초하여 제2합성프레임을 생성함으로써, 사용자에게 시각적 안정감을 줄 수 있을 뿐만 아니라, 향샹된 품질의 영상을 제공할 수 있다. 도 2는 도 1의 전자장치에 관한 구성의 일 예를 도시한다. 이하에서는 도 2를 참조하여, 전자장치에 관한 구성의 일 예를 자세히 설명한다. 본 실시예서는 전자장치 가 TV인 경우에 관해 설명하지만, 전자장치는 다양한 종류의 장치로 구현될 수 있으므로, 본 실시예가 전자장치의 구성을 한정하는 것은 아니다. 전자장치가 TV와 같은 디스플레이장치로 구현되지 않는 경우 도 가능하며, 이 경우 전자장치는 디스플레이와 같은 영상 표시를 위한 구성요소들을 포함하지 않을 수 있다. 예를 들면 전자장치가 셋탑박스로 구현되는 경우에, 전자장치는 인터페이스부를 통해 외부의 TV에 영상 신호를 출력한다. 전자장치는 인터페이스부를 포함한다. 인터페이스부는 서버, 다른 외부장치 등과 연결하여 데이터 를 송수신한다. 다만 이에 한정되는 것은 아니므로, 인터페이스부는 네트워크로 연결된 다양한 장치와 연결 한다. 인터페이스부는 유선 인터페이스부를 포함한다. 유선 인터페이스부는 지상파/위성방송 등 방송규격에 따른 방송신호를 수신할 수 있는 안테나가 연결되거나, 케이블 방송 규격에 따른 방송신호를 수신할 수 있는 케이블 이 연결될 수 있는 커넥터 또는 포트를 포함한다. 다른 예로서, 전자장치는 방송신호를 수신할 수 있는 안 테나를 내장할 수도 있다. 유선 인터페이스부는 HDMI 포트, DisplayPort, DVI 포트, 썬더볼트, 컴포지트 (Composite) 비디오, 컴포넌트(Component) 비디오, 슈퍼 비디오(Super Video), SCART 등과 같이, 비디오 및/또 는 오디오 전송규격에 따른 커넥터 또는 포트 등을 포함한다. 유선 인터페이스부는 USB 포트 등과 같은 범용 데 이터 전송규격에 따른 커넥터 또는 포트 등을 포함한다. 유선 인터페이스부는 광 전송규격에 따라 광케이블이 연결될 수 있는 커넥터 또는 포트 등을 포함한다. 유선 인터페이스부는 내부 오디오 수신부 및 오디오 수신부를 구비한 외부 오디오기기가 연결되며, 오디오기기 로부터 오디오신호를 수신 또는 입력할 수 있는 커넥터 또는 포트 등을 포함한다. 유선 인터페이스부는 헤드셋, 이어폰, 외부 스피커 등과 같은 오디오기기가 연결되며, 오디오기기로 오디오신호를 전송 또는 출력할 수 있는 커넥터 또는 포트 등을 포함한다. 유선 인터페이스부는 이더넷 등과 같은 네트워크 전송규격에 따른 커넥터 또 는 포트를 포함한다. 일 예로, 유선 인터페이스부는 라우터 또는 게이트웨이에 유선 접속된 랜카드 등으로 구현 된다. 유선 인터페이스부는 상기 커넥터 또는 포트를 통해 셋탑박스, 광학미디어 재생장치와 같은 외부기기, 또는 외 부 디스플레이장치나, 스피커, 서버 등과 1:1 또는 1:N(N은 자연수) 방식으로 유선 접속됨으로써, 해당 외부기 기로부터 비디오/오디오신호를 수신하거나 또는 해당 외부기기에 비디오/오디오신호를 송신한다. 유선 인터페이 스부는, 비디오/오디오신호를 각각 별개로 전송하는 커넥터 또는 포트를 포함할 수도 있다. 유선 인터페이스부는 전자장치에 내장되거나, 동글(Dongle) 또는 모듈(Module) 형태로 구현되어 전자장치 의 커넥터에 착탈될 수도 있다. 인터페이스부는 무선 인터페이스부를 포함한다. 무선 인터페이스부는 전자장치의 구현 형태에 대응하여 다양한 방식으로 구현된다. 일 예로, 무선 인터페이스부는 통신방식으로 RF(Radio Frequency), 지그비(Zigbee), 블루투스(Bluetooth), 와이파이(Wi-Fi), UWB(Ultra-Wideband) 및 NFC(Near Field Communication) 등 무선통신 을 사용한다. 무선 인터페이스부는 와이파이 방식에 따라서 AP와 무선통신을 수행하는 무선통신모듈이나, 블루 투스 등과 같은 1대 1 다이렉트 무선통신을 수행하는 무선통신모듈 등으로 구현된다. 무선 인터페이스부는 네트워크 상의 서버와 무선 통신함으로써, 서버와의 사이에 데이터 패킷을 송수신한다. 무 선 인터페이스부는 적외선 통신규격에 따라 IR(Infrared) 신호를 송신 및/또는 수신할 수 있는 IR송신부 및/또 는 IR수신부를 포함한다. 무선 인터페이스부는 IR송신부 및/또는 IR수신부를 통해 리모트 컨트롤러 또는 다른 외부기기로부터 리모트 컨트롤러신호를 수신 또는 입력하거나, 리모트 컨트롤러 또는 다른 외부기기로 리모트 컨트롤러신호를 전송 또는 출력한다. 다른 예로서, 전자장치는 와이파이, 블루투스 등 다른 방식의 무선 인터페이스부를 통해 리 모트 컨트롤러 또는 다른 외부기기와 리모트 컨트롤러신호를 송수신한다. 전자장치는 인터페이스부를 통해 수신하는 비디오/오디오신호가 방송신호인 경우, 수신된 방송신호를 채널 별로 튜닝하는 튜너(Tuner)를 더 포함한다. 전자장치는 디스플레이를 포함한다. 디스플레이는 화면 상에 영상을 표시할 수 있는 디스플레이 패 널을 포함한다. 디스플레이 패널은 액정 방식과 같은 수광 구조 또는 OLED 방식과 같은 자발광 구조로 마련된다. 디스플레이는 디스플레이 패널의 구조에 따라서 부가적인 구성을 추가로 포함할 수 있는데, 일 예로, 디스플레이 패널이 액정 방식이라면, 디스플레이는 액정 디스플레이 패널과, 광을 공급하는 백라이트 유닛과, 액정 디스플레이 패널의 액정을 구동시키는 패널구동기판을 포함한다. 다만, 앞서 설명한 바와 같이, 디스플레이는 전자장치가 셋탑박스 등으로 구현되는 경우 생략된다. 전자장치는 사용자입력부를 포함한다. 사용자입력부는 사용자의 입력을 수행하기 위해 사용자가 조 작할 수 있도록 마련된 다양한 종류의 입력 인터페이스 관련 회로를 포함한다. 사용자입력부는 전자장치 의 종류에 따라서 여러 가지 형태의 구성이 가능하며, 예를 들면 전자장치의 기계적 또는 전자적 버튼 부, 터치패드, 디스플레이에 설치된 터치스크린 등이 있다. 전자장치는 통신부를 포함한다. 통신부는 서버, 다른 외부장치 등과 연결되어 비디오/오디오 신호 를 전송한다. 통신부는 설계 방법에 따라 유선 인터페이스부 또는 무선 인터페이스 중 적어도 하나의 구성 을 포함하며, 유선 인터페이스부 또는 무선 인터페이스 중 적어도 하나의 기능을 수행한다. 전자장치는 출력부를 포함한다. 출력부는 오디오신호에 기초하여 다양한 오디오를 출력한다. 출력 부는 적어도 하나 이상의 스피커로 구현된다. 출력부는 전자장치에 마련된 내부 스피커 또는 외부 에 마련되는 외부 스피커로 구현된다. 출력부가 외부 스피커로 구현되는 경우, 전자장치는 오디오신호 를 외부 스피커로 유선 또는 무선으로 전송한다. 전자장치는 오디오 수신부를 포함한다. 오디오 수신부는 다양한 오디오신호를 수신한다. 오디오 수신부는 사용자 음성의 신호뿐만 아니라, 소음 등 주변으로부터 유입된 오디오의 신호를 수신한다. 오디오 수신부는 수 집된 오디오신호를 프로세서에 전달한다. 오디오 수신부는 전자장치에 마련된 내부 마이크 또는 본체와 분리된 리모트 컨트롤러에 마련된 외부 마이크로 구현된다. 오디오 수신부가 외부 마이크로 구현되는 경우, 외부 마이크로 수신된 오디오신호는 디지털화 되어 리모트 컨트롤러로부터 인터페이스부를 통해 수신된 다. 리모트 컨트롤러는 스마트폰 등을 포함하며, 스마트폰 등에는 리모트 컨트롤러 어플리케이션이 설치된다. 스마트폰 등은 설치된 어플리케이션을 통해 리모트 컨트롤러의 기능, 예컨대, 전자장치를 제어하는 기 능을 수행한다. 이러한 리모트 컨트롤러 어플리케이션은 AI 스피커, AI 로봇 등 다양한 외부 장치에 설치된다. 전자장치는 센서부를 포함한다. 센서부는 전자장치의 전방을 센싱하여, 사용자 또는 다른 전자장치의 유무, 움직임 등을 감지한다. 일 예로, 센서부는 이미지 센서로 구현될 수 있으며, 전자장치의 전방을 캡처 하여, 캡처된 이미지로부터 사용자 또는 다른 전자장치의 유무, 움직임 등에 관한 정보를 획득한다. 이미지 센 서는, CMOS(Complementary Metal Oxide Semiconductor) 또는 CCD(Charge Coupled Device) 방식의 카메라로 구 현된다. 센서부는 적외선 센서로 구현될 수 있으며, 전방으로 출력되는 적외선 신호가 반사되어 돌아오는 시간을 측정하여 사용자 또는 다른 전자장치의 유무, 움직임 등에 관한 정보를 획득한다. 디스플레이, 사용자입력부, 통신부, 출력부, 오디오 수신부, 센서부 등은 인터페이스부와 별도의 구성으로 기재되었으나, 설계 방법에 따라 인터페이스부에 포함되도록 구성된다. 전자장치는 저장부를 포함한다. 저장부는 디지털화된 데이터를 저장한다. 저장부는 전원의 제 공 유무와 무관하게 데이터를 보존할 수 있는 비휘발성 속성의 스토리지(Storage)를 포함한다. 스토리지는 플래 시메모리(Flash-memory), HDD(Hard-disc Drive), SSD(Solid-State Drive), ROM(Read Only Memory) 등을 포함 한다. 저장부는 프로세서에 의해 처리되기 위한 데이터 등이 로드 되며, 전원이 제공되지 않으면 데이터를 보 존할 수 없는 휘발성 속성의 메모리(Memory)를 포함한다. 메모리는 버퍼메모리(Buffer-memory, 42), 램(Random Access Memory) 등을 포함한다. 전자장치는 프로세서를 포함한다. 프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등 으로 구현되는 하나 이상의 하드웨어 프로세서를 포함하며, 설계 방식에 따라서는 SOC(System On Chip)로 구현 될 수도 있다. 프로세서는 전자장치가 디스플레이장치로 구현되는 경우에 디멀티플렉서, 디코더, 스케일러, 오디오 DSP(Digital Signal Processor), 앰프 등의 다양한 프로세스에 대응하는 모듈들을 포함한다. 여기서, 이러한 모 듈들 중 일부 또는 전체가 SOC로 구현된다. 일 예로, 디멀티플렉서, 디코더, 스케일러 등 영상처리와 관련된 모 듈이 영상처리 SOC로 구현되고, 오디오 DSP는 SOC와 별도의 칩셋으로 구현되는 것이 가능하다. 전자장치의 구성은 도 2에 도시된 바에 한정되는 것은 아니므로, 설계 방법에 따라 상기한 구성 중 일부를 제외하거나, 상기한 구성 이외의 구성을 포함한다. 도 3은 도 2의 전자장치에 관한 구성의 구체적인 일 예를 도시한다. 이하에서는 도 3을 참조하여, 전자장치에 관한 구성의 구체적인 일 예를 자세히 설명한다. 본 실시예서는 전자장치가 TV인 경우에 관해 설명하지만, 전자장치는 다양한 종류의 장치로 구현될 수 있으므로, 본 실시예가 전자장치의 구성을 한정하는 것은 아니다. 전자장치는 비디오처리부를 포함한다. 비디오처리부는 비디오프레임을 출력한다. 비디오프레임 은 시간 흐름에 따라 화면 속의 객체가 연속적으로 움직이는 영상을 구성하는 동적 프레임을 포함한다. 전자장치는 그래픽처리부를 포함한다. 그래픽처리부는 그래픽프레임을 출력한다. 그래픽프레임 은 시간 흐름에 따라 화면 속의 객체가 움직이지 않는 정적 프레임을 포함한다. 전자장치는 스케일러를 포함한다. 스케일러는 비디오프레임의 크기, 위치 조정 등을 수행한다. 일 예로, 스케일러는 제1합성프레임을 생성하기 위해 그래픽프레임의 일 영역에 맞도록 비디오프레임 의 크기를 줄일 수 있다. 스케일러는 제1합성프레임에 포함된 비디오프레임에 대응하는 비디오영 역(도 5를 참조)에 맞도록 비디오프레임의 크기를 줄일 수 있다. 비디오영역은 그래픽프레임의 일 영역을 포함한다. 다만, 이에 한정되는 것은 아니므로, 스케일러는 비디오프레임의 해상도를 더 높은 해 상도로 변환할 수 있다. 전자장치는 믹서(Mixer, 33)을 포함한다. 믹서는 그래픽프레임에 비디오프레임을 합성하여 제1합 성프레임을 생성한다. 믹서에 의해 그래픽프레임에 합성되는 비디오프레임은, 스케일러를 통 해 크기, 위치 조정 등이 수행된 것일 수 있다. 믹서를 통해 생성된 제1합성프레임은 디스플레이로 출력되어 표시될 수 있다. 한편, 믹서는 이하에서 설명하는 처리부의 활성화에 대응하여, 처리부에 의해 영상 효과 처리가 수 행된 제2합성프레임을 수신한다. 믹서는 처리부의 활성화에 대응하여 수신된 제2합성프레임을 디 스플레이로 바이패스(by-pass) 할 수 있다. 믹서가 제2합성프레임을 바이패스하는 과정에 대해서는, 이하에서 설명하는 처리부와 관련하여 자세히 설명하기로 한다. 전자장치는 버퍼메모리를 포함한다. 버퍼메모리는 그래픽프레임 또는 제1합성프레임을 저장 한다. 그래픽프레임 또는 제1합성프레임은 영상 효과 처리가 수행되지 않은 것일 수 있다. 버퍼메모리 는 이하에서 설명하는 처리부의 활성화에 대응하여, 그래픽프레임 또는 제1합성프레임을 저장할 수 있다. 버퍼메모리는 처리부의 활성화에 대응하여, 비디오처리부로부터 출력된 비디오프레임를 저장할 수 있다. 버퍼메모리에 저장되는 데이터에 대해서는 도 8을 참조하여 자세히 설명하기로 한다. 전자장치는 합성부를 포함한다. 합성부는 처리부의 활성화에 대응하여, 버퍼메모리에 저장 된 그래픽프레임 또는 제1합성프레임에 비디오프레임을 합성한다. 합성부는 그래픽프레임 또는 제1합성프레임에 비디오프레임을 합성하기 위해 비디오프레임에 대한 스케일링 등을 수행할 수 있다. 다만, 비디오프레임에 대한 스케일링 등은 버퍼메모리에 의해 수행되거나, 버퍼메모리에 포함된 별 도의 구성에 의해 수행될 수도 있다. 일 예로, 합성부는 비디오프레임에 대응하는 비디오영역(도 7를 참조)에 맞도록 비디오프레임의 크기를 줄일 수 있다. 비디오영역은 그래픽프레임 또는 제1합성프레 임의 일 영역을 포함한다. 전자장치는 처리부를 포함한다. 처리부는 영상 효과 처리가 필요한 이벤트에 대응하여 활성화된다. 영상 효과 처리가 필요한 이벤트는 사용자입력부를 통해 수신된 사용자입력에 기초한 것일 수 있다. 사용자 입력은 사용자로부터의 음성 명령에 따라 수행된 음성 인식 처리에 기초할 수 있다. 처리부는 합성부에 의해 합성된 프레임에 대하여 영상 효과 처리를 수행하여, 제2합성프레임을 생성 한다. 합성부에 의해 합성된 프레임은 앞서 설명한 바와 같이, 비디오프레임과 그래픽프레임 간의 합 성 프레임, 또는 비디오프레임과 제1합성프레임 간의 합성 프레임을 포함한다. 영상 효과 처리는, 블러, 샤프닝, 필터링 등을 포함할 수 있다. 처리부는 영상 효과 처리가 수행된 제2합성프레임에 대하여, 추가의 영상 처리를 수행할 수 있다. 추가 의 영상 처리는 영상 효과 처리가 수행된 제2합성프레임이 디스플레이에 표시될 수 있게 하는 다양한 영 상 처리를 포함할 수 있다. 처리부는 추가의 영상 처리를 위해 GPU(Graphic Processing Unit)를 포함할 수 있다. 한편, 처리부는 앞서 설명한 영상 효과 처리를 수행하는 구성 및 추가의 영상 처리를 수행하는 구성을 포함 할 수 있다. 일 예로, 처리부는 합성부에 의해 합성된 프레임에 대하여 영상 효과 처리를 수행하여, 제 2합성프레임을 생성하는 효과적용부를 포함할 수 있다. 처리부는 영상 효과 처리가 수행된 제2합성프레 임에 대하여 추가의 영상 처리를 수행하는 효과처리부를 포함할 수 있다. 다만, 상기한 영상 효과 처리 등이 하나의 구성에 의해 수행되거나, 두 개의 구성에 의해 수행되는지 여부는 설계 방법에 따른 선택 사항이며, 이 하에서는 설명의 편의를 위해 처리부가 영상 효과 처리 등을 수행하는 것으로 설명한다. 믹서는 처리부의 활성화에 대응하여, 처리부로부터 영상 효과 처리가 수행된 제2합성프레임을 수신한다. 제2합성프레임은 영상 효과 처리 이외에 추가의 영상 처리가 수행된 것일 수 있다. 믹서는 제 2합성프레임을 디스플레이로 출력하는, 바이패스 기능을 수행한다. 반면에, 믹서는 처리부의 비활성화에 대응하여, 스케일러를 통해 크기, 위치 조정 등이 수행된 비 디오프레임을 그래픽프레임에 합성하여, 제1합성프레임을 생성한다. 즉, 믹서는 처리부의 활 성화에 대응하여서는, 처리부로부터 수신된 제2합성프레임에 대하여 바이패스 기능을 수행하므로, 처리 부의 활성화 여부에 따라 서로 다른 기능을 수행할 수 있다. 전자장치의 구성은 도 3에 도시된 바에 한정되는 것은 아니므로, 설계 방법에 따라 상기한 구성 중 일부를 제외하거나, 상기한 구성 이외의 구성을 포함할 수 있다. 또한, 도 3에 도시된 구성 중 일부는 도 2의 프로세서 에 포함되거나, 도 3에 도시된 구성의 동작 중 일부는 프로세서에 의해 수행될 수 있다. 일 예로, 합성부 , 처리부 등은 프로세서에 의해 소프트웨어적으로 구현될 수 있다. 프로세서는 비디오처리부가 비디오프레임을 출력하고, 그래픽처리부가 그래픽프레임을 출력하 는 경우, 비디오프레임 및 그래픽프레임에 기초한 제1합성프레임을 생성하여 출력하도록 믹서를 제어한다. 이상의 동작은 처리부의 비활성화에 대응하여 수행될 수 있다. 프로세서는 영상 효과 처리의 이벤트에 대응하여, 표시되는 영상 내 비디오프레임에 대응하는 비디오영역 및 그래픽프레임에 대응하는 그래픽영역을 포함하며, 비디오영역 및 그래픽영역에 영상 효과 처리가 수행된 제2합성프레임을 생성하고, 제2합성프레임이 믹서를 통해 출력되도록 제어한다. 이상 의 동작은 처리부의 활성화에 대응하여 수행될 수 있다. 전자장치의 프로세서는 상기한 동작들을 위한 데이터 분석, 처리, 및 결과 정보 생성 중 적어도 일부에 대하여, 규칙 기반 또는 인공지능 알고리즘을 이용한 인공지능 기술을 적용함으로써, 인공지능 시스템을 구축한 다. 인공지능 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템으로서 기계가 스스로 학습하고 판단하며, 사용 할수록 인식률이 향상되는 시스템이며, 인공지능 알고리즘은 입력 데이터들의 특징을 스스로 분류/학습하는 알 고리즘이다. 인공지능 기술은 기계학습, 신경망 네트워크(Neural Network), 또는 딥러닝 알고리즘 중 적어도 하나를 이용하 여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 요소 기술들로 구성된다. 요소기술들은 인간의 언어/문자를 인식하는 언어적 이해 기술, 사물을 인간의 시각처럼 인식하는 시각적 이해 기술, 정보를 판단하여 논리적으로 추론하고 예측하는 추론/예측 기술, 인간의 경험 정보를 지식데이터로 처리 하는 지식 표현 기술 및 차량의 자율 주행, 로봇의 움직임을 제어하는 동작 제어 기술 중 적어도 하나를 포함할 수 있다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질 의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이 터 생성/분류), 지식 관리(데이터 활용) 등을 포함한다. 이하에서는 상기한 인공지능 알고리즘을 이용한 인공지능 기술이 전자장치의 프로세서에 의해 구현되는 일 예를 설명한다. 다만, 서버의 서버프로세서에 의해서도 동일한 인공지능 기술이 구현될 수 있음을 밝혀둔다. 프로세서는 학습부 및 인식부의 기능을 함께 수행한다. 학습부는 학습된 신경망 네트워크를 생성하는 기능을 수행하고, 인식부는 학습된 신경망 네트워크를 이용하여 데이터를 인식, 추론, 예측, 추정, 판단하는 기능을 수 행한다. 학습부는 신경망 네트워크를 생성하거나 갱신한다. 학습부는 신경망 네트워크를 생성하기 위해서 학습 데이터를 획득한다. 일 예로, 학습부는 학습 데이터를 저장부 또는 서버저장부로부터 획득하거나, 외부로부터 획득한 다. 학습 데이터는, 신경망 네트워크의 학습을 위해 이용되는 데이터일 수 있으며, 상기한 동작을 수행한 데이 터를 학습데이터로 이용하여 신경망 네트워크를 학습시킬 수 있다. 학습부는 학습 데이터를 이용하여 신경망 네트워크를 학습시키기 전에, 획득된 학습 데이터에 대하여 전처리 작 업을 수행하거나, 또는 복수 개의 학습 데이터들 중에서 학습에 이용될 데이터를 선별한다. 일 예로, 학습부는 학습 데이터를 기 설정된 포맷으로 가공하거나, 필터링하거나, 또는 노이즈를 추가/제거하여 학습에 적절한 데 이터의 형태로 가공한다. 학습부는 전처리된 학습 데이터를 이용하여 상기한 동작을 수행하도록 설정된 신경망 네트워크를 생성한다. 학습된 신경망 네트워크는, 복수의 신경망 네트워크 또는 레이어들로 구성된다. 복수의 신경망 네트워크의 노드 들은 가중치를 가지며, 복수의 신경망 네트워크들은 일 신경망 네트워크의 출력 값이 다른 신경망 네트워크의 입력 값으로 이용되도록 서로 연결된다. 신경망 네트워크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN (Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q- Networks)과 같은 모델을 포함한다. 한편, 인식부는 상기한 동작을 수행하기 위해, 타겟 데이터를 획득한다. 타겟 데이터는 저장부 또는 서버저 장부로부터 획득하거나, 외부로부터 획득한다. 타겟 데이터는 신경망 네트워크의 인식 대상이 되는 데이터일 수 있다. 인식부는 타겟 데이터를 학습된 신경망 네트워크에 적용하기 전에, 획득된 타겟 데이터에 대하여 전처리 작업을 수행하거나, 또는 복수 개의 타겟 데이터들 중에서 인식에 이용될 데이터를 선별한다. 일 예로, 인식부 는 타겟 데이터를 기 설정된 포맷으로 가공하거나, 필터링 하거나, 또는 노이즈를 추가/제거하여 인식에 적절한 데이터의 형태로 가공한다. 인식부는 전처리된 타겟 데이터를 신경망 네트워크에 적용함으로써, 신경망 네트워 크로부터 출력되는 츨력값을 획득한다. 인식부는 출력값과 함께, 확률값 또는 신뢰도값을 획득한다. 도 4는 도 1의 전자장치에 관한 제어방법의 일 예를 도시한다. 도 4를 참조하여 이하에서 설명하는 각 동작은 전자장치의 프로세서에 의해 실행될 수 있다. 프로세서는 비디오프레임 및 그래픽프레임에 기초한 제1합성프레임을 생성하여 출력한다(S41). 프로세서는 영상 효과 처리의 이벤트에 대응하여, 표시되는 영상 내 비디오프레임에 대응하는 비디오영역 및 그래픽프레임에 대응하는 그래픽영역을 포함하며, 비디오영역 및 그래픽영역에 영상 효과 처리가 수행된 제2합성프레임을 생성한다(S42). 프로세서는 제2합성프레임이 출력되도록 제어한다(S43). 이와 같이, 프로세서는 영상 효과 처리의 이벤트에 대응하여, 영상 효과 처리가 동일하게 수행된 비디오프레 임 및 그래픽프레임에 기초하여 제2합성프레임을 생성하여 출력할 수 있다. 따라서, 비디오프레임 과의 합성 이전에 그래픽프레임에 영상 효과 처리가 수행되는 장치 구성에서, 사용자에게 시각적 안정감을 줄 수 있을 뿐만 아니라, 향상된 품질의 영상을 제공할 수 있다. 도 5는 도 4의 동작 S41와 관련하여, 제1합성프레임 생성의 일 예를 도시한다. 이하에서는 영상 효과 처리의 이벤트가 없는 경우, 즉, 처리부의 비활성화에 대응하여, 비디오프레임 및 그래픽프레임에 기초하여 제1합성프레임이 생성되는 과정에 대해 설명한다. 도 5에 도시된 바와 같이, 처리부의 비활성화에 대응하여, 그래픽프레임은 그래픽처리부로부터 출력 되어, 처리부에 의한 영상 효과 처리의 수행없이 믹서로 전달된다. 프로세서는 복수의 비디오프레임 중 제1비디오프레임에 대하여 크기, 위치 조정 등이 수행되도록 제 어할 수 있다. 제1비디오프레임에 대한 크기, 위치 조정 등은 프로세서의 제어에 따라 스케일러에 의해 수행될 수 있다. 일 예로, 그래픽프레임이 방송 프로그램 채널 번호 선택을 위한 EPG에 대응하고, 비디 오프레임이 EPG를 통해 선택된 채널의 방송 프로그램에 대응한다고 가정하면, 제1합성프레임a에 포함된 방송 프로그램이 표시되는 비디오영역의 크기에 대응하도록 제1비디오프레임의 크기가 조정되거나, 비디 오영역의 위치에 따라 제1비디오프레임의 위치가 조정될 수 있다. 프로세서는 크기, 위치 조정 등이 수행된 제1비디오프레임을 그래픽프레임에 합성하여 제1합성프레임 a을 생성되도록 제어할 수 있다. 제1합성프레임a을 생성은 프로세서의 제어에 따라 믹서에 의해 수행될 수 있다. 생성된 제1합성프레임a은 제1비디오프레임에 대응하는 비디오영역 및 그래픽프레임 에 대응하는 그래픽영역을 포함한다. 일 예로, 제1합성프레임a의 비디오영역에는 방송 프로그램이 표시되고, 그래픽영역에는 EPG가 표시될 수 있다. 복수의 비디오프레임 중 제1비디오프레임의 다음 비디오프레임인 제2비디오프레임도, 제1비디오프레 임과 마찬가지로, 크기, 위치 조정 등이 수행되어, 그래픽프레임에 합성될 수 있다. 제2비디오프레임 이 그래픽프레임에 합성됨으로써, 제1합성프레임b가 생성될 수 있다. 상기한 과정에 따라 제1비디오프레임, 제2비디오프레임 등에 기초한 제1합성프레임a, 제1합성프레 임b 등이 생성된다. 제1합성프레임a, 제1합성프레임b 등에 포함된 그래픽영역에는, 영상 효과 처리가 수행되지 않은 그래픽프레임이 표시된다. 비디오프레임에 대해서도 영상 효과 처리가 수행된 바 없으므로, 제1합성프레임a, 제1합성프레임b에 포함된 비디오영역에도, 영상 효과 처리가 수행되지 않은 비디오프레임이 표시된다. 이와 같이, 프로세서는 처리부의 비활성화에 대응하여, 비디오프레임에 대응하는 비디오영역 및 그래픽프레임에 대응하는 그래픽영역에 대하여 영상 효과 처리가 수행되지 않는 제1합성프레임을 생성 할 수 있다. 이상에서는, 도 5를 참조하여, 처리부의 비활성화에 따라 영상 효과 처리가 수행되지 않는 비디오프레임 및 그래픽프레임을 포함하는 제1합성프레임의 생성 과정에 대해 설명하였으나, 이하에서는 도 6을 참조하 여, 처리부의 활성화에 따라 영상 효과 처리가 선택적으로 수행된 비디오프레임 및 그래픽프레임을 포함하는 제1합성프레임의 생성 과정에 대해 자세히 설명한다. 도 6은 도 4의 동작 S42와 관련하여, 관련기술에 따른 제1합성프레임 생성의 일 예를 도시한다. 도 6을 참조하여 설명하는 관련기술도, 도 3을 참조하여 설명한 바와 같이, 스케일러, 믹서, 처리부 등에 대응하는 구성을 포함할 수 있다. 이하에서는 설명의 편의를 위해, 본 발명의 각 구성에 대응하는 관 련기술의 각 구성을 스케일러, 믹서, 처리부 등으로 명명하기로 한다. 관련기술에 따르면, 처리부는 영상 효과 처리가 필요한 이벤트가 있는 경우, 활성화된다. 처리부가 활 성화되면, 그래픽프레임에 대하여 영상 효과 처리를 수행한다. 처리부는 그래픽프레임에 대하여 영상 효과 처리를 수행하거나, 영상 효과 처리가 수행된 그래픽프레임 에 대하여 추가의 영상 처리를 수행할 수 있다. 처리부는 영상 효과 처리 또는 추가의 영상 처리를 수행 하기 위한 별도의 구성을 포함할 수 있다. 예컨대, 처리부는 효과적용부 및 효과처리부를 포함할 수 있다. 믹서는 영상 효과 처리가 수행된 그래픽프레임에 복수의 비디오프레임 중 제1비디오프레임을 합 성하여, 제1합성프레임a을 생성한다. 제1비디오프레임은 그래픽프레임과의 합성을 위해 스케일러 를 통해 크기, 위치 조정 등이 수행된 것일 수 있다. 제1비디오프레임에 기초한 제1합성프레임a은 영상 효과 처리가 1회 수행된 그래픽프레임과 영상 효과 처리가 수행되지 않은 제1비디오프레임에 기초 하여 생성된다. 즉, 제1합성프레임a은 영상 효과 처리가 동일하게 수행되지 않은 제1비디오프레임 및 그래픽프레임에 기초하여 생성된다. 복수의 비디오프레임 중 제1비디오프레임의 다음 비디오프레임인 제2비디오프레임에 기초하여 제1합 성프레임b을 생성하기 위해, 처리부는 영상 효과 처리가 1회 수행된 그래픽프레임에 대하여 영상 효 과 처리를 재차 수행한다. 영상 효과 처리가 재차 수행된 그래픽프레임에 대하여 추가의 영상 처리가 수행될 수 있다. 믹서는 영상 효과 처리가 2회 수행된 그래픽프레임에 제2비디오프레임을 합성하여, 제1합성프레임 b을 생성한다. 제2비디오프레임은 스케일러를 통해 크기, 위치 조정 등이 수행된 것일 수 있다. 제2비디오프레임에 기초한 제1합성프레임b은 영상 효과 처리가 2회 수행된 그래픽프레임과 영상 효 과 처리가 수행되지 않은 제2비디오프레임을 포함한다. 즉, 제1합성프레임b은 영상 효과 처리가 동일하 게 수행되지 않은 제2비디오프레임 및 그래픽프레임에 기초하여 생성된다. 복수의 비디오프레임 및 그래픽프레임 간의 합성이 진행될수록 그래픽프레임에 대한 영상 효과 처리는 중복 수행되므로, 영상 효과 처리가 중복 수행된 그래픽프레임 및 영상 효과 처리가 수행되지 않은 비디오프 레임에 기초한 제1합성프레임이 생성된다. 이와 같이, 비디오프레임과의 합성 이전에 그래픽프레임에 대한 영상 효과 처리가 수행되는 장치 구성에 서, 관련기술에 따르면, 처리부의 활성화에 따라 비디오프레임 및 그래픽프레임에 대하여 영상 효과 처리가 선택적으로 수행되는 제1합성프레임이 생성된다. 다만, 비디오프레임 및 그래픽프레임에 대하 여 영상 효과 처리가 동일하게 수행되는 제1합성프레임이 생성되지는 않는다. 이하에서는 도 7을 참조하여, 처리부의 활성화에 따라 비디오프레임 및 그래픽프레임에 대하여 영상 효과 처리가 동일하게 수행되는 과정에 대해 자세히 설명한다. 도 7은 도 4의 동작 S42와 관련하여, 제2합성프레임 생성의 일 예를 도시한다. 도 7에 도시된 바와 같이, 처리부의 활성화에 따라, 프로세서는 복수의 비디오프레임 중 제1비디오프 레임을 그래픽프레임에 합성하여 제1합성프레임a이 생성되도록 제어할 수 있다. 제1비디오프레임 및 그래픽프레임 간의 합성은 프로세서의 제어에 따라 합성부에 의해 수행될 수 있다. 제1비디 오프레임은 크기, 위치 조정 등이 수행된 것일 수 있다. 프로세서는 제1합성프레임a에 대하여 영상 효과 처리를 1회 수행하여, 제2합성프레임a이 생성되도록 한다. 제2합성프레임a은 영상 효과 처리가 1회 수행된 제1비디오프레임에 대응하는 비디오영역 및 영상 효과 처리가 1회 수행된 그래픽프레임에 대응하는 그래픽영역을 포함한다. 즉, 제1비디오프레임(4 1)에 기초한 제2합성프레임a에 포함된 비디오영역 및 그래픽영역에는, 영상 효과 처리가 동일하게 수 행된 제1비디오프레임 및 그래픽프레임이 표시된다. 필요에 따라 제2합성프레임a에 대하여 추가의 영상 처리가 수행될 수 있다. 제2합성프레임a은 디스플레이로 바이패스 될 수 있다. 디스플레이로의 바이패스는 프로세서의 제어에 따라 믹서에 의해 수행될 수 있다. 프로세서는 복수의 비디오프레임 중 제1비디오프레임의 다음 비디오프레임인 제2비디오프레임에 기초하여 제2합성프레임b을 생성한다. 제2합성프레임b을 생성함에 있어서, 그래픽프레임 또는 제1합 성프레임a을 활용할 수 있다. 좀더 구체적으로, 프로세서는 그래픽프레임에 제2비디오프레임을 합성하여 제1합성프레임b을 생 성하거나, 앞서 제1비디오프레임에 기초하여 생성된 제1합성프레임a에 제2비디오프레임을 합성하여 제1합성프레임b을 생성할 수 있다. 그래픽프레임 또는 제1합성프레임a은 영상 효과 처리가 수행되지 않은 것일 수 있다. 또한, 그래픽프레임은 그래픽컨텐츠가 변경되지 않고 유지된 것일 수 있다. 이하에서는 그래픽프레임에 제2비디오프레임을 합성하여 생성된 제1합성프레임b에 기초하여 제2합성 프레임b을 생성하는 과정에 대해 설명한다. 앞서 설명한 바와 같이, 제2비디오프레임을 영상 효과 처리 가 수행되지 않은 그래픽프레임에 합성하여 제1합성프레임b을 생성할 수 있다. 프로세서는 제1합성프레임b에 대하여 영상 효과 처리를 1회 수행하여 제2합성프레임b이 생성되도록 한다. 영상 효과 처리는 프로세서의 제어에 따라 처리부에 의해 수행될 수 있다. 제2합성프레임b은 영상 효과 처리가 1회 수행된 제2비디오프레임에 대응하는 비디오영역 및 영상 효 과 처리가 1회 수행된 그래픽프레임에 대응하는 그래픽영역을 포함한다. 제2합성프레임b에 포함된 비 디오영역 및 그래픽영역에는, 영상 효과 처리가 동일하게 수행된 제2비디오프레임 및 그래픽프레임 이 표시된다. 제1합성프레임a에 제2비디오프레임을 합성하여 생성된 제1합성프레임b에 기초하여 제2합성프레임 b을 생성하는 과정도, 앞서 그래픽프레임에 제2비디오프레임을 합성하여 생성된 제1합성프레임b(5 2)에 기초하여 제2합성프레임b을 생성하는 과정과 유사하다. 즉, 프로세서는 제1합성프레임a에 제2 비디오프레임을 합성하여 생성된 제1합성프레임b에 대하여 영상 효과 처리를 1회 수행하여 제2합성프레 임b이 생성되도록 한다. 영상 효과 처리는 프로세서의 제어에 따라 처리부에 의해 수행될 수 있다. 제2합성프레임b은 영상 효과 처리가 1회 수행된 제2비디오프레임에 대응하는 비디오영역 및 영상 효 과 처리가 1회 수행된 그래픽프레임에 대응하는 그래픽영역을 포함한다. 제2합성프레임b에 포함된 비 디오영역 및 그래픽영역에는, 영상 효과 처리가 동일하게 수행된 제2비디오프레임 및 그래픽프레임 이 표시된다. 이와 같이, 프로세서는 비디오프레임과의 합성 이전에 그래픽프레임에 영상 효과 처리가 수행되는 장 치 구성에서, 영상 효과 처리가 동일하게 수행된 비디오프레임 및 그래픽프레임에 기초하여 제2합성프레 임을 생성하여 출력할 수 있다. 따라서, 영상 효과 처리가 동일하게 수행된 제2합성프레임을 통해 사용자 에게 시각적 안정감을 줄 수 있을 뿐만 아니라, 향상된 품질의 영상을 제공할 수 있다. 도 8은 도 4의 동작 S42와 관련하여, 그래픽프레임 또는 제1합성프레임을 활용하여 제2합성프레임 생성하는 일 예를 도시한다. 도 8에 도시된 바와 같이, 프로세서는 제2합성프레임을 생성함에 있어서, 버퍼메모리에 저장된 그래 픽프레임 또는 제1합성프레임을 활용할 수 있다. 버퍼메모리에 저장된 그래픽프레임 또는 제1합성 프레임은 영상 효과 처리가 수행되지 않은 것일 수 있다. 그래픽프레임은 그래픽처리부로부터 출력되어 버퍼메모리에 저장될 수 있다. 제1합성프레임은 그 래픽처리부로부터 최초 출력되는 그래픽프레임에 비디오프레임을 합성하여 생성된 것일 수 있다. 도 7을 참조하여 설명한 바와 같이, 제1합성프레임은 복수의 비디오프레임 중 제1비디오프레임을 그래픽 처리부로부터 최초 출력된 그래픽프레임에 합성하여 생성된 제1합성프레임a을 포함한다. 프로세서는 생성된 제1합성프레임을 캡처하여, 버퍼메모리에 저장할 수 있다. 다만, 그래픽프레임 또는 제1합성프레임을 획득하여 저장하는 방법에 제한이 있는 것은 아니므로, 영상 효과 처리가 수행되지 않 은 그래픽프레임 또는 제1합성프레임은 다양한 방법으로 획득되어 버퍼메모리에 저장될 수 있다. 비디오프레임은 처리부의 활성화에 따라, 버퍼메모리에 저장될 수 있다. 비디오프레임은 스케일 링이 수행되어 버퍼메모리에 저장되거나, 버퍼메모리에 저장된 이후에 프로세서의 제어에 따라 스케 일링이 수행될 수 있다. 버퍼메모리는 비디오프레임에 대한 스케일링을 직접 수행하거나, 스케일링을 위 한 별도의 구성을 포함할 수 있다. 이하에서는 버퍼메모리에 저장된 그래픽프레임을 활용하여 제2합성프레임을 생성하는 과정에 대해 설 명한다. 버퍼메모리에 저장된 비디오프레임을 그래픽프레임에 합성하여 제1합성프레임을 생성한다. 비디오프레임 및 그래픽프레임 간의 합성은 합성부에 의해 수행될 수 있다. 그리고, 제1합 성프레임에 대하여 영상 효과 처리를 수행함으로써, 제2합성프레임을 생성할 수 있다. 다만, 비디오프레임은 버퍼메모리를 거치지 않을 수 있다. 이 경우, 비디오처리부로부터 출력된 비 디오프레임을 그래픽프레임에 합성하여 제1합성프레임을 생성할 수 있다. 버퍼메모리에 저장된 제1합성프레임을 활용하여 제2합성프레임을 생성하는 과정도, 버퍼메모리에 저장된 그래픽프레임을 활용하여 제2합성프레임을 생성하는 과정과 유사하다. 즉, 버퍼메모리에 저장 된 비디오프레임을 제1합성프레임에 합성하여 새로운 제1합성프레임을 생성한다. 그리고, 새로운 제1 합성프레임에 대하여 영상 효과 처리를 수행함으로써, 제2합성프레임을 생성할 수 있다. 이상과 같은 방법으로, 프로세서는 복수의 비디오프레임 중 제1비디오프레임에 기초한 제2합성프레임 a, 제1비디오프레임의 다음 비디오프레임인 제2비디오프레임에 기초한 제2합성프레임b 등을 생 성하여 출력할 수 있다. 제2합성프레임a은 영상 효과 처리가 동일하게 수행된 제1비디오프레임 및 그래 픽프레임을 포함하며, 제2합성프레임b은 영상 효과 처리가 동일하게 수행된 제2비디오프레임 및 그 래픽프레임을 포함한다. 이와 같이, 프로세서는 제2합성프레임을 생성함에 있어서, 버퍼메모리에 저장된 그래픽프레임 또 는 제1합성프레임을 활용할 수 있으므로, 보다 신속하게 제2합성프레임을 생성하여 출력할 수 있다. 도 9는 도 4의 동작 S42와 관련하여, 영상 효과 처리가 필요한 이벤트의 일 예를 도시한다. 프로세서는 비디오프레임에 대응하는 비디오컨텐츠 및 그래픽프레임에 대응하는 메뉴항목이 동시에 표 시되는 이벤트에 대응하여 제2합성프레임이 출력되도록 제어할 수 있다. 즉, 프로세서는 비디오컨텐츠 및 메뉴항목이 동시에 표시되는 이벤트를 영상 효과 처리가 필요한 이벤트로 식별할 수 있다. 이하에서는 비디오컨 텐츠 및 메뉴항목이 동시에 표시되는 이벤트의 일 예에 대해서 도 9을 참조하여 설명한다. 제1예로서, 비디오프레임에 대응하는 비디오컨텐츠가 표시되는 상황을 가정한다. 프로세서는 비디오컨텐 츠가 표시되는 상황에서 그래픽프레임에 대응하는 메뉴항목의 표시를 개시하는 이벤트가 있는지를 식별할 수 있다. 프로세서는 그래픽프레임에 대응하는 메뉴항목의 표시를 개시하는 이벤트가 있는 경우(S91), 이를 비디오컨텐츠 및 메뉴항목이 동시에 표시되는 이벤트로 식별할 수 있다. 따라서, 프로세서는 제2합성프레임 의 생성하여 출력하도록 제어할 수 있다(S92). 예컨대, 도 9에 도시된 바와 같이, 프로세서는 비디오프레임에 대응하는 어느 방송 프로그램이 표시되는 동안 그래픽프레임에 대응하는 방송 프로그램 채널 번호 선택을 위한 EPG가 실행되는지를 식별할 수 있다. 만일, 방송 프로그램이 표시되는 동안 EPG가 실행되면, 프로세서는 방송 프로그램 및 EPG가 동시에 표시하는 이벤트로 식별하고, 방송 프로그램 및 EPG에 기초하여 제2합성프레임을 생성하여 출력하도록 제어할 수 있다. 제2예로서, 제1합성프레임이 표시되는 상황을 가정한다. 제1합성프레임은 그래픽프레임에 비디오프레 임을 합성하여 생성된 것일 수 있다. 프로세서는 제1합성프레임에 포함된 비디오영역 상에 비디오 프레임에 대응하는 비디오컨텐츠가 표시되는 동안 비디오컨텐츠의 선택 이벤트가 있는지를 식별할 수 있다. 선택 이벤트에 의해 선택되는 비디오컨텐츠는 먼저 표시되는 비디오컨텐츠와 다른 것일 수 있다. 프로세서는 비디오컨텐츠의 선택 이벤트가 있는 경우(S91), 이를 비디오컨텐츠 및 메뉴항목이 동시에 표시되는 이벤트로 식 별할 수 있다. 따라서, 프로세서는 제2합성프레임의 생성하여 출력하도록 제어할 수 있다(S92). 이와 같이, 프로세서는 상황 별로 영상 효과 처리가 필요한 이벤트를 식별할 수 있으므로, 다양한 상황에 능 동적으로 제2합성프레임을 생성하여 출력할 수 있다. 도 10은 도 4의 동작 S42와 관련하여, 영상 효과 처리의 종료가 필요한 이벤트의 일 예를 도시한다. 앞서 도 9를 참조하여 설명한 바와 같이, 프로세서는 비디오컨텐츠 및 메뉴항목이 동시에 표시되는 이벤트를 영상 효과 처리가 필요한 이벤트로 식별하고, 제2합성프레임을 생성하여 출력할 수 있다(S101). 프로세서는 메뉴항목의 표시 종료 이벤트가 있는지를 식별할 수 있으며, 만일, 메뉴항목의 표시 종료 이벤트 가 있는 경우(S102), 이를 영상 효과 처리의 종료가 필요한 이벤트로 식별할 수 있다. 따라서, 프로세서는 제2합성프레임의 생성 및 출력을 종료하고, 제1합성프레임을 생성하여 출력하도록 제어할 수 있다(S92). 일 예로, 방송 프로그램 및 EPG에 기초하여 제2합성프레임이 출력되는 동안, 방송 프로그램 또는 EPG 중 어 느 하나에 대한 표시 종료 이벤트가 있는 경우, 프로세서는 이를 영상 효과 처리의 종료가 필요한 이벤트로 식별하고, 제2합성프레임의 생성 및 출력을 종료할 수 있다. 이와 같이, 프로세서는 상황 별로 영상 효과 처리의 종료가 필요한 이벤트를 식별할 수 있으므로, 상황 능동 적으로 제2합성프레임의 생성 및 출력을 종료하고, 제1합성프레임을 생성하여 출력하도록 제어할 수 있다. 도 11은 도 4의 동작 S42와 관련하여, 영상 효과 처리가 필요한 이벤트의 다른 예를 도시한다. 설명의 편의를 위해 비디오프레임 및 제1그래픽프레임에 기초한 제1합성프레임이 표시되는 상황을 가 정한다. 프로세서는 이 상황에서 제1합성프레임에 포함된 그래픽영역 상에 제1그래픽프레임과 다른 제2그래픽프레임에 대응하는 제2메뉴항목이 표시되는지를 식별할 수 있다. 제2메뉴항목은 및 제1그래픽프레임에 대응하는 제1메뉴항목과 다른 종류의 것일 수 있다. 일 예로, 제1 그래픽프레임에 대응하는 제1메뉴항목이 방송 프로그램 채널 번호 선택을 위한 EPG인 경우, 제2메뉴항목 은 방송 프로그램에 대한 이력 정보를 나타내는 EPG가 될 수 있다. 다만, 이에 한정되는 것은 아니므로, 제2메뉴항목은 제1메뉴항목과 다른 종류의 다양한 EPG를 포함할 수 있다. 프로세서는 제1그래픽프레임과 다른 제2그래픽프레임에 대응하는 제2메뉴항목이 표시되는 경우, 이 를 영상 효과 처리가 필요한 이벤트로 식별할 수 있다. 이 경우, 도 9를 참조하여 설명한 바와 같이, 프로세서 는 비디오프레임을 제1그래픽프레임에 합성하여 생성된 제1합성프레임에 대하여 영상 효과 처리를 수행하여, 제2합성프레임을 생성할 수 있다. 제2메뉴항목의 표시가 종료되면, 프로세서는 이를 영상 효과 처리의 종료가 필요한 이벤트로 식별하고, 도 10을 참조하여 설명한 바와 같이, 제2합성프레임의 생성 및 출력을 종료할 수 있다. 이와 같이, 프로세서는 상황 별로 영상 효과 처리가 필요한 이벤트를 식별할 수 있으므로, 상황 능동적으로 제2합성프레임을 생성하여 출력할 수 있다. 도 12는 도 8의 그래픽프레임 또는 제1합성프레임이 업데이트되는 일 예를 도시한다. 앞서 도 8을 참조하여 설명한 바와 같이, 버퍼메모리에 저장된 그래픽프레임 또는 제1합성프레임을 활용하여 제2합성프레임을 생성한다. 이하에서는 도 12를 참조하여, 버퍼메모리에 저장된 그래픽프레임 또는 제1합성프레임에 대하여 업데이트가 수행되는 과정에 대해 설명한다. 설명의 편의를 위해, 버퍼메모리에 기 저장된 그래픽프레임에 대응하는 제1메뉴항목이 방송 프로그램 채 널 번호 선택을 위한 EPG이고, 새로운 그래픽프레임에 대응하는 제2메뉴항목은 방송 프로그램 녹화를 위한 EPG인 경우를 가정한다. 이 경우, 비디오프레임에 대응하는 방송 프로그램 및 그래픽프레임에 대응하는 방송 프로그램 채널 번호 선택을 위한 EPG에 기초하여 제2합성프레임을 생성할 수 있다. 그래픽프레임에 대응하는 방송 프로그램 채널 번호 선택을 위한 EPG가 새로운 그래픽프레임에 대응하는 방송 프로그램 녹화를 위한 EPG로 변경되면, 방송 프로그램 녹화를 위한 EPG에 대응하는 새로운 그래픽프레임 이 버퍼메모리에 저장된다. 즉, 기 저장된 그래픽프레임이 새로운 그래픽프레임으로 변경된다. 방송 프로그램 녹화를 위한 EPG로의 변경은 EPG 변경을 위한 사용자입력에 따라 수행될 수 있다. 새로운 그래픽프레임으로의 변경에 따라, 프로세서는 이후의 비디오프레임에 대해서는 새로운 그래 픽프레임에 대응하는 방송 프로그램 녹화를 위한 EPG에 기초하여 제1합성프레임을 생성하거나, 제2합성 프레임을 생성하여 출력할 수 있다. 일 예로, 버퍼메모리에 저장된 비디오프레임 및 새로운 그래픽프레임의 합성에 의해 제1합성프레임 을 생성하고, 생성된 제1합성프레임에 대하여 영상 효과 처리를 수행하여, 영상 효과 처리가 수행된 새로 운 그래픽프레임에 기초한 제2합성프레임을 생성할 수 있다. 한편, 제2합성프레임을 생성하기 위해 새로운 그래픽프레임에 기초하여 최초로 생성된 제1합성프레임 을 활용할 수도 있다. 즉, 프로세서는 새로운 제1합성프레임을 버퍼메모리에 저장하고, 이후의 비 디오프레임에 대해서는 새로운 제1합성프레임과의 합성을 통해 제2합성프레임을 생성하여 출력할 수 있다. 이상과 같은 방법으로, 생성되어 출력되는 제2합성프레임은 영상 효과 처리가 동일하게 수행된 비디오 프레임 및 새로운 그래픽프레임을 포함한다. 이와 같이, 새로운 그래픽프레임에 기초하여 버퍼메모리에 기 저장된 그래픽프레임 또는 제1합성프 레임을 업데이트하여, 제2합성프레임을 생성하여 출력할 수 있으므로, 상황 적응적으로 제2합성프레임을 생성하여 출력할 수 있다. 본 문서에 개시된 다양한 실시예들은 전자장치와 같은 기기(Machine)가 읽을 수 있는 저장 매체(Storage Medium)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어로서 구현된다. 일 예로, 전자장치의 프로세 서는 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행한다. 이것은 전자장치와 같은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도 록 운영되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터 에 의해 실행될 수 있는 코드를 포함한다. 기기로 읽을 수 있는 저장매체는, 비일시적(Non-transitory) 저장매 체의 형태로 제공된다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(예컨대, 전자기 파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함한다. 일 예로, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(Computer Program Product)에 포함되어 제공된다. 본 개시에 의한 컴퓨터 프로그램 제품은, 앞서 언급된 바와 같은, 프로세서에 의해 실행되 는 소프트웨어의 명령어들을 포함한다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래된다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예컨대, CD-ROM)의 형태로 배포되거나, 또는 어플리케 이션 스토어(예컨대, 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예컨대, 스마트폰들) 간에 직접, 온 라인으로 배포(예컨대, 다운로드 또는 업로드)된다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더 블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메 모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성된다. 이상, 바람직한 실시예를 통하여 본 발명에 관하여 상세히 설명하였으나, 본 발명은 이에 한정되는 것은 아니며 특허청구범위 내에서 다양하게 실시된다."}
{"patent_id": "10-2020-0122785", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 전자장치를 도시한다. 도 2는 도 1의 전자장치에 관한 구성의 일 예를 도시한다. 도 3은 도 2의 전자장치에 관한 구성의 구체적인 일 예를 도시한다. 도 4는 도 1의 전자장치에 관한 제어방법의 일 예를 도시한다. 도 5는 도 4의 동작 S41와 관련하여, 제1합성프레임 생성의 일 예를 도시한다. 도 6은 도 4의 동작 S42와 관련하여, 관련기술에 따른 제1합성프레임 생성의 일 예를 도시한다. 도 7은 도 4의 동작 S42와 관련하여, 제2합성프레임 생성의 일 예를 도시한다. 도 8은 도 4의 동작 S42와 관련하여, 그래픽프레임 또는 제1합성프레임을 활용하여 제2합성프레임 생성하는 일 예를 도시한다. 도 9는 도 4의 동작 S42와 관련하여, 영상 효과 처리가 필요한 이벤트의 일 예를 도시한다. 도 10은 도 4의 동작 S42와 관련하여, 영상 효과 처리의 종료가 필요한 이벤트의 일 예를 도시한다. 도 11은 도 4의 동작 S42와 관련하여, 영상 효과 처리가 필요한 이벤트의 다른 예를 도시한다. 도 12는 도 8의 그래픽프레임 또는 제1합성프레임이 업데이트되는 일 예를 도시한다."}
