{"patent_id": "10-2022-0180494", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0075378", "출원번호": "10-2022-0180494", "발명의 명칭": "음향 데이터의 인식 정확도를 향상시키기 위한 방법, 장치 및 프로그램", "출원인": "주식회사 코클", "발명자": "한윤창"}}
{"patent_id": "10-2022-0180494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치의 하나 이상의 프로세서에서 수행되는 방법에 있어서,음향 데이터에 기초하여 하나 이상의 음향 프레임을 구성하는 단계;상기 하나 이상의 음향 프레임 각각을 음향 인식 모델의 입력으로 처리하여 각 음향 프레임에 대응하는 예측값을 출력하는 단계;상기 각 음향 프레임에 대응하는 예측값에 기초한 임계값 분석을 통해 하나 이상의 인식 음향 프레임을 식별하는 단계;상기 하나 이상의 인식 음향 프레임에 기초한 시계열 분석을 통해 변환 음향 프레임을 식별하는 단계; 및상기 변환 음향 프레임에 대응하는 예측값에 대한 변환을 수행하는 단계;를 포함하는,음향 데이터의 인식 정확도를 향상시키기 위한 방법."}
{"patent_id": "10-2022-0180494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 음향 데이터에 기초하여 하나 이상의 음향 프레임을 구성하는 단계는,상기 음향 데이터를 미리 정해진 제1시간 단위의 크기를 갖도록 분할하여 상기 하나 이상의 음향 프레임을 구성하는 단계; 를 포함하는,음향 데이터의 인식 정확도를 향상시키기 위한 방법."}
{"patent_id": "10-2022-0180494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 하나 이상의 음향 프레임 각각의 시작 시점은,인접한 음향 프레임 각각의 시작 시점과 제2시간 단위의 크기 차이를 갖도록 결정되는 것을 특징으로 하는,음향 데이터의 인식 정확도를 향상시키기 위한 방법."}
{"patent_id": "10-2022-0180494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 예측값은,하나 이상의 예측 항목 정보 및 상기 하나 이상의 예측 항목 정보 각각에 대응하는 예측 수치 정보를 포함하며,상기 임계값 분석은,상기 각 음향 프레임에 대응하는 하나 이상의 예측 수치 정보 각각이, 상기 각 예측 항목 정보에 대응하여 미리공개특허 10-2023-0075378-3-정해진 임계값 이상인지 여부를 판별하여 상기 하나 이상의 인식 음향 프레임을 식별하는 분석인, 음향 데이터의 인식 정확도를 향상시키기 위한 방법."}
{"patent_id": "10-2022-0180494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 시계열 분석을 통해 변환 음향 프레임을 식별하는 단계는,상기 하나 이상의 인식 음향 프레임 각각에 대응하는 예측 항목 정보를 식별하는 단계;상기 식별된 예측 항목 정보가 미리 정해진 기준 시간 동안 미리 정해진 임계 횟수 이상 반복되는지 여부를 판별하는 단계; 및 상기 판별 결과에 기초하여 상기 변환 음향 프레임을 식별하는 단계;를 포함하는,음향 데이터의 인식 정확도를 향상시키기 위한 방법."}
{"patent_id": "10-2022-0180494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 방법은,하나 이상의 인식 음향 프레임 각각에 대응하는 예측 항목 정보에 기초하여 각 인식 음향 프레임 간의 연관 관계를 식별하는 단계; 및상기 연관 관계에 기초하여 상기 하나 이상의 음향 프레임 각각에 대응하는 임계값 및 임계 횟수의 조정 여부를결정하는 단계; 를 포함하는,음향 데이터의 인식 정확도를 향상시키기 위한 방법."}
{"patent_id": "10-2022-0180494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 예측값에 대한 변환은,상기 변환 음향 프레임에 기초한 상기 음향 인식 모델의 출력을 인식 미대상 항목으로 변환하는 잡음 변환 및상기 변환 음향 프레임에 관련한 예측 항목 정보를 교정 예측 항목 정보로 변환하는 음향 항목 변환 중 적어도하나를 포함하는,음향 데이터의 인식 정확도를 향상시키기 위한 방법."}
{"patent_id": "10-2022-0180494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 교정 예측 항목 정보는,상기 예측 항목 정보의 연관 관계에 기초하여 결정되는 것을 특징으로 하는,공개특허 10-2023-0075378-4-음향 데이터의 인식 정확도를 향상시키기 위한 방법."}
{"patent_id": "10-2022-0180494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,제1항의 방법을 수행하는, 장치."}
{"patent_id": "10-2022-0180494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하드웨어인 컴퓨터와 결합되어, 제1항의 방법을 수행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2022-0180494", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전술한 과제를 해결하기 위한 본 발명의 일 실시예에서, 음향 데이터의 인식 정확도를 향상시키기 위한 방법이 개시된다. 상기 방법은, 음향 데이터에 기초하여 하나 이상의 음향 프레임을 구성하는 단계, 상기 하나 이상의 음향 프레임 각각을 음향 인식 모델의 입력으로 처리하여 각 음향 프레임에 대응하는 예측값을 출력하는 단계, 상기 각 음향 프레임에 대응하는 예측값에 기초한 임계값 분석을 통해 하나 이상의 인식 음향 프레임을 식별하는 단계, 상기 하나 이상의 인식 음향 프레임에 기초한 시계열 분석을 통해 변환 음향 프레임을 식별하는 단계 및 상기 변환 음향 프레임에 대응하는 예측값에 대한 변환을 수행하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0180494", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음향 데이터의 인식률을 향상시키기 위한 방법에 관한 것으로, 보다 구체적으로, 음향 데이터의 후처 리 보정을 통해 인식률을 향상시키는 기술에 관한 것이다."}
{"patent_id": "10-2022-0180494", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "완전히 소리를 못듣거나 또는 소리를 잘 구별하지 못하는 청각 장애우들은 소리를 듣고 상황을 판단하는 것이 어렵기 때문에 일상생활에 많은 어려움이 있을 뿐만 아니라, 소리 정보를 이용하여 실내, 실외 환경에서의 위험 한 상황을 인지할 수 없어 즉각적인 대처가 불가능하다. 청각 장애우뿐 아니라, 이어폰 착용 보행자, 고령자 등 청감각이 없거나 제한된 상황에서는 사용자 주변에서 발생하는 음향이 차단될 수 있다. 추가적으로, 사용자가 수면을 취하는 등 음향을 감지하기 어려운 상황에서는 주변 상황을 인지하지 못하여 위험한 상황에 처하거나, 사고를 당할 우려가 있다. 한편, 이러한 환경속에서 음향 이벤트를 검출하고 인식하는 기술 개발에 대한 필요성이 대두되고 있다. 음향 이 벤트를 검출하고 인식하는 기술은, 실생활 환경 컨텍스트 인식, 위험상황 인식, 미디어 콘텐츠 인식, 유선 통신 상의 상황분석 등 다양한 분야에 응용 가능한 기술로 지속적으로 연구되고 있다. 음향 이벤트 인식 기술로는, 오디오 신호로부터 MFCC, energy, spectral flux, zero crossing rate 등 다양한 특징 값을 추출하여 우수한 특징을 검증하는 연구와 Gaussian mixture model 또는 rule 기반의 분류 방법 등에 대한 연구가 주를 이루고 있으며, 최근에는 상기 방법들을 개선하기 위해 딥러닝 기반의 기계학습 방법이 연구 되고 있다. 그러나, 이러한 방법들은 낮은 신호대비 잡음비에서 음향 검출의 정확도가 보장되며, 주변 잡음과 사건 음향을 구별하는데 어렵다는 한계점을 가진다. 즉, 다양한 주변 노이즈를 포함하는 실생활 환경에서는 신뢰도 높은 음향 이벤트 검출이 어려울 수 있다. 구체 적으로, 유효한 음향 이벤트를 검출하기 위해서는 시계열적(즉, 연속적)으로 획득되는 음향 데이터에 대해 음향 이벤트가 발생했는지 여부를 판단해야 하며, 이와 함께 어떠한 이벤트 클래스가 발생했는지도 인식해야 하기 때 문에 높은 신뢰도를 담보하기 어려울 수 있다. 또한, 둘 이상의 이벤트가 동시에 발생하는 경우, 단일 이벤트 (monophonic)가 아닌 다중 이벤트(polyphonic) 인식 문제까지 해결해야 하므로, 음향 이벤트의 인식률이 더 낮 아질 수 있다. 또한, 실생활에서 획득된 음향 데이터에서 음향 이벤트를 검출 시, 낮은 인식률을 보이는 이유는, 음향 이벤트 가 발생하지 않았음에도 이벤트가 존재한다고 판단하거나, 이벤트가 발생했음에도 이벤트가 존재하지 않는다고판단할 확률 즉, 오류 검출(false alarm) 확률이 존재하기 때문이다. 따라서, 시계열적으로 획득되는 음향 데이터에 대응하여 오류 검출 확률을 감소시키는 경우, 실생활 환경에서 향상된 신뢰도를 가진 음향 이벤트 검출이 가능해질 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 10-2014-0143069"}
{"patent_id": "10-2022-0180494", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 상술한 문제점을 해결하기 위한 것으로서, 음향 데이터에 관련한 후처리 보 정을 통해 향상된 정확도를 가진 음향 데이터 인식 환경을 제공하기 위함이다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0180494", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 다양한 실시예에 따른 음향 데이터의 인식 정확도를 향상시키기 위한 방법을 개시한다. 상기 방법은, 음향 데이터에 기초하여 하나 이상의 음향 프레임을 구성하는 단계, 상기 하나 이상의 음향 프레임 각각을 음향 인식 모델의 입력으로 처리하여 각 음향 프레임에 대응하는 예측값을 출력하는 단계, 상기 각 음향 프레임에 대응하는 예측값에 기초한 임계값 분석을 통해 하나 이상의 인식 음향 프레임을 식별하는 단계, 상기 하나 이상의 인식 음향 프레임에 기초한 시계열 분석을 통해 변환 음향 프레임을 식별하는 단계 및 상기 변환 음향 프레임에 대응하는 예측값에 대한 변환을 수행하는 단계를 포함할 수 있다. 대안적인 실시예에서, 상기 음향 데이터에 기초하여 하나 이상의 음향 프레임을 구성하는 단계는, 상기 음향 데 이터를 미리 정해진 제1시간 단위의 크기를 갖도록 분할하여 상기 하나 이상의 음향 프레임을 구성하는 단계를 포함할 수 있다. 대안적인 실시예에서, 상기 하나 이상의 음향 프레임 각각의 시작 시점은, 인접한 음향 프레임 각각의 시작 시 점과 제2시간 단위의 크기 차이를 갖도록 결정되는 것을 특징으로 할 수 있다. 대안적인 실시예에서, 상기 예측값은, 하나 이상의 예측 항목 정보 및 상기 하나 이상의 예측 항목 정보 각각에 대응하는 예측 수치 정보를 포함하며, 상기 임계값 분석은, 상기 각 음향 프레임에 대응하는 하나 이상의 예측 수치 정보 각각이, 상기 각 예측 항목 정보에 대응하여 미리 정해진 임계값 이상인지 여부를 판별하여 상기 하 나 이상의 인식 음향 프레임을 식별하는 분석일 수 있다. 대안적인 실시예에서, 상기 시계열 분석을 통해 변환 음향 프레임을 식별하는 단계는, 상기 하나 이상의 인식 음향 프레임 각각에 대응하는 예측 항목 정보를 식별하는 단계, 상기 식별된 예측 항목 정보가 미리 정해진 기 준 시간 동안 미리 정해진 임계 횟수 이상 반복되는지 여부를 판별하는 단계 및 상기 판별 결과에 기초하여 상 기 변환 음향 프레임을 식별하는 단계를 포함할 수 있다. 대안적인 실시예에서, 상기 방법은, 하나 이상의 인식 음향 프레임 각각에 대응하는 예측 항목 정보에 기초하여 각 인식 음향 프레임 간의 연관 관계를 식별하는 단계, 상기 연관 관계에 기초하여 상기 하나 이상의 음향 프레 임 각각에 대응하는 임계값 및 임계 횟수의 조정 여부를 결정하는 단계를 포함할 수 있다. 대안적인 실시예에서, 상기 예측값에 대한 변환은, 상기 변환 음향 프레임에 기초한 상기 음향 인식 모델의 출 력을 인식 미대상 항목으로 변환하는 잡음 변환 및 상기 변환 음향 프레임에 관련한 예측 항목 정보를 교정 예 측 항목 정보로 변환하는 음향 항목 변환 중 적어도 하나를 포함할 수 있다. 대안적인 실시예에서, 상기 교정 예측 항목 정보는, 상기 예측 항목 정보의 연관 관계에 기초하여 결정되는 것 을 특징으로 할 수 있다. 본 발명의 다른 실시예에 따르면, 음향 데이터의 인식 정확도를 향상시키기 위한 방법을 수행하는 장치가 개시 된다. 상기 장치는, 하나 이상의 인스트럭션을 저장하는 메모리 및 상기 메모리에 저장된 상기 하나 이상의 인 스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 전 술한 음향 데이터의 인식 정확도를 향상시키기 위한 방법을 수행할 수 있다. 본 발명의 또 다른 실시예에 따르면, 컴퓨터에서 독출가능한 기록매체에 저장된 컴퓨터 프로그램이 개시된다. 상기 컴퓨터 프로그램은 하드웨어인 컴퓨터와 결합되어, 전술한 음향 데이터의 인식 정확도를 향상시키기 위한 방법을 수행할 수 있다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2022-0180494", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 다양한 실시예에 따라, 음향 데이터에 대한 보정을 통해 음향 데이터의 인식 정확도를 향상시키는 효 과를 제공할 수 있다."}
{"patent_id": "10-2022-0180494", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0180494", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다양한 실시예들이 이제 도면을 참조하여 설명된다. 본 명세서에서, 다양한 설명들이 본 발명의 이해를 제공하 기 위해서 제시된다. 그러나, 이러한 실시예들은 이러한 구체적인 설명 없이도 실행될 수 있음이 명백하다. 본 명세서에서 사용되는 용어 \"컴포넌트\", \"모듈\", \"시스템\" 등은 컴퓨터-관련 엔티티, 하드웨어, 펌웨어, 소프 트웨어, 소프트웨어 및 하드웨어의 조합, 또는 소프트웨어의 실행을 지칭한다. 예를 들어, 컴포넌트는 프로세서 상에서 실행되는 처리과정(procedure), 프로세서, 객체, 실행 스레드, 프로그램, 및/또는 컴퓨터일 수 있지만, 이들로 제한되는 것은 아니다. 예를 들어, 컴퓨팅 장치에서 실행되는 애플리케이션 및 컴퓨팅 장치 모두 컴포넌 트일 수 있다. 하나 이상의 컴포넌트는 프로세서 및/또는 실행 스레드 내에 상주할 수 있다. 일 컴포넌트는 하 나의 컴퓨터 내에 로컬화 될 수 있다. 일 컴포넌트는 2개 이상의 컴퓨터들 사이에 분배될 수 있다. 또한, 이러 한 컴포넌트들은 그 내부에 저장된 다양한 데이터 구조들을 갖는 다양한 컴퓨터 판독가능한 매체로부터 실행할수 있다. 컴포넌트들은 예를 들어 하나 이상의 데이터 패킷들을 갖는 신호(예를 들면, 로컬 시스템, 분산 시스 템에서 다른 컴포넌트와 상호작용하는 하나의 컴포넌트로부터의 데이터 및/또는 신호를 통해 다른 시스템과 인 터넷과 같은 네트워크를 통해 전송되는 데이터)에 따라 로컬 및/또는 원격 처리들을 통해 통신할 수 있다. 더불어, 용어 \"또는\"은 배타적 \"또는\"이 아니라 내포적 \"또는\"을 의미하는 것으로 의도된다. 즉, 달리 특정되지 않거나 문맥상 명확하지 않은 경우에, \"X는 A 또는 B를 이용한다\"는 자연적인 내포적 치환 중 하나를 의미하는 것으로 의도된다. 즉, X가 A를 이용하거나; X가 B를 이용하거나; 또는 X가 A 및 B 모두를 이용하는 경우, \"X는 A 또는 B를 이용한다\"가 이들 경우들 어느 것으로도 적용될 수 있다. 또한, 본 명세서에 사용된 \"및/또는\"이라 는 용어는 열거된 관련 아이템들 중 하나 이상의 아이템의 가능한 모든 조합을 지칭하고 포함하는 것으로 이해 되어야 한다. 또한, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 해당 특징 및/또는 구성요소가 존재함을 의미하는 것으로 이해되어야 한다. 다만, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 하나 이상의 다른 특징, 구성요소 및/또 는 이들의 그룹의 존재 또는 추가를 배제하지 않는 것으로 이해되어야 한다. 또한, 달리 특정되지 않거나 단수 형태를 지시하는 것으로 문맥상 명확하지 않은 경우에, 본 명세서와 청구범위에서 단수는 일반적으로 \"하나 또 는 그 이상\"을 의미하는 것으로 해석되어야 한다. 당업자들은 추가적으로 여기서 개시된 실시예들과 관련되어 설명된 다양한 예시적 논리적 블록들, 구성들, 모듈 들, 회로들, 수단들, 로직들, 및 알고리즘 단계들이 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양쪽 모두의 조합 들로 구현될 수 있음을 인식해야 한다. 하드웨어 및 소프트웨어의 상호교환성을 명백하게 예시하기 위해, 다양 한 예시적 컴포넌트들, 블록들, 구성들, 수단들, 로직들, 모듈들, 회로들, 및 단계들은 그들의 기능성 측면에서 일반적으로 위에서 설명되었다. 그러한 기능성이 하드웨어로 또는 소프트웨어로서 구현되는지 여부는 전반적인 시스템에 부과된 특정 어플리케이션(application) 및 설계 제한들에 달려 있다. 숙련된 기술자들은 각각의 특정 어플리케이션들을 위해 다양한 방법들로 설명된 기능성을 구현할 수 있다. 다만, 그러한 구현의 결정들이 본 발 명의 영역을 벗어나게 하는 것으로 해석되어서는 안된다. 제시된 실시예들에 대한 설명은 본 발명의 기술 분야에서 통상의 지식을 가진 자가 본 발명을 이용하거나 또는 실시할 수 있도록 제공된다. 이러한 실시예들에 대한 다양한 변형들은 본 발명의 기술 분야에서 통상의 지식을 가진 자에게 명백할 것이다. 여기에 정의된 일반적인 원리들은 본 발명의 범위를 벗어남이 없이 다른 실시예들 에 적용될 수 있다. 그리하여, 본 발명은 여기에 제시된 실시예들로 한정되는 것이 아니다. 본 발명은 여기에 제시된 원리들 및 신규한 특징들과 일관되는 최광의의 범위에서 해석되어야 할 것이다. 본 명세서에서, 컴퓨터는 적어도 하나의 프로세서를 포함하는 모든 종류의 하드웨어 장치를 의미하는 것이고, 실시 예에 따라 해당 하드웨어 장치에서 동작하는 소프트웨어적 구성도 포괄하는 의미로서 이해될 수 있다. 예 를 들어, 컴퓨터는 스마트폰, 태블릿 PC, 데스크톱, 노트북 및 각 장치에서 구동되는 사용자 클라이언트 및 애 플리케이션을 모두 포함하는 의미로서 이해될 수 있으며, 또한 이에 제한되는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 본 명세서에서 설명되는 각 단계들은 컴퓨터에 의하여 수행되는 것으로 설명되나, 각 단계의 주체는 이에 제한 되는 것은 아니며, 실시 예에 따라 각 단계들의 적어도 일부가 서로 다른 장치에서 수행될 수도 있다. 여기서, 본 발명의 다양한 실시예에 따른 음향 데이터의 인식 정확도를 향상시키기 위한 방법은, 음향 데이터의 인식률이 향상되도록 음향 데이터를 보정하는 방법에 관련한 것일 수 있다. 음향 데이터에 대한 보정은 예컨대, 음향 데이터에 관련한 후처리 보정을 의미할 수 있다. 즉, 본 발명은 시계열적인 음향 데이터를 획득하는 경우, 해당 음향 데이터에 대한 후처리 보정을 수행하여 음향 데이터의 인식 과정에서 정확도를 향상시킬 수 있다. 실 시예에서, 음향 데이터의 인식 정확도 향상은, 음향 데이터에서 특정 이벤트를 감지하는 인식 정확도가 향상됨 을 의미할 수 있다. 한편, 음향 데이터에서 특정 이벤트를 높은 정확도를 통해 감지 또는 인식하기 위해서는 오류 검출의 확률을 저 감시키는 것이 중요할 수 있다. 여기서 오류 검출 확률이란, 음향 이벤트가 발생하지 않았음에도 이벤트가 존재 한다고 판단하거나, 또는 이벤트가 발생했음에도 이벤트가 존재하지 않는다도 판단할 확률에 관련한 것일 수 있 다. 실시예에 따르면, 음향 데이터의 인식 정확도를 향상시키기 위한 방법은, 음향 데이터의 오류 검출 확률을 최소 화시키기 위하여, 음향 데이터를 일정 시간 단위를 가진 복수의 음향 프레임 각각으로 분할하고, 분할된 음향 프레임 각각에 대응하는 음향 인식을 통해 음향 데이터 인식의 정확도 향상을 도모할 수 있다. 이 경우, 각 음 향 프레임은 다른 음향 프레임과 적어도 일부의 중첩 구간을 가질 수 있다. 즉, 본 발명은 시계열 정보인 음향 데이터를 일정 시간 단위로 세분화하여 복수의 음향 프레임을 구성하고, 각 음향 프레임에 대한 분석을 수행할 수 있으며, 분석 결과 복수의 음향 프레임 중 적어도 일부의 음향 프레임에 대한 변환을 수행할 수 있다. 예컨 대, 복수의 음향 프레임 중 적어도 둘 이상의 음향 프레임에 걸쳐 특정 음향(예컨대, 사이렌 소리)이 인식되는 경우에만, 특정 음향이 인식된 것으로 판단할 수 있다. 다시 말해, 복수의 음향 프레임 중 특정 음향 프레임에 서만 특정 음향(예컨대, 사이렌 소리)가 인식되는 경우(즉, 특정 음향 프레임과 인접한 음향 프레임에서는 특정 음향이 인식되지 않은 경우)에는, 특정 음향이 인식되지 않은 것으로 판단하여 해당 음향 프레임에 관련한 변환 을 수행할 수 있다. 여기서 음향 프레임에 관련한 변환이란, 예를 들어, 특정 음향 프레임에 관련하여 인식된 음향(예컨대, 사이렌 소리)이 오인식된 음향이므로, 해당 음향을 인식하지 않은것으로 변환하는 것이나, 또는 다른 음향(예컨대, 인식에 연관되지 않은 음향)으로 변환하는 것을 의미할 수 있다. 즉, 한 프레임에서만 인식 된 소리는 오류로 제거할 수 있으며, 프레임들에 관련하여 연속적으로 인식되는 소리를 정상적으로 인식된 것으 로 판단할 수 있다. 정리하면, 본 발명 음향 데이터를 프레임 단위로 세분화하고, 각 프레임들에 관련하여 연속적으로 인식되지 않 는 소리는 오인식된 소리로 판단하여 후처리 보정을 수행함으로써, 전체 음향 데이터의 인식 정확도를 향상시킬 수 있다. 음향 데이터의 인식 정확도를 향상시키는 방법에 관련한 보다 구체적인 설명은, 이하에서 자세하게 후 술하도록 한다. 도 1은 본 발명의 일 실시예에 따른 음향 데이터의 인식 정확도를 향상시키기 위한 방법을 수행하기 위한 시스 템을 개략적으로 나타낸 도면이다. 도 1에 도시된 바와 같이, 본 발명의 일 실시예에 따른 음향 데이터의 인식 정확도를 향상시키기 위한 방법을 수행하기 위한 시스템은, 음향 데이터의 인식 정확도를 향상시키기 위한 서버 , 사용자 단말 및 외부 서버를 포함할 수 있다. 여기서, 도 1에 도시된 음향 데이터의 인식 정 확도를 향상시키기 위한 방법을 수행하기 위한 시스템은 일 실시예에 따른 것이고, 그 구성 요소가 도 1에 도시 된 실시예에 한정되는 것은 아니며, 필요에 따라 부가, 변경 또는 삭제될 수 있다. 일 실시예에서, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 음향 데이터에 기반하여 특정 이벤 트가 발생하였는지 여부를 판별할 수 있다. 구체적으로, 음향 데이터의 인식 정확도를 향상시키기 위한 서버 는 실생활에 관련한 음향 데이터를 획득하고, 획득한 음향 데이터에 대한 분석을 통해 특정 이벤트가 발생 하였는지 여부를 판별할 수 있다. 일 실시예에서, 특정 이벤트는, 보안, 안전 또는 위험 발생에 관련한 것으로, 예컨대, 경보 소리, 아이의 울음 소리, 유리 깨지는 소리, 타이어 펑크 나는 소리 등의 발생에 관련한 것일 수 있다. 전술한 특정 이벤트에 관련한 음향에 대한 구체적인 기재는 일 예시일 뿐, 본 발명은 이에 제한되지 않는 다. 실시예에 따르면, 실생활에서 획득되는 음향 데이터는 다양한 주변 노이즈를 포함하고 있으므로, 신뢰도 높은 음향 이벤트 검출이 어려울 수 있다. 이에 따라, 본 발명의 음향 데이터의 인식 정확도를 향상시키기 위한 서버 는 음향 데이터를 수신하는 경우, 해당 음향 데이터에 대한 후처리 보정을 수행할 수 있다. 여기서 후처리 보정이란, 음향 데이터의 인식 과정에서 오류 검출 확률을 저감시키기 위한 보정을 의미할 수 있다, 예컨대, 후 처리 보정은, 음향 데이터의 일부 구간에서 인식된 소리(예컨대, 유리 깨지는 소리)를 인식되지 않은 것으로 변 환(즉, 노이즈로 처리)하거나 또는, 인식된 음향 결과를 다른 음향으로 변환하는 것을 포함할 수 있다. 즉, 음 향 데이터의 인식 정확도를 향상시키기 위한 서버는, 실생활에 관련한 시계열적인 음향 데이터를 획득하고, 획득한 음향 데이터에 대한 후처리 보정을 통해 향상된 인식 정확도를 담보할 수 있다. 실시예에 따르면, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 API(Application Programming Interface)에 의해 구현되는 임의의 서버를 포함할 수 있다. 예컨대, 사용자 단말은 음향 데이터를 획득하 여 API를 통해 서버로 전달할 수 있다. 예컨대, 서버는 사용자 단말로부터 음향 데이터를 획득 할 수 있으며, 음향 데이터에 대한 분석을 통해 비상 경보 소리(예컨대, 사이렌 소리)가 발생하였다고 판단할 수 있다. 실시예에서, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 음향 인식 모델(예: 인공지능 모델)을 통해 음향 데이터에 대한 분석을 수행할 수 있다. 일 실시예에서, 음향 인식 모델(예: 인공지능 모델)은 하나 이상의 네트워크 함수로 구성되며, 하나 이상의 네 트워크 함수는 일반적으로 ‘노드’라 지칭될 수 있는 상호 연결된 계산 단위들의 집합으로 구성될 수 있다. 이러한 ‘노드’들은 ‘뉴런(neuron)’들로 지칭될 수도 있다. 하나 이상의 네트워크 함수는 적어도 하나 이상의 노드들을 포함하여 구성된다. 하나 이상의 네트워크 함수를 구성하는 노드(또는 뉴런)들은 하나 이상의 ‘링크 ’에 의해 상호 연결될 수 있다. 인공지능 모델 내에서, 링크를 통해 연결된 하나 이상의 노드들은 상대적으로 입력 노드 및 출력 노드의 관계를 형성할 수 있다. 입력 노드 및 출력 노드의 개념은 상대적인 것으로서, 하나의 노드에 대하여 출력 노드 관계에 있는 임의의 노드는 다른 노드와의 관계에서 입력 노드 관계에 있을 수 있으며, 그 역도 성립할 수 있다. 전술 한 바와 같이, 입력 노드 대 출력 노드 관계는 링크를 중심으로 생성될 수 있다. 하나의 입력 노드에 하나 이상 의 출력 노드가 링크를 통해 연결될 수 있으며, 그 역도 성립할 수 있다. 하나의 링크를 통해 연결된 입력 노드 및 출력 노드 관계에서, 출력 노드는 입력 노드에 입력된 데이터에 기초 하여 그 값이 결정될 수 있다. 여기서 입력 노드와 출력 노드를 상호 연결하는 노드는 가중치(weight)를 가질 수 있다. 가중치는 가변적일 수 있으며, 인공지능 모델이 원하는 기능을 수행하기 위해, 사용자 또는 알고리즘 에 의해 가변될 수 있다. 예를 들어, 하나의 출력 노드에 하나 이상의 입력 노드가 각각의 링크에 의해 상호 연 결된 경우, 출력 노드는 상기 출력 노드와 연결된 입력 노드들에 입력된 값들 및 각각의 입력 노드들에 대응하 는 링크에 설정된 가중치에 기초하여 출력 노드 값을 결정할 수 있다. 전술한 바와 같이, 인공지능 모델은 하나 이상의 노드들이 하나 이상의 링크를 통해 상호연결 되어 인공지능 모 델 내에서 입력 노드 및 출력 노드 관계를 형성한다. 인공지능 모델 내에서 노드들과 링크들의 개수 및 노드들 과 링크들 사이의 연관관계, 링크들 각각에 부여된 가중치의 값에 따라, 인공지능 모델의 특성이 결정될 수 있 다. 예를 들어, 동일한 개수의 노드 및 링크들이 존재하고, 링크들 사이의 가중치 값이 상이한 두 인공지능 모 델이 존재하는 경우, 두 개의 인공지능 모델들은 서로 상이한 것으로 인식될 수 있다. 인공지능 모델을 구성하는 노드들 중 일부는, 최초 입력 노드로부터의 거리들에 기초하여, 하나의 레이어 (layer)를 구성할 수 있다. 예를 들어, 최초 입력 노드로부터 거리가 n인 노드들의 집합은, n 레이어를 구성할 수 있다. 최초 입력 노드로부터 거리는, 최초 입력 노드로부터 해당 노드까지 도달하기 위해 거쳐야 하는 링크 들의 최소 개수에 의해 정의될 수 있다. 그러나, 이러한 레이어의 정의는 설명을 위한 임의적인 것으로서, 인공 지능 모델 내에서 레이어의 차수는 전술한 것과 상이한 방법으로 정의될 수 있다. 예를 들어, 노드들의 레이어 는 최종 출력 노드로부터 거리에 의해 정의될 수도 있다. 최초 입력 노드는 인공지능 모델 내의 노드들 중 다른 노드들과의 관계에서 링크를 거치지 않고 데이터가 직접 입력되는 하나 이상의 노드들을 의미할 수 있다. 또는, 인공지능 모델 네트워크 내에서, 링크를 기준으로 한 노 드 간의 관계에 있어서, 링크로 연결된 다른 입력 노드들 가지지 않는 노드들을 의미할 수 있다. 이와 유사하게, 최종 출력 노드는 인공지능 모델 내의 노드들 중 다른 노드들과의 관계에서, 출력 노드를 가지지 않 는 하나 이상의 노드들을 의미할 수 있다. 또한, 히든 노드는 최초 입력 노드 및 최후 출력 노드가 아닌 인공지 능 모델을 구성하는 노드들을 의미할 수 있다. 본 발명의 일 실시예에 따른 인공지능 모델은 입력 레이어의 노 드가 출력 레이어에 가까운 히든 레이어의 노드보다 많을 수 있으며, 입력 레이어에서 히든 레이어로 진행됨에 따라 노드의 수가 감소하는 형태의 인공지능 모델일 수 있다. 인공지능 모델은 하나 이상의 히든 레이어를 포함할 수 있다. 히든 레이어의 히든 노드는 이전의 레이어의 출력 과 주변 히든 노드의 출력을 입력으로 할 수 있다. 각 히든 레이어 별 히든 노드의 수는 동일할 수도 있고 상이 할 수도 있다. 입력 레이어의 노드의 수는 입력 데이터의 데이터 필드의 수에 기초하여 결정될 수 있으며 히든 노드의 수와 동일할 수도 있고 상이할 수도 있다. 입력 레이어에 입력된 입력 데이터는 히든 레이어의 히든 노 드에 의하여 연산될 수 있고 출력 레이어인 완전 연결 레이어(FCL: fully connected layer)에 의해 출력될 수 있다. 다양한 실시예에서, 인공지능 모델은, 복수의 음향 데이터와 각 음향 데이터에 대응하는 특징정보를 학습 데이 터로 하여 지도학습(supervised learning)될 수 있다. 그러나, 이에 한정되지 않고, 다양한 학습 방법이 적용될 수 있다. 여기서, 지도학습은 통상적으로 특정 데이터와 특정 데이터에 연관된 정보를 라벨링하여 학습 데이터를 생성하 고, 이를 이용하여 학습시키는 방법으로써, 인과 관계를 가진 두 데이터를 라벨링하여 학습 데이터를 생성하고, 생성된 학습 데이터를 통해 학습하는 방법을 의미한다. 일 실시예에서, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 하나 이상의 네트워크 함수의 학습 이 사전 결정된 에폭 이상 수행된 경우, 검증 데이터를 이용하여 학습의 중단 여부를 결정할 수 있다. 사전 결정된 에폭은 전체 학습 목표 에폭의 일부일 수 있다. 검증 데이터는 라벨링된 학습 데이터 중 적어도 일부로 구성될 수 있다. 즉 음향 데이터의 인식 정확도를 향상 시키기 위한 서버는 학습 데이터를 통해 인공지능 모델의 학습을 수행하며, 인공지능 모델의 학습이 사전 결정된 에폭 이상 반복된 후, 검증 데이터를 이용하여 인공지능 모델의 학습 효과가 사전 결정된 수준 이상인지 여부를 판단할 수 있다. 예를 들어, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 100개의 학습 데이터를 이용하여 목표 반복 학습 횟수가 10회인 학습을 수행하는 경우, 사전결정된 에폭인 10회의 반복 학습 을 수행한 후, 10개의 검증 데이터를 이용하여 3회의 반복 학습을 수행하여, 3회의 반복 학습 동안 인공지능 모 델 출력의 변화가 사전결정된 수준 이하인 경우 더 이상의 학습이 무의미한 것으로 판단하고 학습을 종료할 수 있다. 즉, 검증 데이터는 인공지능 모델의 반복 학습에서 에폭별 학습의 효과가 일정 이상인지 이하인지 여부에 기초 하여 학습의 완료를 결정하는 데 이용될 수 있다. 전술한 학습 데이터, 검증 데이터의 수 및 반복 횟수는 예시 일 뿐이며 본 발명은 이에 제한되지 않는다. 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 테스트 데이터를 이용하여 하나 이상의 네트워크 함 수의 성능을 테스트하여 하나 이상의 네트워크 함수의 활성화 여부를 결정함으로써, 인공지능 모델을 생성할 수 있다. 테스트 데이터는 인공지능 모델의 성능을 검증하기 위하여 사용될 수 있으며, 학습 데이터 중 적어도 일 부로 구성될 수 있다. 예를 들어, 학습 데이터 중 70%는 인공지능 모델의 학습(즉, 레이블과 비슷한 결과값을 출력하도록 가중치를 조정하기 위한 학습)을 위해 활용될 수 있으며, 30%는 인공지능 모델의 성능을 검증하기 위한 테스트 데이터로써 활용될 수 있다. 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 학습이 완 료된 인공지능 모델에 테스트 데이터를 입력하고 오차를 측정하여 사전 결정된 성능 이상인지 여부에 따라 인공 지능 모델의 활성화 여부를 결정할 수 있다. 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 학습이 완료된 인공지능 모델에 테스트 데이터를 이 용하여 학습 완료된 인공지능 모델의 성능을 검증하고 학습 완료된 인공지능 모델의 성능이 사전에 결정된 기준 이상인 경우 해당 인공지능 모델을 다른 어플리케이션에서 사용하도록 활성화할 수 있다. 또한, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 학습 완료된 인공지능 모델의 성능이 사전에 결정된 기준 이하인 경우 해당 인공지능 모델을 비활성화하여 폐기할 수 있다. 예를 들어, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 정확도(accuracy), 정밀도(precision), 재현율(recall) 등의 요소를 기 준으로 하여 생성된 인공지능 모델 모델의 성능을 판단할 수 있다. 전술한 성능 평가 기준은 예시일 뿐이며 본 발명은 이에 제한되지 않는다. 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 각각의 인공지능 모 델을 독립적으로 학습시켜 복수의 인공지능 모델 모델을 생성할 수 있으며, 성능을 평가하여 일정 성능 이상의 인공지능 모델만을 사용할 수 있다. 그러나, 이에 한정되지 않는다. 본 명세서에 걸쳐, 연산 모델, 신경망, 네트워크 함수, 뉴럴 네트워크(neural network)는 동일한 의미로 사용될 수 있다. (이하에서는 신경망으로 통일하여 기술한다.) 데이터 구조는 신경망을 포함할 수 있다. 그리고 신경망 을 포함한 데이터 구조는 컴퓨터 판독가능 매체에 저장될 수 있다. 신경망을 포함한 데이터 구조는 또한 신경망 에 입력되는 데이터, 신경망의 가중치, 신경망의 하이퍼 파라미터, 신경망으로부터 획득한 데이터, 신경망의 각 노드 또는 레이어와 연관된 활성 함수, 신경망의 학습을 위한 손실 함수를 포함할 수 있다. 신경망을 포함한 데 이터 구조는 상기 개시된 구성들 중 임의의 구성 요소들을 포함할 수 있다. 즉, 신경망을 포함한 데이터 구조는 신경망에 입력되는 데이터, 신경망의 가중치, 신경망의 하이퍼 파라미터, 신경망으로부터 획득한 데이터, 신경 망의 각 노드 또는 레이어와 연관된 활성 함수, 신경망의 트레이닝을 위한 손실 함수 등 전부 또는 이들의 임의 의 조합을 포함하여 구성될 수 있다. 전술한 구성들 이외에도, 신경망을 포함한 데이터 구조는 신경망의 특성을 결정하는 임의의 다른 정보를 포함할 수 있다. 또한, 데이터 구조는 신경망의 연산 과정에 사용되거나 발생되는 모든 형태의 데이터를 포함할 수 있으며 전술한 사항에 제한되는 것은 아니다. 컴퓨터 판독가능 매체는 컴퓨터 판독가능 기록 매체 및/또는 컴퓨터 판독가능 전송 매체를 포함할 수 있다. 신경망은 일반적으로 노드라 지칭될 수 있는 상호 연결된 계산 단위들의 집합으로 구성될 수 있다. 이러한 노드들은 뉴런(neuron)들로 지칭될 수도 있다. 신경망은 적어도 하나 이상의 노드들을 포함하여 구성된다. 본 발명의 일 실시예에 따르면, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 클라우드 컴퓨팅 서 비스를 제공하는 서버일 수 있다. 보다 구체적으로, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 인터넷 기반 컴퓨팅의 일종으로 정보를 사용자의 컴퓨터가 아닌 인터넷에 연결된 다른 컴퓨터로 처리하는 클라 우드 컴퓨팅 서비스를 제공하는 서버일 수 있다. 상기 클라우드 컴퓨팅 서비스는 인터넷 상에 자료를 저장해 두고, 사용자가 필요한 자료나 프로그램을 자신의 컴퓨터에 설치하지 않고도 인터넷 접속을 통해 언제 어디서나 이용할 수 있는 서비스일 수 있으며, 인터넷 상에 저장된 자료들을 간단한 조작 및 클릭으로 쉽게 공유하고 전 달할 수 있다. 또한, 클라우드 컴퓨팅 서비스는 인터넷 상의 서버에 단순히 자료를 저장하는 것뿐만 아니라, 별 도로 프로그램을 설치하지 않아도 웹에서 제공하는 응용프로그램의 기능을 이용하여 원하는 작업을 수행할 수 있으며, 여러 사람이 동시에 문서를 공유하면서 작업을 진행할 수 있는 서비스일 수 있다. 또한, 클라우드 컴퓨 팅 서비스는 IaaS(Infrastructure as a Service), PaaS(Platform as a Service), SaaS(Software as a Service), 가상 머신 기반 클라우드 서버 및 컨테이너 기반 클라우드 서버 중 적어도 하나의 형태로 구현될 수 있다. 즉, 본 발명의 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 상술한 클라우드 컴퓨팅 서비 스 중 적어도 하나의 형태로 구현될 수 있다. 전술한 클라우드 컴퓨팅 서비스의 구체적인 기재는 예시일 뿐, 본 발명은 클라우드 컴퓨팅 환경을 구축하는 임의의 플랫폼을 포함할 수도 있다. 다양한 실시예에서, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 네트워크를 통해 사용자 단말 과 연결될 수 있고, 음향 데이터를 분석하는 음향 인식 모델을 생성하여 제공할 수 있으며, 뿐만 아니라, 음향 인식 모델을 통해 음향 데이터를 분석한 정보(예컨대, 음향 이벤트 정보)를 사용자 단말로 제공수 있다. 여기서, 네트워크는 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의 미할 수 있다. 예를 들어, 네트워크는 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷(WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한 다. 또한, 여기서, 무선 데이터 통신망은 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), 5GPP(5th Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency), 블루투스(Bluetooth) 네트워크, NFC(Near-Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 일 실시예에서, 사용자 단말은 네트워크를 통해 음향 데이터의 인식 정확도를 향상시키기 위한 서버 와 연결될 수 있으며, 음향 데이터의 인식 정확도를 향상시키기 위한 서버로 음향 데이터를 제공할 수 있 고, 제공된 음향 데이터에 대한 응답으로 각종 이벤트 발생(예를 들어, 경보 소리, 아이의 울음 소리, 유리 깨 지는 소리, 타이어 펑크 나는 소리 등의 발생)에 관련한 정보를 제공받을 수 있다. 여기서, 사용자 단말은 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있으나, 이에 한 정되지 않는다. 예컨대, 사용자 단말은, 특정 영역에 관련한 감지를 수행하기 위하여 특정 영역에 구비될 수 있다. 예를 들어, 사용자 단말은 차량에 구비되어 차량이 주차 중 또는 주행 중 발생하는 음향 데이터 를 획득할 수 있다. 전술한 사용자 단말이 구비되는 구체적인 위치 또는 장소에 관한 설명은 예시일 뿐, 본 발 명은 이에 제한되지 않는다. 일 실시예에서, 외부 서버는 네트워크를 통해 음향 데이터의 인식 정확도를 향상시키기 위한 서버와 연결될 수 있으며, 음향 데이터의 인식 정확도를 향상시키기 위한 서버가 인공지능 모델을 활용하여 음향 데이터를 분석하기 위해 필요한 각종 정보/데이터를 제공하거나, 인공지능 모델을 활용한 음향 데이터 분석을 수행함에 따라 도출되는 결과 데이터를 제공받아 저장 및 관리할 수 있다. 예를 들어, 외부 서버는 음향 데이터의 인식 정확도를 향상시키기 위한 서버의 외부에 별도로 구비되는 저장 서버일 수 있으나, 이에 한 정되지 않는다. 이하 도 2를 참조하여 음향 데이터의 인식 정확도를 향상시키기 위한 서버의 하드웨어 구 성에 대해 설명하도록 한다. 도 2는 본 발명의 일 실시예와 관련된 음향 데이터의 인식 정확도를 향상시키기 위한 서버의 하드웨어 구성도이 다.도 2를 참조하면, 본 발명의 일 실시예에 따른 음향 데이터의 인식 정확도를 향상시키기 위한 서버(이하, “서버”)는 하나 이상의 프로세서, 프로세서에 의하여 수행되는 컴퓨터 프로그램을 로드 (Load)하는 메모리, 버스, 통신 인터페이스 및 컴퓨터 프로그램을 저장하는 스토리지(15 0)를 포함할 수 있다. 여기서, 도 2에는 본 발명의 실시예와 관련 있는 구성요소들만 도시되어 있다. 따라서,"}
{"patent_id": "10-2022-0180494", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명이 속한 기술분야의 통상의 기술자라면 도 2에 도시된 구성요소들 외에 다른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 프로세서는 서버의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발 명의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성될 수 있다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 판독하여 본 발명의 일 실시예에 따른 인공지능 모델 을 위한 데이터 처리를 수행할 수 있다. 본 발명의 일 실시예에 따라 프로세서는 신경망의 학습을 위한 연 산을 수행할 수 있다. 프로세서는 딥러닝(DL: deep learning)에서 학습을 위한 입력 데이터의 처리, 입력 데이터에서의 피처 추출, 오차 계산, 역전파(backpropagation)를 이용한 신경망의 가중치 업데이트 등의 신경망 의 학습을 위한 계산을 수행할 수 있다. 또한, 프로세서는 CPU, GPGPU, 및 TPU 중 적어도 하나가 네트워크 함수의 학습을 처리할 수 있다. 예를 들 어, CPU 와 GPGPU가 함께 네트워크 함수의 학습, 네트워크 함수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 발명의 일 실시예에서 복수의 컴퓨팅 장치의 프로세서를 함께 사용하여 네트워크 함수의 학습, 네트워크 함 수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 발명의 일 실시예에 따른 컴퓨팅 장치에서 수행되는 컴퓨 터 프로그램은 CPU, GPGPU 또는 TPU 실행가능 프로그램일 수 있다. 본 명세서에서 네트워크 함수는 인공 신경망, 뉴럴 네트워크와 상호 교환 가능하게 사용될 수 있다. 본 명세서 에서 네트워크 함수는 하나 이상의 뉴럴 네트워크를 포함할 수도 있으며, 이 경우 네트워크 함수의 출력은 하나 이상의 뉴럴 네트워크의 출력의 앙상블(ensemble)일 수 있다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 판독하여 본 발명의 일 실시예에 따른 음향 인식 모 델을 제공할 수 있다. 본 발명의 일 실시예에 따라, 프로세서는 음향 인식 모델을 학습시키기 위한 계산을 수행할 수 있다. 본 발명의 일 실시예에 따르면, 프로세서는 통상적으로 서버의 전반적인 동작을 처리할 수 있다. 프 로세서는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거나 메모 리에 저장된 응용 프로그램을 구동함으로써, 사용자 또는 사용자 단말에게 적정한 정보 또는, 기능을 제공 하거나 처리할 수 있다. 또한, 프로세서는 본 발명의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프 로그램에 대한 연산을 수행할 수 있으며, 서버는 하나 이상의 프로세서를 구비할 수 있다. 다양한 실시예에서, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저장하는 램(RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포 함할 수 있다. 또한, 프로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템온칩(SoC: system on chip) 형태로 구현될 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 발명의 다양한 실시예에 따른 방 법/동작을 실행하기 위하여 스토리지로부터 컴퓨터 프로그램을 로드할 수 있다. 메모리에 컴퓨 터 프로그램이 로드되면, 프로세서는 컴퓨터 프로그램을 구성하는 하나 이상의 인스트럭션들을 실행함으로써 상기 방법/동작을 수행할 수 있다. 메모리는 RAM과 같은 휘발성 메모리로 구현될 수 있을 것 이나, 본 발명의 기술적 범위가 이에 한정되는 것은 아니다. 버스는 서버의 구성 요소 간 통신 기능을 제공한다. 버스는 주소 버스(address Bus), 데이터 버 스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 서버의 유무선 인터넷 통신을 지원한다. 또한, 통신 인터페이스는 인터넷 통 신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 발명의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 몇몇 실시예에서, 통신 인터페이스는 생략될 수도 있다. 스토리지는 컴퓨터 프로그램을 비 임시적으로 저장할 수 있다. 서버를 통해 음향 데이터의 인식 정확도를 향상시키기 위한 프로세스를 수행하는 경우, 스토리지는 음향 데이터의 인식 정확도를 향상시키 기 위한 프로세스를 제공하기 위하여 필요한 각종 정보를 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드될 때 프로세서로 하여금 본 발명의 다양한 실시예에 따른 방 법/동작을 수행하도록 하는 하나 이상의 인스트럭션들을 포함할 수 있다. 즉, 프로세서는 상기 하나 이상 의 인스트럭션들을 실행함으로써, 본 발명의 다양한 실시예에 따른 상기 방법/동작을 수행할 수 있다. 일 실시예에서, 컴퓨터 프로그램은 음향 데이터에 기초하여 하나 이상의 음향 프레임을 구성하는 단계, 하 나 이상의 음향 프레임 각각을 음향 인식 모델의 입력으로 처리하여 각 음향 프레임에 대응하는 예측값을 출력 하는 단계, 각 음향 프레임에 대응하는 예측값에 기초한 임계값 분석을 통해 하나 이상의 인식 음향 프레임을 식별하는 단계, 하나 이상의 인식 음향 프레임에 기초하여 시계열 분석을 통해 변환 음향 프레임을 식별하는 단 계 및 변환 음향 프레임에 대응하는 예측값에 대한 변환을 수행하는 단계를 포함하는 음향 데이터의 인식 정확 도를 향상시키기 위한 방법을 수행하도록 하는 하나 이상의 인스트럭션을 포함할 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 이하, 도 3 내지 도 9를 참조하여, 서버에 의해 수행되는 음향 데이터의 인식 정확도를 향상시키기 위한 방법에 대해 설명하도록 한다. 도 3은 본 발명의 일 실시예와 관련된 음향 데이터의 인식 정확도를 향상시키기 위한 방법을 예시적으로 나타낸 순서도이다. 도 3에 도시된 단계들은 필요에 의해 순서가 변경될 수 있으며, 적어도 하나 이상의 단계가 생략 또는 추가될 수 있다. 즉, 이하의 단계들은 본 발명의 일 실시예에 불과할 뿐, 본 발명의 권리 범위는 이에 제 한되지 않는다. 본 발명의 일 실시예에 따르면, 서버는 음향 데이터를 획득할 수 있다. 음향 데이터는 실생활에서 획득되 는 음향에 관련한 정보를 포함할 수 있다. 본 발명의 일 실시예에 따른 음향 데이터의 획득은, 메모리에 저장된 음향 데이터를 수신하거나 또는 로딩(loading)하는 것일 수 있다. 또한, 영상 데이터의 획득은, 유/무선 통신 수단에 기초하여 다른 저장 매체, 다른 컴퓨팅 장치, 동일한 컴퓨팅 장치 내의 별도 처리 모듈로부터 데이 터를 수신하거나 또는 로딩하는 것일 수 있다. 일 실시예에 따르면, 음향 데이터는 사용자에 관련한 사용자 단말을 통해 획득될 수 있다. 예를 들어, 사 용자에 관련한 사용자 단말은, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치 또는 특정 공간(예컨대, 사용자의 주거 공간) 상 에 구비된 전자 장치(예컨대, 마이크를 통해 음향 데이터를 수신할 수 있는 장치) 등을 포함할 수 있다. 본 발명의 일 실시예에 따르면, 서버는 음향 데이터에 기초하여 하나 이상의 음향 프레임을 구성할 수 있 다(S100). 하나 이상의 음향 프레임은, 시계열 정보인 음향 데이터를 특정 시간 단위에 기초하여 복수의 프레임 으로 분할한 것일 수 있다. 구체적으로, 서버는 음향 데이터를 미리 정해진 제1시간 단위의 크기를 갖도록 분할하여 하나 이상의 음향 프레임을 구성할 수 있다. 예를 들어, 제1음향 데이터가 1분이라는 시간에 대응하여 획득된 음향 데이터인 경우, 서버는, 제1시간 단위를 2초로 설정하여 제1음향 데이터를 분할하여 30개의 음향 프레임을 구성할 수 있다. 전술한 제1시간 단위 및 하나 이상의 음향 프레임에 관련한 구체적인 수치적 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 일 실시예에 따르면, 서버는 하나 이상의 음향 프레임 각각이 적어도 일부 중첩되도록 하나 이상의 음향 프레임을 구성할 수 있다. 도 4를 참조하여 자세히 설명하면, 하나 이상의 음향 프레임 각각의 시작 시점은, 인 접한 음향 프레임 각각의 시작 시점과 제2시간 단위(400b)의 크기를 갖도록 결정될 수 있다. 일 실시예에 따르 면, 제2시간 단위(400b)의 크기는, 제1시간 단위(400a)의 크기보다 작게 결정될 수 있다. 즉, 서버는 도 4 에 도시된 바와 같이, 동일한 제1시간 단위(400a)를 갖는 하나 이상의 음향 프레임(즉, 제1음향 프레임, 제2음향 프레임, 제3음향 프레임 등)을 생성할 수 있다. 이 경우, 각 음향 프레임은, 인접한 음 향 프레임 각각과 제1시간 단위(400a) 크기 보다 작은 제2시간 단위(400b) 크기 만큼 차이가 나도록 구성될 수 있다. 이에 따라, 각 음향 프레임은, 인접한 음향 프레임 각각과 적어도 일부가 중첩될 수 있다. 구체적인 예를 들어, 음향 데이터가 10초 동안 획득된 음향에 관련하며, 제1시간 단위(400a)가 2초로 설정 될 수 있으며, 제2시간 단위(400b)는 제1시간 단위(400a) 보다 작은 1초로 설정될 수 있다. 이 경우, 제1음향 프레임은 0~2초 동안 획득된 음향에 관련한 것일 수 있으며, 제2음향 프레임은 1~3초 동안 획득된 음 향에 관련한 것일 수 있고, 그리고 제3음향 프레임은 2~4초 동안 획득된 음향에 관련한 것일 수 있다. 전 술한 음향 데이터의 전체 시간, 제1시간 단위, 제2시간 단위 각각에 관련한 구체적인 수치적 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 즉, 각 음향 프레임의 시작 시점이 인접한 음향 프레임 각각의 시작 시점과 제1시간 단위(400a)의 크기 보다 작 은 제2시간 단위(400b)의 크기 차이를 갖도록, 하나 이상의 음향 프레임이 구성됨에 따라, 각 음향 프레임의 적 어도 일부는 중첩 구간을 가질 수 있다. 본 발명의 일 실시예에 따르면, 서버는 하나 이상의 음향 프레임 각각을 음향 인식 모델의 입력으로 처리 하여 각 음향 프레임에 대응하는 예측값을 출력할 수 있다(S200). 일 실시예에 따르면, 서버는 일 실시예에 따르면, 서버는 오토인코더를 비지도학습(Unsupervised Learning) 방식을 통해 학습시킬 수 있다. 구체적으로, 서버는 입력 데이터와 유사한 출력 데이터를 출력 하도록 오토인코더를 구성하는 차원 감소 네트워크 함수(예컨대, 인코더) 및 차원 복원 네트워크 함수(예컨대, 디코더)를 학습시킬 수 있다. 자세히 설명하면, 차원 감소 네트워크 함수를 통해 인코딩 과정에서 입력된 음향 데이터의 핵심 특징 데이터(또는, 피처(feature))만을 히든 레이어를 통해 학습하고 나머지 정보를 손실시킬 수 있다. 이 경우, 차원 복원 네트워크 함수를 통한 디코딩 과정에서 히든 레이어의 출력 데이터는 완벽한 복사 값 이 아닌 입력 데이터(즉, 음향 데이터)의 근사치일 수 있다. 즉, 서버는 출력 데이터와 입력 데이터가 최 대한 같아지도록 가중치를 조정함으로써, 오토인코더를 학습시킬 수 있다. 오토인코더는 입력 데이터와 유사한 출력 데이터를 출력하기 위한 신경망의 일종일 수 있다. 오토 인코더는 적 어도 하나의 히든 레이어를 포함할 수 있으며, 홀수 개의 히든 레이어가 입출력 레이어 사이에 배치될 수 있다. 각각의 레이어의 노드의 수는 입력 레이어의 노드의 수에서 병목 레이어(인코딩)라는 중간 레이어로 축소되었다 가, 병목 레이어에서 출력 레이어(입력 레이어와 대칭)로 축소와 대칭되어 확장될 수도 있다. 입력 레이어 및 출력 레이어의 수는 입력 데이터의 전처리 이후에 남은 입력 데이터의 항목들의의 수와 대응될 수 있다. 오토 인코더 구조에서 인코더에 포함된 히든 레이어의 노드의 수는 입력 레이어에서 멀어질수록 감소하는 구조를 가 질 수 있다. 병목 레이어(인코더와 디코더 사이에 위치하는 가장 적은 노드를 가진 레이어)의 노드의 수는 너무 작은 경우 충분한 양의 정보가 전달되지 않을 수 있으므로, 특정 수 이상(예를 들어, 입력 레이어의 절반 이상 등)으로 유지될 수도 있다. 서버는 객체 정보가 각각 태깅된 복수의 학습 데이터를 포함하는 학습 데이터 세트를 학습된 차원 감소 네 트워크의 입력으로 하여 출력된 객체 별 특징 데이터를 태깅된 객체 정보와 매칭하여 저장할 수 있다. 구체적으 로, 서버는 차원 감소 네트워크 함수를 이용하여 제1음향 식별 정보(예컨대, 유리 깨지는 소리)가 태깅된 제1학습 데이터 서브 세트를 차원 감소 네트워크 함수의 입력으로 하여, 제1학습 데이터 서브 세트에 포함된 학 습 데이터들에 대한 제1객체의 특징(feature) 데이터를 획득할 수 있다. 획득된 특징 데이터는 벡터로 표현될 수 있다. 이 경우, 제1학습 데이터 서브 세트에 포함된 복수의 학습 데이터 각각에 대응하여 출력된 특징 데이 터들은 제1음향에 관련한 학습 데이터를 통한 출력이므로 벡터 공간 상에서 비교적 가까운 거리에 위치할 수 있 다. 서버는 벡터로 표현된 제1음향에 관련한 특징 데이터들에 제1음향 식별 정보(즉, 유리 깨지는 소리)를 매칭하여 저장할 수 있다. 학습된 오토인코더의 차원 감소 네트워크 함수의 경우, 차원 복원 네트워크 함수가 입력 데이터를 잘 복원할 수 있도록 하는 특징을 잘 추출하도록 학습될 수 있다. 또한 예를 들어, 제2음향 식별 정보(예컨대, 사이렌 소리)가 태깅된 제1학습 데이터 서브 세트 각각에 포함된 복수의 학습 데이터들은 차원 감소 네트워크 함수를 통해 특징 데이터(즉, 피처)들로 변환되어 벡터 공간 상에 표시될 수 있다. 이 경우, 해당 특징 데이터들은 제2음향 식별 정보 (즉, 사이렌 소리)에 관련한 학습 데이터를 통한 출력이므로, 벡터 공간 상에서 비교적 가까운 거리에 위치할 수 있다. 이 경우, 제2음향 식별 정보에 대응 하는 특징 데이터들은 제1음향 식별 정보(예컨대, 유리 깨지는 소리)에 대응하는 특징 데이터들과 상이한 벡터 공간 상에 표시될 수 있다. 실시예에서, 서버는 학습된 오토인코더에서 차원 감소 네트워크 함수를 포함하여 음향 인식 모델을 구성할 수 있다. 즉, 상기와 같은 학습 과정을 통해 생성된 차원 감소 네트워크 함수를 포함하여 구성된 음향 인식 모델은 음향 프레임을 입력으로 하는 경우, 해당 음향 프레임을 차원 감소 네트워크 함수를 활용한 연산을 통해 음향 프레임에 대응하는 특징정보(즉, 피처)를 추출할 수 있다. 이 경우, 음향 인식 모델은 음향 프레임에 대응하는 피처가 표시된 영역과 객체 별 특징 데이터의 벡터 공 간 상의 거리 비교를 통해 음향 스타일의 유사성을 평가할 수 있으며, 해당 유사성 평가에 기반하여 음향 데이 터에 대응하는 예측값을 출력할 수 있다. 일 실시예에서, 예측값은, 하나 이상의 예측 항목 정보 및 하나 이상 의 예측 항목 정보 각각에 대응하는 예측 수치 정보를 포함할 수 있다. 구체적으로, 음향 인식 모델은 음향 프레임을 차원 감소 네트워크 함수를 이용하여 연산함으로써, 특징정 보(즉, 피처)를 출력할 수 있다. 이 경우, 음향 인식 모델은, 음향 프레임에 대응하여 출력된 특징정보와 학습 을 통해 벡터 공간 상에 사전 기록된 음향 식별 정보 별 특징 데이터들 간의 위치에 기반하여 음향 프레임에 대 응하는 하나 이상의 예측 항목 정보 및 각 예측 항목 정보에 대응하는 예측 수치 정보를 포함할 수 있다. 하나 이상의 예측 항목 정보는, 어떠한 소리에 관련한 것인지에 관한 정보로, 예컨대, 유리 깨지는 소리, 타이 어가 펑크나는 소리, 비상 사이렌이 작동되는 소리, 강아지가 짖는 소리, 비 내리는 소리 등을 포함할 수 있다. 이러한 예측 항목 정보들은, 음향 프레임에 대응하여 출력된 특징정보와 벡터 공간 상의 위치가 가까운 음향 식 별 정보들에 기초하여 생성될 수 있다. 예컨대, 음향 인식 모델은 제1음향 프레임에 대응하여 출력된 제1특징 정보와 근접한 위치에 있는 특징정보들에 매칭된 음향 식별 정보를 통해 하나 이상의 예측 항목 정보를 구성할 수 있다. 전술한 하나 이상의 예측 항목 정보에 관련한 구체적인 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 각 예측 항목 정보에 대응하는 예측 수치 정보는, 예측 항목 정보 각각에 대응하여 예측한 수치에 관한 정보일 수 있다. 예컨대, 음향 인식 모델은 제1음향 프레임에 대응하여 출력된 제1특징 정보와 근접한 위치에 있는 특 징정보들에 매칭된 음향 식별 정보를 통해 하나 이상의 예측 항목 정보를 구성할 수 있다. 이 경우, 제1특징 정 보가 각 음향 식별 정보에 대응하는 특징정보들과 위치가 가까울수록 높은 예측 수치 정보가 출력될 수 있으며, 제1특징 정보와 각 음향 식별 정보에 대응하는 특징정보들의 위치가 멀수록 낮은 예측 수치 정보가 출력될 수 있다. 구체적인 예를 들어, 도 5에 도시된 바와 같이, 음향 인식 모델은 제1음향 프레임에 대응하여 '사이 렌 소리', '비명 소리', '유리 깨지는 소리' 및 '그외 소리'에 관련한다는 예측 항목 정보를 출력할 수 있 다. 또한, 음향 인식 모델은 각 예측 항목 정보에 대응하여 '1', '95', '3' 및 '2'라는 예측 수치 정 보를 출력할 수 있다. 즉, 음향 인식 모델은 제1음향 프레임에 대응하여 사이렌 소리에 관련될 확률이 1이며, 비명 소리에 관련될 확률이 95이며, 유리 깨지는 소리에 관련될 확률이 '3'이고, 그리고 그외 소 리에 관련될 확률이 '2'라는 예측값을 출력할 수 있다. 전술한 예측 항목 정보 및 예측 수치 정보 각각에 대한 구체적인 수치에 대한 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 즉, 서버는 음향 인식 모델을 통해 음향 데이터에 기초하여 구성한 하나 이상의 음향 프레임 각각에 대응하는 예측값을 출력할 수 있다. 예를 들어, 음향 인식 모델은 제1음향 프레임에 대응하여 제1예 측값을 출력하고, 제2음향 프레임에 대응하여 제2예측값을 출력하고, 그리고 제3음향 프레임에 대응 하여 제3예측값을 출력할 수 있다. 본 발명의 일 실시예에 따르면, 서버는 각 음향 프레임에 대응하는 예측값에 기초한 임계값 분석을 통해 하나 이상의 인식 음향 프레임을 식별할 수 있다(S300). 여기서 임계값 분석은, 각 음향 프레임에 대응하는 하 나 이상의 예측 수치 정보 각각이, 각 예측 항목 정보에 대응하여 미리 정해진 임계값 이상인지 여부를 판별하 여 하나 이상의 인식 음향 프레임을 식별하는 분석을 의미할 수 있다. 임계값 분석을 통해 하나 이상의 인식 음향 프레임을 식별하는 방법에 대한 구체적인 설명은, 도 6을 참조하여 이하에서 후술하도록 한다. 일 실시예에서, 서버는 하나 이상의 음향 프레임 각각에 대응하는 하나 이상의 예측 수치 정보 각각을 식 별할 수 있다(S310). 구체적인 예를 들어, 하나 이상의 음향 프레임은, 제1음향 프레임 및 제2음향 프레임을 포 함할 수 있다. 서버는 각 음향 프레임을 음향 인식 모델의 입력으로 처리하여 각 음향 프레임에 대응 하는 예측값을 출력할 수 있다. 여기서 예측값은, 하나 이상의 예측 항목 정보 및 각 예측 항목 정보에 대응하 는 예측 수치 정보를 포함할 수 있다. 이에 따라, 서버는 각 음향 프레임에 대응하여 음향 인식 모델이 출 력한 예측값들을 통해 각 음향 프레임에 대응하는 예측 수치 정보들을 식별할 수 있다. 예를 들어, 서버는 제1음향 프레임에 대응하는 예측값을 통해 '유리 깨지는 소리' 및 '아이 우는 소 리' 각각에 대응하는 예측 수치 정보가 '82' 및 '5'임을 식별할 수 있다. 또한 예를 들어, 서버는 제2음향 프레임에 대응하는 예측값을 통해 '유리 깨지는 소리' 및 '사이렌 소리' 각각에 대응하는 예측 수치 정보가 '50' 및 '12'임을 식별할 수 있다. 전술한 예측 수치 정보들에 대한 구체적인 수치적 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 또한, 서버는 하나 이상의 예측 항목 정보에 대응하여 미리 정해진 임계값을 식별할 수 있다(S320). 일 실 시예에서, 각 예측 항목 정보에 대응하여 임계값이 사전 설정될 수 있다. 임계값은, 일정 이상의 정확도를 가진 음향 인식 결과를 식별하기 위한 임계치를 의미할 수 있다. 예를 들어, 제1음향 프레임에 대응하는 예측 수치 정보가 임계값 이상인 경우, 제1음향 프레임의 음향 인식 결과는 신뢰할 만한 수준인 것을 의미할 수 있다. 다 른 예를 들어, 제2음향 프레임에 대응하는 예측 수치 정보가 임계값 미만인 경우, 제2음향 프레임의 음향 인식 결과는 정확도가 다소 결여된 것을 의미할 수 있다. 전술한 각 음향 프레임에 대한 구체적인 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 이러한 임계값은 예측 항목 별로 서로 상이하게 설정될 수 있다. 일 실시예에 따르면, 각 예측 항목 별 임계값 은, 음향 인식의 난이도에 대응하여 사전 결정될 수 있다. 예를 들어, 인식이 어려운 음향일수록 임계값이 비교 적 낮게 설정될 수 있으며, 인식이 용이한 음향일수록 임계값이 비교적 높게 설정될 수 있다. 인식이 용이한지 여부에 대한 판별은 예컨대, 벡터 공간 상에서 각 음향 식별 정보에 포함된 특징 정보들의 분포도에 기초한 것 일 수 있다. 실시예에서, 특정 음향 식별 정보에 대응하여 출력된 특징 정보들의 넓게 분포된 경우, 인식이 어 려운 것이며, 특징 정보들이 밀집되어 있을수록 인식이 용이한 것일 수 있다. 즉, 하나 이상의 예측 항목 정보 각각에 대응하여 임계값이 설정되어 있을 수 있다. 구체적인 예를 들어, 비교적 인식이 용이한 폭발음의 임계값 은 90일 수 있으며, 인식이 어려운 아이 울음 소리에 관련한 임계값은 60일 수 있다. 전술한 각 음향에 관련하 여 미리 설정된 임계값에 대한 구체적인 설명은 예시일 뿐, 본 발명은 이에 제한되지 않는다. 서버는 예측 수치 정보 각각이 미리 정해진 임계값 이상인지 여부를 판별하여 하나 이상의 인식 음향 프레 임을 식별할 수 있다(S330). 구체적으로, 서버는 각 음향 프레임에 대응하여 예측값을 출력할 수 있다. 이 경우, 각 음향 프레임에 대응하는 예측값들은 예측 항목 정보 및 예측 수치 정보를 포함할 수 있다. 구체적인 예를 들어, 서버는 제1음향 프레임에 대응하는 예측값을 통해 '유리 깨지는 소리' 및 '아이 우는 소리' 각각에 대응하는 예측 수치 정보가 '82' 및 '5'임을 식별할 수 있으며, 제2음향 프레임에 대응 하는 예측값을 통해 '유리 깨지는 소리' 및 '사이렌 소리' 각각에 대응하는 예측 수치 정보가 '50' 및 '12'임을 식별할 수 있다. 또한, 서버는 각 음향 프레임에 대응하는 예측 항목 정보들(즉, 유리 깨지는 소리, 아이 우는 소리, 사이 렌 소리) 각각에 미리 정해진 임계값을 식별할 수 있다. 예컨대, 유리 깨지는 소리, 아이 우는 소리 및 사이렌 소리에 대응하는 미리 정해진 임계값을 각각 80, 60 및 90으로 식별할 수 있다. 서버는 각 음향 프레임에 대응하는 예측 수치 정보와 이에 대응하는 임계값 각각을 비교하여 하나 이상의 인식 음향 프레임을 식별할 수 있다. 구체적으로, 서버는 출력한 예측값에 포함된 예측 수치 정보 각각이 이미 정해진 임계값 이상인지 여부를 판별하여 하나 이상의 인식 음향 프레임을 식별할 수 있다. 이 경우, 서버는 제1음향 프레임에 유리 깨지는 소리에 대응하는 예측 수치 정보가 82로, 해당 유리 깨지는 소리에 관련하여 미리 정해진 임계값인 80 이상인 것을 식별하여 제1음향 프레임을 하나 이상의 인 식 음향 프레임으로 식별할 수 있다. 또한, 서버는 제2음향 프레임에 유리 깨지는 소리에 대응하는 예측 수치정보가 미리 정해진 임계값인 50으로, 해당 유리 깨지는 소리에 관련하여 미리 정해진 임계값인 80 미만인 것을 식별하여 제2음향 프레임은 하나 이상의 인식 음향 프레임으로 식별할지 않을 수 있다. 다시 말해, 서버는 음향 데이터에 기초하여 구성된 하나 이상의 음향 프레임 중 미리 정해진 임계값 이상인 예측 수치 정보를 가진 음향 프레임들만을 하나 이상의 인식 음향 프레임으로 식별할 수 있다. 즉, 서버 는 각 음향 프레임 중 정확도가 떨어지는 인식 결과에 관련한 프레임들은 제거하고, 일정 신뢰도 이상의 프레임들만을 하나 이상의 인식 음향 프레임으로 식별할 수 있다. 본 발명의 일 실시예에 따르면, 서버는 하나 이상의 인식 음향 프레임에 기초한 시계열 분석을 통해 변환 음향 프레임을 식별할 수 있다(S400). 여기서, 시계열 분석은, 음향 데이터들이 획득되는 시점들을 관측하여 오 인식되는 음향이 존재하는지 여부를 판별하는 분석을 의미할 수 있다. 시계열 분석을 통해 하나 이상의 변환 음 향 프레임을 식별하는 방법에 대한 구체적인 설명은, 도 7을 참조하여 이하에서 후술하도록 한다. 일 실시예에서, 서버는 하나 이상의 인식 음향 프레임 각각에 대응하는 예측 항목 정보를 식별할 수 있다 (S410). 즉, 서버는 임계값 분석 결과 식별된 하나 이상의 인식 음향 프레임들 각각이 어떠한 음향에 관한 것인지 여부를 식별할 수 있다. 예를 들어, 하나 이상의 인식 음향 프레임은, 제1음향 프레임, 제4음향 프레임 및 제5음향 프레임을 포함할 수 있다. 이 경우, 서버는 각 음향 프레임의 예측 항목 정보를 식별할 수 있다. 예컨대, 제1음향 프레임의 예 측 항목 정보는, '유리 깨지는 소리'를 포함할 수 있으며, 제4음향 프레임의 예측 항목 정보는 '사이렌 소리'를 포함할 수 있고, 그리고 제5음향 프레임의 예측 항목 정보는 '사이렌 소리'를 포함할 수 있다. 전술한 하나 이 상의 인식 음향 프레임 및 예측 항목 정보들에 대한 구체적인 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는 다. 실시예에서, 서버는 예측 항목 정보가 미리 정해진 기준 시간 동안 미리 정해진 임계 횟수 이상 반복되는 지 여부를 판별할 수 있다(S420). 구체적으로, 서버는 예측 항목 정보 각각에는 기준 시간 및 임계 횟수가 사전 설정되어 있을 수 있다. 예를 들어, 강아지가 짖는 소리의 경우, 기준 시간은 2개의 음향 프레임에 관련한 시간으로 미리 정해질 수 있으며, 임계 횟수는 2번으로 미리 정해질 수 있다. 다시 말해, 서버는 하나 이 상의 인식 음향 프레임이 강아지 짖는 소리에 관련한 경우, 해당 항목 정보(즉, 강아지 짖는 소리)에 미리 정해 져 있는 기준 시간 및 미리 정해져 있는 임계 횟수를 식별하고, 기준 시간 동안 미리 정해진 임계 횟수만큼 강 아지가 짖는 소리가 반복되어 인식되었는지 여부를 판별할 수 있다. 즉, 서버 하나 이상의 인식 음향 프레 임을 통해 특정 음향이 미리 정해진 기준치만큼 연속해서 인식되는지 여부를 판별할 수 있다. 서버는 판별 결과에 기초하여 변환 음향 프레임을 식별할 수 있다(S430). 서버는 하나 이상의 인식 음향 프레임을 통해 특정 음향이 설정된 기준치만큼 연속해서 인식되지 않았다고 판별(즉, 미리 정해진 기준 시 간 내 미리 정해진 임계 횟수 이상 반복되었다고 판별)한 경우, 하나 이상의 인식 음향 프레임 중 적어도 하나 를 변환 음향 프레임으로 식별할 수 있다. 여기서 변환 음향 프레임은, 오인식 확률을 줄이기 위해, 즉, 인식 정확도의 향상을 위해 변환의 대상이 되는 음향 프레임을 의미할 수 있다. 본 발명의 일 실시예에 따르면, 서버는 변환 음향 프레임에 대응하는 예측값에 대한 변환을 수행할 수 있 다(S500). 실시예에서, 예측값에 대한 변환은, 잡음 변환 및 음향 항목 변환 중 적어도 하나를 포함할 수 있다. 잡음 변환은, 변환 음향 프레임에 기초한 음향 인식 모델의 출력을 인식 미대상 항목으로 변환하는 것을 의미할 수 있다. 즉, 변환 프레임에 관련한 음향 인식 모델의 출력(즉, 예측값)을 인식 미대상 항목(예컨대, others)로 변환하는 것을 의미할 수 있다. 음향 항목 변환은, 변환 음향 프레임에 관련한 예측 항목 정보를 교정 예측 항목 정보로 변환하는 것을 의미할 수 있다. 여기서, 교정 예측 항목 정보는, 예측 항목 정보의 연관 관계에 기초하여 결정될 수 있다. 구체적인 예를 들어, 변환 음향 프레임에 관련한 예측 항목 정보가 '손 씻는 소리'라는 정보를 포함하는 경우, 해당 손 씻는 소리와 연관 관계를 가진 '변기에 물 차는 소리'가 교정 예측 항목 정보로 결정될 수 있다. 이 경 우, 서버는 손 씻는 소리에 관련한 변환 음향 프레임이 변기에 물 차는 소리로 인식되도록 예측 항목 정보 를 변환할 수 있다. 전술한 예측 항목 정보 및 교정 예측 항목 정보에 대한 구체적인 기재는 예시일 뿐, 본 발 명은 이에 제한되지 않는다. 결과적으로, 서버는 하나 이상의 인식 음향 프레임을 통해 특정 음향이 설정된 기준치만큼 연속해서 인식 되지 않았다고 판별(즉, 미리 정해진 기준 시간 내 미리 정해진 임계 횟수 이상 반복되었다고 판별)하는 경우, 변환 프레임을 식별하고, 해당 변환 프레임의 예측값에 대한 변환을 수행할 수 있다. 이 경우, 변환 프레임의예측값 변환은, 변환 프레임이 인식되지 않도록 변환하거나(즉, 인식 미대상 항목으로 변환) 또는, 이벤트를 인 식하고자 하는 경우, 인식 오류를 야기시키지 않는 다른 음향으로 인식되도록 변환하는 것을 의미할 수 있다. 이러한 변환은, 하나 이상의 음향 프레임들 각각이, 인접한 음향 프레임들과 일부 중첩됨에 따라 가능한 것일 수 있다. 예컨대, 제2시간 단위를 통해 일부 중첩되도록 인식되기 때문에, 하나의 음향 프레임에서 단독으로 인 식되는 음향 프레임은 변환 프레임으로 식별되어 변환될 수 있다. 즉, 특정 음향을 타케팅으로 하여 이벤트를 검출하고자 하는 경우, 오인식에 관련한 음향 프레임들이 인식오류 를 야기시지 않도록 보정(또는 변환)함으로써, 음성 데이터의 인식 정확도를 향상시킬 수 있다. 본 발명의 일 실시예에 따르면, 서버는 하나 이상의 인식 음향 프레임 각각에 대응하는 예측 항목 정보에 기초하여 각 인식 음향 프레임 간의 연관 관계를 식별할 수 있다. 예를 들어, 하나 이상의 인식 음향 프레임은, 제1음향 프레임 및 제2음향 프레임을 포함할 수 있다. 제1음향 프레임는 '변기 물 내리는 소리'라는 예측 항목 정보를 포함할 수 있으며, 제2음향 프레임은 '손 씻는 소리'라는 예측 항목 정보를 포함할 수 있다. 서버 는 각 음향 프레임 간의 연관 관계를 식별할 수 있다. 예컨대, 서버는 제1음향 프레임의 획득 이후 제2음 향 프레임의 획득이 예측된다는 연관 관계를 식별할 수 있다. 실시예에서, 서버는 연관 관계에 기초하여 하나 이상의 음향 프레임 각각에 대응하는 임계값 및 임계 횟수 의 조정 여부를 결정할 수 있다. 서버는 음향 프레임들 간의 연관 관계에 따라 음향 프레임에 대응하는 임 계값 및 상기 임계 횟수를 조정할 수 있다. 즉, 음향 프레임들 간의 연관 관계에 따라, 음향 항목 각각 마다 미 리 설정된 임계값 및 임계 횟수가 가변적으로 조정될 수 있다. 보다 자세한 예를 들어, 서버는 변기 물이 내려가는 음향에 관련한 이벤트를 감지하기 위하여 구비될 수 있다. 이 경우, 음향 데이터에 기초하여 획득된 제1음향 프레임은 '변기 물 내리는 소리'라는 예측 항목 정보를 포함할 수 있으며, 제2음향 프레임은 '손 씻는 소리'라는 예측 항목 정보를 포함할 수 있다. 예컨대, 제2음향 프레임에 관련한 음향 또한 물이 흐르는 소리에 관한 것으로, 서버가 감지 또는 인식하고 하는 음향 이벤 트(즉, 변기 물 내리는 소리)와 유사할 수 있다. 이에 따라, 서버는 음향 프레임 간의 연관 관계(즉, 제1 음향 프레임의 획득 이후 손 씻는 소리의 획득이 예측된다는 연관 관계)를 식별하여 손 씻는 소리에 관련한 예 측 항목에 대응하는 임계값 및 임계 횟수를 조정할 수 있다. 예를 들어, 서버는 손 씻는 소리에 관련한 음향 예측 항목에 대응하는 임계값을 기존 80에서 95으로 조정 할 수 있다. 이에 따라, 임계값 분석 과정에서 손 씻는 소리를 판단하기 위한 기준치가 향상되어 인식의 정확도 가 보다 향상될 수 있다. 이 경우, 기존 보다 높은 기준치가 설정됨에 따라 음향 프레임들이 손 씻는 소리로 인 식될 확률이 적어지게 됨에 따라, 변기 물 내리는 소리에 관련한 이벤트 인식의 정확도가 향상될 수 있다. 다른 예를 들어, 서버는 변기 물 내리는 소리 이후 손 씻는 소리에 관련한 음향 예측 항목에 대응하는 임 계 횟수를 기존 2회에서 5회로 조정할 수 있다. 손 씻는 소리가 단독으로 인식되는 경우에는 2회만 연속으로 인 식되어도 정삭적으로 인식된 것으로 판별하나, 연관된 소리(즉, 변기 물 내리는 소리) 이후에는 5회 반복하여 획득되어야만 인식된 것으로 판별할 수 있다. 즉, 음향 간의 연관관계에 따라 임계값 및 임계 횟수를 가변적으로 조정함으로써, 다음 시점에 획득되는 음향 프레임이 인식 미대상 항목(예컨대, others)로 처리되도록 할 수 있다. 다시 말해, 제1음향 프레임이 인식되는 경우, 해당 제1음향 프레임(예컨대, 변기 물 내리는 소리)에 관련한 제2음향 프레임(예컨대, 손 씻는 소리)에 관련한 임계값 및 임계 횟수를 조정하여 기준치를 높임으로서, 이후 제2음향 프레임이 획득될 시, 인식 미대상 항목으로 인식되도록 처리할 수 있다. 이에 따라, 감지하고자 하는 제1음향 프레임에 관련한 인식의 정확도가 극대화될 수 있다. 도 8은 본 발명의 일 실시예와 관련된 음향 데이터 보정 과정을 설명하기 위한 예시적인 표를 도시한다. 도 9는 본 발명의 일 실시예와 관련된 음향 데이터의 보정 과정을 설명하기 위한 예시도를 도시한다. 도 8은, 음향 데이터에 기초하여 5개의 음향 프레임을 구성한 경우에 대응하여 음향 인식 모델일 출력한 예측값 에 관련한 표일 수 있다. 도 8에 도시된 바와 같이, 5개의 음향 프레임은, 0~1초에 대응하는 제1음향 프레임, 0.5~1.5에 대응하는 제2음향 프레임, 1~2초에 대응하는 제3음향 프레임, 1.5~2.5초에 대응하는 제4음향 프레임, 2~3초에 대응하는 제5음향 프레임을 포함할 수 있다. 이 경우, 제1시간 단위(400a)는 1초이며, 제2시간 단위 (400b)는 0.5초일 수 있다. 인접한 음향 프레임 각각의 시작 시점이 제1시간 단위(400a) 크기 보다 작은 제2시 간 단위(400b) 크기 만큼 차이가 나도록 구성됨에 따라, 각 음향 프레임은, 인접한 음향 프레임 각각과 적어도일부가 중첩될 수 있다. 또한, 각 음향 프레임에 대응하는 예측 항목 정보 및 각 예측 항목 정보에 대응하는 예측 수치 정보는 도 8에 도시된 바와 같을 수 있다. 예컨대, 예측 수치 정보는 1에 가까울수록 예측 확률이 높은 것을 의미할 수 있으며, 0에 가까울수록 예측 확률이 낮음을 의미할 수 있다. 예를 들어, 0.5~1.5초 즉 제2음향 프레임에 대응 하는 siren의 출력이 0.9로 가장 높은 것을 확인할 수 있다. 이는, 0.5~1.5초 사이에 획득된 음향이 siren일 확 률이 매우 높은 것을 의미할 수 있다. 도 9의 (a)는 도 8의 예측값에 대응하여 임계값 분석을 수행한 결과를 나타낸 예시도이다. 도 9의 (a)를 참고하 면, siren의 경우, 임계값(예컨대, 0.6) 이상인 프레임들(즉, 제2음향 프레임, 제3음향 프레임 및 제4음향 프레 임)만 이 식별됨을 확인할 수 있다. 또한, scream의 경우, 임계값(예컨대, 0.3) 이상인 프레임들(즉, 제1음향 프레임 및 제4음향 프레임)만 이 식별됨을 확인할 수 있다. 또한, glass break의 경우, 임계값(예컨대, 0.7) 이 상인 프레임(즉, 제5음향 프레임)만 이 식별됨을 확인할 수 있다. 예컨대, 각 예측 항목에 대응하여 임계값 이 상인 음향 프레임들이 하나 이상의 인식 음향 프레임으로 식별될 수 있다. 도 9의 (b)는 도 8의 예측값에 대응하여 시계열 분석을 수행한 결과를 나타낸 예시도이다. 이 경우, 미리 정해 진 기준 시간은 2개의 음향 프레임에 관련한 시간으로 미리 설정될 수 있으며, 임계 횟수는 2번으로 미리 설정 될 수 있다. 도 9의 (a) 및 (b)를 참고하면, siren의 경우, 2회 연속으로 인식 음향 프레임의 인식 결과가 관측된 경우에 관 련한 프레임들만이 인식 대상으로 남아있음을 확인할 수 있다. 구체적으로, 도 9의 (a)에서는 제2음향 프레임이 하나 이상의 인식 음향 프레임으로 식별되었으나, 시계열 분석 결과 도 9의 (b)에서 변환되었음을 확인할 수 있다. 즉, 도 9의 (a)에서 제1음향 프레임과 제2음향 프레임 관측 결과 2회 연속으로 관측되지 않았으므로, 서버는 제2음향 프레임을 변환 프레임으로 식별하여 others로 변 환하는 보정을 수행할 수 있다. 이에 따라, 도 9의 (b)와 같이, siren의 제2음향 프레임 영역에 'x'로 표시될 수 있다. 이는 해당 구간에서 siren 소리가 인식되지 않았음을 나타내는 것일 수 있다. 이후 시점에 관련하여, 제2음향 프레임 및 제3음향 프레임 모두 임계값 이상의 예측 수치 정보를 가짐에 따라 제3음향 프레임은 siren 이 인식되었다고 판단할 수 있다. 제4음향 프레임도 마찬가지로, 제3음향 프레임 및 제4음향 프레임 모두 임계 값 이상의 예측 수치 정보를 가짐에 따라 siren이 인식되었다고 판단할 수 있다. 또한, scream의 경우, 임계값 분석 결과, 도 9의 (a)에서와 같이, 제1음향 프레임 및 제4음향 프레임에 관련하 여 scream이 발생한 것으로 감지한 것을 확인할 수 있다. 다만, 시계열 분석 과정에서, 제3음향 프레임과 제4음 향 프레임 모두에서 2회 연속으로 scream의 발생이 관측되지 않았으므로, 서버는 제4음향 프레임을 변환 프레임으로 식별하여 others로 변환하는 보정을 수행할 수 있다. 이에 따라, 도 9의 (b)와 같이, scream의 제4 음향 프레임 영역에 'x'로 표시될 수 있다. 이는 해당 구간에서 siren 소리가 인식되지 않았음을 나타내는 것일 수 있다. 추가적인 실시예에서, 서버는 전체 음향 데이터의 인식 결과에 대한 정보를 사용자 단말로 제공할 수 있다. 즉, 전체 음향 데이터의 인식 결과에 대한 정보는, 시계열적으로 획득된 전체 음향 데이터에 대응하여 각 시점 별(예컨대, 각 음향 프레임 별) 어떠한 소리가 인식되었는지에 관한 정보를 포함할 수 있다. 예컨대, 전체 음향 데이터의 인식 결과에 대한 정보는, 도 9의 (c)와 같을 수 있다. 도 9의 (c)를 참조하면 제2음향 프레임에 관련하여 siren이 인식되었다는 정보가 표시될 수 있다. 이 경우, siren에 관련한 제2음향 프레임은, 도 9의 (b)에 도시된 바와 같이, 시계열 분석 과정에서 siren 소리가 인식되 지 않았으므로 변환(또는 보정)된 것일 수 있다. 실시예에서, 서버는 전체 음향 데이터의 인식 결과에 대 한 정보를 제공하는 경우, 임계값을 넘었지만, 시계열 분석 과정에서 제외된 결과를 다시 복구해줄 있다. 이는, 음향 인식 과정에서는 연속적으로 두 번 이상 인식되어야 인식 대상으로 활용하나, 전체적인 인지 정보를 제공 하는 경우에는, 해당 인식 결과를 반영하기 위한 것일 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에상주할 수도 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다."}
{"patent_id": "10-2022-0180494", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2022-0180494", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 음향 데이터의 인식 정확도를 향상시키기 위한 방법을 수행하기 위한 시스 템을 개략적으로 나타낸 도면이다. 도 2는 본 발명의 일 실시예와 관련된 음향 데이터의 인식 정확도를 향상시키기 위한 서버의 하드웨어 구성도이 다. 도 3은 본 발명의 일 실시예와 관련된 음향 데이터의 인식 정확도를 향상시키기 위한 방법을 예시적으로 나타낸 순서도를 도시한다. 도 4는 본 발명의 일 실시예와 관련된 음향 데이터에 기초하여 하나 이상의 음향 프레임을 구성하는 과정을 설 명하기 위한 예시도를 도시한다. 도 5는 본 발명의 일 실시예와 관련된 음향 인식 모델이 음향 프레임을 기반으로 예측값을 출력하는 과정을 설 명하기 위한 예시도를 도시한다. 도 6은 본 발명의 일 실시예와 관련된 임계값 분석 과정을 예시적으로 나타낸 순서도를 도시한다. 도 7은 본 발명의 일 실시예와 관련된 시계열 분석 과정을 예시적으로 나타낸 순서도를 도시한다. 도 8은 본 발명의 일 실시예와 관련된 음향 데이터 보정 과정을 설명하기 위한 예시적인 표를 도시한다. 도 9는 본 발명의 일 실시예와 관련된 음향 데이터의 보정 과정을 설명하기 위한 예시도를 도시한다."}
