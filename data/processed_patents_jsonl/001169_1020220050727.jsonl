{"patent_id": "10-2022-0050727", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0151269", "출원번호": "10-2022-0050727", "발명의 명칭": "영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템", "출원인": "조재환", "발명자": "조재환"}}
{"patent_id": "10-2022-0050727", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "식육(食肉)을 촬영한 이미지를 업로드하고, 업로드된 이미지에 대한 부위명칭 및 기 설정된 식육 기준과의 매칭률을 출력하는 사용자 단말; 및적어도 하나의 식육 이미지, 지방 및 단백질의 분포 이미지 및 적어도 하나의 부위명칭을 매핑하여 데이터셋(DataSet)을 구축하는 구축부, 상기 데이터셋을 이용하여 적어도 하나의 인공지능 알고리즘을 학습 및 검증하여모델링하는 모델링부, 상기 적어도 하나의 인공지능 알고리즘 중 정확도가 가장 높은 인공지능 알고리즘을 판별서비스를 위한 인공지능 알고리즘으로 세팅하는 세팅부, 상기 사용자 단말에서 입력된 이미지를 세팅된 인공지능 알고리즘에 질의(Query)로 입력하는 질의부, 질의로 입력된 상기 이미지와 데이터셋 내 이미지 간 유사도를상기 매칭률로 출력하여 상기 사용자 단말로 전송하는 전송부를 포함하는 판별 서비스 제공 서버;를 포함하는 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템."}
{"patent_id": "10-2022-0050727", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 판별 서비스 제공 서버는,상기 사용자 단말에서 업로드된 이미지에 대한 이미지 흔들림 보정(Image Stabilization), 카메라 캘리브레이션(Camera Calibration), 색 분석 및 히스토그램 균일화(Histogram Equalization)를 수행하는 전처리부;를 더 포함하는 것을 특징으로 하는 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템."}
{"patent_id": "10-2022-0050727", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 판별 서비스 제공 서버는,상기 전처리부에서 전처리된 이미지에 대하여 지방 및 단백질을 구분하도록 지방 및 단백질에 대응하는 부위를RoI(Region of Interest)로 설정하는 관심영역설정부;를 더 포함하는 것을 특징으로 하는 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템."}
{"patent_id": "10-2022-0050727", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 판별 서비스 제공 서버는,상기 사용자 단말에서 식육의 부위명칭을 선택한 후, 전면카메라를 구동시켜놓는 경우, 상기 전면카메라에 촬영된 피사체인 객체의 부위명칭을 판별하여 증강현실 콘텐츠로 상기 사용자 단말의 화면 상에 상기 객체 부위에증강하여 디스플레이하고, 상기 객체와 상기 데이터셋 내 부위명칭이 일치하는 식육 이미지와의 매칭률에 기반하여 좋은 식육인지의 여부를 판별해주는 증강현실부;를 더 포함하는 것을 특징으로 하는 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템.공개특허 10-2023-0151269-3-청구항 5 제 1 항에 있어서,상기 적어도 하나의 인공지능 알고리즘은, 적어도 하나의 머신러닝 알고리즘 또는 적어도 하나의 딥러닝 알고리즘이고,상기 적어도 하나의 인공지능 알고리즘은, 질의로 입력된 이미지 내 객체를 탐지(Object Detection)하고, 시멘틱 세그멘테이션(Segmantic Segmentation) 및 인스턴스 세그멘테이션(Instance Segmentation)을 순차적으로 수행하여 지방 및 단백질의 분포 형상 및 비율을 비교하는 것을 특징으로 하는 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템."}
{"patent_id": "10-2022-0050727", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 판별 서비스 제공 서버는,상기 사용자 단말에서 식육의 부위명칭을 선택한 후, 전면카메라를 구동시켜놓는 경우, 상기 부위명칭과 기 매핑되어 저장된 지방 및 단백질의 분포 이미지가 가장 유사한 객체를 탐색하여 화면상에 실시간으로 표기해주는맛판단부;를 더 포함하는 것을 특징으로 하는 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템."}
{"patent_id": "10-2022-0050727", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 사용자 단말은 서로 다른 주체에 귀속된 복수의 사용자 단말이고,상기 판별 서비스 제공 서버는,상기 복수의 사용자 단말에서 업로드 및 상기 인공지능 알고리즘에 질의로 입력된 이미지와, 상기 인공지능 알고리즘에 의해 판별된 매칭률을 적어도 하나의 검증 단말로 전송하고, 상기 질의로 입력된 이미지 및 판별된 매칭률에 대한 오류 검증을 실시하며, 상기 오류검증 결과 오류가 발생된 경우, 오류가 발생된 오류부분 및 오류원인을 상기 적어도 하나의 검증 단말로부터 수신하여 오류패턴을 수정하도록 업데이트하는 업데이트부;를 더 포함하는 것을 특징으로 하는 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템."}
{"patent_id": "10-2022-0050727", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 판별 서비스 제공 서버는,상기 데이터셋(DataSet)을 이루는 적어도 하나의 식육 이미지, 지방 및 단백질의 분포 이미지 및 적어도 하나의부위명칭을 매핑할 때, 적어도 하나의 전문가 단말로 크라우드소싱(CrowdSourcing)을 수행하여 어노테이션(Annotation)을 의뢰한 후, 상기 어노테이션 결과는 적어도 하나의 검증 단말에서 검수한 후 상기 데이터셋으로입력하도록 하는 크라우드소싱부;를 더 포함하는 것을 특징으로 하는 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템."}
{"patent_id": "10-2022-0050727", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,공개특허 10-2023-0151269-4-상기 판별 서비스 제공 서버는,상기 데이터셋을 위한 빅데이터를 구축할 때, 인공지능 학습용 데이터 품질관리 가이드라인에 따라 빅데이터를구축하는 빅데이터화부;를 더 포함하는 것을 특징으로 하는 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템."}
{"patent_id": "10-2022-0050727", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 판별 서비스 제공 서버는,상기 데이터셋은 적어도 하나의 식육 이미지, 지방 및 단백질의 분포 이미지 및 적어도 하나의 부위명칭 외에,상기 적어도 하나의 식육 이미지와 유사한 맛을 내는 부위의 유사 식육 이미지와, 상기 유사 식육 이미지의 지방 및 단백질의 분포 이미지와, 상기 적어도 하나의 식육 이미지에 대응하는 부위가격과의 가격차이의 퍼센테이지를 더 포함하고, 상기 유사 식육 이미지 및 상기 유사 식육 이미지의 지방 및 단백질의 분포 이미지와, 상기사용자 단말에서 업로드된 이미지 및 업로드된 이미지 내 지방 및 단백질의 분포 이미지가 기 설정된 유사도를초과한 경우, 상기 업로드된 이미지에 대응하는 식육의 가격차이 퍼센테이지를 출력하도록 하는 가성비안내부;를 더 포함하는 것을 특징으로 하는 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템."}
{"patent_id": "10-2022-0050727", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템이 제공되며, 식육(食肉)을 촬영한 이미지 를 업로드하고, 업로드된 이미지에 대한 부위명칭 및 기 설정된 식육 기준과의 매칭률을 출력하는 사용자 단말 및 적어도 하나의 식육 이미지, 지방 및 단백질의 분포 이미지 및 적어도 하나의 부위명칭을 매핑하여 데이터셋 (DataSet)을 구축하는 구축부, 데이터셋을 이용하여 적어도 하나의 인공지능 알고리즘을 학습 및 검증하여 모델 링하는 모델링부, 적어도 하나의 인공지능 알고리즘 중 정확도가 가장 높은 인공지능 알고리즘을 판별 서비스를 위한 인공지능 알고리즘으로 세팅하는 세팅부, 사용자 단말에서 입력된 이미지를 세팅된 인공지능 알고리즘에 질 의(Query)로 입력하는 질의부, 질의로 입력된 이미지와 데이터셋 내 이미지 간 유사도를 매칭률로 출력하여 사용 자 단말로 전송하는 전송부를 포함하는 판별 서비스 제공 서버를 포함한다."}
{"patent_id": "10-2022-0050727", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템에 관한 것으로, 스마트폰으로 세절육 또는 포장육을 촬영하면 부위명칭 및 기 구축된 데이터셋 내 이미지와의 매칭률에 기반하여 좋은 고기인 지의 여부를 안내하는 시스템을 제공한다."}
{"patent_id": "10-2022-0050727", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "축산물 위생관리법 제2조에 의하면, 축산물이란 식육·포장육·원유·식용란·식육가공품·유가공품·알가공품을 말한다. 이때, 식육은, 식용을 목적으로 하는 가축의 지육, 정육, 내장이나 그 밖의 부분을 의미하고, 포장육 은, 판매를 목적으로 식육을 절단, 즉 세절 또는 분쇄하여 포장한 상태로 냉장하거나 냉동한 것으로서 화학적 합성품 등의 첨가물이나 다른 식품을 첨가하지 않은 것을 말한다. 축산물에는 식품 등의 표시·광고에 관한 법 률 제4조제1항제1호 및 식품 등의 표시·광고에 관한 법률 시행규칙 제3조제1항에 따라, 식육의 종류, 부위명칭, 등급 및 도축장명을 표기해야 하고, 소·돼지 식육의 표시방법 및 부위 구분기준 제5조제1항 및 별표 1에 따라 쇠고기 및 돼지고기는 분할상태에 따라 대분할과 소분할로 구별하며 그 부위명칭을 기재해야 한다. 이때, 식육의 부위명칭을 허위로 기재하지 않도록 부위를 자동으로 판별하거나 딥러닝 기반 등급을 자동으로 산 정하는 방법이 연구 및 개발되었는데, 이와 관련하여 선행기술인 한국공개특허 제2021-0157509호(2021년12월29 일 공개) 및 한국등록특허 제10-2242011호(2021년04월20일 공고)에는, 부분육의 이미지를 획득 및 중량값을 측 정한 후, 기 구축된 데이터베이스 내 부분육의 이미지 및 중량값과 비교하여 부분육의 부위명을 자동판별하고, 자동판별된 부위명을 부분육에 부착하도록 라벨지에 표기하여 인쇄하는 구성과, 축산물 등급을 자동으로 분류하 기 위한 학습 데이터셋을 구축하기 위하여, 이미지를 획득한 후 정규화하고, 특징파라미터에 기반한 예측값을 산출하는 방식으로 학습을 진행하며, 예측값의 정확도를 인간의 개입이 필요한 지도학습으로 확인한 후 정확도 에 대응하는 확률을 측정하는 구성이 각각 개시된다. 다만, 전자의 경우 이미지 및 중량값을 모두 측정해야 하는데, 일반인인 사용자는 저울을 대부분 가지고 다니지 않으며, 중량값을 측정하기 위해서는 단위 부분육이 필요하지만 구매도 하지 않은 소비자에게 단위 부분육으로 잘라 줄 정육점주는 그리 많지 않다. 후자의 경우에도 등급을 분류한다고 기재되어 있지만, 등급은 이미 법령 및 법규에 따라 전문가가 분류한 것이기 때문에 일반인인 소비자가 분류할 일이 많지 않다. 또, 등급 및 부위 명칭을 기재하는 것도 중요하지만 일반 소비자는 그 부위의 맛이 나는 한, 어떠한 등급 및 부위라도 가성비가 좋으면 구매하기 마련이다. 즉, 꽃등심이 아니더라도 꽃등심과 가까운 부위여서 가격이 싼 윗등심과 척아이 부위인 5번 부위를 고를 수 있다면, 한우와 비교하여 반 가격 또는 그 이하의 가격으로 비슷한 맛을 즐길 수 있게 된다. 이에, 전문 정육업자가 아닌 일반인이라도, 사용자 단말에서 촬영하여 이미지를 업로드하면, 촬영된 이 미지 내 식육이 좋은 고기인지 또 맛있는 부위인지의 여부를 판별해줄 수 있는 시스템의 연구 및 개발이 요구된 다."}
{"patent_id": "10-2022-0050727", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는, 사용자 단말에서 식육을 촬영하여 업로드하면, 기 모델링된 인공지능 알고리즘에 질의 (Query)로 입력하여 촬영된 식육이 맛있는 부위인지의 여부를 판별해줄 수 있도록 하고, 이를 위하여 식육 이미 지, 부위명칭 및 지방과 단백질의 분포에 대한 데이터셋을 인공지능 알고리즘에 입력하여 학습 및 테스트함으로 써 모델링을 수행하며, 사용자 단말에서 입력된 이미지도 라벨러(Labeller)의 라벨링 또는 어노테이션 (Annotation)을 통하여 학습 데이터셋으로 재입력함으로써 데이터셋을 꾸준히 증가시킬 수 있고, 판별 정확도를 높일 수 있도록 하는, 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템을 제공할 수 있다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제로 한정되지 않으며, 또 다른 기 술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2022-0050727", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 발명의 일 실시예는, 식육(食肉)을 촬영한 이미지 를 업로드하고, 업로드된 이미지에 대한 부위명칭 및 기 설정된 식육 기준과의 매칭률을 출력하는 사용자 단말 및 적어도 하나의 식육 이미지, 지방 및 단백질의 분포 이미지 및 적어도 하나의 부위명칭을 매핑하여 데이터셋 (DataSet)을 구축하는 구축부, 데이터셋을 이용하여 적어도 하나의 인공지능 알고리즘을 학습 및 검증하여 모델 링하는 모델링부, 적어도 하나의 인공지능 알고리즘 중 정확도가 가장 높은 인공지능 알고리즘을 판별 서비스를 위한 인공지능 알고리즘으로 세팅하는 세팅부, 사용자 단말에서 입력된 이미지를 세팅된 인공지능 알고리즘에 질의(Query)로 입력하는 질의부, 질의로 입력된 이미지와 데이터셋 내 이미지 간 유사도를 매칭률로 출력하여 사용자 단말로 전송하는 전송부를 포함하는 판별 서비스 제공 서버를 포함한다."}
{"patent_id": "10-2022-0050727", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 사용자 단말에서 식육을 촬영하여 업로드하면, 기 모 델링된 인공지능 알고리즘에 질의(Query)로 입력하여 촬영된 식육이 맛있는 부위인지의 여부를 판별해줄 수 있 도록 하고, 이를 위하여 식육 이미지, 부위명칭 및 지방과 단백질의 분포에 대한 데이터셋을 인공지능 알고리즘 에 입력하여 학습 및 테스트함으로써 모델링을 수행하며, 사용자 단말에서 입력된 이미지도 라벨러(Labeller)의 라벨링 또는 어노테이션(Annotation)을 통하여 학습 데이터셋으로 재입력함으로써 데이터셋을 꾸준히 증가시킬 수 있고, 판별 정확도를 높일 수 있도록 한다."}
{"patent_id": "10-2022-0050727", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미하며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 명세서 전체에서 사용되는 정도의 용어 \"약\", \"실질적으로\" 등은 언급된 의미에 고유한 제조 및 물질 허용오차 가 제시될 때 그 수치에서 또는 그 수치에 근접한 의미로 사용되고, 본 발명의 이해를 돕기 위해 정확하거나 절 대적인 수치가 언급된 개시 내용을 비양심적인 침해자가 부당하게 이용하는 것을 방지하기 위해 사용된다. 본 발명의 명세서 전체에서 사용되는 정도의 용어 \"~(하는) 단계\" 또는 \"~의 단계\"는 \"~ 를 위한 단계\"를 의미하지 않는다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 한편, '~부'는 소프트웨어 또는 하드웨어 에 한정되는 의미는 아니며, '~부'는 어드레싱 할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객 체 지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회 로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또 는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 본 명세서에 있어서 단말, 장치 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말, 장치 또는 디바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기 술된 동작이나 기능 중 일부도 해당 서버와 연결된 단말, 장치 또는 디바이스에서 수행될 수도 있다. 본 명세서에서 있어서, 단말과 매핑(Mapping) 또는 매칭(Matching)으로 기술된 동작이나 기능 중 일부는, 단말 의 식별 정보(Identifying Data)인 단말기의 고유번호나 개인의 식별정보를 매핑 또는 매칭한다는 의미로 해석 될 수 있다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템을 설 명하기 위한 도면이다. 도 1을 참조하면, 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스 템은, 적어도 하나의 사용자 단말, 판별 서비스 제공 서버, 적어도 하나의 전문가 단말, 적 어도 하나의 검수 단말을 포함할 수 있다. 다만, 이러한 도 1의 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템은, 본 발명의 일 실시예에 불과하므로, 도 1을 통하여 본 발명이 한정 해석되 는 것은 아니다. 이때, 도 1의 각 구성요소들은 일반적으로 네트워크(Network, 200)를 통해 연결된다. 예를 들어, 도 1에 도시 된 바와 같이, 적어도 하나의 사용자 단말은 네트워크를 통하여 판별 서비스 제공 서버와 연결 될 수 있다. 그리고, 판별 서비스 제공 서버는, 네트워크를 통하여 적어도 하나의 사용자 단말 , 적어도 하나의 전문가 단말, 적어도 하나의 검수 단말과 연결될 수 있다. 또한, 적어도 하나 의 전문가 단말은, 네트워크를 통하여 판별 서비스 제공 서버와 연결될 수 있다. 그리고, 적어 도 하나의 검수 단말은, 네트워크를 통하여 적어도 하나의 사용자 단말, 판별 서비스 제공 서버 및 적어도 하나의 전문가 단말과 연결될 수 있다. 여기서, 네트워크는, 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의 미하는 것으로, 이러한 네트워크의 일 예에는 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷(WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd GeneRation Partnership Project),5GPP(5th GeneRation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency), 블루투스 (Bluetooth) 네트워크, NFC(Near-Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워 크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 하기에서, 적어도 하나의 라는 용어는 단수 및 복수를 포함하는 용어로 정의되고, 적어도 하나의 라는 용어가 존재하지 않더라도 각 구성요소가 단수 또는 복수로 존재할 수 있고, 단수 또는 복수를 의미할 수 있음은 자명 하다 할 것이다. 또한, 각 구성요소가 단수 또는 복수로 구비되는 것은, 실시예에 따라 변경가능하다 할 것이다. 적어도 하나의 사용자 단말은, 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 관련 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 이용하여 식육을 촬영하여 업로드하고, 부위명칭 및 좋은 고기인지의 여부를 매칭률로 출력하는 단말일 수 있다. 이때, 식육 판별 서비스 제공 서버에는 각 부위명칭에 따라 좋은 고기라고 판별된 식육 이미지와, 지방 및 단백질의 분포 이미지가 매핑되어 저장되어, 이와의 매칭률을 통 하여 좋은 고기인지의 여부를 판단하기로 한다. 즉, 전문 정육업자가 좋은 고기라고 판단한 식육 이미지 자체 와의 이미지 매칭률이나, 지방 및 단백질의 분포 이미지와 이미지 내 지방 및 단백질의 분포 간 매칭률에 따라 좋은 고기인지를 판별해주는 것이다. 일반인은 전문가와 같이 보는 눈이 없기 때문에, 겉만 봐서는 좋은 고기 인지 아닌지의 여부를 모르고, 좋은 고기라면 제 가격이 얼마인지의 여부를 잘 모른다. 중고차를 직접 보고도 일반인은 잘 모르지만 전문가는 침수차량인지 등을 파악할 수 있는 것처럼, 전문가가 판단하는 포인트, 즉 판단 특징을 특징 맵(Feature Map)으로 학습하도록 하고, 이러한 특징이 보이는 식육을 좋은 고기라고 판단하도록 한 다. 여기서, 적어도 하나의 사용자 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터 로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데 스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 사용자 단말은, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 사용자 단말은, 예 를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 판별 서비스 제공 서버는, 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 제공하는 서버일 수 있다. 그리고, 판별 서비스 제공 서버는, 데 이터셋을 구축하기 위하여 적어도 하나의 전문가 단말로 식육 이미지를 전송하고, 라벨링 및 어노테이션을 수행하도록 크라우드소싱을 진행하는 서버일 수 있다. 이때, 판별 서비스 제공 서버는 정부의 가이드라인 인 인공지능 데이터 구축활용 가이드라인 중 축산물품질 영상 AI 데이터 가이드라인에 따라 데이터셋을 구축하 는 서버일 수 있다. 그리고, 판별 서비스 제공 서버는 데이터셋으로 적어도 하나의 인공지능 알고리즘을 학습 및 검증하면서 모델링을 하는 서버일 수 있고, 이 중 가장 정확도가 높은 인공지능 알고리즘을 판별 서비 스 제공 서버의 인공지능 알고리즘으로 세팅하는 서버일 수 있다. 이때, 데이터셋은, 식육 이미지, 지방 및 단백질의 분포 이미지, 부위명칭일 수 있지만 이에 한정되지는 않는다. 이때, 지방 및 단백질의 분포 이미 지는, 식육 이미지 내에서 시멘틱 및 인스턴스 세그멘테이션을 통하여 지방 및 단백질을 구획하여 영역을 구분 한 이미지일 수 있다. 판별 서비스 제공 서버는, 이렇게 학습 및 검증이 완료된 인공지능 알고리즘에 사 용자 단말의 이미지, 즉 식육 이미지를 질의로 입력하고, 그 결과 부위명칭을 출력하면서, 지방 및 단백질 의 분포 이미지 간의 매칭률에 기초하여 좋은 고기인지의 여부를 판단하는 서버일 수 있다. 즉, [식육 이미지- 지방 및 단백질의 분포 이미지-부위명칭]이 데이터셋으로 저장되어 있고, 사용자 단말의 이미지(식육 이미 지)가 인공지능 알고리즘에 질의로 입력되면, 부위명칭이 추출되면서, 부위명칭과 매핑된 [지방 및 단백질의 분 포 이미지]가, 사용자가 입력한 식육 이미지의 [지방 및 단백질의 분포 이미지]와 비교가 되면서 얼마나 유사한 지에 따라 얼마나 좋은 고기인지가 판단되는 것이다. 여기서, 판별 서비스 제공 서버는, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 적어도 하나의 전문가 단말은, 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 관련 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 이용하여 크라우드소싱에 참여하여 데이터셋에 라벨링 또는 어노테이 션을 진행하는 전문가의 단말일 수 있다. 전문가 단말은 식육 이미지가 로우 데이터(Raw Data)인 경우 식 육 이미지 중 분석이 힘든 이미지를 필터링하여 분석에 유의한 이미지만 남기는 정제과정을 수행할 수 있고, 축 종 및 등급별 데이터셋의 크기를 최대한 균일하게 맞추는 작업을 수행할 수 있다. 전문가 단말은 데이터 에 따라 바운딩 박스 어노테이션(Bounding Box Annotation) 또는 키포인트 어노테이션(Keypoint Annotation)을 수행할 수 있고, 검수 단말의 교차 검수를 통해 데이터 검수가 되며, 검수를 통과하지 못한 데이터를 제출 한 전문가 단말은 재가공 및 상술한 과정을 반복하게 된다. 상세한 과정은 정부의 가이드라인에 개시되어 있으므로 상세한 설명은 생략하기로 한다. 여기서, 적어도 하나의 전문가 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터 로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데 스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 전문가 단말은, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 전문가 단말은, 예 를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 적어도 하나의 검수 단말은, 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 관련 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 이용하여 전문가 단말에서 어노테이션 또는 라벨링한 데이터를 검 수하거나, 인공지능 알고리즘에서 출력한 부위명칭 및 매칭률의 오류는 없는지를 검수하는 검수자의 단말일 수 있다. 하나의 전문가 단말에서 어노테이션 또는 라벨링한 데이터는 적어도 두 개의 검수 단말에서 교차 검수를 수행하도록 하고, 정밀도(Precision)검수와 재현률(Recall)검수 두 단계를 거칠 수 있으며, 검수를 통과하지 못한 데이터는 자동으로 가공 프로세스 초기 단계로 복귀시키는 단말일 수 있다. 여기서, 적어도 하나의 검수 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스 크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 검수 단말은, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 검수 단말은, 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 도 2는 도 1의 시스템에 포함된 판별 서비스 제공 서버를 설명하기 위한 블록 구성도이고, 도 3 및 도 4는 본 발명의 일 실시예에 따른 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스가 구현된 일 실시예를 설명 하기 위한 도면이다. 도 2를 참조하면, 판별 서비스 제공 서버는, 구축부, 모델링부, 세팅부, 질의부, 전 송부, 전처리부, 관심영역설정부, 전처리부, 관심영역설정부, 증강현실부, 맛판 단부, 업데이트부, 크라우드소싱부, 빅데이터화부 및 가성비안내부를 포함할 수 있다. 본 발명의 일 실시예에 따른 판별 서비스 제공 서버나 연동되어 동작하는 다른 서버(미도시)가 적어도 하 나의 사용자 단말, 적어도 하나의 전문가 단말 및 적어도 하나의 검수 단말로 영상 기반 인공지 능 알고리즘을 이용한 식육 판별 서비스 애플리케이션, 프로그램, 앱 페이지, 웹 페이지 등을 전송하는 경우, 적어도 하나의 사용자 단말, 적어도 하나의 전문가 단말 및 적어도 하나의 검수 단말은, 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 애플리케이션, 프로그램, 앱 페이지, 웹 페이지 등을 설치하거나 열 수 있다. 또한, 웹 브라우저에서 실행되는 스크립트를 이용하여 서비스 프로그램이 적어도 하나의 사용자 단말, 적어도 하나의 전문가 단말 및 적어도 하나의 검수 단말에서 구동될 수도 있다. 여기서, 웹 브라우저는 웹(WWW: World Wide Web) 서비스를 이용할 수 있게 하는 프로그램으로 HTML(Hyper Text Mark-up Language)로 서술된 하이퍼 텍스트를 받아서 보여주는 프로그램을 의미하며, 예를 들어 넷스케이프 (Netscape), 익스플로러(Explorer), 크롬(Chrome) 등을 포함한다. 또한, 애플리케이션은 단말 상의 응용 프로 그램(Application)을 의미하며, 예를 들어, 모바일 단말(스마트폰)에서 실행되는 앱(App)을 포함한다. 도 2를 설명하기 이전에, 영상 기반 객체인식 인공지능의 기본개념에 대하여 이하에 설명하기로 한다. 이하에 서 설명된 내용들은 도 2에서 중복하여 기재하지 않는다. 객체 인식이란 하나의 특정 이미지를 입력했을 때, 주어진 이미지를 분석하여 특정한 객체(Object)의 위치 (Location)와 종류(Class)를 파악하는 것이다. 즉, 우선 영상에서 객체의 위치를 찾아야하고(Localization), 그 위치의 객체가 어떤 물체인지를 분류해야 된다(Classification). 이를 수행하기 위하여 다양한 방법들이 시 도되어 왔고, 최근 단일단계 검출 방법과 두 단계 검출 방법으로 좁혀지고 있다. 단일 단계 검출 방법은 모든 영역에 대해서 위치 검출과 분류를 동시에 수행한다. 두 단계 검출 방법은 대략적인 위치 검출을 수행하고, 선 출된 후보군들에서 분류를 수행한다. 단일 단계 검출기는 앞에서 언급한 것과 같이 모든 영역에서 객체의 위치 검출과 분류를 동시에 수행한다. 이를 동시에 수행하다보니, 속도는 빠르지만 정확도는 두 단계 검출 방법보다 조금 떨어지는 단점이 존재한다. 반대로 두 단계 검출기는 객체 위치 검출과 분류가 순차적으로 이루어지므로, 정확도는 상대적으로 뛰어나지만 속도가 느리다는 단점을 가지고 있다. 단일 단계 검출기의 대표적인 예로는 YOLO, SSD 알고리즘이, 두 단계 검출기의 대표적 예로는 R-CNN, Faster R-CNN이 있다. 단일 단계 방식과 두 단 계 방식은 인식 속도와 인식 정확도 부분에서 각각의 장점을 갖고 있기 때문에 두 가지 모두 고르게 연구되고 있다. 영상 기반 객체 인식 기술을 단일 단계 검출 방법 및 두 단계 검출 방법으로 나누어 각 알고리즘에 대해 기술한다. <YOLO 알고리즘> 단일 단계 알고리즘의 대표적 예인 YOLO(You Only Look Once) 알고리즘은 하나의 컨볼루션 네트워크를 통해 여 러 바운딩 박스(Bounding Box)에 대한 클래스 확률을 계산하는 방식으로 이루어진다. YOLO는 각각의 바운딩 박 스를 예측하기 위해 이미지 전체의 특징을 활용하는데 이러한 YOLO의 디자인 방식 덕분에 정확성을 유지하면서 종단 간(End-to-End) 학습과 빠른 객체 검출이 가능하다. YOLO에 이미지를 입력하게 되면, 먼저 그 이미지를 SxS 크기의 그리드(Grid)로 나누게 되고 각각의 그리드 셀(Grid Cell)은 B 개의 네모박스와 각 박스에 대한 신 뢰도 점수(Confidence Score)를 갖게 되는데, 이를 수식으로 나타내면 이하 수학식 1과 같다. 수학식 1"}
{"patent_id": "10-2022-0050727", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "각각의 바운딩 박스는 박스의 중심점으로부터 그리드 셀의 범위에 대한 상대값인 (X,Y) 좌표와 전체 이미지의 폭, 높이와 그리드 박스의 폭, 높이에 대한 상대값인 IOU(Intersection Over Union) 및 신뢰도로 구성되게 된다. YOLO 모델은 단일 CNN 구조를 이용하여 설계되었다. YOLO에서의 CNN 구조의 앞단은 컨볼루션층 (Convolutional Layer)이고, 이어서 전결합층(Fully-Connected Layer)으로 구성되어 있다. 컨볼루션층은 이미 지로부터 특징을 추출하고, 전결합층은 클래스 확률과 바운딩 박스의 좌표를 예측한다. 추론 단계에서도 이미 지로부터 객체를 검출하는 데에는 하나의 신경망 계산만 하면 되기 때문에 매우 빠른 속도를 얻을 수 있다. 만 약 객체가 있을 확률이 매우 낮다면, 그곳에 어떠한 클래스가 있는지에 대한 정보도 매우 낮아지게 된다. 위와 같은 과정을 모든 그리드 셀에서 반복하고 그 결과를 종합하는 것으로 최종적인 객체 인식 과정을 마치게 된다. 그러나 YOLO의 그리드 디자인은 한 가지 단점이 있는데, 하나의 객체를 여러 그리드 셀이 동시에 검출하는 경우 가 있다는 점 때문이다. 객체의 크기가 크다거나 객체가 그리드 셀의 경계에 인접해 있는 경우, 그 객체에 대 한 바운딩 박스가 여러 개 생길 수 있다. 즉, 하나의 그리드 셀이 아니라 여러 그리드 셀에서 해당 객체에 대 한 바운딩 박스를 예측할 수 있다는 것이다. 하나의 객체가 하나의 그리드 셀에만 존재하는 경우에는 문제가 없지만, 객체의 크기나 객체의 위치에 따라 이러한 문제가 발생할 수 있고 이를 다중 검출 문제라고 한다. 이 런 다중 검출 문제는 비 최대 억제(Non-Maximal Suppression, NMS) 알고리즘을 적용하여 개선할 수 있다. 비 최대 억제 알고리즘은 각 객체에 대해 예측한 바운딩 박스들 중 가장 높은 정확도를 가진 박스만을 남기기 위한 것으로, 간단히 말해 어떠한 바운딩 박스가 있을 때, 그 바운딩 박스의 분류 점수 순서대로 박스를 내림차 순으로 정렬시켜 순서대로 바운딩 박스의 IOU의 값이 설정한 임계치 값 이하이면, 그 박스를 버리는 방식이다. 단, 임계값을 크게 설정하면 그 값보다 낮은 값을 제거하게 되므로 다수 객체를 인식할 때 정밀도가 감소하게 된다. 결과적으로, 가장 객체가 존재할 가능성이 높은 곳의 바운딩 박스만을 남기게 된다. YOLO는 비교적 빠르고 정확한 출력을 얻을 수 있는 객체 인식 알고리즘이나, 학습 단계에서 몇 가지 한계를 갖 고 있다. 우선 공간적 제약(Spatial Constraints)이다. YOLO는 하나의 그리드 셀마다 두 개의 바운딩 박스를 예 측하고, 하나의 그리드 셀에서 하나의 객체만을 검출할 수 있다. 결과적으로 하나의 그리드 셀에 두 개 이상의 객체가 붙어있다면 이를 잘 검출하지 못하는 문제를 발생시킨다. 두 번째 문제로는 종횡비의 문제가 있다. YOLO 모델은 기존의 데이터로부터 바운딩 박스를 예측하는 것을 학습하기 때문에, 훈련 단계에서 학습하지 못했 던 새로운 종횡비(Aspect Ratio, 가로세로 비율)를 갖는 이미지에서는 검출에 오차가 생기게 된다. 마지막으로 부정확한 위치에 대한 문제가 있다. YOLO는 큰 바운딩 박스와 작은 바운딩 박스에 대해 동일한 가 중치를 둔다. 큰 바운딩 박스에 비해 작은 바운딩 박스가 위치 변화에 따른 IOU 변화가 더 심하기 때문에, 결 과적으로 크기가 큰 바운딩 박스는 위치가 약간 달라져도 객체 인식 능력에 별 영향을 주지 않지만 크기가 작은 바운딩 박스의 경우 위치가 조금만 달라져도 성능에 큰 영향을 줄 수 있고 이로 인한 오차가 발생할 수 있다. <SSD 알고리즘> SSD(Single Shot Multibox Detector)는 단일 단계 검출 기반의 알고리즘으로 위 언급한 YOLO의 한계를 극복하 기 위해 탄생한 기술이다. SSD는 YOLO와 달리 컨볼루션 과정을 거치는 중간 중간 특징맵 들에서 모두 객체 검 출을 수행한다. 컨볼루션층을 계속 진행하여 최종적으로는 1×1 크기의 특징맵까지 뽑게되고 각 단계별로 추출 된 특징맵은 Detector & Classifier를 통과시켜 객체 인식을 수행한다. 높은 해상도의 특징 맵에서는 작은 물 체를 잘 잡아낼 수 있고, 낮은 해도의 특징 맵에서는 큰 물체를 잘 잡아낼 것이라고 추측할 수 있다. SSD는 각 각의 피쳐맵을 가져와서 비율과 크기가 각기 다른 디폴트 박스(Default Box)를 투영한다. 그리고 이렇게 찾아 낸 박스들에 신뢰도(Confidence Level)를 계산한다. <CNN 알고리즘> CNN(Convolution Neural Network)은 대표적인 두 단계 검출 기법으로 가장 널리 쓰이는 영상 이미지 분석 기술 중 하나이다. CNN은 유용한 정보를 얻기 위해 입력 데이터를 필터링하기 위해 사용되는 컨볼루션층 (Convolutional Layer)과 풀링층(Pooling Layer)으로 이루어져 있다. 컨볼루션층에서는 컨볼루션 연산, 패딩 (Padding), 스트라이드(Stride)가 이루어진다. 컨볼루션 연산은 이미지 처리에서 말하는 필터 연산을 말하며, 컨볼루션 연산에서 주요 단어를 꼽자면 필터(Filter), 윈도우(Window), 단일 곱셈-합산(Fused Multiply-Add, FMA)이 있다. 컨볼루션 연산에는 입력 데이터에 필터를 적용하여 데이터의 크기를 줄인다. 패딩은 제로 패딩 (Zero Padding)이라고도 부르며 컨볼루션 연산을 수행하기 전에 미리 입력 데이터 주변에 0을 비롯한 특정 값을 채워 넣어 출력 크기를 조정할 목적으로 사용한다. 다음으로 스트라이드는 필터를 적용하는 위치의 간격을 정하는 것을 의미한다. 풀링층은 가로, 세로 방향의 공 간을 줄이는 연산 작업이며 최대 풀링(Max Pooling)과 평균 풀링(Average Pooling)의 두 가지 과정이 있다. 최 대 풀링의 경우 가장 큰 값들만을 가져와서 표기 하는 방식으로 4×4의 행렬을 2×2의 행렬로 줄여줌으로써 파 라미터(Parameter)의 개수를 줄여 소요되는 컴퓨팅 리소스와 시간을 단축할 수 있다는 장점이 있다. 평균 풀링 은 풀링 영역의 평균을 계산하는 연산이다. 풀링의 윈도우 크기는 스트라이드와 같은 값을 설정하는 것이 보통 이며, 예로 윈도우가 (3,3)이면, 스트라이드는 3으로 설정한다. 이러한 풀링층의 특징은, 먼저 학습해야 할 매 개변수가 없고, 채널 수가 변하지 않으며 입력의 변화에 영향을 적게 받는다는 점이다. 컨볼루션층은 필터를 이용하여 로우 레벨(Low Level)의 특징들을 잡아내고, 점차적으로 하이 레벨(High Level) 의 특징들을 찾아내게 된다. 그 이후 추출한 특징들을 바탕으로 전연결층에서 이미지가 무엇인지를 인식하게 된다. 전연결층은 컨볼루션층으로 추출한 특징을 분류하는 역할을 하며, 보통 수 십에서 수 천 개의 특징을 다 룬다. 각 계층을 1 차원 벡터로 변환하는 Flatten 과정 이후 1 차원 벡터로 변환된 계층을 나의 벡터로 연결하 여 가장 확률이 높은 것을 출력한다. 최근 CNN을 이용하여 입력 이미지로부터 이미지 픽셀을 직접 분류하거나, CNN을 이용해 추출된 특징에 결정트리(Decision Tree), 서포트벡터머신(Support Vector Machine) 등의 기계학 습을 적용하여 라인을 구분하기도 한다. 물체 인식을 위해서는 CNN 기반 모델인 AlexNet이 대세를 이루고 있다.<R-CNN 알고리즘> R-CNN(Region Based Convolutional Neural Networks)은 전처리 과정으로 원하는 영상에 선택적 탐색을 적용하 여 객체가 있으리라 추정하는 후보 영역(Region Proposal, RP)을 찾아낸 다음, 각 후보 영역마다 CNN을 적용하 는 방법을 사용한다. 후처리 과정으로 전통적인 서포트벡터머신 기법을 이용하여 CNN에서 얻은 결과물을 판별 한다. 하지만 전반적인 검출과정에서 RP 마다 CNN을 적용해야 하며 RP 자체도 계산이 필요하므로 성능 문제가 발생한다. <Faster R-CNN 알고리즘> R-CNN의 문제를 해소하기 위해 Faster R-CNN이 제안되었는데, Faster R-CNN에서는 객체가 있을 만한 위치에 대 한 후보군 RoI(Region of Interest)라는 층을 도입하여 CNN을 한 번만 적용하고 RoI 풀링으로 객체 판별을 위한 특징을 추출한다. 따라서 RP 계산은 물론이고 RP 마다 반복적인 CNN 적용도 필요하지 않으므로 성능을 높일 수 있다. 또한 R-CNN 과는 달리 영상 판별을 위해 SVM을 사용하지 않고 단일 네트워크 내부에 소프트맥스 (Softmax) 층을 배치하는 방법으로 모델을 단순화할 수 있다. 입력 이미지로부터 특징 맵을 추출한 다음 RoI를 계산한다. 여기서 얻은 RoI를 이용하여 풀링을 진행한 다음, 분류를 진행하여 객체 검출을 수행하는 것이다. 즉 객체가 있을 만한 위치에 대한 RoI, 즉 후보군들을 찾아낸 후, 후보군들 각각에 대해 분류를 수행하고, 후보 군 내에서 더욱 정확한 위치에 대한 연산을 수행하는 것이다. 이에, 본 발명의 일 실시예에서는 단일 단계 검출 알고리즘은 높은 속도를 가지지만, 낮은 정확도를 가진다는 단점이 존재하는, 반면 두 단계 검출 알고리즘은 정확도는 높으나, 속도가 떨어진다는 단점이 존재함을 고려하 여, 객체 인식 응용 특성에 따라 빠른 속도를 갖는 YOLO, SSD와 같은 단일 단계 알고리즘을 또는 우수한 정확도 를 갖는 R-CNN, Faster R-CNN과 같은 두 단계 알고리즘을 선별적으로 이용할 수 있다. 물론, 상술한 딥러닝 기 반 알고리즘 외에도 기계학습(머신러닝) 기반 알고리즘을 이용할 수 있음은 자명하다 할 것이다. 상술한 기본개념을 기반으로 도 2를 참조하면, 구축부는, 적어도 하나의 식육(食肉) 이미지, 지방 및 단백 질의 분포 이미지 및 적어도 하나의 부위명칭을 매핑하여 데이터셋(DataSet)을 구축할 수 있다. 이때, 단백질 이란 살코기 부위를 의미할 수 있다. 또한, 지방과 단백질을 구분하는 기준은 색상코드에 의할 수 있다. 모델링부는, 데이터셋을 이용하여 적어도 하나의 인공지능 알고리즘을 학습 및 검증하여 모델링할 수 있다. 적어도 하나의 인공지능 알고리즘은, 적어도 하나의 머신러닝 알고리즘 또는 적어도 하나의 딥러닝 알 고리즘일 수 있다. 또한, 적어도 하나의 인공지능 알고리즘은, 질의로 입력된 이미지 내 객체를 탐지(Object Detection)하고, 시멘틱 세그멘테이션(Segmantic Segmentation) 및 인스턴스 세그멘테이션(Instance Segmentation)을 순차적으로 수행하여 지방 및 단백질의 분포 형상 및 비율을 비교할 수 있다. 이때, 시멘틱 세그멘테이션은 객체 분할을 하되, 동일한 클래스인 객체끼리는 동일한 영역 또는 색으로 분할한다. 예를 들어, 탁자에 의자가 4 개 있다면, 의자 4 개는 동일한 색으로 칠해진다. 반면, 인스턴스 세그멘테이션은, 객 체 분할을 하는 과정은 동일한데, 같은 클래스여도 서로 다른 인스턴스로 구분해준다. 상술한 예를 계속 인용 하면, 탁자에 의자가 4 개 있어도, 4 개의 의자는 서로 다른 색으로 칠해진다. 따라서, 각 객체가 겹쳤을 때 각각의 객체를 구분해주지 못하는 시멘틱 세그멘테이션의 문제를 인스턴스 세그멘테이션을 통하여 해결할 수 있 다. 이에, 클래스 레벨이 N 개 존재하는 경우, 시멘틱 세그멘테이션에서는 각 픽셀들이 어떠한 클래스에 포함되는지 또는 안되는지를 N 개의 클래스에 대하여 바이너리하게 계산한다면, 인스턴스 세그멘테이션은 이미 위치 (Localization)를 찾은 후, 그 바운딩 박스가 포커싱하고 있는, 즉 RoI가 포커싱하고 있는 인스턴스의 픽셀이 궁금한 것이므로, 각 바운딩 박스에 이미지 세그멘테이션을 하는데, 동일 클래스여도 서로 다른 인스턴스라면 값을 가지지 않는다. <시멘틱 세그멘테이션> 시멘틱 세그멘테이션은 이미 지내의 모든 픽셀에 대해 클래스 분류를 수행한다. 따라서 이미지내의 특정 객체 를 구분해내는 것 뿐만 아니라 모든 객체 및 영역에 대해 픽셀 기반으로 분류를 수행할 수 있다는 장점을 가지 고 있다. 시멘틱 세그멘테이션을 통한 분류 성능을 좌우하는 가장 큰 요소는 데이터의 정형성인데, 이미지의 각 픽셀에 해당하는 클래스를 표시할 수 있게 된다. 시멘틱 세그멘테이션은 예를 들어, U-Net, DeepLAB v3, SegNet 모델을 이용할 수 있다. <인스턴스 세그멘테이션> 인스턴스 세그멘테이션에는 이미지 분할 뿐만 아니라 지역화 또한 동반되기때문에 문제에 대한 접근법 또한 객 체 검출과 유사하다. 대표적인 알고리즘인 Mask R-CNN 또한 객체 검출알고리즘인 Fast R-CNN에 마스크를 생성 하기 위한 가지를 추가한 형태이다. 그러나, 일반적인 인스턴스 세그멘테이션 알고리즘은 속도가 매우 느리다. 관심 영역을 찾아내는 작업에 시간이 많이 소요되는데, 마스크 생성 작업은 그 이후에 수행되어야만 하기 때문 이다. 반면, YOLACT는 하나의 관심 영역에 국한되지 않는 여러 개의 프로토타입 마스크를 생성함과 동시에 관 심 영역마다 각각의 프로토타입을 반영할 계수를 계산하여, 프로토타입 마스크들의 선형결합으로 최종 마스크를 얻기 때문에 실시간 처리가 가능하다. 세팅부는, 적어도 하나의 인공지능 알고리즘 중 정확도가 가장 높은 인공지능 알고리즘을 판별 서비스를 위한 인공지능 알고리즘으로 세팅할 수 있다. 물론 한 가지 인공지능 알고리즘으로만 세팅하는 것은 아니고 상 술한 기본개념과 같이 각 부위별, 종별, 축산물별 등으로 가장 높은 인공지능 알고리즘을 각각 세팅할 수도 있 고 혼합하여 하이브리드로 설정할 수도 있다. 질의부는, 사용자 단말에서 입력된 이미지를 세팅된 인공지능 알고리즘에 질의(Query)로 입력할 수 있다. 사용자 단말은, 식육을 촬영한 이미지를 업로드하고, 업로드된 이미지에 대한 부위명칭 및 기 설정 된 식육 기준과의 매칭률을 출력할 수 있다. 이때 질의되는 이미지는 전처리가 된 이미지인데 전처리에 대해서 는 전처리부에서 후술하기로 한다. 전송부는, 질의로 입력된 이미지와 데이터셋 내 이미지 간 유사도를 매칭률로 출력하여 사용자 단말 로 전송할 수 있다. 데이터셋 내 이미지는 전문가에 의해 선별된 \"좋은 고기\"에 대한 사진(식육 이미지) 및 마 블링(지방 및 단백질의 분포 이미지)이므로, 이와 비슷한 고기를 찾는 것이 목표이다. 이때, 데이터셋 내 기 저장된 지방 및 단백질의 분포 이미지는 후술하는 바와 같이 세그멘테이션과 같은 어노테이션이 이미 된 라벨링 데이터이다. 그리고, 질의로 입력된 이미지(식육 이미지)는, 바운딩 박스를 통하여 객체 탐지, 및 2 단계의 세 그멘테이션을 통하여 윤곽선 확정 및 지방과 단백질 분포를 자동으로 파악한 이미지이다. 데이터셋 내 이미지 ([식육 이미지]&[지방 및 단백질의 분포 이미지])와, 사용자가 질의로 입력한 이미지([식육 이미지]&[지방 및 단백질의 분포 이미지])를 비교할 수 있다. 상세히 설명하면, 질의로 입력된 식육 이미지로는 부위명칭을 찾아 내고, 부위명칭과 매핑되어 기 저장된 데이터셋 내 이미지([지방 및 단백질의 분포 이미지])와, 바운딩 박스 및 세그멘테이션 처리된 사용자의 이미지([지방 및 단백질의 분포 이미지])를 비교하는 것이다. 이 두 개의 패턴 (특징맵)이 유사할수록 매칭률은 올라가고, \"좋은 고기\"일 확률이 높아진다. 전처리부는, 사용자 단말에서 업로드된 이미지에 대한 이미지 흔들림 보정(Image Stabilization), 카 메라 캘리브레이션(Camera Calibration), 색 분석 및 히스토그램 균일화(Histogram Equalization)를 수행할 수 있다. 이때, 렌즈 왜곡이 존재하는 경우, 렌즈 왜곡 보정도 수행할 수 있다. 색 분석은 컬러코드를 추출하는 과정일 수 있고 기 저장된 컬러차트와의 대비를 이용할 수 있다. 이때, 히스토그램 균일화(또는 평활화)는 히 스토그램을 이용하여 이미지의 명암 대비를 개선시키는 방법이다. 또, 이하의 관심영역설정부의 영상분할 (Image Segmentation)을 위해 식육과 배경을 분리하기 위한 전처리 과정으로 회색조(Gray Scale) 영상으로 변환 할 수 있고, 식육과 배경을 이치화하기 위하여 EM(Expectation Maximization) 알고리즘을 이용할 수 있다. EM 알고리즘은 정보가 은닉되어 있는 경우 가장 유사한 모델을 추정할 때 사용되는 효과적인 반복 알고리즘으로 Maximum Likelihood Estimate 방법을 사용하여 모델 변수를 추정하는 방법이다. 예를 들어 수직 히스토그램이 식육 외곽선에 대한 히스토그램이고, 수평 히스토그램이 조명 왜란에 의해 발생한 노이즈라고 가정하면, 노이즈 를 제거하기 위해 두 개의 가우시안 커브가 만나는 지점을 이치화 값으로 설정할 수 있다. 만약, EM 알고리즘 을 적용하여도 샤클(Shackle)과 노이즈가 나타나는 경우, 샤클과 노이즈를 제거하기 위해 모폴로지 알고리즘인 영상침식(3×3 마스크)을 수행할 수 있다. 그럼에도 불구하고 노이즈가 남는 경우, 노이즈 영역을 제거하기 위 해 라벨링 알고리즘을 적용할 수 있다. 관심영역설정부는, 전처리부에서 전처리된 이미지에 대하여 지방 및 단백질을 구분하도록 지방 및 단백질 에 대응하는 부위를 RoI(Region of Interest)로 설정할 수 있다. 이때, 관심영역인 RoI는 상술한 기본개념 내 의 후보군을 의미할 수 있다. 증강현실부는, 사용자 단말에서 식육의 부위명칭을 선택한 후, 전면카메라를 구동시켜놓는 경우, 전 면카메라에 촬영된 피사체인 객체의 부위명칭을 판별하여 증강현실 콘텐츠로 사용자 단말의 화면 상에 객 체 부위에 증강하여 디스플레이하고, 객체와 데이터셋 내 부위명칭이 일치하는 식육 이미지와의 매칭률에 기반 하여 좋은 식육인지의 여부를 판별해줄 수 있다. 고객인 사용자 입장에서 가장 중요한 것은 한 장 한 장 사진 을 찍어서 비교결과를 얻는 것이 아니라, 윈도우쇼핑하듯이 카메라로 판매대 위의 포장육을 촬영하면서 어느 것이 좋은 고기인지 판별해주는 서비스이다. 예를 들어, 구글에서 실시간으로 OCR을 적용하여 해외여행 시 간판 을 모국어로 화면 내에서 바로 바꾸어주는 것과 같이, 실시간으로 입력된 영상 내 객체를 찾는 객체 탐지, 즉 바운딩 박스를 씌우고, 2 단계 세그멘테이션을 진행한 후, 인공지능 알고리즘에 질의로 입력한다. 물론, 그 이 전에 전처리를 하는 것은 물론이다. 그리고 나서 인공지능 알고리즘에서 매칭률(유사도)이 나오면 이를 즉석에 서 증강현실 콘텐츠로 출력해줄 수 있고, 사용자는 실시간으로 촬영된 화면을 보면서 어느 포장육 또는 세절육 이 좋은 고기인지 확인할 수 있게 된다. 맛판단부는, 사용자 단말에서 식육의 부위명칭을 선택한 후, 전면카메라를 구동시켜놓는 경우, 부위 명칭과 기 매핑되어 저장된 지방 및 단백질의 분포 이미지가 가장 유사한 객체를 탐색하여 화면상에 실시간으로 표기해줄 수 있다. 즉, 가성비가 좋은 고기인지를 확인할 수 있게 된다. 후술하는 바와 같이 척아이 부위에서 꽃등심에 근처에 있는 흉추 5 번 부위를 골라낼 수 있다면, 훨씬 저렴한 가격에(립아이는 척아이보다 1.5배 비 싸므로) 비슷한 맛을 낼 수 있는 가성비있는 구매가 될 수 있다. 이때, 각 식육의 가격은 매일 달라지게 되므 로, 각 부위별 한우, 수입육의 가격차이, 또는 한우 내에서도 각 부위별 차이, 수입육 내에서도 각 부위별 차이 에 대한 평균통계데이터의 퍼센테이지를 저장해둘 수 있다. 예를 들어, 쇠고기의 식육 중 부위명칭이 등심인 부위가 있다. 식품의약품안전처고시 제2019-113호 소·돼지 식육의 표시방법 및 부위 구분기준 및 별표1에 의하면, 한국에서는 등심부위를 도 4와 같이 윗등심, 꽃등심 및 아랫등심으로 구분한다. 등심은 흉추 1 번 내지 12 번에 붙은 부위인데, 윗등심은 흉추 1 번 내지 5 번, 꽃등 심은 6 번 내지 9 번, 아랫등심은 10 번 내지 12 번에 위치한 부분을 절단한 것을 말한다. 이 부위 중에서 가 장 맛이 좋고, 좋은 부위는 꽃등심이다. 윗등심, 꽃등심 및 아랫등심에 붙어잇는 부위는 각기 다른데, 윗등심 은 살치살, 등심, 등심덧살이고, 꽃등심은 하늘색 표시 부분과 같이 새우살과, 등심, 등심덧살이다. 아랫등심 은 채끝살, 등심 및 등심덧살로 구분된다. 아랫등심은 새우살, 등심, 등심덧살로 구분된다. 아랫등심에서 채 끝으로 갈수록 새우살은 줄어들고 등심이 커지다가 채끝살과 안심으로 분화된다. 실질적으로 꽃등심과 아랫등 심은 구분이 어려워 법적인 분류를 떠나 아랫등심도 꽃등심으로 부르기도 한다. 꽃등심이 가장 비싸고 맛있기 위해서는 도 4의 새우살의 유무가 중요하다. 새우살이 붙어있는지, 또 얼마나 많 이 붙어있는지에 따라 맛이 달라진다. 윗등심의 경우 살치살의 지방 형태 및 크기에 따라 맛의 차이가 크다. 따라서, 마트에서 같은 등심을 고르더라도 새우살이 있는지, 살치살은 있는지, 또 있다면 어떠한 형태로 있는지, 분포는 어떠한지, 그 크기와 비율은 어떠한지 등을 고려하여 구매하는 것이 소비자에게 유리하다. 물 론, 쇠고기의 등심 외의 부위는 물론 돼지고기에서도 목살이나 삼겹살 등 부위에 따라, 부위에 따른 지방과 단 백질의 분포에 따라, 또는 비율에 따라 맛이 달라지는 경우가 있다. 또, 수입산 식육을 많이 구입해서 먹는데, 한국에 주로 수입되는 쇠고기는 미국, 호주 및 일본산이 있다. 이때, 수입되는 부위가 한국의 부위구분과 다르다. 예를 들어, 미국산 등심은 척아이(Chuckeye)와 립아이 (Ripeye)로만 구분되어 수입된다. 척아이는 한국의 윗등심과 같이 소의 흉추 1 번 내지 5 번까지의 부위이고, 립아이는 6 번 내지 12 번까지 부위이다. 상술한 바와 같이 꽃등심이 6 번 내지 9 번 부위이므로, 한우와의 가 격차 때문에 수입육을 고르는 소비자 입장에서는 립아이를 사면 꽃등심을 더 저렴한 가격에 살 수 있다. 이때, 립아이가 척아이보다 1.5배 비싸다. 이렇게 식육의 각 부위를 알고 있으면, 저렴한 가격으로 꽃등심과 비슷한 부위를 고를 수 있다. 윗등심과 척아이 부위에서 흉추 5 번 부위, 즉 꽃등심에 가까운 부위를 고를 수 있다면, 또 잘 고른다면 한우와 비교하여 반 가격, 또는 수입육이더라도 30% 이상 싼 가격으로 비슷한 맛을 내는 부위를 먹을 수 있다. 업데이트부는, 복수의 사용자 단말에서 업로드 및 인공지능 알고리즘에 질의로 입력된 이미지와, 인 공지능 알고리즘에 의해 판별된 매칭률을 적어도 하나의 검증 단말로 전송하고, 질의로 입력된 이미지 및 판별된 매칭률에 대한 오류 검증을 실시하며, 오류검증 결과 오류가 발생된 경우, 오류가 발생된 오류부분 및 오류원인을 적어도 하나의 검증 단말로부터 수신하여 오류패턴을 수정하도록 업데이트할 수 있다. 사용자 단말은 서로 다른 주체에 귀속된 복수의 사용자 단말일 수 있다. 크라우드소싱부는, 데이터셋(DataSet)을 이루는 적어도 하나의 식육 이미지, 지방 및 단백질의 분포 이미 지 및 적어도 하나의 부위명칭을 매핑할 때, 적어도 하나의 전문가 단말로 크라우드소싱(CrowdSourcing)을 수행하여 어노테이션(Annotation)을 의뢰한 후, 어노테이션 결과는 적어도 하나의 검증 단말에서 검수한 후 데이터셋으로 입력하도록 할 수 있다. 정부에서 인공지능 및 4차 산업혁명을 과제로 선정하면서 최우선 고 용직종이 라벨러(Labeller)였다. 즉, 기계는 학습할 데이터셋을 인간이 잘 선별하여 제공해야, 이를 학습 및 검증한 후, 유사한 영상, 이미지, 텍스트 등을 분별할 수 있게 된다. 만약, 이미지 판별 인공지능을 모델링한다고 가정하면, 인간이 잘 선별한 [이미지]와, 해당 이미지가 무엇을 의미하는지를 라벨링한 [라벨]이 필요하다. 예를 들어, 쇠고기 등심부위의 A++ 등급의 이미지가 있다면, 기계는 해당 이미지를 보고 라벨이 없 다면 무엇을 의미하는지 모른다. 이때, 인간이 [이미지-쇠고기 등심부위-A++ 등급]으로 라벨링을 해준 후, 데 이터셋으로 지정을 해두어야, 기계인 인공지능은 학습을 할 수 있게 되는 것이다. 또, 이미지 내 마블링을 보고 인간은 지방과 단백질(살코기)가 적절히 잘 배합이 되었다는 것을 배경지식으로 알 수 있지만, 기계는 모른다. 이에, 이미지 내 식육이 위치한 위치를 사각형 박스로 표시하는 바운딩 박스 작 업 후, 바운딩 박스 내 윤곽선 디텍션과 같이 세그멘테이션, 즉 윤곽선을 따라 배경과 구분하는 세그멘테이션 작업을 수행하고, 그 다음 계육의 경우에는 관절이 정확한 위치에 존재하는지를 파악하기 위해 OpenPose와 같이 골격을 파악하는 키포인트 작업을 수행하게 된다. 정리하면, [바운딩 박스->세그멘테이션->키포인트]의 작업으 로 정리될 수 있고, 계육을 제외하면 [바운딩 박스->세그멘테이션]의 과정으로 정리될 수 있다. 이 과정은 상 술한 바와 같이 2 명 이상의 검수자가 교차검수할 수 있으며 이렇게 생성된 데이터셋은 인공지능이 학습할 원천 자료가 된다. 이렇게 학습 및 검증이 끝난 경우를 모델링이 완료되었다고 하며, 모델링이 완료된 인공지능 알 고리즘은, 질의 이미지(Query Image)가 입력되면, 바운딩 박스로 식육에 대응하는 객체를 찾고(Localization), 객체의 윤곽을 구분하며(Segmentation), 지방 및 단백질을 구분하기 위해 시멘틱 및 인스턴스 세그멘테이션으로 자동 구분하여 마블링이 있는 것인지, 기 저장된 데이터셋의 이미지와 비교하여 좋은 고기인 것인지 등을 판단 할 수 있게 된다. 라벨링을 위하여 어노테이션 및 라벨링(Annotation and Labelling)을 포함하는 이미지 어노테이션 시스템을 이 용할 수 있다. [이미지-라벨]을 연결하는 라벨링 작업이 시간과 인력이 많이 소요되기 때문에 라벨러를 별도로 고용하여 라벨링을 하지 않는 이상 대규모의 데이터셋을 마련하는데 시간이 걸리기 마련이다. 학습 데이터 집 합은 원본 이미지가 아닌 특징을 추출한 서브 이미지와 그 특징을 분류하는 태그(Tag) 정보로 구성된다. 이미 지 어노테이션 시스템은 학습 데이터 집합을 생성하는 단계에서 사용할 수 있는, 즉 이미지의 특징을 추출한 서 브 이미지를 생성하고 이미지 어노테이션을 수행하기 위한 도구이다. 이때, 어노테이션 및 라벨링을 위해서는 다양한 오픈소스(Open Source) 도구를 이용할 수도 있는데 이러한 도구들은 웹 기반으로 구성되어 사용자가 직 접 이미지를 업로드하고, 이미지로부터 특징을 추출하며, 분류를 위한 태그 정보를 입력함으로써, 이미지 어노 테이션을 수행할 수 있다. 인간과 기계가 협업하여 성과를 내는 방법 중 하나인 크라우드소싱은 지식 추출에 필요한 개체 연결, 개체 군집 (상호참조해결), 그리고 관계 추출의 기계학습 데이터를 효과적으로 생성하는 다중 작업 주석 방법이다. 크라 우드소싱 방법으로 기계 학습에 필요한 학습 데이터를 수집할 때 고려해야할 것들이 있다. 먼저 작업자 (Worker)가 작업에 대한 충분한 이해를 할 수 있게 교육을 진행해야 하며, 그 다음 악성 작업자를 걸러내는 장 치가 필요하고, 마지막으로 작업이 진행되는 동안 지속적으로 데이터 품질을 관리하는 장치가 필요한데 이는 교 차 검증을 서술했으므로중복하여 설명하지 않는다. 빅데이터화부는, 데이터셋을 위한 빅데이터를 구축할 때, 인공지능 학습용 데이터 품질관리 가이드라인에 따라 빅데이터를 구축할 수 있다. 가성비안내부는, 데이터셋은 적어도 하나의 식육 이미지, 지방 및 단백질의 분포 이미지 및 적어도 하나의 부위명칭 외에, 적어도 하나의 식육 이미지와 유사한 맛을 내는 부위의 유사 식육 이미지와, 유사 식육 이미지 의 지방 및 단백질의 분포 이미지와, 적어도 하나의 식육 이미지에 대응하는 부위가격과의 가격차이의 퍼센테이 지를 더 포함하고, 유사 식육 이미지 및 유사 식육 이미지의 지방 및 단백질의 분포 이미지와, 사용자 단말 에서 업로드된 이미지 및 업로드된 이미지 내 지방 및 단백질의 분포 이미지가 기 설정된 유사도를 초과한 경우, 업로드된 이미지에 대응하는 식육의 가격차이 퍼센테이지를 출력하도록 할 수 있다. 이하, 상술한 도 2의 판별 서비스 제공 서버의 구성에 따른 동작 과정을 도 3 및 도 4를 예로 들어 상세히 설명 하기로 한다. 다만, 실시예는 본 발명의 다양한 실시예 중 어느 하나일 뿐, 이에 한정되지 않음은 자명하다 할 것이다. 도 3a를 참조하면, (a) 적어도 하나의 식육 이미지를 수집하여 빅데이터를 구축하고, (b) 라벨링 및 어노테이션 을 수행하여 인공지능 알고리즘을 학습시킬 데이터셋을 마련한다. 그리고, (c)와 같이 교차검증으로 데이터셋 을 검증한 후, (d)와 같이 인공지능 알고리즘에 식육 이미지를 넣고, 그 결과 부위명칭을 출력하도록 하고, 식 육 이미지에 기 매핑된 지방 및 단백질 분포 이미지와의 유사도를 매칭률로 출력하도록 함으로써 \"좋은 고기\"인 지의 여부를 퍼센테이지로 출력하도록 학습 및 검증한다. 또 도 3b의 (a)를 참조하면 사용자 단말에서 촬 영을 하여 한 장씩 업로드하거나 또는 전면 카메라를 켜놓고 있으면, 전처리 후 ROI를 설정한 후, 객체를 탐지하고, 2 단계 세그멘테이션을 거쳐 인공지능 알고리즘에 질의로 입력하고, 인공지능 알고리즘에서 기 학습 및 검증한 데이터셋과의 유사도를 측정하여 매칭률로 출력하도록 하고, 그 부위의 부위명칭을 출력하여 사용자 단 말로 전송하도록 한다. (b)와 같이 사용자 단말은 안내 메시지를 수신하여 화면 상에 출력할 수 있 고, (c)와 같이 AR로 실시간으로 화면 상에 식육(객체) 상에 매칭률을 출력함으로써 소비자인 사용자의 빠른 구 매결정을 유도할 수도 있다. 도 4는 상술한 바와 같으므로 설명을 생략한다. 이와 같은 도 2 내지 도 4의 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 방법에 대해서 설명 되지 아니한 사항은 앞서 도 1을 통해 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 방법에 대 하여 설명된 내용과 동일하거나 설명된 내용으로부터 용이하게 유추 가능하므로 이하 설명을 생략하도록 한다. 도 5는 본 발명의 일 실시예에 따른 도 1의 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스 템에 포함된 각 구성들 상호 간에 데이터가 송수신되는 과정을 나타낸 도면이다. 이하, 도 5를 통해 각 구성들 상호간에 데이터가 송수신되는 과정의 일 예를 설명할 것이나, 이와 같은 실시예로 본원이 한정 해석되는 것은 아니며, 앞서 설명한 다양한 실시예들에 따라 도 5에 도시된 데이터가 송수신되는 과정이 변경될 수 있음은 기 술분야에 속하는 당업자에게 자명하다. 도 5를 참조하면, 판별 서비스 제공 서버는, 적어도 하나의 식육 이미지, 지방 및 단백질의 분포 이미지 및 적 어도 하나의 부위명칭을 매핑하여 데이터셋(DataSet)을 구축한다(S5100). 그리고, 판별 서비스 제공 서버는, 데이터셋을 이용하여 적어도 하나의 인공지능 알고리즘을 학습 및 검증하여 모델링하고(S5200), 적어도 하나의 인공지능 알고리즘 중 정확도가 가장 높은 인공지능 알고리즘을 판별 서비스 를 위한 인공지능 알고리즘으로 세팅한 후(S5300), 사용자 단말에서 입력된 이미지를 세팅된 인공지능 알고리즘 에 질의(Query)로 입력하여(S5400), 질의로 입력된 이미지와 데이터셋 내 이미지 간 유사도를 매칭률로 출력하 여 사용자 단말로 전송한다(S5500). 상술한 단계들(S5100~S5500)간의 순서는 예시일 뿐, 이에 한정되지 않는다. 즉, 상술한 단계들(S5100~S5500)간 의 순서는 상호 변동될 수 있으며, 이중 일부 단계들은 동시에 실행되거나 삭제될 수도 있다. 이와 같은 도 5의 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 방법에 대해서 설명되지 아니 한 사항은 앞서 도 1 내지 도 4를 통해 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 방법에 대하여 설명된 내용과 동일하거나 설명된 내용으로부터 용이하게 유추 가능하므로 이하 설명을 생략하도록 한다. 도 5를 통해 설명된 일 실시예에 따른 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 방법은, 컴퓨터에 의해 실행되는 애플리케이션이나 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발 성, 분리형 및 비분리형 매체를 모두 포함한다. 전술한 본 발명의 일 실시예에 따른 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 방법은, 단 말기에 기본적으로 설치된 애플리케이션(이는 단말기에 기본적으로 탑재된 플랫폼이나 운영체제 등에 포함된 프 로그램을 포함할 수 있음)에 의해 실행될 수 있고, 사용자가 애플리케이션 스토어 서버, 애플리케이션 또는 해 당 서비스와 관련된 웹 서버 등의 애플리케이션 제공 서버를 통해 마스터 단말기에 직접 설치한 애플리케이션 (즉, 프로그램)에 의해 실행될 수도 있다. 이러한 의미에서, 전술한 본 발명의 일 실시예에 따른 영상 기반 인 공지능 알고리즘을 이용한 식육 판별 서비스 제공 방법은 단말기에 기본적으로 설치되거나 사용자에 의해 직접 설치된 애플리케이션(즉, 프로그램)으로 구현되고 단말기에 등의 컴퓨터로 읽을 수 있는 기록매체에 기록될 수 있다."}
{"patent_id": "10-2022-0050727", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2022-0050727", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 시스템을 설 명하기 위한 도면이다. 도 2는 도 1의 시스템에 포함된 판별 서비스 제공 서버를 설명하기 위한 블록 구성도이다. 도 3 및 도 4는 본 발명의 일 실시예에 따른 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스가 구현된 일 실시예를 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시예에 따른 영상 기반 인공지능 알고리즘을 이용한 식육 판별 서비스 제공 방법을 설명 하기 위한 동작 흐름도이다."}
