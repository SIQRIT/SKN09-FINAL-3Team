{"patent_id": "10-2023-0182559", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0057964", "출원번호": "10-2023-0182559", "발명의 명칭": "전자 장치 및 전자 장치의 동작 방법", "출원인": "삼성전자주식회사", "발명자": "김성태"}}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치(101)에 있어서,메모리(130); 및프로세서(120)를 포함하며, 상기 프로세서(120)는:제1 피사체(subject)와 배경(background)을 포함하는 입력 2차원(2D) 이미지를 식별하고,상기 입력 2D 이미지를 상기 제1 피사체를 포함하는 제1 피사체 이미지와 상기 배경을 포함하는 제1 배경 이미지로 분리(separate)하고,상기 제1 피사체에 대한 3차원(3D) 모델을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하고,상기 제1 배경 이미지 내의 피사체 제외 영역 또는 상기 제1 배경 이미지 외부의 확장 영역 중 적어도 하나에대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성하고, 상기 확장 영역은 상기 제1 피사체의 변경과 연관되며,상기 제2 피사체 이미지와 상기 제2 배경 이미지를 합성하여, 출력 2D 이미지를 생성하도록 설정되는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 프로세서(120)는: 상기 제1 피사체 이미지에 기초하여, 상기 제1 피사체에 대한 이미 생성된 3D 모델을 변형(deform)시키고,상기 변형된 3D 모델을 상기 제1 피사체에 대한 상기 3D 모델로 이용하여 상기 제1 피사체의 크기, 위치 또는방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 상기 변경된 제1 피사체를 포함하는 상기제2 피사체 이미지를 생성하도록 설정되는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 제1 배경 이미지 내의 상기 피사체 제외 영역에 대한 이미지 처리는, 상기 제1 배경 이미지에 포함된 정보를 기초로 상기 피사체 제외 영역에 배경을 추가하기 위한 인-페인팅(in-painting)처리를 포함하는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 상기 프로세서(120)는:상기 제1 피사체를 이동(translation)시키기 위한 사용자 입력을 획득하고,상기 사용자 입력이 획득되는 것에 응답하여, 상기 3D 모델을 이용하여 상기 위치 및 상기 방향을 변경하기 위한 이미지 처리를 수행함으로써, 상기 위치 및 상기 방향이 변경된 제1 피사체를 포함하는 상기 제2 피사체 이미지를 생성하도록 설정되는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서, 상기 제1 배경 이미지 외부의 상기 확장 영역에 대한 이미지처리는, 상기 제1 배경 이미지에 포함된 정보를 기초로 상기 변경된 제1 피사체의 위치와 연관된 확장 영역에배경을 추가하기 위한 아웃-페인팅(out-painting) 처리를 포함하는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2025-0057964-3-제1항 내지 제5항 중 어느 한 항에 있어서, 상기 프로세서(120)는:상기 전자 장치(101)의 내부 저장 장치 또는 상기 전자 장치(101)에 연결된 외부 저장 장치 중 적어도 하나로부터 2D 이미지들을 획득하고,상기 2D 이미지들에 기초하여, 3D 모델이 생성될 적어도 하나의 피사체를 식별하고, 상기 적어도 하나의 피사체는 상기 제1 피사체를 포함하고,상기 2D 이미지들을 상기 식별된 피사체 별로 클러스터링하고,상기 제1 피사체의 클러스터에 속하는 2D 이미지들에서 상기 제1 피사체와 상기 배경을 분리함으로써, 상기 배경이 제외된 상기 제1 피사체를 포함하는 2D 이미지들을 획득하고,상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 상기 제1 피사체에 대한 상기 3D 모델을생성하도록 설정되는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들은, 제1 시점부터 상기 제1 시점 이후의 제2 시점까지의2D 이미지들에 해당하고,상기 프로세서는: 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들에 포함된 시간 정보를 이용하여, 상기 제1 시점에서 상기 제2 시점까지의 기간을 식별하고, 상기 제1 시점에서 상기 제2 시점까지의 기간을 복수의 시간 구간으로 나누고,각 시간 구간에 속하는 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 시간 구간 별로 상기 제1 피사체에 대한 3D 모델을 각각 생성하도록 설정되는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서, 상기 프로세서는:상기 시간 구간 별로 생성된 상기 제1 피사체에 대한 복수의 3D 모델 간의 3D 특징점을 매칭함으로써, 상기 제1피사체의 시간에 따라 변화하는 모습을 3차원으로 제공하도록 설정되는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서, 상기 프로세서는:상기 제1 피사체에 대한 상기 3D 모델의 완성도가 임계 값을 만족하는지 여부를 식별하고,상기 3D 모델의 완성도가 임계 값 미만인 것으로 식별되는 경우, 상기 3D 모델의 완성도를 높이기 위하여 상기제1 피사체에 대한 추가 2D 이미지의 획득을 위한 촬영 가이드를 사용자에게 제공하도록 설정되는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 있어서, 상기 프로세서는:상기 제1 피사체에 대한 상기 3D 모델을 디스플레이 상에 표시하고, 상기 3D 모델의 상기 완성도와 연관된 사용자 입력을 수신하고,상기 사용자 입력에 기초하여 상기 3D 모델의 완성도가 미리 설정된 기준을 만족하는지 여부를 식별하도록 설정되는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항에 있어서, 상기 프로세서는:공개특허 10-2025-0057964-4-상기 제1 피사체에 대한 적어도 하나의 추가 2D 이미지가 획득되는 것에 기초하여, 상기 제1 피사체에 대한 상기 3D 모델을 업데이트 하도록 설정되는, 전자 장치(101)."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "전자 장치(101)의 방법에 있어서,제1 피사체(subject)와 배경(background)을 포함하는 입력 2차원(2D) 이미지를 식별하는 동작;상기 입력 2D 이미지를 상기 제1 피사체를 포함하는 제1 피사체 이미지와 상기 배경을 포함하는 제1 배경 이미지로 분리(separate)하는 동작;상기 제1 피사체에 대한 3차원(3D) 모델을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하는동작;상기 제1 배경 이미지 내의 피사체 제외 영역 또는 상기 제1 배경 이미지 외부의 확장 영역 중 적어도 하나에대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성하는 동작, 상기 확장 영역은 상기 제1 피사체의 변경과 연관되며; 및상기 제2 피사체 이미지와 상기 제2 배경 이미지를 합성하여, 출력 2D 이미지를 생성하도록 설정되는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 방법은:상기 제1 피사체 이미지에 기초하여, 상기 제1 피사체에 대한 이미 생성된 3D 모델을 변형(deform)시키는 동작을 더 포함하고,상기 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하는 동작은: 상기 변형된 3D 모델을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 상기 변경된 제1 피사체를 포함하는 상기 제2 피사체 이미지를 생성하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항 또는 제13항에 있어서, 상기 제1 배경 이미지 내의 상기 피사체 제외 영역에 대한 이미지 처리는, 상기제1 배경 이미지에 포함된 정보를 기초로 상기 피사체 제외 영역에 배경을 추가하기 위한 인-페인팅(in-painting) 처리를 포함하는, 방법."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항 내지 제14항 중 어느 한 항에 있어서, 상기 방법은:상기 제1 피사체를 이동(translation)시키기 위한 사용자 입력을 획득하는 동작; 및상기 사용자 입력이 획득되는 것에 응답하여, 상기 3D 모델을 이용하여 상기 위치 및 상기 방향을 변경하기 위한 이미지 처리를 수행함으로써, 상기 위치 및 상기 방향이 변경된 제1 피사체를 포함하는 제2 피사체 이미지를생성하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항 내지 제15항 중 어느 한 항에 있어서, 상기 제1 배경 이미지 외부의 상기 확장 영역에 대한 이미지 처리는, 상기 제1 배경 이미지에 포함된 정보를 기초로 상기 변경된 피사체의 위치와 연관된 확장 영역에 배경을 추가하기 위한 아웃-페인팅(out-painting) 처리를 포함하는, 방법."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항 내지 제16항 중 어느 한 항에 있어서, 상기 방법은:공개특허 10-2025-0057964-5-상기 전자 장치(101)의 내부 저장 장치 또는 상기 전자 장치(101)에 연결된 외부 저장 장치 중 적어도 하나로부터 2D 이미지들을 획득하는 동작;상기 2D 이미지들에 기초하여, 3D 모델이 생성될 적어도 하나의 피사체를 식별하는 동작, 상기 적어도 하나의피사체는 상기 제1 피사체를 포함하고;상기 2D 이미지들을 상기 식별된 피사체 별로 클러스터링하는 동작; 및상기 제1 피사체의 클러스터에 속하는 2D 이미지들에서 상기 제1 피사체와 상기 배경을 분리함으로써, 상기 배경이 제외된 상기 제1 피사체를 포함하는 2D 이미지들을 획득하는 동작; 및상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 상기 제1 피사체에 대한 상기 3D 모델을생성하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항 내지 제17항 중 어느 한 항에 있어서,상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들은, 제1 시점부터 상기 제1 시점 이후의 제2 시점까지의2D 이미지들에 해당하고,상기 방법은: 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들에 포함된 시간 정보를 이용하여, 상기 제1 시점에서 상기 제2 시점까지의 기간을 식별하는 동작;상기 제1 시점에서 상기 제2 시점까지의 기간을 복수의 시간 구간으로 나누는 동작; 및각 시간 구간에 속하는 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 시간 구간 별로 상기 제1 피사체에 대한 3D 모델을 각각 생성하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항 내지 제18항 중 어느 한 항에 있어서, 상기 방법은:상기 시간 구간 별로 생성된 상기 제1 피사체에 대한 복수의 3D 모델 간의 3D 특징점을 매칭함으로써, 상기 제1피사체의 시간에 따라 변화하는 모습을 3차원으로 제공하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0182559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항 내지 제19항 중 어느 한 항에 있어서, 상기 방법은:상기 제1 피사체에 대한 상기 3D 모델의 완성도가 임계 값을 만족하는지 여부를 식별하는 동작; 및상기 3D 모델의 완성도가 임계 값 미만인 것으로 식별되는 경우, 상기 3D 모델의 완성도를 높이기 위하여 상기제1 피사체에 대한 추가 2D 이미지의 획득을 위한 촬영 가이드를 사용자에게 제공하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0182559", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 3D 모델을 이용하여 2D 이미지를 편집하는 전자 장치를 개시한다. 전자 장치는 제1 피사체와 배경을 포함하는 입력 2D 이미지를 식별하고, 입력 2D 이미지를 제1 피사체를 포함하는 제1 피사체 이미지와 배경을 포 함하는 제1 배경 이미지로 분리하고, 제1 피사체에 대한 3D 모델을 이용하여 제1 피사체의 크기, 위치 또는 방 향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써 변경된 제1 피사체를 포함하는 제2 피사체 이미 지를 생성하고, 제1 배경 이미지 내의 피사체 제외 영역 또는 제1 배경 이미지 외부의 확장 영역 중 적어도 하나 에 대한 이미지 처리를 수행함으로써 변경된 배경을 포함하는 제2 배경 이미지를 생성하고, 제2 피사체 이미지와 제2 배경 이미지를 합성하여 출력 2D 이미지를 생성하도록 설정될 수 있다."}
{"patent_id": "10-2023-0182559", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 전자 장치의 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0182559", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이미지 기반 3차원(3D) 모델링은 피사체를 3차원으로 모델링하기 위한 컴퓨터 비전의 연구 주제 중 하나이다. 이미지 기반 3D 모델링은 예컨대, 다양한 관점에서 촬영된 이미지들에 기초하여 피사체의 표면 정보를 획득하여 피사체에 대한 3D 모델을 획득하는 기술일 수 있다. 최근 3차원 신경망 표현을 학습하고, 이를 기초로 임의의 위치에서 촬영된 것과 같은 영상을 효과적으로 합성할 수 있는, NeRF (Neural Radiance Fields)와 같은 기술의 등장으로 3D 모델링에 큰 발전이 진행되고 있다. 이미지 기반 3D 모델링은 일반적으로 동일한 피사체를 다양한 관점에서 다수 촬영한 이미지를 필요로 한다. 그 러나, 이러한 사진 촬영 과정은 일반적인 사용자에게 정확한 가이드를 제공하기 어렵다. 또한, 사용 가능한 수준의 정밀한 3D 모델을 획득하기 위해, 이미지를 촬영하는 촬영 장소를 제약하거나, 피사체의 움직임을 최소화 한 상태로 동시 다발적인 촬영을 진행하여야 한다. 그러나, 실사용 환경에서 이러한 환경을 제공하기 어렵다. 따라서, 3D 모델의 생성을 목적으로 한 제한적이며 전문화된 촬영 과정을 요구함 없이, 사용자가 이미 가지고 있는 이미지들을 활용하여 3D 모델을 생성하는 방안이 고려될 필요가 있다. 상술한 정보는 본 개시에 대한 이해를 돕기 위한 목적으로 하는 배경 기술(related art)로 제공될 수 있다. 상술한 내용 중 어느 것도 본 개시와 관련된 종래 기술(prior art)로서 적용될 수 있는지에 대하여 어떠한 주장 이나 결정이 제기되지 않는다."}
{"patent_id": "10-2023-0182559", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른, 전자 장치는 메모리 및 프로세서를 포함할 수 있다. 전자 장치(또는, 프로세서)는 제1 피사체(subject)와 배경(background)을 포함하는 입력 2차원(2D) 이미지를 식별할 수 있다. 전자 장치(또는, 프로세서)는 상기 입력 2D 이미지를 상기 제1 피사체를 포함하는 제1 피사체 이미지와 상기 배경을 포함하는 제1 배경 이미지로 분리(separate)할 수 있다. 전자 장치(또는, 프로세서)는 상기 제1 피사체에 대한 3차원(3D) 모델을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성할 수 있다. 전자 장치(또는, 프 로세서)는 상기 제1 배경 이미지 내의 피사체 제외 영역 또는 상기 제1 배경 이미지 외부의 확장 영역 중 적어 도 하나에 대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성할 수 있다. 상기 확장 영역은 상기 제1 피사체의 변경과 연관될 수 있다. 전자 장치(또는, 프로세서)는 상기 제2 피사체 이미지 와 상기 제2 배경 이미지를 합성하여, 출력 2D 이미지를 생성하도록 설정될 수 있다. 본 개시의 일 실시예에 따른, 전자 장치의 방법은 제1 피사체(subject)와 배경(background)을 포함하는 입력 2 차원(2D) 이미지를 식별하는 동작을 포함할 수 있다. 전자 장치의 방법은 상기 입력 2D 이미지를 상기 제1 피사 체를 포함하는 제1 피사체 이미지와 상기 배경을 포함하는 제1 배경 이미지로 분리(separate)하는 동작을 포함 할 수 있다. 전자 장치의 방법은 상기 제1 피사체에 대한 3차원(3D) 모델을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하는 동작을 포함할 수 있다. 전자 장치의 방법은 상기 제1 배경 이미지 내의 피사체 제외 영역 또는 상기 제1 배경 이미지 외부의 확장 영역 중 적어도 하나에 대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성하는 동작을 포함할 수 있다. 상기 확장 영역은 상기 제1 피사 체의 변경과 연관될 수 있다. 전자 장치의 방법은 상기 제2 피사체 이미지와 상기 제2 배경 이미지를 합성하여, 출력 2D 이미지를 생성하도록 설정되는 동작을 포함할 수 있다. 본 개시의 일 실시예에 따른, 컴퓨터로 판독 가능한 적어도 하나의 인스트럭션을 저장하는 저장 매체에 있어서, 상기 적어도 하나의 인스트럭션은 전자 장치의 적어도 하나의 프로세서에 의하여 실행 시에, 상기 전자 장치로 하여금 적어도 하나의 동작을 수행하도록 야기할 수 있다. 적어도 하나의 동작은 제1 피사체(subject)와 배경 (background)을 포함하는 입력 2차원(2D) 이미지를 식별하는 동작을 포함할 수 있다. 적어도 하나의 동작은 상 기 입력 2D 이미지를 상기 제1 피사체를 포함하는 제1 피사체 이미지와 상기 배경을 포함하는 제1 배경 이미지 로 분리(separate)하는 동작을 포함할 수 있다. 적어도 하나의 동작은 상기 제1 피사체에 대한 3차원(3D) 모델 을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으 로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하는 동작을 포함할 수 있다. 적어도 하나의 동 작은 상기 제1 배경 이미지 내의 피사체 제외 영역 또는 상기 제1 배경 이미지 외부의 확장 영역 중 적어도 하 나에 대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성하는 동작을 포함할 수 있다. 상기 확장 영역은 상기 제1 피사체의 변경과 연관될 수 있다. 적어도 하나의 동작은 상기 제2 피사체 이 미지와 상기 제2 배경 이미지를 합성하여, 출력 2D 이미지를 생성하도록 설정되는 동작을 포함할 수 있다."}
{"patent_id": "10-2023-0182559", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으 며 여기에서 설명하는 실시예에 한정되지 않는다. 도면의 설명과 관련하여, 동일하거나 유사한 구성요소에 대해 서는 동일하거나 유사한 참조 부호가 사용될 수 있다. 또한, 도면 및 관련된 설명에서는, 잘 알려진 기능 및 구성에 대한 설명이 명확성과 간결성을 위해 생략될 수 있다. 이때, 처리 흐름도 도면들의 각 블록과 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수행될 수 있음을 이해할 수 있을 것이다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실행 예들에서는 블록들에서 언급된 기 능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 이때, 본 실시예에서 사용되는 '~부'라는 용어는 소프트웨어 또는 FPGA(Field Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)과 같은 하드웨어 구성요소를 의미하며, '~부'는 어떤 역할들 을 수행한다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 패킷 처리 장치들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성 요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구성요소 들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 중앙처리장치(Central Processing Unit, CPU)들을 재생시키도록 구현될 수도 있다. 또한 실시예에서 '~부'는 하나 이상의 패킷 처리 장치를 포함할 수 있다. 도 1은 본 개시의 다양한 실시예들에 따른, 네트워크 환경 내의 전자 장치의 블록도이다. 도 1을 참조하면, 네트워크 환경에서 전자 장치는 제 1 네트워크(예: 근거리 무선 통신 네트워 크)를 통하여 전자 장치와 통신하거나, 또는 제 2 네트워크(예: 원거리 무선 통신 네트워크)를 통하 여 전자 장치 또는 서버와 통신할 수 있다. 일실시예에 따르면, 전자 장치는 서버를 통하 여 전자 장치와 통신할 수 있다. 일실시예에 따르면, 전자 장치는 프로세서, 메모리, 입력 모듈, 음향 출력 모듈, 디스플레이 모듈, 오디오 모듈, 센서 모듈, 인터페이스 , 연결 단자, 햅틱 모듈, 카메라 모듈, 전력 관리 모듈, 배터리, 통신 모듈 , 가입자 식별 모듈, 또는 안테나 모듈을 포함할 수 있다. 어떤 실시예에서는, 전자 장치(10 1)에는, 이 구성요소들 중 적어도 하나(예: 연결 단자)가 생략되거나, 하나 이상의 다른 구성요소가 추가 될 수 있다. 어떤 실시예에서는, 이 구성요소들 중 일부들(예: 센서 모듈, 카메라 모듈, 또는 안테나 모듈)은 하나의 구성요소(예: 디스플레이 모듈)로 통합될 수 있다. 프로세서는, 예를 들면, 소프트웨어(예: 프로그램)를 실행하여 프로세서에 연결된 전자 장치 의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이 터 처리 또는 연산을 수행할 수 있다. 일실시예에 따르면, 데이터 처리 또는 연산의 적어도 일부로서, 프로세 서는 다른 구성요소(예: 센서 모듈 또는 통신 모듈)로부터 수신된 명령 또는 데이터를 휘발성 메모리에 저장하고, 휘발성 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 비휘발성 메모리에 저장할 수 있다. 일실시예에 따르면, 프로세서는 메인 프로세서(예: 중앙 처리 장치 또는 어플리케이션 프로세서) 또는 이와는 독립적으로 또는 함께 운영 가능한 보조 프로세서(예: 그래픽 처리 장치, 신경망 처리 장치(NPU: neural processing unit), 이미지 시그널 프로세서, 센서 허브 프로세서, 또 는 커뮤니케이션 프로세서)를 포함할 수 있다. 예를 들어, 전자 장치가 메인 프로세서 및 보조 프로 세서를 포함하는 경우, 보조 프로세서는 메인 프로세서보다 저전력을 사용하거나, 지정된 기능 에 특화되도록 설정될 수 있다. 보조 프로세서는 메인 프로세서와 별개로, 또는 그 일부로서 구현될 수 있다. 보조 프로세서는, 예를 들면, 메인 프로세서가 인액티브(예: 슬립) 상태에 있는 동안 메인 프로세서 를 대신하여, 또는 메인 프로세서가 액티브(예: 어플리케이션 실행) 상태에 있는 동안 메인 프로세서 와 함께, 전자 장치의 구성요소들 중 적어도 하나의 구성요소(예: 디스플레이 모듈, 센서 모듈 , 또는 통신 모듈)와 관련된 기능 또는 상태들의 적어도 일부를 제어할 수 있다. 일실시예에 따르면, 보조 프로세서(예: 이미지 시그널 프로세서 또는 커뮤니케이션 프로세서)는 기능적으로 관련 있는 다른 구 성요소(예: 카메라 모듈 또는 통신 모듈)의 일부로서 구현될 수 있다. 일실시예에 따르면, 보조 프로 세서(예: 신경망 처리 장치)는 인공지능 모델의 처리에 특화된 하드웨어 구조를 포함할 수 있다. 인공지능 모델은 기계 학습을 통해 생성될 수 있다. 이러한 학습은, 예를 들어, 인공지능이 수행되는 전자 장치 자 체에서 수행될 수 있고, 별도의 서버(예: 서버)를 통해 수행될 수도 있다. 학습 알고리즘은, 예를 들어, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 인공 지능 모델은, 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경망(DNN: deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워 크(deep Q-networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 인공지 능 모델은 하드웨어 구조 이외에, 추가적으로 또는 대체적으로, 소프트웨어 구조를 포함할 수 있다. 메모리는, 전자 장치의 적어도 하나의 구성요소(예: 프로세서 또는 센서 모듈)에 의해 사 용되는 다양한 데이터를 저장할 수 있다. 데이터는, 예를 들어, 소프트웨어(예: 프로그램) 및, 이와 관련 된 명령에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있다. 메모리는, 휘발성 메모리 또는 비 휘발성 메모리를 포함할 수 있다. 프로그램은 메모리에 소프트웨어로서 저장될 수 있으며, 예를 들면, 운영 체제, 미들 웨어 또는 어플리케이션을 포함할 수 있다. 입력 모듈은, 전자 장치의 구성요소(예: 프로세서)에 사용될 명령 또는 데이터를 전자 장치 의 외부(예: 사용자)로부터 수신할 수 있다. 입력 모듈은, 예를 들면, 마이크, 마우스, 키보드, 키 (예: 버튼), 또는 디지털 펜(예: 스타일러스 펜)을 포함할 수 있다. 음향 출력 모듈은 음향 신호를 전자 장치의 외부로 출력할 수 있다. 음향 출력 모듈은, 예를 들 면, 스피커 또는 리시버를 포함할 수 있다. 스피커는 멀티미디어 재생 또는 녹음 재생과 같이 일반적인 용도로사용될 수 있다. 리시버는 착신 전화를 수신하기 위해 사용될 수 있다. 일실시예에 따르면, 리시버는 스피커와 별개로, 또는 그 일부로서 구현될 수 있다. 디스플레이 모듈은 전자 장치의 외부(예: 사용자)로 정보를 시각적으로 제공할 수 있다. 디스플레이 모듈은, 예를 들면, 디스플레이, 홀로그램 장치, 또는 프로젝터 및 해당 장치를 제어하기 위한 제어 회로 를 포함할 수 있다. 일실시예에 따르면, 디스플레이 모듈은 터치를 감지하도록 설정된 터치 센서, 또는 상 기 터치에 의해 발생되는 힘의 세기를 측정하도록 설정된 압력 센서를 포함할 수 있다. 오디오 모듈은 소리를 전기 신호로 변환시키거나, 반대로 전기 신호를 소리로 변환시킬 수 있다. 일실시예 에 따르면, 오디오 모듈은, 입력 모듈을 통해 소리를 획득하거나, 음향 출력 모듈, 또는 전자 장치와 직접 또는 무선으로 연결된 외부 전자 장치(예: 전자 장치)(예: 스피커 또는 헤드폰)를 통해 소리를 출력할 수 있다. 센서 모듈은 전자 장치의 작동 상태(예: 전력 또는 온도), 또는 외부의 환경 상태(예: 사용자 상태) 를 감지하고, 감지된 상태에 대응하는 전기 신호 또는 데이터 값을 생성할 수 있다. 일실시예에 따르면, 센서 모듈은, 예를 들면, 제스처 센서, 자이로 센서, 기압 센서, 마그네틱 센서, 가속도 센서, 그립 센서, 근접 센서, 컬러 센서, IR(infrared) 센서, 생체 센서, 온도 센서, 습도 센서, 또는 조도 센서를 포함할 수 있다. 인터페이스는 전자 장치가 외부 전자 장치(예: 전자 장치)와 직접 또는 무선으로 연결되기 위해 사용될 수 있는 하나 이상의 지정된 프로토콜들을 지원할 수 있다. 일실시예에 따르면, 인터페이스는, 예 를 들면, HDMI(high definition multimedia interface), USB(universal serial bus) 인터페이스, SD카드 인터 페이스, 또는 오디오 인터페이스를 포함할 수 있다. 연결 단자는, 그를 통해서 전자 장치가 외부 전자 장치(예: 전자 장치)와 물리적으로 연결될 수 있는 커넥터를 포함할 수 있다. 일실시예에 따르면, 연결 단자는, 예를 들면, HDMI 커넥터, USB 커넥터, SD 카드 커넥터, 또는 오디오 커넥터(예: 헤드폰 커넥터)를 포함할 수 있다. 햅틱 모듈은 전기적 신호를 사용자가 촉각 또는 운동 감각을 통해서 인지할 수 있는 기계적인 자극(예: 진 동 또는 움직임) 또는 전기적인 자극으로 변환할 수 있다. 일실시예에 따르면, 햅틱 모듈은, 예를 들면, 모터, 압전 소자, 또는 전기 자극 장치를 포함할 수 있다. 카메라 모듈은 정지 영상 및 동영상을 촬영할 수 있다. 일실시예에 따르면, 카메라 모듈은 하나 이상 의 렌즈들, 이미지 센서들, 이미지 시그널 프로세서들, 또는 플래시들을 포함할 수 있다. 전력 관리 모듈은 전자 장치에 공급되는 전력을 관리할 수 있다. 일실시예에 따르면, 전력 관리 모듈 은, 예를 들면, PMIC(power management integrated circuit)의 적어도 일부로서 구현될 수 있다. 배터리는 전자 장치의 적어도 하나의 구성요소에 전력을 공급할 수 있다. 일실시예에 따르면, 배터리 는, 예를 들면, 재충전 불가능한 1차 전지, 재충전 가능한 2차 전지 또는 연료 전지를 포함할 수 있다. 통신 모듈은 전자 장치와 외부 전자 장치(예: 전자 장치, 전자 장치, 또는 서버) 간 의 직접(예: 유선) 통신 채널 또는 무선 통신 채널의 수립, 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 통신 모듈은 프로세서(예: 어플리케이션 프로세서)와 독립적으로 운영되고, 직접(예: 유선) 통신 또는 무선 통신을 지원하는 하나 이상의 커뮤니케이션 프로세서를 포함할 수 있다. 일실시예에 따르면, 통 신 모듈은 통신 모듈(예: 셀룰러 통신 모듈, 근거리 통신 모듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예: LAN(local area network) 통신 모듈, 또는 전력 선 통신 모듈)을 포함할 수 있다. 이들 통신 모듈 중 해당하는 통신 모듈은 제 1 네트워크(예: 블루투스, WiFi(wireless fidelity) direct 또는 IrDA(infrared data association)와 같은 근거리 통신 네트워크) 또는 제 2 네트워크(예: 레거시 셀룰러 네트워크, 5G 네트워크, 차세대 통신 네트워크, 인터넷, 또는 컴퓨터 네 트워크(예: LAN 또는 WAN)와 같은 원거리 통신 네트워크)를 통하여 외부의 전자 장치와 통신할 수 있다. 이런 여러 종류의 통신 모듈들은 하나의 구성요소(예: 단일 칩)로 통합되거나, 또는 서로 별도의 복수의 구성요 소들(예: 복수 칩들)로 구현될 수 있다. 통신 모듈은 가입자 식별 모듈에 저장된 가입자 정보(예: 국 제 모바일 가입자 식별자(IMSI))를 이용하여 제 1 네트워크 또는 제 2 네트워크와 같은 통신 네트워 크 내에서 전자 장치를 확인 또는 인증할 수 있다. 통신 모듈은 4G 네트워크 이후의 5G 네트워크 및 차세대 통신 기술, 예를 들어, NR 접속 기술(new radio access technology)을 지원할 수 있다. NR 접속 기술은 고용량 데이터의 고속 전송(eMBB(enhanced mobilebroadband)), 단말 전력 최소화와 다수 단말의 접속(mMTC(massive machine type communications)), 또는 고신 뢰도와 저지연(URLLC(ultra-reliable and low-latency communications))을 지원할 수 있다. 통신 모듈은, 예를 들어, 높은 데이터 전송률 달성을 위해, 고주파 대역(예: mmWave 대역)을 지원할 수 있다. 통신 모듈(19 2)은 고주파 대역에서의 성능 확보를 위한 다양한 기술들, 예를 들어, 빔포밍(beamforming), 거대 배열 다중 입 출력(massive MIMO(multiple-input and multiple-output)), 전차원 다중입출력(FD-MIMO: full dimensional MIMO), 어레이 안테나(array antenna), 아날로그 빔형성(analog beam-forming), 또는 대규모 안테나(large scale antenna)와 같은 기술들을 지원할 수 있다. 통신 모듈은 전자 장치, 외부 전자 장치(예: 전자 장치) 또는 네트워크 시스템(예: 제 2 네트워크)에 규정되는 다양한 요구사항을 지원할 수 있다. 일 실시예에 따르면, 통신 모듈은 eMBB 실현을 위한 Peak data rate(예: 20Gbps 이상), mMTC 실현을 위한 손 실 Coverage(예: 164dB 이하), 또는 URLLC 실현을 위한 U-plane latency(예: 다운링크(DL) 및 업링크(UL) 각각 0.5ms 이하, 또는 라운드 트립 1ms 이하)를 지원할 수 있다. 안테나 모듈은 신호 또는 전력을 외부(예: 외부의 전자 장치)로 송신하거나 외부로부터 수신할 수 있다. 일실시예에 따르면, 안테나 모듈은 서브스트레이트(예: PCB) 위에 형성된 도전체 또는 도전성 패턴으로 이 루어진 방사체를 포함하는 안테나를 포함할 수 있다. 일실시예에 따르면, 안테나 모듈은 복수의 안테나들 (예: 어레이 안테나)을 포함할 수 있다. 이런 경우, 제 1 네트워크 또는 제 2 네트워크와 같은 통신 네트워크에서 사용되는 통신 방식에 적합한 적어도 하나의 안테나가, 예를 들면, 통신 모듈에 의하여 상기 복수의 안테나들로부터 선택될 수 있다. 신호 또는 전력은 상기 선택된 적어도 하나의 안테나를 통하여 통신 모 듈과 외부의 전자 장치 간에 송신되거나 수신될 수 있다. 어떤 실시예에 따르면, 방사체 이외에 다른 부품 (예: RFIC(radio frequency integrated circuit))이 추가로 안테나 모듈의 일부로 형성될 수 있다. 다양한 실시예에 따르면, 안테나 모듈은 mmWave 안테나 모듈을 형성할 수 있다. 일실시예에 따르면, mmWave 안테나 모듈은 인쇄 회로 기판, 상기 인쇄 회로 기판의 제 1 면(예: 아래 면)에 또는 그에 인접하여 배 치되고 지정된 고주파 대역(예: mmWave 대역)을 지원할 수 있는 RFIC, 및 상기 인쇄 회로 기판의 제 2 면(예: 윗 면 또는 측 면)에 또는 그에 인접하여 배치되고 상기 지정된 고주파 대역의 신호를 송신 또는 수신할 수 있 는 복수의 안테나들(예: 어레이 안테나)을 포함할 수 있다. 상기 구성요소들 중 적어도 일부는 주변 기기들간 통신 방식(예: 버스, GPIO(general purpose input and output), SPI(serial peripheral interface), 또는 MIPI(mobile industry processor interface)을 통해 서로 연결되고 신호(예: 명령 또는 데이터)를 상호간에 교환할 수 있다. 일실시예에 따르면, 명령 또는 데이터는 제 2 네트워크에 연결된 서버를 통해서 전자 장치와 외부의 전자 장치간에 송신 또는 수신될 수 있다. 외부의 전자 장치(102, 또는 104) 각각은 전자 장치 와 동일한 또는 다른 종류의 장치일 수 있다. 일실시예에 따르면, 전자 장치에서 실행되는 동작들의 전부 또는 일부는 외부의 전자 장치들(102, 104, 또는 108) 중 하나 이상의 외부의 전자 장치들에서 실행될 수 있다. 예를 들면, 전자 장치가 어떤 기능이나 서비스를 자동으로, 또는 사용자 또는 다른 장치로부터의 요 청에 반응하여 수행해야 할 경우에, 전자 장치는 기능 또는 서비스를 자체적으로 실행시키는 대신에 또는 추가적으로, 하나 이상의 외부의 전자 장치들에게 그 기능 또는 그 서비스의 적어도 일부를 수행하라고 요청할 수 있다. 상기 요청을 수신한 하나 이상의 외부의 전자 장치들은 요청된 기능 또는 서비스의 적어도 일부, 또는 상기 요청과 관련된 추가 기능 또는 서비스를 실행하고, 그 실행의 결과를 전자 장치로 전달할 수 있다. 전자 장치는 상기 결과를, 그대로 또는 추가적으로 처리하여, 상기 요청에 대한 응답의 적어도 일부로서 제공할 수 있다. 이를 위하여, 예를 들면, 클라우드 컴퓨팅, 분산 컴퓨팅, 모바일 에지 컴퓨팅(MEC: mobile edge computing), 또는 클라이언트-서버 컴퓨팅 기술이 이용될 수 있다. 전자 장치는, 예를 들어, 분산 컴 퓨팅 또는 모바일 에지 컴퓨팅을 이용하여 초저지연 서비스를 제공할 수 있다. 다른 실시예에 있어서, 외부의 전자 장치는 IoT(internet of things) 기기를 포함할 수 있다. 서버는 기계 학습 및/또는 신경망을 이용한 지능형 서버일 수 있다. 일실시예에 따르면, 외부의 전자 장치 또는 서버는 제 2 네트워크 내에 포함될 수 있다. 전자 장치는 5G 통신 기술 및 IoT 관련 기술을 기반으로 지능형 서비스(예: 스마트 홈, 스마트 시티, 스마트 카, 또는 헬스 케어)에 적용될 수 있다. 도 2는 본 개시의 일 실시예에 따른 3차원 모델링 절차를 개략적으로 도시한다. 도 2를 참조하면, 3차원(3D) 모델링 절차는 적어도 하나의 피사체(subject)(또는, 객체)에 대한 3D 모델을 생성 하기 위한 이미지들(예: 2차원(2D) 이미지들)을 처리하는 동작(이하, 제1 동작), 처리된 이미지들을 이용하여 적어도 하나의 피사체(또는, 객체)에 대한 3D 모델을 생성하는 동작(이하, 제2 동작) 및/또는 생성된 3D 모델을이용하는 동작(이하, 제3 동작)을 포함할 수 있다. 본 개시의 다양한 실시예에서는 설명의 편의를 위해, 3D 모 델을 생성하기 위해 사용되는 이미지가 2D 이미지(예: 사진)인 것을 예로 들어 설명하지만, 이에 제한되지 않는 다. 예컨대, 3D 이미지 및/또는 그림이 3D 모델을 생성하기 위해 사용될 수도 있다. 일 실시예에 따르면, 3D 모델을 생성하기 위해 사용되는 이미지들은, 예컨대, 전자 장치(예: 도 1의 전자 장치 ) 내의 저장 장치(예: 사진 저장소)에 저장된 이미지들 및/또는 전자 장치에 연결된 저장 장치(예: 클라우 드)에 저장된 이미지들을 포함할 수 있다. 일 실시예에 따르면, 전자 장치의 내부 및/또는 외부에 저장된 이미 지들은 과거 시점부터 현재까지 촬영되어 저장된 이미지들일 수 있다. 즉, 오랜 기간 동안 축적된 이미지들일 수 있다. 한편, 이러한 이미지들은 3D 모델링을 목적으로 획득된 이미지가 아니기 때문에, 3D 모델링을 위해 사 용되기 위해, 제1 동작과 같은 사전 처리가 필요하다. 일 실시예에 따르면, 제1 동작은 클러스터링(clustering) 동작 및/또는 분할(segmentation) 동작을 포함할 수 있다. 본 개시의 다양한 실시예에서, 클러스터링 동작은 분류 동작으로 지칭될 수도 있고, 분할 동작은 분리 (separation) 동작으로 지칭될 수도 있다. 일 실시예에 따르면, 제1 동작의 클러스터링 동작에서, 전자 장치(예: 도 1의 전자 장치)는 이미지들(예컨 대, 2D 이미지들(예: 사진))을 분석하여 적어도 하나의 피사체를 식별하고, 해당 이미지들을 피사체 별로 클러 스터링 할 수 있다. 예를 들면, 도 2에 도시된 것처럼, 사용자 1의 이미지들, 사용자 2의 이미지들 및 애완 동 물(pet) 1의 이미지들이 획득된 경우, 전자 장치는 사용자 1의 이미지들, 사용자 2의 이미지들 및 애완 동물 1 의 이미지들을 각각 별개의 클러스터로 클러스터링 할 수 있다. 일 실시예에 따르면, 전자 장치는 미리 학습된 제1 인공지능(AI) 모델(이하, 클러스터링 모델)을 이용하여, 획 득된 이미지들을 피사체 별로 클러스터링 할 수 있다. 본 개시에서, 클러스터링 모델은 분류 모델로 지칭될 수 도 있다. 일 실시예에 따르면, 전자 장치는 클러스터링 동작을 통해 클러스터링 된(또는, 분류된) 이미지들을 저장 장치 (예: 데이터베이스(DB))에 저장할 수 있다. 일 예로, 전자 장치는 클러스터링 된 이미지들을 클러스터(또는, 피 사체) 별로 저장할 수 있다. 상술한 클러스터링 동작을 통해 획득된 이미지들 중 적어도 일부는 피사체와 배경을 함께 포함할 수 있다. 예를 들면, 사용자 1에 대한 클러스터링 된 이미지들 중 적어도 일부는, 사용자 1 이외의 부분인 배경(예: 애완 동물 1, 주변 환경 등)을 함께 포함할 수 있다. 이처럼, 피사체와 배경이 함께 포함된 이미지는 해당 피사체에 대한 3D 모델을 생성하기에 적합하지 않을 수 있다. 따라서, 후술할 분할 동작을 통해, 배경이 제거될 필요가 있다. 일 실시예에 따르면, 제1 동작의 분할 동작에서, 전자 장치는 피사체 별로 클러스터링 된 이미지 내에서 해당 피사체와 배경을 분할(segment)(또는, 분리(separate))할 수 있다. 일 실시예에 따르면, 전자 장치는 미리 학습된 제2 인공지능(AI) 모델(이하, 분할(segmentation) 모델)을 이용 하여, 클러스터링 된 이미지 내에서 피사체와 배경을 분할할 수 있다. 이를 통해, 배경이 제외된 피사체만을 포 함하는 이미지들(이하, 피사체 이미지들) 및 피사체가 제외된 배경만을 포함하는 이미지들(이하, 배경 이미지들)이 각 클러스터 별로 생성될 수 있다. 본 개시의 다양한 실시예에서, 분할 모델은 분리 모델로 지칭될 수도 있다. 일 실시예에 따르면, 전자 장치는 분할 동작을 통해 획득된 이미지들을 저장 장치(예: 데이터베이스(DB))에 저 장할 수 있다. 일 예로, 전자 장치는 분할된 이미지들(예: 피사체 이미지들 및/또는 배경 이미지들)을 클러스터 (또는, 피사체) 별로 저장할 수 있다. 일 실시예에 따르면, 제1 동작은 추가적인 이미지 처리 동작을 더 포함할 수 있다. 일 실시예에 따르면, 제1 동작은 추가적인 이미지 처리 동작에서, 피사체가 사람(person)인 경우, 전자 장치는 피사체 이미지들에서 피사체의 특정 부분(예: 사람의 얼굴 또는 상반신)을 검출할 수 있다. 일 실시예에 따르면, 전자 장치는 검출된 피사체의 특정 부분에 대한 이미지들(예: 얼굴 이미지들, 상반신 이미지들)을 저장 장치(예: 데이터베이스(DB))에 저장할 수 있다. 일 실시예에 따르면, 제1 동작의 추가적인 이미지 처리 동작에서, 전자 장치는 피사체에 대한 다양한 3D 모델을 생성하기 위한 이미지 처리(예컨대, 조명 처리, 그림자 처리, 및/또는 피사체의 스타일(예: 안경, 수염, 머리 스타일 등)에 관련된 처리)를 수행할 수 있다.일 실시예에 따르면, 제2 동작은 3D 모델링 동작을 포함할 수 있다. 일 실시예에 따르면, 3D 모델링 동작에서, 전자 장치는 피사체에 대한 이미지들(피사체 이미지들)을 이용하여 해당 피사체에 대한 3D 모델을 생성할 수 있다. 일 실시예에 따르면, 전자 장치는 피사체에 대한 3D 모델을 생성하기 위해, 해당 피사체에 대한 이미지에 포함 되는 정보를 이용할 수 있다. 이미지에 포함되는 정보는 예컨대, 이미지의 특징(feature) 정보(예: 피사체의 특 징, 및/또는 배경의 특징), 피사체와 배경의 분할과 관련된 분할 정보, 이미지에 대한 위치 정보 및 방향 정보 (예컨대, 이미지를 촬영하는 카메라의 위치 정보(예: 상대적 위치) 및 방향 정보(예: 카메라 방향/각도)), 및/ 또는 이미지가 촬영된 시간에 대한 정보를 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 미리 학습된 제3 인공지능(AI) 모델(이하, 3D 모델링 모델)을 이용하여, 해당 피사체에 대한 3D 모델을 생성할 수 있다. 일 실시예에 따르면, 3D 모델링 모델은, 적어도 하나의 네트워크를 포함할 수 있다. 예를 들면, 도 2에 도시된 것처럼, 3D 모델링 모델은, 인코더(encoder), 및/또는 제너레이터(generator)를 포함할 수 있다. 일 실시예에 따르면, 인코더는 입력 데이터(예: 피사체 이미지들)로부터 해당 피사체(또는, 객체)에 대한 특징 (또는, 특징 벡터)를 획득하는 네트워크일 수 있다. 피사체(또는, 객체)에 대한 특징 벡터는, 피사체(또는, 객 체)의 형태, 표면 속성, 구조에 대한 정보를 제공할 수 있다. 특징 벡터는, 이후의 처리 과정, 예컨대, 제너레 이터의 처리 과정에서 사용될 수 있다. 일 실시예에 따르면, 제너레이터는 주어진 입력으로부터 3D 모델을 생성하는 네트워크일 수 있다. 예컨대, 제너 레이터는 인코더로부터 획득된 특징 벡터를 이용하여 해당 피사체(또는, 객체)에 대한 3D 모델을 생성할 수 있 다. 일 실시예에 따르면, 전자 장치는 3D 모델링 동작을 통해 획득된 3D 모델들을 저장 장치(예: 데이터베이스(D B))에 저장할 수 있다. 일 예로, 전자 장치는 3D 모델들을 클러스터(또는, 피사체) 별로 저장할 수 있다. 일 실시예에 따르면, 제1 동작 및 2는 전자 장치가 사용되지 않는 기간(예: 휴지 기간)에 백그라운드에서 실행 될 수 있다. 즉, 3D 모델을 생성하기 위한 이미지 처리 및 3D 모델링은 백그라운드 태스크로 수행될 수 있다. 일 예로, 전자 장치의 내부(또는, 외부)에 저장된 이미지들을 이용한 3D 모델 생성이 사용자에 의해 동의 된 경 우(예: 사용자 동의 입력이 수신된 경우), 전자 장치는 획득된 이미지들을 이용하여, 3D 모델을 생성하기 위한 이미지 처리 및 3D 모델링을 위한 동작을 백그라운드 태스크로 수행할 수 있다. 일 실시예에 따르면, 제1 동작 및 2는 자동으로 실행될 수 있다. 일 예로, 피사체에 대한 미리 설정된 수 이상 의 이미지가 획득되면, 전자 장치는 제1 동작 및 2를 자동으로 개시 및 실행할 수 있다. 상술한 제1 동작 및 2를 통해 피사체에 대한 3D 모델을 생성하는 경우, 사용자가 관심 있게 자주 촬영하여 저장 한 피사체의 이미지를 이용하여 3D 모델을 생성하기 때문에, 3D 모델을 생성하기 위한 번거로운 별도의 사전 촬 영 작업이 생략될 수 있다. 일 실시예에 따르면, 제3 동작은 3D 모델 이용 동작을 포함할 수 있다. 일 실시예에 따르면, 제3 동작의 3D 모델 이용 동작에서, 전자 장치는 3D 모델을 이용하여 기존 이미지(예: 2D 이미지)를 편집(또는, 변경)할 수 있다. 일 실시예에 따르면, 제3 동작의 3D 모델 이용 동작에서, 전자 장치는 3D 모델을 이용하여 새로운 이미지(예: 2D 이미지)를 생성할 수 있다. 일 예로, 전자 장치는 2D 이미지를 생성하기 위한 생성형 AI의 서브 입력으로 3D 모델을 사용할 수 있다. 상술한 3D 모델 이용 동작을 통해, 개인화된 이미지 편집이 가능하며, 생성형 AI를 이용한 개인화된 이미지 생 성이 가능하다. 도 3은 본 개시의 일 실시예에 따른, 3D 모델을 생성하는 방법을 나타내는 흐름도이다. 도 4는 본 개시의 일 실 시예에 따른, 시간 구간 별로 생성된 3D 모델을 나타낸다. 도 3의 3D 모델을 생성하는 방법은 도 2의 제1 동작 및 제2 동작을 통한 피사체(또는, 객체)에 대한 3D 모델을 생성하는 방법의 일 예일 수 있다. 이에 중복된 설명은 생략한다.일 실시예에 따르면, 3D 모델을 생성하는 방법은, 예컨대, 전자 장치의 사진 저장소에 저장된 2D 이미지를 이용 한 3D 모델의 생성을 동의하는 사용자 입력이 식별된 이후에 개시될 수 있다. 일 실시예에 따르면, 3D 모델을 생성하는 방법은 전자 장치가 사용되지 않는 기간(예: 휴지 기간)에 백그라운드 에서 백그라운드 태스크로서 실행될 수 있다. 도 3을 참조하면, 동작 3010에서, 전자 장치(예: 도 1의 전자 장치)는 2D 이미지들을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 전자 장치의 내부 저장 장치(예: 사진 갤러리) 또는 전자 장치에 연결된 외부 저 장 장치(예: 클라우드) 중 적어도 하나로부터 2D 이미지들을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 미리 설정된 수 이상의 2D 이미지들을 획득할 수 있다. 일 실시예에 따르면, 미리 설정된 수는, 피사체에 대한 3D 모델을 생성하기 위해 최소로 필요한 2D 이미지의 수일 수 있다. 동작 3020에서, 전자 장치는 2D 이미지들에 기초하여, 적어도 하나의 피사체(예: 3D 모델이 생성될 적어도 하나 의 피사체)를 식별할 수 있다. 적어도 하나의 피사체는 제1 피사체(예: 도 2의 사용자 1)를 포함할 수 있다. 적 어도 하나의 피사체는 예컨대, 2D 이미지들에 포함된 피사체일 수 있다. 일 실시예에 따르면, 전자 장치는 2D 이미지들을 분석하여, 3D 모델이 생성될 적어도 하나의 피사체를 식별할 수 있다. 동작 3030에서, 전자 장치는 2D 이미지들을 식별된 피사체 별로 클러스터링(또는, 분류) 할 수 있다. 일 실시예에 따르면, 전자 장치는 미리 학습된 클러스터링 모델을 이용하여 2D 이미지들을 식별된 피사체 별로 클러스터링 할 수 있다. 동작 3040에서, 전자 장치는 제1 피사체의 클러스터에 속하는 2D 이미지들에서 제1 피사체와 배경을 분리함으로 써, 배경이 제외된 제1 피사체를 포함하는 2D 이미지들(피사체 이미지들)을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 미리 학습된 분할 모델을 이용하여 제1 피사체의 클러스터에 속하는 2D 이미 지들에서 제1 피사체와 배경을 분리함으로써, 배경이 제외된 제1 피사체만을 포함하는 2D 이미지들을 획득할 수 있다. 일 실시예에 따르면, 피사체가 사람인 경우, 전자 장치는 배경이 제외된 제1 피사체만을 포함하는 2D 이미지들 에서 사람의 얼굴 또는 얼굴을 포함하는 상반신을 검출하고, 얼굴만을 포함하는 2D 이미지들 또는 상반신만을 포함하는 2D 이미지들을 획득할 수 있다. 이를 통해, 전자 장치는 피사체 이미지로부터 얼굴 또는 상반신 이외 의 부분이 제외된 이미지들을 획득할 수 있다. 동작 3050에서, 전자 장치는 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여 제1 피사체에 대한 3D 모델을 생성할 수 있다. 일 실시예에 따르면, 제1 피사체가 사람인 경우, 전자 장치는 제1 피사체 또는 제1 피사체의 일부(예: 얼굴 또 는 상반신)를 포함하는 2D 이미지들을 이용하여 제1 피사체의 일부(예: 얼굴 또는 상반신)에 대한 3D 모델을 생 성할 수 있다. 일 예로, 전자 장치는 제1 피사체 또는 제1 피사체의 얼굴을 포함하는 2D 이미지들을 이용하여, 얼굴 검출(face detection) 및 얼굴의 랜드마크 검출(facial landmark detection)을 수행하여 얼굴에 대한 특 징 데이터를 획득하고, 특징 데이터를 이용하여 얼굴에 대한 3D 모델(3D 얼굴 모델)을 생성할 수 있다. 일 실시예에 따르면, 전자 장치는 미리 학습된 3D 모델링 모델을 이용하여 제1 피사체(또는, 제1 피사체의 일부)에 대한 3D 모델을 생성할 수 있다. 일 실시예에 따르면, 전자 장치는 시간 순으로(예: 시간 구간 별로) 동일한 제1 피사체에 대한 복수의 3D 모델 을 생성할 수 있다. 일 예로, 제1 피사체에 대한 3D 모델을 생성하기 위해 사용되는 2D 이미지들은 제1 시점에 서 제1 시점 이후의 제2 시점까지의 제1 피사체에 대한 2D 이미지들일 수 있다. 예컨대, 과거 시점에서 현재 시 점까지 점진적으로 촬영되어 저장된 2D 이미지들(예: 오랜 시간에 걸쳐 점진적으로 촬영되어 저장된 사용자의 얼굴에 대한 이미지)이 3D 모델을 생성하기 위해 사용될 수 있다. 이 경우, 2D 이미지들에서 보여지는 해당 피 사체의 특징은 동일한 대상임에도 불구하고 시간에 따라 달라질 수 있다. 따라서, 해당 시점의 피사체의 실제 모습과 실질적으로 동일한 피사체의 3D 모델을 제공하기 위해, 전자 장치는 제1 피사체에 대한 하나의 3D 모델 만을 생성하는 대신에, 제1 피사체에 대한 3D 모델을 시간 구간 별로 각각 생성할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 피사체에 대한 3D 모델을 생성하기 위해 사용되는 2D 이미지들(예: 배경 이 제외된 제1 피사체를 포함하는 2D 이미지들)에 포함된 시간 정보(예: 촬영 시간 정보)를 이용하여 2D 이미지 들의 기간(예: 제1 시점에 제2 시점까지의 촬영 기간)을 식별하고, 2D 이미지들의 기간을 복수의 시간 구간으로 나누고, 각 시간 구간에 속하는 2D 이미지들을 이용하여, 시간 구간 별로 제1 피사체에 대한 3D 모델을 각각 생 성할 수 있다. 일 예로, 3D 모델을 생성하기 위해 사용된 2D 이미지가 사용자의 15년 동안의 얼굴 이미지인 경 우, 전자 장치는 사용자의 얼굴에 대한 3D 모델을 5년 단위로 생성하여, 해당 사용자에 대한 3개의 3D 얼굴 모 델을 생성할 수 있다. 예컨대, 도 4에 예시된 것처럼, 제1 피사체(도 1의 사용자 1)에 대하여, 제1 시간 구간의 3D 모델, 제1 시간 구간 이후의 제2 시간 구간의 3D 모델 및 제2 시간 구간 이후의 제3 시간 구간의 3D 모델이 생성될 수 있다. 각 시간 구간의 3D 모델은 해당 시간 구간의 제1 피사체의 특징(예: 얼굴의 특징)을 보여줄 수 있다. 일 실시예에 따르면, 전자 장치는 시간 순으로 생성된 피사체(또는, 객체)에 대한 복수의 3D 모델을 이용하여, 해당 피사체의 시간에 따른 변화하는 모습을 3차원으로 제공(또는, 기록)할 수 있다. 예를 들면, 전자 장치는 시간 구간 별로 생성된 피사체에 대한 복수의 3D 모델 간의 3D 특징점을 매칭함으로써, 해당 피사체의 시간에 따라 변화하는 모습을 3차원으로 제공할 수 있다. 예컨대, 전자 장치는 시간 구간 별로 생성된 피사체에 대한 복수의 3D 모델 간의 3D 특징점을 매칭하고, 시간에 따라 변화하는 과정을 합성함으로써 해당 피사체의 시간에 따른 변화 모습을 3차원으로 제공할 수 있다. 일 예로, 전자 장치는, 도 4에 예시된 것과 같은, 시간 순으로 생 성된 제1 피사체의 얼굴에 대한 복수의 3D 모델 간의 3D 특징점을 매칭하고, 시간에 따라 변화하는 과정을 합성 함으로써 제1 피사체의 얼굴의 시간에 따른 변화 모습을 3차원으로 사용자에게 제공할 수 있다. 도 5는 본 개시의 일 실시예에 따른, 3D 모델을 생성 또는 업데이트하는 방법을 나타내는 흐름도이다. 도 5의 3D 모델을 생성 또는 업데이트하는 방법은 예컨대, 2D 이미지가 추가적으로 획득된 경우에 수행되는 방 법일 수 있으나, 이에 제한되지 않는다. 상술한 것처럼, 피사체에 대한 3D 모델을 생성하기 위해 사용되는 2D 이미지들은 과거 시점에서 현재 시점까지 점진적으로 촬영되어 저장된 2D 이미지들일 수 있다. 이러한 2D 이미지들을 이용하여 생성된 3D 모델은 해당 피 사체에 대한 2D 이미지들이 더 누적될수록 높은 완성도를 가질 수 있다. 따라서, 3D 모델의 완성도(및/또는 정 밀도)를 점진적으로 높이기 위해, 새로 추가된 2D 이미지들을 이용하여 이미 생성된 3D 모델을 업데이트하기 위 한 절차가 필요하다. 도 5를 참조하면, 동작 5010에서, 전자 장치(예: 도 1의 전자 장치)는 추가 2D 이미지를 획득할 수 있다. 일 실시예에 따르면, 추가 2D 이미지는 예컨대, 전자 장치에 의해 촬영되어, 전자 장치 내의 저장 장치(예: 사 진 저장소)에 새로 저장된 이미지 또는 전자 장치에 연결된 저장 장치(예: 클라우드)에 새로 저장된 이미지일 수 있다. 동작 5020에서, 전자 장치는 추가 2D 이미지를 분석하여 추가 2D 이미지에 포함된 피사체(이하, 제1 피사체)를 식별할 수 있다. 동작 5030에서, 전자 장치는 제1 피사체를 포함하는 2D 이미지들의 수가 미리 설정된 수 이상인지 여부를 식별 할 수 있다. 예를 들면, 전자 장치는 저장 장치에 저장된 2D 이미지들 내에서 제1 피사체를 포함하는 2D 이미지 들의 수가 미리 설정된 수 이상인지 여부를 식별할 수 있다. 제1 피사체를 포함하는 2D 이미지들의 수가 미리 설정된 수 이상인 경우, 동작 5040을 수행할 수 있다. 제1 피사체를 포함하는 2D 이미지들의 수가 미리 설정된 수 미만인 경우, 추가 2D 이미지를 저장 장치에 저장하고, 동작 5010을 다시 수행할 수 있다. 이를 통해, 전자 장치는 피사체에 대한 충분한 수의 2D 이미지가 저장(또는, 획득)된 경우에만, 해당 피사체에 대한 이미지 클러 스터링을 수행할 수 있어, 이미지 클러스터링에 따른 불필요한 전력 소모를 막을 수 있다. 동작 5040에서, 전자 장치는 제1 피사체를 포함하는 2D 이미지들을 제1 피사체의 클러스터에 속하는 이미지들로 분류(또는, 클러스터링)할 수 있다. 동작 5040의 설명은 도 3의 동작 3030의 설명을 참조할 수 있다. 이에 중복 된 설명은 생략한다. 동작 5050에서, 전자 장치는 제1 피사체의 클러스터에 속하는 2D 이미지들에서 제1 피사체와 배경을 분리함으로 써, 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 획득할 수 있다. 동작 5050의 설명은 도 3의 동작 3040의 설명을 참조할 수 있다. 이에 중복된 설명은 생략한다. 일 실시예에 따르면, 전자 장치는 제1 피사체가 사람인지를 식별할 수 있다. 제1 피사체가 사람인 경우, 제1 피 사체를 포함하는 2D 이미지들을 이용하여, 얼굴 검출(face detection) 및 얼굴의 랜드마크 검출(faciallandmark detection)을 수행하여 얼굴에 대한 특징 데이터를 획득할 수 있다. 동작 5060에서, 전자 장치는 제1 피사체에 대한 이미 생성된 3D 모델이 존재하는지 여부를 식별할 수 있다. 일 실시예에 따르면, 피사체가 사람인 경우, 전자 장치는 얼굴에 대한 특징 데이터를 이용하여, 얼굴에 대한 이미 생성된 3D 모델(3D 얼굴 모델)이 존재하는지 여부를 식별할 수 있다. 제1 피사체에 대한 이미 생성된 3D 모델이 존재하지 않는 경우, 동작 5070이 수행될 수 있다. 제1 피사체에 대 한 이미 생성된 3D 모델이 존재하는 경우, 동작 5080이 수행될 수 있다. 동작 5070에서, 전자 장치는 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여 제1 피사체에 대한 3D 모델을 생성할 수 있다. 동작 5070의 설명은 도 3의 동작 3050의 설명을 참조할 수 있다. 이에 중복된 설명 은 생략한다. 일 실시예에 따르면, 얼굴에 대한 이미 생성된 3D 얼굴 모델이 존재하지 않는 경우, 전자 장치는 얼굴에 대한 특징 데이터를 이용하여 얼굴에 대한 3D 모델을 생성할 수 있다. 이와 같이, 새로 추가된 2D 이미지들을 이용하 여, 3D 모델이 새로 생성될 수 있다. 동작 5080에서, 전자 장치는 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여 제1 피사체에 대한 이미 생성된 3D 모델을 업데이트(또는, 리파인(refine))할 수 있다. 이러한 추가 2D 이미지들을 이용한 3D 모델 의 업데이트를 통해, 이미 생성된 3D 모델의 완성도 및/또는 정밀도가 시간이 지남에 따라 점진적으로 높아질 수 있다. 일 실시예에 따른, 전자 장치는 미리 학습된 인공지능 모델(이하, 리파인 모델)을 이용하여 이미 생성된 3D 모 델을 업데이트할 수 있다. 일 실시예에 따르면, 전자 장치는 업데이트 된 3D 모델을 저장 장치(예: 데이터베이스(DB))에 저장할 수 있다. 일 예로, 전자 장치는 업데이트된 3D 모델을 클러스터(또는, 피사체) 별로 저장할 수 있다. 일 실시예에 따르면, 얼굴에 대한 이미 생성된 3D 모델이 존재하는 경우, 전자 장치는 얼굴에 대한 특징 데이터 를 이용하여 얼굴에 대한 3D 얼굴 모델을 업데이트할 수 있다. 이와 같이, 새로 추가된 2D 이미지들을 이용하여, 기존 3D 모델이 업데이트될 수 있다. 도 6은 본 개시의 일 실시예에 따른, 3D 모델을 이용하여 2D 이미지를 편집하는 절차를 나타내는 흐름도이다. 도 7은 본 개시의 일 실시예에 따른, 3D 모델을 이용한 2D 이미지 편집의 일 예를 나타낸다. 도 8은 본 개시의 일 실시예에 따른, 3D 모델을 이용한 2D 이미지 편집의 일 예를 나타낸다. 도 7 및 8의 실시예의 2D 이미지 편집은 예컨대, 도 6의 2D 이미지 편집 절차를 이용한 2D 이미지 편집일 수 있 다. 일 실시예에 따르면, 3D 모델을 이용한 2D 이미지의 편집은, 예컨대, 3D 모델을 이용한 2D 이미지 내의 피사체 (또는, 객체)의 회전, 이동, 크기 조정(scaling), 표정 변화, 조명 효과, 그림자 효과, 블러된(blurred) 부분의 복원, 및/또는 합성을 포함할 수 있으나, 이에 제한되지 않는다. 도 6을 참조하면, 동작 6010에서, 전자 장치(예: 도 1의 전자 장치)는 대상 피사체(이하, 제1 피사체로 지 칭될 수 있음)와 배경을 포함하는 입력 2D 이미지를 식별(또는, 획득)할 수 있다. 예를 들면, 도 7 및 8에 예시 된 것처럼, 전자 장치는 제1 피사체(7011,8011) 및 배경(7012,8012)을 포함하는 입력 2D 이미지(7010,8010)를 식별할 수 있다. 동작 6020에서, 전자 장치는 입력 2D 이미지를 제1 피사체를 포함하는 제1 피사체 이미지와 배경을 포함하는 제 1 배경 이미지로 분리할 수 있다. 예를 들면, 도 7 및 8에 예시된 것처럼, 전자 장치는 입력 2D 이미지 (7010,8010)를 제1 피사체 이미지(7021,8021) 및 제1 배경 이미지(7031,8031)로 분리할 수 있다. 일 실시예에 따른, 제1 피사체 이미지는 입력 2D 이미지에서 배경이 제외된(또는, 제거된) 대상 피사체만을 포 함하는 이미지일 수 있다. 일 실시예에 따른, 제1 배경 이미지는 입력 2D 이미지에서 대상 피사체가 제외된(또 는, 제거된) 배경만을 포함하는 이미지일 수 있다. 일 실시예에 따른, 배경은 대상 피사체를 제외한 부분(예: 다른 피사체, 주변 환경 등)일 수 있다. 본 개시의 다양한 실시예에서, 제1 배경 이미지에서 대상 피사체가 제 외된 영역은 피사체 제외 영역으로 지칭될 수 있다. 동작 6030에서, 전자 장치는 제1 피사체에 대한 3D 모델을 이용하여 제1 피사체 이미지 내의 제1 피사체를 변환 하여, 변환된 제1 피사체를 포함하는 제2 피사체 이미지를 생성할 수 있다. 일 실시예에 따르면, 제1 피사체를 변환하는 것은, 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경 하는 것을 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 피사체 이미지에 기초하여, 제1 피사체에 대한 3D 모델을 변형(deform)시 키고, 변형된 3D 모델을 이용하여 제1 피사체 이미지 내의 제1 피사체를 변환할 수 있다. 일 예로, 전자 장치는 제1 피사체 이미지에 기초하여, 제1 피사체에 대한 3D 모델을 제1 피사체 이미지에 대응하는(또는, 맞는) 3D 모 델로 변형할 수 있다. 3D 모델의 변형은, 정해진 변형(deformation) 방식을 이용할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 피사체에 대한 3D 모델(또는, 변형된 3D 모델)을 이용하여 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함 하는 제2 피사체 이미지를 생성할 수 있다. 일 실시예에 따르면, 전자 장치는 사용자 입력을 기초로 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모 델)에 대한 가상의 카메라의 방향을 변경함으로써, 제1 피사체의 방향을 변경할 수 있다. 예를 들면, 도 7에 예 시된 것처럼, 전자 장치는 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모델)을 향하는 가상의 카메라의 방향을 변경하는 사용자 입력이 수신되는 것에 기초하여, 제1 피사체의 방향을 변경할 수 있다. 이후, 전자 장치는 방향이 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성(또는, 렌더링)할 수 있다. 예컨대, 도 7에 예시된 것처럼, 전자 장치는 방향이 변경된 제1 피사체를 포함하는 제2 피사체 이 미지를 생성할 수 있다. 이를 통해, 다른 방향의 제1 피사체의 형상(또는, 모습)이 보여질 수 있다. 예를 들면, 도 7에 예시된 것처럼, 제1 피사체 이미지 상에서 보여지는 제1 피사체의 얼굴의 정면이 아닌, 좌 측면이 제2 피사체 이미지 상에서 보여질 수 있다. 일 실시예에 따르면, 전자 장치는 사용자 입력을 기초로 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모 델)을 이용하여 제1 피사체의 위치를 변경함으로써, 제1 피사체의 위치 및/또는 방향을 변경할 수 있다. 예를 들면, 전자 장치는 제1 피사체를 제1 방향(예: 상, 하, 좌 또는 우 방향)으로 이동(translation)시키기 위한 사 용자 입력을 획득하고, 사용자 입력이 획득되는 것에 응답하여 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모델)을 이용하여 제1 피사체의 위치 및 방향을 변경할 수 있다. 예를 들면, 도 8에 예시된 것처럼, 전자 장치 는 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모델)을 우측 방향으로 이동시키는 사용자 입력을 획득 하고, 사용자 입력이 획득되는 것에 응답하여 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모델)을 이용하 여 제1 피사체의 위치 및 방향을 함께 변경할 수 있다. 이처럼, 사용자 입력은 제1 피사체의 위치 이동을 위한 사용자 입력에 불과하나, 예컨대, 입력 2D 이미지를 촬영한 카메라의 구도가 제1 피사체의 위치 이동과 무 관하게 고정된 상태임을 고려할 때, 해당 카메라 구도 하에서 제1 피사체의 위치 이동은 위치와 방향의 변경을 동반할 수 있다. 이후, 전자 장치는 위치 및 방향이 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성 (또는, 렌더링)할 수 있다. 예를 들면, 도 8에 예시된 것처럼, 전자 장치는 위치 및 방향이 변경된 제1 피사체 를 포함하는 제2 피사체 이미지를 생성할 수 있다. 이를 통해, 다른 위치 및 방향의 제1 피사체의 형상(또는, 모습)이 보여질 수 있다. 예를 들면, 도 8에 예시된 것처럼, 제1 피사체 이미지 상에서 보여 지는 제1 피사체의 얼굴의 정면이 아닌, 정면과 좌 측면 사이의 중간 얼굴이 제2 피사체 이미지 상 에서 보여질 수 있다. 즉, 위치와 방향이 변경된 제1 피사체의 형상이 보여질 수 있다. 일 실시예에 따르면, 전자 장치는 제1 피사체에 대한 3D 모델(또는, 변형된 3D 모델)을 이용하여 제1 피사체의 크기를 변경함으로써, 크기, 위치 및/또는 방향이 변경된 1 피사체를 포함하는 제2 피사체 이미지를 생성할 수 있다. 일 예로, 전자 장치는 사용자 입력을 기초로, 제1 피사체에 대한 3D 모델(또는, 변형된 3D 모델)을 이용 하여 제1 피사체의 크기를 변경할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 피사체에 대한 3D 모델(또는, 변형된 3D 모델)을 이용하여 제1 피사체의 표정 변화, 조명 효과, 그림자 효과, 블러된 부분의 복원, 및/또는 합성을 제공하기 위한 이미지 처리를 수행함 으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성할 수 있다. 일 예로, 전자 장치는 사용자 입 력을 기초로, 3D 모델(또는, 변형된 3D 모델)을 이용하여 제1 피사체의 표정 변화, 조명 효과, 그림자 효과, 블 러된 부분의 복원, 및/또는 합성을 제공하기 위한 이미지 처리를 수행할 수 있다. 동작 6040에서, 전자 장치는 제1 배경 이미지에 대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성할 수 있다. 일 실시예에 따르면, 제1 배경 이미지에 대한 이미지 처리 동작인 동작 6040은 제1 피사체 이미지에 대한 이미지 처리 동작(예: 동작 6020 및 동작 6030)과 병렬적으로 수행될 수 있다. 예컨대, 동작 6040은 동작 6020 또는 6040과 동시에 수행될 수 있다. 동작 6040과 동작 6020 또는 동작 6040 간의 동작의 선후 관계는 구현 방식에 따라 다양할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 배경 이미지 내의 피사체 제외 영역 또는 제1 배경 이미지 외부의 확장 영역 중 적어도 하나에 대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성할 수 있다. 일 실시예에 따르면, 확장 영역은 제1 피사체의 변경(예: 위치 변경)과 연관될 수 있다. 일 실시예에 따르면, 제1 배경 이미지 내의 피사체 제외 영역에 대한 이미지 처리는 제1 배경 이미지 내의 피사 체 제외 영역에 대한 인-페인팅(in-painting) 처리를 포함할 수 있다. 인-페인팅 처리는 예컨대, 현재 이미지에 대한 정보를 기초로 이미지 내의 누락된 영역(missing area)를 복원하기 위한 이미지 처리일 수 있다. 예를 들 면, 제1 배경 이미지 내의 피사체 제외 영역에 대한 이미지 처리는, 제1 배경 이미지에 포함된 정보를 기초로 피사체 제외 영역에 배경을 추가하기 위한 인-페인팅 처리를 포함할 수 있다. 일 예로, 도 7에 예시된 것처럼, 전자 장치는 제1 배경 이미지에 포함된 정보에 기초하여, 제1 배경 이미지 내의 제1 피사체가 제외 된 영역(피사체 제외 영역)을 복원시키기 위한 인-페인팅 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배 경 이미지를 생성할 수 있다. 이를 통해, 피사체 제외 영역이 배경으로 채워질 수 있다. 일 실시예에 따르면, 제1 배경 이미지 외부의 확장 영역에 대한 이미지 처리는, 제1 배경 이미지 외부의 변경된 피사체의 위치에 대응하는 확장 영역에 대한 아웃-페인팅(out-painting) 처리를 포함할 수 있다. 아웃-페인팅 처리는 예컨대, 현재 정보를 기초로 확장된 영역(expanding area)에 대한 이미지를 추가 생성하기 위한 이미지 처리일 수 있다. 예를 들면, 제1 배경 이미지 외부의 확장 영역에 대한 이미지 처리는, 제1 배경 이미지에 포함 된 정보를 기초로 변경된 피사체의 위치와 연관된 확장 영역에 배경을 추가하기 위한 아웃-페인팅 처리를 포함 할 수 있다. 일 예로, 도 8에 예시된 것처럼, 전자 장치는 제1 배경 이미지에 포함된 정보에 기초하여, 제1 배경 이미지 외부의 변경된 피사체의 위치에 대응하는 확장된 영역에 대한 배경을 추가적으로 생 성하기 위한 아웃-페인팅 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성할 수 있 다. 이를 통해, 피사체의 위치 이동에 따라 확장되는 부분(또는, 영역)에 배경이 새롭게 추가될 수 있다. 일 실시예에 따르면, 제1 배경 이미지에 대한 이미지 처리는, 상술한 인페인팅 처리 및 아웃-페인팅 처리를 포 함할 수 있다. 일 예로, 도 8에 예시된 것처럼, 전자 장치는 제1 배경 이미지에 포함된 정보에 기초하여, 제1 배경 이미지 내의 제1 피사체가 제외된 영역(피사체 제외 영역)을 복원시키기 위한 인-페인팅 처리를 수행하고, 제1 배경 이미지 외부의 변경된 피사체의 위치에 대응하는 확장된 영역에 대한 배경을 추가적 으로 생성하기 위한 아웃-페인팅 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성 할 수 있다. 동작 6050에서, 전자 장치는 제2 피사체 이미지와 제2 배경 이미지를 합성하여, 출력 2D 이미지를 생성할 수 있 다. 예를 들면, 도 7 및 8에 예시된 것처럼, 전자 장치는 제2 피사체 이미지(7022,8022)와 제2 배경 이미지 (7032,8032)를 합성하여, 출력 2D 이미지(7040,8040)를 생성할 수 있다. 도 9는 본 개시의 일 실시예에 따른, 3D 모델을 이용하여 2D 이미지를 편집하는 절차를 나타내는 흐름도이다. 도 10은 본 개시의 일 실시예에 따른, 3D 모델을 이용한 2D 이미지 편집의 일 예를 나타낸다. 도 11은 본 개시 의 일 실시예에 따른, 3D 모델을 이용한 2D 이미지 편집의 일 예를 나타낸다. 도 9의 2D 이미지 편집 절차는, 도 6의 2D 이미지 편집 절차와 비교하여, 배경에 대한 이미지 처리(예: 인-페인 팅 처리 및 아웃-페인팅 처리)가 출력 2D 이미지를 생성한 이후에 수행되는 점에서 차이를 가질 뿐, 피사체에 대한 이미지 처리는 동일할 수 있다. 이에 중복된 설명은 생략한다. 도 10 및 11의 실시예의 2D 이미지 편집은 예컨대, 도 9의 2D 이미지 편집 절차를 이용한 2D 이미지 편집일 수 있다. 일 실시예에 따르면, 3D 모델을 이용한 2D 이미지의 편집은, 예컨대, 3D 모델을 이용한 2D 이미지 내의 피사체 (또는, 객체)의 회전, 이동, 크기 조정, 표정 변화, 조명 효과, 그림자 효과, 블러된 부분의 복원, 및/또는 합 성을 포함할 수 있으나, 이에 제한되지 않는다. 도 9를 참조하면, 동작 9010에서, 전자 장치(예: 도 1의 전자 장치)는 대상 피사체(이하, 제1 피사체로 지 칭될 수 있음)와 배경을 포함하는 입력 2D 이미지를 식별(또는, 획득)할 수 있다. 예를 들면, 도 10 및 11에 예 시된 것처럼, 전자 장치는 제1 피사체(10011,11011) 및 배경(10012,11012)을 포함하는 입력 2D 이미지 (10010,11010)를 식별할 수 있다. 동작 9010의 설명은 동작 6010의 설명을 참조할 수 있다. 이에 중복된 설명은생략한다. 동작 9020에서, 전자 장치는 입력 2D 이미지를 제1 피사체를 포함하는 제1 피사체 이미지와 배경을 포함하는 제 1 배경 이미지로 분리할 수 있다. 예를 들면, 도 10 및 11에 예시된 것처럼, 전자 장치는 입력 2D 이미지 (10010,11010)를 제1 피사체 이미지(10021,11021) 및 제1 배경 이미지(10031,11031)로 분리할 수 있다. 동작 9020의 설명은 동작 6020의 설명을 참조할 수 있다. 이에 중복된 설명은 생략한다. 동작 9030에서, 전자 장치는 제1 피사체에 대한 3D 모델을 이용하여 제1 피사체 이미지 내의 제1 피사체를 변환 하여, 변환된 제1 피사체를 포함하는 제2 피사체 이미지를 생성할 수 있다. 동작 9030의 설명은 동작 6030의 설 명을 참조할 수 있다. 이에 중복된 설명은 생략한다. 일 실시예에 따르면, 전자 장치는 사용자 입력을 기초로 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모 델)에 대한 가상의 카메라의 방향을 변경함으로써, 제1 피사체의 방향을 변경할 수 있다. 예를 들면, 도 10에 예시된 것처럼, 전자 장치는 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모델)을 향하는 가상 의 카메라의 방향을 변경하는 사용자 입력이 수신되는 것에 기초하여, 제1 피사체의 방향을 변경할 수 있다. 이후, 전자 장치는 방향이 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성(또는, 렌더링)할 수 있다. 예컨대, 도 10에 예시된 것처럼, 전자 장치는 방향이 변경된 제1 피사체를 포함하는 제2 피사 체 이미지를 생성할 수 있다. 이를 통해, 다른 방향의 제1 피사체의 형상이 보여질 수 있다. 예를 들면, 도 10에 예시된 것처럼, 제1 피사체 이미지 상에서 보여지는 제1 피사체의 얼굴의 정면이 아닌, 좌 측면 이 제2 피사체 이미지 상에서 보여질 수 있다. 일 실시예에 따르면, 전자 장치는 사용자 입력을 기초로 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모 델)을 이용하여 제1 피사체의 위치를 변경함으로써, 제1 피사체의 위치 및/또는 방향을 변경할 수 있다. 예를 들면, 전자 장치는 제1 피사체를 제1 방향(예: 상, 하, 좌 또는 우 방향)으로 이동시키기 위한 사용자 입력을 획득하고, 사용자 입력이 획득되는 것에 응답하여 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모델)을 이 용하여 제1 피사체의 위치 및 방향을 변경할 수 있다. 예를 들면, 도 11에 예시된 것처럼, 전자 장치는 제1 피 사체에 대응하는 3D 모델(또는, 변형된 3D 모델)을 우측 방향으로 이동시키는 사용자 입력을 획득하고, 사용자 입력이 획득되는 것에 응답하여 제1 피사체에 대응하는 3D 모델(또는, 변형된 3D 모델)을 이용하여 제1 피사체의 위치 및 방향을 함께 변경할 수 있다. 이처럼, 사용자 입력은 제1 피사체의 위치 이동을 위한 사용자 입력에 불과하나, 예컨대, 입력 2D 이미지를 촬영한 카메라의 구도가 제1 피사체의 위치 이동과 무관하 게 고정된 상태임을 고려할 때, , 해당 카메라 구도 하에서 제1 피사체의 위치 이동은 위치와 방향의 변경을 동 반할 수 있다. 이후, 전자 장치는 위치 및 방향이 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성(또 는, 렌더링)할 수 있다. 예를 들면, 도 11에 예시된 것처럼, 전자 장치는 위치 및 방향이 변경된 제1 피사체 를 포함하는 제2 피사체 이미지를 생성할 수 있다. 이를 통해, 다른 위치 및 방향의 제1 피사체 의 형상이 보여질 수 있다. 예를 들면, 도 8에 예시된 것처럼, 제1 피사체 이미지 상에서 보여지는 제1 피사체의 얼굴의 정면이 아닌, 정면과 좌 측면 사이의 중간 얼굴이 제2 피사체 이미지 상에서 보 여질 수 있다. 즉, 위치와 방향이 변경된 제1 피사체의 형상이 보여질 수 있다. 일 실시예에 따르면, 전자 장치는 제1 피사체에 대한 3D 모델(또는, 변형된 3D 모델)을 이용하여 제1 피사체의 크기를 변경함으로써, 크기, 위치 및/또는 방향이 변경된 1 피사체를 포함하는 제2 피사체 이미지를 생성할 수 있다. 일 예로, 전자 장치는 사용자 입력을 기초로, 제1 피사체에 대한 3D 모델(또는, 변형된 3D 모델)을 이용 하여 제1 피사체의 크기를 변경할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 피사체에 대한 3D 모델(또는, 변형된 3D 모델)을 이용하여 제1 피사체의 표정 변화, 조명 효과, 그림자 효과, 블러된 부분의 복원, 및/또는 합성을 제공하기 위한 이미지 처리를 수행함 으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성할 수 있다. 일 예로, 전자 장치는 사용자 입 력을 기초로, 3D 모델(또는, 변형된 3D 모델)을 이용하여 제1 피사체의 표정 변화, 조명 효과, 그림자 효과, 블 러된 부분의 복원, 및/또는 합성을 제공하기 위한 이미지 처리를 수행할 수 있다. 동작 9040에서, 전자 장치는 제2 피사체 이미지와 제1 배경 이미지를 합성하여, 출력 2D 이미지를 생성할 수 있 다. 예를 들면, 도 10 및 11에 예시된 것처럼, 전자 장치는 제2 피사체 이미지(10022,10022)와 제1 배경 이미지 (10031,11031)를 합성하여, 출력 2D 이미지(10040,11040)를 생성할 수 있다. 이처럼, 도 6의 실시예와 달리, 도 9의 실시예에서는, 피사체에 대한 이미지 처리가 수행된 제2 피사체 이미지와 배경에 대한 이미지 처리가 수 행되기 이전의 제1 배경 이미지를 합성하기 때문에, 출력 2D 이미지에서 배경을 완성하기 위한 추가적인 처리가 더 필요하다. 이는 동작 9050을 참조하여, 이하에서 설명한다.동작 9050에서, 전자 장치는 출력 2D 이미지 내의 배경에 대한 이미지 처리를 수행함으로써, 변경된 배경(또는, 완성된 배경)을 포함하는 최종 출력 2D 이미지를 생성할 수 있다. 일 실시예에 따르면, 배경에 대한 이미지 처리는 제1 배경 이미지 내의 제1 영역에 대한 인-페인팅 처리를 포함 할 수 있다. 인-페인팅 처리는 예컨대, 현재 이미지에 대한 정보를 기초로 이미지 내의 누락된 영역를 복원하기 위한 이미지 처리일 수 있다. 일 예로, 도 10에 예시된 것처럼, 전자 장치는 제1 배경 이미지 또는 출력 2D 이미지에 포함된 정보에 기초하여, 출력 2D 이미지 내의 배경이 누락된 영역(또는, 부 분)을 복원(또는, 완성)시키기 위한 인-페인팅 처리를 수행함으로써, 변경된 배경(또는, 완성된 배경)을 포함하는 최종 출력 2D 이미지를 생성할 수 있다. 이를 통해, 배경이 누락된 영역(또는, 부분)이 복원될 수 있다. 출력 2D 이미지 내의 배경이 누락된 영역은 제1 배경 이미지 내의 피사체 제외 부분의 적어도 일부와 오버랩 될 수 있다. 일 실시예에 따르면, 배경에 대한 이미지 처리는 제1 배경 이미지 외부의 변경된 피사체의 위치에 대응하는 제2 영역에 대한 아웃-페인팅 처리를 포함할 수 있다. 아웃-페인팅 처리는 예컨대, 현재 이미지에 대한 정보를 기초 로 확장된 영역에 대한 이미지를 추가 생성하기 위한 이미지 처리일 수 있다. 일 예로, 도 11에 예시된 것처럼, 전자 장치는 제1 배경 이미지 또는 출력 2D 이미지에 포함된 정보에 기초하여, 출력 2D 이미지 내의 변경된 피사체의 위치에 대응하는 확장된 영역에 대한 배경을 추가적으로 생성하기 위한 아웃-페인팅 처리를 수행함으로써, 변경된 배경(또는, 완성된 배경)을 포함하는 최종 2D 출력 이미지를 생성할 수 있다. 이를 통해, 피사체의 위치 이동에 따라 확장되는 부분(또는, 영역)에 배경이 새롭게 추가될 수 있다. 출력 2D 이미지 내의 변경된 피사체의 위치에 대응하는 확장된 영역은 제1 배경 이미지 내의 피사체 제외 부분의 적어도 일부와 오버랩 될 수 있다. 일 실시예에 따르면, 배경에 대한 이미지 처리는, 상술한 인페인팅 처리 및 아웃-페인팅 처리를 함께 수행하는 이미지 처리를 포함할 수 있다. 인페인팅 처리 및 아웃-페인팅 처리의 각각에 대한 설명은 상술한 설명을 참조 할 수 있다. 도 12는 본 개시의 일 실시예에 따른 3D 모델을 이용하여 이미지를 생성하는 절차를 나타내는 흐름도이다. 도 12를 참조하면, 동작 12010에서, 전자 장치(예: 도 1의 전자 장치)는 이미지 생성 요청을 식별할 수 있 다. 일 실시예에 따르면, 전자 장치는 사용자 입력에 기초하여, 이미지 생성 요청을 식별할 수 있다. 예를 들면, 전 자 장치는 이미지 생성을 요청하는 사용자 입력을 수신하고, 이를 기초로 이미지 생성 요청을 식별할 수 있다. 일 실시예에 따르면, 이미지 생성 요청은 예컨대, 생성형 AI를 이용한 2D 이미지 또는 3D 이미지를 생성하기 위 한 요청일 수 있다. 일 예로, 이미지 생성 요청은 생성형 AI를 이용한 사진(예: 증명 사진, 프로필 사진) 또는 그림을 생성하기 위한 요청일 수 있다. 일 실시예에 따르면, 이미지 생성 요청은 생성될 이미지(예: 사진 또는 그림)에 관련된 정보(이하, 이미지 생성 관련 정보)를 포함할 수 있다. 이미지 생성 관련 정보는, 예컨대, 생성될 이미지의 대상이 되는 피사체(이하, 대상 피사체)를 지시하는 정보, 대상 피사체가 바라보는 시점에 대한 정보, 생성될 이미지 내에서 대상 피사체 의 위치와 방향에 대한 정보, 대상 피사체의 스타일(예: 헤어 스타일, 안경 착용 여부, 모자 착용 여부, 살찐 정도 및/또는 의상 스타일)에 대한 정보, 대상 피사체의 표정에 대한 정보, 생성될 이미지의 배경에 대한 정보, 생성될 이미지의 조명 효과에 대한 정보, 생성될 이미지의 그림자 효과에 대한 정보, 생성될 이미지 내의 배경 (예: 대상 피사체 이외의 객체/피사체/주변 환경 등)에 대한 정보 및/또는 대상 피사체의 시기(또는, 시간 구간)에 대한 정보를 포함할 수 있다. 일 실시예에 따르면, 이미지 생성 관련 정보는 사용자에 의해 입력된 정 보일 수 있다. 동작 12020에서, 전자 장치는 대상 피사체(또는, 해당 피사체)에 대한 3D 모델을 식별할 수 있다. 일 실시예에 따르면, 전자 장치는 이미지 생성 요청에 기초하여 대상 피사체를 식별하고, 식별된 대상 피사체에 대한 3D 모 델을 식별할 수 있다. 3D 모델은 대상 피사체의 2D 이미지들을 이용하여 이미 생성되어 저장된 3D 모델일 수 있 다. 3D 모델의 생성/업데이트 및 생성된 3D 모델의 종류는, 도 2 내지 5의 설명을 참조할 수 있다. 일 실시예에 따르면, 전자 장치는 식별된 3D 모델을 생성될 이미지에 대한 이미지 처리를 수행하기 위해 이용할 지 여부를 결정할 수 있다. 예를 들면, 식별된 3D 모델을 생성될 이미지에 대한 이미지 처리를 수행하기 위해 이용할지 여부를 결정하기 위해, 전자 장치는 식별된 3D 모델의 완성도가 미리 설정된 기준(예: 임계 값)을 만족하는지 여부를 식별할 수 있다. 일 예로, 식별된 3D 모델을 생성될 이미지에 대한 이미지 처리를 수행하기 위 해 이용할지 여부를 결정하기 위해, 동작 12030에서와 같이, 전자 장치는 3D 모델의 완성도(및/또는 정밀도)가 임계 값 이상인지 여부를 식별할 수 있다. 상술한 것처럼, 피사체에 대한 3D 모델은 피사체에 대한 저장된 2D 이미지들을 이용하여 생성되고 업데이트되므로, 사용 시점에 따라 3D 모델의 완성도(및/또는 정밀도)가 다를 수 있다. 예를 들면, 사용 시점이 제1 시점인 경우, 해당 객체에 대한 3D 모델을 생성하기 위해 사용되는 2D 이미 지의 수가 적어 해당 3D 모델의 완성도(및/또는 정밀도)가 낮을 수 있으나, 사용 시점이 제1 시점 이후인 제2 시점인 경우, 해당 객체에 대한 3D 모델을 생성하기 위해 사용되는 2D 이미지의 수가 충분히 많이 누적되어 3D 모델의 완성도(및/또는 정밀도)가 높아질 수 있다. 일 실시예에 따르면, 임계 값은 피사체에 대한 3D 모델이 이용 가능한 수준을 만족하는지 여부를 확인하기 위해 미리 설정된 값일 수 있다. 일 실시예에 따르면, 전자 장치는 사용자 입력에 기초하여, 또는 사용자 입력 없이 자체적으로 3D 모델의 완성 도(및/또는 정밀도)가 임계 값 이상인지 여부를 식별할 수 있다. 일 예로, 전자 장치는 3D 모델의 완성도(및/또 는 정밀도)와 관련된 사용자 입력을 수신하고, 사용자 입력에 기초하여 3D 모델의 완성도(및/또는 정밀도)가 임 계 값 이상인지 여부를 식별할 수 있다. 예를 들면, 전자 장치는 3D 모델의 일부(예: 머리의 뒷부분)의 완성도 가 떨어진다는 사용자 입력을 수신하고, 수신된 사용자 입력에 기초하여 3D 모델의 완성도가 임계 값 미만임을 식별할 수 있다. 일 실시예에 따르면, 3D 모델의 완성도(및/또는 정밀도)가 임계 값 이상인 경우, 전자 장치는 해당 3D 모델이 사용 가능한 수준을 넘어서는 것으로 확인하고, 동작 12040을 수행할 수 있다. 동작 12040에서, 전자 장치는 3D 모델에 기초하여, 생성될 이미지에 대한 이미지 처리를 수행할 수 있다. 일 실 시예에 따른, 이미지 처리는 생성될 이미지에 대한 화질(또는, 품질) 개선 처리를 포함할 수 있다. 화질 개선 처리는 3D 모델에 기초하여 생성될 이미지의 화질 또는 품질을 개선시키기 위한 처리를 포함할 수 있다. 일 예 로, 화질 개선 처리는 3D 모델의 3D 깊이(depth) 정보를 이용하여, 생성될 이미지 또는 사진에 조명 효과 및/또 는 그림자 효과를 강화하는 처리를 포함할 수 있다. 일 예로, 화질 개선 처리는 3D 모델의 정보를 이용하여, 생 성될 이미지에서 객체의 표정 변화, 스타일 변화, 블러된 부분의 복원, 회전, 이동, 크기 조정 및/또는 합성에 대한 처리를 포함할 수 있다. 이와 같은, 사용 가능한 수준의 완성도 및 정밀도를 갖는 3D 모델을 이용한 화질 개선 처리를 통해, 단순히 생성형 AI를 이용하는 것에 비하여, 더욱 높은 화질 또는 품질의 이미지가 사용자에 게 제공될 수 있다. 예컨대, 더욱 정밀하고, 인상적인 이미지가 사용자에게 제공될 수 있다. 이미지 처리의 일 예에 대하여는 도 13을 참조하여 이하에서 설명한다. 일 실시예에 따르면, 3D 모델의 완성도(및/또는 정밀도)가 임계 값 미만인 경우, 전자 장치는 해당 3D 모델이 사용 가능한 수준을 넘어서지 못하는 것으로 확인하고, 동작 12040를 수행하지 않고, 바로 동작 12050을 수행할 수 있다. 이처럼, 3D 모델이 사용가능한 수준의 완성도(및/또는 정밀도)를 갖지 못하는 경우, 전자 장치는 3D 모델을 이용하여 생성될 이미지에 대한 이미지 처리를 수행하는 동작을 생략할 수 있다. 동작 12050에서, 전자 장치는 생성된 이미지(예: 사진, 그림)를 제공할 수 있다. 일 실시예에 따르면, 전자 장 치는 생성된 이미지를 디스플레이 상에 표시할 수 있다. 디스플레이 상에 표시된 생성된 이미지의 일 예에 대하 여는 도 14를 참조하여 이하에서 설명한다. 도 13은 본 개시의 일 실시예에 따른 3D 모델을 이용하여 이미지를 생성하는 절차 내의 3D 모델을 이용한 이미 지 처리 동작의 일 예를 나타낸다. 도 14는 본 개시의 일 실시예에 따른 3D 모델을 이용하여 이미지를 생성하는 절차를 통해 생성된 이미지들의 예를 도시한다. 도 13 및 14의 실시예에서, 3D 모델을 이용하여 이미지를 생성하는 절차는 예컨대, 도 12의 3D 모델을 이용하여 이미지를 생성하는 절차일 수 있다. 도 13의 실시예는 예컨대, 도 12의 동작 12040의 일 예일 수 있다. 도 13을 참조하면, 동작 13010에서, 전자 장치는 3D 모델의 생성 범위에 기초하여, 생성될 이미지의 생성 범위 및/또는 화질 개선 범위를 결정할 수 있다. 동작 13020에서, 전자 장치는 3D 모델에 기초하여, 생성될 이미지에 대한 화질 개선 처리를 수행할 수 있다. 일 실시예에 따르면, 피사체가 사람인 경우, 해당 피사체에 대한 3D 모델의 생성 범위는 예컨대, 얼굴까지의 범 위이거나, 또는 상반신까지의 범위일 수 있으나, 이에 제한되지 않는다. 일 실시예에 따르면, 3D 모델의 생성 범위가 얼굴까지의 범위인 경우, 전자 장치는 생성될 이미지의 생성 범위 및/또는 생성될 이미지의 화질 개선의 대상이 되는 범위를 얼굴까지의 범위로 할 수 있다. 일 예로, 전자 장치 는 3D 모델을 이용하여 얼굴까지 이미지를 생성하고 화질 개선 처리하거나, 상반신까지 이미지를 생성하지만 얼 굴 까지만 화질 개선 처리를 하여 사용자에게 제공할 수 있다. 예컨대, 도 14의 제1 사진에 예시된 것처 럼, 전자 장치는 상반신까지 이미지를 생성하지만 얼굴 까지만 화질 개선 처리(예: 더 밝은 조명 처리)를 하여 사용자에게 제공할 수 있다. 일 실시예에 따르면, 3D 모델의 생성 범위가 상반신까지의 범위인 경우, 전자 장치는 생성될 이미지의 생성 범 위 및/또는 생성될 이미지의 화질 개선의 대상이 되는 범위를 상반신까지의 범위로 할 수 있다. 일 예로, 전자 장치는 3D 모델을 이용하여 상반신까지 이미지를 생성하고 화질 개선 처리하거나, 하반신까지 이미지를 생성하 지만 상반신 까지만 화질 개선 처리를 하여 사용자에게 제공할 수 있다. 예컨대, 도 14의 제2 사진에 예 시된 것처럼, 전자 장치는 상반신까지 이미지를 생성하고, 상반신 까지 화질 개선 처리(예: 더 밝은 조명 처 리)를 하여 사용자에게 제공할 수 있다. 일 실시예에 따르면, 생성된 3D 모델이 없거나, 또는 생성된 3D 모델이 존재하더라도, 해당 3D 모델의 완성도가 임계 값 미만인 경우, 전자 장치는 도 12의 동작 12040(또는, 도 13의 동작 13010 및 13020)을 생략할 수 있다. 일 예로, 전자 장치는 3D 모델을 이용하여 화질 개선 처리되지 않은 이미지를 사용자에게 제공할 수 있다. 예컨 대, 도 14의 제3 사진 및 제4 사진에 예시된 것처럼, 전자 장치는 상반신까지 이미지를 생성하지만, 얼굴 및 상반신에 대한 화질 개선 처리(예: 더 밝은 조명 처리) 없이 사용자에게 제공할 수 있다. 도 15는 본 개시의 일 실시예에 따른, 3D 모델을 이용하는 절차를 나타내는 흐름도이다. 도 16은 본 개시의 일 실시예에 따른, 3D 모델의 보완을 위해 제공되는 촬영 가이드의 일 예를 보여준다. 도 15를 참조하면, 동작 15010에서, 전자 장치(예: 도 1의 전자 장치)는 2D 이미지를 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 편집될 2D 이미지를 획득할 수 있다. 일 실시예에 따르면, 2D 이미지는 사용자에 의해 입력된 이미지일 수 있다. 동작 15020에서, 전자 장치는 2D 이미지에 대한 이미 생성된 3D 모델이 존재하는지 여부를 결정할 수 있다. 일 실시예에 따르면, 2D 이미지에 대한 이미 생성된 3D 모델이 존재하는지 여부를 결정하기 위해, 전자 장치는 2D 이미지에 포함된 피사체에 대한 이미 생성된 3D 모델이 존재하는지 여부를 식별할 수 있다. 3D 모델의 생성/업 데이터 및 생성된 3D 모델의 종류는 예컨대, 도 2 내지 5를 참조할 수 있다. 이에 중복된 설명은 생략한다. 2D 이미지에 대한 이미 생성된 3D 모델이 존재하는 경우, 동작 15040이 수행될 수 있다. 2D 이미지에 대한 이미 생성된 3D 모델이 존재하지 않은 경우, 동작 15080에 수행될 수 있다. 동작 15040에서, 전자 장치는 3D 모델을 표시(또는, 제공)할 수 있다. 예를 들면, 도 16에 예시된 것처럼, 전자 장치는 3D 모델을 디스플레이 상에 표시할 수 있다. 일 실시예에 따르면, 전자 장치는 3D 모델이 이용가능한 수준을 만족하는지 여부를 결정할 수 있다. 일 예로, 3D 모델이 이용가능한 수준을 만족하는지 여부를 결정하기 위해, 동작 15050에서, 전자 장치는 3D 모델의 완성 도(및/또는 정밀도)가 임계 값 이상인지 여부를 식별할 수 있다. 3D 모델의 완성도(및/또는 정밀도)가 임계 값 이상인지 여부를 식별하는 동작은 예컨대, 동작 12030의 설명을 참조할 수 있다. 이에 중복된 설명은 생략한다. 일 실시예에 따르면, 임계 값은 피사체에 대한 3D 모델이 이용 가능한 수준을 만족하는지 여부를 확인하기 위해 미리 설정된 값일 수 있다. 일 실시예에 따르면, 전자 장치는 사용자 입력에 기초하여, 또는 사용자 입력 없이 자체적으로 3D 모델의 완성 도(및/또는 정밀도)가 임계 값 이상인지 여부를 식별할 수 있다. 일 예로, 전자 장치는 3D 모델의 완성도(및/또 는 정밀도)와 관련된 사용자 입력을 수신하고, 사용자 입력에 기초하여 3D 모델의 완성도(및/또는 정밀도)가 임 계 값 이상인지 여부를 식별할 수 있다. 예를 들면, 전자 장치는 3D 모델의 일부(예: 머리의 뒷부분)의 완성도 가 떨어진다는 사용자 입력을 수신하고, 수신된 사용자 입력에 기초하여 3D 모델의 완성도가 임계 값 미만임을 식별할 수 있다. 3D 모델이 이용가능한 수준을 만족하는 경우(예: 3D 모델의 완성도가 임계 값 이상인 경우), 동작 15060이 수행 될 수 있다. 3D 모델이 이용가능한 수준을 만족하지 못하는 경우(예: 3D 모델의 완성도가 임계 값 미만인 경우), 동작 15070이 수행될 수 있다. 동작 15060에서, 전자 장치는 3D 모델을 이용한 2D 이미지의 편집 기능을 제공할 수 있다. 3D 모델을 이용한 2D 이미지의 편집 기능을 통한 2D 이미지 편집 절차에 대한 설명은 도 6 내지 12의 설명을 참조할 수 있다. 이에 중복된 설명은 생략한다. 동작 15070에서, 전자 장치는 3D 모델의 보완(또는, 업데이트)을 위한 촬영 가이드를 제공할 수 있다. 이처럼, 3D 모델이 이용가능한 수준을 만족하지 못하는 경우, 전자 장치는 3D 모델이 이용가능한 수준을 만족하도록, 촬 영 가이드의 제공을 통한, 추가적인 2D 이미지를 요청할 수 있다. 일 실시예에 따르면, 예컨대, 3D 모델의 일부(예: 머리의 뒷부분)의 완성도가 떨어진다는 사용자 입력을 수신하 는 경우, 전자 장치는 수신된 사용자 입력을 분석하여, 3D 모델의 해당 부분을 업데이트(또는, 보완)하기 위한 추가 촬영을 위한 촬영 가이드를 사용자에게 제공할 수 있다. 일 실시예에 따르면, 전자 장치는 3D 모델의 보완을 위한 촬영 가이드를 시각적으로 제공하거나(예: 가이드 문 구를 디스플레이에 표시), 또는 청각적으로 제공(예: 가이드 음성을 제공)할 수 있다. 일 예로, 사용자의 머리 뒷부분에 대한 3D 모델의 완성도 및/또는 정밀도가 떨어지는 경우, 도 16에 예시된 것처럼, 전자 장치는 “사용자의 머리의 뒷부분에 대한 사진을 다양한 각도로 20장 촬영하여 입력해주세요”와 같은 사진 촬영 가이 드을 디스플레이 상에 표시할 수 있다. 이러한 촬영 가이드를 통해 입력(또는, 추가)된 2D 이미지들은 3D 모델을 보완(또는, 업데이트)하기 위해 사용 될 수 있다. 3D 모델의 업데이트 동작은 예컨대, 도 5의 동작 5080의 설명을 참조할 수 있다. 이에 중복된 설명 은 생략한다. 동작 15080에서, 전자 장치는 2D 이미지를 새로운 클러스터 후보군으로 등록할 수 있다. 이처럼, 2D 이미지에 대한 이미 생성된 3D 모델이 존재하지 않는 경우(예: 2D 이미지에 포함된 피사체에 대한 이미 생성된 3D 모델이 존재하지 않는 경우), 전자 장치는 2D 이미지를 새로운 클러스터 후보군으로 등록하고, 해당 클러스터 후보군에 대한 충분한 2D 이미지가 확보되면, 상술한 클러스터링 및 분할 동작을 통해 3D 이미지를 생성할 수 있다. 이에 대하여는 예컨대, 도 5의 동작 5010 내지 5050의 설명을 참조할 수 있다. 이에 중복된 설명은 생략한다. 일 실시예에 따르면, 전자 장치는 메모리, 및 프로세서를 포함할 수 있다. 일 실시예에 따르면, 상기 프로세서는 제1 피사체(subject)와 배경(background)을 포함하는 입력 2차원 (2D) 이미지를 식별할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 입력 2D 이미지를 상기 제1 피사체를 포함하는 제1 피사체 이 미지와 상기 배경을 포함하는 제1 배경 이미지로 분리(separate)할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제1 피사체에 대한 3차원(3D) 모델을 이용하여 상기 제1 피사 체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제1 배경 이미지 내의 피사체 제외 영역 또는 상기 제1 배경 이미지 외부의 확장 영역 중 적어도 하나에 대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배 경 이미지를 생성할 수 있다. 상기 확장 영역은 상기 제1 피사체의 변경과 연관될 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제2 피사체 이미지와 상기 제2 배경 이미지를 합성하여, 출력 2D 이미지를 생성하도록 설정될 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제1 피사체 이미지에 기초하여, 상기 제1 피사체에 대한 이미 생성된 3D 모델을 변형(deform)시킬 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 변형된 3D 모델을 상기 제1 피사체에 대한 상기 3D 모델로 이 용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성할 수 있다. 일 실시예에 따르면, 상기 제1 배경 이미지 내의 상기 피사체 제외 영역에 대한 이미지 처리는, 상기 제1 배경 이미지에 포함된 정보를 기초로 상기 피사체 제외 영역에 배경을 추가하기 위한 인-페인팅(in-painting) 처리를 포함할 수 있다.일 실시예에 따르면, 상기 프로세서는 상기 제1 피사체를 이동(translation)시키기 위한 사용자 입력을 획 득할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 사용자 입력이 획득되는 것에 응답하여, 상기 3D 모델을 이용하여 상기 위치 및 상기 방향을 변경하기 위한 이미지 처리를 수행함으로써, 상기 위치 및 상기 방향이 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성할 수 잇다. 일 실시예에 따르면, 상기 제1 배경 이미지 외부의 상기 확장 영역에 대한 이미지 처리는, 상기 제1 배경 이미 지에 포함된 정보를 기초로 상기 변경된 피사체의 위치와 연관된 확장 영역에 배경을 추가하기 위한 아웃-페인 팅(out-painting) 처리를 포함할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 전자 장치의 내부 저장 장치 또는 상기 전자 장치에 연결된 외부 저장 장치 중 적어도 하나로부터 2D 이미지들을 획득할 수 있다. 일 실시예에 따르면, 상기 프로세 서는 상기 2D 이미지들에 기초하여, 3D 모델이 생성될 적어도 하나의 피사체를 식별할 수 있다. 상기 적어 도 하나의 피사체는 상기 제1 피사체를 포함할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 2D 이 미지들을 상기 식별된 피사체 별로 클러스터링할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제1 피사체의 클러스터에 속하는 2D 이미지들에서 상기 제1 피사체와 상기 배경을 분리함으로써, 상기 배경이 제외 된 상기 제1 피사체를 포함하는 2D 이미지들을 획득할 있다. 일 실시예에 따르면, 상기 프로세서는 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 상기 제1 피사체에 대한 상기 3D 모델을 생성할 수 있다. 일 실시예에 따르면, 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들은, 제1 시점부터 상기 제1 시점 이후의 제2 시점까지의 2D 이미지들에 해당할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들에 포함된 시간 정보를 이용하여, 상기 제1 시점에서 상기 제2 시점 까지의 기간을 식별할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제1 시점에서 상기 제2 시점까 지의 기간을 복수의 시간 구간으로 나눌 수 있다. 일 실시예에 따르면, 상기 프로세서는 각 시간 구간에 속하는 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 시간 구간 별로 상기 제1 피사체에 대한 3D 모델을 각각 생성하도록 설정될 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 시간 구간 별로 생성된 상기 제1 피사체에 대한 복수의 3D 모 델 간의 3D 특징점을 매칭함으로써, 상기 제1 피사체의 시간에 따라 변화하는 모습을 3차원으로 제공할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제1 피사체에 대한 상기 3D 모델의 완성도가 임계 값을 만족하 는지 여부를 식별할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 3D 모델의 완성도가 임계 값 미 만인 것으로 식별되는 경우, 상기 3D 모델의 완성도를 높이기 위하여 상기 제1 피사체에 대한 추가 2D 이미지의 획득을 위한 촬영 가이드를 사용자에게 제공할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제1 피사체에 대한 상기 3D 모델을 디스플레이 상에 표시할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 3D 모델의 상기 완성도와 연관된 사용자 입력을 수신할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 사용자 입력에 기초하여 상기 3D 모델의 완성도가 미 리 설정된 기준을 만족하는지 여부를 식별할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제1 피사체에 대한 적어도 하나의 추가 2D 이미지가 획득되는 것에 기초하여, 상기 제1 피사체에 대한 상기 3D 모델을 업데이트 하도록 설정될 수 있다. 일 실시예에 따르면, 전자 장치의 방법은 제1 피사체(subject)와 배경(background)을 포함하는 입력 2차원 (2D) 이미지를 식별하는 동작을 포함할 수 있다. 상기 방법은 상기 입력 2D 이미지를 상기 제1 피사체를 포함하 는 제1 피사체 이미지와 상기 배경을 포함하는 제1 배경 이미지로 분리(separate)하는 동작을 포함할 수 있다. 상기 방법은 상기 제1 피사체에 대한 3차원(3D) 모델을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하는 동작을 포함할 수 있다. 상기 방법은 상기 제1 배경 이미지 내의 피사체 제외 영역 또는 상기 제1 배 경 이미지 외부의 확장 영역 중 적어도 하나에 대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성하는 동작을 포함할 수 있고, 상기 확장 영역은 상기 제1 피사체의 변경과 연관될 수 있다. 상기 방법은 상기 제2 피사체 이미지와 상기 제2 배경 이미지를 합성하여, 출력 2D 이미지를 생성하도록 설정되 는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 방법은 상기 제1 피사체 이미지에 기초하여, 상기 제1 피사체에 대한 이미 생성된 3D 모델을 변형(deform)시키는 동작을 더 포함할 수 있다. 상기 변경된 제1 피사체를 포함하는 제2 피사체 이미지 를 생성하는 동작은 상기 변형된 3D 모델을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나 를 변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 제1 배경 이미지 내의 상기 피사체 제외 영역에 대한 이미지 처리는, 상기 제1 배경 이미지에 포함된 정보를 기초로 상기 피사체 제외 영역에 배경을 추가하기 위한 인-페인팅(in-painting) 처리를 포함할 수 있다. 일 실시예에 따르면, 상기 방법은, 상기 제1 피사체를 이동(translation)시키기 위한 사용자 입력을 획득하는 동작 및 상기 사용자 입력이 획득되는 것에 응답하여, 상기 3D 모델을 이용하여 상기 위치 및 상기 방향을 변경 하기 위한 이미지 처리를 수행함으로써, 상기 위치 및 상기 방향이 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 제1 배경 이미지 외부의 상기 확장 영역에 대한 이미지 처리는, 상기 제1 배경 이미 지에 포함된 정보를 기초로 상기 변경된 피사체의 위치와 연관된 확장 영역에 배경을 추가하기 위한 아웃-페인 팅(out-painting) 처리를 포함할 수 있다. 일 실시예에 따르면, 상기 방법은, 상기 전자 장치의 내부 저장 장치 또는 상기 전자 장치에 연결된 외부 저장 장치 중 적어도 하나로부터 2D 이미지들을 획득하는 동작; 상기 2D 이미지들에 기초하여, 3D 모델이 생성될 적어도 하나의 피사체를 식별하는 동작, 상기 적어도 하나의 피사체는 상기 제1 피사체를 포함하고, 상 기 2D 이미지들을 상기 식별된 피사체 별로 클러스터링하는 동작; 및 상기 제1 피사체의 클러스터에 속하는 2D 이미지들에서 상기 제1 피사체와 상기 배경을 분리함으로써, 상기 배경이 제외된 상기 제1 피사체를 포함하는 2D 이미지들을 획득하는 동작 및 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 상기 제1 피사체에 대한 상기 3D 모델을 생성하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들은, 제1 시점부터 상기 제1 시점 이후의 제2 시점까지의 2D 이미지들에 해당할 수 있다. 상기 방법은 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들에 포함된 시간 정보를 이용하여, 상기 제1 시점에서 상기 제2 시점까지의 기간을 식별하는 동작, 상기 제1 시점에서 상기 제2 시점까지의 기간을 복수의 시간 구간으로 나누는 동작, 및 각 시간 구간에 속하는 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 시간 구간 별로 상기 제1 피사체에 대한 3D 모델을 각각 생성하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 방법은 상기 시간 구간 별로 생성된 상기 제1 피사체에 대한 복수의 3D 모델 간의 3D 특징점을 매칭함으로써, 상기 제1 피사체의 시간에 따라 변화하는 모습을 3차원으로 제공하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 방법은 상기 제1 피사체에 대한 상기 3D 모델의 완성도가 임계 값을 만족하는지 여부 를 식별하는 동작 및 상기 3D 모델의 ,완성도가 임계 값 미만인 것으로 식별되는 경우, 상기 3D 모델의 완성도 를 높이기 위하여 상기 제1 피사체에 대한 추가 2D 이미지의 획득을 위한 촬영 가이드를 사용자에게 제공하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 방법은 상기 제1 피사체에 대한 상기 3D 모델을 디스플레이 상에 표시하는 동작 상기 3D 모델의 상기 완성도와 연관된 사용자 입력을 수신하는 동작 및 상기 사용자 입력에 기초하여 상기 3D 모델의 완성도가 미리 설정된 기준을 만족하는지 여부를 식별하는 동작을 포함할 수 있다. 상술한 본 개시의 구체적인 실시 예들에서, 본 개시에 포함되는 구성 요소는 제시된 구체적인 실시 예에 따라 단수 또는 복수로 표현되었다. 그러나, 단수 또는 복수의 표현은 설명의 편의를 위해 제시한 상황에 적합하게 선택된 것으로서, 본 개시가 단수 또는 복수의 구성 요소에 제한되는 것은 아니며, 복수로 표현된 구성 요소라 하더라도 단수로 구성되거나, 단수로 표현된 구성 요소라 하더라도 복수로 구성될 수 있다. 한편 본 개시의 상세한 설명에서는 구체적인 실시 예에 관해 설명하였으나, 본 개시의 범위에서 벗어나지 않는 한도 내에서 여러 가지 변형이 가능함은 물론이다. 그러므로 본 개시의 범위는 설명된 실시 예에 국한되어 정해 져서는 아니 되며 후술하는 특허청구의 범위뿐만 아니라 이 특허청구의 범위와 균등한 것들에 의해 정해져야 한 다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들 은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것 이다."}
{"patent_id": "10-2023-0182559", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 다양한 실시예들에 따른, 네트워크 환경 내의 전자 장치의 블록도이다. 도 2는 본 개시의 일 실시예에 따른, 3차원 모델링 절차를 개략적으로 도시한다. 도 3은 본 개시의 일 실시예에 따른, 3D 모델을 생성하는 방법을 나타내는 흐름도이다. 도 4는 본 개시의 일 실시예에 따른, 시간 구간 별로 생성된 3D 모델을 나타낸다. 도 5는 본 개시의 일 실시예에 따른, 3D 모델을 생성 또는 업데이트하는 방법을 나타내는 흐름도이다. 도 6은 본 개시의 일 실시예에 따른, 3D 모델을 이용하여 2D 이미지를 편집하는 절차를 나타내는 흐름도이다. 도 7은 본 개시의 일 실시예에 따른, 3D 모델을 이용한 2D 이미지 편집의 일 예를 나타낸다. 도 8은 본 개시의 일 실시예에 따른, 3D 모델을 이용한 2D 이미지 편집의 일 예를 나타낸다. 도 9는 본 개시의 일 실시예에 따른, 3D 모델을 이용하여 2D 이미지를 편집하는 절차를 나타내는 흐름도이다. 도 10은 본 개시의 일 실시예에 따른, 3D 모델을 이용한 2D 이미지 편집의 일 예를 나타낸다. 도 11은 본 개시의 일 실시예에 따른, 3D 모델을 이용한 2D 이미지 편집의 일 예를 나타낸다. 도 12는 본 개시의 일 실시예에 따른, 3D 모델을 이용하여 이미지를 생성하는 절차를 나타내는 흐름도이다. 도 13은 본 개시의 일 실시예에 따른, 3D 모델을 이용하여 이미지를 생성하는 절차 내의 3D 모델을 이용한 이미 지 처리 동작의 일 예를 나타낸다. 도 14는 본 개시의 일 실시예에 따른, 3D 모델을 이용하여 이미지를 생성하는 절차를 통해 생성된 이미지들의 예를 도시한다. 도 15는 본 개시의 일 실시예에 따른, 3D 모델을 이용하는 절차를 나타내는 흐름도이다. 도 16은 본 개시의 일 실시예에 따른, 3D 모델의 보완을 위해 제공되는 촬영 가이드의 일 예를 보여준다."}
