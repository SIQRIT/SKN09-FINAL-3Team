{"patent_id": "10-2023-0071054", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0172564", "출원번호": "10-2023-0071054", "발명의 명칭": "결정론적 인공 신경망의 출력 불확실성 추정 방법 및 시스템", "출원인": "한국과학기술원", "발명자": "이상완"}}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서를 포함하는 컴퓨터 장치의 출력 불확실성 추정 방법에 있어서,상기 적어도 하나의 프로세서에 의해, 결정론적 인공 신경망 모델의 학습에 사용된 학습데이터와 상기 학습데이터로 학습된 결정론적 인공 신경망 모델의 출력을 결합하여 데이터셋을 생성하는 단계; 및상기 적어도 하나의 프로세서에 의해, 상기 생성된 데이터셋을 통해 학습된 대리 가우시안 프로세스(proxyGaussian process) 모델의 테스트 데이터에 대한 출력에 기반하여 상기 결정론적 인공 신경망 모델의 출력 불확실성을 추정하는 단계를 포함하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 추정하는 단계는,상기 대리 가우시안 프로세스 모델이 출력하는 예측의 분산을 상기 결정론적 인공 신경망 모델의 출력 불확실성으로 추정하는 것을 특징으로 하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 분산은 가우시안 프로세스 모델과 확률적 신경망 모델의 동치성, 커널 회귀 능선 모델과 결정론적 신경망모델의 동치성 및 커널 회귀 능선 알고리즘의 베이지안 해석에 기초하여 상기 결정론적 인공 신경망 모델의 출력 불확실성에 근사하는 것으로 결정되는 것을 특징으로 하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 적어도 하나의 프로세서에 의해, 상기 학습데이터와 상기 학습데이터에 대응하는 정답 레이블을 포함하는제1 학습 데이터셋을 이용하여 상기 결정론적 인공 신경망 모델을 학습하는 단계를 더 포함하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 데이터셋을 생성하는 단계는,상기 학습된 결정론적 인공 신경망 모델의 출력을 임시 출력 레이블로서 상기 학습데이터와 매칭하여 포함하는제2 학습 데이터셋을 생성하는 것을 특징으로 하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 적어도 하나의 프로세서에 의해, 상기 생성된 데이터셋으로 가우시안 프로세스 모델을 학습하여 상기 대리가우시안 프로세스 모델을 생성하는 단계를 더 포함하는 출력 불확실성 추정 방법.공개특허 10-2024-0172564-3-청구항 7 제1항에 있어서,상기 데이터셋을 생성하는 단계는,상기 학습데이터가 이미지 데이터를 포함하는 경우, 행렬 형태의 상기 학습 데이터를 상기 대리 가우시안 프로세싱 모델을 위한 낮은 차원의 벡터 형태의 입력으로 변환하는 단계를 포함하는 것을 특징으로 하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 벡터 형태의 입력으로 변환하는 단계는,상기 학습데이터에 대해 상기 결정론적 인공 신경망 모델의 중간 은닉층에서 추출한 특징 벡터로 상기 대리 가우시안 프로세싱 모델의 학습을 위한 학습데이터를 변환하는 것을 특징으로 하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 데이터셋을 생성하는 단계는,상기 결정론적 인공 신경망 모델의 출력층이 다수의 유닛으로 구성되는 경우, 상기 결정론적 인공 신경망 모델의 복수 카테고리의 출력을 하나의 스칼라로 통합하는 단계를 포함하는 것을 특징으로 하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 통합하는 단계는,상기 결정론적 인공 신경망 모델의 출력을 소프트맥스 함수를 통해 표현되는 벡터로부터 1차원의 단일한 값인엔트로피(entropy)로 변환하여 상기 결정론적 인공 신경망 모델의 복수 카테고리의 출력을 하나의 스칼라로 통합하는 것을 특징으로 하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 결정론적 인공 신경망 모델은 분류 신경망, 회귀 신경망 및 생성 모델 중 적어도 하나를 포함하는 것을 특징으로 하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 추정하는 단계는,상기 결정론적 인공 신경망 모델의 구조 변형 없이 상기 대리 가우시안 프로세스(proxy Gaussian process) 모델의 테스트 데이터에 대한 출력에 기반하여 상기 결정론적 인공 신경망 모델의 출력 불확실성을 추정하는 것을특징으로 하는 출력 불확실성 추정 방법."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨터 장치와 결합되어 제1항 내지 제12항 중 어느 한 항의 방법을 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2024-0172564-4-컴퓨터 장치에서 판독 가능한 명령을 실행하도록 구현되는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서에 의해, 결정론적 인공 신경망 모델의 학습에 사용된 학습데이터와 상기 학습데이터로 학습된 결정론적 인공 신경망 모델의 출력을 결합하여 데이터셋을 생성하고,상기 적어도 하나의 프로세서에 의해, 상기 생성된 데이터셋을 통해 학습된 대리 가우시안 프로세스(proxyGaussian process) 모델의 테스트 데이터에 대한 출력에 기반하여 상기 결정론적 인공 신경망 모델의 출력 불확실성을 추정하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 출력 불확실성을 추정하기 위해, 상기 적어도 하나의 프로세서에 의해, 상기 대리 가우시안 프로세스 모델이 출력하는 예측의 분산을 상기 결정론적 인공 신경망 모델의 출력 불확실성으로 추정하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 분산은 가우시안 프로세스 모델과 확률적 신경망 모델의 동치성, 커널 회귀 능선 모델과 결정론적 신경망모델의 동치성 및 커널 회귀 능선 알고리즘의 베이지안 해석에 기초하여 상기 결정론적 인공 신경망 모델의 출력 불확실성에 근사하는 것으로 결정되는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 적어도 하나의 프로세서에 의해,상기 학습데이터와 상기 학습데이터에 대응하는 정답 레이블을 포함하는 제1 학습 데이터셋을 이용하여 상기 결정론적 인공 신경망 모델을 학습하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 데이터셋을 생성하기 위해, 상기 적어도 하나의 프로세서에 의해,상기 학습된 결정론적 인공 신경망 모델의 출력을 임시 출력 레이블로서 상기 학습데이터와 매칭하여 포함하는제2 학습 데이터셋을 생성하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제14항에 있어서,상기 적어도 하나의 프로세서에 의해,상기 생성된 데이터셋으로 가우시안 프로세스 모델을 학습하여 상기 대리 가우시안 프로세스 모델을 생성하는공개특허 10-2024-0172564-5-것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2023-0071054", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제14항에 있어서,상기 적어도 하나의 프로세서에 의해,상기 학습데이터가 이미지 데이터를 포함하는 경우, 행렬 형태의 상기 학습 데이터를 상기 대리 가우시안 프로세싱 모델을 위한 낮은 차원의 벡터 형태의 입력으로 변환하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "결정론적 인공 신경망의 출력 불확실성 추정 방법 및 시스템을 개시한다. 일실시예에 따른 결정론적 인공 신경 망의 출력 불확실성 추정 방법은 결정론적 인공 신경망 모델의 학습에 사용된 학습데이터와 상기 학습데이터로 학습된 결정론적 인공 신경망 모델의 출력을 결합하여 데이터셋을 생성하는 단계 및 상기 생성된 데이터셋을 통 해 학습된 대리 가우시안 프로세스(proxy Gaussian process) 모델의 테스트 데이터에 대한 출력에 기반하여 상기 결정론적 인공 신경망 모델의 출력 불확실성을 추정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예들은 결정론적 인공 신경망의 출력 불확실성 추정 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기계학습 문제에서 인공 신경망은 출력의 불확실성이 높은 경우가 많다. 우연히 당장 올바른 출력을 하더라도 향후 오차가 증가할 수 있다. 만약 신경망의 불확실성을 추정하고 모델링할 수 있다면, 선제적으로 신경망의 예측 신뢰도를 높이고 효율적인 학습 전략을 수립할 수 있다. 확률적(Probabilistic, Bayesian) 신경망은 불확 실성을 직접 측정할 수 있지만 빅데이터 적용이 어렵다. 반면 빅데이터 학습에 널리 사용되는 결정론적/비확률 적(Non-Bayesian) 인공 신경망의 불확실성을 측정하는 것은 매우 어렵다. [선행문헌번호] 한국등록특허 제10-1456554호"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "기계학습 과제에서 일반적으로 가장 많이 활용되는 결정론적 인공 신경망에 내재된 출력의 불확실성을, 가우시 안 프로세스(Gaussian Process) 모델을 이용하여 간접 추정할 수 있는 출력 불확실성 추정 방법 및 시스템을 제 공한다."}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "적어도 하나의 프로세서를 포함하는 컴퓨터 장치의 출력 불확실성 추정 방법에 있어서, 상기 적어도 하나의 프 로세서에 의해, 결정론적 인공 신경망 모델의 학습에 사용된 학습데이터와 상기 학습데이터로 학습된 결정론적 인공 신경망 모델의 출력을 결합하여 데이터셋을 생성하는 단계; 및 상기 적어도 하나의 프로세서에 의해, 상기 생성된 데이터셋을 통해 학습된 대리 가우시안 프로세스(proxy Gaussian process) 모델의 테스트 데이터에 대한 출력에 기반하여 상기 결정론적 인공 신경망 모델의 출력 불확실성을 추정하는 단계를 포함하는 출력 불확실성 추정 방법을 제공한다. 일측에 따르면, 상기 추정하는 단계는, 상기 대리 가우시안 프로세스 모델이 출력하는 예측의 분산을 상기 결정 론적 인공 신경망 모델의 출력 불확실성으로 추정하는 것을 특징으로 할 수 있다. 다른 측면에 따르면, 상기 분산은 가우시안 프로세스 모델과 확률적 신경망 모델의 동치성, 커널 회귀 능선 모 델과 결정론적 신경망 모델의 동치성 및 커널 회귀 능선 알고리즘의 베이지안 해석에 기초하여 상기 결정론적 인공 신경망 모델의 출력 불확실성에 근사하는 것으로 결정되는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 출력 불확실성 추정 방법은 상기 적어도 하나의 프로세서에 의해, 상기 학습데이 터와 상기 학습데이터에 대응하는 정답 레이블을 포함하는 제1 학습 데이터셋을 이용하여 상기 결정론적 인공 신경망 모델을 학습하는 단계를 더 포함할 수 있다.또 다른 측면에 따르면, 상기 데이터셋을 생성하는 단계는, 상기 학습된 결정론적 인공 신경망 모델의 출력을 임시 출력 레이블로서 상기 학습데이터와 매칭하여 포함하는 제2 학습 데이터셋을 생성하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 출력 불확실성 추정 방법은 상기 적어도 하나의 프로세서에 의해, 상기 생성된 데 이터셋으로 가우시안 프로세스 모델을 학습하여 상기 대리 가우시안 프로세스 모델을 생성하는 단계를 더 포함 할 수 있다. 또 다른 측면에 따르면, 상기 데이터셋을 생성하는 단계는, 상기 학습데이터가 이미지 데이터를 포함하는 경우, 행렬 형태의 상기 학습 데이터를 상기 대리 가우시안 프로세싱 모델을 위한 낮은 차원의 벡터 형태의 입력으로 변환하는 단계를 포함하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 벡터 형태의 입력으로 변환하는 단계는, 상기 학습데이터에 대해 상기 결정론적 인공 신경망 모델의 중간 은닉층에서 추출한 특징 벡터로 상기 대리 가우시안 프로세싱 모델의 학습을 위한 학 습데이터를 변환하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 데이터셋을 생성하는 단계는, 상기 결정론적 인공 신경망 모델의 출력층이 다수의 유닛으로 구성되는 경우, 상기 결정론적 인공 신경망 모델의 복수 카테고리의 출력을 하나의 스칼라로 통합하는 단계를 포함하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 통합하는 단계는, 상기 결정론적 인공 신경망 모델의 출력을 소프트맥스 함수를 통해 표현되는 벡터로부터 1차원의 단일한 값인 엔트로피(entropy)로 변환하여 상기 결정론적 인공 신경망 모델 의 복수 카테고리의 출력을 하나의 스칼라로 통합하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 결정론적 인공 신경망 모델은 분류 신경망, 회귀 신경망 및 생성 모델 중 적어도 하나를 포함하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 추정하는 단계는, 상기 결정론적 인공 신경망 모델의 구조 변형 없이 상기 대리 가우시안 프로세스(proxy Gaussian process) 모델의 테스트 데이터에 대한 출력에 기반하여 상기 결정론적 인공 신경망 모델의 출력 불확실성을 추정하는 것을 특징으로 할 수 있다. 컴퓨터 장치와 결합되어 상기 방법을 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장된 컴 퓨터 프로그램을 제공한다. 상기 방법을 컴퓨터 장치에 실행시키기 위한 프로그램이 기록되어 있는 컴퓨터 판독 가능한 기록매체를 제공한 다. 컴퓨터 장치에서 판독 가능한 명령을 실행하도록 구현되는 적어도 하나의 프로세서를 포함하고, 상기 적어도 하 나의 프로세서에 의해, 결정론적 인공 신경망 모델의 학습에 사용된 학습데이터와 상기 학습데이터로 학습된 결 정론적 인공 신경망 모델의 출력을 결합하여 데이터셋을 생성하고, 상기 적어도 하나의 프로세서에 의해, 상기 생성된 데이터셋을 통해 학습된 대리 가우시안 프로세스(proxy Gaussian process) 모델의 테스트 데이터에 대한 출력에 기반하여 상기 결정론적 인공 신경망 모델의 출력 불확실성을 추정하는 것을 특징으로 하는 컴퓨터 장치 를 제공한다."}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "기계학습 과제에서 일반적으로 가장 많이 활용되는 결정론적 인공 신경망에 내재된 출력의 불확실성을, 가우시 안 프로세스(Gaussian Process) 모델을 이용하여 간접 추정할 수 있다."}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 기계학습 모델은 보통 유한한 개수의 학습데이터로 이루어진 학습 데이터셋(Training dataset)을 이용하여 학습 데이터가 본래 속하는 분포(모분포)를 통계적으로 추정하는 모델을 의미한다. 통계적으로 모분포를 추정하는 방법의 특성상 기계학습 모델은 필연적으로 불확실성에 직면하게 된다. 불확실성이란 기계학습 모델이 학습하 지 않은, 즉 과거에 경험하지 않은 새로운 데이터에 대해 어느 정도의 확신을 가지고 판단하는 지 그 정도를 정 량화한 것이다. 따라서 불확실성이란 기계학습 모델과 데이터마다 다른 값을 갖는 스칼라값으로 정의된다(즉 불확실성은 모델과 데이터에 의존하는 함수로 해석할 수 있다). 기계학습 모델의 불확실성은 그 발생 기원에 따라 다양한 형태로 정의할 수 있지만 실용적으로 크게 2가지 종류 로 구분할 수 있다. 첫 번째로 데이터 자체의 원인에 의한 불확실성(aleatoric uncertainty)이 있다. 데이터 자체에 혼입되어 있는 노이즈에 의하여 데이터가 속한 모분포를 정확하게 파악하기 어렵거나 데이터를 획득하는 과정에서 필연적으로 야기되는 관측적 한계로 인하여 발생하는 불확실성이다. 데이터에 의한 불확실성은 데이 터를 획득한 이후에는 제거할 수 없는 본질적인 특성이다. 두 번째로 기계학습 모델의 원인으로 인해 발생하는 불확실성(epistemic uncertainty)이 있다. 모델에 의한 불확실성은 추정하고자 하는 특정 국소 분포에 위치하 는 학습데이터가 부족하거나 학습 알고리즘의 불완전성에 의하여 데이터를 통한 모분포를 바르게 추정하지 못할 때 발생한다. 모델에 의한 불확실성은 베이지안(Bayesian) 불확실성이라고도 하며 학습데이터를 추가로 확보하 거나 학습 알고리즘의 개선 등에 의해서 어느 정도 극복할 수 있다는 점에서 불확실성 연구의 주요한 관심 분야 이다. 본 발명의 실시예들에서는 편의상 두 종류의 불확실성을 출력 불확실성으로 통칭한다. 실용적으로 특정 데이터에 대한 특정 기계학습 모델의 불확실성을 알 수 있다면 해당 데이터에 대한 예측을 어 느 정도로 신뢰할 수 있을 지 결정할 수 있다. 특히 모델에 의한 불확실성의 경우 제한된 자원의 학습 환경에 서 기계학습 모델의 최적 학습 전략을 수립하기 위한 정보를 제공한다. 예를 들어 의사를 대신하여 의료 데이 터를 판독하는 기계학습 모델의 경우 입력받는 데이터의 예측 불확실성을 판단함으로써 자신(모델)의 예측을 신 뢰하여 직접 최종 결정을 내릴 지 또는 오라클(의사 등 전문가)에게 추가적인 판단을 의뢰할 지 결정할 수 있다. 그러나 전통적으로 기계학습 모델의 출력 불확실성을 정량화하는 것은 커다란 난제로 알려져 있다. 대부분의 기계학습 모델은 동작 특성상 베이지안 예측 분포를 고려하지 않는 결정론적 매개변수로 데이터의 모분포를 나 타내기 때문이다. 다시 말해, 하나의 입력에 대해 모델은 하나의 기대값이 가장 높은 고정된 값만을 출력하므 로 학습 상태에 따라 나타날 수 있는 다양한 출력의 범위를 알기 어렵다. 이와 반대로 특별히 베이지안 불확실 성을 직접 측정할 수 있도록 설계된 모델들을 베이지안 모델 또는 확률적 모델이라고 한다. 다시 말해, 하나의 동일한 입력에 대해서도 모델은 확률적으로 다른 출력이 샘플링되므로 여러 번 샘플링을 시도하면 출력이 나타 날 수 있는 범위를 추정할 수 있다. 이 범위가 클 수록 출력 불확실성이 높다고 해석이 가능하다. 그러나 확률 적으로 출력을 표현할 수 있는 모델들은 일반적으로 다루기가 매우 어렵고 학습 과정이 복잡하여 실용적으로는사용되지 않는 경향이 있다. 실제 세계의 데이터들은 매우 복잡한 비선형 분포에서 정의되고 있으므로 복잡한 비선형성을 충분히 표현할 수 있는 심층 인공 신경망 모델이 현대 기계학습 문제에서 가장 많이 활용되고 있으 나 대부분의 실용 심층 신경망 모델은 결정론적 모델(일례로, 비베이지안 모델)이다. 다시 말해, 대부분의 실 용적인 고차원 기계학습 모델은 직접 출력 불확실성을 측정하기 어려운 중대한 한계가 있다. 앞서 설명한 바와 같이, 본 발명의 실시예들은 결정론적 심층 인공 신경망의 출력 불확실성을 근사적으로 추론 하는 새로운 방법론을 다룬다. 기존의 방법론에서 해소하기 어려운 문제점들을 해결하여 불확실성 추정의 효율 성을 높일 수 있다. 본 발명의 실시예들에서 해결하고자 하는 과제를 다룬 기존 기술의 개요와 문제점은 다음 (a) 내지 (d)와 같다. (a) 다수의 독립적인 결정론적(비베이지안) 신경망 모델을 학습하여 획득한 앙상블(ensemble)의 예측 분산을 추 정 불확실성으로 취급하는 기술이 있다. 각각의 신경망 모델은 교차 검증(cross-validation) 방식으로 학습하 거나 초매개변수(hyperparameter)를 달리하는 방법으로 학습함으로써 데이터에 대한 다양한 표현 양식을 추상화 할 수 있게 된다. 따라서 개별 모델들의 예측 결과가 상이할수록 앙상블의 예측 불확실성은 높다고 해석할 수 있다. 그러나 앙상블 모델을 생성하기 위해서는 다수의 개별 모델을 생성하여야 하므로 단일 모델에 비해 상당 한 계산 비용(cost)이 발생하고 개별 모델 자체의 불확실성을 추정하는 과제와는 본질적으로 문제의 성질이 다 르므로 모델 자체의 성능 개량에 적용하기 어렵다. (b) 확률적 신경망은 신경망 모델을 구성하는 매개변수를 고정된 값이 아닌 확률분포로 표현하는 신경망 알고리 즘이다. 즉 데이터에 대한 모델의 예측 또한 확률적으로 표현하므로 부수적으로 출력(베이지안) 불확실성을 함 께 나타낼 수 있다. 그러나 확률적 신경망 모델은 계산에 방대한 컴퓨팅 자원이 요구되므로 대규모의 모델에 사용하기 어렵다. (c) 확률적 신경망의 계산 소요량을 낮추면서 베이지안 추론이 가능하게 하는 일종의 근사적 베이지안 신경망 모델에 대한 연구가 활발하게 수행되고 있다. 대표적으로 신경망의 학습과 추론 단계에서 모두 일정한 확률로 신경망 내부의 연결을 무작위 차단하는 몬테카를로(Monte-Carlo) 드롭아웃(Dropout) 기법을 적용하는 방법이 있 다. 그러나 드롭아웃을 적용한 신경망 모델은 여전히 모델의 규모가 커질 경우 학습 자체가 어렵다는 단점이 있다. (d) 그 밖에 신경망의 출력 오차(loss)를 일종의 불확실성으로 보고 특정 신경망 모델의 오차를 학습하는 별도 의 신경망을 두는 방식 등이 제안되었다. 그러나 이와 유사한 상당수의 신경망 불확실성 추정 방식은 불확실성 추정만을 위하여 목표로 하는 신경망의 변형이나 추가적인 요소 도입을 필요로 하므로 신경망 모델의 본래 설계 성능이나 기능의 변형을 일으킬 위험이 있다. 기계학습 문제에서 인공 신경망 모델의 출력 불확실성을 모델링하고 정량화하는 것은 신경망의 학습 전략 수립 과 예측의 신뢰성을 평가하기 위해 매우 중요하다. 본 발명의 실시예들에서는 결정론적 인공 신경망(Non- Bayesian 모델이라고도 하며 동일한 값을 입력할 때 항상 동일한 값을 출력하는 가장 일반적인 형태의 신경망 모델)에서 발생하는 직접 추정하기 어려운 출력 불확실성을 가우시안 프로세스 모델을 이용하여 추정할 수 있는 새로운 방법론을 다룬다. 본 발명의 실시예들에 따른 결정론적 신경망의 불확실성 추정 방법 및 시스템은 다음의 성질에 기반하여 개발되 었다. 확률적 인공 신경망 모델은 가우시안 프로세스 모델과 동치로 해석할 수 있다. 결정론적(비확률적) 인공 신경망 모델은 커널 회귀 능선(Kernel Ridge Regression, KRR) 모델과 동치로 해 석할 수 있다. 앞선 의 커널 회귀 능선 모델의 출력 불확실성은 해당 커널 회귀 능선 모델과 동일한 커널과 학습데이터 를 사용하여 생성되는 의 가우시안 프로세스 모델의 출력 분산(variance)과 동일하다. 상술한 성질 내지 을 통합하면, 결정론적 신경망에 내재된 출력 불확실성은 해당 결정론적 신경망을 근 사하는 가우시안 프로세스 모델을 생성함으로써 추정할 수 있다. 그러나 실제로는 신경망 모델을 구성하는 커널 함수와 가우시안 프로세스 모델을 구성하는 커널 함수는 다른 형 태로 정의되므로, 해석적인 방식으로 원본 신경망을 근사하는 가우시안 프로세스 모델을 생성하기는 어렵다. 본 발명의 실시예들에서는 결정론적 인공 신경망 모델을 학습(training)하고 학습에 사용된 학습데이터 X와 학 습된 모델이 X에 대해 출력하는 출력 Y를 짝지어 만든 데이터셋 D를 통해 생성(학습)한 가우시안 프로세스 모델 이 출력하는 예측의 분산은, 비록 가우시안 프로세스 모델의 커널 함수가 신경망모델에 내재된 커널 함수와 다 르더라도, 원본 인공 신경망 모델에 내재된 출력 불확실성(Bayesian uncertainty)을 근사화 하는 것이라는 결론 에 이른다. 이처럼, 본 발명의 실시예들은 임의의 결정론적 신경망 모델을 가우시안 프로세스 모델(불확실성 표현이 가능하 면서도 간단한 형태를 가지는 메타(meta) 모델의 일종)로 근사함으로써, 해당 결정론적 신경망의 불확실성을 간 접적으로 추론할 수 있다. 도 1은 본 발명의 일실시예에 있어서, 원본 신경망 모델을 모사하는 가우시안 프로세스 모델의 동작 알고리즘의 예를 도시한 도면이다. 본 실시예에 따른 가우시안 프로세스를 이용하여 결정론적 신경망의 출력 불확실성 출 력 불확실성 추정 방법은 아래 1) 내지 4)와 같다. 1) 불확실성을 추정하고자 하는 목표 신경망(비확률적 결정론적 신경망) 모델을 학습 데이터셋(Training Dataset) D를 사용하여 학습시킬 수 있다. 이때, 학습 데이터셋 D는 데이터셋 X와 정답 레이블셋 Y 로 구성될 수 있다. 목표 신경망 모델은 도 1의 실시예에서 분류를 위한 신경망(Neural Networks for classification, 120)에 대응할 수 있다. 2) 학습 진행 중 별도의 검증 데이터셋을 통해 과적합(overfitting)이 발생하기 시작하는 지점 정도에 이른 목 표 신경망 모델에서 학습 데이터셋 D에 대한 출력을 얻어 임시 출력 레이블셋 Y*를 얻을 수 있다. 3) X와 Y*을 매칭하여 학습 데이터셋 D*를 구성하고 학습 데이터셋 D*을 사용하여 임의의 커널 함수 를 도입하여 별도의 가우시안 프로세스 모델을 생성(학습)할 수 있다. 이때, 생성된 가우시안 프로세스 모델을 대리 가우시안 프로세스(Proxy Gaussian Process, proxy GP) 모델이라고 명명하기로 한다. 4) 새로운 테스트 데이터셋이 포함하는 데이터셋 x*에 대해 목표 신경망 모델이 직접 표현하지 못하는 목 표 신경망 모델의 출력 불확실성은 별도로 생성한 가우시안 프로세스 모델이 데이터셋 x*에 대해 출력하는 예측의 분산(Predictive variance, EU for x*)으로 대체하여 추정할 수 있다. 상술한 1) 내지 4)의 절차는 일반적인 절차를 기술한 것으로서 특수한 사례에서는 다음과 같이 변형된 절차가 적용될 수 있다. 이미지와 같은 데이터는 고차원으로 계산 비용이 크게 발생할 뿐만 아니라 행렬(matrix) 형태 이므로 대리 가우시안 프로세스 모델이 직접 입력 받아 처리하기 어렵다. 그러므로 차원이 낮은 벡터 (vector) 형태의 입력으로 변환할 필요가 있다. 이때 목표 신경망 모델에 입력하는 X의 원본 행렬이 아닌 X에 대한 목표 신경망 모델의 중간 은닉층에서 추출한 특징 벡터(feature vector)로 대리 가우시안 프로세 스 모델을 생성할 수 있다. 이는 중간 은닉층에서 획득한 특징 벡터는 입력층의 행렬이 갖는 정보를 대부 분 반영하고 있다는 가정에서 유도되며 극단적으로 입력 행렬과 특징 벡터는 일대일 대응으로 간주할 수 있다는 전제를 가정한다. 출력층이 다수의 유닛으로 구성되는 (대표적으로 분류 신경망) 결정론적 심층 신경망은 신경 망 전체의 불확실성을 다루기 위해 추가적인 가정이 필요하다. 그 이유는 다수의 출력 유닛으로 구성된 신경망 은 각 개별 출력 유닛을 기준으로 그 개별 유닛에서 입력층에 이르는 방향으로 각각 개별적인 커널 회귀 능선 모델이 정의될 수 있기 때문이다. 예를 들어 M개의 카테고리로 분류하는 일반적인 분류 신경망은 M개의 출력 유닛을 가지고 있으므로 M개의 독립적인 커널 회귀 능선 모델이 있다고 가정된다. 이는 하나의 단일 신경망의 불확실성을 하나의 대리 가우시안 프로세스 모델을 사용하여 근사하고자 하는 발명 목표를 달성하기 어렵 다. 이때 다수의 출력 유닛을 가진 신경망의 출력을 하나의 스칼라로 통합하는 커널을 정의할 경우 신경망 모 델 전체 단위를 하나의 스칼라값을 출력하는 신경망 모델로 취급할 수 있다. 예를 들어 다수의 출력 유닛을 갖 는 분류 신경망의 출력은 소프트맥스 함수를 거쳐 표현되는 벡터(simplex)로부터 1차원의 단일한 값인 엔트로피 (entropy)로 변환할 수 있다(cross-entropy와는 다른 개념). 분류 신경망의 최종 출력부터 계산되는 엔트로피 가 데이터 자체의 불확실성(aleatoric uncertainty)을 나타낸다는 점에서 분류 신경망 모델은 데이터의 불확실 성을 단일 스칼라로 출력하는 하나의 회귀 모델로 간주할 수 있다. 이때 입력데이터 X와 출력 엔트로피를 Y*로 취급하면 원본 신경망 전체의 출력 불확실성을 추정할 수 있는 대리 가우시안 프로세스 모델을 쉽게 생성 할 수 있다. 본 발명의 실시예들에 대한 배경이 되는 기초 기술은 다음 (a 내지 (c와 같다. 도 2는 본 발명의 일실시예에 있어서, 확률적(베이지안) 신경망 모델(Bernouli Dropout Neural Networks로 표기)과 가우시안 프로세스, 결정 론적(비베이지안) 신경망 모델과 커널 회귀 능선의 관계의 예를 도시한 도면이다. (a 가우시안 프로세스(Gaussian process) 모델과 확률적(베이지안) 신경망 모델의 동치성 가우시안 프로세스(Gaussian process)는 임의의 데이터 집합이 있을 때 이 집합에 대하여 결합 가우시안 분포를 따르는 확률변수의 집합을 의미한다. 커널(kernel)의 도입을 특징으로 하는 랜덤 과정(random process) 알고리 즘의 일종으로서 특정 함수 자체를 확률적으로 표현할 수 있는 대표적인 비모수(non-parametric) 기계학습 알고 리즘으로 알려져 있다. 가우시안 프로세스에 의해 생성된 모델은 특정 예측의 평균과 분산(variance)을 표현할 수 있는 대표적인 확률적(베이지안) 기계학습 모델이다. 이와 달리 대표적인 모수(parametric) 기계학습 알고 리즘인 신경망은 생물학적 신경 세포의 연결구조를 모방하여 설계되었으며 높은 비선형성을 표현할 수 있어 현 대 기계학습의 대표적인 알고리즘이다. 신경망과 가우시안 프로세스는 그 접근 방식과 성질이 전혀 다른 독립 적인 알고리즘으로 알려졌으나 최근의 연구에 의하면 매개변수를 확률적으로 표현하는 베이지안 신경망은 특정 한 조건에서 가우시안 프로세스와 동치라는 사실이 밝혀졌다. 즉 확률적(베이지안) 신경망 모델은 그 구조가 다층의 은닉층으로 구성된 복잡한 형태라고 하더라도 하나의 거대한 가우시안 프로세스 모델과 동등한 구조적 특성과 기능적 요소를 갖추고 있다. 이와 같은 배경에 의하면 하나의 가우시안 프로세스 모델은 이론적으로 베 이지안 신경망 알고리즘으로 신경망 모델로 변환할 수 있으며 그 반대의 변환도 가능하다고 할 것이다. 보다 구체적으로, 하나의 확률적(베이지안) 신경망 모델이 가우시안 프로세스 모델과 동치임을 증명하는 과정은 이미 공개되었다. 그러나 해당 연구에서는 다수의 출력 유닛을 갖는 신경망(일례로, 분류 신경망)의 경우 출력 유닛을 기준으로 각각 독립적인 가우시안 프로세스 모델을 유도하고, 전체 신경망 모델을 하나의 다변량 가우시 안 프로세스로 모델링하였다. 본 발명의 실시예들에서는 해석 관점을 달리하여 다수의 출력 유닛을 갖는 신경 망 모델인 분류 신경망을 기준으로 출력을 하나의 스칼라로 통합하는 커널을 정의함으로써 분류 신경망 모델을 하나의 단변량 가우시안 프로세스로 모델링할 수 있다. 아래 수학식 1은 K개의 유닛을 가진 단일 은닉층 신경 망 모델에서 두 입력 벡터 xe와 xf에서 가우시안 프로세스 모델에 대응하는 커널 함수를 정의하고 있다. 수학식 1"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이때 w(k)는 k번째 은닉 유닛의 연결 가중를 의미하며, bk는 k번째 은닉 유닛의 편차값을 의미할 수 있다. 함수 g()는 비선형 변환 함수로서 신경망 알고리즘에서 통상적으로 사용되는 ReLu, Tanh 등의 활성 함수가 g()에 해 당될 수 있다. 이때 w의 집합인 은닉층을 첫 번째 은닉층이라는 의미의 숫자 1을 첨자로 병기하여 단일 은닉층 의 출력 Y의 분포를 나타내면 다음 수학식 2와 같이 나타낼 수 있다. 수학식 2"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이때 X는 전체 학습 데이터셋을, σ는 정밀도를 표현하는 매개변수를 각각 의미할 수 있다. 은닉층의 말단에 D 개의 유닛으로 구성하는(즉, D개의 클래스로 분류하는 분류 신경망의) 출력층이 있을 경우, 출력을 단일 스칼라 로 표현하기 위한 커널은 다음 수학식 3과 같은 예시로 정의할 수 있다. 다만, 단일 스칼라로 표현할 수 있다 면 다양한 변형적인 커널의 정의가 가능하다.수학식 3"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이때 w2는 출력층에 해당하는 유닛의 연결 가중치다. 최종 출력을 가우시안 프로세스로 모델링한 최종 출력 Y를 정의하는 수식은 다음 수학식 4와 같다. 수학식 4"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "(b 커널 회귀 능선(Kernel Ridge Regression, KRR) 모델과 결정론적 신경망 모델의 동치성 커널 회귀 능선은 선형 회귀 분석 알고리즘에서 입력으로 받는 변수를 커널(kernel) 함수에 의해 매핑함으로써 비선형적 회귀 분석을 얻는 기계학습 알고리즘이다. 커널 회귀 능선 모델은 결정론적 학습 모델로서 특정한 입 력에 대해서 기대값(likelihood)이 가장 높은 하나의 값(expectation)을 출력한다. 커널 회귀 능선 모델은 앞 서 과 유사한 과정으로 유도하면 결정론적(non-Bayesian) 신경망 모델과 동치임을 알 수 있다. 따라서 하나 의 커널 회귀 능선 모델은 이론적으로 결정론적(비베이지안) 신경망 모델로 변환 표현할 수 있으며 그 반대의 변환도 가능하다고 할 것이다. 커널 회귀 능선 알고리즘은 일반 선형 회귀 알고리즘에서 학습 데이터의 입력 부분을 커널 함수로 치환함으로써 유도될 수 있다. 수학식 5"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 β는 K차원의 벡터이고, φ는 커널을 의미할 수 있다. 학습 데이터가 N개 존재할 때 N×K 차원의 행렬 을 도입함으로써 최적화 방법 등으로 β 근사한 를 우드버리(Woodbury) 행렬 근사와 매개변수 λ를 통해 다음 수학식 6과 같이 표현할 수 있다. 수학식 6 행렬 곱셈 방법을 통해 새로운 데이터 x*에 대한 커널 회귀 능선 모델의 예측 출력 y*는 다음 수학식 7과 같이 정리될 수 있다. 수학식 7"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "만일 두 입력 벡터 xe와 xf에 대한 커널 함수를 아래 수학식 8과 같이 정의할 경우, 수학식 8"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "y*는 다음 수학식 9와 같이 정리될 수 있다. 수학식 9"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "앞서 가우시안 프로세스의 베이지안 신경망과의 동치성을 보이기 위해 정의한 방법으로 커널 함수를 정의할 경 우 수학식 7과 수학식 8에 다음 수학식 10의 커널 함수를 치환할 수 있다. 이 경우 하나의 결정론적 신경망 모 델은 커널 회귀 능선 모델로 치환가능함을 알 수 있다. 수학식 10"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "(c 커널 회귀 능선 알고리즘의 베이지안 해석 가우시안 프로세스와 커널 회귀 능선 알고리즘은 각각 상이한 과정을 통해 유도되었으나 커널 함수에 의한 입력 변수의 매핑을 통해 새로운 입력에 대한 예측(모델의 출력)을 회귀 방법으로 나타낸다는 공통점이 있다. 나아 가 동일한 커널 함수와 동일한 학습데이터로 정의되는 가우시안 프로세스 모델의 평균 예측 출력(mean prediction)과 커널 회귀 능선 최종 출력(expectation)은 동일하다는 중요한 성질이 있다. 이를 통해 커널 회 귀 능선 모델의 출력(Bayesian) 불확실성은 동일한 커널 함수와 동일한 학습데이터에 의해 정의된 가우시안 프 로세스 모델의 예측 분산과 같다는 해석이 가능하다. 가우시안 프로세스 모델과 확률적 신경망 모델은 커널 함수(공분산 함수)에 의해 학습 데이터와 테스트 데이터 (학습에 사용되지 않은 예측을 위한 새로운 데이터)의 관계를 표현한다는 점에서 동치성을 갖는다. 그러나 두 알고리즘은 최적의 모델을 생성하기 위한 방법론적 절차에서 차이가 있다. 가우시안 프로세스는 N개의 학습데 이터로 모델을 학습할 경우 N×N의 크기를 갖는 커널 함수 행렬의 행렬 연산을 통해 최종 모델을 생성한다. 반 면 신경망 모델은 미분가능한 목적 함수에 대해 확률적 경사 하강법을 통해 최적해를 근사적으로 찾아 모델을생성한다. 신경망 모델의 학습 특성상 동적인 학습이 진행될수록 과적합(overfitting)의 가능성도 높아진다. 도 3은 본 발명의 일실시예에 있어서, 확률적(베이지안) 신경망 모델의 단계 0부터 단계 3까지의 학습 동역학 예시를 도시한 도면이다. 본 실시예에서는 분류를 위한 확률적 신경망을 데이터의 불확실성(스칼라)을 출력하 는 단일 신경망 모델로 취급하였을 때의 학습 과정 별 출력분포를 나타낸다. 신경망 모델이 학습(생성)되는 과 정에서 한 학습 단위(epoch)가 진행되는 단계에 따라 단계 0부터 단계 3까지 4 단계로 모델의 특성을 구분할 수 있다. 단계 0(phase 0)은 학습 초기 상태의 신경망 모델로서 학습 데이터(점으로 표기된 데이터 영역)와 테스트 데이 터 모두 평균적인 데이터의 불확실성(aleatoric uncertainty, 모델의 최종 출력)이 높은 값으로 나타난다. 음 영으로 표기된 부분은 출력의 분산으로서 샘플링되는 매개변수에 따라 출력값이 될 수 있는 유의미한 범위를 의 미하며 동시에 모델의 베이지안 불확실성(epistemic uncertainty)을 나타낸다. 즉 단계 0에서는 대부분의 영역 에서 데이터 자체의 불확실성과 모델의 불확실성이 높게 나타난다. 단계 1(phase 1)에서는 학습이 진행됨에 따라 신경망의 출력인 데이터의 불확실성이 실제의 값에 가깝게 나타나 며, 모든 영역에서 모델의 불확실성도 발생하지만 학습 데이터에 대한 모델 불확실성은 상대적으로 감소한다. 단계 2(phase 2)에서는 이론적인 적합 학습(well fitting)상태를 의미하는 것으로 이상적으로 학습이 진행되었 을 경우 학습 데이터의 모델 불확실성은 0으로 감소하고 테스트 데이터에 대한 모델 불확실성만이 측정된다. 그러나 실제로는 단계 2를 거치지 않고 과적합을 의미하는 단계 3으로 진행되므로 단계 2는 가상의 상태라고 할 수 있다. 단계 3(phase 3)에서는 과적합이 발생하여 학습데이터의 불확실성이 0에 가까워진다. 그 이유는 학습이 진행될 수록 학습데이터 자체에 과적합이 일어나 엔트로피가 측정되지 않기 때문이다. 다음으로 단계 1이 대리 가우시안 프로세스 모델을 학습하기 가장 적절한 상태임을 설명하고자 한다. 현실적인 시나리오에서 단계 1이 과적합이 발생하기 전 단계의 학습 상태로 간주할 수 있으며, 이때 관찰되는 학습 데이 터의 모델 불확실성을 인식적 노이즈(epistemic noise)라고 명명하였다. 가우시안 프로세스 모델을 정의할 때 학습데이터는 베이지안 방법론으로 복원하고자 하는 모함수(원본 함수)에서 샘플링된 데이터로 간주될 수 있다. 이 학습데이터의 레이블에는 원본 함수의 실제 출력에서 무작위 노이즈가 추가되어 있다고 가정되므로 가우시안 프로세스는 결국 무작위 노이즈를 고려한 원본 함수를 확률적으로 모델링하는 알고리즘으로 이해할 수 있다. 이 같은 견지에서 확률적 신경망의 인식적 노이즈는 대리 가우시안 프로세스 모델에서 학습데이터의 노이즈에 대응될 수 있고, 이 치환에 의하여 원본 베이지안 신경망의 불확실성을 가장 근사할 수 있는 대리 가우시안 프 로세스 모델을 생성할 수 있다. 학습데이터와 테스트 데이터는 본래 동일한 분포에서 샘플링된 것이므로 단계 1에서는 학습데이터와 테스트 데이터에 대한 원본 베이지안 신경망 모델의 평균 출력 분포는 유사하게 나타난다. 그러나 단계 3과 같이 과적합이 발생한 모델에서는 두 데이터셋에 대한 출력 평균이 달라진다. 따 라서 단계 1을 넘어선 단계에서 학습데이터와 그에 출력값으로 생성한 데이터셋(일례로, 학습 데이터셋 D*)을 사용하여 학습한 대리 가우시안 프로세스 모델은 테스트 데이터에 대한 원본 신경망의 불확실성을 올바르게 근사하기 어렵다. 본 발명은 다양한 형태의 신경망 모델에 직접 적용될 수 있으나 이하에서는 대표적인 4가지의 실시예를 도면과 함께 설명한다. 분류 신경망의 예측 정확도 검증 도 4 내지 도 11은 본 발명의 일실시예에 있어서, 결정론적 CNN 모델에서 생성한 가우시안 프로세스 모델의 예 측 불확실성에 따른 테스트 데이터의 원본 CNN 모델에서의 실제 오차(Loss)와 정확도(Accuracy)의 예를 도시한 그래프들이다. 각각 SVHN 데이터셋과 CIFAR10 데이터셋 중 무작위로 선택한 1,000개 및 2,500개의 학습 데이터 셋을 이용하여 VGG13및 4층(layer) CNN 모델을 학습하였다(총 2Х2Х2=8개 모델 생성). 각각의 모델에 대해 대 리 가우시안 프로세스 모델을 생성하였고, 테스트 데이터셋을 가우시안 프로세스 모델에 입력하여 원본 신경망 모델에 대한 불확실성을 추정하였다. 테스트 데이터셋을 추정된 불확실성을 기준으로 오름차순으로 정렬하여 10% 단위로 10개의 그룹으로 나누어 재분류하였다. 재분류된 10개 그룹의 세부 테스트 데이터셋을 원본 신경망 모델에 입력하여 정답과의 대조를 통해 구한 평균 오차(loss)와 평균 정확도(Accuracy)를 비교하였다. 그 결과 도 4 내지 도 11의 그래프들에서와 같이 불확실성이 높게 예측 될수록 오차가 커지고 정확도가 낮아지는 경향이 명확하게 나타났다.회귀 신경망의 예측 정확도 검증 도 12 내지 도 15는 본 발명의 일실시예에 있어서, 결정론적 CNN 회귀 모델에서 생성한 가우시안 프로세스 모델 의 예측 불확실성에 따른 테스트 데이터의 원본 CNN 모델에서의 실제 오차(Loss)의 예를 도시한 그래프들이다. UTKface 얼굴 데이터셋 (레이블은 인물의 나이) 중 무작위로 선택한 1,000개 및 2,500개의 학습 데이터셋을 이 용하여 VGG13및 4층 CNN 회귀 모델(출력 유닛이 1개)을 학습하였다(총 2×2=4 개 모델 생성). 각각의 모델에 대해 대리 가우시안 프로세스 모델을 생성하였고, 테스트 데이터셋을 가우시안 프로세스 모델에 입력하여 원본 신경망 모델에 대한 불확실성을 추정하였다. 테스트 데이터셋을 추정된 불확실성을 기준으로 오름차순으로 정 렬하여 10% 단위로 10개의 그룹으로 나누어 재분류하였다. 재분류된 10개 그룹의 세부 테스트 데이터셋을 원본 신경망 모델에 입력하여 정답과 대조하여 얻은 평균 오차(loss)와 비교하였다. 그 결과 도 12 내지 도 15에서 와 같이 불확실성이 높게 예측 될수록 오차가 커지는 경향이 나타났다. 능동 학습(active learning) 도 16은 본 발명의 일실시예에 있어서, 결정론적 CNN 모델에서 생성한 가우시안 프로세스 모델의 예측 불확실성 에 따라 학습데이터를 선택하는 능동 학습(active learning)과 다른 알고리즘에 의해 선택하는 능동 학습을 비 교한 예를 도시한 그래프들이다. 각각 SVHN 데이터셋과 CIFAR10 데이터셋에서 500개의 초기 학습데이터를 무작 위 선택하여 VGG16 모델을 생성하였다(총 2개 모델 생성). 각각의 모델에 대해 대리 가우시안 프로세스 모델을 생성하였고, 남은 후보 학습 데이터셋을 가우시안 프로세스 모델에 입력하여 원본 신경망 모델에 대한 불확실성 을 추정하였다. 이후 가장 불확실성이 높게 예측된 학습데이터 200개를 단위로 반복적으로 학습 풀에 추가하는 방식으로 능동 학습(active learning)을 수행하였다. 본 발명의 실시예들에 따른 능동 학습을 수행한 경우가 다른 능동 학습 알고리즘에 의해 능동 학습을 수행한 경우에 비해 유의하게 높은 능동 학습 성능을 달성하였다. 생성 모델에서의 적용 도 17은 본 발명의 일실시예에 있어서, 결정론적 VAE 생성 모델에서 추출한 잠재 벡터(latent vector)의 원본 VAE모델의 가우시안 프로세스 모델의 예측 불확실성에 따른 이미지 생성 결과를 비교한 예를 도시한 도면이다. 4개의 은닉층으로 구성된 생성 모델인 변분 자동 부호화기(Variational Autoencoder)를 구현하고 잠재 노이즈 벡터(noise vector)를 추출하는 은닉층부터 최종 출력층까지의 부분 모델을 대리 가우시안 프로세스로 근사하였 다. 원본 VAE 모델에서 임의의 노이즈를 추출하고 대리 가우시안 프로세스 모델에 입력한 결과 불확실성이 높 은 벡터와 낮은 벡터에서 각각 희미한 이미지와 뚜렷한 이미지가 생성되었다. 즉 생성 모델에서도 이미지를 생 성하기 위한 노이즈의 불확실성을 대리 가우시안 프로세스 모델로 추정할 수 있음을 보였다. 본 발명의 실시예들은 다음과 같은 특징을 가질 수 있다. - 메타 모델 : 기계학습 등 통계적 예측을 위해 생성된 모델을 다시 근사하는 모델을 메타 모델이라고 한다. 본 발명의 실시예들은 원본 모델의 불확실성을 근사하기 위해 메타 모델을 통해 접근한 독창적인 방법론이다. 뿐만 아니라 본 발명의 실시예들은 직접 불확실성을 측정하기 어려운 결정론적 신경망 모델을 확률적 모델로 근 사함으로써 원본 신경망의 숨겨진 불확실성을 합리적 범위 이내로 추정하는 독창적인 방법론이다. - 일반 신경망 모델로의 확장성 : 본 발명의 실시예들은 예시로 든 분류 신경망 뿐만 아니라 회귀 신경망, 생성 모델 등 다양한 형태의 결정론적 신경망 모델에 모두 적용될 수 있으므로 방대한 확장성을 가질 수 있다. - 조작의 편의성 : 본 발명의 실시예들은 신경망의 불확실성 추정을 위해 원본 신경망에 부가적인 구조 변형을 요구하지 않으므로 신경망 모델의 고유한 기능 설계를 간섭하지 않는 장점이 있다. 뿐만 아니라 원본 신경망 모델의 학습에 사용된 데이터만으로 구현이 가능하므로 실용적 편의성이 높다. 한편, 신경망 모델은 현대 인공지능 시스템의 근간을 이루고 있으며 그 적용 범위는 인간의 생명을 직접 다루는 영역에 까지 이르고 있다. 예를 들어 자율주행자동차나 의료진단시스템은 인공지능의 개입이 매우 즉각적으로 이루어져야 하지만 인공지능 시스템의 특성상 잘못된 판단이나 예측은 치명적인 오류를 야기할 수 있다. 만일 그 예측이나 판단의 신뢰도를 불확실성의 형태로 표현할 수 있다면 적어도 인공지능의 판단에 의한 실행을 중지 하거나 보다 신뢰할 수 있는 대상에게 2차적인 판단을 요청할 수 있는 기회를 확보할 수 있다. 이러한 측면에 서 인공지능 시스템의 불확실성을 파악하는 것은 대단히 중요한 문제이지만 불확실성 추정이 난해하거나 많은 비용(cost)가 요구된다면 이를 완화함으로써 인공지능의 개발 비용을 크게 효율화할 수 있을 것이다. 또한 인 공지능 시스템이 개량되기 위해 제한된 학습 자원 하에서 어떤 도메인 지식을 학습하여야 할지 결정하는 기준선 또한 불확실성에서 찾을 수 있다. 학습 데이터를 확보하는 데 비용이 많이 발생하는 전문가 영역에서 비용 절감과 개발 시간 단축에 크게 기여할 수 있다. 대부분의 인공지능 시스템 서비스는 고객의 적절한 요청(input X)에 의한 시스템의 응답(Y)을 제공함으로써 수 행될 수 있다. 만일 몇 개의 요청과 응답 정보를 획득하여 해당 인공지능 시스템의 내부 동작 특성을 불확실성 의 형태로 알 수 있게 될 경우 상대 시스템의 내부를 역공학(reverse engineering)할 수 있다. 본 발명의 실시 예들에서 제안하는 원리는 인공지능 시스템의 보안성 향상과 진단을 위해 광범위하게 활용될 수 있을 것이다. 본 발명의 실시예들에 따른 결정론적 인공 신경망의 출력 불확실성 추정 방법 및 시스템은 다음과 같은 분야에 서 이용될 수 있다. 의료 분야 : 긴급을 요하는 응급실이나 영상의학과 전문의가 부족한 의료기관에서 일반의사가 의료영상 판독 보 조 인공지능 시스템의 도움을 받아 의료영상을 판독하거나 여타의 의료 데이터를 해석할 때, 인공지능 시스템의 판단을 그대로 수용하여 진료에 적용할지, 전문의에게 2차 해석을 의뢰할지 결정하기 위해 활용할 수 있다. 여 타 치료 계획 수립 등에서도 동일하게 적용할 수 있다. 자율주행 교통 시스템 : 불확실성의 추정을 통해 인공지능 시스템이 완전하게 판단하기 어려운 교통 시스템에서 안전상의 판단이 요구되는 영역에서 인간의 개입을 어느 정도로 요청할 지 빠르게 결정할 수 있다. 아울러 상 황 탐색을 통해 학습 데이터를 획득할 경우 최적의 탐색의 방향과 위치 등을 결정하기 위해 적용할 수 있다. 인공지능 솔루션 개발 : 실시간 인공지능 서비스 등 인공지능 시스템 자체를 개발하는 기업에서 모델의 성능 개 량을 위해 학습 데이터를 구입하는 경우 제한된 예산 환경에서 어떤 데이터를 구입할 지 결정할 수 있다. 전문가 시스템 분야 : 강화학습 시스템의 경로 탐색 최적화, 전문 지식을 학습하거나 판단하는 모든 종류의 인 공지능 시스템의 개발에 적용할 수 있다.. 인간-인공지능 상호작용이 필요한 모든 분야 : 사용자와 인공지능 시스템이 끊임없이 상호작용하여야 하는 분야, 예를 들어 뇌 기반 인공지능 등에서 잠재적으로 본 발명을 활용하여 단기간에 신뢰도 있는 과업 달성이 가능할 수 있다. 본 발명의 실시예들에 따른 결정론적 인공 신경망의 출력 불확실성 추정 시스템은 적어도 하나의 컴퓨터 장치에 의해 구현될 수 있으며, 본 발명의 실시예들에 따른 출력 불확실성 추정 방법은 출력 불확실성 추정 시스템에 포함되는 적어도 하나의 컴퓨터 장치를 통해 수행될 수 있다. 컴퓨터 장치에는 본 발명의 일실시예에 따른 컴 퓨터 프로그램이 설치 및 구동될 수 있고, 컴퓨터 장치는 구동된 컴퓨터 프로그램의 제어에 따라 본 발명의 실 시예들에 따른 출력 불확실성 추정 방법을 수행할 수 있다. 상술한 컴퓨터 프로그램은 컴퓨터 장치와 결합되어 출력 불확실성 추정 방법을 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장될 수 있다. 도 18은 본 발명의 일실시예에 따른 컴퓨터 장치의 예를 도시한 블록도이다. 컴퓨터 장치(Computer device, 1800)는 도 18에 도시된 바와 같이, 메모리(Memory, 1810), 프로세서(Processor, 1820), 통신 인터페이스 (Communication interface, 1830) 그리고 입출력 인터페이스(I/O interface, 1840)를 포함할 수 있다. 메모리 는 컴퓨터에서 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory) 및 디스 크 드라이브와 같은 비소멸성 대용량 기록장치(permanent mass storage device)를 포함할 수 있다. 여기서 ROM과 디스크 드라이브와 같은 비소멸성 대용량 기록장치는 메모리와는 구분되는 별도의 영구 저장 장치 로서 컴퓨터 장치에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코 드가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록 매체로부터 메모리로 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판독 가능한 기록매체는 플로피 드라이 브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있 다. 다른 실시예에서 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록 매체가 아닌 통신 인터페이스 를 통해 메모리에 로딩될 수도 있다. 예를 들어, 소프트웨어 구성요소들은 네트워크(Network, 1860)를 통해 수신되는 파일들에 의해 설치되는 컴퓨터 프로그램에 기반하여 컴퓨터 장치의 메모리(181 0)에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 인터페이스에 의해 프로세서로 제공될 수 있다. 예를 들어 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행하도록 구성될 수 있다. 통신 인터페이스는 네트워크를 통해 컴퓨터 장치가 다른 장치와 서로 통신하기 위한 기능을 제공할 수 있다. 일례로, 컴퓨터 장치의 프로세서가 메모리와 같은 기록 장치에 저장된 프 로그램 코드에 따라 생성한 요청이나 명령, 데이터, 파일 등이 통신 인터페이스의 제어에 따라 네트워크 를 통해 다른 장치들로 전달될 수 있다. 역으로, 다른 장치로부터의 신호나 명령, 데이터, 파일 등이 네 트워크를 거쳐 컴퓨터 장치의 통신 인터페이스를 통해 컴퓨터 장치로 수신될 수 있다. 통신 인터페이스를 통해 수신된 신호나 명령, 데이터 등은 프로세서나 메모리로 전달될 수 있고, 파일 등은 컴퓨터 장치가 더 포함할 수 있는 저장 매체(상술한 영구 저장 장치)로 저장될 수 있다. 입출력 인터페이스는 입출력 장치(I/O device, 1850)와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 마이크, 키보드 또는 마우스 등의 장치를, 그리고 출력 장치는 디스플레이, 스피커와 같은 장치를 포함할 수 있다. 다른 예로 입출력 인터페이스는 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와의 인터페이스를 위한 수단일 수도 있다. 입출력 장치는 컴퓨터 장치와 하나 의 장치로 구성될 수도 있다. 또한, 다른 실시예들에서 컴퓨터 장치는 도 18의 구성요소들보다 더 적은 혹은 더 많은 구성요소들을 포 함할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 컴 퓨터 장치는 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버 (transceiver), 데이터베이스 등과 같은 다른 구성요소들을 더 포함할 수도 있다. 도 19는 본 발명의 일실시예에 따른 출력 불확실성 추정 방법의 예를 도시한 흐름도이다. 본 실시예에 따른 출 력 불확실성 추정 방법은 도 18을 통해 설명한 컴퓨터 장치에 의해 수행될 수 있다. 이때, 컴퓨터 장치 의 프로세서는 메모리가 포함하는 운영체제의 코드나 적어도 하나의 컴퓨터 프로그램의 코드 에 따른 제어 명령(instruction)을 실행하도록 구현될 수 있다. 여기서, 프로세서는 컴퓨터 장치 에 저장된 코드가 제공하는 제어 명령에 따라 컴퓨터 장치가 도 19의 방법이 포함하는 단계들(1910 내지 1940)을 수행하도록 컴퓨터 장치를 제어할 수 있다. 단계에서 컴퓨터 장치는 학습데이터와 학습데이터에 대응하는 정답 레이블을 포함하는 제1 학습 데 이터셋을 이용하여 결정론적 인공 신경망 모델을 학습할 수 있다. 여기서, 결정론적 인공 신경망 모델은 분류 신경망, 회귀 신경망 및 생성 모델 중 적어도 하나를 포함할 수 있다. 단계에서 컴퓨터 장치는 결정론적 인공 신경망 모델의 학습에 사용된 학습데이터와 학습데이터로 학습된 결정론적 인공 신경망 모델의 출력을 결합하여 제2 학습 데이터셋을 생성할 수 있다. 이 경우, 컴퓨터 장치는 학습된 결정론적 인공 신경망 모델의 출력을 임시 출력 레이블로서 학습데이터와 매칭하여 포함하 는 제2 학습 데이터셋을 생성할 수 있다. 이때, 학습데이터가 이미지 데이터를 포함하는 경우, 컴퓨터 장치 는 행렬 형태의 학습데이터를 대리 가우시안 프로세싱 모델을 위한 낮은 차원의 벡터 형태의 입력으로 변 환할 수 있다. 일례로, 컴퓨터 장치는 학습데이터에 대해 결정론적 인공 신경망 모델의 중간 은닉층에서 추출한 특징 벡터로 대리 가우시안 프로세싱 모델의 학습을 위한 학습데이터를 변환할 수 있다. 또한, 결정론 적 인공 신경망 모델의 출력층이 다수의 유닛으로 구성되는 경우, 컴퓨터 장치는 결정론적 인공 신경망 모델의 복수 카테고리의 출력을 하나의 스칼라로 통합할 수 있다. 이 경우, 컴퓨터 장치는 결정론적 인 공 신경망 모델의 출력을 소프트맥스 함수를 통해 표현되는 벡터로부터 1차원의 단일한 값인 엔트로피(entrop y)로 변환하여 결정론적 인공 신경망 모델의 복수 카테고리의 출력을 하나의 스칼라로 통합할 수 있다. 단계에서 컴퓨터 장치는 생성된 제2 학습 데이터셋으로 가우시안 프로세스 모델을 학습하여 대리 가우시안 프로세스 모델을 생성할 수 있다. 다시 말해, 결정론적 인공 신경망 모델은 학습데이터와 정답 레이 블을 포함하는 제1 학습 데이터셋을 이용하여 학습될 수 있고, 대리 가우시안 프로세스 모델은 학습데이터와 학 습된 결정론적 인공 신경망 모델의 출력으로서의 레이블을 포함하는 제2 학습 데이터셋을 이용하여 학습될 수 있다. 단계에서 컴퓨터 장치는 생성된 제2 학습 데이터셋을 통해 학습된 대리 가우시안 프로세스(proxy Gaussian process) 모델의 테스트 데이터에 대한 출력에 기반하여 결정론적 인공 신경망 모델의 출력 불확실성 을 추정할 수 있다. 일실시예로, 컴퓨터 장치는 대리 가우시안 프로세스 모델이 출력하는 예측의 분산을 결정론적 인공 신경망 모델의 출력 불확실성으로 추정할 수 있다. 앞서 설명한 바와 같이, 분산은 가우시안 프 로세스 모델과 확률적 신경망 모델의 동치성, 커널 회귀 능선 모델과 결정론적 신경망 모델의 동치성 및 커널 회귀 능선 알고리즘의 베이지안 해석에 기초하여 결정론적 인공 신경망 모델의 출력 불확실성에 근사하는 것으 로 결정될 수 있다. 따라서, 컴퓨터 장치는 결정론적 인공 신경망 모델의 구조 변형 없이 대리 가우시안 프로세스(proxy Gaussian process) 모델의 테스트 데이터에 대한 출력에 기반하여 결정론적 인공 신경망 모델의출력 불확실성을 추정할 수 있다. 이와 같이, 본 발명의 실시예들에 따르면, 기계학습 과제에서 일반적으로 가장 많이 활용되는 결정론적 인공 신 경망에 내재된 출력의 불확실성을, 가우시안 프로세스(Gaussian Process) 모델을 이용하여 간접 추정할 수 있다. 또한, 인공지능 시스템에 대한 일반 수요자의 신뢰도 제고에 기여할 뿐만 아니라 신경망 불확실성 추정 에 관한 연구개발을 촉진함으로써 관련 시장의 확장에 긍정적인 기여를 할 것으로 기대된다. 이상에서 설명된 시스템 또는 장치는 하드웨어 구성요소, 또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조 합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트 워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같 은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어 를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의 해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2023-0071054", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19"}
{"patent_id": "10-2023-0071054", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 있어서, 원본 신경망 모델을 모사하는 가우시안 프로세스 모델의 동작 알고리즘의 예를 도시한 도면이다. 도 2는 본 발명의 일실시예에 있어서, 확률적(베이지안) 신경망 모델(Bernouli Dropout Neural Networks로 표 기)과 가우시안 프로세스, 결정론적(비베이지안) 신경망 모델과 커널 회귀 능선의 관계의 예를 도시한 도면이다. 도 3은 본 발명의 일실시예에 있어서, 확률적(베이지안) 신경망 모델의 단계 0부터 단계 3까지의 학습 동역학예시를 도시한 도면이다. 도 4 내지 도 11은 본 발명의 일실시예에 있어서, 결정론적 CNN 모델에서 생성한 가우시안 프로세스 모델의 예 측 불확실성에 따른 테스트 데이터의 원본 CNN 모델에서의 실제 오차(Loss)와 정확도(Accuracy)의 예를 도시한 그래프들이다. 도 12 내지 도 15는 본 발명의 일실시예에 있어서, 결정론적 CNN 회귀 모델에서 생성한 가우시안 프로세스 모델 의 예측 불확실성에 따른 테스트 데이터의 원본 CNN 모델에서의 실제 오차(Loss)의 예를 도시한 그래프들이다. 도 16은 본 발명의 일실시예에 있어서, 결정론적 CNN 모델에서 생성한 가우시안 프로세스 모델의 예측 불확실성 에 따라 학습데이터를 선택하는 능동 학습(active learning)과 다른 알고리즘에 의해 선택하는 능동 학습을 비 교한 예를 도시한 도면이다. 도 17은 본 발명의 일실시예에 있어서, 결정론적 VAE 생성 모델에서 추출한 잠재 벡터(latent vector)의 원본 VAE모델의 가우시안 프로세스 모델의 예측 불확실성에 따른 이미지 생성 결과를 비교한 예를 도시한 도면이다. 도 18은 본 발명의 일실시예에 따른 컴퓨터 장치의 예를 도시한 블록도이다. 도 19는 본 발명의 일실시예에 따른 출력 불확실성 추정 방법의 예를 도시한 흐름도이다."}
