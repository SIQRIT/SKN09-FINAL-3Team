{"patent_id": "10-2019-0115578", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0033809", "출원번호": "10-2019-0115578", "발명의 명칭": "인공 신경망을 이용하여 로봇을 제어하는 제어 서버 및 방법와, 이를 구현하는 로봇", "출원인": "엘지전자 주식회사", "발명자": "박성길"}}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "액츄에이터 또는 모터를 구비하는 구동부;인공 신경망 기반의 알고리즘 모델을 이용하여 상기 구동부를 제어하는 프로세서; 및 상기 알고리즘 모델을 학습하는 러닝 프로세서;를 포함하되, 상기 알고리즘 모델은 제1 GAN(Generative Adversarial Networks) 및 제2 GAN를 포함하고, 상기 프로세서는, 학습된 제1 GAN에 포함된 제1 생성자(generator)에 복수의 시뮬레이션 이미지를 입력하여 복수의 실제-유사-가짜(real-like-fake) 이미지를 생성하고, 상기 러닝 프로세서는, 복수의 랜덤 텍스처 렌더링 이미지 및 상기 복수의 실제-유사-가짜 이미지에 기초하여제2 GAN를 학습하고, 상기 프로세서는, 상기 학습된 제2 GAN에 포함된 제2 생성자에 실제(real) 이미지를 입력하여 원형(canonical)이미지를 생성하고, 상기 원형 이미지를 이용하여 상기 구동부를 제어하는, 로봇."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 실제-유사-가짜 이미지는 실제 환경에서 획득된 이미지와 유사한 가짜(fake) 이미지인, 로봇."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 러닝 프로세서는 상기 제1 GAN를 학습하고, 상기 제1 GAN를 학습하기 위한 학습 데이터는 복수의 학습 시뮬레이션 이미지 및 복수의 학습 실제 이미지를 포함하는, 로봇."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 러닝 프로세서는 상기 제1 GAN를 학습하기 위해 복수의 제1 학습 동작을 수행하되, 상기 복수의 제1 학습 동작 중 하나의 제1 학습 동작에서, 상기 제1 생성자의 입력층으로 상기 학습 시뮬레이션 이미지가 입력되고, 상기 제1 생성자의 출력층으로 실제-유사-가짜 이미지가 출력되며,상기 제1 GAN에 포함된 제1 구별자의 입력층으로 상기 제1 생성자에서 출력된 실제-유사-가짜 이미지 및 제1 이미지가 입력되고, 상기 제1 구별자의 출력층으로 구별 결과가 출력되며, 상기 제1 이미지는 실제 이미지 및 이전의 제1 학습 수행 단계에서 상기 제1 생성자에서 출력된 이전의 실제-유사-가짜 이미지 중 하나의 이미지인, 로봇. 공개특허 10-2021-0033809-3-청구항 5 제1항에 있어서, 상기 러닝 프로세서는 상기 제2 GAN를 학습하기 위해 복수의 제2 학습 동작을 수행하되, 상기 복수의 제2 학습 동작 중 하나의 제2 학습 동작에서, 상기 제2 생성자의 입력층으로 랜덤 텍스처 렌더링 이미지 또는 상기 제1 생성자에서 생성된 실제-유사-가짜 이미지 중 하나가 입력되고, 상기 제2 생성자의 출력층으로 가짜 원형 이미지가 출력되며,상기 제2 GAN에 포함된 제2 구별자의 입력층으로 상기 제2 생성자에서 출력된 가짜 원형 이미지 및 제2 이미지가 입력되고, 상기 제2 구별자의 출력층으로 구별 결과가 출력되며, 상기 제2 이미지는 원형 이미지 및 이전의 제2 학습 수행 단계에서 상기 제2 생성자에서 출력된 이전의 가짜 원형 이미지 중 하나의 이미지인, 로봇."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 가짜 원형 이미지는 원형 이미지와 유사한 가짜 원형 이미지인, 로봇."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "로봇과 통신을 수행하는 통신부; 인공 신경망 기반의 알고리즘 모델을 이용하여 상기 로봇을 제어하는 제어 신호를 생성하는 프로세서; 및 상기 알고리즘 모델을 학습하는 러닝 프로세서;를 포함하되, 상기 통신부는 상기 제어 신호를 상기 로봇으로 전송하고, 상기 알고리즘 모델은 제1 GAN 및 제2 GAN를 포함하며, 상기 프로세서는, 학습된 제1 GAN에 포함된 제1 생성자에 복수의 시뮬레이션 이미지를 입력하여 복수의 실제-유사-가짜 이미지를 생성하고, 상기 러닝 프로세서는, 복수의 랜덤 텍스처 렌더링 이미지 및 상기 복수의 실제-유사-가짜 이미지에 기초하여제2 GAN를 학습하고, 상기 프로세서는, 상기 학습된 제2 GAN에 포함된 제2 생성자에 실제 이미지를 입력하여 원형 이미지를생성하고, 상기 원형 이미지를 이용하여 상기 로봇을 제어하는, 제어 서버."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 통신부는 5G 네트워크를 통해 상기 제어 신호를 상기 로봇으로 전송하는, 제어 서버."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 실제-유사-가짜 이미지는 실제 환경에서 획득된 이미지와 유사한 가짜 이미지인, 제어 서버.공개특허 10-2021-0033809-4-청구항 10 제7항에 있어서, 상기 러닝 프로세서는 상기 제1 GAN를 학습하고, 상기 제1 GAN를 학습하기 위한 학습 데이터는 복수의 학습 시뮬레이션 이미지 및 복수의 학습 실제 이미지를 포함하는, 제어 서버."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 러닝 프로세서는 상기 제1 GAN를 학습하기 위해 복수의 제1 학습 동작을 수행하되, 상기 복수의 제1 학습 동작 중 하나의 제1 학습 동작에서, 상기 제1 생성자의 입력층으로 상기 학습 시뮬레이션 이미지가 입력되고, 상기 제1 생성자의 출력층으로 실제-유사-가짜 이미지가 출력되며,상기 제1 GAN에 포함된 제1 구별자의 입력층으로 상기 제1 생성자에서 출력된 실제-유사-가짜 이미지 및 제1 이미지가 입력되고, 상기 제1 구별자의 출력층으로 구별 결과가 출력되며, 상기 제1 이미지는 실제 이미지 및 이전의 제1 학습 수행 단계에서 상기 제1 생성자에서 출력된 이전의 실제-유사-가짜 이미지 중 하나의 이미지인, 제어 서버."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 러닝 프로세서는 상기 제2 GAN를 학습하기 위해 복수의 제2 학습 동작을 수행하되, 상기 복수의 제2 학습 동작 중 하나의 제2 학습 동작에서, 상기 제2 생성자의 입력층으로 랜덤 텍스처 렌더링 이미지 또는 상기 제1 생성자에서 생성된 실제-유사-가짜 이미지 중 하나가 입력되고, 상기 제2 생성자의 출력층으로 가짜 원형 이미지가 출력되며,상기 제2 GAN에 포함된 제2 구별자의 입력층으로 상기 제2 생성자에서 출력된 가짜 원형 이미지 및 제2 이미지가 입력되고, 상기 제2 구별자의 출력층으로 구별 결과가 출력되며, 상기 제2 이미지는 원형 이미지 및 이전의 제2 학습 수행 단계에서 상기 제2 생성자에서 출력된 이전의 가짜 원형 이미지 중 하나의 이미지인, 제어 서버."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 가짜 원형 이미지는 원형 이미지와 유사한 가짜 원형 이미지인, 제어 서버."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "러닝 프로세서 및 프로세서를 포함하는 장치에서 수행되는 로봇의 동작을 제어하는 방법에 있어서, 상기 프로세서가, 학습된 제1 GAN에 포함된 제1 생성자에 복수의 시뮬레이션 이미지를 입력하여 복수의 실제-유사-가짜 이미지를 생성하는 단계;상기 러닝 프로세서가, 복수의 랜덤 텍스처 렌더링 이미지 및 상기 복수의 실제-유사-가짜 이미지에 기초하여공개특허 10-2021-0033809-5-제2 GAN를 학습하는 단계;상기 프로세서가, 상기 학습된 제2 GAN에 포함된 제2 생성자에 실제 이미지를 입력하여 원형 이미지를 생성하는단계; 및 상기 원형 이미지를 이용하여 상기 로봇의 동작을 제어하는 단계;를 포함하는, 로봇의 동작 제어 방법."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 실제-유사-가짜 이미지는 실제 환경에서 획득된 유사한 가짜 이미지인, 로봇의 동작 제어 방법."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 복수의 실제-유사-가짜 이미지를 생성하는 단계에 선행하여, 상기 러닝 프로세서가 상기 제1 GAN를 학습하는 단계;를 더 포함하고, 상기 제1 GAN를 학습하기 위한 학습 데이터는 복수의 학습 시뮬레이션 이미지 및 복수의 학습 실제 이미지를 포함하는, 로봇의 동작 제어 방법."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 제1 GAN를 학습하는 단계는, 복수의 제1 학습 수행 단계를 포함하되, 상기 복수의 제1 학습 수행 단계 중 하나의 제1 학습 수행 단계에서, 상기 제1 생성자의 입력층으로 상기 학습 시뮬레이션 이미지가 입력되고, 상기 제1 생성자의 출력층으로 실제-유사-가짜 이미지가 출력되며,상기 제1 GAN에 포함된 제1 구별자의 입력층으로 상기 제1 생성자에서 출력된 실제-유사-가짜 이미지 및 제1 이미지가 입력되고, 상기 제1 구별자의 출력층으로 구별 결과가 출력되며, 상기 제1 이미지는 실제 이미지 및 이전의 제1 학습 수행 단계에서 상기 제1 생성자에서 출력된 이전의 실제-유사-가짜 이미지 중 하나의 이미지인, 로봇의 동작 제어 방법."}
{"patent_id": "10-2019-0115578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서, 상기 제2 GAN를 학습하는 단계는, 복수의 제2 학습 수행 단계를 포함하되, 상기 복수의 제2 학습 수행 단계 중 하나의 제2 학습 수행 단계에서, 상기 제2 생성자의 입력층으로 랜덤 텍스처 렌더링 이미지 또는 상기 제1 생성자에서 생성된 실제-유사-가짜 이미지 중 하나가 입력되고, 상기 제2 생성자의 출력층으로 가짜 원형 이미지가 출력되며,상기 제2 GAN에 포함된 제2 구별자의 입력층으로 상기 제2 생성자에서 출력된 가짜 원형 이미지 및 제2 이미지가 입력되고, 상기 제2 구별자의 출력층으로 구별 결과가 출력되며, 상기 제2 이미지는 원형 이미지 및 이전의 제2 학습 수행 단계에서 상기 제2 생성자에서 출력된 이전의 가짜 원형 이미지 중 하나의 이미지인, 로봇의 동작 제어 방법.공개특허 10-2021-0033809-6-청구항 19 제18항에 있어서, 상기 가짜 원형 이미지는 원형 이미지와 유사한 가짜 원형 이미지인, 로봇의 동작 제어 방법."}
{"patent_id": "10-2019-0115578", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 신경망을 이용하여 로봇을 제어하는 제어 서버 및 방법와, 이를 구현하는 로봇이 개시된다. 본 발명의 로 봇은 구동부, 인공 신경망 기반의 알고리즘 모델을 이용하여 구동부를 제어하는 프로세서 및 알고리즘 모델을 학 습하는 러닝 프로세서를 포함하되, 알고리즘 모델은 제1 GAN(Generative Adversarial Networks) 및 제2 GAN를 포함하고, 프로세서는, 학습된 제1 GAN에 포함된 제1 생성자(generator)에 복수의 시뮬레이션 이미지를 입력하여 복수의 실제-유사-가짜(real-like-fake) 이미지를 생성하고, 러닝 프로세서는, 복수의 랜덤 텍스처 렌더링 이미 지 및 복수의 실제-유사-가짜 이미지에 기초하여 제2 GAN를 학습하고, 프로세서는, 학습된 제2 GAN에 포함된 제2 생성자에 실제(real) 이미지를 입력하여 원형(canonical) 이미지를 생성하고, 원형 이미지를 이용하여 구동부를 제어한다."}
{"patent_id": "10-2019-0115578", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 신경망을 이용하여 로봇을 제어하는 제어 서버 및 방법와, 이를 구현하는 로봇에 관한 기술이다."}
{"patent_id": "10-2019-0115578", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 산업용으로 개발되어 공장 자동화의 일 부분을 담당하여 왔다. 최근에는 로봇을 응용한 분야가 더욱 확 대되어, 의료용 로봇, 우주 항공 로봇 등이 개발되고, 일반 가정에서 사용할 수 있는 가정용 로봇도 만들어지고 있다. 이러한 로봇 중에서 자력으로 주행이 가능한 것을 이동 로봇이라고 한다. 한편, 종래 기술에서는 실제 환경에서 획득된 이미지, 즉 실제(real) 이미지를 이용하여 로봇의 동작을 학습시 킨다. 그러나, 실제 이미지를 획득하는데는 많은 비용이 소요되며, 따라서 개선된 종래 기술에서는 시뮬레이션 을 통해 로봇의 동작을 학습한다. 이 때, 시뮬레이션 환경은 실제 환경과 차이가 있으며, 이를 해결하기 위해 도메인 적응(Domain Adaptation) 방법이 사용된다. Konstantinos Bousmalis 등이 발표한 논문(Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping)에서는 도메인 적응을 위해 GAN(Generative Adversarial Network)을 사용하여 시뮬 레이션 이미지를 실제 이미지로 변환하는 방법을 개시하였다. 또한, Stephen James 등이 발표한 논문(Sim-to-Real via Sim-to-Sim: Data-efcient Robotic Grasping via Randomized-to-Canonical Adaptation Networks)에서는 랜덤으로 텍스처가 렌더링된 시뮬레이션 이미지를 원형 (Canonical) 이미지를 변환하는 RCAN(Randomized-Canonical Adaptation Networks) 방법을 개시하였다. 하지만, RCAN을 이용한 원형 영상의 실제 변환 성능은 RCAN에서 제시한 결과와는 차이가 있다. 즉, RCAN은 실제 환경에서 획득된 이미지(즉, 실제 이미지)를 랜덤으로 텍스처가 렌더링된 이미지로 가정한다. 그러나, 실제 이미지와 랜덤으로 텍스처가 렌더링된 이미지 사이에는 시각적 차이(Visual gap)가 존재한다. 따 라서, 몇 백만 단위의 이미지 데이터를 취득하지 않으면 시각적 차이에 의해 테스트 시점에서 RCAN의 성능은 저 하된다. 또한, 상기에서 언급한 바와 같이 RCAN을 학습시키기 위해 몇 백만 단위의 학습 데이터가 필요한데, 이는 학습 데이터의 취득 시간이 오래 걸리고, 학습 시간이 증가되는 단점이 있다."}
{"patent_id": "10-2019-0115578", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 2개의 GAN을 이용하여 로봇의 동작을 보다 정확하게 제어할 수 있는 제어하는 제어 서버 및 방법와, 이를 구현하는 로봇을 제공하는 것이다. 또한, 본 발명의 다른 목적은 적은 수의 실제 이미지를 이용하여 로봇을 제어하는 제어 서버 및 방법와, 이를 구현하는 로봇을 제공하는 것이다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발 명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것 이다."}
{"patent_id": "10-2019-0115578", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 의한 로봇은, 액츄에이터 또는 모터를 구비하는 구동부, 인공 신경망 기반의 알고리즘 모델을 이용하여 상기 구동부를 제어하는 프로세서 및 상기 알고리즘 모델을 학습하는 러닝 프로세서를 포함하 되, 상기 알고리즘 모델은 제1 GAN(Generative Adversarial Networks) 및 제2 GAN를 포함하고, 상기 프로세서 는, 학습된 제1 GAN에 포함된 제1 생성자(generator)에 복수의 시뮬레이션 이미지를 입력하여 복수의 실제-유사 -가짜(real-like-fake) 이미지를 생성하고, 상기 러닝 프로세서는, 복수의 랜덤 텍스처 렌더링 이미지 및 상기 복수의 실제-유사-가짜 이미지에 기초하여 제2 GAN를 학습하고, 상기 프로세서는, 상기 학습된 제2 GAN에 포함 된 제2 생성자에 실제(real) 이미지를 입력하여 원형(canonical) 이미지를 생성하고, 상기 원형 이미지를 이용 하여 상기 구동부를 제어한다. 본 발명의 일 실시예에 의한 제어 서버는, 로봇과 통신을 수행하는 통신부, 인공 신경망 기반의 알고리즘 모델 을 이용하여 상기 로봇을 제어하는 제어 신호를 생성하는 프로세서 및 상기 알고리즘 모델을 학습하는 러닝 프 로세서를 포함하되, 상기 통신부는 상기 제어 신호를 상기 로봇으로 전송하고, 상기 알고리즘 모델은 제1 GAN 및 제2 GAN를 포함하며, 상기 프로세서는, 학습된 제1 GAN에 포함된 제1 생성자에 복수의 시뮬레이션 이미지를 입력하여 복수의 실제-유사-가짜 이미지를 생성하고, 상기 러닝 프로세서는, 복수의 랜덤 텍스처 렌더링 이미지 및 상기 복수의 실제-유사-가짜 이미지에 기초하여 제2 GAN를 학습하고, 상기 프로세서는, 상기 학습된 제2 GAN 에 포함된 제2 생성자에 실제 이미지를 입력하여 원형 이미지를 생성하고, 상기 원형 이미지를 이용하여 상기 로봇을 제어한다. 본 발명의 일 실시예에 의한 로봇의 동작을 제어하는 방법은, 프로세서가, 학습된 제1 GAN에 포함된 제1 생성자 에 복수의 시뮬레이션 이미지를 입력하여 복수의 실제-유사-가짜 이미지를 생성하는 단계, 상기 러닝 프로세서 가, 복수의 랜덤 텍스처 렌더링 이미지 및 상기 복수의 실제-유사-가짜 이미지에 기초하여 제2 GAN를 학습하는 단계, 상기 프로세서가, 상기 학습된 제2 GAN에 포함된 제2 생성자에 실제 이미지를 입력하여 원형 이미지를 생 성하는 단계 및 상기 원형 이미지를 이용하여 상기 로봇의 동작을 제어하는 단계를 포함한다."}
{"patent_id": "10-2019-0115578", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 2개의 GAN을 이용하여 로봇의 동작을 보다 정확하게 제어할 수 있다. 본 발명에 따르면, 적은 수의 실제 이미지를 이용하여 로봇을 정확하게 제어할 수 있다."}
{"patent_id": "10-2019-0115578", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조 부호를 붙이도록 한다. 또한, 본 발명의 일부 실시예들을 예시적인 도면을 참조하여 상세하게 설명한다. 각 도면의 구성요소들에 참조부호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가질 수 있다. 또한, 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에 는 그 상세한 설명은 생략할 수 있다. 본 발명의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질, 차례, 순서 또는 개수 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성 요소 사이에 다른 구성 요소가 \"개재\"되거나, 각 구성 요소가 다른 구성 요소를 통해 \"연결\", \"결합\" 또는 \"접 속\"될 수도 있다고 이해되어야 할 것이다. 또한, 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요 소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘 어져서 구현될 수도 있다. 본 명세서에서 개시된 로봇은 스스로 보유한 능력에 의해 주어진 일을 자동으로 처리하거나 작동하는 기계를 의 미할 수 있다. 특히, 환경을 인식하고 스스로 판단하여 동작을 수행하는 기능을 갖는 로봇을 지능형 로봇이라 칭할 수 있다. 로봇은 사용 목적이나 분야에 따라 산업용, 의료용, 가정용, 군사용 등으로 분류할 수 있다. 로봇은 액츄에이터 또는 모터를 포함하는 구동부를 구비하여 로봇 관절을 움직이는 등의 다양한 물리적 동작을 수행할 수 있다. 또한, 이동 가능한 로봇은 구동부에 휠, 브레이크, 프로펠러 등이 포함되어, 구동부를 통해 지상에서 주행하거나 공중에서 비행할 수 있다. 도 1은 본 발명의 일 실시예에 따른 AI 장치의 개략적인 구성을 도시한 도면이다. AI 장치는 TV, 프로젝터, 휴대폰, 스마트폰, 데스크탑 컴퓨터, 노트북, 디지털 방송용 단말기, PDA(personal digital assistants), PMP(portable multimedia player), 네비게이션, 태블릿 PC, 웨어러블 장치, 셋톱박스(STB), DMB 수신기, 라디오, 세탁기, 냉장고, 데스크탑 컴퓨터, 디지털 사이니지, 로봇, 차량 등 과 같은, 고정형 기기 또는 이동 가능한 기기 등으로 구현될 수 있다. 도 1을 참조하면, AI 장치는 통신부, 입력부, 러닝 프로세서, 센싱부, 출력부, 메모리 및 프로세서 등을 포함할 수 있다. 통신부는 유무선 통신 기술을 이용하여 다른 AI 장치(100a 내지 100e)나 후술할 AI 서버 등의 외부 장치들과 데이터를 송수신할 수 있다. 예컨대, 통신부는 외부 장치들과 센서 정보, 사용자 입력, 학습 모델, 제어 신호 등을 송수신할 수 있다. 이 때, 통신부가 이용하는 통신 기술에는 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), 5G, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블 루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), ZigBee, NFC(Near Field Communication) 등이 있다. 입력부는 다양한 종류의 데이터를 획득할 수 있다. 이때, 입력부는 영상 신호 입력을 위한 카메라, 오디오 신호를 수신하기 위한 마이크로폰, 사용자로부터 정보를 입력 받기 위한 사용자 입력부 등을 포함할 수 있다. 여기서, 카메라나 마이크로폰을 센서로 취급하여, 카메라나 마이크로폰으로부터 획득한 신호를 센싱 데이터 또는 센서 정보라고 할 수도 있다. 입력부는 모델 학습을 위한 학습 데이터 및 학습 모델을 이용하여 출력을 획득할 때 사용될 입력 데이터 등을 획득할 수 있다. 입력부는 가공되지 않은 입력 데이터를 획득할 수도 있으며, 이 경우 프로세서 또는 러닝 프로세서는 입력 데이터에 대하여 전처리로써 입력 특징점(input feature)을 추출할 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망으로 구성된 모델을 학습시킬 수 있다. 여기서, 학습된 인공 신경망을 학습 모델이라 칭할 수 있다. 학습 모델은 학습 데이터가 아닌 새로운 입력 데 이터에 대하여 결과 값을 추론해 내는데 사용될 수 있고, 추론된 값은 어떠한 동작을 수행하기 위한 판단의 기 초로 이용될 수 있다. 이 때, 러닝 프로세서는 AI 서버의 러닝 프로세서과 함께 AI 프로세싱을 수행할 수 있다. 러닝 프로세서는 AI 장치에 통합되거나 구현된 메모리를 포함할 수 있다. 또는, 러닝 프로세서(13 0)는 메모리, AI 장치에 직접 결합된 외부 메모리 또는 외부 장치에서 유지되는 메모리를 사용하여 구현될 수도 있다. 센싱부는 다양한 센서들을 이용하여 AI 장치 내부 정보, AI 장치의 주변 환경 정보 및 사용자 정보 중 적어도 하나를 획득할 수 있다. 이 때, 센싱부에 포함되는 센서에는 근접 센서, 조도 센서, 가속도 센서, 자기 센서, 자이로 센서, 관성 센서, RGB 센서, IR 센서, 지문 인식 센서, 초음파 센서, 광 센서, 마이크로폰, 라이다, 레이더 등이 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시킬 수 있다. 이 때, 출력부에는 시각 정보를 출력하는 디스플레이부, 청각 정보를 출력하는 스피커, 촉각 정보를 출력 하는 햅틱 모듈 등이 포함될 수 있다. 메모리는 AI 장치의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 예컨대, 메모리는 입력 부에서 획득한 입력 데이터, 학습 데이터, 학습 모델, 학습 히스토리 등을 저장할 수 있다. 프로세서는 데이터 분석 알고리즘 또는 머신 러닝 알고리즘을 사용하여 결정되거나 생성된 정보에 기초하 여, AI 장치의 적어도 하나의 실행 가능한 동작을 결정할 수 있다. 그리고, 프로세서는 AI 장치 의 구성 요소들을 제어하여 결정된 동작을 수행할 수 있다. 이를 위해, 프로세서는 러닝 프로세서 또는 메모리의 데이터를 요청, 검색, 수신 또는 활용할 수 있고, 적어도 하나의 실행 가능한 동작 중 예측되는 동작이나, 바람직한 것으로 판단되는 동작을 실행하도록 AI 장치의 구성 요소들을 제어할 수 있다. 이 때, 프로세서는 결정된 동작을 수행하기 위하여 외부 장치와의 연계가 필요한 경우, 해당 외부 장치를 제어하기 위한 제어 신호를 생성하고, 생성한 제어 신호를 해당 외부 장치에 전송할 수 있다. 프로세서는 사용자 입력에 대하여 의도 정보를 획득하고, 획득한 의도 정보에 기초하여 사용자의 요구 사 항을 결정할 수 있다. 이 때, 프로세서는 음성 입력을 문자열로 변환하기 위한 STT(Speech To Text) 엔진 또는 자연어의 의도 정 보를 획득하기 위한 자연어 처리(NLP: Natural Language Processing) 엔진 중에서 적어도 하나 이상을 이용하여, 사용자 입력에 상응하는 의도 정보를 획득할 수 있다. STT 엔진 또는 NLP 엔진 중에서 적어도 하나는 머신 러닝 알고리즘에 따라 학습된 인공 신경망으로 구성될 수 있다. 그리고, STT 엔진 또는 NLP 엔진 중에서 적어도 하나는 러닝 프로세서에 의해 학습된 것이나, AI 서버의 러닝 프로세서에 의해 학습된 것이거나, 또는 이들의 분산 처리에 의해 학습된 것일 수 있다. 프로세서는 AI 장치의 동작 내용이나 동작에 대한 사용자의 피드백 등을 포함하는 이력 정보를 수집 하여 메모리 또는 러닝 프로세서에 저장하거나, AI 서버 등의 외부 장치에 전송할 수 있다. 수 집된 이력 정보는 학습 모델을 갱신하는데 이용될 수 있다. 프로세서는 메모리에 저장된 응용 프로그램을 구동하기 위하여, AI 장치의 구성 요소들 중 적어 도 일부를 제어할 수 있다. 나아가, 프로세서는 응용 프로그램의 구동을 위하여, AI 장치에 포함된 구성 요소들 중 둘 이상을 서로 조합하여 동작시킬 수 있다. 도 2는 본 발명의 일 실시예에 따른 AI 서버의 개략적인 구성을 도시한 도면이다. 도 2를 참조하면, AI 서버는 머신 러닝 알고리즘을 이용하여 인공 신경망을 학습시키거나 학습된 인공 신 경망을 이용하는 장치를 의미할 수 있다. 여기서, AI 서버는 복수의 서버들로 구성되어 분산 처리를 수행할 수도 있고, 5G 네트워크로 정의될 수 있 다. 이 때, AI 서버는 AI 장치의 일부의 구성으로 포함되어, AI 프로세싱 중 적어도 일부를 함께 수행할 수도 있다. AI 서버는 통신부, 메모리, 러닝 프로세서 및 프로세서 등을 포함할 수 있다. 통신부는 AI 장치 등의 외부 장치와 데이터를 송수신할 수 있다. 메모리는 모델 저장부를 포함할 수 있다. 모델 저장부는 러닝 프로세서을 통하여 학습 중 인 또는 학습된 모델(또는 인공 신경망, 231a)을 저장할 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망(231a)을 학습시킬 수 있다. 학습 모델은 인공 신경 망의 AI 서버에 탑재된 상태에서 이용되거나, AI 장치 등의 외부 장치에 탑재되어 이용될 수도 있다. 학습 모델은 하드웨어, 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 학습 모델의 일부 또는 전부가 소프트웨어로 구현되는 경우 학습 모델을 구성하는 하나 이상의 명령어(instruction)는 메모리 에 저장될 수 있다. 프로세서는 학습 모델을 이용하여 새로운 입력 데이터에 대하여 결과 값을 추론하고, 추론한 결과 값에 기 초한 응답이나 제어 명령을 생성할 수 있다. 앞서 설명한 AI 장치 및 AI 서버는 본 명세서에 후술되는 내용에 적용될 수 있으며, 본 명세서에서 제안하는 방법들의 기술적 특징을 구체화하거나 명확하게 하는데 보충될 수 있다. 도 3은 본 발명의 일 실시예에 따른 로봇의 개략적인 구성을 도시한 도면이다. 도 3을 참조하면, 로봇은 구동부, 통신부, 메모리, 러닝 프로세서 및 프로세서(35 0)를 포함한다. 이하, 각 구성 요소 별로 그 기능을 상세하게 설명한다. 구동부는 액츄에이터, 모터 등이 포함되고, 로봇 관절이 포함된 로봇 팔과 대응될 수 있다. 로봇 팔은 공 간에 존재하는 객체들을 파지하는 동작을 수행할 수 있다. 통신부는 외부 장치와 통신을 수행한다. 이 때, 통신부가 이용하는 통신 기술에는 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), 5G, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블 루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), ZigBee, NFC(Near Field Communication) 등이 있다. 메모리는 휘발성 및/또는 비휘발성 메모리일 수 있고, 로봇의 적어도 하나의 다른 구성요소에 관계된 명령 또는 데이터를 저장한다. 특히, 메모리는 로봇의 구동부를 제어하기 위해 사용되는 인공 신경 망 기반의 알고리즘 모델을 저장한다. 인공 신경망 기반의 알고리즘 모델은 제1 GAN(Generative Adversarial Networks) 및 제2 GAN을 포함한다. 러닝 프로세서는 인공 신경망 기반의 알고리즘 모델을 학습하는 기능을 수행한다. 프로세서는 중앙처리장치, 애플리케이션 프로세서, 또는 커뮤니케이션 프로세서 중 하나 또는 그 이상을 포함할 수 있다. 예를 들면, 프로세서는 로봇의 적어도 하나의 다른 구성요소들의 제어 및/또는 통 신에 관한 연산이나 데이터 처리를 실행할 수 있다. 특히, 프로세서는 컴퓨터 프로그램의 실행에 관계된 명령을 실행할 수 있으며, 인공 신경망 기반의 알고리즘 모델을 이용하여 구동부를 제어할 수 있다. 이하, 인공 신경망 기반의 알고리즘을 간략하게 설명한 후, 구동부를 제어하는 러닝 프로세서 및 프 로세서의 동작을 상세하게 설명한다. 인공 지능은 인공적인 지능 또는 이를 만들 수 있는 방법론을 연구하는 분야를 의미하며, 머신 러닝(기계 학습, Machine Learning)은 인공 지능 분야에서 다루는 다양한 문제를 정의하고 그것을 해결하는 방법론을 연구하는 분야를 의미한다. 머신 러닝은 어떠한 작업에 대하여 꾸준한 경험을 통해 그 작업에 대한 성능을 높이는 알고 리즘으로 정의하기도 한다.인공 신경망(ANN: Artificial Neural Network)은 머신 러닝에서 사용되는 모델로써, 시냅스의 결합으로 네트워 크를 형성한 인공 뉴런(노드)들로 구성되는, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 인공 신경 망은 다른 레이어의 뉴런들 사이의 연결 패턴, 모델 파라미터를 갱신하는 학습 과정, 출력값을 생성하는 활성화 함수(Activation Function)에 의해 정의될 수 있다. 인공 신경망은 입력층(Input Layer), 출력층(Output Layer), 그리고 선택적으로 하나 이상의 은닉층(Hidden Layer)를 포함할 수 있다. 각 층은 하나 이상의 뉴런을 포함하고, 인공 신경망은 뉴런과 뉴런을 연결하는 시냅 스를 포함할 수 있다. 인공 신경망에서 각 뉴런은 시냅스를 통해 입력되는 입력 신호들, 가중치, 편향에 대한 활성 함수의 함수 값을 출력할 수 있다. 모델 파라미터는 학습을 통해 결정되는 파라미터를 의미하며, 시냅스 연결의 가중치와 뉴런의 편향 등이 포함된 다. 그리고, 하이퍼파라미터는 머신 러닝 알고리즘에서 학습 전에 설정되어야 하는 파라미터를 의미하며, 학습 률(Learning Rate), 반복 횟수, 미니 배치 크기, 초기화 함수 등이 포함된다. 인공 신경망의 학습의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함 수는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표로 이용될 수 있다. 머신 러닝은 학습 방식에 따라 지도 학습(Supervised Learning), 비지도 학습(Unsupervised Learning), 강화 학습(Reinforcement Learning)으로 분류할 수 있다. 지도 학습은 학습 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시키는 방법을 의미하며, 레이블이란 학습 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 비지도 학습은 학습 데이터에 대한 레이블이 주어지지 않는 상태에서 인공 신경망을 학습시키는 방법을 의미할 수 있다. 강화 학습은 어떤 환경 안에서 정의된 에이전트가 각 상태에서 누적 보상을 최대화하는 행동 혹은 행동 순서를 선택하도록 학습시키는 학습 방법을 의미할 수 있다. 인공 신경망 중에서 복수의 은닉층을 포함하는 심층 신경망(DNN: Deep Neural Network)으로 구현되는 머신 러닝 을 딥 러닝(심층 학습, Deep Learning)이라 부르기도 하며, 딥 러닝은 머신 러닝의 일부이다. 이하에서, 머신 러닝은 딥 러닝을 포함하는 의미로 사용된다. 한편, GAN(Generative Adversarial Networks)은 신경 네트워크를 위한 비교적 새로운 기계 학습의 아키텍처이 다. 도 4에서는 GAN의 구조를 도시하고 있다. GAN은 기계 학습에서 비지도 학습의 한 부분에 속하며, 이미지를 만드는 데 사용되는 새로운 유형의 생성 모델 이다. GAN의 개념은 구별자(discriminator) 네트워크를 도입하여 생성자(generator) 네트워크를 학습한다. \"adversarial\"이란 단어는 서로 대립하는 두 네트워크, 즉 생성자와 구별자를 의미한다. 도 4에 예시된 것처럼, 생성자가 구별자를 속일 수 있는 더욱 사실적인 이미지를 만들려고 시도하는 동안, 구별 자는 생성자가 생성한 이미지를 진짜 이미지로부터 구별하기 위해 지속적으로 매개 변수를 조정한다. 게임 이 론적 관점에서, 생성자 및 구별자는 제로섬 게임에서 서로 경쟁한다. 도 5는 본 발명의 일 실시예에 따른 로봇의 제어 방법의 흐름도를 도시한 도면이다. 본 발명은 실제 환경에서의 로봇을 동작을 제어하기 위해 도 6과 같은 시뮬레이션 환경에서 로봇의 동작을 학습한다. 이하, 각 단계 별로 수행되는 과정을 설명한다. 먼저, 단계(S510)에서, 러닝 프로세서는 제1 GAN를 학습한다. 제1 GAN는 제1 생성자 및 제1 구별자를 포 함한다. 본 발명의 일 실시예에 따르면, 제1 GAN를 학습하기 위한 학습 데이터는 복수의 학습 시뮬레이션 이미지 및 복 수의 학습 실제(real) 이미지를 포함할 수 있다. 보다 상세하게, 러닝 프로세서는 제1 GAN를 학습하기 위해 복수의 제1 학습 동작을 수행한다. 즉, 단계 (S510)에서는 복수의 제1 학습 수행 단계가 수행된다. 여기서, 복수의 제1 학습 동작 각각에서, 제1 생성자의 입력층으로 학습 시뮬레이션 이미지가 입력되고, 제1 생 성자의 출력층으로 실제-유사-가짜(real-like-fake) 이미지가 출력되고, 제1 구별자의 입력층으로 제1 생성자에 서 출력된 실제-유사-가짜 이미지 및 제1 이미지가 입력되고, 제1 구별자의 출력층으로 구별 결과가 출력된다. 이는 도 7에 도시된 바와 같다. 각 이미지에 대해 보다 상세하게 설명하면 다음과 같다. 실제 이미지는 실제 환경에서 카메라 등의 영상 획득 장치를 통해 획득된 이미지이다. 학습 시뮬레이션 이미지는 학습에 사용되는 시뮬레이션 이미지로서, 별도의 시뮬레이터에서 생성된다. 로봇 이 공간에 배치된 객체를 파지하는 동작을 수행하는 경우, 시뮬레이션 이미지는 공간 내의 객체 별로 인덱 스가 부여된 이미지를 의미하며, 객체의 위치 정보 등을 이용하여 컴퓨터 프로그램 등을 통해 생성된 이미지이 다. 실제-유사-가짜 이미지는 실제 환경에서 획득된 이미지인 실제 이미지와 거의 유사한 가짜(fake) 이미지를 의미 한다. 도 8의 (a)에서는 시뮬레이션 이미지의 일례를 도시하고 있고, 도 8의 (b)에서는 제1 생성자에서 출력된 실제- 유사-가짜 이미지의 일례를 도시하고 있다. 한편, 시뮬레이션 이미지 및 실제-유사-가짜 이미지는 본 발명자가 공개한 공개 논문 \"실세계의 로봇조작 학습을 위한 이중 생성적 적대 신경망 기반 도메일 적응 기술\"를 참고한 다. 그리고, 제1 이미지는 실제 환경에서 획득된 실제 이미지 및 이전의 제1 학습 수행 단계에서 제1 생성자에서 출 력된 이전의 실제-유사-가짜 이미지 중 하나의 이미지이다. 즉, 제1 구별자의 입력으로 실제 이미지가 입력되 거나 이전 실제-유사-가짜 이미지가 입력될 수 있다. 한편, 제1 구별자를 0 또는 1의 값을 출력하며, 이는 제1 구별자의 입력으로 입력된 2개의 이미지에 따라 서로 상이하다. 요컨대, 제1 GAN는 시뮬레이션 이미지와 실제 이미지로 학습을 수행한다. 제1 생성자는 시뮬레이션 이미지에서 실제-유사-가짜 이미지를 생성하며, 제1 구별자는 실제-유사-가짜 이미지와 실제 이미지를 구분한다. 다음으로, 단계(S520)에서, 프로세서는 학습된 제1 GAN의 제1 생성자에 복수의 시뮬레이션 이미지를 입력 하여 복수의 실제-유사-가짜 이미지를 생성한다. 이 때, 복수의 시뮬레이션 이미지는 제1 생성자에 순차적으로 입력되며, 이에 따라 순차적으로 복수의 실제-유사-가짜 이미지가 제1 생성자에서 출력된다. 계속하여, 단계(S530)에서, 러닝 프로세서는 제2 GAN를 학습한다. 제2 GAN는 제2 생성자 및 제2 구별자를 포함한다. 본 발명의 일 실시예에 따르면, 제2 GAN를 학습하기 위한 학습 데이터는 복수의 랜덤 텍스처 렌더링 이미지 및 복수의 실제-유사-가짜 이미지를 포함할 수 있다. 이 때, 복수의 실제-유사-가짜 이미지는 앞서 언급한 학습된 제1 GAN의 제1 생성자에서 출력된 이미지이다. 보다 상세하게, 러닝 프로세서는 제2 GAN를 학습하기 위해 복수의 제2 학습 동작을 수행한다. 즉, 단계 (S530)에서는 복수의 제2 학습 수행 단계가 수행된다. 여기서, 복수의 제2 학습 동작 각각에서, 제2 생성자의 입력층으로 랜덤 텍스처 렌더링 이미지 또는 제1 생성자 에서 생성된 실제-유사-가짜 이미지 중 하나가 입력되고, 제2 생성자의 출력층으로 가짜 원형(canonical) 이미 지가 출력되고, 제2 구별자의 입력층으로 제2 생성자에서 출력된 가짜 원형 이미지 및 제2 이미지가 입력되고, 제2 구별자의 출력층으로 구별 결과가 출력된다. 이는 도 9에 도시된 바와 같다. 각 이미지에 대해 보다 상세하게 설명하면 다음과 같다. 랜덤 텍스처 렌더링 이미지는 시뮬레이터에서 생성된 시뮬레이션 이미지를 랜덤으로 텍스처를 랜더링한 이미지 이다. 이는 도 10의 (a)에 도시된 바와 같다. 원형 이미지는 로봇 팔을 포함하는 시뮬레이션 이미지에서 로봇 팔의 관절 부분들의 색상을 다른 구성 요소와 구분되게 표시하는 이미지를 의미한다. 이는 도 10의 (b)에 도시된 바와 같다. 그리고, 가짜 원형 이미지는 원형 이미지와 유사한 가짜의 이미지를 의미한다. 한편, 랜덤 텍스처 렌더링 이미지 및 원형 이미지는 본 발명자가 공개한 공개 논문 \"실세계의 로봇조작 학습을 위한 이중 생성적 적대 신경망 기반 도메일 적응 기술\"를 참고한다. 또한, 제2 이미지는 원형 이미지 및 이전의 제2 학습 수행 단계에서 상기 제2 생성자에서 출력된 이전의 가짜 원형 이미지 중 하나의 이미지이다. 즉, 제2 구별자의 입력으로 원형 이미지가 입력되거나 이전의 가짜 원형 이미지가 입력될 수 있다. 한편, 제2 구별자를 0 또는 1의 값을 출력하며, 이는 제2 구별자의 입력으로 입력된 2개의 이미지에 따라 서로 상이하다. 요컨대, 제2 GAN는 랜덤 텍스터 랜더링 이미지뿐만 아니라, 제1 생성자를 통해 출력된 실제-유사-거짓 이미지를 사용하여 학습을 수행한다. 제2 생성자는 가짜 원형 이미지를 생성하며, 제2 구별자는 가짜 원형 이미지와 원 형 이미지를 구분한다. 한편, 제2 생성자는 세그먼테이션 이미지를 더 출력할 수 있다. 세그먼테이션 이미지는 이미지 내의 객체를 의 미적으로 구분한 이미지를 의미하는 것으로서, 제2 생성자의 파라미터를 조절하기 위해 이용된다. 이는 도 10 의 (c)에 도시된 바와 같다. 한편, 세그먼테이션 이미지는 본 발명자가 공개한 공개 논문 \"실세계의 로봇조작 학습을 위한 이중 생성적 적대 신경망 기반 도메일 적응 기술\"를 참고한다. 그 후, 단계(S540)에서, 프로세서는 학습된 제2 GAN에 포함된 제2 생성자에 실제 이미지를 입력하여 원형 이미지를 생성한다. 그리고, 단계(S550)에서, 프로세서는 원형 이미지를 이용하여 구동부를 제어한 다. 즉, 단계(S540) 및 단계(S550)는 구동부를 제어하기 위한 단계들로서, 프로세서는 학습이 완료된 제2 생성자에 실제 이미지를 입력하여 원형 이미지를 출력하며, 출력된 원형 이미지를 이용하여 실제 구동부, 즉 로봇 팔을 제어한다. 요컨대, 본 발명의 특징적 구성을 설명하면 다음과 같다. 배경 기술에서 언급한 RCAN은, 시뮬레이션 환경에서, 랜덤으로 텍스처가 렌더링된 이미지를 랜덤화되지 않은 원 형(canonical) 이미지로 변환하는 방법을 배우는 학습 모델로, 랜덤 변환(domain randomization)과 GAN이 결합 된 학습 모델이다. 여기서, 생성자는 랜덤으로 텍스처가 렌더링된 영상을 입력으로 받아 원형 이미지를 생성하 고, 구별자는 원형 이미지와 학습 데이터인 원형 레이블 이미지를 구분하며 학습한다. RCAN는 실제 환경에서 획득된 이미지도 랜덤으로 텍스처가 렌더링된 이미지 중 하나라고 가정한다. 그러나, 실 제 환경에서 획득된 이미지와 랜덤으로 텍스처가 렌더링된 이미지 사이에는 시각적 차이(Visual gap)가 존재하 며, 몇 백만 단위의 데이터를 취득하지 않으면 이러한 시각적 차이에 의해 테스트 시점에서 RCAN의 성능은 저하 된다. 또한, 학습 데이터의 취득 시간이 오래 걸리고, 학습 시간이 증가되는 단점이 있다. 따라서, 본 발명에서는 2개의 GAN를 사용하여 상기한 문제점을 해결하며, 이에 따라 상대적으로 적은 수의 데이 터로 기존의 RCAN과 비슷한 성능을 달성할 수 있다. 즉, 본 발명은 랜덤으로 텍스처가 렌더링된 이미지뿐만 아니라 실제-유사-거짓 이미지를 더 이용하여 제2 GAN를 학습시키는 것이다. 실제-유사-거짓 이미지를 제2 GAN을 학습하는데 이용하면, 로봇의 동작을 실제적으로 제어하는 경우, 실제 이미지가 입력된다 하더라도 로봇의 동작을 보다 정확하게 제어할 수 있다. 또한, 실제-유사-거짓 이미지를 생성하는데 제1 GAN이 사용될 수 있다. 이 때, 실제 이미지 데이터가 학습에 이용될 수 있으나, 실제 데이터를 이용하여 로봇의 동작을 학습시키는 이미지 데이터의 개수보다 적은 실 제 이미지 데이터가 사용되는 장점이 있다. 도 8은 본 발명의 일 실시예에 따른 제어 서버의 개략적인 구성을 도시한 도면이다. 도 8을 참조하면, 제어 서버는 AI 서버일 수 있으며, 통신부, 메모리, 러닝 프로세서 및 프로세서를 포함한다.통신부는 로봇과 통신을 수행한다. 일례로, 통신부는 아래에서 설명하는 로봇의 제어 신호를 로봇 으로 전송할 수 있다. 이 때, 통신부는 5G 네트워크를 이용하여 로봇과 통신을 수행할 수 있다. 본 발명의 일 실시예에 따르면, 5G 네트워크를 통한 통신부와 로봇 간의 통신 연결 절차는, 초기 접속 절 차, 임의 접속 절차 및 UL grant의 송수신 절차, DL grant 송수신 절차를 포함하며, 통신부는 통신 연결 절차를 수행한 후 제어 신호를 로봇으로 전송할 수 있다. 메모리는 휘발성 및/또는 비휘발성 메모리일 수 있고, 제어 서버의 적어도 하나의 다른 구성요소에 관계된 명령 또는 데이터를 저장한다. 특히, 메모리는 로봇를 제어하기 위해 사용되는 인공 신경망 기반 의 알고리즘 모델을 저장한다. 인공 신경망 기반의 알고리즘 모델은 제1 GAN(Generative Adversarial Networks) 및 제2 GAN을 포함한다. 러닝 프로세서는 인공 신경망 기반의 알고리즘 모델을 학습하는 기능을 수행한다. 프로세서는 중앙처리장치, 애플리케이션 프로세서, 또는 커뮤니케이션 프로세서 중 하나 또는 그 이상을 포함할 수 있다. 특히, 프로세서는 컴퓨터 프로그램의 실행에 관계된 명령을 실행할 수 있으며, 인공 신 경망 기반의 알고리즘 모델을 이용하여 로봇의 제어 신호를 생성할 수 있다. 한편, 러닝 프로세서 및 프로세서의 동작은 앞서 설명한 도 3의 러닝 프로세서 및 프로세서 의 동작과 유사하므로, 상세한 설명은 생략하기로 한다. 요컨대, 제어 서버는 로봇 팔을 포함하는 로봇을 제어하는 기능을 수행하며, 로봇은 러닝 프로세서를 포 함하지 않을 수 있으며, 로봇 팔을 구동하기 위한 간단한 연산만을 수행하는 프로세서를 구비할 수 있다. 제어 서버는 2개의 GAN를 이용하여 원형 이미지를 생성하고, 이를 이용하여 로봇을 제어하는 제어 신호를 생성 할 수 있다. 또한, 본 발명의 실시예를 구성하는 모든 구성 요소들이 하나로 결합되거나 결합되어 동작하는 것으로 설명되었 다고 해서, 본 발명이 반드시 이러한 실시예에 한정되는 것은 아니며, 본 발명의 목적 범위 내에서 모든 구성 요소들이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 또한, 그 모든 구성 요소들이 각각 하나의 독 립적인 하드웨어로 구현될 수 있지만, 각 구성 요소들의 그 일부 또는 전부가 선택적으로 조합되어 하나 또는 복수 개의 하드웨어에서 조합된 일부 또는 전부의 기능을 수행하는 프로그램 모듈을 갖는 컴퓨터 프로그램으로 서 구현될 수도 있다. 그 컴퓨터 프로그램을 구성하는 코드들 및 코드 세그먼트들은 본 발명의 기술 분야의 당 업자에 의해 용이하게 추론될 수 있을 것이다. 이러한 컴퓨터 프로그램은 컴퓨터가 읽을 수 있는 저장매체 (Computer Readable Media)에 저장되어 컴퓨터에 의하여 읽혀지고 실행됨으로써, 본 발명의 실시예를 구현할 수 있다. 컴퓨터 프로그램의 저장매체로서는 자기 기록매체, 광 기록매체, 반도체 기록소자를 포함하는 저장매체를 포함한다. 또한 본 발명의 실시예를 구현하는 컴퓨터 프로그램은 외부의 장치를 통하여 실시간으로 전송되는 프 로그램 모듈을 포함한다. 이상에서는 본 발명의 실시예를 중심으로 설명하였지만, 통상의 기술자의 수준에서 다양한 변경이나 변형을 가 할 수 있다. 따라서, 이러한 변경과 변형이 본 발명의 범위를 벗어나지 않는 한 본 발명의 범주 내에 포함되는 것으로 이해할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2019-0115578", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 AI 장치의 개략적인 구성을 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 AI 서버의 개략적인 구성을 도시한 도면이다. 도 3은 본 발명의 일 실시예에 따른 로봇의 개략적인 구성을 도시한 도면이다. 도 4는 GAN의 구조를 도시한 도면이다. 도 5는 본 발명의 일 실시예에 따른 로봇의 제어 방법의 흐름도를 도시한 도면이다. 도 6은 도 5의 방법에서 수행되는 로봇의 동작 학습의 개념을 설명하기 위한 도면이다. 도 7 및 도 9는 본 발명에서 사용되는 GAN의 구조의 개념을 설명하기 위한 도면이다. 도 8 및 도 10은 본 발명에서 언급된 이미지들의 일례를 도시한 도면이다. 도 11은 본 발명의 일 실시예에 따른 제어 서버의 개략적인 구성을 도시한 도면이다."}
