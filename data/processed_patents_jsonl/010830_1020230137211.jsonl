{"patent_id": "10-2023-0137211", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0147405", "출원번호": "10-2023-0137211", "발명의 명칭": "지능형 생성 컨텐츠 및 탠덤 컴퓨팅을 갖는 대화형 디스플레이를 위한 방법 및 시스템", "출원인": "브렐리온 인코포레이티트", "발명자": "바르막 헤쉬마트 데코르디"}}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "확장된 디스플레이 생성기로서,복수의 입력 스트림을 생성 또는 수신하는 입력 스트림 모듈;복수의 기능을 구현하는 기능 모듈 ― 복수의 기능 중 각 기능은 복수의 입력 스트림 중 적어도 하나의 입력 스트림에서 작동하도록 구성됨 ―;복수의 시각적 템플릿 ― 복수의 시각적 템플릿 중 각 템플릿은 복수의 기능으로부터 출력을 포맷하도록 구성됨―;복수의 기능, 입력 스트림 및 시각적 템플릿의 그래픽 표현을 생성하도록 구성되는 그래픽 사용자 인터페이스;를 포함하며,그래픽 사용자 인터페이스를 통해 복수의 기능, 복수의 입력 스트림, 복수의 시각적 템플릿 중 적어도 하나를사용자가 선택하면 디스플레이 컨텐츠가 생성되며,디스플레이 컨텐츠는 복수의 시각적 템플릿으로부터의 시각적 템플릿을 사용하여 복수의 기능 중에서 제시된 선택된 기능에 대한 대응출력을 포함하는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 디스플레이 컨텐츠를 수신하고 표시하는 확장된 디스플레이 시스템을 더 포함하는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,복수의 상기 입력 스트림은 제1 입력 스트림 및 제2 일벽 스트림을 포함하며,확장된 디스플레이 시스템은 적어도 하나의 메인 섹션 및 적어도 하나의 확장된 섹션을 포함하며,확장된 디스플레이 시스템은 메인 섹션에 제1 입력 스트림에 기초한 제1 디스플레이 컨텐츠 및 확장된 섹션에제2 디스플레이 컨텐츠를 나타내며, 제2 디스플레이 컨텐츠는 제1 디스플레이 컨텐츠 및 제2 입력 스트림에 대해 작동하도록 구성되는 복수의 기능 중 하나의 기능으로부터 출력되는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 확장된 디스플레이 시스템은 가상 디스플레이 시스템이며, 메인 섹션은 가상 디스플레이 시스템이 제1 깊이에 표시되도록 구성되며 적어도 하나의 확장된 섹션은 가상 디스플레이 시스템이 복수의 상이한 깊이에 표시되도록 구성되는 복수의 확장된 섹션 중에 있는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,공개특허 10-2024-0147405-3-눈 추적기, 헤드 추적기 및 위치 파악 장치로 구성된 세트로부터의 입력 장치를 더 포함하는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 확장된 디스플레이 시스템의 복수의 확장된 부분은 무선으로 통신하는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 확장된 디스플레이 시스템은 가상 디스플레이 시스템이며, 복수의 가상 탬플릿으로부터의 템플릿은 각각의깊이에서 복수의 가상 이미지를 포맷하며, 각각의 깊이는 적어도 2 개의 고유한 깊이를 포함하는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서,상기 확장된 디스플레이 시스템은 복수의 초점 평면에서 디스플레이 컨텐츠 내의 복수의 객체를 표시하도록 구성되며, 복수의 초점 평면 중 하나의 깊이는 사용자의 깊이 인식을 최적화하는 알고리즘에 의해 계산되는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제2항에 있어서,복수의 상기 기능 중 하나의 기능은 복수의 입력 스트림 중 제1 입력 스트림에 대해 작동하고 제1 입력 스트림의 복수의 특징의 검출에 기초하여 주석을 출력하도록 구성되며,확장된 디스플레이 시스템은 제1 초점 평면에 주석을 표시하고 제1 초점 평면과 상이한 제2 초점 평면에서 제1입력 스트림의 컨텐츠를 표시하도록 구성되는 가상 디스플레이 시스템인,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제2항에 있어서,상기 확장된 디스플레이 시스템은 전화기, 시계, 태블릿, 헤드셋, 뷰어, 뷰파인더, 텔레비전 또는 차량 계기판에 통합되는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,복수의 상기 템플릿으로부터의 시각적 템플릿은 사용자의 시선에 실질적으로 수직인 방향을 따라 타일링된 복수의 가상 이미지를 사용하여 시야를 확장하도록 구성되는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 입력 스트림 모듈은 인터넷, 게임, 게임 엔진, 기존 애플리케이션, 웹사이트, 시뮬레이션, 훈련 비디오,공개특허 10-2024-0147405-4-카메라 비디오, 카메라 이미지, 사용자 입력, 센서 입력 및 데이터세트를 포함하는 세트를 사용하거나 이로부터복수의 입력 스트림 중 적어도 하나를 생성하거나 수신하는,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,복수의 상기 기능으로부터의 적어도 하나의 기능은 사용자 입력에 기초하여 디스플레이 컨텐츠의 적어도 일부를생성하도록 구성되는 인공 지능(AI) 기능인,확장된 디스플레이 생성기."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "경험 스테이션으로서,메인 부분 및 확장된 부분을 갖는 가상 디스플레이 시스템; 및(i) 복수의 입력 스트림을 수신하고 ― 입력 스트림 중 적어도 하나는 가상 디스플레이 시스템의 메인 부분에대해 디스플레이 컨텐츠를 제공함 ―, (ii) 사용자에 의한 동작의 시퀀스를 캡처하고, (iii) 가상 디스플레이시스템이 사용자에 의해 복수의 입력 스트림에 대한 복수의 미래 가능한 동작을 확장된 부분에 표시하게 하도록구성되는 생성 기능을 구현하는 모듈;을 포함하는,경험 스테이션."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 생성 기능은 가상 디스플레이 시스템의 확장된 부분에 대한 복수의 미래 가능한 동작을 결정하기 위해 시간 인자를 사용하도록 구성되는,경험 스테이션."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 생성 기능은 트리거되면 가상 디스플레이 시스템의 확장된 부분에 컨텐츠를 생성하게 하는 이벤트 기반 동작 트리거를 포함하는,경험 스테이션."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 생성 기능은 사용자의 동작과 병행하여 사용자가 부여한 권한 수준에 기초하여 예측 작업을 자동으로 제안하고 실행하도록 추가로 구성되는,경험 스테이션."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서,복수의 상기 입력 스트림은 인터넷, 게임, 기존 애플리케이션, 웹사이트, 비디오, 이미지 및 데이터 시각화 장치 중 적어도 하나를 포함하는,경험 스테이션."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "공개특허 10-2024-0147405-5-제14항에 있어서,사용자의 시선을 검출하고 복수의 입력 스트림 중 입력 스트림으로 시선 위치를 출력하는 센서를 더 포함하며,생성 기능은 시선 위치에 기초하여 복수의 미래 가능한 동작의 표시를 동적으로 변경하도록 구성되는,경험 스테이션."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "생성 확장된 디스플레이 스테이션으로서,메인 부분 및 확장된 부분을 가지며 복수의 입력 스트림 중 입력 스트림으로부터 제1 디스플레이 컨텐츠를 표시하도록 구성되는 확장된 디스플레이 시스템; 및복수의 입력 스트림 중 적어도 하나에 대해 작동하고 확장된 디스플레이 시스템의 확장된 부분에 제2 디스플레이 컨텐츠를 출력하도록 구성되는 계산 모듈;을 포함하는,생성 확장된 디스플레이 스테이션."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 확장된 디스플레이 시스템은 가상 디스플레이 시스템이므로, 다층 디스플레이는 복수의 입력 스트림으로부터의 이미지를 제1 층에 표시하고, 계산 모듈은 주석 층을 생성하는,생성 확장된 디스플레이 스테이션."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항에 있어서,사용자로부터의 정보를 캡처하는 센서를 더 포함하며, 정보는 계산 모듈에 입력된 복수의 입력 스트림 중 입력스트림이며 계산 모듈은 정보에 기초하여 제1 또는 제2 디스플레이 컨텐츠를 수정하도록 추가로 구성되는,생성 확장된 디스플레이 스테이션."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제20항에 있어서,상기 제2 디스플레이 컨텐츠가 복수의 수직 검색 엔진 추천이 되도록 사용자의 질의를 입력으로 취하도록 구성되는 인공 지능(AI) 모듈을 더 포함하며, 제1 수직 검색 엔진 추천은 질의에 의해 결정되며, 제2 수직 검색 엔진 추천은 제1 수직 검색 엔진 추천의 결과에 의해 적어도 부분적으로 결정되는,생성 확장된 디스플레이 스테이션."}
{"patent_id": "10-2023-0137211", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제20항에 있어서,상기 계산 모듈은 신경망 또는 변환기를 포함하는 AI 모듈이며,AI 모듈은 복수의 입력 스트림 중 적어도 2 개를 비교하고 확장된 디스플레이 시스템의 단일 디스플레이 컨텐츠로 이들을 병합하도록 구성되는,생성 확장된 디스플레이 스테이션."}
{"patent_id": "10-2023-0137211", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "확장된 디스플레이 시스템의 활용도를 향상시키기 위한 시스템 및 방법이 설명된다. 일부 측면은 입력 스트림을 생성하거나 수신하기 위한 입력 스트림 모듈을 갖는 확장된 디스플레이 생성기에 관한 것이다. 입력 스트림은 로 컬에서(예를 들어, 게임 엔진에 의해) 또는 원격으로(예를 들어, 인터넷으로부터) 생성될 수 있다. 생성기의 기 능 모듈은 입력 스트림에서 정보를 수정하거나 추출하는 기능을 제공한다. 그 다음 확장된 디스플레이 생성기는 입력 스트림과 기능 출력에 템플릿을 적용하여 해당 디스플레이 컨텐츠가 사용자에게 표시되는 방식을 정의한다. 그래픽 사용자 인터페이스는 사용해야 하는 입력 스트림, 기능 및 시각적 템플릿을 지정하는데 사용된다. 확장된 디스플레이는 선택된 입력 스트림 및 기능 출력이 시각적 템플릿에 의해 정의된 형식으로 표시한다."}
{"patent_id": "10-2023-0137211", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 예측 및 생성 요소를 갖는 다양한 디스플레이 시스템의 소프트웨어 계층 경험에 관한 것이며, 더 구 체적으로는 탠덤 컴퓨터 및 생성 컨텐츠 엔진을 갖는 확장된 디스플레이 시스템을 포함하는 새로운 사용자 및다중 사용자 소프트웨어 경험에 관한 것이다."}
{"patent_id": "10-2023-0137211", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "오늘날 사회에서는 생산성 향상을 위한 멀티 태스킹 애플리케이션뿐만 아니라 기계 학습 기반 또는 생성 인공 지능(AI) 컨텐츠 및 예측 모델링 또는 컨텐츠 생성을 위한 애플리케이션의 개발이 증가하고 있다. 가상 디스플레이 시스템은 다양한 사양으로 설계 및 구현된다. 예를 들어, 특허 번호 US 11,067,825 B2 및 US 11,768,825 B1에서 Dehkordi는 현실적인 깊이 인식 효과를 달성하기 위해 단안 및 양안 깊이 단서(depth cue)를 제공하는 가상 디스플레이 시스템을 설명한다. 특허 번호 US 11,592,684 B2에서 Dehkordi는 전계 진화 공동이라 는 광학 구성요소를 개시했으며, 이는 광을 앞뒤로 접어 공동을 사용하여 여러 번 왕복함으로써 광원이 물리적 디스플레이 시스템과의 거리에 비해 관찰자로부터 더 멀리 보이도록 한다. 특허 번호 US 11,196,976 B2에서 Dehkordi는 디스플레이 시스템의 동공 크기를 넘어 확장되는 크기 또는 깊이로 광 필드를 테셀레이팅 (tessellating)하는 가상 디스플레이 시스템을 추가로 공개했다. 마지막으로, 특허 번호 US 11,320,668 B2에서 Dehkordi 등은 광학 융합을 사용하여 광학 품질 또는 디스플레이 시스템의 특성을 수정하는 방법을 개시했으며, 이는 디스플레이 시스템에 의해 생성된 이미지로부터 시각적 아티팩트를 제거하기 위해 계산 방법과 광학 아키 텍처를 결합하는 것이다."}
{"patent_id": "10-2023-0137211", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일부 양태는 복수의 입력 스트림을 생성하거나 수신하기 위한 입력 스트림 모듈; 복수의 기능을 구현하는 기능 모듈 ― 복수의 기능 중 각 기능은 복수의 입력 스트립 중 적어도 하나의 입력 스트림에서 작동하도록 구성됨 ―; 복수의 시각적 템플릿 ― 복수의 시각적 템플릿 중 각 템플릿은 복수의 기능으로부터 출력을 포맷하도록 구 성됨 ―; 복수의 기능, 입력 스트림 및 시각적 템플릿의 그래픽 표현을 생성하도록 구성되는 그래픽 사용자 인 터페이스;를 갖는 확장된 디스플레이 생성기에 관한 것이며, 그래픽 사용자 인터페이스를 통한 복수의 기능, 입 력 스트림 및 시각적 템플릿 중 적어도 하나의 사용자 선택은 생성기가 디스플레이 컨테츠를 생성하게 하며, 디 스플레이 컨텐츠는 복수의 시각적 템플릿으로부터 시각적 템플릿을 사용하여 복수의 기능 중에서 제시된 선택 기능에 대한 대응 출력을 포함한다. 일부 실시예에서, 확장된 디스플레이 생성기는 디스플레이 컨텐츠를 수신하고 표시하기 위한 확장된 디스플레이 시스템을 더 포함한다. 확장된 디스플레이 생성기의 일부 실시예에서, 복수의 입력 스트림은 제1 입력 스트림 및 제2 입력 스트림을 포 함하며, 확장된 디스플레이 시스템은 적어도 하나의 메인 섹션 및 적어도 하나의 확장된 섹션을 포함하며, 확장 된 디스플레이 시스템은 메인 섹션에 대한 제1 입력 스트림 및 확장된 섹션에 대한 제2 디스플레이 컨텐츠에 기 초하여 제1 디스플레이 컨텐츠를 도시하며, 제2 디스플레이 컨텐츠는 제1 디스플레이 컨텐츠 및 제2 입력 스트 림에 동작하도록 구성된 복수의 기능 중 하나의 기능으로부터 출력된다. 확장된 디스플레이 생성기의 일부 실시예에서, 확장된 디스플레이 시스템은 가상 디스플레이 시스템이며, 메인 섹션은 가상 디스플레이 시스템의 제1 깊이에서 표시되도록 구성되며 적어도 하나의 확장된 섹션은 가상 디스플 레이 시스템에 복수의 상이한 깊이로 표시되도록 구성되는 복수의 확장된 섹션 중 하나이다. 일부 실시예에서, 확장된 디스플레이 생성기는 눈 추적기, 헤드추적기 및 위치 측정 장치(localization devic e)로 구성된 세트로부터의 입력 장치를 더 포함한다. 확장된 디스플레이 생성기의 일부 실시예에서, 확장된 디스플레이 시스템의 복수의 확장된 부분은 무선으로 통 신한다. 확장된 디스플레이 생성기의 일부 실시예에서, 확장된 디스플레이 시스템은 가상 디스플레이 시스템이며, 복수 의 시각적 템플릿으로부터의 템플릿은 각각의 깊이에서 각각 복수의 가상 이미지를 포맷하며, 각각의 깊이는 적 어도 2 개 이상의 고유 깊이를 포함한다. 확장된 디스플레이 생성기의 일부 실시예에서, 확장된 디스플레이 시스템은 복수의 초점 평면에서 디스플레이 컨텐츠의 목수의 객체를 표시하도록 구성되며, 복수의 초점 평면 중 하나의 깊이는 사용자의 깊이 인식을 최적 화하는 알고리즘에 의해 계산된다.확장된 디스플레이 생성기의 일부 실시예에서, 복수의 기능 중 하나의 기능은 복수의 입력 스트림 중 제1 입력 스트림에 대해 동작하고, 제1 입력 스트림의 복수의 특징의 검출에 기반하여 주석을 출력하도록 구성되며, 확장 된 디스플레이 시스템은 제1 초점 평면의 주석 및 제1 초점 평면과 상이한 제2 초점 평면에 제1 입력 스트림의 컨텐츠를 표시하도록 구성되는 가상 디스플레이 시스템이다. 확장된 디스플레이 생성기의 일부 실시예에서, 입력 스트림 모듈은 사용자에 대한 정보 또는 센서에 의해 캡처 되는 환경에 기초하여 복수의 입력 스트립 중에 제1 입력 스트림을 생성하도록 구성되는 센서를 포함하며, 복수 의 기능 중 하나의 기능은 확장된 디스플레이 시스템에 의해 생성되는 디스플레이 컨텐츠를 수정하기 위해 제1 입력 스트림에서 작동한다. 확장된 디스플레이 생성기의 일부 실시예에서, 복수의 입력 스트림 중 하나는 비디오 게임이며, 복수의 기능 중 하나는 비디오 게임으로부터 깊이 맵을 추출하고 확장된 디스플레이 시스템에 깊이 맵을 표시하도록 구성된다. 확장된 디스플레이 생성기의 일부 실시예에서, 확장된 디스플레이 시스템은 전화, 시계, 태블릿, 헤드셋, 뷰어, 뷰파인더, 텔레비전 또는 차량 계기판에 통합된다. 확장된 디스플레이 생성기의 일부 실시예에서, 복수의 탬플릿으로부터의 시각적 템플릿은 사용자의 시선에 실질 적으로 수직인 방향을 따라 타일링된 복수의 가상 이미지를 사용하여 시야를 확장하도록 구성된다. 확장된 디스플레이 생성기의 일부 실시예에서, 복수의 시각적 템플릿으로부터의 템플릿은 사용자 정의된다. 일 부 실시예에서, 복수의 기능으로부터의 기능은 사용자 정의 기능이다. 확장된 디스플레이 생성기의 일부 실시예에서, 입력 스트림 모듈은 인터넷, 게임, 게임 엔진, 기존 애플리케이 션, 웹사이트, 시뮬레이션, 훈련 비디오, 카메라 비디오, 카메라 이미지, 사용자 입력, 센서 입력 및 데이터 세 트를 포함하는 세트로부터 또는 이를 사용하여 복수의 입력 스트림 중 적어도 하나를 생성 또는 수신한다. 확장된 디스플레이 생성기의 일부 실시예에서, 복수의 입력 스트림 중 하나는 비디오 게임이며, 복수의 기능 중 하나는 비디오 게임의 디스플레이 컨텐츠의 형상을 기하학적으로 변환하도록 구성된다. 확장된 디스플레이 생성기의 일부 실시예에서, 복수의 기능으로부터의 적어도 하나의 기능은 사용자 입력에 기 초하여 디스플레이 컨텐츠의 적어도 일부를 생성하도록 구성된 AI 기능이다. 다른 양태는 메인 부분 및 확장된 부분을 갖는 가상 디스플레이 시스템; 및 (i) 복수의 입력 시스템을 수신하고 ― 입력 스트림 중 적어도 하나는 가상 디스플레이 시스템의 메인 부분에 대한 디스플레이 컨텐츠를 제공함 ―, (ii) 사용자에 의해 일련의 동작을 캡처하고, (iii) 가상 디스플레이 시스템이 사용자에 의한 복수의 입력 스트 림에 대한 복수의 미래 가능한 동작을 확장된 부분에 표시하게 하도록 구성되는 생성 기능을 구현하는 모듈을 갖는 경험 스테이션에 관한 것이다. 경험 스테이션의 일부 실시예에서, 생성 기능은 가상 디스플레이 시스템의 확장된 부분에 대한 복수의 미래 가 능한 동작을 결정하기 위해 시간 요소를 사용하도록 구성된다. 경험 스테이션의 일부 실시예에서, 생성 기능은 트리거되면 가상 디스플레이 시스템의 확장된 부분에 컨텐츠가 생성되도록 하는 이벤트 기반 동작 트리거를 포함한다. 경험 스테이션의 일부 실시예에서, 이벤트 기반 동작 트 리거는 사용자 입력에 의해 트리거되도록 구성된다. 경험 스테이션의 일부 실시예에서, 생성 기능은 사용자의동작과 병행하여 사용자에 의해 부여된 허가 수준에 기 초하여 예측 작업을 자동으로 제안하고 실행하도록 구성된다. 경험 스테이션의 일부 실시예에서, 복수의 입력 스트림은 인터넷, 게임, 기존 애플리케이션, 웹사이트, 비디오, 이미지 및 데이터 시각화 장치(data visualizer) 중 적어도 하나를 포함한다. 경험 스테이션의 일부 실시예에서, 생성 기능은 사용자의 복수의 과거 동작의 확률적 분석에 적어도 부분적으로 기초하여 복수의 미래 가능한 동작을 결정하도록 구성된다. 경험 스테이션의 일부 실시예에서, 생성 기능은 가상 디스플레이 시스템이 주석 층으로서 복수의 미래 가능한 동작을 출력하게 하도록 구성된다. 경험 스테이션의 일부 실시예에서, 생성 기능은 가상 디스플레이 시스템이 각각의 복수의 가상 깊이에 복수의 미래 가능한 동작을 표시하게 하도록 구성된다.일부 실시예에서, 경험 스테이션은 사용자의 시선을 검출하고 복수의 입력 스트림 중 입력 스트립으로서 시선 위치를 출력하는 센서를 더 포함하며, 생성 기능은 시선 위치에 기초하여 복수의 미래 가능한 동작의 표시를 동 적으로 변경하도록 구성된다. 다른 양태는 생성 확장 디스플레이 시스템에 관한 것이다. 생성 확장 디스플레이 스테이션은 메인 부분과 확장 된 부분을 갖고, 복수의 입력 스트림 중 입력 스트림으로부터의 제1 디스플레이 컨텐츠를 표시하도록 구성되는 확장된 디스플레이 시스템; 및 복수의 입력 스트림 중 적어도 하나에 대해 동작하고 확장된 디스플레이 시스템 의 확장된 부분에 제2 디스플레이 컨텐츠를 출력하도록 구성되는 계산 모듈;을 포함한다. 생성 확장 디스플레이 스테이션의 일부 실시예에서, 확장된 디스플레이 시스템의 적어도 일부는 시각적 환경을 생성하기 위해 가상 이미지를 표시하도록 구성된다. 생성 확장 디스플레이 스테이션의 일부 실시예에서, 확장된 디스플레이 시스템은 다층 디스플레이가 제1 층에 복수의 입력 스트림으로부터의 이미지를 표시하고 계산 모듈이 주석 층을 생성하는 가상 디스플레이 시스템이다. 일부 실시예에서, 생성 확장 디스플레이 스테이션은 사용자로부터 정보를 캡처하기 위한 센서를 가지며 정보는 계산 모듈에 입력된 복수의 입력 스트림 중 입력 스트림이며, 계산 모듈은 정보에 기초하여 제1 또는 제2 디스 플레이 컨텐츠를 수정하도록 추가로 구성된다. 일부 실시예에서, 생성 확장 디스플레이 스테이션은 제2 디스플레이 컨텐츠가 복수의 수직 검색 엔진 추천이 되 도록 사용자의 질의를 입력으로 취하도록 구성된 AI 모듈을 가지며, 제1 수직 검색 엔진 추천은 질의에 의해 결 정되며, 제2 수직 검색 엔진 추천은 제1 수직 검색 엔진 추천의 결과에 의해 적어도 부분적으로 결정된다. 생성 확장 디스플레이 스테이션의 일부 실시예에서, 제2 디스플레이 컨텐츠는 사용자의 설정 또는 사용자 이력 에 의해 영향을 받는다. 생성 확장 디스플레이 스테이션의 일부 실시예에서, 계산 모듈은 신경망 또는 변환기를 포함하는 AI 모듈이다. AI 모듈은 복수의 입력 스트림 중 적어도 2 개를 비교하고 이를 확장된 디스플레이 시스템의 단일 디스플레이 컨텐츠로 병합하도록 구성될 수 있다. 다른 양태는 컨텐츠를 표시하기 위해 메인 부분과 확장된 부분을 갖는 확장된 디스플레이 시스템 ― 메인 부분 은 복수의 입력 스트림 중 입력 스트림에 의해 직접 공급되도록 구성되며, 입력 스트림을 로컬 소스를 가짐 ―; 및 적어도 하나의 프로세서에 의해 실행 가능한 명령이 인코딩되는 비일시적 컴퓨터 판독 가능 저장 매체;를 포 함하는 확장된 디스플레이 경험 스테이션에 관한 것이며, 명령은 (i) 복수의 입력 스트림 중에서 입력 스트림을 입력으로 취하도록 구성되는 복수의 기능, 및 (ii) 복수의 기능으로부터 선택된 기능을 사용하여 확장된 디스플 레이 시스템의 확장된 부분에 표시하기 위해 제2 디스플레이 컨텐츠를 생성하도록 구성되는 소프트웨어 애플리 케이션을 포함하여, 확장된 디스플레이 시스템의 메인 부분의 제1 디스플레이 컨텐츠가 확장된 부분의 제2 디스 플레이 컨텐츠와 상호작용한다. 일부 실시예에서, 확장된 디스플레이 경험 스테이션은 사용자에 대한 정보를 캡처하고 정보를 선택된 기능으로 입력하도록 구성되는 적어도 하나의 센서를 더 포함하며, 선택된 기능은 확장된 디스플레이 시스템의 제1 및 제 2 디스플레이 컨텐츠 중 적어도 하나의 동적 수정을 출력한다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 확장된 디스플레이 시스템의 확장된 부분은 메인 부분의 가상 깊이와 상이한 가상 깊이로 표시된다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 적어도 하나의 프로세서의 적어도 일부는 확장된 디스플 레이 시스템과 통신하는 원격 소스의 일부이며, 원격 소스는 소프트웨어 애플리케이션을 실행하도록 구성된다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 적어도 하나의 프로세서의 적어도 일부는 확장된 디스플 레이 시스템의 일부이며, 적어도 부분적으로 그 상에서 실행되도록 구성된다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 소프트웨어 애플리케이션은 원격 소스와 통신하고 확장된 디스플레이 시스템의 확장된 부분에 표시된 제2 디스플레이 컨텐츠에 대한 지원을 원격 소스로부터 수신하도록 추가로 구성된다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 입력 장치는 사용자로부터 정보를 캡처하도록 구성되며, 소프트웨어 애플리케이션은 훈련 경험을 위해 구성되어 복수의 기능이 복수의 대화형 보조 이미지 부분을 제공한다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 소프트웨어 애플리케이션은 제1 사용자의 사용에 기초하 여 제2 사용자에 대한 훈련 경험을 업데이트하도록 구성된다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 소프트웨어 애플리케이션은 비디오 애플리케이션이며, 비 디오의 특징은 AI 모듈에 의해 영향을 받는다. 일부 실시예에서, 확장된 디스플레이 경험 스테이션은 사용자 입력 장치를 더 포함하며, 비디오 애플리케이션은 클릭 가능한 비디오이며, 사용자 입력 장치에 대한 입력에 기초하여 AI 기능은 (i) 클릭 가능한 비디오의 객체 에 대한 정보, (ii) 클릭 가능한 비디오의 새로운 프레임 및 (iii) 클릭 가능한 비디오와 관련된 추가 컨텐츠 중 하나를 생성한다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 비디오 애플리케이션은 실시간 비디오 또는 원격 환경이 며, AI 모듈은 실시간 비디오에서 사람 또는 사람의 동작을 검출하고 실시간 비디오의 디스플레이와 동시에 일 련의 동작을 표시하도록 구성된다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 복수의 기능 중 하나는 복수의 입력 스트림 중 하나의 특 징을 검축하고 확장된 디스플레이 시스템에 시각적으로 수정된 특징을 출력하도록 구성되는 컴퓨터 비전 기능이 다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 컴퓨터 비전 기능은 확장된 디스플레이 시스템의 메인 부 분에 표시되는 제1 이미지의 컨텐츠를 검출하고 확장된 디스플레이 시스템의 확장된 부분에 표시하기 위한 제2 컨텐츠를 생성하도록 구성되며, 제2 컨텐츠는 제1 컨텐츠에서 참조로 식별된다. 일부 실시예에서, 확장된 디스플레이 경험 스테이션은 복수의 사용자가 복수의 확장된 디스플레이 시스템과 상 호작용하는 공동 애플리케이션에서 사용하도록 구성되며, 확장된 디스플레이 시스템 각각은 시각적으로 공유된 환경의 일부를 표시한다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 확장된 디스플레이 시스템은 모바일 장치, 태블릿, 스마 트폰, 스마트워치 또는 헤드셋의 확장된 디스플레이 경험 스테이션의 일부에 통신 가능하게 결합된다. 다른 양태는 이미지를 수신하고 이미지의 적어도 일부의 수정된 기하학적 구조를 출력하도록 구성되는 기하학적 변환 기능을 구현하는 모듈 및 확장된 디스플레이 시스템을 갖는 다른 확장된 디스플레이 경험 스테이션에 관한 것이다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 이미지는 비디오의 복수의 이미지 중 하나이며 기하학적 변환 기능은 비디오에 적용된다. 확장된 디스플레이 경험 스테이션의 일부 실시예에서, 비디오는 비디오 게임이며, 기하학적 변환 기능은 포즈 워핑, 보폭 워핑, 원근 워핑, 배향 워핑 및 모션 워핑 중 적어도 하나를 제공하기 위해 비디오 게임에 대해 동 작한다. 일부 실시예에서, 확장된 디스플레이 경험 스테이션은 이미지를 캡처하기 위한 카메라 및 원격 회의 (teleconferencing) 애플리케이션을 더 포함하며, 이미지는 적어도 사용자 및 사용자의 환경에 관한 것이며, 모 듈은 기하학적 변환 기능을 사용하여 수정된 기하학적 구조를 갖는 제2 이미지를 생성하며, 이미지 및 제2 이미 지는 공유된 시각적 환경에서 결합된다. 일부 실시예에서, 확장된 디스플레이 경험 스테이션은 사용자의 제스처를 캡처하도록 구성된 카메라를 더 포함 하며, 기하학적 변환 기능에 의해 출력된 이미지의 적어도 일부의 수정된 기하학적 구조는 제스처에 기초하여 수정된다. 일부 실시예에서, 확장된 디스플레이 경험 스테이션은 이미지를 캡처하도록 구성된 카메라를 더 포함하며, 이미 지는 사용자의 환경이며, 기하학적 변환 기능은 이미지의 일부에 작용하여 부분이 가상 현실 환경에 표시되도록 구성된다. 다른 양태는 다층 디스플레이를 출력하도록 구성되는 확장된 디스플레이 시스템; 및 다층 디스플레이의 복수의 초점 평면 각각으로부터의 컨텐츠를 입력으로서 취하고 생성 컨텐츠를 출력하도록 각각 구성되는 복수의 계산 모듈을 포함하는 생성 디스플레이 경험 스테이션에 관한 것이며, 생성 컨텐츠는 다층 디스플레이의 컨텐츠를 수정한다. 생성 디스플레이 경험 스테이션의 일부 실시예에서, 복수의 계산 모듈 중 적어도 하나의 계산 모듈은 AI 모듈이 다. 생성 디스플레이 경험 스테이션의 일부 실시예에서, 컨텐츠는 텍스트 소스를 포함하며 AI 모듈은 텍스트 소 스로부터 도출되는 논리적 추론을 출력한다. 생성 디스플레이 경험 스테이션의 일부 실시예에서, 다층 디스플레이의 제1 깊이는 주석 층이며, 제2 깊이는 컴 퓨터 시뮬레이션 또는 훈련 시뮬레이션을 표시한다. 일부 실시예에서, 제2 깊이는 훈련 시뮬레이션을 표시하며, 주석 층은 강사의 이미지를 표시한다. 일부 실시예에서, 생성 디스플레이 경험 스테이션은 사용자의 시선을 검출하는 센서; 및 다층 디스플레이의 복 수의 초점 평면 중 하나에 메뉴를 표시하고 검출된 시선에 기초하여 메뉴를 수정하도록 구성된 사용자 인터페이 스;를 더 포함한다. 생성 디스플레이 경험 스테이션의 일부 실시예에서, 다층 디스플레이의 깊이 층의 서브세트는 적어도 하나의 입 력 스트림으로부터 복수의 이미지를 나타내며, 다층 디스플레이의 다른 층은 생성 컨텐츠를 나타내며, 생성 컨 텐츠는 복수의 이미지 사이의 차이이다. 일부 실시예에서, 적어도 하나의 입력 스트림은 비디오이며 차이는 비 디오의 프레임 사이의 시간 지연에 기초한다. 일부 실시예에서, 생성 디스플레이 경험 스테이션은 사용자로부터 정보를 캡처하기 위한 적어도 하나의 센서를 더 포함하며, 정보는 복수의 계산 모듈 중 하나에 입력되는 복수의 입력 스트림 중 입력 스트림이며, 계산 모듈 은 정보에 기초하여 제1 또는 제2 디스플레이 컨텐츠를 수정하도록 추가로 구성된다. 일부 실시예에서 센서는 사용자 입력 장치이다. 생성 디스플레이 경험 스테이션의 일부 실시예에서, 복수의 계산 모듈은 생성 디스플레이 컨텐츠가 복수의 AI 모듈 각각의 가능한 출력의 조합이 되도록 서로 확률적으로 결합되는 복수의 AI 모듈이다. 다른 양태는 복수의 입력 스트림을 생성 또는 수신하는 입력 스트림 모듈 ― 복수의 입력 스트림은 제1 입력 스 트림을 포함하며, 입력 스트림 모듈은 원격 소스로부터 제1 입력 스트림을 수신하도록 구성됨 ―; 복수의 입력 스트림에 대해 동작하도록 구성된 복수의 기능을 구현하는 기능 모듈 ― 복수의 기능은 제1 기능을 포함함 ―; 및 제1 기능으로부터 출력되는 컨텐츠를 표시하는 확장된 디스플레이 시스템을 포함하는 탠덤 컴퓨팅 시스템에 관한 것이다. 탠덤 컴퓨팅 시스템의 일부 실시예에서, 원격 소스는 클라우드 소스, 인터넷, 분산 네트워크, 센서 및 로컬 영 역 네트워크 중 적어도 하나이다. 일부 실시예에서, 원격 소스는 분산 네트워크이며, 분산 네트워크로부터의 제 1 입력 스트림은 제1 기능에 입력되며, 제1 기능으로부터 출력된 디스플레이 컨텐츠는 분산 네트워크로부터의 정보로부터 형성된 응집성 이미지이다. 탠덤 컴퓨팅 시스템의 일부 실시예에서, 디스플레이 컨텐츠의 일부는 원격 소스로부터의 정보에 의해서만 생성 된다. 탠덤 컴퓨팅 시스템의 일부 실시예에서, 복수의 입력 스트림은 제2 입력 스트림을 더 포함하며, 입력 스트림 모 듈은 로컬 소스로부터 제2 입력 스트림을 수신하도록 구성되며, 제1 기능은 적어도 제1 입력 스트림 및 제2 입 력 스트림으로부터의 정보의 중첩에 의해 생성되는 디스플레이 컨텐츠의 일부를 출력한다. 탠덤 컴퓨팅 시스템의 일부 실시예에서, 디스플레이 컨텐츠는 낮은 대역폭 구성요소 및 높은 대역폭 구성요소로 분할되며, 원격 소스는 나중에 디스플레이 컨텐츠를 수정하기 위해 구성요소 중 하나에 대한 정보를 확장된 디 스플레이 시스템에 중계한다. 일부 실시예에서, 탠덤 컴퓨팅 시스템은 사용자로부터의 입력을 수집하도록 구성된 적어도 하나의 센서를 더 포 함하며, 복수의 기능 중 적어도 하나로부터의 출력은 상기 입력에 의존한다. 탠덤 컴퓨팅 시스템의 일부 실시예에서, 기능 중 하나는 복수의 입력 스트림 중 2 개의 입력 스트림 간의 차이 를 계산하고 표시하도록 구성되는 시간 지연 기능이다. 탠덤 컴퓨팅 시스템의 일부 실시예에서, 원격 소스는 원격 회의를 위해 구성되는 공유된 시각적 환경의 일부이 며, 제1 기능은 원격 회의 동안 대화의 특징을 검출하도록 구성된 AI 모듈이며, 확장된 디스플레이 시스템의 디 스플레이 컨텐츠는 특징에 대한 정보를 포함한다.탠덤 컴퓨팅 시스템의 일부 실시예에서, 확장된 디스플레이 시스템은 제1 층 및 제2 층을 포함하는 다층 디스플 레이이며, 입력 스트림 모듈은 로컬 소스로부터의 제2 입력 스트림을 수신하도록 구성되며, 복수의 기능은 입력 으로서 제2 입력 스트림을 수신하고 제2 입력 스트림에 기초하여 제2 디스플레이 컨텐츠를 출력하도록 구성되는 제2 기능을 더 포함하며, 디스플레이 컨텐츠는 원격 소스에 기초하여 제1 디스플레이 컨텐츠이며 제1 층에 표시 되며, 로컬 소스에 기초하여 제2 디스플레이 컨텐츠는 제2 층에 표시된다. 일부 실시예에서, 탠덤 컴퓨팅 시스템은 원격 조작 애플리케이션을 위해 원격 제어 차량에 연결된 카메라 어레 이를 더 포함한다. 일부 실시예에서, 센서 어레이는 사용자로부터의 헤드추적, SLAM 및 시선 중 적어도 하나를 포함하며, 복수의 기능 중 적어도 하나는 입력으로서 상기 데이터를 수신하며 시각적 환경의 각도 정확도 동적 투시(angle-accurate dynamic perspective)를 출력한다. 탠덤 컴퓨팅 시스템의 일부 실시예에서, 복수의 입력 스트림은 협업 애플리케이션에 참여하는 각각의 원격 사용 자에 대한 정보를 각각 포함하는 적어도 하위 복수의 입력 스트림을 포함한다. 일부 실시예에서, 확장된 디스플 레이 시스템은 공유된 시각적 환경을 표시하도록 구성되며, 복수의 기능 중 적어도 하나의 기능은 제2 사용자를 위한 상이한 형태, 제2 사용자 프로필 및 이력 중 적어도 하나에 의해 결정되는 상이한 형태로 제1 사용자에 의 해 공유된 컨텐츠를 동적으로 번역하도록 구성된다. 탠덤 컴퓨팅 시스템의 일부 실시예에서, 확장된 디스플레이 시스템은 복수의 사용자에 의해 사용하기 위해 구성 되는 다층 디스플레이의 공유된 시각적 환경을 표시하며, 제1 층은 원격 소스에 의해 생성되며, 제1 층은 복수 의 사용자에 의해 공통적으로 볼 수 있으며, 복수의 사용자 각각의 제2 층 각각에 의해 영향을 받도록 추가로 구성된다. 일부 실시예에서, 입력 센서는 기하학적 구조 또는 사용자를 검출하도록 구성되며, 각 사용자의 각각 의 제2 층은 제1 층에 대한 윈도우 역할을 하며, 윈도우는 기하학적 구조에 의해 결정된다. 탠덤 컴퓨팅 시스템의 일부 실시예에서, 제1 사용자의 사용자 입력은 각각의 제2 층 중 하나의 수정된 컨텐츠를 출력하는 기능에 입력된다. 다른 양태는 복수의 입력 스트림을 생성 또는 수신하는 입력 스트림 모듈; 입력으로서 복수의 입력 스트림 중 적어도 하나의 입력 스트림을 수신하고 복수의 입력 스트림 중 적어도 하나로부터 도출된 가상 이미지의 주석인 생성 시각 정보를 출력하도록 구성되는 AI 기능을 구현하기 위한 기능 모듈; 및 생성 시각 정보를 표시하도록 구성되는 확장된 디스플레이 시스템;을 포함하는 생성 디스플레이 시스템에 관한 것이다. 일부 실시예에서, 생성 디스플레이 시스템은 사용자 입력을 검출하도록 구성되는 사용자 입력 장치를 더 포함하 며, AI 기능은 복수의 입력 스트림 중 적어도 하나에 기초하여 생성 시각 정보를 연속적으로 업데이트하도록 구 성되며, AI 기능은 사용자 입력 장치로부터 사용자 입력을 수신하고 사용자 입력에 기초하여 생성 시각 정보를 변경하도록 추가로 구성된다. 생성 디스플레이 시스템의 일부 실시예에서, AI 기능은 적어도 하나의 초점 평면 이미지를 입력으로 취하며 확 장된 시야 디스플레이 이미지로서 주석을 출력한다. 생성 디스플레이 시스템의 일부 실시예에서, 복수의 입력 스트림 중 적어도 하나는 원격 소스로부터 나온다. 생성 디스플레이 시스템의 일부 실시예에서, 생성 시각 컨텐츠는 사용자 프로필 또는 사용자 이력에 의해 수정 된다."}
{"patent_id": "10-2023-0137211", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "최신 디스플레이 장치는 대역폭 공유, 컨텐츠 생성 및 사용자 상호작용에 대한 새로운 채널을 제공한다. 증강 현실(AR), 가상 현실(VR), 확장 현실(XR), 혼합 현실(MR), 헤드셋, 독립형 가상 디스플레이 시스템과 같은 몰입 형 컨텐츠 및 하드웨어는 모두 인간 생산성과 엔터테인먼트를 향상시키는 새로운 방법과 소프트웨어 애플리케이 션을 제공하는 방식이다. 기계 학습(ML), 인공 지능(AI) 알고리즘, 다른 소프트웨어 아키텍처 및 알고리즘과 결 합하여 예측 및 생성 시각 컨텐츠를 새롭고 독특한 방식으로 표시하여 사용자 경험을 증폭하거나 풍부하게 할 수 있다. 발명자는 사용자의 시야(FoV)에 제공되는 가능성의 세트를 연장하고 확장하기 위해 동시에 실행되는 컴퓨터 파워를 활용함으로써 사용자의 시각적 경험이 풍부해질 수 있음을 인지하고 인식했다. 최신 디스플레이 장치는 예를 들어 이러한 컨텐츠를 3차원 디스플레이, 가상 및 다층 디스플레이 또는 다중 모니터 설정을 포함 하지만 이에 제한되지 않는 다양한 디스플레이 시스템에 통합하는 소프트웨어 메커니즘을 공유하는 대역폭의 새 로운 채널을 제공한다. 일부 실시예에서, 디스플레이 이미지는 측면 패널 및 모니터로 확장된 단지 2D 이미지이 다. 일부 다른 실시예에서, 디스플레이는 단안 깊이를 갖는 이미지를 제공하며, 뷰어는 적어도 하나의 이미지 평면에 대한 수용 깊이 단서를 경험한다. 일부 실시예에서, 디스플레이 이미지는 입체 이미지이다. 일부 실시예 에서, 입체 및 단안 깊이 단서가 모두 제공된다. 개시된 기술의 사용자는 향상된 생산성, 엔터테인먼트 가치 또 는 임의의 애플리케이션에 대한 생성 제안을 경험할 수 있다. 본 개시에서는, 새로운 소프트웨어 방법 및 소프트웨어 애플리케이션이 논의된다. 본 명세서에 설명된 일부 실 시예는 확장된 디스플레이 시스템에서 사용하기 위해 구성된 그러한 방법 및 애플리케이션을 개시하며, 이는 소 프트웨어 애플리케이션, 예측 시각적 소프트웨어의 통합, 협업 및 단일 사용자 애플리케이션, 그리고 원격 소스 를 포함하는 복수의 소스를 포함하는 소프트웨어 애플리케이션 및 디스플레이를 생성하기 위한 방법을 포함한다. 사용자 생산성, 훈련, 비디오 회의, 텔레프레즌스(telepresence) 또는 엔터테인먼트를 위한 시각적 대역폭을 생성하는 새로운 방법이 설명된다. 명명법 “디스플레이 시스템” 또는 “디스플레이”는 이미지를 생성하는 임의의 장치이다. 디스플레이 이미지의 물리 적 소스는 액정 디스플레이(LCD), 발광 다이오드(LED) 디스플레이, 마이크로 LED 디스플레이, 유기 발광 다이오 드(OLED) 디스플레이, 폴리머 발광 다이오드(POLED) 디스플레이, 활성 매트릭스 유기 발광 다이오드(AMOLED) 디 스플레이, MOLED 등과 같은 디스플레이 패널 또는 복수의 디스플레이 패널에 의해 생성되는 바와 같이 표준 2D 이미지 또는 비디오일 수 있다.이러한 디스플레이 기술 또는 그 중 복수는 다른 디스플레이 시스템에도 통합될 수 있다. 일부 실시예에서, 공간 광 변조기(SLM)가 사용된다. 일부 디스플레이 시스템에서, 광원은 마스크 또는 패턴화된 요소와 결합되어 광원을 분할하고 주소 지정이 가능하도록 만들 수 있다. 다른 소스는 예를 들어 프로 젝션 기반 디스플레이 시스템에 사용하도록 구성된 하나 또는 여러 개의 LED, 백라이트 또는 레이저 빔과 같은 일반적인 광원일 수 있다. 또한, 디스플레이 시스템은 헤드셋, 휴대용 장치 또는 독립형 시스템일 수 있으며, 여기서 용어 “독립형”은 장치 하우징이 테이블과 같은 구조물 위에 놓일 수 있음을 의미한다. 일부 실시예에서, 디스플레이 시스템은 기 계적 암에 의해 구조물에 부착되도록 구성된다. 본 개시에서, “확장된 디스플레이” 또는 “확장된 디스플레이 시스템”은 디스플레이에 공급되는 메인 컨텐츠 가 아닌 확장된 컨텐츠에 할당, 확장 또는 전용되는 이미지 또는 시각화의 일부를 갖는 임의의 디스플레이 시스 템이다. 이는 다중 모니터 설정; 모니터 프로젝션 시스템 하이브리드 설정; 가상 디스플레이 시스템; 확장된 헤 드트래킹 뷰를 갖는 AR, VR 및 XR 헤드셋; 다중 프로젝션 시스템; 광필드 디스플레이 시스템; 다중 초점 디스플 레이 시스템; 체적 디스플레이 시스템; 타일링된 비디오 벽; 또는 동일한 환경의 부분에 연결된 임의의 디스플 레이 시스템을 포함한다. 일부 실시예에서, 확장된 디스플레이 시스템은 모니터의 한 부분 및 휴대폰, 태블릿, 랩톱 스크린, 터치 스크린, 광고 스크린 또는 AR/VR/XR/MR 장치의 다른 부분을 갖는다. 확장된 디스플레이 시스 템은 임의의 애플리케이션의 임의의 스크린 장치에 있는 디스플레이의 집합으로 나눌 수 있다. 확장된 디스플레 이 시스템은 하나 또는 복수의 장치에 있는 디스플레이 또는 픽셀의 집합으로 간주될 수 있으므로 픽셀의 메인 입력 세트와 픽셀의 확장된 세트가 있다. 픽셀의 확장된 세트는 “확장된 부분(portion)” 또는 “확장된 부분 (part)”이라고 불릴 수 있다. 확장된 디스플레이 시스템은 기본 컴퓨터 시스템(“로컬 소스”)에 의해 컨텐츠 가 생성되는 메인 부분을 갖는 것으로 설명될 수 있으며, 보조 또는 간접 컴퓨터 시스템 또는 소스(“원격 소스 ”)에 의해 생성될 수 있는 2차 부분(즉, 확장된 부분)을 가질 수 있다. “가상 디스플레이 시스템”은 둘 이상의 인지된 깊이 또는 이미지를 생성하는 디스플레이 패널의 깊이와 다른 인지된 깊이에서 이미지를 생성하는 확장된 디스플레이 시스템이다. 이러한 이미지는 단안 깊이에 의존할 수 있 으며; 이는 입체형, 자동입체형 또는 (자동)멀티-스코픽(multi-scopic)일 수 있다. 가상 디스플레이 시스템은 컴퓨터 모니터나 텔레비전 세트와 같은 독립형 시스템일 수 있다. 이는 휴대폰, 태블릿, 헤드셋, 스마트 워치 또는 임의의 휴대용 장치의 일부일 수 있다. 이는 임의의 애플리케이션에서 단일 사용자 또는 여러 사용자를 위 한 것일 수 있다. 가상 디스플레이 시스템은 체적 또는 광필드 디스플레이일 수 있다. 일부 실시예에서, 가상 디스플레이 시스템은 광의 간섭 조작에 기초하여 이미지를 생성하기 위해 광의 파동 특성에 의존하는 홀로그램 디스플레이이다. 용어 “디스플레이 컨텐츠”는 뷰어가 인지하는 소스 정보 또는 최종 이미지 정보를 설명하는데 사용된다. 일부 실시예에서, 가상 디스플레이 시스템은 뷰어의 두 눈을 동시에 둘러쌀만큼 충분히 큰 볼륨을 갖는 아이박스를 생성한다. 다른 실시예에서, 가상 디스플레이 시스템은 각각 왼쪽 및 오른쪽 눈으로 동시에 볼 수 있도록 구성 된 왼쪽 아이박스 및 오른쪽 아이박스를 생성한다. 아이박스의 크기와 수는 디스플레이의 특정 성격과 디자인에 따라 다르다. 가상 디스플레이 시스템을 포함하는 확장된 디스플레이 시스템은 디스플레이의 특성에 영향을 주는 액정 또는 다른 편광 종속 요소; 광 경로를 재지향하거나, 임의의 차원의 크기에 영향을 미치거나, 초점 깊이를 수정하거 나 또는 수차 및 왜곡을 교정하는 임의의 유형의 거울 또는 렌즈; 임의의 표면 코팅, 활성 요소; 이미지 품질을 보조하는 스펙트럼 또는 공간 필터; 광학 공동; 또는 뷰어에 도달하는 원하지 않는 산란 또는 주변 광을 줄이기 위해 차폐층 또는 반사 방지층 역할을 하는 임의의 유형의 요소 또는 코팅을 포함하는 임의의 하드웨어가 통합 될 수 있다. 일부 실시예에서, 디스플레이 시스템은 메타물질 및 메타표면, 비선형 광학 요소, 광결정, 동급 지 수 물질, 이방성 또는 이중 이방성 요소 또는 광학 전기 광학 요소를 포함한다. 일부 실시예에서, 확장된 디스 플레이 시스템은 광학 가상 디스플레이 시스템이다. 그러나, 확장된 디스플레이 시스템은 인간의 청각 시스템이 소비하도록 구성되는 무선 주파수 또는 음향 디스플레이 시스템을 포함하는 임의의 양식일 수 있다. 디스플레이 또는 디스플레이의 요소는 일부 실시예에서 휘어질 수 있다. 일부 실시예에서, “필드 전개 공동”, “FE 공동” 또는 “FEC”는 광이 실질적으로 그 자체로 접힐 수 있는 광학 공동이다. FEC는 사용자에게 3차원 인식을 위한 깊이 단서를 제공하는데 도움을 준다. 일부 실시예에서, 깊이 단서는 단안 깊이 단서이다. FEC의 예는 제1 세미 반사 요소, 공기 또는 유전 재료의 갭 및 제2 세미 반사 요소를 포함한다. 광은 제1 세미 반사 요소를 통해, 갭을 통해 이동하며, 제2 세미 반사 요소에 의해 반사되며, 갭을 통해 뒤로 이동하며, 제1 세미 반사 요소에 의해 반사되며, 갭을 통해 다시 앞으로 이동하며, 그 다음 뷰 어에게 세미 반사 요소에 의해 전송된다. 결과적으로 이 경우 광이 이동한 유효 거리는 갭 거리 자체보다 3배 더 크다. 왕복 횟수는 임의적이다. 예를 들어, 왕복은 0, 1, 2 또는 3회일 수 있다. 일부 실시예에서, 편광기, 파장 플레이트 및 편광 빔 분할기와 같은 편광 의존형 및 편광 충격 요소를 사용하여 효율성을 높이거나 왕복 횟수를 수정할 수 있다. 예를 들어 광원이 대략 점 광원인 픽셀인 경우, FEC는 광이 갭을 한번 통과한 경우보다 픽셀의 구형 파면을 더 평평하게 만든다. FEC에서는 왕복 횟수가 이미지의 초점 평면을 결정하고 그에 따라 뷰어의 단안 깊이 단서를 결정한다. 일부 실 시예에서, 상이한 광선은 상이한 총 거리를 이동하여 복수의 초점 평면 또는 복수의 이미지 깊이를 갖는 다초점 이미지를 생성한다. 일부 실시예에서, 이미지 깊이는 예를 들어 왕복 횟수를 수정하는 전기 광학 구조를 통해 동적이거나 조정 가능하다. “광 필드”는 기하학적 광선 근사에 의존하는 광 전파의 수학적 모델이다. 일부 광 필드 모델은 회절과 같은 파동 기반 효과를 포함한다. 광 필드 디스플레이는 광 필드 모델링을 사용하여 사용자에 대해 3D 효과를 생성하 도록 설계된 3차원 디스플레이이다. 동심 광필드 디스플레이는 뷰어로부터 고정된 반경에 있는 디스플레이의 임 의의 두 픽셀에 대해 제1 픽셀의 라이트 콘(light cone)의 주 광선이 제2 픽셀의 라이트 콘의 주 광선과 교차하 는 광 필드 디스플레이이다. 동심 광 필드 디스플레이는 모든 지점에서 눈의 초점을 맞출 수 있는 이미지를 생 성한다. 디스플레이 시스템은 이미지를 생성하거나, 기존 이미지에 주석을 오버레이하거나, 한 세트의 디스플레이 컨텐 츠를 대화형 환경을 위해 다른 세트에 다시 공급하거나, 또는 주변 환경에 맞게 조정할 수 있다. 사용자는 VR, AR, XR 경험을 가지거나, 효과를 통해 비디오를 보거나, 원격 시스템을 모니터링하고 동시에 예측 제안을 받거 나, 아바타에게 디지털 컨텐츠나 온라인 리소스에 각인을 만들 수 있는 권한을 제공하거나 또는 생성 컨텐츠 생 성을 위해 AI를 사용할 수 있다. 일부 실시예에서, 디스플레이 컨텐츠의 하위 섹션은 다른 하위 섹션에 영향을 주는 알고리즘에 입력된다. 디스플레이 컨텐츠의 “하위 섹션”은 디스플레이 시스템에 의해 생성된 디스플레이 컨텐츠의 분할이다. 일부 실시예에서, 하위 섹션은 픽셀 또는 픽셀의 세트이다. 픽셀의 세트는 분리되어 있거나 연속될 수 있다. 일부 실 시예에서, 하위 섹션은 표시 컨텐츠의 특징 유형에 대응한다. 예를 들어, 사람의 이미지의 하위 섹션은 머리 또 는 팔일 수 있고, 다른 하위 섹션은 손 또는 눈일 수 있다. 일부 실시예에서, 하위 섹션은 다중 초점 평면을 생 성하는 디스플레이의 초점 평면 또는 층의 일부 또는 전체 층일 수 있다. 일부 실시예에서, 하위 섹션은 이미지 의 스펙트럼 컨텐츠의 일부이거나 임의의 수학적 기초로 이미지의 일부이다. 하위 섹션은 다양한 시점에 다르게 분할될 수도 있다. 디스플레이 컨텐츠는 사용자에 의해 조작되거나 다양한 입력 장치를 통해 사용자와 상호 작용할 수 있다. 입력 장치는 일반적으로 자동이 아닌 의도적으로 사용자 입력을 취하는 센서의 유형이다. 카메라, 키보드 및 마우스 입력, 터치 스크린, 제스처 센서, 머리 추적, 눈 추적, VR 패들, 사운드 입력, 음성 검출과 같은 입력 장치를 통해 다양한 양식으로 사용자 피드백을 허용한다. 일부 실시예에서, 다양한 생물학적 또는 건강 센서는 심박수, 자세, 앉거나 서 있는 배향, 혈압, 시선 또는 초점과 같은 정보를 캡처하고 알고리즘에서 해당 정보를 사용하여 표시된 컨텐츠에 영향을 미친다. 예를 들어, 일부 실시예에서 시선이 검출될 수 있고 시선의 위치가 추적될 수 있다. 시선 검출은 사람의 초점, 즉 사람이 보고 있는 위치, 무엇을 보고 있는지, 어떻게 깜박이거나 윙크하는지, 임의의 자극, 시각 또는 다른 것에 대해 사람의 동공이 어떻게 반응하는지(예를 들어, 동공 크기의 변화)를 측정할 수 있다. 적외선 센서와 같은 센서는 적외선 광을 눈에 비추어 눈의 움직임에 따른 반사율의 변화를 검출할 수 있다. 일부 실시예에서, 눈의 카메라 캡처 이미지 및 CNN(convolutional neutral network)은 시선을 추정하는데 사용된다. 시선이 디스 플레이 시스템에 의해 감지되거나 알려지면, 디스플레이 컨텐츠는 시선을 기반으로 변경될 수 있다. 예를 들어, 시선은 사용자가 메뉴를 표시하는 것과 같이 사용자가 취할 수 있는 동작에 대응하는 특정 디스플레이 컨텐츠를 보고 잇는 것일 수 있다. 다른 예에서, 제1 층은 장면의 광시야 이미지 또는 지도 상의 사용자의 위치를 표시할 수 있으며 눈 추적 피드백은 특정 영역을 확대하거나 시선의 초점인 영역에 대한 주석을 표시한다. 이 예는 텔 레스코핑 기능이라고 부를 수 있다.일부 실시예에서, 사용자 입력 도는 환경 입력은 디스플레이 시스템과 직접 또는 간접적으로 인터페이스할 수 있는 다른 다양한 센서 또는 AI 메커니즘을 통해 생성될 수 있다. 센서는 임의의 유형의 카메라, 압력 또는 촉 각 센서, 사람이나 환경에 대한 건강 생물학적 정보를 검출하는 센서, 시계 및 다른 타이밍 센서, 온도 센서, 오디오 센서(임의의 유형의 마이크를 포함함), 화학 센서 또는 과학 및 공학 목적을 위한 계측 센서를 포함한다. 디스플레이 컨텐츠의 소스는 로컬 또는 원격일 수 있다. 소스는 로컬 워크스테이션, 랩톱, 컴퓨터, 에지 장치, 분산 센서, 인터넷, 클라우드 소스, 서브 또는 서버 팜 또는 데이터를 통신할 수 있는 임의의 전자 장치를 포함 한다. 소스는 마이크로 컨트롤러, 필드 프로그래밍 가능한 게이트 어레이(FPGA), 클라우드 컴퓨터 또는 서버, 에지 장치, 분산 네트워크, 사물 인터넷(IoT)을 포함할 수 있다. 소스는 데이터를 디스플레이 시스템에 전송하 기 전에 데이터에 대해 작동할 수 있으며, 소스는 작동할 데이터를 데이터 시스템으로부터 수신할 수 있다. 원격 소스는 클라우드 서버, 인터넷, 분산 네트워크 또는 센서, 에지 장치, 무선 네트워크를 통해 연결된 시스 템 또는 IoT를 포함하지만 이에 제한되지는 않는다. 원격 소스는 반드시 멀리 위치될 필요는 없으며 로컬 소스 가 아닌 스테이션에서 작동하는 처리 유닛(CPU, GPU 또는 신경 처리 유닛(NPU))을 포함할 수 있다. 로컬 소스는 사용자 인터페이스 시스템에 내장되며 확장된 디스플레이의 메인 디스플레이 부분에 대한 메인 워크스테이션 역 할을 한다. “통신 채널”은 예를 들어 소스와 디스플레이 사이의 정보와 데이터의 전송을 허용하는 적어도 두 시스템 또는 사용자 간의 링크를 의미한다. 이는 유선 또는 무선일 수 있다. 통신 채널은 이더넷, USB, 무선 네트워크, 단거 리 무선 기술(예를 들어, 블루투스), 광섬유 시스템, 디지털 가입자 회선(DSL), 동축 케이블과 같은 무선 주파 수(RF) 채널을 포함한다. “입력 스트림”은 로컬 또는 원격 데이터 저장 시스템 또는 데이터를 검색할 수 있는 소스로부터의 데이터 또 는 정보를 의미한다. 데이터는 실시간으로 전송될 수 있다. 이는 물리적 소스 자체 또는 다른 컨텐츠에 대한 메 타데이터를 포함할 수 있다. 입력 스트림은 디스플레이 시스템에 직접 표시하기 위한 그래픽 데이터일 수 있다. 일부 실시예에서, 입력 스트림은 디스플레이 시스템의 하위 섹션으로 향하는 하나 이상의 입력 스트림을 의미할 수 있다. 일부 실시예에서, 입력 스트림은 디스플레이의 하나의 하위 섹션에서 사용자 동작에 의해 생성되며 다 른 하위 섹션에 표시된다. 레이턴시(latency)는 정보가 통신 채널을 따라 전송을 시작하는 순간과 채널 끝에서 정보가 수신되는 순간 사이 의 지연이다. 일반적으로, 레이턴시와 컨텐츠 대역폭 간에는 상충 관계가 있다. 원격 소스의 경우 데이터 통신 의 레이턴시는 소프트웨어 애플리케이션 설계에 통합될 수 있는 파라미터이다. 원격으로 생성된 컨텐츠의 레이 턴시는 다양한 신경망의 ML 가중치 및 선형 층에 통합될 수 있다. 일부 실시예에서, 다양한 AI 및 ML 알고리즘이 시각적 예측 서비스에 통합될 수 있다. 생성 사전 훈련된 변환기 및 양방향 인코더 표현과 같은 기존 학습 알고리즘은 본 명세서에 설명된 바와 같이 사용자 동작에 대해 일반화 되고 부분 또는 전체 확장된 디스플레이를 명령하기 위해 확장된 디스플레이 시스템에 통합될 수 있다. 애플리케이션은 그래픽 예측 보조원 및 가상 보조원, 품질 관리, 원격 작업, 비행 시뮬레이션 및 방어, 의료 및 진단 영상, e-스포츠 및 게임, 금융 거래를 포함하지만 이에 제한되지는 않는다. 이러한 사용레에서는 사용자가 정보를 바탕으로 결정을 내릴 수 있도록 다차원 데이터세트를 직관적인 방식으로 표시해야 한다. 일부 실시예에 서, 예측 분석이 계산될 수 있다. 일부 실시예에서, 사용자가 부여한 권한을 가진 가상 아바타 또는 AI 시스템 은 이러한 예측 분석에 작용한다. AI 생성 컨텐츠의 예는 텍스트-이미지, 이미지-텍스트, 이미지- 또는 텍스트- 작업, 텍스트-코드, 텍스트-추론, 이미지- 또는 텍스트-추천 또는 임의의 다른 조합을 포함한다. AI 기능 또는 모듈은 상이한 모델 또는 훈련 데이터를 결합하기 위한 확률적 분석에 의해 컨텐츠 생성을 지원할 수 있다. 용어 “사용자” 또는 “뷰어”는 시각, 청각, 촉각 또는 후각일 수 있는 감각을 사용하여 시스템과 상호작용하 는 사람을 의미한다. 일부 실시예에서, 시스템은 디스플레이 시스템 또는 확장된 디스플레이 시스템이다. 사용 자는 비동기 애플리케이션을 허용하기 위해 상이한 시간에 시스템을 사용할 미래의 사용자일 수도 있다. “사용 자 인터페이스” 또는 “UI”는 사용자가 상호작용할 수 있는 대화형 도구(토글 버튼, 라디오 버튼, 스크롤 바 또는 드롭 다운 메뉴와 같음) 및 스크린의 세트에 대응한다. 마찬가지로, “사용자 경험” 또는 “UX”는 UI에 의해 결정되는 사용자의 종합적인 경험을 정의한다. “3D 이미지”는 결과적으로 다양한 깊이의 디스플레이 컨텐츠, 서로에 대해 다양한 깊이의 컨텐츠의 다른 부분 또는 물리적 디스플레이 시스템과 상이한 깊이에서 나타나는 디스플레이 컨텐츠를 인식하는 뷰어의 임의의 깊이단서를 유발하는 이미지이다. 일부 실시예에서, 시차 효과가 생성된다. 일부 실시예에서, 3D 효과는 각 눈에 상 이한 이미지를 전송함으로써 입체적으로 트리거된다. 일부 실시예에서, 3D 효과는 “단안 깊이” 단서를 사용하 여 트리거되며, 각 눈은 적절한 초점 평면에 초점을 맞추거나 이에 적응한다. 가상 이미지는 가상 디스플레이 시스템에 표시되는 이미지이다. 가상 이미지는 다초점, 가변초점, 광 필드 이미지, 홀로그램, 입체, 무안경식 입체 또는 (자동)멀티 스코픽일 수 있다. 가상 이미지의 가상 깊이는 디스플레이 시스템의 제어, 사용자 또는 센서 입력, 또는 사전 프로그래밍된 루틴을 통해 동적으로 조정될 수 있다. 컨텐츠가 위치되는 깊이는 “초점 평면”의 “가상 깊이”라고 한다. 다양한 가상 깊이에서 디스플레이 컨텐츠 를 생성하는 디스플레이는 “다층 디스플레이 시스템” 또는 “다층 디스플레이”라고 한다. 예를 들어, 다층 디스플레이 시스템은 뷰어가 다양한 디스플레이 컨텐츠를 보기 위해 그의 눈을 다양한 깊이에 맞춰야 하는 방식 으로 디스플레이 컨텐츠가 표시되는 시스템이다. 일부 실시예에서 다층 디스플레이는 투명 디스플레이를 포함한 다. 지정된 가상 깊이에서 컨텐츠를 표시하는 것을 “층”, “깊이 층” 또는 “가상 층”이라고 한다. “주석 층”은 디스플레이 시스템의 다른 컨텐츠의 컨텍스트, 추가 정보 또는 설명을 제공하는 디스플레이 컨텐 츠이다. 예를 들어, 주석 층은 다층 디스플레이의 층 또는 초점 평면일 수 있다. 주석 층은 다른 층의 컨텐츠에 대한 그래픽 또는 텍스트 주석을 제공한다. 확장된 디스플레이의 다른 포맷은 주석을 또한 포함할 수 있다. 주 석은 호버링 그래픽, 확장된 FoV 디스플레이에 표시되거나 단일 이미지의 관련 디스플레이 컨텐츠 위에 오버레 이될 수 있다. 일부 실시예에서, 디스플레이 컨텐츠의 관심 있는 다른 특성은 해상도, 새로 고침 속도, 밝기, FoV, 가시 구역, 단안 깊이, 또는 조절, 버전스(vergence), 아이 박스 또는 헤드 박스를 포함하지만 이에 제한되지는 않는다. “시각적 템플릿”은 가상 디스플레이 시스템에서데이터와 정보를 계산적으로 구성하고 표시하기 위한 미리 결 정된 방식을 의미한다. 시각적 템플릿의 예는 다층 디스플레이에 의해 생성된 층의 세트이다. 일반적으로, “시각적 환경”은 서로 상호작용할 수 잇는 디스플레이 컨텐츠 또는 가상 이미지의 모음이다. 디 스플레이 컨텐츠는 소스 카메라 이미지 또는 컴퓨터 그래픽과 같은 계산적으로 렌더링된 이미지를 가질 수 있다. 시각적 환경은 모든 컨텐츠가 가상 디스플레이 컨텐츠인 가상 현실 환경일 수 있다. 가상 이미지가 물리 적 환경에 겹쳐지는 증강 또는 혼합 현실 환경일 수 있거나 또는 LCD 패널과 같은 디스플레이 패널로부터의 기 존 이미지 컨텐츠일 수 있다. 일부 실시예에서, 시각적 환경은 단 하나의 가상 이미지를 포함한다. 시각적 환경 은 키네마틱 리그(kinematic rig)의 단일 사용자에 의해 사용될 수 있거나 예를 들어 인터넷이나 임의의 유형의 유선 또는 무선 네트워크를 통해 서로 통신하는 복수의 디스플레이 시스템에 의해 공유 또는 표시될 수 있다. “공유된 시각적 환경”은 재택 근무 애플리케이션, 원격 회의, 웹 회의, 온라인 교육, 협업 또는 다중 플레이 어 게임을 포함하는 임의의 협업 활동에 사용될 수 있는 시각적 환경이다. 시각적 환경 또는 공유된 시각적 환 경에서, 상이한 사용자는 상이한 관점으로부터 디스플레이 컨텐츠를 볼 수 있으며, 일부 실시예에서, 공유된 시 각적 환경은 몰입적이어서, 두 사용자 각각이 별도의 위치에서 디스플레이를 사용하지만 동일한 공유된 시각적 환경에서 서로 물리적으로 옆에 있다는 것을 인식하거나, 사용자가 예를 들어 가상 환경에서 탐색하거나 가상 파노라마의 주변 영역에 공동 사용자를 가짐으로써 디스플레이 시스템의 물리적 위치가 아닌 위치에 있는 것을 인식한다. 확장된 디스플레이 시스템 및 가상 디스플레이 시스템은 비디오 게임, 게임 엔진, 원격 조작, 시뮬레이션 훈련, 원격 회의 및 컴퓨터 시뮬레이션을 포함하는 다양한 애플리케이션에 유용한다. 비디오 게임은 사용자 인터페이스를 통해 하나 이상의 플레이어와 상호작용하는 전자 게임이며 오디오 및 시각 적 피드백을 활용하여 오디오 및 시각적 피드백을 활용하여 몰입감 있고 상호작용적인 게임 경험을 만든다. 비 디오 게임은 콘솔, 개인용 컴퓨터, 모바일 장치 및 가상 현실 시스템을 포함하는 다양한 플랫폼을 위해 설계될 수 있으며, 액션, 어드벤처, 롤플레잉, 시뮬레이션, 스포츠, 퍼즐 및 전략 게임과 같은 다양한 게임 장르를 포 함할 수 있다. 게임 메커니즘과 규칙은 게임에 따라 다를 수 있지만 일반적으로 플레이어가 게임 환경 내에서 달성해야 하는 목적을 포함한다. 게임 엔진은 비디오 게임을 생성하기 위한 플랫폼이다. 원격 조작은 작업자가 원격 장치 또는 시스템에서 실시간으로 작업을 수행할 수 있도록 하는 원격 장치 또는 시 스템을 제어하는 방법이다. 원격 조작 시스템은 일반적으로 작업자가 원격 환경을 인식하고 조작할 수 있는 센 서와 액추에이터뿐만 아니라 작업자에게 피드백과 제어를 제공하는 사용자 인터페이스를 포함한다. 원격 장치 또는 시스템은 위험하거나 접근하기 어려운 위치에 있을 수 있거나, 작동하려면 전문 기술이나 전문 지식이 필 요할 수 있으므로 원격 조작은 제조, 건설, 탐사 및 원격 제어된 차량 사용을 포함하는 다양한 산업에서 유용한도구가 된다. 원격 조작 시스템은 인공 지능 및 기계 학습 알고리즘을 통합하여 작업자의 능력을 향상시키고 원 격 조작의 특정 측면을 자동화할 수도 있다. 원격 회의는 원격 참가자가 인터넷과 같은 통신 채널을 통해 실시간 회의에서 통신하고 협업할 수 있도록 하는 기술이다. 원격 회의 시스템은 일반적으로 참가자가 회의에 연결하고 카메라, 마이크, 스피커, 디스플레이 스크 린 및 사용자 인터페이스와 같이 서로 상호작용할 수 있도록 하는 하드웨어 및 소프트웨어 구성요소 모두를 포 함한다. 시스템은 화면 공유, 파일 공유, 가상 화이트보드, 채팅 메시징과 같은 특징을 통합하여 협업 경험을 강화시킬 수도 있다. 원격 회의는 일반적으로 원격 미팅, 프레젠테이션, 교육 세션 및 상담을 용이하게 하여 참 가자가 물리적인 이동 없이도 통신하고 함께 작업할 수 있게 한다. 시뮬레이션 훈련은 일반적으로 컴퓨터 소프트웨어와 특수 하드웨어를 사용하여 시뮬레이션 환경에서 작업 경험 을 재현하는 기술이다. 항공기 비행 작업을 시뮬레이션하는 비행 시뮬레이션 기술이 그 예이다. 비행 시뮬레이 션 시스템은 일반적으로 실제 항공기의 제어 및 장비를 모방한 조종석 시뮬레이터 또는 제어 인터페이스뿐만 아 니라 시뮬레이션된 환경을 사실적으로 표현하는 시각적 디스플레이 시스템을 포함한다. 시뮬레이터는 몰입형 경 험을 향상시키기 위해 동작 및 사운드 효과를 포함할 수도 있다. 비행 시뮬레이션은 조종사 훈련, 항공기 설계 및 테스트, 엔터테인먼트와 같이 다양한 목적을 위해 사용될 수 있다. 시뮬레이션은 실제 데이터와 물리적 모델 을 기반으로 항공기와 그 환경의 동작을 정확하게 복제할 수 있으며, 다양한 비행 조건과 비상 상황을 시뮬레이 션하기 위해 시나리오와 이벤트를 통합할 수도 있다. 비행 시뮬레이션 훈련 애플리케이션에 대한 사용자 입력은 요크(yoke) 및 스로틀(throttle), 물리적 패널 또는 터치 스크린을 포함한다. 컴퓨터 시뮬레이션은 상이한 조건에서 시스템 또는 프로세스의 동작과 상호작용을 모방하도록 설계된 실제 시스 템 또는 프로세스의 디지털 모델이다. 컴퓨터 시뮬레이션은 일반적으로 수학적 알고리즘, 컴퓨터 프로그램 및 데이터 입력을 사용하여 시스템의 동작을 탐색하고 분석할 수 있는 시각적 환경을 만든다. 시뮬레이션된 시스템 은 날씨 시스템, 화학적 반응, 전자기 현상 또는 기계 장치와 같은 물리적 객체나 현상일 수 있거나, 시장이나 소셜 네트워크와 같은 추상적인 개념일 수 있다. 컴퓨터 시뮬레이션은 과학 연구, 엔지니어링 설계 및 테스트, 훈련 및 교육과 같은 다양한 목적으로 사용될 수 있다. 컴퓨터 시뮬레이션의 정확성과 복잡성은 특정 애플리케 이션에 필요한 세부 수준과 충실도에 따라 크게 달라질 수 있다. 종종 컴퓨터 시뮬레이션은 사용자가 모델링 파 라미터나 계산 파라미터를 변경하여 시뮬레이션된 시스템의 세부사항과 상호작용할 수 있게 한다. 임의의 실시예에서, 임의의 센서는 사용자, 환경 또는 다른 외부 조건 및 디스플레이 시스템에 대한 시나리오에 대한 정보를 제공하는데 사용될 수 있다. 일부 실시예에서, 예를 들어, 카메라는 사용자 또는 사용자의 환경에 관한 정보를 캡처하는데 사용된다. 다수의 카메라 또는 카메라 어레이 또는 카메라 시스템이 사용될 수 있다. 일부 실시예에서, 깊이 카메라는 깊이 또는 감지 제스처 및 포즈에 대한 정보를 캡처하며 이는 임의의 유형일 수 있다. 본 개시에서, “깊이 카메라”, “깊이 센서” 또는 “RBGD 카메라”는 카메라 사이의 거리와 객체 지 점까지의 거리를 기록하는 이미징 장치이다. 이는 능동적으로 조명되거나 수동적으로 조명될 수 있으며 다수의 카메라를 포함할 수 있다. 광 검출 및 거리 측정(LIDAR), 및 비행 시간 카메라는 활성 깊이 카메라의 예이다. 깊이 카메라는 광간섭 단층 촬영 감지(즉, 자기상관)를 사용할 수도 있다. 적외선(IR) 조명을 사용하여 구조나 음영에서 깊이를 추출할 수 있다. 깊이 카메라는 제스처 인식 또는 얼굴 인식 특징을 포함할 수 있다. 깊이는 예를 들어 스테레오 이미징을 통해 기존 카메라 또는 복수의 기존 카메라로부터 추정될 수 있다. 카메라 어레이 또는 카메라 시스템은 이러한 카메라의 조합을 포함할 수 있다. “제스처”는 사용자의 동작, 표정, 자세 배향이며, 이는 일반적으로 사람이나 컴퓨터에 의해 해석되어 원하는 특정 변화, 감정 또는 신체 상태를 나타낸다. 이들은 일반적으로 인간이 관찰될 수 있는 시간 스케일에 있다. 마이크로 제스처는 1초 이내에 발생하는 동작, 표정 또는 배향이다. 이들은 일반적으로 비자발적이며 제스처와 유사한 특징을 나타낸다. 이들은 시선의 짧은 변화, 손가락 두드리기 또는 다른 비자발적 동작을 포함할 수 있 다. 제스처는 카메라로 캡처되어 딥러닝 알고리즘 또는 컨볼루셔널 신경망을 통해 식별되거나 분류될 수 있다. 일반적으로 사람, 사용자, 객체, 디스플레이 이미지 또는 다른 가상 또는 물리적 객체의 “기하학적 구조”는 항목의 위치 및 배향을 모두 포함하는 용어이다. 일부 실시예에서, 객체의 기하학적 구조는 형상, 즉 객체가 얼 마나 왜곡되거나, 늘어나거나, 기울어지거나 일반적으로 변형되는지에 대응할 수 있다. 예를 들어, 카메라 및 알고리즘을 함께 사용하여 공간에서 물리적 객체의 위치를 식별할 수 있다. 본 문서에서, 용어 “기계 판독 가능 매체”, “컴퓨터 판독 가능 매체” 및 이에 유사한 용어는 기계가 특정 방식으로 작동하도록 유발하는 데이터 및/또는 명령을 저장하는 휘발성 또는 비휘발성인 비일시적 매체를 지칭 하는데 사용된다. 기계 판독 가능 매체의 일반적인 형태는 예를 들어 하드 디스크, 고체 상태 드라이브(SSD),자기 테이프 또는 다른 자기 데이터 저장 매체, 광학 디스크 또는 임의의 다른 광학 데이터 저장 매체, 홀의 패 턴이 있는 임의의 물리적 매체, 랜덤 액세스 메모리(RAM), 프로그래밍 가능한 읽기 전용 메모리(PROM), 삭제 가 능 프로그래밍 가능한 읽기 전용 메모리(EPROM), FLASH-EPROM, 비휘발성 랜덤 액세스 메모리(NVRAM), 임의의 다 른 메모리 칩 또는 카트리지 및 동일한 네트워크 버전을 포함한다. 이들 및 다른 다양한 형태의 컴퓨터 판독 가능 매체는 실행을 위해 하나 이상의 명령의 하나 이상의 시퀀스를 처리 장치로 전달하는데 포함될 수 있다. 매체에 구현된 이러한 명령을 일반적으로 “명령” 또는 “코드”라고 한다. 명령은 컴퓨터 프로그램 또는 다른 그룹의 형태로 그룹화될 수 있다. 실행될 때, 이러한 명령은 처리 장 치가 본 명세서에 설명된 바와 같이 본 출원의 특징 또는 기능을 수행할 수 있게 한다. “처리 장치”는 처리 작업을 수행하는 단일 프로세서 또는 처리 작업을 수행하는 특수 및/또는 범용 프로세서 의 조합으로 구현될 수 있다. 처리 장치는 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 가속 처리 유닛(APU), 디지털 신호 프로세서(DSP), 필드 프로그래밍 가능 게이트 어레이(FPGA), 애플리케이션 특이 집적 회로(ASIC), 시스템 온 칩(SOC) 및/또는 다른 처리 회로를 포함할 수 있다. AI는 기계가 생성하는 임의의 지능적인 작업이다. 지능적인 작업은 인식, 감지, 장면 이해, 생성 또는 인식 정 보 또는 추론을 포함한다. 용어 “신경망(neural network)”, “인공 신경망” 도는 “신경망(neural net)”은 AI 구현의 예이며 여러 데이터 소스 및 유형의 패턴을 학습하고 전에 본 적이 없는 데이터에 대해 예측할 수 있 는 컴퓨팅 소프트웨어 아키텍처를 의미한다. 신경망의 유형, 알고리즘 또는 아키텍처는 피드포워드 (feedforward) 신경망, 순호나 신경망(RNN), 잔여 신경망, 생성 적대 신경망(generative adversarial network, GAN), 모듈형 신경망 또는 컨볼루셔널 신경망(CNN)(객체 검출 및 인식에 사용됨)을 포함한다. 신경망은 다양한 유형의 신경망 아키텍처의 조합을 포함할 수 있다. 신경망의 파라미터는 훈련 데이터를 사용하여 결정되거나 훈 련될 수 있다. 신경망은 감독되거나 감독되지 않을 수 있다. 학습은 비용 기능의 최적화를 통해 완료될 수 있다. 일부 실시예에서, 신경망 아키텍처는 방사형 기반 네트워크, 다층 퍼셉트론 아키텍처(multi-layer perceptron architecture), 장단기 메모리(LSTM), 홉필드 네트워크(Hopfield network) 또는 볼츠만 기계이다. 신경망 아키텍처는 일대일, 일대다, 다대일, 다대다일 수 있다. AI 알고리즘 중 임의의 것은 본 개시의 AI 기반 실시예에서 사용될 수 있다. 예를 들어, GAN은 손실 기능을 최소화하기 위해 확률적 경사 하강법(stochastic gradient descent)에 의한 최적화를 사용할 수 있다. LSTM 또는 RNN은 역전파로 경사 하강법 알고리즘을 사용할 수 있다. “변환기”는 다양한 방식으로 입력 데이터에 가중치를 주는 자기 주의에 의존하는 딥 러닝의 기계 학습 모델이 다. 변환기는 컴퓨터 비전 및 자연어 처리(NLP)에 자주 사용된다. 입력 데이터가 순차적이 아닌 한 번에 처리된 다는 점에서 RNN과 다르다. 사전 훈련된 생성 변환기 및 변환기로부터의 양방향 인코더 표현은 변환기 시스템의"}
{"patent_id": "10-2023-0137211", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예이다. 애플리케이션은 비디오 또는 이미지 이해, 문서 요약 또는 생성, 언어 번역 등을 포함한다. 학습 알고리즘은 감독되거나 감독되지 않을 수 있다. 본 명세서에 개시된 실시예를 구현하는데 사용되는 일부 지도 학습 알고리즘은 의사결정 트리(decision tree) 또는 랜덤 포레스트(random forest), 지원 벡터 머신, 베 이지안 알고리즘(Bayesian algorithm) 및 로지스틱 또는 선형 회귀를 포함한다. 비지도 학습은 태그가 지정되지 않은 데이터의 패턴과 추세를 이해하여 정보를 얻는다. 일부 알고리즘은 클러스터링, K-평균 클러스터링 및 가 우스 혼합 모델을 포함한다. 일부 실시예에서, 비신경망 계산 방법은 디스플레이 컨텐츠를 생성하는데 사용된다. 일부 실시예에서, 신경망은 다른 계산 방법 또는 알고리즘과 결합된다. 다른 계산 방법은 최적화 알 고리즘, 무차별 대입 알고리즘(brute force algorithm), 무작위 알고리즘 및 재귀 알고리즘을 포함한다. 알고리 즘은 임의의 수학적 연산이나 물리적 현상을 구현할 수 있다. “아바타”는 디지털 또는 시각적 환경에서 사용자의 캐릭터 또는 표현을 포함할 수 있는 컴퓨터 프로그램 또는 프로그램 인터페이스이다. 아바타는 시각적으로 사람과 유사할 수 있지만 기본 형태를 취할 수도 있다. 일부 실 시예에서, 아바타는 시각적 유사성을 전혀 갖지 않거나 테스트 또는 오디오 모드를 사용하여 사용자와 통신한다. 일부 실시예에서, 아바타는 사용자에게 제안하거나, 예측하거나, 작업 실행을 지원하기 위한 사용자 인터페이스 역할을 한다. 일부 실시예에서, 아바타는 사용자로부터 직접적인 영향을 받지 않고 작업을 실행하는 권한을 갖는다. 아바타는 AI 기반일 수 있다. 아바타는 신경망 또는 다른 딥 러닝 메커니즘을 사용할 수 있다. “탠덤 컴퓨팅”은 디스플레이 시스템이 복수의 소스로부터 디스플레이 컨텐츠를 표시하는 방법이며, 그 중 적 어도 하나는 확장된 디스플레이 시스템의 확장된 부분에 컨텐츠를 표시하는 원격 소스이다. 디스플레이 컨텐츠 는 다양하게 서로 상호작용할 수 있다.두 디스플레이 컨텐츠가 서로 상호작용하는 맥락에서 “상호작용”한다는 것은 디스플레이 시스템의 한 부분의 디스플레이 컨텐츠가 제2 부분의 디스플레이 컨텐츠에 동적으로 영향을 미치는 기능에 입력되고 그 반대의 경우 도 마찬가지라는 것을 의미하며, 즉 제2 부분의 디스플레이 컨텐츠는 제1 부분의 디스플레이 컨텐츠에 동적으로 영향을 미치는 기능(동일한 기능일 수 있음)에 입력된다. “렌더 병렬화”는 랜더링 작업을 분할하여 다양한 로컬 및 비로컬 계산 리소스에 분산할 수 있는 기능을 의미 한다. 그래픽은 체적 비디오, 신경 렌더링 또는 신경 복사 필드의 컨텐츠를 활용하여 컴퓨터 그래픽 기술 및 복 사 방정식을 포함하는 다양한 방식으로 렌더링될 수 있다. “그래픽 사용자 인터페이스” 또는 “GUI”는 사용자가 그래픽 및 시각적 방식으로 시스템 및 정보와 상호 작 용할 수 있도록 하는 디스플레이 시스템에 표시되는 임의의 인터페이스를 의미한다. GUI는 라디오 버튼, 토글 스위치, 드롭 다운 메뉴 또는 스크롤 바와 같이 사용자가 정보를 입력하는 다양한 방법을 포함할 수 있다. GUI 를 통해 사용자는 소프트웨어와 상호작용하거나 소프트웨어를 생성하거나 전자 장치와 상호 작용할 수 있다. “기능”은 컨텐츠의 조각을 가져와 컨텐츠의 다른 피스를 생성하거나 원본 컨텐츠에 주석을 달거나 수정하는 매핑이다. 기능은 매핑이나 작업을 구현하는 알고리즘일 수 있다. 기능은 컨텐츠의 다수의 피스를 가져와 컨텐 츠의 다수의 피스를 출력할 수 있다. 기능은 낮은 수준일 수 있으며, 예를 들어 수학적 연산 또는 이미지 처리 기능일 수 있다. 기능은 중간 수준일 수 있으며, 예를 들어 이미지를 가져와 장면 내에서 에지와 같은 특징을 검출할 수 있다. 기능은 컴퓨터 비전 지원 기능일 수 있다. 또는 기능은 컨텐츠의 특성을 강화할 수 있다. 기능 은 높은 수준일 수 있으며, 예를 들어 컨텐츠를 생성하거나 객체의 클래스를 검출하거나 입력 컨텐츠를 관찰하 는 뷰어가 취할 미래 가능한 작업에 대해 예측할 수 있다. 일부 실시예에서, 기능은 미리 정의된다. 일부 실시 예에서, 기능은 사용자 정의된다. 기능은 신경망, 인코더/디코더 시스템, 변환기 또는 이들 예의 조합을 포함하 는 AI를 통해 실행될 수 있다. 기능은 다양한 데이터 또는 이미지를 최적화, 정렬 또는 주문하는 다양한 방법을 포함할 수도 있다. 기능은 결정적이거나 확률적일 수 있다. 이들은 다수의 입력을 받아 다수의 출력을 생성할 수 있으며, 이는 시간에 따라 달라질 수 있다. 계산 기능의 예는 환경 지도를 구성하거나 업데이트하거나 그 안에 사용자 또는 객체를 추적하는 동시 위치 및 매핑(SLAM) 기능이다. SLAM 알고리즘은 카메라와 같은 감각 데이터를 입력으로 받아들이고 감각 데이터를 기반 으로 객체의 가장 가능성 있는 위치를 계산하는 것을 포함할 수 있다. 솔루션은 기대치 최대화 알고리즘 (expectation-maximalization algorithm)을 포함할 수 있다. 입자 또는 칼만(Kalman) 필터가 사용될 수 있다. 다른 기능은 머리 추적 사용 사례와 같이 객체 또는 사용자의 신체 부분을 추적하기 위해 사용될 수 있다. 추적 은 등속 모델로 구현될 수 있다. 용어 “그래픽 인텔리전스”, “지능 생성 컨텐츠” 또는 “생성 컨텐츠”는 입력이 적어도 하나의 입력 스트림 인 컨텐츠를 출력하는 기능을 의미한다. 입력 스트림은 디스플레이 시스템용으로 구성된 컨텐츠를 포함할 수 있 다. 그래픽 인텔리전스의 예는 디스플레이 이미지의 세트를 입력으로 사용하고, 입력을 사용하고 사용자가 해당 입력과 상호작용하기 위한 방법을 제안하는 다양한 주석을 갖는 제2 디스플레이 이미지를 출력하는 AI 모듈 또 는 기능이다. 출력 컨텐츠는 시각 데이터일 수 있다. 출력 컨텐츠는 다른 기능에 대한 입력으로 사용될 수 있다. 그래픽 인텔리전스는 또한 사용자, 사용자의 환경 또는 제조 창고, 자동차 주변 또는 다른 산업 설정과 같은 다른 환경의 감지 데이터를 입력으로 사용할 수 있다. “생성 기능”은 하나 이상의 입력 스트립을 입력으 로 받아 새 컨텐츠를 출력하는 기능이다. 일부 실시예에서, 생성 기능은 또한 사용자의 입력, 프로필, 이력에 의해 영향을 받거나 파라미터화된다. 사용자 프로필은 사용자, 예를 들어 관심 분야, 목표, 원하는 시청 컨텐츠, 인구 통계에 대한 정보를 포함한다. 사용자 이력은 특정 애플리케이션 또는 애플리케이션의 세트의 사 용자에 의해 만들어지는 이력 사용이다. 이는 예를 들어 검색 이력, 이메일 수신자 목록, 특정 기간동안 사용자 가 본 미디어 목록 등일 수 있다. “협업 소프트웨어 애플리케이션”은 복수의 사용자가 이를 통해 서로 상호작용하는 애플리케이션이다. 상호작 용은 동시적이거나 비동시적일 수 있다. 예로는 원격 회의 또는 웹 회의, 온라인 강좌, 다인원 게임, 제어 센터 의 다양한 애플리케이션 또는 원격 운영 상황, 웹 세미나 또는 다른 원격 학습 환경을 포함한다. 협업 소프트웨 어 애플리케이션은 공유된 시각적 환경에서 사용될 수 있다. 본 설명에서, “실시예” “일 실시예” 또는 유사한 단어나 문구에 대한 참조는 설명되는 특징, 기능, 구조 또 는 특성이 여기에 소개된 기술 또는 발명의 예임을 의미한다. 본 명세서에서 이러한 문구가 등장한다고 해서 반 드시 모두 동일한 실시예를 지칭하는 것은 아니다. 한편, 본 명세서에서 언급된 실시에는 반드시 상호 배타적인것은 아니다. 본 명세서에서 설명된 다양한 실시예는 예시적인 블록도, 흐름도 및 다른 예시의 관점에서 설명된다. 본 문서를 읽은 후 당업자에게 명백해지는 바와 같이, 예시된 실시예 및 그 다양한 대안은 예시된 예에 국한되지 않고 구 현될 수 있다. 예를 들어, 블록 다이어그램 및 그에 따른 설명은 특정 아키텍처 또는 구성을 요구하는 것으로 해석되어서는 안된다. 본 개시의 모든 예시, 도면 및 예는 여기에 소개된 기술의 선택된 버전을 설명하며, 여기에 소개된 기술의 범위 를 제한하려는 의도는 없다. 추가적으로, 본 개시 전체에 걸쳐, 용어 “임의로 조작된”은 본 발명 또는 본 발 명의 구성요소가 본 발명의 또는 본 발명 내의 특정 구성요소의 목적 및 의도를 달성하도록 하는 하나 이상의 구성요소를 갖는 임의의 형상, 크기, 재료, 특징, 유형 또는 종류, 배향, 위치, 수량, 구성요소 및 구성요소의 배열을 의미한다. 이러한 모든 구성요소 및 소프트웨어는 원하는 프로필을 제공하도록 임의로 조작될 수 있다. 본 명세서에서 사 용된 “임의의 파라미터 변화”는 파라미터의 변화, 변경, 변조, 프로그래밍, 벤치마킹, 최적화 및/또는 제어를 의미하며, 이는 다음 변화 중 하나 또는 복수를 포함할 수 있다: 대역폭, 채널 용량, 밝기, 초점 평면 깊이, 시 차, 권한 수준, 센서 또는 카메라 감도, 주파수 범위, 편광, 데이터 속도, 기하학 또는 배향, 시퀀스 또는 타이 밍 배열, 런타임 또는 다른 물리적 또는 계산적 특성. 기능, 시각적 템플릿, 그래픽 사용자 인터페이스, 입력 스트림 수신 및 입력 스트림 생성과 같은 본 명세서에서 설명된 일부 기능은 하나 이상의 모듈에서 구현될 수 있다. 모듈은 기능을 구현하기 위한 하드웨어 및/또는 소 프트웨어를 포함한다. 예를 들어, 이러한 기능은 하나 이상의 비일시적 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 코드를 실행하는 하나 이상의 프로세서를 갖는 모듈을 통해 구현될 수 있다. 일부 실시예에서, 기능은 전용 하드웨어(예를 들어, ASIC, FPGA)를 갖는 모듈을 통해 적어도 일부가 구현된다. 일부 실시예에서 모듈은 구성요소를 공유할 수 있다. 예를 들어, 제1 기능 모듈 및 제2 기능 모듈은 모두 공통 프로세서를 활용하거나 (예를 들어 시분할(time-share) 또는 멀티 스레딩(multithreading)을 통해) 공통 컴퓨터 저장 매체(예를 들어, 상이한 메모리 위치)에 저장된 컴퓨터 실행 가능 코드를 가질 수 있다. 어떤 경우에는 모듈이 하드웨어 모듈 또는 소프트웨어 모듈로 식별될 수 있다. 하드웨어 모듈은 모듈의 기능을 구현하기 위한 하드웨어를 포함하거나 공유한다. 하드웨어 모듈은 소프트웨어를 포함할 수 있으며, 즉 소프트웨 어 모듈을 포함할 수 있다. 소프트웨어 모듈은 예를 들어 비일시적 컴퓨터 판독 가능 저장 매체에 저장될 수 있 는 정보를 포함한다. 일부 실시예에서, 정보는 하나 이상의 프로세서에 의해 실행 가능한 명령을 포함할 수 있 다. 일부 실시예에서, 정보는 FPGA와 같은 하드웨어를 구성하기 위해 적어도 부분적으로 사용될 수 있다. 일부 실시예에서, 기능, 시각적 템플릿, 그래픽 사용자 인터페이스, 입력 스트림 수신 및 입력 스트림 생성과 같은 기능을 구현하기 위한 정보는 소프트웨어 모듈로 기록될 수 있다. 예를 들어, 기능은 저장 매체에서 소프트웨어 모듈을 읽고 이를 하나 이상의 프로세서로 실행함으로써 또는 저장 매체로부터 소프트웨어 모듈을 읽고 하드웨 어를 구성하기 위해 정보를 사용함으로써 구현될 수 있다. 이전 섹션에 설명된 프로세스, 방법 및 알고리즘 각각은 컴퓨터 하드웨어를 포함하는 하나 이상의 컴퓨터 시스 템 또는 컴퓨터 프로세서에 의해 실행되는 코드 구성요소로 구현되고 완전히 또는 부분적으로 자동화될 수 있다. 프로세스 및 알고리즘은 특정 애플리케이션회로에서 부분적으로 또는 전체적으로 구현될 수 있다. 위에 설명된 다양한 특징 및 프로세스는 서로 독립적으로 사용될 수 있거나 다양한 방식으로 결합될 수 있다. 상이한 결합 및 서브 결합은 본 개시의 범위 내에 속하도록 의도되었으며, 특정 방법 또는 프로세스 블록은 일부 구현 에서 생략될 수 있다. 추가적으로, 문맥상 달리 지시하지 않는 한, 본 명세서에 설명된 방법 및 프로세스는 임 의의 순서로 제한되지 않으며, 이와 관련된 블록 또는 상태는 적절한 다른 순서로 수행될 수 있거나 병렬로 또 는 일부 다른 방식으로 수행될 수 있다. 블록 또는 상태는 개시된 예시적인 실시예로부터 추가되거나 제거될 수 있다. 특정 작업 또는 프로세스의 성능은 단일 기계 내에 있을 뿐만 아니라 여러 기계에 걸쳐 배포되는 컴퓨터 시스템 또는 컴퓨터 프로세서에 분산될 수 있다. 본 명세서에 사용된 용어 “또는”은 포괄적인 또는 배타적인 의미로 해석될 수 있다. 또한, 리소스, 작업 또는 구조의 설명을 단수로 읽어 복수를 배제해서는 안된다. 달리 구체적으로 언급되거나 사용된 문맥 내에서 다르게 이해되지 않는 한 특히 “할 수 있다(can)”, “할 수 있다(could)”, “할 수 있다(might)” 또는 “할 수 있 다(may)”와 같은 조건부 언어는 일반적으로 특정 실시예가 다른 실시예가 포함하지 않는 특정 특징, 요소 및/ 또는 단계를 전달하려는 의도이다.본 문서에서 사용된 용어 및 문구 및 그 변형은 별도로 명시하지 않는 한 제한이 아닌 개방형으로 해석되어야 한다. “기존의(conventional)”, “전통적인(traditional)”, “정상의”, “표준”, “알려진”과 같은 형용 사 및 유사한 의미의 용어는 설명된 항목을 특정 기간 또는 특정 시점에 사용 가능한 항목으로 제한하는 것으로 해석되어서는 안되지만, 대신 현재 또는 미래의 어느 시점에나 이용 가능하거나 알려질 수 있는 기존, 전통적인, 정상인, 또는 표준 기술을 포괄하는 것으로 읽어야 한다. 어떤 경우에는 “하나 이상”, “적어도”, “그러나 이에 제한되지 않음” 또는 다른 유사한 문구와 같은 확대된 단어 및 문구가 존재한다고 해서 이러한 확장 문구가 없을 수 있는 경우에 더 좁은 경우가 의도되거나 필요하다는 의미로 해석되어서는 안된다. 도 1은 모든 개시 도면 전체에 걸쳐 사용되며 사전 요소 또는 용어집 요소(glossary element)의 역할을 하는 요 소를 나타내는 아이콘을 도시한다. 도 1에서, 아이콘은 본 개시에 설명된 디스플레이 시스템의 일반 사용자 를 도시한다. 용어 “사용자”는 위에 정의된다. 아이콘은 다른 사용자와 협력하는 사용자를 도시한다. 협업 소프트웨어 애플리케이션은 원격 회의, 온라인 교육 플랫폼, 다중 사용자 게임 또는 엔터테인먼트, 동시 스트리 밍을 포함한다. 협업 사용자는 공유된 시각적 환경에서 서로 상호 작용할 수 있다. 또한 시각적 환경에서 다양 한 시간에 비동기적으로 상호 작용할 수도 있다. 아이콘은 소스를 가져온 입력 스트림을 나타낸다. 입력 스트림은 시각적 컨텐츠, 메타데이터, 프로그래밍 코 드, 텍스트 데이터, 데이터베이스 정보, 수학적 양, 오디오 데이터 또는 수치 데이터와 같은 임의의 컨텐츠일 수 있다. 또한, 데이터 스트림의 형식은 임의적이며 예를 들어 압축 또는 압축 형식, 벡터 또는 비트맵 형식을 포함할 수 있다. 아이콘은 원격 또는 로컬일 수 있는 일반 소스를 나타낸다. 소스는 표시할 데이터 또는 메타데이터를 제공할 수 있다. 소스는 또한 데이터 또는 메타데이터에 대해 작동할 수 있다. 일반 소스, 로컬 소스 또는 원격 소스는 데이터를 디스플레이 시스템으로 전송하기 전에 데이터에 대해 작동할 수도 있다. 아이콘은 로컬 소스를 나 타낸다. 로컬 소스는 워크스테이션, 랩탑, 데스크탑 컴퓨터; 및 확장된 디스플레이의 메인 부분에 대한 컨텐츠 에 물리적으로 연결되고 이를 생성하는 마이크로컨트롤러 및 마이크로컨트롤러 어레이를 포함한다. 아이콘은 원격 소스를 나타낸다. 원격 소스는 인터넷, IoT, 원격 서버, 확장된 네트워크, 분산 네트워크 또는 에지 장치 에 대한 다른 컴퓨터를 포함한다. 원격 소스는 “간접 소스”라고도 불릴 수 있으며, 즉 원격 소스는 접선 또는 확장된 정보 또는 확장된 디스플레이의 확장된 부분에 대한 디스플레이 컨텐츠를 제공한다. 원격 소스는 확장 디스플레이의 메인 부분에 있는 디스플레이 컨텐츠를 입력으로 사용하고 기능을 사용하여 해당 디스플레이 컨텐 츠에 대해 작동하며 기능의 결과를 출력하는 로컬 소스에 직접 연결되지 않은 계산 모듈도 포함하여 출력이 확 장된 디스플레이 시스템의 확장된 부분의 디스플레이 컨텐츠에 영향을 미치거나 그 일부가 된다. 즉, 원격 소스 는 메인 부분의 디스플레이 컨텐츠가 로컬 소스에 의해 어떻게 생성되는지에 대한 정보 없이 확장된 부분의 디 스플레이 컨텐츠에 영향을 미치기 위해 확장된 디스플레이의 메인 부분의 디스플레이 컨텐츠를 사용할 수 있다. 아이콘은 일반적인 디스플레이 시스템을 나타낸다. 본 명세서에 설명된 실시예에서, 디스플레이 시스템은 확 장된 디스플레이 시스템이지만, 당업자는 임의의 디스플레이 시스템에서 사용하기 위해 이 설명을 적응시키고 실행할 수 있다. 일부 실시예에서, 디스플레이 시스템은 컨텐츠로서 디스플레이하기 위한 데이터를 순수하게 수 신한다. 일부 실시예에서, 이는 데이터를 처리할 수도 있다. 디스플레이 시스템은 디스플레이 컨텐츠에 영향을 미치도록 동기화되는 마이크 또는 스피커와 같은 오디오 시스템을 포함할 수 있다. 이는 디스플레이 시스템에 통합될 수 있다. 아이콘은 디스플레이 시스템과 쌍을 이루는 로컬 소스를 나타낸다. 예는 컴퓨터 모니터가 있는 워크스테이션이다. 아이콘은 표시되는 일반 이미지 또는 디스플레이 컨텐츠를 나타낸다. 아이콘은 원격 소스로부터 생성되 는 일반 이미지 또는 디스플레이 컨텐츠를 나타낸다. 이미지는 독립적인 디스플레이 컨텐츠일 수 있거나, 이는 더 큰 디스플레이 컨텐츠의 하위 섹션일 수 있으며, 나머지는 다른 소스에서 가져온다. 아이콘은 하나의 디 스플레이 컨텐츠의 적어도 일부가 제2 디스플레이 컨텐츠의 적어도 일부와 중첩하는 층의 세트 또는 다층 그래 픽 정보를 나타낸다. 층의 수는 임의적일 수 있으며, 예를 들어 2층, 3층, 6층, 8층 등일 수 있다. 일부 실시예 에서, 초점 깊이와 같은 측 특성은 조정 가능하다. 아이콘은 일반적인 입력 장치를 나타낸다. 아이콘은 사람, 사용자 또는 환경에 대한 정보를 캡처하고 해당 정보와 통신하는 일반 센서를 나타낸다. 일반 센서는 카메라를 포함할 수 있다. 아이콘은 일반적인 카 메라 또는 카메라 시스템을 나타낸다. 아이콘은 적어도 하나의 데이터 스트림에 작용하는 기능을 설명하는 블록 다이어그램 아이콘을 나타낸다. 아이콘은 지정된 입력에 기초하여 원하는 출력을 생성하는 일련의 연결된 기능 또는 위젯 블록을 나타낸다.아이콘은 일반 주석을 나타낸다. 이는 예를 들어 다층 디스플레이에 나타나는 텍스트 또는 그래픽을 포함하 거나, 이는 주석을 생성하는 특별 기능으로 사용될 수 있다. 아이콘은 일반 AI 모듈을 나타낸다. 예시적인 AI 모듈은 신경망, 변환기 또는 다른 딥 러닝 또는 ML 알고리즘을 포함할 수 있다. AI 모듈은 예를 들어 각각 자신의 출력 컨텐츠를 다른 것의 입력에 공급함으로써 서로 상호작용하는 여러 AI 모듈을 포함할 수 있다. 일부 실시예에서, AI 모듈은 상호 관련된 작업, 예를 들어 영화 작성을 수행하는 여러 AI 모듈을 포함하여 하나의 모 듈이 오디오 컨텐츠와 다른 시각적 컨텐츠를 생성하고 오디오 컨텐츠가 비디오 컨텐츠에 영향을 미치고 그 반대 의 경우도 마찬가지이다. 일부 실시예에서, 다수의 AI 모듈은 개별 작업을 병렬로 수행하도록 구성된다. 일반적 으로, “계산 모듈”은 지정된 방식으로 입력을 처리하도록 구성된 장치이다. 계산 모듈은 특정 기능을 갖는 경 향이 있으며 일반적으로 예를 들어 컴퓨터의 일반 프로세서와 다르다. 아이콘은 일반적인 기하학적 변환 기능을 나타낸다. 기하학적 변환 알고리즘의 예는 포즈 워핑 알고리즘 (pose warping algorithm)이다. 포즈 또는 모션 워핑은 일련의 객체 위의 지점의 위치를 비교하고 동적 시계열 (예를 들어 음성 인식에도 사용될 수 있음) 알고리즘을 사용하여 해당 거리를 최적화하는 것을 포함할 수 있다. 변환 기능은 스플라인 기반으로 다양한 파라미터 곡선을 변환할 수도 있다. 이러한 변환 기능 또는 알고리즘은 보폭 워핑, 관점 워핑, 배향 워핑, 변형 워핑 또는 모션 워핑에도 사용될 수 있다. 기하학적 변환 기능은 비디 오 게임의 캐릭터에 대한 데이터와 같은 합성 데이터에 작용할 수도 있거나, 이는 카메라로 캡처되고 기계 학습 알고리즘에 기초하여 환경으로부터 분할된 사용자의 이미지와 같은 실제 데이터에 작용할 수도 있다. 본 개시에서, 기하학적 변환은 시프트, 회전, 아핀 변환, 호모그래프 변환을 포함하는 임의의 종류의 기하학적 변환이다. 기하학적 변환은 또한 계산 재매핑을 포함한다. 예를 들어, 깊이 재매핑은 사용자와 카메라의 거리를 처리하여 올바른 물리적 또는 기하학적 비율을 유지하는 가상 이미지를 랜더링하는 예이다. 깊이 재매핑은 동형 (isomorphism) 또는 호모그래피를 사용하여 재매핑을 평가할 수 있다. 기하학적 변환은 또한 어안 왜곡(fisheye distortion) 또는 배럴/핀쿠션 왜곡을 포함하는 광학 시스템에 의해 발생할 수 있는 왜곡을 제거하는데 사용되 는 디워핑을 포함한다. 아이콘은 사용자 정의 작업 또는 사용자 정의 모델/템플릿을 나타낸다. 여기서 소프트웨어 기술의 임의의 구성요소는 사용자 정의될 수 있다. 도 2a 내지 2d는 소프트웨어 생성, 예측 애플리케이션, 단일 사용자 및 협업 애플리케이션 및 가상 디스플레이 시스템에서 사용하도록 구성된 로컬 및 원격 소스를 모두 통합하는 소프트웨어 애플리케이션을 포함하는 소프트 웨어 애플리케이션의 실시예를 도시한다. 도 2a는 확장된 디스플레이 시스템에서 사용하도록 구성된 시각적 컨턴츠를 생성하기 위한 “스트림 위버 (stream weaver)”(STW)라고 하는 소프트웨어 생성 애플리케이션을 묘사한다. 이는 다양한 소스로부터 데이 터를 수집 및 컴파일하고, 기능을 사용하여 상기 데이터에 대해 작동하고, 템플릿에 따라 상기 데이터 를 사용자에게 표시하는 것과 관련된 일련의 단계를 포함한다. 단계 t1은 데이터가 추출되는 N 소스의 세트 를 설명한다. 소스는 원격, 로컬 또는 두 유형의 임의의 적절한 조합일 수 있다. 소스는 비디오 입력 스트림, 카메라 입력 스트림, 게임 입력 스트림, 애플리케이션 또는 임의의 코드 또는 장치 연결일 수 있다. 단 계 t2는 소스로부터 가져온 데이터를 처리하는 기능의 세트를 설명한다. 기능은 소스의 메타데이터를 포함 하는 소스의 입력 스트림에 대해 작동할 수 있다. 단계 t3은 선택된 시각적 템플릿에 대해 구성된 단계 t2 의 기능에 의해 생성된 디스플레이 컨텐츠를 보여주는 프로세스를 설명한다. 내보낸 시각적 템플릿은 내장 된 선택 또는 사용자 정의될 수 있다. 다양한 시각적 템플릿 옵션 및 특징은 디스플레이 유형 또는 그래픽 사양, 가상 이미지 또는 초점 평면의 배열, 해상도, 밝기 및 깊이 해상도를 포함한다. 일부 실시예에서, 기능 은 시각적 템플릿을 선택한 후 또는 동시에 선택된다. 단계 t2에서 생성된 정보를 정정, 수정 또는 개선하 기 위해 오류 정정 블록이 추가될 수 있다. 기능 및 소스를 순서대로 구성할 필요는 없으며, 소스의 수는 사용되는 기능의 수와 동일할 필요가 없다. 일부 실시예에서, 기능은 입력으로서 다수의 소스를 취한다. 예를 들어, 기능 “F4”는 “소스 1”, “소스 2” 및 “소스 3”으로부터의 입력 스트림을 입력으로 사용할 수 있다. 기능은 복합적으로 작동할 수도 있다. 예를 들 어, 기능 “F8”은 기능 “F7”의 출력을 입력으로 사용할 수 있다. 일부 입력 스트림은 그에 대해 작동하는 임 의의 기능 없이 내보내기 템플릿에 통합될 수 있다. 일부 실시예에서, 기능이 없으며 모든 소스가 시각적 템플 릿에 직접 통합된다. 일부 실시예에서, 기능은 기능의 출력이 입력으로서 기능에 공급될 수 있는 피드백 루프를 갖는다. 예를 들어 안정성, 반복 기능, 진동 또는 비선형 역학을 위해 피드백이 필요한 경우가 이에 해당할 수 있다.기능 자체는 기본 또는 확장된 수학 연산 및 계산 또는 그래픽 연산을 포함한다. 다른 기능은 자기 주의 변환기 또는 신경망과 같은 ML 아키텍처를 포함한다. 일부 실시예에서, 신경망은 사전 및 훈련 데이터를 포함한다. 기 능은 일반적으로 시간에 따라 달라지며 작업 시 사용자 입력이나 디스플레이 시스템에서 사용자 작업 이력에 따 라 달라진다. 일부 실시예에서, 전체 기능 세트는 시스템에 입력된 프롬프트에 기초하여 생성 신경망에 의해 결정될 수 있다. 이를 통해 컴퓨터는 해당 프롬프트에 따라 사물을 재구성하고 사용자에게 시각적으로 표시할 수 있는 방법을 선 택할 수 있다. 예를 들어, 하나의 프롬프트는 “내 검색과 관련된 1000 개의 비디오 결과에 대한 조감도를 제공 하고 가장 인기 있는 항목을 강조 표시한다”일 수 있다. 이러한 프롬프트에서, 컴퓨터는 N = 1000을 정의하고 이를 모든 기능을 통해 집합적으로 응집력 있게 전송하고 상이한 깊이 층에 주석을 표시하기 시작한다. 더 간단한 다른 예에서, 사용자는 게임 스트림과 같은 메인 컨텐츠 소스만 가질 수 있으며, 사용자는 UI를 탐색 하고 이 소스와 상호작용하기 위해 다른 스트림을 선택(또는 다른 스트림을 생성)할 방법을 선택할 수 있다. 예 를 들어, 메인 중앙 모니터의 각 프레임에 대해 두 측면 모니터는 중앙 이미지의 아웃페인팅 프레임, 중간 색상, 평균 색상, 2초 지연 또는 반전된 복제본 또는 메인 게임 스트림의 기하학적으로 변환된 버전을 표시하도 록 선택할 수 있다. 이 경우에 언급된 것처럼, 다른 두 모니터는 중앙 모니터에 표시된 컨텐츠에 따라 달라진다. 스트림은 반드시 비디오 스트림일 필요는 없지만 대화형 인터페이스일 수 있다. 이는 비디오 편집 소 프트웨어에서 수행된 비디오 혼합과 여기에서 함께 혼합된 여러 대화형 스트림 사이의 눈에 띄는 차이점이다. 이들 기능의 추가 카테고리 및 가계도는 도 4a 내지 4b, 5a 내지 5j 및 6a 내지 6j에 설명될 것이다. 본 명세서 전반에 걸쳐 설명되고 도면에서 참조된 기능, 시각적 템플릿, 그래픽 사용자 인터페이스, AI 및 다른 알고리즘은 소프트웨어, 하드웨어 또는 이들의 임의의 적절한 조합으로 구현될 수 있다는 것이 이해되어야 한다. 소프트웨어는 처리 장치에 의해 실행될 때 처리 장치 자체 또는 처리 장치에 작동 가능하게 연결된 하드 웨어에서 설명된 결과를 생성하는 메모리(예를 들어, 비일시적 컴퓨터 판독 가능 저장 매체)에 저장된 기계 판 독 가능 코드로 구성될 수 있다(예를 들어, 메모리, 확장 디스플레이 시스템). 도 2b는 중앙 디스플레이를 보고 있는 사용자에 의한 과거 및 현재 이벤트 또는 동작을 기능에 입력 함으로써 디스플레이 시스템을 갖는 로컬 소스가 사용자가 취할 수 있는 잠재적인 작업에 대응하는 사용자에 게 컨텐츠를 표시하는 예측 소프트웨어 애플리케이션 “펀넬 확장기(funnel expander)” 또는 “이벤트”를 나 타낸다. 일부 실시예에서, 다수의 원격 또는 로컬 소스가 사용된다. 과거의 동작은 좁거나 덜 눈에 띄는 디스플 레이(9A)에 표시될 수 있고 잠재적인 동작은 더 넓은 디스플레이(9B)에 표시될 수 있으므로 과거와 현재의 동작 은 미래 가능성의 확장 또는 펀넬을 표시하는데 도움이 된다. 일반 입력 장치, 카메라 또는 센서에 의해 캡처된 사용자에 의한 현재 입력 및 피드백이 처리된다. 디스플레이 컨텐츠는 또한 의미있는 방식으로 사용자 이력을 나타내는 일부 인포그래픽을 포함할 수도 있다. 사용자 이력은 사용된 애플리케이션이, 사용된 애플리케이션의 특징, 애플리케이션이 사용된 기간, 순서 대로 사용된 애플리케이션, 수행된 동작, 본 디스플레이 컨텐츠, 기간 및 타임 스탬프 및 생산성과 같은 일부 지표에 대해 측정될 때 그 중요성을 포함한다. 기능은 사용자가 참여할 가능성이 가장 높은 예측된 동작의 세트를 출력으로 생성할 수 있다. 일부 실시예에서, 제안된 컨텐츠는 확률적 분석과 상이한 방법에 의해 공식화 된다. 방법은 이벤트 기반, 우선순위 기반, 시간 기반, 사용자에 의한 미리 선택된 설정 기반 또는 임의의 적절 한 방법일 수 있다. 일부 실시예에서, 사용자는 사용자 입력을 보조하거나 예측된 동작을 실행할 수 있는 권한을 부여받을 수 있는 아바타와 상호작용한다. 이러한 방식으로 사용자는 여러 병렬 프로세스에서 멀티 태스킹을 수행할 수 있다. 아바타는 시각화, 텍스트 명령의 세트 또는 사용자에게 보이지 않는 서브루틴일 수 있다. 일부 실시예에서, 기능은 확률적이어서, 가장 빈번하게 일어나거나 현재 동작 또는 디스플레이 컨텐츠와 가장 관련이 있는 동작이 다른 동작보다 더 크게 가중치가 부여된다. 일부 실시예에서, 기능은 시간 요인에 기초하여 최근의 과거로부터의 동작은 먼 과거의 동작보다 더 크게 가중치가 부여된다. 일부 실시예에서, 신경망 또는 변 환기는 소프트웨어의 예측 동작을 결정하거나 개선하는데 도움을 주기 위해 사용된다. 일부 실시예에서 예측 특징은 사용자의 현재 동작의 성공에 대한 추정 또는 사용자가 현재 동작을 완료하는데 걸린 시간, 사용자의 일정이나 달력이 어떻게 영향을 받을 수 있는지를 포함한다. 달력을 입력으로 사용하면 예 측 특징이 다양한 작업을 완료하기 위한 대체 시간을 제안할 수 있다. 이 실시예는 커서 또는 사용자 입력이 있는 무한 스크롤로서 확장된 디스플레이 스크린을 사용하여 시간과 공간 모두에서 4차원 스크롤링을 허용한다. 일부 실시예에서, 사용자는 확장된 디스플레이 시스템의 여러 부분 또는 깊이에서 병렬 가능성을 볼 수 있고 게임화된 메카닉으로 원하는 옵션을 간단히 선택할 수 있다. 표시되는 병렬 가능성은 현재 사용자 작업에 따라 다르므로 실시간으로 동적으로 변경될 수 있다. 이 실시예는 컴퓨터가 데이 터 스트림을 만들 때 컴퓨터와 거의 실시간 상호작용(앞뒤로 “탁구와 같은” 피드백)을 하면서 사용자가 컴퓨 터에 의해 생성된 다양한 가능성을 가능한 한 많이 볼 수 있도록 돕는다. 예를 들어, 오늘날 단어 문서를 작성 하려면 한 줄씩 써야 하거나, 텍스트가 컴퓨터에 의해 생성된 경우 사용자는 한 번에 하나의 변형을 읽거나 한 줄씩 편집하거나 다른 변형을 요청해야 한다. 여기에 설명된 실시예에서, 변형의 확장된 세트는 확장된 디스플 레이의 상이한 부분에 표시되므로 사용자는 읽는 동안 어떤 변형이 텍스트에 짜여져 있는지 실시간으로 선택할 수도 있다. 다른 예는 롤링 스크린 실시예이다. 오늘날 사용자는 웹 사이트, 컴퓨터 코드 또는 수직으로 긴 데이터를 스크 롤할 때 스크린의 수직 해상도로 제한된다. 3 개 모니터 설정의 경우, 이 배열은 수직 데이터를 더 많이 보는데 도움이 되지 않는다. 펀넬 확장기를 사용하면, 사용자는 해당 수직 데이터의 연속으로 측면 모니터 또는 전방 깊이 층을 갖는다. 펀넬 확장기는 또한 모니터 내부, 다른 깊이 층 또는 주변 FoV에서 다양한 가능성 또는 병렬 가능성을 제안할 수 있다. 예를 들어, VR 헤드셋에서, 수직 기사를 읽을 때, 사용자는 주변에서 볼 수 있는 메 인 기사 옆에 나타나는 여러 다른 평행 기사를 볼 수 있다. 펀넬 확장기의 더 자세한 내용은 도 7a 내지 7g에 제공될 것이다. 도 2c는 하나 이상의 사용자가 도 2a 또는 2b의 실시예에 의해 생성되는 소프트웨어와 상호작용하는 환경에서 소프트웨어 애플리케이션의 사용을 나타낸다. 사용자는 동일한 컨텐츠와 다양한 방식으로 상호작용할 수 있으며, 즉 컨텐츠는 제2 사용자(1B)에 대한 포맷인 포맷 B와 비교하여 상이한 포맷의 포맷 A 또는 시각화로 제 1 사용자(1A)에게 표시될 수 있다. 제1 사용자(1A)는 중앙 디스플레이 외에 다층 디스플레이 이미지, 호버링 그래픽 및 2D 확장을 생성하는 디스플레이 시스템을 사용한다. 사용자는 일반 입력 또는 센서와 같은 임의의 수단을 통해 정 보를 입력한다. 사용자 입력 또는 디스플레이 컨텐츠를 결정하는 기능에 기초하여, 다층 디스플레이 이미지 각각의 디스플레이 컨텐츠는 기능을 통해 사용자가 볼 수 있는 영역의 최전방으로 앞뒤로 밀릴 수 있다. 디 스플레이는 로컬 소스에 연결될 수 있다. 일부 실시예에서, 다중 디스플레이 시스템은 원격 소스, 예를 들어 인터넷을 통해 연결된다. 제2 사용자(1 B)는 제1 사용자(1A)와 유사한 컨텐츠를 보여주는 로컬 소스 및 디스플레이 시스템과 상호작용한다. 포맷 B 의 디스플레이 컨텐츠는 상이한 사용자와 상이한 템플릿을 사용하여 표시될 수 있다. 예를 들어, 일부 실시예에 서 시각적 템플릿은 다양한 기능을 통해 각각 상호작용하도록 구성된 제1 이미지와 복수의 다층 이미지의 세 트(11A 및 11B)로 구성될 수 있다. 예를 들어, 사용자(1B)는 마우스와 같은 일반 입력을 사용하여 비디오 게임 환경을 통해 스크롤할 수 있으 며, 비디오 게임 캐릭터가 환경 내에서 이동할 때 환경 내 상이한 깊이에 각각 대응하는 상이한 층이 사용자 (1B)로부터 더 가까이 오거나 더 멀리 이동한다. 제1 사용자(1A)는 게임의 팀원일 수 있고 그의 팀원의 건강에 대한 주석으로서 호버링 그래픽을 사용할 수 있다. 다른 예에서, 원격 회의 통화 애플리케이션은 한 층에 사용자를 나타내고 다른 층에는 다양한 통화 특징, 화이 트보드, 공유 환경 또는 메모를 나타낸다. 다양한 디스플레이 컨텐츠 및 디스플레이 층은 기능을 통해 서로 상 호작용한다. 예를 들어, 사용자(1A)의 호버링 그래픽은 다층 디스플레이 구성에서 다른 사용자(1B)의 비디 오를 포함하는 이미지의 세트에 기초하여 정보를 제시할 수 있다. 도 2d는 다수의 사용자가 원격 소스 및 로컬 소스를 통해 디스플레이 컨텐츠와 상호작용하는 실시예를 강조한다. 일부 실시예에서, 사용자가 단 한 명이지만, 사용자가 여러 명일 수도 있다. 도 2d에서, 제1 사용자 (1A)는 다층 이미지의 세트에서 한 쌍의 디스플레이 이미지를 본다. 다층 이미지의 세트의 후방 층은 원격 소스에 의해 생성될 수 있으며 다수의 사용자가 동일한 디스플레이 컨텐츠에 액세스하는 공유된 시각적 도메인에 대응할 수 있다. 원격 소스로부터의 입력 스트림은 표시되기 전에 기능에 의해 작동될 수 있다. 전방 층은 디스플레이 시스템에 연결된 로컬 소스에 의해 또는 디스플레이 시스템이 있는 로컬 소스에 의해 생성될 수 있다. 일부 실시예에서, 주어진 층 또는 이미지의 하위 섹션은 사용자의 입력, 이력 또는 설정에 기초하여 생성된다. 일부 실시예에서, 섹션은 연속적이지 않다. 일부 실시예에서, 하위 섹션은 개별 픽 셀 또는 픽셀의 세트이다. 이러한 공유된 시각적 도메인은 예를 들어 후방 층의 공통 공간에 대응하는 공유된 시각 환경 및 전방 층에서 생성된 공통 공간에 대한 관점 또는 윈도우일 수 있다.일부 실시예에서, 사용자로부터의 입력은 모션 추적, SLAM 입력 또는 디스플레이 시스템에 대한 사용자의 위치 또는 배향에 기초하여 장면을 동적으로 변경하는 배향 입력이다. 일부 실시예에서, 디스플레이 이미지의 하위 섹션은 후방 층에 영향을 미치는 기능에 입력된다. 일부 실시예에서, 데이터 소싱의 구분은 컨텐츠 의존적 대역폭, 이미지 모드 분석에 따라 달라진다. 사용자는 능동 사용자일 수 있고 윈도우를 조작할 수 있거나, 이들 은 수동 사용자일 수 있고 디스플레이 컨텐츠가 제품 또는 서비스를 소개하는 광고 사용 사례의 경우처럼 단지 결정된 컨텐츠를 경험할 수 있다. 도 2d의 일부 실시예에서, 예를 들어, 다수의 사용자가 상이한 환경에서 상이한 워크스테이션으로부터 확대된 가상 “클라우드” 이미지를 볼 수 있으며 로컬 워크스테이션은 디스플레이 컨텐츠의 상이한 윈도우를 공유 가 능한 볼 수 있는 구역으로 클라우드 이미지에 제공한다. 일부 실시예에서, 단일 사용자는 다수의 입력 소스로부 터 컨텐츠를 볼 수 있다. 일부 실시예에서, 디스플레이 시스템은 모바일 장치, 태블릿 또는 분산 네트워크에 영 향을 받는 메인 워크스테이션을 포함한다. 도 3a 및 3b는 도 2a의 소프트웨어 생성 프로그램에 대한 흐름도를 나타낸다. 도 3a의 흐름도는 단계 27에서 소스 정보 세트가 먼저 선택되거나 설명되는 것을 나타낸다. 그 다음 단계 28A에 서 해당 소스에 작용하는 기능이 설명되거나 선택된다. 일부 실시예에서, 기능은 하나 이상의 소스를 입력으로 취하고 다른 소스를 출력으로 생성한다. 그 다음 단계 29에서 시각적 템플릿이 설명되거나 선택된다. 일부 실시 예에서, 시각적 템플릿의 선택은 시각적 템플릿의 배향, 어떤 소스가 템플릿에 나타나는지 등과 같은 추가 기능 선택을 단계 28B에서 허용한다. 일부 실시예에서, 설명 또는 선택 사이의 오류 피드백 동작 단계 30A및 단계 30B는 선택의 오류, 불일치 또는 비호환성을 확인한다. 일부 실시예에서, 소프트웨어 생성 프로그램은 이러한 피드백 루프에서 소스, 기능 또는 템플릿의 선택을 비교함으로써 결과적인 소프트웨어를 최적화, 변경 또는 개 선하기 위한 제안을 한다. 이는 소프트웨어에 제공되는 프롬프트로 인해 발생할 수 있거나 또는 이는 사용자 또 는 다른 감각 입력에 기초하여 동적으로 발생할 수 있다. 마지막으로, 내보내기 인터페이스 스트림은 최종 인터페이스 또는 스트림의 형태를 정의하기 위해 사용자 또는 알고리즘에 의해 선택된다. 예를 들어 이는 주어 진 포맷 유형, 압축 비율 또는 파일 이름일 수 있다. 도 3b의 흐름도는 소스 설명 및 템플릿 설명이 단계 27A에서 동시에 발생하고 모든 잠재적인 기능이 단계 28에 서 별도의 기능 설명 블록에서 선택되는 대안적인 흐름도를 나타낸다. 그 다음 스트림은 단계 31에서 최종 사용 자를 위한 최종 내보내기 스트림으로 내보내 진다. 도 3a의 흐름도와 같이, 일부 실시예에서, 피드백 단계 30은 선택 사이에서 선택의 오류, 불일치 또는 비호환성을 확인하기 위해 오류 검사 모듈을 활용한다. 일부 실시예에 서, 소프트웨어 생성 프로그램은 소스, 기능 또는 템플릿의 선택을 비교함으로써 결과적인 소프트웨어를 최적화, 변경 또는 개선하기 위한 제안을 한다. 도 4a 및 4b는 스트림 위버(STW) 프로세스의 코어에 있는 파이프라인을 나타낸다. 이 파이프라인은 사용자가 소 프트웨어 애플리케이션을 생성하기 위한 GUI의 일련의 드랍 다운 메뉴일 수 있다. 그러나 GUI는 임의의 구성일 수 있으며 입력 스트림, 기능, 소스 및 시각적 템플릿에 대한 정보를 명확하게 표시하도록 구성될 수 있다. 도 4a에 도시된 STW 프로세스는 데이터 또는 입력 스트림이 검색되는 소스를 결정하기 위한 소스 풀링 단계 32로 시작한다. 프로세스는 기능 배열 단계 33으로 계속되며, 여기서 이전 단계에서 가져온 데이터 및 정보는 다양한 기능으로 처리된다. 즉, 이 단계에서, 기능이 선택되고, 기능에 대한 입력이 선택되고, 출력이 선택된다. 출력 은 기능 및 소스의 선택에 의해 자동으로 결정될 수 있다. 다음 단계는 템플릿 선택 단계 34이며, 이전 단계에 서 처리된 정보를 조합하기 위한 시각적 템플릿이 선택된다. 마지막 단계는 정보를 사용자 또는 다른 애플리케 이션으로 내보내는 내보내기 단계 35이다. 도 4a는 또한 예시적인 입력 스트림, 기능, 시각적 템플릿 및 내보내기 모드를 도시한다. 소스 세트는 카메 라, 비디오 또는 클립 ― 비디오 또는 카메라 소스는 임의적일 수 있으며 예를 들어 사용자의 비디오를 캡처하는 카메라에 제한되지 않음 ―, 음악 또는 사운드 녹음, UX 환경, GPS 또는 다른 매핑 데이터 , 주석이 있거나 없는 텍스트 문서, 웹사이트, 게이밍 애플리케이션, 메타데이터 또는 하 이퍼링크, 일반 데이터 스트림, 원격 소스(클라우드 기반 데이터와 같음), 기능의 출력, 또는 라 이브러리 또는 일반 센서 데이터를 포함하지만 이에 제한되지는 않는다. 기능은 개별 기능일 수 있거나 이들은 기능 블록으로 그룹화될 수 있다. 기능 블록 세트는 카메라 소스 기능 블록, UX- 또는 UI-소스 기능 블록, 텍스트-/주석-소스 기능 블록, 일반-소스 기능 블록 ― 기능은 임의적일 수 있거나 사용자 정의될 수 있음 ―, 엔진 소스 기능 블록 및 AI-생성 기능 블록을 포함하지만 이에 제한되지는 않는다. 이러한 기능 블록에서, 기능 자체는예를 들어 입력 스트림의 이해 또는 분류를 기반으로 AI가 생성한다. 예를 들어, 입력 스트림은 비디오일 수 있 으며, AI 기능은 먼저 비디오의 유형을 훈련 비디오 또는 엔터테인먼트 비디오로 분류한다. 그러면 다른 AI 기 능은 예상된 사용자의 원하는 애플리케이션을 기반으로 작업을 생성할 수 있다. 시각적 템플릿 세트는 호버링 그래픽, 다층 스크린, 에지 모드 확장 모드, 측면 2D 데스크탑 확장, 탠덤 확장 또는 가상 대역폭 디스플레이 ― 이미지의 적어도 일부가 원격 소스에 의해 생성되는 디스플레이 ―, 사용자 정의된 템플릿 및 AI 생성 템플릿을 포함하지만 이에 제한되지는 않는다. 이 템 플릿은 이전 단계에서 기능의 출력에 기초하여 자동으로 생성될 수 있다. 예를 들어, 주석을 포함하는 클릭 가 능한 훈련 비디오의 출력은 주석을 포함하고 주석이 있는 객체의 모션에 기초하여 자동으로 이동된 다수의 호버 링 그래픽이 있는 디스플레이일 수 있다. 호버링 그래픽은 뷰어의 눈이 물리적 디스플레이 시스템의 거리보다 가까운 거리에 수용되도록 디스플레이 컨텐츠를 보여줄 수 있다. 이러한 방식으로 호버링 그래픽은 디스플레이 시스템 자체보다 사용자에게 더 가깝게 나타난다. 이는 예를 들어 위상 공액, 역반사 또는 역굴절(투과 시 역반사) 요소를 사용하여 생성될 수 있으며, 이는 디스플레이 시스템으로부터의 광의 지점 소스가 사용자와 디스플레이 시스템 사이에 초점이 맞춰지도록 한 다. 다층 이미지는 뷰어의 눈이 상이한 깊이에 수용되고 결과적으로 뷰어가 초점이 맞춰지는 상이한 디스플레이 컨텐츠를 보도록 디스플레이 컨텐츠의 다수의 층을 보여준다. 이는 예를 들어 다수의 디스플레이 패널을 포함하 는 광의 편광 또는 이동한 경로 길이를 수정할 수 있는 전환 가능한 요소에 따라 광을 1회 또는 다수 왕복하기 위해 필드 전개 공동을 사용하여 생성될 수 있다. 에지 모드 확장기 및 2D 확장 템플릿은 뷰어의 FoV를 확장하는 가상 이미지를 생성한다. 이는 복수의 디스플레이 이미지로 시작하여 시스템을 빠져나가기 전에 상이한 방향으로 이동하는 경로를 따라 광을 향하게 함으로써 달성될 수 있다. 전체 깊이 평면에 걸쳐 코헤시브 이미지(cohesive image)를 형성하기 위해, 인간의 눈으로 볼 수 있는 것보다 작은 간격, 예를 들어 디스플레이 컨텐츠를 볼 때 20/20 비전 또는 20/40 비전을 갖 는 사람이 볼 수 있는 것보다 작은 간격이 되도록 복수의 이미지가 함께 타일링된다. 일부 실시예에서, 갭이 바 람직할 수 있다. 일부 실시예에서, 타일링은 다수의 방향, 예를 들어 수직 및 수평으로 발생한다. 일부 실시예 에서, 이미지 또는 데이터는 임의의 템플릿을 사용하여 확장된 FoV에서 공간적으로 분리된다. 타일 또는 공간적 으로 분리된 이미지는 사용자나 센서 입력 또는 다양한 계산 루틴에 따라 동적으로 위치를 변경할 수 있다. 일부 실시예에서, 에지 확장기 또는 확장된 FoV 템플릿은 확장된 디스플레이 시스템에서 다수의 물리적 모니터 를 사용한다. 일부 실시예에서, 이들은 가상 디스플레이 시스템에 의해 생성된 가상 이미지일 수 있다. 탠덤 확장 또는 가상 대역폭 디스플레이 템플릿은 디스플레이 컨텐츠의 일부에 대한 정보가 원격 소스에 의 해 수신될 때의 디스플레이이다. 정보는 디스플레이 컨텐츠 자체(예를 들어, 원격으로 렌더링된 디스플레이 컨 텐츠), 디스플레이 컨텐츠에 대한 메타데이터, 그래픽 설정에 대한 정보 또는 환경에 대한 데이터일 수 있다. 정보는 특정 애플리케이션에만 적용되거나 복수의 애플리케이션에 영향을 미칠 수 있다. 일부 실시예에서, 원격 소스에 의해 영향을 받는 디스플레이 컨텐츠의 분할은 사용자 설정, 애플리케이션 특징 또는 대역폭 제약에 따 라 동적으로 변경된다. 내보내기 단계의 결과는 상호작용 특징 또는 동적 게임 엔진 및/또는 대화형 매체를 갖는 예측 애플리케이 션, 상호작용 비디오(57A)(클릭 가능), 메타데이터, 데이터베이스, 새로운 UX(57B), 새로운 게임(57C)일 수 있 수 있다. STW에 의해 생성된 결과 애플리케이션은 확장된 디스플레이 시스템에 표시될 수 있다. 이들은 가상 디스플레이 시스템에 표시될 수 있다. 도 4b는 도 4a의 사용자 정의 또는 AI 생성 템플릿 옵션의 세부사항을 나타낸다. 이 프로세스에서, 템플릿 드롭 다운 메뉴는 사용자 정의 템플릿 또는 AI 생성 템플릿에만 초점을 맞춘다. 이들 중 하나가 선택되 면, 새로운 특성 드롭다운 메뉴가 나타낸다. 사용자는 특성 세트 중에서 선택하여 새로운 템플릿을 정 의한다. 특성은 디스플레이 컨텐츠의 형상, 배향 및 위치; 코어 해상도; 다양한 소스 또는 리서치에 대한 상이한 섹션의 할당을 포함한다. 예를 들어, 일부 실시예에서, 사용자는 디스플레이 이미지의 형상을 선택하고, 형상은 정사각 형, 직사각형, 임의의 사변형, 삼각형, 원 또는 거품(bubble) 또는 임의의 조합일 수 있다. 해상도는 고화질, 풀(full) 고화질, 와이드 울트라 확장된 그래픽 어레이, 쿼드(quad) 고화질, 와이드 쿼드 고화질 또는 울트라고화질과 같은 임의의 설정일 수 있다. 사용자 정의 시각적 템플릿은 도 4a에 도시된 시각적 템플릿의 조합일 수 있다. 특성 드롭다운 메뉴는 AI 생성 템플릿에 대한 AI 파라미터 세트를 포함할 수 있다. 예를 들어, 사용자 는 기능의 출력에 대해 수행할 다양한 AI 분석을 선택할 수 있다. 사용자는 AI 생성 템플릿이 먼저 출력의 대역 폭을 분석한 다음 모든 정보를 표시할 수 있는 크기의 2D 확장을 생성하기를 원할 수 있다. 또는 사용자는 이미 지 깊이 범위를 인식하거나 추정하도록 AI 생성 템플릿을 설정한 다음 예를 들어 깊이 층을 인간 시각 시스템의 호롭터(horopter)와 일치시켜 뷰어의 깊이 인식을 최적화할 깊이층이 있는 다수의 이미지를 생성할 수 있다. 사용자 정의 템플릿은 또한 결과 소프트웨어가 하나의 앱, 여러 앱을 통합할 수 있는지, 컴퓨터의 전체 작동 시 스템에 걸쳐 있는지, 인터넷 액세스를 포함하는지, 사용자 상호작용을 통해 능동 또는 수동 매체를 생성할 수 있는지를 포함하는 다양한 권한을 선택하기 위한 권한 드롭다운 메뉴를 포함할 수도 있다. 일부 실시예에서, 템플릿은 일반적인 동적 2D 기하학적 형상 또는 임의의 마스크일 수 있으며 동일한 2D 디스플 레이에 도시될 수 있다. 예를 들어, 디스플레이는 비디오를 표시하기 위해 삼각형으로 분할될 수 있으며, 다른 삼각형은 더 매력적인 포맷의 게임용 카메라 비디오 스트림이다. 일부 실시예에서, 사용자가 스크린에서 텍스트 파일을 읽을 때, 눈 추적 장치로부터의 입력은 사용자가 보고 있는 곳을 볼 수 있고 결과적으로 사용자의 시선 의 위치에 기초하여 강조된 영역을 제외한 나머지 디스플레이 컨텐츠를 자동으로 어둡게 할 수 있다. 일부 실시 예에서, 시선의 영역은 임의의 다른 방식으로 또는 다른 특성으로 렌더링될 수 있다. 예를 들어, 시선의 영역은 더 높은 그래픽 충실도로 렌더링될 수 있거나, 이는 사용자가 주변을 둘러볼 때 도구 옵션 세트를 추적할 수 있 으므로 사용자가 스크린의 FoV에서 보는 모든 곳에서 도구 세트에 더 쉽게 액세스할 수 있다. 일부 실시예에서, 마스크는 암시적 접근법을 갖고 디스플레이 컨텐츠의 분석에 기초하여 형상 또는 마스크를 생 성하는 내부 알고리즘 또는 AI 알고리즘에 기초하여 동적으로 변경될 수 있다. 다중 깊이층이 있는 일부 실시예에서, 사용자의 머리와 시선 위치를 따르고 사용자에게 스크린에 표시된 정보의 나머지 부분에 기초하여 만들기 위한 가장 가능성 높은 선택을 보여주는 제1 층에 표시된 도구의 세트가 있을 수 있다. 하지만 이 경우, 사용자는 기본 앱에서 버튼을 클릭하기 위해 마우스를 움직일 필요가 없다. 대신, 표 시된 제안을 사용하여 화살표 키나 다른 보조 키를 단순히 클릭하여 진행할 수 있다. 이는 마우스 오버를 여러 번 하는 조작을 줄이는데 도움이 된다. 일부 실시예에서, 템플릿은 디스플레이 컨텐츠가 마치 3D 환경의 상이한 측면에 매핑되거나 스키닝된 것처럼 표 시되도록 아핀 병진 변환(affine translational transform)을 거치도록 3D 환경에서 정의될 수 있다. 예를 들 어, 광고는 3D 환경에 표시하기 위해 투사도로 변환된다. 일부 실시예에서, 적용되는 기하학적 템플릿은 주류 또는 보조 스트림에서 취해진 이벤트 또는 동작 항목에 기 초하여 동적으로 변경될 수 있다. 예를 들어, 게임에서 캐릭터가 총을 쏘거나 점프하는 것과 같은 이벤트가 발 생하면 측면 디스플레이 컨텐츠는 특정 색상을 깜빡이거나 특정 이미지를 표시하거나, 이는 확대 또는 축소될 수 있다. 일부 실시예에서, 템플릿은 다수의 동시 장치에 표시되도록 구성된 템플릿을 포함한다. 예를 들어, 휴대폰 스크 린이나 태블릿 스크린은 랩탑과 시각적 템플릿을 공유할 수 있다. 여기서, 비제한적인 예로서, 게임 캐릭터가 게임에서 위아래로 점프하는 경우, 랩탑에서는 특정 디스플레이 컨텐츠가 표시되고 두번째는 휴대폰에, 세번째 는 태블릿에 표시된다. 다른 예에서, 사용자는 데스크탑 스크린으로 금융 거래를 실행하고 있으며 STW 생성 애플리케이션의 일부로 휴 대폰 또는 태블릿 스크린을 선택했다. 특정 뉴스 항목이 나오거나 특정 주식이 업데이트되면 해당 스트림의 관 련 컨텐츠가 휴대폰 또는 태블릿으로 전송된다. 일부 실시예에서, STW는 시뮬레이션, 훈련 또는 교육 애플리케이션을 생성하는데 사용된다. 트레이너 또는 교육 자의 역할을 하는 사용자는 깊이층, 보조 디스플레이 또는 확장된 FoV의 일부를 훈련생에게 공유하여 훈련 매체 및 자료와 기하학적으로 관련이 있는 것처럼 보이는 훈련 명령을 제공할 수 있다. 일부 실시예에서, 트레이너는 사용자 의도를 예측하여 명령을 생성하는 채팅 봇 또는 AI 기반 알고리즘일 수 있다. 일부 실시예에서, AI는 사 용자가 무엇을 할 수 있는지만 보여주는 것이 아니라 기본 입력 스트림에 액세스할 수 있는 권한을 가질 수 있 다. 일부 실시예에서, 훈련 컨텐츠는 사용자 앞에서 단계별로 비디오 스트림으로 재생될 수 있다. 훈련 및 시뮬레이션 경험은 다수의 사용자를 포함할 수 있다. 예를 들어, 교육자나 트레이너는 디스플레이 시스 템에서 훈련하는 사용자를 관찰할 수 있다. 교육자는 자신의 디스플레이 시스템을 사용할 수 있거나, 교육자의 이미지는 카메라에 의해 캡처되어 사용자의 확장된 디스플레이 시스템의 확장된 부분을 통해 사용자에게 표시될 수 있다. 교육자는 음성, 키보드 또는 마우스 입력 또는 감각 입력을 기반으로 실시간 피드백을 사용자에게 제 공할 수 있으며, 피드백은 시각적 또는 텍스트 컨텐츠로 주석으로 표시되거나 기존 주석에 대한 변경사항으로 사용자의 디스플레이 시스템에 표시될 수 있다. 일부 실시예에서, 다수의 사용자는 각각 디스플레이 시스템을 사용할 수 있지만, 카메라에 의해 캡처된 제1 사 용자의 이미지는 서로 옆에 있는 경험을 모방하기 위해 제2 사용자의 디스플레이 시스템의 확장된 부분에 표시 되며 그 반대의 경우도 마찬가지다. 각각의 이미지는 사실적인 주변 이미지를 제공하기 위해 워핑되거나 워핑되 지 않을 수 있다. 일부 실시예에서, 디스플레이 시스템은 통신 가능하게 결합된 독립형 모니터 및 헤드셋과 같은 다수의 디스플레 이 장치를 포함한다. 예를 들어, 독립형 모니터는 시뮬레이션이나 훈련 운동의 광시야 이미지를 표시할 수 있으 며, 사용자는 모니터에 표시된 컨텐츠 또는 사용자의 기하학적 구조 또는 시선을 기반으로 주석을 표시하는 헤 드셋을 착용하고 있다. 헤드셋과 모니터 사이의 통신은 예를 들어 연결 케이블을 통해 유선을 이루어질 수 있거 나 예를 들어 wi-fi 네트워크 또는 원격 중앙 소스를 통해 무선으로 이루어질 수 있다. 일부 실시예에서, STW 애플리케이션은 권한 설정 및 출력 템플릿에 따라 비디오 편집을 돕도록 구성될 수 있다. AI 프로그램은 확장된 디스플레이의 일부로 나타나는 비디오 스트림에서 작업이 어떻게 수행되는지 사용자에게 보여줄 수 있거나, AI 또는 트레이너는 프로그램을 제어하고 현재 작업을 단계별로 수행할 수 있다. 임의의 단 계에서, 훈련생은 사용자 또는 감각 입력을 기반으로 트레이너가 하고 있는 일에 개입 및/또는 협업하여 변경할 수 있다. 도 5a 내지 5j는 다양한 소스에 대한 기능 블록의 여러 예를 나타낸다. 이러한 다양한 기능은 시각적 템플릿으 로 구성된 최종 표시를 위해 선택한 입력 스트림에서 작동하기 위해 STW를 사용하는 사용자가 선택한다. 기능 블록은 STW가 선택할 수 있는 이용 가능한 기능을 구성하는 방법일 수 있다. STW를 사용하는 사용자가 생성하는 소프트웨어 기반 디스플레이 컨텐츠인 최종 소프트웨어 제품은 일반 앱, 비디오, 클릭 가능한 비디오, 메타데이 터, 예측 앱, 데이터베이스, 게임 및 대화형 미디어를 포함한다. 다음 실시예는 STW의 기능 블록과 결과적인 소 프트웨어 애플리케이션 중 일부를 모두 설명한다. 도 5a의 \"사용자 입력이 있는 미디어 주석기(annotator)\"와 같은 일부 실시예에서, 소스는 VR 또는 AR 애플리케 이션, 비디오 투시(video see-through), 원격 조작, 다른 장치 원격 제어, 원격 회의 또는 비디오 컨텐츠 생성 및 카메라 소스 기능 블록(16A)에 나타나는 가능한 기능의 일부에 대해 사용될 수 있는 카메라 소스를 포함한다. 결과적인 소프트웨어는 대화형 비디오 애플리케이션에 사용된다. 예를 들어, 카메라 소스 기능 블록 은 주석 기능을 포함하여 디스플레이 시스템은 비디오의 측면을 강조하기 위해 카메라 소스 컨텐츠 위에 오 버레이되는 디지털 컨텐츠를 생성할 수 있다. 디지털 컨텐츠는 카메라 컨텐츠와 동일한 초점 평면에 위치될 수 있거나, 이는 호버링 그래픽 또는 호버링 텍스트 또는 다층 템플릿의 다른 층에서와 같이 다른 초점 평면에 위 치될 수 있다. 주석은 사용자 프로필이나 작업에 따라 사전 프로그래밍되거나 AI 모듈을 통해 동적으로 생성될 수 있다. 카메라 소스 기능 블록은 사용자가 컨텐츠에 대해 피드백을 제공하거나 질문을 할 수 있도록 코멘트 기능도 포함할 수 있다. 사용자 피드백은 피드백에 응답할 수 있는 채팅봇과 같은 AI 모듈과 통합된 텍스트 기반 피드백 메커니즘일 수 있다. 보다 일반적으로, 사용자가 키보드 스트로크, 마우스 클릭, 제스처 또는 얼굴 표정, 또는 음성 명령을 포함하는 임의의 양식으로 소프트웨어에 입력을 제공할 수 있게 하는 사용자 입력 기능 이 있을 수 있다. 일부 실시예에서, 사용자 입력 기능은 예를 들어 온라인 퀴즈 또는 훈련 비디오에서 사용 하기 위해 카메라 소스 정보의 지정된 프레임에 대한 입력을 요청하도록 구성된다. 다른 기능은 사용자가 가상 아바타 또는 보조자와 상호작용할 수 있도록 하는 아바타 보조 기능이다. 아바타는 경험 중에 사용자를 안 내하기 위해 사용자 컨텐츠 또는 카메라 소스 정보에 기초하여 제안을 제공할 수 있다. 이 기능 블록의 마지막 은 그래픽 기능이다. 그래픽은 경고 라벨, 사용자를 위한 축하 이미지 또는 카메라 컨텐츠의 특징을 강조하 는 그래픽을 포함한다. 그래픽 기능은 비디오 프레임을 처리하는 표준 그래픽 기능으로서 구현될 수 있거나 이 는 사용자의 사용자 입력 또는 센서 입력에 기초할 수 있다. 예를 들어, 그래픽 기능은 사용자의 시선을 취하여 사용자가 초점을 맞추고 있는 디스플레이 영역을 밝게 할 수 있다. 도 5a 내지 5b의 실시예의 특정 기능이 특정 소스와 연관되지만, 이러한 기능은 다른 실시예에서 사용될 수 있 다. 아바타 어시스턴트는 예를 들어 결과적인 소프트웨어의 기능을 지원하거나 영향을 미치기 위해 임의의 실시예에 사용될 수 있다.실시예에서, 아바타 어시스턴트는 훈련 비디오에서 객체의 상대적 중요성에 기초하여 정보를 출력하도록 프로그 래밍될 수 있고 음성 질문과 같은 사용자 입력을 취하고 비디오 컨텐츠에 기초하여 이에 대답할 수 있다. 기능 은 요청 시 추가 정보를 제공하거나 비디오의 한 부분에서 다른 부분으로 개념을 연결하는 단서를 제공하기 위 해 비디오 컨텐츠와 관련된 사전, 훈련 데이터 또는 검색 엔진에 연결될 수 있다. 실시예에서, 그래픽 기능은 비디오를 통한 사용자의 진행, 센서로부터 캡처된 사용자의 시선 또는 사용자의 SLAM 입력에 기초하여 비디오의 측면을 강조할 수 있다. 예를 들어, 비디오는 물리적 작업을 수행할 때 올바른 자세를 훈련하는 비디오일 수 있으며, 인디케이터 기능은 사용자의 포즈를 입력으로 취하여 캐릭터의 포즈와 비 교한다. 기능은 비디오의 하이라이트를 출력하여 사용자와 비교하여 비디오 캐릭터의 등 자세 또는 어깨 자세를 강조하는 비디오의 캐릭터에 대해 자세를 어떻게 변경해야 하는지 보여준다. 이 예의 흐름도가 도 6a에 도시된 다. 도 5b는 카메라 소스 기능 블록(16B)이 온라인 쇼핑 플랫폼 또는 광고에 대한 소스로 사용하도록 구성된 \"E-커 머스 스마트 추천기/광고기\"의 실시예를 도시한다. 예를 들어, 다층 디스플레이 컨텐츠는 상업 광고인 비디오 층과 카메라에 의해 캡처된 사용자의 시선에 기초하여 항목의 주석을 포함하는 제2 층을 포함할 수 있다. 주석 은 구매 가능한 항목을 강조하거나 확장된 디스플레이 이미지에 추가 정보를 표시할 수 있다. 이 기능 블록은 라이브 비디오 또는 비디오 녹화를 사용할 수 있다. 기능 중 하나는 비디오 컨텐츠에서 구매 가 능한 항목이 강조되고 온라인 쇼핑 플랫폼에 대한 링크를 포함할 수 있도록 구성되는 구매 기능을 포함한다. 구매 가능한 컨텐츠는 객체 검출 알고리즘과 판매 가능성을 결정하는 검색 엔진을 통해 식별될 수 있 으며, 소프트웨어는 사용자 입력 또는 사용자 프로필에 기초하여 어떤 객체를 강조할 지 결정할 수 있다. 이 예 의 흐름도가 도 6b에 도시된다. 예를 들어, 과학 장비를 검색하고 구매한 사용자는 검색 이력이 집 장식에 중점 을 둔 사용자와는 다른 객체가 강조된다는 것을 볼 수 있다. 기능 입력은 비디오 프레임과 사용자 입력/프로필 이며 출력은 판매 가능한 정보, 구매 옵션 및 다양한 대안을 갖는 주석 층일 수 있다. 일부 실시예에서, 세부사 항은 디스플레이 시스템에 대한 사용자의 이력, 이전 구매, 검색 이력 또는 다른 사용자 고유 세부사항에 의해 영향을 받는다. 공유 기능은 사용자가 카메라 소스로부터의 컨텐츠를 다른 사용자 또는 네트워크의 잠재적 사용자와 공유할 수 있게 한다. 이 기능은 예를 들어 비디오에서 검출된 객체에 대한 빠른 응답(QR) 코드를 생 성할 수 있으며, 여기서 QR 코드는 다른 사용자와 공유되어 비디오를 시청하는 다른 사용자의 호버링 그래픽에 QR 코드가 나타난다. 이 예에서, 사용자가 마우스 입력으로 클릭한 위치에 기초하여 QR 코드가 생성된다. 다른 기능은 사용자가 비디오의 객체를 클릭하고 사용자 생성 텍스트 또는 선택된 그래픽일 수 있는 피드백을 비디오 제작자 또는 다양한 판매자에게 제공하도록 구성되는 코멘트 기능이다. 이 기능에 대한 입력은 구매 기능 으로부터 생성된 주석 층을 포함한다. 일부 실시예에서, 구매 기능 또는 피드백 기능은 디스플레이에 연결 된 카메라 시스템에 기초하여 사용자의 신체 유형을 입력으로 취하며, 예를 들어 웨어러블 제품이 제대로 맞는 지 결정하도록 구성된다. 이들 실시예에서, 사용자의 기하학적 구조를 스크린 상의 판매 가능한 항목의 형상과 정렬하여 항목을 착용한 사용자의 가상 현실 이미지를 생성하기 위해 기하학적 변환 하위 기능이 사용되어야 한 다. 유사하게, 문의 기능은 사용자가 이전 구매에 대한 평가를 보거나 제품을 리뷰하는 온라인 포럼에 연결함으 로써 비디오의 객체에 대한 더 많은 정보를 얻을 수 있게 한다. 예를 들어, 일부 실시예에서, 사용자는 주어진 객체 위에 커서를 놓으면 해당 제품에 대한 사용자 경험에 관한 목록이 호버링 그래픽 또는 에지 확장 디스플레 이에 표시된다. 이 블록의 다른 기능은 현재 인스턴스의 소프트웨어 경험을 통한 사용자의 네비게이션에 대한 정보가 예를 들어 다수의 사용자, 다양한 쇼핑 플랫폼의 개별 사용자의 별도 소프트웨어 계정 또는 문의 기능의 미래 사용자 를 위한 메모리 뱅크에 자동으로 입력되도록 구성되는 동기화 기능이다. 예를 들어, 사용자는 모바일 장치 에 저장된 쇼핑 플랫폼 애플리케이션을 동기화할 수 있으며, 쇼핑 카트 또는 브라우저는 다층 디스플레이 장치 에 입력되어 다양한 주석 및 QR 코드가 강조되거나 강조되지 않는다. 도 5c에 도시된 \"원격 작업/협업 경험 촉진기\"인 다른 실시예에서, 카메라 소스 기능 블록(16C)은 예를 들어 온 라인 강의실, 웹 세미나, 품질 제어 모니터링, 제어 센터 또는 원격 작업에서 사용하기 위한 다양한 협업 시각 적 환경 또는 모니터링 환경을 위한 기능을 포함한다. 일부 실시예에서, 카메라 소스 기능 블록은 일반 센서 통 합 기능을 포함한다. 이 기능은 예를 들어 다른 사용자, 원격 또는 자율 차량, 보안 카메라 또는 로봇 또는 기계 부품을 관찰하는 카메라로부터 네트워크 또는 다른 카메라에 연결된 임의의 센서의 통합을 허용한다. 이러 한 입력은 컨텐츠가 다층 디스플레이에 실시간으로 오버레이되도록 동기화될 수 있다. 다른 실시예에서, 이미지는 예를 들어 다중 카메라 차량 내비게이션 시스템에서 사용되는 것과 같이 확장된 FoV로 타일링되어 차량 환경 의 파노라마 뷰를 생성한다. 다른 기능은 이미지 처리 기능이다. 이 기능은 카메라 소스 또는 시각적 컨텐 츠를 생성하도록 구성되는 임의의 센서 소스를 조작하는 별도의 하위 기능을 가질 수 있다. 예를 들어, 이 기능 에 대한 입력은 비디오 자체 및 감각 입력일 수 있으며, 이미지 처리 기능은 사용자 정의 모니터링 작업을 기반 으로 뷰어가 주의를 집중해야 하는 더 밝은 픽셀 영역 또는 디스플레이 컨텐츠를 출력하도록 프로그래밍된다. 또한, 화이트보드 기능은 사용자가 예를 들어 온라인 코스에 대한 온라인 레슨에서와 같이 별도의 애플리케 이션을 공유하거나 별도의 애플리케이션을 카메라 소스와 병합할 수 있게 한다. 공유 컨텐츠는 기존 공유 메커 니즘일 수 있거나, 이는 컨텐츠가 동적으로 번역되어 뷰어의 요구에 맞게 조정되는 동적 메커니즘일 수 있다. 예를 들어, 화이트보드 기능에 대한 입력은 비행 궤적의 데이터세트일 수 있으며, 기능은 해당 데이터를 다층 비행 시뮬레이터에 오버레이되는 시각적 궤적으로 표시하도록 구성된다. 예를 들어, 확장된 디스플레이 시스템은 다수의 사용자가 카메라에 의해 캡처된 그 자체의 가상 이미지를 통해 서로 상호작용할 수 있는 하나의 영역을 포함할 수 있다. 영역은 화이트보드 기능에 의해 생성된다. 다층 디스플레이의 제2 층 또는 확장된 시야일 수 있는 제2 영역은 사용자가 시선 또는 제스처 감지를 통해 조작하는 가상 화이트보드 공간일 수 있다. 예를 들어, 센서 통합 기능은 제스처 센서 또는 카메라 시스템에서 캡처 된 제스처를 입력으로 취한 다음 필기 텍스트와 같이 가상 화이트보드 공간에 표시할 동작을 결정할 수 있다. 이 예는 도 6c에서 추가로 설명된다. 컨텐츠가 사용자 또는 사용자의 신체 부위의 이미지를 포함하는 디스플레이의 경우, 프로젝션 매핑 또는 기하학 적 변환은 디스플레이 이미지에 영향을 주는데 사용되는 이미지 처리 기능의 유형일 수 있다. 기하학적 왜곡은 광학 시스템의 왜곡을 제거하는 것을 포함할 수 있다. 일반적으로, 기하학적 왜곡은 임의의 방식으로 제거되거 나 보상될 수 있다. 예를 들어, 다항식 왜곡 알고리즘을 사용하여 렌즈 또는 어안 왜곡을 제거할 수 있다. 카메 라 보정을 사용하여 카메라의 왜곡을 제거할 수도 있다. 이미지 처리 기능은 또한 밝기 조정, 포비티드 보기(foveated viewing), 에지 강화, 블러링(blurring) 특 징, 비디오 또는 이미지 필터, 배경 블러링, 계산 재매핑 등을 포함한다. 이 기능은 전체 소스에 대해 작동할 수 있거나, 이는 사용자에 의해 결정되거나 센서 입력에 기초하여 소스의 파티션에 대해 작동할 수 있다. 기능 은 이미지 처리를 지원하기 위해 다른 루틴을 필요로 할 수 있다. 자율 주행 또는 원격 작동 차량에서, 파노라 마 뷰가 표시되며 이러한 이미지 처리 기능 중 하나는 객체를 식별하고, 속도를 추정한 다음 속도가 임계값을 초과하면 이를 강조하도록 구성된다. 다른 기능은 모든 시각적 컨텐츠를 함께 분석하고 해당 컨텐츠에 대해 작 동하는 생성적 방법을 제안하도록 구성된 AI 모듈이다. 또한, 사운드, 음악 및 다른 오디오 효과를 수정하기 위한 오디오 기능이 있다. 오디오 소스는 디스플레이 시스템에 연결되는 마이크일 수 있거나, 이는 원격 소스일 수 있다. 기능은 스피커나 다른 오디오 변환기를 통 해 오디오를 출력하도록 구성될 수도 있다. 예를 들어, 오디오 신호는 홀로그램 또는 빔포밍 방법을 통해 다층 디스플레이의 제1 층 또는 제2 층에서 나오는 것처럼 소리가 나도록 구성될 수 있으므로, 사용자가 소리를 들을 때 사용자는 소스와 연관된 거리를 인식할 수 있다. 이는 예를 들어 화이트보드 공간과 관련된 오디오 효과나 가상 교실에서 다수의 사용자에 의해 만들어진 음성 소리일 수 있다. 빔포밍은 각각 개별 음파를 방출하는 스피 커의 배열을 사용하여 생성되며, 총 음파는 원하는 깊이에서 음원에 근접한 파면을 생성한다. 개별 음파는 근사 치가 얼마나 정확한지에 따라 개별 음파의 상대 위상을 출력하는 최적화 알고리즘에 의해 결정된다. 도 5d는 카메라 소스 기능 블록(16D)의 \"다중-소스/-컨텐츠 생성기 및 병합기\"인 실시예를 도시하며, 카메라 소 스는 일반 이미지 소스이다. 기능 블록은 이미지 처리 기능 및 주석 층 기능을 포함하여, 카메라 컨텐 츠의 다양한 설명 또는 시각화가 카메라 컨텐츠 근처에 오버레이되거나 표시될 수 있다. 실시예는 또한 사용자 가 다른 비디오 또는 카메라 소스를 원본 컨텐츠와 결합할 수 있게 하는 병합 기능을 가질 수 있다. 예를 들어, 이 기능 블록은 원격 작동 또는 연구 방법을 포함하는 실시예에서 사용될 수 있으며, 카메라 또는 광검출 기는 설정에 대한 광학 정보를 기록하고 다른 센서는 사용된 장비를 모니터링하여 병합 기능이 카메라와 오버레 이된 센서 데이터를 결합한다. 병합 기능은 먼저 사용자 선택 또는 사용자 정의 기능을 통해 자동으로 분석될 수 있으며, 확장된 측면 윈도우는 장비 설정이 증분 단위로 이동하여 발생할 수 있는 대체 결과를 표시한다. 대 체 결과는 기본 물리 법칙의 수치 시뮬레이션을 통해 계산되거나 딥러닝 알고리즘을 통해 계산될 수 있다. 일부 실시예에서, 병합 기능은 다양한 상관관계 및 추세에 대한 데이터를 비교하는 AI 신경망에 기초할 수 있다. 이 예에서, 원본 이미지는 터치업 특징, 시각적 데이터의 자동 암호화 또는 비디오 미디어용 컨텐츠 생성 을 포함할 수 있는 사용자 사양을 기반으로 AI 생성 이미지 컨텐츠와 병합될 수 있다.실시예에서, 비디오는 직원을 모니터링하기 위한 건설 현장 또는 창고와 같은 작업장의 실시간 피드일 수 있다. 이 예에서, 중앙 디스플레이는 라이브 피드를 표시할 수 있으며, 확장된 디스플레이 이미지는 라이브 피드의 스 냅샷 또는 프레임을 표시할 수 있다. 이 경우, 병합 기능은 비디오의 이력 프레임을 확장된 디스플레이의 라이브 프레임과 병합하도록 프로그래밍된다. 병합 기능의 하위 루틴은 먼저 프레임을 분석하여 잘못된 절차적 동작, 생산성 수준 또는 동료와의 상호작용과 같은 중요하거나 연관된 개인 동작을 식별할 수 있다. 이 하위 루 틴은 CNN을 사용하여 유사한 객체나 포즈를 검출할 수 있다. 다른 하위 루틴은 이러한 프레임이 표시될 대 사용 자가 집중할 수 있도록 주석을 추가할 수 있다. 예를 들어, CNN의 출력은 창고 직원이 무거운 상자를 들어올리 는 모든 프레임을 검출 및 표시하고 사람이 너무 적은 프레임을 식별하여 사용자에게 개입하라는 경고 주석을 추가한다. 이 실시예는 도 6d에서 추가로 설명된다. 일부 실시예에서, 비디오 소스는 비디오 편집 환경에서 사용된다. 일부 실시예에서, 병합된 컨텐츠는 시각 컨텐 츠가 아니라 일반적으로 카메라 컨텐츠에 영향을 주거나 향상시키는 일부 다른 유형의 정보이다. 병합 기능은 다층 디스플레이의 특정 층 또는 관심 있는 층의 하위 섹션에 따라 달라질 수 있다. 오디오 기능은 사용자 가 오디오 신호를 편집, 추가 또는 방출할 수 있게 한다. 마지막으로, 업로드 기능은 사용자가 컨텐츠 또는 컨텐츠의 일부를 다른 장치나 네트워크로 전송하게 한다. 업로드 기능은 다수의 사용자로부터 컨텐츠를 수집하 거나 데이터베이스 또는 기계 학습 알고리즘용 훈련 라이브러리에 컨텐츠를 추가하는 자체 병합 또는 동기화 하 위 루틴을 포함할 수도 있다. \"벤치마크 및 로직 분석기\"인 다른 실시예가 도 5e에 도시되며, 여기서 소스는 텍스트 기반 소스이며, 기능의 세트는 텍스트 소스 기능 블록(16E)이다. 텍스트 소스는 문서, 스프레드시트, 온라인 주소록, 저널 또는 출판물, e-북, 컴퓨터 코드 또는 프레젠테이션일 수 있다. 기능 블록은 병합 기능을 포함하여, 다수의 텍스 트 소스가 병합될 수 있다. 예를 들어, 사용자는 두 가지 버전의 컴퓨터 코드를 결합하려고 할 수 있다. 이 기 능은 여러 옵션으로 구성될 수 있다. 제1 옵션은 별도의 파일에 작성된 업데이트된 코드로 기존 코드의 라인을 업데이트하는 것이다. 제2 옵션은 컴퓨터 코드의 두 버전을 비교하고 두 입력에 기초하여 최적화된 업데이트된 버전을 생성하는 것이다. 일부 실시예에서, 사용자의 원래 코드는 자동으로 컴파일, 실행 및 벤치마킹될 수 있 으며, 사용자가 다양한 성능을 비교할 수 있는 방식으로 배열된 조정 또는 대체 알고리즘의 세트가 다른 디스플 레이 컨텐츠에 제안된다. 이 예는 도 6e에서 추가로 논의된다. 주석 기능은 호버링 그래픽 또는 다층 디스 플레이의 원본 텍스트에 대한 설명, 그래픽 또는 다른 시각화를 추가할 수 있다. 일부 실시예에서, 텍스트 또는 주석은 예를 들어 QR 코드를 클릭함으로써 이벤트에 의존하거나 객체에 의해 고정되도록 만들어질 수 있다. 일 부 실시예에서, SLAM 입력 또는 시선 입력은 주석에 영향을 미친다. 일부 실시예에서, 주석 기능은 톤, 일관성, 논리적 건전성 또는 감정에 대해 텍스를 읽거나, 수정이 필요한 텍스트의 위치에 주석을 달거나, 확장된 디스플 레이 이미지에서 대체 단락 또는 이미지를 제안하도록 구성된 하위 루틴을 포함할 수 있다. 이 블록의 다른 기능은 예를 들어 공리적 진술(axiomatic statement)을 프로그래밍 명령에 매핑함으로써 논리적 프로그래밍에 의해 생성되는 논리적 분석기 기능이다. 사용자는 증명 방법을 지정하고 귀납법에 의한 증명, 모순에 의한 증명 또는 다른 적합한 증명 방법 기능을 설정할 수 있다. 대안적으로, 기능은 AI 생성 접근 방식 을 사용하고 온라인에서 사용할 수 있는 다양한 증명 및 정리를 수집하여 새로운 증명을 생성할 수 있다. 이 기 능은 테긋트나 코드를 문서의 구조에 따라 진리값이 분석되는 진술로 구문 분석한다. 논리적 분석기 기능의 출력은 언어적 논증의 강도를 평가하는 분류기일 수 있거나, 이는 논리적 결함을 지적할 수 있다. 일부 실시예 에서, 출력은 임의의 논리적 오류를 정정하기 위한 제안을 포함할 수 있다. 논리는 아리스토텔레스 논리 규칙에 기초한 형식적 언어 논리일 수 있거나, 이는 예를 들어 공리 집합 이론이나 기하학적 증명에서 사용되는 수학적 논리로 형식화될 수 있다. 사용자 입력 기능은 사용자가 예를 들어 제스처를 사용하여 텍스트와 상호작용할 수 있게 한다. 일부 실시 예에서, 입력은 예를 들어 기존 문서에서 new next를 입력하는 소스에서와 동일하다. 사용자 입력은 음성-텍스 트 기능 또는 음성-계산 기능과 같은 입력의 새로운 방법 또는 기능일 수 있다. 이 실시예의 마지막은 사용자가 텍스트를 직접 편집하거나 수정하지 않고도 문서의 메타데이터 또는 다른 특성에 주석을 달거나 볼 수 있도록 하는 코멘트 기능이다. 도 5f는 소프트웨어 엔진을 설계하는 방법으로 구성되는 사용자 정의 소스 기능 블록(16F)의 실시예를 나타내며, 즉 이 실시예는 \"소프트웨어 엔진/데이터 어셈블러\"이다. 이 기능 블록이 작동하는 소스는 임의의 데 이터 유형일 수 있다. 예를 들어 이는 데이터베이스, 포인트 클라우드, 조회 테이블 또는 사전, 온라인 저장소, 인터넷 또는 코드 블록의 라이브러리일 수 있다. 생성되는 엔진 유형은 임의적이다. 이는 데이터베이스 엔진, 그래픽 엔진, 물리 엔진, 검색 엔진, 플로팅 엔진, 웹 브라우징 엔진 또는 게임 엔진일 수 있다. STW는 다수의엔진을 생성하기 위한 다수의 기능 블록을 가질 수 있다. 엔진은 컨텐츠 처리, 장면 이해 또는 이미지 처리를 지원할 수 있다. 일부 실시예에서, 엔진은 실시간 엔진 또는 앱별 추천 엔진으로 구성된 추천 엔진이다. 이 기능 블록에서, 라이브러리 기능은 다양한 엔진 라이브러리를 정렬하거나 새로운 라이브러리를 설계 또 는 구현하는데 사용될 수 있다. 일부 실시예에서, 라이브러리는 입력 시 사용자 질의 또는 원하는 작업을 가질 수 있으며, 라이브러리는 AI 모듈을 기반으로 생성된다. 예를 들어, 사용자가 \"3차원 데이터 그래프 작성을 위 한 모든 하위 루틴 제공\"이라는 라이브러리 기능을 입력할 수 있고, 라이브러리 기능은 소스 데이터를 검색하거 나 그 자체를 생성하여 데이터를 그래픽으로 표시하는 방법을 출력한다. 또는 라이브러리 기능은 입력 데이터를 취하며 입력 데이터의 구조 또는 크기를 기반으로 라이브러리를 식별할 수 있다. 예를 들어, 입력 데이터는 게 놈 서열 또는 단백질의 세트에 대응할 수 있으며, 라이브러리 기능은 데이터를 게놈 서열 또는 단백질의 세트로 먼저 식별하고 유사한 모든 데이터세트를 인터넷에서 검색하고 입력 데이터와 동일한 포맷으로 데이터세트의 라 이브러리를 구축하는 AI 기반 기능이다. 그래픽 기능은 시각적 애플리케이션, 물리 기반 그래픽 렌더링 또는 엔진에 사용하기 위한 해상도, 프레임 속도 또는 강도 변화와 같은 맞춤형 그래픽 설정을 허용할 수 있다. 일부 실시예에서, 그래픽 기능은 그래픽을 렌더링하기 위해 다양한 물리적 또는 동적 법칙을 구현하는 하위 기능을 가질 수 있다. 이 기능에 대한 입력 데 이터는 비디오 게임에 사용되는 포인트 클라우드이거나 연구 목적의 과학 이미지일 수 있다. 이 기능은 보다 구 체적인 게임 엔진 기능 블록에 대한 하위 루틴일 수도 있다. UI/UX 기능은 소스에 작용하고 이를 유용하거나 매력적인 방식으로 표시한다. 예를 들어, UI/UX 기능은 수치 데이터를 취하며 AI 모듈을 기반으로 데이터 세트를 분류하고, 분류 및 데이터 크기를 기반으로 최상의 표현 모드를 최적화하고, 그래픽으로 배열하고 사용자 상호작용을 위한 주석/라벨을 생성하는 하위 기능을 포함할 수 있다. 이 실시예는 도 6f에서 추가로 설명된다. 다른 하위 기능은 확률 기능, 시간 의존 기능 또는 신경망 또는 다른 딥러닝 기능일 수 있는 예측 기능을 포함할 수 있으며, 기능은 사용자 입력의 소스와 이 력을 모두 입력으로 취하며 사용자의 가능한 미래 동작을 제안하는 새로운 그래픽을 생성한다. 예를 들어, AI- 기반 UI/UX 기능은 데이터를 특정 기간 동안 영역의 날씨 데이터로 데이터를 분류할 수 있으며, 사용자가 데이 터를 평균화하거나 미래로 데이터를 추정하거나, 상이한 시간 간격으로부터의 데이터에 대해 인터넷을 검색하게 하는 툴바가 생성된다. 일부 실시예에서, 예를 들어, 원하는 엔진은 데이터베이스 엔진이며, 디스플레이 패널은 다층 디스플레이로 구 성되며, 여기서 깊이 층은 이미지의 포인트 클라우드와 같이 체적 정보를 조작하는데 사용될 수 있는 예를 들어 3차원 데이터베이스를 생성하기 위한 데이터의 다른 차원에 대응한다. UX 기능은 데이터베이스에서 데이터를 취 하며 데이터의 구조를 분석하여, 인포그래픽이나 다차원 그래프와 같이 시각적으로 매력적인 방식으로 표시하기 위해 데이터 유형의 라이브러리와 이를 비교한다. 코드 블록은 새로운 코드를 생성하기 위해 생성된 엔진의 사용자가 엔진을 수정하거나 향상시키게 한다. 신 경망 기능은 엔진이 임의의 애플리케이션에 대해 신경망을 통합할 수 있게 한다. 예를 들어, 게임 엔진에서, CNN은 비디오 카메라에 의해 캡처된 장면에서 객체를 검출하고 이를 비디오 게임 환경에 통합하는데 사용될 수 있다. 일부 실시예에서, API 기능은 추가적으로 사용자가 로컬 하드웨어 또는 네트워크에 분산된 하 드웨어와 상호작용하도록 소스 정보를 구성하게 한다. 예를 들어, 데이터는 카메라 이미지의 세트로부터 또는 기기 또는 기계의 사용 세부 정보로부터 실시간으로 가져올 수 있다. \"게임 및 월드 워핑 엔진\"인 도 5g에 도시된 실시예에서, 소스는 기존 게임 또는 게임 엔진이며, 기능 블록은 게임 기능 블록(16G)이다. 기능 블록은 그래픽 기능(해상도 효과 또는 향상과 같음), 오디오 기능, 코 멘트 기능을 포함하여 코멘트(예를 들어, 멀티플레이어 게임), 3D 리매핑 효과 및 메쉬 생성을 위한 계산 재매핑 기능 및 게임 내 게임 캐릭터 또는 그래픽의 다양한 워핑 효과를 위한 기하학적 변환 기능을 포 함한다. 일부 실시예에서, 주석 기능이 포함된다. 일부 실시예에서, 기존 게임은 1인칭 시점 게임이며, 장면의 상이한 항목이 다층 디스플레이에서 상이한 깊이로 표시된다. 일부 실시예에서, 층 중 하나는 사용자의 시선 또는 캐릭터 모션에 기초하여 힌트를 제공하는 주석 층일 수 있다. 다른 실시예에서, 사용자는 캐릭터가 카메라 시스템에 의해 캡처되는 사용자의 이미지인 게임을 플레이할 수 있으며, 기하학적 변환은 게임에서 캐릭터의 형상 및 크기를 동적으로 최적화하기 위해 기하학적 변환 기능과 함께 사용된다. 일부 실시예에서, 게임은 게임의 베타 버전이며, AI 구성요소는 사용자가 게임 을 평가할 때 연장된 지연의 윈도우 내에 상이한 관점 또는 상호작용을 제안한다. 이 예는 도 6g에서 추가로 설 명된다.\"동적 UI 생성기\"인 도 5h에 도시된 일부 실시예에서, UI 기능 블록(16H)은 임의의 UI를 소스로 갖는다. UI는 특정 특징, 버튼, 링크, 아이콘, 시각적 요소 또는 오디오 요소를 갖는 웹사이트 랜딩 페이지일 수 있다. UI 기 능 블록은 입력 기능을 통해 사용자 입력을 수용하거나, 업로드 기능을 통해 로컬 또는 원격 소스 정보 를 검출 또는 업로드하거나, 다운로드 기능을 통해 명령을 수신하기 위해, 그래픽 기능 및 다양한 그래 픽 품질을 설정하는 능력을 포함한다. 일부 실시예에서, 사용자 정의 기능은 사용자가 입력 소스를 임의의 조작할 수 있게 한다. 사용자 정의 기능은 이미지 처리 하위 기능 블록; 코드를 작성, 컴파일 및 실행하기 위한 터미널 윈도우 또는 본 개시에 설명된 임의의 기능일 수 있다. 예를 들어, 일부 실시예에서, 이 기능 블록은 웹 사이트 테스트에 사용되고, 사용자는 체크박스 또는 라디오 버튼과 같은 다양한 입력 요청으로 웹사이트를 테스 트하고 있다. 사용자가 웹사이트를 탐색할 때, 시선과 상호작용이 기록되고, 주석 오버레이에 의해, 사용되지 않은 부분은 강조되거나 더 밝아져, 디자이너는 웹 사이트에 대한 그래픽 피드백을 가질 수 있다. 또는 웹사이 트 특징은 테스터의 이력 사용에 기초하여 동적으로 조정될 수 있다. 이 예시적인 실시예는 도 6h로 설명된다. 도 5i에서, 도시된 \"미디어 특징 인식기 및 주석기\"인 실시예는 소스로서 디스플레이 컨텐츠를 갖는다. 이는 이 전 기능 블록으로부터 출력된 일반 디스플레이 컨텐츠를 포함할 수 있다. 예를 들어, 여기서 입력은 도 5a의 기 능에 의해 작동된 후 클릭 가능한 훈련 비디오일 수 있다. 복합 기능 블록(16I)은 소스 이미지의 특징을 검출하 는 검출 기능을 포함한다. 특징 검출은 낮은 수준(예를 들어, 에지 검출), 중간 수준(예를 들어, 시선 또는 얼굴 추적) 또는 높은 수준(사람을 포함하는 디스플레이 컨텐츠의 감정적 검출)일 수 있다. 일부 실시예에서, 검출은 객체 검출이거나, 이는 사용자가 아닌 환경과 관련된 특징 검출일 수 있다. 다른 기능은 사용자에 의해 결정되는 임의의 기능인 사용자 정의 기능이다. 일부 실시예에서, 사용자 정의 기능은 수학적 연산자일 수 있다. 일부 실시예에서, 이 기능은 소스를 다른 사전 선택된 기능 또는 기계 학습 파이프라인(훈련 데이터 또는 입력 데이터 또는 인코딩 데이터로서)에 입력한다. 다른 기능은 소스에 주석 및 주석 층을 추가하기 위한 주석 기능, 맞춤형 코드를 생성하고 컴파일하기 위한 코드 블록 기능 및 기존의 이미지 처리 기능을 갖 는 소스 이미지 또는 비디오를 처리하기 위한 이미지 처리 기능을 포함한다. 코드 블록 기능은 생성 AI의 도움을 받을 수 있으므로, 코드 블록은 훈련 데이터에 기초하여 자동으로 생성 되고 소스 데이터와 병합된다. 일부 실시예에서, 코드 블록 기능은 단말기를 측면 윈도우 또는 측면 디스플레이 에 표시할 수 있으며, 사용자는 피드백을 통해 실시간으로 AI 생성 코드를 수정하거나 영향을 미칠 수 있다. 예를 들어, 원격 환경 탐색 또는 검색 및 구조 작업에서 카메라는 사용자가 장면을 조사할 수 있도록 표시할 이 미지를 캡처할 수 있다. 기본 디스플레이 층은 장면을 표시하고 다층 디스플레이 하이라이트의 제2 층은 사람이 나 얼굴을 검출하도록 사용자 정의 기능으로 프로그래밍된다. 또한, 사용자 정의 기능 또는 병렬 기능의 하위 루틴을 사용하면 구조 팀이 구조의 우선순위를 정할 수 있도록 사람이 처한 위험 수준을 정량화하여 더 높은 수 준의 장면을 이해할 수 있다. 일부 실시예에서, 비디오는 시뮬레이션에 기초한 훈련 비디오이며, 사용자는 위험 수준과 구조 전술을 결정하도록 요청받는다. 이 예는 도 6i에서 추가로 논의된다. 일부 실시예에서, 다양한 ML/AI 엔진은 입력에 대해 작동하는 별도의 기능이다. 예를 들어, 클릭 가능한 훈련 비디오에서, 사용자는 디스플레이 컨텐츠 내의 다양한 다른 데이터에 기초하여 이미지의 구성요소를 선택하라는 요청을 받을 수 있다. AI 엔진은 가능한 선택이나 사용자의 시선을 기반으로 가능한 결과를 예측한다. 훈련의 난이도, 시간 응답 및 미래 전개는 사용자 동작 및 AI 훈련에 기초하여 동적으로 조정될 수 있다. \"시각적 환경/UX 이머저(immerser)\"인 도 5j에서, 입력 소스는 시각적 환경의 생성을 위해 구성되는 소스일 수 있다. 이러한 시각적 환경은 가상 몰입 기능 블록(16J)이 사용되도록 몰입형 원격 회의 또는 온라인 강의실용일 수 있다. 원격 회의는 협업 소프트웨어 애플리케이션의 예이다. 이 기능 블록은 도 5c에 설명된 실시예의 일부 에 대해 사용될 수도 있다. 여기서 기능 블록은 가상 화이트보드 공간을 공유하기 위한 화이트보드 기능을 포함하며, 이는 예를 들어 다층 애플리케이션에서 투명한 수정을 하거나 다층 디스플레이 상에 표시하기 위해 2D 또는 3D 컨텐츠를 최적화하도록 구성된 다층 기능을 사용하여 다른 비디오 소스에 오버레이될 수 있다. 이 기능은 시각적 컨텐츠를 취하고 가상 깊이를 최적화하여 데이터를 표시할 수 있다. 최적화는 인간 뷰어의 깊 이 인식과 비교하여 초점 깊이 정보를 최소화한다. 또한, 주석 기능은 주석을 오버레이하고, 기하학적 변환 기능은 다양한 캡처된 이미지를 조정하여 이를 시각적 환경에 매핑하며, 이미지 처리 기능은 디스플레이 컨텐츠의 다양한 층에 대한 이미지 처리를 수행한 다. 예를 들어, 이미지 처리 기능 중 하나는 배럴 또는 핀쿠션 왜곡(pincushion distortion), 깊이 리매핑 또는 자동 장면 블러링/디블러링에 대해 보상하기 위해 사용자의 이미지에 대한 기하학적 변환을 실행하도록 프로그 래밍된 왜곡 보상 기능일 수 있다. 다른 예에서, 공유된 화이트보드 공간은 제1 초점 평면에 투사도리 수 있으며, 사용자는 제2 초점평면에 투사되어 현실적인 가상 강의실을 만들 수 있다. 기하학적 변환 기능은 컨텐 츠가 어느 초점 평면에 있는지 그리고 웹캠에 대한 사용자의 물리적 위치에 기초하여 객체의 크기를 자동으로 조절한다. 일부 실시예에서, 웹캠은 캡처된 컨텐츠가 가상 강의실 또는 작업 공간과 같은 시각적 환경의 일부로서 디스플 레이 시스템에 표시되도록 환경을 캡처하는 카메라 시스템 비디오의 일부일 수 있다. 객체 검출 기능은 물리적 객체나 물리적 화이트보드와 같은 장면 내 중요한 객체를 인식하고 분할하여 시각적 환경에 병합될 수 있다. 이 미지 처리 기능 및 기하학적 변환 기능은 환경 장면에 대해 작용하고 장면의 객체를 기하학적으로 워핑 하여 시각적 환경에 오버레이할 수 있다. 사용자를 가리키는 다른 카메라에 의해 검출된 시선에 기초하여, 디스 플레이 시스템은 신경 방사 필드(NeRF)를 사용하여 시각적 환경에서 투명 구성요소의 시점을 조정할 수 있다. 이 예는 도 6j에서 추가로 설명된다. 다른 예로서, 화이트보드 기능은 예를 들어 온라인 코스에 대한 온라인 레슨에서와 같이 사용자가 별도의 애플리케이션을 공유하거나 별도의 애플리케이션을 카메라 소스와 병합할 수 있게 한다. 공유된 컨텐츠는 기존 공유 메커니즘일 수 있거나, 이는 컨텐츠가 동적으로 변형되어 뷰어의 요구에 맞게 조정되는 동적 메커니즘일 수 있다. 예를 들어, 화이트보드 기능에 대한 입력은 비행 궤적의 데이터세트일 수 있으며, 기능은 해당 데이터 를 다층 비행 시뮬레이터에 오버레이되는 시각적 궤적으로 표시하도록 구성된다. 본 실시예에서는 특정 입력 소스가 설명되었지만, 임의의 디지털 컨텐츠가 소스로 입력될 수 있다. 일부 실시예 에서, 소스는 다른 기존 앱, 기존 웹사이트, 웹사이트의 그룹을 포함한다. 예를 들어, 가상 환경/UX 이머저 기 능 블록(16J)에 대한 입력은 기존 상용 소프트웨어로부터의 원격 회의 통화일 수 있다. 다른 예는 게임 및 월드 워핑 엔진의 기능 블록(16G) 또는 소프트웨어 엔진/데이터 어셈블러 기능 블록(16F)이 기존 기존 게임 엔진 환 경을 입력으로 취할 수 있다는 것이다. 도 6a 내지 6j는 각각 도 5a 내지 5j의 예시적인 실시예에 대한 흐름도를 도시한다. 도 6a는 대화형 훈련 비디오를 생성하도록 구성되는 도 5a의 기능 블록에 대응하는 흐름도를 나타낸다. 사 용자의 SLAM 데이터는 단계 83에서 포즈 추정 기능(15A)에 입력되며, 이는 입력으로도 포즈의 사전을 가질 수 있다. 출력은 사용자의 포즈의 분류이다. 소프트웨어는 단계 84에서 사용자 포즈가 캐릭터 포즈와 충분히 일 치하는지 여부를 결정한다. 만약 그렇다면, 단계 85A에서 시스템은 훈련 비디오를 완전한 것으로 보여주거나 계 속하도록 하는 제1 디스플레이 컨텐츠를 출력한다. 그렇지 않은 경우, 단계 87에서 계산 블록에서 차이가 계산 되며, 단계 85B에서 사용자가 스스로 수정할 수 있도록 비디오의 강조된 부분을 보여주는 제2 디스플레이 컨텐 츠가 출력된다. 포즈 추정기는 피드포워드 신경망에 의해 생성될 수 있으며, 인코더를 이용하여 포즈를 벡터 공 간에서 분류하고 그 차이를 계산함으로써 사용자와 캐릭터 간의 차이를 계산할 수 있다. 도 6b는 도 5b에 설명된 바와 같은 대화형 비디오에 대한 흐름도를 나타낸다. 이 흐름도에서, 사용자의 시 선은 뷰 초점을 추정하기 위한 추정 뷰 초점 기능(15B)에 대한 입력이다. 출력은 디스플레이 시스템의 시선 위치이다. 그러면 소프트웨어는 단계 84에서 결정을 내린다. 초점의 객체가 판매 가능하다면, 제1 디스플레이 컨텐츠(85A)로서 객체에 대한 추가 정보가 표시된다. 그렇지 않다면, 디스플레이는 시선이 변할 때까지 동일한 비디오를 유지하는 제2 디스플레이 컨텐츠(85B)를 표시한다. 도 6c는 도 5c로부터의 애플리케이션을 강조하는 흐름도을 나타낸다. 이 흐름도에서, 사용자 제스처는 식 별된 제스처를 표시 가능한 제스처를 나타낼 수 있는 제1 계산 블록(87A)으로 출력하는 제스처 추정 기능(15C 1)에 대한 제1 입력(83A)이다. 동시에, 카메라 시스템은 캡처된 이미지를 제2 입력(83B)으로 기하학적 추정 기 능(15C2)에 입력하고, 이는 두 기능의 출력을 표시 가능한 제스처를 포함하는 디스플레이 컨텐츠로 결합할 수 있는 제2 계산 블록(87B)에 정보를 출력한다. 추정된 기하학적 구조 및 표시 가능한 제스처가 결합되어 표시 되기 전에 제스처를 변형하거나 워프한다. 도 6d는 도 5d의 장면 분석 예 또는 동작 리포터의 흐름도를 나타낸다. 실시간 비디오는 장면 이해 분석 기능(15D)으로의 입력이다. 기능은 비디오의 프레임을 비교하고 이들을 상호 연관시킨다. 상관관계는 특징 기반일 수 있다. 출력은 계산 블록에서 어떤 프레임이 사용자가 미리 결정할 수 있는 지정된 활동과 관련되 어 있는지 식별한다. 출력은 원본 실시간 비디오와 함께 프레임의 세트로 구성된 디스플레이 컨텐츠로 표시 된다. 장면 이해 분석은 CNN 또는 지역 기반 CNN(R-CNN)을 통해 또는 트리 검색을 통해 완료될 수 있다. 도 6e는 도 5e에서 논의된 예시적인 실시예에 대한 흐름도를 나타낸다. 사용자 코드는 코드를 컴파일하고 그 결과를 병합 기능(15E)에 입력하는 제1 계산 블록(87A)에 대한 입력이다. 컴파일된 코드는 또한 제2 계산 블록(87B)에서 기능 또는 벤치마크 테스트를 위해 독립적으로 분석되며, 그 결과는 병합 기능(15E)에 도 입 력된다. 병합 기능은 사용자 코드와 벤치마크를 라이브러리에 저장될 수 있는 기존 코드 블록과 비교하거나, 이 는 AI 모듈을 사용하여 생성 사전 훈련된 변환기를 사용하여 새로운 코드를 생성할 수 있다. 그러면 하나 이상 의 새로운 코드가 병합 코드로 출력되고, 이는 제3 계산 블록(87C)에서 기능에 대해 분석된다. 결과적인 병합 코드와 분석은 사용자가 비교할 수 있도록 원래 코드와 함께 표시 컨텐츠로 표시된다. 도 6f는 도 5f로부터의 실시예의 기능을 설명하는 흐름도를 나타낸다. 데이터베이스는 데이터 유형 라이브 러리인 사전을 가질 수 있는 UX 분석 기능(15F)에 입력된다. 데이터 유형 라이브러리는 다양한 형태의 데이터, 파일 포맷, 애플리케이션뿐만 아니라 프레젠테이션의 최상의 모드에 대한 정보를 포함할 수 있다. UX 분석은 데이터베이스 데이터의 제안된 시각화를 계산 블록으로 출력하고, 이는 이후 디스플레이 시스템에 디스플레이 컨텐츠로 표시된다. 도 6g는 게임 엔진 또는 테스트용으로 구성된 도 5g에 설명된 실시예와 관련된 흐름도를 나타낸다. 사용자 는 AI 컨텐츠 생성 기능(15G)에 입력으로서 정보 또는 사용자의 시선을 입력한다. AI 컨텐츠 생성기는 게임 스타일, 장르, 캐릭터 또는 게임 환경에 대한 정보를 포함하는 게임 엔진 사전을 가질 수 있다. AI 컨텐츠 생성기는 새로운 게임 모드 또는 그래픽을 계산 블록으로 출력하고, 이는 디스플레이 컨텐츠로서 디스 플레이 시스템에 시각적으로 표시된다. 도 6h는 웹사이트 테스트 소프트웨어로 사용하기 위해 구성된 도 5h의 실시예에 대한 흐름도를 나타낸다. 사용자 입력은 추적 특징 사용 기능(15H1)에 입력되며, 이는 과거 사용에 기초하여 웹사이트 특징을 자동으 로 업데이트하고 계산 블록의 결과를 제1 표시 컨텐츠(85A)로서 확장된 디스플레이에 표시한다. 예를 들어, 이 기능은 단순히 커서 좌표의 위치를 시간 순서로 추적한 다음 커서가 가장 많은 시간을 소비하는 위치를 식별 할 수 있다. 업데이트된 특징 웹사이트는 가장 가능성 있는 커서 위치에 배치되는 특징의 세트로부터의 특징일 수 있다. 수정된 웹사이트의 확장된 디스플레이 컨텐츠는 사용자가 변경 사항을 비교하기 위해 원래 웹사이트 옆에 있을 수 있다. 추적 기능의 출력은 수정 사항을 제안하는 AI 기능(15H2)에 입력될 수도 있으며, 이는 원래 웹사이트 디스플레이 위에 주석 층으로 제2 디스플레이 컨텐츠(85B)로 표시된다. 도 6i는 검색 및 구조 작업을 위한 도 5i의 예시적인 실시예에 대한 흐름도를 나타낸다. 실시간 비디오는 객체 식별 기능(15I1)에 입력된다. 이 기능은 CNN 또는 R-CNN일 수 있다. 기능의 출력은 제1 계산 블록 (87A)에서 위험에 처한 사람을 식별하고 해당 정보를 제1 디스플레이 컨텐츠(85A)로서 디스플레이 시스템에 표 시한다. 디스플레이 방법은 예를 들어 개인의 이미지를 밝게 하거나 해당 위치에 주석을 달 수 있다. 객체 식별 기능의 출력은 장면 이해 기능(15I2)에 입력되며, 이는 특정 위험, 예를 들어 화재나 전기 위험이 가장 위험할 수 있는 장면을 분석한다. 출력은 제2 계산 블록(87B)에서 이러한 위험의 식별이며, 이는 제2 디스플레이 컨텐 츠(85B)로서 디스플레이 시스템에 표시된다. 출력은 구조할 개인에 대한 절차 또는 명령을 포함할 수 있다. 도 6j는 원격 회의 또는 ARVR 애플리케이션의 도 5j의 예시적인 실시예에 대한 흐름도를 나타낸다. 카메라 시스템은 사용자를 포함할 수 있는 환경을 캡처한다. 해당 정보는 환경에서 중요하거나 관련된 객체를 식별하는 객체 식별 기능(15J1)에 제1 입력(83A)으로 입력된다. (이는 가중치의 상이한 세트를 갖는 CNN을 사용한다는 점 에서 도 6i와 비교하여 다른 객체 식별 기능일 수 있다.) 식별은 사전 또는 룩업 테이블과 관련될 수 있거나, 중요한 객체는 미리 지정될 수 있다. 출력은 계산 블록에 도시된 바와 같이 환경의 이미지를 시각적 환경에 오버레이한 것이다. 사용자의 입력, 시선 또는 SLAM 데이터는 NeRF 기능(15J2)에 대한 가상 환경 입력(83B)와 함께 제2 입력으로 입력될 수 있으며, 이는 완전히 연결된 심층 신경망으로 구현될 수 있으며 시각적 환경의 다 양한 관점을 계산한다. 결과는 디스플레이 시스템에 디스플레이 컨텐츠로 표시된다. 도 7a 내지 7g는 사용자 경험을 지원하거나 영향을 미치기 위해 예측 특징을 사용하는 다양한 소프트웨어 애플 리케이션을 묘사하는 도 2b의 상이한 실시예를 설명한다. 일부 실시예에서, 현재 설명된 소프트웨어 애플리케이 션은 도 2a 및 도 5a 내지 5j의 방법뿐만 아니라 도 4a 및 4b에 논의된 STW 인터페이스를 사용하여 생성된다. 도 7a는 과거의 동작 및 이벤트가 사용자 입력과 함께 처리되어 상이한 미래의 동작과 가능성에 대한 예측을 생 성하는 일반적인 \"펀넬 확장기\"라는 실시예를 설명한다. 이 실시예에서, 사용자는 과거 사용에 대한 컨텐츠 또는 정보를 묘사하는 과거 컨텐츠 디스플레이 이미지(9A) 및 미래 사용에 대한 컨텐츠 또는 정보를 묘사하는 미래 컨텐츠 디스플레이 이미지(9B)를 더 포함하는 중앙 디스플레이 이미지를 보고 있다. 사용자는 디스플레 이 시스템과 쌍을 이루는 로컬 소스를 통해 컨텐츠를 볼 수 있다. 일반 기능(15A, 15B)뿐만 아니라 AI 모듈 은 과거 및 현재 컨텐츠뿐만 아니라 사용자 입력을 입력으로 취할 수 있어 미래 동작 가능성의 확장된 시각화를 생성할 수 있다. 인포그래픽은 유용한 방식으로 과거 컨텐츠를 표시할 수 있다.기능에 대한 입력은 임의의 기간의 현재 사용 및 과거 사용이 될 수 있다. 일부 실시예에서, 기능은 추천 엔진 이며, 사용자 또는 사용자의 이력 또는 프로필은 설정 동작을 결정한다. 다른 기능은 확률적이거나 시간에 의존 한다. 신경망을 포함하는 기능은 시스템 또는 센서 입력에 대한 사용자 입력을 입력으로 취한다. 일부 실시예에 서 과거 동작의 이력이 인포그래픽으로 표시된다. 일부 실시예에서 인포그래픽은 각 가지가 사용자에 의해 취해 진 공통 동작의 집합체인 확장 가능한 트리 그래프이다. 트리 그래프의 줄기는 해당 동작 세트의 타임 스탬프를 나타내며, 각 가지의 범위는 각 동작 유형에 소요되는 시간의 양과 연관될 수 있다. 시간 지연을 기능으로 사용하는 실시예에서, 사용자는 데이터베이스를 사용하거나, 데이터 입력을 수행하거나, 시뮬레이션의 수치 결과를 분석하고 있다. 기본 디스플레이 컨텐츠는 사용자가 데이터를 입력하는 스프레드시트 이다. 가장 최근 활동은 입력된 가장 최근의 데이터이므로 제2 층 또는 기본 이미지에 인접한 확장된 FoV에 표 시되는 기본 예측 활동은 계속해서 데이터를 입력한다. 소프트웨어는 입력할 데이터를 예측할 수 있거나, 이는 데이터베이스 또는 스프레드시트의 확장된 영역을 표시할 수 있다. 제2 최근 활동은 문서를 여는 것이었으므로 소프트웨어는 새 문서를 열거나 현재 문서를 닫을 것으로 예상하여 데이터베이스 또는 스프레드시트를 저장하라 는 표시를 2차 디스플레이 층에서 예측한다. 가장 오래된 동작은 시뮬레이션과 같은 데이터 생성을 위해 상이한 애플리케이션을 사용하는 것이었다. 제3 예측 동작은 시뮬레이션을 다시 실행하여 파라미터를 수정하는 것이다. 도 7b는 상이한 동작 및 가능성에 대한 예측이 가중 시간 감쇠 또는 확률적 요인에 따라 표시되는 \"확률적 예측 기\" 실시예를 설명한다. 실시예에서, 사용자는 과거 컨텐츠 디스플레이 컨텐츠(9A) 및 미래 컨텐츠 디스플레이 컨텐츠(9B)를 더 포함하는 디스플레이 이미지를 보고 있다. 과거와 현재의 사용은 예를 들어 가장 가능성이 높은 다음 동작을 계산하기 위해 확률 분포를 사용하고 이에 따라 이를 표시하는 기능에 입력된다. 가 장 가능성이 있는 미래 동작은 디스플레이 컨텐츠의 가장 눈에 띄는 확장 부분에서 중앙에 가장 눈에 띄게 표시된다. 매체 돌출도(medium prominence)가 높은 디스플레이 컨텐츠의 확장된 부분에는 매체 가능성이 높은 미래 동작이 덜 두드러지게 표시되며, 가능성이 가장 낮은 미래 동작은 가장 먼 곳에 가장 눈에 띄지 않게 표시된다. 일부 실시예에서, 디스플레이 컨텐츠는 다층 디스플레이 또는 호버링 그래픽으로 표시되며, 여 기서 가장 가능성 있는 컨텐츠는 가장 밝거나 사용자에게 가깝다. 사용자는 입력 장치 또는 센서를 통해 직접 정보를 입력할 수 있으며, 이 데이터로부터 동작을 재배열하거 나 동작을 동적으로 변경할 수 있다. 일부 실시예에서, 센서는 사용자 또는 환경에 관한 정보를 캡처하고 해당 정보를 디스플레이 시스템에 전달하여 예측 능력을 지원한다. 확률적 방법은 다음과 같이 공식화될 수 있다. 모든 사용자 동작을 벡터 공간 x로 인코딩한다. 이는 특정 애플 리케이션에 대한 것일 수 있거나, 이는 애플리케이션의 세트에 대한 것일 수 있다. 일부 실시예에서, 0이 아닌 벡터는 기본적으로 희소하므로 새로운 동작이 추가될 수 있다. 다음으로 확률 밀도 기능을 정의한다. 일부 실시 예에서, 종형 곡선(bell curve)(가우스 함수), 로렌츠(Lorentizian), 또는 코시(Cauchy) 함수일 수 있다. 이러 한 기능은 개별 동작의 세트에 대해 구분될 수 있다. 일부 실시예에서, 확률 밀도 함수는 특정 표준 편차, 왜곡 (skew), 첨도(kurtosis) 또는 모멘트 또는 중심 모멘트의 세트를 유지하는 것과 같은 특정 제약 조건에 의해 정 의된다. 또는 그 대신에 특성 함수, 순간 생성 함수, 누적 함수가 주어진다. 일부 실시예에서, 확률 특성은 벡 터 공간 x에 속하는 다양한 동작 xi의 상관관계에 의해 또는 시스템이 보정되는 기간 동안 사용자 동작의 상대적 빈도에 의해 정의된다. 일부 실시예에서, 동작의 시퀀스는 어떤 의미에서는 고정적이며, 예를 들어 넓은 의미에서는 고정적이거나, 엄 밀히 고정적이거나 증분적으로 고정적이다. 일부 실시예에서, 시스템은 고정되지 않으며, 예를 들어 시간 또는 다른 외부 요인에 따라 달라진다. 동작의 제2 세트는 제2 벡터 공간 y로 인코딩된다. 일부 실시예에서, 예를 들어 3 또는 4 또는 9 개와 같이 동 작의 2 개 초과의 세트가 있다. 사용자가 특정 동작 xi에 대해 디스플레이 시스템을 사용하는 경우, 소프트웨어 는 모든 조건부 확률을 계산한다."}
{"patent_id": "10-2023-0137211", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "각각의 잠재적인 동작 yj에 대해, 두 이벤트 A 및 B에 대한 조건부 확률 P(A｜B)는 B가 발생했다는 조건 또는 제약에서 A가 발생할 확률이다. 조건부 확률은 A 및 B가 모두 발생할 확률 P(A 및 B)와 B가 발생할 확률 P(B)의 비율로 간주할 수 있다. 위의 pij값은 최대 확률, 제2 최대값 또는 일부 다른 측정항목을 사용하여 동작을 결정한다. 그런 다음 디스플레 이 시스템은 2차 가상 디스플레이 또는 디스플레이 층의 세트에 이러한 잠재적인 동작을 표시한다. 일부 실시예 에서, 사용자 동작을 예측하는 방법은 초과 예측, 시계열 분석 또는 다른 시리즈 분석을 사용한다. 일부 실시예에서, 도 7b에 도시된 바와 같이, 사용자는 소셜 미디어 플랫폼과 상호작용하고 있다. 중앙 디스 플레이는 랜딩 페이지를 표시한다. 사용자의 이력 및 디스플레이 시스템 또는 애플리케이션 자체에 대한 다 수의 사용자의 이력에 기초하여, 확률적 기능은 사용자가 일련의 업데이트를 스크롤할 가능성이 가장 높은지 결 정한다. 가장 가능성이 높은 미래 동작은 디스플레이 컨텐츠의 가장 눈에 띄는 확장 부분에서 중앙에 가장 눈에 띄게 표시된다. 이 컨텐츠는 결과적으로 확장 업데이트 또는 스크롤 피드를 표시할 수 있다. 다음 윈도우 에서, 매체 가능성이 높은 미래 동작은 매체 중요성의 디스플레이 컨텐츠의 확장된 부분에서 덜 두드러지게 표시된다. 마지막으로, 가능성이 가장 낮은 미래 동작은 가장 원격으로 눈에 띄지 않게 표시된다. 이 컨텐 츠는 마케팅 캠페인 클릭을 포함할 수 있다. 사용자가 소셜 미디어 플랫폼과 상호작용하면 확률 분포가 업데이 트되고 디스플레이 컨텐츠가 재배열된다. 다양한 센서는 사용자에 대한 정보를 캡처할 수 있다. 사용자는 임의의 입력 수단을 사용하여 제안된 컨텐츠를 윈도우로 가져올 수 있다. 일부 실시예에서, 예측된 동작은 다른 애플리케이션으로의 전환에 대응한다. 예측 알고리즘은 가능한 다양한 사용자 동작에 대한 데이터를 사용하며 이벤트는 생산성, 성공/실패, 사용자 만 족도에 대한 메타데이터를 포함한다. 예를 들어, 소셜 미디어 사이트를 처음 탐색하기 시작한 사용자가 광고를 클릭하고 항목을 구매할 가능성이 가장 높으며 두 번째로 가능성이 높은 이벤트는 메시지에 응답하는 것이다. x1 을 소셜 미디오 사이트 탐색, y1을 광고 클릭, y2를 메시지에 응답하는 이벤트로 설정하여, p11=0.8 p21=0.5이다. 이 시나리오에서, 중앙 2차 디스플레이는 광고에 대한 컨텐츠를 표시하고 제2 2차 디스플레이는 메시지 응답에 대한 컨텐츠를 표시한다. 그러나, y11에 대한 메타데이터는 광고를 클릭하면 예산 모니터링 앱에서 초과드래프트 (overdraft) 수수료가 발생했음을 나타낸다. 따라서, 디스플레이 시스템은 p11의 값을 0.5 미만, 예를 들어 0.4 로 줄일 수 있다. 또는 디스플레이 시스템은 디스플레이 컨텐츠에 경고 메시지를 포함할 수 있다. 도 7c는 사용자 초점, 시점, 생산성 스타일, 메타데이터 또는 환경 요인에 기초한 우선순위 기준 P1, P2, P3에 기초하여 상이한 옵션과 가능성이 상이한 층에 표시되는 \"동적 우선순위\"라는 실시예를 설명한다. 가장 높은 우 선순위로 간주되는 컨텐츠(P1)는 사용자가 볼 수 있도록 중앙 메인 스크린에 표시되는 반면, 제2 우선순 위 컨텐츠(P2)는 리마인더로서 FoV 2D 확장에 자동으로 표시된다. 우선순위 중 일부는 다층 디스플레이(1 1)에 구성될 수 있으며, 가장 높은 우선순위는 사용자에게 가깝다. 사용자가 평소에 하는 제안은 제3 우선순위 (P3)로 예를 들어 에지 디스플레이로 표시된다. 중앙 디스플레이에 대한 컨텐츠의 거리는 컨텐츠의 우선순 위 및/또는 중요도를 나타낸다. 일부 실시예에서, 이는 시간 의존적이며 사용자 이력에 의존한다. 일부 실시예 에서, 센서는 사용자 또는 환경에 대한 정보를 캡처하고 그 정보를 디스플레이 시스템에 전달하여 예측 능력을 보조한다. 사용자는 제어 기능에 직접 정보를 입력하여 특정 우선순위를 무시하거나, 리마인더를 나타내 거나, 권장 작업을 수행하는 능력을 갖는다. 우선순위 기반 실시예는 달력이나 디지털 목록에 나열된 항목을 식 별하거나 비교함으로써 생성될 수 있다. 또는, 실시예가 사용자 입력 및 시점을 포함하는 경우, 실시예는 예를 들어 상이한 사용자 조건 하에서 상이한 시점에 작업이 소요되는 기간을 추적하고 역사적으로 가장 빠르게 완료 된 때 시간에 작업을 제안할 수 있다. 일부 실시예에서, 디스플레이 시스템 컨텐츠는 생산성을 위해 구성된다. 사용자는 하루 중 특정 시간에 디스 플레이 시스템과 상호작용하고 있으며, 중앙 디스플레이에 표시되는 메인 우선순위 동작은 이메일에 응답하 는 것이다. 시점에 기초하여, 소프트웨어는 해당 시점의 제2 동작에 대한 사용자의 생산성 수준으로 인해 제2 동작(P2)의 우선순위가 높다는 것을 감지한다. 일부 실시예에서, 다음 우선순위(P2)는 달력에 열거된 기한을 기 반으로 하며 FoV 2D 확장으로 표시된다. 제3 우선순위(P3)는 청구서, 투자 계정, 세금과 같은 개인 재정을 모니터링하는 것이며, 이는 모두 에지 디스플레이에서 잠재적인 동작으로 나타난다. 일부 실시예에서, 우선 순위(P3)는 다층 디스플레이의 2차 층이므로 사용자는 눈을 집중할 필요 없이, 즉 주변 위치에 유지할 필요 없이 이를 상기할 수 있다. 일부 실시예에서, 상이한 우선순위는 모두 단일 작업과 관련될 수 있다. 예를 들어, 중앙 우선순위는 중요한 금 융 거래를 만드는 것을 포함하며, 제2 우선순위는 소프트웨어 프로그램이 수정이나 다른 거래를 제안하도록 해당 거래의 결과에 대한 현금 흐름을 모니터링할 수 있으며, 제3 우선순위는 주택 계약금, 은퇴 활동 또는 여행 계획을 위한 저축 증가와 같은 장기적인 재정 목표의 세트가 표시될 수 있다. 디스플레이 시스템은 또한 상이한 차원의 접선 활동을 배열할 수도 있다. 예를 들어, 재무 관련 우선순위는 모 두 측면 확장에 표시될 수 있다. 주택에 대한 모기지 지불과 관련된 디스플레이 이미지는 주택 개조, 필요한 수 리 또는 중요한 날씨 경고에 대한 주석이 포함된 여러 깊이 층을 가질 수도 있다. 배열은 사용자 입력 또는 감 지 데이터에 따라 동적으로 변경될 수 있다. 일부 실시예에서, 우선순위(P1, P2, ...)는 사용자 프로필을 입력으로 취하고 다양한 추천 활동을 출력하는 추 천 엔진에 기반한 추천이다. 추천된 동작은 단일 소프트웨어 애플리케이션 내에 있거나(예를 들어, 사용자의 독 서 이력과 관련된 가능한 모든 디지털 라이브러리 도서 표시), 이들은 다수의 앱에 걸쳐 있을 수 있다(예를 들 어, 특정 소셜 미디어 앱에서 채팅 특징 사용의 사용자 이력에 기초하여, 엔진은 상이한 소셜 미디어 플랫폼에 서 다수의 채팅 스트림을 추천한다). 도 7d는 예측 및 추천이 애플리케이션 내에서 또는 다수의 애플리케이션에 걸쳐 이루어질 수 있는 \"병렬 검색 추천기\"라는 실시예를 설명한다. 일부 실시예에서, 예측 및 추천은 수직 검색 엔진 기능에 기초할 수 있다. 사 용자는 중앙 디스플레이 이미지를 보며, 현재 동작에 기초하거나 또는 사용자 질의에 기초하여, 복수의 수직 검색 엔진이 복수의 디스플레이 이미지에 생성된다. 예를 들어, 사용자는 수직 검색 엔진 기능으로 질 의를 입력한다. 일부 실시예에서, 디스플레이 이미지는 다층 디스플레이에 배열되거나 수직으로 확장된 FoV 의 열로서 배열된다. 한 열에서 검색이 진행되면, 사용자의 현재 동작이나 질의를 기반으로 동적으로 업데이트 되지만, 이는 사용할 수 있는 다른 잠재적인 검색에도 참여하고 해당 결과를 디스플레이 이미지의 다른 세트에 표시한다. 제1 검색에서 검색된 데이터는 예를 들어 자기 주의 메커니즘을 사용하여 키워드에 주의를 기울이는 기능에 입력되며, 그 다음 해당 정보를 제2 검색에 대한 새로운 질의로 사용하며, 이는 제2 다층 디스플레 이에 표시될 수 있다. 하나의 검색 엔진이 다른 검색 엔진을 생성하기 위해 사용하는 기능 관계는 다양한 섹션 또는 제1 검색의 상관관계에 주의를 기울이는 변환기일 수 있다. 일부 실시예에서, 사용자는 연구 주제에 대한 문헌 검색을 수행하고 있다. 기본 검색은 사용자가 키워드 A, B 및 C를 사용하여 시작된다. 가상 디스플레이 이미지의 제1 세트에 수직 검색이 나타난다. 소프트웨어 메커니즘 은 검색 결과를 능동적으로 스캔하고 새로운 키워드 D를 발견한다. 가상 디스플레이 이미지의 제2 세트는 D에 대한 검색 결과만 보고하거나 A 내지 D의 조합에 대한 검색 결과를 보고한다. 일부 실시예에서, 사용자는 검색 파라미터를 과학적 소스 및 저널로 제한했지만, 소프트웨어는 초기 키워드의 특허 이력을 나타내는 문구를 검출 하고 제2 검색에서 선행기술을 표시한다. 처음 두 번의 수직 검색 수치를 분석한 후 제3 검색은 원하는 연구 주 제에 대한 수치 시뮬레이션 또는 정량적 분석을 지원할 수 있는 다양한 다운로드 가능한 실행 파일을 표시할 수 있다. 수직 검색 엔진은 표준 수직 검색 알고리즘(예를 들어, 크롤링, 인덱싱 및 순위 지정)을 사용할 수 있으며 객체 식별 알고리즘은 다음 검색을 시작하기 위해 키워드 또는 문구를 식별하는데 사용될 수 있다. 도 7e는 가상 보조 아바타는 중앙 디스플레이 이미지를 보고 있는 사용자와 상호작용하고 이메일 응 답, 스케치 또는 디자인 드래프팅, 채팅, 메모 작성 등과 같은 상이한 작업 기능을 달성하기 위해 사용자 명령에 응답할 때 FoV 2D 확장에 표시되는 \"아바타 보조 예측기\"인 실시예를 설명한다. 사용자가 사용할 수 있는 상이한 작업, 예측 및 추천은 가상 보조자에게 내릴 명령으로 표시된다. 일부 실시예에서, 가상 아바타는 사용자에게 항상 직접적으로 보이지 않거나 음성 명령을 통해 사용자에 의해 호출된다. 실시예에서, 가상 아바타는 사용자가 주요 목표를 완료하는 것을 돕기 위해 2차 작업을 지원하고 있다. 예 를 들어, 사용자는 텍스트, 도면 및 참조가 필요한 문서를 생성하고 있다. 사용자는 주요 텍스트 컨텐츠를 생성학하고 있으며 아바타 시스템에 도면의 기본 파라미터: 도면 크기, 해상도, 포맷을 입력했다. 아바타는 이 에 따라 이미지 파일의 세트를 편집한 다음 API를 사용하여 이미지에 파일을 통합하는 권한을 갖는다. 아바타는 이미지 컨텐츠 자체를 분석하고 변환기 메커니즘을 기반으로 이미지를 설명하는 단어를 추출한다. 이러한 단어 는 최종 제품을 개선하는데 도움이 되도록 대체 또는 개선된 도면으로 사용자에게 제시되는 웹 검색의 키워드가 된다. 일부 실시예에서, 사용자의 권한은 디스플레이 컨텐츠의 아바타 제어 하위 섹션(23A)에 의해 정의되여, 아바타 는 디스플레이의 특정 윈도우 내의 컨텐츠를 자동으로 모니터링하고, 사용자는 요소를 해당 하위 섹션 안팎으로 드래그해서 상호작용한다. 이는 실시간으로 아바타 권한을 부여하거나 철회하는 역할을 하며, 특정 컨텐츠는 아바타가 어떤 기능을 우선시해야 하는지 동적으로 주장한다. 실시예에서, 사용자는 이미지를 하위 섹션으로 드래 그할 수 있으며, 이는 아바타가 이미지 처리 기술에 참여해야 함을 나타내는 반면, 텍스트 문서의 폴더가 하위 섹션으로 드래그되면 아바타는 이를 참고 문헌(bibliography)을 구축하도록 문학 검색을 수행하여 이를 해석한 다. 실시예에서, 사용자는 시뮬레이션 결과를 분석하고 있으며, 아바타 기능은 결과를 알려진 결과에, 동적 검색 결 과에, 또는 초기 입력 파라미터와 비교하여 분석을 지원한다. 예를 들어, 시뮬레이션의 결과에는 아바타 기능이 입력 데이터와의 불분명한 상관관계를 처리하는 그래프 또는 이미지를 포함할 수 있으며, 아바타는 결과가 물리 적으로 유효하거나 시뮬레이션에 기술적 오류가 발생했음을 암시할 수 있다. 일부 실시예에서, 아바타 보조는 사용자가 테긋트나 그래픽을 입력하기 위한 단말기일 수 있고, 아바타 보조는 입력에 기초하여 계속해서 후속 질문을 촉발할 수 있다. 예를 들어, 사용자는 의자의 이미지를 입력할 수 있으 며, 아바타 보조는 먼저 질문 \"이게 뭔가요?\"를 디스플레이에 생성할 수 있다. 그 다음, 이 컨텐츠 아래에는, \"가구입니다\", \"갈색입니다\", \"나무로 만든 객체입니다\"와 같은 가능한 답변의 세트를 제공할 수 있다. 그 다 음, 이 답변의 세트 아래에는 제1 응답에 의존하는 추가 질문 트리가 있다. 사용자는 언제든지 아바타가 생성한 질문 및 답변을 중단, 지시 또는 안내할 수 있다. 질문 및 답변 전개는 사용자 이력 또는 사용자 설정에 따라 달라질 수 있다. 실시예에서, 복수의 아바타 보조는 파생 컨텐츠에 병렬로 영향을 미칠 수 있다. 예를 들어, 이들은 헬프 센터의 채팅봇일 수 있으며, 사용자는 아바타 보조의 메시지를 모니터링하고 실시간으로 결과에 영향을 미칠 수 있다. 도 7f는 상이한 예측 및 가능성을 동적으로 끌어오는 사용자의 이벤트 클릭 또는 마우스 클릭과 같은 사용자 입 력을 통한 온스트림 클릭에 기초하여 상이한 예측 및 추천이 상이한 이벤트 층(E1, E2, E3)에 표시되는 \"이 벤트 트리거 예측기\"인 실시예를 설명한다. 이벤트는 비디오나 다른 소프트웨어 애플리케이션의 트리거에 의해 자동으로 생성될 수 있거나, 이벤트는 특정 소프트웨어 애플리케이션의 조합이 특정 방식으로 사용될 때 트리거 될 수 있다. 예를 들어, 일부 실시예에서, 사용자는 중앙 디스플레이 이미지에서 페인팅 기술에 대한 비디오 튜토리얼 을 보면서 비디오의 이미지 처리를 수행하는 것을 시작한다. 튜토리얼 동안, 특정 브러시 스토로크는 다중 출력 기능에 의해 검출되며, 사용자가 비디오의 해당 부분을 재생할 때 사용자 클릭은 기능에 입력되고, 해당 브 러시 스트로크에 대한 유사한 튜토리얼이 다른 튜토리얼 E1에서 발견되며, 사용자는 유사한 그래픽 디자인 제품 에 대한 광고가 E2에 표시되도록 브러시의 이미지를 클릭할 수 있으며, 사용자가 튜토리얼의 최종 결과를 보기 위해 비디오를 일시 중지하는 동안, 완제품을 보여줄 향후 장소가 연락처 정보와 함께 표시되거나 튜터에게 후 속 질문위한 온라인 양식이 E3에 표시된다. 이벤트는 FoV 2D 확장에 표시될 수 있다. 또는 이벤트는 다층 디스플레이에 표시될 수 있다. 일부 실시예에서, 기계 학습 알고리즘은 유사한 효과를 달성하기 위한 다양한 대 체 기술 또는 방법을 다른 디스플레이 이미지에 보여줄 수 있다. 다른 실시예에서, 사용자는 비디오 게임을 플레이하고 있다. 사용자는 게임을 탐색하고 특정 이정표에 도달하며, 제1 이벤트 E1은 게임의 다음 단계에서 완료할 작업을 선택할 수 있다. 제2 이벤트는 사용자가 비디 오 게임 환경의 특정 영역을 스크롤하는 것일 수 있으며, 이는 게임의 숨겨진 특징인 디스플레이 이벤트 E2를 트리거할 수 있다. 마지막으로, 사용자가 게임을 일시중지하거나 링크를 클릭하면 제3 이벤트가 트리거될 수 있 으며, E3 디스플레이 컨텐츠는 보너스 특징, 게임 속편 또는 다른 엔터테인먼트 옵션에 대한 마케팅 추가 기능 이다. 임의의 실시예에서, 이벤트 기반 디스플레이 컨텐츠는 사용자 이력에 의해 영향을 받을 수 있다. 다양한 실시예에서, 디스플레이 컨텐츠는 임의의 방식으로 배열될 수 있다. 일 실시예에서, 디스플레이 컨텐츠 는 예를 들어 시각적 스크롤 또는 시각적 벨트를 생성하기 위해 측면으로 배열될 수 있다. 사용자는 시각적 스 크롤이 동적으로 회전될 수 있도록 시선 또는 제스처를 통해 입력을 제공할 수 있다. 사용자는 관심 있는 디스 플레이 컨텐츠에 초점을 맞추고 해당 디스플레이 컨텐츠는 중앙 보기 위치로 이동된다. 다른 디스플레이 컨텐츠 는 순차적으로 이동된다. 예를 들어, 이벤트 기반 예측 디스플레이는 이벤트의 3 개의 확장된 디스플레이를 표 시할 수 있으므로, E1은 좌측에 위치되며, E2는 중앙에, E3는 우측에 위치된다. 사용자가 E1에 시선을 집중시키 면, E1은 오른쪽으로 중앙으로 이동하며, E2는 오른쪽으로 우측으로 이동하며, E3는 좌측 위치로 이동된다. 시 각적 스크롤은 다양한 과거 또는 미래의 시점에 단일 이벤트 또는 동작을 표시하도록 구성될 수 있다. 이는 \"시 간의 스크롤(temporal scroll)\"이다. 예를 들어, 시각적 스크롤은 일련의 잠재적인 시간 종속 동작을 가질 수 있다. 시각적 스크롤은 작업의 다양한 측면 또는 주어진 애플리케이션에 대한 상이한 작업이 별도로 표시되도록 공간적으로 분리될 수 있다. 시각적 스크롤은 시공간적으로 분리될 수 있으므로 가능한 컨텐츠는 시간적으로 스크롤되는 동작 또는 공간적으로 분리된 컨텐츠의 조합일 수 있다. 도 7g는 가능성의 가상 연속체가 동시에 또는 쉽게 보일 수 있도록 파라메트릭 시각화 메커니즘을 고려하는 \"파 라메트릭 시각화 장치\" 실시예를 설명한다. 본 실시예의 예는 다음과 같다. 사용자는 중앙 디스플레이 이미 지에서 영화를 본다. 영화의 컨텐츠는 현재 장면의 주석 또는 대체 결과를 생성하고 이를 확장된 디스플레이 시스템의 확장된 부분에 표시하는 신경망 및/또는 AI 모듈에 공급된다. 사용자는 또한 일반 입력 장치를 사용하여 파라미터 기능에 정보를 입력하며, 이는 또한 라이브러리 를 입력으로 취할 수 있다. 이 파라미터는 사용자가 선호도, 사용자 이력 또는 프로필, 수량 및 주석의 범 위 또는 다른 제약을 AI 및 ML 기능에 입력할 수 있게 한다. 출력(P)은 AI/ML 기능을 조정하기 위한 파라미터의 세트이다. 이 실시예에서, 예를 들어, 파라미터화 중 하나는 영화의 다층 디스플레이 컨텐츠의 세트를 생성하는 프로 필 A를 초래하며, 제1 세트는 상세하고 더 큰 주석 및 시각적 컨텐츠로 시각적 컨텐츠에 대한 주석을 설명한다. 제2 세트는 더 조용하고 작으며, 관련 사운드트랙에 대한 사소한 정보만을 갖는다. 제2 포맷, 프로필 B는 반대 되는 소리에 대한 시각적 정보의 상대적 중요성을 가질 수 있다. 사운드트랙 정보는 호버링 그래픽과 같은 주석과 함께 눈에 띄게 표시되며 시각적 컨텐츠에 대한 일부 기본 정보는 에지 디스플레이로 표시된다. 다른 예에서, 제1 사용자는 영화의 과학적 세부사항에 관심이 있을 수 있고 디스플레이 컨텐츠에 대한 \"밝은\" 설정 파라미터를 설정하여 가능한 주석이 모두 객체 중 일부 또는 영화의 모션의 과학적 또는 기술적 세부사항 을 표시한다. 제2 사용자는 인테리어 디자이너일 수 있으며 디스플레이 파라미터를 \"강함\"으로 설정하여 영화 장면이 집 안의 방일 때마다 장면의 모든 가구, 가정용품 및 다른 상품에 대한 주석에 판매 가능성, 가격, 가용 성 또는 벤더 위치를 포함한다. 이는 출력 디스플레이가 다양한 설정에 따라 균형을 이루는 \"디스플레이 이퀄라 이저\" 기능으로 설명될 수 있다. 도 8a 내지 8d는 도 7a 내지 7g에 설명된 실시예 중 일부에서 미래의 사용자 동작을 예측하기 위한 상이한 프로 세스를 설명한다. 도 8a는 도 7a의 실시예와 관련된 프로세스를 설명한다. 사용자 이력 및 사용자의 현재 동작을 포함하는 사 용자 입력은 예측된 또는 가능한 동작의 디스플레이 결과를 생성하는 예측 기능에 입력된다. 사용 자는 그 다음 어떤 동작을 취해야 하는지에 대한 결정을 내리고, 이는 다음 동작을 초래한다. 현재 동 작은 다음 예측을 위해 사용자 이력에 통합된다. 도 8b는 도 7b의 실시예와 관련된 프로세스를 설명한다. 사용자 입력, 사용자 이력 및 현재 동작은 확률적 상관 예측기에 입력되며, 이는 가능한 또는 예측 된 동작의 디스플레이 결과를 생성한다. 사용자는 다음 동작을 취하기로 결정을 내린다. 그러면 현재 동작은 다음 예측을 위해 사용자 이력에 통합된다. 도 8c는 도 7c의 실시예와 관련된 프로세스를 설명한다. 여기서, 사용자 입력은 우선순위 순위 기능에 입력된 사용자 이력이며, 그 다음 우선순위 상관기에 입력된다. 가능한 동작은 우선순위에 기초하여 순위 가 지정되고 표시 결과는 우선순위가 지정된 동작을 보여준다. 사용자는 다음 동작 현재 동작이 무엇 인지에 대해 결정을 내린다. 일부 실시예에서, 우선순위 상관기는 피드포워드 네트워크, RNN, LSTM, 주의 기반 변환기, 이들의 조합을 포함하는 임의의 종류의 신경망이다. 도 8d는 도 7d의 실시예와 관련된 프로세스를 설명한다. 사용자 입력은 제1 수직 검색 엔진(103A)에 공급되 는 검색 질의이다. 결과는 제1 디스플레이(99A)에 표시된다. 제1 검색으로부터의 데이터는 또한 제2 수직 검색 엔진(103B)에 입력할 키워드에 주의하고 이를 식별하는 변환기에 또한 입력된다. 이 제2 검색의 출력은 제 2 디스플레이 결과(99B)로 표시된다. 일부 실시예에서, 2 개 초과의 수직 검색 엔진이 사용된다. 일부 실시예에 서, 나중 검색의 출력은 이전 검색을 수정하는데 사용될 수 있다. 도 8e는 아바타 보조를 갖도록 구성되는 도 7e의 실시예의 프로세스를 설명한다. 권한(105A)을 갖는 아바타는 가능하거나 예측된 동작에 대응하는 디스플레이 결과를 생성적으로 표시한다. 주어진 권한은 사용자가 현 재 동작에서 다음 동작으로 이동할 때 아바타가 동작을 실행할 수 있게 한다. 다음 동작은 아바타 보 조의 권한(105B)을 수정하고 그에 의해 완료되는 작업의 다음 반복에 영향을 줄 수 있다. 도 8f는 도 7f의 실시예의 프로세스를 설명한다. 사용자의 현재 동작은 다양한 동작 또는 다른 컨텐츠에 대 응하는 디스플레이 결과를 생성하는 이벤트 기반 트리거에 의해 검출된다. 사용자는 다음 동작이 무엇 인지 결정을 내린다.마지막으로, 도 8g는 도 7g의 실시예의 프로세를 도시한다. 사용자 입력, 파라미터 설정은 AI 모듈 또 는 신경망의 강도 및 컨텐츠를 결정하는 파라미터(P)를 생성하는 파라미터화기에 입력된다. 생성 출력 은 주석 층에 대응하는 디스플레이 결과를 초래한다. 도 9a 및 9b는 본 개시의 예측 및 생성 소프트웨어를 지원하기 위해 다양한 기계 학습 알고리즘 및 방법을 묘사 한다. 도 9a는 일반적인 신경망 파이프라인을 보여준다. 입력은 사용자 이력 및 입력이며 잠재적인 동작의 모음 (bag)은 신경망과 같은 기계 학습 아키텍처로 입력 역할을 한다. 신경망은 잠재적인 동작의 세트를 출력한다. 신경망은 단일 사용자의 장기 이력, 디스플레이 시스템 상의 다수의 사용자 또는 이들의 조합으로부 터 도출된 훈련 데이터를 포함할 수 있다. 일부 실시예에서, 신경망은 훈련 데이터에 대해 학습된 사전을 사용한다. 훈련 데이터는 로컬 디스플레이 시스 템, 작업 환경, 사용자의 고유한 세트로부터 나올 수 있다. 일부 실시예에서, 사전 및 학습은 분산된 사용자로 부터의 훈련 데이터를 기반으로 발생한다. 도 9b는 장기 단기 메모리(LSTM) 신경망으로 구성된 순환 신경망의 보다 구체적인 예를 나타낸다. 이 도면에서, 사용자 입력, 이력 및 동작의 모음은 LSTM에 입력된다. 이 입력은 활성화 기능(g1, g2, g3, g4 및 g5)를 사용하여 LSTM에 공급된다. 이전 셀의 입력 및 출력값은 활성화 기능(g1, g2, g3)을 사용하여 신경망 층을 통해 전송된다. 그 다음 곱셈과 덧셈 연산을 통해 이전 셀 상태와 결합된다. 잠재적인 동작이 생성된다(111A). 셀 상태는 신경망 및 활성화 층(g5)을 사용하여 동작되고 활성화 기능(g4)을 사용하여 신경망 이후 현재 동작 및 사용자 입력과 결합된다. 활성화 기능은 무엇이는 될 수 있다. 일부 실시예에서, 이들은 시그모이드 (sigmoid) 또는 tanh 함수이다. 결과는 숨겨진 층 정보(114A)와 함께 LSTM의 다음 셀 반복(113A)에 공급되며, 이는 시퀀스에서 출력되는 제2 잠재적 동작(111B)을 생성하고 업데이트된 숨겨진 층 정보(114B)와 함께 다음 셀 반복(113B)에 공급된다. 제3 동작(111C)이 생성된다. 일부 실시예에서, 사용자 아바타는 예측된 동작 또는 그 하위 세트의 실행(112A, 112B, 112C)에 대한 권한을 갖는다. 활성화 기능은 표준 시그모이드 또는 tan 함수일 수 있다. 일부 실시예에서, 이들은 사용자 정의된다. 일부 실시예에서, 특히 다양한 애플리케이션에서 사용자 입력을 사용하는 이미지/객체 검출 추천을 위한 기존의 신경망, 단순화된 RNN, GRU, CNN을 포함하는 상이한 신경망이 구현된다. 일부 실시예에서, 아키텍처는 일대일, 일대다, 다대일(분류기에서와 같음) 또는 다대다이다. 도 10a 및 10b는 다른 애플리케이션을 위해 구성되는 예측된 동작을 도출하거나, 과거 동작을 분류하거나, 동작 의 세트를 동작의 새로운 세트로 변환하는 변환기 아키텍처에서의 주의를 사용하는 것을 예시한다. 도 10a에서, 사용자 동작 및 이력은 파이프라인에 입력되며 위치(순차) 임페딩(115A)을 통해 변환되어 인코더 블록 에 입력된다. 입력 데이터는 선형 레이어에 의해 질의 Q, 키 K, 값 V를 생성하기 위해 작동된다. 인코딩 블록은 Q, K, V를 결합하고 예를 들어 SoftMax를 통해 정규화한다. 피드포워드 층은 주의 매트릭스 A를 생성하 기 위해 데이터에 대해 작용한다. 일부 실시예에서, 인코딩 블록에 잔여 데이터 바이패스 요소가 있다. 일부 실 시예에서, 다중 인코딩 블록은 병렬로 작동한다. 그 다음 데이터는 다중 헤드 주의 블록을 포함하고 데이터 행 렬을 결합 및 정규화하며 피드포워드 층을 사용하여 데이터에 작용하는 디코딩 블록으로 전송된다. 일부 실시예에서, 잔여 요소 또는 마스킹 블록이 있다. 출력(118i)은 생성적 동작/아바타 반응/잠재적 동작에 대한 검색 결과의 세트이다. 일부 실시예에서, 분류 블록(118A)은 현재 사용되는 동작의 유형을 식별한다. 일부 실시 예에서, 동작은 사용자 아바타에 의해 자동으로 실행된다. 일부 실시예에서, 다중 변환기 헤드 또는 주의의 다중 단계 또는 디코더 및 인코더의 다중 스택이 있다. 피드백 메커니즘, 마스크 및 위치 인코더는 모두 임의의 실시예에 포함될 수 있다. 주의 매트릭스의 예가 도 10b에 도시된다. 각 행은 입력(사용자 이력의 동작)에 대응하며, 각 열은 잠재적인 출력 동작에 대응한다. 회색조 값은 입력 동작과 출력 동작 간의 상관관계에 대응한다. 예를 들 어, 입력 동작 1은 출력 동작 1(흰색 음영)과 매우 강한 상관관계가 있고, 출력 동작 2 및 3(회색 음영)과 중간 강도의 상관관계가 있고, 출력 동작 N(검은색 음영)과는 매우 약한 상관관계가 있다. 이러한 방식으로 출력 동 작의 세트는 입력 동작의 세트와 이러한 동작이 발생한 순서 모두에 의해 결정된다. 도 11a 내지 11g는 새로운 단일 사용자 사용 사례의 여러 실시예를 설명한다. 도 11a는 활성 컨텐츠 생성에 사용하도록 구성된 확장된 FoV 및 호버링 그래픽을 포함하는 \"지능 확장기\"인 예 시적인 디스플레이 시스템을 묘사한다. 이 실시예에서, 사용자는 예측 특징을 갖는 텍스트의 동적 참조를 경험 한다. 시간 t1에 중앙 디스플레이(9A)는 텍스트를 표시한다. 객체 검출기 기능 분석기는 텍스트에서 키워드 와 문구를 검출하여 방정식과 도면을 식별하고 이를 2D 확장(25A)으 별도의 디스플레이 이미지에 표시한다. 별 도의 디스플레이 이미지는 다층 디스플레이의 일부일 수 있거나, 이는 확장된 시야 이미지일 수 있다. 별도의 디스플레이 컨텐츠는 자동으로 업데이트되어 시간 t2에 상이한 컨텐츠가 기본 디스플레이 이미지(9B)에 표시될 때, 상이한 2차 컨텐츠가 2D 확장(25B)에서 식별된다. 두 경우 모두, 호버링 그래픽은 이전 시점의 컨텐츠 를 표시한다. 예를 들어, 기본 디스플레이는 \"도 1에 도시된 바와 같이\"라는 텍스트를 포함할 수 있으며, 호버 링 그래픽은 그림 \"도 1\"과 관련된 기본 텍스트 부분을 자동으로 표시한다. 별도의 주석 기능은 확장된 윈 도우에 표시된 컨텐츠에 대한 추가 정보에 주석을 달거나 이를 추가할 수 있다. 예를 들어, 이는 도시된 도면 및 방정식으로부터 만들어진 관련된 도면 또는 수학적 추론을 표시할 수 있다. 실시예에서, 기능은 중앙 디스플레이의 일부를 강조하거나 확장된 디스플레이 컨텐츠에 주석을 달아 다양한 컨 텐츠 간의 관계를 강조할 수 있다. 도 11b는 \"논리 추론 확장기\"인 도 11a의 디스플레이의 변형을 묘사한다. 기본 디스플레이 층에는 텍스트와 같은 기본 컨텐츠를 표시한다. 텍스트에는 소프트웨어가 자동으로 논리적 설명으로 검출된 다양한 설명이 있다. FoV 2D 확장인 2차 디스플레이 이미지 또는 일부 실시예에서는 다층 디스플레이는 논리 기능에 의해 생 성된 바와 같이 검출된 설명의 논리적 결과를 보여준다. 예를 들어, 기본 텍스트가 \"Eq 1을 Eq 2로 더한다\"를 언급하면, 두 방정식 1 및 2가 2차 이미지에 표시되며, eq 1을 eq 2로 대체하여 생성된 결과도 표시된다. 2차 디스플레이 패널을 제어하는 논리 기능은 결과를 계산하기 위한 수학적 논리 구조가 미리 프로그래밍 된다. 일부 실시예에서, 논리적 결과는 사용자 지향적이다. 예를 들어, 사용자는 오디오 입력, 다양한 명령 또는 \"방 정식 10이 증명될 수 있습니까?\" 또는 \"방정식 11 및 12가 동시에 참인가요, 즉 상호 일관성이 있나요?\" 또는 \"방정식 9의 좌측 표현의 미분 가능한 특성은 무엇입니까?\"를 포함하는 질문을 사용하여 텍스트를 질의할 수 있다. AI 프로그램은 AI 프로그램에 저장된 다양한 수학 라이브러리를 기반으로 질문에 답할 수 있다. 예를 들 어, AI 프로그램은 방정식 9를 분석하여 왼쪽에서 원하는 표현을 식별하고 연결성, 부드러움, 차별성 또는 다른 기하학적 또는 위상학적 특징을 분석하고 결과를 2차 호버링 그래픽 또는 주석 오버레이로 출력할 수 있다. 도 11c에서, 도시된 실시예는 \"스마트 포맷팅 통합기\"이며, 이는 컨텐츠를 편집하거나 생성하도록 구성된 애플 리케이션 병합기 역할을 한다. 사용자는 일부 실시예에서 텍스트 문서인 컨텐츠를 생성하고 있다. 시간 t1에서, 사용자는 기본 디스플레이(9A)에 일부 텍스트 정보를 생성했으며, 예를 들어 참조용으로 사용된 일부 소스 정보 는 FoV 2D 확장(25A)으로 제2 디스플레이에 표시된다. 일부 실시예에서, 이는 호버링 그래픽 또는 다층 디스플 레이 이미지의 일부이다. 시간 t1에서, 사용자는 병합 기능을 사용하여 2 개의 윈도우로부터 컨텐츠를 병합 하는 동작을 수행한다. 2 개의 컨텐츠의 학습된 이해를 기반으로, 소프트웨어는 자동으로 2차 이미지의 소스 정 보를 형식을 지정하고 기본 디스플레이 이미지에 형식화된 참고 문헌을 생성한다. 일부 실시예에서, 사용자 동 작은 마우스 클릭 및 드래그, 키스트로크(keystroke), 음성 명령 또는 제스처를 포함한다. 일부 실시예에서, 병합은 예측 모델에 의해 제안되며, 사용자는 제안을 확인하거나 거부한다. 일부 실시예에서, 병합은 예측 아바 타의 사용자 권한에 기초하여 자동으로 수행된다. 그 결과 시간 t2에서 메인 디스플레이 이미지(9B)는 통합된 소스 정보로 수정된다. 시간 t2에서 FoV 2D 확장(25B)은 변하지 않을 수 있다. 일부 실시예에서, 소스 자료에 대한 다른 제안은 라이브러리와 어떤 텍스트가 기록되었는지에 대한 분석에 기초 하여 만들어진다. 실시예에서, 제안은 입력 텍스트에 기초한 논제 진술, 가설 또는 뛰어난 질문의 세트일 수 있 다. 도 11d는 사용자 상황에 민감한 \"지능 프로그래밍 추천기\"의 실시예를 묘사한다. 사용자는 일부 실시예에서 컴 퓨터 프로그램인 컨텐츠를 생성하고 있다. 일부 실시예에서 컨텐츠는 멀티미디어 제품 또는 예술 또는 엔터네인 먼트 제품이다. 중앙 디스플레이는 사용자의 주요 작업 공간이며, 디스플레이 시스템은 FoV 2D 확장으로 서 두 개의 가상 측면 이미지를 생성한다. 일부 실시예에서, 측면 이미지는 호버링 그래픽 또는 에지 디스플레 이 이미지이다. 좌측 디스플레이 이미지는 사용자 동작을 표시한다. 우측 이미지는 사용자 이력을 기초로 AI 모 듈에서 수행되는 제안된 동작을 표시한다. 카메라는 선택적으로 제스처 센서로 기능할 수 있다. 일부 실시 예에서, 제안된 디스플레이 컨텐츠는 사용자가 생성하려고 시도하는 것과 동일한 결과를 생성하는 대안적인 방 법이다. 일부 실시예에서, 제안된 컨텐츠는 사용자 생성 컨텐츠의 최적화된 버전이다. 사용자는 카메라를 통한 제스처 인식에 의해 원하는 결과에 대한 정보를 입력한다. 일부 실시예에서, 사용자는 키보드 또는 마우스 또는 음성 명령을 사용한다. 이 소프트웨어 애플리케이션은 프로그래밍, 예술, a/v 또는 멀티미디어 생성, 아키텍처,3d 디자인 및 엔지니어링, 게임 디자인을 포함하는 다양한 방식으로 사용될 수 있다. AI 소프트웨어 메커니즘은 다른 대안을 표시할 수 있다. 예를 들어, 게임 디자인 모듈에서, 사용자는 프롬프트 에 텍스트를 말하거나 입력하여 생성된 게임 캐릭터를 만든다. AI 소프트웨어는 해당 캐릭터를 생성하고 해당 캐릭터에 대한 내러티브, 캐릭터가 내러티브를 충족하는데 필요할 수 있는 다른 특징 또는 특성 및 이와 상호작 용할 수 있는 보조 캐릭터를 제안한다. 도 11e는 사용자가 카메라와 함께 디스플레이 시스템을 사용하는 \"AI 피드백을 갖는 자세 인코더\" 실시예를 예 시한다. 일부 실시예에서 소프트웨어 애플리케이션은 채팅봇, 자연어 처리, 예측 텍스트 또는 생성적 사전 훈련 된 변환기를 사용하는 채팅 프롬프트이다. 사용자는 워크스테이션에 데이터를 입력하고 가상 시스템은 시간 t1에서 중앙 디스플레이 이미지(9A)에 결과 컨텐츠를 표시한다. 카메라는 사용자에 대한 제스처, 마이크로 제스처, 얼굴 표정 및 자세를 캡처하고 결과 디스플레이(9A)는 이러한 물리적 특징을 결과에 통합한다. 일부 실 시예에서 결과는 호버링 그래픽(24A)에 주석 정보로 표시될 수 있다. 동일한 요청 대화가 있어도, 소프트웨어는 자세나 얼굴 표정에 대해 학습된 데이터를 사용하여 t1과 비교하여 t2에서 상이한 결과(호버링 그래픽(2B) 및 메인 디스플레이 이미지 컨텐츠(9B))를 생성한다. 주석은 개인의 신체적 특징이 어떻게 사용되었는지 설명하고 대체 결과를 예측할 수 있다. 원격 회의 소프트웨어의 맥락에서 디스플레이는 나쁜 자세, 방황하는 눈 접촉을 계산적으로 다시 매핑하거나 더 긍정적인 디스플레이 컨텐츠를 위해 다른 불리한 사회적 단서를 강조하는 다른 기능을 가질 수 있다. 도 11f는 호버링 그래픽 목적을 갖는 다층 디스플레이로 구성된 \"글로벌 그래픽 지능 프로파일러\"인 디 스플레이 시스템의 실시예를 묘사한다. 일부 실시예에서, 사용 사례는 의료 이미징을 포함한다. 사용자는 다층 디스플레이에서 상이한 양식으로부터 도출된 객체의 이미지의 세트를 관찰한다. 예를 들어, 의료 이미징을 포함하는 일부 실시예에서, 상이한 층은 CT 스캔, MRI, PET 스캔, X-레이 또는 사진이다. 이들 이미지는 신경망 (모든 양식에 대한 사전 데이터를 가짐)에 입력되어 최종 층을 생성한다. 최종 층은 관심 영역을 표시하거 나 객관적인 질문을 확인하는 주석 층이다. 2차 호버링 이미지 층은 주석 층을 입력으로 취하며 AI 모듈 을 통해 주석에 대한 설명, 진단 또는 예후 또는 주석 층에 구체적으로 명시되지 않은 주석의 다른 특징을 생성한다. 일부 실시예에서, 소스 데이터는 훈련 모듈을 위해 구성되는 AI 생성이다. 일부 실시예에서, 디스플레이 컨텐츠 는 신경 방사 필드를 사용하여 기하학적으로 변환되고, AI 소프트웨어는 대화형 훈련 및 제안된 교육을 위해 상 이한 뷰를 제안한다. 일부 실시예에서, AI 메커니즘은 트레이너 또는 교육자의 역할을 하고 프로그램의 목표에 기초하여 강조되는 이미지 또는 주석을 지시하는 제2 사용자에 의해 제어된다. 일부 실시예에서, \"다층 기하학적 구조 워퍼\"인 도 11g에 도시되는 바와 같이, 상이한 층은 공통 앵커 또는 타 겟 지점을 공유하는 비디오 게임 내의 캐릭터의 포즈 자산의 시퀀스에 대응할 수 있으며, 호버링 그래픽은 공통 앵커에 기초하여 자산의 워프된 버전이다. 이 실시예에서, 기능은 예를 들어 캐릭터의 포즈나 보폭을 워프할 수 있는 기하학적 변환 기능이다. 다층 이미지의 층 중 하나, 즉 후방 층은 캐릭터의 도면이 워핑되어야 하는 타겟 그래픽을 포함할 수 있다. 타겟 그래픽은 특정 랜드마크나 앵커 포인트가 있는 장면 또는 환경일 수 있으 므로 워핑은 앵커 포인트를 기반으로 동적으로 조정된다. 일부 실시예에서, 기능은 장면을 분석하고 캐릭터 의 포즈 자산의 하위 세트를 표시한다. 그 다음 이러한 포즈 자산은 기하학적 변환 기능에 입력되어 호버링 그래픽에서 워프된 포즈를 생성한다. 워핑 및 기하학적 변환은 앵커가 GAN의 \"시드\" 역할을 할 수 있는 GAN(Generative-Adversarial-Network)을 통해 구현될 수 있다. 도 12는 탠덤 컴퓨팅의 소프트웨어 메커니즘의 흐름도를 도시한다. 다중 입력 스트림은 인터넷(6A), 로컬 소스 및 일반 원격 소스를 포함한다. 예로는 클라우드 서버, 로컬 워크스테이션, 데이지 변경 워크스테이션, 분산 네트워크 및 에지 장치를 포함한다. 데이터는 선택적으로 다양한 기능에 의해 작동된 다음 병합 블록 에서 병합된다. 결과로 병합된 데이터는 다른 기능에 의해 작동될 수 있으며 컨텐츠 분석 블록에 서 신경망을 포함할 수 있는 디스플레이 시스템에 의해 분석된다. 제2 컨텐츠 분석 블록은 사용자 동작의 현재 컨텍스트나 사용되는 작업 또는 애플리케이션에서 컨텐츠를 이해한다. 컨텐츠는 조립 블록에서 조립 되며 그 다음 컨텐츠는 디스플레이 시스템에 표시된다. 일부 실시예에서, 예측 동작 또는 제안은 컨텐츠에 포함된다. 사용자 입력, 동작 및 이력은 모니터 블록에서 모니터링되어 분석 유닛을 다시 피드백된다. 피 드백은 분석 블록으로 전달되기 전에 기계 학습 알고리즘에 대해 업데이트된 학습 사전에 상주할 수 있다. 일부 실시예에서, 병합은 입력 스트림의 비선형 기능 또는 다차원 기능이다. 사용자 동작 및 피드백은 동작 수행, 의사 결정 선택에 대한 시간 지연을 포함한다. 제안된 컨텐츠는 소프트웨 어에 부여된 권한에 따라 자동으로 제공될 수 있다. 일부 실시예에서, 제안은 하위 애플리케이션 또는 자동 완 성 양식 또는 온라인 데이터 입력 요청을 호출한다. 일부 실시예에서, 제안은 예를 들어 사용자의 건강 데이터 에 기초하여 휴식을 취하거나, 작업을 전환하거나, 집중을 유지하도록 제안함으로써 사용자의 건강에 영향을 미 친다. 도 13a 내지 13i은 에지 컴퓨팅 장치 및 분산 네트워크를 포함하는 탠덤 컴퓨팅 방법을 사용하는 다양한 실시예 를 묘사한다. 도 13a는 \"탠덤 확장 디스플레이 시스템\"인 일반적인 탠덤 컴퓨팅 환경을 묘사한다. 디스플레이 시스템은 일반 중앙 디스플레이 및 FoV 2D 확장을 포함하는 N 개의 디스플레이 이미지를 생성한다. 일부 실시예에서, 3 개 초과의 패널 또는 3개보다 적은 패널이 있다. 일부 실시예에서, 구성은 다층 디스플레이 패널이다. 도 13a에 서, 디스플레이 컨텐츠의 여러 소스가 있다. 소스 중 하나는 디스플레이 시스템에 연결된 로컬 소스이고 전체 중앙 디스플레이 이미지에 디스플레이 컨텐츠를 생성한다. 다른 소스는 원격 소스이며 측면 윈도우 에 컨텐츠를 생성한다. 우측 윈도우는 전체적으로 원격 소싱되며, 즉 전체 디스플레이 이미지는 원격 소스 로 인한 것이다. 좌측 윈도우에서는 부분(10A)이 원격 소스에 의해 생성되고 원래 로컬 소스는 나머지를 생성한 다. 임의의 실시예에서, 디스플레이 컨텐츠는 기능, 예를 들어 F1, F2, ..., FN을 사용하여 작동될 수 있다. 모든 소스는 직접 또는 다양한 데이지 체인 구성을 통해 서로 통신할 수 있다. 도 13b의 실시예는 원격 작동, 로봇 제어 또는 품질 제어에 사용하도록 구성된 \"AI 감각 네트워크 통합기\"인 예 시적인 탠덤 컴퓨터를 예시한다. 다층 디스플레이의 하나의 디스플레이 영역은 예를 들어, 원격 소스로 부터 제조에 사용되는 비디오 원격 제어 로봇을 보여준다. 제조 현장, 판매자 현장 또는 임의의 다른 위치에서 분산된 원격 센서의 어레이는 로봇의 환경을 강조하는 전방 층의 컨텐츠를 원격으로 생성한다. 일부 실시예 에서, 원격 센서는 작동 온도 또는 범위 제한과 같은 로봇에 대한 정보를 묘사한다. 일부 실시예에서, 원격 센 서는 품질 제어 감지, 무작위 변화, 응력 및 변형 또는 제품 또는 로봇의 열적 또는 기계적 안정성과 같은 로봇 이 조작하는 제품에 대한 정보를 묘사한다. 이중 층 다층 디스플레이 이미지는 둘 다 기하학적 변환 기능에 입력되며, 이는 비디오에 감각 데이터를 오버레이하는데 사용된다. 예를 들어, 감각 데이터는 온도 센서의 세트 일 수 있으며, 기하학적 변환 기능은 역전파 알고리즘을 사용하여 장치의 온도 프로필을 매핑한다. 제2 기능은 감각 데이터 및 비디오를 입력으로 취하고 호버링 그래픽에서 주석을 출력하는 AI 모듈이다. 주석은 로 봇에 대한 설명 컨텐츠를 제공하거나, 이는 부품 고장을 예측하거나, 이는 작동에 대해 수정을 제안하거나, 이 는 지원을 위해 공급업체에 문의할 것을 제안한다. 예를 들어, 비디오에 계층화된 온도 프로필을 기반으로 AI 모듈은 로봇 부품이 과열되고 있거나 개입이 이루어지지 않으면 가까운 미래에 과열될 수 있음을 나타내는 컨텐 츠를 생성할 수 있다. 도 13c는 가상 현실 환경에서 원격 회의를 위한 \"다층 스마트 원격 회의\"인 탠덤 컴퓨팅 실시예를 묘사한다. 다 층 디스플레이는 공유된 가상 현실 환경에서 주어진 사용자를 각 층에 표시한다. 층 중 하나는 사람의 원격 소스 이미지이다. 기하학적 변환 기능은 장면 속 객체 및 사람에 작용하여 사용자의 다양한 깊이 및 위 치에 할당된다. 예를 들어, 객체 검출 하위 루틴은 카메라에 대한 사람의 위치에 따라 달라지는 한 층에서 사람 의 크기를 검출한 다음 두 사람의 크기가 유사하도록 두 번째 사람의 이미지를 확대하거나 축소한다. 일부 실시예에서, 2차 호버링 그래픽 층은 각 사용자의 얼굴 표정, 시선, 톤 또는 머리 위치에 기초하여 각 사용자에게 주석 및 피드백을 제공하므로, 사용자는 제안된 피드백에 기초하여 그의 동작을 수정할 수 있다. 일 부 실시예에서, AI 모듈은 대화에 영향을 미치기 위해 대화 및 대화 내의 다수의 사용자를 평가한다. 예를 들어, 얼굴표정 분석기 기능은 협업 사용자의 기분을 평가하고 대화의 톤이 진지해야하는지, 형식적이어야 하는 지, 비공식적이어야 하는지, 또는 가벼운 마음이어야 하는지를 나타낼 수 있다. 실시예는 함께 결합될 수 있다. 예를 들어, \"다층 스마트 원격 회의\"는 그 동작의 일부로서 \"AI 피드백을 갖는 자세 인코더\"인 도 11e를 포함할 수 있다. 도 13d의 실시예는 비행 시뮬레이터, 게이밍 경험, 훈련 경험 또는 날씨/기후 모니터로 사용하기 위해 구성된 다층 탠덤 컴퓨팅을 갖는 확장된 가상 FoV 디스플레이의 사용 사례를 예시한다. 이 \"다초점 지능 시뮬레이터\"에 서 다층 디스플레이의 여러 층은 원격으로 공급되는 이미지이다. 이들은 비행 시뮬레이터의 이미지일 수 있다. 입력 스트림은 다층 최적화기를 통과하여 디스플레이 컨텐츠를 최적화하여 깊이 인식을 최대화한다. AI 모듈은 시뮬레이션 이미지를 취하고 사용자 연수생이 볼 수 있도록 전방 층에 주석을 제공한다. 주 석은 다음 동작, 시뮬레이션된 환경의 위험, 경고, 예측된 대안, 예측된 모션 또는 환경의 미래 역학에 대한 제안할 수 있다. 주석 층은 계측 클러스터 및 게이지의 이미지 또한 포함할 수 있다. 일부 실시예에서, 중앙 시청 영역은 시뮬레이션을 보여줄 수 있고, 확장된 디스플레이는 중앙 컨텐츠에 기반하여 사용자가 내릴 수 있는 선 택의 AI 생성 예측 결과를 보여줄 수 있다. 일부 실시예에서, 환경은 예를 들어 기존 비행기에 위치된 카메라에 의해 생성된 실시간 이미지이며, 이는 비행 시뮬레이션 또는 관찰에 사용된다. 또는 이는 원격 작동 환경에서 사용자가 제어하는 원격 제어 차량의 실시간 이미지일 수 있다. 일부 실시예에서, 주석 층은 레이턴시를 포함하는 지연에 기초하여 미래 시간에서 예측된 장 면 또는 예측된 모션을 보여준다. 일부 실시예에서, 도 13d의 확장된 디스플레이는 박물관과 같은 환경의 가상 투어로 사용하도록 구성되며, 주석 층은 환경의 항목에 대한 주석을 제공한다. 일부 실시예에서, 디스플레이 시스템과 통신하는 센서 어레이는 시각적 환경의 별개의 부분에 영향을 주거나 보 여주기 위한 사용자에 대한 SLAM 정보를 수집한다. 예를 들어, 원격 작업 센터에서, SLAM 정보는 정확한 각도의 시점을 위한 가상 컨텐츠의 시점을 기하학적으로 변경하는 기능에 입력되며, 이는 센서, 카메라, 통신 채널에서 발생하는 왜곡이 없는 실제 시점이다. 또는 예를 들어 사용자가 어디를 보고 있는지 검출하고 디스플레이 컨텐 츠의 해당 부분을 수정하거나 해당 영역을 확대하기 위해 머리 추적 및 시선이 사용될 수 있다. 일부 실시예에 서, AI 모듈은 명령을 주석으로 제공할 수 있는 트레이너 또는 교육자에 의해 대체되거나 영향을 받는다. 교육 자는 사용자 주변에서 볼 수 있어 시각적 환경이 몰입적일 수 있으며, 교육자 및 사용자는 동일한 장소에 있는 듯한 느낌을 가질 수 있다. 이 실시예에서, 이러한 몰입은 사용자가 더 현실감 있는 시각적 환경을 경험할 수 있게 한다. 일부 실시예에서, 머리 추적 또는 시선은 시점의 이동을 모방하기 위해 시뮬레이션 환경을 수정하는 기하학적 변환 기능에 입력될 수 있다. 도 13e는 탠덤 디스플레이 시스템이 구성되는 \"텐덤 지능 컨텐츠 생성기\"인 실시예를 묘사한다. 다층 디스플레 이는 로컬 소스에 의해 생성되고 예를 들어 과학 데이터 또는 그래픽을 묘사하는 메인 디스플레이 이미지 를 갖는다. 디스플레이 시스템을 갖는 로컬 소스가 낮은 대역폭 소스인 경우, 그래픽 또는 데이터는 해상 도가 낮거나 FoV, 시간 해상도, 특징 묘사 또는 공간 해상도와 같은 일부 다른 방식으로 제한된다. 사용자는 디 스플레이 이미지 상에서 커서 위치를 이동시키기 위한 커서 입력을 포함하는 입력을 제공한다. 커서의 위 치가 검출되고 디스플레이 컨텐츠의 인근 부분이 원격 소스로 전송되어 인근 환경에 대한 추가 정보를 전달 한다. 원격 소스는 원격 소스 이미지에서 원하는 주석을 생성하기 위해 주석 기능을 사용할 수 있다. 일부 실시예에서, 커서는 사용되지 않고 그 대신 관심 있는 컨텐츠는 눈 추적 입력 장치에 의해 생성되는 시선 위치에 의해 결정된다. 그 추가 정보는 다층 디스플레이의 2차 디스플레이 이미지에 표시된다. 이는 FoV 2D 확장 디스플레이 또는 호버링 그래픽일 수 있다. 추가 정보는 고해상도일 수 있거나 환경에 대한 향상된 이미지 일 수 있다. 일부 실시예에서, 추가 정보는 설명 텍스트, 추가 도면 또는 도식, 유사한 객체의 이미지(예를 들 어 이미지 웹 검색에서 사용되는 것과 같음)이다. 일부 실시예에서, 추가 정보는 에지 디스플레이 이미지에서 나타나는 그래프 또는 간단한 텍스트이다. 일부 실시예에서, 그래픽 기능은 고전력 계산 소스로부터 렌더링되는 동적 이미지 향상 또는 업스케일을 생 성한다. 일부 실시예에서, 상이한 기능 블록은 사용자가 수정, 주석, 설명 또는 제안의 상이한 분류를 선택하게 한다. 주석 기능 및 그래픽 기능은 사용자 프로필 또는 이력에 의해 파라미터화될 수 있다. 도 13f의 실시예는 \"시간 지연 AI 예측/차별화\"인 탠덤 컴퓨터의 사용을 묘사하며, 다층 디스플레이는 객체 의 이미지의 시간 경과 시퀀스 또는 비디오의 다중 프레임을 생성한다. 실시예에서, 이는 제1 원격 소스 이미지 (10A) 및 제2 원격 소스 이미지(10B)를 생성하며, 여기서 제2 이미지는 제1 이미지의 시간 지연된 버전이다. 시 간 지연사용자 설정에 의해 제어될 수 있거나, 이는 객체 모션의 비디오의 레이턴시를 포함할 수 있다. 지 연은 조정되어 상이한 시각 스케일을 관찰할 수 있다. 예를 들어, 이는 사용자가 매우 빠른 변화를 고려할 수 있도록 가능한 한 작게 조정될 수 있거나 이는 느린 변화를 고려하기 위해 더 크게 조정될 수 있다. 일부 실시예에서, 이 애플리케이션은 날씨 예측에 사용되며, 관심 객체는 폭풍 또는 다른 국지적인 날씨 효과이 다. 그 다음 두 층 모두 객체의 예측된 진화를 제3 층으로 출력하는 AI 모듈에 입력된다. 시간 지연이 포함 될 수 있으며, 예측된 이미지는 상이한 확률이 강조된 여러 가능한 궤적, 예를 들어 135A 및 135B를 표시하거나, 이는 기후 이력에서 장기 추세에 대한 지역 날씨 패턴과 같이 상이한 시간 스케일에 기초하여 다양 한 결과를 표시할 수 있다. 일부 실시예에서, 2 개의 이미지는 거의 동일하고 예측된 이미지는 2 개의 이미지 또는 2 개의 비디오 프레임 사이의 차이에 대한 정보를 제공한다. 이러한 방식으로, 본 실시예는 시각적 컨텐츠를 시간에 따라 차별화한다. 일부 실시예에서, 상이한 이미지는 상이한 입력 스트림으로부터 나오고 시간차이는 상이한 시간 스케일에서 컨 텐츠를 대조하기 위해 조정 가능하다. AI 모듈은 연구 중인 객체의 움직임을 설명하는 임의의 물리적 법칙을 통 합할 수 있다. 도 13g에서, 탠덤 컴퓨터는 \"실시간 프로그래밍 가능 업데이트 예측기\"에서 자동으로 금융 거래 프로그램을 구 축하는데 사용하도록 구성된다. 사용자는 고주파 거래 작업을 위한 컴퓨터 코드를 보여주는 중앙 디스플레이 를 본다. 다수의 가상 에지가 중앙 이미지 주위에 표시되며 모두 원격 소스에 의해 생성된다. 에지 이미지는 주식 시장 가치(S1)와 다양한 시간의 추세를 포함하며, 로컬 워크스테이션은 자동으로 실시간으로 코 드를 컴파일한다. 코드 및 원격 소스 데이터는 기능에 입력되어 에지 디스플레이(S2)의 실제 값과 함께 표 시할 주가의 예측된 변화를 생성한다. 일부 실시예에서, 레이턴시는 시간 지연에 통합되어 시장 조건이 어 떻게 변화하고 어떤 알고리즘이 향후 개정에서 유리할 수 있는지에 대한 예측 제안을 하는 기능을 지원한다. 기 능은 AI 모듈일 수 있거나, 이는 정통 계량경제학의 통계 모델일 수 있다. 일부 실시예에서, 예측 조치는 시장 현장에서 물리적으로 더 멀리 위치한 고주파 거래에 대한 레이턴시를 완화하는데 사용될 수 있다. 기능은 동적 시간 워핑 알고리즘에 의존하여 시계열 데이터를 비교하고 이들 간의 일치를 최적화할 수 있다. 도 13h 및 13i는 사용자가 다층 디스플레이를 보고 있는 실시예를 묘사한다. 도 13h에서, 사용자는 다층 디 스플레이를 본다. 각 층에는 상이한 컨텐츠가 표시된다. 각 층은 사용자의 눈이 개별적으로 적응할 수 있는 다양한 초점 심도에 대응한다. 센서는 시선이나 기하학적 구조와 같은 사용자에 대한 정보를 검출할 수 있 다. 센서는 뷰어의 특정 제스처를 식별하는 제스처 카메라일 수 있다. 센서는 환경에 대한 정보를 검출할 수 있 다. 센서로부터의 데이터 및 각 층에 대한 컨텐츠는 AI 모듈의 세트(18A 및 18B)에 입력되며, 이는 예를 들어 상이한 사전, 훈련 메커니즘 또는 아키텍처를 사용하여 상이하기 구성될 수 있다. AI 모듈의 출력은 디스플레이 컨텐츠에 영향을 미친다. 예를 들어, 사용자 시선은 디스플레이 중앙에 있을 수 있으며, 각 층의 컨텐츠는 방사 상 내측 또는 외측으로 이동하여 컨텐츠가 표시되는 위치를 변경할 수 있다. 이러한 방식으로 AI 모듈의 세트는 뷰어와 상이한 초점 평면 간의 피드백 또는 통신 네트워크를 생성한다. 도 13i는 다층 디스플레이의 4 개의 층과 3 개의 상이한 AI 모듈(18A, 18B 및 18C)을 갖는 유사한 설정을 보여준다. 사용자는 두 눈 렌즈가 그 깊이를 수용하도록 후방 층의 지점에 초점을 맞춘다. 사용자가 다른 층의 컨텐츠를 본 경우, 렌즈의 조절 이 변경된다. 두 경우 모두 층은 로컬로 소싱되거나 원격으로 소싱될 수 있다. 도 14a 내지 14e는 새로운 다중 사용자 및 협업 사용 사례의 상이한 실시예를 보여준다. 협업 사용 사례는 애플 리케이션의 컨텐츠 편집/생성/주석; 컨텐츠/데이터 남색; 제어실 애플리케이션; 계산/시뮬레이션, 렌더링, 매핑 과 같은 처리 수행; 및 추세/패턴 분석 또는 다차원 데이터 시각화;를 포함하지만 이에 제한되지는 않는다. 도 14a는 두 사용자가 화상 회의에 참여하는 \"컨텐츠 인식 컨텐츠 공유기\"인 실시예를 묘사한다. 중앙 디스 플레이 이미지에 표시된 하나의 사람은 정보를 전송하고 컨텐츠를 설명하고 수신 협업 사용자에게 컨텐츠 를 푸시한다. 이 실시예에서, 송신 사용자는 수신 사용자의 디스플레이 시스템의 일부 측면을 제어한다. 예를 들어, 송신 사용자는 컨텐츠의 최적 표시 또는 상호작용을 위해 시각적 템플릿을 선택할 수 있다. 송신 사용자 는 수신 사용자를 위해 컨텐츠를 다층 디스플레이에 푸시하기로 결정할 수 있으며, 여기서 다층 디스플레이 는 사용자에 의해 생성된 주석이 있는 특정 레슨에 대한 이미지의 세트이다. 송신 사용자는 제스처, 키보드 또 는 마우스 입력 또는 음성 활성화를 포함하는 다양한 수단을 통해 컨텐츠 및 디스플레이 시스템 구성을 지시한 다. 협업 사용자는 카메라를 포함하는 일반 입력 장치를 사용하여 디스플레이 컨텐츠와 상호작용할 수 있다. 일부 실시예에서, 센서 또는 센서 어레이는 사용자로부터 입력을 수신하는데 사용된다. 설명자와 수신 자의 역할을 누가 호스트이고 누가 게스트인지 결정하는 소프트웨어 구성에 따라 동적으로 전환될 수 있다. 도 14b는 두 명의 협업 사용자가 항공 교통 관제와 같은 복잡한 작업을 포함하는 시나리오에서 협력하고 있 는 \"협업 작업 매니저\"인 실시예를 묘사한다. 각 사용자는 시나리오의 다양한 측면(예를 들어, 항공 교통 관 제)을 보여주는 자신의 디스플레이 시스템 및 컨텐츠를 갖는다. 이 실시예에서, 디스플레이 시스템은 모두 다층 이미지의 세트를 표시한다. 각 사용자에 의해 처리된 정보는 그들 사이에서 앞뒤로 전달될 수 있으며 임의 의 입력 장치 또는 센서를 사용하여 다른 사용자의 상이한 스트림으로 푸시될 수 있다. 예를 들어, 항공 교통 관제에서, 하나의 사용자는 비행기의 경로를 모니터링하고, 다른 사용자는 상이한 최적화된 경로를 계산하 거나 예상 궤적과 상호작용한다. 제1 사용자가 모니터링하는 고도, 속도 및 방향과 같은 교통 정보는 제2 사용자에 의해 숫자로 푸시될 수 있으며, 이는 코드 기능을 사용하여 최적화된 경로를 생성하고 그래픽 모 드에 대체 경로로 제1 사용자에게 전달될 수 있다. 여기서 소프트웨어가 사용하는 기능은 한 사용자의 정보를 제2 사용자가 사용할 수 있는 형식으로 병합하는 병합 기능이다. 교통을 모니터링하는 사용자에 대한 정보표시는 본질적으로 더 그래픽적일 수 있는 반면 계산을 실행하는 사용자에 대한 정보 표시는 본질적으로 더 숫 자적이고 표로 표시될 수 있다. 각 사용자에 대한 스트림은 처리되는 정보의 성격에 맞게 조정될 수 있다. 소프 트웨어는 전송되는 정보에 따라 가상 디스플레이 컨텐츠 또는 탬플릿을 자동으로 조정할 수 있다. 도 14c는 온라인 교육 시나리오를 포함하는 \"다중 사용자 동적 컨텐츠 번역기\"인 실시예를 설명한다. 교사는 청 중(예를 들어, 협업 사용자인 학생)에게 컨텐츠를 푸시하고, 이는 컨텐츠의 맞춤형 버전을 수신한다. 이는 각 학생이 그의 학습 선호도와 디스플레이 설정에 따라 컨텐츠를 다르게 수신할 수 있는 것을 제외하고 도 14a 의 적용과 같다. 예를 들어, 제1 학생은 다양한 보정, 테스트 또는 해당 학생과의 인터뷰를 통해 발견된 시각적 학습자일 수 있으므로 각각의 디스플레이 시스템에서 생성되는 컨텐츠는 더 그래픽적이다. 제2 학생은 각각의 디스플레이가 수학 방정식을 사용하여 텍스트 기반이 되도록 정량적 추론을 더 잘할 수 있다. 소프트웨어 기능 은 예를 들어 기계 학습 알고리즘을 통해 원본 컨텐츠를 복수의 디스플레이 컨텐츠로 변환한다. 예를 들어, 교 육자는 물리적 원리에 대한 정보를 낭독할 수 있다. 음성-텍스트 프로그램은 진술을 기록하고, AI 생성기는 텍 스트와 텍스트를 입력으로 사용하는 웹 검색을 기반으로 시각적 컨텐츠를 생성한다. 정보는 모두 학생의 워크스 테이션으로 전송되며, 로컬 분석기는 학생 이력 및 입력을 기반으로 음성, 텍스트, 이미지 또는 임의의 조합 중 어떤 방식이 최적인지 결정한다. 각 사용자는 이러한 번역 기능을 통합한 고유의 화이트보드 기능(70A, 70B, 70C)을 통해 교사에 의해 공유되는 컨텐츠를 수신한다. 일부 실시예에서, 동적 번역은 데이터 또는 메타데이터를 사용하고 AI 모듈은 학생을 위한 질문 작성을 돕기 위 해 주석 층을 제공한다. 주석 층은 교육자 또는 학생에게 표시될 수 있다. 도 14d는 상이한 위치에 있는 두 사용자 간의 영화 제작 또는 엔터테인먼트 미디어 생성과 같은 협업 시나리오 의 실시예를 설명한다. \"생성 컨텐츠 다중 사용자 혼합기\"인 이 실시예에서, 두 사용자는 각각의 디스플레이 시스템에 표시된 진행 중인 공통 작업을 포함하는 다층 디스플레이를 공유한다. 각 사용자는 앞뒤로 수행할 작업의 다양한 측면에 대해 논의하면서 다른 사용자에게 푸시될 수 있는 FoV 2D 확장 또는 다층 디스플레이 를 갖는다. 예를 들어, 제1 사용자는 프레임 및 사운드트랙을 편집하는 작업을 할 수 있는 반면, 제2 사용자는 제1 사용자가 편집하는 클립 및 사운드트랙에 인공 효과를 개선하고 추가하는 작업을 할 수 있다. 각 사용자는 자신의 주변 디스플레이를 사용하여 최종 제품을 편집하고 개선하기 위한 다양한 제안을 다 른 사용자에게 보여줄 수 있다. 일부 실시예에서, 이 구성은 웹 회의, 멀티플레이어 게임 또는 협업 원격 작업 에 사용된다. 일부 실시예에서, 주석 층은 AI 생성될 수 있다. 한 사용자에 대한 주석 층은 다른 사용자의 세부 정보를 입력 으로 사용할 수 있으며, 이는 하이퍼링크, 광고 또는 채팅 인터페이스와 같은 다양한 앱 제안을 출력하여 협업 작업을 완료하는데 도움을 줄 수 있다. 도 14e는 반드시 동일한 위치에 있을 필요는 없는 두 사용자가 예를 들어 텍스트 및 그래픽을 갖는 연구 논 문을 작성할 때 다차원 컨텐츠를 생성하는 협업 시나리오의 \"협업 컨텐츠 병합\"인 실시예를 설명한다. 제1 사용 자는 디스플레이 이미지에서 의료 이미징을 분석 및 보고하는데 집중할 수 있는 반면, 제2 사용자는 제2 디 스플레이에서 일부 약물의 효과를 분석하고 보고하는데 집중할 수 있다. 두 보고서의 결과는 원격 소스로 전송되고, 그 후 협업 결과를 병합하고 실시간 업데이트하며, 이는 예를 들어 원격 소스 이미지의 층으로 디스플레이 시스템에 의해 표시된다. 이미지는 함께 다양한 오버레이 주석을 포함할 수 있는 다층 디스플레 이를 형성할 수 있다. 두 사용자 모두 작업이 진행됨에 따라 동일한 공통 프로젝트를 본다. 일부 실시예에서, 두 사용자는 동일한 물리적 위치에 있으며, 최종 결과는 두 사용자가 공통 디스플레이에서 동시에 볼 수 있도록 한번 표시된다. 일부 실시예에서, 다양한 주석은 다른 사용자가 볼 수 있도록 각 사용자에 의해 임의의 층에서 이루어질 수 있다. 이 실시예에서, 사용자는 상이한 소프트웨어 애플리케이션을 사용할 수 있다. 예를 들어, 둘 다 텍스트에 기여하는 경우, 한 사용자는 WYSIWYG(what-you-see-is-what-you-get) 소프트웨어를 사용하는 반면, 다른 사용자는 일반 텍스트 소프트웨어를 사용한다. 개별 컨텐츠가 생성되면 이는 로컬에서 공통 형식으 로 변환된다. 두 정보 세트 모두 원격 소스에 업로드되어 이를 함께 분석하고 통합하거나 병합된다. 원격 소 스는 그 다음 병합된 문서를 보기 위해 사용자의 디스플레이 시스템으로 다시 보낼 수 있다. 도 15a 및 15b는 상이한 텍스트 및 그래픽 편집 방식을 동시에 설명하는 상이한 흐름도를 보여준다. 도 15a는 두 사용자가 동일한 문서에 대해 작업하는 탠덤 텍스트 편집 시나리오의 흐름도를 묘사한다. 각 사용 자는 상이한 텍스트 편집 도구를 사용하여 작업한다. 예를 들어, 하나의 사용자는 TeX와 같은 일반 텍스트 편집 기(135A)로 작업할 수 있고, 다른 사용자는 Microsoft Word와 같은 WYSIWYG 편집기(135B)로 작업할 수 있다. 로컬 처리 유닛은 입력 데이터를 공통 포맷으로 변환하기 위한 변환 블록(136A) 및 변환 블록(136B)을 포함한다. 공통 포맷은 ASCII 유형 데이터일 수 있다. 정보는 분석 블록에서 데이터를 분석하는 원격 소스 로 전송된다. 이 블록은 또한 신경망에서 사용하도록 구성된 사전을 취한다. 데이터는 그 다음 병합 블 록에서 결합되고 컴파일 블록에서 컴파일된다. 그 다음 원격 소스는 결과를 디스플레이용 디스플 레이 시스템으로 보낸다. 컴파일된 데이터는 분석 사전을 업데이트하기 위해 사전 데이터로 변환 블록에 공 급된다. 도 15b는 3D 이미지가 원격 소스에 의해 생성되는 흐름도를 묘사한다. 일부 실시예에서, 원본 데이터는 2D 이미지 또는 2D 이미지의 세트이다. 원격 소프트웨어는 다수의 카메라로부터의 스테레오 정보, 비행 시간 정보, 음영 또는 형상으로부터의 깊이, 투영 기하학적 구조 또는 단안 깊이 추정과 같은 다양한 단서에 기초하 여 이미지의 깊이를 추정하는 추정 블록을 가지며, 3D 이미지로 이들을 병합한다. 원격 소스는 그 다음 정보를 임계값 블록을 갖고 다층 디스플레이의 층에 대응하는 깊이 평면의 개별 세트로 깊이 정 보를 임계화하거나 비닝하는 로컬 소스에 정보를 전송한다. 임계화 최적화는 인간 시각화 시스템(HVS)에 대한 정보를 갖는 HVS 사전뿐만 아니라 사용자 또는 SLAM 정보로부터의 입력을 포함하는 신경망을 사용할 수 있다. HVS 사전은 시력이나 깊이 인식에 대한 정보를 포함할 수 있다. 깊이 인식 정보는 인간 호롭터 및 파 눔의 융합 영역(Panum's Fusion Area)에 대한 데이터; 연령에 따라 다양한 인구 집단에 대한 융합 또는 조절 측 정 기준; 또는 뇌, 눈 및 연결 신경계에 대하 정보를 포함할 수 있다. 일부 실시예에서, 깊이 인식 정보는 다른 정보에 대해 높게 가중치가 부여되어, 알고리즘은 뷰어에 대한 이미지 컨텐츠의 깊이 인식을 최적화한다. 예를 들어, 이미지 초점 평면은 파눔의 융합 영역과 관련된 형상으로 매핑될 수 있다. 도 16a 내지 16c는 디스플레이 컨텐츠를 생성하기 위해 원격 및 로컬 소스 모두가 사용되는 파이프라인의 세트 를 묘사한다. 일부 실시예에서, 파이프라인은 애플리케이션 독립적이며 로컬 워크스테이션에 의해 설정된다. 도 16a에서, 로컬 컴퓨터는 픽셀을 두 세트 sj' 및 sj로 나눈다. 픽셀 sj는 일부 작업 Rij에 의해 렌더링되 도록 원격 소스로 전송된다. 픽셀 sj'는 Lij 작업에 의해 렌더링되도록 로컬 소스로 전송된다. 결과 픽셀 은 합으로 함께 추가되어 픽셀 pi = Lij sj + Rij sj'를 생성한다. 그 다음 이들 픽셀은 디스플레이로서 표시된다. 일부 실시예에서, 부분적으로 현재 디스플레이 컨텐츠에 기초한 사용자 입력은 원격 및 로컬로 전송된 픽셀 세트를 변경하기 위해 로컬 컴퓨터로 피드백된다. 일부 실시예에서, 세트 sj 및 sj'는 서로소 (disjoint)이다. 일부 실시예에서, 이들은 중첩되어 교차점은 가중 중첩으로서 원격 및 로컬 소스 모두로부터 기여를 수신하는 픽셀의 세트를 나타낸다. 도 16b는 컨텐츠가 대역폭에 의해 분할되는 유사한 파이프라인을 예시한다. 컨텐츠 컨트롤러 유닛은 원하 는 디스플레이 컨텐츠를 분석한다. 정보는 컨텐츠를 적절한 기반으로 분해하는 기반 최적화 유닛으로 전송 된다. 예를 들어, 기초는 표준 푸리에 기초일 수 있거나, 이는 희소 기초(sparse basis) 또는 웨이블릿 기초 (wavelet basis) 또는 컨텐츠 적응형 기초일 수 있다. 대부분의 에너지가 있는 기본 모드(여기서는 고대역폭 컨 텐츠라고 함)는 원격 소스로 전송된 다음 컨텐츠를 페치(fetch)되거나 렌더링한다. 그 다음 낮은 대역폭 컨 텐츠는 로컬 소스에 의해 페치되거나 렌더링된다. 그 다음 2 개의 컨텐츠의 세트는 합으로서 함께 추가 되고, 합은 디스플레이로 전송된다. 일부 실시예에서, 사용자 입력은 컨텐츠 유형을 조정할 수 있다. 예를 들어, 사용자는 이미지를 처리하거나 특정 기능을 사용하기를 원할 수 있다. 사용자는 특정 이미지 기반에 대응하는 양식을 선택할 수 있다. 기본은 표준 푸리에 기초, 점 희소 기초, 에지 기초 또는 고 레벨 객체 검출 을 위한 고 레벨 기초일 수 있다. 이미지 I는 기본 모드 Bm과 가중치 wm의 중첩으로 표현될 수 있다:"}
{"patent_id": "10-2023-0137211", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "다음으로, wm'을 임계값으로 설정하고 wm'이 임계값보다 높은 m'의 범위를 찾는다. 이 범위는 디스플레이 컨텐츠 의 고 대역폭 부분에 대응한다. 해당 범위를 고 대역폭 프로세서로 보내 픽셀 값을 처리하고 생성한다. 나머지 는 저 대역폭 프로세서와 결합하며, 결과를 추가하고 디스플레이 시스템으로 보낸다. 일부 실시예에서, 컨텐츠는 특징 유형에 기초하여 분리된다. 예를 들어, 날카로운 에지를 포함하는 디스플레이 컨텐츠는 원격 소스에 의해 생성되며, 광범위한 특징을 포함하는 디스플레이 컨텐츠는 로컬 소스에 의해 생성된 다. 또는, 일부 실시예에서, 인간 대상에 대한 정보는 원격 소스에 의해 생성되며, 풍경에 대한 정보는 원격 소 스에 의해 생성된다. 선택된 기반은 특정 소프트웨어 애플리케이션에 따라 달라질 수 있거나, 이는 동적으로 생 성될 수 있다. 이러한 방식으로, 분리는 포비티드 렌더링의 형태이다.도 16c에서, 다층 그래픽 디스플레이의 컨텐츠는 로컬 컴퓨터에 의해 분석된다. 층 정보 중 일부는 디스플 레이 생성을 위해 로컬 소스로 전송된다. 결과는 원격 소스로 전송된다. 로컬 및 원격 디스플레이 컨텐츠 생성의 결과는 합으로 함께 추가되고 디스플레이로 표시된다. 사용자 입력은 원하는 컨텐츠의 로 컬 컴퓨터 분석을 변경하게 한다. 일부 실시예에서, 원격 소스의 레이턴시에 대한 정보는 원격 디스플레이 컨텐 츠에 영향을 주기 위해 예측 모델링 능력을 갖는 시간 지연 블록으로 결합된다. 도 17a 내지 17d는 시간과 공간에 걸쳐 있는 다양한 이벤트의 인포그래픽 디스플레이와 관련된 일부 보조 실시 예를 묘사한다. 도 17a는 중앙 디스플레이가 현재 시간과 관련된 정보 및 이벤트를 표시하는 반면, 중앙 디스플레이 아래의 디스플레이는 현재에 이르는 과거 이벤트를 순서대로 표시하기 위해 막대로서 과거 컨텐츠 그래픽을 표시 하는 \"시간 범위\" 실시예를 묘사한다. 한편, 중앙 화면의 상부의 화면은 먼 미래 래픽과 비교 가능한 이벤 트/옵션보다 가까운 미래에 가능성이 더 높은 이벤트/옵션이 강조되는 방식으로 미래 가능한 옵션 및 이벤트의 스택을 표시하는 미래 컨텐츠 그래픽을 표시한다. 일부 실시예에서, 막대의 폭은 활동 가능성을 나타내고 위치는 다른 요인(생산성 또는 하루 중 시간과 같은)에 기초한 권장 사항을 나타낸다. 거품은 먼 미래에 대한 불확실성을 나타낸다. 도 17b는 과거에 묘사된 이벤트(156A, 156B, 156C 및 156D)가 가까운 미래에 가능한 이벤트의 크기가 사용자가 이러한 이벤트를 활성화할 가능성과 관련된 방식으로 표시되는 \"공간 범위\" 실시예를 묘사한다. 일부 실시예에 서, 상이한 부분의 음영 또는 색상은 미래 권장되는 동작을 나타낸다. 도 17c는 관심 이벤트(157A)가 중앙 화면 아래의 화면에 표시되는 이전 이벤트(157C)에 연결되고 관심 이벤트에 서 도출된 가능한 이벤트(157B)가 중앙 화면 위의 화면에 표시되는 \"트리 스팬(tree-span)\" 실시예를 묘사한다. 그래프의 노드는 다양한 과거, 현재 또는 미래 동작에 대응한다. 연결은 동작 간의 상관관계에 의해 결정된다. 일부 실시예에서, 각 구성요소가 그래프이며, 한 구성요소의 노드가 임의의 다른 구성요소의 노드에 연결되지 않도록 하는 다수의 구성요소가 있다. 도 17d는 예를 들어 이메일에서 제안된 단어의 톤이 사용자의 현재 입력의 기능으로 동적으로 변경되는 인포그 래픽의 실시예를 묘사한다. 톤은 긍정적, 부정적 또는 중성 톤으로 다양할 수 있다. 본 디스플레이는 사용자 가 이메일을 작성하기 위한 이메일 환경의 이미지를 보여줄 수 있다. 처음에는 사용자에게 톤에 따라 수직으로 구성된 초기 제안 단어가 표시된다. 제1 분포(158A)는 중성 톤의 중심에 위치한다. 사용자가 단어 선택을 진행함에 따라, 그는 약간 부정적인 톤을 선택하므로 다음 분포(158B)는 선택한 톤에 기초하여 단어의 상이한 세트를 표시한다. 제3 분포(158C)는 사용자가 부정에서 긍정으로 톤을 변경하는 것을 따른다.도면 도면1 도면2a 도면2b 도면2c 도면2d 도면3a 도면3b 도면4a 도면4b 도면5a 도면5b 도면5c 도면5d 도면5e 도면5f 도면5g 도면5h 도면5i 도면5j 도면6a 도면6b 도면6c 도면6d 도면6e 도면6f 도면6g 도면6h 도면6i 도면6j 도면7a 도면7b 도면7c 도면7d 도면7e 도면7f 도면7g 도면8a 도면8b 도면8c 도면8d 도면8e 도면8f 도면8g 도면9a 도면9b 도면10a 도면10b 도면11a 도면11b 도면11c 도면11d 도면11e 도면11f 도면11g 도면12 도면13a 도면13b 도면13c 도면13d 도면13e 도면13f 도면13g 도면13h 도면13i 도면14a 도면14b 도면14c 도면14d 도면14e 도면15a 도면15b 도면16a 도면16b 도면16c 도면17a 도면17b 도면17c 도면17d"}
{"patent_id": "10-2023-0137211", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 예시적인 실시예의 공통적인 특징인 요소의 세트를 도시한다. 도 2a 내지 2d는 원격 컴퓨팅 소스가 있거나 없는 확장된, 가상 또는 다층 디스플레이 시스템을 사용하는 소프 트웨어 애플리케이션의 세트를 설명한다. 도 3a 및 3b는 가상 또는 다층 디스플레이를 위한 소프트웨어 생성 메커니즘의 흐름도를 도시한다. 도 4a 및 4b는 확장된, 가상 또는 다층 디스플레이 시스템에 대한 소프트웨어 생성 메커니즘의 상세한 드롭다운 메뉴를 도시한다. 도 5a 내지 5j는 다양한 소프트웨어 경험을 생성하기 위해 소프트웨어 생성 메커니즘에서 사용될 수 있는 예시 적인 기능 블록의 세트를 도시한다. 이러한 블록은 사용자가 선택하거나 특정 시간에 시스템의 프롬프트나 입력 을 기반으로 결정될 수 있다.도 6a 내지 6j는 도 5a 내지 5j에 설명된 예시적인 실시예에 대응하는 흐름도 또는 블록도의 세트를 도시한다. 도 7a 내지 7g는 디스플레이 시스템으로 실행될 수 있고 현재 사용과 상관되는 대체 동작을 표시하도록 구성된 생성된 소프트웨어 경험의 실시예의 세트를 도시한다. 도 8a 내지 8g는 도 7a 내지 7g의 실시예의 일부에 대한 대안적인 동작을 표시하기 위한 예시적인 메커니즘을 보여주는 흐름도의 세트를 도시한다. 도 9a 및 9b는 본 개시에 설명된 소프트웨어의 예측 특징을 구현하는데 사용될 수 있는 신경망 블록도를 도시한 다. 도 10a 및 10b는 확장된, 가상 또는 다층 디스플레이 시스템 내에서 대안적인 동작을 예측하는데 사용하기 위한 자기 주의(self-attention) 메커니즘을 도시하는 블록도를 도시한다. 도 11a 내지 11g는 확장된, 가상 또는 다층 디스플레이 시스템을 위한 소프트웨어 애플리케이션의 실시예의 세 트를 도시한다. 도 12는 원격 및 로컬 소스로부터의 컨텐츠를 동시에 표시하기 위한 메커니즘을 설명하기 위한 흐름도이다. 도 13a 내지 13i는 컨텐츠가 로컬 또는 원격 소스로부터 도출되는 확장된, 가상 또는 다층 디스플레이 시스템을 위한 생성 소프트웨어 애플리케이션의 실시예의 세트를 도시한다. 도 14a 내지 14e는 다중 사용자 애플리케이션을 위한 확장된, 가상 또는 다층 디스플레이 시스템을 위한 생성 소프트웨어 애플리케이션의 실시예의 세트를 도시한다. 도 15a 및 15b는 본 개시에 설명된 생성 소프트웨어 애플리케이션의 일부에 대한 흐름도의 세트를 도시한다. 도 16a 내지 16c는 확장된 디스플레이 시스템을 원격 소스 및 로컬 소스 하위 섹션으로 분할하는 것을 설명하는 흐름도의 세트를 도시한다. 도 17a 내지 17d는 시퀀스를 따르고 생성 소프트웨어 애플리케이션에서 발생하는 중앙 이벤트로부터 분기될 수 있는 정보 및 이벤트를 그래픽으로 표시하는 방법을 도시하는 보조 실시예를 도시한다."}
