{"patent_id": "10-2020-0138406", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0053995", "출원번호": "10-2020-0138406", "발명의 명칭": "심화신경망을 이용한 에코 및 잡음 통합 제거 방법 및 장치", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "마이크입력 신호 및 원단신호를 입력 받아, 상기 마이크입력 신호에 대한 제1특징 벡터와 상기 원단신호에 대한제2특징 벡터를 추출하는 특징 벡터 추출부;상기 제1특징 벡터 및 상기 제2특징 벡터를 입력 정보로 하고, 상기 마이크입력 신호에 포함되어 있는 에코신호와 잡음신호를 1차적으로 추정한 제1에코신호 및 제1잡음신호를 출력 정보를 하는, 기 학습된 제1인공신경망;상기 제1특징 벡터, 제2특징 벡터, 제1잡음신호 및 제2잡음신호를 입력 정보로 하고, 상기 에코신호 및 상기 잡음신호를 2차적으로 추정한 제2에코신호 및 제2잡음신호를 출력 정보로 하는, 기 학습된 제2인공신경망; 상기 제1특징 벡터, 제2특징 벡터, 제1잡음신호 및 제2잡음신호를 입력 정보로 하고, 상기 마이크입력 신호에서 상기 에코신호와 상기 잡음신호를 제거하기 위한 최적이득(Optimal gain)을 출력 정보로 하는, 기 학습된 제3인공신경망; 및상기 최적이득을 이용하여 상기 마이크입력 신호에서 상기 에코신호와 상기 잡음신호가 제거된 최종 추정 음성신호를 출력하는 음성합성부;를 포함하는 심화신경망을 이용한 에코 및 잡음 통합 제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제2인공신경망은,상기 제2에코신호를 출력하는 제2에코신호 추정 인공신경망과 및 상기 제2잡음신호를 출력하는 제2잡음신호 추정 인공신경망을 포함하는, 심화신경망을 이용한 에코 및 잡음 통합 제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제2에코신호 추정 인공신경망은,상기 제2에코신호를 추정하는 경우, 적대적 학습 기법을 사용하여 상기 제2잡음신호가 상기 제2에코신호의 추정에 영향을 미치지 않도록 학습을 수행하는, 심화신경망을 이용한 에코 및 잡음 통합 제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제2에코신호 추정 인공신경망의 손실함수는,상기 제2에코신호와 제1레퍼런스 신호와의 차이를 손실함수로 하는 제1손실함수와, 상기 제2잡음신호와 제2 레퍼런스 신호와의 차이를 손실함수로 하는 제2손실함수를 포함하는, 심화신경망을 이용한 에코 및 잡음 통합 제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 제2에코신호 추정 인공신경망은,상기 제1손실함수의 값은 최소가 되도록 상기 제2에코신호 추정 인공신경망을 학습시키고, 상기 제2손실함수의값은 최대가 되도록 상기 제2에코신호 추정 인공신경망을 학습시키는, 심화신경망을 이용한 에코 및 잡음 통합제거 장치. 공개특허 10-2022-0053995-3-청구항 6 제2항에 있어서, 상기 제2잡음신호 추정 인공신경망은,상기 제2잡음신호를 추정하는 경우, 적대적 학습 기법을 사용하여 상기 제2에코신호가 상기 제2잡음신호의 추정에 영향을 미치지 않도록 학습을 수행하는, 심화신경망을 이용한 에코 및 잡음 통합 제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 제2잡음신호 추정 인공신경망의 손실함수는,상기 제2잡음신호와 제3레퍼런스 신호와의 차이를 손실함수로 하는 제3손실함수와, 상기 제2에코신호와 제4 레퍼런스 신호와의 차이를 손실함수로 하는 제4손실함수를 포함하는, 심화신경망을 이용한 에코 및 잡음 통합 제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 제2잡음신호 추정 인공신경망은,상기 제3손실함수의 값은 최소가 되도록 상기 제2잡음신호 추정 인공신경망을 학습시키고, 상기 제4손실함수의값은 최대가 되도록 상기 제2잡음신호 추정 인공신경망을 학습시키는, 심화신경망을 이용한 에코 및 잡음 통합제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 특징 벡터 추출부는,숏타임 푸리에 변환(Short-Time Fourier Transform, STFT)을 수행하여 시간 영역의 상기 마이크입력 신호 및원단 화자 신호를 주파수 영역의 신호로 변환하고, 변환된 주파수 영역의 신호의 로그 파워 스펙트럼(Log PowerSpectrum, LPS)을 특징 벡터로 추출하는, 심화신경망을 이용한 에코 및 잡음 통합 제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 상기 제3인공신경망은,회기 학습(regression)을 통하여 연속적인 최적 이득(optimal gain)을 추정하고, 평균제곱오차(Mean SquaredError, MSE)를 상기 제3인공신경망의 목적 함수로 하여 타겟(target) 특징 벡터인 잡음 및 에코의 통합 제거 이득과 상기 제3인공신경망에 의해 추정된 상기 최적 이득의 차이를 최소화하는 방향으로 상기 제3인공신경망을학습시키는, 심화신경망을 이용한 에코 및 잡음 통합 제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 제1인공신경망은,상기 제1에코신호를 출력하는 제1에코신호 추정 인공신경망과 및 상기 제1에코신호 추정 인공신경망과 독립적으로 구성되어 상기 제1잡음신호를 출력하는 제1잡음신호 추정 인공신경망을 포함하는, 심화신경망을 이용한 에코및 잡음 통합 제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "마이크입력 신호 및 원단신호를 입력 받아, 상기 마이크입력 신호에 대한 제1특징 벡터와 상기 원단 신호에 대공개특허 10-2022-0053995-4-한 제2특징 벡터를 추출하는 특징 벡터 추출부;상기 제1특징 벡터 및 상기 제2특징 벡터를 입력 정보로 하고, 상기 마이크입력 신호에 포함되어 있는 에코신호와 잡음신호를 1차적으로 추정한 제1에코신호 및 제1잡음신호를 출력 정보를 하는, 기 학습된 제1인공신경망;및상기 제1특징 벡터, 제2특징 벡터, 제1잡음신호 및 제2잡음신호를 입력 정보로 하고, 상기 에코신호 및 상기 잡음신호를 2차적으로 추정한 제2에코신호 및 제2잡음신호를 출력 정보로 하는, 기 학습된 제2인공신경망을 포함하는 심화신경망을 이용한 에코 및 잡음 통합 제거 장치."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "마이크입력 신호 및 원단 신호를 포함하는 음성신호로부터 상기 마이크입력 신호에 대한 제1특징 벡터와 상기원단 신호에 대한 제2특징 벡터를 추출하는 특징 벡터 추출 단계;상기 제1특징 벡터 및 상기 제2특징 벡터를 기초로 , 상기 마이크입력 신호에 포함되어 있는 에코신호와 잡음신호를 1차적으로 추정한 제1에코신호 및 제1잡음신호를 기 학습된 제1인공신경망을 이용하여 출력하는 단계;상기 제1특징 벡터, 제2특징 벡터, 제1잡음신호 및 제2잡음신호를 기초로 상기 에코신호 및 상기 잡음신호를 2차적으로 추정한 제2에코신호 및 제2잡음신호를 기 학습된 제2인공신경망을 이용하여 출력하는 단계; 상기 제1특징 벡터, 제2특징 벡터, 제1잡음신호 및 제2잡음신호를 기초로, 상기 음성신호에서 상기 에코신호와상기 잡음신호를 제거하기 위한 최적이득(Optimal gain)을 기 학습된 제3인공신경망을 이용하는 출력하는 단계;및상기 최적이득을 이용하여 상기 마이크입력 신호에서 상기 에코신호와 상기 잡음신호가 제거된 최종 추정 음성신호를 출력하는 단계;를 포함하는 심화신경망을 이용한 에코 및 잡음 통합 제거 방법."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 제2인공신경망은,상기 제2에코신호를 출력하는 제2에코신호 추정 인공신경망과 및 상기 제2잡음신호를 출력하는 제2잡음신호 추정 인공신경망을 포함하여 구성되는, 심화신경망을 이용한 에코 및 잡음 통합 제거 방법."}
{"patent_id": "10-2020-0138406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 제2에코신호를 추정하는 단계는,적대적 학습 기법을 사용하여 상기 제2잡음신호가 상기 제2에코신호의 추정에 영향을 미치지 않는 학습 방법을사용하여 상기 제2에코신호를 추정하고,상기 제2잡음신호를 추정하는 단계는, 적대적 학습 기법을 사용하여 상기 제2에코신호가 상기 제2잡음신호의 추정에 영향을 미치지 않는 학습 방법을사용하여 상기 제2잡음신호를 추정하는, 심화신경망을 이용한 에코 및 잡음 통합 제거 방법."}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 심화신경망을 이용한 에코 및 잡음 통합 제거 장치는 마이크입력 신호 및 원단신호를 입력 받 아, 상기 마이크입력 신호에 대한 제1특징 벡터와 상기 원단신호에 대한 제2특징 벡터를 추출하는 특징 벡터 추 출부, 상기 제1특징 벡터 및 상기 제2특징 벡터를 입력 정보로 하고, 상기 마이크입력 신호에 포함되어 있는 에 (뒷면에 계속)"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 심화신경망을 이용한 에코 및 잡음 통합 제거 방법 및 장치에 관한 발명으로서, 보다 상세하게는 1차 적으로 추정한 에코 신호 및 잡음신호를 기초로 적대적 학습기법을 이용하여 에코 및 잡음이 제거된 음성 신호 를 획득하는 기술에 관한 발명이다."}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성통신(speech communication)이란 음성통신 사용자끼리 상호간의 의사소통을 위해 사용자의 발화된 음성을 상대방에게 전달하는 기술을 의미하며, 구체적으로 널리 사용되고 있는 전화 뿐만 아니라 컨퍼런스 콜, 영상통 화, 화상회의 등의 다양한 분야에서 사용되고 있다. 음성통신에서 상대방에게 정확한 의미를 전달하기 위해서는 발화자의 깨끗한 음성신호만 전달 되어야 하나 두 화자 혹은 여러 화자가 동시에 발화하는 상황이나, 직전 화자 의 발화가 다시 마이크로 입력되어 스피커에서의 재생과 마이크에서의 입력이 반복되는 음향학적 반향(acoustic echo)인 에코 현상이 발생한 경우, 발화자의 음성이 정확하게 전달될 수 없게 된다. 또한, 휴대용 디지털 기기를 통해 음원을 녹음하거나 음성 신호를 입력 받는 환경은 통상적으로 주변 간섭음이 없이 조용한 환경이기보다는 다양한 소음과 주변 간섭음이 모두 포함되어 있는 환경일 경우가 더 많으므로 사용 자의 정확한 음성을 인식하기 위해서는 입력되는 음성 신호로부터 잡음을 분리하고 제거하는 기술이 중요하다. 따라서, 상대방에게 정확한 음성신호가 전달되기 위해서는 앞서 설명한 에코신호 뿐만 아니라 사용자의 주변 환 경에서 발생하는 다양한 잡음신호가 제거되어야 하며, 근래에는 에코신호와 잡음신호를 통합적으로 제거하는 기 술들이 제안되고 있다. 음성 잡음 및 에코의 통합 제거 기술이란 음성 신호에 포함된 잡음 및 에코를 제거하는 기술로서, 일반적으로 잡음 제거기 및 에코 제거기를 독립적으로 설계한 후 직렬로 연결하여 잡음 및 에코 제거를 순차적으로 수행한 다. 그러나 이러한 잡음 및 에코 제거기는 잡음 제거기 및 에코 제거기의 위치에 따라 성능의 차이가 크게 발생 하게 된다. 예를 들어 잡음 제거기가 에코 제거기의 앞단에 위치할 경우 잡음 제거기의 비선형적인 연산으로 인 하여 반향 제거기의 성능 저하가 발생하게 된다. 또한, 반향 제거기가 잡음 제거기의 앞단에 위치할 경우, 잡음 제거기가 추정해야 할 잡음의 스펙트럼이 반향 제거 과정에서 왜곡이 생길 수 있기 때문에 잡음 추정의 성능이 저하되는 문제점이 발생하게 된다. 이에 따라 잡음 및 에코를 한꺼번에 통합적으로 제거하는 잡음 및 에코의 통합 제거 기술이 사용될 수 있다. 종 래에는 음성 신호와 잡음 및 에코 사이의 통계적 정보를 이용하는 통계 모델 기반의 잡음 및 에코의 통합 제거 기술이 주로 사용되었으나, 통계 모델 기반의 음성 향상 기술은 정상 잡음 환경과는 달리 비정상 잡음 환경에서 성능이 크게 저하되는 문제점을 가지고 있다. 예를 들어, 음성 인식에서 잡음이 존재하지 않은 깨끗한 신호를 이용하여 음성 인식 모델을 학습시킨 후 잡음이 존재하는 신호로 테스트를 수행할 경우 성능이 감소한다. 이러한 성능 감소를 해결하기 위해 잡음이 존재하는 음성을 이용하여 음성 인식 모델을 학습하는 기술이 제안되 었으나, 학습된 잡음 환경에 최적화되어 학습된 잡음 환경에서 테스트하는 경우에는 우수한 성능을 보이나, 학 습되지 않은 잡음 환경에서 테스트하는 경우에는 성능이 저하되는 문제점이 존재한다. 또한, 최근에는 인공신경망의 기술이 발전함에 따라, 머신러닝 기법인 심화신경망(Deep Neural Network, DNN)이 다양한 음성 향상 및 음성 인식 연구에서 우수한 성능을 보이고 있다. 심화신경망은 다수의 은닉 층과 은닉 노 드들을 통하여 입력 특징 벡터와 출력 특징 벡터 사이의 비선형적인 관계를 효과적으로 모델링하여 우수한 성능 을 보인다. 따라서, 심화신경망을 이용하여 잡음 및 에코를 한꺼번에 제거하는 기술이 발전하고 있는데, 대부분 의 종래 기술은 잡음과 에코를 한번씩 제거하거나 음성을 직접적으로 추정하는 방법을 사용하는데, 이는 단계별 로 제거되는 단계에서 음성의 일정 부분이 억제되는 단점을 가지거나, 음성신호를 직접 추정할 때 남아있는 잔 여 에코 및 잡음에 의해 정확한 음성을 추정하지 못한다는 문제점이 존재한다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1871604호 '심화 신경망을 이용한 다채널 마이크 기반의 잔향시간 추정 방 법 및 장치'(2018.06.25. 공개) (특허문헌 0002) 한국등록특허 제10-1988504호 '딥러닝에 의해 생성된 가상환경을 이용한 강화학습 방 법'(2019.06.05. 공개)"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 일 실시예에 따른 심화신경망을 이용한 에코 및 잡음 통합 제거 방법 및 장치는 상기 설명한 문제점을 해결하기 위해 고안된 발명으로서, 보다 에코와 잡음이 효율적으로 제거된 음성 신호를 추출할 수 있는 에코 및 잡음 통합 제거 장치 및 방법을 제공하기 위함이다. 구체적으로, 마이크입력 신호 및 원단신호를 이용하여1차적으로 추정된 잡음신호와 에코신호를 기초로 적대적 학습 기법을 사용하여 마이크에 입력된 신호 중 잡음신호와 에코신호를 최종적으로 추정한 후, 마이크입력 신호 에서 잡음신호와 에코신호가 제거된 깨끗한 사용자의 음성 신호만을 제공할 수 있는 에코 및 잡음 통합 제거 장 치 및 발명을 제공하기 위함이다."}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 심화신경망을 이용한 에코 및 잡음 통합 제거 장치는 마이크입력 신호 및 원단신호를 입력 받 아, 상기 마이크입력 신호에 대한 제1특징 벡터와 상기 원단신호에 대한 제2특징 벡터를 추출하는 특징 벡터 추 출부, 상기 제1특징 벡터 및 상기 제2특징 벡터를 입력 정보로 하고, 상기 마이크입력 신호에 포함되어 있는 에 코신호와 잡음신호를 1차적으로 추정한 제1에코신호 및 제1잡음신호를 출력 정보를 하는, 기 학습된 제1인공신 경망, 상기 제1특징 벡터, 제2특징 벡터, 제1잡음신호 및 제2잡음신호를 입력 정보로 하고, 상기 에코신호 및 상기 잡음신호를 2차적으로 추정한 제2에코신호 및 제2잡음신호를 출력 정보로 하는, 기 학습된 제2인공신경망, 상기 제1특징 벡터, 제2특징 벡터, 제1잡음신호 및 제2잡음신호를 입력 정보로 하고, 상기 마이크입력 신호에서 상기 에코신호와 상기 잡음신호를 제거하기 위한 최적이득(Optimal gain)을 출력 정보로 하는, 기 학습된 제3인 공신경망 및 상기 최적이득을 이용하여 상기 마이크입력 신호에서 상기 에코신호와 상기 잡음신호가 제거된 최 종 추정 음성신호를 출력하는 음성합성부를 포함할 수 있다. 상기 제2인공신경망은, 상기 제2에코신호를 출력하는 제2에코신호 추정 인공신경망과 및 상기 제2잡음신호를 출 력하는 제2잡음신호 추정 인공신경망을 포함할 수 있다. 상기 제2에코신호 추정 인공신경망은, 상기 제2에코신호를 추정하는 경우, 적대적 학습 기법을 사용하여 상기 제2잡음신호가 상기 제2에코신호의 추정에 영향을 미치지 않도록 학습을 수행할 수 있다. 상기 제2에코신호 추정 인공신경망의 손실함수는, 상기 제2에코신호와 제1레퍼런스 신호와의 차이를 손실함수로 하는 제1손실함수와, 상기 제2잡음신호와 제2 레퍼런스 신호와의 차이를 손실함수로 하는 제2손실함수를 포함할 수 있다. 상기 제2에코신호 추정 인공신경망은, 상기 제1손실함수의 값은 최소가 되도록 상기 제2에코신호 추정 인공신경 망을 학습시키고, 상기 제2손실함수의 값은 최대가 되도록 상기 제2에코신호 추정 인공신경망을 학습시킬 수 있 다. 상기 제2잡음신호 추정 인공신경망은, 상기 제2잡음신호를 추정하는 경우, 적대적 학습 기법을 사용하여 상기 제2에코신호가 상기 제2잡음신호의 추정에 영향을 미치지 않도록 학습을 수행할 수 있다. 상기 제2잡음신호 추정 인공신경망의 손실함수는, 상기 제2잡음신호와 제3레퍼런스 신호와의 차이를 손실함수로 하는 제3손실함수와, 상기 제2에코신호와 제4 레퍼런스 신호와의 차이를 손실함수로 하는 제4손실함수를 포함할 수 있다. 상기 제2잡음신호 추정 인공신경망은, 상기 제3손실함수의 값은 최소가 되도록 상기 제2잡음신호 추정 인공신경 망을 학습시키고, 상기 제4손실함수의 값은 최대가 되도록 상기 제2잡음신호 추정 인공신경망을 학습시킬 수 있 다. 상기 특징 벡터 추출부는, 숏타임 푸리에 변환(Short-Time Fourier Transform, STFT)을 수행하여 시간 영역의 상기 마이크입력 신호 및 원단 화자 신호를 주파수 영역의 신호로 변환하고, 변환된 주파수 영역의 신호의 로그 파워 스펙트럼(Log Power Spectrum, LPS)을 특징 벡터로 추출할 수 있다. 상기 제3인공신경망은, 회기 학습(regression)을 통하여 연속적인 최적 이득(optimal gain)을 추정하고, 평균제 곱오차(Mean Squared Error, MSE)를 상기 제3인공신경망의 목적 함수로 하여 타겟(target) 특징 벡터인 잡음 및 에코의 통합 제거 이득과 상기 제3인공신경망에 의해 추정된 상기 최적 이득의 차이를 최소화하는 방향으로 상 기 제3인공신경망을 학습시킬 수 있다. 상기 제1인공신경망은, 상기 제1에코신호를 출력하는 제1에코신호 추정 인공신경망과 및 상기 제1에코신호 추정 인공신경망과 독립적으로 구성되어 상기 제1잡음신호를 출력하는 제1잡음신호 추정 인공신경망을 포함할 수 있 다.다른 실시예에 따른 심화신경망을 이용한 에코 및 잡음 통합 제거 장치는 마이크입력 신호 및 원단신호를 입력 받아, 상기 마이크입력 신호에 대한 제1특징 벡터와 상기 원단 신호에 대한 제2특징 벡터를 추출하는 특징 벡터 추출부, 상기 제1특징 벡터 및 상기 제2특징 벡터를 입력 정보로 하고, 상기 마이크입력 신호에 포함되어 있는 에코신호와 잡음신호를 1차적으로 추정한 제1에코신호 및 제1잡음신호를 출력 정보를 하는, 기 학습된 제1인공 신경망 및 상기 제1특징 벡터, 제2특징 벡터, 제1잡음신호 및 제2잡음신호를 입력 정보로 하고, 상기 에코신호 및 상기 잡음신호를 2차적으로 추정한 제2에코신호 및 제2잡음신호를 출력 정보로 하는, 기 학습된 제2인공신경 망을 포함할 수 있다. 다른 실시예에 따른 심화신경망을 이용한 에코 및 잡음 통합 제거 방법은, 마이크입력 신호 및 원단 신호를 포 함하는 음성신호로부터 상기 마이크입력 신호에 대한 제1특징 벡터와 상기 원단 신호에 대한 제2특징 벡터를 추 출하는 특징 벡터 추출 단계, 상기 제1특징 벡터 및 상기 제2특징 벡터를 기초로 , 상기 마이크입력 신호에 포 함되어 있는 에코신호와 잡음신호를 1차적으로 추정한 제1에코신호 및 제1잡음신호를 기 학습된 제1인공신경망 을 이용하여 출력하는 단계, 상기 제1특징 벡터, 제2특징 벡터, 제1잡음신호 및 제2잡음신호를 기초로 상기 에 코신호 및 상기 잡음신호를 2차적으로 추정한 제2에코신호 및 제2잡음신호를 기 학습된 제2인공신경망을 이용하 여 출력하는 단계, 상기 제1특징 벡터, 제2특징 벡터, 제1잡음신호 및 제2잡음신호를 기초로, 상기 음성신호에 서 상기 에코신호와 상기 잡음신호를 제거하기 위한 최적이득(Optimal gain)을 기 학습된 제3인공신경망을 이용 하는 출력하는 단계 및 상기 최적이득을 이용하여 상기 마이크입력 신호에서 상기 에코신호와 상기 잡음신호가 제거된 최종 추정 음성신호를 출력하는 단계;를 포함할 수 있다. 상기 제2인공신경망은, 상기 제2에코신호를 출력하는 제2에코신호 추정 인공신경망과 및 상기 제2잡음신호를 출 력하는 제2잡음신호 추정 인공신경망을 포함하여 구성될 수 있다. 상기 제2에코신호를 추정하는 단계는, 적대적 학습 기법을 사용하여 상기 제2잡음신호가 상기 제2에코신호의 추 정에 영향을 미치지 않는 학습 방법을 사용하여 상기 제2에코신호를 추정하고, 상기 제2잡음신호를 추정하는 단 계는, 적대적 학습 기법을 사용하여 상기 제2에코신호가 상기 제2잡음신호의 추정에 영향을 미치지 않는 학습 방법을 사용하여 상기 제2잡음신호를 추정할 수 있다."}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따른 심화신경망을 이용한 에코 및 잡음 통합 제거 방법은, 종래 기술과 달리 마이크입력 신호에 포함되어 있는 에코신호와 잡음신호를 별도로 추정하되 서로 영향을 최대한 주지 않도록 적대적 학습 기법을 사 용하는바, 에코신호와 잡음신호가 보다 깨끗하게 제거된 사용자의 음성신호만을 추출할 수 있는 효과가 존재한 다. 따라서, 가정 환경에서 사용되는 인공지능 스피커, 공항에서 사용되는 로봇, 음성인식 및 PC 음성통신 시스템 등 배경잡음신호와 에코신호가 존재하는 환경에서 마이크로폰을 통해 사용자의 음성을 수집하여 처리하는 경우, 배경 잡음신호와 에코신호를 보다 효율적으로 제거할 수 있어, 음성 품질 및 명료도를 향상시킬 수 있는 효과가 존재한다."}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 실시 예들은 첨부된 도면들을 참조하여 설명한다. 각 도면의 구성요소들에 참조 부호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가 지도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시 예를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 실시예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생략한 다. 또한, 이하에서 본 발명의 실시 예들을 설명할 것이나, 본 발명의 기술적 사상은 이에 한정되거나 제한되지 않고 당업자에 의해 변형되어 다양하게 실시될 수 있다. 또한, 본 명세서에서 사용한 용어는 실시 예를 설명하기 위해 사용된 것으로, 개시된 발명을 제한 및/또는 한정 하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\", \"구비하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들 이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않 는다. 또한, 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함하며, 본 명세서에 서 사용한 \"제 1\", \"제 2\" 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지 만, 상기 구성 요소들은 상기 용어들에 의해 한정되지는 않는다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략한다. 음성 향상 기술은 마이크로폰으로 입력된 잡음신호 및 에코신호를 제거하여 깨끗한 음성을 추정하는 기술로, 음 성 인식과 음성 통신과 같은 음성 어플리케이션에 필수적인 기술이다. 예를 들어 음성 인식에서 잡음 및 에코가 존재하지 않은 깨끗한 신호로 음성 인식 모델을 학습시킨 후 잡음이 존재하는 신호로 테스트를 할 경우 성능이 감소하게 된다. 이를 해결하기 위하여 음성 인식 수행 전에 잡음 및 에코를 제거하는 음성 향상 기술을 도입하 여 음성 인식의 성능을 높일 수 있다. 또한, 음성 향상 기술은 음성 통신에서 잡음 및 에코를 제거하여 선명하 고 명확하게 음성을 전달하여 통화 품질을 높이기 위해서도 사용될 수 있다. 이하 설명되는 아래의 실시 예들은 심화신경망(DNN)을 이용하여 음성에 존재하는 잡음 및 에코를 통합적으로 제 거하는 기술에 관한 발명으로서, 더 구체적으로 실시예들은 원단 화자 신호와 마이크 입력 정보만으로는 심화신 경망(DNN)이 학습이 잘되지 않는 문제점을 해결하기 위하여, 1차적으로 에코신호와 잡음신호를 독립적으로 추정 한 후, 추정된 신호들을 적대적 학습 기법을 이용하여 2차적으로 에코신호와 잡음신호를 추정함으로써, 보다 정 확히 에코신호와 잡음신호를 정확히 추정할 수 있는 기술에 관한 발명이다. 또한, 본 실시예들에서는 STFT(Short Time Fourier Transform) 및 STFT(Inverse Short Time Fourier Transform) 변환을 이용하는 경우를 예로 들어 설명하나, 이는 실시예에 해당되며, STFT, ISTFT 이외에 DFT(Discrete Fourier Transform), IDFT(Inverse Discrete Fourier Transform) 변환, FFT(Fast Fourier Transform), IFFT(Inverse Fast Fourier Transform) 변환 등이 이용될 수도 있다. 이하에서는 음성 신호에 포함된 잡음 및 에코를 심화신경망 기반으로 통합하여 제거하는 기술에 대해 보다 상세 히 설명하기로 한다. 도 1은 에코신호와 잡음신호가 존재하는 음성 통신 환경에서 에코신호 및 잡음신호가 통합 제거 장치로 입력되 는 신호들을 도시한 도면이며, 도 2는 본 발명의 실시예에 따른 심화신경망을 이용한 에코 및 잡음 통합 제거 장치의 일부 구성 요소를 도시한 블럭도이다.도 1을 참조하면, 마이크에 입력되는 신호 y(t)는 아래 식 과 같이, 사용자가 마이크로 입력하는 음 성신호(speech signal)인 s(t)와 사용자가 존재하는 공간에서 다양한 환경에 의해 발생되는 잡음신호(noise signal)인 n(t)와 스피커를 통해 출력된 원단 신호(far end signal)가 마이크와 스피커 사이의 RIR(Room Impulse Response)와 컨불루션(convolution) 되어 다시 마이크로 다시 입력되는 에코신호(echo signal)인 d(t)의 합으로 구성될 수 있다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명에 따른 에코 및 잡음 통합 제거 장치는 마이크 입력 신호인 y(t)와 원단 신호인 x(t)를 이용하여 화자의 음성신호 s(t)를 추정한 추정 음성신호인 s'(t)를 출력할 수 있다. 여기에서 잡음 및 에코가 포함된 마 이크 입력 신호는 잡음과 에코가 동시에 존재하는 마이크 입력 신호를 의미한다. 도 2를 참조하면, 심화신경망을 이용한 에코 및 잡음 통합 제거 장치는 특징 벡터를 추출하는 특징 벡터 추출부, 제1에코신호 및 제1잡음신호를 추정하고 출력하는 제1인공신경망, 제2에코신호 및 제2잡음신 호를 추정하고 출력하는 제2인공신경망, 에코 및 잡음 통합 제거 이득 값을 출력하는 제3인공신경망 및 사용자의 음성을 추정한 최종 추정 음성을 출력하는 음성합성부 등을 포함할 수 있다. 도 3은 본 발명의 특징 백터 추출부에 입력되는 입력 정보와 출력되는 출력 정보를 도시한 도면이다. 도 3에 도시된 바와 같이 특징 벡터 추출부는 푸리에 변환부와 LPS 추출부를 포함할 수 있다. 푸리에 변환부는 시간 영역의 마이크입력 신호와 원단신호를 주파수 영역에 관한 식으로 변환시킬 수 있다. 구체적으로, 푸리에 변환부는 마이크입력 신호에 포함되어 있는 s(t), d(t) 및 v(t)를 숏타 임 푸리에 변환(STFT)을 통하여 각각 S(k,ㅣ), D(k,l) 및 N(k,l)로 변환하여 아래 식 와 같이 주파수 영역으 로 표현할 수 있다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "식 에서 k,와 l은 각각 frequency-bin index와 frame index를 의미한다.숏타임 푸리에 변환(STFT)을 수행하 는 이유는 인공신경망에 입력할 특징벡터를 추출하기 위해 수행하는 것이며, 이는 연산량의 효율을 가져올 수 있다. 원단신호 또한 푸리에 변환부에 의해 시간 영역에서 주파수 영역의 식으로 표현될 수 있다. 구체적으 로, 앞서 설명한 숏타임 푸리에 변환(STFT)에 의해 원단신호인 x(t)는 X(m,l)로 표현될 수 있다. 특징 벡터 추출부의 LPS 추출부는 복수의 인공신경망(120, 130, 140)에 입력할 입력 특징 벡터의 추 출을 위하여 주파수 영역 신호의 로그 파워 스펙트럼(Log Power Spectrum, LPS)을 추출할 수 있다. 구체적으로, LPS 추출부는 마이크입력 신호 및 원단신호가 푸리에 변환부에 의해 변환된 신 호들에 대해 로그 파워 스펙트럼(log power spectrum)을 추출하여 제1특징 벡터에 해당하는 마이크입력 신호 LPS와 제2특징 벡터에 해당하는 단신호 LPS를 출력 정보로 하여 출력할 수 있다. 특징 벡터 추출부 에 의해 출력된 마이크입력 신호 LPS와 원단신호 LPS는 제1인공신경망, 제2인공신경망 및 제3인공신경망의 입력 특징 벡터로 사용될 수 있다. 도 4는 본 발명의 제1인공신경망에 입력되는 입력 정보와 출력되는 출력 정보를 도시한 도면이다. 도 5는 본 발 명의 제1에코신호 추정 인공신경망의 학습방법을 설명하기 위한 도면이고, 도 6은 제1잡음심호 추정 인공신경망 의 학습방법을 설명하기 위한 도면이다. 도 4를 참조하면, 제1 인공신경망은 특징 벡터 추출부에 출력된 마이크입력 신호 LPS와 원단신호 LPS를 입력 정보로 하고, 마이크입력 신호에 포함되어 있는 에코신호와 잡음신호를 각각 추정한 제1에 코신호와 제1잡음신호를 출력 정보로 하는 인공신경망으로서, 제1인공신경망은 상기 입력 정보와 출력 정보를 기초로 학습을 수행하는 학습 세션(미도시)과, 입력 정보를 기초로 출력 정보를 추론하는 추론 세 션(미도시)을 포함할 수 있다. 제1인공신경망의 학습 세션은 입력 정보(21,22)와 출력 정보(31,32)를 기초로 학습을 수행하는 세션이며, 추론 세션은 학습된 제1 인공신경망을 이용하여 실시간으로 입력되는 입력 정보(21,22)를 분석하여, 마이 크입력 신호에 포함되어 있는 에코신호와 잡음신호를 각각 추정한 제1에코신호와 제2에코신호를 출 력 정보로 하여 출력할 수 있으며, 제1에코신호는 1차적으로 추정된 에코신호의 LPS 정보를 포함하고 있으며, 제1잡음신호는 1차적으로 추정된 잡음신호의 LPS 정보를 포함할 수 있다. 구체적으로, 본 발명에 따른 제1인공신경망은 특징 벡터 추출부에 의해 출력된 마이크입력 신호 LPS 및 원단신호 LPS에 포함되어 있는 임의의 길이를 가지는 특징벡터를 입력정보로 입력 받아 프레임 단위로 잡음신호와 에코신호를 추정하는 방법으로 학습을 수행할 수 있다. 일 실시예로, 제1인공신경망은 시간 순서대로 나열된 프레임 단위의 특징벡터를 제1인공신경망의 입 력정보로 입력 받아 비선형 연산을 통해 2개의 은닉층(hidden layer)를 거친 후, 마지막으로 출력층에서 에코신 호와 잡음신호의 LPS를 추정하도록 학습할 수 있다. 또한, 제1인공신경망은 출력되는 출력 정보들의 정확성을 높이기 위해 음성 왜곡을 발생시키는 요소인 에 코신호와 잡음신호를 하나의 인공신경망에서 추정하는 것이 아니라, 별도로 구성되어 있는 제1에코신호 추정 인 공신경망과 제1잡음신호 추정 인공신경망를 이용하여 제1에코신호 추정 인공신경망은 에코신호 를 추정하도록 하게 하고, 제1잡음심호 추정 인공신경망은 잡음신호를 추정하도록 구성될 수 있다. 도 5를 참조하면, 제1에코신호 추정 인공신경망은 에코신호의 LPS를 보다 정확하게 추정하기 위해 마이크 입력 신호에 포함되어 있는 target 에코신호의 LPS즉, 에코 레퍼런스 신호와 제1에코신호 추정 인공신 경망을 통해 추정된 제1에코신호의 LPS와의 평균제곱오차(mean squared error)를 손실함수로 하고, 상 기 손실함수의 값을 최소화하는 방법으로 학습을 진행할 수 있으며, 구체적으로 제1에코신호 추정 인공신경망 의 손실함수 식은 아래 식과 같이 정의될 수 있다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "제1잡음신호 추정 인공신경망 또한 잡음신호의 LPS를 정확하게 추정하기 위해, 도 6에 도시된 바와 같이 마이크입력 신호에 포함되어 있는 target 잡음신호의 LPS즉, 잡음 레퍼런스 신호와 제1잡음신호 추정 인공신경망을 통해 추정된 제1잡음신호의 LPS와의 평균제곱오차(mean squared error)를 손실함수로 하 고, 상기 손실함수의 값을 최소화하는 방법으로 학습을 진행할 수 있으며, 제1잡음신호 추정 인공신경망의 손실함수는 아래 식 와 같이 정의될 수 있다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "식 과 에서의 M과 K는 학습에 사용되는 전체 프레임 개수이며 K는 STFT 이후에 학습에 사용되는 전체 주 파수의 개수를 의미하며, 제1인공신경망에 의해 출력된 출력 정보들은 제2인공신경망의 입력 정보로 활용될 수 있다. 이하 제2인공신경망과 제3인공신경망에 대해 구체적으로 알아본다. 도 7은 본 발명의 제2인공신경망에 입력되는 입력 정보와 출력되는 출력 정보를 도시한 도면이다. 도 8은 본 발 명의 제2에코신호 추정 인공신경망의 학습방법을 설명하기 위한 도면이고, 도 9는 제2잡음심호 추정 인공신경망 의 학습방법을 설명하기 위한 도면이며, 도 10은 제3인공신경망과 음성합성부를 설명하기 위한 도면이다. 도 7을 참조하면, 제2 인공신경망은 특징 벡터 추출부에 출력된 출력된 마이크입력 신호 LPS와 원단신호 LPS 및 제1인공신경망에서 출력된 제1에코신호와 제1잡음신호를 입력 정보로 하고, 마이크입력 신호에 포함되어 있는 에코신호와 잡음신호를 2차적으로 추정한 제2에코신호와 제2잡음신호 를 출력 정보롤 하는 인공신경망으로서, 제2인공신경망은 상기 입력 정보와 출력 정보를 기초로 학습 을 수행하는 학습 세션(미도시)과, 입력 정보를 기초로 출력 정보를 추론하는 추론 세션(미도시)을 포함할 수 있다. 제2인공신경망의 학습 세션은 입력 정보(31,32,21,22)와 출력 정보(51,52)를 기초로 학습을 수행할 수 있 는 세션이며, 추론 세션은 학습된 제2 인공신경망을 이용하여 실시간으로 입력되는 입력 정보 (31,32,21,22)를 분석하여, 마이크입력 신호에 포함되어 있는 에코 신호와 잡음 신호를 다시 한번 추정한 정보인 제2에코신호와 제2잡음신호를 출력 정보로 하여 출력할 수 있다. 즉, 제2에코신호는 제1인공신경망에 의해 1차적으로 추정된 제1에코신호 및 다른 입력 정보들 (32,21,22)를 기초로 마이크입력 신호에 포함되어 있는 에코신호를 다시 한번 추정한 신호를 의미하며, 제2 잡음신호는 제1인공신경망에 의해 1차적으로 추정된 제1잡음신호 및 다른 입력 정보들(31,21,22) 를 기초로 마이크입력 신호에 포함되어 있는 잡음신호를 다시 한번 추정한 신호를 의미한다. 여기서 제2에 코신호는 2차적으로 추정된 에코신호의 LPS 정보를 포함할 수 있고, 제2잡음신호는 2차적으로 추정된 잡음신호의 LPS 정보를 포함할 수 있다. 제1인공신경망에서 추정되어 출력된 제1에코신호 및 제1잡음신호의 LPS는 서로의 성분을 고려하 지 않고 독립적으로 추정했기 때문에 정확성이 상대적으로 떨어질 수 있으며, 이렇게 추정된 에코신호와 잡음신 호에 대한 정보를 그대로 사용하게 될 경우 음성왜곡이 발생할 수 있다. 따라서, 음성 왜곡을 방지하기 위해 에코신호와 잡음신호를 동시에 제거하는 것이 효과적이며, 본 발명의 경우 이를 효율적으로 구현하기 위해 음성왜곡을 발생시키는 요소인 에코신호와 잡음신호를 하나의 인공신경망에서 추정하는 것이 아니라, 각각 독립적으로 존재하는 제2에코신호 추정 인공신경망과 제2잡음심호 추정 인공 신경망이 각각 에코신호와 잡음신호를 추정하므로, 에코신호와 잡음신호가 중복되어 추정되는 문제를 방지 할 수 있다. 구체적으로, 제2에코신호 추정 인공신경망은 에코신호를 효과적으로 추정할 수 있도록 학습을 수행함에 있 어서, 에코신호는 추정이 실제 값과 유사해질 수 있도록 추정을 하되, 잡음신호에 대해는 둔감하게 반응하도록 인공신경망을 학습시키고, 제2잡음신호 추정 인공신경망은 잡음신호를 효과적으로 추정할 수 있도록 학습 을 수행함에 있어서, 잡음신호는 추정이 실제 값과 유사해질 수 있도록 추정을 하되, 에코신호에 대해는 둔감 하게 반응하도록 인공신경망을 학습시키는 방법인 적대적 학습(adversarial training) 방법을 사용하여 각각 학 습을 수행할 수 있다. 적대적 학습이란 추정 신호에 대한 정확성에 영향을 미칠 수 있는 인자가 복수 개인 경우, 정확성을 높일 수 있 는 성분에 대해서는 추정이 잘 이루어지는 방향(손실함수의 값이 작아지는 방향)으로 학습을 수행하고, 정확성 에 부정적인 영향을 미칠 수 있는 성분에 대해서는 그 성분에 대해서는 인공신경망이 둔감하게 반응할 수 있는 방향(손실함수의 갑의 증가하는 방향)으로 학습을 수행하는 방법을 의미한다. 이러한 방법으로 추정을 하는 경우 제2에코신호 추정 인공신경망은 에코신호에 대해서만 중점적으로 추정 하고, 제2잡음심호 추정 인공신경망은 잡음신호에 대해서만 중점적으로 추정을 하므로, 제2인공신경망이 에코신호와 잡음신호를 추정함에 있어서 중복 추정을 피할 수 있는 효과가 존재하며, 제2에코신호 추정 인공신 경망과 제2잡음심호 추정 인공신경망은 제1인공신경망에서 추정되었던 에코신호와 잡음신호에 대한 정보인 제1에코신호와 제1잡음신호를 고려하여 에코신호와 잡음신호를 추정하므로 제1인공신경망 보다 정확히 에코신호와 잡음신호를 추정할 수 있는 장점이 존재한다. 즉, 도 8에 도시된 바와 같이 제2에코신호 추정 인공신경망은 에코신호의 LPS를 정확하게 추정하기 위해, 제2에코신호 추정 인공신경망을 통해 추정된 제2에코신호의 LPS와 마이크입력 신호에 포함되어 있 는 실제 에코신호에 대한 정보인 제1레퍼런스 신호와의 차이를 제1손실함수로 하고, 상기 제1손실함수의 값 이 최소가 되는 방향으로 학습을 진행할 수 있다. 따라서, 에코신호의 추정에 사용되는 파라미터(parameter)들 은 에코신호의 LPS를 더욱 잘 추정되도록 손실함수를 최소화 하는 방향으로 업데이트 될 수 있다. 또한, 제2에코신호 추정 인공신경망은 에코신호를 추정함에 있어서, 잡음신호가 추정에 영향을 미치지 않 도록 하는 방향으로 학습을 수행하는 바, 제2에코신호 추정 인공신경망을 통해 추정된 제2잡음신호의 LPS와 이에 대한 레퍼런스 정보인 제2레퍼런신호의 LPS와 차이를 제2손실함수로 하고, 상기 제2손실함수의 값은 최대가 되는 방향으로 학습을 수행할 수 있다. 따라서, 제2에코신호 추정 인공신경망은 잡음신호에 추정에 사용되는 파라미터들에 대해서는 잡음신호의 LPS를 잘 추정하지 못하도록 손실함수를 최대화 하는 방향으로 학습시키므로, 제2에코신호 추정 인공신경망 은 잡음신호의 추정 성능에 둔감하면서, 에코신호의 추정 성능은 향상될 수 있도록 학습을 수행할 수 있으 며, 제2에코신호 추정 인공신경망의 손실함수는 위에서 설명한 식에 아래 식 가 추가된 식으로 구성 될 수 있다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "반대로, 제2잡음신호 추정 인공신경망은 잡음신호의 LPS를 정확하게 추정하기 위해, 도 9에 도시된 바와 같이 제2잡음신호 추정 인공신경망을 통해 추정된 제2잡음신호의 LPS와 마이크입력 신호에 포함되 어 있는 실제 잡음신호에 대한 정보인 제3레퍼런스 신호와의 차이를 제3손실함수로 하고, 상기 제3손실함수 의 값이 최소가 되는 방향으로 학습을 진행할 수 있다. 따라서, 잡음신호의 추정에 사용되는 파라미터 (parameter)들은 잡음신호의 LPS를 더욱 잘 추정되도록 손실함수를 최소화 하는 방향으로 업데이트 될 수 있다. 또한, 제2잡음신호 추정 인공신경망은 잡음신호를 추정함에 있어서, 에코신호가 추정에 영향을 미치지 않 도록 하는 방향으로 학습을 수행하는 바, 제2잡음신호 추정 인공신경망을 통해 추정된 제2에코신호의 LPS와 이에 대한 레퍼런스 정보인 제4레퍼런신호의 LPS와 차이를 제4손실함수로 하고, 상기 제4손실함수의 값은 최대가 되는 방향으로 학습을 수행할 수 있다. 따라서, 제2잡음신호 추정 인공신경망은 에코신호에 추정에 사용되는 파라미터들은 잡음신호의 LPS를 잘 추정하지 못하도록 손실함수를 최대화 하는 방향으로 학습시키므로, 제2잡음신호 추정 인공신경망은 에코 신호의 추정 성능에 둔감하면서, 잡음신호의 추정 성능은 향상될 수 있도록 학습을 수행할 수 있으며, 제2잡음 신호 추정 인공신경망의 손실함수는 위에서 설명한 식에 아래 식 이 추가된 식으로 구성될 수 있다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "제2에코신호 추정 인공신경망은 학습을 함에 있어서, 파라미터가 업데이트 되는 식은 최소화가 되도록 하고, 식 는 최대화가 되는 방향으로 학습을 진행하고, 제2잡음신호 추정 인공신경망은 학습을 함에 있 어서, 파라미터가 업데이트 되는 식는 최소화가 되도록 하고, 식 은 최대화가 되는 방향으로 학습을 진행 할 수 있다. 따라서, 제2에코신호 추정 인공신경망은 아래 식 과 같은 파라미터 업데이트 규칙이 적용 될 수 있으며, 제2잡음신호 추정 인공신경망은 아래 식 과 같은 파라미터 업데이트 규칙이 적용될 수 있다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "식 과 에서 는 학습비율을 나타내며, 과 는 back-propagation 시 gradient reversal의 정도를 조 절할 수 있는 hyperparameter를 의미한다. 제2인공신경망에 의해 마이크입력 신호에 포함되어 있는 에코신호와 입력신호를 추정한 제2에코신호 와 제2잡음신호가 출력되면, 제3인공신경망은 제2에코신호와 제2잡음신호에 포함되어 있는 제2 에코신호의 LPS 정보와 제2잡음신호의 LPS 정보 및 특징 벡터 추출부에 의해 출력된 마이크입력 신호 LPS 정보 및 원단신호 LPS 정보를 기초로 마이크입력 신호에 포함되어 있는 에코신호와 잡음신호를 통합적으로 제거하기 위한 최적 이득(optimal gain, 70)을 출력할 수 있으며, 음성합성부는 최적 이득 정 보를 기초로 마이크 입력 신호에서 에코신호와 잡음신호를 제거한 최종 추정 음성신호를 출력할 수 있다. 구체적으로, 제3인공신경망은 앞서 설명한 식의 제곱을 아래 식 와 같이 변환할 수 있다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "식에서 *는 conjugate operator를 의미하며, 음성, 에코, 잡음의 경우 보통 통계적 독립으로 가정되기 때문 에 제곱 텀을 제외한 성분들은 0이 된다. 따라서 음성을 추정하기 위한 최적 이득인mask는 아래 식 과 같 이 표현될 수 있으며 0 ~ 1의 값을 가진다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "제3인공신경망은 추정된 mask의 정확도를 높이기 위해 학습을 수행할 수 있는데, 구체적으로 제3인공신경 망에 의해 추정된 mask와 레퍼런스 정보에 해당하는 실제 mask 와의 차이에 대한 평균제곱오차(mean squared error)를 손실함수로 하고, 상기 손실함수의 값이 최소가 되는 방향으로 학습을 진행할 수 있으며, 구 체적인 손실함수의 식은 아래 식 과 같다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "음성합성부는 잡음신호 및 에코신호가 포함된 마이크입력 신호 LPS에 추정된 잡음 및 에코의 통합 제 거 이득을 곱하여 사용자의 음성신호에 대한 LPS를 획득할 수 있다. 다만, 추정된 음성신호는 위상 정보를 고려 하지 않았기 때문에 아래 식 를 이용하여 주파수 도메인에서 추정된 사용자의 음성신호에 대한 크기와 마이 크입력 신호의 위상 정보를 곱한 후, 인버스 숏타임 푸리에 변환(Inverse Short-Time Fourier Transform, ISTFT)을 수행하여 최종적으로 잡음 및 에코가 제거된 최종 음성 신호의 파형을 획득할 수 있다. 즉, 잡음 및 에코가 통합 제거된 최종 추정 음성신호를 획득할 수 있다. 식 -"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 13, "content": "도 11 내지 도13은 본 발명의 효과를 설명하기 위한 실험 데이터를 도시한 도면으로서, 도 11은 RIR(Room Impulse Response) 생성기의 파라미터 설정 값을, 도 12와 도 13은 본 발명과 다른 인공신경망 모델의 학습 결 과를 비교하여 도시한 도면이다. 도 11 내지 13에서 설명되는 실험은 TIMIT 데이터베이스(DB)를 이용하여 진행하였고 데이터베이스는 모두 16 kHz로 샘플링된 신호로 이루어져 있으며, 실험을 위해 음성신호에 에코신호를 convolution한 데이터와 잡음신호 데이터를 이용해 학습용 데이터셋은 3000개의 발화로 구성하였고, 평가용 데이터셋은 184개의 발화로 구성하였 다. 또한, 잡음신호와 에코신호에 의해 오염된 다채널 음성신호를 생성하기 위해서 시물레이션을 통해 특정 방 (room)환경에서 RIR(Room Impulse Response)을 생성해주는 RIR 생성기 툴킷을 이용하여 다양한 종류의 방 환경 에 대해 시뮬레이션하여 RIR를 생성하였다. 또한, 학습용 데이터셋에 적용할 RIR을 18개, 평가용 데이터셋에 적용할 RIR을 2개를 적용하였으며, RIR 생성을 위한 방 환경을 설정하는 데에는 도 11에 도시된 표의 설정에 따 라 랜덤하게 환경을 설정하였다. 잡음 신호로는 ITU-T recommendation P. 501 database를 사용하였으며 잡음은 평가용 음성 데이터셋과 랜덤하게 더하였으며, 더할 때의 신호대잡음비(signal-to-noie ratio : SNR)은 학습용은 4 dB, 8 dB, 12 dB 중 하나를택하여 랜덤하게 더하였으며, 평가용은 10 dB로 고정하여 사용하였다. 본 발명에 따른 인공신경망과 결과를 비교하기 위한 다른 인공신경망을 학습하는 경우, 대부분의 설정 값들은 동일하게 진행하였다. 첫 번째로, 프레임 길이와 프레임 이동(shift) 길이를 각각 32 ms와 16 ms로 설정하였으 며, 이는 음성인식 혹은 음성통신 환경에서 16 kHz로 샘플링된 신호를 잡음이나 에코신호 제거와 같은 전처리 알고리즘에서 많이 사용되는 설정 값이다. 모든 심화신경망 모델은 Adam 알고리즘을 이용하여 학습되었으며, 전 처리 부분의 심화신경망들은 mini-batch 크기를 256로 설정하여 30번의 epoch동안 학습되었다. Initial learning rate는 0.0001로 설정하였으며, Dropout은 10%로 설정하였다. 각 인공신경망 모델들에 대한 평가를 위해 평가 데이터셋에 포함된 발화들을 이용하여 각 잡음 별 184개의 발화 에 대한 결과를 분석하였다. 평가를 위해 perceptual evaluation of speech quality(PESQ), short-time objective intelligibility(STOI) 그리고 echo return loss enhancement (ERLE)를 사용하였고 음성과 에코가 동시에 존재하는 구간과 에코만 존재하는 구간을 나누어 점수를 측정하였며, 비교 심화 신경망으로는 본 발명과 관련된 종래 기술 중 심화 신경망을 활용한 전처리 알고리즘인, stacked-DNN, CRN을 적용하였다. PESQ는 -0.5 ~ 4.5 사이의 점수를 가지고, STOI는 0~1 사이의 점수를 가지며, ERLE는 값의 범위가 특정되어 있 지 않고 점수가 높을수록 에코를 잘 제거했다는 것을 의미한다. 먼저 음성 품질을 평가하는 PESQ를 살펴보면 모든 잡음 환경에서 전처리를 적용하지 않은 경우(un-process)에 비교해보면 모든 심화신경망을 활용한 전처리 알고리즘이 음성품질을 향상시키는 것으로 나타내며 그 중 본 발 명에서 제안한 방법이 가장 높은 점수를 보여준다. 다음으로 ERLE를 살펴보면 대부분의 잡음환경에서 에코만 존재하는 구간에서의 에코 제거 성능이 본 발명에서 제안한 방법이 가장 높은 성능을 나타내며, 버스와 자동차 잡음에서는 stacked-DNN 알고리즘이 더 높은 것으로 확인되지만 음성구간에서의 점수와 함께 보면 에코신호는 더욱 잘 제거하지만 음성 왜곡이 다소 발생하는 것을 알 수 있다. 음성 명료도를 평가하는 STOI의 경우도 모든 환경에서 본 발명에서 제안한 방법이 가장 높은 성능을 나타내며 3 가지의 객관적 평가 지표를 종합해보면 거의 모든 잡음 환경에서 종래 기술과 비교하여 크게 점수가 향상된 것 을 확인할 수 있다. 따라서, 본 발명에 의한 잡음 및 에코 통합 제거 학습 기법을 이용하여 배경 잡음과 에코가 존재하는 환경에서 마이크로폰을 통해 음성을 수집하여 음성신호를 처리하는 경우 보다 정확하게 사용자의 음성을 추정하고 추출할 수 있는 장점이 존재한다. 이상과 같이 실시예들은 음성 향상 기술로 음성 인식과 음성 통신 기술을 수행하기 이전에 잡음 및 에코를 제거 하여 보다 우수한 성능을 도출할 수 있으며, 휴대폰 단말기나 보이스톡 등에서 음성 통화 품질을 높이기 위해 적용될 수 도 있다. 또한, 최근 다양한 사물인터넷(Internet of Things, IoT) 기기에서 음성 인식이 수행되는데 이는 조용한 환경에서만 수행되는 것이 아니라 주변 잡음이 존재하는 환경에서 수행될 수 있으며, IoT 기기의 스피커에서 소리가 나올 때 이 소리가 다시 들어가 에코를 발생할 수 있다. 따라서 음성 인식 수행 전 잡음 및 에코를 제거하여 IoT 기기에서 수행되는 음성 인식의 성능을 높일 수 있다. 또한, 본 실시예들은 우수한 품질의 음성 향상 신호를 제공하므로 다양한 음성 통신 기술에 적용되어 깨끗한 품질의 음성을 제공할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세 서, 컨트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨 터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 운영 체제 상에서 수행되는 하나 이상의 소 프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경"}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2020-0138406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범 위에 속한다."}
{"patent_id": "10-2020-0138406", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 에코와 잡음이 존재하는 음성 통신 환경에서 에코 및 잡음 통합 제거 장치로 입력되는 신호들을 도시한 도면이다. 도 2는 본 발명의 실시예에 따른 심화신경망을 이용한 에코 및 잡음 통합 제거 장치의 일부 구성 요소를 도시한 블럭도이다. 도 3은 본 발명의 특징 백터 추출부에 입력되는 입력 정보와 출력되는 출력 정보를 도시한 도면이다. 도 4는 본 발명의 제1인공신경망에 입력되는 입력 정보와 출력되는 출력 정보를 도시한 도면이다. 도 5는 본 발명의 제1에코신호 추정 인공신경망의 학습방법을 설명하기 위한 도면이다. 도 6은 본 발명의 제1잡음심호 추정 인공신경망의 학습방법을 설명하기 위한 도면이다. 도 7은 본 발명의 제2인공신경망에 입력되는 입력 정보와 출력되는 출력 정보를 도시한 도면이다. 도 8은 본 발명의 제2에코신호 추정 인공신경망의 학습방법을 설명하기 위한 도면이다.도 9는 본 발명의 제2잡음심호 추정 인공신경망의 학습방법을 설명하기 위한 도면이다. 도 10은 본 발명의 제3인공신경망과 음성합성부의 입력 정보를 출력 정보를 설명하기 위한 도면이다. 도 11은 본 발명의 실험 데이터에 대한 설정 값으로서, RIR 생성기의 파라미터 설정 값을 도시한 표이다. 도 12와 도 13은 본 발명과 다른 인공신경망 모델의 학습 결과를 비교하여 도시한 도면이다."}
