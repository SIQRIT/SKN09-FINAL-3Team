{"patent_id": "10-2020-0129464", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0046261", "출원번호": "10-2020-0129464", "발명의 명칭": "증강 현실을 디스플레이하는 방법 및 이를 수행하는 전자 장치", "출원인": "삼성전자주식회사", "발명자": "정재욱"}}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 카메라를 이용해서 대상체 (target object)가 포함된 현실 공간 에 대하여 획득한 이미지 상에 서버로부터 수신한 증강 현실 컨텐츠를 디스플레이하는 방법에 있어서,상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보 를 획득하는 단계;상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보를 상기 서버로 전송하는 단계;상기 서버가 상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보에 기초하여 생성한 상기 증강 현실 컨텐츠를 상기 서버로부터 수신하는 단계; 및상기 수신된 증강 현실 컨텐츠를 상기 이미지 상에 디스플레이하는 단계를 포함하고,상기 증강 현실 컨텐츠를 상기 이미지 상에 디스플레이하는 단계는, 상기 이미지로부터 상기 대상체를 식별함으로써, 상기 이미지 내에서의 상기 대상체의 위치에 관한 대상체 위치정보를 식별하는 단계; 상기 증강 현실 컨텐츠로부터 상기 증강 현실 컨텐츠가 상기 전자 장치의 디스플레이에 디스플레이될 위치에 관한 제1 AR 위치 정보를 식별하는 단계;상기 대상체 위치 정보와 상기 제1 AR 위치 정보를 비교함으로써, 제2 AR 위치 정보를 획득하는 단계; 및상기 제2 AR 위치 정보에 기초하여 상기 증강 현실 컨텐츠를 상기 이미지 상에 디스플레이하는 단계를포함하는, 방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 증강 현실 컨텐츠를 상기 이미지 상에 디스플레이하는 단계는, 상기 카메라를 이용하여 획득된 복수의 이미지들의 각각으로부터 상기 대상체를 식별함으로써, 상기 이미지들상에서의 상기 대상체의 이동 속도를 식별하는 단계;상기 대상체의 이동 속도에 따라 식별되는 상기 대상체 위치 정보와 상기 제1 AR 위치 정보를 비교하는 단계;및상기 비교 결과에 기초하여, 상기 제1 AR 위치 정보를 상기 제2 AR 위치 정보로 변경하는 단계를 포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 대상체 위치 정보를 식별하는 단계는, 상기 카메라를 이용하여 획득된 복수의 이미지들의 각각으로부터 상기 대상체를 식별함으로써, 상기 이미지들의각각으로부터 대상체 위치 정보를 누적하여 획득하는 단계;상기 획득된 대상체 위치 정보들과 상기 제1 AR 위치 정보를 비교한 결과에 기초하여, 상기 제1 AR 위치 정보를공개특허 10-2022-0046261-3-상기 제2 AR 위치 정보로 변경하는 단계를 포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 제2 AR 위치 정보를 생성하는 단계는,상기 전자 장치와 상기 서버 사이의 데이터 송수신 지연 시간 에 기초하여, 상기 제1 AR 위치 정보를 상기 제2AR 위치 정보로 변경하는 단계를 포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 대상체 위치 정보를 식별하는 단계는,상기 전자 장치의 움직임을 검출 함으로써, 상기 이미지 상에서 상기 대상체의 이동 방향 및 이동 속도를 검출하는 단계;상기 대상체의 이동 속도에 따라 식별되는 상기 대상체 위치 정보와 상기 제1 AR 위치 정보를 비교하는 단계;및상기 비교 결과에 기초하여, 상기 제1 AR 위치 정보를 상기 제2 AR 위치 정보로 변경하는 단계를 포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 증강 현실 컨텐츠를 상기 이미지 상에 디스플레이하는 단계는, 상기 이미지로부터 적어도 하나의 랜드 마크를 식별 하는 단계;상기 랜드 마크에 기초하여 상기 이미지를 복수의 그리드들로 분할(segment)하는 단계; 상기 복수의 그리드들에 기초하여 , 상기 대상체 위치 정보와 상기 제1 AR 위치 정보를 비교하는 단계; 및상기 비교 결과에 기초하여, 상기 제1 AR 위치 정보를 상기 제2 AR 위치 정보로 변경하는 단계를 포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 대상체 위치 정보와 상기 제1 AR 위치 정보를 비교하는 단계는,상기 복수의 그리드들에 기초하여, 상기 이미지 상에서 상기 대상체의 이동 방향 및 이동 속도를 검출 하는 단계;상기 대상체의 이동 속도에 따라 식별되는 상기 대상체 위치 정보와 상기 제1 AR 위치 정보를 비교하는 단계;및공개특허 10-2022-0046261-4-상기 비교 결과에 기초하여, 상기 제1 AR 위치 정보를 상기 제2 AR 위치 정보로 변경하는 단계를 포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보를 상기 서버로 전송하는 단계는,상기 이미지로부터 상기 대상체를 식별 하는 단계; 및상기 이미지 및 상기 식별된 대상체에 관한 정보를 상기 서버로 전송하는 단계를 포함하고,상기 증강 현실 컨텐츠를 상기 서버로부터 수신하는 단계는,상기 서버로 송신된 상기 대상체에 관한 정보에 기초하여 생성된 증강 현실 컨텐츠를 수신하는 단계를포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 이미지로부터 상기 대상체를 식별하는 단계는,상기 증강 현실 컨텐츠가 획득될 대상체를 특정 하는 사용자 입력을 수신하는 단계; 및상기 사용자 입력에 기초하여 특정된 대상체를 식별하는 단계를 포함하고,상기 증강 현실 컨텐츠를 상기 서버로부터 수신하는 단계는,상기 특정된 대상체에 관한 정보에 기초하여 생성된 증강 현실 컨텐츠를 수신하는 단계를 포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보를 상기 서버로 전송하는 단계는,증강 현실 컨텐츠의 종류 를 선택하는 사용자 입력을 수신하는 단계; 및상기 선택된 증강 현실 컨텐츠의 종류에 관한 정보를 상기 서버로 전송하는 단계;를 포함하고,상기 증강 현실 컨텐츠를 상기 서버로부터 수신하는 단계는,상기 선택된 증강 현실 컨텐츠의 종류에 대응하도록 생성된 증강 현실 컨텐츠를 수신하는 단계를 포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치가 카메라를 이용해서 대상체(target object)가 포함된 현실 공간에 대하여 획득한 이미지상에 디스플레이될 증강 현실 컨텐츠를 서버가 생성하는 방법에 있어서,상기 전자 장치로부터 상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보 를 수신하는 단계;공개특허 10-2022-0046261-5-상기 전자 장치의 위치 정보에 기초하여, 가상의 3차원 공간 내의 상기 전자 장치의 위치를 식별하는 단계 ;상기 전자 장치의 시야 정보에 기초하여, 상기 현실 공간내의 전자 장치의 시야와 상기 가상의 3차원 공간내의전자 장치의 시야를 매칭하는 단계;상기 가상의 3차원 공간내의 상기 전자 장치의 위치 및 상기 가상의 3차원 공간내의 전자 장치의 시야에 기초하여, 상기 대상체에 대응하는 증강 현실 컨텐츠를 생성하는 단계; 및상기 증강 현실 컨텐츠를 상기 전자 장치로 전송하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 증강 현실 컨텐츠를 생성하는 단계는, 상기 현실 공간과 상기 가상의 3차원 공간을 매칭하는 단계;상기 현실 공간 내의 대상체의 제1 위치 정보를 획득하는 단계; 상기 제1 위치 정보에 기초하여 상기 가상의 3차원 공간 내의 대상체의 제2 위치 정보를 획득하는 단계;상기 제2 위치 정보에 기초하여, 상기 증강 현실 컨텐츠가 위치될 제1 AR 위치 정보를 획득하는 단계; 및상기 제1 AR 위치 정보가 포함된 상기 증강 현실 컨텐츠를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 전자 장치의 시야 정보를 수신하는 단계는,상기 전자 장치로부터 상기 이미지를 수신하는 단계를 포함하고,상기 현실 공간내의 전자 장치의 시야와 상기 가상의 3차원 공간내의 전자 장치의 시야를 매칭하는 단계는,상기 이미지로부터 적어도 하나의 랜드 마크를 식별하는 단계;상기 랜드 마크에 기초하여 상기 이미지를 복수의 제1 그리드들로 분할하는 단계;상기 랜드 마크에 기초하여 상기 가상의 3차원 공간을 복수의 제2 그리드들로 분할하는 단계;상기 랜드 마크에 기초하여 상기 제1 그리드들과 상기 제2 그리드들을 매칭하는 단계;상기 제2 그리드들에 기초하여 상기 증강 현실 컨텐츠가 위치될 제1 AR 위치 정보를 획득하는 단계; 및 상기 제1 AR 위치 정보가 포함된 상기 증강 현실 컨텐츠를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 제1 AR 위치 정보를 획득하는 단계는, 상기 현실 공간 내의 대상체의 제1 위치 정보를 획득하는 단계; 상기 제1 위치 정보에 기초하여 상기 가상의 3차원 공간 내의 대상체의 제2 위치 정보를 획득하는 단계; 및공개특허 10-2022-0046261-6-상기 제2 위치 정보에 기초하여, 상기 제2 그리드들 상의 상기 제1 AR 위치 정보를 획득하는 단계를 포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 제1 위치 정보를 획득하는 단계는,상기 이미지로부터 상기 대상체를 식별하는 단계; 및상기 제1 그리드들에 기초하여, 상기 대상체의 제1 위치 정보를 획득하는 단계;를 포함하는,방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서, 상기 전자 장치의 시야 정보를 수신하는 단계는,상기 전자 장치로부터 상기 이미지를 수신하는 단계를 포함하고,상기 증강 현실 컨텐츠를 생성하는 단계는,상기 이미지로부터 상기 대상체를 식별하는 단계;상기 식별된 대상체의 이동 방향 및 이동 속도를 검출하는 단계; 및상기 대상체의 이동 방향 및 이동 속도에 기초하여, 상기 증강 현실 컨텐츠가 위치될 제1 AR 위치 정보를 획득하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서, 상기 증강 현실 컨텐츠를 생성하는 단계는,상기 전자 장치와 상기 서버 사이의 데이터 송수신 지연 시간에 기초 하여, 상기 증강 현실 컨텐츠가 위치될 제1 AR 위치 정보를 획득하는 단계; 및상기 제1 AR 위치 정보가 포함된 상기 증강 현실 컨텐츠를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서, 상기 전자 장치의 시야 정보를 수신하는 단계는,상기 전자 장치로부터 상기 이미지 및 상기 대상체에 관한 정보 를 수신하는 단계를 포함하고,상기 증강 현실 컨텐츠를 생성하는 단계는,상기 수신된 대상체에 관한 정보에 기초하여, 상기 증강 현실 컨텐츠를 생성하는 단계를 포함하는, 공개특허 10-2022-0046261-7-방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 대상체에 관한 정보를 수신하는 단계는,상기 전자 장치로부터 사용자 입력으로 특정된 상기 대상체에 관한 정보 를 수신하는 단계를 포함하고,상기 증강 현실 컨텐츠를 생성하는 단계는,상기 특정된 대상체에 관한 정보에 기초하여, 상기 증강 현실 컨텐츠를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0129464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서, 상기 전자 장치의 시야 정보를 수신하는 단계는,상기 전자 장치로부터 사용자 입력으로 선택된 증강 현실 컨텐츠의 종류에 관한 정보 를 수신하는 단계를 포함하고,상기 증강 현실 컨텐츠를 생성하는 단계는,상기 수신된 증강 현실 컨텐츠의 종류에 대응하는 상기 증강 현실 컨텐츠를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0129464", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "개시된 실시예들은 증강 현실을 디스플레이하는 전자 장치 및 대상체(target object)가 포함된 현실 공간에 대하 여 획득한 이미지 상에 서버로부터 수신한 증강 현실 컨텐츠를 디스플레이하는 방법에 관한 것으로서, 상기 방법 은 상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보를 획득하는 단계, 상기 전자 장치의 위치 정보 (뒷면에 계속)"}
{"patent_id": "10-2020-0129464", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 실시예들은 증강 현실을 디스플레이하는 방법 및 증강 현실을 디스플레이하는 전자 장치에 관한 것이다."}
{"patent_id": "10-2020-0129464", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "증강 현실(AUGMENTED REALITY)은 현실 세계를 기반으로, 가상의 대상 또는 사물을 합성 및 결합함으로써, 부가 적인 정보를 제공하는 가상의 화면을 사용자에게 제공하는 기술을 의미한다. 증강 현실 기술은 원격 의료 진단, 방송, 위치기반 서비스, 모바일 게임, 모바일 솔루션 업계, 교육 분야 등으 로 그 활용범위가 다양하게 확장되고 있다. 사용자 단말기는 직접 증강 현실 컨텐츠를 생성하고 및 렌더링함으로써, 증강 현실을 구현할 수 있다. 하지만, 사용자 단말기의 컴퓨팅 성능의 한계와 증강 현실 컨텐츠를 렌더링할 때 발생되는 전력 소비량으로 인하여, 사 용자 단말기가 증강 현실 컨텐츠를 생성하는데 한계점이 존재하였다. 최근, 네트워크 기술이 발전됨에 따라서, 보다 강력한 컴퓨팅 성능을 보유한 서버가 증강 현실 컨텐츠를 생성하 고 및 렌더링한 데이터를 사용자 단말기가 수신하여 출력하는 클라우드 기반의 증강 현실 기술이 주목받고 있다. 즉, 사용자 단말기는 서버로 전송한 사용자 단말기의 위치 정보 및 방향 정보에 대응하는 증강 현실 컨 텐츠를 서버로부터 수신하여 디스플레이하는 것이다. 하지만, 클라우드 기반의 증강 현실 기술은 사용자 단말기와 서버 사이에 데이터가 송수신됨으로써 발생되는 지 연시간에 의해서, 증강 현실 컨텐츠가 표시될 대상체(target object)가 빠르게 움직이거나, 사용자 단말기가 빠 르게 움직이는 경우에, 대상체의 위치에 맞게 증강 현실 컨텐츠를 표시하지 못하는 문제점이 존재한다. 따라서, 종래의 클라우드 기반의 증강 현실 기술은 자연스럽지 못한 증강 현실 컨텐츠를 사용자에게 제공하는"}
{"patent_id": "10-2020-0129464", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "문제가 발생된다.발명의 내용"}
{"patent_id": "10-2020-0129464", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 일 실시예가 해결하고자 하는 과제는 전술한 문제를 해결하기 위한 것으로서, 사용자 단말기와 서버 사 이에 데이터가 송수신됨으로써 발생되는 지연시간과 무관하게 자연스러운 증강 현실 컨텐츠를 디스플레이하는 전자 장치 및 전자 장치를 이용하여 증강 현실 컨텐츠를 디스플레이하는 방법을 제공할 수 있다. 또한, 개시된 일 실시예는 전자 장치가 지연시간과 무관하게 자연스러운 증강 현실을 제공하도록, 전자 장치로 증강 현실 컨텐츠를 제공하는 서버 및 서버를 이용하여 전자 장치로 증강 현실 컨텐츠를 제공하는 방법을 제공 할 수 있다. 한편, 개시된 실시예들이 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 이 하의 실시예들로부터 또 다른 기술적 과제들이 유추될 수 있다."}
{"patent_id": "10-2020-0129464", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위하여 개시된 실시예의 일 측면인, 전자 장치가 카메라를 이용해서 대상체 (target object)가 포함된 현실 공간 에 대하여 획득한 이미지 상에 서버로부터 수신한 증강 현실 컨텐츠를 디스플레이 하는 방법은, 상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보를 획득하는 단계, 상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보를 상기 서버로 전송하는 단계, 상기 서버가 상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보에 기초하여 생성한 상기 증강 현실 컨텐츠를 상기 서버로부터 수신하는 단 계 및 상기 수신된 증강 현실 컨텐츠를 상기 이미지 상에 디스플레이하는 단계를 포함하고, 상기 증강 현실 컨 텐츠를 상기 이미지 상에 디스플레이하는 단계는, 상기 이미지로부터 상기 대상체를 식별함으로써, 상기 이미지 내에서의 상기 대상체의 위치에 관한 대상체 위치 정보를 식별하는 단계, 상기 증강 현실 컨텐츠로부터 상기 증 강 현실 컨텐츠가 상기 전자 장치의 디스플레이에 디스플레이될 위치에 관한 제1 AR 위치 정보를 식별하는 단계, 상기 대상체 위치 정보와 상기 제1 AR 위치 정보를 비교함으로써, 제2 AR 위치 정보를 획득하는 단계 및 상기 제2 AR 위치 정보에 기초하여 상기 증강 현실 컨텐츠를 상기 이미지 상에 디스플레이하는 단계를 포함할 수 있다. 상술한 과제를 해결하기 위하여 개시된 실시예의 일 측면인 전자 장치가 카메라를 이용해서 대상체(target object)가 포함된 현실 공간에 대하여 획득한 이미지상에 디스플레이될 증강 현실 컨텐츠를 서버가 생성하는 방 법은, 상기 전자 장치로부터 상기 전자 장치의 위치 정보 및 상기 전자 장치의 시야 정보 를 수신하는 단계, 상 기 전자 장치의 위치 정보에 기초하여, 가상의 3차원 공간 내의 상기 전자 장치의 위치를 식별하는 단계, 상기 전자 장치의 시야 정보에 기초하여, 상기 현실 공간내의 전자 장치의 시야와 상기 가상의 3차원 공간내의 전자 장치의 시야를 매칭하는 단계, 상기 가상의 3차원 공간내의 상기 전자 장치의 위치 및 상기 가상의 3차원 공간 내의 전자 장치의 시야에 기초하여, 상기 대상체에 대응하는 증강 현실 컨텐츠를 생성하는 단계 및 상기 증강 현실 컨텐츠를 상기 전자 장치로 전송하는 단계를 포함할 수 있다. 또한, 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 컴퓨터로 읽을 수 있는 기록매체는 개시된 방법 의 실시예들 중 적어도 하나를 컴퓨터에서 실행시키기 위한 프로그램을 기록한 것일 수 있다. 또한, 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 기록매체에 저장된 어플리케이션은 개시된 방법 의 실시예들 중 적어도 하나의 기능을 실행시키기 위한 것일 수 있다."}
{"patent_id": "10-2020-0129464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서는 본 발명의 권리범위를 명확히 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 실시할 수 있도록, 본 발명의 원리를 설명하고, 실시예들을 개시한다. 개시된 실시예들은 다양한 형태 로 구현될 수 있다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 명세서가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2020-0129464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 발명이 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 ‘부’(part, portion)라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실 시예들에 따라 복수의 ‘부’가 하나의 요소(unit, element)로 구현되거나, 하나의 ‘부’가 복수의 요소들을 포함하는 것도 가능하다. 이하 첨부된 도면들을 참고하여 본 발명의 작용 원리 및 실시예들에 대해 설명한다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술 을 채용할 수 있다. “매커니즘”, “요소”, “수단” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 본 명세서에서 사용되는 “제1” 또는 “제2” 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 사용될 수 있다. 이하에서는 도면을 참조하여 실시 예들을 상세히 설명한다. 도 1은 전자 장치가 서버로부터 수신된 증강 현실 컨텐츠를 디스플레이하는 방법의 예시를 설명하는 도면이다. 도 1을 참조하면, 전자 장치는 서버로부터 수신한 데이터를 이용하여 사용자에게 증강 현실 컨텐츠를 제공할 수 있다. 예를 들면, 전자 장치는 대상체가 포함된 현실 공간에 대하여 획득한 이미지 상에 서버로부터 수신한 증강 현실 컨텐츠를 디스플레이할 수 있다. 일 실시예에 따르면, 전자 장치는 서버와 네트워크를 통해서 데이터를 송수신 할 수 있는 모바일 장치 (예를 들면, 스마트폰, 태블릿PC 등), 범용 컴퓨터(PC, Personal Computer)와 같은 연산 장치를 포함할 수 있다. 또한, 전자 장치는 인공지능 모델을 포함하는 모바일 장치(예를 들면, 스마트폰, 태블릿PC 등), 범 용 컴퓨터(PC, Personal Computer) 같은 연산 장치를 포함할 수 있다. 전자 장치는 사용자 입력을 수신할 수 있다. 예를 들면, 전자 장치는 증강 현실 컨텐츠의 종류를 선택하는 사용자 입력을 수신할 수 있다. 다른 예를 들면, 전자 장치는 대상체를 특정하는 사용자 입 력을 수신할 수 있다. 대상체는 전자 장치가 사용자에게 제공할 증강 현실 컨텐츠의 목적 대상을 의미한다. 예를 들면, 대상체는 경기 중인 운동 선수와 같이 동적인 대상체, 건물과 같이 고정된 대상체 일 수 있다. 증강 현실 컨텐츠는 사용자가 증강 현실을 체험할 수 있도록 현실 공간을 반영하는 이미지 상에 덧씌워지 는(overlap) 컨텐츠를 의미한다. 예를 들면, 증강 현실 컨텐츠는 경기중인 운동 선수에 관한 정보, 공연 자에 대한 정보, 공연중인 작품에 대한 정보 및 전시 작품에 대한 정보를 포함할 수 있다. 전자 장치는 전자 장치의 위치 정보 및 전자 장치의 시야 정보에 기초하여 증강 현실 컨텐츠 를 디스플레이 할 수 있다. 전자 장치는 현실 공간이 반영된 이미지 상의 대상체에 대응하는 위치에 증강 현실 컨텐츠를 디스플레이 할 수 있다. 전자 장치의 시야 정보는 전자 장치가 증강 현실 컨텐츠를 표시하기 위한 현실 공간을 향하는 전 자 장치의 방향에 관한 정보를 의미한다. 일 실시예에 따르면, 전자 장치의 시야 정보는 전자 장치의 자이로 센서와 같은 위치, 동작 센서 등으 로부터 획득될 수 있다. 일 실시예에 따르면, 전자 장치의 시야 정보는 전자 장치의 카메라에 의해서 획득된 이미지 상의 시야 (Field of View)에 의해서 획득될 수 있다. 일 실시예에 따르면, 전자 장치의 시야 정보는 전자 장치의 카메라에 의해서 획득된 이미지들이 비교됨 으로써, 획득될 수 있다. 전자 장치의 위치 정보는 전자 장치가 위치한 곳을 나타내는 정보를 의미한다. 일 실시예에 따르면, 전자 장치의 위치 정보는 GPS와 같은 전자 장치의 위치 센서에 의해서 획득될 수 있다. 일 실시예에 따르면, 전자 장치의 위치 정보는 비콘을 이용한 측위 기술을 통해서 획득될 수 있다. 일 실시예에 따르면, 전자 장치의 위치 정보는 경기장, 공연장 및 전시장과 같은 구조에 대한 데이터가 기 획득된 공간의 좌석 번호/ QR코드를 전자 장치가 식별함으로써 획득될 수 있다. 전자 장치는 위치 정보 및 시야 정보를 서버로 전송할 수 있다. 전자 장치는 이미지로부터 식별한 대상체에 관한 정보를 서버로 함께 전송할 수 있다. 전자 장치는 사용자가 선택한 증강 현 실 컨텐츠의 종류에 관한 정보를 서버로 함께 전송할 수 있다. 서버는 전자 장치와 데이터를 송수신할 수 있다. 서버는 수신된 데이터를 데이터 베이스에 저장할 수 있다. 또한, 서버는 수신된 데이터에 대해서 다양한 연산을 수행할 수 있다. 예를 들면, 서버는 전자 장치가 획득한 이미지에 포함된 대상체에 관련된 증강 현실 컨텐츠를 생성하고, 전자 장치로 전송할 수 있다. 전자 장치는 서버로부터 수신된, 증강 현실 컨텐츠가 디스플레이될위치 정보(이하, AR 위치 정보)에 기초하여, 증강 현실 컨텐츠를 디스플레이 할 수 있다. 일 실시예에 따르면, 서버는 증강 현실 컨텐츠를 생성하기 위해서, 전자 장치의 위치 정보 및 전 자 장치의 시야 정보를 획득할 수 있다. 예를 들면, 서버는 전자 장치로부터 전자 장치의 위 치 정보 및 시야 정보를 수신할 수 있다. 다른 예를 들면, 서버는 기설정된 장소에 설치된 비콘을 이용하 여 전자 장치의 위치 정보를 획득할 수 있다. 서버는 전자 장치의 위치 정보 및 시야 정보에 기초하여, 전자 장치가 획득한 이미지에 포함 된 대상체에 대한 증강 현실 컨텐츠를 생성할 수 있다. 일 실시예에 따르면, 서버는 전자 장치의 위치 정보 및 시야 정보에 기초하여, 이미지 상에서의 대상체 및 대상체의 위치를 식별할 수 있다. 일 실시예에 따르면, 서버는 전자 장치의 위치 정보 및 시야 정보에 기초하여, 구조에 대한 데이터가 기획득된 현실 공간상에서 전자 장치의 위치 및 전자 장치가 향하는 방향을 식별할 수 있다. 서버(2 0)는 데이터베이스에 저장된 공간의 구조에 대한 데이터에 전자 장치의 위치 정보 및 시야 정보를 적용함으 로써 현실 공간내에서의 전자 장치의 위치 및 전자 장치가 향하는 방향을 정확하게 식별할 수 있다. 서버는 전자 장치의 위치 및 전자 장치가 향하는 방향에 기초하여 이미지 상에서의 대상체 의 위치를 식별할 수 있다. 일 실시예에 따르면, 서버는 가상의 3차원 공간을 생성하고, 전자 장치의 위치 정보 및 시야 정보 에 기초하여 현실 공간과 매칭함으로써, 서버는 현실 공간과 매칭된 가상의 3차원 공간 상에서의 전자 장치의 위치 및 전자 장치가 향하는 방향을 식별할 수 있다. 서버는 전자 장치의 위치 및 전 자 장치가 향하는 방향에 기초하여, 가상의 3차원 공간의 대상체로부터 이미지 상에서의 대 상체의 위치를 식별할 수 있다. 일 실시예에 따르면, 서버는 현실 공간 내에서의 대상체의 위치에 기초하여, 이미지 상에서의 대상체 의 위치를 식별할 수 있다. 예를 들면, 서버는 현실 공간 내에서의 대상체에 부착된 센서를 이용하여 대상체의 위치를 식별함으로써, 가상의 3차원 공간 상에서의 대상체의 위치를 획득하고, 이미지 상에서의 대상체의 위치를 식별할 수 있다. 일 실시예에 따르면, 서버는 식별된 대상체에 대한 정보를 포함하는 증강 현실 컨텐츠를 생성할 수 있 다. 예를 들면, 서버는 경기장 내의 운동 선수를 식별하고, 운동 선수에 대한 정보를 포함하는 증강 현실 컨텐츠를 생성할 수 있다. 다른 예를 들면, 서버는 공연장 내의 공연자 및 무대 위의 소품을 식별하고, 공연자 및 무대 위의 소품에 대한 정보를 포함하는 증강 현실 컨텐츠를 생성할 수 있다. 일 실시예에 따르면, 서버는 전자 장치에 디스플레이 되는 대상체의 위치에 기초하여, 전자 장치 에 디스플레이되는 증강 현실 컨텐츠의 위치를 식별할 수 있다. 예를 들면, 서버는 대상체 의 위치 인근에 증강 현실 컨텐츠가 디스플레이될 수 있도록 AR 위치 정보를 생성할 수 있다. 서버는 증강 현실 컨텐츠를 전자 장치로 전송할 수 있다. 서버는 전자 장치로 AR 위치 정보를 함께 전송할 수 있다. 전자 장치는 서버로부터 수신한 증강 현실 컨텐츠를 현실 공간에 대하여 획득한 이미지 상에 서버로부터 수신한 AR 위치 정보에 기초하여, 증강 현실 컨텐츠를 디스플레이 할 수 있다. 일 실시예에 따르면, 전자 장치는 전자 장치와 서버 사이에 데이터를 송수신할 때의 지연 시간에 의해서 발생되는 증강 현실 컨텐츠의 위치의 오차를 고려하여, 증강 현실 컨텐츠를 디스플레이 할 수 있다. 일 실시예에 따르면, 전자 장치는 이미지내에서 식별한 대상체의 위치 정보와 AR 위치 정보를 비 교한 결과에 기초하여, 증강 현실 컨텐츠가 디스플레이될 위치를 식별할 수 있다. 예를 들면, 전자 장치는 대상체가 포함된 복수의 이미지들을 획득하고, 복수의 이미지들의 각각으로부터 대 상체를 식별함으로써, 이미지상에서의 대상체의 위치 정보를 누적하여 획득할 수 있다. 전자 장치는 대상체의 위치 정보들과 AR 위치 정보를 비교한 결과에 기초하여, 증강 현실 컨텐츠가 디스플레이될 위치 를 식별할 수 있다. 다른 예를 들면, 전자 장치는, 복수의 이미지들의 각각으로부터 대상체를 식별함으로써, 복수의 이미지들 상에서의 대상체의 이동 속도 및 이동 방향을 식별하고, 대상체의 이동 속도 및 이동 방향에 따라서 식별되는 대상체의 위치 정보와 AR 위치 정보를 비교함으로써, 증강 현실 컨텐츠가 디스플레이될 위치를 식별할 수 있다. 다른 예를 들면, 전자 장치는 전자 장치와 서버 사이에 데이터를 송수신하는 동안의 지연 시간을 측정하고, 측정된 지연 시간과 대상체의 이동 속도를 파라미터로 이용하여 연산함으로써, 증강 현실 컨텐츠 가 디스플레이 될 위치를 식별할 수 있다. 전자 장치는 식별 결과를 이용하여 증강 현실 컨텐츠를 이미지 상에 디스플레이 할 수 있다. 한편, 전자 장치 및 서버 중에서 적어도 하나는 대상체를 식별하거나, 증강 현실 컨텐츠를 생성 및 디 스플레이하기 위해서 인공지능 기술을 이용할 수 있다. 예를 들면, 전자 장치는 인공지능 모델에 이미지 를 적용하고, 인공지능 모델로부터 출력되는 결과를 이용하여 이미지로부터 대상체를 식별하거 나, 대상체의 이동 방향 및 이동 속도를 식별할 수 있다. 다른 예를 들면, 서버는 인공지능 모델에 전자 장치로부터 수신된 전자 장치의 위치 정보 및 시야 정보를 인공지능 모델에 적용하고, 인공지능 모델로부터 출력되는 결과를 이용하여 현실 공간과 가상의 3차원 공간을 매칭하고, 가상의 3차원 공간 상에서의 전자 장치의 위치 및 전자 장치가 향하는 방향을 식별할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 일 실시예에 따르면, 인공지능 모델은 서버에 포함될 수 있다. 전자 장치는 전자 장치가 획득한 데 이터들을 서버로 전송할 수 있다. 서버는 전자 장치로부터 수신된 데이터를 인공지능 모델에 적용 하고, 인공지능 모델로부터 출력된 데이터를 전자 장치로 전송할 수 있다. 일 실시예에 따르면, 인공지능 모델은 전자 장치에 포함될 수 있다. 전자 장치는 내부 메모리에 인공 지능 모델을 구성하는 데이터를 저장하고 이용할 수 있다. 예를 들면, 전자 장치는 서버로부터 인공지 능 모델을 구성하는 데이터를 수신함으로써, 인공지능 모델을 내부 메모리에 저장하고 이용할 수 있다. 또한, 전자 장치는 서버로부터 인공지능 모델을 갱신하는 데이터를 수신할 수 있다. 개시된 인공지능 모델은 학습 데이터로서 입력된 복수의 텍스트 데이터 및 이미지 데이터를 소정의 기준에 의해 학습함으로써 생성된 것일 수 있다. 인공지능 모델은 전자 장치로부터 입력된 데이터에 대응하여, 학습된 기능을 수행함으로써 결과 데이터를 생성하고, 결과 데이터를 출력할 수 있다. 개시된 인공지능 모델은 적어도 하나의 기능을 수행하도록 학습된(trained) 복수개의 인공지능 모델을 포함할 수 있다. 도 2는 종래 기술에 따른, 전자 장치가 서버로부터 수신된 증강 현실 컨텐츠를 디스플레이할 때 발생되는 문제 를 설명하는 도면이다. 도 2를 참조하면, 종래 기술에 따른, 전자 장치와 서버 사이에 데이터를 송수신하는 동안 발생되는 지 연 시간 동안에, 이미지 상의 대상체가 우측으로 이동함에 따라서, 대상체의 위치에 맞게 증강 현실 컨텐츠가 디스플레이 되지 못한다. 즉, 증강 현실 컨텐츠는 지연 시간에 의하여 대상체와 거리(d)가 이격된 상태로 디스플레이 된다. 구체적으로, 0ms에는, 현실 공간에서의 대상체의 위치, 서버가 생성한 가상의 3차원 공간(210a) 상에서의 대상체(230a)의 위치와 전자 장치에 디스플레이된 이미지(110a) 내의 대상체(130a)의 위치가 매칭되므로, 전자 장치는 서버로부터 수신한 증강 현실 컨텐츠(270a)를 이용하여, 대상체(130a)의 위치에 맞게 증강 현실 컨텐츠(170a)가 디스플레이 됨을 알 수 있다. 50ms에는, 현실 공간에서의 대상체와 전자 장치에 디스플레이된 이미지(110b) 내의 대상체(130b)가 0ms의 대상체보다 우측으로 이동하였다. 전자 장치는 서버가 생성한 증강 현실 컨텐츠를 수신해서 디스플레이 하므로, 서버로부터 증강 현실 컨텐츠를 새롭게 수신하기 전까지 이전에 수신된 증강 현실 컨텐츠(170a)를 계속 디스플레이 한다. 따라서, 증강 현실 컨텐츠(170a)가 대상체(130b)에 대응하는 위치에 디스플레이 되지 못 한다. 서버는 50ms시의 현실 공간에서의 대상체와 전자 장치에 디스플레이 된 이미지(110b) 내의 대상체 (130b)에 대응되는 위치에 대응하는 증강 현실 컨텐츠(270b)를 가상의 3차원 공간(210a)상에서 생성하여 전자 장치로 전송한다. 하지만, 100ms 및 150ms에는, 현실 공간의 대상체 및 전자 장치에 디스플레이 되는 이미지(110c, 110d) 상 의 대상체(130c, 130d)는 보다 우측으로 이동하였다. 따라서, 전자 장치는 서버로부터 수신된 증강 현 실 컨텐츠(270b)를 이용하여, 대상체(130d)에 대응하는 위치에 증강 현실 컨텐츠(170b)를 디스플레이 하지 못한 다. 따라서, 종래 기술에 따른 증강 현실 컨텐츠는 전자 장치와 서버사이의 데이터를 송수신할 때의 지연 시간에 의해서 대상체에 대응하는 위치에 디스플레이 되지 못하고, 자연스럽지 못한 증강 현실 컨텐츠를 사용자 에게 제공하는 문제가 발생되는 것이다. 그러므로, 전자 장치는 증강 현실 컨텐츠가 디스플레이될 위치를 조정할 필요가 존재한다. 도 3은 일 실시예에 따른, 전자 장치와 서버가 증강 현실 컨텐츠를 생성하여 디스플레이하는 방법의 순서도이다. 도 3의 단계 310을 참조하면, 전자 장치는 서버로 전자 장치의 위치 정보 및 시야 정보를 전송할 수 있다. 예를 들면, 전자 장치는 경기장, 공연장 및 전시장과 같은 현실 공간내에서의 전자 장치의 위치 정보 및 시야 정보를 서버로 전송할 수 있다. 이 때, 전자 장치는 이미지로부터 식별한 대상체에 관한 정보를 서버로 함께 전송할 수 있다. 전자 장치는 사용자가 선택한 증강 현실 컨텐츠의 종류에 관한 정보를 서버로 함께 전송할 수 있다. 전자 장치는 서버와의 데이터를 송수신 할 때 발생되는 지연 시간을 측정할 수 있다. 일 실시예에 따르면, 전자 장치의 위치 정보는 전자 장치가 GPS와 같은 전자 장치의 위치 센서를 이용하여 획득한 것일 수 있다. 전자 장치는 위치 센서를 이용하여, 전자 장치의 움직임을 검출하고, 검출된 움직임에 기초하여 전자 장치의 위치 정보를 갱신할 수 있다. 일 실시예에 따르면, 전자 장치의 위치 정보는 전자 장치가 기설정된 장소에 설치된 QR코드를 식별함으 로써, 획득된 것일 수 있다. 또는, 전자 장치의 위치 정보는 전자 장치가 기설정된 장소에 설치된 비콘 을 이용한 측위 기술을 통해서 획득한 것일 수 있다. 또는, 전자 장치의 위치 정보는 경기장, 공연장, 전 시장과 같은 구조에 대한 데이터가 기 획득된 공간의 좌석 번호를 이용하여 획득된 것일 수 있다. 일 실시예에 따르면, 전자 장치의 시야 정보는 전자 장치가 자이로 센서와 같은 위치, 동작 센서 등으 로부터 획득할 수 있다. 전자 장치는 위치, 동작 센서를 이용하여 전자 장치의 움직임을 검출하고, 검출된 움직임에 기초하여 전자 장치의 시야 정보를 갱신할 수 있다. 일 실시예에 따르면, 전자 장치의 시야 정보는 전자 장치의 카메라에 의해서 획득된 이미지 상의 시야 (Field of View)에 의해서 획득된 것일 수 있다. 예를 들면, 전자 장치의 배면에 위치된 카메라를 이용하 여 획득되는 이미지에 증강 현실 컨텐츠를 표시하는 전자 장치의 시야 정보는 전자 장치의 배면에 직교하는 방향에 관한 정보일 수 있다. 일 실시예에 따르면, 전자 장치의 시야 정보는 전자 장치의 카메라에 의해서 획득된 이미지들을 비교함 으로써 획득된 것일 수 있다. 도 3의 단계 320을 참조하면, 전자 장치는 대상체가 포함된 현실 공간에 대해서 카메라를 이용하여 이미지 를 획득할 수 있다. 예를 들면, 전자 장치는 운동 선수가 포함된 경기장을 촬영한 이미지를 획득할 수 있다. 전자 장치가 사용자에게 증강 현실 컨텐츠를 제공하는 동안에는 전자 장치가 이미지를 계속 획득하므로, 특정 단계에 한정되지 않는다. 도 3의 단계 330을 참조하면, 전자 장치는 이미지로부터 대상체를 식별하고 추적할 수 있다. 예 를 들면, 전자 장치는 경기장을 촬영한 이미지로부터 운동 선수를 식별하고, 운동 선수의 움직임을 추적할 수 있다. 본 단계는, 필수적인 것은 아니므로 생략될 수 있다. 또는, 본 단계는 단계 320과 함께 수행될 수 있으며, 단계 320과 마찬가지로 전자 장치가 사용자에게 증강 현실 컨텐츠를 제공하는 동안에는 계속 수행될 수 있 다. 도 3의 단계 340을 참조하면, 서버는 증강 현실 컨텐츠를 생성할 수 있다. 서버는 전자 장치(1 0)의 위치 정보 및 시야 정보에 기초하여 전자 장치의 위치 및 전자 장치가 향하는 방향을 식별할 수 있다. 서버는 전자 장치의 위치 및 전자 장치가 향하는 방향에 기초하여, 대상체를 식별할 수 있 다. 서버는 식별된 대상체에 관한 증강 현실 컨텐츠를 생성할 수 있다. 예를 들면, 서버는 경기장 내에서의 전자 장치의 위치 정보 및 시야 정보에 기초하여, 전자 장치에 디스플레이되는 이미지로부터 운동 선수를 식별하고, 운동 선수에 대한 증강 현실 컨텐츠를 생성할 수 있다. 일 실시예에 따르면, 서버는 데이터베이스에 저장된 공간의 구조에 대한 데이터에 전자 장치의 위치 정 보 및 시야 정보를 적용함으로써, 현실 공간내에서의 전자 장치의 위치 및 전자 장치가 향하는 방향을 식별할 수 있다. 일 실시예에 따르면, 서버는, 가상의 3차원 공간을 생성하고, 전자 장치의 위치 정보 및 시야 정보에 기초하여 현실 공간과 매칭함으로써, 현실 공간과 매칭된 가상의 3차원 공간 상에서의 전자 장치의 위 치 및 전자 장치가 향하는 방향을 식별할 수 있다. 서버는 식별된 전자 장치의 위치 및 전자 장치가 향하는 방향에 기초하여, 전자 장치에 디스플 레이 되는 이미지에 포함된 대상체를 식별할 수 있다. 일 실시예에 따르면, 서버는 현실 공간내에서의 대상체의 위치를 식별함으로써, 전자 장치에 디스플레 이되는 이미지 상의 대상체를 식별할 수 있다. 예를 들면, 서버는 대상체에 부착된 센서를 이용하여 현실 공간내에서의 대상체의 위치를 식별할 수 있다. 다른 예를 들면, 서버는 현실 공간에 설치된 복수의 카메라를 이용하여 획득된 이미지들로부터 현실 공간내 에서의 대상체의 위치를 식별할 수 있다. 다른 예를 들면, 서버는 복수의 전자 장치들로부터 획득된 이미 지들로부터 현실 공간내에서의 대상체의 위치를 식별할 수 있다. 서버는 현실 공간내에서의 전자 장치의 위치 및 전자 장치가 향하는 방향에 기초하여, 현실 공간에 서의 대상체의 위치로부터 전자 장치의 시야 내에 존재하는 대상체를 식별할 수 있다. 서버는 현실 공간에서의 대상체의 위치로부터 현실 공간과 매칭된 가상의 3차원 공간에서의 대상체의 위치 를 식별할 수 있다. 서버는 가상의 3차원 공간에서의 전자 장치의 위치 및 방향으로부터, 전자 장치 의 시야 내에 존재하는 대상체를 식별할 수 있다. 서버는 식별된 대상체에 대한 증강 현실 컨텐츠를 생성할 수 있다. 예를 들면, 서버는 투수 정보, 타자 정보, 공격수에 관한 정보, 수비수에 관한 정보, 사용자가 선택한 운동 선수의 신체 정보, 운동 선 수의 스탯(stat) 정보, 경기에 관한 정보, 경기장에 관한 정보와 같은 증강 현실 컨텐츠를 생성할 수 있다. 일 실시예에 따르면, 서버는 사용자가 선택한 종류에 맞는 증강 현실 컨텐츠를 생성할 수 있다. 예를 들면, 서버는 사용자가 야구 선수의 스탯(stat)에 관한 정보를 선택한 것에 대응하여, 야구 선수의 타율, 타점과 스탯(stat)을 포함하는 증강 현실 컨텐츠를 생성할 수 있다. 일 실시예에 따르면, 서버는 증강 현실 컨텐츠가 전자 장치에 디스플레이될 위치에 관한 AR 위치 정보를 생성할 수 있다. 예를 들면, 서버는 이미지 내의 대상체의 인근에 관한 AR 위치 정보를 생성할 수 있다. 또는, 서버는 이미지 내의 기설정된 위치(예를 들면, 이미지의 상단 중앙)에 관한 AR 위치 정보를 생성할 수 있다. AR 위치 정보는 증강 현실 컨텐츠에 포함되거나, 별도로 생성될 수 있다. 도 3의 단계 350을 참조하면, 서버는 전자 장치로 증강 현실 컨텐츠에 관한 데이터를 전송할 수 있다. 이 때, 서버는 전자 장치로 증강 현실 컨텐츠의 AR 위치 정보를 함께 전송할 수 있다. 또 한, 서버 및 전자 장치 중에서 적어도 하나는 데이터를 송수신할 때 발생되는 지연 시간을 측정할 수 있다. 도 3의 단계 360을 참조하면, 전자 장치는 대상체의 위치 정보 및 AR 위치 정보를 식별할 수 있다. 일 실시예에 따르면, 전자 장치는 대상체가 포함된 복수의 이미지들을 획득하고, 복수의 이미지들의 각각으 로부터 대상체를 식별함으로써, 이미지상에서의 대상체의 위치 정보를 누적하여 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 복수의 이미지들의 각각으로부터 대상체를 식별함으로써, 복수의 이미지 들 상에서의 대상체의 이동 속도 및 이동 방향을 식별할 수 있다. 전자 장치는 대상체의 이동 속도 및 이동 방향으로부터 대상체의 위치 정보를 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 전자 장치의 움직임을 검출함으로써, 이미지 상에서의 대상체 의 이동 방향 및 이동 속도를 식별할 수 있다. 전자 장치는 대상체의 이동 속도 및 이동 방향으로부터 대상체의 위치 정보를 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 이미지로부터 적어도 하나의 랜드 마크를 식별하고, 랜드 마크에 기 초하여 이미지를 복수의 그리드(grid)로 분할할 수 있다. 랜드 마크(landmark)는 이미지 상의 특징점을 의미한다. 예를 들면, 야구 경기장의 베이스, 마운드, 베이스 라인, 축구 경기장의 라인 및 골대 등이 랜드 마 크에 해당될 수 있다. 전자 장치는 복수의 그리드들을 좌표로 이용함으로써, 이미지상에서 대상체 의 이동 방향 및 이동 속도를 식별할 수 있다. 전자 장치는 대상체의 이동 속도 및 이동 방향으 로부터 대상체의 위치 정보를 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 서버로부터 수신된 AR 위치 정보를 이용하여, 이미지 상에 증강 현실 컨텐츠가 디스플레이 될 위치를 식별할 수 있다. 도 3의 단계 370을 참조하면, 전자 장치는 이미지상에 증강 현실 컨텐츠를 디스플레이 할 수 있 다. 전자 장치는 대상체의 위치 정보 및 서버로부터 수신한 AR 위치 정보를 비교함으로써, 증강 현실 컨텐츠가 디스플레이 될 위치를 식별할 수 있다. 전자 장치는 식별된 대상체의 위치 정보 와 서버로부터 수신된 제1 AR 위치 정보가 다른 경우에, 전자 장치는 최근에 획득된 대상체의 위 치 정보를 제2 AR 위치 정보로 식별할 수 있다. 일 실시예에 따르면, 전자 장치는 복수의 이미지들로부터 누적하여 획득된 대상체의 위치 정보들과 서 버로부터 수신된 제1 AR 위치 정보를 비교함으로써, 증강 현실 컨텐츠가 디스플레이 될 위치를 식별할 수 있다. 예를 들면, AR 위치 정보가 누적하여 획득된 대상체의 위치 정보들에서 과거의 위치 정보와 동일한 경우에, 전자 장치는 최근에 획득된 대상체의 위치 정보를 제2 AR 위치 정보로 식별할 수 있다. 일 실시예에 따르면, 전자 장치는 이미지 상에서의 대상체의 이동 방향 및 이동 속도에 기초하여 식별된 대상체의 위치 정보와 AR 위치 정보를 비교함으로서, 증강 현실 컨텐츠가 디스플레이 될 위치 를 식별할 수 있다. 예를 들면, 전자 장치는 전자 장치의 움직임을 검출함으로써, 이미지 상에서의 대상체의 이 동 방향 및 이동 속도를 식별할 수 있다. 전자 장치는 대상체의 이동 속도 및 이동 방향에 따라서 식별되는대상체의 위치 정보와 AR 위치 정보를 비교함으로써, 증강 현실 컨텐츠가 디스플레이될 위치를 식별할 수 있다. 다른 예를 들면, 전자 장치는 이미지로부터 적어도 하나의 랜드 마크를 식별하고, 랜드 마크에 기초하 여 이미지를 복수의 그리드(grid)로 분할할 수 있다. 전자 장치는 복수의 그리드들에 기초하여 이미 지상에서 대상체의 이동 방향 및 이동 속도를 식별할 수 있다. 전자 장치는 대상체의 이동 속도 및 이동 방향에 따라서 식별되는 대상체의 위치 정보와 AR 위치 정보를 비교함으로써, 증강 현실 컨텐츠가 디 스플레이될 위치를 식별할 수 있다. 일 실시예예 따르면, 전자 장치는 서버와의 데이터를 송수신 하는 동안의 지연 시간과 임계값을 비교하 여, 지연 시간이 임계값을 초과하는 경우에, 전자 장치가 식별한 대상체의 위치 정보를 제2 AR 위치 정보로 식별할 수 있다. 예를 들면, 전자 장치는 대상체의 이동 속도에 기초하여, 서버와의 데이터를 송수신 하는 동안의 지연 시간을 반영한 대상체의 위치 정보를 제2 AR 위치 정보로 식별할 수 있다. 즉, 전자 장치는 서 버와의 데이터를 송수신 하는 동안의 지연 시간과 대상체의 이동 속도를 연산한 결과로부터 식별된 대 상체의 위치 정보와 서버로부터 수신된 제1 AR 위치 정보가 다른 경우에, 연산 결과로 식별된 대상체 의 위치 정보를 제2 AR 위치 정보로 식별할 수 있다. 전자 장치는 제1 AR 위치 정보를 제2 AR 위치 정보로 변경함으로써, 증강 현실 컨텐츠가 디스플레이되 는 위치를 보정할 수 있다. 도 4는 일 실시예에 따른, 전자 장치가 서버로부터 수신된 증강 현실 컨텐츠를 디스플레이하는 방법을 설명하는 도면이다. 도 4를 참조하면, 일 실시예에 따른, 전자 장치는 서버와의 데이터를 송수신하는 동안 발생되는 지연 시간 동안에 우측으로 이동하는 대상체의 위치에 맞게 증강 현실 컨텐츠를 디스플레이할 수 있다. 구체적으로, 0ms에는, 현실 공간에서의 대상체의 위치, 서버가 생성한 가상의 3차원 공간(210a) 상에서의 대상체(230a)의 위치 및 전자 장치에 디스플레이된 이미지(111a) 내의 대상체의 위치가 매칭되므로, 전자 장치는 서버로부터 수신한 증강 현실 컨텐츠(270a)를 이용하여, 대상체(130a)의 위치에 맞게 증강 현실 컨텐츠(171a)가 디스플레이 됨을 알 수 있다. 50ms에는, 현실 공간에서의 대상체와 전자 장치에 디스플레이된 이미지(111b) 내의 대상체(130b)가 0ms의 대상체보다 우측으로 이동하였다. 전자 장치는 서버로부터 추가로 수신된 증강 현실 컨텐츠가 없는 경우에 도, 대상체(130b)를 식별 및 추적함으로써, 대상체(130b)의 인근에 증강 현실 컨텐츠(171b)를 디스플레이 할 수 있다. 서버는 50ms시의 현실 공간에서의 대상체와 전자 장치에 디스플레이 된 이미지(111b) 내의 대상체 (130b)에 대응되는 위치에 대응하는 증강 현실 컨텐츠(270b)를 생성하여 전자 장치로 전송한다. 또한, 100ms에도, 전자 장치는 이동 중인 대상체(130c)를 식별 및 추적하여, 전자 장치에 디스플레이 된 이미지(111c) 내의 대상체(130c)의 인근에 증강 현실 컨텐츠(171c)를 디스플레이 할 수 있다. 100ms 및 150ms에는, 현실 공간의 대상체 및 전자 장치에 디스플레이 되는 이미지(111c, 111d) 상의 대상체 (130c, 130d)는 보다 우측으로 이동하였기 때문에, 전자 장치가 식별 및 추적한 대상체(130d)의 위치 정보 와 서버로부터 수신된 증강 현실 컨텐츠(270b)의 제1 AR 위치 정보가 동일하지 않다. 150ms에는, 전자 장치는 대상체(130d)의 위치 정보와 서버로부터 수신된 증강 현실 컨텐츠(270b)의 제1 AR 위치 정보가 동일하지 않음을 식별할 수 있다. 전자 장치는 대상체(130d)의 위치 정보를 제2 AR 위치 정보로 식별하고, 제1 AR 위치 정보를 제2 AR 위치 정보로 변경할 수 있다. 전자 장치는 제2 AR 위치 정보 에 기초하여 이미지(111d)상의 대상체(130d)의 인근에 증강 현실 컨텐츠(171d)를 디스플레이 할 수 있다. 도 2와 도 4를 참조하면, 도 4의 일 실시예에 따른 전자 장치가 증강 현실 컨텐츠를 디스플레이하는 방법은 도 2의 종래 기술에 따른 전자 장치가 증강 현실 컨텐츠를 디스플레이하는 방법에 비해서 사용자에게 자 연스러운 증강 현실 컨텐츠를 제공할 수 있다. 도 5는 일 실시예에 따른, 전자 장치가 서버로부터 수신된 증강 현실 컨텐츠를 디스플레이하는 방법의 순서도이 고, 도 6은 일 실시예에 따른, 전자 장치가 획득한 이미지와 서버의 가상의 3차원 공간을 매칭하는 방법의 예시를 설명하는 도면이고, 도 7은 일 실시예에 따른, 서버가 카메라를 이용하여 획득한 대상체의 위치를 식별하고 매칭하는 방법의 예시를 설명하는 도면이다. 일 실시예에 따르면, 랜드 마크 및 그리드를 통해서 이미지와 가상의 3차원 공간이 매칭될 수 있다. 도 5의 단계 511 및 도 6을 참조하면, 전자 장치는 대상체가 포함된 현실 공간에 대해서 카메라를 이용하여 이미지를 획득할 수 있다. 예를 들면, 전자 장치는 야구 선수가 포함된 야구 경기장을 촬영함으로써 이미지를 획득할 수 있다. 도 5의 단계 511은 도 3의 단계320를 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 5의 단계 513 및 도 6을 참조하면, 전자 장치는 이미지로부터 제1 랜드 마크를 식별할 수 있 다. 예를 들면, 전자 장치는 이미지로부터 야구 경기장의 베이스들을 제1 랜드 마크로서 식별할 수 있다. 일 실시예에 따르면, 전자 장치는 인공지능 신경망에 이미지를 적용함으로써, 이미지로부터 제1 랜드 마크를 식별할 수 있다. 인공지능 신경망은 이미지로부터 특징점을 획득하고, 특징점에 기초하 여 제1 랜드 마크를 식별한 결과를 전자 장치로 출력하도록 학습된 모델을 포함할 수 있다. 도 5의 단계 515 및 도 6을 참조하면, 전자 장치는 이미지를 제1 그리드로 분할할 수 있다. 전 자 장치는 제1 랜드 마크를 기준으로, 이미지를 복수의 영역으로 분할하는 제1 그리드를 설 정할 수 있다. 예를 들면, 전자 장치는 이미지내의 베이스들 사이의 영역을 소정의 비율로 분할하는 제1 그리드를 설정할 수 있다. 전자 장치는 제1 그리드를 좌표로 설정할 수 있다. 도 5의 단계 517 및 도 6을 참조하면, 전자 장치는 제1 그리드가 설정된 이미지를 서버로 전 송할 수 있다. 예를 들면, 전자 장치는 제1 그리드가 표시된 이미지를 서버로 전송할 수 있다. 다른 예를 들면, 전자 장치는 이미지와 함께 제1 그리드를 서버로 전송할 수 있다. 이 경우, 제1 그 리드는 좌표가 설정된 것일 수 있다. 도 5의 단계 531 및 도 6을 참조하면, 서버는 가상의 3차원 공간의 구조에 대한 데이터를 획득할 수 있다. 예를 들면, 서버는 경기장, 공연장 및 전시장과 같은 공간의 구조에 대한 데이터가 저장된 DB로 부터 획득할 수 있다. 도 5의 단계 533 및 도 6을 참조하면, 서버는 가상의 3차원 공간을 제2 그리드로 분할할 수 있다. 일 실시예에 따르면, 서버는 가상의 3차원 공간으로부터 제2 랜드 마크를 식별하고, 제2 랜드 마 크에 기초하여 제2 그리드를 설정할 수 있다. 예를 들면, 서버는 DB에 저장된 가상의 3차원 공간으로부터 제2 랜드 마크를 식별할 수 있다. 구체적으로, 서버는 DB에 저장된 야구 경기장의 구조에 대한 데이터로부터 야구 경기장의 베이 스들을 제2 랜드 마크로 식별할 수 있다. 이 경우, 제2 랜드 마크는 구조에 대한 데이터에 미리 설정 된 것일 수 있다. 도 7을 참조하여 다른 예를 들면, 서버는 현실 공간을 촬영하는 카메라로부터 획득된 이미지로부터 제2 랜드 마크를 식별할 수 있다. 구체적으로, 서버는 인공지능 신경망에 랜드마크가 포함된 이 미지를 적용함으로써, 이미지로부터 제2 랜드 마크를 식별할 수 있다. 인공지능 신경망은 이미지 로부터 특징점을 획득하고, 특징점에 기초하여 제2 랜드 마크를 식별한 결과를 서버로 출력하도록 학습된 모델을 포함할 수 있다. 또한, 서버는 제2 랜드 마크를 기준으로, 가상의 3차원 공간을 복수의 영역으로 분할하는 제2 그 리드를 식별할 수 있다. 예를 들면, 서버는 가상의 3차원 공간내의 베이스들 사이의 영역을 소 정의 비율로 분할하는 제2 그리드를 식별할 수 있다. 이 경우, 제2 그리드는 구조에 대한 데이터에 미리 설정된 것일 수 있다. 또는, 제2 그리드는 서버가 제2 랜드 마크를 기준으로 가상의 3차원 공간상에 설정한 것일 수 있다. 한편, 제2 그리드는 좌표가 설정된 것일 수 있다. 도 5의 단계 551과 도 6을 참조하면, 서버는 제1 그리드와 제2 그리드를 매칭할 수 있다. 서버 는 제1 그리드와 제2 그리드를 매칭함으로써, 이미지와 가상의 3차원 공간을 매칭할 수 있다. 일 실시예에 따르면, 서버는 제1 랜드 마크 및 제2 랜드 마크를 비교함으로써, 제1 그리드 와 제2 그리드를 매칭할 수 있다. 일 실시예에 따르면, 서버는 제1 그리드에 설정된 좌표와 제2 그리드에 설정된 좌표를 비교함으 로써, 제1 그리드와 제2 그리드를 매칭할 수 있다. 일 실시예에 따르면, 전자 장치의 위치 및 시야 정보에 기초하여, 제1 그리드와 제2 그리드를 매 칭할 수 있다. 예를 들면, 서버는 전자 장치로부터 수신한 전자 장치의 위치 정보를 공간의 구조 에 대한 데이터에 적용함으로써, 현실 공간내에서의 전자 장치의 위치에 대응하는 가상의 3차원 공간 을 식별할 수 있다. 또한, 서버는 전자 장치로부터 수신한 전자 장치의 시야 정보로부터 가상의 3 차원 공간내에서의 전자 장치의 시야를 식별함으로써, 제2 랜드 마크와 이미지로부터 식별 된 제1 랜드 마크를 매칭할 수 있다. 서버는 매칭된 제1 랜드 마크와 제2 랜드 마크에 기 초하여, 제1 그리드와 제2 그리드를 매칭할 수 있다. 도 5의 단계 553를 참조하면, 서버는 증강 현실 컨텐츠를 생성할 수 있다. 예를 들면, 서버는 야구 경 기장 내의 운동 선수를 식별하고, 운동 선수에 대한 정보를 포함하는 증강 현실 컨텐츠를 생성할 수 있다. 구체적으로, 서버는 투수 정보, 타자 정보, 공격수에 관한 정보, 수비수에 관한 정보, 사용자가 선택한 운 동 선수의 신체 정보, 운동 선수의 스탯(stat) 정보, 경기에 관한 정보, 경기장에 관한 정보와 같은 대상체에 관한 정보를 DB로부터 획득하여 증강 현실 컨텐츠를 생성할 수 있다. 일 실시예에 따르면, 서버는 가상의 3차원 공간상에서의 대상체의 위치 정보에 기초하여, 증강 현실 컨텐츠를 생성할 수 있다. 서버는 가상의 3차원 공간 상에서의 대상체의 위치 정보가 포함 된 증강 현실 컨텐츠를 생성할 수 있다. 또는, 서버는 증강 현실 컨텐츠와는 별도로 가상의 3차원 공간 상에서의 대상체의 위치 정보를 포함하는 데이터를 생성할 수 있다. 서버는 현실 공간에서의 대상체의 위치를 식별하여 야구 경기장의 구조에 대한 데이터에 적용함으로써, 가 상의 3차원 공간 상에서의 대상체의 위치 정보를 획득할 수 있다. 예를 들면, 서버는 현실 공간 내에서의 대상체에 부착된 센서를 이용하여 대상체의 위치를 식별함으로써, 가상의 3차원 공간 상에서의 대상체의 위치 정보를 획득할 수 있다. 구체적으로, 서버는 야구 선수에 부착된 센서를 이용하여 야구 경기장 내에서의 야구 선수의 위치 정보를 획득할 수 있다. 도 7을 참조하여 다른 예를 들면, 서버는 현실 공간을 촬영하는 카메라로부터 획득된 이미지들로부 터 대상체의 위치를 식별함으로써, 가상의 3차원 공간 상에서의 대상체의 위치 정보를 획득할 수 있 다. 구체적으로, 서버는 기설정된 위치에서 야구 경기장을 촬영하는 카메라들로부터 획득된 이미지들로부 터 야구 경기장 내에서의 야구 선수의 위치 정보를 획득할 수 있다. 이 경우, 이미지들은 서버로 위치 정 보 및 시야 정보가 전송한 전자 장치에 포함된 카메라에 의해서 획득된 것일 수 있다. 도 5의 단계 555 및 도 6을 참조하면, 서버는 전자 장치로 증강 현실 컨텐츠를 전송할 수 있다. 일 실시예에 따르면, 서버는 가상의 3차원 공간 상에서의 대상체의 위치 정보가 AR 위치 정보로 서 포함된 증강 현실 컨텐츠를 전자 장치로 전송할 수 있다. 일 실시예에 따르면, 서버는 증강 현실 컨텐츠와는 별도로 생성된, 가상의 3차원 공간 상에서의 대상 체의 위치 정보를 AR 위치 정보로서 포함하는 데이터를 증강 현실 컨텐츠와 함께 전자 장치로 전송할 수 있다. 일 실시예에 따르면, 서버는 도 5의 단계 532에서 생성한 가상의 3차원 공간 내에 포함된 모든 대상체들에 대한 증강 현실 컨텐츠들 중에서, 전자 장치로부터 수신된 전자 장치의 시야 정보에 기초하여, 전자 장 치의 시야에 포함된 대상체에 대한 정보가 포함된 증강 현실 컨텐츠만을 전자 장치로 전송할 수 있다. 도 5의 단계 571을 참조하면, 전자 장치는 이미지로부터 대상체를 식별하고, 추적할 수 있다. 전 자 장치는 대상체를 추적함으로써, 대상체의 위치 정보를 획득하고 갱신할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 그리드를 좌표로 이용하여 이미지에 포함된 대상체의 위치를 식별할 수 있다. 예를 들면, 전자 장치는 제1 그리드를 좌표로 이용하여, 복수의 이미지들 상 에서의 대상체의 위치 정보를 획득하고 갱신함으로써, 대상체의 이동 속도 및 이동 방향을 식별할 수 있다. 전자 장치는 인공지능 신경망에 제1 그리드에 의해서 분할된 복수의 이미지들을 적용함으로써, 인공지능 신경망으로부터 출력되는 대상체의 위치 정보를 획득하고 갱신함으로써, 대상체의 이동 속도 및 이동 방향을 식별할 수 있다. 일 실시예에 따르면, 전자 장치는 서버로부터 수신되는 대상체의 위치 정보에 기초하여, 이미지 로부터 대상체를 식별할 수 있다. 이 경우, 서버는 제2 그리드에 의해서 분할 된 영역 중 에서 대상체가 위치한 영역을 식별하고, 제2 그리드를 좌표로 이용하여 대상체의 위치 정보를 전자 장치로 전송할 수 있다. 도 5의 단계 573을 참조하면, 전자 장치는 대상체의 위치 정보와 AR 위치 정보를 식별할 수 있다. 전 자 장치는 이미지로부터 획득한 대상체의 위치 정보와 서버로부터 수신한 AR 위치 정보를 비교함 으로써, 증강 현실 컨텐츠가 디스플레이 될 위치를 식별할 수 있다. 일 실시예에 따르면, 전자 장치는 좌표로 설정된 제1 그리드를 이용하여 획득된 대상체의 위치 정보와 서버가 제2 그리드를 좌표로 이용하여 전송한 AR 위치 정보를 비교함으로써, 증강 현실 컨텐츠 가 디스플레이 될 위치를 식별할 수 있다. 제1 그리드 및 제2 그리드는 단계 551에서 매칭된 것일 수 있다. 도 5의 단계 575를 참조하면, 전자 장치는 식별된 위치 상에 증강 현실 컨텐츠를 디스플레이 할 수 있 다. 도 5의 단계 573 및 단계 575는 도 3의 단계 360 및 370를 참조하여 기술된 실시예들이 유추 적용될 수 있으므 로, 중복되는 내용은 생략한다. 도 5 내지 도 7의 실시예가 전자 장치 및 서버에 적용됨으로써, 전자 장치와 서버는 대상체 (130, 230)의 위치 정보를 용이하게 획득하고, 대상체(130, 230)를 용이하게 추적할 수 있다. 또한, 전자 장치 는 대상체에 대응하는 위치에 증강 현실 컨텐츠를 디스플레이 할 수 있다. 도 8은 일 실시예에 따른, 전자 장치가 사용자 입력에 기초하여 서버로부터 수신된 증강 현실 컨텐츠를 디스플 레이하는 방법의 순서도이고, 도 9는 일 실시예에 따른, 전자 장치가 사용자 입력에 기초하여 서버로부터 수신 된 증강 현실 컨텐츠를 디스플레이하는 방법의 예시를 설명하는 도면이다. 도 8의 단계 811 및 도 9를 참조하면, 전자 장치는 대상체가 포함된 현실 공간에 대해서 카메라를 이용하여 이미지를 획득할 수 있다. 예를 들면, 전자 장치는 야구 선수가 포함된 야구 경기장을 촬영함으로써 이미지를 획득할 수 있다. 도 8의 단계 811은 도 3의 단계 320, 도 5의 단계 511과 유사하므로, 중복되는 내용은 생략한다. 도 8의 단계 812를 참조하면, 전자 장치는 이미지로부터 대상체를 식별하고, 추적할 수 있다. 전 자 장치는 대상체를 추적함으로써, 대상체의 위치 정보를 획득하고 갱신할 수 있다. 일 실시예에 따르면, 전자 장치는 인공지능 신경망으로 이미지를 적용함으로써, 이미지로부터 적 어도 하나의 대상체를 식별하고 추적할 수 있다. 인공지능 신경망은 이미지로부터 특징점을 획득하 고, 특징점에 기초하여 적어도 하나의 대상체를 식별한 결과를 전자 장치로 출력하도록 학습된 모델을 포함할 수 있다. 인공지능 신경망은 전자 장치로부터 적용되는 복수의 이미지들 상에서의 대상체의 이동 속도 및 이동 방향을 식별한 결과를 전자 장치로 출력하도록 학습된 모델을 포함할 수 있다. 인공지능 신경 망에 포함된 모델은 전자 장치가 서버로부터 수신한 모델일 수 있다. 일 실시예에 따르면, 전자 장치는 이미지로부터 식별된 제1 랜드 마크에 기초하여, 적어도 하나 의 대상체를 식별하고 추적할 수 있다. 예를 들면, 전자 장치는 야구 베이스들의 인근에 위치한 야구 선수들을 식별하고 움직임을 추적할 수 있다. 일 실시예에 따르면, 전자 장치는 이미지를 분할하는 제1 그리드를 이용하여, 이미지로부터 적어도 하나의 대상체를 식별하고 추적할 수 있다. 예를 들면, 전자 장치는 야구 베이스와 함께 제1 그리드에 의해서 분할된 영역에 포함된 야구 선수를 식별할 수 있다. 다른 예를 들면, 전자 장치는 야 구 베이스에 대응하는 제1 그리드에 설정된 좌표를 식별하고, 식별된 좌표 인근의 야구 선수를 식별할 수 있다. 전자 장치는 제1 그리드에 설정된 좌표를 이용하여, 야구 선수의 이동 속도 및 이동 방향을 식 별함으로써, 야구 선수를 추적할 수 있다. 도 8의 단계 813 및 도 9를 참조하면, 전자 장치는 사용자로부터 대상체를 선택하는 입력을 수신할 수 있다. 예를 들면, 전자 장치는 터치스크린을 통해서 마운드 위의 투수를 선택하는 사용자의 입력을 수신할수 있다. 도 8의 단계 814 및 도 9를 참조하면, 전자 장치는 사용자가 선택한 대상체를 확대한 이미지를 획득할 수 있다. 전자 장치는 사용자 입력에 대응하는 디스플레이의 좌표에 기초하여, 사용자가 선택한 대상체 를 확대한 이미지를 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 전자 장치의 망원렌즈를 이용하여는 카메라로 대상체를 촬영함으로써, 대상체를 확대한 이미지를 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 고해상도 카메라로 대상체를 촬영하고, 획득된 이미지를 크롭함으로써, 대상체를 확대한 이미지를 획득할 수 있다. 도 8의 단계 815 및 도 9를 참조하면, 전자 장치는 확대 이미지로부터 대상체에 대한 정보를 획득함으 로써, 대상체를 식별할 수 있는지 여부를 판단할 수 있다. 예를 들면, 전자 장치는 투수를 확대하여 촬영한 이미지로부터 투수의 등번호를 식별함으로써, 식별된 등번 호에 대응하는 선수 정보를 획득할 수 있는지 여부를 판단할 수 있다. 전자 장치는 등번호가 가려진 이미 지를 획득하거나, 저해상도 이미지를 획득하거나, 카메라가 흔들림으로 인해서 선명하지 않은 이미지를 획득함 으로써, 등번호를 식별할 수 없는 경우에는 대상체를 식별할 수 없다고 판단할 수 있다. 전자 장치는 식별된 등번호에 대응하는 선수 정보(예를 들면, 스탯 정보)를 메모리로부터 획득할 수 있다. 또는 전자 장치는 선수 정보를 서버로부터 수신할 수 있다. 다른 예를 들면, 전자 장치는 투수를 확대하여 촬영한 이미지로부터 투수의 얼굴을 식별함으로써, 선수 정 보를 획득할 수 있는지 여부를 판단할 수 있다. 전자 장치는 투수를 확대하여 촬영한 이미지를 인공지능 신경망에 적용함으로써, 촬영된 이미지에 대응하는 선수를 검색한 결과인 인공지능 신경망의 출력에 기초하여 선수 정보를 획득할 수 있는지 여부를 판단할 수 있다. 도 8의 단계 816을 참조하면, 전자 장치는 대상체를 선택하는 사용자의 입력에 관한 정보를 서버 로 전송할 수 있다. 예를 들면, 전자 장치는 사용자가 선택한 야구 선수가 포함된 영역에 관한 좌표를 서버 로 전송할 수 있다. 이 경우, 좌표는 제1 그리드 상에 설정된 것일 수 있다. 다른 예를 들면, 전자 장치는 사용자의 입력에 대응하는 디스플레이의 좌표를 서버로 전송할 수 있다. 도 8의 단계 817을 참조하면, 전자 장치는 단계 815에서 획득된 대상체에 관한 정보에 기초하여, 전자 장치가 식별한 대상체에 관한 정보를 서버로 전송 할 수 있다. 예를 들면, 전자 장치는 단계 815에서 식별된 야구 선수의 등번호를 서버로 전송할 수 있다. 다른 예를 들면, 전자 장치는 야구 선 수의 등번호에 기초하여 획득된 야구 선수에 대한 정보(예를 들면, 이름, 신체 정보, 스탯 정보 등)를 서버(2 0)로 전송할 수 있다. 도 8의 단계 821 및 도 9를 참조하면, 서버는 사용자가 선택한 대상체에 관한 증강 현실 컨텐츠를 생 성할 수 있다. 일 실시예에 따르면, 서버는 단계 816에서 전자 장치로부터 수신된 사용자의 입력에 관한 정보에 기초 하여 대상체를 식별하고, 대상체에 관한 증강 현실 컨텐츠를 생성할 수 있다. 예를 들면, 서버 는 제1 그리드 상에 설정된 좌표를 제2 그리드 상에 설정된 좌표와 비교함으로써, 제2 그리드 상에서의 야구 선수들로부터 사용자가 선택한 투수를 식별할 수 있다. 다른 예를 들면, 서버는 전자 장치 의 시야 정보와 매칭된 가상의 3차원 공간으로부터, 전자 장치의 디스플레이의 좌표에 대응하는 투수를 식별할 수 있다. 서버는 투수의 이름, 신체 정보, 스탯 정보 등을 이용하여 증강 현실 컨텐츠(17 0)를 생성할 수 있다. 일 실시예에 따르면, 서버는 단계 817에서 전자 장치가 획득한 대상체에 관한 정보를 이용하여 증 강 현실 컨텐츠를 생성할 수 있다. 예를 들면, 서버는 전자 장치가 식별한 투수의 등번호를 이용 하여 DB에 저장된 투수에 대한 정보(예를 들면, 이름, 신체 정보, 스탯 정보 등)를 획득하고, 획득된 정보 를 이용하여 증강 현실 컨텐츠를 생성할 수 있다. 다른 예를 들면, 서버는 전자 장치로부터 수신 한 투수에 대한 정보(예를 들면, 이름, 신체 정보, 스탯 정보 등)를 이용하여 증강 현실 컨텐츠를 생성할 수 있다. 도 8의 단계 821는 도 5의 단계 553을 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 8의 단계 823 및 도 9를 참조하면, 서버는 생성한 증강 현실 컨텐츠를 전자 장치로 전송할 수 있다. 도 8의 단계 823은 도 5의 단계 555를 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 8의 단계 831을 참조하면, 전자 장치는 대상체를 추적하여 획득한 대상체의 위치 정보와 서버 로부터 수신한 AR 위치 정보를 식별할 수 있다. 도 8의 단계 831은 도 5의 단계 571 및 단계 573를 참조하 여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 8의 단계 833 및 도 9를 참조하면, 전자 장치는 서버로부터 수신한 증강 현실 컨텐츠를 대상체(13 1)의 위치에 맞게 디스플레이 할 수 있다. 도 8의 단계 833은 도 5의 단계 573 및 단계 575를 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 8 및 도 9의 실시예가 전자 장치 및 서버에 적용됨으로써, 전자 장치와 서버는 사용자가 선 택하는 대상체에 관한 증강 현실 컨텐츠를 사용자에게 제공할 수 있다. 도 10은 일 실시예에 따른, 전자 장치가 사용자 입력에 기초하여 서버로부터 수신된 증강 현실 컨텐츠를 디스플 레이하는 방법의 순서도이다. 도 10의 단계 1011을 참조하면, 전자 장치는 대상체가 포함된 현실 공간에 대해서 카메라를 이용하여 이미 지를 획득할 수 있다. 도 10의 단계 1011은 도 3의 단계 320을 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 10의 단계 1013을 참조하면, 전자 장치는 이미지로부터 대상체를 식별하고 추적할 수 있다. 도 10 의 단계 1013은 도 8의 단계 812를 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생 략한다. 도 10의 단계 1015를 참조하면, 전자 장치는 증강 현실 컨텐츠를 선택하는 사용자 입력을 수신할 수 있다. 전자 장치는 사용자가 증강 현실 컨텐츠를 선택하는 입력을 수신하기 위한 인터페이스를 제공할 수 있다. 예를 들면, 전자 장치는 증강 현실 컨텐츠의 종류, 증강 현실 컨텐츠의 대상을 선택하기 위한 그 래픽 유저 인터페이스(GUI)를 디스플레이 할 수 있다. 전자 장치는 제공하는 증강 현실 컨텐츠의 종류, 증강 현실 컨텐츠의 대상을 프리셋으로 제공함으로써, 사용자가 원하는 증강 현실 컨텐츠를 빠 르게 선택할 수 있는 인터페이스를 제공할 수 있다. 구체적으로, 전자 장치는 야구 선수 정보, 진행중인 경기에 관한 정보, 경기장에 관한 정보와 같은 증강 현실 컨텐츠의 종류를 선택하는 사용자 입력을 수신할 수 있다. 전자 장치는 홈 팀에 관한 정보, 원 정 팀에 관한 정보, 공격수들에 관한 정보, 수비수들에 관한 정보, 투수에 관한 정보, 타자에 관한 정보와 같이 증강 현실 컨텐츠의 대상을 선택하는 사용자 입력을 수신할 수 있다. 도 10의 단계 1017을 참조하면, 전자 장치는 수신된 사용자 입력에 관한 정보를 서버로 전송할 수 있다. 예를 들면, 전자 장치는 사용자가 선택한 증강 현실 컨텐츠의 종류, 증강 현실 컨텐츠의 대상에 관한 정보를 서버로 전송할 수 있다. 구체적으로, 전자 장치는 사용자가 선택한 야구 선수 정 보, 진행중인 경기에 관한 정보, 경기장에 관한 정보와 같은 증강 현실 컨텐츠의 종류에 관한 정보를 서버 로 전송할 수 있다. 전자 장치는 사용자가 선택한 홈 팀에 관한 정보, 원정 팀에 관한 정보, 공격수들 에 관한 정보, 수비수들에 관한 정보, 투수에 관한 정보, 타자에 관한 정보와 같은 증강 현실 컨텐츠의 대 상에 관한 정보를 서버로 전송할 수 있다. 도 10의 단계 1021을 참조하면, 서버는 전자 장치로부터 수신된 사용자 입력에 관한 정보에 기초하여 증강 현실 컨텐츠를 생성할 수 있다. 예를 들면, 서버는 사용자가 선택한 증강 현실 컨텐츠의 종류, 증강 현실 컨텐츠의 대상에 관한 정보에 대응하는 증강 현실 컨텐츠를 생성할 수 있다. 구체적으로, 서버는 사용자가 선택한 야구 선수 정보, 진행중인 경기에 관한 정보, 경기장에 관한 정보와 같은 증강 현실 컨텐츠의 종류에 관한 정보에 대응하는 증강 현실 컨텐츠를 생성할 수 있다. 서버는 사용자가 선택한 홈 팀에 관한 정보, 원정 팀에 관한 정보, 공격수들에 관한 정보, 수비수들에 관한 정보, 투수 에 관한 정보, 타자에 관한 정보와 같은 증강 현실 컨텐츠의 대상에 관한 정보에 대응하는 증강 현실 컨텐츠를 생성할 수 있다. 도 10의 단계 1021는 도 5의 단계 553 및 도 8의 단계 821를 참조하여 기술된 실시예들 이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 10의 단계 1023을 참조하면, 서버는 생성된 증강 현실 컨텐츠를 전자 장치로 전송할 수 있다. 도 10의 단계 1023은 도 5의 단계 555 및 도 8의 단계 823을 참조하여 기술된 실시예들이 유추 적용될 수 있으 므로, 중복되는 내용은 생략한다. 도 10의 단계 1031을 참조하면, 전자 장치는 대상체를 추적하여 획득한 대상체의 위치 정보와 서 버로부터 수신한 AR 위치 정보를 식별할 수 있다. 도 10의 단계 1031은 도 5의 단계 571 및 단계 573, 도 8의 단계 831를 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 10의 단계 1033을 참조하면, 전자 장치는 서버로부터 수신한 증강 현실 컨텐츠를 대상체의 위 치에 맞게 디스플레이 할 수 있다. 도 10의 단계 1033은 도 5의 단계 573 및 단계 575, 도 8의 단계 833를 참조 하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 10의 실시예가 전자 장치 및 서버에 적용됨으로써, 전자 장치와 서버는 사용자가 선택한 증 강 현실 컨텐츠를 사용자에게 제공할 수 있다. 도 11은 일 실시예에 따른, 전자 장치가 사용자 입력에 기초하여 서버로부터 수신된 증강 현실 컨텐츠를 디스플 레이하는 방법의 순서도이다. 도 11의 단계 1111을 참조하면, 전자 장치는 대상체가 포함된 현실 공간에 대해서 카메라를 이용하여 이미 지를 획득할 수 있다. 도 11의 단계 1111은 도 3의 단계 320 및 도 10의 단계 1011을 참조하여 기술된 실 시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 11의 단계 1113을 참조하면, 전자 장치는 이미지로부터 대상체를 식별하고 추적할 수 있다. 도 11 의 단계 1113은 도 8의 단계 812 및 도 10의 단계 1013를 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 11의 단계 1121을 참조하면, 서버는 증강 현실 컨텐츠를 생성할 수 있다. 서버는 전자 장치에 서 디스플레이될 수 있는 증강 현실 컨텐츠들을 미리 모두 생성할 수 있다. 예를 들면, 서버는 사용자가 선택할 수 있는 증강 현실 컨텐츠의 종류, 증강 현실 컨텐츠의 대상 에 관한 정보에 대응하는 증강 현실 컨텐츠를 생성할 수 있다. 구체적으로, 서버는 사용자가 선택할 수 있 는 야구 선수 정보, 진행중인 경기에 관한 정보, 경기장에 관한 정보와 같은 증강 현실 컨텐츠의 종류에 관한 정보에 대응하는 증강 현실 컨텐츠를 생성할 수 있다. 서버는 사용자가 선택할 수 있는 홈 팀에 관한 정보, 원정 팀에 관한 정보, 공격수들에 관한 정보, 수비수들에 관한 정보, 투수에 관한 정보, 타자에 관한 정 보와 같은 증강 현실 컨텐츠의 대상에 관한 정보에 대응하는 증강 현실 컨텐츠를 생성할 수 있다. 다른 예를 들면, 서버는 전자 장치의 시야에 포함된 대상체들에 관한 증강 현실 컨텐츠를 생성할 수 있 다. 이 경우, 서버는 전자 장치의 시야와 매칭된 가상의 3차원 공간에 포함된 대상체를 식별하여, 식별된 대상체에 관한 증강 현실 컨텐츠를 생성할 수 있다. 도 11의 단계 1121는 도 5의 단계 553, 도 8의 단계 821 및 도 10의 단계 1021를 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 11의 단계 1123을 참조하면, 서버는 생성된 증강 현실 컨텐츠를 전자 장치로 전송할 수 있다. 도 11의 단계 1123은 도 5의 단계 555, 도 8의 단계 823 및 도 10의 단계 1023을 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 11의 단계 1131을 참조하면, 전자 장치는 대상체를 추적하여 획득한 대상체의 위치 정보와 서버로부터 수신한 AR 위치 정보를 식별할 수 있다. 도 11의 단계 1131은 도 5의 단계 571 및 단계 573, 도 8의 단계 831 및 도 10의 단계 1031를 참조하여 기술된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 11의 단계 1133을 참조하면, 전자 장치는 증강 현실 컨텐츠를 선택하는 사용자 입력을 수신할 수 있다. 전자 장치는 사용자가 증강 현실 컨텐츠를 선택하는 입력을 수신하기 위한 인터페이스를 제공할 수 있다. 예를 들면, 전자 장치는 증강 현실 컨텐츠의 종류, 증강 현실 컨텐츠의 대상을 선택하기 위한 그 래픽 유저 인터페이스(GUI)를 디스플레이 할 수 있다. 전자 장치는 제공하는 증강 현실 컨텐츠의 종류, 증강 현실 컨텐츠의 대상을 프리셋으로 제공함으로써, 사용자가 원하는 증강 현실 컨텐츠를 빠르게 선택할 수 있는 인터페이스를 제공할 수 있다. 도 11의 단계 1133은 도 10의 단계 1015를 참조하여 기술 된 실시예들이 유추 적용될 수 있으므로, 중복되는 내용은 생략한다. 도 11의 단계 1135를 참조하면, 전자 장치는 사용자가 선택한 증강 현실 컨텐츠를 디스플레이 할 수 있다. 전자 장치는 서버로부터 수신한 증강 현실 컨텐츠 중에서 사용자가 선택한 증강 현실 컨텐츠만을 디스 플레이 할 수 있다. 예를 들면, 전자 장치는 서버로부터 전송된 증강 현실 컨텐츠들 중에서 사용자가 선택한 증강 현실 컨 텐츠의 종류를 디스플레이 할 수 있다. 구체적으로, 전자 장치는 서버로부터 수신된 야구 선수 정보, 진행중인 경기에 관한 정보, 경기장에 관한 정보와 같은 증강 현실 컨텐츠의 종류, 홈 팀에 관한 정 보, 원정 팀에 관한 정보, 공격수들에 관한 정보, 수비수들에 관한 정보, 투수에 관한 정보, 타자에 관한 정보 와 같은 증강 현실 컨텐츠의 대상에 관한 정보 중에서, 사용자가 선택한 투수에 관한 정보에 대응하는 증 강 현실 컨텐츠를 디스플레이 할 수 있다. 도 11의 실시예가 전자 장치 및 서버에 적용됨으로써, 전자 장치와 서버는 사용자의 입력에 즉 각적으로 반응하여 증강 현실 컨텐츠를 제공할 수 있다. 도 12는 일 실시예에 따른, 전자 장치의 블록도이다. 도 12를 참조하면, 전자 장치는, 사용자 입력부, 출력부, 프로세서, 통신부 및 메모리(1 7)를 포함할 수 있다. 그러나, 도 12에 도시된 구성 요소 모두가 전자 장치의 필수 구성 요소인 것은 아니 다. 도 12에 도시된 구성 요소보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 도 12에 도시된 구성 요소보다 적은 구성 요소에 의해 전자 장치가 구현될 수도 있다. 사용자 입력부는, 사용자가 전자 장치를 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들 어, 사용자 입력부에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압 력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 터치스크린, 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 사용자 입력부는 도 1 내지 도 11을 참조하여 설명한 실시예들을 전자 장치가 수행하기 위해 필요한 사 용자 입력을 수신할 수 있다. 출력부는 전자 장치에서 처리되는 정보를 출력한다. 출력부는 도 1 내지 도 11을 참조하여 설명한 실시예들에 관련된 정보를 출력할 수 있다. 출력부는 이미지 및 증강 현실 컨텐츠를 디스플레이 하는 디스플레이부(12-1)를 포함할 수 있다. 프로세서는, 통상적으로 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메모리 에 저장된 적어도 하나의 인스트럭션을 실행함으로써, 사용자에게 증강 현실 컨텐츠를 제공하기 위하여 사 용자 입력부, 출력부, 통신부, 메모리 등을 전반적으로 제어할 수 있다. 예를 들면, 프로세서는 이미지 획득 모듈(17a)에 저장된 인스트럭션을 실행함으로써, 카메라가 대상체가 포 함된 현실 공간에 대해서 이미지를 획득할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 다른 예를 들면, 프로세서는 대상체 식별 모듈(17b) 에 저장된 인스트럭션을 실행함으로써, 이미지로 부터 대상체를 식별하고 추적할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 다른 예를 들면, 프로세서는 AR 위치 정보 획득 모듈(17c) 에 저장된 인스트럭션을 실행함으로써, 대상체 의 위치 정보 및 AR 위치 정보를 식별할 수 있다. 또한, 프로세서는 서버로부터 수신된 AR 위치 정보를 이용하여, 이미지 상에 증강 현실 컨텐츠가 디스플레이 될 위치를 식별할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 다른 예를 들면, 프로세서는 증강 현실 컨텐츠 출력 모듈(17d) 에 저장된 인스트럭션을 실행함으로써, 증강 현실 컨텐츠를 디스플레이하도록 디스플레이부(12-1)를 제어할 수 있다. 프로세서는 서버로부터 수신된 AR 위치 정보를 이용하여, 이미지 상에 증강 현실 컨텐츠가 디스플레이 될 위치를 식별할 수 있다. 프로세서는 대상체의 위치 정보 및 서버로부터 수신한 AR 위치 정보를 비교함으로써, 증강 현실 컨텐츠가 디스플레이 될 위치를 식별할 수 있다. 프로세서는 식별된 위치에 증강 현실 컨텐츠를 디스플레이하도록 디스플레이부(12-1)를 제어 할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 프로세서는 범용적으로 이용되는 적어도 하나의 프로세서일 수 있다. 또한, 프로세서는 인공지능 모델 의 기능을 수행하기 위해서 제작된 적어도 하나의 프로세서를 포함할 수 있다. 프로세서는 인공지능 모델이 새로운 학습 데이터를 학습하도록 일련의 인스트럭션를 실행할 수 있다. 프로세서는 메모리에 저장된 소프트웨어 모듈을 실행함으로써, 도 1 내지 도 11을 참조하여 위에서 설명한 인공지능 모델의 기능을 수행할 수 있다. 통신부는, 전자 장치가 다른 장치(미도시) 및 서버와 통신을 하게 하는 하나 이상의 구성요소를 포 함할 수 있다. 다른 장치(미도시)는 전자 장치와 같은 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 메모리는, 프로세서의 처리 및 제어를 위한 적어도 하나의 인스트럭션 및 적어도 하나의 프로그램을 저 장할 수 있고, 전자 장치로 입력되거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 메모리는 램(RAM, Random Access Memory) SRAM(Static Random Access Memory)과 같이 일시적으로 데이터를 저장하는 메모리 및 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 롬 (ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크과 같이 비일시적으로 데이터를 저 장하는 데이터 스토리지 중에서 적어도 하나의 타입의 저장매체를 포함할 수 있다. 도 13은 일 실시예에 따른, 전자 장치에 포함된 메모리의 소프트웨어 모듈을 나타내는 블록도이다. 도 13을 참조하면, 메모리는 도 1 내지 도 11를 참조하여 위에서 설명한 실시예를 전자 장치가 수행하 기 위한 인스터럭션이 포함된 소프트웨어 모듈로서, 이미지 획득 모듈(17a), 대상체 식별 모듈(17b), AR 위치 정보 획득 모듈(17c) 및 증강 현실 컨텐츠 출력 모듈(17d)을 포함할 수 있다. 그러나, 도 13에 도시된 소프트웨 어 모듈보다 많은 소프트웨어 모듈에 의해 전자 장치가 증강 현실 컨텐츠를 사용자에게 제공할 수 있고, 도 13에 도시된 소프트웨어 모듈보다 적은 소프트웨어 모듈에 의해 전자 장치가 증강 현실 컨텐츠를 사용자에 게 제공할 수 있다. 예를 들면, 이미지 획득 모듈(17a)에 포함된 인스트럭션을 프로세서가 실행함으로써, 전자 장치는 카메 라를 이용하여 대상체가 포함된 현실 공간에 대해서 이미지를 획득할 수 있다. 도 1 내지 도 11을 참조하 여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 다른 예를 들면, 대상체 식별 모듈(17b)에 포함된 인스트럭션을 프로세서가 실행함으로써, 전자 장치는 이미지로부터 대상체를 식별하고 추적할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예 와 중복되는 내용은 생략한다. 다른 예를 들면, AR 위치 정보 획득 모듈(17c)에 포함된 인스트럭션을 프로세서가 실행함으로써, 전자 장치 는 대상체의 위치 정보 및 AR 위치 정보를 식별할 수 있다. 전자 장치는 서버로부터 수신된 AR 위치 정보를 이용하여, 이미지 상에 증강 현실 컨텐츠가 디스플레이 될 위치를 식별할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 다른 예를 들면, 증강 현실 컨텐츠 출력 모듈(17d)에 포함된 인스트럭션을 프로세서가 실행함으로써, 전자 장치는 증강 현실 컨텐츠를 디스플레이 할 수 있다. 전자 장치는 서버로부터 수신된 AR 위치 정보를 이용하여, 이미지 상에 증강 현실 컨텐츠가 디스플레이 될 위치를 식별할 수 있다. 전자 장치 는 대상체의 위치 정보 및 서버로부터 수신한 AR 위치 정보를 비교함으로써, 증강 현실 컨텐츠 가 디스플레이 될 위치를 식별할 수 있다. 전자 장치는 식별된 위치에 증강 현실 컨텐츠를 디스 플레이 할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 도 14는 일 실시예에 따른, 서버의 블록도이다. 일부 실시예에 따른 서버는 통신부, 메모리, DB 및 프로세서를 포함할 수 있다. 통신부는 서버가 전자 장치와 통신을 하게 하는 하나 이상의 구성요소를 포함할 수 있다. 메모리는 프로세서의 처리 및 제어를 위한 적어도 하나의 인스트럭션 및 적어도 하나의 프로그램을 저 장할 수 있고, 서버로 입력되거나 서버로부터 출력되는 데이터를 저장할 수도 있다. 메모리는 프로 세서가 증강 현실 컨텐츠를 생성하기 위한 인스트럭션 및 프로그램을 저장할 수 있다. DB는 전자 장치로부터 수신한 데이터를 저장할 수 있다. DB는 전자 장치로 전송할 증강 현실 컨텐츠를 생성하기 위한 정보를 저장할 수 있다. 예를 들면, DB는 투수 정보, 타자 정보, 공격수에 관한 정보, 수비수에 관한 정보, 사용자가 선택한 운동 선수의 신체 정보, 운동 선수의 스탯(stat) 정보, 경기에 관 한 정보, 경기장에 관한 정보와 같은 대상체에 관한 정보를 저장할 수 있다. 프로세서는 통상적으로 서버의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 서버의 메 모리에 저장된 프로그램들을 실행함으로써, DB 및 통신부 등을 전반적으로 제어할 수 있다. 또한, 프로세서는 서버와 연결된 카메라로부터 이미지를 획득할 수 있다. 프로세서는 프로그램들을 실행함으로써, 도 1 내지 도 11을 참조하여 설명한 서버의 동작을 수행할 수 있다. 예를 들면, 프로세서는 가상의 3차원 공간 획득 모듈(27a) 에 저장된 인스트럭션을 실행함으로써, 경기장, 공연장 및 전시장과 같은 구조에 대한 데이터로부터 가상의 3차원 공간을 생성할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 다른 예를 들면, 프로세서는 전자 장치의 위치 및 시야 식별 모듈(27b) 에 저장된 인스트럭션을 실행함으로 써, 이미지와 가상의 3차원 공간을 매칭할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시 예와 중복되는 내용은 생략한다. 다른 예를 들면, 프로세서는 대상체 식별 모듈(27c) 에 저장된 인스트럭션을 실행함으로써, 가상의 3차원 공간에 포함된 대상체를 식별하고 추적할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 다른 예를 들면, 프로세서는 증강 현실 컨텐츠 생성 모듈(27d) 에 저장된 인스트럭션을 실행함으로써, 증강 현실 컨텐츠를 생성하고, 전자 장치로 전송할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 도 15는 일 실시예에 따른, 서버에 포함된 메모리의 소프트웨어 모듈을 나타내는 블록도이다. 도 15를 참조하면, 메모리는 도 1 내지 도 11를 참조하여 위에서 설명한 실시예들을 서버가 수행하기 위한 소프트웨어 모듈로서, 가상의 3차원 공간 획득 모듈(27a), 전자 장치의 위치 및 시야 식별 모듈(27b), 대 상체 식별 모듈(27c) 및 증강 현실 컨텐츠 생성 모듈(27d)을 포함할 수 있다. 그러나, 도 15에 도시된 소프트 웨어 모듈보다 많은 소프트웨어 모듈에 의해 서버가 증강 현실 컨텐츠를 생성할 수 있고, 도 15에 도시된 소프트웨어 모듈보다 적은 소프트웨어 모듈에 의해 서버가 증강 현실 컨텐츠를 생성할 수 있다. 예를 들면, 가상의 3차원 공간 획득 모듈(27a)에 포함된 인스트럭션을 프로세서가 실행함으로써, 서버 는 경기장, 공연장 및 전시장과 같은 구조에 대한 데이터로부터 가상의 3차원 공간을 생성할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 다른 예를 들면, 전자 장치의 위치 및 시야 식별 모듈(27b)에 포함된 인스트럭션을 프로세서가 실행함으로 써, 서버는 이미지와 가상의 3차원 공간을 매칭할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 다른 예를 들면, 대상체 식별 모듈(27c)에 포함된 인스트럭션을 프로세서가 실행함으로써, 서버는 가상 의 3차원 공간에 포함된 대상체를 식별하고 추적할 수 있다. 도 1 내지 도 11을 참조하여 위에서 설명한 실시예와 중복되는 내용은 생략한다. 다른 예를 들면, 증강 현실 컨텐츠 생성 모듈(27d)에 포함된 인스트럭션을 프로세서가 실행함으로써, 서버 는 증강 현실 컨텐츠를 생성하고, 전자 장치로 전송할 수 있다. 도 1 내지 도 11을 참조하여 위 에서 설명한 실시예와 중복되는 내용은 생략한다. 도 1 내지 도 15의 실시예에 따르면, 전자 장치는 증강 현실 컨텐츠가 표시될 대상체(target object)가 빠 르게 움직이거나, 사용자 단말기가 빠르게 움직이는 경우에도, 대상체의 위치에 맞게 증강 현실 컨텐츠를 표시 함으로써, 자연스러운 증강 현실 컨텐츠를 사용자에게 제공할 수 있다. 일부 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기 록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로 그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다."}
{"patent_id": "10-2020-0129464", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 전자 장치가 서버로부터 수신된 증강 현실 컨텐츠를 디스플레이하는 방법의 예시를 설명하는 도면이다. 도 2는 종래 기술에 따른, 전자 장치가 서버로부터 수신된 증강 현실 컨텐츠를 디스플레이할 때 발생되는 문제 를 설명하는 도면이다. 도 3은 일 실시예에 따른, 전자 장치와 서버가 증강 현실 컨텐츠를 생성하여 디스플레이하는 방법의 순서도이다. 도 4는 일 실시예에 따른, 전자 장치가 서버로부터 수신된 증강 현실 컨텐츠를 디스플레이하는 방법을 설명하는 도면이다. 도 5는 일 실시예에 따른, 전자 장치가 서버로부터 수신된 증강 현실 컨텐츠를 디스플레이하는 방법의 순서도이 다. 도 6은 일 실시예에 따른, 전자 장치가 획득한 이미지와 서버의 가상의 3차원 공간을 매칭하는 방법의 예시를 설명하는 도면이다. 도 7은 일 실시예에 따른, 서버가 카메라를 이용하여 획득한 대상체의 위치를 식별하고 매칭하는 방법의 예시를 설명하는 도면이다. 도 8은 일 실시예에 따른, 전자 장치가 사용자 입력에 기초하여 서버로부터 수신된 증강 현실 컨텐츠를 디스플 레이하는 방법의 순서도이다. 도 9는 일 실시예에 따른, 전자 장치가 사용자 입력에 기초하여 서버로부터 수신된 증강 현실 컨텐츠를 디스플 레이하는 방법의 예시를 설명하는 도면이다. 도 10은 일 실시예에 따른, 전자 장치가 사용자 입력에 기초하여 서버로부터 수신된 증강 현실 컨텐츠를 디스플 레이하는 방법의 순서도이다. 도 11은 일 실시예에 따른, 전자 장치가 사용자 입력에 기초하여 서버로부터 수신된 증강 현실 컨텐츠를 디스플 레이하는 방법의 순서도이다. 도 12는 일 실시예에 따른, 전자 장치의 블록도이다. 도 13은 일 실시예에 따른, 전자 장치에 포함된 메모리의 소프트웨어 모듈을 나타내는 블록도이다. 도 14는 일 실시예에 따른, 서버의 블록도이다. 도 15는 일 실시예에 따른, 서버에 포함된 메모리의 소프트웨어 모듈을 나타내는 블록도이다."}
