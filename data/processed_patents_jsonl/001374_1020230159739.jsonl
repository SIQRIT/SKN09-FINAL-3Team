{"patent_id": "10-2023-0159739", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0053664", "출원번호": "10-2023-0159739", "발명의 명칭": "음성 에이전트 간 통신 방법 및 이를 위한 전자 장치", "출원인": "삼성전자주식회사", "발명자": "김상헌"}}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,통신 회로; 및상기 통신 회로와 전기적으로 연결되는 적어도 하나의 프로세서;를 포함하고,상기 적어도 하나의 프로세서는:사용자 입력을 획득하고,상기 사용자 입력에 기반하여 태스크(Task)를 식별하고,상기 태스크를 수행하기 위해 외부 전자 장치에 음성 호(call)를 위한 제1 세션의 확립 요청을 송신하고,상기 외부 전자 장치로부터 응답을 수신하고,상기 응답에 기반하여 상기 음성 호의 응답자(responder)가 기계 학습에 기반한 음성 에이전트(agent)인지 여부를 결정하고,상기 응답자가 상기 음성 에이전트라는 결정에 기반하여, 상기 외부 전자 장치에 상기 태스크와 연관된 정보를포함하는 데이터 정보를 송신하도록 설정된, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 적어도 하나의 프로세서는,상기 응답에 상기 응답자가 상기 음성 에이전트임을 나타내는(indicate) 정보가 포함되어 있으면, 상기 응답자가 음성 에이전트라는 결정을 하도록 설정된, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 응답자가 음성 에이전트임을 나타내는 정보는,식별 정보 또는 패턴 정보 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 식별 정보는 SDP(session description protocol) 패킷에 포함된, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 3에 있어서,상기 패턴 정보는 DTMF(dual tone multiple frequency)에 기반한 주파수 패턴 정보를 포함하는, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "에 있어서,상기 적어도 하나의 프로세서는,상기 데이터 정보의 크기가 지정된 크기 이상이면, 상기 제2 세션의 확립 요청을 송신하도록 설정된, 전자장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 6에 있어서,상기 적어도 하나의 프로세서는,상기 데이터 정보의 크기가 지정된 크기 미만이면, 상기 제1 세션을 통해 상기 데이터 정보를 송신하도록 설정된, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서,상기 응답은 상기 제1 세션의 확립 요청에 대한 응답, 상기 전자 장치가 송신한 상기 태스크와 연관된 음성 정보에 대한 응답 또는 별도의 통신 채널을 통해 획득한 응답 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 별도의 채널은 근거리 무선 통신 채널을 포함하는, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 1에 있어서,상기 적어도 하나의 프로세서는,상기 응답자가 상기 음성 에이전트라는 결정에 기반하여, 상기 응답자가 상기 음성 에이전트임을 지시하는 정보를 제공하도록 더 설정된, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 전자 장치는 디스플레이를 더 포함하고,상기 적어도 하나의 프로세서는,상기 디스플레이에 UI(User Interface)를 표시하여 상기 정보를 제공하도록 설정된, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 1에 있어서,상기 요청은 상기 제1 세션의 확립 요청의 요청자가 음성 에이전트임을 나타내는 정보를 포함하는, 전자 장치."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "전자 장치를 이용한 방법에 있어서,사용자 입력을 획득하는 동작;상기 사용자 입력에 기반하여 태스크(Task)를 식별하는 동작;상기 태스크를 수행하기 위해, 외부 전자 장치에 음성 호(call)를 위한 제1 세션의 확립 요청을 송신하는 동작;공개특허 10-2025-0053664-4-상기 외부 전자 장치로부터 응답을 수신하는 동작;상기 응답에 기반하여 상기 음성 호의 응답자(responder)가 기계 학습에 기반한 음성 에이전트(agent)인지 여부를 결정하는 동작; 및상기 응답자가 상기 음성 에이전트라는 결정에 기반하여, 상기 외부 전자 장치에 상기 태스크와 연관된 정보를포함하는 데이터 정보를 송신하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 14에 있어서,상기 응답에 상기 음성 에이전트임을 나타내는(indicate) 정보가 포함되어 있으면, 상기 응답자가 상기 음성 에이전트라고 결정하는 동작을 더 포함하는, 방법."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 15에 있어서,상기 음성 에이전트임을 나타내는 정보는,식별 정보 또는 패턴 정보 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 16에 있어서,상기 식별 정보는 SDP(session description protocol) 패킷에 포함된, 방법."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 16에 있어서,상기 패턴 정보는 DTMF(dual tone multiple frequency)에 기반한 주파수 패턴 정보를 포함하는, 방법."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 14에 있어서,상기 외부 전자 장치에 데이터 통신을 위한 제2 세션의 확립 요청을 송신하는 동작을 더 포함하는, 방법."}
{"patent_id": "10-2023-0159739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "청구항 19에 있어서,상기 제2 세션의 확립 요청을 송신하는 동작은, 상기 데이터 정보의 크기가 지정된 크기 이상이면 상기 제2 세션의 확립 요청을 송신하는 동작을 포함하는, 방법."}
{"patent_id": "10-2023-0159739", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 문서에 개시되는 일 실시 예에 따른 전자 장치는 통신 회로 및 상기 통신 회로와 전기적으로 연결되는 적어도 하나의 프로세서를 포함할 수 있다. 또한, 상기 적어도 하나의 프로세서는 사용자 입력을 획득하고, 상기 사용자 입력에 기반하여 태스크(Task)를 식별하고, 상기 태스크를 수행하기 위해, 외부 전자 장치에 음성 호(call)를 위 한 제1 세션의 확립 요청을 송신하고, 상기 외부 전자 장치로부터 응답을 수신하고, 상기 응답에 기반하여 상기 음성 호의 응답자(responder)가 기계 학습에 기반한 음성 에이전트(agent)인지 여부를 결정하고, 상기 응답자가 상기 음성 에이전트라는 결정에 기반하여, 상기 외부 전자 장치에 상기 태스크와 연관된 정보를 포함하는 데이터 정보를 송신하도록 설정될 수 있다."}
{"patent_id": "10-2023-0159739", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 문서에서 개시되는 실시 예들은 음성 에이전트 간 통신 방법 및 이를 위한 전자 장치와 관련된다."}
{"patent_id": "10-2023-0159739", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 장치는 음성 에이전트(voice agent)를 통해 사용자 입력(예: 음성 입력)을 수신하고, 음성 입력에 기반하 여 외부 전자 장치와 정보를 교환할 수 있다. 한편, ARS(Automatic Response System) 서비스는 사전에 녹음된 음성정보를 이용자가 시스템에 접속하면 안내하 는 서비스를 의미하고, IVR(Interactive Voice Response) 서비스는 사용 목적에 따라 고객이 입력한 정보를 상 담원이나 데이터베이스 서버에 보낼 수가 있어서 입력된 정보를 토대로 고객에게 맞춤형 정보를 제공하는 서비스를 의미한다. 상술한 정보는 본 개시에 대한 이해를 돕기 위한 목적으로 하는 배경 기술(related art)로 제공될 수 있다. 상 술한 내용 중 어느 것도 본 개시와 관련하여 종래 기술(prior art)로서 적용될 수 있는지에 관해서는 어떠한 주 장이나 결정이 제기되지 않는다."}
{"patent_id": "10-2023-0159739", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 문서에 개시되는 일 실시 예에 따른 전자 장치는 통신 회로 및 상기 통신 회로와 전기적으로 연결되는 적어 도 하나의 프로세서를 포함할 수 있다. 또한, 상기 적어도 하나의 프로세서는 사용자 입력을 획득하고, 상기 사 용자 입력에 기반하여 태스크(Task)를 식별하고, 상기 태스크를 수행하기 위해, 외부 전자 장치에 음성 호 (call)를 위한 제1 세션의 확립 요청을 송신하고, 상기 외부 전자 장치로부터 응답을 수신하고, 상기 응답에 기 반하여 상기 음성 호의 응답자(responder)가 기계 학습에 기반한 음성 에이전트(agent)인지 여부를 결정하고, 상기 응답자가 상기 음성 에이전트라는 결정에 기반하여, 상기 외부 전자 장치에 상기 태스크와 연관된 정보를 포함하는 데이터 정보를 송신하도록 설정될 수 있다. 본 문서에 개시되는 일 실시 예에 따른 방법은 사용자 입력을 획득하는 동작, 상기 사용자 입력에 기반하여 태 스크(Task)를 식별하는 동작, 상기 태스크를 수행하기 위해, 외부 전자 장치에 음성 호(call)를 위한 제1 세션 의 확립 요청을 송신하는 동작, 상기 외부 전자 장치로부터 응답을 수신하는 동작, 상기 응답에 기반하여 상기 음성 호의 응답자(responder)가 기계 학습에 기반한 음성 에이전트(agent)인지 여부를 결정하는 동작 및 상기 응답자가 상기 음성 에이전트라는 결정에 기반하여, 상기 외부 전자 장치에 상기 태스크와 연관된 정보를 포함 하는 데이터 정보를 송신하는 동작을 포함할 수 있다. 본 문서에 개시되는 일 실시 예에 따른 인스트럭션들을 저장하는 컴퓨터 판독가능 저장 매체에 있어서, 상기 인 스트럭션들은, 전자 장치의 적어도 하나의 프로세서의 의하여 실행되었을 때, 상기 적어도 하나의 프로세서가 사용자 입력을 획득하고, 상기 사용자 입력에 기반하여 태스크(Task)를 식별하고, 상기 태스크를 수행하기 위해 외부 전자 장치에 음성 호(call)를 위한 제1 세션의 확립 요청을 송신하고, 상기 외부 전자 장치로부터 응답을 수신하고, 상기 응답에 기반하여 상기 음성 호의 응답자(responder)가 기계 학습에 기반한 음성 에이전트 (agent)인지 여부를 결정하고, 상기 응답자가 상기 음성 에이전트라는 결정에 기반하여, 상기 외부 전자 장치에 상기 태스크와 연관된 정보를 포함하는 데이터 정보를 송신하도록 할 수 있다."}
{"patent_id": "10-2023-0159739", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 발명을 특정한 실시 형 태에 대해 한정하려는 것이 아니며, 본 발명의 실시 예의 다양한 변경(modification), 균등물(equivalent), 및/ 또는 대체물(alternative)을 포함하는 것으로 이해되어야 한다. 도 1은 일 실시 예에 따른, 전자 장치가 외부 전자 장치와 통신하는 시스템 도면이다. 도 1을 참조하면, 일 실시 예에 따른 전자 장치가 외부 전자 장치와 통신하는 시스템은, 전자 장치, 외부 전자 장치, 음성 에이전트(11, 21), IP(internet protocol) 네트워크, PSTN(public switched telephone network) 중 적어도 하나를 포함할 수 있다. 예를 들어, 음성 에이전트는 생성형 AI(generative artificial intelligence)를 포함할 수 있다. 생성형 AI는 텍스트, 오디오, 이미지 등의 기존 콘텐츠를 활용하여 유사한 콘텐츠를 새로 만들어낼 수 있다. 전자 장치(예: 전자 장치, 외부 전자 장치)는 예를 들면, 스마트폰, 스마트패드(Smart Pad), 태블릿 PC, 웨어러블 장치, 커넥티드카, 및/또는 휴대 단말기와 같은 임의의 종류의 무선 통신 장치를 포함할 수 있다. 전자 장치는, 예를 들어, 데스크탑 컴퓨터 또는 스마트 TV와 같은 고정용 단말기를 포함할 수도 있다. 전자 장 치는 도 10의 전자 장치 또는 도 11의 사용자 단말에 의해 참조될 수 있다. 외부 전자 장치 는 도 10의 전자 장치에 의해 참조될 수 있다. 일 실시 예에서, 전자 장치는 외부 전자 장치와 통신할 수 있다. 예를 들어, 전자 장치는 IP 네트 워크 또는 PSTN 중 적어도 하나를 통해 외부 전자 장치와 통신할 수 있다. 예를 들어, 전자 장치 는 외부 전자 장치와 음성 통신 또는 데이터 통신을 하여 정보를 교환할 수 있다. 전자 장치는 외 부 전자 장치와 근거리 무선 통신을 통해 정보를 교환할 수도 있다. 예를 들어, 전자 장치는 UWB(ultra-wide band), 블루투스 또는 NFC(near field communication)에 기반하여 외부 전자 장치와 근거 리 무선 통신을 할 수 있다. 일 실시 예에서, 전자 장치는 사용자로부터 음성, 텍스트 및/또는 터치 형태의 사용자 입력을 수신할 수 있 다. 전자 장치는 음성 에이전트(voice agent)를 통해 사용자 입력에 대응한 태스크를 수행할 수 있다. 예를 들어, 태스크의 수행은 적어도 하나의 어플리케이션의 실행을 포함할 수 있다. 예를 들어, 적어도 하나의 어플 리케이션은 전화 걸기, 정보의 검색, 송금 또는 결제 진행, SMS 메시지 작성, 이메일 작성, 음악 재생, 사진 촬 영, 사용자 위치 탐색, 지도/내비게이션 서비스 등을 비롯한 각종 다양한 형태의 태스크(그러나 이로써 제한되 는 것은 아님) 수행과 연관된 어플리케이션을 포함할 수 있다. 예를 들어, 전자 장치는 IP 네트워크를 통해 외부 전자 장치와 음성 통신을 위한 대화 세션을 수 립할 수 있다. 예를 들어, 음성 통신을 위한 대화 세션을 수립하는 절차는 도 9에서 참조될 수 있다. 전자 장치 의 음성 에이전트는 수립된 대화 세션을 통해 외부 전자 장치와 음성 및/또는 데이터 정보를 교환 할 수 있다. 전자 장치의 음성 에이전트는 사용자 입력을 실시간으로 상기 대화 세션을 통해 외부 전자 장치에 제공할 수 있다. 전자 장치는 음성 에이전트가 수행한 동작 결과를 사용자에게 제공할 수 있다. 예를 들어, 전자 장치 는 시각적 인터페이스 및/또는 청각적 인터페이스를 통해 상기 동작 결과를 사용자에게 제공할 수 있다. 예 를 들어, 전자 장치는 사용자 입력에 대응한 동작 결과로서의 대화 응답을, 시각, 청각 및/또는 촉각 형태 (예컨대, 음성, 음향, 텍스트, 비디오, 이미지, 기호, 이모티콘, 하이퍼링크, 애니메이션, 각종 노티스, 모션, 햅틱 피드백 등을 포함할 수 있으며, 이로써 제한되는 것은 아님)등 다양한 형태로써 사용자에게 제공할 수 있 다. 네트워크(예: IP 네트워크, PSTN)는 복수의 전자 장치(예: 전자 장치, 외부 전자 장치) 및 서버(예: 음성 에이전트 서버)들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미할 수 있 다. 예를 들어, 네트워크는 LAN(Local Area Network), WAN(Wide Area Network), 인터넷, 유무선 데이터 통신망, 전화망 및/또는 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망은 셀룰러 네트워크,WIMAX(World Interoperability for Microwave Access) 네트워크, 와이파이(Wi-Fi) 네트워크, 인터넷 (Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency) 기반 네트워크, 블루투스(Bluetooth) 네트워크, NFC(Near-Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크 및/또는 DMB(Digital Multimedia Broadcasting) 네트워크 등을 포함할 수 있으나, 이에 한정되지는 않는다. 예를 들어, 네트워크는 도 10의 제2 네트워크에 의해 참조될 수 있다. 도 2는 일 실시 예에 따른, 전자 장치의 구성을 나타내는 블록도이다. 도 2를 참조하면, 전자 장치는 통신 회로, 스피커, 마이크, 메모리, 프로세서 또는 디스플레이 중 적어도 하나를 포함할 수 있다. 일 실시 예에서, 통신 회로는 전자 장치와 적어도 하나의 외부 장치(예: 외부 전자 장치, 방송 서 버 및/또는 컨트롤러(리모컨)) 간의 통신을 지원할 수 있다. 예를 들어, 통신 회로는 외부 네트워크(예: IP 네트워크 및/또는 PSTN)에 접속함으로써 상기 적어도 하나의 외부 전자 장치와 신호 또는 데이터 의 송수신을 수행할 수 있다. 예를 들어, 통신 회로는, 유선 통신 또는 무선 통신을 기반으로, 규정된 프 로토콜(protocol)에 따른 네트워크에 접속함으로써, 적어도 하나의 외부 장치와 신호 또는 데이터의 송수신을 수행할 수 있다. 통신 회로는 도 10의 통신 모듈에 의해 참조될 수 있다. 스피커는 오디오 데이터를 오디오 신호로서 출력할 수 있다. 스피커는 오디오 데이터를 포함하는 전 기적 신호를 오디오 신호로 변환하여 출력할 수 있다. 스피커는 디지털화된 전기적 신호를 아날로그화하는 디지털-아날로그 변환기(Digital to Analog Convertor: DAC) 또는 디지털-아날로그 변환기에 의하여 아날로그화 된 전기적 신호를 증폭하는 앰프 중 적어도 하나를 포함할 수 있다. 스피커는 도 10과 관련하여 후술될 음 향 출력 모듈에 의해 참조될 수 있다. 마이크는 음성 신호를 수신할 수 있다. 일 실시 예에서, 마이크는 전자 장치의 일 영역으로 탑재 되는 적어도 하나의 마이크 장치를 포함할 수 있으며, 특정 어플리케이션(예: 음성 인식 어플리케이션)의 실행 에 트리거(trigger)되어 활성화되거나 또는, 항시 활성화되는 상태(예: always on microphone)로 제어될 수 있 다. 마이크는 전자 장치와 상호작용하는 컨트롤러(예: 리모컨)에 탑재된 적어도 하나의 마이크 장치를 포함할 수 있다. 상기 컨트롤러에 탑재된 적어도 하나의 마이크 장치는 수신한 음성 입력을 전자 장치로 전 송할 수 있다. 전자 장치 또는 컨트롤러에 탑재된 적어도 하나의 마이크 장치는 음성 입력의 수신 효율과 관련하여 적어도 일부가 전자 장치 또는 컨트롤러의 외부로 노출될 수 있다. 마이크는 도 10과 관련하 여 후술될 입력 모듈에 의해 참조될 수 있다. 메모리는 내장 메모리 또는 외장 메모리를 포함할 수 있다. 내장 메모리는, 예를 들면, 휘발성 메모리(예: DRAM(dynamic random access memory), SRAM(static random access memory), 또는 SDRAM(synchronous DRAM)), 비휘발성 메모리(예: PROM(programmable read-only memory), OTPROM(one time PROM), EPROM(erasable PROM), EEPROM(electrically erasable and PROM), mask ROM, flash ROM, flash memory, hard drive, 또는 SSD(solid state drive) 중 적어도 하나를 포함할 수 있다. 외장 메모리는 flash drive(예: compact flash), SD(secure digital), micro-SD, mini-SD, xD(extreme digital), MMC(multi-media card) 또는 메모리 스틱 중 적어도 하나 를 포함할 수 있다. 메모리는 도 10과 관련하여 후술될 메모리에 의해 참조될 수 있다. 메모리는 프로세서에 의해 실행될 수 있는 인스트럭션들을 저장할 수 있다. 메모리는 전자 장치 운용과 관계되는 적어도 하나의 데이터를 저장하거나, 전자 장치 구성요소들의 기능 동작과 관계되는 명령을 저장할 수 있다. 예를 들어, 메모리는 사용자 입력을 저장할 수 있다. 예를 들어, 사용자 입력은 마이크를 통하여 수신되는 음성 입력 또는 디스플레이를 통한 터치 입력 중 적어도 하나를 포함할 수 있다. 메모리는 전자 장치의 제조 시 프리로드(preloaded) 형태로 탑재되거나, 온라인 마켓(예: 앱 스 토어(app store))으로부터 서드 파티(third party) 형태로 다운로드 받는 적어도 하나의 어플리케이션을 저장할 수 있다. 예를 들어, 적어도 하나의 어플리케이션은 음성 인식 서비스의 운용을 지원하는 음성 인식 어플리케이 션을 포함할 수 있다. 디스플레이는 각종 화면을 출력할 수 있다. 예를 들어, 프로세서는 디스플레이를 이용하여 다양 한 화면들(예: 메인 인터페이스 화면, 홈 화면, 시스템 설정 화면, 또는 어플리케이션 실행 화면)을 출력할 수 있다. 예를 들어, 디스플레이는 외부 전자 장치로부터 수신한 응답을 제공할 수 있다. 예를 들어, 디 스플레이는 외부 전자 장치의 응답자가 음성 에이전트이면, 응답자가 음성 에이전트임을 사용자에게 UI(user interface)를 통해 제공할 수 있다. 예를 들어, 음성 에이전트는 생성형 AI(generative artificial intelligence)를 포함할 수 있다. 생성형 AI는 텍스트, 오디오, 이미지 등의 기존 콘텐츠를 활용하 여 유사한 콘텐츠를 새로 만들어낼 수 있다. 디스플레이는 디스플레이 패널, 커버 글라스 및 터치 패널(또는, 터치 센서)을 포함하는 터치스크린 디스 플레이로 구현될 수 있다. 상기 디스플레이 패널은 영상 정보에 대응하는 구동 신호를 지정된 프레임률(frame rate)로 수신하고, 상기 구동 신호에 기초하여 영상 정보에 대응하는 화면을 출력할 수 있다. 상기 커버 글라스 는 디스플레이 패널의 상부에 배치되어 상기 디스플레이 패널의 화면 출력에 따른 광을 투과시킬 수 있다. 디스 플레이는 도 10과 관련하여 후술될 디스플레이 모듈에 의해 참조될 수 있다. 프로세서는 통신 회로, 스피커, 마이크, 메모리 및 디스플레이와 연결될 수 있 다. 예를 들어, 프로세서는 전자 장치의 구성요소들과 전기적으로 연결될 수 있다. 예를 들어, 프로세 서는 전자 장치의 구성요소들과 유선 또는 무선으로 연결될 수 있다. 프로세서는 단일 칩 또는 복수의 칩들로 구성될 수 있다. 프로세서는 적어도 하나의 프로세싱 회로(processing circuitry)를 포함할 수 있다. 프로세서는 전자 장치의 동작에 필요한 연산을 수행할 수 있다. 프로세서는 전자 장치 의 구성 요소들을 제어할 수 있다. 프로세서는 도 10과 관련하여 후술될 프로세서에 의해 참조 될 수 있다. 본 개시에서, 전자 장치의 동작은 프로세서에 의하여 수행되는 것으로 참조될(referred to) 수 있다. 프로세서는 소프트웨어의 명령을 실행하는 적어도 하나의 전기 회로를 포함할 수 있으며, 적어도 하나의 전기 회로를 이용하여 후술되는 다양한 데이터 처리 및 계산을 수행할 수 있다. 일 예에서, 프로세서는 마이크를 통하여 수신하는 사용자 음성 입력에 따른 음성 데이터를 외부 서버 로 전송할 수 있다. 프로세서는 외부 서버로부터 음성 데이터 분석에 따른 신호, 데이터 또는 명령을 수신 하여 처리할 수 있다. 프로세서는 외부 서버를 통해 사용자 입력에 대응하는 태스크를 식별할 수 있다. 예 를 들어, 프로세서는 외부 서버로부터 사용자 입력과 연관된 사용자의 의도를 결정할 수 있다. 프로세서 는 사용자의 의도에 기반하여 수행할 태스크를 식별할 수 있다. 일 예에서, 프로세서는 보조 프로세서(예: NPU(neural processing unit), GPU(graphic processing uni t))를 포함할 수 있다. 프로세서는 보조 프로세서를 이용하여 사용자 입력에 기반한 태스크를 수행할 수 있다. 예를 들어, 프로세서는 사용자로부터 획득한 사용자 입력(예: 음성 입력, 터치 입력)을 인식하고 분 석하여 사용자의 의도(intent)를 파악할 수 있다. 프로세서는 사용자의 의도를 결정하여 사용자 입력에 대 응하는 태스크를 식별할 수 있다. 프로세서는 사용자 입력에 기반하여 식별된 태스크를 수행할 수 있다. 예를 들어, 태스크는 특정 어플리케이션의 실행을 포함할 수 있다. 일 실시 예에서, 프로세서는 음성 인식을 위하여 마이크를 통해 수신된 음성 데이터를 전처리 (preprocessing)할 수 있다. 예를 들어, 프로세서는 음성 데이터에 포함된 에코(echo)를 제거하는 적응 반 향 제거(adaptive echo canceller), 음성 데이터를 필터링하여 배경잡음을 억제하는 노이즈 억제(noise suppression), 음성 데이터에 이득(gain) 값을 적용하여 음량 또는 주파수 특성을 변경하는 자동 이득 제어 (automatic gain control) 또는 사용자 음성 입력의 종점을 검출하여 음성 데이터의 구간을 판단하는 종점 검출 (end-point detection) 중 적어도 하나에 대한 전처리를 수행할 수 있다. 프로세서는 사용자로부터 사용자 입력을 획득할 수 있다. 예를 들어, 사용자 입력은 음성 입력 또는 터치 입력 중 적어도 하나를 포함할 수 있다. 프로세서는 마이크를 통해 사용자로부터 음성 입력을 획득할 수 있다. 프로세서는 디스플레이를 통해 사용자로부터 터치 입력을 획득할 수 있다. 프로세서는 사용자 입력에 기반하여 음성 에이전트(voice agent)를 호출할 수 있다. 예를 들어, 사용 자 입력은 음성 에이전트의 호출을 위한 지정된 명령어(예: wake-up word)를 포함할 수 있다. 예를 들어, 프로세서는 전자 장치에 내장된 지능형 앱(또는, 음성 인식 앱)을 통해 음성 에이전트를 호출할 수 있다. 예를 들어, 음성 에이전트는 생성형 AI(generative artificial intelligence)를 포함할 수 있다. 생성형 AI는 텍스트, 오디오, 이미지 등의 기존 콘텐츠를 활용하여 유사한 콘텐츠를 새로 만들어낼 수 있다. 음성 에이전트는 사용자로부터 사용자 입력(예: 음성 입력 또는 터치 입력)을 수신할 수 있다. 음성 에이전 트는 사용자 입력에 기반하여 태스크를 식별할 수 있다. 음성 에이전트는 식별한 태스크를 수행할 수 있다. 예를 들어, 후술되는 프로세서의 동작들의 적어도 일부는 음성 에이전트에 의해 수행되는 것으 로 참조될 수 있다.프로세서는 음성 에이전트를 이용하여 사용자 입력에 기반한 태스크를 식별할 수 있다. 프로세서(27 1)는 사용자 입력에 기반하여, 단독으로 또는 외부 서버를 통해 사용자 입력에 연관된 사용자의 의도를 결정할 수 있다. 프로세서는 결정된 사용자의 의도를 통해 사용자 입력에 대응하는 태스크를 식별할 수 있다. 프 로세서는 사용자 입력 및/또는 사용자의 컨텍스트 정보에 기반하여 태스크에 연관된 적어도 하나의 파라미 터(예: 어플리케이션, 엔티티, 슬롯)를 식별할 수 있다. 예를 들어, 태스크는 특정 어플리케이션의 실행을 포함 할 수도 있다. 예를 들어, 사용자 입력이 특정 식당의 식사 예약과 연관된 것인 경우, 프로세서는 '식당 예약'이라는 사 용자 의도를 결정할 수 있다. 이 경우, 프로세서는 특정 식당에 전화를 걸어 식사 예약에 필요한 정보를 송신하는 것과 관련된 태스크를 식별할 수 있다. 예를 들어, 식사 예약에 필요한 정보는 예약 시간, 인원수 또 는 식사 메뉴 중 적어도 하나를 포함할 수 있다. 예를 들어, 사용자 입력이 '사진관에서 촬영했던 사진(예: 전자 장치의 갤러리에 저장된 사진)을 언제까지 출력해서 준비해줘'에 대한 것인 경우, 프로세서는 사진관(예: 외부 전자 장치)에 전화를 걸고, 갤러 리에 저장된 사진에 대한 이미지 정보 및 예약 정보를 포함하는 텍스트 정보를 사진관에 송신할 수 있다. 일 예에서, 사용자 입력이 식당 예약과 관련하여 불분명한 정보를 포함하는 경우, 프로세서는 사용자에 연 관된 데이터 정보(예: 사용자에 개인화된 특성 정보)를 이용하여 사용자의 의도를 결정할 수 있다. 예를 들어, 사용자의 개인화된 특성 정보는 임의의 어플리케이션에 저장되어 있는 사용자의 개인 정보, 검색 기록 또는 시 청 기록 등을 포함할 수 있다. 예를 들어, 사용자 입력이 식당 예약과 관련하여 “자주 가는 중식당에 저녁 식사 예약해줘”와 같이 식당 이름, 식사 메뉴, 예약 인원 또는 예약 시간 중 적어도 하나가 생략된 경우, 프로세서는 사용자의 개인화 된 특성 정보를 이용하여 생략된 정보를 특정할 수 있다. 또 다른 예로, 사용자 입력이 식당 예약과 관련하여 “괜찮은 중식당에 식사 예약해줘”와 같이 식당 이름, 식사 메뉴, 예약 인원 또는 예약 시간 중 적어도 하나가 생략된 경우, 프로세서는 정보 검색 어플리케이션 및/또는 지도 앱 등을 이용하여, 사용자 주변에 인기가 많은 중식당을 식별할 수 있다. 또한, 프로세서는 현재 시각을 고려하여, 사용자가 예약하려는 시간이 점 심 시간(예: 오후 12시)인지 또는 저녁 시간(예: 저녁 6시)인지 구별할 수 있다. 일 예에서, 사용자 입력이 식당 예약과 관련하여 불분명한 정보를 포함하는 경우, 프로세서는 사용자로부 터 추가 사용자 입력을 획득할 수 있다. 예를 들어, 사용자 입력이 식당 예약과 관련하여 불분명한 정보를 포함 하는 경우, 프로세서는 음성 에이전트를 이용하여 사용자에게 상기 불분명한 정보의 제공을 요청할 수 있다. 예를 들어, 음성 에이전트는 스피커를 통해 청각적으로 불분명한 정보의 제공을 요청할 수 있다. 예를 들어, 음성 에이전트는 디스플레이를 통해 시각적으로 불분명한 정보의 제공을 요청할 수 있다. 프로세서는 음성 에이전트를 이용하여, 식별한 태스크를 수행할 수 있다. 예를 들어, 프로세서는 식별한 태스크와 연관된 음성 정보를 외부 전자 장치(예: 외부 전자 장치)에 송신할 수 있다. 프로세서 는 식별된 태스크를 수행하면서, 외부 전자 장치의 응답자가 음성 에이전트(예: 음성 에이전트)인 지 여부를 나타내는(indicate) 정보의 제공을 요청할 수도 있다. 예를 들어, 프로세서는 태스크와 연관된 음성 정보의 송신과 함께 응답자가 음성 에이전트인지를 나타내는 정보의 제공 요청을 할 수 있다. 예를 들어, 프로세서는 외부 전자 장치(예: 외부 전자 장치)에 음성 및/또는 데이터 통신을 위한 연결 을 확립하여 태스크를 수행할 수 있다. 일 예에서, 외부 전자 장치의 응답은 외부 전자 장치의 음성 에 이전트에 의하여 수행될 수 있다. 즉, 전자 장치의 음성 에이전트는 외부 전자 장치의 음성 에 이전트와 음성 및/또는 데이터 통신을 통해 태스크를 수행할 수 있다. 일 예에서, 프로세서는 태스크를 수행하기 위해, 외부 전자 장치(예: 외부 전자 장치)에 제1 세션의 설정을 위한 요청을 송신할 수 있다. 예를 들어, 제1 세션은 음성 호(call) 통신을 위한 것일 수 있다. 예를 들 어, 프로세서는 음성 에이전트를 이용하여 통신 회로를 통해 외부 전자 장치에 음성 호 통신 을 위한 요청을 송신할 수 있다. 예를 들어, 음성 호 통신을 위한 요청은 도 9와 관련하여 후술될 수 있다. 예 를 들어, 음성 에이전트는 사용자 입력에 기반하여 식별한 태스크가 '식당 예약'에 관한 것인 경우, 예약할 식 당에 통화 어플리케이션을 통해 전화를 걸 수 있다. 일 실시 예에서, 음성 에이전트는 예약할 식당의 전화 번호를 메모리에서 식별할 수 있다. 또는, 음성 에이전트는 예약할 식당의 전화번호를 외부 서버를 통 해 검색할 수 있다. 예를 들어, 외부 서버는 도 11의 서비스 서버에 의해 참조될 수 있다.프로세서는 음성 에이전트를 이용하여 외부 전자 장치로부터 응답을 수신할 수 있다. 일 예에서, 프로세서는 외부 전자 장치로부터 '음성 호 통신을 위한 요청'에 대한 응답인 제1 세션 개시 응답을 수신할 수 있다. 프로세서는, 제1 세션 개시 응답을 수신한 경우, 외부 전자 장치와 정보를 교환할 수 있다. 제1 세션 개시 응답(예: 도 9의 SIP 200 OK 메시지)은 도 9와 관련하여 후술될 수 있다. 일 예에서, 프로세서는 '외부 전자 장치에 송신한 태스크와 연관된 음성 정보'에 대한 응답을 수신할 수도 있다. 프로세서는, 외부 전자 장치에 송신한 태스크와 연관된 음성 정보에 대한 응답을 수신한 경우, 수신한 응답을 사용자에게 제공할 수 있다. 예를 들어, 태스크가 '식당 예약'에 관한 것인 경우, 프로세 서는 예약할 식당(예: 외부 전자 장치)에 전화를 걸어 예약에 필요한 정보를 음성 정보로 송신할 수 있다. 일 예에서, 프로세서는 외부 전자 장치의 사용자와 음성 통신 중에, 외부 전자 장치의 음성 에이 전트로부터 응답을 획득할 수도 있다. 예를 들어, 외부 전자 장치의 사용자가 전화 통화 중에 응답자를 음성 에이전트로 전환한 경우, 프로세서는 음성 에이전트로부터 음성 에이전트임을 나타내는 정보 를 포함하는 응답을 획득할 수 있다. 예를 들어, 음성 에이전트임을 나타내는 정보는 DTMF에 기반한 패턴 정보 를 포함할 수 있다. 일 예에서, 프로세서는 별도의 채널을 통해 외부 전자 장치로부터 응답을 수신할 수도 있다. 예를 들 어, 별도의 채널은 도 1에서 상술한 근거리 무선 통신에 기반한 통신 채널에 의해 참조될 수 있다. 예를 들어, 프로세서는 별도의 채널을 통해 외부 전자 장치와 정보를 교환할 수 있다. 프로세서는 음성 에이전트를 이용해서, 외부 전자 장치로부터 수신된 응답에 기반하여 응답자 (responder)가 기계 학습에 기반한 음성 에이전트인지 여부를 결정할 수 있다. 예를 들어, 프로세서는 외부 전자 장치가 응답한 응답에 응답자가 음성 에이전트임을 나타내는(indicate) 정보가 포함되어 있 으면, 상기 응답의 응답자가 음성 에이전트라고 결정할 수 있다. 예를 들어, 응답자가 음성 에이전트임을 나타내는 정보는 식별 정보 또는 패턴 정보 중 적어도 하나를 포함 할 수 있다. 예를 들어, 식별 정보는 SDP(session description protocol) 패킷에 포함될 수 있다. 예를 들어, 패턴 정보는 DTMF(dual tone multiple frequency)에 기반한 주파수 패턴 정보를 포함할 수 있다. 응답자가 음 성 에이전트임을 나타내는 정보(예: 식별 정보, 패턴 정보)는 도 7과 관련하여 후술될 수 있다. 음성 에이전트는 외부 전자 장치와의 근거리 무선 통신을 통해 외부 전자 장치의 응답자가 음성 에 이전트임을 식별할 수도 있다. 근거리 무선 통신을 통해 외부 전자 장치의 응답자가 음성 에이전트(2 1)임을 식별하는 방법은 도 7과 관련하여 후술될 수 있다. 프로세서는 외부 전자 장치로부터 수신한 응답의 응답자가 음성 에이전트라고 결정한 경우, 상기 외부 전자 장치에 태스크와 연관된 정보를 포함하는 데이터 정보를 송신할 수 있다. 예를 들어, 프로세서 는 '응답자가 음성 에이전트임을 나타내는 정보'를 포함하는 응답을 식당(예: 외부 전자 장치)으로부 터 수신한 경우, 외부 전자 장치에 예약에 필요한 정보를 데이터 정보로 송신할 수 있다. 예를 들어, 데이 터 정보는 이미지 정보, 텍스트 정보, 오디오 정보 또는 비디오 정보 중 적어도 하나를 포함할 수 있다. 프로세서는 음성 에이전트를 이용하여 외부 전자 장치에 제2 세션의 설정을 위한 요청을 송신할 수 있다. 예를 들어, 제2 세션은 데이터 통신을 위한 것일 수 있다. 예를 들어, 프로세서는 데이터 정보를 송신하기 위해, 음성 호 통신 시 이용되는 프로토콜(예: RTP(Real-time Transport Protocol))과 다른 프로토콜 (예: TCP(Transmission Control Protocol))을 이용할 수 있다. 이 경우, 프로세서는 통신 회로를 통 해 외부 전자 장치에 데이터 통신(예: IP 네트워크를 통한 임의의 데이터 통신)을 위한 요청을 송신할 수 있다. 예를 들어, 데이터 통신을 위한 요청은 TCP(Transmission Control Protocol), IP(Internet Protocol) 또 는 UDP(User Datagram Protocol)의 연결 절차에 따른 연결 요청에 대응할 수 있다. 프로세서는 외부 전자 장치의 음성 에이전트와 데이터 통신을 하여 태스크와 연관된 데이터 정보를 교환할 수 있다. 일 실시 예에서, 프로세서는 외부 전자 장치에 송신하려는 상기 데이터 정보의 크기에 기반하여 데이 터 통신을 위한 제2 세션의 설정을 요청할 수 있다. 예를 들어, 외부 전자 장치에 송신하려는 상기 데이터 정보의 크기가 지정된 크기 이상이면, 프로세서는 상기 제2 세션의 설정을 요청을 송신할 수 있다. 예를 들어, 프로세서는 태스크와 연관된 데이터 정보의 크기가 지정된 크기 이상인 경우에는, 제1 세션이 아닌 제2 세션의 설정을 통해 상기 데이터 정보를 송신할 수 있다.예를 들어, 외부 전자 장치에 송신하려는 데이터 정보의 크기가 지정된 크기 미만이면, 프로세서는 음 성 호 통신을 위한 제1 세션을 통해 상기 데이터 정보를 송신할 수 있다. 예를 들어, 외부 전자 장치에 송 신하려는 데이터 정보(예: 텍스트 정보)의 크기가 작아서 음성 호 통신을 위한 제1 세션으로 상기 데이터 정보 를 송신할 수 있으면, 프로세서는 상기 제1 세션으로 상기 데이터 정보를 송신할 수 있다. 프로세서는 외부 전자 장치로부터 수신한 응답의 응답자가 음성 에이전트라고 결정하면, 음성 에 이전트를 이용하여 응답자가 음성 에이전트임을 알려주는 알림을 사용자에게 제공할 수 있다. 예를 들 어, 프로세서는 디스플레이에 UI(User Interface)를 표시하여 응답자가 음성 에이전트임을 알려주는 알림을 사용자에게 제공할 수 있다. 예를 들어, 프로세서는 상기 알림을 스피커를 통해 오디오로 제 공할 수 있다. 프로세서는 음성 에이전트를 이용하여, 외부 전자 장치에 대한 음성 호 통신을 위한 제1 세션의 설정 요청에, 요청자 및/또는 통신자가 음성 에이전트임을 나타내는(indicate) 정보를 포함할 수 있다. 예 를 들어, 외부 전자 장치와 음성 호 통신을 하는 자가 음성 에이전트인 경우, 프로세서는 음성 호 통신을 위한 제1 세션의 설정 요청에 요청자 및/또는 통신자가 음성 에이전트임을 나타내는 정보를 포함할 수 있다. 요청자 및/또는 통신자가 음성 에이전트임을 나타내는 정보는 도 7 및/또는 8과 관련하여 후술될 수 있다. 상기 기술한 전자 장치의 구성요소들의 각각의 구성요소는 단수 또는 복수의 개체를 포함할 수 있으며, 복 수의 개체 중 일부는 다른 구성요소에 분리 배치될 수도 있다. 일 실시 예에서, 전술한 해당 구성요소들 중 하 나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상의 다른 구성요소들 또는 동작들이 추가될 수 있다. 도 3은 일 실시 예에 따른, 전자 장치가 외부 전자 장치와 통신하는 방법의 순서도이다. 도 2 및 3을 참조하면, 전자 장치는 동작 310에서, 전자 장치는 외부의 전자 장치(예: 외부 전자 장치 )와 음성 호 통신을 위한 제1 세션의 연결을 확립(establish)할 수 있다. 일 실시 예에서, 전자 장치는 사용자로부터 사용자 입력을 수신할 수 있다. 전자 장치는 사용자 입력에 대응하는 태스크를 수행하기 위해 외부 전자 장치에 음성 호 통신을 위한 제1 세션의 설정을 요청할 수 있다. 예를 들어, 사용자 입력에 대응 하는 태스크가 '식당 예약'에 관한 것인 경우, 전자 장치는 예약을 하기 위해 식당(예: 외부 전자 장치 )에 음성 호 통신을 위한 제1 세션의 설정을 요청하여 전화를 걸 수 있다. 전자 장치는 외부 전자 장치 로부터 음성 호 통신에 대한 제1 세션 개시 응답을 수신하면, 외부 전자 장치에 음성 정보를 교환할 수 있다. 예를 들어, 전자 장치는 상기 식당 예약에 필요한 정보를 음성 정보로 송신하고, 그 결과를 수신할 수 있다. 동작 320에서, 전자 장치는 외부 전자 장치로부터 수신한 응답에 기반하여, 응답자가 음성 에이전트 (voice agent)인지 여부를 결정할 수 있다. 일 실시 예에서, 전자 장치는 외부 전자 장치로부터 수 신한 응답에, 응답자가 음성 에이전트임을 나타내는(indicate) 정보가 포함되어 있는지 식별할 수 있다. 응 답에 응답자가 음성 에이전트임을 나타내는 정보가 포함되어 있으면, 전자 장치는 상기 응답의 응답자 가 음성 에이전트라고 결정할 수 있다. 응답자가 음성 에이전트임을 나타내는 정보는 도 7과 관련하여 후술될 수 있다. 동작 330에서. 전자 장치는 외부 전자 장치로부터 수신한 응답의 응답자가 음성 에이전트(예: 음성 에 이전트)라고 결정하면, 제1 세션을 종료하고 데이터 통신을 위한 제2 세션의 연결을 확립할 수 있다. 예를 들어, 데이터 통신 연결의 확립 절차는 TCP의 연결 절차에 대응할 수 있다. 일 예에서, 전자 장치는, 외부 전자 장치의 응답자가 음성 에이전트이면 음성 호 통신을 위한 제1 세션의 연결을 해제할 수 있다. 이 경우, 전자 장치는 음성 정보의 교환을 위한 음성 통신 대신에, 별도의 데이터 통신을 위한 제2 세션의 설 정을 요청하여 데이터 통신할 수 있다. 예를 들어, 사용자가 음성 에이전트를 이용하여 식당 예약을 하려는 경우, 전자 장치는 외부 전자 장치의 응답자가 음성 에이전트라는 결정에 기반하여, 음성 호 통신 을 위한 제1 세션을 종료하고 데이터 통신을 위한 제2 세션을 통해 식당 예약과 연관된 태스크를 수행할 수 있 다. 도 3의 동작 330에는 음성 호 통신을 위한 제1 세션을 종료하고 별도의 데이터 통신을 위한 제2 세션의 연결을 확립하는 것으로 도시되어 있지만, 이에 한정되지 않을 수 있다. 예를 들어, 전자 장치는 외부 전자 장치 로부터 수신한 응답의 응답자가 음성 에이전트라고 결정하면, 음성 호 통신을 위한 제1 세션을 유지하면서 별도의 데이터 통신을 위한 제2 세션의 연결을 확립할 수 있다. 예를 들어, 전자 장치의 음성 에이전 트와 외부 전자 장치의 음성 에이전트가 데이터 통신을 하는 과정에서 전자 장치의 사용자가 추가적인 음성 정보를 송신하려는 경우, 전자 장치는 음성 호 통신을 통해 사용자의 음성 정보를 송신할 수 있다. 예를 들어, 사용자가 식당 예약을 하려다가 취소하려는 경우, 전자 장치는 사용자의 예약 취소에 대 응하는 음성 정보를 음성 호 통신을 통해 송신할 수 있다. 동작 340에서, 전자 장치는 외부 전자 장치로부터 데이터 정보를 수신하고 수신한 데이터 정보를 표시 할 수 있다. 일 실시 예에서, 전자 장치는 데이터 통신을 통해 외부 전자 장치와 데이터 정보를 교환할 수 있다. 예를 들어, 데이터 통신은 제1 세션 및/또는 제2 세션을 통해 이루어질 수 있다. 전자 장치는 수 신한 데이터 정보를 사용자에게 제공할 수 있다. 예를 들어, 전자 장치는 수신한 데이터 정보를 디스플레이 또는 스피커를 이용하여 사용자에게 제공할 수 있다. 도 4는, 일 실시 예에 따른, 전자 장치가 외부 전자 장치와 통신하는 방법의 흐름도이다. 도 2 내지 4를 참조하면, 동작 410에서, 전자 장치는 외부의 전자 장치(예: 외부 전자 장치)와 통신할 수 있다. 예를 들어, 전자 장치는 외부 전자 장치와 음성 호 통신을 할 수 있다. 동작 410은 동작 310 에 의해 참조될 수 있다. 동작 420에서, 전자 장치는 외부 전자 장치로부터 수신한 응답의 응답자가 음성 에이전트(예: 음성 에 이전트)인지 여부를 결정할 수 있다. 예를 들어, 외부 전자 장치로부터 수신한 응답은 '음성 호 통신을 위한 제1 세션의 설정 요청'에 대한 응답, '전자 장치가 송신한 태스크와 연관된 음성 정보'에 대한 응답 또는 별도의 채널을 통해 획득한 응답 중 적어도 하나를 포함할 수 있다. 전자 장치는 수신한 응답에 응답 자가 음성 에이전트임을 나타내는(indicate) 정보를 포함하고 있는지 식별할 수 있다. 전자 장치는 상 기 응답에 응답자가 음성 에이전트임을 나타내는 정보가 포함되어 있으면, 상기 응답의 응답자가 음성 에이 전트라고 결정할 수 있다. 응답자가 음성 에이전트임을 나타내는 정보는 도 7과 관련하여 후술될 수 있 다. 전자 장치는 외부 전자 장치의 응답자가 음성 에이전트(예: 음성 에이전트)라고 결정한 경우(예: 동작 420 - Yes), 동작 430에서, 외부 전자 장치와 데이터 통신을 할 수 있다. 일 실시 예에서, 전자 장치 는 외부 전자 장치의 응답자가 음성 에이전트이면, 음성 통신이 아닌 데이터 통신을 하여 정보를 교환할 수 있다. 예를 들어, 음성 통신은 전자 장치와 외부 전자 장치간에 음성 정보의 교환을 포함할 수 있다. 예를 들어, 데이터 통신은 전자 장치와 외부 전자 장치간에 데이터 정보의 교환을 포함할 수 있다. 전자 장치는 외부 전자 장치와 음성 호 통신 연결이 확립되어 있으면, 음성 호 통신의 연결을 해제하거 나 또는 유지하면서, 외부 전자 장치에 별도의 데이터 통신 연결을 새로 확립할 수 있다. 전자 장치는 음성 에이전트와 데이터 통신을 하기 위해 효율적인 통신 프로토콜로 변경할 수 있다. 예를 들어, 전자 장 치는 음성 호 통신을 하는 경우에 RTP(Real-time Transport Protocol)를 이용하는 반면에, 데이터 통신을 하는 경우에는 TCP(Transmission Control Protocol)를 이용할 수 있다. 또한, 외부 전자 장치에 송신하려는 데이터 정보의 크기가 지정된 크기보다 작은 경우, 전자 장치는 RTP를 이용하여서도 데이터통신을 할 수 있다. 즉, 외부 전자 장치에 송신하려는 데이터 정보의 크기가 지 정된 크기보다 작은 경우, 전자 장치는 RTP 또는 TCP 중 어느 하나를 이용하여 외부 전자 장치와 데이 터 통신을 하여 데이터 정보의 교환을 할 수 있다. 전자 장치는 음성 에이전트와 TCP를 이용하여 데이터 통신을 할 수 있다. 예를 들어, 전자 장치는 사용자 입력에 대응하는 태스크를 수행하기 위해, 태스크와 연관된 데이터 정보를 데이터 통신으로 송신할 수 있다. 예를 들어, 전자 장치는 '식당 예약'에 관한 태스크를 수행하는 경우, 예약에 필요한 정보를 포함하 는 데이터 정보를 데이터 통신을 통해 식당(예: 외부 전자 장치)에 송신할 수 있다. 이에 대해, 전자 장치 는 식당으로부터 데이터 통신을 통해 응답(예: 예약 완료 여부)을 수신할 수 있다. 동작 440에서, 전자 장치는 외부 전자 장치로부터 수신한 데이터 정보를 제1 인터페이스로 표시할 수 있다. 일 실시 예에서, 전자 장치는 외부 전자 장치와 데이터 정보를 교환할 수 있다. 전자 장치는 외부 전자 장치로부터 데이터 정보를 수신하는 경우, 상기 데이터 정보를 제1 인터페이스로 표시하여 사용 자에게 제공할 수 있다. 예를 들어, 전자 장치가 상술한 '식당 예약'에 관한 태스크를 수행하기 위해 상기 데이터 정보를 송신한 경우, 전자 장치는 식당(예: 외부 전자 장치)으로부터 응답(예: 예약 완료 여부)에 대한 데이터 정보를 수신할 수 있다. 이 경우, 전자 장치는 수신한 데이터 정보를 디스플레이에 UI(user interface)를 통하여 사용자에게 제공할 수 있다. 또는, 전자 장치는 수신한 데이터 정보를 오디오 정보로 변환하여 스피커를 통해 사용자에게 제공할 수 있다. 전자 장치는 외부 전자 장치의 응답자가 음성 에이전트가 아니라고 결정한 경우(예: 동작 420 - No), 동작 450에서, 외부 전자 장치와 음성 통신을 할 수 있다. 일 실시 예에서, 전자 장치는 외부 전 자 장치의 응답자가 음성 에이전트가 아니라면, 음성 통신을 하여 정보를 교환할 수 있다. 이 경우, 전 자 장치는 외부 전자 장치와 RTP를 이용하여 음성 통신을 할 수 있다. 예를 들어, 전자 장치는 사 용자 입력에 대응하는 태스크를 수행하기 위해, 태스크와 연관된 데이터 정보를 음성 통신으로 송신할 수 있다. 예를 들어, 전자 장치는 '식당 예약'에 관한 태스크를 수행하는 경우, 예약에 필요한 정보를 포함하는 음성 정보를 음성 통신을 통해 식당(예: 외부 전자 장치)에 송신할 수 있다. 이에 대해, 전자 장치는 식당으 로부터 음성 통신을 통해 응답(예: 예약 완료 여부를 나타내는 정보를 포함하는 응답)을 수신할 수 있다. 동작 460에서, 전자 장치는 외부 전자 장치로부터 수신한 음성 정보를 제2 인터페이스로 표시할 수 있 다. 일 실시 예에서, 전자 장치는 외부 전자 장치의 사용자와 음성 정보를 교환할 수 있다. 전자 장치 는 외부 전자 장치로부터 음성 정보를 수신하는 경우, 상기 음성 정보를 제2 인터페이스로 표시하여 사 용자에게 제공할 수 있다. 예를 들어, 동작 450에서 상술한 '식당 예약'에 관한 태스크를 수행하기 위해 상기 음성 정보를 송신한 경우, 전자 장치는 식당(예: 외부 전자 장치)으로부터 응답(예: 예약 완료 여부)에 대한 음성 정보를 수신할 수 있다. 이 경우, 전자 장치는 수신한 음성 정보를 데이터 정보로 변환하여, 디 스플레이에 UI(user interface)를 통하여 사용자에게 제공할 수 있다. 또는, 전자 장치는 수신한 음성 정보를 스피커를 통해 사용자에게 제공할 수 있다. 도 5는, 일 실시 예에 따른, 전자 장치와 외부 전자 장치가 통신하는 방법을 나타내는 신호 흐름도이다. 도 2 내지 5를 참조하면, 동작 510에서, 전자 장치는 외부 전자 장치에 음성 호 통신을 위한 제1 세션 의 설정을 요청하는 신호를 송신할 수 있다. 일 실시 예에서, 전자 장치는 사용자로부터 사용자 입력(예: 터치 입력, 음성 입력)을 획득할 수 있다. 전자 장치는 사용자 입력에 대응하는 태스크를 수행하기 위해 외 부 전자 장치에 음성 호 통신을 위한 제1 세션의 설정을 요청하는 신호를 송신할 수 있다. 예를 들어, 사용 자 입력에 대응하는 태스크가 '식당 예약'에 관한 것인 경우, 전자 장치는 예약을 하기 위해 식당(예: 외부 전자 장치)에 음성 호 통신을 위한 제1 세션의 설정을 요청하는 신호를 송신하여 전화를 걸 수 있다. 동작 520에서, 외부 전자 장치는 전자 장치에 제1 응답을 송신할 수 있다. 예를 들어, 제1 응답은 '제1 세션의 설정을 위한 요청'에 대한 응답, '전자 장치가 송신한 태스크와 연관된 음성 정보'에 대한 응답 또 는 별도의 채널을 통해 획득한 응답 중 적어도 하나를 포함할 수 있다. 일 실시 예에서, 외부 전자 장치는 전자 장치에 제1 세션의 설정을 위한 요청에 대한 응답인 제1 세션 개시 응답을 송신할 수 있다. 예를 들어, 외부 전자 장치는 전자 장치가 제1 세션 개시 응답을 수신한 경우, 전자 장치와 정보를 교환할 수 있다. 제1 세션 개시 응답(예: 도 9의 SIP 200 OK 메시지)은 도 9와 관련하여 후술될 수 있다. 또한, 외부 전자 장치는 전자 장치에 전자 장치가 송신한 태스크와 연관된 음성 정보에 대한 응답 을 송신할 수도 있다. 예를 들어, 전자 장치가 송신한 태스크와 연관된 음성 정보가 '식당 예약'과 관련하 여 예약 시 필요한 정보인 경우, 외부 전자 장치는 예약 완료 여부에 대한 결과를 제공할 수 있다. 또한, 외부 전자 장치는 전자 장치에 별도의 채널을 통해 응답자가 음성 에이전트임을 알리는 응답을 송신할 수도 있다. 예를 들어, 별도의 채널은 도 1에서 상술한 근거리 무선 통신에 기반한 통신 채널에 의해 참 조될 수 있다. 예를 들어, 외부 전자 장치는 별도의 채널을 통해 전자 장치와 정보를 교환할 수 있다. 동작 530에서, 전자 장치는 외부 전자 장치로부터 수신한 응답에 기반하여, 응답자가 음성 에이전트 (voice agent)(예: 음성 에이전트)인지 여부를 결정할 수 있다. 일 실시 예에서, 전자 장치는 외부 전 자 장치로부터 수신한 응답에, 상기 응답의 응답자가 음성 에이전트임을 나타내는(indicate) 정보가 포 함되어 있는지 식별할 수 있다. 응답에 응답자가 음성 에이전트임을 나타내는 정보가 포함되어 있으면, 전 자 장치는 상기 응답의 응답자가 음성 에이전트라고 결정할 수 있다. 응답자가 음성 에이전트임을 나타내는 정보는 도 7과 관련하여 후술될 수 있다. 동작 540에서. 전자 장치는 외부 전자 장치로부터 수신한 응답의 응답자가 음성 에이전트라고 결정 하면, 음성 호 통신을 중단하고 데이터 통신을 위한 제2 세션의 설정을 요청하는 신호를 송신할 수 있다. 일 실시 예에서, 전자 장치는, 외부 전자 장치의 응답자가 음성 에이전트이면 음성 호 통신을 중단할 수 있다. 이 경우, 전자 장치는 별도의 데이터 통신을 위한 제2 세션의 설정을 요청하는 신호를 송신할 수 있 다. 전자 장치는 외부 전자 장치의 응답자인 음성 에이전트와 데이터 통신을 통해 데이터 정보를 주고받을 수 있다. 데이터 통신은 제1 세션 및/또는 제2 세션을 통해 이루어질 수 있다. 동작 550에서, 외부 전자 장치는 제2 응답을 송신할 수 있다. 일 실시 예에서, 외부 전자 장치는 제2 세션의 설정 요청에 대한 제2 응답인 제2 세션 개시 응답을 송신할 수 있다. 예를 들어, 외부 전자 장치의 음성 에이전트가 전자 장치와 데이터 정보를 교환하기 위해 제2 세션 개시 응답을 송신할 수 있다. 동작 560에서, 전자 장치는 수행할 태스크와 연관된 데이터 정보를 외부 전자 장치에 송신할 수 있다. 예를 들어, 데이터 정보는 데이터 정보를 포함할 수 있다. 일 실시 예에서, 전자 장치는 외부 전자 장치 에 태스크에 연관된 정보를 포함하는 데이터 정보를 송신할 수 있다. 예를 들어, 사용자의 사용자 입력이 '식당 예약'인 경우, 전자 장치는 식당 예약을 위한 태스크를 수행할 수 있다. 이 경우, 전자 장치는 식당 예약에 필요한 정보를 포함하는 데이터 정보를 식당(예: 외부 전자 장치)에 송신할 수 있다. 동작 570에서, 외부 전자 장치는 제3 응답을 송신할 수 있다. 일 실시 예에서, 외부 전자 장치는 동작 560에서 전자 장치가 송신한 데이터 정보에 기반하여 제3 응답을 송신할 수 있다. 예를 들어, 외부 전자 장 치는 데이터 통신을 통해 전자 장치에 데이터 정보를 송신할 수 있다. 이때, 데이터 정보는 데이터 정 보를 포함할 수 있다. 예를 들어, 전자 장치가 상술한 식당 예약에 필요한 정보를 포함하는 데이터 정보를 송신한 경우, 외부 전자 장치는 예약 완료 여부를 포함하는 데이터 정보를 전자 장치에 송신할 수 있다. 동작 580에서, 전자 장치는 외부 전자 장치로부터 데이터 정보를 수신하고 수신한 데이터 정보를 표시 할 수 있다. 일 실시 예에서, 전자 장치는 데이터 통신을 통해 외부 전자 장치와 데이터 정보를 교환할 수 있다. 전자 장치는 수신한 데이터 정보를 사용자에게 제공할 수 있다. 예를 들어, 전자 장치는 수신 한 데이터 정보를 디스플레이 또는 스피커를 이용하여 사용자에게 제공할 수 있다. 예를 들어, 상술 한 '식당 예약'에 관한 태스크를 수행하기 위해 전자 장치가 데이터 정보를 송신한 경우, 전자 장치는 식당(예: 외부 전자 장치)으로부터 응답(예: 예약 완료 여부)에 대한 데이터 정보를 수신할 수 있다. 이 경 우, 전자 장치는 수신한 데이터 정보를 디스플레이에 UI(user interface)를 통하여 사용자에게 제공할 수 있다. 또는, 전자 장치는 수신한 데이터 정보를 오디오 정보로 변환하여 스피커를 통해 사용자에게 제공할 수 있다. 도 6은 일 실시 예에 따른, 전자 장치가 외부 전자 장치의 음성 에이전트와 통신하는 방법의 순서도이다. 도 2 및 6을 참조하면, 동작 610에서, 전자 장치는 사용자로부터 사용자 입력을 획득할 수 있다. 예를 들어, 사용자 입력은 음성 입력 또는 터치 입력 중 적어도 하나를 포함할 수 있다. 일 실시 예에서, 전자 장치 는 마이크를 통해 사용자로부터 음성 입력을 획득할 수 있다. 전자 장치는 디스플레이를 통 해 사용자로부터 터치 입력을 획득할 수 있다. 동작 620에서, 전자 장치는 사용자 입력에 기반하여 태스크를 식별할 수 있다. 일 실시 예에서, 전자 장치 가 사용자로부터 음성 입력을 획득한 경우, 전자 장치는 자동 음성 인식(ASR) 모듈을 이용하여 음성 입 력의 음성 데이터를 텍스트 데이터로 변환할 수 있다. 예를 들어, 자동 음성 인식 모듈은 수신되는 음성 입력을 인식하여 텍스트 데이터로 변환할 수 있다. 자동 음성 인식 모듈은 발화 또는 발성에 관계된 적어도 하나의 정 보를 포함하는 음향 모델(acoustic model) 또는, 적어도 하나의 단위 음소 정보 및 상기 단위 음소 정보의 조합 정보를 포함하는 언어 모델(language model)을 이용하여 음성 입력을 텍스트 데이터로 변환할 수 있다. 자동 음 성 인식 모듈은 변환된 텍스트 데이터를 자연어 이해 모듈로 전달할 수 있다. 자동 음성 인식 모듈에 의해 텍스 트 데이터로 변환된 사용자의 음성 입력은 전자 장치에서 처리될 수도 있고, 외부 서버에 전송되어 처리될 수도 있다. 자동 음성 인식 모듈은 도 11과 관련하여 후술될 자동 음성 인식 모듈에 의해 참조될 수 있다. 일 실시 예에서, 전자 장치는 자동 음성 인식 모듈로부터 전달받은 텍스트 데이터에 기초하여 음성 입력과 관계된 사용자의 의도를 도출할 수 있다. 또는, 전자 장치는 사용자의 터치에 기초하여 터치 입력과 관계된 사용자의 의도를 도출할 수 있다. 자연어 이해 모듈은 텍스트 데이터를 문법적 단위(예: 단어, 구 또는 형태 소)로 구분할 수 있다. 자연어 이해 모듈은 문법적 단위로 구분된 텍스트 데이터를 각각의 단위에 대한 문법적 요소 또는 언어적 특징을 분석하여 사용자의 의도를 도출할 수 있다. 자연어 이해 모듈은 도출된 사용자의 의도에 관계되는 신호, 데이터 또는 명령 정보를 생성할 수 있다. 자연어 이해 모듈은 자동 음성 인식 모듈로부터 전달받은 텍스트 데이터 또는 터치 입력에 기반한 텍스트 데이터와, 도출된 사용자의 의도를 매핑하여 인덱스 또는 데이터베이스로 저장할 수 있다. 자연어 이해 모듈은, 자동 음성 인식 모듈로부터 임의의 텍스트 데이터를 전달받는 경우 또는 터치 입력으로부터 텍스트 데이터를 획득한 경우, 상기 인덱스 또는 상기 데이터베이스 상 에서 상기 임의의 텍스트 데이터와 동일 또는 유사한 양상의 텍스트 데이터를 식별할 수 있다. 자연어 이해 모 듈은 식별된 텍스트 데이터에 매핑된 사용자의 의도를 획득할 수 있다. 자연어 이해 모듈은 도 11과 관련하여 후술될 자연어 이해 모듈에 의해 참조될 수 있다. 전자 장치는 사용자의 의도를 도출하여 사용자 입력에 대응하는 태스크를 식별할 수 있다. 예를 들어, 사용 자 입력이 특정 식당의 '식사 예약'과 연관된 것인 경우, 프로세서는 '식당 예약'에 관한 태스크를 식별할 수 있다. 예를 들어, '식당 예약'에 관한 태스크는 특정 식당에 전화를 걸어 식사 예약에 필요한 정보를 송신하 는 것과 관련될 수 있다. 예를 들어, 식사 예약에 필요한 정보는 예약 시간, 인원수 또는 식사 메뉴 중 적어도 하나를 포함할 수 있다. 동작 630에서, 전자 장치는 태스크를 수행하기 위해, 외부의 전자 장치(예: 외부 전자 장치)에 제1 세 션의 설정을 위한 요청을 할 수 있다. 예를 들어, 제1 세션은 음성 호(call) 통신을 위한 것일 수 있다. 예를 들어, 전자 장치는 음성 에이전트를 이용하여 통신 회로를 통해 외부 전자 장치에 음성 호 통 신을 위한 제1 세션의 설정 요청을 송신할 수 있다. 예를 들어, 음성 호 통신을 위한 제1 세션의 연결 절차는 도 9와 관련하여 후술될 수 있다. 예를 들어, 음성 에이전트는 사용자 입력에 기반하여 식별한 태스크가 ' 식당 예약'에 관한 것인 경우, 예약할 식당에 통화 어플리케이션을 통해 전화를 걸 수 있다. 일 예에서, 음성 에이전트는 예약할 식당의 전화번호를 메모리에서 식별할 수 있다. 또는, 음성 에이 전트는 예약할 식당의 전화번호를 외부 서버를 통해 검색할 수 있다. 예를 들어, 외부 서버는 도 11의 서비 스 서버에 의해 참조될 수 있다. 동작 640에서, 전자 장치는 외부 전자 장치로부터 응답을 수신할 수 있다. 일 실시 예에서, 전자 장치 는 외부 전자 장치로부터 '음성 호 통신을 위한 제1 세션의 설정 요청'에 대한 응답인 제1 세션 개시 응답을 수신할 수 있다. 전자 장치는, 제1 세션 개시 응답을 수신한 경우, 외부 전자 장치와 정보를 교 환할 수 있다. 제1 세션 개시 응답(예: 도 9의 SIP 200 OK 메시지)은 도 9와 관련하여 후술될 수 있다. 일 예에서, 전자 장치는 '전자 장치가 송신한 태스크와 연관된 음성 정보'에 대한 응답을 수신할 수도 있다. 예를 들어, 동작 620에서 식별한 태스크가 '식당 예약'에 관한 것인 경우, 전자 장치는 예약할 식당 (예: 외부 전자 장치)에 전화를 걸어 예약에 필요한 정보를 음성 정보로 송신할 수 있다. 이 경우, 전자 장 치는 식당으로부터 예약 완료 여부에 대한 응답을 수신할 수 있다. 일 예에서, 전자 장치는 별도의 채널을 통해 외부 전자 장치로부터 응답을 수신할 수도 있다. 예를 들 어, 별도의 채널은 도 1에서 상술한 근거리 무선 통신에 기반한 통신 채널에 의해 참조될 수 있다. 예를 들어, 전자 장치는 별도의 채널을 통해 외부 전자 장치와 정보를 교환할 수 있다. 동작 650에서, 전자 장치는 외부 전자 장치로부터 수신한 응답에 기반하여 응답자(responder)가 기계 학습에 기반한 음성 에이전트(voice agent)인지 여부를 결정할 수 있다. 예를 들어, 전자 장치는 외부 전자 장치가 응답한 응답에 응답자가 음성 에이전트임을 나타내는(indicate) 정보가 포함되어 있으면, 상기 응답의 응답자가 음성 에이전트라고 결정할 수 있다. 예를 들어, 응답자가 음성 에이전트임을 나 타내는 정보는 식별 정보 또는 패턴 정보 중 적어도 하나를 포함할 수 있다. 응답자가 음성 에이전트임을 나타내는 정보(예: 식별 정보, 패턴 정보)는 도 7 관련하여 후술될 수 있다. 동작 660에서, 전자 장치는 외부 전자 장치로부터 수신한 응답의 응답자가 음성 에이전트라고 결정 한 경우, 상기 외부 전자 장치에 태스크와 연관된 정보를 포함하는 데이터 정보를 송신할 수 있다. 예를 들 어, 사용자 입력에 기반한 태스크가 '식당 예약'에 관한 것인 경우, 전자 장치는 음성 에이전트를 이용 하여, 태스크를 수행하기 위해 예약할 식당(예: 외부 전자 장치)에 음성 통신을 요청하고 예약에 필요한 정 보를 음성 정보로 송신할 수 있다. 이 경우, 전자 장치는, '응답자가 음성 에이전트임을 나타내는 정보'를 포함하는 응답을 식당으로부터 수신한 경우, 음성 에이전트에 예약에 필요한 정보를 데이터 정보로 송신할 수 있다. 도 7은 일 실시 예에 따른, 전자 장치가 외부 전자 장치의 음성 에이전트와 통신하는 세부적인 방법의 순서도이 다.도 2, 6 및 7을 참조하면, 전자 장치는 동작 600을 수행할 수 있다. 예를 들어, 전자 장치는 사용자로 부터 사용자 입력을 획득할 수 있다. 또한, 전자 장치는 사용자 입력에 기반하여 태스크를 식별할 수 있다. 또한, 전자 장치는 식별된 태스크를 수행하기 위해, 외부의 전자 장치(예: 외부 전자 장치)에 제1 세션 의 설정을 위한 요청을 할 수 있다. 또한, 전자 장치는 외부 전자 장치로부터 응답을 수신할 수 있다. 동작 720에서, 전자 장치는 외부 전자 장치로부터 수신한 응답에, 응답자가 음성 에이전트임을 나 타내는 정보가 포함되어 있는지 식별할 수 있다. 전자 장치는 외부 전자 장치로부터 수신한 응답에, 응 답자가 음성 에이전트임을 나타내는 정보가 포함되어 있다고 식별하면, 상기 응답의 응답자가 음성 에이전 트라고 결정할 수 있다. 일 실시 예에서, 전자 장치는 제1 세션 개시 응답을 수신하는 경우, 상기 제1 세션 개시 응답에 응답자가 음성 에이전트임을 나타내는 정보가 포함되어 있는지 식별할 수 있다. 예를 들어, 전자 장치와 외부 전 자 장치는 음성 통신을 개시할 때, SIP(Session Initiation Protocol) 및 SDP(Session Description Protocol)를 이용할 수 있다. 이 경우, 외부 전자 장치는 도 9에서 후술될 통신 개시 응답인 SIP 200 OK 메 시지에, 응답자가 음성 에이전트임을 나타내는 식별 정보를 포함시켜 송신할 수 있다. SIP 200 OK 메시지에 응답자가 음성 에이전트임을 나타내는 식별 정보가 포함되어 있으면, 전자 장치는 응답자가 음성 에이 전트라고 결정할 수 있다. 예를 들어, 응답자가 음성 에이전트임을 나타내는 식별 정보는 SIP 200 OK 메시지에 포함되어 있는 SDP(session description protocol) Answer 패킷에 포함될 수 있다. 예를 들어, SDP 패킷의 포맷은 하기의 표 1과 같이 구성될 수 있다. 표 1 v=o o=sally 2890844526 2890844526 IN IP4 atlanta.com s= c=IN IP4 10.1.x.x/127 t=0 0 m=audio 49172 RTP/AVP 0 a=rtpmap:0 PCMU/8000 v는 SDP 프로토콜의 버전을 나타낼 수 있다. 예를 들어, 표 1의 SDP 버전은 0일 수 있다. o는 SDP 메시지를 생 성한 owner 또는 creator를 나타낼 수 있다. 예를 들어, o에는 username, session-ID, session version, network type, address type 및 unicast address가 순서대로 표시될 수 있다. s는 세션 이름을 나타낼 수 있다. c는 미디어의 주소를 정의할 수 있다. 예를 들어, c에는 network type, address type 및 connection- address가 순서대로 표시될 수 있다. t는 세션이 작동하는 시간을 나타낼 수 있다. 예를 들어, t에는 시작 시간 과 끝 시간이 표시될 수 있다. 또한, 't= 0 0'은 고정 세션을 의미할 수 있다. m은 미디어 설명을 나타낼 수 있 다. 예를 들어, m에는 media name(예: audio, video, text, application, message) 및 transport address(예: port, protocol, format)가 표시될 수 있다. 예를 들어, port는 미디어가 전송될 전송 포트를 나타낼 수 있다. 예를 들어, format은 미디어의 포맷을 나타낼 수 있고, 각 포맷에 대한 상세한 설명은 a=에 표시될 수 있다. a 는 미디어 속성을 나타낼 수 있다. 예를 들어, 'a=rtpmap: '에는 payload type, encoding name/clock rate이 순서대로 표시될 수 있다. 예를 들어, 표 1의 'a='을 참조하면, 0번 포맷은 PCMU로 인코딩되었고, clock rate은 8000을 의미할 수 있다.일 실시 예에서, 외부 전자 장치는 SDP 패킷의 포맷 중 필드 'o'의 username에, 응 답자가 음성 에이전트임을 나타내는 정보를 표시할 수 있다. 예를 들어, 외부 전자 장치는 'o=sally-AI 2890844526 2890844526 IN IP4 atlanta.com'라고 표시하여, 외부 전자 장치인 sally의 응답자가 음성 에이 전트임을 나타낼 수 있다. 예를 들어, 필드 'o'의 'AI'는 응답자가 음성 에이전트임을 나타내는 정보일 수 있다. 일 실시 예에서, 전자 장치는 '전자 장치가 송신한 태스크와 연관된 음성 정보'에 대한 응답을 수신하 는 경우, 상기 '전자 장치가 송신한 태스크와 연관된 음성 정보'에 대한 응답에, 응답자가 음성 에이전트 임을 나타내는 정보가 포함되어 있는지 식별할 수 있다. 예를 들어, 외부 전자 장치와 전자 장치는 음성 정보를 교환할 때 RTP(Real-time Transport Protocol)을 이용할 수 있다. 외부 전자 장치는 '전자 장 치가 송신한 태스크와 연관된 음성 정보'에 대한 응답을 송신할 때, RTP 패킷의 헤더(header) 또는 페이로 드(pay load) 중 적어도 하나에 응답자가 음성 에이전트임을 나타내는 식별 정보를 포함시킬 수 있다. RTP 패킷의 헤더(header) 또는 페이로드(pay load) 중 적어도 하나에 응답자가 음성 에이전트임을 나타내는 식별 정 보가 포함되어 있으면, 전자 장치는 응답자가 음성 에이전트라고 결정할 수 있다. 일 실시 예에서, 전자 장치는 별도의 채널을 통해 외부 전자 장치로부터 응답을 수신하는 경우, 상기 별도의 채널을 통해 획득한 응답에 응답자가 음성 에이전트임을 나타내는 정보가 포함되어 있는지 식별할 수 있다. 예를 들어, 별도의 채널은 근거리 무선 통신을 위한 채널을 포함할 수 있다. 예를 들어, 전자 장치 는 UWB(ultra-wide band), 블루투스 또는 NFC(near field communication)에 기반하여 외부 전자 장치 와 근거리 무선 통신을 할 수 있다. 외부 전자 장치가 전자 장치와 근거리 무선 통신을 할 수 있으면, 외부 전자 장치는 상기 근거리 무선 통신을 통해 응답자가 음성 에이전트임을 알려줄 수 있다. 또는, 외부 전자 장치는 전자 장치가 근처에 있으면, 니어바이 쉐어(nearby share)를 통해 응답자가 음 성 에이전트임을 알려줄 수도 있다. 예를 들어, 전자 장치가 외부 전자 장치와 근거리 무선 통신을 위해 주변 기기를 검색하여 외부 전자 장치를 찾는 경우, 외부 전자 장치의 검색 정보가 음성 에이전트 라고 표시될 수 있다. 예를 들어, 전자 장치는 외부 전자 장치의 음성 에이전트의 계정 정보 또는 식별 정보를 통해 응답자가 음성 에이전트임을 결정할 수 있다. 일 실시 예에서, 외부 전자 장치는, 전자 장치에 송신하는 응답 신호에 패턴 정보를 포함하여, 응답자 가 음성 에이전트임을 알려줄 수 있다. 예를 들어, 패턴 정보는 DTMF(dual tone multiple frequency)에 기 반한 주파수 패턴 정보를 포함할 수 있다. 예를 들어, 상기 주파수 패턴 정보에는 응답자가 음성 에이전트 임을 나타내는 정보에 대응할 수 있다. 외부 전자 장치는 제1 세션 개시 응답, '전자 장치가 송신한 태 스크와 연관된 음성 정보'에 대한 응답 또는 별도의 채널을 통한 응답 중 적어도 하나에, 상기 주파수 패턴 정 보를 포함시켜 송신할 수 있다. 또는, 외부 전자 장치는 음성 호 통신 중에 응답자가 음성 에이전트로 전환되는 경우, 전자 장치에 DTMF에 기반한 주파수 패턴 정보를 송신할 수 있다. 응답에 응답자가 음성 에이전트임을 나타내는 정보가 포함되어 있지 않은 경우(예: 동작 720-No), 동작 730 에서, 전자 장치는 음성 호 통신을 통해 태스크와 연관된 정보를 송신할 수 있다. 예를 들어, 응답자가 외 부 전자 장치의 사용자이면, 전자 장치는 외부 전자 장치와 음성 호 통신을 통해 음성 정보를 교환 하여 태스크를 수행할 수 있다. 응답에 응답자가 음성 에이전트임을 나타내는 정보가 포함되어 있는 경우(예: 동작 720-Yes), 동작 740에서, 전자 장치는 사용자 입력에 기반하여 식별된 태스크를 수행하기 위해, 태스크와 연관된 정보의 크 기가 지정된 크기 이상인지 결정할 수 있다. 일 실시 예에서, 전자 장치는 사용자 입력에 기반하여 식별된 태스크를 수행하기 위해, 태스크와 연관된 정보를 포함하는 데이터 정보를 외부 전자 장치에 송신할 수 있 다. 예를 들어, 전자 장치는 '식당 예약'에 관한 태스크를 수행하는 경우, 예약에 필요한 정보를 포함하는 데이터 정보를 식당(예: 외부 전자 장치)에 송신할 수 있다. 이 경우, 전자 장치는 예약에 필요한 정보 의 크기가 지정된 크기 이상인지 여부를 결정할 수 있다. 예를 들어, 지정된 크기는 RTP(Real-time Transport Protocol)를 이용하여 송신할 수 있는 데이터 정보의 최대 크기에 대응할 수 있다. 외부 전자 장치에 송신하려는 데이터 정보의 크기가 지정된 크기보다 작은 경우(예: 동작 740-No), 동작 730에서, 전자 장치는 데이터 정보를 제1 세션을 통해 외부 전자 장치에 송신할 수 있다. 예를 들어, 외부 전자 장치에 송신하려는 데이터 정보의 크기가 작아 RTP를 이용하여 송신할 수 있으면, 전자 장치(1 0)는 RTP를 이용한 제1 세션을 통해 데이터 정보를 송신할 수 있다. 또한, 도 7에는 외부 전자 장치에 송신 하려는 데이터 정보의 크기가 지정된 크기보다 작은 경우(예: 동작 740-No), 음성 호 통신을 통해 데이터 정보 를 송신하는 것으로 도시되어 있지만, 전자 장치는 TCP를 이용하여 데이터 통신을 통해서도 상기 데이터 정 보를 송신할 수도 있다. 외부 전자 장치에 송신하려는 데이터 정보의 크기가 지정된 크기 이상인 경우(예: 동작 740-Yes), 동작 750 에서, 전자 장치는 외부 전자 장치에 데이터 통신을 위한 제2 세션의 설정을 요청할 수 있다. 데이터 통신을 위한 제2 세션의 연결 절차는 TCP(Transmission Control Protocol)를 이용한 통신 연결 절차에 대응할 수 있다. 전자 장치는 외부 전자 장치의 응답자가 음성 에이전트라고 결정한 경우, 외부 전자 장치 에 데이터 통신을 위한 제2 세션의 설정을 요청하여 데이터 정보를 교환할 수 있다. 전자 장치는 제1 세션을 통해 음성 호 통신을 하는 경우에 RTP를 이용하는 반면에, 제2 세션을 통해 데이터 통신을 하는 경우에는 TCP(Transmission Control Protocol)를 이용할 수 있다. 다만, 전자 장치는 제1 세 션을 통해서도 데이터 통신을 할 수 있다. 이 경우, 전자 장치는 RTP를 통해 데이터 통신을 할 수 있다.동작 760에서, 전자 장치는 데이터 통신을 통해 태스크와 연관된 데이터 정보를 송신할 수 있다. 일 예에서, 전자 장치는 데이터 정보를 데이터 통신을 위한 제2 세션을 통해 외부 전자 장치에 송신할 수 있다. 예를 들어, 외부 전자 장치에 송신하려는 데이터 정보의 크기가 커서 RTP를 이용하여 송신할 수 없으 면, 전자 장치는 TCP를 이용하여 제2 세션을 통해 데이터 정보를 송신할 수 있다. 도 8은 일 실시 예에 따른, 전자 장치의 음성 에이전트가 외부 전자 장치에 음성 호 통신을 위한 제1 세션의 설 정을 요청하는 경우에 표시되는 인터페이스의 도면이다. 도 2 및 8을 참조하면, 전자 장치는 사용자로부터 사용자 입력을 획득할 수 있다. 예를 들어, 사용자 입력 은 음성 입력 또는 터치 입력 중 적어도 하나를 포함할 수 있다. 일 실시 예에서, 전자 장치의 음성 에이전 트는 사용자 입력에 기반하여 태스크를 식별할 수 있다. 전자 장치의 음성 에이전트는 식별한 태스 크를 수행하기 위해 외부의 전자 장치(예: 외부 전자 장치)에 음성 통신을 할 수 있다. 전자 장치의 음성 에이전트가 외부 전자 장치와 음성 통신을 할 때, 제1 어포던스 (affordance)가 전자 장치의 디스플레이에 표시될 수 있다. 예를 들어, 제1 어포던스는 음 성 에이전트임을 나타내는 이미지를 포함할 수 있다. 외부 전자 장치는 전자 장치의 음성 에이전트 와 음성 통신을 하는 경우, 제2 어포던스를 디스플레이에 표시할 수 있다. 예를 들어, 제2 어포던스 는 음성 통신을 하는 상대방이 음성 에이전트임을 나타내는 이미지를 포함할 수 있다. 외부 전자 장치 의 사용자는 제2 어포던스를 통해 전자 장치의 응답자가 음성 에이전트임을 알 수 있다. 여기서 사용된 용어 \"어포던스\"는 전자 장치(예: 전자 장치, 외부 전자 장치)의 디스플레이 화면에 선 택적으로 표시될 수 있는 사용자 상호작용형 GUI(graphical user interface) 객체(object)를 포함할 수 있다. 예를 들어, 어포던스는 이미지(예: 아이콘), 버튼 또는 텍스트(예: 하이퍼링크) 중 적어도 하나를 포함할 수 있 다. 도 9는 일 실시 예에 따른, 전자 장치가 외부 전자 장치와 음성 호 통신을 위한 제1 세션을 설정하는 흐름도이 다. 도 9를 참조하면, 전자 장치는 외부 전자 장치와 음성 호 통신을 위한 제1 세션을 개시하기 위해 SIP(Session Initiation Protocol) 및/또는 SDP(Session Description Protocol)를 이용할 수 있다. SIP는 세션 을 설정하는 프로토콜을 의미하고, SDP는 단말 간의 멀티미디어 세션과 관련된 미디어 타입 및/또는 포맷을 협 상하는 프로토콜을 의미할 수 있다. 예를 들어, 세션은 음성 통화와 데이터 전송을 위한 대화에 대응할 수 있다. 일 실시 예에서, 전자 장치는 SIP 및/또는 SDP에 기반하여 외부 전자 장치와, 미디어 서비스(예: 영상 통화 및/또는 음성 통화 서비스)를 위한 세션 설립을 위한 협상 절차를 수행할 수 있다. 동작 910에서, 전자 장치는 제1 세션의 설정을 위한 요청인 SIP INVITE 메시지를 외부 전자 장치에 송 신할 수 있다. SIP INVITE 메시지는 외부 전자 장치에 음성 호 통신을 위한 제1 세션 확립을 요청하는 메시 지를 의미할 수 있다. 예를 들어, SIP INVITE 메시지는 음성 통화나 데이터 전송 등의 서비스 관련 세션 시작을 알리거나 사용자를 초대하기 위한 메시지를 의미할 수 있다. SIP INVITE 메시지에는 SDP Offer가 포함될 수 있 다. 예를 들어, 전자 장치가 외부 전자 장치에 전화를 거는 순간, 전자 장치는 외부 전자 장치(2 0)에 SDP offer가 포함되어 있는 SIP INVITE 메시지를 송신할 수 있다. 동작 920에서, 전자 장치는 외부 전자 장치로부터 SIP INVITE 메시지의 응답 메시지인 SIP 200 OK 메시 지(예: 도 2 내지 7의 제1 세션 개시 응답)를 수신할 수 있다. SIP 200 OK 메시지에는 SDP Answer가 포함될 수 있다. 예를 들어, 외부 전자 장치가 전자 장치의 전화 통화를 연결하는 순간, 전자 장치는 SDP Answer가 포함되어 있는 SIP 200 OK 메시지를 외부 전자 장치로부터 수신할 수 있다. 동작 930에서, 전자 장치는 SIP 200 OK 메시지를 수신하면, 외부 전자 장치에 SIP ACK 메시지를 송신할 수 있다. SIP ACK 메시지의 송신에 기반하여, 전자 장치와 외부 전자 장치 사이에 음성 호 통신을 위한 제1 세션이 확립될 수 있다. 예를 들어, 전자 장치는 RTP에 기반하여 확립된 제1 세션을 통하여 외부 전자 장치와 데이터를 교환할 수 있다. 도 10은, 다양한 실시예들에 따른, 네트워크 환경 내의 전자 장치의 블록도이다. 도 10을 참조하면, 네트워크 환경에서 전자 장치는 제1 네트워크(예: 근거리 무선 통신 네트워크)를 통하여 전자 장치와 통신하거나, 또는 제2 네트워크(예: 원거리 무선 통신 네트워크)를 통하여 전 자 장치 또는 서버 중 적어도 하나와 통신할 수 있다. 일실시예에 따르면, 전자 장치는 서버를 통하여 전자 장치와 통신할 수 있다. 일실시예에 따르면, 전자 장치는 프로세서, 메모리, 입력 모듈, 음향 출력 모듈, 디스플레이 모듈, 오디오 모듈, 센서 모 듈, 인터페이스, 연결 단자, 햅틱 모듈, 카메라 모듈, 전력 관리 모듈, 배터리, 통신 모듈, 가입자 식별 모듈, 또는 안테나 모듈을 포함할 수 있다. 어떤 실 시예에서는, 전자 장치에는, 이 구성요소들 중 적어도 하나(예: 연결 단자)가 생략되거나, 하나 이 상의 다른 구성요소가 추가될 수 있다. 어떤 실시예에서는, 이 구성요소들 중 일부들(예: 센서 모듈, 카 메라 모듈, 또는 안테나 모듈)은 하나의 구성요소(예: 디스플레이 모듈)로 통합될 수 있다. 프로세서는, 예를 들면, 소프트웨어(예: 프로그램)를 실행하여 프로세서에 연결된 전자 장치 의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데 이터 처리 또는 연산을 수행할 수 있다. 일실시예에 따르면, 데이터 처리 또는 연산의 적어도 일부로서, 프로세 서는 다른 구성요소(예: 센서 모듈 또는 통신 모듈)로부터 수신된 명령 또는 데이터를 휘발 성 메모리에 저장하고, 휘발성 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 비휘 발성 메모리에 저장할 수 있다. 일실시예에 따르면, 프로세서는 메인 프로세서(예: 중앙 처 리 장치 또는 어플리케이션 프로세서) 또는 이와는 독립적으로 또는 함께 운영 가능한 보조 프로세서(예: 그래픽 처리 장치, 신경망 처리 장치(NPU: neural processing unit), 이미지 시그널 프로세서, 센서 허브 프로 세서, 또는 커뮤니케이션 프로세서)를 포함할 수 있다. 예를 들어, 전자 장치가 메인 프로세서 및 보조 프로세서를 포함하는 경우, 보조 프로세서는 메인 프로세서보다 저전력을 사용하거나, 지정된 기능에 특화되도록 설정될 수 있다. 보조 프로세서는 메인 프로세서와 별개로, 또는 그 일 부로서 구현될 수 있다. 보조 프로세서는, 예를 들면, 메인 프로세서가 인액티브(예: 슬립) 상태에 있는 동안 메인 프로세 서를 대신하여, 또는 메인 프로세서가 액티브(예: 어플리케이션 실행) 상태에 있는 동안 메인 프로 세서와 함께, 전자 장치의 구성요소들 중 적어도 하나의 구성요소(예: 디스플레이 모듈, 센 서 모듈, 또는 통신 모듈)와 관련된 기능 또는 상태들의 적어도 일부를 제어할 수 있다. 일실시예 에 따르면, 보조 프로세서(예: 이미지 시그널 프로세서 또는 커뮤니케이션 프로세서)는 기능적으로 관련 있는 다른 구성요소(예: 카메라 모듈 또는 통신 모듈)의 일부로서 구현될 수 있다. 일실시예에 따 르면, 보조 프로세서(예: 신경망 처리 장치)는 인공지능 모델의 처리에 특화된 하드웨어 구조를 포함할 수 있다. 인공지능 모델은 기계 학습을 통해 생성될 수 있다. 이러한 학습은, 예를 들어, 인공지능 모델이 수행 되는 전자 장치 자체에서 수행될 수 있고, 별도의 서버(예: 서버)를 통해 수행될 수도 있다. 학습 알고리즘은, 예를 들어, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경 망(DNN: deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 하드웨어 구조 이외에, 추가적으로 또는 대체적으로, 소프트웨어 구조를 포 함할 수 있다. 메모리는, 전자 장치의 적어도 하나의 구성요소(예: 프로세서 또는 센서 모듈)에 의해 사용되는 다양한 데이터를 저장할 수 있다. 데이터는, 예를 들어, 소프트웨어(예: 프로그램) 및, 이와 관 련된 명령에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있다. 메모리는, 휘발성 메모리 또는 비휘발성 메모리를 포함할 수 있다. 프로그램은 메모리에 소프트웨어로서 저장될 수 있으며, 예를 들면, 운영 체제, 미들 웨어 또는 어플리케이션을 포함할 수 있다. 입력 모듈은, 전자 장치의 구성요소(예: 프로세서)에 사용될 명령 또는 데이터를 전자 장치 의 외부(예: 사용자)로부터 수신할 수 있다. 입력 모듈은, 예를 들면, 마이크, 마우스, 키보드, 키 (예: 버튼), 또는 디지털 펜(예: 스타일러스 펜)을 포함할 수 있다. 음향 출력 모듈은 음향 신호를 전자 장치의 외부로 출력할 수 있다. 음향 출력 모듈은, 예를 들면, 스피커 또는 리시버를 포함할 수 있다. 스피커는 멀티미디어 재생 또는 녹음 재생과 같이 일반적인 용도 로 사용될 수 있다. 리시버는 착신 전화를 수신하기 위해 사용될 수 있다. 일실시예에 따르면, 리시버는 스피커와 별개로, 또는 그 일부로서 구현될 수 있다. 디스플레이 모듈은 전자 장치의 외부(예: 사용자)로 정보를 시각적으로 제공할 수 있다. 디스플레 이 모듈은, 예를 들면, 디스플레이, 홀로그램 장치, 또는 프로젝터 및 해당 장치를 제어하기 위한 제어 회로를 포함할 수 있다. 일실시예에 따르면, 디스플레이 모듈은 터치를 감지하도록 설정된 터치 센서, 또 는 상기 터치에 의해 발생되는 힘의 세기를 측정하도록 설정된 압력 센서를 포함할 수 있다. 오디오 모듈은 소리를 전기 신호로 변환시키거나, 반대로 전기 신호를 소리로 변환시킬 수 있다. 일실시 예에 따르면, 오디오 모듈은, 입력 모듈을 통해 소리를 획득하거나, 음향 출력 모듈, 또는 전자 장치와 직접 또는 무선으로 연결된 외부 전자 장치(예: 전자 장치)(예: 스피커 또는 헤드폰) 를 통해 소리를 출력할 수 있다. 센서 모듈은 전자 장치의 작동 상태(예: 전력 또는 온도), 또는 외부의 환경 상태(예: 사용자 상태)를 감지하고, 감지된 상태에 대응하는 전기 신호 또는 데이터 값을 생성할 수 있다. 일실시예에 따르면, 센서 모듈은, 예를 들면, 제스처 센서, 자이로 센서, 기압 센서, 마그네틱 센서, 가속도 센서, 그립 센서, 근접 센서, 컬러 센서, IR(infrared) 센서, 생체 센서, 온도 센서, 습도 센서, 또는 조도 센서를 포함할 수 있다. 인터페이스는 전자 장치가 외부 전자 장치(예: 전자 장치)와 직접 또는 무선으로 연결되기 위해 사용될 수 있는 하나 이상의 지정된 프로토콜들을 지원할 수 있다. 일실시예에 따르면, 인터페이스 는, 예를 들면, HDMI(high definition multimedia interface), USB(universal serial bus) 인터페이스, SD카드 인터페이스, 또는 오디오 인터페이스를 포함할 수 있다. 연결 단자는, 그를 통해서 전자 장치가 외부 전자 장치(예: 전자 장치)와 물리적으로 연결될 수 있는 커넥터를 포함할 수 있다. 일실시예에 따르면, 연결 단자는, 예를 들면, HDMI 커넥터, USB 커넥 터, SD 카드 커넥터, 또는 오디오 커넥터(예: 헤드폰 커넥터)를 포함할 수 있다. 햅틱 모듈은 전기적 신호를 사용자가 촉각 또는 운동 감각을 통해서 인지할 수 있는 기계적인 자극(예: 진동 또는 움직임) 또는 전기적인 자극으로 변환할 수 있다. 일실시예에 따르면, 햅틱 모듈은, 예를 들면, 모터, 압전 소자, 또는 전기 자극 장치를 포함할 수 있다. 카메라 모듈은 정지 영상 및 동영상을 촬영할 수 있다. 일실시예에 따르면, 카메라 모듈은 하나 이 상의 렌즈들, 이미지 센서들, 이미지 시그널 프로세서들, 또는 플래시들을 포함할 수 있다. 전력 관리 모듈은 전자 장치에 공급되는 전력을 관리할 수 있다. 일실시예에 따르면, 전력 관리 모 듈은, 예를 들면, PMIC(power management integrated circuit)의 적어도 일부로서 구현될 수 있다. 배터리는 전자 장치의 적어도 하나의 구성요소에 전력을 공급할 수 있다. 일실시예에 따르면, 배터 리는, 예를 들면, 재충전 불가능한 1차 전지, 재충전 가능한 2차 전지 또는 연료 전지를 포함할 수 있다. 통신 모듈은 전자 장치와 외부 전자 장치(예: 전자 장치, 전자 장치, 또는 서버 ) 간의 직접(예: 유선) 통신 채널 또는 무선 통신 채널의 수립, 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 통신 모듈은 프로세서(예: 어플리케이션 프로세서)와 독립적으로 운영되고, 직접 (예: 유선) 통신 또는 무선 통신을 지원하는 하나 이상의 커뮤니케이션 프로세서를 포함할 수 있다. 일실시예에 따르면, 통신 모듈은 무선 통신 모듈(예: 셀룰러 통신 모듈, 근거리 무선 통신 모듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예: LAN(local area network) 통신 모듈, 또는 전력선 통신 모듈)을 포함할 수 있다. 이들 통신 모듈 중 해당하는 통신 모듈은 제1 네트워크(예: 블루투스, WiFi(wireless fidelity) direct 또는 IrDA(infrared data association)와 같은 근거리 통신 네트워크) 또는 제2 네트워크(예: 레거시 셀룰러 네트워크, 5G 네트워크, 차세대 통신 네트 워크, 인터넷, 또는 컴퓨터 네트워크(예: LAN 또는 WAN)와 같은 원거리 통신 네트워크)를 통하여 외부의 전자 장치와 통신할 수 있다. 이런 여러 종류의 통신 모듈들은 하나의 구성요소(예: 단일 칩)로 통합되거나, 또는 서로 별도의 복수의 구성요소들(예: 복수 칩들)로 구현될 수 있다. 무선 통신 모듈은 가입자 식별 모듈에 저장된 가입자 정보(예: 국제 모바일 가입자 식별자(IMSI))를 이용하여 제1 네트워크 또는 제2 네트워크와 같은 통신 네트워크 내에서 전자 장치를 확인 또는 인증할 수 있다. 무선 통신 모듈은 4G 네트워크 이후의 5G 네트워크 및 차세대 통신 기술, 예를 들어, NR 접속 기술(new radio access technology)을 지원할 수 있다. NR 접속 기술은 고용량 데이터의 고속 전송(eMBB(enhancedmobile broadband)), 단말 전력 최소화와 다수 단말의 접속(mMTC(massive machine type communications)), 또 는 고신뢰도와 저지연(URLLC(ultra-reliable and low-latency communications))을 지원할 수 있다. 무선 통신 모듈은, 예를 들어, 높은 데이터 전송률 달성을 위해, 고주파 대역(예: mmWave 대역)을 지원할 수 있다. 무선 통신 모듈은 고주파 대역에서의 성능 확보를 위한 다양한 기술들, 예를 들어, 빔포밍(beamforming), 거대 배열 다중 입출력(massive MIMO(multiple-input and multiple-output)), 전차원 다중입출력(FD-MIMO: full dimensional MIMO), 어레이 안테나(array antenna), 아날로그 빔형성(analog beam-forming), 또는 대규모 안테나(large scale antenna)와 같은 기술들을 지원할 수 있다. 무선 통신 모듈은 전자 장치, 외 부 전자 장치(예: 전자 장치) 또는 네트워크 시스템(예: 제2 네트워크)에 규정되는 다양한 요구사 항을 지원할 수 있다. 일실시예에 따르면, 무선 통신 모듈은 eMBB 실현을 위한 Peak data rate(예: 20Gbps 이상), mMTC 실현을 위한 손실 Coverage(예: 164dB 이하), 또는 URLLC 실현을 위한 U-plane latency(예: 다운링크(DL) 및 업링크(UL) 각각 0.5ms 이하, 또는 라운드 트립 1ms 이하)를 지원할 수 있다. 안테나 모듈은 신호 또는 전력을 외부(예: 외부의 전자 장치)로 송신하거나 외부로부터 수신할 수 있다. 일실시예에 따르면, 안테나 모듈은 서브스트레이트(예: PCB) 위에 형성된 도전체 또는 도전성 패턴으로 이루어진 방사체를 포함하는 안테나를 포함할 수 있다. 일실시예에 따르면, 안테나 모듈은 복수의 안테나 들(예: 어레이 안테나)을 포함할 수 있다. 이런 경우, 제1 네트워크 또는 제2 네트워크와 같은 통 신 네트워크에서 사용되는 통신 방식에 적합한 적어도 하나의 안테나가, 예를 들면, 통신 모듈에 의하여 상기 복수의 안테나들로부터 선택될 수 있다. 신호 또는 전력은 상기 선택된 적어도 하나의 안테나를 통하여 통 신 모듈과 외부의 전자 장치 간에 송신되거나 수신될 수 있다. 어떤 실시예에 따르면, 방사체 이외에 다 른 부품(예: RFIC(radio frequency integrated circuit))이 추가로 안테나 모듈의 일부로 형성될 수 있 다. 다양한 실시예에 따르면, 안테나 모듈은 mmWave 안테나 모듈을 형성할 수 있다. 일실시예에 따르면, mmWave 안테나 모듈은 인쇄 회로 기판, 상기 인쇄 회로 기판의 제1 면(예: 아래 면)에 또는 그에 인접하여 배치 되고 지정된 고주파 대역(예: mmWave 대역)을 지원할 수 있는 RFIC, 및 상기 인쇄 회로 기판의 제2 면(예: 윗 면 또는 측 면)에 또는 그에 인접하여 배치되고 상기 지정된 고주파 대역의 신호를 송신 또는 수신할 수 있는 복수의 안테나들(예: 어레이 안테나)을 포함할 수 있다. 상기 구성요소들 중 적어도 일부는 주변 기기들간 통신 방식(예: 버스, GPIO(general purpose input and output), SPI(serial peripheral interface), 또는 MIPI(mobile industry processor interface))을 통해 서로 연결되고 신호(예: 명령 또는 데이터)를 상호간에 교환할 수 있다. 일실시예에 따르면, 명령 또는 데이터는 제2 네트워크에 연결된 서버를 통해서 전자 장치와 외부의 전자 장치간에 송신 또는 수신될 수 있다. 외부의 전자 장치(1002, 또는 1004) 각각은 전자 장치 와 동일한 또는 다른 종류의 장치일 수 있다. 일실시예에 따르면, 전자 장치에서 실행되는 동작들 의 전부 또는 일부는 외부의 전자 장치들(1002, 1004, 또는 1008) 중 하나 이상의 외부의 전자 장치들에서 실행 될 수 있다. 예를 들면, 전자 장치가 어떤 기능이나 서비스를 자동으로, 또는 사용자 또는 다른 장치로부 터의 요청에 반응하여 수행해야 할 경우에, 전자 장치는 기능 또는 서비스를 자체적으로 실행시키는 대신 에 또는 추가적으로, 하나 이상의 외부의 전자 장치들에게 그 기능 또는 그 서비스의 적어도 일부를 수행하라고 요청할 수 있다. 상기 요청을 수신한 하나 이상의 외부의 전자 장치들은 요청된 기능 또는 서비스의 적어도 일 부, 또는 상기 요청과 관련된 추가 기능 또는 서비스를 실행하고, 그 실행의 결과를 전자 장치로 전달할 수 있다. 전자 장치는 상기 결과를, 그대로 또는 추가적으로 처리하여, 상기 요청에 대한 응답의 적어도 일부로서 제공할 수 있다. 이를 위하여, 예를 들면, 클라우드 컴퓨팅, 분산 컴퓨팅, 모바일 에지 컴퓨팅(MEC: mobile edge computing), 또는 클라이언트-서버 컴퓨팅 기술이 이용될 수 있다. 전자 장치는, 예를 들어, 분산 컴퓨팅 또는 모바일 에지 컴퓨팅을 이용하여 초저지연 서비스를 제공할 수 있다. 다른 실시예에 있 어서, 외부의 전자 장치는 IoT(internet of things) 기기를 포함할 수 있다. 서버는 기계 학습 및 /또는 신경망을 이용한 지능형 서버일 수 있다. 일실시예에 따르면, 외부의 전자 장치 또는 서버는 제2 네트워크 내에 포함될 수 있다. 전자 장치는 5G 통신 기술 및 IoT 관련 기술을 기반으로 지능 형 서비스(예: 스마트 홈, 스마트 시티, 스마트 카, 또는 헬스 케어)에 적용될 수 있다. 도 11는 일 실시예에 따른 통합 지능 (integrated intelligence) 시스템을 나타낸 블록도이다. 도 11를 참조하면, 일 실시예의 통합 지능 시스템은 사용자 단말, 지능형 서버, 및 서비스 서버 를 포함할 수 있다. 일 실시 예의 사용자 단말(예: 도 10의 전자 장치)은, 인터넷에 연결 가능한 단말 장치(또는, 전자 장치)일 수 있으며, 예를 들어, 휴대폰, 스마트폰, PDA(personal digital assistant), 노트북 컴퓨터, TV(television), 백색 가전, 웨어러블 장치, HMD (head mounted device), 또는 스마트 스피커일 수 있다. 도시된 실시 예에 따르면, 사용자 단말은 통신 인터페이스, 마이크, 스피커, 디스플레 이, 메모리, 및/또는 프로세서를 포함할 수 있다. 상기 열거된 구성요소들은 서로 작동적으 로 또는 전기적으로 연결될 수 있다. 통신 인터페이스(예: 도 10의 통신 모듈)는 외부 장치와 연결되어 데이터를 교화하도록 구성될 수 있다. 마이크(예: 도 10의 오디오 모듈)는 소리(예: 사용자 발화)를 수신하여, 전기적 신호로 변환 할 수 있다. 스피커(예: 도 10의 음향 출력 모듈)는 전기적 신호를 소리(예: 음성)로 출력할 수 있 다. 디스플레이(예: 도 10의 디스플레이 모듈)는 이미지 또는 비디오를 표시하도록 구성될 수 있다. 일 실시 예의 디스플레이는 또한 실행되는 앱(app)(또는, 어플리케이션 프로그램(application program))의 그래픽 사용자 인터페이스(graphic user interface, GUI)를 표시할 수 있다. 일 실시 예의 메모리(예: 도 10의 메모리)는 클라이언트 모듈, SDK(software development kit), 및 복수의 어플리케이션들을 저장할 수 있다. 상기 클라이언트 모듈, 및 SDK는 범용 적인 기능을 수행하기 위한 프레임워크(framework)(또는, 솔루션 프로그램)를 구성할 수 있다. 또한, 클라이언 트 모듈 또는 SDK는 음성 입력을 처리하기 위한 프레임워크를 구성할 수 있다. 상기 복수의 어플리케이션들(예: 1135a, 1135b)은 지정된 기능을 수행하기 위한 프로그램일 수 있다. 일 실시 예에 따르면, 복수의 어플리케이션들은 제1 앱(1135a), 및/또는 제2 앱(1135b)을 포함할 수 있다. 일 실시 예에 따르면, 복수의 어플리케이션들 각각은 지정된 기능을 수행하기 위한 복수의 동작들을 포함할 수 있다. 예를 들어, 상기 어플리케이션들은, 알람 앱, 메시지 앱, 및/또는 스케줄 앱을 포함할 수 있다. 일 실시 예에 따르 면, 복수의 어플리케이션들은 프로세서에 의해 실행되어 상기 복수의 동작들 중 적어도 일부를 순차적으 로 실행할 수 있다. 일 실시 예의 프로세서는 사용자 단말의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서 는 통신 인터페이스, 마이크, 스피커, 및 디스플레이와 전기적으로 연결되어 지 정된 동작을 수행할 수 있다. 예를 들어, 프로세서는 적어도 하나의 프로세서를 포함할 수 있다. 일 실시 예의 프로세서는 또한 상기 메모리에 저장된 프로그램을 실행하여 지정된 기능을 수행할 수 있다. 예를 들어, 프로세서는 클라이언트 모듈 또는 SDK 중 적어도 하나를 실행하여, 음 성 입력을 처리하기 위한 이하의 동작을 수행할 수 있다. 프로세서는, 예를 들어, SDK를 통해 복수 의 어플리케이션들의 동작을 제어할 수 있다. 클라이언트 모듈 또는 SDK의 동작으로 설명된 이하 의 동작들은 프로세서의 실행에 의하여 수행되는 동작일 수 있다. 일 실시 예의 클라이언트 모듈은 음성 입력을 수신할 수 있다. 예를 들어, 클라이언트 모듈은 마이 크를 통해 감지된 사용자 발화에 대응되는 음성 신호를 수신할 수 있다. 상기 클라이언트 모듈은 수신된 음성 입력(예: 음성 신호)을 지능형 서버로 송신할 수 있다. 클라이언트 모듈은 수신된 음 성 입력과 함께, 사용자 단말의 상태 정보를 지능형 서버로 송신할 수 있다. 상기 상태 정보는, 예 를 들어, 앱의 실행 상태 정보일 수 있다. 일 실시 예의 클라이언트 모듈은 수신된 음성 입력에 대응되는 결과를 지능형 서버로부터 수신할 수 있다. 예를 들어, 클라이언트 모듈은 지능형 서버에서 상기 수신된 음성 입력에 대응되는 결과 를 산출할 수 있는 경우, 수신된 음성 입력에 대응되는 결과를 수신할 수 있다. 클라이언트 모듈은 상기 수신된 결과를 디스플레이에 표시할 수 있다. 일 실시 예의 클라이언트 모듈은 수신된 음성 입력에 대응되는 플랜을 수신할 수 있다. 클라이언트 모듈 은 플랜에 따라 앱의 복수의 동작을 실행한 결과를 디스플레이에 표시할 수 있다. 클라이언트 모듈 은, 예를 들어, 복수의 동작의 실행 결과를 순차적으로 디스플레이에 표시할 수 있다. 사용자 단말(110 1)은, 다른 예를 들어, 복수의 동작을 실행한 일부 결과(예: 마지막 동작의 결과)만을 디스플레이에 표시할 수 있다. 일 실시 예에 따르면, 클라이언트 모듈은 지능형 서버로부터 음성 입력에 대응되는 결과를 산출하 기 위해 필요한 정보를 획득하기 위한 요청을 수신할 수 있다. 일 실시 예에 따르면, 클라이언트 모듈은상기 요청에 대응하여 상기 필요한 정보를 지능형 서버로 송신할 수 있다. 일 실시 예의 클라이언트 모듈은 플랜에 따라 복수의 동작을 실행한 결과 정보를 지능형 서버로 송 신할 수 있다. 지능형 서버는 상기 결과 정보를 이용하여 수신된 음성 입력이 올바르게 처리된 것을 확인 할 수 있다. 일 실시 예의 클라이언트 모듈은 음성 인식 모듈을 포함할 수 있다. 일 실시 예에 따르면, 클라이언트 모 듈은 상기 음성 인식 모듈을 통해 제한된 기능을 수행하는 음성 입력을 인식할 수 있다. 예를 들어, 클라 이언트 모듈은 지정된 음성 입력(예: 웨이크 업!)에 대응하여 유기적인 동작을 수행함으로써 음성 입력을 처리하기 위한 지능형 앱을 실행할 수 있다. 일 실시 예의 지능형 서버는 네트워크(예: 도 10의 제1 네트워크 및/또는 제2 네트워크 )를 통해 사용자 단말로부터 사용자 음성 입력과 관련된 정보를 수신할 수 있다. 일 실시 예에 따 르면, 지능형 서버는 수신된 음성 입력과 관련된 데이터를 텍스트 데이터(text data)로 변경할 수 있다. 일 실시 예에 따르면, 지능형 서버는 상기 텍스트 데이터에 기초하여 사용자 음성 입력과 대응되는 태스 크(task)를 수행하기 위한 적어도 하나의 플랜(plan)을 생성할 수 있다 일 실시 예에 따르면, 플랜은 인공 지능(artificial intelligent)(AI) 시스템에 의해 생성될 수 있다. 인공지능 시스템은 룰 베이스 시스템(rule-based system) 일 수도 있고, 신경망 베이스 시스템(neural network-based system)(예: 피드포워드 신경망(feedforward neural network(FNN)), 및/또는 순환 신경망(recurrent neural network(RNN))) 일 수도 있다. 또는, 전술한 것의 조합 또는 이와 다른 인공지능 시스템일 수도 있다. 일 실시 예에 따르면, 플랜은 미리 정의된 플랜들의 집합에서 선택될 수 있거나, 사용자 요청에 응답하여 실시간으로 생 성될 수 있다. 예를 들어, 인공지능 시스템은 미리 정의된 복수의 플랜들 중 적어도 하나의 플랜을 선택할 수 있다. 일 실시 예의 지능형 서버는 생성된 플랜에 따른 결과를 사용자 단말로 송신하거나, 생성된 플랜을 사용자 단말로 송신할 수 있다. 일 실시 예에 따르면, 사용자 단말은 플랜에 따른 결과를 디스플레 이에 표시할 수 있다. 일 실시 예에 따르면, 사용자 단말은 플랜에 따른 동작을 실행한 결과를 디 스플레이에 표시할 수 있다. 일 실시 예의 지능형 서버는 프론트 엔드(front end), 자연어 플랫폼(natural language platform), 캡슐 데이터베이스(capsule database), 실행 엔진(execution engine), 엔드 유 저 인터페이스(end user interface), 매니지먼트 플랫폼(management platform), 빅 데이터 플랫폼 (big data platform), 또는 분석 플랫폼(analytic platform)을 포함할 수 있다. 일 실시 예의 프론트 엔드는 사용자 단말에 의하여 수신된 음성 입력을 사용자 단말로부터 수신할 수 있다. 프론트 엔드는 상기 음성 입력에 대응되는 응답을 사용자 단말로 송신할 수 있다. 일 실시 예에 따르면, 자연어 플랫폼은 자동 음성 인식 모듈(automatic speech recognition module)(ASR module), 자연어 이해 모듈(natural language understanding module)(NLU module), 플래너 모듈 (planner module), 자연어 생성 모듈(natural language generator module)(NLG module), 및/또는 텍스트 음성 변환 모듈(text to speech module)(TTS module)을 포함할 수 있다. 일 실시 예의 자동 음성 인식 모듈은 사용자 단말로부터 수신된 음성 입력을 텍스트 데이터로 변환 할 수 있다. 일 실시 예의 자연어 이해 모듈은 음성 입력의 텍스트 데이터를 이용하여 사용자의 의도를 결정할 수 있다. 예를 들어, 자연어 이해 모듈은 문법적 분석(syntactic analyze) 및/또는 의미적 분석 (semantic analyze)을 수행하여 사용자의 의도를 결정할 수 있다. 일 실시 예의 자연어 이해 모듈은 형태 소 또는 구의 언어적 특징(예: 문법적 요소)을 이용하여 음성 입력으로부터 추출된 단어의 의미를 파악하고, 상 기 파악된 단어의 의미를 의도에 매칭시켜 사용자의 의도를 결정할 수 있다. 일 실시 예의 플래너 모듈은 자연어 이해 모듈에서 결정된 의도 및 파라미터를 이용하여 플랜을 생 성할 수 있다. 일 실시 예에 따르면, 플래너 모듈은 상기 결정된 의도에 기초하여 태스크를 수행하기 위 해 필요한 복수의 도메인을 결정할 수 있다. 플래너 모듈은 상기 의도에 기초하여 결정된 복수의 도메인 각각에 포함된 복수의 동작을 결정할 수 있다. 일 실시 예에 따르면, 플래너 모듈은 상기 결정된 복수의 동작을 실행하는데 필요한 파라미터나, 상기 복수의 동작의 실행에 의해 출력되는 결과 값을 결정할 수 있다. 상기 파라미터, 및 상기 결과 값은 지정된 형식(또는, 클래스)의 컨셉으로 정의될 수 있다. 이에 따라, 플랜은 사용자의 의도에 의해 결정된 복수의 동작, 및/또는 복수의 컨셉을 포함할 수 있다. 상기 플래너 모듈은상기 복수의 동작, 및 상기 복수의 컨셉 사이의 관계를 단계적(또는, 계층적)으로 결정할 수 있다. 예를 들어, 플래너 모듈은 복수의 컨셉에 기초하여 사용자의 의도에 기초하여 결정된 복수의 동작의 실행 순서를 결 정할 수 있다. 다시 말해, 플래너 모듈은 복수의 동작의 실행에 필요한 파라미터, 및 복수의 동작의 실행 에 의해 출력되는 결과에 기초하여, 복수의 동작의 실행 순서를 결정할 수 있다. 이에 따라, 플래너 모듈(122 5)은 복수의 동작 및 복수의 컨셉 사이의 연관 정보(예: 온톨로지(ontology))가 포함된 플랜을 생성할 수 있다. 상기 플래너 모듈은 컨셉과 동작의 관계들의 집합이 저장된 캡슐 데이터베이스에 저장된 정보를 이 용하여 플랜을 생성할 수 있다. 일 실시 예의 자연어 생성 모듈은 지정된 정보를 텍스트 형태로 변경할 수 있다. 상기 텍스트 형태로 변 경된 정보는 자연어 발화의 형태일 수 있다. 일 실시 예의 텍스트 음성 변환 모듈은 텍스트 형태의 정보 를 음성 형태의 정보로 변경할 수 있다. 일 실시 예에 따르면, 자연어 플랫폼의 기능의 일부 기능 또는 전체 기능은 사용자 단말에서도 구 현가능 할 수 있다. 예를 들어, 사용자 단말이 자동 음성 인식 모듈 및/또는 자연어 이해 모듈을 포함할 수 있다. 사용자 단말이 사용자 음성 입력을 인식한 뒤, 인식된 음성 입력에 대응하는 데이터 정보를 지 능형 서버로 송신할 수 있다. 예를 들어, 사용자 단말이 텍스트 음성 변환 모듈을 포함할 수 있다. 사용자 단말이 지능형 서버로부터 데이터 정보를 수신하고, 수신된 데이터 정보를 음성으로 출력할 수 있다. 상기 캡슐 데이터베이스는 복수의 도메인에 대응되는 복수의 컨셉과 동작들의 관계에 대한 정보를 저장할 수 있다. 일 실시예에 따른 캡슐은 플랜에 포함된 복수의 동작 오브젝트(action object)(또는 동작 정보) 및/또 는 컨셉 오브젝트(concept object)(또는 컨셉 정보)를 포함할 수 있다. 일 실시 예에 따르면, 캡슐 데이터베이 스는 CAN(concept action network)의 형태로 복수의 캡슐을 저장할 수 있다. 일 실시 예에 따르면, 복수 의 캡슐은 캡슐 데이터베이스에 포함된 기능 저장소(function registry)에 저장될 수 있다. 상기 캡슐 데이터베이스는 음성 입력에 대응되는 플랜을 결정할 때 필요한 전략 정보가 저장된 전략 레지 스트리(strategy registry)를 포함할 수 있다. 상기 전략 정보는 음성 입력에 대응되는 복수의 플랜이 있는 경 우, 하나의 플랜을 결정하기 위한 기준 정보를 포함할 수 있다. 일 실시 예에 따르면, 캡슐 데이터베이스(123 0)는 지정된 상황에서 사용자에게 후속 동작을 제안하기 위한 후속 동작의 정보가 저장된 후속 동작 레지스트리 (follow up registry)를 포함할 수 있다. 상기 후속 동작은, 예를 들어, 후속 발화를 포함할 수 있다. 일 실시 예에 따르면, 캡슐 데이터베이스는 사용자 단말을 통해 출력되는 정보의 레이아웃(layout) 정보를 저장하는 레이아웃 레지스트리(layout registry)를 포함할 수 있다. 일 실시 예에 따르면, 캡슐 데이터베이스 는 캡슐 정보에 포함된 어휘(vocabulary) 정보가 저장된 어휘 레지스트리(vocabulary registry)를 포함 할 수 있다. 일 실시 예에 따르면, 캡슐 데이터베이스는 사용자와의 대화(dialog)(또는, 인터렉션 (interaction)) 정보가 저장된 대화 레지스트리(dialog registry)를 포함할 수 있다. 상기 캡슐 데이터베이스 는 개발자 툴(developer tool)을 통해 저장된 오브젝트를 업데이트(update)할 수 있다. 상기 개발자 툴은, 예를 들어, 동작 오브젝트 또는 컨셉 오브젝트를 업데이트하기 위한 기능 에디터(function editor)를 포 함할 수 있다. 상기 개발자 툴은 어휘를 업데이트하기 위한 어휘 에디터(vocabulary editor)를 포함할 수 있다. 상기 개발자 툴은 플랜을 결정하는 전략을 생성 및 등록하는 전략 에디터(strategy editor)를 포함할 수 있다. 상기 개발자 툴은 사용자와의 대화를 생성하는 대화 에디터(dialog editor)를 포함할 수 있다. 상기 개발자 툴 은 후속 목표를 활성화하고, 힌트를 제공하는 후속 발화를 편집할 수 있는 후속 동작 에디터(follow up edito r)를 포함할 수 있다. 상기 후속 목표는 현재 설정된 목표, 사용자의 선호도 또는 환경 조건에 기초하여 결정될 수 있다. 일 실시 예에서는 캡슐 데이터베이스가 사용자 단말 내에도 구현될 수 있다. 일 실시 예의 실행 엔진은 상기 생성된 플랜을 이용하여 결과를 산출할 수 있다. 엔드 유저 인터페이스 는 산출된 결과를 사용자 단말로 송신할 수 있다. 이에 따라, 사용자 단말은 상기 결과를 수 신하고, 상기 수신된 결과를 사용자에게 제공할 수 있다. 일 실시 예의 매니지먼트 플랫폼은 지능형 서버 에서 이용되는 정보를 관리할 수 있다. 일 실시 예의 빅 데이터 플랫폼은 사용자의 데이터를 수집 할 수 있다. 일 실시 예의 분석 플랫폼은 지능형 서버의 QoS(quality of service)를 관리할 수 있 다. 예를 들어, 분석 플랫폼은 지능형 서버의 구성 요소 및 처리 속도(또는, 효율성)를 관리할 수 있다. 일 실시 예의 서비스 서버는 사용자 단말에 지정된 서비스(예: 음식 주문 또는 호텔 예약)를 제공 할 수 있다. 일 실시 예에 따르면, 서비스 서버는 제3 자에 의해 운영되는 서버일 수 있다. 일 실시 예의서비스 서버는 수신된 음성 입력에 대응되는 플랜을 생성하기 위한 정보를 지능형 서버에 제공할 수 있다. 상기 제공된 정보는 캡슐 데이터베이스에 저장될 수 있다. 또한, 서비스 서버는 플랜에 따른 결과 정보를 지능형 서버에 제공할 수 있다. 서비스 서버는 네트워크를 통하여 지능형 서버 및/또는 사용자 단말과 통신할 수 있다. 서비스 서버는 별도의 연결을 통하여 지능형 서버와 통신할 수 있다. 도 11에는 서비스 서버가 하나의 서버로 도시되어 있으나, 본 문서의 실시 예들이 이에 제한되는 것은 아니다. 서비스 서버의 각각의 서비스(1301, 1302, 및 1303)들 중 적어도 하 나는 별도의 서버로 구현될 수 있다. 위에 기술된 통합 지능 시스템에서, 상기 사용자 단말은, 사용자 입력에 응답하여 사용자에게 다양한 인 텔리전트 서비스를 제공할 수 있다. 상기 사용자 입력은, 예를 들어, 물리적 버튼을 통한 입력, 터치 입력 또 는 음성 입력을 포함할 수 있다. 일 실시 예에서, 상기 사용자 단말은 내부에 저장된 지능형 앱(또는, 음성 인식 앱)을 통해 음성 인식 서 비스를 제공할 수 있다. 이 경우, 예를 들어, 사용자 단말은 상기 마이크를 통해 수신된 사용자 발 화(utterance) 또는 음성 입력(voice input)을 인식하고, 인식된 음성 입력에 대응되는 서비스를 사용자에게 제 공할 수 있다. 일 실시 예에서, 사용자 단말은 수신된 음성 입력에 기초하여, 단독으로 또는 상기 지능형 서버 및 /또는 서비스 서버와 함께 지정된 동작을 수행할 수 있다. 예를 들어, 사용자 단말은 수신된 음성 입력에 대응되는 앱을 실행시키고, 실행된 앱을 통해 지정된 동작을 수행할 수 있다. 일 실시 예에서, 사용자 단말이 지능형 서버 및/또는 서비스 서버와 함께 서비스를 제공하는 경우에는, 상기 사용자 단말은, 상기 마이크를 이용하여 사용자 발화를 감지하고, 상기 감지된 사 용자 발화에 대응되는 신호(또는, 음성 데이터)를 생성할 수 있다. 상기 사용자 단말은, 상기 음성 데이 터를 통신 인터페이스를 이용하여 지능형 서버로 송신할 수 있다. 일 실시 예에 따른 지능형 서버는 사용자 단말로부터 수신된 음성 입력에 대한 응답으로써, 음성 입력에 대응되는 태스크(task)를 수행하기 위한 플랜, 또는 상기 플랜에 따라 동작을 수행한 결과를 생성할 수 있다. 상기 플랜은, 예를 들어, 사용자의 음성 입력에 대응되는 태스크(task)를 수행하기 위한 복수의 동작 및/ 또는 상기 복수의 동작과 관련된 복수의 컨셉을 포함할 수 있다. 상기 컨셉은 상기 복수의 동작의 실행에 입력 되는 파라미터나, 복수의 동작의 실행에 의해 출력되는 결과 값을 정의한 것일 수 있다. 상기 플랜은 복수의 동 작 및/또는 복수의 컨셉 사이의 연관 정보를 포함할 수 있다. 일 실시 예의 사용자 단말은, 통신 인터페이스를 이용하여 상기 응답을 수신할 수 있다. 사용자 단 말은 상기 스피커를 이용하여 사용자 단말 내부에서 생성된 음성 신호를 외부로 출력하거나, 디스플레이를 이용하여 사용자 단말 내부에서 생성된 이미지를 외부로 출력할 수 있다. 도 12는 일 실시 예에 따른, 컨셉과 동작의 관계 정보가 데이터베이스에 저장된 형태를 나타낸 도면이다. 상기 지능형 서버의 캡슐 데이터베이스(예: 캡슐 데이터베이스)는 CAN (concept action network) 형태로 캡슐을 저장할 수 있다. 상기 캡슐 데이터베이스는 사용자의 음성 입력에 대응되는 태스크를 처리하기 위한 동작, 및 상기 동작을 위해 필요한 파라미터를 CAN(concept action network) 형태로 저장될 수 있다. 상기 캡슐 데이터베이스는 복수의 도메인(예: 어플리케이션) 각각에 대응되는 복수의 캡슐(캡슐A, 캡슐 B)을 저장할 수 있다. 일 실시 예에 따르면, 하나의 캡슐(예: 캡슐A)은 하나의 도메인(예: 위치 (geo), 어플리케이션)에 대응될 수 있다. 또한, 하나의 캡슐에는 캡슐과 관련된 도메인에 대한 기능을 수행하기 위한 적어도 하나의 서비스 제공자의 캡슐(예: CP 1, CP 2 , CP3 , 및/또는 CP4 )이 대응될 수 있다. 일 실시 예에 따르면, 하나의 캡슐은 지정된 기능을 수행하기 위한 적어도 하나 이상의 동작 (1230a) 및 적어도 하나 이상의 컨셉(1230b)을 포함할 수 있다. 상기, 자연어 플랫폼은 캡슐 데이터베이스에 저장된 캡슐을 이용하여 수신된 음성 입력에 대응하는 태스크를 수행하기 위한 플랜을 생성할 수 있다. 예를 들어, 자연어 플랫폼의 플래너 모듈은 캡슐 데이터 베이스에 저장된 캡슐을 이용하여 플랜을 생성할 수 있다. 예를 들어, 캡슐 A의 동작들(1231a, 1232a)과 컨셉들(1231b, 1232b) 및 캡슐 B의 동작(1234a)과 컨셉(1234b)을 이용하여 플랜을 생성할 수 있다. 도 13은 일 실시 예에 따른 사용자 단말이 지능형 앱을 통해 수신된 음성 입력을 처리하는 화면을 나타낸 도면 이다. 사용자 단말은 지능형 서버를 통해 사용자 입력을 처리하기 위해 지능형 앱을 실행할 수 있다. 일 실시 예에 따르면, 제1 화면에서, 사용자 단말은 지정된 음성 입력(예: 웨이크 업!)을 인식하거 나 하드웨어 키(예: 전용 하드웨어 키)를 통한 입력을 수신하면, 음성 입력을 처리하기 위한 지능형 앱을 실행 할 수 있다. 사용자 단말은, 예를 들어, 스케줄 앱을 실행한 상태에서 지능형 앱을 실행할 수 있다. 일 실시 예에 따르면, 사용자 단말은 지능형 앱에 대응되는 오브젝트(예: 아이콘)를 디스플레이(116 0)에 표시할 수 있다. 일 실시 예에 따르면, 사용자 단말은 사용자 발화에 의한 음성 입력을 수신할 수 있다. 예를 들어, 사용자 단말은 \"이번주 일정 알려줘!\"라는 음성 입력을 수신할 수 있다. 일 실시 예에 따르면, 사용자 단말은 수신된 음성 입력의 텍스트 데이터가 표시된 지능형 앱의 UI(user interface)(예: 입력창)를 디스플레이에 표시할 수 있다. 일 실시 예에 따르면, 제2 화면에서, 사용자 단말은 수신된 음성 입력에 대응되는 결과를 디스플레 이에 표시할 수 있다. 예를 들어, 사용자 단말은 수신된 사용자 입력에 대응되는 플랜을 수신하고, 플랜 에 따라 '이번주 일정'을 디스플레이에 표시할 수 있다. 본 문서에 개시된 다양한 실시 예들에 따른 전자 장치는 다양한 형태의 장치가 될 수 있다. 전자 장치는, 예를 들면, 휴대용 통신 장치(예: 스마트폰), 컴퓨터 장치, 휴대용 멀티미디어 장치, 휴대용 의료 기기, 카메라, 웨 어러블 장치, 또는 가전 장치를 포함할 수 있다. 본 문서의 실시예에 따른 전자 장치는 전술한 기기들에 한정되 지 않는다. 본 문서의 다양한 실시 예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한 정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템 에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제1\", \"제2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위 해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제2) 구성요소에, \"기능적으로\" 또는 \"통신적으로\"라는 용어와 함께 또는 이런 용어 없 이, \"커플드\" 또는 \"커넥티드\"라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으 로(예: 유선으로), 무선으로, 또는 제3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서의 다양한 실시 예들에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포 함할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부가 될 수 있다. 예를 들면, 일실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형태로 구현될 수 있다. 본 문서의 다양한 실시 예들은 기기(machine)(예: 전자 장치) 의해 읽을 수 있는 저장 매체(storage medium)(예: 내장 메모리 또는 외장 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨 어(예: 프로그램)로서 구현될 수 있다. 예를 들면, 기기(예: 전자 장치)의 프로세서(예: 프로세서 )는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행 될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매체의 형태로 제공될 수 있다. 여기서, ‘비일시적’은 저장 매체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 실시 예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory(CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어™)를 통해 또는 두 개의 사용자 장치 들(예: 스마트 폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있으며, 복수의 개체 중 일부는 다른 구성요소에 분리 배치될 수도 있다. 다양한 실시 예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상 의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 상기 동 작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추가될 수 있다."}
{"patent_id": "10-2023-0159739", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따른, 전자 장치가 외부 전자 장치와 통신하는 시스템 도면이다. 도 2는 일 실시 예에 따른, 전자 장치의 구성을 나타내는 블록도이다. 도 3은 일 실시 예에 따른, 전자 장치가 외부 전자 장치와 통신하는 방법의 순서도이다. 도 4는 일 실시 예에 따른, 전자 장치가 외부 전자 장치와 통신하는 방법의 흐름도이다. 도 5는 일 실시 예에 따른, 전자 장치와 외부 전자 장치가 통신하는 방법을 나타내는 신호 흐름도이다. 도 6은 일 실시 예에 따른, 전자 장치가 외부 전자 장치의 음성 에이전트와 통신하는 방법의 순서도이다. 도 7은 일 실시 예에 따른, 전자 장치가 외부 전자 장치의 음성 에이전트와 통신하는 세부적인 방법의 순서도이 다. 도 8은 일 실시 예에 따른, 전자 장치의 음성 에이전트가 외부 전자 장치에 음성 호 통신을 위한 제1 세션의 설 정을 요청하는 경우에 표시되는 인터페이스의 도면이다. 도 9는 일 실시 예에 따른, 전자 장치가 외부 전자 장치와 음성 호 통신을 연결하는 흐름도이다. 도 10은 다양한 실시 예들에 따른, 네트워크 환경 내의 전자 장치의 블록도이다. 도 11은 일 실시 예에 따른 통합 지능 (integrated intelligence) 시스템을 나타낸 블록도이다. 도 12는 일 실시 예에 따른, 컨셉과 동작의 관계 정보가 데이터베이스에 저장된 형태를 나타낸 도면이다.도 13은 일 실시 예에 따른 사용자 단말이 지능형 앱을 통해 수신된 음성 입력을 처리하는 화면을 나타낸 도면 이다. 도면의 설명과 관련하여, 동일 또는 유사한 구성요소에 대해서는 동일 또는 유사한 참조 부호가 사용될 수 있다."}
