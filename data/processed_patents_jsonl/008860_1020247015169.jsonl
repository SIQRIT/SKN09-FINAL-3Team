{"patent_id": "10-2024-7015169", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0096506", "출원번호": "10-2024-7015169", "발명의 명칭": "효율적인 객체 검출을 위한 현저성 기반 입력 리샘플링", "출원인": "퀄컴 인코포레이티드", "발명자": "에테샤미 베이노르디, 바박"}}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 신경망(ANN: artificial neural network)을 이용하는 비디오 처리의 프로세서-구현 방법으로서,제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하는 단계;상기 비디오의 상기 제1 프레임에 기초하여 현저성 맵(saliency map)을 생성하는 단계;상기 현저성 맵에 기초하여 상기 비디오의 상기 제2 프레임을 샘플링하는 단계로서, 상기 제2 프레임의 제1 부분은 제1 해상도로 샘플링되고, 상기 제2 프레임의 제2 부분은 제2 해상도로 샘플링되고, 상기 제1 해상도는 상기 제2 해상도와 상이한, 상기 비디오의 상기 제2 프레임을 샘플링하는 단계;상기 샘플링에 기초하여 리샘플링된 제2 프레임을 생성하는 단계; 및상기 리샘플링된 제2 프레임을 처리해서 상기 비디오와 연관된 추론을 결정하는 단계를 포함하는, 인공 신경망(ANN)을 이용하는 비디오 처리의 프로세서-구현 방법."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 부분은 상기 현저성 맵에 포함된 다수의 경계 박스 중 하나의 위치에 대응하는, 인공신경망(ANN)을 이용하는 비디오 처리의 프로세서-구현 방법."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제1 부분에 대한 상기 제1 해상도는 상기 제2 해상도보다 큰, 인공 신경망(ANN)을 이용하는 비디오 처리의 프로세서-구현 방법."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 현저성 맵에 기초하여 일 세트의 제어 지점 각각에 대한 변위를 결정하는 단계;상기 일 세트의 제어 지점에 대한 상기 변위에 기초하여 균일한 격자 지점의 세트를 변환하여 샘플링 격자를 생성하는 단계; 및상기 샘플링 격자에 기초하여 상기 리샘플링된 제2 프레임을 생성하는 단계를 더 포함하는, 인공 신경망(ANN)을이용하는 비디오 처리의 프로세서-구현 방법."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 리샘플링된 제2 프레임은 학습된 줌 거동에 기초하여 생성되는, 인공 신경망(ANN)을 이용하는 비디오 처리의 프로세서-구현 방법."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 현저성 맵에 기초하여 상기 제2 프레임의 제3 부분을 제3 해상도로 샘플링하는 단계를 더포함하고, 상기 제3 해상도는 상기 제1 해상도 및 상기 제2 해상도와 상이한, 인공 신경망(ANN)을 이용하는 비디오 처리의 프로세서-구현 방법."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 ANN은 제1 신경망 모델 및 제2 신경망 모델을 포함하고, 상기 제1 신경망 모델은 상기 제2 신경망 모델보다 더 큰 처리 용량을 갖도록 구성되고, 상기 방법은,상기 제1 프레임을 상기 제1 신경망 모델을 통해 처리하는 단계; 및공개특허 10-2024-0096506-3-후속 프레임을 상기 제2 신경망 모델을 통해 처리하는 단계를 더 포함하는, 인공 신경망(ANN)을 이용하는 비디오 처리의 프로세서-구현 방법."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "인공 신경망(ANN)을 이용하는 비디오 처리 장치로서,메모리; 및상기 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는,제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하고;상기 비디오의 상기 제1 프레임에 기초하여 현저성 맵을 생성하고;상기 현저성 맵에 기초하여 상기 비디오의 상기 제2 프레임을 샘플링하는 것으로서, 상기 제2 프레임의 제1 부분은 제1 해상도로 샘플링되고, 상기 제2 프레임의 제2 부분은 제2 해상도로 샘플링되고, 상기 제1 해상도는 상기 제2 해상도와 상이한, 상기 비디오의 상기 제2 프레임을 샘플링하고;상기 샘플링에 기초하여 리샘플링된 제2 프레임을 생성하고;상기 리샘플링된 제2 프레임을 처리해서 상기 비디오와 연관된 추론을 결정하도록 구성되는, 인공 신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 제1 부분은 상기 현저성 맵에 포함된 다수의 경계 박스 중 하나의 위치에 대응하는, 인공신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 제1 부분에 대한 상기 제1 해상도는 상기 제2 해상도보다 큰, 인공 신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는,상기 현저성 맵에 기초하여 일 세트의 제어 지점 각각에 대한 변위를 결정하고;상기 일 세트의 제어 지점에 대한 상기 변위에 기초하여 균일한 격자 지점의 세트를 변환하여 샘플링 격자를 생성하고;상기 샘플링 격자에 기초하여 상기 리샘플링된 제2 프레임을 생성하도록 더 구성되는, 인공 신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 적어도 하나의 프로세서는 학습된 줌 거동에 기초하여 상기 리샘플링된 제2 프레임을 생성하도록 더 구성되는, 인공 신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는 상기 현저성 맵에 기초하여 상기 제2 프레임의 제3 부분을 제3해상도로 샘플링하도록 더 구성되고, 상기 제3 해상도는 상기 제1 해상도 및 상기 제2 해상도와 상이한, 인공신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서, 상기 ANN은 제1 신경망 모델 및 제2 신경망 모델을 포함하고, 상기 제1 신경망 모델은 상기 제2 신경망 모델보다 더 큰 처리 용량을 갖도록 구성되고, 상기 적어도 하나의 프로세서는,상기 제1 프레임을 상기 제1 신경망 모델을 통해 처리하고;공개특허 10-2024-0096506-4-후속 프레임을 상기 제2 신경망 모델을 통해 처리하도록 더 구성되는, 인공 신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "인공 신경망(ANN)을 이용한 비디오 처리를 위한 프로그램 코드가 기록된 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 프로그램 코드는 프로세서에 의해 실행되고, 상기 프로그램 코드는,제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하는 프로그램 코드;상기 비디오의 상기 제1 프레임에 기초하여 현저성 맵을 생성하는 프로그램 코드;상기 현저성 맵에 기초하여 상기 비디오의 상기 제2 프레임을 샘플링하는 프로그램 코드로서, 상기 제2 프레임의 제1 부분은 제1 해상도로 샘플링되고, 상기 제2 프레임의 제2 부분은 제2 해상도로 샘플링되고, 상기 제1 해상도는 상기 제2 해상도와 상이한, 상기 비디오의 상기 제2 프레임을 샘플링하는 프로그램 코드;상기 샘플링에 기초하여 리샘플링된 제2 프레임을 생성하는 프로그램 코드; 및상기 리샘플링된 제2 프레임을 처리해서 상기 비디오와 연관된 추론을 결정하는 프로그램 코드를 포함하는, 인공 신경망(ANN)을 이용한 비디오 처리를 위한 프로그램 코드가 기록된 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제1 부분은 상기 현저성 맵에 포함된 다수의 경계 박스 중 하나의 위치에 대응하는, 인공 신경망(ANN)을 이용한 비디오 처리를 위한 프로그램 코드가 기록된 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 제1 부분에 대한 제1 해상도는 상기 제2 해상도보다 큰, 인공 신경망(ANN)을 이용한 비디오 처리를 위한 프로그램 코드가 기록된 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 상기 프로그램 코드는,상기 현저성 맵에 기초하여 일 세트의 제어 지점에 대한 변위를 결정하는 프로그램 코드;상기 일 세트의 제어 지점에 대한 상기 변위에 기초하여 균일한 격자 지점의 세트를 변환하여 샘플링 격자를 생성하는 프로그램 코드; 및상기 샘플링 격자에 기초하여 상기 리샘플링된 제2 프레임을 생성하는 프로그램 코드를 더 포함하는, 인공 신경망(ANN)을 이용한 비디오 처리를 위한 프로그램 코드가 기록된 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 프로그램 코드는, 학습된 줌 거동에 기초하여 상기 리샘플링된 제2 프레임을 생성하는프로그램 코드를 더 포함하는, 인공 신경망(ANN)을 이용한 비디오 처리를 위한 프로그램 코드가 기록된 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서, 상기 프로그램 코드는, 상기 현저성 맵에 기초하여 상기 제2 프레임의 제3 부분을 제3 해상도로 샘플링하는 프로그램 코드를 더 포함하고, 상기 제3 해상도는 상기 제1 해상도 및 상기 제2 해상도와상이한, 인공 신경망(ANN)을 이용한 비디오 처리를 위한 프로그램 코드가 기록된 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제15항에 있어서, 상기 ANN은 제1 신경망 모델 및 제2 신경망 모델을 포함하고, 상기 제1 신경망 모델은 상기제2 신경망 모델보다 더 큰 처리 용량을 갖도록 구성되고, 상기 프로그램 코드는,상기 제1 프레임을 상기 제1 신경망 모델을 통해 처리하는 프로그램 코드; 및공개특허 10-2024-0096506-5-후속 프레임을 상기 제2 신경망 모델을 통해 처리하는 프로그램 코드를 더 포함하는, 인공 신경망(ANN)을 이용한 비디오 처리를 위한 프로그램 코드가 기록된 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "인공 신경망(ANN)을 이용하는 비디오 처리 장치로서,제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하는 수단;상기 비디오의 상기 제1 프레임에 기초하여 현저성 맵을 생성하는 수단;상기 현저성 맵에 기초하여 상기 비디오의 상기 제2 프레임을 샘플링하는 수단으로서, 상기 제2 프레임의 제1부분은 제1 해상도로 샘플링되고, 상기 제2 프레임의 제2 부분은 제2 해상도로 샘플링되고, 상기 제1 해상도는상기 제2 해상도와 상이한, 상기 비디오의 상기 제2 프레임을 샘플링하는 수단;상기 샘플링에 기초하여 리샘플링된 제2 프레임을 생성하는 수단; 및상기 리샘플링된 제2 프레임을 처리해서 상기 비디오와 연관된 추론을 결정하는 수단을 포함하는, 인공 신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 상기 제1 부분은 상기 현저성 맵에 포함된 다수의 경계 박스 중 하나의 위치에 대응하는, 인공 신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 제1 부분에 대한 상기 제1 해상도는 상기 제2 해상도보다 큰, 인공 신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제22항에 있어서,상기 현저성 맵에 기초하여 일 세트의 제어 지점에 대한 변위를 결정하는 수단;상기 일 세트의 제어 지점에 대한 상기 변위에 기초하여 균일한 격자 지점의 세트를 변환하여 샘플링 격자를 생성하는 수단; 및상기 샘플링 격자에 기초하여 상기 리샘플링된 제2 프레임을 생성하는 수단을 더 포함하는, 인공 신경망(ANN)을이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제25항에 있어서, 학습된 줌 거동에 기초하여 상기 리샘플링된 제2 프레임을 생성하는 수단을 더 포함하는, 인공 신경망(ANN)을 이용하는 비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제22항에 있어서, 상기 현저성 맵에 기초하여 상기 제2 프레임의 제3 부분을 제3 해상도로 샘플링하는 단계를더 포함하고, 상기 제3 해상도는 상기 제1 해상도 및 상기 제2 해상도와 상이한, 인공 신경망(ANN)을 이용하는비디오 처리 장치."}
{"patent_id": "10-2024-7015169", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제22항에 있어서, 상기 ANN은 제1 신경망 모델 및 제2 신경망 모델을 포함하고, 상기 제1 신경망 모델은 상기제2 신경망 모델보다 더 큰 처리 용량을 갖도록 구성되고, 상기 장치는,상기 제1 프레임을 상기 제1 신경망 모델을 통해 처리하는 것; 및상기 제2 신경망 모델을 통해 후속 프레임을 처리하는 것을 더 포함하는, 인공 신경망(ANN)을 이용하는 비디오처리 장치.공개특허 10-2024-0096506-6-"}
{"patent_id": "10-2024-7015169", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 신경망을 통한 비디오 처리 사용의 프로세서-구현 방법은 제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하는 단계를 포함한다. 비디오의 제1 프레임에 기초하여 현저성 맵이 생성된다. 비디오의 제2 프레임은 현 저성 맵에 기초하여 샘플링된다. 제2 프레임의 제1 부분은 제1 해상도로 샘플링되고, 제2 프레임의 제2 부분은 제2 해상도로 샘플링된다. 제1 해상도는 제2 해상도와 상이하다. 제2 프레임의 샘플링에 기초하여 리샘플링된 제2 프레임이 생성된다. 리샘플링된 제2 프레임이 처리되어서 비디오와 연관된 추론을 결정한다."}
{"patent_id": "10-2024-7015169", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원의 교차 참조 본 출원은 2021년 11월 16일에 출원되고, 명칭이 \"SALIENCY-BASED INPUT RESAMPLING FOR EFFICIENT OBJECT DETECTION\" 인 미국 임시 출원 제 63/280,104 호에 대한 우선권을 주장하는, 2022년 10월 25일 출원되고, 명칭 이 \"SALIENCY-BASED INPUT RESAMPLING FOR EFFICIENT OBJECT DETECTION\" 인 미국 특허출원 제17/973,370호에 대한 우선권을 주장하며, 이 출원들의 개시는 그 전부가 본 명세서에 참조로 명백히 원용된다."}
{"patent_id": "10-2024-7015169", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "기술분야 본 개시내용의 양태는 일반적으로 인공 신경망을 통한 비디오 처리에 관한 것이다."}
{"patent_id": "10-2024-7015169", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망은 인공 뉴런의 상호 연결된 그룹(예컨대, 뉴런 모델)을 포함할 수 있다. 인공 신경망은 컴퓨테이 셔널 디바이스이거나, 컴퓨테이셔널 디바이스에 의해 수행될 방법으로 표현될 수 있다. 신경망은 텐서(tensor)를 소비하고 텐서를 생성하는 피연산자로 구성된다. 신경망은 복잡한 문제를 해결하는 데 사용될 수 있지만, 솔루션을 생성하기 위해 수행될 수 있는 계산의 수 및 네트워크(network) 크기가 방대할 수 있기 때문에, 네트워크가 작업을 완료하는 시간이 길 수 있다. 더욱이, 이러한 작업은 제한된 계산 능력을 가질 수 있는 모바일 디바이스 상에서 수행될 수 있기 때문에, 심층 신경망의 계산 비용이 문제가 될 수 있다. 컨볼루션 신경망(CNN: convolutional neural network)은 피드-포워드(feed-forward) 인공 신경망의 일 유형이 다. 컨볼루션 신경망은, 각각이 수용 필드(field)를 갖고 집합적으로 입력 공간을 타일링(tile)하는 뉴런의 집 합을 포함할 수 있다. 컨볼루션 신경망(CNN), 이를테면 딥 컨볼루션 신경망(DCN: deep convolutional neural network)은 다수의 애플리케이션을 갖는다. 특히, 이러한 신경망 아키텍처(architecture)는 이미지 인식, 패턴 인식, 음성 인식, 자율 주행, 및 다른 분류 작업과 같은 다양한 기술에서 사용된다. 신경망은 또한 인간 포즈 추정, 객체 검출, 의미론적 세그먼트화, 비디오 압축 및 노이즈 제거와 같은 비디오 또는 비디오 스트림의 이미지 기반 처리에 다양한 애플리케이션을 갖고 있다. 불행하게도, 이러한 비디오 처리 는 계산 집약적이므로, 상당한 처리 시간이 걸리고 메모리 비용 및 전력 소비도 증가시킬 수 있다. 이러한 문제는 계산 리소스 및 전력 리소스가 제한된 디바이스에 신경망이 전개될 때 더 악화될 수 있다. 예를 들어, 자율 주행 및 비디오 감시와 같은 미션 크리티컬 시스템을 위한 이러한 신경망의 현재 구현예는 작업 정 확도에만 최적화될 수 있으며, 디바이스의 계산 비용 또는 런타임은 고려되지 않을 수 있다. 나아가, 4K 카메라 기술의 출현으로 인해서, 한 장면에서 더 자세한 콘텐츠를 검색할 수 있는 새로운 기회가 제 공되어 검출 및 분류 정확도가 향상될 수 있지만, 이 더 자세한 콘텐츠를 처리하는 컴퓨팅 리소스와 관련해서 더 큰 문제가 발생할 수도 있다. 본 개시내용은 독립 청구항에서 각각 제시된다. 본 개시내용의 일부 양태는 종속 청구항에서 기술된다. 본 개시내용의 양태에서, 인공 신경망을 이용한 비디오 처리의 프로세서-구현 방법은 제1 프레임 및 제2 프레임 을 포함하는 비디오를 수신하는 단계를 포함한다. 방법은 또한, 비디오의 제1 프레임에 기초하여 현저성 맵 (saliency map)을 생성하는 단계를 포함한다. 방법은 현저성 맵에 기초하여 비디오의 제2 프레임을 샘플링하는 단계를 더 포함한다. 제2 프레임의 제1 부분은 제1 해상도로 샘플링되고, 제2 프레임의 제2 부분은 제2 해상도 로 샘플링된다. 제1 해상도는 제2 해상도와 상이하다. 방법은 샘플링에 기초하여 리샘플링된 제2 프레임을 생 성하는 단계를 더 포함한다. 방법은 리샘플링된 제2 프레임을 처리해서 비디오와 연관된 추론을 결정하는 단계 를 더 포함한다. 본 개시내용의 다른 양태에서, 인공 신경망(ANN: artificial neural network)을 이용하는 비디오 처리를 위한 장치가 제시된다. 장치는 메모리 및 메모리에 커플링된 하나 이상의 프로세서(들)를 갖는다. 프로세서(들)는 제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하도록 구성된다. 프로세서(들)는 또한, 비디오의 제1 프레임에 기초하여 현저성 맵을 생성하도록 구성된다. 프로세서(들)는 또한, 현저성 맵에 기초하여 비디오의 제2 프레임을 샘플링하도록 구성된다. 제2 프레임의 제1 부분은 제1 해상도로 샘플링되고, 제2 프레임의 제2 부분 은 제2 해상도로 샘플링된다. 제1 해상도는 제2 해상도와 상이하다. 프로세서(들)는 샘플링에 기초하여 리샘 플링된 제2 프레임을 생성하도록 더 구성된다. 프로세서(들)는 또한, 리샘플링된 제2 프레임을 처리해서 비디 오와 연관된 추론을 결정하도록 구성된다. 본 개시내용의 다른 양태에서, 비일시적 컴퓨터 판독 가능 저장 매체가 개시된다. 비일시적 컴퓨터 판독 가능 저장 매체는 인공 신경망을 이용한 비디오 처리를 위한 프로그램 코드를 갖는다. 프로그램 코드는 프로세서에 의해 실행되며, 제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하는 프로그램 코드를 포함한다. 프로그램 코드는 또한, 비디오의 제1 프레임에 기초하여 현저성 맵을 생성하는 프로그램 코드를 포함한다. 프로그램 코 드는 현저성 맵에 기초하여 비디오의 제2 프레임을 샘플링하는 프로그램 코드를 더 포함한다. 제2 프레임의 제 1 부분은 제1 해상도로 샘플링되고, 제2 프레임의 제2 부분은 제2 해상도로 샘플링된다. 제1 해상도는 제2 해 상도와 상이하다. 프로그램 코드는 샘플링에 기초하여 리샘플링된 제2 프레임을 생성하는 프로그램 코드를 더 포함한다. 또한, 프로그램 코드는 리샘플링된 제2 프레임을 처리해서 비디오와 연관된 추론을 결정하는 프로그 램 코드를 포함한다. 본 개시내용의 또 다른 양태에서, 인공 신경망(ANN)을 이용하는 비디오 처리를 위한 장치가 제시된다. 장치는 제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하는 수단을 포함한다. 장치는 또한, 비디오의 제1 프레임 에 기초하여 현저성 맵을 생성하는 수단을 포함한다. 장치는 현저성 맵에 기초하여 비디오의 제2 프레임을 샘 플링하는 수단을 더 포함한다. 제2 프레임의 제1 부분은 제1 해상도로 샘플링되고, 제2 프레임의 제2 부분은 제2 해상도로 샘플링된다. 제1 해상도는 제2 해상도와 상이하다. 장치는 샘플링에 기초하여 리샘플링된 제2 프레임을 생성하는 수단을 더 포함한다. 장치는 또한 리샘플링된 제2 프레임을 처리해서 비디오와 연관된 추론 을 결정하는 수단을 포함한다. 본 개시내용의 추가적인 피처 및 이점은 이하에서 설명될 것이다. 본 개시내용이 본 개시내용의 동일한 목적을 수행하기 위해 다른 구조를 수정 또는 설계하기 위한 기초로서 쉽게 이용될 수도 있다는 것이 당업자에 의해 인 식되어야 한다. 또한, 이러한 등가의 구성은 첨부된 청구항에 기재된 바와 같은 본 개시내용의 교시로부터 벗 어나지 않는다는 것이 당업자에 의해 인식되어야 한다. 본 개시내용의 특징인 것으로 여겨지는 신규한 피처는, 추가적인 목적 및 이점과 함께, 그것의 구성 및 동작 방법 양자에 관하여, 첨부 도면과 관련하여 고려될 때 이 하의 설명으로부터 더 잘 이해될 것이다. 그러나, 각각의 도면은 단지 예시 및 설명의 목적을 위해 제공되고, 본 개시내용의 제한의 정의로서 의도되지 않는다는 것이 명백하게 이해될 것이다."}
{"patent_id": "10-2024-7015169", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부 도면과 관련하여 아래에 제시되는 상세한 설명은 다양한 구성의 설명으로 의도되며, 설명되는 개념이 실시 될 수 있는 유일한 구성만을 나타내는 것으로 의도되는 것은 아니다. 상세한 설명은 다양한 개념의 완전한 이 해를 제공할 목적으로 특정 세부사항을 포함한다. 그러나, 이런 개념이 이런 특정 세부사항들 없이도 실시될 수 있다는 것이 당업자에게는 자명할 것이다. 일부 예시에서, 잘 알려진 구조 및 컴포넌트는 그러한 개념을 불 명료하게 하는 것을 회피하기 위해 블록도 형태로 도시된다. 교시에 기반하여, 당업자는, 본 개시내용의 임의의 다른 양태와 독립적으로 또는 그 양태와 조합하여 구현되는 지에 관계없이, 본 개시내용의 범위가 본 개시내용의 임의의 양태를 커버하도록 의도된다는 것을 인식해야 한다. 예컨대, 기재된 임의의 수의 양태를 사용하여 장치가 구현될 수 있거나 방법이 실시될 수 있다. 또한, 본 개시내용의 범위는 제시되는 본 개시내용의 다양한 양태에 부가하여 또는 그 외에 다른 구조, 기능, 또는 구 조와 기능을 사용하여 실시되는 그러한 장치 또는 방법을 커버하는 것으로 의도된다. 개시된 본 개시내용의 임 의의 양태가 청구항의 하나 이상의 엘리먼트에 의해 구현될 수 있다는 것이 이해되어야 한다. 단어 \"예시적인\" 은 \"예, 실례, 또는 예시로서 역할을 하는 것\"을 의미하도록 사용된다. \"예시적인\" 것으로서 설명된 임의의 양태가 반드시 다른 양태에 비해 유리하거나 또는 바람직한 것으로서 해석되어야 하는 것은 아니 다. 특정 양태가 설명되지만, 이러한 양태의 많은 변형 및 치환이 본 개시내용의 범위 내에 포함된다. 선호되는 양 태의 일부 이익 및 이점이 언급되지만, 본 개시내용의 범위는 특정 이익, 용도, 또는 목적에 국한된 것으로 의 도되는 것은 아니다. 그보다, 본 개시내용의 양태는 다른 기술, 시스템 구성, 네트워크, 및 프로토콜에 폭넓게 적용될 수 있는 것으로 의도되며, 이들 중 일부는 선호되는 양태에 대한 하기의 설명 및 도면에서 예로서 설명 된다. 상세한 설명 및 도면은 제한하는 것이 아니라 개시내용의 단지 예시이고, 개시내용의 범위는 첨부된 청 구항 및 그 등가물에 의해 정의된다. 설명되는 바와 같이, 신경망은 또한 인간 포즈 추정, 객체 검출, 의미론적 세그먼트화, 비디오 압축 및 노이즈 제거와 같은 비디오 또는 비디오 스트림의 이미지 기반 처리에 다양한 애플리케이션을 갖고 있다. 불행하게도, 이러한 비디오 처리는 계산 집약적이므로, 상당한 처리 시간이 걸리고 에너지 소비도 증가시킬 수 있다. 또한 4K(4K는 약 4000 픽셀의 수평 디스플레이 해상도를 가리킴) 카메라와 같이 이미지 캡처 디바이스의 품질이 향상됨에 따라서, 인공 지능(AI) 솔루션이 보다 상세한 비디오 콘텐츠를 검색하는 것을 가능하게 하며, 따라서 이는 비디오의 고성능 객체 검출에 널리 채택되고 있다. 그러나, 이러한 더 높은 해상도 신호에 기인하는 인식 성능(예를 들어, 정확도)의 증가는, 계산 비용을 증가시킬 수 있다. 이는 자원이 제한된 디바이스에 최첨단 비 디오 객체 검출기를 적용하는 것을 제한한다. 일부 종래 방식은 계산 비용을 감소시키기 위해 입력을 단순하게 다운 샘플링할 수 있지만, 이러한 종래 방식은 검출 성능을 저하시킨다. 일부 종래 방식은 헤비한(heavy) 특징 추출기와 라이트한(light) 특징 추출기를 인터리빙하는 것, 계산을 로컬 윈도우로 제한하는 것, 또는 라이트한 광학 흐름 예측기를 사용해서 키 프레임에서 후속하는 프레임으로 특징을 외삽하는 것을 포함할 수 있다. 그러나, 이러한 종래 방식은 두 개의 서로 다른 특징 추출기로 인한 특징 정렬 불량 또는 빈번한 전역 장면 변화를 처리하는 데 있어서의 비효율성으로 인해 어려움을 겪을 수 있다. 이러한 문제 및 다른 문제를 해결하기 위해, 본 개시내용의 양태는 고해상도의 이미지의 세분화된(fine- grained) 상세는 유지하면서, 중요하지 않은 또는 덜 중요한 배경 영역을 상당히 다운 샘플링시키는 것을 허용 한 비균일한 입력 샘플링에 대한 것이다. 예를 들어, 일부 양태에서, 효율적인 객체 검출을 위한 현저성 기반 입력 리샘플링이 채용될 수 있다. 더욱이, 본 개시내용의 양태는 예를 들어, 자율 주행, 증강 현실 및 비디오 감시와 같은 수많은 현실 세계의 응용에 유익하게 적용될 수 있다. 도 1은 인공 신경망(예컨대, 종단 간 신경망)을 사용한 비디오 처리를 위해 구성된 중앙 처리 유닛(CPU: central processing unit) 또는 다중 코어(multi-core) CPU를 포함할 수 있는 시스템-온-칩(SoC: system- on-a-chip)의 예시적인 구현을 예시한다. 변수(예컨대, 신경 신호 및 시냅스 가중치(synaptic weights)), 컴퓨테이셔널 디바이스와 연관된 시스템 매개변수(예컨대, 가중치를 갖는 신경망), 지연, 주파수 빈 (bin) 정보, 및 작업 정보가 신경 처리 유닛(NPU: neural processing unit)과 연관된 메모리 블록에,CPU와 연관된 메모리 블록에, 그래픽 처리 유닛(GPU: graphics processing unit)과 연관된 메모리 블록에, 디지털 신호 프로세서(DSP: digital signal processor)와 연관된 메모리 블록에, 메모리 블록 에 저장될 수 있거나, 또는 다수의 블록에 걸쳐 분산될 수 있다. CPU에서 실행되는 명령은 CPU(10 2)와 연관된 프로그램 메모리로부터 로딩될 수 있거나, 또는 메모리 블록으로부터 로딩될 수 있다. SoC는 또한 GPU, DSP, 5G(fifth generation) 접속, 4G LTE(fourth generation long term evolution) 접속, Wi-Fi 접속, USB 접속, 블루투스(Bluetooth) 접속 등을 포함할 수 있는 접속 블록, 및 예를 들어, 제스처(gesture)를 검출 및 인식할 수 있는 멀티미디어(multimedia) 프로세서와 같은 특정 기 능에 맞춰진 추가 처리 블록을 포함할 수 있다. 일 구현예에서, NPU는 CPU, DSP 및/또는 GPU에서 구현된다. SoC는 또한 센서 프로세서, 이미지 신호 프로세서(ISP: image signal processor) 및/또는 내비게이션 모듈(navigation module)을 포함할 수 있으며, 이는 글로벌 포지셔 닝 시스템(global positioning system)을 포함할 수 있다. SoC는 ARM 명령 세트에 기초할 수 있다. 본 개시내용의 양태에서, 범용 프로세서에 로딩된 명령은 제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하기 위한 코드를 포함할 수 있다. 범용 프로세서는 또한, 비디오의 제1 프레임에 기초하여 현저성 맵을 생성하기 위한 코드를 포함할 수 있다. 범용 프로세서 는 현저성 맵에 기초하여 비디오의 제2 프레임을 샘플링하는 코드를 더 포함할 수 있다. 제2 프레임의 제 1 부분은 제1 해상도로 샘플링되고, 제2 프레임의 제2 부분은 제2 해상도로 샘플링된다. 제1 해상도는 제2 해 상도와 상이하다. 범용 프로세서는 또한 제2 프레임의 샘플링에 기초하여 리샘플링된 제2 프레임을 생성 하는 코드를 포함할 수 있다. 범용 프로세서는 또한 리샘플링된 제2 프레임을 처리해서 비디오와 연관된 추론을 결정하는 코드를 포함할 수 있다. 딥 러닝 아키텍처는 각각의 계층에서 연속적으로 더 높은 추상화 레벨의 입력을 나타내도록 학습함으로써 객체 인식 작업을 수행할 수 있으며, 이에 의해 입력 데이터의 유용한 특징 표현을 구축할 수 있다. 이 방식으로, 딥 러닝은 전통적인 기계 학습의 주요 병목 현상을 해결한다. 딥 러닝의 출현 전에, 객체 인식 문제에 대한 기 계 학습 접근법은, 어쩌면 얕은 분류기와 함께, 인간 공학 특징에 크게 의존했을 수 있다. 얕은 분류기는, 예 컨대, 2-부류 선형 분류기일 수 있고, 여기서는 특징 벡터 성분의 가중 합이 임계치와 비교됨으로써 입력이 어 느 부류에 속하는지가 예측될 수 있다. 인간 공학 특징은 도메인 전문 지식을 갖춘 엔지니어에 의해서 특정 문 제 도메인에 맞게 조정된 템플릿 또는 커널일 수 있다. 대조적으로, 딥 러닝 아키텍처는 인간 엔지니어가 설계 할 수 있는 것과 유사한 특징을 나타내기 위해서 훈련을 통해 학습할 수 있다. 게다가, 딥 네트워크는 인간이 고려하지 않았을 수 있는 새로운 유형의 특징을 나타내고 인식하기 위해 학습할 수 있다. 딥 러닝 아키텍처는 특징의 계층 구조(hierarchy)를 학습할 수 있다. 예를 들어, 시각적 데이터가 제시되는 경 우, 제1 계층은 입력 스트림에서 에지와 같은 비교적 간단한 특징을 인식하는 것을 학습할 수 있다. 다른 예에 서, 청각적 데이터가 제시되는 경우, 제1 계층은 특정 주파수에서 스펙트럼 파워를 인식하는 것을 학습할 수 있 다. 제1 계층의 출력을 입력으로서 취하는 제2 계층은 시각적 데이터에 대한 간단한 형상 또는 청각적 데이터 에 대한 사운드의 조합과 같은 특징의 조합을 인식하는 것을 학습할 수 있다. 예를 들어, 상위 계층은 시각적 데이터에서 복잡한 형상 또는 청각적 데이터에서 워드(word)를 표현하도록 학습할 수 있다. 더 상위 계층은 일 반적인 시각 객체 또는 구어(spoken phrase)를 인식하도록 학습할 수 있다. 딥 러닝 아키텍처는 자연스런 계층 구조를 갖는 문제에 적용될 때 특히 잘 수행될 수 있다. 예를 들어, 전동 차량의 분류는 휠, 윈드실드(windshield), 및 다른 특징을 인식하는 제1 학습으로부터 이익을 얻을 수 있다. 이러한 특징은 자동차, 트럭, 및 항공기를 인식하기 위해 상이한 방식으로 더 높은 계층에서 조합될 수 있다. 신경망은 다양한 연결 패턴으로 설계될 수 있다. 피드-포워드 네트워크에서, 정보는 하위 계층으로부터 상위 계층으로 전달되고, 주어진 계층의 각각의 뉴런은 상위 계층의 뉴런과 통신한다. 계층 구조적 표현은 전술한 바와 같이 피드-포워드 네트워크의 연속적인 계층에 구축될 수 있다. 신경망은 또한 순환(recurrent) 또는 피 드백(탑-다운식(top-down)이라고도 함) 연결을 가질 수 있다. 순환 연결(recurrent connection)에서, 주어진 계층의 뉴런으로부터의 출력은 동일한 계층의 다른 뉴런으로 통신될 수 있다. 순환 아키텍처는 시퀀스로 신경 망에 전달되는 입력 데이터 청크(input data chunk) 중 하나 초과에 걸쳐 있는 패턴을 인식하는 데 도움이 될 수 있다. 주어진 계층의 뉴런으로부터 하위 계층의 뉴런으로의 연결은 피드백(또는 탑-다운식) 연결이라고 지 칭된다. 많은 피드백 연결을 갖는 네트워크는 하이-레벨 개념의 인식이 입력의 특정 로우-레벨 특징을 판별하 는 것을 도울 수 있을 때 도움이 될 수 있다. 신경망의 계층 사이의 연결은 완전 연결되거나 국소 연결될 수 있다. 도 2a는 완전 연결 신경망의 실시예 를 예시한다. 완전 연결 신경망에서, 제1 계층의 뉴런은 제2 계층의 모든 뉴런에 출력을 통신할 수 있어 서, 제2 계층의 각각의 뉴런은 제1 계층의 모든 뉴런으로부터 입력을 수신할 것이다. 도 2b는 국소 연결 신경 망의 실시예를 예시한다. 국소 연결 신경망에서, 제1 계층의 뉴런은 제2 계층의 제한된 수의 뉴런에 연결될 수 있다. 보다 일반적으로, 국소 연결 신경망의 국소 연결된 계층은 계층 내의 각각의 뉴런이 동 일하거나 유사한 연결 패턴을 가질 것이지만, 상이한 값(예를 들어, 210, 212, 214, 및 216)을 가질 수 있는 연 결 강도를 갖도록 구성될 수 있다. 국소 연결된 연결 패턴은 상위 계층에서 공간적으로 별개인 수용 필드를 발 생시킬 수 있는데, 이는 주어진 영역 내의 상위 계층 뉴런이 네트워크에 대한 전체 입력의 제한된 부분의 속성 에 대한 훈련을 통해 튜닝되는 입력을 수신할 수 있기 때문이다. 국소 연결된 신경망의 일례는 컨볼루션 신경망(convolutional neural network)이다. 도 2c는 컨볼루션 신경망 의 실시예를 예시한다. 컨볼루션 신경망은 제2 계층의 각각의 뉴런에 대한 입력과 연관된 연결 강도 가 공유되도록(예를 들어, 208) 구성될 수 있다. 컨볼루션 신경망은 입력의 공간적 위치가 의미있는 문제에 매 우 적합할 수 있다. 일 유형의 컨볼루션 신경망은 딥 컨볼루션 네트워크(DCN: deep convolutional network)이다. 도 2d는 자동차 장착 카메라와 같은 이미지 캡처(capturing) 디바이스로부터 입력된 이미지로부터 시각적 특징을 인 식하도록 설계된 DCN의 상세한 예를 예시한다. 본 실시예의 DCN은 교통 표지판 및 교통 표지판 상에 제공된 숫자를 식별하도록 훈련될 수 있다. 물론, DCN은 차선 마킹을 식별하거나 교통 신호등을 식별하는 것과 같은 다른 과제에 대해 훈련될 수 있다. DCN은 지도 학습(supervised learning)으로 훈련될 수 있다. 훈련 동안, DCN에는 속도 제한 표지판 의 이미지와 같은 이미지가 제시될 수 있고, 그런 다음 순방향 패스가 계산되어 출력을 생성할 수 있 다. DCN은 특징 추출부(feature extraction section) 및 분류부(classification section)를 포함할 수 있다. 이미지를 수신할 때, 컨볼루션 계층은 제1 세트의 특징 맵을 생성하기 위해 컨볼루션 커 널(도시되지 않음)을 이미지에 적용할 수 있다. 일 예로서, 컨볼루션 계층에 대한 컨볼루션 커널은 28x28 특징 맵을 생성하는 5x5 커널일 수 있다. 본 실시예에서, 4개의 상이한 특징 맵이 제1 세트의 특징 맵 에서 생성되기 때문에, 4개의 상이한 컨볼루션 커널이 컨볼루션 계층에서 이미지에 적용되었다. 컨볼루션 커널은 또한 필터 또는 컨볼루션 필터로 지칭될 수 있다. 제1 세트의 특징 맵은 제2 세트의 특징 맵을 생성하기 위해 최대 풀링 계층(max pooling layer)(도시 되지 않음)에 의해 서브샘플링될 수 있다. 최대 풀링 계층은 제1 세트의 특징 맵의 크기를 감소시킨다. 즉, 14x14와 같은 제2 세트의 특징 맵의 크기는 28x28과 같은 제1 세트의 특징 맵의 크기보다 작다. 감소된 크기는 메모리 소비를 감소시키면서 후속 계층에 유사한 정보를 제공한다. 제2 세트의 특징 맵은 특징 맵의 하나 이상의 후속 세트(도시되지 않음)를 생성하기 위해 하나 이상의 후속 컨볼루션 계층(도시되지 않음)을 통해 추가로 컨볼루션될 수 있다. 도 2d의 실시예에서, 제2 세트의 특징 맵은 컨볼루션되어 제1 특징 벡터를 생성한다. 또한, 제1 특 징 벡터는 제2 특징 벡터를 생성하기 위해 추가로 컨볼루션된다. 제2 특징 벡터의 각각의 특징 은 \"표지판(sign)\", \"60\" 및 \"100\"과 같은 이미지의 가능한 특징에 대응하는 숫자를 포함할 수 있다. 소 프트맥스 함수(softmax function)(도시되지 않음)는 제2 특징 벡터 내의 숫자를 확률로 변환할 수 있다. 이와 같이, DCN의 출력은 하나 이상의 특징을 포함하는 이미지의 확률일 수 있다. 본 실시예에서, \"사인(sign)\" 및 \"60\"에 대한 출력에서의 확률은 \"30\", \"40\", \"50\", \"70\", \"80\", \"90\" 및 \"100\"과 같은 출력의 다른 것의 확률보다 높다. 훈련 전에, DCN에 의해 생성된 출력은 부정확 할 가능성이 있다. 따라서, 출력과 타겟 출력(target output) 사이의 에러(error)가 계산될 수 있다. 타 겟 출력은 이미지의 실측 자료(ground truth)(예를 들어, \"사인\" 및 \"60\")이다. 그런 다음, DCN의 가중치는 DCN의 출력이 타겟 출력과 더 근접하게 정렬되도록 조정될 수 있다. 가중치를 조정하기 위해, 학습 알고리즘은 가중치에 대한 기울기 벡터(gradient vector)를 계산할 수 있다. 기 울기는 가중치가 조정되면 에러가 증가하거나 감소할 양을 나타낼 수 있다. 최상위 계층에서, 기울기는 끝에서 두번째 계층(penultimate layer)의 활성화된 뉴런과 출력 계층의 뉴런을 연결하는 가중치의 값에 직접 대응할 수 있다. 하위 계층에서, 기울기는 가중치의 값 및 상위 계층의 계산된 에러 기울기에 의존할 수 있다. 이어 서, 오차를 줄이기 위해 가중치가 조정될 수 있다. 가중치를 조정하는 이러한 방식은 신경망을 통한 \"역방향 패스\"를 수반하기 때문에 \"역 전파(back propagation)\"로 지칭될 수 있다.실제로, 가중치의 오차 기울기가 작은 수의 예들에 걸쳐 계산될 수 있으므로, 계산된 기울기는 실제 오차 기울 기에 근접한다. 이러한 접근 방법은 확률적 기울기 하강법(stochastic gradient descent)으로 지칭될 수 있다. 확률적 기울기 하강법은, 전체 시스템의 달성가능한 오차 레이트가 감소하는 것을 중단할 때까지 또는 오차 레 이트가 타깃 레벨에 도달할 때까지, 반복될 수 있다. 학습 후에, DCN에는 새로운 이미지가 제시될 수 있 고, DCN를 통한 순방향 패스는 DCN의 추론 또는 예측으로 간주될 수 있는 출력을 산출할 수 있 다. 딥 신뢰 신경망(DBN: Deep Belief Network)은 다수의 은닉 노드 계층을 포함하는 확률론적 모델이다. DBN은 훈 련 데이터 세트의 계층 구조 표현을 추출하는 데 사용될 수 있다. DBN은 제한된 볼츠만 머신(RBM: Restricted Boltzmann Machine)의 계층을 쌓아서 획득될 수 있다. RBM은 일 세트의 입력에 대한 확률 분포를 학습할 수 있 는 인공 신경망의 일 유형이다. RBM은 각각의 입력이 분류되어야 하는 클래스에 대한 정보가 없을 때 확률 분 포를 학습할 수 있기 때문에, 비지도 학습에서 종종 RBM이 사용된다. 하이브리드 비지도 및 지도 패러다임을 사용하여, DBN의 바닥 RBM은 비지도 방식으로 훈련될 수 있고, 특징 추출기로서 기능할 수 있고, 상부 RBM은 (이전 계층 및 타겟 클래스로부터의 입력의 조인트 분포(joint distribution) 상에서) 지도 방식으로 훈련될 수 있고, 분류기로서 기능할 수 있다. DCN은 추가적인 풀링(pooling) 및 정규화 계층을 갖게 구성되는, 컨볼루션 네트워크의 네트워크이다. DCN은 많 은 과제에 대한 최신 성능을 달성했다. DCN은 입력 및 출력 타겟 둘 모두가 많은 예시에 대해 알려져 있고 기 울기 하강 방법의 사용에 의해 네트워크의 가중치를 수정하는 데 사용되는 지도 학습을 사용하여 훈련될 수 있 다. DCN은 피드-포워드 네트워크일 수 있다. 또한, 상기에서 설명된 바와 같이, DCN의 제1 계층의 뉴런으로부터 다 음 상위 계층의 뉴런의 그룹으로의 연결은 제1 계층의 뉴런에 걸쳐 공유된다. DCN의 피드-포워드 및 공유 연결 은 빠른 프로세싱을 위해 활용될 수 있다. DCN의 계산 부담은, 예를 들어, 순환 또는 피드백 연결을 포함하는 유사한 크기의 신경망의 계산 부담보다 훨씬 적을 수 있다. 컨볼루션 네트워크의 각각의 계층의 프로세싱은 공간적으로 불변인 템플릿 또는 기저 투영(basis projection)으 로 간주될 수 있다. 입력이 컬러 이미지의 적색, 녹색, 및 청색 채널과 같은 다수의 채널로 먼저 분해되면, 해 당 입력에 대해 훈련된 컨볼루션 네트워크는 이미지의 축들을 따른 2개의 공간 차원 및 컬러 정보를 캡처하는 제3 차원을 갖는 3차원으로 간주될 수 있다. 컨볼루션 연결의 출력은 후속 계층에서 특징 맵을 형성하기 위해 고려될 수 있고, 특징 맵의 각각의 요소(예를 들어, 220)는 이전 계층의 다양한 뉴런(예를 들어, 특징 맵들 )으로부터 그리고 다수의 채널 각각으로부터 입력을 수신한다. 특징 맵의 값은 비-선형성, 이를테면 max(0, x)인 교정(rectification)을 통해 추가로 프로세싱될 수 있다. 인접한 뉴런으로부터의 값은 추가로 풀 링될 수 있는데, 이는 다운 샘플링(down-sampling)에 대응하고, 이러한 값은 추가 국소 불변성 및 차원 감소를 제공할 수 있다. 백색화(whitening)에 대응하는 정규화는 또한 특징 맵에서 뉴런 간의 측방 억제를 통해 적용 될 수 있다. 딥 러닝 아키텍처의 성능은, 더 많은 라벨링된 데이터 포인트가 이용가능하게 됨에 따라 또는 컴퓨테이셔널 능 력이 증가함에 따라 증가할 수 있다. 현대의 심층 신경망은, 단지 15년 전에 일반 연구원에게 이용가능하였던 것보다 수천 배 더 많은 컴퓨팅 자원으로 일상적으로 훈련된다. 새로운 아키텍처 및 훈련 패러다임은 딥 러닝 의 성능을 더욱 향상시킬 수 있다. 교정된 선형 유닛은 소실 기울기로 알려진 훈련 문제를 줄일 수 있다. 새 로운 훈련 기술은 과적합(over-fitting)을 줄여서, 더 큰 모델이 더 나은 일반화를 달성하게 할 수 있다. 캡슐 화 기술은 주어진 수용 필드에서 데이터를 추상화하고 전반적인 성능을 더욱 향상시킬 수 있다. 도 3은 딥 컨볼루션 네트워크(DCN)를 예시한 블록도이다. 딥 컨볼루션 네트워크는 연결 및 가중치 공유에 기초하여 다수의 상이한 유형의 계층을 포함할 수 있다. 도 3에 도시된 바와 같이, 딥 컨볼루션 네트워 크는 컨볼루션 블록(354A, 354B)을 포함한다. 컨볼루션 블록(354A, 354B) 각각은 컨볼루션 계층 (CONV), 정규화 계층(LNorm), 및 최대 풀링 계층(MAX POOL)으로 구성될 수 있다. 비록 2개의 컨볼루션 블록(354A, 354B)만이 도시되지만, 본 개시내용은 이에 제한되지 않으며, 대신에, 설계 선호도에 따라 임의의 수의 컨볼루션 블록(354A, 354B)이 딥 컨볼루션 네트워크에 포함될 수 있다. 컨볼루션 계층은 특징 맵을 생성하기 위해 입력 데이터에 적용될 수 있는 하나 이상의 컨볼루션 필터를 포 함할 수 있다. 정규화 계층은 컨볼루션 필터의 출력을 정규화할 수 있다. 예를 들어, 정규화 층은 백색화(whitening) 또는 측방 억제(lateral inhibition)를 제공할 수 있다. 최대 풀링 계층은 국소 불변및 차원 감소를 위해 공간에 걸쳐 다운 샘플링 집성을 제공할 수 있다. 예를 들어, 딥 컨볼루션 네트워크의 병렬 필터 뱅크(bank)는 SoC(예를 들어, 도 1)의 CPU 또는 GPU에 로딩되어 높은 성능 및 낮은 전력 소비를 달성할 수 있다. 대안적인 실시형태에서, 병렬 필터 뱅크 는 SoC의 DSP 또는 ISP 상에 로딩될 수 있다. 추가로, 딥 컨볼루션 네트워크는 SoC 상에 존재할 수 있는 다른 프로세싱 블록, 이를테면 각각 센서 및 내비게이션에 전용인 센서 프로세서 및 내비게이션 모듈에 액세스할 수 있다. 딥 컨볼루션 네트워크는 또한 하나 이상의 완전 연결 계층(FC1 및 FC2)을 포함할 수 있다. 딥 컨볼 루션 네트워크는 로지스틱 회귀(logistic regression)(LR) 계층을 더 포함할 수 있다. 딥 컨볼루션 네트워크의 각각의 계층(356, 358, 360, 362, 364) 사이에는 업데이트될 가중치(도시되지 않음)가 있다. 계층(예를 들어, 356, 358, 360, 362, 364) 각각의 출력은 컨볼루션 블록(354A) 중 제1 컨볼루션 블록에서 공급 되는 입력 데이터(예를 들어, 이미지, 오디오, 비디오, 센서 데이터 및/또는 다른 입력 데이터)로부터 계 층 구조적 특징 표현을 학습하기 위해 딥 컨볼루션 네트워크에서 계층들(예를 들어, 356, 358, 360, 362, 364)의 연속되는 하나의 입력으로서 기능할 수 있다. 딥 컨볼루션 네트워크의 출력은 입력 데이터에 대한 분류 스코어이다. 분류 스코어는 일 세트의 확률일 수 있으며, 여기서 각각의 확률은 입력 데 이터가 일 세트의 특징으로부터의 특징을 포함하는 확률이다. 도 4는 인공 지능(AI: artificial intelligence) 기능을 모듈화할 수 있는 예시적인 소프트웨어 아키텍처(40 0)를 예시하는 블록도이다. 아키텍처를 사용하여, SoC의 다양한 프로세싱 블록(예를 들어, CPU, DSP, GPU 및/또는 NPU)(도 1의 SoC와 유사할 수 있음)으로 하여금 본 개시내용 의 양태에 따라, AI 애플리케이션에 대한 훈련 후 양자화에 대해 개시된 바와 같이 적응형 라운딩 (adaptive rounding)을 지원하게 할 수 있는 애플리케이션이 설계될 수 있다. AI 애플리케이션은 예를 들어, 디바이스가 현재 동작하는 위치를 표시하는 장면의 검출 및 인식을 제공할 수 있는 사용자 공간에 정의된 기능을 호출하도록 구성될 수 있다. AI 애플리케이션은 예를 들어, 인식된 장면이 사무실인지, 강의실인지, 식당인지 또는 호수와 같은 실외 환경인지에 따라 마이크로폰 (microphone) 및 카메라를 상이하게 구성할 수 있다. AI 애플리케이션은 현재 장면의 추정치를 제공하도 록 SceneDetect 애플리케이션 프로그래밍 인터페이스(API: application programming interface)와 같은 AI 기능 API에서 정의된 라이브러리와 연관된 컴파일된 프로그램 코드에 대한 요청을 할 수 있다. 이러한 요청 은 궁극적으로, 예를 들어 비디오 및 포지셔닝 데이터에 기초하여 추론 응답을 제공하도록 구성된 심층 신경망 의 출력에 의존할 수 있다. 심층 신경망은 예를 들어, 비디오 및 포지셔닝 데이터에 기초하여 장면 추정치를 제공하도록 구성된 차동 신경망일 수 있다. 런타임 프레임워크(runtime framework)의 컴파일링된 코드일 수 있는 런타임 엔진(engine)은 AI 애플리케 이션에 추가로 액세스 가능할 수 있다. AI 애플리케이션은 런타임 엔진으로 하여금, 예를 들어 특정 시간 간격으로 또는 애플리케이션의 사용자 인터페이스에 의해 검출된 이벤트에 의해 트리거된 장면 추정치와 같은 인터페이스를 요청하게 할 수 있다. 추론 응답(예를 들어, 장면을 추정하기 위해)을 제공하게 될 때, 런타임 엔진은 결국, SoC 상에서 실행되는 리눅스 커널과 같은 운영 시스템(OS: operating system) 공간 내의 운영 시스템에 신호를 전송할 수 있다. 운영 시스템은 결국, CPU, DSP, GPU, NPU, 또는 이의 어떤 조합 상에서 양자화의 연속 완화가 수행되게 할 수 있다. CPU는 운영 시스템에 의해 직접 액세스될 수 있고, 다른 프로세싱 블록은 각각 DSP, GPU 또는 NPU에 대한 드라이버(414, 416 또는 418)와 같은 드라이버를 통해 액세스될 수 있다. 예시적인 예에서, 심층 신경망은 CPU, DSP 및 GPU와 같은 프로세싱 블록의 조합 상에서 실행되도록 구성될 수 있 거나, 또는 NPU 상에서 실행될 수 있다. 본 개시내용의 양태는 현저성 기반 입력 리샘플링에 관한 것이다. 즉, 이미지 또는 비디오와 같은 입력은 입력 의 더 현저한(salient) 부분이 입력의 덜 현저한 부분보다 더 높은 해상도로 샘플링되도록 샘플링될 수 있다. 그 결과 디테일-보존 이미지는 공간적으로 더 작아질 수 있으므로 계산 비용이 절감되는 동시에 고해상도 입력 과 유사한 성능을 가능하게 할 수 있다. 본 개시내용의 양태에 따라, 주어진 일 세트의 고해상도 비디오 프레임 및 대응하는 라벨 에 대해, 경 계 박스가 검출될 수 있고, 각각의 프레임에서 하나 이상의 객체의 카테고리 또는 분류가 결정될 수도 있다.현저성 기반 입력 리샘플링을 위한 프레임워크는 i) 객체 검출 모델 및 (여기서"}
{"patent_id": "10-2024-7015169", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이고, (여기서 FLOP는 초당 부동 소수점 연산임), ii) 현저성 맵 생성기, iii) 리샘플링 모듈, 및 iv) 역변환 모듈을 포함할 수 있다. 추론 시, 제1 단계에서, 제1 고해상도 프레임 (키 프레임)이 객체 검출 모델 (고성능 검출 모델)에 제공될 수 있다. 객체 검출 모델 은 프레임 에 대응하는 하나 이상의 경계 박스를 생성할 수 있고, 이들의 스코어는 글로벌 현저성 맵을 구축하기 위해 현저성 맵 생성기로 전달될 수 있다. 글 로벌 현저성 맵 및 제2 고해상도 프레임 이 리샘플링 모듈로 전달될 수 있다. 리샘플링 모듈은 프레임의 다운 샘플링된 디테일-보존 이미지 를 생성할 수 있다. 프레임의 다운 샘플링된 이미지 는 라이트 검출 모델 에 제공될 수 있다. 이러한 다운 샘플링된 이미지 의 특성으로 인해, 라이트 검출 모델 은 더 낮은 계산 비용으로 객체 검출 모델 과 유사한 성능(예를 들어, 정확도)을 가질 수 있다. 연속적 인 프레임 각각에 대하여, 현저성 맵은 라이트 검출 모델 을 사용하여 이전 프레임 의 검출 출력으 로부터 생성될 수 있다. 일부 양태에서, 시간에 따른 에러의 전파를 방지하기 위해, 검출 출력은 더 강한 객체 검출 모델 (예를 들어, 모든 S시간 단계에서 또는 프레임에서)을 사용하여 주기적으로 또는 비주기적으로 업 데이트될 수 있다. 현저성 맵 생성기는 비모수적(non-parametric) 검출-마스크 생성기일 수 있다. 현저성 맵 생성기는, 리샘플링 동안 보존될 수 있는 현저한 픽셀에 대응하는 맵을 출력할 수 있다. 이 현저성 맵(예를 들어, 마스크)은, 예를 들어, 0.5의 임계값 τ 이상의 스코어를 갖는 각각의 경계 박스 검출로부터 생성될 수 있다. 일부 양태에서, 이미지 영역의 1%보다 작은 공간 영역을 가진 객체에는 1인 제1 라벨이 할당될 수 있고, 더 큰 면적을 가진 객체에는 0.5의 라벨이 할당된다. 이렇게 하면 리샘플링 모듈이 더 작은 객체의 해상도를 유지하 는 데 더 집중할 수 있다. 배경 픽셀은 0으로 라벨링될 수 있다. 현저성 맵은 리샘플링 모듈로 전달하기 전에 128×128로 다운 샘플링될 수 있다. 리샘플링 모듈은, 예를 들어 박판 스플라인 공간 변환기에 기초할 수 있다. 리샘플링 모듈은 i) 로컬라이제이 션 네트워크, ii) 격자 생성기 및 iii) 샘플러를 포함할 수 있다. 로컬라이제이션 네트워크는 컨볼루션 신경망일 수 있으며, 예를 들어, 8개의 컨볼루션 계층 및 2개의 완전 연결 계층을 포함할 수 있다. 로컬라이제이션 네트워크는 현저성 맵을 입력으로 수신할 수 있고, 차례로, 예를 들어, 유클리드 평면에서 격자(예를 들어, 16×16) 상에 정의된 N개의 제어 지점의 세트(예를 들어, N=256)의 변위를 추정할 수 있다. 격자 생성기는 샘플링 격자를 생성하고 다음과 같이 기능할 수 있다. 2차원(2-D) 격자 에 서 균일하게 샘플링된 제어 지점들 세트와 로컬라이제이션 네트워크에 의해 제공되는 대응하는 변위 가 주어지면, 선형계를 풀어서 매개변수 W를 도출할 수 있다. 여기서, 제어 지점을 적층하여 부분행렬 P이 형성되고, 부분행렬 K는 ,"}
{"patent_id": "10-2024-7015169", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "로 정의되고, V는 변위된 제어 지점의 적층된 세트를 나타내며, O는 0으로 구성된 부분행렬이고, U는 방사형 기 저 함수이고, r는 지점 사이의 규범(norm)이다. 매개변수 W를 추정한 이후에, 다음과 같이 조밀한 균일한 격자에 변형이 적용되어서 샘플링 격자 G를 획득할 수 있다:"}
{"patent_id": "10-2024-7015169", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 는 조밀한 지점으로 L과 유사하게 계산된다. 이후, 샘플러는 입력 이미지 와 함께 샘플링 격자 G를 취해서 디테일-보존 리샘플링된 이미지 를 생성할 수 있다. 확대할 위치에 대한 명시적인 지침 없이 로컬라이제이션 네트워크의 매개변수를 학습하면 균일한 왜곡이 발생할 수 있으며 원하는 디테일이 유지되지 않을 수 있다. 이 문제를 해결하기 위해, 정규화기가 비모수적 주의 기반 (non-parametric attention-based) 샘플링 방법을 통해 샘플링 격자 G를 정규화할 수 있다. 이 리샘플링 방법 은 입력으로서 현저성 맵을 수신할 수 있고, 맵 내의 현저한 영역을 보존하는 샘플링 격자를 생성할 수 있다. 생성된 샘플링 격자는 샘플링 모듈이 명시적인 줌 효과 또는 거동을 학습하기 위한 지도 신호(supervision signal)로 작용할 수 있다. 그러나 이러한 방식은 미분이 불가능하고(non-differentiable), 계산 비용이 많이 들 수 있으며, 동일한 이미지에 다양한 현저성 레벨을 가진 다수의 객체가 나타날 때 변형을 일으킬 수 있다. 이 방법은 현저성 맵을 x축과 y축에 대한 2개의 주변 분포(marginal distribution)로 분해한다. 그러나 이러한 주변화(marginalization)는 더 높은 현저성 레벨을 가진 객체와 같은 행/열에 있는 낮은 현저성 의 영역에 바람직하지 않은 왜곡을 초래한다. 보다 구체적으로, 현저성 맵의 좌표 및 가 높은 값을 갖는 경우, 결과적인 샘플링 격자는 현저성 레벨에 관계없이 및 에서, 그리고 및 에서 조밀할 수 있다. 이러한 에러는 이미지에 현저성 레벨이 서로 다른 다수의 객체가 있는 경우 문제 가 될 수 있다. 리샘플링 모듈은 완전히 미분 가능하고, 계산 비용이 저렴하지만, 비중재 지도(unmediated supervision)를 받는 경우에는 동일한 바람직하지 않은 아티팩트가 샘플러에 전해질 수 있다. 이러한 문제를 해결하기 위해 가중 L2-손실 함수가 사용될 수 있다:"}
{"patent_id": "10-2024-7015169", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 G는 리샘플링 모듈에 의해 생성된 격자이고, G'는 주의 기반 샘플링 방법에 의해 생성된 격자이며, M은 가중 마스크이다. 가중 마스크 M은 작은 객체 , 큰 객체 및 배경 에 대해 서로 다른 값이 할당될 수 있다. 현저성 맵이 작은 객체 또는 큰 객체를 갖는 경우, 값 은 (1, 1, 0.5)로 설정될 수 도 있고, 그렇지 않으면 (1, 0, 0)으로 설정될 수 있다. 직관적으로, 현저성 맵이 단일 현저성 레벨(예를 들어, 다수의 작은 객체)로 구성될 때, 객체 각각에 줌 효과가 제공될 수 있다. 따라서, 전체 격자에 대한 완 전한 지도(full supervision)가 제공될 수 있다. 일부 양태에서, 네트워크 모델은 와 조합해서 검출 손실을 사용하여 종단간(end-to-end)으로 훈련될 수 있다. 리샘플링된 이미지에 대한 라이트 검출 모델 의 경계 상자 출력이 주어지면, 역변환이 적용되어서 경계 상자 의 좌표를 원본 이미지 격자로 복구할 수 있다. 이는 예를 들어, 경계 상자 좌표로부터 격자 변위 오프셋을 감 산해서 달성될 수 있다. 경계 상자 좌표가 부동 소수점 값이므로, 각각의 경계 상자 좌표에 대해, 원래 좌표는 변형 격자에서 가장 가까운 두 셀에 대응하는 변위를 선형으로 보간함으로써 복구될 수 있다. 도 5은 본 개시내용의 양태에 따른, 현저성 기반 입력 리샘플링을 위한 예시적인 아키텍처를 예시하는 도 면이다. 예시적인 아키텍처는 검출기 키, 현저성 맵 생성기, 리샘플링 모듈 및 검출기 를 포함할 수 있다. 아키텍쳐는 비디오를 수신할 수 있다. 비디오는 예를 들어, N개의 프레임의 시 퀀스(예를 들어, 520a, 520b)를 포함할 수 있다. 비디오의 각각의 프레임은 이미지를 포함할 수 있다. 검출기 키(예를 들어, 헤비 검출기 는 비디오의 제1 프레임(520a)을 수신하고, 제1 비디오 프레임(520a)에서 검출된 하나 이상의 객체에 대한 경계 박스를 생성할 수 있다. 경계 박스 정보(예를 들어, 540)는 현저성 맵 생성기에 제공될 수 있다. 현저성 맵 생성기는 검출된 객체 각각(예를 들어, 이러한 검출된 객체 가 위치될 수 있는 경계 박스)에 대한 위치를 나타내는 현저성 맵을 생성할 수 있다. 현저성 맵은 리샘플링 모 듈에 제공될 수 있다. 리샘플링 모듈은 로컬라이제이션 네트워크, 격자 생성기 및 샘플러를 포함할 수 있다. 로 컬라이제이션 네트워크는 컨볼루션 신경망(예를 들어, 도 3의 350)일 수 있다. 로컬라이제이션 네트워크 는 현저성 맵을 입력으로 수신할 수 있다. 로컬라이제이션 네트워크는 연속적인 컨볼루션 계층을 통 해 현저성 맵을 처리해서 현저성 맵의 특징을 추출할 수 있다. 로컬라이제이션 네트워크는 현저성 맵의 추출된 특징에 기초하여 일 세트의 제어 지점에 대한 변위의 추정치를 생성할 수 있다. 즉, 일 세트의 균일하 게 샘플링된 제어 지점 및 이들의 대응하는 변위가 주어졌을 때, 박판 스플라인 변환의 매개변수가 계산될 수 있다. 이 매개변수는 격자 생성기에 제공될 수 있다. 격자 생성기는 계산된 매개변수에 기초하여 조밀하고 균일한 격자를 샘플링 격자로 변환할 수 있다. 격자 생성기는 격자를 샘플러에 출력할 수 있다. 샘플러는 샘플링 격자에 따라서 리샘플링된 입력 프레임 또는 이미지를 생성할 수 있다. 일부 양태에서, 리샘플링 모듈은 격자 정규화기를 더 포함할 수 있다. 리샘플링 모듈은 격자 정규화기에 기초하여, 비디오에 포함된 객체(현저성 맵에 표시됨)를 줌인하기 위한 줌 거동을 학습할 수 있다. 리샘플링 모듈은 현저성 맵 생성기로부터 제2 프레임(520b) 및 현저성 맵을 수신할 수 있다. 현저성 맵을 사용하여, 리샘플링 모듈은 제2 프레임(520b)을 다운 샘플링하여, 더 작은 객체의 해상도는 보존되는 반면 배경 픽셀의 해상도는 더 크게 감소되게 할 수 있다. 리샘플링된 제2 프레임은 검출기(예를 들어, 라 이트 검출기 )에 공급될 수 있다. 제2 프레임(520b)의 보다 현저한 영역의 해상도를 보존한 후, 검출기(52 2)는 제2 프레임(520b)에서 검출된 하나 이상의 객체에 대한 경계 박스를 생성할 수 있다. 검출기의 출력은 역변환 블록에 공급될 수 있다. 역변환 블록은 검출기 출력을 원래의 이미지 격자로 다 시 변환하고, 원래의 이미지 격자 포맷의 검출기 출력을 현저성 맵 생성부에 공급한다. 도 6은 본 개시내용의 양태에 따른, 현저성 기반 입력 리샘플링의 예시적인 구현예의 도면이다. 예시적인 구현예는 헤비 검출기, 라이트 검출기 및 리샘플링 모듈을 포함할 수 있다. 헤비 검출기 및 라이트 검출기는 각각 컨볼루션 신경망(예를 들어, 350)으로 구성될 수 있다. 예를 들어, 헤비 검출기는 라이트 검출기보다 훨씬 더 많은 메모리 및 처리 용량으로 구성될 수 있다. 도 6에 도시된 바와 같이, 예를 들어 비디오 처리 과제를 위해서 비디오의 3개의 프레임이 수신될 수 있다. 물 론, 이것은 이해하기 쉽기 위한 예일 뿐이며 한정은 아니다. 오히려, 본 개시내용의 양태에 따라서 임의의 수 의 이미지 또는 비디오 프레임이 수신되고 처리될 수 있다. 제1 비디오 프레임, 프레임 T는 헤비 검출기 를 통해 수신될 수 있다. 각각의 비디오 프레임은 고해상도 비디오 프레임(예를 들어, 4K 비디오 프레임)일 수 있다. 헤비 검출기는 비디오 프레임 T를 처리할 수 있고, 현저성 맵(606a)을 생성할 수 있다. 현저성 맵 (606a)은 프레임 T에 표시된 이미지의 하나 이상의 중요한 부분 또는 현저한 부분의 위치를 나타낼 수 있 다. 예를 들어, 현저성 맵(606a)은 프레임에 포함된 객체 또는 사람의 위치를 식별할 수 있다. 현저성 맵 (606a)은 리샘플링 모듈에 제공될 수 있다. 현저성 맵(606a)에 더해서, 리샘플링 모듈은 또한 처리될 비디오의 다음 프레임, 프레임 T+1을 수신할 수 있다. 리샘플링 모듈은 현저성 맵(606a)에 기초하여 비디오 프레임 T+1을 샘플링할 수 있다. 예를 들어, 현저 성 맵(606a)의 현저한 부분에 대응하는 프레임 T+1의 부분은 제1 해상도로 샘플링될 수 있고, 프레임 T+1 의 나머지는 제1 해상도보다 낮은 제2 해상도로 샘플링될 수 있다. 도 6에 도시된 바와 같이, 프레임 T+1은, 예를 들어, 896 x 896의 해상도를 가질 수 있다. 반면에, 리샘플링된 프레임 T+1(610a)은, 예를 들어 512 x 512의 전체 해상도를 가질 수 있다. 그러나, 프레임 T+1을 리샘플링된 프레임 T+1(610a)과 비교할 때, 현저성 맵(606a)의 현저한 부분(예를 들어, 자동차)에 대응하는 프레임 T+1에 묘사된 객체는 프레임 T+1의 나머지 부분보다 더 높은 해상도로 리샘플링된 프레임일 수 있다. 예를 들어, 리샘플링된 프레임 T+1(610a)의 자동차 의 크기가 입력 프레임 T+1에 표시된 자동차보다 더 크게 표시되어, 확대 효과를 제공한다. 현저한 영역을 이 미지의 나머지 부분보다 더 높은 해상도로 제공함으로써, 프레임 T+1 처리와 연관된 계산 부하를 줄이면서 이러 한 객체를 검출하고 분류하는 정확도가 증가된다. 따라서, 리샘플링된 프레임 T+1(610a)은 라이트 검출기(60 4)에 공급되어 프레임 T+1 내의 객체를 검출 및/또는 분류할 수 있다. 이후, 이러한 검출 정보는 역방향 리샘플링 모듈에 제공될 수 있다. 역방향 리샘플링 모듈은 리샘플 링 모듈과 대칭으로 구성될 수 있다. 이와 같이, 역방향 리샘플링 모듈은 리샘플링 과정을 역으로 해서 프레임 T+1의 본래 해상도(예를 들어, 896 x 896)를 복원할 수 있다. 역방향 리샘플링 모듈은 업데 이트된 현저성 맵(606b)을 생성할 수 있는데, 이는 현저한 부분(예를 들어, 경계 박스 내에 도시됨)의 업 데이트된 위치를 나타낼 수도 있다. 일부 양태에서, 역방향 리샘플링 모듈은 이미지의 추가적인 현저한 부분을 결정하고 이러한 부분을 업데이트된 현저성 맵(606b)에 포함할 수도 있다. 업데이트된 현저성 맵(606b) 및 프레임 T+2은 리샘플링 모듈에 의해 수신될 수 있다. 프레임 T+2는 프레 임 T+1에 대해 설명된 것과 유사한 방식으로 업데이트된 현저성 맵(606b)에 기초하여 리샘플링될 수 있다. 리 샘플링된 프레임 T+2(610b)이 라이트 검출기에 공급될 수 있으며, 라이트 검출기는 프레임 T+2 내의 하나 이상의 객체(예컨대, 업데이트된 현저성 맵(606b) 내의 경계 박스에 대응하는 프레임 T+2의 위치에서의 객 체)를 검출 및/또는 분류하기 위한 추론 과제를 다시 수행할 수 있다. 검출 정보는 역방향 리샘플링 모듈(61 2)에 제공될 수 있으며, 이는 원래의 프레임 T+2의 해상도를 복원하고 업데이트된 현저성 맵(606c)을 생성할 수 있다. 입력 비디오의 추가 프레임은 유사한 방식으로 처리될 수 있다. 도 7은 본 개시내용의 양태에 따른, 리샘플링 모듈에 대한 구현예 및 훈련의 예를 예시하는 블록도이 다. 도 7을 참조하면, 리샘플링 모듈은 컨볼루션 신경망을 포함할 수 있는데, 이는 입력으로서 현저 성 맵(예를 들어, 현저성 맵(606a))을 취한다. 이 예시적인 구현예에서, 컨볼루션 신경망은 연속적인 컨 볼루션 계층을 통해 현저성 맵(606a)을 처리하여, 박판 스플라인 변환의 제어 지점의 예측을 생성할 수 있 다. 박판 스플라인 변환의 제어 지점을 사용하여, 격자는 입력(예를 들어, 비디오 프레임)을 변형시키도 록 예측되거나 결정될 수 있다. 프레임 T+1은 격자 기반 입력 변환에 따라 리샘플링될 수 있다. 일부 양태에서, 현저한 객체에 대한 줌 거동은 삼선형 주의 메커니즘(trilinear attention mechanism)에 따라 학습될 수 있다. 일부 양태에서, 리샘플링 모듈은 객체 검출 손실 및 줌 손실에 의해 주어진 L2 손실에 기초하여 훈련된다. 도 8은 본 개시내용의 양태에 따른, 현저성 기반 리샘플링과 종래의 균일한 리샘플링 사이의 예시적인 비교 를 도시하는 도면이다. 도 8에 도시된 바와 같이, 종래 방식은 균일한 다운 샘플링을 적용하여 리샘 플링된 이미지를 생성할 수 있다. 이렇게 하면 경계 상자를 통해 표시되는 중요한 객체가 입력 이미지의 다른 모든 부분과 동일하게 다운 샘플링된다. 따라서, 이러한 객체를 검출하고 분류하는 것은 더 어려울 수 있다.한편, 본 개시내용의 양태에 따라, 현저성 맵에 기초하여 리샘플링된 입력 이미지가 생성될 수 있다. 따 라서, 입력을 다운 샘플링함에 있어서, 이미지에 포함된 객체(예를 들어, 경계 박스를 통해 나타남)에 대한 공 간 해상도는 보존될 수 있는 반면, 이미지의 다른 부분(예를 들어, 배경)의 더 큰 다운 샘플링을 허용할 수 있 다. 도 9는 본 개시내용의 양태에 따른, 인공 신경망을 통해 비디오를 처리하기 위한 프로세스를 예시하는 흐 름도이다. 도 9에 도시된 바와 같이, 프로세스는 블록 902에서 적어도 제1 프레임 및 제2 프레임을 포함 하는 비디오를 수신한다. 예를 들어, 도 5를 참조하여 설명한 바와 같이, 아키텍쳐는 비디오를 수신할 수 있다. 비디오는 예를 들어, N개의 프레임의 시퀀스(예를 들어, 520a, 520b)를 포함할 수 있다. 비디오의 각각 의 프레임(예를 들어, 520a, 520b)은 이미지를 포함할 수 있다. 검출기 키는, 비디오의 제1 프레임(520 a)을 수신할 수 있다. 프로세스는 블록 904에서 비디오의 첫 프레임에 기초하여 현저성 맵을 생성한다. 도 5를 참조하여 설명한 바와 같이, 검출기 키는 비디오의 제1 프레임(520a)을 수신하고, 제1 비디오 프레임(520a)에서 검출된 하 나 이상의 객체에 대한 경계 박스를 생성할 수 있다. 경계 박스 정보(예를 들어, 540)가 현저성 맵 생성 기에 제공될 수 있다. 현저성 맵 생성기는 검출된 객체 각각(예를 들어, 이러한 검출된 객체가 위치 될 수 있는 경계 박스)에 대한 위치를 나타내는 현저성 맵을 생성할 수 있다. 프로세스는 블록 906에서 현저성 맵에 기초하여 비디오의 제2 프레임을 샘플링한다. 제2 프레임의 제1 부 분은 제1 해상도로 샘플링되고, 제2 프레임의 제2 부분은 제2 해상도로 샘플링된다. 제1 해상도는 제2 해상도 와 상이하다. 예를 들어, 도 5 및 도 6을 참조하여 설명된 바와 같이, 리샘플링 모듈은 또한 처리될 비디 오의 다음 프레임, 프레임 T+1을 수신할 수 있다. 리샘플링 모듈은 현저성 맵(606a)에 기초하여 비디오 프레임 T+1을 샘플링할 수 있다. 예를 들어, 현저성 맵(606a)의 현저한 부분에 대응하는 프레임 T+1의 부분은 제 1 해상도로 샘플링될 수 있고, 프레임 T+1의 나머지는 제1 해상도보다 낮은 제2 해상도로 샘플링될 수 있다. 추가적으로, 프로세스는 블록 908에서 샘플링에 기초하여 리샘플링된 제2 프레임을 생성한다. 도 6에 도 시된 바와 같이, 프로세스는 리샘플링 모듈을 통해 샘플링에 기초하여 리샘플링된 프레임 T+1을 생성할 수 있다. 리샘플링된 프레임 T+1(610a)은, 예를 들어 512 x 512의 전체 해상도를 가질 수 있다. 그러나, 프레임 T+1을 리샘플링된 프레임 T+1(610a)과 비교할 때, 현저성 맵(606a)의 현저한 부분(예를 들어, 자동차)에 대응하는 프레임 T+1에 묘사된 객체는 프레임 T+1의 나머지 부분보다 더 높은 해상도로 리샘플링된 프레임일 수 있다. 예를 들어, 리샘플링된 프레임 T+1(610a)의 자동차의 크기가 입력 프레임 T+1에 표시된 자동차보다 더 크게 표시되어, 확대 효과를 제공한다. 더욱이, 블록 910에서, 프로세스는 리샘플링된 제2 프레임을 처리해서 비디오와 연관된 추론을 결정한다. 예를 들어, 도 6을 참조하면, 리샘플링된 프레임 T+1(610a)은 라이트 검출기에 공급되어 프레임(T+1) 내의 객체를 검출 및/또는 분류할 수 있다. 리샘플링된 프레임 T+1이 이미지의 나머지 부분보다 더 높은 해상도로 현저한 영역을 제공하기 때문에, 프레임 T+1 처리와 연관된 계산 부하를 줄이면서 이러한 객체를 검출하고 분류 하는 정확도가 증가된다. 일부 양태에서, 비디오의 추가 프레임(예를 들어, N개 프레임)이 처리될 수도 있다. 몇몇 실시예에서, 프레임 은 제2 해상도에서 처리될 수 있는데, 여기서 제2 해상도는 제1 해상도보다 낮다. 제2 실시예에서, 프로세스는 N개 프레임 중 한 프레임을 제1 해상도로 (예를 들어, 헤비 검출기를 통해) 주기적으로 또는 비주기적으로 처리할 수 있으며, 여기서 제1 해상도는 제2 해상도보다 높다. 그 후, 프로세스는 다음 기간 또는 시점이 발생 할 때까지 더 낮은 해상도로 (예를 들어, 라이트 검출기를 통해) 후속 프레임을 처리할 수 있다. 구현예들이 다음의 넘버링된 조항에서 제공된다. 1. 인공 신경망(ANN: artificial neural network)을 이용하는 비디오 처리의 프로세서-구현 방법으로서, 제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하는 단계; 비디오의 제1 프레임에 기초하여 현저성 맵을 생성하는 단계; 현저성 맵에 기초하여 비디오의 제2 프레임을 샘플링하는 단계로서, 제2 프레임의 제1 부분은 제1 해상도로 샘 플링되고, 제2 프레임의 제2 부분은 제2 해상도로 샘플링되며, 제1 해상도는 제2 해상도와 상이한, 상기 비디오 의 제2 프레임을 샘플링하는 단계;샘플링에 기초하여 리샘플링된 제2 프레임을 생성하는 단계; 리샘플링된 제2 프레임을 처리해서 비디오와 연관된 추론을 결정하는 단계를 포함한다. 2. 조항 1의 프로세서-구현 방법으로서, 제1 부분은 현저성 맵에 포함된 다수의 경계 박스 중 하나의 위치에 대 응한다. 3. 조항 1 또는 2의 프로세서-구현 방법으로서, 제1 부분에 대한 제1 해상도는 제2 해상도보다 크다. 4. 조항 1 내지 3 중 어느 하나의 프로세서-구현 방법으로서, 현저성 맵에 기초하여 일 세트의 제어 지점 각각에 대한 변위를 결정하는 단계; 일 세트의 제어 지점에 대한 변위에 기초하여 균일한 격자 지점의 세트를 변환하여 샘플링 격자를 생성하는 단 계; 및 샘플링 격자에 기초하여 리샘플링된 제2 프레임을 생성하는 단계를 더 포함한다. 5. 조항 1 내지 4 중 어느 하나의 프로세서-구현 방법으로서, 리샘플링된 제2 프레임은 학습된 줌 거동에 기초 하여 생성된다. 6. 조항 1 내지 5 중 어느 하나의 프로세서-구현 방법으로서, 현저성 맵에 기초하여 제2 프레임의 제3 부분을 제3 해상도로 샘플링하는 단계를 더 포함하고, 제3 해상도는 제1 해상도 및 제2 해상도와 상이하다. 7. 조항 1 내지 6 중 어느 하나의 프로세서-구현 방법으로서, ANN은 제1 신경망 모델 및 제2 신경망 모델을 포 함하고, 제1 신경망 모델은 제2 신경망 모델보다 더 큰 처리 용량을 갖도록 구성되고, 이 방법은, 제1 프레임을 제1 신경망 모델을 통해 처리하는 단계; 및 후속 프레임을 제2 신경망 모델을 통해 처리하는 단계를 더 포함한다. 8. 인공 신경망(ANN)을 이용하는 비디오 처리 장치로서, 메모리; 및 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서는, 제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하고; 비디오의 제1 프레임에 기초하여 현저성 맵을 생성하고; 현저성 맵에 기초하여 비디오의 제2 프레임을 샘플링하는 것으로서, 제2 프레임의 제1 부분은 제1 해상도로 샘 플링되고, 제2 프레임의 제2 부분은 제2 해상도로 샘플링되며, 제1 해상도는 제2 해상도와 상이한, 상기 비디오 의 제2 프레임을 샘플링하고; 샘플링에 기초하여 리샘플링된 제2 프레임을 생성하고; 리샘플링된 제2 프레임을 처리해서 비디오와 연관된 추론을 결정하도록 구성된다. 9. 조항 8의 장치로서, 제1 부분은 현저성 맵에 포함된 다수의 경계 박스 중 하나의 위치에 대응한다. 10. 조항 8 또는 9의 장치로서, 제1 부분에 대한 제1 해상도는 제2 해상도보다 크다. 11. 조항 8 내지 10 중 어느 하나의 장치로서, 적어도 하나의 프로세서는 또한, 현저성 맵에 기초하여 일 세트의 제어 지점 각각에 대한 변위를 결정하고; 일 세트의 제어 지점에 대한 변위에 기초하여 균일한 격자 지점의 세트를 변환하여 샘플링 격자를 생성하고; 샘플링 격자에 기초하여 리샘플링된 제2 프레임을 생성하도록 구성된다. 12. 조항 8 내지 11 중 어느 하나의 장치로서, 적어도 하나의 프로세서는 학습된 줌 거동에 기초하여 리샘플링 된 제2 프레임을 생성하도록 더 구성된다. 13. 조항 8 내지 12 중 어느 하나의 장치로서, 적어도 하나의 프로세서는 현저성 맵에 기초하여 제2 프레임의 제3 부분을 제3 해상도로 샘플링하도록 더 구성되고, 제3 해상도는 제1 해상도 및 제2 해상도와 상이하다.14. 조항 8 내지 13 중 어느 하나의 장치로서, ANN은 제1 신경망 모델 및 제2 신경망 모델을 포함하고, 제1 신 경망 모델은 제2 신경망 모델보다 더 큰 처리 용량을 갖도록 구성되고, 적어도 하나의 프로세서는, 제1 프레임을 제1 신경망 모델을 통해 처리하고; 후속 프레임을 제2 신경망 모델을 통해 처리하도록 더 구성된다. 15. 인공 신경망(ANN)을 이용한 비디오 처리를 위한 프로그램 코드가 기록된 비일시적 컴퓨터 판독 가능 매체로 서, 프로그램 코드는 프로세서에 의해 실행되고, 프로그램 코드는, 제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하는 프로그램 코드; 비디오의 제1 프레임에 기초하여 현저성 맵을 생성하는 프로그램 코드; 현저성 맵에 기초하여 비디오의 제2 프레임을 샘플링하는 프로그램 코드로서, 제2 프레임의 제1 부분은 제1 해 상도로 샘플링되고, 제2 프레임의 제2 부분은 제2 해상도로 샘플링되며, 제1 해상도는 제2 해상도와 상이한, 상 기 비디오의 제2 프레임을 샘플링하는 프로그램 코드; 샘플링에 기초하여 리샘플링된 제2 프레임을 생성하는 프로그램 코드; 및 리샘플링된 제2 프레임을 처리해서 비디오와 연관된 추론을 결정하는 프로그램 코드를 포함한다. 16. 조항 15의 비일시적 컴퓨터 판독 가능 매체로서, 제1 부분은 현저성 맵에 포함된 다수의 경계 박스 중 하나 의 위치에 대응한다. 17. 조항 15 또는 16의 비일시적 컴퓨터 판독 가능 매체로서, 제1 부분에 대한 제1 해상도는 제2 해상도보다 크 다. 18. 조항 15 내지 17 중 어느 하나의 비일시적 컴퓨터 판독 가능 매체로서, 프로그램 코드는, 현저성 맵에 기초하여 일 세트의 제어 지점 각각에 대한 변위를 결정하는 프로그램 코드; 일 세트의 제어 지점에 대한 변위에 기초하여 균일한 격자 지점의 세트를 변환하여 샘플링 격자를 생성하는 프 로그램 코드; 및 샘플링 격자에 기초하여 리샘플링된 제2 프레임을 생성하는 프로그램 코드를 더 포함한다. 19. 조항 15 내지 18 중 어느 하나의 비일시적 컴퓨터 판독 가능 매체로서, 프로그램 코드는, 학습된 줌 동작에 기초하여 리샘플링된 제2 프레임을 생성하는 프로그램 코드를 더 포함한다. 20. 조항 15 내지 19 중 어느 하나의 비일시적 컴퓨터 판독 가능 매체로서, 프로그램 코드는, 현저성 맵에 기초 하여 제2 프레임의 제3 부분을 제3 해상도로 샘플링하는 프로그램 코드를 더 포함하고, 제3 해상도는 제1 해상 도 및 제2 해상도와 상이하다. 21. 조항 15 내지 20 중 어느 하나의 비일시적 컴퓨터 판독 가능 매체로서, ANN은 제1 신경망 모델 및 제2 신경 망 모델을 포함하고, 제1 신경망 모델은 제2 신경망 모델보다 더 큰 처리 용량을 갖도록 구성되고, 프로그램 코 드는, 제1 프레임을 제1 신경망 모델을 통해 처리하는 프로그램 코드; 및 후속 프레임을 제2 신경망 모델을 통해 처리하는 프로그램 코드를 더 포함한다. 22. 인공 신경망(ANN)을 이용하는 비디오 처리 장치로서, 제1 프레임 및 제2 프레임을 포함하는 비디오를 수신하는 수단; 비디오의 제1 프레임에 기초하여 현저성 맵을 생성하는 수단; 현저성 맵에 기초하여 비디오의 제2 프레임을 샘플링하는 수단으로서, 제2 프레임의 제1 부분은 제1 해상도로 샘플링되고, 제2 프레임의 제2 부분은 제2 해상도로 샘플링되며, 제1 해상도는 제2 해상도와 상이한, 상기 비디 오의 제2 프레임을 샘플링하는 수단; 샘플링에 기초하여 리샘플링된 제2 프레임을 생성하는 수단; 및 리샘플링된 제2 프레임을 처리해서 비디오와 연관된 추론을 결정하는 수단을 포함한다. 23. 조항 22의 장치로서, 제1 부분은 현저성 맵에 포함된 다수의 경계 박스 중 하나의 위치에 대응한다. 24. 조항 22 또는 23의 장치로서, 제1 부분에 대한 제1 해상도는 제2 해상도보다 크다. 25. 조항 22 내지 24 중 어느 하나의 장치로서, 현저성 맵에 기초하여 일 세트의 제어 지점 각각에 대한 변위를 결정하는 수단; 일 세트의 제어 지점에 대한 변위에 기초하여 균일한 격자 지점의 세트를 변환하여 샘플링 격자를 생성하는 수 단; 및 샘플링 격자에 기초하여 리샘플링된 제2 프레임을 생성하는 수단을 더 포함한다. 26. 조항 22 내지 25 중 어느 하나의 장치로서, 학습된 줌 거동에 기초하여 리샘플링된 제2 프레임을 생성하는 수단을 더 포함한다. 27. 조항 22 내지 26 중 어느 하나의 장치로서, 현저성 맵에 기초하여 제2 프레임의 제3 부분을 제3 해상도로 샘플링하는 수단을 더 포함하고, 제3 해상도는 제1 해상도 및 제2 해상도와 상이하다. 28. 조항 22 내지 27 중 어느 하나의 장치로서, ANN은 제1 신경망 모델 및 제2 신경망 모델을 포함하고, 제1 신 경망 모델은 제2 신경망 모델보다 더 큰 처리 용량을 갖도록 구성되고, 장치는, 제1 프레임을 제1 신경망 모델을 통해 처리하는 것; 및 후속 프레임을 제2 신경망 모델을 통해 처리하는 것을 더 포함한다. 일 양태에서, 수신 수단, 현저성 맵을 생성하는 수단, 샘플링 수단, 리샘플링된 제2 프레임을 생성하는 수단, 및/또는 처리 수단은 CPU, CPU와 연관된 프로그램 메모리, 전용 메모리 블록, 완전 연결 계층 , NPU 및/또는 열거된 기능을 수행하도록 구성된 라우팅 연결 프로세싱 유닛일 수 있다. 다른 구성에서, 위에서 언급된 수단은 위에서 언급된 수단에 의해 언급된 기능을 수행하도록 구성된 임의의 모듈 또 는 임의의 장치일 수 있다. 위에서 설명된 방법의 다양한 동작은 대응하는 기능을 수행할 수 있는 임의의 적합한 수단에 의해 수행될 수 있 다. 이러한 수단은 회로, 주문형 집적회로(ASIC: application specific integrated circuit) 또는 프로세서를 포함하지만 이에 한정된 것은 아닌 다양한 하드웨어 및/또는 소프트웨어 컴포넌트(들) 및/또는 모듈(들)을 포함 할 수 있다. 일반적으로, 도면에 예시된 동작이 존재하는 경우, 그러한 동작은 비슷한 번호를 가진 대응하는 상대 수단 + 기능 컴포넌트를 가질 수 있다. 본 명세서에서 사용된 바와 같이, 용어 \"결정하는 것\"은 광범위하게 다양한 액션을 포괄한다. 예를 들어, \"결 정하는 것\"은 계산하는 것, 컴퓨팅하는 것, 프로세싱하는 것, 도출하는 것, 조사하는 것, 룩업하는 것(예를 들 어, 테이블, 데이터베이스 또는 다른 데이터 구조에서 룩업하는 것), 확인하는 것 등을 포함할 수 있다. 부가 적으로, \"결정하는 것\"은 수신하는 것(예를 들어, 정보를 수신하는 것), 액세스하는 것(예를 들어, 메모리 내 데이터에 액세스하는 것) 등을 포함할 수도 있다. 더욱이, \"결정하는 것\"은 해결하는 것, 선택하는 것, 선출하 는 것, 확립하는 것 등을 포함할 수도 있다. 본 명세서에서 사용된 바와 같이, 항목의 리스트 \"중 적어도 하나\"를 지칭하는 어구는, 단일의 멤버를 포함하는 그러한 항목의 임의의 조합을 지칭한다. 예를 들어, \"a, b 또는 c 중 적어도 하나\"는 a, b, c, a-b, a-c, b-c 및 a-b-c를 포함하도록 의도된다. 본 개시와 관련하여 설명된 다양한 예시적인 논리 블록, 모듈, 및 회로는 범용 프로세서, 디지털 신호 프로세서 (DSP), 주문형 집적회로(ASIC), 필드 프로그래밍가능 게이트 어레이 신호(FPGA) 또는 다른 프로그래밍가능 로직 디바이스(PLD), 이산 게이트 또는 트랜지스터 로직, 이산 하드웨어 컴포넌트, 또는 본 명세서에서 설명된 기능 을 수행하도록 설계된 이의 임의의 조합으로 구현 또는 수행될 수도 있다. 범용 프로세서는 마이크로프로세서 일 수 있지만, 대안예에서, 프로세서는 임의의 상업적으로 이용가능한 프로세서, 제어기, 마이크로제어기 또는 상태 기계일 수 있다. 또한, 프로세서는 컴퓨팅 디바이스의 조합, 예컨대 DSP와 마이크로프로세서의 조합, 복 수의 마이크로프로세서, DSP 코어와 결합된 하나 이상의 마이크로프로세서, 또는 임의의 다른 그러한 구성으로 서 구현될 수 있다. 본 개시와 관련하여 설명되는 알고리즘 또는 방법의 단계는 직접적으로 하드웨어로, 프로세서에 의해 실행되는 소프트웨어 모듈로, 또는 이 둘의 조합으로 구현될 수 있다. 소프트웨어 모듈은 당업계에 공지된 임의의 형태의 저장 매체에 상주할 수 있다. 사용될 수 있는 저장 매체의 일부 예들은 랜덤 액세스 메모리(RAM: random access memory), 판독 전용 메모리(ROM: read only memory), 플래시 메모리, 삭제가능한 프로그램가능 판독 전 용 메모리(EPROM: erasable programmable read-only memory), 전자적으로 삭제가능한 프로그램가능 판독 전용 메모리(EEPROM: electrically erasable programmable read-only memory), 레지스터, 하드디스크, 착탈식 디스 크, CD-ROM 등을 포함한다. 소프트웨어 모듈은 단일 명령 또는 다수의 명령을 포함할 수 있으며, 그리고 수 개 의 상이한 코드 세그먼트에 걸쳐, 상이한 프로그램 사이에, 그리고 다수의 저장 매체에 걸쳐 분산될 수 있다. 저장 매체는, 프로세서가 저장 매체로부터 정보를 판독하고 저장 매체에 정보를 기록할 수 있도록 프로세서에 커플링될 수 있다. 대안적으로, 저장 매체는 프로세서에 통합될 수 있다. 개시된 방법은 설명된 방법을 달성하기 위한 하나 이상 단계 또는 동작을 포함한다. 방법 단계 및/또는 동작은 청구항의 범위를 벗어나지 않고 서로 교환될 수 있다. 즉, 단계 또는 동작의 특정한 순서가 규정되지 않으면, 특정 단계 및/또는 동작의 순서 및/또는 사용은 청구항의 범위를 벗어나지 않고 변형될 수 있다. 설명된 기능은 하드웨어, 소프트웨어, 펌웨어, 또는 이의 임의의 조합으로 구현될 수 있다. 하드웨어로 구현된 다면, 예시적인 하드웨어 구성은 디바이스의 프로세싱 시스템을 포함할 수 있다. 프로세싱 시스템은 버스 아키 텍처로 구현될 수 있다. 버스는 프로세싱 시스템의 특정 애플리케이션 및 전체적인 설계 제약에 따라, 임의의 수의 상호접속 버스 및 브리지를 포함할 수 있다. 버스는 프로세서, 기계 판독 가능 매체, 및 버스 인터페이스 를 포함하는 다양한 회로를 함께 링크시킬 수 있다. 버스 인터페이스는 다른 무엇보다도, 네트워크 어댑터를 버스를 통해 프로세싱 시스템에 접속하는 데 사용될 수 있다. 네트워크 어댑터는 신호 프로세싱 기능을 구현하 는 데 사용될 수 있다. 특정 양태의 경우, 사용자 인터페이스(예컨대, 키패드, 디스플레이, 마우스, 조이스틱 등)가 또한 버스에 접속될 수 있다. 버스는 또한 타이밍 소스, 주변장치, 전압 조절기, 전력 관리 회로 등과"}
{"patent_id": "10-2024-7015169", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "같은 다양한 다른 회로를 링크할 수 있으며, 이는 당해 기술분야에 잘 알려져 있고 따라서 더 이상 설명되지 않 을 것이다. 프로세서는, 기계 판독 가능 매체에 저장된 소프트웨어의 실행을 비롯하여, 버스의 관리 및 일반적 프로세싱을 담당할 수 있다. 프로세서는 하나 이상의 범용 및/또는 특수-목적 프로세서로 구현될 수 있다. 예는 마이크로 프로세서, 마이크로제어기, DSP 프로세서, 및 소프트웨어를 실행할 수 있는 다른 회로를 포함한다. 소프트웨어 는, 소프트웨어, 펌웨어, 미들웨어, 마이크로코드, 하드웨어 기술 언어 또는 다른 용어로 지칭되든지에 관계없 이, 명령들, 데이터 또는 이의 임의의 조합을 의미하도록 넓게 해석되어야 한다. 기계 판독 가능 매체는 예로 서, 랜덤 액세스 메모리(RAM), 플래시 메모리, 판독 전용 메모리(ROM), 프로그램가능 판독 전용 메모리(PROM), 삭제가능한 프로그램가능 판독 전용 메모리(EPROM), 전자적으로 삭제가능한 프로그램가능 판독 전용 메모리 (EEPROM), 레지스터, 자기 디스크, 광 디스크, 하드 드라이브, 또는 임의의 다른 적당한 저장 매체, 또는 이의 임의의 조합을 포함할 수 있다. 기계 판독 가능 매체는 컴퓨터-프로그램 제품으로 구현될 수 있다. 컴퓨터 프 로그램 제품은 패키징 재료를 포함할 수 있다. 하드웨어 구현에서, 기계 판독 가능 매체는 프로세서와 별개인 프로세싱 시스템의 부품일 수 있다. 그러나, 당 업자가 용이하게 이해할 바와 같이, 기계 판독 가능 매체, 또는 그것의 임의의 부분은 프로세싱 시스템의 외부 에 있을 수 있다. 예로서, 기계 판독 가능 매체는 송신선, 데이터에 의해 변조된 반송파, 및/또는 디바이스와 는 별개인 컴퓨터 제품을 포함할 수 있으며, 이들 모두 버스 인터페이스를 통해 프로세서에 의해 액세스될 수 있다. 대안적으로 또는 추가적으로, 기계 판독 가능 매체 또는 이의 임의의 일부는 프로세서로 통합될 수 있으 며, 이를테면, 그 경우는 캐시 및/또는 범용 레지스터 파일이 해당될 수 있다. 논의된 다양한 컴포넌트는 국소 컴포넌트와 같은 특정 위치를 갖는 것으로 설명될 수 있지만, 이러한 컴포넌트는 또한 다양한 방식으로 구성될 수 있는데, 이를테면 특정 컴포넌트가 분산 컴퓨팅 시스템의 일부로서 구성된다. 프로세싱 시스템은, 프로세서 기능성을 제공하는 하나 이상의 마이크로프로세서 그리고 기계 판독 가능 매체의 적어도 일부를 제공하는 외부 메모리를 가지며 이들 모두가 외부 버스 아키텍처를 통해 다른 지원 회로와 함께 링크되는, 범용 프로세싱 시스템으로서 구성될 수 있다. 대안적으로, 프로세싱 시스템은 설명된 신경 시스템의 모델 및 뉴런 모델을 구현하기 위한 하나 이상의 신경계 형태의(neuromorphic) 프로세서를 포함할 수 있다. 다 른 대안으로서, 프로세싱 시스템은 하나 이상의 필드 프로그램가능한 게이트 어레이(FPGA: field programmable gate array), 프로그램가능한 로직 디바이스(PLD: programmable logic device), 제어기, 상태 머신, 게이티드 (gated) 로직, 이산 하드웨어 컴포넌트, 또는 임의의 다른 적합한 회로를 갖거나, 단일 칩(chip)으로 통합된 기 계 판독 가능 매체의 적어도 일부, 프로세서, 버스 인터페이스, 사용자 인터페이스 및 지원 회로를 갖는 주문형 집적회로(ASIC), 또는 본 개시내용 전반에 걸쳐 설명된 다양한 기능을 수행할 수 있는 회로의 임의의 조합으로 구현될 수 있다. 당업자는, 특정 애플리케이션 및 전체 시스템에 부과된 전체 설계 제약에 따라 프로세싱 시스템에 대한 설명된 기능을 최상으로 구현하는 방법을 인지할 것이다. 기계 판독 가능 매체는 다수의 소프트웨어 모듈을 포함할 수 있다. 소프트웨어 모듈은, 프로세서에 의해 실행 되는 경우, 프로세싱 시스템으로 하여금 다양한 기능을 수행하게 하는 명령을 포함한다. 소프트웨어 모듈은 송 신 모듈 및 수신 모듈을 포함할 수 있다. 각각의 소프트웨어 모듈은 단일 저장 디바이스에 상주할 수 있거나, 또는 다수의 저장 디바이스에 걸쳐 분산될 수 있다. 예로서, 소프트웨어 모듈은 트리거링 이벤트가 발생할 때 하드 드라이브로부터 RAM으로 로딩될 수 있다. 소프트웨어 모듈의 실행 동안, 프로세서는 액세스 속도를 증가 시키기 위해 명령 중 일부를 캐시로 로딩할 수 있다. 그런 다음, 하나 이상의 캐시 라인은 프로세서에 의한 실 행을 위해 범용 레지스터 파일로 로딩될 수 있다. 아래에서 소프트웨어 모듈의 기능을 참조할 때, 그러한 기능 이 그 소프트웨어 모듈로부터의 명령들을 실행할 때 프로세서에 의해 구현된다는 것이 이해될 것이다. 더욱이, 본 개시내용의 양태는 프로세서, 컴퓨터, 기계, 또는 이러한 양태를 구현하는 다른 시스템의 기능에 대한 개선 을 야기한다고 인식되어야 한다. 소프트웨어로 구현되는 경우, 상기 기능은 컴퓨터 판독 가능 매체 상에 하나 이상의 명령 또는 코드로서 저장되 거나 이를 통해 송신될 수 있다. 컴퓨터 판독 가능 매체는, 일 장소에서 다른 장소로의 컴퓨터 프로그램의 전 달을 용이하게 하는 임의의 매체를 포함한 통신 매체 및 컴퓨터 저장 매체 둘 모두를 포함한다. 저장 매체는 컴퓨터에 의해 액세스 가능한 임의의 이용가능한 매체일 수 있다. 비제한적인 예로서, 이러한 컴퓨터 판독 가 능 매체는 RAM, ROM, EEPROM, CD-ROM, 또는 다른 광학 디스크 저장소, 자기 디스크 저장소 또는 다른 자기 저장 디바이스, 또는 명령 또는 데이터 구조의 형태로 요구되는 프로그램 코드를 전달하거나 저장하기 위해 사용될 수 있으며 컴퓨터에 의해 액세스될 수 있는 임의의 다른 매체를 포함할 수 있다. 추가로, 임의의 접속이 컴퓨 터 판독 가능 매체로 적절히 지칭된다. 예컨대, 소프트웨어가 동축 케이블, 광섬유 케이블, 연선(twisted pair), 디지털 가입자 회선(DSL: digital subscriber line), 또는 (적외선(IR), 라디오, 및 마이크로파와 같은) 무선 기법을 사용하여 웹사이트, 서버, 또는 다른 원격 소스로부터 송신되면, 동축 케이블, 광섬유 케이 블, 연선, DSL, 또는 (적외선, 라디오, 및 마이크로파와 같은) 무선 기법이 매체의 정의에 포함된다. 본 명세 서에서 사용된 디스크(disk) 및 디스크(disc)는 콤팩트 디스크(CD: compact disc), 레이저 디스크(disc), 광학 디스크(disc), 디지털 다목적 디스크(DVD: digital versatile disc), 플로피 디스크(disk) 및 블루-레이® 디 스크(disc)를 포함하며, 여기서 디스크(disk)는 일반적으로 데이터를 자기적으로 재생하지만, 디스크(disc)는 레이저를 이용하여 광학적으로 데이터를 재생한다. 따라서, 일부 양태에서, 컴퓨터 판독 가능 매체는 비일시적 컴퓨터 판독 가능 매체(예컨대, 유형의(tangible) 매체)를 포함할 수 있다. 추가로, 다른 양태에 대해, 컴퓨터 판독 가능 매체는 일시적 컴퓨터 판독 가능 매체(예컨대, 신호)를 포함할 수 있다. 상기의 것의 조합이 또한 컴퓨터 판독 가능 매체의 범위 내에 포함되어야 한다. 따라서, 특정 양태는 본 명세서에서 제시되는 동작을 수행하기 위한 컴퓨터 프로그램 제품을 포함할 수 있다. 예를 들어, 이러한 컴퓨터 프로그램 제품은 명령들이 저장(및/또는 인코딩)된 컴퓨터 판독 가능 매체를 포함할 수 있고, 명령은 설명된 동작을 수행하도록 하나 이상의 프로세서에 의해 실행 가능하다. 특정 양태에 대해, 컴퓨터 프로그램 제품은 패키징 재료를 포함할 수 있다. 추가로, 설명된 방법 및 기법을 수행하기 위한 모듈 및/또는 다른 적절한 수단은 적용 가능한 경우에 사용자 단 말 및/또는 기지국에 의해 다운로드(download)될 수 있고 그리고/또는 다른 방식으로 획득될 수 있다고 인식되 어야 한다. 예를 들어, 이러한 디바이스는 서버에 커플링되어, 설명된 방법을 수행하기 위한 수단의 전달을 가 능하게 할 수 있다. 대안적으로, 설명된 다양한 방법은 사용자 단말 및/또는 기지국이 저장 수단(예컨대, RAM, ROM, 콤팩트 디스크(CD)나 플로피 디스크와 같은 물리적 저장 매체 등)을 디바이스에 결합 또는 제공할 때 다양 한 방법을 얻을 수 있도록, 이러한 저장 수단을 통해 제공될 수 있다. 더욱이, 설명된 방법 및 기법을 디바이 스에 제공하기 위한 임의의 다른 적당한 기법이 이용될 수 있다. 청구항이 위에서 예시되는 바로 그 구성 및 컴포넌트로 제한되지 않는다는 것을 이해할 것이다. 위에서 설명한 방법 및 장치의 배치, 동작 및 세부사항에 대해 청구항의 범위를 벗어나지 않으면서 다양한 변형, 변경 및 개조 가 이루어질 수 있다.도면 도면1 도면2a 도면2b 도면2c 도면2d 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2024-7015169", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시내용의 특징, 본질 및 이점은 도면과 함께 받아들여질 때 아래 제시되는 상세한 설명으로부터 보다 명백 해질 것이며, 도면에서는 비슷한 참조 번호가 전체에 걸쳐 상응하게 식별한다. 도 1은 본 개시내용의 특정 양태에 따른, 범용 프로세서를 포함하는 시스템-온-칩(SoC: system-on-a-chip)을 사 용하는 신경망의 예시적인 구현을 예시한다. 도 2a, 도 2b 및 도 2c는 본 개시내용의 양태에 따른 신경망을 예시하는 도면이다. 도 2d는 본 개시내용의 양태에 따른, 예시적인 딥 컨볼루션 네트워크(DCN: deep convolutional network)를 예 시하는 도면이다. 도 3은 본 개시내용의 다양한 양태에 따른, 예시적인 딥 컨볼루션 네트워크(DCN)를 예시한 블록도이다. 도 4는 인공 지능(AI: artificial intelligence) 기능을 모듈화(modularize)할 수 있는 예시적인 소프트웨어 아키텍처를 예시하는 블록도이다. 도 5는 본 개시내용의 양태에 따른, 현저성 기반 입력 리샘플링을 위한 예시적인 아키텍처를 예시하는 도면이다. 도 6은 본 개시내용의 양태에 따른, 현저성 기반 입력 리샘플링의 예시적인 구현예를 예시하는 도면이다. 도 7은 본 개시내용의 양태에 따른, 리샘플링 모듈에 대한 구현예 및 훈련의 예를 예시하는 블록도이다. 도 8은 본 개시내용의 양태에 따른, 현저성 기반 리샘플링과 종래의 균일한 리샘플링 사이의 예시적인 비교를도시하는 도면이다. 도 9는 본 개시내용의 양태에 따른, 인공 신경망으로 비디오를 처리하기 위한 프로세스를 예시하는 흐름도이다."}
