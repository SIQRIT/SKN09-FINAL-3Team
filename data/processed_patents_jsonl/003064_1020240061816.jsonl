{"patent_id": "10-2024-0061816", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0045443", "출원번호": "10-2024-0061816", "발명의 명칭": "관심 영역 기반 영상 정보 부호화 및 복호화 방법", "출원인": "한화비전 주식회사", "발명자": "임정은"}}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "VCM(video coding for machines) 인코딩 장치에 있어서,입력 영상의 일부 프레임율을 변경하는 시간적 리샘플링 수행기;상기 입력 영상의 복수 개의 프레임에 대하여, 각 프레임에 포함된 하나 이상의 관심 영역을 추출하고, 상기 하나 이상의 관심 영역을 기반으로 처리된 영상을 생성하는 관심영역 기반 처리기; 및상기 하나 이상의 관심 영역에 대한 정보 및 상기 입력 영상을 부호화하여 비트스트림을 생성하는 내부 부호화수행기를 포함하고,상기 하나 이상의 관심 영역에 대한 정보는 시간적 샘플링 레이트를 포함하는, VCM 인코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 입력 영상은 상기 하나 이상의 관심 영역을 기반으로 처리된 영상 및 그 외 영역에 해당하는 비 관심영역영상으로 구분되고,상기 내부 부호화 수행기는 상기 하나 이상의 관심 영역을 기반으로 처리된 영상과 비 관심영역 영상에 대하여각각 부호화를 수행하여,상기 내부 부호화 수행기는 상기 하나 이상의 관심 영역에 대한 정보를 부호화한 비트스트림, 상기 하나 이상의관심 영역을 기반으로 처리된 영상을 부호화한 비트스트림 및 비 관심 영역 영상을 부호화한 비트스트림을 먹싱(Muxing)하여 하나의 비트스트림을 출력하는, VCM 인코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 시간적 리샘플링 수행기는, 상기 입력 영상의 전체 프레임에 대하여 동일한 프레임율로 시간적 리샘플링을수행하거나,상기 입력 영상 내 일련의 프레임 그룹 단위로 서로 다른 프레임율로 시간적 리샘플링을 수행하는, VCM 인코딩장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 내부 부호화 수행기는 시간적 샘플링이 수행된 경우, 관심 영역을 포함하는 프레임들 중 일부 프레임의 관심 영역에 대해서만 관심 영역 정보를 부호화하는, VCM 인코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 내부 부호화 수행기는 주기적으로 시간적 샘플링이 수행된 경우, 샘플링 레이트 n(n은 1 이상의 정수)으로시간적 리샘플링이 수행된 관심 영역에 대하여 프레임 주기 m(m은 n이하의 정수)마다 관심 영역에 대한 정보를부호화하고,상기 내부 부호화 수행기는 비주기적으로 시간적 리샘플링이 수행된 경우, 임의의 인접한 두 프레임 사이의 간격을 k라 할 때 프레임 주기 k/p(p는 1이상 k미만의 정수)마다 관심 영역에 대한 정보를 부호화하는, VCM 인코딩 장치.공개특허 10-2025-0045443-3-청구항 6 제3항에 있어서,상기 내부 부호화 수행기는, 상기 입력 영상에 대하여 시간적 리샘플링이 수행되지 않은 경우, 상기 입력 영상에서 하나 이상의 특정 관심 영역에 대한 정보만 부호화를 수행하고,상기 하나 이상의 특정 관심 영역은, 상기 입력 영상에 포함된 프레임들 사이의 대표 밝기 값의 차이 또는 프레임들에 포함된 관심 영역의 대표 밝기 값의 차이가 미리 설정된 임계 값 이상인 경우에 해당하는, VCM 인코딩장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 내부 부호화 수행기는, 상기 입력 영상의 복수 개의 프레임들 중 서로 대응되는 관심 영역에 대해, 상기대응관계에 기초하여 관심 영역 정보를 부호화하며,상기 관심 영역 정보는, 두 관심 영역 간의 위치, 움직임 파라미터, 및 보상 파라미터 중 적어도 하나를 포함하는, VCM 인코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 대응되는 관심 영역은 객체 탐지 또는 객체 추적을 목적으로 학습된 심층신경망을 이용하여 추출되는, VCM인코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 움직임 파라미터는, 스케일(scale), 시어(sheer), 및 회전(rotation)을 포함하는 어파인 움직임을 나타내는 하나 이상의 파라미터를 포함하고,상기 어파인 움직임 파라미터는 아래 수학식에 의해 정의되며, 여기서, a, b, c, d는 어파인 파라미터를 나타내고, Trans_x 및 Trans_y는 x 축 및 y축에 대한 변환 모션 정보를 나타내고, x, y는 현재 관심 영역 내 픽셀 값의 위치를 나타내고, x', y'는 어파인 움직임이 적용된 픽셀 값의 위치를 나타내는, VCM 인코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 보상 파라미터는, 상기 입력 영상에 포함된 두 프레임의 대표 밝기 값의 차이 또는 대응 관심 영역의 대표밝기 값의 차이가 미리 설정된 임계 값 이상인 경우를 나타내는 하나 이상의 파라미터를 포함하며,상기 보상 파라미터는 아래 수학싱에 의해 정의되며,여기서, 는 두 프레임 중 시간적으로 이전 프레임의 i 번째 관심 영역을 나타내고,는 시간적으로 다음 프레임의 i 번째 관심 영역을 나타내는, VCM 인코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,공개특허 10-2025-0045443-4-상기 입력 영상의 각 프레임 또는 일련의 프레임 단위로 공간적 해상도를 변경하는 공간적 리샘플링 수행기를더 포함하고,상기 공간적 리샘플링 수행기 또는 관심영역 기반 처리기는, 상기 입력 영상의 하나 이상의 관심 영역에 대해서만 해상도를 변경하거나, 상기 하나 이상의 관심 영역을 기반으로 처리된 영상 및 비 관심영역 영상에 대하여각기 다른 해상도로 해상도를 변경하며,상기 하나 이상의 관심 영역에 대한 정보는 변경된 해상도 정보를 포함하는, VCM 인코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "VCM(video coding for machines) 디코딩 장치에 있어서,비트스트림을 복호화하여 복원 영상을 생성하는 내부 복호화 수행기;상기 비트스트림에서 파싱한 관심영역 기반 처리 정보를 이용하여 상기 복원 영상에서 관심 영역을 기반으로 복원 영상을 재구성하는 관심영역 기반 복원기;상기 비트스트림에서 파싱한 시간적 리샘플링 정보를 이용하여 상기 복원 영상의 시간적 복원을 수행하는 시간적 복원 수행기를 포함하는, VCM 디코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 관심영역 기반 처리 정보는 관심 영역 ID 정보, 관심 영역의 크기 정보, 관심 영역의 패킹 정보, 대응 관심 영역 정보, 대응 관심 영역 중 두 관심 영역 간의 위치 정보, 대응 관심 영역의 움직임 파라미터, 및 대응관심 영역의 보상 파라미터 중 적어도 하나를 포함하는, VCM 디코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 내부 복호화 수행기는, 상기 비트스트림을 디먹싱(Demuxing)하여 관심영역 기반 처리된 영상, 관심 영역에대한 정보, 및 비 관심영역 영상을 각각 복호화하고,상기 관심 영역에 대한 정보를 기반으로, 상기 관심영역 기반 처리된 영상을 복원하며, 상기 관심 영역에 대한 정보는 관심 영역의 위치 정보, 선형 움직임 파라미터, 어파인 움직임 파라미터, 및 보상 파라미터 중 적어도 하나를 포함하는, VCM 디코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 어파인 움직임 파라미터는, 스케일(scale), 시어(sheer), 및 회전(rotation)을 포함하는 어파인 움직임을나타내고,상기 어파인 움직임 파라미터는 아래 수학식에 의해 정의되며, 여기서, a, b, c, d는 어파인 파라미터를 나타내고, Trans_x 및 Trans_y는 x 축 및 y축에 대한 변환 모션 정보를 나타내고, x, y는 현재 관심 영역 내 픽셀 값의 위치를 나타내고, x', y'는 어파인 움직임이 적용된 픽셀 값의 위치를 나타내는, VCM 디코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 시간적 복원 수행기는 상기 비트스트림에 대한 복호화를 수행한 이후, 시간적 복원을 먼저 한 후, 하나 이상의 관심 영역을 기반으로 복원 영상을 생성하는, VCM 디코딩 장치.공개특허 10-2025-0045443-5-청구항 17 제12항에 있어서,상기 시간적 복원 수행기는, 복호화된 관심 영역에 대한 정보에 기반하여 하나 이상의 시간적 프레임 복원 방법에 따라 복원된 중간 프레임들 내부의 관심 영역의 위치를 보정하고,상기 하나 이상의 시간적 프레임 복원 방법은 동일한 크기의 관심 영역을 포함하는 프레임인지 여부, 인접한 두프레임의 관심 영역의 크기의 차분 값이 미리 설정된 임계 값 이하인지 여부, 또는 인접한 두 프레임의 관심 영역의 크기의 차분 값이 미리 설정된 임계 값을 초과하는지 여부에 따라 선택되는, VCM 디코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,머신 비전 태스크 수행기를 더 포함하고,상기 머신 비전 태스크 수행기는 학습이 수행된 심층신경망을 이용하여 머신 비전 태스크를 수행하고, 복원된관심영역 기반 처리 정보에 기반하여 머신 비전 태스크 수행 결과를 보정하는, VCM 디코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 머신 비전 태스크 수행기는, 객체 추적을 목적으로 학습된 심층신경망을 이용하여 복원 영상에서 객체를추적하고, 추적된 객체를 포함하는 관심 영역에 대하여, 복원된 관심영역 기반 처리 정보에 기반하여 관심 영역의 위치를보정하는, VCM 디코딩 장치."}
{"patent_id": "10-2024-0061816", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "명령어들을 기록하고 있는 비휘발성(non-volatile) 컴퓨터 판독가능 저장매체로서,상기 명령어들은, 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금:입력 영상의 일부 프레임율을 변경하는 단계;상기 입력 영상의 복수 개의 프레임에 대하여, 각 프레임에 포함된 하나 이상의 관심 영역을 추출하고, 상기 하나 이상의 관심 영역을 기반으로 처리된 영상을 생성하는 단계; 및상기 하나 이상의 관심 영역에 대한 정보 및 상기 입력 영상을 부호화하여 비트스트림을 생성하는 단계를 수행하도록 하고,상기 하나 이상의 관심 영역에 대한 정보는 시간적 샘플링 레이트를 포함하는, 비일시적 컴퓨터 판독가능 저장매체."}
{"patent_id": "10-2024-0061816", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 예시는 VCM(video coding for machines) 인코딩 장치를 제시한다. 상기 인코딩 장치는, 입력 영상 의 일부 프레임율을 변경하는 시간적 리샘플링 수행기; 상기 입력 영상의 복수 개의 프레임에 대하여, 각 프레임 에 포함된 하나 이상의 관심 영역을 추출하고, 상기 하나 이상의 관심 영역을 기반으로 처리된 영상을 생성하는 관심영역 기반 처리기; 및 상기 하나 이상의 관심 영역에 대한 정보 및 상기 입력 영상을 부호화하여 비트스트림 을 생성하는 내부 부호화 수행기를 포함하고, 상기 하나 이상의 관심 영역에 대한 정보는 시간적 샘플링 레이트 를 포함할 수 있다."}
{"patent_id": "10-2024-0061816", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 관심 영역 기반 영상 정보 부호화 및 복호화 방법에 관한 것이다."}
{"patent_id": "10-2024-0061816", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보 통신 산업의 지속적인 발달을 통해 HD(High Definition) 해상도를 가지는 방송 서비스가 세계적으로 확산 되었다. 이러한 확산을 통해, 많은 사용자들이 고해상도이며 고화질인 영상(image) 및/또는 비디오(video)에 익숙해지게 되었고, 보다 높은 화질, 즉 4K 또는 8K 이상의 UHD(Ultra High Definition) 영상/비디오와 같은 고해상도, 고 품질의 영상/비디오에 대한 수요가 다양한 분야에서 증가되었다. 이러한 UHD 영상데이터를 코딩하는 기술은 2013년 표준 기술인 HEVC(High Efficiency Video Coding)를 통해 완 성되었다. HEVC는 이전의 H.264/AVC 기술보다 더 높은 압축률과 더 낮은 복잡도를 갖는 차세대 영상 압축 기술이며, HD급, UHD급 영상의 방대한 데이터를 효과적으로 압축하기 위한 핵심 기술이다. HEVC는 이전의 압축 표준들과 같이 블록 단위의 부호화를 수행한다. 다만 H.264/AVC와 달리 하나의 프로파일만 존재하는 차이점이 있다. HEVC의 유일한 프로파일에 포함된 핵심 부 호화 기술은 총 8개 분야로 계층적 부호화 구조 기술, 변환 기술, 양자화 기술, 화면 내 예측 부호화 기술, 화 면 간 움직임 예측 기술, 엔트로피 부호화 기술, 루프 필터 기술 및 기타 기술이 있다. 2013년 HEVC 비디오 코덱 제정 이후, 4K, 8K를 비디오 영상을 이용한 실감 영상 및 가상 현실 서비스 등이 확대 됨에 따라 HEVC 대비 2배 이상 성능 개선을 목표로 하는 차세대 비디오 코덱인, 다용도 비디오 부호화(VVC: Versatile Video Coding) 표준이 개발되었다. VVC는 H.266으로 불린다. H.266(VVC)은 이전 세대 코덱인 H.265(HEVC)보다 2배 이상의 효율을 목표로 개발되었다. VVC는 처음에는 4K 이 상의 해상도를 감안하고 개발되었으나 점점 VR 시장의 확장으로 인한 360도 영상을 대응할 목적으로 무려 16K 수준의 초고해상도 영상처리용으로도 개발되었다. 또한 점차 디스플레이 기술의 발달로 HDR 시장이 확대됨에 따 라 이에 대응하기 위해 10비트 색심도는 물론이고 16비트 색심도를 지원하며 1000니트, 4000니트, 10000니트의 밝기 표현을 지원한다. 또한 VR시장과 360도 영상시장을 염두하여 개발되고 있기에 0~120 FPS 범위의 부분 프레 임 속도를 지원한다. <인공 지능의 발전> 인공지능(artificial intelligence: AI)도 점차 발전하고 있다. AI는 인간의 지능, 즉 인식(Recognition), 분 류(Classification), 추론(Inference), 예측(Predict), 조작/의사결정(Control/Decision making) 등을 할 수 있는 지능을 인공적으로 모방하는 것을 의미한다. 인공 지능 기술의 발전 및 사물인터넷(Internet Of Things; IOT) 기기의 증가로 인해 기계 간 트래픽이 폭증할 것으로 예측되고, 기계(machine)에 의존하는 영상 분석이 널리 사용될 것으로 예측되고 있다. 그러나, 기계에 의해 분석되어야 할 영상이 기하급수적으로 증가될 것으로 예상됨에 따라, 서버의 부하 및 전력 소모 문제가 제기될 것으로 예측된다."}
{"patent_id": "10-2024-0061816", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 개시는 기계에 의한 영상 분석을 효과적으로 수행할 수 있도록 하기 위하여, 관심 영역 기반 영상 정보 부호화 및 복호화 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2024-0061816", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 목적을 달성하기 위하여, 본 명세서의 일 개시에 따르면, VCM 인코딩 장치가 제공된다. VCM 인코딩 장치는, 입력 영상의 일부 프레임율을 변경하는 시간적 리샘플링 수행기; 상기 입력 영상의 복수 개 의 프레임에 대하여, 각 프레임에 포함된 하나 이상의 관심 영역을 추출하고, 상기 하나 이상의 관심 영역을 기 반으로 처리된 영상을 생성하는 관심영역 기반 처리기; 및 상기 하나 이상의 관심 영역에 대한 정보 및 상기 입 력 영상을 부호화하여 비트스트림을 생성하는 내부 부호화 수행기를 포함하고, 상기 하나 이상의 관심 영역에 대한 정보는 시간적 샘플링 레이트를 포함할 수 있다. 본 명세서의 일 개시에 따른 VCM 디코딩 장치가 제공된다. VCM 디코딩 장치는, 비트스트림을 복호화하여 복원 영상을 생성하는 내부 복호화 수행기; 상기 비트스트림에서 파싱한 관심영역 기반 처리 정보를 이용하여 상기 복원 영상에서 관심 영역을 기반으로 복원 영상을 재구성하는 관심영역 기반 복원기; 상기 비트스트림에서 파싱 한 시간적 리샘플링 정보를 이용하여 상기 복원 영상의 시간적 복원을 수행하는 시간적 복원 수행기를 포함할 수 있다. 본 명세서의 일 개시에 따른 명령어들을 기록하고 있는 비휘발성(non-volatile) 컴퓨터 판독가능 저장매체로서, 상기 명령어들은, 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금: 입력 영 상의 일부 프레임율을 변경하는 단계; 상기 입력 영상의 복수 개의 프레임에 대하여, 각 프레임에 포함된 하나 이상의 관심 영역을 추출하고, 상기 하나 이상의 관심 영역을 기반으로 처리된 영상을 생성하는 단계; 및 상기 하나 이상의 관심 영역에 대한 정보 및 상기 입력 영상을 부호화하여 비트스트림을 생성하는 단계를 수행하도록 하고, 상기 하나 이상의 관심 영역에 대한 정보는 시간적 샘플링 레이트를 포함할 수 있다."}
{"patent_id": "10-2024-0061816", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 의하면, 기계에 의한 영상 분석을 효과적으로 수행할 수 있다. 본 개시에 의하면, VCM 인코딩 장치에서 입력 영상에 대한 관심 영역을 추출하여 전송하는 경우 VCM 디코딩 장 치에서 딥 뉴럴 네트워크의 정확도가 향상될 수 있다. VCM 인코딩 장치는 GOP 또는 일련의 프레임 단위로 관심 영역에 대한 위치, 움직임에 대한 정보를 시그널링하여 VCM 디코딩 장치에 전송할 수 있다. 본 개시에 의하면, VCM 인코딩 장치에서 입력 영상에 대한 시간적 리샘플링을 수행하고 관심 영역을 추출하여 부호화하는 경우, 부호화 효율이 높아질 수 있다. 나아가, VCM 디코딩 장치에서 일부 프레임과 관심 영역 간의 움직임 정보를 기반으로 복원 영상의 시간적 복원을 수행하는 경우 관심 영역의 위치를 보다 정확하게 복원할 수 있다. VCM 디코딩 장치에서 머신 비전 태스크 수행시, 관심 영역 움직임 정보를 기반으로 태스크 수행 결과 에 대한 보정을 할 수 있다. 예를 들어, 빛의 밝기가 급변하는 프레임 사이에서 보정을 통해 객체 태스크의 결 과 정확도를 높일 수 있다."}
{"patent_id": "10-2024-0061816", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 또는 출원에 개시되어 있는 본 개시의 개념에 따른 실시 예들에 대해서 특정한 구조적 내지 단계적 설명들은 단지 본 개시의 개념에 따른 실시 예를 설명하기 위한 목적으로 예시된 것으로, 본 개시의 개념에 따 른 실시 예들은 다양한 형태로 실시될 수 있으며 본 개시의 개념에 따른 실시 예들은 다양한 형태로 실시될 수 있으며 본 명세서 또는 출원에 설명된 실시 예들에 한정되는 것으로 해석되어서는 아니 된다. 본 개시의 개념에 따른 실시 예는 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있으므로 특정 실시 예들을 도면에 예시하고 본 명세서 또는 출원에 상세하게 설명하고자 한다. 그러나, 이는 본 개시의 개념에 따 른 실시 예를 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 개시의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다.제1 및/또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만, 예컨대 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 서술된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식 적인 의미로 해석되지 않는다. 실시 예를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략한다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않고 더욱 명확히 전달하기 위함이다. 이 문서는 비디오/영상 코딩에 관한 것이다. 예를 들어 이 문서에서 개시된 방법/실시예는 VVC (Versatile Video Coding) 표준 (ITU-T Rec. H.266), VVC 이후의 차세대 비디오/이미지 코딩 표준, 또는 그 이외의 비디오 코딩 관련 표준들(예를 들어, HEVC (High Efficiency Video Coding) 표준 (ITU-T Rec. H.265), EVC(essential video coding) 표준, AVS2 표준 등)과 관련될 수 있다. 이 문서에서는 비디오/영상 코딩에 관한 다양한 실시예들을 제시하며, 다른 언급이 없는 한 상기 실시예들은 서 로 조합되어 수행될 수도 있다. 이 문서에서 비디오(video)는 시간의 흐름에 따른 일련의 영상(image)들의 집합을 의미할 수 있다. 픽처 (picture)는 일반적으로 특정 시간대의 하나의 영상을 나타내는 단위를 의미하며, 슬라이스(slice)/타일(tile) 는 코딩에 있어서 픽처의 일부를 구성하는 단위이다. 슬라이스/타일은 하나 이상의 CTU(coding tree unit)을 포함할 수 있다. 하나의 픽처는 하나 이상의 슬라이스/ 타일로 구성될 수 있다. 하나의 픽처는 하나 이상의 타일 그룹으로 구성될 수 있다. 하나의 타일 그룹은 하나 이상의 타일들을 포함할 수 있다. 픽셀(pixel) 또는 펠(pel)은 하나의 픽처(또는 영상)을 구성하는 최소의 단위를 의미할 수 있다. 또한, 픽셀에 대응하는 용어로서 '샘플(sample)'이 사용될 수 있다. 샘플은 일반적으로 픽셀 또는 픽셀의 값을 나타낼 수 있 으며, 루마(luma) 성분의 픽셀/픽셀값만을 나타낼 수도 있고, 크로마(chroma) 성분의 픽셀/픽셀 값만을 나타낼 수도 있다. 또는 샘플은 공간 도메인에서의 픽셀값을 의미할 수도 있고, 이러한 픽셀값이 주파수 도메인으로 변 환되면 주파수 도메인에서의 변환 계수를 의미할 수도 있다. 유닛(unit)은 영상 처리의 기본 단위를 나타낼 수 있다. 유닛은 픽처의 특정 영역 및 해당 영역에 관련된 정보 중 적어도 하나를 포함할 수 있다. 하나의 유닛은 하나의 루마 블록 및 두개의 크로마(ex. cb, cr) 블록을 포함할 수 있다. 유닛은 경우에 따라서 블록(block) 또는 영역(area) 등의 용어와 혼용하여 사용될 수 있다. 일반적인 경우, MxN 블록은 M개의 열과 N 개의 행으로 이루어진 샘플들(또는 샘플 어레이) 또는 변환 계수(transform coefficient)들의 집합(또는어레이)을 포함할 수 있다. 도 1은 비디오/영상 코딩 시스템의 예를 개략적으로 나타낸다. 도 1을 참조하면, 비디오/영상 코딩 시스템은 소스 디바이스 및 수신 디바이스를 포함할 수 있다. 소스 디바이 스는 인코딩된 비디오(video)/영상(image) 정보 또는 데이터를 파일 또는 스트리밍 형태로 디지털 저장매체 또 는 네트워크를 통하여 수신 디바이스로 전달할 수 있다. 상기 소스 디바이스는 비디오 소스, 인코딩 장치, 전송부를 포함할 수 있다. 상기 수신 디바이스는 수신부, 디 코딩 장치 및 렌더러를 포함할 수 있다. 상기 인코딩 장치는 비디오/영상 인코딩 장치라고 불릴 수 있고, 상기 디코딩 장치는 비디오/영상 디코딩 장치 라고 불릴 수 있다. 송신기는 인코딩 장치에 포함될 수 있다. 수신기는 디코딩 장치에 포함될 수 있다. 렌더러 는 디스플레이부를 포함할 수도 있고, 디스플레이부는 별개의 디바이스 또는 외부 컴포넌트로 구성될 수도 있다. 비디오 소스는 비디오/영상의 캡쳐, 합성 또는 생성 과정 등을 통하여 비디오/영상을 획득할 수 있다. 비디오 소스는 비디오/영상 캡쳐 디바이스 및/또는 비디오/영상 생성 디바이스를 포함할 수 있다. 비디오/영상 캡쳐 디 바이스는 예를 들어, 하나 이상의 카메라, 이전에 캡쳐된 비디오/영상을 포함하는 비디오/영상 아카이브 등을 포함할 수 있다. 비디오/영상 생성 디바이스는 예를 들어 컴퓨터, 타블렛 및 스마트폰 등을 포함할 수 있으며 (전자적으로) 비디오/영상을 생성할 수 있다. 예를 들어, 컴퓨터 등을 통하여 가상의 비디오/영상이 생성될 수 있으며, 이 경우 관련 데이터가 생성되는 과정으로 비디오/영상 캡쳐 과정이 갈음될 수 있다. 인코딩 장치는 입력 비디오/영상을 인코딩할 수 있다. 인코딩 장치는 압축 및 코딩 효율을 위하여 예측, 변환, 양자화 등 일련의 절차를 수행할 수 있다. 인코딩된 데이터(인코딩된 비디오/영상 정보)는 비트스트림 (bitstream) 형태로 출력될 수 있다. 전송부는 비트스트림 형태로 출력된 인코딩된 비디오/영상 정보 또는 데이터를 파일 또는 스트리밍 형태로 디지 털 저장매체 또는 네트워크를 통하여 수신 디바이스의 수신부로 전달할 수 있다. 디지털 저장 매체는 USB, SD, CD, DVD, 블루레이, HDD, SSD 등 다양한 저장 매체를 포함할 수 있다. 전송부는 미리 정해진 파일 포맷을 통하 여 미디어 파일을 생성하기 위한 엘리먼트를 포함할 수 있고, 방송/통신 네트워크를 통한 전송을 위한 엘리먼트 를 포함할 수 있다. 수신부는 상기 비트스트림을 수신/추출하여 디코딩 장치로 전달할 수 있다. 디코딩 장치는 인코딩 장치의 동작에 대응하는 역양자화, 역변환, 예측 등 일련의 절차를 수행하여 비디오/영상 을 디코딩할 수 있다. 렌더러는 디코딩된 비디오/영상을 렌더링할 수 있다. 렌더링된 비디오/영상은 디스플레이부를 통하여 디스플레 이될 수 있다. 도 2는 비디오/영상 인코딩 장치의 구성을 개략적으로 설명하는 도면이다. 이하 비디오 인코딩 장치라 함은 영상 인코딩 장치를 포함할 수 있다. 도 2를 참조하면, 인코딩 장치(10a)는 영상 분할부(image partitioner, 10a-10), 예측부(predictor, 10a-20), 레지듀얼 처리부(residual processor, 10a-30), 엔트로피 인코딩부(entropy encoder, 10a-40), 가산부(adder, 10a-50), 필터링부(filter, 10a-60) 및 메모리(memory, 10a-70)를 포함하여 구성될 수 있다. 예측부(10a-20)는 인터 예측부(10a-21) 및 인트라 예측부(10a-22)를 포함할 수 있다. 레지듀얼 처리부(10a-30)는 변환부 (transformer, 10a-32), 양자화부(quantizer 10a-33), 역양자화부(dequantizer 10a-34), 역변환부(inverse transformer, 10a-35)를 포함할 수 있다. 레지듀얼 처리부(10a-30)는 감산부(subtractor, 10a-31)를 더 포함할 수 있다. 가산부(10a-50)는 복원부(reconstructor) 또는 복원 블록 생성부(reconstructed block generator)로 불릴 수 있다. 상술한 영상 분할부(10a-10), 예측부(10a-20), 레지듀얼 처리부(10a-30), 엔트로피 인코딩부 (10a-40), 가산부(10a-50) 및 필터링부(10a-60)는 실시예에 따라 하나 이상의 하드웨어 컴포넌트(예를 들어 인 코더 칩셋 또는 프로세서)에 의하여 구성될 수 있다. 또한 메모리(10a-70)는 DPB(decoded picture buffer)를 포함할 수 있고, 디지털 저장 매체에 의하여 구성될 수도 있다. 상기 하드웨어 컴포넌트는 메모리(10a-70)를 내 /외부 컴포넌트로 더 포함할 수도 있다. 영상 분할부(10a-10)는 인코딩 장치(10a)에 입력된 입력 영상(또는, 픽처, 프레임)를 하나 이상의 처리 유닛 (processing unit)으로 분할할 수 있다. 일 예로, 상기 처리 유닛은 코딩 유닛(coding unit, CU)이라고 불릴 수 있다. 이 경우 코딩 유닛은 코딩 트리 유닛(coding tree unit, CTU) 또는 최대 코딩 유닛(largest coding unit, LCU)으로부터 QTBTTT (Quad-tree binary-tree ternary-tree) 구조에 따라 재귀적으로(recursively) 분할될 수 있다. 예를 들어, 하나의 코딩 유 닛은 쿼드 트리 구조, 바이너리 트리 구조, 및/또는 터너리 구조를 기반으로 하위(deeper) 뎁스의 복수의 코딩 유닛들로 분할될 수 있다. 이 경우 예를 들어 쿼드 트리 구조가 먼저 적용되고 바이너리 트리 구조 및/또는 터 너리 구조가 나중에 적용될 수 있다. 또는 바이너리 트리 구조가 먼저 적용될 수도 있다. 더 이상 분할되지 않 는 최종 코딩 유닛을 기반으로 본 문서에 따른 코딩 절차가 수행될 수 있다. 이 경우 영상 특성에 따른 코딩 효 율 등을 기반으로, 최대 코딩 유닛이 바로 최종 코딩 유닛으로 사용될 수 있고, 또는 필요에 따라 코딩 유닛은 재귀적으로(recursively) 보다 하위 뎁스의 코딩 유닛들로 분할되어 최적의 사이즈의 코딩 유닛이 최종 코딩 유 닛으로 사용될 수 있다. 여기서 코딩 절차라 함은 후술하는 예측, 변환, 및 복원 등의 절차를 포함할 수 있다. 다른 예로, 상기 처리 유닛은 예측 유닛(PU: Prediction Unit) 또는 변환 유닛(TU: Transform Unit)을 더 포함 할 수 있다. 이 경우 상기 예측 유닛 및 상기 변환 유닛은 각각 상술한 최종 코딩 유닛으로부터 분할 또는 파티 셔닝될 수 있다. 상기 예측 유닛은 샘플 예측의 단위일 수 있고, 상기 변환 유닛은 변환 계수를 유도하는 단위 및/또는 변환 계수로부터 레지듀얼 신호(residual signal)를 유도하는 단위일 수 있다. 유닛은 경우에 따라서 블록(block) 또는 영역(area) 등의 용어와 혼용하여 사용될 수 있다. 일반적인 경우, MxN 블록은 M개의 열과 N개의 행으로 이루어진 샘플들 또는 변환 계수(transform coefficient)들의 집합을 나타낼 수 있다. 샘플은 일반적으로 픽셀 또는 픽셀의 값을 나타낼 수 있으며, 휘도(luma) 성분의 픽셀/픽셀값만을 나 타낼 수도 있고, 채도(chroma) 성분의 픽셀/픽셀 값만을 나타낼 수도 있다. 샘플은 하나의 픽처(또는 영상)을 픽셀(pixel) 또는 펠(pel)에 대응하는 용어로서 사용될 수 있다. 감산부(10a-31)는 입력 영상 신호(원본 블록, 원본 샘플들 또는 원본 샘플 어레이)에서 예측부(10a-20)로부터 출력된 예측 신호(예측된 블록, 예측 샘플들 또는 예측 샘플 어레이)를 감산하여 레지듀얼 신호(레지듀얼 블록, 레지듀얼 샘플들 또는 레지듀얼 샘플 어레이)를 생성할 수 있고, 생성된 레지듀얼 신호는 변환부(10a-32)로 전 송된다. 예측부(10a-20)는 처리 대상 블록(이하, 현재 블록이라 함)에 대한 예측을 수행하고, 상기 현재 블록에 대한 예측 샘플들을 포함하는 예측된 블록(predicted block)을 생성할 수 있다. 예측부(10a-20)는 현재 블록 또는 CU 단위로 인트라 예측이 적용되는지 또는 인터 예측이 적용되는지 결정할 수 있다. 예측부는 각 예측모드에 대한 설명에서 후술하는 바와 같이 예측 모드 정보 등 예측에 관한 다양한 정보 를 생성하여 엔트로피 인코딩부(10a-40)로 전달할 수 있다. 예측에 관한 정보는 엔트로피 인코딩부(10a-40)에서 인코딩되어 비트스트림 형태로 출력될 수 있다. 인트라 예측부(10a-22)는 현재 픽처 내의 샘플들을 참조하여 현재 블록을 예측할 수 있다. 상기 참조되는 샘플 들은 예측 모드에 따라 상기 현재 블록의 주변(neighbor)에 위치할 수 있고, 또는 떨어져서 위치할 수도 있다. 인트라 예측에서 예측 모드들은 복수의 비방향성 모드와 복수의 방향성 모드를 포함할 수 있다. 비방향성 모드 는 예를 들어 DC 모드 및 플래너 모드(Planar 모드)를 포함할 수 있다. 방향성 모드는 예측 방향의 세밀한 정도 에 따라 예를 들어 33개의 방향성 예측 모드 또는 65개의 방향성 예측 모드를 포함할 수 있다. 다만, 이는 예시로서 설정에 따라 그 이상 또는 그 이하의 개수의 방향성 예측 모드들이 사용될 수 있다. 인트 라 예측부(10a-22)는 주변 블록에 적용된 예측 모드를 이용하여, 현재 블록에 적용되는 예측 모드를 결정할 수 도 있다. 인터 예측부(10a-21)는 참조 픽처 상에서 움직임 벡터에 의해 특정되는 참조 블록(참조 샘플 어레이)을 기반으 로, 현재 블록에 대한 예측된 블록을 유도할 수 있다. 이때, 인터 예측 모드에서 전송되는 움직임 정보의 양을 줄이기 위해 주변 블록과 현재 블록 간의 움직임 정보의 상관성에 기초하여 움직임 정보를 블록, 서브블록 또는 샘플 단위로 예측할 수 있다. 상기 움직임 정보는 움직임 벡터 및 참조 픽처 인덱스를 포함할 수 있다. 상기 움 직임 정보는 인터 예측 방향(L0 예측, L1 예측, Bi 예측 등) 정보를 더 포함할 수 있다. 인터 예측의 경우에, 주변 블록은 현재 픽처 내에 존재하는 공간적 주변 블록(spatial neighboring block)과 참조 픽처에 존재하는 시간적 주변 블록(temporal neighboring block)을 포함할 수 있다. 상기 참조 블록을 포함하는 참조 픽처와 상 기 시간적 주변 블록을 포함하는 참조 픽처는 동일할 수도 있고, 다를 수도 있다. 상기 시간적 주변 블록은 동 일 위치 참조 블록(collocated reference block), 동일 위치 CU(colCU) 등의 이름으로 불릴 수 있으며, 상기 시간적 주변 블록을 포함하는 참조 픽처는 동일 위치 픽처(collocated picture, colPic)라고 불릴 수도 있다.예를 들어, 인터 예측부(10a-21)는 주변 블록들을 기반으로 움직임 정보 후보 리스트를 구성하고, 상기 현재 블 록의 움직임 벡터 및/또는 참조 픽처 인덱스를 도출하기 위하여 어떤 후보가 사용되는지를 지시하는 정보를 생 성할 수 있다. 다양한 예측 모드를 기반으로 인터 예측이 수행될 수 있으며, 예를 들어 스킵 모드와 머지 모드 의 경우에, 인터 예측부(10a-21)는 주변 블록의 움직임 정보를 현재 블록의 움직임 정보로 이용할 수 있다. 스 킵 모드의 경우, 머지 모드와 달리 레지듀얼 신호가 전송되지 않을 수 있다. 움직임 정보 예측(motion vector prediction, MVP) 모드의 경우, 주변 블록의 움직임 벡터를 움직임 벡터 예측자(motion vector predictor)로 이용하고, 움직임 벡터 차분(motion vector difference)을 시그널링함으로써 현재 블록의 움직임 벡터를 지시할 수 있다. 예측부(10a-20)는 후술하는 다양한 예측 방법을 기반으로 예측 신호를 생성할 수 있다. 예를 들어, 예측부는 하 나의 블록에 대한 예측을 위하여 인트라 예측 또는 인터 예측을 적용할 수 있을 뿐 아니라, 인트라 예측과 인터 예측을 동시에 적용할 수 있다. 이는 combined inter and intra prediction (CIIP)라고 불릴 수 있다. 또한, 예측부는 블록에 대한 예측을 위하여 인트라 블록 카피(intra block copy, IBC)를 수행할 수도 있다. 상기 인트 라 블록 카피는 예를 들어 SCC(screen content coding) 등과 같이 게임 등의 컨텐츠 영상/동영상 코딩을 위하여 사용될 수 있다. IBC는 기본적으로 현재 픽처 내에서 예측을 수행하나 현재 픽처 내에서 참조 블록을 도출하는 점에서 인터 예측과 유사하게 수행될 수 있다. 즉, IBC는 본 문서에서 설명되는 인터 예측 기법들 중 적어도 하 나를 이용할 수 있다. 인터 예측부(10a-21) 및/또는 인트라 예측부(10a-22)를 통해 생성된 예측 신호는 복원 신호를 생성하기 위해 이 용되거나 레지듀얼 신호를 생성하기 위해 이용될 수 있다. 변환부(10a-32)는 레지듀얼 신호에 변환 기법을 적용 하여 변환 계수들(transform coefficients)를 생성할 수 있다. 예를 들어, 변환 기법은 DCT(Discrete Cosine Transform), DST(Discrete Sine Transform), GBT(Graph-Based Transform), 또는 CNT(Conditionally Non- linear Transform) 등을 포함할 수 있다. 여기서, GBT는 픽셀 간의 관계 정보를 그래프로 표현한다고 할 때 이 그래프로부터 얻어진 변환을 의미한다. CNT는 이전에 복원된 모든 픽셀(all previously reconstructed pixel) 를 이용하여 예측 신호를 생성하고 그에 기초하여 획득되는 변환을 의미한다. 또한, 변환 과정은 정사각형의 동 일한 크기를 갖는 픽셀 블록에 적용될 수도 있고, 정사각형이 아닌 가변 크기의 블록에도 적용될 수 있다. 양자화부(10a-33)는 변환 계수들을 양자화하여 엔트로피 인코딩부(10a-40)로 전송되고, 엔트로피 인코딩부(10a- 40)는 양자화된 신호(양자화된 변환 계수들에 관한 정보)를 인코딩하여 비트스트림으로 출력할 수 있다. 상기 양자화된 변환 계수들에 관한 정보는 레지듀얼 정보라고 불릴 수 있다. 양자화부(10a-33)는 계수 스캔 순서(scan order)를 기반으로 블록 형태의 양자화된 변환 계수들을 1차원 벡터 형태로 재정렬할 수 있고, 상기 1차원 벡터 형태의 양자화된 변환 계수들을 기반으로 상기 양자화된 변환 계수 들에 관한 정보를 생성할 수도 있다. 엔트로피 인코딩부(10a-40)는 예를 들어 지수 골롬(exponential Golomb), CAVLC(context-adaptive variable length coding), CABAC(context-adaptive binary arithmetic coding) 등과 같은 다양한 인코딩 방법을 수행할 수 있다. 엔트로피 인코딩부(10a-40)는 양자화된 변환 계수들 외 비디오/이미지 복원에 필요한 정보들(예컨대 신택스 요 소들(syntax elements)의 값 등)을 함께 또는 별도로 인코딩할 수도 있다. 인코딩된 정보(ex. 인코딩된 비디오/ 영상 정보)는 비트스트림 형태로 NAL(network abstraction layer) 유닛 단위로 전송 또는 저장될 수 있다. 상기 비디오/영상 정보는 어댑테이션 파라미터 세트(APS), 픽처 파라미터 세트(PPS), 시퀀스 파라미터 세트(SPS) 또 는 비디오 파라미터 세트(VPS) 등 다양한 파라미터 세트에 관한 정보를 더 포함할 수 있다. 또한 상기 비디오/ 영상 정보는 일반 제한 정보(general constraint information)을 더 포함할 수 있다. 본 문서에서 후술되는 시 그널링/전송되는 정보 및/또는 신택스 요소들은 상술한 인코딩 절차를 통하여 인코딩되어 상기 비트스트림에 포 함될 수 있다. 상기 비트스트림은 네트워크를 통하여 전송될 수 있고, 또는 디지털 저장매체에 저장될 수 있다. 여기서 네트워크는 방송망 및/또는 통신망 등을 포함할 수 있고, 디지털 저장매체는 USB, SD, CD, DVD, 블루레 이, HDD, SSD 등 다양한 저장매체를 포함할 수 있다. 엔트로피 인코딩부(10a-40)로부터 출력된 신호는 전송하는 전송부(미도시) 및/또는 저장하는 저장부(미도시)가 인코딩 장치(10a)의 내/외부 엘리먼트로서 구성될 수 있고, 또는 전송부는 엔트로피 인코딩부(10a-40)에 포함될 수도 있다. 양자화부(10a-33)로부터 출력된 양자화된 변환 계수들은 예측 신호를 생성하기 위해 이용될 수 있다. 예를 들어, 양자화된 변환 계수들에 역양자화부(10a-34) 및 역변환부(10a-35)를 통해 역양자화 및 역변환을 적용함으 로써 레지듀얼 신호(레지듀얼 블록 or 레지듀얼 샘플들)를 복원할 수 있다. 가산부(10a-50)는 복원된 레지듀얼 신호를 예측부(10a-20)로부터 출력된 예측 신호에 더함으로써 복원(reconstructed) 신호(복원 픽처, 복원 블록,복원 샘플들 또는 복원 샘플 어레이)가 생성될 수 있다. 스킵 모드가 적용된 경우와 같이 처리 대상 블록에 대 한 레지듀얼이 없는 경우, 예측된 블록이 복원 블록으로 사용될 수 있다. 생성된 복원 신호는 현재 픽처 내 다 음 처리 대상 블록의 인트라 예측을 위하여 사용될 수 있고, 후술하는 바와 같이 필터링을 거쳐서 다음 픽처의 인터 예측을 위하여 사용될 수도 있다. 한편 픽처 인코딩 및/또는 복원 과정에서 LMCS (luma mapping with chroma scaling)가 적용될 수도 있다. 필터링부(10a-60)는 복원 신호에 필터링을 적용하여 주관적/객관적 화질을 향상시킬 수 있다. 예를 들어 필터링 부(10a-60)는 복원 픽처에 다양한 필터링 방법을 적용하여 수정된(modified) 복원 픽처를 생성할 수 있고, 상기 수정된 복원 픽처를 메모리(10a-70), 구체적으로 메모리(10a-70)의 DPB에 저장할 수 있다. 상기 다양한 필터링 방법은 예를 들어, 디블록킹 필터링, 샘플 적응적 오프셋(sample adaptive offset, SAO), 적응적 루프 필터 (adaptive loop filter), 양방향 필터(bilateral filter) 등을 포함할 수 있다. 필터링부(10a-60)는 각 필터링 방법에 대한 설명에서 후술하는 바와 같이 필터링에 관한 다양한 정보를 생성하여 엔트로피 인코딩부(10a-90)로 전달할 수 있다. 필터링 관한 정보는 엔트로피 인코딩부(10a-90)에서 인코딩되어 비트스트림 형태로 출력될 수 있다. 메모리(10a-70)에 전송된 수정된 복원 픽처는 인터 예측부(10a-80)에서 참조 픽처로 사용될 수 있다. 인코딩 장 치는 이를 통하여 인터 예측이 적용되는 경우, 인코딩 장치(10a)와 디코딩 장치에서의 예측 미스매치를 피할 수 있고, 부호화 효율도 향상시킬 수 있다. 메모리(10a-70)의 DPB는 수정된 복원 픽처를 인터 예측부(10a-21)에서의 참조 픽처로 사용하기 위해 저장할 수 있다. 메모리(10a-70)는 현재 픽처 내 움직임 정보가 도출된(또는 인코딩된) 블록의 움직임 정보 및/또는 이미 복원된 픽처 내 블록들의 움직임 정보를 저장할 수 있다. 상기 저장된 움직임 정보는 공간적 주변 블록의 움직 임 정보 또는 시간적 주변 블록의 움직임 정보로 활용하기 위하여 인터 예측부(10a-21)에 전달할 수 있다. 메모 리(10a-70)는 현재 픽처 내 복원된 블록들의 복원 샘플들을 저장할 수 있고, 인트라 예측부(10a-22)에 전달할 수 있다. 도 3은 비디오/영상 디코딩 장치의 구성을 개략적으로 설명하는 도면이다. 도 3을 참조하면, 디코딩 장치(10b)는 엔트로피 디코딩부(entropy decoder, 10b-10), 레지듀얼 처리부 (residual processor, 10b-20), 예측부(predictor, 10b-30), 가산부(adder, 10b-40), 필터링부(filter, 10b- 50) 및 메모리(memory, 10b-60)를 포함하여 구성될 수 있다. 예측부(10b-30)는 인터 예측부(10b-31) 및 인트라 예측부(10b-32)를 포함할 수 있다. 레지듀얼 처리부(10b-20)는 역양자화부(dequantizer, 10b-21) 및 역변환부 (inverse transformer, 10b-21)를 포함할 수 있다. 상술한 엔트로피 디코딩부(10b-10), 레지듀얼 처리부(10b- 20), 예측부(10b-30), 가산부(10b-40) 및 필터링부(10b-50)는 실시예에 따라 하나의 하드웨어 컴포넌트(예를 들 어 디코더 칩셋 또는 프로세서)에 의하여 구성될 수 있다. 또한 메모리(10b-60)는 DPB(decoded picture buffer)를 포함할 수 있고, 디지털 저장 매체에 의하여 구성될 수도 있다. 상기 하드웨어 컴포넌트는 메모리 (10b-60)을 내/외부 컴포넌트로 더 포함할 수도 있다. 비디오/영상 정보를 포함하는 비트스트림이 입력되면, 디코딩 장치(10b)는 도 2의 인코딩 장치에서 비디오/영상 정보가 처리된 프로세스에 대응하여 영상을 복원할 수 있다. 예를 들어, 디코딩 장치(10b)는 상기 비트스트림으 로부터 획득한 블록 분할 관련 정보를 기반으로 유닛들/블록들을 도출할 수 있다. 디코딩 장치(10b)는 인코딩 장치에서 적용된 처리 유닛을 이용하여 디코딩을 수행할 수 있다. 따라서 디코딩의 처리 유닛은 예를 들어 코딩 유닛일 수 있고, 코딩 유닛은 코딩 트리 유닛 또는 최대 코딩 유닛으로부터 쿼드 트리 구조, 바이너리 트리 구 조 및/또는 터너리 트리 구조를 따라서 분할될 수 있다. 코딩 유닛으로부터 하나 이상의 변환 유닛이 도출될 수 있다. 그리고, 디코딩 장치(10b)를 통해 디코딩 및 출력된 복원 영상 신호는 재생 장치를 통해 재생될 수 있다. 디코딩 장치(10b)는 도 2의 인코딩 장치로부터 출력된 신호를 비트스트림 형태로 수신할 수 있고, 수신된 신호 는 엔트로피 디코딩부(10b-10)를 통해 디코딩될 수 있다. 예를 들어, 엔트로피 디코딩부(10b-10)는 상기 비트스 트림을 파싱하여 영상 복원(또는 픽처 복원)에 필요한 정보(ex. 비디오/영상 정보)를 도출할 수 있다. 상기 비 디오/영상 정보는 어댑테이션 파라미터 세트(APS), 픽처 파라미터 세트(PPS), 시퀀스 파라미터 세트(SPS) 또는 비디오 파라미터 세트(VPS) 등 다양한 파라미터 세트에 관한 정보를 더 포함할 수 있다. 또한 상기 비디오/영상 정보는 일반 제한 정보(general constraint information)을 더 포함할 수 있다. 디코딩 장치는 상기 파라미터 세트에 관한 정보 및/또는 상기 일반 제한 정보를 더 기반으로 픽처를 디코딩할 수 있다. 본 문서에서 후술되는 시그널링/수신되는 정보 및/또는 신택스 요소들은 상기 디코딩 절차를 통하여디코딩되어 상기 비트스트림으로부터 획득될 수 있다. 예컨대, 엔트로피 디코딩부(10b-10)는 지수 골롬 부호화, CAVLC 또는 CABAC 등의 코딩 방법을 기초로 비트스트림 내 정보를 디코딩하고, 영상 복원에 필요한 신택스 엘리 먼트의 값, 레지듀얼에 관한 변환 계수의 양자화된 값 들을 출력할 수 있다. 보다 상세하게, CABAC 엔트로피 디코딩 방법은, 비트스트림에서 각 구문 요소에 해당하는 빈을 수신하고, 디코 딩 대상 구문 요소 정보와 주변 및 디코딩 대상 블록의 디코딩 정보 혹은 이전 단계에서 디코딩된 심볼/빈의 정 보를 이용하여 문맥(context) 모델을 결정하고, 결정된 문맥 모델에 따라 빈(bin)의 발생 확률을 예측하여 빈의 산술 디코딩(arithmetic decoding)를 수행하여 각 구문 요소의 값에 해당하는 심볼을 생성할 수 있다. 이때, CABAC 엔트로피 디코딩 방법은 문맥 모델 결정 후 다음 심볼/빈의 문맥 모델을 위해 디코딩된 심볼/빈의 정보를 이용하여 문맥 모델을 업데이트할 수 있다. 엔트로피 디코딩부(10b-10)에서 디코딩된 정보 중 예측에 관한 정보 는 예측부(10b-30)로 제공되고, 엔트로피 디코딩부(10b-10)에서 엔트로피 디코딩이 수행된 레지듀얼에 대한 정 보, 즉 양자화된 변환 계수들 및 관련 파라미터 정보는 역양자화부(10b-21)로 입력될 수 있다. 또한, 엔트로피 디코딩부(10b-10)에서 디코딩된 정보 중 필터링에 관한 정보는 필터링부(10b-50)으로 제공될 수 있다. 한편, 인코딩 장치로부터 출력된 신호를 수신하는 수신부(미도시)가 디코딩 장치(10b)의 내/외부 엘리먼 트로서 더 구성될 수 있고, 또는 수신부는 엔트로피 디코딩부(10b-10)의 구성요소일 수도 있다. 한편, 본 문서 에 따른 디코딩 장치는 비디오/영상/픽처 디코딩 장치라고 불릴 수 있고, 상기 디코딩 장치는 정보 디코더(비디 오/영상/픽처 정보 디코더) 및 샘플 디코더(비디오/영상/픽처 샘플 디코더)로 구분할 수도 있다. 상기 정보 디 코더는 상기 엔트로피 디코딩부(10b-10)를 포함할 수 있고, 상기 샘플 디코더는 상기 역양자화부(10b-21), 역변 환부(10b-22), 예측부(10b-30), 가산부(10b-40), 필터링부(10b-50) 및 메모리(10b-60) 중 적어도 하나를 포함 할 수 있다. 역양자화부(10b-21)에서는 양자화된 변환 계수들을 역양자화하여 변환 계수들을 출력할 수 있다. 역양자화부 (10b-21)는 양자화된 변환 계수들을 2차원의 블록 형태로 재정렬할 수 있다. 이 경우 상기 재정렬은 인코딩 장 치에서 수행된 계수 스캔 순서를 기반하여 재정렬을 수행할 수 있다. 역양자화부(10b-21)는 양자화 파라미터(예 를 들어 양자화 스텝 사이즈 정보)를 이용하여 양자화된 변환 계수들에 대한 역양자화를 수행하고, 변환 계수들 (transform coefficient)를 획득할 수 있다. 역변환부(10b-22)에서는 변환 계수들를 역변환하여 레지듀얼 신호(레지듀얼 블록, 레지듀얼 샘플 어레이)를 획 득하게 된다. 예측부는 현재 블록에 대한 예측을 수행하고, 상기 현재 블록에 대한 예측 샘플들을 포함하는 예측된 블록 (predicted block)을 생성할 수 있다. 예측부는 엔트로피 디코딩부(10b-10)로부터 출력된 상기 예측에 관한 정보를 기반으로 상기 현재 블록에 인트라 예측이 적용되는지 또는 인터 예측이 적용되는지 결정할 수 있고, 구체적인 인트라/인터 예측 모드를 결정할 수 있다. 예측부는 후술하는 다양한 예측 방법을 기반으로 예측 신호를 생성할 수 있다. 예를 들어, 예측부는 하나의 블 록에 대한 예측을 위하여 인트라 예측 또는 인터 예측을 적용할 수 있을 뿐 아니라, 인트라 예측과 인터 예측을 동시에 적용할 수 있다. 이는 combined inter and intra prediction (CIIP)라고 불릴 수 있다. 또한, 예측부는 블록에 대한 예측을 위하여 인트라 블록 카피(intra block copy, IBC)를 수행할 수도 있다. 상기 인트라 블록 카피는 예를 들어 SCC(screen content coding) 등과 같이 게임 등의 컨텐츠 영상/동영상 코딩을 위하여 사용될 수 있다. IBC는 기본적으로 현재 픽처 내에서 예측을 수행하나 현재 픽처 내에서 참조 블록을 도출하는 점에서 인터 예측과 유사하게 수행될 수 있다. 즉, IBC는 본 문서에서 설명되는 인터 예측 기법들 중 적어도 하나를 이 용할 수 있다. 인트라 예측부(10b-32)는 현재 픽처 내의 샘플들을 참조하여 현재 블록을 예측할 수 있다. 상기 참조되는 샘플 들은 예측 모드에 따라 상기 현재 블록의 주변(neighbor)에 위치할 수 있고, 또는 떨어져서 위치할 수도 있다. 인트라 예측에서 예측 모드들은 복수의 비방향성 모드와 복수의 방향성 모드를 포함할 수 있다. 인트라 예측부 (10b-32)는 주변 블록에 적용된 예측 모드를 이용하여, 현재 블록에 적용되는 예측 모드를 결정할 수도 있다. 인터 예측부(10b-31)는 참조 픽처 상에서 움직임 벡터에 의해 특정되는 참조 블록(참조 샘플 어레이)을 기반으 로, 현재 블록에 대한 예측된 블록을 유도할 수 있다. 이때, 인터 예측 모드에서 전송되는 움직임 정보의 양을 줄이기 위해 주변 블록과 현재 블록 간의 움직임 정보의 상관성에 기초하여 움직임 정보를 블록, 서브블록 또는 샘플 단위로 예측할 수 있다. 상기 움직임 정보는 움직임 벡터 및 참조 픽처 인덱스를 포함할 수 있다. 상기 움직임 정보는 인터 예측 방향(L0 예측, L1 예측, Bi 예측 등) 정보를 더 포함할 수 있다. 인터 예측의 경우에, 주변 블록은 현재 픽처 내에 존재하는 공간적 주변 블록(spatial neighboring block)과 참 조 픽처에 존재하는 시간적 주변 블록(temporal neighboring block)을 포함할 수 있다. 예를 들어, 인터 예측부 (10b-31)는 주변 블록들을 기반으로 움직임 정보 후보 리스트를 구성하고, 수신한 후보 선택 정보를 기반으로 상기 현재 블록의 움직임 벡터 및/또는 참조 픽처 인덱스를 도출할 수 있다. 다양한 예측 모드를 기반으로 인터 예측이 수행될 수 있으며, 상기 예측에 관한 정보는 상기 현재 블록에 대한 인터 예측의 모드를 지시하는 정보 를 포함할 수 있다. 가산부(10b-40)는 획득된 레지듀얼 신호를 예측부(10b-30)로부터 출력된 예측 신호(예측된 블록, 예측 샘플 어 레이)에 더함으로써 복원 신호(복원 픽처, 복원 블록, 복원 샘플 어레이)를 생성할 수 있다. 스킵 모드가 적용 된 경우와 같이 처리 대상 블록에 대한 레지듀얼이 없는 경우, 예측된 블록이 복원 블록으로 사용될 수 있다. 가산부(10b-40)는 복원부 또는 복원 블록 생성부라고 불릴 수 있다. 생성된 복원 신호는 현재 픽처 내 다음 처리 대상 블록의 인트라 예측을 위하여 사용될 수 있고, 후술하는 바와 같이 필터링을 거쳐서 출력될 수도 있고 또는 다음 픽처의 인터 예측을 위하여 사용될 수도 있다. 한편, 픽처 디코딩 과정에서 LMCS (luma mapping with chroma scaling)가 적용될 수도 있다. 필터링부(10b-50)는 복원 신호에 필터링을 적용하여 주관적/객관적 화질을 향상시킬 수 있다. 예를 들어 필터링 부(10b-50)는 복원 픽처에 다양한 필터링 방법을 적용하여 수정된(modified) 복원 픽처를 생성할 수 있고, 상기 수정된 복원 픽처를 메모리, 구체적으로 메모리(10b-60)의 DPB에 전송할 수 있다. 상기 다양한 필터링 방법 은 예를 들어, 디블록킹 필터링, 샘플 적응적 오프셋(sample adaptive offset), 적응적 루프 필터(adaptive loop filter), 양방향 필터(bilateral filter) 등을 포함할 수 있다. 메모리(10b-60)의 DPB에 저장된 (수정된) 복원 픽처는 인터 예측부(10b-31)에서 참조 픽쳐로 사용될 수 있다. 메모리(10b-60)는 현재 픽처 내 움직임 정보가 도출된(또는 디코딩된) 블록의 움직임 정보 및/또는 이미 복원된 픽처 내 블록들의 움직임 정보를 저장할 수 있다. 상기 저장된 움직임 정보는 공간적 주변 블록의 움직임 정보 또는 시간적 주변 블록의 움직임 정보로 활용하기 위하여 인터 예측부(10b-31)에 전달할 수 있다. 메모리(10b- 60)는 현재 픽처 내 복원된 블록들의 복원 샘플들을 저장할 수 있고, 인트라 예측부(10b-32)에 전달할 수 있다. 본 명세서에서, 디코딩 장치(10b)의 예측부(10b-30), 역양자화부(10b-21), 역변환부(10b-22) 및 필터링부(10b- 50) 등에서 설명된 실시예들은 각각 인코딩 장치(10a)의 예측부(10a-20), 역양자화부(10a-34), 역변환부(10a- 35) 및 필터링부(10a-60) 등에도 동일 또는 대응되도록 적용될 수 있다. 상술한 바와 같이 비디오 코딩을 수행함에 있어 압축 효율을 높이기 위하여 예측을 수행한다. 이를 통하여 코딩 대상 블록인 현재 블록에 대한 예측 샘플들을 포함하는 예측된 블록을 생성할 수 있다. 여기서 상기 예측된 블 록은 공간 도메인(또는 픽셀 도메인)에서의 예측 샘플들을 포함한다. 상기 예측된 블록은 인코딩 장치 및 디코 딩 장치에서 동일하게 도출되며, 상기 인코딩 장치는 원본 블록의 원본 샘플 값 자체가 아닌 상기 원본 블록과 상기 예측된 블록 간의 레지듀얼에 대한 정보(레지듀얼 정보)를 디코딩 장치로 시그널링함으로써 영상 코딩 효 율을 높일 수 있다. 디코딩 장치는 상기 레지듀얼 정보를 기반으로 레지듀얼 샘플들을 포함하는 레지듀얼 블록 을 도출하고, 상기 레지듀얼 블록과 상기 예측된 블록을 합하여 복원 샘플들을 포함하는 복원 블록을 생성할 수 있고, 복원 블록들을 포함하는 복원 픽처를 생성할 수 있다. 상기 레지듀얼 정보는 변환 및 양자화 절차를 통하여 생성될 수 있다. 예를 들어, 인코딩 장치는 상기 원본 블록과 상기 예측된 블록 간의 레지듀얼 블록을 도출하고, 상기 레지듀얼 블록에 포함된 레지듀얼 샘플들(레지듀얼 샘플 어레이)에 변환 절차를 수행하여 변환 계수들을 도출하고, 상기 변환 계수들에 양자화 절차를 수행하여 양자화된 변환 계수들을 도출하여 관련된 레지듀얼 정보를 (비트스트림 을 통하여) 디코딩 장치로 시그널링할 수 있다. 여기서 상기 레지듀얼 정보는 상기 양자화된 변환 계수들의 값 정보, 위치 정보, 변환 기법, 변환 커널, 양자화 파라미터 등의 정보를 포함할 수 있다. 디코딩 장치는 상기 레 지듀얼 정보를 기반으로 역양자화/역변환 절차를 수행하고 레지듀얼 샘플들(또는 레지듀얼 블록)을 도출할 수 있다. 디코딩 장치는 예측된 블록과 상기 레지듀얼 블록을 기반으로 복원 픽처를 생성할 수 있다. 인코딩 장치 는 또한 이후 픽처의 인터 예측을 위한 참조를 위하여 양자화된 변환 계수들을 역양자화/역변환하여 레지듀얼 블록을 도출하고, 이를 기반으로 복원 픽처를 생성할 수 있다.<VCM(Video coding for Machines)> 최근에 Surveillance, Intelligent Transportation, Smart City, Intelligent Industry, Intelligent Content 와 같은 다양한 산업 분야가 발전함에 따라 기계에 의해 소비되는 영상 또는 특징맵(Feature Map) 데이터양이 증가하고 있다. 이에 반해, 현재 사용 중인 전통적인 영상 압축방식은 시청자가 인지하는 시각(Human Vision)의 특성을 고려해 개발된 기술이기에 불필요한 정보들을 포함하고 있어 기계 임무 수행에 비효율적이다. 예를 들어, 시청자 시각 기준의 영상은 기계의 데이터 소비시각의 영상(예, 특징맵)보다 해상도가 높을 수 있다. 따 라서, 기계 임무 수행에 대해 효율적으로 특징맵을 압축하기 위한 비디오 코덱 기술에 관한 연구가 요구되고 있 다. 멀티미디어 부호화 국제표준화 그룹인 MPEG(Moving Picture Experts Group)에서 VCM(Video Coding for Machine) 기술이 논의되고 있다. VCM은 사람이 보는 시청자 시각 기준이 아닌 기계의 데이터 소비시각(Machine Vision)에 대한 기준의 영상 또는 특징맵 부호화 기술이다. 이 문서에서는 특징맵을 피처맵이라 지칭할 수 있고, 특징은 피처라 지칭할 수 있다. 도 4a 내지 도 4d는 VCM 인코더와 VCM 디코더를 나타낸 예시도들이다. 도 4a을 참조하면, VCM 인코더(100a)와 VCM 디코더(100b)가 나타나 있다. VCM 인코더(100a)가 비디오 및/또는 특징맵을 인코딩하여 비트스트림으로 전송하면, VCM 디코더(100b)는 상기 비트스트림을 디코딩하여 출력할 수 있다. 이때, VCM 디코더(100b)는 하나 이상의 비디오 및/또는 특징맵을 출 력할 수 있다. 예를 들어, VCM 디코더(100b)는 머신을 이용한 분석을 위한 제1 특징맵을 출력할 수 있고, 사용 자에 의한 시청을 위한 제1 영상을 출력할 수 있다. 상기 제1 영상은 상기 제1 특징맵에 비하여 보다 고해상도 일 수 있다. 도 4b를 참조하면, VCM 인코더(100a)의 전단에는 특징맵을 추출하는 특징 추출기(Feature Extractor)가 연결될 수 있다. VCM 인코더(100a)는 피처 인코더(Feature Encoder)를 포함할 수 있다. VCM 디코더(100b)는 피처 디코더(Feature Decoder)와 비디오 재생성기(Video reconstructor)를 포함할 수 있다. 상기 피처 디코더는 비트스트림으로부터 피처맵(Feature Map)을 디코딩하여, 머신을 이용한 분석을 위한 제1 특징맵을 출력할 수 있다. 상기 비디오 재생성기는 비트스트림으로부터 사용자에 의한 시청을 위한 제1 영 상을 재생성하여 출력할 수 있다. 도 4c 참조하면, VCM 인코더의 전단에는 특징맵을 추출하는 특징 추출기(Feature Extractor)가 연결되어 있다. VCM 인코더(100a)는 피처 인코더를 포함할 수 있다. VCM 디코더(100b)는 피처 디코더를 포함할 수 있다. 상기 피처 디코더는 비트스트림으로부터 피처맵을 디코딩하 여, 머신을 이용한 분석을 위한 제1 피처맵을 출력할 수 있다. 즉, 비트스트림은 영상이 아닌 피처맵으로만 인 코딩될 수 있다. 부연 설명하면, 피처맵은 영상을 기초로 머신의 특정 타스크를 처리하기 위한 특징에 대한 정 보를 포함한 데이터 일 수 있다. 도 4d를 참조하면, VCM 인코더(100a)의 전단에는 특징 추출기(Feature Extractor)가 연결되어 있을 수 있다. VCM 인코더(100a)는 피처 컨버터와 비디오 인코더를 포함할 수 있다. 상기 비디오 인코더는 도 2에 도시된 인코 딩 장치(10a)일 수 있다. 도 4d를 도시된 VCM 디코더(100b)는 비디오 디코더와 인버스 컨버터를 포함할 수 있다. 상기 비디오 디코더는 도 3에 도시된 디코딩 장치(10b)일 수 있다. 도 5는 본 개시의 일 실시 예에 따른 인코딩 장치의 블록도를 도시한다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)는 영상(비디오)를 입력받아 시간적, 공간적 리샘플링을 수행하 고, 관심 영역을 추출하여, 내부 부호화를 거쳐 비트 스트림을 생성 및 출력할 수 있다. 인코딩 장치(10a)는 시 간적 리샘플링 수행기, 공간적 리샘플링 수행기, 관심영역기반 처리기 및 내부 부호화 수행기 을 포함할 수 있다. 도 5에 도시된 인코딩 장치(10a)에 포함된 구성요소 간의 순서는 다양한 실시 예에서 변경될 수 있고, 일부 구성요소는 생략될 수 있다. 실시 예에 따라, 시간적 리샘플링 수행기 및/또는 공간 적 리샘플링 수행기는 생략될 수 있고, 시간적 리샘플링 수행기 및/또는 공간적 리샘플링 수행기가 생략되는 경우, 관심영역기반 처리기에 의해 관심 영역을 기반으로 처리된 영상이 내부 부호화 수 행기의 입력이 될 수 있다. 예를 들어, 시간적 리샘플링 수행기 및 공간적 리샘플링 수행기가 생략된 경우 입력 영상은 관심영역기반 처리기에서 곧바로 하나 이상의 관심 영역이 추출되고, 추출된 관 심 영역들이 내부 부호화 수행기에 입력되어, 내부 부호화 수행기가 부호화를 수행하여 비트스트림을 생성할 수 있다. 본 개시에서 설명의 편의를 위해 인코딩 장치(10a)는 인코더 또는 부호화기라 지칭할 수 있고, 디코딩 장치(10b)는 디코더 또는 복호화기라 지칭할 수 있다. 시간적 리샘플링 수행기는 영상을 입력 받아 프레임 단위 샘플링을 수행하여, 일부 프레임이 샘플링된 영 상을 출력할 수 있다. 시간적 리샘플링 수행기는 일부 프레임의 프레임율을 변경할 있다. 실시 예에 따라, 시간적 리샘플링 수행기는 영상 전체에 동일한 정도의 샘플링을 수행할 수 있다. 즉, 시간적 리샘플링 수 행기는 동일한 프레임율로 영상 전체를 리샘플링할 수 있다. 또 다른 실시 예에 따라, 시간적 리샘플링 수 행기는 영상 내 일련의 프레임 그룹 단위 별로 서로 다른 샘플링 정도를 적용하여 시간적 리샘플링을 수행 할 수 있다. 즉, 시간적 리샘플링 수행기는 일련의 프레임 그룹 단위로 가변적인 프레임율로 리샘플링할 수 있다. 일 실시 예에서, 시간적 리샘플링 수행기는 관심 영역 기반 처리된 영상과 비 관심 영역 영상에 대하여, 상이한 샘플링 레이트로 샘플링을 수행할 수 있다. 예를 들어, 시간적 리샘플링 수행기는 관심영역 기반 처리된 영상은 제1 샘플링 레이트로 샘플링을 수행할 수 있고, 비 관심영역 영상에 대해서는 제2 샘플링 레이트 로 샘플링을 수행할 수 있다. 실시 예에 따라, 시간적 리샘플링 수행기는 시간적 리샘플링 과정에 사용된 정보(일 예시에서, 시간적 샘 플링 레이트 등)를 복호화기로 전송할 수 있다. 복호화기에서는 관심영역 기반 처리된 영상과 비 관심영역 영상 에 대해 복호화를 수행한 후, 관심영역 기반 처리된 영상과 비 관심영역 영상에 해당하는 각 샘플링 레이트를 파싱하여 각각 업샘플링을 수행할 수 있다. 이때 관심영역 기반 처리된 영상에 적용된 샘플링 레이트와 비 관심 영역 영상에 적용된 샘플링 레이트는 상이할 수 있다. 공간적 리샘플링 수행기는 입력 영상 또는 시간적 리샘플링이 수행된 영상을 입력 받아 각 프레임 또는 일 련의 프레임 단위로 공간적 해상도가 변경된 영상을 출력할 수 있다. 공간적 리샘플링 수행기는 입력 영상 의 각 프레임에 포함된 관심 영역에 대하여 해상도를 변경할 수 있다. 일 실시 예에서, 공간적 리샘플링 수행기 는 관심영역에 대해서만 해상도를 변경할 수 있다. 공간적 리샘플링 수행기는 하나의 프레임에 여러 개의 관심 영역이 있는 경우, 각 관심 영역마다 해상도를 변경할 수 있다. 각 관심 영역에 대한 정보는 변경된 해상도 정보를 포함할 수 있다. 예를 들어, 제1 관심영역에 대하여 제1 스케일 팩터가 적용되고, 제2 관심영역 에 대하여 제2 스케일 팩터가 적용될 수 있다. 스케일 팩터는 예를 들어, scale factor, scale factor nominator, scale factor, denominator, size(%) 파라미터 등 중 적어도 하나를 이용하여 저장될 수 있다. 다른 실시 예에서, 공간적 리샘플링 수행기는 관심 영역과 비 관심영역에 대하여 각각 다른 해상도를 적용 하여 샘플링을 수행할 수 있다. 예를 들어, 공간적 리샘플링 수행기는 관심영역 기반 처리된 영상은 제1 해상도로 변경할 수 있고, 비 관심영역 영상에 대해서는 제2 해상도로 변경할 수 있다. 실시 예에 따라, 공간적 리샘플링 수행기는 공간적 리샘플링 과정에 사용된 정보(일 예시에서, 각 프레임 의 공간적 샘플링 레이트 및/또는 일련의 프레임 단위의 공간적 샘플링 레이트 등)를 복호화기로 전송할 수 있 다. 복호화기는 비트스트림을 복호화한 후, 관심 영역 기반 처리된 영상과 비 관심영역 영상에 대하여 각 해상 도 정보를 파싱하고, 각각 해상도를 변경할 수 있다. 이때 관심영역 기반 처리된 영상에 적용된 해상도와 비 관 심영역에 적용된 해상도는 상이할 수 있다. 관심영역기반 처리기는 입력 영상, 시간적 리샘플링이 수행된 영상, 또는 시간적 리샘플링 및 공간적 리샘 플링이 수행된 영상을 입력 받아, 각 프레임 또는 일련의 프레임 단위 내 존재하는 관심 영역을 추출하고, 추출 된 관심 영역을 기반으로 처리된 영상을 출력할 수 있다. 관심영역기반 처리기는 프레임 분석부, 관 심 영역 선택부, 및 관심영역 기반 영상 처리부를 포함할 수 있다. 관심영역 기반 처리기는 입 력 영상에 포함된 복수 개의 프레임에서 관심 영역을 추출하고, 동일한 관심 영역(예를 들어, 검출된 객체 등) 에 대하여 각 프레임을 기준으로 대응 관계를 설정할 수 있다. 관심영역 기반 처리기는 연속된 일련의 프 레임들에서 동일한 객체(관심영역)이 검출되는 경우, 연속한 프레임들에 대하여 동일한 관심영역을 설정할 수 있다. 관심영역 기반 처리기는 관심 영역에 대한 정보를 복호화기로 전송할 수 있다. 관심 영역에 대한 정 보는 각 프레임에 대하여 저장될 수 있다. 관심영역 기반 처리기는 동일한 관심 영역을 포함하는 여러 프 레임에 대응 관계를 설정하고, 관심 영역에 대한 위치 변화, 크기 변화 등을 저장할 수 있다. 예를 들어, 관심영역 기반 처리기는 일련의 프레임 단위 내에 존재하는 관심 영역에 대한 선형 움직임, 어파인 움직임 등 을 시그널링하여 복호화기로 전송할 수 있다. 관심영역 기반 처리기는 선형 움직임에 대하여 위치 변화 값 을 시그널링할 수 있고, 어파인 움직임에 대하여 움직임 종류에 따라 정의되는 파라미터를 이용하여 시그널링할 수 있다. 예를 들어, 관심영역 기반 처리기는 스케일(scale) 변화, 회전(rotation) 변화, 시어(sheer) 변 화 등을 포함하는 어파인 움직임 정보를 복호화기로 전송할 수 있다. 관심영역 기반 처리기는 어파인 움직 임이 존재하는 경우를 식별하기 위한 플래그(예를 들어, LinearMotion_flag)를 복호화기로 전송할 수 있다. 관심영역기반 처리기는 관심 영역을 고려하여 해상도를 변경할 수 있다. 실시 예에 따라, 관심영역 기반 처리기는 하나의 프레임에 여러 개의 관심 영역이 있는 경우, 각 관심 영역마다 해상도를 변경할 수 있다. 각 관심 영역에 대한 정보는 변경된 해상도 정보를 포함할 수 있다. 예를 들어, 제1 관심영역에 대하여 제1 스 케일 팩터가 적용되고, 제2 관심영역에 대하여 제2 스케일 팩터가 적용될 수 있다. 관심영역기반 처리기는 관심영역 기반 처리 과정에 사용된 정보(일 예시에서, 관심 영역 ID 정보, 관심 영 역의 크기 정보, 패킹 정보, 시간적 샘플링 레이트, 공간적 해상도 등)를 복호화기로 전송할 수 있다. 관심영역 기반 처리기의 상세한 설명은 도 6에서 후술한다. 내부 부호화 수행기는 입력 영상, 또는 시간적/공간적 리샘플링 및 관심영역 처리 중 일부 또는 전체가 수 행된 영상을 입력 받아, 영상 부호화를 수행하여 비트스트림을 생성할 수 있다. 내부 부호화 수행기는 다 운샘플링 수행부, 영상 부호화 수행부 및 관심영역 정보 부호화 수행부를 포함할 수 있다. 실시 예에 따라, 내부 부호화 수행기는 2D 비디오 부호화기(예를 들어, AVC/H.264, HEVC/H.265, VVC/H.266, AV1, VP9 등)를 이용할 수 있고, 하나 이상의 컨볼루션 레이어가 포함된 2D 비디오 부호화기를 이용할 수 있다. 실시 예에 따라, 내부 부호화 수행기의 입력 영상의 색공간을 YUV420, YUV444 등의 색공간으로 변환 후, 부호화가 수행될 수 있다. 이때, 실시 예에 따라, 내부 부호화 수행기는 부/복호화기 간 약속에 의해 정의 된 변환 방법을 통해 변환할 수 있고, 색공간 변환 정보를 복호화기로 전송할 수 있다. 내부 부호화 수행기 의 상세한 설명은 도 7a 내지 7c에서 후술한다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)는 입력 영상에서 관심 영역을 추출하여 전송함으로써 딥 뉴럴 네트워크(Deep Neural Network)의 정확도를 향상시킬 수 있다. 또한, 인코딩 장치(10a)는 관심영역을 추출하고, 시간적 리샘플링을 함께 수행하여 디코딩 장치(10b)에 전송하는 부호화 효율이 높아지는 효과를 가진다. 인코딩 장치(10a)는 각 GOP(Group of Pictures) 또는 일련의 프레임 묶음별로 각 관심 영역에 대한 위치 및 움직임 등 의 정보의 압축을 수행하여, 디코딩 장치(10b)에 전송할 수 있다. 도 6은 본 개시의 일 실시 예에 따른 관심영역기반 처리기의 상세 동작을 나타낸다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)의 관심영역기반 처리기는 프레임 분석부, 관심 영역 선택부, 및 관심영역 기반 영상 처리부를 포함할 수 있다. 프레임 분석부는 분석 영역 선택 모 듈(531a) 및 관심 영역 후보 추출 모듈(531b)을 포함할 수 있다. 관심영역 선택부는 관심영역 선택 모듈 (532a) 및 대응 관심 영역 선정 모듈(532b)을 포함할 수 있다. 다양한 실시 예에서, 관심영역기반 처리기 의 세부 구성요소들은 일부 생략될 수 있고, 구성요소 간의 순서가 변경될 수 있다. 프레임 분석부는 입력 영상을 입력 받아, 관심 영역 후보를 출력할 수 있다. 입력 영상은 원본 영상일 수 있고, 다양한 실시 예에 따라 시간적 및/또는 공간적 리샘플링을 수행한 영상일 수 있다. 프레임 분석부는 입력 영상 또는 시간적/공간적 리샘플링을 수행한 영상의 각 프레임 내에 존재하는 하나 이상의 관심 영역 후보들의 정보(예를 들어, 관심영역의 개수, 관심영역의 위치, 관심영역의 점수 등)를 획득할 수 있다. 관심영역의 점수는 미리 정해진 기준에 따라 산출될 수 있다. 예를 들어, 관심영역의 점수는 관심영역 의 중요도 또는 가중치에 따라 산출될 수 있다. 일 예시로, 관심영역의 점수는 객체 탐지 또는 객체 추적을 목 적으로 학습된 심층신경망 모델을 이용하여 관심영역 후보를 추출하는 경우, 관심영역에 포함된 객체 검출 정확 도에 비례하여 산출될 수 있다. 분석영역 선택 모듈(531a)은 입력 영상에 대하여 하나 이상의 프레임 단위로 분석영역을 선택할 수 있다. 분석 영역 선택 모듈(531a)은 전체 프레임 중 프레임 분석이 수행될 영역을 선택할 수 있고, 이후 영상 내 일부 영역 에 대해서만 프레임 분석 모듈이 수행될 수 있다. 분석영역 선택 모듈(531a)은 영상 내 전체 프레임에 대해 동 일한 영역을 선택할 수 있다. 또는 분석영역 선택 모듈(531a)은 영상 내 일련의 프레임 그룹단위로 동일한 영역 을 선택할 수 있다. 일련의 프레임 그룹마다 선택된 영역은 상이할 수 있다. 분석영역 선택 모듈(531a)은 분석 대상으로 선택된 일부 영역에 대한 정보를 복호화기로 전송할 수 있다. 실시 예에 따라, 분석영역 선택 모듈(531a)은 프레임 분석 모듈이 수행되지 않은 영역은 복호화기로 전송하지 않을 수 있다. 관심영역 후보 추출 모듈(531b)은 선택된 분석 대상 영역에 대하여 프레임 단위로 관심 영역 후보를 추출할 수 있고, 또는 일련의 프레임 단위로 관심 영역 후보를 추출할 수 있다. 각 프레임 내 관심 영역 후보의 크기는 높 이와 너비가 모두 4의 배수일 수 있다. 실시 예에 따라 관심영역 후보 추출 모듈(531b)은 학습이 수행된 하나 이상의 컨볼루션 레이어(convolution layer)로 구성된 심층신경망(Deep Neural Network)을 이용할 수 있다. 실 시 예에 따라, 심층신경망은 객체 탐지를 목적으로 학습된 신경망일 수 있고, 객체 추적을 목적으로 학습된 신 경망일 수 있다. 관심영역 후보 추출 모듈(531b)은 프레임 단위로 관심 영역 후보를 추출할 수 있고, 일련의 프 레임 단위로 추출할 수 있다. 관심영역 후보 추출 모듈(531b)은 각 프레임 또는 일련의 프레임 그룹에 대해, 검 출된 객체(관심 영역 후보)의 검출 정확도가 낮은 경우, 관심 영역 후보에서 제외할 수 있다. 관심영역 선택부는 프레임 분석부로부터 출력된 관심영역 후보들 중에서 관심 영역을 선택하고, 복수 개의 관심 영역들 중에서 대응 관계를 파악하고, 대응되는 관심영역을 선정할 수 있다. 선택된 관심영역은 영상 부호화를 위해 내부 부호화 수행기에 전송될 수 있다. 관심영역 선택 모듈(532a)은 관심영역 후보들 중, 관심 영역으로써 부호화를 수행할 영역을 결정할 수 있다. 비 관심영역 영상은 프레임 내 관심 영역 외의 영역일 수 있고, 비 관심 영역에 해당하는 부분은 주변 픽셀 값 및/ 또는 중간 값으로 채워질 수 있다(filling). 실시 예에 따라, 입력 영상에서 선택된 관심 영역은 각 프레임마다 상이할 수 있고, 일련의 프레임 그룹마다 상이할 수 있다. 대응관심 영역 선정 모듈(532b)은 영상 내 프레임에 포함된 관심 영역들의 대응 관계를 파악하고, 대응 관계에 따른 대응 관심 영역을 선정할 수 있다. 일 실시 예에서, 대응관심 영역 선정 모듈(532b)은 동일한 관심 영역 (예를 들어, 검출된 객체)가 연속된 프레임에 포함되는 경우, 일련의 프레임 그룹 단위로 대응 관심 영역을 선 정할 수 있다. 일 예시에서, 일련의 프레임 그룹 단위로 대응 관심영역 선정 모듈(532b)이 수행되는 경우, 입력 되는 첫 프레임의 관심 영역 후보(검출된 객체)를 후보로 선정하여, 이후 프레임의 관심 영역 후보와 대응 관계 를 통해 대응 관심 영역을 선정할 수 있다. 실시 예에 따라, 첫 프레임의 관심 영역 후보와 이후 프레임의 관심 영역 후보와 대응 관계는 각 검출된 객체의 전체 영역 및/또는 일부 영역 간의 픽셀 간 유사성에 기반하여 구할 수 있다. 일 예시에서, 픽셀 간 유사성은 Cross-correlation 및/또는 픽셀 값의 histogram 비교 등을 통해 산출 할 수 있다. 대응관심 영역 선정 모듈(532b)은 특정 크기로 모든 관심 영역 후보의 크기를 다운샘플링 또는 업샘플링을 수행 한 후, 대응 관심 영역을 선정할 수 있다. 실시 예에 따라, 특정 크기는 영상의 해상도에 따라 결정될 수 있고, 및/또는 각 프레임별 추출된 관심 영역 후보의 크기를 비교하여, 가장 작은 크기를 갖는 관심 영역의 크기로 결 정될 수 있다. 대응관심 영역 선정 모듈(532b)은 선정된 관심 영역에 대해 ID를 부여할 수 있다. 대응관심 영역 선정 모듈 (532b)은 대응 관심영역이 선정되는 단위 별로 ID를 부여할 수 있다. 한 프레임 내에서 관심 영역 후보 추출 모 듈(531b)에서 추출된 관심 영역 후보들의 영역이 서로 겹치는 경우, 겹치는 영역이 일정 임계 값을 넘는 경우 해당 관심 영역들을 하나의 관심 영역으로 분류할 수 있다. 이때 임계 값은 프레임의 크기 및/또는 관심 영역 후보의 크기에 따라 결정될 수 있다. 대응관심 영역 선정 모듈(532b)은 현재 프레임의 관심 영역 중 이전 프레임의 관심 영역과 대응되는 영역이 없 는 경우, 해당 관심 영역에 새로운 ID를 부여할 수 있다. 대응관심 영역 선정 모듈(532b)은 현재 프레임의 관심 영역 중 순서상 더욱 이전 프레임들 중 대응되는 관심 영역이 있는 경우, 대응되는 이전 프레임의 관심영역에 대한 기존 ID를 현재 프레임의 관심 영역에 부여할 수 있다. 다양한 실시 예에서, 대응관심 영역 선정 모듈 (532b)은 대응 관계를 구하는 다양한 방법을 이용할 수 있다. 실시 예에 따라, 관심영역 후보 추출 모듈(531b)이 객체 추적을 목적으로 학습된 신경망을 이용하는 경우, 추적 대상인 객체가 대응 관심 영역에 해당하기 때문에 대응 관심 영역 선정 모듈(532b)의 동작은 생략될 수 있다. 관심영역 기반 영상 처리부는 영상 내 선택된 관심 영역 정보를 입력 받아 각 프레임마다 선택된 관심영역 들을 이용하여 다양한 실시 예에 따라 관심 영역 기반의 처리된 영상을 생성할 수 있다. 일 예시에서, 관심영역 기반 영상 처리부는 관심 영역들을 패킹하고, 관심 영역들의 패킹이 수행된 각 프레임을 생성할 수 있다. 관심영역 기반 영상 처리부는 프레임 내 관심 영역을 제외한 비 관심영역을 특정 값(예를 들어, 중간 값 등)으로 채울 수 있고, 비 관심 영역들이 특정 값으로 채워진 프레임을 생성할 수 있다. 실시 예에 따라, 관심영역 기반 처리기는 관심영역 추출 과정에 사용된 정보(일 예시에서, 관심 영역 식별 (ID) 정보, 관심 영역의 크기 정보, 패킹 정보 등)를 복호화기로 전송할 수 있다. 도 7a, 7b 및 7c는 본 개시의 일 실시 예에 따른 내부 부호화 수행기의 상세 동작을 나타낸다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)의 내부 부호화 수행기는 관심영역 기반 처리된 영상, 비 관심영역 영상 및 관심영역 정보를 부호화하여 비트스트림을 생성할 수 있다. 본 개시의 일 실시 예에 따른 내 부 부호화 수행기는 다운샘플링 수행부, 영상 부호화 수행부 및 관심영역 정보 부호화 수행부 를 포함할 수 있다. 관심영역 정보 부호화 수행기는 정보 부호화를 수행할 관심영역 선택 모듈 (543a), 정보 부호화를 수행할 프레임 선택 모듈(543b) 및 정보 부호화 수행 모듈(543c)를 포함할 수 있다. 다 양한 실시 예에서, 내부 부호화 수행기의 세부 구성요소들은 일부 생략될 수 있고, 구성요소 간의 순서가 변경될 수 있다. 내부 부호화 수행기는 관심영역 기반 처리된 영상에 대하여 매 프레임마다 부호화를 수행할 수 있고, 비 관심영역 영상에 대하여 일련의 프레임 그룹내 일부 프레임에 대해서만 부호화를 수행할 수 있다. 내부 부호화 수행기는 부호화를 수행하기 전에 다운 샘플링을 수행한 후, 관심영역 기반 처리된 영상 내 관심 영역에 대한 정보를 부호화할 수 있다. 영상 부호화 수행부 및 관심영역 정보 부호화 수행부를 통해 출력된 비트스트림을 합쳐(MUXing, multiplexing)하여 하나의 비트스트림으로 생성할 수 있다. 관심영역 정보 부호화 수행부에 대한 상세한 설명은 도 8에서 후술한다. 다운샘플링 수행부는 관심영역 기반 처리된 영상과 비 관심영역 영상에 대해 서로 다른 샘플링 레이트로 영상 부호화 수행 이전에 각각 다운샘플링을 수행할 수 있다. 다운샘플링이 수행된 경우, 다운샘플링 수행부 는 샘플링 레이트 정보를 복호화기로 시그널링할 수 있다. 영상 부호화 수행부는 비디오 부호화기(AVC/H.264, HEVC/H.265, VVC/H.266, AV1, VP9 등)을 이용할 수 있 고, 하나 이상의 컨볼루션 레이어가 포함된 2D 비디오 부호화기를 이용할 수 있다. 영상 부호화 수행부는 관심영역 기반 처리된 영상과 비 관심영역 영상에 대해 동일한 비디오 부호화기를 이용할 수 있고, 또는 서로 다른 비디오 부호화기를 이용할 수 있다. 관심영역 정보 부호화 수행부는 입력되는 영상 내 모든 프레임 또는 일부 프레임에 포함된 관심영역들에 대한 정보(예를 들어, 위치, 움직임, 매핑 정보 등)에 대한 부호화를 수행할 수 있다. 관심영역 정보 부호화 수 행부는 영상 부호화 수행부의 비디오 부호화기의 일부 과정(예를 들어, 엔트로피 코딩 등)을 이용할 수 있다. 도 7a를 참조하면, 내부 부호화 수행기는 비 관심영역 영상에 대하여 다운샘플링 수행부 및 영상 부 호화 수행부를 적용할 수 있다. 도 7b를 참조하면, 내부 부호화 수행기는 관심영역 기반 처리된 영상 에 대하여 다운샘플링 수행부 및 영상 부호화 수행부를 적용하고, 별도로 관심영역에 대한 정보에 대 하여 관심영역 정보 부호화 수행부를 적용하여 비트스트림을 생성할 수 있다. 도 7c를 참조하면, 내부 부 호화 수행기는 관심영역 기반 처리된 영상에 대하여 다운샘플링 수행부를 먼저 수행한 후, 관심영역 에 대한 정보에 대하여 관심영역 정보 부호화 수행부를 적용하고, 관심영역 기반 처리된 영상에 대해 영상 부호화 수행부를 적용하여 비트스트림을 생성할 수 있다. 도 8은 본 개시의 일 실시 예에 따른 관심영역 정보 부호화 수행부의 상세 동작을 나타낸다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)의 내부 부호화 수행기에 포함된 관심영역 정보 부호화 수 행부는 관심영역 기반 처리된 영상에 대하여 관심 영역에 대한 정보를 부호화하여 비트스트림을 생성할 수 있다. 본 개시의 일 실시 예에 따른 관심영역 정보 부호화 수행기는 정보 부호화를 수행할 관심영역 선택 모듈(543a), 정보 부호화를 수행할 프레임 선택 모듈(543b) 및 정보 부호화 수행 모듈(543c)를 포함할 수 있다. 관심영역 정보 부호화 수행기의 세부 구성요소들은 일부 생략될 수 있고, 구성요소 간의 순서가 변경될 수 있다. 정보 부호화를 수행할 관심영역 선택 모듈(543a)은 관심 영역 기반 처리된 영상을 입력 받아, 선택된 관심 영역 들 중 정보 부호화를 수행할 관심 영역을 선택할 수 있다. 정보 부호화 대상은 관심 영역의 움직임 정보, 보상 파라미터 등이 될 수 있다. 정보 부호화를 수행할 프레임 선택 모듈(543b)은 정보 부호화를 수행할 관심 영역 및/또는 관심 영역 기반 처리 된 영상을 입력 받아, 영상 내 프레임 중 정보 부호화를 수행할 프레임을 선택할 수 있다. 정보 부호화 수행 모듈(543c)은 선택된 프레임 내 모든 관심 영역의 정보를 부호화할 수 있다. 정보 부호화 수 행 모듈(543c)은 선택된 프레임 내에서 정보 부호화를 수행할 관심영역 선택 모듈(543a)에 의해 선택된 관심 영 역들의 정보만 부호화할 수 있다. 정보 부호화 수행 모듈(543c)은 정보 부호화를 수행할 프레임 선택 모듈 (543b)에 의해 선택된 프레임 내에서 정보 부호화를 수행할 관심영역 선택 모듈(543a)에 의해 선택된 관심 영역 들의 정보를 부호화하여 비트스트림을 생성할 수 있다. 실시 예에 따라, 입력 영상에 대하여 시간적 리샘플링이 수행된 경우, 관심영역 정보 부호화 수행부는 시 간적 샘플링 레이트보다 작은 주기의 일부 프레임에 대해 관심영역 정보를 부호화할 수 있다. 일 예시에서, 관 심영역 정보 부호화 수행부는 샘플링 레이트 n(n은 1 이상의 정수)을 이용하여 주기적으로 시간적 리샘플 링이 수행된 경우, m(m은 1이상 및 n 이하의 정수) 프레임 주기마다 해당 프레임 내 관심 영역에 대한 정보를 부호화할 수 있다. 다른 예시에서, 영상 전체에서 시간적 리샘플링이 비주기적으로 수행된 경우, 관심영역 정보 부호화 수행부는 시간적 리샘플링이 수행된 영상의 임의의 인접한 두 프레임 사이의 프레임 간격이 k(k는 1 이상의 정수) 라 할 때, k/p(p는 1 이상 k 미만 정수) 주기마다 해당 프레임 내 관심 영역 정보를 부호화할 수 있다. 관심영역 정보 부호화 수행부는 u(u는 1 이상의 정수) 프레임 주기마다 해당 프레임 내 관심 영 역 정보를 부호화할 수 있다. 프레임 선택 과정을 통해 관심 영역 정보의 부호화를 수행할 프레임 내에서 일부 관심 영역에 대해서만 관심 영 역 정보를 부호화할 수 있다. 실시 예에 따라, 입력 영상에 대하여 시간적 리샘플링이 수행되지 않은 경우, 관심영역 정보 부호화 수행부 는 하나 이상의 특정 관심 영역들의 정보만 부호화를 수행할 수 있다. 관심영역 정보 부호화 수행부 는 특정 프레임들 간의 관심 영역들의 정보만 부호화할 수 있다. 실시 예에 따라, 각 프레임 사이의 대표 밝기 값 차이가 특정 임계 값 이상인 경우, 해당 프레임 간의 관심 영역들의 정보만 부호화를 수행할 수 있다. 각 프 레임 사이의 각 프레임 내 대응되는 관심 영역의 대표 밝기 값 차이가 특정 임계 값 이상인 경우, 해당 프레임 간의 관심 영역들의 정보만 부호화를 수행할 수 있다. 관심영역 정보 부호화 수행부는 관심 영역 정보 부호화를 수행할 두 프레임 사이에 대해, 각 프레임 내에 서 서로 대응되는 관심 영역에 대해, 관심 영역 정보 부호화를 수행할 수 있다. 관심영역 정보 부호화 수행부 는 관심 영역의 위치에 대한 정보를 부호화할 수 있고, 두 관심 영역 간의 위치 차분 값을 부호화할 수 있 다. 이때 위치는 관심 영역의 좌상단 좌표일 수 있다. 관심영역 정보 부호화 수행부는 관심 영역의 위치 정보(좌표 및 차분 값)와 함께 움직임 파라미터를 부호화할 수 있다. 일 예시에서, 움직임 파라미터는 어파인 (affine) 움직임을 표현하기 위한 파라미터일 수 있다. 관심영역 정보 부호화 수행부는 변환 모션 (translation motion)에 대한 정보는 위치 정보(좌표 및 차분 값)로, 스케일(scale), 시어(sheer), 회전 (rotation)에 대한 정보는 움직임 파라미터로 부호화를 수행할 수 있다. 실시 예에 따라, 어파인 움직임은 수학식 1으로 표현될 수 있다. 수학식 1"}
{"patent_id": "10-2024-0061816", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, a, b, c, d는 어파인 파라미터를 나타낸다. Trans_x 및 Trans_y는 x 축 및 y축에 대한 변환 모션 정보 를 나타낸다. x, y는 현재 관심 영역 내 픽셀 값의 위치를 나타내고, x', y'는 어파인 움직임이 적용된 픽셀 값 의 위치를 나타낸다. 관심영역 정보 부호화 수행부는 관심 영역의 위치 정보와 움직임 파라미터를 복호화기로 전송할 수 있다. 실시 예에 따라, 관심영역 정보 부호화 수행부는 1)두 프레임 사이의 밝기 값의 대표 값 차이가 특정 임계 값보다 큰 경우 및/또는 2)대응 관심 영역의 밝기 값의 대표 값 차이가 특정 임계 값보다 큰 경우, 두 관심 영 역 간 보상 파라미터 정보를 부호화할 수 있다. 이때 관심 영역 간 보상 파라미터 적용 여부에 대한 정보는 프 레임 단위, 또는 관심 영역 단위로 시그널링 될 수 있다. 다양한 실시 예에서, 1)프레임 사이의 밝기 값의 대표 값 차이에 대한 특정 임계 값과 2)대응 관심 영역의 발기 값의 대표 값 차이에 대한 특정 임계 값은 서로 다를 수 있다. 실시 예에 따라, 보상 파라미터는 두 개의 파라미터(일 예시로, α 및 β)로 정의할 수 있고, 아래 수학식 2와 같이 표현될 수 있다. 수학식 2"}
{"patent_id": "10-2024-0061816", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 는 두 프레임 중 시간적으로 이전 프레임의 i 번째 관심 영역을 나타내고, 는 시간적으로 다음 프레임의 i 번째 관심 영역을 나타낸다. 도 9는 본 개시의 일 실시 예에 따른 디코딩 장치의 블록도를 도시한다. 본 개시의 일 실시 예에 따른 디코딩 장치(10b)는 인코딩 장치(10a)로부터 비트스트림을 수신하여, 복호화를 수 행하여 복원 영상(비디오)를 출력할 수 있다. 디코딩 장치(10b)는 내부 복호화 수행기, 관심영역 기반 복 원기, 공간적 복원 수행기, 시간적 복원 수행기 및 후처리 필터 수행기를 포함할 수 있다. 머신비전 태스크 수행기는 디코딩 장치(10b)에 의해 복원된 영상에 대하여 머신 비전 태스크를 수행하여 결과를 출력할 수 있다. 머신 비전 태스크가 객체 탐지, 객체 추적 또는 객체 분할 등의 경우, 태스크 수행 결 과에 대한 정확도를 측정하기 위한 메트릭을 사용할 수 있다. 예를 들어, 머신 비전 태스크 수행 결과에 대한 정확도를 측정하기 위한 메트릭은 객체 탐지 결과에 대한 mAP, 객체 추적 결과에 대한 MOTA 등 일 수 있다. 실 시 예에 따라 디코딩 장치(10b)는 머신비전 태스크 수행기를 더 포함할 수 있다. 실시 예에 따라 도 9의 구성요소들 간의 순서는 변경될 수 있다. 실시 예에 따라, 관심영역 기반 복원기, 공간적 복원 수행기 , 및 시간적 복원 수행기의 순서는 도 5의 인코딩 장치(10a)에 따른 원본 영상의 부호화 과정에서 각 대응 과정(관심영역 기반 부호화기, 공간적 샘플링 수행기, 시간적 샘플링 수행기이 수행된 순 서의 역순일 수 있다. 내부 복호화 수행기는 비트스트림을 입력 받아 영상 복호화를 수행하여 복원된 영상을 생성할 수 있다. 내 부 복호화 수행기는 영상 복호화 수행부, 업샘플링 수행부 및 관심영역 정보 복호화 수행부 를 포함할 수 있다. 실시 예에 따라, 내부 복호화 수행기는 2D 비디오 복호화기(AVC/H.264, HEVC/H.265, VVC/H.266, AV1, VP9, 등)를 이용할 수 있고, 하나 이상의 컨볼루션 레이어가 포함된 2D 비디오 복호화기를 이용할 수 있다. 실시 예에 따라, 내부 복호화 수행기는 복원된 영상의 색공간을 다른 색공간 으로 암시적 또는/그리고 명시적으로 변환 후, 이후 영상 복호화 과정을 수행할 수 있다. 예를 들면, 복원된 영 상의 색공간이 RGB444가 아닌 YUV420, YUV444, 등 중 하나인 경우, RGB444 공간으로 암시적 또는/그리고 명시적 으로 변환 후, 이후 영상 복호화 과정이 수행될 수 있다. 관심영역 기반 복원기는 실시 예에 따라 복호화된 영상과 인코딩장치(10a)로부터 전송받은 관심 영역 기반 처리 정보(일 예시로, 관심 영역 ID 정보, 관심 영역의 크기 정보, 패킹 정보 등)를 이용하여 관심 영역 기반 처리된 영상을 복원할 수 있다. 관심영역 기반 복원기는 영상 재구성부를 포함할 수 있다. 공간적 복원 수행기는 실시 예에 따라 부호화기로부터 전송받은 공간적 리샘플링 과정에 사용된 정보(일 예시로, 각 프레임의 공간적 샘플링 레이트 및/또는 일련의 프레임 단위의 공간적 샘플링 레이트 등)를 이용하 여 복호화된 영상 또는 복호화 및 관심영역 기반 복원 영상에 대하여 공간적 복원을 수행할 수 있다. 시간적 복원 수행기는 실시 예에 따라, 인코딩 장치(10a)로부터 전송받은 시간적 리샘플링 과정에 사용된 정보(일 예시로, 시간적 샘플링 레이트 등)을 이용하여 도 9의 선행 과정의 일부 또는 전체가 수행된 영상에 대 하여 시간적 복원을 수행할 수 있다. 후처리 필터 수행기는 실시 예에 따라 도 9의 선행 과정의 일부 또는 전체가 수행된 영상에 대하여 필터링 을 수행할 수 있다. 실시 예에 따라, 후처리 필터 수행기는 고정된 필터를 사용할 수 있고, 인코딩 장치 (10a)와 디코딩 장치(10b)의 약속에 의해 설정된 다수 개의 필터를 이용할 수 있다. 후처리 필터 수행기는 사전에 약속된 필터 정보를 인코딩 장치(10a)로부터 수신할 수 있다. 머신비전 태스크 수행기는 실시 예에 따라 복원된 영상 또는 복원된 영상과 부가 정보를 입력 받아 머신 비전 태스크 결과(일 예시로, mAP, MOTA 등) 도출을 위한 과정을 수행할 수 있다. 머신비전 태스크 수행기 는 학습이 수행된 하나 이상의 컨볼루션 레이어로 구성된 심층신경망(Deep Neural Network)을 이용할 수 있다. 머신비전 태스크 수행기는 인코딩 장치(10a)로부터 머신 비전 태스크 종류 및/또는 심층신경망의종류 등에 대한 정보를 수신할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 내부 복호화 수행기 및 관심 영역 기반 복원기의 상세 동작을 나타낸다. 도 10은 도 9의 디코딩 장치(10b)에 포함된 내부 복호화 수행기 및 관심영역 기반 복원기의 각 구성 요소에 의한 내부 복호화 수행 과정 및 관심영역 기반 복원 과정의 각 단계를 도시한다. 실시 예에 따라, 입력 되는 비트스트림은 Demuxing을 우선 수행하여 각각을 도 9의 각 복호화 수행부(911, 913)의 입력으로 인가될 수 있다. 영상 복호화 수행부는 비트스트림을 입력 받아 복호화를 수행하여 영상과 관심 영역 정보를 복원할 수 있 다. 복원된 관심 영역 기반 처리된 영상의 프레임 수와 복원된 비 관심영역 영상의 프레임 수는 서로 상이할 수 있다. 업샘플링 수행부는 샘플링 레이트를 수신하여 관심 영역 기반 처리된 영상 및 비 관심 영역 영상에 대한 복호화 이후 각각 업샘플링을 수행할 수 있다. 샘플링 레이트는 관심영역 기반 처리된 영상과 비관심영역 영상 에 대하여 각각 상이할 수 있다. 실시 예에 따라, 업샘플링 수행부는 업샘플링 방법으로 Bilinear upsampling, bilateral upsampling, nearest-neighbor upsampling, 하나 이상의 컨볼루션 레이어가 포함된 심 층신경망 중 하나를 선택하여 사용할 수 있다. 실시 예에 따라, 업샘플링 수행부는 관심 영역 기반 처리된 영상과 비 관심 영역 영상에 대하여 상이한 업샘플링 방법으로 업샘플링을 수행할 수 있고, 관심영역 기반 처리 된 영상 내에서도 가변적으로 업샘플링 방법을 선택 적용할 수 있다. 예를 들어, 업샘플링 수행부는 샘플 링 레이트에 따라 업샘플링 방법을 결정할 수 있고, 샘플링 레이트가 상이한 경우 업샘플링 방법도 상이할 수 있다. 관심영역 정보 복호화 수행부는 비트스트림을 입력 받아 복호화를 수행하여 관심 영역 정보를 복원할 수 있다. 관심영역 정보 복호화 수행부는 인코딩 장치(10a)에서 다운 샘플링된 관심 영역에 대한 정보를 부호 화한 경우, 관심 영역 정보에 대한 복호화를 수행한 후 업샘플링 수행부에 전송하여 업샘플링을 수행할 수 있다. 실시 예에 따라, 관심 영역 정보 복호화 수행부는, 한 프레임 내에 다수 개의 관심 영역이 존재하는 경우, 각 관심 영역에 대해 복호화를 수행할 수 있다. 관심영역 정보 복호화 수행부의 상세한 설명은 도 11에서 후술한다. 실시 예에 따라, 영상 재구성부는 복원된 관심 영역과 복원된 비 관심 영역 영상을 입력 받아 원본 영상으 로의 복원을 수행하여 복원 영상을 출력할 수 있다. 실시 예에 따라, 복원된 관심 영역 정보는 영상 재구성부 에서 사용될 수 있다. 실시 예에 따라, 영상 재구성부는 복원된 영상에 대하여 해상도 개선을 위한 필터링을 수행할 수 있다. 영 상 재구성부는 복원된 관심 영역 정보를 더 이용하여 영상을 재구성하여 복원 영상을 생성할 수 있다. 다 양한 실시 예에서, 영상 재구성부는 관심영역 기반 처리된 영상과 비 관심영역 영상에 대한 경계 및 관심 영역 중 적어도 하나에 대하여 필터링을 수행할 수 있다. 일 실시 예에서, 영상 재구성부는 영역 경계 필 터링 수행 모듈을 이용하여 관심영역 기반 처리된 영상과 비 관심영역 영역의 경계 필터링을 할 수 있다. 다른 일 실시 예에서, 영상 재구성부는 관심영역 기반 처리된 영상의 하나 이상의 관심 영역에 대하여 디블러링 (deblurring) 등의 필터링을 수행할 수 있다. 다양한 실시 예에서, 영상 재구성부는 시간적 리샘플링이 적용된 영상을 복원하기 위해 해상도 개선을 위 한 필터링을 수행할 수 있다. 중간 프레임을 삭제하는 시간적 리샘플링 과정에서 프레임 간 품질 차이로 인해 상대적으로 품질이 낮은 중간 프레임이 복원될 수 있는데, 복원된 중간 프레임의 관심 영역에 대하여 디블러링 필터링을 수행하면, 중간 프레임의 품질이 향상될 수 있다. 예를 들어, 영상 재구성부는 시간적 리샘플링 과정에서 입력되는 두 프레임의 관심 영역에 대해 디블러링 필터링을 수행하여 복원 영상을 생성할 수 있다. 실 시 예에 따라, 영상 재구성부는 다양한 기능을 목적으로 각각 학습된 여러 심층신경망 중 어느 하나를 이 용하여 필터링을 수행할 수 있다. 예를 들어, 영상 재구성부는 디블러링을 목적으로 학습된 심층신경망을 이용하여 관심영역 내 디블러링을 수행할 수 있다. 디블러링 필터링을 적용한 경우 복원 성능이 좋아질 수 있다. 복원된 비 관심영역 영상은 복원된 관심 영역의 각 프레임마다 존재할 수 있고, 일련의 프레임 그룹 단위마다 하나의 복원된 비 관심 영역 영상이 존재할 수 있다. 일 예시로, 각 GOP 단위로 인트라 프레임(Intra frame)에 대해서만 복원된 비 관심 영역 영상이 존재할 수 있다. 실시 예에 따라, 영상 재구성부는 복원된 비 관심 영역 영상이 일련의 프레임 그룹 단위마다 하나가 존재하는 경우, 각 복원된 관심 영역의 프레임에 대해 동일한복원된 비 관심영역 영상을 이용하여 복원 영상을 생성할 수 있다. 실시 예에 따라, 각 복원된 관심 영역에 대 해, 해당 관심 영역의 경계와 대응 위치의 복원된 비 관심 영역 영상의 경계는 서로 다른 필터링이 적용될 수 있다. 실시 예에 따라, 영상 재구성부는 각 복원된 관심 영역에 대해 해당 관심 영역의 경계와 대응 위치 의 복원된 비 관심 영역 영상의 경계의 픽셀 값의 차이에 따라 암시적으로 필터링 방법을 결정할 수 있다. 실시 예에 따라, 영상 재구성부는 특정 관심 영역에 대한 필터링 방법을 인코딩 장치(10a)로부터 수신하여, 필 터링을 수행할 수 있다. 도 11은 본 개시의 일 실시 예에 따른 관심영역 정보 복호화 수행부의 세부 동작을 나타낸다. 본 개시의 일 실시 예에 따른 디코딩 장치(10b)의 내부 복호화 수행기에 포함된 관심영역 정보 복호화 수 행부는 비트스트림으로부터 파싱한 선형 움직임 정보 플래그(LinearMotion_flag) 및 보상 파라미터 여부 정보 플래그(Comp_param_flag)에 기반하여 관심 영역 정보를 복호화할 수 있다. 관심영역 정보 복호화 수행부 는 위치정보 복호화 모듈(913a), 움직임 파라미터 복원 수행부(913b) 및 보상 파라미터 복원 수행부(913 c)를 포함할 수 있다. 관심영역 정보 복호화 수행부는 관심 영역 단위 및/또는 프레임 단위로 도 11의 각 단계를 수행할 수 있다. 다양한 실시 예에서, 도 11의 각 단계의 순서는 변경될 수 있으며, 일부 구성은 생략될 수 있다. 실시 예에 따라서, 위치정보 복호화 모듈(913a)는 특정 프레임 간격 사이에서 특정 관심 영역의 위치 정보를 복 호화할 수 있다. 일 예시로, 위치정보 복호화 모듈(913a)는 두 프레임 사이의 대응 관심 영역의 위치 변화/차분 정보를 복호화할 수 있다. 이때, 선형 위치 변화/차분 값이 복원될 수 있다. 실시 예에 따라, 특정 관심 영역 또는 특정 프레임 내 관심 영역들이 추가적인 움직임 외에 선형 움직임만을 갖 는 경우, LinearMotion_flag가 0이며, 추가적인 위치 및 움직임 정보의 복호화 과정이 생략될 수 있다. 실시 예에 따라, LiearMotion_flag가 1인 경우, 관심 영역 간 선형 움직임 외에 추가적인 움직임이 있음을 나타 내며, 움직임 파라미터 복원 수행부(913b)가 움직임 파라미터 복원 수행을 할 수 있다. 일 예시로, 추가적인 움 직임은 스케일(scale), 회전(rotation), 시어(sheer)와 같은 어파인 움직임일 수 있다. 실시 예에 따라, 움직임 파라미터 복원 수행부(913b)는 LiearMotion_flag 와 관계없이 움직임 파라미터 복원 수 행을 할 수 있다. 어파인 움직임 정보는 수학식 1에 따라 어파인 파라미터(예를 들어, {a, b, c, d}, 또는 {a,b,c,d, Trans_x, Trans_y})를 이용하여 표현될 수 있다. 실시 예에 따라, 움직임 정보 내에 값들은 각 관심 영역에 대해 독립적으로 전송될 수 있다. 인코딩 장치(10a)로부터 이전 프레임과 동일하거나 대응되는 ID를 가 지고 있는 관심 영역의 움직임 정보와의 차분 값 및 현재 프레임 내 이미 복호화된 관심영역의 움직임 정보와의 차분 값 중 적어도 하나가 전송될 수 있다. 각 관심 영역의 움직임 정보는 일련의 프레임 그룹 단위로 관리될 수 있다. 여기서 일련의 프레임 그룹 단위란, GOP(group of picture) 단위 일 수 있다. 실시 예에 따라, 인코딩 장치(10a)로부터 프레임 그룹 내에 각 관심 영역에 대해 첫 번째 프레임 내 관심 영역의 움직임 정보가 전송되 고, 복호화 순서상 다음 프레임 내 관심 영역은 이전 프레임의 동일한 ID 또는 대응되는 ID의 관심 영역의 움직 임 정보에 대한 차분 값만 전송될 수 있다. 각 관심 영역에 대해, 그룹 내 중간 프레임으로부터 움직임 정보의 차분 값이 전송될 수 있다. 이때 차분 값이란, 값의 차이일 수 있고, 비율의 차이일 수 있다. 실시 예에 따라, 움직임 정보 중 일부 정보에 대해서만 차분 값이 전송되고, 그 외의 움직임 정보는 프레임 단위로 전송될 수 있 다. 실시 예에 따라, 위치 및 움직임 정보에 대한 복호화 수행 후, 비트스트림으로부터 파싱한 Comp_param_flag가 1 인 경우, 보상 파라미터 복원수행 모듈(913c)는 보상 파라미터(일 예시로, 스케일 파라미터 α, 오프셋 파라미 터 β)를 복호화할 수 있다. 보상 파라미터는 인코딩 장치(10a)로부터 수신하여 복호화될 수 있고, 디코딩 장치 (10b)에서 두 대응 관심영역 또는 두 대응 프레임 사이의 대표 밝기 값을 통해 유도될 수 있다. 도 12a 및 12b는 본 개시의 일 실시 예에 따른 시간적 복원 수행기의 세부 동작을 나타낸다. 본 개시의 일 실시 예에 따른 시간적 복원 수행기는 복원 영상 및 복원된 관심 영역 정보에 기반하여 시간 적 복원을 수행한 영상을 생성할 수 있다. 시간적 복원 수행기는 시간적 프레임 복원 수행부 및 관심 영역 시간적 보정부를 포함할 수 있다. 다양한 실시 예에서, 시간적 복원 수행기의 세부 구성요소의 순서는 변경될 수 있고, 일부 구성은 생략될 수 있다. 도 12a는 시간적 프레임 복원 수행부가 복원 영상 및 복원된 관심 영역 정보를 수신하여, 시간적 복원된 영상을 생성하는 일 실시 예를 도시한다. 도 12b는 시간 적 프레임 복원 수행부가 복원 영상을 수신하여 시간적 프레임 복원을 우선 수행한 후, 관심 영역 시간적 보정부가 시간적 프레임 복원이 수행된 영상과 복원된 관심 영역 정보를 수신하여, 시간적 복원이 수행된영상을 생성할 수 있다. 도 12a를 참조하면, 일 실시 예에 따른 시간적 프레임 복원 수행부는 복원할 프레임 수의 정보(일 예시로, 시간적 샘플링 레이트 등)을 파싱하여, 복원 영상 및 복원된 관심 영역 정보를 입력 받아 복원 영상을 이용하여 중간 프레임의 복원을 수행하고, 이때 복원된 관심 영역 정보를 이용하여 복원된 중간 프레임들 내부의 관심 영 역들의 픽셀 값 정보 및 위치 정보 보정을 수행할 수 있다. 도 12b를 참조하면, 일 실시 예에 따른 시간적 프레임 복원 수행부는 복원할 프레임 수의 정보(일 예시로, 시간적 샘플링 레이트 등)를 수신하여, 복원 영상을 이용하여 중간 프레임의 복원을 수행할 수 있다. 관심 영역 시간적 보정부는 실시 예에 따라 시간적 프레임 복원 수행이 된 영상 및 복원된 관심 영역 정보를 입력받 아 시간적 프레임 복원 수행이 된 영상 내 관심 영역들에 대한 보정을 수행할 수 있다. 도 13은 본 개시의 일 실시 예에 따른 관심영역에 대한 시간적 보정의 일 예시이다. 본 개시의 일 실시 예에 따른 디코딩 장치(10b)는 시간적 복원 수행기를 포함하고, 시간적 복원 수행기 는 관심영역에 대한 시간적 보정을 수행할 수 있다. 일 실시 예에서, 시간적 복원 수행기의 관심영역 시간적 보정부는 복원된 관심 영역 정보를 이용하여 복원된 중간 프레임들 내부의 관심 영역에 대한 보정 을 할 수 있다. 실시 예에 따라, 복원 영상 내 프레임의 의 크기를 갖는 특정 관심 영역에 대해 복원된 관심 영역 정보를 통해 복원된 중간 프레임들 중, 대응되는 중간 프레임의 위치를 기준으로 도 13의 (a)와 같이 1 이상의 정수 , 에 대해 탐색 범위 를 선택할 수 있다. 탐색 범위 내 특정 탐색 방법에 따라, 블록과 복원 영상 내 프레임의 크기의 관심 영역 간 차이 값(일 예시로, SAD (Sum of Absolute Difference) 등)을 이 용하여 복원된 중간 프레임 내의 최적의 대응 관심 영역을 찾은 후, 해당 블록을 복원된 관심 영역의 정보에 맞 춰 도 13의 (b)와 같이 위치 보정을 수행할 수 있다. 이때 위치 보정을 하면서 값이 존재하지 않는 영역 즉, 도 13의 (b)에서 보전 전 대응되는 관심 영역 중 보정 후 대응되는 관심 영역에 포함되지 않는 영역은 중간 값으로 채워질 수 있고, 또는 특정 필터링 과정을 통해 값이 채워질 수 있다. 실시 예에 따라, 복원된 관심 영역 정보에 보상 파라미터 정보가 존재하는 경우, 탐색 과정에 보상 파라미터를 적용하여 탐색할 수 있다. 실시 예에 따라 내부 복호화 수행기는 복원된 영상이 관심 영역 기반 복원 및 시간적 복원이 함께 수행되 는 경우, 내부 복호화 수행 이후, 시간적 복원 수행을 먼저 한 후, 관심 영역 기반 복원을 수행할 수 있다. 일 실시 예에서, 관심 영역 기반 복원 방법 중 위치 정보의 복원 과정만 시간적 복원 수행 이후에 수행될 수 있다. 실시 예에 따라, 시간적 복원 수행 과정에 있어, 일련의 프레임 그룹 단위 내의 내부 복호화 수행기를 통해 복 원된 영상 내 각 프레임에 대해 아래 네가지 방법에 따라 시간적 복원을 수행할 수 있다. 시간적 복원 수행기 는 인접하거나 인접하지 않은 두 프레임에 포함된 관심 영역의 크기를 기준으로, 다음 시간적 복원 방법 중 어느 하나를 이용하여 시간적 복원을 수행할 수 있다. 1) 인접한 또는 비인접한 두 프레임의 관심 영역의 크기가 동일한 경우, 두 프레임 중 시간적으로 앞선 프레임 을 복사하여 복원된 프레임을 생성할 수 있다. 이후 관심 영역 기반 복원 과정에서 위치 정보를 이용하여 관심 영역의 위치를 복원할 수 있다. 시간적 복원 수행 과정의 입력인 두 프레임의 관심 영역의 위치 정보를 서브 샘 플링하여 중간 프레임들(복사 방법을 통해 복원된 프레임들)의 위치 정보를 복원할 수 있다. 일 실시 예에서, 관심 영역의 크기는 관심 영역이 존재하는 영역의 크기 또는 각 관심 영역이 차지하는 영역의 크기일 수 있다. 2) 인접한 또는 비인접한 두 프레임의 관심 영역의 크기가 동일한 경우, 각 프레임 내 관심 영역에 대해서 PSNR(Peak signal-to-noise ratio) 및 SSIM(Structural Similarity Index Measure) 등 중 하나 이상의 메트릭 측정 값을 비교하여 시간적 프레임 복원 방법에 대해 결정할 수 있다. 3-1) 인접한 두 프레임의 관심 영역의 크기의 차분 값이 특정 임계 값보다 작은 경우, 두 프레임을 이용하여 시 간적 복원이 수행될 프레임의 수를 이라 할 때, 앞선 프레임만 복사하거나, 뒤 프레임만 복사하여 시간적 복원 을 수행할 수 있다. 또는, 번째 프레임은 두 프레임 중 시간적으로 앞선 프레임을 복사하고, 번째 프레임은 두 프레임 중 시간적으로 뒤의 프레임을 복사하여 시간적 복원을 수행할 수 있다. 이후, 관심 영역 기반 복원 과정에서 위치 정보를 이용하여 관심 영역의 위치를 복원할 수 있거나, 시간적 복원 수행 과정의 입 력인 두 프레임의 관심 영역의 위치 정보를 서브샘플링하여 중간 프레임들(복사 방법을 통해 복원된 프레임들) 의 위치 정보를 복원할 수 있다. 이때 서브샘플링하는 방법은 다양할 수 있으며, 일 예시로 앞선 프레임이 복사 되어 생성된 프레임들에 대해서는 앞선 프레임의 관심 영역의 위치 정보에 가중치를 더 부여할 수 있다. 일 실 시 예에서, 관심 영역의 크기는 관심 영역이 존재하는 크기 또는 각 관심 영역이 차지하는 크기일 수 있다. 3-2) 인접한 두 프레임의 관심 영역의 크기의 차이가 일정 임계 값 이하인 경우, 두 프레임 내 관심 영역에 대 해서 PSNR(Peak signal-to-noise ratio) 및 SSIM(Structural Similarity Index Measure) 등 중 하나 이상의 메 트릭 측정 값을 비교하여 시간적 프레임 복원 방법에 대해 결정할 수 있다. 이때 메트릭 비교를 위해 두 프레임 내 관심 영역 중 크기가 더 큰 관심 영역을 크기가 작은 관심 영역과 동일한 크기가 되도록 다운샘플링한 후, 메트릭 비교를 수행할 수 있다. 또는 반대로, 크기가 더 작은 관심 영역을 크기가 큰 관심 영역과 동일한 크기 가 되도록 업샘플링한 후, 메트릭 비교를 수행할 수 있다. 실시 예에 따라, 프레임 간 크기가 상이한 관심 영역 을 비교하기 위해, 두 영역의 좌상단 위치를 동일하게 옮긴 후, 더 작은 영역만큼의 영역에 대한 비교를 수행하 거나, 큰 영역만큼의 영역에 대한 비교를 수행할 수 있다. 이때 큰 영역만큼의 비교를 수행하는 경우, 작은 영 역의 벗어난 영역을 중간 값으로 채우거나 경계 값을 이용하여 패딩을 수행할 수 있다. 4-1) 두 프레임 내의 관심 영역의 차이가 일정 임계값을 초과하는 경우, 시간적 프레임 복원을 수행하지 않을 수 있다. 4-2) 두 프레임 내의 관심 영역의 차이가 일정 임계값을 초과하는 경우, 시간적 프레임 복원은 최종 복원된 영 상의 시간적 순서에 따라 두 프레임 중 인접한 프레임을 복사하여 개의 프레임을 생성하여 수행할 수 있다. 도 14a 및 14b는 본 개시의 일 실시 예에 따른 머신 비전 태스크 수행기의 상세 동작을 나타낸다. 본 개시의 일 실시 예에 따른 머신 비전 태스크 수행기는 딥 뉴럴 네트워크 수행부 및 관심영역 정 보 기반 보정부를 포함할 수 있다. 다양한 실시 예에서, 머신 비전 태스크 수행기의 세부 구성요소 의 순서는 변경될 수 있고, 일부 구성은 생략될 수 있다. 일 실시 예에서, 딥 뉴럴 네트워크 수행부는 학습이 수행된 하나 이상의 컨볼루션 레이어로 구성된 딥 뉴 럴 네트워크를 이용할 수 있다. 머신 비전 태스크 수행기는 인코딩 장치(10a)로부터 머신 비전 태스크 종류 및/또는 딥 뉴럴 네트워크의 종류 등에 대한 정보를 수신하여, 수신한 정보를 기반으로 머신 비전 태스크를 수행할 수 있다. 일 실시 예에서, 관심영역 정보 기반 보정부는 복원된 관심 영역 정보를 이용하여 딥 뉴럴 네트워크의 수 행 결과(일 예시로, 객체 추적 태스크에서 관심 영역의 위치 정보 등)를 보정할 수 있다. 관심영역 정보 기반 보정부는 딥 뉴럴 네트워크 수행부에 포함되어 동작할 수 있다. 실시 예에 따라, 수행할 머신 비전 태스크의 종류가 객체 추적과 같은 영상 프레임 간의 독립적인 처리 외의 과 정이 존재하는 경우, 다음과 같이 관심영역의 위치 보정을 할 수 있다. 일 실시 예에서, 영상 내 프레임들에 대해 추적된 객체가 사라지는 지점, 예를 들어, 1~10 프레임까지는 5번 객 체가 추적되고 11번째 프레임에서 5번 객체가 추적되지 않는 경우, 10번째 프레임에서 5번 객체에 대한 정보가 복원된 관심 영역 정보에 있는 경우, 해당 정보에 10번째 프레임과 11번째 프레임 간의 관심 영역 정보가 존재 하는 경우 해당 관심 영역 정보를 이용하여 객체 추적 결과를 보정할 수 있다. 다른 일 실시 예에서, 영상 내 프레임들에 대해 현재 프레임의 대표 밝기 값이 다음 프레임의 대표 밝기 값과 차이가 특정 임계 값을 넘는 경우, 관심 영역 정보 내에 두 프레임 간의 관심 영역들에 대한 정보가 존재하면 두 프레임 간의 객체 추적 결과에 더하여 상기 일 실시 예의 과정과 같이 관심 영역 정보를 이용하여 객체 추적 결과를 보정할 수 있다. 다른 예시에서, 현재 프레임에서 추적된 객체가 다음 프레임에서 추적되지 않는 경우, 상기 일 실시 예의 과정과 같이 보정을 수행할 수 있다. 또 다른 예시에서, 현재 프레임에서 추적된 객체가 다 음 프레임에서 추적되는 경우, 도 13과 같이 현재 프레임 내 추적된 객체 정보(크기 및 위치)를 이용하여 탐색 과정을 통해 다음 프레임에서 현재 프레임의 추적된 객체와 대응되는 객체를 찾아 이를 객체 추적 결과에 추가 함으로써 객체 추적 결과를 보정할 수 있다. <본 개시의 실시 예들에 사용되는 Semantics 및 Syntax 설명> 시간적 복원 정보와 관련된 semantics는 일련의 프레임 그룹 단위, 예를 들어 GOP 단위를 기준으로 설명한다. Ⅰ. temporal_restoration_data( ) 관련 temporal_restoration_flag: 시간적 리샘플링에 대한 적용 여부에 대한 플래그, 1인 경우 시간적 리샘플링 적용 Temporal_resampling_ratio_idx: 시간적 리샘플링율에 대한 리스트의 인덱스, 시간적 리샘플링 적용에 대해 temporal_restoration_flag로 표기하므로 입력신호와 출력신호가 동일한 경우는 포함하지 않는다. 예를 들어, 샘플링율은 1/2, 1/4, 1/8 등 비율의 형태 중 하나가 될 수 있고 초당 프레임의 숫자가 될 수 있다. 부호화기와 복호화기는 해당 샘플링율 리스트에 대해서 약속하고 부호화기는 리스트의 인덱스를 전송할 수 있다. 실시예에 따라 상기 전송된 응용에 대해 리샘플링율이 고정되거나 필요한 프레임의 개수가 고정된 경우 해당 정보는 생략 될 수 있다. same_period_flag: 시간적 리샘플링에 대한 적용시 주기적 리샘플링, 또는 비주기적 리샘플링을 사용하는지 에 대한 플래그이며, 실시예에 따라 시간적 리샘플링의 주기성이 고정되는 경우 해당 정보 및 관련 정보는 생략 될 수 있다. same_period_flag가 1인 경우 동일한 주기로 시간적 리샘플링 된 것을 의미한다. delta_frame_idx[i]: 프레임숫자에 따라 이전 프레임 인덱스와의 차분 값을 전송한다. 이전 인덱스와의 차분 값이므로 프레임율로 계산된 num_of_frames보다 1개 작은 개수를 전송하면 된다. 이때 i는 프레임 인덱스를 나 타낸다. RoI_Processing_flag: 현재 시퀀스가 관심 영역 기반 처리가 수행되었는지 여부를 나타내는 1-bit 플래그 num_of_GOPs: 한 시퀀스 내 GOP 수를 나타내는 정보 num_of_frames: 한 GOP 내 프레임 수를 나타내는 정보 num_of_RoIs: 한 프레임 내 관심 영역 수를 나타내는 정보 upsamp_ratio_RoIs: 관심 영역의 업샘플링 레이트 정보, 해당 정보로 복원된 관심 영역 기반 처리된 영상을 얻을 수 있다. upsamp_ratio_nonRoIs: 비 관심 영역의 업샘플링 레이트 정보, 해당 정보로 복원된 비 관심 영역 영상을 얻 을 수 있다. RoI_exist_region_LT, RoI_exist_region_LT: 픽처 내 관심 영역이 존재하는 영역의 좌상단 좌표 RoI_exist_region_RB, RoI_exist_region_RB: 픽처 내 관심 영역이 존재하는 영역의 우하단 좌표 frame_RoI_Information_flag[p]: 관심 영역 정보 부호화가 수행되는 프레임 정보, 1인 경우 해당 프레임 내 관심 영역의 정보를 부호화 수행, 0인 경우 해당 프레임은 스킵한다. 이때, 해당 플래그가 1인 가장 인접한 두 프레임 간의 관심 영역 정보를 부호화 수행 only_specific_RoI_flag 및 specific_RoI_flag[j]: only_specific_RoI_flag가 1인 경우, 관심 영역 정보 부호화가 수행되는 프레임 내 모든 관심 영역의 정보를 부호화 수행, only_specific_RoI_flag가 0인 경우, specific_RoI_flag[j]를 파싱받아 해당 플래그가 1인 관심 영역에 대해서만 정보 부호화를 수행. 이때 j는 관심 영역 인덱스를 나타낸다. LinearMotion_flag[j]: 해당 플래그가 1인 경우, 관심 영역 정보 부호화가 수행되는 두 프레임 내 j번째 관 심 영역은 선형 움직임을 갖고, 움직임 위치 및 차분 값의 정보만 복호화 수행, 해당 플래그가 0인 경우, 상기 관심 영역은 선형 움직임 외에 예시로 어파인 움직임을 갖고, 움직임 위치 및 차분 값의 정보에 추가로, 어파인 파라미터를 복호화 수행 Affine_param_a[j], Affine_param_b[j], Affine_param_c[j], Affine_param_d[j]: LinearMotion_flag[j]이 0인 경우, 복호화 될 수 있는 정보이며 네 개의 어파인 파라미터를 이용해서 어파인 수식 (수학식 1)을 통해 움 직임 정보를 얻을 수 있다. Comp_param_flag[j]: 해당 플래그가 1인 경우, 관심 영역 정보 부호화가 수행되는 두 프레임 내 j번째 관심 영역은 보상 파라미터를 갖고, 이때 보상 파라미터는 명시적으로 시그널링/파싱할 수 있고, 복호화기에서 주변 복원 픽셀 정보를 통해 유도할 수 있다. 보상 파라미터 적용은 수학식 2의 예시와 같이 적용할 수 있다.상기 시간적 복원 정보(temporal restoration data)의 일 신텍스의 예시는 다음 표 1과 같다. 표 1 Descriptor temporal_restoration_data( ) { temporal_restoration_flag ue if( temporal_restoration_flag ) { temporal_resampling_ratio_idx ue(v) same_period_flag ue if( !same_period_flag ) { for( i=0; i<num_of_frames; i++ ) { delta_frame_idx[i] ue(v) } } } } 상기 관심영역 정보의 일 신텍스의 예시는 다음 표 2와 같다. 표 2 Descriptor RoI_Processing_flag u if( RoI_Processing_flag ) { num_of_GOPs ue(v) RoI_exist_region_LT ue(v) RoI_exist_region_LT ue(v) RoI_exist_region_RB ue(v) RoI_exist_region_RB ue(v) for ( i=0; i<num_of_GOPs; i++ ) { upsamp_ratio_RoIs ue(v) upsamp_ratio_nonRoIs ue(v) num_of_frames ue(v) num_of_RoIs ue(v) only_specific_RoI_flag ue for ( p=0; p<num_of_frames; p++ ) { frame_RoI_Information_flag[p] ue } if ( only_specific_RoI_flag ) { for ( p=0; p<num_of_frames; p++ ) { for ( j=0; j<num_of_RoIs; j++ ) { if ( frame_RoI_Information_flag[p] ) { specific_RoI_flag[j] ue } } } } int a = 0; for ( p=0; p<num_of_frames; p++ ) { if ( frame_RoI_Information_flag[p]) { if ( !only_specific_RoI_flag ) { for ( j=0; j<num_of_RoIs; j++ ) { if ( a == 0 ) { pos_RoI(i)(p)(j)[0] ue(v) pos_RoI(i)(p)(j)[1] ue(v) a++; } else { pos_diff_coding LinearMotion_flag ue Comp_param_flag ue if ( !LinearMotion_flag ) { Affine_param_a ue(v) Affine_param_b ue(v) Affine_param_c ue(v) Affine_param_d ue(v) } } } } else { for ( j=0; j<num_of_RoIs; j++ ) { if ( specific_RoI_flag[i] ) { if ( a == 0 ) { pos_RoI(i)(p)(j)[0] ue(v) pos_RoI(i)(p)(j)[1] ue(v) a++; } else { pos_diff_coding LinearMotion_flag ue Comp_param_flag ue if ( !LinearMotion_flag ) { Affine_param_a ue(v) Affine_param_b ue(v) Affine_param_c ue(v) Affine_param_d ue(v) } } } } } } } } 다양한 실시 예에서, 위치 차이에 대한 복원 정보는 다음과 같이 정의할 수 있다. 아래 위치 차이에 대한 복원 정보와 관련된 semantics는 일련의 프레임 그룹 단위, 예를 들어 GOP 단위를 기준으로 설명한다. n은 GOP 인덱 스, p는 프레임 인덱스, m은 관심 영역 인덱스를 나타낸다. Ⅱ. pos_diff_coding( ) 관련 pos_RoI(n)(p)(m)[0], pos_RoI(n)(p)(m)[1]: 각 일련의 프레임 그룹 단위 (GOP) 내 첫 번째 프레임 내 존재 하는 관심 영역들의 위치 정보 - RoI_exist_region_LT, RoI_exist_region_LT, 중, 0이 아닌 값을 파싱한 경우, 일 예시로, RoI_exist_region_LT + pos_RoI(n)(m)[0], RoI_exist_region_LT + pos_RoI(n)(m)[1]이 m번째 관심 영역 최종 복원된 위치일 수 있다. - pos_diff_coding을 통해 얻은 위치 차분 값에 대해, 동일한 방법으로 관심 영역의 최종 복원된 위치를 구할 수 있다. abs_pos_diff_greater0_flag_RoI(n)(p)(m)[0], abs_pos_diff_greater0_flag_RoI(n)(p)(m)[1]: 0번째 프레 임의 동일 관심 영역에 대해 x축 및 y축 위치 정보 차분 값의 절대 값이 0인지 여부를 나타내는 1-bit 플래그abs_pos_diff_greater1_flag_RoI(n)(p)(m)[0], abs_pos_diff_greater1_flag_RoI(n)(p)(m)[1]: 0번째 프레 임의 동일 관심 영역에 대해 x축 및 y축 위치 정보 차분 값의 절대 값이 1인지 여부를 나타내는 1-bit 플래그 abs_pos_diff_minus2_RoI(i)(p)(j)[0], abs_pos_diff_minus2_RoI(i)(p)(j)[0]: 0번째 프레임의 동일 관심 영역에 대해 x축 및 y축 위치 정보 차분 값 절대 값의 -2의 해당하는 값을 나타내는 정보 pos_diff_sign_flag(i)(p)(j)[0], pos_diff_sign_flag(i)(p)(j)[1]: 0번째 프레임의 동일 관심 영역에 대해 x축 및 y축 부호 값을 나타내는 1-bit 플래그, 1인 경우 + 부호, 0인 경우 - 부호 아래 표 3은 다양한 실시 예에 따른 위치 차이에 대한 복원 정보의 일 신택스 예시이다. 표 3 Descriptor pos_diff_coding( ) { abs_pos_diff_greater0_flag_RoI(i)(p)(j)[0] ue abs_pos_diff_greater0_flag_RoI(i)(p)(j)[1] ue if( abs_pos_diff_greater0_flag_RoI(i)(p)(j)[0] ) abs_pos_diff_greater1_flag_RoI(i)(p)(j)[0] ue if( abs_pos_diff_greater0_flag_RoI(i)(p)(j)[1] ) abs_pos_diff_greater1_flag_RoI(i)(p)(j)[1] ue if( abs_pos_diff_greater0_flag_RoI(i)(p)(j)[0] ) { if( abs_pos_diff_greater1_flag_RoI(i)(p)(j)[0] ) abs_pos_diff_minus2_RoI(i)(p)(j)[0] ue(v) pos_diff_sign_flag(i)(p)(j)[0] ue } if( abs_pos_diff_greater0_flag_RoI(i)(p)(j)[1] ) { if( abs_pos_diff_greater1_flag_RoI(i)(p)(j)[1] ) abs_pos_diff_minus2_RoI(i)(p)(j)[1] ue(v) pos_diff_sign_flag(i)(p)(j)[1] ue } } 본 명세서와 도면에 나타난 본 개시의 예시들은 본 개시의 기술 내용을 쉽게 설명하고 본 개시의 이해를 돕기 위해 특정 예를 제시한 것뿐이며, 본 명의 범위를 한정하고자 하는 것은 아니다. 지금까지 설명한 예시들 이외 에도 다른 변형 예들이 실시 가능하다는 것은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 자명 한 것이다. 본 명세서에 기재된 청구항들은 다양한 방식으로 조합될 수 있다. 예를 들어, 본 명세서의 방법 청구항의 기술 적 특징이 조합되어 장치로 구현될 수 있고, 본 명세서의 장치 청구항의 기술적 특징이 조합되어 방법으로 구현 될 수 있다. 또한, 본 명세서의 방법 청구항의 기술적 특징과 장치 청구항의 기술적 특징이 조합되어 장치로 구 현될 수 있고, 본 명세서의 방법 청구항의 기술적 특징과 장치 청구항의 기술적 특징이 조합되어 방법으로 구현 될 수 있다."}
{"patent_id": "10-2024-0061816", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 비디오/영상 코딩 시스템의 예를 개략적으로 나타낸다. 도 2는 비디오/영상 인코딩 장치의 구성을 개략적으로 설명하는 도면이다. 도 3은 비디오/영상 디코딩 장치의 구성을 개략적으로 설명하는 도면이다. 도 4a 내지 도 4d는 VCM 인코더와 VCM 디코더를 나타낸 예시도들이다. 도 5는 본 개시의 일 실시 예에 따른 인코딩 장치의 블록도를 도시한다. 도 6은 본 개시의 일 실시 예에 따른 관심영역기반 처리기의 상세 동작을 나타낸다. 도 7a, 7b 및 7c는 본 개시의 일 실시 예에 따른 내부 부호화 수행기의 상세 동작을 나타낸다. 도 8은 본 개시의 일 실시 예에 따른 관심영역 정보 부호화 수행부의 상세 동작을 나타낸다. 도 9는 본 개시의 일 실시 예에 따른 디코딩 장치의 블록도를 도시한다. 도 10은 본 개시의 일 실시 예에 따른 내부 복호화 수행기 및 관심 영역 기반 복원기의 상세 동작을 나타낸다. 도 11은 본 개시의 일 실시 예에 따른 관심영역 정보 복호화 수행부의 세부 동작을 나타낸다. 도 12a 및 12b는 본 개시의 일 실시 예에 따른 시간적 복원 수행기의 세부 동작을 나타낸다. 도 13은 본 개시의 일 실시 예에 따른 관심영역에 대한 시간적 보정의 일 예시이다. 도 14a 및 14b는 본 개시의 일 실시 예에 따른 머신 비전 태스크 수행기의 상세 동작을 나타낸다."}
