{"patent_id": "10-2019-0091525", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0013830", "출원번호": "10-2019-0091525", "발명의 명칭": "의료용 인공 신경망의 분석 결과를 평가하는 의료용 인공 신경망 기반 의료 영상 분석 장치", "출원인": "주식회사 코어라인소프트", "발명자": "김진국"}}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "의료용 인공 신경망에 기반하여 의료 영상을 분석하는 의료 영상 분석 장치로서, 상기 의료 영상 분석 장치는컴퓨팅 시스템을 포함하며 상기 컴퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함하고,상기 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고,상기 제1 분석 결과를 제2 인공 신경망에 입력하고,상기 제1 분석 결과에 대한 상기 제2 인공 신경망의 추론에 의하여 얻어지는 제1 평가 결과를 획득하고, 상기 제1 평가 결과를 상기 제1 의료 영상 및 상기 제1 분석 결과에 대한 평가 결과로서 사용자에게 제공하는인공 신경망 기반 의료 영상 분석 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제1 평가 결과에 기반하여 상기 제1 분석 결과에 대한 수용 여부를 상기 사용자에게 제안하는 인공 신경망기반 의료 영상 분석 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제2 인공 신경망은 복수의 제2 의료 영상들에 대한 상기 제1 인공 신경망의 추론에 의하여 생성되는 복수의 제2 분석 결과들 각각에 대한 전문가 평가를 입력받아 상기 복수의 제2 분석 결과들 각각이 타당한지를 평가하는 기능을 학습한 인공 신경망인 인공 신경망 기반 의료 영상 분석 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 인공 신경망은 상기 제1 의료 영상에 대한 영상 분할, 임상적 진단 또는 상기 제1 의료 영상 내의 분할된 객체에 대한 측정 중 적어도 하나 이상을 상기 제1 분석 결과로서 제공하는 인공 신경망 기반 의료 영상분석 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망이 상기 제1 분석 결과에 대한 문맥 정보를 추출하도록 상기 제2 인공 신경망을 제어하고, 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 제1 분석 결과를 평가하는 상기 제1 평가 결과를 추론에 의하여 출력하도록 상기 제2 인공 신경망을 제어하는 인공 신경망 기반 의료 영상 분석 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 적어도 하나 이상의 프로세서는 공개특허 10-2021-0013830-3-상기 제1 의료 영상 및 상기 제1 분석 결과를 함께 상기 제2 인공 신경망에 입력하고, 상기 제2 인공 신경망이 상기 제1 의료 영상에 대한 문맥 정보를 추출하도록 상기 제2 인공 신경망을 제어하고, 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 제1 의료 영상에 대한 상기 제1 분석 결과를 평가하는상기 제1 평가 결과를 추론에 의하여 출력하도록 상기 제2 인공 신경망을 제어하는 인공 신경망 기반 의료 영상분석 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제1 평가 결과를 출력하는 상기 제2 인공 신경망의 내부 파라미터에 기반한 히트맵 정보를 상기 제1 의료영상 또는 상기 제1 분석 결과에 오버레이하여 표시하고, 상기 히트맵 정보를 상기 제2 인공 신경망이 상기 제1평가 결과를 출력하는 과정에 대한 설명적 정보(descriptive information)로서 상기 사용자에게 제공하는 인공신경망 기반 의료 영상 분석 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과를 미리 정해진 규칙에 의하여 대표적인 시각화 형태로 시각화하고, 상기 대표적인 시각화 형태로 시각화된 상기 제1 분석 결과를 상기 제2 인공 신경망의 입력으로 제공하는 인공신경망 기반 의료 영상 분석 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "의료용 인공 신경망의 훈련 장치로서, 상기 의료용 인공 신경망의 훈련 장치는 컴퓨팅 시스템을 포함하며 상기컴퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함하고,상기 적어도 하나 이상의 프로세서는 복수의 제2 의료 영상들에 대한 제1 인공 신경망의 추론에 의하여 생성되는 복수의 제2 분석 결과들을 획득하거나 수신하고,상기 복수의 제2 분석 결과들 각각에 대한 전문가의 평가를 포함한 사용자 입력을 획득하고, 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가를 제2 인공 신경망에 입력하고,상기 제2 인공 신경망이 상기 복수의 제2 분석 결과들 각각이 타당한지를 평가하는 기능을 학습하도록 상기 제2인공 신경망을 훈련하는 의료용 인공 신경망의 훈련 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제1 인공 신경망은 상기 복수의 제2 의료 영상들 각각에 대한 영상 분할, 임상적 진단 또는 상기 복수의제2 의료 영상들 각각 내의 분할된 객체에 대한 측정 중 적어도 하나 이상을 상기 복수의 제2 분석 결과들로서제공하는 의료용 인공 신경망의 훈련 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망이 상기 복수의 제2 분석 결과들 각각에 대한 문맥 정보를 추출하도록 상기 제2 인공 신경공개특허 10-2021-0013830-4-망을 제어하고, 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가 간의 관련성을 학습하도록 상기 제2 인공 신경망을 훈련하는 의료용 인공신경망의 훈련 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 복수의 제2 의료 영상들, 상기 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가를 함께 상기 제2 인공 신경망에 입력하고,상기 제2 인공 신경망이 상기 복수의 제2 의료 영상들 각각에 대한 문맥 정보를 추출하고, 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 복수의 제2 의료 영상들 각각에 대한 상기 제2 분석결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가 간의 관련성을 학습하도록 상기 제2인공 신경망을 훈련하는 의료용 인공 신경망의 훈련 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 복수의 제2 분석 결과들 각각에 대한 학습을 위한 훈련 과정에서, 상기 제2 인공 신경망의 내부 파라미터에 기반한 히트맵 정보를 생성하고, 상기 히트맵 정보를 상기 복수의 제2 의료 영상들 각각 또는 상기 복수의 제2 분석 결과들 각각에 오버레이하여표시하고, 상기 히트맵 정보를 상기 제2 인공 신경망의 훈련 과정에 대한 설명적 정보(descriptiveinformation)로서 사용자에게 제공하는 의료용 인공 신경망의 훈련 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 적어도 하나 이상의 프로세서는 상기 복수의 제2 분석 결과들 각각을 미리 정해진 규칙에 의하여 대표적인 시각화 형태로 시각화하고, 상기 대표적인 시각화 형태로 시각화된 상기 복수의 제2 분석 결과들 각각을 상기 제2 인공 신경망의 입력으로제공하는 의료용 인공 신경망의 훈련 장치."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨팅 시스템에서 실행되는 인공 신경망 기반 의료 영상 분석 방법에 있어서,제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하는 단계;상기 제1 분석 결과를 제2 인공 신경망에 입력하는 단계;상기 제1 분석 결과에 대한 상기 제2 인공 신경망의 추론에 의하여 얻어지는 제1 평가 결과를 획득하는 단계;및상기 제1 평가 결과를 상기 제1 의료 영상 및 상기 제1 분석 결과에 대한 평가 결과로서 사용자에게 제공하는단계;를 포함하는 인공 신경망 기반 의료 영상 분석 방법."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,공개특허 10-2021-0013830-5-상기 제1 평가 결과에 기반하여 상기 제1 분석 결과에 대한 수용 여부를 상기 사용자에게 제안하는 단계;를 더 포함하는 인공 신경망 기반 의료 영상 분석 방법."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 제2 인공 신경망의 추론에 의하여 얻어지는 상기 제1 평가 결과를 획득하는 단계는상기 제2 인공 신경망이 상기 제1 분석 결과에 대한 문맥 정보를 추출하는 단계; 및상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 제1 분석 결과를 평가하는 상기 제1 평가 결과를 추론에 의하여 출력하는 단계;를 포함하는 인공 신경망 기반 의료 영상 분석 방법."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서,상기 제1 분석 결과를 미리 정해진 규칙에 의하여 대표적인 시각화 형태로 시각화하는 단계; 및상기 대표적인 시각화 형태로 시각화된 상기 제1 분석 결과를 상기 제2 인공 신경망의 입력으로 제공하는 단계;를 더 포함하는 인공 신경망 기반 의료 영상 분석 방법."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "컴퓨팅 시스템에서 실행되는 의료용 인공 신경망의 훈련 방법에 있어서,복수의 제2 의료 영상들에 대한 제1 인공 신경망의 추론에 의하여 생성되는 복수의 제2 분석 결과들을 획득하거나 수신하는 단계;상기 복수의 제2 분석 결과들 각각에 대한 전문가의 평가를 포함한 사용자 입력을 획득하는 단계;상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가를 제2 인공 신경망에 입력하는 단계; 및상기 제2 인공 신경망이 상기 복수의 제2 분석 결과들 각각이 타당한지를 평가하는 기능을 학습하도록 상기 제2인공 신경망을 훈련하는 단계;를 포함하는 의료용 인공 신경망의 훈련 방법."}
{"patent_id": "10-2019-0091525", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 제2 인공 신경망을 훈련하는 단계는상기 제2 인공 신경망이 상기 복수의 제2 분석 결과들 각각에 대한 문맥 정보를 추출하는 단계; 및 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가 간의 관련성을 학습하도록 상기 제2 인공 신경망을 훈련하는 단계;를 포함하는 의료용 인공 신경망의 훈련 방법."}
{"patent_id": "10-2019-0091525", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "컴퓨팅 시스템을 포함하는 의료용 인공 신경망에 기반하여 의료 영상을 분석하는 장치가 개시된다. 본 발명의 일 실시예에 따른 장치는 컴퓨팅 시스템을 포함하며 상기 컴퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 상기 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지 는 제1 분석 결과를 획득하거나 수신하고, 상기 제1 분석 결과를 제2 인공 신경망에 입력하고, 상기 제1 분석 결 과에 대한 상기 제2 인공 신경망의 추론에 의하여 얻어지는 제1 평가 결과를 획득하고, 상기 제1 평가 결과를 상 기 제1 의료 영상 및 상기 제1 분석 결과에 대한 평가 결과로서 사용자에게 제공한다."}
{"patent_id": "10-2019-0091525", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자동화된 시스템에 의하여 인공 신경망 기반 의료 영상 분석을 실행하는 장치 및 방법에 관한 것이다. 구체적으로는 의료용 인공 신경망의 분석 결과에 대한 부가 정보를 생성하여 사용자(영상의 (radiologist) 또는 임상의(clinician)를 포함함)에게 제공하고, 의료 영상에 대한 분석을 지원하는 방법 및 그 방법을 실행하는 장치(컴퓨팅 시스템)에 관한 것이다.본 발명은 산업통상자원부 및 한국산업기술평가관리원의 전자시스템산업핵심기술개발(R&D)사업의 일환으로 수행 한 연구로부터 도출된 것이다[과제고유번호: 1415160865, 세부과제번호 : 10072064, 과제명: 폐, 간, 심질환 영 상판독지원을 위한 인공지능 원천기술개발 및 PACS 연계 상용화]."}
{"patent_id": "10-2019-0091525", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상 내 객체를 분할(segmentation) 또는 검출(detection)하고, 영상 내 객체를 분류(classify)하는 기술은 영 상 처리에서 다양한 용도로 활용된다. 의료 영상에서는 영상의 밝기 값 또는 강도 값(intensity)에 기반하여 영 상 내 객체를 분할, 검출, 분류하고 이때 객체는 인체의 장기(organ), 병변(lesion)일 수 있다. 영상 처리 과정을 자동화하는 데 있어서 최근 인공 신경망으로서 딥러닝, 컨볼루션 신경망(CNN, Convolutional Neural Network)의 도입은 영상 처리 자동화 프로세스의 성능을 비약적으로 향상시켰다. 그러나 한편으로 딥러닝, CNN 등의 최근의 인공 신경망은 내부가 블랙박스에 가까워, 도출되는 결과가 우수하더 라도 사용자가 이를 전적으로 수용하고 채택하는 데에 거부감이 있다. 특히 인공 신경망에 대한 거부감은 인간 의 생명을 다루는 분야인 의료 영상 분야에서는 더욱 중요하게 부각된다. 설명 가능한 인공지능(explainable artificial intelligence, X-AI)에 대한 연구가 미국 국방고등연구계획국 (DARPA, Defense Advanced Research Projects Agency) 등에 의하여 시도되고 있다 (https://www.darpa.mil/program/explainable-artificial-intelligence). 다만 아직까지 가시적인 성과는 드러 나지 않고 있는 상황이다. 인공 신경망을 이용하여 의료 영상의 병변을 자동으로 진단한 결과에 대하여 사용자 피드백을 받아 인공 신경망 의 자동 진단 결과를 수정한 수정 진단 결과를 생성하는 기술이 한국등록특허 KR 10-1818074호 \"인공지능 기반 의료용 자동 진단 보조 방법 및 그 시스템\"에 의하여 개시되었다. 인공 신경망을 이용하여 의료 기기의 임상 데이터에 대한 진단을 수행하고, 진단 결과에 대한 통계적 검정을 통 하여 의료 기기의 자동 진단 결과에 대한 유효성을 평가하는 기술이 한국등록특허 KR 10-1929752호 \"인공지능 기반 의료기기의 임상적 유효성 평가 방법 및 시스템\"에 의하여 개시되었다. 상기 선행기술 KR 10-1818074호 및 KR 10-1929752호는 인공 신경망에 의한 자동 진단 결과를 검증하거나 사용자 에 의하여 피드백받아 수정하는 기술로서, 인공 신경망에 의한 자동 진단 결과에 대한 신뢰성이 높지 않기 때문 에 이를 보완하려는 기술이다. 그러나 상기 선행기술 KR 10-1818074호는 인공 신경망의 자동 진단 결과를 사용 자가 특정 영역에 대한 수정, 삭제, 추가가 가능한 사용자 인터페이스를 제공할 뿐이고, 상기 선행기술 KR 10- 1929752호는 인공 신경망의 자동 진단 결과와 인간 전문가의 진단 결과 간의 통계적 일치도를 구하는 기술이어 서, 결국 인공 신경망의 자동 진단 결과 자체가 신뢰할 만한 지, 인공 신경망의 자동 진단 결과가 어떤 점에서 신뢰할 만한 지에 대한 설명적 정보(descriptive information)를 도출하기는 어렵다. 한편 의료 도메인에서 복잡한 형태의 병변을 분할/검출하고, 분류/진단하기 위한 기술로서 복수의 분할 알고리 듬들을 선택적으로 적용하는 기술이 국제공개특허 WO 2018/015414 \"METHOD AND SYSTEM FOR ARTIFICIAL INTELLIGENCE BASED MEDICAL IMAGE SEGMENTATION\" 등이 소개된 바 있다. 상기 선행문헌 WO 2018/015414 에서는 영상 분할의 최종 결과물을 얻기 위하여 pre-trained 분할 알고리듬들을 비교하고 적어도 어느 하나를 선택하는 기법이 적용된다. 이 과정에서도 복수의 분할 알고리듬들을 비교하고 평 가하는 개념이 소개된다. 그러나 상기 선행문헌 WO 2018/015414 에서도 분할 알고리듬들을 선택적으로 적용하는 기준이 무엇인지에 대한 설명적 정보(descriptive information, explanation)를 도출할 수 없어 임상의(clinician) 또는 영상의 (radiologist)가 이러한 분할 기법이 임상적으로 어느 정도 유용한 지에 대한 신뢰를 높이기 어렵다는 문제가 있다. 의료 영상의 판독 과정에서도 전적으로 블랙박스처럼 실행되는 인공지능 판독 시스템이 결과를 도출하는 과정을 임상적으로 신뢰할 수 없다는 유사한 문제점이 여전히 존재한다. 선행기술문헌 특허문헌(특허문헌 0001) 한국등록특허 KR 10-1818074호 \"인공지능 기반 의료용 자동 진단 보조 방법 및 그 시스템\" (2018년 1월 8일) (특허문헌 0002) 한국등록특허 KR 10-1929752호 \"인공지능 기반 의료기기의 임상적 유효성 평가 방법 및 시스템\" (2018년 12월 11일) (특허문헌 0003) 국제공개특허 WO 2018/015414 \"METHOD AND SYSTEM FOR ARTIFICIAL INTELLIGENCE BASED MEDICAL IMAGE SEGMENTATION\" (2018년 1월 25일)"}
{"patent_id": "10-2019-0091525", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "최근 딥러닝 기반의 인공지능 기법을 적용하여 영상 분할, 영상 내 객체의 검출, 및 분류 기법의 성능을 향상하 고자 하는 노력이 계속되고 있다. 그러나 딥러닝 기반 인공지능의 경우, 그 동작으로부터 제공되는 결과물이 우 연히 높은 성능을 보이는 것인지, 그 임무(task)에 적절한 판단 과정을 거친 것인 지를 사용자가 알 수 없는 블 랙박스(black-box)라는 점이 활용 가능성을 제한하고 있다. 반면 설명이 용이한 룰-베이스드(rule-based) 방식의 훈련 또는 학습으로는 딥러닝 만큼의 성과가 얻어지지 못 하는 점에서 사용이 제한되고 있다. 따라서 향상된 성능을 가지면서도 설명적 정보(descriptive information, explanation)를 제공할 수 있는 딥러닝 기반 인공지능에 대한 연구가 활발하다. 인공 신경망을 이용한 영상 처 리를 실제로 응용하는 데 있어서, 특히 의료 영상 분야에서는 분할, 진단 및 분류 등 분석의 근거에 대한 설명 적 정보가 필요한데 종래 기술로는 아직까지 설명적 정보를 도출하지 못하는 상황이다. 상기 선행기술 KR 10-1818074호에서는 인공 신경망에 의한 자동 진단 결과를 사용자가 수정할 수 있는 사용자 인터페이스, 수정된 정보를 구별하여 표시할 수 있는 데이터 포맷에 대해서만 규정하고 있어서 인공 신경망의 자동 진단 결과를 인간 전문가가 보기 전까지는 유효한 진단 결과인지 미리 알 수가 없다. 상기 선행기술 KR 10-1929752호에서는 인공 신경망의 자동 진단 결과와 독립적으로 인간 전문가의 진단 결과를 도출한 후, 양 결과를 비교하여 통계적으로 검증할 뿐이므로 인공 신경망의 자동 진단 결과 자체에 대해서는 인 간 전문가의 평가를 알 수 없다. 따라서 상기 선행기술 KR 10-1818074호와 상기 KR 10-1929752호를 결합하더라도 인공 신경망의 자동 진단 결과 에 대한 인간 전문가의 평가 결과를 미리 예측할 수는 없다. 또한 상기 선행기술들에 기반해서는 인공 신경망의 자동 진단 결과 자체가 신뢰할 만한 지, 인공 신경망의 자동 진단 결과가 어떤 점에서 신뢰할 만한 지에 대한 설명적 정보(descriptive information)를 도출하기 어렵다. 상기 선행문헌 WO 2018/015414에서도 어떤 요소가 최종적인 분할 segmentation 성능을 향상하는 데에 영향을 미 치는 지에 대한 설명적 정보(descriptive information, explanation)를 도출할 수 없고, 분할 과정에서 영상의 (radiologist) 또는 임상의(clinician)가 임상적으로 유의미한 피드백을 제공하더라도, 이 피드백이 실제로 딥 러닝 시스템에 적절히 적용되었는지 확인할 수 있는 방법이 없다. 본 발명의 목적은 인공 신경망의 자동 분석 결과에 대한 인간 전문가의 평가 결과를 미리 예측하는 것이다. 본 발명의 목적은 제1 인공 신경망의 자동 분석 결과에 대한 제2 인공 신경망의 추론을 통하여 제1 인공 신경망의 자동 분석 결과의 적합 여부를 예측하고, 예측된 적합 여부를 제공함으로써 사용자에 의하여 최종적으로 채택되 는 의료 영상 분석 결과의 정확도를 높이는 것이다."}
{"patent_id": "10-2019-0091525", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 상기의 목적을 달성하기 위하여 도출된 구성으로서, 본 발명의 일 실시예에 따른 의료용 인공 신경망 에 기반하여 의료 영상을 분석하는 의료 영상 분석 장치는 컴퓨팅 시스템을 포함하며 상기 컴퓨팅 시스템은 적 어도 하나 이상의 프로세서를 포함한다. 상기 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고, 상기 제1 분석 결과를 제2 인공 신경 망에 입력하고, 상기 제1 분석 결과에 대한 상기 제2 인공 신경망의 추론에 의하여 얻어지는 제1 평가 결과를 획득하고, 상기 제1 평가 결과를 상기 제1 의료 영상 및 상기 제1 분석 결과에 대한 평가 결과로서 사용자에게제공한다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제1 평가 결과에 기반하여 상기 제1 분석 결과에 대한 수용 여 부를 상기 사용자에게 제안할 수 있다. 이때 상기 제2 인공 신경망은 복수의 제2 의료 영상들에 대한 상기 제1 인공 신경망의 추론에 의하여 생성되는 복수의 제2 분석 결과들 각각에 대한 전문가 평가를 입력받아 상기 복수의 제2 분석 결과들 각각이 타당한지를 평가하는 기능을 학습한 인공 신경망일 수 있다. 이때 상기 제1 인공 신경망은 상기 제1 의료 영상에 대한 영상 분할, 임상적 진단 또는 상기 제1 의료 영상 내 의 분할된 객체에 대한 측정 중 적어도 하나 이상을 상기 제1 분석 결과로서 제공할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망이 상기 제1 분석 결과에 대한 문맥 정보 (context information)를 추출하도록 상기 제2 인공 신경망을 제어할 수 있다. 또한 상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 제1 분석 결과를 평가하는 상기 제1 평가 결과를 추론에 의하여 출력하도록 상기 제2 인공 신경망을 제어할 수 있다. 이때 문맥 정보는 영상 분할인지, 영상 진단인지, 분할된 관심 영역 또는 병변에 대한 측정인지를 나타내는 정보를 의미할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제1 의료 영상 및 상기 제1 분석 결과를 함께 상기 제2 인공 신 경망에 입력할 수 있고, 상기 제2 인공 신경망이 상기 제1 의료 영상에 대한 문맥 정보를 추출하도록 상기 제2 인공 신경망을 제어할 수 있다. 또한 상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 제1 의료 영상에 대한 상기 제1 분석 결과를 평가하는 상기 제1 평가 결과를 추론에 의하 여 출력하도록 상기 제2 인공 신경망을 제어할 수 있다. 예를 들어 제2 인공 신경망이 제1 의료 영상도 함께 입 력받는 경우, 제2 인공 신경망은 제1 의료 영상에 대한 문맥 정보를 추출하고, 제1 인공 신경망의 제1 분석 결 과에 대한 제1 평가 결과도 출력할 수 있다. 이때 제2 인공 신경망은 미리 복수의 제2 의료 영상들에 대한 상기 제1 인공 신경망의 추론에 의하여 생성되는 복수의 제2 분석 결과들 각각에 대한 전문가 평가를 입력받아 상기 복수의 제2 분석 결과들 각각이 타당한지를 평가하는 기능을 학습한 인공 신경망일 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제1 평가 결과를 출력하는 상기 제2 인공 신경망의 내부 파라미 터에 기반한 히트맵(heatmap) 정보를 상기 제1 의료 영상 또는 상기 제1 분석 결과에 오버레이하여 표시하고, 상기 히트맵 정보를 상기 제2 인공 신경망이 상기 제1 평가 결과를 출력하는 과정에 대한 설명적 정보 (descriptive information)로서 상기 사용자에게 제공할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과를 미리 정해진 규칙에 의하여 대표적인 시각화 형태로 시각화할 수 있고, 상기 대표적인 시각화 형태로 시각화된 상기 제1 분석 결과를 상기 제2 인공 신경망 의 입력으로 제공할 수 있다. 본 발명의 일 실시예에 따른 의료용 인공 신경망의 훈련 장치는 컴퓨팅 시스템을 포함하며 상기 컴퓨팅 시스템 은 적어도 하나 이상의 프로세서를 포함한다. 상기 적어도 하나 이상의 프로세서는 복수의 제2 의료 영상들에 대한 제1 인공 신경망의 추론에 의하여 생성되는 복수의 제2 분석 결과들을 획득하거나 수신하고, 상기 복수의 제2 분석 결과들 각각에 대한 전문가의 평가를 포함한 사용자 입력을 획득하고, 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가를 제2 인공 신경망에 입력하고, 상기 제2 인 공 신경망이 상기 복수의 제2 분석 결과들 각각이 타당한지를 평가하는 기능을 학습하도록 상기 제2 인공 신경 망을 훈련한다. 이때 상기 제1 인공 신경망은 상기 복수의 제2 의료 영상들 각각에 대한 영상 분할, 임상적 진단 또는 상기 복 수의 제2 의료 영상들 각각 내의 분할된 객체에 대한 측정 중 적어도 하나 이상을 상기 복수의 제2 분석 결과들 로서 제공하는 인공 신경망일 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망이 상기 복수의 제2 분석 결과들 각각에 대한 문맥 정보를 추출하도록 상기 제2 인공 신경망을 제어할 수 있고, 상기 제2 인공 신경망이 상기 문맥 정보에 기 반하여 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가 간의 관 련성을 학습하도록 상기 제2 인공 신경망을 훈련할 수 있다. 이때 문맥 정보는 영상 분할인지, 영상 진단인지, 분할된 관심 영역 또는 병변에 대한 측정인지를 나타내는 정보를 의미할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 복수의 제2 의료 영상들, 상기 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가를 함께 상기 제2 인공 신경망에 입력할 수 있고, 상기 제2 인공 신경망이 상기 복수의 제2 의료 영상들 각각에 대한 문맥 정보를 추출할 수 있다. 또한 상기 적어도 하나 이 상의 프로세서는 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 복수의 제2 의료 영상들 각각에 대한 상기 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가 간의 관련성을 학습하 도록 상기 제2 인공 신경망을 훈련할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 복수의 제2 분석 결과들 각각에 대한 학습을 위한 훈련 과정에 서, 상기 제2 인공 신경망의 내부 파라미터에 기반한 히트맵 정보를 생성할 수 있고, 상기 히트맵 정보를 상기 복수의 제2 의료 영상들 각각 또는 상기 복수의 제2 분석 결과들 각각에 오버레이하여 표시하고, 상기 히트맵 정보를 상기 제2 인공 신경망의 훈련 과정에 대한 설명적 정보(descriptive information)로서 사용자에게 제공 할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 복수의 제2 분석 결과들 각각을 미리 정해진 규칙 에 의하여 대표적인 시각화 형태로 시각화할 수 있고, 상기 대표적인 시각화 형태로 시각화된 상기 복수의 제2 분석 결과들 각각을 상기 제2 인공 신경망의 입력으로 제공할 수 있다. 본 발명의 일 실시예에 따른 컴퓨팅 시스템에서 실행되는 인공 신경망 기반 의료 영상 분석 방법은 제1 의료 영 상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하는 단계; 상기 제1 분 석 결과를 제2 인공 신경망에 입력하는 단계; 상기 제1 분석 결과에 대한 상기 제2 인공 신경망의 추론에 의하 여 얻어지는 제1 평가 결과를 획득하는 단계; 및 상기 제1 평가 결과를 상기 제1 의료 영상 및 상기 제1 분석 결과에 대한 평가 결과로서 사용자에게 제공하는 단계를 포함한다. 본 발명의 일 실시예에 따른 컴퓨팅 시스템에서 실행되는 의료용 인공 신경망의 훈련 방법은 복수의 제2 의료 영상들에 대한 제1 인공 신경망의 추론에 의하여 생성되는 복수의 제2 분석 결과들을 획득하거나 수신하는 단계; 상기 복수의 제2 분석 결과들 각각에 대한 전문가의 평가를 포함한 사용자 입력을 획득하는 단계; 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가를 제2 인공 신경망에 입력하는 단계; 및 상기 제2 인공 신경망이 상기 복수의 제2 분석 결과들 각각이 타당한지를 평가하는 기능을 학습하도록 상기 제2 인공 신경망을 훈련하는 단계를 포함한다."}
{"patent_id": "10-2019-0091525", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 인공 신경망의 자동 분석 결과에 대한 인간 전문가의 평가 결과를 미리 예측할 수 있다. 본 발명에 따르면 제1 인공 신경망의 자동 분석 결과에 대한 제2 인공 신경망의 추론을 통하여 제1 인공 신경망의 자동 분석 결과의 적합 여부를 예측하고, 예측된 적합 여부를 제공함으로써 사용자에 의하여 최종적으로 채택되 는 의료 영상 분석 결과의 정확도를 높일 수 있다. 제2 인공 신경망의 학습은 제1 인공 신경망의 자동 분석 결과 및 제1 인공 신경망의 자동 분석 결과에 대한 전 문가의 평가에 기반하여 이루어질 수 있다. 본 발명에 따르면 제1 인공 신경망의 자동 분석 결과가 쓸모 있는 지 여부에 대한 제2 인공 신경망의 평가는 인간 전문가가 제1 인공 신경망의 자동 분석 결과를 평가할 때 이용 되는 대표적인 시각화 형태를 이용하여 학습될 수 있다. 이로 인하여 종래 기술들보다 인간 전문가가 해석 가능 한 시각화 형태에 가까운 환경에서 제2 인공 신경망의 학습이 이루어지고, 종래 기술들보다 인간 전문가의 평가 에 가까운 평가 결과를 얻을 수 있다. 또한 본 발명의 제2 인공 신경망은 심층 신경망 등을 이용하여 고도화될 수 있으며, 인간 전문가가 육안으로는 발견하기 어려운 평가 요소를 발견하여 제1 인공 신경망의 자동 분석 결과가 적합한 지 여부를 더욱 정확하게 평가할 수 있다. 제1 인공 신경망의 자동 분석 결과에 대한 본 발명의 제2 인공 신경망의 평가 결과는 제1 인공 신경망의 자동 분석 결과를 인간 전문가가 해석하는 방식을 모방하여 훈련된 것이므로, 제1 인공 신경망의 자동 분석 결과에 대한 인간의 관점에서 본 설명적 정보(descriptive information)로서 이해될 수 있다. 또한 본 발명에 따르면 제1 인공 신경망의 자동 분석 결과에 대한 제2 인공 신경망의 평가 결과는 제1 인공 신 경망의 자동 분석 결과에 대한 임상적 유용성에 대한 정보를 제공할 수 있다. 이때 사용자는 제1 인공 신경망의 임상적 유용성에 대한 정보를 얻을 수 있고, 임상적 유용성에 대한 정보를 제1 인공 신경망에 대한 피드백으로 제공하여, 향후 제1 인공 신경망을 더욱 고도화하고 개선하는 데에 기여할 수도 있다. 즉, 본 발명에 의하여 제 공되는 설명적 정보는 제1 인공 신경망과 같이, 인공 신경망에 기반한 의료 영상 자동 분석 알고리듬들의 성능 을 향상하는 데에 유용하게 사용될 수도 있다."}
{"patent_id": "10-2019-0091525", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "상기 목적 외에 본 발명의 다른 목적 및 특징들은 첨부 도면을 참조한 실시예에 대한 설명을 통하여 명백히 드 러나게 될 것이다. 본 발명의 바람직한 실시예를 첨부된 도면들을 참조하여 상세히 설명한다. 본 발명을 설명함에 있어, 관련된 공 지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설 명은 생략한다. 최근 급속히 발전한 딥러닝/CNN 기반 인공 신경망 기술은 영상 분야에 적용할 경우, 인간의 육안으로 구분하기 어려운 시각적 요소를 구분하는 용도로 고려되고 있다. 이러한 기술의 적용 분야는 보안, 의료 영상, 비파괴 검 사 등 다양한 분야로 확대될 가능성이 기대되고 있다. 예를 들어 의료 영상 분야에서, 암 조직 중 생검(biopsy) 상태에서 즉시 암으로 판정되지 않고, 병리학적 (pathology) 관점에서 추적 모니터링된 이후에 비로소 암인지 여부가 판정되는 경우가 있다. 인간의 육안으로는 의료 영상에서 해당 세포가 암인지 여부를 확진하기 어려우나, 인공 신경망 기술을 적용할 경우 인간의 육안으 로 관찰하는 것보다 더 정확한 예측 결과를 얻을 수 있을 것이라는 기대가 있다. 그러나 인공 신경망 기술이 일부 연구에서 인간의 육안보다 우수한 예측/분류/판독(진단) 결과를 얻을 수 있다 해도, 인공 신경망 기술의 적용으로 인하여 얻어진 예측/분류/판독(진단) 결과에 대한 설명적 정보가 부족하여 의료 현장에서 이를 수용하고 채택하기는 어려운 점이 문제로 대두된다. 본 발명은 인공 신경망 기술을 적용하여 인간의 육안으로 분류하기 어려운 영상 내 객체를 분류/예측하는 성능 을 향상시키고자 하는 의도에서 도출되었다. 또한 인공 신경망 기술의 분류/예측 성능을 향상시키기 위해서라도 인공 신경망 기술의 분류/예측 과정에 기반한 최종 판독 결과의 생성까지 도달하는 내부 동작에 대한 설명적 정 보를 얻는 것은 대단히 중요하다. 본 발명은 인공 신경망에 기반한 복수의 의료 영상 판독 알고리듬들의 각각의 성능 지표 및 임상적 유용성을 정 량화된 지표로서 제시할 수 있다. 이로 인하여 인공 신경망의 분류/예측 과정에 기반한 최종 판독 결과가 도출 되는 과정에 대한 설명적 정보를 제공할 수 있으며, 인공 신경망의 분류/예측/판독(지원) 결과를 인간 사용자가 채택할 것인지에 대한 레퍼런스를 제공할 수 있다. 종래 기술의 인공 신경망을 의료 영상의 판독/진단에 적용하였을 때, 주어진 임무(task) 내의 주어진 데이터 범 위에만 과적합(overfit)되어 통계적 정확도는 높으나, 몇몇 임상적으로 중요한 진단 포인트에서는 정확도가 낮 은 경우가 있다. 적지 않은 종래 기술의 인공 신경망이 이러한 상황에 놓여 있으며, 이로 인하여 임상의들이 인 공 신경망이 적용된 의료 영상의 판독/진단 결과에 대하여 신뢰하기 어려운 상황이 빈번하게 발생한다. 이러한 위험성은 널리 알려진 인공 신경망인 IBM의 Watson 솔루션이, 학습된 데이터에 포함된 환자의 인종 정보 등에 과적합되어 새로운 인종의 환자들의 데이터셋에서는 정확도가 현저하게 저하되는 등의 문제점을 노출하고 있다는 데에서 더욱 명백하다. 따라서 인공 신경망의 우수한 판독/진단 잠재능력을 최대한 활용하되, 임상의들이 이러한 판독/진단 결과를 수 용할 지 여부에 대한 정량화된 지표를 제공하고, 임상의들이 이러한 정량화된 지표를 생성하는 데에 직접적인 피드백을 제공할 수 있는 경로를 확보하는 것은 대단히 중요하다. 특히 종래의 인공 신경망이 의료 영상의 분석과 분류에 우수한 성능을 나타내지만, 인간 전문가의 관점에서 바 라보았을 때 중요하지 않은 요소에 과적합(overfit)되어 임상적 유용성을 떨어뜨리고 있는 만큼, 종래의 인공 신경망의 분석 결과에 대한 인간 전문가의 관점을 정확히 반영할 수 있는 평가 결과를 별도의 인공 신경망을 이 용하여 제공할 수 있다면 상기 평가 결과는 종래의 인공 신경망의 분석 결과에 대한 임상적 유용성을 높일 수 있는 설명적 정보로서 활용될 수 있을 것이다. 도 1은 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 장치를 도시하는 도면이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 의료용 인공 신경망에 기반하여 의료 영상을 분석하는 의료 영상 분석 장치는 컴퓨팅 시스템을 포함하며 상기 컴퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 상기 적어도 하나 이상의 프로세서는 제1 의료 영상에 대한 제1 인공 신경망의 추론 에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하고, 상기 제1 분석 결과를 제2 인공 신경망 에 입력하고, 상기 제1 분석 결과에 대한 상기 제2 인공 신경망의 추론에 의하여 얻어지는 제1 평가 결과를 획득하고, 상기 제1 평가 결과를 상기 제1 의료 영상 및 상기 제1 분석 결과 에 대한 평가 결과로서 사용자에게 제공한다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제1 평가 결과에 기반하여 상기 제1 분석 결과 에 대한 수용 여부를 상기 사용자에게 제안할 수 있다. 이때 상기 제2 인공 신경망은 복수의 제2 의료 영상들에 대한 상기 제1 인공 신경망의 추론에 의하여 생성되는 복수의 제2 분석 결과들 각각에 대한 전문가 평가를 입력받아 상기 복수의 제2 분석 결과들 각각이 타 당한지를 평가하는 기능을 학습한 인공 신경망일 수 있다. 이때 상기 제1 인공 신경망은 상기 제1 의료 영상에 대한 영상 분할, 임상적 진단 또는 상기 제1 의 료 영상 내의 분할된 객체에 대한 측정 중 적어도 하나 이상을 상기 제1 분석 결과로서 제공할 수 있 다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망이 상기 제1 분석 결과에 대한 문맥 정보(context information)를 추출하도록 상기 제2 인공 신경망을 제어할 수 있다. 또한 상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 제1 분석 결과 를 평가하는 상기 제1 평가 결과를 추론에 의하여 출력하도록 상기 제2 인공 신경망을 제어할 수 있다. 이때 문맥 정보는 영상 분할인지, 영상 진단인지, 분할된 관심 영역 또는 병변에 대한 측정인지를 나 타내는 정보를 의미할 수 있다. 문맥 정보의 예로는 폐의 Lobe 분할인지, Airway 분할인지, Airway Measurement 인지 등을 구분하는 정보를 들 수 있다. 제2 인공 신경망은 통합된 Task에 대한 통합 훈련된 경우일 수 있 으며, 문맥 정보에 기반하여 주어진 Task가 어떤 Task인 지를 구별하고 구별된 Task에 맞는 평가 결과를 도출할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과를 그대로 상기 제2 인공 신경망 에 입력할 수도 있고, 다른 실시예에 따라서는 제1 의료 영상을 수신한 후, 상기 제1 의료 영상 및 상기 제1 분석 결과를 함께 상기 제2 인공 신경망에 입력할 수도 있다. 이때 상기 적어도 하나 이상 의 프로세서는 상기 제2 인공 신경망이 상기 제1 의료 영상에 대한 문맥 정보를 추출하도록 상 기 제2 인공 신경망을 제어할 수 있다. 또한 상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신 경망이 상기 문맥 정보에 기반하여 상기 제1 의료 영상에 대한 상기 제1 분석 결과를 평가하는 상기 제1 평가 결과를 추론에 의하여 출력하도록 상기 제2 인공 신경망을 제어할 수 있다. 예를 들어 제2 인공 신경망이 제1 의료 영상도 함께 입력받는 경우, 제2 인공 신경망은 제1 의료 영상 에 대한 문맥 정보를 추출하고, 제1 인공 신경망의 제1 분석 결과에 대한 제1 평가 결과도 출력할 수 있다. 이때 제2 인공 신경망은 미리 복수의 제2 의료 영상들에 대한 상기 제1 인공 신경망(11 0)의 추론에 의하여 생성되는 복수의 제2 분석 결과들 각각에 대한 전문가 평가를 입력받아 상기 복수의 제2 분 석 결과들 각각이 타당한지를 평가하는 기능을 학습한 인공 신경망일 수 있다. 학습 과정에서도 제2 인공 신경 망은 복수의 제2 분석 결과들 각각 및 복수의 제2 의료 영상들 각각에 대한 문맥 정보를 추출할 수 있다.제2 인공 신경망에서 문맥 정보가 각각의 분류된 Task에 대한 복수의 제2 분석 결과들에 대한 평가 결과를 학습하는 과정을 분류하는 기준으로 작용할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제1 평가 결과를 출력하는 상기 제2 인공 신경망 의 내부 파라미터에 기반한 히트맵(heatmap) 정보를 상기 제1 의료 영상 또는 상기 제1 분석 결과 에 오버레이하여 표시하고, 상기 히트맵 정보를 상기 제2 인공 신경망이 상기 제1 평가 결과를 출력하는 과정에 대한 설명적 정보(descriptive information)로서 상기 사용자에게 제공할 수 있다. 히트맵 정 보는 제2 인공 신경망이 제1 분석 결과에 대한 제1 평가 결과를 도출하는 근거로서 제공될 수 있다. 즉, 제2 인공 신경망이 제1 평가 결과를 도출하는 데에 주로 추출된 특징이 히트맵으로 표시될 것이므로 인간 전문가가 제1 인공 신경망의 자동 분석 결과를 평가하는 데 중점적으로 검토하는 사항과 제 2 인공 신경망의 히트맵이 대체로 일치하는 지를 제2 인공 신경망 자체의 신뢰도를 나타내는 근거로 서도 활용될 수 있다. 또는 제2 인공 신경망이 제1 평가 결과를 도출하는 데에 주로 추출되는 특징이 히트맵으로 확인되면, 인간 전문가가 놓칠 수 있는 평가 포인트에 대한 제2 인공 신경망을 이용한 검증의 근거로서도 활용될 수 있다. 또는 제2 인공 신경망이 제1 평가 결과를 도출하는 근거이므로, 이 내용 을 향후 제1 인공 신경망의 분석 성능을 향상시키는 데에 이용할 수도 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제1 분석 결과를 미리 정해진 규칙에 의하여 대표적 인 시각화 형태로 시각화할 수 있고, 상기 대표적인 시각화 형태로 시각화된 상기 제1 분석 결과를 상기 제2 인공 신경망의 입력으로 제공할 수 있다. 이때 대표적인 시각화 형태는 '인간 전문가가 해석 가 능한 형태' 또는 '인간 전문가가 해석 시 주로 사용하는 형태'를 의미하며, 미리 정해진 규칙에 의하여 컴퓨팅 시스템에 의하여 분석되고 추출된 패턴에 기반하여 결정될 수 있다. 예를 들어, 인간 전문가가 제1 인공 신경망의 분석 결과를 평가한 결과를 제2 인공 신경망의 학습을 위하여 사용할 수 있는데, 이때 인간 전문가가 제1 인공 신경망의 분석 결과를 평가하기 위하여 제1 인공 신경망의 분석 결과를 의료 영상 에 오버레이하거나 의료 영상을 제1 인공 신경망의 분석 결과와 함께 비교 가능하도록 시각화할 수 있을 것이다. 또한 의료 영상을 특수한 형태로 시각화한 후 제1 인공 신경망의 분석 결과와 함께 비교 가능하도 록 시각화되거나, 특수한 형태로 시각화된 의료 영상에 제1 인공 신경망의 분석 결과가 오버레이될 수 있 다. 컴퓨팅 시스템 및 프로세서는 이러한 인간 전문가가 제1 인공 신경망의 분석 결과를 평가하 기 위하여 채택한 시각화 옵션/시각화 형태를 추적하고 분석하여 패턴화할 수 있다. 이처럼 패턴화된 시각화 옵 션/시각화 형태를 대표적인 시각화 형태라고 명명할 수 있다. 한편 상기에 언급된 문맥 정보에 기반하여 세분화 된 Task에 맞추어 대표적인 시각화 형태도 세분화될 수 있다. 즉, 이 과정은 미리 정해진 규칙에 의하여 컴퓨팅 시스템 내의 적어도 하나 이상의 프로세서에 의하 여 수행될 수 있다. 다만 미리 정해진 규칙은, 제1 인공 신경망의 분석 결과를 인간 전문가인 사용자가 평 가하는 과정을 컴퓨팅 시스템이 모니터링하여, 가장 대표적인 시각화 형태를 추출하고, 추출된 시각화 형 태를 미리 정해진 규칙을 도출하고 정의할 수 있다. 즉, 프로세서에 의하여 제1 인공 신경망의 제1 분석 결과가 제2 인공 신경망의 입력으로 제공할 때 그대로 입력되는 것이 아니라 제1 분석 결과가 문맥 정보에 기반하여 세분류된 대표적인 시각화 형태로 시각화된 후, 제2 인공 신경망의 입력으로 제공될 수 있다. 이러한 대표적인 시각화 형태는 복수의 제2 의료 영상들에 대한 제2 분석 결과를 인간 전문가의 평가 결과와 함께 제2 인공 신경망이 학습 하는 경우에도 표준화되어 적용될 수 있다. 종래 기술들은 인공 신경망을 이용한 임상적 진단에 대하여 인간 전문가의 평가 결과를 반영하지만, 선행기술 KR 10-1818074에서는 인간 전문가가 수정한 정보를 표시할 수 있는 데이터 포맷에 대해서만 규정하고 있어서 인 공 신경망의 자동 진단 결과에 대한 별도의 평가 기준을 제시하는 것은 아니다. 선행기술 KR 10-1929752에서는 인공 신경망의 자동 진단 결과와 독립적으로 인간 전문가의 진단 결과를 도출한 후, 양 결과를 비교하여 통계적 으로 검증할 뿐이므로 인공 신경망의 자동 진단 결과에 대한 인간 전문가의 평가를 확인할 수 있는 방법이 없다. 또 다른 종래 기술들은 인공 신경망의 자동 진단 결과에 인간 전문가의 평가 또는 피드백을 반영하기는 하지만, 평가 또는 피드백이 인공 신경망의 구성 중 일부로서 융합되어 종래의 인공 신경망 CAD(Computer-aided Diagnosis) 모델에 평가 또는 피드백 지표가 반영된 새로운 자동 진단 결과를 제시하는 기술들이 존재한다. 이러한 종래 기술들에서는 인공 신경망의 자동 진단 결과 외에 '여러 다른 정보'가 종합적으로 부가된다. 즉, 평가 인덱스(인간 전문가의 평가 결과를 반영한 인덱스)를 생성하는 인공 신경망 모델은 기존 CAD 인공 신경망모델의 자동 진단 결과 외에도 많은 부가적인 임상 진단 정보를 입력받는다. 이 경우 선행 기술의 평가 인덱스 를 생성하는 인공 신경망 모델의 입력 데이터는 매우 복잡해지는데, 평가 인덱스를 생성하는 인공 신경망 모델 의 입력 데이터는 인간이 이해하는 간단한 형태가 아니고, 따라서 평가 인덱스를 생성하는 과정을 인간이 직관 적으로 이해하거나 검증할 수 없다. 즉, 상기 선행기술은 인공 신경망의 딥러닝 구조의 특징을 최대한 활용하는 것으로서, 인간이 이해할 수 없거나 인간이 인지할 수 없는 부분을 딥 인공 신경망의 구성에 맡겨 해결하는 기 술로 볼 수 있다. 이러한 종래의 인공 신경망 기술은 몇몇 도메인에서 인간의 인지 또는 판단보다 우수한 성능을 내고 있으나, 그 분석 결과를 인간이 수용하거나 검증할 수 있는 수단이 없다. 상기 선행기술도 분석 결과에 대한 평가 인덱스 지표를 제공하지만, 정작 그 평가 인덱스를 생성하는 과정이 인간이 수용하거나 검증하기에 매우 난해하다는 점 이 문제로 지적된다. 본 발명은 원본 의료 영상에 대해서는 제1 인공 신경망의 분석에 의존할 뿐, 제2 인공 신경망은 원본 의료 영상에 대해서는 어떤 오퍼레이션도 할 필요 없다. 다만 이 과정에서 제2 인공 신경망의 평가 동작을 인간이 수행하는 평가 동작과 호응시키기 위하여 제1 인공 신경망의 분석 결과를 원본 의료 영상과 결합하 거나, 원본 의료 영상에 기반한 시각화 과정을 거쳐서 제2 인공 신경망의 입력으로 제공한다. 본 발명의 실시예에서는 제1 인공 신경망과는 완전히 독립된 제2 인공 신경망이 제1 인공 신경망 의 분석 결과를 평가하는 과정을 훈련함으로써, 제2 인공 신경망은 인간 전문가를 대신하여 제1 인공 신경망의 분석 결과에 대한 평가를 수행할 수 있다. 이는 종래 기술들이 제1 인공 신경망의 진단 결 과에 대한 평가를 반영하되, 융합된 인공 신경망 모델에 의하여 인간 전문가의 평가가 반영된 새로운 진단 결과 를 도출하는 경향과 차별화된다. 즉 종래 기술들에서는 제1 인공 신경망의 진단 결과에 대한 전문가의 평가가 반영된 새로운 진단 결과를 융합된 인공 신경망 모델이 도출되므로, 제1 인공 신경망의 진단 결과에 대한 평가 자체에 대해서는 외부 의 사용자가 알 수가 없으며, 제1 인공 신경망의 진단 결과 중 어떤 포인트가 평가에 중요한 역할을 수행 하는 지 등을 외부의 사용자가 알 수가 없다. 본 발명의 실시예에서는 제1 인공 신경망과 완전히 독립적인 제2 인공 신경망이 제1 인공 신경망 의 분석 결과에 대하여 평가 결과를 도출할 수 있으므로, 이는 제1 인공 신경망의 분석 결과에 대한 설명적 정보로서 외부의 사용자에게 제공될 수 있고, 제1 인공 신경망의 분석 결과에 대한 임상적 유용성 에 대하여 인간 전문가인 사용자의 신뢰도를 제공할 수 있는 근거가 될 수 있다. 도 2는 본 발명의 일 실시예에 따른 의료용 인공 신경망의 훈련 장치를 도시하는 도면이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 의료용 인공 신경망의 훈련 장치는 컴퓨팅 시스템을 포함하 며 상기 컴퓨팅 시스템은 적어도 하나 이상의 프로세서를 포함한다. 상기 적어도 하나 이상의 프로세 서는 복수의 제2 의료 영상들에 대한 제1 인공 신경망의 추론에 의하여 생성되는 복수의 제2 분 석 결과들을 획득하거나 수신하고, 상기 복수의 제2 분석 결과들 각각에 대한 전문가의 평가를 포함한 사용자 입력을 획득하고, 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각 에 대한 상기 전문가의 평가를 제2 인공 신경망에 입력하고, 상기 제2 인공 신경망이 상기 복수 의 제2 분석 결과들 각각이 타당한지를 평가하는 기능을 학습하도록 상기 제2 인공 신경망을 훈련한 다. 제2 인공 신경망은 제2 분석 결과들과 전문가의 평가를 입력으로 수신하여 제2 인공 신경망 내부의 연산에 의하여 얻어지는 함수 값을 출력하여 프로세서로 전달하고, 프로세서는 함 수 값에 기반하여 제2 인공 신경망의 훈련을 계속할 지 종료할 지 여부를 결정할 수 있다. 이때 상기 제1 인공 신경망은 상기 복수의 제2 의료 영상들 각각에 대한 영상 분할, 임상적 진단 또 는 상기 복수의 제2 의료 영상들 각각 내의 분할된 객체에 대한 측정 중 적어도 하나 이상을 상기 복수의 제2 분석 결과들로서 제공하는 인공 신경망일 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망이 상기 복수의 제2 분석 결과들 각각에 대한 문맥 정보를 추출하도록 상기 제2 인공 신경망을 제어할 수 있고, 상기 제2 인공 신경 망이 상기 문맥 정보에 기반하여 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가 간의 관련성을 학습하도록 상기 제2 인공 신경망을 훈련할 수 있다. 이때 문맥 정보는 영상 분할인지, 영상 진단인지, 분할된 관심 영역 또는 병변에 대한 측정인지를 나타내는 정 보를 의미할 수 있다. 문맥 정보의 예로는 폐의 Lobe 분할인지, Airway 분할인지, Airway Measurement인지 등을구분하는 정보를 들 수 있다. 제2 인공 신경망은 통합된 Task에 대한 통합 훈련된 경우일 수 있으며, 문맥 정보에 기반하여 주어진 Task가 어떤 Task인 지를 구별하고 구별된 Task에 맞는 평가 결과를 도출할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제2 분석 결과들을 그대로 상기 제2 인공 신경망 에 입력할 수도 있고, 본 발명의 다른 실시예에 따라서는 상기 복수의 제2 의료 영상들, 상기 제2 분 석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가를 함께 상기 제2 인공 신경망에 입력할 수도 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망 이 상기 복수의 제2 의료 영상들 각각에 대한 문맥 정보를 추출할 수 있다. 또한 상기 적어도 하나 이상의 프로세서는 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 복수의 제2 의료 영상들 각각에 대한 상기 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가 의 평가 간의 관련성을 학습하도록 상기 제2 인공 신경망을 훈련할 수 있다. 제2 인공 신경망에 서 문맥 정보가 각각의 분류된 Task에 대한 복수의 제2 분석 결과들에 대한 평가 결과를 학습하는 과정을 분류하는 기준으로 작용할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 복수의 제2 분석 결과들 각각에 대한 학습을 위한 훈 련 과정에서, 상기 제2 인공 신경망의 내부 파라미터에 기반한 히트맵 정보를 생성할 수 있고, 상기 히트 맵 정보를 상기 복수의 제2 의료 영상들 각각 또는 상기 복수의 제2 분석 결과들 각각에 오버레이하 여 표시하고, 상기 히트맵 정보를 상기 제2 인공 신경망의 훈련 과정에 대한 설명적 정보(descriptive information)로서 사용자에게 제공할 수 있다. 히트맵 정보는 제2 인공 신경망의 평가 결과에 대한 설명의 근거로서 이용될 수 있다. 히트맵 정보는 영상의(radiologist) 또는 임상의(clinician)와 같은 의료진이 제2 인 공 신경망의 평가 결과에 대한 의료진의 신뢰도 제고를 위하여 이용되거나, 제2 인공 신경망의 평가 결과에 대한 의료진의 교차 검증, 제2 인공 신경망의 평가 결과를 통하여 인간 전문가가 발견하기 어려운 중요한 진단 포인트를 의료진이 수용하는 기준으로 이용될 수 있다. 히트맵 정보는 제2 인공 신경망을 개 발하는 소프트웨어 또는 인공 지능 전문가에게도 유용한 정보로서 활용될 수 있다. 제2 인공 신경망의 동 작이 원활한지, 제2 인공 신경망이 임상적으로 유의미한 시각적 요소에 적절하게 포커싱하고 있는지 등을 히트맵의 분포에 기반하여 개발자가 판단할 수 있다. 이때 상기 적어도 하나 이상의 프로세서는 상기 복수의 제2 분석 결과들 각각을 미리 정해진 규칙에 의하여 대표적인 시각화 형태로 시각화할 수 있고, 상기 대표적인 시각화 형태로 시각화된 상기 복수의 제2 분 석 결과들 각각을 상기 제2 인공 신경망의 입력으로 제공할 수 있다. 본 발명의 컴퓨팅 시스템은 제1 인공 신경망의 분석 결과(임상적 진단, 영상 분할, 측정 결과 중 적 어도 하나 이상)에 대한 전문가 평가를 피드백받고, 제1 인공 신경망의 분석 결과 및 전문가 평가를 제2 인공 신경망의 입력으로 제공하여 제2 인공 신경망이 제1 인공 신경망의 분석 결과에 대한 전문 가 평가를 학습하도록 제어한다. 제1 인공 신경망의 분석 결과 중 어떤 세부사항이 전문가 평가에 중요한 역할을 하는 지 등을 파악하는 것은 제2 인공 신경망의 학습에 의하여 제2 인공 신경망 내부의 네트 워크 파라미터에 의하여 규정될 것이다. 이 과정에서 제2 인공 신경망의 학습은 인간 전문가인 사용자가 제1 인공 신경망의 분석 결과를 평가 할 때 주로 이용하는 시각화 형태, 시각화 요소, 디스플레이 화면, 디스플레이 화면에 표시되는 제1 인공 신경 망의 분석 결과 및 원본 의료 영상의 디스플레이 형태 등을 모두 포함하여 제공되는 훈련용 입력 영상에 기반하여 실행된다. 따라서 제2 인공 신경망의 학습 과정은 인간 전문가인 사용자가 수행하는 제1 인공 신 경망의 분석 결과에 대한 평가 과정과 가장 유사한 결과를 제공할 것이며, 이 과정에서 제1 인공 신경망 의 분석 결과에 대한 평가 과정에서 인간이 인지하지 못하지만 평가에 중요한 역할을 하는 세부 지표 등이 제2 인공 신경망의 학습에 의하여 추출되고 학습될 것이다. 본 발명의 컴퓨팅 시스템은 제2 인공 신경망을 제1 인공 신경망과 완전히 분리하고, 제1 인공 신경망과 완전히 독립적으로 동작하는 제2 인공 신경망을 이용함으로써, 제1 인공 신경망의 분 석 결과를 '인간 전문가인 사용자에게 설명하기 용이한 형태'로 평가할 수 있는 점이 최대의 장점이라고 할 수 있다. 이때 제2 인공 신경망의 학습과 훈련을 위하여, 제1 인공 신경망의 분석 결과는 '인간 전문가 인 사용자가 해석할 수 있는 형태'로 주어지고, 인간 전문가인 사용자가 해석할 수 있는 형태로 주어진 분석 결 과에 대해서 인간 전문가인 사용자인 전문가의 피드백을 받게 된다. 제2 인공 신경망의 추론 과정의 입력 으로 주어지는 것은 제1 인공 신경망의 분석 결과로서 '인간 전문가인 사용자가 해석할 수 있는 형태'로 제공되는 분석 결과이고, 제2 인공 신경망의 훈련 과정의 입력으로 주어지는 것은 제1 인공 신경망의분석 결과로서 '인간 전문가인 사용자가 해석할 수 있는 형태'로 제공되는 분석 결과 및 그에 대한 인간 전문가 의 평가이다. 이때 인간 전문가인 사용자가 해석할 수 있는 형태란 제1 인공 신경망의 분석 결과가 의료 영상에 오버레 이되는 형태, 또는 제1 인공 신경망의 분석 결과가 인간 전문가인 사용자가 진단에 사용하기 위하여 시각 화되는 재가공 과정을 거친 형태로 표현되는 것을 의미한다. 본 발명의 실시예에 따라서는 사용자가 제1 인공 신경망의 분석 결과를 검증하기 위하여 의료 영상의 다른 뷰와 결합하거나, 다른 뷰와 동기화하여 비교하 는 명령을 실행할 경우, 본 발명의 컴퓨팅 시스템은 이러한 사용자의 명령을 수집하고 분석하여 사용자가 제1 인공 신경망의 분석 결과를 검증하기 위하여 사용하는 대표적인 시각화 형태를 도출할 수 있다. 예를 들어, 제1 인공 신경망의 분석 결과가 어떤 병변에 대한 진단, 또는 영상 분할을 의미하는 마스크로 표현되면, 인간 전문가인 사용자는 그 마스크를 의료 영상에 오버레이하여 비교해 보는 것이 일반적인 루틴일 수 있다. 이 경우 제2 인공 신경망에는 제1 인공 신경망의 분석 결과인 마스크가 그대로 투입되는 것 이 아니라, 미리 정해진 규칙에 의하여 의료 영상에 제1 인공 신경망의 분석 결과인 마스크가 오버레이된 영상이 입력으로 제공된다. 이때 제1 인공 신경망이 분석을 위하여 입력받는 의료 영상의 타입과, 제 2 인공 신경망의 입력을 위하여 오버레이되는 의료 영상의 타입은 서로 동일할 수도 있고 서로 다를 수도 있다. 또한 제1 인공 신경망이 입력받는 의료 영상의 뷰(view)와 제2 인공 신경망의 입력을 위하여 오버레이되는 의료 영상의 뷰가 서로 동일할 수도 있고 서로 다를 수도 있다. 도 1과 도 2를 함께 참조하면, 본 발명의 특징은 다음과 같이 기술할 수 있다. 본 발명의 실시예에서는 제1 인 공 신경망(110, 210)(영상 분석 기능)과 평가만을 수행하는 제2 인공 신경망(120, 220)을 분리한다. 이때 제2 인공 신경망(120, 220)은 평가 기능에만 최적화되므로 주어진 Task에 대한 집중도가 높다. 제1 인공 신경망 (110, 210)에서 얻어진 분석 결과를 제2 인공 신경망(120, 220)이 평가하는 데 있어서 종래 기술들의 경우 CAD 진단과 평가 인덱스가 융합된 새로운 CAD 모델이 도출되므로, CAD 진단의 어떤 요소 또는 포인트가 평가 인덱스 생성에 기여하는 지 등 세부적인 기능의 구별이 불분명하고, CAD 진단 모듈의 진단 결과에 대한 평가(평가 인덱 스 생성) 자체의 적합성 등 분석이 용이하지 않다. 제1 인공 신경망(110, 210)과 제2 인공 신경망(120, 220)을 분리함으로써 전문가의 평가 시 중요하게 작용하는 요인을 제2 인공 신경망(120, 220)이 집중적으로 추출할 수 있도록 하고, CAD 진단 결과(또는 분할/측정 결과)의 정확성 자체에는 영향을 주지 않으면서 진단/분할/측정 결 과에 대한 평가의 중요 요인을 효과적으로 추출할 수 있도록 한다. 제1 인공 신경망(110, 210)의 분석 결과가 특정 데이터셋에 오버핏되지는 않았는지, 제1 인공 신경망(110, 21 0)의 분석 결과가 높은 평가를 받지 못하는 이유는 무엇인지 등의 원인을 분석하는 데에 있어서도 이처럼 제1 인공 신경망(110, 210)과 분리된 제2 인공 신경망(120, 220)이 독립적으로 평가 기능을 학습하는 것이 유리하다. 또한 본 발명에서는 제2 인공 신경망(120, 220)에 입력되는 데이터를 간단한 형태로 표준화할 수 있다. 입력 데 이터는 제1 인공 신경망(110, 210)의 분석 결과와 그에 대한 전문가 평가일 뿐이다. 실시예에 따라서는 제1 인 공 신경망(110, 210)의 분석 결과와 전문가 평가가 원본 의료 영상의 대표적인 시각화 형태와 결합되어 디스플 레이될 수 있다. 전문가 평가들이 서로 얼마나 일치하는지, 전문가 평가들이 인공 신경망의 분석 결과의 어떤 점에 초점을 맞추어 평가하는 지 등의 요인은 제2 인공 신경망(120, 220)의 학습 과정을 통하여 도출하도록 한 다. 제2 인공 신경망(120, 220)의 분석의 자유도를 높이는 대신 주어지는 Task를 단순하고 명확히 한다. 한편, 제2 인공 신경망(120, 220)은 제1 인공 신경망(110, 210)과 분리함으로써, 제2 인공 신경망(120, 220)이 분석 과정 자체를 다시 할 필요는 없도록 한다. 이는 학습 과정을 빠르게 수행할 수 있도록 하는 한편, 제2 인공 신 경망(120, 220)이 주어지는 Task에 집중할 수 있도록 한다. 제1 인공 신경망(110, 210)의 분석 결과를 생성하는 과정과, 제2 인공 신경망(120, 220)이 제1 인공 신경망(110, 210)의 분석 결과를 평가하는 과정은 명확히 분리 되어 영향을 주지 않을 수 있다. 제2 인공 신경망(120, 220)은 제1 인공 신경망(110, 210)의 동작 및 특징에 대 한 설명적 정보를 제공할 수 있는데, 종래 기술들의 평가 모듈(평가 인덱스 생성 모델)이 제1 인공 신경망(110, 210)과 결합하는 점과 비교하면 오히려 평가 과정에서 중요하게 작용하는 요인들을 제1 인공 신경망(110, 210) 의 분석 결과와 독립적으로 추출할 수 있다. 이 점은 오히려 최종 사용자 입장에서는 제1 인공 신경망(110, 210)의 분석 결과를 평가하는 데에 어떤 점이 중요한 지 정성적으로 기술하는 설명적 정보를 획득하는 데에 더 욱 용이하다. 즉, 최종 사용자는 제1 인공 신경망(110, 210)의 분석 결과를 수용할 지 여부에 대해서 설명할 수 있도록 최적화된 정보를 제공받을 수 있다. 한편 제1 인공 신경망(110, 210)의 개발자에게 있어서도, 제1 인공 신경망(110, 210)의 분석 결과가 높은 평가 와 사용자의 채택을 받기 위해서 더욱 개선해야 할 점에 대해서 정성적으로 설명되는 정보를 제공받을 수 있다. 즉, 제1 인공 신경망(110, 210)의 개선할 점에 어서도 설명할 수 있도록 최적화된 정보를 제공받을 수 있다. 한편 본 발명에서 제1 인공 신경망(110, 210)과 제2 인공 신경망(120, 220)이 분리되므로, 제1 인공 신경망 (110, 210)에서 도출된 분석 결과를 인간 전문가가 평가할 수 있는 영역이라면 무엇이든지 제2 인공 신경망 (120, 220)의 학습 대상이 될 수 있다. 예를 들어 종래 기술에서는 주로 CAD, 즉, 병변의 검출, 진단을 수행하 는 인공 신경망이 평가의 적용 대상이 되었으나, 본 발명이 적용될 수 있는 분야가 확대될 수 있다. 예를 들어 영상의 분할, 영상 내의 병변의 검출 뿐만 아니라 영상의 분할을 통하여 분할된 특정 관심 영역에 대한 측정도 본 발명의 제2 인공 신경망(120, 220)의 평가 대상이 될 수 있다. 따라서 본 발명의 제2 인공 신경망(120, 22 0)은 다양한 Task에 대한 혼합된 학습을 수행할 수 있으며, 문맥 정보를 추출하여 어떤 Task인 지(예를 들어 분 할, 진단, 또는 측정)를 제2 인공 신경망(120, 220)이 스스로 파악한 후 각 분류에 맞는 평가를 수행할 수 있다. 도 3은 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 과정을 도시하는 도면이다. 제1 인공 신경망은 입력 영상에 대한 추론을 실행하여 분석 결과(312a, 312b)를 출력할 수 있다. 프로세서 (도 3에서는 도시되지 않음)는 분석 결과(312a, 312b)를 제2 인공 신경망에 입력할 수 있다. 이때 제2 인 공 신경망은 제1 인공 신경망과 독립적으로 구성되며, 분석 결과(312a, 312b)에 대한 평가 결과 (350a, 350b)를 도출할 수 있다. 분석 결과(312a)에 대한 평가 결과(350a)는 분석 결과(312a)를 인간 전문가라 면 Accept할 것인지, Reject할 것이지를 예측하여 추론된 결과로 도출된다. 마찬가지로 분석 결과(312b)에 대한 평가 결과(350b)는 분석 결과(312b)를 인간 전문가라면 Accept할 것인지, Reject할 것이지를 예측하여 추론된 결과로 도출된다. 분석 결과(312a, 312b)는 제1 인공 신경망에 의한 폐의 기도 분할 결과일 수 있다. 도 3 에 도시된 것처럼 본 발명의 제2 인공 신경망은 의료 영상에 제1 인공 신경망을 적용하여 얻어지는 분석 결과, 즉, 영상 분할, 영상 내 병변 검출, 검출된 병변에 대한 임상적 진단, 및 영상 분할된 관심 영역에 대한 측정 중 적어도 하나 이상에 대하여 인간 전문가인 사용자의 평가 결과를 미리 학습하고, 새로운 입력이 주어졌을 때 인간 전문가인 사용자의 평가 결과를 예측하여 추론할 수 있다. 이때 프로세서는 제2 인공 신경망에 의하여 Reject 된 분석 결과는 수동으로 결과를 다시 얻을 것을 권장 하는 메뉴를 사용자에게 제공할 수 있다. 도 3에서 평가 결과(350a, 350b)는 Accept 또는 Reject 로 표시된 실시예가 도시되었으나, 이는 학습에 이용되 는 평가 결과의 형식에 따른 것이고, 학습에 이용되는 전문가의 평가 결과가 점수(score)를 부여하는 방식이면 제2 인공 신경망의 평가 결과 또한 점수로서 제공될 수 있다. 도 4는 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 과정을 도시하는 도면이다. 도 4를 참조하면, 원본 의료 영상(440a, 440b)이 제1 인공 신경망에 입력되어 원본 의료 영상(440a, 440 b)으로부터 분할된 기도 벽 영상을 분석 결과(412a, 412b)로서 얻을 수 있다. 프로세서는 분할된 기도 벽 영상인 분석 결과(412a, 412b)를 그대로 제2 인공 신경망의 입력으로 제공할 수도 있겠으나, 도 4의 실시 예에서는 원본 의료 영상(440a, 440b)에 분석 결과(412a, 412b)를 오버레이(overlay)하여 인간 전문가인 사용자 가 판단 가능하도록 대표적인 시각화 형태(414a, 414b)로 변환하고, 대표적인 시각화 형태(414a, 414b)를 제2 인공 신경망의 입력으로 제공할 수 있다. 이때 원본 의료 영상(440a, 440b)는 CT 슬라이스 셋이고, 대표적인 시각화 형태(414a, 414b)는 3차원 볼륨 렌더 링 영상 또는 MPR(Multi-Planar Reformation) 영상일 수도 있다. 즉, 반드시 원본 의료 영상(440a, 440b)이 그 대로 분석 결과(412a, 412b)와 결합되는 것은 아니며, 인간 전문가인 사용자가 사용하는 시각화 옵션을 고려하 여 원본 의료 영상(440a, 440b)의 뷰, 뷰의 방향, 줌 등의 디스플레이 옵션 또한 조정된 후 분석 결과(412a, 412b)와 결합되어 대표적인 시각화 형태(414a, 414b)로 표현될 수 있다. 평가 결과(450a, 450b)는 Reject 또는 Accept 의 유사 의사 결정 결과로서 제공될 수도 있으나, 의사 결정 점수 로 제공될 수도 있음은 앞에서 설명한 바와 같다. 도 5는 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 과정을 도시하는 도면이다. 컴퓨팅 시스템이 최종적으로 구하고자 하는 파라미터가 Airway Measurement 이고 하나의 airway branch에 대한 wall thickness를 정량화하고자 하는 경우일 때, 컴퓨팅 시스템은 제1 인공 신경망에서 도출된 airway segmentation 분석 결과를 제2 인공 신경망에 의하여 평가한 후, Accept 판정을 받은 segmentation 결과만을이용하여 wall thickness를 정량화하고, 이와 같은 방법으로 정량화된 airway branch의 대표값으로 설정할 수 있다. 도 5를 참고하면, 분석하고자 하는 대상이 영상에 의하여 도시된다. 제1 인공 신경망은 모든 분석을 스스 로 완결할 수 없을 수도 있다. 도 5의 실시예에서는 영상 내에 도시된 airway branch의 10개의 위치에서 제1 인공 신경망이 airway segmentation 한 결과가 분석 결과로서 제공된다. 도 5에서는 제2 인공 신경망은 10개의 분석 결과 중 5개의 분석 결과(이 경우에는 airway segmentation)를 accept하고 5개를 reject한 실시예가 도시된다. 이때 프로세서는 후속 오퍼레이션으로 accept된 airway segmentation 결과만을 이용하여 branch의 wall thickness의 대표값을 정량화할 수 있다. 정량화된 대표값은 최종적으로 구하고자 하는 파라미터인 Airway Measurement 중 airway branch의 wall thickness 대표값으로 제공될 수 있다. 도 5에서 개시된 본 발명의 일 실시예에 따르면, 컴퓨팅 시스템이 최종적으로 제공하도록 요청된 최종 결과물을 생성하기 위한 중간 결과물을 제1 인공 신경망에 의하여 얻을 수 있을 때, 제2 인공 신경망은 제1 인공 신경망 에서 얻어지는 분석 결과들 중 평가 결과 Accept되거나 평가 점수가 일정 기준치 이상인 경우만을 선별하여 최 종 결과물을 생성하기 위한 중간 결과물로서 지정할 수 있다. 컴퓨팅 시스템과 프로세서는 선택된 중간 결과물 에 대한 후속 오퍼레이션을 수행하여 최종 결과물을 생성하고 사용자의 요청에 응답하여 제공할 수 있다. 도 6은 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 과정 및 의료용 인공 신경망 훈련 과정에 공통되는 인공 신경망의 입력을 생성하는 과정을 도시하는 도면이다. 일반적으로 왼쪽 폐(left lung)는 상측 로브(superior lobe, upper lobe)와 하측 로브(inferior lobe, lower lobe)로 구분되고, 오른쪽 폐(right lung)는 상측 로브와 하측 로브 사이에 가운데 로브(middle lobe)로 구분되는 점이 알려져 있다. 도 6은 제1 인공 신경망에 의하여 오른쪽 폐 영상에 대한 lobe segmentation 이 수행된 결과를 도시하는 도면이 다. 일반적으로 알려진 lobe segmentation 기술은 각 lobe 별로 segmentation 된 결과가 mask 형태로 출력된다. 따 라서 제1 인공 신경망의 분석 결과는 도 6과 같지 않고, 각 lobe의 segmented mask의 형태로 주어진다. 그러나 다수의 인간 전문가인 사용자들은 lobe segmentation 이 정확히 수행되었는지를 확인하기 위하여 lung이 표시된 의료 영상에 각 lobe의 mask를 overlay하여 lobe segmentation 결과의 적합성 여부를 평가할 것이다. 본 발명의 프로세서는 이러한 사용자들의 시각화 옵션을 분석하고 그에 따라 제1 인공 신경망의 분석 결과가 단 독 lobe의 mask들로 주어지는 경우에, 이들 개별 lobe의 mask들을 lung 영상에 overlay하여 도 6과 같은 영상을 생성하고, 도 6과 같은 영상을 제2 인공 신경망의 입력으로 제공할 수 있다. 이때 사용자들이 lobe segmentation 결과를 평가하기 위하여 주로 lung의 sagittal 영상을 이용하는 것이 파악 되었다면, 프로세서는 lung의 sagittal 영상에서 개별 lobe의 mask를 overlay하여 제2 인공 신경망의 입력으로 제공될 영상을 생성할 수 있다. 또한 하나의 lobe segmentation 결과는 3D 공간에 걸쳐 표현되므로, 프로세서는 사용자들의 lobe segmentation 결과를 평가하는 시각화 옵션을 추적한 결과 하나의 sagittal 영상이 아니라 복수의 sagittal 영상이 더 빈번하 게 이용된다고 판단되면, 제1 인공 신경망의 분석 결과인 개별 lobe의 mask를 복수의 sagittal 영상에 각각 overlay하여 복수의 입력 영상을 생성하고, 복수의 입력 영상을 제2 인공 신경망에 입력으로 제공할 수 있다. 도 6을 참조하면 상위 로브와 가운데 로브는 화살표의 첨단이 가리키는 포인트에서 오버랩되는 상태임이 발견된다. 또한 가운데 로브와 하위 로브는 화살표의 첨단이 가리키는 포인트에서 오 버랩되는 상태임이 발견된다. 이러한 개별 lobe의 mask 끼리 오버랩되는 것은 엄밀히 말하면 틀린 것이지만, 임 상적으로 큰 오류가 없는 오버랩이라면 전문가에 의하여 accept 될 수 있다. 이러한 전문가의 accept 여부 또는 평가 점수를 제2 인공 신경망의 입력으로 제공하여 제2 인공 신경망이 훈련 하고, 전문가의 평가 결과를 모방할 수 있도록 제2 인공 신경망이 학습한다. 제1 인공 신경망에 의하여 새로운 lobe segmentation 결과가 제공된 경우, 프로세서는 도 6과 같은 하나 이상의 overlay된 영상을 생성하여 제2 인공 신경망의 입력으로 제공하고, 제2 인공 신경망이 제1 인공 신경망의 새로 운 lobe segmentation 결과에 대한 평가 결과를 도출하도록 제2 인공 신경망을 제어할 수 있다.도 7은 본 발명의 일 실시예에 따른 인공 신경망의 입력을 생성하는 과정을 도시하는 도면이다. 개별 lobe의 mask 끼리 overlap되는 지 여부는 sagittal 영상에서 효과적으로 인지될 수 있지만, 개별 lobe의 mask 중 어느 mask도 cover하지 못하는 영역이 있는 지 등은 3D 볼륨 렌더링 영상에서 더욱 효과적으로 인지될 수도 있다. 도 7에서는 오른쪽 폐의 3D 볼륨 렌더링 영상에 개별 lobe의 mask가 overlay된 제1 영상, 제2 영상 이 도시되고, 왼쪽 폐의 3D 볼륨 렌더링 영상에 개별 lobe의 mask가 overlay된 제3 영상, 제4 영상 이 도시된다. 제1 영상, 제2 영상은 동일한 오른쪽 폐의 3D 볼륨 렌더링의 결과물 및 overlay 결과물을 서로 다른 뷰포인트에서 바라본 영상이며, 제3 영상, 제4 영상은 동일한 왼쪽 폐의 3D 볼륨 렌더링의 결과물 및 overlay 결과물을 서로 다른 뷰포인트에서 바라본 영상이다. 도 8은 본 발명의 일 실시예에 따른 인공 신경망의 입력을 생성하는 과정을 도시하는 도면이다. 도 8(a)(b)(c)에서는 제1 인공 신경망이 출력한 airway segmentation 의 결과물을 서로 다른 뷰포인트에서 바라 본 3D 볼륨 렌더링 영상으로 표현하는 도면이 도시된다. 도 8(a)(b)(c)는 각각 서로 다른 뷰포인트에서 바라본 영상이다. Airway segmentation 결과물을 평가하기 위한 시각화 옵션으로는 airway mask가 overlay된 MPR 영상도 널리 이 용되나, airway가 워낙 가늘어 정확한 분할 여부가 식별되기 어려우면 도 8과 같이 airway가 segmented된 부분 을 나타내는 3D 볼륨 렌더링 영상이 제2 인공 신경망의 입력으로 제공될 수 있다. 본 발명의 실시예에 따라서는 프로세서는 도 8과 같은 복수개의 뷰포인트에서 바라본 3D 볼륨 렌더링 영상과 개 별 lobe의 mask들을 하나의 MPR 영상 위에 overlay하여 얻어지는 MPR 영상(도시되지 않음)을 함께 제2 인공 신 경망의 입력으로 제공하여 제1 인공 신경망의 airway segmentation 결과에 대한 평가를 출력하도록 제2 인공 신 경망을 제어할 수 있다. 도 9는 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 장치(시스템)에 의하여 실행되는 인공 신 경망 기반 의료 영상 분석 방법을 도시하는 동작 흐름도이다. 도 1과 도 9를 함께 참조하면, 본 발명의 일 실시예에 따른 컴퓨팅 시스템에서 실행되는 인공 신경망 기반 의료 영상 분석 방법은 제1 의료 영상에 대한 제1 인공 신경망의 추론에 의하여 얻어지는 제1 분석 결과를 획득하거나 수신하는 단계(S910); 상기 제1 분석 결과를 제2 인공 신경망에 입력하는 단 계(S920); 상기 제1 분석 결과에 대한 상기 제2 인공 신경망의 추론에 의하여 얻어지는 제1 평가 결 과를 획득하는 단계(S930); 및 상기 제1 평가 결과를 상기 제1 의료 영상 및 상기 제1 분석 결 과에 대한 평가 결과로서 사용자에게 제공하는 단계(S940)를 포함한다. 이때 본 발명의 방법은 상기 제1 평가 결과에 기반하여 상기 제1 분석 결과에 대한 수용 여부를 상기 사용자에게 제안하는 단계를 더 포함할 수 있다. 한편 상기 제2 인공 신경망의 추론에 의하여 얻어지는 상기 제1 평가 결과를 획득하는 단계(S930)는 상기 제2 인공 신경망이 상기 제1 분석 결과에 대한 문맥 정보를 추출하는 단계; 및 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 제1 분석 결과를 평가하는 상기 제1 평가 결과를 추 론에 의하여 출력하는 단계를 포함할 수 있다. 본 발명의 실시예에 따른 방법은 상기 제1 분석 결과를 미리 정해진 규칙에 의하여 대표적인 시각화 형태 로 시각화하는 단계; 및 상기 대표적인 시각화 형태로 시각화된 상기 제1 분석 결과를 상기 제2 인공 신경 망의 입력으로 제공하는 단계를 더 포함할 수 있다. 한편 상기 제1 분석 결과를 상기 제2 인공 신경망에 입력하는 단계(S920)는 상기 제1 의료 영상 및 상기 제1 분석 결과를 함께 상기 제2 인공 신경망에 입력하고, 상기 제2 인공 신경망의 추론에 의하여 얻어지는 상기 제1 평가 결과를 획득하는 단계(S930)는 상기 제2 인공 신경망이 상기 제1 의료 영상에 대한 문맥 정보를 추출하는 단계; 및 상기 제2 인공 신경망이 상기 문맥 정보에 기 반하여 상기 제1 의료 영상에 대한 상기 제1 분석 결과를 평가하는 상기 제1 평가 결과를 추론 에 의하여 출력하는 단계를 포함할 수 있다. 또한 본 발명의 실시예에 따른 방법은 상기 제1 평가 결과를 출력하는 상기 제2 인공 신경망의 내부 파라미터에 기반한 히트맵 정보를 상기 제1 의료 영상 또는 상기 제1 분석 결과에 오버레이하여 표시 하고, 상기 히트맵 정보를 상기 제2 인공 신경망이 상기 제1 평가 결과를 출력하는 과정에 대한 설명 적 정보(descriptive information)로서 상기 사용자에게 제공하는 단계를 더 포함할 수 있다. 도 10은 본 발명의 일 실시예에 따른 의료용 인공 신경망의 훈련 장치(시스템)에 의하여 실행되는 의료용 인공 신경망의 훈련 방법을 도시하는 동작 흐름도이다. 도 10을 참조하면, 본 발명의 일 실시예에 따른 컴퓨팅 시스템에서 실행되는 의료용 인공 신경망의 훈련 방법은 복수의 제2 의료 영상들에 대한 제1 인공 신경망의 추론에 의하여 생성되는 복수의 제2 분석 결과들을 획득하거나 수신하는 단계(S1010); 상기 복수의 제2 분석 결과들 각각에 대한 전문가의 평 가를 포함한 사용자 입력을 획득하는 단계(S1020); 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가를 제2 인공 신경망에 입력하는 단계(S1030); 및 상기 제2 인공 신경망이 상기 복수의 제2 분석 결과들 각각이 타당한지를 평가하는 기능을 학습하도 록 상기 제2 인공 신경망을 훈련하는 단계(S1040)를 포함한다. 이때 상기 제2 인공 신경망을 훈련하는 단계(S1040)는 상기 제2 인공 신경망이 상기 복수의 제2 분석 결과들 각각에 대한 문맥 정보를 추출하는 단계; 및 상기 제2 인공 신경망이 상기 문맥 정보에 기반 하여 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가 간의 관련성을 학습하도록 상기 제2 인공 신경망을 훈련하는 단계를 포함할 수 있다. 상기 복수의 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가(21 6)를 제2 인공 신경망에 입력하는 단계(S1030)는 상기 복수의 제2 의료 영상들, 상기 제2 분석 결과 들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가를 함께 상기 제2 인공 신 경망에 입력하고, 상기 제2 인공 신경망을 훈련하는 단계(S1040)는 상기 제2 인공 신경망이 상기 복수의 제2 의료 영상 들 각각에 대한 문맥 정보를 추출하는 단계; 및 상기 제2 인공 신경망이 상기 문맥 정보에 기반하여 상기 복수의 제2 의료 영상들 각각에 대한 상기 제2 분석 결과들 및 상기 복수의 제2 분석 결과들 각각에 대한 상기 전문가의 평가 간의 관련성을 학습하도록 상기 제2 인공 신경망을 훈련하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 방법은 상기 복수의 제2 분석 결과들 각각에 대한 학습을 위한 훈련 과정에서, 상기 제2 인공 신경망의 내부 파라미터에 기반한 히트맵 정보를 생성하는 단계; 및 상기 히트맵 정보를 상기 복수의 제2 의료 영상들 각각 또는 상기 복수의 제2 분석 결과들 각각에 오버레이하여 표시하고, 상기 히트맵 정보를 상기 제2 인공 신경망의 훈련 과정에 대한 설명적 정보(descriptive information)로서 사용자에게 제공하는 단계를 더 포함할 수 있다. 본 발명의 일 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되 어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이 터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하 여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같 은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함 한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 그러나, 본 발명이 실시예들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 본 발명의 실시예와 도면에 소개된 길이, 높이, 크기, 폭 등은 이해를 돕기 위해 과장 된 것일 수 있다. 이상과 같이 본 발명에서는 구체적인 구성 요소 등과 같은 특정 사항들과 한정된 실시예 및 도면에 의해 설명되 었으나 이는 본 발명의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 발명은 상기의 실시예에 한정되 는 것은 아니며, 본 발명이 속하는 분야에서 통상적인 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및변형이 가능하다. 따라서, 본 발명의 사상은 설명된 실시예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등하거나 등가적 변형이 있는 모든 것들은 본 발명 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2019-0091525", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 장치를 도시하는 도면이다. 도 2는 본 발명의 일 실시예에 따른 의료용 인공 신경망의 훈련 장치를 도시하는 도면이다. 도 3은 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 과정을 도시하는 도면이다. 도 4는 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 과정을 도시하는 도면이다. 도 5는 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 과정을 도시하는 도면이다. 도 6은 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 과정 및 의료용 인공 신경망 훈련 과정에 공통되는 인공 신경망의 입력을 생성하는 과정을 도시하는 도면이다. 도 7은 본 발명의 일 실시예에 따른 인공 신경망의 입력을 생성하는 과정을 도시하는 도면이다. 도 8은 본 발명의 일 실시예에 따른 인공 신경망의 입력을 생성하는 과정을 도시하는 도면이다. 도 9는 본 발명의 일 실시예에 따른 인공 신경망 기반 의료 영상 분석 장치(시스템)에 의하여 실행되는 인공 신 경망 기반 의료 영상 분석 방법을 도시하는 동작 흐름도이다. 도 10은 본 발명의 일 실시예에 따른 의료용 인공 신경망의 훈련 장치(시스템)에 의하여 실행되는 의료용 인공 신경망의 훈련 방법을 도시하는 동작 흐름도이다."}
