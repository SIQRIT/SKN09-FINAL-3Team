{"patent_id": "10-2021-0005479", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0102940", "출원번호": "10-2021-0005479", "발명의 명칭": "사운드 기반 다중 기기 운영 모니터링 방법과 이를 위한 시스템", "출원인": "서울대학교산학협력단", "발명자": "안성훈"}}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "작동 중인 타겟 장비에서 생겨난 사운드를 마이크부를 통해 수집하여 디지털 사운드 데이터로 변환하는 단계;변환된 디지털 사운드 데이터를 상기 타겟 장비의 동작 상태에 관한 모니터링을 위한 모니터링 데이터와 그 모니터링에 이용되는 인공신경망의 훈련을 위한 학습데이터로 제공하는 단계; 상기 학습 데이터를 상기 타겟 장비의 동작 상태 예측을 위한 훈련용 학습 데이터로 이용하여 훈련된 인공신경망 모델을 구축하는 단계; 그리고상기 모니터링 데이터를 상기 인공신경망 모델에 입력하여 상기 타겟 장비의 동작 상태를 예측하는 단계를 포함하는 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링 방법."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제공하는 단계는 상기 학습 데이터의 경우 상기 사운드 데이터 저장부에 저장된 상기 사운드 데이터 파일을 소정 크기 단위로 트리밍(trimming)하여 다수의 단위 사운드 파일 형태로 제공하고, 상기모니터링 데이터의 경우 상기 사운드 데이터 저장부에 저장된 상기 사운드 데이터 파일을 데이터 길이에 대한별도의 가공 없이 그대로 제공하는 단계를 포함하는 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링방법."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 인공신경망 모델을 구축하는 단계는 상기 학습 데이터를 분류 및 레이블링 처리를 하여재가공하는 단계; 및 재가공된 학습데이터로 상기 타겟 장비에서 방출되는 사운드와 상기 타겟 장비의 동작 상태 간의 관계에 대하여 훈련을 수행하여 상기 타겟 장비의 동작상태 예측모델을 생성하는 단계를 포함하는 것을특징으로 하는 사운드 기반 다중 기기 운영 모니터링 방법."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 타겟 장비가 복수 개인 경우, 상기 변환하는 단계는 복수 개의 마이크를 이용하여 복수 개의 타겟 장비 각각의 사운드를 별도로 입력받아 사운드신호를 출력하는 단계; 및 상기 복수 개의 마이크에 대응하는 복수의 사운드 신호를 각각 별도로 처리하여복수의 사운드 데이터 파일로 저장하는 단계를 포함하고,상기 제공하는 단계는 상기 복수 개의 타겟 장비의 상기 학습데이터와 상기 모니터링 데이터를 각 타겟 장비별학습 데이터와 모니터링 데이터를 구별되게 제공하는 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링방법."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 인공신경망 모델을 구축하는 단계는 각 타겟 장비별 학습 데이터를 분류 및 레이블링 처리를 하여 상기 복수의 타겟 장비 각각에 대응되는 복수의 학습데이터 세트를 생성하는 단계; 및 생성된 상기복수의 학습데이터 세트를 각각 별도로 학습하여 각 타겟 장비에 대응하는 훈련된 인공신경망 모델을 생성하는단계를 포함하는 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링 방법."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 각 타겟 장비에 대응하는 각 인공신경망 모델은 해당 타겟 장비의 작동상태만 분류하고 나머지모든 타겟 장비들의 사운드는 소음으로 간주함으로써, 복수의 타겟 장비들 각각의 상태를 복수의 인공신경망 모델에 기반하여 동시병행적으로 분석하여 예측할 수 있도록 구성된 것을 특징으로 하는 사운드 기반 다중 기기운영 모니터링 방법.공개특허 10-2022-0102940-3-청구항 7 제5항에 있어서, 각 타겟 장비별 학습 데이터 세트는 해당 타겟 장비의 학습데이터에 대한 레이블을 지정하는작업, 데이터 증가 및 배경 소음 추가 처리를 하는 작업, 그리고 시간-신호세기의 1차원 데이터에서 시간/주파수-신호세기의 2차원 데이터로 변환하는 작업을 통해 생성되는 것을 특징으로 하는 사운드 기반 다중 기기 운영모니터링 방법."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "작동 중인 타겟 장비에서 생겨난 사운드를 수집하고 디지털 사운드 데이터로 변환하여 상기 타겟 장비의 동작상태에 관한 모니터링을 위한 모니터링 데이터와 그 모니터링에 이용되는 인공신경망의 훈련을 위한 학습데이터로 제공하도록 구성된 사운드신호 수집장치; 및상기 사운드신호 수집장치로부터 제공받은 상기 학습 데이터를 상기 타겟 장비의 동작 상태 예측을 위한 훈련용학습 데이터로 이용하여 훈련된 인공신경망 모델을 구축하고, 상기 사운드신호 수집장치로부터 제공받은 상기모니터링 데이터를 상기 인공신경망 모델에 기반하여 분석하여 상기 타겟 장비의 동작 상태를 예측하도록 구성된 신호분석장치를 구비하는 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 사운드신호 수집장치는, 상기 타겟 장비에서 방출되는 사운드를 입력받아 사운드신호로출력하도록 구성된 마이크부; 상기 마이크부에서 출력되는 아날로그 사운드신호를 디지털화 하여 소정 포맷의원시 사운드 데이터로 변환하도록 구성된 사운드신호 처리부; 상기 사운드신호 처리부로부터 제공되는 상기 원시 사운드 데이터를 사운드 데이터 파일로 저장하도록 구성된 사운드 데이터 저장부; 그리고 상기 사운드 데이터 저장부에 저장된 원시 사운드 데이터를 인공신경망 훈련용 학습 데이터로서 그리고 상기 타겟 장비의 동작상태를 예측하기 위한 모니터링 데이터로서 각각 별도로 상기 신호 분석장치에 제공하도록 구성된 사운드 데이터제공부를 구비하는 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 사운드 데이터 제공부는 상기 학습 데이터의 경우 상기 사운드 데이터 저장부에 저장된상기 사운드 데이터 파일을 소정 크기 단위로 트리밍(trimming)하여 다수의 단위 사운드 파일 형태로 제공하고,상기 모니터링 데이터의 경우 상기 사운드 데이터 저장부에 저장된 상기 사운드 데이터 파일을 데이터 길이에대한 별도의 가공 없이 그대로 제공하는 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 학습 데이터와 상기 모니터링 데이터는 wav 파일 형식으로 구성되는 것을 특징으로 하는사운드 기반 다중 기기 운영 모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 타겟 장비가 복수 개인 경우, 상기 사운드신호 수집장치에서는, 상기 마이크부가 복수 개의 마이크를 이용하여 복수 개의 타겟 장비 각각의 사운드를 별도로 입력받아 사운드신호를 출력하고, 상기 사운드신호 처리부 및 상기 사운드 데이터 저장부가 상기 복수 개의 마이크에 대응하는 복수의 사운드 신호를 각각 별도로 처리하여 복수의 사운드 데이터 파일로 저장하고, 상기 사운드 데이터 제공부가 상기 복수 개의 타겟장비의 상기 학습데이터와 상기 모니터링 데이터를 상기 신호분석장치로 제공할 때 각 타겟 장비별 학습 데이터와 모니터링 데이터를 구별되게 제공하는 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 신호분석장치는, 상기 사운드 데이터 제공부로부터 제공받은 각 타겟 장비별 학습 데이터를 가공하여 상기 복수의 타겟 장비 각각에 대응되는 복수의 학습데이터 세트를 생성하고, 생성된 상기 복수의 학습데이터 세트를 각각 별도로 학습하여 각 타겟 장비에 대응하는 훈련된 인공신경망 모델을 구축하도록 구성된 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2022-0102940-4-제8항에 있어서, 상기 신호 분석장치는, 상기 사운드신호 수집장치로부터 제공된 상기 학습 데이터를 분류 및레이블링 처리를 하여 재가공하도록 구성된 학습데이터 가공부; 상기 학습데이터 가공부에 의해 재가공된 학습데이터로 상기 타겟 장비에서 방출되는 사운드와 상기 타겟 장비의 동작 상태 간의 관계에 대하여 훈련을 수행하여 상기 타겟 장비의 동작상태 예측모델을 생성하도록 구성된 인공신경망 훈련부; 그리고 상기 사운드신호 수집장치로부터 제공되는 상기 모니터링 데이터를 소정 크기 단위로 트리밍(trimming)하여 상기 동작상태 예측모델에 순차적으로 입력하여 상기 타겟 장비의 동작상태를 예측하도록 구성된 동작상태 예측부를 구비하는 것을특징으로 하는 사운드 기반 다중 기기 운영 모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 타겟 장비가 복수 개인 경우, 상기 사운드신호 수집장치에서는, 상기 마이크부가 복수개의 마이크를 이용하여 복수 개의 타겟 장비 각각의 사운드를 별도로 입력받아 사운드신호를 출력하고, 상기사운드신호 처리부 및 상기 사운드 데이터 저장부가 상기 복수 개의 마이크에 대응하는 복수의 사운드 신호를각각 별도로 처리하여 복수의 사운드 데이터 파일로 저장하고, 상기 사운드 데이터 제공부가 상기 복수 개의 타겟 장비의 상기 학습데이터와 상기 모니터링 데이터를 상기 신호분석장치로 제공할 때 각 타겟 장비별 학습 데이터와 모니터링 데이터를 구별되게 제공하는 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 학습데이터 가공부는 상기 사운드 데이터 제공부로부터 제공받은 각 타겟 장비별 학습데이터를 가공하여 상기 복수의 타겟 장비 각각에 대응되는 복수의 학습데이터 세트를 생성하고, 상기 인공신경망 훈련부는 상기 복수의 학습데이터 세트를 각각 별도로 학습하여 각 타겟 장비마다 별도의 훈련된 인공신경망모델을 구축하도록 구성된 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 각 타겟 장비에 대응하는 각 인공신경망 모델은 해당 타겟 장비의 작동상태만 분류하고 나머지 모든 타겟 장비들의 사운드는 소음으로 간주함으로써, 상기 동작 상태 예측부는 복수의 타겟 장비들에 각각의 상태를 복수의 인공신경망 모델에 기반하여 동시병행적으로 분석하여 예측할 수 있도록 구성된 것을 특징으로 하는 사운드 기반 다중 기기 운영 모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서, 각 타겟 장비별 학습 데이터 세트는 해당 타겟 장비의 학습데이터에 대한 레이블을 지정하는작업, 데이터 증가 및 배경 소음 추가 처리를 하는 작업, 그리고 시간-신호세기의 1차원 데이터에서 시간/주파수-신호세기의 2차원 데이터로 변환하는 작업을 통해 생성되는 것을 특징으로 하는 사운드 기반 다중 기기 운영모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 1차원 데이터를 상기 2차원 데이터로 변환하는 처리는 STFT(Short-Time FourierTransform), 또는 로그-멜 스펙트로그램을 이용하여 수행되는 것을 특징으로 하는 사운드 기반 다중 기기 운영모니터링 시스템."}
{"patent_id": "10-2021-0005479", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사운드 기반 다중 기기 운영 모니터링 방법과 이를 위한 시스템이 개시된다. 작동 중인 타겟 장비에서 생겨난 사 운드를 마이크부를 통해 수집하여 디지털 사운드 데이터로 변환하고, 타겟 장비의 동작 상태에 관한 모니터링을 위한 모니터링 데이터와 그 모니터링에 이용되는 인공신경망의 훈련을 위한 학습데이터로 제공한다. 그 학습 데 이터를 타겟 장비의 동작 상태 예측을 위한 훈련용 학습 데이터로 이용하여 훈련된 인공신경망 모델을 구축한다. 모니터링 데이터를 인공신경망 모델에 입력하여 타겟 장비의 동작 상태를 예측한다. 이 때, 타겟 장비가 복수 개 인 경우, 각 타겟 장비별로 별도의 인공신경망 모델을 구축한다. 각 인공신경망 모델은 해당 타겟 장비의 작동상 태만 분류하고 나머지 모든 타겟 장비들의 사운드는 소음으로 간주함으로써, 복수의 타겟 장비들 각각의 상태를 복수의 인공신경망 모델에 기반하여 동시병행적으로 분석하여 예측할 수 있다."}
{"patent_id": "10-2021-0005479", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 작동 중인 기계 장비들의 상태를 모니터링하는 기술에 관한 것으로, 보다 상세하게는 다수의 기계 장 비들의 동작 사운드를 이용하여 기계 장비들의 동작 상태를 실시간으로 모니터링 하는 기술에 관한 것이다."}
{"patent_id": "10-2021-0005479", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "4 차 산업 혁명의 여파로 많은 국가, 대학, 기관 및 기업이 관련 기술을 개발하기 위해 노력하고 있다. 이 산업 혁명의 가장 일반적으로 인정되는 측면은 정보 통신 기술 (ICT)의 발전이다. 빠른 응답과 넓은 대역폭을 가능하 게 하는 5G 통신의 개선과 모든 기기에 통신 기능을 탑재 할 수 있는 사물 인터넷 (IoT)은 빠르고 광범위한 정보 수집을 가능하게 한다. 클라우드 컴퓨팅과 빅데이터 관리 기술을 통해 정보를 저장할 수 있다. 컴퓨팅 성능 이 크게 향상되면서 머신 러닝과 같은 효율적인 데이터 분석 기술을 통해 고성능 인공 지능 (AI)이 탄생했다. 스마트 팩토리는 4 차 산업 혁명에 대한 제조 공정 분야의 주요 키워드이다. 스마트 팩토리는 클라우드 기반의 중앙집중식 시스템에 연결된 장치와 인터넷과 클라우드를 통한 대화형 정보 교환 기능을 갖춘 제조 시스템으로 정의할 수 있다. 이 중앙집중식 시스템을 통해 더 높은 수준의 모니터링, 분석, 제어 및 설계가 가능하므로 스 마트 팩토리는 제조의 미래로 관심을 끌고 있다. 가상 물리 시스템 (Cyber-Physical System: CPS)는 수집된 정보를 기반으로 제조 프로세스를 시뮬레이션할 수 있는 가상 시스템이다. 현재 가상 공간에서 장치를 사용한 실험은 개별 장치 수준을 넘어 공장에서 발생하는 일 을 미리 테스트하고 전체 공장의 성능을 시뮬레이션할 수 있다. 이러한 CPS는 공장 설계에 적용되고 있으며 실 제 공장의 성능을 향상시키기 시작했다. 스마트 팩토리와 CPS 구현의 가장 중요한 부분은 모든 기기를 IoT 기반의 시스템에 연결되는 스마트 기기로 만 드는 것이다. 각 장치의 상태는 실시간으로 공유되고 클라우드에 수집되어 이전보다 더 나은 장치 식별 및 제어 가 가능하다. 따라서 각 장치에 대한 자세한 정보를 수집할 수 있어야 한다. 요즘 새로 개발되는 장치는 일반적으로 IoT 기반 기능을 탑재하여 스마트 장치가 된다. 그러나 오래 전에 생산 된 장치에는 일반적으로 다른 장치 또는 시스템에 대한 연결 수단이 없다. 이러한 장치를 쉽고 저렴한 비용으로 스마트 장치로 전환하는 기술이 필요하다. 이는 새로운 플랜트를 설계 및 건설하고 새로운 장치를 획득할 수 있 는 대기업보다 기존 장치에 더 많이 의존할 가능성이 있는 소규모 회사의 공장에 더 시급하다. 소규모 기업은 자본이 부족하고 공장 전체를 리노베이션 할 수 없기 때문에 대대적인 변화를 도입하기가 어렵고 다른 곳의 변 화 속도에 맞출 수 없다는 현실에 직면하게 된다. 이러한 사정이 고려되어, 시각 / 음향 / 열 / 전력 소모와 같은 다양한 방법을 사용하여 장치의 상태를 원격으 로 모니터링하는 기술이 개발되고 있다. 시각적 방법은 일반적으로 장치의 작동을 관찰하고 비정상 상태를 식별하는 데 사용된다. 이러한 방법의 분석은 최근 합성공 신경망 (Convolutional Neural Network: CNN)과 같은 인공 지능 (AI)을 사용하여 향상되었다. 장 치에 설치된 디스플레이 패널에서 정보를 읽거나 전체 제조 공정 시스템의 정보 맵을 시각적으로 인식하고 분석 하려는 시도가 있었다. 열은 수많은 장치 및 공장의 상태를 이해하는 데 사용되는 가장 기본적인 정보이며, 난방 및 냉방 제어는 장치 관리의 기본 프로세스이다. 최근에는 실시간 정보 획득이 가능할 정도로 크게 개선된 열 화상 카메라 등 열 분 포 측정 기술을 활용한 다양한 연구가 진행되고 있다. 전력 소비량을 측정하려면 별도의 장치를 설치해야 하지만, 추가 정보 없이 대상 장치에 대한 정보를 추출 할 수 있고 데이터의 신뢰성이 높기 때문에 이 방법에 대한 연구가 진행되고 있다. 마지막으로, 소리는 일반적으로 장치의 상태를 식별하는 데 사용된다. 공구 마모 및 진동과 같은 기계 부품의 문제를 진단하는 데 우수한 성능을 보여주기 때문에 많은 연구가 수행되고 있다. 또한 최근에는 진동을 2 차원 (2D) 데이터로 변환하여 영상 처리에 사용되는 AI 도구로 기계의 상태를 분류하는 데 사용되는 진동 분석이 주 목받고 있다. 소리는 기체, 액체 또는 고체와 같은 매체를 통해 전달되는 진동이다. 사운드의 주목할 만한 특징 중 하나는 다 양한 신호가 같은 공간을 차지하면(coincide) 서로 영향을 주지 않고 겹쳐진다는 것이다. 사운드에는 다양한 정 보가 담겨있을 수 있으며, 다른 요인의 간섭이 있어도 이 정보는 유지된다. 따라서 주변 환경이 통제되지 않은 상태에서도 정보를 얻을 수 있으며 여러 소스에 대한 정보를 동시에 획득 할 수 있다. 소리를 처리하면 많은 데이터가 생성되기 때문에 최근 분석에서는 기존의 분석 방법이 아닌 인공 자연 네트워크 (Artificial Natural Networks: ANN) 또는 지원 벡터 기계 (Support Vector Machines: SVM) 또는 랜덤 포레스 트 (Random Forest: RF)를 사용하고 있다. 1 차원 원시 신호를 통해 사운드를 분석하는 것은 어렵지만, 사운드 를 푸리에 변환을 통해 2차원(2D) 데이터로 변환하고 주파수 별로 정렬하면 더 쉽게 사운드 분석을 수행할 수 있다. 2D 데이터의 경우 다양한 방법으로 신호를 분류하기 위한 연구가 진행되고 있다. 예를 들어 이미지 처리 에 자주 사용되는 CNN을 적용하는 것은 간단하다. 신호 분류에 대한 현재 연구의 전형적인 예는 오류 진단이다. 장치 외부에 마이크 등의 센서를 설치하는 것만으 로 고장 진단이 가능하기 때문에 고장 발생 시 비정상적인 소리를 인식하는 연구가 진행되고 있다. 또한 제조 공정 중 또는 제조 공정 직후에 발생하는 소리를 분류하여 결함을 감지하려는 시도가 많이 있다. 마 찬가지로 누수와 같은 장치의 결함을 감지하려는 시도는 CNN을 통해 음향 방출을 분석하고 있다. 현재의 다른 연구에는 도시의 소음 분류, 구조 상태 모니터링, 인간 활동 분류, 음악 장르 식별이 포함된다. 선행기술문헌"}
{"patent_id": "10-2021-0005479", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "스마트공장은 4차 산업혁명을 주제로 한 제조공정 분야의 주요 키워드다. 스마트 팩토리를 실현하기 위해서는 모든 기기를 중앙집중식 시스템과 연결된 스마트 기기로 만들어 실시간으로 정보를 교환할 수 있도록 하는 것이 필수적이다. 소리는 다양한 장치의 상태 정보를 동시에 담을 수 있고, 마이크만 사용하여 기기 외부에서 쉽게 녹음할 수 있기 때문에 기기를 스마트 기기로 만드는 효율적인 수단이 될 수 있다. 최근 CNN을 이용한 다양한 연구가 진행되고 있으며 다양한 소리를 분석해 좋은 결과를 얻고 있다. 앞에서 언급했듯이 소리를 사용하여 장 치의 상태를 결정하기 위해 여러 가지 연구가 수행되고 있다. 그러나 실시간으로 여러 장치의 상태를 모니터링 하려는 시도는 없었다. 따라서 본 발명은 제조 공정에서 동시에 동작하는 다양한 기계 장비들이 생성하는 사운드를 훈련된 인공신경망 예측 모델에 입력하여 각 기계장비의 상태를 실시간으로 모니터링 모니터링 할 수 있는 사운드 기반 다중 기기 운영 모니터링 방법과 시스템을 제공하는 것을 목적으로 한다. 본 발명이 해결하고자 하는 과제는 상술한 과제들에 한정되는 것이 아니며, 본 발명의 사상 및 영역으로부터 벗 어나지 않는 범위에서 다양하게 확장될 수 있을 것이다."}
{"patent_id": "10-2021-0005479", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 본 발명의 목적을 실현하기 위한 실시예들에 따른 사운드 기반 다중 기기 운영 모니터링 방법은 작동 중인 타겟 장비에서 생겨난 사운드를 마이크부를 통해 수집하여 디지털 사운드 데이터로 변환하는 단계; 변환된 디지 털 사운드 데이터를 상기 타겟 장비의 동작 상태에 관한 모니터링을 위한 모니터링 데이터와 그 모니터링에 이 용되는 인공신경망의 훈련을 위한 학습데이터로 제공하는 단계; 상기 학습 데이터를 상기 타겟 장비의 동작 상 태 예측을 위한 훈련용 학습 데이터로 이용하여 훈련된 인공신경망 모델을 구축하는 단계; 그리고 상기 모니터 링 데이터를 상기 인공신경망 모델에 입력하여 상기 타겟 장비의 동작 상태를 예측하는 단계를 포함한다. 예시적인 실시예들에 있어서, 상기 제공하는 단계는 상기 학습 데이터의 경우 상기 사운드 데이터 저장부에 저 장된 상기 사운드 데이터 파일을 소정 크기 단위로 트리밍(trimming)하여 다수의 단위 사운드 파일 형태로 제공 하고, 상기 모니터링 데이터의 경우 상기 사운드 데이터 저장부에 저장된 상기 사운드 데이터 파일을 데이터 길 이에 대한 별도의 가공 없이 그대로 제공하는 단계를 포함할 수 있다. 예시적인 실시예들에 있어서, 상기 인공신경망 모델을 구축하는 단계는 상기 학습 데이터를 분류 및 레이블링 처리를 하여 재가공하는 단계; 및 재가공된 학습데이터로 상기 타겟 장비에서 방출되는 사운드와 상기 타겟 장 비의 동작 상태 간의 관계에 대하여 훈련을 수행하여 상기 타겟 장비의 동작상태 예측모델을 생성하는 단계를 포함할 수 있다. 예시적인 실시예들에 있어서, 상기 타겟 장비가 복수 개인 경우, 상기 변환하는 단계는 복수 개의 마이크를 이 용하여 복수 개의 타겟 장비 각각의 사운드를 별도로 입력받아 사운드신호를 출력하는 단계; 및 상기 복수 개의 마이크에 대응하는 복수의 사운드 신호를 각각 별도로 처리하여 복수의 사운드 데이터 파일로 저장하는 단계를 포함할 수 있다. 또한, 상기 제공하는 단계는 상기 복수 개의 타겟 장비의 상기 학습데이터와 상기 모니터링 데 이터를 각 타겟 장비별 학습 데이터와 모니터링 데이터를 구별되게 제공할 수 있다. 예시적인 실시예들에 있어서, 상기 인공신경망 모델을 구축하는 단계는 각 타겟 장비별 학습 데이터를 분류 및 레이블링 처리를 하여 상기 복수의 타겟 장비 각각에 대응되는 복수의 학습데이터 세트를 생성하는 단계; 및 생 성된 상기 복수의 학습데이터 세트를 각각 별도로 학습하여 각 타겟 장비에 대응하는 훈련된 인공신경망 모델을 생성하는 단계를 포함할 수 있다.예시적인 실시예들에 있어서, 각 타겟 장비에 대응하는 각 인공신경망 모델은 해당 타겟 장비의 작동상태만 분 류하고 나머지 모든 타겟 장비들의 사운드는 소음으로 간주함으로써, 복수의 타겟 장비들 각각의 상태를 복수의 인공신경망 모델에 기반하여 동시병행적으로 분석하여 예측할 수 있도록 구성될 수 있다. 예시적인 실시예들에 있어서, 각 타겟 장비별 학습 데이터 세트는 해당 타겟 장비의 학습데이터에 대한 레이블 을 지정하는 작업, 데이터 증가 및 배경 소음 추가 처리를 하는 작업, 그리고 시간-신호세기의 1차원 데이터에 서 시간/주파수-신호세기의 2차원 데이터로 변환하는 작업을 통해 생성될 수 있다. 한편, 상기 본 발명의 목적을 실현하기 위한 실시예들에 따른 사운드 기반 다중 기기 운영 모니터링 시스템은 사운드신호 수집장치와 신호분석장치를 포함한다. 상기 사운드신호 수집장치는 작동 중인 타겟 장비에서 생겨난 사운드를 수집하고 디지털 사운드 데이터로 변환하여 상기 타겟 장비의 동작 상태에 관한 모니터링을 위한 모니 터링 데이터와 그 모니터링에 이용되는 인공신경망의 훈련을 위한 학습데이터로 제공하도록 구성된다. 상기 신 호분석장치는 상기 사운드신호 수집장치로부터 제공받은 상기 학습 데이터를 상기 타겟 장비의 동작 상태 예측 을 위한 훈련용 학습 데이터로 이용하여 훈련된 인공신경망 모델을 구축하고, 상기 사운드신호 수집장치로부터 제공받은 상기 모니터링 데이터를 상기 인공신경망 모델에 기반하여 분석하여 상기 타겟 장비의 동작 상태를 예 측하도록 구성된 다. 예시적인 실시예들에 있어서, 상기 사운드신호 수집장치는 마이크부, 사운드신호 처리부, 사운드 데이터 저장부, 그리고 사운드 데이터 제공부를 포함할 수 있다. 상기 마이크부는 상기 타겟 장비에서 방출되는 사운드 를 입력받아 사운드신호로 출력하도록 구성될 수 있다. 상기 사운드신호 처리부는 상기 마이크부에서 출력되는 아날로그 사운드신호를 디지털화 하여 소정 포맷의 원시 사운드 데이터로 변환하도록 구성될 수 있다. 상기 사 운드 데이터 저장부는 상기 사운드신호 처리부로부터 제공되는 상기 원시 사운드 데이터를 사운드 데이터 파일 로 저장하도록 구성될 수 있다. 상기 사운드 데이터 제공부는 상기 사운드 데이터 저장부에 저장된 원시 사운드 데이터를 인공신경망 훈련용 학습 데이터로서 그리고 상기 타겟 장비의 동작상태를 예측하기 위한 모니터링 데 이터로서 각각 별도로 상기 신호 분석장치에 제공하도록 구성될 수 있다. 예시적인 실시예들에 있어서, 상기 사운드 데이터 제공부는 상기 학습 데이터의 경우 상기 사운드 데이터 저장 부에 저장된 상기 사운드 데이터 파일을 소정 크기 단위로 트리밍(trimming)하여 다수의 단위 사운드 파일 형태 로 제공하고, 상기 모니터링 데이터의 경우 상기 사운드 데이터 저장부에 저장된 상기 사운드 데이터 파일을 데 이터 길이에 대한 별도의 가공 없이 그대로 제공할 수 있다. 예시적인 실시예들에 있어서, 상기 타겟 장비가 복수 개인 경우, 상기 사운드신호 수집장치에서는, 상기 마이크 부가 복수 개의 마이크를 이용하여 복수 개의 타겟 장비 각각의 사운드를 별도로 입력받아 사운드신호를 출력하 고, 상기 사운드신호 처리부 및 상기 사운드 데이터 저장부가 상기 복수 개의 마이크에 대응하는 복수의 사운드 신호를 각각 별도로 처리하여 복수의 사운드 데이터 파일로 저장하고, 상기 사운드 데이터 제공부가 상기 복수 개의 타겟 장비의 상기 학습데이터와 상기 모니터링 데이터를 상기 신호분석장치로 제공할 때 각 타겟 장비별 학습 데이터와 모니터링 데이터를 구별되게 제공할 수 있다. 예시적인 실시예들에 있어서, 상기 신호분석장치는, 상기 사운드 데이터 제공부로부터 제공받은 각 타겟 장비별 학습 데이터를 가공하여 상기 복수의 타겟 장비 각각에 대응되는 복수의 학습데이터 세트를 생성하고, 생성된 상기 복수의 학습데이터 세트를 각각 별도로 학습하여 각 타겟 장비에 대응하는 훈련된 인공신경망 모델을 구축 하도록 구성될 수 있다. 예시적인 실시예들에 있어서, 상기 신호 분석장치는 학습데이터 가공부, 인공신경망 훈련부, 그리고 동작상태 예측부를 포함할 수 있다. 상기 학습데이터 가공부는 상기 사운드신호 수집장치로부터 제공된 상기 학습 데이터 를 분류 및 레이블링 처리를 하여 재가공하도록 구성될 수 있다. 상기 인공신경망 훈련부는 상기 학습데이터 가 공부에 의해 재가공된 학습데이터로 상기 타겟 장비에서 방출되는 사운드와 상기 타겟 장비의 동작 상태 간의 관계에 대하여 훈련을 수행하여 상기 타겟 장비의 동작상태 예측모델을 생성하도록 구성될 수 있다. 상기 동작 상태 예측부는 상기 사운드신호 수집장치로부터 제공되는 상기 모니터링 데이터를 소정 크기 단위로 트리밍 (trimming)하여 상기 동작상태 예측모델에 순차적으로 입력하여 상기 타겟 장비의 동작상태를 예측하도록 구성 될 수 있다. 예시적인 실시예들에 있어서, 상기 타겟 장비가 복수 개인 경우, 상기 사운드신호 수집장치에서는, 상기 마이크 부가 복수 개의 마이크를 이용하여 복수 개의 타겟 장비 각각의 사운드를 별도로 입력받아 사운드신호를 출력하 고, 상기 사운드신호 처리부 및 상기 사운드 데이터 저장부가 상기 복수 개의 마이크에 대응하는 복수의 사운드신호를 각각 별도로 처리하여 복수의 사운드 데이터 파일로 저장하고, 상기 사운드 데이터 제공부가 상기 복수 개의 타겟 장비의 상기 학습데이터와 상기 모니터링 데이터를 상기 신호분석장치로 제공할 때 각 타겟 장비별 학습 데이터와 모니터링 데이터를 구별되게 제공할 수 있다. 예시적인 실시예들에 있어서, 상기 학습데이터 가공부는 상기 사운드 데이터 제공부로부터 제공받은 각 타겟 장 비별 학습 데이터를 가공하여 상기 복수의 타겟 장비 각각에 대응되는 복수의 학습데이터 세트를 생성하고, 상 기 인공신경망 훈련부는 상기 복수의 학습데이터 세트를 각각 별도로 학습하여 각 타겟 장비마다 별도의 훈련된 인공신경망 모델을 구축하도록 구성될 수 있다. 예시적인 실시예들에 있어서, 각 타겟 장비에 대응하는 각 인공신경망 모델은 해당 타겟 장비의 작동상태만 분 류하고 나머지 모든 타겟 장비들의 사운드는 소음으로 간주함으로써, 상기 동작 상태 예측부는 복수의 타겟 장 비들에 각각의 상태를 복수의 인공신경망 모델에 기반하여 동시병행적으로 분석하여 예측할 수 있도록 구성될 수 있다. 예시적인 실시예들에 있어서, 각 타겟 장비별 학습 데이터 세트는 해당 타겟 장비의 학습데이터에 대한 레이블 을 지정하는 작업, 데이터 증가 및 배경 소음 추가 처리를 하는 작업, 그리고 시간-신호세기의 1차원 데이터에 서 시간/주파수-신호세기의 2차원 데이터로 변환하는 작업을 통해 생성될 수 있다. 예시적인 실시예들에 있어서, 상기 1차원 데이터를 상기 2차원 데이터로 변환하는 처리는 STFT(Short-Time Fourier Transform), 또는 로그-멜 스펙트로그램을 이용하여 수행될 수 있다."}
{"patent_id": "10-2021-0005479", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 예시적인 실시예들에 따르면, 공장에서 운용되는 장비들 각각에 대하여 각 장비의 동작 중에 발생하 는 소리를 획득하여 학습용 사운드 데이터로 가공하고, 장비의 동작 상태와 소리 간의 관계에 관하여 인공신경 망 기술을 이용하여 그 학습용 사운드 데이터로 훈련함으로써 각 장비의 상태를 예측할 수 있는 예측모델을 구 축할 수 있다. 나아가, 그 장비들의 작동 시 발생하는 소리를 실시간으로 획득하여 기 구축된 인공신경망 예측 모델에 입력 데이터로 제공하여 해당 장비의 동작 상태를 실시간으로 예측할 수 있다. 또한, 본 발명의 예시적인 실시예들에 따르면, 사운드 정보를 이용하므로 다수의 장비들의 동작 상태를 동시병 행적으로 식별할 수 있고, 각 장비의 상태를 예측할 수 있다. 즉, 다수의 장비들이 동시에 동작하는 경우, 각 장비별로 별도의 인공신경망 예측모델을 구축하고, 각 장비의 동작 사운드를 실시간으로 획득하여 해당 인공신 경망 예측모델에 입력함으로써, 다수의 장비들의 동작상태 예측을 동시병행적으로 수행할 수 있다. 실제 실험에 따르면, 로그-멜 스펙트로그램(log-mel spectrogram)과 합성곱 신경망(CNN)으로 녹음된 소리를 분 석해 71~92%의 정확도로 3개 장치의 작동 상태를 탐지할 수 있었다. 성능 향상을 위해 강도가 다른 개별 기기 작동 사운드의 구성을 통해 가상 데이터 세트를 생성하여 학습시킬 수 있다. 이를 통해 정확도를 87%~99%까지 높일 수 있고 필요한 사운드 데이터 양을 줄일 수 있다."}
{"patent_id": "10-2021-0005479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 도면상의 동일 한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. CNN은 LeCun에서 처음 제안한 이미지 처리 방법이다. CNN은 이미지와 다른 형태의 데이터를 처리하는 데 상당한 성공을 거두었다. CNN의 컨벌루션 계층은 많은 수의 필터를 포함하고, 이러한 필터를 통해 입력 데이터의 특성 을 추출한다. 그런 다음 풀링 레이어에서 로컬 특성을 추출한다. 본 발명에서는 원시 데이터를 푸리에 변환으로 처리하여 2D로 만든다. 이것이 CNN의 입력 데이터이다. 컨텍스트 레이어인 또 다른 CNN 레이어도 2D 필터를 사 용한다. 입력 데이터는 예를 들어 빨간색, 녹색 및 파란색 채널로 구성된 이미지와 달리 하나의 오디오 채널에 서 가져온 것이다. 입력 데이터는 컨볼루션 필터를 통해 전달되어 각 데이터의 특성을 추출한다. 2D 컨벌루션 필터는 다음 공식으 로 계산된다. …… 여기서 Yi 와 Yi+1 은 각각 2D 컨볼루션 필터를 통과하기 전과 후의 데이터이다. F는 필터이다. b는 바이어스이 다. M과 N은 2D 컨볼루션 필터의 사이즈를 나타낸다. Yi+1 세트를 특징 맵(feature map)이라고 한다. 특징 맵에서 중요한 로컬 정보를 추출하는 풀링 레이어는 일반적으로 컨볼루션 레이어 다음에 적용된다. 그러나 풀링 레이어를 통과함에 따라 특징 맵의 크기가 줄어든다. 평균 또는 최대 풀링 레이어가 일반적으로 사용된다. 본 발명에서는 후자를 사용한다. 최대 풀링 작업은 특징 맵에서 필터 커널의 최대 크기만 추출한다. 필터 커널 에서 추출한 기하학은 다음과 같이 얻어진다. ……"}
{"patent_id": "10-2021-0005479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "…… 여기서 A는 필터 커널이고, aij는 필터 커널의 요소이다. n은 컨볼루션 필터의 사이즈이다. 컨볼루션 레이어와 풀링 레이어를 번갈아 사용하여 데이터를 분류하기 위해 완전히 연결된 레이어와 소프트맥스(softmax) 분류가 추가될 수 있다. 일반적인 2D CNN 구조는 아래에서 설명한다. 드롭 아웃은 데이터 과적합을 줄일 수 있는 기술이다. 특히 소규모 신경망을 훈련할 때 드롭 아웃은 성능 저하 를 방지하여 이 문제를 해결하는 쉽고 효과적인 방법을 제공한다. 본 발명에서는 동일한 기능을 반복적으로 추 출하여 속이 비어있는 것을 방지하기 위해 훈련 중에 드롭 아웃 기술을 적용한다. 일부 은닉 뉴런은 피드 포워 드 학습(feedforward learning)에 포함되지 않도록 0으로 설정될 수 있다. 소프트맥스(Softmax) 회귀는 일반적으로 다중 상태 분류를 위한 신경망의 최상위 계층으로 구현된다. 다중 은닉 계층에서 파생된 정보는 글로벌 역전파 최적화에 따라 지도된 분류기(supervised classifiers)의 입력으로 사용된다. 예시적인 실시예에서는 소프트맥스 회귀를 네트워크의 기계적 상태 분류기로 사용될 수 있다. 훈련 샘플 은 x(i)로 표시되며 레이블 세트는 y(i)이다. 여기서 i = 1, 2, … , K는 훈련 샘플의 수이다. x(i) ∈ 및 y(i) ∈ {1,2,3,4,…, K} 여기서 K는 레이블이 지정된 범주의 수이다. x(i)의 경우 입력 표본에 대해 소프트맥 스 회귀는 각 레이블 j (j = 1, 2,…, K)에 대한 확률 p(y(i) = j | x(i))를 추정할 수 있다. 각 레이블에 속 하는 x(i)의 추정확률은 가설 함수(hypothesis function)에 따라 구할 수 있다."}
{"patent_id": "10-2021-0005479", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "…… 이 분류기는 네트워크의 출력이 각 클래스의 확률로 해석될 수 있도록 출력이 양수이고 합계가 1인지 확인한다. 심층 신경망은 여러 비선형 변환과 근사적이고 복잡한 비선형 함수를 통해 원시 입력 신호에서 얼굴 표정과 관 련된 정보를 적응적으로 캡처할 수 있다. 이러한 네트워크는 일반적으로 기본 CNN 아키텍처로 사용된다. 이 CNN 아키텍처 기반에 알고리즘을 추가하여 네트워크를 효율적으로 훈련시키고 진단 성능을 향상시킬 수 있다. 도 1은 본 발명의 예시적인 실시예에 따른 사운드 기반 동작 모니터링을 위한 제안 된 컨볼루션 신경망 아키텍 처를 보여준다. 도 1을 참조하면, 제안된 프레임 워크에서 수집된 원시 데이터는 2D 형식으로 변환되어 모델 입력으로 사용되며, 신호 처리 및 오류 진단에 대한 사전 전문 지식이 필요하지 않다. 지오메트리 맵 치수가 변경되지 않도록 제로 조정 작업(zero-adjustment operation)이 구현된다. 풀링 계층 (pooling layers)은 일반적으로 정보의 중요한 기능을 유지하면서 매개변수 수를 줄이고 훈련 프로세스를 가속 화하기 위해 딥 네트워크에서 사용된다. 풀링 계층 결정은 특정 오류 진단 문제와 해당 데이터 세트에 따라 달 라질 수 있다. 대부분의 경우 평균 풀링 계층은 나머지 두 빌딩 블록 사이에 사용된다. 마지막으로, 시스템에서 추출한 학습된 특징은 완전 연결 계층과 소프트맥스 회귀로 전달되어 고장 범주 (failure categories)를 추정한다. 배치 정규화(Batch normalization)는 특히 딥 러닝을 위한 훈련 프로세스를 가속화 할 수 있으며 최근 연구에서 우수한 성능을 입증했다. 본 발명에서는 각 컨벌루션 레이어 이후에 배치 정규화가 사용된다. 또한 정류된 선형 단위 활성화 함수가 네트워크에서 사용된다. 훈련 과정에서 경사 확산이 발생하지 않기 때문에 일반적으로 특히 깊은 구조에서 더 나은 성능을 얻을 수 있다. 크로스 엔트로피 함수는 학습 과정에서 손실 함수로 사용된다. 역전파(back-propagation: BP) 알고리즘은 레이 어들의 모든 가중치 업데이트에 적용되며 훈련 중에 확률적 기울기 강하 최적화 방법을 사용한다. 많은 학습 데 이터가 필요한 경우 데이터 향상을 통해 유용한 학습 샘플을 생성할 수 있다. 더 깊은 구조를 통해 더 나은 기 능 추출을 보장하기 위해 여러 CNN 빌딩 블록을 잠재적으로 네트워크에 쌓을 수 있다. 도 2는 본 발명의 예시적인 실시예에 따른 사운드 기반 원격 실시간 다중 기기 운영 모니터링 시스템(이하, '모 니터링 시스템'이라 함)의 구성을 나타내는 블록도이다. 도 2를 참조하면, 모니터링 시스템은 하나 이상의 타겟 장비에서 생성된 사운드신호를 수집하여 디지 털 사운드신호로 변환하고, 신호 분석을 위해 제공하도록 구성된 사운드신호 수집장치와, 사운드신호 수집 장치로부터 제공받은 디지털 사운드신호를 분석하여 타겟장비의 상태를 모니터링하도록 구성된 신호 분석장치를 포함할 수 있다. 타겟 장비는 모니터링 대상 기기로서, 동작 중에 소리를 방출한다. 예시적인 실시예에서, 사운드 신호 수 집 장치는 타겟 장비에서 생겨난 소리를 수집하여 신호 분석 장치에 제공하도록 구성되고, 신호 분석 장치는 제공받은 사운드 신호를 타겟 장비에 관한 학습용 사운드 데이터로 미리 훈련된 인공신 경망에 기반하여 분석하여 타겟 장비의 동작 상태를 예측하도록 구성될 수 있다. 예시적인 실시예에서, 사운드신호 수집장치는 마이크부, 사운드신호 처리부, 사운드 데이터 저 장부, 사운드 데이터 제공부 등을 포함할 수 있다. 신호 분석장치는 학습데이터 가공부, 인공신경망 훈련부, 동작상태 예측부 등의 기능모듈을 포함할 수 있다. 이러한 기능모듈은 컴퓨터 프 로그램 모듈과, 예컨대 MATLAB프로그램 등이 설치된 컴퓨터 장치로 구현될 수 있다. 사운드신호 수집장치에 있어서, 마이크부는 타겟 장비에서 방출되는 소리를 입력으로 받아 사운 드 신호로 출력한다. 사운드신호 처리부는 마이크부와 연결되어 마이크부에서 출력되는 아날로그 사운드 신호를 처리하여 후단에 연결된 신호 분석장치에서 사용 가능한 형태로 변경할 수 있다. 예컨대, 마이크부와 사운드신호 처리부는 예컨대 USB 케이블과 리눅스 커널의 구성 요소 중 하나인 고급 리눅스 사운드 아키텍처(Advanced Linux Sound Architecture: ALSA) 관리 프로그램을 이용하여 연결될 수 있다. 사운드신호 처리부는 마이크부의 출력 사운드 신호를 디지털화하여 무손실형 오디오 파일(wav 등)의 포맷으로 변환할 수 있다(주파수는 상관 없음). 변환된 사운드 파일은 사운드 데이터 저장부에 저장 될 수 있다. 이러한 사운드 파일의 수집은 2가지 작업 목적이 있다. 한 가지는 인공신경망 학습용 기초 데이터로서 사용하기 위해 사운드 파일을 수집하는 것이고, 나머지 한 가지는 장비의 동작 상태를 실제로 모니터링하기 위해 사운드 파일을 수집하는 것이다. 둘 다 같은 하드웨어에서 같은 방식으로 파일을 받는다. 즉, 타겟 장비의 상태를 분석, 예측하기 위한 인공신경망 기반 학습을 위한 기초자료로서 사운드 신호 수집을 먼저 하고, 충분한 인공신 경망 학습이 이루어진 다음에 실제 모니터링이 진행될 수 있다. 예시적인 실시예에서, 사운드 데이터 제공부는 사운드 데이터 저장부에 저장된 사운드 데이터를 소정 크기로 트리밍(trimming)하여 신호 분석장치로 제공할 수 있다. 인공신경망을 통해 각 타겟 장비의 상태를 예측하는 데 필요한 학습을 위해, 사운드 데이터 제공부는 학습용 사운드 데이터를 신호 분석 장치 의 학습데이터 가공부에 제공할 수 있다. 그 학습용 사운드 데이터는 인공신경망 훈련부에 제공 되고 다양한 사운드에 대한 학습이 수행될 수 있다. 사운드 신호 학습을 통해 예측 능력이 갖춰지면 즉, 학습된 인공신경망이 확보된되면, 사운드 데이터 제공부 는 마이크부, 사운드신호 처리부, 사운드 데이터 제공부를 통해 수집된 사운드 데이터를 그 학습된 인공신경망을 기반으로 하는 동작상태 예측부에 타겟 장비의 동작 상태를 실제로 모니터링 하기 위한 분석용 데이터로서 제공할 수 있다. 사운드 데이터 제공부가 학습데이터 가공부와 동작상 태 예측부로 제공하는 사운드 데이터의 길이는 동일할 수 있다. 예컨대 그 사운드 데이터는 예컨대 1 ~ 수 초의 길이를 가질 수 있다. 예시적인 실시예에서, 사운드 데이터 제공부는 인공신경망 학습용 기초 자료로 수집되는 사운드 데이터를 미리 소정 길이의 사운드 파일, 예컨대 1초짜리 wav파일로 재가공 하여 학습데이터 가공부에 입력 데이터 로 제공할 수 있다. 반면에, 타겟 장비의 동작을 실제 모니터링하기 위해 사운드 데이터를 수집하는 경우 에는, 사운드 데이터 제공부는 데이터 길이에 대한 별도의 가공 없이, 예컨대 wav 파일 형태 그대로 동작 상태 예측부에 입력 데이터로 제공할 수 있다. Wav 파일은 예시적일 뿐이고, 사운드 데이터 제공부가 신호분석장치로 제공하는 사운드 파일은 wav 포맷이 아닌 다른 포맷일 수도 있다. 동작상태 예측부는 입력된 그 wav 파일을 자체적으로 예컨대 1초 단위로 트림하여 사용할 수 있다. 사운드신호 수집장치는 예컨대 라즈베리 파이(raspberry Pi) 또는 아두이노와 같은 플랫폼 장치를 사용하 여 구현될 수도 있다. 신호 분석장치에 있어서, 학습데이터 가공부는 사운드신호 수집장치의 사운드 데이터 제공부 로부터 제공되는 학습용 사운드 데이터, 예컨대 1초짜리의 wav 파일들에 대하여 전처리한 다음, 분류를 하 고 레이블링 처리를 하여 인공신경망 훈련부에 학습 데이터로 제공할 수 있다. 인공신경망 훈련부는 그 학습 데이터로 장비에서 방출되는 소리와 그 장비의 동작 상태 간의 관계에 대하 여 학습을 수행할 수 있다. 많은 양의 학습 데이터로 훈련하는 것을 통해 인공신경망 훈련부는 장비에서 발생하는 소리가 주어졌을 때 그 장비의 동작 상태를 정확하게 예측할 수 있는 모델을 구축할 수 있다. 이러한 동작 상태 예측 모델은 각 타겟장비마다 별도로 생성될 수 있다. 동작상태 예측부는 인공신경망 훈련부가 구축한 예측 모델을 포함할 수 있다. 동작상태 예측부 는 사운드 데이터 제공부가 제공하는 타겟 장비의 사운드 데이터 파일을 입력받아 그 파일 내의 사운 드 데이터를 소정 단위길이(예컨대 1초 길이)씩 자른다. 그리고 동작상태 예측부는 각 단위길이의 사운드 데이터를 순차적으로 예측 모델에 입력하여 타겟 장비의 동작상태를 예측할 수 있다. 예시적인 실시예에서, 기본적으로, 녹음된 사운드 데이터의 학습 및 실제 예측을 수행하는 신호분석장치는 단일의 컴퓨팅 장치로 구현될 수 있다. 다만, 동작상태 예측부만 분리해서 이를 사운드신호 수집장치(20 0)에서 일 구성요소로서 구현할 수도 있다. 이 경우, 사전에 학습된 인공신경망을 활용하여, 독립적으로 작동되 는 컴퓨팅 장치(예컨대, 라즈베리 파이 혹은 유사 플랫폼)를 이용하여 모니터링 시스템을 구현하는 것도 가능하다.이와 같은 과정을 통해 타겟 장비에서 방출되는 사운드를 스트리밍 방식으로 실시간으로 녹음하고, 분석하 여 그것의 동작 상태에 관해 모니터링 작업을 수행할 수 있다. 도 3은 예시적인 실시예에 따른 사운드 기반 원격 실시간 다중 기기 운영 모니터링 시스템의 알고리즘을 개략적 으로 도시한다.도 3을 참조하면, 개시된 것은 모니터링 시스템의 알고리즘이다. 먼저, 타겟 장비로부 터 취득한 원시 사운드 신호를 소정 포맷의 디지털 데이터로 변환하고 소정 길이 단위로 분할하는 등의 가공을 통해 훈련용(학습용) 샘플 데이터 세트를 준비한다(S10, S20). 준비된 훈련용 샘플 데이터 세트의 각 단위 샘플 데이터는 1차원 데이터인데, 이를 2차원 데이터로 변환하고 배경 소음도 추가하는(S40) 등 사운드 데이터를 변 환한다(S50). 그 변환된 데이터로 신경망을 훈련시켜 훈련된 신경망(예측 모델)을 구축할 수 있다(S60). 그런 다음, 타겟 장비에서 방출되는 실시간 사운드를 수집하여 기록한 데이터(S70, S80)와 훈련된 신경망 (S90)을 이용하여 타겟 장비의 현재 상태에 관한 확률을 계산할 수 있다(S100). 이 계산된 확률로 타겟 장 비의 상태가 예측될 수 있다. 상태 예측에 사용되는 신경망의 경우, 단순한 CNN 구조를 사용할 수 있지만, ResNet-18, ResNet-50, GoogleNet 등 보다 복잡한 구조의 신경망을 사용할 수도 있다. 예시적인 실시예로 개시된 알고리즘의 특징은 이 시스템이 개별 시스템과 병렬 시스템의 합이라는 점이다. 이 시스템은 사운드를 타겟 장비의 사운드와 기타 과외의 사운드의 합으로 간주한다. 기타 다른 장비들의 동 작 사운드는 과외의 사운드로 간주한다. 이하에서는 도 3의 알고리즘을 좀 더 구체적으로 설명한다. 먼저, 원시 사운드 신호를 획득하여 훈련용 샘플 데이터 세트를 구성한다(S10-S50 단계). 원시 사운드 신호는 미리 마이크 어레이에서 직접 얻을 수 있지만 후술할 가상 데이터 세트를 사용할 수도 있다. 데이터는 예컨대 1 초의 길이 단위로 트리밍되고(S10), 데이터 정렬을 허용하도록 레이블이 지정될 수 있다(S20). 시간 척도를 다 른 형태로 바꾸고(translate) 조정하는 등 데이터 증가(data augmentation)를 위한 처리를 수행하고(S30), 배 경 소음을 추가하여(S40) 최종 훈련용 학습데이터 세트를 만들 수 있다(S50). 그런 다음, 이렇게 구성된 데이터는 1차원 (시간-신호세기) 데이터인데, 이를 STFT(Short-Time Fourier Transform), 또는 로그-멜 스펙트로그램(log-mel spectrogram) (혹은 Wavelet Transform) 등을 사용하여 2차원 (시간/주파수 신호세기) 데이터 형태로 변환될 수 있다(S50). 로그-멜 스펙트로그램을 이용한 변환 시, 프레임 듀레이션과 호프(hop) 듀레이션은 예컨대 0.01초와 0.004초를 각각 적용할 수 있고, 밴드의 수는 40으로 적용할 수 있다. 로그-멜 스펙트로그램은 주파수 대역 영역을 사람의 가청 주파수에 할당하고 그 크기를 로그 스케일로 변환하는 단시간 푸리에 변환 (short-time Fourier transform: STFT)에 기반한 일종의 웨이블릿 변환(wavelet transform)이다. 사람이 듣는 것과 유사한 결과를 제공할 수 있다. 따라서 주로 소리 인식 분야에서 사용되며 특히 분류에서 매우 높은 성능을 달성한다. 데이터 세트는 각 장치의 작동 상태에 따라 정렬될 수 있다. 이와 같은 인공신경망 훈련에 사용될 학습 데이터를 가공하는 작업의 대부분은 학습 데이터 가공부에서 수 행될 수 있다. 준비된 학습 데이터는 인공신경망 훈련부에 제공될 수 있다. 인공신경망 훈련부에서는, 그 준비된 학습 데이터 세트를 이용하여 인공신경망을 훈련시킬 수 있다. 훈련을 통해 학습 된 인공 신경망이 확보될 수 있다. 모니터링 해야 할 타겟 장비가 복수 개(Equipment 1-4) 있는 경우, 각 장비 별로 별도의 훈련을 수행하여 각 장비마다 훈련된 인공신경망을 구축할 수 있다(S60). 동작상태 예측부는 이렇게 준비된 인공신경망을 이용하여 타겟 장비의 현재의 사운드 데이터를 토대 로 그 장비의 동작 상태를 모니터링할 수 있다. 훈련된 신경망을 사용하기 위해 타겟 장비들의 작동음이 마이크부를 통해 녹음하여 사운드 데이터 저장부에 저장될 수 있다(S70). 실제 모니터링을 위한 사운 드는 예컨대 wav 파일 형태 생성될 수 있다. 사운드 데이터 제공부는 훈련용 학습 데이터 세트를 준비하는 과정에서와 같이 그 녹음된 사운드 데이터 파일을 별도의 가공 없이 예컨대 1 초 길이의 샘플로 트리밍할 수 있다. 이와 같이 함으로써 스트리밍 방식으로 실시간으로 녹음되는 사운드 신호에 대해서도 모니터링 작업을 수행할 수 있다. 트리밍된 샘플 사운드 데이터 는 1차원 (시간-강도) 데이터인데, 이를 STFT(Short-Time Fourier Transform), 로그-멜 스펙트로그램 (혹은 Wavelet Transform) 등을 이용하여2차원 (시간/주파수 강도) 데이터 형태로 변환할 수 있다(S80). 로그-멜 스 펙트로그램을 이용한 변환 시, 프레임 듀레이션과 호프(hop) 듀레이션은 예컨대 0.025초와 0.01초를 각각 적용 할 수 있고, 밴드의 수는 40으로 적용할 수 있다. 타겟 장비가 복수 개이면 각 장비 별로 모니터링 데이터를 별도로 만들 수 있다. 사운드 데이터 제공부는 그 변환된 모니터링용 사운드 데이터를 동작상태 예측부에 제공할 수 있다 (S90). 동작상태 예측부에는 미리 준비한 훈련된 인공신경망이 구축되어 있다. 동작상태 예측부는 훈련된 인공신경망에 기반하여 각 타겟 장비의 각 작동 상태에 대한 예측 확률을 계산하고 그 계산된 확률 값에 기초하여 해당 타겟 장비의 가장 가능성 높은 작동 상태를 예측할 수 있다 (S100). 예시적인 실시예에 따른 모니터링 시스템은 각 타겟 장비 별로 해당 장비의 작동 상태를 분류하는 인 공신경망 모델을 포함할 수 있다. 즉, 타겟 장비가 복수 개이면 인공신경망 모델도 동일한 개수를 포함할 수 있다. 모니터링 시스템은 모든 타겟 장비를 동시병행적으로 모니터링 할 수 있다. 각 인공신경망 모델은 한 타겟 장비의 작동 상태만 분류하고, 나머지 다른 모든 장비들의 소리는 소음으로 간주할 수 있다. 이 모니터링 시스템의 장점은 여러 장비가 동시에 작동하더라도 그 장비들의 작동소리가 감지되기만 하면 그 장비들을 각각 독립적으로 그리고 동시병행적으로 식별하여 각 장비의 상태를 예측할 수 있다는 점이다. 즉, 이 론적으로는 개수의 제한 없이 많은 장비들의 상태를 동시병행적으로 모니터링 할 수 있다는 것이다. 본 발명의 실험을 위해 사용된 하드웨어 및 소프트웨어의 사양은 표 1에 나열되어 있다. 표 1 하드웨어/소프트웨어의 사양 Specification Value Operating System Microsoft® Windows® 10 Home Software Platform MATLAB R2020a System RAM Samsung® 32 GB (DDR3) Processor Type (CPU) Intel® core i7-4790 (3.9 GHz) Graphics Card (GPU) NVIDIA® GeForce GTX 750 이하에서는, 실제 모니터링 시스템의 생성을 설명하고 필요한 데이터를 얻은 방법을 설명한다. 이 기록 과정을 통해 얻은 정보의 유형을 설명하고 주어진 알고리즘을 통해 분석한 결과를 설명한다. 이 프로세스는 작업 공간에서 사운드를 녹음하는 것으로 시작된다. 녹음 장치 (Respeaker Mic Array 2.0)의 세 부 사양은 표 2에 예시되어 있다. 표 2 마이크 어레이 사양 Specification Value Name Respeaker Mic Array 2.0 No. of Mic 4 (Output: 5ch) Sensitivity 26 dBFS (Omnidirectional) Diameter Φ70 mm Max sample rate 48 kHz Digital signal processor XMOS XVF-3000 Recording Program Audacity 2.3.3 마이크부로 사용된 마이크 어레이가 도 4에 예시되어 있다. 그 마이크 어레이로 녹음된 신호의 예는 도 5 에 예시되어 있다. 일 예로, 마이크 어레이의 출력 수는 5 개이다. 4 개의 신호는 원시 신호이다. 5 번째 신호는 디지털 신호 프로 세서에 의해 출력된다. 무 지향성(Omnidirectional) 마이크가 사용되므로 도착 시간 차이에 따라 위상차가 존재 할 수 있으며, 수신 신호들은 거의 동일하다. 모니터링 대상 장비로는 띠톱, 드릴, 펌프 및 선삭(turning) 장비를 선택했다. 이들 장비는 실험실에서 임의의 위치에 배치되었다. 도 6은 STFT 및 log-mel 스펙트로그램으로 후처리 된 작동음의 기록 결과를 보여준다. 훈련용 데이터 세트를 만들기 위해 도 7와 표 3의 방식에 따라 녹음을 수행했다. 두 개의 마이크 어레이를 설치 하고 각각 마이크 1의 원시 신호와 디지털 신호 프로세서 출력의 두 신호를 수집했다. 녹음은 800 초간 지속되 었고, 총 길이가 3200 초인 녹음 된 사운드는 각각 1 초 길이의 3200 개 파일로 나누어졌다. 데이터의 다양성을 보장하기 위해 마이크 어레이는 임의의 위치에 설치되었다. 표 3 데이터 훈련을 위한 데이터 세트의 사양 Specification Value Total number of data (recording time) 3200 files (800 sec) Data format .wav file with 1 sec length Number of target device 4 (bandsaw, drill, pump, turning) Number of channel 4 (2ch per each mic array and 2 mic arrays) 녹음된 사운드를 바탕으로 모니터링 시스템이 훈련되었다. 도 8은 모니터링 시스템을 사용하여 펌프를 모니터링 하고 회전한 결과를 보여준다. 모니터링 시스템은 장치의 소리를 인식하고 두 장치가 동시에 작동하거나 또는 장치가 소음과 함께 작동할 때 문제없이 작동하고 있음을 감지 할 수 있었다. (예: 박수 치는 사람). 모니터링 시스템의 성능을 평가하기 위해 도 9 및 표 4의 방식에 따라 테스트 데이터 세트를 생성했다. 이전과 같이 띠톱, 드릴, 펌프 및 터닝 장비를 타겟 장비로 삼고, 2 개의 마이크 어레이를 설치하고, 각각 2 개의 신호 (마이크 1의 원시 신호 및 디지털 신호 프로세서의 출력)은 160초 동안 녹음되어 총 640 초의 녹음된 사운드를 제공하였다. 데이터는 각각 1 초 길이의 640 개의 .wav 파일로 분할되었다. 데이터의 다양성을 보장하기 위해 마이크 어레이는 새로운 임의의 위치에 설치되었다. 모니터링 시스템의 성능은 이 테스트 세트의 결과를 운영 계획과 비교하여 평가되었다. 성능은 각 장치의 작동 상태와 일치하는 예측 비율로 정의되었다. 표 4 성능 평가를 위한 표준 데이터 세트 사양 Specification Value Total number of data (recording time) 640 files (160 sec) Data format .wav file with 1 sec length Number of target device 4 (bandsaw, drill, pump, turning) Number of channel 4 (2ch per each mic array and 2 mic arrays) 성능 평가 결과는 도 10에 나와 있다. 모니터링 시스템의 정확도는 띠톱, 드릴, 펌프 및 선삭 장비에 대해 각각 약 70 %, 53 %, 95 % 및 91 %였다. 이것은 시스템이 띠톱, 펌프 및 선삭 장비의 소리는 잘 인식할 수 있다는 것 을 보여준다. 다만, 드릴 소리에 대한 인식 정확도는 낮은 편인데, 이는 드릴이 매우 조용했기 때문에 인공신경 망이 훈련 과정에서 특성을 제대로 추출하지 못했기 때문인 것으로 추정할 수 있다. 드릴의 소리는 작동 중일 때도 다른 장치 소리로 위장되었을 것으로 추정된다. 장치에 관한 인식률을 높이기 위해 모니터링 대상 주파수 변경을 시도될 수 있다. 도 11은 테스트 데이터 세트 에 사용된 사운드를 STFT를 이용하여 주파수 영역으로 변환한 결과이다. 장치의 작동음은 일반적으로 특정 주파 수에 집중되며 시스템이 해당 주파수에 집중하도록 설정하면 모니터링 시스템의 성능이 향상될 수 있다. 띠톱의 경우 모니터링 대상 주파수 범위는 주로 1,500Hz 미만의 저주파 영역에서 뚜렷한 특성으로 인해 50Hz 7,000Hz 에서 10Hz 1,500Hz로 변경될 수 있다. 이러한 주파수 영역 변경에 따라 도 12에서 볼 수 있듯이 모니터링 시스 템의 정확도는 71 %에서 85 %로 향상될 수 있다. 모니터링 시스템의 인식 성능 향상을 위해 simple-CNN 대신 다양한 인공신경망을 적용할 수 있다. 선정된 인공 신경망은 ResNet-18, ResNet-50, GoogLeNet이며, 이들 인공신경망은 이미지 인식에 사용되는 인공신경망으로 좋 은 성능을 보였다. 그 결과 인식 성능은 도 13에 예시된 것처럼 simple-CNN 이 71 %를 보인 것에서 ResNet-18, ResNet-50, GoogLeNet은 77 %, 77 %, 79 %로 각각 향상되었다. 결과는 도 13과 같다. 적용된 인공신경망 관련 정보는 표 5와 같다. 표 5에서 볼 수 있듯이 ResNet-18, ResNet-50, GoogLeNet와 같은 복잡한 인공 신경망은 인지 성능을 향상시킬 수 있지만, 처리 시간이 2.5 ~ 5 배 증가했으며 동일한 데이터 세 트로 교육을 수행하더라도 더 나은 컴퓨터가 필요했다. 또한 데이터는 40x98x3의 RGB 이미지로 변환되어야 한다. 따라서 신경망 선택에 대한 고려가 필요하다. 표 5 모니터링 시스템에 사용된 신경망들의 사양 Network Size of network Input data Process Time (640 images) Simple-CNN 0.5 MB 40x98x1, Value 8.0 sec ResNet-18 40 MB 40x98x3, RGB image 21.9 sec ResNet-50 86 MB 40x98x3, RGB image 39.8 sec GoogLeNet 22 MB 40x98x3, RGB image 37.5 sec 소리는 겹치면서 독립적으로 자신의 정보를 보존 할 수 있는 특성이 있다. 즉, .wav 파일을 결합하여 결합된 단 순하고 기계적인 사운드로 새로운 가상 데이터 세트를 생성할 수 있다. 이 방법의 장점은 어떤 크기의 데이터 세트도 생성할 수 있고, 실제로 구현하기 어려운 상황에 관해 데이터 세트를 생성할 수 있으며, 여러 상황을 재 현하는 것이 아니라 기계의 작동 소리 만 녹음하면 되므로 새로운 데이터 세트를 쉽게 생성 할 수 있다는 것이다. 도 14는 가상 데이터 세트를 생성하는 과정과 고려해야 할 요소를 보여준다. 이 과정을 통해 모니터링 하고자 하는 기계의 작동음을 결합하여 다양한 상황에 맞는 가상 데이터 세트를 만들었다. 이 과정에서 다음 항목이 고 려될 수 있다: 1) 사운드 풀의 데이터 샘플 수; 2) 추출 된 샘플의 강도 수정 여부: 수정 없음, 동일한 강도로 수정, 무작위 강도로 수정; 3) 사운드가 없는 샘플을 포함할지 여부 (모든 장치가 꺼져 있음); 4) 결합된 샘플 의 강도 수정 여부: 수정 없음, 동일한 강도로 수정, 무작위 강도로 수정; 그리고 5) 배경음 포함 여부. 표 6 모니터링 시스템용 가상 데이터 세트 사양 Specification Value Raw data in the sample pool 10 files per device (1 sec per file) Total data 2,999 .wav files Intensity of raw data Modified to the same intensity Zero-sound sample Excluded Intensity of combined data No modification Background sound Recorded sound when all devices are off Frequency range 10 - 1,500 Hz (bandsaw)50 - 7,000 Hz (other devices) 표 6에 나열된 조건에서 가상 데이터 세트를 사용한 모니터링 시스템의 성능은 도 15와 같다. 모니터링 시스템 의 정확도는 밴드 톱, 드릴, 펌프 및 선삭 장치 각각에 대하여 약 87%, 59%, 97%, 99%였다. 따라서 가상 데이터 세트로 훈련된 모니터링 시스템은 실제 레코딩으로 훈련되었을 때와 마찬가지로 작동했다. 일부 장치에 관해서 는 성능이 약 10% 정도 향상되었다. 다만, 조용한 작동음을 방출하는 드릴의 경우 가상 데이터 세트로도 모니터 링 성능이 높게 나오지는 않았다. 위에서 설명한 실시예들에서는 CNN과 같은 인공신경망을 사용하여 장치들의 작동음을 분류하여 동시에 작동하는 여러 장치의 작동 상태를 모니터링하는 시스템과 방법을 설명하였다. CNN과 같은 인공신경망이 녹음된 작동 음으로 훈련되었을 때, 모니터링 시스템은 약 7192 %의 정확도로 장치의 작동 상태를 인식할 수 있다. 다만, 드릴과 같이 방출 음이 강하지 않은 장치의 경우는 작동 상태 인식 정확도 가 다소 낮게 나타난다. 모니터링 대상 주파수 범위를 수정한 후 띠톱의 정확도가 71%에서 85%로 향상될 수 있 다. 각 장치의 1초 사운드 파일을 결합하여 생성된 가상 데이터 세트로 훈련했을 때 시스템의 정확도는 약 87 ~ 99 %로 향상될 수 있다. 산업상 이용가능성본 발명은 제조 공정 모니터링을 위한 사운드 기반 모니터링 시스템으로 이용될 수 있다: 이 모니터링 시스템은, 제조 공정에 사용되는 각 기기의 외부에 간단한 시스템으로 설치되어 각 기기의 작동음을 녹음, 분석 하여 해당 기기의 작동 상태를 파악할 수 있고, 이를 통해 전체 제조 공정의 진행 상황을 분석하는 시스템으로 활용될 수 있다. 또한, 상기 사운드 기반 모니터링 시스템은 비상 상황 추적을 위한 사운드 기반 시스템으로도 활용될 수 있다. 수작업 장치를 사용한 작업장 및CNC 기계가 설치된 공장 환경, 알루미늄 주조공장 등에 작업 공정 모니터링 시 스템으로 활용될 수 있다. CNC 기계에 대한 ATC 작동 모니터링에 따르면 연속 작동 사운드뿐만 아니라 순간적인 사운드를 기반으로 이벤트를 모니터링 할 수 있음을 보여주었다. 따라서 다양한 비상 상황을 지속적으로 모니터 링하여 공장의 공정의 안정성을 높이는 수단으로 활용될 수 있다."}
{"patent_id": "10-2021-0005479", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 예시적인 실시예에 따른 사운드 기반 동작 모니터링을 위한 컨볼루션 신경망 아키텍처를 보여 준다. 도 2는 본 발명의 예시적인 실시예에 따른 사운드 기반 원격 실시간 다중 기기 운영 모니터링 시스템의 구성을 나타내는 블록도이다. 도 3은 본 발명의 예시적인 실시예에 따른 사운드 기반 원격 실시간 다중 기기 운영 모니터링 시스템의 알고리 즘을 개략적으로 나타낸다. 도 4는 본 발명의 예시적인 실시예에 따른 마이크부로 사용되는 마이크 어레이를 예시한다. 도 5는 도 4의 마이크 어레이에서 수신 및 처리된 신호를 예시한다. 도 6은 단시간 푸리에 변환(왼쪽) 및 log-mel 스펙트로 그램(오른쪽)으로 처리 한 후 타겟 장치의 작동 사운드 의 기록 결과를 예시한다. 도 7은 본 발명의 예시적인 실시예에 따른 모니터링 시스템을 훈련하기 위해 샘플 데이터를 수집하기 위한 실험 설정을 예시한다: (a) 장치가 작동 된 시간. (b) 각 장치의 위치.도 8은 본 발명의 예시적인 실시예에 따른 사운드 기반 다중 기기 운영 모니터링 시스템을 사용하여 펌프를 모 니터링하고 회전한 결과를 보여준다. 도 9는 본 발명의 예시적인 실시예에 따른 모니터링 시스템을 평가하기 위한 테스트 데이터 세트를 수집하기 위 한 실험 설정을 예시한다. (a) 장치가 작동된 시간. (b) 각 장치의 위치. 도 10은 실제 데이터를 기반으로 한 모니터링 시스템의 성능 평가 결과를 예시한다. 도 11은 테스트 데이터 세트에 사용된 사운드를 STFT를 이용하여 주파수 영역으로 푸리에 변환 처리된 작동음을 예시한다. 도 12는 모니터링 대상 주파수 범위가 다른 모니터링 시스템의 성능 평가 결과를 예시한다. 도 13은 신경망이 다른 모니터링 시스템의 성능 평가 결과를 예시한다. 도 14. 훈련용 가상 데이터 세트를 생성하는 과정과 고려해야 할 요소를 보여준다. 도 15는 가상 데이터 세트에 기반한 모니터링 시스템의 성능 평가 결과를 예시한다."}
