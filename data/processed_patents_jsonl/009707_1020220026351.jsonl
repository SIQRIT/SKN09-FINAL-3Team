{"patent_id": "10-2022-0026351", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0128875", "출원번호": "10-2022-0026351", "발명의 명칭": "상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 호감도를 측정하는 장치 및 그", "출원인": "주식회사 마블러스", "발명자": "오하람"}}
{"patent_id": "10-2022-0026351", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 호감도를 측정하는 전자 장치에 있어서,상기 전자 장치는 적어도 하나의 프로세서, 메모리, 송수신부, 카메라 및 녹음장치를 포함하고,상기 프로세서는상기 카메라와 상기 녹음장치를 통해 상기 사용자에 대한 음성 데이터 및 영상 데이터를 획득하고,상기 음성 데이터 및 상기 영상 데이터로부터 상기 사용자의 내적 요인 및 외적 요인을 획득하고,상기 내적 요인 및 상기 외적 요인으로부터 상기 상호작용 상대방에 대한 상기 상호작용 선호도를 측정하고,상기 송수신부를 통해 서버로부터 상기 상호작용 상대방의 상기 사용자에 대한 상호작용 선호도를 수신하고,상기 상호작용 상대방의 상기 상호작용 선호도를 고려하여 상기 사용자의 상호작용 호감도를 측정하는, 전자 장치."}
{"patent_id": "10-2022-0026351", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 내적 요인은상기 이미지 데이터로부터 획득한 상기 사용자에 대한 생체 신호 정보를 포함하고,상기 생체 신호 정보는상기 사용자에 대한 심박 변이도(HRV)를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0026351", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 프로세서는원격 광혈류 측정 기법을 이용하여 상기 이미지 데이터로부터 상기 사용자의 심박 변이도를 획득하고,상기 생체 신호 정보는상기 심박 변이도의 고주파 영역, 저주파 영역 및 심박 변이도에 기초한 스트레스 수치를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0026351", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 외적 요인은상기 음성 데이터로부터 획득한 행동 정보와 상기 이미지 데이터로부터 획득한 감정 정보, 집중도 정보 및 시선정보를 포함하고, 상기 행동 정보는상기 상호작용 과정에서의 대화 시간, 대화 횟수 및 대화 내용에 기초한 대화 긍부정도를 포함하고,공개특허 10-2023-0128875-3-상기 감정 정보는상기 사용자의 표정 변화에 기초한 감정을 포함하고,상기 시선 정보는상기 사용자의 시선 위치와 시선 고정 시간을 포함하고,상기 집중도 정보는상기 생체 신호와 상기 시선 정보를 고려하여 산출한 상기 사용자의 집중도를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0026351", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 프로세서는상기 상호작용 상대방의 상기 상호작용 선호도가 긍정적이면 상기 사용자의 상호작용 호감도를 증가시키고, 상기 상호작용 상대방의 상기 상호작용 선호도가 부정적이면 상기 사용자의 상호작용 호감도를 감소시키는, 전자장치."}
{"patent_id": "10-2022-0026351", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 프로세서는상기 사용자에 대한 상기 상호작용 상대방의 선호도를 상승시키기 위한 추천 컨텐츠를 선정하여 상기 사용자에게 제공하는, 전자 장치."}
{"patent_id": "10-2022-0026351", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 프로세서는상기 사용자의 상기 상호작용 호감도를 상승시키기 위한 추천 컨텐츠를 선정하여 상기 사용자에게 제공하는, 전자 장치."}
{"patent_id": "10-2022-0026351", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 호감도를 측정하는 방법에 있어서, 상기 방법은카메라와 녹음장치를 통해 상기 사용자에 대한 음성 데이터 및 영상 데이터를 획득하는 단계;상기 음성 데이터 및 상기 영상 데이터로부터 상기 사용자의 내적 요인 및 외적 요인을 획득하는 단계;상기 내적 요인 및 상기 외적 요인으로부터 상기 상호작용 상대방에 대한 상기 상호작용 선호도를 측정하는 단계;서버로부터 상기 상호작용 상대방의 상기 사용자에 대한 상호작용 선호도를 수신하는 단계; 및상기 상호작용 상대방의 상기 상호작용 선호도를 고려하여 상기 사용자의 상호작용 호감도를 측정하는 단계를포함하는, 방법.공개특허 10-2023-0128875-4-청구항 9 상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 호감도를 측정하는 방법을 기록한 컴퓨터 판독가능한 저장 매체에 있어서, 상기 방법은카메라와 녹음장치를 통해 상기 사용자에 대한 음성 데이터 및 영상 데이터를 획득하는 단계;상기 음성 데이터 및 상기 영상 데이터로부터 상기 사용자의 내적 요인 및 외적 요인을 획득하는 단계;상기 내적 요인 및 상기 외적 요인으로부터 상기 상호작용 상대방에 대한 상기 상호작용 선호도를 측정하는 단계;서버로부터 상기 상호작용 상대방의 상기 사용자에 대한 상호작용 선호도를 수신하는 단계; 및상기 상호작용 상대방의 상기 상호작용 선호도를 고려하여 상기 사용자의 상호작용 호감도를 측정하는 단계를포함하는, 저장 매체."}
{"patent_id": "10-2022-0026351", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 호감도를 측정하는 전자 장치에 있어서, 상기 전자 장치는 적어도 하나의 프로세서, 메모리, 송수신부, 카메라 및 녹음장치를 포함하고, 상기 프 로세서는 상기 카메라와 상기 녹음장치를 통해 상기 사용자에 대한 음성 데이터 및 영상 데이터를 획득하고, 상 기 음성 데이터 및 상기 영상 데이터로부터 상기 사용자의 내적 요인 및 외적 요인을 획득하고, 상기 내적 요인 및 상기 외적 요인으로부터 상기 상호작용 상대방에 대한 상기 상호작용 선호도를 측정하고, 상기 송수신부를 통 해 서버로부터 상기 상호작용 상대방의 상기 사용자에 대한 상호작용 선호도를 수신하고, 상기 상호작용 상대방 의 상기 상호작용 선호도를 고려하여 상기 사용자의 상호작용 호감도를 측정하는, 전자 장치에 관한 것이다."}
{"patent_id": "10-2022-0026351", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 호감도를 측정하는 장치 및 그 방법에 관한 것이다. 구체적으로, 본 발명은 사용자가 상대방과 상호작용을 수행하는 과정에서 수집한 대화 정보, 시선 정보 및 심박 정보 등으로부터 사용자의 내적 요인과 외적 요인을 분석하고, 사용자의 내적 요인과 외적 요인에 기초하여 상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 호감도를 측정하며, 나아가 상대방과 더 좋은 관계를 형성하기 위한 정보를 제공하는 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2022-0026351", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존에는 사용자의 행동 데이터에 기반하여 사용자의 선호도 및 호감도를 측정하였다. 커머스의 경우 사용자의 유입 경로, 머무른 시간, 동일 카테고리 검색횟수, 상품을 클릭한 횟수, 게임의 경우 특정 사용자와 호감도를 측정하기 위해 유입경로, 게임을 플레이 한 시간, 대화를 나눈 횟수 등과 같이 빈도와 시간으로 구성된 정보를 사용하여 호감도와 선호도를 측정하고 있고, 이를 기반으로 추천 시스템을 적용하고 있다. 하지만 시간과 빈도 에 따른 정보만으로는 자극적인 정보나 과대 포장된 정보에 대해서 사용자들이 실제로 선호하는 정보인지 판단 하고 이를 기반으로 마케팅에 사용하는 방법이 앞으로 나아가야할 초 개인화 시대에 맞지 않는 문제를 가지고 있다. 최근 뇌파와 심박수와 관련된 많은 연구에서 이러한 생체 신호의 변화가 사람의 선호도 또는 불안/스트레스를 판단하는 근거가 될 수 있다고 말하고 있다. 또한, 비대면 원격 상황의 증가하고 있는 현실에서 대면 상호작용의 기회가 줄어들어 유소년기 어린이나 초등학 생의 사회성을 키우기 위한 많은 노력과 연구가 진행되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 특허 출원번호 제10-2019-0106883호 (2019.08.29.) (선호도 결정 방법 및 이를 이용 한 선호도 결정용 디바이스)"}
{"patent_id": "10-2022-0026351", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위하여 다음과 같은 해결 과제를 목적으로 한다. 본 발명은 상호작용 과정에서 수집된 사용자의 대화 정보와 생체 정보를 고려한 상호작용 상대방에 대한 상호작 용 선호도와 사용자의 상호작용 호감도를 측정하는 것을 목적으로 한다. 본 발명은 상호작용 선호도와 상호작용 호감도를 고려하여 사용자에 적합한 상호작용 콘텐츠를 추천하는 것을 목적으로 한다. 본 발명의 해결과제는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 해결과제들은 아래의 기"}
{"patent_id": "10-2022-0026351", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "재로부터 당해 기술분야에 있어서의 통상의 지식을 가진 자가 명확하게 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0026351", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 다양한 실시 예는, 상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 호감도를 측정하는 전자 장치에 있어서, 상기 전자 장치는 적어도 하나의 프로세서, 메모리, 송수신부, 카메라 및 녹음장치를 포함 하고, 상기 프로세서는 상기 카메라와 상기 녹음장치를 통해 상기 사용자에 대한 음성 데이터 및 영상 데이터를 획득하고, 상기 음성 데이터 및 상기 영상 데이터로부터 상기 사용자의 내적 요인 및 외적 요인을 획득하고, 상 기 내적 요인 및 상기 외적 요인으로부터 상기 상호작용 상대방에 대한 상기 상호작용 선호도를 측정하고, 상기 송수신부를 통해 서버로부터 상기 상호작용 상대방의 상기 사용자에 대한 상호작용 선호도를 수신하고, 상기 상 호작용 상대방의 상기 상호작용 선호도를 고려하여 상기 사용자의 상호작용 호감도를 측정하는, 전자 장치를 제 공한다. 상기 내적 요인은 상기 이미지 데이터로부터 획득한 상기 사용자에 대한 생체 신호 정보를 포함하고, 상기 생체 신호 정보는 상기 사용자에 대한 심박 변이도(HRV)를 포함할 수 있다. 상기 프로세서는 원격 광혈류 측정 기법을 이용하여 상기 이미지 데이터로부터 상기 사용자의 심박 변이도를 획 득하고, 상기 생체 신호 정보는 상기 심박 변이도의 고주파 영역, 저주파 영역 및 심박 변이도에 기초한 스트레 스 수치를 포함할 수 있다. 상기 외적 요인은 상기 음성 데이터로부터 획득한 행동 정보와 상기 이미지 데이터로부터 획득한 감정 정보, 집 중도 정보 및 시선 정보를 포함하고, 상기 행동 정보는 상기 상호작용 과정에서의 대화 시간, 대화 횟수 및 대 화 내용에 기초한 대화 긍부정도를 포함하고, 상기 감정 정보는 상기 사용자의 표정 변화에 기초한 감정을 포함 하고, 상기 시선 정보는 상기 사용자의 시선 위치와 시선 고정 시간을 포함하고, 상기 집중도 정보는 상기 생체 신호와 상기 시선 정보를 고려하여 산출한 상기 사용자의 집중도를 포함할 수 있다. 상기 프로세서는 상기 상호작용 상대방의 상기 상호작용 선호도가 긍정적이면 상기 사용자의 상호작용 호감도를 증가시키고, 상기 상호작용 상대방의 상기 상호작용 선호도가 부정적이면 상기 사용자의 상호작용 호감도를 감 소시킬 수 있다. 상기 프로세서는 상기 사용자에 대한 상기 상호작용 상대방의 선호도를 상승시키기 위한 추천 컨텐츠를 선정하 여 상기 사용자에게 제공할 수 있다. 상기 프로세서는 상기 사용자의 상기 상호작용 호감도를 상승시키기 위한 추천 컨텐츠를 선정하여 상기 사용자 에게 제공할 수 있다. 본 발명의 다양한 실시 예는, 상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 호감도를 측정하는 방법에 있어서, 상기 방법은 카메라와 녹음장치를 통해 상기 사용자에 대한 음성 데이터 및 영상 데이터를 획득 하는 단계; 상기 음성 데이터 및 상기 영상 데이터로부터 상기 사용자의 내적 요인 및 외적 요인을 획득하는 단 계; 상기 내적 요인 및 상기 외적 요인으로부터 상기 상호작용 상대방에 대한 상기 상호작용 선호도를 측정하는 단계; 서버로부터 상기 상호작용 상대방의 상기 사용자에 대한 상호작용 선호도를 수신하는 단계; 및 상기 상호 작용 상대방의 상기 상호작용 선호도를 고려하여 상기 사용자의 상호작용 호감도를 측정하는 단계를 포함하는, 방법과 이를 기록한 컴퓨터 판독 가능한 저장 매체를 제공한다."}
{"patent_id": "10-2022-0026351", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 사용자가 상호작용을 하는 과정에서 수집된 대화 정보와 생체 정보를 고려함에 따라 사용자의 내적 요인과 외적 요인이 반영된 상호작용 선호도와 상호작용 호감도를 보다 정확히 측정할 수 있고, 보다 정확한 선 호도 기반 추천 서비스를 제공할 수 있다. 본 발명에 따르면 비대면/원격 환경에서 상호작용을 하면서도 상대방의 선호도와 관련된 피드백을 받을 수 있어 비대면 환경에서도 사회성을 길들일 수 있다. 나아가, 본 발명에 따르면 사람의 상호작용 선호도를 고려하여 인공지능의 대화 능력을 학습할 수 있어 보다 사 용자 친화적인 인고지능의 학습 및 개발이 가능하다."}
{"patent_id": "10-2022-0026351", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터"}
{"patent_id": "10-2022-0026351", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "당해 기술분야에 있어서의 통상의 지식을 가진 자가 명확하게 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0026351", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참고로 하여 본 발명의 실시 예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 도 1은 본 발명의 다양한 실시 예들에 따른 상호작용 상대방의 상호작용 호감도와 사용자의 상호작용 선호도를 측정하는 시스템을 나타낸 도면이다. 도 1을 참고하면, 본 발명의 다양한 실시 예들에 따른 상호작용 상대방의 상호작용 선호도와 사용자의 상호작용 호감도를 측정하는 시스템은 전자 장치, 유/무선 통신 네트워크, 서버를 포함할 수 있다. 이하에서, 상호작용 선호도는 사용자가 상호작용하면서 상대방에게 느끼는 호감의 정도를 나타내는 수치이 며, 상호작용 호감도는 사용자가 타인으로부터 얼마나 호감을 사는지를 나타내는 수치이다. 이 두 측정 값 은 서로 상호작용하며 측정될 수 있다. 전자 장치는, 유/무선 통신 네트워크를 통하여 서버로부터 사용자의 상호작용에 상응하는 추천 컨텐츠 데이터를 수신하여 사용자에게 제공하고, 서버에게 사용자의 상호작용 과정에서의행동 정보와 생체 정보를 수집하여 전송할 수 있는 단말 장치일 수 있다. 전자 장치는 퍼스널 컴퓨터, 셀룰러 폰, 스마트 폰 및 태블릿 컴퓨터 등과 같이, 정보를 저장할 수 있는 메모리, 정보의 송수신을 수행할 수 있는 송수신부, 정보의 연산을 수행할 수 있는 적어도 하나의 프로세서를 포함하는 전자 장치일 수 있다. 나아가, 전자 장치는 사용자의 신체에 착용되는 스마트 워치, 스마트 글래 스, 헤드 마운트 디스플레이(HMD)와 같은 웨어러블 디바이스일 수 있다. 전자 장치는 단말기 또는 사용자 단말기라 칭할 수 있다. 유/무선 통신 네트워크는, 전자 장치 및 서버가 서로 신호 및 데이터를 송수신할 수 있는 통신 경로를 제공할 수 있다. 유/무선 통신 네트워크는 특정한 통신 프로토콜에 따른 통신 방식에 한정되지 않 으며, 구현 예에 따라 적절한 통신 방식이 사용될 수 있다. 예를 들어, 인터넷 프로토콜(IP) 기초의 시스템으로 구성되는 경우 유/무선 통신 네트워크는 유무선 인터넷망으로 구현될 수 있으며, 전자 장치 및 서버 가 이동 통신 단말로서 구현되는 경우 유/무선 통신 네트워크는 셀룰러 네트워크 또는 WLAN(wireless local area network) 네트워크와 같은 무선망으로 구현될 수 있다. 서버는, 유/무선 통신 네트워크를 통하여 전자 장치에게 사용자의 상호작용에 상응하는 추 천 컨텐츠 데이터를 전송하고, 전자 장치로부터 사용자의 상호작용 과정에서의 행동 정보와 생체 정 보를 수집하여 수신할 수 있는 단말 장치를 의미할 수 있다. 서버는 정보를 저장할 수 있는 메모리, 정보의 송수신을 수행할 수 있는 송수신부, 정보의 연산을 수행할 수 있는 적어도 하나의 프로세서를 포함하는 전자 장치일 수 있다. 서버는 단일한 서버뿐만 아니라 복수의 서버가 하나의 서버군을 형성하는 경우도 함께 지칭할 수 있다. 복 수의 서버가 하나의 서버군을 형성하는 경우, 복수의 서버는 분산 컴퓨팅 또는 병렬 컴퓨팅을 통해 연산을 나누 어 처리할 수 있다. 도 2는 본 발명의 다양한 실시 예들에 따른 상호작용 상대방의 상호작용 호감도와 사용자의 상호작용 선호도를 측정하는 시스템을 나타낸 도면이다. 도 1과 중복되는 설명은 생략한다. 도 2를 참고하면, 본 발명의 다양한 실시 예들에 따른 상호작용 상대방의 상호작용 호감도와 사용자의 상호작용 선호도를 측정하는 시스템은 제1 전자 장치(110_1), 제2 전자 장치(110_2), 유/무선 통신 네트워크, 서 버를 포함할 수 있다. 제1 전자 장치(110_1)는 제1 사용자(100_1)에 대응하는 전자 장치이고, 제2 전자 장치(110_2)는 제2 사용 자(100_2)에 대응하는 전자 장치일 수 있다. 즉, 전자 장치(110_1)는 제1 사용자(100_1)의 행동 정보와 생 체 정보를 획득하고, 제1 사용자(100_1)에게 컨텐츠를 출력할 수 있다. 또한, 제2 전자 장치(110_2)는 제2 사용 자(100_2)의 행동 정보와 생체 정보를 획득하고, 제2 사용자(100_2)에게 컨텐츠를 출력할 수 있다. 이하에서, 제1 전자 장치(110_1)는 제1 단말기 또는 제1 사용자 단말기라 칭하고, 제2 전자 장치(110_2)는 제2 단말기 또 는 제2 사용자 단말기라 칭할 수 있다. 제2 사용자(100_2)는 실제 사람이 아니라 AI일 수도 있다. 유/무선 통신 네트워크는, 제1 전자 장치(110_1), 제2 전자 장치(110_2) 및 서버가 서로 신호 및 데 이터를 송수신할 수 있는 통신 경로를 제공할 수 있다. 이에 따라, 유/무선 통신 네트워크는 필요에 따라 제1 전자 장치(110_1)와 제2 전자 장치(110_2)가 서로에게 관련된 정보를 주고받을 수 있는 통로가 되어줄 수 있다. 서버는, 제1 사용자(100_1)와 제2 사용자(100_2)가 상호작용하는 경우에, 유/무선 통신 네트워크를 통하여 제1 전자 장치(110_1)와 제2 전자 장치(110_2)로부터 제1 사용자(100_1)와 제2 사용자(100_2) 각각에 상 응하는 행동 정보와 생체 정보를 수신하고, 제1 전자 장치(110_1)에 제2 사용자(100_2)와의 상호작용에 상응하 는 추천 컨텐츠 데이터를 전송하고, 제2 전자 장치(110_2)에 제1 사용자(100_1)와의 상호작용에 상응하는 추천 컨텐츠 데이터를 전송할 수 있다. 도 3은 본 발명의 다양한 실시 예들에 따른 전자 장치의 구성을 나타낸 블록도이다. 도 3을 참고하면, 본 발명의 다양한 실시 예들에 따른 전자 장치는 메모리, 송수신부, 프로세서 , 카메라, 녹음장치 및 출력장치를 포함할 수 있다. 전자 장치는, 직접 또는 서버의 연산을 통해, 전자 장치를 사용하는 사용자가 다른 사용자 와 상호작용하는 과정에서 수집된 데이터에 기초하여 사용자의 행동 정보와 생체 정보를 획득하고, 상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 호감도를 산출하고, 그에 대응하는 추천 컨 텐츠를 결정하여 출력하는 전자 장치를 의미할 수 있다. 메모리는 데이터를 영구적, 반영구적 또는 임시적으로 저장하는 다양한 저장 장치를 지칭할 수 있다. 예컨 대, 메모리에는 HDD(Hard Disk Drive), SSD(Solid State Drive), CD(Compact Disc), RAM(Random Access Memory), Rom(Read Only Memory) 등이 포함될 수 있다. 메모리는, 프로세서와 연결되고 프로세서의 동작을 위한 기본 프로그램, 응용 프로그램, 설정 정보, 프로세서의 연산에 의하여 생성된 정보 등의 데이터를 저장할 수 있다. 메모리는 휘발성 메모 리, 비휘발성 메모리 또는 휘발성 메모리와 비휘발성 메모리의 조합으로 구성될 수 있다. 그리고, 메모리 는 프로세서의 요청에 따라 저장된 데이터를 제공할 수 있다. 메모리는 송수신부에서 수신한 데이터, 카메라와 녹음장치에서 생성한 데이터, 프로세서 에서 생성되거나 처리된 데이터를 영구적으로 또는 임시로 저장할 수 있다. 예컨대, 메모리는 송수신 부를 통해 수신한 추천 컨텐츠, 카메라에서 생성한 영상 데이터, 녹음장치에서 생성한 음성 데 이터, 프로세서에서 생성한 연산 데이터 등을 저장할 수 있다. 송수신부는, 프로세서와 연결되어 데이터를 송수신하며, 다른 전자 장치 또는 서버 등의 외부 장치들과 데이터를 송수신할 수 있다. 송수신부의 전부 또는 일부는 송신기(transmitter), 수신기 (receiver), 송수신기(transceiver), 통신부(communication unit), 통신 모뎀(communication model) 또는 통신 회로(communication circuit)로 지칭할 수 있다. 송수신기는 유선 접속 시스템 및 무선 접속 시스템들인 IEEE(institute of electrical and electronics engineers) 802.xx 시스템, IEEE Wi-Fi 시스템, 3GPP(3rd generation partnership project) 시스템, 3GPP LTE(long term evolution) 시스템, 3GPP 5G NR(new radio) 시 스템, 3GPP2 시스템, 블루투스(Bluetooth) 등 다양한 무선 통신 규격 중 적어도 하나를 지원할 수 있다. 프로세서는, 본 발명에서 제안한 절차 및/또는 방법들을 구현하도록 구성될 수 있다. 프로세서는 데 이터 분석 알고리즘 또는 머신 러닝 알고리즘을 사용하여 결정되거나 생성된 정보에 기초하여, 전자 장치 의 적어도 하나의 실행 가능한 동작을 결정할 수 있다. 그리고, 프로세서는 전자 장치의 구성 요소들 을 제어하여, 결정된 동작을 수행할 수 있다. 이를 위해, 프로세서는 메모리의 데이터를 요청, 검색, 수신 또는 활용할 수 있고, 상기 적어도 하나의 실행 가능한 동작 중 예측되는 동작이나, 바람직한 것으로 판단 되는 동작을 실행하도록 전자 장치의 구성 요소들을 제어할 수 있다. 프로세서는 결정된 동작을 수행하기 위하여 서버와 같은 외부 장치와의 연계가 필요한 경우, 해당 외 부 장치를 제어하기 위한 제어 신호를 생성하고, 통신부를 통해 해당 외부 장치에 생성된 제어 신호를 전 송할 수 있다. 프로세서는 사용자 입력에 대하여 의도 정보를 획득하고, 획득한 의도 정보에 기초하여 사용자의 요 구 사항을 결정할 수 있다. 예컨대, 프로세서는 음성 입력을 문자열로 변환하기 위한 STT(Speech To Text) 엔진 또는 자연어의 의도 정보를 획득하기 위한 자연어 처리(NLP: Natural Language Processing) 엔진 중에서 적어도 하나 이상을 이용하여, 사용자 입력에 상응하는 의도 정보를 획득할 수 있다. STT 엔진 또는 NLP 엔진 중에서 적어도 하나 이상은 적어도 일부가 머신 러닝 알고리즘에 따라 학습된 인공 신경망으로 구성될 수 있다. 프로세서는 사용자의 행동 정보와 생체 정보의 기계 학습 분석에 기반하여 추천 컨텐츠를 제공하기 위하여 전자 장치의 전반적인 동작들을 제어한다. 예를 들어, 프로세서는 카메라와 녹음장치 를 통해 사용자에 대한 이미지 데이터와 음성 데이터를 획득하고, 미리 정해진 처리를 통해 행동 정 보와 생체 정보를 획득하며, 송수신부를 통해 서버에 행동 정보와 생체 정보를 전송하여 추천 컨텐츠 를 수신할 수 있고, 이 과정에서 메모리에 데이터를 기록하고 읽을 수 있다. 프로세서는 복수의 프로세서들로 구성될 수 있고, 인간의 뇌의 신경세포와 시냅스를 모하여 인공 신경망의 연산에 유리하게 설계된 뉴로모픽 프로세서(Neuromorphic processor) 등을 포함하여 구성될 수도 있다. 카메라는 이미지 센서에 의해 얻어지는 정지 영상 또는 동영상 등의 화상 프레임을 처리할 수 있다. 카메 라는 하나 또는 복수 개로 구성될 수 있다. 처리된 화상 프레임은 출력장치의 디스플레이(Display)에 표시되거나, 송수신부를 통해 외부 장치에 전송되거나, 프로세서에 의해 처리되거나, 메모리에 저장될 수 있다. 카메라는 RGB 센서를 포함하여 RGB 이미지를 획득할 수도 있다. 또한, 카메라는 IR 센서 또는 깊이 센서를 더 포함하여 IR 이미지 또는 Depth 이미지를 더 획득할 수도 있다. 카메라는 사용자의 얼굴을 포함하는 이미지를 획득할 수 있다. 실시 예에 따라, 카메라는 사용 자의 얼굴과 상반신을 포함하는 이미지를 획득할 수 있다. 녹음장치는 음파를 수신하여 전기적인 음성 데이터로 변환할 수 있으며, 녹음장치는 마이크로폰 (microphone)을 지칭할 수 있다. 변환된 음성 데이터는 전자 장치에서 수행 중인 기능(또는 실행 중인 응 용 프로그램)에 따라 다양하게 활용될 수 있다. 한편, 마이크로폰에는 외부의 음파를 수신하는 과정에서 잡음(noise)을 제거하기 위한 다양한 잡음 제거 알고리즘이 적용될 수 있다. 출력장치는 디스플레이 또는 스피커 하나 이상을 포함할 수 있다. 출력 장치는 프로세서의 제어 에 따라서 컨텐츠를 출력할 수 있다. 디스플레이는 전자 장치에서 처리되는 정보를 화상으로 표시할 수 있 다. 예컨대, 디스플레이는 전자 장치에서 구동되는 응용 프로그램의 실행화면 정보, 또는 이러한 실행화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 디스플레이는 터치 센 서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써 터치 스크린으로 구현되어 입력 인터페이스와 출력 인터페이스를 동시에 제공할 수 있다. 스피커는 전자 장치에서 처리된 오디오 데이터를 오디오 데이터를 음파로 출력할 수 있다. 출력장치는 메모리에 저장된 데이터, 프로세서에 의해 처리된 데이터, 송수신부를 통해 서 버로부터 데이터를 출력할 수 있다. 예컨대, 출력 장치는 서버로부터 수신하거나 프로세서(11 3)에 의해 처리되어 생성된 추천 컨텐츠, 상호작용 상대방에 대한 호감도와 선호도 등을 출력할 수 있다. 도 4는 본 발명의 다양한 실시 예들에 따른 서버의 구성을 나타낸 블록도이다. 도 4를 참고하면, 본 발명의 다양한 실시 예들에 따른 서버는 메모리, 송수신부 및 프로세서 를 포함할 수 있다. 서버는 전자 장치를 사용하는 사용자가 다른 사용자와 상호작용하는 과정에서 수집된 데이 터에 기초하여 사용자의 상호작용 상대방에 대한 상호작용 선호도와 사용자의 상호작용 선호도를 산 출하고, 그에 대응하는 추천 컨텐츠를 결정하는 서버를 의미할 수 있다. 메모리는 데이터를 영구적, 반영구적 또는 임시적으로 저장하는 다양한 저장 장치를 지칭할 수 있다. 예컨 대, 메모리에는 HDD(Hard Disk Drive), SSD(Solid State Drive), CD(Compact Disc), RAM(Random Access Memory), Rom(Read Only Memory) 등이 포함될 수 있다. 메모리는, 프로세서와 연결되고 프로세서의 동작을 위한 기본 프로그램, 응용 프로그램, 설정 정보, 프로세서의 연산에 의하여 생성된 정보 등의 데이터를 저장할 수 있다. 메모리는 휘발성 메모 리, 비휘발성 메모리 또는 휘발성 메모리와 비휘발성 메모리의 조합으로 구성될 수 있다. 그리고, 메모리 는 프로세서의 요청에 따라 저장된 데이터를 제공할 수 있다. 메모리는 송수신부에서 수신한 데이터, 프로세서에서 생성되거나 처리된 데이터를 영구적으로 또는 임시로 저장할 수 있다. 예컨대, 메모리는 송수신부를 통해 수신한 추천 컨텐츠, 프로세서(13 3)에서 생성한 연산 데이터 등을 저장할 수 있다. 송수신부는, 프로세서와 연결되어 데이터를 송수신하며, 전자 장치 또는 다른 서버 등의 외부 장치들과 데이터를 송수신할 수 있다. 송수신부의 전부 또는 일부는 송신기(transmitter), 수신기 (receiver), 송수신기(transceiver), 통신부(communication unit), 통신 모뎀(communication model) 또는 통신 회로(communication circuit)로 지칭할 수 있다. 송수신기는 유선 접속 시스템 및 무선 접속 시스템들인 IEEE(institute of electrical and electronics engineers) 802.xx 시스템, IEEE Wi-Fi 시스템, 3GPP(3rd generation partnership project) 시스템, 3GPP LTE(long term evolution) 시스템, 3GPP 5G NR(new radio) 시 스템, 3GPP2 시스템, 블루투스(Bluetooth) 등 다양한 무선 통신 규격 중 적어도 하나를 지원할 수 있다.프로세서는, 본 발명에서 제안한 절차 및/또는 방법들을 구현하도록 구성될 수 있다. 프로세서는 데 이터 분석 알고리즘 또는 머신 러닝 알고리즘을 사용하여 결정되거나 생성된 정보에 기초하여, 서버의 적 어도 하나의 실행 가능한 동작을 결정할 수 있다. 그리고, 프로세서는 서버의 구성 요소들을 제어하 여, 결정된 동작을 수행할 수 있다. 이를 위해, 프로세서는 메모리의 데이터를 요청, 검색, 수신 또 는 활용할 수 있고, 상기 적어도 하나의 실행 가능한 동작 중 예측되는 동작이나, 바람직한 것으로 판단되는 동 작을 실행하도록 서버의 구성 요소들을 제어할 수 있다. 프로세서는 결정된 동작을 수행하기 위하여 전자 장치와 같은 외부 장치와의 연계가 필요한 경우, 해 당 외부 장치를 제어하기 위한 제어 신호를 생성하고, 통신부를 통해 해당 외부 장치에 생성된 제어 신호 를 전송할 수 있다. 프로세서는 사용자 입력에 대하여 의도 정보를 획득하고, 획득한 의도 정보에 기초하여 사용자의 요 구 사항을 결정할 수 있다. 예컨대, 프로세서는 음성 입력을 문자열로 변환하기 위한 STT(Speech To Text) 엔진 또는 자연어의 의도 정보를 획득하기 위한 자연어 처리(NLP: Natural Language Processing) 엔진 중에서 적어도 하나 이상을 이용하여, 사용자 입력에 상응하는 의도 정보를 획득할 수 있다. STT 엔진 또는 NLP 엔진 중에서 적어도 하나 이상은 적어도 일부가 머신 러닝 알고리즘에 따라 학습된 인공 신경망으로 구성될 수 있다. 프로세서는 사용자의 행동 정보와 생체 정보의 기계 학습 분석에 기반하여 추천 컨텐츠를 제공하기 위하여 전자 장치와 서버의 전반적인 동작들을 제어한다. 예를 들어, 프로세서는 송수신부(13 2)를 통해 전자 장치로부터 사용자에 대한 이미지 데이터와 음성 데이터를 수신하고, 이미지 데이터 와 음성 데이터로부터 사용자의 행동 정보와 생체 정보를 획득하고, 획득한 사용자의 행동 정보와 생 체 정보로부터 사용자의 상호작용 선호도와 상호작용 호감도를 측정하고, 측정한 상호작용 선호도와 상호 작용 선호도를 고려하여 추천 컨텐츠를 결정하고, 송수신부를 통해 전자 장치에 추천 컨텐츠를 송신 할 수 있고, 이 과정에서 메모리에 데이터를 기록하고 읽을 수 있다. 프로세서는 복수의 프로세서들로 구성될 수 있고, 인간의 뇌의 신경세포와 시냅스를 모하여 인공 신경망의 연산에 유리하게 설계된 뉴로모픽 프로세서(Neuromorphic processor) 등을 포함하여 구성될 수도 있다. 도 5는 본 발명의 다양한 실시 예들에 따른 전자 장치의 동작 방법을 나타낸 동작 흐름도이다. 이하에서, 전자 장치는 제1 사용자(100_1)에 대응하는 제1 전자 장치(110_1)를 의미하고, 상호작용 상대방 은 제2 사용자(100_2)를 의미할 수 있다. 도 5를 참조하면, S501 단계에서, 전자 장치는 녹음장치와 카메라를 통해 사용자에 대한 음성 데이터와 영상 데이터를 획득한다. 음성 데이터는 사용자가 상호작용 상대방과 상호작용하는 과정에서 발화한 음성을 포함하며, 영상 데이터 는 사용자의 얼굴을 포함할 수 있다. S502 단계에서, 전자 장치는 사용자의 음성 데이터와 영상 데이터로부터 사용자의 내적 요인 및 외적 요인을 획득한다. 사용자의 내적 요인은 사용자의 생체 신호를 의미하며, 대표적으로 심박변이도(HRV: Heart Rate Variability)가 이에 포함된다. 사용자의 외적 요인에는 행동 정보, 감정 정보, 집중도 정보, 시선 정보가 포함된다. 행동 정보는 사용자가 현실 또는 메타버스 환경에서 다른 사용자와 상호작용하는 과정에서 발생 하는 정보를 의미할 수 있고, 상호작용 과정에서의 대화 시간, 대화 횟수 및 대화 내용의 긍부정도를 포함할 수 있다. 감정 정보는 상호작용 과정에서의 사용자의 감정과 집중도를 포함할 수 있다. 시선 정보는 사용자 의 시선 위치와 시선 고정 시간을 포함할 수 있다. 전자 장치는 원격 광혈류 측정(rPPG: Remote Photoplethysmography) 방식을 이용하여 이미지 데이터에 포 함된 사용자의 얼굴에서 광혈류량의 변화량을 측정하고, 측정한 광혈류량에 기초하여 심박 변이도를 측정 하고, 심박수의 고주파 영역과 저주파 영역을 구분하여 저주파 영역과 고주파 영역의 비율에 기초하여 스트레스 를 판단할 수 있다. 전자 장치는 음성 데이터로부터 대화 시간, 대화 횟수를 획득하고, 음성 분석 모델을 사용하여 대화를 하 는 동안 음성의 긍정/부정/중립의 감정을 분류할 수 있다. 또한, 전자 장치는 STT(Speech to Text) 엔진을이용하여 음성 데이터를 대화 텍스트로 변환하고, NLP(Natural Language Process) 엔진 등을 이용하여 대화 텍 스트로부터 대화 내용을 분석하며, 문맥 분석을 통해 대화 주제와 대화의 내용이 긍정적이었는지 부정적이었는 지를 나타내는 긍부정도를 판단할 수 있다. STT 엔진과 NLP 엔진은 인공 신경망으로 구성될 수 있으며, RNN(Recurrent Neural Network), LSTM(Long Short-Term Memory) 등을 포함할 수 있다. 전자 장치는 얼굴 인식 기술을 이용한 감정 분류 모델을 이용하여 이미지 데이터에 포함된 사용자 얼굴에 서 표정 기반한 감정을 분류한다. 감정의 분류는 긍정/부정/중립의 제1 유형 감정과, 즐거움/놀람/슬픔/화남/두 려움/불쾌함/덤덤함의 제2 유형 감정 각각에 대해 수행될 수 있다. 상술한 7종의 제2 유형 감정은 예시에 불과 하며, 실시 예에 따라 그 종류와 수가 다르게 설정될 수 있다. 감정 분류 모델은 인공신경망으로 구성되며, 입 력 데이터로 사용자 얼굴이 포함된 이미지 데이터가 입력되면, 그에 대한 출력으로 각 감정에 대한 확률을 출력 하는 모델일 수 있다. 예컨대, 감정 분류 모델은 CNN(Convolutional Neural Network)를 포함하는 인공 신경망 으로 구성될 수 있고, 이미지 데이터에서 얼굴 랜드마크를 추출하여 사용자의 감정을 추론하는 모델일 수 있다. 전자 장치는 얼굴 인식 기술과 원격 광혈류량 측정 기술을 사용하여 사용자의 심박수를 측정하고, 집 중도 판단 모델을 이용하여 심박수의 상태 변화 패턴으로부터 사용자의 집중도를 몰입/집중/보통으로 분류 할 수 있다. 집중도 판단 모델은 인공 신경망으로 구성되어, 심박수가 입력되면 그 출력으로 각 집중도로 분류 될 확률을 출력하는 모델일 수 있다. 전자 장치는 얼굴 인식 기술을 이용한 시선 추적 모델을 이용하여 이미지 데이터에 포함된 사용자 얼굴에 서 사용자의 시선을 추적한다. 시선 추적 모델은 사용자의 얼굴에서 눈동자 영역을 검출하고, 스크린 또는 카메라와 눈동자 사이의 보정 작업을 통해 동공의 움직임을 계산하고, 이를 바탕으로 상호작용을 하는 객 체의 영역과 시선이 머무르는 위치를 단위 시간별로 측정할 수 있다. 시선 추적 모델은 인공신경망으로 구성되 며, 입력 데이터로 사용자 얼굴이 포함된 이미지 데이터가 입력되면, 시선 위치, 시선 고정 시간, 상호작용에 대한 집중 여부 및 몰입 상태를 추론하는 모델일 수 있다. S503 단계에서, 전자 장치는 사용자의 내적 요인과 외적 요인에 기초하여 상호작용 상대방에 대한 선 호도를 측정한다. 전자 장치는 사용자의 내적 요인과 외적 요인 각 항목을 가중합하여 상호작용 상대방에 대한 선호도 를 측정할 수 있다. 내적 요소는 심리적 감정을 표현하는 의미를 내포하고 있으므로, 외적으로 보이는 변화보다 높은 가중치를 부여하여 내적 요소가 선호도를 측정하는데 더 많은 영향력을 미치는 요인으로 사용되도록 선호 도를 계산할 수 있다. S504 단계에서, 전자 장치는 서버를 통해 상호작용 상대방에 대한 사용자의 선호도를 송신하고, 사용자에 대한 상호작용 상대방의 선호도를 수신한다. 상술하였듯, 상호작용 상대방에 대한 사용자의 선호도는 사용자가 상호작용 상대방과 상호작용하는 과정에서 상대방에 대해 갖는 호감을 나타내며, 사용자에 대한 상호작용 상대방의 선호도는 상호작용 과정 에서 상호작용 상대방이 사용자에 대해 갖는 호감을 나타낸다. S505 단계에서, 전자 장치는 사용자에 대한 상호작용 상대방의 선호도를 고려하여 사용자의 상호작용 호감도를 측정한다. 전자 장치는 상호작용 상대방의 사용자에 대한 상호작용 선호도에 기초하여 사용자의 상호작용 호감도를 결정할 수 있다. 일 예로, 전자 장치는 사용자에 대한 상대방의 상호작용 선호도가 일정 기 준치 이상이면 사용자의 상호작용 호감도를 상향 조정하고, 그 반대의 경우에는 상용자의 상호작용 호감도를 하향 조정할 수 있다. 선호도/호감도 측정 결과는 실시간 알고리즘으로 반영되며, 사용자의 선호도/호감도에 대한 정보는 상호작 용을 통해 변화하는 결과를 확인할 수 있도록 정보를 제공할 수 있으나, 상호작용 상대방의 선호도의 경우 사람 의 심리를 눈으로 판단할 수 없는 것과 같이 정보를 보여주지 않을 수 있다. 사용자, 전자 장치 또는 서버는 호감도의 변화를 통해 더욱 좋은 상호작용 관계를 형성할 수 있는 정보를 확인할 수 있다. S506 단계에서, 전자 장치는 상호작용 상대방의 상호작용 선호도를 높이는 추천 컨텐츠를 선정하여 제공할 수 있다. 또는, 전자 장치는 사용자의 상호작용 호감도를 높이는 추천 컨텐츠를 선정하여 제공할 수 있다. 사용자의 호감도는 상호작용을 하는 상대방의 선호도에 영향을 받아 측정이 되므로, 사용자 간의 상호작용 시 개개인이 상호작용하는 대상과의 선호도를 높일 수 있는 대화 방법을 사용하도록 하는 것이 호감도를 올리는 데 효과적이다. 호감도를 높이기 위해 상대방의 관심사에 설정된 키워드 또는 상대방의 성격, 성별 등과 같은 개인정보의 내용을 상호작용시 대화의 주제로 추천을 해줌으로써, 상호간의 관심분야, 영역을 공유하며 대화의 선호도를 높일 수 있는 방법을 제안한다. 두 번 이상의 상호작용을 진행하는 사용자라면, 이전 상호작용의 대화 내용을 분석하여 상대방이 어떤 특정 주제 혹은 단어에서 선호도가 감소하는 추세를 보였는지에 대한 피드백 정 보를 제공하여 사용자가 상대방에 대한 배려하는 화법, 공감능력 등의 커뮤니케이션 스킬을 스스로 판단하는데 도움을 줄 수 있다. 최근 비대면/원격 환경이 도입되는 사례가 늘어남에 따라 유소년기 어린이들이 사회성을 기르기 어려워졌다. 본 발명에서 제시하는 방법은 아바타를 통한 상호작용 속에서도 상호작용 선호도와 호감도에 기초하여 추천 대화 내용을 제안받을 수 있어 사회성을 증진하기 위한 시스템으로 활용할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 상술한 S502 단계, S503 단계, S50 5단계 또는 S506 단계 중 적어도 일 부가 전자 장치가 아닌 서버에 의하여 수행될 수도 있다. 예컨대, 도 5에서는 전자 장치가 사용 자에 대한 음성 데이터와 영상 데이터로부터 사용자의 내적 요인 및 외적 요인을 획득(S502 단계)하는 것으로 설명되었으나, 인공지능 모델을 이용하는 가장 많은 연산이 필요한 단계이기에 이를 서버에서 수행할 수 있다. 이를 위해, 전자 장치는 사용자에 대한 음성 데이터와 영상 데이터를 서버에 전송하고, 서버는 음성 데이터와 영상 데이터로부터 사용자의 내적 요인과 외적 요인을 획득하며, 획 득한 내적 요인과 외적 요인을 전자 장치로 전송할 수 있다. 또는, 전자 장치는 오직 사용자에 대한 데이터를 수집하고 컨텐츠를 제공하기 위한 단말기로만 활용하고, 중요한 연산은 서버에서 수행하도 록 구현될 수 있으며, 이 경우 내적 요인과 외적 요인을 획득하는 단계(S502 단계), 선호도를 측정하는 단계 (S503 단계), 호감도를 측정하는 단계(S505 단계) 및 추천 컨텐츠를 선정하는 단계(S506 단계)가 모두 서버 에서 수행될 수 있다. 도 6은 본 발명의 다양한 실시 예들에 따른 생체 신호를 획득하는 방법의 일 예를 나타낸 도면이다. 도 6을 참조하면, 전자 장치 또는 서버는 원격 광혈류 측정(rPPG) 기법을 이용하여 사용자의 얼 굴을 포함하는 이미지 데이터로부터 심박수와 심박 변이도를 측정할 수 있다. rPPG는 혈액 속의 헤모글로빈이 적색광을 반사하고 녹색광을 흡수하는 원리를 이용하여 이미지 데이터만으로 비접촉식으로 심박 변이도를 측정 하는 기법이다. 전자 장치 또는 서버는 이미지 데이터에서 얼굴 영역을 추출하고, 얼굴 영역에서 RGB 이미지에서 G채 널(녹색 채널)만을 추출하고 FFT(Fast Fourier Transform)를 진행하여 주파수 영역으로 변환한다. 실시 예에 따 라, 밴드 패스 필터를 이용하여 저주파 영역과 고주파 영역을 배제할 수 있다. 그리고 NN 간격(N-N interval) 또는 RR 간격(R-R interval) 값을 통해 심박수와 심박 변이도를 측정할 수 있다. 전자 장치 또는 서버는 심박수를 고주파 영역(HF)과 저주파 영역(LF)으로 구분하며, 고주파 영역 대 비 저주파 영역의 비율(LF/HF ratio)로부터 사용자의 스트레스를 판단할 수 있다. 이는 사람이 스트레스를 받게 되면 교감 신경계가 활성화되어 심박수가 높아지는 현상을 보인다는 일반적인 연구 결과에 기초한 것이다. 실시 예에 따라, 고주파 영역 대비 저주파 영역의 비율(LF/HF ratio)를 대신하여 저주파 영역 대비 고주파 영역 의 비율(HF/LF ratio)를 사용할 수도 있다. 고주파 영역(HF)와 저주파 영역(LF)를 구분하는 심박수의 기준은 다양하게 설정될 수 있으며, 일 예로 심박수가 120BPM 이상인 구간을 고주파 영역(HF)으로, 그 이외 구간을 저주파 영역(LF)으로 구분할 수 있다. 전자 장치 또는 서버는 고주파 영역 대비 저주파 영역의 비율이 0.5에서 2.0 사이인 경우에는 스트레 스 수치가 평이한 상태인 것으로 판단하고, 그 이외의 경우에는 스트레스가 높다고 판단할 수 있다. 도 7은 본 발명의 다양한 실시 예들에 따른 사용자의 시선을 추적하는 방법의 일 예를 나타낸 도면이다. 도 7을 참조하면, 전자 장치 또는 서버는 사용자의 얼굴이 포함된 이미지 데이터에서 사용자 얼 굴을 인식하고, 얼굴에서 랜드마크를 인식할 수 있다. 그리고, 랜드마크 인식을 통해 눈과 눈동자 영역을 검출 하여 시선 방향을 판단할 수 있다. 추가로, 사용자의 얼굴 방향(head pose)을 추정하고, 이를 반영하여 시선 방향을 판단할 수 있다. 전자 장치 또는 서버는 사용자의 얼굴과 카메라, 그리고 디스플레이의 상대적 위치에 기초 하여, 사용자의 시선이 어느 지점을 바라보고 있는지 판단할 수 있고, 이를 위하여 사전에 캘리브레이션 작업이 수행될 수 있다. 도 8은 본 발명의 다양한 실시 예들에 따른 상호작용 선호도를 측정하는 과정을 나타낸 도면이다. 도 8을 참조하면, 사용자가 상호작용을 하는 과정에서 전자 장치는 음성 데이터와 이미지 데이터를 생성한다. 상술한 것과 같이, 음성 데이터와 이미지 데이터로부터 내적 요인과 외적 요인을 획득하는 것은 전자 장치에서 수행될 수도 있고, 서버에서 수행될 수도 있다. 전자 장치 또는 서버는 음성 데이터로부터 행동 정보를 획득하며, 행동 정보에는 대화 시간, 대화 횟 수, 그리고 대화 내용에 기초한 대화 긍부정도가 포함될 수 있다. 전자 장치 또는 서버는 이미지 데이터로부터 사용자의 표정 변화에 기초하여 감정 정보를 획득 하며, 감정 정보에는 긍정/부정/중립으로 분류되는 제1 유형 감정과 즐거움/놀람/슬픔/화남/두려움/불쾌함/덤덤 함으로 예시되는 감정들로 분류되는 제2 유형 감정이 포함될 수 있다. 전자 장치 또는 서버는 이미지 데이터로부터 사용자의 집중도 정보를 획득하며, 구체적으로 사 용자의 생체 신호와 시선 정보의 변화에 기초하여 사용자의 집중도를 몰입/집중/보통으로 분류할 수 있다. 전자 장치 또는 서버는 이미지 데이터로부터 사용자의 얼굴 방향과 눈동자 방향을 인식하여 시 선 정보를 획득할 수 있고, 시선 정보에는 시선 위치와 시선 고정 시간 등이 포함될 수 있다. 전자 장치 또는 서버는 이미지 데이터로부터 rPPG 기법을 이용하여 사용자의 심박 변이도를 포 함하는 생체 신호를 획득할 수 있고, 생체 신호로부터 고주파 영역(HF), 저주파 영역(LF) 그리고 스트레스 정보 를 획득할 수 있다. 전자 장치 또는 서버는 획득한 내적 요인과 외적 요인들의 가중합을 통해 상호작용 상대방에 대한 사 용자의 상호작용 선호도를 산출할 수 있다. 이를 위해 상술한 각 내적 요인들과 외적 요인들이 수치화될 수 있다. 도 9는 본 발명의 다양한 실시 예들에 따른 상호작용 선호도와 상호작용 호감도를 측정하는 과정을 나타낸 도면 이다. 도 9를 참조하면, 제1 사용자(100_1)와 제2 사용자(100_2)가 상호작용하는 경우에, 제1 전자 장치(110_1) 또는 서버는 제1 사용자(100_1)에 대한 내적 요인과 외적 요인을 수집하여 제2 사용자(100_2)에 대한 제1 사용 자(100_1)의 상호작용 선호도를 측정하고, 제2 전자 장치(110_2) 또는 서버는 제2 사용자(100_2)에 대한 내적 요인과 외적 요인을 수집하여 제1 사용자(100_1)에 대한 제2 사용자(100_2)의 상호작용 선호도를 측정할 수 있다. 개인의 상호작용 호감도는 다른 사용자들이 해당 개인에 대하여 어떠한 선호도를 갖고 있는지가 반영되어 결정 될 수 있다. 이에 따라, 제1 전자 장치(110_1) 또는 서버는 제1 사용자(100_1)에 대한 제2 사용자(100_ 2)의 상호작용 선호도를 고려하여 제1 사용자(100_1)의 상호작용 호감도를 측정하고, 제2 전자 장치(110_2) 또 는 서버는 제2 사용자(100_2)에 대한 제1 사용자(100_1)의 상호작용 선호도를 고려하여 제2 사용자(100_ 2)의 상호작용 호감도를 측정할 수 있다. 도 10은 본 발명에 따라 상호작용 선호도와 상호작용 호감도를 측정하는 과정의 예시를 나타낸 도면이다. 기존의 설명과 중복되는 설명은 생략한다. 도 10의 예시에서와 같이, 전자 장치 또는 서버는 제1 사용자(100_1) 및 제2 사용자(100_2) 각각의 상호작용 상대방에 대한 상호작용 선호도를 산출할 수 있다. 수집된 내적 요소와 외적 요소들을 확인하면, 제1 사용자(100_1)는 제2 사용자(100_2)와 상호작용하는 과정에서 다소 만족스럽지 않았음을 확인할 수 있다. 이는 제2 사용자(100_2)가 제1 사용자(100_1)와 상호작용하면서 제1 사용자(100_1)를 만족시키지 못하였음을 의미하며, 이러한 점은 제1 사용자(100_1)의 상호작용 선호도가 전반적 으로 낮은 수치를 유지하거나 급격하게 감소 구간이 나타나는 것으로 확인할 수 있다. 제1 사용자(100_ 1)는 제2 사용자(100_2)와 상호작용을 하면서 상호작용 선호도가 낮았기 때문에, 제2 사용자(100_2)의 상호작용 호감도는 하향 조정될 수 있다. 수집된 내적 요소와 외적 요소들을 확인하면, 제2 사용자(100_2)는 제1 사용자(100_1)와 상호작용하는 과정에서 만족스러웠음을 확인할 수 있다. 이는 제1 사용자(100_1)가 제2 사용자(100_2)와 상호작용하면서 제2 사용자 (100_2)를 만족시켰음을 의미하며, 이러한 점은 제2 사용자(100_2)의 상호작용 선호도가 전반적으로 높은 유지 하는 것으로 확인할 수 있다. 제2 사용자(100_2)는 제1 사용자(100_1)와 상호작용을 하면서 상호작용 선호도가 낮았기 때문에, 제1 사용자(100_1)의 상호작용 호감도는 상향 조정될 수 있다. 제2 전자 장치(110_2) 또는 서버는 제1 사용자(100_1)의 제2 사용자(100_2)에 대한 상호작용 선호도가 급 격하게 감소하는 구간에, 제2 사용자(100_2)에게 제1 사용자(100_1)의 선호도를 상승시킬 수 있는 추천 키워드 등을 제공하는 피드백을 제공할 수 있다. 도 11은 본 발명의 다양한 실시 예들에 따른 상호작용 상대방의 상호작용 호감도와 사용자의 상호작용 선호도를 측정하는 시스템을 나타낸 도면이다. 도 1과 중복되는 설명은 생략한다. 도 11을 참고하면, 본 발명의 다양한 실시 예들에 따른 상호작용 상대방의 상호작용 호감도와 사용자의 상호작 용 선호도를 측정하는 시스템은 제1 전자 장치(110_1), 유/무선 통신 네트워크, 서버 그리고 인공 지능(AI, 100_3)를 포함할 수 있다. 즉, 도 11은 제1 사용자(100_1)의 상호작용 상대방이 사람이 아닌 인공지능 (100_3)인 경우를 나타낸다. 인공지능(100_3)은 별도의 전자 장치로 구현될 수도 있고, 서버에 구현될 수도 있다. 인공지능(100_3)과 상호작용을 하게 되는 경우, 인공지능(100_3)은 상호작용 상대방에 대한 상호작용 선호도를 측정할 수 없지만, 사람인 상호작용 상대방의 상호작용 선호도에 기초하여 인공지능(100_3)의 호감도를 산출할 수 있다. 즉, 서버는 제1 사용자(100_1)와 인공지능(100_3) 사이에 상호작용하는 과정에서 제1 사용자 (100_1)의 인공지능(100_3)에 대한 상호작용 선호도에 기초하여 인공지능(100_3)의 호감도를 산출할 수 있다. 이를 통해 인공지능(100_3)의 상호작용 호감도를 상승시키는 방향으로 인공지능의 대화 능력을 학습시킬 수 있 다. 인간과의 소통을 위한 인공지능의 연구는 인간의 감정을 이해하고, 인간의 감정을 모방하는 것에서 시작하여 현 재, 인공지능의 행동에 적용하는 증강에 대한 초기 연구가 많이 진행되고 있다. 이러한 감성컴퓨팅의 핵심 목표 는 인간과의 자연스럽고 사회적인 소통과 이해를 달성하는 것이다. 이에 생체 신호 기반 선호도/호감도 측정 방 법을 적용하여, 감정증진 AI가 외적요인의 감정 변화뿐만 아니라 내적요인에 의한 감정의 변화를 인식하여 사용 자의 감정변화를 더욱 세밀하게 인지할 수 있다. 생체 신호 기반의 선호도/호감도 측정을 사용하여 생성된 피드 백을 적용하여, 단순히 명령을 주고받는 기계와 사람의 관계에서 벗어나, 더 나아가 사용자의 감정에 즉각, 세 밀하게 대응하고 원활한 소통이 가능한 감성 컴퓨팅 기술을 구현할 수 있다. 하드웨어를 이용하여 본 발명의 실시 예를 구현하는 경우에는, 본 발명을 수행하도록 구성된 ASICs(application specific integrated circuits) 또는 DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays) 등이 본 발명의 프로 세서에 구비될 수 있다. 한편, 상술한 방법은, 컴퓨터에서 실행될 수 있는 프로그램으로 작성 가능하고, 컴퓨터 판독 가능 매체를 이용 하여 상기 프로그램을 동작시키는 범용 디지털 컴퓨터에서 구현될 수 있다. 또한, 상술한 방법에서 사용된 데이 터의 구조는 컴퓨터 판독 가능한 저장 매체에 여러 수단을 통하여 기록될 수 있다. 본 발명의 다양한 방법들을 수행하기 위한 실행 가능한 컴퓨터 코드를 포함하는 저장 디바이스를 설명하기 위해 사용될 수 있는 프로그램 저장 디바이스들은, 반송파(carrier waves)나 신호들과 같이 일시적인 대상들은 포함하는 것으로 이해되지는 않 아야 한다. 상기 컴퓨터 판독 가능한 저장 매체는 마그네틱 저장매체(예를 들면, 롬, 플로피 디스크, 하드 디스크 등), 광학적 판독 매체(예를 들면, 시디롬, DVD 등)와 같은 저장 매체를 포함한다. 이상에서 설명된 실시 예들은 본 발명의 구성요소들과 특징들이 소정 형태로 결합된 것들이다. 각 구성요소 또 는 특징은 별도의 명시적 언급이 없는 한 선택적인 것으로 고려되어야 한다. 각 구성요소 또는 특징은 다른 구 성요소나 특징과 결합되지 않은 형태로 실시될 수 있다. 또한, 일부 구성요소들 및/또는 특징들을 결합하여 본 발명의 실시 예를 구성하는 것도 가능하다. 발명의 실시 예들에서 설명되는 동작들의 순서는 변경될 수 있다. 어느 실시 예의 일부 구성이나 특징은 다른 실시 예에 포함될 수 있고, 또는 다른 실시 예의 대응하는 구성 또 는 특징과 교체될 수 있다. 특허청구범위에서 명시적인 인용 관계가 있지 않은 청구항들을 결합하여 실시 예를 구성하거나 출원 후의 보정에 의해 새로운 청구항으로 포함시킬 수 있음은 자명하다. 본 발명이 본 발명의 기술적 사상 및 본질적인 특징을 벗어나지 않고 다른 형태로 구체화될 수 있음은 본 발명 이 속한 분야 통상의 기술자에게 명백할 것이다. 따라서, 상기 실시 예는 제한적인 것이 아니라 예시적인 모든 관점에서 고려되어야 한다. 본 발명의 권리범위는 첨부된 청구항의 합리적 해석 및 본 발명의 균등한 범위 내 가능한 모든 변화에 의하여 결정되어야 한다."}
{"patent_id": "10-2022-0026351", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 다양한 실시 예들에 따른 상호작용 상대방의 상호작용 호감도와 사용자의 상호작용 선호도를 측정하는 시스템을 나타낸 도면이다. 도 2는 본 발명의 다양한 실시 예들에 따른 상호작용 상대방의 상호작용 호감도와 사용자의 상호작용 선호도를 측정하는 시스템을 나타낸 도면이다. 도 3은 본 발명의 다양한 실시 예들에 따른 전자 장치의 구성을 나타낸 블록도이다. 도 4는 본 발명의 다양한 실시 예들에 따른 서버의 구성을 나타낸 블록도이다. 도 5는 본 발명의 다양한 실시 예들에 따른 전자 장치의 동작 방법을 나타낸 동작 흐름도이다. 도 6은 본 발명의 다양한 실시 예들에 따른 생체 신호를 획득하는 방법의 일 예를 나타낸 도면이다. 도 7은 본 발명의 다양한 실시 예들에 따른 사용자의 시선을 추적하는 방법의 일 예를 나타낸 도면이다. 도 8은 본 발명의 다양한 실시 예들에 따른 상호작용 선호도를 측정하는 과정을 나타낸 도면이다. 도 9는 본 발명의 다양한 실시 예들에 따른 상호작용 선호도와 상호작용 호감도를 측정하는 과정을 나타낸 도면 이다. 도 10은 본 발명에 따라 상호작용 선호도와 상호작용 호감도를 측정하는 과정의 예시를 나타낸 도면이다. 도 11은 본 발명의 다양한 실시 예들에 따른 상호작용 상대방의 상호작용 호감도와 사용자의 상호작용 선호도를 측정하는 시스템을 나타낸 도면이다."}
