{"patent_id": "10-2011-0104176", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2013-0039546", "출원번호": "10-2011-0104176", "발명의 명칭": "정밀한 제어를 위한 뇌-기계 인터페이스 장치 및 방법", "출원인": "서울대학교산학협력단", "발명자": "정천기"}}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "대상물 동작 정보를 포함하는 변환 뇌파 정보를 입력받고, 상기 변환 뇌파 정보로부터 대상물 동작 정보를 포함한 대상물 제어 정보를 추출하여 융합 제어부로 전달하는 뇌파 정보 처리부;목적물의 목적물 위치 정보를 포함한 목적물 정보를 입력받고, 상기 목적물 정보를 이용하여 대상물 동작 정보를 포함한 상기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하는 융합 제어부; 를 포함하는 뇌-컴퓨터 인터페이스 장치"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 대상물은 인공 팔, 마우스 커서, 디스플레이에 표시되는 응용 프로그램의 컨트롤 수단, 오디오 또는 비디오 재생 장치의 컨트롤 수단, 휠체어 및 자동차 중 어느 하나인 것을 특징으로 하는 뇌-컴퓨터 인터페이스 장치"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서, 인간의 뇌파 신호를 입력받고, 상기 입력받은 뇌파 신호를 대상물 동작 정보를 포함하는 변환 뇌파 정보로 변환하여 상기 뇌파 정보 처리부로 전달하는 뇌파 신호 변환부를 더 포함하는 뇌-컴퓨터 인터페이스 장치"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서, 뇌파 신호를 입력받고, 상기 뇌파 신호에서 잡음 신호를 제거한 후 상기 뇌파 신호 변환부로 전달하는 뇌파 신호 전처리부를 더 포함하는 뇌-컴퓨터 인터페이스 장치"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항 또는 제 3항에 있어서, 적어도 하나 이상의 목적물 후보들에 대한 목적물 위치 정보를 포함하는 목적물 정보를 입력받아 목적물을 결정하고, 상기 결정된 목적물의 목적물 정보를 융합 제어부로 전달하는 목적물 결정부를 더 포함하는 뇌-컴퓨터 인터페이스 장치"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서, 영상을 입력받고, 상기 입력된 영상에서 적어도 하나 이상의 목적물 후보들을 추출하며, 상기 입력된 영상을 이용해 상기 목적물 후보들의 목적물 위치 정보를 포함한 목적물 정보를 설정하여, 상기 목적물 정보를 목적물 결정부로 전달하는 영상 인식부를 더 포함하는 뇌-컴퓨터 인터페이스 장치"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2013-0039546-3-제 6항에 있어서, 상기 입력된 영상은 스테레오 카메라로부터 촬영된 스테레오 영상이고, 상기 목적물 위치 정보는 3차원 위치 정보인 것을 특징으로 하는 뇌-컴퓨터 인터페이스 장치"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "뇌-컴퓨터 인터페이스 장치에 사용되는 뇌-컴퓨터 인터페이스 방법에 있어서,대상물 동작 정보를 포함하는 변환 뇌파 정보를 입력받는 단계;상기 변환 뇌파 정보로부터 대상물 동작 정보를 포함한 대상물 제어 정보를 추출하는 단계;목적물에 대한 목적물 위치 정보를 포함하는 목적물 정보를 입력받는 단계;상기 목적물 정보를 이용하여 대상물 동작 정보를 포함한 상기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하는 단계; 를 포함하는 뇌-컴퓨터 인터페이스 방법"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서, 상기 대상물은 인공 팔, 마우스 커서, 디스플레이에 표시되는 응용 프로그램의 컨트롤 수단, 오디오 또는 비디오 재생 장치의 컨트롤 수단, 휠체어 및 자동차 중 어느 하나인 것을 특징으로 하는 뇌-컴퓨터 인터페이스 방법"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8항에 있어서, 상기 변환 뇌파 정보를 입력받는 단계 이전에, 뇌파 신호를 입력받고, 상기 입력받은 뇌파 신호를 대상물 동작정보를 포함하는 변환 뇌파 정보로 변환하는 단계를 더 포함하는 뇌-컴퓨터 인터페이스 방법"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서, 상기 변환 뇌파 정보로 변환하는 단계 이전에, 입력받은 상기 뇌파 신호에서 잡음 신호를 제거하는 단계를 더포함하는 뇌-컴퓨터 인터페이스 방법"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 8항 또는 제 10항에 있어서, 목적물 정보를 입력받는 단계 이전에, 적어도 하나 이상의 목적물 후보들에 대한 목적물 위치 정보를 포함한 목적물 정보를 입력받아 목적물을 결정하는 단계를 더 포함하는 뇌-컴퓨터 인터페이스 방법"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서, 적어도 하나 이상의 목적물 후보들에 대한 목적물 정보를 입력받는 단계 이전에, 영상을 입력받고, 상기 입력된영상에서 적어도 하나 이상의 목적물 후보들을 추출하며, 상기 입력된 영상을 이용해 상기 목적물 후보들의 목공개특허 10-2013-0039546-4-적물 위치 정보를 포함한 목적물 정보를 설정하는 단계를 더 포함하는 뇌-컴퓨터 인터페이스 방법"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서, 상기 입력된 영상은 스테레오 카메라로부터 촬영된 스테레오 영상이고, 상기 목적물 위치 정보는 3차원 위치 정보인 것을 특징으로 하는 뇌-컴퓨터 인터페이스 방법"}
{"patent_id": "10-2011-0104176", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 8항 내지 제 15항 중 어느 한 항의 뇌-컴퓨터 인터페이스 방법을 프로그램으로 기록한 컴퓨터로 판독 가능한매체명 세 서기 술 분 야본 발명은 제어 대상물의 정밀한 제어를 위한 뇌-컴퓨터 인터페이스 장치 및 방법에 관한 것이다. [0001]배 경 기 술뇌-기계 인터페이스기술 (뇌-컴퓨터 인터페이스 기술, 이하 BMI 기술이라 함)은 피험자의 생각만으로 컴퓨터나 [0002]기계를 제어하는 기술을 말한다. 최근 각 연구기관에서 BMI 기술의 중요성과 파급성을 인식하고 많은 투자를 하고 있는 이유는, BMI 기술을 통해 몸을 전혀 움직이지 못하는 전신마비환자도 자신의 의사를 표현하거나 물건을집어 옮기거나 이동수단을 제어할 수 있으므로, 그 활용성과 의미가 매우 필요하고 가치 있기 때문이다. 그뿐만아니라 BMI 기술은 일반인에게도 매우 유용하고 이상적인 유저 인터페이스 (UI) 기술로서 활용 가능한데, 텔레비전의 채널을 바꾸거나 에어컨의 온도를 조절하고 음악 볼륨을 조절하는 등 모든 전자기기제어에 활용될 수 있다. 또한, 게임기와 같은 엔터테인먼트분야, 군사용 또는 움직이기 어려운 노약자들에게도 적용될 수 있으므로,이 기술의 사회적, 경제적 파급효과는 매우 크다.BMI 기술을 구현하는 방법에는 여러 가지 방법이 사용될 수 있다. BMI 기술 연구 초창기에 사용되었던 방법으로 [0003]서 느린 피질전압 (Slow Cortical Potentials) 방법은, 주의나 집중에 의해 뇌파의 전위가 음이 되는 현상과 그렇지 않을 때 전위가 양의 값을 갖는 현상을 이용하여 상하(Top, Bottom) 구별 과 같은 1차원 작업 에서 전위가느리게 양이나 음의 값을 갖게 되는 현상을 이용하였다. 느린 피질전압 방법은 그 당시에는 생각으로 컴퓨터를제어할 수 있는 획기적 방법이었으나 반응이 느리고 고차원 구분이 불가능하기 때문에 현재는 거의 사용되고 있지 않다.다른 BMI 기술의 구현 방법으로서, 감각운동파 (Sensorimotor Rhythms)를 이용하는 방법은 가장 활발히 진행되 [0004]고 있는 연구방법 중 하나이다. 감각 운동파를 이용하는 BMI 기술은 1차 감각운동피질에서 움직임에 따라 μ파(8~12Hz)나 β파3~30Hz)가 증가하거나 감소하는 현상을 이용하는 방법으로 일반적으로 왼쪽과 오른쪽 두 가지경우를 구분하기 위해 많이 사용되어왔다. 감각 운동파의 증감을 이용한 방법으로서 독일 베를린의 연구그룹은 70~80%의 성공률로 마우스 커서를 제어하는 [0005]데 성공하였다 (Benjamin Blankertz et al., 2008). 하지만 상기 기술된 BMI 기술의 구현 방법은 좌우 두 가지를 구분하거나 상하좌우를 구분하는 정도로 미리 정해 [0006]공개특허 10-2013-0039546-5-진 선택지 상에서의 선택만이 가능하며, 인식률도 제한된 실험환경에서의 실험이기 때문에 실 생활에 사용하기위해서는 보다 안정적이고 인식률이 높은 BMI 기술이 필요하다.영국의 BCI Group이 2009년 Journal of Neural Engineering에 낸 논문을 보면, P300을 이용한 BMI 방법을 통해 [0007]80% 이상의 성공률을 보이는 타이핑 기술을 선보였다 (M. Salvaris et al, 2009). P300기반 BMI 기술이란 자극제시 후 300ms 이후쯤에 두정엽 영역에서 나타나는 positive peak를 이용하는 방법으로 순차적으로 여러 자극을보여주고, 피험자가 선택하려고 했던 자극에서 P300이 더 뚜렷이 나타나는 것을 이용하는 방법이다.또한 최근 주목받고 있는 방법 중 한 가지로 SSVEP (Steady-State Visually Evoked Potential)라는 기술이 있 [0008]다. 이 방법은 시각자극의 빈도수(주파수)에 따라 후두엽에서 해당 주파수의 세기가 증가하는 현상을 이용한 방법으로 상대적으로 신호 구분이 용이하며, 2차원 상에서 동시에 여러 자극 중 하나를 선택하는 것이 가능하다.일본의 RIKEN 연구소에서 2010년 Neuroscience Letters에 발표한 논문에 따르면 이 SSVEP 방법을 이용하여 8개의 방향 중 한 방향을 선택하는 방법의 마우스 커서 제어방법을 선보였다 (Hovagim Bakardjian et al., 2010).이렇듯 P300이나 SSVEP를 이용한 BMI 기술은 상대적으로 다양한 선택을 가능하게 하지만 여전히 실험 전 미리 [0009]정해놓은 몇 가지 선택사항 중 한 가지를 선택하는 것 외에는 할 수 없다는 단점이 있으며, 시각적 자극을 필요로 하기 때문에 컴퓨터상에서의 작업이 아닌 일상생활에서의 사용이 불가능한 문제점이 있다.또한, 뇌파만을 이용한 종래의 일반적인 BMI 기술로서는 뇌파로부터 피험자의 의사를 정확히 해독(Decoding)하 [0010]기 어려워 해당 뇌파를 이용하여 사물을 제어할 때 정확도가 떨어지는 문제점이 있다.발명의 내용해결하려는 과제본 발명이 이루고자 하는 기술적 과제는 뇌파를 이용하여 사물을 제어하는 뇌-컴퓨터 인터페이스 장치 및 방법 [0011]을 제공하는 데 있다.본 발명이 이루고자 하는 또 다른 기술적 과제는 뇌파를 이용하여 사물을 제어할 때 목적물의 정보를 이용하여 [0012]제어의 정확도를 높이는 뇌-컴퓨터 인터페이스 장치 및 방법을 제공하는 데 있다.본 발명이 이루고자 하는 또 다른 기술적 과제는 뇌파를 이용하여 사물을 제어할 때 영상인식을 이용하여 제어 [0013]의 정확도를 높이는 뇌-컴퓨터 인터페이스 장치 및 방법을 제공하는 데 있다. 본 발명이 이루고자 하는 또 다른 기술적 과제는 뇌파를 이용하여 사물을 제어할 때 영상인식을 이용하여 목적 [0014]물 결정의 정확도를 높이는 뇌-컴퓨터 인터페이스 장치 및 방법을 제공하는 데 있다. 과제의 해결 수단본 발명의 과제를 해결하기 위한 뇌-컴퓨터 인터페이스 장치에 따르면, 대상물 동작 정보를 포함하는 변환 뇌파 [0015]정보를 입력받고, 상기 변환 뇌파 정보로부터 대상물 동작 정보를 포함한 대상물 제어 정보를 추출하여 융합 제어부로 전달하는 뇌파 정보 처리부, 목적물의 목적물 위치 정보를 포함한 목적물 정보를 입력받고, 상기 목적물정보를 이용하여 대상물 동작 정보를 포함한 상기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하는 융합 제어부를 포함할 수 있다.공개특허 10-2013-0039546-6-또한 상기 뇌-컴퓨터 인터페이스 장치에서 상기 대상물은 인공 팔, 마우스 커서, 디스플레이에 표시되는 응용 [0016]프로그램의 컨트롤 수단, 오디오 또는 비디오 재생 장치의 컨트롤 수단, 휠체어 및 자동차 중 어느 하나일 수있다.또한 상기 뇌-컴퓨터 인터페이스 장치는 인간의 뇌파 신호를 입력받고, 상기 입력받은 뇌파 신호를 대상물 동작 [0017]정보를 포함하는 변환 뇌파 정보로 변환하여 상기 뇌파 정보 처리부로 전달하는 뇌파 신호 변환부를 더 포함할수 있다.또한 상기 뇌-컴퓨터 인터페이스 장치는 뇌파 신호를 입력받고, 상기 뇌파 신호에서 잡음 신호를 제거한 후 상 [0018]기 뇌파 신호 변환부로 전달하는 뇌파 신호 전처리부를 더 포함할 수 있다.또한 상기 뇌-컴퓨터 인터페이스 장치는 적어도 하나 이상의 목적물 후보들에 대한 목적물 위치 정보를 포함하 [0019]는 목적물 정보를 입력받아 목적물을 결정하고, 상기 결정된 목적물의 목적물 정보를 융합 제어부로 전달하는목적물 결정부를 더 포함할 수 있다.또한 상기 뇌-컴퓨터 인터페이스 장치는 영상을 입력받고, 상기 입력된 영상에서 적어도 하나 이상의 목적물 후 [0020]보들을 추출하며, 상기 입력된 영상을 이용해 상기 목적물 후보들의 목적물 위치 정보를 포함한 목적물 정보를설정하여, 상기 목적물 정보를 목적물 결정부로 전달하는 영상 인식부를 더 포함할 수 있다.또한 상기 뇌-컴퓨터 인터페이스 장치에서 상기 입력된 영상은 스테레오 카메라로부터 촬영된 스테레오 영상이 [0021]고, 상기 목적물 위치 정보는 3차원 위치 정보일 수 있다.본 발명의 과제를 해결하기 위한 뇌-컴퓨터 인터페이스 방법에 따르면, 대상물 동작 정보를 포함하는 변환 뇌파 [0022]정보를 입력받는 단계, 상기 변환 뇌파 정보로부터 대상물 동작 정보를 포함한 대상물 제어 정보를 추출하는 단계, 목적물에 대한 목적물 위치 정보를 포함하는 목적물 정보를 입력받는 단계 및 상기 목적물 정보를 이용하여대상물 동작 정보를 포함한 상기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하는 단계를 포함할수 있다.발명의 효과본 발명에 의하면, 피험자의 뇌파를 이용하여 뇌-컴퓨터 인터페이스가 가능하며 대상물을 제어할 수 있다. [0023]또한, 본 발명에 의하면 목적물 정보를 이용하여 뇌-컴퓨터 인터페이스에서 대상물 제어의 정확도를 높일 수 있 [0024]다.또한, 본 발명에 의하면 목적물의 영상 인식을 이용하여 뇌-컴퓨터 인터페이스에서 대상물 제어의 정확도를 높 [0025]일 수 있다.또한, 본 발명에 의하면 대상물 및 대상물의 상황을 고려하여 뇌-컴퓨터 인터페이스에서 목적물의 결정에 대한 [0026]정확도를 높일 수 있다.공개특허 10-2013-0039546-7-도면의 간단한 설명도 1은 본 발명인 뇌-컴퓨터 인터페이스 장치의 일 실시예이다. [0027]도 2는 본 발명인 뇌-컴퓨터 인터페이스 장치의 목적물이 디스플레이에 표시되는 응용 프로그램의 컨트롤 수단인 경우를 보여주는 일 실시예이다. 도 3은 본 발명인 뇌-컴퓨터 인터페이스 장치의 일 실시예이다.도 4는 본 발명인 뇌-컴퓨터 인터페이스 장치의 일 실시예이다.도 5는 본 발명인 뇌-컴퓨터 인터페이스 장치의 블록도를 나타내는 일 실시예이다.도 6은 입력된 영상의 영상 인식을 통해 목적물 정보를 파악하는 일 실시예이다.도 7, 도 8 및 도 9는 본 발명의 실시예들에 따른 뇌-컴퓨터 인터페이스 방법의 단계를 나타낸 순서도들이다.도 10은 입력된 영상의 영상 인식을 통해 목적물 정보를 파악하는 일 실시예이다.도 11은 입력된 스테레오 영상의 영상 인식을 통해 사물들의 깊이 정보를 파악하는 일 실시예이다.도 12는 대상물 동작 정보와 목적물 위치 정보 및 보정된 대상물 동작 정보의 일 실시예이다.발명을 실시하기 위한 구체적인 내용본 발명의 목적과 기술적 구성 및 그에 따른 작용 효과에 관한 자세한 사항은 본 발명의 명세서에 첨부된 도면 [0028]에 의거한 이하의 상세한 설명에 의해서 보다 명확하게 이해될 것이다. 첨부된 도면을 참조하여 본 발명에 따른실시예를 상세하게 설명한다.본 명세서에서 개시되는 실시예들은 본 발명의 범위를 한정하는 것으로 해석되거나 이용되지 않아야 할 것이다. [0029]이 분야의 통상의 기술자에게 본 명세서의 실시예를 포함한 설명은 다양한 응용을 갖는다는 것이 당연하다. 따라서, 특허청구범위에 의해 한정되지 않는 이상, 임의의 실시예는 본 발명을 보다 잘 설명하기 위한 예시적인것이며 본 발명의 범위가 실시예들로 한정되는 것을 의도하지 않는다.도 1은 피험자의 변환 뇌파 정보와 목적물 정보를 이용하여 대상물을 제어하는 뇌-컴퓨터 인터페이스 장치(13 [0030]0)의 일 실시예를 나타낸다. 도 1에 표시되고 아래에 설명되는 기능 블록들은 가능한 구현의 예들일 뿐이다. 다른 구현들에서는 상세한 설명의 사상 및 범위를 벗어나지 않는 범위에서 다른 기능 블록들이 사용될 수 있다.또한, 뇌-컴퓨터 인터페이스 장치(130)의 하나 이상의 기능 블록이 개별 블록들로 표시되지만, 뇌-컴퓨터 인터페이스 장치(130)의 기능 블록들 중 하나 이상은 동일 기능을 실행하는 다양한 하드웨어 및 소프트웨어 구성들의 조합일 수 있다.본 명세서에서 뇌파는 피험자의 뇌의 활성화 및 상태에 따라 변화되는 전기적 자기적 신호들을 의미한다. 실시 [0031]예를 보면, 뇌파 신호를 측정하는 방법에 따라 다음과 같은 뇌파 신호가 될 수 있다.EEG (Electroencephalogram)는 뇌전도를 의미하며, 사람 또는 동물의 대뇌에 일어나는 전위변동, 또는 그것에 [0032]의하여 일어나는 뇌전류(brain current)를 두피(頭皮) 상에서 유도하여 기록한 전기 기록 신호를 의미한다.MEG (Magnetoencephalogram)는 뇌자도를 의미하며, SQUID 센서 등으로 뇌신경세포의 전기적 활동에서 발생하는 [0033]미세한 생체 자기를 측정하여 기록한 신호를 의미한다. 공개특허 10-2013-0039546-8-ECoG (Electrocorticogram)는 피질전도를 의미하며, 대뇌에 일어나는 전위변동, 또는 그것에 의하여 일어나는 [0034]뇌전류(brain current)를 대뇌 피질(Cerebral Cortex)의 표면으로부터 전극을 심어 직접 측정하여 기록한 전기기록 신호를 의미한다.NIRS (Near-infrared spectroscopy) 는 근적외선 분광기를 의미하며, 본 발명에 쓰일 수 있는 NIRS 뇌파 신호 [0035]는 낮은 수준의 광파를 뇌에 비쳐 반사되어 나오는 차이를 측정하여 기록하는 신호를 의미한다.본 명세서에서는 EEG, MEG, ECoG 등의 뇌파 신호를 예로 들었지만, 뇌파 신호는 상기 특정 종류의 뇌파 신호에 [0036]한정되지 않고 인간의 뇌로부터 발생하여 인간의 두부(頭部, 머리)에서 측정 가능한 모든 신호들을 포함한다고볼 것이다.도 1을 참조하면, 뇌-컴퓨터 인터페이스 장치의 뇌파 정보 처리부(131)는 대상물 동작 정보를 포함하는 변환 뇌 [0037]파 정보를 입력받을 수 있다.대상물은 입력된 뇌파 신호 또는 변환 뇌파 정보가 측정된 피험자가 뇌파 신호 또는 변환 뇌파 정보를 이용하여 [0038]제어하려는 대상을 의미한다.본 발명에서 대상물은 특별히 한정되지 않으나, 예를 들면 인공 팔(151)(351), 디스플레이의 마우스 커서, 디스 [0039]플레이에 표시되는 응용 프로그램의 컨트롤 수단(235), 오디오 또는 비디오 재상 장치의 컨트롤 수단, 휠체어(153) 및 자동차 중에서 어느 하나가 될 수 있다.변환 뇌파 정보란, 피험자의 EEG, MEG, ECoG 등의 뇌파 신호로부터 대상물을 제어하기 위해 피험자가 의도하는 [0040]대상물에 관한 동작정보(대상물 동작정보)를 포함하는 정보들을 추출하고, 추출된 대상물에 관한 동작정보(대상물 동작정보)를 포함하여 구성된 정보를 말한다. 즉, 피험자의 EEG, MEG, ECoG 등의 뇌파 신호가 대상물 동작정보를 포함하고 컴퓨터 등 제어 장치가 인식 가능한 신호 형태의 정보로 변환된 것을 의미한다. EEG 뇌파 신호의 예를 들면 피험자의 두피에 부착된 전극(111) (311) (411)을 통해서 측정 가능하나, 이 밖에도 [0041]종래의 MEG, ECoG 뇌파 신호를 측정하는 방법으로도 포착 가능하다. 즉, EEG, MEG, ECoG, NIRS 등의 뇌활동 측정장비 중 어느 하나를 이용하여 뇌파 신호를 측정할 수 있다.측정된 뇌파 신호는 컴퓨터 등의 인터페이스 장치(113)를 통해 대상물 동작 정보를 포함하는 변환 뇌파 정보로 [0042]변환된 후 뇌파정보 처리부(131)로 입력될 수 있다. 상기 인터페이스 장치(113)의 일 예를 들면, 피험자의 EEG를 측정하고, 해당 EEG 뇌파 신호에 디지털 변환, 잡 [0043]음 처리 등의 전처리를 수행하고, 미리 설정된 특징벡터(Feature Vector)를 추출한 후에, 이 특징 벡터를 이용하여 회귀(Regression), 인공 신경망(Artificial Neural Network) 등의 인공 지능(Artificial Intelligence)기법을 적용하여 피험자가 의도하는 대상물 동작정보를 추출하고, 상기 대상물 동작 정보를 포함하여 변환 뇌파신호로 변환할 수 있다.대상물 동작 정보는 대상물의 동작을 나타내는 모든 정보를 의미한다. 일 예를 들면, 인공 팔(151)(351)(451)이 [0044]대상물인 경우, 대상물 동작 정보는 인공 팔의 현재 위치에서부터 목적지 위치까지의 벡터정보, 인공 팔의 이동속도에 대한 속도 정보 등의 동작을 위한 정보들을 포함할 수 있다.공개특허 10-2013-0039546-9-일 예를 들면, 상기 대상물 동작정보는 인공 팔이라는 대상물을 “위로 올린다”는 대상물 동작 정보가 될 수 [0045]있거나, 휠체어라는 대상물을 “앞으로 전진한다”라는 대상물 동작 정보가 될 수 있다. 이러한 대상물 동작 정보는 전자의 경우 “UP”이라는 미리 설정된 코드를 이용할 수 있고, 후자의 경우는 “FORWARD”라는 미리 설정된 코드를 이용해 대상물 동작 정보를 구성하고 이 정보를 포함한 정보를 뇌파 변환 정보로 구성할 수 있다. 다른 일 예를 들면 대상물 동작 정보는 대상물의 현재 위치에서부터 목적지 위치까지의 벡터정보를 포함해서 구 [0046]성될 수 있다. 예를 들어, 대상물이 인공 팔이고 인공 팔의 이동 벡터가 현재 인공 팔의 위치에서 X축 방향으로30 cm, Y축 방향으로 60 cm, Z축 방향으로 40 cm 이동하는 것이라면, 대상물 동작 정보는 “X:30-Y:60-Z:40”으로 구성될 수 있다.또한, 예를 들어 상기 대상물 동작 정보에 인공 팔의 이동 속도에 대한 속도 정보(예로서 속도는 80cm/min)가 [0047]포함된다면 대상물 동작 정보는 대상물의 이동 벡터와 함께 구성되어 “X:30-Y:60-Z:40, V:80”으로 구성될 수있다상기 속도 정보는 절대 속도 정보로써(예를 들어 80cm/min) 표현될 수도 있고, 또는 미리 설정된 속도의 등급 [0048]단위로써 구분하여 'FAST', 'SLOW', 'MEDIUM'으로 구성될 수도 있다.예를 들어, 대상물이 휠체어(153)이고 이를 빠른 속도로 앞으로 전진하는 것이 피험자의 의사로 판단되었다면, [0049]대상물 동작 정보는 미리 설정된 속도의 등급 단위로 구성될 수 있고, “FORWARD FAST”라는 대상물 동작 정보를 포함하는 변환 뇌파 정보로 구성될 수 있다.또한, 제어 장치에 연결된 대상물이 복수이며, 동시에 피험자가 제어 가능한 대상물이 복수인 경우에 대상물 동 [0050]작 정보와 피험자가 제어를 원하는 대상물이 무엇인지에 대한 정보도 함께 포함되어 변환 뇌파 정보를 구성할수 있다.제어 장치에 연결된 대상물이 복수이며, 동시에 피험자가 제어 가능한 대상물이 복수인 경우의 일 예를 들면 다 [0051]음과 같다.대상물이 인공 팔(151)이고 추출된 대상물 동작정보가 “UP”의 경우에, 인공 팔이라는 대상물의 대상물 코드를 [0052]“ARM”이라고 제어장치에 미리 설정했다면, 변환 뇌파 정보는 “ARM UP”이라는 대상물 코드와 대상물 동작정보를 포함하는 정보로 구성될 수 있다.대상물이 휠체어(153)이고 추출된 대상물 동작정보가 “FORWARD”의 경우에, 휠체어라는 대상물의 코드를 “ [0053]WHEELCHAIR”라고 제어장치에 미리 설정했다면, 변환 뇌파 정보는 “WHEELCHAIR FORWARD”라는 대상물 코드와대상물 동작정보를 포함하는 정보로 구성될 수 있다.변환 뇌파 정보는 앞에서 설명한 대상물에 관한 동작정보(대상물 동작정보)를 포함하여 구성된 정보를 의미하므 [0054]로, 변환 뇌파 정보에는 대상물 동작에 대한 정보뿐만 아니라 피험자의 ID, 성별, 나이 등의 정보도 포함될 수있다.따라서, 본 발명인 뇌-인터페이스 장치는 복수의 피험자로부터 검지된 뇌파신호가 변환된 복수의 뇌파 변환 정 [0055]공개특허 10-2013-0039546-10-보를 입력 받아, 다수의 대상물을 제어하는 것도 당연하다고 볼 것이다.뇌파 정보 처리부는 변환 뇌파 신호에서 상기 “ARM UP” 또는 “WHEELCHAIR FORWARD” 등의 대상물 동작 정보 [0056]를 포함하는 대상물 제어 정보를 추출하여 융합 제어부(133)로 전달한다.대상물 제어 정보란 변환 뇌파 정보로부터 대상물의 제어를 위해 대상물과 관련된 정보만을 추출한 것을 의미한 [0057]다. 예를 들어, 제어 장치에 연결된 대상물이 복수이며, 동시에 피험자가 제어 가능한 대상물이 복수이고, 변환 뇌 [0058]파 정보에 피험자의 ID(예를 들어 'A123'), 피험자의 성별(예를 들어 'MALE'), 대상물 코드(예를 들어 'ARM'),대상물 동작정보(예를 들어 'UP')로 구성되어 “A123-MALE-ARM-UP”인 경우에, 대상물 제어 정보는 피험자의 ID및 성별을 제외한 대상물 코드 및 대상물 동작정보를 추출하여 “ARM-UP”이 될 수 있다.융합 제어부(133)는 입력받은 목적물의 목적물 정보를 이용해 뇌파 정보 처리부에서 전달된 대상물 제어 정보를 [0059]보정한다. 상기 입력받은 목적물 정보는 적어도 하나 이상의 목적물에 대한 목적물 정보일 수 있다. 상기 목적물 정보는 목적물 위치 정보를 포함하며, 목적물 인식 정보를 포함할 수도 있다.목적물은 제어되는 대상물의 동작 목적이 되는 대상을 의미한다. 도 6을 참조하면, 인공 팔의 제어 최종 목적이 [0060]특정 A라는 컵(655)을 잡는 것이라면, 해당 A가 목적물이 될 수 있다. 휠체어의 이동 목표가 특정 B라는 지점이라면, 해당 B 지점이 목적물이 될 수 있다.목적물 위치 정보는 목적물의 3차원적 위치를 말하며, 영상 인식 및 근거리 통신 등을 통해서 파악된 목적물의 [0061]위치로 설정될 수 있다. 목적물 인식 정보는, 특정(Unique) 목적물 후보 또는 목적물 등의 사물을 서로 구별하기 위한 정보를 의미한다.예를 들어, 목적물 A의 위치가 제어 대상물인 인공 팔에서의 상대적인 3차원적 위치가 X축 방향으로 30 cm, Y축 [0062]방향으로 50 cm, Z축 방향으로 40 cm라면, 목적물 인식 정보와 목적물 위치 정보를 결합하여 “OBJECT-A, X:30-Y:50-Z:40”으로 목적물 A의 목적물 정보가 설정되어 입력될 수 있다.융합 제어부는 입력된 목적물의 목적물 정보를 이용하여 피험자의 변환 뇌파 정보로부터 추출된 대상물 제어 정 [0063]보를 보정하고 대상물 최종 제어 정보를 출력한다. 대상물 최종 제어 정보는 목적물 정보를 이용하여 대상물 제어 정보를 보정한 정보를 말한다. [0064]예를 들어, 추출된 대상물 제어 정보의 대상물 동작정보가 \"ARM-UP\"이고 목적물 A의 목적물 위치 정보가 \"X:30- [0065]Y:50-Z:40\"이라면, 대상물 제어 정보는 \"ARM-UP\"과 목적물 인식정보를 포함하는 목적물 정보 \"OBJECT-A, X:30-Y:50-Z:40\"를 포함하여 \"ARM-UP, OBJECT-A, X:30-Y:50-Z:40\"로 보정하여 대상물 최종 제어 정보를 설정할 수있다.또한, 예를 들어 제어부에 입력된 대상물 제어 정보의 대상물 동작정보가 현재 위치에서부터 목적지 위치까지의 [0066]이동 벡터정보를 포함해서 구성될 수 있다. 예를 들어, 대상물이 인공 팔이고, 인공 팔의 이동 벡터가 현재 인공 팔의 위치에서 X축 방향으로 30 cm, Y축 방향으로 60 cm, Z축 방향으로 40 cm 이동하는 것이라면, 대상물 동공개특허 10-2013-0039546-11-작 정보는 \"ARM, X:30-Y:60-Z:40\"으로 설정될 수 있다. 이 경우, 목적물 A의 목적물 위치 정보가 \"X:30-Y:50-Z:40\"이라면 대상물 제어 정보 \"ARM, X:30-Y:60-Z:40\"를 [0067]목적물 정보 \"OBJECT-A, X:30-Y:50-Z:40\"를 이용해 보정하게 되고, \"ARM, OBJECT-A, X:30-Y:50-Z:40\"로 보정하여 대상물 최종 제어 정보를 설정할 수 있다. 또는, 대상물 제어 정보의 대상물 동작 정보와 목적물 위치 정보의 중간 값으로 대상물 제어 정보를 보정하여, \"ARM, OBJECT-A, X:30-Y:55-Z:40\"로 대상물 최종 제어 정보를 설정할 수도 있다.또한, 복수의 목적물 A, B 에 대한 목적물 정보들이 입력되면, 복수의 목적물 A, B의 각 목적물 정보를 이용해 [0068]A, B의 중간 위치로 대상물 제어 정보를 보정하거나, A, B 중에서 대상물 제어정보의 이동 벡터위치에 보다 가까운 목적물 정보를 이용해 대상물 제어 정보를 보정하여 대상물 최종 제어 정보를 설정할 수 있다. 예를 들면, 대상물 제어 정보가 \"ARM, X:30-Y:60-Z:40\"이고 목적물 A 및 B의 목적물 정보인 \"OBJECT-A, X:30- [0069]Y:50-Z:40\", \"OBJECT-B, X:30-Y:70-Z:60\"를 이용해 보정하게 되면, 목적물 A와 B의 중간 위치인 \"X:30-Y:60-Z:50\"를 이용하여 대상물 제어 정보를 \"ARM, X:30-Y:60-Z:50\"로 대상물 최종 제어 정보를 설정할 수 있다.또는, 목적물이 복수인 경우 목적물 위치들의 단순 평균이 아닌 기하평균이나 산술 평균 등을 이용하여 대상물제어 정보를 보정할 수도 있다.또한, 측정값으로부터 예측된 값을 보정해주는 알고리즘인 칼만 필터 (Kalman filter)나 칼만필터의 비선형 시 [0070]스템 버전인 확장칼만필터 (Extended kalman filter), 언센티드 칼만 필터 (Unscented kalman filter), 파티클필터 (particle filter), 베이지안 필터 (Bayesian filter) 등을 적용하여 목적물 정보를 이용해 대상물 제어정보를 보정하여 대상물 최종 제어 정보를 설정할 수도 있다. 또한, 도 12에서처럼 목적물 정보의 목적물 위치 정보나 대상물 동작 정보는 단순한 숫자 값이 아닌 확률 값의 [0071]분포로도 표현될 수 있다. 예를 들어, 대상물 동작 정보의 X축 동작 정보는 X축 위치 변이에 따른 각 확률 값의분포(1201), 목적물 정보의 목적물 위치 정보는 X축 위치 변이에 따른 각 확률 값의 분포(1203)로 나타낼 수 있다. 이 경우 대상물 최종 제어 정보는 양 분포를 고려하여 대상물 제어 정보를 보정하게 되고, 역시 X축 위치변이에 따른 각 확률 값의 분포(1202)로 설정될 수 있다. 대상물 최종 제어 정보의 Y축, Z축에 대한 제어 정보도 마찬가지로 설정될 수 있다.대상물 최종 제어 정보는 대상물의 움직임과 이에 따른 변환 뇌파 정보로부터 추출된 대상물 제어 정보 변화 및 [0072]이에 따른 목적물 후보들의 목적물 정보 변화에 따라 계속 변화하여 설정될 수 있다.예를 들어, 대상물 제어 정보가 \"ARM, X:30-Y:60-Z:40\"이고 목적물 A의 목적물정보 \"OBJECT-A, X:30-Y:50- [0073]Z:40\"를 이용해 보정하는 경우, 대상물 제어 정보를 \"ARM, OBJECT-A, X:30-Y:50-Z:40\"로 보정하여 대상물 최종제어 정보를 설정한다. 따라서 대상물인 인공 팔을 목적물 A로 이동 벡터 X:30-Y:50-Z:40를 이용해 이동시키게되고, 이동 중에 피험자의 뇌파 신호가 변화하여 입력된 변환 뇌파 정보로부터 추출된 대상물 제어 정보가 변화할 수 있다. 변화된 대상물 제어 정보가 \"ARM, X:30-Y:20-Z:40\"이고, 입력된 목적물 정보가 목적물 B에 대한 정보로 변화되면, 목적물 B의 목적물 정보를 이용하여 대상물 제어 정보를 보정할 수 있고, 대상물 최종 제어 정보는 \"ARM, OBJECT-B, X:30-Y:30-Z:40\"로 변화되어 설정될 수 있다.또한, 측정값으로부터 예측된 값을 보정해주는 알고리즘을 사용할 경우, 대상물 제어 정보가 \"ARM, X:30-Y:60- [0074]Z:40\"이고 목적물 A의 목적물 정보 \"OBJECT-A, X:30-Y:50-Z:40\"를 이용해 보정하게 되면, 칼만 필터 등의 알고리즘의 적용에 따라 대상물 제어 정보를 \"ARM, X:30-Y:55-Z:40\"로 보정하여 대상물 최종 제어 정보를 설정할 수공개특허 10-2013-0039546-12-있다. 따라서 대상물인 인공 팔을 이동 벡터 X:30-Y:55-Z:40를 이용해 이동시키게 되고, 이동 중에 피험자의 뇌파 신호가 변화하여 입력된 변환 뇌파 정보로부터 추출된 대상물 제어 정보가 다시 변화할 수 있다. 변화된 대상물 제어 정보가 \"ARM, X:30-Y:20-Z:40\"이고 입력된 목적물 정보가 목적물 B에 대한 정보로 변화되면, 목적물B의 목적물 정보 \"OBJECT-B, X:30-Y:40-Z:40\"를 이용해 칼만 필터 등의 알고리즘의 적용에 따라 대상물 제어 정보를 보정할 수 있고, 대상물 최종 제어 정보는 \"ARM, X:30-Y:30-Z:40\"로 변화되어 설정될 수 있다.도 3을 참조하면, 뇌-컴퓨터 인터페이스 장치는 인간의 뇌파 신호를 입력받고, 상기 입력받은 뇌파 신호를 대상 [0075]물 동작 정보를 포함하는 변환 뇌파 정보로 변환하여 뇌파 정보 처리부로 전달하는 뇌파 신호 변환부(337)를 더포함할 수 있다.상기 뇌파 신호 변환부(337)는 입력된 뇌파신호 또는 잡음 제거 등의 전처리(Pre-processing) 과정을 거친 뇌파 [0076]신호에 대해 특징 추출(Feature Extract) 과정을 포함하는 신호 처리부, 추출된 특징을 이용해 대상물 동작 정보를 판단하는 과정을 포함하는 데이터 분류 및 판단부(Classification)를 포함할 수 있다. 입력된 뇌파신호 또는 잡음이 제거된 뇌파신호는 뇌파 신호 변환부의 신호 처리부로 전달될 수 있으며, 신호 처 [0077]리부에서는 사용자의 의도를 인지하기에 유용한 신호의 특징(Feature)들을 추출하게 된다. 여기에는 뇌파 신호를 특정 구간으로 잘라 신호 처리를 해줄 수 있도록 하는 에포킹 (Epoching) 과 사람 간 뇌파 신호의 차이와 사람 내 뇌파 신호의 차이를 줄여주기 위한 정규화 (Normalization), 오버피팅 (Over-fitting)을 막기 위한 다운샘플링 (Down Sampling)이 포함될 수 있다. 에포킹은 실시간 데이터 처리를 위한 것으로 수십 밀리초(milisecond)에서 초(second)단위로 사용될 수 있으며, 다운 샘플링은 20ms 정도의 간격이 적당하나 사람이나상황에 따라 수ms에서 수십ms 정도로 달라질 수 있다. 경우에 따라 퓨리에 변환 (Fourier Transform )이나 엔벨로프 (Envelope)을 구하는 신호처리가 포함될 수 있다.상기 데이터 분류 및 판단부는 뇌파 신호에 나타난 피험자의 의사를 파악하여 대상물에 대한 제어 형태를 판단 [0078]하게 된다. 구체적으로 보면, 데이터 분류 및 판단부는 데이터 학습과정을 통해 학습 데이터(Training Data)로부터 특징 파라미터 (Feature Parameter)를 결정하게 되며, 이렇게 결정된 특징 파라미터를 통해 새로운 데이터에 대하여 적절한 대상물 동작 정보를 결정할 수 있다. 학습데이터로부터 특징 파라미터를 결정하고 새로운 데이터에 대해 적절한 출력을 결정하기 위해 데이터 분류 및 판단부는 다중 선형 회귀 (Multiple LinearRegression), 서포트-벡터 회귀 (Support-Vector Regression) 등의 회귀방법이 사용될 수 있으며, 인공신경망(Neural-Network)이나 서포트-벡터 머신 (Support-Vector Machine) 등의 분류알고리즘이 적용될 수 있다.도 5를 참조하면 뇌-컴퓨터 인터페이스 장치는 뇌파 신호 전처리부(590)를 더 포함할 수 있다. 상기 뇌파 신호 [0079]전처리부(는 뇌파 신호를 입력받아 상기 뇌파 신호에서 잡음 신호를 제거한 후 뇌파 신호 변환부로 전달할 수있다.상기 뇌파 신호 전처리부(590)는 저역 통과 필터(Low-Pass Filter), 고역 통과 필터 (High-Pass Filter), 대역 [0080]통과 필터 (Band-Pass Filter), 노치 필터 (Notch Filter) 중 어느 하나를 포함할 수 있으며, 동시에 상기 뇌파 신호에 혼입되어 있는 잡음을 제거하기 위해 독립성분분석법(ICA)나 주성분분석법(PCA)을 수행하기 위한 부분이 포함될 수 있다.상기 잡음 신호는 뇌파 신호 이외의 신호를 말한다. 예를 들어, 일반적인 전송 경로(유, 무선 채널)에 따른 일 [0081]반적인 잡음(Noise Signal) 이외에도, EMG(Electromyogram, 근전도), EOG(Electrooculogram, 안전도) 등의 뇌파 신호 이외의 다른 생체 신호들도 관심 신호가 아니므로 잡음 신호로 취급하여 필터링 등을 통해서 제거할 수있다.공개특허 10-2013-0039546-13-도 4를 참조하면 뇌-컴퓨터 인터페이스 장치는 목적물 결정부(434)를 더 포함할 수 있다. 목적물 결정부는 적어 [0082]도 하나 이상의 목적물 후보들에 대한 목적물 위치 정보를 포함한 목적물 정보를 입력받아 목적물을 결정하고,상기 결정된 목적물의 목적물 정보를 융합 제어부로 전달할 수 있다.목적물 후보는 목적물로 결정될 수 있는 대상들을 의미한다. 목적물 후보는 영상 인식(Image Recognition), [0083]Zigbee, USN(Ubiquitous Sensor Network), RFID(Radio Frequency Identification), NFC(Near FieldCommunication) 등을 통해 파악될 수 있다.상기 목적물 정보는 목적물 위치 정보를 포함하며, 목적물 인식 정보를 포함할 수도 있다. 목적물 인식 정보는, [0084]특정(Unique) 목적물 후보 또는 목적물을 서로 구별하기 위한 정보를 의미한다. 예를 들어, 영상 인식 및 근거리 통신 등을 통해서 인공 팔의 동작 방향(또는 뇌파 신호가 측정되는 피험자가 바라보는 방향)에 A, B, C 세가지 사물들이 존재하고, 상기 A, B, C 세가지 사물들은 목적물 후보들로 인식될 수 있다. 이 경우, 미리 설정된A, B, C의 식별자인 “OBJECT-A”, “OBJECT-B”, “OBJECT-C”가 목적물 인식정보로 설정될 수 있으며, 영상인식 및 근거리 통신 등을 통해서 파악된 A, B, C 각 목적물 후보들의 위치가 목적물 위치 정보로 설정될 수 있다.도 3을 참조하면, 뇌파 신호가 측정되는 피험자가 바라보는 방향을 촬영한 영상의 자동 영상 인식을 통해 해당 [0085]영상에 사물이 A(391), B(393), C(395) 세 개가 있는 것으로 파악되면, 상기 사물 A, B, C를 목적물 후보로 인식할 수 있다.또한, 도 4를 참조하여 근거리 통신을 이용할 경우를 예로 들면, 각 사물들에 RFID용 전자 태그, NFC 태그, [0086]Zigbee 칩, USN 센서 등을 부착시켰을 경우에는 뇌파 신호가 측정되는 피험자 주변의 일정 범위에 존재하는 각사물들의 위치를 파악 가능하다. 따라서, 뇌파 신호가 측정되는 피험자의 위치나 제어하고자 하는 대상물의 위치 및 이동 방향 등을 고려하여 관련 있는 사물들(490)을 목적물 후보로 인식할 수 있다.상기 목적물 결정부는 뇌파 신호가 측정되는 피험자의 위치나 제어하고자 하는 대상물의 위치 및 이동 방향 등 [0087]을 고려하여 적어도 하나 이상의 목적물 후보들로부터 목적물을 결정할 수 있다.도 4를 참조하여 예를 들면, 근거리 통신 등을 통해서 파악된 사물 A(491), B(493), C(495)가 뇌파 신호가 측정 [0088]된 피험자의 주변 사물로 인식되었고, 그 중에서 피험자의 시각 방향과 제어하고자 하는 대상물의 방향을 고려하여 사물 A, B 가 목적물 후보로 인식되었을 경우를 고려해 볼 수 있다. 이 경우, 목적물 결정부는 목적물 후보들 중에서 대상물인 인공팔(451)의 현재 위치와 가장 가까운 목적물 후보를 최종 목적물로 판단하거나, 대상물의 현재 움직임 방향의 연장 직선 방향에 있는 목적물 후보를 최종 목적물로 판단할 수 있다.도 4를 참조하여 다른 예를 들면, 변환 뇌파로부터 추출된 대상물 제어 정보를 참조하고, 대상물의 이동 방향, [0089]속도를 고려하여 최종 목적물로 판단할 수 있다. 예를 들어, 대상물이 인공 팔이고 목적물 후보가 A, B, C이며대상물 제어 정보가 “X:10-Y:10-Z:00, V:10”인 경우를 살펴본다. 목적물 후보 A, B, C 모두가 대상물의 이동방향으로부터 일정 범위 내에 존재하더라도 대상물의 속도가 작은 경우는 보다 가까운 목적물 후보인 C를 최종목적물로 인식할 수 있고, 반대로 대상물의 속도가 큰 경우는 보다 멀리 있는 목적물 후보인 B를 최종 목적물로인식할 수 있다.도 4를 참조하여 다른 예를 들면, 대상물 제어 정보와 목적물 후보들의 목적물 위치 정보들을 고려할 경우, 복 [0090]공개특허 10-2013-0039546-14-수의 목적물 후보가 목적물로 결정될 수 있다. 예를 들어, 대상물이 인공 팔이고 목적물 후보가 A, B, C인경우, 대상물 제어 정보를 고려하면 목적물 후보 A, B가 모두 관련도가 유사하게 나올 경우 A, B 모두를 목적물로 결정할 수 있다. 이 경우, 시간에 따라 피험자로부터의 뇌파 신호 및 그로부터 변환된 변환 뇌파 신호는 변화하므로, 이에 따른 대상물의 움직임을 고려하여 최종적으로는 목적물이 하나로 결정될 수 있다. 도 10을 참조하여 다른 예를 들면, 피험자의 상황과 대상물을 고려하여 목적물 후보를 결정할 수도 있다. 예를 [0091]들어, 대상물이 자동차이고 입력된 영상에서 인식된 목적물 후보들이 다양하게 있는 경우(1010), 대상물이 자동차인 점을 고려하여 앞서 진행하는 자동차(1013) 또는 중앙선 표시는 목적물로 결정하지 않을 수 있다. 또는, 대상물이 휠체어이고 입력된 영상에서 인식된 목적물 후보들이 다양하게 있는 경우(1040), 대상물이 휠체 [0092]어인 점을 고려하여 도로에 있는 자동차(1045), 주변 사람(1042)은 목적물로 결정하지 않을 수 있다. 또는, 대상물이 디스플레이에 표시되는 동영상 프로그램의 볼륨이나 진행 컨트롤일 경우, 대상물을 고려하여 해 [0093]당 컨트롤과 관련 있는 레벨 표시(1021) 중에서만 목적물을 결정할 수도 있다.또한, 피험자로부터의 뇌파 신호 및 그로부터 변환된 변환 뇌파 신호와 주변 상황은 계속해서 변화할 수 있으므 [0094]로, 이에 따라 목적물 후보 및 결정된 목적물도 변화할 수 있는 것은 당연하다고 할 것이다.또한, 목적물 결정을 위해 상기 설명과 미리 설정된 기준에 적합한 목적물 후보를 목적물로 결정할 수도 [0095]있지만, 인공 신경망(Artificial Neural Network) 등의 인공 지능(Artificial Intelligence) 기법을 적용하여목적물 후보를 결정할 수도 있다. 도 3을 참조하면 뇌-컴퓨터 인터페이스 장치는 영상 인식부(335)를 더 포함할 수 있다. 영상 인식부는 영상을 [0096]입력받고, 상기 입력된 영상에서 적어도 하나 이상의 목적물 후보들을 추출하고, 목적물 후보들의 목적물 위치정보를 포함한 목적물 정보를 설정하여 목적물 결정부로 전달한다. 상기 목적물 정보는 목적물 인식 정보를 포함할 수도 있다.상기 영상 인식부는 외부 카메라(370)로부터 영상을 입력받을 수도 있고, 또는 다른 전송 장치를 통해서도 영상 [0097]을 입력받을 수 있다. 상기 입력되는 영상은, 뇌파 신호가 측정되는 피험자 주변의 영상이며, 특히 피험자의 고개가 향한 방향이나 시 [0098]선이 향한 방향의 주변 영상이 적합할 것이다.또한 도 10을 참조하면, 상기 입력되는 영상은 카메라를 이용하여 촬영된 영상(1010, 1040)에 한정하지 않으며, [0099]대상물에 따라 디스플레이의 캡쳐(Capture) 화면 영상(1020, 1030) 등 모든 영상이 입력될 수 있다.상기 영상 인식부(335)는 입력된 영상으로부터 파악된 사물의 위치와 형태에 대한 정보를 이용하여 목적물 후보 [0100]들의 목적물 인식 정보 및 목적물 위치 정보를 포함한 목적물 정보를 설정하여 목적물 결정부(334)로 전달할 수있다.상기 영상 인식부(335)는 입력된 영상에 대해 저주파 통과 필터링, 고주파 통과 필터링 등의 선형 공간 필터링 [0101]기법을 통한 영상처리 기법이나 최대 필터링, 최소 필터링 등의 비선형 공간 필터링이 포함하는 영상 전처리 과공개특허 10-2013-0039546-15-정을 수행할 수도 있다.상기 영상 인식부(335)는 입력된 영상에 대해 임계치로 영상을 양분화하는 방법 (Thresholding)이나 Harris [0102]corner detection, 차영상 혹은 색상 필터링과 같은 방법들을 조합하여 영상에 존재하는 사물의 형태를 구하고,K-means 알고리즘과 같은 비 교사 학습법 (Unsupervised Learning)을 이용하여 사물들을 클러스터링(Clustering)하는 영상처리기술을 적용하여 영상에 존재하는 사물의 위치를 파악할 수 있다.일 예를 들면, 도 6에서 목적물 후보는 입력된 영상에 대해 위에서 설명한 영상 처리 과정을 통해서 인식되는 [0103]필기구(653), 컵(655), 가위(657)가 목적물 후보가 될 수 있다. 따라서, 상기 인식된 필기구(653), 컵(655), 가위(657)들에 대한 목적물 인식 정보 및 목적물 위치 정보를 포함한 목적물 정보들이 설정되어 목적물 결정부(334)로 전달될 수 있다.또한, 상기 영상 인식부는 위에서 설명한 것처럼 입력된 영상에서 인식되는 모든 사물들을 목적물 후보로 인식 [0104]하여 목적물 정보를 설정할 수도 있지만, 피험자의 시각 방향과 제어하고자 하는 대상물의 방향 등의 여러 상황을 고려하여 인식된 사물들 중에서 일부만을 목적물 후보로 인식할 수도 있다. 목적물 후보들은 상황의 변화에 따라 재인식될 수 있음을 유념해야 한다. 예를 들어, 피험자의 뇌파 신호로부터 [0105]변환된 변환 뇌파 정보가 일정 시간 이전의 변환 뇌파 정보와 비교할 때 일정 값 이상의 변화를 보이거나, 피험자의 시각 방향이나 고개의 방향이 일정 범위 이상의 변화를 보이거나, 영상 인식 및 근거리 통신 등을 통해서파악된 사물들의 목적물 정보가 일정 값 이상의 변화를 보이는 등의 경우에는 목적물 후보들을 재인식 가능할것이다. 또는, 위에서 예로 든 각 경우를 별도로 구별하지 않고, 종합적으로 판단하여 피험자의 대상물 제어에 대한 목 [0106]적물이 변화되었다고 판단되는 경우에도 목적물 후보들을 재인식 가능할 것이다.위 설명과 같은 목적물 후보들의 파악을 위한 상황 변화 여부를 판단하기 위해서, 소정 값 이상의 변화를 상황 [0107]변화로 판단할 수도 있고, 인공 신경망(Artificial Neural Network) 등의 인공 지능(Artificial Intelligence)기법을 적용하여 상황 변화를 판단할 수도 있다.또한, 상기 영상 인식부는 도 6의 경우와 같은 사물들뿐만 아니라, 도 10에서 볼 수 있는 것처럼 도로의 차선 [0108]표시(1011, 1012), 디스플레이(1020)에 표시되는 응용 프로그램의 볼륨 또는 진행 조절 컨트롤 주위의 레벨표시(1021), 디스플레이(1030)에 표시되는 마우스 포인터의 주변 아이콘(1031)이나 클릭 가능한 개체(1032, 1033)등처럼 주변 배경과 다르게 구별 가능하다면 목적물 후보로 인식할 수 있다.또한, 상기 영상 인식부는 입력된 영상에 존재하는 사물들을 대상물의 상황을 고려하여 목적물 후보들로 인식할 [0109]수도 있다. 예를 들어 도 10에서 대상물이 자동차이고 도로를 주행하는 경우(1010)에, 대상물에 앞서 진행하는다른 자동차(1013), 진행 차선 표시(1012)를 사물로 인식 가능하지만, 대상물인 자동차의 주행 상황을 고려하여전방의 자동차가 너무 근거리이거나 대상물이 자동차라는 점을 고려하여 목적물 후보로 인식하지 않을 수 있다.이와 비슷하게, 도 10에서 대상물이 휠체어이고 보도를 진행하는 경우(1040)에, 주변 사물로 버스 정류장 표시 [0110](1041), 보도에 서 있는 사람(1042), 차도의 자동차(1045) 등을 사물로 인식 가능하지만, 휠체어가 대상물이라는 점을 고려하여 보도에 서 있는 사람, 차도의 자동차는 목적물 후보로 인식하지 않을 수 있다.공개특허 10-2013-0039546-16-또한, 이 경우에도 입력된 영상과 대상물의 상황을 고려하여, 다른 자동차의 번호판은 자동차(1013)를 목적물 [0111]후보로 인식함으로써 충분히 목적을 달성할 수 있으므로, 주변 배경과 다르게 구별 가능함에도 불구하고 목적물후보로 인식하지 않을 수 있다. 도 3을 참조하면 뇌-컴퓨터 인터페이스 장치는 영상 인식부(335)에서 스테레오 카메라로부터 촬영된 스테레오 [0112]이미지를 입력 받고, 상기 스테레오 이미지로부터 추출된 사물들의 3차원 위치 정보를 이용하여 목적물 위치 정보를 포함한 목적물 정보를 설정할 수 있다.도 11을 참조하면, 영상 인식부는 스테레오 영상에 대해 영상 정합(Image Matching) 등의 기술을 통해 사물의 [0113]깊이 정보를 구하여(1103) 사물의 3차원 위치정보를 얻고, 이를 이용해 목적물 위치 정보를 포함한 목적물 정보를 설정할 수 있다.뇌-컴퓨터 인터페이스 장치의 대상물은 인공 팔, 마우스 커서, 디스플레이에 표시되는 응용 프로그램의 컨트롤 [0114]수단, 오디오 장치의 컨트롤 수단, 휠체어 및 자동차 중 어느 하나일 수 있다.도2를 참조하면, 디스플레이(210)에 표시되는 응용 프로그램(230)이 동영상 재생프로그램이거나 음악 재생 프로 [0115]그램일 경우, 대상물은 상기 프로그램들에서 각각 볼륨 컨트롤 수단 또는 재생 진행 컨트롤 수단(235)일 수 있다.도 7에 나타난 본 발명의 실시예에 따른 뇌-컴퓨터 인터페이스 방법은, 변환 뇌파 정보를 입력받는 단계(710), [0116]대상물 제어 정보를 추출하는 단계(750), 목적물 정보를 입력받는 단계(720), 상기 목적물 정보를 이용하여 상기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하는 단계(790)를 포함한다.변환 뇌파정보를 입력받는 단계(710)는 대상물 동작 정보를 포함하는 변환 뇌파 정보를 입력받는 단계이다. [0117]대상물 제어 정보를 추출하는 단계(750)는 상기 변환 뇌파 정보로부터 대상물 인식 정보 및 대상물 동작 정보를 [0118]포함한 대상물 제어 정보를 추출하는 단계이다. 피험자로부터 측정된 뇌파 신호들에서 피험자가 의도하는 대상물에 관한 동작정보(대상물 동작정보)를 추출하여 구성한 변환 뇌파 정보로부터 대상물 제어 정보를 추출한다. 목적물 정보를 입력받는 단계(720)는 목적물의 목적물 위치 정보를 포함한 목적물 정보를 입력받는다. 상기 목 [0119]적물은 목적물 후보가 아닌 최종 목적물을 의미하며, 입력받는 목적물 정보는 적어도 하나 이상의 목적물에 대한 목적물 정보일 수 있다. 또한, 상기 목적물 정보는 목적물 인식 정보를 포함할 수도 있다.목적물 정보를 이용하여 상기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하는 단계(790)는 입력 [0120]된 목적물 정보를 이용하여 상기 대상물 제어 정보를 보정한다. 목적물 정보의 목적물 위치 정보나 대상물 동작 정보는 명확한 숫자 값이 아닌 도 12에서처럼 확률 값의 분포로 [0121]도 표현될 수 있다. 이 경우 대상물 최종 제어 정보는 양 분포를 고려하여 대상물 제어 정보를 보정할 수 있다.대상물 최종 제어 정보는 대상물의 움직임과 이에 따른 변환 뇌파 정보로부터 추출된 대상물 제어 정보 변화 및 [0122]이에 따른 목적물 후보들의 목적물 정보 변화에 따라 계속 변화하여 설정될 수 있다.공개특허 10-2013-0039546-17-도 8에 나타난 본 발명의 실시예에 따른 뇌-컴퓨터 인터페이스 방법은, 뇌파 신호를 입력받는 단계(810), 변환 [0123]뇌파 정보로 변환하는 단계(830), 목적물 후보들에 대한 목적물 정보를 입력받는 단계(820), 목적물을 결정하는단계(840)를 더 포함한다.뇌파 신호를 입력받는 단계(810)는 피험자로부터 측정된 EEG, MEG 등의 뇌파 신호를 입력받는다. [0124] [0125]변환 뇌파 정보로 변환하는 단계(830)는 입력된 뇌파 신호로부터 대상물 동작 정보 등을 판단하여 변환 뇌파 정 [0126]보로 변환한다.목적물 후보들에 대한 목적물 정보를 입력받는 단계(820)는 피험자 주변이나 대상물 주변에 존재하는 목적물 후 [0127]보들의 목적물 위치 정보를 포함하는 목적물 정보를 입력받는다. 또한, 상기 목적물 정보는 목적물 인식 정보를포함할 수도 있다. 목적물을 결정하는 단계(840)는 적어도 하나 이상의 목적물 후보들에 대한 목적물 정보들 중에서 대상물의 제어 [0128]에 대한 목적물을 결정한다. 상기 결정되는 목적물은 적어도 하나 이상의 목적물일 수 있다.상기 변환 뇌파 정보로 변환하는 단계(830)는 입력된 뇌파신호 또는 잡음 제거 등의 전처리(Pre-processing) 과 [0129]정을 거친 뇌파신호에 대해 특징 추출(Feature Extract) 과정을 포함하는 신호 처리 과정, 추출된 특징을 이용해 대상물 동작 정보를 판단하는 과정을 포함하는 데이터 분류 및 판단(Classification) 과정을 포함할 수있다.도 9에 나타난 본 발명의 실시예에 따른 뇌-컴퓨터 인터페이스 방법은, 영상을 입력 받는 단계(920), 목적물 후 [0130]보들에 대한 목적물 정보를 추출하는 단계(940)를 더 포함한다.영상을 입력 받는 단계(920)는 피험자 주변이나 대상물 주변에 존재하는 사물들에 대한 영상을 입력 받는다. [0131]상기 입력되는 영상은, 뇌파 신호가 측정되는 피험자 주변의 영상이며, 특히 피험자의 고개가 향한 방향이나 시 [0132]선이 향한 방향의 주변 영상이 적합할 것이다.목적물 후보들에 대한 목적물 정보를 추출하는 단계(940)는 입력된 영상으로부터 영상 전처리 과정이나 사물들 [0133]을 클러스터링(Clustering)하는 영상 처리 기술들과 입력된 영상으로부터 파악된 사물의 위치와 형태에 대한 정보를 이용하여 목적물 후보들의 목적물 위치 정보를 포함한 목적물 정보를 추출할 수 있다. 또한, 상기 목적물정보는 목적물 인식 정보를 포함할 수도 있다.상기 입력된 영상은 스테레오 카메라로부터 촬영된 스테레오 영상이고, 상기 목적물 위치 정보는 스테레오 영상 [0134]으로부터 얻어진 깊이 정보를 이용하여 생성된 3차원 위치 정보일 수 있다.본 발명의 이해를 돕기 위해 설명된 실시예들에서 사용된 특정 용어들이 본 발명을 한정하는 것은 아니다. 본 [0135]발명은 통상의 기술자들에게 당연한 모든 구성 요소 및 동등한 가치를 갖는 모든 구성 요소를 포함할 수 있다.공개특허 10-2013-0039546-18-부호의 설명110: 뇌파 신호를 측정하는 전극을 부착한 피험자 및 뇌파 신호 변환 인터페이스 [0136]130: 뇌-컴퓨터 인터페이스 장치 150: 대상물들 151: 인공 팔 153: 휠체어210: 디스플레이 화면230: 디스플레이에 표시된 응용 프로그램235: 디스플레이에 표시된 응용 프로그램의 컨트롤237: 디스플레이에 표시된 응용 프로그램의 컨트롤 레벨310: 뇌파 신호를 측정하는 전극을 부착한 피험자 330: 뇌-컴퓨터 인터페이스 장치 370: 스테레오 영상 카메라390: 목적물들410: 뇌파 신호를 측정하는 전극을 부착한 피험자430: 뇌-컴퓨터 인터페이스 장치497: NFC, ZigBee 등의 센서610: 뇌-컴퓨터 인터페이스 장치에 입력된 영상1201: 대상물 동작 정보1202: 보정된 대상물 동작 정보1203: 목적물 위치 정보공개특허 10-2013-0039546-19-도면도면1도면2공개특허 10-2013-0039546-20-도면3공개특허 10-2013-0039546-21-도면4도면5공개특허 10-2013-0039546-22-도면6도면7공개특허 10-2013-0039546-23-도면8공개특허 10-2013-0039546-24-도면9공개특허 10-2013-0039546-25-도면10도면11공개특허 10-2013-0039546-26-도면12공개특허 10-2013-0039546-27-"}
{"patent_id": "10-2011-0104176", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 대상물 동작 제어를 위한 뇌-컴퓨터 인터페이스 장치 및 방법에 관한 것으로서, 대상물 동작 정보를 포함하는 변환 뇌파 정보를 입력받고, 상기 변환 뇌파 정보로부터 대상물 동작 정보를 포함한 대상물 제어 정보 를 추출하여 융합 제어부로 전달하는 뇌파 정보 처리부와 목적물의 목적물 위치 정보를 포함한 목적물 정보를 입 력받고, 상기 목적물 정보를 이용하여 대상물 동작 정보를 포함한 상기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하는 융합 제어부를 포함한다. 본 발명에 따르면 목적물 정보를 이용하여 뇌-컴퓨터 인터페이스 장치 및 방법에서 대상물 제어의 정확도를 높일 수 있다."}
{"patent_id": "10-2011-0104176", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 제어 대상물의 정밀한 제어를 위한 뇌-컴퓨터 인터페이스 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2011-0104176", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "뇌-기계 인터페이스기술 (뇌-컴퓨터 인터페이스 기술, 이하 BMI 기술이라 함)은 피험자의 생각만으로 컴퓨터나 기계를 제어하는 기술을 말한다. 최근 각 연구기관에서 BMI 기술의 중요성과 파급성을 인식하고 많은 투자를 하 고 있는 이유는, BMI 기술을 통해 몸을 전혀 움직이지 못하는 전신마비환자도 자신의 의사를 표현하거나 물건을 집어 옮기거나 이동수단을 제어할 수 있으므로, 그 활용성과 의미가 매우 필요하고 가치 있기 때문이다. 그뿐만 아니라 BMI 기술은 일반인에게도 매우 유용하고 이상적인 유저 인터페이스 (UI) 기술로서 활용 가능한데, 텔레 비전의 채널을 바꾸거나 에어컨의 온도를 조절하고 음악 볼륨을 조절하는 등 모든 전자기기제어에 활용될 수 있 다. 또한, 게임기와 같은 엔터테인먼트분야, 군사용 또는 움직이기 어려운 노약자들에게도 적용될 수 있으므로, 이 기술의 사회적, 경제적 파급효과는 매우 크다. BMI 기술을 구현하는 방법에는 여러 가지 방법이 사용될 수 있다. BMI 기술 연구 초창기에 사용되었던 방법으로 서 느린 피질전압 (Slow Cortical Potentials) 방법은, 주의나 집중에 의해 뇌파의 전위가 음이 되는 현상과 그 렇지 않을 때 전위가 양의 값을 갖는 현상을 이용하여 상하(Top, Bottom) 구별 과 같은 1차원 작업 에서 전위가 느리게 양이나 음의 값을 갖게 되는 현상을 이용하였다. 느린 피질전압 방법은 그 당시에는 생각으로 컴퓨터를 제어할 수 있는 획기적 방법이었으나 반응이 느리고 고차원 구분이 불가능하기 때문에 현재는 거의 사용되고 있 지 않다. 다른 BMI 기술의 구현 방법으로서, 감각운동파 (Sensorimotor Rhythms)를 이용하는 방법은 가장 활발히 진행되 고 있는 연구방법 중 하나이다. 감각 운동파를 이용하는 BMI 기술은 1차 감각운동피질에서 움직임에 따라 μ파 (8~12Hz)나 β파3~30Hz)가 증가하거나 감소하는 현상을 이용하는 방법으로 일반적으로 왼쪽과 오른쪽 두 가지 경우를 구분하기 위해 많이 사용되어왔다. 감각 운동파의 증감을 이용한 방법으로서 독일 베를린의 연구그룹은 70~80%의 성공률로 마우스 커서를 제어하는 데 성공하였다 (Benjamin Blankertz et al., 2008). 하지만 상기 기술된 BMI 기술의 구현 방법은 좌우 두 가지를 구분하거나 상하좌우를 구분하는 정도로 미리 정해 진 선택지 상에서의 선택만이 가능하며, 인식률도 제한된 실험환경에서의 실험이기 때문에 실 생활에 사용하기 위해서는 보다 안정적이고 인식률이 높은 BMI 기술이 필요하다. 영국의 BCI Group이 2009년 Journal of Neural Engineering에 낸 논문을 보면, P300을 이용한 BMI 방법을 통해 80% 이상의 성공률을 보이는 타이핑 기술을 선보였다 (M. Salvaris et al, 2009). P300기반 BMI 기술이란 자극 제시 후 300ms 이후쯤에 두정엽 영역에서 나타나는 positive peak를 이용하는 방법으로 순차적으로 여러 자극을 보여주고, 피험자가 선택하려고 했던 자극에서 P300이 더 뚜렷이 나타나는 것을 이용하는 방법이다. 또한 최근 주목받고 있는 방법 중 한 가지로 SSVEP (Steady-State Visually Evoked Potential)라는 기술이 있 다. 이 방법은 시각자극의 빈도수(주파수)에 따라 후두엽에서 해당 주파수의 세기가 증가하는 현상을 이용한 방 법으로 상대적으로 신호 구분이 용이하며, 2차원 상에서 동시에 여러 자극 중 하나를 선택하는 것이 가능하다. 일본의 RIKEN 연구소에서 2010년 Neuroscience Letters에 발표한 논문에 따르면 이 SSVEP 방법을 이용하여 8개 의 방향 중 한 방향을 선택하는 방법의 마우스 커서 제어방법을 선보였다 (Hovagim Bakardjian et al., 2010). 이렇듯 P300이나 SSVEP를 이용한 BMI 기술은 상대적으로 다양한 선택을 가능하게 하지만 여전히 실험 전 미리 정해놓은 몇 가지 선택사항 중 한 가지를 선택하는 것 외에는 할 수 없다는 단점이 있으며, 시각적 자극을 필요 로 하기 때문에 컴퓨터상에서의 작업이 아닌 일상생활에서의 사용이 불가능한 문제점이 있다. 또한, 뇌파만을 이용한 종래의 일반적인 BMI 기술로서는 뇌파로부터 피험자의 의사를 정확히 해독(Decoding)하 기 어려워 해당 뇌파를 이용하여 사물을 제어할 때 정확도가 떨어지는 문제점이 있다."}
{"patent_id": "10-2011-0104176", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는 뇌파를 이용하여 사물을 제어하는 뇌-컴퓨터 인터페이스 장치 및 방법 을 제공하는 데 있다. 본 발명이 이루고자 하는 또 다른 기술적 과제는 뇌파를 이용하여 사물을 제어할 때 목적물의 정보를 이용하여 제어의 정확도를 높이는 뇌-컴퓨터 인터페이스 장치 및 방법을 제공하는 데 있다. 본 발명이 이루고자 하는 또 다른 기술적 과제는 뇌파를 이용하여 사물을 제어할 때 영상인식을 이용하여 제어 의 정확도를 높이는 뇌-컴퓨터 인터페이스 장치 및 방법을 제공하는 데 있다. 본 발명이 이루고자 하는 또 다른 기술적 과제는 뇌파를 이용하여 사물을 제어할 때 영상인식을 이용하여 목적 물 결정의 정확도를 높이는 뇌-컴퓨터 인터페이스 장치 및 방법을 제공하는 데 있다."}
{"patent_id": "10-2011-0104176", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 과제를 해결하기 위한 뇌-컴퓨터 인터페이스 장치에 따르면, 대상물 동작 정보를 포함하는 변환 뇌파 정보를 입력받고, 상기 변환 뇌파 정보로부터 대상물 동작 정보를 포함한 대상물 제어 정보를 추출하여 융합 제 어부로 전달하는 뇌파 정보 처리부, 목적물의 목적물 위치 정보를 포함한 목적물 정보를 입력받고, 상기 목적물 정보를 이용하여 대상물 동작 정보를 포함한 상기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하 는 융합 제어부를 포함할 수 있다.또한 상기 뇌-컴퓨터 인터페이스 장치에서 상기 대상물은 인공 팔, 마우스 커서, 디스플레이에 표시되는 응용 프로그램의 컨트롤 수단, 오디오 또는 비디오 재생 장치의 컨트롤 수단, 휠체어 및 자동차 중 어느 하나일 수 있다. 또한 상기 뇌-컴퓨터 인터페이스 장치는 인간의 뇌파 신호를 입력받고, 상기 입력받은 뇌파 신호를 대상물 동작 정보를 포함하는 변환 뇌파 정보로 변환하여 상기 뇌파 정보 처리부로 전달하는 뇌파 신호 변환부를 더 포함할 수 있다. 또한 상기 뇌-컴퓨터 인터페이스 장치는 뇌파 신호를 입력받고, 상기 뇌파 신호에서 잡음 신호를 제거한 후 상 기 뇌파 신호 변환부로 전달하는 뇌파 신호 전처리부를 더 포함할 수 있다. 또한 상기 뇌-컴퓨터 인터페이스 장치는 적어도 하나 이상의 목적물 후보들에 대한 목적물 위치 정보를 포함하 는 목적물 정보를 입력받아 목적물을 결정하고, 상기 결정된 목적물의 목적물 정보를 융합 제어부로 전달하는 목적물 결정부를 더 포함할 수 있다. 또한 상기 뇌-컴퓨터 인터페이스 장치는 영상을 입력받고, 상기 입력된 영상에서 적어도 하나 이상의 목적물 후 보들을 추출하며, 상기 입력된 영상을 이용해 상기 목적물 후보들의 목적물 위치 정보를 포함한 목적물 정보를 설정하여, 상기 목적물 정보를 목적물 결정부로 전달하는 영상 인식부를 더 포함할 수 있다. 또한 상기 뇌-컴퓨터 인터페이스 장치에서 상기 입력된 영상은 스테레오 카메라로부터 촬영된 스테레오 영상이 고, 상기 목적물 위치 정보는 3차원 위치 정보일 수 있다. 본 발명의 과제를 해결하기 위한 뇌-컴퓨터 인터페이스 방법에 따르면, 대상물 동작 정보를 포함하는 변환 뇌파 정보를 입력받는 단계, 상기 변환 뇌파 정보로부터 대상물 동작 정보를 포함한 대상물 제어 정보를 추출하는 단 계, 목적물에 대한 목적물 위치 정보를 포함하는 목적물 정보를 입력받는 단계 및 상기 목적물 정보를 이용하여 대상물 동작 정보를 포함한 상기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2011-0104176", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 피험자의 뇌파를 이용하여 뇌-컴퓨터 인터페이스가 가능하며 대상물을 제어할 수 있다. 또한, 본 발명에 의하면 목적물 정보를 이용하여 뇌-컴퓨터 인터페이스에서 대상물 제어의 정확도를 높일 수 있 다. 또한, 본 발명에 의하면 목적물의 영상 인식을 이용하여 뇌-컴퓨터 인터페이스에서 대상물 제어의 정확도를 높 일 수 있다. 또한, 본 발명에 의하면 대상물 및 대상물의 상황을 고려하여 뇌-컴퓨터 인터페이스에서 목적물의 결정에 대한 정확도를 높일 수 있다."}
{"patent_id": "10-2011-0104176", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적과 기술적 구성 및 그에 따른 작용 효과에 관한 자세한 사항은 본 발명의 명세서에 첨부된 도면 에 의거한 이하의 상세한 설명에 의해서 보다 명확하게 이해될 것이다. 첨부된 도면을 참조하여 본 발명에 따른 실시예를 상세하게 설명한다. 본 명세서에서 개시되는 실시예들은 본 발명의 범위를 한정하는 것으로 해석되거나 이용되지 않아야 할 것이다. 이 분야의 통상의 기술자에게 본 명세서의 실시예를 포함한 설명은 다양한 응용을 갖는다는 것이 당연하다. 따 라서, 특허청구범위에 의해 한정되지 않는 이상, 임의의 실시예는 본 발명을 보다 잘 설명하기 위한 예시적인 것이며 본 발명의 범위가 실시예들로 한정되는 것을 의도하지 않는다. 도 1은 피험자의 변환 뇌파 정보와 목적물 정보를 이용하여 대상물을 제어하는 뇌-컴퓨터 인터페이스 장치(13 0)의 일 실시예를 나타낸다. 도 1에 표시되고 아래에 설명되는 기능 블록들은 가능한 구현의 예들일 뿐이다. 다 른 구현들에서는 상세한 설명의 사상 및 범위를 벗어나지 않는 범위에서 다른 기능 블록들이 사용될 수 있다. 또한, 뇌-컴퓨터 인터페이스 장치의 하나 이상의 기능 블록이 개별 블록들로 표시되지만, 뇌-컴퓨터 인터 페이스 장치의 기능 블록들 중 하나 이상은 동일 기능을 실행하는 다양한 하드웨어 및 소프트웨어 구성들 의 조합일 수 있다. 본 명세서에서 뇌파는 피험자의 뇌의 활성화 및 상태에 따라 변화되는 전기적 자기적 신호들을 의미한다. 실시 예를 보면, 뇌파 신호를 측정하는 방법에 따라 다음과 같은 뇌파 신호가 될 수 있다. EEG (Electroencephalogram)는 뇌전도를 의미하며, 사람 또는 동물의 대뇌에 일어나는 전위변동, 또는 그것에 의하여 일어나는 뇌전류(brain current)를 두피(頭皮) 상에서 유도하여 기록한 전기 기록 신호를 의미한다. MEG (Magnetoencephalogram)는 뇌자도를 의미하며, SQUID 센서 등으로 뇌신경세포의 전기적 활동에서 발생하는 미세한 생체 자기를 측정하여 기록한 신호를 의미한다. ECoG (Electrocorticogram)는 피질전도를 의미하며, 대뇌에 일어나는 전위변동, 또는 그것에 의하여 일어나는 뇌전류(brain current)를 대뇌 피질(Cerebral Cortex)의 표면으로부터 전극을 심어 직접 측정하여 기록한 전기 기록 신호를 의미한다. NIRS (Near-infrared spectroscopy) 는 근적외선 분광기를 의미하며, 본 발명에 쓰일 수 있는 NIRS 뇌파 신호 는 낮은 수준의 광파를 뇌에 비쳐 반사되어 나오는 차이를 측정하여 기록하는 신호를 의미한다. 본 명세서에서는 EEG, MEG, ECoG 등의 뇌파 신호를 예로 들었지만, 뇌파 신호는 상기 특정 종류의 뇌파 신호에 한정되지 않고 인간의 뇌로부터 발생하여 인간의 두부(頭部, 머리)에서 측정 가능한 모든 신호들을 포함한다고 볼 것이다. 도 1을 참조하면, 뇌-컴퓨터 인터페이스 장치의 뇌파 정보 처리부는 대상물 동작 정보를 포함하는 변환 뇌 파 정보를 입력받을 수 있다. 대상물은 입력된 뇌파 신호 또는 변환 뇌파 정보가 측정된 피험자가 뇌파 신호 또는 변환 뇌파 정보를 이용하여 제어하려는 대상을 의미한다. 본 발명에서 대상물은 특별히 한정되지 않으나, 예를 들면 인공 팔, 디스플레이의 마우스 커서, 디스 플레이에 표시되는 응용 프로그램의 컨트롤 수단, 오디오 또는 비디오 재상 장치의 컨트롤 수단, 휠체어 및 자동차 중에서 어느 하나가 될 수 있다. 변환 뇌파 정보란, 피험자의 EEG, MEG, ECoG 등의 뇌파 신호로부터 대상물을 제어하기 위해 피험자가 의도하는 대상물에 관한 동작정보(대상물 동작정보)를 포함하는 정보들을 추출하고, 추출된 대상물에 관한 동작정보(대상 물 동작정보)를 포함하여 구성된 정보를 말한다. 즉, 피험자의 EEG, MEG, ECoG 등의 뇌파 신호가 대상물 동작정 보를 포함하고 컴퓨터 등 제어 장치가 인식 가능한 신호 형태의 정보로 변환된 것을 의미한다. EEG 뇌파 신호의 예를 들면 피험자의 두피에 부착된 전극 을 통해서 측정 가능하나, 이 밖에도 종래의 MEG, ECoG 뇌파 신호를 측정하는 방법으로도 포착 가능하다. 즉, EEG, MEG, ECoG, NIRS 등의 뇌활동 측 정장비 중 어느 하나를 이용하여 뇌파 신호를 측정할 수 있다. 측정된 뇌파 신호는 컴퓨터 등의 인터페이스 장치를 통해 대상물 동작 정보를 포함하는 변환 뇌파 정보로 변환된 후 뇌파정보 처리부로 입력될 수 있다. 상기 인터페이스 장치의 일 예를 들면, 피험자의 EEG를 측정하고, 해당 EEG 뇌파 신호에 디지털 변환, 잡 음 처리 등의 전처리를 수행하고, 미리 설정된 특징벡터(Feature Vector)를 추출한 후에, 이 특징 벡터를 이용 하여 회귀(Regression), 인공 신경망(Artificial Neural Network) 등의 인공 지능(Artificial Intelligence) 기법을 적용하여 피험자가 의도하는 대상물 동작정보를 추출하고, 상기 대상물 동작 정보를 포함하여 변환 뇌파 신호로 변환할 수 있다. 대상물 동작 정보는 대상물의 동작을 나타내는 모든 정보를 의미한다. 일 예를 들면, 인공 팔이 대상물인 경우, 대상물 동작 정보는 인공 팔의 현재 위치에서부터 목적지 위치까지의 벡터정보, 인공 팔의 이동 속도에 대한 속도 정보 등의 동작을 위한 정보들을 포함할 수 있다.일 예를 들면, 상기 대상물 동작정보는 인공 팔이라는 대상물을 “위로 올린다”는 대상물 동작 정보가 될 수 있거나, 휠체어라는 대상물을 “앞으로 전진한다”라는 대상물 동작 정보가 될 수 있다. 이러한 대상물 동작 정 보는 전자의 경우 “UP”이라는 미리 설정된 코드를 이용할 수 있고, 후자의 경우는 “FORWARD”라는 미리 설정 된 코드를 이용해 대상물 동작 정보를 구성하고 이 정보를 포함한 정보를 뇌파 변환 정보로 구성할 수 있다. 다른 일 예를 들면 대상물 동작 정보는 대상물의 현재 위치에서부터 목적지 위치까지의 벡터정보를 포함해서 구 성될 수 있다. 예를 들어, 대상물이 인공 팔이고 인공 팔의 이동 벡터가 현재 인공 팔의 위치에서 X축 방향으로 30 cm, Y축 방향으로 60 cm, Z축 방향으로 40 cm 이동하는 것이라면, 대상물 동작 정보는 “X:30-Y:60-Z:40” 으로 구성될 수 있다. 또한, 예를 들어 상기 대상물 동작 정보에 인공 팔의 이동 속도에 대한 속도 정보(예로서 속도는 80cm/min)가 포함된다면 대상물 동작 정보는 대상물의 이동 벡터와 함께 구성되어 “X:30-Y:60-Z:40, V:80”으로 구성될 수 있다 상기 속도 정보는 절대 속도 정보로써(예를 들어 80cm/min) 표현될 수도 있고, 또는 미리 설정된 속도의 등급 단위로써 구분하여 'FAST', 'SLOW', 'MEDIUM'으로 구성될 수도 있다. 예를 들어, 대상물이 휠체어이고 이를 빠른 속도로 앞으로 전진하는 것이 피험자의 의사로 판단되었다면, 대상물 동작 정보는 미리 설정된 속도의 등급 단위로 구성될 수 있고, “FORWARD FAST”라는 대상물 동작 정보 를 포함하는 변환 뇌파 정보로 구성될 수 있다. 또한, 제어 장치에 연결된 대상물이 복수이며, 동시에 피험자가 제어 가능한 대상물이 복수인 경우에 대상물 동 작 정보와 피험자가 제어를 원하는 대상물이 무엇인지에 대한 정보도 함께 포함되어 변환 뇌파 정보를 구성할 수 있다. 제어 장치에 연결된 대상물이 복수이며, 동시에 피험자가 제어 가능한 대상물이 복수인 경우의 일 예를 들면 다 음과 같다. 대상물이 인공 팔이고 추출된 대상물 동작정보가 “UP”의 경우에, 인공 팔이라는 대상물의 대상물 코드를 “ARM”이라고 제어장치에 미리 설정했다면, 변환 뇌파 정보는 “ARM UP”이라는 대상물 코드와 대상물 동작정 보를 포함하는 정보로 구성될 수 있다. 대상물이 휠체어이고 추출된 대상물 동작정보가 “FORWARD”의 경우에, 휠체어라는 대상물의 코드를 “ WHEELCHAIR”라고 제어장치에 미리 설정했다면, 변환 뇌파 정보는 “WHEELCHAIR FORWARD”라는 대상물 코드와 대상물 동작정보를 포함하는 정보로 구성될 수 있다. 변환 뇌파 정보는 앞에서 설명한 대상물에 관한 동작정보(대상물 동작정보)를 포함하여 구성된 정보를 의미하므 로, 변환 뇌파 정보에는 대상물 동작에 대한 정보뿐만 아니라 피험자의 ID, 성별, 나이 등의 정보도 포함될 수 있다. 따라서, 본 발명인 뇌-인터페이스 장치는 복수의 피험자로부터 검지된 뇌파신호가 변환된 복수의 뇌파 변환 정 보를 입력 받아, 다수의 대상물을 제어하는 것도 당연하다고 볼 것이다. 뇌파 정보 처리부는 변환 뇌파 신호에서 상기 “ARM UP” 또는 “WHEELCHAIR FORWARD” 등의 대상물 동작 정보 를 포함하는 대상물 제어 정보를 추출하여 융합 제어부로 전달한다. 대상물 제어 정보란 변환 뇌파 정보로부터 대상물의 제어를 위해 대상물과 관련된 정보만을 추출한 것을 의미한 다. 예를 들어, 제어 장치에 연결된 대상물이 복수이며, 동시에 피험자가 제어 가능한 대상물이 복수이고, 변환 뇌 파 정보에 피험자의 ID(예를 들어 'A123'), 피험자의 성별(예를 들어 'MALE'), 대상물 코드(예를 들어 'ARM'), 대상물 동작정보(예를 들어 'UP')로 구성되어 “A123-MALE-ARM-UP”인 경우에, 대상물 제어 정보는 피험자의 ID 및 성별을 제외한 대상물 코드 및 대상물 동작정보를 추출하여 “ARM-UP”이 될 수 있다. 융합 제어부는 입력받은 목적물의 목적물 정보를 이용해 뇌파 정보 처리부에서 전달된 대상물 제어 정보를 보정한다. 상기 입력받은 목적물 정보는 적어도 하나 이상의 목적물에 대한 목적물 정보일 수 있다. 상기 목적 물 정보는 목적물 위치 정보를 포함하며, 목적물 인식 정보를 포함할 수도 있다. 목적물은 제어되는 대상물의 동작 목적이 되는 대상을 의미한다. 도 6을 참조하면, 인공 팔의 제어 최종 목적이 특정 A라는 컵을 잡는 것이라면, 해당 A가 목적물이 될 수 있다. 휠체어의 이동 목표가 특정 B라는 지점이 라면, 해당 B 지점이 목적물이 될 수 있다. 목적물 위치 정보는 목적물의 3차원적 위치를 말하며, 영상 인식 및 근거리 통신 등을 통해서 파악된 목적물의 위치로 설정될 수 있다. 목적물 인식 정보는, 특정(Unique) 목적물 후보 또는 목적물 등의 사물을 서로 구별하 기 위한 정보를 의미한다. 예를 들어, 목적물 A의 위치가 제어 대상물인 인공 팔에서의 상대적인 3차원적 위치가 X축 방향으로 30 cm, Y축 방향으로 50 cm, Z축 방향으로 40 cm라면, 목적물 인식 정보와 목적물 위치 정보를 결합하여 “OBJECT-A, X:30- Y:50-Z:40”으로 목적물 A의 목적물 정보가 설정되어 입력될 수 있다. 융합 제어부는 입력된 목적물의 목적물 정보를 이용하여 피험자의 변환 뇌파 정보로부터 추출된 대상물 제어 정 보를 보정하고 대상물 최종 제어 정보를 출력한다. 대상물 최종 제어 정보는 목적물 정보를 이용하여 대상물 제어 정보를 보정한 정보를 말한다. 예를 들어, 추출된 대상물 제어 정보의 대상물 동작정보가 \"ARM-UP\"이고 목적물 A의 목적물 위치 정보가 \"X:30- Y:50-Z:40\"이라면, 대상물 제어 정보는 \"ARM-UP\"과 목적물 인식정보를 포함하는 목적물 정보 \"OBJECT-A, X:30- Y:50-Z:40\"를 포함하여 \"ARM-UP, OBJECT-A, X:30-Y:50-Z:40\"로 보정하여 대상물 최종 제어 정보를 설정할 수 있다. 또한, 예를 들어 제어부에 입력된 대상물 제어 정보의 대상물 동작정보가 현재 위치에서부터 목적지 위치까지의 이동 벡터정보를 포함해서 구성될 수 있다. 예를 들어, 대상물이 인공 팔이고, 인공 팔의 이동 벡터가 현재 인 공 팔의 위치에서 X축 방향으로 30 cm, Y축 방향으로 60 cm, Z축 방향으로 40 cm 이동하는 것이라면, 대상물 동작 정보는 \"ARM, X:30-Y:60-Z:40\"으로 설정될 수 있다. 이 경우, 목적물 A의 목적물 위치 정보가 \"X:30-Y:50-Z:40\"이라면 대상물 제어 정보 \"ARM, X:30-Y:60-Z:40\"를 목적물 정보 \"OBJECT-A, X:30-Y:50-Z:40\"를 이용해 보정하게 되고, \"ARM, OBJECT-A, X:30-Y:50-Z:40\"로 보정하 여 대상물 최종 제어 정보를 설정할 수 있다. 또는, 대상물 제어 정보의 대상물 동작 정보와 목적물 위치 정보 의 중간 값으로 대상물 제어 정보를 보정하여, \"ARM, OBJECT-A, X:30-Y:55-Z:40\"로 대상물 최종 제어 정보를 설 정할 수도 있다. 또한, 복수의 목적물 A, B 에 대한 목적물 정보들이 입력되면, 복수의 목적물 A, B의 각 목적물 정보를 이용해 A, B의 중간 위치로 대상물 제어 정보를 보정하거나, A, B 중에서 대상물 제어정보의 이동 벡터위치에 보다 가 까운 목적물 정보를 이용해 대상물 제어 정보를 보정하여 대상물 최종 제어 정보를 설정할 수 있다. 예를 들면, 대상물 제어 정보가 \"ARM, X:30-Y:60-Z:40\"이고 목적물 A 및 B의 목적물 정보인 \"OBJECT-A, X:30- Y:50-Z:40\", \"OBJECT-B, X:30-Y:70-Z:60\"를 이용해 보정하게 되면, 목적물 A와 B의 중간 위치인 \"X:30-Y:60- Z:50\"를 이용하여 대상물 제어 정보를 \"ARM, X:30-Y:60-Z:50\"로 대상물 최종 제어 정보를 설정할 수 있다. 또는, 목적물이 복수인 경우 목적물 위치들의 단순 평균이 아닌 기하평균이나 산술 평균 등을 이용하여 대상물 제어 정보를 보정할 수도 있다. 또한, 측정값으로부터 예측된 값을 보정해주는 알고리즘인 칼만 필터 (Kalman filter)나 칼만필터의 비선형 시 스템 버전인 확장칼만필터 (Extended kalman filter), 언센티드 칼만 필터 (Unscented kalman filter), 파티클 필터 (particle filter), 베이지안 필터 (Bayesian filter) 등을 적용하여 목적물 정보를 이용해 대상물 제어 정보를 보정하여 대상물 최종 제어 정보를 설정할 수도 있다. 또한, 도 12에서처럼 목적물 정보의 목적물 위치 정보나 대상물 동작 정보는 단순한 숫자 값이 아닌 확률 값의 분포로도 표현될 수 있다. 예를 들어, 대상물 동작 정보의 X축 동작 정보는 X축 위치 변이에 따른 각 확률 값의 분포, 목적물 정보의 목적물 위치 정보는 X축 위치 변이에 따른 각 확률 값의 분포로 나타낼 수 있 다. 이 경우 대상물 최종 제어 정보는 양 분포를 고려하여 대상물 제어 정보를 보정하게 되고, 역시 X축 위치 변이에 따른 각 확률 값의 분포로 설정될 수 있다. 대상물 최종 제어 정보의 Y축, Z축에 대한 제어 정보 도 마찬가지로 설정될 수 있다. 대상물 최종 제어 정보는 대상물의 움직임과 이에 따른 변환 뇌파 정보로부터 추출된 대상물 제어 정보 변화 및 이에 따른 목적물 후보들의 목적물 정보 변화에 따라 계속 변화하여 설정될 수 있다. 예를 들어, 대상물 제어 정보가 \"ARM, X:30-Y:60-Z:40\"이고 목적물 A의 목적물정보 \"OBJECT-A, X:30-Y:50- Z:40\"를 이용해 보정하는 경우, 대상물 제어 정보를 \"ARM, OBJECT-A, X:30-Y:50-Z:40\"로 보정하여 대상물 최종 제어 정보를 설정한다. 따라서 대상물인 인공 팔을 목적물 A로 이동 벡터 X:30-Y:50-Z:40를 이용해 이동시키게 되고, 이동 중에 피험자의 뇌파 신호가 변화하여 입력된 변환 뇌파 정보로부터 추출된 대상물 제어 정보가 변화 할 수 있다. 변화된 대상물 제어 정보가 \"ARM, X:30-Y:20-Z:40\"이고, 입력된 목적물 정보가 목적물 B에 대한 정 보로 변화되면, 목적물 B의 목적물 정보를 이용하여 대상물 제어 정보를 보정할 수 있고, 대상물 최종 제어 정 보는 \"ARM, OBJECT-B, X:30-Y:30-Z:40\"로 변화되어 설정될 수 있다. 또한, 측정값으로부터 예측된 값을 보정해주는 알고리즘을 사용할 경우, 대상물 제어 정보가 \"ARM, X:30-Y:60- Z:40\"이고 목적물 A의 목적물 정보 \"OBJECT-A, X:30-Y:50-Z:40\"를 이용해 보정하게 되면, 칼만 필터 등의 알고 리즘의 적용에 따라 대상물 제어 정보를 \"ARM, X:30-Y:55-Z:40\"로 보정하여 대상물 최종 제어 정보를 설정할 수있다. 따라서 대상물인 인공 팔을 이동 벡터 X:30-Y:55-Z:40를 이용해 이동시키게 되고, 이동 중에 피험자의 뇌 파 신호가 변화하여 입력된 변환 뇌파 정보로부터 추출된 대상물 제어 정보가 다시 변화할 수 있다. 변화된 대 상물 제어 정보가 \"ARM, X:30-Y:20-Z:40\"이고 입력된 목적물 정보가 목적물 B에 대한 정보로 변화되면, 목적물 B의 목적물 정보 \"OBJECT-B, X:30-Y:40-Z:40\"를 이용해 칼만 필터 등의 알고리즘의 적용에 따라 대상물 제어 정 보를 보정할 수 있고, 대상물 최종 제어 정보는 \"ARM, X:30-Y:30-Z:40\"로 변화되어 설정될 수 있다. 도 3을 참조하면, 뇌-컴퓨터 인터페이스 장치는 인간의 뇌파 신호를 입력받고, 상기 입력받은 뇌파 신호를 대상 물 동작 정보를 포함하는 변환 뇌파 정보로 변환하여 뇌파 정보 처리부로 전달하는 뇌파 신호 변환부를 더 포함할 수 있다. 상기 뇌파 신호 변환부는 입력된 뇌파신호 또는 잡음 제거 등의 전처리(Pre-processing) 과정을 거친 뇌파 신호에 대해 특징 추출(Feature Extract) 과정을 포함하는 신호 처리부, 추출된 특징을 이용해 대상물 동작 정 보를 판단하는 과정을 포함하는 데이터 분류 및 판단부(Classification)를 포함할 수 있다. 입력된 뇌파신호 또는 잡음이 제거된 뇌파신호는 뇌파 신호 변환부의 신호 처리부로 전달될 수 있으며, 신호 처 리부에서는 사용자의 의도를 인지하기에 유용한 신호의 특징(Feature)들을 추출하게 된다. 여기에는 뇌파 신호 를 특정 구간으로 잘라 신호 처리를 해줄 수 있도록 하는 에포킹 (Epoching) 과 사람 간 뇌파 신호의 차이와 사 람 내 뇌파 신호의 차이를 줄여주기 위한 정규화 (Normalization), 오버피팅 (Over-fitting)을 막기 위한 다운 샘플링 (Down Sampling)이 포함될 수 있다. 에포킹은 실시간 데이터 처리를 위한 것으로 수십 밀리초 (milisecond)에서 초(second)단위로 사용될 수 있으며, 다운 샘플링은 20ms 정도의 간격이 적당하나 사람이나 상황에 따라 수ms에서 수십ms 정도로 달라질 수 있다. 경우에 따라 퓨리에 변환 (Fourier Transform )이나 엔벨 로프 (Envelope)을 구하는 신호처리가 포함될 수 있다. 상기 데이터 분류 및 판단부는 뇌파 신호에 나타난 피험자의 의사를 파악하여 대상물에 대한 제어 형태를 판단 하게 된다. 구체적으로 보면, 데이터 분류 및 판단부는 데이터 학습과정을 통해 학습 데이터(Training Data)로 부터 특징 파라미터 (Feature Parameter)를 결정하게 되며, 이렇게 결정된 특징 파라미터를 통해 새로운 데이터 에 대하여 적절한 대상물 동작 정보를 결정할 수 있다. 학습데이터로부터 특징 파라미터를 결정하고 새로운 데 이터에 대해 적절한 출력을 결정하기 위해 데이터 분류 및 판단부는 다중 선형 회귀 (Multiple Linear Regression), 서포트-벡터 회귀 (Support-Vector Regression) 등의 회귀방법이 사용될 수 있으며, 인공신경망 (Neural-Network)이나 서포트-벡터 머신 (Support-Vector Machine) 등의 분류알고리즘이 적용될 수 있다. 도 5를 참조하면 뇌-컴퓨터 인터페이스 장치는 뇌파 신호 전처리부를 더 포함할 수 있다. 상기 뇌파 신호 전처리부(는 뇌파 신호를 입력받아 상기 뇌파 신호에서 잡음 신호를 제거한 후 뇌파 신호 변환부로 전달할 수 있다. 상기 뇌파 신호 전처리부는 저역 통과 필터(Low-Pass Filter), 고역 통과 필터 (High-Pass Filter), 대역 통과 필터 (Band-Pass Filter), 노치 필터 (Notch Filter) 중 어느 하나를 포함할 수 있으며, 동시에 상기 뇌 파 신호에 혼입되어 있는 잡음을 제거하기 위해 독립성분분석법(ICA)나 주성분분석법(PCA)을 수행하기 위한 부 분이 포함될 수 있다. 상기 잡음 신호는 뇌파 신호 이외의 신호를 말한다. 예를 들어, 일반적인 전송 경로(유, 무선 채널)에 따른 일 반적인 잡음(Noise Signal) 이외에도, EMG(Electromyogram, 근전도), EOG(Electrooculogram, 안전도) 등의 뇌 파 신호 이외의 다른 생체 신호들도 관심 신호가 아니므로 잡음 신호로 취급하여 필터링 등을 통해서 제거할 수 있다.도 4를 참조하면 뇌-컴퓨터 인터페이스 장치는 목적물 결정부를 더 포함할 수 있다. 목적물 결정부는 적어 도 하나 이상의 목적물 후보들에 대한 목적물 위치 정보를 포함한 목적물 정보를 입력받아 목적물을 결정하고, 상기 결정된 목적물의 목적물 정보를 융합 제어부로 전달할 수 있다. 목적물 후보는 목적물로 결정될 수 있는 대상들을 의미한다. 목적물 후보는 영상 인식(Image Recognition), Zigbee, USN(Ubiquitous Sensor Network), RFID(Radio Frequency Identification), NFC(Near Field Communication) 등을 통해 파악될 수 있다. 상기 목적물 정보는 목적물 위치 정보를 포함하며, 목적물 인식 정보를 포함할 수도 있다. 목적물 인식 정보는, 특정(Unique) 목적물 후보 또는 목적물을 서로 구별하기 위한 정보를 의미한다. 예를 들어, 영상 인식 및 근거 리 통신 등을 통해서 인공 팔의 동작 방향(또는 뇌파 신호가 측정되는 피험자가 바라보는 방향)에 A, B, C 세가 지 사물들이 존재하고, 상기 A, B, C 세가지 사물들은 목적물 후보들로 인식될 수 있다. 이 경우, 미리 설정된 A, B, C의 식별자인 “OBJECT-A”, “OBJECT-B”, “OBJECT-C”가 목적물 인식정보로 설정될 수 있으며, 영상 인식 및 근거리 통신 등을 통해서 파악된 A, B, C 각 목적물 후보들의 위치가 목적물 위치 정보로 설정될 수 있 다. 도 3을 참조하면, 뇌파 신호가 측정되는 피험자가 바라보는 방향을 촬영한 영상의 자동 영상 인식을 통해 해당 영상에 사물이 A, B, C 세 개가 있는 것으로 파악되면, 상기 사물 A, B, C를 목적물 후보로 인 식할 수 있다. 또한, 도 4를 참조하여 근거리 통신을 이용할 경우를 예로 들면, 각 사물들에 RFID용 전자 태그, NFC 태그, Zigbee 칩, USN 센서 등을 부착시켰을 경우에는 뇌파 신호가 측정되는 피험자 주변의 일정 범위에 존재하는 각 사물들의 위치를 파악 가능하다. 따라서, 뇌파 신호가 측정되는 피험자의 위치나 제어하고자 하는 대상물의 위 치 및 이동 방향 등을 고려하여 관련 있는 사물들을 목적물 후보로 인식할 수 있다. 상기 목적물 결정부는 뇌파 신호가 측정되는 피험자의 위치나 제어하고자 하는 대상물의 위치 및 이동 방향 등 을 고려하여 적어도 하나 이상의 목적물 후보들로부터 목적물을 결정할 수 있다. 도 4를 참조하여 예를 들면, 근거리 통신 등을 통해서 파악된 사물 A, B, C가 뇌파 신호가 측정 된 피험자의 주변 사물로 인식되었고, 그 중에서 피험자의 시각 방향과 제어하고자 하는 대상물의 방향을 고려 하여 사물 A, B 가 목적물 후보로 인식되었을 경우를 고려해 볼 수 있다. 이 경우, 목적물 결정부는 목적물 후 보들 중에서 대상물인 인공팔의 현재 위치와 가장 가까운 목적물 후보를 최종 목적물로 판단하거나, 대상 물의 현재 움직임 방향의 연장 직선 방향에 있는 목적물 후보를 최종 목적물로 판단할 수 있다. 도 4를 참조하여 다른 예를 들면, 변환 뇌파로부터 추출된 대상물 제어 정보를 참조하고, 대상물의 이동 방향, 속도를 고려하여 최종 목적물로 판단할 수 있다. 예를 들어, 대상물이 인공 팔이고 목적물 후보가 A, B, C이며 대상물 제어 정보가 “X:10-Y:10-Z:00, V:10”인 경우를 살펴본다. 목적물 후보 A, B, C 모두가 대상물의 이동 방향으로부터 일정 범위 내에 존재하더라도 대상물의 속도가 작은 경우는 보다 가까운 목적물 후보인 C를 최종 목적물로 인식할 수 있고, 반대로 대상물의 속도가 큰 경우는 보다 멀리 있는 목적물 후보인 B를 최종 목적물로 인식할 수 있다. 도 4를 참조하여 다른 예를 들면, 대상물 제어 정보와 목적물 후보들의 목적물 위치 정보들을 고려할 경우, 복 수의 목적물 후보가 목적물로 결정될 수 있다. 예를 들어, 대상물이 인공 팔이고 목적물 후보가 A, B, C인 경우, 대상물 제어 정보를 고려하면 목적물 후보 A, B가 모두 관련도가 유사하게 나올 경우 A, B 모두를 목적물 로 결정할 수 있다. 이 경우, 시간에 따라 피험자로부터의 뇌파 신호 및 그로부터 변환된 변환 뇌파 신호는 변 화하므로, 이에 따른 대상물의 움직임을 고려하여 최종적으로는 목적물이 하나로 결정될 수 있다. 도 10을 참조하여 다른 예를 들면, 피험자의 상황과 대상물을 고려하여 목적물 후보를 결정할 수도 있다. 예를 들어, 대상물이 자동차이고 입력된 영상에서 인식된 목적물 후보들이 다양하게 있는 경우, 대상물이 자동 차인 점을 고려하여 앞서 진행하는 자동차 또는 중앙선 표시는 목적물로 결정하지 않을 수 있다. 또는, 대상물이 휠체어이고 입력된 영상에서 인식된 목적물 후보들이 다양하게 있는 경우, 대상물이 휠체 어인 점을 고려하여 도로에 있는 자동차, 주변 사람은 목적물로 결정하지 않을 수 있다. 또는, 대상물이 디스플레이에 표시되는 동영상 프로그램의 볼륨이나 진행 컨트롤일 경우, 대상물을 고려하여 해 당 컨트롤과 관련 있는 레벨 표시 중에서만 목적물을 결정할 수도 있다. 또한, 피험자로부터의 뇌파 신호 및 그로부터 변환된 변환 뇌파 신호와 주변 상황은 계속해서 변화할 수 있으므 로, 이에 따라 목적물 후보 및 결정된 목적물도 변화할 수 있는 것은 당연하다고 할 것이다. 또한, 목적물 결정을 위해 상기 설명과 미리 설정된 기준에 적합한 목적물 후보를 목적물로 결정할 수도 있지만, 인공 신경망(Artificial Neural Network) 등의 인공 지능(Artificial Intelligence) 기법을 적용하여 목적물 후보를 결정할 수도 있다. 도 3을 참조하면 뇌-컴퓨터 인터페이스 장치는 영상 인식부를 더 포함할 수 있다. 영상 인식부는 영상을 입력받고, 상기 입력된 영상에서 적어도 하나 이상의 목적물 후보들을 추출하고, 목적물 후보들의 목적물 위치 정보를 포함한 목적물 정보를 설정하여 목적물 결정부로 전달한다. 상기 목적물 정보는 목적물 인식 정보를 포 함할 수도 있다. 상기 영상 인식부는 외부 카메라로부터 영상을 입력받을 수도 있고, 또는 다른 전송 장치를 통해서도 영상 을 입력받을 수 있다. 상기 입력되는 영상은, 뇌파 신호가 측정되는 피험자 주변의 영상이며, 특히 피험자의 고개가 향한 방향이나 시 선이 향한 방향의 주변 영상이 적합할 것이다. 또한 도 10을 참조하면, 상기 입력되는 영상은 카메라를 이용하여 촬영된 영상(1010, 1040)에 한정하지 않으며, 대상물에 따라 디스플레이의 캡쳐(Capture) 화면 영상(1020, 1030) 등 모든 영상이 입력될 수 있다. 상기 영상 인식부는 입력된 영상으로부터 파악된 사물의 위치와 형태에 대한 정보를 이용하여 목적물 후보 들의 목적물 인식 정보 및 목적물 위치 정보를 포함한 목적물 정보를 설정하여 목적물 결정부로 전달할 수 있다. 상기 영상 인식부는 입력된 영상에 대해 저주파 통과 필터링, 고주파 통과 필터링 등의 선형 공간 필터링 기법을 통한 영상처리 기법이나 최대 필터링, 최소 필터링 등의 비선형 공간 필터링이 포함하는 영상 전처리 과정을 수행할 수도 있다. 상기 영상 인식부는 입력된 영상에 대해 임계치로 영상을 양분화하는 방법 (Thresholding)이나 Harris corner detection, 차영상 혹은 색상 필터링과 같은 방법들을 조합하여 영상에 존재하는 사물의 형태를 구하고, K-means 알고리즘과 같은 비 교사 학습법 (Unsupervised Learning)을 이용하여 사물들을 클러스터링 (Clustering)하는 영상처리기술을 적용하여 영상에 존재하는 사물의 위치를 파악할 수 있다. 일 예를 들면, 도 6에서 목적물 후보는 입력된 영상에 대해 위에서 설명한 영상 처리 과정을 통해서 인식되는 필기구, 컵, 가위가 목적물 후보가 될 수 있다. 따라서, 상기 인식된 필기구, 컵, 가 위들에 대한 목적물 인식 정보 및 목적물 위치 정보를 포함한 목적물 정보들이 설정되어 목적물 결정부 로 전달될 수 있다. 또한, 상기 영상 인식부는 위에서 설명한 것처럼 입력된 영상에서 인식되는 모든 사물들을 목적물 후보로 인식 하여 목적물 정보를 설정할 수도 있지만, 피험자의 시각 방향과 제어하고자 하는 대상물의 방향 등의 여러 상황 을 고려하여 인식된 사물들 중에서 일부만을 목적물 후보로 인식할 수도 있다. 목적물 후보들은 상황의 변화에 따라 재인식될 수 있음을 유념해야 한다. 예를 들어, 피험자의 뇌파 신호로부터 변환된 변환 뇌파 정보가 일정 시간 이전의 변환 뇌파 정보와 비교할 때 일정 값 이상의 변화를 보이거나, 피험 자의 시각 방향이나 고개의 방향이 일정 범위 이상의 변화를 보이거나, 영상 인식 및 근거리 통신 등을 통해서 파악된 사물들의 목적물 정보가 일정 값 이상의 변화를 보이는 등의 경우에는 목적물 후보들을 재인식 가능할 것이다. 또는, 위에서 예로 든 각 경우를 별도로 구별하지 않고, 종합적으로 판단하여 피험자의 대상물 제어에 대한 목 적물이 변화되었다고 판단되는 경우에도 목적물 후보들을 재인식 가능할 것이다. 위 설명과 같은 목적물 후보들의 파악을 위한 상황 변화 여부를 판단하기 위해서, 소정 값 이상의 변화를 상황 변화로 판단할 수도 있고, 인공 신경망(Artificial Neural Network) 등의 인공 지능(Artificial Intelligence) 기법을 적용하여 상황 변화를 판단할 수도 있다. 또한, 상기 영상 인식부는 도 6의 경우와 같은 사물들뿐만 아니라, 도 10에서 볼 수 있는 것처럼 도로의 차선 표시(1011, 1012), 디스플레이에 표시되는 응용 프로그램의 볼륨 또는 진행 조절 컨트롤 주위의 레벨표시 , 디스플레이에 표시되는 마우스 포인터의 주변 아이콘이나 클릭 가능한 개체(1032, 1033) 등처럼 주변 배경과 다르게 구별 가능하다면 목적물 후보로 인식할 수 있다. 또한, 상기 영상 인식부는 입력된 영상에 존재하는 사물들을 대상물의 상황을 고려하여 목적물 후보들로 인식할 수도 있다. 예를 들어 도 10에서 대상물이 자동차이고 도로를 주행하는 경우에, 대상물에 앞서 진행하는 다른 자동차, 진행 차선 표시를 사물로 인식 가능하지만, 대상물인 자동차의 주행 상황을 고려하여 전방의 자동차가 너무 근거리이거나 대상물이 자동차라는 점을 고려하여 목적물 후보로 인식하지 않을 수 있다. 이와 비슷하게, 도 10에서 대상물이 휠체어이고 보도를 진행하는 경우에, 주변 사물로 버스 정류장 표시 , 보도에 서 있는 사람, 차도의 자동차 등을 사물로 인식 가능하지만, 휠체어가 대상물이라 는 점을 고려하여 보도에 서 있는 사람, 차도의 자동차는 목적물 후보로 인식하지 않을 수 있다.또한, 이 경우에도 입력된 영상과 대상물의 상황을 고려하여, 다른 자동차의 번호판은 자동차를 목적물 후보로 인식함으로써 충분히 목적을 달성할 수 있으므로, 주변 배경과 다르게 구별 가능함에도 불구하고 목적물 후보로 인식하지 않을 수 있다. 도 3을 참조하면 뇌-컴퓨터 인터페이스 장치는 영상 인식부에서 스테레오 카메라로부터 촬영된 스테레오 이미지를 입력 받고, 상기 스테레오 이미지로부터 추출된 사물들의 3차원 위치 정보를 이용하여 목적물 위치 정 보를 포함한 목적물 정보를 설정할 수 있다. 도 11을 참조하면, 영상 인식부는 스테레오 영상에 대해 영상 정합(Image Matching) 등의 기술을 통해 사물의 깊이 정보를 구하여 사물의 3차원 위치정보를 얻고, 이를 이용해 목적물 위치 정보를 포함한 목적물 정보 를 설정할 수 있다. 뇌-컴퓨터 인터페이스 장치의 대상물은 인공 팔, 마우스 커서, 디스플레이에 표시되는 응용 프로그램의 컨트롤 수단, 오디오 장치의 컨트롤 수단, 휠체어 및 자동차 중 어느 하나일 수 있다. 도2를 참조하면, 디스플레이에 표시되는 응용 프로그램이 동영상 재생프로그램이거나 음악 재생 프로 그램일 경우, 대상물은 상기 프로그램들에서 각각 볼륨 컨트롤 수단 또는 재생 진행 컨트롤 수단일 수 있 다. 도 7에 나타난 본 발명의 실시예에 따른 뇌-컴퓨터 인터페이스 방법은, 변환 뇌파 정보를 입력받는 단계, 대상물 제어 정보를 추출하는 단계, 목적물 정보를 입력받는 단계, 상기 목적물 정보를 이용하여 상 기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하는 단계를 포함한다. 변환 뇌파정보를 입력받는 단계는 대상물 동작 정보를 포함하는 변환 뇌파 정보를 입력받는 단계이다. 대상물 제어 정보를 추출하는 단계는 상기 변환 뇌파 정보로부터 대상물 인식 정보 및 대상물 동작 정보를 포함한 대상물 제어 정보를 추출하는 단계이다. 피험자로부터 측정된 뇌파 신호들에서 피험자가 의도하는 대상 물에 관한 동작정보(대상물 동작정보)를 추출하여 구성한 변환 뇌파 정보로부터 대상물 제어 정보를 추출한다. 목적물 정보를 입력받는 단계는 목적물의 목적물 위치 정보를 포함한 목적물 정보를 입력받는다. 상기 목 적물은 목적물 후보가 아닌 최종 목적물을 의미하며, 입력받는 목적물 정보는 적어도 하나 이상의 목적물에 대 한 목적물 정보일 수 있다. 또한, 상기 목적물 정보는 목적물 인식 정보를 포함할 수도 있다. 목적물 정보를 이용하여 상기 대상물 제어 정보를 보정한 대상물 최종 제어 정보를 출력하는 단계는 입력 된 목적물 정보를 이용하여 상기 대상물 제어 정보를 보정한다. 목적물 정보의 목적물 위치 정보나 대상물 동작 정보는 명확한 숫자 값이 아닌 도 12에서처럼 확률 값의 분포로 도 표현될 수 있다. 이 경우 대상물 최종 제어 정보는 양 분포를 고려하여 대상물 제어 정보를 보정할 수 있다. 대상물 최종 제어 정보는 대상물의 움직임과 이에 따른 변환 뇌파 정보로부터 추출된 대상물 제어 정보 변화 및 이에 따른 목적물 후보들의 목적물 정보 변화에 따라 계속 변화하여 설정될 수 있다.도 8에 나타난 본 발명의 실시예에 따른 뇌-컴퓨터 인터페이스 방법은, 뇌파 신호를 입력받는 단계, 변환 뇌파 정보로 변환하는 단계, 목적물 후보들에 대한 목적물 정보를 입력받는 단계, 목적물을 결정하는 단계를 더 포함한다. 뇌파 신호를 입력받는 단계는 피험자로부터 측정된 EEG, MEG 등의 뇌파 신호를 입력받는다."}
{"patent_id": "10-2011-0104176", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "변환 뇌파 정보로 변환하는 단계는 입력된 뇌파 신호로부터 대상물 동작 정보 등을 판단하여 변환 뇌파 정 보로 변환한다. 목적물 후보들에 대한 목적물 정보를 입력받는 단계는 피험자 주변이나 대상물 주변에 존재하는 목적물 후 보들의 목적물 위치 정보를 포함하는 목적물 정보를 입력받는다. 또한, 상기 목적물 정보는 목적물 인식 정보를 포함할 수도 있다. 목적물을 결정하는 단계는 적어도 하나 이상의 목적물 후보들에 대한 목적물 정보들 중에서 대상물의 제어 에 대한 목적물을 결정한다. 상기 결정되는 목적물은 적어도 하나 이상의 목적물일 수 있다. 상기 변환 뇌파 정보로 변환하는 단계는 입력된 뇌파신호 또는 잡음 제거 등의 전처리(Pre-processing) 과 정을 거친 뇌파신호에 대해 특징 추출(Feature Extract) 과정을 포함하는 신호 처리 과정, 추출된 특징을 이용 해 대상물 동작 정보를 판단하는 과정을 포함하는 데이터 분류 및 판단(Classification) 과정을 포함할 수 있다. 도 9에 나타난 본 발명의 실시예에 따른 뇌-컴퓨터 인터페이스 방법은, 영상을 입력 받는 단계, 목적물 후 보들에 대한 목적물 정보를 추출하는 단계를 더 포함한다. 영상을 입력 받는 단계는 피험자 주변이나 대상물 주변에 존재하는 사물들에 대한 영상을 입력 받는다. 상기 입력되는 영상은, 뇌파 신호가 측정되는 피험자 주변의 영상이며, 특히 피험자의 고개가 향한 방향이나 시 선이 향한 방향의 주변 영상이 적합할 것이다. 목적물 후보들에 대한 목적물 정보를 추출하는 단계는 입력된 영상으로부터 영상 전처리 과정이나 사물들 을 클러스터링(Clustering)하는 영상 처리 기술들과 입력된 영상으로부터 파악된 사물의 위치와 형태에 대한 정 보를 이용하여 목적물 후보들의 목적물 위치 정보를 포함한 목적물 정보를 추출할 수 있다. 또한, 상기 목적물 정보는 목적물 인식 정보를 포함할 수도 있다. 상기 입력된 영상은 스테레오 카메라로부터 촬영된 스테레오 영상이고, 상기 목적물 위치 정보는 스테레오 영상 으로부터 얻어진 깊이 정보를 이용하여 생성된 3차원 위치 정보일 수 있다. 본 발명의 이해를 돕기 위해 설명된 실시예들에서 사용된 특정 용어들이 본 발명을 한정하는 것은 아니다. 본 발명은 통상의 기술자들에게 당연한 모든 구성 요소 및 동등한 가치를 갖는 모든 구성 요소를 포함할 수 있다.부호의 설명 110: 뇌파 신호를 측정하는 전극을 부착한 피험자 및 뇌파 신호 변환 인터페이스 130: 뇌-컴퓨터 인터페이스 장치 150: 대상물들 151: 인공 팔 153: 휠체어 210: 디스플레이 화면 230: 디스플레이에 표시된 응용 프로그램 235: 디스플레이에 표시된 응용 프로그램의 컨트롤 237: 디스플레이에 표시된 응용 프로그램의 컨트롤 레벨 310: 뇌파 신호를 측정하는 전극을 부착한 피험자 330: 뇌-컴퓨터 인터페이스 장치 370: 스테레오 영상 카메라 390: 목적물들 410: 뇌파 신호를 측정하는 전극을 부착한 피험자 430: 뇌-컴퓨터 인터페이스 장치 497: NFC, ZigBee 등의 센서 610: 뇌-컴퓨터 인터페이스 장치에 입력된 영상 1201: 대상물 동작 정보 1202: 보정된 대상물 동작 정보 1203: 목적물 위치 정보도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2011-0104176", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명인 뇌-컴퓨터 인터페이스 장치의 일 실시예이다. 도 2는 본 발명인 뇌-컴퓨터 인터페이스 장치의 목적물이 디스플레이에 표시되는 응용 프로그램의 컨트롤 수단 인 경우를 보여주는 일 실시예이다. 도 3은 본 발명인 뇌-컴퓨터 인터페이스 장치의 일 실시예이다. 도 4는 본 발명인 뇌-컴퓨터 인터페이스 장치의 일 실시예이다. 도 5는 본 발명인 뇌-컴퓨터 인터페이스 장치의 블록도를 나타내는 일 실시예이다. 도 6은 입력된 영상의 영상 인식을 통해 목적물 정보를 파악하는 일 실시예이다. 도 7, 도 8 및 도 9는 본 발명의 실시예들에 따른 뇌-컴퓨터 인터페이스 방법의 단계를 나타낸 순서도들이다. 도 10은 입력된 영상의 영상 인식을 통해 목적물 정보를 파악하는 일 실시예이다. 도 11은 입력된 스테레오 영상의 영상 인식을 통해 사물들의 깊이 정보를 파악하는 일 실시예이다. 도 12는 대상물 동작 정보와 목적물 위치 정보 및 보정된 대상물 동작 정보의 일 실시예이다."}
