{"patent_id": "10-2022-0002953", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0107042", "출원번호": "10-2022-0002953", "발명의 명칭": "전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "박별"}}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서, 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,이미지 정보, 주변 상황 정보, 및 사용자 취향 정보 중 적어도 하나를 포함하는, 음원 생성 정보를 획득하고, 상기 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득하고,상기 음원 생성 태그들에 기반하여 음원을 생성하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하고, 상기 필터링된 음원 생성 태그들을 이용하여 상기 음원을 생성하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,인식 결과의 정확도, 태그 별 중복도, 및 태그 별 웨이트 중 적어도 하나에 기반하여, 상기 이미지 정보에 매핑되는 음원 생성 태그들 별 점수를 획득하고, 상기 이미지 정보에 매핑되는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하여 제1 태그들을 획득하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상황에 따른 사용자 선호도를 나타내는 상황 기반 태그 별 웨이트에 기반하여, 상기 주변 상황 정보에 매핑되는음원 생성 태그들 별 점수를 획득하고, 상기 주변 상황 정보에 매핑되는 음원 생성 태그들 중 높은 점수를 갖는음원 생성 태그들을 필터링하여 제2 태그들을 획득하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 태그들 및 상기 제2 태그들 중 적어도 하나를 이용하여, 상기 음원을 생성하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 주변 상황 정보 및 사용자 식별 정보 중 적어도 하나에 기반하여, 상기 필터링된 음원 생성 태그들을 추가로 필터링하고, 상기 추가로 필터링된 태그들을 이용하여 상기 음원을 생성하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 사용자 취향 정보 및 음악 재생 이력 정보 중 적어도 하나에 기반하여 사용자 선호도를 나타내는 태그 별공개특허 10-2023-0107042-3-웨이트를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 생성된 음원에 따라 음악을 재생하고, 음악 재생 정보에 따라 상기 태그 별 웨이트를 업데이트하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서, 상기 음악 재생 정보는 상기 음악의 재생 빈도, 음악 전체 청취 정도, 재생 중단 정도, 빨리감기 정도, 스킵 정도에 대한 정보를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서, 디스플레이를 더 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 디스플레이에 출력되는 이미지에 대한 부가 정보, 상기 이미지에서 식별된 컬러나 스타일, 상기 이미지에서 식별된 오브젝트의 종류, 및 상기 식별된 오브젝트가 사람인 경우 사람의 표정 중 적어도 하나에 기반하여상기 이미지 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 항에 있어서, 카메라, 센서 및 통신 모듈 중 적어도 하나를 더 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 카메라, 상기 센서 및 상기 통신 모듈 중 적어도 하나로부터 획득된, 사용자 유무에 대한 정보, 날씨정보, 날짜 정보, 시간 정보, 계절 정보, 공휴일 정보, 기념일 정보, 온도 정보, 조도 정보 및 위치 정보 중 적어도 하나로부터 상기 주변 상황 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,사용자 프로필 정보, 사용자의 시청 이력 정보, 및 사용자로부터 선택 받은 선호 음악 정보 중 적어도 하나로부터 상기 사용자 취향 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "이미지 정보, 주변 상황 정보, 및 사용자 취향 정보 중 적어도 하나를 포함하는, 음원 생성 정보를 획득하는 단계; 상기 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득하는 단계; 및상기 음원 생성 태그들에 기반하여 음원을 생성하는 단계를 포함하는, 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서, 상기 음원을 생성하는 단계는상기 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하는 단계; 및상기 필터링된 음원 생성 태그들을 이용하여 상기 음원을 생성하는 단계를 포함하는, 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서, 상기 음원 생성 태그들을 필터링하는 단계는인식 결과의 정확도, 태그 별 중복도, 및 사용자 선호도를 나타내는 태그 별 웨이트 중 적어도 하나에공개특허 10-2023-0107042-4-기반하여, 상기 이미지 정보에 매핑되는 음원 생성 태그들 별 점수를 획득하는 단계; 및상기 이미지 정보에 매핑되는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하여 제1 태그들을 획득하는 단계를 포함하는, 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서, 상기 음원 생성 태그들을 필터링하는 단계는상황에 따른 사용자 선호도를 나타내는 상황 기반 태그 별 웨이트에 기반하여, 상기 주변 상황 정보에 매핑되는음원 생성 태그들 별 점수를 획득하는 단계; 및상기 주변 상황 정보에 매핑되는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하여 제2 태그들을 획득하는 단계를 포함하는, 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서, 상기 음원을 생성하는 단계는 상기 제1 태그들 및 상기 제2 태그들 중 적어도 하나를 이용하여, 상기 음원을 생성하는 단계를 포함하는, 전자장치의 동작 방법."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14 항에 있어서, 상기 주변 상황 정보 및 사용자 식별 정보 중 적어도 하나에 기반하여, 상기 필터링된 음원생성 태그들을 추가로 필터링하는 단계를 더 포함하고, 상기 음원을 생성하는 단계는 상기 추가로 필터링된 태그들을 이용하여 상기 음원을 생성하는 단계를 포함하는,전자 장치의 동작 방법."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13 항에 있어서, 상기 사용자 취향 정보 및 음악 재생 이력 정보 중 적어도 하나에 기반하여 사용자 선호도를나타내는 태그 별 웨이트를 획득하는 단계; 상기 생성된 음원에 따라 음악을 재생하는 단계; 및음악 재생 정보에 따라 상기 태그 별 웨이트를 업데이트하는 단계를 더 포함하는, 전자 장치의 동작 방법."}
{"patent_id": "10-2022-0002953", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "이미지 정보, 주변 상황 정보, 및 사용자 취향 정보 중 적어도 하나를 포함하는, 음원 생성 정보를 획득하는 단계; 상기 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득하는 단계; 및상기 음원 생성 태그들에 기반하여 음원을 생성하는 단계를 포함하는, 전자 장치의 동작 방법을 구현하기 위한프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2022-0002953", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이미지 정보, 주변 상황 정보, 및 사용자 취향 정보 중 적어도 하나를 포함하는, 음원 생성 정보를 획득하는 단 계, 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득하는 단계 및 음원 생성 태그들에 기반하여 음원을 생성 하는 단계를 포함하는, 전자 장치의 동작 방법이 개시된다."}
{"patent_id": "10-2022-0002953", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 다양한 실시 예들은 전자 장치 및 그 동작 방법에 관한 것으로, 보다 상세하게는 화면에 출력되는 이미 지나 주변 상황 등을 기반으로 자동으로 음악을 생성하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0002953", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사용자는 전자 장치를 이용하여 사진이나 이미지, 디지털 작품 등을 감상할 수 있다. 사용자는 정적인 환경에서 사진이나 이미지를 보는 것 보다 사진이나 주변 상황 등에 어울리는 배경 음악을 청취하면서 이미지를 감상하는 것을 더 선호할 수 있다. 기존에 이미 생성된 음악은 사용자 취향, 화면에 현재 출력되는 사진이나 현재의 주변 상황 등과 같이 매번 바 뀌는 다양한 상황을 모두 반영하기 힘들다는 한계가 있다. 따라서, 전자 장치에서 현재 출력되는 이미지나 주변 상황, 사용자 취향 등을 자동으로 고려하여 이미지에 어울리는 음악을 생성하고 이를 사용자에게 제공하는 기술 이 요구된다."}
{"patent_id": "10-2022-0002953", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다양한 실시 예들은 이미지 정보, 주변 상황 정보, 사용자 취향 정보 중 적어도 하나를 음원 생성 정보로 획득 하고, 이를 고려하여 음원을 생성하는 전자 장치 및 그 동작 방법을 제공하기 위한 것이다. 다양한 실시 예들은 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득하고, 음원 생성 태그들에 기반하여 음 원을 생성하는 전자 장치 및 그 동작 방법을 제공하기 위한 것이다. 다양한 실시 예들은 점수에 따라 음원 생성 태그들을 필터링하고 필터링된 음원 생성 태그들에 기반하여 음원을 생성하는 전자 장치 및 그 동작 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2022-0002953", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시 예에 따른 전자 장치는 하나 이상의 인스트럭션을 저장하는 메모리 및 상기 메모리에 저장된 상기 하나 이 상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로 써, 이미지 정보, 주변 상황 정보, 및 사용자 취향 정보 중 적어도 하나를 포함하는, 음원 생성 정보를 획득하 고, 상기 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득하고, 상기 음원 생성 태그들에 기반하여 음원을 생성할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하고, 상기 필터링된 음원 생성 태그들을 이용하여 상기 음원을 생성할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 인식 결과의 정확도, 태그 별 중 복도, 및 태그 별 웨이트 중 적어도 하나에 기반하여, 상기 이미지 정보에 매핑되는 음원 생성 태그들 별 점수 를 획득하고, 상기 이미지 정보에 매핑되는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링 하여 제1 태그들을 획득할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상황에 따른 사용자 선호도를 나 타내는 상황 기반 태그 별 웨이트에 기반하여, 상기 주변 상황 정보에 매핑되는 음원 생성 태그들 별 점수를 획 득하고, 상기 주변 상황 정보에 매핑되는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하 여 제2 태그들을 획득할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 태그들 및 상기 제2 태 그들 중 적어도 하나를 이용하여, 상기 음원을 생성할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 주변 상황 정보 및 사용자 식별 정보 중 적어도 하나에 기반하여, 상기 필터링된 음원 생성 태그들을 추가로 필터링하고, 상기 추가로 필 터링된 태그들을 이용하여 상기 음원을 생성할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 사용자 취향 정보 및 음악 재생 이력 정보 중 적어도 하나에 기반하여 사용자 선호도를 나타내는 태그 별 웨이트를 획득할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 생성된 음원에 따라 음악을 재생하고, 음악 재생 정보에 따라 상기 태그 별 웨이트를 업데이트할 수 있다. 실시 예에서, 상기 음악 재생 정보는 상기 음악의 재생 빈도, 음악 전체 청취 정도, 재생 중단 정도, 빨리 감기 정도, 스킵 정도에 대한 정보를 포함할 수 있다. 실시 예에서, 상기 전자 장치는 디스플레이를 더 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실 행함으로써, 상기 디스플레이에 출력되는 이미지에 대한 부가 정보, 상기 이미지에서 식별된 컬러나 스타일, 상 기 이미지에서 식별된 오브젝트의 종류, 및 상기 식별된 오브젝트가 사람인 경우 사람의 표정 중 적어도 하나에 기반하여 상기 이미지 정보를 획득할 수 있다. 실시 예에서, 상기 전자 장치는 카메라, 센서 및 통신 모듈 중 적어도 하나를 더 포함하고, 상기 프로세서는 상 기 하나 이상의 인스트럭션을 실행함으로써, 상기 카메라, 상기 센서 및 상기 통신 모듈 중 적어도 하나로부터 획득된, 사용자 유무에 대한 정보, 날씨 정보, 날짜 정보, 시간 정보, 계절 정보, 공휴일 정보, 기념일 정보, 온도 정보, 조도 정보 및 위치 정보 중 적어도 하나로부터 상기 주변 상황 정보를 획득할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 사용자 프로필 정보, 사용자의 시 청 이력 정보, 및 사용자로부터 선택 받은 선호 음악 정보 중 적어도 하나로부터 상기 사용자 취향 정보를 획득 할 수 있다. 실시 예에 따른 전자 장치의 동작 방법은 이미지 정보, 주변 상황 정보, 및 사용자 취향 정보 중 적어도 하나를 포함하는, 음원 생성 정보를 획득하는 단계, 상기 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득하는 단 계 및 상기 음원 생성 태그들에 기반하여 음원을 생성하는 단계를 포함할 수 있다. 실시 예에 따른 컴퓨터로 읽을 수 있는 기록 매체는 이미지 정보, 주변 상황 정보, 및 사용자 취향 정보 중 적 어도 하나를 포함하는, 음원 생성 정보를 획득하는 단계, 상기 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득하는 단계 및 상기 음원 생성 태그들에 기반하여 음원을 생성하는 단계를 포함하는, 전자 장치의 동작 방법 을 구현하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체일 수 있다."}
{"patent_id": "10-2022-0002953", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예에 따른 전자 장치 및 그 동작 방법은 이미지 정보, 주변 상황 정보, 사용자 취향 정보 중 적어도 하 나를 포함하는 음원 생성 정보를 획득하고, 이를 고려하여 음원을 생성할 수 있다. 일 실시 예에 따른 전자 장치 및 그 동작 방법은 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득하고, 음 원 생성 태그들에 기반하여 음원을 생성할 수 있다. 일 실시 예에 따른 전자 장치 및 그 동작 방법은 점수에 따라 음원 생성 태그들을 필터링하고 필터링된 음원 생 성 태그들에 기반하여 음원을 생성할 수 있다."}
{"patent_id": "10-2022-0002953", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시 예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시에서 사용되는 용어는, 본 개시에서 언급되는 기능을 고려하여 현재 사용되는 일반적인 용어로 기재되었 으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 다양한 다른 용어를 의미할 수 있다. 따라서 본 개시에서 사용되는 용어는 용어의 명칭만으로 해석되어서는 안되며, 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 해석되어야 한다. 또한, 본 개시에서 사용된 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것이며, 본 개시를 한정하려는 의도로 사용되는 것이 아니다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 본 명세서, 특히, 특허 청구 범위에서 사용된 “상기” 및 이와 유사한 지시어는 단수 및 복수 모두를 지시하는 것일 수 있다. 또한, 본 개시에 따른 방법을 설명하는 단계들의 순서를 명백하게 지정하는 기재가 없다면, 기재 된 단계들은 적당한 순서로 행해질 수 있다. 기재된 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아니 다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시 예에서\" 또는 \"일 실시 예에서\" 등의 어구는 반드시 모두 동일 한 실시 예를 가리키는 것은 아니다. 본 개시의 일부 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술 을 채용할 수 있다. “매커니즘”, “요소”, “수단” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 명세서에서 “사용자”라는 용어는 전자 장치를 이용하는 사람을 의미하며, 소비자, 평가자, 시청자, 관 리자 또는 설치 기사를 포함할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 실시 예에 따라, 음원 생성 정보에 기반하여 음악을 생성하고 이를 사용자에게 제공하는 것을 설명하기 위한 도면이다. 도 1을 참조하면, 전자 장치는 화면에 이미지를 출력할 수 있다. 실시 예에서, 전자 장치는 화면을 포함하는 다양한 형태의 디스플레이 장치로 구현될 수 있다. 일 실시 예 로, 도 1은 전자 장치가 디지털 TV인 경우를 도시한다. 예컨대, 전자 장치는 앰비언트(Ambient) 서비스를 실행하여 화면에 이미지를 출력할 수 있다. 앰비언트 서 비스는 디지털 TV 등의 디스플레이 장치가 오프(off) 상태일 때 블랙 화면 대신에, 그림, 사진, 또는 시계 등과 같이 의미 있는 이미지가 디스플레이 되도록 하는 서비스를 의미할 수 있다. 전자 장치는 전자 장치 내부에 기 저장되어 있는 이미지를 화면에 출력하거나 또는 외부 서버로부터 앰비언트 서비스 실행을 위한 이미지 등을 수신하여 화면에 출력할 수 있다. 또는 전자 장치는 주변 기기 와 유무선 통신을 수행하여 주변 기기에 저장된 사진이나 작품 이미지 등을 전자 장치의 화면을 통해 출력할 수 있다. 예컨대, 전자 장치는 USB(미도시), PC(미도시), 태블릿(미도시), 핸드폰(미도시) 등과 같은 사용자 단말기에 저장되어 있는 사진이나 그림 등을 전자 장치의 화면에 출력할 수 있다. 실시 예에서, 전자 장치는 음원 생성 정보를 획득할 수 있다. 실시 예에서, 음원 생성 정보는 음원 생성을 위해 수집되는 정보로, 음원 생성에 영향을 주는 정보를 의미할 수 있다. 실시 예에서, 음원 생성에 영향을 주는 정보는 화면에서 출력되는 이미지, 사용자 주변의 외부 형편이나 상태를 나타내는 정보, 또는 사용자의 선호도나 취향 등에 대한 정보를 포함할 수 있다. 실시 예에서, 전자 장치는 화면에서 출력되는 이미지에 대한 정보를 이미지 정보로, 주변의 형편이나 상태 를 나타내는 정보를 주변 상황 정보로, 사용자의 선호도나 취향을 나타내는 정보를 사용자 취향 정보로 획득할 수 있다. 실시 예에서, 전자 장치는 화면에 출력되는 이미지로부터 이미지 정보를 획득할 수 있다. 이미지 정보는 화면에 출력되는 이미지 자체의 고유 특성에 대한 정보일 수 있다. 이미지 정보는 화면에 출력되는 이미지에서 식별된 컬러나 스타일, 이미지에서 식별된 오브젝트의 종류, 및 식별된 오브젝트가 사람인 경우 사람의 표정 중 적어도 하나를 포함할 수 있다. 또한 이미지 정보는 이미지에 대한 부가 정보를 포함할 수 있다. 도 1에서는 일 예로, 전자 장치가 앰비언트 서비스를 실행하여 화면에 빈센트 반 고흐의 명화인 ‘해바라 기’ 작품을 출력한 것을 도시한다. 전자 장치는 화면에 출력된 이미지를 분석하여, 이미지에 포함된 오브젝트가 해바라기이고, 이미지의 스타 일 정보가 빈센트 반 고흐 풍의 명화라는 것과 컬러가 진한 노란색이라는 정보, 기타 빈센트 반 고흐에 대한 설 명이나 해바라기 작품에 대한 부가 정보 중 적어도 하나를 획득할 수 있다. 실시 예에서, 전자 장치는 주변 상황 정보를 획득할 수 있다. 주변 상황 정보는 전자 장치 및 사용자 가 위치한 장소의 주변 또는 밖의 상황을 표시하는 정보를 의미할 수 있다. 주변 상황 정보는, 전자 장치 에 구비된 카메라나, 센서를 통해 획득되거나, 또는 외부 서버로부터 수신하여 획득될 수 있다. 예컨대, 주변 상황 정보는 사용자 유무에 대한 정보, 날씨 정보, 날짜 정보, 시간 정보, 계절 정보, 공휴일 정보, 기념일 정 보, 온도 정보, 조도 정보 및 위치 정보 중 적어도 하나를 포함할 수 있다. 예컨대, 도 1에서, 전자 장치는 온도 센서(미도시)를 통해 주변의 온도가 섭씨 20도라는 정보를 획득하거 나 조도 센서(미도시)를 통해 조도가 300룩스(lx)라는 정보를 획득할 수 있다. 또는, 전자 장치는 통신 모 듈(미도시)을 통해 외부 서버 등으로부터 현재 시각이 오후 시각이고, 주변 날씨는 따뜻하고, 계절은 가을이고, 오늘 날짜는 9월 5일이고, 전자 장치의 위치는 미국 워싱턴 주의 시애틀 지역이라는 정보 등을 획득할 수 있다. 실시 예에서, 전자 장치는 사용자 취향 정보를 획득할 수 있다. 사용자 취향 정보는 사용자의 취미나 선호 하는 방향을 나타내는 정보를 의미할 수 있다. 실시 예에서, 사용자 취향 정보는 사용자 프로필 정보나 사용자 의 시청 이력 정보로부터 획득될 수 있다. 또는 실시 예에서, 사용자 취향 정보는 사용자로부터 직접 선호 음악 정보를 선택 받아 획득될 수 있다. 또는 사용자 취향 정보는 사용자의 이전 음악 청취 이력이 있는 경우, 이전 음악 청취 이력에 기반하여 획득될 수 있다. 예컨대, 도 1에서, 전자 장치는 사용자의 프로필 정보로부터 사용자가 30대 여성이고, 전자 장치의 시청 이력으로부터 사용자가 선호하는 프로그램이 멜로 드라마라는 정보 등을 획득하고 이로부터 사용자의 취향 을 추론할 수 있다. 또는 전자 장치는 사용자가 선호한다고 입력한 음악 정보 또는 사용자가 이전에 청취 한 음악이 클래식 곡이고, 조용한 곡이고, 피아노와 바이올린 악기로 연주된 곡인 경우, 이로부터 사용자의 취 향을 추론할 수 있다. 실시 예에서, 전자 장치는 이미지 정보, 주변 상황 정보, 사용자 취향 정보 중 적어도 하나를 포함하는 음 원 생성 정보를 획득하고, 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득할 수 있다. 실시 예에서, 전자 장치는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링할 수 있다. 실시 예에서, 전자 장치는 음원 생성 태그들을 필터링하기 위해 태그 별 웨이트를 획득할 수 있다. 전자 장치는 사용자 취향 정보 및 음악 재생 이력 정보 중 적어도 하나에 기반하여 각 태그에 대한 사용자 선호 도를 나타내는 태그 별 웨이트를 획득할 수 있다. 실시 예에서, 전자 장치는 인식 결과의 정확도, 태그 별 중복도, 및 태그 별 웨이트 중 적어도 하나에 기 반하여, 이미지 정보에 매핑되는 음원 생성 태그들 별 점수를 획득하고, 이미지 정보에 매핑되는 음원 생성 태 그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하여 제1 태그들을 획득할 수 있다. 실시 예에서, 전자 장치는 상황에 따른 사용자 선호도를 나타내는 상황 기반 태그 별 웨이트를 획득할 수 있다. 전자 장치는 상황 기반 태그 별 웨이트에 기반하여, 주변 상황 정보에 매핑되는 음원 생성 태그들 별 점수를 획득하고, 주변 상황 정보에 매핑되는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필 터링하여 제2 태그들을 획득할 수 있다. 실시 예에서, 전자 장치는 제1 태그들 및 제2 태그들 중 적어도 하나를 이용하여 음원을 생성할 수 있다. 경우에 따라, 전자 장치는 주변 상황 정보 및 사용자 식별 정보 중 적어도 하나에 기반하여, 필터링된 음 원 생성 태그들을 추가로 필터링하고, 추가로 필터링된 태그들을 이용하여 음원을 생성할 수도 있다. 실시 예에서, 전자 장치는 적어도 하나의 뉴럴 네트워크를 이용하여, 음원 생성 태그들로부터 음원을 생성 할 수 있다. 전자 장치가 이용하는 뉴럴 네트워크는 태그와 음원을 학습 데이터 셋으로 이용하여 훈련된 뉴럴 네트워크일 수 있다. 실시 예에서, 전자 장치는 생성된 음원에 따라 음악을 재생할 수 있다. 실시 예에서, 전자 장치는 사용자가 음악을 재생하는 정도를 나타내는 음악 재생 정보를 획득하고, 음악 재생 정보에 따라 태그 별 웨이트를 업데이트할 수 있다. 실시 예에서, 음악 재생 정보는 음악의 재생 빈도, 음 악 전체 청취 정도, 재생 중단 정도, 빨리 감기 정도, 스킵 정도에 대한 정보를 포함할 수 있다. 이와 같이, 실시 예에 따르면, 전자 장치는 다양한 형태의 음원 생성 정보를 획득하고, 음원 생성 정보에 기반하여 이미지, 주변 상황, 사용자 취향 등에 맞는 음원을 생성함으로써, 사용자에게 감상하는 이미지, 주변 상황, 기타 사용자 취향 등에 어울리는 음악을 제공 할 수 있다. 도 2는 실시 예에 따른 전자 장치의 일 예의 내부 블록도이다. 도 2의 전자 장치(100a)는 도 1의 전자 장치의 일 예일 수 있다. 실시 예에서, 전자 장치(100a)는 화면을 통해 이미지를 출력할 수 있는 다양한 형태의 디스플레이 장치로 구현 될 수 있다. 디스플레이 장치는 이미지를 사용자에게 시각적으로 출력하는 장치일 수 있다. 예컨대, 전자 장치 (100a)는 디지털 텔레비전, 웨어러블 디바이스, 스마트 폰, 각종 PC(personal computer)들, 예컨대 데스크 톱 (desk top), 태블릿 PC, 랩탑 컴퓨터, PDA(personal digital assistant), GPS(global positioning system) 장 치, 스마트 미러(smart mirror), 전자책 단말기, 네비게이션, 키오스크, 디지털 카메라, 웨어러블 장치 (wearable device), 스마트 와치(smart watch), 홈네트워크 장치, 보안용 장치, 의료 장치 등과 같은 다양한 형태의 전자 기기일 수 있다. 전자 장치(100a)는 고정형 또는 이동형일 수 있다. 또는 전자 장치(100a)는 냉장고나 세탁기 등과 같은 다양한 형태의 가전 제품 등의 전면에 삽입되는 디스플레이 와 같은 형태일 수도 있다. 또는, 전자 장치(100a)는 화면을 포함하는 디스플레이 장치와 유선 또는 무선 통신망을 통해 연결된 전자 장치 로 구현될 수도 있다. 예컨대, 전자 장치(100a)는 미디어 플레이어나, 셋탑 박스, 인공지능(AI) 스피커 등의 형 태로 구현될 수도 있다. 또한, 본 개시의 실시 예에 따른 전자 장치(100a)는 전술한 디지털 텔레비전, 웨어러블 디바이스, 스마트 폰, 각종 PC(personal computer)들, 예컨대 데스크 톱(desk top), 태블릿 PC, 랩탑 컴퓨터, PDA(personal digital assistant), 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 스마트 미러(smart mirror), 전자책 단말기, 네비게이션, 키오스크, 디지털 카메라, 웨어러블 장치(wearable device), 스마트 와치 (smart watch), 홈네트워크 장치, 보안용 장치, 의료 장치, 냉장고나 세탁기, 기타 가전 제품 등의 전면에 삽입 되는 디스플레이, 미디어 플레이어, 셋탑 박스나 인공지능(AI) 스피커 등과 같은 다양한 형태의 전자 기기에 포 함되거나 탑재되는 형태로 형성될 수 있다. 도 2를 참조하면, 전자 장치(100a)는 프로세서 및 메모리를 포함할 수 있다. 실시 예에 따른 메모리는, 적어도 하나의 인스트럭션을 저장할 수 있다. 메모리는 프로세서가 실행하는 적어도 하나의 프로그램을 저장하고 있을 수 있다. 메모리에는 기 정의된 동작 규칙이나 프로그 램이 저장될 수 있다. 또한 메모리는 전자 장치(100a)로 입력되거나 전자 장치(100a)로부터 출력되는 데이터를 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 실시 예에서, 메모리는 음원 생성 정보를 획득하기 위한 하나 이상의 인스트럭션을 포함할 수 있다. 실시 예에서, 메모리는 태그 별 웨이트를 획득하기 위한 하나 이상의 인스트럭션을 포함할 수 있다. 실시 예에서, 메모리는 태그 별 웨이트를 저장할 수 있다. 실시 예에서, 메모리는 태그 별 웨이트를 업데이트하기 위한 하나 이상의 인스트럭션을 포함할 수 있다. 실시 예에서, 메모리에는 태그로부터 음원을 생성하기 위한 소프트웨어가 저장될 수 있다. 실시 예에서, 메모리에는 적어도 하나의 뉴럴 네트워크 및/또는 기 정의된 동작 규칙이나 AI 모델이 저장 될 수 있다. 실시 예에서, 메모리에 저장된 적어도 하나의 뉴럴 네트워크 및/또는 기 정의된 동작 규칙이 나 AI 모델은 태그로부터 음원을 생성하기 위한 하나 이상의 인스트럭션을 포함할 수 있다. 실시 예에서, 프로세서는 전자 장치(100a)의 전반적인 동작을 제어한다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 전자 장치(100a)가 기능하도록 제어할 수 있다. 실시 예에서, 프로세서는 음원 생성 정보를 획득할 수 있다. 음원 생성 정보는 이미지 정보, 주변 상황 정 보, 및 사용자 취향 정보 중 적어도 하나를 포함할 수 있다. 실시 예에서, 전자 장치(100a)는 디스플레이(미도시)를 더 포함할 수 있다. 실시 예에서, 프로세서는 디스플레이에 출력되는 이미지에 대한 부가 정보, 이미지에서 식별된 컬러나 스 타일, 이미지에서 식별된 오브젝트의 종류, 및 식별된 오브젝트가 사람인 경우 사람의 표정 중 적어도 하나에 기반하여 이미지 정보를 획득할 수 있다. 실시 예에서, 전자 장치(100a)는 카메라(미도시), 센서(미도시) 및 통신 모듈(미도시) 중 적어도 하나를 더 포 함할 수 있다. 실시 예에서, 프로세서는 카메라, 센서 및 통신 모듈 중 적어도 하나로부터 획득된, 사용자 유무에 대한 정보, 날씨 정보, 날짜 정보, 시간 정보, 계절 정보, 공휴일 정보, 기념일 정보, 온도 정보, 조도 정보 및 위치 정보 중 적어도 하나로부터 주변 상황 정보를 획득할 수 있다. 실시 예에서, 프로세서는 사용자 프로필 정보, 사용자의 시청 이력 정보, 및 사용자로부터 선택 받은 선호 음악 정보 중 적어도 하나로부터 사용자 취향 정보를 획득할 수 있다. 실시 예에서, 프로세서는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하고, 필터링 된 음원 생성 태그들을 이용하여 음원을 생성할 수 있다. 실시 예에서, 프로세서는 인식 결과의 정확도, 태그 별 중복도, 및 사용자 선호도를 나타내는 태그 별 웨 이트 중 적어도 하나에 기반하여, 이미지 정보에 매핑되는 음원 생성 태그들 별 점수를 획득하고, 이미지 정보 에 매핑되는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하여 제1 태그들을 획득할 수 있 다. 실시 예에서, 프로세서는 상황에 따른 사용자 선호도를 나타내는 상황 기반 태그 별 웨이트에 기반하여, 주변 상황 정보에 매핑되는 음원 생성 태그들 별 점수를 획득하고, 주변 상황 정보에 매핑되는 음원 생성 태그 들 중 높은 점수를 갖는 음원 생성 태그들을 필터링하여 제2 태그들을 획득할 수 있다. 실시 예에서, 프로세서는 제1 태그들 및 제2 태그들 중 적어도 하나를 이용하여, 음원을 생성할 수 있다. 실시 예에서, 프로세서는 주변 상황 정보 및 사용자 식별 정보 중 적어도 하나에 기반하여, 필터링된 음원 생성 태그들을 추가로 필터링하고, 추가로 필터링된 태그들을 이용하여 음원을 생성할 수 있다. 실시 예에서, 프로세서는 사용자 취향 정보 및 음악 재생 이력 정보 중 적어도 하나에 기반하여 사용자 선 호도를 나타내는 태그 별 웨이트를 획득할 수 있다. 실시 예에서, 프로세서는 생성된 음원에 따라 음악을 재생하고, 음악 재생 정보에 따라 태그 별 웨이트를 업데이트할 수 있다. 실시 예에서, 음악 재생 정보는 음악의 재생 빈도, 음악 전체 청취 정도, 재생 중단 정도, 빨리 감기 정도, 스 킵 정도에 대한 정보를 포함할 수 있다. 실시 예에서, 프로세서는, 이후 태그들 별 점수를 획득할 때, 업데이트된 태그 별 웨이트를 이용하여 음원 생성 태그들 별 점수를 획득할 수 있다. 실시 예에서, 프로세서는 음원 생성 태그들 별 점수가 높은 태그들을 필터링하고, 필터링된 음원 생성 태 그들을 이용하여 음원을 생성할 수 있다. 실시 예에서, 프로세서는 적어도 하나의 뉴럴 네트워크를 이용하여, 음원 생성 태그들로부터 음원을 획득 할 수 있다. 실시 예에서, 프로세서는 인공지능(Artificial Intelligence, AI) 기술을 이용할 수 있다. 실시 예에서, 프로세서는 AI 모델을 적어도 하나 저장하고 있을 수 있다. 실시 예에서 프로세서는 복수 개의 AI 모 델들을 이용하여 입력 데이터으로부터 출력 데이터를 생성할 수 있다. 또는, 프로세서가 아닌 메모리(22 0)가 AI 모델들, 즉, 뉴럴 네트워크를 저장하고 있을 수도 있다. 실시 예에서, 프로세서가 이용하는 뉴럴 네트워크는 태그들로부터 음원을 획득하도록 학습된 뉴럴 네트워 크일 수 있다. 실시 예에서, 프로세서는 뉴럴 네트워크를 이용하여 음원 생성 태그들로부터 음원을 획득할 수 있다. 실시 예에서, 뉴럴 네트워크는 GAN(Star Generative Adversarial Networks)을 포함할 수 있다. 도 3은 실시 예에 따른 도 2의 프로세서의 내부 블록도이다. 도 3을 참조하면, 프로세서는 음원 생성 정보 획득부, 음원 생성 태그 획득부, 음원 생성부 및 음악 재생부를 포함할 수 있다. 실시 예에 따른 음원 생성 정보 획득부는 음원 생성을 위해 다양한 음원 생성 정보를 획득할 수 있다. 실 시 예에서, 음원 생성 정보는 이미지 정보, 주변 상황 정보, 사용자 취향 정보 중 적어도 하나를 포함할 수 있 다. 음원 생성 정보 획득부가 음원 정보를 획득하는 방법에 대해서는 도 4 및 도 5에 대한 상세한 설명에 서 보다 구체적으로 설명하기로 한다. 실시 예에 따른 음원 생성 태그 획득부는 음원 생성 정보 획득부로부터 음원 생성 정보를 수신하고, 음원 생성 정보로부터 음원 생성 태그들을 도출할 수 있다. 실시 예에서, 음원 생성 태그 획득부는 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득할 수 있다. 실시 예에서, 태그는 정보에 할당된 키워드 또는 단어 등의 메타데이터를 의미할 수 있다. 정보에 태그가 할당 된다는 것은 정보에 다양한 분야나 다양한 속성의 태그가 연관 지어지는 것을 의미할 수 있다. 실시 예에서, 전자 장치(100a) 내부의 메모리나 데이터 베이스(미도시)에는 복수의 정보들 및 각각의 정보 들에 할당된 태그들이 저장되어 있을 수 있다. 또는 전자 장치(100a)가 아니라 외부 서버에 복수의 정보들 및 정보들에 할당된 태그들이 저장되어 있을 수 있다. 실시 예에서, 음원 생성 태그 획득부는 음원 생성 정보 획득부로부터 음원 생성 정보를 수신하고, 메 모리나 데이터 베이스, 또는 외부 서버에 저장된 수많은 정보 중 음원 생성 정보를 검색하고, 음원 생성 정보에 매핑되는 태그들을 검색할 수 있다. 이하, 복수의 태그들 중에서 음원 생성 정보에 매핑되는 태그들을 음원 생성 태그로 호칭하기로 한다. 실시 예에서, 음원 생성 태그 획득부는 음원 생성 태그들을 필터링할 수 있다. 실시 예에서, 음원 생성 태 그 획득부는 음원 생성 태그들을 필터링하기 위해, 각각의 음원 생성 태그들에 점수를 부여할 수 있다. 음 원 생성 태그 획득부는 음원 생성 태그들에 점수를 부여하기 위해 태그 별 웨이트를 획득할 수 있다. 태그 별 웨이트는 각 태그에 대한 사용자 선호도를 나타낼 수 있다. 실시 예에서, 음원 생성 태그 획득부는 사 용자 취향 정보나 음악 재생 이력 중 적어도 하나에 기반하여 태그 별 웨이트를 획득할 수 있다. 음원 생성 태그 획득부는 태그 별 웨이트나 태그의 중복도 등을 고려하여 태그 별 점수를 획득하고, 태그 별 점수에 따 라 음원 생성 태그들을 필터링할 수 있다. 실시 예에서, 음원 생성 태그 획득부는 주변 상황 정보나 사용자 프로필 정보 등에 따라 필터링된 음원 생 성 태그들을 추가로 더 필터링할 수도 있다. 음원 생성 태그 획득부는 필터링된 음원 생성 태그들을 음원 생성부로 전달할 수 있다. 실시 예에 따른 음원 생성부는 음원 생성 태그 획득부로부터 음원 생성 태그들을 수신하고 음원 생성 태그들을 이용하여 음원을 획득하거나, 또는 음원 생성을 위한 악보를 획득할 수 있다. 실시 예에서, 음원은 다 운로드 받거나 실시간 스트리밍하여 재생할 수 있는 형태의 음악 데이터를 의미할 수 있다. 예컨대, 음원은 mp3, midi, wav 등과 같은 재생 가능한 음악 파일 형태일 수 있다. 실시 예에서, 음원 생성부는 뉴럴 네트워크를 이용하여 음원을 획득할 수 있다. 음원 생성부가 이용 하는 뉴럴 네트워크는 음악 콘텐츠와 음악 콘텐츠에 어울리는 태그들을 학습 데이터 셋으로 이용하여 훈련된 뉴 럴 네트워크일 수 있다. 보다 구체적으로, 음악 콘텐츠는 조성, 코드, 멜로디, 비트, 박자, 템포, 리듬, 장르, 분위기 등의 텍스트 정보로 인코딩될 수 있다. 각 음악 콘텐츠 별로 어울리는 태그들이 라벨링되어 학습 데이터 셋으로 이용될 수 있다. 학습이 끝난 뉴럴 네트워크는 태그를 입력 받고, 입력된 태그에 어울리는 음악 콘텐츠, 즉, 음원을 획득할 수 있다. 실시 예에 따른 음악 재생부는 음원 생성부가 생성한 음원에 따라 음악을 재생할 수 있다. 음악 재생부는 음원 생성부로부터 악보를 수신하고 악보에 따라 음원을 재생하거나, 또는 음원 생성 부로부터 음원 자체를 수신하여 음원을 뮤직 플레이어를 이용하여 재생할 수 있다. 사용자는 음악 재생부가 재생하는 음악을 청취할 수 있다. 사용자는 재생되는 음악이 마음에 들어 해당 음 악을 여러 번 청취할 수도 있고, 또는 음악이 마음에 들지 않아 음악이 다 끝나기 전에 음악 재생을 정지할 수 도 있다. 실시 예에서, 사용자의 음악 청취에 대한 정보, 즉, 음악 재생에 대한 정보는 음원 생성 태그 획득부로 피 드백 되어 전송될 수 있다. 음원 생성 태그 획득부는 음악 재생 정보를 획득하고 음악 재생 정보를 이용하 여 태그 별 웨이트를 업데이트할 수 있다. 음원 생성 태그 획득부는 사용자의 음악 재생 이력에 기초하여 사용자가 반복하여 청취한 음원에 연관된 태그에 대한 웨이트를 높이고, 사용자가 중지한 음원에 연관된 태그에 대한 웨이트를 낮춤으로써 태그 별 웨이트를 업데이트할 수 있다. 음원 생성 태그 획득부는 이후 업데이트 된 태그 별 웨이트를 이용하여 태그 별 점수를 획득하고, 이에 기반하여 태그를 필터링함으로써 사용자의 음악 재생 이력이 잘 반영된 음악이 생성되도록 할 수 있다. 도 4는 실시 예에 따른 도 3의 음원 생성 정보 획득부의 내부 블록도이다. 도 4를 참조하면, 음원 생성 정보 획득부는 이미지 정보 획득부, 주변 상황 정보 획득부 및 사 용자 취향 정보 획득부를 포함할 수 있다. 실시 예에 따른 이미지 정보 획득부는 전자 장치(100a)에 출력된 이미지로부터 이미지 정보를 획득할 수 있다. 이미지 정보 획득부는 화면에 출력되는 이미지를 캡쳐하고, 캡쳐된 이미지를 분석하여 이미지 정보 를 획득할 수 있다. 이미지 정보는 화면에 출력되는 이미지 자체의 고유 특성에 대한 정보일 수 있다. 이미지 정보는 이미지에서 식 별된 컬러나 스타일, 이미지에서 식별된 오브젝트의 종류, 및 식별된 오브젝트가 사람인 경우 사람의 표정 중 적어도 하나에 기반하여 획득될 수 있다. 또는, 이미지 정보 획득부는 화면에 출력되는 이미지에 대한 부 가 정보를 이미지와 함께, 또는 이미지와 별도로 전자 장치(100a) 내부의 메모리나, 외부 서버, 또는 외부 사용 자 단말 등으로부터 수신하여 이를 이미지 정보로 이용할 수도 있다. 실시 예에 따른 주변 상황 정보 획득부는 통신 신호, 센서 신호, 카메라 신호 중 적어도 하나를 수신할 수 있다. 주변 상황 정보 획득부는 정해진 시간 마다 또는 랜덤한 시간 간격마다, 또는 기 설정된 시각 마다, 또는 온도가 급변하거나 날짜가 바뀌는 것과 같은 이벤트가 발생할 때 마다 통신 신호, 센서 신호 및 카메라 신 호 중 적어도 하나를 새로 획득할 수 있다. 통신 신호는 통신망을 통해 외부 서버 등으로부터 획득된 신호로, 외부 상황을 나타내는 정보, 예컨대, 외부의 날씨 정보, 날짜 정보, 시간 정보, 계절 정보, 조도 정보, 온도 정보, 위치 정보, 공휴일 정보 중 적어도 하나를 포함할 수 있다. 실시 예에 따른 주변 상황 정보 획득부는 다양한 센서를 이용하여 전자 장치(100a) 주변의 외부 상황에 대 한 센서 신호를 획득할 수 있다. 센서 신호는 센서를 통해 센싱된 신호로, 센서의 종류에 따라 다양한 형태의 신호를 포함할 수 있다. 예컨대, 주변 상황 정보 획득부는 온/습도 센서를 이용하여 주변의 온도나 습도를 감지할 수 있다. 또는 주변 상황 정보 획득부는 조도 센서를 이용하여 전자 장치(100a) 주변의 조도를 감지할 수 있다. 조도 센 서는 주변의 빛의 양을 측정하여 빛의 양에 따라 밝기를 측정할 수 있다. 또는 주변 상황 정보 획득부는 위치 센서를 이용하여 전자 장치(100a)의 위치를 감지할 수 있다. 또는 주변 상황 정보 획득부는 위치 센서 및/또는 근접 센서를 이용하여 전자 장치(100a)와 사용자 사이의 거리를 감지할 수 있다. 또는 주변 상황 정보 획득부는 프레즌스(presence) 센서를 이용하여, 프레즌스 센서에서 방출된 IR 신호가 반사되어 오는지 여부나 반사되어 돌아오는 시간 간격 등에 따라 주변에 사람이 있는지 여부 등을 센싱할 수 있 다. 또는 주변 상황 정보 획득부는 프레즌스 센서 대신 카메라를 이용하여 전자 장치(100a) 주변에 사용자 가 있는지 여부를 식별할 수도 있다. 카메라 렌즈에 사용자가 포착되는지 여부에 따라, 주변 상황 정보 획득부 는 사용자 유무를 판단하고 사용자 유무를 주변 상황 정보로 획득할 수 있다. 실시 예에 따른 사용자 취향 정보 획득부는 사용자 취향 정보를 획득할 수 있다. 사용자 취향 정보는 사용 자가 선호하는 음악을 추론하기 위해 획득될 수 있다. 실시 예에서, 사용자 취향 정보는 사용자 프로필 정보나 사용자의 시청 이력 정보, 선호 음악 정보 중 적어도 하나로부터 추론될 수 있다. 사용자 프로필 정보는 사용자를 식별하기 위한 정보로, 사용자의 계정(account)을 기반으로 생성될 수 있다. 사 용자 프로필 정보는 사용자의 성별, 나이, 결혼 유무, 자녀 유무, 가족 수, 직업, 생일 등의 기념일 정보를 포 함할 수 있다. 예컨대, 사용자가 전자 장치(100a)에 계정을 생성한 경우, 전자 장치(100a)는 사용자가 계정을 생성할 때 입력한 프로필 정보를 사용자 계정에 매칭시키고 이를 전자 장치(100a) 내부에 저장하거나 또는 전자 장치(100a)에 서비스를 제공하는 연동된 외부 서버에 저장시킬 수 있다. 또는, 전자 장치(100a)에 카메라가 구 비된 경우, 전자 장치(100a)는 카메라를 통해 포착된 사용자의 얼굴을 인식하여 사용자의 연령대나 사용자의 성 별 등을 식별하고 이로부터 사용자 취향 정보를 추론할 수도 있다. 실시 예에서, 사용자 취향 정보 획득부는 사용자가 전자 장치(100a)를 이용하여 프로그램이나 콘텐츠를 시 청한 이력 정보를 획득하고 이로부터 사용자 정보를 추론할 수도 있다. 예컨대, 사용자가 주로 시청하는 콘텐츠가 애완동물과 관련된 콘텐츠이고, 또한 로맨틱 코메디 장르의 콘텐츠인 경우, 사용자 취향 정보 획득부는 사용자가 밝고 따뜻한 음악을 선호할 것이라고 추론할 수 있다. 또는 실시 예에서, 사용자 취향 정보는 사용자로부터 선택 받은 선호 음악 정보로부터 획득될 수도 있다. 예컨 대, 사용자는 전자 장치(100a)에 계정을 생성할 때 선호하는 음악에 대한 정보를 입력하거나, 또는 전자 장치 (100a)를 이용하여 음악을 자동으로 생성하는 프로그램이 실행되도록 하기 위해서 프로그램 이용 시 최초에 한 해 전자 장치(100a)에 선호 음악에 대한 정보를 직접 입력할 수도 있다. 또는 사용자 취향 정보는 사용자의 이전 음악 청취 이력이 있는 경우, 이전 음악 청취 이력에 기반하여 획득되 거나 업데이트될 수 있다. 예컨대, 사용자 취향 정보는 사용자가 선호하거나 이전에 청취한 음악의 무드(mood), 감도(velocity), 악기, 조성, 코드, 멜로디, 비트, 박자, 템포, 리듬, 장르, 분위기 등에 대한 정보로부터 획득 될 수 있다. 또한, 사용자 취향 정보 획득부는 사용자가 특정 음악을 재생한 정도, 사용자가 해당 음악을 전부 다 청취했는지, 일부만 청취했는지 등을 나타내는 음악 재생 시간 등으로부터 사용자가 특정 음악을 선호 하는 정도를 획득하고 이로부터 사용자 취향 정보를 추론할 수도 있다. 사용자 취향 정보는 사용자의 이전 음악 청취 이력에 따라 주기적으로 또는 음악 청취 이벤트가 발생할 때마다 업데이트될 수 있다. 따라서, 이전 음악 청취 이력이 많을수록 보다 정확한 사용자 취향 정보가 획득될 수 있다. 이와 같이, 실시 예에 의하면, 전자 장치(100a)는 이미지 정보, 주변 상황 정보, 사용자 취향 정보와 같이 다양 한 형태의 음원 생성 정보를 이용하여 음원을 생성할 수 있다. 따라서, 동일한 이미지가 화면에 출력되더라도, 전자 장치(100a)는 주변 상황 정보나 사용자 취향 정보에 따라 다른 음원을 생성하여 사용자에게 제공할 수 있다. 도 5는 실시 예에 따른 도 4의 이미지 정보 획득부가 이미지 정보를 획득하는 방법을 설명하기 위한 도면이다. 실시 예에서, 이미지 정보 획득부는 이미지를 입력 받고, 이미지로부터 이미지 정보를 획득할 수 있다. 이 미지 정보는 이미지 자체의 고유 특징을 나타내는 정보일 수 있다. 이미지 정보는 이미지에 대한 부가 정보, 이 미지에서 식별된 컬러나 스타일, 이미지에서 식별된 오브젝트의 종류, 및 식별된 오브젝트가 사람인 경우 사람 의 표정 중 적어도 하나로부터 이미지 정보를 획득할 수 있다. 실시 예에서, 이미지 정보 획득부는 적어도 하나의 뉴럴 네트워크를 이용하여 이미지로부터 이미지 정보를 획득할 수 있다. 적어도 하나의 뉴럴 네트워크는 CNN(Convolution Neural Network), DCNN(Deep Convolution Neural Network) 또는 캡스넷(Capsnet) 기반의 신경망일 수 있으나, 이에 한정되는 것은 아니다. 실시 예에서, 이미지 정보 획득부는 이미지로부터 컬러 정보를 획득할 수 있다. 컬러 정보는 이미지에서 많이 사용된 색의 RGB 값일 수 있다. 이미지 정보 획득부는 각 픽셀의 RGB 값을 컬러 차이 알고리즘을 통 해 유사한 색으로 그루핑할 수 있다. 이미지 정보 획득부는 그루핑된 색상들로부터 우세한 컬러를 클러스 터링(clustering) 하여 하나의 이미지 별로 하나 또는 복수개의 우세한(dominant) 컬러에 해당하는 RGB 값을 획 득할 수 있다. 실시 예에서, 이미지 정보 획득부는 이미지에서 우세한 색상이 파란색, 하늘색, 흰색이라는 것을 식별하고 이러한 색상에 어울리는 감정 정보, 예컨대, 청량감, 시원함 등의 정보를 추가로 획득할 수 있다. 실시 예에서, 이미지 정보 획득부는 이미지로부터 스타일 정보를 획득할 수 있다. 스타일 정보는 이미지의 스타일이 느와르(noir)인지, 빈티지(vintage)인지, 로맨틱인지, 공포인지 등을 나타내는 정보일 수 있다. 이미 지가 그림인 경우, 스타일 정보는 회화 양식을 나타내는 화풍을 포함할 수 있다. 스타일 정보는 수채화, 유화, 수묵화, 점묘화, 입체화와 같이 그림을 그리는 방식이나 양식을 나타내거나 반 고흐 풍, 모네 풍, 마네 풍, 피 카소 풍 등과 같은 특정한 화가의 경향과 특징을 지칭할 수도 있다. 또는 스타일 정보는 중세 시대, 르네상스 시대, 근대시대, 현대 시대 회화와 같이 시대별로 분류되는 특징이거나, 동양화, 서양화, 등과 같은 지역별로 분류되는 특징이거나, 인상파, 추상파, 사실주의 등과 같은 회화 양식의 특징을 포함할 수 있다. 또는, 스타일 정보는 이미지가 갖는 질감, 색감, 분위기, 콘트라스트, 광택 또는 색의 3요소인 명도(Intensity), 색도(Hue), 채도(Saturation) 등에 대한 정보를 포함할 수 있다. 또는 이미지가 사진인 경우, 스타일 정보는 카메라 촬영 기법에 대한 정보를 포함할 수 있다. 예컨대, 스타일 정보는 사진 촬영 시 이용된 기법이 패닝 기법(Panning Shot)인지, 틸팅 기법(Tilting shot)인지, 주밍 기법 (Zooming Shot)인지, 접사 촬영(Marco Shot)인지, 야경 촬영인지 등에 대한 정보를 포함할 수 있다. 또는 스타 일 정보는 피사체의 구도, 화각, 노출 정도, 렌즈 종류, 블러링(blurring) 정도, 포커스 길이 등을 포함할 수 있으나 이에 한정되는 것은 아니다. 실시 예에서, 이미지 정보 획득부는 이미지에서 오브젝트 디텍션(object detection)을 수행할 수 있다. 이 미지 정보 획득부는 이미지 처리 기술을 이용하거나, 또는 인공 지능 기술을 이용하여 이미지로부터 오브 젝트를 검출할 수 있다. 예컨대, 이미지 정보 획득부는 두 개 이상의 히든 레이어들을 포함하는 딥 뉴럴 네트워크(DNN)를 이용하여 이미지로부터 오브젝트가 있음을 인식하고, 오브젝트가 무엇인지를 분류 (classification)하고, 오브젝트의 위치(localization)를 식별함으로써, 오브젝트 디텍션을 수행할 수 있다. 예 컨대, 도 5에서, 이미지 정보 획득부는 이미지로부터 사람, 구름, 하늘, 바다 등의 오브젝트를 검출할 수 있다. 또한, 이미지 정보 획득부는 오브젝트가 사람이고, 각각이 어른과 아이임을 식별할 수 있다. 이미지 정보 획득부는 검출된 오브젝트 종류가 어린이와 어른으로 구성된 가족, 구름, 하늘, 바다 등인 것으로부 터 행복, 즐거움 등의 감정 정보를 더 획득할 수 있다. 실시 예에서, 이미지 정보 획득부는 오브젝트가 사람인 경우 사람의 표정을 식별할 수 있다. 예컨대, 이미 지 정보 획득부는 적어도 하나의 뉴럴 네트워크를 이용하여 이미지로부터 얼굴을 검출할 수 있다. 이미지 정보 획득부는 검출된 얼굴에서 특징을 추출하고, 이를 이용하여 표정을 인식할 수 있다. 이미지 정보 획 득부는 인식된 표정으로부터 감정을 추론할 수 있다. 도 5에서, 이미지 정보 획득부는 이미지에 포함 된 사람의 표정을 식별하고, 표정이 웃는다는 것으로부터 기쁨이나 행복 등의 감정을 추론할 수 있다. 실시 예에서, 이미지 정보 획득부는 이미지에 대한 부가 정보를 이미지 정보로 획득할 수도 있다. 이미지 에 대한 부가 정보는 이미지의 크기, 이미지의 제작 년도, 이미지에 대한 설명 등을 포함할 수 있다. 이미지에 대한 설명은 이미지의 생성 이력이나 이미지의 주제나 분위기에 대한 설명, 이미지의 종류나 스타일, 색감, 질감 등에 대한 설명, 이미지를 생성한 포토그래퍼나 화가 등의 작가에 대한 설명, 이미지가 생성된 장소, 이미지 의 수상 이력 등과 같은 다양한 정보를 포함할 수 있다. 이미지 정보 획득부는 이미지에 대한 부가 정보를 이미지와 함께 획득할 수 있다. 예컨대, 이미지 정보 획 득부는 이미지에 대한 부가 정보를 서버(미도시)나 전자 장치(100a) 주변의 사용자 단말기로부터 수신하여 획득할 수 있다. 전자 장치(100a)는 이미지에 대한 부가 정보를 이미지와 함께 서버나 사용자 단말기로부터 수 신하여 획득할 수 있다. 또는 전자 장치(100a)는 이미지에 대한 정보를 이미지를 수신한 서버나 사용자 단말기 와는 별도의 서버 등으로부터 검색하여 획득할 수도 있다. 예컨대, 이미지가 유명 작품인 경우, 전자 장치 (100a)는 이미지에 대한 타이틀만을 이미지와 함께 수신하고, 타이틀을 이용하여, 별도의 서버로부터 해당 이미 지에 대한 상세 부가 정보를 획득할 수 있다. 이와 같이, 실시 예에 의하면, 이미지 정보 획득부는 이미지로부터 다양한 형태의 이미지 정보를 획득할 수 있다. 또한, 이미지 정보 획득부는 이미지 정보에 대응하는 감정 정보를 획득할 수 있다. 도 6은 실시 예에 따른 도 3의 음원 생성 태그 획득부의 내부 블록도이다. 도 6을 참조하면, 음원 생성 태그 획득부는 태그 매핑부, 데이터 베이스, 태그 필터링부 및 웨이트 획득부를 포함할 수 있다. 실시 예에서, 음원 생성 태그 획득부는 데이터 베이스(data base, DB, 322)를 포함할 수 있다. 데이터 베 이스에는 음원과 관련된 복수의 정보들 및 각각의 정보들에 매핑된 태그들이 데이터 형태로 저장되어 있을 수 있다. 태그는 정보를 분류하거나, 경계를 표시하거나, 정보의 속성이나 정체성 등을 표시하는 식별자일 수 있다. 태그 는 단어, 이미지 또는 기타 식별 표시의 형태를 취할 수 있다. 데이터 베이스에는 음원과 관련된 복수의 정보들 각각에 대해 하나 이상의 태그가 할당되어 저장되어 있을 수 있다. 태그는 많은 양의 정보를 효과적으로 관리하거나 검색하는 데 사용되는 정보로, 각 정보에 부여되어 정보를 분류하는 데 사용될 수 있다. 실시 예에서, 태그 매핑부는 이러한 태그의 특성을 이용하여, 정보에 대응하는 태그를 검색하여 이용할 수 있다. 실시 예에서, 태그 매핑부는 음원 생성 정보 획득부로부터 음원 생성 정보를 수신하고, 음원 생성 정보에 매핑되는 음원 생성 태그들을 데이터 베이스에서 검색하여 획득할 수 있다. 즉, 태그 매핑부 는 데이터 베이스에 저장된 정보에서 음원 생성 정보 획득부로부터 수신한 음원 생성 정보를 찾 고, 음원 생성 정보에 매핑된 태그들인 음원 생성 태그들을 검색할 수 있다. 태그 매핑부는 검색된 음원 생성 태그들을 태그 필터링부로 전달할 수 있다. 다만, 이는 하나의 실시 예로, 음원과 관련된 정보 및 정보에 매핑되는 태그들은 전자 장치(100a) 내부의 데이 터 베이스에 저장되어 있는 것이 아니라 전자 장치(100a) 외부의 서버 등에 저장되어 있을 수도 있다. 이 경우, 태그 매핑부는 통신부(미도시)를 통해 외부 서버에 음원 생성 정보를 전송하고, 외부 서버로부터 음 원 생성 정보에 매핑되는 음원 생성 태그들을 수신하여 획득할 수 있다. 실시 예에서, 웨이트 획득부는 태그 별 웨이트를 획득할 수 있다. 실시 예에서, 태그 별 웨이트는 각각의 태그에 대한 사용자의 선호도를 나타내는 정보일 수 있다. 실시 예에서, 웨이트 획득부는 사용자 취향 정보를 기반으로 태그 별 웨이트를 생성할 수 있다. 웨이트 획 득부는 음원 생성 정보 획득부로부터 사용자 취향 정보에 대한 음원 생성 정보를 수신하고, 이를 이 용하여 각 태그 별로 사용자 선호도를 수치화하여 태그 별 웨이트를 생성할 수 있다. 이후, 태그 필터링부는 사용자의 음악 청취 이력 정보, 즉, 음악 재생 정보에 따라 태그 별 웨이트를 추가 적으로 업데이트할 수 있다. 예컨대, 웨이트 획득부는 음악의 재생 빈도, 음악 전체 청취 정도, 재생 중단 정도, 빨리 감기 정도, 스킵 정도에 대한 정보 등을 음악 재생 정보로 이용하고, 이에 기반하여 태그 별 웨이트 를 업데이트할 수 있다. 예컨대, 웨이트 획득부는 음악이 끝까지 재생되고 사용자가 반복하여 청취한 음악 에 대해서는 그 음악을 생성하는 데 이용된 태그들에 더 높은 웨이트를 부여하고, 반대로, 사용자가 재생을 중 단하거나 스킵한 음악에 대해서는 그 음악을 생성하는 데 이용된 태그들에 더 낮은 웨이트를 부여함으로써, 태 그 별 웨이트를 업데이트할 수 있다. 실시 예예서, 웨이트 획득부는 상황 기반 태그 별 웨이트를 생성할 수 있다. 상황 기반 태그 별 웨이트는 주변 상황을 고려한 태그 별 웨이트를 의미할 수 있다. 웨이트 획득부는 태그 별 웨이트에 주변 상황에 따 른 가중치를 한 번 더 부여하여 상황 기반 태그 별 웨이트를 생성할 수 있다. 즉, 웨이트 획득부는 사용자가 특정 주변 상황에서 선호하는 음악이나 특정 주변 상황에서 재생한 이력이 있는 음원에 대해, 그 음원을 생 성하는 데 이용된 태그들에 주변 상황에 따른 가중치를 부여하여 상황 기반 태그 별 웨이트를 생성할 수 있다. 예컨대, 봄비가 오는 아침에, 사용자가 주로 들었던 음악이 보통 템포이고, 감도는 보통이고, 악기는 피아노이 고, 피치(pitch)는 중간 톤인 경우, 웨이트 획득부는 봄비가 오는 아침이라는 특정 상황에 대응하여 위 특 징을 갖는 음악을 생성하는 데 이용된 태그들에 대해 더 높은 웨이트를 부여함으로써 상황 기반 태그 별 웨이트 를 생성할 수 있다. 실시 예에서, 웨이트 획득부는 태그 별 웨이트 및/또는 상황 기반 태그 별 웨이트를 테이블 형태로 생성하 고 이를 저장하고 있을 수 있다. 웨이트 획득부는 사용자가 음악을 재생하는 정도 등을 고려하여, 태그 별 웨이트 및/또는 상황 기반 태그 별 웨이트를 계속하여 업데이트할 수 있다. 실시 예에서, 태그 필터링부는 태그 매핑부로부터 수신한 음원 생성 태그들을 필터링하여 음원 생성 에 직접 이용될 태그들만을 획득할 수 있다. 실시 예에서, 태그 필터링부는 태그들을 필터링하기 위해, 음원 생성 태그들에 점수를 부여할 수 있다. 태 그 필터링부는 음원 생성 태그들에 점수를 부여하기 위해 웨이트 획득부로부터 태그 별 웨이트를 수 신하고 이를 고려하여 태그 별 점수를 생성할 수 있다. 실시 예에서, 태그 필터링부는 음원 생성 태그들 간에 중복되는 태그들이 있는 경우, 중복도를 고려하여 태그 별 점수를 생성할 수 있다. 중복도는 음원 생성 정보에 매핑되는 태그들 중 중복되는 태그들이 있는 경우 그 중복되는 정도를 나타내는 정보일 수 있다. 예컨대, 태그 필터링부는 태그 매핑부로부터 수신한 태그들 간에 동일 태그들이 있는 경우, 동일 태그들의 개수를 고려하여 태그 별로 중복도를 결정할 수 있다. 실시 예에서, 태그 필터링부는 태그 별 웨이트나, 중복도 외에도 다양한 정보를 이용하여 태그 별 점수를 생성할 수 있다. 실시 예에서, 태그 필터링부가 태그 별 점수를 부여하기 위해 이용하는 정보는 음원 생성 정보에 따라 달라질 수 있다. 실시 예에서, 음원 생성 정보가 이미지 정보인 경우, 태그 필터링부는 태그 별 웨이트 및 중복도 외에도, 이미지를 인식한 결과의 정확도를 더 고려할 수 있다. 이미지를 인식한 결과의 정확도는, 이미지에 대한 오브젝 트 디텍션의 수행 결과에 대한 신뢰도를 의미할 수 있다. 즉, 이미지를 인식한 결과의 정확도는 이미지에서 오 브젝트가 얼마나 정확히 검출되었는지를 나타내는 정보일 수 있다. 또는, 이미지를 인식한 결과의 정확도는 이 미지에서 오브젝트가 차지하는 비중에 따라 결정될 수도 있다. 예컨대, 이미지에서 오브젝트가 한 명의 사람의 얼굴과 자동차 한 대이고, 사람의 얼굴이 이미지 전체의 70퍼센트를 차지하고, 자동차가 이미지 전체의 10퍼센 트를 차지하는 경우, 이미지를 인식한 결과의 정확도는 얼굴과 자동차 각각에 대해 70퍼센트, 10퍼센트의 비중 으로 부여될 수 있다. 실시 예에서, 태그 필터링부는 이미지 정보에 매핑되는 음원 생성 태그들 각각에 대한 태그 별 웨이트, 중 복도, 이미지를 인식한 결과의 정확도 중 적어도 하나를 고려하여 점수가 높은 태그들을 필터링할 수 있다. 실시 예에서, 음원 생성 정보가 주변 상황 정보인 경우, 태그 필터링부는 상황 기반 태그 별 웨이트를 이 용하여 주변 상황 정보에 매핑되는 음원 생성 태그들 별로 점수를 부여할 수 있다. 실시 예에서, 태그 필터링부 는 주변 상황 정보를 기반으로 획득된 음원 생성 태그들에 점수를 부여하기 위해, 웨이트 획득부로부 터 상황 기반 태그 별 웨이트를 획득하고 이를 이용하여 상황에 맞는 태그 별 점수를 생성할 수 있다. 태그 필 터링부는 상황 기반 태그 별 웨이트에 기반하여 주변 상황 정보에 매핑되는 음원 생성 태그들 별 점수를 획득하고, 점수가 높은 태그들을 필터링할 수 있다. 실시 예에서, 태그 필터링부는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링할 수 있 다. 실시 예에서, 태그 필터링부는 복수의 음원 생성 태그들의 개수가 기준치 이상인 경우, 태그들의 개수 가 기준치 이하가 되도록 음원 생성 태그들을 필터링할 수 있다. 여기서, 기준치는 태그 매핑부로부터 수 신한 음원 생성 태그들의 개수에 비례하여 결정될 수도 있고, 또는 기 설정된 임의의 개수일 수도 있다. 예컨대, 음원 생성 정보에 매핑되는 음원 생성 태그들이 200개인 경우, 태그 필터링부는 점수가 높은 순서 대로, 정해진 퍼센테이지인, 20%에 해당하는 40개의 태그들만을 필터링할 수 있다. 또는 태그 필터링부는 100개의 음원 생성 태그들 중 점수가 높은 순서대로, 미리 정해진 개수인 30개의 태그들만을 필터링할 수도 있 다. 또는, 태그 필터링부는 복수의 음원 생성 태그들 중 점수가 소정 점수 이상인 태그들만을 필터링할 수 있다. 또는, 태그 필터링부는 점수가 높은 순서대로 소정 점수 이상이면서 소정 개수 이내의 태그들만을필터링할 수도 있다. 실시 예에서, 태그 필터링부는 필터링된 태그들을 음원 생성부로 전달할 수 있다. 태그 필터링부 는 이미지 정보에 매핑되는 음원 생성 태그들 중에서 필터링하여 획득한 태그들과, 주변 상황 정보에 매핑 되는 음원 생성 태그들 중에서 필터링하여 획득한 태그들을 함께 음원 생성부로 전달할 수 있다. 실시 예에서, 태그 필터링부는 필터링된 음원 생성 태그들을 추가로 더 필터링할 수도 있다. 예컨대, 태그 필터링부는 필터링된 음원 생성 태그들의 개수가 여전히 많은 경우, 필터링된 음원 생성 태그들을 추가로 더 필터링할 수 있다. 예컨대, 태그 필터링부는 이미지 정보에 매핑되는 음원 생성 태그들 중에서 필터링하여 획득한 태그들과, 주변 상황 정보에 매핑되는 음원 생성 태그들 중에서 필터링하여 획득한 태그들을 합치고 이들을 추가로 필터링 한 후 필터링된 태그들만을 음원 생성부로 전달할 수 있다. 또는, 태그 필터링부는 주변 상황 정보에 따라 서로 다른 음악 스타일의 음원이 생성되도록 하기 위해 음 원 생성 태그들을 한번 더 필터링할 수도 있다. 태그 필터링부는 센서나 서버 등을 통해 획득한 주변 상황 정보에 따라, 예컨대, 현재 주변 상황이 겨울이고 시간대가 밤인 경우일 때와 여름 한낮이고 햇볕이 강렬한 경 우일 때, 서로 다른 점수를 음원 생성 태그들에 부여함으로써 주변 상황에 따라 다른 음원 생성 태그들이 필터 링되도록 할 수 있다. 이 경우, 태그 필터링부는 주변 환경에 따라 한번 더 필터링된 음원 생성 태그들을 음원 생성부로 전송하게 되므로, 음원 생성부는 서로 다른 주변 환경에 보다 적절한 분위기나 장르, 템포, 이퀄라이저 등을 갖는 서로 다른 음악 스타일의 음원을 생성 할 수 있다. 또는, 다른 예로, 태그 필터링부는 사용자 식별 정보에 따라 음원 생성 태그들을 한번 더 필터링할 수도 있다. 전자 장치(100a)가 카메라를 포함하는 경우, 태그 필터링부는 카메라로 인식된 사용자 식별 정보를 이용하여 사용자에 따라 다른 음원 생성 태그들이 필터링되도록 할 수 있다. 예컨대, 태그 필터링부는 카 메라 등을 이용하여 획득된 사용자 식별 정보에 따라 사용자가 10대 남성임을 식별한 경우와, 사용자가 50대 여 성임을 식별한 경우에, 서로 다른 음원이 생성되도록 하기 위해 음원 생성 태그들에 서로 다른 점수를 부여할 수 있다. 또는, 사용자가 본인 계정으로 로그인을 한 경우, 태그 필터링부는 사용자 계정에 대응하는 사용자 프로필 정보를 획득하고, 이를 이용하여 사용자 프로필에 보다 적합한 음원 생성 태그들을 필터링할 수 있다. 태그 필터링부는 세대나 성별에 따라 서로 다른 음원 생성 태그들을 필터링하고 이를 음원 생성부에 전달하게 되고, 이에 따라, 음원 생성부는 세대나 성별에 따라 분위기나 빠르기 등이 다른 스타일의 음원 을 생성할 수 있다. 도 7은 실시 예에 따라, 도 6의 태그 필터링부가 태그 별 점수를 고려하여 태그를 필터링하는 것을 설명하기 위 한 도면이다. 실시 예에서, 태그 필터링부는 음원 생성 태그들에 점수를 부여하고, 점수에 따라 음원 생성 태그들을 필 터링할 수 있다. 태그 필터링부는 음원 생성 태그들을 나열하고, 각각의 태그에 대한 태그 별 웨이트를 웨 이트 획득부로부터 수신하고, 각 태그 별로 웨이트를 부여할 수 있다. 또한 태그 필터링부는 음원 생 성 태그들 중 중복되는 태그들이 있는 경우, 각 태그 별로 중복도를 부여할 수 있다. 실시 예에서, 태그 필터링부는 태그들을 필터링함에 있어서 음원 생성 태그들의 종류에 따라 추가로 다른 정보를 이용할 수도 있다. 예컨대, 태그 필터링부는 음원 생성 태그들이 이미지 정보에 대응하는 태그들인 경우, 태그 별 웨이트 및 중복도 외에 오브젝트 디텍션의 정확도를 더 고려할 수 있다. 도 7을 참조하면, 제1 테이블은 태그 필터링부가 이미지 정보에 매핑되는 음원 생성 태그들에 대해 점수를 부여하는 것을 나타낸다. 제1 테이블은 음원 생성 태그들, 즉, Tag 1부터 Tag 5 각각에 대해, 태그 별 웨이트, 정확도(Accuracy), 중복도(Number)를 나타낸다. 여기서, Tag 1부터 Tag 5는 이미지 정보에 매핑되는 음원 생성 태그들을 나타낸다. 태그 필터링부는 이미지 정보에 매핑되는 음원 생성 태그들 각각에 대해, 태그 별 웨이트, 정확도, 중복도를 함께 고려하여 각 태그 별로 점수를 계산할 수 있다. 실시 예에서, 태그 필터링부는 태그 별 점수를 계산하는 데 있어서, 태그 별 웨이트와 정확도, 중복도를 같은 비중으로 고려하거나, 또는 각각의 항목 별로 서로 다른 가중치를 부여하여 최종 점수를 계산할 수 있다. 도 7에서, 제2 테이블은 태그 필터링부가 주변 상황 정보에 매핑되는 음원 생성 태그들에 대해 점수 를 부여하는 것을 나타낸다. 제2 테이블에서 Tag 1부터 Tag 4는 주변 상황 정보에 매핑되는 음원 생성 태 그들을 나타낸다. 태그 필터링부는 주변 상황 정보에 매핑되는 음원 생성 태그들에 대해, 웨이트 획득부 로부터 수신한 상황 기반 태그 별 웨이트를 고려하여 상황에 맞는 태그 별 점수를 생성할 수 있다. 예컨대, 현재 주변 상황이, 봄비가 오는 아침인 경우, 태그 필터링부는 봄비가 오는 아침이라는 특정 상황 에 대응하여 생성된 상황 기반 태그 별 웨이트를 웨이트 획득부로부터 검색하여 이용할 수 있다. 즉, 태그 필터링부는 웨이트 획득부로부터 Tag 1부터 Tag 4에 대응하는 상황 기반 태그 별 웨이트를 검색하고 이를 Tag 1부터 Tag 4에 대한 점수로 이용할 수 있다. 태그 필터링부는 각 태그 별 점수에 기반하여 음원 생성에 직접적으로 이용할 태그들을 필터링할 수 있다. 도 8은 실시 예에 따른 음원 생성 정보와 태그 간의 관계를 도시한 도면이다. 실시 예에서, 전자 장치는 음원과 태그 간의 유사도를 이용할 수 있다. 예컨대, 전자 장치는 MFCC(MelFrequency Cepstral Coefficient) 알고리즘을 이용하여 음원을 특징 벡터로 변환할 수 있다. 전자 장치는 주파수 도메인에 서 웨이브 파형을 시간별로 잘라서 각 조각마다 푸리에 변환을 취한 후 이들을 연결하고, 주파수 대역 별로 묶 어서 MFCC를 추출할 수 있다. 전자 장치는 MFCC를 기반으로 음원 간의 유사도를 측정할 수 있다. 도 8을 참조하면, 음원 생성에 이용될 수 있는 정보는 그래프 위에 점들로 표현될 수 있다. 도 8에서 각각 의 점은 음원과 관련된 정보를 나타낼 수 있다. 음원과 관련된 정보는, 음원에서 추출되는 특징들로, 예컨대, 장르, 조성, 코드, 멜로디, 비트, 박자, 템포 등의 정보를 포함할 수 있다. 그래프에서 점 사이의 거리는 정보 간 관련도 내지는 유사도를 나타낼 수 있다. 즉, 점간 거리가 가까울수록 관련도가 높은 관계를 나타낼 수 있다. 도 8의 그래프는 음원에서 추출되는 특징 중 장르에 대한 그래프일 수 있다. 그래프에서, 각 점은 형 태에 따라 서로 다른 장르를 갖는 정보를 의미할 수 있다. 예컨대 삼각형과 네모, 별 모양 각각은 서로 다른 장 르를 갖는 음원 관련 정보를 표현할 수 있다. 그래프의 X 축과 Y축 값들은 장르를 종류에 따라 구분하여 나타낼 수 있다. 예컨대, 그래프의 X축을 따라 오른쪽으로 갈수록 음원의 장르는 soul, blues, jazz 등으 로 바뀔 수 있다. 또한, 그래프에서 Y축을 따라 위쪽으로 갈수록 음원의 장르는 rock, hip hop, R&B 등을 나타 낼 수 있다. 도 8은 음원의 장르에 대해 도시하였으나, 음원과 관련된 다른 정보, 예컨대, 조성, 코드, 멜로디, 비트, 박자, 템포 등에 대해서도 각각의 그래프가 생성될 수 있다. 음원과 관련된 정보에는 태그들이 매핑될 수 있다. 이는, 거꾸로, 태그를 이용하여 태그에 매핑되는 음원과 관 련된 정보를 검색할 수 있다는 것을 의미할 수 있다. 예컨대, 필터링된 태그가 Ta1 1과 Tag 4의 조합인 경우, 음원 생성부는 Ta1 1과 Tag 4의 조합에 대응하는 음원을 검색할 수 있다. Ta1 1과 Tag 4의 조합에 대 응하는 음원이 classical한 장르를 갖는 음원인 경우, 음원 생성부는 classical한 장르를 갖는 음원 을 생성할 수 있다. 또한, 음원 생성부는 Ta1 1과 Tag 4의 조합에 대응하는 조성, 코드, 멜로디, 비트, 박 자, 템포 등을 갖는 음원을 검색하고, 이들을 조합하여 음원을 생성할 수 있다. 도 9는 실시 예에 따라, 태그로부터 음원을 획득하도록 학습된 신경망을 설명하기 위한 도면이다. 도 9를 참조하면, 인공지능을 이용하여 태그로부터 음원을 생성하는 과정은 두 가지 과정으로 이루어질 수 있다. 먼저 훈련 과정에서는 복수의 훈련 데이터를 입력으로 하여 신경망, 즉, 뉴럴 네트워크 모델을 훈련시킬 수 있다. 각 훈련 결과인 출력 데이터는 다시 뉴럴 네트워크 모델로 피드백되어 뉴럴 네트 워크 모델의 가중치를 업데이트하는데 이용될 수 있다. 뉴럴 네트워크 모델은 복수의 훈련 데이터가 입력된 것에 응답하여, 복수의 훈련 데이터로부터 다른 속성 을 갖는 데이터를 검출하는 방법을 학습 및 또는 훈련할 수 있으며, 학습 및/또는 훈련된 결과에 기초하여 생성 될 수 있다. 보다 구체적으로, 훈련 데이터는 복수의 태그들 및 태그들과 관련도가 높은 음원을 포함할 수 있다. 복수 의 태그들은 다양한 음원 생성 정보에 대응하는 태그들일 수 있다. 뉴럴 네트워크 모델은 태그 별로 관련도가 높은 음원들의 집합을 그루핑하여 학습될 수 있다. 즉, 뉴럴 네 트워크 모델은 태그들의 특징을 나타내는 조성이나, 코드, 리듬, 분위기, 장르 등의 특징 정보를획득하고, 획득한 특징 정보로부터 음원을 생성하도록 훈련될 수 있다. 실시 예에서, 뉴럴 네트워크 모델은 GAN(Generative Adversarial Network)일 수 있다. 뉴럴 네트워크 모델은 음원 자체를 이미지로 변환해서 이를 학습할 수 있다. 예컨대, 뉴럴 네트워크 모델 은 음원을 MFCC(MelFrequency Cepstral Coefficient) 알고리즘을 이용하여 음원을 주파수 변환하고, 음원 으로부터 특징 정보를 획득할 수 있다. MFCC 알고리즘은 음원을 20ms-40ms정도의 작은 프레임들로 나누고 나누 어진 프레임들의 스펙트럼을 분석하여 특징을 추출하는 기법일 수 있다. 뉴럴 네트워크 모델은 MFCC 알고 리즘을 이용하여 획득한 주파수 도메인 상의 특징들 간의 파형의 유사도를 이용하여 음원 간 유사도를 측정할 수 있다. 또한, 뉴럴 네트워크 모델은 음원에 매핑된 태그 간 유사도도 함께 측정할 수 있다. 뉴럴 네트워크 모델은 획득하고자 하는 도메인 정보와 원본 데이터, 즉, 필터링된 태그들을 입력 값으로 받을 수 있다. GAN은 모든 가능한 도메인들 사이의 매핑을 하나의 generator를 통해 학습할 수 있다. 예컨대, GAN은 태그들과 음원의 장르에 대한 도메인 정보를 모두 훈련 데이터로 입력 받고, 태그에 따라 적절한 장 르의 음원을 학습할 수 있다. 뉴럴 네트워크 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행할 수 있다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화 되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN: Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 뉴럴 네트워크 모델은 매핑 네트워크(mapping network)를 포함할 수 있다. 매핑 네트워크는 비선형으로, 특징들 사이의 편중된 상관관계를 줄여 줄 수 있다. 매핑 네트워크는 복수 개의 레이어들을 포함할 수 있다. 각 레이어들은 적어도 하나의 노드로 표현될 수 있고, 계층 간 노드들은 엣지로 연결된다. 노드들은 이전 및 이후 의 레이어들에 포함된 노드들과 완전 연결(Fully Connected)되어 있을 수 있다. 뉴럴 네트워크 모델은 입력된 정보를 매핑 네트워크에 통과시켜 중간 벡터를 획득할 수 있다. 중간 벡터는 태그의 속성 정보를 담고 있는 웨이트일 수 있다. 예를 들어, 속성 정보로부터 추출된 특징 벡터가 음원의 장르 에 대응하는 특징에 관한 것이면, 뉴럴 네트워크 모델은 이러한 특징을 갖는 중간 벡터를 생성할 수 있다. 예를 들어, 속성 정보로부터 추출된 특징 벡터가 음원의 템포와 관련된 속성에 대응하는 특징에 관한 것이면, 뉴럴 네트워크 모델은 이러한 템포의 특징을 갖는 중간 벡터를 생성할 수 있다. 뉴럴 네트워크 모델은 생성한 중간 벡터를 이용하여, 복수의 레이어들 마다 음원에 대한 정보를 입히는 방 식으로 출력 데이터를 합성할 수 있다. 뉴럴 네트워크 모델은 텐서(tensor)를 입력 받을 수 있다. 텐서는 딥러닝 모델의 정보를 담고 있는 데이터 스트럭쳐일 수 있다. 텐서는 학습 데이터들의 속성이 반영되지 않은 베이스 정보로, 평균적인 음원에 대응하는 정보일 수 있다. 실시 예에서, 텐서는 기본적인 음원을 갖는 부가 정보 영역의 레이아웃을 의미할 수 있다. 뉴럴 네트워크 모델에는 4X4X512의 텐서로 시작해서 1024X1024X3으로 끝나는 복수 개의 레이어들을 포함할 수 있다. 각 레이어들은 컨벌루션, 업샘플링을 통해 다음 레이어로 연결될 수 있다. 웨이트는 뉴럴 네트워크 모델의 각각의 레이어들로 입력될 수 있다. 뉴럴 네트워크 모델은 중간 벡터, 즉, 웨이트를 이용하여 각각의 레이어들에 대한 속성이나 음원의 특징들을 표현하도록 학습될 수 있다. 계층의 깊이가 얕을수록 이미지의 하위 레벨 특징, 즉, coarse한 특징들이 추출되고, 계층의 깊이가 깊어질수록 디테일한 상위 레벨 특징이 추출될 수 있다. 뉴럴 네트워크 모델은 하위 레벨부터 상위 레벨에서 획득한 특징들에 기반하여 결과 데이터를 획득할 수 있다. 결과 데이터는 음원 또는 음원 생성에 이용되는 악보일 수 있다. 각 훈련 결과는 뉴럴 네트워크 모델로부터 출력 데이터로 도출될 수 있다. 출력 데이터는 뉴럴 네트워크 모델의 가중치들을 업데이트하는데 이용될 수 있다. 훈련 결과가 일정 신뢰도를 넘도록 뉴럴 네 트워크 모델이 훈련되면 이 모델은 훈련된 뉴럴 네트워크 모델로서 이용될 수 있다. 적용 과정에서는 적용 데이터를 훈련된 뉴럴 네트워크 모델에 입력하여, 입력된 적용 데이터 로부터 결과 데이터를 획득할 수 있다. 실시 예에서, 적용 데이터는 필터링된 음원 생성 태그들이고, 뉴럴 네트워크 모델로부터 출력되는 결 과 데이터는 음원 또는 음원 생성을 위한 악보일 수 있다. 뉴럴 네트워크 모델을 이용하여 필터링된 태그들로부터 음원을 획득하는 방법을 학습하는 동작은, 전자 장 치(100a)에서 수행될 수 있다. 또는 이러한 학습 동작은 전자 장치(100a)와는 별개의 외부의 컴퓨팅 장치에서 수행될 수 있다. 예를 들어, 뉴럴 네트워크 모델을 이용하여 태그로부터 음원을 획득하는 방법을 학습하는 동작은, 상대적으로 복잡한 연산량을 필요로 할 수 있다. 이에 따라, 외부의 컴퓨팅 장치가 학습하는 동작을 수 행하고, 전자 장치(100a)는 외부 컴퓨팅 장치로부터 학습이 끝난 뉴럴 네트워크 모델을 수신함으로써, 전 자 장치(100a)에서 수행되어야 하는 연산량을 줄일 수 있다. 전자 장치(100a)는 뉴럴 네트워크 모델을 외 부 서버로부터 수신하여 메모리에 저장하고, 저장된 뉴럴 네트워크 모델을 이용하여 태그로부터 음원을 획 득할 수 있다. 도 10은 실시 예에 따른 전자 장치의 내부 블록도이다. 도 10의 전자 장치는 도 2의 전자 장치(100a)의 일 예일 수 있다. 도 10의 전자 장치는 도 2의 전자 장치(100a)의 구성 요소를 포함할 수 있다. 도 10를 참조하면, 전자 장치는 프로세서, 및 메모리 외에, 튜너부, 통신부, 감 지부, 입/출력부, 비디오 처리부, 디스플레이부, 오디오 처리부, 오디오 출력부 , 및 사용자 입력부를 포함할 수 있다. 튜너부는 유선 또는 무선으로 수신되는 방송 콘텐츠 등을 증폭(amplification), 혼합(mixing), 공진 (resonance)등을 통하여 많은 전파 성분 중에서 전자 장치에서 수신하고자 하는 채널의 주파수만을 튜닝 (tuning)시켜 선택할 수 있다. 튜너부를 통해 수신된 콘텐츠는 디코딩되어 오디오, 비디오 및/또는 부가 정보로 분리된다. 분리된 오디오, 비디오 및/또는 부가 정보는 프로세서의 제어에 의해 메모리에 저 장될 수 있다. 통신부는 프로세서의 제어에 의해 전자 장치를 주변 기기나 외부 장치, 서버, 이동 단말기 등 과 연결할 수 있다. 통신부는 무선 통신을 수행할 수 있는 적어도 하나의 통신 모듈을 포함할 수 있다. 통신부는 전자 장치의 성능 및 구조에 대응하여 무선랜 모듈, 블루투스 모듈, 유선 이 더넷(Ethernet) 중 적어도 하나를 포함할 수 있다. 블루투스 모듈은 블루투스 통신 규격에 따라서 주변 기기로부터 전송된 블루투스 신호를 수신할 수 있다. 블루투스 모듈은 BLE(Bluetooth Low Energy) 통신 모듈이 될 수 있으며, BLE 신호를 수신할 수 있다. 블 루투스 모듈은 BLE 신호가 수신되는지 여부를 감지하기 위해서 상시적으로 또는 일시적으로 BLE 신호를 스캔할 수 있다. 무선랜 모듈은 와이파이(Wi-Fi) 통신 규격에 따라서 주변 기기와 와이파이 신호를 송수 신할 수 있다. 실시 예에서, 통신부는 통신 모듈을 이용하여 외부 장치나 서버 등으로부터 외부 상황을 나타내는 다양한 정보들, 예컨대 날씨나 시간, 날짜 등에 대한 정보, 내지는, 사용자 계정에 연계되어 있는 사용자 프로필 정보 등을 획득하고, 이를 프로세서에 전송할 수 있다. 감지부는 사용자의 음성, 사용자의 이미지, 또는 사용자의 인터랙션을 감지하며, 마이크, 카메라부 , 광 수신부, 센싱부를 포함할 수 있다. 마이크는 사용자의 발화(utterance)된 음성 이나 노이즈를 포함하는 오디오 신호를 수신할 수 있고 수신된 오디오 신호를 전기 신호로 변환하여 프로세서 로 출력할 수 있다. 카메라부는 센서(미도시) 및 렌즈(미도시)를 포함하고, 화면에 맺힌 이미지를 촬영하여 캡쳐하고 이를 프 로세서로 전송할 수 있다. 광 수신부는, 광 신호(제어 신호를 포함)를 수신할 수 있다. 광 수신부는 리모컨이나 핸드폰 등과 같은 제어 장치로부터 사용자 입력(예를 들어, 터치, 눌림, 터치 제스처, 음성, 또는 모션)에 대응되는 광 신호를 수신할 수 있다. 센싱부는 전자 장치(100a) 주변의 상태를 감지하고, 감지된 정보를 통신부 또는 프로세서로 전달할 수 있다. 센싱부는 예컨대, 센서는 온/습도 센서, 프레즌스 센서, 조도 센서, 위치 센서(예컨대, GPS), 기압 센서 및 근접 센서 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 입/출력부는 프로세서의 제어에 의해 전자 장치 외부의 기기 등으로부터 비디오(예를 들어, 동이미지 신호나 정지 이미지 신호 등), 오디오(예를 들어, 음성 신호나, 음악 신호 등) 및 부가 정보 등을 수 신할 수 있다. 입/출력부는 HDMI 포트(High-Definition Multimedia Interface port, 1041), 컴포넌트 잭(component jack, 1042), PC 포트(PC port, 1043), 및 USB 포트(USB port, 1044) 중 하나를 포함할 수 있다. 입/출력부 는 HDMI 포트, 컴포넌트 잭, PC 포트, 및 USB 포트의 조합을 포함할 수 있다. 비디오 처리부는, 디스플레이부에 의해 표시될 이미지 데이터를 처리하며, 이미지 데이터에 대한 디코딩, 렌더링, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 및 해상도 변환 등과 같은 다양한 이미지 처리 동작을 수행할 수 있다. 디스플레이부는 방송국으로부터 수신하거나 외부 서버, 또는 외부 저장 매체 등으로부터 수신한 콘텐츠를 화면에 출력할 수 있다. 콘텐츠는 미디어 신호로, 비디오 신호, 이미지, 텍스트 신호 등을 포함할 수 있다. 디스플레이부가 터치 화면으로 구현되는 경우, 디스플레이부는 출력 장치 이외에 사용자 인터페이 스와 같은 입력 장치로 사용될 수 있다. 예를 들어, 디스플레이부는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발광 다이 오드(organic light-emitting diode), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(4D display), 전기 영동 디스플레이(electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고, 디 스플레이부의 구현 형태에 따라, 디스플레이부는 둘 이상 포함될 수 있다. 오디오 처리부는 오디오 데이터에 대한 처리를 수행한다. 오디오 처리부에서는 오디오 데이터에 대 한 디코딩이나 증폭, 노이즈 필터링 등과 같은 다양한 처리가 수행될 수 있다. 오디오 출력부는 프로세서의 제어에 의해 튜너부를 통해 수신된 콘텐츠에 포함된 오디오, 통 신부 또는 입/출력부를 통해 입력되는 오디오, 메모리에 저장된 오디오를 출력할 수 있다. 오 디오 출력부는 스피커, 헤드폰 또는 S/PDIF(Sony/Philips Digital Interface: 출력 단 자) 중 적어도 하나를 포함할 수 있다. 실시 예에서, 오디오 출력부는 프로세서가 생성한 음원에 따라 음악을 연주하여 출력할 수 있다. 사용자 입력부는 전자 장치를 제어하기 위한 사용자 입력을 수신할 수 있다. 사용자 입력부 는 사용자의 터치를 감지하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용자의 회전 조작을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch), 음성 인식을 위한 마이크, 모션을 센싱하는 모션 감지 센 서 등을 포함하는 다양한 형태의 사용자 입력 디바이스를 포함할 수 있으나 이에 제한되지 않는다. 리모컨이나 기타 이동 단말기가 전자 장치를 제어하는 경우, 사용자 입력부는 이동 단말기로부터 수신되는 제 어 신호를 수신할 수 있다. 도 11은 실시 예에 따라, 음원을 생성하는 방법을 도시한 순서도이다. 도 11을 참조하면, 전자 장치는 음원 생성 정보를 획득할 수 있다(단계 1110). 실시 예에서, 음원 생성 정보는 이미지 정보, 주변 상황 정보, 및 사용자 취향 정보 중 적어도 하나를 포함할 수 있다. 실시 예에서, 전자 장치는 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득할 수 있다(단계 1120). 실시 예에서, 전자 장치는 내부의 데이터 베이스나 외부의 서버 등에 저장된 음원과 관련된 정보들 중, 음원 생 성 정보에 매핑되는 정보들을 찾고, 음원 생성 정보에 매핑되어 있는 태그들을 검색하여 획득할 수 있다. 실시 예에서, 전자 장치는 음원 생성 태그들에 기반하여 음원을 생성할 수 있다(단계 1130). 실시 예에서, 전자 장치는 태그와 음원 간의 관계를 학습한 뉴럴 네트워크를 이용하여, 뉴럴 네트워크에 음원 생성 태그들을 입력시키고, 뉴럴 네트워크로부터 음원을 획득할 수 있다. 도 12는 실시 예에 따라, 음원 생성 태그들을 필터링하는 방법을 도시한 순서도이다. 도 12를 참조하면, 전자 장치는 음원 생성 태그들 별 점수를 획득할 수 있다(단계 1210). 전자 장치는 태그 별 중복도, 인식 결과의 정확도, 태그 별 웨이트, 상황 기반 태그 별 웨이트 중 적어도 하나 에 기반하여 음원 생성 태그들에 대한 점수를 획득할 수 있다. 실시 예에서, 전자 장치는 높은 점수를 갖는 음원 생성 태그들을 필터링할 수 있다(단계 1220). 실시 예에서, 전자 장치는 음원 생성 태그들 중 기준 값 이상의 점수를 갖는 음원 생성 태그들을 필터링하거나, 또는 높은 점수 순서대로 소정 개수만큼의 음원 생성 태그들을 필터링할 수 있다. 실시 예에서, 전자 장치는 주변 상황 정보 및 사용자 식별 정보 중 적어도 하나에 기반하여, 필터링된 음원 생 성 태그들을 추가로 필터링할 수도 있다. 실시 예에서, 전자 장치는 필터링된 음원 생성 태그들을 이용하여 음원을 생성할 수 있다(단계 1230). 전자 장치는 태그와 음원 간의 관계를 학습한 뉴럴 네트워크에, 필터링된 태그들을 입력 시키고, 뉴럴 네트워크 로부터 필터링된 태그들에 대응하는 음원을 획득할 수 있다. 도 13은 실시 예에 따라, 음원 생성 정보 별로 음원 생성 태그들을 필터링하여 음원을 생성하는 방법을 도시한 순서도이다. 도 13을 참조하면, 전자 장치는 이미지 정보에 매핑되는 음원 생성 태그들 별 점수를 획득할 수 있다(단계 1310). 실시 예에서, 전자 장치는 음원 생성 정보 중, 이미지로부터 획득된 이미지 정보에 대해서 매핑되는 음원 생성 태그들을 획득할 수 있다. 전자 장치는 이미지 정보에 매핑되는 음원 생성 태그들 별로 점수를 획득할 수 있다. 예컨대, 전자 장치는 이미지 정보에 매핑되는 음원 생성 태그들 각각에 대해, 인식 결과의 정확도, 태그 별 중 복도, 태그 별 웨이트 중 적어도 하나에 기반하여, 이미지 정보에 매핑되는 음원 생성 태그들 별 점수를 획득할 수 있다. 실시 예에서, 전자 장치는 이미지 정보에 매핑되는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들을 필터링할 수 있다. 이미지 정보에 매핑되는 음원 생성 태그들 중에서 필터링된 음원 생성 태그들을 제1 태그들 이라 할 때, 전자 장치는 제1 태그들을 획득할 수 있다(단계 1320). 실시 예에서, 전자 장치는 주변 상황 정보에 매핑되는 음원 생성 태그들 별 점수를 획득할 수 있다(단계 1330). 실시 예에서, 전자 장치는 음원 생성 정보 중, 주변 상황 정보에 대해, 주변 상황 정보에 매핑되는 음원 생성 태그들을 획득하고, 주변 상황 정보에 매핑되는 음원 생성 태그들 별로 점수를 획득할 수 있다. 실시 예에서, 전자 장치는 상황에 따른 사용자 선호도를 나타내는 상황 기반 태그 별 웨이트를 획득하고, 상황 기반 태그 별 웨이트에 기반하여, 주변 상황 정보에 매핑되는 음원 생성 태그들 별 점수를 획득할 수 있다. 또 는 전자 장치는 상황 기반 태그 별 웨이트 외에, 태그 별 중복도를 더 고려하여 주변 상황 정보에 매핑되는 음 원 생성 태그들 별 점수를 획득할 수도 있다. 실시 예에서, 전자 장치는 주변 상황 정보에 매핑되는 음원 생성 태그들 중 높은 점수를 갖는 음원 생성 태그들 을 필터링할 수 있다. 실시 예에서, 주변 상황 정보에 매핑되는 음원 생성 태그들 중에서 필터링된 음원 생성 태그들을 제2 태그들이 라 할 때, 전자 장치는 제2 태그들을 획득할 수 있다(단계 1340). 실시 예에서, 전자 장치는 제1 태그들과 제2 태그들 중 적어도 하나를 이용하여 음원을 생성할 수 있다(단계 1340). 예컨대, 전자 장치는 제1 태그들과 제2 태그들을 합치고 이들을 점수에 따라 한번 더 필터링할 수 있다. 또는 전자 장치는 제1 태그들과 제2 태그들 중 중복되는 태그들만을 필터링할 수 있다. 전자 장치는 다양한 방법으로 제1 태그들와 제2 태그들을 함께 고려하여 최종 태그들을 획득하고, 최종 태그들에 기반하여 음원을 생성할 수 있다. 도 14는 실시 예에 따라, 태그 별 웨이트를 획득하는 방법을 도시한 순서도이다. 도 14를 참조하면, 전자 장치는 태그 별 웨이트를 획득할 수 있다. 실시 예에서, 태그 별 웨이트는 각각의 태그에 대한 사용자의 선호도를 나타내는 정보일 수 있다. 전자 장치는 사용자 취향 정보와 음악 재생 이력 중 적어도 하나를 기반으로 태그 별 웨이트를 생성할 수 있다. 예컨대, 아 직 사용자의 음악 재생 이력이 없거나 충분하지 않은 경우, 전자 장치는 사용자 취향 정보에 기반하여서만 태그 별 웨이트를 생성할 수 있다. 실시 예에서, 전자 장치는 음원이 생성되면 음원에 따라 음악을 재생할 수 있다(단계 1420). 실시 예에서, 전자 장치는 음악 재생에 따라 태그 별 웨이트를 업데이트할 수 있다(단계 1430). 예컨대, 전자 장치는 사용자가 특정 음악을 반복하여 청취하는 경우, 특정 음악을 생성하는 데 이용된 태그들의 웨이트를 늘림으로써 태그 별 웨이트를 업데이트할 수 있다. 이후, 전자 장치는 업데이트된 태그 별 웨이트를 이용하여, 태그 별 점수를 부여할 수 있다. 전자 장치는 업데 이트된 태그 별 웨이트에 따라 바뀐 태그 별 점수를 이용하여 태그를 필터링함으로써, 음악 재생 정보에 따라 다른 음악이 생성되도록 할 수 있다. 일부 실시 예에 따른 전자 장치의 동작 방법 및 장치는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비 휘발성 매체, 분리형 및 비 분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위 한 임의의 방법 또는 기술로 구현된 휘발성 및 비 휘발성, 분리형 및 비 분리형 매체를 모두 포함한다. 통신 매 체는 전형적으로 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신 호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전달 매체를 포함한다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 또한, 전술한 본 개시의 실시 예에 따른 전자 장치 및 그 동작 방법은 이미지 정보, 주변 상황 정보, 및 사용자 취향 정보 중 적어도 하나를 포함하는, 음원 생성 정보를 획득하는 단계, 상기 음원 생성 정보에 매핑되는 음원 생성 태그들을 획득하는 단계 및 상기 음원 생성 태그들에 기반하여 음원을 생성하는 단계를 포함하는, 전자 장 치의 동작 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체/저장 매체를 포함하는 컴 퓨터 프로그램 제품으로 구현될 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매체의 형태로 제공될 수 있다. 여기서,‘비 일시적 저장 매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의 미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분 하지 않는다. 예로, '비일시적 저장 매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간 에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품 (예:다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중 계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있 다."}
{"patent_id": "10-2022-0002953", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 설명은 예시를 위한 것이며, 발명이 속하는 기술분야의 통상의 지식을 가진 자는 발명의 기술적 사상이 나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한 다. 예를 들어, 단일 형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14"}
{"patent_id": "10-2022-0002953", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시 예에 따라, 음원 생성 정보에 기반하여 음악을 생성하고 이를 사용자에게 제공하는 것을 설명하기 위한 도면이다. 도 2는 실시 예에 따른 전자 장치의 일 예의 내부 블록도이다. 도 3은 실시 예에 따른 도 2의 프로세서의 내부 블록도이다. 도 4는 실시 예에 따른 도 3의 음원 생성 정보 획득부의 내부 블록도이다. 도 5는 실시 예에 따른 도 4의 이미지 정보 획득부가 이미지 정보를 획득하는 방법을 설명하기 위한 도면이다. 도 6은 실시 예에 따른 도 3의 음원 생성 태그 획득부의 내부 블록도이다. 도 7은 실시 예에 따라, 도 6의 태그 필터링부가 태그 별 점수를 고려하여 태그를 필터링하는 것을 설명하기 위 한 도면이다. 도 8은 실시 예에 따른 음원 생성 정보와 태그 간의 관계를 도시한 도면이다. 도 9는 실시 예에 따라, 태그로부터 음원을 획득하도록 학습된 신경망을 설명하기 위한 도면이다. 도 10은 실시 예에 따른 전자 장치의 내부 블록도이다. 도 11은 실시 예에 따라, 음원을 생성하는 방법을 도시한 순서도이다. 도 12는 실시 예에 따라, 음원 생성 태그들을 필터링하는 방법을 도시한 순서도이다. 도 13은 실시 예에 따라, 음원 생성 정보 별로 음원 생성 태그들을 필터링하여 음원을 생성하는 방법을 도시한 순서도이다. 도 14는 실시 예에 따라, 태그 별 웨이트를 획득하는 방법을 도시한 순서도이다."}
