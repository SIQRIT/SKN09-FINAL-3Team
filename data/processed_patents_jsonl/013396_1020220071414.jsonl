{"patent_id": "10-2022-0071414", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0055939", "출원번호": "10-2022-0071414", "발명의 명칭": "캐시 메모리 관리 장치 및 방법", "출원인": "한국전자통신연구원", "발명자": "김현미"}}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 프로세서; 및상기 하나 이상의 프로세서에 의해 실행되는 적어도 하나 이상의 프로그램을 저장하는 실행메모리를 포함하고,상기 적어도 하나 이상의 프로그램은캐시 메모리 접근 요청에 따라 데이터를 읽어오기 위한 접근 요청 주소를 수신하면 상기 캐시 메모리의 1단계태그와 2단계 태그를 읽어오고,상기 접근 요청 주소가 상기 1단계 태그의 값과 상기 2단계 태그의 값이 일치하는지 확인하고,상기 접근 요청 주소가 상기 1단계 태그 및 상기 2단계 태그의 값이 모두 일치하는 경우, 데이터 메모리로부터상기 데이터를 읽어오는 것을 특징으로 하는 캐시 메모리 관리 장치."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 캐시 메모리는 복수개의 캐시라인들이 설정되고,상기 복수개의 캐시라인들은 캐시라인 길이를 기반으로 캐시라인 세트의 개수가 다르게 설정된 것을 특징으로하는 캐시 메모리 관리 장치."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 1단계 태그는 세트 인덱스로 상기 캐시 메모리의 각 캐시라인에 사용되는 태그이고,상기 2단계 태그는 상기 캐시 메모리의 각 캐시라인에서 기설정된 캐시라인의 세트마다 할당되는 것을 특징으로하는 캐시 메모리 관리 장치."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 캐시라인 세트의 전체에 공통으로 사용되는 태그는 상기 1단계 태그의 메모리에 저장되고,상기 캐시라인 세트의 각각에 사용되는 태그는 상기 2단계 태그의 메모리에 저장되는 것을 특징으로 하는 캐시메모리 관리 장치."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 2단계 태그의 메모리는상태 정보에 기설정된 비트값을 이용하여 상기 캐시라인들 중 어느 캐시라인이 0의 값을 갖는지 설정되는 것을특징으로 하는 캐시 메모리 관리 장치."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,상기 적어도 하나 이상의 프로그램은상기 접근 요청 주소와 상기 1단계 태그의 값이 일치하지 않는 경우, 상기 상태 정보의 기설정된 비트값을 확인공개특허 10-2023-0055939-3-하는 것을 특징으로 하는 캐시 메모리 관리 장치."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 적어도 하나 이상의 프로그램은상기 상태 정보의 기설정된 비트값 및 상기 2단계 태그의 첫번째 캐시라인 세트의 값이 상기 접근 요청 주소와일치하는지 확인하는 것을 특징으로 하는 캐시 메모리 관리 장치."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 적어도 하나 이상의 프로그램은상기 상태 정보의 기설정된 비트값 및 상기 2단계 태그의 첫번째 캐시라인 세트의 값 중 어느 하나가 상기 접근요청 주소와 일치하지 않는 경우, 상기 2단계 태그의 다음번째 캐시라인 세트들 중 일치하는 캐시라인 세트의값이 존재하는지 확인하는 것을 특징으로 하는 캐시 메모리 관리 장치."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 적어도 하나 이상의 프로그램은일치하는 캐시라인 세트의 값이 존재하지 않는 경우, 캐시 미스로 처리하고, 일치하는 캐시라인 세트의 값이 존재하는 경우, 상기 데이터 메모리에서 상기 데이터를 읽어오는 것을 특징으로 하는 캐시 메모리 관리 장치."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "캐시 메모리 관리 장치의 캐시 메모리 관리 방법에 있어서,캐시 메모리 접근 요청에 따라 데이터를 읽어오기 위한 접근 요청 주소를 수신하면 상기 캐시 메모리의 1단계태그와 2단계 태그를 읽어오는 단계;상기 접근 요청 주소가 상기 1단계 태그의 값과 상기 2단계 태그의 값이 일치하는지 확인하는 단계; 및상기 접근 요청 주소가 상기 1단계 태그 및 상기 2단계 태그의 값이 모두 일치하는 경우, 데이터 메모리로부터상기 데이터를 읽어오는 단계;를 포함하는 것을 특징으로 하는 캐시 메모리 관리 방법."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서,상기 캐시 메모리는 복수개의 캐시라인들이 설정되고,상기 복수개의 캐시라인들은 캐시라인 길이를 기반으로 캐시라인 세트의 개수가 다르게 설정된 것을 특징으로하는 캐시 메모리 관리 방법."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 1단계 태그는 세트 인덱스로 상기 캐시 메모리의 각 캐시라인에 사용되는 태그이고,상기 2단계 태그는 상기 캐시 메모리의 각 캐시라인에서 기설정된 캐시라인의 세트마다 할당되는 것을 특징으로하는 캐시 메모리 관리 방법."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2023-0055939-4-청구항 12에 있어서,상기 캐시라인 세트의 전체에 공통으로 사용되는 태그는 상기 1단계 태그의 메모리에 저장되고,상기 캐시라인 세트의 각각에 사용되는 태그는 상기 2단계 태그의 메모리에 저장되는 것을 특징으로 하는 캐시메모리 관리 방법."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13에 있어서,상기 2단계 태그의 메모리는상태 정보에 기설정된 비트값을 이용하여 상기 캐시라인들 중 어느 캐시라인이 0의 값을 갖는지 설정되는 것을특징으로 하는 캐시 메모리 관리 방법."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 14에 있어서,상기 확인하는 단계는상기 접근 요청 주소와 상기 1단계 태그의 값이 일치하지 않는 경우, 상기 상태 정보의 기설정된 비트값을 확인하는 것을 특징으로 하는 캐시 메모리 관리 방법."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 15에 있어서,상기 확인하는 단계는상기 상태 정보의 기설정된 비트값 및 상기 2단계 태그의 첫번째 캐시라인 세트의 값이 상기 접근 요청 주소와일치하는지 확인하는 것을 특징으로 하는 캐시 메모리 관리 방법."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 16에 있어서,상기 확인하는 단계는상기 상태 정보의 기설정된 비트값 및 상기 2단계 태그의 첫번째 캐시라인 세트의 값 중 어느 하나가 상기 접근요청 주소와 일치하지 않는 경우, 상기 2단계 태그의 다음번째 캐시라인 세트들 중 일치하는 캐시라인 세트의값이 존재하는지 확인하는 것을 특징으로 하는 캐시 메모리 관리 방법."}
{"patent_id": "10-2022-0071414", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 17에 있어서,상기 데이터를 읽어오는 단계는일치하는 캐시라인 세트의 값이 존재하지 않는 경우, 캐시 미스로 처리하고, 일치하는 캐시라인 세트의 값이 존재하는 경우, 상기 데이터 메모리에서 상기 데이터를 읽어오는 것을 특징으로 하는 캐시 메모리 관리 방법."}
{"patent_id": "10-2022-0071414", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "캐시 메모리 관리 장치 및 방법이 개시된다. 본 발명의 일실시예에 따른 캐시 메모리 관리 장치는 하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의해 실행되는 적어도 하나 이상의 프로그램을 저장하는 실행메모리 를 포함하고, 상기 적어도 하나 이상의 프로그램은 캐시 메모리 접근 요청에 따라 데이터를 읽어오기 위한 접근 요청 주소를 수신하면 상기 캐시 메모리의 1단계 태그와 2단계 태그를 읽어오고, 상기 접근 요청 주소가 상기 1 단계 태그의 값과 상기 2단계 태그의 값이 일치하는지 확인하고, 상기 접근 요청 주소가 상기 1단계 태그 및 상 기 2단계 태그의 값이 모두 일치하는 경우, 데이터 메모리로부터 상기 데이터를 읽어온다."}
{"patent_id": "10-2022-0071414", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 캐시 메모리 관리 기술에 관한 것으로, 보다 상세하게는 인공지능 프로세서를 위한 고효율 및 저전력 캐시 메모리 관리 기술에 관한 것이다."}
{"patent_id": "10-2022-0071414", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 프로세서를 구성하기 위해 데이터를 빠른 속도로 엑세스(access)하기 위한 온칩(On-chip) 메모리나 캐 시(Cache)는 필수적이다. 특히, 고성능 병렬 프로세싱 기반의 인공지능 프로세서는 여러 층(heirarchy)의 공유캐시 기반의 시스템으로 구성되고 캐시는 온칩에서의 데이터 재사용율을 높여 성능 향상 및 효율적인 전력소모 효과를 가져온다. 하지만, 캐시에서 미스(miss)가 발생할 때는 외부 메모리 엑세스가 필요하므로 이는 프로세서 의 연산 및 전력소모 성능을 현저히 저하시키는 요인이 되기 때문에 캐시 미스 레이트(cache miss rate)를 줄이 기 위한 방법을 필요로 하게 된다. 또한, 캐시의 다양한 구조가 프로세서의 특성 및 구동하고자 하는 프로그램 의 특성과 맞지 않을 때는 기대하는 성능 향상의 반대효과를 가져올 수도 있다. 현재 인공지능의 학습과 추론 알고리즘을 처리하는 프로세서 중 가장 넓게 사용되고 있는 프로세서 구조 중 하 나는 GPU의 SIMT(Single Instruction Multiple Thread) 구조이다. 하나의 명령어로 수천개의 스레드(thread)를 동작시켜 연산을 수행하도록 하는 고성능 병렬 컴퓨팅 구조이다. 이런 고성능 병렬 컴퓨팅 구조에서는 높은 성 능을 위해 빠른 연산기, 높은 메모리 대역폭을 필요로 하고 높은 전력이 소모되며 그로 인해 많은 열이 발생하 는 문제가 야기된다. 이 중 높은 메모리 대역폭을 제공하기 위해 넓은 캐시 라인(cache line)을 가진 L1 데이터 캐시를 필요로 한다. 하지만, 넒은 캐리 라인은 다양한 데이터 타입이나 연산 종류에 따라 캐시 미스율(cache miss rate)를 높여 비효율적인 캐시 동작을 야기하고 따라서 연산 성능을 저하시키고 전력소모량을 높인다. 예를 들어, 엔비디아(NVIDIA)의 GPU의 경우, L1 캐시의 캐시라인의 크기는 128Kbyte를 채택하여 와프(Warp)내의 총 32개의 스레드가 동시에 메모리의 4바이트씩의 데이터에 접근이 가능하도록 했다. 하지만, 최근 인공지능 알 고리즘의 발전에 따라 연산 데이터의 타입이 이전에 주로 사용되었던 4바이트의 단정밀도 부동소수점(single- precision floating point)과 다른 크기를 갖거나 32개보다 적은 스레드를 필요로 하는 경우가 다수 발생했다. 따라서, 처리하고자 하는 프로그램에 따라 처리되는 데이터의 크기와 활용되는 스레드의 개수 등이 매우 불규칙 해지고 128K바이트의 넓은 캐시라인은 4바이트x32개 스레드의 조건이 벗어난 프로그램을 처리하는 경우 높은 캐 시 미스율(miss rate)를 발생시키고 따라서 전체 인공지능 프로세서의 성능 저하 및 전력 소모 증가를 야기한다. 한편, 한국공개특허 제 10-2021-0075007 호\"인공지능 프로세서를 위한 캐시\"는 인공지능 알고리즘의 연산 대상 이 되는 특징 데이터 및 커널 데이터를 압축하여 외부 메모리에 저장하고, 외부 메모리를 읽고 쓰는 횟수를 줄 일 수 있는 인공지능 프로세서를 위한 캐시에 관하여 개시하고 있다."}
{"patent_id": "10-2022-0071414", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 고병렬성을 기반으로 한 고성능 인공지능 프로세서에서 캐시 성능을 최대화하고, 전력 소모를 최소화 하여 인공지능 프로세서를 효율적으로 관리하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0071414", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일실시예에 따른 캐시 메모리 관리 장치는 하나 이상의 프로세서 및 상 기 하나 이상의 프로세서에 의해 실행되는 적어도 하나 이상의 프로그램을 저장하는 실행메모리를 포함하고, 상 기 적어도 하나 이상의 프로그램은 캐시 메모리 접근 요청에 따라 데이터를 읽어오기 위한 접근 요청 주소를 수 신하면 상기 캐시 메모리의 1단계 태그와 2단계 태그를 읽어오고, 상기 접근 요청 주소가 상기 1단계 태그의 값 과 상기 2단계 태그의 값이 일치하는지 확인하고, 상기 접근 요청 주소가 상기 1단계 태그 및 상기 2단계 태그 의 값이 모두 일치하는 경우, 데이터 메모리로부터 상기 데이터를 읽어온다. 이 때, 상기 캐시 메모리는 복수개의 캐시라인들이 설정되고, 상기 복수개의 캐시라인들은 캐시라인 길이를 기 반으로 캐시라인 세트의 개수가 다르게 설정될 수 있다. 이 때, 상기 1단계 태그는 세트 인덱스로 상기 캐시 메모리의 각 캐시라인에 사용되는 태그이고, 상기 2단계 태 그는 상기 캐시 메모리의 각 캐시라인에서 기설정된 캐시라인의 세트마다 할당될 수 있다. 이 때, 상기 캐시라인 세트의 전체에 공통으로 사용되는 태그는 상기 1단계 태그의 메모리에 저장되고, 상기 캐 시라인 세트의 각각에 사용되는 태그는 상기 2단계 태그의 메모리에 저장될 수 있다. 이 때, 상기 2단계 태그의 메모리는 상태 정보에 기설정된 비트값을 이용하여 상기 캐시라인들 중 어느 캐시라 인이 0의 값을 갖는지 설정될 수 있다. 이 때, 상기 적어도 하나 이상의 프로그램은 상기 접근 요청 주소와 상기 1단계 태그의 값이 일치하지 않는 경 우, 상기 상태 정보의 기설정된 비트값을 확인할 수 있다.이 때, 상기 적어도 하나 이상의 프로그램은 상기 상태 정보의 기설정된 비트값 및 상기 2단계 태그의 첫번째 캐시라인 세트의 값이 상기 접근 요청 주소와 일치하는지 확인할 수 있다. 이 때, 상기 적어도 하나 이상의 프로그램은 상기 상태 정보의 기설정된 비트값 및 상기 2단계 태그의 첫번째 캐시라인 세트의 값 중 어느 하나가 상기 접근 요청 주소와 일치하지 않는 경우, 상기 2단계 태그의 다음번째 캐시라인 세트들 중 일치하는 캐시라인 세트의 값이 존재하는지 확인할 수 있다. 이 때, 상기 적어도 하나 이상의 프로그램은 일치하는 캐시라인 세트의 값이 존재하지 않는 경우, 캐시 미스로 처리하고, 일치하는 캐시라인 세트의 값이 존재하는 경우, 상기 데이터 메모리에서 상기 데이터를 읽어올 수 있 다. 또한, 상기한 목적을 달성하기 위한 본 발명의 일실시예에 따른 캐시 메모리 관리 방법은 캐시 메모리 관리 장 치의 캐시 메모리 관리 방법에 있어서, 캐시 메모리 접근 요청에 따라 데이터를 읽어오기 위한 접근 요청 주소 를 수신하면 상기 캐시 메모리의 1단계 태그와 2단계 태그를 읽어오는 단계; 상기 접근 요청 주소가 상기 1단계 태그의 값과 상기 2단계 태그의 값이 일치하는지 확인하는 단계 및 상기 접근 요청 주소가 상기 1단계 태그 및 상기 2단계 태그의 값이 모두 일치하는 경우, 데이터 메모리로부터 상기 데이터를 읽어오는 단계를 포함한다. 이 때, 상기 캐시 메모리는 복수개의 캐시라인들이 설정되고, 상기 복수개의 캐시라인들은 캐시라인 길이를 기 반으로 캐시라인 세트의 개수가 다르게 설정된 것일 수 있다. 이 때, 상기 1단계 태그는 세트 인덱스로 상기 캐시 메모리의 각 캐시라인에 사용되는 태그이고, 상기 2단계 태 그는 상기 캐시 메모리의 각 캐시라인에서 기설정된 캐시라인의 세트마다 할당될 수 있다. 이 때, 상기 캐시라인 세트의 전체에 공통으로 사용되는 태그는 상기 1단계 태그의 메모리에 저장되고, 상기 캐 시라인 세트의 각각에 사용되는 태그는 상기 2단계 태그의 메모리에 저장될 수 있다. 이 때, 상기 2단계 태그의 메모리는 상태 정보에 기설정된 비트값을 이용하여 상기 캐시라인들 중 어느 캐시라 인이 0의 값을 갖는지 설정될 수 있다. 이 때, 상기 확인하는 단계는 상기 접근 요청 주소와 상기 1단계 태그의 값이 일치하지 않는 경우, 상기 상태 정보의 기설정된 비트값을 확인할 수 있다. 이 때, 상기 확인하는 단계는 상기 상태 정보의 기설정된 비트값 및 상기 2단계 태그의 첫번째 캐시라인 세트의 값이 상기 접근 요청 주소와 일치하는지 확인할 수 있다. 이 때, 상기 확인하는 단계는상기 상태 정보의 기설정된 비트값 및 상기 2단계 태그의 첫번째 캐시라인 세트의 값 중 어느 하나가 상기 접근 요청 주소와 일치하지 않는 경우, 상기 2단계 태그의 다음번째 캐시라인 세트들 중 일치하는 캐시라인 세트의 값이 존재하는지 확인할 수 있다. 이 때, 상기 데이터를 읽어오는 단계는 일치하는 캐시라인 세트의 값이 존재하지 않는 경우, 캐시 미스로 처리 하고, 일치하는 캐시라인 세트의 값이 존재하는 경우, 상기 데이터 메모리에서 상기 데이터를 읽어올 수 있다."}
{"patent_id": "10-2022-0071414", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 고병렬성을 기반으로 한 고성능 인공지능 프로세서에서 캐시 성능을 최대화하고, 전력 소모를 최소화 하여 인공지능 프로세서를 효율적으로 관리할 수 있다."}
{"patent_id": "10-2022-0071414", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명을 첨부된 도면을 참조하여 상세히 설명하면 다음과 같다. 여기서, 반복되는 설명, 본 발명의 요지를 불 필요하게 흐릴 수 있는 공지 기능, 및 구성에 대한 상세한 설명은 생략한다. 본 발명의 실시형태는 당 업계에서 평균적인 지식을 가진 자에게 본 발명을 보다 완전하게 설명하기 위해서 제공되는 것이다. 따라서, 도면에서의 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하, 본 발명에 따른 바람직한 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 본 발명의 일실시예에 따른 인공지능 프로세스를 위한 캐시 메모리 관리 장치를 나타낸 블록도이다. 도 2는 도 1에 도시된 스트리밍 멀티프로세서의 일 옐를 세부적으로 나타낸 블록도이다. 도 3은 도 2에 도시된 실 행 유닛의 일 예를 세부적으로 나타낸 블록도이다. 도 1을 참조하면, 본 발명의 일실시예에 따른 인공지능 프로세스를 위한 캐시 메모리 관리 장치는 GPU의 SIMT(Single Instruction Multiple Thread) 구조에 상응하는 것을 알 수 있다. 캐시 메모리 관리 장치는 복수개의 스트리밍 멀티프로세서들, 온-칩 인터커넥션 네트워크, L2 캐시들 및 오프― 칩 글로벌 메모리를 포함할 수 있다. 도 2를 참조하면, 스트리밍 멀티프로세서는 복수개의 실행 유닛(EU, execution unit)들, 인터커넥션 네트워크, L1 데이터 캐시 및 L1 인스트럭션 캐시를 포함할 수 있다. 도 3을 참조하면, 실행 유닛은 L0 인스트럭션 캐시, 컨트롤 유닛, 메모리 유닛 및 프로세싱 유닛(PU, processing unit)을 포함할 수 있다. 프로세싱 유닛은 실행 유닛 내에서 연산처리를 담당하는 기본 연산기이다. 메모리는 프로세싱 유닛에 데이터를 공급하고 연산 결과를 저장하기 위해 클러스터 계층과 쌍을 이뤄 계층 적으로 구성될 수 있다. 온칩(on-chip) 공유 메모리(shared memory) 및 L1 캐시는 높은 대역폭(Bandwidth)과 낮은 지연(latency)의 활 용해 여러 연산기가 동시에 메모리에 접근 하도록 지원하여 병렬성을 최대화할 수 있다. 본 발명에서는 다양한 연산에 따라 효율적인 관리가 가능한 캐시 구성을 통해 연산 성능 뿐만 아니라 전력 소모 의 효율성을 높일 수 있다. 더욱이 인공지능 프로세서에서 처리하는 알고리즘의 경우, 활성 데이터(activation) 값이 '0'인 경우가 많다는 특징이 있다. 따라서, 이 특징을 캐시 구성에 활용하면 전력소모량을 추가적으로 감 소시킬 수 있기 때문에 인공지능 프로세서를 위한 효율적인 캐시 구성이 가능해진다. 이를 위해, 본 발명의 일실시예에 따른 캐시 메모리 관리 장치 및 방법은 가변 캐시라인 구성을 제공할 수 있다. 더욱이 인공지능 알고리즘 처리시 다뤄지는 활성데이터의 값이 0인 경우가 많은 희소성(sparsity) 특성을 이용하여 가변 캐시라인 구성을 결합시키면 보다 더 효율적인 인공지능 프로세서를 위한 캐시 메모리 관리 장치 를 구현할 수 있다. 도 4는 본 발명의 일실시예에 따른 캐시 주소 구조를 나타낸 도면이다. 도 4를 참조하면, 총 48bit의 주소길이를 갖는 128KB 단위의 캐시라인으로 이뤄진 2-way 집합 연관된 캐시 주소 구조를 나타낸 것을 알 수 있다. 캐시는 검색속도와 저장속도의 상충관계를 절충한 집합 연관 캐시(set associative cache) 구조 기반으로 구성 되고 웨이(way)의 개수만큼 데이터 메모리와 태그 메모리를 포함할 수 있다. 이 때, 태그 정보는 128KB 단위의 캐시라인을 위한 주소 정보 중 인덱스(index) 정보와 바이트 오프셋(offset) 정보를 제외한 나머지 주소 정보를 나타내는 것을 알 수 있다. 태그 정보를 저장하기 위한 태그 메모리는 데이터 메모리와 별도의 물리적 메모리를 사용하여 구성되는 것을 알 수 있다. 도 5는 본 발명의 일실시예에 따른 캐시의 주소 구조을 나타낸 도면이다. 도 6은 본 발명의 일실시예에 따른 태 그 메모리 구조를 나타낸 도면이다. 도 7은 본 발명의 일실시예에 따른 데이터 메모리 구조를 나타낸 도면이다. 도 8은 본 발명의 일실시예에 따른 1단계 태그(s1-tag)의 구조를 나타낸 도면이다. 도 5 내지 도 8을 참조하면, 128KB, 64KB, 32KB 세 가지의 캐시라인 구성이 가변적으로 가능한 캐시 주소 구조, 태그 메모리 구조, 데이터 메모리 구조 및 1단계 태그(s1-tag)의 구조를 나타낸 것을 알 수 있다. 태그 주소는 1단계 태그(s1-tag)와 2단계(s2-tag)를 포함하는 것을 알 수 있다. 예를 들어, 도 7에 도시된 데이터 메모리 구조가 32KB 캐시라인길이를 갖도록 설정된 경우, 캐시라인 0은 32kb 로 4개의 set로 나뉜 것을 알 수 있고, 캐시라인 1은 64kb로 2개의 set로 나뉜 것을 알 수 있고, 캐시라인 2는 128kb로 1개의 set를 갖는 것을 알 수 있다. 이처럼, 캐시 메모리는 복수개의 캐시라인들이 설정되고, 상기 복수개의 캐시라인들은 캐시라인 길이를 기반으 로 캐시라인 세트의 개수가 다르게 설정될 수 있다. 각 32KB의 캐시라인은 4개의 set으로 나뉘고 4개의 set 전체에 공통으로 사용되는 태그는 s1-tag 메모리에, 4개 의 set 각각에 사용되는 태그는 s2-tag에 저장될 수 있다. 메모리 접근 요청 시 두 단계 태그 비교기(s1-tag 비 교기와 s2-tag 비교기)를 사용하여 캐시 힛(hit)/미스(miss)를 판단할 수 있다. 캐시 주소 구조에서와 같이 S2-tag 값의 구성은 기존 주소값의 태그의 일부분과 오프셋의 일부분을 사용하여 구 성될 수 있다. S2-tag 메모리에는 3비트의 상태 정보를 추가하여 1비트는 유효비트로 사용하고 나머지 2비트는 각 캐시라인이 어떤 granularity로 구성되는지 기설정된 granularity 비트값으로 나타낸 것을 알 수 있다. 추가적으로 granularity 비트값이 모두 1이면 해당 캐시라인의 데이터는 모두 '0'의 값을 갖는 데이터로 설정될 수 있다. 이를 이용해 상태 정보를 보고 해당 캐시라인의 데이터가 모두 '0'이면 데이터 메모리를 접근하지 않도록 하여 메모리 접근에 필요한 전력 소모를 아낄 수 있다. 도 9는 본 발명의 일실시예에 따른 캐시 메모리 관리 방법을 나타낸 동작흐름도이다. 도 9를 참조하면, 본 발명의 일실시예에 따른 캐시 메모리 관리 방법은 먼저 캐시 메모리 접근 요청을 수신할 수 있다(S210). 또한, 단계(S220)는 캐시 메모리 접근 요청을 수신하면 s1-tag 와 s2-tag(set0)을 읽을 수 있다. 이 때, 단계(S220)는 태그 메모리들의 접근 시간을 줄이기 위해 s2-tag(set0)는 s1-tag와 함께 태그메모리로부 터 읽을 수 있다. 또한, 단계(S230)는 s1-tag가 접근 요청 주소의 s1-tag 값과 일치하는 지 확인할 수 있다. 이 때, 단계(S230)는 태그 정보가 일치하지 않으면 캐시 미스 정책에 의해 외부 메모리로부터 데이터를 읽어올 수 있다(S290). 이 때, 단계(S230)는 태그 정보가 일치하면 상태 정보가 'all zero'인지를 판단할 수 있다(S240). 이 때, 단계(S240)는 상태 정보가 'all zero'인 경우 데이터 메모리의 접근 없이 데이터 값을 0으로 리턴할 수 있다(S210). 이 때, 단계(S240)는 상태 정보가 'all zero'가 아닌 경우, granularity 상태를 확인할 수 있다(S250). 이 때, 단계(S260)는 granularity 값과 s2-tag의 최하위 비트(least significant bit, LSB) 값이 어느 하나가 'zero'가 아닌 경우, set0가 아닌 다른 세트의 s2-tag 값을 읽어올 수 있다(S270). 이 때, 단계(S270)는 상기s2-tag의 다음번째 캐시라인 세트(set 1/2/3...)들 중 일치하는 캐시라인 세트의 값이 존재하는지 확인할 수 있다. 이 때, 단계(S260)는 granularity 값과 s2-tag의 LSB 값이 모두'zero'가 인 경우, s2-tag 값을 확인할 수 있다 (S280). 이 때, 단계(S280)는 s2-tag가 접근 요청 주소의 s2-tag 값과 일치하는 지 확인할 수 있다. 이 때, 단계(S280)는 s2-tag가 접근 요청 주소의 s2-tag 값과 일치하는 경우, 캐시 히트를 확인하여 데이터 메 모리로부터 데이터를 읽어오고(S210), s2-tag가 접근 요청 주소의 s2-tag 값과 일치하지 않는 경우, 캐시 미스 를 처리할 수 있다(S290). 이처럼, 본 발명의 일실시예에 따른 캐시 메모리 관리 장치 및 방법은 두 단계(s1-tag, s2-tag)의 캐시 태그 구 성에 따라 캐시라인을 가변적으로 사용하여 다양한 연산에 대한 대응력을 높이고 이에 따라 캐시 미스율을 낮출 수 있다. 또한, 데이터의 희소성(sparsity)까지 고려하여 캐시 접근을 위한 전력 효율까지 향상시킬 수 있다. 도 10은 본 발명의 일실시예에 따른 컴퓨터 시스템을 나타낸 도면이다. 도 10을 참조하면, 본 발명의 일실시예에 따른 캐시 메모리 관리 장치는 컴퓨터로 읽을 수 있는 기록매체 와 같은 컴퓨터 시스템에서 구현될 수 있다. 도 10에 도시된 바와 같이, 컴퓨터 시스템은 버스 를 통하여 서로 통신하는 하나 이상의 프로세서, 메모리, 사용자 인터페이스 입력 장치 , 사용자 인터페이스 출력 장치 및 스토리지를 포함할 수 있다. 또한, 컴퓨터 시스템 은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있다. 프로세서는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로세싱 인스트럭션들을 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 다양한 형태의 휘발성 또는 비휘발성 저장 매체일 수 있다. 예를 들어, 메 모리는 ROM이나 RAM을 포함할 수 있다. 본 발명의 일실시예에 따른 캐시 메모리 관리 장치는 하나 이상의 프로세서; 및 상기 하나 이상의 프로세 서에 의해 실행되는 적어도 하나 이상의 프로그램을 저장하는 실행메모리를 포함하고, 상기 적어도 하나 이상의 프로그램은 캐시 메모리 접근 요청에 따라 데이터를 읽어오기 위한 접근 요청 주소를 수신하면 상 기 캐시 메모리의 1단계 태그와 2단계 태그를 읽어오고, 상기 접근 요청 주소가 상기 1단계 태그의 값과 상기 2 단계 태그의 값이 일치하는지 확인하고, 상기 접근 요청 주소가 상기 1단계 태그 및 상기 2단계 태그의 값이 모 두 일치하는 경우, 데이터 메모리로부터 상기 데이터를 읽어온다. 이 때, 상기 캐시 메모리는 복수개의 캐시라인들이 설정되고, 상기 복수개의 캐시라인들은 캐시라인 길이를 기 반으로 캐시라인 세트의 개수가 다르게 설정될 수 있다. 이 때, 상기 1단계 태그는 세트 인덱스로 상기 캐시 메모리의 각 캐시라인에 사용되는 태그이고, 상기 2단계 태 그는 상기 캐시 메모리의 각 캐시라인에서 기설정된 캐시라인의 세트마다 할당될 수 있다. 이 때, 상기 캐시라인 세트의 전체에 공통으로 사용되는 태그는 상기 1단계 태그의 메모리에 저장되고, 상기 캐 시라인 세트의 각각에 사용되는 태그는 상기 2단계 태그의 메모리에 저장될 수 있다. 이 때, 상기 2단계 태그의 메모리는 상태 정보에 기설정된 비트값을 이용하여 상기 캐시라인들 중 어느 캐시라 인이 0의 값을 갖는지 설정될 수 있다. 이 때, 상기 적어도 하나 이상의 프로그램은 상기 접근 요청 주소와 상기 1단계 태그의 값이 일치하지 않는 경 우, 상기 상태 정보의 기설정된 비트값을 확인할 수 있다. 이 때, 상기 적어도 하나 이상의 프로그램은 상기 상태 정보의 기설정된 비트값 및 상기 2단계 태그의 첫번째 캐시라인 세트의 값이 상기 접근 요청 주소와 일치하는지 확인할 수 있다. 이 때, 상기 적어도 하나 이상의 프로그램은 상기 상태 정보의 기설정된 비트값 및 상기 2단계 태그의 첫번째 캐시라인 세트의 값 중 어느 하나가 상기 접근 요청 주소와 일치하지 않는 경우, 상기 2단계 태그의 다음번째 캐시라인 세트들 중 일치하는 캐시라인 세트의 값이 존재하는지 확인할 수 있다. 이 때, 상기 적어도 하나 이상의 프로그램은 일치하는 캐시라인 세트의 값이 존재하지 않는 경우, 캐시 미스로 처리하고, 일치하는 캐시라인 세트의 값이 존재하는 경우, 상기 데이터 메모리에서 상기 데이터를 읽어올 수 있 다. 이상에서와 같이 본 발명의 일실시예에 따른 캐시 메모리 관리 장치 및 방법은 상기한 바와 같이 설명된 실시예 들의 구성과 방법이 한정되게 적용될 수 있는 것이 아니라, 상기 실시예들은 다양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또는 일부가 선택적으로 조합되어 구성될 수도 있다."}
{"patent_id": "10-2022-0071414", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 인공지능 프로세스를 위한 캐시 메모리 관리 장치를 나타낸 블록도이다. 도 2는 도 1에 도시된 스트리밍 멀티프로세서의 일 옐를 세부적으로 나타낸 블록도이다. 도 3은 도 2에 도시된 실행 유닛의 일 예를 세부적으로 나타낸 블록도이다. 도 4는 본 발명의 일실시예에 따른 캐시 주소 구조를 나타낸 도면이다. 도 5는 본 발명의 일실시예에 따른 캐시의 주소 구조을 나타낸 도면이다. 도 6은 본 발명의 일실시예에 따른 태그 메모리 구조를 나타낸 도면이다. 도 7은 본 발명의 일실시예에 따른 데이터 메모리 구조를 나타낸 도면이다.도 8은 본 발명의 일실시예에 따른 1단계 태그(s1-tag)의 구조를 나타낸 도면이다. 도 9는 본 발명의 일실시예에 따른 캐시 메모리 관리 방법을 나타낸 동작흐름도이다. 도 10은 본 발명의 일실시예에 따른 컴퓨터 시스템을 나타낸 도면이다."}
