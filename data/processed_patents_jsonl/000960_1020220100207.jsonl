{"patent_id": "10-2022-0100207", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0021631", "출원번호": "10-2022-0100207", "발명의 명칭": "디스플레이 장치 및 그 동작 방법", "출원인": "엘지전자 주식회사", "발명자": "이상석"}}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디스플레이 장치의 동작 방법에 있어서,음성 데이터를 수신하는 단계;상기 수신된 음성 데이터를 화자 단위로 분리하여 처리하는 단계; 및현재 재생 모드가 멀티-뷰 모드이면, 각 멀티-뷰 화면 영역상에 상기 화자 단위로 분리 처리된 각 음성 데이터에 따른 콘텐츠가 출력되도록 제어하는 단계를 포함하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 수신된 음성 데이터를 화자 단위로 분리하여 처리하는 단계는,화자 인식 특징 정보를 DB(Database)로부터 추출하는 단계;상기 수신 음성 데이터로부터 상기 추출된 화자 인식 특징 정보에 상응하는 부분에 대한 타임스탬프 정보를 추출하는 단계; 및상기 추출된 타임스탬프 정보에 기초하여 상기 음성 데이터가 화자 단위로 구분하여 분리하는 단계를 포함하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 수신된 음성 데이터를 화자 단위로 분리하여 처리하는 단계는,상기 추출된 타임스탬프 정보에 기초하여 화자 단위로 구분하여 분리된 상기 음성 데이터를 STT(Speech-to-Tex)처리하는 단계; 및상기 STT 처리된 화자 단위의 음성 데이터를 NLP(Natural Language Processing) 처리하는 단계를 더 포함하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제어하는 단계는,상기 화자 단위로 분리 처리된 각 음성 데이터에 상응하는 상기 각 멀티-뷰 화면 영역을 결정하여 맵핑하는 단계를 포함하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제어하는 단계는,상기 각 멀티-뷰 화면 영역에 현재 재생 중인 콘텐츠 정보를 추출하는 단계를 더 포함하는,공개특허 10-2024-0021631-3-디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제어하는 단계는,상기 추출된 각 멀티-뷰 화면 영역에서 현재 재생 중인 콘텐츠 정보와 해당 멀티-뷰 화면 영역에 맵핑된 음성데이터에 기초하여, 동시 출력 가능 여부를 판단하여 콘텐츠를 출력하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제어하는 단계는,상기 동시 출력 가능 여부 판단 결과, 상기 멀티-뷰 화면 영역에 맵핑된 음성 데이터에 따른 동작 명령이 동시출력 가능하면, 해당 화면 영역에서 현재 재생 중인 콘텐츠 화면의 일 영역에 상기 동작 명령에 따른 데이터를출력하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 제어하는 단계는,상기 동시 출력 가능 여부 판단 결과, 상기 멀티-뷰 화면 영역에 맵핑된 음성 데이터에 따른 동작 명령이 동시출력이 불가능하면, 해당 화면 영역에서 현재 재생 중인 콘텐츠를 대신하여 상기 동작 명령에 따른 데이터를 출력하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 화자 단위로 분리되어 처리된 각 음성 데이터에 따른 요청이 동시 처리 가능한 요청인지 판단하는 단계를더 포함하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 동시 처리 가능 요청 판단 결과, 만약 동시 처리 불가능 요청이면, 메인 화자를 결정하고 상기 화자 단위로 분리하여 처리된 음성 데이터 중 상기 결정된 메인 화자의 음성 데이터에 따른 요청만 활성화하는 단계를 더포함하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 각 멀티-뷰 화면 영역에서 현재 재생 중인 콘텐츠 정보를 추출하는 단계; 및상기 각 멀티-뷰 화면 영역의 콘텐츠 정보에 기초하여 상기 활성화된 메인 화자의 음성 데이터에 따른 요청을출력할 멀티-뷰 화면 영역을 결정하는 단계를 더 포함하는,공개특허 10-2024-0021631-4-디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 결정된 멀티-뷰 화면의 콘텐츠 정보에 기초하여 동시 출력 가능 여부를 판단하여 동시 출력 가능하면 상기메인 화자의 음성 데이터에 따른 요청에 상응하는 데이터를 해당 멀티-뷰 화면의 콘텐츠 상의 일 영역에 출력하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 화자 단위로 분리되어 처리된 음성 데이터를 서버로 업로드하는 단계; 및상기 업로드 된 화자 단위로 분리되어 처리된 음성 데이터에 대해 STT 및 NLP 처리에 따라 생성된 NLP 응답을상기 서버로부터 다운로드 받는 단계를 더 포함하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "서버에서, 디스플레이 장치의 동작을 제어하는 방법에 있어서,상기 수신된 음성 데이터로부터 화자 단위로 분리된 음성 데이터를 수신하는 단계;상기 수신된 화자 단위의 각 음성 데이터를 각각 STT 처리하는 단계;상기 각 STT 처리된 텍스트 데이터를 NLP 처리하는 단계;상기 NLP 처리된 각 데이터에 대한 콘텐츠 정보를 생성하는 단계; 및상기 디스플레이 장치의 현재 재생 모드가 멀티-뷰 모드이면, 각 멀티-뷰 화면 영역상에 상기 생성된 NLP 처리에 따른 콘텐츠가 출력되도록 제어하는 단계를 포함하는,디스플레이 장치의 동작 방법."}
{"patent_id": "10-2022-0100207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "디스플레이 장치에 있어서,메모리; 및 상기 메모리와 통신하는 프로세서를 포함하되, 상기 프로세서는,입력되는 음성 데이터를 화자 단위로 분리하여 처리하고, 현재 재생 모드가 멀티-뷰 모드이면, 각 멀티-뷰 화면영역상에 상기 화자 단위로 분리 처리된 각 음성 데이터에 따른 콘텐츠가 출력되도록 제어하는,디스플레이 장치."}
{"patent_id": "10-2022-0100207", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "디스플레이 장치 및 그 동작 방법이 개시된다. 여기서, 본 개시의 일실시예에 따른 디스플레이 장치의 동작 방법 은, 음성 데이터를 수신하는 단계; 상기 수신된 음성 데이터를 화자 단위로 분리하여 처리하는 단계; 및 현재 재 생 모드가 멀티-뷰 모드이면, 각 멀티-뷰 화면 영역상에 상기 화자 단위로 분리 처리된 각 음성 데이터에 따른 콘텐츠가 출력되도록 제어하는 단계를 포함한다."}
{"patent_id": "10-2022-0100207", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 디스플레이 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0100207", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래 디스플레이 장치에 대한 입력 인터페이스는 리모컨이 주로 이용되었다. 즉, 사용자가 리모컨 상에 구비된 다양한 입력 버튼을 눌러 기능을 요청하면, 디스플레이 장치는 상기 요청에 상응하는 동작을 수행하였다. 디지털 기술의 급격한 발전으로 콘텐츠가 점점 고사양, 고화질로 제작됨에 따라 디스플레이 장치도 그에 맞춰 발전해 가고 있어, 종래 리모컨에 구비된 버튼이나 리모컨을 통한 제스처 인식을 통해 디스플레이 장치를 사용 자가 원하는 대로 제어하기에는 불편함이 있었다. 이에 음성 인식을 통한 입력 기술이 디스플레이 장치에 채용되기에 이르렀다. 그러나, 종래 음성 인식 기술은 다양한 상황에서 사용자의 음성을 정확하게 인식하는데 어려움이 있었다. 특히, 음성 인식 사용시 예를 들어, 주변의 간섭 음원이 들어올 때 의도하지 않는 음원이 인식되면, 음성 인식 프로세스를 반복하여 재시도하는 문 제점이 있었다. 이러한 문제점을 해소하고자 간섭 음원을 제거하는 방식의 하나로, 입력 음원의 레벨 차이를 이용하여, 레벨 차 이가 많이 나는 경우 적은 레벨을 제거하는 방법이 이용되나, 여전히 한계가 있다."}
{"patent_id": "10-2022-0100207", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은, 복수의 화자가 발화하는 경우, 디스플레이 장치에서 화자를 구분하여 음성 인식 처리하는 것 이다. 본 개시의 다른 목적은, 상기의 경우에 구분된 화자 정보에 기초하여 음성 인식 처리를 통하여, 디스플레이 장 치에 대한 사용자의 의도에 부합하는 서비스 제공을 통해 이용 편의성과 제품 만족도를 높이는 것이다."}
{"patent_id": "10-2022-0100207", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일실시예에 따른 디스플레이 장치의 동작 방법은, 음성 데이터를 수신하는 단계; 상기 수신된 음성 데이터를 화자 단위로 분리하여 처리하는 단계; 및 현재 재생 모드가 멀티-뷰 모드이면, 각 멀티-뷰 화면 영역 상에 상기 화자 단위로 분리 처리된 각 음성 데이터에 따른 콘텐츠가 출력되도록 제어하는 단계를 포함한다. 본 개시의 일실시예에 따른 서버에서 디스플레이 장치의 동작을 제어하는 방법은, 상기 수신된 음성 데이터로부 터 화자 단위로 분리된 음성 데이터를 수신하는 단계; 상기 수신된 화자 단위의 각 음성 데이터를 각각 STT 처 리하는 단계; 상기 각 STT 처리된 텍스트 데이터를 NLP 처리하는 단계; 상기 NLP 처리된 각 데이터에 대한 콘텐 츠 정보를 생성하는 단계; 및 상기 디스플레이 장치의 현재 재생 모드가 멀티-뷰 모드이면, 각 멀티-뷰 화면 영 역상에 상기 생성된 NLP 처리에 따른 콘텐츠가 출력되도록 제어하는 단계를 포함한다. 본 개시의 일실시예에 따른 디스플레이 장치는, 메모리; 및 상기 메모리와 통신하는 프로세서를 포함하되, 상기 프로세서는, 입력되는 음성 데이터를 화자 단위로 분리하여 처리하고, 현재 재생 모드가 멀티-뷰 모드이면, 각 멀티-뷰 화면 영역상에 상기 화자 단위로 분리 처리된 각 음성 데이터에 따른 콘텐츠가 출력되도록 제어한다."}
{"patent_id": "10-2022-0100207", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시예들 중 적어도 하나의 실시예에 따르면, 복수의 화자로부터 입력되는 음성 데이터를 화 자 단위로 구분하여 처리할 수 있는 효과가 있다. 본 개시의 다양한 실시예들 중 적어도 하나의 실시예에 따르면, 상기 복수의 화자로부터 입력되는 음성 데이터 를 화자 단위로 구분하여 재생 모드를 포함하여 상황에 따라 적응적으로 처리할 수 있는 효과가 있다. 본 개시의 다양한 실시예들 중 적어도 하나의 실시예에 따르면, 상기 복수의 화자로부터 입력되는 음성 데이터 를 화자 단위로 구분함으로써 의도에 부합하는 동작을 수행하여 이용 만족도와 제품 만족도를 높일 수 있는 효 과가 있다."}
{"patent_id": "10-2022-0100207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시와 관련된 실시예에 대하여 도면을 참조하여 보다 상세하게 설명한다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 “모듈” 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 도 1은 본 개시의 일실시예에 따른 디스플레이 장치의 구성을 블록도로 도시한 것이다. 도 1을 참조하면, 디스플레이 장치는 방송 수신부, 외부장치 인터페이스부, 저장부, 사용 자입력 인터페이스부, 제어부, 무선 통신부, 음성 획득부, 디스플레이부, 오디오 출 력부, 및 전원공급부를 포함할 수 있다. 방송 수신부는 튜너, 복조부 및 네트워크 인터페이스부를 포함할 수 있다. 튜너는 채널 선국 명령에 따라 특정 방송 채널을 선국할 수 있다. 튜너는 선국된 특정 방송 채널에 대한 방송 신호를 수신할 수 있다. 복조부는 수신한 방송 신호를 비디오 신호, 오디오 신호, 방송 프로그램과 관련된 데이터 신호로 분리할 수 있고, 분리된 비디오 신호, 오디오 신호 및 데이터 신호를 출력이 가능한 형태로 복원할 수 있다. 네트워크 인터페이스부는 디스플레이 장치를 인터넷망을 포함하는 유/무선 네트워크와 연결하기 위한 인터페이스를 제공할 수 있다. 네트워크 인터페이스부는 접속된 네트워크 또는 접속된 네트워크에 링크된 다른 네트워크를 통해, 다른 사용자 또는 다른 전자 기기와 데이터를 송신 또는 수신할 수 있다. 네트워크 인터페이스부는 접속된 네트워크 또는 접속된 네트워크에 링크된 다른 네트워크를 통해, 소정 웹 페이지에 접속할 수 있다. 즉, 네트워크를 통해 소정 웹 페이지에 접속하여, 해당 서버와 데이터를 송신 또는 수신할 수 있다. 그리고, 네트워크 인터페이스부는 콘텐츠 제공자 또는 네트워크 운영자가 제공하는 콘텐츠 또는 데이터들 을 수신할 수 있다. 즉, 네트워크 인터페이스부는 네트워크를 통하여 콘텐츠 제공자 또는 네트워크 제공자 로부터 제공되는 영화, 광고, 게임, VOD(Video on Demand), 방송 신호 등의 콘텐츠 및 그와 관련된 정보를 수신 할 수 있다. 또한, 네트워크 인터페이스부는 네트워크 운영자가 제공하는 펌웨어의 업데이트 정보 및 업데이트 파일을 수신할 수 있으며, 인터넷 또는 콘텐츠 제공자 또는 네트워크 운영자에게 데이터들을 송신할 수 있다. 네트워크 인터페이스부는 네트워크를 통해, 공중에 공개(open)된 애플리케이션들 중 원하는 애플리케이션 을 선택하여 수신할 수 있다. 외부장치 인터페이스부는 인접하는 외부장치 내의 애플리케이션 또는 애플리케이션 목록을 수신하여, 제어 부 또는 저장부로 전달할 수 있다. 외부장치 인터페이스부는 디스플레이 장치와 외부 장치 간의 연결 경로를 제공할 수 있다. 외부장치 인터페이스부는 디스플레이 장치에 무선 또는 유선으로 연결된 외부장치로부터 출력된 영상, 오디오 중 하나 이상을 수신하여, 제어부로 전달할 수 있다. 외부장치 인터페이스부는 복수의 외부 입력 단 자들을 포함할 수 있다. 복수의 외부 입력 단자들은 RGB 단자, 하나 이상의 HDMI(High Definition Multimedia Interface) 단자, 컴포넌트(Component) 단자를 포함할 수 있다. 외부장치 인터페이스부를 통해 입력된 외부장치의 영상 신호는 디스플레이부를 통해 출력될 수 있다. 외부장치 인터페이스부를 통해 입력된 외부장치의 음성 신호는 오디오 출력부를 통해 출력될 수 있다.외부장치 인터페이스부에 연결 가능한 외부 장치는 셋톱 박스, 블루레이 플레이어, DVD 플레이어, 게임기, 사운드 바, 스마트폰, PC, USB 메모리, 홈 씨어터 중 어느 하나일 수 있으나, 이는 예시에 불과하다. 또한, 디스플레이 장치에 미리 등록된 다른 사용자 또는 다른 전자 기기 중 선택된 사용자 또는 선택된 전 자기기에, 디스플레이 장치에 저장된 일부의 콘텐츠 데이터를 송신할 수 있다. 저장부는 제어부 내의 각 신호 처리 및 제어를 위한 프로그램을 저장하고, 신호 처리된 영상, 음성 또는 데이터신호를 저장할 수 있다. 또한, 저장부는 외부장치 인터페이스부 또는 네트워크 인터페이스부로부터 입력되는 영상, 음성, 또는 데이터 신호의 임시 저장을 위한 기능을 수행할 수도 있으며, 채널 기억 기능을 통하여 소정 이미지 에 관한 정보를 저장할 수도 있다. 저장부는 외부장치 인터페이스부 또는 네트워크 인터페이스부로부터 입력되는 애플리케이션 또 는 애플리케이션 목록을 저장할 수 있다. 디스플레이 장치는 저장부 내에 저장되어 있는 콘텐츠 파일(동영상 파일, 정지영상 파일, 음악 파일, 문서 파일, 애플리케이션 파일 등)을 재생하여 사용자에게 제공할 수 있다. 사용자 입력 인터페이스부는 사용자가 입력한 신호를 제어부로 전달하거나, 제어부로부터의 신 호를 사용자에게 전달할 수 있다. 예를 들어, 사용자 입력 인터페이스부는 블루투스(Bluetooth), UWB(Ultra Wideband), 지그비(ZigBee) 방식, RF(Radio Frequency) 통신 방식 또는 적외선(IR) 통신 방식 등 다 양한 통신 방식에 따라, 원격제어장치로부터 전원 온/오프, 채널 선택, 화면 설정 등의 제어 신호를 수신 하여 처리하거나, 제어부로부터의 제어 신호를 원격제어장치로 송신하도록 처리할 수 있다. 또한, 사용자 입력 인터페이스부는, 전원키, 채널키, 볼륨키, 설정치 등의 로컬키(미도시)에서 입력되는 제어 신호를 제어부에 전달할 수 있다. 제어부에서 영상 처리된 영상 신호는 디스플레이부로 입력되어 해당 영상 신호에 대응하는 영상으로 표시될 수 있다. 또한, 제어부에서 영상 처리된 영상 신호는 외부장치 인터페이스부를 통하여 외부 출력장치로 입력될 수 있다. 제어부에서 처리된 음성 신호는 오디오 출력부로 오디오 출력될 수 있다. 또한, 제어부에서 처 리된 음성 신호는 외부장치 인터페이스부를 통하여 외부 출력장치로 입력될 수 있다. 그 외, 제어부는, 디스플레이 장치 내의 전반적인 동작을 제어할 수 있다. 또한, 제어부는 사용자 입력 인터페이스부를 통하여 입력된 사용자 명령 또는 내부 프로그램에 의하 여 디스플레이 장치를 제어할 수 있으며, 네트워크에 접속하여 사용자가 원하는 애플리케이션 또는 애플리 케이션 목록을 디스플레이 장치 내로 다운받을 수 있도록 할 수 있다. 제어부는 사용자가 선택한 채널 정보 등이 처리한 영상 또는 음성 신호와 함께 디스플레이부 또는 오 디오 출력부를 통하여 출력될 수 있도록 한다. 또한, 제어부는 사용자 입력 인터페이스부를 통하여 수신한 외부장치 영상 재생 명령에 따라, 외부장 치 인터페이스부를 통하여 입력되는 외부 장치, 예를 들어, 카메라 또는 캠코더로부터의, 영상 신호 또는 음성 신호가 디스플레이부 또는 오디오 출력부를 통해 출력될 수 있도록 한다. 한편, 제어부는 영상을 표시하도록 디스플레이부를 제어할 수 있으며, 예를 들어 튜너를 통해 입력되는 방송 영상, 또는 외부장치 인터페이스부를 통해 입력되는 외부 입력 영상, 또는 네트워크 인터페 이스부를 통해 입력되는 영상, 또는 저장부에 저장된 영상이 디스플레이부에서 표시되도록 제어할 수 있다. 이 경우, 디스플레이부에 표시되는 영상은 정지 영상 또는 동영상일 수 있으며, 2D 영상 또는 3D 영 상일 수 있다. 또한, 제어부는 디스플레이 장치 내에 저장된 콘텐츠, 또는 수신된 방송 콘텐츠, 외부로부터 입력되 는 외부 입력 콘텐츠가 재생되도록 제어할 수 있으며, 콘텐츠는 방송 영상, 외부 입력 영상, 오디오 파일, 정지 영상, 접속된 웹 화면, 및 문서 파일 등 다양한 형태일 수 있다. 무선 통신부는 유선 또는 무선 통신을 통해 외부 기기와 통신을 수행할 수 있다. 무선 통신부는 외부 기기와 근거리 통신(Short range communication)을 수행할 수 있다. 이를 위해, 무선 통신부는 블루투스(Bluetooth™), BLE(Bluetooth Low Energy), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless- Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 근 거리 통신을 지원할 수 있다. 이러한, 무선 통신부는 근거리 무선 통신망(Wireless Area Networks)을 통해 디스플레이 장치와 무선 통신 시스템 사이, 디스플레이 장치와 다른 디스플레이 장치 사이, 또 는 디스플레이 장치와 디스플레이 장치(100, 또는 외부서버)가 위치한 네트워크 사이의 무선 통신을 지원 할 수 있다. 근거리 무선 통신망은 근거리 무선 개인 통신망(Wireless Personal Area Networks)일 수 있다. 여기에서, 다른 디스플레이 장치는 본 개시에 따른 디스플레이 장치와 데이터를 상호 교환하는 것이 가능한(또는 연동 가능한) 웨어러블 디바이스(wearable device, 예를 들어, 스마트워치(smart watch), 스마트 글래스(smart glass), HMD(head mounted display), 스마트 폰과 같은 이동 단말기가 될 수 있다. 무선 통신부 는 디스플레이 장치 주변에, 통신 가능한 웨어러블 디바이스를 감지(또는 인식)할 수 있다. 나아가, 제어부는 감지된 웨어러블 디바이스가 본 개시에 따른 디스플레이 장치와 통신하도록 인증된 (authenticated) 디바이스인 경우, 디스플레이 장치에서 처리되는 데이터의 적어도 일부를, 무선 통신부 를 통해 웨어러블 디바이스로 송신할 수 있다. 따라서, 웨어러블 디바이스의 사용자는, 디스플레이 장치 에서 처리되는 데이터를, 웨어러블 디바이스를 통해 이용할 수 있다. 음성 획득부는 오디오를 획득할 수 있다. 음성 획득부는 적어도 하나의 마이크(미도시)를 포함할 수 있고, 마이크(미도시)를 통해 디스플레이 장치 주변의 오디오를 획득할 수 있다. 디스플레이부는 제어부에서 처리된 영상 신호, 데이터 신호, OSD 신호 또는 외부장치 인터페이스부 에서 수신되는 영상 신호, 데이터 신호 등을 각각 R, G, B 신호로 변환하여 구동 신호를 생성할 수 있다. 한편, 도 1에 도시된 디스플레이 장치는 본 개시의 일실시예에 불과하므로. 도시된 구성요소들 중 일부는 실제 구현되는 디스플레이 장치의 사양에 따라 통합, 추가, 또는 생략될 수 있다. 즉, 필요에 따라 2 이상의 구성요소가 하나의 구성요소로 합쳐지거나, 혹은 하나의 구성요소가 2 이상의 구성요 소로 세분되어 구성될 수 있다. 또한, 각 블록에서 수행하는 기능은 본 개시의 실시예를 설명하기 위한 것이며, 그 구체적인 동작이나 장치는 본 개시의 권리범위를 제한하지 아니한다. 본 개시의 또 다른 실시예에 따르면, 디스플레이 장치는 도 1에 도시된 바와 달리, 튜너와 복조부 를 구비하지 않고 네트워크 인터페이스부 또는 외부장치 인터페이스부를 통해서 영상을 수신하 여 재생할 수도 있다. 예를 들어, 디스플레이 장치는 방송 신호 또는 다양한 네트워크 서비스에 따른 콘텐츠들을 수신하기 위한 등과 같은 셋톱박스 등과 같은 영상 처리 장치와 영상 처리 장치로부터 입력되는 콘텐츠를 재생하는 콘텐츠 재 생 장치로 분리되어 구현될 수 있다. 이 경우, 이하에서 설명할 본 개시의 실시예에 따른 디스플레이 장치의 동작 방법은 도 1을 참조하여 설명한 바 와 같은 디스플레이 장치뿐 아니라, 분리된 셋톱박스 등과 같은 영상 처리 장치 또는 디스플레이부 및 오디오 출력부를 구비하는 콘텐츠 재생 장치 중 어느 하나에 의해 수행될 수도 있다. 오디오 출력부는, 제어부에서 음성 처리된 신호를 입력 받아 음성으로 출력한다. 전원 공급부는, 디스플레이 장치 전반에 걸쳐 해당 전원을 공급한다. 특히, 시스템 온 칩(System On Chip, SOC)의 형태로 구현될 수 있는 제어부와, 영상 표시를 위한 디스플레이부, 오디오 출력을 위한 오디오 출력부 등에 전원을 공급할 수 있다. 구체적으로, 전원 공급부는, 교류 전원을 직류 전원으로 변환하는 컨버터와, 직류 전원의 레벨을 변환하는 dc/dc 컨버터를 구비할 수 있다. 다음으로, 도 2 내지 도 3을 참조하여, 본 개시의 일실시예에 따른 원격제어장치에 대해 설명한다. 도 2는 본 개시의 일실시예에 따른 원격제어장치의 블록도이고, 도 3은 본개시의 일실시예에 따른 원격제어장치 의 실제 구성 예를 보여준다. 먼저, 도 2를 참조하면, 원격제어장치는 지문인식부, 무선통신부, 사용자 입력부, 센서부 , 출력부, 전원공급부, 저장부, 제어부, 음성 획득부를 포함할 수 있다.도 2를 참조하면, 무선통신부는 전술하여 설명한 본 개시의 실시예들에 따른 디스플레이 장치 중 임의의 어느 하나와 신호를 송수신한다. 원격제어장치는 RF 통신규격에 따라 디스플레이 장치와 신호를 송수신할 수 있는 RF 모듈을 구 비하며, IR 통신규격에 따라 디스플레이 장치와 신호를 송수신할 수 있는 IR 모듈을 구비할 수 있다. 또한, 원격제어장치는 블루투스 통신규격에 따라 디스플레이 장치와 신호를 송수신할 수 있는 블루투 스 모듈를 구비할 수 있다. 또한, 원격제어장치는 NFC(Near Field Communication) 통신 규격에 따라 디스플레이 장치와 신호를 송수할 수 있는 NFC 모듈을 구비하며, WLAN(Wireless LAN) 통신 규격에 따 라 디스플레이 장치와 신호를 송수신할 수 있는 WLAN 모듈을 구비할 수 있다. 또한, 원격제어장치는 디스플레이 장치로 원격제어장치의 움직임 등에 관한 정보가 담긴 신호를 무선 통신부를 통해 전송한다. 한편, 원격제어장치는 디스플레이 장치가 전송한 신호를 RF 모듈을 통하여 수신할 수 있으며, 필요에 따라 IR 모듈을 통하여 디스플레이 장치로 전원 온/오프, 채널 변경, 볼륨 변경 등에 관한 명 령을 전송할 수 있다. 사용자 입력부는 키패드, 버튼, 터치 패드, 또는 터치 스크린 등으로 구성될 수 있다. 사용자는 사용자 입 력부를 조작하여 원격제어장치으로 디스플레이 장치와 관련된 명령을 입력할 수 있다. 사용자 입력부가 하드키 버튼을 구비할 경우 사용자는 하드키 버튼의 푸시 동작을 통하여 원격제어장치으로 디스플레이 장치와 관련된 명령을 입력할 수 있다. 이에 대해서는 도 3을 참조하여 설명한다. 도 3을 참조하면, 원격제어장치는 복수의 버튼을 포함할 수 있다. 복수의 버튼은 지문 인식 버튼, 전 원 버튼, 홈 버튼, 라이브 버튼, 외부 입력 버튼, 음량 조절 버튼, 음성 인식 버튼 , 채널 변경 버튼, 확인 버튼 및 뒤로 가기 버튼을 포함할 수 있다. 지문 인식 버튼은 사용자의 지문을 인식하기 위한 버튼일 수 있다. 일실시예로, 지문 인식 버튼은 푸 시 동작이 가능하여, 푸시 동작 및 지문 인식 동작을 수신할 수도 있다. 전원 버튼은 디스플레이 장치 의 전원을 온/오프 하기 위한 버튼일 수 있다. 홈 버튼은 디스플레이 장치의 홈 화면으로 이동 하기 위한 버튼일 수 있다. 라이브 버튼은 실시간 방송 프로그램을 디스플레이 하기 위한 버튼일 수 있다. 외부 입력 버튼은 디스플레이 장치에 연결된 외부 입력을 수신하기 위한 버튼일 수 있다. 음량 조절 버튼은 디스플레이 장치가 출력하는 음량의 크기를 조절하기 위한 버튼일 수 있다. 음성 인식 버튼 은 사용자의 음성을 수신하고, 수신된 음성을 인식하기 위한 버튼일 수 있다. 채널 변경 버튼은 특정 방송 채널의 방송 신호를 수신하기 위한 버튼일 수 있다. 확인 버튼은 특정 기능을 선택하기 위한 버튼일 수 있고, 뒤로 가기 버튼은 이전 화면으로 되돌아가기 위한 버튼일 수 있다. 다시 도 2를 설명한다. 사용자 입력부가 터치스크린을 구비할 경우 사용자는 터치스크린의 소프트 키를 터치하여 원격제어장치 로 디스플레이 장치와 관련된 명령을 입력할 수 있다. 또한, 사용자 입력부는 스크롤 키나, 조 그 키 등 사용자가 조작할 수 있는 다양한 종류의 입력수단을 구비할 수 있으며 본 실시예는 본 개시의 권리범 위를 제한하지 아니한다. 센서부는 자이로 센서 또는 가속도 센서를 구비할 수 있으며, 자이로 센서는 원격제어장치 의 움직임에 관한 정보를 센싱할 수 있다. 예를 들어, 자이로 센서는 원격제어장치의 동작에 관한 정보를 x, y, z 축을 기준으로 센싱할 수 있 으며, 가속도 센서는 원격제어장치의 이동속도 등에 관한 정보를 센싱할 수 있다. 한편, 원격제어장 치는 거리측정센서를 더 구비할 수 있어, 디스플레이 장치의 디스플레이부와의 거리를 센싱할 수 있다. 출력부는 사용자 입력부의 조작에 대응하거나 디스플레이 장치에서 전송한 신호에 대응하는 영 상 또는 음성 신호를 출력할 수 있다. 출력부를 통하여 사용자는 사용자 입력부의 조작 여부 또는 디 스플레이 장치의 제어 여부를 인지할 수 있다. 예를 들어, 출력부는 사용자 입력부가 조작되거나 무선 통신부를 통하여 디스플레이 장치 와 신호가 송수신되면 점등되는 LED 모듈, 진동을 발생하는 진동 모듈, 음향을 출력하는 음향 출력모듈, 또는 영상을 출력하는 디스플레이 모듈을 구비할 수 있다. 또한, 전원공급부는 원격제어장치로 전원을 공급하며, 원격제어장치가 소정 시간 동안 움직이지 않은 경우 전원 공급을 중단함으로써 전원 낭비를 줄일 수 있다. 전원공급부는 원격제어장치에 구비 된 소정 키가 조작된 경우에 전원 공급을 재개할 수 있다. 저장부는 원격제어장치의 제어 또는 동작에 필요한 여러 종류의 프로그램, 애플리케이션 데이터 등이 저장될 수 있다. 만일 원격제어장치가 디스플레이 장치와 RF 모듈을 통하여 무선으로 신호를 송 수신할 경우 원격제어장치와 디스플레이 장치는 소정 주파수 대역을 통하여 신호를 송수신한다. 원격제어장치의 제어부는 원격제어장치와 페어링 된 디스플레이 장치와 신호를 무선으로 송수신할 수 있는 주파수 대역 등에 관한 정보를 저장부에 저장하고 참조할 수 있다. 제어부는 원격제어장치의 제어에 관련된 제반사항을 제어한다. 제어부는 사용자 입력부의 소정 키 조작에 대응하는 신호 또는 센서부에서 센싱한 원격제어장치의 움직임에 대응하는 신호를 무 선 통신부를 통하여 디스플레이 장치로 전송할 수 있다. 또한, 원격제어장치의 음성 획득부는 음성을 획득할 수 있다. 음성 획득부는 적어도 하나 이상의 마이크을 포함할 수 있고, 마이크를 통해 음성을 획득할 수 있다. 다음으로 도 4를 설명한다. 도 4는 본 개시의 실시예에 따라 원격제어장치를 활용하는 예를 보여준다. 도 4의 (a)는 원격제어장치에 대응하는 포인터가 디스플레이부에 표시되는 것을 예시한다. 사용자는 원격제어장치를 상하, 좌우로 움직이거나 회전할 수 있다. 디스플레이 장치의 디스플레이부 에 표시된 포인터는 원격제어장치의 움직임에 대응한다. 이러한 원격제어장치는, 도면과 같이, 3D 공간 상의 움직임에 따라 해당 포인터가 이동되어 표시되므로, 공간 리모컨이라 명명할 수 있다. 도 4의 (b)는 사용자가 원격제어장치를 왼쪽으로 이동하면, 디스플레이 장치의 디스플레이부에 표시된 포인터도 이에 대응하여 왼쪽으로 이동하는 것을 예시한다. 원격제어장치의 센서를 통하여 감지된 원격제어장치의 움직임에 관한 정보는 디스플레이 장치로 전송된다. 디스플레이 장치는 원격제어장치의 움직임에 관한 정보로부터 포인터의 좌표를 산출 할 수 있다. 디스플레이 장치는 산출한 좌표에 대응하도록 포인터를 표시할 수 있다. 도 4의 (c)는, 원격제어장치 내의 특정 버튼을 누른 상태에서, 사용자가 원격제어장치를 디스플레이 부에서 멀어지도록 이동하는 경우를 예시한다. 이에 의해, 포인터에 대응하는 디스플레이부 내 의 선택 영역이 줌인되어 확대 표시될 수 있다. 이와 반대로, 사용자가 원격제어장치를 디스플레이부에 가까워지도록 이동하는 경우, 포인터에 대응하는 디스플레이부 내의 선택 영역이 줌아웃되어 축소 표시될 수 있다. 한편, 원격제어장치가 디스플레이부에서 멀어지는 경우, 선택 영역이 줌아웃되고, 원격제어장치(20 0)가 디스플레이부에 가까워지는 경우, 선택 영역이 줌인될 수도 있다. 또한, 원격제어장치 내의 특정 버튼을 누른 상태에서는 상하, 좌우 이동의 인식이 배제될 수 있다. 즉, 원 격제어장치가 디스플레이부에서 멀어지거나 접근하도록 이동하는 경우, 상, 하, 좌, 우 이동은 인식 되지 않고, 앞뒤 이동만 인식되도록 할 수 있다. 원격제어장치 내의 특정 버튼을 누르지 않은 상태에서는, 원격제어장치의 상, 하, 좌, 우 이동에 따라 포인터만 이동하게 된다. 한편, 포인터의 이동속도나 이동방향은 원격제어장치의 이동속도나 이동방향에 대응할 수 있다. 한편, 본 명세서에서의 포인터는, 원격제어장치의 동작에 대응하여, 디스플레이부에 표시되는 오브젝 트를 의미한다. 따라서, 포인터로 도면에 도시된 화살표 형상 외에 다양한 형상의 오브젝트가 가능하다. 예를 들어, 점, 커서, 프롬프트, 두꺼운 외곽선 등을 포함하는 개념일 수 있다. 그리고, 포인터가 디스플 레이부 상의 가로축과 세로축 중 어느 한 지점(point)에 대응하여 표시되는 것은 물론, 선(line), 면 (surface) 등 복수 지점에 대응하여 표시되는 것도 가능하다.도 5a 및 도 5b는 본 개시의 실시예에 따른 스탠드 타입의 디스플레이 장치의 가로 모드 및 세로 모드를 설명하 기 위한 도면이다. 도 5a 및 도 5b를 참조하면, 스탠드 타입의 디스플레이 장치가 도시되어 있다. 디스플레이 장치에는 샤프트 및 스탠드 베이스가 연결될 수 있다. 샤프트는 디스플레이 장치 및 스탠드 베이스를 이어줄 수 있다. 샤프트는 수직하게 연장될 수 있다. 샤프트의 하단은 스탠드 베이스의 가장자리부에 연결될 수 있다. 샤프트의 하단은 스탠드 베이스의 둘레부에 회전 가능하게 연결될 수 있다. 디스플레이 장치 및 샤프트는 스탠드 베이스에 대해 수직축(vertical axis)을 중심으로 회전할 수 있다. 샤프트의 상부는 디스플레이 장치의 후면에 연결될 수 있다. 스탠드 베이스는 디스플레이 장치를 지지하는 역할을 할 수 있다. 디스플레이 장치는 샤프트 및 스탠드 베이스를 포함하도록 구성될 수 있다. 디스플레이 장치는 샤프트의 상부와 디스플레이의 후면이 맞닿은 지점을 중심으로 회전할 수 있 다. 도 5의 (a)는 디스플레이의 가로 길이가 세로 길이보다 큰 자세를 갖는 가로 모드로 동작함을 나타내고, 도 5의 (b)는 디스플레이의 세로 길이가 가로 길이보다 큰 자세를 갖는 가로 모드로 동작함을 나타낼 수 있다. 사용자는 스탠드 타입의 디스플레이 장치를 이동시킬 수 있다. 즉, 스탠드 타입의 디스플레이 장치는 고정된 기기와는 달리 이동성이 향상되어 사용자는 배치 위치에 구애받지 않는다. 다음으로, 디스플레이 장치에서 음성 신호를 처리하는 다양한 실시예들을 설명한다. 이하에서, “음성 신호”라 함은, 디스플레이 장치로 어떤 요청을 하는 화자(사용자)의 음성 데이터가 포 함된 신호를 나타낼 수 있다. 본 개시에서는 특히 상기 음성 신호에 적어도 둘 이상의 화자들(예를 들어, 설명의 편의상 ‘멀티-화자(multi- speaker)’라 함)의 각 음성 데이터가 포함된 경우를 예로 하여 설명하나, 이에 한정되는 것은 아니다. 상기 디스플레이 장치는 각 멀티-화자로부터 요청 즉, 음성 데이터가 동시에 수신되거나 미리 정한 소정 시간 범위 내의 짧은 시간 내에 수신되는 경우에는 이를 하나의 음성 신호로 처리할 수 있다. 상기에서, 소정 시간 범위라 함은 예를 들어, 선 입력된 음성 데이터의 수신 시점에서부터 상기 선 입력 음성 데이터의 처리가 디스플레이 장치에서 아직 이루어지지 않은 시점까지를 나타낼 수 있다. 실시예에 따라서, 상기 음성 신호 는 멀티-화자가 아닌 싱글 화자로부터 적어도 두 개의 다른 요청을 위한 각 음성 데이터가 포함된 경우도 포함 할 수 있다. 한편, 상기 음성 데이터에는 콘텐츠나 어플리케이션에 관한 요청, 검색이나 정보의 제공에 대한 요 청 등 다양한 요청이 포함될 수 있다. 본 개시에 따른 디스플레이 장치는 멀티-화자의 음성 데이터가 포함된 음성 신호가 입력되면, 상기 음성 신호로부터 각 멀티-화자를 구분하고, 구분된 각 멀티-화자의 음성 데이터를 식별하여, 디스플레이 장치의 현재 동작 상태와 상기 식별된 화자 또는 음성 데이터에 기초하여 동작할 수 있다. 도 6은 본 개시의 다른 일실시예에 따른 디스플레이 장치의 구성을 블록도로 도시한 것이다. 도 7은 본 개시의 일실시예에 따른 멀티-화자의 음성 데이터 처리 과정을 설명하기 위해 도시한 도면이다. 본 개시의 일실시예에 따른 디스플레이 장치는 메모리와 상기 메모리와 통신하는 프로세서를 포함할 수 있다. 프로세서는 입력되는 음성 데이터를 화자 단위로 분리하여 처리하고, 디스플레이 장치의 현재 재생 모드에 따라 다르게 처리할 수 있다. 예를 들어, 상기 프로세서는 디스플레이 장치의 현재 재생 모드 가 멀티-뷰 모드(multi-view mode)이면, 각 멀티-뷰 화면 영역 상에 상기 분리된 각 멀티-화자의 음성 데이터에따른 콘텐츠가 각각 출력되도록 제어할 수 있다. 한편, 프로세서는 내장 또는 외장된 DB 즉, 제1 DB와 제2 DB와 통신하여 데이터를 수집, 기록/ 저장, 추출/독출 등 데이터 커뮤니케이션을 수행할 수 있다. 도 6을 참조하면, 프로세서는 통신부, 데이터수신부, 화자인식/처리부, 동시처리판단부 , 멀티-액션 처리부, 화자데이터처리부 및 제어부를 포함하여 구성될 수 있다. 실시예에 따라, 상기 프로세서는 도 6에 도시된 구성요소 외에 하나 또는 그 이상의 다른 구성요소를 더 포함하여 구성되거나 반대일 수 있다. 다른 실시예에 따르면, 도 6에 도시된 상기 프로세서의 구성요소들 중 일부는 다른 구성요소(들)과 모듈 형태로 구현될 수도 있고, 반대일 수도 있다. 예를 들어, 화자인식/처리부, 동 시처리판단부, 멀티-액션 처리부, 및 화자데이터처리부 중 적어도 둘 이상이 모듈화되어 개별 존재하거나 제어부에 포함될 수 있다. 통신부는 디스플레이 장치의 타 구성요소 또는 외부 장치(서버 포함)와의 통신 인터페이스 환경을 지 원한다. 데이터수신부는 상기 통신부를 통해 타 구성요소 또는 외부 장치로부터 데이터를 수신할 수 있다. 이 때, 수신되는 데이터에는 멀티-화자의 음성 데이터가 포함된 음성 신호가 포함될 수 있다. 화자인식/처리부는 상기 데이터수신부를 통해 수신된 음성 신호 내 멀티-화자를 인식하고, 인식된 멀 티-화자 내 각 화자를 식별하고, 식별된 각 화자의 음성 데이터를 상기 음성 신호로부터 분리하여 예를 들어, 도 7에 도시된 바와 같이 처리할 수 있다. 실시예에 따라서, 상기 화자 인식 및 처리 과정의 적어도 일부는 외 부 장치 예를 들어, 서버에서 수행될 수 있다. 도 7을 참조하면, “날씨 보여줘”(화자 A에 의한 제1 음성 데이터)와 “유튜브 실행해줘”(화자 B에 의한 제2 음성 데이터)가 포함된 음성 신호가 수신되면, 디스플레이 장치(또는 서버)는 각 멀티-화자를 인식하고, 인식된 각 화자의 음성 데이터를 구분하여 처리할 수 있다. 도 7을 참조하면, 디스플레이 장치의 프로세서 내 화자인식/처리부는 화자 인식 특징 추출 모듈, 타 임스탬프 추출 모듈, 음성 데이터 분리 모듈, 제1 STT 처리 모듈 및 제2 STT 처리 모듈 를 포함하여 구성될 수 있다. 실시예에 따라서, 상기 화자인식/처리부는 도 7에 도시된 구성과 다르게 하 나 또는 그 이상의 구성요소들을 더 포함하여 구성되거나 반대일 수 있다. 또한, 상기 화자인식/처리부를 구성하는 화자 인식 특징 추출 모듈, 타임스탬프 추출 모듈, 음성 데이터 분리 모듈, 제1 STT 처리 모듈 및 제2 STT 처리 모듈 중 적어도 둘 이상이 하나의 모듈로 구현되거나 반대일 수도 있다. 화자 인식 특징 추출 모듈은 화자 인식 특징 DB로부터 화자 인식을 위한 특징을 추출할 수 있다. 이 때, 상기 화자 인식 특징 DB는 디스플레이 장치 또는 화자인식/처리부 내에 포함될 수도 있으나, 도 7에 도시된 바와 달리, 원격에 위치할 수도 있다. 예를 들어, 원격(예를 들어, 서버단)에 위치한 화 자 인식 특징 DB는 화자인식/처리부의 요청에 따라 관련 (화자) 데이터를 제공할 수 있다. 타임스탬프 추출 모듈은 상기 추출한 화자 인식 특징에 상응하는 음성 데이터 구간(예를 들어, 시작 구간 및 종료 구간)에 대한 타임스탬프(timestamp) 정보를 추출할 수 있다. 음성 데이터 분리 모듈은 상기 타임스탬프 정보에 기초하여 각 화자의 음성 데이터 예를 들어, 화자 A의 제1 음성 데이터(“날씨 보여줘”)와 화자 B의 제2 음성 데이터(“유튜브 실행해줘”)를 분리할 수 있다. STT(Speech to Text) 처리부에서는 상기 분리된 음성 데이터를 STT 처리할 수 있다. 도 7을 참조하면, 제1 STT 처리 모듈은 분리된 화자 A의 제1 음성 데이터를 STT 처리하고, 제2 STT 처리 모듈은 분리된 화자 B의 제2 음성 데이터를 STT 처리할 수 있다. 이렇게 분리 처리된 각 화자의 음성 데이터는 NLP(Natural Language Processing) 처리 모듈에서 NLP 처리 될 수 있다. 상기 STT 처리부와 NLP 처리 모듈 중 적어도 하나는 디스플레이 장치 또는 서버단에 포함될 수 있다. 한편, 상기 STT 및 NLP 프로세스 내지 알고리즘에 대해 공지기술을 참조하며, 본 명세서에서 별도 상세 설명은 생략한다. 동시 처리 판단부는 각 멀티-화자의 음성 데이터가 디스플레이 장치상에서 동시 처리 가능한지 여부 를 판단할 수 있다. 상기 동시 처리 판단부는 디스플레이 장치의 재생 모드가 멀티-뷰 모드(Multi- view mode)가 아니라 싱글-뷰 모드(Single-view mode)인 경우에 기능을 수행할 수 있으나, 이에 한정되는 것은 아니다. 실시예에 따라서, 동시 처리 판단부는 각 멀티-화자의 음성 데이터가 현재 재생 중인 콘텐츠와의 관계를 고려할 때, 동시 출력 가능한지 여부를 판단할 수도 있다. 이 때, 상기 동시 처리 판단부는 디스플레이 장 치의 재생 모드가 싱글-뷰 모드(Single-view mode)가 아니라 멀티-뷰 모드(Multi-view mode)인 경우에도 동시 출력 가능 여부 판단 기능을 수행할 수 있다. 즉, 동시 처리 판단부는 각 멀티-뷰 화면 영역에 대해 해당 영역에서 현재 출력 중인 콘텐츠와 상기 각 멀티-화자의 음성 데이터에 따른 요청(명령)에 따른 콘텐츠가 동시에 출력 가능한지 아니면 대체하여야 하는지 등을 판단할 수 있다. 멀티-액션 처리부는 각 멀티-화자의 음성 데이터에 따른 명령을 디스플레이 장치상에서 함께 처리되 도록 멀티-액션 처리할 수 있다. 화자 데이터 처리부는 각 멀티-화자의 음성 데이터에 따른 실제 데이터를 처리할 수 있다. 제어부는 프로세서의 전반적인 동작을 제어하며 특히, 멀티-화자의 음성 데이터가 포함된 음성 신호 처리에 대한 다양한 상황에 따른 제어 동작을 수행할 수 있다. 제1 DB와 제2 DB는 상기 프로세서와 데이터 커뮤니케이션을 통해 데이터의 기록/저장, 추출/독 출 등을 수행할 수 있다. 상기 제1 DB와 제2 DB 중 어느 하나는 도 7의 화자 인식 특징 DB에 상 응하거나 그를 포함할 수 있다. 도 8 내지 14는 본 개시의 실시예에 따른 멀티-화자 데이터가 포함된 음성 신호의 처리 방법을 설명하기 위해 도시한 도면이다. 이하에서는, 설명의 편의상 화자가 2명인 멀티-화자 케이스를 예로 하여 설명하나, 이에 한정되는 것은 아니다. 본 명세서에서 ‘콘텐츠’라 함은 특별히 명시하지 않는한, 방송 프로그램, 어플리케이션, 외부 입력 등 디스플 레이에서 재생 가능한 모든 형태를 포함할 수 있다. 본 개시의 일실시예에 따르면, 디스플레이 장치는 음성 데이터를 수신하여 상기 수신된 음성 데이터를 화 자 단위로 분리하여 처리하고, 현재 재생 모드가 멀티-뷰 모드이면, 각 멀티-뷰 화면 영역상에 상기 화자 단위 로 분리 처리된 각 음성 데이터에 따른 콘텐츠가 출력되도록 제어할 수 있다. 디스플레이 장치는 화자 인식 특징 정보를 DB로부터 추출하되, 상기 수신 음성 데이터로부터 상기 추출된 화자 인식 특징 정보에 상응하는 부분에 대한 타임스탬프 정보를 추출하고, 상기 추출된 타임스탬프 정보에 기 초하여 상기 음성 데이터를 화자 단위로 구분하여 분리하는 단계를 포함하여, 상기 수신된 음성 데이터를 화자 단위로 분리하여 처리할 수 있다. 디스플레이 장치는 추출된 타임스탬프 정보에 기초하여 화자 단위로 분리된 음성 데이터를 STT 처리하고, 상기 STT 처리된 화자 단위의 음성 데이터를 NLP 처리하는 단계를 더 포함하여 상기 수신된 음성 데이터를 화자 단위로 분리하여 처리할 수 있다. 디스플레이 장치는 화자 단위로 분리 처리된 각 음성 데이터에 상응하는 멀티-뷰 화면 영역을 결정하여 맵 핑(mapping)할 수 있다. 디스플레이 장치는 결정된 각 멀티-뷰 화면 영역에 현재 재생 중인 콘텐츠 정보를 추출할 수 있다. 디스플레이 장치는 추출된 각 멀티-뷰 화면 영역에서 현재 재생 중인 콘텐츠 정보와 해당 멀티-뷰 화면 영 역으로 맵핑된 음성 데이터에 따른 콘텐츠를 대비하여, 동시 출력 가능 여부를 판단할 수 있다. 디스플레이 장치는 동시 출력 가능 여부 판단 결과, 멀티-뷰 화면 영역에 맵핑된 음성 데이터에 따른 동작 명령(콘텐츠)이 동시 출력 가능하면, 해당 화면 영역에서 현재 재생 중인 콘텐츠 화면의 일 영역에 상기 동작 명령에 따른 데이터를 출력할 수 있다. 디스플레이 장치는 동시 출력 가능 여부 판단 결과, 멀티-뷰 화면 영역에 맵핑된 음성 데이터에 따른 동작 명령(콘텐츠)이 동시 출력이 불가능하면, 해당 화면 영역에 현재 재생 중인 콘텐츠를 대신하여 상기 동작 명령 에 따른 데이터를 출력할 수 있다. 디스플레이 장치는 화자 단위로 분리되어 처리된 각 음성 데이터에 따른 요청이 동시 처리 가능한 요청인 지 판단하여, 판단 결과 만약 동시 처리 불가능 요청이면, 메인 화자를 결정하고 화자 단위로 분리하여 처리된 음성 데이터 중 상기 결정된 메인 화자에 해당하는 음성 데이터에 따른 요청만 활성화할 수 있다. 디스플레이 장치는 각 멀티-뷰 화면 영역에서 현재 재생 중인 콘텐츠 정보를 추출하고, 추출된 각 멀티-뷰 화면 영역의 콘텐츠 정보에 기초하여 상기 활성화된 메인 화자에 해당하는 음성 데이터에 따른 요청을 출력할 멀티-뷰 화면을 결정할 수 있다. 상기 디스플레이 장치는 상기 메인 화자에 해당하는 음성 데이터에 따른 요청을 출력할 멀티-뷰 화면의 콘텐츠 정보에 기초하여 동시 출력 가능 여부를 판단하고, 동시 출력 가능하면 상기 요청에 따른 콘텐츠를 해당 멀티-뷰 화면의 콘텐츠 상의 일 영역에 출력할 수 있다. 디스플레이 장치는 전술한 바와 같이, 화자 단위로 분리되어 처리된 음성 데이터를 서버로 업로드하고, 상 기 서버로부터 업로드 된 음성 데이터에 대해 NLP 처리에 따라 생성된 NLP 응답을 다운로드 받을 수 있다. 본 개시의 일실시예에 따른 서버에서 디스플레이 장치의 동작을 제어하는 방법은, 수신되는 음성 데이터로 부터 화자 단위로 분리된 음성 데이터를 수신하고, 상기 화자 단위의 각 음성 데이터를 각각 STT 처리 및 NLP 처리하여, 상기 NLP 처리된 각 음성 데이터에 대한 정보 즉, NLP 응답을 생성하여, 상기 디스플레이 장치 로 전송할 수 있다. 이 때, 상기 서버는, 상기 디스플레이 장치의 현재 재생 모드가 멀티-뷰 모드로 인식 되면, 각 멀티-뷰 화면 영역상에 상기 생성된 NLP 응답에 상응하는 콘텐츠가 출력되도록 제어할 수 있다. 도 8의 (a)를 참조하면, 디스플레이 장치는 음성 입력이 수신되면(S101), 멀티-화자 여부를 판단할 수 있 다(S103). 이 때, 수신되는 입력 음성에 멀티-화자 음성 데이터가 포함되었는지에 대한 판단은 예를 들어, 전술 한 도 6 및/또는 7의 관련 설명에 따라 이루어질 수 있다. 디스플레이 장치는 상기 S103 단계 판단 결과, 입력 음성에 멀티-화자 음성 데이터가 포함된 것으로 판단 되면, 현재 디스플레이 장치의 재생 모드가 멀티-뷰 모드인지 판단할 수 있다(S105). 상기 S105 단계 판단 결과 만약 디스플레이 장치의 현재 재생 모드가 멀티-뷰 모드이면, 디스플레이 장치 는 각 화자의 음성 데이터를 STT 처리하고, STT 처리된 데이터를 NLP로 전달할 수 있다(S107). 디스플레이 장치는 상기 S107 단계에서 NLP로 전달 후, 상기 NLP로부터 NLP 처리 결과 즉, NLP 응답을 수 신하여 도 8의 (b)에 도시된 바와 같이, 각 멀티-뷰 화면 영역에 출력되도록 제어할 수 있다(S109). 도 7 및 도 8의 (b)를 참조하면, 제1 멀티-뷰 화면 영역에는 콘텐츠 재생 화면상에 날씨 정보가 제공되고, 제2 멀티-뷰 화면 영역에는 기 제공 중인 콘텐츠를 대신하여 유튜브 어플리케이션 실행 화면이 제공될 수 있다. 도 8에서, 디스플레이 장치는 상기 S105 단계를 생략하고, 멀티-화자이면 도 8의 (b)와 같이 자동으로 멀 티-뷰 모드를 실행하고, 각 멀티-뷰 화면에 제1 화자와 제2 화자의 음성 데이터에 따른 출력을 제공할 수도 있 다. 도 8의 (a)에서, 디스플레이 장치는 상기 S105 단계 판단 결과 만약 현재 재생 모드가 멀티-뷰 모드가 아 닌 경우 즉, 싱글-뷰 모드이면, 특정 화자의 음성 데이터만 STT 처리하고, STT 처리 결과를 NLP로 전달할 수 있 다(S111). 디스플레이 장치는 이후 NLP 응답을 수신하여, 도 8의 (c)에 도시된 바와 같이, 화면을 통하여 상기 수신 된 NLP 응답에 따른 동작을 수행할 수 있다(S113). 도 8의 (a) 및 (c)를 참조하면, 상기 S111 단계에서 특정 화자는 예를 들어, 메인 화자로 볼 수 있다. 상기 메 인 화자는 예를 들어, 현재 디스플레이 장치에 로그인(logged-in) 한 화자, 현재 화면 상에 재생 중인 콘 텐츠와 관련성이 더 높은 화자, 상대적으로 미리 설정된 화자 우선순위가 더 높은 화자 등 다양한 방식에 따라 멀티-화자 중 하나의 화자 즉, 메인 화자가 결정될 수 있다. 예를 들어, 도 8의 (c)에서는, 현재 재생 중인 콘 텐츠 상에 날씨 정보가 출력된 것을 알 수 있다. 이 경우는 예컨대, 메인 화자에 의해 요청된 날씨 정보가 디스 플레이 장치상에서 현재 재생 중인 콘텐츠와 동시 처리 또는 동시 출력이 가능한 콘텐츠이기에, 도 8의 (c)에 도시된 바와 같이, 날씨 정보가 상기 현재 재생 중인 콘텐츠 상에 제공되었다. 다만, 전술한 바와 달리, 상기 메인 화자에 의해 요청된 동작(예를 들어, 콘텐츠)이 디스플레이 장치에서 현재 재생 중인 콘텐츠와 동시 처리 또는 동시 출력이 불가능한 경우에는, 도 8의 (c)와 달리 상기 메인 화자에 의해 요청된 동작이 상기 현재 재생 중인 콘텐츠를 대체할 수 있다. 이 때, 상기 대체되는 이전 재생 중이었던 콘텐츠는 예를 들어, 재생 정지되되 백그라운드(background)에서 대기 상태일 수 있다.실시예에 따라서, NLP 응답에 포함된 동작(콘텐츠)이 예를 들어, 디스플레이 장치에서 현재 재생 콘텐츠와 동시 처리 또는 동시 출력이 불가능하여 결국 현재 재생 콘텐츠를 대신하여야 하는 경우에는, 상기 현재 재생 콘텐츠와 함께 출력 가능한 동작(콘텐츠)을 요청한 화자 또는 화자의 음성 데이터가 상대적으로 더 우선순위가 높게 처리할 수도 있다. 다른 실시예에 따르면, 멀티-화자의 음성 입력을 처리하는 시점에, 디스플레이 장치는 리소소(resource)의 상태 정보를 획득하고, 상기 멀티-화자의 음성 입력에 대해 상기 리소스의 상태 정보를 기준으로 특정 화자를 메인 화자로 선택할 수 있다. 전술한 각 실시예에서 언급된 내용은 각각 가중치로 기능하여 설정된 바에 따라 가중치가 부여되어, 디스플레이 장치는 상기 가중치 값 또는 그 합을 참고하여 본 명세서에서 기술하는 다양한 판단 과정에 이용할 수 있 다. 다음으로, 도 9를 참조하면, 디스플레이 장치는 음성 입력이 수신되면(S201), 현재 재생 모드가 멀티-뷰 모드인지 판단할 수 있다(S203). 디스플레이 장치는 상기 S203 단계 판단 결과 현재 재생 모드가 멀티-뷰 모드인 경우에는, 다음으로 상기 수신 음성 입력에 멀티-화자 음성 데이터가 포함되었는지 판단할 수 있다(S205). 디스플레이 장치는 상기 S205 단계 판단 결과 상기 수신 음성 입력이 싱글-화자 입력인 경우에는, 상기 싱 글-화자 입력을 출력할 멀티-뷰 화면 영역을 선택 또는 결정할 수 있다(S207). 디스플레이 장치는 상기 싱글-화자 입력에 따른 콘텐츠를 처리하고(S211), 상기 처리된 콘텐츠를 상기 S207 단계를 통해 선택 또는 결정된 출력 멀티-뷰 화면 영역에 출력할 수 있다(S213). 상기 S207 단계와 관련하여, 디스플레이 장치는 각 멀티-뷰 화면 영역에 링크된(또는 맵핑된) 화자에 대한 정보와 해당 각 멀티-뷰 화면 영역에서 재생 중인 콘텐츠 정보 중 적어도 하나를 참조할 수 있다. 예를 들어, 상기 각 멀티-뷰 화면 영역이 서로 다른 사용자에게 할당되었고, 상기 각 멀티-뷰 화면 영역에 링크된 각 화자 가 서로 다른 경우에는, 상기 싱글-화자 입력의 화자와 일치하는 사용자에 할당된 멀티-뷰 화면 영역에 상기 처 리된 콘텐츠를 출력하는 것이 바람직하다. 도 9의 (b)를 참조하면, 제1 멀티-뷰 화면 영역은 제1 화자에 할당되고, 제2 멀티-뷰 화면 영역은 제 2화자에 할당된 경우, 싱글-화자 입력이 상기 제1 화자의 음성 입력인 경우에는, 비록 제2 멀티-뷰 화면 영역 에서 출력 중인 콘텐츠가 없다고 하더라도 상기 제1 화자에 대해 할당된 영역인 제1 멀티-뷰 화면 영역 에 콘텐츠를 제공할 수 있다. 실시예에 따라, 상기에서, 제2 멀티-뷰 화면 영역이 만약 출력 중인 콘 텐츠가 없는 경우에는 전술한 바와 달리, 상기 제2 화자에 의한 콘텐츠 재생 요청이 수신되기 전까지는 상기 제 2 멀티-뷰 화면 영역에 상기 제1 화자의 음성 입력에 상응하는 콘텐츠가 재생될 수 있다. 디스플레이 장치는 상기 S205 단계 판단 결과 수신 음성 입력이 멀티-화자 입력인 경우에는, 각 멀티-화자 입력을 출력할 각 멀티-뷰 화면 영역(930, 940)을 선택 또는 결정할 수 있다(S209). 디스플레이 장치는 각 멀티-화자 입력에 따른 콘텐츠를 처리하고(S211), 처리된 각 콘텐츠를 상기 S209 단 계를 통해 선택 또는 결정된 각 멀티-뷰 화면 영역(930, 940)에 도 9의 (c)에 도시된 바와 같이 출력할 수 있다 (S213). 도 9의 (a) 및 (c)를 참조하면, 디스플레이 장치는 각 멀티-뷰 화면 영역(930, 940)에 링크된 화자와 수신 되는 음성 입력에서 식별되는 각 멀티-화자와 일치하는 경우에는, 해당 화자에 따라 출력 화면 영역을 결정할 수 있다. 다만, 디스플레이 장치는 멀티-화자 중 적어도 하나의 화자와 상기 각 멀티-뷰 화면 영역(930, 940)에 링크된 화자가 일치하지 않는 경우에는, 각 멀티-뷰 화면 영역에서 현재 재생 중인 콘텐츠 정보나 상기 각 멀티-뷰 화면 영역(930, 940)에 링크된 화자 정보 등을 참조하여 특정 멀티-뷰 화면 영역을 해당 멀티-화자 를 위해 선택 또는 결정할 수도 있다. 예를 들어, 수신하는 음성 입력에 멀티-화자 즉, 화자 1과 화자 2의 음성 입력이 포함되고, 상기 화자 1의 음성 입력은 어플리케이션 B의 실행 요청, 그리고 화자 2의 음성 입력은 날씨 정보 요청이고, 제1 멀티-뷰 화면 영역 은 화자 1에 링크되어 있으며, 어플리케이션 A를 실행 중이고, 제2 멀티-뷰 화면 영역은 화자 3에 링 크되어 있으며 뉴스 어플리케이션을 실행 중이라고 하자. 상기와 같은 경우, 화자 1의 음성 입력은 제1 멀티-뷰 화면에 그대로 출력할 수 있다. 다만, 화자 2의 경우 제2 멀티-뷰 화면은 현재 화자 3과 링크되어 있기 때문에, 그 처리 방식이 요구된다. 이 경우, 디스플레이 장치는 상기 제2 멀티-뷰 화면 영역 상에 제공 중인 콘텐츠의 속성과 상기 화자 2의 음성 데이터에 따른 동작이 동시 출력이 가능한지 여부를 판단하고, 판단 결과에 기초하여 두 화자의 콘텐 츠를 동시에 제공할 수도 있다. 예컨대, 디스플레이 장치는 상기에서 화자 2는 날씨 정보를 요청한바, 제2 멀티-뷰 화면 영역은 현재 화자 3을 위해 출력 중인 뉴스 어플리케이션과 관련성이 있으며, 동시 출력 가 능한바, 도 9의 (c)에 도시된 바와 같이 동시 출력할 수 있다. 반면, 디스플레이 장치는 상기 제2 멀티-뷰 화면 상에 제공 중인 콘텐츠의 속성과 상기 화자 2의 음 성 데이터에 따른 동작이 동시 출력이 가능한지 여부를 판단한 결과에 기초하여 어느 하나의 콘텐츠만 제공하여 야 할 수 있다. 실시예에 따라, 디스플레이 장치는 상기 화자 2와 화자 3의 화자 우선순위 정보를 참조할 수 있다. 다른 실시예에 따르면, 디스플레이 장치는 상기 화자 2와 화자 3이 요청한 콘텐츠의 중요도 또는 콘텐츠 우선순위 정보를 참조할 수도 있다. 또 다른 실시예에 따르면, 디스플레이 장치는 상기 화자 우선순위 정보와 상기 콘텐츠의 중요도 또는 콘텐 츠의 우선순위 정보를 모두 고려하여 상기 복수의 화자들 중 하나의 화자를 선택할 수도 있다. 디스플레이 장치는 예를 들어, 화자 3으로부터 미리 정한 시간 동안 추가 입력이 존재하는지 판단하고, 없 으면 상기 화자 3 대신에 화자 2를 선택할 수 있다. 디스플레이 장치는 제1 멀티-뷰 화면 영역에서 출력 중인 콘텐츠와의 관계를 고려할 수 있다. 디스플 레이 장치는 예를 들어, 상기 제1 멀티-뷰 화면 영역에서 출력 중인 콘텐츠가 오디오 출력이 요구되 고, 제2 멀티-뷰 화면 영역에서 출력 중인 콘텐츠도 오디오 출력이 요구되는 경우, 어느 하나의 오디오 출 력은 뮤트(mute)처리하거나 다른 출력 수단을 통해 출력되어야 하는바, 이 경우에는 상기 제2 멀티-뷰 화면 영 역에서는 오디오 출력이 필요 없는 콘텐츠를 출력하는 것이 바람직한바, 그에 기초하여 화자 2 또는 화자 3을 선택할 수도 있다. 다음으로, 도 10과 11을 참조하면, 멀티-화자의 음성 입력이 디스플레이 장치에서 동시에 처리(출력) 가능 여부에 따라 그 동작 방법이 달라질 수 있다. 설명의 편의상, 도 10과 11에서는 싱글-뷰 모드를 예로 하여 설명 하나, 이에 한정되는 것은 아니다. 도 10을 참조하면, 디스플레이 장치는 멀터-화자가 인식되면(S301), 동시 처리 판단 가능 여부를 판단할 수 있다(S303). 디스플레이 장치는 상기 S303 단계 판단 결과, Case 1 내지 3에 따라 각각 다른 동작을 수행할 수 있다. 디스플레이 장치는 멀티-화자의 음성 입력이 동시 처리 가능한 Case 1인 경우에는, 멀티-액션 처리하고 (S305), 화면상에 도 11의 (a)와 같이 멀티-액션 처리 결과를 제공할 수 있다. 예를 들어, 다른 풀 사이즈(Full size) 어플리케이션 위에 표시할 수 있는 오버레이(overlay) 어플리케이션은 날씨 카드, 시간 카드와 같은 종류가 있다. 따라서, 실시예에 따라, 디스플레이 장치는 풀 카드(Full card) 위에 오버레이 카드를 동시에 실행할 수 있는 조건인지를 여부로 동시 처리 가능 여부를 판단할 수 있다. 도 11의 (a)를 예로 하면, 유튜브 풀 사이즈 카드 상에는 날씨 오버레이 카드가 함께 출력될 수 있 다. 이 경우는 동시 처리 가능으로 판단될 수 있다. 디스플레이 장치는 멀티-화자의 음성 입력이 동시 처리 가능하지 않은 경우에는, 다시 메인 화자 정보가 등록되어 있는지 판단할 수 있다(S307). 도 10을 참조하면, Case 2는 동시 처리가 되지 않는 조건이나, 메인 화자가 등록되어 있는 경우이고, 그렇지 않 은 경우가 Case 3로 볼 수 있다. 디스플레이 장치는 S307 단계 판단 결과 메인 화자가 등록되어 있는 경우(Case 2), 등록된 메인 화자의 음 성 데이터를 추출하고(S309), 도 11의 (b)에 도시된 바와 같이 추출된 메인 화자의 음성 데이터에 따른 동작을 수행할 수 있다(S311). 반면, 디스플레이 장치는 상기 S307 단계 판단 결과 메인 화자가 등록되어 있지 않은 경우(Case 3)에는, 메인 화자를 자동 판단하고(S313), 판단된 메인 화자의 음성 데이터를 추출 후, 도 11의 (c)에 도시된 바와 같이 그에 따른 동작을 수행할 수 있다(S315). 본 명세서에서 기술하는 ‘동시 처리 가부’는 서버나 사용자의 설정 또는 학습 결과에 기초하여 다양한 방식으 로 결정될 수 있으며, 그것은 화자 정보, 콘텐츠 정보, 시간 내지 공간 정보, 환경 정보 등 다양한 팩터들이 반 영될 수 있다. 예컨대, 멀티-화자의 음성 입력이 각각 제1 동영상 어플리케이션 실행 요청과 제2 동영상 어플리 케이션 실행 요청인 경우, 디스플레이 장치는 리소스의 문제 등에 의해 동시에 2개의 동영상 어플리케이션 실행 요청을 처리하지 못할 수 있다. 따라서, 이 경우는 동시 처리 가능하지 않은 케이스로 볼 수 있다. 도 12의 (a)를 참조하면, 디스플레이 장치는 제1 멀티-뷰 영역에 제1 어플리케이션의 제1 콘텐츠의 1회차 비디오 데이터를 출력하고, 제2 멀티-뷰 영역에 동일 어플리케이션의 동일 콘텐츠의 8회차 비디오 데이터를 재생할 수 있다. 이 경우, 디스플레이 장치는 상기 제1 멀티-뷰 영역과 제2 멀티-뷰 영역에서 동일 어플리케이 션의 동일 콘텐츠이나 다른 시리즈의 비디오 데이터가 각각 할당되는 경우에는 적어도 하나의 화자에 대한 시청 에 방해가 있을 수 있다. 따라서, 디스플레이 장치는 상기와 같은 경우에는 메인 화자를 결정하고, 메인 화자에 의해 요청된 하나의 콘텐츠만 출력할 수 있다. 즉, 디스플레이 장치는 상기 경우에는 동시 처리 불 가능으로 처리할 수 있다. 한편, 도 12의 (a)와 같은 경우, 디스플레이 장치는 상기 각 멀티-뷰 영역에서 출력되는 콘텐츠는 동일하 는 상기 콘텐츠를 제공하기 위해 실행되는 어플리케이션이 서로 다른 경우에도 전술한 바와 같이 동시 처리 불 가능으로 처리할 수 있다. 도 12의 (b)를 참조하면, 디스플레이 장치는 제1 멀티-뷰 영역에 제1 어플리케이션을 할당하고, 제2 멀티-뷰 영역에 제2 어플리케이션을 할당할 수 있다. 이 경우, 디스플레이 장치는 동시 처리 가능 또는 불가능 모두 판단할 수 있다. 예를 들어, 특별히 설정된 사항이 없는 경우, 디스플레이 장치는 예컨 대, 리소스 상태 정보에 따라 상기 두 어플리케이션의 동시 처리 가능 여부를 결정할 수 있다. 도 12의 (b)를 참조하면 예컨대, 두 멀티-뷰 영역(1230, 1240)에 모두 비디오 어플리케이션 실행 요청이 할당된 경우로, 리소 스가 두 비디오 어플리케이션을 함께 처리하기에 충분한 경우, 디스플레이 장치는 동시 출력할 수 있다. 다만, 상기 경우에, 오디오 처리가 문제될 수 있으며, 오디오 처리에 대한 설정이 없는 경우, 디스플레이 장치 는 동시 처리 불가능으로 판단할 수도 있고, 전술한 바와 같이 둘 중 메인 화자를 결정하여 동시 처리하여 출력할 수도 있다. 도 12의 (c)를 참조하면, 디스플레이 장치는 제1 멀티-뷰 영역에는 제1 어플리케이션을 할당하고, 제2 멀티-뷰 영역에는 제2 어플리케이션을 할당할 수 있으며, 각 멀티-뷰 영역에 할당된 어플리케이션은 인터넷 어플리케이션과 비디오 어플리케이션이고, 특별히 설정된 내용이 없으면 동시 처리 가능으로 판단될 수 있다. 한편, 도 12에서 각 멀티-뷰 화면에 대한 할당은 전술한 본 개시에 따른 멀티-화자의 음성 입력에 따른 것일 수 있다. 도 13의 (a)를 참조하면, 디스플레이 장치는 음성 신호가 수신되면(S401), 상기 음성 신호에 멀티-화자 음 성 데이터가 포함되었는지 판단할 수 있다. 상기 판단 결과에 따라, 디스플레이 장치는 멀티-화자인 경우 음성 신호를 분리 처리하거나 싱글-화자의 음성 신호를 처리할 수 있다. 상기에서, 음성 신호에 멀티-화자 음성 데이터가 포함된 경우, 디스플레이 장치는 멀티-화자 중 메인 화자 를 판단할 수 있다(S403). 디스플레이 장치는 상기 S403 단계를 통해 메인 화자가 식별되면, 상기 메인 화자에 대해 도 13의 (b)에 도시된 바와 같은 루틴(routine) 정보를 독출할 수 있다(S405). 상기 루틴 정보는 예컨대, 메모리, DB 등에 미 리 저장된 정보로서, 화자와 기동어에 기초하여 작성된 정보일 수 있다. 예를 들어, 도 13의 (b)에서는 화자-기 동어-루틴이 맵핑된 정보가 예시되었으나, 이에 한정되는 것은 아니다. 도 13의 (b)를 참조하면, 디스플레이 장치는 화자 A와 관련하여, 루틴 정보로 원거리 기동어가 ‘굿모닝’ 인 경우에는 뉴스 채널 전환 ? 날씨 시청 루틴, ‘굿나잇’인 경우에는 갤러리 실행 ? 내일 날씨 시청 ? 30분 뒤 TV 끄기 루틴이 맵핑되어 저장할 수 있다. 반면, 도 13의 (b)를 참조하면, 디스플레이 장치는 화자 B와 관련하여, 루틴 정보로 원거리 기동어가 ‘굿 모닝’인 경우에는 유튜브 음악 재생 ? 날씨 시청 루틴, ‘굿나잇’인 경우에는 유튜브 음악 재생 ? 30분 뒤 TV끄기 루틴이 맵핑되어 저장할 수 있다. 디스플레이 장치는 독출한 루틴 정보에 대응하는 적어도 하나의 어플리케이션을 호출하고(S407), 실행하여 콘텐츠를 출력할 수 있다(S409). 상기에서, 메인 화자가 화자 B이고, 원격 기동어가 굿모닝인 경우, 독출되는 루틴 정보에 따라 디스플레이 장치 는 유튜브 음악을 재생하고, 이후 날씨 정보를 출력할 수 있다. 실시예에 따라서, 디스플레이 장치는 현재 재생 모드가 싱글-뷰 모드이면, 도 13의 (c)와 같이 2개의 어플 리케이션을 동시에 호출하여 실행하고, 하나의 어플리케이션 실행 화면 상에 다른 하나의 어플리케이션 실행 화면을 오버레이하여 제공할 수 있다. 도 13의 (c)에서는 디스플레이 장치가, 루틴 정보에 포 함된 복수의 어플리케이션들을 동시에 호출하여 실행하였으나, 이에 한정되는 것은 아니다. 예를 들어, 상기 루 틴 정보에 포함된 각 어플리케이션 실행 화면은, 디스플레이 장치에서 상기 루틴 정보와 관계없이 기 재생 중인 어플리케이션 화면상에 오버레이 되어 출력될 수도 있다. 이 경우는 예컨대, 디스플레이 장치에서 상 기 두 어플리케이션을 동시에 출력할 수 있는 경우이나, 그렇지 않은 경우에는 상기 루틴 정보에 포함된 어플리 케이션이 상기 기 재생 중인 어플리케이션을 대체하여 실행될 수 있다. 후자의 경우, 도 13의 (d)와 같이, 디스 플레이 장치는 멀티-뷰 모드로 전환하여 동시에 출력할 수도 있다. 상기에서, 루틴 정보에 따라 디스플레 이 장치는 하나의 어플리케이션을 실행하고, 해당 어플리케이션이 실행 종료(또는 미리 설정된 시간 동안 실행 후 종료)되면 이어서 상기 루틴 정보에 정의된 다른 어플리케이션을 실행할 수 있다. 전술한 바와 같이, 루틴 정보를 참고하여, 맵핑된 복수의 어플리케이션을 동시 제공 또는 순차 제공 여부는 예를 들어, 상기 루틴 정보 내 각 어플리케이션의 속성에 따라 결정될 수 있다. 다른 실시예에 따르면, 디스플레이 장치는 현재 재생 모드가 멀티-뷰 모드인 경우, 도 13의 (d)와 같이 2 개의 어플리케이션을 동시에 실행하여 각 멀티-뷰 화면(1210, 1220)에 맵핑하여 제공할 수 있다. 이 때, 상기 각 어플리케이션에 대한 화면 영역의 할당은 임의적일 수 있으며, 상기 화면 제공 후 화자의 입력이나 화자의 현재 위치 등에 따라 결정될 수 있다. 또한, 만약 3개 이상의 어플리케이션이 루틴 정보에 포함된 경우, 상기 둘 중 어느 하나의 화면 영역이 선택되어 해당 화면 영역에서 실행되는 어플리케이션의 종료 후 나머지 어플리 케이션이 실행될 수 있다. 예를 들어, 제1 화면 영역의 콘텐츠의 총 재생 시간이 1시간이고, 제2 화면 영역의 콘텐츠의 총 재생 시간이 30분이면, 디스플레이 장치는 상기 제2 화면을 나머지 어플리케이션의 실행 화면 으로 할당할 수 있다. 전술한 도 13의 (a)에서 S403 단계는 필수적이지 않을 수 있다. 예컨대, 디스플레이 장치는 단지 멀티-화 자이면서 현재 재생 모드가 싱글-뷰 모드인 경우에만 메인 화자를 판단하고, 현재 재생 모드가 멀티-뷰 모드인 경우에는 상기 S403 단계를 건너뛸 수도 있다. 한편, 도 13의 (b)의 루틴 정보는 일실시예일뿐, 이에 한정되는 것은 아니다. 예컨대, 상기 원거리 기동어는 고 려되지 않을 수 있다. 상기 원거리 기동어를 대신하여 현재 시간 정보, 콘텐츠 정보 등이 고려될 수도 있다. 디 스플레이 장치는 이러한 루틴 정보를 인공지능 학습 모델을 통한 학습, 상기 루틴 정보에 대한 각 화자의 피드백(예를 들어, 동작, 음성 입력 등) 등을 참조하여 계속하여 업데이트 및 저장할 수 있다. 도 13의 (b)에서는 각 화자에 대해 카테고리 정보로만 정의되었으나, 구체적으로 해당 카테고리(또는 어플리케 이션)의 어떤 콘텐츠나 정보를 출력할 것인지에 대해 더욱 상세하게 정의될 수도 있다. 도 14의 (a)를 참조하면, 디스플레이 장치는 현재 재생 모드가 멀티-뷰 모드인 경우, 제1 뷰 영역은 사용자 A(User A)에 할당하고, 제2 뷰 영역은 사용자 B(User B)에 할당할 수 있다. 디스플레이 장치는 주기/비주기로 사용자를 감지할 수 있으며, 감지 결과 상기 사용자 A와 사용자 B 중 특 정 사용자가 자리를 비운 것으로 식별되면, 식별 결과에 따른 처리를 할 수 있다. 실시예에 따라, 예를 들어, 상기 자리를 비운 사용자가 메인 화자인지 여부에 따라 상이하게 처리할 수 있다. 설명의 편의상, 도 14에서 메인 화자는 사용자 A로 가정한다. 디스플레이 장치는 메인 화자인 사용자 A가 자리를 비운 것으로 식별되면, 도 14의 (b)에 도시된 바와 같 이 비록 사용자 B는 계속하여 감지되더라도, 이전과 동일하게 멀티-뷰 모드를 유지할 수 있다. 다만, 이 경우, 메인 화자인 사용자 A에 대한 콘텐츠의 재생은 일시 정지, 미러링 서비스 등이 될 수 있다. 상기 미러링 서비스 가 제공되는 경우, 디스플레이 장치는 도 14의 (c)와 같이 상기 사용자 B를 위한 전체 화면으로 전환할 수 도 있다. 한편, 상기 사용자 A가 자리를 비운 시간이 미리 설정된 시간 이상이면, 디스플레이 장치는 도14의 (c)와 같이 사용자 B를 위한 전체 화면으로 전환할 수도 있다. 반면, 메인 화자가 아닌 사용자 B가 자리를 비운 것으로 식별되면, 디스플레이 장치는 도 14의 (c)에 도시 된 바와 같이 멀티-뷰 모드를 싱글-뷰 모드 즉, 전체 화면 모드로 변경 처리할 수 있다. 이 경우, 상기 사용자 B를 위한 콘텐츠는 종료되거나 재생 중단 또는 정지되어 백그라운드에서 대기 상태일 수도 있다. 본 명세서의 전술한 실시예들에서 멀티-화자의 음성 데이터가 포함된 음성 신호로부터 메인 화자를 판단함에 있 어서, 원거리 기동어(trigger word)를 참조할 수 있다. 예를 들어, 디스플레이 장치는 음성 신호 내에 “하이 엘지(Hi LG)”와 같은 원거리 기동어가 포함된 경우, 상기 원거리 기어동에 대한 타임스탬프를 추출하고, 해당 화자를 메인 화자로 판단할 수 있다. 이 때, 디 스플레이 장치는 멀티-화자의 음성 데이터의 순서(또는 시간 순서)는 고려하지 않을 수 있다. 한편, 상기에서 각 멀티-화자들의 음성 데이터에 모두 원거리 기동어가 포함된 경우, 디스플레이 장치는 전술한 바와 같이 각각 타임스탬프를 추출하고, 타임스탬프에 기초하여 선 입력 음성 데이터의 화자를 메인 화 자로 선정하고, 나머지 화자의 원거리 기동어 및 음성 데이터는 무시할 수 있다. 다만, 디스플레이 장치가 멀티-뷰 모드인 경우에는 상기 후 입력 음성 데이터의 원거리 기동어 및 음성 데이터는 추출 및 처리 대상이 될 수 있다. 실시예에 따라서, 후자의 경우, 디스플레이 장치는 멀티-뷰 모드가 아니라고 하더라도, 상기 후 입력 음성 데이터의 원거리 기동어 및 음성 데이터를 추출 및 처리할 수 있으나, 그 출력은 상기 선 입력 음성 데이터에 따른 재생이 정지, 종료 등이 있는 경우에 이루어질 수 있다. 실시예에 따라, 각 멀티-화자들의 음성 데이터에 모두 원거리 기동어가 포함된 경우, 순서에 관계없이 각 원거 리 기동어에 이은 명령 또는 요청의 우선순위 정보가 참조되어 메인 화자가 결정될 수 있다. 실시예에 따라, 각 멀티-화자들의 음성 데이터에 모두 원거리 기동어가 포함된 경우, 각 화자의 우선순위 정보 나 상기 원거리 기동어에 대한 신호 레벨에 따라 메인 화자가 결정될 수 있다. 실시예에 따라, 각 멀티-화자들의 음성 데이터에 모두 원거리 기동어가 포함된 경우, 상기 각 원거리 기동에 이 은 명령 또는 요청과 현재 디스플레이 장치의 재생 콘텐츠와의 관련성에 기초하여 메인 화자가 결정될 수 있다. 실시예에 따라, 각 멀티-화자들의 음성 데이터에 모두 원거리 기동어가 포함된 경우, 디스플레이 장치의 현재 위치 또는 속한 공간에 대한 정보, 시간 정보 등에 기초하여 메인 화자가 결정될 수 있다. 예를 들어, 디 스플레이 장치가 예를 들어, 부엌이라는 공간에 위치한 경우, 특정 사용자(예를 들어, 요리사, 엄마)에 더 많은 가중치가 부여되어 메인 화자로 결정될 수 있다. 상기에서, 디스플레이 장치가 속한 공간 정보나 시 간 정보 등은, 원거리 기동어의 존재에도 불구하고 메인 화자 결정을 위한 팩터로 그와 동일하거나 더 많은 가 중치(또는 우선순위)가 부여될 수도 있다. 도 15는 본 개시의 일실시예에 따른 멀티-화자 데이터의 처리 방법에 대한 순서도이다. 디스플레이 장치는 멀티-화자의 음성 데이터가 포함된 음성 신호를 수신할 수 있다(S501). 디스플레이 장치는 현재 화면을 통해 재생 중인 콘텐츠를 식별할 수 있다(S503). 디스플레이 장치는 상기 각 멀티-화자와 상기 콘텐츠 사이의 관련성을 판단할 수 있다(S505). 디스플레이 장치는 상기 S505 단계 판단 결과 상기 식별 콘텐츠에 관련성이 더 높은 화자를 메인 화자로 지정할 수 있다(S507). 디스플레이 장치는 상기 메인 화자로 지정된 화자의 음성 데이터에 기초한 동작을 수행할 수 있다(S509). 디스플레이 장치는 한편, 상기 S505 단계 판단 결과 만약 상기 식별 콘텐츠와 화자 사이의 관련성이 유의 미하지 않은 경우, 디스플레이 장치의 현재 재생 모드가 멀티-뷰 모드인지 판단할 수 있다(S507). 디스플레이 장치는 상기 S507 단계 판단 결과 현재 재생 모드가 멀티-뷰 모드인 경우, 각 멀티-뷰 화면 영 역과 각 멀티-화자의 음성 데이터를 맵핑하고, 상기 맵핑에 따라 각 화자의 입력에 따른 동작을 해당 멀티-뷰 화면 영역에서 제공할 수 있다. 도 8 내지 10, 13 및 15의 도시된 순서는 일실시예일뿐, 그에 한정되는 것은 아니다. 다시 말해, 실시예에 따라 상기 순서도 내 하나 또는 그 이상의 단계들은 동시에 수행되거나 도시된 바와 다른 순서도 동작될 수도 있다. 또한, 도 8 내지 10, 13 및 15에서 비록 한 단계로 도시되었다고 하더라도 실시예에 따라 해당 단계는 복수의단계로 구분되어 동작될 수도 있고, 반대도 가능하다. 그 밖에, 비록 도시되진 않았으나, 하나 또는 그 이상의 본 개시와 관련된 동작이 더 수행될 수도 있다. 이상의 설명은 본 개시의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 개시가 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 개시의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 개시에 개시된 실시예들은 본 개시의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 개시의 기술 사상의 범위가 한정되는 것은 아니다. 본 개시의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사 상은 본 개시의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0100207", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일실시예에 따른 디스플레이 장치의 구성을 블록도로 도시한 것이다. 도 2는 본 개시의 일실시예에 따른 원격제어장치의 구성 블록도이다. 도 3은 본 개시의 일실시예에 따른 원격제어장치의 실제 구성 예를 보여준다. 도 4는 본 개시의 실시예에 따라 원격 제어 장치를 활용하는 예를 보여준다. 도 5는 본 개시의 실시예에 따른 스탠드 타입의 디스플레이 장치의 가로 모드 및 세로 모드를 설명하기 위한 도면이다. 도 6은 본 개시의 다른 일실시예에 따른 디스플레이 장치의 구성을 블록도로 도시한 것이다. 도 7은 본 개시의 일실시예에 따른 멀티-화자 데이터 처리 과정을 설명하기 위해 도시한 도면이다. 도 8 내지 14는 본 개시의 실시예에 따른 멀티-화자 데이터의 처리 방법을 설명하기 위해 도시한 도면이다. 도 15는 본 개시의 일실시예에 따른 멀티-화자 데이터의 처리 방법에 대한 순서도이다."}
