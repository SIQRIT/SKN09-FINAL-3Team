{"patent_id": "10-2019-0177115", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0084123", "출원번호": "10-2019-0177115", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "이정훈"}}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,제1 정보 및 제2 정보가 저장된 메모리; 및상기 전자 장치의 리소스 정보에 기초하여 상기제1 정보를 로딩하여 제1 가중치 매트릭스를 획득하거나, 상기 제1 정보 및 상기 제2 정보를 로딩하여 제2 가중치 매트릭스를 획득하는 프로세서;를 포함하며,상기 제1 정보는,상기 제1 가중치 매트릭스와 관련된 가중치 및상기 가중치에 대응되는 제1 인덱스를 포함하며,상기 제2 정보는,상기 제2 가중치 매트릭스를 획득하기 위한 추가 가중치 및 상기 추가 가중치에 대응되는 제2 인덱스를 포함하는, 전자 장치."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,입력 데이터를 상기 제1 가중치 매트릭스 또는 상기 제2 가중치 매트릭스를 이용하는 인공 지능 모델(Artificial Intelligence Model)에 입력하여 출력 데이터를 획득하며,상기 전자 장치의리소스 정보가 변경되면, 변경된 리소스 정보에 기초하여 상기 제1 가중치 매트릭스에 기초하여 상기 제2 가중치 매트릭스를 획득하거나, 상기 제2 가중치 매트릭스에 기초하여 상기 제1 가중치 매트릭스를 획득하는, 전자장치."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제2 가중치 매트릭스는,상기 제1 정보에 포함된 가중치, 상기 제1 인덱스, 상기 추가 가중치 및 상기 제2 인덱스에 기초하여 획득되는, 전자 장치."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,상기 제1 인덱스 및 상기 제2 인덱스에 기초하여 상기 제1 정보에 포함된 가중치에 상기 추가 가중치를 결합하여 상기 제2 가중치 매트릭스를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는,상기 제1 인덱스에 기초하여 상기 제2 가중치 매트릭스에서 상기 제1 인덱스에대응되는 가중치의 위치를 결정하고상기 제2 인덱스에 기초하여 상기 제2 가중치 매트릭스에서 상기 제2 인덱스에 대응되는 추가 가중치의 위치를 결정하고,상기 제1 인덱스에 대응되는 가중치의 위치 및 상기 제2 인덱스에대응되는 가중치의 위치에 기초하여 상기 제1 인덱스 또는 상기 제2 인덱스 중 적어도 하나를 변경하고,상기 가중치의 위치, 상기 추가 가중치의 위치 및 상기 변경된 인덱스에 기초하여 상기 제2 가중치 매트릭스를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 리소스 정보는,상기 전자 장치의 내부 메모리 가용 용량, 상기 전자 장치의 전력 상태, 상기 전자 장치에서 실행되는 어플리케이션의 리소스 또는 상기 전자 장치에서 실행되는 인공 지능 모델의 리소스중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제1 정보는,가중치 정보에서 제1 임계값 미만의 가중치를 프루닝하여 획득된 정보에서 제2임계값 이상의 가중치 및 상기 제2 임계값 이상의 가중치에 대응되는 인덱스를 포함하며,상기 제2 정보는,상기프루닝하여 획득된 정보에서 상기 제2 임계값 미만의 가중치 및 상기 제2 임계값 미만의 가중치에 대응되는 인덱스를 포함하는, 전자 장치."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제1 정보는,상기 프루닝하여 획득된 정보에서 상기 제2 임계값 이상의 가중치를 제1 학습하여 획득된 가중치 및 상기 제1 학습하여 획득된 가중치에 대응되는 인덱스를 포함하며,상기 제2 정보는,상기공개특허 10-2021-0084123-2-프루닝하여 획득된 정보에서 상기 제2 임계값 이상의 가중치 및 상기 제2 임계값 미만의 가중치를 제2 학습하여상기 제2 학습하여 획득된 가중치에 대응되는 인덱스를 포함하며,상기 제2 학습시에 상기 제2 임계값 이상의 가중치는 고정되는, 전자 장치."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는,상기 제2 가중치 매트릭스에 대응되는 제3 정보에 포함된 가중치, 상기 가중치에 대응되는 제3 인덱스 및 상기 제2 인덱스에 기초하여 상기 제3 정보에서 상기 제2 인덱스에 대응되는 추가가중치를 제거하여 상기 제1 가중치 매트릭스를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 프로세서는,상기 제2 인덱스 및 상기 제3 인덱스에 기초하여 상기 제2 가중치 매트릭스에서 상기 추가 가중치의 위치를 결정하고,상기 추가 가중치의 위치에 기초하여 상기 제3 정보에서 상기 추가 가중치를 제거하고 상기 제3 정보에서 상기 제거된 추가 가중치의 위치와 인접한 가중치의 인덱스를 수정하여 상기 제1 가중치 매트릭스를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 정보 및 제2 정보가 저장된 전자 장치의 제어 방법에 있어서,상기 전자 장치의 리소스 정보에 기초하여 상기 제1 정보를 로딩하여 제1 가중치 매트릭스를 획득하거나, 상기 제1 정보 및 상기 제2 정보를 로딩하여 제2가중치 매트릭스를 획득하는 단계;를 포함하며,상기 제1 정보는, 상기 제1 가중치 매트릭스와 관련된 가중치 및상기 가중치에 대응되는 제1 인덱스를 포함하며,상기 제2 정보는, 상기 제2 가중치 매트릭스를 획득하기 위한추가 가중치 및 상기 추가 가중치에 대응되는 제2 인덱스를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제어 방법은,입력 데이터를 상기 제1 가중치 매트릭스 또는 상기 제2 가중치 매트릭스를이용하는 인공 지능 모델(Artificial Intelligence Model)에 입력하여 출력 데이터를 획득하는 단계; 및상기 전자 장치의 리소스 정보가 변경되면, 변경된 리소스 정보에 기초하여 상기 제1 가중치 매트릭스에 기초하여 상기제2 가중치 매트릭스를 획득하거나, 상기 제2 가중치 매트릭스에 기초하여 상기 제1 가중치 매트릭스를 획득하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 제2 가중치 매트릭스는,상기 제1 정보에 포함된 가중치, 상기 제1 인덱스, 상기 추가 가중치 및 상기 제2 인덱스에 기초하여 획득되는, 제어 방법."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제2 가중치 매트릭스를 획득하는 단계는,상기 제1 인덱스 및 상기 제2 인덱스에 기초하여상기 제1 정보에 포함된 가중치에 상기 추가 가중치를 결합하여 상기 제2 가중치 매트릭스를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제2 가중치 매트릭스를 획득하는 단계는,상기 제1 인덱스에 기초하여 상기 제2 가중치 매트릭스에서 상기 제1 인덱스에 대응되는 가중치의 위치를 결정하고,상기 제2 인덱스에 기초하여 상기 제2 가중치 매트릭스에서 상기 제2 인덱스에 대응되는 추가 가중치의 위치를 결정하고,상기 제1 인덱스에 대응되는 가중치의 위치 및 상기 제2 인덱스에 대응되는 가중치의 위치에 기초하여 상기 제1 인덱스 또는 상기 제2 인덱스 중적어도 하나를 변경하고,상기 가중치의 위치, 상기 추가 가중치의 위치 및 상기 변경된 인덱스에 기초하여 상기제2 가중치 매트릭스를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 리소스 정보는,상기 전자 장치의 내부 메모리 가용 용량, 상기 전자 장치의 전력 상태,상기 전자 장치에서 실행되는 어플리케이션의 리소스 또는 상기 전자 장치에서 실행되는 인공 지능 모델의 리소스 중 적어도 하나를 포함하는, 제어 방법.공개특허 10-2021-0084123-3-청구항 17 제11항에 있어서,상기 제1 정보는,가중치 정보에서 제1 임계값 미만의 가중치를 프루닝하여 획득된 정보에서 제2 임계값 이상의 가중치 및 상기 제2 임계값 이상의 가중치에 대응되는 인덱스를 포함하며,상기 제2 정보는,상기 프루닝하여 획득된 정보에서 상기 제2 임계값 미만의 가중치 및 상기 제2 임계값 미만의 가중치에 대응되는인덱스를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 제1 정보는,상기 프루닝하여 획득된 정보에서 상기 제2 임계값 이상의 가중치를 제1 학습하여 획득된 가중치 및 상기 제1 학습하여 획득된 가중치에 대응되는 인덱스를 포함하며,상기 제2 정보는,상기프루닝하여 획득된 정보에서 상기 제2 임계값 이상의 가중치 및 상기 제2 임계값 미만의 가중치를 제2 학습하여상기 제2 학습하여 획득된 가중치에 대응되는 인덱스를 포함하며,상기 제2 학습시에 상기 제2 임계값 이상의 가중치는 고정되는, 제어 방법."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 제어 방법은,상기 제2 가중치 매트릭스에 대응되는 제3 정보에 포함된 가중치, 상기 가중치에 대응되는 제3 인덱스 및 상기 제2 인덱스에 기초하여 상기 제3 정보에서 상기 제2 인덱스에 대응되는 추가가중치를 제거하여 상기 제1 가중치 매트릭스를 획득하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177115", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 제1 가중치 매트릭스를 획득하는 단계는,상기 제2 인덱스 및 상기 제3 인덱스에 기초하여상기 제2 가중치 매트릭스에서 상기 추가 가중치의 위치를 결정하고,상기 추가 가중치의 위치에 기초하여 상기제3 정보에서 상기 추가 가중치를 제거하고 상기 제3 정보에서 상기 제거된 추가 가중치의 위치와 인접한 가중치의 인덱스를 수정하여 상기 제1 가중치 매트릭스를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0177115", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 본 전자 장치는 제1 정보 및 제2 정보가 저장된 메모리 및 전자 장치의 리소스 정보에 기 초하여 제1 정보를 로딩하여 제1 가중치 매트릭스를 획득하거나, 제1 정보 및 제2 정보를 로딩하여 제2 가중치 매트릭스를 획득하는 프로세서를 포함하고, 제1 정보는 제1 가중치 매트릭스와 관련된 가중치 및 가중치에 대응 되는 제1 인덱스를 포함하고, 제2 정보는 제2 가중치 매트릭스를 획득하기 위한 추가 가중치 및 추가 가중치에 대응되는 제2 인덱스를 포함한다."}
{"patent_id": "10-2019-0177115", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 제어방법에 관한 것으로, 더욱 상세하게는 신경망 경량화 동작을 수행 하는 전자 장 치 및 그 제어방법에 대한 것이다."}
{"patent_id": "10-2019-0177115", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "제한된 자원을 가진 전자 기기에서, DNN (deep neural network)을 수행하는 경우, 기존 신경망을 더 작은(단순 한) 신경망 모델로 변경해 주는 신경망 경량화 기술이 매우 중요하다. 신경망 경량화를 통해, 파라미터의 사이 즈를 줄여 메모리 대역폭 및 전송에 따른 전력소모를 줄일 수 있고, 압축된 파라미터를 계산에 이용하여, 계산 량을 크게 감소 시킬 수 있기 때문이다. DNN 연산의 대부분은 input (feature) 과 가중치(또는 파라미터)의 곱으로 구성되는데, 파라미터들 중 일부의 값을 0으로 강제하는 것을 프루닝(pruning)이라 한다. 프루닝을 적용할 경우, 0이 아닌 파라미터들만을 압축하 여, 데이터 전송량을 줄일 수 있고, 값이 0인 파라미터들은 계산에서 제외시킬 수 있어 계산량도 크게 감소시킬 수 있다. 다만 학습된(trained) 파라미터 값이 변경됨에 따라 실제 정확도와는 차이를 보일 수 있다. 따라서, 재학습(retrain) 과정을 통해 프루닝 전의 정확도에 근접하여 회복할 수 있다. 상술한 바와 같이 신경망 경량화 동작을 이용하여 전력 소모를 줄이고 계산량을 감소시킬 수 있다. 하지만, 종 래 기술은 이미 한번 신경망 경량화 방식이 정해지면, 정해진 경량화 방식을 운용할 뿐 확장성이 불가능하다는 문제점이 있었다. 구체적으로, 전자 기기의 리소스에 따라 신경망 경량화가 일정하게 적용될 뿐, 다양한 전자 기기의 상황에 따라 경량화 방식이 일정하게 적용되어 효율적인 연산이 불가능하다는 문제점이 있었다."}
{"patent_id": "10-2019-0177115", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2019-0177115", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제를 개선하기 위해 고안된 것으로, 본 개시의 목적은 전자 장치의 리소스 정보를 고려하여, 신경망 경량화 동작을 수행하는 전자 장치 및 그의 제어 방법을 제공함에 있다."}
{"patent_id": "10-2019-0177115", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위한 본 실시 예에 따른 전자 장치는 제1 정보 및 제2 정보가 저장된 메모리 및 상기 전자 장치의 리소스 정보에 기초하여 상기 제1 정보를 로딩하여 제1 가중치 매트릭스를 획득하거나, 상기 제1 정보 및 상기 제2 정보를 로딩하여 제2 가중치 매트릭스를 획득하는 프로세서를 포함하고, 상기 제1 정보는 상 기 제1 가중치 매트릭스와 관련된 가중치 및 상기 가중치에 대응되는 제1 인덱스를 포함하고, 상기 제2 정보는 상기 제2 가중치 매트릭스를 획득하기 위한 추가 가중치 및 상기 추가 가중치에 대응되는 제2 인덱스를 포함한 다. 여기서, 상기 프로세서는 입력 데이터를 상기 제1 가중치 매트릭스 또는 상기 제2 가중치 매트릭스를 이용하는 인공 지능 모델(Artificial Intelligence Model)에 입력하여 출력 데이터를 획득할 수 있고, 상기 전자 장치의 리소스 정보가 변경되면, 변경된 리소스 정보에 기초하여 상기 제1 가중치 매트릭스에 기초하여 상기 제2 가중 치 매트릭스를 획득하거나, 상기 제2 가중치 매트릭스에 기초하여 상기 제1 가중치 매트릭스를 획득할 수 있다. 한편, 상기 제2 가중치 매트릭스는 상기 제1 정보에 포함된 가중치, 상기 제1 인덱스, 상기 추가 가중치 및 상 기 제2 인덱스에 기초하여 획득될 수 있다. 여기서, 상기 프로세서는 상기 제1 인덱스 및 상기 제2 인덱스에 기초하여 상기 제1 정보에 포함된 가중치에 상 기 추가 가중치를 결합하여 상기 제2 가중치 매트릭스를 획득할 수 있다. 여기서, 상기 프로세서는 상기 제1 인덱스에 기초하여 상기 제2 가중치 매트릭스에서 상기 제1 인덱스에 대응되 는 가중치의 위치를 결정할 수 있고, 상기 제2 인덱스에 기초하여 상기 제2 가중치 매트릭스에서 상기 제2 인덱 스에 대응되는 추가 가중치의 위치를 결정할 수 있고, 상기 제1 인덱스에 대응되는 가중치의 위치 및 상기 제2 인덱스에 대응되는 가중치의 위치에 기초하여 상기 제1 인덱스 또는 상기 제2 인덱스 중 적어도 하나를 변경할 수 있고, 상기 가중치의 위치, 상기 추가 가중치의 위치 및 상기 변경된 인덱스에 기초하여 상기 제2 가중치 매 트릭스를 획득할 수 있다. 한편, 상기 리소스 정보는 상기 전자 장치의 내부 메모리 가용 용량, 상기 전자 장치의 전력 상태, 상기 전자 장치에서 실행되는 어플리케이션의 리소스 또는 상기 전자 장치에서 실행되는 인공 지능 모델의 리소스 중 적어 도 하나를 포함할 수 있다. 또한, 상기 제1 정보는 가중치 정보에서 제1 임계값 미만의 가중치를 프루닝하여 획득된 정보에서 제2 임계값 이상의 가중치 및 상기 제2 임계값 이상의 가중치에 대응되는 인덱스를 포함할 수 있고, 상기 제2 정보는 상기 프루닝하여 획득된 정보에서 상기 제2 임계값 미만의 가중치 및 상기 제2 임계값 미만의 가중치에 대응되는 인 덱스를 포함할 수 있다. 여기서, 상기 제1 정보는 상기 프루닝하여 획득된 정보에서 상기 제2 임계값 이상의 가중치를 제1 학습하여 획 득된 가중치 및 상기 제1 학습하여 획득된 가중치에 대응되는 인덱스를 포함할 수 있고, 상기 제2 정보는 상기 프루닝하여 획득된 정보에서 상기 제2 임계값 이상의 가중치 및 상기 제2 임계값 미만의 가중치를 제2 학습하여 상기 제2 학습하여 획득된 가중치에 대응되는 인덱스를 포함할 수 있고, 상기 제2 학습시에 상기 제2 임계값 이 상의 가중치는 고정될 수 있다. 한편, 상기 프로세서는 상기 제2 가중치 매트릭스에 대응되는 제3 정보에 포함된 가중치, 상기 가중치에 대응되 는 제3 인덱스 및 상기 제2 인덱스에 기초하여 상기 제3 정보에서 상기 제2 인덱스에 대응되는 추가 가중치를 제거하여 상기 제1 가중치 매트릭스를 획득할 수 있다. 여기서, 상기 프로세서는 상기 제2 인덱스 및 상기 제3 인덱스에 기초하여 상기 제2 가중치 매트릭스에서 상기 추가 가중치의 위치를 결정할 수 있고, 상기 추가 가중치의 위치에 기초하여 상기 제3 정보에서 상기 추가 가중 치를 제거할 수 있고 상기 제3 정보에서 상기 제거된 추가 가중치의 위치와 인접한 가중치의 인덱스를 수정하여 상기 제1 가중치 매트릭스를 획득할 수 있다. 한편, 본 개시의 일 실시 예에 따른 제1 정보 및 제2 정보가 저장된 전자 장치의 제어 방법에 있어서, 상기 전 자 장치의 리소스 정보에 기초하여 상기 제1 정보를 로딩하여 제1 가중치 매트릭스를 획득하거나, 상기 제1 정 보 및 상기 제2 정보를 로딩하여 제2 가중치 매트릭스를 획득하는 단계를 포함하고, 상기 제1 정보는 상기 제1 가중치 매트릭스와 관련된 가중치 및 상기 가중치에 대응되는 제1 인덱스를 포함하고, 상기 제2 정보는 상기 제 2 가중치 매트릭스를 획득하기 위한 추가 가중치 및 상기 추가 가중치에 대응되는 제2 인덱스를 포함한다. 여기서, 상기 제어 방법은 입력 데이터를 상기 제1 가중치 매트릭스 또는 상기 제2 가중치 매트릭스를 이용하는 인공 지능 모델(Artificial Intelligence Model)에 입력하여 출력 데이터를 획득하는 단계 및 상기 전자 장치의 리소스 정보가 변경되면, 변경된 리소스 정보에 기초하여 상기 제1 가중치 매트릭스에 기초하여 상기 제2 가중 치 매트릭스를 획득하거나, 상기 제2 가중치 매트릭스에 기초하여 상기 제1 가중치 매트릭스를 획득하는 단계를 더 포함할 수 있다. 한편, 상기 제2 가중치 매트릭스는 상기 제1 정보에 포함된 가중치, 상기 제1 인덱스, 상기 추가 가중치 및 상 기 제2 인덱스에 기초하여 획득될 수 있다. 여기서, 상기 제2 가중치 매트릭스를 획득하는 단계는 상기 제1 인덱스 및 상기 제2 인덱스에 기초하여 상기 제 1 정보에 포함된 가중치에 상기 추가 가중치를 결합하여 상기 제2 가중치 매트릭스를 획득할 수 있다. 여기서, 상기 제2 가중치 매트릭스를 획득하는 단계는 상기 제1 인덱스에 기초하여 상기 제2 가중치 매트릭스에 서 상기 제1 인덱스에 대응되는 가중치의 위치를 결정할 수 있고, 상기 제2 인덱스에 기초하여 상기 제2 가중치 매트릭스에서 상기 제2 인덱스에 대응되는 추가 가중치의 위치를 결정할 수 있고, 상기 제1 인덱스에 대응되는 가중치의 위치 및 상기 제2 인덱스에 대응되는 가중치의 위치에 기초하여 상기 제1 인덱스 또는 상기 제2 인덱 스 중 적어도 하나를 변경할 수 있고, 상기 가중치의 위치, 상기 추가 가중치의 위치 및 상기 변경된 인덱스에 기초하여 상기 제2 가중치 매트릭스를 획득할 수 있다. 한편, 상기 리소스 정보는 상기 전자 장치의 내부 메모리 가용 용량, 상기 전자 장치의 전력 상태, 상기 전자 장치에서 실행되는 어플리케이션의 리소스 또는 상기 전자 장치에서 실행되는 인공 지능 모델의 리소스 중 적어 도 하나를 포함할 수 있다. 한편, 상기 제1 정보는 가중치 정보에서 제1 임계값 미만의 가중치를 프루닝하여 획득된 정보에서 제2 임계값 이상의 가중치 및 상기 제2 임계값 이상의 가중치에 대응되는 인덱스를 포함할 수 있고, 상기 제2 정보는 상기 프루닝하여 획득된 정보에서 상기 제2 임계값 미만의 가중치 및 상기 제2 임계값 미만의 가중치에 대응되는 인 덱스를 포함할 수 있다. 여기서, 상기 제1 정보는 상기 프루닝하여 획득된 정보에서 상기 제2 임계값 이상의 가중치를 제1 학습하여 획 득된 가중치 및 상기 제1 학습하여 획득된 가중치에 대응되는 인덱스를 포함할 수 있고, 상기 제2 정보는 상기 프루닝하여 획득된 정보에서 상기 제2 임계값 이상의 가중치 및 상기 제2 임계값 미만의 가중치를 제2 학습하여 상기 제2 학습하여 획득된 가중치에 대응되는 인덱스를 포함할 수 있고, 상기 제2 학습시에 상기 제2 임계값 이 상의 가중치는 고정될 수 있다. 한편, 상기 제어 방법은 상기 제2 가중치 매트릭스에 대응되는 제3 정보에 포함된 가중치, 상기 가중치에 대응 되는 제3 인덱스 및 상기 제2 인덱스에 기초하여 상기 제3 정보에서 상기 제2 인덱스에 대응되는 추가 가중치를 제거하여 상기 제1 가중치 매트릭스를 획득하는 단계를 더 포함할 수 있다. 여기서, 상기 제1 가중치 매트릭스를 획득하는 단계는 상기 제2 인덱스 및 상기 제3 인덱스에 기초하여 상기 제 2 가중치 매트릭스에서 상기 추가 가중치의 위치를 결정할 수 있고, 상기 추가 가중치의 위치에 기초하여 상기 제3 정보에서 상기 추가 가중치를 제거할 수 있고 상기 제3 정보에서 상기 제거된 추가 가중치의 위치와 인접한 가중치의 인덱스를 수정하여 상기 제1 가중치 매트릭스를 획득할 수 있다."}
{"patent_id": "10-2019-0177115", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다.본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 명세서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU(Neural Network Processing Unit)와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치를 도시한 블록도이다. 도 1을 참조하면, 전자 장치는 메모리 및 프로세서로 구성될 수 있다. 본 명세서의 다양한 실시 예들에 따른 전자 장치는, 예를 들면, 스마트폰, 태블릿 PC, 이동 전화기, 영상 전화기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, PDA, PMP(portable multimedia player), MP3 플레이어, 카메라, 또는 웨어러블 장치 중 적어도 하나를 포함할 수 있다. 웨어러블 장치는 액세서리형(예:시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD)), 직 물 또는 의류 일체형(예: 전자 의복), 신체 부착형(예: 스킨 패드 또는 문신), 또는 생체 이식형 회로 중 적어 도 하나를 포함할 수 있다. 어떤 실시예들에서, 전자 장치는, 예를 들면, 텔레비전, DVD(digital video disk) 플레이어, 오디오 중 적어도 하나를 포함할 수 있다. 메모리는 프로세서에 포함된 롬(ROM)(예를 들어, EEPROM(electrically erasable programmable read- only memory)), 램(RAM) 등의 내부 메모리로 구현되거나, 프로세서와 별도의 메모리로 구현될 수도 있다. 이 경우, 메모리는 데이터 저장 용도에 따라 전자 장치에 임베디드된 메모리 형태로 구현되거나, 전 자 장치에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 전자 장치의 구동을 위한 데이터의 경우 전자 장치에 임베디드된 메모리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현되고, 전자 장 치에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결 가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 메모리에 적어도 하나의 인스트럭션을 저장할 수 있다. 여기서, 인스트럭션은 사용자의 명령, 사용자의 조 작 또는 기 설정된 이벤트 중 적어도 하나를 의미할 수 있다. 본 개시의 일 실시 예에 따른 메모리는 인공 지능 모델을 저장할 수 있다. 한편, 반드시 인공 지능 모델이 전자 장치의 메모리에 저장되는 것은 아니며, 인공 지능 모델은 외부 서버에 저장되는 형태로 구현될 수 있다. 프로세서는 전자 장치의 전반적인 제어 동작을 수행할 수 있다. 프로세서는 디지털 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프 로세서(microprocessor), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙 처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤 러(controller), 어플리케이션 프로세서(application processor(AP)), GPU(graphics-processing unit) 또는 커 뮤니케이션 프로세서(communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 또한, 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 또 한, 프로세서는 메모리에 저장된 컴퓨터 실행가능 명령어(computer executable instructions)를 실 행함으로써 다양한 기능을 수행할 수 있다. 프로세서는 전자 장치의 리소스 정보에 기초하여 제1 정보를 로딩하여 제1 가중치 매트릭스를 획득하 거나, 제1 정보 및 제2 정보를 로딩하여 제2 가중치 매트릭스를 획득하는 프로세서를 포함할 수 있다. 여기서, 제1 정보는 제1 가중치 매트릭스와 관련된 가중치 및 제1 가중치 매트릭스와 관련된 가중치 에 대응되는 제1 인 덱스를 포함하고, 제2 정보는 제2 가중치 매트릭스를 획득하기 위한 추가 가중치 및 추가 가중치에 대응되는 제 2 인덱스를 포함할 수 있다. 프로세서는 리소스 정보에 기초하여 제1 정보를 로딩할지 아니면 제1 정보 및 제2 정보를 모두 로딩할지 결정할 수 있다. 여기서, 제1 정보 및 제2 정보는 제1 클래스 및 제2 클래스에 대응되는 가중치와 관련된 정보 를 의미할 수 있다. 여기서, 클래스는 인공 지능 모델에서 이용되는 가중치 매트릭스를 압축하는 과정에서 획득되는 가중치 값을 크 기에 따라 구분한 그룹이 될 수 있다. . 예를 들어, 원본 가중치 매트릭스에 100개의 가중치가 포함되어 있다고 가정한다. 원본 가중치 매트릭스를 압축(예를 들어 프루닝)함에 따라 100 개의 가중치 중 50개가 0으로 프루닝 되고, 50 개의 가중치가 0이 아닌 값을 가진다고 가정할 때, 50개의 가중치 중 임계값 이상인 가중치를 제1 클 래스에 할당하고 50개의 가중치 중 가중치 값이 임계값 미만인 가중치를 제2 클래스에 할당할 수 있다. 한편, 클래스의 개수, 임계값 개수 및 임계값은 실시 예에 따라 달라질 수 있다.따라서, 본 개시에서 제1 정보를 로딩하여 제1 가중치 매트릭스를 획득하는 것은 제1 클래스에 포함된(또는 할 당된) 가중치에 대한 정보에 기초하여 가중치 매트릭스를 획득하는 것을 의미할 수 있다. 또한, 제1 정보 및 제 2 정보를 로딩하여 제2 가중치 매트릭스를 획득하는 것은 제1 클래스에 포함된 가중치 및 제2 클래스에 포함된 가중치 모두에 대한 정보에 기초하여 가중치 매트릭스를 획득하는 것을 의미할 수 있다. 한편, 프로세서는 전자 장치의 리소스 정보에 기초하여 제1 클래스에 대응되는 가중치 정보(또는 가 중치 데이터, 이하 편의를 위해 가중치 정보로 통일하여 기재한다.)를 이용할지 아니면 제1 클래스 및 제2 클래 스에 대응되는 가중치 정보를 이용할지 결정할 수 있다. 여기서, 리소스 정보는 현재 전자 장치의 하드웨 어와 관련된 리소스, 특정 모듈 또는 특정 어플리케이션을 수행하기 위하여 필요한 요구 리소스 등에 관련된 정 보를 의미할 수 있다. 예를 들어, 리소스 정보는 전자 장치의 내부 메모리 용량(총 용량, 이용 용량, 가용 용량), 전자 장치의 전력 상태, 전자 장치에서 실행되는 어플리케이션의 리소스, 전자 장치에서 실행되는 인공 지능 모델의 리소스 중 적어도 하나를 포함할 수 있다. 여기서, 내부 메모리 이용 용량은 내부 메모리의 총 용량 중 이미 사용되고 있는 용량을 의미할 수 있고, 가용 용량은 내부 메모리에서 현재 이용 가능한 용량을 의미할 수 있다. 예를 들어 가용 용량은 내부 메모리의 총 용 량에서 내부 메모리 이용 용량을 뺀 용량으로 산출될 수 있다. 전자 장치의 전력 상태는 현재 전자 장치의 전력 상태 또는 현재 설정된 전력 모드 등을 의미할 수 있다. 예를 들어 현재 전자 장치의 전력이 충분하지 못한 경우 제1 및 제2 정보를 모두 업로드하게 되면, 부하가 클 수 있다. 이에 따라 프로세서는 제1 정보 만을 로딩하여 가중치 매트릭스를 획득할 수 있다. 또 는, 전자 장치가 저전력 모드인 경우 제1 정보 만을 로딩하여 가중치 매트릭스를 획득할 수 있다. 전자 장치에서 실행되는 어플리케이션의 리소스는 현재 실행 중인 어플리케이션에서 이용되는 인공 지능 모델이 요구하는 가중치 매트릭스의 정확도와 관련된 것일 수 있다. 예를 들어, 현재 실행 중인 어플리케이션에 서 이용되는 가중치 매트릭스가 제1 정보 만으로 획득 가능한 제1 가중치 매트릭스인 경우 제1 정보 만을 로딩 하고, 현재 실행 중인 어플리케이션에서 이용되는 가중치 매트릭스가 제1 정보 및 제2 정보로 획득 가능한 제2 가중치 매트릭스인 경우 제1 정보 및 제2 정보를 모두 로딩 할 수 있다. 한편, 동일한 어플리케이션 또는 동일한 인공 지능 모델을 이용하는 경우에도 요구 리소스가 실시간으로 달라질 수 있다. 예를 들어, 동일한 어플리케이션에서 제1 기능을 수행하는데 요구되는 가중치 매트릭스 및 제2 기능을 수행하는데 요구되는 가중치 매트릭스가 상이할 수 있다. 구체적인 동작은 도 12 및 도 13에서 후술한다. 상술한 바와 같이 프로세서는 전자 장치의 리소스 정보에 기초하여 제1 클래스에 대응되는 가중치 정 보 즉, 제1 정보를 이용할지 아니면 제1 클래스 및 제2 클래스에 대응되는 가중치 정보 즉, 제1 정보 및 제2 정 보를 모두 이용할지 결정할 수 있다. 프로세서는 상술한 바와 같이 리소스 정보에 기초하여 클래스 조합을 식별하고, 식별된 클래스 조합에 대 응되는 가중치 정보를 획득할 수 있다. 그리고, 프로세서는 획득된 가중치 정보에 기초하여 가중치 매트릭 스를 획득할 수 있다. 그리고, 프로세서는 획득된 가중치 매트릭스와 입력 데이터에 기초하여 출력 데이터 를 획득할 수 있다. 한편, 리소스 정보는 실시간으로 변경될 수 있으며, 프로세서는 실시간으로 전자 장치의 리소스 정보 를 획득할 수 있다. 그리고, 프로세서는 획득된 리소스 정보에 기초하여 리소스가 임계값 이상 변경된 것으로 식별되면, 프로세서는 새로운 가중치 매트릭스를 획득할 수 있다. 여기서, 임계값은 내부 메모리의 가용 리소스, 클래스별 리소스에 기초하여 획득될 수 있다. 리소스 정보가 변경되는 실시 예는 현재 이용되는 리소스가 증가하는 경우와 감소하는 경우가 있을 수 있다. 현 재 이용 중인 리소스가 감소하는 경우는 가용 리소스가 증가하는 것이므로 처리 동작에 문제가 없지만, 현재 이 용 중인 리소스가 증가하는 경우 가용 리소스가 감소하는 것이므로 문제가 발생할 수 있다. 이하에서는 설명의 편의를 위하여 전자 장치의 리소스 정보가 프로세서의 내부 메모리의 가용 용량과 관련된 것으로 상정하여 설명하도록 한다. 프로세서는 실시간으로 내부 메모리의 가용 용량을 판단할 수 있다. 프로세서는 현재 제1 및 제2 정 보를 이용하여 획득된 제2 가중치 매트릭스를 이용하는 도중 내부 메모리의 가용 용량이 감소하는 경우 제2 가 중치 매트릭스를 제1 가중치 매트릭스로 변경하기 위하여 제2 가중치 매트릭스에서 제2 정보를 제외시켜, 제1 매트릭스를 획득할 수 있다. 한편, 인공 지능 분석의 대상이 증가하거나, 상대적으로 높은 정확도가 요구되는경우가 있을 수 있다. . 프로세서는 현재 제1 정보를 이용하여 획득된 제1 가중치 매트릭스를 이용하는 도 중 인공 지능 분석의 대상이 증가하는 경우, 제1 가중치 매트릭스를 제2 가중치 매트릭스로 변경하기 위하여 제 1 가중치 매트릭스에 제2 정보를 추가하여, 제2 가중치 매트릭스를 획득할 수 있다. 이하에서는 제1 정보, 또 는 제1 정보 및 제2 정보를 이용하여 제1 가중치 매트릭스 또는 제2 가중치 매트릭스를 획득하는 구체적 방법에 대해 설명하도록 한다. 프로세서는 인공 지능 모델에 적용할 제1 가중치 매트릭스가 필요한 경우, 제1 클래스에 대응되는 제1 가 중치 정보 (또는 제1 정보)를 획득할 수 있다. 또한, 제1 가중치 정보는 제1 클래스에 포함된 가중치, 제1 클래 스에 포함된 가중치에 대응되는 제1 인덱스를 포함할 수 있다. 여기서, 제1 인덱스는 복수의 가중치 각각에 대 응되는 복수의 인덱스를 포함할 수 있다. 예를 들어, 제1 클래스에 포함된 가중치가 3개이면 제1 인덱스도 3개 일 수 있다. 일 실시 예에 따른 프로세서는 제1 가중치 정보에 기초하여 제1 가중치 매트릭스를 획득할 수 있다. 여기 서, 제1 가중치 매트릭스는 제1 클래스만을 이용하여 획득된 것이며 상대적으로 높은 가중치가 반영된 매트릭스 일 수 있다. 프로세서는 인공 지능 모델에 적용할 제2 가중치 매트릭스가 제1 클래스에 대응되는 제1 가중치 정보(또는 제1 정보)뿐 아니라, 제2 클래스에 대응되는 제2 가중치 정보 (또는 제2 정보)를 획득할 수 있다. 제2 가중치 정보는 제2 클래스에 포함된 가중치, 제2 클래스에 포함된 가중치에 대응되는 제2 인덱스를 포함할 수 있다. 여 기서, 제2 클래스에 포함된 가중치는 제1 클래스에 포함된 가중치와 함께 제2 가중치 매트릭스를 구성하는데 이 용되므로, 이하에서 추가 가중치라고 명명하도록 한다. 한편, 프로세서는 제1 인덱스 및 제2 인덱스에 기초하여 제1 가중치 정보에 포함된 가중치에 추가 가중치 를 결합하여 제2 가중치 매트릭스를 획득할 수 있다. 구체적으로, 프로세서는 제1 인덱스에 기초하여 제2 가중치 매트릭스에서 제1 인덱스에 대응되는 가중치의 위치를 결정할 수 있고, 제2 인덱스에 기초하여 제2 가중치 매트릭스에서 제2 인덱스에 대응되는 추가 가중치의 위치를 결정할 수 있고, 제1 인덱스에 대응되는 가중치의 위치 및 제2 인덱스에 대응되는 가중치의 위치에 기초 하여 제1 인덱스 또는 제2 인덱스 중 적어도 하나를 변경할 수 있고, 가중치의 위치, 추가 가중치의 위치 및 변 경된 인덱스에 기초하여 제2 가중치 매트릭스를 획득할 수 있다. 프로세서는 제2 가중치 매트릭스를 생성함에 있어, 제1 가중치 정보에 포함된 가중치의 위치를 제1 가중치 정보에 포함된 제1 인덱스에 기초하여 식별할 수 있고, 제2 가중치 정보에 포함된 가중치(추가 가중치)의 위치 를 제2 가중치 정보에 포함된 제2 인덱스에 기초하여 식별할 수 있다. 여기서, 제2 가중치 매트릭스를 생성함에 있어, 프로세서는 필요에 따라 제1 인덱스 또는 제2 인덱스 중 적어도 하나가 변경될 수 있다. 제2 가중치 매트릭스는 제1 가중치 정보 및 제2 가중치 정보가 결합되는 것이므 로 제1 인덱스 및 제2 인덱스를 그대로 이용할 수 없다. 따라서, 제2 가중치 매트릭스를 생성함에 있어 제1 인 덱스 또는 제2 인덱스 값들은 변경될 수 있다. 단, 최초로 저장되는 초기 인덱스 (제1 인덱스 또는 제2 인덱스 중 어느 하나)은 변경되지 않을 수 있다. 예를 들어, 도 5a에서 제1 가중치 정보에 포함된 제1 인덱스는 {3,1 0}이고 제2 가중치 정보에 포함된 제2 인덱스는 {9}이다. 하지만, 새로 생성된 가중치 정보의 인덱스는 {3,5, 4}이다. 초기 인덱스인 3만 유지되고 제1 인덱스 및 제2 인덱스 모두 값이 변경될 수 있다. 결합 동작에 기초하여 새로운 가중치 정보 및 새로운 가중치 매트릭스를 생성하는 구체적인 동작은 도 5a 및 도 9에서 기재한다. 한편, 제1 가중치 정보는 가중치 정보에서 제1 임계값 미만의 가중치를 프루닝(pruning)하여 획득된 정보에서 제2 임계값 이상의 가중치 및 제2 임계값 이상의 가중치에 대응되는 인덱스를 포함할 수 있고, 제2 가중치 정보 는 프루닝하여 획득된 정보에서 제2 임계값 미만의 가중치 및 제2 임계값 미만의 가중치에 대응되는 인덱스를 포함할 수 있다. 여기서, 가중치 정보는 클래스에 따라 구분되지 않은 초기 가중치들의 그룹을 의미할 수 있다. 가중치 정보는 도 7의 706에 대응될 수 있다. 여기서, 프루닝 동작이란 임계값 미만의 가중치를 0으로 변경하는 동작을 의미할 수 있다. 프로세서는 가 중치 정보에 포함된 복수의 가중치들 중 제1 임계값 미만의 가중치를 0으로 변경하는 프루닝 동작을 수행할 수 있다.프루닝 동작을 수행하여 변경된 가중치 정보를 프루닝된 가중치 정보로 기재할 수 있다. 프루닝된 가중치 정보 는 도7의 711에 대응될 수 있다. 프로세서는 프루닝된 가중치 정보에 포함된 복수의 가중치들을 복수의 클래스로 구분할 수 있다. 구체적으 로, 프로세서는 프루닝된 가중치 정보에 포함된 복수의 가중치들을 가중치 크기값에 기초하여 복수의 클래 스로 구분할 수 있다. 프로세서는 프루닝된 가중치 정보에 포함된 복수의 가중치들 중 가중치의 크기값(또 는 가중치의 중요도)이 제2 임계값 이상인 경우 제1 클래스로 할당하고, 제2 임계값 미만인 경우 제2 클래스로 할당할 수 있다. 제1 클래스에는 상대적으로 높은 크기값의 가중치가 할당되고 제2 클래스에는 상대적으로 낮은 크기값의 가중치가 할당될 수 있다. 여기서, 제1 임계값과 제2 임계값은 다른 기준으로 이용될 수 있으며, 상이 한 값을 가질 수 있다. 한편, 프로세서는 프루닝된 가중치 정보에 포함된 복수의 가중치들 중 제1 클래스에 포함된 가중치 및 제1 클래스에 포함된 가중치에 대응되는 제1 인덱스를 획득할 수 있다. 또한, 프로세서는 프루닝된 가중치 정 보에 포함된 복수의 가중치들 중 제2 클래스에 포함된 가중치 및 제2 클래스에 포함된 가중치에 대응되는 제2 인덱스를 획득할 수 있다. 한편, 제1 정보는 프루닝하여 획득된 정보(프루닝된 가중치 정보)에서 제2 임계값 이상의 가중치를 제1 학습하 여 획득된 가중치 및 제1 학습하여 획득된 가중치에 대응되는 인덱스를 포함할 수 있고, 제2 정보는 프루닝하여 획득된 정보(프루닝된 가중치 정보)에서 제2 임계값 이상의 가중치 및 제2 임계값 미만의 가중치를 제2 학습하 여 제2 학습하여 획득된 가중치에 대응되는 인덱스를 포함할 수 있고, 제2 학습시에 제2 임계값 이상의 가중치 는 고정될 수 있다. 여기서, 제1 학습 및 제2 학습은 재학습(retraining) 과정에 해당할 수 있다. 재학습 과정이란 변형된 가중치 정보에 대하여 오차를 줄이기 위하여 확인하는 과정을 의미할 수 있다. 재학습 과정에서 기존 가중치 정보가 변 경될 수 있다. 제1 학습은 하나의 클래스에 대하여 재학습하는 것일 수 있고 제2 학습은 복수개의 클래스에 대 하여 재학습하는 것일 수 있다. 도 14a의 S1421 단계를 참고하면, 특정 클래스에 포함된 가중치를 재학습하는 경우, 가중치가 변경될 수 있다. 프로세서는 프루닝된 가중치 정보에서 제2 임계값 이상인 가중치를 제1 클래스에 할당할 수 있다. 그리고, 프로세서는 제1 클래스에 할당된(포함된) 가중치를 재학습(제1 학습)할 수 있다. 여기서, 제1 클래스에 포 함된 가중치는 재학습(제1 학습)되는 과정에서 변경될 수 있다. 도 14a의 S1426 단계를 참고하면, 복수개의 클래스에 포함된 가중치를 재학습하는 경우, 복수개의 클래스 중 일 부 클래스에 대해서 가중치가 변경되지 않을 수 있고 복수개의 클래스 중 나머지 클래스에 대해서 가중치가 변 경될 수 있다. 프로세서는 프루닝된 가중치 정보에서 제2 임계값 이상인 가중치를 제1 클래스에 할당할 수 있고 프루닝된 가중치 정보에서 제2 임계값 미만인 가중치를 제2 클래스에 할당할 수 있다. 그리고, 프로세서 는 제1 클래스 및 제2 클래스에 할당된(포함된) 가중치를 재학습(제2 학습)할 수 있다. 여기서, 제1 클래 스에 포함된 가중치는 재학습(제2 학습)되는 과정에서 고정되고, 제2 클래스에 포함된 가중치만 재학습(제2 학 습)되는 과정에서 변경될 수 있다. 복수의 클래스에 재학습 동작을 수행하는 경우, 상대적으로 가중치가 높은 클래스에 포함된 가중치가 고정되고 상대적으로 가중치가 낮은 클래스에 포함된 가중치가 변경될 수 있다. 한편, 프로세서는 가중치 정보에 기초하여 프루닝 동작을 수행하고, 프루닝된 가중치 정보에서 제로 스킵 핑 동작을 수행할 수 있으며, 프루닝 및 제로 스킵핑 동작이 수행된 가중치 정보를 복수의 클래스로 구분할 수 있다. 제로 스킵핑 동작에 대해선 도3 및 도7에서 후술한다. 한편, 실시 예에 따라, 프루닝 동작, 제로 스킵핑 동작, 복수의 클래스로 구분하는 동작 중 적어도 어느 하나가 생략될 수 있으며, 순서 역시 변경될 수 있다. 한편, 제1 가중치 매트릭스는 제1 가중치 정보를 이용하여 획득된 매트릭스일 수 있으며, 제2 가중치 매트릭스 는 제1 가중치 정보 및 제2 가중치 정보를 이용하여 획득된 매트릭스일 수 있다. 구체적으로, 프로세서는 제2 가중치 매트릭스를 생성하기 위하여 제1 가중치 정보 및 제2 가중치 정보를 결합하여 제3 가중치 정보를 획 득할 수 있다. 제3 가중치 정보는 제1 클래스 및 제2 클래스에 포함된 가중치 및 제1 클래스 및 제2 클래스에 포함된 가중치에 대응되는 인덱스(제3 인덱스)를 포함할 수 있다. 그리고, 프로세서는 획득된 제3 가중치 정보에 기초하여 제2 가중치 매트릭스를 획득할 수 있다. 프로세서는 기존 가중치 정보에서 특정 클래스에 포함된 가중치를 제거하는 동작을 수행할 수 있다. 프로 세서가 이미 제1 가중치 정보 및 제2 가중치 정보를 이용하여 제2 가중치 매트릭스를 획득한 것으로 가정 한다. 이미 제2 가중치 매트릭스를 이용하여 인공 지능 분석하는 도중에 내부 메모리의 부족에 따라 리소스가부족한 상황이 있을 수 있다. 여기서, 프로세서는 인공 지능 분석에 필요한 리소스를 줄이기 위하여 가중 치 정보 또는 가중치 매트릭스를 변경할 수 있다. 예를 들어, 프로세서는 리소스를 줄이기 위하여 복수의 클래스 중 가중치가 낮은 클래스에 포함된 가중치를 제거하는 동작을 수행할 수 있다. 프로세서는 제2 가중치 매트릭스에 대응되는 제3 가중치 정보에 포함된 가중치, 가중치에 대응되는 제3 인 덱스 및 제2 인덱스에 기초하여 제3 가중치 정보에서 제2 인덱스에 대응되는 추가 가중치를 제거하여 제1 가중 치 매트릭스를 획득할 수 있다. 여기서, 제2 가중치 매트릭스에 대응되는 제3 가중치 정보는 제1 가중치 정보 및 제2 가중치 정보를 결합한 정 보일 수 있다. 또한, 제3 가중치 정보에 포함된 가중치는 제1 클래스 및 제2 클래스에 포함된 가중치를 의미할 수 있다. 또한, 가중치에 대응되는 제3 인덱스는 제1 클래스 및 제2 클래스에 포함된 가중치에 대응되는 인덱스 를 의미할 수 있다. 또한, 제2 인덱스에 대응되는 추가 가중치는 제2 클래스에 포함된 가중치를 의미할 수 있다. 여기서, 프로세서는 제2 인덱스 및 제3 인덱스에 기초하여 제2 가중치 매트릭스에서 추가 가중치의 위치를 결정할 수 있고, 추가 가중치의 위치에 기초하여 제3 가중치 정보에서 추가 가중치를 제거할 수 있고 제3 가중 치 정보에서 제거된 추가 가중치의 위치와 인접한 가중치의 인덱스를 수정하여 제1 가중치 매트릭스를 획득할 수 있다. 여기서, 추가 가중치는 제2 클래스에 포함된 가중치를 의미할 수 있다. 프로세서는 기 설정된 이벤트에 기초하여 복수의 클래스 중 특정 클래스의 가중치를 제거하는 동작을 수행 할 수 있다. 구체적으로, 프로세서는 전자 장치의 리소스 정보에 기초하여 획득한 제3 가중치 정보 (또는 제2 가중치 매트릭스)에 포함된 가중치(제1 클래스 및 제2 클래스에 포함된 가중치) 중 제2 클래스에 포 함된 가중치를 제거할 수 있다. 프로세서는 복수의 가중치들 중 제2 클래스에 포함된 가중치만을 제거하기 위하여 제2 인덱스를 이용할 수 있다. 제2 인덱스만 알면 제2 클래스에 포함된 가중치의 위치를 파악할 수 있으 므로, 제2 클래스에 포함된 가중치의 크기값(또는 가중치의 중요도)을 모르더라도 제2 클래스에 포함된 가중치 만을 제거할 수 있다. 따라서, 프로세서는 제3 가중치 정보 및 제2 인덱스에 기초하여 제3 가중치 정보(또 는 제2 가중치 매트릭스)에 포함된 가중치(제1 클래스 및 제2 클래스에 포함된 가중치) 중 제2 클래스에 포함된 가중치를 제거할 수 있다. 그리고, 프로세서는 제3 인덱스 중 제거된 가중치와 바로 인접한 위치에 있는 인덱스를 변경할 수 있다. 구체적으로, 프로세서는 인접한 인덱스가 2개이면 2개의 인덱스 각각의 데이터 를 합하여 새로운 인덱스를 획득할 수 있다. 구체적인 계산 과정은 도 10a, 도 10b, 도 10c에서 후술한다. 프로세서는 제3 가중치 정보(또는 제2 가중치 매트릭스)에 포함된 가중치(제1 클래스 및 제2 클래스에 포 함된 가중치) 중 제2 클래스에 포함된 가중치를 제거하여 새로운 가중치 정보를 획득할 수 있다. 여기서, 새로 운 가중치 정보는 제1 가중치 정보에 대응될 수 있다. 프로세서는 획득된 가중치 매트릭스 및 입력 데이터에 기초하여 출력 데이터를 획득할 수 있다. 구체적으 로, 프로세서는 획득된 가중치 매트릭스와 입력 데이터를 이용하여 곱셈 연산을 수행할 수 있고, 연산 결 과로서 출력 데이터를 획득할 수 있다. 본 개시는 다양한 신경망에 대하여 확장 가능한(scalable) 동작 시나리오를 가능하게 함으로써 사용자의 만족도 를 극대화하고, 탑재되는 제품의 경쟁력을 높일 수 있다. 또한, 본 개시는 소비 전력에 따른 동작 지점의 선택 이 가능하기 때문에 메모리 용량이 낮은 전자 장치(예를 들어, 모바일 기기)의 사용자 만족도를 극대화 할 수 있다. 구체적으로, 본 개시는 가중치 정보를 복수의 클래스로 구분하여 전자 장치의 리소스 정보에 기초하여 클래스 조합을 결정할 수 있다. 따라서, 리소스가 부족한 상황에서도 클래스 조합을 적절히 선택하거나 새로운 가중치 매트릭스를 생성함으로써 인공 지능 분석을 수행할 수 있다. 한편, 본 개시는 전자 장치 가중치가 저장되는 형식이 RLC (run length coding)인 것으로 기재하였다. 하 지만, 실시 예에 따라 가중치가 저장되는 형식이 CSR(compressed sparse row), CSC(compressed sparse colum n)일 수 있다. CSR은 매트릭스에서 가로의 순서대로 재정렬하는 방법으로 행에 관여하여 정리 압축하는 방식을 의미할 수 있다. CSC는 매트릭스에서 가로와 세로의 순서대로 재정렬하는 방법으로 행에 관여하여 정리하는 방 식을 CSR 열에 관하여 적용하는 것을 의미할 수 있다. 한편, 이상에서는 전자 장치를 구성하는 간단한 구성에 대해서만 도시하고 설명하였지만, 구현 시에는 다 양한 구성이 추가로 구비될 수 있다. 이에 대해서는 도 2를 참조하여 이하에서 설명한다. 도 2는 도 1의 전자 장치의 구체적인 구성을 설명하기 위한 블록도이다. 도 2를 참조하면, 전자 장치는 메모리, 프로세서, 통신 인터페이스, 디스플레이, 사 용자 인터페이스 및 입출력 인터페이스로 구성될 수 있다. 한편, 메모리 및 프로세서의 동작 중에서 앞서 설명한 것과 동일한 동작에 대해서는 중복 설명은 생 략한다. 프로세서는 메모리에 저장된 각종 프로그램을 이용하여 전자 장치의 동작을 전반적으로 제어한 다. 구체적으로, 프로세서는 RAM, ROM, 메인 CPU, 제1 내지 n 인터페이스, 버스를 포함한다. RAM, ROM, 메인 CPU, 제1 내지 n 인터페이스 등은 버스를 통해 서로 연결될 수 있다. ROM에는 시스템 부팅을 위 한 명령어 세트 등이 저장된다. 턴온 명령이 입력되어 전원이 공급되면, 메인 CPU는 ROM에 저장된 명령어에 따 라 메모리에 저장된 O/S를 RAM에 복사하고, O/S를 실행시켜 시스템을 부팅시킨다. 부팅이 완료되면, 메인 CPU는 메모리에 저장된 각종 어플리케이션 프로그램을 RAM에 복사하고, RAM에 복사된 어플리케이션 프로그 램을 실행시켜 각종 동작을 수행한다. 메인 CPU는 메모리에 액세스하여, 메모리에 저장된 O/S를 이용 하여 부팅을 수행한다. 그리고, 메모리에 저장된 각종 프로그램, 컨텐츠 데이터 등을 이용하여 다양한 동 작을 수행한다. 제1 내지 n 인터페이스는 상술한 각종 구성 요소들과 연결된다. 인터페이스들 중 하나는 네트워 크를 통해 외부 장치와 연결되는 네트워크 인터페이스가 될 수도 있다. 통신 인터페이스는 다양한 유형의 통신 방식에 따라 다양한 유형의 외부 장치와 통신을 수행하는 구성이다. 통신 인터페이스는 와이파이 모듈, 블루투스 모듈, 적외선 통신 모듈 및 무선 통신 모듈 등을 포함한다. 여기서, 각 통신 모듈은 적어도 하나의 하드웨어 칩 형태로 구현될 수 있다. 와이파이 모듈, 블루투스 모듈은 각각 WiFi 방식, 블루투스 방식으로 통신을 수행한다. 와이파이 모듈이나 블루 투스 모듈을 이용하는 경우에는SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신하여, 이를 이용하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 적외선 통신 모듈은 시 광선과 밀리미터파 사이에 있는 적외선을 이용하여 근거리에 무선으로 데이터를 전송하 는 적외선 통신(IrDA, infrared Data Association)기술에 따라 통신을 수행한다. 무선 통신 모듈은 상술한 통신 방식 이외에 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation)등과 같은 다양한 무선 통신 규격에 따라 통신을 수행하는 적어도 하나의 통신 칩을 포함할 수 있다. 그 밖에 통신 인터페이스는LAN(Local Area Network) 모듈, 이더넷 모듈, 또는 페어 케이블, 동축 케이블 또는 광섬유 케이블 등을 이용하여 통신을 수행하는 유선 통신 모듈 중 적어도 하나를 포함할 수 있다. 일 예에 따라 통신 인터페이스는 리모컨과 같은 외부 장치 및 외부 서버와 통신하기 위해 동일한 통신 모 듈(예를 들어, Wi-Fi 모듈)을 이용할 수 있다. 다른 예에 따라 통신 인터페이스는 리모컨과 같은 외부 장치 및 외부 서버와 통신하기 위해 상이한 통신 모듈(예를 들어, Wi-Fi 모듈)을 이용할 수 있다. 예를 들어, 통신 인터페이스는 외부 서버와 통신하기 위 해 이더넷 모듈 또는 WiFi 모듈 중 적어도 하나를 이용할 수 있고, 리모컨과 같은 외부 장치와 통신하기 위해 BT 모듈을 이용할 수도 있다. 다만 이는 일 실시 예에 불과하며 통신 인터페이스는 복수의 외부 장치 또는 외부 서버와 통신하는 경우 다양한 통신 모듈 중 적어도 하나의 통신 모듈을 이용할 수 있다. 디스플레이는 LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플레이, PDP(Plasma Display Panel) 등과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 디스플레이내에는 a- si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 한편, 디스플레이는 터치 센서와 결합된 터치 스크린, 플 렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display) 등으로 구현될 수 있다. 또한, 본 개시의 일 실시 예에 따른, 디스플레이는 영상을 출력하는 디스플레이 패널뿐만 아니라, 디스플 레이 패널을 하우징하는 베젤을 포함할 수 있다. 특히, 본 개시의 일 실시 예에 따른, 베젤은 사용자 인터렉션 을 감지하기 위한 터치 센서(미도시)를 포함할 수 있다.사용자 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린으로도 구현될 수 있다. 여기서, 버튼은 전자 장치 의 본체 외관의 전면부나 측면부, 배면부 등의 임의의 영역에 형성된 기계적 버튼, 터치 패드, 휠 등과 같 은 다양한 유형의 버튼이 될 수 있다. 입출력 인터페이스는 HDMI(High Definition Multimedia Interface), MHL (Mobile High-Definition Link), USB (Universal Serial Bus), DP(Display Port), 썬더볼트(Thunderbolt), VGA(Video Graphics Array) 포트, RGB 포트, D-SUB(D-subminiature), DVI(Digital Visual Interface) 중 어느 하나의 인터페이스일 수 있 다. 입출력 인터페이스는 오디오 및 비디오 신호 중 적어도 하나를 입출력 할 수 있다. 구현 예에 따라, 입출력 인터페이스는 오디오 신호만을 입출력하는 포트와 비디오 신호만을 입출력하는 포 트를 별개의 포트로 포함하거나, 오디오 신호 및 비디오 신호를 모두 입출력하는 하나의 포트로 구현될 수 있다. 전자 장치는 스피커(미도시)를 포함할 수 있다. 스피커(미도시)는 입출력 인터페이스에서 처리된 각 종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시지 등을 출력하는 구성요소일 수 있다. 전자 장치는 마이크(미도시)를 더 포함할 수 있다. 마이크는 사용자 음성이나 기타 소리를 입력 받아 오디 오 데이터로 변환하기 위한 구성이다. 마이크(미도시)는 활성화 상태에서 사용자의 음성을 수신할 수 있다. 예를 들어, 마이크는 전자 장치의 상 측이나 전면 방향, 측면 방향 등에 일체형으로 형성될 수 있다. 마이크는 아날로그 형태의 사용자 음성을 수집 하는 마이크, 수집된 사용자 음성을 증폭하는 앰프 회로, 증폭된 사용자 음성을 샘플링하여 디지털 신호로 변환 하는 A/D 변환회로, 변환된 디지털 신호로부터 노이즈 성분을 제거하는 필터 회로 등과 같은 다양한 구성을 포 함할 수 있다. 카메라(미도시)는 피사체를 촬상하여 촬상 영상을 생성하기 위한 구성이며, 여기서 촬상 영상은 동영상과 정지 영상 모두를 포함하는 개념이다. 카메라(미도시)는 적어도 하나의 외부 기기에 대한 이미지를 획득할 수 있으며, 카메라, 렌즈, 적외선 센서 등 으로 구현될 수 있다. 카메라(미도시)는 렌즈와 이미지 센서를 포함할 수 있다. 렌즈의 종류에는 일반적인 범용 렌즈, 광각 렌즈, 줌 렌즈 등이 있으며, 전자 장치의 종류, 특성, 사용 환경 등에 따라 결정될 수 있다. 이미지 센서로는 상보 성 금속 산화물 반도체(Complementary Metal Oxide Semiconductor: CMOS)와 전하결합소자(Charge Coupled Device: CCD) 등이 사용될 수 있다. 카메라(미도시)는 입사된 빛을 영상 신호로 출력한다. 구체적으로, 카메라(미도시)는 렌즈, 화소 및 AD 컨버터 를 구비할 수 있다. 렌즈는 피사체의 빛을 모아서 촬상 영역에 광학상이 맺히게 하며, 화소는 렌즈를 통해 입상 되는 빚을 아날로그 형태의 영상 신호로 출력할 수 있다. 그리고 AD 컨버터는 아날로그 형태의 영상 신호를 디 지털 형태의 영상 신호로 변환하여 출력할 수 있다. 특히, 카메라(미도시)는 전자 장치의 전면 방향을 촬 상하도록 배치되어, 전자 장치의 전면에 존재하는 사용자를 촬상하여 촬상 영상을 생성할 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치를 설명함에 있어 카메라(미도시)가 한 개인 것으로 설명하 고 있지만, 실제 구현 시에는 복수개의 촬상부가 배치될 수 있다. 전자 장치는 복수개의 촬상부를 구비할 수 있고, 복수개의 촬상부를 통해 수신되는 영상을 결합하여 사용자의 머리 자세를 식별할 수 있다. 한 개의 카 메라를 이용하는 것보다 복수개의 카메라를 이용하면 3차원적인 움직임을 더욱 정밀하게 분석할 수 있어 사용자 의 머리 자세를 식별하는데 효과적일 수 있다. 도 3은 본 개시의 일 실시 예에 따른 제로 스킵핑 동작을 설명하기 위한 도면이다. 도 3을 참조하면, 전자 장치는 일 실시 예에 따라 일반적인 방법으로 입력 데이터를 처리하거나 제로 스킵핑(zerp-skipping) 방법에 기초하여 입력 데이터를 처리할 수 있다. 일반적인 방법은 가중치 정보 및 입력 데이터 를 곱하는 방법일 수 있다. 일반적인 방법 에서는 가중치 정보에서 어떠한 변형을 가하지 않을 수 있으며 이미 획득된 가중치를 그대로 이용하는 방 법일 수 있다. 가중치 정보는 가중치가 0인 데이터와 가중치가 0이 아닌 데이터로 구분될 수 있다. 가중치가 0인 데이터는 복수의 그룹으로 구분될 수 있으며, 복수의 그룹(306-1,306-2,306-3)은 연속하는 0 데이터를 기준으로 구분될 수 있다. 가중치 정보에서 0이 아닌 데이터는 {0.7,-0.1,0.86}일 수 있다. 그리고, 전자 장치 는 일반적인 방법에 따라 가중치 정보 및 입력 데이터 각각을 곱할 수 있다. 여기서, 전자 장 치는 총 15번의 곱셈 계산을 수행할 수 있다. 한편, 제로 스킵핑 방법은 가중치 정보에서 0의 데이터를 갖는 가중치를 스킵하는 방법일 수 있다. 여기서, 스킵 동작은 0을 곱하는 계산 과정을 수행하지 않는 것을 의미할 수 있다. 예를 들어, 제로 스킵핑 방 법은 가중치 정보에서 0 가중치 정보를 제외하고 0의 개수를 인덱스로 이용하는 것일 수 있다. 그리 고, 제로 스킵핑 방법은 각 그룹들(306-1,306-2,306-3)에 포함된 0의 개수를 획득할 수 있다. 복수의 그룹 (306-1,306-2,306-3)의 0의 개수는 3개, 5개, 4개일 수 있다. 그리고 0의 개수 정보는 인덱스로 이용될 수 있다. 예를 들어, 전자 장치는 복수의 그룹(306-1,306-2,306-3)의 0의 개수 정보를 인덱스(311-1,311- 2,311-3)로 이용할 수 있다. 제1 그룹(306-1)의 인덱스(311-1)는 스킵하는 입력 데이터(12,2,9)의 개수(3개)를 의미할 수 있다. 그리고, 제2 그룹(306-2)의 인덱스(311-2)는 스킵하는 입력 데이터(45,6,23,3,12)의 개수(5 개)를 의미할 수 있다. 그리고, 제3 그룹(306-3)의 인덱스(311-3)는 스킵하는 입력 데이터(9,1,45,6)의 개수(4 개)를 의미할 수 있다. 그리고, 제로 스킵핑 방법은 가중치 정보 중 0이 아닌 데이터(0.7,- 0.1,0.86)에 대해서 각각 입력 데이터(1,2,23)를 곱할 수 있다. 결과적으로, 전자 장치는 제로 스킵핑 동 작에 의하여 가중치 정보에 기초하여 {3,0.7,5,-0.1,4,0.86}에 해당하는 가중치 정보를 획득할 수 있다. 그리고, 여기서, “3,5,4”는 인덱스이고 “0.7,-0.1,0.86”은 가중치일 수 있다. 전자 장치는 일반적인 방법에 의하면 총 15번의 계산 과정을 수행해야 하지만, 제로 스킵핑 방법 에 의하면 3번의 계산 과정을 수행하면 되므로, 계산 과정을 단순화 시킬 수 있다. 도 4는 본 개시의 다른 실시 예에 따른 제로 스킵핑 동작을 설명하기 위한 도면이다. 도 4를 참조하면, 전자 장치는 가중치의 크기값(또는 가중치의 중요도)에 기초하여 제로 스킵핑 동작을 수 행할 수 있다. 전자 장치는 가중치의 크기값(또는 가중치의 중요도)이 임계값 이상인 가중치만을 획득하여 제로 스킵핑 동작을 수행하거나, 가중치의 크기값(또는 가중치의 중요도)이 임계값 미만인 가중치만을 획 득하여 제로 스킵핑 동작을 수행할 수 있다. 401 동작과 관련하여, 전자 장치는 가중치 정보에서 0과 0이 아닌 데이터(0.7,-0.1,0.86)을 구분할 수 있다. 그리고, 0이 아닌 데이터(0.7,-0.1,0.86)에서 임계값(예를 들어, 0.2) 이상의 가중치(0.7,0.86)를 식 별할 수 있다. 전자 장치는 0이 아닌 데이터 중 임계값(0.2)보다 작은 가중치(-0.1)를 0과 동일하게 판단 할 수 있다. 그리고, 전자 장치는 가중치 정보를 0인 데이터 그룹(406-1,406-2)과 0이 아닌 데이터 그룹(407-1,407-2)으로 구분할 수 있다. 그리고, 도 3에서 설명한 바와 같이 전자 장치는 가중치가 0인 데 이터 그룹 각각에서 0의 개수를 식별할 수 있다. 406-1 그룹에 대응되는 0의 개수는 3이며, 406-2 그룹에 대응 되는 0의 개수는 10이다. 여기서, 전자 장치는 임계값(0.2)보다 작은 가중치도 0의 개수에 포함시켜 계산 할 수 있다. 예를 들어, “-0.1”은 0이 아니지만, 가중치가 0.2보다 작은 경우 데이터를 0으로 판단하므로, “ -0.1”도 0의 개수에 포함시켜 계산할 수 있다. 401 동작과 관련하여, 전자 장치는 획득된 0의 개수를 인덱스로 이용할 수 있다. 406-1 그룹에 대응되는 0 의 개수는 3이며, 전자 장치는 획득된 0의 개수를 406-1 그룹에 대응되는 인덱스(411-1)로 이용할 수 있다. 그리고, 406-2 그룹에 대응되는 0의 개수는 10이며, 전자 장치는 획득된 0의 개수를 406-2 그룹 에 대응되는 인덱스(411-2)로 이용할 수 있다. 401 동작과 관련하여, 전자 장치는 가중치 정보, 기 설정된 임계값 및 획득된 인덱스(411-1,411-2)에 기초하여 제1 가중치 정보를 획득할 수 있다. 제1 가중치 정보는 인덱스(411-1,411-2), 가중치(407- 1,407-2) 및 순서 정보(411-1,407-1,411-2,407-2 순서)를 포함할 수 있다. 가중치 정보와 가중치 정보는 모두 가중치와 관련된 정보에 해당할 수 있다. 다만, 설명의 편의를 위 하여 최초의 가중치는 가중치 정보로 기재하고 제로 스킵핑 동작에 의하여 변경된 가중치를 가중치 정보로 기재 할 수 있다. 401 동작은 가중치 크기가 임계값 (0.2) 이상인 경우 가중치 정보로부터 제로 스킵핑 동작을 수행하여 가 중치 제1 를 획득하는 과정을 설명한 것이다. 402 동작과 관련하여, 전자 장치는 가중치 크기가 임계값(0.2)미만인 경우 가중치 정보로부터 제로 스킵핑 동작을 수행하여 가중치 정보를 획득할 수 있다. 402 동작과 관련하여, 전자 장치는 가중치 정보에서 0과 0이 아닌 데이터(0.7,-0.1,0.86)을 구분할 수 있다. 그리고, 0이 아닌 데이터(0.7,-0.1,0.86)에서 임계값(예를 들어, 0.2) 미만의 가중치(-0.1)를 식별할 수 있다. 전자 장치는 0이 아닌 데이터 중 임계값(0.2) 이상인 가중치(0.7,0.86)를 0과 동일하게 판단할 수 있다. 여기서, 전자 장치는 0이 아닌 데이터 중에서 마지막 위치에 식별된 임계값(0.2) 미만의 가중치 (-0.1)이후의 가중치를 판단하지 않을 수 있다. 이미 401 동작에 의하여 가중치(0.86)가 반영되어 있으므로, 마 지막으로 식별된 가중치(-0.1) 이후의 가중치를 판단하지 무시하여 가중치 정보에 포함시키지 않을 수 있 다. 그리고, 전자 장치는 가중치 정보를 0인 데이터 그룹(406-3)과 0이 아닌 데이터(407-3)로 구분할 수 있다. 그리고, 도 3에서 설명한 바와 같이 전자 장치는 가중치가 0인 데이터 그룹 각각에서 0의 개수를 식별할 수 있다. 406-3 그룹에 대응되는 0의 개수는 9 이다. 여기서, 전자 장치는 임계값(0.2) 이상인 가 중치도 0의 개수에 포함시켜 계산할 수 있다. 예를 들어, “0.7”은 0이 아니지만, 가중치가 0.2이상인 경우 데 이터를 0으로 판단하므로, “0.7”도 0의 개수에 포함시켜 계산할 수 있다. 402 동작과 관련하여, 전자 장치는 획득된 0의 개수를 인덱스로 이용할 수 있다. 406-3 그룹에 대응되는 0 의 개수는 9이며, 전자 장치는 획득된 0의 개수를 406-3 그룹에 대응되는 인덱스(411-3)로 이용할 수 있다. 402 동작과 관련하여, 전자 장치는 가중치 정보, 기 설정된 임계값 및 획득된 인덱스(411-3)에 기초 하여 가중치 정보를 획득할 수 있다. 가중치 정보는 인덱스(411-3), 가중치(407-3) 및 순서 정보 (411-3,407-3 순서)를 포함할 수 있다. 전자 장치는 복수의 클래스로 가중치 정보를 구분할 수 있다. 여기서, 클래스는 인공 지능 분석에 이 용되는 복수의 가중치를 구분하는 단위를 의미할 수 있다. 클래스는 가중치의 크기값(또는 가중치의 중요도)에 기초하여 구분될 수 있다. 예를 들어, 인공 지능 분석에 100개의 가중치가 이용된다고 가정한다. 100개의 가중 치 중 가중치 값이 임계값 이상인 가중치를 제1 클래스에 할당하고 100개의 가중치 중 가중치 값이 임계값 미만 인 가중치를 제2 클래스에 할당할 수 있다. 한편, 클래스의 개수, 임계값 개수 및 임계값은 실시 예에 따라 달 라질 수 있다 예를 들어, 제1 클래스는 제1 가중치 크기 기준(예를 들어, 가중치의 크기값이 0.2 이상)에 따라 획득되는 제1 가중치 정보와 관련된 정보를 의미하고 제2 클래스는 제2 가중치 크기 기준(예를 들어, 가중치의 크기값이 0.2 미만)에 따라 획득되는 가중치 정보와 관련된 정보를 의미할 수 있다. 전자 장치는 복수의 클래스에 대응되는 가중치 정보(410,415)를 획득할 수 있다. 제1 가중치 정보는 상대적으로 가중치가 큰 데이터를 그룹핑한 정보이며, 가중치 정보는 가중치가 작은 데이터를 그룹핑한 정 보일 수 있다. 제1 정보 및 제2 정보를 모두 이용하는 경우, 가중치 정보 모두를 이용하는 것이 므로, 계산의 정확도가 유지될 수 있다. 다만, 전자 장치의 리소스가 부족할 경우, 제1 정보 및 제2 정보를 모두 이용할 수 없으므로, 제1 정보만을 이용하여 계산 동작을 수행할 수 있다. 상대적으로 큰 값의 가중치로 이루어진 제1 정보만을 이용하는 경우, 정확도는 약간 떨어질 수 있으나, 계산 처리 동 작을 정상적으로 수행할 수 있다. 도 5a는 도4의 실시 예에 따른 제로 스킵핑 동작에 의해 생성된 정보에 기초하여 가중치 매트릭스를 획득하는 동작을 설명하기 위한 도면이다. 도 5a를 참조하면, 가중치 정보 는 도 4의 가중치 정보에 대응되며, 가중치 정보(510,515)는 도4의 가중치 정보(410,415)에 대응될 수 있다. 따라서, 가중치 정보 및 복수의 클래스에 대응되는 가중치 정보 (510,515)에 대한 중복 설명을 생략한다. 전자 장치는 획득된 가중치 정보(510,515)를 DRAM에 저장할 수 있으며, 필요에 따라 가중치 정보 (510, 515)를 커널 발생부에 전송할 수 있다. 커널 발생부는 커널 발생 모듈일 수 있으며, 수신되는 적어도 하나의 가중치 정보에 기초하여 새로운 가중 치 정보를 생성할 수 있다. 예를 들어, 커널 발생부는 제1 클래스에 대응되는 제1 가중치 정보 및 제 2 클래스에 대응되는 제2 가중치 정보에 기초하여 새로운 클래스에 대응되는 새로운 가중치 정보를 생성할 수 있다. 여기서, 커널 발생부는 새로운 가중치 정보를 생성하기 위하여 기 정의된 아래의 코 드 정보를 이용할 수 있다. 기 정의된 코드 정보는 스택 구조를 이용하여 데이터를 처리하는 동작과 관련된 코드일 수 있다. 한편, 커널 발생부는 파라미터 발생부일 수 있다. 여기서, 커널 발생부에 의해 생성된 새로운 가중치 정보는 도3에서 제로 스킵핑 동작에 의하여 획득 된 가중치 정보와 동일할 수 있다. 도3에서 개시한 가중치 정보는 가중치 정보로부터 제로 스킵핑 동작을 수행한 것이며, 도5에서 개시한 가중치 정보는 복수의 클래스에 대응되는 가중치 정보(510, 515)에 기초하 여 획득된 것이라는 점에서 차이가 있다. 따라서, 도3의 방법에 의해서는 복수의 클래스에 대응되는 가중치 정 보(510, 515)를 결합하여 새로운 가중치 정보를 획득할 수 없다. 따라서, 커널 발생부는 분리된 가중 치 정보를 결합하여 하나의 통합된 가중치 정보를 생성할 수 있다. 한편, 도 5a에서 개시하고 있는 동작은 아래의 코드를 통해 수행될 수 있다. while (not empty) { for (all classes) { skip_count = pop (class_id, SKIP); if (skip_count < count_min) { count_min = skip_count; class_sel = class_id; } push (class_id, SKIP, skip_count); } for (every classes) { if (class_id != class_sel) { skip_count = pop (class_id, SKIP); skip_count -= (count_min + 1); push (class_id, SKIP, skip_count); } } skip_count = pop (class_sel, SKIP); kernel_val = pop (class_sel, KERNEL); store (skip_count, kernel_val); } 도 5b는 가중치 매트릭스를 획득하는 다른 실시 예의 동작을 설명하기 위한 도면이다. 도 5b를 참조하면, 전자 장치는 클래스별 가중치 정보(510,515)를 DRAM에 저장할 수 있으며, 커널 발 생부에서 생성된 새로운 가중치 정보를 온칩 메모리에 저장할 수 있다. 여기서 가중치 정보 는 제1 클래스에 대응되는 제1 가중치 정보일 수 있고, 가중치 정보는 제2 클래스에 대응되는 제2 가 중치 정보일 수 있다. 그리고, 가중치 정보는 제1 클래스 및 제2 클래스를 결합하여 새로 생성된 가중치 정보일 수 있다. 여기서, 사용자는 실시 예에 따라, 제1 클래스에 대응되는 가중치 정보를 온칩 메모리를 새로 생성하는 동작을 수행할 수 있다. 여기서, 가중치 정보는 인덱스(525-1,525-3,525-5) 및 인덱스(525- 1,525-3,525-5)에 대응되는 가중치들(525-2,525-4,525-6)을 포함할 수 있다. 일 실시 예에 따라, 제1 클래스에 대응되는 가중치 정보를 생성하기 위하여 커널 발생부는 제1 클래스 및 제2 클래스가 결합되어 생성된 가중치 정보를 온칩 메모리로부터 수신하고 제2 클래스에 대응되는 제 2 가중치 정보를 수신할 수 있다. 여기서, 가중치 정보는 인덱스(515-1) 및 인덱스(515-1)에 대응되는 가중치(515-2)를 포함할 수 있다. 일 예로, 커널 발생부는 DRAM로부터 가중치 정보 중 인덱스(515-1)만을 수신할 수 있다. 이미 가중 치에 대한 정보를 온칩 메모리에 저장하고 있기 때문에 가중치(515-2)를 별도로 수신하지 않고 인덱스 (515-1)만을 수신할 수 있다. 그리고, 커널 발생부는 수신된 인덱스(515-1) 및 수신된 가중치 정보에 기초하여 제1 클래스에 대응되는 가중치 정보를 생성할 수 있다. 가중치 정보는 인덱스(530-1,530-3) 및 인덱스(530-1,530-3)에 대응되는 가중치(530-2,530-4)를 포함할 수 있다. 커널 발생부는 가중치 정보 에서 수신된 인덱스(515-1)에 해당하는 “9”에 해당하는 가중치를 제거할 수 있다. 가중치 정보 중 인덱스는 그 자체의 값을 더하고 가중치에 해당하는 부분은 “1”로 환산하여 계산할 수 있다. 구체적으로, 커 널 발생부는 인덱스(525-1) “3”, 가중치(525-2)의 환산값 “1”, 인덱스(525-3) “5”를 더해 9라는 숫 자를 확인할 수 있고, 이후 값인 가중치(525-4) “-0.1”을 삭제할 수 있다. 커널 발생부는 인덱스(525-3) “5” 삭제된 가중치(525-4)의 환산값 “1” 인덱스(525-5) “4”를 모두 더하여 “10”을 획득할 수 있으며, “10”은 새로운 인덱스(530-3)로 이용될 수 있다. 다른 실시 예에 따라, 커널 발생부는 온칩 메모리에 저장된 가중치 정보를 삭제하고, 제1 클래 스에 대응되는 제1 가중치 정보를 DRAM으로부터 수신할 수 있다. 제1 가중치 정보는 새로 생성 된 가중치 정보와 동일할 수 있다. 한편, 도 5b에 개시된 동작들은 도 5a에서 설명한 코드를 이용하여 수행될 수 있다. 코드의 중복 기재를 생략한 다. 도 6a는 가중치 매트릭스를 획득하는 다양한 실시 예를 설명하기 위한 도면이다. 도 6a을 참조하면, 전자 장치는 DRAM, DMAC(Direct Memory Access Controller), 커널 발생부 및 온칩 메모리 중 적어도 하나를 포함할 수 있다. 그리고, 전자 장치는 상술한 복수의 구성 요소 중 적어도 하나에 기초하여 최종 가중치 정보를 획득할 수 있으며, 최종 가중치 정보에 기초하여 인공 지 능 분석을 수행할 수 있다. 전자 장치는 다양한 실시 예에 따라 가중치 정보를 생성 또는 변경하는 동작을 수행할 수 있다. 제1 실시 예는 제1 클래스에 대응되는 가중치 정보가 DRAM에 저장되어 있으며 제1 클래스에 대응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행하는 실시 예를 가정한다. 전자 장치는 제1 클래스에 대 응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행하므로, 별도의 가중치 정보 생성 또는 변경 동작이 필 요하지 않을 수 있다. 따라서, 커널 발생부에 의하여 새로운 가중치 정보를 생성할 필요가 없다. 전자 장 치는 DRAM에 저장된 제1 클래스에 대응되는 가중치 정보를 DMAC으로 전송하고, DMAC에 전 송된 제1 클래스에 대응되는 가중치 정보를 바로 온칩 메모리에 전송할 수 있다. 그리고, 전자 장치 는 온칩 메모리에 전송된 제1 클래스 정보에 대응되는 가중치 정보를 이용하여 인공 지능 분석을 수행할 수 있다. 제1 실시 예에 따른 데이터 처리 방법은 빠른 데이터 처리 속도를 요구하는 경우 이용될 수 있다. 제2 실시 예는 DRAM에 제1 클래스에 대응되는 가중치 정보 및 제2 클래스에 대응되는 가중치 정보를 저장되어 있으며 제1 클래스에 대응되는 가중치 정보 및 제2 클래스에 대응되는 가중치 정보 모두를 이용하여 인공 지능 분석을 수행하는 실시 예를 가정한다. DRAM에는 제1 클래스에 대응되는 가중치 정보 및 제2 클 래스에 대응되는 가중치 정보만이 저장되어 있으며 제1 클래스 및 제2 클래스를 결합한 통합 가중치 정보는 없 으므로, 전자 장치는 통합 가중치 정보를 생성할 수 있다. 통합 가중치 정보를 생성하기 위하여 전자 장치 는 DRAM에 저장된 제1 클래스에 대응되는 가중치 정보 및 제2 클래스에 대응되는 가중치 정보를 DMAC에 전달할 수 있으며, DMAC은 커널 발생부에 다시 제1 클래스에 대응되는 가중치 정보 및 제2 클래스에 대응되는 가중치 정보를 전송할 수 있다. 커널 발생부는 수신된 제1 클래스에 대응되는 가중 치 정보 및 제2 클래스에 대응되는 가중치 정보에 기초하여 새로운 가중치 정보(통합 가중치 정보)를 생성할 수 있다. 그리고, 전자 장치는 커널 발생부에서 생성된 통합 가중치 정보를 온칩 메모리에 전송할 수 있으며, 온칩 메모리에 전송된 통합 가중치 정보에 기초하여 인공 지능 분석을 수행할 수 있다. 제2 실 시 예에 따른 데이터 처리 방법은 높은 퀄리티의 데이터 분석 결과를 요구하는 경우 이용될 수 있다. 제3 실시 예는 DRAM에 제2 클래스에 대응되는 가중치 정보가 저장되어 있고, 온칩 메모리에 제1 클래스에 대응되는 가중치 정보가 저장되어 있으며, 제1 클래스에 대응되는 가중치 정보 및 제2 클래스에 대응 되는 가중치 정보를 모두 이용하여 인공 지능 분석을 수행하는 실시 예를 가정한다. 여기서, 전자 장치는 결과적으로 제1 클래스 및 제2 클래스를 결합하는 가중치 정보를 획득하지 못하였으므로, 통합 가중치 정보를생성해야 한다. 따라서, 전자 장치는 DRAM에 저장된 제2 클래스에 대응되는 가중치 정보를 DMAC(60 2)에 전송하고, DMAC에 전송된 제2 클래스에 대응되는 가중치 정보를 커널 발생부로 전송할 수 있다. 그리고, 전자 장치는 온칩 메모리에 저장된 제1 클래스에 대응되는 가중치 정보를 커널 발생부 로 전송할 수 있다. 그리고, 전자 장치는 커널 발생부를 통해 제1 클래스에 대응되는 가중치 정보 및 제2 클래스에 대응되는 가중치 정보에 기초하여 통합 가중치 정보를 생성할 수 있다. 그리고, 전자 장치는 생성된 통합 가중치 정보를 커널 발생부에서 온칩 메모리로 전송할 수 있다. 그리고, 전자 장치(10 0)는 온칩 메모리에 전송된 통합 가중치 정보에 기초하여 인공 지능 분석을 수행할 수 있다. 제3 실시 예 에 따른 데이터 처리 방법은 빠른 데이터 처리 방식에서 높은 퀄리티의 데이터 처리 방식으로 변경하는 경 우 이용될 수 있다. 제4 실시 예는 DRAM에 제2 클래스에 대응되는 가중치 정보가 저장되어 있고 온칩 메모리에 제1 클래스 및 제2 클래스 모두에 대응되는 통합 가중치 정보가 저장되어 있으며, 제1 클래스에 대응되는 가중치 정 보만을 이용하여 인공 지능 분석을 수행하는 실시 예를 가정한다. 현재, 온칩 메모리에는 통합 가중치 정 보만 저장되어 있으므로 전자 장치는 커널 발생부에 의하여 제1 클래스에 대응되는 가중치 정보를 생 성해야 한다. 따라서, 전자 장치는 온칩 메모리로부터 통합 가중치 정보를 커널 발생부에 전송 할 수 있다. 그리고, 전자 장치는 DRAM에서 제2 클래스에 대응되는 가중치 정보를 DMAC으로 전 송하고, 전송된 제2 클래스에 대응되는 가중치 정보를 커널 발생부으로 전송할 수 있다. 전자 장치는 통합 가중치 정보 및 제2 클래스에 대응되는 가중치 정보에 기초하여 제1 클래스에 대응되는 가중치 정보를 생 성할 수 있다. 통합 가중치 정보에는 제1 클래스에 대응되는 가중치 정보 및 제2 클래스에 대응되는 가중치 정 보를 모두 포함하고 있으므로, 전자 장치는 통합 가중치 정보에서 제2 클래스에 대응되는 가중치 정보만을 제거하는 동작을 수행할 수 있다. 커널 발생부가 데이터 제거 동작을 수행한다는 측면에서 커널 발생부 는 erase mode에 해당할 수 있다. 그리고, 전자 장치는 커널 발생부에서 생성된 제1 클래스에 대응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행할 수 있다. 제 4 실시 예 에 따른 데이터 처리 방법은 높은 퀄리티 데이터 처리 방식에서 빠른 데이터 처리 방식으로 변경하는 경우 이용될 수 있다. 제 5실시 예는 온칩 메모리에 제1 클래스에 대응되는 가중치 정보 및 제2 클래스에 대응되는 가중치 정보가 각각 저장되어 있으며, 제1 클래스 및 제2 클래스 모두에 대응되는 통합 가중치 정보를 이용하여 인공 지능 분석을 수행하는 실시 예를 가정한다. 전자 장치는 통학 가중치 정보를 생성하기 위하여 온칩 메모리 에서 제1 클래스에 대응되는 가중치 정보 및 제2 클래스에 대응되는 가중치 정보 각각을 커널 발생부(60 3)로 전송할 수 있다. 그리고, 전자 장치는 커널 발생부를 통해 제1 클래스에 대응되는 가중치 정보 및 제2 클래스에 대응되는 가중치 정보에 기초하여 통합 가중치 정보를 생성할 수 있다. 그리고, 전자 장치 는 커널 발생부에서 생성된 통합 가중치 정보를 온칩 메모리에 전송할 수 있다. 그리고, 전자 장치는 통합 가중치 정보에 기초하여 인공 지능 분석을 수행할 수 있다. 제5 실시 예에 따른 데이터 처리 방법은 빠른 데이터 처리 방식에서 높은 퀄리티 처리 방식으로 변경하는 경우 이용될 수 있다. 도 6b는 가중치 매트릭스를 획득하는 또 다른 실시 예들을 설명하기 위한 도면이다. 도 6b를 참조하면, 도 6a에서 설명한 바와 같이 전자 장치는 DRAM, DMAC(Direct Memory Access Controller), 커널 발생부 및 온칩 메모리 중 적어도 하나를 포함할 수 있다. 제6 실시 예는 제 4실시예와 유사하게 DRAM에 제2 클래스에 대응되는 가중치 정보가 저장되어 있고 온칩 메모리에 제1 클래스 및 제2 클래스 모두에 대응되는 통합 가중치 정보가 저장되어 있으며, 제1 클래스에 대응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행하는 실시 예일 수 있다. 다만, 제 6 실시 예의 커널 발생부는 DRAM으로부터 제2 클래스에 대응되는 가중치 정보 전체가 아니라 인덱스만 을 수신할 수 있다. 이미 제2 클래스에 대응되는 가중치 정보 중 가중치는 온칩 메모리로부터 수신 받으므 로, DRAM으로부터 가중치를 제외하고 인덱스만을 수신할 수 있다. 이와 관련된 구체적인 동작은 도 5b에서 기술하였다. 제 7 실시 예는 DRAM에 제3 클래스에 대응되는 가중치 정보가 저장되어 있고 온칩 메모리에 제1 클래스, 제2 클래스 및 제3 클래스 모두에 대응되는 통합 가중치 정보가 저장되어 있으며, 제1 클래스 및 제2 클래스에 대응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행하는 실시 예일 수 있다. 현재, 온칩 메모 리에는 통합 가중치 정보만 저장되어 있으므로 전자 장치는 커널 발생부에 의하여 제1 클래스 및 제2 클래스에 대응되는 가중치 정보를 생성해야 한다. 따라서, 전자 장치는 온칩 메모리로부터 통 합 가중치 정보를 커널 발생부에 전송하도록 제어할 수 있다. 그리고, 전자 장치는 DRAM에 저장된 제3 클래스에 대응되는 가중치 정보 중 인덱스만을 DMAC을 거쳐 커널 발생부에 전송하도록 제어할 수 있다. 그리고, 커널 발생부는 수신된 통합 가중치 정보 및 인덱스를 이용하여 새로운 가중치 정보를 생 성할 수 있다. 이와 관련된 구체적인 동작은 도 10b에서 후술한다. 제 8 실시 예는 DRAM에 제2 클래스에 대응되는 가중치 정보 및 제3 클래스에 대응되는 가중치 정보가 저장되어 있고 온칩 메모리에 제1 클래스, 제2 클래스 및 제3 클래스 모두에 대응되는 통합 가중치 정보가 저장되어 있으며, 제1 클래스에 대응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행하는 실시 예일 수 있다. 현재, 온칩 메모리에는 통합 가중치 정보만 저장되어 있으므로 전자 장치는 커널 발생부 에 의하여 제1 클래스에 대응되는 가중치 정보를 생성해야 한다. 따라서, 전자 장치는 온칩 메모리로 부터 통합 가중치 정보를 커널 발생부에 전송하도록 제어할 수 있다. 그리고, 전자 장치는 DRAM(60 1)에 저장된 제2 클래스에 대응되는 가중치 정보의 인덱스 및 제3 클래스에 대응되는 가중치 정보의 인덱스만을 DMAC을 거쳐 커널 발생부에 전송하도록 제어할 수 있다. 그리고, 커널 발생부는 수신된 통합 가 중치 정보 및 인덱스를 이용하여 새로운 가중치 정보를 생성할 수 있다. 이와 관련된 구체적인 동작은 도 10c에 서 후술한다. 도 7은 일반적인 방법, 프루닝 동작, 제로 스킵핑 동작을 설명하는 도면일 수 있다. 도 7을 참조하면, 전자 장치는 일반적인 방법 에 따라 가중치 정보와 입력 데이터를 곱할 수 있다. 일반적인 방법에서는 가중치 정보에서 어떠한 변형을 가하지 않을 수 있으며 이미 획득된 가중치를 그대로 이용하는 방법일 수 있다. 한편, 전자 장치는 가중치 정보에서 가중치 크기 정보를 고려하여 가중치 정보를 변경할 수 있 다. 구체적으로, 전자 장치는 프루닝 동작을 수행할 수 있다. 프루닝 동작가중치 크기가 임계값 이하인 경우, 해당 가중치를 0으로 변경하는 동작일 수 있다. 예를 들어, 임계값이 0.09라고 가정한다. 전자 장 치는 가중치의 크기값이 임계값(0.09)이하인 가중치를 0으로 변경할 수 있다. 전자 장치는 가중치 정 보에서 가중치 크기가 임계값(0.09)이하인 가중치를 연속하는 가중치들로 그룹핑할수 있으며 전자 장치 는 복수의 그룹(706-1, 706-2, 706-3)을 획득할 수 있다. 그리고, 전자 장치는 각 복수의 그룹(706- 1, 706-2, 706-3)에 포함된 가중치를 0으로 변경할 수 있다. 이러한 프루닝 동작은 일정 크기 이하의 가중 치들을 0으로 변경하여 계산 과정을 단순하게 하는데 목적이 있을 수 있다. 결과적으로, 전자 장치는 프루 닝 동작을 통하여 변경된 가중치 정보를 획득할 수 있다. 그리고, 전자 장치는 변경된 가중치 정보 및 입력 데이터를 곱할 수 있다. 일반적인 방법과 프루닝 동작에 의한 계산 방법은 횟수는 동일하지만, 프루닝 동작에 의한 계산 방법은 0을 곱하는 횟수가 많아 계산 과정이 단순화될 수 있 으며 처리 속도가 향상될 수 있다. 한편, 전자 장치는 프루닝 동작에 의하여 생성된 변경된 가중치 정보에서 제로 스킵핑 동작 을 수행할 수 있다. 제로 스킵핑 동작에 대해서는 도 3에서 설명한 바 중복 설명은 생략한다. 전자 장치 는 변경된 가중치 정보에 제로 스킵핑 동작을 수행하여 가중치 정보를 생성할 수 있으며, 가중치 정보는 인덱스(3,5,4), 가중치(0.7,-0.1,0.86) 및 순서 정보(3,0.7,5,-0.1,4,0.86)를 포함할 수 있다. 도 8은 가중치 정보를 획득하는 일 실시 예를 설명하기 위한 도면이다. 도 8을 참조하면, 전자 장치는 가중치 정보를 기 설정된 기준에 따라 복수의 클래스 각각에 대응되는 가중치 정보를 획득할 수 있다. 복수의 클래스 및 복수의 클래스에 대응되는 가중치 정보 획득 동작에 대해서는 도 4에서 구체적으로 설명 하였는 바, 중복되는 설명은 생략한다. 여기서, 가중치 정보는 이미 프루닝 동작이 수행된 결과 데이터에 해당할 수 있다. 가중치 정보는 가 중치가 0인 데이터와 가중치가 0이 아닌 데이터(805-1,805-2,805-3,805-4,805-5)를 포함할 수 있다. 여기서, 전자 장치는 3개의 클래스로 가중치 정보를 분리할 수 있다. 3개의 클래스를 구분하기 위해 제1 임계값 및 제2 임계값이 기 저장되어 있을 수 있다. 전자 장치는 가중치의 크기값(또는 가중치의 중요 도)이 제1 임계값 이상인 경우 제1 클래스에 해당하는 것으로 판단하고, 가중치의 크기값(또는 가중치의 중요도)이 제2 임계값 이상 제1 임계값 미만인 경우 제2 클래스에 해당하는 것으로 판단하고, 가중치의 크기값 (또는 가중치의 중요도)이 제2 임계값 미만인 경우 제3 클래스에 해당하는 것으로 판단할 수 있다. 예를 들어, 제1 임계값이 0.6이고 제2 임계값이 0.3으로 가정한다. 가중치 0.7(805-1), 0.8(805-4)은 각 크기값 이 제1 임계값(0.6) 이상이므로, 전자 장치는 가중치 0.7(805-1), 0.8(805-4)가 제1 클래스에 해당하는것으로 판단할 수 있다. 그리고, 가중치 0.5(805-3), -0.4(805-5)는 각 크기값이 제2 임계값(0.3) 이상 및 제1 임계값(0.6) 미만 이므로, 전자 장치는 가중치 0.5(805-3), -0.4(805-5)가 제2 클래스에 해당하는 것으로 판단할 수 있다. 그리고, 가중치-0.1(805-2)은 크기값이 제2 임계값(0.3) 미만이므로, 전자 장치는 가중치 -0.1(805-2)이 제3 클래스에 해당하는 것으로 판단할 수 있다. 제1 클래스는 가장 높은 크기값을 갖는 가중치 그룹이며 제3 클래스는 가장 낮은 크기값을 갖는 가중치 그룹일 수 있다. 전자 장치는 각각의 클래스에 대응되는 가중치 정보를 획득할 수 있다. 구체적으로, 전자 장치는 제1 클래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정보, 제3 클래스에 대응되는 가중치 정보를 획득할 수 있다. 제1 클래스에 대응되는 가중치 정보는 제1 클래스로 판단된 가중치(805- 1,805-4)를 제외한 가중치를 0으로 간주하는 방식에 의하여 획득될 수 있다. 제2 클래스에 대응되는 가중치 정 보는 제2 클래스로 판단된 가중치(805-3,805-5)를 제외한 가중치를 0으로 간주하는 방식에 의하여 획득될 수 있다. 제3 클래스에 대응되는 가중치 정보는 제3 클래스로 판단된 가중치(805-2)를 제외한 가중치를 0 으로 간주하는 방식에 의하여 획득될 수 있다. 한편, 각 클래스에 대응되는 가중치 정보는 각 클래스의 마지막 가중치 뒤에 배치되는 0의 개수를 포함하지 않 을 수 있다. 예를 들어, 제1 클래스에 대응되는 가중치 정보는 마지막 가중치(805-4)까지의 데이터만을 포 함하며, 제3 클래스에 대응되는 가중치 정보는 마지막 가중치(805-2)까지의 데이터만을 포함할 수 있다. 한편, 각 클래스에 대응되는 가중치 정보를 획득하는 방법은 도 4에서 설명 하였으므로 중복 설명을 생략한다. 전자 장치는 DRAM 또는 커널 발생부 중 적어도 하나를 포함할 수 있다. 전자 장치는 DRAM에 제1 클래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정보, 제3 클래스에 대응되는 가중치 정보를 DRAM에 저장할 수 있다. 그리고, 필요에 따라 전자 장치는 제1 클래스 에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정보, 제3 클래스에 대응되는 가중치 정보 중 적어도 하나를 이용하여 인공 지능 분석을 수행할 수 있다. 도 8에서 제1 클래스에 대응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행하는 것으로 가정한다. 전자 장치는 DRAM에 저장된 복수의 가중치 정보 중 제1 클래스에 대응되는 가중치 정보만을 이 용하여 인공 지능 분석을 수행할 수 있다. 여기서, 전자 장치는 제1 클래스에 대응되는 가중치 정보 를 커널 발생부로 전달할 수 있다. 다만, DRAM 자체에 이미 제1 클래스에 대응되는 가중치 정보(81 1)가 포함되어 있으므로, 새로운 가중치 정보를 생성할 필요는 없을 수 있다. 커널 발생부가 별도의 결합 동작을 수행할 필요가 없으므로, 도 8에서 개시한 실시 예에 따른 데이터 처리 방법은 빠른 데이터 처리 속도를 요하는 경우 이용될 수 있다. 한편, 도 8에서 제1 클래스에 대응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행하는 실시 예는 도 6a의 제1 실시 예와 유사한 실시 예일 수 있다. 다만, 도 8에서 개시하는 실시 예는 도 6a의 제1 실시 예와 달리 3개의 클래스로 구분된 실시 예일 수 있다. 도 9는 가중치 정보를 생성하는 실시 예를 설명하기 위한 도면이다. 도 9를 참조하면, 가중치 정보는 도8의 가중치 정보에 대응될 수 있다. 또한, 제1 클래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정보, 제3 클래스에 대응되는 가중치 정보는 각각 도 8의 가중치 정보(811,812,813)에 대응될 수 있다. 따라서, 중복되는 설명은 생략한다. 도 9에 따른 실시 예는 DRAM에 제1 클래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정보 및 제3 클래스에 대응되는 가중치 정보가 저장되어 있으며 제1 클래스, 제2 클래스, 제3 클래스 에 대응되는 가중치 정보 모두를 이용하여 인공 지능 분석을 수행하는 실시 예를 가정한다. 여기서, 제1 클래스, 제2 클래스, 제3 클래스에 대응되는 가중치 정보 모두를 통합한 새로운 가중치 정보를 통합 가중치 정 보로 기술할 수 있다. 전자 장치는 제1 클래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정보, 제3 클 래스에 대응되는 가중치 정보를 결합하기 위하여 DRAM에 저장된 각 가중치 정보(911,912,913)를 커널 발생부에 전송할 수 있으며, 커널 발생부는 각 가중치 정보(911,912,913)에 기초하여 통합 가중치 정 보를 생성할 수 있다. 여기서, 커널 발생부는 통합 가중치 정보를 생성하기 위하여 기 정의된 코드 정보를 이용할 수 있다. 기 정의된 코드 정보는 스택 구조를 이용하여 데이터를 처리하는 동작과 관련된 코드일 수 있다. 도 9에서 개시한 실시 예에 따른 데이터 처리 방법은 데이터 분석 결과에 대하여 높은 퀄리티를 요하는 경우 이용될 수 있다. 한편, 도 9에서 통합 가중치 정보를 이용하여 인공 지능 분석을 수행하는 실시 예는 도 6a의 제2 실시 예 와 유사한 실시 예일 수 있다. 다만, 도 9에서 개시하는 실시 예는 도 6a의 제2 실시 예와 달리 3개 의 클래스로 구분된 실시 예일 수 있다. 한편, 도9에 개시된 동작들은 도 5a에서 설명한 코드를 이용하여 수행될 수 있다. 코드의 중복 기재를 생략한다. 도 10a는 가중치 정보를 생성하는 다른 실시 예를 설명하기 위한 도면이다. 가중치 정보도 10a를 참조하면, 가중치 정보는 도8의 가중치 정보에 대응될 수 있다. 또한, 제1 클 래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정보, 제3 클래스에 대응되는 가중치 정보는 각각 도 8의 가중치 정보(811,812,813)에 대응될 수 있다. 그리고 제1클래스, 제2클래스 및 제3 클래스 모두에 대응되는 통합 가중치 정보는 도9의 통합 가중치 정보에 대응될 수 있다. 따라서, 도 8 및 도 9와 중복되는 설명은 생략한다. 도 10a의 실시 예는 DRAM에 제1 클래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정 보, 제3 클래스에 대응되는 가중치 정보가 저장되어 있으며, 온칩 메모리에 통합 가중치 정 보가 저장되어 있다고 가정한다. 그리고, 도 10a의 실시 예는 제1 클래스 및 제2 클래스에 대응되는 가중 치 정보를 이용하여 인공 지능 분석을 수행하는 실시 예를 가정한다. 여기서, 가중치 정보는 인덱스 (1013-1) 및 인덱스(1013-1)에 대응되는 가중치(1013-2)를 포함할 수 있다. 또한, 가중치 정보는 인덱스 (1014-1,1014-3,1014-5,1014-7,1014-9) 및 인덱스(1014-1,1014-3,1014-5,1014-7,1014-9)에 대응되는 가중치 (1014-2,1014-4,1014-6,1014-8,1014-10)을 포함할 수 있다. 통합 가중치 정보는 제1 클래스, 제2 클래스 및 제3 클래스가 모두 포함된 가중치 정보를 의미할 있다. 도 10a의 실시 예에 따르면, 전자 장치는 제1 클래스에 대응되는 가중치 정보, 제2 클래스에 대응되 는 가중치 정보, 제3 클래스에 대응되는 가중치 정보, 통합 가중치 정보만을 저장하고 있을 뿐, 제1 클래스 및 제2 클래스에 대응되는 가중치 정보를 저장하고 있지 않을 수 있다. 따라서, 전자 장치(10 0)는 커널 발생부를 통해 제1 클래스 및 제2 클래스에 대응되는 가중치 정보를 생성할 수 있다. 여 기서, 가중치 정보는 인덱스(1016-1,1016-3,1016-5,1016-7) 및 인덱스(1016-1,1016-3,1016-5,1016-7)에 대응되는 가중치(1016-2,1016-4,1016-6,1016-8)를 포함할 수 있다. 여기서, 커널 발생부는 DRAM으로부터 제3 클래스에 대응되는 가중치 정보 중 인덱스(1013-1) 및 인덱스(1013-1)에 대응되는 가중치(1013-2) 모두를 수신할 수 있다. 그리고, 커널 발생부는 온칩 메모 리로부터 통합 가중치 정보 중 인덱스(1014-1,1014-3,1014-5,1014-7,1014-9) 및 인덱스(1014- 1,1014-3,1014-5,1014-7,1014-9)에 대응되는 가중치(1014-2,1014-4,1014-6,1014-8,1014-10)를 수신할 수 있다. 여기서, 커널 발생부는 통합 가중치 정보 및 제3 클래스에 대응되는 가중치 정보에 기초하여 제1 클래스 및 제2 클래스에 대응되는 가중치 정보를 생성할 수 있다. 통합 가중치 정보는 제1 클 래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정보 및 제3 클래스에 대응되는 가중 치 정보를 모두 포함하고 있으므로, 전자 장치는 통합 가중치 정보에서 제3 클래스에 대응되 는 가중치 정보만을 제거하는 동작을 수행할 수 있다. 커널 발생부가 데이터 제거 동작을 수행한다는 측 면에서 커널 발생부는 erase mode에 해당할 수 있다. 그리고, 전자 장치는 커널 발생부에서 생성된 제1 클래스 및 제2 클래스에 대응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행할 수 있 다. 도 10a의 실시 예에 따른 데이터 처리 방법은 빠른 데이터 처리 속도 및 높은 퀄리티의 데이터 분석 결과를 요구하는 경우 이용될 수 있다. 도 10b는 도 10a의 실시 예에서 다른 계산 과정을 적용하는 동작을 설명하기 위한 도면이다. 도 10b를 참조하면, 커널 발생부는 도 10a와 동일한 동작을 수행하는 과정에서 DRAM으로부터 가중 치(1013-2)를 수신하지 않을 수 있다. 구체적으로, 커널 발생부는 DRAM으로부터 인덱스(1013-1)만 을 수신할 수 있다. 결과적으로, 새로운 가중치 정보를 생성하는 과정에서 가중치를 빼는 동작만이 수행 될 수 있다. 따라서, 커널 발생부는 인덱스(1013-1)만으로 제거해야할 가중치(-0.1)의 위치를 찾을 수 있 다. 따라서, 커널 발생부는 도 10a의 실시 예와 다르게 DRAM으로부터 가중치 정보 중 인덱스 (1013-1)만을 수신할 수 있다.도 10b에 대한 나머지 동작들은 도 10a와 대응될 수 있으므로, 중복되는 설명을 생략한다. 도 10c 는 가중치 정보를 생성하는 또 다른 실시 예를 설명하기 위한 도면이다. 도 10c를 참조하면, DRAM은 제1 클래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정 보, 제3 클래스에 대응되는 가중치 정보를 포함할 수 있다. 여기서, 가중치 정보는 인덱스 (1012-1, 1012-3) 및 인덱스(1012-1, 1012-3)에 대응되는 가중치(1012-2,1012-4)를 포함할 수 있다. 또한, 가 중치 정보는 인덱스(1013-1) 및 인덱스(1013-1)에 대응되는 가중치(1013-2)를 포함할 수 있다. 커널 발생부는 DRAM으로부터 가중치 정보의 인덱스(1012-1,1012-3) 및 가중치 정보의 인덱스(1013-1)만을 수신할 수 있다. 그리고, 커널 발생부는 온칩 메모리로부터 통합 가중치 정보 중 인덱스(1014-1,1014-3,1014-5,1014-7,1014-9) 및 인덱스(1014-1,1014-3,1014-5,1014-7,1014-9)에 대응되는 가중치(1014-2,1014-4,1014-6,1014-8,1014-10)를 수신할 수 있다. 여기서, 커널 발생부는 수신된 가중치 정보에서 가중치 정보의 인덱스(1012-1,1012-3) 및 가 중치 정보의 인덱스(1013-1)에 해당하는 가중치를 제거함으로서 새로운 가중치 정보를 생성할 수 있다. 여기서, 가중치 정보는 인덱스(1017-1,1017-3) 및 인덱스(1017-1,1017-3)에 대응되는 가중치 (1017-2,1017-4)를 포함할 수 있다. 가중치 정보는 제1 클래스에 대응되는 가중치 정보를 의미할 수 있으 며, 결과적으로 가중치 정보와 동일할 수 있다. 도 10c에 대한 나머지 동작들은 도 10a 및 도 10c와 대응될 수 있으므로, 중복되는 설명을 생략한다. 도 11은 프루닝 동작에 기초하여 변경되는 가중치의 분포를 설명하기 위한 도면이다. 도 11을 참조하면, 조직도는 기본 가중치 정보에 대응되는 조직도이고 조직도는 프루닝 동작 이후 의 조직도일 수 있다. 조직도 및 조직도에서는 입력층 및 출력층 사이의 관계를 나타낼 수 있다. 한편, 프루닝 동작은 인공 지능 모델에 의하여 수행될 수 있다. 입력층은 4개의 노드(i1, i2, i3, i4)를 포함하며 출력층은 5개의 노드(o1, o2, o3, o4, o5)를 포함하는 것으 로 가정한다. 여기서, 입력층의 노드들과 출력층의 노드들 사이에 가중치가 정해질 수 있으며, 상술한 가정에서 는 총 20개의 가중치가 정해질 수 있다. 조직도 및 조직도에서는 굵은 실선은 가중치가 0이 아닌 데이터를 의미하며, 가는 실선은 가중치가 0인 데이터를 의미하며, 점선은 프루닝 동작이 수행된 데이터를 의미 할 수 있다. 표는 기본 가중치 정보를 의미하고, 표는 기본 가중치 정보에서 프루닝 동작이 이루어진 가중치 정 보를 의미할 수 있다. 인공 지능 모델은 표에 포함된 20개의 가중치에서 0이 아닌 가중치를 식별할 수 있 고, 0이 아닌 가중치에서 기 설정된 임계값(0.1) 미만의 가중치를 식별할 수 있다. 인공 지능 모델은 0이 아닌 가중치에서 기 설정된 임계값(0.1) 미만의 가중치를 하나의 그룹으로 그룹핑 할 수 있다. 그리고, 인공 지능 모델은 식별된 그룹에 대하여 프루닝 동작을 수행할 수 있다. 여기서, 프루닝 동작은 0이 아닌 데이 터를 0으로 변경하는 것을 의미할 수 있다. 식별된 그룹에 대하여 프루닝 동작을 수행한 후의 데이터 그 룹은 모두 가중치가 0일 수 있다. 표는 기본 가중치 정보에 대한 가중치 크기별 개수 정보를 나타낼 수 있으며, 표는 프루닝 동작이 이루어진 가중치 정보에 대한 가중치 크기별 개수 정보를 나타낼 수 있다. 표는 표에 대응될 수 있 고, 표는 표에 대응될 수 있다. 그래프은 기본 가중치 정보에 대한 가중치 크기와 가중치 개수의 관계를 나타낼 수 있으며, 그래프(114 0)는 프루닝 동작이 이루어진 가중치 정보에 대한 가중치 크기와 가중치 개수와의 관계를 나타낼 수 있다. 그래 프에 따라, 기본 가중치 정보는 가중치 크기가 클수록 가중치 개수가 줄어들고 가중치 크기가 작을수록 가중치 개수는 늘어나는 분포를 가질 수 있다. 그리고, 영역은 그룹에 대응될 수 있으며, 영역 은 그룹에 대응될 수 있다. 한편, 포인트는 프루닝 동작에 기초하여 0의 개수가 늘어난 결과 가 반영된 것일 수 있다. 도 12는 전자 장치의 리소스를 고려하지 않고 가중치를 결정하는 실시 예를 설명하기 위한 도면이다. 도 12를 참조하면, 가중치 정보에 포함된 가중치의 총 개수가 고정될 수 있다. 가중치의 총 개수가 고정되어 있 으면 가중치를 포함하는 인공 지능 모듈의 정확도도 일정할 수 있다. 표는 가중치 개수와 인공 지능 모듈의 정확도의 관계를 나타내기 위한 표이다. 가중치의 총 개수가 n1으 로 고정되면, 인공 지능 모듈의 정확도 역시 고정될 수 있다. 전자 장치가 사람의 얼굴을 인식하는 인공 지능 모듈을 포함하고 있으며, 분석 한도 얼굴 개수는 7로 가정한다. 제1 실시 예는 타겟 얼굴 개수가 4인 것으로 가정한다. 인공 지능 모듈의 분석 한도 얼굴 개수는 7이므로, 전자 장치는 분석 한도 얼굴 개수보다 작은 4개의 타겟 얼굴을 모두 분석할 수 있다. 제1 실시 예는 전자 장치의 리소스가 충분한 경우에 대응되는 실시 예일 수 있다. 제2 실시 예는 타겟 얼굴 개수가 15인 것으로 가정한다. 전자 장치의 분석 한도 얼굴 개수는 7이므 로, 전자 장치는 모든 타겟 얼굴을 분석 할 수 없다. 따라서, 전자 장치는 15개의 타겟 얼굴 중 7개 의 얼굴을 식별하여 7개의 타겟 얼굴에 대해서만 분석을 수행하고, 나머지 8개의 타겟 얼굴은 분석하지 않을 수 있다. 제2 실시 예는 전자 장치의 리소스가 부족한 경우에 대응되는 실시 예일 수 있다. 도 13은 전자 장치의 리소스를 고려하여 가중치를 결정하는 실시 예를 설명하기 위한 도면이다. 도 13을 참조하면, 가중치 정보에 포함된 가중치의 총 개수가 변경될 수 있다. 가중치의 총 개수가 변경되면 인 공 지능 모듈의 정확도이며 변경될 수 있다. 가중치의 총 개수가 작아지면 인공 지능 모듈의 정확도가 떨어질 수 있고 가중치의 총 개수가 커지면 정확도가 인공 지능 모듈의 정확도가 오를 수 있다. 전자 장치에 포함된 현재 인공 지능 모듈의 가중치의 총 개수가 n1이며 분석 한도 얼굴 개수는 7이라고 가 정한다. 제1 실시 예는 타겟 얼굴 개수가 4인 것으로 가정한다. 전자 장치의 분석 한도 얼굴 개수는 7이므로, 전자 장치는 분석 한도 얼굴 개수보다 작은 4개의 타겟 얼굴을 모두 분석할 수 있다. 제1 실시 예는 전자 장치의 리소스가 충분한 경우에 대응되는 실시 예일 수 있다. 제2 실시 예는 타겟 얼굴 개수가 15인 것으로 가정한다. 인공 지능 모듈의 분석 한도 얼굴 개수는 7이므 로, 전자 장치는 모든 타겟 얼굴을 분석 할 수 없다. 따라서, 전자 장치는 타겟 얼굴 15개를 모두 분 석하기 위하여 가중치의 총 개수를 변경할 수 있다. 전자 장치는 n1 보다 작은 n2로 가중치의 총 개수를 변경할 수 있다. 가중치의 총 개수가 작아지면 계산량이 적어지므로 전자 장치의 리소스가 확보 될 수 있 다. 그리고, 가중치의 총 개수가 n2 이면 분석 한도 얼굴 개수가 15라고 가정한다. 전자 장치는 인공 지능 모듈에 대한 가중치의 총 개수 정보를 n1에서 n1보다 작은 값인 n2로 변경함으로써 타겟 얼굴(15개)을 모두 분 석할 수 있다. 다만, 가중치의 총 개수 가 작아짐으로 인하여 인공 지능 모듈의 정확도가 낮아질 수 있다. 전자 장치는 사용자가 요구하는 정확도와 전자 장치의 리소스 정보를 모두 고려하여 복수개의 동작 지점 중 최적의 동 작 지점을 식별할 수 있다. 전자 장치는 식별된 최적의 동작 지점에 기초하여 가중치의 총 개수를 n1에서 n2로 변경할 수 있다. 도 14a는 복수의 가중치를 복수의 클래스로 구분하는 동작을 설명하기 위한 도면이다. 도 14a를 참조하면, 전자 장치는 인공 지능 분석을 수행하기 전에 가중치 정보를 미리 학습할 수 있다. 여 기서, 미리 학습되는 가중치 정보는 전자 장치가 아닌 외부 서버에서 생성될 수 있다. 그리고, 외부 서버 는 가중치 정보를 복수의 클래스로 구분할 수 있다. 복수의 클래수 개수는 기 정의된 숫자일 수 있으며, 학습 방식 역시 기 정의된 것일 수 있다. 도 14a에서 개시하는 복수의 표(1405,1410,1415-1,1415-2,1420,1425,1430,1435)는 가중치 크기와 가중치 개수 의 관계를 나타내는 것일 수 있다. 한편, 가중치 정보를 복수의 클래스로 구분하기 위하여 외부 서버는 제1 단계 및 제2 단계를 포함 할 수 있다. 제1 단계에서, 가중치 정보는 클래스A1 및 클래스 B1으로 구분될 수 있다. 표에 따라, 클래스 A1은 가중치의 크기(또는 가중치의 중요도)가 상대적으로 큰 클래스이고 클래스 B1은 가중치의 크기(또는 가중치의 중요도)가 상대적으로 작은 클래스일 수 있다. 클래스 A1과 클래스 B1을 나누는 기준은 기 설정된 정보 또는 사 용자 입력 정보일 수 있다. 예를 들어, 기 설정된 정보가 제1 클래스를 상위 20%이고 제2 클래스를 상위 20%에 서 상위 100%로 구분하는 기준일 수 있다. 외부 서버는 모든 가중치에서 가중치의 크기(또는 가중치의 중요도) 를 기준으로 상위 20%에 대응되는 가중치를 클래스 A1으로 그룹핑하고, 상위 20%에서 상위 100%에 대응되는 가 중치를 클래스 B1으로 그룹핑할 수 있다. 여기서, 전체 가중치를 클래스 A1 및 클래스 B1으로 구분함에 있어서,일 실시 예에 따라 기존 가중치의 값이 학습 결과에 기초하여 변경될 수 있다. 다만, 다른 실시 예에 따라, 기 존 가중치의 값이 그대로 유지되면서 그룹핑 동작만 수행되는 형태로 구현될 수 있다. 또한, 외부 서버는 복수의 클래스 중 상대적으로 가중치 크기가 작은 클래스(클래스 B1)에 대하여 프루닝 동작 을 수행할 수 있다 (S1406). 클래스 B1에 대하여 프루닝 동작이 수행되면 상대적으로 크기가 작은 가중치가 0으 로 변경될 수 있으며, 변경된 결과에 대응되는 관계 그래프는 그래프일 수 있다. 그래프는 가중치 정보에 프루닝 동작이 수행되면 상대적으로 큰 가중치만 남아 있다는 것을 나타낼 수 있다. 또한, 외부 서버는 가중치 정보에 남아 있는 클래스(클래스 A1)에 대하여 재학습 동작을 수행할 수 있다 (S1411-1). 재학습 동작(S1411-1)의 결과에 대응되는 관계 그래프는 그래프(1415-1)일 수 있다. 여기서, 재학습 동작(S1411-1)은 클래스 A1에 포함된 가중치를 재학습하는 동작을 의미할 수 있다. 가중치를 재학습하는 동작에 기초하여 기존 클래스 A1에 포함된 가중치가 변경될 수 있으며, 변경된 가중치들을 클래스 A2로 기재할 수 있다. 즉, 클래스 A1과 클래스 A2의 가중치는 상이할 수 있다. 또한, 외부 서버는 클래스 A2에 대하여 재학습 동작을 수행할 수 있다 (S1411-2). 재학습 동작(S1411-2)의 결과 에 대응되는 관계 그래프는 그래프(1415-2)일 수 있다. 여기서, 재학습 동작(S1411-2)은 하나의 클래스를 다시 복수의 클래스로 구분하는 것을 의미할 수 있다. 예를 들어, 외부 서버는 재학습 동작에 기초하여 클래스 A2를 클래스 a11 및 클래스 a12로 구분할 수 있다. 클래스 A2에서 클래스 a11 및 클래스 a12로 구분하는 기준은 기 설정된 정보 또는 사용자 입력 정보일 수 있다. 예를 들어, 복수의 클래스로 구분되는 기준이 구분되는 대상의 50%라고 가정한다. 외부 서버는 클래스 A2에 포함된 가중치에서 상위 50%에 대응되는 가중치를 클래스 a11로 그 룹핑하고, 상위 50%에서 상위 100%에 대응되는 가중치를 클래스 a12로 그룹핑할 수 있다. 여기서, 클래스 a11 및 클래스 a12는 각각 전체 가중치의 10%씩을 포함할 수 있다. 여기서, 재학습 동작(S1411-2)은 그룹핑 동작과 함께 가중치의 값들이 변경되는 동작을 포함할 수 있다. 즉, 재학습 동작(S1411-2)의 결과에 기초하여 클래스 A2에 포함된 가중치와 클래스 a11 및 클래스 a12에 포함된 가중치는 상이할 수 있다. 또한, 외부 서버는 복수의 클래스 중 상대적으로 가중치 크기가 작은 클래스(클래스 a12)에 대하여 프루닝 동작 을 수행할 수 있다 (S1416). 클래스 a12에 대하여 프루닝 동작이 수행되면 상대적으로 크기가 작은 가중치가 0 으로 변경될 수 있으며, 변경된 결과에 대응되는 관계 그래프는 그래프일 수 있다. 그래프는 가중 치 정보에 프루닝 동작이 수행되면 상대적으로 큰 가중치만 남아 있다는 것을 나타낼 수 있다. 또한, 외부 서버는 가중치 정보에 남아 있는 클래스(클래스 a11)에 대하여 재학습 동작을 수행할 수 있다 (S1421). 여기서, 재학습 동작은 기존 클래스에 포함된 가중치를 새로운 가중치로 변경하는 것을 의미할 수 있 다. 재학습 동작 (S1421)의 결과에 대응되는 관계 그래프는 그래프일 수 있다. 예를 들어, 외부 서버는 클래스 a11을 클래스 a13으로 변경할 수 있다. 여기서, 클래스 a13에 포함된 가중치와 클래스 a11에 포함된 가 중치는 상이할 수 있다. 여기서, S1421 재학습 동작은 제1 단계에서 제2 단계로 넘어가는 동작일 수 있다. 또한, 외부 서버는 가중치 정보에 대하여 재학습 동작을 수행할 수 있다 (S1426). 여기서, 재학습 동작은 가중 치 정보에 남아 있는 클래스(클래스 a13)에 프루닝 동작으로 제거하였던 클래스(클래스 a12)를 추가하여 재학습 하는 것을 의미할 수 있다. 프루닝 동작으로 제거하였던 클래스(클래스 a12)를 추가하여 재학습하는 것은 클래 스 a12에 포함된 가중치가 변경되는 것을 의미할 수 있다. 재학습 동작(S1426)의 결과에 대응되는 관계 그래프 는 그래프일 수 있다. 예를 들어, 외부 서버는 재학습 동작에 기초하여 클래스 a13에 클래스 a14를 구분 할 수 있다. 그리고, 클래스 a14는 클래스 a12를 재학습하는 동작(S1426)에서 생성된 클래스일 수 있다. 구체적 으로, 외부 서버는 클래스 a12를 추가하고 클래스 a13 및 클래스 a12에 대하여 재학습 동작(S1426)을 수행할 수 있다. 여기서, 재학습 동작(S1426)이 수행되는 동안 클래스 a13에 포함된 가중치는 변경되지 않을 수 있다. 외 부 서버는 클래스 a12에 포함된 가중치만을 변경할 수 있고, 클래스 a12에 포함된 가중치를 변경하여 새로운 클 래스 a14로 그룹핑할 수 있다. 즉, 외부 서버는 클래스 a12에 포함된 가중치를 변경하여 새로운 클래스 a13를 생성할 수 있다. 클래스 a14는 클래스 a12를 재학습하는 동작(S1426)에서 생성된 클래스일 수 있고, 클래스 a14 에 포함된 가중치와 클래스 a12에 포함된 가중치가 상이할 수 있다. 또한, 외부 서버는 가중치 정보에 대하여 재학습 동작을 수행할 수 있다 (S1431). 여기서, 재학습 동작은 가중 치 정보에 남아 있는 클래스(클래스 a13, 클래스 a14)에 프루닝 동작으로 제거하였던 클래스(클래스 B1)를 추가 하여 재학습하는 것을 의미할 수 있다. 프루닝 동작으로 제거하였던 클래스(클래스 B1)를 추가하여 재학습하는 것은 클래스 B1에 포함된 가중치가 변경되는 것을 의미할 수 있다. 재학습 동작(S1431)의 결과에 대응되는 관계 그래프는 그래프일 수 있다. 예를 들어, 외부 서버는 재학습 동작에 기초하여 클래스 a13및 클래스 a14에클래스 B2를 추가할 수 있다. 여기서, 클래스 a13및 클래스 a14에 대응되는 가중치는 재학습 동작(S1431)에 의 하여 값이 변경되지 않을 수 있다. 외부 서버는 클래스 a13, 클래스 a14, 클래스 B1에 기초하여 재학습동작을 수행하되, 클래스 B1에 대응되는 가중치만을 변경할 수 있다. 여기서, 클래스 B1에 대응되는 가중치를 변경하여 새로운 클래스 B2를 생성할 수 있다. 클래스 B2는 클래스 B1을 재학습하는 동작(S1431)에서 생성된 클래스일 수 있고, 클래스 B2에 포함된 가중치와 클래스 B1에 포함된 가중치가 상이할 수 있다. 외부 서버는 최종적으로, 가중치 정보를 3개의 그룹(클래스 a13, 클래스 a14, 클래스 B2)으로 구분할 수 있으며, 최종적으로 획득된 3개의 그룹(클래스 a13, 클래스 a14, 클래스 B2)을 메모리에 저장할 수 있다. 또한, 외부 서버는 메모리에 저장된 3개의 그룹(클래스 a13, 클래스 a14, 클래스 B2)에 대응되는 가중치 정보를 각각 저장할 수 있다. 도 14b는 복수의 가중치를 복수의 클래스로 구분하는 동작의 계산 과정을 설명하기 위한 도면이다. 도 14b를 참조하면, 외부 서버는 최초 가중치를 포함할 수 있다. 여기서, 최초 가중치는 표에 도시한 4*5 행렬로 나타낼 수 있다. 외부 서버는 최초 가중치에 기초하여 70%프루닝 동작, 80% 프루닝 동작, 80% 프루닝 동작, 을 수행할 수 있다. 70% 프루닝 동작은 최초 가중치에서 30%의 가중치를 남기고 70%의 가중치를 0으로 변환 하는 것을 의미할 수 있다. 70% 가중치 동작은 구분(sorting) 동작, 프루닝(pruning) 동작, 재학습(retraining) 동작을 포 함할 수 있다. 여기서, 구분(sorting) 동작은 가중치(최초 또는 변환된 가중치)를 기 설정된 방식에 의하여 배 열하는 것을 의미할 수 있다. 최초의 구분 동작에서 외부 서버는 별도의 데이터 변환 없이 그대로 최초 가중치 를 표와 같이 배열할 수 있다. 그리고, 외부 서버는 표에 대응되는 가중치에서 70%에 해당하는 가 중치를 프루닝 할 수 있다. 프루닝 되는 대상 가중치는 가중치의 크기에 기초하여 결정될 수 있다. 하지만, 반 드시 가중치의 크기만을 고려하지 않고 추가적으로 다양한 기준이 적용될 수 있다. 70% 프루닝을 수행하면, 외 부 서버는 표에 대응되는 가중치를 획득할 수 있다. 외부 서버는 표에 대응되는 가중치를 획득한 이후에 재학습 동작을 수행할 수 있다. 외부 서버는 재학습 동작의 결과로서 표에 대응되는 가중치를 획 득할 수 있다. 외부 서버는 표에 대응되는 가중치에 기초하여 80% 프루닝 동작을 수행할 수 있다. 80% 프루닝 동작은 표에 대응되는 가중치(0을 포함)에서 20%의 가중치를 남기고 80%의 가중치를 0 으로 변환하는 것을 의미할 수 있다. 외부 서버는 표에 대응되는 가중치에서 구분 동작을 수행할 수 있다. 구분 동작을 수행하면서 외부 서버는 일부 가중치를 변경할 수 있다. 예를 들어, 외부 서버는 표에 대응되는 가중치 중 “0.62”를 “0.82”로 변경할 수 있다. 외부 서버는 구분 동작에 기초하여 표에 대 응되는 가중치를 획득할 수 있다. 그리고, 외부 서버는 획득된 표에 대응되는 가중치에 기초하여 프루닝 동작을 수행하여 표에 대응되는 가중치를 획득할 수 있다. 그리고, 외부 서버는 획득된 표에 대응 되는 가중치에 기초하여 재학습 동작을 수행하여 표에 대응되는 가중치를 획득할 수 있다. 외부 서버는 표에 대응되는 가중치에 기초하여 90% 프루닝 동작을 수행할 수 있다. 90% 프루닝 동작은 표에 대응되는 가중치(0을 포함)에서 10%의 가중치를 남기고 90%의 가중치를 0 으로 변환하는 것을 의미할 수 있다. 외부 서버는 표에 대응되는 가중치에서 구분 동작을 수행할 수 있다. 여기서, 구분 동작은 별도의 데이터 변경 없이 그대로 가중치가 배열되는 것을 의미할 수 있다. 외부 서 버는 구분 동작에 기초하여 표에 대응되는 가중치를 획득할 수 있다. 그리고, 외부 서버는 획득된 표 에 대응되는 가중치에 기초하여 프루닝 동작을 수행하여 표에 대응되는 가중치를 획득할 수 있다. 그리고, 외부 서버는 획득된 표에 대응되는 가중치에 기초하여 재학습 동작을 수행하여 표에 대응 되는 가중치를 획득할 수 있다. 여기서, 외부 서버는 표에 대응되는 가중치 중 0값이 아닌 가중치(“1.43 ”, “0.94”)가 제1 클래스에 대응되는 가중치인 것으로 식별할 수 있다. 그리고, 외부 서버는 제2 클래스에 대응되는 가중치를 식별하기 위하여 복원 동작을 수행할 수 있다. 도 14c는 도 14b의 동작을 연속하여 설명하기 위한 도면이다. 도 14c를 참조하면, 외부 서버는 표에 대응되는 가중치에 기초하여 복원 동작을 수행할 수 있다. 외부 서버는 표에 대응되는 가중치에 기초하여 복원 동작을 수행할 수 있다. 구체적으로, 외부 서 버는 90% 프루닝 동작에서 0으로 변환되었던 가중치(“0.71”, “0.85”)를 복원함으로서 표에 대 응되는 가중치를 획득할 수 있다. 그리고, 외부 서버는 표에 대응되는 가중치에 기초하여 재학습 동작을 수행함으로서 표에 대응되는 가중치를 획득할 수 있다. 여기서, 재학습 동작에 기초하여 일부 가중치가 변경될 수 있다. 여기서, 외부 서버는 제1 클래스에 대응되는 가중치(“1.43”, “0.94”)는 변경하지 않고 복원 동작에서 추가된 가중치(“0.71”, “0.85”)만을 새로운 가중치(“0.66”, “1.10”)로 변경할 수 있 다. 여기서, 외부 서버는 복원 과정에서 새로 획득된 가중치(“0.66”, “1.10”)를 제2 클래스에 대응되는 가 중치로 식별할 수 있다. 한편, 외부 서버는 표에 대응되는 가중치에 기초하여 복원 동작을 수행할 수 있다. 외부 서버는 표 에 대응되는 가중치에 기초하여 복원 동작을 수행할 수 있다. 구체적으로, 외부 서버는 80% 프루닝 동작에서 0으로 변환되었던 가중치(“0.30”, “0.41”)를 복원함으로서 표에 대응되는 가중치를 획득할 수 있다. 그리고, 외부 서버는 표에 대응되는 가중치에 기초하여 재학습 동작을 수행함으로서 표 에 대응되는 가중치를 획득할 수 있다. 여기서, 재학습 동작에 기초하여 일부 가중치가 변경될 수 있다. 여기서, 외부 서버는 제1 클래스에 대응되는 가중치(“1.43”, “0.94”) 및 제2 클래스에 대응되는 가중치(“ 0.66”, “1.10”)는 변경하지 않고 복원 동작에서 추가된 가중치(“0.30”, “0.41”)만을 새로운 가중 치(“0.14”, “0.49”)로 변경할 수 있다. 여기서, 외부 서버는 복원 과정에서 새로 획득된 가중치(“0.14”, “0.49”)를 제3 클래스에 대응되는 가중치로 식별할 수 있다. 외부 서버는 결과적으로 복수의 클래스로 구분된 가중치를 획득할 수 있다. 구체적으로, 제1 클래스에 대 응되는 가중치는 “1.43”, “0.94”일 수 있고, 제2 클래스에 대응되는 가중치는 “0.66”, “1.10”일 수 있 고, 제3 클래스에 대응되는 가중치는 “0.14”, “0.49”일 수 있다. 외부 서버는 획득된 가중치에 관하 여 인덱스 및 인덱스에 대응되는 가중치를 결합하여 가중치 정보를 생성할 수 있다. 그리고, 외부 서버는 생성 된 가중치 정보를 전자 장치에 전송할 수 있다. 도 14d는 가중치 분포를 설명하기 위한 도면이다. 도 14d를 참조하면, 그래프는 가중치의 분포를 나타낼 수 있다. 그래프의 가로축은 가중치를 의미 할 수 있으며, 세로축은 가중치의 수를 의미할 수 있다. 도 14a 및 도 14b에서 설명한 가중치들과 관련하여, 가 중치의 절대값이 작을수록 가중치의 개수가 많을 수 있으며, 가중치의 절대값이 클수록 가중치의 개수가 적을 수 있다. 도 15는 복수의 클래스로 구분된 가중치 정보에 기초하여 인공 지능 분석을 수행하는 복수의 실시 예를 설명하 기 위한 도면이다. 도 15에서 개시하는 제1 실시 예는 커널 발생부와 NPU(1535, 신경망 프로세서)가 구분된 실시 예일 수 있다. 구체적으로, 제1 실시 예는 초기 가중치를 복수의 클래스로 구분하는 동작, 구분된 복수 의 클래스에 대응되는 가중치 및 전자 장치의 리소스에 기초하여 어느 클래스에 대응되는 가중치를 이용할 것인지 결정하는 동작을 포함할 수 있다. 여기서, 가중치를 복수의 클래스로 구분하여 저장하는 동작은 외부 서버(미도시)에서 이루어질 수 있으며, 이외의 동작은 전자 장치에서 수행될 수 있다. 전자 장치 는 외부 서버(미도시)로부터 복수의 클래스로 구분된 가중치를 수신하여 DRAM(메모리)에 저장할 수 있다. 한편, 외부 서버(미도시)는 인공 지능 모델에 이용되는 가중치를 결정하기 위하여 계산 과정을 수행하는 서버를 의미할 수 있다. 초기 가중치를 복수의 클래스로 구분하여 저장하는 동작과 관련하여, 외부 서버(미도시)는 초기 가중치가 저장된 환경에서 초기 가중치를 복수의 클래스로 구분하는 환경으로 변경할 수 있다. 초기 가중치 가 저장된 환경이란 인공 지능 모듈에 이용되는 복수의 가중치들이 기설정된 개수로 유지되는 환경을 의 미할 수 있다. 초기 가중치를 복수의 클래스로 구분하는 환경이란 초기 저장된 기 설정된 가중치를 가중 치의 크기값(또는 가중치의 중요도)에 기초하여 복수의 클래스로 구분해 놓는 환경을 의미할 수 있다. 초기 가 중치를 복수의 클래스로 구분하는 환경에 대한 구체적인 동작은 도 14a 및 도 14b에서 기재 하였으므로 중복 설명을 생략한다. 한편, 초기 가중치가 저장된 환경 및 초기 가중치를 복수의 클래스로 구분하는 환 경은 외부 서버(미도시)의 환경일 수 있다. 외부 서버(미도시)는 각각의 환경(1505, 1506)에 대응되는 가 중치 정보를 전자 장치에 전송할 수 있으며, 전자 장치는 수신된 가중치 정보를 DRAM(미도시)에 저장 할 수 있다. 특히, 전자 장치는 오프라인 상태(외부 네트워크와 연결되지 않은 환경)에서 가중치를 복수의 클래스로 구분하여 저장할 수 있다. 제1 실시 예에 따라, 전자 장치는 DRAM(미도시), 상태 분석 모듈, 동작 제어 모듈, 커 널 발생부, SRAM, 신경망 프로세서 중 적어도 하나를 포함할 수 있다. DRAM(미도시)은 복수의 클래스에 대응되는 가중치 정보를 외부 서버(미도시)로부터 수신하여 저장할 수 있다. 그리고, 전자 장치는 커널 발생부에 기초하여 필요한 가중치 정보를 DRAM(미도시)에서 커널 발생부로 전송할 수 있다. 그리고, 커널 발생부는 필요한 가중치 정보에 기초하여 새로운 가중치 정보를 생성할 수 있다. 한편, 커널 발생부에서 가중치 정보를 변경할 필요가 없는 경우, 전자 장치는 DRAM(미도시)에서 바로 SRAM에 가중치를 전송할 수 있다. 가중치 정보를 결합하여 새로운 가중치 정보를 생성할지 기존 가중치 정보를 그대로 이용할지 여부는 상태 분석 모듈, 동작 제어 모듈에 기초하여 판단될 수 있다. 구체적으로, 상태 분석 모듈은 현재 전자 장치의 리소스 상태를 분석할 수 있다. 그리고, 동작 제어 모듈은 상태 분석 모듈에서 식별한 전자 장치의 리소스에 기초하여 동작 지점을 결정할 수 있다. 동작 지점을 선택하는 동작은 DRAM(미도시) 에 저장된 복수 개의 클래스에 대응되는 가중치 정보를 어떻게 이용할 것인지 결정하는 동작일 수 있다. 일 예로, 현재 전자 장치의 리소스가 충분한 경우, 동작 제어 모듈은 모든 클래스에 대응되는 가중 치 정보를 모두 이용하여 인공 지능 분석을 수행할 수 있다. 모든 클래스에 대응되는 가중치 정보를 종합하여 인공 지능 분석을 수행하기 위하여 동작 제어 모듈은 제1 클래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정보, 제3 클래스에 대응되는 가중치 정보를 결합(또는 통합)하도록 결정할 수 있다. 그리고, 전자 장치 는 제1 클래스에 대응되는 가중치 정보, 제2 클래스에 대응되는 가중치 정보, 제3 클래스에 대 응되는 가중치 정보를 DRAM(미도시)에서 커널 발생부로 전송할 수 있고 커널 발생부에서 제1 클래 스, 제2 클래스 및 제3 클래스에 대응되는 통합 가중치 정보를 생성할 수 있다. 그리고, 전자 장치는 생성 된 통합 가중치 정보를 커널 발생부에서 SRAM으로 전송할 수 있다. 다른 예로, 전자 장치 의 리소스가 충분하지 않은 경우, 동작 제어 모듈은 최적의 동작 지점을 식별 할 수 있다. 최적의 동작 지점은 사용자 만족도(분석 정확도) 및 처리 시간 중 적어도 하나에 기초하여 결정될 수 있다. 최적의 동작 지점이 제1 클래스에 대응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행하는 것으로 결정되었다고 가정한다. 동작 제어 모듈은 새로운 가중치 정보를 생성하지 않고 DRAM(미도시)에 저 장된 제1 클래스에 대응되는 가중치 정보를 SRAM으로 전송하도록 제어 신호를 DRAM(미도시)에 전송할 수 있다. SRAM은 DRAM(미도시) 또는 커널 발생부로부터 가중치 정보를 수신하여 신경망 프로세서에 전 달할 수 있다. 신경망 프로세서는 수신된 가중치 정보에 기초하여 인공 지능 분석을 수행할 수 있다. 한편, 제2 실시 예는 NPU에 커널 발생부가 포함된 형태로 구현되는 실시 예일 수 있다. 제2 실시 예에서 제1 실시 예에서와 마찬가지로 외부 서버에서 초기 가중치를 복수의 클래스로 구분하 여 저장하는 동작이 동일하게 이루어질 수 있으며, 중복되는 설명을 생략한다. 제2 실시 예에 따라, 전자 장치는 DRAM, DMAC, SRAM, NPU, 커널 발생부 를 포함할 수 있다. 전자 장치는 외부 서버(미도시)로부터 복수의 클래스로 구분된 가중치 정보를 수신하여 DRAM에 저장할 수 있다. 그리고, 전자 장치는 상태 분석 모듈(미도시), 동작 제어 모듈(미 도시)에 기초하여 전자 장치의 리소스 상태를 분석하고 동작 지점을 결정할 수 있다. 전자 장치는 결 정된 동작 지점에 대한 정보를 NPU에 저장할 수 있다. 그리고, NPU는 결정된 동작 지점에 대응되는 가중치 정보를 요청하는 제어 신호를 생성할 수 있다. 그리고, 전자 장치는 생성된 제어 신호를 DRAM에 전송 할 수 있다. 그리고, 전자 장치는 생성된 제어 신호에 대응되는 가중치 정보를 DRAM에서 획득하여 DMAC, SRAM을 거쳐 NPU에 전송할 수 있다. 그리고, NPU는 수신된 가중치 정보를 커널 발생부에 전송할 수 있다. 그리고, 커널 발생부는 수신된 가중치 정보 에 기초하여 결정된 동작 지점에 대응되는 새로운 가중치 정보를 생성할 수 있다. 도 16은 복수의 클래스로 가중치 정보에 기초하여 인공 지능 분석을 수행하는 다른 실시 예를 설명하기 위한 도 면이다. 도 16을 참조하면, 전자 장치는 동작 제어 모듈, 동작 지점 결정 모듈, 모드 결정 모듈 , 커널 발생부, 메모리 중 적어도 하나를 포함할 수 있다. 여기서, 메모리는 on-chip memory 또는 SRAM일 수 있다. 동작 제어 모듈은 전자 장치의 리소스를 분석하여 현재 전자 장치의 리소스가 충분한지 부족한 지 판단할 수 있다. 만약, 전자 장치의 리소스가 부족한 경우, 동작 제어 모듈은 최적의 동작 지점 을 찾도록 동작 지점 결정 모듈을 이용할 수 있다. 동작 지점 결정 모듈은 현재 전자 장치에 서 이용 가능한 리소스와 필요한 리소스를 비교하여 최적의 동작 지점을 식별할 수 있다. 구체적으로, 동작 지 점 결정 모듈은 복수의 클래스 중 어느 클래스를 이용하여 인공 지능 분석을 수행하여야 하는지 결정할수 있다. 어느 클래스를 이용하여 인공 지능 분석을 수행해야하는지 동작 지점 결정 모듈에 의하여 결정 되면, 커널 발생부는 동작 지점 결정 모듈 에 의하여 결정된 클래스에 대응되는 클래스에 대응되는 가중치 정보를 수신할 수 있다. 그리고, 커널 발생부는 수신된 가중치 정보에 기초하여 새로운 가중치 정 보를 생성할 수 있다. 그리고, 커널 발생부는 생성된 가중치 정보를 메모리에 전송할 수 있다. 동작 제어 모듈은 최적의 동작 지점을 식별한 이후 현재 새로운 클래스에 대응되는 가중치 정보를 추가할 것인지 기존 가중치 정보에서 특정 클래스에 대응되는 가중치 정보를 제거할 것인지 결정할 수 있다. 현재 새로 운 클래스에 대응되는 가중치 정보를 추가하는 실시 예는 도 5a 및 도 9의 실시 예와 유사할 수 있으며, 기존 가중치 정보에서 특정 클래스에 대응되는 가중치 정보를 제거하는 실시 예는 도 10a의 실시 예와 유사할 수 있 다. 모드 결정 모듈은 현재 전자 장치의 리소스 상태에 초하여 현재 삽입 모드가 필요한지 제거 모드가 필요한지에 대한 제어 신호를 전송 받을 수 있다. 새로운 클래스에 대응되는 가중치 정보를 추가하는 실시 예의 경우, 모드 결정 모듈은 삽입 모드를 결정할 수 있다. 삽입 모드는 기존 인덱스에 새로운 가중치를 삽입 하여 새로운 가중치 정보를 생성하는 것을 의미할 수 있다. 한편, 기존 가중치 정보에서 특정 클래스에 대응되 는 가중치 정보를 제거하는 실시 예의 경우, 모드 결정 모듈은 제거 모드를 결정할 수 있다. 제거 모드는 기존 가중치 중 적어도 하나의 가중치를 0으로 변경하는 것을 의미할 수 있다. 모드 결정 모듈은 결정된 모드에 따라 커널 발생부에 대응되는 제어 신호를 전송할 수 있다. 여기서, 커널 발생부는 디코더의 역할을 수행할 수 있다. 디코더는 이전과 현재 설정된 동작 지점의 차이 에 맞게 클래스를 구성할 수 있다. 또한, 디코더는 각 클래스의 가중치 정보를 디코딩하여 결합할 수 있다. 그 리고, 디코더는 모드 결정 모듈에 의하여 결정된 모드에 따라 데이터를 커널 발생부에 전달할 수 있다. 커널 발생부는 삽입 모드인 경우 인덱스 및 가중치 모두 커널 발생부에 전송할 수 있다. 또 한, 커널 발생부는 제거 모드인 경우 인덱스만을 커널 발생부에 전송할 수 있다. 삽입 모드의 경우 가중치를 삽입하는 동작을 수행해야 하므로 가중치가 필요하지만 제거 모드의 경우 특정 위치의 가중치를 제거 하는 동작을 수행하는 것이므로 특정 위치에 대응되는 인덱스만 전송할 수 있다. 또한, 커널 발생부는 삽입 모드 또는 제거 모드에 따라 기 정의된 동작을 수행하여 새로운 가중치 정보를 생성할 수 있다. 그리고, 커널 발생부는 생성된 가중치 정보를 메모리에 전송할 수 있다. 전자 장 치는 메모리에 전송된 가중치 정보에 기초하여 인공 지능 분석을 수행할 수 있다. 도 17은 리소스 정보를 고려하여 클래스를 식별하는 일 실시 예를 설명하기 위한 도면이다. 도 17을 참조하면, 전자 장치는 내부 메모리 리소스 및 클래스별 리소스에 기초하여 인공 지 능 분석에 이용되는 클래스를 식별할 수 있다. 전자 장치에 포함된 내부 메모리의 총 리소스가 100이라고 가정한다. 내부 메모리 리소스는 사용 리 소스 및 가용 리소스를 포함할 수 있다. 사용 리소스는 현재 내부 메모리가 사용하고 있는 리소스를 의미할 수 있으며, 가용 리소스는 현재 내부 메모리에서 추가적으로 처리 가능한 용량을 의미할 수 있다. 현재 내부 메모리와 관련하여 사용 리소스가 40이고 가용 리소스가 60이라고 가정한다. 그리고, 클 래스별 리소스(또는 클래스 조합별 리소스)는 복수의 클래스 조합에 따른 리소스 정보를 의미할 수 있다. 예를 들어, 전자 장치 는 제1 클래스만을 이용하여 인공 지능 분석을 수행하는데 필요한 리소스와 제1 클래스 및 제2 클래스를 이용하여 인공 지능 분석을 수행하는데 필요한 리소스를 저장할 수 있다. 여 기서, 제1 클래스만을 이용하여 인공 지능 분석을 수행하는데 필요한 리소스 가 40이고 제1 클래스 및 제 2 클래스를 이용하여 인공 지능 분석을 수행하는데 필요한 리소스 가 80이라고 가정한다. 전자 장치는 가용 리소스가 60이므로 가용 리소스보다 높은 리소스가 필요한 동작을 처리하지 않는 것으로 판단할 수 있다. 그리고, 전자 장치는 가용 리소스보다 작은 리소스가 필요한 동작을 처리할 수 있다. 가용 리소스보다 작은 리소스에 대응되는 클래스 조합은 제1 클래스만을 이용하는 경우 로 판단할 수 있다. 따라서, 전자 장치는 제1 클래스만을 이용하여 인공 지능 분석을 수행할 수 있다. 이 경우, 내부 메모리에서 추가적으로 처리해야 할 처리 리소스는 40일 수 있다. 전자 장치는 제1 클래스만을 이용하여 인공 지능 분석을 수행할 수 있고, 인공 지능 분석이 수행되는 동안 내부 메모리의 리소스는 사용 리소스가 80이고 가용 리소스가 20일 수 있다.도 18은 리소스 정보를 고려하여 클래스를 식별하는 다른 실시 예를 설명하기 위한 도면이다. 도 18을 참조하면, 내부 메모리 리소스, 클래스별 리소스, 처리 리소스, 사용 리소스 (1811,1861-1,1861-2), 가용 리소스(1812,1862-1,1862-2)는 도 17의 내부 메모리 리소스, 클래스별 리소 스, 처리 리소스, 사용 리소스 (1711,1741), 가용 리소스(1712,1742)에 대응될 수 있으므로 중복 설명은 생략한다. 전자 장치에 포함된 내부 메모리의 총 리소스가 100이라고 가정한다. 그리고, 현재 내부 메모리와 관련하 여 사용 리소스가 10이고 가용 리소스가 90이라고 가정한다. 그리고, 클래스별 리소스와 관 련하여, 제1 클래스만을 이용하여 인공 지능 분석을 수행하는데 필요한 리소스 가 40이고 제1 클래스 및 제2 클래스를 이용하여 인공 지능 분석을 수행하는데 필요한 리소스 가 80이라고 가정한다. 전자 장치는 현재 내부 메모리의 가용 리소스보다 작은 클래스 조합을 식별할 수 있다. 가용 리소스 보다 작은 클래스 조합은 제1 클래스를 이용하는 조합, 제1 클래스 및 제2 클래스를 모두 이용하는 조합 일 수 있다. 내부 메모리의 가용 리소스가 여유가 있어 클래스 조합과 관련하여 복수의 조합이 모두 실행 가능한 상황일 수 있다. 즉, 처리 리소스는 제1 클래스만을 이용한 인공 지능 분석의 경우 40일 수 있고, 제1 클래스 및 제2 클래스를 모두 이용한 인공 지능 분석의 경우 80일 수 있다. 따라서, 전자 장치는 기 설정된 기준에 의하여 복수의 조합 중 특정 조합을 식별할 수 있다. 기 설정된 기 준은 사용자 만족도와 관련된 것일 수 있으며, 사용자 만족도는 처리 속도 또는 처리 결과의 품질(정확도) 중 적어도 하나일 수 있다. 일 예로, 전자 장치가 처리 속도가 중요한 인공 지능 분석을 수행하는 것으로 가정한다. 전자 장치 는 복수의 클래스 조합 중 리소스가 낮은 클래스 조합(제1 클래스만을 이용)을 식별할 수 있다. 그리고, 제1 클래스만을 이용하여 인공 지능 분석을 수행하는 동안 내부 메모리의 리소스(1860-1)는 사용 리소스(1861- 1)가 50이고 가용 리소스(1862-1)가 50일 수 있다. 다른 예로, 전자 장치가 처리 결과의 품질이 중요한 인공 지능 분석을 수행하는 것으로 가정한다. 전자 장치는 복수의 클래스 조합 중 리소스가 높은 클래스 조합(제1 클래스 및 제2 클래스 모두를 이용)을 식별할 수 있다. 그리고, 제1 클래스 및 제2 클래스 모두를 이용하여 인공 지능 분석을 수행하는 동안 내부 메 모리의 리소스(1860-2)는 사용 리소스(1861-2)가 90이고 가용 리소스(1862-2)가 10일 수 있다. 도 19은 리소스 정보를 고려하여 클래스를 식별하는 또 다른 실시 예를 설명하기 위한 도면이다. 도 19을 참조하면, 내부 메모리 리소스, 클래스별 리소스, 처리 리소스, 사용 리소스 (1911,1951), 가용 리소스(1912,1952)는 도 17의 내부 메모리 리소스, 클래스별 리소스, 처리 리 소스, 사용 리소스 (1711,1741), 가용 리소스(1712,1742)에 대응될 수 있으므로 중복 설명은 생략한다. 전자 장치에 포함된 내부 메모리의 총 리소스가 100이라고 가정한다. 그리고, 현재 내부 메모리와 관련하 여 사용 리소스가 40이고 가용 리소스가 60이라고 가정한다. 그리고, 클래스별 리소스와 관 련하여, 제1 클래스만을 이용하여 인공 지능 분석을 수행하는데 필요한 리소스 가 40이고 제1 클래스 및 제2 클래스를 이용하여 인공 지능 분석을 수행하는데 필요한 리소스 가 80이라고 가정한다. 전자 장치가 인공 지능 분석을 수행함에 있어 클래스 조합에 따라 필요할 리소스 이외에 인공 지능 분석 중 특정 동작에 필요한 요구 리소스가 있을 수 있다. 예를 들어, 인공 지능 분석과정에서 이루어지는 다 양한 기능들은 추가 리소스가 필요할 수 있다. 예를 들어, 인공 지능 분석에서 이루어지는 동작 중 제1 기능의 리소스가 20이라고 가정한다. 도 17 및 도 18에서는 클래스별 조합에 따른 리소스만을 고려하였지만, 전자 장치는 추가적으로 특정 동작 에 필요한 요구 리소스를 고려할 수 있다. 결과적으로, 제1 클래스만을 이용하여 제1 기능을 수행하기 위 하여 총 60의 리소스가 필요하며 제1 클래스 및 제2 클래스를 이용하여 제1 기능을 수행하기 위하여 총 100의 리소스가 필요할 수 있다. 여기서, 전자 장치는 가용 리소스가 90이므로 제1 클래스 및 제2 클래스를 이용하여 제1 기능을 수 행할 수 없다고 판단할 수 있으며, 제1 클래스만을 이용하여 제1 기능을 수행할 수 있다. 여기서, 내부 메모리 에서 추가적으로 수행되는 동작과 관련하여 처리 리소스는 60일 수 있다. 그리고, 제1 클래스만을 이용하여 인공 지능 분석 중 제1 기능을 수행하는 동안 내부 메모리의 리소스는 사용 리소스가 70이고 가용 리소스가 30일 수 있다. 도 20은 동작 지점을 설정하는 동작을 설명하기 위한 흐름도이다. 도 20을 참조하면, 전자 장치는 전자 장치의 리소스 상태를 확인할 수 있다(S2005). 전자 장치 는 현재 전자 장치의 실시간 리소스 정보를 획득할 수 있다. 또한, 전자 장치는 동작 상황이 종료되었는지 여부를 판단할 수 있다 (S2010). 여기서, 동작 상황이란 현 재 전자 장치가 리소스를 이용하여 특정 동작을 수행하는 상황을 의미할 수 있다. 예를 들어, 동작 상황은 전자 장치가 인공 지능 분석을 위하여 수학적 계산을 수행하는 상황일 수 있다. 전자 장치의 동작 상황이 종료되지 않은 경우, 전자 장치는 동작 지점의 변경이 필요한지 여부를 판 단할 수 있다 (S2015). 그리고, 전자 장치의 동작 상황이 종료된 경우, 전자 장치는 동작 지점의 변 경이 필요한지 여부를 판단하지 않을 수 있다. 여기서, 동작 지점이란 전자 장치가 리소스를 이용하여 특 정 동작을 수행하는 데이터 처리 방식 또는 데이터 처리 기준값을 의미할 수 있다. 예를 들어, 동작 지점이 변경되는 것은 데이터 처리 방식 또는 데이터 처리 기준값이 변경되는 것을 의미할 수 있다. 데이터 처리 방식은 빠른 속도로 데이터를 처리하는 방식 또는 고품질(정확도)의 분석 결과를 획득하도록 데이터를 처리하는 방식이 있을 수 있다. 일반적으로 빠른 속도 또는 고품질을 위한 데이터 처리 방식은 리소스 가 많이 필요할 수 있고 느린 속도 또는 저품질을 위한 데이터 처리 방식은 리소스가 적게 필요할 수 있다. 전자 장치는 S1605 단계에서 획득한 전자 장치의 리소스와 현재 수행하려는 특정 동작의 리소스 요구 량을 비교할 수 있다. 현재 수행하려는 특정 동작의 리소스 요구량이 전자 장치의 리소스보다 작다면, 전 자 장치는 특정 동작을 수행하고 전자 장치의 리소스 상태를 계속 확인할 수 있다 (S2016). 현재 수행하려는 특정 동작의 리소스 요구량이 전자 장치의 리소스보다 크다면, 전자 장치는 동작 지 점의 변경이 필요하다고 판단할 수 있다. 그리고, 전자 장치는 비용 함수를 생성할 수 있다. 비용 함수란 동작 지점의 변경을 위해 이용되는 함수를 의미할 수 있다. 전자 장치는 비용 함수를 이용하여 최적의 동 작 지점을 식별할 수 있다 (S2025). 전자 장치는 사용자의 만족도를 극대화하는 동작 지점을 식별할 수 있 으며, 사용자의 만족도는 처리 속도 또는 처리 결과의 품질 중 적어도 하나를 포함할 수 있다. 사용자마다 처리 속도를 더 중요하게 여기거나 고품질을 더 중요하게 여길 수 있다. 따라서, 사용자의 만족도는 사용자마다 달라 질 수 있으며 설정에 의해 변경될 수 있다. 따라서, 전자 장치는 기 정의된 사용자 만족도에 기초하여 최 적의 동작 지점을 식별할 수 있다. 그리고, 전자 장치 식별된 최적의 동작 지점을 설정하여 인공 지능 분 석을 수행할 수 있다 (S2030). 일 예로, 전자 장치에서 수행되는 인공 지능 분석이 얼굴 인식 동작이라고 가정한다. 전자 장치는 입 력 데이터에 포함된 사람의 얼굴을 탐지하고 탐지된 얼굴에 대한 세부 정보(탐지된 얼굴이 누구인지를 나타내는 정보)를 획득할 수 있다. 전자 장치에서 수행되는 인공 지능 모듈의 리소스에 기초하여 현재 7명의 얼굴만 을 분석할 수 있다고 가정한다. 하지만, 입력 데이터에 15명의 얼굴이 탐지되었다고 가정한다. 전자 장치 는 7명의 얼굴만을 분석하고 8명의 얼굴은 7명의 얼굴 분석이 완료된 이후에 분석 동작을 수행해야 한다. 여기 서, 사용자가 처리 속도를 처리 결과의 품질보다 더 중요하게 생각한다고 가정한다. 전자 장치는 동시에 최대한 많은 수의 얼굴을 분석할 수 있도록 최적의 동작 지점을 식별하여 기존 동작 지점을 변경할 수 있다. 구 체적으로, 처리 속도를 높이기 위하여, 전자 장치는 최소한의 클래스에 대응되는 가중치 정보만을 이용하 여 인공 지능 분석을 수행할 수 있다. 최소한의 클래스에 대응되는 가중치 정보만을 이용하여 인공 지능 분석을 수행하면 정확도는 떨어질 수 있으나 처리 속도를 높일 수 있으므로, 사용자의 의도에 따라 동작하는 전자 장치 를 구현할 수 있다. 다른 예로, 전자 장치에서 수행되는 인공 지능 분석이 전력 소모와 관련하여 저전력 모드를 수행하는 동작 이라고 가정한다. 전자 장치는 전력 소모량과 처리 결과의 품질에 기초하여 최적의 동작 지점을 식별할 수 있다. 한편, 전자 장치는 동작 주파수 감소에 따른 전력 사용량의 변화 및 전원 차단 중 적어도 하나에 기 초하여 최적의 동작 지점을 식별할 수 있다. 또 다른 예로, 동작 지점은 정확도(accuracy), 지연 시간(latency) 또는 지속 기간(duration) 중 적어도 하나에 기초하여 결정될 수 있다. 자율 주행 또는 동영상 재생과 관련된 작업은 실시간 개념이 중요할 수 있다. 따라서, 자율 주행 또는 동영상 재생과 관련된 작업을 수행하는 경우, 전자 장치는 지연 시간을 가장 크게 고려하고 이후 정확도를 고려하여 동작 지점을 식별할 수 있다. 여기서, 지연 시간이 낮을수록 사용자의 만족도 가 높다고 판단될 수 있으며, 정확도가 높을수록 사용자의 만족도가 높다고 판단될 수 있다. 또한, 전자 장치는 최소 지연 시간 또는 최소 정확도를 설정하여 동작 지점을 식별할 수 있다. 예를 들어, 전자 장치(10 0)는 지연 시간이 최소 33ms 이하라는 점을 고려하여 동작 지점을 식별할 수 있다. 한편, 얼굴 인식, 홍채 인식, 지문 인식과 관련된 작업은 정확성이 중요할 수 있다. 따라서, 얼굴 인식, 홍채 인식, 지문 인식과 관련된 작업을 수행하는 경우, 전자 장치는 정확도를 가장 크게 고려하고, 이후 지속 기간을 고려하여 동작 지점을 식별할 수 있다. 여기서, 정확도가 높을수록 사용자의 만족도가 높다고 판단될 수 있다. 여기서, 전자 장치는 최소 정확도를 설정하여 동작 지점을 식별할 수 있다. 예를 들어, 전자 장치 는 최소 정확도가 95% 이상이라는 점을 고려하여 동작 지점을 식별할 수 있다. 도 21은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 도면이다. 한편, 전자 장치의 제어 방법은 제1 가중치 매트릭스와 관련된 가중치 및 가중치에 대응되는 제1 인덱스를 포함하는 제1 정보 및 제2 가중치 매트릭스를 획득하기 위한 추가 가중치 및 추가 가중치에 대응되는 제2 인덱 스를 포함하는 제2 정보를 저장할 수 있다 (S2105). 또한, 제어 방법은 전자 장치의 리소스 정보에 기초하 여 제1 정보를 로딩하여 제1 가중치 매트릭스를 획득하거나, 제1 정보 및 제2 정보를 로딩하여 제2 가중치 매트 릭스를 획득한다 (S2110). 여기서, 제어 방법은 입력 데이터를 제1 가중치 매트릭스 또는 제2 가중치 매트릭스를 이용하는 인공 지능 모델 (Artificial Intelligence Model)에 입력하여 출력 데이터를 획득하는 단계 및 전자 장치의 리소스 정보 가 변경되면, 변경된 리소스 정보에 기초하여 제1 가중치 매트릭스에 기초하여 제2 가중치 매트릭스를 획득하거 나, 제2 가중치 매트릭스에 기초하여 제1 가중치 매트릭스를 획득하는 단계를 더 포함할 수 있다. 한편, 제2 가중치 매트릭스는 제1 정보에 포함된 가중치, 제1 인덱스, 추가 가중치 및 제2 인덱스에 기초하여 획득될 수 있다. 한편, 전자 장치는 제2 클래스에 대응되는 제2 가중치 정보 (또는 제2 정보)를 획득할 수 있고, 또한, 제2 가중치 정보는 제2 클래스에 포함된 가중치, 제2 클래스에 포함된 가중치에 대응되는 제2 인덱스를 포함할 수 있다. 일 실시 예에 따른 전자 장치는 제1 가중치 정보에 기초하여 제1 가중치 매트릭스를 획득할 수 있다. 여기 서, 제1 가중치 매트릭스는 제1 클래스만을 이용하여 획득된 것이며 상대적으로 높은 가중치가 반영된 매트릭스 일 수 있다. 다른 실시 예에 따른 전자 장치는 제1 가중치 정보 및 제2 가중치 정보에 기초하여 제2 가중치 매트릭스를 획득할 수 있다. 여기서, 제2 가중치 매트릭스는 제1 클래스 및 제2 클래스를 이용하여 획득된 것일 수 있다. 제2 가중치 매트릭스는 제1 가중치 정보에 포함된 가중치, 제1 인덱스, 추가 가중치 및 제2 인덱스에 기초하여 획득될 수 있다. 여기서, 제1 가중치 정보에 포함된 가중치는 제1 클래스에 포함된 가중치를 의미할 수 있고, 제1 인덱스는 제1 클래스에 포함된 가중치에 대응되는 인덱스를 의미할 수 있다. 또한, 추가 가중치는 제2 클래스에 포함된 가중 치를 의미할 수 있으며 제2 인덱스는 제2 클래스에 포함된 가중치에 대응되는 인덱스를 의미할 수 있다. 여기서, 제2 가중치 매트릭스를 획득하는 단계는 제1 인덱스 및 제2 인덱스에 기초하여 제1 정보에 포함된 가중 치에 추가 가중치를 결합하여 제2 가중치 매트릭스를 획득할 수 있다. 제1 인덱스 및 제1 가중치 정보에 포함된 가중치는 제1 클래스와 관련된 정보일 수 있고, 제2 인덱스 및 추가 가중치는 제2 클래스와 관련된 것일 수 있다. 결국, 전자 장치는 제1 가중치 정보 및 제2 가중치 정보를 결합하여 새로운 가중치 정보를 생성할 수 있고, 새로 생성된 가중치 정보에 기초하여 새로운 가중치 매트릭스 를 생성할 수 있다. 여기서, 제2 가중치 매트릭스를 획득하는 단계는 제1 인덱스에 기초하여 제2 가중치 매트릭스에서 제1 인덱스에 대응되는 가중치의 위치를 결정할 수 있고, 제2 인덱스에 기초하여 제2 가중치 매트릭스에서 제2 인덱스에 대응 되는 추가 가중치의 위치를 결정할 수 있고, 제1 인덱스에 대응되는 가중치의 위치 및 제2 인덱스에 대응되는 가중치의 위치에 기초하여 제1 인덱스 또는 제2 인덱스 중 적어도 하나를 변경할 수 있고, 가중치의 위치, 추가 가중치의 위치 및 변경된 인덱스에 기초하여 제2 가중치 매트릭스를 획득할 수 있다. 리소스 정보는 현재 전자 장치의 리소스 및 특정 모듈(또는 특정 동작)을 수행하기 위하여 필요한 요구 리 소스에 관련된 정보를 의미할 수 있다.여기서, 리소스 정보는 전자 장치의 내부 메모리 용량(총 용량, 이용 용량, 가용 용량), 전자 장치의 전력 상태, 전자 장치에서 실행되는 어플리케이션의 리소스, 전자 장치에서 실행되는 인공 지능 모델 의 리소스 중 적어도 하나를 포함할 수 있다. 일 예로, 리소스 정보는 전자 장치의 전력 상태에 대응되는 요구 리소스를 포함할 수 있다. 전자 장치 의 전력 상태가 고성능 모드인 경우 요구 리소스가 클 수 있다. 하지만, 전자 장치의 전력 상태가 절 전 모드인 경우 요구 리소스가 작을 수 있다. 전자 장치의 전력 상태에 따라 요구 리소스가 달라질 수 있 으므로, 전자 장치는 전자 장치의 전력 상태에 대응되는 리소스 정보에 기초하여 제1 정보를 로딩할 지 또는 제1정보 및 제2 정보를 모두 로딩할지 결정할 수 있다. 다른 예로, 리소스 정보는 전자 장치에서 실행되는 어플리케이션에 따른 요구 리소스를 포함할 수 있다. 전자 장치에서 실행되는 어플리케이션이 인공 지능 모듈을 분석하는 경우 요구 리소스가 클 수 있다. 하지 만, 전자 장치에서 실행되는 어플리케이션이 알람 기능과 관련된 프로그램인 경우 요구 리소스가 작을 수 있다. 전자 장치에서 실행되는 어플리케이션의 리소스에 따라 요구 리소스가 달라질 수 있으므로, 전자 장 치는 전자 장치에서 실행되는 어플리케이션에 대응되는 리소스 정보에 기초하여 제1 정보를 로딩할지 또는 제1정보 및 제2 정보를 모두 로딩할지 결정할 수 있다. 또 다른 예로, 리소스 정보는 전자 장치에서 실행되는 인공 지능 모델의 리소스에 대응되는 요구 리소스가 달라질 수 있다. 인공 지능 모델의 리소스가 다르다는 것은 분석 동작이 다르다는 것을 의미할 수 있다. 이미지 인식과 관련된 인공 지능 모델의 경우 요구 리소스가 클 수 있다. 하지만, 텍스트 인식과 관련된 인공 지능 모 델의 경우 요구 리소스가 작을 수 있다. 전자 장치에서 실행되는 인공 지능 모델의 리소스에 따라 요구 리 소스가 달라질 수 있으므로, 전자 장치는 전자 장치에서 실행되는 인공 지능 모델의 리소스에 대응되 는 리소스 정보에 기초하여 제1 정보를 로딩할지 또는 제1정보 및 제2 정보를 모두 로딩할지 결정할 수 있다. 전자 장치는 리소스 정보에 기초하여 한편, 전자 장치는 리소스 정보에 기초하여 제1 클래스에 대응 되는 가중치 정보(제1 정보)를 이용할지 아니면 제1 클래스 및 제2 클래스에 대응되는 가중치 정보(제2 정보)를 이용할지 결정할 수 있다. 전자 장치는 제1 클래스에 대응되는 가중치 정보를 이용하는 경우 필요한 리소스 및 제1 클래스 및 제2 클 래스에 대응되는 가중치 정보를 이용하는 경우 필요한 리소스에 대한 정보를 이미 저장할 수 있다. 따라서, 전 자 장치는 특정 동작을 수행하는 요구 리소스에 기초하여 제1 클래스에 대응되는 가중치 정보를 이용할지 아니면 제1 클래스 및 제2 클래스에 대응되는 가중치 정보를 이용할지 결정할 수 있다. 일 예로, 2개의 클래스가 존재하는 경우를 가정한다. 제1 클래스만을 이용하는 경우 리소스가 40이고 제1 클래 스 및 제2 클래스 모두를 이용하는 경우 리소스가 80인 것으로 가정한다. 그리고 현재 내부 메모리의 가용 리소 스가 60이라고 가정한다. 전자 장치는 현재 내부 메모리의 가용 리소스보다 작은 리소스를 갖는 특정 클래스 조합(제1 클래스만을 이용하는 경우)을 이용할 것을 결정할 수 있다. 가용 리소스는 현재 내부 메모리에 서 추가적으로 처리 가능한 용량을 의미할 수 있고, 클래스별 리소스(또는 클래스 조합별 리소스)는 복수의 클 래스 조합에 따른 리소스 정보를 의미할 수 있다. 리소스 정보와 관련된 다양한 실시 예에 대해선 도 17 내지 도 19에서 기재하였다. 한편, 전자 장치는 제2 클래스에 대응되는 가중치 정보만을 이용하는 실시 예도 구현 가능할 수 있다. 다 만, 제1 클래스가 상대적으로 높은 가중치로 구성된 가중치 그룹이고 제2 클래스가 상대적으로 낮은 가중치로 구성된 가중치 그룹이라는 점에서 낮은 가중치만으로 인공 지능 분석을 하는 실시 예가 흔하지 않을 수 있다. 부족한 리소스에서 인공 지능 분석을 해야 한다면 높은 가중치를 포함하는 클래스를 이용해야 분석 정확도가 높 아지기 때문이다. 따라서, 본 개시는 상대적으로 높은 가중치 그룹인 제1 클래스에 대응되는 가중치 정보만을 이용하는 실시 예에 대해서 자세히 기술한다. 리소스 정보가 변경되는 실시 예는 리소스 정보가 증가하는 경우와 감소하는 경우가 있을 수 있다. 2가지 경우 중 실질적으로 문제가 되는 것은 리소스가 증가하는 경우가 있을 수 있다. 리소스 정보가 감소하는 경우는 기존 내부 메모리의 가용 리소스가 증가하는 것이므로 처리 동작에 문제가 없지만, 리소스가 증가하는 경우 가용 리 소스가 감소하는 것이므로 가용 리소스보다 큰 리소스 동작을 수행하는 경우 처리 용량과 관련하여 문제가 발생 할 수 있다. 따라서, 전자 장치는 실시간으로 내부 메모리의 가용 리소스 및 인공 지능 분석에 필요한 리소스를 판단할 수 있다. 인공 지능 분석에 필요한 리소스가 내부 메모리의 가용 리소스보다 큰 경우, 전자 장치는 새로운 가중치 매트릭스를 획득할 수 있다. 새로운 가중치 매트릭스를 획득하기 위하여 전자 장치는 클래스별 리 소스 및 가용 리소스를 고려할 수 있다. 즉, 전자 장치는 가용 리소스안에서 인공 지능 분석이 수행 가능 한 클래스 조합을 식별하여 식별된 클래스 조합에 기초하여 가중치 매트릭스를 획득할 수 있다. 한편, 리소스 정보가 증가되는 실시 예는 갑자기 인공 지능 분석의 대상이 증가하여 리소스가 증가하는 경우 또 는 처리 속도가 높은 인공 지능 모듈에서 고품질의 인공 지능 모듈로 사용자가 변경하길 원하는 경우가 있을 수 있다. 또한, 리소스가 감소하는 실시 예는 인공 지능 분석의 대상이 감소하여 리소스가 감소하는 경우 또는 고 품질의 인공 지능 모듈에서 처리 속도가 높은 인공 지능 모듈로 사용자가 변경하길 원하는 경우가 있을 수 있다. 리소스가 변경되는 실시 예에 대한 구체적인 설명은 도 6a에서 기재하였다. 한편, 제1 정보는 가중치 정보에서 제1 임계값 미만의 가중치를 프루닝하여 획득된 정보에서 제2 임계값 이상의 가중치 및 제2 임계값 이상의 가중치에 대응되는 인덱스를 포함할 수 있고, 제2 정보는 프루닝하여 획득된 정보 에서 제2 임계값 미만의 가중치 및 제2 임계값 미만의 가중치에 대응되는 인덱스를 포함할 수 있다. 여기서, 제1 정보는 프루닝하여 획득된 정보에서 제2 임계값 이상의 가중치를 제1 학습하여 획득된 가중치 및 제1 학습하여 획득된 가중치에 대응되는 인덱스를 포함할 수 있고, 제2 정보는 프루닝하여 획득된 정보에서 제2 임계값 이상의 가중치 및 제2 임계값 미만의 가중치를 제2 학습하여 제2 학습하여 획득된 가중치에 대응되는 인 덱스를 포함할 수 있고, 제2 학습시에 제2 임계값 이상의 가중치는 고정될 수 있다. 한편, 제어 방법은 제2 가중치 매트릭스에 대응되는 제3 정보에 포함된 가중치, 가중치에 대응되는 제3 인덱스 및 제2 인덱스에 기초하여 제3 정보에서 제2 인덱스에 대응되는 추가 가중치를 제거하여 제1 가중치 매트릭스를 획득하는 단계를 더 포함할 수 있다. 여기서, 제1 가중치 매트릭스를 획득하는 단계는 제2 인덱스 및 제3 인덱스에 기초하여 제2 가중치 매트릭스에 서 추가 가중치의 위치를 결정할 수 있고, 추가 가중치의 위치에 기초하여 제3 정보에서 추가 가중치를 제거할 수 있고 제3 정보에서 제거된 추가 가중치의 위치와 인접한 가중치의 인덱스를 수정하여 제1 가중치 매트릭스를 획득할 수 있다. 한편, 도 21과 같은 전자 장치의 제어 방법은 도 1 또는 도 2의 구성을 가지는 전자 장치 상에서 실행될 수 있 으며, 그 밖의 구성을 가지는 전자 장치 상에서도 실행될 수 있다. 도 22는 본 개시의 일 실시 예에 따른 동작 지점 변경에 따른 지연 시간의 변화를 비교하기 위한 도면이다. 도 22를 참조하면, 전자 장치는 다양한 실시 예에 따른 컨벌루션 연산 동작을 수행할 수 있다. (a) 실시 예는 표에서, (b) 실시 예는 표에서 (c) 실시 예는 표에서, (d) 실시 예는 표에서 설 명한다. 전자 장치는 DMA로부터 On chip memory(SRAM)에 컨벌루션 레이어에 대응되는 파라미터를 전송하는 동작 을 수행할 수 있다. 또한, 전자 장치는 NPU에 포함된 커널 발생부를 통하여 컨벌루션 레이어에 대응 되는 파라미터를 이용하여 컨벌루션 연산 동작을 수행할 수 있다 . 한편, NPU는 커널 발생부 및 On chip memory(SRAM)를 포함할 수 있다. On chip memory(SRAM)에는 특정 레이어에 대응되는 파라미터 정보가 저장될 수 있으며, 커널 발생부는 On chip memory(SRAM)에 저장된 파라미터 정보를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. 한편, 2206 및 2207 영역으로 표시하는 동작들은 표뿐만 아니라 나머지 표(2210, 2215, 2220)에도 동일하 게 적용되는 바 중복 설명을 생략한다. 한편, 도 22의 표(2205 내지 2220)들은 일정한 시간 간격(T01 구간, T12 구간, T23 구간, T34 구간, T45 구간, T56 구간)으로 구분될 수 있다. 예를 들어, T01 구간은 0에서 t1 시점까지의 시간 구간을 의미할 수 있다. 표를 참조하면, 전자 장치는 T01 구간에 DMA로부터 NPU에 포함된 On chip memory(SRAM)에 기본 레 이어에 대응되는 파라미터 정보 (param0)를 전송할 수 있다. 그리고, 전자 장치는 T12 구간에 NPU에 포함된 커널 발생부를 통하여 기본 레이어에 대응되는 파라미터 정 보 (param0)를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. 그리고, 전자 장치는 T23 구간에 DMA로부터 NPU에 포함된 On chip memory(SRAM)에 제1 레이어에 대응되는 파라미터 정보 (param1)를 전송할 수 있다.그리고, 전자 장치는 NPU에 포함된 커널 발생부를 통하여 T34 구간에 NPU에 포함된 커널 발생부를 통하여 제1 레이어에 대응되는 파라미터 정보 (param1)를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. T45 구간 및 T56 구간에 대한 동작은 앞선 동작에 반복되는 바 중복 설명을 생략한다. 표에 따른 (a) 실시 예에 대응되는 총 연산 시간은 t6일 수 있다. 표에 설명한 (a) 실시 예는 DMA 로부터 파라미터 정보를 수신하는 동작과 NPU에 포함된 커널 발생부에서 컨벌루션 연산 동작을 수행하는 동작을 별개의 시간 구간에서 수행하고 있어 처리 시간이 길 수 있다. 한편, 표에 따른 (b) 실시 예는 전자 장치가 파라미터 정보를 전송하는 동작과 컨벌루션 연산 동작 을 동일한 시간 구간에서 수행할 수 있다. 구체적으로, 전자 장치는 T01 구간에서 NPU에 포함된 커널 발생 부를 통하여 기본 레이어에 대응되는 파라미터 정보 (param0)를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. 그리고, 전자 장치는 T01 구간에서 DMA로부터 NPU에 포함된 On chip memory(SRAM)에 제1 레이어에 대응되는 파라미터 정보(param1)를 전송할 수 있다. 그리고, 전자 장치는 T12 구간에 NPU에 포함된 커널 발생부를 통하여 제1 레이어에 대응되는 파라미터 정 보(param1)를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. 그리고, 전자 장치는 T12 구간에 DMA로부터 NPU에 포함된 On chip memory(SRAM)에 제2 레이어에 대응되는 파라미터 정보(param2)를 전송할 수 있다. 그리고, 전자 장치는 T23 구간에 NPU에 포함된 커널 발생부를 통하여 제2 레이어에 대응되는 파라미터 정 보(param2)를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. 표에 따른 (b) 실시 예에 대응되는 총 연산 시간은 t3일 수 있다. 이는 표의 (a) 실시 예보다 작은 크기의 연산 시간일 수 있다. 한편, 표에 따른 (c)실시 예는 동작 지점의 변경이 있는 경우를 설명하기 위한 실시 예이다. 전자 장치 는 T01 구간에서 NPU에 포함된 커널 발생부를 통하여 기본 레이어에 대응되는 파라미터 정보 (param0)를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. 그리고, 전자 장치는 T01 구간에서 DMA로부터 NPU에 포함 된 On chip memory(SRAM)에 제1 레이어에 대응되는 파라미터 정보(param1)를 전송할 수 있다. 여기서, t1 시점 에 제1 동작 지점 변경(2215-1)이 있는 것으로 가정한다. 제1 동작 지점 변경(2215-1)이 있는 것으로 식별하면, 전자 장치는 T12 구간에 DMA로부터 NPU에 포함된 On chip memory(SRAM)에 변경된 제1 레이어에 대응되는 파라미터 정보 (param1’)를 전송할 수 있다. 그리고, 전자 장치는 T23 구간에 NPU에 포함된 커널 발생부를 통하여 변경된 제1 레이어에 대응되는 파라 미터 정보 (param1’)를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. 그리고, 전자 장치는 T23 구간에 DMA로부터 NPU에 포함된 On chip memory(SRAM)에 변경된 제2 레이어에 대응되는 파라미터 정보 (param2’)를 전송할 수 있다. 여기서, t3 시점에 제2 동작 지점 변경(2215-2)이 있는 것으로 가정한다. 제2 동작 지점 변경(2215-2)이 있는 것으로 식별하면, 전자 장치는 T34 구간에 DMA로부터 NPU에 포함된 On chip memory(SRAM)에 재변경된 제2 레이어에 대응되는 파라미터 정보 (param2’’)를 전송할 수 있다. 그리고, 전자 장치는 T45 구간에 NPU에 포함된 커널 발생부를 통하여 재변경된 제2 레이어에 대응되는 파 라미터 정보 (param2’’)를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. 표에 따른 (c) 실시 예에 대응되는 총 연산 시간은 t5일 수 있다. 표에 따른 (c) 실시 예는 동작 지점의 변경이 있을 때마다 DMA로부터 새로운 파라미터 정보를 수신할 수 있다. 이 경우, 새로운 파라미터 정보 를 수신하는 과정에서 시간이 소요될 수 있다. 한편, 표에 따른 (d)실시 예는 동작 지점의 변경이 있는 경우를 DMA로부터 새로운 파라미터 정보를 수신 하지 않고 컨벌루션 연산 동작을 수행하는 과정을 설명하기 위한 실시 예이다. 전자 장치는 T01 구간에서 NPU에 포함된 커널 발생부를 통하여 기본 레이어에 대응되는 파라미터 정보 (param0)를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. 그리고, 전자 장치는 T01 구간에서 DMA로부터 NPU에 포함된 On chip memory(SRAM)에 제1 레이어에 대응되는 파라미터 정보(param1)를 전송할 수 있다. 여기서, t1 시점에 제1 동작 지점 변경(2220-1)이 있는 것으로 가정한다. 제1 동작 지점 변경(2215-1)이 있는 것으로 식별하면, 전자 장치는 T12 구간에 NPU에 포함된 커널 발생부 를 통하여 제1 레이어에 대응되는 파라미터 정보(param1)에 기초하여 변경된 제1 레이어에 대응되는 파라미터정보 (param1’)를 획득할 수 있다. 그리고, 전자 장치는 T12 구간에 NPU에 포함된 커널 발생부를 통하여 변경된 제1 레이어에 대응되는 파라미터 정보 (param1’)를 이용하여 컨벌루션 연산 동작을 수행할 수 있다. 그 리고, 전자 장치는 T12 구간에 DMA로부터 NPU에 포함된 On chip memory(SRAM)에 변경된 제2 레이어에 대 응되는 파라미터 정보(param2’)를 전송할 수 있다. 여기서, t2 시점에 제2 동작 지점 변경(2220-1)이 있는 것으로 가정한다. 제2 동작 지점 변경(2220-2)이 있는 것으로 식별하면, 전자 장치는 T23 구간에 NPU에 포함된 커널 발생부 를 통하여 변경된 제2 레이어에 대응되는 파라미터 정보(param2)에 기초하여 재변경된 제2 레이어에 대응되는 파라미터 정보 (param2’’)를 획득할 수 있다. 그리고, 전자 장치는 T23 구간에 NPU에 포함된 커널 발생 부를 통하여 재변경된 제2 레이어에 대응되는 파라미터 정보 (param2’’)를 이용하여 컨벌루션 연산 동작을 수 행할 수 있다. 표에 따른 (d) 실시 예에 대응되는 총 연산 시간은 t3일 수 있다. 표에 따른 (c) 실시 예와 달리 (d) 실시 예는 DMA로부터 새로운 파라미터 정보를 수신하지 않을 수 있다. (d) 실시 예는 기존에 수신된 파라미 터 정보를 이용하여 새로운 파라미터 정보를 새로 생성함으로써 지연 시간을 감소시킬 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 어플리케이션 형태 로 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또 는 하드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치 및 디스플레이 장치 중 적어도 하나의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실 시 예들에 따른 전자 장치(예: 전자 장치(A))를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세 서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저 장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신 호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시 적으로 저장됨을 구분하지 않는다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2019-0177115", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형 실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다. 부호의 설명100: 전자 장치110: 메모리 120: 프로세서130: 통신 인터페이스"}
{"patent_id": "10-2019-0177115", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치를 도시한 블록도이다. 도 2는 도 1의 전자 장치의 구체적인 구성을 설명하기 위한 블록도이다. 도 3은 본 개시의 일 실시 예에 따른 제로 스킵핑 동작을 설명하기 위한 도면이다. 도 4는 본 개시의 다른 실시 예에 따른 제로 스킵핑 동작을 설명하기 위한 도면이다. 도 5a는 도4의 실시 예에 따른 제로 스킵핑 동작에 의해 생성된 정보에 기초하여 가중치 매트릭스를 획득하는일 실시 예의 동작을 설명하기 위한 도면이다. 도 5b는 가중치 매트릭스를 획득하는 다른 실시 예의 동작을 설명하기 위한 도면이다. 도 6a는 가중치 매트릭스를 획득하는 다양한 실시 예를 설명하기 위한 도면이다. 도 6b는 가중치 매트릭스를 획득하는 또 다른 실시 예들을 설명하기 위한 도면이다. 도 7은 프루닝 동작 및 제로 스킵핑 동작을 설명하기 위한 도면이다. 도 8은 가중치 정보를 획득하는 일 실시 예를 설명하기 위한 도면이다. 도 9는 가중치 정보를 생성하는 실시 예를 설명하기 위한 도면이다. 도 10a는 가중치 정보를 생성하는 다른 실시 예를 설명하기 위한 도면이다. 도 10b는 도 10a의 실시 예에서 다른 계산 과정을 적용하는 동작을 설명하기 위한 도면이다. 도 10c 는 가중치 정보를 생성하는 또 다른 실시 예를 설명하기 위한 도면이다. 도 11은 프루닝 동작에 기초하여 변경되는 가중치의 분포를 설명하기 위한 도면이다. 도 12는 전자 장치의 리소스를 고려하지 않고 가중치를 결정하는 실시 예를 설명하기 위한 도면이다. 도 13은 전자 장치의 리소스를 고려하여 가중치를 결정하는 실시 예를 설명하기 위한 도면이다. 도 14a는 복수의 가중치를 복수의 클래스로 구분하는 동작을 설명하기 위한 도면이다. 도 14b는 복수의 가중치를 복수의 클래스로 구분하는 동작의 계산 과정을 설명하기 위한 도면이다. 도 14c는 도 14b의 동작을 연속하여 설명하기 위한 도면이다. 도 14d는 가중치 분포를 설명하기 위한 도면이다. 도 15는 복수의 클래스로 구분된 가중치 정보에 기초하여 인공 지능 분석을 수행하는 일 실시 예를 설명하기 위 한 도면이다. 도 16은 복수의 클래스로 가중치 정보에 기초하여 인공 지능 분석을 수행하는 다른 실시 예를 설명하기 위한 도 면이다. 도 17은 리소스 정보를 고려하여 클래스를 식별하는 일 실시 예를 설명하기 위한 도면이다. 도 18은 리소스 정보를 고려하여 클래스를 식별하는 다른 실시 예를 설명하기 위한 도면이다. 도 19은 리소스 정보를 고려하여 클래스를 식별하는 또 다른 실시 예를 설명하기 위한 도면이다. 도 20은 동작 지점을 설정하는 동작을 설명하기 위한 흐름도이다. 도 21은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 도면이다. 도 22는 본 개시의 일 실시 예에 따른 동작 지점 변경에 따른 지연 시간의 변화를 비교하기 위한 도면이다."}
