{"patent_id": "10-2022-0122595", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0043468", "출원번호": "10-2022-0122595", "발명의 명칭": "한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 시스템 및 방법", "출원인": "한국딥러닝 주식회사", "발명자": "김지현"}}
{"patent_id": "10-2022-0122595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "외부단말 또는 외부서버로부터 인식 대상 이미지를 수집하고, 수집된 인식 대상 이미지의 노이즈, 워터마크, 배경 색상 및 프레임 중 적어도 하나 이상을 제거하기 위한 전처리를 수행하는 텍스트 이미지 수집 및 전처리부상기 텍스트 이미지 수집 및 전처리부(110)에서 수집된 인식 대상 문서 이미지 내의 텍스트 구조(초성, 중성,종성), 형식, 숫자, 도형, 기호를 식별 및/또는 판독하기 위한 크롭(Crop)영역을 설정한 후, 상기 크롭(Crop)영역 내의 텍스트 구조(초성, 중성, 종성), 숫자, 도형, 기호의 위치를 탐색하고, 탐지된 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호의 둘레를 따라 사각형상을 표시하여 사각형상의 픽셀 위치 정보를 생성 및판독하는 OCR 모델링부;검출한 픽셀 위치 좌표를 기초로 텍스트의 문장구조, 형식, 숫자, 도형, 기호 중 적어도 하나 이상이 포함된 크롭(Crop) 이미지에서 특정 클래스만을 탐지하기 위한 라벨링 처리를 수행하는 라벨링부;데이터베이스에 저장된 복수의 라벨링 이미지를 조합하여 가상의 이미지 템플릿을 생성하는 텍스트 가상이미지생성부; 및라벨링(labeling)된 제1 학습 데이터(가상의 이미지 템플릿) 및 제2 학습 데이터(클롭 이미지)를 구축한 적어도하나 이상의 학습 모델로 학습하고, 학습된 데이터 셋을 데이터베이스화하는 인공지능 데이터 학습부를 포함하는 한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 시스템."}
{"patent_id": "10-2022-0122595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "텍스트 이미지 수집 및 전처리부에서 외부단말 또는 외부서버로부터 인식 대상 이미지를 수집하고, 수집된 인식대상 이미지의 노이즈, 워터마크, 배경 색상 및 프레임 중 적어도 하나 이상을 제거하기 위한 전처리를 수행하는 단계;OCR 모델링부에서 상기 텍스트 이미지 수집 및 전처리부에서 수집된 인식 대상 문서 이미지 내의 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호를 식별 및/또는 판독하기 위한 크롭(Crop)영역을 설정한 후, 상기크롭(Crop) 영역 내의 텍스트 구조(초성, 중성, 종성), 숫자, 도형, 기호의 위치를 탐색하고, 탐지된 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호의 둘레를 따라 사각형상을 표시하여 사각형상의 픽셀 위치 정보를 생성 및 판독하는 단계;라벨링부에서 검출한 픽셀 위치 좌표를 기초로 텍스트의 문장구조, 형식, 숫자, 도형, 기호 중 적어도 하나 이상이 포함된 크롭(Crop) 이미지에서 특정 클래스만을 탐지하기 위한 라벨링 처리를 수행하는 단계;텍스트 가상이미지 생성부에서 데이터베이스에 저장된 복수의 라벨링 이미지를 조합하여 가상의 이미지 템플릿을 생성하는 단계; 및인공지능 데이터 학습부에서 라벨링(labeling)된 제1 학습 데이터(가상의 이미지 템플릿) 및 제2 학습 데이터(클롭 이미지)를 구축한 적어도 하나 이상의 학습 모델로 학습하고, 학습된 데이터 셋을 데이터베이스화하는 단계를 포함하는 한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 방법."}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 시스템은 외부단말 또는 외부서버로부터 인식 대상 이미지를 수집하고, 수집된 인식 대상 이미지의 노이즈, 워터마크, 배경 색상 및 프레임 중 적어도 하나 이상을 제거하기 위한 전처리를 수행하는 텍스트 이미지 수집 및 전처리부 상기 텍스트 (뒷면에 계속)"}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재, 일반적으로 OCR(Optical Character Recognition, 광학적 문자 판독) 기술을 응용하여 문서를 인식한다. 이 기술을 이용하여 인식할 때, 문서의 카테고리를 정확하게 획득하고, 상응하는 템플릿을 사용해야 하지만, 관 련 기술에 의한 분서 분류 결과는 정확하지 않다. 따라서, 어떻게 문서를 정확하게 분류하는 가하는 것은 하나의 시급히 해결해야 할 과제이다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2019-0095651호"}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 종래의 문제점을 해결하기 위한 한국어 가상이미지 생성기술을 이용한 대용 량 문서 데이터 구축 시스템 및 방법을 제공하는 데 그 목적이 있다."}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위한 본 발명의 일 실시예에 따른 한국어 가상이미지 생성기술을 이용한 대용량 문서 데 이터 구축 시스템은 외부단말 또는 외부서버로부터 인식 대상 이미지를 수집하고, 수집된 인식 대상 이미지의 노이즈, 워터마크, 배경 색상 및 프레임 중 적어도 하나 이상을 제거하기 위한 전처리를 수행하는 텍스트 이미 지 수집 및 전처리부; 상기 텍스트 이미지 수집 및 전처리부에서 수집된 인식 대상 문서 이미지 내의 텍스트 구 조(초성, 중성, 종성), 형식, 숫자, 도형, 기호를 식별 및/또는 판독하기 위한 크롭(Crop)영역을 설정한 후, 상 기 크롭(Crop) 영역 내의 텍스트 구조(초성, 중성, 종성), 숫자, 도형, 기호의 위치를 탐색하고, 탐지된 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호의 둘레를 따라 사각형상을 표시하여 사각형상의 픽셀 위치 정 보를 생성 및 판독하는 OCR 모델링부; 검출한 픽셀 위치 좌표를 기초로 텍스트의 문장구조, 형식, 숫자, 도형, 기호 중 적어도 하나 이상이 포함된 크롭(Crop) 이미지에서 특정 클래스만을 탐지하기 위한 라벨링 처리를 수행 하는 라벨링부; 데이터베이스에 저장된 복수의 라벨링 이미지를 조합하여 가상의 이미지 템플릿을 생성하는 텍 스트 가상이미지 생성부; 및 라벨링(labeling)된 제1 학습 데이터(가상의 이미지 템플릿) 및 제2 학습 데이터 (클롭 이미지)를 구축한 적어도 하나 이상의 학습 모델로 학습하고, 학습된 데이터 셋을 데이터베이스화하는 인 공지능 데이터 학습부를 포함한다. 상기 과제를 해결하기 위한 본 발명의 일 실시예에 따른 한국어 가상이미지 생성기술을 이용한 대용량 문서 데 이터 구축 방법은 외부단말 또는 외부서버로부터 인식 대상 이미지를 수집하고, 수집된 인식 대상 이미지의 노 이즈, 워터마크, 배경 색상 및 프레임 중 적어도 하나 이상을 제거하기 위한 전처리를 수행하는 단계; 상기 텍 스트 이미지 수집 및 전처리부에서 수집된 인식 대상 문서 이미지 내의 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호를 식별 및/또는 판독하기 위한 크롭(Crop)영역을 설정한 후, 상기 크롭(Crop) 영역 내 의 텍스트 구조(초성, 중성, 종성), 숫자, 도형, 기호의 위치를 탐색하고, 탐지된 텍스트 구조(초성, 중성, 종 성), 형식, 숫자, 도형, 기호의 둘레를 따라 사각형상을 표시하여 사각형상의 픽셀 위치 정보를 생성 및 판독하 는 단계; 검출한 픽셀 위치 좌표를 기초로 텍스트의 문장구조, 형식, 숫자, 도형, 기호 중 적어도 하나 이상이 포함된 크롭(Crop) 이미지에서 특정 클래스만을 탐지하기 위한 라벨링 처리를 수행하는 단계; 데이터베이스에 저장된 복수의 라벨링 이미지를 조합하여 가상의 이미지 템플릿을 생성하는 단계; 및 라벨링(labeling)된 제1 학습 데이터(가상의 이미지 템플릿) 및 제2 학습 데이터(클롭 이미지)를 구축한 적어도 하나 이상의 학습 모델 로 학습하고, 학습된 데이터 셋을 데이터베이스화하는 단계를 포함한다."}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "따라서, 본 발명의 일 실시예에 따른 한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 시스템 및 방법을 이용하면, 이미지 문서 상에 기재된 문자, 숫자, 기호를 포함하는 글자를 인식하고, 인식된 글자에 대한 상대적인 위치 정보에 기반하여 항목들 간의 연결관계를 분석한 소스를 기반으로 대용량의 OCR 모델링에 적용될 테스트 정보를 생성 및 학습함으로써, OCR 모델의 정확도를 향상시킬 수 있다는 이점이 있다. 또한, 자동으로 분류된 문서 이미지로부터 추출된 텍스트 데이터에 기반해 문서와 유사한 가상 문서를 생성할 수 있고, 생성된 가상 문서를 파생 및/또는 확장시켜 OCR 모델의 성능검증을 보다 정확하게 실시할 수 있다는 이점이 있다. 또한, 다양한 형태의 문서 이미지에 포함된 다양한 문자를 인식하기 위해 신경망(Neural Nets), HMM(Hidden Markov Models) 또는 KNN(K-Nerest-Neighbor) 방법을 적용하고, 다양한 글꼴이나 형태를 가진 문서에 대한 인 식률을 높이기 위해 다량의 트레이닝 데이터를 이용하여 문자 학습을 통해 문자 인식 모델을 트레이닝함으로써, 문자 인식 모델의 성능을 향상시킬 수 있다는 이점이 있다. 또한, 사람이 직접 문서를 촬영하거나 스캔하여 다량의 트레이닝 데이터를 수집하는 데에는 한계가 있는 문제를 해결할 수 있고, 제한된 트레이닝 데이터 세트(Training data set)로 인한 문자 분류 오류발생확률을 낮출 수 있어, 결과적으로 광학적 문자 인식 엔진의 분류 성능을 향상시킬 수 있다는 이점이 있다."}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에서 사용되는 기술적 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려 는 의도가 아님을 유의해야 한다. 또한, 본 발명에서 사용되는 기술적 용어는 본 발명에서 특별히 다른 의미로 정의되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 의미로 해석되어야 하며, 과도하게 포괄적인 의미로 해석되거나, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 발명에서 사용되는 기술적인 용어가 본 발명의 사상을 정확하게 표현하지 못하는 잘못된 기술적 용어일 때에 는 당업자가 올바르게 이해할 수 있는 기술적 용어로 대체되어 이해되어야 할 것이다. 또한, 본 발명에서 사용 되는 일반적인 용어는 사전에 정의되어 있는 바에 따라, 또는 전후 문맥상에 따라 해석되어야 하며, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 발명에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함한다. 본 발명에서 \"구성된다\" 또는 \"포함한다\" 등의 용어는 발명에 기재된 여러 구성 요소들 또는 여러 단계를 반드 시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들은 포함되지 않을 수 도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한다. 또한, 본 발명에서 사용되는 제 1, 제 2 등과 같이 서수를 포함하는 용어는 구성 요소들을 설명하는데 사용될 수 있지만, 구성 요소들은 용어들에 의해 한정되어서는 안 된다. 용어들은 하나의 구성 요소를 다른 구성 요소 로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성 요소는 제 2 구성 요소로 명명될 수 있고, 유사하게 제 2 구성 요소도 제 1 구성 요소로 명명될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일 하거나 유사한 구성 요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 발명의 사상을 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 발명의 사상이 제한되는 것으로 해석되어서는 아니 됨을 유의해야 한다.이하, 첨부된 도면들에 기초하여 본 발명의 일 실시예에 따른 한국어 가상이미지 생성기술을 통한 대용량 문서 데이터 구축 시스템 및 방법을 보다 상세하게 설명하도록 한다. 도 1은 본 발명의 일 실시예에 따른 한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 시스템의 장치 구성도이다. 도 1에 도시된 바와 같이, 본 발명의 일 실시예에 따른 텍스트 가상이미지 생성기술을 이용한 대용량 문서 데이 터 구축 시스템은 텍스트 이미지 수집부 및 전처리부, OCR 모델링부, 라벨링부, 텍스트 가 상이미지 생성부, 데이터 학습부, 성능검증부를 포함한다. 상기 텍스트 수집 및 전처리부는 외부단말 또는 외부서버로부터 인식 대상 이미지를 수집하는 구성으로, 여기서, 인식 대상 이미지는 글자, 도형, 기호를 포함하는 이미지일 수 있다. 또한, 인식 대상 이미지의 확장자 는 jpg, png, bmp, tiff 등을 포함할 수 있다. 또한, 텍스트 이미지 수집 및 전처리부는 수집된 인식 대상 이미지에 전처리를 수행하는 구성일 수 있다. 여기서, 전처리는 예를 들어, 노이즈, 워터마크, 배경 색상 및 프레임 등을 제거하는 과정과 문서의 글자 및 흰 배경만을 남기는 과정을 포함할 수 있다. 즉, 후술하는 OCR 모델링부 내의 엔진에서 글자와 배경의 명확한 경계가 있어야 인식 정확도가 높아지므로, 텍 스트(숫자, 글자, 기호, 도형 등) 영역을 정확히 검출하기 위해서는 해당 문서 이미지에 대해 전처리 과정이 동 반되어야 한다. 이러한 전처리 과정을 통해 글자 오인식에 대한 가능성을 줄일 수 있다. 전처리 과정에 의하면, 문서 이미지에 대해 x축 및 y축에 대해 미분하여 밝기 변화가 나타나는 픽셀들을 검출하 고, 밝기 변화가 나타나는 픽셀들을 이용하여 문서 이미지 내 테이블을 구성하는 적어도 하나의 직선을 검출하 여 테이블을 구성하는 직선을 삭제하고, 픽셀의 미분 값을 이용하여 가로 세로가 긴 직선들이 검출되어 해당 직 선들이 제거되는 과정을 포함할 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[수학식 2]"}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이미지의 경계는 이미지의 픽셀 주변으로 밝기 값이 급격히 변하므로, 픽셀 값이 급격히 변하는 픽셀들을 검출 하고 상기의 수학식 1을 이용하여 이미지의 X축과 Y축에 대해 미분하여 각각 검출하고 수학식 2를 이용하여 검 출된 픽셀의 크기 및 각도를 계산하여 최종적으로 가로, 세로가 가장 긴 직선들만 검출할 수 있다. 이렇게 검출된 테이블 영역에 해당하는 직선(검정색 픽셀 값: 0)은 해당하는 부분의 문서 이미지에서 삭제(픽셀 값을 255로 변경)될 수 있다. 더불어, 전처리 과정은 문서 이미지를 이진화하는 과정을 포함할 수 있다. 예를 들어, 문서 이미지가 흰색 배경과 검정색 글씨로 나누어지도록 하는 작업을 수행할 수 있다. 한편, 텍스트 이미지 수집 및 전처리부의 경우, 이미지의 경계를 검출하기 위한 Canny Edge Detection 알고리즘이 프로 그래밍되어 있을 수 있다. 다음으로, 상기 OCR 모델링부는 상기 텍스트 이미지 수집 및 전처리부에서 수집된 인식 대상 문서 이 미지 내의 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호를 식별 및/또는 판독하기 위한 크롭(Crop)영역을 설정한 후, 설정된 크롭(Crop)영역 내의 텍스트 구조, 형식, 도형, 기호를 판독하는 구성일 수 있다. 또한, 상기 OCR 모델링부는 상기 크롭(Crop) 영역 내의 텍스트 구조(초성, 중성, 종성), 숫자, 도형, 기호 의 위치를 탐색하고, 탐지된 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호의 둘레를 따라 사각형상 을 표시하여 사각형상의 픽셀 위치 정보를 생성하는 구성일 수 있다. 즉, 텍스트 구조(초성, 중성, 종성), 텍스트 형식, 숫자, 도형, 기호 객체에 대한 상대적인 위치 인식을 수행하 고, 각 위치에 따른 배열을 확인할 수 있도록 탐지된 글자, 숫자, 도형, 기호 객체의 둘레를 따라 사각형상을 표시하며, 표시된 사각형상의 픽셀 위치 값(좌표 정보)를 생성하는 구성일 수 있다. 여기서, 상기 OCR 모델링부는 PSENet(Progressive Scale Expansion Network) 기반의 딥러닝 모델을 이용 하여 인식 대상 문서 이미지를 포함하는 학습 데이터로부터 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호 객체와 그 위치를 탐지하고 탐지율의 향상을 위해 학습을 수행할 수 있다. 다음으로, 라벨링부는 검출한 픽셀 위치 좌표를 기초로 텍스트의 문장구조, 형식, 숫자, 도형, 기호 중 적 어도 하나 이상이 포함된 크롭(Crop) 이미지에서 특정 클래스만을 탐지하기 위한 라벨링 처리를 수행하는 구성 일 수 있다. 라벨링된 이미지는 PASCAL VOC 데이터 형태로 구성된다. 다음으로, 가상문서 생성부는 데이터베이스에 저장된 복수의 라벨링 이미지를 조합하여 가상의 이미지 템 플릿을 생성하는 구성일 수 있다. 여기서, 가상의 이미지 템플릿은 실제 사용되는 문서와 유사한 형태를 정의할 수 있다. 또한, 실제 사용되는 문 서의 특성과 유사한 특성, 예컨대, 텍스트의 색상, 크기, 글씨체나 문서에 포함된 표, 배경, 색상, 워터마크 등 광학 문자 인식에 영향을 미치는 특징이 유사한 것을 의미한다. 다음으로, 데이터베이스는 라베링 처리된 가상의 이미지 템플릿 및 크롭 이미지를 저장하는 구성일 수 있 다. 또한, 상기 데이터베이스는 크롭 이미지 내의 객체(숫자, 음절(초성, 중성, 종성) 기호 등) 이미지를 개별 로 저장할 수 있고, 객체 간의 수평거리 또는 수직거리를 서로 대응시켜 저장하는 구성일 수 있다. 상기 데이터베이스는 빅데이터를 구축하기 위하여, 저장된 로우 데이터 내에 포함된 비정형(Unstructed) 데이터, 정형(Structured) 데이터 및 반정형 데이터(Semi-structured)를 정제하고, 메타 데이터로 분류를 포함 한 전처리를 실시할 수 있고, 전처리된 데이터를 데이터 마이닝(Data Mining)을 포함하는 분석을 실시할 수 있 다. 이때, 데이터 마이닝은, 전처리된 데이터 간의 내재된 관계를 탐색하여 클래스가 알려진 훈련 데이터 셋을 학습 시켜 새로운 데이터의 클래스를 예측하는 분류(Classification) 또는 클래스 정보 없이 유사성을 기준으로 데이 터를 그룹짓는 군집화(Clustering)를 수행할 수 있다. 물론, 이외에도 다양한 마이닝 방법이 존재할 수 있으며, 수집 및 저장되는 빅데이터의 종류나 이후에 요청될 질의(Query)의 종류에 따라 다르게 마이닝될 수도 있다. 이렇게 구축된 빅데이터는, 인공신경망 딥러닝이나 기 계학습 등으로 검증과정을 거칠 수도 있다. 이때, 인공 신경망은 CNN(Convolutional neural network) 구조가 이용될 수 있는데, CNN은 컨볼루션 층을 이용 한 네트워크 구조로 이미지 처리에 적합하며, 이미지 데이터를 입력으로 하여 이미지 내의 특징을 기반으로 이 미지를 분류할 수 있기 때문이다. 또한, 텍스트 마이닝(Text Mining)은 비/반정형 텍스트 데이터에서 자연어처리 기술에 기반하여 유용한 정보를 추출, 가공하는 것을 목적으로 하는 기술이다. 텍스트 마이닝 기술을 통해 방대한 텍스트 뭉치에서 의미 있는 정보를 추출해 내고, 다른 정보와의 연계성을 파악하며, 텍스트가 가진 카테고리를 찾아내거나 단순한 정보 검 색 그 이상의 결과를 얻어낼 수 있다. 이를 이용하여, 본 발명의 일 실시예에 서는, 질의로 입력되는 식별자나 자연어를 분석하고, 그 안에 숨겨진 정보를 발굴해 내기 위해 대용량 언어자원과 통계적, 규칙적 알고리즘이 사 용될 수 있다다음으로, 인공지능 데이터 학습부는 라벨링(labeling)된 제1 학습 데이터(가상의 이미지 템플릿) 및 제2 학습 데이터(클롭 이미지)를 구축한 적어도 하나 이상의 학습 모델로 학습하고, 학습된 데이터 셋을 데이터베이 스화하는 구성일 수 있다. 여기에서, 인식 모델은 딥러닝(Deep Learning) 또는 심층신경망(Deep Neural Network)을 포함하는 기계학습 알 고리즘을 통해 구축되는 학습 모델에 해당할 수 있다. 또한, 제2 학습 데이터는 사전에 수집된 데이터들의 집합 이고, 제1 학습 데이터는 제2 학습 데이터의 조합으로 파생된 학습 데이터이며, 각 학습 데이터는 라벨정보가 부여된 데이터일 수 있다. 적어도 하나 이상의 인식 모델인 학습 모델 각각은 서로 다른 학습 과정으로 서로 다른 학습 데이터를 적용할 수 있다. 한편, 제1 인식 모듈 구축은 1 학습 데이터의 일부를 학습을 통해 수행되고, 제2 인식 모델 구축은 제1 학습 데 이터의 나머지를 학습을 통해 수행될 수 있다. 또는 제1 학습 데이터에서 랜덤하게 선택되는 데이터들을 순차적 으로 학습하여 제1 및 제2 인식 모델을 각각 구축할 수도 있다. 상기 인공지능 데이터 학습부는 제1 학습 데이터를 소정의 비율로 학습 데이터와 테스트 데이터로 구분할 수 있으며, 학습 데이터로 인식 모델을 구축하는 과정에서 테스트 데이터로 측정된 정확도(Accuracy)가 소정의 기준을 충족할 때까지 학습 과정을 반복적으로 수행할 수 있다. 이후, 학습 완료된 인식 모델들은 데이터베이스 에 저장되어 관리될 수 있다. 한편, 본 발명에서는 인공지능 데이터 학습부의 네트워크 성능 비교를 위해 faster-RCNN-Inception, ResNet, MobileNet를 각 100,000번 학습을 수행 하였다. faster-RCNN-Inception은 인셉션 모듈(Inception module)을 사용한 모 델이다. 인셉션 모듈(Inception modul e)은 Going Deep with Convolutions(Szegedy et al, 2015)에서 소개된 모델로서 같은 합성곱 레 이어 에서 다 른 크기(1x1, 3x3, 5x5)의 합성곱 필터를 병렬로 적용하여 다 양한 크기의 특징을 얻는다. 이중 1x1 합성곱을 사용하여 차원을 줄여 층 이 깊어지면서 생겨난 연산 증가 문제를 통제하였다. ResNet은 Deep Residual Learning for Image Recognition(Kaiming He et al, 2015)에서 소개되었고 ILSVRC대 회 2015년 우승 모델로서 top-5 error가 3.6%인 사람의 분류 수준 5% 내외를 뛰어 넘는 모델이다. ResNet의 구조는 Residual Block과 Identity Block으로 이루어져있고 이 것은 같은 연산이지만 Identity Block에서는 입력값과 출력값의 크기를 맞 추어 주는 작업만 필요로 한다. 층이 깊어지면 역전파되는 그래디언 트(gradient)가 점점 0에 가까워져서 학습이 잘 되지 않는 그래디언트 베니싱(gradient vanishing) (Razvan et al, 2013)이 발생하게 된다. ResNet은 이러한 Residual Block을 사용함으로서 그래디언트가 잘 흐를 수 있는 길 (shortcut, skip connection)을 만들어 주었다. 또한 Residual Block은 앙상블(ensemble)모델을 구축한 것과 비슷한 효과를 내어 그 성능이 더 좋은 모델이다. MobileNet은 MobileNets: Efficient Convolutional Neural Networks for Mobile Vision(Andrew G. Howard et al, 2017)에서 소개되어진 네트워크이다. MobileNet은 합성곱 층의 연산이 길어진다는 단점을 보안하여 이를 줄이는 것으로 기존의 합성곱을 깊이별 (depthwise)의 합성곱과 1x1의 위 치별(pointwise)합성곱으로 분리된 합성곱 방법을사용 하였다. 깊이별 합성곱 은 각 입력 채널마다 하나의 필터를 사용하고 위치별 합성곱은 깊이 별 합성곱의 결과를 통합하는 1x1 크기의 합성곱을 사용한다. 기존의 합 성곱은 입력을 필터링(filtering)하고 통합(combining)하는 과정이 한 번에 이루 어지는 반면 MobileNet에서는 이를 필터링을 담당하는 층과 통합을 담당하는 층을 분리하여 네트워크를 구성하 였다. 이를 통하여 모델의 크 기와 계산을 줄일 수 있다. 각 네트워크들은 학습하면서 동일한 파라미터들을 사용하였고 파라메터들은 다음의 표 1과 같다. 표 1 사용된 파라미터 내용 학습율(learning rate) 0.003 Threshold 0.7 Activation function ReLUMomentum 0.9 도 2는 본 발명의 일 실시예에 따른 한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 방법을 설 명한 흐름도이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 방법(S700)은 텍스트 이미지 수집 및 전처리부에서 외부단말 또는 외부서버로부터 인식 대상 이미지를 수 집하고, 수집한 인식 대상 이미지에 전처리 과정(S710)을 수행하는 구성일 수 있다. 여기서, 전처리는 예를 들어, 노이즈, 워터마크, 배경 색상 및 프레임 등을 제거하는 과정과 문서의 글자 및 흰 배경만을 남기는 과정을 포함할 수 있다. 즉, 후술하는 OCR 모델링부 내의 엔진에서 글자와 배경의 명확한 경계가 있어야 인식 정확도가 높아지므로, 텍스트(숫자, 글자, 기호, 도형 등) 영역을 정확히 검출하기 위해서는 해당 문서 이미지에 대해 전 처리 과정이 동반되어야 한다. 이러한 전처리 과정을 통해 글자 오인식에 대한 가능성을 줄일 수 있다. 전처리 과정에 의하면, 문서 이미지에 대해 x축 및 y축에 대해 미분하여 밝기 변화가 나타나는 픽셀들을 검출하 고, 밝기 변화가 나타나는 픽셀들을 이용하여 문서 이미지 내 테이블을 구성하는 적어도 하나의 직선을 검출하 여 테이블을 구성하는 직선을 삭제하고, 픽셀의 미분 값을 이용하여 가로 세로가 긴 직선들이 검출되어 해당 직 선들이 제거되는 과정을 포함할 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[수학식 2]"}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이미지의 경계는 이미지의 픽셀 주변으로 밝기 값이 급격히 변하므로, 픽셀 값이 급격히 변하는 픽셀들을 검출 하고 상기의 수학식 1을 이용하여 이미지의 X축과 Y축에 대해 미분하여 각각 검출하고 수학식 2를 이용하여 검 출된 픽셀의 크기 및 각도를 계산하여 최종적으로 가로, 세로가 가장 긴 직선들만 검출할 수 있다. 이렇게 검출된 테이블 영역에 해당하는 직선(검정색 픽셀 값: 0)은 해당하는 부분의 문서 이미지에서 삭제(픽셀 값을 255로 변경)될 수 있다. 더불어, 전처리 과정은 문서 이미지를 이진화하는 과정을 포함할 수 있다. 예를 들어, 문서 이미지가 흰색 배경과 검정색 글씨로 나누어지도록 하는 작업을 수행할 수 있다. 한편, 텍스트 이미지 수집 및 전처리부의 경우, 이미지의 경계를 검출하기 위한 Canny Edge Detection 알고리즘이 프로 그래밍되어 있을 수 있다. 다음으로, 상기 S710 과정이 완료되면, 상기 OCR 모델링부에서 상기 수집부에서 수집된 인식 대상 문 서 이미지 내의 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호를 식별 및/또는 판독하기 위한 크롭 (Crop)영역을 설정한 후, 설정된 크롭(Crop)영역 내의 텍스트 구조, 형식, 도형, 기호를 판독(S720)한다. 상기 S720 과정은 상기 판독영역 내의 글자, 숫자, 도형, 기호의 위치를 탐색하고, 탐지된 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호의 둘레를 따라 사각형상을 표시하여 사각형상의 픽셀 위치 정보를 생성하는 과정을 포함할 수 있다. 즉, 텍스트 구조(초성, 중성, 종성), 텍스트 형식, 숫자, 도형, 기호 객체에 대한 상대적인 위치 인식을 수행하 고, 각 위치에 따른 배열을 확인할 수 있도록 탐지된 글자, 숫자, 도형, 기호 객체의 둘레를 따라 사각형상을 표시하며, 표시된 사각형상의 픽셀 위치 값(좌표 정보)를 생성하는 과정일 수 있다. 또한, 상기 S720 과정은 PSENet(Progressive Scale Expansion Network) 기반의 딥러닝 모델을 이용하여 인식 대상 문서 이미지를 포함하는 학습 데이터로부터 텍스트 구조(초성, 중성, 종성), 형식, 숫자, 도형, 기호 객체 와 그 위치를 탐지하고 탐지율의 향상을 위해 학습을 수행하는 과정을 더 포함할 수 있다. 다음으로, S720 과정이 완료되면, 라벨링부에서 검출한 픽셀 위치 좌표를 기초로 텍스트의 문장구조, 형식, 숫자, 도형, 기호 중 적어도 하나 이상이 포함된 크롭(Crop) 이미지에서 특정 클래스만을 탐지하기 위한 라벨링 처리를 수행(S730)한다. 여기서, 라벨링된 이미지는 PASCAL VOC 데이터 형태로 구성된다. 이후, 상기 S730 과정이 완료되면, 가상문서 생성부에서 데이터베이스에 저장된 복수의 라벨링 크롭(Crop) 이미지를 조합하여 가상의 이미지 템플릿을 생성(S740)한다. 여기서, 가상의 이미지 템플릿은 실제 사용되는 문서와 유사한 형태를 정의할 수 있다. 또한, 실제 사용되는 문 서의 특성과 유사한 특성, 예컨대, 텍스트의 색상, 크기, 글씨체나 문서에 포함된 표, 배경, 색상, 워터마크 등 광학 문자 인식에 영향을 미치는 특징이 유사한 것을 의미한다. 다음으로, 상기 S740 과정이 완료되면, 인공지능 데이터 학습부는 라벨링(labeling)된 제1 학습 데이터(가 상의 이미지 템플릿) 및 제2 학습 데이터(클롭 이미지)를 구축한 적어도 하나 이상의 학습 모델로 학습하고, 학 습된 데이터 셋을 데이터베이스화(S750)한다. 여기에서, 인식 모델은 딥러닝(Deep Learning) 또는 심층신경망(Deep Neural Network)을 포함하는 기계학습 알 고리즘을 통해 구축되는 학습 모델에 해당할 수 있다. 또한, 제2 학습 데이터는 사전에 수집된 데이터들의 집합 이고, 제1 학습 데이터는 제2 학습 데이터의 조합으로 파생된 학습 데이터이며, 각 학습 데이터는 라벨정보가 부여된 데이터일 수 있다. 적어도 하나 이상의 인식 모델인 학습 모델 각각은 서로 다른 학습 과정으로 서로 다른 학습 데이터를 적용할 수 있다. 한편, 제1 인식 모듈 구축은 1 학습 데이터의 일부를 학습을 통해 수행되고, 제2 인식 모델 구축은 제1 학습 데 이터의 나머지를 학습을 통해 수행될 수 있다. 또는 제1 학습 데이터에서 랜덤하게 선택되는 데이터들을 순차적 으로 학습하여 제1 및 제2 인식 모델을 각각 구축할 수도 있다. 상기 인공지능 데이터 학습부는 제1 학습 데이터를 소정의 비율로 학습 데이터와 테스트 데이터로 구분할 수 있으며, 학습 데이터로 인식 모델을 구축하는 과정에서 테스트 데이터로 측정된 정확도(Accuracy)가 소정의 기준을 충족할 때까지 학습 과정을 반복적으로 수행할 수 있다. 이후, 학습 완료된 인식 모델들은 데이터베이스 에 저장되어 관리될 수 있다. 따라서, 본 발명의 일 실시예에 따른 한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 시스템 및 방법을 이용하면, 이미지 문서 상에 기재된 문자, 숫자, 기호를 포함하는 글자를 인식하고, 인식된 글자에 대한 상대적인 위치 정보에 기반하여 항목들 간의 연결관계를 분석한 소스를 기반으로 대용량의 OCR 모델링에 적용될 테스트 정보를 생성 및 학습함으로써, OCR 모델의 정확도를 향상시킬 수 있다는 이점이 있다. 또한, 자동으로 분류된 문서 이미지로부터 추출된 텍스트 데이터에 기반해 문서와 유사한 가상 문서를 생성할 수 있고, 생성된 가상 문서를 파생 및/또는 확장시켜 OCR 모델의 성능검증을 보다 정확하게 실시할 수 있다는 이점이 있다. 또한, 다양한 형태의 문서 이미지에 포함된 다양한 문자를 인식하기 위해 신경망(Neural Nets), HMM(Hidden Markov Models) 또는 KNN(K-Nerest-Neighbor) 방법을 적용하고, 다양한 글꼴이나 형태를 가진 문서에 대한 인 식률을 높이기 위해 다량의 트레이닝 데이터를 이용하여 문자 학습을 통해 문자 인식 모델을 트레이닝함으로써, 문자 인식 모델의 성능을 향상시킬 수 있다는 이점이 있다.또한, 사람이 직접 문서를 촬영하거나 스캔하여 다량의 트레이닝 데이터를 수집하는 데에는 한계가 있는 문제를 해결할 수 있고, 제한된 트레이닝 데이터 세트(Training data set)로 인한 문자 분류 오류발생확률을 낮출 수 있어, 결과적으로 광학적 문자 인식 엔진의 분류 성능을 향상시킬 수 있다는 이점이 있다. 본 발명은 Deep learning기반의 Faster-RCNN을 사용하고, CNN을 통한 디지털 텍스트 화 작업을 수행함으로써, 훈련 을 시켰을 시에 원하는 class에 대한 탐지가 가능하고 문서 이미지에 흐림, 빛 바램 등이 존재하여도 탐지 가 잘 된다는 노이즈에 덜 민감하다는 장점이 있어, 기존 OCR보다 범용성이 높을 것으로 예상 된다. 상술한 이점을 통해 다양한 형태를 갖고 있는 문서를 사용하여 학습을 시 키고 보다 많은 class들을 추가하여 새로운 형태의 문서가 들어와도 원하는 class들을 탐지할 수 있는 모델을 생성 할 수 있다는 이점이 있다. 본 발명의 일 실시예에서 사용된 “~부”는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요 소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세 서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또 는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되 는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접 근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명"}
{"patent_id": "10-2022-0122595", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상장 치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또 는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분 산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체 에 저장될 수 있다 본 발명의 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특 별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 전술된 내용은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어 나지 않는 범위에서 수정 및 변형이 가능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상 을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다.부호의 설명 100: 한국어 가상이미지 생성기술을 이용한 대용량 문서 데이터 구축 시스템 110: 텍스트 이미지 수집 및 전처리부 120: OCR 모델링부 130: 라벨링부 140: 가상문서 이미지 생성부 150: 데이터베이스 160: 인공지능 데이터 학습부"}
{"patent_id": "10-2022-0122595", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 한국어 가상문서 생성기술을 통한 대용량 문서 데이터 구축 시스템의 장치 구성도이다. 도 2는 본 발명의 일 실시예에 따른 한국어 가상문서 생성기술을 통한 대용량 문서 데이터 구축 방법을 설명한 흐름도이다."}
