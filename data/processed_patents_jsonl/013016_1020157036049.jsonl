{"patent_id": "10-2015-7036049", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2016-0013928", "출원번호": "10-2015-7036049", "발명의 명칭": "ＨＵＤ 객체 설계 및 방법", "출원인": "스미스, 찰스, 안소니", "발명자": "스미스, 찰스, 안소니"}}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터로 하여금 3차원 객체의 1인칭 증강 현실 뷰를 가능하게 하는 제어 로직이 저장된 컴퓨터 사용 가능 매체를 포함하는 컴퓨터 프로그램 제품에 있어서, 표시 장치와 하나 이상의 센서 사이의 통신을 개시하는 컴퓨터 판독 가능 프로그램 코드와, 상기 하나 이상의 센서로부터 센서 데이터를 수신하는 컴퓨터 판독 가능 프로그램 코드와, 상기 하나 이상의 센서로부터의 데이터를 이용해서 증강 현실 환경을 생성하는 컴퓨터 판독 가능 프로그램 코드와, 3차원 대상 객체를 상기 증강 현실 환경에 포함시키는 컴퓨터 판독 가능 프로그램 코드와, 상기 증강 현실 환경에 데카르트 좌표 격자를 적용하는 컴퓨터 판독 가능 프로그램 코드와,상기 대상 객체를 1인칭 증강 현실 뷰로 상기 증강 현실 환경에 표시하는 컴퓨터 판독 가능 프로그램 코드를 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 대상 객체의 조작을 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 표시 장치의 위치 또는 방향의 변경을 반영하기 위해, 상기 대상 객체의 상기 표시를 변경하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 센서 데이터는, 상기 증강 현실 환경의 물리적인 특성, 스케일, 위치 및 방향에 관한 데이터를 포함하는,컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 상기 증강 현실 환경 위로 3차원 이미지의 중첩을 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2016-0013928-3-제 1 항에 있어서, 상기 증강 현실 환경은 상기 하나 이상의 센서의 위치 결정에 의해서 생성되는, 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 데카르트 좌표 격자의 가상 표현을 제공하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 가상 표현은 상기 표시 장치와 상기 하나 이상의 센서 사이의 동기화에 의해서 구현되는, 컴퓨터 프로그램제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 상기 하나 이상의 센서의 실제 위치를 이용해서 표시 원점을 규정하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는, 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서, 실사(photorealistic) 사용자 인터페이스를 시뮬레이션하기 위해 실시간 효과를 렌더링하는 컴퓨터 판독 가능프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서, 상기 증강 현실 환경 내에 사용자가 존재하는 것을 시뮬레이션하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1 항에 있어서, 상기 대상 객체에 물리적인 속성 적용을 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 상기 대상 객체에 물리적인 속성 적용 효과를 시뮬레이션하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는공개특허 10-2016-0013928-4-컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서, 상기 대상 객체에 시뮬레이션된 물리적인 속성의 효과를 표시하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 1 항에 있어서, 상기 대상 객체는 상기 표시 장치에 의해 캡쳐되는 실제 객체의 이미지인, 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 1 항에 있어서, 상기 대상 객체는 사용자에 의해서 상기 증강 현실 내에 생성된 3차원 디자인인 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 1 항에 있어서, 상기 표시 장치에 의한 모션 캡쳐링 및 근접도 감지를 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 1 항에 있어서, 상기 증강 현실 환경 내에 다수의 사용자의 참여를 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서, 상기 다수의 사용자에 의한 협력 설계(co-designing)를 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 1 항에 있어서, 상기 증강 현실 환경의 내부 차원(inner dimension) 사용자 POV(point of view)를 생성해서, 상기 사용자가 상기 증강 현실 환경 내에서 보고 네비게이트하는 것을 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품. 공개특허 10-2016-0013928-5-청구항 21 제 20 항에 있어서, 상기 표시 장치의 위치 및 상기 증강 현실 환경의 속성을, 상기 표시 장치의 초점과 결합하는 컴퓨터 판독 가능프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 1 항에 있어서, 상기 표시 장치에 의해서 상기 대상 객체를 향해 줌인(zooming in) 또는 상기 대상 객체로부터 줌아웃(zoomingout)하는 것을 시뮬레이션하는 것을 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 1 항에 있어서, 상기 증강 현실 환경의 네비게이션을 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제 23 항에 있어서, 상기 표시 장치에 의해 모션을 감지하는 컴퓨터 판독 가능 프로그램 코드와, 상기 하나 이상의 센서에 대한 근접도와 관련해서 상기 표시 장치의 위치를 결정하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제 1 항에 있어서, 상기 대상 객체에 물리적인 속성을 적용하는 것에 기초해서, 가능한 대상 객체 아웃컴(outcome)을 생성 및 표시하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제 1 항에 있어서, 상기 표시 장치에 있어서의 상기 증강 현실 환경에 대한 근접도의 변화에 기초해서 음향 재생을 생성하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제 1 항에 있어서, 표시 원점을 결정하는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품. 공개특허 10-2016-0013928-6-청구항 28 제 27 항에 있어서, 상기 컴퓨터 판독 가능 프로그램 코드는 상기 하나 이상의 센서에 의해 형성된 위치 결정 레이아웃의 폭 및 길이 변수를 결정하는 컴퓨터 판독 가능 프로그램 코드; 및 상기 폭 및 길이 변수를 2로 나누는 컴퓨터 판독 가능 프로그램 코드를 더 포함하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2015-7036049", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 하나 이상의 센서에 매핑되어서, HUD(heads up display) 장치를 통해서 커스컴 3D 객체에 대한 1인칭 증강 현실 뷰를 생성하고 볼 수 있게 하는, 표시 환경이라고 불리는 사각형상 3D 모델링 격자에 관한 것이다. 위 치 센서를 통해서 표시 환경의 위치 결정 및 주위 둘레를 생성할 수 있다. 표시 환경은, 모션 센서에 의해 감지 되는 표시 장치의 물리적인 움직임과, 동기화된 위치 센서에 대한 근접도에 기초한 표시 장치의 물리적인 위치의 조합에 의해서 네비게이트될 수 있다. 표시 장치의 센서는, 언제 장치가 표시 환경에 대해서 이동하는지 인식해 서, 표시되는 3D 모델의 재렌더링을 개시한다. 표시 장치의 움직임을 통해서 3D 모델의 1인칭 묘사 및 투시가 가 능하게 되며, 이는 커스토마이즈 가능한 스케일, 방향, 위치 결정, 물리 및 인공 지능을 이용해서 3D 모델을 설 계하는데 사용될 수 있다."}
{"patent_id": "10-2015-7036049", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2013년 5월 30일에 출원된, 본 출원인의 미국 특허 가출원 제 61/828,745호 'HUD 객체 설계 및 방 법'의 우선권을 주장한다. 본 출원은 전반적으로, HUD 장치의 움직임 및/또는 위치 센서와의 상호 연관성에 기초한 3차원 객체의 설계, 객 체로의 속성 추가, 및 객체의 뷰의 표시가 가능한, 헤드 업 디스플레이(HUD) 증강 현실(AR) 표시 환경에 관한 것이다."}
{"patent_id": "10-2015-7036049", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "3차원 렌더링이란, X, Y, Z 격자선에 표시되었다가 3D 효과를 가진 2D 이미지로 변환되는 와이어 프레임 3D 모 델을 가리킨다. 3D 렌더링된 객체는 자주 볼 수 있지만, 이를 생성하고 렌더링하기 위해서는 3D 모델링 소프트 웨어가 필요하다. 그러나, 이 소프트웨어는 1인칭 시점 증강 현실(AR)로 객체를 표시하지는 않는다. 증강 현실 (AR)은, 그 구성 요소들이 컴퓨터-생성 소프트웨어에 의해 시뮬레이션되어 있는(혹은 변경되어 있는), 물리적인 현실 세계 환경의 라이브 뷰이다. 현재의 증강 현실 표시 방법에서는 이미지를 인식해서 3D 모델을 표시하기 위 한 카메라가 필요하다. 또한, 이 방법은 대축적 3D 모델을 표시하는 능력에는 한계가 있다. 센서 대신 카메라를 이용하는 경우, 사용자는 렌더링 지연 및 시야의 한계를 느낄 수 있다. 또한, 일부 경우에, 객체의 고유 속성으 로 인해서, 물리적인 혹은 시각적인 특성을 시뮬레이션하는 것이 어려워진다. 현재의 모델링 소프트웨어는 너무 복잡해질 수 있고 낮은 품질의 비현실적인 이미지를 생성한다."}
{"patent_id": "10-2015-7036049", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 맞춤식 3D 모델의 증강 현실 표현을 생성할 수 있는 헤드 업 디스플레이를 제공하는 것이다."}
{"patent_id": "10-2015-7036049", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예의 일 측면은 핸드헬드 혹은 웨어러블 기기의 소프트웨어에 의해 헤드업 디스플레이의 POV가 렌더링되는 것에 관한 것이다. 본 발명의 실시예의 일 측면은, 고품질 3D 모델을 생성할 수 있는 사용자 친화적 시스템을 제공하는 것이다. 본 발명의 실시예의 다른 측면은 고정형 센서의 위치에 기초해서 X, Y, Z 축을 규정하는 사각형 그리드에 관한 것이다. 본 발명의 실시예의 다른 측면은, 동기화된 고정형 센서의 근접도와 연관된, 모션 센서에 의해 감지되는 HUD의 물리적인 움직임과 그 물리적인 위치와의 조합에 의해서 네비게이트되는 사용자 인터페이스를 구비한 소프트웨 어에 관한 것이다. 본 발명의 실시예의 다른 측면은, 렌더링된 3D 객체에 대한 사용자의 뷰를 HUD의 움직임에 기초해서 계산할 수 있는, HUD의 모션 센서에 관한 것이다. 본 발명의 추가적인 측면, 목적, 특성 및 이점은, 첨부된 도면을 참조로 이하의 상세한 설명의 바람직한 실시예 를 읽음으로써 명확하게 이해할 것이다."}
{"patent_id": "10-2015-7036049", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 맞춤식 3D 모델의 증강 현실 표현을 생성할 수 있는 헤드 업 디스플레이를 제공한다."}
{"patent_id": "10-2015-7036049", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 측면은 3차원 객체의 1인칭 증강 현실 뷰, 설계 및 전개를 가능하게 하는 시스템, 방법 및 컴퓨터 프 로그램 제품에 관한 것이다. 본 발명의 실시예의 일 측면에 있어서, 컴퓨터로 하여금 3차원 객체의 1인칭 증강 현실 뷰를 가능하게 하는 컴퓨터 프로그램 제품이 개시된다. 이 측면에서 개시되는 바와 같이, 이 컴퓨터 프로 그램 제품은, 컴퓨터로 하여금 3차원 객체의 1인칭 증강 현실 뷰를 가능하게 하는 제어 로직이 저장된 컴퓨터 이용가능 매체를 포함할 수 있다. 이 제어 로직은, 표시 장치와 하나 이상의 센서 사이의 통신을 개시하는 연산 과, 하나 이상의 센서로부터 센서 데이터를 수신하는 연산과, 하나 이상의 센서로부터의 데이터를 이용해서 증 강 현실 환경을 생성하는 연산과, 3차원 대상 객체를 증강 현실 환경에 포함시키는 연산과, 증강 현실 환경에 데카르트 좌표 격자를 적용하는 연산과, 대상 객체를 1인칭 증강 현실 뷰로 증강 현실 환경에 표시하는 연산과 같은 다양한 연산(operation)을 위한 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 본 발명의 실시예의 일 측면에 있어서, 제어 로직은 대상 객체의 조작을 가능하게 하는 컴퓨터 판독 가능 프로 그램 코드를 포함할 수 있다. 본 발명의 실시예의 일 측면에 있어서, 제어 로직은, 표시 장치의 위치 및/또는 방향의 변경을 반영해서 대상 객체의 표시를 변경하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 다른 측면에 있어서, GPS를 통해서, 표시 장치의 위치 및/또는 방향의 변경을 반영하는 것을 도울 수 있게 하는 컴퓨터 판독 가능 프로그램 코드도 고려될 수 있다. 본 발명의 실시예의 일 측면에 있어서, 센서 데이터는, 대상 객체의 물리적인 특성, 스케일, 위치 및/또는 방향 에 관한 정보 혹은 데이터를 포함한다. 본 발명의 실시예의 일 측면에 있어서, 제어 로직은 증강 현실 환경에 대한 3차원 이미지의 중첩을 가능하게 하 는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 본 발명의 실시예의 일 측면에 있어서, 증강 현실 환경은 하나 이상의 센서의 위치 결정에 의해서 생성될 수 있 다. 본 발명의 실시예의 일 측면에 있어서, 데카르트 좌표 격자의 가상 표현을 제공하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 본 발명의 실시예의 일 측면에 있어서, 데카르트 좌표 격자의 가상 표현은 표시 장치와 하나 이상의 센서 사이 의 동기화에 의해서 구현될 수 있다. 본 발명의 실시예의 다른 측면에 있어서, 제어 로직은, 하나 이상의 센서의 실시간 및/또는 실제 위치를 이용해 서 표시 원점을 규정하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 본 발명의 실시예의 다른 측면에 있어서, 제어 로직은, 실사(photorealistic) 사용자 인터페이스를 시뮬레이션 하도록 실시간 효과를 렌더링하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 본 발명의 실시예의 다른 측면에 있어서, 제어 로직은, 증강 현실 환경의 내부 차원(inner dimension) 사용자 POV를 생성하고, 이로써 사용자가 증강 현실 환경 내에서 보고 네비게이트하는 것을 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 여기서, 일례로, 표시 장치에 투영됨으로써, 사용자가 증강 현실 환경 내를 걸어가고 및/또는 인터렉트하는 것처럼 나타날 것이다. 본 발명의 실시예의 다른 측면에 있어서, 제어 로직은 대상 객체에 물리적인 속성을 적용하는 것을 가능하게 하 는, 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 다른 측면에서는, 증강 현실 환경 자체에 물리적인 속 성을 적용하는 것을 가능하게 하는, 컴퓨터 판독 가능 프로그램 코드를 고려할 수 있다. 본 발명의 실시예의 또 다른 측면에 있어서, 제어 로직은 대상 객체에 물리적인 속성을 적용하는 효과를 시뮬레 이션하는 컴퓨터 판독 가능 프로그램 코드 및 대상 객체에 시뮬레이션된 물리적인 속성의 효과를 표시하는 컴퓨 터 판독 가능 프로그램 코드를 포함할 수 있다. 본 발명의 실시예의 또 다른 측면에 있어서, 대상 객체는 표시 장치에 의해 캡쳐되는 실제 객체의 이미지가 될 수 있다. 일 측면에서, 대상 객체의 이미지는 표시 장치의 카메라에 의해 캡쳐될 수 있다. 다른 측면에서, 이미 지는 표시 장치에 업로드될 수 있다. 본 발명의 실시예의 또 다른 측면에 있어서, 대상 객체는 사용자에 의해서 증강 현실 내에 생성된 3차원 설계가 될 수 있다. 본 발명의 실시예의 또 다른 측면에 있어서, 시스템은 3차원 모델을 외부 소스로부터 업로드할 수 있다. 본 발명의 실시예의 또 다른 측면에 있어서, 제어 로직은, 표시 장치에 의한 모션 캡쳐링 및 근접도 감지를 가 능하게 하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 본 발명의 실시예의 또 다른 측면에 있어서, 제어 로직은 다수의 사용자가 증강 현실 환경 내에 참여하는 것을 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 이는 일 측면에서, 다수의 사용자에 의한 협 력 설계를 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다 본 발명의 실시예의 또 다른 측면에 있어서, 제어 로직은, 표시 장치에 의해서 대상 객체에 대해 줌인 혹은 줌 아웃하는 것을 시뮬레이션하는 것을 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 본 발명의 실시예의 또 다른 측면에 있어서, 제어 로직은, 증강 현실 환경의 사용자의 시선을 시뮬레이션하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 이 코드는 일 측면에서, 표시 장치의 위치 및 증강 현실 환 경의 특성을 표시 장치의 초점과 결합하는 코드를 포함할 수 있다. 본 발명의 실시예의 또 다른 측면에 있어서, 제어 로직은 증강 현실 환경의 네비게이션을 가능하게 하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 현재, 본 발명의 실시예의 또 다른 측면에 있어서, 컴퓨터 판독 가 능 프로그램 코드는, 표시 장치에 의해 모션을 감지하는 컴퓨터 판독 가능 프로그램 코드 및 하나 이상의 센서 에 대한 근접도와 관련해서 표시 장치의 위치를 측정하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 본 발명의 실시예의 또 다른 측면에 있어서, 제어 로직은 사용자에 의해 정의된 물리적인 속성을 적용하는 것에 기초해서, 가능한 대상 객체 아웃컴(outcome)을 생성해서 표시하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다 본 발명의 실시예의 또 다른 측면에 있어서, 제어 로직은, 표시 장치에 있어서의 증강 현실 환경에 대한 근접도 의 변화에 기초해서 음향 재생을 생성하는 컴퓨터 판독 가능 프로그램 코드를 포함할 수 있다. 본 발명의 실시예의 또 다른 측면에 있어서, 제어 로직은 표시 원점을 결정하는 컴퓨터 판독 가능 프로그램 코 드를 포함할 수 있다. 일 측면에서, 이 컴퓨터 판독 가능 프로그램 코드는 하나 이상의 센서에 의해 형성된 위 치 결정 레이아웃의 폭 및 길이 변수를 결정하는 컴퓨터 판독 가능 프로그램 코드 및 이 폭 및 길이 변수를 2로 나누는 컴퓨터 판독 가능 프로그램 코드를 더 포함할 수 있다. 이 위치 결정 레이아웃은 예컨대, 사각 형상으로 이 경우 그 표시 원점은 길이 및 폭 값을 각각 2로 나눔으로써 결정될 수 있다. HUD 라고도 알려진 헤드업 디스플레이 혹은 헤즈업(heads-up)는, 사용자가 자신의 평상시 시점으로 벗어나지 않 아도 되게 데이터를 표시하는 투명 디스플레이이다. 본 발명은 헤드업 디스플레이와 맞춤식 CAD(computer aided design) 소프트웨어를 결합해서, 사용자가 고유의 3차원(3D) 모델을 증강 현실 환경에 표시되게 하는 것을 가능 하게 한다. 또한, HUD는 모션 캡쳐링 및 근접도 감지 기능을 가질 것이다. 본 발명에서 요구되는 소프트웨어는 내부에 혹은 외부에 저장될 수 있다. 내부적으로는 맞춤식 CAD 소프트웨어는 HUD 장치의 내장형 CPU 내에 국부 적으로 저장되어 처리될 수 있다. 다른 방안으로, 예컨대, 외부 장치(휴대 전화, PC, 웹 서버)로부터의 컨텐츠 를 간단하게 표시하는 구글 글래스와 같은 HUD 장치 내에서는, 맞춤식 CAD 소프트웨어는 HUD 장치의 외부에 저 장되어 처리될 수 있다. 본 발명에서 말하는 HUD 장치는 헤드업 디스플레이로 한정되는 것이 아니며, 투명한 및 /또는 시뮬레이션된 가상 현실 1인칭 시점을 표시할 수 있는 웨어러블 장치 및 다른 모바일 장치를 포함할 수 있다. 투명한 증강 현실 시점을 표시하는 HUD 장치는 투명 LED 디스플레이 기술을 사용해서 실사에 3D 이미지가 중첩된 것을 보여줄 수 있다. HUD의 1인칭 시점 3D를 시뮬레이션하는 장치는 장치의 내장 혹은 외장 카메라에 의해 캡쳐된 실사의 뷰에 중첩된 이미지를 렌더링할 수 있다. 일례로, 장치의 내장 카메라에 의해 캡쳐된(혹은 이를 통해서 보여지는) 실사에 대한 사용자의 시점을 증강시키는 3D 환경의 1인칭 시점을 표시하는 테블릿을 들 수 있다. 본 발명의 장치 및 HUD는 이하에서는 표시 장치 및/또는 HUD라고 할 수도 있다. 도 1을 참조하면, 예시적인 사각형의 테카르트 격자가 도시되어 있다. 도 1에 도시된 바와 같이, 3차원 공간의 데카르트 좌표계에서는, 일정한 순서를 갖는 서로 수직인 3개의 선(축)과; 3개의 축 모두에서의 하나의 길이 단 위와; 각 축에서의 방향을 선택하는 것이 포함될 수 있다. 2차원의 경우와 같이, 각축은 수직선이 될 수 있다. 한 점 P의 좌표는 도 1에 도시된 바와 같이, 점 p를 지나며 각각의 좌표축에 대해 수직인 선을 도식하고, 이들 선이 축과 만나는 지점에서의 이들 수직선의 3개의 숫자를 읽음으로써 얻어진다. 이들 좌표계는 주로 CAD 혹은 3D 모델링 소프트웨어를 이용해서 3D 모델을 설계하는데 사용된다. 본 발명에서 증강 현실 환경은, 카메라의 조준선을 이용(leverage)하는 이미지 인식 대신에, 센서 위치를 이용함으로써 생성된다. 여기서 좌표계는 위치 센 서에 의해 인에이블됨으로써, 정확한 실제 위치를 위치 결정하면서 표시될 수 있다. 도 2를 참조하면, 본 발명의 실시예의 일 측면에 따른 사용자가 위치 센서를 위치 결정하는 것이 도 시되어 있다. 여기서 사용자는 센서와 함께 도시되어 있다. 센서는 이하 설명하는 바와 같이 하 나 이상 있을 수 이다. 위치 센서는, 표시 장치의 인식 소프트웨어 성능을 통해서, 표시 장치가, 물리적인 존재를 인식 혹은 감지할 수 있는 임의의 근접 센서가 될 수 있다. 위치 센서는 주로 사용자에게, 증강 현 실 환경의 물리적인 특성, 스케일, 위치 및/또는 방향을 규정하는 성능을 제공하는데 이용된다. 도 3, 4, 5를 참조하면, 본 발명의 실시예의 일 측면에 따른, 사용자가 복수의 위치 센서를 위치 결 정하는 것 및 센서 동기화 처리의 예, 그리고 전개식 표시 환경의 예가 도시되어 있다. 위치 센서는, 사용 자가 이들을 평면에 배치할 수 있고, 표시 장치가 이들을 감지할 수 있을 정도로, 넓게 혹은 좁게 이격되어 위 치 결정될 수 있다. 위치 센서는 도시된 바와 같이 실제 환경의 크기 및 치수를 정확하게 복제해서 시뮬레 이션하도록 의도적으로 배치된다. 이로써, 도 5에 도시된 바와 같이, 정확한 축적의 3D 모델 혹은 대상 객체 를 고층 건물 정도로 크게 혹은 동전 정도로 작게 렌더링할 수 있는 증강 현실 환경의 생성이 가능하게 된 다. 위치 센서는 사용자의 작업 공간의 바운더리 혹은 주위 치수를 규정하도록 평면 상에 배치될 수 있다. 위치 센서는 표시 장치와 동기화되어서, 사각형의 데카르트 격자의 물리적인 위치의 기준점에 대한 가상 표현을 제공한다. 표시 장치의 소프트웨어는 내부 혹은 외부 표시 장치 센서를 이용해서 위치 센서의 위치 를 측정하거나 이와 동기화된다. 동기화 처리 중에, 소프트웨어는 센서 사이의 거리를 계산해서 실제 용량/제한 에 대응하는 증강 현실 환경 치수의 용량/제한을 캡쳐한다. 도 4에 도시된 바와 같이, 센서 사이의 거리 및/또는 근접도를 계산하는 센서 동기화 처리에서는, 컴퓨터에 의 해 생성된, 센서 사이의 가상 가로선이 사용되고, 이후 눈금이 매겨진다. 이렇게 생성된 눈금을 카운트해서, 그 사이의 전체 측정 가능 가상 단위(센티미터, 인치, 피트 등)를 측정한다. 동기화 처리를 통해, 생성된 선 및 눈 금은 표시 장치 사용자 인터페이스에서는 디폴트로 숨겨져 있지만, 사용자가 요청하면 표시될 수 있다. 사용자 가 센서 사이의 길이 및 폭을 지정해 둠으로써, 수정하고자 하는 프로젝트에서의 작업 공간의 크기 용량이 적절 한지 및 센서가 정확하게 평행하게 배치되어 있는지를 확인할 수 있다. 동기화를 통해서, 도 6에 도시된 바와 같은, 증강 현실 환경 혹은 표시 환경이라고 하는 컴퓨터-생성된 3축의 3D 사각 격자가 생성된다. 표시 환 경은 하나 이상의 고정 센서에 매핑되어서 증강 현실 표시 영역 혹은 작업 공간을 생성할 수 있다. 표시 환경은 주로 증강 현실 객체, 애플리케이션 혹은 운영 체제를 표시 및/또는 설계하는데 사용될 수 있 다. 도 7 및 8을 참조하면, 도 7은 본 발명의 실시예의 일 측면에 따른, 공식을 이용해서 사용자가 SSO(Single Sensor Origin)를 나타내는 것을 도시하고 있고, 또한 도 8은 본 발명의 실시예의 일 측면에 따른, 대축적 의 환경을 전개하는 것을 나타내고 있다. 표시 환경을 전개하기 위해서는 SSO 및 MSO(Multiple Sensor Origin)를 통해서 표시 원점 (Display Origin Point)을 규정할 필요가 있다. 표시 원점은 SSO의 위치에 의해 규정되는 하나의 실제 위치가 될 수도 있고, 혹은 표시 환경의 물리적인 치수를 정의하도록 사각형상의 점의 세트로서 위치 결정된 복수의 센 서가 될 수도 있다. SSO의 지점은, 사용자가 (0,0,0)와 같은 표시 환경의 원점 및 표시 환경 의 소프트웨어 전개 지점을 자동으로 나타내고자 할 때 필요한 물리적인 위치에 배치된 하나의 센서에 기 초하고 있다. SSO는 표시 환경의 길이 및 폭을 설정하기 위한 중간점으로서 사용된다. SSO는 또한 표 시 환경의 높이 혹은 폭의 기준점으로서 사용된다. 길이, 폭 및 높이(혹은 깊이) 값은 사용자가 수동 으로 설정할 수도 있다. 이로써 소프트웨어는, 도 7 및 8에 각각 도시된 바와 같이, 표시 환경의 원점으로 써 SSO 혹은 MSO를 계산하고, 이로부터 사용자의 길이, 폭 및 높이(혹은 깊이) 값을 이용해서 3D의 사각형 둘레를 자동으로 생성할 수 있게 된다. MSO를 이용해서 표시 환경을 전개하기 위해서는, 소프트웨어가 임시 원점으로서 하나 이상의 센서를 이용하고, 2개의 다른 인접 센서로부터 이 원점까지의 거리 를 계산해서 길이 및 폭 값을 생성해야 한다. 이러한 계산을 통해, 소프트웨어가 MSO를 생성하기 위한 실 제 물리적인 지점이 제공된다. MSO는 복수의, 주로 사각형 구성으로 결합될 수 있는 4개의 센서의 중 점값이다. 이 4개의 센서의 길이 및 폭 값을 반으로 나누어서, 도 8에 도시된 바와 같은 MSO의 x 및 y 변 수값을 설정한다. 예컨대, x=폭/2이고 y=길이/2라면, MSO의 지점은 좌표(X, Y, Z)와 같을 것이다. MSO를 계산할 때, 사용자가 표시 환경의 높이 값을 규정할 때까지는 z 변수의 디폴트값은 0이다. (MSO) 처리 예; 1. 표시 환경의 사각형상의 네 모서리를 정의하도록 4개의 센서를 배치한다. 2. 사각형의 4개의 변의 길이 및 폭 변수를 계산한다 예 : L=12, W=6 3. 길이 및 폭을 2로 나누어서 X 및 y 변수값을 계산한다. 예 : X=(12/2); Y=(6/2) X=6, Y=3, Z=0 MSO=(6,3,0) 4. 소프트웨어가 사전에 계산된 MSO 지점을 표시 환경 특성에 저장한다. 일단 표시 환경의 표시 원점이 설정되면, 사용자는 표시 환경 특성이라고 하는 표시 환경의 리스트를 정의할 수 있다. 표시 환경 특성은 소프트웨어에 의해 생성된 메뉴로, 사용자는 이를 통해서 표시 환경 에 적용될 속성값의 리스트를 관리할 수 있다. 저장되는 속성은 표시 환경의 인터렉티브한 물리적인 성능에 관한 메타데이터를 포함할 수 있다. 저장될 수 있는 특성의 몇가지 예로는 MSO, SSO, 환경 길이, 환경 폭, 환경 높이, 최대 X 축값, 최대 Y 축값, 최대 Z 축값을 들 수 있지만, 이것으로 한정되는 것은 아니며, 표시 환경의 가시적인 특성도 또한 이들 특성에 의해 설정된다. 도 9를 참조하면, 본 발명의 실시예의 일 측면에 따른 표시 장치의 위치 동기화 처리가 도시되어 있다. 표 시 장치의 위치는 표시 장치로부터 표시 환경의 센서까지 계산된 거리 및 높이값의 조합으 로부터 구해질 수 있다. 이 계산의 결과를, 도 9에 도시된 바와 같은 HUD 센서 동기화 처리라고 한다. HUD 센서 동기화 처리는, 측정을 위해서 위치 센서로부터 표시 장치까지 그려진 눈금을 사용한다는 점을 제외 하면, 상기의 센서 동기화 처리와 동일하다. 표시 장치의 거리 및 높이는 HUD 센서 동기화 처리에 의해 측 정되어서, MSO 혹은 SSO로부터의 세로선과 교차하는, 표시 장치로부터의 가로선을 생성한다. 표 시 장치의 거리는 표시 장치로부터 MSO 혹은 SSO의 세로 교차점까지의 가로 눈금을 카운트 해서 측정한다. 표시 장치의 높이는 MSO 혹은 SSO의 가로 교차점으로부터 표시 장치까지의 세로 눈금을 세어서 측정할 수 있다. 표시 장치의 위치는 (표시 장치를 사용하는) 사용자가 표시 장 치의 물리적인 위치 및/또는 방향을 변경하면 변경되기 때문에, 유동적으로 계산될 수 있다. 이러한 재계산은, 표시 장치의 모션 캡쳐링 감지 기능에 의해 신호를 수신함으로써 개시된다. 도 10~12를 참조하면, 본 발명의 실시예의 일 측면에 따른, 예시적인 3D 렌더링 및 투영과, 표시 장치의 1인칭 시점에 있어서의 초점 및 시선과 함께 나타낸 표시 장치 POV(point of view)와, 표시 장치의 3인칭 시점에 있어 서의 초점 및 시선과 함께 나타낸 표시 장치 POV를 나타내고 있다. POV라고 하는 표시 장치 사용자 인터페이스(UI)는, 3D 렌더링의 컴퓨터 그래픽 처리를 이용해서, 3D 와이 어 프레임 모델을 2D 이미지로 자동으로 변환한다. 도 10에 도시된 바와 같이, 3D 와이어 모델의 지점들이 표시 환경에 도시되고, 표시 장치의 소프트웨어가 실시간 3D 렌더링 효과를 적용해서 실사(photorealistic) 사 용자 인터페이스를 시뮬레이션한다. POV는 사용자의 현실의 1인칭 POV를 3D 렌더링된 객체와 함께 시뮬레이션한다. 또한, POV는 3D 투영 및 직교 투영을 이용해서 표시 환경의 종횡비를 표시함으로써, 도 11 및 12에 도시된 바와 같이 화상면으로서 2D 이미지를 표시한다. 이 화상면은, 표시 장치 의 초점으로부터의 시선 및 표시 환경에 대해 수직인 생성된 면이다. 시각 투영 초점은 사용자의 시 야의 중심 혹은 원점이다. 도 11 및 12에 도시된 바와 같이, 표시 장치의 위치 및 표시 환경의 특성이 초 점과 결합되어서 사용자의 시각의 시선을 시뮬레이션한다. 도 13~15를 참조하면, 본 발명의 실시예의 일 측면에 따른, 근접도를 달리하면서 표시 환경을 보는 표시 장치 POV, 모션 캡쳐링 및 이미지가 1인칭 시점의 시선에 따라서 달라지고 있는 표시 특성, 모션 캡쳐링 및 이미지가 3인칭 시점의 시선에 따라서 달라지고 있는 표시 특성이 도시되어 있다. 표시 환경에 대한 표시 장치의 감지된 인접도가 변경되는 것으로 인해서 표시 장치의 시선을 재 계산할 때, 모션 캡쳐 기술이 사용될 수 있다. 도 13~15에 도시된 바와 같이, 사용자가 표시 환경에 대한 장치의 근접도를 변경하면, 모션이 캡쳐되고 소프트웨어는 표시 장치에 의해 투영되는 이미지를 재렌더링 한다. 도 14 및 15에 도시된 바와 같이 이 재렌더링에서는 표시 장치의 POV의 시선이 표시 환경 과 만나는 지점을 다시 계산함으로써, 표시 환경의 네비게이션을 시뮬레이션한다. 도 16~18을 참조하면, 본 발명의 실시예의 일 측면에 따른, 3인칭 시점에 있어서의 표시 환경 3D 방향 네비게이 션, 1인칭 및 3인칭의 POV 머리 기울임 모션 캡쳐 뷰 효과가 도시되어 있다. 표시 환경 네비게이션은 도 16에 도시된 바와 같이 위, 아래, 좌, 우, 앞, 뒤의 현실 세계의 3차원 움직임 및 뷰의 효과를 낸다. 사용자는 또한 도 17 및 도 18에 도시된 바와 같이 경사 각도로 뷰를 볼 수 있다. 도 19 및 20을 참조하면, 본 발명의 실시예의 일 측면에 따른, 1인칭 및 3인칭 시점에 있어서의 내부 위치 및 외부 위치 POV의 예가 도시되어 있다. 위치 시점은, 표시 환경의 주위의 내부 혹은 외부의 사용자의 가능 범위(ability)를 시뮬레이션한다. 대축적 표시 환경이 전개되고, 표시 장치의 위치가 표시 환경(60 0)의 주위 내에서 측정될 수 있는 시나리오에서는, 표시되는 이미지는 내부 차원 POV를 생성하도록 조정될 것이다. 내부 차원 POV는 사용자의 시선을 조정해서, 표시 환경을 360도의 가로 세로 시야 범위에서, 내부로부 터 보게 한다. 예컨대, 큰 건물의 3D 모델을 생성하기에 충분하도록 다수의 센서가 이격되어 있는 표시 환경에 서는, 사용자는 잠재적으로 도 19 및 20에 도시된 바와 같이 이 모델의 내측 앵글 및 외측 앵글을 모두 네 비게이션하거나 혹은 볼 수 있다. 사용자의 표시 장치 가로 시선이 임의의 표시 환경의 좌표를 만족하지 않는다 면, 이미지는 표시되지 않을 것이고, 따라서 사용자가 환경 혹은 객체를 보지 않는 것처럼 시뮬레이션할 것이다. 도 21 및 22를 참조하면, 본 발명의 실시예의 일 측면에 따른, 인터렉션 장치의 동기화 처리의 예 및 사용자 가 인터렉션 장치를 이용하는 것이 도시되어 있다. 인터렉션 장치는, 표시 장치의 소프 트웨어와 동기화되어서 사용자가 입력한 소프트웨어 커맨드를 캡쳐하는 주변 기기를 포함하고 있다. 또한, 인터렉션 장치를 통해서 사용자는, 장치 동기화 처리를 이용해서 인터렉션 장치의 위치 좌표를 캡쳐해서 POV에 의해 볼 수 있는 소프트웨어 커맨드를 생성함으로써, 표시 환경 인터페이스를 조작할 수 있다. 도 21에 도시된 바와 같이 장치 동기화 처리는, 표시 장치 대신 주변 기기가 사용된다는 점을 제외하면, 마찬가지 로 HUD 센서 동기화 처리에 사용된다. 또한, 일부 장치는 스타일러스 막대(wand), 키보드, 마우스, 휴대형 리모 컨, 손, 눈, 혹은 신체의 움직임을 캡쳐하는 장치, BCI(brain computer interface) 장치(이것으로 한정되는 것 은 아님)를 포함할 수 있다. 인터렉션 장치 소프트웨어 커맨드 입력 기능은, 상기 설명한 사용자의 표시 환경의 POV를 표시하는 방법과 유사하게 처리되며, 여기서는 이미지가 렌더링되는 대신, 표시 환경에 대한 인터렉션 장 치의 물리적인 근접도가 캡쳐되고, 소프트웨어가 도 22에 도시된 바와 같이 장치의 위치에 대한 커맨드를 처리 한다. 도 23~27을 참조하면, 본 발명의 실시예의 일 측면에 따른, 격자선 없는, 3인칭 POV 시점에 있어서의 설계 사용 자 인터페이스, 격자선이 토글된, 3인칭 POV 시점에 있어서의 설계 사용자 인터페이스, 설계 사용자 인터페이스 의 격자선이 없는 다른 표시 환경 뷰, 설계 사용자 인터페이스의 격자선이 있는 다른 표시 환경 뷰, 사용자가 스큐잉과 리사이징하면서 1D 객체에서 3D 객체로 단계적으로 설계하는 것이 도시되어 있다. 특정한 속성을 이용해서 현실 세계의 물리적인 치수, 질감 및 다른 특성을 시뮬레이션함으로써, 표시 환경(60 0)에서 객체가 설계되고 표시될 수 있다. 사용자는 자신이 설계하는 대로 다수의 표시 환경의 시점 및 객체의 방향을 보고 및/또는 조작할 수 있다. 설계 인터페이스는 다수의 객체 생성 툴을 제공하며, 이는 인터렉 션 장치를 사용해서 개시되는 소프트웨어 커맨트로 객체를 설계하는데 사용된다. 표시 환경과 표시 장치의 동기화를 이용함으로써, 사용자는 표시 환경 상의 특정한 지점들에 기초해서 3D 객체를 설계하고 조작할 수 있다. 본 발명에서 가리키는 3D 객체는, 표시 환경이라고 하는, 소프트웨어에 의해 생성된 데카르트 좌 표계 상에 도시된 3D 모델이다. 도 23~26에 도시된 바와 같이, 객체 설계 처리시에, 사용자는 객체 설계 정확도 를 강화하기 위해서, 투명 그리드의 대안의 표시 환경 뷰를 토글 온 및 토클 오프할 수 있을 것이다. 맞춤식 CAD 소프트웨어 측면들이 설계 인터페이스를 통해서 제공되어서, 3D 객체 설계 처리 동안 1인칭 시점을 사용자 에게 제공한다. 이 처리에서는 길이, 폭 및 높이, 혹은 반경과 같은 물리적인 특성을 특정함으로써 1차원(1D) 형상의 형성을 이용한다. 예컨대, 일부 1D 형상은 원형, 사각형 혹은 삼각형이 될 수 있다. 이들 1D 형상을 변 형해서, 원뿔, 육면체, 및 구와 같은 3D 모델을 생성한다. 이후에 3D 모델은 도 27에 도시된 바와 같이, 커스토 마이즈되어서 크기와 같은 물리적인 특성 및 고유 형상을 캡쳐한다. 1D 형상은 또한, 사용자가 형상의 물리적인 특성을 형성하는데 이용하는 기본적인 프리핸드 툴(freehand tool) 혹은 직선 그리기 툴을 이용해서 설계될 수 도 있다. 사용자의 설계 시점은 표시 장치 POV에 기초하고 있으며, 이는 표시 환경과의 근접도에 따라서 변경된 다. 도 28~31을 참조하면, 본 발명의 실시예의 일 측면에 따른, 1인칭 및 3인칭의 표시 장치의 POV에 있어서의 객체의 방향을 회전시키는 것, 사용자 근접도에 기초해서 1인칭 및 3인칭 POV에 있어서의 스냅 포인트가 도시되어 있다. 스냅 포인트(snap points)는 Autodesk사의 AutoCAD Object Snaps(Osnaps)와 유사한 것으로, 다른 CAD 소프트웨어 커맨드와 함께 객체를 정확하게 도식하고 조작하는데 사용될 수 있다. 스냅 포인트를 이용해 서, 특정한 객체의 위치로 스냅해서 인터렉션 지점으로서 나타낼 수 있다. 사용자가 표시 장치에 표시된 객체를 근접도에 기초해서 보고 있기 때문에, 사용자는 도 28 및 29에 도시된 바와 같이 더 양호한 POV를 위해서 표시 환경 주위에서 물리적으로 네비게이트해야 하거나, 혹은 스냅 포인트를 이용해서 필요한 객체를 이동 혹은 회전 시키면서 인터렉티브 장치를 이용해서 3D 객체의 방향을 조정할 것이다. 나아가, 도 30 및 31에 도시된 바와 같이, 스냅 포인트는 선의 마지막 지점 혹은 원의 중심을 정확하게 스냅하 고, 3D 객체의 고유 형상의 일부로서 다른 선분을 도식할 수 있다. 도 32 및 33을 참조하면, 본 발명의 실시예의 일 측면에 따른, 1인칭 및 3인칭 POV에 있어서의 스냅 포인트를 교체하도록 뷰를 네비게이팅/변경하는 것이 도시되어 있다. 표시 장치의 인접도가 변경됨에 따라서, 스냅 포인 트는 보일 수도 있고 보이지 않을 수도 있다. 이로써, 도 32 및 33에 도시된 바와 같이, 사용자는, 3D 객 체의 지점을 보는 것이 사용자의 시점 혹은 객체의 방향에 기초해서 인터렉션만을 차단하는 경험을 할 수 있다. 도 34 및 35를 참조하면, 도 34는 본 발명의 실시예의 일 측면에 따른, 메뉴를 이용해서 물리적인 속성을 추가 하는 것을 나타내고 있고, 도 35는 본 발명의 실시예의 일 측면에 따른, 질감과 중력으로, 객체에 물리적인 속 성을 할당하는 것을 나타내고 있다. 물리적인 특성 사용자 인터페이스(UI)는 물리적인 속성을 사전 설계 된 3D 객체에 할당하는 데 사용될 수 있다. 이 사용자 인터페이스는, 도 34에 도시된 바와 같이 사용자에 의해 할당되는 속성의 메뉴를 제시해서, 객체의 물리적인 혹은 가시적인 속성을 시뮬레이션한다. 일부 속성은 하기 표 1에 나열된 속성을 포함할 수 있으며, 이것으로 한정되는 것은 아니다. 표 1 흡수도 전기 위치 광채(radiance) 알베도(albedo) 전기 임피던스 휘도 가용성 각도 모멘텀 전계 발광 비열(specific heat) 면적 전위 광택 저항 취성 배출 유연성 반사율 끓는점 유속 자계 반사도 커패시턴스 유동성 자속 회전 색상 빈도 질량 강도 농도 경도 용융점 강성 밀도 인덕턴스 모멘트 온도 유전체 고유 임피던스 모멘텀 장력 연성 세기 불투명도 열전도 분산 복사율 투과율 속도 효율 길이 유전율 점도 탄성 압력 가소성 체적 파동 임피던스 표시 장치의 소프트웨어 혹은 인터렉션 장치에 의해서 다양한 객체 리액션 및 인터렉션이 발생되도록, 물 리적인 특성은 소프트웨어에 의해 인식된다. 계산된 3D 객체의 리액션은, 현실 세계의 반응 혹은 다양한 타입의 물리 시스템에 대한 유사한 시뮬레이션을 제공하도록 소프트웨어에 의해 처리된, 선택 가능하고 커스토마이즈 가능한 물리 엔진에 의해서 사전 결정된다. 본 발명의 실시예의 일 측면에 따라서, 물리 엔진은 현실 세계의 물 리적인 리액션을 시뮬레이션하도록 계산된 결과를 구한다. 물리 엔진은 소프트웨어의 일부가 될 수도 있고, 혹 은 장치 내에 혹은 장치 밖에 있는 소프트웨어가 될 수도 있다. 표시 장치의 소프트웨어를 통해서 사용자는 다양하게 시뮬레이션된 환경 내의 객체에 대한 1인칭 시 점을 가지고 이들이 어떻게 리액션하는지 볼 수 있다. 시뮬레이션된 환경은, 도 36에 도시된 바와 같이, 온도 및 환경 효과를 포함한 실생활 세팅 내에 객체가 있는 효과를 포함할 수 있다. 본 발명의 실시예의 일 측면에 따라서, 표시 레이어 인덱스를 사용해서, 객체 및 리액션/솔루션이 사용자에 의 해 보여지는 것을 필터링하고 순서를 정할 수 있다. 각각의 레이어의 순서는 특정한 인덱스 숫자로 결정될 수 있으며, \"0\"은 바닥이 되고, 그 위에 레이어가 적층되면서 숫자가 증가한다. 레이어는 턴오프될 수도 있고(보이 지 않음), 순서가 변경될 수도 있으며(리인덱스), 삭제 혹은 차단될 수도 있다(수정 불가). 도 36 및 37을 참조하면, 도 36은 본 발명의 실시예의 일 측면에 따른, 3인칭 시점에 있어서의, 물리 엔진을 통 해서 객체에 중력이 적용되고 있는 것을 나타내고, 도 37은 본 발명의 실시예의 일 측면에 따른, 본 발명의 실 시예의 일 측면에 따른, 사용자의 3인칭 시점에 있어서의, 충돌의 물리 엔진 시뮬레이션 및 출동 검출 효과를 나타내고 있다. 도 38 및 39를 참조하면, 본 발명의 실시예의 일 측면에 따른, 1인칭 및 3인칭 POV에 있어서의 객체가 단계별로 애니메이션 캡쳐를 거치는 것을 나타내고 있고, 도 40 및 41은 본 발명의 실시예의 일 측면에 따른, 소프트웨어 이벤트 트리거의 물리 반응 'IF 문' 및 인터렉션 장치 이벤트 트리거의 물리 반응 'IF 문'을 나타내고 있다. 상 술한 물리 엔진은 사용자가 규정한 물리 특성에 기초해서 가능한 물리 모멘트 결과를 계산한다. 사용자는 사전 설정된 물리 엔진을 이용하거나 혹은 커스컴 물리 엔진을 불러와서(import) 시뮬레이션된 결과 성능을 수정할 수 있다. 적용되는 맞춤식 물리 엔진의 예로는, 지구와는 다른 달의 대기 특성을 시뮬레이션하는 환경을 들 수 있다. 사용자는 객체의 물리 특성값을 조정함으로써 물리적인 계산 결과를 수정한다. 사용자는 표시 환경 을 이용해서 현실 세계의 리액션과 유사한 다이나믹한 리액션을 실시간으로 경험할 수 있다. 객체 스루(Object Thought)는 객체에 대한 인공 지능을 시뮬레이션한다. 객체 스루 인터페이스를 통해서 사용자 는, 인터렉션 장치에 의해 트리거된 사용자의 액션이나 혹은 소프트웨어에 의해 생성된 자동화된 이벤트 트리거 에 기초해서, 프레임 단위로 복제될 객체 애니메이션을 챕쳐할 수 있다. 모멘트를 캡쳐하는 것은, 도 38 및 39 에 도시된 바와 같이, 사용자가 객체를 이동시키고 이후에 소프트웨어를 이용해서 객체의 스냅 포인트 의 위치 변경에 대한 계산 결과를 단계적으로 캡쳐하는 것으로 이루어진다. 크기 및 형상과 같은 객체의 물리적인 특성을 변경하는 것도 단계별 조작에 의해 캡쳐된다. 객체를 프레임단위로 캡쳐한 이후에, 사용자는 객체의 로지컬 액션, 리액션 및 일반적인 모멘트 성능을 시뮬레이션하도록 물리 리액션 로직을 구성한다. 이 물 리 리액션 로직은 애니메이션을 통해서 캡쳐된 객체를 이용해고, IF 문 공식 로직을 적용해서 소프트웨어 및/또 는 사용자에 의해 개시된 이벤트 트리거에 대해서 객체가 어떻게 리액션하는지 결정한다. IF 문 공식은 개 시자의 커맨드(개시 이벤트) 및 액션으로 이루어진 단계별 처리를 생성한다. \"IF 문\"은 일반적으로 개시 이벤트, 리액션, 그리고 다수의 로지컬 결과를 생성하는 절(clause), 파라미터 및 변수를 갖고 있다. 일례로, 도 40 및 41에 도시된 바와 같이, 타이어가 기대어 있는 물체를 사용자가 이동시키면(개시 이벤 트), 타이어는 멀리 굴러간다(객체는 회전 액션을 한다). 이러한 \"IF 문\" 기반 인공 지능(물리 리액션 로 직)을 통해서, 객체는 다이나믹 솔루션을 위한 스크립된 액션 및 리액션을 가질 수 있게 된다. 본 발명은, 실시예의 일 측면에서, OSE(Object Solution Environment) 사용자 인터페이스을 포함할 수 있으며, 이는, 맞춤식 액션 공식, 향상된 과학적인 공식, 메뉴, 컨텐츠 및 미디어 타입(이미지, 비디오, 오디오 등)을 포함하는, 사용자 처리 솔루션(HUD 애플리케이션 혹은 미디어 컨텐츠)을 생성하는데 이용하는 툴을 제공할 수 있다. 객체 솔루션은 모바일 애플리케이션 및/또는 컴퓨터 프로그램의 개념과 유사하게, 다른 HUD 사용자에 의 한 재사용 및 인터렉션을 위해서 패키지될 수 있다. 오디오 재생은 표시 장치의 물리적인 위치의 영향을 받을 수도 있다. 객체가 발생시키는 소리는 소프트웨 어에 의해서 시뮬레이션되어서, 사용자가 표시 환경을 네비게이션하는 동안 3D 사운드 효과를 듣는 경험을 할 수 있게 한다. 표시 장치가 표시 환경에 대한 근접도를 상대적으로 변경함에 따라서, 소프트웨어 는 소리 재생에 변화를 준다. 머리-관련 전달 기능 및 반향(reverberation)을 이용함으로써, 소스(벽 및 바닥에 서의 반사를 포함)로부터 청취자의 귀를 향하는 방향에서의 소리의 변화가 시뮤레이션될 수 있다. 이 효과는 청 취자의 뒤, 위 및 아래에 있는 음원의 위치를 측정하는 것을 포함한다. 일부 3D 기술에서는 바이노럴(binaural) 레코딩을 스테레오 레코딩으로 변화한다. 모로우 사운드 트루(MorrowSound True) 3D는 바이노럴, 스테레오, 5.1 및 다른 포맷을 8.1 단일 및 다수 존의 3D 사운드 경험으로 실시간으로 변환시킨다. 도 42 및 43을 참조하면, 본 발명의 실시예의 일 측면에 따른, 1인칭 및 3인칭 시점의 복수의 사용자가 협력 설 계 작업을 수행하는 것이 도시되어 있다. 본 발명은 복수의 사용자가 협력하는 측면을 제공하며, 표시 환 경의 인터렉트, 네비게이션 및 시청을 동시에 행할 수 있게 한다. 일 측면에서 이러한 협력을 위해서는, 사용자 가 동시에 3D 환경 데이터에 액세스할 수 있도록, 인터넷 혹은 로컬 서버 접속이 필요하다. 복수 사용자 가 액세스하면 '협력-설계'하는 능력을 제공할 것이며, 이 '협력-설계'는 사용자가 동시에 객체를 설계하고, 커 멘드와 같은 라이브 마크업 그리고 객체 및/또는 환경에 관한 편집을 제공할 수 있는, 객체 설계 및 표시시의 처리이다. 또한, 협력 설계 특성은, 다수의 사용자가 표시 환경의 측면들을 보거나 제시하는 키 툴로서 사용될 것이다. 본 발명의 실시예의 일 측면에 있어서, 사용자는 환경에 커맨드 및 도면을 추가해서, 주석을 저장하고 변경을 추가할 수 있다. CAD 소프트웨어와 같은 응용 가능한 소프트웨어를 통해서 사용자는 하나의 환경에서 객 체를 협력-설계할 수 있다. CAD 소프트웨어가 외부에서 웹 서버를 통해서 처리되면, 다수의 사용자는 객체를 협 력해서 설계할 수 있다. 표시 환경의 각각의 사용자 POV는, 도 42 및 43에 도시된 바와 같이, 다양한 표시 앵글및 표시되고 있는 개체에 대해 고유의 시점을 가질 것이다. 도 44 및 45를 참조하면, 도 44는 본 발명의 실시예의 일 측면에 따른, 타이어를 회전/반동시키고 또한 오디오 를 생성하는 것과 이미지가, 인터렉트되는 것을 나타내고 있고, 도 45는 본 발명의 실시예의 일 측면에 따른, 사람이 표시되고, 표시 환경과 인터렉트되는 3D 비디오를 나타내는 도면이다. 솔루션 설계 처리는 설계된 객체, 물리, 그리고 메뉴 및 미디어 컨텐츠를 가진 AI의 패키지로 구성된다. 이러한 처리를 통해서 사용자는, 애플리케이션으로서의 표시 장치에 설계를 위해서 표시되는 표시 환경 혹은 객체를 보 고, 생성하며, 저장하고, 공유하고, 이와 인터렉트할 수 있다. 인터렉트 메뉴 및 액션은, 저장된 소프트웨어 커 맨드를 개시할 때 사용자가 적용할 수 있는 다양한 옵션을 제공한다. 이 예에서의 소프트웨어 커맨드는 사전 설 계된 액션/이벤트 트리거가 될 수도 있고, 혹은 사용자가 정의한 이벤트를 개시시키는 객체 물리 리액션 로직이 될 수도 있다. 인터렉티브 장치는 사용자 인터렉션의 소스를 생성하는 이들 소프트웨어 커맨드를 개시하는 능력 을 갖고 있다. 또한, 이미지, 오디오 및 비디오와 같은 미디어는 사용자의 인터렉션 및 경험을 더 강화하는데 사용된다. 예로서, 도 44에 도시된 바와 같은, 소리 효과와 함께 결합된 타이어 회전 액션의 3D 모델의 이벤트 를 트리거하는, 사용자 규정된 이미지를 들 수 있다. 또한, 예로서, 도 45에 도시된 바와 같은, 사용자가 본 발 명의 3D 객체 성능과 유사한 표시 장치와 인터렉트하고 주위를 네비게이트할 수 있는, 인물의 3D 캡쳐 비디오를 들 수 있다. 이하, 본 발명의 일 측면의 예시적인 응용예를 설명한다. 우선, 사용자는 표시 환경의 OSE 작업 공간에 대한 윤 곽/바운더리를 결정하도록, 위치 센서를 사용해서 작업 공간을 지정할 수 있다. 이후에 사용자는 설계 툴을 이 용해서 형상의 조작을 개시함으로써 지정한 객체 물리 치수를 생성한다. 각 객체가 OSE 물리의 연관성을 생성하 도록 사용자가 물리적인 속성을 선택할 수 있는 경우에는, 객체에 속성이 적용될 수 있다. 사용자는 시뮬레이션 되는 OSE에 대한 물리를 구성해야 한다. 사용자는 객체의 인공 지능을 시뮬레이션하도록 객체 스루(Object Thought)를 설계할 수 있다. '스루' 사용자 인터페이스를 통해서, 사용자는, 인터렉션 장치에 의해 사용자가 트 리거한 액션 혹은 소프트웨어에 의해 트리거/제공되는 자동화된 이벤트에 기초해서, 복제될 객체의 움직임을 프 레임 단위로 캡쳐할 수 있다. 사용자는 로직 및/또는 애니메이션을 특정 객체에 적용해서 움직임을 생성한다. 선택적으로, 사용자는 논리학 혹은 다른 통계학을 참조할 수 있다. 패키지된 프로젝트는 저장되어서 다른 프로 젝트와 공유될 수 있다. 본 발명을 특정 바람직한 실시예를 참조하면서 설명했지만, 본 발명의 사상 및 범주를 벗어남 없이 변형 및 수 정이 행해질 수 있다는 것을 이해할 것이다."}
{"patent_id": "10-2015-7036049", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 예시적인 사각형의 데카르트 격자를 나타내는 도면, 도 2는 본 발명의 실시예의 일 측면에 따른, 사용자가 위치 센서를 위치 결정하는 것을 나타내는 도면, 도 3은 본 발명의 실시예의 일 측면에 따른, 사용자가 복수의 위치 센서를 위치 결정하는 것을 나타내는 도면, 도 4는 본 발명의 실시예의 일 측면에 따른, 센서 동기화 처리의 예를 나타내는 도면, 도 5는 본 발명의 실시예의 일 측면에 따른, 전개된 표시 환경을 나타내는 도면, 도 6은 본 발명의 실시예의 일 측면에 따른, 사용자가 공식을 이용해서 MSO(Multiple Sensor Origin)을 식별하 는 것을 나타내는 도면, 도 7은 본 발명의 실시예의 일 측면에 따른, 사용자가 공식을 이용해서 SSO(Single Sensor Origin)을 식별하는 것을 나타내는 도면, 도 8은 본 발명의 실시예의 일 측면에 따른 대축적 환경의 전개를 나타내는 도면, 도 9는 본 발명의 실시예의 일 측면에 따른 표시 장치 위치 동기화 처리의 일례를 나타내는 도면, 도 10은 예시적인 3D 렌더링 및 투영을 나타내는 도면, 도 11은 본 발명의 실시예의 일 측면에 따른, 표시 장치 POV(point of view)를, 표시 장치의 1인칭 시점에 있어 서의 초점 및 시선과 함께 나타내는 도면, 도 12는 본 발명의 실시예의 일 측면에 따른, 표시 장치 POV를, 표시 장치의 3인칭 시점에 있어서의 초점 및 시 선과 함께 나타내는 도면, 도 13은 본 발명의 실시예의 일 측면에 따른, 근접도를 달리하면서 표시 환경을 보는 사용자의 표시 장치 POV를 나타내는 도면, 도 14는 본 발명의 실시예의 일 측면에 따른, 1인칭 시점의 시선에 따라서 달라지는 모션 캡쳐링 및 이미지를 나타내는 도면, 도 15는 본 발명의 실시예의 일 측면에 따른, 3인칭 시점의 시선에 따라서 달라지는 모션 캡쳐링 및 이미지를 나타내는 도면, 도 16은 본 발명의 실시예의 일 측면에 따른, 3인칭 시점에 있어서의 표시 환경 3D 방향 네비게이션을 나타내는 도면, 도 17은 본 발명의 실시예의 일 측면에 따른, 1인칭의 POV 머리 기울임 모션 캡쳐 뷰 효과를 나타내는 도면, 도 18은 본 발명의 실시예의 일 측면에 따른, 3인칭의 POV 머리 기울임 모션 캡쳐 뷰 효과를 나타내는 도면, 도 19는 본 발명의 실시예의 일 측면에 따른, 1인칭 및 3인칭 시점에 있어서의 내부 위치 POV의 예를 나타내는 도면, 도 20은 본 발명의 실시예의 일 측면에 따른, 1인칭 및 3인칭 시점에 있어서의 외부 위치 POV의 예를 나타내는 도면, 도 21은 본 발명의 실시예의 일 측면에 따른, 인터렉션 장치의 동기화 처리의 예를 나타내는 도면, 도 22는 본 발명의 실시예의 일 측면에 따른, HUD 1인칭 시점에서 사용자의 손이 인터렉션 장치를 이용해서 객 체와 인터렉트하는 것을 나타내는 도면, 도 23은 본 발명의 실시예의 일 측면에 따른, 격자선이 없는, 3인칭 POV 시점에 있어서의 설계 사용자 인터페이 스를 나타내는 도면, 도 24는 본 발명의 실시예의 일 측면에 따른, 격자선이 토글된, 3인칭 POV 시점에 있어서의 설계 사용자 인터페 이스를 나타내는 도면, 도 25는 본 발명의 실시예의 일 측면에 따른, 설계 사용자 인터페이스의 격자선이 없는 다른 표시 환경 뷰를 나 타내는 도면, 도 26은 본 발명의 실시예의 일 측면에 따른, 설계 사용자 인터페이스의 격자선이 있는 다른 표시 환경 뷰를 나 타내는 도면, 도 27은 본 발명의 실시예의 일 측면에 따른, 사용자가 스큐잉과 리사이징하면서 1D 객체로부터 3D 객체로 단계 적으로 설계하는 것을 나타내는 도면, 도 28은 본 발명의 실시예의 일 측면에 따른, 1인칭 POV에 있어서의 객체의 방향을 회전시키는 것을 나타내는 도면, 도 29는 본 발명의 실시예의 일 측면에 따른, 3인칭 POV에 있어서의 객체의 방향을 회전시키는 것을 나타내는 도면, 도 30은 본 발명의 실시예의 일 측면에 따른, 사용자 근접도에 기초해서 1인칭 POV에 있어서의 스냅 포인트 (snap points)를 보는 것을 나타내는 도면, 도 31은 본 발명의 실시예의 일 측면에 따른, 사용자 근접도에 기초해서 3인칭 POV에 있어서의 스냅 포인트를 보는 것을 나타내는 도면, 도 32는 본 발명의 실시예의 일 측면에 따른, 뷰를 네비게이팅/변경해서 1인칭 POV에 있어서의 스냅 포인트를 교체하는 것을 나타내는 도면, 도 33은 본 발명의 실시예의 일 측면에 따른, 3인칭 POV에 있어서의 스냅 포인트를 교체하도록 뷰를 네비게이팅 /변경하는 것을 나타내는 도면, 도 34는 본 발명의 실시예의 일 측면에 따른, 메뉴를 이용해서 물리적인 속성을 추가하는 것을 나타내는 도면, 도 35는 본 발명의 실시예의 일 측면에 따른, 질감과 중력으로, 객체의 물리적인 속성 효과를 나타내는 도면, 도 36은 본 발명의 실시예의 일 측면에 따른, 사용자의 3인칭 시점에 있어서의, 물리 엔진을 통해서 객체에 중 력이 적용되고 있는 것을 나타내는 도면, 도 37은 본 발명의 실시예의 일 측면에 따른, 사용자의 3인칭 시점에 있어서의, 충돌의 물리 엔진 시뮬레이션 및 출동 검출 효과를 나타내는 도면, 도 38은 본 발명의 실시예의 일 측면에 따른, 사용자의 1인칭 POV에 있어서의 객체가 단계별로 애니메이션 캡쳐 를 거치는 것을 나타내는 도면, 도 39는 본 발명의 실시예의 일 측면에 따른, 사용자의 1인칭 POV에 있어서의 객체가 단계별로 애니메이션 캡쳐 를 거치는 것을 나타내는 도면, 도 40은 본 발명의 실시예의 일 측면에 따른, 소프트웨어 이벤트 트리거의 물리 리액션 'IF 문'을 나타내는 도 면, 도 41은 본 발명의 실시예의 일 측면에 따른, 인터렉션 장치 이벤트 트리거의 물리 반응 'IF 문'을 나타내는 도 면, 도 42는 본 발명의 실시예의 일 측면에 따른, 1인칭 시점의 복수의 사용자가 협력 설계하는 것을 나타내는 도면, 도 43은 본 발명의 실시예의 일 측면에 따른, 3인칭 시점의 복수의 사용자가 협력 설계하는 것을 나타내는 도 면, 도 44는 본 발명의 실시예의 일 측면에 따른, 타이어를 회전/반동시키고 또한 오디오를 생성하는 것과 이미지가, 인터렉트되는 것을 나타내는 도면, 도 45는 본 발명의 실시예의 일 측면에 따른, 사람이 표시되고, 표시 환경과 인터렉트되는 3D 비디오를 나타내 는 도면이다."}
