{"patent_id": "10-2017-0152974", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0056009", "출원번호": "10-2017-0152974", "발명의 명칭": "메트릭 학습 기반의 데이터 분류와 관련된 장치 및 그 방법", "출원인": "삼성전자주식회사", "발명자": "장태권"}}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 인스트럭션이 저장되는 메모리; 및상기 저장된 인스트럭션을 실행하는 프로세서를 포함하되,상기 프로세서는,제1 클래스의 트레이닝 데이터에서 특징 데이터를 추출하고,상기 추출된 특징 데이터를 임베딩 공간에 매핑하여 특징 포인트를 얻으며,상기 얻어진 특징 포인트와 앵커 포인트 간의 거리를 감소시키는 방향으로 인공 신경망을 학습시키되,상기 앵커 포인트는 상기 제1 클래스의 대표 데이터에서 추출된 특징 데이터가 상기 임베딩 공간에 매핑된것인,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 인공 신경망을 학습 시키는 것은,상기 제1 클래스의 트레이닝 데이터의 특징 포인트와 상기 앵커 포인트가 가까울 수록 손실이 적고, 상기 제1클래스와 다른 제2 클래스의 트레이닝 데이터의 특징 포인트와 상기 앵커 포인트는 가까울 수록 손실이 큰 것으로 손실 값을 정의하는 손실 함수(loss function)을 이용하여 상기 인공 신경망을 학습시키는 것을 포함하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 인공 신경망을 학습 시키는 것은,상기 제1 클래스의 트레이닝 데이터의 특징 데이터를 추출하기 위한 CNN(Convolutional Neural Network) 레이어와, 상기 CNN 레이어에서 출력된 데이터를 입력 받아 상기 얻어진 특징 포인트와 상기 앵커 포인트 간의 거리를구하기 위한 메트릭 학습 레이어를 일괄하여 학습시키는 것을 포함하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 인공 신경망을 학습 시키는 것은,상기 제1 클래스의 트레이닝 데이터의 특징 데이터를 추출하기 위한 CNN 레이어에서 출력된 데이터를 입력 받아상기 얻어진 특징 포인트와 상기 앵커 포인트 간의 거리를 구하기 위한 메트릭 학습 레이어 만을 상기 CNN 레이어와 분리하여 학습시키는 것을 포함하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,공개특허 10-2019-0056009-2-상기 인공 신경망은, 상기 임베딩 공간 상에 형성된 클러스터 특징 데이터를 출력하는 메트릭 학습 레이어를 포함하고, 상기 인공 신경망을 학습 시키는 것은,상기 메트릭 학습 레이어로부터 출력된 데이터를 입력 받아 각 클래스 별 컨피던스 레벨을 출력하는 단일 레이어로 구성된 객체 분류 레이어를 학습시키는 것을 포함하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 인공 신경망을 학습 시키는 것은,상기 제1 클래스의 트레이닝 데이터의 특징 포인트가 상기 제1 클래스의 앵커 포인트에 더 가까워지도록 하고,동시에 제2 클래스의 트레이닝 데이터의 특징 포인트가 상기 임베딩 공간 상에서 상기 제2 클래스의 앵커 포인트에 더 가까워지도록 하는 방향으로 상기 인공 신경망을 학습 시키는 것을 포함하고,상기 제1 클래스의 앵커 포인트의 위치 및 상기 제2 클래스의 앵커 포인트의 위치는, 상기 제1 클래스와 상기제2 클래스 사이의 시맨틱(semantic) 관계 정보를 반영하여 결정되는 것을 특징으로 하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 시맨틱 관계 정보는,상기 제1 클래스의 키워드와 상기 제2 클래스의 키워드 사이의 시맨틱 트리에서의 거리를 포함하되,상기 시맨틱 트리는, 각 키워드 간 시맨틱 계층 관계가 반영된 것이고,상기 제1 클래스의 키워드와 상기 제2 클래스의 키워드 사이의 상기 시맨틱 트리에서의 거리는 상기 제1 클래스의 키워드에 대응되는 제1 노드와 상기 제2 클래스의 키워드에 대응되는 제2 노드 사이의 노드의 수가 많을 수록 멀어지도록 세팅 되는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서,상기 인공 신경망을 학습 시키는 것은,상기 제1 클래스와 상기 제2 클래스 사이의 상기 시맨틱 관계 정보를 반영하여, 제1 클래스 클러스터 및 제2 클래스 클러스터 중 적어도 하나의 상기 임베딩 공간 상의 위치를 업데이트 하는 것을 포함하되,상기 제1 클래스 클러스터는 상기 제1 클래스의 특징 포인트 및 상기 제1 클래스의 앵커포인트로 구성된것이고,상기 제2 클래스 클러스터는 상기 제2 클래스의 특징 포인트 및 상기 제2 클래스의 앵커포인트로 구성된 것인,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서,상기 인공 신경망을 학습 시키는 것은,상기 제1 클래스의 특징 포인트를 반영하여 상기 앵커 포인트의 상기 임베딩 공간 상의 위치를 업데이트 하는것과, 상기 제1 클래스의 특징 포인트와 상기 업데이트 된 앵커 포인트 사이의 거리를 감소시키는 방향으로 상공개특허 10-2019-0056009-3-기 인공 신경망을 학습시키는 것을 포함하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서,상기 앵커 포인트의 상기 임베딩 공간 상의 위치를 업데이트 하는 것은,학습 시작 시점부터 제1 횟수의 반복으로 구성되는 초기 학습에서는 상기 앵커 포인트의 위치 업데이트를 수행하지 않고, 상기 초기 학습 이후의 반복에서 상기 앵커 포인트의 위치 업데이트를 수행하는 것을 포함하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 초기 학습 이후의 반복에서 상기 앵커 포인트의 위치 업데이트를 수행하는 것은,상기 초기 학습 이후의 반복에서, 2 이상의 제2 횟수의 반복 마다 한번씩 상기 앵커 포인트의 위치 업데이트를수행하는 것을 포함하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10 항에 있어서,상기 제1 횟수는,상기 트레이닝 데이터의 타입이 제1 타입인 경우 제1 값으로 설정되고, 상기 트레이닝 데이터의 타입이 제2 타입인 경우 제2 값으로 설정되는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "하나 이상의 인스트럭션이 저장되는 메모리; 및상기 저장된 인스트럭션을 실행하는 프로세서를 포함하되,상기 프로세서는,비디오의 현재 프레임에서 추출된 복수의 객체 각각의 특징 데이터를 가리키는 임베딩 공간 상의 특징 포인트들을 제1 결정하고,복수의 클래스의 앵커 포인트들의 상기 임베딩 공간 상의 위치를, 각 클래스 사이의 시맨틱 관계 정보를 반영하여 제2 결정하고,복수의 클래스의 앵커 포인트들의 상기 임베딩 공간 상의 위치를, 각각의 앵커 포인트에 인접한 특징 포인트들의 위치를 반영하여 제1 업데이트 하고,상기 특징 포인트들 각각이, 위치가 업데이트된 상기 앵커 포인트들 중 최근접 앵커 포인트에 더 가까워지도록하는 방향으로 인공 신경망을 학습시키고,각각의 앵커 포인트 및 상기 앵커 포인트에 인접한 특징 포인트들로 구성된 클래스 별 클러스터의 상기 임베딩공간 상의 위치를, 각각의 앵커 포인트가 가리키는 클래스 사이의 시맨틱 관계 정보를 반영하여 제2 업데이트하고,상기 현재 프레임을 다음으로 넘기면서 상기 제1 결정하는 것, 상기 제2 결정하는 것, 상기 제1 업데이트 하는것, 상기 학습시키는 것 및 상기 제2 업데이트 하는 것을 반복하는,전자 장치.공개특허 10-2019-0056009-4-청구항 14 제13 항에 있어서,상기 프로세서는,상기 학습 된 인공 신경망에 의한 상기 클래스 별 클러스터의 형성 결과에 대한 사용자 피드백을 얻고,상기 사용자 피드백을 반영하여 상기 인공 신경망을 더 학습 시키는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "하나 이상의 인스트럭션이 저장되는 메모리; 및상기 저장된 인스트럭션을 실행하는 프로세서를 포함하되,상기 프로세서는,임베딩 공간 상의 특징 포인트에 관련된 데이터를 출력하는 객체 인식 모델을 이용하여, 영상에서 추출된 복수의 객체 각각의 상기 임베딩 공간 상의 특징 포인트들을 얻고,상기 특징 포인트들 중 적어도 일부에 가장 근접 한 앵커 포인트의 키워드를 이용하여 상기 영상의 장면을 이해하되,상기 앵커 포인트는, 각 클래스 별 대표 이미지가 상기 임베딩 공간 상에 매핑된 것이고,상기 임베딩 공간은, 상기 앵커 포인트 사이의 시맨틱(semantic) 관계를 반영하여 상기 앵커 포인트 사이의 거리가 산출되는 특징 공간인,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 영상의 장면을 이해하는 것은,상기 매핑된 특징 포인트들 각각에 가장 근접 한 하위 레벨 앵커 포인트를 선정하고,상기 선정된 하위 레벨 앵커 포인트들 각각에 대응하는 시맨틱 트리의 노드들 중 적어도 일부의 상위 노드를 선정하고, 선정된 상위 노드에 대응되는 키워드를 이용하여 상기 영상의 장면을 이해하는 것을 포함하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15 항에 있어서,상기 영상의 장면을 이해하는 것은,상기 매핑된 특징 포인트들 중 적어도 일부에 가장 근접 한 상위 레벨 앵커 포인트를 선정하고,상기 선정된 상위 레벨 앵커 포인트에 대응하는 키워드를 이용하여 상기 영상의 장면을 이해하는 것을포함하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15 항에 있어서,상기 프로세서는,상기 객체 인식 모델을 상기 영상의 타입에 기반하여 선정하는,공개특허 10-2019-0056009-5-전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15 항에 있어서,상기 프로세서는,상기 객체 인식 모델을 상기 전자 장치의 사용자의 프로필 정보에 기반하여 선정하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15 항에 있어서,상기 프로세서는,상기 객체 인식 모델을 응용 서비스 타입에 기반하여 선정하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제15 항에 있어서,상기 프로세서는,상기 이해된 장면에 대응 되는 추가 컨텐츠를 출력하는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제15 항에 있어서,상기 객체 인식 모델은 각 클래스의 키워드 간 시맨틱 계층 관계를 표현하는 시맨틱 트리를 이용하여 기계학습된 결과로서 생성된 인공 신경망으로 구성되는,전자 장치."}
{"patent_id": "10-2017-0152974", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "전자 장치에 의하여 수행되는 방법에 있어서,임베딩 공간 상의 특징 포인트에 관련된 데이터를 출력하는 객체 인식 모델을 이용하여, 영상에서 추출된 복수의 객체 각각의 상기 임베딩 공간 상의 특징 포인트들을 얻는 단계; 및상기 특징 포인트들 중 적어도 일부에 가장 근접 한 앵커 포인트의 키워드를 이용하여 상기 영상의 장면을 이해하는 단계를 포함하되,상기 앵커 포인트는, 각 클래스 별 대표 이미지가 상기 임베딩 공간 상에 매핑된 것이고,상기 임베딩 공간은, 상기 앵커 포인트 사이의 시맨틱(semantic) 관계를 반영하여 상기 앵커 포인트 사이의 거리가 산출되는 특징 공간인,방법."}
{"patent_id": "10-2017-0152974", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "개선된 분류(classifying) 성능을 제공하는 메트릭 학습(metric learning), 시맨틱 관계를 고려한 객체의 분류 및 그에 기반한 장면의 의미 이해 등 기계학습 기반의 정보 이해 능력을 갖춘 인공지능 기술이 제공된다. 본 발 명의 일 실시예에 따른 전자 장치는 본 발명의 일 실시예에 따른 전자 장치는, 하나 이상의 인스트럭션이 저장되 는 메모리와, 상기 저장된 인스트럭션을 실행하는 프로세서를 포함한다. 이 때, 상기 프로세서는, 제1 클래스의 트레이닝 데이터에서 특징 데이터를 추출하고, 상기 추출된 특징 데이터를 임베딩 공간에 매핑하여 특징 포인트 를 얻으며, 상기 얻어진 특징 포인트와 앵커 포인트 간의 거리를 감소시키는 방향으로 인공 신경망을 학습시킨다."}
{"patent_id": "10-2017-0152974", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝 등의 기계학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인공지능 (AI) 시스템 및 그 응용에 관련된 것으로서, 본 발명은 메트릭 학습 기반의 데이터 분류와 관련된 장치 및 그 방법에 관한 것이다. 보다 자세하게는, 개선된 성능의 메트릭 학습 및 그에 기반한 시맨틱(semantic)이 고려된데이터 분류를 수행하는 것과 관련된 기능을 수행하는 전자 장치 및 그 전자 장치에 의하여 수행되는 방법에 관 한 것이다."}
{"patent_id": "10-2017-0152974", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 Rule 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 Rule 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 딥러닝 등의 기계학습 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조 작 제어(행동 제어) 등을 포함한다. 기계학습의 한 범주에 속하는 메트릭 학습(metric learning)은 입력 데이터셋의 특징 벡터(feature vector)가 투사(project) 또는 매핑(mapping)되는 특징 공간(feature space)에 적용되기에 가장 적합한 형태의 메트릭 (metric)을 학습하는 소프트웨어 기술이다. 상기 메트릭은 거리 함수(distance function)라고도 지칭되고, 이에 따라 상기 메트릭 학습은 거리 메트릭 학습(distance metric learning)이라고도 지칭된다. 메트릭 학습을 위한 트레이닝 데이터셋에는, 각 데이터 쌍 별로 유사/비유사가 정의될 수 있다. 메트릭 학습은 유사한 데이터의 포인트 사이는 더 가까운 거리로 판단하게 하고, 비유사한 데이터의 포인트 사이는 더 먼 거리 로 판단하게 하는 거리 함수를 학습하는 것이다. 거리 함수는 KNN(K-Nearest Neighbors) 알고리즘 등, 입력 데 이터의 특징 포인트 사이 거리를 기준으로 입력 데이터를 분류(classifying)하는 알고리즘들의 성능에 큰 영향 을 미칠 수 있다. 따라서, 분류 성능의 개선을 위하여 메트릭 학습을 통한 최적의 거리 함수를 구하는 것이 중 요하다. 상술한 메트릭 학습은, 서로 다른 데이터를 정확하게 분류하는 것과 관련된다. 한편, 데이터를 이해하기 위하여 는 서로 다른 데이터를 정확하게 분류하는 것뿐만 아니라, 데이터가 가지는 의미(semantics, 이하 '시맨틱'이라 함)를 파악하는 것도 필요하다. 즉, 분석 대상 데이터의 정확한 분류 및 그 데이터의 시맨틱에 대한 파악이 모 두 만족되어야, 데이터를 이해할 수 있을 것이다. 기계학습을 이용하여 데이터의 의미를 파악하기 위하여, 상기 데이터에서 추출된 특징 데이터가 특징 공간 상에 클러스터링 될 때, 각각의 클러스터가 시맨틱 관계를 반영하여 상기 특징 공간 상에 배치되는 것이 중요하다. 그렇지 않다면, 데이터가 같은 클러스터에 속한 것인지, 아닌지 만을 판단할 수 있을 뿐, 데이터의 의미를 이해 하고, 나아가 복수의 데이터들을 종합적으로 판단하여 상황, 의미 등을 이해하는 것은 불가능하다. 이를 위해, 제1 클러스터에 속한 데이터들의 시맨틱과 제2 클러스터에 속한 데이터들의 시맨틱 사이의 유사도에 따라, 상기 특징 공간 상의 제1 클러스터와 제2 클러스터의 상대적 위치가 달라져야 할 것이다. 영상의 장면 이해, 음성 인식을 통한 감정 분석 등, 입력 데이터에 대한 의미론적 이해를 요구하는 인공지능 응 용 서비스를 제공하기 위하여, 지금까지 설명한 개선된 메트릭 학습 방법의 제공 및 데이터의 의미를 반영한 클 러스터링 방법의 제공이 요구된다."}
{"patent_id": "10-2017-0152974", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는, 개선된 성능의 메트릭 학습을 수행하는 전자 장치, 또는 그 방법을 제공하는 것이다. 본 발명이 해결하고자 하는 다른 기술적 과제는, 상기 메트릭 학습의 결과가 반영된 임베딩 공간(embedding space)을 기반으로 하는 개선된 성능의 분류 모델 생성을 위한 기계학습을 수행하는 전자 장치, 또는 그 방법을 제공하는 것이다. 본 발명이 해결하고자 하는 또 다른 기술적 과제는, 비디오의 각 프레임에서 추출된 객체를 트레이닝 데이터로 서 이용하여, 각 객체의 시맨틱 관계 정보가 반영된 메트릭 학습을 수행하는 전자 장치, 또는 그 방법을 제공하 는 것이다. 본 발명이 해결하고자 하는 또 다른 기술적 과제는, 인공지능 알고리듬을 이용한 기계학습의 결과로 기 생성된 객체 인식 모델을 이용하여 영상에 포함된 각 객체의 시맨틱을 식별하고, 각 객체의 시맨틱 관계를 이용하여 영 상의 장면을 이해하는 전자 장치, 또는 그 방법을 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적"}
{"patent_id": "10-2017-0152974", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "과제들은 아래의 기재로부터 본 발명의 기술분야에서의 통상의 기술자에게 명확하게 이해 될 수 있을 것이다."}
{"patent_id": "10-2017-0152974", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술된 문제점들을 해결하기 위한 본 발명의 일 실시예에 따른 전자 장치는, 하나 이상의 인스트럭션이 저 장되는 메모리와, 상기 저장된 인스트럭션을 실행하는 프로세서를 포함한다. 이 때, 상기 프로세서는, 제1 클래 스의 트레이닝 데이터에서 특징 데이터를 추출하고, 상기 추출된 특징 데이터를 임베딩 공간에 매핑하여 특징 포인트를 얻으며, 상기 얻어진 특징 포인트와 앵커 포인트 간의 거리를 감소시키는 방향으로 인공 신경망을 학 습시킨다. 이 때, 상기 앵커 포인트는 상기 제1 클래스의 대표 데이터에서 추출된 특징 데이터가 상기 임베딩 공간에 매핑된 것이다. 일 실시예에서, 상기 인공 신경망을 학습 시키는 것은, 상기 제1 클래스의 트레이닝 데이터의 특징 포인트와 상 기 앵커 포인트가 가까울 수록 손실이 적고, 상기 제1 클래스와 다른 제2 클래스의 트레이닝 데이터의 특징 포 인트와 상기 앵커 포인트는 가까울 수록 손실이 큰 것으로 손실 값을 정의하는 손실 함수(loss function)을 이 용하여 상기 인공 신경망을 학습시키는 것을 포함한다. 일 실시예에서, 상기 인공 신경망을 학습 시키는 것은, 상기 제1 클래스의 트레이닝 데이터의 특징 데이터를 추 출하기 위한 CNN(Convolutional Neural Network) 레이어와, 상기 CNN 레이어에서 출력된 데이터를 입력 받아 상기 얻어진 특징 포인트와 상기 앵커 포인트 간의 거리를 구하기 위한 메트릭 학습 레이어를 일괄하여 학습시 키는 것을 포함한다. 일 실시예에서, 상기 인공 신경망을 학습 시키는 것은, 상기 제1 클래스의 트레이닝 데이터의 특징 데이터를 추 출하기 위한 CNN 레이어에서 출력된 데이터를 입력 받아 상기 얻어진 특징 포인트와 상기 앵커 포인트 간의 거 리를 구하기 위한 메트릭 학습 레이어 만을 상기 CNN 레이어와 분리하여 학습시키는 것을 포함한다. 일 실시예에서, 상기 인공 신경망은, 상기 임베딩 공간 상에 형성된 클러스터 특징 데이터를 출력하는 메트릭 학습 레이어를 포함한다. 이 때, 상기 인공 신경망을 학습 시키는 것은 상기 메트릭 학습 레이어로부터 출력된 데이터를 입력 받아 각 클래스 별 컨피던스 레벨을 출력하는 단일 레이어로 구성된 객체 분류 레이어를 학습시 키는 것을 포함한다. 일 실시예에서, 상기 인공 신경망을 학습 시키는 것은, 상기 제1 클래스의 트레이닝 데이터의 특징 포인트가 상 기 제1 클래스의 앵커 포인트에 더 가까워지도록 하고, 동시에 제2 클래스의 트레이닝 데이터의 특징 포인트가, 상기 임베딩 공간 상에서 상기 제2 클래스의 앵커 포인트에 더 가까워지도록 하는 방향으로 학습 시키는 것을 포함한다. 이 때, 상기 제1 클래스의 앵커 포인트의 위치 및 상기 제2 클래스의 앵커 포인트의 위치는, 상기 제 1 클래스와 상기 제2 클래스 사이의 시맨틱(semantic) 관계 정보를 반영하여 결정되는 것을 특징으로 한다. 또 한, 상기 시맨틱 관계 정보는, 상기 제1 클래스의 키워드와 상기 제2 클래스의 키워드 사이의 시맨틱 트리에서 의 거리를 포함하되, 상기 시맨틱 트리는, 각 키워드 간 시맨틱 계층 관계가 반영된 것이고, 상기 제1 클래스의 키워드와 상기 제2 클래스의 키워드 사이의 상기 시맨틱 트리에서의 거리는 상기 제1 클래스의 키워드에 대응되 는 제1 노드와 상기 제2 클래스의 키워드에 대응되는 제2 노드 사이의 노드의 수가 많을 수록 멀어지도록 세팅 될 수 있다. 또한, 상기 인공 신경망을 학습 시키는 것은, 상기 제1 클래스와 상기 제2 클래스 사이의 상기 시 맨틱 관계 정보를 반영하여, 제1 클래스 클러스터 및 제2 클래스 클러스터 중 적어도 하나의 상기 임베딩 공간상의 위치를 업데이트 하는 것을 포함할 수 있다. 이 때, 상기 제1 클래스 클러스터는 상기 제1 클래스의 특징 포인트 및 상기 제1 클래스의 앵커포인트로 구성된 것이고, 상기 제2 클래스 클러스터는 상기 제2 클래스의 특 징 포인트 및 상기 제2 클래스의 앵커포인트로 구성된 것일 수 있다. 일 실시예에서, 상기 인공 신경망을 학습 시키는 것은, 상기 제1 클래스의 특징 포인트를 반영하여, 상기 앵커 포인트의 상기 임베딩 공간 상의 위치를 업데이트 하는 것과, 상기 제1 클래스의 특징 포인트와, 상기 업데이트 된 앵커 포인트 사이의 거리를 감소시키는 방향으로 상기 인공 신경망을 학습시키는 것을 포함할 수 있다. 이 때, 상기 앵커 포인트의 상기 임베딩 공간 상의 위치를 업데이트 하는 것은, 학습 시작 시점부터 제1 횟수의 반 복으로 구성되는 초기 학습에서는 상기 앵커 포인트의 위치 업데이트를 수행하지 않고, 상기 초기 학습 이후의 반복에서 상기 앵커 포인트의 위치 업데이트를 수행하는 것을 포함할 수 있다. 이 때, 상기 초기 학습 이후의 반복에서 상기 앵커 포인트의 위치 업데이트를 수행하는 것은, 상기 초기 학습 이후의 반복에서, 2 이상의 제2 횟수의 반복 마다 한번씩 상기 앵커 포인트의 위치 업데이트를 수행하는 것을 포함할 수 있다. 또한, 상기 제1 횟수는, 상기 트레이닝 데이터의 타입이 제1 타입인 경우 제1 값으로 설정되고, 상기 트레이닝 데이터의 타입이 제2 타입인 경우 제2 값으로 설정될 수 있다. 상기 기술된 문제점들을 해결하기 위한 본 발명의 다른 실시예에 따른 전자 장치는, 하나 이상의 인스트럭션이 저장되는 메모리와, 상기 저장된 인스트럭션을 실행하는 프로세서를 포함한다. 이 때, 상기 프로세서는, 비디오 의 현재 프레임에서 추출된 복수의 객체 각각의 특징 데이터를 가리키는 임베딩 공간 상의 특징 포인트들을 제1 결정하고, 복수의 클래스의 앵커 포인트들의 상기 임베딩 공간 상의 위치를, 각 클래스 사이의 시맨틱 관계 정 보를 반영하여 제2 결정하고, 복수의 클래스의 앵커 포인트들의 상기 임베딩 공간 상의 위치를, 각각의 앵커 포 인트에 인접한 특징 포인트들의 위치를 반영하여 제1 업데이트 하고, 상기 특징 포인트들 각각이, 상기 위치가 업데이트된 상기 앵커 포인트들 중 최근접 앵커 포인트에 더 가까워지도록 하는 방향으로 인공 신경망을 학습시 키고, 각각의 앵커 포인트 및 상기 앵커 포인트에 인접한 특징 포인트들로 구성된 클래스 별 클러스터의 상기 임베딩 공간 상의 위치를, 각각의 앵커 포인트가 가리키는 클래스 사이의 시맨틱 관계 정보를 반영하여 제2 업 데이트 하고, 상기 현재 프레임을 다음으로 넘기면서 상기 제1 결정하는 것, 상기 제2 결정하는 것, 상기 제1 업데이트 하는 것, 상기 학습시키는 것 및 상기 제2 업데이트 하는 것을 반복할 수 있다. 일 실시예에서, 상기 프로세서는, 상기 학습 된 인공 신경망에 의한 상기 클래스 별 클러스터의 형성 결과에 대 한 사용자 피드백을 얻고, 상기 사용자 피드백을 반영하여 상기 인공 신경망을 더 학습시킬 수 있다.. 상기 기술된 문제점들을 해결하기 위한 본 발명의 또 다른 실시예에 따른 전자 장치는, 하나 이상의 인스트럭션 이 저장되는 메모리와, 상기 저장된 인스트럭션을 실행하는 프로세서를 포함한다. 상기 프로세서는, 임베딩 공 간 상의 특징 포인트에 관련된 데이터를 출력하는 객체 인식 모델을 이용하여, 영상에서 추출된 복수의 객체 각 각의 상기 임베딩 공간 상의 특징 포인트들을 얻고, 상기 특징 포인트들 중 적어도 일부에 가장 근접 한 앵커 포인트의 키워드를 이용하여 상기 영상의 장면을 이해한다. 이 때, 상기 앵커 포인트는, 각 클래스 별 대표 이 미지가 상기 임베딩 공간 상에 매핑된 것이고, 상기 임베딩 공간은, 상기 앵커 포인트 사이의 시맨틱(semantic) 관계를 반영하여 상기 앵커 포인트 사이의 거리가 산출되는 특징 공간일 수 있다. 일 실시예에서, 상기 영상의 장면을 이해하는 것은, 상기 매핑된 특징 포인트들 각각에 가장 근접 한 하위 레벨 앵커 포인트를 선정하고, 상기 선정된 하위 레벨 앵커 포인트들 각각에 대응하는 시맨틱 트리의 노드들 중, 적 어도 일부의 상위 노드를 선정하고, 선정된 상위 노드에 대응되는 키워드를 이용하여 상기 영상의 장면을 이해 하는 것을 포함할 수 있다. 일 실시예에서, 상기 영상의 장면을 이해하는 것은, 상기 매핑된 특징 포인트들 중 적어도 일부에 가장 근접 한 상위 레벨 앵커 포인트를 선정하고, 상기 선정된 상위 레벨 앵커 포인트에 대응하는 키워드를 이용하여 상기 영 상의 장면을 이해하는 것을 포함할 수 있다. 일 실시예에서, 상기 프로세서는, 상기 객체 인식 모델을 상기 영상의 타입에 기반하여 선정할 수 있다. 일 실시예에서, 상기 프로세서는, 상기 객체 인식 모델을 상기 전자 장치의 사용자의 프로필 정보에 기반하여 선정할 수 있다. 일 실시예에서, 상기 프로세서는, 상기 객체 인식 모델을 응용 서비스 타입에 기반하여 선정할 수 있다. 일 실시예에서, 상기 프로세서는, 상기 이해된 장면에 대응 되는 추가 컨텐츠를 출력할 수 있다. 일 실시예에서, 상기 객체 인식 모델은 각 클래스의 키워드 간 시맨틱 계층 관계를 표현하는 시맨틱 트리를 이 용하여 기계학습 된 결과로서 생성된 인공 신경망으로 구성되는 것일 수 있다. 상기 기술된 문제점들을 해결하기 위한 본 발명의 또 다른 실시예에 따른 전자 장치에 의하여 수행되는 방법은, 임베딩 공간 상의 특징 포인트에 관련된 데이터를 출력하는 객체 인식 모델을 이용하여, 영상에서 추출된 복수 의 객체 각각의 상기 임베딩 공간 상의 특징 포인트들을 얻는 단계와, 상기 특징 포인트들 중 적어도 일부에 가 장 근접 한 앵커 포인트의 키워드를 이용하여 상기 영상의 장면을 이해하는 단계를 포함한다. 상기 앵커 포인트 는, 각 클래스 별 대표 이미지가 상기 임베딩 공간 상에 매핑된 것이고, 상기 임베딩 공간은, 상기 앵커 포인트 사이의 시맨틱 관계를 반영하여 상기 앵커 포인트 사이의 거리가 산출되는 특징 공간일 수 있다."}
{"patent_id": "10-2017-0152974", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예들을 상세히 설명한다. 본 발명의 이점 및 특징, 그리 고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것 이다. 그러나 본 발명은 이하에서 게시되는 실시 예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될"}
{"patent_id": "10-2017-0152974", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수 있으며, 단지 본 실시 예들은 본 발명의 게시가 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지 식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정 의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해 석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것 은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 이하, 도면들을 참 조하여 본 발명의 몇몇 실시예들을 설명한다. 도 1을 참조하여 본 발명의 일 실시예에 따른 장면 이해 기반 서비스 시스템의 구성 및 동작을 설명한다. 본 실 시예에 따른 시스템은 객체 인식 모델 학습 장치 및 전자 장치(100a, 100b, 100c)를 포함할 수 있다. 전자 장치(100a, 100b, 100c)는 사용자에 의하여 사용되는 사용자 단말로서, 예를 들어, 스마트폰, 스마트워치 등의 웨어러블 디바이스, 태블릿, 데스크톱, 노트북, 디지털 TV, 디지털 사이니지, 키오스크 등의 연산 프로세서가 구비된 컴퓨팅 장치 또는 컴퓨팅 수단이 구비된 디지털 장치 등의 전자 장치일 수 있다. 객체 인식 모델 학습 장치는 기계학습을 수행하여 영상의 객체를 인식하는 모델을 생성하고, 그 결과로 만 들어진 객체 인식 모델 관련 데이터를 전자 장치(100a, 100b, 100c)에 제공한다. 전자 장치(100a, 100b, 100c)는 객체 인식 모델 관련 데이터를 이용하여 동영상의 각 프레임 또는 이미지에 포함된 하나 이상의 객 체를 인식하고, 그 결과를 바탕으로 장면(scene)을 이해한다. 객체를 인식한다는 것은, 이미지에 포함된 객체 영역, 즉 ROI(Region Of Interest)가 표현하는 주제를 기 지정 된 키워드들 중 하나로 결정하는 것을 의미한다. 즉, 객체의 인식은, 객체 영역을 추출하고, 추출된 객체 영역 의 이미지를 분류기(classifier)에 입력하여 어떤 주제의 이미지인지 선정하는 것을 포함한다. 장면을 이해한다는 것은, 현재 표시 화면에 포함된 객체들의 인식 결과를 이용하여, 현재 표시 화면이 표현하는 전체적인 의미 또는 상황을 결정하는 것을 의미한다. 예를 들어, 현재 표시 화면에서 '도마', '칼' 및 '생선'의 3개 객체가 인식된 경우, 현재 표시 화면의 장면 이해 결과는 '요리'가 될 수 있을 것이다. 이처럼, 장면의 이 해를 위하여는 시맨틱 계층 관계가 고려될 필요가 있다. 본 발명의 몇몇 실시예에 따른 장면 이해 방법에 대하 여는 후술한다. 일 실시예에서, 전자 장치(100a, 100b, 100c)는 객체 인식 모델 관련 데이터 중 적어도 일부를 이용하여 각 객체의 시맨틱 관계 정보(미도시)가 반영된 거리 함수에 대한 데이터를 생성하고, 객체 이미지의 특징 포인트의 임베딩 공간 상의 위치를 기준으로 객체를 인식할 수 있다. 상기 임베딩 공간은 상기 거리 함수에 의하여 포인 트 간 거리가 산출되는 공간이다. 본 실시예에 따른 시스템은 서비스 서버를 더 포함할 수 있다. 서비스 서버는 전자 장치(100a, 100b, 100c)에 서버/클라이언트 모델 기반의 온라인 서비스를 제공하는 전자 장치이다. 전자 장치(100a, 100b, 100c) 가 장면의 이해 결과를 나타내는 데이터를 서비스 서버에 제공하여, 서비스 서버로부터 장면 반영 서비스를 제공 받을 수 있다. 장면 반영 서비스는, 전자 장치(100a, 100b, 100c)에 표시된 특정 장면에 대응되는 추가 컨텐츠를 제공하는 것을 포함할 수 있다. 예를 들어, 상기 추가 컨텐츠는 장면 맞춤형 광고, 장면 대응 텍스트를 이용한 검색 결과, 장면 맞춤형 미디어일 수 있다. 한편, 일 실시예에서, 전자 장치(100a, 100b, 100c)는 상기 객체 인식 모델에 대하여 점진 학습(incremental learning)을 수행함으로써, 그 성능을 개선시킬 수 있다. 상기 점진 학습은, 객체 인식 모델에 대한 사용자 피 드백을 제공 받고, 상기 피드백을 반영하여 상기 객체 인식 모델을 다시 학습 하는 것으로 이해 될 수 있을 것 이다. 이러한 점진 학습과 관련하여 자세한 설명은 후술한다. 다음으로, 도 2를 참조하여, 본 발명의 다른 실시예에 따른 전자 장치의 구성 및 동작을 설명한다. 본 실시 예에 따른 전자 장치는 기계학습을 수행하여 분류 등의 판단을 수행하는 장치인 바, 높은 수준의 컴퓨팅 성능이 요구된다. 따라서, 본 실시예에 따른 전자 장치는, 예를 들어 도 1의 객체 인식 모델 학습 장치와 같은 서버 장 치일 수 있다. 다만, 본 실시예에 따른 전자 장치가 반드시 서버 장치에 한정되는 것은 아니다. 사용자 단말 장 치 역시 이하 상술하는 구성을 만족시키고, 동일한 동작을 수행하는 것은 본 실시예에 따른 전자 장치가 될 수 있음을 유의한다. 도 2에 도시된 바와 같이, 본 실시예에 따른 전자 장치는 프로세서 및 프로세서에서 수행되는 메 트릭 생성 프로그램(130b)을 저장하는 메모리를 포함한다. 프로세서는 하나 이상의 중앙 처리 장치 (CPU; Central Processing Unit) 및 하나 이상의 그래픽 처리 장치(GPU; Graphics Processing Unit) 중 적어도하나를 이용하여 구성될 수 있다. 일 실시예에서, 전자 장치는 스토리지, 네트워크를 통하여 외부 장치와의 데이터 송수신을 중개하는 네트워크 인터페이스 및 시스템 버스 중 적어도 하나를 더 포함할 수 있다. 시스템 버스는 프로 세서, 메모리, 스토리지 및 네트워크 인터페이스 사이의 데이터 송수신 통로 역할을 수행 한다. 메모리는, 예를 들어 RAM(Random Access Memory)와 같은 휘발성 데이터 저장장치일 수 있다. 스토리 지는 플래시 메모리와 같은 비휘발성 메모리, 하드디스크 등의 데이터 저장 장치일 수 있다. 스토리지는 시맨틱 트리 및 클래스 별 대표 데이터를 저장할 수 있다. 시맨틱 트리의 각 노드는 키워드와 일대일 대응되고, 각 노드는 키워드 사이의 계층적인 연결관계에 따라 서로 부모/자식 관계로 연결된다. 각 노드의 키워드는, 트레이닝 데이터셋의 클래스에 일대일 대응되는 것일 수 있다. 시맨틱 트리 의 구체적인 예시는 도 6 등을 참조하여 후술한다. 클래스 별 대표 데이터는 트레이닝 데이터셋의 각 클래스의 대표 데이터이다. 예를 들어, 상기 트레이닝 데이터셋이 객체 인식을 위한 이미지 셋인 경우, 클래스 '독수리'의 대표 데이터는, 독수리가 표현된 대표 이미 지를 가리키는 것이다. 또한, 클래스 '독수리'의 대표 데이터에서 추출된 특징 데이터가 임베딩 공간에 매핑 되 면, '독수리' 클래스의 앵커 포인트가 된다. 다른 예로, 트레이닝 데이터셋이 음성 인식을 위한 보이스(voice) 셋인 경우, 클래스 '독수리'의 대표 데이터는, 독수리를 발음한 대표 보이스를 가리키는 것이다. 또한, 클래스 '독수리'의 대표 보이스 사운드에서 추출된 특징 데이터가 임베딩 공간에 매핑 되면, '독수리' 클래스의 앵커 포인트가 된다. 일 실시예에서, 메트릭 생성을 위한 기계학습 진행 시, 클래스 별 대표 데이터가 별도로 제공될 수 있다. 이 경 우에는 제공된 대표 데이터를 이용하여 기계학습을 진행하고, 제공된 대표 데이터가 없는 경우, 스토리지 에 저장된 클래스 별 대표 데이터가 디폴트 데이터로서 사용될 수 있다. 스토리지는 메트릭 생성 프로그램(130a)을 더 저장할 수 있다. 메트릭 생성 프로그램(130a)은 실행 가능 바이너리 파일(미도시)을 포함할 수 있고, 상기 실행 가능 바이너리 파일은 메트릭 생성 프로그램(130a)과 함께 메모리에 로드 된다. 도 2에는 메모리에 저장된 메트릭 생성 프로그램(130b)이 도시되어 있다. 메트 릭 생성 프로그램(130b)이 실행 될 때, 시맨틱 트리가 수시로 참조될 수 있다. 따라서, 실행 속도 향상을 위해, 시맨틱 트리도 메모리로 로드 되어 저장될 수 있다. 스토리지는 ML(Machine Learning) 파라미터 셋도 저장할 수 있다. ML 파라미터 셋은 기계학 습의 결과 생성된 분류 모델(classifying model)을 정의하는 데이터로서, 상기 분류 모델이 인공 신경망(neural network) 기반의 모델인 경우 상기 인공 신경망을 정의하기 위한 파라미터 셋(parameter set)일 수 있다. 전자 장치는 메트릭 생성 프로그램(130b)에 포함된 메트릭 학습 인스트럭션, 시맨틱 트리 인터페이스 인스트럭션, 분류 학습 인스트럭션 및 모델 생성 인스트럭션 중 적어도 하나를 프로세서 를 통해 실행함으로써, 거리 함수를 결정하기 위한 메트릭 학습을 수행하거나, 거리 함수를 결정하고 그 거리 함수가 반영된 임베딩 공간 기반의 분류 모델을 생성하기 위한 기계학습을 수행할 수 있다. 이하, 전자 장 치에 의하여 수행될 수 있는 상기 기계학습 관련 동작에 대하여 설명한다. 본 명세서에서 인스트럭션(instruction)은 기능을 기준으로 묶인 일련의 명령어들로서 프로세서에서 실행되는 것을 가리킨다. 먼저, 전자 장치에 의하여 실행될 수 있는 개선된 성능의 메트릭 학습에 대하여 설명한다. 도 3은 종래 기술에 따른 메트릭 학습을 설명하기 위한 도면이다. 도 3에는 특징 공간에 매핑 된 2가지 클 래스의 특징 포인트들이 도시 되어 있다. 제1 클래스는 사각형으로, 제2 클래스는 원형으로 각각 그 포인트가 표시되어 있다. 특징 공간에서 각 포인트들 사이의 거리(distance)는 i) 유클리디안 거리(Euclidean distance), 또는 ii) 마하라노비스 거리(Mahalanobis Distance) 등 널리 알려진 범용 거리 함수를 이용하여 측 정 될 것이다. 그런데, 상기 범용 거리 함수가 트레이닝 데이터 간의 유사/비유사를 적절하게 표현하지 못하는 경우가 많다. 상기 범용 거리 함수는, 말그대로 여러가지 상황에 일반적으로 쓸 수 있는 거리 함수이고, 학습 대상 트레이닝 데이터셋에 포함된 트레이닝 데이터에 최적화 된 것은 아니기 때문이다. 이를 반영하듯, 도 3의 특징 공간에는 제1 클래스의 특징 포인트와 제2 클래스의 특징 포인트가 일부 혼재 되어 있는 것이 도시되어 있 다. 이러한 경우, 클러스터링이 명확하게 이뤄지지 않고, 결과적으로 분류 모델의 정확도가 떨어지고, 복잡도가 올라갈 수 있다.이러한 문제를 해결하기 위해, 종래 기술에 따른 메트릭 학습을 수행하면 학습 대상 트레이닝 데이터셋에 최적 화된 거리 함수가 구해진다. 그리고, 이러한 거리 함수에 따라 거리 측정이 이뤄지는 특징 공간이 구성될 것이다. 메트릭 학습에 의하여 생성된 거리 함수에 따라 거리 측정이 이뤄지는 특징 공간을 임베딩 공간으로 지 칭한다. 도 3에 도시된 바와 같이, 임베딩 공간에서 제1 클래스의 특징 포인트들 사이의 거리는 특징 공간 상의 제1 클래스의 특징 포인트들 사이의 거리에 비하여 더 짧다. 또한, 임베딩 공간에서 제2 클래스의 특징 포 인트들 사이의 거리는 특징 공간 상의 제2 클래스의 특징 포인트들 사이의 거리에 비하여 더 짧다. 이렇게 동일한 클래스의 특징 포인트들 사이의 거리가 더 가까워짐에 따라 제1 클래스의 클러스터와 제2 클래스의 클러스터는 더 명확하게 분리되고, 그에 따라 분류 모델의 정확도가 향상되고, 연산에 소요되는 컴퓨팅 부 하도 감소된다. 하지만, 종래 기술에 따른 메트릭 학습의 경우, 높은 정확도의 거리 함수를 구하기 위하여, 다수의 트레이닝 데 이터가 학습되어야 한다. 이러한 종래 기술의 메트릭 학습의 문제점은 도 4를 참조하여 후술될 개선된 성능의 메트릭 학습에 의하여 해결된다. 또한, 메트릭 학습의 결과로 생성된 거리 함수는 클래스 간 유사/비유사 만을 반영하고, 유사/비유사의 정도는 고려하지 못하며, 더욱이 클래스의 시맨틱 또한 고려하지 못한다. 이러한 종래 기술의 메트릭 학습의 문제점은 도 6 내지 도 11을 참조하여 후술될 개선된 성능의 메트릭 학습에 의하여 해결된다. 도 4를 참조하여, 본 발명의 몇몇 실시예들에 따른 전자 장치 또는 방법에 적용되는 개선된 성능의 메트릭 학습 을 설명한다. 단순히 유사한 특징 포인트들끼리 더 가까워지도록 하는 거리 함수를 생성하는 종래 기술에 따른 메트릭 학습과 달리, 본 발명의 몇몇 실시예들에 따른 개선된 성능의 메트릭 학습은 트레이닝 데이터의 특징 포인트가 앵커 포 인트에 더 가까워지도록 하는 거리 함수를 생성한다. 이를 위해, 상기 메트릭 학습에 적용되는 손실 함수(loss function)는 예를 들어, 제1 클래스의 트레이닝 데이터의 특징 포인트와 상기 앵커 포인트는 가까울 수록 손실 이 적고, 상기 제1 클래스와 다른 제2 클래스의 트레이닝 데이터의 특징 포인트와 상기 앵커 포인트는 가까울 수록 손실이 큰 것으로 손실 값을 정의하는 것으로 세팅 될 수 있다. 도 4에 도시된 바와 같이, 각 클래스의 앵커 포인트(71a, 72a)는 트레이닝 데이터 중 어느 하나가 아니라, 별도 의 대표 데이터(71c, 72c)에서 추출된 특징 데이터가 매핑된 것일 수 있다. 이미 설명한 바와 같이, 대표 데이 터(71c, 72c)는 메트릭 학습 시작 시점에 입력 된 데이터일 수 있다. 또한, 앵커 포인트(71a, 72a)가 시맨틱 트 리의 특정 노드(특정 클래스에 대응되는)에 대응되는 것이라면, 대표 데이터(71c, 72c)가 입력되지 않더라도 클 래스 별 대표 데이터가 기본 적용될 수도 있다. 본 실시예에 따른 개선된 성능의 메트릭 학습은, 종래 기술 대비 더 적은 개수의 트레이닝 데이터만으로도 각 클래스의 클러스터가 충분히 집중되어 분포되도록 하는 거리 함수가 생성되는 효과를 가진다. 특징 공간을 대상으로 본 실시예에 따른 메트릭 학습이 적용되면, 임베딩 공간을 구성하는 거리 함수 (미도시)가 생성될 것이다. 도 4에는 상기 생성된 거리 함수의 영향으로, 제1 클래스의 특징 포인트들이 제1 클 래스의 앵커 포인트(71b) 쪽으로 가까워지고, 동시에 제2 클래스의 특징 포인트들이 제2 클래스의 앵커 포인트 (72b) 쪽으로 가까워진 것이 도시되어 있다. 이처럼 각 클래스의 특징 포인트들의 위치가 메트릭 학습 이전 대 비 더 밀집되게 업데이트 됨에 따라, 각 클래스의 클러스터(71d, 72d)의 영역도 임베딩 공간 상에서 더 좁 게 형성된다. 이에 따라, 각 클래스의 클러스터(71d, 72d)는 종래 기술에 따른 메트릭 학습 결과 대비 더 명확 하게 분리되고, 그에 따라 분류 모델의 정확도가 향상되고, 연산에 소요되는 컴퓨팅 부하도 감소된다. 도 5는 도 4를 참조하여 설명한 개선된 성능의 메트릭 학습의 성능을, 종래 기술에 따른 분류 알고리즘과 비교 하여 설명하기 위한 도면이다. SVM(Support Vector Machine) 등 널리 알려진 분류 알고리즘은, 특징 공간 상의 각 클래스 별 분류 기준선을 생성한다. 이러한 분류 기준선은 비선형일 수도 있다. 그러나, 도 5에 기 재된 바와 같이, 각 클래스 별 클러스터링이 잘 이뤄지지 않아 분류 기준선이 높은 차원의 함수를 요구하는 경우, 그 분류 모델은 높은 컴퓨팅 부하를 요할 것이다. 반면에, 도 4를 참조하여 설명한 메트릭 학습의 결과를 이용하여 분류 모델을 학습한다면, 요구 되는 컴퓨팅 부 하가 현저히 감소한다. 도 5에 도시된 것과 같이, 각 클래스의 앵커 포인트(73, 74, 75)를 기준으로 특징 포인 트들이 고도로 밀집되게 클러스터링 되어 있어서, 분류 기준선의 복잡도가 종래 기술 대비 완화되었기 때문이다. 한편, 본 발명의 몇몇 실시예들에 다른 메트릭 학습에서, 상기 앵커 포인트의 위치는 앵커 포인트에 대응되는 클래스 간의 시맨틱 관계를 고려하여 결정된다. 이하, 관련 하여 도 6 내지 도 10을 참조하여 설명한다. 도 6에 도시된, Falcon 노드(76c)의 앵커 포인트(76a)와 Swan 노드(74c)의 앵커 포인트(76a) 사이의 특징 공간 상의 거리보다, 도 7에 도시된 Falcon 노드(76c)의 앵커 포인트(76a)와 Poodle 노드(73c)의 앵커 포인트 (73b) 사이의 특징 공간 상의 거리가 더 길다. 이는, Falcon 클래스와 Swan 클래스 간의 시맨틱 관계가, Falcon 클래스와 Poodle 클래스 간의 시맨틱 관계보다 가깝기 때문이다. 다시 말하면, 시맨틱 트리 상, Falcon 노드(76c)와 Swan 노드(74c) 간의 거리가, Falcon 노드(76c)와 Poodle 노드(73c) 간의 거리보다 가깝기 때문이 다. 일 실시예에서, 시맨틱 트리 상에서 두개의 노드 사이의 거리는, 두개의 노드 사이의 노드의 수 또는 에지의 수 가 많을 수록 멀어지도록 세팅 될 수 있다. 예를 들어, 상기 거리가 노드 사이의 에지의 수로 세팅 된다면, Falcon 노드(76c)와 Swan 노드(74c) 간의 거리는 2(Falcon-Bird 간 에지, Bird-Swan 간 에지)이고, Falcon 노 드(76c)와 Poodle 노드(73c) 간의 거리는 4(Falcon-Bird 간 에지, Bird-Animal 간 에지, Animal-Dog 간 에지, Dog-Poodle 간 에지)가 된다. 도 6에서 Falcon 앵커 포인트(76b)로 인접 특징 포인트들이 가까워져서 Falcon 클러스터(76d)가 형성되고, Swan 앵커 포인트(74b)로 인접 특징 포인트들이 가까워져서 Swan 클러스터(74d)가 형성된다. 이처럼, 앵커 포인트는 클러스터의 응집도를 높이는 기준점이 된다. 따라서, 앵커 포인트가 서로 적당히 이격 되는 것이 분류 성능의 향상을 위하여 중요하다. 본 실시예는, 각 앵커 포인트의 위치를 시맨틱 관계를 고려하여 결정하므로, 앵커 포 인트가 서로 적당히 이격 되도록 유도한다. 도 7에서 Falcon 앵커 포인트(76b)로 인접 특징 포인트들이 가까워져서 Falcon 클러스터(76d)가 형성되고, Poodle 앵커 포인트(73b)로 인접 특징 포인트들이 가까워져서 Poodle 클러스터(73d)가 형성된다. Poodle 클러스 터(73d)의 위치는, 도 6의 Swan 클러스터(74b)의 위치보다, Falcon 클러스터(76d)로부터 더 멀다. 그리고, Poodle 클래스의 특징 포인트들은, 본 실시예에 따른 메트릭 학습을 수행하기 전보다 Falcon 클러스터(76d)로부 터 더 멀어진 것을 확인할 수 있다. 이는, Falcon과 Poodle의 시맨틱 관계가 반영된 것이다. 또한, Falcon 클래 스의 앵커 포인트(76b)와 Poodle 클래스의 앵커 포인트(73b)가 먼저 시맨틱 관계를 반영한 클러스터 기준점의 역할을 수행함으로써, Falcon 클러스터(76d) 및 Poodle 클러스터(73d)의 위치 또한 시맨틱 트리 상의 관계를 반 영하게 되는 점을 이해할 수 있을 것이다. 도 6 및 도 7에는 각각 2개씩의 앵커 포인트만 도시 되어 있으나, 학습되는 트레이닝 데이터의 클래스 개수만큼 의 앵커 포인트가 특징 공간에 배치될 것이고, 모든 앵커 포인트 쌍 사이의 거리가 시맨틱 관계를 만족하도 록 앵커 포인트의 위치가 결정될 것이다. 즉, 클래스의 개수가 늘어날 수록, 각 앵커 포인트의 위치는 시맨틱 트리의 각 대응 노드 사이의 거리를 더 정확하게 반영하게 된다. 그 결과, 도 8에 도시된 것과 같이, 3개 이상의 앵커 포인트들이 반영되어 학습된 거리 함수를 얻고, 상기 거리 함수가 반영된 임베딩 공간 상에 시맨틱 트리의 하위 노드들의 클러스터 영역을 포함하는 상위 노드의 클러 스터 영역이 형성될 수도 있을 것이다. 이러한 점을 이용하여 분석 대상 데이터에서 복수의 특징 데이터가 추출 될 수 있다면, 각 특징 데이터가 가리키는 시맨틱 트리 상 하위 노드를 식별하고, 식별된 하위 노드들이 소속된 상위 노드를 식별하는 등의 방식으로, 상기 분석 대상 데이터의 시맨틱을 고려한 계층적 이해가 가능할 것이다. 이에 대하여는 도 16을 참조하여 후술한다. 일 실시예에서, 상기 메트릭 학습 과정에서 앵커 포인트의 위치가 업데이트 될 수도 있다. 이와 관련하여 도 9 내지 도 11을 참조하여 설명한다. 기계학습의 하나인 메트릭 학습 역시 각각의 트레이닝 데이터를 신경망에 입력하고, 신경망에서 출력된 데이터 에 대하여 손실 함수를 이용하여 평가하고, 그 결과를 이용하여 상기 신경망의 가중치를 조정하는 하는 동작을 전체 트레이닝 데이터셋에 대하여 반복(iteration) 한다. 거리 함수가 존재하지 않는 상태에서는, 단순 특징 공간 상에 앵커 포인트가 매핑된다. 따라서, 이 때에는 현재 임베딩 공간은 특징 공간이 된다. 다만, 거리 함수가 구해지고, 구해진 거리 함수가 반영된 임베딩 공간이 형성 되면, 그 형성된 임베딩 공간으로 현지 임베딩 공간이 업데이트 된다. 도 9에는 현재 임베딩 공간에 Falcon 클래스의 앵커 포인트(76a) 및 Poodle 클래스의 앵커 포인트(73a)가 매핑된 후, 앵커 업데이트 프로세스에 따라 Falcon 클래스의 앵커 포인트가 Falcon 클래스의 트레이닝 데이터의 특징 포인트들의 위치를 반영하여 업데이트(76a') 되고, Poodle 클래스의 앵커 포인트가 Poodle 클래스의 트레 이닝 데이터의 특징 포인트들의 위치를 반영하여 업데이트(73a') 되는 것이 도시되어 있다. 일 실시예에서, 제1 클래스에 대한 상기 업데이트에 의하여, 상기 제1 클래스의 앵커 포인트의 위치는, 상기 제 1 클래스의 앵커 포인트 및 현재 반복(iteration)까지 입력된 모든 제1 클래스의 트레이닝 데이터의 특징 포인 트들의 대표 값으로 업데이트 될 수 있다. 예를 들어, 상기 대표 값은 평균 값 또는 중앙 값일 수 있다. 상기 업데이트에 의하여, Poodle 클래스의 앵커 포인트 위치와 트레이닝 데이터의 특징 포인트의 위치 사이의 이격이 심했던 문제가 개선되었음을 확인할 수 있다. 메트릭 학습의 결과, 현재 iteration에 따른 거리 함수는, Falcon 클래스의 특징 포인트들이 업데이트 된 앵커 포인트(76a')에 가까워지고, Poodle 클래스의 특징 포인트들은 업데이트 된 앵커 포인트(73a')에 가까워지도록 하는 거리 함수로 업데이트 된다. 도 9에는, 업데이트 된 거리 함수가 반영된 임베딩 공간이 도시되었다. 메트릭 학습은, 학습할 다음 트레이닝 데이터가 남아 있다면, 다음의 반복(iteration)으로 진행된다. 상술한 바와 같이, 앵커 포인트는 대표 데이터의 특징 데이터가 특징 공간(또는, 학습의 반복(iteration)이 진 행 중인 경우 현재 임베딩 공간)에 매핑 된 것이다. 대표 데이터의 선정에 아무리 신중을 구하더라도, 해당 클 래스의 트레이닝 데이터 모두에 대한 이상적인 대표 포인트가 되지는 못할 것이다. 따라서, 최초의 앵커 포인트 를 계속해서 유지하여 학습을 반복(iteration)하게 되면, 임베딩 공간 상 각 클러스터의 위치가 트레이닝 데이 터를 정확하게 반영하지 못하는 문제가 있다. 하지만, 그럼에도 불구하고 상기 앵커 포인트는 트레이닝 데이터 의 특징 포인트들의 위치의 기준점 역할을 수행할 필요가 있다. 일 실시예에서, 상기 두가지 상반된 목표를 모두 만족시키기 위하여, 제1 클래스의 앵커 포인트의 위치를, 상기 제1 클래스의 특징 포인트들의 위치를 반영하여 업데이트 하되, 학습 초기에는 앵커 포인트의 업데이트를 하지 않을 수 있다. 상기 학습 초기는, 학습 시작 시점부터 제1 횟수의 반복(iteration)으로 구성된다. 이 때, 앵커 포인트의 위치를 업데이트 하더라도, 2 이상의 제2 횟수의 반복 마다 한번씩 상기 앵커 포인트의 위치 업데이트 를 수행함으로써, 너무 잦은 앵커 포인트 업데이트에 의한 오버헤드를 줄일 수 있다. 일 실시예에서, 학습 초기 구간을 정의하는 상기 제1 횟수는 트레이닝 데이터의 타입을 기준으로 설정될 수 있 다. 즉, 상기 제1 횟수는, 상기 트레이닝 데이터의 타입이 제1 타입인 경우 제1 값으로 설정되고, 상기 트레이 닝 데이터의 타입이 제2 타입인 경우 제2 값으로 설정될 수 있다. 예를 들어, 상기 제1 타입은 영상 데이터이고, 상기 제2 타입은 음성 데이터일 수 있다. 일 실시예에서, 메트릭 학습에 따른 임베딩 공간 업데이트 이후, 클러스터 사이의 거리를 클러스터 간 시맨틱 관계를 고려하여 조정한 후, 다음 반복(iteration)으로 넘어갈 수도 있다. 이와 관련하여 도 10을 참조하면, 메 트릭 학습에 따라 임베딩 공간이 업데이트 된 후, 클러스터 위치 조정(cluster position revision)에 따라, 3개 의 클러스터(73e, 76e, 78e)의 위치가 조정된다. 이러한 클러스터 간 위치 조정에 의하여, 앵커 포인트 업데이 트에 의한 시맨틱 관계의 훼손이 점점 확대되는 것을 차단할 수 있는 효과가 있다. 도 10의 사례를 참조로 설명하면, Falcon 클러스터(76e)와 Eagle 클러스터(78e) 사이의 적정 거리는 시맨틱 트 리의 Falcon 노드(76c)와 Eagle 노드(78c) 사이의 거리에 기반하여 결정되는데, 상기 결정된 거리가 현재 임베딩 공간 상의 두 클러스터(76e, 78e) 사이의 거리보다 짧기 때문에, 두 클러스터(76e, 78e)는 서로 가까워 지는 방향으로 이동한다(76f, 78f). 또한, Poodle 클러스터(73e)는 시맨틱 트리에 따라 결정된 적정 거리 보다 더 Falcon 클러스터(76e) 및 Eagle 클러스터(78e) 쪽으로 접근하였으므로, 두 개의 클러스터(76e, 78e)로 부터 멀어지는 방향으로 이동한다(73f). 도 11에는 도 10의 클러스터 위치 조정에 따라 조정된 3개의 클러스터 의 위치(73g, 76g, 78g)가 도시되어 있다. 도 10을 참조하여 설명한 실시예에 따른 메트릭 학습은, 상기 클러스터 위치 조정 이후, 학습할 다음 트레이닝 데이터가 남아 있다면, 다음의 반복(iteration)으로 진행된다. 이 때, 다음의 반복(iteration)에서 현재 임베딩 스페이스에는 조정된 위치(73g, 76g, 78g)의 3개의 클러스터가 포함된 상태에서, 다음 트레이닝 데이터 의 특징 포인트가 추가로 매핑될 것이다. 이하, 상술한 전자 장치의 메트릭 학습 관련 동작을, 메트릭 생성 프로그램에 포함되는 인스트럭션 각각의 동작 을 참조하여 설명한다. 도 12를 참조하여, 메트릭 생성 프로그램이 트레이닝 데이터 셋의 학습 결과 얻어진 거리 함수(즉, 메트릭)를 출력하는 동작을 하는 것을 설명한다. 상술한 바와 같이, 몇몇 실시예들에서, 상기 메트릭 학습 도중 시맨틱 트리가 조회될 수 있고, 앵커 포인 트 형성을 위한 별도의 클래스 대표 데이터가 입력 되지 않으면, 전자 장치에 저장된 클래스 별 대표 데이터 가 사용될 수 있다. 시맨틱 트리 인터페이스 인스트럭션은 메트릭 학습 인스트럭션의 요청에 응답하여 시맨틱 트리 또는 클래스 별 대표 데이터의 조회 결과를 메트릭 학습 인스트럭션에 회신한다. 일 실시예에서, 메트릭 학습 인스트럭션은 트레이닝 데이터를 CNN(Convolution Neural Network) 레 이어들에 입력하여 입력 된 트레이닝 데이터의 특징 데이터를 얻고, 얻어진 특징 데이터를 DML(Deep Metric Learning) 레이어들(1311a)에 입력하여, DML 레이어들(1311a)로부터 출력된 거리 함수 관련 데이터를 얻 을 수 있다. 메트릭 학습 인스트럭션은, CNN 레이어들과, CNN 레이어들에서 DML 레이어들(1311a)를 일괄 하여 학습시키거나, DML 레이어들(1311a)만을 CNN 레이어들과 분리하여 학습시킬 수 있다. 다른 실시예에서, 트레이닝 데이터의 특징 데이터를 얻기 위해 CNN(Convolution Neural Network) 레이어들 대신 다른 머신 러닝 알고리즘이 이용될 수도 있음을 유의한다. DML 레이어들(1311a)은 상술한 메트릭 학습이 수행되는 딥러닝 기반의 인공 신경망 네트워크이다. 모델 생성 인스트럭션은 DML 레이어들(1311a)로부터 출력된 거리 함수 관련 데이터를 사전 정의된 방식으 로 패키징 하여 출력한다. 상기 출력된 데이터는 네트워크 인터페이스를 통하여 외부 장치에 송신되거나, 추후 참조될 경우를 대비하여 전자 장치의 스토리지 장치에 저장될 수 있다. 도 13을 참조하여, 메트릭 생성 프로그램이 트레이닝 데이터 셋의 학습 결과 얻어진 거리 함수(즉, 메트릭)를 반영한 임베딩 스페이스 기반의 분류 모델을 생성하여 출력하는 동작을 하는 것을 설명한다. 도 13의 시맨틱 트리 인터페이스 인스트럭션은 도 12를 참조하여 설명한 것과 동일하게 동작한다. 메트릭 학습 인스트럭션은, DML 레이어들(1311b)이 메트릭 학습의 결과 생성된 거리 함수가 아니라, 상기 거리 함수가 반영되어 형성된 임베딩 공간 상의 클러스터 형성 결과를 반영하는 클러스터 특징 데이터(cluster feature)를 출력하는 레이어를 도 12의 DML 레이어들(1311a) 대비 더 포함하는 점을 제외하고는 도 12를 참조하 여 설명한 것과 동일하게 동작한다. 분류 학습 인스트럭션은 메트릭 학습 인스트럭션에 따라 생성된 거리 함수에 기반한 분류 모델을 생성한다. 분류 학습 인스트럭션은 메트릭 학습 인스트럭션에 의하여 학습 되는 메트릭 학습 레이 어들, 특히 DML 레이어들(1311b)로부터 출력된 데이터를 입력 받아 각 클래스 별 컨피던스 레벨을 출력하는 단 일 레이어로 구성된 객체 분류 레이어를 학습시킬 수 있다. 분류 학습 인스트럭션이 단일 레이어 만으로 분류 모델을 학습 시킬 수 있는 이유는, DML 레이어들 (1311b)에서 출력된 클러스터 특징 데이터가 서로 충분히 이격 되어 위치하는 클러스터링 결과를 반영하기 때문 이다. 따라서, 클러스터 특징 데이터로부터 각 클래스 별 컨피던스 레벨을 산출하기 위한 연산의 복잡도가 낮으 므로, 단일 레이어만으로도 분류 모델을 학습 시킬 수 있다. 모델 생성 인스트럭션은 분류 학습 인스트럭션으로부터 출력된 데이터를 사전 정의된 방식으로 패 키징 한 ML 파라미터 셋을 출력한다. ML 파라미터 셋에는, CNN 레이어들을 정의하기 위한 파 라미터 셋, DML 레이어들(1311b)를 정의하기 위한 파라미터 셋 및 분류 레이어를 정의하기 위한 파라미터 셋이 모두 포함될 수 있다. 즉, ML 파라미터 셋은 CNN 레이어들, DML 레이어들(1311b) 및 분류 레 이어를 순차적으로 연결하여 데이터의 분류 결과를 출력하는 모델을 생성하기 위한 데이터를 포함할 수 있다. 모델 생성 인스트럭션에 의하여 출력된 데이터는 네트워크 인터페이스를 통하여 외부 장치에 송신 되거나, 추후 참조될 경우를 대비하여 전자 장치의 스토리지 장치에 저장될 수 있다. 이하, 도 14를 참조하여, 메트릭 생성 프로그램(130b)이 비디오의 각 프레임 이미지가 포함된 트레이닝 데이터 셋을 이용하여, 상기 비디오에 포함된 각 객체를 분류하는 모델을 생성하기 위한 메트릭 학습을 수행하는 동작 을 수행하는 실시예를 설명한다. 본 실시예에 따른 메트릭 생성 프로그램(130b)의 동작은 도 10을 참조하여 설 명한 전자 장치의 동작을 인스트럭션 단위로 정리한 것으로 이해될 수 있을 것이다. 비디오 프레임 획득 인스트럭션은 비디오 데이터를 입력 받아, 순차적으로 프레임 이미지를 객체 추출 인 스트럭션에 제공한다. 비디오의 다음 프레임 이미지가 존재하지 않는 경우, 상기 비디오를 이용한 학습이 종료된 것이므로 마지막 거리 함수 또는, 상기 마지막 거리 함수가 반영된 마지막 임베딩 공간 상의 클러스터 특징 데이터가 출력될 것이다. 본 실시예에 따른 메트릭 생성 프로그램(130b)에 비디오 프레임 획득 인스트럭션 및 객체 추출 인스트럭 션이 포함될 수도 있지만, 외부 프로그램에 의하여 객체 추출 결과가 제공될 수도 있음을 유의한다. 객체 추출 인스트럭션은 공지된 객체 추출 알고리즘을 이용하여 제공 받은 프레임 이미지에서 하나 이상 의 객체 이미지를 추출하고, 추출된 객체 이미지를 특징 포인트 결정 인스트럭션에 제공한다. 특징 포인 트 결정 인스트럭션은 CNN 레이어들을 이용하여, 상기 객체 이미지 각각의 특징 데이터를 출력하고, 현재 임베딩 공간에 매핑하여 특징 포인트들을 추가한다. 앵커 포인트 위치 결정 인스트럭션은 복수의 클래스의 앵커 포인트(anchor point)들의 위치를, 각 클래스 사이의 시맨틱(semantic) 관계 정보를 반영하여 결정한다. 앵커 포인트 위치 결정 인스트럭션은 메트릭 생성 프로그램의 실행 시작 시, 즉 메트릭 학습이 시작 될 때에 한하여 앵커 포인트의 초기 위치를 세팅하기 위 해 수행되고, 앵커 포인트 위치 업데이트가 시작되면 더 이상 실행되지 않을 수 있다. 앵커 포인트 위치 업데이트 인스트럭션은 각 앵커 포인트들의 위치를 각각의 앵커 포인트에 인접한 특징 포인트들의 위치를 반영하여 업데이트한다. 메트릭 학습 및 임베딩 공간 업데이트 인스트럭션은 상기 특징 포인트들 각각이, 상기 업데이트된 앵커 포인트들 중 최근접 앵커 포인트에 더 가까워지도록 하는 거리 함수를 생성 하는 메트릭 학습의 현재 반복 (iteration)을 수행하고, 상기 생성된 거리 함수를 반영하여 상기 임베딩 공간을 업데이트한다. 클러스터 위치 업데이트 인스트럭션은 각각의 앵커 포인트 및 상기 앵커 포인트에 인접한 특징 포인트들 로 구성된 클래스 별 클러스터의 상기 임베딩 공간 상의 위치를, 각각의 앵커 포인트가 가리키는 클래스 사이의 시맨틱 관계 정보를 반영하여 업데이트한다. 다음으로는, 비디오 프레임 획득 인스트럭션이 다음 프레임 의 이미지를 제공하는 동작과 함께, 다음 사이클이 수행될 것이다. 한편, 일 실시예에서, 기존에 메트릭 생성 프로그램(130b)에 의하여 학습된 결과로 생성된 객체 클러스터 형성 모델(비디오의 프레임 이미지를 입력 받아, 상기 프레임 이미지에 포함된 각 객체 이미지가 어떤 클러스터에 속 하는지에 대한 판단 결과를 출력하는)에 대하여 사용자 피드백을 얻는 인스트럭션(미도시)이 더 수행될 수 있다. 이 경우, 상기 피드백을 이용하여, 상기 기존의 객체 클러스터 형성 모델을 업데이트 하기 위한 메트릭 학습 및 임베딩 공간 업데이트 인스트럭션 및 클러스터 위치 업데이트 인스트럭션이 수행될 수 있 다. 본 실시예는 점진 학습(incremental learning)의 한 형태로 이해될 수 있을 것이다. 이 때, 본 실시예에 따 른 메트릭 생성 프로그램(130b)을 실행하는 전자 장치는 사용자 단말일 수 있다. 이하, 본 발명의 다른 실시예에 따른 전자 장치의 구성 및 동작을 설명한다. 본 실시예에 따른 전자 장치는, 상 술한 전자 장치에서 수행된 기계학습의 결과 만들어진 모델을 실행하는 장치인 것으로 이해될 수 있다. 이하 그 일 예로서, 비디오의 재생 중 상기 모델을 이용하여 현재 표시되는 화면에 표시된 각 객체를 인식하고, 각 객체 의 인식 결과를 이용하여 현재 표시되는 화면의 장면(scene)을 이해하는 전자 장치의 구성 및 동작을 설명한다. 도 15의 전자 장치 역시 도 2의 전자 장치와 유사한 하드웨어 구성을 갖는다. 이하, 공통 부분에 대한 중복된 설명은 생략한다. 스토리지에는 디스플레이에서 재생(160b) 되는 비디오 데이터(160a), 도 2의 전자 장치 등으로부터 네트워크 인터페이스를 통해 수신된 객체 인식 모델, 시맨틱 트리, 클래스 별 대표 데이터, 장면 이해 프로그램(170a), 응용 서비스 어플리케이션(180a)가 저장될 수 있다. 장면 이해 프로그램(170a)은 메모리에 로드되어 저장된다(170b). 이하, 장면 이해 프로그램(170b)의 동작 을 각 인스트럭션 단위로 설명한다. 객체 추출 인스트럭션은 디스플레이를 통해 재생되는 비디오(160b)의 현재 화면에서 객체를 추출한 다. 이 때, 디스플레이에 표시되는 영상에서 객체를 추출할 수만 있으면 족하므로, 상기 영상은 비디오의 프레임이거나 또는 일반 이미지 모두 가능하다. 본 실시예에 따른 장면 이해 프로그램(170b)에 객체 추출 인스 트럭션이 포함될 수도 있지만, 외부 프로그램에 의하여 객체 추출 결과가 제공될 수도 있음을 유의한다. 객체 인식 모델 선택 인스트럭션은 스토리지에 저장된 객체 인식 모델 중 하나를 선택한다. 객 체 인식 모델은, 예를 들어 도 13을 참조하여 설명한 ML 파라미터 셋일 수 있다. 즉, 객체 인식 모델 은 시맨틱 관계 정보를 반영한 거리 함수가 반영 된 임베딩 공간 상에 객체 이미지의 특징 포인트를 매핑 하고, 상기 특징 포인트의 임베딩 공간 내 위치를 기반으로 객체의 클래스를 출력하는 것일 수 있다. 스토리지에는 복수의 객체 인식 모델이 저장될 수 있다. 이 경우, 객체 인식 모델 선택 인스트럭션 이 복수의 객체 인식 모델 중 하나를 선택할 수 있다. 물론, 적용 대상 객체 인식 모델이 고정되 어 객체 인식 모델 선택 인스트럭션의 동작이 필요하지 않을 수도 있다. 이하, 복수의 객체 인식 모델 중 하나가 선택되는 실시예들에 대하여 설명한다. 일 실시예에서, 복수의 객체 인식 모델은 제1 장르의 비디오를 이용하여 기계학습한 결과 생성된 제1 객체 인식 모델과 제2 장르의 비디오를 이용하여 기계학습한 결과 생성된 제2 객체 인식 모델을 포함할 수 있다. 이 때, 객체 인식 모델 선택 인스트럭션은 영상의 타입에 기반하여 선정할 수 있다. 예를 들어, 객체 인식 모델 선택 인스트럭션은 현재 재생 중인 비디오의 메타 정보 등으로부터 장르 정보를 얻고, 상기 비디오 의 장르 정보에 대응 되는 장르 정보가 태그 된 객체 인식 모델을 선정할 수 있다. 본 실시예에 따르면 객체 인 식 모델의 학습에 사용된 비디오와 상기 객체 인식 모델에 입력 될 비디오의 장르를 일치시킴으로써, 객체 인식 정확도를 증가시킬 수 있는 효과가 있다. 다른 실시예에서, 객체 인식 모델 선택 인스트럭션은 전자 장치의 사용자 프로필(미도시)에 등록된 정보를 기초로 복수의 객체 인식 모델 중 어느 하나를 선택할 수도 있다. 예를 들어, 상기 사용자 프로필에 따를 때, 선호하는 영화 장르에 액션이 기재되었다면, 객체 인식 모델 선택 인스트럭션은 액션 장르의 비 디오를 이용하여 학습된 객체 인식 모델을 선정할 수 있을 것이다. 또 다른 실시예에서, 객체 인식 모델 선택 인스트럭션은 응용 서비스의 타입에 따라 복수의 객체 인식 모 델 중 어느 하나를 선택할 수도 있다. 장면 이해 프로그램(170b)과 연계된 응용 서비스 어플리케이션(180 b)에 따라 상기 응용 서비스의 타입이 결정될 수 있다. 상기 응용 서비스는, 장면 이해 프로그램(170b)에 의하 여 판정된 현재 장면 이해 결과에 대응되는 추가 컨텐츠를 제공하는 것을 포함할 수 있다. 응용 서비스 어플리 케이션(180b)은 장면 이해 프로그램(170b)와 별도의 독자적인 프로그램일 수도 있지만, 장면 이해 프로그램 (170b) 내부의 인스트럭션일 수도 있음을 유의한다. 예를 들어, 상기 추가 컨텐츠는 장면 맞춤형 광고, 장면 대응 텍스트를 이용한 검색 결과, 장면 맞춤형 미디어 일 수 있다. 예를 들어 상기 추가 컨텐츠가 장면 맞춤형 광고인 경우, 객체 인식 모델 선택 인스트럭션은 광고 대상 객체 이미지가 집중적으로 학습된 객체 인식 모델을 선택할 것이다. 객체 포인트 생성 인스트럭션은 상기 선정된 객체 인식 모델을 이용하여, 영상에서 추출된 복수의 객체 각각의 특징 포인트를 임베딩 공간에 매핑한다. 다음으로, 장면 이해 인스트럭션은 영상에서 추출된 상기 매핑된 특징 포인트들 중 적어도 일부에 가장 근접 한 앵커 포인트를 선정하고, 상기 선정된 앵커 포인트의 키워드를 이용하여 상기 영상의 장면을 이해한다. 이 과정에서, 시맨틱 트리의 조회가 요구되는데, 시맨틱 트리 인터페이스 인스트럭션이 상기 조회를 담당할 수 있다. 이에 대하여 도 16을 참조하여 보다 자세히 설명한다. 도 16을 참조하면, 영상(160b)에서 2개의 객체(95a, 96a)가 추출된 경우, 객체 포인트 생성 인스트럭션은 객체 인식 모델을 이용하여 임베딩 공간에 객체(95a)의 이미지의 특징 포인트(95b)를 매핑하고, 객체(96a) 의 이미지의 특징 포인트(96b)를 매핑할 것이다. 이 때, 장면 이해 인스트럭션은 임베딩 공간에서 2 개의 특징 포인트(95b, 96b)와 가장 인접한 앵커 포인트들(76a, 78a)을 선정한다. 특징 포인트(95b)와 가장 인접한 앵커 포인트는 Falcon의 앵커 포인트(76a)이고, 특징 포인트(96b)와 가장 인접 한 앵커 포인트는 Eagle의 앵커 포인트(76b)라고 가정한다. 이러한 상황에서, 일 실시예에 따르면, 시맨틱 트리 상에서 Falcon의 앵커 포인트(76a)에 대응되는 노드(76c)와 Eagle의 앵커 포인트(76b)에 대응 되는 노드 (78c) 모두의 상위 노드인 Bird 노드(92c)가 선정되어, 장면 이해 결과가 'Bird'로 결정될 수 있다. 다른 실시 예에 따르면, 특징 포인트(95b, 96b)와 가장 인접한 상위 레벨 앵커 포인트가 선정될 수도 있다. 상기 상위 레 벨 앵커 포인트는, 시맨틱 트리 상에서 기 지정된 깊이(depth) 이하의 노드에 대응되는 앵커 포인트를 가 리킨다. 예를 들어, 상기 기 지정된 깊이가 '1'인 경우, 특징 포인트(95b, 96b)와 가장 인접한 상위 레벨 앵커 포인트는 Bird 노드(92c)의 앵커 포인트(92a)가 될 것이다. 따라서, 이 경우에도 장면 이해 결과가 'Bird'로 결 정될 수 있다. 일 실시예에서, 도 16에 도시된 바와 같이, 장면 이해 결과는 계층적으로 레벨을 나누어 출력될 수도 있다. 이 는, 임베딩 공간이 계층적인 시맨틱 관계를 반영하고 있기 때문에 가능하다. 일 실시예에서, 영상에서 기 지정된 수 이상의 객체가 추출된 경우, 일부의 객체에 대하여 가장 근접 한 앵커 포인트를 선정하고, 상기 선정된 앵커 포인트의 키워드를 이용하여 상기 영상의 장면을 이해할 수도 있다. 이 경우, 영상에서 추출된 일부의 객체는 동떨어진 의미를 가질 수도 있고, 그렇게 되면 장면의 이해에 있어서 노 이즈로 작용하기 때문이다. 이하, 본 발명의 몇몇 실시예들에 따른, 전자 장치에 의하여 수행되는 방법들에 대하여, 도 17 내지 도 19를 참 조하여 설명한다. 도 17은 본 발명의 또 다른 실시예에 따른 메트릭 학습 방법의 순서도이다. 본 실시예에 따른 방법은, 예를 들 어 도 2에 도시된 전자 장치에 의하여 수행될 수 있다. 상기 메트릭 학습 방법에 도 2 내지 도 5를 참조하 여 설명한 전자 장치의 동작이 적어도 일부 포함될 수 있음을 유의한다. 따라서, 이하 설명되는 메트릭 학습 방 법에 대한 설명에서 별도의 개시가 없더라도, 도 2 내지 도 5을 참조하여 상술한 동작이 상기 메트릭 학습 방법 에 포함될 수 있다. 또한, 이하 상기 방법들에 대한 설명에서, 동작의 주체에 대한 기재가 존재하지 않는 경우, 상기 주체는 상기 전자 장치로 해석될 수 있다. 단계 S101에서, 트레이닝 데이터의 현재 임베딩 공간 상의 특징 포인트가 결정된다. 상기 트레이닝 데이터는, 트레이닝 데이터 셋 중 현재 반복(iteration)의 학습 대상인 데이터이고, 상기 현재 임베딩 공간은 현재 구해진 거리 함수가 반영된 특징 공간이다. 상기 현재 임베딩 공간은, 상기 거리 함수가 구해진 바 없으면, 초기 상태 로서 범용 거리 함수가 적용된 특징 공간이다. 단계 S103에서, 앵커 포인트 위치가 결정된다. 상기 앵커 포인트 위치가 이미 결정된 상태라면, 앵커 포인트 위 치의 결정은 추가로 수행되지 않을 수도 있다. 또한, 상술한 바와 같이, 초기 학습 단계를 지났다면, 기존 앵커 포인트의 위치가 특징 포인트의 위치를 반영하여 주기적으로 업데이트 될 수도 있다. 단계 S105에서, 특징 포인트가 앵커 포인트에 더 가까워 지도록 메트릭 학습이 수행된다. 상술한 바와 같이, 종 래 기술에 따른 메트릭 학습 대비, 특징 포인트가 앵커 포인트라는 기준점에 가까워지도록 거리 함수가 학습되 므로, 학습 속도가 더 빠르다는 장점이 있다. 본 실시예에 따른 메트릭 학습 방법은, 학습할 다음 트레이닝 데 이터가 남아 있다면(S107), 다음의 반복(iteration)으로 진행되고, 학습할 다음 트레이닝 데이터가 존재하지 않 는다면, 학습된 결과로서 거리 함수 관련 데이터를 출력한다(S109). 도 18은 본 발명의 또 다른 실시예에 따른 객체 인식 모델 생성 방법의 순서도이다. 본 실시예에 따른 방법은, 예를 들어 도 2에 도시된 전자 장치에 의하여 수행될 수 있다. 상기 객체 인식 모델 생성 방법에 도 2, 도 10 및 도 14를 참조하여 설명한 전자 장치의 동작이 적어도 일부 포함될 수 있음을 유의한다. 따라서, 이하 설 명되는 객체 인식 모델 생성 방법에 대한 설명에서 별도의 개시가 없더라도, 도 2, 도 10 및 도 14를 참조하여 상술한 동작이 상기 객체 인식 모델 생성 방법에 포함될 수 있다. 또한, 이하 상기 방법에 대한 설명에서, 동작 의 주체에 대한 기재가 존재하지 않는 경우, 상기 주체는 상기 전자 장치로 해석될 수 있다. 단계 S201에서, 비디오의 현재 프레임 이미지에 대하여 객체 인식이 수행된다. 상술한 바와 같이, 외부 프로그 램으로부터 객체 인식 결과를 제공 받을 수도 있다. 단계 S203에서, 각 객체의 이미지에 대한 현재 임베딩 공간 상의 특징 포인트가 결정된다. 또한, 단계 S205에서, 앵커 포인트의 위치를 시맨틱 관계 정보를 반영하여 결정한다. 도 18에 도시된 바와 달리, 단계 S203 보다 단계 S205가 먼저 수행될 수도 있다. 단계 S207에서, 앵커 포인트 위치를 클러스터의 평균 값 등으로 업데이트 한다. 단계 S209에서, 특징 포인트들 이 업데이트 된 위치의 앵커 포인트에 더 가까워지도록 메트릭 학습을 수행한다. 상기 메트릭 학습을 통해 객체 이미지의 특징 데이터 추출을 위한 CNN 레이어들 및 메트릭 학습을 위한 DML 레이어들이 학습될 수 있을 것이다. 단계 S211에서, 상기 메트릭 학습에 의하여 구해진 거리 함수를 이용하여 현재 임베딩 공간을 업데이트 한다. 단계 S213에서, 앵커 포인트 위치의 업데이트에 따라 시맨틱 관계 정보가 훼손 되는 것을 방지하기 위하여, 클 러스터 간 상대 위치를 시맨틱 관계 정보 반영하여 수정한다. 본 실시예에 따른 객체 인식 모델 생성 방법은, 학습할 다음 프레임이 남아 있다면(S215), 다음의 반복 (iteration)으로 진행된다. 비디오의 마지막 프레임까지 학습을 완료했다면, 단계 S217에서 학습 된 거리 함수 를 기반으로 분류 모델을 학습한다. 상기 분류 모델 학습을 통해, 메트릭 학습 레이어로부터 출력된 데이터를입력 받아 각 클래스 별 컨피던스 레벨을 출력하는 단일 레이어로 구성된 객체 분류 레이어가 학습 될 수 있을 것이다. 다음으로, 단계 S219에서, 객체 인식 모델에 대한 데이터가 출력된다. 상기 출력되는 데이터는 상기 CNN 레이어 들, DML 레이어들, 상기 객체 분류 레이어의 학습된 파라미터 셋을 포함할 수 있다. 도 19는 본 발명의 또 다른 실시예에 따른 장면 이해 방법의 순서도이다. 본 실시예에 따른 방법은, 예를 들어 도 15에 도시된 전자 장치에 의하여 수행될 수 있다. 상기 장면 이해 방법에 도 15 및 도 16을 참조하여 설명한 전자 장치의 동작이 적어도 일부 포함될 수 있음을 유의한다. 따라서, 이하 설명되는 장면 이해 방법에 대한 설명에서 별도의 개시가 없더라도, 도 15 및 도 16을 참조하여 상술한 동작이 상기 장면 이해 방법에 포함 될 수 있다. 또한, 이하 상기 방법에 대한 설명에서, 동작의 주체에 대한 기재가 존재하지 않는 경우, 상기 주 체는 상기 전자 장치로 해석될 수 있다. 단계 S301에서, 객체 인식 모델이 서버 장치 등으로부터 다운로드 되어 저장된다. 비디오의 재생(S303) 등을 이 유로 영상이 디스플레이 되는 경우, 현재 디스플레이 되는 영상에서 복수의 객체를 추출한다(S305). 이 때, 다 운로드 된 객체 인식 모델 중 사용 대상 객체 인식 모델이 선정될 수 있다. 단계 S307에서, 선정된 객체 인식 모델을 이용하여, 각각의 객체 이미지에 대하여 그 특징 포인트를 상기 객체 인식 모델에 따른 임베딩 공간에 매핑한다. 단계 S309에서, 매핑된 특징 포인트 중 적어도 일부와 인접한 앵커 포인트가 선정되고, 단계 S311에서, 선정된 앵커 포인트의 의미 및 그 시맨틱 관계를 이용하여, 현재 디스플레 이 되는 영상의 장면을 이해한다. 한편, 영상의 장면 이해 결과가 제시되고, 그에 대한 사용자의 피드백이 입력될 수 있다(S313). 상기 피드백이 입력되면, 입력된 피드백을 이용하여 객체 인식 모델에 대한 학습이 수행될 수 있다(S314). 이는, 점진 학습 (incremental learning)의 한 형태로서 이해될 수 있다. 단계 S315에서, 장면 이해 결과 데이터를 서비스 서버에 송신하고, 그에 대한 응답으로서 장면에 대응되는 추가 컨텐츠가 출력될 수 있다(S317). 비디오의 재생이 종료되지 않는 한(S319), 다음 프레임으로 이동(S312)하면서 상기 장면 이해 방법이 계속 수행 될 수 있다. 지금까지 설명된 본 발명의 실시예에 따른 방법들은 컴퓨터가 읽을 수 있는 코드로 구현된 컴퓨터프로그램의 실 행에 의하여 수행될 수 있다. 상기 컴퓨터프로그램은 인터넷 등의 네트워크를 통하여 제1 전자 장치로부터 제2 전자 장치에 전송되어 상기 제2 전자 장치에 설치될 수 있고, 이로써 상기 제2 전자 장치에서 사용될 수 있다. 상기 제1 전자 장치 및 상기 제2 전자 장치는, 서버 장치, 클라우드 서비스를 위한 서버 풀에 속한 물리 서버, 데스크탑 피씨와 같은 고정식 전자 장치를 모두 포함한다. 상기 컴퓨터프로그램은 DVD-ROM, 플래시 메모리 장치 등의 비-일시적인(non-transitory) 기록매체(recording medium)에 저장된 것일 수도 있다."}
{"patent_id": "10-2017-0152974", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정 적인 것이 아닌 것으로 이해해야만 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19"}
{"patent_id": "10-2017-0152974", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 장면 이해 기반 서비스 시스템의 구성도이다. 도 2는 본 발명의 일 실시예에 따른 전자 장치의 하드웨어 구성도이다. 도 3은 종래 기술에 따른 메트릭 학습을 설명하기 위한 도면이다. 도 4는 본 발명의 몇몇 실시예들에 따른 전자 장치 또는 방법에 적용되는 개선된 성능의 메트릭 학습을 설명하 기 위한 도면이다. 도 5는 본 발명의 몇몇 실시예들에 따른 전자 장치 또는 방법에 적용되는 개선된 성능의 메트릭 학습의 성능을, 종래 기술에 따른 분류 알고리즘과 비교하여 설명하기 위한 도면이다. 도 6은 본 발명의 몇몇 실시예들에 따른 전자 장치 또는 방법에 적용되는 개선된 성능의 메트릭 학습의 특징을 설명하기 위한 도면이다. 도 7은 본 발명의 몇몇 실시예들에 따른 전자 장치 또는 방법에 적용되는 메트릭 학습 과정에서, 두개의 앵커 포인트 간의 상대적 위치가 앵커 포인트 간의 시맨틱 관계에 따라 결정되는 점을 설명하기 위한 도면이다. 도 8은 본 발명의 몇몇 실시예들에 따른 전자 장치 또는 방법에 적용되는 시맨틱 관계가 반영된 메트릭 학습의 특징을 설명하기 위한 도면이다. 도 9는 본 발명의 몇몇 실시예들에 따른 전자 장치 또는 방법에 적용되는 메트릭 학습 과정에 있어서, 앵커 포 인트의 업데이트가 수행되는 것을 설명하기 위한도면이다. 도 10 내지 도 11은 본 발명의 몇몇 실시예들에 따른 전자 장치 또는 방법에 적용되는 메트릭 학습 과정에 있어 서, 앵커 포인트의 업데이트 및 임베딩 스페이스 업데이트 이후의 클러스터 위치 업데이트가 수행되는 것을 설 명하기 위한도면이다. 도 12 내지 도 14는, 본 발명의 일 실시예에 따른 전자 장치의 메트릭 생성 프로그램의 동작 예시를 상세 설명 하기 위한 도면이다. 도 15는, 본 발명의 다른 실시예에 따른 전자 장치의 하드웨어 구성도이다. 도 16은 도 15의 전자 장치의 장면 이해 동작을 설명하기 위한 개념도이다. 도 17은 본 발명의 또 다른 실시예에 따른 메트릭 학습 방법의 순서도이다. 도 18은 본 발명의 또 다른 실시예에 따른 객체 인식 모델 생성 방법의 순서도이다. 도 19는 본 발명의 또 다른 실시예에 따른 장면 이해 방법의 순서도이다."}
