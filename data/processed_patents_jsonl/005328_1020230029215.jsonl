{"patent_id": "10-2023-0029215", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0136045", "출원번호": "10-2023-0029215", "발명의 명칭": "음성인식 모델 생성을 위한 학습용 음성파일의 전처리 방법 및 이를 이용한 컴퓨팅 장치", "출원인": "주식회사 케이티", "발명자": "김철우"}}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성인식 모델 생성을 위한, 컴퓨팅 장치의 학습용 음성파일에 대한 전처리 방법에 있어서,음성인식장치를 이용하여, 학습용 음성파일 내 음성신호를 텍스트로 변환하고, 상기 텍스트 내에 포함된 각각의어절들을 분리한 어절정보를 생성하는 단계;미리 설정된 시간간격의 윈도우를 이용하여, 상기 학습용 음성파일 내 음성신호에 나타난 주파수를 부호화한 코드정보를 생성하는 단계; 및상기 어절정보 및 코드정보를 동기화하여 전처리 데이터를 생성하는 단계를 포함하는, 학습용 음성파일에 대한전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 어절정보는상기 학습용 음성파일 내 상기 어절이 나타나는 시작시점 및 종료시점, 상기 어절에 대응하는 텍스트인 어절 텍스트, 및 상기 어절 텍스트의 정확도를 나타내는 신뢰도를 포함하는 것인, 학습용 음성파일에 대한 전처리방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 코드정보를 생성하는 단계는상기 윈도우를 슬라이딩하면서 중첩되는 각각의 시간구간들에 대해 상기 코드정보를 생성하는 것인, 학습용 음성파일에 대한 전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 코드정보를 생성하는 단계는단위 주파수 간격으로 구분되는 복수의 주파수 레벨 중 상기 음성신호의 주파수에 대응하는 주파수 레벨과, 연속되는 윈도우 내에서 동일한 주파수 레벨이 반복되는 횟수를 이용하여, 상기 코드정보를 생성하는 것인, 학습용 음성파일에 대한 전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 코드정보를 생성하는 단계는각각의 윈도우 내에 나타난 상기 음성신호의 주파수에 대응하는 음계 및 옥타브와, 동일한 음계 및 옥타브를 가지는 윈도우가 연속으로 나타나는 반복횟수를 이용하여, 상기 코드정보를 생성하는 것인, 학습용 음성파일에 대한 전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 코드정보를 생성하는 단계는공개특허 10-2024-0136045-3-묵음 및 음성의 주파수 범위를 벗어나는 고주파음을 나타내는 기호를 각각 추가하여, 상기 음성신호 내 묵음이나 고주파음이 포함되면 상기 기호들을 이용하여 상기 코드정보를 생성하는 것인, 학습용 음성파일에 대한 전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 전처리 데이터를 이용하여, 상기 학습용 음성파일 내 포함되는 복수의 음성그룹들을 분류하기 위한 N그램규칙을 생성하는 단계를 더 포함하는 것인, 학습용 음성파일에 대한 전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 N그램 규칙을 생성하는 단계는상기 학습용 음성파일 내에 포함된 복수의 음성그룹들에 대한 정보를 입력받는 것인, 학습용 음성파일에 대한전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 N그램 규칙을 생성하는 단계는상기 학습용 음성파일의 전체 분량 중에서, 미리 설정된 시간길이를 이용하여 상기 N그램 규칙을 생성하는것인, 학습용 음성파일에 대한 전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 복수의 음성그룹은화자음, 잡음 및 복수의 화자들이 포함된 경우 2 이상의 화자들의 음성이 혼합된 충돌음 중 적어도 어느 2 이상을 포함하는 것인, 학습용 음성파일에 대한 전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서, 상기 N그램 규칙을 생성하는 단계는상기 코드정보에 포함된 각각의 코드들을 이용하여, 상기 코드들의 연결순서를 기반으로 하는 연결규칙이나, 동일한 연결순서를 가지는 코드들의 빈도를 기반으로 하는 빈도통계를, 각각의 음성그룹별로 생성하는 것인, 학습용 음성파일에 대한 전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 N그램 규칙을 생성하는 단계는상기 연결순서가 일치하는 코드의 개수가 많거나, 동일한 연결순서를 가지는 코드들의 빈도가 높을수록 높은 값을 나타내도록 평가값을 설정하고, 상기 평가값이 임계값 이상이면 상기 전처리 데이터가 대응하는 음성그룹에포함되는 것으로 판별하도록 상기 임계값을 설정하는 것인, 학습용 음성파일에 대한 전처리 방법."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2024-0136045-4-하드웨어와 결합하여, 제1항 내지 제12항 중 어느 한 항의 학습용 음성파일에 대한 전처리 방법을 실행하기 위하여 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "프로세서를 포함하며, 음성인식 모델 생성을 위한 학습용 음성파일에 대한 전처리를 수행하는 컴퓨팅 장치에 있어서, 상기 프로세서는음성인식장치를 이용하여, 학습용 음성파일 내 음성신호를 텍스트로 변환하고, 상기 텍스트 내에 포함된 각각의어절들을 분리한 어절정보를 생성하는 것;미리 설정된 시간간격의 윈도우를 이용하여, 상기 학습용 음성파일 내 음성신호에 나타난 주파수를 부호화한 코드정보를 생성하는 것; 및상기 어절정보 및 코드정보를 동기화하여 전처리 데이터를 생성하는 것을 수행하는, 컴퓨팅 장치."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 코드정보를 생성하는 것은단위 주파수 간격으로 구분되는 복수의 주파수 레벨 중 상기 음성신호의 주파수에 대응하는 주파수 레벨과, 연속되는 윈도우 내에서 동일한 주파수 레벨이 반복되는 횟수를 이용하여, 상기 코드정보를 생성하는 것인, 컴퓨팅 장치."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14에 있어서, 상기 코드정보를 생성하는 것은각각의 윈도우 내에 나타난 상기 음성신호의 주파수에 대응하는 음계 및 옥타브와, 동일한 음계 및 옥타브를 가지는 윈도우가 연속으로 나타나는 반복횟수를 이용하여, 상기 코드정보를 생성하는 것인, 컴퓨팅 장치."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서, 상기 전처리 데이터를 이용하여, 상기 학습용 음성파일 내 포함되는 복수의 음성그룹들을 분류하기 위한 N그램규칙을 생성하는 것을 더 포함하여 수행하는 것인, 컴퓨팅 장치."}
{"patent_id": "10-2023-0029215", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 N그램 규칙을 생성하는 것은상기 코드정보에 포함된 각각의 코드들을 이용하여, 상기 코드들의 연결순서를 기반으로 하는 연결규칙이나, 동일한 연결순서를 가지는 코드들의 빈도를 기반으로 하는 빈도통계를, 각각의 음성그룹별로 생성하는 것인, 컴퓨팅 장치."}
{"patent_id": "10-2023-0029215", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 음성인식 모델 생성을 위한 컴퓨팅 장치의 학습용 음성파일에 대한 전처리 방법 및 이를 이용한 컴퓨 팅 장치에 관한 것으로, 본 발명의 일 실시예에 의한 음성인식 모델 생성을 위한 컴퓨팅 장치의 학습용 음성파일 에 대한 전처리 방법은, 음성인식장치를 이용하여, 학습용 음성파일 내 음성신호를 텍스트로 변환하고, 상기 텍 스트 내에 포함된 각각의 어절들을 분리한 어절정보를 생성하는 단계; 미리 설정된 시간간격의 윈도우를 이용하 여, 상기 학습용 음성파일 내 음성신호에 나타난 주파수를 부호화한 코드정보를 생성하는 단계; 및 상기 어절정 보 및 코드정보를 동기화하여 전처리 데이터를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0029215", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 학습데이터에 대한 전처리 방법 등에 관한 것으로, 특히 음성인식 모델 생성을 위한 학습용 음성파일 에 대한 전처리 방법 및 이를 위한 컴퓨팅 장치에 관한 것이다."}
{"patent_id": "10-2023-0029215", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성인식 기술이 발전하면서 인공지능 자동응답시스템 등과 같이 다양한 분야에서 음성인식 기술이 적용되고 있 다. 인공지능 자동응답시스템은 적용되는 분야 및 응답해야 할 서비스 종류에 따라 그 음성인식 키워드 및 문장 이 다양하다. 일반적으로, 음성인식 문장을 학습하기 위해, 해당 분야에 대한 상담자와 고객 간의 대화를 녹취 하고, 녹취한 파일을 다시 들으면서 받아쓰기하는 방식으로 학습데이터를 수집할 수 있다. 즉, 학습데이터를 수 집하기 위해서는 고객과 상담원의 대화를 녹취하고, 다시 받아쓰기하여 학습데이터를 획득하므로 큰 비용과 많 은 시간이 소요될 수 있다. 이를 해결하기 위한 방안으로, 사전 또는 키워드 데이터베이스를 기초로 음성데이터를 텍스트데이터로 변환한 후, 텍스트데이터에 발생된 오기를 수정하는 방안이 제안되었다. 그러나, 화자의 발화특성이 다양하고, 학습데 이터를 듣고 정제하는 작업은 수작업으로 이루어지며, 텍스트 변환시 인식 오류가 포함될 수 있으므로, 생성된 학습데이터는 결국 인력에 의존하여 전량 검수해야하는 문제점이 존재한다. 예를 들어, 대용량 음성데이터를 다수의 작업자가 나누어 오류 정정작업을 수행하는 경우, 음성품질이 좋지 않 거나, 사투리 발화의 경우 작업자마다 다르게 정정하는 등의 문제가 발생할 수 있다. 또한, 음성품질이 좋은 경 우에도, 작업자의 배경지식에 따라, 키워드 또는 문장을 다르게 표시하거나 틀리게 표시 할 수 있다. 그 결과 학습후 인식율 측정에서 오류로 나타나게 된다. 또한, 음성데이터 자체가 대상음성이 아닌 잡음이 유입되어 있거나, 두사람 이상의 대화가 중첩되는 경우에는 기계 또는 수작업 전사가 정확하게 되기 어렵고 작업자마다 작업결과가 달라지는 주요 원인중 하나로 작용한다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허공보 제10-2020-0114019호"}
{"patent_id": "10-2023-0029215", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은, 음성인식모델 학습을 위한 학습용 음성파일에 대한 전처리를 효율적으로 수행하여, 음성인식율이 향 상된 음성인식모델을 생성할 수 있는, 음성인식 모델 생성을 위한 학습용 음성파일의 전처리 방법 및 이를 이용 한 컴퓨팅 장치를 제공하기 위한 것이다. 본 발명은, 전처리를 통하여 학습용 음성파일 내 포함된 음성그룹들을 구별할 수 있는, 음성인식 모델 생성을 위한 학습용 음성파일의 전처리 방법 및 이를 이용한 컴퓨팅 장치를 제공하기 위한 것이다."}
{"patent_id": "10-2023-0029215", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 의한 음성인식 모델 생성을 위한 컴퓨팅 장치의 학습용 음성파일에 대한 전처리 방법은, 음성인식장치를 이용하여, 학습용 음성파일 내 음성신호를 텍스트로 변환하고, 상기 텍스트 내에 포함된 각각의 어절들을 분리한 어절정보를 생성하는 단계; 미리 설정된 시간간격의 윈도우를 이용하여, 상기 학습용 음성파일 내 음성신호에 나타난 주파수를 부호화한 코드정보를 생성하는 단계; 및 상기 어절정보 및 코드정보를 동기화하 여 전처리 데이터를 생성하는 단계를 포함할 수 있다. 여기서 상기 어절정보는, 상기 학습용 음성파일 내 상기 어절이 나타나는 시작시점 및 종료시점, 상기 어절에 대응하는 텍스트인 어절 텍스트, 및 상기 어절 텍스트의 정확도를 나타내는 신뢰도를 포함할 수 있다.여기서 상기 코드정보를 생성하는 단계는, 상기 윈도우를 슬라이딩하면서 중첩되는 각각의 시간구간들에 대해 상기 코드정보를 생성하는 것일 수 있다. 여기서 상기 코드정보를 생성하는 단계는, 단위 주파수 간격으로 구분되는 복수의 주파수 레벨 중 상기 음성신 호의 주파수에 대응하는 주파수 레벨과, 연속되는 윈도우 내에서 동일한 주파수 레벨이 반복되는 횟수를 이용하 여, 상기 코드정보를 생성하는 것일 수 있다. 여기서 상기 코드정보를 생성하는 단계는, 각각의 윈도우 내에 나타난 상기 음성신호의 주파수에 대응하는 음계 및 옥타브와, 동일한 음계 및 옥타브를 가지는 윈도우가 연속으로 나타나는 반복횟수를 이용하여, 상기 코드정 보를 생성하는 것일 수 있다. 여기서 상기 코드정보를 생성하는 단계는, 묵음 및 음성의 주파수 범위를 벗어나는 고주파음을 나타내는 기호를 각각 추가하여, 상기 음성신호 내 묵음이나 고주파음이 포함되면 상기 기호들을 이용하여 상기 코드정보를 생성 하는 것일 수 있다. 여기서, 본 발명의 일 실시예에 의한 학습용 음성파일에 대한 전처리 방법은, 상기 전처리 데이터를 이용하여, 상기 학습용 음성파일 내 포함되는 복수의 음성그룹들을 분류하기 위한 N그램 규칙을 생성하는 단계를 더 포함 하는 것일 수 있다. 여기서 상기 N그램 규칙을 생성하는 단계는, 상기 학습용 음성파일 내에 포함된 복수의 음성그룹들에 대한 정보 를 입력받는 것일 수 있다. 여기서 상기 N그램 규칙을 생성하는 단계는, 상기 학습용 음성파일의 전체 분량 중에서, 미리 설정된 시간길이 를 이용하여 상기 N그램 규칙을 생성하는 것일 수 있다. 여기서 상기 복수의 음성그룹은, 화자음, 잡음 및 복수의 화자들이 포함된 경우 2 이상의 화자들의 음성이 혼합 된 충돌음 중 적어도 어느 2 이상을 포함하는 것일 수 있다. 여기서 상기 N그램 규칙을 생성하는 단계는, 상기 코드정보에 포함된 각각의 코드들을 이용하여, 상기 코드들의 연결순서를 기반으로 하는 연결규칙이나, 동일한 연결순서를 가지는 코드들의 빈도를 기반으로 하는 빈도통계를, 각각의 음성그룹별로 생성하는 것일 수 있다. 여기서 상기 N그램 규칙을 생성하는 단계는, 상기 연결순서가 일치하는 코드의 개수가 많거나, 동일한 연결순서 를 가지는 코드들의 빈도가 높을수록 높은 값을 나타내도록 평가값을 설정하고, 상기 평가값이 임계값 이상이면 상기 전처리 데이터가 대응하는 음성그룹에 포함되는 것으로 판별하도록 상기 임계값을 설정하는 것일 수 있다. 본 발명의 일 실시예에 의하면, 하드웨어와 결합하여, 상술한 학습용 음성파일에 대한 전처리 방법을 실행하기 위하여 매체에 저장된 컴퓨터 프로그램을 구현할 수 있다. 본 발명의 일 실시예에 의한 컴퓨팅 장치는, 프로세서를 포함하며, 음성인식 모델 생성을 위한 학습용 음성파일 에 대한 전처리를 수행하는 컴퓨팅 장치에 관한 것으로, 상기 프로세서는 음성인식장치를 이용하여, 학습용 음 성파일 내 음성신호를 텍스트로 변환하고, 상기 텍스트 내에 포함된 각각의 어절들을 분리한 어절정보를 생성하 는 것; 미리 설정된 시간간격의 윈도우를 이용하여, 상기 학습용 음성파일 내 음성신호에 나타난 주파수를 부호 화한 코드정보를 생성하는 것; 및 상기 어절정보 및 코드정보를 동기화하여 전처리 데이터를 생성하는 것을 수 행할 수 있다. 여기서 상기 코드정보를 생성하는 것은, 단위 주파수 간격으로 구분되는 복수의 주파수 레벨 중 상기 음성신호 의 주파수에 대응하는 주파수 레벨과, 연속되는 윈도우 내에서 동일한 주파수 레벨이 반복되는 횟수를 이용하여, 상기 코드정보를 생성하는 것일 수 있다. 여기서 상기 코드정보를 생성하는 것은, 각각의 윈도우 내에 나타난 상기 음성신호의 주파수에 대응하는 음계 및 옥타브와, 동일한 음계 및 옥타브를 가지는 윈도우가 연속으로 나타나는 반복횟수를 이용하여, 상기 코드정 보를 생성하는 것일 수 있다. 여기서, 본 발명의 일 실시예에 의한 컴퓨팅 장치는, 상기 전처리 데이터를 이용하여, 상기 학습용 음성파일 내 포함되는 복수의 음성그룹들을 분류하기 위한 N그램 규칙을 생성하는 것을 더 포함하여 수행하는 것일 수 있다. 여기서 상기 N그램 규칙을 생성하는 것은, 상기 코드정보에 포함된 각각의 코드들을 이용하여, 상기 코드들의 연결순서를 기반으로 하는 연결규칙이나, 동일한 연결순서를 가지는 코드들의 빈도를 기반으로 하는빈도통계를, 각각의 음성그룹별로 생성하는 것일 수 있다. 덧붙여 상기한 과제의 해결수단은, 본 발명의 특징을 모두 열거한 것이 아니다. 본 발명의 다양한 특징과 그에 따른 장점과 효과는 아래의 구체적인 실시형태를 참조하여 보다 상세하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0029215", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 의한 음성인식 모델 생성을 위한 학습용 음성파일의 전처리 방법 및 이를 이용한 컴퓨팅 장치에 의하면, 학습용 음성파일에 대한 전처리를 통하여 음성인식율이 향상된 음성인식모델을 생성하는 것이 가능하다. 본 발명의 일 실시예에 의한 음성인식 모델 생성을 위한 학습용 음성파일의 전처리 방법 및 이를 이용한 컴퓨팅 장치에 의하면, 전처리를 통하여 학습용 음성파일 내 포함된 음성그룹들을 구별하기 위한 N그램 규칙을 자동으 로 생성할 수 있으며, 이를 활용하여 용이하게 각각의 음성그룹들을 구별하는 것이 가능하다."}
{"patent_id": "10-2023-0029215", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실 시할 수 있도록 바람직한 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예를 상세하게 설명함에 있 어, 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 유사한 기능 및 작용을 하는 부분에 대해서는 도면 전체에 걸쳐 동일한 부호를 사용한다. 덧붙여, 명세서 전체에서, 어떤 부분이 다른 부분과 '연결'되어 있다고 할 때, 이는 '직접적으로 연결'되어 있 는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고 '간접적으로 연결'되어 있는 경우도 포함한다. 또한, 어떤 구성요소를 '포함'한다는 것은, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있다는 것을 의미한다. 또한, 명세서에 기재된 \"~부\", \"모듈\" 등의 용어는 적어 도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 와 소프트웨어의 결합으로 구현될 수 있다. 도1은 본 발명의 일 실시예에 의한 음성인식모델 생성 시스템을 나타내는 개략도이다. 도1을 참조하면, 본 발명의 일 실시예에 의한 음성인식모델 생성 시스템은, 전처리 장치 및 학습장치(20 0)를 포함할 수 있다. 전처리 장치는 복수의 학습용 음성파일(d) 내에 포함된 음성신호들에 대한 노이즈 제거 및 화자분리 등의 전처리를 수행할 수 있으며, 전처리된 학습데이터를 학습장치로 제공할 수 있다. 여기서, 학습용 음성파일 (d)은 인공지능 자동응답시스템 등에 적용되는 음성인식 모델(M)을 학습하기 위한 것으로, 실시예에 따라서는 고객과 상담원 사이의 대화를 녹취하여 생성할 수 있다. 학습장치는 전처리된 학습데이터를 기반으로 딥러닝 또는 기계학습 기법으로 학습을 수행하여, 음성인식모 델(M)을 생성할 수 있다. 즉, 학습장치에서 품질이 높은 음성인식모델(M)을 생성할 수 있도록, 전처리 장 치는 학습용 음성파일(d)을 전처리하여 가공할 수 있다. 구체적으로, 도2를 참조하면, 본 발명의 일 실시예에 의한 전처리 장치는 어절정보 생성부, 코드정보 생성 부, 전처리 데이터 생성부 및 N 그램 규칙 생성부를 포함할 수 있다. 먼저, 어절정보 생성부는 음성인식장치를 이용하여, 학습용 음성파일(d) 내 음성신호를 텍스트로 변환하고, 텍스트 내에 포함된 각각의 어절들을 분리한 어절정보를 생성할 수 있다. 여기서, 음성인식장치는 딥 러닝 또는 기계학습을 기반으로 생성한 것으로, 실시예에 따라 다양한 STT(Speech To Text) 알고리즘을 활용할 수 있다. 예를 들어, 도3(a)에 도시한 바와 같이, 학습용 음성파일(d) 내에는 \"안녕하십니까 무엇을 도와 드릴까요 아 예 수고하십니다 네네 지금 소액으로 하고 있는데 그 환율 원달라 인가요 그게 있잖아요 네네 고게 예를들어 제 가\"의 음성이 포함되어 있을 수 있다. 다만, 음성인식장치에서 음성을 텍스트로 변환하는 경우에 인식오류가 발 생할 수 있으며, 그에 따라 도3(b)에 도시한 바와 같이, \"그러십니까 나세요 입니다 무엇을 도와드릴까요 아 예 생각 좀 해 있잖아요 네네 지금 소인 그러는데 네 그 환율 원 달라요 인가요 그거 있잖아요 네네 고객 예를 들 어서 제가\"의 텍스트로 변환될 수 있다. 여기서, 어절정보 생성부는 생성한 텍스트로부터 각각의 어절을 분리하여 어절정보를 생성할 수 있으며, 이때 어절정보에는 학습용 음성파일(d) 내 어절이 나타나는 시작시점 및 종료시점, 어절에 대응하는 텍스트인 어절 텍스트와 어절 텍스트의 정확도를 나타내는 신뢰도 등이 포함될 수 있다. 예를들어, 첫어절인 \"그러십니까\"에 대한 어절정보는 {\"endTime\":730,\"startTime\":100,\"word\":\"그러십니 까\",\"confidence\":0.917}로 생성될 수 있다. 즉, \"그러십니까\"는 학습용 음성파일(d) 내 시작시점 100ms에 시작 되어 종료시점인 730ms 에 종료되는 것으로, 어절 텍스트는 \"그러십니까\"에 해당하고, \"그러십니까\"의 인식의 정확도인 신뢰도는 \"0.917\"에 해당한다. 어절정보 생성부는 수신한 학습용 음성파일(d) 내 포함된 전체 음성신호 또는 전체 음성 신호 중 미리 설 정된 시간길이만큼에 대해 어절 정보를 생성할 수 있다. 도4는 도3(b)에서 인식한 텍스트 \"그러십니까 나세요 입니다 무엇을 도와드릴까요 아 예 생각 좀 해 있잖아요 네네 지금 소인 그러는데 네 그 환율 원 달라요 인가요 그거 있잖아요 네네 고객 예를 들어서 제가\"에 대한 전체 어절 정보를 나타내는 것이다. 코드정보 생성부는 미리 설정된 시간간격의 윈도우를 이용하여, 학습용 음성파일 내 음성신호에 나타난 주 파수를 부호화한 코드정보를 생성할 수 있다. 실시예에 따라서는, 윈도우를 슬라이딩하면서 중첩되는 각각의 시 간구간들에 대해 코드정보를 생성할 수 있다. 여기서, 코드정보 생성부는 단위 주파수 간격으로 구분되는 복수의 주파수 레벨 중 음성신호의 주파수에 대응하는 주파수 레벨과, 연속되는 윈도우 내에서 동일한 주파수 레벨이 반복되는 횟수를 이용하여, 코드정보를 생성할 수 있다. 실시예에 따라서는, 각각의 윈도우 내에 나타난 음성신호의 주파수에 대응하는 음계(A, B, C, D, E, F, G) 및 옥타브와, 동일한 음계 및 옥타브를 가지는 윈도우가 연속으로 나타나는 반복횟수를 이용하여, 코드정보를 생성할 수 있다. 여기서, 음성신호 내에 묵음 및 음성의 주파수 범위를 벗어나는 고주파음 등이 포 함되는 경우가 있을 수 있으며, 이 경우에는 묵음과 고주파음을 나타내는 기호(예를 들어, 묵음은 sil, 고주파 음은 bp)를 각각 추가하여, 코드정보를 생성하도록 할 수 있다. 예를 들어, \"그러십니까\"의 경우 \"B6x3 G2x2 bpx2 B3x3 B6x2 B3x1 A#3x6 A3x2 B6x2 B5x3 G#3x5\"로 나타낼 수 있다. 여기서, B는 음계, 6는 옥타브, x3는 반 복횟수 3을 나타내고, bpx2에서 bp는 고주파음, x2는 반복횟수 2를 각각 나타낸다. 이와 같은 방식으로 각각의 음성신호로부터 코드정보를 생성할 수 있다. 전처리 데이터 생성부는 어절정보 및 코드정보를 동기화하여 전처리 데이터를 생성할 수 있다. 따라서, 각 각의 어절정보에 대응하는 코드정보가 매칭될 수 있으며, 이 경우 도5와 같이 전처리 데이터를 생성할 수 있다. 즉, 각각의 어절 \"그러십니까\". \"나세요\", \"입니다\" 등에 대응하는 각각의 코드정보 \"B6x3 G2x2 bpx2 B3x3 B6x2 B3x1 A#3x6 A3x2 B6x2 B5x3 G#3x5\", \"G#3x1 G3x3 bpx1 C0x1 B5x2 A5x1 B6x2 G#3x7\", \"G#3x1 G3x13\" 등을 매칭 하여 전처리 데이터를 생성할 수 있다. 이후, 전처리 데이터를 기반으로 음성신호 내에 포함된 각각의 음성그룹 을 분리하고 잡음 등을 제거할 수 있다. N 그램 규칙 생성부는 전처리 데이터를 이용하여, 학습용 음성파일 내 포함되는 복수의 음성그룹들을 분류 하기 위한 N그램 규칙을 생성할 수 있다. 여기서, 복수의 음성그룹은 화자음, 잡음 및 충돌음 등을 포함하는 것으로, 충돌음은 복수의 화자들이 포함된 경우 2 이상의 화자들의 음성이 혼합된 소리에 해당한다. N 그램 규칙 생성부는, N그램 규칙을 생성하기 위하여, 먼저 학습용 음성 파일 내에 포함된 복수의 음성그 룹들에 대한 정보를 입력받을 수 있다. 예를 들어, 작업자 등이 학습용 음성 파일 내 포함된 각각의 음성그룹들 을 구별하는 작업을 수행할 수 있으며, N 그램 규칙 생성부는 음성신호 내 각각의 어절들을 발화한 음성그 룹들의 정보를 입력받을 수 있다. 따라서, N그램 규칙 생성부는 입력받은 음성그룹들의 정보를 기반으로 각각의 전처리 데이터의 음성그룹을 구별할 수 있다. 실시예에 따라서는, 미리 설정된 시간길이(예를 들어, 1분) 동안의 음성파일에 대한 각각의 음성그룹들의 정보를 수신할 수 있다. 구체적으로, 도6 내지 도8을 참조하면, 도5에 나타난 전체 전처리 데이터로부터, \"상담사\"가 발화한 음성신호에 대응하는 전처리 데이터, \"고객\"이 발화한 음성신호에 대응하는 전처리 데이터, \"충돌음, 잡음\"에 대응하는 전 처리 데이터를 각각 추출하는 것이 가능하다. 이후, N그램 규칙 생성부는 코드정보에 포함된 각각의 코드들을 이용하여, 코드들의 연결순서를 기반으로 하는 연결규칙이나, 동일한 연결순서를 가지는 코드들의 빈도를 기반으로 하는 빈도통계를, 각각의 음성그룹별 로 생성할 수 있다. 구체적으로, 도9를 참조하면, \"상담사\"가 발화한 음성신호에 대응하는 전처리 데이터로부터 각각의 연결규칙과, 빈도통계를 생성한 예시가 나타나 있다. 먼저 \"상담사\"가 발화한 첫번째 어절인 \"그러십니까\"에 대응하는 코드 정보는 \"B6x3 G2x2 bpx2 B3x3 B6x2 B3x1 A#3x6 A3x2 B6x2 B5x3 G#3x5\"에 해당하고, 여기서, \"B6x3\" 다음에는 \"G2x2\"가 나타남을 확인할 수 있다. 이외에도, 상담사의 전체 발화 중에는 \"B6x3\" 다음에 \"G3x2\", \"E6x1\"이 나 타나는 경우가 존재하며, 이 경우 연결규칙으로 \"B6x3\":[\"G2x2\",\"G3x2\",\"E6x1\"]를 표시할 수 있다. 즉, B6x3 음 뒤에 나올 수 있는 음은 \"G2x2\",\"G3x2\",\"E6x1\" 중에 하나임을 나타내는 것이다. 동일한 방식으로 \"상담사\"가 발화한 전체 전처리 데이터에 포함된 각각의 음에 대해 연결규칙을 생성하면, 도9에 나타난 바와 같이, \"상담사\"에 대한 연결규칙을 생성하는 것이 가능하다. 또한, 빈도통계의 경우, 각각의 음의 다음에 나타나는 음의 출현횟수를 표시하여 나타낼 수 있다. 즉, \"상담 사\"의 발화에서 \"B6x3\" 다음에는 \"G2x2\"가 나타나는 경우, 전체 \"상담사\"의 발화에서 \"B6x3\" 다음에는 \"G2x2\"가 나타나는 횟수를 구하여 표시하는 것이다. 예를 들어, \"B6x3_G2x2\":1 로 표시할 수 있으며, 이는 B6x3 다음에 G2x2 음이 1번 출현했다는 것을 의미한다. 동일한 방식으로 \"상담사\"가 발화한 전체 전처리 데이터에 포함된 각 각의 음에 대해 빈도통계를 생성하면, 도9에 나타난 바와 같이, \"상담사\"에 대한 빈도통계를 생성하는 것이 가 능하다. 여기서, 연결규칙과 빈도통계는 해당 화자의 발음이나 억양, 말투, 말버릇 등을 반영하는 것이므로, 이를 활용 하여 각각의 화자들을 구별하는 것이 가능하다. 한편, 여기서는 연결규칙이나 빈도통계 생성시 1개의 음단위로 확인하는 유니그램 방식을 예시하였으나, 실시예에 따라서는 2개, 3개, ... , N 개의 음단위로 확인하는 N그램 기반으로 연결규칙 또는 빈도통계를 생성하는 것도 가능하다. 이후, N그램 규칙 생성부는, 도10 및 도11에 도시한 바와 같이, 각각의 \"고객\"과 \"충돌음, 잡음\"에 대해서 도 연결규칙 및 빈도통계를 생성할 수 있다. 다음으로, N그램 규칙 생성부는 각각의 화자별로 생성된 연결규칙 및 빈도통계를 활용하여, 각각의 전처리 데이터들을 평가하여 음성그룹 별로 구별할 수 있다. 구체적으로, N그램 규칙 생성부는 음성신호가 입력되 면, 시작오류, 종료오류, 연결오류, 전체길이, 빈도통계값을 반영하여, 각각의 음성그룹에 포함될 확률을 나타 내는 0~1(또는 1~100) 사이의 평가값을 생성하도록 할 수 있다. 여기서, N그램 규칙 생성부는 연결순서가 일치하는 코드의 개수가 많거나, 동일한 연결순서를 가지는 코드 들의 빈도가 높을수록 높은 값을 나타내도록 평가값을 설정할 수 있다. 또한, N그램 규칙 생성부는 평가값 이 임계값 이상이면 전처리 데이터가 대응하는 음성그룹에 포함되는 것으로 판별하도록 임계값을 설정할 수 있 다. 예를 들어, 도12에 도시한 바와 같이, \"고객\"이 발화한 \"인가요\"에 대응하는 코드 데이터인 \"C3x3 B2x7 B0x1 G#3x2 A3x3 A#3x2 B3x3 A#3x1 A3x1\" 를 \"상담사\"에 해당하는 N그램 규칙을 적용하고 계산할 수 있다. 여기서, 연결규칙검사 결과는 {C3x3}*{B2x7}*{B0x1}*{G#3x2}*{A3x3}*{A#3x2}*B3x3*A#3x1_A3x1와 같이 나타날 수 있다. 여기서, 두 개의 코드 가 \"*\"으로 연결된 것은 연결규칙 내에 일치하는 것이 없다는 것을 의미하고, 두개의 코드가 \"_\"로 연결된 것은 연결규칙 내에 일치하는 것이 존재함을 의미한다. 도12를 참조하면, 가장 마지막에 A#3x1_A3x1가 존재하므로, 전체 8개의 연속되는 코드 쌍 중에서 1개만 일치하는 경우에 해당하며, 이에 대한 규칙 평가값은 0.13에 해당한 다. 구체적으로, 규칙 평가값 e = 100/(n.length-2) = 100/7 = 14.28571428571429로 계산할 수 있다. 여기서, n.length는 해당 코드 데이터 내에 포함된 코드의 개수로, 코드 데이터 \"C3x3 B2x7 B0x1 G#3x2 A3x3 A#3x2 B3x3 A#3x1 A3x1\"에서 n.length는 9에 해당한다. 또한, \"상담사\"에 해당하는 N그램 규칙 중에는, 시작하는 코드 가 \"C3x3\"인 경우는 없으므로, 시작 오류에 대한 패널티 e*(0.1) = 1.428571428571429를 적용할 수 있다. 즉, N그램을 이용한 음성분류시 시작 음과 종료 음이 중요하므로, 각각의 시작 오류와 종료 오류에 대한 패널티를 추가할 수 있다. 여기서는, 종료 음이 연결규칙을 만족하는 경우에 해당하므로, 시작 오류만을 반영할 수 있다. 따라서, 시작 오류를 반영한 규칙 평가값은 e - e*(0.1) = 12.85714285714286으로 계산될 수 있으며, 이를 정규 화하면 e = 12.85714285714286/100 = 0.1286에 해당한다. 여기서, 소수점 셋째자리에서 반올림하면, 최종적으로 규칙 평가값 e = 0.13을 구할 수 있다. 또한, 빈도통계검사 결과는, C3x3_B2x7:0/B2x7_B0x1:0/B0x1_G#3x2:0/G#3x2_A3x3:0/A3x3_A#3x2:0/A#3x2_B3x3:0/B3x3_A#3x1:0/A#3x1_A3x1:1 /와 같이 나타날 수 있다. 여기서, 앞의 7쌍의 연속되는 두개 코드들은 \"상담사\"에 해당하는 연결규칙과 일치하 는 경우가 없으므로 전부 0으로 나타날 수 있다. 다만, 마지막 A#3x1_A3x1는 해당 연결규칙과 일치하는 것으로, \"상담사\"의 빈도통계를 확인하면 A#3x1_A3x1가 나타나는 경우는 1번 존재한다. 따라서, A#3x1_A3x1:1로 표시될 수 있다. 이 경우, 빈도 평가값은 0.018로 계산될 수 있다. 즉, A#3x1_A3x1만 연결규칙과 일치하고, 이때의 빈 도통계는 1이므로 빈도누적값 sum = 1 에 해당한다. 따라서, 빈도평가값 ev = e*(sum/(n.length-2)) = 0.1286 * (1/7) = 0.018으로 구할 수 있다(소수점 넷째자리에서 반올림). 여기서는, \"고객\"이 발화한 음성신호를 \"상담사\"에 해당하는 N그램 규칙에 적용한 것으로, 규칙 평가값 및 빈도 평가값 등의 평가값이 낮게 나타남을 확인할 수 있다. 실시예에 따라서는, 각각의 N그램 규칙에 따른 평가값을 도13의 의사코드를 이용하여 구할 수 있다. 구체적으로, 도13을 참조하면, mEvaluateNewSentenceWithAddedNGM_DB는 평가대상문장에 대한 규칙 평가값 및 빈도 평가값 등을 계산하는 함수로, s는 평가대상문장, DB는 적용할 연결규칙이 저장된 데이터베이스, SDB는 적 용할 연결규칙에 따른 빈도통계가 저장된 데이터베이스에 해당한다. 먼저, 연결규칙검사 결과 저장용 변수 ret과 빈도통계검사 결과 저장용 변수 ret_stat를 선언하고, 누적빈도 저 장용 변수 sum과 규칙평가값 e는 각각 초기값 0으로 선언할 수 있다. 여기서, GetLogicalNGrams(s, NGM_N)은 주어진 평가대상문장 s를 미리 정의된 N그램으로 분리하여 생성하는 함수에 해당한다. NGM_N은 평가대상문장을 몇 개의 음단위로 분할할 것인지를 나타내는 변수로, 유니그램의 경우 1로 설정할 수 있다. 다만, n의 개수가 2 보다 작은 경우는 평가대상문장이 너무 짧은 경우에 해당하므로, 예외처리를 위하여 0을 리턴하도록 할 수 있다. 또한, 규칙평가값을 구하기 위한 가중치 w를 100/(n.length-2)로 설정할 수 있다. 이후, 루프(loop)를 이용하여, 평가대상문장 s 내에 대응하는 연결규칙이 포함되는지를 확인할 수 있다. 즉, n[i]를 포함하는 연결규칙이 DB 내에 포함되면 ret에 n[i]를 포함하도록 하고, n[i]를 포함하는 연결규칙 자체 가 DB 내에 포함되지 않으면 ret에 n[i]를 포함하면서 중괄호 {}를 더 포함하도록 할 수 있다. 예를 들어, n [i]가 C3X3고, C3X3에 대한 연결규칙이 DB 내에 존재하지 않으면 ret에 {C3X3}가 포함되도록 할 수 있다. 또한, 평가대상문장에 포함되는 시작 음이 연결규칙 내에 포함되는지를 확인할 수 있으며(if i==0), 시작 음부터 연결 규칙에 포함되지 않은 경우에는 f_start를 true로 설정하여, 시작 오류 발생을 표시할 수 있다. 여기서, n[i]를 포함하는 연결규칙이 DB 내에 포함되고, 다음 n[i+1]과 연결되는 연결규칙이 존재하는 경우에는, 언더바(_)를 포함하여 ret 내에 n[i]와 n[i+1]가 언더바로 연결되도록 할 수 있다. 이때, 규칙평가값e에 가중치 w를 더할 수 있다. 가중치는 100/(n.length-2)로 설정되므로, 규칙평가값은 100이하의 값을 가지게 된다. 반면에, 다음 n[i+1]과 연결되는 연결규칙이 존재하지 않는 경우에는, 별표(*)를 포함하여 ret 내에 n [i]와 n[i+1]가 별표로 연결되도록 할 수 있다. 이후, 평가대상문장 s 내의 n[i]와 n[i+1]을 언더바로 연결한 ht를 선언하고, ht를 SDB에서 검색할 수 있다. 여 기서, SDB 내에 해당 ht가 존재하면, ret_stat에 해당 ht와 ht의 SDB 내 빈도통계값을 포함하도록 할 수 있다. 즉, ht와 빈도통계값 사이에는 콜론(:)이 포함되고, 콜론 이후에 SDB에서 검색된 빈도통계값을 표시한 후 슬래 시(/)를 표시할 수 있다. 반면에, SDB 내에 해당 ht가 존재하지 않으면, ret_stat에 해당 ht, 콜론, 0 및 슬래 시를 포함하도록 하여, 0을 해당 ht에 대한 빈도통계값으로 표시할 수 있다. 상술한 동작을 평가대상문장 s 전체에 대해 수행하도록 루프를 반복할 수 있다. 여기서, 루프가 종료된 이후, 평가대상문장에 포함되는 종료 음에 대한 연결규칙을 확인할 수 있으며, 해당 종료 음이 연결규칙에 포함되지 않는 경우에는 f_end를 true로 설정하여, 종료 오류 발생을 표시할 수 있다. 이후, 시작 오류 또는 종료 오류가 존재하면, 규칙평가값(e)에 각각 (0.1)*e의 패널티를 부여할 수 있으며, 규 칙평가값(e)을 100으로 나누어 0~1 값으로 정규화시킬 수 있다. 또한, 빈도평가값(ev)는 규칙평가값(e)에 빈도 에 대한 가중치(sum/(n.length-2))를 반영하여 구할 수 있다. 최종적으로, 규칙평가값(e), 빈도평가값(ev), 연 결규칙검사 결과(ret)와 빈도통계검사 결과(ret_stat)를 리턴할 수 있다. 추가적으로, 도14를 참조하면, \"상담사\", \"고객\", \"충격음, 잡음\"의 각각의 음성그룹에 포함되는 첫번째 어절에 대응하는 전처리 데이터를, 각각의 N그램 규칙에 적용하여, 각각의 N그램 규칙이 음성그룹들을 구별할 수 있는 지 검증할 수 있다. 구체적으로, \"상담사\"의 첫번째 어절인 \"그러십니까\"는 \"B6x3 G2x2 bpx2 B3x3 B6x2 B3x1 A#3x6 A3x2 B6x2 B5x3 G#3x5\"에 해당하고, \"고객\"의 첫번째 어절인 \"아\"는 \"D6x1 E5x2 D#3x1 E3x5 F3x3 F#3x7\"에 해당하며, \"충격음, 잡음\"의 첫번째 어절인 \"지금\"은 \"B6x3 C#3x5\"에 해당한다. 각각의 전처리 데이터를 상담사 N 그램 규칙, 고객 N 그램 규칙, 잡음 N 그램 규칙에 적용하면, \"상담사\"의 첫 번째 어절인 \"B6x3 G2x2 bpx2 B3x3 B6x2 B3x1 A#3x6 A3x2 B6x2 B5x3 G#3x5\"는 상담사 N 그램 규칙에서 평가값 100이 나오고, 나머지 고객 N 그램 규칙 및 잡음 N 그램 규칙에서는 각각 평가값 0이 나타남을 확인할 수 있다. 마찬가지로 \"고객\"의 첫번째 어절인 \"D6x1 E5x2 D#3x1 E3x5 F3x3 F#3x7\"는 고객 N 그램 규칙에서 평가값 100이 나오고, 나머지 상담사 N 그램 규칙 및 잡음 N 그램 규칙에서는 각각 평가값 0이 나타나며, \"충돌음, 잡음\"의 첫번째 어절인 \"B6x3 C#3x5\"는 잡음 N 그램 규칙에서 평가값 100이 나오고, 나머지 상담사 N 그램 규칙 및 고객 N 그램 규칙에서는 각각 평가값 0이 나타남을 확인할 수 있다. 따라서, 각각의 N그램 규칙을 이용하여, 개별 음 성그룹에 포함되는 음성신호들을 구별할 수 있음을 확인할 수 있다. 한편, N 그램 규칙 생성부는 학습용 음성파일의 전체 분량 중에서, 미리 설정된 시간길이를 이용하여 N그 램 규칙을 생성할 수 있다. 즉, 10분 분량의 학습용 음성 파일 중에서 1분 정도에 해당하는 음성신호에 대해 전 처리 데이터를 생성한 후, 이를 기반으로 N 그램 규칙을 생성하고, 나머지 9분에 N 그램 규칙을 적용하여 각각 의 화자구분 및 잡음 제거 등의 전처리를 수행할 수 있다. 도15는 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 환경을 설명하기 위한 블록도이다. 도시된 실시예 에서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가질 수 있고, 이하에 기술된 것 이외 에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 일 실시예에서, 컴퓨팅 장치는 전처리 장치일 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있 다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실 행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메 모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자 기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치 에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다. 도16은 본 발명의 일 실시예에 의한 음성인식 모델 생성을 위한 컴퓨팅 장치의 학습용 음성파일에 대한 전처리 방법을 나타내는 순서도이다. 여기서, 각 단계들은 본 발명의 일 실시예에 의한 컴퓨팅 장치에 의하여 수행될 수 있다. 도16을 참조하면, 컴퓨팅 장치는, 음성인식장치를 이용하여, 학습용 음성파일 내 음성신호를 텍스트로 변환하고, 텍스트 내에 포함된 각각의 어절들을 분리한 어절정보를 생성할 수 있다(S10). 여기서, 음성인식장치 는 딥러닝 또는 기계학습을 기반으로 생성한 것으로, 실시예에 따라 다양한 STT 알고리즘을 활용할 수 있다. 이 후, 컴퓨팅 장치는 생성된 텍스트로부터 각각의 어절을 분리하여 어절정보를 생성할 수 있으며, 이때 어절정보 에는 학습용 음성파일 내 어절이 나타나는 시작시점 및 종료시점, 어절에 대응하는 텍스트인 어절 텍스트와 어 절 텍스트의 정확도를 나타내는 신뢰도 등이 포함될 수 있다. 이후, 컴퓨팅 장치는, 미리 설정된 시간간격의 윈도우를 이용하여, 학습용 음성파일 내 음성신호에 나타난 주파 수를 부호화한 코드정보를 생성할 수 있다(S20). 실시예에 따라서는, 윈도우를 슬라이딩하면서 중첩되는 각각의 시간구간들에 대해 코드정보를 생성할 수 있다. 여기서, 컴퓨팅 장치는 단위 주파수 간격으로 구분되는 복수의 주파수 레벨 중 음성신호의 주파수에 대응하는 주파수 레벨과, 연속되는 윈도우 내에서 동일한 주파수 레벨이 반복되는 횟수를 이용하여, 코드정보를 생성할 수 있다. 실시예에 따라서는, 각각의 윈도우 내에 나타난 음성신 호의 주파수에 대응하는 음계(A, B, C, D, E, F, G) 및 옥타브와, 동일한 음계 및 옥타브를 가지는 윈도우가 연 속으로 나타나는 반복횟수를 이용하여, 코드정보를 생성하는 것도 가능하다. 추가적으로, 음성신호 내에는 묵음 및 음성의 주파수 범위를 벗어나는 고주파음 등이 포함되는 경우가 있을 수 있으며, 이 경우에는 묵음과 고주파 음을 나타내는 기호(예를 들어, 묵음은 sil, 고주파음은 bp)를 각각 추가하여, 코드정보를 생성하도록 할 수 있 다. 어절정보 및 코드정보가 생성되면, 컴퓨팅 장치는 어절정보 및 코드정보를 동기화하여 전처리 데이터를 생성할 수 있다(S30). 즉, 각각의 어절정보에 대응하는 코드정보를 매칭시켜 전처리 데이터를 생성할 수 있다. 이후, 전처리 데이터를 기반으로 음성신호 내에 포함된 각각의 음성그룹을 분리하고 잡음 등을 제거하도록 할 수 있다. 컴퓨팅 장치는, 전처리 데이터를 이용하여, 학습용 음성파일 내 포함되는 복수의 음성그룹들을 분류하기 위한 N 그램 규칙을 생성할 수 있다(S40). 여기서, 복수의 음성그룹은 화자음, 잡음 및 충돌음 등을 포함하는 것으로, 충돌음은 복수의 화자들이 포함된 경우 2 이상의 화자들의 음성이 혼합된 소리에 해당한다. 컴퓨팅 장치는, N그램 규칙을 생성하기 위하여, 먼저 학습용 음성 파일 내에 포함된 복수의 음성그룹들에 대한 정보를 입력받을 수 있다. 예를 들어, 작업자 등이 학습용 음성 파일 내 포함된 각각의 음성그룹들을 구별하는 작업을 수행할 수 있으며, 컴퓨팅 장치는 음성신호 내 각각의 어절들을 발화한 음성그룹들의 정보를 입력받을 수 있다. 따라서, 컴퓨팅 장치는 입력받은 음성그룹들의 정보를 기반으로 각각의 전처리 데이터의 음성그룹을 구별할 수 있다. 이후, 컴퓨팅 장치는 코드정보에 포함된 각각의 코드들을 이용하여, 코드들의 연결순서를 기반으로 하는 연결규 칙이나, 동일한 연결순서를 가지는 코드들의 빈도를 기반으로 하는 빈도통계를, 각각의 음성그룹별로 생성할 수 있다. 여기서, 연결규칙과 빈도통계는 해당 화자의 발음이나 억양, 말투, 말버릇 등을 반영하는 것이므로, 이를 활용하여 각각의 화자들을 구별하는 것이 가능하다. 한편, 여기서는 연결규칙이나 빈도통계 생성시 1개의 음단 위로 확인하는 유니그램 방식을 예시하였으나, 실시예에 따라서는 2개, 3개, ... , N 개의 음단위로 확인하는 N 그램 기반으로 연결규칙 또는 빈도통계를 생성하는 것도 가능하다. 다음으로, 컴퓨팅 장치는 각각의 화자별로 생성된 연결규칙 및 빈도통계를 활용하여, 각각의 전처리 데이터들을 평가하여 음성그룹 별로 구별할 수 있다. 구체적으로, 컴퓨팅 장치는 음성신호가 입력되면, 시작오류, 종료오류, 연결오류, 전체길이, 빈도통계값을 반영하여, 각각의 음성그룹에 포함될 확률을 나타내는 0~1(또는 1~100) 사이의 평가값을 생성하도록 할 수 있다. 여기서, 컴퓨팅 장치는 연결순서가 일치하는 코드의 개수가 많거나, 동일한 연결순서를 가지는 코드들의 빈도가 높을수록 높은 값을 나타내도록 평가값을 설정할 수 있다. 또한, 평가값이 임계값 이상이면 전처리 데이터가 대 응하는 음성그룹에 포함되는 것으로 판별하도록 임계값을 설정할 수 있다. 한편, 컴퓨팅 장치는 학습용 음성파일의 전체 분량 중에서, 미리 설정된 시간길이를 이용하여 N그램 규칙을 생 성할 수 있다. 즉, 10분 분량의 학습용 음성 파일 중에서 1분 정도에 해당하는 음성신호에 대해 전처리 데이터 를 생성한 후, 이를 기반으로 N 그램 규칙을 생성하고, 나머지 9분에 N 그램 규칙을 적용하여 각각의 화자구분 및 잡음 제거 등의 전처리를 수행할 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장 수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한 적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해 석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2023-0029215", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명은 전술한 실시예 및 첨부된 도면에 의해 한정되는 것이 아니다. 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 있어, 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 본 발명에 따른 구성요소를 치 환, 변형 및 변경할 수 있다는 것이 명백할 것이다."}
{"patent_id": "10-2023-0029215", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 본 발명의 일 실시예에 의한 음성인식모델 생성 시스템을 나타내는 개략도이다. 도2는 본 발명의 일 실시예에 의한 전처리 장치를 나타내는 블록도이다. 도3은 본 발명의 일 실시예에 의한 학습용 음성파일의 음성인식을 나타내는 예시도이다. 도4는 본 발명의 일 실시예에 의한 어절정보 생성을 나타내는 예시도이다. 도5는 본 발명의 일 실시예에 의한 전처리 데이터 생성을 나타내는 예시도이다. 도6 내지 도8은 본 발명의 일 실시예에 의한 전처리 데이터를 상담사, 고객 및 잡음으로 구별한 예시도이다. 도9 내지 도11은 본 발명의 일 실시예에 의한 음성그룹별 연결규칙 및 빈도통계를 나타내는 예시도이다. 도12는 본 발명의 일 실시예에 의한 N 그램 규칙에 따른 평가값 연산을 나타내는 예시도이다. 도13은 본 발명의 일 실시예에 의한 N 그램 규칙에 따른 평가값 연산을 위한 의사코드(pseudocode)이다. 도14는 본 발명의 일 실시예에 의한 각 음성그룹별 전처리 데이터에 대한 검증결과를 나타내는 예시도이다. 도15는 본 발명의 일 실시예에 의한 컴퓨팅 장치를 나타내는 블록도이다. 도16은 본 발명의 일 실시예에 의한 음성인식 모델 생성을 위한 컴퓨팅 장치의 학습용 음성파일에 대한 전처리 방법을 나타내는 순서도이다."}
