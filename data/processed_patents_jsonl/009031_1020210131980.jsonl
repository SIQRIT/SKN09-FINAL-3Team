{"patent_id": "10-2021-0131980", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0048954", "출원번호": "10-2021-0131980", "발명의 명칭": "연합학습을 이용한 버츄어 휴먼 서비스 장치 및 방법", "출원인": "주식회사 도어오픈", "발명자": "이종수"}}
{"patent_id": "10-2021-0131980", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 클라이언트에 구성되며, 사용자 최후 대화 정보에 대한 버츄어 휴먼의 인터렉션 정보를 생성하는 연합학습을 이용한 버츄어 휴먼 서비스 장치에 있어서,상기 사용자 클라이언트에 입력된 상기 사용자 최후 대화 정보 및 사용자 이전 대화 정보를 수신하고, 상기 사용자 이전 대화 정보에 대응되는 상기 버츄어 휴먼의 인터렉션인 버츄어 휴먼 이전 대화 정보를 수신하며, 상기사용자 최후 대화 정보, 상기 사용자 이전 대화 정보 및 상기 버츄어 휴먼 이전 대화 정보를 입력 데이터로 하고 상기 인터렉션 정보를 출력 데이터로 하는 인터렉션 생성 모듈;상기 사용자 최후 대화 정보에서 상기 부적절 텍스트를 상기 적절 텍스트로 치환한 적절 사용자 최후 대화 정보를 이용하여 상기 인터렉션 생성 모듈의 파라미터를 업데이트 하는 클라이언트 학습 모듈;상기 클라이언트 학습 모듈에 의해 업데이트 된 상기 인터렉션 생성 모듈의 상기 파라미터를 유무선 네트워크로연결된 메인 신경망 서버에 업로드 하는 파라미터 업로드 모듈; 및상기 메인 신경망 서버에서 기학습된 인터렉션 생성 메인 신경망을 다운로드 하여 상기 인터렉션 생성 모듈의일부 네트워크와 치환하는 메인 신경망 다운로드 모듈;을 포함하고, 상기 메인 신경망 서버는, 상기 파라미터와 다른 사용자 클라이언트에서 업로드 된 다른 파라미터를 통합하여상기 인터렉션 생성 메인 신경망을 업데이트 하도록 구성되는 것을 특징으로 하는, 연합학습을 이용한 버츄어 휴먼 서비스 장치."}
{"patent_id": "10-2021-0131980", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 연합학습을 이용한 버츄어 휴먼 서비스 장치 및 방법에 관한 것이다. 이를 위하여, 사용자 클라이언트 에 입력된 사용자 최후 대화 정보 및 사용자 이전 대화 정보를 수신하고, 사용자 이전 대화 정보에 대응되는 버 츄어 휴먼의 인터렉션인 버츄어 휴먼 이전 대화 정보를 수신하며, 사용자 최후 대화 정보, 사용자 이전 대화 정 (뒷면에 계속)"}
{"patent_id": "10-2021-0131980", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 연합학습을 이용한 버츄어 휴먼 서비스 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0131980", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 기술의 발달로 인공지능을 이용한 자연어 처리 기술, 음성 처리 기술과 그래픽 처리 기술을 이용 한 버츄어 휴먼이 콘텐츠 시장에서 각광을 받고 있다. 대표적으로, 싸이더스스튜디오엑스의 '로지', 디오비스튜 디오의 '루이', 스캐터랩의 '이루다' 등의 버츄어 휴먼이 서비스 된 바 있으며, 특히 싸이더스스튜디오엑스의 '로지'는 2021년 상반기에 쉐보레 볼트EUV 광고, 레스케이프 광고, 반얀트리 광고 등을 수주하여 10억원 내지 12억원의 광고 매출을 발생시킨 것으로 알려졌다. 미국 기업 중에서는 Brud의 'lil miquela'라는 버츄어 휴먼이 가장 유명하며, 인스타그램, 유튜브, 틱톡을 모두 합하여 약 500만명의 팔로워를 보유하고 있고 샤넬, 프라다, 버버리, 루이비통 등의 광고 모델로 활동하여 2019년 한해에만 약 140억원의 매출을 발생시킨 것으로 알려져있 다. 미국 시장조사 업체인 비즈니스 인사이더 인텔리전스에 따르면 기업이 인플루언스에 쓰는 마케팅 비용은 2019년 80억달러(약 9조원)에서 2020년 150억달러(약 17조원)로 2배 가량 늘어난 것으로 분석되고 있다. 미국 블룸버그통신은 이 자료를 인용해 이 중 상당 부분은 가상 인플루언서가 차지할 것이라고 분석한 바 있다. 이때, 이러한 버츄어 휴먼 기술에서 그래픽 처리 기술은 Style Transfer, StyleGAN, ObamaNet과 같은 GAN 기술 의 발달로 버츄어 휴먼의 그래픽을 상당히 자연스럽게 서비스할 수 있게 되었고, 음성 처리 기술은 Tacotron, Attention is all you need 등의 딥러닝 음성 합성 기술의 발달로 버츄어 휴먼의 음성을 자연스럽게 서비스할 수 있게 되었다. 하지만, 버츄어 휴먼의 인터렉션과 관련된 기술은 그래픽 처리 기술이나 음성 처리 기술에 비 해 그 진보가 미약한 상황이다. 버츄어 휴먼의 인터렉션 기술의 현 실황과 관련하여, 스캐터랩의 '이루다' 사건이 대표적이다. '이루다'는 20대 여성 페르소나를 가진 채팅형 버츄어 휴먼으로서, 2020년 12월 페이스북 메신저를 통해 처음 서비스를 시작하였 다. 하지만, 일부 사용자들이 '이루다'에 성적 발언을 하여 논란이 시작되면서 '이루다'가 개인정보를 출력하는 개인정보 유출 및 정보기본권 문제, '이루다'가 특정 집단 혐오 발언을 출력하는 문제, '이루다'의 학습 데이터 가 승인 받지 않은 카카오톡 채팅 데이터인 문제가 대두되어 결국 2021년 1월에 '이루다'는 서비스를 종료하게 되었고, 개인정보위원회에서는 스캐터랩에 대해 벌금 1.3억원을 처분하였다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 10-2020-0144218, 대화형 유전자 알고리즘을 기반으로 사용자 취향을 반영 한 감정 기반 처리방법, 주식회사 스캐터랩 (특허문헌 0002) 대한민국 공개특허 10-2020-0143764, 감성 교감 서비스 시스템 및 그 방법, 주식회사 스캐터랩"}
{"patent_id": "10-2021-0131980", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명의 목적은 개인정보 유출 문제, 버츄어 휴먼의 부적절 발언(혐오 발언, 성적 발언, 욕설 등)에 대한 학습 및 출력 문제를 해결하기 위한, 웹/앱 상의 메타버스 서비스, 증강현실 서비스, 게임 서비스, 챗봇 서비스, 고객 응대 키오스크, 버추얼 휴먼 등의 서비스에 적용되어 사용자와 텍스트 또는 음성으로 대화하는 연 합학습 기반의 버츄어 휴먼 인터렉션 생성 장치 및 방법을 제공하는데에 있다."}
{"patent_id": "10-2021-0131980", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이하 본 발명의 목적을 달성하기 위한 구체적 수단에 대하여 설명한다. 본 발명의 목적은, 사용자 클라이언트에 구성되며, 사용자 최후 대화 정보에 대한 버츄어 휴먼의 인터렉션 정보 를 생성하는 버츄어 휴먼 인터렉션 생성 장치에 있어서, 상기 사용자 클라이언트에 입력된 상기 사용자 최후 대 화 정보 및 사용자 이전 대화 정보를 수신하고, 상기 사용자 이전 대화 정보에 대응되는 상기 버츄어 휴먼의 인 터렉션인 버츄어 휴먼 이전 대화 정보를 수신하며, 상기 사용자 최후 대화 정보, 상기 사용자 이전 대화 정보 및 상기 버츄어 휴먼 이전 대화 정보를 입력 데이터로 하고 상기 인터렉션 정보를 출력 데이터로 하는 인터렉션 생성 모듈; 상기 사용자 최후 대화 정보를 수신하고, 부적절 텍스트 데이터베이스와 연결되어 상기 부적절 텍스 트 데이터베이스에서 상기 사용자 최후 대화 정보의 각 단어 텍스트를 검색하여 부적절 텍스트의 포함 여부를 의미하는 부적절 여부 정보 및 부적절 텍스트 위치 정보를 출력하는 부적절 인덱싱 모듈; 상기 부적절 여부 정 보가 '분류안됨' class를 포함하는 경우 수행되며, 상기 사용자 최후 대화 정보의 인코딩 벡터인 사용자 최후 대화 벡터, 상기 부적절 텍스트 위치 정보를 입력 데이터로 하고 부적절 스코어를 출력 데이터로 하는 기학습된 인공신경망 모듈인 부적절 스코어링 인공신경망 모듈; 상기 부적절 텍스트를 포함하는 상기 사용자 최후 대화 정보를 입력 데이터로 하고 상기 부적절 텍스트에 대응되는 적절 텍스트를 출력 데이터로 하는 인코더-디코더 결합 구조의 인공신경망 모듈인 적절 텍스트 생성 모듈; 상기 사용자 최후 대화 정보에서 상기 부적절 텍스트를 상기 적절 텍스트로 치환한 적절 사용자 최후 대화 정보를 이용하여 상기 인터렉션 생성 모듈의 파라미터를 업 데이트 하는 클라이언트 학습 모듈; 상기 클라이언트 학습 모듈에 의해 업데이트 된 상기 인터렉션 생성 모듈의 상기 파라미터를 유무선 네트워크로 연결된 메인 신경망 서버에 업로드 하는 파라미터 업로드 모듈; 및 상기 메 인 신경망 서버에서 기학습된 인터렉션 생성 메인 신경망을 다운로드 하여 상기 인터렉션 생성 모듈의 일부 네 트워크와 치환하는 메인 신경망 다운로드 모듈;을 포함하고, 상기 메인 신경망 서버는, 상기 파라미터와 다른 사용자 클라이언트에서 업로드 된 다른 파라미터를 통합하여 상기 인터렉션 생성 메인 신경망을 업데이트 하도 록 구성되는 것을 특징으로 하는, 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치를 제공하여 달성될 수 있다. 또한, 상기 인터렉션 생성 모듈은, 상기 사용자 최후 대화 정보, 상기 사용자 이전 대화 정보 및 상기 버츄어 휴먼 이전 대화 정보를 수신하고 인코딩하여 사용자 최후 대화 벡터, 사용자 이전 대화 벡터 및 버츄어 휴먼 이 전 대화 벡터를 생성하는 대화 인코더; 상기 사용자 최후 대화 벡터, 상기 사용자 이전 대화 벡터 및 상기 버츄 어 휴먼 이전 대화 벡터를 입력 데이터로 하고 전체적인 대화 토픽의 특징을 인코딩 한 토픽 벡터를 출력 데이 터로 하는 토픽 인코더; 및 상기 사용자 최후 대화 벡터 및 상기 토픽 벡터를 입력 데이터로 하고 상기 사용자 최후 대화 벡터에 대한 상기 인터렉션 정보를 출력 데이터로 생성하는 인터렉션 디코더;를 포함하는 것을 특징 으로 할 수 있다. 또한, 상기 적절 텍스트 생성 모듈은, 상기 사용자 최후 대화 정보 및 상기 부적절 텍스트 위치 정보를 수신하 여 상기 부적절 텍스트를 블랭크로 교체하여 마스킹 하는 마스크 모듈; 상기 사용자 최후 대화 정보를 입력 데 이터로 하고 상기 사용자 최후 대화 정보에 대한 감성 분류 정보를 출력 데이터로 하는 감성 분석 모듈; 및 상 기 마스크 모듈에 의해 마스킹 된 상기 사용자 최후 대화 정보의 상기 블랭크에 상기 감성 분류 정보를 삽입하 여 입력 데이터로 하고 상기 부적절 텍스트에 대응되는 상기 적절 텍스트를 출력 데이터로 하는 제너레이터 모 듈;을 포함하는 것을 특징으로 할 수 있다. 또한, 상기 클라이언트 학습 모듈은, 상기 부적절 텍스트에 대해 출력되는 상기 부적절 스코어를 저장하고, 이 후 동일한 상기 부적절 텍스트에 대해 추가로 상기 부적절 스코어가 출력되었을 때 상기 부적절 텍스트에 대한 상기 부적절 스코어들을 통합하여 통합된 상기 부적절 스코어가 기준 스코어 이상인 경우, 상기 부적절 텍스트 가 포함된 상기 사용자 최후 대화 정보에 대한 상기 부적절 스코어를 [1]로 레이블링하여 상기 부적절 스코어링 인공신경망 모듈의 학습 세션을 수행하도록 구성되고, 상기 파라미터 업로드 모듈은, 상기 부적절 스코어링 인 공신경망 모듈의 상기 학습 세션 이후의 상기 파라미터를 상기 메인 신경망 서버에 업로드 할 수 있다. 또한, 상기 인터렉션 생성 모듈에 포함된 인공신경망의 후방 특정 수의 레이어를 업데이트 하고, 상기 인터렉션 생성 모듈에 의해 출력되는 상기 인터렉션 정보를 입력 데이터로 하고 상기 사용자 이전 대화 정보와의 유사도 를 출력 데이터로 하는 스타일 판별기;를 더 포함하며, 상기 유사도가 높아지는 방향으로 상기 인터렉션 생성 모듈의 상기 후방 특정 수의 레이어를 업데이트 하도록 구성될 수 있다. 또한, 상기 파라미터 업로드 모듈은, 상기 파라미터에 노이즈를 합산하여 상기 메인 신경망 서버에 업로드 하고, 상기 노이즈는 양의 값 또는 음의 값으로 랜덤하게 부여되는 것을 특징으로 할 수 있다. 또한, 상기 파라미터 업로드 모듈은, 상기 파라미터와 함께 상기 부적절 스코어를 상기 메인 신경망 서버에 업 로드 하고, 상기 메인 신경망 서버의 상기 인터렉션 생성 메인 신경망을 업데이트는, 상기 부적절 스코어를 상 기 파라미터의 가중치로 사용하여 수행되는 것을 특징으로 할 수 있다. 본 발명의 다른 목적은, 사용자 클라이언트에 구성되며, 사용자 최후 대화 정보에 대한 버츄어 휴먼의 인터렉션 정보를 생성하는 버츄어 휴먼 인터렉션 생성 방법에 있어서, 인터렉션 생성 모듈이, 상기 사용자 클라이언트에 입력된 상기 사용자 최후 대화 정보 및 사용자 이전 대화 정보를 수신하고, 상기 사용자 이전 대화 정보에 대응 되는 상기 버츄어 휴먼의 인터렉션인 버츄어 휴먼 이전 대화 정보를 수신하며, 상기 사용자 최후 대화 정보, 상 기 사용자 이전 대화 정보 및 상기 버츄어 휴먼 이전 대화 정보를 입력 데이터로 하고 상기 인터렉션 정보를 출 력 데이터로 하는 인터렉션 생성 단계; 부적절 인덱싱 모듈이, 상기 사용자 최후 대화 정보를 수신하고, 부적절 텍스트 데이터베이스와 연결되어 상기 부적절 텍스트 데이터베이스에서 상기 사용자 최후 대화 정보의 각 단어 텍스트를 검색하여 부적절 텍스트의 포함 여부를 의미하는 부적절 여부 정보 및 부적절 텍스트 위치 정보를 출 력하는 부적절 인덱싱 단계; 부적절 스코어링 인공신경망 모듈이, 상기 부적절 여부 정보가 '분류안됨' class를 포함하는 경우 수행되며, 상기 사용자 최후 대화 정보의 인코딩 벡터인 사용자 최후 대화 벡터, 상기 부적절 텍 스트 위치 정보를 입력 데이터로 하고 부적절 스코어를 출력 데이터로 하는 부적절 스코어링 인공신경망 단계; 인코더-디코더 결합 구조의 인공신경망 모듈인 적절 텍스트 생성 모듈이, 상기 부적절 텍스트를 포함하는 상기 사용자 최후 대화 정보를 입력 데이터로 하고 상기 부적절 텍스트에 대응되는 적절 텍스트를 출력 데이터로 하 는 적절 텍스트 생성 단계; 클라이언트 학습 모듈이, 상기 사용자 최후 대화 정보에서 상기 부적절 텍스트를 상 기 적절 텍스트로 치환한 적절 사용자 최후 대화 정보를 이용하여 상기 인터렉션 생성 모듈의 파라미터를 업데 이트 하는 클라이언트 학습 단계; 파라미터 업로드 모듈이, 상기 클라이언트 학습 모듈에 의해 업데이트 된 상 기 인터렉션 생성 모듈의 상기 파라미터를 유무선 네트워크로 연결된 메인 신경망 서버에 업로드 하는 파라미터 업로드 단계; 및 메인 신경망 다운로드 모듈이, 상기 메인 신경망 서버에서 기학습된 인터렉션 생성 메인 신경 망을 다운로드 하여 상기 인터렉션 생성 모듈의 일부 네트워크와 치환하는 메인 신경망 다운로드 단계;를 포함 하고, 상기 메인 신경망 서버는, 상기 파라미터와 다른 사용자 클라이언트에서 업로드 된 다른 파라미터를 통합하여 상기 인터렉션 생성 메인 신경망을 업데이트 하도록 구성되는 것을 특징으로 하는, 인공지능 기반의 버츄 어 휴먼 인터렉션 생성 방법을 제공하여 달성될 수 있다."}
{"patent_id": "10-2021-0131980", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같이, 본 발명에 의하면 이하와 같은 효과가 있다. 첫째, 본 발명의 일실시예에 따르면, 개인정보의 유출 없이도 버츄어 휴먼의 인터렉션 생성 인공신경망을 학습 시킬 수 있는 효과가 발생된다. 둘째, 본 발명의 일실시예에 따르면, 사용자가 버츄어 휴먼에게 부적절 발언을 입력한 대화 정보가 버츄어 휴먼 의 인터렉션 생성 인공신경망의 학습 데이터로 사용되어도 버츄어 휴먼이 부적절 발언을 출력하지 않는 효과가 발생된다. 셋째, 본 발명의 일실시예에 따르면, 메인 신경망 모듈에서의 연합 학습 시 부적절 스코어가 파라미터의 가중치로 사용됨으로써 미니 배치(mini batch)의 효과가 발생된다. 넷째, 본 발명의 일실시예에 따르면, 각 클라이언트의 신경망을 메인 신경망으로 완전히 교체하지 않으므로, 인 터렉션 생성 모듈을 계속적으로 업데이트 하면서도 각 클라이언트에서 출력되는 사용자 맞춤형 인터렉션을 유지 할 수 있게 되어 인터렉션의 개인화가 가능해지는 효과가 발생된다. 다섯째, 본 발명의 일실시예에 따르면, 메인 신경망 모듈에서의 연합 학습 시 부적절 스코어가 파라미터의 가중치로 사용됨으로써 네트워크 토폴로지 및 비동기 통신 문제가 저감되는 효과가 발생된다. 여섯째, 본 발명의 일실시예에 따르면, 클라이언트에서 파라미터에 노이즈가 적용되어 메인 신경망 서버에 업로 드 되므로, 제3자가 파라미터를 취득하더라도 대화 정보의 취득이 불가능한 효과가 발생된다. 일곱째, 본 발명의 일실시예에 따르면, 감정 분류 정보가 마스크 모듈에 의해 생성되는 blank에 삽입되어 제너 레이터에 입력되게 됨으로써 부적절 텍스트가 포함된 대화 정보의 감성과 토픽을 벗어나지 않는 범위 내에서 적 절 텍스트가 생성되게 되는 효과가 발생된다."}
{"patent_id": "10-2021-0131980", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작원리를 상세하게 설명함에 있 어서 관련된 공지기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 특정 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 특정 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하 발명의 설명에서 컨볼루져널 곱을 활용한 Neural Network인 Convolutional Neural Network은 CNN, ConvNet 등으로 기재될 수 있다. 이하 발명의 설명에서 '대화' 및 '대화 정보'는 텍스트 정보 또는 음성 정보를 기초로 생성된 텍스트 정보를 모두 포함할 수 있다. 이하 발명의 설명에서 기술되는 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치의 발명의 범위는, 웹/앱 상의 메타버스 서비스, 증강현실 서비스, 게임 서비스, 챗봇 서비스, 고객 응대 키오스크, 버추얼 휴먼 등의 서비스 에 적용되어 사용자와 텍스트 또는 음성으로 대화하는 버츄어 휴먼의 인터렉션을 생성하는 것을 포함할 수 있다. 특히, 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치에서 인터렉션 정보가 텍스트로 출력되도록 기재 되어 있다 하더라도, 본 발명의 범위는 이러한 텍스트 기반의 인터렉션 정보를 기초로 TTS 적용하여 음성 인터 렉션을 서비스하는 것을 배제하지 않는다. 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치 도 1은 본 발명의 일실시예에 따른 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치의 파라미터 업로드 단 계와 메인 신경망 다운로드 단계를 도시한 모식도, 도 2는 본 발명의 일실시예에 따른 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치를 도시한 모식도, 도 3은 본 발명의 일실시예에 따른 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치와 메인 신경망 서버와의 관계를 도시한 모식도이다. 도 1, 2, 3에 도시된 바와 같 이, 본 발명의 일실시예에 따른 인공지능 기반의 버츄어 휴먼 인터렉션 장치는 복수개의 사용자 클라이언트 에 각각 구성되며, 메인 신경망 서버와 유무선 네트워크로 연결되어 클라이언트 학습 단계, 파라미터 업데이트 단계 및 메인 신경망 다운로드 단계를 수행하도록 구성될 수 있다. 또한, 본 발명의 일실시예에 따른 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치는, 인터렉션 생성 모듈, 부적절 텍스트 검출 모듈 , 적절 텍스트 생성 모듈, 클라이언트 학습 모듈, 파라미터 업로드 모듈, 메인 신경망 다운로 드 모듈을 포함하도록 구성될 수 있고, 메인 신경망 서버는 메인 신경망 모듈, 연합 학습 모듈 을 포함하도록 구성될 수 있다. 도 1에 도시된 바와 같이, 클라이언트 학습 단계에서는 클라이언트 신경망(A)을 포함하는 사용자 클라이언트 에서 각각 자체적으로 클라이언트 신경망을 학습하여 각 사용자 클라이언트별로 서로 다른 파라미터 를 갖는 클라이언트 신경망(a,b,c)이 구성되게 된다. 파라미터 업로드 단계에서는 각 사용자 클라이언트별 로 기학습된 클라이언트 신경망(a, b, c)의 파라미터가 메인 신경망 서버에 업로드되고, 메인 신경망 서버 에서는 업로드 된 파라미터를 기초로 메인 신경망(A)이 업데이트(A->A') 된다. 메인 신경망 다운로드 단계 에서는 업데이트 된 메인 신경망(A')이 각각의 사용자 클라이언트에 다운로드 되고, 사용자 클라이언트 에서는 다운로드 된 메인 신경망(A')이 클라이언트 신경망(a,b,c)의 일부를 교체(치환)하도록 전이 (transfer)되어 클라이언트 신경망이 a', b', c'로 업데이트 된다. 이때, 클라이언트 신경망은 인터렉션 생성 모듈, 부적절 텍스트 검출 모듈의 신경망을 의미할 수 있고, 메인 신경망은 인터렉션 생성 메인 신경망, 부적절 스코어링 메인 신경망을 의미할 수 있다. 이에 따르면, 개인정보의 유출 없이도 버츄어 휴먼의 인터렉션 생성 인공신경망을 학습시킬 수 있는 효과가 발 생된다. 또한, 사용자가 버츄어 휴먼에게 부적절 발언을 입력한 대화 정보가 버츄어 휴먼의 인터렉션 생성 인공 신경망의 학습 데이터로 사용되어도 버츄어 휴먼이 부적절 발언을 출력하지 않는 효과가 발생된다. 또한, 각 클 라이언트의 신경망을 메인 신경망으로 완전히 교체하지 않으므로, 인터렉션 생성 모듈을 계속적으로 업데이트 하면서도 각 클라이언트에서 출력되는 사용자 맞춤형 인터렉션을 유지할 수 있게 되어 인터렉션의 개인화가 가 능해지는 효과가 발생된다. 인터렉션 생성 모듈은 사용자 최후 대화 정보 및 이전 대화 정보(사용자 이전 대화 정보 및 버츄어 휴먼 이 전 대화 정보)를 수신하고, 상기 사용자 최후 대화 정보에 대응되는 버츄어 휴먼의 인터렉션인 인터렉션 정보를 생성하는 모듈이다. 도 4는 본 발명의 일실시예에 따른 인터렉션 생성 모듈을 도시한 모식도이다. 도 4에 도시된 바와 같이, 인터렉션 생성 모듈은 대화 인코더, 토픽 인코더, 인터렉션 디코더를 포함 하도록 구성될 수 있다. 대화 인코더와 관련하여, 도 5는 본 발명의 일실시예에 따른 대화 인코더를 도시한 모식도이다. 도 5에 도시된 바와 같이, 대화 인코더는 사용자 최후 대화 정보 및 이전 대화 정보(사용자 이전 대화 정보 및 버 츄어 휴먼 이전 대화 정보)를 수신하고, 각 대화 별로 인코딩하여 사용자 최후 대화 벡터, 사용자 이전 대화 벡 터, 버츄어 휴먼 이전 대화 벡터를 생성하는 모듈이다. 대화 인코더는 대화 정보의 단어를 분해 및 임베딩 하여 단어 벡터를 생성하고, 단어 벡터를 입력 데이터로 하여 대화 벡터를 출력 데이터로 하는 CNN, RNN, LSTM, VAE 등의 임베딩 인공신경망을 포함하도록 구성될 수 있다. 대화 인코더에서 대화 정보(사용자 최후 대화 정보 및 이전 대화 정보)의 형태소를 분류하고 품사를 태깅하여 토큰화하는 처리는 KoNLPy 라이브러리에서 Okt(Open Korean Text) class가 이용될 수 있다. 또한, 대화 인코더에서 토큰화 된 대화 정보를 벡터화 하 는 처리는 임베딩 인공신경망을 통해 one hot encoding 또는 CountVectorization 등의 인코딩 방법이 이용될 수 있다. 사용자 최후 대화 벡터는, 사용자가 버츄어 휴먼에 대해 입력한 최후의 대화 정보인 사용자 최후 대화 정보를 상기 대화 정보 수신 모듈이 수신하여 인코딩 후 출력하는 사용자 최후 대화 정보의 특징을 인코딩 한 벡터를 의미한다. 사용자 이전 대화 벡터는, 사용자가 버츄어 휴먼에 대해 입력한 대화 정보 중 사용자 최후 대화 정보 이전의 대 화 정보인 사용자 이전 대화 정보를 상기 대화 정보 수신 모듈이 수신하여 인코딩 후 출력하는 사용자 이전 대 화 정보의 특징을 인코딩 한 인코딩 벡터를 의미한다. 사용자 이전 대화 벡터는 사용자의 대화 정보에 대한 인 코딩 벡터라는 식별자가 포함될 수 있다. 버츄어 휴먼 이전 대화 벡터는, 버츄어 휴먼이 사용자에 대해 생성한 대화 정보(인터렉션 생성 모듈에 의해 생성된 인터렉션 정보) 중 사용자 최후 대화 정보 이전의 대화 정보인 버츄어 휴먼 이전 대화 정보를 상기 대화 정보 수신 모듈이 수신하여 인코딩 후 출력하는 버츄어 휴먼 이전 대화 정보의 특징을 인코딩 한 인코딩 벡터를 의미한다. 버츄어 휴먼 이전 대화 벡터는 버츄어 휴먼의 대화 정보(인터렉션 정보)에 대한 인코딩 벡터라는 식 별자가 포함될 수 있다. 토픽 인코더와 관련하여, 도 6은 본 발명의 일실시예에 따른 토픽 인코더를 도시한 모식도이다. 도 6에 도시된 바와 같이, 토픽 인코더(12, topic encoder)는, 사용자 최후 대화 벡터, 사용자 이전 대화 벡터 및 버츄 어 휴먼 이전 대화 벡터를 조합한 조합 벡터를 수신하고, 조합 벡터를 인코딩하여 사용자와 버츄어 휴먼의 전체 적인 대화 토픽(topic)의 특징을 인코딩 한 토픽 벡터(topic vector)를 출력하는 모듈이다. 구체적으로, 토픽 인코더는, 사용자 최후 대화 벡터, 사용자 이전 대화 벡터 및 버츄어 휴먼 이전 대화 벡터가 시간 순서대로 순차적으로 입력되도록 입력 데이터가 구성되고, 토픽 벡터가 출력 데이터로 구성되는 GRU(Gated recurrent unit) 셀 또는 LSTM(Long-Short Term Memory) 셀을 포함하는 순환신경망(RNN, Recurrent Neural Network)으로 구성될 수 있다. 예를 들어, 토픽 인코더는, FC(Fully Connected Layer)-ReLU-Dropout-FC-ReLU-Dropout의 n개의 FC Layer 구조로 구성된 Pre-net, n-D Convolution layer, Bidirectional RNN 모듈(forward sequence와 backward sequence를 결합하여 출력)이 연결되어 사용자 최후 대화 벡터, 사용자 이전 대화 벡터 및 버츄어 휴 먼 이전 대화 벡터에 대한 토픽 특징 벡터인 토픽 벡터가 출력되도록 구성될 수 있다. 이때, Pre-net은 dropout 기법을 적용한 2층의 fully connected layer로서 과적합을 방지하고 트레이닝이 수렴하는 것을 돕는 네트워크이다. 특히, n-D Convolution layer는 1D Convolution Bank를 이용하여 unigram 부터 K-gram까지의 길이를 가지는 필 터로 상기 사용자 최후 대화 벡터, 사용자 이전 대화 벡터 및 버츄어 휴먼 이전 대화 벡터를 convolution하고, 그 결과들을 Stacking하도록 구성될 수 있다. 이후 local invariance를 향상시키기 위해 max pooling이 구성되 고, 이때 시간 축의 해상도를 유지하기 위해 stride=1로 구성될 수 있다. 이후의 high level feature들을 추출 하기 위해 몇 층의 1D Convolution을 연산한 뒤 residual connection을 적용하여 1D Convolution의 결과에 상 기 사용자 최후 대화 벡터, 사용자 이전 대화 벡터 및 버츄어 휴먼 이전 대화 벡터를 더한 값이 highway network를 거쳐서 Bidirectional RNN 모듈에 입력되도록 구성될 수 있다. 이때, Highway network는 한 층의 신 경망을 거친 결과와 최초 입력 정보인 상기 사용자 최후 대화 벡터, 사용자 이전 대화 벡터 및 버츄어 휴먼 이 전 대화 벡터를 weighted sum 하는 구조로 구성될 수 있다. 이에 따르면, 이전 대화 정보의 각 대화 정보에 대해 특정 어텐션이 적용되어 이전 대화 정보를 대표하는 토픽 벡터로 출력되게 되므로, 인터렉션 디코더의 출력 데이터인 인터렉션 정보에 전반적인 대화 토픽에 대한 관 련도가 향상되는 효과가 발생된다. 인터렉션 디코더와 관련하여, 도 7은 본 발명의 일실시예에 따른 토픽 인코더를 도시한 모식도이다. 도 7에 도시된 바와 같이, 인터렉션 디코더는, 사용자 최후 대화 벡터 및 토픽 벡터를 조합한 조합 벡터를 수 신하고, 상기 사용자 최후 대화 벡터에 대한 버츄어 휴먼의 인터렉션 정보를 생성하는 디코딩 모듈이다. 구체적 으로, 인터렉션 디코더는, 사용자 최후 대화 벡터와 토픽 벡터가 조합되어 입력되도록 입력 데이터가 구성 되고, 인터렉션 정보가 출력 데이터로 구성되는 GRU(Gated recurrent unit) 셀 또는 LSTM(Long-Short Term Memory) 셀을 포함하는 순환신경망(RNN, Recurrent Neural Network)으로 구성될 수 있다. 구체적으로, 인터렉 션 디코더는, 토픽 인코더에서 생성되는 토픽 벡터(topic vector)와 사용자 최후 대화 벡터가 concatenate된 조합 벡터를 기초로 사용자 최후 대화 정보에 대응되는 버츄어 휴먼의 인터렉션인 인터렉션 정보 를 출력하도록 구성될 수 있다. 특히, 본 발명의 일실시예에 따른 인터렉션 디코더는 time step 당 한 단어 의 인터렉션 텍스트를 출력함으로써 트레이닝 시간, 합성 시간, 모델 사이즈를 저감시킬 수 있다. 예를 들어, 인터렉션 디코더의 첫 번째 time step에서 [그냥]을 출력하고, 첫 번째 time step의 hidden layer weight 를 수신한 인터렉션 디코더의 두 번째 time step에서 [그랬어!]를 출력하고, 두 번째 time step의 hidden layer weight를 수신한 인터렉션 디코더의 세 번째 time step에서 [너는?]을 출력하여, 인터렉션 디코더 에서는 최종적으로 이를 통합한 [그냥 그랬어! 너는?]의 인터렉션 정보를 출력하도록 구성될 수 있다. 또한, 인터렉션 디코더는 스타일 판별기를 더 포함할 수 있고, 스타일 판별기에 의해 인터렉션 디코더의 후방 레이어(최후 n개의 layer)의 파라미터가 업데이트 되도록 구성될 수 있다. 스타일 판별기 는 인터렉션 디코더에 의해 출력되는 인터렉션 정보를 입력 데이터로 하고 사용자 이전 대화 벡터와의 유사도를 출력 데이터로 하여 기학습된 인공신경망 모듈이며, 유사도가 높아지는 방향으로 인터렉션 디코더(1 3)의 후방 레이어의 파라미터를 업데이트 하도록 구성될 수 있다. 이에 따르면, 인터렉션 디코더에 의해 출 력되는 인터렉션 정보가 사용자의 대화 패턴이나 표현 방식과 유사해지도록 인터렉션이 개인화 되는 효과가 발 생된다. 부적절 텍스트 검출 모듈은, 사용자 최후 대화 정보를 수신하고 사용자 최후 대화 정보에 대한 '부적절' class/'분류안됨' class를 인덱싱(indexing)하는 부적절 인덱싱 모듈과 부적절 인덱싱 모듈에서 '분류 안됨' class로 인덱싱되는 경우 사용자 최후 대화 정보, 부적절 텍스트 위치 정보 및 토픽 벡터를 수신하여 부 적절 스코어를 출력하는 부적절 스코어링 인공신경망 모듈을 포함하도록 구성될 수 있다. 부적절 인덱싱 모듈과 관련하여, 도 8은 본 발명의 일실시예에 따른 부적절 인덱싱 모듈을 도시한 모식 도이다. 도 8에 도시된 바와 같이, 부적절 인덱싱 모듈은, 사용자 최후 대화 정보를 입력 데이터로 하고, 사용자 최후 대화 정보의 단어를 분해 및 임베딩하여 단어 텍스트를 생성하고, 단어 텍스트를 입력 데이터로 하 여 부적절 텍스트 데이터베이스에서의 검색을 통해 상기 사용자 최후 대화 정보에 대한 부적절 여부 정보 및 부 적절 텍스트 위치 정보를 출력 데이터로 하는 인덱싱 모듈을 포함하도록 구성될 수 있다. 이때, 부적절 여부 정 보는 '부적절' class/'분류안됨' class를 포함할 수 있으며, 사용자 최후 대화 정보에서 부적절 텍스트의 위치 정보인 부적절 텍스트 위치 정보를 함께 출력하도록 구성될 수 있다. 예를 들어, 부적절 인덱싱 모듈에 [이런 ㅁㅁㅁ]이라는 부적절 텍스트 데이터베이스에 기저장된 비속어가 입력되는 경우, 부적절 인덱싱 모듈에 서는 최종적으로 [부적절]이라는 부적절 여부 정보 및 [2]라는 부적절 텍스트 위치 정보가 출력되도록 구성될 수 있다. 부적절 스코어링 인공신경망 모듈과 관련하여, 도 9는 본 발명의 일실시예에 따른 부적절 스코어링 인공신 경망 모듈을 도시한 모식도이다. 도 9에 도시된 바와 같이, 부적절 스코어링 인공신경망 모듈은, 상기 부적절 인덱싱 모듈에서 '분류안됨' class가 출력되는 경우, 사용자 최후 대화 벡터, 부적절 텍스트 위치 정보 및 토픽 벡터를 입력 데이터로 하고 부적절 스코어를 출력 데이터로 하는 기학습된 인공신경망 모듈로 구 성될 수 있다. 예를 들어, 부적절 인덱싱 모듈에 [이런 ㅁㅁㅁ]이라는 기저장되지 않은 비속어가 입력되는 경우, 부적절 인덱싱 모듈에서는 최종적으로 [분류안됨]이라는 부적절 여부 정보 및 [2]라는 부적절 텍스트 위치 정보가 출력되도록 구성될 수 있고, 부적절 스코어링 인공신경망 모듈에서는 [0.85]라는 부적절 스코 어가 출력되도록 구성될 수 있다. 이에 따르면, 부적절 텍스트 데이터베이스에 기저장되지 않은 비속어와 같은 부적절 텍스트의 경우에도 부적절 스코어링 인공신경망 모듈로 2차적으로 검증하게 되므로 학습 데이터에 존재하지 않는 부적절 텍스트의 검 출이 용이해지고, 부적절 스코어링 인공신경망 모듈에 의해 부적절 텍스트 데이터베이스가 확장될 수 있는 효과가 발생된다. 또한, 부적절 스코어링 인공신경망 모듈만 존재하는 경우보다 컴퓨팅 리소스 및 처리 속 도가 저감되는 효과가 발생된다. 적절 텍스트 생성 모듈과 관련하여, 도 10은 본 발명의 일실시예에 따른 적절 텍스트 생성 모듈을 도시 한 모식도이다. 도 10에 도시된 바와 같이 적절 텍스트 생성 모듈은, 마스크 모듈과 제너레이터 모듈을 포 함하며, 사용자 최후 대화 정보가 부적절 인덱싱 모듈에서 '부적절' class로 검색되거나, 부적절 인덱싱 모 듈에서 '분류안됨' class로 검색되고 부적절 스코어링 인공신경망 모듈에서 부적절 스코어가 특정 스코 어 이상으로 출력되는 경우, 마스크 모듈이 사용자 최후 대화 정보 및 부적절 텍스트 위치 정보를 수신하여 부 적절 텍스트를 마스킹하고, 감성 분석 모듈이 사용자 최후 대화 정보를 수신하여 감성 분류 정보를 출력하며, 마스크된 사용자 최후 대화 정보 및 감성 분류 정보를 적절 텍스트 생성 모듈에 포함된 제너레이터 모듈에 입력하여 마스크 된 부분에 삽입될 적절 텍스트를 출력하는 모듈이다. 마스크 모듈은, 사용자 최후 대화 정보 및 부적절 텍스트 위치 정보를 수신하여 부적절 텍스트를 블랭크(blan k)로 교체하여 마스킹(masking) 하는 모듈이다. 예를 들어, 마스크 모듈에 [이런 ㅁㅁㅁ!]이라는 비속어가 입력 되는 경우, 마스크 모듈에서는 부적절 텍스트를 블랭크(blank) 처리하여 [이런 {blank}!]가 출력되도록 구성될 수 있다. 감성 분석 모듈은, 상기 사용자 최후 대화 정보를 입력 데이터로 하고 사용자 최후 대화 정보에 대한 감성 분류 정보를 생성하는 감성 분류 인공신경망 모듈이다. 감성 분류 정보는, 특정 감성에 대한 class 정보 및 해당 class의 confidence를 포함하도록 구성될 수 있다. 감성 분석 모듈에 이용되는 감성 사전은 기설정된 감성 사전 인 SentiwordNet 등이 활용될 수 있고, 감성 분석 모듈의 학습에는 Naver sentiment corpus와 같이 sentiment 값이 레이블링 된 corpus가 학습 데이터로 이용되도록 구성될 수 있다. 감성 분석 모듈에서 사용자 최후 대화 정보의 형태소를 분류하고 품사를 태깅하여 토큰화하는 처리는 KoNLPy 라이브러리에서 Okt(Open Korean Text) class가 이용될 수 있다. 또한, 감성 분석 모듈에서 토큰화 된 사용자 최후 대화 정보를 벡터화 하는 처리는 one hot encoding 또는 CountVectorization 등의 인코딩 방법이 이용될 수 있다. 감성 분석 모듈에서 벡터화 된 사용자 최후 대화 정보를 입력하여 감성 분류 정보를 생성하는 처리는 인공신경망이나 SVM 등의 머신러닝 기 법이 이용될 수 있고, 예를 들어 Input - Dense(unit 64) - ReLU - Dense(unit 64) - ReLU - Dense(unit 1) - Sigmoid - Output의 네트워크 구조로 구성될 수 있으며, 손실함수로는 binary_crossentropy 등이 사용될 수 있 으며, 학습 세션에서는 RMSProp 옵티마이저를 통해서 경사하강법으로 처리되도록 구성될 수 있다. 예를 들어, 감성 분석 모듈에 [이런 ㅁㅁㅁ!]이라는 비속어가 입력되는 경우, 감성 분석 모듈에서는 최종적으로 [부정,0. 8]이라는 감성 분류 정보가 출력되도록 구성될 수 있다. 제너레이터 모듈은, 마스크 모듈에 의해 마스킹 된 사용자 최후 대화 정보의 블랭크에 상기 감성 분류 정보를 삽입하여 입력 데이터로 하고, 상기 부적절 텍스트에 대응되는 적절 텍스트를 출력 데이터로 출력하는 인코더- 디코더 결합 구조의 인공신경망 모듈이다. 제너레이터 모듈에 의해 출력된 적절 텍스트를 마스킹 된 사용자 최 후 대화 정보의 블랭크에 삽입하여 부적절 텍스트가 적절 텍스트로 교체된 사용자 최후 대화 정보(적절 사용자 최후 대화 정보)가 클라이언트 학습 모듈에 의해 인터렉션 생성 모듈의 학습 세션에 학습 데이터로 이용될 수 있다. 예를 들어, 적절 텍스트 생성 모듈에 [이런 ㅁㅁㅁ!]이라는 비속어가 입력되는 경우, 마스크 모듈에서는 [이런 {blank}!]가 출력되고 감성 분석 모듈에서는 [부정,0.8]이 출력되며, 제너레이터 모듈에서는 [이런 {blank}!]의 blank에 [부정,0.8]를 삽입한 [이런 {부정,0.8}!]를 입력 데이터로 하고, 부적절 텍스트에 대응되는 [나쁜 사람]이라는 적절 텍스트를 출력 데이터로 생성하도록 구성될 수 있다. 제너레이터 모듈의 추론 단계(inference)에서는 마스킹 된 사용자 최후 대화 정보의 블랭크에 상기 감성 분류 정보를 삽입하여 입력 데이터로 수신하고, 상기 부적절 텍스트에 대응되는 적절 텍스트를 출력 데이터로 생성하 도록 구성된다. 제너레이터 모듈의 학습 단계(training)에서는 내츄럴리티 구분 모듈 및 부적절 인덱싱 모듈에 의해 제너레 이터 모듈이 학습되게 되며, 제너레이터 모듈이 마스킹 된 사용자 최후 대화 정보의 블랭크에 상기 감성 분류 정보를 삽입하여 입력 데이터로 수신하고 상기 부적절 텍스트에 대응되는 적절 텍스트를 출력 데이터로 생성하 면 ConvNet 인코더인 기학습된 내츄럴리티 구분 모듈에서 상기 적절 텍스트가 실제 사용자들의 대화 정보와 유 사한지 구분(분류)하게 되며, 제너레이터 모듈에 의해 생성된 적절 텍스트가 기학습된 내츄럴리티 구분 모듈에 서 실제 사용자들의 대화 정보와 유사하지 않은 것으로 구분되게 되는 경우, 제너레이터 모듈에 의해 생성된 적 절 텍스트와 내츄럴리티 구분 모듈에서 실제 사용자들의 대화 정보의 차이(Cross entropy 등 적용)를 기초로 에 러(error, 손실)를 출력하여 제너레이터 모듈을 업데이트하는 방법(예를 들어, Back Propagation)으로 내츄럴리 티 구분 모듈의 출력값에 의해 제너레이터 모듈이 학습되게 된다. 또한, 제너레이터 모듈이 마스킹 된 사용자 최후 대화 정보의 블랭크에 상기 감성 분류 정보를 삽입하여 입력 데이터로 수신하고 상기 부적절 텍스트에 대 응되는 적절 텍스트를 출력 데이터로 생성하면 부적절 인덱싱 모듈에서 상기 적절 텍스트의 부적절 여부 정 보를 출력하게 되며, 제너레이터 모듈에 의해 생성된 적절 텍스트가 입력될 때 부적절 인덱싱 모듈에서 '부 적절' class 또는 '분류안됨' class가 출력되지 않도록 제너레이터 모듈을 업데이트하는 방법(예를 들어, Back Propagation)으로 부적절 인덱싱 모듈의 출력값에 의해 제너레이터 모듈이 학습되게 된다. 이에 따르면, 사용자가 버츄어 휴먼에게 부적절 발언을 입력한 대화 정보가 버츄어 휴먼의 인터렉션 생성 인공 신경망의 학습 데이터로 사용되어도 버츄어 휴먼이 부적절 발언을 출력하지 않는 효과가 발생된다. 또한, 감정 분류 정보가 마스크 모듈에 의해 생성되는 blank에 삽입되어 제너레이터에 입력되게 됨으로써 부적절 텍스트가 포함된 대화 정보의 감성과 토픽을 벗어나지 않는 범위 내에서 적절 텍스트가 생성되게 되는 효과가 발생된다. 클라이언트 학습 모듈은, 상기 부적절 인덱싱 모듈에서 '부적절' class가 출력되거나, '분류안됨' class가 출력되고 부적절 스코어링 인공신경망 모듈에서 부적절 스코어가 특정 스코어 이상으로 출력되는 경우, 사용자 최후 대화 정보에서 부적절 텍스트를 적절 텍스트로 치환(교체)하여 생성한 적절 사용자 최후 대 화 정보와 이전 대화 정보를 이용하여 인터렉션 생성 모듈의 학습 세션을 수행하여 파라미터를 업데이트하 도록 구성될 수 있다. 또한, 클라이언트 학습 모듈은, 특정 부적절 텍스트에 대해 출력되는 부적절 스코어를 저장하고, 이후 동일 한 부적절 텍스트에 대해 추가로 부적절 스코어가 출력되었을 때 해당 부적절 텍스트에 대한 부적절 스코어들을 통합하여 통합된 부적절 스코어가 기준 스코어 이상인 경우, 특정 스코어 이상의 부적절 스코어가 출력된 부적 절 텍스트가 포함된 사용자 최후 대화 정보의 사용자 최후 대화 벡터의 부적절 스코어를 [1]로 레이블링하여 부 적절 스코어링 인공신경망 모듈의 학습 세션을 수행하여 파라미터를 업데이트 하도록 구성될 수 있다. 클라이언트 학습 모듈의 인터렉션 생성 모듈의 학습 세션과 관련하여, 도 11은 본 발명의 일실시예에 따른 클라이언트 학습 모듈의 인터렉션 생성 모듈의 학습 세션을 도시한 모식도이다. 도 11에 도시된 바와 같이, 클라이언트 학습 모듈의 인터렉션 생성 모듈의 학습 세션은 부적절 인덱싱 모듈에서 ' 부적절' class가 출력되거나, 부적절 인덱싱 모듈에서 '분류안됨' class가 출력되고 부적절 스코어링 인공 신경망 모듈에서 부적절 스코어가 특정 스코어 이상으로 출력되는 경우에 수행되며, 적절 사용자 최후 대화 정보와 이전 대화 정보(사용자 이전 대화 정보 및 버츄어 휴먼 이전 대화 정보)를 학습 데이터로 이용하고, 버 츄어 휴먼 최후 대화 정보(사용자 최후 대화 정보 직전에 출력된 최후의 버츄어 휴먼 이전 대화 정보) 및 이전 대화 정보를 입력 데이터로 하고 인터렉션 정보를 출력 데이터로 하며, 적절 사용자 최후 대화 정보를 ground truth로 하여 출력 데이터인 인터렉션 정보와 적절 사용자 최후 대화 정보의 손실(loss)이 작아지는 방향으로 (또는, 유사도가 높아지는 방향으로) 인터렉션 생성 모듈의 파라미터가 업데이트되도록 구성될 수 있다. 또 한, 인터렉션 디코더는 스타일 판별기를 더 포함할 수 있고, 스타일 판별기에 의해 인터렉션 디 코더의 후방 레이어(최후 n개의 layer)의 파라미터가 업데이트 되도록 구성될 수 있다. 스타일 판별기는 인터렉션 디코더에 의해 출력되는 인터렉션 정보를 입력 데이터로 하고 사용자 이전 대화 벡터와의 유 사도(또는 손실)를 출력 데이터로 하여 기학습된 인공신경망 모듈이며, 유사도가 높아지는 방향(또는 손실이 작 아지는 방향)으로 인터렉션 디코더의 후방 레이어의 파라미터를 업데이트 하도록 구성될 수 있다. 클라이언트 학습 모듈의 부적절 스코어링 인공신경망 모듈의 학습 세션과 관련하여, 도 12는 본 발명의 일실시예에 따른 클라이언트 학습 모듈의 부적절 스코어링 인공신경망 모듈의 학습 세션을 도시한 모식 도이다. 도 12에 도시된 바와 같이 클라이언트 학습 모듈의 부적절 스코어링 인공신경망 모듈의 학습 세션은, 상기 부적절 인덱싱 모듈에서 부적절 여부 정보에 '분류안됨' class가 출력되고 부적절 스코어링 인공신경망 모듈에서 부적절 스코어가 특정 스코어 이상으로 출력되고, 이후 동일한 부적절 텍스트에 대해 추가로 부적절 스코어가 출력되었을 때 해당 부적절 텍스트에 대한 부적절 스코어들을 통합하여 통합된 부적절 스코어(통합 부적절 스코어)가 기준 스코어 이상인 경우에 수행되며, 부적절 텍스트를 포함하는 사용자 최후 대 화 정보의 사용자 최후 대화 벡터, 부적절 텍스트 위치 정보 및 토픽 벡터를 입력 데이터로 하고 부적절 스코어 링 정보를 출력 데이터로 하며, [1]을 ground truth로 하여 출력 데이터인 부적절 스코어링 정보와 ground truth의 손실(loss)이 작아지는 방향으로(또는, 유사도가 높아지는 방향으로) 부적절 스코어링 인공신경망 모듈 의 파라미터가 업데이트되도록 구성될 수 있다. 파라미터 업로드 모듈은, 클라이언트 학습 모듈에 의한 인터렉션 생성 모듈 및 부적절 스코어링 인 공신경망 모듈의 학습 세션 이후, 인터렉션 생성 모듈 및 부적절 스코어링 인공신경망 모듈의 변경 된 파라미터 및 부적절 스코어를 메인 신경망 서버의 연합 학습 모듈에 업로드하는 모듈이다. 파라미 터는, 인터렉션 생성 모듈 및 부적절 스코어링 인공신경망 모듈의 학습 세션 이후 그래디언트(g) 또는 인공신경망의 웨이트(w)를 포함할 수 있다. 파라미터 업로드 모듈의 인터렉션 생성 모듈에 대한 파라미 터 업로드 및 부적절 스코어 업로드는 상기 부적절 인덱싱 모듈에서 부적절 여부 정보에 '분류안됨' class 가 출력되고 부적절 스코어링 인공신경망 모듈에서 부적절 스코어가 특정 스코어 이상으로 출력되는 경우에 수행되며, 파라미터 업로드 모듈의 부적절 스코어링 인공신경망 모듈에 대한 파라미터 업로드는 통합 부적절 스코어가 기준 스코어 이상인 경우에 수행되는 부적절 스코어링 인공신경망 모듈의 학습 세션 이후 에 수행되도록 구성될 수 있다. 또한, 파라미터 업로드 모듈은, 인터렉션 생성 모듈 및 부적절 스코어링 인공신경망 모듈의 변경된 파라미터에 노이즈(ε)를 적용하여 메인 신경망 서버에 업로드하도록 구성될 수 있다. 예를 들어, 파라미 터가 그래디언트(g)인 경우, g+ε로 업로드 되도록 구성될 수 있고, 파라미터가 웨이트(w)인 경우 w+ε로 업로 드 되도록 구성될 수 있다. 이때, 노이즈(ε)는 양의 값과 음의 값이 랜덤하게 부여되어 연합 학습 모듈에 서의 연합 학습 시 노이즈의 영향이 최소한으로 적용되도록 구성될 수 있다. 이에 따르면, 클라이언트에서 파라미터에 노이즈가 적용되어 메인 신경망 서버에 업로드 되므로, 제3자가 파라 미터를 취득하더라도 대화 정보의 취득이 불가능한 효과가 발생된다. 메인 신경망 다운로드 모듈은, 메인 신경망 서버의 연합 학습 모듈에 의해 기학습된 인터렉션 생 성 메인 신경망을 다운로드하여 인터렉션 생성 모듈의 일부 네트워크를 치환(교체, 전이)하고, 기학습된 부 적절 스코어링 메인 신경망을 다운로드하여 부적절 스코어링 인공신경망 모듈의 네트워크를 치환(교체, 전 이)하는 모듈이다. 인터렉션 생성 모듈의 네트워크 다운로드는, 메인 신경망 서버의 메인 신경망 모듈에서 기학습된 인터렉션 생성 메인 신경망을 다운로드 받고, 인터렉션 생성 모듈의 일구성인 인터렉션 디코더의 후방 레이어(스타일 판별기에 의해 학습되는 최후 n개의 layer)를 제외한 나머지를 다운로드 받은 인터렉션 생 성 메인 신경망으로 치환(교체, 전이)하도록 구성된다. 이에 따르면, 각 클라이언트의 인터렉션 생성 모듈 의 신경망을 메인 신경망으로 완전히 교체하지 않으므로, 인터렉션 생성 모듈을 계속적으로 업데이트 하면서도 각 클라이언트에서 출력되는 사용자 맞춤형 인터렉션을 유지할 수 있게 되어 인터렉션의 개인화가 가능해지는 효과가 발생된다. 부적절 스코어링 인공신경망 모듈의 네트워크 다운로드는, 메인 신경망 서버의 메인 신경망 모듈(21 0)에서 기학습된 부적절 스코어링 메인 신경망을 다운로드 받고, 부적절 스코어링 인공신경망 모듈을 다운 로드 받은 부적절 스코어링 메인 신경망으로 치환(교체, 전이)하도록 구성된다. 메인 신경망 서버는, 메인 신경망 모듈과 연합 학습 모듈을 포함할 수 있고, 복수의 사용자 클 라이언트에서 업로드되는 인터렉션 생성 모듈 및 부적절 스코어링 인공신경망 모듈의 파라미터를 취합하여 메인 신경망 모듈을 업데이트한 뒤, 기학습된 메인 신경망을 사용자 클라이언트에 다시 배 포하도록 구성되는 서버이다. 메인 신경망 모듈은, 인터렉션 생성 메인 신경망 및 부적절 스코어링 메인 신경망을 포함할 수 있으며, 연 합 학습 모듈에 의해 특정 그래디언트(g) 또는 특정 웨이트(w)로 파라미터가 업데이트되도록 구성될 수 있 다. 인터렉션 생성 메인 신경망은, 인터렉션 생성 모듈에 대응되는 메인 신경망을 의미하고, 부적절 스코어 링 메인 신경망은, 부적절 스코어링 인공신경망 모듈에 대응되는 메인 신경망을 의미한다. 연합 학습 모듈은, 복수의 사용자 클라이언트에서 업로드되는 인터렉션 생성 모듈 및 부적절 스 코어링 인공신경망 모듈의 파라미터 및 부적절 스코어링 인공신경망 모듈의 부적절 스코어를 취합한 뒤, 취합된 부적절 스코어의 합이 특정 스코어 이상인 경우 취합 된 파라미터를 이용하여 메인 신경망 모듈 을 업데이트 하도록 구성되는 모듈이다. 이때, 취합된 파라미터를 이용하여 메인 신경망 모듈을 업데 이트하는 방법은 아래와 같이 부적절 스코어가 파라미터의 가중치로 사용되고, 파라미터의 합산에 부적절 스코 어의 합으로 나눔으로써 파라미터가 부적절 스코어를 기준으로 평균되도록 구성될 수 있다. 파라미터가 그래디언트(g)인 경우, 연합 학습 모듈에서는 아래의 수학식과 같이 메인 신경망 모듈의 파라미터를 업데이트 하도록 구성될 수 있다. 수학식 1"}
{"patent_id": "10-2021-0131980", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위 수학식 1에서, wnew는 메인 신경망 모듈의 업데이트 후 웨이트, wold는 메인 신경망 모듈의 업데이 트 이전 웨이트, α는 learning rate, sn은 사용자 클라이언트 n에서 업로드 된 부적절 스코어, gn은 사용 자 클라이언트 n에서 업로드 된 그래디언트를 의미하도록 구성될 수 있다. 파라미터가 웨이트(w)인 경우, 연합 학습 모듈에서는 아래의 수학식과 같이 메인 신경망 모듈의 파라 미터를 업데이트 하도록 구성될 수 있다. 수학식 2"}
{"patent_id": "10-2021-0131980", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "위 수학식 1에서, wnew는 메인 신경망 모듈의 업데이트 후 웨이트, sn은 사용자 클라이언트 n에서 업 로드 된 부적절 스코어, wn은 사용자 클라이언트 n에서 업로드 된 웨이트를 의미하도록 구성될 수 있다. 이에 따르면, 메인 신경망 모듈에서의 연합 학습 시 부적절 스코어가 파라미터의 가중치로 사용됨으로써 미니 배치(mini batch)의 효과가 발생된다. 또한, 메인 신경망 모듈에서의 연합 학습 시 부적절 스코어가 파라미터의 가중치로 사용됨으로써 네트워크 토폴로지 및 비동기 통신 문제가 저감되는 효과가 발생된다. 이상에서 설명한 바와 같이, 본 발명이 속하는 기술 분야의 통상의 기술자는 본 발명이 그 기술적 사상이나 필 수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로상술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범 위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함하는 것으로 해석되어야 한다. 본 명세서 내에 기술된 특징들 및 장점들은 모두를 포함하지 않으며, 특히 많은 추가적인 특징들 및 장점들이 도면들, 명세서, 및 청구항들을 고려하여 당업자에게 명백해질 것이다. 더욱이, 본 명세서에 사용된 언어는 주 로 읽기 쉽도록 그리고 교시의 목적으로 선택되었고, 본 발명의 주제를 묘사하거나 제한하기 위해 선택되지 않 을 수도 있다는 것을 주의해야 한다. 본 발명의 실시예들의 상기한 설명은 예시의 목적으로 제시되었다. 이는 개시된 정확한 형태로 본 발명을 제한 하거나, 빠뜨리는 것 없이 만들려고 의도한 것이 아니다. 당업자는 상기한 개시에 비추어 많은 수정 및 변형이 가능하다는 것을 이해할 수 있다. 그러므로 본 발명의 범위는 상세한 설명에 의해 한정되지 않고, 이를 기반으로 하는 출원의 임의의 청구항들에 의해 한정된다. 따라서, 본 발명의 실시예들의 개시는 예시적인 것이며, 이하의 청구항에 기재된 본 발명의 범 위를 제한하는 것은 아니다."}
{"patent_id": "10-2021-0131980", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 발명의 상세한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어 해석되어서는 아니 된다. 도 1은 본 발명의 일실시예에 따른 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치의 파라미터 업로드 단 계와 메인 신경망 다운로드 단계를 도시한 모식도, 도 2는 본 발명의 일실시예에 따른 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치를 도시한 모식도, 도 3은 본 발명의 일실시예에 따른 인공지능 기반의 버츄어 휴먼 인터렉션 생성 장치와 메인 신경망 서버 와의 관계를 도시한 모식도, 도 4는 본 발명의 일실시예에 따른 인터렉션 생성 모듈을 도시한 모식도, 도 5는 본 발명의 일실시예에 따른 대화 인코더를 도시한 모식도, 도 6은 본 발명의 일실시예에 따른 토픽 인코더를 도시한 모식도, 도 7은 본 발명의 일실시예에 따른 토픽 인코더를 도시한 모식도, 도 8은 본 발명의 일실시예에 따른 부적절 인덱싱 모듈을 도시한 모식도, 도 9는 본 발명의 일실시예에 따른 부적절 스코어링 인공신경망 모듈을 도시한 모식도, 도 10은 본 발명의 일실시예에 따른 적절 텍스트 생성 모듈을 도시한 모식도, 도 11은 본 발명의 일실시예에 따른 클라이언트 학습 모듈의 인터렉션 생성 모듈의 학습 세션을 도시한모식도, 도 12는 본 발명의 일실시예에 따른 클라이언트 학습 모듈의 부적절 스코어링 인공신경망 모듈의 학습 세션을 도시한 모식도이다."}
