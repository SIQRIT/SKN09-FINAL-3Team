{"patent_id": "10-2019-0113317", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0032074", "출원번호": "10-2019-0113317", "발명의 명칭": "트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴", "출원인": "포항공과대학교 산학협력단", "발명자": "유인경"}}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "워드 라인, 비트 라인, 및 커패시터와 연결되는 트랜지스터; 및상기 트랜지스터와 연결되는 커패시터를 포함하되,상기 비트 라인의 입력은 펄스 발진기(pulse generator)와 연결되고 출력은 센스 앰프(Sense Amplifier)와 연결되는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 센스 앰프와 상기 비트 라인 사이에 배치되는 선택 트랜지스터를 더 포함하는 트랜지스터-커패시터 쌍으로가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 센스 앰프와 상기 선택 트랜지스터 사이에 배치되는 다이오드를 더 포함하는 트랜지스터-커패시터 쌍으로가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 센스 앰프와 상기 다이오드 사이에 배치되는 어큐뮬레이터(accumulator)를 더 포함하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 센스 앰프와 상기 어큐뮬레이터 사이에 배치되는 선별용 선택 트랜지스터를 더 포함하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서,상기 센스 앰프와 선별용 선택트랜지스터 사이에 선별기(discriminator)를 더 포함하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 2항에 있어서,상기 비트 라인과 상기 펄스 발진기 사이에 위치한 다이오드를 더 포함하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 선택 트랜지스터의 그라운드에 해당하는 P웰(p-well)을 상기 다이오드와 상기 펄스 발진기 사이에 연결하는 배선을 더 포함하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈공개특허 10-2021-0032074-3-뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1항에 있어서,상기 워드 라인에 인가되는 전압은 일정한 전압이고, 상기 비트 라인에 인가되는 전압은 입력 신호에 대응하는펄스 전압인 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1항에 있어서,상기 비트 라인에 인가되는 펄스 전압은 상기 커패시터 플레이트에 인가되는 상시 전압의 두 배 이상인 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "워드 라인, 비트 라인, 및 커패시터와 연결되는 트랜지스터;상기 트랜지스터와 연결되는 커패시터; 및상기 커패시터에 연결되는 플레이트를 포함하되, 상기 비트 라인의 입력은 펄스 발진기(pulse generator)와 연결되고 출력은 센스 앰프(Sense Amplifier)와 연결되는 가중치 셀들을 포함하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 가중치 셀들의 워드 라인에 순차적으로 전압을 인가하여 순차적으로 행렬 곱셈(Matrix Multiplication)을수행하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,상기 행렬 곱셈의 출력 정보를 차기 은닉층의 입력 정보로 사용하여 행렬 곱셈을 수행하는 트랜지스터-커패시터쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 행렬 곱셈을 반복적으로 수행한 결과에 대한 반복 횟수 정보, 가중치 정보, 입력 정보, 출력 정보 및 은닉층 정보를 저장하는 상기 뉴럴 네트워크 외부의 저장 매체를 더 포함하는 트랜지스터-커패시터 쌍으로 가중치를조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11항에 있어서,상기 가중치 셀들의 두개 이상의 워드 라인을 선택하여 게이트 전압을 동시에 인가함으로써 순차적으로 행렬 곱셈을 수행하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "워드 라인, 비트 라인, 및 커패시터와 연결되는 트랜지스터; 상기 트랜지스터와 연결되는 커패시터; 및 상기 커공개특허 10-2021-0032074-4-패시터에 연결되는 플레이트를 포함하되, 상기 비트 라인의 입력은 펄스 발진기(pulse generator)와 연결되고출력은 센스 앰프(Sense Amplifier)와 연결되는 제1 가중치 셀들; 및워드 라인, 비트 라인, 및 커패시터와 연결되는 트랜지스터; 상기 트랜지스터와 연결되는 커패시터; 및 상기 커패시터에 연결되는 플레이트를 포함하되, 상기 비트 라인은 상기 제1 가중치 셀들의 출력 및 센스 앰프(SenseAmplifier)와 연결되는 제2 가중치 셀들을 포함하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16항에 있어서,상기 제1 가중치 셀들의 출력과 상기 제2 가중치 셀들의 입력 사이에 배치되는 다이오드를 더 포함하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 16항에 있어서,상기 제1 가중치 셀들의 워드 라인에 순차적으로 전압을 인가하여 순차적으로 행렬 곱셈(MatrixMultiplication)을 수행하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18항에 있어서,상기 행렬 곱셈의 출력 정보를 상기 제2 가중치 셀들에 저장하고 차기 은닉층의 입력 정보로 사용하여 행렬 곱셈을 수행하는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19항에 있어서,상기 제2 가중치 셀들은 상기 제1 가중치 셀들에서 방전되는 전하들을 모으는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크."}
{"patent_id": "10-2019-0113317", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예에 따른 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크는 워드 라인, 비트 라인, 및 커패시터와 연결되는 트랜지스터와, 트랜지스터와 연결되는 커패시터 를 포함하되, 비트 라인의 입력은 펄스 발진기(pulse generator)와 연결되고 출력은 센스 앰프(Sense Amplifier)와 연결된다."}
{"patent_id": "10-2019-0113317", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 뉴럴 네트워크에 관한 것으로서, 보다 상세하게는 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크에 관한 것이다."}
{"patent_id": "10-2019-0113317", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "모바일용 뉴럴 프로세서는 학습을 서버나 컴퓨터로 수행하고 학습결과를 모바일 뉴럴 프로세서에 저장하여 추론 (inference)을 수행한다. 이 때 뉴럴 프로세서의 가중치에 저장되는 값은 멀티레벨이 되는 것이 바람직하나 멀 티레벨 값에 한계가 있어서 학습을 수행한 후 전지 작업(pruning), 데이터 압축 등의 과정을 거쳐 작은 비트폭 (small bit-width)화 한 다음 그 값을 모바일 뉴럴 프로세서 가중치로 저장한다. 이 가중치는 불휘발성 메모리 또는 휘발성 메모리에 저장할 수 있다. 서버용으로는 Google의 TPU(Tensor Processing Unit)가 있는데 가중치 값을 DRAM에 저장한 후 페치(fetch)하여 행렬 곱셈부(matrix multiply unit, MMU)로 보낸다. 출력(output) 계산 결과는 DRAM에 저장된 새로운 가중치 값과 함께 다시 행렬 곱셈부 입력(input)으로 보내어 최종 출력(output) 결과가 나올 때까지 순환시킨다. 가중치를 불휘발성 메모리에 저장하여 사용하는 경우에는 추론 속도가 빠른 장점이 있으나 은닉층(hidden layer)을 모두 제작해야 하므로 회로 오버헤드(circuit overhead)가 증가하는 단점이 있다. Google의 TPU같은 경우는 가중치 정보를 뉴럴 네트워크 외부에 저장하고, 동일한 뉴럴 네트위크를 다시 사용하면서 순차적으로 계산하기 때문에 추론 속도는 감소하지만 회로 오버헤드를 줄일 수 있다. 커패시턴스 기반 행렬 곱셈(matrix multiplication)은 커패시턴스를 가중치로 사용한다. 가중치를 결정하기 위 해 커패시터들을 그룹으로 묶거나 커패시터의 크기를 바꾸는 방법이 있다. 위 기재된 내용은 오직 본 발명의 기술적 사상들에 대한 배경 기술의 이해를 돕기 위한 것이며, 따라서 그것은 본 발명의 기술 분야의 당업자에게 알려진 선행 기술에 해당하는 내용으로 이해될 수 없다."}
{"patent_id": "10-2019-0113317", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 인공지능 학습에서 학습결과를 수행하기 위한 가중치 조절 방법에 관한 뉴럴 네트워크 구성 및 작동 원리이다 가중치 소자를 하드웨어를 이용하여 멀티레벨로 제작한다는 것은 물리적 한계가 있기 때문에, 소프트웨어에서 사용하는 가중치 비트폭(weight bit-width)을 따라갈 수 없다. 예를 들어서 16 비트폭의 멀티레벨, 즉, 65,536 저항 레벨을 갖는 저항 메모리 소재는 현재로서는 구현하기 어렵다. 따라서 가중치 값을 소프트웨어만큼 탄력적 으로 입력하면서 행렬 곱셈이 가능한 행렬 곱셈부의 구조와 작동 방법을 고안해야 한다. 커패시터의 크기를 바꾸는 방법은 여러 크기의 커패시터를 제작한 후 필요한 크기를 선택하는 방법이고 커패시 터를 묶는 방법은 여러 커패시터를 동시에 작동하는 방법이다. 이러한 경우 회로가 복잡해지고 특히 비트 라인 커패시턴스(bit line capacitance) 같은 기생 커패시턴스(parasitic capacitance)의 영향을 받는다. 또한, 은 닉층을 필요한 만큼 제작하는 것이 칩(chip) 크기에 제약을 주는 또 하나의 문제가 된다."}
{"patent_id": "10-2019-0113317", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위하여 본 발명의 실시예에 따른 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱셈 뉴럴 네트워크는, 워드 라인, 비트 라인, 및 커패시터와 연결되는 트랜지스터 와; 상기 트랜지스터와 연결되는 커패시터를 포함하되, 상기 비트 라인의 입력은 펄스 발진기(pulse generato r)와 연결되고 출력은 센스 앰프(Sense Amplifier)와 연결된다. 상기 센스 앰프와 상기 비트 라인 사이에 배치되는 선택 트랜지스터를 더 포함할 수 있다. 상기 센스 앰프와 상기 선택 트랜지스터 사이에 배치되는 다이오드를 더 포함할 수 있다. 상기 센스 앰프와 상기 다이오드 사이에 배치되는 어큐뮬레이터(accumulator)를 더 포함할 수 있다. 상기 센스 앰프와 상기 어큐뮬레이터 사이에 배치되는 선별용 선택 트랜지스터를 더 포함할 수 있다. 상기 센스 앰프와 선별용 선택트랜지스터 사이에 선별기(discriminator)를 더 포함할 수 있다. 상기 비트 라인과 상기 펄스 발진기 사이에 위치한 다이오드를 더 포함할 수 있다. 상기 선택 트랜지스터의 그라운드에 해당하는 P웰(p-well)을 상기 다이오드와 상기 펄스 발진기 사이에 연결하 는 배선을 더 포함할 수 있다. 상기 워드 라인에 인가되는 전압은 일정한 전압이고, 상기 비트 라인에 인가되는 전압은 입력 신호에 대응할 수 있다. 상기 비트 라인에 인가되는 펄스 전압은 상기 커패시터 플레이트에 인가되는 상시 전압의 두 배 이상일 수 있다. 본 발명의 실시예에 따른 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱 셈 뉴럴 네트워크는, 워드 라인, 비트 라인, 및 커패시터와 연결되는 트랜지스터와; 상기 트랜지스터와 연결되 는 커패시터와; 상기 커패시터에 연결되는 플레이트를 포함하되, 상기 비트 라인의 입력은 펄스 발진기(pulse generator)와 연결되고 출력은 센스 앰프(Sense Amplifier)와 연결되는 가중치 셀들을 포함한다. 상기 가중치 셀들의 워드 라인에 순차적으로 전압을 인가하여 순차적으로 행렬 곱셈(Matrix Multiplication)을 수행할 수 있다. 상기 행렬 곱셈의 출력 정보를 차기 은닉층의 입력 정보로 사용하여 행렬 곱셈을 수행할 수 있다. 상기 행렬 곱셈을 반복적으로 수행한 결과에 대한 반복 횟수 정보, 가중치 정보, 입력 정보, 출력 정보 및 은닉 층 정보를 저장하는 상기 뉴럴 네트워크 외부의 저장 매체를 더 포함할 수 있다. 상기 가중치 셀들의 두개 이상의 워드 라인을 선택하여 게이트 전압을 동시에 인가함으로써 순차적으로 행렬 곱 셈을 수행할 수 있다. 본 발명의 실시예에 따른 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순차 행렬 곱 셈 뉴럴 네트워크는, 워드 라인, 비트 라인, 및 커패시터와 연결되는 트랜지스터; 상기 트랜지스터와 연결되는 커패시터; 및 상기 커패시터에 연결되는 플레이트를 포함하되, 상기 비트 라인의 입력은 펄스 발진기(pulse generator)와 연결되고 출력은 센스 앰프(Sense Amplifier)와 연결되는 제1 가중치 셀들과; 워드 라인, 비트 라 인, 및 커패시터와 연결되는 트랜지스터; 상기 트랜지스터와 연결되는 커패시터; 및 상기 커패시터에 연결되는 플레이트를 포함하되, 상기 비트 라인은 상기 제1 가중치 셀들의 출력 및 센스 앰프(Sense Amplifier)와 연결되 는 제2 가중치 셀들을 포함한다. 상기 제1 가중치 셀들의 출력과 상기 제2 가중치 셀들의 입력 사이에 배치되는 다이오드를 더 포함할 수 있다. 상기 제1 가중치 셀들의 워드 라인에 순차적으로 전압을 인가하여 순차적으로 행렬 곱셈(Matrix Multiplication)을 수행할 수 있다. 상기 행렬 곱셈의 출력 정보를 상기 제2 가중치 셀들에 저장하고 차기 은닉층의 입력 정보로 사용하여 행렬 곱 셈을 수행할 수 있다. 상기 제2 가중치 셀들은 상기 제1 가중치 셀들에서 방전되는 전하들을 모을 수 있다."}
{"patent_id": "10-2019-0113317", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이와 같은 본 발명의 실시예에 따른 트랜지스터-커패시터 쌍으로 가중치를 조절할 수 있는 커패시턴스 기반 순 차 행렬 곱셈 뉴럴 네트워크는, 가중치와 은닉층 수를 탄력적으로 조절할 수 있으며, 회로 부하를 줄일 수 있고 행렬 곱셈 유닛 칩 크기(matrix multiplication unit chip size)도 최소화할 수 있다."}
{"patent_id": "10-2019-0113317", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "위 발명의 배경이 되는 기술 란에 기재된 내용은 오직 본 발명의 기술적 사상에 대한 배경 기술의 이해를 돕기 위한 것이며, 따라서 그것은 본 발명의 기술 분야의 당업자에게 알려진 선행 기술에 해당하는 내용으로 이해될 수 없다. 아래의 서술에서, 설명의 목적으로, 다양한 실시예들의 이해를 돕기 위해 많은 구체적인 세부 내용들이 제시된 다. 그러나, 다양한 실시예들이 이러한 구체적인 세부 내용들 없이 또는 하나 이상의 동등한 방식으로 실시될 수 있다는 것은 명백하다. 다른 예시들에서, 잘 알려진 구조들과 장치들은 다양한 실시예들을 불필요하게 이해 하기 어렵게 하는 것을 피하기 위해 블록도로 표시된다. 도면에서, 레이어들, 필름들, 패널들, 영역들 등의 크기 또는 상대적인 크기는 명확한 설명을 위해 과장될 수 있다. 또한, 동일한 참조 번호는 동일한 구성 요소를 나타낸다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 그러나, 만약 어떤 부분이 다른 부분과 \"직접적으로 연결되어 있다\"고 서술되어 있으면, 이는 해당 부분과 다른 부분 사이에 다른 소자가 없음을 의미할 것이다. \"X, Y, 및 Z 중 적어도 어느 하나\", 그리고 \"X, Y, 및 Z로 구성된 그룹으로부터선택된 적어도 어느 하나\"는 X 하나, Y 하나, Z 하나, 또는 X, Y, 및 Z 중 둘 또는 그 이상의 어떤 조합 (예를 들면, XYZ, XYY, YZ, ZZ) 으로 이해될 것이다. 여기에서, \"및/또는\"은 해당 구성들 중 하나 또는 그 이상의 모 든 조합을 포함한다. 여기에서, 첫번째, 두번째 등과 같은 용어가 다양한 소자들, 요소들, 지역들, 레이어들, 및/또는 섹션들을 설명 하기 위해 사용될 수 있지만, 이러한 소자들, 요소들, 지역들, 레이어들, 및/또는 섹션들은 이러한 용어들에 한 정되지 않는다. 이러한 용어들은 하나의 소자, 요소, 지역, 레이어, 및/또는 섹션을 다른 소자, 요소, 지역, 레 이어, 및 또는 섹션과 구별하기 위해 사용된다. 따라서, 일 실시예에서의 첫번째 소자, 요소, 지역, 레이어, 및 /또는 섹션은 다른 실시예에서 두번째 소자, 요소, 지역, 레이어, 및/또는 섹션이라 칭할 수 있다. \"아래\", \"위\" 등과 같은 공간적으로 상대적인 용어가 설명의 목적으로 사용될 수 있으며, 그렇게 함으로써 도면 에서 도시된 대로 하나의 소자 또는 특징과 다른 소자(들) 또는 특징(들)과의 관계를 설명한다. 이는 도면 상에 서 하나의 구성 요소의 다른 구성 요소에 대한 관계를 나타내는 데에 사용될 뿐, 절대적인 위치를 의미하는 것 은 아니다. 예를 들어, 도면에 도시된 장치가 뒤집히면, 다른 소자들 또는 특징들의 \"아래\"에 위치하는 것으로 묘사된 소자들은 다른 소자들 또는 특징들의 \"위\"의 방향에 위치한다. 따라서, 일 실시예에서 \"아래\" 라는 용어 는 위와 아래의 양방향을 포함할 수 있다. 뿐만 아니라, 장치는 그 외의 다른 방향일 수 있다 (예를 들어, 90도 회전된 혹은 다른 방향에서), 그리고, 여기에서 사용되는 그런 공간적으로 상대적인 용어들은 그에 따라 해석된 다. 여기에서 사용된 용어는 특정한 실시예들을 설명하는 목적이고 제한하기 위한 목적이 아니다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다 고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제 외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 다른 정의가 없는 한, 여기에 사용된 용어들은 본 발명이 속하는 분야에서 통상적인 지식을 가진 자에게 일반적으로 이해되는 것과 같은 의미를 갖는 다. 도 1은 본 발명의 일 실시예에 따른 뉴럴 네트워크를 개략적으로 나타내는 회로도이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 뉴럴 네트워크(neural network)는 입력 뉴런, 출력 뉴런 , 및 가중치 셀을 포함한다. 시냅스 소자는 입력 뉴런으로부터 수평으로 연장하는 로우 라인 (R)(row lines) 및 출력 뉴런으로부터 수직으로 연장하는 컬럼 라인(C)(column lines)의 교차점에 배치될 수 있다. 설명의 편의를 위해 도 1에는 예시적으로 각각 네 개의 입력 뉴런 및 출력 뉴런이 도시되었으 나, 본 발명은 이에 한정되지 않는다. 입력 뉴런은 학습 모드(learning mode), 리셋 모드(reset mode), 보정 또는 읽기 모드(reading mode)에서 로우 라인(R)을 통하여 가중치 셀로 전기적 펄스들(pulses)을 전송할 수 있다. 출력 뉴런은 학습 모드 또는 리셋 모드 또는 보정 또는 읽기 모드에서 컬럼 라인(C)을 통하여 가중치 셀 로부터 전기적 펄스를 수신할 수 있다. 도 2는 본 발명의 일 실시예에 따른 뉴럴 네트워크의 가중치 셀을 개략적으로 나타내는 회로도이다. 도 3은 본 발명의 일 실시예에 따른 뉴럴 네트워크의 가중치 셀의 작동 원리를 개략적으로 나타내는 회로도이다. 본 발명의 실시예에 따른 가중치 비트폭을 탄력적으로 적용하기 위하여 가중치를 새롭게 정의한다. 현재까지는 커패시턴스를 기초로 하는 가중치에서 Q=CV(전하량=커패시턴스×전압)를 적용하여 C를 멀티레벨화 했다. 여기서 선형 멀티레벨은 배수 n을 사용하여 C=nCO로 표현할 수 있다. 이 때 기저(ground) 커패시턴스가 되는 CO는 가중 치의 해상도(resolution)가 되고 COV는 전하량의 해상도(resolution)가 된다. 여기서 n은 배수 개념에서 횟수 (number) 개념으로 전환할 수 있기 때문에 CO를 n회 적용하는 방식을 도입할 수 있다. 따라서 가중치를 n으로 정의할 수 있다. 도 2 및 도 3을 참조하면, 본 발명의 실시예에 따른 뉴럴 네트워크의 가중치 셀은, 워드 라인(WL), 비트 라인 (BL), 및 커패시터와 연결되는 트랜지스터와, 트랜지스터와 연결되는 커패시터를 포함하고, 워드 라인은 비트 라인과 직교하여 배치된다. 실시예로서, 비트 라인의 입력은 펄스 발진기와 연결되고 출력은 센스 엠프와 연결 될 수 있다. 본 발명의 일 실시예에 따르면, 비트 라인과 센스 엠프 사이에는 선택 트랜지스터(ST)가 배치된다. 실시예로서, 선택 트랜지스터의 게이트에 일정 시간() 동안 게이트 전압을 인가함으로써 뉴럴 네트위크의 가중치 셀에펄스 트레인이 인가되는 시간, 즉 인가되는 펄스 횟수(nj)를 조절할 수 있다. j는 가중치 셀 어레이의 열의 개 수이다. 본 발명의 일 실시예에 따르면, 트랜지스터와 커패시터로 구성된 가중치 셀을 이용하여 커패시터를 반복적으로 충방전하여 일정 시간동안 방전하는 전하량을 출력값으로 한다. 실시예로서, 가중치 셀의 워드 라인에 인가되는 전압은 일정한 전압이고, 비트 라인에 인가되는 전압은 입력 신호에 대응하는 펄스 전압이다. 실시예로서, 비트 라인에 인가되는 전압은 커패시터 플레이트에 인가되는 상시 전압의 두배 이상일 수 있다. 도 4는 본 발명의 일 실시예에 따른 뉴럴 네트워크 구성을 개략적으로 나타내는 회로도이다. 도 4를 참조하면, 본 발명의 실시예에 따른 뉴럴 네트워크의 가중치 셀은, 워드 라인(WL), 비트 라인(BL), 및 커패시터와 연결되는 트랜지스터와, 트랜지스터와 연결되는 커패시터와, 상기 커패시터에 연결되는 플레이트를 포함하고, 비트 라인의 입력은 펄스 발진기와 연결되고 출력은 센스 앰프와 연결된다. 도 3 및 도 4를 참조하면, 트랜지스터의 비트 라인에는 입력 신호에 대응되는 입력 전압 Vpj의 펄스 트레인 (pulse train)을 인가하고, 워드 라인에는 전압 Vg를 인가하되 행 별로 순차로 인가한다. 실시예로서, 행을 2개, 3개, 혹은 그 이상으로 동시에 작동시켜 선형적으로 방전량을 증가시킬 수 있다. 본 발명의 일 실시예에 따르면, 공통 펄스 발진기와 각각의 비트 라인 사이에 셀프 전압 분배기가 배치되어, 각 각의 비트 라인에 입력되는 펄스 트레인 전압을 조절한다. 실시예로서, 셀프 전압 분배기의 게이트 전압(Vj)을 조절하여 비트 라인에 입력되는 펄스 전압(Vpj)을 결정할 수 있다. 비트 라인의 출력에는 선택 트랜지스터가 배치되어, 선택 트랜지스터의 게이트에 각각 일정 시간() 동안 게 이트 전압을 인가함으로써 펄스 트레인 전압이 인가되는 시간을 조절한다. 본 발명의 실시예에 따른 뉴럴 네트워크의 각 가중치 셀에서 방출되는 전하량은 Q=n()C(Vpj-Vcc/2)가 된다. n()는 펄스 폭 에 의해 선형적으로 결정되는 입력 펄스 횟수(count)이다. 이 관계에 의해 입력 전압과 가중치에 해당하는 n과의 곱셈(multiplication)이 가능해진다. 의 최소 기본 단위를 라고 하면 n()C(Vpj-Vcc/2)는 Q의 해상도(resolution)가 된다. 행을 묶어서 작동하는 경우는 행 수만큼의 비율로 가 중치의 선형성(linearity)을 확장할 수 있다. 실시예로서, 펄스 발진기의 입력 펄스 지연(delay) 동안 비트 라인으로부터 방전되는 방전 전하가 펄스 발진기 로 역류하는 것을 막기 위하여, 비트 라인과 셀프 전압 분배기 사이에 다이오드를 배치할 수 있다. 실시예로서, 펄스 발진기의 펄스 전압이 인가되는 동안 비트라인으로 펄스가 직접 선별기로 진행되는 것을 방지 하기 위하여, 선택 트랜지스터의 그라운드에 해당하는 P웰(p-well)과, 다이오드와 셀프 전압 분배기 사이를 연 결하는 배선을 제작할 수 있다. 펄스 전압이 인가되면 선택 트랜지스터 P웰에도 전압이 인가되므로 선택 트랜지 스터에 인가되는 게이트 전압을 상쇄시키거나 그 이상으로 선택 트랜지스터를 오프(off) 상태로 만들기 때문에 펄스가 선별기로 직접 진행하는 것을 방지한다. 따라서 입력 펄스 전압 Vpj는 선택 트랜지스터에 인가되는 게이 트 전압 Vg보다 클 수 있다. (Vpj ≥Vg) 출력 비트 라인들은 하나로 연결하여 출력 전하들을 모으는 또 다른 1T-1C 트랜지스터-커패시터 쌍의 어레이에 연결하여 전하들을 축적시킨다. 이 때 어큐뮬레이터(accumulator)에서 발생할 수 있는 역전압에 의한 전하의 역 류를 방지하기 위해 선택 트랜지스터와 어큐뮬레이터 사이에 다이오드를 추가할 수 있다. 도 5, 도 6, 및 도 7은 본 발명의 일 실시예에 따른 뉴럴 네트워크의 동작을 설명하기 위한 회로도이다. 도 5, 도 6, 및 도 7을 참조하면, 본 발명의 실시예에 따른 뉴럴 네트워크는 가중치 셀을 어레이(array)로 구성 하고 이를 네트워크 레이어(network layer)로 제작한 다음 가중치 셀 어레이의 행 별로 순차로 작동시키는 동시 에 출력 값을 다음 은닉층의 입력 정보로 사용하는 리커런트(recurrent) 혹은 이터레이션(iteration) 방식을 적 용한다. 도 5 및 도 6을 참조하면, 본 발명의 실시예에 따른 뉴럴 네트워크의 특정 행의 각 가중치 셀에 입력 전압을 인 가하는 시간은, 열 별로 연결된 선택 트랜지스터의 게이트에 인가하는 게이트 전압 펄스의 폭으로 조절한다. 셀 프 전압 분배기의 전압 다이나믹 레인지(dynamic range)는 비트 라인에 입력되는 전압의 다이나믹 레인지 조건 에 맞추어 설계한다. 실시예로서, 행렬 곱셈은 워드 라인에 순차적으로 전압을 인가하여 행 별로 순차적으로 수 행하고, 각 은닉층별 가중치 정보와 입력 정보는 뉴럴 네트워크 외부의 저장 매체에 저장할 수 있다. 외부의 저 장 매체에는 레이어별 가중치 정보와 입력 정보를 저장하여 추론(inference)시 순환 컴퓨팅(computing)에 사용 한다. 도 5 및 도 6을 참조하면, i 개의 행 중, 두번째 행을 선택한 실시예를 확인할 수 있으나 본 발명은 이에 한정 되지 않고 여러 행을 동시에 선택하여 충방전 전하량을 확대 사용할 수 있다. 축적된 전하들의 양이 일정 값을 넘으면 활성화하게 되는데 이 전하들을 축적하는 동안 어큐뮬레이터에는 전압 이 증가하게 된다. 이 역전압이 제1 가중치 셀 어레이에서 방전(discharging)되는 전하들을 막을 수 있으므로 어큐뮬레이터를 구성하는 1T-1C 셀 어레이를 충분히 크게 제작한다. 또한 축적된 전하들을 일정시간 동안 방전 시켜서 어큐뮬레이터에 전하들이 남아 있을 경우에 차기 은닉층의 입력 정보로 사용한다. 어큐뮬레이터에 전하 들이 남아있지 않는다면 차기 은닉층의 입력이 없게 된다. 잔류 전하 여부를 판단하는 것은 센스 앰프(sense amplifier)로 수행하고 일정 시간 어큐뮬레이터의 전하들을 소멸시키는 것은 NMOS-PMOS 트랜지스터 쌍으로 수행 한다. 도 7을 참조하면, 선별(discrimination)과 잔류 전하를 검출하는 방법을 확인할 수 있다. 어큐뮬레이터에 축적 된 전하를 인버터로 보내기 위해서 어큐뮬레이터의 플레이트(plate)에 Vcc/2 전압을 인가하고 인버터에 전압 Vg'를 인가한 다음 인버터 앞의 선별용 선택 트랜지스터(DT)의 게이트에 전압 Vg를 인가한다. 인버터에 전압 Vg'을 인가하면 NMOS 트랜지스터가 on 상태가 되어 축적되었던 전하들이 NMOS 트랜지스터를 통하여 방전되어 소 멸한다. 일정 기간 후에 인버터 전압을 제거하면 PMOS 트랜지스터가 작동하면서 잔류 전하가 센스 앰프 쪽으로 흐르고 이로 인해 잔류 전하 여부를 감지할 수 있다. 전술한 바와 같은 본 발명의 실시예들에 따르면, 본 발명의 실시예에 따른 가중치 비트폭을 탄력적으로 적용할 수 있는 가중치 셀은, 가중치와 은닉층 수를 탄력적으로 조절할 수 있으며, 회로 오버헤드를 줄일 수 있고 행렬 곱셈 유닛 칩 크기(matrix multiplication unit chip size)도 최소화할 수 있다. 이상과 같이 본 발명에서는 구체적인 구성 요소 등과 같은 특정 사항들과 한정된 실시예 및 도면에 의해 설명되 었으나 이는 본 발명의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 발명은 상기의 실시예에 한정되 는 것은 아니며, 본 발명이 속하는 분야에서 통상적인 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변형이 가능하다. 따라서, 본 발명의 사상은 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등하거나 등가적 변형이 있는 모든 것들은 본 발명 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2019-0113317", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 뉴럴 네트워크를 개략적으로 나타내는 회로도이다. 도 2는 본 발명의 일 실시예에 따른 뉴럴 네트워크의 가중치 셀을 개략적으로 나타내는 회로도이다. 도 3은 본 발명의 일 실시예에 따른 뉴럴 네트워크의 가중치 셀의 동작 원리를 개략적으로 나타내는 회로도이다. 도 4는 본 발명의 일 실시예에 따른 뉴럴 네트워크 구성을 개략적으로 나타내는 회로도이다. 도 5, 도 6, 및 도 7은 본 발명의 일 실시예에 따른 뉴럴 네트워크의 동작을 설명하기 위한 회로도이다."}
