{"patent_id": "10-2023-0100599", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0019457", "출원번호": "10-2023-0100599", "발명의 명칭": "모바일 로봇을 이용한 사고 예방 시스템", "출원인": "주식회사 아워스", "발명자": "최재영"}}
{"patent_id": "10-2023-0100599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이동과 무선통신 기반의 데이터 송수신 및 제어 신호에 대응하는 동작을 수행하는 모바일 로봇과 근로자가 혼재한 공간 내 안전사고를 예방하는 모바일 로봇을 이용한 사고 예방 시스템에 있어서,로봇 바디, 기설정된 센서, 제어 장치, 전원공급 장치, 엑추에이터 및 통신 장치를 포함하고 수신한 신호에 대응하여 물품의 운송, 분류 및 순찰을 수행하는 모바일 로봇;상기 모바일 로봇의 기설정된 위치에 영상촬영장치를 마련하여 영상 촬영, 수집 및 분석을 수행하는영상처리부;기설정된 공간 및 상기 모바일 로봇 내에 온도 측정센서, 습도 측정센서, 유해가스 농도 측정센서 및 미세먼지농도 측정센서를 마련하여 환경정보를 수집하는 센서부;상기 영상처리부 및 상기 환경정보에 대응하여 상기 모바일 로봇에 원격 제어 신호를 전송하는 모바일 로봇 제어부; 및상기 모바일 로봇의 운행 정보, 상기 영상 정보 및 상기 환경정보를 수신하고 기설정된 기준에 대응하여 상기모바일 로봇, 상기 모바일 로봇을 관리하는 모바일 로봇 관리자 및 상기 근로자의 단말에 경보 및 알림을 전송하는 모니터링부;를 포함하는 것을 특징으로 하는 모바일 로봇을 이용한 사고 예방 시스템."}
{"patent_id": "10-2023-0100599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 영상처리부는,상기 영상촬영장치를 이용하여 영상 데이터를 수집하는 영상촬영부;기설정된 인공지능 객체 감지 모델을 이용하여 장애물 통로 및 근로자를 식별하여 표시하는 객체감지부; 및상기 객체감지부에서 감지한 객체와 상기 모바일 로봇 간의 거리를 산출하는 거리산출부;를 포함하는 것을 특징으로 하는 모바일 로봇을 이용한 사고 예방 시스템."}
{"patent_id": "10-2023-0100599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 센서부는,상기 환경정보를 측정하는 측정센서에 공급되는 공급전압, 소비전류 및 출력전압을 수집하는 센서정보수집부; 상기 측정센서에서 측정된 센싱 데이터의 측정값 변화율이 기설정된 비율을 초과하는 시각인 비교 대상 시각을추출하는 센서 오류측정부; 및상기 센서 오류측정부의 비교 대상 시각을 주기적으로 상기 모니터링부에 전송하는 데이터 전송부;를 포함하며,상기 센서 오류측정부는,상기 기설정된 비율을 초과하는 시각이 존재하지 않는 경우, 상기 측정센서로부터 수집한 센싱 데이터 내 n개의임의의 시각에 대응하는 센싱 데이터를 비교 대상 시각으로 추출하는 것을 특징으로 하는 모바일 로봇을 이용한공개특허 10-2025-0019457-3-사고 예방 시스템."}
{"patent_id": "10-2023-0100599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 센서부는,상기 측정센서의 위치로부터 기설정된 반경 내 동일한 사양의 센서인 비교센서를 더 마련하고,상기 모니터링부는,상기 측정센서 및 상기 비교센서로부터 수집된 센싱 데이터 및 비교 대상 시각을 이용하여 하기 [수학식 1]에따라 센서 고장 확률(STR)을 산출하며,[수학식 1](여기서, STR은 센서 고장 확률, Tms1은 제1 시각에서 측정센서의 측정값, Tms2는 제2 시각에서 측정센서의측정값, Tms3은 제3 시각에서 측정센서의 측정값, Tmsn은 제n 시각에서 측정센서의 측정값, Tcst1은 제1 시각에서비교센서의 측정값, Tcst2는 제2 시각에서 비교센서의 측정값, Tcs3는 제3 시각에서 비교센서의 측정값, Tcsn은 제n시각에서 비교센서의 측정값, Tmsav는 측정센서의 평균 측정값, SE는 측정센서의 효율 편차를 의미함)상기 측정센서의 효율 편차(SE)는 하기 [수학식 2]에 따라 산출하고,[수학식 2](여기서, SEav는 측정센서의 평균 효율, SEi는 측정센서의 초기 효율을 의미함)상기 측정센서의 평균 효율은 하기 [수학식 3]에 따라 산출하는 것을 특징으로 하는 모바일 로봇을 이용한 사고예방 시스템.[수학식 3](여기서, WIN1은 제1 시각에서 측정센서에 공급되는 전력, WOUT1은 제1 시각에서 측정센서가 센싱한 측정값을 전기신호로 출력 시 측정되는 전력, WIN2은 제2 시각에서 측정센서에 공급되는 전력, WOUT2은 제2 시각에서 측정센서가센싱한 측정값을 전기신호로 출력 시 측정되는 전력, WINn은 제n 시각에서 측정센서에 공급되는 전력, WOUTn은 제n시각에서 측정센서가 센싱한 측정값을 전기신호로 출력 시 측정되는 전력을 의미함)"}
{"patent_id": "10-2023-0100599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 모니터링부는,상기 모바일 로봇 관리자 및 상기 근로자의 기설정된 웨어러블 단말로부터 건강정보 데이터를 실시간으로 수신공개특허 10-2025-0019457-4-하고,상기 모바일 로봇 관리자의 건강정보 데이터가 기설정된 기준 범위를 벗어나는 경우, 상기 모바일 로봇 관리자가 제어중인 모바일 로봇이 기설정된 위치로 자동으로 강제 이동하며,상기 근로자의 건강정보 데이터가 기설정된 기준 범위를 벗어나는 경우, 상기 근로자의 단말과 인접한 상기 모바일 로봇 및 타 근로자 단말 중 적어도 하나의 단말에 구조요청 알림 및 해당 위치정보를 자동 전송하는 것을특징으로 하는 모바일 로봇을 이용한 사고 예방 시스템."}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 모바일 로봇을 이용한 사고 예방 시스템에 관한 것으로서, 이동과 무선통신 기반의 데이터 송수신 및 제어 신호에 대응하는 동작을 수행하는 모바일 로봇과 근로자가 혼재한 공간 내 안전사고를 예방하는 모바일 로 봇을 이용한 사고 예방 시스템에 있어서, 로봇 바디, 기설정된 센서, 제어 장치, 전원공급 장치, 엑추에이터 및 (뒷면에 계속)"}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 원격 제어 로봇 기반의 근로자 사고 예방 및 감시 시스템에 관한 것으로서, 보다 상세하게는 센서, 카메라, 라이다 등을 탑재하고 이동이 가능한 로봇을 원격으로 제어하여 산업시설 내 근로자의 안전사고를 방지 하고 사람과 상호작용하는 모바일 로봇을 이용한 사고 예방 시스템에 관한 것이다."}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "모바일 로봇은 휴대성과 이동성이 강조된 로봇으로, 자율적으로 이동하고 다양한 장소에서 작업 수행이 가능하 며 스마트폰이나 태블릿과 같은 모바일 디바이스를 사용하여 원격 제어 또는 자율적인 작업 수행이 가능하며 대 표적인 특징으로는 이동성, 자율성, 원격제어, 상호작용, 다양한 응용분야 및 가능성이 특징이자 장점으로 각광 받고 있다. 이를 통해, 모바일 로봇은 인간의 노동력을 대체, 보조 및 생산성을 향상시키기 위해 물류 및 창고관리, 제조업 무, 의료 및 건강관리, 보안 및 경비, 농업 등에 활용될 수 있으며, 여러 산업분야에서 혁신적인 응용가능성으 로 현재 인공지능(AI, Artificial Intelligence)과 센서 기술의 발전으로 그 활용성이 더욱 다양해지고 있다. 그 중에서, 산업현장 내 모바일 로봇을 이용하여 생산성을 향상시키고 인력을 대체하는 현상이 최근 두드러지고 있으나, 모바일 로봇과 근로자가 혼재하면서 상호간의 안전상 위험요소가 되는 현상이 발생하고 있다. 이를 방지하기 위해, 근로자 및 모바일 로봇의 교육과 훈련, 작업환경 및 상황에 따른 위험 평가, 모바일 로봇 내 안전장치, 근로자와 로봇의 활동구역 구분, 모바일 로봇의 원격 모니터링 및 주기적인 점검과 유지보수 등이 수행되고 있으나, 근로자 자체의 인구가 감소하여 안전사고 발생율이 유지 또는 감소하는 추세이나 실제 인구수 대비 안전사고 방지와 관련하여 큰 효과는 나타나지 않고 있는 실정이다. 따라서, 근로자와 모바일 로봇이 혼재하는 공간에서 근로자의 위치, 존재 여부 등을 모바일 로봇 내 마련된 다 수 개의 센서 및 영상촬영 장치를 이용하여 수집하고, 이를 인공지능 기반의 데이터 분석을 수행하여 안전사고 위험 시 근로자 및 관리자 단말에 경고 및 알림표시를 수행하여 안전사고를 예방하는 모바일 로봇을 이용한 사 고 예방 시스템에 대한 연구가 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-2202352호"}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 근로자와 모바일 로봇이 혼재하는 공간 내 모바일 로봇에 센서 및 영상촬영장치를 마련함으로써, 공 간 내 환경정보 및 영상정보를 데이터화하여 분석함에 목적이 있다.또한, 모바일 로봇으로부터 수집한 데이터를 분석함으로써, 모바일 로봇 인근의 근로자, 장애물, 타 모바일 로 봇, 경로를 구분하고 이에 대응하는 동작을 수행하여 작업 효율성을 향상시킴에 목적이 있다. 또한, 모바일 로봇의 이동에 대응하여 공간 내 마련된 타 센서 및 근로자의 단말과 무선통신함으로써, 순찰 및 경비 역할과 동시에 해당 근로자로부터 수집한 건강정보가 기준범위를 벗어날 시 도움요청 및 이상신호를 전송 하여 안전사고 발생 시 빠른 대응을 수행함에 목적이 있다."}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시례에 따른 모바일 로봇을 이용한 사고 예방 시스템은, 이동과 무선통신 기반의 데이터 송수신 및 제어 신호에 대응하는 동작을 수행하는 모바일 로봇과 근로자가 혼재한 공간 내 안전사고를 예방하는 모바일 로봇을 이용한 사고 예방 시스템에 있어서, 로봇 바디, 기설정된 센서, 제어 장치, 전원공급 장치, 엑추에이터 및 통신 장치를 포함하고 수신한 신호에 대응하여 물품의 운송, 분류 및 순찰을 수행하는 모바일 로봇, 상기 모 바일 로봇의 기설정된 위치에 영상촬영장치를 마련하여 영상 촬영, 수집 및 분석을 수행하는 영상처리부, 기설 정된 공간 및 상기 모바일 로봇 내에 온도 측정센서, 습도 측정센서, 유해가스 농도 측정센서 및 미세먼지 농도 측정센서를 마련하여 환경정보를 수집하는 센서부, 상기 영상처리부 및 상기 환경정보에 대응하여 상기 모바일 로봇에 원격 제어 신호를 전송하는 모바일 로봇 제어부 및 상기 모바일 로봇의 운행 정보, 상기 영상 정보 및 상기 환경정보를 수신하고 기설정된 기준에 대응하여 상기 모바일 로봇, 상기 모바일 로봇을 관리하는 모바일 로봇 관리자 및 상기 근로자의 단말에 경보 및 알림을 전송하는 모니터링부를 포함할 수 있다. 또한, 상기 영상처리부는, 상기 영상촬영장치를 이용하여 영상 데이터를 수집하는 영상촬영부, 기설정된 인공지 능 객체 감지 모델을 이용하여 장애물 통로 및 근로자를 식별하여 표시하는 객체감지부 및 상기 객체감지부에서 감지한 객체와 상기 모바일 로봇 간의 거리를 산출하는 거리산출부를 포함할 수 있다. 또한, 상기 센서부는, 상기 환경정보를 측정하는 측정센서에 공급되는 공급전압, 소비전류 및 출력전압을 수집 하는 센서정보수집부, 상기 측정센서에서 측정된 센싱 데이터의 측정값 변화율이 기설정된 비율을 초과하는 시 각인 비교 대상 시각을 추출하는 센서 오류측정부 및 상기 센서 오류측정부의 비교 대상 시각을 주기적으로 상 기 모니터링부에 전송하는 데이터 전송부를 포함하며, 상기 센서 오류측정부는, 상기 기설정된 비율을 초과하는 시각이 존재하지 않는 경우, 상기 측정센서로부터 수집한 센싱 데이터 내 n개의 임의의 시각에 대응하는 센싱 데이터를 비교 대상 시각으로 추출할 수 있다. 또한, 상기 센서부는, 상기 환경정보를 측정하는 측정센서에 공급되는 공급전압, 소비전류 및 출력전압을 수집 하는 센서정보수집부, 상기 측정센서에서 측정된 센싱 데이터의 측정값 변화율이 기설정된 비율을 초과하는 시 각인 비교 대상 시각을 추출하는 센서 오류측정부 및 상기 센서 오류측정부의 비교 대상 시각을 주기적으로 상 기 모니터링부에 전송하는 데이터 전송부를 포함하며, 상기 센서 오류측정부는, 상기 기설정된 비율을 초과하는 시각이 존재하지 않는 경우, 상기 측정센서로부터 수집한 센싱 데이터 내 n개의 임의의 시각에 대응하는 센싱 데이터를 비교 대상 시각으로 추출할 수 있다. 또한, 상기 센서부는, 상기 측정센서의 위치로부터 기설정된 반경 내 동일한 사양의 센서인 비교센서를 더 마련 하고, 상기 모니터링부는, 상기 측정센서 및 상기 비교센서로부터 수집된 센싱 데이터 및 비교 대상 시각을 이 용하여 하기 [수학식 1]에 따라 센서 고장 확률(STR)을 산출하며, [수학식 1]"}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "(여기서, STR은 센서 고장 확률, Tms1은 제1 시각에서 측정센서의 측정값, Tms2는 제2 시각에서 측정센서의 측정값, Tms3은 제3 시각에서 측정센서의 측정값, Tmsn은 제n 시각에서 측정센서의 측정값, Tcst1은 제1 시각에서 비교센서의 측정값, Tcst2는 제2 시각에서 비교센서의 측정값, Tcs3는 제3 시각에서 비교센서의 측정값, Tcsn은 제n 시각에서 비교센서의 측정값, Tmsav는 측정센서의 평균 측정값, SE는 측정센서의 효율 편차를 의미함) 상기 측정센서의 효율 편차(SE)는 하기 [수학식 2]에 따라 산출하고, [수학식 2]"}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "(여기서, SEav는 측정센서의 평균 효율, SEi는 측정센서의 초기 효율을 의미함) 상기 측정센서의 평균 효율은 하기 [수학식 3]에 따라 산출할 수 있다. [수학식 3]"}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "(여기서, WIN1은 제1 시각에서 측정센서에 공급되는 전력, WOUT1은 제1 시각에서 측정센서가 센싱한 측정값을 전기 신호로 출력 시 측정되는 전력, WIN2은 제2 시각에서 측정센서에 공급되는 전력, WOUT2은 제2 시각에서 측정센서가 센싱한 측정값을 전기신호로 출력 시 측정되는 전력, WINn은 제n 시각에서 측정센서에 공급되는 전력, WOUTn은 제n 시각에서 측정센서가 센싱한 측정값을 전기신호로 출력 시 측정되는 전력을 의미함) 또한, 상기 모니터링부는, 상기 모바일 로봇 관리자 및 상기 근로자의 기설정된 웨어러블 단말로부터 건강정보 데이터를 실시간으로 수신하고, 상기 모바일 로봇 관리자의 건강정보 데이터가 기설정된 기준 범위를 벗어나는 경우, 상기 모바일 로봇 관리자가 제어중인 모바일 로봇이 기설정된 위치로 자동으로 강제 이동하며, 상기 근로 자의 건강정보 데이터가 기설정된 기준 범위를 벗어나는 경우, 상기 근로자의 단말과 인접한 상기 모바일 로봇 및 타 근로자 단말 중 적어도 하나의 단말에 구조요청 알림 및 해당 위치정보를 자동 전송할 수 있다."}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 본 발명은 근로자와 모바일 로봇이 혼재하는 공간 내 모바일 로봇에 센서 및 영상촬영장치를 마련함으로써, 공간 내 환경정보 및 영상정보를 데이터화하여 분석할 수 있다. 또한, 모바일 로봇으로부터 수집한 데이터를 분석함으로써, 모바일 로봇 인근의 근로자, 장애물, 타 모바일 로 봇, 경로를 구분하고 이에 대응하는 동작을 수행하여 작업 효율성을 향상시킬 수 있다. 또한, 모바일 로봇의 이동에 대응하여 공간 내 마련된 타 센서 및 근로자의 단말과 무선통신함으로써, 순찰 및 경비 역할과 동시에 해당 근로자로부터 수집한 건강정보가 기준범위를 벗어날 시 도움요청 및 이상신호를 전송 하여 안전사고 발생 시 빠른 대응을 수행할 수 있다."}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이상과 같은 본 발명에 대한 해결하고자 하는 과제, 과제의 해결 수단, 발명의 효과를 포함한 구체적인 사항들 은 다음에 기재할 실시례 및 도면들에 포함되어 있다. 본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법 은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시례들을 참조하면 명확해질 것이다. 본 발명의 권리범위는 이하에서 설명하는 실시례에 한정되는 것은 아니며, 본 발명의 기술적 요지를 벗어나지"}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "않는 범위 내에서 당해 기술분야의 통상적인 지식을 가진자에 의하여 다양하게 변형 실시될 수 있다.이하, 본 발명인 모바일 로봇을 이용한 사고 예방 시스템은 첨부된 도 1 내지 도 3을 참고로 상세하게 설명한다. 우선, 도 1은 본 발명의 일실시례에 따른 모바일 로봇을 이용한 사고 예방 시스템의 블록도를 도시한 도면이고, 도 2는 본 발명의 일실시례에 따른 모바일 로봇을 이용한 사고 예방 시스템 내 영상처리부의 중간 블록도를 도 시한 도면이며, 도 3은 본 발명의 일실시례에 따른 모바일 로봇을 이용한 사고 예방 시스템 내 센서부의 중간 블록도이다. 도 1을 참고하면, 본 발명의 일실시례에 따른 모바일 로봇을 이용한 사고 예방 시스템은, 모바일 로봇 , 영상처리부, 센서부, 모바일 로봇 제어부 및 모니터링부를 포함할 수 있다. 본 발명인 모바일 로봇을 이용한 사고 예방 시스템 은, 이동과 무선통신 기반의 데이터 송수신 및 수신된 제어 신호에 대응하는 동작을 수행하는 모바일 로봇과 근로자가 혼재한 공간 내 안전사고를 예방하는 모바일 로 봇을 이용한 사고 예방 시스템을 통해 상기 공간 내 환경정보 및 근로자 정보를 수집하고 모바일 로봇과 근로자 간 충돌 사고를 방지하며 근로자가 착용한 웨어러블 단말로부터 건강 데이터를 수신하여 건강 상태 이상으로 인 한 안전사고 발생 시 빠른 대처를 수행할 수 있다. 상기 모바일 로봇은, 로봇 바디, 기설정된 센서, 제어 장치, 전원공급 장치, 엑추에이터 및 통신 장치를 포함할 수 있다. 여기서, 상기 모바일 로봇의 상기 로봇 바디는, 로봇의 물리적인 구조로써, 이동을 위한 바퀴, 트랙, 다리 등의 구조를 포함하여 근로자와 혼재한 공간 내 지면의 다양한 지형에서 이동을 수행할 수 있도록 마련될 수 있 다. 또한, 상기 모바일 로봇 내 주변 환경 정보를 수집하기 위해 카메라, 라이다(LiDAR), 초음파 센서, 적외선 센서, 접촉 센서 등이 마련되어 주변 환경 정보의 센싱 및 인식을 수행하며, 상기 센싱된 주변 환경 정보를 이 용하여 수행할 동작을 결정하고, 모터 등의 엑추에이터를 제어하여 동작 구현을 수행할 수 있다. 이때, 상기 엑추에이터는 상기 모바일 로봇의 움직임을 실제로 실행하는 장치를 의미하며, 모바일 로봇 내 마련된 모터, 실린더 등을 의미할 수 있다. 또한, 상기 모바일 로봇은 전원을 공급받는 배터리 및 외부로부터 데이터 송수신을 수행하는 통신 장치를 포함하여 현재 모바일 로봇의 상태, 수집한 주변 환경 정보 및 모바일 로봇을 제어하는 관리자로부터의 제 어 신호의 송수신을 수행할 수 있다. 여기서, 상기 제어 신호의 송수신은, 상기 모바일 로봇 제어부 및 모니터링부에서 전송한 제어 신호 에 대응하여 해당 제어 동작의 이행 여부를 송신하는 것을 의미할 수 있다. 한편, 상기 모바일 로봇은, 담당 역할에 대응하여 리프트, 간이 컨베이어 밸트, 경보장치 등이 더 마련되 어 근로자와 혼재한 공장, 창고, 물류센터 등에서 물건을 운송하고, 모바일 로봇 간 충돌을 방지하는 최적 의 동선을 이용하여 생산성을 향상시킬 수 있다. 또한, 상기 모바일 로봇은, 해당 모바일 로봇의 역할에 대응하여 근로자 보조, 청소, 순찰, 이상 근 로자 상태 파악 등 다양한 역할을 수행하며, 이에 따라 장착되는 로봇 바디 및 액세서리가 변경되어 구성될 수 있다. 여기서, 상기 모바일 로봇이 근로자 보조 역할인 경우, 동일한 경로 및 동일한 동작을 수행하는 반복 작업 을 근로자 대신 수행하는 역할을 수행하며, 순찰 역할인 경우, 인접한 모바일 로봇과 통신하여 경로상 충 돌을 회피하는 경로로 이동되며, 근로자가 착용한 웨어러블 단말로부터 해당 근로자의 건강 데이터인 체온, 심 박수, 호흡수 등을 수집하여 정상 기준치와 비교 후 정상 기준 범위를 벗어날 시 경보, 알람, 상기 모니터링부 에 신호 전송 등을 수행하여 근로자 상태의 파악 및 보고를 수행할 수 있다. 상기 영상처리부는, 상기 모바일 로봇의 기설정된 위치에 영상촬영장치를 마련하여 영상 촬영, 수집 및 분 석을 수행할 수 있다. 여기서, 영상촬영장치는 영상을 촬영하는 카메라 등의 장치를 의미하며, 대표적으로 1대의 카메라를 이용하여 주변 360도 영상을 촬영하는 360도 카메라가 마련되어 영상정보를 수집할 수 있다. 이때, 상기 모바일 로봇에 영상촬영장치가 마련되는 기설정된 위치는 내 지면으로부터 가장 높은 상면, 후 면, 전면, 측면, 높이 조절부위 중 하나의 위치에 마련되되, 해당 위치를 기준으로 영상촬영에 가려지는 구조물 이 없는 부위에 위치하는 것이 이상적일 수 있다. 즉, 상기 모바일 로봇에 영상촬영장치가 마련되는 위치 중 가장 우선적으로 고려되는 위치는 이동 시 근로 자 또는 타 모바일 로봇이 왜곡이나 장애물의 방해없이 촬영되는 위치가 가장 우선적으로 고려될 수 있다. 또한, 상기 영상처리부의 영상촬영장치는 360도 카메라 이외에도 최소한의 크기와 장치의 구성으로 다양한 각도를 촬영하고 영상 데이터로 수집할 수 있는 영상촬영장치가 변경 또는 추가되어 사용될 수 있다. 한편, 상기 영상처리부는 도 2를 참고하여 더욱 상세히 설명한다. 도 2를 참고하면, 상기 영상처리부는, 영상촬영부, 객체감지부 및 거리산출부를 포함할 수 있다. 상기 영상촬영부는, 영상촬영장치를 이용하여 영상 데이터를 수집할 수 있다. 즉, 상기 영상촬영부는, 모바일 로봇에 마련된 영상촬영장치로부터 촬영되는 영상을 영상 데이터로 변환하 여 저장 및 수집할 수 있다. 상기 객체감지부는, 기설정된 인공지능 객체 감지 모델을 이용하여 장애물, 통로, 타 모바일 로봇 및 근로 자를 식별하고 감지할 수 있다. 보다 상세하게는, 상기 객체감지부는, 상기 영상촬영부에서 수집한 영상 데이터 내에서 특정 물체들 을 인식하고 해당 물체들의 위치와 경계 상자를 찾아내는 작업인 객체 감지(Object Detection)를 이용하여 영상 데이터로부터 다수 개의 객체를 탐지 및 분류할 수 있다. 일례로, 상기 객체감지부는, 공장 내부에 순찰 역할을 수행하는 순찰 모바일 로봇에 360도 카메라가 영상 촬영부로 마련되고, 순찰 모바일 로봇이 이동 순찰을 하며 촬영을 수행하는 경우, 영상촬영부에서 수 집한 영상 데이터 내 장애물, 통로, 타 모바일 로봇 및 근로자를 동신에 인식하고 객체 분류를 수행할 수 있다. 이를 통해, 상기 객체감지부는, 상기 영상촬영부에서 촬영하여 데이터화한 영상 데이터 내 장애물, 통로, 타 모바일 로봇 및 근로자 중 하나로 인식한 객체에 경계 상자를 생성하는 물체의 위치와 크기를 표시하 고, 해당 객체가 어떤 객체인지를 분류하여 상기 모니터링부 및 모바일 로봇 관리자 단말에 전송할 수 있 다. 여기서, 상기 영상 데이터 내 장애물, 통로, 타 모바일 로봇 및 근로자를 감지하는 객체 감지를 수행하기 위한 기설정된 인공지능 객체 감지 모델은, 딥러닝(Deep Learning) 기술 중 컨볼루션 신경망(Convolutional Neural Networks, CNN)을 기반한 YOLO(you Only Look Once), SSD(Single Shot Multibox Detecter), Faster R- CNN(Region-based Convolutional Neural Networks) 등의 인공지능 모델이 사용될 수 있다. 보다 상세하게는, 상기 객체감지부는, 상기 영상 데이터를 이용하여 YOLO, SSD, Faster R-CNN 등의 딥러닝 기반 인공지능 모델을 사용하여 객체의 위치와 경계 상자를 찾고, 해당 물체들을 각각의 클래스인 장애물, 통로, 타 모바일 로봇 및 사람 중 하나로 분류하는 객체 분류(Object Classification), 픽셀 수준에서 이미지를 분할하여 각각의 픽셀을 객체로 분류하고 객체의 정확한 윤곽을 파악하는 객체 분할(Object Segmentation), 컨 볼루션 신경망을 사용한 이미지 특징을 추출하는 특징 추출(Feature Extraction), 크기조정·색상조절·명압대 비 조절 등의 작업을 수행하는 전처리, 객체 감지 및 분류 결과를 활용하여 장애물, 통로, 타 모바일 로봇 및 사람 중 적어도 하나의 객체로 식별하는 후처리 및 연속적인 프레임들을 처리하여 장애물, 통로, 타 모바일 로 봇 및 사람 중 하나로 인식된 객체의 변화를 추적하고 인식하는 영상 시퀀스 처리를 수행할 수 있다. 이를 통해, 상기 객체감지부는, 상기 영상촬영부에서 수집한 영상 데이터 내 장애물, 통로, 타 모바 일 로봇 및 사람(근로자)을 인식하고 분류할 수 있다. 또한, 상기 객체감지부는, 상기 영상촬영부에 마련된 영상촬영장치가 360도 카메라인 경우, 상기 360 도 카메라와 시맨틱 세그멘테이션(Semantic Segmantation)을 이용하여 실시간으로 주변 장애물 인식을 수행할 수 있다. 보다 상세하게는, 상기 객체감지부는, 360도 카메라로 촬영된 주변 환경 영상 데이터 내 이미지를 필요한 크기로 조정하고, 색상 및 명암 대비 조정을 수행하여 시맨틱 세그멘테이션 모델의 입력에 대응되도록 전처리 수행할 수 있다. 상기와 같이 전처리 수행된 이미지를 시맨틱 세그멘테이션 모델에 입력으로 제공하면, 상기 시 맨틱 세그멘테이션 모델이 이미지의 각 픽셀을 장애물, 통로, 타 모바일 로봇 및 사람 등의 클래스로 분류하되주변 장애물의 위치와 경계를 파악할 수 있다. 상기 거리산출부는, 상기 객체감지부에서 감지한 객체와 해당 영상을 촬영한 상기 모바일 로봇 과의 거리를 산출할 수 있다. 여기서, 상기 거리산출부를 이용하여 영상 데이터 내 객체와의 거리를 산출하는 방법은, 상기 영상촬영 장 치에 스테레오 카메라 또는 시간 차를 이용한 이미지 촬영 방법을 사용하여 영상 데이터의 픽셀 단위로 대상물 과의 거리를 측정하여 3D 깊이 맵을 생성하는 깊이 맵 생성(Depth Map Generation) 또는 구조화된 광 패턴을 대 상물에 조사하여 해당 패턴이 변형된 형태를 촬영하는 구조화된 광조사(Structured Light) 방법을 이용하여 촬 영된 영상 데이터 내 패턴 왜곡을 기반으로 대상물과의 거리를 측정하는 방법 등이 사용될 수 있다. 한편, 상기 영상촬영장치가 360도 카메라인 경우, 360도 카메라로 촬영된 영상 데이터에 깊이 추정(Depth Estimation) 알고리즘을 적용하여 상대적인 거리 정보를 추출하고, 모바일 로봇에 LiDAR(Light Detection and Ranging)와 같은 거리 측정 센서와 조합하여 거리 측정의 정확도를 향상시킬 수 있다. 이때, 상기 LiDAR는 레이저를 이용하여 물체와의 거리를 정밀하게 측정하는 기술로, 360도 카메라로 측정된 깊 이 정보와 비교 및 보완하는 거리 측정 데이터를 수집할 수 있다. 또 다른 방법으로는, 상기 거리측정부는, 상기 영상촬영장치가 360도 카메라인 경우, 상기 360도 카메라와 무선 송수신 모듈을 결합하여 무선 시그널의 시차(Time of Arrival, TOA)를 측정할 수 있다. 이를 통해, 시그널 을 전송하는 기준점과 수신되는 기준점 사이의 시간 차이를 계산하여 대상 객체와의 거리를 추정하여 산출할 수 있다. 다시 도 1을 참고하면, 상기 센서부는, 기설정된 공간 및 상기 모바일 로봇 내 온도 측정센서, 습도 측정 센서, 유해가스 농도 측정센서 및 미세먼지 농도 측정센서를 마련하여 환경정보를 수집할 수 있다. 여기서, 상기 기설정된 공간은, 모바일 로봇과 근로자가 혼재하여 작업을 수행하는 공장, 물류센터 등의 공간을 의미하며, 해당 공간 내 기둥, 모바일 로봇 이동경로 등에 상기 언급된 측정센서가 마련되어 환경 정보를 수집할 수 있다. 또한, 상기 센서부는, 기설정된 공간에 마련된 장비와 작업 특성에 따라, 압력 측정센서, 가속도 측정센서, 광센서, 레이저 센서, 초음파 센서, 자기 센서, 무게 센서 등이 더 마련되어 해당 센서를 통해 측정 가능한 환경정보를 더 수집할 수 있다. 또한, 상기 센서부는, 기설정된 공간 주변의 근로자 단말, 모바일 로봇 및 모바일 로봇 관리자 단말에 무 선신호를 발송하여 위치 정보를 전달하는 비콘(Beacon)이 더 마련될 수 있다. 이를 통해, 상기 모바일 로봇 및 근로자는 비콘을 이용하여 공장 내 정확도가 높은 위치파악이 수행되며 해당 비콘이 위치한 특정 지점에 상기 모바일 로봇 또는 근로자 단말이 도달했을 시 발생시키는 신호인 트리거를 발 생시킬 수 있다. 일례로, 상기 트리거는 모바일 로봇 또는 근로자가 위험 지역에 위치한 경우 근로자 단말, 모바일 로봇 및 모바 일 로봇 관리자 단말에 경고 신호를 발생시킬 수 있다. 또 다른 일례로, 근로자의 건강상태에 문제가 생겼을 시, 상기 근로자 단말 및 해당 근로자가 자리한 위치와 가 장 가까운 위치의 비콘 신호가 트리거 되는 경우, 현재 근로자 단말로부터 구조 요청 신호 수신 시, 전송된 비 콘 위치 정보를 통해 상기 근로자 단말의 상세한 위치를 상기 모니터링부에 전송하여 신속한 대처를 수행 할 수 있다. 여기서, 상기 센서부는 도 3을 참고하여 더욱 상세히 설명한다. 도 3을 참고하면, 상기 센서부는, 센서 정보수집부, 센서 오류측정부 및 데이터 전송부를 포함할 수 있다. 상기 센서 정보수집부는, 상기 언급된 측정센서(온도 측정센서, 습도 측정센서, 유해가스 농도 측정센서 및 미세먼지 농도 측정센서)에 공급하는 공급전압, 소비전류 및 출력전압을 수집할 수 있다. 보다 상세하게는, 상기 센서 정보수집부는, 측정센서의 전원 공급선과 출력선에 전압 및 전류 측정센서를 더 마련하여 전원으로부터 공급받는 공급전압, 소비전류 및 출력전압을 수집할 수 있다.한편, 상기 측정센서로부터 기설정된 반경 내 동일한 센서(동일한 모델의 센서)가 비교센서로 구비될 수 있다. 여기서, 상기 기설정된 반경은, 상기 측정센서의 중심위치로부터 10mm 내지 500mm 반경 내의 위치가 이상적이며, 측정센서와 근접할수록 비교 시 정확도가 높은 것으로 판단할 수 있다. 상기 센서 오류측정부는, 측정센서로부터 수집된 센싱 데이터의 측정값 변화율이 기설정된 ㅂ비율을 초과 하는 시각인 비교 대상 시각을 추출할 수 있다. 여기서, 상기 기설정된 비율은, 25% 내지 30%로 설정될 수 있으며, 측정센서의 종류와 주변 환경에 따라 최소 10%에서 최대 90%까지 기설정된 비율이 변경될 수 있다. 또한, 상기 센싱 데이터의 측정값 변화율을 산출하는 방법은, 상기 센서 정보수집부에서 수집한 센싱 데이 터의 시간 범위 내 t2시각에 측정한 측정값 Tt2에서 ta시간 간격인 t1시각에 측정한 측정값 Tt1을 차감한 값에 Tt1 측정값을 나눈 후, 100을 곱하여 절대값을 취한 값을 측정값 변화율로 산출할 수 있다. 일례로, 사용자가 설정한 시간간격이 2초, 현재 측정센서인 온도센서가 동작한 후 종료까지의 측정시각이 총 2000초이고, 1520초에 측정한 측정값이 21℃, 1518초에 측정한 측정값이 31.6℃인 경우, 측정값 변화율은 약 36.2%(100*(21-28.6)/21)로 산출될 수 있다. 이때, 상기 사용자가 설정한 비율이 30%인 경우, 상기 측정값 변화 율이 30%를 초과했기 때문에 1518초는 비교 대상 시각으로 추출될 수 있다. 한편, 상기 센서 오류측정부는, 상기 측정값 변화율이 기설정된 비율을 초과하는 시각이 존재하지 않아 추 출되지 않는 경우, 센싱 데이터 내 n개의 임의의 시각에 대응하는 센싱 데이터를 비교 대상 시각으로 추출하여 상기 모니터링부에 전송할 수 있다. 여기서, 상기 센싱 데이터 내 무작위 n개의 시각을 추출하는 방법은, 프로그래밍 언어가 적용된 프로그램을 이 용하여 추출할 수 있으며, 상기 프로그래밍 언어는 파이썬(python), 자바(Java), C언어, C++, 자바스크립트 (JavaScript), 고(Go), 루비(Ruby), 스위프트(Swift), 코틀린(Kotlin), PHP, C#(C Sharp) 등을 의미할 수 있다. 일례로, 파이썬을 이용하여 센싱 데이터 내 무작위 n개의 시각을 추출하는 방법은, Random 모듈과 Datetime 모 듈을 이용하여 센싱 데이터 내 센서가 동작하는 시간 범위를 설정한 후 무작위 n개의 시각을 추출하거나, Numpy 모듈을 이용할 수 있다. 또한, 상기 센싱 데이터 내 n개의 시각을 무작위로 추출하는 또 다른 방법은 피셔-예이츠 셔플(Fisher-Yates shuffle) 알고리즘을 상기 센싱 데이터의 시간범위에 적용하여 센싱 데이터 내 n개의 시각을 무작위로 추출하는 방법이 사용될 수 있다. 한편, 상기 센서 오류측정부에서 추출되는 n개의 시각에서 n은 사용자가 설정한 운용환경에 따라 달라질 수 있는 자연수를 의미하며, 임의의 시각인 n개의 시각에 대한 의미는 센싱 데이터에서 수집된 전체 시간 중 규 칙성이 없는 랜덤(Random) 형식으로 추출한 시각을 의미할 수 있다. 상기 데이터 전송부는, 센서 오류측정부의 비교 대상 시각을 주기적으로 상기 모니터링부에 전 송할 수 있다. 또한, 상기 데이터 전송부는, 상기 센서 정보수집부에서 수집된 측정센서의 공급전압, 소비전류 및 출력전압을 포함하는 데이터를 상기 모니터링부에 전송할 수 있다. 상기와 같은 과정을 통해, 상기 센서부는, 다수 개의 측정센서로부터 수집한 측정값의 집합인 센싱 데이터 를 모바일 로봇 관리자 단말, 시설의 관리 또는 안전 관리를 수행하는 관리자 단말 및 근로자 단말에 전송하며, 기설정된 시간 간격에 대응하여 센싱 데이터의 변화율이 기설정된 변화율을 초과하지 않는 구간을 '표준상태 구 간'으로 구분하고, 상기 기설정된 변화율을 초과하는 구간을 '이상상태 구간'으로 구분할 수 있다. 여기서, 상기 관리자 단말을 포함하는 입력장치를 이용하여 사익 센서부에서 수집된 센싱 데이터의 '이상 상태 구간'이 사용자가 설정한 '이상상태 구간'의 최대 시간 범위를 초과하거나 상기 '이상상태 구간'이 발생한 횟수가 일정 횟수를 초과하는 경우, 해당 센서가 위치한 공정의 공정중지, 모바일 로봇의 이동 중지, 모바일 로 봇의 작동 중지, 시스템 일시정지, 전원차단, 해당 위치와 인접한 근로자 및 모바일 로봇 관리자 단말에 이상신 호 전송 및 관리자 단말에 센서 교체 알람 신호를 상기 모니터링부에 전송하는 동작이 자동 수행되도록 설 정할 수 있다. 이를 통해, 이상현상 발생에 대한 빠른 대처를 수행할 수 있다.또한, 상기 센서부는, 모바일 로봇을 이용한 사고 예방 시스템이 구성된 공간인 공장, 물류센터 등의 공간 내 마련된 다수 개의 측정센서로부터 수집한 센싱 데이터를 이용하여 진단한 환경정보를 상기 모니터링부 , 모바일 로봇, 모바일 로봇 관리자 단말, 근로자 단말 및 관리자 단말로 전송하여 내부 환경정보를 공유 할 수 있다. 또한, 설정한 상대습도 측정값 상한치 및 하한치를 기준하여 측정값이 해당 값을 벗어난 값으로 측정되는 경우 도 '이상상태 구간'으로 분류할 수 있다. 일례로, 모바일 로봇을 이용한 사고 예방 시스템이 구성된 물류센터 내 위치한 습도 측정센서를 이용하여 측정되는 상대습도의 평균값이 90~95%이고, 센서 담당자(관리자)가 센싱 데이터 변화율 설정값을 20%로 설정한 상태이고, 0초에서 46,800초까지의 상대습도를 측정한 센싱 데이터를 이용하여 '표준상태 구간' 또는 '이상상태 구간' 분류를 수행하는 경우, 상기 상대습도의 초당 변화율이 센싱 데이터 변화율 설정값과 동일한 수치인 20% 를 초과하는 구간을 '이상상태 구간', 초당 변화율이 20%미만인 구간을 '표준상태 구간'으로 분류할 수 있다. 즉, 상대습도 상한치는 95%, 하한치는 90%로 설정한 상태이고, 149초에서 측정된 상대습도 측정값이 72%, 150초 에서 측정된 상대습도 측정값이 91%, 151초에서 측정된 상대습도 측정값이 97%인 경우, 149~150초 구간에 대한 변화율은 약26.38(100*(91-72)/72)로 산출될 수 있다. 이때, 상기 149~150초 구간은 초당 변화율이 20%를 초과 하므로 '이상상태 구간'으로 분류될 수 있다. 또한, 상기 150~151초 구간에 대한 초당 변화율은 약 6.59%(100*(917-91)/91)로 산출되어 초당 변화율이 20%를 초과하지 않으나, 151초에서 측정된 상대습도 측정값 이 센서 담당자(관리자)가 설정한 상한치인 95%를 초과했기 때문에 '이상상태 구간'으로 분류될 수 있다. 또한, 상기 센서부는, 측정센서의 위치로부터 기설정된 반경 내 동일한 사양의 센서인 비교센서를 더 마련 할 수 있다. 이때, 모바일 로봇에 동일한 사양의 센서가 마련된 경우, 상기 모바일 로봇이 이동중에 기설정된 위 치에 마련된 측정센서와 일정 거리 내로 인접한 경우, 상기 모바일 로봇 내 마련된 동일한 사양의 센서가 비교센서로 인식될 수 있다. 일례로, 물류센터 내 기둥에 온도 측정센서가 측정센서로 마련되어 있고, 상기 온도 측정센서로부터 100mm 거리 에 상기 온도 측정센서와 동일한 사양의 온도 센서인 비교센서가 더 마련되어 있는 상태에서, 해당 기둥을 지나 는 모바일 로봇에도 동일한 온도 측정센서가 마련되어 상기 기둥에 마련된 온도 측정센서와의 거리가 100mm 미 만이 되는 시점에서 모바일 로봇 내 온도 측정센서 역시 비교센서로 인식될 수 있다. 이때, 상기 측정센서 가 위치한 기둥과 상기 모바일 로봇간의 거리를 측정하는 방법은, 상기 기둥에 초음파센서, 모바일 로봇과 100mm 거리 미만으로 인식되는 RFID, 모바일 로봇 내 영상처리부를 통해 산출된 상기 기둥과의 거리 가 100mm이하인 경우 자동으로 현재 온도 측정센서로부터 측정되는 온도 센싱 데이터를 전송하는 방법을 사용할 수 있다. 한편, 상기 비교센서가 고정형인 경우, 상기 측정센서가 마련된 위치로부터 10mm 내지 500mm 떨어진 위치에 고 정되어 마련될 수 있다. 일례로, 상기 측정센서가 물류센터 내 기둥에 마련된 경우, 상기 비교센서는 상기 측정센서가 마련된 기둥으로 부터 10mm 내지 500mm 떨어진 위치 내 동일한 사양으로 마련되어 비교센서로 사용될 수 있다. 상기와 같이, 마련된 비교센서로부터 수집된 센싱 데이터 및 상기 측정센서로부터 측정된 센싱 데이터는 상기 모니터링부에 자동 전송될 수 있다. 다시 도 1을 참고하면, 상기 모바일 로봇 제어부는, 영상처리부 및 환경정보에 대응하여 모바일 로봇 에 원격 제어 신호를 전송할 수 있다. 보다 상세하게는, 상기 모바일 로봇 제어부는, 영상처리부에서 모니터링부로 데이터를 전송한 이후 다시 상기 모니터링부에서 전송된 신호에 대응하여 모바일 로봇의 감속, 정지, 동력 차단, 원점 이동 등의 신호를 수신하고, 이를 최우선 명령으로 처리하여 모바일 로봇의 제어를 수행할 수 있다. 여기서, 상기 모바일 로봇의 제어를 수행하는 조건은, 모바일 로봇의 배터리 시간이 기설정된 비율 미만, 모바일 로봇 관리자의 웨어러블 단말로부터 수집한 건강 데이터의 기준치 범위 초과, 상기 모바일 로봇과 근로자간 안전거리가 기준치 미만, 해당 모바일 로봇과 인접한 근로자의 웨어러블 단말로부터 수집한 건강 데이터가 기준치 범위를 초과하고 구조요청 신호가 전송된 시점 등이 상기 모바일 로봇 제어부를 통해 제 어하는 조건으로 설정되며, 해당 조건의 추가 및 삭제를 통해 작업환경에 따른 제어 조건을 자유롭게 설정 및변경할 수 있다. 일례로, 물류센터 내 물류를 상차 또는 하차하는 모바일 로봇으로부터 수집한 배터리 전원 정보를 기초한 최대 운행시간은 6시간으로 산출되고, 모바일 로봇과 근로자 간 안전거리가 5m로 설정된 상태에서 상기 모 바일 로봇 관리자가 모바일 로봇의 상·하차 경로 및 동작 프로그래밍을 수행한 후 최초로 09시 00분에 작 업을 시작하여 11시 30분까지 운행하였으며, 13시부터 15시까지 운행한 후, 15시20분부터 다시 운행을 한 경우, 16시 40분이 되는 시점에 금일 총운행시간의 잔여시간이 10분남았음을 알릴 수 있다. 또한, 16시 50분이 되는 시점에는 해당 모바일 로봇 관리자에게 잔여 배터리 시간 및 원점이동 요청 신호를 전송하며, 해당 모바일 로봇 관리자가 원점이동을 수행하지 않는 경우, 상기 모바일 로봇은 자동으로 원점 이동 수행될 수 있다. 또한, 모바일 로봇이 작업 중 영상촬영장치로부터 수집된 영상 데이터의 분석을 통해 장애물, 통로, 타 모바일 로봇 및 근로자를 구분하되, 타 모바일 로봇 간 안전거리인 5m 반경 내 위치한 경우 10m 내지 5m거리까지 속도제한 및 감속신호를 전송하여 모바일 로봇 간 충돌을 방지할 수 있다. 한편, 상기 근로자와 안전거리가 5m 내로 좁혀지는 경우, 상기 모바일 로봇의 동력을 즉시 차단하여 근로자와의 충동사고를 예방할 수 있다. 상기 모니터링부는, 모바일 로봇의 운행 정보, 상기 모바일 로봇으로부터 촬영되는 영상 데이터 및 환경정보를 수신하고, 기설정된 기준에 대응하여 모바일 로봇, 모바일 로봇 관리자, 관리자, 근로자 등 의 단말에 경보 알림을 전송할 수 있다. 보다 상세하게는, 상기 모니터링부는, 모바일 로봇을 관리하는 관리자 정보, 작업기록, 상기 센서부 에서 수집한 환경정보, 상기 모바일 로봇의 이동경로, 예상 작업 경로, 예상 작업명, 영상촬영장치로 부터 객체 감지된 영상처리 정보, 모바일 로봇 관리자 단말 및 근로자 단말에 자동 알림 및 경보를 전송하기 위 한 조건 설정 및 경보 전달 방식 등의 설정 및 신호 전송을 수행할 수 있다. 여기서, 상기 모바일 로봇의 작업을 위한 경로는 다양한 알고리즘과 프로세스가 적용될 수 있으며 지도 기반의 경로, SLAM(Simultaneous Localization and Mapping), A*알고리즘(A Star Algorithm), Dijkstra알고리즘 등을 이용하여 작업 경로를 설정할 수 있다. 또한, 상기 모니터링부는, 측정센서 및 비교센서로부터 수집된 센싱 데이터 및 비교 대상 시각을 이용하여 하기 [수학식 1]에 따라 센서 고장 확률(STR)을 산출할 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "(여기서, STR은 센서 고장 확률, Tms1은 제1 시각에서 측정센서의 측정값, Tms2는 제2 시각에서 측정센서의 측정값, Tms3은 제3 시각에서 측정센서의 측정값, Tmsn은 제n 시각에서 측정센서의 측정값, Tcst1은 제1 시각에서 비교센서의 측정값, Tcst2는 제2 시각에서 비교센서의 측정값, Tcs3는 제3 시각에서 비교센서의 측정값, Tcsn은 제n 시각에서 비교센서의 측정값, Tmsav는 측정센서의 평균 측정값, SE는 측정센서의 효율 편차를 의미함) 이때, 상기 측정센서의 평균 효율(SEav)은 하기 [수학식 2]에 따라 산출할 수 있다. [수학식 2]"}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "(여기서, SEav는 측정센서의 평균 효율, SEi는 측정센서의 초기 효율을 의미함) 상기 측정센서의 평균 효율은 하기 [수학식 3]에 따라 산출할 수 있다. [수학식 3] (여기서, WIN1은 제1 시각에서 측정센서에 공급되는 전력, WOUT1은 제1 시각에서 측정센서가 센싱한 측정값을 전기 신호로 출력 시 측정되는 전력, WIN2은 제2 시각에서 측정센서에 공급되는 전력, WOUT2은 제2 시각에서 측정센서가 센싱한 측정값을 전기신호로 출력 시 측정되는 전력, WINn은 제n 시각에서 측정센서에 공급되는 전력, WOUTn은 제n 시각에서 측정센서가 센싱한 측정값을 전기신호로 출력 시 측정되는 전력을 의미함) 이때, 상기 [수학식 1] 내지 [수학식 3]에서 언급된 n시각은 상기 센서 오류측정부에서 추출한 센싱 데이 터의 측정값 변화율이 기설정된 비율을 초과하는 복수 개의 시각 또는 랜덤 추출된 시각의 개수를 의미할 수 있 다. 일례로, 물류센터 기둥에 측정센서로 마련된 제1 온도센서와, 상기 제1 온도센서와 동일한 모델이고 10mm반경 내 비교센서로 마련된 제2 온도센서가 구비되어 있는 상태에서 상기 제1 온도센서의 입출력 전압 및 측정센서 내부의 소비전류가 표시될 수 있다. 이때, 상기 측정센서에서 3개의 시각이 추출되고, 추출된 제1 시각 내지 제 3 시각동안 공급된 전압이 4.9V, 5V, 5V이고, 해당 시각에서 상기 측정센서가 1mA, 0.9mA, 1.1mA의 전류를 소비 하고, 10mV, 9mV, 11mV으로 출력되는 것으로 측정되는 경우, 측정센서에 공급되는 제1 시각에서의 입력 전력 (WIN1)은 0.0049W(4.9V*0.001A), 제2 시각에서의 입력 전력(WIN2)은 0.0045W(5V*0.0009A), 제3 시각에서의 입력 전력(WIN3)은 0.0055W(5V*0.0011A)로 계산될 수 있다. 또한, 상기 측정센서로부터 출력되는 제1 시각의 출력 전 력(Wout1)은 0.00001W(0.01V*0.001A), 제2 시각의 출력 전력(WOUT2-)은 0.000081W(0.009V*0.0009A), 제3 시각의 출력 전력(WOUT3)은 0.0000121W(0.011V*0.0011A)로 산출될 수 있다. 이를 이용하여 상기 측정센서의 평균 효율 (SEav)은 약 0.74(100/3*(0.00001/0.0049+0.000081/0.0045+0.0000121/0.0055))로 산출될 수 있다. 이때, 측정 되는 측정센서의 제조사에서 제공하는 초기 효율(SEi)이 0.75%인 경우, 측정센서의 효율 편차(SE)는 -0.01로 산 출될 수 있다. 여기서, 상기 측정센서의 평균 효율(SEav)은 산출값이 0에 수렴할수록 효율적인 센서이며, 제조사 로부터 수집되거나 초기에 측정된 측정값을 이용하여 산출된 효율인 초기 효율보다 산출값이 높을수록 센서의 전기적인 영역에서의 고장 확률이 높은 것으로 판단할 수 있다. 한편, 상기 측정센서의 초기 효율(SEi)이 제공되 지 않는 경우에는 상기 시선 유도봉에 마련되기 전 측정한 효율을 초기 효율(SEi)로 설정하여 상기 모니터링부 에 입력될 수 있다. 또한, 상기 온도 측정센서가 마련된 물류센터 내 환경이 60도의 온도로 유지되도록 설정된 환경에서 제1 온도 센서의 동작에 따른 센싱 데이터가 0초부터 28,800초까지 수집될 수 있다. 이때, 상기 제1 온도 센서로부터 수 집한 평균 측정값이 60.5℃이고, 센싱 데이터 처리 프로그램을 이용하여 상기 제1 온도 센서의 센싱 데이터로부 터 무작위 3개의 시각을 추출한 경우, 각 시각에서 측정되는 측정값이 59℃(485초), 65℃(1893초), 71℃(2021초)로 추출될 수 있다. 여기서, 상기 제1 온도 센서와 동시에 작동한 제2 온도 센서로부터 동일한 시 각과 각 시각에서 측정되는 측정값이 60.1℃(485초), 62.5℃(1893초), 53℃(2021초)일 때 상기 제1 온도 센서의 고장 확률(STR)을 산출할 수 있다. 즉, 상기 제1 온도 센서의 고장 확률(STR)은, 약 14.1%(Min((｜59-60.1｜+｜ 65-62.5｜+｜51-73｜)/(3*60.5)*100+0), 100)로 산출될 수 있다. 또 다른 일례로, 상기 모니터링부는, 상기 측정센서와 비교센서의 거리에 따른 가중치를 반영한 하기 [수 학식 1-2]에 따라, 센서 고장 확률(STR)을 산출할 수 있다. [수학식 1-2]"}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "(여기서, Dv는 측정센서와 비교센서의 거리 가중치를 의미함) 이때, 상기 측정센서와 비교센서의 거리값 가중치(D-v)는, 사용자가 설정한 가중치에 대응하여 적용되며, 상기 가중치는 사용자가 자유롭게 변경하여 적용할 수 있다. 일례로, 측정센서와 비교센서가 동일한 모델의 온도 측정센서로 상기 시선 유도봉의 측면에 마련되는 경우, 측 정센서와 비교센서의 거리(D)에 따른 측정센서와 비교센서의 거리 가중치(Dv)는 하기 [표 1]에 따라 산출될 수 있다.[표 1]"}
{"patent_id": "10-2023-0100599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이때, 거리 가중치(Dv)를 반영하지 않은 상기 실시례와 동일한 조건인 경우, 상기 거리 가중치(Dv)가 반영된 제1 온도 센서의 고장 확률(STR)은, 약 14.1%(Min((｜59-60.1｜+｜65-62.5｜+｜51-73｜)/(3*60.5)*1*100+0), 100)로 산출될 수 있다. 상기와 같은 과정을 통해, 상기 모니터링부는, 상기 센서부로부터 수집한 센싱 데이터를 이용하여 센 서의 고장 확률(STR)을 산출할 수 있다. 또한, 상기 모니터링부를 통해 산출된 고장 확률(STR)이 기설정된 비율을 초과하는 경우, 상기 기설정된 사 용자 단말에 센서의 고장알림, 교체 알림 등을 전송할 수 있다. 여기서, 상기 고장 확률(STR)의 기설정된 비율은 기본적으로 40%로 설정될 수 있으며, 센서의 종류와 민감도에 따라 사용자가 0 내지 99% 사이로 비율을 재설정할 수 있다. 한편, 상기 모니터링부는, 산출된 센서 고장 확률(STR)이 기설정된 범위를 초과하는 경우, 센서를 관리하는 관리자 단말에 센서 교체 및 점검 알림 전송을 수행할 수 있다. 여기서, 상기 기설정된 확률은 40%이상으로 산출된 경우를 의미할 수 있으나, 센서의 종류와 센서로부터 측정되 는 센싱 데이터의 중요도에 따라 교체 알림 발송의 기준이 되는 센서 고장 확률(STR)의 수치는 사용자에 의해 자 유롭게 변경될 수 있다. 한편, 상기 모니터링부에서 센서 고장으로 판단한 경우, 해당 센서가 위치한 인근에 소형 스피커 또는 LED 조명 기저장된 음성 출력 및 조명 출력 수행 명령 신호를 전송하여 고장 상태를 표시할 수 있다. 또한, 상기 모니터링부는, 모바일 로봇 관리자 및 근로자의 기설정된 웨어러블 단말로부터 건강정보 데이 터를 실시간으로 수신할 수 있다. 여기서, 상기 기설정된 웨어러블 단말은, 운전자 및 근로자가 착용한 웨어러블 스마트 기기를 의미하며 대표적 으로 스마트워치, 스마트링 등 착용자의 체온, 심박수 등을 측정할 수 있는 단말기를 의미할 수 있다. 이를 통해, 상기 모니터링부는, 모바일 로봇 관리자의 건강정보 데이터가 기설정된 기준 범위를 벗어나는 경우, 상기 모바일 로봇 관리자가 작업 관리 및 제어중인 모바일 로봇이 기설정된 위치로 강제 이동할 수 있다. 여기서, 상기 기설정된 위치는, 상기 모바일 로봇의 충전, 대기, 수리 등이 이루어지는 모바일 로봇의 대 기장소를 의미하며, 사용자 설정에 대응하여 강제 이동하는 위치가 자유롭게 변경될 수 있다. 또한, 상기 모니터링부를 통해 수신된 상기 근로자의 건강정보 데이터가 기설정된 기준 범위를 벗어나는 경우, 근로자의 단말과 가장 가까운 운전자 및 타 근로자 단말 중 적어도 하나의 단말에 구조요청 알림 및 상기 근로자 단말의 위치정보를 자동 전송할 수 있다. 일례로, 근로자의 건강정보 데이터의 정상 기준 범위가 체온 36.5~37.5℃이고, 정상 심박수 기준 범위가 분당 60~100회로 설정된 상황에서 해당 시간 근로자의 심박수가 분당 60회 미만이거나 체온이 38.5℃를 초과한 것으 로 상기 모니터링부에 전송된 경우, 상기 모니터링부는 상기 센서부에 마련된 비콘을 이용하여 해당 근로자의 단말위치를 파악할 수 있다. 이후 상기 모니터링부는, 해당 위치와 가장 가까운 타 근로자 단말에 구조요청 알림을 송신하고, 인근의 모바일 로봇 관리자 단말 전체에 건강이상 근로자의 위치와 구조 예 상 경로에 작업중인 모바일 로봇의 작업을 중지시켜 구조시간이 지연되는 상황을 미연에 방지할 수 있다. 여기서, 상기 근로자 단말의 위치정보는, 상기 근로자 단말과 가장 가까운 비콘을 감지하여 해당 비콘의 위치정 보를 전송할 수 있다. 상기와 같은 과정을 통해, 상기 모바일 로봇을 이용한 사고 예방 시스템은 근로자와 중장비가 혼재하는 공간에 서 모바일 로봇과 근로자가 혼재하여 작업 시, 모바일 로봇에 마련된 영상촬영장치를 이용하여 수집한 영상 데 이터를 인공지능 기반의 객체 감지를 수행하여 장애물, 통로, 타 모바일 로봇 및 근로자를 구별하여 안전사고를 예방할 수 있다. 또한, 해당 공간 내 다수 개의 센서 및 비콘을 마련하여 주변 환경정보를 수집하고, 근로자 단말 및 모바일 로봇을 통해 공간 내 위치를 정확하게 식별할 수 있다. 한편, 상기 센서들의 경우, 측정센서 인근 에 동일한 사양의 비교센서를 더 마련하여 센서의 고장확률 산출 및 이상여부를 빠르게 파악하여 유해가스 누출, 급격한 기온상승 등으로 인해 발생할 수 있는 대량의 인명사고를 미연에 방지할 수 있다. 또한, 모바일 로봇을 이용한 작업 시 모바일 로봇 관리자, 근로자의 건강정보 데이터를 수집하고, 건강정보 데이터가 기준 범 위를 벗어나는 경우, 구조요청 및 해당 단말의 위치를 자동 전송하여 인근 근로자 단말, 모바일 로봇 및 모바일 로봇 관리자에 전송하여 구조 경로 확보 및 빠른 구조를 수행할 수 있다. 본 발명의 일실시례에 따르면, 본 발명에 따르면, 본 발명은 근로자와 모바일 로봇이 혼재하는 공간 내 모바일 로봇에 센서 및 영상촬영장치를 마련함으로써, 공간 내 환경정보 및 영상정보를 데이터화하여 분석할 수 있다. 또한, 모바일 로봇으로부터 수집한 데이터를 분석함으로써, 모바일 로봇 인근의 근로자, 장애물, 타 모바일 로 봇, 경로를 구분하고 이에 대응하는 동작을 수행하여 작업 효율성을 향상시킬 수 있다. 또한, 모바일 로봇의 이동에 대응하여 공간 내 마련된 타 센서 및 근로자의 단말과 무선통신함으로써, 순찰 및 경비 역할과 동시에 해당 근로자로부터 수집한 건강정보가 기준범위를 벗어날 시 도움요청 및 이상신호를 전송 하여 안전사고 발생 시 빠른 대응을 수행할 수 있다. 이상과 같이 본 발명의 일실시례는 비록 한정된 실시례와 도면에 의해 설명되었으나, 본 발명의 일실시례는 상 기 설명된 실시례에 한정되는 것은 아니며, 이는 본 발명이 속하는 분야에서 통상의 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변형이 가능하다. 따라서 본 발명의 일실시례는 아래에 기재된 특허청구범위에 의해 서만 파악되어야 하고, 이의 균등 또는 등가적 변형 모두는 본 발명 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2023-0100599", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시례에 따른 모바일 로봇을 이용한 사고 예방 시스템의 블록도를 도시한 도면이다. 도 2는 본 발명의 일실시례에 따른 모바일 로봇을 이용한 사고 예방 시스템 내 영상처리부의 중간 블록도를 도 시한 도면이다. 도 3은 본 발명의 일실시례에 따른 모바일 로봇을 이용한 사고 예방 시스템 내 센서부의 중간 블록도이다."}
