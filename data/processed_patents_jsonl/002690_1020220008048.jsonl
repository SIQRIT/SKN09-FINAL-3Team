{"patent_id": "10-2022-0008048", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0111959", "출원번호": "10-2022-0008048", "발명의 명칭": "인공지능 모델 학습을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법 및 이", "출원인": "주식회사 콕스웨이브", "발명자": "김기정"}}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(a) 딥러닝 모델에 대한 학습을 수행하는 컴퓨팅 시스템이, 상기 딥러닝 모델을 학습하는데 이용될 데이터 셋의매니페스트(manifest)를 상기 데이터셋을 스트리밍하는 클라우드 서버로부터 수신하는 단계-여기서, 상기 데이터셋은 상기 딥러닝 모델을 1 에폭(epoch)만큼 학습할 수 있는 데이터를 포함하며, 상기 데이터셋의 매니페스트는, 상기 데이터 셋을 구성하는 데이터 조각의 형태 정보를 포함함;(b) 상기 컴퓨팅 시스템이, 상기 딥러닝 모델에 설정된 배치 크기(batch size)에 상응하는 데이터 조각 요청을상기 클라우드 서버로 전송하는 단계;(c) 상기 클라우드 서버가, 상기 데이터 조각 요청에 응답하여 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 상기 컴퓨팅 시스템으로 전송하는 단계;(d) 상기 컴퓨팅 시스템이, 수신한 상기 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 이용하여 상기 딥러닝 모델을 1 이터레이션(iteration)만큼 학습하는 단계; 및(e) 상기 딥러닝 모델이 1 에폭만큼 학습될 때까지, 상기 (b) 단계 내지 상기 (d) 단계를 반복 수행하는 단계를포함하는 딥러닝을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 데이터 조각 요청은, 재가공 형태에 대한 정보를 포함하고,상기 (c) 단계는,상기 재가공 형태 정보에 기초하여 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각을 재가공하여, 상기적어도 하나의 데이터 조각 각각의 재가공 데이터를 생성하는 단계; 및 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 상기 컴퓨팅 시스템으로 전송하는 단계를 포함하는 딥러닝을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 재가공 형태 정보는,이미지 파일의 사이즈 정보, 이미지 파일의 화질 정보, 추가될 노이즈 정보, 이미지의 표준화 정보, 이미지의크롭에 관한 정보 및 이미지의 회전에 관한 정보 중 적어도 하나를 포함하는 딥러닝을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 컴퓨팅 시스템은 상기 컴퓨팅 시스템에 설치된 그래픽 프로세서 유닛(Graphic Process Unit; GPU)를 이용하여 상기 딥러닝 모델을 학습하며,상기 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법은,공개특허 10-2023-0111959-3-상기 컴퓨팅 시스템이, 상기 GPU의 잔여 메모리의 크기를 측정하는 단계; 및상기 컴퓨팅 시스템이, 상기 잔여 메모리의 크기에 기초하여 상기 배치 사이즈를 조정하는 단계를 더 포함하는딥러닝을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 잔여 메모리의 크기에 기초하여 상기 배치 사이즈를 조정하는 단계는, 상기 잔여 메모리의 크기가 소정의 기준 수치보다 작은 경우, 상기 배치 사이즈를 축소하는 단계; 및상기 잔여 메모리의 크기가 소정의 기준 수치보다 큰 경우, 상기 배치 사이즈를 확대했을 때의 예상 잔여 메모리 크기를 산출하고, 산출한 상기 예상 잔여 메모리의 크기가 상기 기준 수치보다 크면 상기 배치 사이즈를 확대하는 단계를 포함하는 딥러닝을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "(a) 딥러닝 모델에 대한 학습을 수행하는 컴퓨팅 시스템이, 상기 딥러닝 모델을 학습하는데 이용될 데이터 셋의 매니페스트(manifest)를 상기 데이터셋을 스트리밍하는 클라우드 서버로부터 수신하는 단계-여기서, 상기 데이터셋은 상기 딥러닝 모델을 1 에폭(epoch)만큼 학습할 수 있는 데이터를 포함하며, 상기 데이터셋의 매니페스트는, 상기 데이터 셋을 구성하는 데이터 조각의 형태 정보를 포함함;(b) 상기 컴퓨팅 시스템이, 상기 딥러닝 모델에 설정된 배치 크기(batch size)에 상응하는 데이터 조각 요청을상기 클라우드 서버로 전송하는 단계-여기서 상기 클라우드 서버는, 상기 데이터 조각 요청에 응답하여 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를상기 컴퓨팅 시스템으로 전송함;(c) 상기 컴퓨팅 시스템이, 상기 클라우드 서버로부터 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 수신하는 단계; 및(d) 상기 컴퓨팅 시스템이, 수신한 상기 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 이용하여 상기 딥러닝 모델을 1 이터레이션(iteration)만큼 학습하는 단계; 및(e) 상기 딥러닝 모델이 1 에폭만큼 학습될 때까지, 상기 (b) 단계 내지 상기 (d) 단계를 반복 수행하는 단계를포함하는 동적으로 스트리밍되는 클라우드 기반 호스팅 데이터셋을 이용한 딥러닝 방법."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 데이터 조각 요청은, 재가공 형태에 대한 정보를 포함하고,상기 클라우드 서버는,상기 재가공 형태 정보에 기초하여 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각을 재가공하여, 상기적어도 하나의 데이터 조각 각각의 재가공 데이터를 생성하고, 상기 적어도 하나의 데이터 조각 각각의 재가공데이터를 상기 컴퓨팅 시스템으로 전송하는 동적으로 스트리밍되는 클라우드 기반 호스팅 데이터셋을 이용한 딥러닝 방법."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,공개특허 10-2023-0111959-4-상기 컴퓨팅 시스템은 상기 컴퓨팅 시스템에 설치된 그래픽 프로세서 유닛(Graphic Process Unit; GPU)를 이용하여 상기 딥러닝 모델을 학습하며,상기 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법은,상기 컴퓨팅 시스템이, 상기 GPU의 잔여 메모리의 크기를 측정하는 단계; 및상기 컴퓨팅 시스템이, 상기 잔여 메모리의 크기에 기초하여 상기 배치 사이즈를 조정하는 단계를 더 포함하는동적으로 스트리밍되는 클라우드 기반 호스팅 데이터셋을 이용한 딥러닝 방법."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 잔여 메모리의 크기에 기초하여 상기 배치 사이즈를 조정하는 단계는, 상기 잔여 메모리의 크기가 소정의 기준 수치보다 작은 경우, 상기 배치 사이즈를 축소하는 단계; 및상기 잔여 메모리의 크기가 소정의 기준 수치보다 큰 경우, 상기 배치 사이즈를 확대했을 때의 예상 잔여 메모리 크기를 산출하고, 산출한 상기 예상 잔여 메모리의 크기가 상기 기준 수치보다 크면 상기 배치 사이즈를 확대하는 단계를 포함하는 동적으로 스트리밍되는 클라우드 기반 호스팅 데이터셋을 이용한 딥러닝 방법."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "데이터 처리장치에 설치되며 제1항 내지 제9항 중 어느 한 항에 기재된 방법을 수행하기 위한 매체에 기록된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제9항 중 어느 한 항에 기재된 방법을 수행하기 위한 컴퓨터 프로그램이 기록된 컴퓨터 판독 가능한기록매체."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "컴퓨팅 시스템으로서,프로세서; 및 컴퓨터 프로그램을 저장하는 메모리를 포함하고,상기 컴퓨터 프로그램은, 상기 프로세서에 의해 실행되는 경우, 상기 컴퓨팅 시스템으로 하여금 제6항 내지 제9항 중 어느 한 항에 기재된 방법을 수행하도록 하는 컴퓨팅 시스템."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "클라우드 기반 호스팅 데이터셋을 이용하여 딥러닝 모델에 대한 학습을 수행하는 컴퓨팅 시스템으로서,딥러닝 모델을 학습하는데 이용될 데이터 셋의 매니페스트(manifest)를 상기 데이터셋을 스트리밍하는 클라우드서버로부터 수신하고, 상기 딥러닝 모델에 설정된 배치 크기(batch size)에 상응하는 데이터 조각 요청을 상기클라우드 서버로 전송하는 데이터 파싱 모듈-여기서, 상기 데이터셋은 상기 딥러닝 모델을 1 에폭(epoch)만큼학습할 수 있는 데이터를 포함하며, 상기 데이터셋의 매니페스트는 상기 데이터 셋을 구성하는 데이터 조각의형태 정보를 포함하고, 상기 클라우드 서버는 상기 데이터 조각 요청에 응답하여 상기 데이터 조각 요청에 포함된 배치 크기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 상기 컴퓨팅 시스템으로 전송함;상기 클라우드 서버로부터 수신한 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하공개특허 10-2023-0111959-5-나의 데이터 조각 각각의 재가공 데이터를 저장하는 스토리지 모듈; 및수신한 상기 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 이용하여 상기 딥러닝 모델을 1 이터레이션(iteration)만큼 학습하는 학습모듈을 포함하는 컴퓨팅 시스템."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 학습모듈은 상기 컴퓨팅 시스템에 설치된 그래픽 프로세서 유닛(Graphic Process Unit; GPU)를 이용하여상기 딥러닝 모델을 학습하며,상기 컴퓨팅 시스템은,상기 GPU의 잔여 메모리의 크기를 측정하고, 상기 잔여 메모리의 크기에 기초하여 상기 배치 사이즈를 조정하는적응형 컨트롤러 모듈을 더 포함하는 컴퓨팅 시스템."}
{"patent_id": "10-2022-0008048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 적응형 컨트롤러 모듈은, 상기 잔여 메모리의 크기가 소정의 기준 수치보다 작은 경우, 상기 배치 사이즈를 축소하고,상기 잔여 메모리의 크기가 소정의 기준 수치보다 큰 경우, 상기 배치 사이즈를 확대했을 때의 예상 잔여 메모리 크기를 산출하고, 산출한 상기 예상 잔여 메모리의 크기가 상기 기준 수치보다 크면 상기 배치 사이즈를 확대하는 컴퓨팅 시스템."}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 모델 학습을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법 및 이를 수행 하는 컴퓨팅 시스템에 관한 것이다.이 개시된다. 본 발명의 일 측면에 따르면, (a) 딥러닝 모델에 대한 학습을 수행하는 컴퓨팅 시스템이, 상기 딥러닝 모델을 학습하는데 이용될 데이터 셋의 매니페스트(manifest)를 상기 데 (뒷면에 계속)"}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델 학습을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법 및 이를 수행 하는 컴퓨팅 시스템에 관한 것이다. 본 발명은 인공지능 학습에 필수 요소인 데이터셋에 관련한 분야이다. 그 중에서 특히, 클라우드 기반 데이터셋에 관하여 다룬다."}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "공공 데이터셋은 단순히 공부를 위한 용도로만 사용되는 것이 아니라, 새로운 모델 개발 시 퍼포먼스 비교나 초 과학습을 방지하기 위한 용도 등 다양한 필요에 의해 사용된다. 기존의 클라우드 기반 공공 데이터셋의 경우, 데이터셋별 홈페이지를 만들어서 공유하거나 고용량의 경우 별도 의 다운로드 프로그램을 통해 다운 받을 수 있었다. 상대적으로 용량이 작은 데이터셋(eg. MNIST)의 경우에는 큰 문제가 없지만, 데이터셋의 용량이 수백 기가바이트 내지는 수 테라바이트까지도 이르는 요즈음 데이터셋을 다운로드 받는 것만 하더라도 쉬운 일이 아니다. 공공 데이터셋을 받아 인공지능 모델 학습을 시작하기 위해서 는 데이터셋을 해당 실험이 진행될 워크스테이션(컴퓨터)에 다운로드 받고 시작해야하기 때문에 실험을 시작하 기도 전에 많은 시간이 낭비되고 있는 실정이다. (https://aihub.or.kr/aihub-data/vision/about)"}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적인 과제는 인공지능 모델 학습을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법 및 이를 수행하는 컴퓨팅 시스템을 제공하는 것이다. 본 발명은 클라우드 호스팅 데이터셋 을 사용한 인공지능 모델 학습 시, 데이터셋 사전 다운로드에 의한 실험 시작 지연이라는 문제점을 해결하고자 한다."}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, (a) 딥러닝 모델에 대한 학습을 수행하는 컴퓨팅 시스템이, 상기 딥러닝 모델을 학습하는데 이용될 데이터 셋의 매니페스트(manifest)를 상기 데이터셋을 스트리밍하는 클라우드 서버로부터 수 신하는 단계-여기서, 상기 데이터셋은 상기 딥러닝 모델을 1 에폭(epoch)만큼 학습할 수 있는 데이터를 포함하 며, 상기 데이터셋의 매니페스트는, 상기 데이터 셋을 구성하는 데이터 조각의 형태 정보를 포함함; (b) 상기 컴퓨팅 시스템이, 상기 딥러닝 모델에 설정된 배치 크기(batch size)에 상응하는 데이터 조각 요청을 상기 클라 우드 서버로 전송하는 단계; (c) 상기 클라우드 서버가, 상기 데이터 조각 요청에 응답하여 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 상기 컴퓨 팅 시스템으로 전송하는 단계; (d) 상기 컴퓨팅 시스템이, 수신한 상기 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 이용하여 상기 딥러닝 모델을 1 이터레이션(iteration)만큼 학습하는 단계; 및 (e) 상기 딥러닝 모델이 1 에폭만큼 학습될 때까지, 상기 (b) 단계 내지 상기 (d) 단계를 반 복 수행하는 단계를 포함하는 딥러닝을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법이 제공 된다. 일 실시예에서, 상기 데이터 조각 요청은, 재가공 형태에 대한 정보를 포함하고, 상기 (c) 단계는, 상기 재가공 형태 정보에 기초하여 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각을 재가공하여, 상기 적어도 하나 의 데이터 조각 각각의 재가공 데이터를 생성하는 단계; 및 상기 적어도 하나의 데이터 조각 각각의 재가공 데 이터를 상기 컴퓨팅 시스템으로 전송하는 단계를 포함할 수 있다. 일 실시예에서, 상기 재가공 형태 정보는, 이미지 파일의 사이즈 정보, 이미지 파일의 화질 정보, 추가될 노이 즈 정보, 이미지의 표준화 정보, 이미지의 크롭에 관한 정보 및 이미지의 회전에 관한 정보 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 상기 컴퓨팅 시스템은 상기 컴퓨팅 시스템에 설치된 그래픽 프로세서 유닛(Graphic Process Unit; GPU)를 이용하여 상기 딥러닝 모델을 학습하며, 상기 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리 밍 방법은, 상기 컴퓨팅 시스템이, 상기 GPU의 잔여 메모리의 크기를 측정하는 단계; 및 상기 컴퓨팅 시스템이, 상기 잔여 메모리의 크기에 기초하여 상기 배치 사이즈를 조정하는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 잔여 메모리의 크기에 기초하여 상기 배치 사이즈를 조정하는 단계는, 상기 잔여 메모리의 크기가 소정의 기준 수치보다 작은 경우, 상기 배치 사이즈를 축소하는 단계; 및 상기 잔여 메모리의 크기가 소 정의 기준 수치보다 큰 경우, 상기 배치 사이즈를 확대했을 때의 예상 잔여 메모리 크기를 산출하고, 산출한 상 기 예상 잔여 메모리의 크기가 상기 기준 수치보다 크면 상기 배치 사이즈를 확대하는 단계를 포함할 수 있다. 본 발명의 다른 일 측면에 따르면, (a) 딥러닝 모델에 대한 학습을 수행하는 컴퓨팅 시스템이, 상기 딥러닝 모 델을 학습하는데 이용될 데이터 셋의 매니페스트(manifest)를 상기 데이터셋을 스트리밍하는 클라우드 서버로부 터 수신하는 단계-여기서, 상기 데이터셋은 상기 딥러닝 모델을 1 에폭(epoch)만큼 학습할 수 있는 데이터를 포 함하며, 상기 데이터셋의 매니페스트는, 상기 데이터 셋을 구성하는 데이터 조각의 형태 정보를 포함함; (b) 상 기 컴퓨팅 시스템이, 상기 딥러닝 모델에 설정된 배치 크기(batch size)에 상응하는 데이터 조각 요청을 상기 클라우드 서버로 전송하는 단계-여기서 상기 클라우드 서버는, 상기 데이터 조각 요청에 응답하여 상기 배치 크 기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 상기 컴퓨팅 시스템으로 전송함; (c) 상기 컴퓨팅 시스템이, 상기 클라우드 서버로부터 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 수신하는 단계; 및 (d) 상기 컴퓨팅 시스템이, 수신한 상기 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각 의 재가공 데이터를 이용하여 상기 딥러닝 모델을 1 이터레이션(iteration)만큼 학습하는 단계; 및 (e) 상기 딥 러닝 모델이 1 에폭만큼 학습될 때까지, 상기 (b) 단계 내지 상기 (d) 단계를 반복 수행하는 단계를 포함하는 동적으로 스트리밍되는 클라우드 기반 호스팅 데이터셋을 이용한 딥러닝 방법이 제공된다. 본 발명의 다른 일 측면에 따르면, 데이터 처리장치에 설치되며 상술한 방법을 수행하기 위한 매체에 기록된 컴 퓨터 프로그램이 제공된다. 본 발명의 다른 일 측면에 따르면, 상술한 방법을 수행하기 위한 컴퓨터 프로그램이 기록된 컴퓨터 판독 가능한 기록매체가 제공된다. 본 발명의 다른 일 측면에 따르면, 컴퓨팅 시스템으로서, 프로세서; 및 컴퓨터 프로그램을 저장하는 메모리를 포함하고, 상기 컴퓨터 프로그램은, 상기 프로세서에 의해 실행되는 경우, 상기 컴퓨팅 시스템으로 하여금 상술한 방법을 수행하도록 하는 컴퓨팅 시스템이 제공된다. 본 발명의 다른 일 측면에 따르면, 클라우드 기반 호스팅 데이터셋을 이용하여 딥러닝 모델에 대한 학습을 수행 하는 컴퓨팅 시스템으로서, 딥러닝 모델을 학습하는데 이용될 데이터 셋의 매니페스트(manifest)를 상기 데이터 셋을 스트리밍하는 클라우드 서버로부터 수신하고, 상기 딥러닝 모델에 설정된 배치 크기(batch size)에 상응하 는 데이터 조각 요청을 상기 클라우드 서버로 전송하는 데이터 파싱 모듈-여기서, 상기 데이터셋은 상기 딥러닝 모델을 1 에폭(epoch)만큼 학습할 수 있는 데이터를 포함하며, 상기 데이터셋의 매니페스트는 상기 데이터 셋을 구성하는 데이터 조각의 형태 정보를 포함하고, 상기 클라우드 서버는 상기 데이터 조각 요청에 응답하여 상기 데이터 조각 요청에 포함된 배치 크기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 상기 컴퓨팅 시스템으로 전송함; 상기 클라우드 서버로부터 수신한 상기 배치 크 기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 저장 하는 스토리지 모듈; 및 수신한 상기 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 이용하여 상기 딥러닝 모델을 1 이터레이션(iteration)만큼 학습하는 학습모듈을 포함하는 컴 퓨팅 시스템이 제공된다. 일 실시예에서, 상기 학습모듈은 상기 컴퓨팅 시스템에 설치된 그래픽 프로세서 유닛(Graphic Process Unit; GPU)를 이용하여 상기 딥러닝 모델을 학습하며, 상기 컴퓨팅 시스템은, 상기 GPU의 잔여 메모리의 크기를 측정 하고, 상기 잔여 메모리의 크기에 기초하여 상기 배치 사이즈를 조정하는 적응형 컨트롤러 모듈을 더 포함할 수 있다. 일 실시예에서, 상기 적응형 컨트롤러 모듈은, 상기 잔여 메모리의 크기가 소정의 기준 수치보다 작은 경우, 상 기 배치 사이즈를 축소하고, 상기 잔여 메모리의 크기가 소정의 기준 수치보다 큰 경우, 상기 배치 사이즈를 확 대했을 때의 예상 잔여 메모리 크기를 산출하고, 산출한 상기 예상 잔여 메모리의 크기가 상기 기준 수치보다 크면 상기 배치 사이즈를 확대할 수 있다."}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 기술적 사상에 의하면, 본 발명은 인공지능 모델 학습을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법 및 이를 수행하는 컴퓨팅 시스템을 제공할 수 있다. 또한 클라우드 호스팅 데이터셋으로 인공지능 모델을 학습하려고 하는 사용자는 본 발명을 통해 크게 세가지 이 득을 취할 수 있다. 첫째, 데이터셋을 모두 다운로드(복제)하지 않고도 학습을 시작할 수 있기에 더욱 빠른 학 습이 가능하다. 둘째, 실험 중간에 GPU 메모리의 부족 등으로 인해 발생하는 batch size(1회 학습에 필요한 데 이터 사이즈의 기준이 됨)에 순응하여 동적으로 적용되기 때문에 실험을 재시작할 필요가 없기에 불필요한 시간 및 컴퓨팅 자원을 낭비하지 않는다. 셋째, 워크스테이션마다, 데이터셋 버전이 바뀔 때마다 실험을 위해 복제해 둘 필요가 없기 때문에 저장 공간을 절약할 수 있다."}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어 야 한다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다 고 판단되는 경우 그 상세한 설명을 생략한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 제1, 제2 등의 용어는 특별한 순서를 나타내는 것이 아니며, 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에 있어서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 또한, 본 명세서에 있어서는 어느 하나의 구성요소가 다른 구성요소로 데이터를 '전송'하는 경우에는 상기 구성 요소는 상기 다른 구성요소로 직접 상기 데이터를 전송할 수도 있고, 적어도 하나의 또 다른 구성요소를 통하여 상기 데이터를 상기 다른 구성요소로 전송할 수도 있는 것을 의미한다. 반대로 어느 하나의 구성요소가 다른 구 성요소로 데이터를 '직접 전송'하는 경우에는 상기 구성요소에서 다른 구성요소를 통하지 않고 상기 다른 구성 요소로 상기 데이터가 전송되는 것을 의미한다. 이하, 첨부된 도면들을 참조하여 본 발명의 실시예들을 중심으로 본 발명을 상세히 설명한다. 각 도면에 제시된 동일한 참조부호는 동일한 부재를 나타낸다. 도 1은 본 발명의 일 실시예에 따른 인공지능 모델 학습(딥러닝)을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법(이하, '데이터셋 스트리밍 방법'이라고 함)의 동작 환경을 나타내는 도면이다. 상기 데이터셋 스트리밍 방법은 데이터셋을 이용하여 딥러닝 모델을 학습하는 컴퓨팅 시스템 및 상기 컴퓨 팅 시스템로 데이터셋을 스트리밍하는 클라우드 서버에 의해 수행될 수 있다. 상기 컴퓨팅 시스템은 자신에게 할당된 딥러닝 모델을 학습할 수 있으며, 상기 클라우드 서버에 서 제공하는 데이터셋을 이용하여 자신에게 할당된 딥러닝 모델을 학습할 수 있다. 본 명세서에서 딥러닝 모델(deep learning model)은 딥러닝을 통해 특정한 문제를 해결할 수 있도록 학습될 수 있는 인공 뉴럴 네트워크(artificial neural network)을 지칭하는 용어일 수 있으며, 인공 뉴럴 네트워크는 인 간의 뉴런의 동작 원리에 기초하여 인공적으로 구축한 뉴럴 네트워크로서, 다층 퍼셉트론 모델을 포함하며, 인 공 뉴럴 네트워크를 정의하는 일련의 설계사항들을 표현하는 정보의 집합을 의미할 수 있다. 상기 딥러닝 모델 은 입력 레이어(input layer)과 출력 레이어(output layer) 사이에 여러 개의 은닉 레이어(hidden layer) 들로 이뤄진 인공신경망일 수 있다. 일 실시예에서, 상기 딥러닝 모델은 컨볼루셔널 뉴럴 네트워크(Convolutional Neural Network, CNN)이거나 혹은 컨볼루셔널 뉴럴 네트워크를 포함할 수 있다. 컨볼루셔널 뉴럴 네트워크는 잘 알려진 바와 같이, 입력 레 이어, 복수의 히든 레이어들, 및 출력 레이어를 포함할 수 있다. 복수의 히든 레이어들 각각은 컨볼루션 레이어 및 풀링 레이어(또는 서브 샘플링 레이어)를 포함할 수 있다. 컨볼루션 뉴럴 네트워크는 이러한 각각의 레이어 들을 정의하기 위한 함수, 필터, 스트라이드(stride), 웨이트 팩터 등에 의해 정의될 수 있다. 또한, 출력 레이 어는 풀리 커넥티드(fully connected)된 전방향 레이어(FeedForward layer)로 정의될 수 있다. 컨볼루션 뉴럴 네트워크를 구성하는 각각의 레이어별 설계 사항은 널리 알려져 있다. 예컨대, 복수의 레이어들에 포함될 레이 어의 개수, 상기 복수의 레이어들을 정의하기 위한 컨볼루션 함수, 풀링 함수, 활성화 함수 각각에 대해서는 공 지된 함수들이 이용될 수도 있고, 본 발명의 기술적 사상을 구현하기 위해 별도로 정의된 함수들이 이용될 수도 있다. 다만 상기 딥러닝 모델은 반드시 컨볼루셔널 뉴럴 네트워크인 것은 아니며, 실시예에 따라서 상기 딥러닝 모델은 순환 신경망(Recurrent Neural Network, RNN), LSTM(Long Short-Term Memory) 모델, 혹은 인코더/ 디코더 모델일 수도 있다. 상기 클라우드 서버는 저장장치에 적어도 하나의 데이터 셋(20, 20-1 내지 20-M)을 저장할 수 있으며, 상 기 컴퓨팅 시스템의 요청이 요청하는 데이터셋(예를 들어, 20)을 요청한 컴퓨팅 시스템으로 스트리밍할 수 있다. 상기 클라우드 서버에 저장된 각각의 데이터셋은 복수의 데이터 조각으로 구성될 수 있으며 상기 클라우드 서버는 적어도 하나의 데이터 조각 단위로 데이터를 스트리밍할 수 있다. 상기 컴퓨팅 시스템은 상기 클라우드 서버로부터 데이터셋을 모두 수신한 후에 딥러닝 모델을 학습하는 것이 아니라 데이터 셋의 데이터 조각을 차례로 수신하면서 수신한 데이터 조각을 차례로 이용하여 딥러닝 모델을 학습할 수 있다. 데이터셋을 구성하는 데이터 조각 각각은 파일의 형태일 수도 있지만 이에 한정되는 것은 아니며, 데이터셋을 구성하는 각각의 데이터 조각은 미리 설정된 기준에 의해 상기 데이터셋을 분할한 일부일 수 있다. 예를 들어, 상기 데이터 조각은 데이터 셋 전체를 특정한 크기로 분할하거나 특정한 구분자를 기준으로 분할한 각각의 부분 일 수도 있다. 예를 들어 상기 데이터셋이 복수의 이미지로 구성된 경우 상기 데이터셋을 구성하는 데이터 조각은 각각의 이미 지 파일일수도 있으며, 하나의 이미지를 일정한 크기로 분할한 부분 이미지일 수도 있다. 또한, 예를 들어 상기 데이터셋이 복수의 텍스트로 구성된 경우 상기 데이터셋을 구성하는 데이터 조각은 각각의 텍스트 파일, 텍스트 를 구성하는 각각의 문장 혹은 단락일 수도 있다. 한편 상기 클라우드 서버는 저장하고 있는 데이터셋(20, 20-1 내지 20-M) 각각에 상응하는 매니페스트(30, 30-1 내지 30-M)를 더 저장할 수 있다. 상기 매니페스트는 그에 상응하는 데이터셋 및/또는 해당 데이터셋을 구성하는 데이터 조각에 대한 정보를 포함 하는 메타데이터일 수 있다. 상기 매니페스트는 그에 상응하는 데이터셋의 고유식별정보, 데이터셋의 명칭, 데 이터셋의 크기, 데이터셋에 대한 설명이나 개요 정보, 데이터 타입(예를 들어, 이미지, 텍스트, 음성, 비디오 등), 데이터 구조, 버전 번호, 라이선스, 데이터 셋을 구성하는 데이터 조각의 리스트나 데이터 조각의 형태 정 보(예를 들어, 데이터 조각의 크기, 형태, 타입 등)를 포함할 수 있다. 또한 데이터셋이 이미지로 구성되어 있 는 경우, 이미지의 해상도나 색공간의 타입에 관한 정보 등을 더 포함할 수도 있다. 상기 컴퓨팅 시스템은 상기 클라우드 서버가 제공하는 각 데이터셋의 매니페스트(20, 20-1 내지 20- M)을 먼저 획득하여, 상기 상기 클라우드 서버가 제공할 수 있는 데이터셋을 미리 파악할 수 있으며, 특정 데이터셋의 매니페스트를 분석하여 스트리밍받을 데이터셋에 대한 유효한 데이터 조각 요청을 생성하고, 상기 클라우드 서버로부터 데이터 조각 요청에 상응하는 하나 혹은 복수의 데이터 조각을 수신하고, 딥러닝 모 델이 읽을 수 있는 텐서 형태로 변환하여 스토리지에 저장할 수 있다. 또한 스토리지에 보관된 데이터를 인공지 능 학습 프레임워크(PyTorch, Tensorflow 등)에 제공하여 딥러닝 모델이 학습되도록 할 수 있다. 한편, 상기 클라우드 서버는 다수의 컴퓨팅 시스템(100, 100-1 내지 100-N)으로 데이터셋을 스트리밍할 수 있으며, 각각의 컴퓨팅 시스템(100, 100-1 내지 100-N) 각각은 상기 클라우드 서버로부터 학습에 필요한 데이터셋을 받아 자신에게 할당된 딥러닝 모델(10, 10-1 내지 10-N)을 학습할 수 있다. 상기 컴퓨팅 시스템(100, 100-1 내지 100-N)은 전자적인 정보 처리를 수행하는 정보처리시스템일 수 있다. 상기 컴퓨팅 시스템(100, 100-1 내지 100-N)은 휴대전화, 위성전화, 무선전화, 스마트폰, 타블렛 PC, PDA(Personal Digital Assistant) 등의 핸드헬드 장치 혹은 랩탑이나 데스크탑을 포함하는 사용자 단말일 수도 있으나 이에 한정되는 것은 아니며, 워크스테이션이나 서버일 수도 있다. 상기 클라우드 서버는 서버 장치, 또는 서버 장치 및 상기 서버 장치에 설치되는 소프트웨어의 결합의 형 태일 수 있다. 서버 장치는 단일의 장치 또는 소정의 통신 인터페이스를 통하여 연결된 복수의 장치로 구성된 장치 군으로 구현될 수 있다. 상기 컴퓨팅 시스템(100, 100-1 내지 100-N)은 딥러닝 모델의 학습을 위해 필요한 전용 애플리케이션이 설치될 수 있으며, 필요에 따라 상기 컴퓨팅 시스템(100, 100-1 내지 100-N)은 상기 클라우드 서버와 통신하며 본 발명의 기술적 사상을 구현하기 위한 각종 메시지, 신호, 데이터 및/또는 정보를 송수신할 수 있다. 일 실시예 에서, 상기 컴퓨팅 시스템(100, 100-1 내지 100-N)은 HTTP 통신을 통해 상기 클라우드 서버로 요청을 전송 하거나 데이터를 수신할 수 있다.도 2는 본 발명의 일 실시예에 따른 데이터셋 스트리밍 방법 및 이를 이용한 딥러닝 모델 학습 방법을 설명하기 위한 도면이다. 도 2를 참조하면, 상기 클라우드 서버는 데이터셋의 매니페스트를 상기 컴퓨팅 시스템으로 전송할 수 있다(S100). 상기 데이터셋은 복수의 데이터 조각(예를 들어 31)로 구성될 수 있다. 또한 실시예에 따라 상기 데이터셋은 딥러닝 모델을 1 에폭(epoch)만큼 학습할 수 있는 데이터 조각을 포함할 수 있다. 상기 데이터셋의 매니페스트는 상기 데이터 셋을 구성하는 데이터 조각(예를 들어 31)의 형 태 정보를 포함할 수 있다. 예를 들어 상기 매니페스트는 데이터 조각의 크기, 타입, 해상도 등의 정보 를 포함할 수 있다. 이 외에도 앞서 설명한 바와 같이 상기 매니페스트는 상기 데이터셋 혹은 상기 데 이터셋을 구성하는 각각의 데이터 조각과 관련된 각종 정보를 더 포함할 수 있음은 물론이다. 한편 상기 컴퓨팅 시스템은 수신한 매니페스트를 통하여 데이터셋의 구성을 파악하고, 그에 기초하여 상기 딥러닝 모델에 설정된 배치 크기(batch size)에 상응하는 데이터 조각 요청을 생성할 수 있다(S200). 상기 데이터 조각 요청은 상기 딥러닝 모델에 설정된 상기 배치 크기만큼 데이터 조각들을 전송해달라는 요청일 수 있다. 일 실시예에서, 상기 데이터 조각 요청은 상기 배치 사이즈에 대한 정보를 포함할 수 있으며, 이 경우 상기 클 라우드 서버가 상기 데이터 조각 요청에 포함된 배치 사이즈와 각 데이터 조각의 크기를 비교하여, 전송할 적어도 하나의 데이터 조각을 결정할 수 있다. 다른 일 실시예에서, 상기 데이터 조각 요청은 상기 클라우드 서 버가 전송할 데이터 조각의 개수가 포함될 수 있으며, 이 경우 상기 데이터 조각 요청에 포함되는 데이터 조각의 개수는 상기 컴퓨팅 시스템에 의해 결정될 수 있다. 실시예에 따라, 상기 딥러닝 모델에 설정된 배치 크기는 네트워크 상태나 상기 컴퓨팅 시스템의 리소스(예 를 들어, 딥러닝 모델 학습에 이용되는 그래픽 프로세서 유닛(Graphic Process Unit; GPU)의 메모리 사용량 등)에 의해 동적으로 결정될 수 있는데, 이에 대하여는 후술하기로 한다. 한편, 상기 컴퓨팅 시스템은 생성한 데이터 조각 요청을 상기 클라우드 서버로 전송할 수 있으며 (S300), 상기 클라우드 서버는 상기 데이터 조각 요청에 응답하여 상기 배치 크기에 상응하는 적어도 하나 의 데이터 조각을 상기 컴퓨팅 시스템으로 전송할 수 있다(S500). 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각은 상기 딥러닝 모델을 1이터레이션만큼 학습할 수 있는 양의 데이터일 수 있으며, 상기 컴퓨팅 시스템은 수신한 상기 적어도 하나의 데이터 조각을 이용하여 상기 딥러닝 모델을 1 이터레이션(iteration)만큼 학습할 수 있다(S600). 보다 상세하게는 상기 컴퓨팅 시스템 은 수신한 적어도 하나의 데이터 조각을 상기 딥러닝 모델에 입력 가능한 텐서 형태로 변환하여 스토 리지에 저장할 수 있으며, 스토리지에 저장된 텐서 형태의 데이터를 이용하여 상기 딥러닝 모델을 학습할 수 있 다. 한편, 실시예에 따라서, 상기 데이터 조각 요청은 재가공 형태에 대한 정보를 포함할 수 있다. 예를 들어, 상기 재가공 형태 정보는 이미지 파일의 사이즈 정보, 이미지 파일의 화질 정보, 추가될 노이즈 정보, 이미지의 표준 화 정보, 이미지의 크롭에 관한 정보 및 이미지의 회전에 관한 정보 중 적어도 하나를 포함할 수 있다. 재가공 형태에 대한 정보를 포함하는 데이터 조각 요청을 수신한 상기 클라우드 서버는 상기 재가공 형태 정보에 기초하여 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각을 재가공하여, 상기 적어도 하나의 데 이터 조각 각각의 재가공 데이터를 생성할 수 있으며(S400), 상기 적어도 하나의 데이터 조각 각각의 재가공 데 이터를 상기 컴퓨팅 시스템으로 전송할 수 있다(S500). 그러면 상기 컴퓨팅 시스템은 수신한 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 이용하여 상기 딥러닝 모델을 1 이터레이션만큼 학습할 수 있다 (S600). 한편, 상기 컴퓨팅 시스템은 수신한 데이터 조각들(혹은 이들의 재가공 데이터)을 이용하여 상기 딥러닝 모델이 학습되는 동안, 상기 S200 내지 S500 단계를 다시 수행하여 다음에 이용할 적어도 하나의 데이터 조 각(혹은 이들의 재가공 데이터)를 미리 수신할 수 있으며, 이전에 수신한 데이터 조각들(혹은 이들의 재가공 데 이터)에 의한 학습이 완료되면 다음에 수신한 적어도 하나의 데이터 조각(혹은 이들의 재가공 데이터)를 이용하 여 다음 이터레이션의 학습 과정을 수행할 수 있다(S600). 또한 상기 컴퓨팅 시스템은 상기 데이터셋 에 의해 딥러닝 모델이 1 에폭(epoch)만큼 학습될 때까지 이를 반복 수행할 수 있다. 도 3은 데이터 조각의 획득 및 획득한 데이터 조각에 의한 딥러닝 모델 학습 과정의 일 예를 시간 순으로 표현 한 도면이다. 도 3을 참조하면, 상기 컴퓨팅 시스템은 데이터 조각 D1 내지 D5를 획득한 후, 데이터 조 각 D1 내지 D5을 이용하여 딥러닝 모델을 1이터레이션만큼 학습할 수 있으며, 데이터 조각 D1 내지 D5을 이 용하여 딥러닝 모델이 학습되는 동안 다음에 이용할 데이터 조각 D6 내지 D10을 획득할 수 있다. 데이터 조 각 D1 내지 D5을 이용한 학습 과정의 완료되고 데이터 조각 D6 내지 D10의 획득 과정도 완료되면 상기 컴퓨팅 시스템은 데이터 조각 D6 내지 D10을 이용하여 딥러닝 모델을 1이터레이션만큼 학습할 수 있으며, 데이 터 조각 D6 내지 D10을 이용하여 딥러닝 모델이 학습되는 동안 다음에 이용할 데이터 조각 D11 내지 D15를 획득 할 수 있다. 데이터 조각 D6 내지 D10을 이용한 학습 과정의 완료되고 데이터 조각 D11 내지 D15의 획득 과 정도 완료되면 상기 컴퓨팅 시스템은 데이터 조각 D11 내지 D15을 이용하여 딥러닝 모델을 1이터레이션만 큼 학습할 수 있으며, 데이터 조각 D11 내지 D15을 이용하여 딥러닝 모델이 학습되는 동안 다음에 이용할 데 이터 조각 D16 내지 D20을 획득할 수 있다. 데이터 조각 D11 내지 D15을 이용한 학습 과정이 완료되고 데이 터 조각 D16 내지 D20의 획득 과정도 완료되면 상기 컴퓨팅 시스템은 데이터 조각 D16 내지 D20을 이용하 여 딥러닝 모델을 1이터레이션만큼 학습할 수 있다. 이와 같이 상기 컴퓨팅 시스템은 데이터셋을 모두 받아두고 이를 이용하여 딥러닝 모델을 학습하는 것 이 아니라, 클라우드 서버가 차례로 스트리밍하는 데이터 조각을 이용하여 딥러닝 모델을 학습할 수 있다. 즉, 데이터셋을 모두 다운로드(복제)하지 않고도 학습을 시작할 수 있기에 더욱 빠른 학습이 가능하다는 장점이 있다. 또한 데이터셋의 버전이 바뀔 때마다 실험/학습을 위해 데이터셋을 복제해 둘 필요가 없기 때문에 저장 공간을 절약할 수 있다는 장점이 있다. 또한 한편 상기 컴퓨팅 시스템은 상기 클라우드 서버로 요청할 데이터 조각의 크기 혹은 개수(즉, 딥러닝 모델의 배치 크기)를 동적으로 조절할 수 있는데, 이하에서는 도 4를 참조하여 이에 대하여 보다 상세하게 설명 하기로 한다. 도 4는 본 발명의 일 실시예에 따른 배치 크기 조절 과정의 일 예를 도시한 흐름도이다. 도 4를 참조하면, 상기 컴퓨팅 시스템은 상기 컴퓨팅 시스템에 설치되어 딥러닝 모델의 학습에 이용되는 GPU의 잔여 메 모리의 크기(Z)를 측정할 수 있다(S10). 상기 컴퓨팅 시스템은 상기 잔여 메모리의 크기(Z)에 기초하여 상기 배치 사이즈를 조정할 수 있으며, 보 다 상세하게는 상기 컴퓨팅 시스템은 상기 잔여 메모리의 크기(Z)가 소정의 기준 수치(예를 들어 전체 GPU 메모리의 10%)보다 작은지 여부를 판단하고(S20), 판단 결과 작은 경우, 상기 배치 크기를 축소할 수 있다 (S30). 만약 잔여 메모리의 크기(Z)가 상기 기준 수치보다 큰 경우, 상기 배치 크기를 확대했을 때의 예상 잔여 메모리 크기(Z')를 산출하고(S40), 산출한 상기 예상 잔여 메모리의 크기(Z')가 상기 기준 수치(예를 들어 전체 GPU 메모리의 10%)보다 크면 상기 배치 사이즈를 확대할 수 있다(S50, S70). 그렇지 않다면 배치 사이즈는 종전 그대로 유지될 수 있다(S60). 이와 같이 본 발명의 기술적 사상에 따르면 딥러닝 모델이 학습되는 과정에서 GPU 메모리의 부족 등으로 인해 발생하는 배치 크기(1 이터레이션의 학습에 필요한 데이터 사이즈의 기준이 됨)에 순응하여 동적으로 적용되기 때문에 학습을 재시작할 필요가 없기에 불필요한 시간 및 컴퓨팅 자원을 낭비하지 않는다는 장점이 있다. 도 5는 본 발명의 일 실시예에 따른 컴퓨팅 시스템의 물리적 구성의 일 예를 개략적으로 도시한 도면이며, 도 6 은 본 발명의 일 실시예에 따른 컴퓨팅 시스템의 논리적 구성의 일 예를 개략적으로 도시한 도면이다. 상기 컴퓨팅 시스템는 물리적으로는 도 5에 도시된 바와 같은 구성을 가질 수 있다. 상기 컴퓨팅 시스템 은 본 발명의 기술적 사상을 구현하기 위한 프로그램 및 딥러닝 모델이 저장되는 메모리, 및 상기 메모리에 저장된 프로그램을 실행하기 위한 프로세서가 구비될 수 있다. 상기 프로세서는 상기 컴퓨팅 시스템의 구현 예에 따라, CPU, APU, 마이크로 프로세서, ASIC 등 다양"}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한 명칭으로 명명될 수 있음을 본 발명의 기술분야의 평균적 전문가는 용이하게 추론할 수 있을 것이다. 또한, 앞서 설명한 바와 같이 상기 컴퓨팅 시스템은 복수의 물리적 장치들이 유기적으로 결합되어 구현될 수도 있으며, 이러한 경우 상기 프로세서는 물리적 장치 별로 적어도 한 개 구비되어 본 발명의 컴퓨팅 시스템"}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "을 구현할 수 있음을 본 발명의 기술분야의 평균적 전문가는 용이하게 추론할 수 있을 것이다. 상기 프로 세서는 딥러닝 모델을 학습하는데 이용되는 GPU를 포함할 수 있다. 상기 메모리는 상기 프로그램이 저장되며, 상기 프로그램을 구동시키기 위해 상기 프로세서가 접근할 수 있는 어떠한 형태의 저장장치로 구현되어도 무방하다. 또한 하드웨어적 구현 예에 따라 상기 메모리는 어 느 하나의 저장장치가 아니라 복수의 저장장치로 구현될 수도 있다. 또한 상기 메모리는 주기억장치뿐만아니라, 임시기억장치를 포함할 수도 있다. 또한 휘발성 메모리 또는 비휘발성 메모리로 구현될 수도 있다 상기 메모리는 예를 들어, 플래시 메모리, ROM, RAM, EEROM, EPROM, EEPROM, 하드 디스크, 레지스터를 포함할 수 있다. 또는 상기 메모리는 상기 프로그램이 저장되고 상기 프로세서에 의해 구동될 수 있도록 구현되는 모든 형태의 정보저장 수단을 포함하는 의미로 정의될 수 있다. 상기 컴퓨팅 시스템은 실시 예에 따라 본 발명의 기술적 사상에 따른 데이터 처리 방법을 수행할 수 있다. 또한 상기 컴퓨팅 시스템의 실시 예에 따라 다양한 주변장치들(주변장치 1 내지 주변장치 K, 180)이 더 구 비될 수 있다. 예를 들어, 키보드, 디스플레이 장치, 그래픽 카드, 네트워킹 장치, 스토리지 장치 등이 주변장"}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "치로서 상기 컴퓨팅 시스템에 더 포함될 수 있음을 본 발명의 기술분야의 평균적 전문가는 용이하게 추론 할 수 있을 것이다. 이하, 본 명세서에서 소정의 모듈이 어떤 기능을 수행한다고 함은 상기 프로세서가 상기 메모리에 구"}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "비된 프로그램을 구동하여 상기 기능을 수행하는 것을 의미함을 본 발명의 기술분야의 평균적 전문가는 용이하 게 추론할 수 있을 것이다. 도 6을 참조하면, 상기 컴퓨팅 시스템은 데이터 파싱 모듈, 스토리지 모듈, 학습모듈, 적 응형 컨트롤러 모듈, 제어모듈을 포함할 수 있다. 본 발명의 실시예에 따라서는, 도 6의 구성요소들 중 일부 구성요소는 반드시 본 발명의 구현에 필수적으로 필요한 구성요소에 해당하지 않을 수도 있으며, 또한 실시예에 따라 상기 컴퓨팅 시스템은 이보다 더 많은 구성요소를 포함할 수도 있음은 물론이다. 예를 들어 상기 컴퓨팅 시스템은 상기 클라우드 서버와 HTTP 등의 통신 프로토콜을 통하여 데이터를 송수신할 수 있는 통신모듈(미도시)을 더 포함할 수 있다. 상술한 인공지능 모델 학습을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법을 수행하는 컴퓨 팅 시스템은 본 발명의 기술적 사상을 구현하기 위해 필요한 하드웨어 리소스(resource) 및/또는 소프트웨어를 구비한 논리적인 구성을 의미할 수 있으며, 반드시 하나의 물리적인 구성요소를 의미하거나 하나의 장치를 의미 하는 것은 아니다. 즉, 상기 컴퓨팅 시스템은 본 발명의 기술적 사상을 구현하기 위해 구비되는 하드웨어 및/또 는 소프트웨어의 논리적인 결합을 의미할 수 있으며, 필요한 경우에는 서로 이격된 장치에 설치되어 각각의 기 능을 수행함으로써 본 발명의 기술적 사상을 구현하기 위한 논리적인 구성들의 집합으로 구현될 수도 있다. 또 한, 상기 컴퓨팅 시스템은 본 발명의 기술적 사상을 구현하기 위한 각각의 기능 또는 역할별로 별도로 구현되는 구성들의 집합을 의미할 수도 있다. 컴퓨팅 시스템의 각 구성은 서로 다른 물리적 장치에 위치할 수도 있고, 동 일한 물리적 장치에 위치할 수도 있다. 또한, 구현 예에 따라서는 상기 컴퓨팅 시스템의 구성 요소 각각을 구성 하는 소프트웨어 및/또는 하드웨어의 결합 역시 서로 다른 물리적 장치에 위치하고, 서로 다른 물리적 장치에 위치한 구성들이 서로 유기적으로 결합되어 각각의 상기 모듈들을 구현할 수도 있다. 또한, 본 명세서에서 모듈이라 함은, 본 발명의 기술적 사상을 수행하기 위한 하드웨어 및 상기 하드웨어를 구 동하기 위한 소프트웨어의 기능적, 구조적 결합을 의미할 수 있다. 예컨대, 상기 모듈은 소정의 코드와 상기 소 정의 코드가 수행되기 위한 하드웨어 리소스(resource)의 논리적인 단위를 의미할 수 있으며, 반드시 물리적으"}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "로 연결된 코드를 의미하거나, 한 종류의 하드웨어를 의미하는 것은 아님은 본 발명의 기술분야의 평균적 전문 가에게는 용이하게 추론될 수 있다. 상기 제어모듈은 상기 컴퓨팅 시스템의 다른 구성(예를 들어, 데이터 파싱 모듈, 스토리지 모듈 , 학습모듈, 적응형 컨트롤러 모듈 등)의 기능 및/또는 리소스를 제어할 수 있다. 상기 데이터 파싱 모듈은 상기 딥러닝 모델을 학습하는데 이용될 데이터 셋의 매니페스트를 상기 데이 터셋을 스트리밍하는 클라우드 서버로부터 수신하고, 상기 클라우드 서버로 상기 딥러닝 모델에 설정된 배치 크기에 상응하는 데이터 조각 요청을 전송할 수 있다. 일 실시예에서, 상기 데이터셋은 상기 딥러 닝 모델을 1 에폭만큼 학습할 수 있는 데이터를 포함할 수 있으며, 상기 데이터셋의 매니페스트는 상기 데이터 셋을 구성하는 데이터 조각의 형태 정보를 포함할 수 있다. 한편, 상기 클라우드 서버는 상기 데이터 조각 요청에 포함된 배치 크기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 상기 컴퓨팅 시스템으로 전송할 수 있다. 상기 스토리지 모듈은 상기 클라우드 서버로부터 수신한 상기 배치 크기에 상응하는 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재가공 데이터를 스토리지 장치에 저장할 수 있다. 상기 학습모듈은 수신한 상기 적어도 하나의 데이터 조각 또는 상기 적어도 하나의 데이터 조각 각각의 재 가공 데이터를 이용하여 상기 딥러닝 모델을 1 이터레이션만큼 학습할 수 있다. 한편, 상기 학습모듈은 상기 컴퓨팅 시스템에 설치된 그래픽 프로세서 유닛를 이용하여 상기 딥러닝 모델을 학습할 수 있다. 상기 적응형 컨트롤러 모듈은 딥러닝이 중단되지 않도록 네트워크 상태, GPU 메모리 등의 클라이언트 리소 스와 인공지능 학습 진행 정도를 실시간으로 추척하여 딥러닝 모델의 학습이 리소스 부족으로 인해 강제 종료되 지 않으면서 학습이 완료되면 바로 준비된 다음 데이터 조각으로 빠른 학습을 할 수 있도록 배치 크기를 적응적 으로 조절할 수 있다. 즉, 상기 적응형 컨트롤러 모듈은 상기 GPU의 잔여 메모리의 크기를 측정하고, 상기 잔여 메모리의 크기에 기초하여 딥러닝 모델의 배치 크기를 동적으로 조정할 수 있다. 일 실시예에서, 상기 적응형 컨트롤러 모듈은 상기 잔여 메모리의 크기가 소정의 기준 수치보다 작은 경우, 상기 배치 사이즈를 축소하고, 상기 잔여 메모리의 크기가 소정의 기준 수치보다 큰 경우, 상기 배치 사 이즈를 확대했을 때의 예상 잔여 메모리 크기를 산출하고, 산출한 상기 예상 잔여 메모리의 크기가 상기 기준 수치보다 크면 상기 배치 사이즈를 확대할 수 있다. 도 7a는 클라우드 데이터셋(좌상)을 사용하려고 하는 여러 컴퓨터(워크스테이션)의 초기 상태를 나타내는 도면 이며, 도 7b는 종전의 방식으로 딥러닝 모델을 시작할 수 있는 데이터 분포 상태를 나타내는 도면이며, 도 7c는 본 발명을 사용했을 때 모델 학습을 시작할 수 있는 데이터 분포 상태를 도시하고 있다. 즉, 종전의 방식의 경우에는 도 7b에 도시된 바와 같이 데이터셋 전체를 학습이 진행될 컴퓨터에 미리 다운로드 를 받고 학습을 시작해야 하기 때문에 학습을 시작하기도 전에 많은 시간이 낭비되는 단점이 있다. 하지만 본 발명의 기술적 사상을 이용할 경우, 도 7c에 도시된 바와 같이 데이터셋을 모두 다운로드(복제)하지 않고도 학 습을 시작할 수 있기에 더욱 빠른 학습이 가능하다는 장점이 있다. 한편, 구현 예에 따라서, 상기 컴퓨팅 시스템은 프로세서 및 상기 프로세서에 의해 실행되는 프로그램을 저장하 는 메모리를 포함할 수 있다. 상기 프로세서는 싱글 코어 CPU혹은 멀티 코어 CPU를 포함할 수 있다. 메모리는 고속 랜덤 액세스 메모리를 포함할 수 있고 하나 이상의 자기 디스크 저장 장치, 플래시 메모리 장치, 또는 기 타 비휘발성 고체상태 메모리 장치와 같은 비휘발성 메모리를 포함할 수도 있다. 프로세서 및 기타 구성 요소에 의한 메모리로의 액세스는 메모리 컨트롤러에 의해 제어될 수 있다. 한편, 본 발명의 실시예에 따른 방법은 컴퓨터가 읽을 수 있는 프로그램 명령 형태로 구현되어 컴퓨터로 읽을 수 있는 기록 매체에 저장될 수 있으며, 본 발명의 실시예에 따른 제어 프로그램 및 대상 프로그램도 컴퓨터로 판독 가능한 기록 매체에 저장될 수 있다. 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함한다. 기록 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 소프트웨어 분야 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터로 읽을 수 있는 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체 (magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media) 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하 고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용 해서 전자적으로 정보를 처리하는 장치, 예를 들어, 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한 다. 상술한 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2022-0008048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타나며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로해석되어야 한다."}
{"patent_id": "10-2022-0008048", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 본 발명의 일 실시예에 따른 인공지능 모델 학습(딥러닝)을 위한 클라우드 기반 호스팅 데이터셋의 동적 적응 스트리밍 방법의 동작 환경을 나타내는 도면이다. 도 2는 본 발명의 일 실시예에 따른 데이터셋 스트리밍 방법 및 이를 이용한 딥러닝 모델 학습 방법을 설명하기 위한 도면이다. 도 3은 데이터 조각의 획득 및 획득한 데이터 조각에 의한 딥러닝 모델 학습 과정의 일 예를 시간 순으로 표현 한 도면이다. 도 4는 본 발명의 일 실시예에 따른 배치 크기 조절 과정의 일 예를 도시한 흐름도이다. 도 5는 본 발명의 일 실시예에 따른 컴퓨팅 시스템의 물리적 구성의 일 예를 개략적으로 도시한 도면이며, 도 6 은 본 발명의 일 실시예에 따른 컴퓨팅 시스템의 논리적 구성의 일 예를 개략적으로 도시한 도면이다. 도 7a는 클라우드 데이터셋을 사용하려고 하는 여러 컴퓨터(워크스테이션)의 초기 상태를 나타내는 도면이며, 도 7b는 종전의 방식으로 딥러닝 모델을 시작할 수 있는 데이터 분포 상태를 나타내는 도면이며, 도 7c는 본 발 명을 사용했을 때 모델 학습을 시작할 수 있는 데이터 분포 상태를 도시하고 있다."}
