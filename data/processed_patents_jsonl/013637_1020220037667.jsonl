{"patent_id": "10-2022-0037667", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0139256", "출원번호": "10-2022-0037667", "발명의 명칭": "무인비행체를 이용한 보행안내장치 및 방법", "출원인": "서울시립대학교 산학협력단", "발명자": "최민제"}}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "무인비행체로부터 보행자가 포함된 보행 이미지를 수집하는 이미지 수집부;상기 수집된 보행 이미지 중 상기 무인비행체가 트래킹(tracking)할 대상인 보행자를 타겟팅하는 타겟팅부; 및상기 보행 이미지의 특징을 나타내는 보행 입력벡터를 생성하고, 학습된 검출모델을 통해 상기 생성된 보행 입력벡터를 분석하여 상기 보행자가 보행하는 주변의 상태를 검출하는 검출부;를 포함하는 보행안내장치."}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 무인비행체로부터 수집된 보행 이미지 중 상기 보행자를 타겟팅하기 위한 타겟모델과, 상기 보행자의 보행경로에 존재하는 장애물을 검출하는 검출모델을 학습하는 학습부;를 더 포함하는 것을 특징으로 하는 보행안내장치."}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 학습부는,학습용 입력벡터와, 학습용 입력벡터에 대응하는 소프트 레이블 및 하드 레이블을 포함하는 레이블을 마련하고,기본손실함수의 하이퍼파라미터를 설정하여 하드 손실 최적화를 위한 하드손실함수를 생성하며, 상기 타겟모델 또는 상기 검출모델에 학습용 입력벡터를 입력하고, 상기 타겟모델 또는 상기 검출모델에 학습용입력벡터에 대해 복수의 계층 간 가중치가 적용되는 복수의 연산을 통해 상기 소프트 레이블에 대응하는 소프트출력값을 산출하면,상기 소프트 출력값을 상기 하드 레이블에 대응하는 하드 출력값으로 변환하고, 상기 변환된 하드 출력값 및 상기 하드 손실함수를 이용하여 상기 하드 레이블과 상기 하드 출력값의 차이를 나타내는 하드 손실이 최소가 되도록 상기 타겟모델 또는 상기 검출모델의 파라미터를 갱신하는 것을 특징으로 하는 보행안내장치."}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 학습부는,기본손실함수의 하이퍼파라미터를 설정하여 복합 손실 최적화를 위한 복합손실함수를 생성하고,상기 타겟모델 또는 상기 검출모델에 학습용 입력벡터를 입력하고, 상기 타겟모델 또는 상기 검출모델에 대해복수의 계층 간 가중치가 적용되는 복수의 연산을 통해 상기 소프트 레이블에 대응하는 소프트 출력값을 산출하면,상기 소프트 출력값으로부터 상기 하드 레이블에 대응하는 하드 출력값을 도출하고, 상기 소프트 출력값, 상기하드 출력값 및 상기 복합손실함수를 이용하여 상기 하드 레이블과 상기 하드 출력값의 차이를 나타내는 하드손실이 최소가 되도록 상기 타겟모델 또는 상기 검출모델의 파라미터를 갱신하는 것을 특징으로 하는 보행안내장치."}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 2항에 있어서,공개특허 10-2023-0139256-3-상기 타겟팅부는,상기 보행 이미지 중 타겟에 해당하는 보행자가 경계 박스(bounding box)로 지정되면 상기 지정된 경계 박스 내에 있는 타겟 이미지를 상기 타겟모델에 적용하여 상기 타겟모델을 학습시키며, 상기 학습된 타겟모델을 통해실시간으로 수집되는 보행 이미지에서 상기 타겟 이미지를 검출하여 상기 보행자를 타겟팅하는 것을 특징으로하는 보행안내장치."}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 검출부는,상기 보행 이미지를 복수의 구역으로 분할하고, 상기 분할된 각 구역마다 식별번호를 부여하고, 상기 식별번호가 부여된 구역별로 상기 보행 입력벡터를 생성하며, 상기 구역별로 생성된 보행 입력벡터를 상기 학습된 검출모델의 입력값으로 적용하는 것을 특징으로 하는 보행안내장치."}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 검출부는,상기 식별번호를 기반으로 상기 보행자의 보행 경로에 존재하는 장애물의 위치를 검출하는 것을 특징으로 하는보행안내장치."}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6항에 있어서,상기 검출부는,상기 보행 이미지의 전방을 기준으로 최상측에 위치한 복수의 구역 중 가장 왼쪽에 위치한 구역으로부터 행과열의 순서대로 식별번호를 부여하는 것을 특징으로 하는 보행안내장치."}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1항에 있어서,상기 검출부는,상기 보행자가 착용하고, 상기 보행자의 시야각에 대응되는 시점 이미지를 촬영하는 스마트 글래스로부터 촬영된 시점 이미지를 더 이용하여 상기 상태를 검출하는 것을 특징으로 하는 보행안내장치."}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 검출부는,상기 검출된 장애물의 종류, 크기, 위치, 이동유무 및 이동속도 중 적어도 하나를 시각, 청각 및 촉각 중 적어도 하나의 감각으로 인지하도록 보행안내신호를 생성하거나,상기 스마트 글래스를 통한 증강현실로 상기 검출된 장애물을 인지하도록 보행안내신호를 생성하는 것을 특징으로 하는 보행안내장치."}
{"patent_id": "10-2022-0037667", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "보행안내장치가 무인비행체로부터 보행자가 포함된 보행 이미지를 수집하는 단계;상기 보행안내장치가 상기 수집된 보행 이미지 중 상기 무인비행체가 트래킹할 대상인 보행자를 타겟팅하는 단계; 및상기 보행안내장치가 상기 보행 이미지의 특징을 나타내는 보행 입력벡터를 생성하고, 학습된 검출모델을 통해공개특허 10-2023-0139256-4-상기 생성된 보행 입력벡터를 분석하여 상기 보행자가 보행하는 주변의 상태를 검출하는 단계;를 포함하는 보행안내방법."}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "무인비행체를 이용한 보행안내장치 및 방법이 개시된다. 보행안내장치는 무인비행체로부터 보행자가 포함된 보행 이미지를 수집하는 이미지 수집부, 수집된 보행 이미지 중 상기 무인비행체가 트래킹(tracking)할 대상인 보행자 를 타겟팅하는 타겟팅부 및 보행 이미지의 특징을 나타내는 보행 입력벡터를 생성하고, 학습된 검출모델을 통해 생성된 보행 입력벡터를 분석하여 보행자가 보행하는 주변의 상태를 검출하는 검출부를 포함한다."}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 보행안내장치에 관한 것으로, 더욱 상세하게는 무인비행체로부터 촬영된 영상정보를 학습된 인공지능 모델에 적용하여 원거리 또는 사각지대의 장애물과 관련된 정보를 미리 보행자에게 안내하는 무인비행체를 이용 한 보행안내장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 교통약자는 장애인, 고령자, 임산부, 영유아를 동반한 사람, 어린이 등과 같이 이동에 불편함을 느 끼는 사람을 말한다. 이러한 교통약자는 보행 상황에서 다양한 사고 위험에 노출되고, 특히 신호등이나 횡단보 도가 없는 곳을 횡단할 때, 운전자와 교통약자 간의 공유된 신호 체계가 없어 추돌 사고가 발생할 위험성이 크 다. 또한 야간 보행시에는 교통약자의 시야확보가 어려워 쉽게 주변 사물의 움직임을 파악하기 어렵기 때문에 주간 보다 약 10% 더 많은 사고가 발생하고 있다. 이러한 문제점을 해결하기 위해 다양한 보행안내장치들이 개발되고 있으나, 종래의 보행안내장치들은 대부분 교 통약자의 시점에서 보여지는 영상정보를 기반으로 보행안내를 하기 때문에 원거리 또는 사각지대에서 갑자기 접 근하는 장애물(차량, 사람, 동물 등)을 피하기 어려운 문제점을 가지고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허공보 제10-2092602호(2020.03.24.)"}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 보행 경로 상에 존재하는 장애물의 상태를 미리 식별하여 보행자, 특히 교통 약자의 보행을 안전하게 이루어질 수 있도록 도와주는 무인비행체를 이용한 보행안내장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위해 본 발명에 따른 보행안내장치는 무인비행체로부터 보행자가 포함된 보행 이미지를 수집하는 이미지 수집부, 상기 수집된 보행 이미지 중 상기 무인비행체가 트래킹(tracking)할 대상인 보행자를 타겟팅하는 타겟팅부 및 상기 보행 이미지의 특징을 나타내는 보행 입력벡터를 생성하고, 학습된 검출모델을 통 해 상기 생성된 보행 입력벡터를 분석하여 상기 보행자가 보행하는 주변의 상태를 검출하는 검출부를 포함한다. 또한 상기 무인비행체로부터 수집된 보행 이미지 중 상기 보행자를 타겟팅하기 위한 타겟모델과, 상기 보행자의 보행 경로에 존재하는 장애물을 검출하는 검출모델을 학습하는 학습부를 더 포함하는 것을 특징으로 한다. 또한 상기 학습부는, 학습용 입력벡터와, 학습용 입력벡터에 대응하는 소프트 레이블 및 하드 레이블을 포함하 는 레이블을 마련하고, 기본손실함수의 하이퍼파라미터를 설정하여 하드 손실 최적화를 위한 하드손실함수를 생 성하며, 상기 타겟모델 또는 상기 검출모델에 학습용 입력벡터를 입력하고, 상기 타겟모델 또는 상기 검출모델 에 학습용 입력벡터에 대해 복수의 계층 간 가중치가 적용되는 복수의 연산을 통해 상기 소프트 레이블에 대응 하는 소프트 출력값을 산출하면, 상기 소프트 출력값을 상기 하드 레이블에 대응하는 하드 출력값으로 변환하고, 상기 변환된 하드 출력값 및 상기 하드 손실함수를 이용하여 상기 하드 레이블과 상기 하드 출력값의 차이를 나타내는 하드 손실이 최소가 되도록 상기 타겟모델 또는 상기 검출모델의 파라미터를 갱신하는 것을 특징으로 한다. 또한 상기 학습부는, 기본손실함수의 하이퍼파라미터를 설정하여 복합 손실 최적화를 위한 복합손실함수를 생성 하고, 상기 타겟모델 또는 상기 검출모델에 학습용 입력벡터를 입력하고, 상기 타겟모델 또는 상기 검출모델에 대해 복수의 계층 간 가중치가 적용되는 복수의 연산을 통해 상기 소프트 레이블에 대응하는 소프트 출력값을 산출하면, 상기 소프트 출력값으로부터 상기 하드 레이블에 대응하는 하드 출력값을 도출하고, 상기 소프트 출 력값, 상기 하드 출력값 및 상기 복합손실함수를 이용하여 상기 하드 레이블과 상기 하드 출력값의 차이를 나타 내는 하드 손실이 최소가 되도록 상기 타겟모델 또는 상기 검출모델의 파라미터를 갱신하는 것을 특징으로 한다. 또한 상기 타겟팅부는, 상기 보행 이미지 중 타겟에 해당하는 보행자가 경계 박스(bounding box)로 지정되면 상 기 지정된 경계 박스 내에 있는 타겟 이미지를 상기 타겟모델에 적용하여 상기 타겟모델을 학습시키며, 상기 학 습된 타겟모델을 통해 실시간으로 수집되는 보행 이미지에서 상기 타겟 이미지를 검출하여 상기 보행자를 타겟 팅하는 것을 특징으로 한다. 또한 상기 검출부는, 상기 보행 이미지를 복수의 구역으로 분할하고, 상기 분할된 각 구역마다 식별번호를 부여 하고, 상기 식별번호가 부여된 구역별로 상기 보행 입력벡터를 생성하며, 상기 구역별로 생성된 보행 입력벡터 를 상기 학습된 검출모델의 입력값으로 적용하는 것을 특징으로 한다. 또한 상기 검출부는, 상기 식별번호를 기반으로 상기 보행자의 보행 경로에 존재하는 장애물의 위치를 검출하는 것을 특징으로 한다. 또한 상기 검출부는, 상기 보행 이미지의 전방을 기준으로 최상측에 위치한 복수의 구역 중 가장 왼쪽에 위치한 구역으로부터 행과 열의 순서대로 식별번호를 부여하는 것을 특징으로 한다. 또한 상기 검출부는, 상기 보행자가 착용하고, 상기 보행자의 시야각에 대응되는 시점 이미지를 촬영하는 스마 트 글래스로부터 촬영된 시점 이미지를 더 이용하여 상기 상태를 검출하는 것을 특징으로 한다. 또한 상기 검출부는, 상기 검출된 장애물의 종류, 크기, 위치, 이동유무 및 이동속도 중 적어도 하나를 시각, 청각 및 촉각 중 적어도 하나의 감각으로 인지하도록 보행안내신호를 생성하거나, 상기 스마트 글래스를 통한 증강현실로 상기 검출된 장애물을 인지하도록 보행안내신호를 생성하는 것을 특징으로 한다. 본 발명에 따른 보행안내방법은 보행안내장치가 무인비행체로부터 보행자가 포함된 보행 이미지를 수집하는 단 계, 상기 보행안내장치가 상기 수집된 보행 이미지 중 상기 무인비행체가 트래킹할 대상인 보행자를 타겟팅하는 단계 및 상기 보행안내장치가 상기 보행 이미지의 특징을 나타내는 보행 입력벡터를 생성하고, 학습된 검출모델 을 통해 상기 생성된 보행 입력벡터를 분석하여 상기 보행자가 보행하는 주변의 상태를 검출하는 단계를 포함한 다."}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면 보행자, 특히 교통약자를 트래킹하는 무인비행체를 통해 보행 경로 상에 존재하는 장애물의 상태를 촬영하고, 촬영된 영상정보를 인공지능 모델인 검출모델에 적용하여 장애물의 상태를 정확하게 검출함으로써, 안전한 보행안내를 지원할 수 있다."}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 명세서 및 도면(이하 '본 명세서')에서, 동일한 구성요소에 대해서 중복된 설명은 생략한다. 또한 본 명세서에서, 어떤 구성요소가 다른 구성요소에 '연결되어' 있다거나 '접속되어' 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존 재할 수도 있다고 이해되어야 할 것이다. 반면에 본 명세서에서, 어떤 구성요소가 다른 구성요소에 '직접 연결 되어' 있다거나 '직접 접속되어' 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되 어야 할 것이다. 또한, 본 명세서에서 사용되는 용어는 단지 특정한 실시예를 설명하기 위해 사용되는 것으로써, 본 발명을 한정 하려는 의도로 사용되는 것이 아니다. 또한 본 명세서에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 또한 본 명세서에서, '포함하다' 또는 '가지다' 등의 용어는 명세서에 기재된 특징, 숫자, 단계, 동작, 구성요 소, 부품, 또는 이들을 조합한 것이 존재함을 지정하려는 것일 뿐, 하나 또는 그 이상의 다른 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이 해되어야 할 것이다. 또한 본 명세서에서, '및/또는' 이라는 용어는 복수의 기재된 항목들의 조합 또는 복수의 기재된 항목들 중의 어느 항목을 포함한다. 본 명세서에서, 'A 또는 B'는, 'A', 'B', 또는 'A와 B 모두'를 포함할 수 있다. 또한 본 명세서에서, 본 발명의 요지를 흐리게 할 수 있는 공지 기능 및 구성에 대한 상세한 설명은 생략될 것 이다. 도 1은 본 발명의 실시예에 따른 보행안내시스템을 설명하기 위한 구성도이다. 도 1을 참조하면, 보행안내시스템은 보행 경로 상에 존재하는 장애물의 상태를 미리 식별하여 보행자, 특 히 교통약자의 보행을 안전하게 이루어질 수 있도록 도와준다. 여기서 교통약자는 장애인, 고령자, 임산부, 영 유아를 동반한 사람, 어린이 등과 같이 이동에 불편함을 느끼는 사람을 의미하고, 장애물은 사람, 차량, 자전거, 오토바이, 개인용 이동수단(personal mobility, PM), 입간판, 전신주, 신호기, 표지판, 가로수, 불량 노면(빙판, 물웅덩이, 진흙 등) 등을 포함한다. 보행안내시스템은 보행안내장치 및 무인비행체 를 포함하고, 스마트 글래스(smart glasses)를 더 포함한다. 보행안내장치는 보행자가 사용하고, 휴대하는 단말로써, 보행자가 보행할 때에 경로를 안내하는 동시에 경 로 상에 존재하는 장애물의 상태를 안내한다. 보행안내장치는 무인비행체가 트래킹(tracking)할 타겟 인 보행자를 설정한다. 이를 통해 보행안내장치는 무인비행체가 타겟인 보행자만을 트래킹하며 이동 할 수 있도록 한다. 보행안내장치는 무인비행체로부터 보행자의 주변을 촬영한 보행 이미지를 수집하 고, 수집된 보행 이미지를 인공지능 모델에 적용하여 보행 경로 상에 존재하는 장애물과 같이 보행자의 보행에 문제가 될 수 있는 요소를 검출한다. 이때 보행안내장치는 스마트 글래스로부터 촬영된 시점 이미지 를 더 이용하여 보행에 문제가 될 수 있는 요소를 검출할 수 있다. 보행안내장치는 검출된 결과를 보행자 에게 제공하여 미리 위험 요소를 회피할 수 있도록 도와준다. 한편 보행안내장치는 무인비행체 및 스마트 글래스과의 연동을 수행하기 위해 각 구성 간의 연동을 지원하는 애플리케이션을 구비할 수 있다. 무인비행체는 자동으로 조정이 되는 무인 항공기로써, 드론(drone) 등을 포함할 수 있다. 무인비행체(20 0)는 보행자를 트래킹하면서 해당 보행자의 주변을 촬영한다. 무인비행체는 보행안내장치로부터 비행 제어신호를 수신하면 비행 제어신호에 따라 비행을 수행한다. 이때 무인비행체는 카메라를 구동시켜 비행 하는 주변의 영상을 촬영한 후, 촬영된 영상을 보행안내장치로 전송한다. 이후 무인비행체는 보행안 내장치로부터 보행자의 타겟팅 데이터를 수신하면 수신된 타겟팅 데이터를 기반으로 설정된 보행자만을 트 래킹하며 비행한다. 이때 무인비행체는 보행자와 일정한 거리 및 고도를 유지한 상태로 후방에서 따라가는 비행을 할 수 있다. 이를 위해 무인비행체는 보행안내장치와의 수신 신호 강도(received signal strength indication, RSSI)를 이용하여 보행자와의 거리를 일정하게 유지하고, 고도센서를 이용하여 보행자와 의 고도를 일정하게 유지할 수 있으나, 이에 한정하지 않는다. 무인비행체는 보행자를 트래킹하면서 보행 자의 주변을 촬영한 보행 이미지를 보행안내장치로 전송한다. 여기서 보행 이미지는 탑뷰(top view) 이미 지로써, 보행자의 시야에 보이지 않는 원거리 또는 사각지대까지 확인 가능한 이미지이다. 스마트 글래스는 보행자가 안경과 같이 착용하는 장치로써, 보행자의 시야각에 대응되는 영상인 시점 이미 지를 촬영한다. 스마트 글래스는 촬영된 시점 이미지를 보행안내장치로 전송한다. 여기서 시점 이미 지는 보행자의 전방(front) 이미지로써, 보행자의 근거리 또는 중거리에 존재하는 장애물에 대한 확인이 가능하 고, 시야에 보이는 객체들을 보다 정확하게 인지할 수 있는 도와주는 이미지일 수 있다. 도 2는 본 발명의 실시예에 따른 보행안내장치를 설명하기 위한 블록도이고, 도 1 내지 도 8을 참조하면, 보행안내장치는 통신부, 입력부, 제어부, 출력부 및 저 장부를 포함한다. 통신부는 무인비행체 및 스마트 글래스와의 통신을 수행한다. 통신부는 비행 제어신호 및 타겟 설정과 관련된 타겟팅 데이터를 무인비행체로 전송하고, 무인비행체로부터 촬영된 보행 이미지 를 수신한다. 통신부는 구동 제어신호 및 안내 메시지를 스마트 글래스로 전송하고, 스마트 글래스 로부터 시점 이미지를 수신한다. 입력부는 사용자 입력을 입력받는다. 입력부는 무인비행체의 비행을 제어하기 위한 사용자 입력, 타겟을 설정하기 위한 사용자 입력, 스마트 글래스의 구동을 제어하기 위한 사용자 입력 등이 입력 된다. 제어부는 보행안내장치의 전반적인 제어를 수행한다. 제어부는 무인비행체가 트래킹할 타 겟인 보행자를 설정하고, 무인비행체로부터 보행자의 주변을 촬영한 보행 이미지를 수집하며, 수집된 보행 이미지의 특징을 나타내는 보행 입력벡터를 생성하고, 학습된 인공지능 모델을 통해 보행 입력벡터를 분석 하여 보행자가 보행하는 주변의 상태를 검출한다. 제어부의 자세한 설명은 도 3 내지 도 8을 통해 설 명한다. 출력부는 통신부로부터 수신된 보행 이미지, 시점 이미지를 출력하고, 제어부로부터 검출된 장 애물과 관련된 정보를 출력한다. 출력부는 시각적, 청각적, 촉각적 효과가 나타나도록 각 정보들을 출력할 수 있다. 예를 들면 출력부는 디스플레이 상에 검출된 장애물을 경계 박스 지정하고, 관련 내용을 주석으 로 표시하거나, 음성을 통해 각 구역별 장애물 유무, 장애물 종류, 크기, 이동상황, 이동속도 등을 출력하거나, 진동을 통해 장애물 유무, 근접 상태를 출력할 수 있다. 저장부는 보행안내장치가 구동하기 위한 프로그램 또는 알고리즘이 저장된다. 저장부는 통신부 로부터 수신된 보행 이미지, 시점 이미지가 저장되고, 제어부로부터 검출된 장애물과 관련된 정보가 저장된다. 저장부는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램 (Random Access Memory, RAM), SRAM(Static Random Access Memory), 롬(Read-Only Memory, ROM), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크 및 광디스크 중 적어도 하나의 저장매체를 포함할 수 있다. 도 3은 도 2의 제어부를 상세하게 설명하기 위한 블록도이고, 도 4는 본 발명의 실시예에 따른 타겟 설정 및 장 애물 검출을 위한 인공지능 모델의 구성을 설명하기 위한 도면이며, 도 5는 도 4의 인공지능 모델에 대한 노드 를 설명하기 위한 도면이고, 도 6은 본 발명의 실시예에 따른 타겟 설정하는 과정을 설명하기 위한 도면이며, 도 7은 본 발명의 실시예에 따른 보행자를 트래킹하는 과정을 설명하기 위한 도면이고, 도 8은 본 발명의 실시 예에 따른 장애물 검출하는 과정을 설명하기 위한 도면이다. 도 2 내지 도 8을 참조하면, 제어부는 이미지 수집부, 타겟팅부 및 검출부를 포함하고, 학 습부를 더 포함할 수 있다. 학습부는 인공지능 모델을 학습한다. 즉 학습부는 무인비행체로부터 수집된 영상 중 보행자를 타겟팅하기 위한 타겟모델(TM)과 보행자의 보행 경로에 존재하는 장애물을 검출하는 검출모델(DM)을 학습한다. 여기서 타겟모델(TM) 및 검출모델(DM)은 인공신경망이고, 다층퍼셉트론(Multilayer Perceptron, MLP)이 될 수 있으나, 이에 한정하지 않는다. 이러한 타겟모델(TM) 및 검출모델(DM)은 복수의 계층(IL, HL, OL)을 포함한다. 이러한 복수의 계층은 입력층(IL), 복수의 은닉 계층(HL1 내지 HLk, HL) 및 출력층(OL)을 포함한다. 또한, 복수의 계층(IL, HL, OL) 각각은 복수의 노드를 포함한다. 예컨대 입력층(IL)은 n개의 입력노드(i1 ~ i n)를 포함하며, 출력층(OL)은 1개의 출력노드(o)를 포함할 수 있다. 또한, 은닉층(HL) 중 제1 은닉계층(HL1)은 a개의 노드(h11 ~ h1a)를 포함하고, 제2 은닉계층(HL2)은 b개의 노드(h21 ~ h2b)를 포함하고, 제k 은닉계층 (HLk)은 c개의 노드(hk1 ~ hkc)를 포함할 수 있다. 복수의 계층의 복수의 노드 모두는 연산을 가진다. 특히, 서로 다른 계층의 복수의 노드는 가중치(W: weight)를 가지는 채널(점선으로 표시)로 연결된다. 다른 말로, 어느 하나의 노드의 연산 결과는 가중치가 적용되어 다음 계층 노드의 입력이 된다. 한편, 도 5에 본 발명의 실시예에 따른 노드(h)가 도시되었다. 이러한 노드(h)는 검출모델(DM)의 어느 하나의 노드가 될 수 있다. 노드(h)는 입력된 신호 x=[x1, x2, …, xn]에 가중치 w=[w1, w2, …, wn]를 적용한 후, 그 결과에 함수 F를 취한다. 여기서, 함수 F는 활성화 함수(activation function)이다. 활성화함수는 시그모이드 (Sigmoid), 하이퍼볼릭탄젠트(tanh: Hyperbolic tangent), ELU(Exponential Linear Unit), ReLU(Rectified Linear Unit), Leakly ReLU, Maxout, Minout, Softmax 등을 예시할 수 있다. 이러한 활성화함수 중 어느 하나 를 선택하여 사용할 수 있다. 각 노드의 출력은 다음의 [수학식 1]과 같다. 수학식 1"}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 설명되지 않은 파라미터 중 b는 임계치이며, 이러한 임계치는 [수학식 1]에서 의 값이 임 계치 보다 작을 때 해당 노드가 활성화되지 않도록 하는 역할을 한다. [수학식 1]에 따르면, 입력이 동일한 경우에도, 출력은 가중치(W)에 따라 다른 값이 된다. 예를 들면 노드(h)의 이전 계층의 노드가 3개라고 가정한다. 이에 따라, 해당 노드에 대해 3개의 입력(n=3) X1, X2, X3과 3개의 가중 치 W1, W2, W3이 존재한다. 노드(h)는 3개의 입력 X1, X2, X3에 대응하는 가중치 W1, W2, W3을 곱한 값을 입력받고, 모두 합산한 후, 합산된 값을 활성화 함수에 대입하여 출력을 산출한다. 구체적으로, 입력 x=[X1, X2, X3] = 0.5, -0.3, 0이라고 가정하고, 가중치 w=[W1, W2, W3] = 4, 5, 2라고 가정한다. 또한, 설명의 편의를 위하 여 전달 함수는 ‘sgn()’이라고 가정하면, 다음과 같이 출력값이 산출된다. x1 × w1 = 0.5 × 4 = 2 x2 × w2 = - 0.3 × 5 = -1.5 x3 × w3 = 0 × 2 = 0 2 + (-1.5) + 0 = 0.5 sgn(0.5) = 1 이와 같이, 본 발명의 타겟모델(TM) 및 검출모델(DM) 중 어느 하나의 노드는 이전 계층의 노드값에 가중치를 적 용한 값을 입력받고, 이를 합산하여 활성화함수에 따라 연산을 수행하고, 이러한 결과를 다음 계층의 입력으로 전달한다. 정리하면 학습부는 학습이 완료되지 않은 타겟모델(TM) 및 검출모델(DM)에 학습용 입력벡터와 학습용 입력 벡터에 대응하는 레이블을 포함하는 학습 데이터를 적용하여 복수의 계층 간 가중치가 적용되는 연산을 수행한 후, 연산 출력값과 학습용 데이터에 대응하는 출력값의 차이를 최소가 되도록 타겟모델(TM) 및 검출모델(DM)의 파라미터를 갱신하여 모델을 최적화한다. 이미지 수집부는 무인비행체로부터 보행자가 포함된 보행 이미지를 수집한다. 여기서 보행 이미 지는 탑뷰 이미지로써, 보행자의 후방에서 바라보는 방향에서 촬영하여 보행자의 주변이 촬영된 이미 지일 수 있다. 이를 통해 이미지 수집부는 실제 보행자가 보행하는 방향의 상태정보가 포함된 이미지 를 수집할 수 있다. 타겟팅부는 무인비행체가 트래킹할 타겟인 보행자를 설정한다. 타겟팅부는 무인비행체 로부터 촬영된 보행 이미지에서 사용자 입력에 의해 보행자가 경계 박스(bounding box)로 지정 되면 지정된 경계 박스 내의 보행자가 포함된 영상을 학습 데이터로 인식한 후, 인식된 학습 데이터를 타겟모델 (TM)에 적용하여 타겟모델(TM)을 학습시킨다. 타겟팅부는 학습된 타겟모델(TM)을 통해 실시간으로 수집되 는 보행 이미지에서 타겟 이미지를 검출하여 보행자를 타겟팅한다. 이때 타겟팅부는 타겟팅된 보행자와 관 련된 정보인 타겟팅 데이터를 무인비행체로 전송시킴으로써, 무인비행체가 보행자만을 트래킹할 수 있도록 지원한다. 여기서 타겟팅 데이터는 타겟과 관련된 정보 이외에 무인비행체의 고도, 타겟과의 거리 등의 비행과 관련된 정보가 더 포함될 수 있다. 검출부는 이미지 수집부로부터 보행 이미지를 수신하면(도 8a) 보행 이미지의 특징을 나타내는 보행 입력벡터를 생성한다. 이때 검출부는 보행 이미지를 복수의 구역으로 분할하고, 분할된 각 구역마다 식별 번호를 부여하고, 식별번호가 부여된 구역별로 보행 입력벡터를 생성할 수 있다(도 8b). 검출부는 보행 이 미지의 전방을 기준으로 최상측에 위치한 복수의 구역 중 가장 왼쪽에 위치한 구역으로부터 행과 열의 순서대로 식별번호를 부여할 수 있다. 또한 검출부는 보행 이미지를 색상(hue), 채도(saturation), 명도(value) 및 밝기(luminance) 중 적어도 하나를 이용하여 보행 입력벡터를 생성할 수 있다. 검출부는 학습부에서 학습된 검출모델(DM)을 통해 보행 입력벡터를 분석하여 보행자가 보행하는 주변의 상태를 검출한다. 즉 검출부 은 보행 이미지의 구역별로 생성된 보행 입력벡터를 학습된 검출모델(DM)의 입력값으로 적용함으로써, 각 구역별로 부여된 식별번호를 기반으로 보행자의 보행 경로에 존재하는 장애물의 위치를 검출할 수 있다. 검출부는 검출모델(DM)의 입력층(IL)에 보행 입력벡터가 입력되면, 보행 입력벡터에 대해 복수의 계층(IL, HL, OL)의 가중치가 적용되는 복수의 연산을 수행하여 장애물의 유무에 대한 확률을 산출한다. 그러면, 검출부 는 산출된 확률에 따라 장애물의 유무를 판단하고, 장애물이 있다고 판단된 위치와 해당 종류를 검출할 수 있다. 상세하게는 보행 입력벡터가 타겟모델(TM)의 입력층(IL)의 복수의 입력노드(i1 ~ in)에 입력되면 제1 은닉층 (HL1)의 복수의 제1 은닉노드(h11 ~ h1a) 각각은 복수의 입력노드(i1 ~ in)의 타겟 입력벡터에 가중치가 적용된 값을 입력받고(점선으로 표시), 입력된 값을 모두 합산한 후, 합산된 값에 대해 활성화함수에 따른 연산을 수행 하여 복수의 제1 은닉노드값을 산출한다. 이어서 제2 은닉층(PHL2)의 복수의 제2 은닉노드(h21 ~ h2b) 각각은 복수의 제1 은닉노드(h11 ~ h1a)의 복수의 제1 은닉노드값 각각에 가중치가 적용된 값을 입력받고(점선으로 표 시), 입력된 값을 모두 합산하며, 합산된 값에 대해 활성화함수에 따른 연산을 수행하여 복수의 제2 은닉노드값 을 산출한다. 이와 같은 방식으로 은닉층(HL) 내에서 이전의 노드값이 가중치가 적용되어 전달되고, 연산을 통 해 현재의 노드값이 산출된다. 이러한 과정을 반복하여, 제k 은닉계층(PHLk)의 복수의 제k 은닉노드(hk1 ~ hk c)의 복수의 제k 은닉노드값을 산출할 수 있다. 그러면 출력노드(o) 각각은 제k 은닉계층(PHLk)의 복수의 제k 은닉노드(hk1 ~ hkc)의 복수의 제k 은닉노드값에 가중치 w=[w1, w2, …, wc×2]가 적용된 값을 입력받고(점선으 로 표시), 입력된 값을 모두 합산한 후, 합산된 값에 대해 활성화함수에 따른 연산을 수행하여 출력값을 산출한 다. 출력층(OL)의 출력노드(o)의 출력값은 입력된 보행 입력벡터에 대응하는 객체가 장애물인 확률을 나타낸다. 예 컨대 출력노드(o)의 출력값이 0.841이면 보행 입력벡터에 대응하는 객체가 장애물일 확률이 84%이다. 이와 같이 검출모델(DM)이 확률(0.841)을 출력하면 검출부는 해당 확률에 따라 보행 입력벡터에 대응하는 객체를 장애물로 판단한다. 이때 검출부는 장애물 판단뿐만 아니라 장애물의 종류 및 위치도 판단할 수 있다. 여기서 검출부는 무인비행체가 아닌 스마트 글래스로부터 수신된 시점 이미지인 경우에도 전술 된 설명과 같이 동일한 과정으로 장애물 유무 판단 및 장애물의 종류와 위치를 판단할 수 있다. 또한 검출부는 무인비행체로부터 수신된 보행 이미지를 분석하여 장애물과 관련된 결과값을 검출하고, 스마트 글래스로부터 수신된 시점 이미지를 분석하여 장애물과 관련된 결과값을 검출한 경우, 두 결과값을 비교 분석하여 최종적인 분석 결과를 도출할 수 있다. 이때 검출부는 보행 이미지를 기반으로 검출된 결과값 중 원거리 및 사각지대에 해당하는 결과값에 가중치를 부여하고, 시점 이미지를 기반으로 검출된 결과값 중 근거리 및 중거리에 해당하는 결과값에 가중치를 부여할 수 있다. 검출부는 검출된 장애물의 종류, 크기, 위치, 이동유무 및 이동속도 중 적어도 하나가 출력부 또는 스마트 글래스를 통해 출력되도록 보행안내신호를 생성한다. 예를 들면 검출부는 디스플레이 상에 검 출된 장애물을 경계 박스로 지정하고, 관련 내용을 주석으로 표시하거나, 스마트 글래스를 통해 장애물을 증강현실로 표시하도록 보행안내신호를 생성할 수 있다. 또한 검출부는 시력이 안 좋은 보행자를 위해, 각 구역별 장애물 유무, 장애물 종류, 크기, 이동상황, 이동속도 등을 음성으로 출력하도록 보행안내신호를 생성하 거나, 장애물 유무 및 근접 상태를 진동으로 출력하도록 보행안내신호를 생성할 수 있다. 여기서 검출부는 장애물과 가까워질수록 진동세기가 커지고, 진동주기가 빨라지도록 보행안내신호를 생성할 수 있다. 도 9는 본 발명의 실시예에 따른 인공지능 모델을 학습하는 방법을 설명하기 위한 순서도이다. 도 1 및 도 9를 참조하면, 보행안내장치는 보행안내를 수행하기 이전에 인공지능 모델을 학습시켜 보행 경 로에 존재하는 장애물에 대한 검출 정확도를 향상시킬 수 있다. S110 단계에서, 보행안내장치는 학습용 입력벡터 및 학습용 입력벡터에 대응하는 레이블을 포함하는 학습 데이터를 마련한다. 학습용 입력벡터는 전술한 바와 같이, 학습용 보행 이미지에 대해 적어도 하나의 특징검출 필터를 이용하여 생성된다. 학습용 보행 이미지는 보행자가 한 명 이상 포함된 이미지이다. 또한, 학습용 입력 벡터에 대응하는 레이블은 하드 레이블 및 소프트 레이블을 포함한다. 하드 레이블은 출력층의 하드 출력값에 대응하는 레이블이고, 소프트 레이블은 출력층의 소프트 출력값에 대응하는 레이블이다. 소프트 출력값은 장애 물의 존재 여부를 확률로 나타내는 값, 예컨대, [0.841]로 나타내는 것이며, 하드 출력값은 확률을 나타내는 수 치를 장애물의 존재 여부를 결정한 값으로 나타내는 것이다. 예컨대, 소프트 출력값이 [0.841]인 경우, 하드 출 력값은 [1]이 된다. 이와 같은, 학습용 입력벡터가 마련되면, 보행안내장치는 다음의 [수학식 2]과 같은 기본손실함수를 이용 하여 학습을 수행할 수 있다. 수학식 2"}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[수학식 2]에서 Lb은 기본손실함수를 나타낸다. yi는 하드 출력값이고, ei는 하드 출력값에 대응하는 하드 레이 블이다. gi는 소프트 출력값이고, ci는 소프트 출력값에 대응하는 소프트 레이블이다. i는 출력층의 노드에 대 응하는 인덱스이다. 그리고 H는 하이퍼파라미터를 나타낸다. S120 단계에서, 보행안내장치는 하드 손실 최적화를 위한 하이퍼파라미터를 설정한다. 이때, 보행안내장치 는 하이퍼파라미터 H를 0으로 설정한다. 이러한 설정에 따라 [수학식 2]의 기본손실함수에서 하드 손실을 최적화하는 학습에서 사용되는 하드손실함수가 생성되며, 다음의 [수학식 3]와 같다. 수학식 3"}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, Lh은 하드손실 또는 하드손실함수를 나타낸다. [수학식 2]와 마찬가지로, yi는 하드 출력값이고, ei는 하드 레이블이다. 또한, i는 출력층의 노드에 대응하는 인덱스이다. S130 단계에서, 보행안내장치는 하드 손실을 최적화하는 학습을 수행한다. 이러한 S130 단계에서 보행안내 장치는 타겟모델(TM) 및 검출모델(DM)에 학습용 입력벡터를 입력한다. 그러면, 타겟모델(TM) 및 검출모델 (DM)은 학습용 입력벡터에 대해 복수의 계층 간 가중치가 적용되는 복수의 연산을 통해 출력값을 산출한다. 여 기서, 출력값은 소프트 출력값이지만, 하드 손실을 최적화하는 학습에서는 하드 출력값을 이용해야 한다. 이에 따라, 보행안내장치는 소프트 출력값을 하드 출력값으로 변환하고, 변환된 하드 출력값 및 [수학식 3]와 같은 하드손실함수를 이용하여 앞서 설정된 하드 레이블과 하드 출력값의 차이를 나타내는 [수학식 3]의 하드손 실함수의 손실, 즉, 하드 손실이 최소가 되도록 타겟모델(TM) 및 검출모델(DM)의 파라미터(예컨대, [수학식 1] 의 가중치, 임계치)를 수정하는 하드 손실 최적화를 수행한다. 이러한 하드 손실 최적화는 복수의 서로 다른 학 습용 입력벡터를 이용하여 반복하여 수행되며, 이러한 반복은 평가 지표를 통해 원하는 정확도에 도달할 때까지 이루어질 수 있다. S140 단계에서, 보행안내장치는 복합 손실 최적화를 위한 하이퍼파라미터를 설정한다. 이때, 보행안내장치 는 하이퍼파라미터 H를 0.5로 설정한다. 이러한 설정에 따라 [수학식 2]의 기본손실함수에서 복합 손실을 최적화하는 학습에서 사용되는 복합손실함수가 생성되며, 다음의 [수학식 4]와 같다. 수학식 4"}
{"patent_id": "10-2022-0037667", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, Lc는 복합손실함수 또는 복합 손실을 나타낸다. yi는 하드 출력값이고, 상기 ei는 하드 레이블이다. 또 한, gi는 소프트 출력값이고, ci는 소프트 레이블이다. i는 출력층의 노드에 대응하는 인덱스이다. S150 단계에서, 보행안내장치는 복합 손실을 최적화하는 학습을 수행한다. 이때, 보행안내장치는 타 겟모델(TM) 및 검출모델(DM)에 학습용 입력벡터를 입력한다. 그러면 타겟모델(TM) 및 검출모델(DM)은 학습용 입 력벡터에 대해 복수의 계층 간 가중치가 적용되는 복수의 연산을 통해 출력값을 산출한다. 여기서, 출력값은 소 프트 출력값이지만, 하드 출력값이 요구된다. 이에 따라, 보행안내장치는 소프트 출력값으로부터 하드 출 력값을 도출하고, 소프트출력값과 하드출력값 및 [수학식 4]와 같은 복합손실함수를 이용하여 [수학식 4]의 복 합손실함수 중 복합 손실이 최소가 되도록 타겟모델(TM) 및 검출모델(DM)의 파라미터(예컨대, [수학식 1]의 가 중치, 임계치)를 수정하는 복합 손실 최적화를 수행한다. 이러한 복합 손실은 하드 레이블과 하드 출력값의 차 이를 나타내는 하드 손실 및 소프트 레이블과 소프트 출력값의 차이를 소프트 손실을 포함한다. 이에 따라, 보 행안내장치는 타겟모델(TM) 및 검출모델(DM)의 정밀화를 위해 복합 손실 최적화 시, 소프트 손실이 최소가 되면서, 복합 손실이 최소가 되도록 타겟모델(TM) 및 검출모델(DM)의 파라미터(예컨대, [수학식 1]의 가중치, 임계치)를 수정한다. 이러한 복합 손실 최적화는 복수의 서로 다른 학습용 입력벡터를 이용하여 반복하여 수행 되며, 이러한 반복은 평가 지표를 통해 원하는 정확도에 도달할 때까지 이루어질 수 있다. 도 10은 본 발명의 실시예에 따른 보행안내방법을 설명하기 위한 순서도이다. 도 1 및 도 10을 참조하면, 보행안내방법은 보행자를 트래킹하는 무인비행체를 통해 보행 경로 상에 존재 하는 장애물의 상태를 촬영하고, 촬영된 영상정보를 인공지능 모델인 검출모델(DM)에 적용하여 장애물의 상태를 정확하게 검출할 수 있다.S210 단계에서, 보행안내장치는 이미지를 수집한다. 보행안내장치는 무인비행체와 연동되는 애 플리케이션을 실행한 후, 무인비행체의 비행을 제어한다. 이때 보행안내장치는 무인비행체가 비 행하면서 촬영한 보행 이미지를 수집한다. 여기서 보행 이미지는 보행자를 하나 이상 포함하는 이미지로써, 보 행자는 교통약자일 수 있다. 이때 보행안내장치는 스마트 글래스의 구동도 제어한 후, 시점 이미지를 수집할 수 있다. S220 단계에서, 보행안내장치는 교통약자를 타겟팅한다. 보행안내장치는 무인비행체로부터 촬영 된 보행 이미지에서 사용자 입력에 의해 교통약자가 경계 박스로 지정되면 지정된 경계 박스 내의 교통약자가 포함된 영상을 학습 데이터로 인식한 후, 인식된 학습 데이터를 타겟모델(TM)에 적용하여 타겟모델(TM)을 학습 시킨다. 보행안내장치는 학습된 타겟모델(TM)을 통해 실시간으로 수집되는 보행 이미지에서 타겟 이미지를 검출하여 교통약자를 타겟팅한다. 이때 보행안내장치는 타겟팅된 교통약자와 관련된 정보인 타겟팅 데이터 를 무인비행체로 전송시킴으로써, 무인비행체가 교통약자만을 트래킹할 수 있도록 지원한다. S230 단계에서, 보행안내장치는 보행자 주변 상태를 검출한다. 보행안내장치는 무인비행체가 트 래킹하면서 촬영한 보행 이미지를 수신하면 보행 이미지의 특징을 나타내는 보행 입력벡터를 생성한다. 보행안 내장치는 검출모델(DM)의 입력층(IL)에 보행 입력벡터를 입력하고, 보행 입력벡터에 대해 복수의 계층(IL, HL, OL)의 가중치가 적용되는 복수의 연산을 수행하여 장애물의 유무에 대한 확률을 산출한다. 보행안내장치 는 산출된 확률에 따라 장애물의 유무를 판단하고, 장애물이 있다고 판단된 위치와 해당 종류를 검출한다. S240 단계에서, 보행안내장치는 보행 안내를 출력한다. 보행안내장치는 보행 경로의 안내를 하는 동 시에 검출된 장애물과 관련된 정보를 출력한다. 이때 보행안내장치는 장애물의 유무뿐만 아니라 종류, 위 치 등을 출력할 수 있다. 도 11은 본 발명의 실시예에 따른 컴퓨팅 장치를 설명하기 위한 블록도이다. 도 11의 컴퓨팅 장치(TN100)는 본 명세서에서 기술된 장치(예, 보행안내장치, 무인비행체 관련 장치, 스마트 글 래스 관련 장치 등) 일 수 있다. 컴퓨팅 장치(TN100)는 적어도 하나의 프로세서(TN110), 송수신 장치(TN120), 및 메모리(TN130)를 포함할 수 있 다. 또한, 컴퓨팅 장치(TN100)는 저장 장치(TN140), 입력 인터페이스 장치(TN150), 출력 인터페이스 장치 (TN160) 등을 더 포함할 수 있다. 컴퓨팅 장치(TN100)에 포함된 구성 요소들은 버스(bus)(TN170)에 의해 연결 되어 서로 통신을 수행할 수 있다. 프로세서(TN110)는 메모리(TN130) 및 저장 장치(TN140) 중에서 적어도 하나에 저장된 프로그램 명령(program command)을 실행할 수 있다. 프로세서(TN110)는 중앙 처리 장치(CPU: central processing unit), 그래픽 처리 장치(GPU: graphics processing unit), 또는 본 발명의 실시예에 따른 방법들이 수행되는 전용의 프로세서를 의 미할 수 있다. 프로세서(TN110)는 본 발명의 실시예와 관련하여 기술된 절차, 기능, 및 방법 등을 구현하도록 구성될 수 있다. 프로세서(TN110)는 컴퓨팅 장치(TN100)의 각 구성 요소를 제어할 수 있다. 메모리(TN130) 및 저장 장치(TN140) 각각은 프로세서(TN110)의 동작과 관련된 다양한 정보를 저장할 수 있다. 메모리(TN130) 및 저장 장치(TN140) 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하나로 구 성될 수 있다. 예를 들어, 메모리(TN130)는 읽기 전용 메모리(ROM: read only memory) 및 랜덤 액세스 메모리 (RAM: random access memory) 중에서 적어도 하나로 구성될 수 있다. 송수신 장치(TN120)는 유선 신호 또는 무선 신호를 송신 또는 수신할 수 있다. 송수신 장치(TN120)는 네트워크 에 연결되어 통신을 수행할 수 있다. 한편, 본 발명의 실시예는 지금까지 설명한 장치 및/또는 방법을 통해서만 구현되는 것은 아니며, 본 발명의 실 시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있으며, 이러한 구현은 전술한 실시예의 기재로부터 본 발명이 속하는 기술 분야의 통상의 기술자라면 쉽게 구 현할 수 있는 것이다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 통상의 기술자의 여러 변형 및 개량 형태 또 한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2022-0037667", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 보행안내시스템을 설명하기 위한 구성도이다. 도 2는 본 발명의 실시예에 따른 보행안내장치를 설명하기 위한 블록도이다. 도 3은 도 2의 제어부를 상세하게 설명하기 위한 블록도이다. 도 4는 본 발명의 실시예에 따른 타겟 설정 및 장애물 검출을 위한 인공지능 모델의 구성을 설명하기 위한 도면 이다. 도 5는 도 4의 인공지능 모델에 대한 노드를 설명하기 위한 도면이다. 도 6은 본 발명의 실시예에 따른 타겟 설정하는 과정을 설명하기 위한 도면이다. 도 7은 본 발명의 실시예에 따른 보행자를 트래킹하는 과정을 설명하기 위한 도면이다.도 8은 본 발명의 실시예에 따른 장애물 검출하는 과정을 설명하기 위한 도면이다. 도 9는 본 발명의 실시예에 따른 인공지능 모델을 학습하는 방법을 설명하기 위한 순서도이다. 도 10는 본 발명의 실시예에 따른 보행안내방법을 설명하기 위한 순서도이다. 도 11은 본 발명의 실시예에 따른 컴퓨팅 장치를 설명하기 위한 블록도이다."}
