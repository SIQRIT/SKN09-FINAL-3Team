{"patent_id": "10-2019-0157203", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0067505", "출원번호": "10-2019-0157203", "발명의 명칭": "뉴럴 네트워크 가속기의 효율적인 제어, 모니터링 및 소프트웨어 디버깅 방법", "출원인": "한국전자기술연구원", "발명자": "김병수"}}
{"patent_id": "10-2019-0157203", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "호스트로부터 명령어 세트와 입력 데이터를 수신하는 인터페이스;명령어 세트와 입력 데이터가 저장되는 메모리;인터페이스를 통해 수신한 명령어 세트와 입력 데이터를 메모리에 저장하는 컨트롤러;명령어 세트에 따라 뉴럴 네트워크 연산을 수행하는 가속기 코어;를 포함하는 것을 특징으로 하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2019-0157203", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,메모리는,명령어 세트가 기록되는 제1 영역, 입력 데이터가 기록되는 제2 영역, 제어 데이터가 기록되는 제3 영역 및 가속기 코어의 출력 데이터가 기록되는 제4 영역을 포함하는 것을 특징으로 하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2019-0157203", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,명령어 세트에는,뉴럴 네트워크의 종류를 지시하는 정보, 입력 데이터, 뉴럴 네트워크의 가중치, 바이어스, 출력 데이터가 저장되는 메모리 위치와 길이를 지시하는 정보, 뉴럴 네트워크의 제어 파라미터를 포함되는 것을 특징으로 하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2019-0157203", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,가속기 코어는,메모리의 제1 영역에 기록된 명령어 세트를 읽어 디코딩하고, 메모리 위치와 길이를 참조하여 메모리에 기록된입력 데이터, 가중치, 바이어스 정보를 내부 버퍼에 저장하는 것을 특징으로 하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2019-0157203", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,가속기 코어는,뉴럴 네트워크 연산에 사용할 PE들을 구성하여 뉴럴 네트워크 연산을 수행하고, 연산 수행에 따른 출력 데이터를 메모리의 제4 영역에 저장하고,호스트는,메모리의 제4 영역에 기록된 출력 데이터들을 참조하여 가속기 코어의 상태를 모니터링하는 것을 특징으로 하는공개특허 10-2021-0067505-3-뉴럴 네트워크 가속기."}
{"patent_id": "10-2019-0157203", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,호스트는,가속기 코어의 PE들에 의해 연산이 수행되는 중에도 가속기 코어의 상태를 모니터링할 수 있는 것을 특징으로하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2019-0157203", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,인터페이스는,PCIE(Peripheral Component Interconnect Experimental) 인터페이스를 통해 호스트와 연결되는 것을 특징으로하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2019-0157203", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "호스트로부터 명령어 세트와 입력 데이터를 수신하는 단계;수신한 명령어 세트와 입력 데이터를 저장하는 단계;수신한 명령어 세트에 따라 수신한 입력 데이터로 뉴럴 네트워크 연산을 수행하는 단계;를 포함하는 것을 특징으로 하는 뉴럴 네트워크 제어 방법."}
{"patent_id": "10-2019-0157203", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "뉴럴 네트워크 가속기의 효율적인 제어, 모니터링 및 소프트웨어 디버깅 방법이 제공된다. 본 발명의 실시예에 따른 뉴럴 네트워크 가속기는, 호스트로부터 명령어 세트와 입력 데이터를 수신하는 인터페이스, 명령어 세트와 입력 데이터가 저장되는 메모리, 인터페이스를 통해 수신한 명령어 세트와 입력 데이터를 메모리에 저장하는 컨 트롤러 및 명령어 세트에 따라 뉴럴 네트워크 연산을 수행하는 가속기 코어를 포함한다. 이에 의해, 뉴럴 네트워 크 가속기의 동작을 명령어 단위로 세분화하여 제어할 수 있고, 뉴럴 네트워크 루틴의 실행 후 가속기 장치의 중 간 결과 데이터 및 상태를 확인할 수 있으므로, 뉴럴 네트워크 가속기를 사용하는 인공지능 장치의 소프트웨어 개발에 소요되는 시간과 노력을 줄일 수 있게 된다."}
{"patent_id": "10-2019-0157203", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 뉴럴 네트워크 가속기 개발 관련 기술에 관한 것으로, 더욱 상세하게는 뉴럴 네트워크 기술이 탑재되 어진 하드웨어 장치를 효과적으로 제어하고 모니터링하면서 소프트웨어를 디버깅하기 위한 방법에 관한 것이다."}
{"patent_id": "10-2019-0157203", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "뉴럴 네트워크가 탑재된 장치에서 동작하는 소프트웨어는, 뉴럴 네트워크 기능을 구현한 부분(루틴)과 이를 동 작시키기 위한 준비 및 관리 부분(루틴)으로 나누어지며, 뉴럴 네트워크 장치의 동작 속도를 향상시키기 위해 이들은 각각 독립된 프로세서에서 구동된다. 따라서 뉴럴 네트워크 루틴과 관리 루틴은 각각의 프로세서의 아키 텍처에 맞게 개발하여야 한다. 한편, 단순한 컨볼루션 연산을 수행하는 대량의 연산기를 동시에 이용하여 대량의 데이터에 대한 계산을 처리하 는 뉴럴 네트워크 구현 부분의 특성 상, 컨볼루션 연산의 실행을 위해 뉴럴 네트워크 가속기에 보내진 연산 명 령어는 가속기에 보내진 이후 중단할 수 없으며, 명령어의 처리가 완료될 때 까지 가속기의 내부 상태에 대한 확인도 불가능하다. 이는 단순한 연산기를 대량으로 결합하는 과정에서, 각 연산기의 제어 로직을 제거함으로서 종래의 프로세서 아 키텍처에서는 불가능한 수준의 연산 능력을 확보하여, 컨볼루션 계산을 획기적으로 가속할 수 있는 뉴럴 네트워 크 가속기만의 고유한 장점과는 절대적으로 대치되는 부분이다. 따라서, 기존의 이기종 컴퓨팅 기술용 소프트웨어 개발 방법으로는 인공지능 장치용 소프트웨어 개발 과정에서 인공지능 루틴에 대한 연산 중간 과정과 연산 중 신경망 가속기의 내부 상태를 확인할 수 없으며, 이는 인공지 능 소프트웨어의 디버깅 및 개발을 어렵게 하는 원인이 된다."}
{"patent_id": "10-2019-0157203", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 목적은, 뉴럴 네트워크 가속기의 동작을 명령어 단위로 세분화하여 제어할 수 있고, 뉴럴 네트워크 가속기의 내부 상태를 언제든지 구체적으로 확인할 수 있는 뉴럴 네트워크 가속기의 효율적인 제어, 모니터링 및 소프트웨어 디버깅 방법을 제공함에 있다."}
{"patent_id": "10-2019-0157203", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른, 뉴럴 네트워크 가속기는, 호스트로부터 명령어 세트와 입력 데이터를 수신하는 인터페이스; 명령어 세트와 입력 데이터가 저장되는 메모리; 인터페이스를 통해 수신한 명령어 세트와 입력 데이터를 메모리에 저장하는 컨트롤러; 명령어 세트에 따라 뉴럴 네트워크 연산을 수행하는 가속기 코어;를 포함한다. 메모리는, 명령어 세트가 기록되는 제1 영역, 입력 데이터가 기록되는 제2 영역, 제어 데이터가 기록되는 제3 영역 및 가속기 코어의 출력 데이터가 기록되는 제4 영역을 포함할 수 있다. 명령어 세트에는, 뉴럴 네트워크의 종류를 지시하는 정보, 입력 데이터, 뉴럴 네트워크의 가중치, 바이어스, 출 력 데이터가 저장되는 메모리 위치와 길이를 지시하는 정보, 뉴럴 네트워크의 제어 파라미터를 포함될 수 있다. 가속기 코어는, 메모리의 제1 영역에 기록된 명령어 세트를 읽어 디코딩하고, 메모리 위치와 길이를 참조하여 메모리에 기록된 입력 데이터, 가중치, 바이어스 정보를 내부 버퍼에 저장할 수 있다. 가속기 코어는, 뉴럴 네트워크 연산에 사용할 PE들을 구성하여 뉴럴 네트워크 연산을 수행하고, 연산 수행에 따 른 출력 데이터를 메모리의 제4 영역에 저장할 수 있다. 호스트는, 메모리의 제4 영역에 기록된 출력 데이터들을 참조하여 가속기 코어의 상태를 모니터링할 수 있다. 호스트는, 가속기 코어의 PE들에 의해 연산이 수행되는 중에도 가속기 코어의 상태를 모니터링할 수 있다. 한편, 본 발명의 다른 실시예에 따른, 뉴럴 네트워크 제어 방법은, 호스트로부터 명령어 세트와 입력 데이터를 수신하는 단계; 수신한 명령어 세트와 입력 데이터를 저장하는 단계; 수신한 명령어 세트에 따라 수신한 입력 데이터로 뉴럴 네트워크 연산을 수행하는 단계;를 포함한다."}
{"patent_id": "10-2019-0157203", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상 설명한 바와 같이, 본 발명의 실시예들에 따르면, 뉴럴 네트워크 가속기의 동작을 명령어 단위로 세분화하 여 제어할 수 있고, 뉴럴 네트워크 루틴의 실행 후 가속기 장치의 중간 결과 데이터 및 상태를 확인할 수 있으 므로, 뉴럴 네트워크 가속기를 사용하는 인공지능 장치의 소프트웨어 개발에 소요되는 시간과 노력을 줄일 수 있게 된다."}
{"patent_id": "10-2019-0157203", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 본 발명의 실시예에서는 뉴럴 네트워크 가속기를 효율적으로 제어하면서 소프트웨어 디버깅을 위한 뉴럴 네트워 크 가속기의 상태/결과 모니터링을 뉴럴 네트워크 가속기가 연산하고 있는 중에도 수행할 수 있는 방법을 제시 한다. 즉, 본 발명의 실시예에서는, 뉴럴 네트워크 가속기의 동작을 명령어 단위로 세분화하여 제어하면서, 뉴럴 네트 워크 가속기의 내부 상태를 언제든지 구체적으로 확인할 수 있도록 한다. 도 1은 본 발명의 실시예가 적용가능한 뉴럴 네트워크 가속기의 개발 환경을 도시한 도면이다. 본 발명의 실시 예가 적용가능한 개발 환경은, 도 1에 도시된 바와 같이, 호스트와 뉴럴 네트워크 가속기와 PCIE(Peripheral Component Interconnect Experimental) 인터페이스를 통해 상호 연결되어 구축된다. 호스트는 소프트웨어 개발환경 모듈, API(Application Programming Interface) 모듈, 디바이스 드라이버 모듈 및 PCIE 인터페이스를 포함하여 구성된다. 소프트웨어 개발환경 모듈은 개발자가 뉴럴 네트워크 가속기에 탑재되는 뉴럴 네트워크를 개발하고 개별적인 명령어가 아닌 명령어 세트를 통해 제어하면서 디버깅할 수 있도록 하기 위해 제공되는 툴이다. API 모듈은 외부 개발자에게 개발환경을 제공하기 위한 모듈이ㄷ다. 디바이스 드라이버 모듈은 PCIE 인터페이스를 통해 뉴럴 네트워크 가속기와 호스트를 연결시켜 주는 모듈이다 뉴럴 네트워크 가속기는 PCIE 인터페이스, 컨트롤러, 뉴럴 네트워크 가속기 코어 및 메모 리를 포함하여 구성된다. PCIE 인터페이스는 호스트의 PCIE 인터페이스와 물리적인 연결을 위한 통신 인터페이스이고, 컨 트롤러는 PCIE 인터페이스를 통해 호스트와 연결된다. 가속기 코어는 뉴럴 네트워크의 학습/추론을 위해 대량의 PE(Processing Element)들을 생성하여 컨벌루션 연산을 수행한다. 호스트는 뉴럴 네트워크 가속기에 대한 연산 명령어를 개별적으로 연속하여 보내지 않고, 미리 정의 된 규격에 따른 명령어 세트로 생성하여 PCIE 인터페이스를 컨트롤러로 전달한다. 가속기 코어 에 생성된 대량의 PE들을 동시에 제어할 수 있도록 하기 위함이다. 도 2에는 호스트가 컨트롤러로 전달하는 명령어 세트를 예시하였다. 도시된 바와 같이, 명령어 세트 에는, Layer type, Input_mem offset, Weight_mem offset, Bias_mem offset, Output_mem offset, Control parameter가 포함된다. Layer type은 뉴럴 네트워크의 종류를 지시하는 정보이다. Input_mem offset, Weight_mem offset, Bias_mem offset, Output_mem offset는 입력 데이터, 뉴럴 네트워크의 가중치, 바이어스, 출력 데이터가 저장되는 메모리 위치와 길이를 지시하는 정보이다. Control parameter는 뉴럴 네트워크의 제어 파라미터로, 바이어스, 가중치 등을 포함한다. 컨트롤러는 호스트로부터 전달받은 명령어 세트를 메모리에 기록한다. 또한, 컨트롤러는 호스트로부터 수신하는 입력 데이터도 메모리에 기록한다. 도 3에는 메모리의 맵 구조를 나타내었다. 도시된 바와 같이, 메모리에는, Layer Parameter 영역, Input 영역, Bias 영역, Weight 영역, Output 영역을 포함하여 구성된다 Layer Parameter 영역은 전술한 명령어 세트가 기록되는 영역이다. Input 영역에는 입력 데이터가 기록되고, Bias 영역에는 뉴럴 네트워크의 바이어스 정보가 기록되며, Weight 영역은 뉴럴 네트워크의 가중치 정보가 기록 되고, Output 영역에는 뉴럴 네트워크의 출력 데이터가 기록된다. 호스트로부터 명령어 세트의 실행 명령이 있으며, 컨트롤러는 명령어 세트에 따라 가속기 코어 의 제어를 시작하여 뉴럴 네트워크 연산을 개시한다. 이하에서, 명령어 세트를 실행하는 과정에 대해, 도 4를 참조하여 상세히 설명한다. 도 4는 명령어 세트 실행 과정의 설명에 제공되는 흐름도이다. 도시된 바와 같이, 명령어 세트가 실행되면, 가속기 코어는 먼저 메모리의 Layer Parameter 영역에 저장되어 있는 명령어 세트를 읽어들여(S310), Layer type, 메모리 옵셋들(Input_mem offset, Weight_mem offset, Bias_mem offset, Output_mem offset) 및 Control parameter를 디코딩한다(S320). 다음, 뉴럴 네트워크 가속기 코어는 메모리 옵셋과 길이 값을 참조하여 입력 데이터, 가중치, 바이어스 정 보를 메모리에서 읽어들여 뉴럴 네트워크 가속기 코어의 내부 버퍼에 저장한다(S330). 그리고, 뉴럴 네트워크 가속기 코어는 뉴럴 네트워크 연산에 사용할 PE들을 구성하고 버퍼 데이터를 할당 한다(S340). 다음, 뉴럴 네트워크 가속기 코어는 PE들을 실행하여 뉴럴 네트워크 연산이 수행되도록 하고(S350), 연산 이 수행되면 출력 데이터를 메모리의 Output 영역에 기록한다(S360,S370). 위 과정은 한 레이어(이를 테면, convolution 레이어, fully connected 레이어)의 연산이 끝날 때까지 반복하여 수행된다(S380). 뉴럴 네트워크 가속기의 PE들에 의해 연산을 수행하는 중에도, 호스트는 메모리의 Output 영역 에 기록되는 출력 데이터들을 확인하여, 뉴럴 네트워크 가속기의 상태를 모니터링할 수 있다. 즉, 호스트는 뉴럴 네트워크 가속기의 연산이 종료되지 않은 상태에서도 명령어 세트에 기록된 값을 참조하여 메모리에 기록된 중간 결과들을 확인할 수 있는 것이다. 이를 통해, 호스트는 원하는 뉴럴 네트워크 계층에 관한 연산들에 대해서, 그에 맞는 명령어 세트를 생성 하여 제어할 수 있다. 지금까지, 뉴럴 네트워크 가속기의 효율적인 제어, 모니터링 및 소프트웨어 디버깅 방법에 대해 바람직한 실시 예를 들어 상세히 설명하였다. 위 실시예에서는, 뉴럴 네트워크 가속기 장치에 대한 효과적인 소프트웨어 개발 및 디버깅을 위해, 뉴럴 네트워 크 가속기를 명령어 세트 기반으로 제어하는 방법을 제시하였다. 본 발명의 실시예에 의해, 뉴럴 네트워크 루틴의 실행 후 뉴럴 네트워크 가속기 장치의 중간 결과 데이터 및 상 태를 확인할 수 있으므로, 뉴럴 네트워크 가속기를 사용하는 인공지능 장치의 소프트웨어 개발에 소요되는 시간 과 노력을 줄일 수 있게 된다. 한편, 본 실시예에 따른 장치와 방법의 기능을 수행하게 하는 컴퓨터 프로그램을 수록한 컴퓨터로 읽을 수 있는 기록매체에도 본 발명의 기술적 사상이 적용될 수 있음은 물론이다. 또한, 본 발명의 다양한 실시예에 따른 기 술적 사상은 컴퓨터로 읽을 수 있는 기록매체에 기록된 컴퓨터로 읽을 수 있는 코드 형태로 구현될 수도 있다. 컴퓨터로 읽을 수 있는 기록매체는 컴퓨터에 의해 읽을 수 있고 데이터를 저장할 수 있는 어떤 데이터 저장 장 치이더라도 가능하다. 예를 들어, 컴퓨터로 읽을 수 있는 기록매체는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광디스크, 하드 디스크 드라이브, 등이 될 수 있음은 물론이다. 또한, 컴퓨터로 읽을 수 있는 기록매체 에 저장된 컴퓨터로 읽을 수 있는 코드 또는 프로그램은 컴퓨터간에 연결된 네트워크를 통해 전송될 수도 있다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2019-0157203", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2019-0157203", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예가 적용가능한 뉴럴 네트워크 가속기의 개발 환경을 도시한 도면, 도 2는 호스트의 명령어 세트를 나타낸 도면, 도 3은 메모리의 맵 구조를 나타낸 도면, 그리고, 도 4는 명령어 세트 실행 과정의 설명에 제공되는 흐름도이다."}
