{"patent_id": "10-2023-0001514", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0110157", "출원번호": "10-2023-0001514", "발명의 명칭": "산업현장에서의 안전사고 감시를 위한 디지털 트윈 기반의 현장 관리 서버 및 현장 관리 방법", "출원인": "주식회사 넥스트디앤에이", "발명자": "이형준"}}
{"patent_id": "10-2023-0001514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "산업현장에 배치된 복수의 카메라로부터의 2D 영상 및 상기 산업현장에 배치된 1 이상의 이동 로봇으로부터의로그 데이터 - 상기 로그 데이터는 시간의 흐름에 따른 상기 이동 로봇의 위치, 경로, 방향 및 충돌 레벨을 포함함 - 를 수집하는 데이터 통신부;상기 2D 영상 및 상기 로그 데이터를 누적 기록하는 데이터 기록부; 및상기 데이터 통신부 및 상기 데이터 기록부에 동작 가능하게 결합되는 프로세서를 포함하되,상기 프로세서는,상기 2D 영상 및 상기 로그 데이터를 기초로, 상기 산업현장 내에서의 사고 이벤트의 발생을 검출하고,상기 사고 이벤트가 발생된 시각 및 위치를 나타내는 사고 설명 정보를 사고 이력으로서 상기 데이터 기록부에저장하도록 구성되는 것을 특징으로 하는, 현장 관리 서버."}
{"patent_id": "10-2023-0001514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 사고 이벤트의 발생이 검출되는 경우, 상기 사고 이벤트의 사고 설명 정보를 기초로, 상기 2D 영상을 3D영상으로 렌더링하여 상기 산업현장의 적어도 일부분에 대한 사고 재현 영상을 생성하도록 구성되는 것을 특징으로 하는, 현장 관리 서버."}
{"patent_id": "10-2023-0001514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 사고 이벤트의 사고 설명 정보를 원인 분석 모델에 입력하되, 상기 원인 분석 모델은 상기 사고 설명 정보를 서로 다른 사고 원인에 맵핑된 복수의 클러스터 중 어느 하나로 분류하도록 미리 학습된 것이고,상기 사고 설명 정보에 대해 상기 원인 분석 모델에 의해 분류된 어느 한 클러스터에 맵핑된 사고 원인에 기 부여된 사고 분류 코드를 상기 사고 이벤트에 맵핑하도록 구성되는 것을 특징으로 하는, 현장 관리 서버."}
{"patent_id": "10-2023-0001514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 프로세서는,상기 산업현장의 사고 발생 가능 공간에 대해 가상 분할된 다수의 하위 영역 중에서 상기 사고 이벤트가 발생한하위 영역의 사고 가이드 정보를 갱신하고,상기 다수의 하위 영역 각각의 사고 가이드 정보를 기초로, 하위 영역별 사고 위험도를 산출하며,상기 하위 영역별 사고 위험도를 기초로, 하위 영역별로 사고 방지 규칙을 할당하는 것을 특징으로 하는, 현장관리 서버.공개특허 10-2024-0110157-3-청구항 5 제4항에 있어서,상기 프로세서는,상기 로그 데이터를 기초로, 상기 다수의 하위 영역 중 상기 이동 로봇이 현재 위치하는 하위 영역을 식별하고,상기 식별된 하위 영역에 할당된 사고 방지 규칙에 따라, 상기 이동 로봇을 원격 제어하도록 구성되는 것을 특징으로 하는, 현장 관리 서버."}
{"patent_id": "10-2023-0001514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는,상기 다수의 하위 영역 각각의 사고 위험도를, 복수의 구간 중 어느 하나로 등급화하고,상기 복수의 구간에 일대일 대응하는 복수의 안전 거리 중 어느 하나를 하위 영역별로 설정하고,상기 식별된 하위 영역으로부터 상기 식별된 하위 영역에 설정된 안전 거리 이내에 다른 이동 로봇이나 작업자가 위치하는 것을 조건으로, 상기 식별된 하위 영역에 할당된 사고 방지 규칙에 따라, 상기 이동 로봇을 원격제어하도록 구성되는 것을 특징으로 하는, 현장 관리 서버."}
{"patent_id": "10-2023-0001514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 프로세서는,상기 데이터 통신부에 의해 수집된 상기 2D 영상 및 상기 산업현장 내에 위치하는 작업자의 통신 단말기로부터수집된 위치 신호를 기초로, 상기 작업자의 현 위치를 식별하고,상기 다수의 하위 영역 중 상기 작업자가 현재 위치하는 하위 영역을 식별하고,상기 식별된 하위 영역에 할당된 사고 방지 규칙에 따라, 상기 작업자의 통신 단말기를 원격 제어하도록 구성되는 것을 특징으로 하는, 현장 관리 서버."}
{"patent_id": "10-2023-0001514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제8항 중 어느 한 항에 따른 상기 현장 관리 서버에 의해 실행 가능한 현장 관리 방법에 있어서,상기 산업현장에 배치된 복수의 카메라로부터의 2D 영상 및 상기 산업현장에 배치된 1 이상의 이동 로봇으로부터의 로그 데이터 - 상기 로그 데이터는 시간의 흐름에 따른 상기 이동 로봇의 위치, 경로, 방향 및 충돌 레벨을 포함함 - 를 수집하는 단계;상기 2D 영상 및 상기 로그 데이터를 누적 기록하는 단계;상기 2D 영상 및 상기 로그 데이터를 기초로, 상기 산업현장 내에서의 사고 이벤트의 발생을 검출하는 단계; 및상기 사고 이벤트가 발생된 시각 및 위치를 나타내는 사고 설명 정보를 사고 이력으로서 상기 데이터 기록부에저장하는 단계;를 포함하는 것을 특징으로 하는, 현장 관리 방법."}
{"patent_id": "10-2023-0001514", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "안전사고 관리를 위한 디지털 트윈 기반의 산업현장 모니터링 시스템 및 현장 관리 방법이 개시된다. 본 발명에 따른 현장 관리 서버는 산업현장 모니터링 시스템에 포함되는 것으로서, 산업현장에 배치된 복수의 카메라로부터 의 2D 영상 및 상기 산업현장에 배치된 1 이상의 이동 로봇으로부터의 로그 데이터 - 상기 로그 데이터는 시간의 흐름에 따른 상기 이동 로봇의 위치, 경로, 방향 및 충돌 레벨을 포함함 - 를 수집하는 데이터 통신부, 상기 2D 영상 및 상기 로그 데이터를 누적 기록하는 데이터 기록부 및 상기 데이터 통신부 및 상기 데이터 기록부에 동작 가능하게 결합되는 프로세서를 포함한다. 상기 프로세서는, 상기 2D 영상 및 상기 로그 데이터를 기초로, 상기 산업현장 내에서의 사고 이벤트의 발생을 검출하고, 상기 사고 이벤트가 발생된 시각 및 위치를 나타내는 사고 설명 정보를 사고 이력으로서 상기 데이터 기록부에 저장하도록 구성된다."}
{"patent_id": "10-2023-0001514", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 디지털 트윈 기반의 현장 관리 서버 및 현장 관리 방법에 관한 것으로, 보다 상세하게는 산업현장 내 에 배치된 다수의 카메라와 1 이상의 이동 로봇으로부터 수집한 현장 데이터를 분석하여 산업현장에서의 안전 사고 발생 여부를 즉각적으로 파악하고, 카메라 영상과 로봇 데이터 간의 상호 보완을 통해 산업현장 내 존재하 는 사각지대를 최소화하여 사고 발생 원인을 규명하며, 향후의 안전 사고를 예방하기 위한 안전 대책(조치)를 자동적으로 수립 및 실행하는 기술에 관한 것이다."}
{"patent_id": "10-2023-0001514", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "산업현장의 각종 안정사고를 줄이고 관련자들의 경각심을 높이기 위한 취지로 2022년 1월부터 중대재해처벌법이 시행됨에 따라, 산업현장에서의 안전사고를 미연에 방지하고 부득이 안전사고가 발생한 경우에는 해당 사고의 원인을 정확하고 신속하게 파악하는 것이 더욱 중요해졌다. 특허문헌 1에 따른 산업시설 관리 시스템은 복합 기술을 통한 전국의 산업 시설물을 원격으로 감시 제어하고 데 이터베이스 구축을 통해 산업시설 및 자원의 최적화 운전을 지원한다. 또한, 특허문헌 2에 따르면 공정데이터 추적이 가능한 미들웨어를 이용한 공정관리 시스템은 시스템을 구축하는데 시간과 비용을 절감할 수 있으며, 공 장에서 사용되는 모든 장치의 데이터를 습득할 수 있어 생산계획을 구상하는데 도움을 준다. 또한, 특허문헌 3 에 따르면 대규모 데이터 세트들을 갖는 산업 사물 인터넷 데이터 수집 환경에서의 검출을 위한 방법들 및 시스 템들은 산업 환경에서의 모니터링, 원격 제어, 자율 액션, 및 다른 활동을 위해 수집된 데이터를 활용한다. 도 1은 종래기술에 따른 산업현장의 모식도로서, 다수의 설비가 배치된 산업현장 내부에서 각각 고유의 인지 범 위를 가지는 이동 로봇(AGV)과 작업자(U)가 각자 맡은 역할을 수행하는 도중에 설비나 기타 구조물 등으로 인해 인지 범위가 제한됨으로 인해 미쳐 상대를 발견하여 회피하는 데에 실패함에 따라 충돌 사고가 발생할 수 있다. 그런데, 종래기술이 적용된 산업현장에는 극히 제한된 일부 공간에 대한 촬영을 통해 획득된 영상 확인만이 가 능하여서 부주의나 작업 미숙 내지는 시스템 에러 등으로 인해 발생 가능한 각종 안전 사고가 실제가 일어났는 지 즉각적으로든 사후적으로든 검출해내기에는 미흡한 측면이 있다. 더욱이, 일단 안전 사고가 발생해버린 경우, 산업현장 내 곳곳에 형성된 사각지대로 인해 해당 안전 사고가 언제 어떤 이유로 얼마나 심하게 일어났는 지 규명해내기 쉽지 않을 뿐만 아니라 향후에 동종의 안전 사고의 재발 방지를 위한 일종의 가이드를 제공하지 못한다. 선행기술문헌 특허문헌 (특허문헌 0001) 특허문헌 1: 등록특허공보 제10-0448668호(2004.09.03) (특허문헌 0002) 특허문헌 2: 등록특허공보 제10-1724557호(2017.04.03) (특허문헌 0003) 특허문헌 3: 공개특허공보 제10-2020-0037816호(2020.04.09)"}
{"patent_id": "10-2023-0001514", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 다양한 각도로 촬영된 2D 영상을 입력하고, 단말기가 통제하는 이동 로봇의 현장 장치에 대한 로그 데이터를 기록하고, 2D 영상을 3D 영상으로 렌더링 변환하고, 동기화된 장치 상태, 뉴럴 렌더링 이미지 모델을 수행하여 이동 로봇과 작업자의 충돌 사고를 예측하고, 방지하는 산업현장 모니터링 시스템을 제공하는 것을 목 적으로 한다. 또한, 본 발명은 3D 영상에서 사고 발생을 예측하고, 이동 로봇과 작업자에게 가이드를 제공해서 사고 재발을 방지하는 산업현장 모니터링 시스템을 제공하는 것을 또 다른 목적으로 한다. 본 발명의 다른 목적 및 장점들은 하기의 설명에 의해서 이해될 수 있으며, 본 발명의 실시예에 의해 보다 분명 하게 알게 될 것이다. 또한, 본 발명의 목적 및 장점들은 특허청구범위에 나타난 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2023-0001514", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따른 현장 관리 서버는 산업현장 모니터링 시스템에 포함되는 것으로서, 산업현장에 배치 된 복수의 카메라로부터의 2D 영상 및 상기 산업현장에 배치된 1 이상의 이동 로봇으로부터의 로그 데이터 - 상 기 로그 데이터는 시간의 흐름에 따른 상기 이동 로봇의 위치, 경로, 방향 및 충돌 레벨을 포함함 - 를 수집하 는 데이터 통신부, 상기 2D 영상 및 상기 로그 데이터를 누적 기록하는 데이터 기록부 및 상기 데이터 통신부 및 상기 데이터 기록부에 동작 가능하게 결합되는 프로세서를 포함한다. 상기 프로세서는, 상기 2D 영상 및 상 기 로그 데이터를 기초로, 상기 산업현장 내에서의 사고 이벤트의 발생을 검출하고, 상기 사고 이벤트가 발생된 시각 및 위치를 나타내는 사고 설명 정보를 사고 이력으로서 상기 데이터 기록부에 저장하도록 구성된다. 상기 프로세서는, 상기 사고 이벤트의 발생이 검출되는 경우, 상기 사고 이벤트의 사고 설명 정보를 기초로, 상 기 2D 영상을 3D 영상으로 렌더링하여 상기 산업현장의 적어도 일부분에 대한 사고 재현 영상을 생성하도록 구 성될 수 있다. 상기 프로세서는, 상기 사고 이벤트의 사고 설명 정보를 원인 분석 모델에 입력할 수 있다. 상기 원인 분석 모 델은 상기 사고 설명 정보를 서로 다른 사고 원인에 맵핑된 복수의 클러스터 중 어느 하나로 분류하도록 미리 학습된 것일 수 있다. 상기 프로세서는, 상기 사고 설명 정보에 대해 상기 원인 분석 모델에 의해 분류된 어느 한 클러스터에 맵핑된 사고 원인에 기 부여된 사고 분류 코드를 상기 사고 이벤트에 맵핑하도록 구성될 수 있다. 상기 프로세서는, 상기 산업현장의 사고 발생 가능 공간에 대해 가상 분할된 다수의 하위 영역 중에서 상기 사 고 이벤트가 발생한 하위 영역의 사고 가이드 정보를 갱신할 수 있다. 상기 프로세서는, 상기 다수의 하위 영역 각각의 사고 가이드 정보를 기초로, 하위 영역별 사고 위험도를 산출하며, 상기 하위 영역별 사고 위험도를 기 초로, 하위 영역별로 사고 방지 규칙을 할당할 수 있다. 상기 프로세서는, 상기 로그 데이터를 기초로, 상기 다수의 하위 영역 중 상기 이동 로봇이 현재 위치하는 하위 영역을 식별하고, 상기 식별된 하위 영역에 할당된 사고 방지 규칙에 따라, 상기 이동 로봇을 원격 제어하도록 구성될 수 있다. 상기 프로세서는, 상기 다수의 하위 영역 각각의 사고 위험도를, 복수의 구간 중 어느 하나로 등급화하고, 상기 복수의 구간에 일대일 대응하는 복수의 안전 거리 중 어느 하나를 하위 영역별로 설정하고, 상기 식별된 하위 영역으로부터 상기 식별된 하위 영역에 설정된 안전 거리 이내에 다른 이동 로봇이나 작업자가 위치하는 것을 조건으로, 상기 식별된 하위 영역에 할당된 사고 방지 규칙에 따라, 상기 이동 로봇을 원격 제어하도록 구성될 수 있다. 상기 프로세서는, 상기 데이터 통신부에 의해 수집된 상기 2D 영상 및 상기 산업현장 내에 위치하는 작업자의 통신 단말기로부터 수집된 위치 신호를 기초로, 상기 작업자의 현 위치를 식별하고, 상기 다수의 하위 영역 중 상기 작업자가 현재 위치하는 하위 영역을 식별하고, 상기 식별된 하위 영역에 할당된 사고 방지 규칙에 따라, 상기 작업자의 통신 단말기를 원격 제어하도록 구성될 수 있다. 본 발명의 다른 측면에 따른 현장 관리 방법은 상기 현장 관리 서버에 의해 실행 가능한 것으로서, 상기 산업현 장에 배치된 복수의 카메라로부터의 2D 영상 및 상기 산업현장에 배치된 1 이상의 이동 로봇으로부터의 로그 데 이터 - 상기 로그 데이터는 시간의 흐름에 따른 상기 이동 로봇의 위치, 경로, 방향 및 충돌 레벨을 포함함 - 를 수집하는 단계, 상기 2D 영상 및 상기 로그 데이터를 누적 기록하는 단계, 상기 2D 영상 및 상기 로그 데이 터를 기초로, 상기 산업현장 내에서의 사고 이벤트의 발생을 검출하는 단계 및 상기 사고 이벤트가 발생된 시각 및 위치를 나타내는 사고 설명 정보를 사고 이력으로서 상기 데이터 기록부에 저장하는 단계를 포함한다."}
{"patent_id": "10-2023-0001514", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들 중 적어도 하나에 의하면, 다양한 각도로 촬영된 고화질 현장 스냅샷 이미지를 입력하고, 단말기가 통제하는 이동 로봇의 현장 장치에 대한 로그 데이터를 기록하고, 스냅샷 이미지를 3D 영상으로 렌더 링 변환하고, 동기화된 장치 상태, 뉴럴 렌더링 이미지 모델을 수행하여 이동 로봇과 작업자의 충돌 사고를 예측하고, 방지함으로써 카메라와 이동 로봇에서 얻은 데이터로 현장의 상태를 정확히 파악하고, 원격으로 자세히 상황을 볼 수 있고, 지속적으로 데이터를 얻음으로써 현재의 상황 뿐만 아니라 미래에 일어날 상황에 대해 대비 도 가능한 효과를 가질 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 3D 영상에서 사고 발생을 예측하고, 이동 로봇과 작업자에 게 가이드를 제공해서 사고 재발을 방지함으로써 만약 사고사 일어난다면 사고의 정확한 원인 파악과 당시 상황 을 정확히 이해할 수 있게 될 것이고, 이로 인해 미래에 같은 사고가 일어나는 것을 방지하고, 3D 디지털 트윈 을 이용하여 직원을 상대로 원격 교육을 진행할 수 있고, 현장과 같은 모델을 통한 교육으로 산업현장의 효율성 을 높이는 효과를 가질 수 있다."}
{"patent_id": "10-2023-0001514", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0001514", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적과 기술적 구성 및 그에 따른 작용 효과에 관한 자세한 사항은 본 발명의 명세서에 첨부된 도면 에 의거한 이하의 상세한 설명에 의해 보다 명확하게 이해될 것이다. 첨부된 도면을 참조하여 본 발명에 따른 실시예를 상세하게 설명한다. 본 명세서에서 개시되는 실시예들은 본 발명의 범위를 한정하는 것으로 해석되거나 이용되지 않아야 할 것이다. 이 분야의 통상의 기술자에게 본 명세서의 실시예를 포함한 설명은 다양한 응용을 갖는다는 것이 당연하다. 따 라서, 본 발명의 상세한 설명에 기재된 임의의 실시예들은 본 발명을 보다 잘 설명하기 위한 예시적인 것이며 본 발명의 범위가 실시예들로 한정되는 것을 의도하지 않는다. 도면에 표시되고 아래에 설명되는 기능 블록들은 가능한 구현의 예들일 뿐이다. 다른 구현들에서는 상세한 설명 의 사상 및 범위를 벗어나지 않는 범위에서 다른 기능 블록들이 사용될 수 있다. 또한, 본 발명의 하나 이상의 기능 블록이 개별 블록들로 표시되지만, 본 발명의 기능 블록들 중 하나 이상은 동일 기능을 실행하는 다양한 하드웨어 및 소프트웨어 구성들의 조합일 수 있다. 제1, 제2 등과 같이 서수를 포함하는 용어들은, 다양한 구성요소들 중 어느 하나를 나머지와 구별하는 목적으로 사용되는 것이고, 그러한 용어들에 의해 구성요소들을 한정하기 위해 사용되는 것은 아니다. 또한, 어떤 구성요소들을 포함한다는 표현은 \"개방형\"의 표현으로서 해당 구성요소들이 존재하는 것을 단순히 지칭할 뿐이며, 추가적인 구성요소들을 배제하는 것으로 이해되어서는 안 된다. 나아가 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급될 때에는, 그 다른 구성 요소에 직접적으로 연결 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 한다. 도 2는 본 발명의 일 실시예에 따른 산업현장 모니터링 시스템의 구성을 개략적으로 나타낸 모식도이다. 도 2를 참조하면, 산업현장 모니터링 시스템은, 카메라(C), 이동 로봇(AGV), 현장 관리 서버 및 통신 단말기(T)를 포함한다. 여기서, 카메라(C), 이동 로봇(AGV) 및 통신 단말기(T)는 각각 다수일 수 있다. 산업현장에는 다수의 설비(E)가 정해진 위치에 배치되며, 산업현장의 건물 구조물과 다수의 설비(E)에 의해 정 의되는 통로 등의 작업 공간을 통해 이동 로봇(AGV)과 작업자(U)가 이동하면서 산업현장의 목적에 부합하는 공정, 임무 또는 작업이 이루어진다. 카메라(C)는 단안 카메라, 스테레오 카메라, 적외선 카메라 또는 CCTV 중 하나 또는 둘 이상의 조합이 이용될 수 있다. 각 이동 로봇(AGV)은 무인 운반차, 모바일 로봇 또는 AGV(Automated Guided Vehicle)이라고 칭해질 수 있다. 이동 로봇(AGV)은 자체적인 주행 기능을 제공하는 구동부(예, 전기 모터와 휠), 통신 회로, 적어도 1종의 공간 인식 센서 및 상황 감지 센서(예, 충격 센서, 속도계, 자이로스코프, GPS 모듈)를 포함하고, 완전 자율 주행, 부분 자율 주행 또는 완전 통제 주행을 통해 자신에게 할당된 임무(작업)를 수행하도록 제공된다. 현장 관리 서버는 산업현장의 내부나 외부에 구비되어 다수의 카메라(C) 및 이동 로봇(AGV)과 유무선 통신 네트워크를 통해 상호 작용할 수 있도록 제공된다. 현장 관리 서버는 산업현장 내부의 곳곳에 위치하는 다수의 카메라(C) 및 이동 로봇(AGV)의 동작을 원격으 로 제어할 수 있고, 카메라(C)별로 획득되는 2D 영상과 이동 로봇(AGV)의 동작 상태를 나타내는 로그 데이터를 수집할 수 있다. 현장 관리 서버는 수집된 데이터를 그 자체에 마련된 저장소나 외부의 클라우드에 보관할 수 있다. 클라우드 저장소는 현장 관리 서버로부터 전달받은 로그 데이터를 이용하여 현장 관리 서 버의 동작 이상을 모니터링하고, 현장 관리 서버가 이상 동작하지 않도록 이상 발생에 대응한다. 로 그 데이터는 이동 로봇(AGV)의 위치, 충돌 레벨, 이동 경로, 속도, 가속도, 방향, 자세, 2D 영상(이동 로봇에 의해 취득된 것)을 포함한다. 현장 관리 서버는 카메라(C)로 촬영된 2D 영상을 3D 영상으로 변환할 수 있다. 이때, 2D 영상으로부터 3D 영상으로의 변환에는, Instant NeRF 등과 같은 인공지능 기반의 렌더링 알고리즘이 이용될 수 있다. 현장 관리 서버는 2D 영상, 3D 영상 및 로그 데이터 중 적어도 하나를 기초로 산업현장 내의 사고 발생 여 부 및/또는 사고 발생 가능성을 연산할 수 있고, 나아가서는 이동 로봇(AGV) 및 작업자(U) 중 적어도 하나를 대 상으로 사고 발생 방지를 위한 가이드나 원격 제어를 실시할 수도 있다. 또한, 현장 관리 서버는 부득이 안전 사고가 실제로 발생한 경우에는, 해당 사고의 발생 시각과 원인을 자동 파악하고, 동종 사고의 재발 방지 대책을 수립한 다음, 그 결과를 작업자(U)가 확인 가능한 형태로 반환할 수 있다. 일 예로, 현장 관리 서버는 이동 로봇(AGV)에서 수집된 로그 데이터가 일정 레벨 이상의 충돌 레벨을 포함 하는 경우, 해당 충돌 레벨의 시간 코드를 기초로 사고 발생 시각을 식별(추정)할 수 있으며, 사고 발생 시각을 포함하는 시간 구간에 걸쳐 촬영된 2D 영상을 특정하여 3D 영상으로 변환할 수 있다. 이때, 상기 시간 구간의 길이는, 충돌 레벨의 크기에 비례하도록 설정될 수 있다. 즉, 충돌 레벨이 크가는 것은 사고의 심각성이 높다는 것을 의미하므로, 심한 충돌이 발생한 것으로 파악되는 경우에는 그 사고의 전후 상황을 정밀하게 파악하기 위 한 일환으로서 3D 영상을 확보하고자 하는 시간 구간의 길이를 그만큼 증가시키는 것이다. 물론, 현장 관리 서버는 2D 영상 또는 3D 영상에 대한 객체 인식 알고리즘의 적용을 통해 로그 데이터 없 이도 이동 로봇(AGV) 간, 이동 로봇(AGV)과 작업자(U) 간, 이동 로봇(AGV)과 시설(E) 간 또는 작업자(U) 간의 사고가 언제 어느 위치에서 얼마나 큰 세기로 발생하였는지 검출 및 기록할 수도 있다. 현장 관리 서버는 산업현장 내에서의 사고 발생 여부와는 무관하게 카메라(C)별로 수집되는 2D 영상을 실 시간 또는 준실시간적으로 3D 영상으로 변환할 수 있으며, 이로써 산업현장에 대한 디지털 트윈이 생성될 수 있 다. 3D 영상 포맷을 가진 디지털 트윈은 다수의 카메라(C)에 의해 촬영되는 산업현장의 전체 또는 적어도 일부분을 실시간 또는 준실시간으로 시각화한 것이거나, 1 이상의 카메라(C)에 의해 촬영되는 산업현장의 일부분만을 실 시간 또는 준실시간으로 시각화한 것일 수 있다. 현장 관리 서버는 상기 시간 구간 즉, 사고 발생 시간대에서의 3D 영상 구간을 사고 재현 영상으로서 별도 로 관리할 수도 있다. 이러한 사고 재현 영상은 3D 형태로 렌더링된 것인바, 작업자(U)의 통신 단말기(T)(예, AR 글라스, 헤드 마운트 디스플레이, 스마트폰, 퍼스널 컴퓨터 등)에서 반복 재생은 물론 터치 조작이나 제스쳐 등을 통해 각도 전환/확대/축소된 뷰로 표시 가능하다. 한편, 산업현장은 전술된 바와 같이 다수의 설비(E)이 배치되어 이동 로봇(AGV)과 작업자(U)의 이동이 불가한 공간과 그 외의 나머지 공간 즉, 이동 로봇(AGV)과 작업자(U)의 이동이 가능한 공간으로 구분될 수 있다. 이동 로봇(AGV)과 작업자(U)의 이동이 가능한 공간은 사고 발생 가능 공간으로 현장 관리 서버에 설정될 수 있 고, 사고 발생 가능 공간만을 대상으로 모니터링함으로써 한정된 하드웨어 및 소프트웨어 자원을 효율적으로 운 용할 수 있다. 사고 발생 가능 공간을 정의하는 버드 뷰(탑뷰)가 사전 제작되어 현장 관리 서버에 저장될 수 있다. 이러 한 버드 뷰의 대상 영역은 격자 등과 같은 소정 사이즈의 다수의 하위 영역으로 가상 분할될 수 있고, 각 하위 영역에는 고유의 식별 코드가 미리 부여될 수 있다. 만약 어떠한 사고가 산업현장 내에서 발생한 경우, 현장 관 리 서버는 해당 사고가 발생한 각 하위 영역의 식별 코드에 해당 사고의 사고 가이드 정보를 맵핑하여 저 장할 수 있다. 이로써, 산업현장의 어느 위치에서 어느 시간대에 어떤 유형의 사고가 빈번히 발생하는지를 나타 내는 사고 이력이 정밀하게 누적 관리될 수 있고, 사고 유형별 발생 가능성을 예측할 수 있을 뿐만 아니라 사고 유형별 방지 대책의 수립이 가능하다. 또한, 작업자(U)의 통신 단말기(T)로부터 특정 유형의 사고 이력이 요청 되는 경우, 해당 유형에 대응하는 것으로 기록된 사고 이력만을 선별하여 즉각적으로 피드백 가능하다는 장점 또는 있다. 현장 관리 서버는 사고 이벤트, 가이드를 포함하는 과거 사고 이력 정보를 기초로 이동 로봇(AGV)의 현 동 작 상태에 따른 사고 가능성을 예측하고, 사고 가능성이 높을 경우(일정 임계치를 초과할 경우) 이동 로봇(AG V)이 안전하게 사고를 회피하도록 원격 제어할 수 있다. 현장 관리 서버는 그에 의해 원격 통제 가능한 이 동 로봇(AGV)의 사고 가능성을 모니터링하고, 사고 가능성이 높을 경우(일정 임계치를 초과할 경우) 현장 관리 서버에 이동 로봇(AGV)의 원격 제어를 명령할 수 있다. 현장 관리 서버에 의해 수집된 로그 데이터는 사고 당시는 물론 사고 전 일정 시간과 사고 후 일정 시간에 걸친 이동 로봇(AGV)의 동작과 주변 상황을 직간접적으로 설명하고 있다. 예를 들어, 사고 유형이 설비(E)에 의 한 사각 지대에 해당하는 통로의 코너 부근에서의 이동 로봇(AGV)과 작업자(U) 간의 충돌이라면, 이동 로봇 (AGV)이 코너로 인한 사각 지대를 확인하지 못하여 속도를 미리 감소시키지 못한 것이 사고 원인으로 식별된다. 이동 로봇(AGV)의 관점에서의 산업현장 내의 사각 지대란, 이동 로봇(AGV) 자체에 구비된 센서들(예, 카메라 (C), 라이다, 레이더, 초음파 센서 등)의 본래 센싱 범위가 산업현장의 설비(E)나 기타 장애물 등으로 인해 제 한(차단)되는 영역 내지는 공간을 의미한다. 현장 관리 서버의 주요 기능은 크게 사고 재현 기능, 사고 원인 식별 기능 및 사고 방지 기능을 포함하며, 각 기능에 대해서는 이하에서 도면들을 참고하여 보다 상세히 설명하기로 한다. 도 3은 도 1에 도시된 산업현장 모니터링 시스템이 적용되는 산업현장의 예시적인 내부 모습을 설명하는 데에 참조되는 도면이다. 도 3을 참조하면, 산업현장에는 다수의 설비(E)가 미리 정해진 위치에 자리잡고 있다. 4개의 카메라(C)가 산업 현장 내의 서로 다른 위치에 설치되어, 각각 고유의 촬영 범위에 대한 2D 영상을 생성한다. 설명의 편의를 위해, 이동 로봇(AGV)과 작업자(U)가 각각 하나씩 도시하였다. 도 1과 비교할 때 도 3에서는 카메라(C)가 다수 배치되어 있으며, 이로써 산업현장 내에서 사고 발생이 가능한 공간이 빠짐없이 영상물로 기록될 수 있다. 4개의 카메라(C)에 의해 이동 로봇(AGV)과 작업자(U) 각각의 이동 경로, 위치, 방향 등이 촬영되고, 현장 관리 서버는 카메라(C)별로 취득되는 2D 영상을 처리(예, 작업자(U)와 로봇을 객체로 검출)하여 이동 로봇(AG V)과 작업자(U)의 충돌 사고 시점은 물론 사고 전후의 시간대에서의 산업현장 내 물리적 상황을 인식할 수 있다. 충돌 사고 직전에 이동 로봇(AGV)은 이동 로봇(AGV) 자체의 제한적인 센싱 범위로 인해 반대편 코너 근처에서 접근하는 작업자(U)나 다른 이동 로봇(AGV)을 감지하기 어려워서 계속 이동한다. 충돌 사고의 가능성에도 불구 하고 이동 로봇(AGV)의 사각지대로 인해 이동 로봇(AGV)이 계속 코너를 향하여 이동함으로 인해 코너 근처에서 이동 로봇(AGV)가 작업자(U)와 충돌하는 사고가 발생할 수 있다. 도 4는 도 3에 도시된 산업현장에서 발생된 사고 상황을 3차원 형태로 재현한 영상을 예시한다. 도 4를 참조하면, 현장 관리 서버는 2D 영상을 3D 영상으로 변환할 수 있으며, 도 3의 하단 상황과 같이 이동 로봇(AGV)이 설비(E) 사이를 이동하는 중 코너 근처에서 이동 로봇(AGV)과 작업자(U)간에 충돌 사고가 발 생한 상황을 보여주고 있다. 본 발명에 따른 산업현장 모니터링 시스템은 산업현장의 전체 공간 중에서 사고가 발생한 영역에 대한 3D 영상만을 특정적으로 추출할 수 있고, 향후에 동종의 사고 발생을 방지하기 위한 목적으로, 특정 유형의 사고 가능성이 임계치를 초과하는 경우에는 이동 로봇(AGV)과 작업자(U) 중 적어도 하나에게 가이드를 제공해서 사고 재발을 방지한다. 현장 관리 서버는 카메라(C)별로 취득되는 2D 영상 대신 그를 변환하여 얻은 3D 영상을 처리(예, 작업자 (U)와 로봇을 객체로 검출)하여 이동 로봇(AGV)과 작업자(U)의 충돌 사고 시점은 물론 사고 전후의 시간대에서 의 산업현장 내 물리적 상황을 인식할 수도 있다. 도 5는 도 2에 도시된 현장 관리 서버의 구성을 예시적으로 나타낸 도면이다. 도 5를 참조하면, 현장 관리 서버는 데이터 통신부 및 컨트롤러를 포함한다. 데이터 통신부는 2 이상의 카메라(C)에 의해 다양한 각도(촬영 범위)로 촬영된 2D 영상(예, 스냅샷 이미지)을 입력받는다. 이때, 카메라(C)로부터 수집되는 2D 영상은 일정 레벨 이상의 해상도를 갖는 고화질 영 상일 수 있다. 컨트롤러는, 입출력 인터페이스, 데이터 기록부 및 프로세서와, 이들을 통신 가능하도록 접속하는 데이터 버스를 포함한다. 입출력 인터페이스는, 데이터 통신부로부터 수집된 산업현장의 센싱 정보를 데이터 버스를 통해 데이터 기록부 및/또는 프로세서에 전달하고, 프로세서가 후술된 방법들을 실행함으로써 생성된 신호, 데이터, 정보 및/또는 명령을 입출력 인터페이스에 전달한다. 데이터 기록부는 하드웨어적으로 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입(Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타 입(multimedia card micro type), 램(random access memory; RAM), SRAM(static random access memory), 롬 (read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory) 중 적어도 하나 또는 둘 이상의 타입의 저장매체를 포함할 수 있다. 데 이터 기록부는 후술된 현장 관리 방법을 실행하는 명령어가 기록된 컴퓨터 프로그램이 저장된 저장매체를 포함할 수 있다. 데이터 기록부는, 본 발명에 따른 산업현장 관리에 요구되는 학습 모델, 컴퓨터 프로그램 및/또는 데이터 를 저장하고 있다. 또한, 데이터 기록부는 카메라(C) 별 2D 영상은 물론 자율 주행하거나 또는 현장 관리 서버에 의해 통제되는 이동 로봇(AGV)으로부터 수집된 로그 데이터를 기록한다. 또한, 데이터 기록부(22 2)는 데이터 통신부에 의해 수집되는 작업자(U)별 통신 단말기(T)의 위치 신호를 비롯한 로그 데이터 역시 도 기록할 수 있다. 프로세서는, 입출력 인터페이스 및 데이터 기록부에 동작 가능하게 결합되어, 현장 관리 서버 의 전체적인 동작을 제어한다. 프로세서는 하드웨어적으로, ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 포함할 수 있다. 프로세서는 기능 블록으로서 주 제어부, 원인 분석부 및 사고 방지부를 포함할 수 있다. 주 제어부는 2D 영상을 3D 영상으로 변환할 뿐만 아니라, 카메라(C) 및 이동 로봇(AGV)의 시간 기준을 동 기화한다. 아울러, 주 제어부는 사고 재현 영상을 추출하고, 사고 발생 시마다 데이터 기록부에 기록 된 사고 이력을 갱신할 수 있다. 원인 분석부는 로그 데이터, 2D 영상 및 3D 영상 중 적어도 하나를 기초로, 이동 로봇(AGV) 및/또는 작업 자(U)에게 발생된 유형별 사고(사고 이벤트)의 발생 여부 및/또는 가능성을 판단하고, 기 발생된 사고 이벤트의 원인을 추정(식별)할 수 있다. 사고 방지부는 산업현장 내에서 과거에 발생된 사고(들)의 이력 정보를 토대로 향후에 발생 가능한 사고를 미연에 방지하기 위한 선제적인 가이드(안전 조치)를 이동 로봇(AGV)과 작업자(U) 중 적어도 하나에게 제공할 수 있다. 도 6은 본 발명의 일 실시예에 따른 현장 관리 방법을 예시적으로 설명하기 위한 순서도이다. 도 6의 방법은 현 장 관리 서버의 사고 재현 기능의 실행을 위한 것일 수 있다. 도 6의 방법의 각 단계는 프로세서에 의해 실행될 수 있다. 도 6을 참조하면, 단계 S610에서, 현장 관리 서버는 산업현장에 대한 센싱 정보를 수집한다. 수집된 센싱 정보는 현장 관리 서버 내부 및/또는 외부에 구비된 저장소에 기록될 수 있다. 여기서, 센싱 정보는, 기본 적으로 카메라(C) 별 2D 영상을 포함하고, 이동 로봇(AGV) 별 로그 데이터 및/또는 통신 단말기(T) 별 로그 데 이터를 더 포함할 수 있다. 단계 S620에서, 현장 관리 서버는 센싱 정보를 기초로, 산업현장 내의 사고 발생 여부를 판정한다. 단계 S620의 값이 \"예\"인 경우, 도 6의 방법은 단계 S630으로 진행한다. 단계 S630에서, 현장 관리 서버는 센싱 정보로부터 사고 설명 정보를 추출한다. 사고 설명 정보는, 단계 S620에 발생한 것으로 판정된 사고의 대상, 시각, 위치, 세기(예, 충돌 세기), 타입(예, 이동 로봇(AGV) 단독 사고, 작업자(U) 단독 사고, 이동 로봇(AGV) 간의 사고 등) 등을 나타내는 정보일 수 있다. 단계 S640에서, 현장 관리 서버는 사고 설명 정보를 기초로, 사고 재현 영상을 생성한다. 구체적으로, 현 장 관리 서버는 사고 설명 정보가 나타내는 사고 시각에 대응하는 2D 영상 구간을 특정한 다음, 특정된 2D 영상을 3D 영상으로 변환한다. 추가적으로, 3D 영상에서 사고 위치에 대응하는 부분을 추출함으로써 사고 재현 영상의 생성이 완료될 수 있다. 단계 S650에서, 현장 관리 서버는 단계 S620에 발생한 것으로 판정된 사고의 사고 설명 정보를 이용하여 산업현장에서의 사고 이력을 갱신한다. 도 6에서는 단계 S650이 단계 S640에 후행하는 것으로 도시되어 있으나, 이는 하나의 예시에 불과하며, 단계 S640이 단계 S650보다 후행하거나 두 단계 중 어느 하나가 실행 중에 다른 하나가 병렬적으로 실행될 수도 있다. 도 7은 본 발명의 다른 실시예에 따른 현장 관리 방법을 예시적으로 설명하기 위한 순서도이다. 도 7의 방법은 현장 관리 서버의 사고 원인 식별 기능의 실행을 위한 것일 수 있다. 도 7의 방법의 각 단계는 프로세서 에 의해 실행될 수 있다. 도 7을 참조하면, 단계 S710에서, 현장 관리 서버는 데이터 기록부에 저장된 사고 이력에 정렬된 사 고 이벤트 목록 중에서 원인 식별 대상을 설정한다. 예컨대, 현장 관리 서버는 산업현장 내에서 과거에 발 생한 바 있는 사고들을 소정 기준(예, 발생 시각)에 따라 리스트화하여 작업자(U)의 통신 단말기(T)에 제공할 수 있고, 작업자(U)거 사고 리스트에서 특정 사고를 선택하면, 통신 단말기(T)은 선택된 특정 사고를 원인 식별 대상으로 현장 관리 서버에 통지할 수 있다. 단계 S720에서, 현장 관리 서버는 단계 S710에서 원인 식별 대상으로 설정된 사고 이벤트의 사고 설명 정 보를 데이터 기록부로부터 획득한다. 단계 S730에서, 현장 관리 서버는 단계 S720에서 획득된 사고 설명 정보(추가적으로 2D 영상 또는 3D 영상 이 함께 활용될 수 있음)를 원인 분석 모델에 입력하여, 원인 분석 모델로부터 원인 식별 대상이 되는 사고 이 벤트의 사고 원인을 식별할 수 있다. 여기서, 원인 분석 모델은, 대량의 학습 데이터 셋을 통해 사전 학습된 딥 러닝 모델일 수 있고, 서로 다른 사고 원인에 맵핑된 복수의 클러스터를 가지며, 어떤 사고 설명 정보가 입력 데이터로 수신되는 경우, 해당 입력 데이터를 상기 복수의 클러스터 중에서 어느 한 클러스터로 분류한다. 현장 관리 서버는 원인 분석 모델의 동작에 의해 분류된 어느 한 클러스터에 맵핑된 사고 원인을 단계 S720에서 획득된 사고 설명 정보에 대한 정답으로서 출력하는 것이다. 일 예로, 사고 설명 정보가 (i)특정 이동 로봇 (AGV)이 특정 시각에 코너 부근에서 임계치 이상의 충돌을 센싱한 것, (ii)동일 시각에 동기화된 2D 영상에서 작업자(U)와 특정 이동 로봇(AGV)이 소정 거리 내에 위치하는 것으로 객체 인식되는 것 및 (iii)작업자(U)와 특 정 이동 로봇(AGV) 중 적어도 하나의 속도가 동일 시각에서 소정치 이상 급감하는 것을 나타내는 경우, 해당 사 고 이벤트는 코너 부근의 사각지대로 인해 특정 이동 로봇(AGV)이 미리 속도를 감소시키지 못한 채로 주행한 것 이 원인이라고 식별될 수 있다. 단계 S740에서, 현장 관리 서버는 원인 식별 대상으로 설정된 사고 이벤트에 단계 S730에서 식별된 사고 원인에 기 부여된 사고 분류 코드를 맵핑할 수 있다. 각각의 사고 원인은 몇가지 카테고리로 범주화될 수 있고, 카테고리별로 고유의 사고 분류 코드가 부여됨으로써, 사후적으로 관리자에 의한 사고 이벤트별 사고 원인의 관 리와 검색의 용이성을 도모할 수 있다. 도 8은 본 발명의 또 다른 실시예에 따른 현장 관리 방법을 예시적으로 설명하기 위한 순서도이다. 도 8의 방법 은 현장 관리 서버의 사고 방지 기능의 실행을 위한 것일 수 있다. 사고 방지 기능은, 과거의 사고 이력을 토대로 미래에 동일 타입의 사고가 발생하지 않도록 소정의 안전 조치를 취하는 것이다. 도 8의 방법의 각 단계 는 프로세서에 의해 실행될 수 있다. 도 8을 참조하면, 단계 S810에서, 현장 관리 서버는 데이터 기록부에 저장된 사고 이력을 기초로, 산 업현장 내에 미리 정의된 사고 발생 가능 공간의 하위 영역별로 맵핑된 사고 가이드 정보를 획득한다. 임의의 하위 영역의 사고 가이드 정보는, 해당 하위 영역에서 사고 이벤트가 발생할 때마다 갱신될 수 있다. 임 의의 하위 영역에 맵핑된 사고 가이드 정보는, 해당 하위 영역에서 과거에 발생한 적이 있는 사고의 총 횟수와 사고별 유형(예, 로봇 간의 충돌, 작업자(U) 간의 충돌, 로봇과 작업자(U) 간의 충돌, 로봇과 시설 간의 충돌, 작업자(U)와 시설 간의 충돌) 및 발생 시각 및 심각도(예, 충돌 강도, 손상 수준) 중 적어도 한 가지 이상을 나 타내는 것일 수 있다. 만약 임의의 하위 영역에 맵핑된 사고 가이드 정보는, 로봇에 연관된 유형에 해당하는 사 고의 발생 시각을 기준으로 과거 소정 시간에 걸친 이동 로봇(AGV)의 동작 이력(예, 속도, 이동 경로 등)을 추 가적으로 나타낼 수 있다. 아울러, 임의의 하위 영역에 맵핑된 사고 가이드 정보는, 해당 하위 영역에서 발생된 사고별 사고 원인을 더 나타낼 수 있다. 단계 S820에서, 현장 관리 서버는 사고 발생 가능 공간의 하위 영역별로 맵핑된 사고 가이드 정보를 기초 로, 하위 영역별 사고 위험도를 산출한다. 여기서, 사고 위험도는 사고 가이드 정보가 나타내는 항목별 점수의 총 합에 대응(예, 비례, 양의 상관관계 보유)할 수 있다. 예컨대, 어떤 하위 영역에서의 항목들(예, 사고 총 횟 수, 사고별 유형, 사고별 발생 시각 및 사고별 심각도)은 각각 미리 주어진 연산 로직(예, 함수 등)을 통해 점 수화될 수 있고, 모든 항목들의 점수를 합산함으로써 해당 하위 영역의 사고 위험도가 결정될 수 있다. 상기 연 산 로직은, 여러 사고 유형들 중 관리자(사람)가 사고 당사자가 되는 유형은 그렇지 않은 유형의 사고보다 높은 점수가 할당되도록 설계된 것일 수 있다. 또한, 상기 연산 로직은, 야간 등과 같이 사람의 집중력이 상대적으로 저하되거나 관리자의 수가 적어 즉각적인 안전 대처가 이루어지기 어려운 것으로 미리 정해진 시간대에 속하는 시각에 발생된 사고에 대해서는 그 외의 시각에 발생된 사고보다 높은 점수가 할당되도록 설계된 것일 수 있다. 단계 S830에서, 현장 관리 서버는 하위 영역별 사고 위험도를 기초로, 하위 영역별로 사고 방지 규칙을 할 당한다. 예컨대, 사고 위험도의 전체 범위가 3개의 구간(예, 저, 중, 고)으로 구분(등급화)된 경우, 현장 관리 서버는 '저' 구간에 해당하는 하위 영역에 대해서는 별도의 제한을 두지 않는 한편, '중' 구간에 해당하는 하위 영역에 대해서는 제1 사고 방지 규칙(예, 최고 속도 제한)을 부여하며, '상' 구간에 해당하는 하위 영역에 대해서는 제2 사고 방지 규칙(예, 위험 경고, 경로 회피, 타경로 탐색)을 부여할 수 있다. 3개 구간으로의 등급 화는 하나의 예시에 불과하며, 2개 구간 이상이면 무방하다. 단계 S840에서, 현장 관리 서버는 단계 S830에서 하위 영역별로 할당된 사고 방지 규칙을 이용하여, 이동 로봇(AGV) 및 통신 단말기(T) 중 적어도 하나를 원격 제어한다. 이를 위해, 현장 관리 서버는 각 이동 로 봇(AGV)의 현 위치가 다수의 하위 영역 중 어느 영역인지 지속 추적(식별)하고, 추가적으로 각 작업자(U)의 현 위치도 지속 추적할 수 있다. 일 예로, 현장 관리 서버는 이동 로봇(AGV)의 로그 데이터, 2D 영상 및 3D 영상 중 적어도 하나를 기초로 이동 로봇(AGV)이 '저' 구간에 해당하는 하위 영역으로부터 '중' 구간에 해당하는 하위 영역에 진입한 것으로 확인되는 경우, 제1 사고 방지 규칙에 따라 이동 로봇(AGV)의 최고 속도를 1m/s에서 0.3m/s로 하향시킬 수 있다. 다른 예로, 현장 관리 서버는 이동 로봇(AGV)의 로그 데이터, 2D 영상 및 3D 영상 중 적어도 하나를 기초 로 작업자(U)가 '저' 또는 '중' 구간에 해당하는 하위 영역으로부터 '상' 구간에 해당하는 하위 영역에 진입한 것으로 확인되는 경우, 제2 사고 방지 규칙에 따라 해당 작업자(U)의 통신 단말기(T)에 경고 메시지를 전송할 수 있다. 경고 메시지를 수신한 통신 단말기(T)는 소정 음압 이상의 알람음을 발생시킴과 동시에 현재의 하위 영역에서 '저' 구간에 해당하는 하위 영역으로 이동을 유도하기 위한 경로 안내 화면을 출력할 수 있다. 여기서, 작업자(U)가 어느 하위 영역에 위치하고 있는지는 2D 영상이나 3D 영상 대신, 해당 작업자(U)가 소지한 통신 단말기(T)의 위치 신호(예, GPS 신호)에 기초하여 파악될 수 있다.다른 예로, 현장 관리 서버는 이동 로봇(AGV)의 로그 데이터, 2D 영상 및 3D 영상 중 적어도 하나를 기초 로 이동 로봇(AGV)이 '중' 구간에 해당하는 하위 영역으로부터 '상' 구간에 해당하는 하위 영역에 진입한 것으 로 확인되는 경우, 해당 이동 로봇(AGV)의 목적지를 확인한 다음, 제2 사고 방지 규칙에 따라 현 위치로부터 목 적지까지 이동하기 위해 거칠 수 있는 여러 경로 중에서 '저' 구간, '중' 구간 또는 이 둘의 조합에 의한 최단 경로를 탐색하고, 탐색된 최단 경로로 해당 이동 로봇(AGV)이 주행하도록 원격 제어할 수 있다. 참고로, 각각의 이동 로봇(AGV)은 고유의 임무를 부여받아 산업현장 내를 주행하는 바, 이동 로봇(AGV)은 자신의 임무에 따른 목적지를 로그 데이터에 포함시켜 현장 관리 서버에 전송할 수 있다. 한편, 단계 S840에서 실행되는 이동 로봇(AGV) 및 통신 단말기(T) 중 적어도 하나를 원격 제어는, 하위 영역별 로 할당된 사고 방지 규칙에 따라 무조건적으로 실행되는 대신, 두 이동 로봇(AGV) 간, 두 작업자(U) 간 및 이 동 로봇(AGV)과 작업자(U) 간의 거리가 소정의 안전 거리 이하인 것을 조건으로 실행될 수 있다. 예컨대, 이동 로봇(AGV)이 '상' 구간에 해당하는 하위 영역에 위치하더라도, 해당 이동 로봇(AGV)에 가장 가까운 작업자(U)가 해당 이동 로봇(AGV)으로부터 상기 안전 거리 이상 이격된 위치에 있는 경우, 해당 이동 로봇(AGV)은 기본적인 규정 속도(예, 최대 1m/s)로 별도 제한없이 주행하면서 임무를 수행할 수 있다. 이때, 현장 관리 서버는 다수의 하위 영역 각각의 사고 위험도에 대응하는 안전 거리를 하위 영역별로 설 정할 수 있다. 예컨대, '상' 구간에 해당하는 하위 영역에 설정되는 안전 거리는 '중' 구간에 해당하는 하위 영 역에 설정되는 안전 거리 이상일 수 있다. 사고 위험도에 따른 구간(등급)별 안전 거리는 룩업테이블 등의 형태 로 데이터 기록부에 미리 저장되어 있을 수 있다. 통신 단말기(T)는 현장 관리 서버로부터 1 이상의 사고 이벤트에 관련된 정보를 수신하고, 수신된 정보를 그래픽 인터페이스로 표시할 수 있다. 이에 따라, 산업현장에서 현재까지 발생된 모든 사고 이벤트 중에서 작업 자나 관리자가 요청하는 특정 사고 이벤트의 사고 재현 영상이 통신 단말기(T)에 표시되어, 작업자들을 대상으 로 한 원격 안전 교육에도 활용 가능하다는 장점이 있다. 본 발명은 상술한 특정의 실시예 및 응용예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗"}
{"patent_id": "10-2023-0001514", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "어남이 없이 당해 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 구별되어 이해되어서는 안 될 것이다. 특히, 본 명세서에 첨부된 도면에 도시된 블록도와 순서도에 포함된 본 발명의 기술적 특징을 실행하는 구성들 은 상기 구성들 사이의 논리적인 경계를 의미한다. 그러나 소프트웨어나 하드웨어의 실시 예에 따르면, 도시된 구성들과 그 기능들은 독립형 소프트웨어 모듈, 모놀리식 소프트웨어 구조, 코드, 서비스 및 이들을 조합한 형 태로 실행되며, 저장된 프로그램 코드, 명령어 등을 실행할 수 있는 프로세서를 구비한 컴퓨터에서 실행 가능한 매체에 저장되어 그 기능들이 구현될 수 있으므로 이러한 모든 실시 예 역시 본 발명의 권리범위 내에 속하는 것으로 보아야 할 것이다. 따라서, 첨부된 도면과 그에 대한 기술은 본 발명의 기술적 특징을 설명하기는 하나, 이러한 기술적 특징을 구 현하기 위한 소프트웨어의 특정 배열이 분명하게 언급되지 않는 한, 단순히 추론되어서는 안 된다. 즉, 이상에 서 기술한 다양한 실시 예들이 존재할 수 있으며, 그러한 실시 예들이 본 발명과 동일한 기술적 특징을 보유하 면서 일부 변형될 수 있으므로, 이 역시 본 발명의 권리범위 내에 속하는 것으로 보아야 할 것이다. 또한, 순서도의 경우 특정한 순서로 도면에서 동작들을 묘사하고 있지만, 이는 가장 바람직한 결과를 얻기 위하 여 도시된 것으로서, 도시된 특정한 순서나 순차적인 순서대로 그러한 동작들을 반드시 실행되어야 한다거나 모 든 도시된 동작들이 반드시 실행되어야 하는 것으로 이해되어서는 안 된다. 특정한 경우, 멀티 태스킹과 병렬 프로세싱이 유리할 수 있다. 아울러, 이상에서 기술한 실시형태의 다양한 시스템 컴포넌트의 분리는 그러한 분 리를 모든 실시형태에서 요구하는 것으로 이해되어서는 안되며, 설명한 프로그램 컴포넌트와 시스템들은 일반적 으로 단일의 소프트웨어 제품으로 함께 통합되거나 다중 소프트웨어 제품에 패키징될 수 있다는 점을 이해하여 야 한다."}
{"patent_id": "10-2023-0001514", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 후술되는 발명의 상세한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사 항에만 한정되어 해석되어서는 아니 된다. 도 1은 산업현장에서의 사고 상황을 예시한다. 도 2는 본 발명의 일 실시예에 따른 산업현장 모니터링 시스템의 구성을 개략적으로 나타낸 모식도이다. 도 3은 도 1에 도시된 산업현장 모니터링 시스템이 적용되는 산업현장의 예시적인 내부 모습을 설명하는 데에 참조되는 도면이다. 도 4는 도 3에 도시된 산업현장에서 발생된 사고 상황을 3차원 형태로 재현한 영상을 예시한다. 도 5는 도 2에 도시된 현장 관리 서버의 구성을 예시적으로 나타낸 도면이다. 도 6은 본 발명의 일 실시예에 따른 현장 관리 방법을 예시적으로 설명하기 위한 순서도이다. 도 7은 본 발명의 다른 실시예에 따른 현장 관리 방법을 예시적으로 설명하기 위한 순서도이다. 도 8은 본 발명의 또 다른 실시예에 따른 현장 관리 방법을 예시적으로 설명하기 위한 순서도이다."}
