{"patent_id": "10-2023-0096850", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0015435", "출원번호": "10-2023-0096850", "발명의 명칭": "프레임 선택에 의한 인공지능 기반의 객체 동작 인식 방법 및 장치", "출원인": "주식회사 마크애니", "발명자": "권용혜"}}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능에 기반하여 객체의 동작을 인식하는 방법에 있어서,행동 인식 대상인 단위 영상을 입력받는 단계;상기 단위 영상에서 객체의 존재 유무를 검출하는 제1 검출을 수행하는 단계;상기 단위 영상에서 상기 객체의 동작을 인식하는 제2 검출을 수행하는 단계; 및상기 제2 검출의 결과를 포함하는 정보를 출력하는 단계;를 포함하되,상기 제1 검출의 결과가 부정적이면, 상기 제2 검출은 실행되지 않는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 객체는 사람 및 차량 중 적어도 하나를 포함하고,상기 객체의 동작은 상기 제2 검출을 통해 인식하고자 하는 상기 객체의 적어도 한 가지 유형의 동작을 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 제1 검출의 결과가 부정적이면, 상기 결과를 포함하는 정보를 출력하는 단계는 상기 제1 검출의 부정적 결과만을 출력하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 단위 영상에 대한 추가 처리 단계를 더 포함하고,상기 제1 검출의 결과가 부정적이면, 상기 추가 처리 단계는 실행되지 않는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 출력하는 단계에서 출력되는 정보는, 상기 입력된 단위 영상을 포함하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 출력하는 단계에서 출력되는 정보는, 영상 데이터셋을 포함하고,상기 출력하는 단계는, 상기 제1 검출 및 상기 제2 검출의 결과 중 적어도 하나를 참조하여 상기 입력된 단위공개특허 10-2025-0015435-3-영상을 데이터셋에 포함할지를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 데이터셋은, 객체 동작 인식 인공지능의 학습을 위한 학습 데이터셋인 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 데이터셋은, 상기 제2 검출을 위해 사용되는 객체 동작 인식 인공지능의 재학습에 사용되는 것을 특징으로하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 제1 검출은, 상기 단위 영상에서 적어도 하나의 객체에 대한 경계상자(bounding box)를 검출하는 단계를포함하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 객체는 사람을 포함하고,상기 제1 검출은, 상기 단위 영상에서 적어도 하나의 객체에 대해 두부(頭部)의 존재를 검출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서,상기 객체는 사람을 포함하고,상기 제2 검출은, 상기 단위 영상에서 적어도 하나의 객체에 대해 인체 자세 정보를 생성하는 단계를 포함하는,방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 제2 검출은, 상기 단위 영상에 기초하여 적어도 하나의 인체 관절 정보를 생성하고, 상기 단위 영상에 기초하여 적어도 하나의 관절 방향성 정보를 생성하고, 상기 적어도 하나의 인체 관절 정보와 상기 적어도 하나의관절 방향성 정보를 결합하여 상기 인체 자세 정보를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,공개특허 10-2025-0015435-4-상기 제2 검출은, 상기 단위 영상에 기초하여 시간적으로 연속된 적어도 하나의 상기 인체 자세 정보를 생성하고, 상기 적어도 하나의 인체 자세 정보에 기초하여 적어도 하나의 행동 특징값을 획득하고, 적어도 하나의 상기 행동 특징값에 기초하여 적어도 하나의 상기 객체 동작을 검출하고, 상기 객체 동작에 관련된 정보를 출력하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 1 항에 있어서,상기 제1 검출에는 기계 학습, 인공 신경망, 장단기기억(long-short term memory; LSTM), 및 변환기(transformer)중 적어도 하나를 포함하는 인공지능에 기반한 검출 단계가 포함되지 아니하고,상기 제2 검출에는 기계 학습, 인공 신경망, 장단기기억, 및 변환기 중 적어도 하나를 포함하는 인공지능에 기반한 검출 단계가 포함되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 1 항에 있어서,상기 제2 검출은, 상기 제1 검출의 결과를 참조하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 1 항에 있어서,상기 제2 검출은 상기 제1 검출보다 높은 복잡도를 가지는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "인공지능에 기반하여 단위 영상을 처리하여 객체의 동작을 인식하는 장치에 있어서,프로세서;메모리;단위 영상을 입력받는 입력부;상기 단위 영상에서 객체의 존재 유무를 검출하는 제1 검출부;상기 단위 영상에서 상기 객체의 동작을 인식하는 제2 검출부; 및상기 제2 검출의 결과를 포함하는 정보를 출력하는 출력부;를 포함하되,상기 제1 검출부의 출력이 부정적이면, 상기 제2 검출부는 동작하지 않도록 구성되는, 장치."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 객체는 사람 및 차량 중 적어도 하나를 포함하고,상기 객체의 동작은 상기 제2 검출부를 통해 인식하고자 하는 상기 객체의 적어도 한 가지 유형의 동작을 포함하는 것을 특징으로 하는, 방법.공개특허 10-2025-0015435-5-청구항 19 제 17 항에 있어서,상기 단위 영상에 대한 추가적 정보처리를 수행하는 부가처리부를 더 포함하고,상기 제1 검출의 결과가 부정적이면, 상기 부가처리부는 동작하지 않도록 구성되는, 장치."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 17 항에 있어서,상기 출력부에서 출력되는 정보는, 영상 데이터셋을 포함하고,상기 출력부는, 상기 제1 검출부 및 상기 제2 검출부의 동작 중 적어도 하나를 참조하여 상기 입력된 단위 영상을 데이터셋에 포함할지를 결정하도록 구성되는, 장치."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 17 항에 있어서,기계 학습, 인공 신경망, 장단기기억(long-short term memory; LSTM), 및 변환기(transformer) 중 적어도 하나를 포함하는 인공지능 검출부를 더 포함하고,상기 인공지능 검출부는, 상기 제1 검출부에는 연결되지 않고, 상기 제2 검출부에만 연결되는 것을 특징으로 하는, 장치."}
{"patent_id": "10-2023-0096850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 17 항에 있어서,상기 제2 검출부의 동작은 상기 제1 검출부의 동작보다 높은 복잡도를 가지는 것을 특징으로 하는, 장치."}
{"patent_id": "10-2023-0096850", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 영상에서의 객체 동작 인식에 관한 것으로, 보다 구체적으로는 객체 동작 인식 방 법의 처리 효율을 강화하는 데 대한 것이다. 본 발명의 일 실시예에 따른 인공지능에 기반하여 객체의 동작을 인 식하는 방법은, 행동 인식 대상인 단위 영상을 입력받는 단계, 상기 단위 영상에서 객체의 존재 유무를 검출하는 제1 검출을 수행하는 단계, 상기 단위 영상에서 상기 객체의 동작을 인식하는 제2 검출을 수행하는 단계, 및 상 기 제2 검출의 결과를 포함하는 정보를 출력하는 단계를 포함하되, 상기 제1 검출의 결과가 부정적이면, 상기 제 2 검출은 실행되지 않는 것을 특징으로 할 수 있다."}
{"patent_id": "10-2023-0096850", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 영상에서의 객체 동작 인식에 관한 것으로, 보다 구체적으로는 객체 동작 인식 방 법의 처리 효율을 강화하는 데 대한 것이다."}
{"patent_id": "10-2023-0096850", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(artificial intelligence; AI) 및 기계 학습(machine learning; ML) 기술이 종래에 다양한 분야에서 활용되고 있다. 인공지능은 인공적인 지능 또는 이를 만들 수 있는 방법론을 포괄적으로 칭할 수 있으며, 기계 학습은 인공지능 분야에서 다루는 다양한 문제를 정의하고 컴퓨터 등의 기계로 하여금 그것을 해결하도록 구성 하는 방법론을 포괄적으로 칭할 수 있다. 특히, 기계 학습은 소정의 작업에 대한 반복적 해결 경험을 인공지능 구조가 구현된 기계에 제공하여 상기 기계의 성능을 향상시키는 방법론을 의미할 수 있다. 또한, 인공지능이나 기계 학습 기술의 구현을 위하여, 사람의 뇌 신경망 구조를 모사하여 구성되는 인공 신경망 (artificial neural network)을 활용하는 기술이 종래에 활용되고 있다. 상기 인공 신경망은 여러 계층에 의하 여 복합적으로 구성될 수 있으며, 입력을 수용하는 입력층, 상호 연결 구조를 실현하는 은닉층, 그리고 판단 결 과를 도출하는 출력층으로 구분될 수 있다. 이러한 인공 신경망은 다양한 파생 형태로 구현될 수 있으며, 예를 들어, 합성곱(convolution) 기반의 신경망은 합성곱 신경망(convolutional neural network; CNN)으로 칭할 수 있다. 또한 복수의 은닉층을 포함하는 인공 신경망을 사용하는 경우를 심층 신경망(deep neural network; DNN)으로 칭할 수 있으며, 상기 DNN에 기반하여 구현되는 기계 학습을 딥 러닝(심층 학습; deep learning)이라 부르 기도 한다. 상기 딥 러닝을 포함하는 기계 학습의 방법론 가운데 지도 학습(supervised learning)이라는 개념이 존재한다. 지도학습이란, 인공지능으로 하여금 정답이 레이블(label)로서 표시되어 있는 대량의 데이터를 처리함으로써 그 인공 신경망을 재구축하도록 하는 기계 학습 방법론을 의미할 수 있다. 즉, 인공지능 기계에 문제에 대응하는 정답을 '지도'함으로써 학습시키는 방법을 의미할 수 있다. 이렇게 기계 학습된 인공지능은 정답을 알 수 없는 데이터로부터 상기 정답에 근접하는 결과를 역산하도록 구성될 수 있다. 이러한 지도 학습을 위하여서는 문제와 정답 쌍으로 구성된, 즉 원자료(raw data)와 그에 상응하는 레이블이 표 기된 대량의 데이터가 요구된다. 상기와 같이 기계학습에 있어서의 지도 학습에 사용되는 데이터의 집합을 학습 데이터 셋(set), 또는 기계 학습 데이터 셋이라고 칭할 수 있다. 최근 상기 인공지능 및 기계 학습 방법에 의하여 영상 및 화상으로부터 특정한 객체의 동작을 인식하는 기술이 개발되어 오고 있다. 특히 동영상으로부터 사람의 존재를 인식하고, 그 사람이 행동을 취하고 있는지의 여부를 인식하고, 나아가 그 행동의 종류를 인식하는 영상 인식 모델(video recognition model)에 기반한 기술들이 제 공되어져 오고 있다. 이러한 기술들은 종래에 컴퓨터 비전(computer vision) 기술로써 널리 알려져 온 것들이나, 인공지능 및 기계 학습 방법과 결합됨으로써 대량의 데이터에 대하여 높은 정확도로 인식이 이루어질 수 있도록 하는 기술들이 새로이 출현하고 있다."}
{"patent_id": "10-2023-0096850", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "종래에 영상 인식 모델을 운용하는 데 있어서는 다음과 같은 기술적 한계사항들이 존재하였다. 첫째로, 그 학습 데이터 셋의 준비에 곤란함이 있었다. 영상 인식 모델은 기계 학습에 의하여 영상의 행동을 판 별하는 능력을 획득하게 되는데, 상기 기계 학습을 위한 학습 데이터 셋의 규모가 방대할 필요가 있으나, 이를 준비하는 데 곤란함이 있는 것이다. 더욱이, 상기 학습 데이터 셋은 인간의 행동을 인식하도록 인공지능을 기계 학습시키는 데 도움이 되는 자료로 만 구성되는 것이 학습에 바람직하나, 실제로는 영상 내에 사람이 없거나 또는 사람 외의 다른 객체(예를 들어, 차량, 사물, 동물과 같은 것)의 동작이 포함되어 있는 경우의 데이터 또한 혼입되어 입력되고 있는 바, 잘못된 샘플로부터 잘못된 인식 절차를 학습할 우려가 상존하고 있다. 물론, 만약 영상 인식 모델이 인간이 아닌 차량, 사물, 동물 등 다른 객체의 동작을 인식하도록 마련되는 경우 에는, 인간이 포함되는 데이터가 상기 잘못된 데이터로 간주될 수 있음은 자명하다. 둘째로, 그 복잡도에 곤란함이 있었다. 영상 인식 모델이 동작히기 위하여서는 인공지능을 운용한 상당량의 연 산 자원 소모가 요구된다. 그런데 어떤 영상에 사람의 행동이 존재하는지의 여부를 사전에 알 수 없는 이상, 이 러한 연산 자원의 소모는 영상을 구성하는 모든 단위 시간당 화상, 즉 프레임에 대해 이루어지게 되고, 높은 연 산 복잡도를 발생시킬 수 있다."}
{"patent_id": "10-2023-0096850", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 인공지능에 기반하여 객체의 동작을 인식하는 방법은, 행동 인식 대상인 단위 영상을 입력받는 단계, 상기 단위 영상에서 객체의 존재 유무를 검출하는 제1 검출을 수행하는 단계, 상기 단위 영상에서 상기 객체의 동작을 인식하는 제2 검출을 수행하는 단계, 및 상기 제2 검출의 결과를 포함하는 정보를 출력하는 단계를 포함하되, 상기 제1 검출의 결과가 부정적이면, 상기 제2 검출은 실행되지 않는 것을 특징으로 할 수 있다. 상기 방법은, 상기 객체는 사람 및 차량 중 적어도 하나를 포함하고, 상기 객체의 동작은 상기 제2 검출을 통해 인식하고자 하는 상기 객체의 적어도 한 가지 유형의 동작을 포함하는 것을 특징으로 할 수 있다. 상기 방법은, 상기 제1 검출의 결과가 부정적이면, 상기 결과를 포함하는 정보를 출력하는 단계는 상기 제1 검 출의 부정적 결과만을 출력할 수 있다. 상기 방법은, 상기 단위 영상에 대한 추가 처리 단계를 더 포함하고, 상기 제1 검출의 결과가 부정적이면, 상기 추가 처리 단계는 실행되지 않을 수 있다. 상기 출력하는 단계에서 출력되는 정보는, 상기 입력된 단위 영상을 포함할 수 있다. 상기 출력하는 단계에서 출력되는 정보는, 영상 데이터셋을 포함하고, 상기 출력하는 단계는, 상기 제1 검출 및 상기 제2 검출의 결과 중 적어도 하나를 참조하여 상기 입력된 단위 영상을 데이터셋에 포함할지를 결정하는 단 계를 포함할 수 있다. 상기 데이터셋은, 객체 동작 인식 인공지능의 학습을 위한 학습 데이터셋인 것을 특징으로 할 수 있다. 상기 데이터셋은, 상기 제2 검출을 위해 사용되는 객체 동작 인식 인공지능의 재학습에 사용되는 것을 특징으로 할 수 있다. 상기 제1 검출은, 상기 단위 영상에서 적어도 하나의 객체에 대한 경계상자(bounding box)를 검출하는 단계를 포함할 수 있다. 상기 방법은, 상기 객체는 사람을 포함하고, 상기 제1 검출은, 상기 단위 영상에서 적어도 하나의 객체에 대해 두부(頭部)의 존재를 검출하는 단계를 포함할 수 있다. 상기 방법은, 상기 객체는 사람을 포함하고, 상기 제2 검출은, 상기 단위 영상에서 적어도 하나의 객체에 대해 인체 자세 정보를 생성하는 단계를 포함할 수 있다. 상기 제2 검출은, 상기 단위 영상에 기초하여 적어도 하나의 인체 관절 정보를 생성하고, 상기 단위 영상에 기 초하여 적어도 하나의 관절 방향성 정보를 생성하고, 상기 적어도 하나의 인체 관절 정보와 상기 적어도 하나의 관절 방향성 정보를 결합하여 상기 인체 자세 정보를 생성하는 단계를 포함할 수 있다. 상기 제2 검출은, 상기 단위 영상에 기초하여 시간적으로 연속된 적어도 하나의 상기 인체 자세 정보를 생성하 고, 상기 적어도 하나의 인체 자세 정보에 기초하여 적어도 하나의 행동 특징값을 획득하고, 적어도 하나의 상 기 행동 특징값에 기초하여 적어도 하나의 상기 객체 동작을 검출하고, 상기 객체 동작에 관련된 정보를 출력하 는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 검출에는 기계 학습, 인공 신경망, 장단기기억(long-short term memory, LSTM), 및 변 환기(transformer) 중 적어도 하나를 포함하는 인공지능에 기반한 검출 단계가 포함되지 아니하고, 상기 제2 검 출에는 기계 학습, 인공 신경망, 장단기기억, 및 변환기 중 적어도 하나를 포함하는 인공지능에 기반한 검출 단 계가 포함되는 것을 특징으로 할 수 있다. 상기 제2 검출은, 상기 제1 검출의 결과를 참조하는 단계를 포함할 수 있다. 상기 제2 검출은 상기 제1 검출보다 높은 복잡도를 가지는 것을 특징으로 할 수 있다. 상술한 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 인공지능에 기반하여 단위 영상을 처리하여 객체의 동작을 인식하는 장치는, 프로세서, 메모리, 단위 영상을 입력받는 입력부, 상기 단위 영상에서 객체의 존재 유무를 검출하는 제1 검출부, 상기 단위 영상에서 상기 객체의 동작을 인식하는 제2 검출부, 및 상기 제2 검출의 결과를 포함하는 정보를 출력하는 출력부를 포함하되, 상기 제1 검출부의 출력이 부정적이면, 상기 제2 검출부는 동작하지 않도록 구성될 수 있다. 상기 장은, 상기 객체는 사람을 포함하고, 상기 객체의 동작은 상기 제2 검출부를 통해 인식하고자 하는 적어도 한 가지 유형의 사람 행동을 포함하는 것을 특징으로 할 수 있다. 상기 장치는, 상기 단위 영상에 대한 추가적 정보처리를 수행하는 부가처리부를 더 포함하고, 상기 제1 검출의 결과가 부정적이면, 상기 부가처리부는 동작하지 않도록 구성될 수 있다. 상기 출력부에서 출력되는 정보는, 영상 데이터셋을 포함하고, 상기 출력부는, 상기 제1 검출부 및 상기 제2 검 출부의 동작 중 적어도 하나를 참조하여 상기 입력된 단위 영상을 데이터셋에 포함할지를 결정하도록 구성될 수 있다. 상기 장치는, 기계 학습, 인공 신경망, 장단기기억(long-short term memory, LSTM), 및 변환기(transformer) 중 적어도 하나를 포함하는 인공지능 검출부를 더 포함하고, 상기 인공지능 검출부는, 상기 제1 검출부에는 연 결되지 않고, 상기 제2 검출부에만 연결되는 것을 특징으로 할 수 있다. 상기 제2 검출부의 동작은 상기 제1 검출부의 동작보다 높은 복잡도를 가지는 것을 특징으로 할 수 있다."}
{"patent_id": "10-2023-0096850", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 상술한 해결 수단에 의하여 상술하였던 종래기술의 한계를 극복한다. 첫째로, 학습 데이터 셋의 준비 에 있어서 사람이 포함되지 않은 영상 데이터를 제거하도록 함으로써 영상 인식 모델의 기계 학습이 더욱 원활 하게 동작하도록 한다. 또한 영상 인식 모델이 실제 동작할 때에 있어서는, 사람의 존재 여부만을 인식하는 상 대적으로 단순한 알고리즘에 의하여 먼저 판단을 진행함으로써, 모든 프레임에 일률적으로 가해지던 복잡도 부 담이 해소되도록 한다."}
{"patent_id": "10-2023-0096850", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제 1, 제 2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 명명될 수 있다. \"및/또는\"이라는 용어는 복수의 관련된 기재된 항 목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함하며, 또한, 달리 지시되지 않는 한 비배 타적이다. 본 출원에 항목을 열거하는 경우 그것은 본 출원 발명의 사상과 가능한 실시 방법들을 용이하게 설명 하기 위한 예시적 서술에 그치며, 따라서, 본 발명의 실시예 범위를 한정하는 의도를 가지지 아니한다. 본 명세서에서 \"A 또는 B(A or B)\"는 \"오직 A\", \"오직 B\" 또는 \"A와 B 모두\"를 의미할 수 있다. 달리 표현하면, 본 명세서에서 \"A 또는 B(A or B)\"는 \"A 및/또는 B(A and/or B)\"으로 해석될 수 있다. 예를 들어, 본 명세서에 서 \"A, B 또는 C(A, B or C)\"는 \"오직 A\", \"오직 B\", \"오직 C\", 또는 \"A, B 및 C의 임의의 모든 조합(any combination of A, B and C)\"를 의미할 수 있다. 본 명세서에서 사용되는 슬래쉬(/)나 쉼표(comma)는 \"및/또는(and/or)\"을 의미할 수 있다. 예를 들어, \"A/B\"는 \"A 및/또는 B\"를 의미할 수 있다. 이에 따라 \"A/B\"는 \"오직 A\", \"오직 B\", 또는 \"A와 B 모두\"를 의미할 수 있다. 예를 들어, \"A, B, C\"는 \"A, B 또는 C\"를 의미할 수 있다. 본 명세서에서 \"적어도 하나의 A 및 B(at least one of A and B)\"는, \"오직 A\", \"오직 B\" 또는 \"A와 B 모두\"를 의미할 수 있다. 또한, 본 명세서에서 \"적어도 하나의 A 또는 B(at least one of A or B)\"나 \"적어도 하나의 A 및/또는 B(at least one of A and/or B)\"라는 표현은 \"적어도 하나의 A 및 B(at least one of A and B)\"와 동 일하게 해석될 수 있다. 또한, 본 명세서에서 \"적어도 하나의 A, B 및 C(at least one of A, B and C)\"는, \"오직 A\", \"오직 B\", \"오직 C\", 또는 \"A, B 및 C의 임의의 모든 조합(any combination of A, B and C)\"를 의미할 수 있다. 또한, \"적어도 하나의 A, B 또는 C(at least one of A, B or C)\"나 \"적어도 하나의 A, B 및/또는 C(at least one of A, B and/or C)\"는 \"적어도 하나의 A, B 및 C(at least one of A, B and C)\"를 의미할 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 이용하고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 출원에서 발명을 설명함에 있어, 실시예들은 설명된 기능 또는 기능들을 수행하는 단위 블록들의 측면에서 설명되거나 예시될 수 있다. 상기 블록들이란 본 출원에서 하나 또는 복수의 장치, 유닛, 모듈, 부 등으로 표현 될 수 있다. 상기 블록들은 하나 또는 복수의 논리 게이트, 집적 회로, 프로세서, 컨트롤러, 메모리, 전자 부품 또는 이에 한정되지 않는 정보처리 하드웨어의 구현 방법에 의하여 하드웨어적으로 실시될 수도 있다. 또는, 상 기 블록들은 응용 소프트웨어, 운영 체제 소프트웨어, 펌웨어, 또는 이에 한정되지 않는 정보처리 소프트웨어의 구현 방법에 의하여 소프트웨어적으로 실시될 수도 있다. 하나의 블록은 동일한 기능을 수행하는 복수의 블록들 로 분리되어 실시될 수도 있으며, 반대로 복수의 블록들의 기능을 동시에 수행하기 위한 하나의 블록이 실시될 수도 있다. 상기 블록들은 또한 임의의 기준에 의하여 물리적으로 분리되거나 결합되어 실시될 수 있다. 상기 블록들은 통신 네트워크, 인터넷, 클라우드 서비스, 또는 이에 한정되지 않는 통신 방법에 의해 물리적 위치가 특정되지 않고 서로 이격되어 있는 환경에서 동작하도록 실시될 수도 있다. 상기의 모든 실시 방법은 동일한 기 술적 사상을 구현하기 위하여 정보통신 기술 분야에 익숙한 통상의 기술자가 취할 수 있는 다양한 실시예의 영 역이므로, 여하의 상세한 구현 방법은 모두 본 출원상 발명의 기술적 사상 영역에 포함되는 것으로 해석되어야 한다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 또한 복수의 실시예들은 서로 배타적이 아니며, 일부 실시예들이 새로운 실시예들을 형성하기 위해 하나 이상의 다른 실시예들과 조합될 수 있음을 전제로 한다. 본 발명은 상술한 해결 수단에 의하여 상술하였던 종래기술의 한계를 극복한다. 첫째로, 학습 데이터 셋의 준비 에 있어서 사람이 포함되지 않은 영상 데이터를 제거하도록 함으로써 영상 인식 모델의 기계 학습이 더욱 원활 하게 동작하도록 한다. 또한 영상 인식 모델이 실제 동작할 때에 있어서는, 사람의 존재 여부만을 인식하는 상 대적으로 단순한 알고리즘에 의하여 먼저 판단을 진행함으로써, 모든 프레임에 일률적으로 가해지던 복잡도 부 담이 해소되도록 한다. 상기와 같은 기능의 동작을 위하여, 본 발명에서는 입력되는 영상으로부터 필요한 프레 임만을 선택하여 처리 및 판단을 수행하는 구조를 제공한다. 도 1은 본 발명의 일 실시예에 따른 영상 프레임의 선택에 대한 개념도이다. 어떤 영상 처리 시스템을 위하여서 는, 그 특성이 구분되지 않는 동영상이 제공될 수 있다. 상기 동영상은 실시간으로 제공되거나 또는 저장되어 있는 기록 매체로부터 인출(load)될 수 있는 것으로, 그 공급 및/또는 입력 방식은 어떠한 형태로 구 현되더라도 무방하다.상기 동영상은 디지털 영상 인코딩 규격에 따라 생성된 디지털 영상 데이터일 수 있다. 상기 디지털 영상 인코딩 규격은 MPEG-2, MPEG-4 Video, H.263, H.264/AVC, H.265/HEVC, H.266/VVC, VC-1, AV1, QuickTime, VP- 9, VP-10, Motion JPEG과 같은 규격명으로 알려진 인코딩 규격 중 적어도 하나를 포함할 수 있다. 물론, 상기 열거된 예시 이외에 영상 인코딩에 사용할 수 있는 어떠한 다른 규격이 사용되더라도 본 발명을 동일하게 실시 할 수 있음은 당업자에게는 쉽게 알 수 있는 사실일 것이다. 상기 동영상은 적어도 하나의 프레임(111~115)으로 구성되어 있을 수 있다. 상기 동영상의 각 프레임 (111~115)에는 사물이나 적어도 하나의 사람(142, 145)과 같은 대상이 촬영되어 있을 수 있다. 그리고, 상 기 사람(142, 145)은 개별적으로 또는 상호 작용에 의하여 특정한 행동을 취하는 상황이 발생할 수 있으며, 이러한 행동은 상기 동영상을 구성하는 적어도 하나의 프레임(예를 들어, 프레임)에 촬 영되어 있을 수 있다. 상술하였던 바와 같이, 상기 동영상으로부터 상기 행동을 인식하는 것은 통상적으로 알려진 인공지능 및 기계 학습에 의한 처리 방법으로 수행될 수 있다. 본 발명의 제1 실시예에 있어서, 본 발명은 상기 동영상을 판단 대상으로 하여 상기 동영상으로부터 상기 행동을 인식하고자 하는 방법 및/또는 장치의 일부로서 적용될 수 있는 것이다. 이러한 경우, 상기 인공지능 및 기계 학습에 의한 처리 방법은 많은 연산 자원을 요구하게 된다. 따라서, 상기 인공지능에 의한 처 리 방법을 적용하기에 앞서, 그러한 처리가 적용될 필요가 있는 프레임 구간, 즉 예를 들어, 상기 행동을 취할 가능성이 있는 사람(142, 145)이 촬영되어 있는 프레임들(가령, 112~114)로 이루어진 대상 구간만을 상기 처리 방법의 수행 대상으로 할 수 있다. 본 발명의 제2 실시예에 있어서, 본 발명은 상기 동영상을 학습 데이터 셋으로 하여 상기 동영상에 촬영된 상기 행동을 이용하여 상기 처리 방법을 수행하기 위한 인공지능을 기계 학습시키는 방법 및/또는 장치의 일부로서 적용될 수 있는 것이다. 이러한 경우, 상기 인공지능에 학습되는 상기 동영상에서 상기 행동의 식별과 무관한 프레임(가령, 프레임(111, 115))은 상기 기계 학습의 입력으로서 주어질 필요가 없 다고 간주될 수 있다. 따라서, 학습의 필요가 있는 프레임, 즉 예를 들어, 상기 행동을 취할 가능성이 있 는 사람(142, 145)이 촬영되어 있는 프레임들(가령, 112~114)로 이루어진 대상 구간만을 상기 기계 학습의 수행 대상으로 할 수 있다. 상기 두 실시예는 모두 주어진 전체 동영상으로부터 상기 행동의 검출 가능성이 있는 대상 구간(13 0)을 용이하게 추출할 수 있게 한다는 기술적 과제를 공유한다. 따라서 본 발명에서는 상기 행동의 검출 절차를 제1 검출 단계와 제2 검출 단계로 분리함으로써, 이러한 효율성을 달성하고자 한다. 이하의 설명에서는, 인식을 실행하는 실시예인 제1 실시예를 기준으로 먼저 본 발명의 동작 원리를 설명한다. 도 2는 본 발명의 일 실시예에 따른 제1 검출 및 제2 검출의 개념도이다. 본 발명의 일 실시예에 따르면, 상술 한 실시예들과 같이 인공지능에 기반하여 객체의 동작을 인식하고자 하는 과정에 있어서, 상기 동영상은 프레임 단위로 입력될 수 있다. 상기 프레임은 그 밖의 다른 영상 분할 단위이더라도 무방하므로, 예를 들어, 하나의 그룹 오브 픽처(group of picture; GOP) 구간이거나, 그보다 더 길거나 짧은 프레임의 집합이거나, 또는 서브- 픽처(sub-picture) 단위를 구성하는 슬라이스, 네트워크 축약 유닛(network abstraction unit), 블록(block), 부호화 단위(coding unit)와 같은 다양한 분할 단위일 수 있다. 따라서, 이를 단위 영상 부분이라는 일반적 개 념으로 칭할 수도 있으나, 설명의 편의를 위해 프레임으로 호칭한다. 도 2를 참조하면, 상기 행동이 검출될 수 있는 프레임은 제1 검출을 통해 사람의 존재가 식별된 프레임으로 확인되고, 상기 프레임은 제2 검출의 대상이 되어 사람의 행동이 구체적으로 식별된 프레임으로서 처리될 수 있다. 반면, 상기 행동이 검출될 가능성이 낮은 프레임의 경우, 제1 검출을 통해 사람의 존재가 식별되지 않는 것이 확인된 프레임로 구분되고, 결과적으로 제2 검 출로 이행되지 않는 프레임이 될 수 있다. 이하 도 3의 순서도를 함께 참조하여 설명한다. 도 3은 본 발명의 일 실시예에 따른 제1 검출과 제2 검출의 수 행 과정에 대한 순서도이다. 도 2의 상단 예시에 있어서, 상기 행동이 검출될 수 있는 프레임이 입력(S310)될 수 있다. 다음으로, 상기 프레임으로부터 행동을 검출하기 위한 본격적인 단계가 수행되기에 앞서, 본 발명에서는 보다 단순한 처리 단계인 제1 검출을 수행(220, S320)하도록 구성될 수 있다.상기 제1 검출(220, S320)은, 일 실시예에 따르면, 상기 프레임에서 사람의 존재 유무를 검출하는 상대적으로 단순한 알고리즘에 의한 검출 방법을 의미할 수 있다. 예를 들어, 일 실시예에서, 상기 제1 검출(220, S320)은, 상기 프레임에서 적어도 하나의 사람에 대한 경계상자(bounding box)를 검출하는 검출 방법을 의미할 수 있다. (상기 경계상자에 기반한 검출의 예가 도 2에 도시되어 있다.) 이러한 경계 상자의 판별은 사람의 행동을 구체적으로 인식하는 것에 비하여 단순하게 이루어질 수 있다. 또는, 본 발명의 다른 일 실시예에서, 상기 제1 검출(220, S320)은, 상기 단위 영상에서 적어도 하나의 사람에 대해 두부(頭部)의 존재를 검출하는 검출 방법을 의미할 수 있다. 이처럼 사람의 머리 부분을 판별하는 것 역시, 사람의 행동을 구체적으로 인식하는 것에 비하 여 단순하게 이루어질 수 있는 것이다. 상기 제1 검출이 수행된 프레임에서 상기 사람의 존재가 검출되는지를 판단(S330)할 수 있다. 사람이 검출된 경우, 상기 프레임을 선택하여 제2 검출(230, S340)의 대상으로 할 수 있다. 상기 제2 검출(230, S340)은 본래 수행하고자 하였던 행동의 검출 과정을 의미할 수 있다. 상기 제2 검출(230, S340)은, 본 발명의 일 실시예에 따르면, 상기 프레임에서 적어도 하나의 객체에 대해 인체 자세 정보를 생성하여 수행되는 것일 수 있다. 이하 도 4를 더 함께 참조하여 설명한다. 도 4는 본 발명의 일 실시예에 따른 제2 검출의 과정에 대한 개념도이다. 도 4를 참조하면, 상기 제2 검출(230, S340)은 입력으로 주어진 프레임에 활영된 적어도 하나의 사람(415, 416)과 그 행동을 인식하도록 구성된 방법일 수 있다. 상기 프레임은 기계 학습된 인공지능 모델에 투입되고, 그 결과로 상기 화상에서 적어도 하나의 인체의 관 절이 위치할 가능성을 나타내는 히트 맵(heat map)이 생성될 수 있다. 상기 히트 맵은 상기 사람 의 화상에서 인체의 관절이 존재할 가능성이 높은 영역에 높은 값이 부여된 등고선의 형태로 해석될 수 있다. 상기 히트 맵을 기초로, 상기 화상에 나타난 적어도 하나의 인체 관절부 위치를 결정하여 관절부 위치 정보을 획득할 수 있다. 상기 관절부 위치 정보는 다시 상기 기계 학습된 인공지능 모델에 투입되고, 그 결과로 상기 관절부가 가 질 가능성이 높은 골격 방향성 정보를 획득할 수 있다. 상기 골격 방향성 정보란, 상기 관절부 간에 어떠한 골격(bone)이 존재하는지를 추정하기 위해 각 관절이 어느 방향의 골격에 연관되는지에 대한 정보 일 수 있다. 상기 골격을 각각의 관절부에 대하여 추정함으로써, 인체의 골격 정보가 획득되면, 상기 관절 부 위치 정보와 결합하여 하나의 사람 형상을 식별할 수 있도록 연결된 골격을 획득할 수 있다. 상기 연결된 골격은 결과적으로 하나의 인체로서 식별되어 인체 자세 정보로 저장될 수 있다. 상기 인체 자세 정보에서, 상기 인체에 속하는 각각의 관절부는 상기 인체를 구성하는 적합한 관절부 의 명칭, 이를테면 얼굴, 목, 가슴, 오른쪽 어깨, 오른쪽 팔꿈치, 오른쪽 손목, 왼쪽 어깨, 왼쪽 팔꿈치, 왼쪽 손목, 등, 허리, 배, 척추, 상기 인체에서 골반 중앙, 엉덩이, 오른쪽 골반, 오른쪽 무릎, 오른쪽 발목, 왼쪽 골반, 왼쪽 무릎, 및 왼쪽 발목을 포함하는 관절부 명칭으로 지칭되거나, 또는 이에 상응하는 식별부호 등으로 지칭되는 정보로 저장될 수 있다. 또한, 상기 인체에 속하는 각각의 관절부는 상기 프레임에 있어서 가지는 평면적 위치, 예를 들면 화상의 정보 기준점으로부터의 x-픽셀 거리와 y-픽셀 거리와 같은 정보에 의하 여 그 위치가 확정될 수 있고, 상기 확정된 위치 정보가 저장될 수 있다. 상기 프레임에 만약 복수의 인체가 촬영된 경우라 하여도, 상술한 과정의 전부 또는 일부를 직렬적 또는 병렬적으로 반복함으로써 복수의 인체를 식별할 수 있고, 따라서 상기 인체 자세 정보는 상기 복수의 인체 각각에 대해서도 상술한 것과 같이 관절부를 지칭하는 정보 및 위치를 확정하는 정보를 포함 할 수 있다. 본 발명의 일 실시예에 따르면, 상기 원본 화상은 상술한 절차를 실시하기에 앞서 사전 가공하여 특징값을 생성하는 과정에 투입될 수 있다. 상기 특징값은, 본 발명의 실시예에 따라서는, 상기 기계 학습 인공지능이 학 습하기 용이하고 또한 입력 값으로 처리하기 용이한 형태로 변형된 상기 화상일 수 있다. 상기 제2 검출(230, S340)은 상기 획득된 인체 자세 정보로부터 해당 자세가 추출된 사람이 어떠한 구체적 행동 을 취하고 있는지를 분석하도록 구성될 수 있으며, 특히 상기 사람에 의하여 소정의 행동이 실행되고 있는지를 구분 및 판단하기 위한 기능을 보유하도록 구성될 수 있다. 상기 인체 자세 정보로부터 행동에 관련된 정보를 판단하는 기능은 종래의 또는 새로이 개발될 다양한 알고리즘에 의하여 실현될 수 있으며, 본 발명의 일 실시예 에 따르면, 일정 시간 구간 동안의 인체 자세 정보를 누적 처리함으로써 상기 일정 시간 구간 내에서의 사람 행 동 발생의 여부를 판단하는 방식일 수 있다.상기 제2 검출(230, S340)은, 시간적으로 연속된 적어도 하나의 상기 인체 자세 정보를 입력받아 처리하는 과정 으로 구성될 수 있다. 시간적으로 연속된 자세 정보는 인체의 자세 변화 과정에 대한 정보를 포함함으로써 인체 의 행동을 감지하는 데 있어 중요한 요소로 작용한다. 하나의 영상 프레임으로부터 유래한 하나의 인체 자세 정 보에 기준하여 판단하더라도 본 발명의 사상 구현에 문제는 없으나, 단일 프레임에서 나타나는 큰 동작의 종류 를 정밀하게 추적하기 위하여 일정 시간 동안의 행동에 따른 자세의 변화 과정을 분석하는 것이 더욱 유용한 효 과를 가진다. 본 발명의 일 실시예에 따르면, 상기 제2 검출(230, S340)은, 상기 시간적으로 연속된 자세 정보를 통합적으로 분석하기 위하여 합성곱 기반의 장단기기억(convolutional long short-term memory, ConvLSTM)으로 구현되는 기계 학습 인공지능에 의하여 실행될 수 있다. 이하 도 5a를 더 참조하여 설명한다. 도 5a는 본 발명의 일 실시예에 따른 합성곱 기반의 장단기기억(ConvLST M)에 의하여 시간적으로 연속된 자세 정보를 분석하는 과정의 개념도이다. 상술한 바와 같이, 입력된 영상 프레 임으로부터 상술한 절차에 의하여 인체 자세 정보를 획득할 수 있다. 상기 인체 자세 정보는 하 나의 ConvLSTM 처리 단계에 입력될 수 있다. 그리고, 상기 ConvLSTM 처리 단계는 일정 시간 동안 제 공되는 인체 자세 정보를 수용하도록 구성될 수 있다. ConvLSTM에 의한 분석이 이루어지기 위한 영상 프레임의 시퀀스 길이(sequence length)는 본 발명을 실시하는 자에 따라 임의로 지정될 수 있다. 상기 시퀀스 길이 를 N이라 하면, N개의 영상 프레임으로부터 획득한 N개의 인체 자세 정보가 N개의 ConvLSTM 처 리 단계에 순차적으로 입력될 수 있다. 상기 시퀀스 길이만큼 누적 반복하여 처리된 ConvLSTM 처리 결과가 상기 시퀀스 길이 동안 제공된 영상 프 레임으로부터 획득된 인체 행동에 대한 특징값을 포함하고 있다고 볼 수 있다. 상기 특징값으로부터 행동 의 여부 및 행동의 유형 중 적어도 하나를 포함하는 정보를 획득할 수 있다. 상기 획득 과정을 용이하게 하기 위하여, 상기 누적 반복하여 처리된 ConvLSTM 처리의 결과는 적응적 평균 풀링(adaptive average pooling)에 기초하여 단순화될 수 있다. 또한, 상기 적응적 평균 풀링의 결과는 다시 합성곱에 의하여 계산됨으로써, 상기 시퀀스 길이 동안 제공된 영상 프레임에서 특정 행동이 검출되었는지의 여부를 보다 용이하게 획득하는 데 사용될 수 있다. 본 발명의 일 실시예에 따르면, 상기 합성곱에 의한 계산 단계의 결과는 특정 행동의 존재 여부를 나타내는 참/ 거짓(TRUE/FALSE) 값 또는 0/1 값을 포함할 수 있다. 본 발명의 다른 실시예에 따르면, 상기 합성곱에 의한 계 산 단계의 결과 및 상기 적응적 평균 풀링에 의한 단순화의 결과를 참조함으로써 식별된 행동의 유형을 포함할 수 있다. 한편, 본 발명의 다른 일 실시예에 따르면, 상기 제2 검출(230, S340)은, 상기 시간적으로 연속된 자세 정보를 통합적으로 분석하기 위하여 변환기(transformer) 기반의 특징값 처리 기술로 구현되는 연산수단에 의하여 실행 될 수 있다. 상기 변환기란, 화상에 포함되는 정보를 소정 함수연산에 의하여 특정한 정보 도메인(domain)으로 (바람직하게는 무손실적으로) 변환함으로써, 상기 정보의 특징값을 추출하거나, 상기 특징값을 필터링하거나, 상기 특징값을 병합하여 단일한 특징값으로 도출하는 데에 활용될 수 있는 기능을 의미할 수 있다. 이하 도 5b를 더 참조하여 설명한다. 도 5b는 본 발명의 일 실시예에 따른 시공간적 변환기(spatiotemporal transformer)에 의하여 시간적으로 연속된 자세 정보를 분석하는 과정의 개념도이다. 상술한 바와 같이, 입력된 영상 프레임으로부터 상술한 절차에 의하여 인체 자세 정보를 획득할 수 있다. 상기 인체 자세 정보 는 각각의 프레임 단위로 공간적 변환기(spatial transformer)에 투입될 수 있다. 상기 공간적 변환 기는 상기 인체 자세 정보를 변환하여 공간적 특징값을 획득하도록 구성될 수 있다. 상기 공간적 특징값은 다시 시공간적 변환기에 투입될 수 있다. 상기 시공간적 변환기는 일정 시간 동안 제공되는 공간적 특징값을 수용하도록 구성될 수 있다. 상술한 바와 같이, 입력되는 영상 프레 임의 시퀀스 길이(sequence length)는 본 발명을 실시하는 자에 따라 임의로 지정될 수 있다. 상기 시퀀스 길이를 N이라 하면, N개의 영상 프레임으로부터 N개의 공간적 특징값이 생성되고, 상기 N개의 공간적 특징값이 상기 시공간적 변환기를 통해 병합 변환되어 단일한 시공간적 특징값으로 도출 될 수 있다. 상기 시공간적 특징값은, 상기 시퀀스 길이만큼의 공간적 변환 결과를 병합함으로써, 결과적으로 상 기 시퀀스 길이 동안 제공된 영상 프레임으로부터 획득된 인체 행동에 대한 특징값을 포함하고 있다고 볼 수 있다. 상기 특징값으로부터 행동의 여부 및 행동의 유형 중 적어도 하나를 포함하는 정보를 획득할 수 있음은 상술한 바와 같다. 도 5c는 본 발명의 일 실시예에 따른 시공간적 변환기(spatiotemporal transformer)에 의하여 시간적으로 연속 된 자세 정보를 분석하는 과정의 변형된 실시방법에 대한 개념도이다. 도 5c의 좌측을 참조하면, 본 발명의 다른 일 실시예에 있어서, 상기 인체 자세 정보는 공간적 변환기 에 투입되기에 앞서 초기 특징값 추출 변환기에 먼저 투입되어 초기 특징값을 생성하도록 구성 될 수도 있다. 이 경우 상기 공간적 변환기는 상기 초기 특징값을 입력으로 받아 상기 공간적 특징값 을 도출하도록 구성될 수 있다. 도 5c의 중앙을 참조하면, 본 발명의 다른 일 실시예에 있어서, 상기 변환기에 의한 절차는 상술한 ConvLSTM에 의한 절차나 그와 유사한 CNN에 의한 절차에 후속하여 추가적으로 이루어질 수도 있다. 가령, 입력된 영상 프레 임을 CNN에 투입하여 특징값을 추출하고, 상기 특징값을 상기 공간적 변환기의 입력 으로 할 수 있다. 도 5c의 우측을 참조하면, 본 발명의 또다른 일 실시예에 있어서, 상기 변환기에 의한 절차는 상기 ConvLSTM이 나 CNN에 의한 절차를 완전히 대체할 수도 있다. 즉, 상기 영상 프레임은 인체 자세 정보의 추출이 없이 변환기에, 바람직하게는 상기 변형된 실시예에 있어서의 초기 특징값 추출 변환기에 투입되어, 그 특징값 을 획득하는 절차가 시작될 수 있다. 그 밖에도 다양한 변형 실시의 가능성이 존재함은 자명하다. 다시 도 3의 순서도를 참조하면, 상술한 절차에 따라 상기 제2 검출(230, S340)은 상기 식별되는 행동의 존재 여부 및/또는 유형을 포함하는 결과를 도출하고, 이를 통해 식별 대상이 되는 행동의 검출 여부를 최종적으로 판단(S350)하도록 구성될 수 있다. 상기 판단의 결과 제2 검출을 통한 행동 인식이 성공적이었던 경우, 상기 제 2검출의 결과를 출력(S360)할 수 있다. 상기 출력 정보는, 예를 들어, 행동의 종류, 행동의 강도(intensity), 행동의 심각성(severity), 행동의 지속 시간, 행동의 상호 작용에 참여하는 사람의 수, 및 행동의 대상이 되는 사람 또는 객체에 관련된 정보 중 적어도 하나를 포함할 수 있다. 본 발명의 일 실시예에서는, 만약 상기 제2 검출(S350)의 결과가 부정적인 경우, 상기 제2 검출의 결과 출력(S360)이 실행되지 않도록(S370) 구성될 수도 있다. 다시 도 2의 예시를 참조하면, 도 2의 하단 예시에 있어서, 상기 행동이 검출될 가능성이 낮은 프레임이 입력(S310)될 수 있다. 이 경우에도 마찬가지로, 상기 프레임으로부터 행동을 검출하기 위한 본격적인 단 계가 수행되기에 앞서, 본 발명에서는 보다 단순한 처리 단계인 제1 검출을 수행(260, S320)하도록 구성될 수 있다. 그런데 이 경우, 상기 제1 검출(260, S370)은 성공적이지 못하고, 상술한 예시에 따라 설명하면, 경계 상자가 식별되지 않거나, 또는 사람의 머리가 식별되지 않는 등의 결과로 나타날 수 있다. (이러한 결과의 없음에 대하 여 도 2의 예시에서는 부호 270으로 나타내고 있다.) 이러한 경우, 상기 제1 검출이 수행된 프레임에서 상 기 사람의 존재가 검출되지 아니함이 판단(S330)될 수 있고, 이 경우, 상기 프레임의 처리는 더 지속 되지 않도록, 예를 들어, 제2 검출로 이행하지 않도록(280, S370) 구성될 수 있다. 즉, 상기 제1 검출(S330)의 결과가 부정적이면, 상기 제2 검출(S350)은 실행되지 않을 수 있다. 본 발명의 다른 일 실시예에서는, 만약 상기 제1 검출(S330)의 결과가 부정적인 경우, 상기 처리 결과를 출력하 는 단계(S360)로 이행하되, 상기 출력되는 처리 결과는 상기 제1 검출의 부정적 결과만을 출력하도록 구성될 수 있다. 즉, 상기 입력된 프레임으로부터 행동 인식을 기대할 수 없었음을 출력하도록 구성될 수 있다. 본 발명의 다른 일 실시예에서는, 상기 출력 이후에 상기 제2 검출의 결과에 기반하여 진행되는 추가적인 영상 처리의 단계들이 존재할 수 있다. 바람직하게는, 도 3에 있어서 단계 S360으로부터 종료의 사이에 배치될 수 있 는 것으로 볼 수 있다. 상기 추가적인 영상 처리의 단계는, 예를 들어, 상기 식별된 사람의 행동 정보를 더욱 증강하여 분류하는 제3 검출 단계나, 상기 행동에 대하여 상기 프레임에 레이블링(labeling) 또는 태깅 (tagging)을 자동적으로 수행하는 단계나, 또는 상기 행동 인식을 수행한 기계 학습 인공지능에 대한 재학습 단 계 중 어느 하나이거나, 그 밖에 본 발명에 의하여 한정되지 아니하는 임의의 영상 처리 단계를 포함할 수 있다. 이러한 추가 처리의 단계들 또한, 상기 제1 검출의 결과가 부정적이면, 실행되지 않고 모든 처리가 종료 에 이행하도록(S370) 구성될 수 있다. 상술한 바와 같이 상기 제2 검출(S230, S340)은, 바람직하게는, 도 3에 나타나는 것과 같은 자세 예측 모델 및/ 또는 도 4에 나타나는 합성곱 기반의 장단기기억(ConvLSTM)과 같은 높은 연산량을 요구하는, 필요에 따라서는 인공지능 의존적인 방법으로 구현될 수 있다. 이에 비하여, 상기 제1 검출(220, 260, S320)은, 상술한 바와 같이 상대적으로 단순한 방법으로 구현되어 있을 수 있으며, 기계 학습, 인공 신경망, 및 장단기기억(long-short term memory; LSTM)을 포함하는 인공지능에 기반한 검출 단계가 포함되지 않도록 구성될 수 있다. 이처럼 상기 제2 검출이 상기 제1 검출보다 높은 복잡도를 가지게 됨으로써, 상기 제1 검출을 기반으로 하여 상기 제2 검출 의 실행 여부를 판단하도록 하고, 이를 통하여 상기 제2 검출의 높은 복잡도 연산에 소요되는 시간적 및 연산적 자원을 절감하는 이로운 효과를 기대할 수 있게 된다. 본 발명의 실시예에 따라서, 상기 제2 검출(S230, S340)은, 상기 제1 검출(220, 260, S320)의 결과를 참조하여 수행되도록 구성될 수 있다. 일례로서, 다시 도 2의 상단 예시를 참조하면, 상기 제1 검출(220, S320)에 의하여 획득된 경계 상자가 있을 경우, 상기 제2 검출(S230, S340)은 상기 경계 상자에 기반하여 상기 행동 의 인식 방법을 수행하도록 구성될 수 있다. 그 밖에도 다양한 방법 및 정보의 유형에 의하여, 선행하는 영상 처리 및 인식 알고리즘이 후속하는 영상 처리 및 인식 알고리즘에 그 기초적 연산 과정의 일부를 공유할 수 있 는 것임은 통상의 기술자에게 쉽게 이해될 수 있을 것이다. 상술하는 설명에 있어서는 행동의 인식을 목적으로 하는 제1 실시예를 기준으로 설명하였으나, 동일한 절차가 인공지능의 학습을 목적으로 하는 제2 실시예에 기준하여서도 이루어질 수 있음 또한 쉽게 알 수 있다. 단 이 경우, 도 3에서 처리 결과를 출력(S360)하는 과정에서의 출력 내용이 달라질 수 있다. 도 6은 본 발명의 예시로서 나타낸 제1 실시예와 제2 실시예의 동작을 비교한 개념도이다. 상기 제1 실시예를 기준으로 상술한 실시방법과 같이 동일하게 동작하는 본 발명의 실시체(610a)가 있는 경우, 도 6의 (a)와 같이 판단 대상인 영상 데이터를 제공하거나, 또는 도 6의 (b)와 같이 학습 대상인 영상 데이터가 제공될 수 있다. 도 6의 (a)의 경우에는 상술한 바와 같이 제2 검출 단계의 연산 소요를 절감하는 방법에 의하여 행동 인식의 결과 정보가 출력될 수 있다. 그에 비하여, 도 6의 (b)의 경우에는, 상기 출력의 내용은 상기 입력 된 단위 영상, 즉 프레임 그 자체를 포함하는 영상 데이터셋일 수 있다. 예를 들어, 도 1을 다시 참조하면, 도 1의 동영상이 상기 도 6의 (b)에 입력으로서 주어진 경우, 상 기 실시체(610b)에 의하여서는 행동의 인식에 대한 기계 학습에 적합한 프레임, 즉 대상 구간에 해당하는 프레임(예시적으로, 112~114)이 출력으로 도출되고, 그 외의 프레임(예시적으로, 111, 115)은 출력에 포함되지 않음으로써, 상기 주어진 동영상을 특정한 목적의 영상 데이터셋으로 변환하도록 사용될 수 있다. 즉, 상기 실시체의 출력을 통해, 상기 제1 검출 및 상기 제2 검출의 결과 중 적어도 하나를 참조하여 상기 입력된 프레임을 상기 출력되는 데이터셋에 포함할지를 결정하여, 그 결과가 반영될 수 있는 것이다. 본 발명의 일 실시예에 따르면, 상기 출력되는 영상 데이터셋은 사람 등 객체의 동작을 인식하는 인공지능 의 기계 학습을 위한 학습 데이터셋일 수 있다. 따라서, 상기 출력된 데이터셋은, 상기 실시체의 입력으로 되먹임될 수 있다. 예를 들어, 본 발명의 일 실시예에서, 하나의 실시체(610b)는 본 발명에 의한 방법을 학습 영상 데이터셋의 생산을 위하여 사용하고, 그 결과를 다른 실시체(610a)에 학습 입력으로서 제공하여, 상 기 다른 실시체(610a)의 인공지능을 동작 가능 상태로 하거나 또는 그 성능을 더욱 강화하는 목적, 즉 재학습의 목적으로 사용될 수 있다. 그리고 상기 다른 실시체(610a)는, 역시 본 발명에 의한 방법에 따라 상기 제1 검출 및 상기 제2 검출을 포함하는 영상 처리 절차를 수행하는데, 이 때 상기 제공받은 학습 데이터에 기반하여 기계 학습된 인공지능이 사용될 수 있는 것이다. 물론, 본 발명의 다른 실시예에 따르면, 도 6의 (c)와 같이, 상기 실시체(610c)는 단일한 실시형태를 가지고, 동작 모드에 따라서 주어지는 입력을 판단의 대상 또는 학습의 대상으로 간주하고, 처리에 따라서 행 동 인식의 결과 및/또는 학습 데이터셋을 출력하며, 상기 학습 데이터셋을 스스로에게 되먹임 하여 재학습하도록 구성되어 있을 수도 있으며, 그 밖에 다양한 변형 실시의 형태가 본 명세서에 의하여 한정되지 않고 허용된다. 상술한 본 발명의 다양한 실시예에서 행동 인식, 식별, 및 검출의 대상으로 사람으로 하였으나, 본 발명을 실시 하는 통상의 기술자는 여기에 한정되지 않고 임의의 유형을 가진 객체의 임의의 행동을 검출하기 위하여 본 발 명을 동일하게 원용할 수 있음을 이해할 것이다. 즉, 본 발명은 사람의 행동, 예를 들면 사람의 대화, 교류, 범 죄/이상 행동과 같은 것을 효율적으로 검출하거나, 또는 그러한 검출을 실시하는 인공지능을 학습시키기 위한 데이터 셋을 생성하는 데 사용될 수 있는 반면, 차량의 행동, 예를 들면 과속, 추돌, 교통규제 위반과 같은 행 동을 효율적으로 검출하거나, 또는 그러한 검출을 실시하는 인공지능을 학습시키기 위한 데이터 셋을 생성하는 데 사용될 수 있다. 차량을 대상으로 하는 경우 상기 제1 검출은 프레임 내에서 차량의 존재 여부만을 추출하고, 상기 제2 검출은 검출된 차량의 동작을 분석하도록 구성될 수 있는 것이다. 그 외에 사람이 아닌 동 물, 자연지물, 기타 사물 및 객체 등 어떠한 대상에 대해서라도 상기 제1 검출을 통해 그 존재의 유무를 판단하여 처리할 프레임의 수를 줄인 다음 상기 제2 검출을 통해 정밀 분석함으로써 어떠한 인공지능에 기반한 처리를 달성하게 되는 경우라면 본 발명이 동일하게 적용될 수 있음이 자명하다. 상술한 제1 검출 및 제2 검출을 포함하는 본 발명의 방법은 상술한 바와 같이 실시쳬(예를 들어, 도 6의 실시체 )로 구현될 수 있으며, 상기 실시체는 독립적 장치를 구성하거나, 또는 다른 장치 및/또는 시스템의 기능 부로서 구현될 수 있다. 도 7은 본 발명의 일 실시예에 따른 인공지능에 기반하여 단위 영상을 처리하여 객체의 동작을 인식하는 장치의 블록도이다. 도 7에는 상기 실시체로서 독립 장치의 형태를 가지는 장치의 블록도가 개시되어 있으나, 이는 본 발명의 다양한 실시 형태를 한정하지 아니하는 예시적 개시에 불과하다. 실시예에 의하면, 상기 영상 처리 장치 는 연산 기능을 가지는 프로세서, 컴퓨터 판독 가능한 메모리, 단위 영상(프레임)을 입력받는 입력부, 상기 단위 영상에서 객체의 존재 유무를 검출하는 제1 검출부, 상기 단위 영상에서 상기 객 체의 동작을 인식하는 제2 검출부, 및 상기 제2 검출의 결과를 포함하는 정보를 출력부를 포함하도록 구성될 수 있다. 상기 각 기능부는 버스(bus), 회로, 또는 루틴(routine)과 서브루틴(subroutine)의 관계와 같이 다양한 형태로 상호 연결되어 상기 영상 처리 장치 내에서 정보를 교환하도록 구성될 수 있다. 또한, 상기 상호 연 결을 통하여, 상기 각 기능부, 특히 상기 제1 검출부 및 제2 검출부와 같이 계산의 수행을 주로 요하는 기능부의 동작을 실행 또는 지원하기 위한 목적에서, 연산 기능을 가지는 프로세서 및 상기 프로세 서에 연결되는 메모리를 포함하도록 구성될 수 있다. 본 명세서에 기재된 상기 프로세서는, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프 로세서(digital signal processor), 마이크로컴퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 의미할 수 있다. 상기 프로세서는, 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어(software)를 수행 하도록 구성될 수 있다. 또한, 처리 장치는 상기 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 상기 프로세서가 단수로 표현되는 경우라 할지라도, 해"}
{"patent_id": "10-2023-0096850", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "당 기술분야에서 통상의 지식을 가진 자는, 상기 프로세서가 복수 개의 처리요소(processing element) 및/ 또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 본 발명의 일 실시예에 따른 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 상기 프로세서는 병렬 프로세서(parallel processor)나 멀티-코어 프로세서(multi-core processor)와 같이, 다양한 처리 구성 (processing configuration)에 의하여 구현될 수 있다. 상기 소프트웨어는, 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함하 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 상기 소프트웨어는, 상기 프로세서에 의하여 해석되거나 상 기 프로세서에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장 치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구 적으로, 또는 일시적으로 구체화(embody)될 수 있다. 상기 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 상기 소프트웨어는 또한, 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 상기 메 모리에 기록되거나 저장될 수 있다. 상기 메모리는 컴퓨터 판독 가능 기록 매체일 수 있으며, 상기 컴퓨터 판독 가능 기록 매체에는 프로그램 명령, 데이터 파일, 데이터 구조 등이 단독으로 또는 조합되어 기록 될 수도 있다. 상기 메모리에 저장되는 프로그램 명령은 본 발명의 실시예를 위하여 특별히 설계되고 구성 된 명령 체계에 기반하거나, 또는 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 명령 체계, 예를 들어 어셈블리어(Assembly), C, C++, Java, Python 언어 등으로 예시되는 명령 체계를 따를 수도 있다. 상기 명령 체 계 및 그에 의한 프로그램 명령은 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 본 발명의 일 실시예에 따른 장치 및/또는 상기 프로세서에 의해서 실행될 수 있는 고급 언 어 코드를 포함하는 것으로 이해되어야 한다. 본 명세서에 기재된 상기 메모리를 포함하여 본 발명의 일 실시예에 따른 장치를 구성하는 컴퓨터 판독 가 능 기록 매체는, 프로세서 캐시(Cache), 램(RAM), 플래시 메모리와 같이 상기 프로세서가 동작하는 동안만유지되는 일시적 또는 휘발성 기록 매체를 포함할 수 있고, 또는 하드 디스크, 플로피 디스크, 및 자기 테이프 와 같은 자기체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 또는 정적 상태 메모리(solid state memory) 와 같이 상대적으로 비휘발성적이거나 장기 기록이 가능한 기록 매체를 포함할 수 있고, 또는 하드웨어 상에 배 치된 롬(ROM)과 같은 읽기 전용의 기록 매체를 포함할 수 있으며, 나아가 회로배선에 의한 하드-와이어드(hard- wired) 구조에 의하여 일련의 프로그램 명령과 등가의 동작을 수행하도록 구성된 하드웨어 그 자체 또한, 본 발 명의 실시예를 구현하는 상기 동작을 수행하기 위한 각 단계가 상기 하드웨어 부품의 연결과 배치에 의하여 기 록되어 있다고 볼 수 있으므로, 그 연결 및 배치방법이 곧 상기 메모리와 등가인 것으로 볼 수 있음은 통 상의 기술자에게 자명하다. 상기 프로세서 및 상기 메모리에 대하여 상술한 실시예는 상호 배타적이지 않으며, 필요에 따라 선택되거 나 결합되어 실시될 수 있다. 예를 들어, 하나의 하드웨어 장치는 본 발명 실시예의 동작을 수행하기 위해 하나 이상의 상기 소프트웨어로 구성된 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 또 다른 예를 들어, 본 명세서에 있어서, 어떠한 기능부에 할당된 동작의 전부 또는 일부는 본 발명의 일 실시예에 따른 장치 에(바람직하게는, 상기 메모리의 범주에 속하는 어느 하나의 기록 매체에) 저장된 하나 이상의 상기 소프 트웨어에 의하여 구현되어, 상기 프로세서에 의하여 실행되도록 구성될 수 있으며, 이러한 경우, 상기와 같은 기능부는 상기 프로세서에 \"포함되는\" 기능부로서 칭해질 수 있다. 본 발명의 일 실시예에 있어서, 상기 프로세서는 상기 제1 검출부와 상기 제2 검출부의 동작을 제어하도록 구성될 수 있다. 따라서, 상술한 방법과 동일하게, 상기 프로세서는 상기 제1 검출부의 출력이 부정적인 경우, 상기 제2 검출부가 동작하지 않도록 제어할 수 있다. 실시예에 따라서, 상기 제2 검출부의 동작은 상기 제1 검출부의 동작보다 높은 복잡도를 가지도록 구 성될 수 있다. 이러한 경우 각각의 검출부에 구현되는 알고리즘 및/또는 방법의 예는 앞서 설명한 바를 준용할 수 있다. 본 발명의 일 실시예에 있어서, 상기 영상 처리 장치에는 상기 입력된 영상에 대한 추가적 정보처리를 수 행하는 부가처리부를 더 포함할 수 있다. 상기 부가처리부의 동작 내용은 앞서 도 3을 참조하여 상술한 추 가적 정보처리의 실시예를 준용할 수 있다. 바람직하게는, 상기 부가처리부 또한 상기 각각의 기능부와 상 호 연결되어 있을 수 있다. 이 때, 상기 프로세서는 상기 부가처리부의 동작을 제어하도록 구성 될 수 있다. 따라서, 상술한 방법과 동일하게, 상기 프로세서는 상기 제1 검출부의 출력이 부정적인 경우, 상기 부가처리부가 동작하지 않도록 제어할 수 있다. 상기 출력부의 출력 또한 앞서 도 1 내지 6을 통하여 설명한 바와 같을 수 있다. 상기 출력부에서 출 력되는 정보는, 영상 데이터셋을 포함하고, 이 때 상기 출력부는, 상기 제1 검출부 및 상기 제2 검출부의 동작 중 적어도 하나를 참조하여 상기 입력부에 입력된 특정 단위 영상, 예를 들면 프레임을 출력하는 데 이터셋에 포함할지를 결정하도록 구성될 수 있다. 상기 장치에는 기계 학습, 인공 신경망, 및 장단기기억(long-short term memory; LSTM) 중 적어도 하나를 포함하는 인공지능 검출부가 마련되어 있을 수 있다. 상기 인공지능 검출부는 상술하였던 방법에 의 하여 인간(또는 그 밖의 객체)의 특정 행동을 검출하는 방법을 구현하는 기능부일 수 있다. 상기 인공지능 검출 부는 상기 제2 검출부에 포함되거나, 적어도 연결되는 형태로 구현될 수 있다. 만약 연결되는 형태로 구현된다면, 상기 인공지능 검출부는 상기 제1 검출부에는 연결되지 않고, 상기 제2 검출부에만 연결되어도 좋다. 다만, 상호 연결을 통하여 일반적인 기능부로서 접속되어 있어도 무방하다. 이상 본 발명에 대하여 도면 및 실시예를 참조하여 설명하였으나, 이미 상술한 바와 같이 본 발명의 보호범위가 상기 제시된 도면 또는 실시예에 의해 한정되는 것을 의미하지는 않으며, 해당 기술 분야의 숙련된 당업자는 본 발명 특허의 청구범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하 게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5a 도면5b 도면5c 도면6 도면7"}
{"patent_id": "10-2023-0096850", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 영상 프레임의 선택에 대한 개념도, 도 2는 본 발명의 일 실시예에 따른 제1 검출 및 제2 검출의 개념도, 도 3은 본 발명의 일 실시예에 따른 제1 검출과 제2 검출의 수행 과정에 대한 순서도, 도 4는 본 발명의 일 실시예에 따른 제2 검출의 과정에 대한 개념도, 도 5a는 본 발명의 일 실시예에 따른 합성곱 기반의 장단기기억(ConvLSTM)에 의하여 시간적으로 연속된 자세 정 보를 분석하는 과정의 개념도, 도 5b는 본 발명의 일 실시예에 따른 시공간적 변환기(spatiotemporal transformer)에 의하여 시간적으로 연속 된 자세 정보를 분석하는 과정의 개념도, 도 5c는 본 발명의 일 실시예에 따른 시공간적 변환기(spatiotemporal transformer)에 의하여 시간적으로 연속 된 자세 정보를 분석하는 과정의 변형된 실시방법에 대한 개념도, 도 6은 본 발명의 예시로서 나타낸 제1 실시예와 제2 실시예의 동작을 비교한 개념도, 그리고 도 7은 본 발명의 일 실시예에 따른 인공지능에 기반하여 단위 영상을 처리하여 객체의 동작을 인식하는 장치의 블록도이다."}
