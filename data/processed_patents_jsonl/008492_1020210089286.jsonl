{"patent_id": "10-2021-0089286", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0008530", "출원번호": "10-2021-0089286", "발명의 명칭": "영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치 및 방법", "출원인": "주식회사 트립비토즈", "발명자": "정지하"}}
{"patent_id": "10-2021-0089286", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행 영상 및 상기 여행 영상의위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 모듈;상기 여행 영상의 프레임 중 특정 프레임을 대표 프레임으로 선정하는 대표 프레임 선정 모듈; 상기 대표 프레임을 입력 데이터로 하고 상기 위치 정보가 포함된 구역의 테마에 대한 분류 정보인 제1구역 분류 정보를 출력 데이터로 하는 대표 프레임 분류 인공신경망 모듈을 포함하며, 상기 여행 영상 및 상기 영상 정보에 대한 상기 제1구역 분류 정보를 출력하는 대표 프레임 분류 모듈;입력 데이터를 대표 프레임으로 하고 출력 데이터로 특징 클래스 정보(class probability) 및 특징 좌표 정보(coordinate data)를 포함하는 CNN 계열의 특징 추출 인공신경망을 포함하는 특징 추출 모듈;상기 대표 프레임 분류 모듈의 특정 컨볼루전 레이어(Convolution Layer)와 연결되어 클래스 별 액티베이션 맵(Activation map)을 의미하는 클래스 액티베이션 정보를 수신하고, 상기 클래스 액티베이션 정보 및 상기 특징좌표 정보를 이용하여 각 클래스의 특징 중요도 정보를 생성하며, 생성된 상기 특징 중요도 정보가 가장 큰 클래스를 코어 특징으로 선정하는 코어 특징 선정 모듈; 상기 대표 프레임 선정 모듈에서 선정된 상기 대표 프레임의 전후 프레임들 중 상기 코어 특징을 포함하는 복수의 프레임을 후보 프레임으로 선정하는 후보 프레임 선정 모듈; 및상기 대표 프레임과 상기 후보 프레임을 상기 코어 특징을 기준으로 정합(stiching)하여 파노라마 대표 프레임을 생성하는 프레임 정합 모듈;를 포함하고,상기 프레임 정합 모듈에서 생성된 상기 파노라마 대표 프레임은 상기 대표 프레임 분류 모듈에 입력 데이터로입력되어 제2구역 분류 정보를 출력 데이터로 출력하도록 구성되는 것을 특징으로 하는. 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치."}
{"patent_id": "10-2021-0089286", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 특징 중요도 정보는, 각 클래스의 상기 특징 좌표 정보에 따른 바운딩 박스(bounding box) 범위 내에 상기 클래스 액티베이션 정보의hitmap이 포함되는 비율 또는 각 클래스의 상기 바운딩 박스 범위 내에서의 상기 클래스 액티베이션 정보의 액티베이션 값의 합을 포함하는 것을 특징으로 하는, 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치."}
{"patent_id": "10-2021-0089286", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "여행 영상 수신 모듈이, 생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행영상 및 상기 여행 영상의 위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 단계;대표 프레임 선정 모듈이, 상기 여행 영상의 프레임 중 특정 프레임을 대표 프레임으로 선정하는 대표 프레임선정 단계; 상기 대표 프레임을 입력 데이터로 하고 상기 위치 정보가 포함된 구역의 테마에 대한 분류 정보인 제1구역 분공개특허 10-2023-0008530-3-류 정보를 출력 데이터로 하는 대표 프레임 분류 인공신경망 모듈을 포함하는 대표 프레임 분류 모듈이, 상기여행 영상 및 상기 영상 정보에 대한 상기 제1구역 분류 정보를 출력하는 대표 프레임 분류 단계;입력 데이터를 대표 프레임으로 하고 출력 데이터로 특징 클래스 정보(class probability) 및 특징 좌표 정보(coordinate data)를 포함하는 CNN 계열의 특징 추출 인공신경망을 포함하는 특징 추출 모듈이, 상기 특징 클래스 정보 및 상기 특징 좌표 정보를 출력하는 특징 추출 단계;코어 특징 선정 모듈이, 상기 대표 프레임 분류 모듈의 특정 컨볼루전 레이어(Convolution Layer)와 연결되어클래스 별 액티베이션 맵(Activation map)을 의미하는 클래스 액티베이션 정보를 수신하고, 상기 클래스 액티베이션 정보 및 상기 특징 좌표 정보를 이용하여 각 클래스의 특징 중요도 정보를 생성하며, 생성된 상기 특징 중요도 정보가 가장 큰 클래스를 코어 특징으로 선정하는 코어 특징 선정 단계; 후보 프레임 선정 모듈이, 상기 대표 프레임의 전후 프레임들 중 상기 코어 특징을 포함하는 복수의 프레임을후보 프레임으로 선정하는 후보 프레임 선정 단계; 및프레임 정합 모듈이, 상기 대표 프레임과 상기 후보 프레임을 상기 코어 특징을 기준으로 정합(stiching)하여파노라마 대표 프레임을 생성하는 프레임 정합 단계;를 포함하고,상기 파노라마 대표 프레임은 상기 대표 프레임 분류 모듈에 입력 데이터로 입력되어 제2구역 분류 정보를 출력데이터로 출력하도록 구성되는 것을 특징으로 하는. 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 방법."}
{"patent_id": "10-2021-0089286", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "여행 영상 분류 프로그램 코드를 포함하는 메모리 모듈; 및상기 여행 영상 분류 프로그램 코드를 수행하는 처리 모듈;을 포함하고, 상기 여행 영상 분류 프로그램 코드는, 생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행 영상 및 상기 여행 영상의위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 단계;상기 여행 영상의 프레임 중 특정 프레임을 대표 프레임으로 선정하는 대표 프레임 선정 단계; 상기 대표 프레임을 입력 데이터로 하고 상기 위치 정보가 포함된 구역의 테마에 대한 분류 정보인 제1구역 분류 정보를 출력 데이터로 하는 대표 프레임 분류 인공신경망 모듈이 상기 여행 영상 및 상기 영상 정보에 대한상기 제1구역 분류 정보를 출력하는 대표 프레임 분류 단계;입력 데이터를 대표 프레임으로 하고 출력 데이터로 특징 클래스 정보(class probability) 및 특징 좌표 정보(coordinate data)를 포함하는 CNN 계열의 특징 추출 인공신경망이 상기 특징 클래스 정보 및 상기 특징 좌표정보를 출력하는 특징 추출 단계;상기 대표 프레임 분류 인공신경망 모듈의 특정 컨볼루전 레이어(Convolution Layer)와 연결되어 클래스 별 액티베이션 맵(Activation map)을 의미하는 클래스 액티베이션 정보를 수신하고, 상기 클래스 액티베이션 정보 및상기 특징 좌표 정보를 이용하여 각 클래스의 특징 중요도 정보를 생성하며, 생성된 상기 특징 중요도 정보가가장 큰 클래스를 코어 특징으로 선정하는 코어 특징 선정 단계; 상기 대표 프레임의 전후 프레임들 중 상기 코어 특징을 포함하는 복수의 프레임을 후보 프레임으로 선정하는후보 프레임 선정 단계; 및상기 대표 프레임과 상기 후보 프레임을 상기 코어 특징을 기준으로 정합(stiching)하여 파노라마 대표 프레임을 생성하는 프레임 정합 단계;를 포함한 단계를 컴퓨터 상에서 수행하도록 구성되는 것을 특징으로 하고,공개특허 10-2023-0008530-4-상기 파노라마 대표 프레임은 상기 대표 프레임 분류 모듈에 입력 데이터로 입력되어 제2구역 분류 정보를 출력데이터로 출력하도록 구성되는 것을 특징으로 하는, 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치."}
{"patent_id": "10-2021-0089286", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "여행 영상 수신 모듈이, 생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행영상 및 상기 여행 영상의 위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 단계;대표 프레임 선정 모듈이, 상기 여행 영상의 프레임 중 특정 프레임을 대표 프레임으로 선정하는 대표 프레임선정 단계; 상기 대표 프레임을 입력 데이터로 하고 상기 위치 정보가 포함된 구역의 테마에 대한 분류 정보인 제1구역 분류 정보를 출력 데이터로 하는 대표 프레임 분류 인공신경망 모듈을 포함하는 대표 프레임 분류 모듈이, 상기여행 영상 및 상기 영상 정보에 대한 상기 제1구역 분류 정보를 출력하는 대표 프레임 분류 단계;입력 데이터를 대표 프레임으로 하고 출력 데이터로 특징 클래스 정보(class probability) 및 특징 좌표 정보(coordinate data)를 포함하는 CNN 계열의 특징 추출 인공신경망을 포함하는 특징 추출 모듈이, 상기 특징 클래스 정보 및 상기 특징 좌표 정보를 출력하는 특징 추출 단계;코어 특징 선정 모듈이, 상기 대표 프레임 분류 모듈의 특정 컨볼루전 레이어(Convolution Layer)와 연결되어클래스 별 액티베이션 맵(Activation map)을 의미하는 클래스 액티베이션 정보를 수신하고, 상기 클래스 액티베이션 정보 및 상기 특징 좌표 정보를 이용하여 각 클래스의 특징 중요도 정보를 생성하며, 생성된 상기 특징 중요도 정보가 가장 큰 클래스를 코어 특징으로 선정하는 코어 특징 선정 단계; 후보 프레임 선정 모듈이, 상기 대표 프레임의 전후 프레임들 중 상기 코어 특징을 포함하는 복수의 프레임을후보 프레임으로 선정하는 후보 프레임 선정 단계; 및프레임 정합 모듈이, 상기 대표 프레임과 상기 후보 프레임을 상기 코어 특징을 기준으로 정합(stiching)하여파노라마 대표 프레임을 생성하는 프레임 정합 단계;를 포함한 단계를 컴퓨터 상에서 수행하도록 구성되는 것을 특징으로 하고,상기 파노라마 대표 프레임은 상기 대표 프레임 분류 모듈에 입력 데이터로 입력되어 제2구역 분류 정보를 출력데이터로 출력하도록 구성되는 것을 특징으로 하는. 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 방법을 컴퓨터 상에서 수행하도록 구성되는 기록매체에저장된 프로그램."}
{"patent_id": "10-2021-0089286", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치 및 방법에 관한 것이다. 이를 위하여, 대 표 프레임을 입력 데이터로 하고 대표 프레임 내에 포함된 오브젝트에 대한 분류 정보인 Class 분류 정보 및 오 브젝트의 대표 프레임 내 비율에 대한 정보인 오브젝트 크기 정보를 출력 데이터로 하는 CNN 모듈을 포함하고, Class 분류 정보 및 오브젝트 크기 정보를 입력 데이터로 하고 위치 정보가 포함된 구역의 테마에 대한 분류 정 보인 구역 분류 정보를 출력 데이터로 하는 인공신경망 모듈을 포함하며, 여행 영상 및 영상 정보에 대한 구역 분류 정보를 출력하는 대표 프레임 분류 모듈을 제공할 수 있다. 이에 따르면, 여행 영상을 사용자의 니즈에 따 라 구분되는 구역으로 분류하는 것이 가능해지는 효과가 발생된다."}
{"patent_id": "10-2021-0089286", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0089286", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "여행 산업은 스마트폰의 등장에 따라 급변하였으며 이에 따라 매년 꾸준히 성장하고 있는 산업군 중 하나이다. 여행 산업은 크게 항공, 숙박, 렌터카, 액티비티 티켓, 여행가이드 혹은 패키지여행으로 구분될 수 있다. 이 중 숙박 예약 산업은 여행 산업에서의 필수적인 요소로서 수요 및 공급이 가장 크고 경쟁도 가장 심화되어 있는 산 업군이다. 숙박 예약 산업에서의 대표적인 플레이어로는, 호텔 예약에 호텔스닷컴, 익스피디아, 부킹닷컴, 아고 다, 호텔엔조이, 당일 호텔 타임커머스에 데일리호텔, 세일투나잇, 호텔타임(여기어때), 호텔나우(야놀자), 모 텔 예약에 야놀자, 여기어때, 팬션 예약에 야놀자팬션, 우리팬션, 떠나요닷컴, 게스트하우스나 민박 예약에 에 어비앤비, 코자자, 올스테이, 호텔메타검색에 트립어드바이저, 호텔스컴바인, 스카이스캐너, 트리바고 등이 있 다. 이러한 다양한 여행 서비스의 등장으로 여행객들은 과거에 단순히 패키지 여행을 구매하던 방식과 달리 여행 경 험과 일정을 직접 설계하고자 하는 경향이 발생하기 시작하였다. 이와 더불어 여행 서비스들은 고객들이 원하지 도 않는 상품과 프로모션을 푸시하는 방식에서 벗어나 다양한 방식으로 상품을 제공함으로써 여행 설계의 새로 운 소비 경험을 제공하는데 주력하고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 10-1979764, 최저가 호텔 예약에 따른 차액보상이 가능한 호텔 예약 방법 및 시스템, (주)트립비토즈 (특허문헌 0002) 미국 등록특허 US 10346402 B2, Optimized system and method for finding best fares, Expedia, Inc. (특허문헌 0003) 미국 등록특허 US 7783506 B2, System and method for managing reservation requests for one or more inventory items, Expedia, Inc. (특허문헌 0004) 미국 등록특허 US 6826543 B1, System and method for conducting transactions involving generically identified items, Hotels.com (특허문헌 0005) 미국 공개특허 US 2016-0078374 A1, GRAPHICAL USER INTERFACE FOR HOTEL SEARCH SYSTEMS, GOOGLE INC. (특허문헌 0006) 미국 공개특허 US 2013-0031506 A1, HOTEL RESULTS INTERFACE, GOOGLE INC."}
{"patent_id": "10-2021-0089286", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인스타그램, 페이스북, 틱톡, 스냅, 스노우 등의 소셜 네트워크가 영상 기반으로 발달하게 됨에 따라 여행 산업 에서의 여행지 경험을 제공하는 방식이 영상 기반으로 전향되어야 할 필요성이 증대되고 있었다. 이러한 영상 기반 여행 경험 제공의 측면에서, 여행 설계의 새로운 소비 경험을 제공하는 방법 중 하나로 여행 크리에이터들 이 각종 소셜 네트워크나 여행 서비스 상에서 여행 영상을 사용자들에게 제공하는 방법이 있다. 여행 영상(동영 상 또는 이미지)을 소셜 네트워크/여행 서비스 상에 업로드하는 여행 크리에이터들이 창출할 수 있는 기존의 수 익은 광고 수익(배너 광고, PPL 광고, 기획 영상 광고, 영상 전 광고 등)에 한정되어 있었고, 업로드 한 여행 영상에서부터 여행 상품의 판매가 발생하는 경우에 보상을 제공하여 여행 상품의 구매를 효율적으로 유도하는 여행 영상들의 생산을 촉진하는 여행 서비스 시스템은 나타나지 않았다. 이러한 여행 서비스 시스템을 효과적으 로 구성하기 위해서는 여행 영상을 사용자의 니즈에 따라 분류하는 것이 필요하였다. 따라서, 본 발명의 목적은, 여행 영상의 생성자가 업로드 한 여행 영상을 여행자의 니즈에 따라 구분되는 구역 으로 분류하는 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치 및 방법을 제공하는데에 있다."}
{"patent_id": "10-2021-0089286", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이하 본 발명의 목적을 달성하기 위한 구체적 수단에 대하여 설명한다. 본 발명의 목적은, 생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행 영상 및 상기 여행 영상의 위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 모듈; 연속된 복수의 상기 여 행 영상 프레임을 입력 데이터로 하고, 상기 여행 영상 프레임에서의 촬영 방향 벡터의 시작점의 가속도의 크기 또는 촬영 방향 벡터의 각속력을 포함하는 움직임 정보를 출력 데이터로 출력하도록 기학습된 인공신경망을 포 함하고, 복수의 상기 여행 영상 프레임 각각에 대해 상기 움직임 정보를 생성하는 움직임 정보 출력 모듈; 상기 여행 영상 프레임의 상기 움직임 정보를 프레임 순서로 나열할 때, 상대적으로 낮은 상기 움직임 정보를 갖는프레임 구간을 적어도 하나 이상 선정하고, 상기 프레임 구간 중에서 매 프레임의 상기 움직임 정보와 기준 움 직임 정보의 차이를 합산한 값이 가장 큰 프레임 구간을 상기 여행 영상을 대표하는 구간인 대표 구간으로 선정 하는 대표 구간 선정 모듈; 상기 대표 구간 내에서 가장 낮은 움직임 정보를 갖는 프레임을 대표 프레임으로 선 정하는 대표 프레임 선정 모듈; 및 상기 대표 프레임을 입력 데이터로 하고 상기 대표 프레임 내에 포함된 오브 젝트에 대한 분류 정보인 Class 분류 정보 및 상기 오브젝트의 상기 대표 프레임 내 비율에 대한 정보인 오브젝 트 크기 정보를 출력 데이터로 하는 CNN 모듈을 포함하고, 상기 Class 분류 정보 및 상기 오브젝트 크기 정보를 입력 데이터로 하고 상기 위치 정보가 포함된 구역의 테마에 대한 분류 정보인 구역 분류 정보를 출력 데이터로 하는 인공신경망 모듈을 포함하며, 상기 여행 영상 및 상기 영상 정보에 대한 상기 구역 분류 정보를 출력하는 대표 프레임 분류 모듈;를 포함하는, 인공지능 기반의 여행 영상 분류 장치를 제공하여 달성될 수 있다. 본 발명의 다른 목적은, 여행 영상 수신 모듈이, 생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행 영상 및 상기 여행 영상의 위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 단계; 연속된 복수의 상기 여행 영상 프레임을 입력 데이터로 하고, 상기 여행 영상 프레임에서의 촬영 방향 벡 터의 시작점의 가속도의 크기 또는 촬영 방향 벡터의 각속력을 포함하는 움직임 정보를 출력 데이터로 출력하도 록 기학습된 인공신경망을 포함하는 움직임 정보 출력 모듈이, 복수의 상기 여행 영상 프레임 각각에 대해 상기 움직임 정보를 생성하는 움직임 정보 출력 단계; 대표 구간 선정 모듈이, 상기 여행 영상 프레임의 상기 움직임 정보를 프레임 순서로 나열할 때, 상대적으로 낮은 상기 움직임 정보를 갖는 프레임 구간을 적어도 하나 이상 선정하고, 상기 프레임 구간 중에서 매 프레임의 상기 움직임 정보와 기준 움직임 정보의 차이를 합산한 값이 가장 큰 프레임 구간을 상기 여행 영상을 대표하는 구간인 대표 구간으로 선정하는 대표 구간 선정 단계; 대표 프레임 선정 모듈이, 상기 대표 구간 내에서 가장 낮은 움직임 정보를 갖는 프레임을 대표 프레임으로 선정하는 대표 프레임 선정 단계; 및 상기 대표 프레임을 입력 데이터로 하고 상기 대표 프레임 내에 포함된 오브젝트에 대한 분류 정보인 Class 분류 정보 및 상기 오브젝트의 상기 대표 프레임 내 비율에 대한 정보인 오브젝트 크기 정보를 출력 데이터로 하는 CNN 모듈을 포함하고, 상기 Class 분류 정보 및 상기 오브젝트 크기 정보를 입력 데 이터로 하고 상기 위치 정보가 포함된 구역의 테마에 대한 분류 정보인 구역 분류 정보를 출력 데이터로 하는 인공신경망 모듈을 포함하는 대표 프레임 분류 모듈이, 상기 여행 영상 및 상기 영상 정보에 대한 상기 구역 분 류 정보를 출력하는 대표 프레임 분류 단계;를 포함하는, 인공지능 기반의 여행 영상 분류 방법을 제공하여 달 성될 수 있다. 본 발명의 다른 목적은, 여행 영상 분류 프로그램 코드를 포함하는 메모리 모듈; 및 상기 여행 영상 분류 프로 그램 코드를 수행하는 처리 모듈; 을 포함하고, 상기 여행 영상 분류 프로그램 코드는, 생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행 영상 및 상기 여행 영상의 위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 단계; 연속된 복수의 상기 여행 영상 프레임을 입력 데이터로 하고, 상기 여행 영상 프레임에서의 촬영 방향 벡터의 시작점의 가속도의 크기 또는 촬영 방향 벡터의 각속력을 포함하는 움직임 정보를 출력 데이터로 출력하도록 기학습된 인공신경망에 상기 여행 영상 프레임를 입력하여, 복수의 상 기 여행 영상 프레임 각각에 대해 상기 움직임 정보를 생성하는 움직임 정보 출력 단계; 상기 여행 영상 프레임 의 상기 움직임 정보를 프레임 순서로 나열할 때, 상대적으로 낮은 상기 움직임 정보를 갖는 프레임 구간을 적 어도 하나 이상 선정하고, 상기 프레임 구간 중에서 매 프레임의 상기 움직임 정보와 기준 움직임 정보의 차이 를 합산한 값이 가장 큰 프레임 구간을 상기 여행 영상을 대표하는 구간인 대표 구간으로 선정하는 대표 구간 선정 단계; 상기 대표 구간 내에서 가장 낮은 움직임 정보를 갖는 프레임을 대표 프레임으로 선정하는 대표 프 레임 선정 단계; 및 상기 대표 프레임을 입력 데이터로 하고 상기 대표 프레임 내에 포함된 오브젝트에 대한 분 류 정보인 Class 분류 정보 및 상기 오브젝트의 상기 대표 프레임 내 비율에 대한 정보인 오브젝트 크기 정보를 출력 데이터로 하는 CNN 모듈에 상기 대표 프레임을 입력하여 상기 Class 분류 정보 및 상기 오브젝트 크기 정 보를 출력하고, 상기 Class 분류 정보 및 상기 오브젝트 크기 정보를 입력 데이터로 하고 상기 위치 정보가 포 함된 구역의 테마에 대한 분류 정보인 구역 분류 정보를 출력 데이터로 하는 인공신경망 모듈에 상기 Class 분 류 정보 및 상기 오브젝트 크기 정보를 입력하여 상기 여행 영상 및 상기 영상 정보에 대한 상기 구역 분류 정 보를 출력하는 대표 프레임 분류 단계;를 포함한 단계를 컴퓨터 상에서 수행하도록 구성되는 것을 특징으로 하 는, 인공지능 기반의 여행 영상 분류 장치를 제공하여 달성될 수 있다. 본 발명의 다른 목적은, 생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행 영상 및 상기 여행 영상의 위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 모듈; 상기 여행 영상의 프레임 중 특정 프레임을 대표 프레임으로 선정하는 대표 프레임 선정 모듈; 상기 대표 프레임을 입력 데이터로 하고 상기 위치 정보가 포함된 구역의 테마에 대한 분류 정보인 제1구역 분류 정보를 출력 데이터로 하는 대표 프레임 분류 인공신경망 모듈을 포함하며, 상기 여행 영상 및 상기 영상 정보에 대한 상기 제1구역 분류 정보를 출력하는 대표 프레임 분류 모듈; 입력 데이터를 대표 프레임으로 하고 출력 데이터로 특징 클래스 정보(class probability) 및 특징 좌표 정보(coordinate data)를 포함하는 CNN 계열의 특징 추출 인공신경망을 포함하는 특 징 추출 모듈; 상기 대표 프레임 분류 모듈의 특정 컨볼루전 레이어(Convolution Layer)와 연결되어 클래스 별 액티베이션 맵(Activation map)을 의미하는 클래스 액티베이션 정보를 수신하고, 상기 클래스 액티베이션 정보 및 상기 특징 좌표 정보를 이용하여 각 클래스의 특징 중요도 정보를 생성하며, 생성된 상기 특징 중요도 정보 가 가장 큰 클래스를 코어 특징으로 선정하는 코어 특징 선정 모듈; 상기 대표 프레임 선정 모듈에서 선정된 상 기 대표 프레임의 전후 프레임들 중 상기 코어 특징을 포함하는 복수의 프레임을 후보 프레임으로 선정하는 후 보 프레임 선정 모듈; 및 상기 대표 프레임과 상기 후보 프레임을 상기 코어 특징을 기준으로 정합(stiching)하 여 파노라마 대표 프레임을 생성하는 프레임 정합 모듈;를 포함하고, 상기 프레임 정합 모듈에서 생성된 상기 파노라마 대표 프레임은 상기 대표 프레임 분류 모듈에 입력 데이터로 입력되어 제2구역 분류 정보를 출력 데이 터로 출력하도록 구성되는 것을 특징으로 하는. 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치를 제공하여 달성될 수 있다. 또한, 상기 특징 중요도 정보는, 각 클래스의 상기 특징 좌표 정보에 따른 바운딩 박스(bounding box) 범위 내 에 상기 클래스 액티베이션 정보의 hitmap이 포함되는 비율 또는 각 클래스의 상기 바운딩 박스 범위 내에서의 상기 클래스 액티베이션 정보의 액티베이션 값의 합을 포함하는 것을 특징으로 할 수 있다. 본 발명의 다른 목적은, 여행 영상 수신 모듈이, 생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행 영상 및 상기 여행 영상의 위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 단계; 대표 프레임 선정 모듈이, 상기 여행 영상의 프레임 중 특정 프레임을 대표 프레임으로 선정하는 대표 프 레임 선정 단계; 상기 대표 프레임을 입력 데이터로 하고 상기 위치 정보가 포함된 구역의 테마에 대한 분류 정 보인 제1구역 분류 정보를 출력 데이터로 하는 대표 프레임 분류 인공신경망 모듈을 포함하는 대표 프레임 분류 모듈이, 상기 여행 영상 및 상기 영상 정보에 대한 상기 제1구역 분류 정보를 출력하는 대표 프레임 분류 단계; 입력 데이터를 대표 프레임으로 하고 출력 데이터로 특징 클래스 정보(class probability) 및 특징 좌표 정보 (coordinate data)를 포함하는 CNN 계열의 특징 추출 인공신경망을 포함하는 특징 추출 모듈이, 상기 특징 클래 스 정보 및 상기 특징 좌표 정보를 출력하는 특징 추출 단계; 코어 특징 선정 모듈이, 상기 대표 프레임 분류 모듈의 특정 컨볼루전 레이어(Convolution Layer)와 연결되어 클래스 별 액티베이션 맵(Activation map)을 의미 하는 클래스 액티베이션 정보를 수신하고, 상기 클래스 액티베이션 정보 및 상기 특징 좌표 정보를 이용하여 각 클래스의 특징 중요도 정보를 생성하며, 생성된 상기 특징 중요도 정보가 가장 큰 클래스를 코어 특징으로 선정 하는 코어 특징 선정 단계; 후보 프레임 선정 모듈이, 상기 대표 프레임의 전후 프레임들 중 상기 코어 특징을 포함하는 복수의 프레임을 후보 프레임으로 선정하는 후보 프레임 선정 단계; 및 프레임 정합 모듈이, 상기 대 표 프레임과 상기 후보 프레임을 상기 코어 특징을 기준으로 정합(stiching)하여 파노라마 대표 프레임을 생성 하는 프레임 정합 단계;를 포함하고, 상기 파노라마 대표 프레임은 상기 대표 프레임 분류 모듈에 입력 데이터 로 입력되어 제2구역 분류 정보를 출력 데이터로 출력하도록 구성되는 것을 특징으로 하는. 영상의 파노라마 이 미지 변환을 이용한 여행 영상 분류 방법을 제공하여 달성될 수 있다. 본 발명의 다른 목적은, 여행 영상 분류 프로그램 코드를 포함하는 메모리 모듈; 및 상기 여행 영상 분류 프로 그램 코드를 수행하는 처리 모듈;을 포함하고, 상기 여행 영상 분류 프로그램 코드는, 생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행 영상 및 상기 여행 영상의 위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 단계; 상기 여행 영상의 프레임 중 특정 프레임을 대표 프레임으로 선정 하는 대표 프레임 선정 단계; 상기 대표 프레임을 입력 데이터로 하고 상기 위치 정보가 포함된 구역의 테마에 대한 분류 정보인 제1구역 분류 정보를 출력 데이터로 하는 대표 프레임 분류 인공신경망 모듈이 상기 여행 영 상 및 상기 영상 정보에 대한 상기 제1구역 분류 정보를 출력하는 대표 프레임 분류 단계; 입력 데이터를 대표 프레임으로 하고 출력 데이터로 특징 클래스 정보(class probability) 및 특징 좌표 정보(coordinate data)를 포함하는 CNN 계열의 특징 추출 인공신경망이 상기 특징 클래스 정보 및 상기 특징 좌표 정보를 출력하는 특징추출 단계; 상기 대표 프레임 분류 인공신경망 모듈의 특정 컨볼루전 레이어(Convolution Layer)와 연결되어 클 래스 별 액티베이션 맵(Activation map)을 의미하는 클래스 액티베이션 정보를 수신하고, 상기 클래스 액티베이 션 정보 및 상기 특징 좌표 정보를 이용하여 각 클래스의 특징 중요도 정보를 생성하며, 생성된 상기 특징 중요 도 정보가 가장 큰 클래스를 코어 특징으로 선정하는 코어 특징 선정 단계; 상기 대표 프레임의 전후 프레임들 중 상기 코어 특징을 포함하는 복수의 프레임을 후보 프레임으로 선정하는 후보 프레임 선정 단계; 및 상기 대 표 프레임과 상기 후보 프레임을 상기 코어 특징을 기준으로 정합(stiching)하여 파노라마 대표 프레임을 생성 하는 프레임 정합 단계;를 포함한 단계를 컴퓨터 상에서 수행하도록 구성되는 것을 특징으로 하고, 상기 파노라 마 대표 프레임은 상기 대표 프레임 분류 모듈에 입력 데이터로 입력되어 제2구역 분류 정보를 출력 데이터로 출력하도록 구성되는 것을 특징으로 하는, 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치를 제공 하여 달성될 수 있다. 본 발명의 다른 목적은, 여행 영상 수신 모듈이, 생성자 클라이언트에서 생성되고 시계열의 복수의 여행 영상 프레임으로 구성된 여행 영상 및 상기 여행 영상의 위치 정보를 포함하는 영상 정보를 수신하는 여행 영상 수신 단계; 대표 프레임 선정 모듈이, 상기 여행 영상의 프레임 중 특정 프레임을 대표 프레임으로 선정하는 대표 프 레임 선정 단계; 상기 대표 프레임을 입력 데이터로 하고 상기 위치 정보가 포함된 구역의 테마에 대한 분류 정 보인 제1구역 분류 정보를 출력 데이터로 하는 대표 프레임 분류 인공신경망 모듈을 포함하는 대표 프레임 분류 모듈이, 상기 여행 영상 및 상기 영상 정보에 대한 상기 제1구역 분류 정보를 출력하는 대표 프레임 분류 단계; 입력 데이터를 대표 프레임으로 하고 출력 데이터로 특징 클래스 정보(class probability) 및 특징 좌표 정보 (coordinate data)를 포함하는 CNN 계열의 특징 추출 인공신경망을 포함하는 특징 추출 모듈이, 상기 특징 클래 스 정보 및 상기 특징 좌표 정보를 출력하는 특징 추출 단계; 코어 특징 선정 모듈이, 상기 대표 프레임 분류 모듈의 특정 컨볼루전 레이어(Convolution Layer)와 연결되어 클래스 별 액티베이션 맵(Activation map)을 의미 하는 클래스 액티베이션 정보를 수신하고, 상기 클래스 액티베이션 정보 및 상기 특징 좌표 정보를 이용하여 각 클래스의 특징 중요도 정보를 생성하며, 생성된 상기 특징 중요도 정보가 가장 큰 클래스를 코어 특징으로 선정 하는 코어 특징 선정 단계; 후보 프레임 선정 모듈이, 상기 대표 프레임의 전후 프레임들 중 상기 코어 특징을 포함하는 복수의 프레임을 후보 프레임으로 선정하는 후보 프레임 선정 단계; 및 프레임 정합 모듈이, 상기 대 표 프레임과 상기 후보 프레임을 상기 코어 특징을 기준으로 정합(stiching)하여 파노라마 대표 프레임을 생성 하는 프레임 정합 단계;를 포함한 단계를 컴퓨터 상에서 수행하도록 구성되는 것을 특징으로 하고, 상기 파노라 마 대표 프레임은 상기 대표 프레임 분류 모듈에 입력 데이터로 입력되어 제2구역 분류 정보를 출력 데이터로 출력하도록 구성되는 것을 특징으로 하는. 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 방법을 컴퓨 터 상에서 수행하도록 구성되는 기록매체에 저장된 프로그램을 제공하여 달성될 수 있다."}
{"patent_id": "10-2021-0089286", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같이, 본 발명에 의하면 이하와 같은 효과가 있다. 첫째, 본 발명의 일실시예에 따르면, 여행 영상을 사용자의 니즈에 따라 구분되는 구역으로 분류하는 것이 가능 해지는 효과가 발생된다. 둘째, 본 발명의 일실시예에 따르면, 여행 영상을 업로드 한 생성자에게 여행 영상의 구역 분류 정보에 따라 리 워드를 달리 할 수 있는 효과가 발생된다."}
{"patent_id": "10-2021-0089286", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작원리를 상세하게 설명함에 있 어서 관련된 공지기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 특정 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 특정 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하 발명의 설명에서 컨볼루져널 곱을 활용한 Neural Network인 Convolutional Neural Network은 CNN, ConvNet 등으로 기재될 수 있다. 이하 발명의 설명에서는 설명의 편의에 따라 호텔 예약을 기준으로 기술하였지만, 본 발명의 범위는 호텔 예약 에 한정되지 않고 민박, 호스텔, 모텔, 호텔의 타임커머스, 액티비티, 패키지 여행, 가이드, 렌트카 등의 모든 여행 상품에 대한 범위를 포함할 수 있다. 이하에서 여행 영상이란, 특정 여행 지역에서 촬영된 다양한 압축 방식, 다양한 코덱의 시청각 정보를 의미할 수 있다. 인공지능 기반의 여행 영상 분류 장치 도 1은 본 발명의 일실시예에 따른 인공지능 기반의 여행 영상 분류 장치를 도시한 모식도이다. 도 1에 도시된 바와 같이, 본 발명의 일실시예에 따른 인공지능 기반의 여행 영상 분류 장치는 여행 영상 수신 모듈, 움직임 정보 출력 모듈, 대표 구간 선정 모듈, 대표 프레임 선정 모듈, 대표 프레임 분류 모듈을 포함할 수 있다. 도 2는 본 발명의 일실시예에 따른 인공지능 기반의 여행 영상 분류 장치의 작동관계를 도시한 모식도이다. 도 2에 도시된 바와 같이, 여행 영상을 생성하는 유저(여행 크리에이터)인 생성자의 클라이 언트(생성자 클라이언트, 100)에 구성된 애플리케이션 모듈에서 여행 영상을 생성하여 인공지능 기반의 여행 영 상 분류 장치의 여행 영상 수신 모듈에 송신하고, 여행 영상 수신 모듈에서는 수신된 여행 영상의 각 프레임인 여행 영상 프레임을 움직임 정보 출력 모듈에 송신한다. 움직임 정보 출력 모듈에서는 연 속된 복수의 여행 영상 프레임을 기초로 움직임 정보를 생성하고, 대표 구간 선정 모듈에서는 프레임 별 움 직임 정보를 기초로 연속된 여행 영상 프레임을 복수의 구간으로 구분하고, 복수의 구간들 중 대표 구간을 선정 하여 대표 구간 정보를 생성하게 된다. 대표 프레임 선정 모듈에서는 대표 구간 정보 내에서의 특정 여행 영상 프레임을 대표 프레임으로 선정하여 대표 프레임 정보를 생성하고, 대표 프레임 분류 모듈에서는 대표 프레임 정보에 대응되는 대표 프레임을 입력 받고 구역 분류 정보를 출력 하도록 구성될 수 있다. 각 구성에 대 한 구체적인 설명 및 실시예는 다음과 같다. 여행 영상 수신 모듈은 생성자 클라이언트에서 송신된 여행 영상 및 영상 정보를 생성자 클라이언트 의 애플리케이션 모듈에서 수신하는 모듈이다. 본 발명의 일실시예에 따른 여행 영상은 시계열로 구성된 복수의 여행 영상 프레임으로 구성되고, 영상 정보는 해당 여행 영상의 생성자 정보, 위치 정보, 시간 정보, 오 디오 형식 정보, 오디오 샘플 레이트(예를 들어, 헤르츠 단위), 오디오 스트림 채널 개수 정보, 파일명 정보, 크기 정보, 총 프레임 수 정보, 초당 프레임 수 정보, 영상 높이 정보(예를 들어, 픽셀 단위), 영상 너비 정보 (예를 들어, 픽셀 단위), 이미지 유형 정보, 압축 코덱 정보 등을 포함할 수 있다. 본 발명의 일실시예에 따른 여행 영상은 여행 영상의 생성자인 여행 크리에이터가 생성자 클라이언트의 카메라를 통해 촬영한 영상 또 는 생성자 클라이언트에 기저장된 영상을 포함할 수 있다. 본 발명의 다른 실시예에 따르면, 생성자 클라 이언트에서 여행 영상을 수신한 서버 또는 데이터베이스에서 여행 영상 및 영상 정보를 여행 영상 수신 모 듈에 송신하도록 구성될 수 있다. 움직임 정보 출력 모듈은 여행 영상 프레임을 프레임 시간 순서로 수신하고, 연속된 2개의 여행 영상 프레 임을 입력 데이터로 하여 움직임 정보를 출력하도록 기학습된 인공신경망을 포함하는 모듈이다. 도 3은 본 발명 의 일실시예에 따른 움직임 정보 출력 모듈의 작동관계를 도시한 모식도이다. 도 3에 도시된 바와 같이, 움 직임 정보 출력 모듈은 연속된 2개의 여행 영상 프레임을 입력 데이터로 하고, 움직임 정보를 출력 데이터 로 하는 인공신경망 모듈을 포함하도록 구성될 수 있고, 프레임 순서에 따라 움직임 정보를 출력하도록 구성될 수 있다. 이때, 2개의 여행 영상 프레임이 입력 데이터로 입력되는 것은 본 발명의 일실시예이며, 본 발명의 범 위는 복수개의 여행 영상 프레임이 입력 데이터로 입력되는 것을 포함할 수 있다. 도 3에 도시된 바와 같이, 본 발명의 일실시예에 따른 움직임 정보 출력 모듈에서는 여행 영상 프레임 t-3 및 t-2가 입력 데이터로 입력 되어 움직임 정보 t-2가 출력되고, 여행 영상 프레임 t-2 및 t-1이 입력 데이터로 입력되어 움직임 정보 t-1이 출력되고, 여행 영상 프레임 t-1 및 t가 입력 데이터로 입력되어 움직임 정보 t가 출력되도록 구성될 수 있다. 움직임 정보는, 촬영하는 카메라(일 실시예에 따르면 생성자 클라이언트에 구성된 카메라, 촬영 방향 벡터의 시 작점)의 가속도의 크기(scalar 값, magnitude of acceleration), 촬영 방향 벡터의 각속력(scalar 값, angular speed) 또는 촬영하는 카메라의 가속도의 크기와 촬영 방향 벡터의 각속력을 병합한 값을 의미할 수 있다. 움직 임 정보 출력 모듈의 학습 세션에서 손실(Loss) 계산을 위한 움직임 정보의 레퍼런스 정보인 비교 데이터는 생성자 클라이언트의 가속도 센서, 자이로 센서의 센싱 값으로 계산될 수 있다. 예를 들어, 상기 카메라의 가속도의 크기는 움직임 정보 출력 모듈이 생성자 클라이언트의 가속도 센서에서 출력되는 가속도 벡 터의 크기로 계산할 수 있고, 구체적으로는 가속도 센서의 x축 출력값(d2x/dt2, x는 x축 변위 벡터), y축 출력값 (d2y/dt2, y는 y축 변위 벡터) 및 z축 출력값(d2z/dt2, z는 z축 변위 벡터) 각각을 제곱하여 더한 후 제곱근을 씌워서 계산될 수 있다. 또한, 상기 촬영 방향 벡터의 각속력은 움직임 정보 출력 모듈이 생성자 클라이언 트의 자이로 센서에서 출력되는 각속도 벡터의 크기로 계산할 수 있고, 구체적으로는 자이로 센서의 x축 출력값(dθx/dt, θx는 x축 회전각), y축 출력값(dθy/dt, θy는 y축 회전각) 및 z축 출력값(dθz/dt, θz는 z축 회전각) 각각을 제곱하여 더한 후 제곱근을 씌워서 계산될 수 있다. 움직임 정보 출력 모듈의 인공신경망 학습 세션(training session)에서는 움직임 정보 출력 모듈이 연 속된 복수개의 여행 영상 프레임을 입력 데이터로 입력 받고, 입력된 여행 영상 프레임들 중에서 특정 프레임에대한 움직임 정보를 출력 데이터로 출력 한 뒤, 상기 특정 프레임에 대하여 기계산된 움직임 정보인 비교 데이 터와 출력 데이터의 차이를 기초로 한 손실함수 계산을 통해 출력 데이터의 비교 데이터에 대한 손실이 감소되 는 방향으로 움직임 정보 출력 모듈의 weight 등 파라미터를 업데이트 하도록 구성될 수 있다. 이때, 본 발 명의 일실시예에 따른 움직임 정보 출력 모듈의 손실함수는 크로스 엔트로피 손실함수(Cross-entropy loss function), Contrastive loss function, Center loss function 등이 활용될 수 있다. 움직임 정보 출력 모듈의 인공신경망 추론 세션(inference session)에서는 움직임 정보 출력 모듈이 연 속된 복수개의 여행 영상 프레임을 입력 데이터로 입력 받고, 입력된 여행 영상 프레임들 중에서 특정 프레임에 대한 움직임 정보를 출력 데이터로 출력 하도록 구성될 수 있다. 이에 따르면, 생성자 클라이언트에서 가속도 센서 출력값과 자이로 센서 출력값을 매 프레임 별로 수신하 지 않아도 되어, 애플리케이션 모듈이 단순해지고 송수신 정보의 규모 및 처리 하여야 하는 정보의 규모가 저감 되는 효과가 발생된다. 본 발명의 다른 실시예에 따르면, 움직임 정보 출력 모듈은 강화학습 모듈을 포함할 수 있다. 도 4는 본 발 명의 다른 실시예에 따른 강화학습 모듈을 포함한 움직임 정보 출력 모듈을 도시한 모식도이다. 도 4에 도 시된 바와 같이, 본 발명의 다른 실시예에 따른 움직임 정보 출력 모듈의 강화학습 모듈은, 여행 영상을 Environment, 상기 움직임 정보 출력 모듈을 Agent로 하고, 입력 데이터인 연속된 복수의 여행 영상 프레임 을 State로 하며, 이러한 State에서 Agent인 움직임 정보 출력 모듈이 특정 프레임에 대해 출력하는 움직임 정보(출력 데이터)를 Action으로 하고, 출력 데이터와 비교 데이터와의 차이가 적을수록 높은 Reward가 생성되 어 Agent인 움직임 정보 출력 모듈을 업데이트 하도록 구성될 수 있다. 대표 구간 선정 모듈은 움직임 정보 출력 모듈에서 여행 영상 프레임 각각에 대해 생성된 움직임 정보 를 기초로 상대적으로 낮은 카메라 움직임을 보이는 연속된 여행 영상 프레임으로 구성된 프레임 구간을 적어도 하나 이상 선정하고, 해당 구간 중에서 상기 여행 영상을 대표하는 구간인 대표 구간을 선정하는 모듈이다. 도 5는 대표 구간 선정 모듈의 대표 구간 선정을 도시한 모식도이다. 도 5에 도시된 바와 같이 움직임 정보 출 력 모듈에서 여행 영상 프레임 각각에 대해 생성된 움직임 정보를 프레임 순서에 따라 나열하였을 때, 복수 개의 프레임 구간을 선정하고, 해당 프레임 구간들 중에서 대표 구간을 선정하도록 구성될 수 있다. 본 발명의 일실시예에 따른 대표 구간 선정 모듈의 구체적인 대표 구간 선정 방법은 아래와 같다. 특정 움직임 정보(기준 움직임 정보) 이하의 움직임 정보를 갖는 연속된 복수개의 프레임으로 구성되는 적 어도 하나 이상의 프레임 구간을 선정 선정된 프레임 구간이 하나인 경우, 해당 프레임 구간을 대표 구간으로 선정 선정된 프레임 구간이 복수 인 경우, 선정된 복수의 프레임 구간 중 매 프레임의 움직임 정보와 기준 움직 임 정보와의 차이를 합산한 값이 가장 큰 프레임 구간을 대표 구간으로 선정 이에 따르면, 여행 크리에이터인 생성자가 생성한 여행 영상에서의 주요 콘텍스트를 포함하는 프레임 구간을 계 산 부하가 낮은 알고리즘으로 자동으로 추출할 수 있게 되는 효과가 발생된다. 대표 프레임 선정 모듈은 대표 구간 선정 모듈에서 선정된 대표 구간 내에서 대표 프레임을 선정하는 모듈이다. 본 발명의 일실시예에 따르면 대표 구간 내에서 가장 낮은 움직임 정보를 갖는 프레임을 대표 프레임 으로 선정하고 대표 프레임 정보를 생성하도록 구성될 수 있다. 대표 구간 선정 모듈과 대표 프레임 선정 모듈에 따르면, 순간적으로 카메라가 정지한 경우에 대표 프 레임으로 선정되는 경우를 방지할 수 있게 되는 효과가 발생된다. 또한, 여행 크리에이터인 생성자가 생성한 여 행 영상에서의 주요 콘텍스트를 포함하는 대표 프레임을 계산 부하가 낮은 알고리즘으로 자동으로 추출할 수 있 게 되는 효과가 발생된다. 기존에는 여행 영상의 콘텍스트를 대표하는 프레임을 추출하는 작업을 생성자가 직접 수행할 수 밖에 없었다. 대표 프레임 분류 모듈은 대표 프레임 선정 모듈에서 선정된 대표 프레임을 입력 데이터로 하고, 구역 분류 정보를 출력 데이터로 하는 인공신경망 모듈을 의미할 수 있다. 구역 분류 정보는, 해당 영상 정보가 촬영된 구역의 테마에 대한 분류 정보를 의미한다. 예를 들어, 노는 존(Zone), 마시는 존, 먹는 존, 보는 존, 쇼핑 존 등의 구역 분류를 의미할 수 있다. 본 발명의 일실시예에 따른 노는 존은 클럽, 해수욕장, 수영장 등이 포함 된 구역, 마시는 존은 와인 바, 칵테일 바, 비어 펍, 바틀샵 등이 포함된 구역, 먹는 존은 각종 레스토랑, 해당 지역 맛집이나 길거리 음식이 포함된 구역, 보는 존은 각종 관광 구역이나 자연경관 구역이 포함된 구역, 쇼핑 존은 명품 매장, 백화점, 아울렛, 면세 매장, 기념품점, 길거리 쇼핑 등이 포함된 구역을 의미할 수 있다. 대표 프레임 분류 모듈의 구성과 관련하여, 도 6은 본 발명의 일실시예에 따른 대표 프레임 분류 모듈 의 구성을 도시한 모식도이다. 도 6에 도시된 바와 같이, 본 발명의 일실시예에 따른 대표 프레임 분류 모듈 은 복수의 CNN 모듈 및 구역 분류 인공신경망 모듈을 포함할 수 있다. 대표 프레임 분류 모듈의 복수의 CNN 모듈은 서로 다른 학습 데이터로 학습되거나, 서로 다른 파라미터를 갖는 네트워크로 구성된다. 도 7은 본 발명의 일실시예에 따른 제nCNN 모듈을 도시한 모식도이다. 도 7에 도시 된 바와 같이, 본 발명의 일실시예에 따른 제nCNN 모듈의 입력 레이어(input layer)는 소스 데이터로서 대표 프 레임이 입력되게 되고, 예를 들어 가로 32, 세로 32, 높이 n의 채널을 가지고 입력의 크기는 [32x32xn]인 매트 릭스로 구성될 수 있다. CONV 레이어(Conv. layer)는 Conv. Filter에 의해 소스 데이터인 대표 프레임의 일부 영역과 연결되어 계산되며, 이 연결된 영역과 가중치의 내적 연산(dot product)을 계산하게 되고, 예를 들어 Conv. layer의 볼륨은 [32x32x12]와 같은 크기를 갖게 된다. 이후 RELU 레이어 등의 Activation 함수가 계산되 며, RELU는 max(0,x)와 같이 각 요소에 적용되는 액티베이션 함수(activation function)이고, 볼륨의 크기를 변화시키지 않으며(예를 들어, 여전히 [32x32x12]) Activation map을 생성한다. POOL 레이어(pooling layer)는 \"가로,세로\" 차원에 대해 다운샘플링(downsampling)을 수행하고, 예를 들어 [16x16x12]와 같이 줄어든 볼륨 (Activation map)을 출력한다. n번째 Activation map n)과 연결된 FC(fully-connected) 레이어 이후 클래스 점 수들을 계산하여, 예를 들어 [m x m x 1]의 크기를 갖는 제n분류 정보를 포함하는 볼륨(output layer)을 출력한 다. 본 발명의 일실시예에 따른 분류 정보는 대표 프레임 내에 포함된 오브젝트에 대한 분류 정보를 의미할 수 있고, 각각의 CNN 모듈에서 적어도 하나 이상 출력되도록 구성될 수 있다. 본 발명의 일실시예에 따른 복수의 CNN 모듈의 분류 정보는 검출된 오브젝트의 분류 된 Class에 대한 정보 (Class 분류 정보) 및 해당 오브젝트가 입력된 대표 프레임 내에서 차지하는 비율에 대한 정보(오브젝트 크기 정보)를 포함하는 텐서(tensor)로 구성될 수 있고, 손실함수는 Class 손실함수와 오브젝트 크기 손실함수를 포 함할 수 있다. CNN 모듈의 손실함수는 CNN 모듈의 학습 세션에서 인공신경망의 weight를 업데이트 하기 위해 활 용되며, 손실함수를 최소(global minimum 또는 local minimum)로 하도록 CNN 모듈의 weight를 업데이트 할 수 있다. Class 손실함수는 대표 프레임이 입력된 CNN 모듈에서 출력되는 분류 정보 내에 포함된 Class 분류 정보 와 대표 프레임 내에 포함된 실제 오브젝트의 Class 분류 정보인 ground truth(비교 데이터)와의 차이를 의미할 수 있다. 오브젝트 크기 손실함수는 대표 프레임이 입력된 CNN 모듈에서 출력되는 분류 정보 내에 포함된 오브 젝트 크기 정보와 대표 프레임 내에 포함된 실제 오브젝트가 대표 프레임 내에서 차지하는 비율인 ground truth(비교 데이터)와의 차이를 의미할 수 있다. 본 발명의 일실시예에 따른 Class 분류 정보는, 예를 들어, 하 늘, 바다, 수영장, 음식, 음료, 테이블, 의자, 자동차, 자전거, 사람 등의 오브젝트에 대한 class를 분류한 정 보를 의미할 수 있다. 본 발명의 일실시예에 따른 오브젝트 크기 정보는 30%, 4% 등의 비율을 의미할 수 있다. 또한, 본 발명의 일실시예에 따른 복수의 CNN 모듈은 각각 서로 다른 학습 데이터를 통해 서로 다른 오브젝트를 분류하도록 학습될 수 있다. 이러한 학습 데이터 및 손실함수의 구성에 따라, 복수의 CNN 모듈에서는 각각 서로 다른 특정 오브젝트에 대한 Class와 해당 오브젝트의 크기를 출력하도록 구성될 수 있다. 본 발명의 다른 실시예에 따르면, 복수의 CNN 모듈 대신에 YOLO, R-CNN 등의 멀티플 오브젝트 디텍션을 위한 CNN 아키텍쳐가 구성될 수 있고, 출력 데이터 및 손실함수는 본 발명의 일실시예에 따른 복수의 CNN 모듈의 출 력 데이터 tensor(Class 분류 정보 및 오브젝트 크기 정보) 및 손실함수(Class 손실함수 및 오브젝트 크기 손실 함수)가 준용될 수 있다. 대표 프레임 분류 모듈의 구역 분류 인공신경망 모듈은 복수의 CNN 모듈에서 출력된 복수의 오브젝트에 대 한 복수의 분류 정보(Class 분류 정보 및 오브젝트 크기 정보)를 입력 데이터로 하고, 구역 분류 정보를 출력 데이터로 하는 인공신경망으로 구성될 수 있다. 도 8은 본 발명의 일실시예에 따른 분류 인공신경망 모듈을 도 시한 모식도이다. 도 8에 도시된 바와 같이, 복수의 CNN 모듈에서 출력된 복수의 분류 정보(제1분류 정보, 제2분류 정보, ... , 제n분류 정보)를 입력 데이터로 하고 구역 분류 정보를 출력 정보로 하는 인공신경망으로 구 성될 수 있다. 본 발명의 일실시예에 따른 구역 분류 인공신경망 모듈의 학습 세션(training session)에서는, 대표 프레임이 입력된 복수의 CNN 모듈에서 출력된 분류 정보를 입력 데이터로 구역 분류 인공신경망 모듈에 입력하고, 구역 분류 인공신경망 모듈에서 출력 데이터로서 출력 된 구역 분류 정보와 해당 여행 영상의 실제 구역 분류 정보 (비교 데이터, ground truth)의 차이를 기초로 back propagation 등의 학습 방법으로 구역 분류 인공신경망 모 듈의 hidden layer의 weight를 업데이트 하도록 구성될 수 있다. 본 발명의 일실시예에 따른 구역 분류 인공신경망 모듈의 추론 세션(inference session)에서는, 대표 프레임이 입력된 복수의 CNN 모듈에서 출력된 분류 정보를 입력 데이터로 구역 분류 인공신경망 모듈에 입력하고, 구역 분류 인공신경망 모듈에서 출력 데이터로서 출력 된 구역 분류 정보를 해당 여행 영상의 구역 분류 정보로서 활 용하도록 구성될 수 있다. 예를 들어, 복수의 CNN 모듈에서 분류 정보가 (음식, 12%), (테이블, 30%), (사람, 20%), (수저, 3%) 등으로 출력되고, 해당 분류 정보를 구역 분류 인공신경망 모듈에 입력하였을 때, 구역 분류 인공신경망 모듈에서는 ' 먹는 존'으로 구역 분류 정보가 출력되도록 구성될 수 있다. 이에 따르면, 대표 프레임을 입력받고 구역 분류 정보를 출력하는 하나의 CNN 모듈로 구성하는 구조에 비해 적 은 학습 데이터 또는 각 Class 별로 데이터 양의 불균형이 심한 학습 데이터로도 최적화가 용이해지는 효과가 발생된다. 또한, 각 구역으로 분류될 수 있는 이미지나 영상은 매우 다양하기 때문에 CNN 아키텍쳐로 높은 분류 성능을 내기가 매우 어려운데, 본 발명의 일실시예에 따르면 CNN 모듈에 의해 출력된 분류 정보를 인공신경망 모듈로 재분류 함으로써 이러한 문제점이 해소되는 효과가 발생된다. 구역 분류 정보의 활용과 관련하여, 도 9는 본 발명의 일실시예에 따른 구역 분류 인공신경망 모듈에 의해 출력 된 구역 분류 정보를 여행 지역의 지도에 매핑한 모식도이다. 도 9에 도시된 바와 같이, 본 발명의 일실시예에 따른 구역 분류 정보는 영상 정보 내에 포함된 위치 정보를 기초로 특정 여행 지역의 지도에 매핑되고, 해당 애 플리케이션 모듈이 구성된 사용자 클라이언트의 디스플레이에 구역 분류 정보를 포함한 여행 지역의 지도 정보 를 출력하게 되며, 사용자는 해당 지도 정보를 토대로 원하는 테마를 즐기기 위하여 해당 위치로 이동하거나, 애플리케이션 모듈을 통해 원하는 테마에 관한 구역의 정보를 온라인으로 취득할 수 있게 된다. [변형예 - 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치] 본 발명의 변형예에 따른 여행 영상 분류 장치인 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치와 관련하여, 도 10은 본 발명의 변형예에 따른 여행 영상 분류 장치인 영상의 파노라마 이미지 변환을 이용한 여 행 영상 분류 장치를 도시한 모식도, 도 11은 본 발명의 변형예에 따른 여행 영상 분류 장치인 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치의 작동관계를 도시한 모식도이다. 도 10, 11에 도시된 바와 같이, 본 발명의 변형예에 따른 여행 영상 분류 장치인 영상의 파노라마 이미지 변환을 이용한 여행 영상 분류 장치에 따르면, 본 발명의 일실시예에 따른 인공지능 기반의 여행 영상 분류 장치에 특징 추출 모듈, 코어 특징 선정 모듈, 후보 프레임 선정 모듈, 프레임 정합 모듈을 더 포함하고, 대표 프레임 선정 모듈 의 대표 프레임 선정 이후 특징 추출 모듈, 코어 특징 선정 모듈, 후보 프레임 선정 모듈, 프레임 정합 모듈에 의해 대표 프레임이 파노라마 이미지로 변환된 형태인 파노라마 대표 프레임을 생성하고, 생성 된 파노라마 대표 프레임을 대표 프레임 분류 모듈에 입력하는 것을 특징으로 할 수 있다. 특징 추출 모듈과 관련하여, 도 12는 본 발명의 변형예에 따른 여행 영상 분류 장치의 일구성인 특징 추출 모듈의 구조를 도시한 모식도이다. 도 12에 도시된 바와 같이, 특징 추출 모듈은 상기 대표 프레임 선 정 모듈에서 선정된 대표 프레임의 오브젝트 특징을 추출하는 특징 추출 인공신경망 모듈을 포함하고, 상기 특징 추출 인공신경망 모듈은 입력 데이터를 대표 프레임 또는 후보 프레임으로 하고 출력 데이터로 특징 클래 스 정보(class probability) 및 특징 좌표 정보(coordinate data)를 포함하는 ConvNet 계열의 인공신경망으로 구성될 수 있다. 본 발명의 일실시예에 따른 특징 추출 인공신경망 모듈은 classification과 localization을 수행하는 multi- object detection 인공신경망 모듈을 포함할 수 있고, 이러한 multi-object detection 인공신경망 모듈로는 2- stage detector로서 RCNN, OverFeat(ICLR 2014), Fast RCNN(ICCV 2015), Faster RCNN(NIPS 2015), Mask RCNN(ICCV 2017) 등이 활용될 수 있고, 1-stage detector로서 anchor based의 YOLO v1(CVPR 2016), YOLO v2(CVPR 2017), YOLO v3(arXiv 2018), SSD(ECCV 2016), RetinaNet(ICCV 2017) 등이 활용될 수 있으며, 1- stage detector로서 non-anchor based의 CornerNet(ECCV 2018), ExtreamNet, CenterNet 등이 활 용될 수 있다. 본 발명의 일실시예에 따른 특징 추출 인공신경망 모듈의 출력 데이터는, 적어도 하나 이상의 object에 대한 특 정 class와 그 신뢰도를 의미하는 특징 클래스 정보(confidence score 또는 class probability), 해당 object 의 특징 좌표 정보(coordinate data)를 포함할 수 있고, object의 특징 좌표 정보는 인공신경망의 구성에 따라 bounding box의 top-left coner와 bottom-right coner의 좌표, bounding box의 centeral region 좌표, bounding box의 width 및 hight를 포함하도록 구성될 수 있다. 도 13은 본 발명의 변형예에 따른 특징 추출 인공신경망 모듈이 YOLO v1(CVPR 2016)으로 구성되는 경우의 구조 를 도시한 모식도이다. 예를 들어, 도 13에 도시된 바와 같이 본 발명의 변형예에 따른 특징 추출 인공신경망 모듈을 YOLO v1(CVPR 2016)으로 구성하는 경우, DarkNet Architecture를 사용하게 되며, convolution layer들 을 통해 feature map을 추출하고, fully connected layer를 거쳐 바로 bounding box의 coordinate data(특징 좌표 정보)와 class probability(class confidence, 특징 클래스 정보)를 추론(inference)하여 출력 데이터로 서 출력하도록 구성된다. YOLO에서는 input 이미지인 대표 프레임 또는 후보 프레임을 SxS grid로 나누고 각 grid 영역에 해당하는 bounding box(SxSxB개)와 Class confidence(Probability(object)×IoU(prediction, ground truth)), Class probability map(Probability(Class_i|object))을 구하도록 구성된다. 구체적인 네트워 크 구조를 예를 들면, 한 grid 영역당 5개의 bounding box coordinate(특징 좌표 정보)와 confidence score(특 징 클래스 정보)를 출력하도록 구성될 수 있고, 대표 프레임 또는 후보 프레임은 448x448x3의 크기로 입력되도 록 구성될 수 있으며, DarkNet Architecture의 Activation map은 7x7x1024의 크기로 구성될 수 있고, DarkNet Architecture 이후 4096 및 7x7x30의 Fully Connected Layer가 구성될 수 있다. 코어 특징 선정 모듈과 관련하여, 도 14는 본 발명의 변형예에 따른 코어 특징 선정 모듈의 작동관계를 도시한 모식도이다. 도 14에 도시된 바와 같이, 코어 특징 선정 모듈은 대표 프레임 분류 모듈의 제 nCNN 모듈의 마지막 Conv.layer(Fully connected layer 이전의 Conv.layer)와 연결되어 대표 프레임 분류 모듈 의 입력 데이터가 대표 프레임일 때 Conv.layer에서 출력되는 적어도 한 차원 이상의 Activation map을 포 함하는 액티베이션 정보(좌표 별 액티베이션 값을 포함)를 입력받고, 특징 추출 모듈에 대표 프레임이 입력 데이터로 입력되어 출력 데이터로 출력되는 각 class의 coordinate data(특징 좌표 정보)를 입력받으며, 특징 추출 모듈에서 입력받은 각 class의 coordinate data(특징 좌표 정보) 또는 액티베이션 정보의 좌표를 대표 프레임의 크기와 activation map의 크기에 따라 조정하며, 각 class의 coordinate data(특징 좌표 정보)에 따 른 bounding box 범위 내에 대표 프레임 분류 모듈의 activation map의 hitmap이 포함되는 비율(액티베이 션 비율) 또는 activation weight(액티베이션 값)의 합을 각 class별 특징 중요도 정보로서 출력한다. 출력된 특징 중요도 정보가 가장 큰 class를 코어 특징으로 선정한다. 코어 특징 선정 모듈의 제2변형예와 관련하여, 도 15는 본 발명의 제2변형예에 따른 코어 특징 선정 모듈 의 작동관계를 도시한 모식도이다. 도 15에 도시된 바와 같이, 본 발명의 제2변형예에 따르면, 대표 프레임 분류 모듈이 구역 분류 정보를 출력 데이터로 출력하는 단일 컨볼루젼 네트워크로 구성된 인공신경망으로 구성되고, 코어 특징 선정 모듈과 대표 프레임 분류 모듈의 사이에 차원을 축소하는 클래스 액티베이션 생성 모듈을 더 포함하며, 제2변형예의 클래스 액티베이션 생성 모듈은 대표 프레임 분류 모듈의 마지막 Conv.layer(Fully connected layer 이전의 Conv.layer)와 연결되어 대표 프레임 분류 모듈의 입력 데이터가 대표 프레임일 때 Conv.layer에서 출력되는 적어도 한 차원 이상의 Activation map을 포함하는 액티베 이션 정보(좌표 별 액티베이션 값을 포함)를 입력받고 각 class에 대응되는 Activation map을 포함하는 클래스 액티베이션 정보(각 class에 따른 좌표 별 액티베이션 값을 포함)를 출력하며, sigmoid 함수를 통해 구역 분류 정보를 출력하도록 대표 프레임 분류 모듈과 함께 학습될 수 있다. 또한, 코어 특징 선정 모듈에는 상 기 클래스 액티베이션 정보와 특징 추출 모듈에 대표 프레임이 입력 데이터로 입력되어 출력 데이터로 출력 되는 각 class의 coordinate data(특징 좌표 정보)가 입력되며, 입력되는 특징 좌표 정보 또는 클래스 액티베이 션 정보의 좌표를 대표 프레임의 크기와 class activation map의 크기에 따라 조정하여 각 class의 coordinate data(특징 좌표 정보)에 따른 bounding box 범위 내에 대표 프레임 분류 모듈의 class activation map의hitmap이 포함되는 비율(액티베이션 비율) 또는 activation weight(액티베이션 값)의 합을 각 class별 특징 중 요도 정보로서 출력한다. 출력된 특징 중요도 정보가 가장 큰 class를 코어 특징으로 선정한다. 이때, 클래스 액티베이션 생성 모듈에 의한 클래스 액티베이션 정보의 생성은 아래와 같이 수행될 수 있다. 수학식 1"}
{"patent_id": "10-2021-0089286", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위 수학식 1에서, Mc(x,y)는 class c로의 분류에 영향을 주는 (x,y)에 위치한 액티베이션 값, wkc는 activation map에서 class c에 대한 k번째 채널의 가중치, fk(x,y)는 Activation map의 k번째 채널의 (x,y)에 위치한 액티 베이션 값을 의미한다. 본 발명의 제2변형예에 따르면, 전체 클래스에 대한 Activation map이 아닌, 각 class 별로 달리 생성되는 Class activaiton map을 이용하여 각 class별 특징 중요도 정보를 출력하게 되므로, 구역 분류 정보의 추론 (inference)에 보다 중요한 object를 코어 특징 정보로 선정할 수 있게 되는 효과가 발생된다. 또한, 대표 프레 임 분류 모듈부터 클래스 액티베이션 생성 모듈까지 단일 인공신경망 모듈로 구성할 수 있게 됨으로써 인공신경망 학습 및 추론의 효율이 향상되는 효과가 발생된다. 후보 프레임 선정 모듈과 관련하여, 도 16은 본 발명의 변형예에 따른 후보 프레임 선정 모듈을 도시한 모식도이다. 도 16에 도시된 바와 같이, 후보 프레임 선정 모듈은 상기 대표 프레임 선정 모듈에서 선 정된 대표 프레임의 전후 프레임들 중 상기 코어 특징을 포함하는 복수의 프레임을 후보 프레임으로 선정하는 모듈이다. 후보 프레임 선정 모듈은 전후 프레임들을 특징 추출 모듈에 입력하여 출력되는 특징 클래스 정보 중 코어 특징과 동일한 class에 대한 confidence score(class probability)가 특정 수준 이상인 프레임을 순차적으로 후보 프레임으로 선정하는 모듈이다. 예를 들어, 도 15에서 코어 특징과 동일한 class에 대한 confidence score가 0.7 이상인 프레임을 후보 프레임으로 선정하는 경우, confidence score가 0.65인 프레임 과 대표 프레임의 사이를 순차적으로 후보 프레임으로 선정하도록 구성될 수 있다. 프레임 정합 모듈은 대표 프레임과 후보 프레임을 코어 특징 기준으로 정합(stiching)하여 파노라마 대표 프레임을 생성하는 모듈이다. 대표 프레임과 후보 프레임의 정합 방법으로는 후보 프레임에 대하여 코어 특징을 기준으로 이미지를 분할하여 분할 이미지를 생성하고, 분할 이미지 중 코어 특징을 포함하지 않는 분할 이미지 를 대표 프레임에 정합하는 방법으로 파노라마 대표 프레임을 생성하도록 구성될 수 있다. 프레임 정합 모듈 에서 생성된 파노라마 대표 프레임은 대표 프레임 분류 모듈에 입력 데이터로 입력되어 보다 성능이 좋 은 구역 분류 정보인 제2구역 분류 정보를 출력 데이터로 출력하도록 구성될 수 있다. 본 발명의 변형예에 따르면, 대표 프레임을 파노라마 이미지로 변환하여 구역 분류를 추론할 수 있게 되므로, 대표 프레임을 통해 전체 여행 영상의 구역을 분류하는 방식의 단점을 상쇄할 수 있게 되는 효과가 발생된다. 또한, 구역 분류를 추론하는 인공신경망 모듈의 추론 성능을 향상시키는 방향으로 파노라마 이미지를 생성하도 록 구성되므로 기존의 컴퓨터 비전 방식의 파노라마 이미지 생성 알고리즘에 비하여 여행 영상의 구역 분류에 대한 정확도가 향상되게 되는 효과가 발생된다. 기존에는 파노라마 이미지를 생성하기 위해 SIFT(Scale-invariant Feature Transform) 알고리즘, SURF(Speed Up Robust Features) 알고리즘, CDVS(Compact Descriptor for Visual Search) 알고리즘 등의 컴퓨터 비전 계열 의 알고리즘으로 특징점을 추출하고, RANSAC 알고리즘, PROSAC 알고리즘 등을 적용하여 특징점들 중에서 outlier를 제거하며, 두 이미지의 inlier 특징점들 중에서 매칭점을 선별하며, 각 이미지의 참인 특징점들(inlier)로 선별된 매칭점을 이용하여 호모그래피 행렬을 산출하고, 산출된 호모그래피 행렬을 이용하여 이미지 정합(스티칭, stiching)을 수행하여 파노라마 이미지를 생성하게 된다. 이러한 기존의 방식을 본 발명의 일실시 예에 따른 파노라마 대표 프레임의 생성에 적용하게 되면 여행 영상의 전체 프레임에 대한 특징점 추출 및 outlier 제거를 컴퓨팅하는데 상당한 컴퓨팅 리소스가 요구되게 되고, 컴퓨터 비전 기반의 기존 알고리즘의 특 성 상 outlier를 확실하게 제거하지 못해 다양한 형태의 문제가 발생되며, 여행 영상의 구역 분류와 전혀 관련 이 없는 파노라마 이미지가 생성되게 되는 문제가 발생되게 된다. 이상에서 설명한 바와 같이, 본 발명이 속하는 기술 분야의 통상의 기술자는 본 발명이 그 기술적 사상이나 필 수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 상술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범 위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함하는 것으로 해석되어야 한다. 본 명세서 내에 기술된 특징들 및 장점들은 모두를 포함하지 않으며, 특히 많은 추가적인 특징들 및 장점들이 도면들, 명세서, 및 청구항들을 고려하여 당업자에게 명백해질 것이다. 더욱이, 본 명세서에 사용된 언어는 주 로 읽기 쉽도록 그리고 교시의 목적으로 선택되었고, 본 발명의 주제를 묘사하거나 제한하기 위해 선택되지 않 을 수도 있다는 것을 주의해야 한다. 본 발명의 실시예들의 상기한 설명은 예시의 목적으로 제시되었다. 이는 개시된 정확한 형태로 본 발명을 제한 하거나, 빠뜨리는 것 없이 만들려고 의도한 것이 아니다. 당업자는 상기한 개시에 비추어 많은 수정 및 변형이 가능하다는 것을 이해할 수 있다. 그러므로 본 발명의 범위는 상세한 설명에 의해 한정되지 않고, 이를 기반으로 하는 출원의 임의의 청구항들에 의해 한정된다. 따라서, 본 발명의 실시예들의 개시는 예시적인 것이며, 이하의 청구항에 기재된 본 발명의 범 위를 제한하는 것은 아니다."}
{"patent_id": "10-2021-0089286", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 발명의 상세한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어 해석되어서는 아니 된다. 도 1은 본 발명의 일실시예에 따른 인공지능 기반의 여행 영상 분류 장치를 도시한 모식도, 도 2는 본 발명의 일실시예에 따른 인공지능 기반의 여행 영상 분류 장치의 작동관계를 도시한 모식도,도 3은 본 발명의 일실시예에 따른 움직임 정보 출력 모듈의 작동관계를 도시한 모식도, 도 4는 본 발명의 다른 실시예에 따른 강화학습 모듈을 포함한 움직임 정보 출력 모듈을 도시한 모식도, 도 5는 대표 구간 선정 모듈의 대표 구간 선정을 도시한 모식도, 도 6은 본 발명의 일실시예에 따른 대표 프레임 분류 모듈의 구성을 도시한 모식도, 도 7은 본 발명의 일실시예에 따른 제nCNN 모듈을 도시한 모식도, 도 8은 본 발명의 일실시예에 따른 분류 인공신경망 모듈을 도시한 모식도, 도 9는 본 발명의 일실시예에 따른 구역 분류 인공신경망 모듈에 의해 출력된 구역 분류 정보를 여행 지역의 지 도에 매핑한 모식도, 도 10은 본 발명의 변형예에 따른 여행 영상 분류 장치인 영상의 파노라마 이미지 변환을 이용한 여행 영상 분 류 장치를 도시한 모식도, 도 11은 본 발명의 변형예에 따른 여행 영상 분류 장치인 영상의 파노라마 이미지 변환을 이용한 여행 영상 분 류 장치의 작동관계를 도시한 모식도, 도 12는 본 발명의 변형예에 따른 여행 영상 분류 장치의 일구성인 특징 추출 모듈의 구조를 도시한 모식도, 도 13은 본 발명의 변형예에 따른 특징 추출 인공신경망 모듈이 YOLO v1(CVPR 2016)으로 구성되는 경우의 구조 를 도시한 모식도, 도 14는 본 발명의 변형예에 따른 코어 특징 선정 모듈의 작동관계를 도시한 모식도, 도 15는 본 발명의 제2변형예에 따른 코어 특징 선정 모듈의 작동관계를 도시한 모식도, 도 16은 본 발명의 변형예에 따른 후보 프레임 선정 모듈을 도시한 모식도이다."}
