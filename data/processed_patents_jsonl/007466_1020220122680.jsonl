{"patent_id": "10-2022-0122680", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0043876", "출원번호": "10-2022-0122680", "발명의 명칭": "3D 프린팅 된 객체의 이미지를 바탕으로 3D 프린터를 식별하는 신경망 기반의 전자 장치", "출원인": "한림대학교 산학협력단", "발명자": "허종욱"}}
{"patent_id": "10-2022-0122680", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,3D 프린팅을 수행하는 프린터를 식별하도록 훈련된 인공지능 모델을 포함하는 메모리; 및3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 상기 인공지능 모델에 입력하여, 상기 객체를 생성한 3D 프린터를 식별하는, 프로세서;를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0122680", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공지능 모델은,서로 다른 복수의 3D 프린터를 통해 생성된 복수의 객체 각각이 일정 거리 내에서 촬영된 클로즈업 이미지를 바탕으로 훈련된 제1 인공지능 모델을 포함하고,상기 프로세서는,상기 객체의 적어도 일부가 상기 일정 거리 내에서 촬영된 클로즈업 이미지를 상기 제1 인공지능 모델에 입력하는, 전자 장치."}
{"patent_id": "10-2022-0122680", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 인공지능 모델은,서로 다른 복수의 3D 프린터를 통해 생성된 복수의 객체 각각이 전체적으로 포함되도록 촬영된 전체 객체 이미지를 바탕으로 훈련된 제2 인공지능 모델을 포함하고,상기 프로세서는,상기 객체의 전체가 촬영된 전체 객체 이미지를 상기 제2 인공지능 모델에 입력하는, 전자 장치."}
{"patent_id": "10-2022-0122680", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 인공지능 모델은,상기 객체가 촬영된 상기 이미지가 입력되면, 특징 정보를 추출하는, 인코더 모듈; 및상기 특징 정보를 적어도 하나의 3D 프린터의 지문과 비교하여, 상기 객체가 각 분류의 프린터에 의해 생성되었을 가능성을 출력하는, 분류 모듈;을 포함하고,상기 인코더 모듈은,서로 다른 분류의 3D 프린터들 각각의 지문에 해당하는 특징 정보 간의 마진이 일정 수치 이상 되도록, 상기 3D프린터들 각각을 통해 생성된 객체들의 이미지로부터 특징 정보를 추출하는, 전자 장치."}
{"patent_id": "10-2022-0122680", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 인공지능 모델은,서로 다른 복수의 프린터를 통해 생성된 복수의 객체 각각이 일정 거리 내에서 촬영된 클로즈업 이미지를 바탕공개특허 10-2024-0043876-3-으로 훈련된 제1 인공지능 모델; 및상기 복수의 객체 각각이 전체적으로 포함되도록 촬영된 전체 객체 이미지를 바탕으로 훈련된 제2 인공지능 모델;을 포함하고,상기 프로세서는,상기 객체의 적어도 일부가 상기 일정 거리 내에서 촬영된 클로즈업 이미지를 상기 제1 인공지능 모델에 입력하여 제1 출력 정보를 획득하고,상기 객체의 전체가 촬영된 전체 객체 이미지를 상기 제2 인공지능 모델에 입력하여 제2 출력 정보를 획득하고,상기 제1 출력 정보와 상기 제2 출력 정보를 결합하여, 상기 객체를 생성한 프린터를 식별하는, 전자 장치."}
{"patent_id": "10-2022-0122680", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는,상기 제1 출력 정보 및 상기 제2 출력 정보 각각에 0.6 및 0.4의 비중을 부여하는, 전자 장치."}
{"patent_id": "10-2022-0122680", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "3D 프린팅을 수행하는 프린터를 식별하도록 훈련된 인공지능 모델을 포함하는 전자 장치의 제어 방법에 있어서, 상기 전자 장치가, 3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 상기 인공지능 모델에 입력하는 단계; 및상기 전자 장치가, 상기 인공지능 모델의 출력을 바탕으로 상기 객체를 생성한 3D 프린터를 식별하는 단계;를포함하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0122680", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "전자 장치에 있어서,3D 프린팅을 수행하는 프린터의 필라멘트 종류를 식별하도록 훈련된 인공지능 모델을 포함하는 메모리; 및3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 상기 인공지능 모델에 입력하여, 상기 객체를 생성한 3D 프린터의 필라멘트 종류를 식별하는, 프로세서;를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0122680", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "전자 장치에 있어서,스캔-및-재인쇄 여부를 식별하도록 훈련된 인공지능 모델을 포함하는 메모리; 및3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 상기 인공지능 모델에 입력하여, 상기 객체가 스캔-및-재인쇄과정을 통해 생성되었는지 여부를 식별하는, 프로세서;를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 본 전자 장치는, 3D 프린팅을 수행하는 프린터를 식별하도록 훈련된 인공지능 모델을 포 함하는 메모리, 3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 인공지능 모델에 입력하여, 객체를 생성한 3D 프린터를 식별하는, 프로세서를 포함한다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 3D 프린팅 객체의 출처를 식별하는 전자 장치에 관한 것으로, 보다 상세하게는, 3D 프린팅 객체의 이 미지를 분석하여 3D 프린팅을 수행한 3D 프린터를 식별하는 전자 장치에 관한 것이다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "속도 개선, 광범위한 사용 환경, 재료의 다양화 및 소프트웨어 개선과 함께 3D 프린팅 기술의 확산은, 3D 재료 및 제품을 구축하기 위한 적층 제조(AM) 등에서 널리 사용되는 데 기여했다. AM은 전통적인 제조 방법에 비해 자재 낭비와 환경 오염을 줄이면서 개인화 및 소량 배치 생산이 가능하다. 또한 기존의 방법으로는 불가능한 복 잡하거나 특이한 모양을 생산할 수 있다. 특히 Thingiverse와 같은 3D 객체 유통 포털의 성장과 함께 '프로슈머 (Prosumer)'라는 전문 지식을 갖춘 일반 고객에 의한 3D 객체의 개인화 제작 및 유통이 증가할 것으로예상된다. 다만, 3D 프린팅 기술의 발달로 범죄 활동을 위한 불법 도구 제작에 활용되는 사례도 증가하고 있다. 이렇듯, 3D 프린터가 에 의해 품목이 더 쉽게 생산됨에 따라, 그 생산의 남용으로 인해 3D 인쇄의 출처를 식별하는 것이 더 중요해지고 있다. 따라서, 상용화된 3D 프린터를 이용하여 3D 콘텐츠 환경을 구축할 때 불법 배포를 통한 저 작권 침해, 정보 위조로 인한 부당한 이익 및 피해, 민감한 정보의 무결성, 출처 식별 등의 보안 문제를 고려해 야 한다. 레이저 프린터의 소스 식별과 같은 멀티미디어 포렌식 분야가 집중적으로 연구되어 왔다. 대조적으로, 3D 인쇄 객체의 소스 식별을 다루는 연구는 소수에 불과하다. 기존의 연구에서는 보안 시스템 외부의 일반적인 환경을 고려하지 않고 추가적인 데이터(예: 워터마크 신호, 블 록체인, QR 코드)를 사용하여 조형물의 출처를 추적하였다. Li et al.은 3D 프린팅된 물체에 대해 험준한 융기, 넓은 융기, 보편적인 미세한 분기점과 같은 물체 표면의 굴곡 및 부착 질감을 기반으로 하는 블라인드 소스 식 별 기술을 제안했다. Peng et al.은 인쇄 노이즈 및 미리 정의된 서명 임베딩을 기반으로 소스 식별 기술을 제 안했다. 우리는 Li et al.의 연구를 계속하여 통계 기반 텍스처를 넘어 보다 다양한 샘플, 제어된 환경, 캡처 장치 및 심층 방법론에 대해 작업했다. 3D 프린터는 전문(고급) 프린터와 저가형 프린터의 두 가지 범주로 분류할 수 있다. 전문 프린터는 정확하고 고 품질의 인쇄를 제공하지만 높은 비용과 유지 관리의 어려움으로 인해 일반 소비자에게 적합하지 않다. 대조적으 로, 저가형 프린터는 완벽한 출력물을 생성하기 어렵더라도 대중에게 쉽게 접근할 수 있다. 현재 3D 프린터 시 장은 다양한 산업 분야에서 널리 상용화되고 있다. 시중에 나와 있는 3D 프린터의 70% 이상이 필라멘트를 녹이 고 쌓는 FDM(Fused Deposition Modeling) 기술을 사용한다. 구체적으로, 노즐을 통해 필라멘트를 녹이고 추출한 필라멘트를 상온에서 경화시킨다. FDM 방식은 다른 3D 프린터에 비해 구조와 장치 프로그램이 간단하여 장비 가 격과 유지 보수 비용이 저렴하다. 또한, 용도에 따라 다양한 재료를 적용할 수 있다. SLA(stereolithography), 디지털 광 처리, 및 선택적 레이저 소결과 같은 다른 3D 프린팅 기술은 FDM 방식보다 출력 품질이 더 높을 수 있지만 유지 관리 비용과 독성 물질의 존재로 인해 관리가 더 어려워 일반 소비자에게 는 적합하지 않다. 3D 프린팅을 통한 남용의 예로는 열쇠, 총기 복제, 지문, 얼굴 위조 등이 있다. 도 1은 3D 프린팅된 물체의 남 용 사례의 세 가지 샘플을 보여준다. 예를 들어, 3D 프린터로 인쇄된 키로 자동차 시동을 걸거나, 3D 인쇄된 총 으로 쏘거나, 지문을 위조하여 돈을 훔치고 스마트폰을 잠금 해제할 수 있다. 최근에는 3D 프린터로 출력한 안 면 마스크로 안면 인식 보안 시스템을 잠금 해제하는 사례도 있다. 지문과 얼굴 인식이 개인 정보를 관리하는 세상에서 3D 프린팅의 출처를 식별하는 것은 사람들이 남용될 가능성이 있는 아이템을 쉽게 생산할 수 있기 때 문에 더욱 중요해지고 있다. 또 다른 남용 사례는 불법 배포 및 저작권 침해 사례이다. 대부분의 저작권 솔루션은 3D 프린팅 프로세스가 이 러한 보호를 비활성화하기 때문에 비효율적이다. 파일 헤더 및 디지털 좌표와 같은 디지털 정보는 인쇄 중에 완 전히 손실된다. 예를 들어, 디지털 권리 관리 시스템에 의해 규제되는 3D 총기 객체는 규제 없이 3D 프린팅 후 배포될 수 있다. 따라서, 관련 포렌식 기술은 진품과 위조품을 구별하는 중요한 증거가 되어야 하며, 해적 콘텐 츠 추적에 중요한 역할을 해야 한다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 CNN(Convolutional Neural Network) 모델을 바탕으로 3D 프린팅 객체의 이미지를 분석하여 3D 프린 팅을 수행한 3D 프린터를 식별하는 전자 장치를 제공한다. 본 개시의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 개시의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 개시의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 개시의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 전자 장치는, 3D 프린팅을 수행하는 프린터를 식별하도록 훈련된 인공지능 모델을 포함하는 메모리, 3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 상기 인공지능 모델에 입력하여, 상기 객체 를 생성한 3D 프린터를 식별하는, 프로세서를 포함한다. 상기 인공지능 모델은, 서로 다른 복수의 3D 프린터를 통해 생성된 복수의 객체 각각이 일정 거리 내에서 촬영 된 클로즈업 이미지를 바탕으로 훈련된 제1 인공지능 모델을 포함할 수 있다. 이때, 상기 프로세서는, 상기 객 체의 적어도 일부가 상기 일정 거리 내에서 촬영된 클로즈업 이미지를 상기 제1 인공지능 모델에 입력할 수 있 다. 상기 인공지능 모델은, 서로 다른 복수의 3D 프린터를 통해 생성된 복수의 객체 각각이 전체적으로 포함되도록 촬영된 전체 객체 이미지를 바탕으로 훈련된 제2 인공지능 모델을 포함할 수도 있다. 이때, 상기 프로세서는, 상기 객체의 전체가 촬영된 전체 객체 이미지를 상기 제2 인공지능 모델에 입력할 수 있다. 상기 인공지능 모델은, 상기 객체가 촬영된 상기 이미지가 입력되면, 특징 정보를 추출하는, 인코더 모듈, 상기 특징 정보를 적어도 하나의 3D 프린터의 지문과 비교하여, 상기 객체가 각 분류의 프린터에 의해 생성되었을 가 능성을 출력하는, 분류 모듈을 포함할 수 있다. 여기서, 상기 인코더 모듈은, 서로 다른 분류의 3D 프린터들 각각의 지문에 해당하는 특징 정보 간의 마진이 일 정 수치 이상 되도록, 상기 3D 프린터들 각각을 통해 생성된 객체들의 이미지로부터 특징 정보를 추출할 수도 있다. 한편, 상기 인공지능 모델은, 서로 다른 복수의 프린터를 통해 생성된 복수의 객체 각각이 일정 거리 내에서 촬 영된 클로즈업 이미지를 바탕으로 훈련된 제1 인공지능 모델, 상기 복수의 객체 각각이 전체적으로 포함되도록 촬영된 전체 객체 이미지를 바탕으로 훈련된 제2 인공지능 모델을 모두 포함할 수 있다. 이때, 상기 프로세서는, 상기 객체의 적어도 일부가 상기 일정 거리 내에서 촬영된 클로즈업 이미지를 상기 제1 인공지능 모델에 입력하여 제1 출력 정보를 획득하고, 상기 객체의 전체가 촬영된 전체 객체 이미지를 상기 제2 인공지능 모델에 입력하여 제2 출력 정보를 획득하고, 상기 제1 출력 정보와 상기 제2 출력 정보를 결합하여, 상기 객체 를 생성한 프린터를 식별할 수 있다. 여기서, 상기 프로세서는, 상기 제1 출력 정보 및 상기 제2 출력 정보 각각에 0.6 및 0.4의 비중을 적용하여 결 합할 수도 있다. 본 개시의 일 실시 예에 따라 3D 프린팅을 수행하는 프린터를 식별하도록 훈련된 인공지능 모델을 포함하는 전 자 장치의 제어 방법은, 상기 전자 장치가, 3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 상기 인공지능 모 델에 입력하는 단계, 상기 전자 장치가, 상기 인공지능 모델의 출력을 바탕으로 상기 객체를 생성한 3D 프린터 를 식별하는 단계를 포함한다. 본 개시의 일 실시 예에 따른 전자 장치는, 3D 프린팅을 수행하는 프린터의 필라멘트 종류를 식별하도록 훈련된 인공지능 모델을 포함하는 메모리, 3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 상기 인공지능 모델에 입 력하여, 상기 객체를 생성한 3D 프린터의 필라멘트 종류를 식별하는, 프로세서를 포함한다. 본 개시의 일 실시 예에 따른 전자 장치는, 스캔-및-재인쇄 여부를 식별하도록 훈련된 인공지능 모델을 포함하 는 메모리, 3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 상기 인공지능 모델에 입력하여, 상기 객체가 스 캔-및-재인쇄 과정을 통해 생성되었는지 여부를 식별하는, 프로세서를 포함한다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따른 전자 장치 및 그 제어 방법은, 3D 프린팅 객체의 클로즈업 이미지 및/또는 전체 객체 이미지를 분석하여 프린터의 종류, 필라멘트의 종류, 스캔-및-재인쇄 여부 중 적어도 하나를 식별할 수 있다. 특히, 본 개시에 따른 전자 장치 및 그 제어 방법은, 종래의 기술에 비해 정확도와 편의성 면에서 더욱 뛰어나 다는 점이 확인된다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에 대하여 구체적으로 설명하기에 앞서, 본 명세서 및 도면의 기재 방법에 대하여 설명한다. 먼저, 본 명세서 및 청구범위에서 사용되는 용어는 본 개시의 다양한 실시 예들에서의 기능을 고려하여 일반적 인 용어들을 선택하였다. 하지만, 이러한 용어들은 당해 기술 분야에 종사하는 기술자의 의도나 법률적 또는 기 술적 해석 및 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 일부 용어는 출원인이 임의로 선정한 용어 도 있다. 이러한 용어에 대해서는 본 명세서에서 정의된 의미로 해석될 수 있으며, 구체적인 용어 정의가 없으 면 본 명세서의 전반적인 내용 및 당해 기술 분야의 통상적인 기술 상식을 토대로 해석될 수도 있다. 또한, 본 명세서에 첨부된 각 도면에 기재된 동일한 참조번호 또는 부호는 실질적으로 동일한 기능을 수행하는 부품 또는 구성요소를 나타낸다. 설명 및 이해의 편의를 위해서 서로 다른 실시 예들에서도 동일한 참조번호 또 는 부호를 사용하여 설명한다. 즉, 복수의 도면에서 동일한 참조 번호를 가지는 구성요소가 모두 도시되어 있다 고 하더라도, 복수의 도면들이 하나의 실시 예를 의미하는 것은 아니다. 또한, 본 명세서 및 청구범위에서는 구성요소들 간의 구별을 위하여 \"제1\", \"제2\" 등과 같이 서수를 포함하는 용어가 사용될 수 있다. 이러한 서수는 동일 또는 유사한 구성요소들을 서로 구별하기 위하여 사용하는 것이며 이러한 서수 사용으로 인하여 용어의 의미가 한정 해석되어서는 안 된다. 일 예로, 이러한 서수와 결합된 구성 요소는 그 숫자에 의해 사용 순서나 배치 순서 등이 제한되어서는 안 된다. 필요에 따라서는, 각 서수들은 서로 교체되어 사용될 수도 있다. 본 명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 실시 예에서 \"모듈\", \"유닛\", \"부(Part)\" 등과 같은 용어는 적어도 하나의 기능이나 동작을 수행하는 구성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\", \"유닛\", \"부(Part)\" 등은 각각이 개별적인 특정 한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나의 프로세서로 구현될 수 있다. 또한, 본 개시의 실시 예에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적인 연결뿐 아니라, 다른 매체를 통한 간접적인 연결의 경우도 포함한다. 또한, 어떤 부분이 어떤 구성요소를 포함한다는 의미는, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것 을 의미한다. 3D 프린팅 물체의 출처는 프린팅 과정에서 발생하는 다양한 보이지 않는 흔적에서 식별될 수 있다. 따라서, 3D 인쇄된 객체의 크고 조직화된 데이터베이스를 수집하고 이를 스캔하여 미세한 흔적을 캡처하였다. 그런 다음, 공개 데이터 세트를 도입하고 3D 인쇄 객체 분석을 위한 벤치마크를 공식화하였다. 그 결과 명명된 본 개시에 따른 SI3DP 벤치마크 데이터 세트에는, 표준 디지털 카메라 이미지와 3D 인쇄 객체의 클로즈업 이미지가 포함된다. 마지막으로 CNN(Convolutional Neural Networks) 기반의 각 식별 작업에 대한 탐 지 방법을 제안하고 실험 결과를 제공한다. 본 개시에 따른 SI3DP 데이터 세트는 디지털 포렌식 연구 및 지적 재산권 보호에서 소스 식별에 대한 향후 심층 연구를 촉진할 수 있다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 개시에 따른 연구의 기여는 다음과 같이 요약된다. 먼저 소비자 수준의 3D 프린터 포렌식에 대한 벤치마크 데이터 세트를 제시한다. 이 데이터 세트는 18가지 다른 인쇄 옵션에서 252개의 조작된 객체에서 20,149개의 클로즈업 이미지로 구성된다. 우리는 또한 추가 연구 를 위해 전체 객체 이미지(full object image)를 제공한다. 3D 인쇄된 객체의 소스와 매개변수(parameter)를 식별하기 위한 파이프라인을 제시한다. 베이스라인은 표면 질감의 미시적 차이(클로즈업 이미지 테스트)와 상대적으로 거시적인 뷰(전체 객체 이미지 테스트)에서의 성능 수준을 기반으로 프린터 유형 및 속성을 식별할 수 있음을 보여준다. 다른 이미지 양식 및 작업에서 풍부한 지식을 활용하기 위해 장치 수준 식별 작업을 위한 multitask- multimodal 아키텍처를 제안한다. 3D 프린팅에서는 프린팅 대상의 제조 공정과 표면 품질에 영향을 미치는 요인을 분석하는 것도 중요하다. 따라 서 인쇄 중 발생할 수 있는 다양한 프린터 특성 요인을 패턴과 랜덤 노이즈로 분류하였다. 1) 패턴 노이즈: 프린터 모델, 필라멘트, 슬라이싱 파라미터 등 인쇄 시 결정된 파라미터에 따라 패턴 노이즈가 형성된다. '슬라이싱'이라는 용어는 원본 객체를 가져와 3D 프린터에 공급하기 위해 개별 레이어로 슬라이싱하 는 것을 의미한다. 슬라이싱 매개변수는 결정적인 표면 특징으로 이어진다. 얇은 두께의 레이어는 더 높은 인쇄 해상도를 제공하지만 인쇄 시간이 더 오래 걸린다. 쉘 두께(또는 쉘 수)는 곡률과 표면 품질에 큰 영향을 미친 다. 주파수 분석을 통해 구별되는 특정한 공간적 표시나 주기적인 패턴으로 표현될 수 있다. 2) 랜덤 노이즈: 동일한 조건에서 물체를 제작하더라도 결과적으로 3D 프린팅된 물체는 미세한 표면 변형을 보 인다. Hao Peng et al.에서 랜덤 구성 요소는 객체-레벨 식별에 중요한 요소이다. 압출하는 동안 필라멘트 직경 (filament diameter), 스풀(spool) 및 피더 휠(feeder wheel)과 같은 랜덤 구성 요소의 변화로 인해 결함이 발 생할 수 있다. 헤드가 표면을 가로질러 과도한 항력을 들어올릴 때 일시적인 과소 압출(under-extrusion) 및 과 압출(over-extrusion)이라고 하는 드물게 건너뛴 층은 필라멘트 흔적을 남긴다. 프린팅 베드(printing bed)와 챔버(chamber)의 온도도 인쇄 품질 변화에 영향을 준다. 프린터 별로 다른 모델을 선택하는 것이 공평하지 않을 수 있기 때문에 각 프린터에 대해 공통 객체 모델이 선 택되었다. 도난, 협박 등의 상황에서 의미 있는 오브제로 선정된 모델은 열쇠, 총알, 이빨, 아이언맨 피규어로 구성됐다. 3D 프린터로 인쇄된 집이나 자동차 열쇠는 도난당하는 경우 상당한 위험을 초래할 수 있다. 3D 프린 터로 치아를 만든다면 임플란트와 틀니는 더 저렴하고 빠르게 사용할 수 있을 뿐만 아니라 의학적으로도 의미가 있다. 미디어에서 확인된 3D 총알은 사람에게 치명적인 위험을 초래하고 군사적 영향을 미친다. 마지막으로 Iron Man 객체는 상업용 모델의 저작권 문제를 나타내기 위해 선택되었다.표 1"}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "표 1과 같이 본 개시에 따른 실험에 사용된 프린터 모델에는 MakerBot의 Method X와 Replicator, Cubicon의 210F 및 320C, Flashforge의 Finder가 있으며 가격은 400 ~ 12,000 달러이다. 210F, 320C, Finder 각각 4대씩 같은 종류의 프린터를 분류하는데 사용되었다. 또한 온도조절에 영향을 미치고 유해물질 및 소음을 차단하는 요인인 챔버라고 하는 밀폐장치의 존재를 고려해 야 한다. 각 프린터 장치에 대해 세 가지 다른 품질 매개변수를 설정하였다. 각 매개변수 집합에 대한 자세한 내용은 후술한다. 표 2"}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "또한, 표 2와 같이 7가지 유형의 프린터 필라멘트가 포함되었다. Replicator의 필라멘트를 제외하고 캡처의 용 이성을 위해 다른 모든 필라멘트에 대해 검정색을 선택했다. 맨 눈으로 필라멘트의 종류(재료)를 구별하기는 어 렵다. 가격, 크기, 무게, 노즐 등 다양한 사양의 프린터를 준비했다. MethodX는 용해 과정을 수반하는 수용성 지지체 를 사용한다. 인쇄 후 지지대를 제거하고 나머지 거친 부분은 블러셔와 에어 컴프레서 건을 사용하여 연마했다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "또한 스카치 테이프를 사용하여 문자열 아티팩트를 제거했다. 요약하자면, 14개의 다른 장치, 7개의 필라멘트 유형 및 3개의 품질에서 252개의 3D 인쇄 개체(도 2 참조)가 수집되었다. 3D 프린팅된 물체의 표면에서 이하와 같은 유형의 디지털 데이터가 수집되었다. 1) 클로즈업 이미지, 2) 도 3 및 도 4와 같은 전체 객체 이미지이다. 또한, 스캔-및-재인쇄의 결과물인 객체에 대한 이미지(클로즈업 이미지 또는 전체 객체 이미지)도 수집될 수 있다. (클로즈업 이미지 획득): 3D 물체 표면의 미세한 질감 패턴을 포착하기 위해 광학 돋보기와 함께 HAYEAR HY- 5200 카메라 모델이 사용되었다. 클로즈업 이미지는 50x 광학 줌을 바탕으로 1280x720 해상도 JPEG 이미지로 획 득되었다. 물체는 현미경에서 2.1cm 떨어진 곳에서 촬영되었다. 지지 제거 흔적이 많은 바닥면은 제외하고 상, 전면, 후면, 양면이 촬영되었다. 모든 모델을 동일한 방향으로 지정하고 특정 너비로 이동했다. 도 5 및 표 3은 클로즈업 이미지 데이터 세트의 세부 통계를 보여준다. 총 20,149개의 이미지에 대해 각 개체에 대해 최소 50개 의 현미경 이미지가 촬영되었다.표 3"}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "(전체 객체 이미지 획득): 전체 객체 이미지를 촬영하기 위해 Sony DCS-W830 디지털 카메라가 사용되었다. 카메 라는 삼각대를 이용하여 30cm 거리를 두고 고정하였고, 영상은 상하좌우에서 촬영하였다. 이미지 해상도는 1920x1080으로 설정했고 동일한 제어 환경에서 총 693개의 이미지를 촬영했다. 앞서 제시된 데이터 세트를 기반으로 다양한 소스 식별 작업과 포렌식 연구를 도출할 수 있다. (인쇄물 속성): 인쇄물의 속성, 보다 구체적으로 본 개시의 벤치마크에서 구별되는 주요 속성의 집합 Θ가 정의 되었다. 데이터 세트에서 3D 인쇄 개체의 처리 기록을 식별하기 위해 5개의 속성 Θ = {M, F, Q, D, R}을 제공 한다. 제공된 속성 Θ은 다음과 같다: 프린터 모델 P, 필라멘트 유형 F, 품질 매개변수(Quality Parameter) Q, 프린터 장치-레벨(Device-Level) 식별 D, 및 스캔-및-재인쇄(Scan-and-Reprint) R. 여기서 프린터 모델 식별 본 개시에서 다루는 실험에서는 5가지 모델의 3D 프린터가 사용되었다. 필라멘트가 서로 다른 인쇄 케이스들과 동일한 프린터에 대한 옵션들이 포함된다(방법 X). 각 모델에 대한 개별 3D 프린터 설정을 갖는 것 외에도 사용 자는 프린팅 옵션과 필라멘트를 반복적으로 변경할 수 있다. 따라서 주어진 속성에 대한 프린터 모델의 소스를 식별하는 것은 어려울 것이다. 필라멘트 재료 식별 FDM 프린팅의 필라멘트는 품질, 강도, 비용 및 적용을 결정하는 가장 중요한 요소 중 하나이다. 필라멘트에 대 한 많은 연구가 환경이나 인체에 무해하거나, 재활용이 가능한 필라멘트를 찾는 것을 다룬다. 또한, 단단한 3D 물체를 찾기 위해 필라멘트를 비교하는 연구도 수행되었다. 그러나 포렌식 목적으로 서로 다른 필라멘트의 질감 패턴을 분석하거나 차별화 한 연구는 아직 없다. 본 개시의 실험에서는 하나의 프린터에서 최대 4가지 유형의 필라멘트를 사용하여 데이터 세트를 구성했으며, 이는 동일한 모델의 서로 다른 필라멘트를 식별하는 기반이 된 다. 본 개시의 실험에서 사용된 데이터 세트의 필라멘트는 Replicator+를 제외하고는 검은색이며 육안으로 구분 할 수 없다. 품질 매개변수 식별 프린팅 대상의 표면 품질에 영향을 미치는 슬라이싱 매개변수는 매우 다양하나, 층(layer)의 두께, 쉘(shell)의 개수가 대표적이다. 층의 두께는 3D 프린팅 시 적층의 단위가 되는 각 층의 두께를 의미하고, 쉘의 개수는 외벽 을 구성하는 쉘의 개수 내지는 크기를 의미한다. 상술한 것처럼 각 프린팅 장치에 대해 Quality1(0.2mm, 3), Quality2(0.2mm, 2) 및 Quality3(0.3mm, 2)의 세 가지 다른 프린팅 매개변수를 설정했다. 여기서 (δ(mm), ns)은 각각 층(layer)의 두께와 쉘(shell)의 수를 나 타낸다. 레이어 두께는 프린터 및 필라멘트 유형에 관계없이 일관된 패턴을 나타낸다. 따라서 매개변수의 품질에 따라 각 프린터의 샘플을 분류하고 동일한 프린터에서 다른 인쇄 옵션을 사용하여 개체를 분류할 수 있도록 설계되었 다. 장치-레벨 식별 장치-레벨은, 동일한 모델의 프린터라도 어떤 사용자, 어떤 장소, 어떤 기관에서 사용되는 프린터인지를 나타내 는 정보이다. 예를 들어, 동일 브랜드의 제품이라도 기기마다 출력되는 패턴들이 다르기 때문에, 본 개시에서 설명하는 실험에서는 동일 모델의 프린터를 4대씩 준비했다. 장치-레벨 소스 식별은 개별 프린터 장치가 획득한 개체에 남기는 장치 별 추적에 따라 다르다. 표 3과 같이 14 개의 개별 프린터가 사용되었다. 다만, 세 가지 다른 품질 매개변수와 필라멘트 유형에도 불구하고 3D 프린터의 장치-레벨 식별은 어려울 것이다. 본 개시에 따른 작업의 주요 가정은 유사하거나 다른 인쇄 설정이 동일한 장 비에 공존할 수 있다는 것이다. 따라서, 이 작업의 유사한 프린터에 대해 다음과 같이 데이터 세트의 하위 집합 이 선택될 수 있다. 210F_1, 320C_1 및 Finder_1의 Quality1 데이터; 210F_2, 320C_2 및 Finder_2의 Quality2 데이터 210F_3, 210F_4, 320C_3, 320C_4, Finder_3 및 Finder_4의 Quality3 데이터. 동일한 4가지 유형의 프린 터 중에서 정확한 샘플 설정과 환경으로 2개의 케이스가 인쇄된다. 스캔 후 재인쇄 감지 스캔-및-재인쇄는, 한 번 출력을 했던 것을 다시 스캔한 뒤, 다시 3D 파일로 만들어서 출력을 하는 과정을 의미 한다. 스캔-및-재인쇄는 3D 개체 보호를 비활성화하는 잠재적인 방법 중 하나이다. 이 프로세스는 컨텐츠 보안의 아날 로그적 취약점에 초점을 맞추고 RFID 태그 및 워터마크와 같은 추가 소스 식별 정보의 대부분을 비활성화한다. 예를 들어, 3D 프린팅 객체를 생성하기 위한 도면 파일을 구할 수 없을 때, 악의적인 목적을 가진 사람이 3D 프 린팅 객체를 직접 스캔해서 이를 본인의 프린터로 직접 만들어 더 싸게 판매하는 등의 상황이 발생할 수 있다. 따라서, 재인쇄된 개체를 일반 개체와 구별하는 새로운 포렌식 작업의 도입이 필요하다. 3D 프린팅된 개체를 Quality1(0.2, 3)으로 스캔한 다음 다시 인쇄하여 Replicator+, 320F 및 Finder 모델에서 총 36개의 개체를 수 집했다. 3D로 디테일 표면 텍스처를 캡처하기 위해 고해상도(> 0.05mm)와 정확도(> 8μm)를 갖춘 단일 데스크탑 스캐너 모델인 Maestro 3D MDS500 모델이 사용되었다. 개체당 평균 50M 면을 가진 표면 메쉬가 수집되었다. 이하 실험의 진행 및 결과에 대해 서술한다. 평가 프로토콜의 목적은 소스 프린터 식별 체계를 평가하는 주요 단계를 정의하는 것이다. 작업 별 분류기 (classifier)의 효율성을 측정하기 위한 평가 프로토콜은 다음과 같다. 1) 데이터 유형 선택: 아날로그 3D 프린팅된 물체를 디지털 방식으로 분석하기 위해서는 훈련 및 평가를 위한 데이터 유형을 선택해야 한다. SI3DP 데이터 세트는 클로즈업 이미지 sc, 전체 객체 이미지 sf, 스캔 및 재인쇄 데이터 s3의 세 가지 데이터 유형을 제공한다. multi-modal 알고리즘을 수행하기 위해 여러 데이터 유형이 선택 될 수 있다. 2) 교차 검증을 위한 데이터 분리: 3D 프린팅된 객체를 대량으로 획득하는 것이 어렵기 때문에 독립적인 데이터 세트 생성 시 분석 결과를 평가하기 위해 k-fold 교차 검증이 필요하다. 데이터 세트를 미리 4개의 독립적인 폴 드(folds)로 분할했다(k = 4). 일관된 교차 검증을 위해 데이터 세트는 다양한 객체에 할당된 폴드 번호 세트를 제공한다. 3) 작업 별 평가: 선택된 데이터 유형을 기반으로 각 작업에 대한 평가를 수행한다. 평가는 개체별로 수행되며 작업의 평균 정밀도는 out-of-fold 예측(샘플 외 예측 유형)에서 계산된다. 성능은 전체 긍정적 예측에 대한 올 바르게 예측된 긍정적 관찰의 비율인 메트릭 정밀도를 기반으로 평가된다.본 개시의 실험에서는 가장 널리 사용되고 알려진 방법인 CNN(Convolutional Neural Network)을 사용하여 최첨 단 성능을 시연했다. 도 6은 제안된 접근 방식의 개요를 보여준다. 기본 네트워크로 ImageNet 데이터베이스를 기반으로 하는 노이즈 스튜던트 교육(Qizhe Xie et al.)과 함께 사전 훈련된 EfficientNet-B3 모델을 사용한다. 단일 작업 학습의 경 우 기본 네트워크는 코사인 학습률 스케줄러 및 Adam 최적화 프로그램과 결합된 3e-5 학습률의 범주형 교차 엔 트로피 손실을 기반으로 최적화된다. 네트워크 훈련은 각 폴드에서 수렴하는 데 30 Epoch, 개략적으로 4시간이 걸렸다. 장치-레벨 식별 작업(D)의 성능을 향상시키기 위해 다른 이미지 양식과 하위 작업의 지식을 활용하는 multitask-multimodal 아키텍처가 제안되었다. 여기서, 멀티태스크(multitask)는 예를 들어 클로즈업 이미지와 전체 객체 이미지 각각에 대한 분류기 모델의 출력을 활용하는 것이고, 멀티모달(multimodal)은 하나의 분류기 모델을 통해 복수의 속성(ex. 프린터 식별, 필라멘트 유형 식별, 품질 매개변수 식별, 장치-레벨 식별, 스캔-및 -재인쇄 여부 식별 중 둘 이상)을 파악하는 개념을 의미한다. 동일한 기본 네트워크가 사용되었으며 목적은 다음과 같이 정의된다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서 LCE, , Cθ는 각각 범주형 교차 엔트로피 손실, 다중 작업 학습을 위한 하위 작업 및 대상 분류기를 나 타낸다. 대괄호 [, ]는 벡터 연결 연산자를 나타낸다. 가중치 β = 0.8을 사용하여 작업 D에 집중한다. 단일 인 코더 E(·)를 사용하여 다양한 양식(ex. 프린터 식별, 필라멘트 유형 식별, 품질 매개변수 식별, 장치-레벨 식 별, 스캔-및-재인쇄 여부 식별 중 둘 이상)에서 특징을 추출할 수 있다. 이때, 양식 별로 별도의 인코더를 사용 할 수 있지만 실험적으로 성능이 크게 향상되지는 않았다. 숫자 데이터가 안정적인 네트워크 훈련에 충분하지 않았기 때문에 데이터 수를 크게 늘리기 위해 다양한 데이터 증가 기법(예: 아핀 변환, 노이즈 추가, 무작위 대비, 흐림 및 컷아웃)이 수행되었다. 클로즈업 이미지 및 전체 객체 이미지에 대한 실험이 수행되었다. 검증을 위해 각 객체의 모든 이미지를 평가하고 추정된 확률의 평균값 을 최종 결정에 사용했다. 각 작업에 대한 기타 설정은 이하 자세히 설명한다. 본 개시의 베이스라인 모델에 대한 두 가지 실험 결과가 제시되었다. 표 4"}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "표 4는 각 작업에 대한 전체 결과를 요약한 것이다. 미세한 차이로 프린터를 식별할 수 있다(클로즈업 이미지 테스트). 프린터 모델, 필라멘트 유형, 스캔-및-재인쇄 작업은 훈련 결과에 따라 모델 내 가중치(: 모델 내 서 로 다른 레이어를 구성하는 노드 간 가중치)가 수렴된 후 상당히 좋은 성능을 보였다. 대조적으로, 본 개시의 모델은 장치-레벨 식별 및 품질 매개변수에 대해 좋은 성능을 나타내지는 않았다. 클로즈업 이미지와 같은 미시적인 관점만이 프린터 모델을 식별하는 데 유용하다는 기존의 믿음과 달리, 상대적 으로 거시적인 관점(전체 객체 이미지)에서도 일정 수준의 성능을 달성했다. 따라서 클로즈업 이미지 모델과 전 체 객체 이미지 모델과 함께 앙상블 기법을 사용하여 정밀도 향상을 얻을 수 있다.최고의 앙상블 점수를 제시하기 위해, 가중치 β와 함께 클래스 가능성인 sc 및 sf를 이하와 같이 블렌딩하였다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "{M, F, Q, D, R} = {0.6, 1.0, 0.3, 1.0, 0.8}과 같이 각 작업에 대해 α를 경험적으로 선택했다(도 7(a) 참조). 예를 들어, 프린터의 식별에 있어서는, 클로즈업 이미지를 분석하는 모델의 출력과 전체 객체 이미지를 분석하는 모델의 출력 각각이 0.6 : 0.4의 비중에 따라 결합되는 경우 가장 최적의 결과를 보였다. 여기서, 각 모델(: 분류기)의 출력은, 각 분류의 프린터에 해당할 가능성을 나타낼 수 있다. 클로즈업 이미지 테스트를 위해 클로즈업 이미지의 수를 다양하게 하여 전체적인 정밀도를 보여준다. 도 7(b)와 같이 테스트 이미지의 개수에 따라 정확도가 점차 향상되었다. 비교 테스트를 위해 GLCM(gray-level co-occurrence matrix)을 기반으로 하는 지원 벡터 머신(SVM) 분류기가 사용되었다. Li et al.은 두 가지 별개의 패턴인 밴딩 텍스처와 부착 텍스처를 대상으로 제안했다. 다만, 본 개 시에서 제작된 모델들 사이에서 부착 텍스처가 잘 발생하지 않는다. 따라서 밴딩 텍스처가 있는 클로즈업 이미"}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "지만 비교 테스트를 수행하는 데 사용되었다. 요약하면, GLCM을 사용하여 의미 있는 결과를 얻지 못했고, 본 개 시에 따른 베이스라인은 표 4와 같이 훨씬 더 나은 일반화 성능을 보여준다. 각 작업에 대한 GLCM 기반 방법의 자세한 정밀도는 다음과 같습니다. {M, F, Q, D, R} = {0.404, 0.716, 0.455, 0.299, 0.561}. Li et al.의 강건성 분석에서도 GLCM 기반 방법이 기하학과 질감 스타일에 상당한 영향을 받는다고 보고했다. 반면, 본 개시에 따른 접근 방식은 표 5와 같이 다양한 기하학적 모양에서 안정적인 성능을 보여준다. 표 5"}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "포렌식 응용에서 중요한 증거는 다양한 물체의 모양을 포함할 수 있으므로 프린팅 모델의 기하학에 따른 성능 평가도 필요하다. 훈련에서 하나의 기하학이 무작위로 제외된 상태로 교차 검증이 수행되었다. 표 5에서 보는 바와 같이 실험 결과는 물체의 형태나 질감의 종류에 관계없이 일관된 성능을 보였다. 프린터 모델 식별 프린터의 모델명, 브랜드, 식별 정보 중 적어도 하나를 식별하기 위한 과정이다. 클로즈업 이미지 세트를 기반으로 한 평가는 0.991의 식별 정밀도를 보여주었다. 특정 필라멘트와 설정이 적용 되기 때문에 인쇄면의 프린터 특성화를 위한 다양한 유형의 노이즈 패턴이 있다. 전체 객체 이미지의 경우 거시 적 물체의 형태에 더 집중하여 학습을 진행하였으며, 계속해서 좋은 성능(0.986)을 보였다. 210F 및 320C 프린 터에서는 동일한 프린터 제조업체와 필라멘트를 사용했기 때문에 잘못된 경우가 발생했다(도 8 참조). 앙상블에 서 1.000이라는 결과를 얻었으므로 디지털 이미징을 통해 프린터 모델을 결정하는 문제는 해결할 수 있게 되었 다. 필라멘트 재료 식별 도 9는 필라멘트 재료 식별에 대한 실험 결과를 보여준다. 전체 정확도는 0.981이었다. 분류기(모델) 훈련이 진 행되는 동안 훈련 손실(Loss)은 일부 필라멘트 유형(PETG, 나일론, ASA 및 ABS)에 대해 빠르게 수렴되지 않았다. 또한 1) ABS 및 ASA, 2) PETG 및 PLA+와 같은 몇 가지 오류 사례가 있었다. 도 4와 같이 수집된 표면 이미지는 상당히 유사하다. 각 필라멘트 쌍에 있어 기본 재료 또는 생산 방법 역시 동일하다(표 2 참조). 품질 매개변수 식별 레이어 두께(δ)와 쉘 수(ns. Number of shells)의 두 가지 유형의 슬라이싱 매개변수에 대한 실험이 수행되었 다. 레이어 두께는 상당히 다른 표면 스타일을 생성한다. 따라서 클로즈업 이미지를 기반으로 한 실험에서 예상 한 대로 층 두께가 잘 구별되었다. 쉘의 개수에 따른 분류는 만족할 만한 성능을 나타내지 않았으며, 이는 본 매개변수에 의한 미시적 표면의 시각적 차이가 없음을 의미한다. 이에 반해 전체 객체 영상을 이용한 판별은 약간 더 나은 성능을 보였다(표 6 참조). 표 6"}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "이러한 결과는 미시 영상보다 전체 객체 영상에서 쉘 수(ns)의 제조흔적이 적절하게 관찰되었음을 의미한다. 따 라서 ns에 의해 영향을 받는 표면 상태의 일관성이 거시적 관점에서 구별될 수 있다고 볼 수 있다. 장치-레벨 식별 표 4에서 보는 바와 같이 클로즈업과 전체 객체 이미지의 전체 정확도는 각각 0.725와 0.617이었다. 도 10은 각 인쇄 장치에 대한 실험 결과를 보여준다. 장치-레벨 점수는 모델에 따라 클러스터링되는 경향이 있으며 이러한 경향은 다중 작업(multi-task) 학습 이후에 더 강해진다. 또한, 관련 작업 뿐 아니라 다른 이미지 양식에서 정 보를 수집하기 위해 본 개시의 일 실시 예에 따라 multitask-multimodal 아키텍처를 제안한다. 표 7은 제안된 접근법의 절제 결과를 간략하게 보여준다. 프린터 장치 식별을 위해 하위 작업 목표 P가 더 나은 성능을 얻는 데 도움이 되었다. 또한, multimodal training은 5.5% 개선을 달성했다. 도 7(a)의 이전 앙상블에 비해 더 최적 화된 결과를 얻었다. 그러나 동일한 프린터 및 매개변수의 장치-레벨 평가는 여전히 충분히 정확하지 않았다. 수집된 객체는 동일한 설정 및 환경(예: 공간, 온도, 습도)에서 제작되었으므로 기준 접근 방식으로 잘 구분할 수 없다. 다른 연구의 실험과 달리 동일한 색상과 브랜드의 필라멘트를 사용하여 장치-레벨 식별이 더 어려웠다. 스캔 및 재인쇄 감지 9가지 유형의 인쇄 설정(Replicator+, 320F, Finder)에서 가져온 총 36개의 객체에 대하여 추가 실험하였다. 클 로즈업 및 전체 객체 이미지에 따른 전체 정확도는 각각 1.000 및 0.972였다. 스캔 및 재인쇄 후 눈에 띄는 표 면 패턴이 나타나지 않음에도, 본 개시에 따른 베이스라인 방법은 클로즈업 이미지를 기반으로 스캔 및 재인쇄 개체를 완벽하게 감지한다. 한편, 본 개시의 일 실시 예에 따른 인공지능 모델(: 분류기) 내에는, 서로 다른 소스 프린터 사이에 마진 을 갖는 지문 임베딩을 추출하는 인코더를 포함할 수 있다. 지문 일치 작업에 대한 고유한 표현을 추출하는 E(s)를 최적화하기 위해 다음과 같이 설명된 삼중항 손실이 사용될 수 있다."}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "객체는 sa, sa와 동일한 소스를 설명하는 sp, sa와 동일한 소스를 나타내지 않는 sn을 그려서 형성된다. m은 sp와 sn의 임베딩 출력 사이의 마진 값이다. 일 예로, 마진 값 m = 1.0인 사전 최적화된 기본 네트워크 (EfficientNet-B3 모델)의 1,536-dim 기능이 사용되었다. 여기에서 삼중항 손실 최적화는 다른 작업과 별도로 수행되었다. 도 11은 보안 프린터 목록 외의 장치에 대해 계산된 유클리드 마진을 보여준다. 이 예비 실험에서는 인코더 훈 련에 클로즈업 이미지 데이터 세트를 사용했다(다만, 전체 객체 이미지 데이터 세트 역시 사용 가능하다). 결과는 동일하거나 다른 프린터 쌍에서 파생된 평균 거리가 보안 프린터와 비교하여 차별화됨을 보여준다. 이 접근 방식은 1) 데이터베이스 인덱싱을 위한 고유한 지문, 2) 두 개의 알 수 없는 인쇄 객체의 소스 비교, 3) 보안 프린터 목록에서 외부 장치 감지와 같은 적용이 가능하다. 본 개시는 소비자 수준 3D 프린터에서 3D 프린트 결과 생성된 객체의 포렌식에 대한 통찰력을 갖춘 전자 장치 및 그 제어 방법을 제공한다. 보다 일반화된 멀티미디어 포렌식 연구 기법을 위한 표준 벤치마크 SI3DP 데이터 세트가 소개된다. 본 개시에 따른 베이스라인은 표면 질감의 미세한 차이를 기반으로 프린터 유형과 속성을 식 별할 수 있음을 보여준다(클로즈업 이미지 테스트). CNN의 발전은 비교적 거시적인 보기(전체 객체 이미지)에서 도 특정 수준의 성능을 달성하는 데 도움이 되었다. 클로즈업 및 전체 객체 이미지에 대해 훈련된 분류기의 성 능은 서로 보완적이다. 따라서 더 나은 결과를 얻기 위해 분류기의 앙상블을 사용할 것을 제안한다. 근접 촬영 이미지와 같은 미시적 뷰만이 프린터 모델을 식별하는 데 유용하다는 기존의 믿음과 달리, 클로즈업 이미지용 모델 및 전체 객체 이미지용 모델이 모두 사용된 multi-task-modal 학습을 사용하는 것이 정확도의 향상을 가져 오는 것으로 확인된다. 상술한 개념과 실험 결과를 토대로, 이하 전자 장치 내지는 전자 장치의 제어 방법에 해당하는 기술적 사상에 대해 설명한다. 이하 내용이 상술한 실험을 통해 뒷받침될 수는 있으나, 상술한 실험과 동일한 범위로 한정될 필요가 없음은 물론이다. 도 12는 본 개시의 일 실시 예에 따른 전자 장치의 구성 및 동작을 설명하기 위한 블록도이다. 도 12를 참조하면, 전자 장치는 메모리 및 프로세서를 포함한다. 전자 장치는 3D 프린팅 객체가 촬영된 이미지를 분석하여 프린터를 식별하기 위한 다양한 기기에 해당할 수 있다. 구체적으로, 전자 장치는 서버, 위조 방지 장치, 소스(: 프린터) 감별 장치, 카메라 장치 등으로 구현될 수 있으며, 위조 방지 시스템을 구성하는 적어도 하나의 컴퓨터에 해당할 수도 있다. 또는, 전자 장치는 스마트폰, 태블릿 PC, 데스크탑 PC, 노트북 PC, PDA 등 범용적인 단말 기기로 구현될 수도 있다. 이 경우, 전자 장치는 적어도 하나의 서버를 통해 제공되는 웹 페이지, 애플리케이션, 또는 소 프트웨어 프로그램을 통해 후술할 기능을 수행할 수도 있다. 메모리는 전자 장치의 구성요소들의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 전자 장치의 구성요소와 관련된 적어도 하나의 인스트럭션 또는 데이터를 저장하기 위한 구성이다. 메모리는 ROM, 플래시 메모리 등의 비휘발성 메모리를 포함할 수 있으며, DRAM 등으로 구성된 휘발성 메모 리를 포함할 수 있다. 또한, 메모리는 하드 디스크, SSD(Solid state drive) 등을 포함할 수도 있다. 도 12를 참조하면, 메모리는 인공지능 모델을 포함할 수 있다. 인공지능 모델은 비지도 학습, 지도 학습, 또는 하이브리드 학습 기반의 모델일 수 있다. 예를 들어, 인공지능 모델은 신경망 모델에 해당할 수 있다. 구체적으로, 인공지능 모델은 DNN(Deep Neural Network), CNN(Convolutional Neural Network) 모델, RNN(Recurrent Neural Network) 모델, GAN(Generative Adversarial Network) 모델, RL(Reinforcement Learning) 모델, 트랜스포머(Transformer) 등 다양한 학습 방식의 모델로 구현될 수 있다. 이 밖에, 인공지능 모델은 HMM(Hidden Markov model), 퍼셉트론, SVM(Support Vector Machine), NBC(Nave Bayes Classifier), SOM(Self-Organizing Map), ART(Adaptive Resonance Theory), DBN(Deep Belief Network), BM(Boltzmann machine), K-means 알고리즘 등 다양한 학습 알고리즘 기반 모델로 구현될 수 도 있다. 본 개시의 일 실시 예로, 인공지능 모델은 하나 이상의 레이어를 포함하는 신경망 모델로 구현될 수 있으 며, 서로 다른 레이어에 포함된 노드 간 가중치의 값을 매개로 업데이트/훈련될 수 있다. 대표적으로, 인공지능 모델은 CNN 모델에 해당할 수 있다. 인공지능 모델은 3D 프린팅 객체가 촬영된 이미지를 분석하여 1) 프린터 식별, 2) 필라멘트 종류 식별, 3) 스캔-및-재인쇄 여부 식별 중 적어도 하나의 기능을 수행하도록 훈련된 것일 수 있다. 프로세서는 전자 장치를 전반적으로 제어하기 위한 구성이다. 구체적으로, 프로세서는 메모리 와 연결되는 한편 메모리에 저장된 적어도 하나의 인스트럭션을 실행함으로써 본 개시의 다양한 실시 예들에 따른 동작을 수행할 수 있다. 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit) 등과 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서 등을 포함할 수 있 다. 인공지능 전용 프로세서는, 특정 인공지능 모델의 훈련 내지는 이용에 특화된 하드웨어 구조로 설계될 수 있다. 일 실시 예로, 프로세서는 3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 인공지능 모델에 입력하 여, 객체를 생성한 3D 프린터를 식별할 수 있다. 이때, 이미지는 전자 장치의 카메라에 의해 촬영된 것일 수도 있고, 외부 전자 장치의 카메라에 의해 촬영 되어 전자 장치로 전송된 것일 수도 있다. 이미지는, 클로즈업 이미지 또는 전체 객체 이미지에 해당할 수 있다. 클로즈업 이미지는 3D 프린팅 객체의 적 어도 일부가 일정 거리 내에서 일정 배율 이상 확대되어 촬영된 이미지에 해당한다. 전체 객체 이미지는, 3D 프 린팅 객체의 전체가 담긴 이미지에 해당하며, 다양한 방향에서 촬영된 이미지일 수 있다. 3D 프린터를 식별하는 동작은, 3D 프린터의 제품명, 모델명, 브랜드 등을 식별하는 등 3D 프린터를 분류하는 동 작을 의미한다. 구체적으로, 인공지능 모델은, 서로 다른 복수의 3D 프린터를 통해 생성된 복수의 객체 각각이 일정 거리 내에서 촬영된 클로즈업 이미지를 바탕으로 훈련된 제1 인공지능 모델을 포함할 수 있다. 이때, 프로세서는, 일 객체(: 검사 대상인 객체)의 적어도 일부가 일정 거리 내에서 촬영된 클로즈업 이미 지를 제1 인공지능 모델에 입력할 수 있다. 그 결과, 제1 인공지능 모델은 해당 객체가 어떤 프린터인지에 대한 분류 결과를 출력할 수 있다. 구체적으로, 각 분류의 프린터에 매칭될 가능성이 출력될 수 있다. 또한, 인공지능 모델은, 서로 다른 복수의 3D 프린터를 통해 생성된 복수의 객체 각각이 전체적으로 포함 되도록 촬영된 전체 객체 이미지를 바탕으로 훈련된 제2 인공지능 모델을 포함할 수도 있다. 이때, 프로세서는, 검사 대상인 객체의 전체가 촬영된 전체 객체 이미지를 제2 인공지능 모델에 입력할 수 있다. 그 결과, 제2 인공지능 모델은 해당 객체가 어떤 프린터인지에 대한 분류 결과를 출력할 수 있다. 구체적으로, 각 분류의 프린터에 매칭될 가능성이 출력될 수 있다. 한편, 인공지능 모델은 객체가 촬영된 이미지가 입력되면, 특징 정보를 추출하는 인코더 모듈, 특징 정보 를 적어도 하나의 3D 프린터의 지문과 비교하여, 객체가 각 분류의 프린터에 의해 생성되었을 가능성을 출력하 는 분류 모듈을 각각 포함할 수 있다. 일 예로, 인코더 모듈은 컨볼루션 레이어에 매칭되고 분류 모듈은 풀리- 커넥티드 레이어에 매칭될 수 있으나, 이에 한정되지 않는다. 여기서, 지문은, 각 분류의 3D 프린터의 특징 정보에 매칭되는 개념이다. 지문 개념의 활용을 위해, 인코더 모 듈은, 서로 다른 분류의 3D 프린터들 각각의 지문에 해당하는 특징 정보 간의 마진이 일정 수치 이상 되도록, 3D 프린터들 각각을 통해 생성된 객체들의 이미지로부터 특징 정보를 추출할 수 있다. 그 결과, 각 분류의 3D 프린터들 각각의 특징 정보는 명확한 차이를 가질 수 있으며, 지문의 개념으로 활용될 수 있다. 한편, 일 실시 예로, 인공지능 모델은 상술한 제1 인공지능 모델 및 제2 인공지능 모델을 모두 포함할 수 있다. 이때, 프로세서는 제1 및 제2 인공지능 모델의 출력을 앙상블하여 분류를 수행할 수도 있다. 구체적으로, 프로세서는, 객체의 적어도 일부가 일정 거리 내에서 촬영된 클로즈업 이미지를 제1 인공지능 모델에 입력하여 제1 출력 정보를 획득하고, 객체의 전체가 촬영된 전체 객체 이미지를 상기 제2 인공지능 모델 에 입력하여 제2 출력 정보를 획득할 수 있다. 여기서, 제1 출력 정보 및 제2 출력 정보는, 각 분류의 3D 프린 터에 매칭될 가능성(확률)을 포함할 수 있다. 이때, 프로세서는 제1 출력 정보와 제2 출력 정보를 결합하여, 객체를 생성한 프린터를 식별할 수 있다. 여기서, 제1 출력 정보와 제2 출력 정보는 기설정된 비중에 따라 결합될 수 있다. 일 예로, 상술한 도 7의 (a)의 실험 결과를 고려했을 때, 3D 프린터 식별에 있어서 제1 출력 정보 및 제2 출력 정보 각각에 대해 0.6 및 0.4의 비중이 적용되는 것이 가장 적절할 수 있다. 한편, 상술한 실시 예를 통해서는 인공지능 모델이 3D 프린터를 식별하도록 훈련된 경우만을 가정하였으나, 필라멘트 종류를 식별하도록 훈련된 경우, 스캔-및-재인쇄 과정을 통해 생성되었는지 여부를 판 단하도록 훈련된 경우 등이 각각 가능하다. 일 실시 예로, 메모리는 3D 프린팅을 수행하는 프린터의 필라멘트 종류를 식별하도록 훈련된 인공지능 모 델을 포함할 수 있으며, 프로세서는 3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 해당 인공지능 모델 에 입력하여, 객체를 생성한 3D 프린터의 필라멘트 종류를 식별할 수 있다. 여기서, 인공지능 모델은 다양한 종 류의 필라멘트에 따라 프린팅 된 3D 프린팅 객체의 이미지를 바탕으로 훈련된 모델일 수 있으며, CNN 모델에 해 당할 수 있으나 이에 한정되지 않는다. 여기서, 상술한 도 7의 (a)의 실험 결과를 고려했을 때, 필라멘트 종류의 식별에 있어서 클로즈업 이미지 기반 의 모델만이 사용되는 것이 가장 적절할 수 있다(앙상블 비중 1 : 0). 또한, 일 실시 예로, 메모리는 스캔-및-재인쇄 여부를 식별하도록 훈련된 인공지능 모델을 포함할 수 있으 며, 프로세서는 3D 프린팅에 따라 생성된 객체가 촬영된 이미지를 해당 인공지능 모델에 입력하여, 객체가 스캔-및-재인쇄 과정을 통해 생성되었는지 여부를 식별할 수 있다. 여기서, 인공지능 모델은 원본인 3D 이미지 데이터를 바탕으로 프린팅 된 3D 프린팅 객체가 촬영된 이미지를 통해 훈련될 수 있다. 또한, 인공지능 모델은, 원본을 바탕으로 프린팅 된 3D 프린팅 객체에 대한 스캔-및-재인쇄 과정을 통해 생성된 3D 프린팅 객체가 촬영 된 이미지를 통해 훈련될 수 있다. 본 인공지능 역시 CNN 모델에 해당할 수 있으나 이에 한정되지 않는다. 여기서, 상술한 도 7의 (a)의 실험 결과를 고려했을 때, 스캔-및-재인쇄 여부의 식별에 있어서, 클로즈업 이미 지 기반의 모델과 전체 객체 이미지 기반의 모델 각각의 출력에 대해 0.8 : 0.2의 비중이 적용되는 앙상블이 가 장 적절할 수도 있다. 한편, 메모리에 저장된 인공지능 모델은, 상술한 분류 기능들(3D 프린터 식별, 필라멘트 종류 식별, 스캔- 및-재인쇄 여부 식별) 중 둘 이상의 분류 기능을 동시에 수행하도록 훈련된 것일 수 있음은 물론이다(multi- modal). 한편, 도 13은 본 개시의 다양한 실시 예에 따른 전자 장치의 상세한 구성을 설명하기 위한 블록도이다. 도 13을 참조하면, 전자 장치는 메모리 및 프로세서 외에도 카메라, 통신부, 디스플 레이, 카메라 중 적어도 하나를 더 포함할 수 있다. 카메라는 3D 프린팅 객체를 촬영하기 위한 구성으로, RGB 카메라, 뎁스 카메라 등에 해당할 수 있다. 카메 라는 클로즈업 이미지를 촬영하기 위해 일정 배율 이상의 확대가 가능한 제1 카메라, 전체 객체 이미지를 촬영하기 위한 일정 거리 범위의 제2 카메라를 각각 포함할 수 있다. 통신부는 다양한 유무선 통신방식으로 적어도 하나의 외부 장치와 통신을 수행하기 위한 회로, 모듈, 칩 등을 포함할 수 있다. 로봇의 이동성 확보를 위해 통신부는 무선 통신을 수행하기 위한 다양한 회로/ 모듈/칩을 구비할 수 있다. 통신부는 다양한 유무선 통신방식으로 적어도 하나의 외부 장치와 통신을 수행하기 위한 회로, 모듈, 칩 등을 포함할 수 있다. 통신부는 다양한 네트워크를 통해 외부 장치와 연결될 수 있다. 네트워크는 영역 또는 규모에 따라 개인 통신망(PAN; Personal Area Network), 근거리 통신망(LAN; Local Area Network), 광역 통신망(WAN; Wide Area Network) 등일 수 있으며, 네트워크의 개방성에 따라 인트라넷 (Intranet), 엑스트라넷(Extranet), 또는 인터넷(Internet) 등일 수 있다. 통신부는 LTE(long-term evolution), LTE-A(LTE Advance), 5G(5th Generation) 이동통신, CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), GSM(Global System for Mobile Communications), DMA(Time Division Multiple Access), WiFi(Wi-Fi), WiFi Direct, Bluetooth, NFC(near field communication), Zigbee 등 다양한 무선 통 신 방식을 통해 외부 장치들과 연결될 수 있다.또한, 통신부는 이더넷(Ethernet), 광 네트워크(optical network), USB(Universal Serial Bus), 선더볼트 (ThunderBolt) 등의 유선 통신 방식을 통해 외부 장치들과 연결될 수도 있다. 전자 장치는 통신부를 통해 3D 프린팅 객체가 촬영된 이미지, 인공지능 모델을 구성하는 데이터, 분 류 결과 데이터 등을 송수신할 수 있다. 디스플레이는 다양한 정보를 시각적으로 출력하기 위한 구성으로, LCD(Lizuid Crystal Display), LED(Light Emitting Diodes), OLED(Organic Light Emitting Diodes), TOLED(Transparent OLED), Micro LED 등 으로 구현될 수 있다. 또한, 디스플레이는 평면 디스플레이, 곡면 디스플레이, 플렉서블 디스플레이, 폴더 블 디스플레이 등으로 구현될 수도 있다. 전자 장치는 3D 프린팅 객체의 이미지, 분류 결과 데이터, 객체 이미지가 입력된 인공지능 모델을 통해 추 출된 프린터의 지문 정보 등을 표시하도록 디스플레이를 제어할 수 있다. 사용자 입력부는 다양한 사용자 명령 내지는 정보를 입력 받기 위한 구성이다. 사용자 입력부는 적어 도 하나의 버튼, 터치 패드, 마이크, 카메라 등을 포함할 수 있다. 일 예로, 전자 장치는 사용자 입력부를 통해 수신되는 사용자 명령에 따라 적어도 하나의 이미지(: 3D 프린팅 객체가 포함된 이미지)를 선택하고, 이미지 내 객체를 생성한 3D 프린터를 식별할 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 서로 저촉되지 않는 한 복수의 실시 예가 결합되어 구현될 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(Software), 하드웨어(Hardware) 또는 이들의 조합된 것 을 이용하여 컴퓨터(Computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 본 개시에서 설명되는 실시 예들은 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 프로세서(Processors), 제어기 (Controllers), 마이크로 컨트롤러(Micro-controllers), 마이크로 프로세서(Microprocessors), 기타 기능 수행 을 위한 전기적인 유닛(Unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 상술한 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 각 장치에서의 처리동작을 수행하기 위한 컴퓨터 명령어 (Computer Instructions) 또는 컴퓨터 프로그램은 비일시적 컴퓨터 판독 가능 매체(Non-transitory Computer- readable Medium)에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어 또는 컴 퓨터 프로그램은 전자 장치 등 특정 기기의 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 전자 장치의 동작을 상술한 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(Reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2022-0122680", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안 될 것이다."}
{"patent_id": "10-2022-0122680", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 인증되지 않은 3D 프린팅 객체(a), 지문 생성(b), 3D 프린팅 객체의 불법 배포(c), 얼굴이 스캔되어 프 린팅 된 마스크를 통해 얼굴 인식 보안이 해제되는 상황(d)을 각각 도시한 도면,도 2는 본 개시에 따른 데이터 세트의 획득을 위해 제작된 3D 객체들이 도시된 도면, 도 3은 본 개시에 따른 데이터 세트 SI3DP의 데이터 샘플들, 도 4는 필라멘트 종류에 대한 품질 매개변수, 텍스처 유형 각각에 대한 클로즈업 이미지의 샘플들을 도시한 도 면, 도 5는 본 개시에 따른 데이터 세트인 SI3DP의 필라멘트, 프린터 모델, 객체 모델, 품질 유형에 대한 클로즈업 이미지의 통계를 나타낸 그래프들, 도 6은 본 개시의 일 실시 예에 따라 활용되는 인공지능 모델의 구조를 도시한 도면, 도 7은 본 개시의 일 실시 예에 따라 각 분류 기능을 수행함에 있어서 클로즈업 이미지 기반 모델과 전체 객체 이미지 기반 모델의 앙상블 비중 별 정확도, 클로즈업 이미지의 수에 따른 정확도를 각각 도시한 그래프들, 도 8은 클로즈업 이미지로 구성된 데이터 세트, 전체 객체 이미지로 구성된 데이터 세트 각각에 기초한 프린터 모델 식별 결과를 도시한 confusion matrix, 도 9는 클로즈업 이미지로 구성된 데이터 세트, 전체 객체 이미지로 구성된 데이터 세트 각각에 기초한 필라멘 트 재료 식별 결과를 도시한 confusion matrix, 도 10은 클로즈업 이미지가 적용된 품질 매개변수 분류 기능, 클로즈업 이미지와 전체 객체 이미지가 모두 적용 되고 서브 태스크가 추가된 경우의 품질 매개변수 분류 기능 각각의 confusion matrix, 도 11은 특징 정보의 수치 차이(: 거리)를 도시한 히스토그램의 예시를 도시한 그래프, 도 12는 본 개시의 일 실시 예에 따른 전자 장치의 구성 및 동작을 설명하기 위한 블록도, 그리고 도 13은 본 개시의 다양한 실시 예에 따른 전자 장치의 상세한 구성을 설명하기 위한 블록도이다."}
