{"patent_id": "10-2021-0168053", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0054211", "출원번호": "10-2021-0168053", "발명의 명칭": "인공지능 기반 대화 이미지 생성 방법 및 이를 수행하는 장치", "출원인": "김동준", "발명자": "김동준"}}
{"patent_id": "10-2021-0168053", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력된 이미지의 객체를 인식하는 단계;상기 인식된 객체의 객체 별 감정을 학습된 신경망을 통해 인식하는 단계;상기 인식된 감정의 조합 정보와 매칭 후보 텍스트 내 문장 단위의 감정조합 정보를 비교하여 추출된 매칭 텍스트를 수신하는 단계; 및상기 객체의 적어도 일부와 상기 텍스트를 매핑하여 대화 이미지를 생성하는 단계를 포함하는 인공지능 기반 대화 이미지 생성 방법."}
{"patent_id": "10-2021-0168053", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 매칭 텍스트는 상기 이미지 내 위치 정보 또는 상기 인식된 객체 중 이미지내 장소를 정의하는 배경요소정보를 이용하여 추출된 매칭 후보 텍스트로부터 추출되는 것을 특징으로 하는 인공지능 기반 대화 이미지 생성방법."}
{"patent_id": "10-2021-0168053", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 감정을 인식하는 단계는 사람의 이미지 내 위치에 따른 감정의 순차적인 정보를 추출하는 것을 특징으로하는 인공지능 기반 대화 이미지 생성 방법."}
{"patent_id": "10-2021-0168053", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 매칭 텍스트를 수신하는 단계는, 상기 이미지로부터 인식된 감정의 순차적인 정보와 일치하는 순서를 갖는문장 단위의 감정 조합 정보를 갖는 텍스트를 수신하는 것을 특징으로 하는 인공지능 기반 대화 이미지 생성 방법."}
{"patent_id": "10-2021-0168053", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 이미지로부터 인식된 감정 조합 정보는 객체별 제1 순위 감정과 제2 순위 감정의 복수의 조합으로 구성되며,상기 매칭 텍스트를 수신하는 단계는 상기 제1 순위 및 상기 제2 순위 감정의 순차적인 정보와 일치하는 순서를갖는 문장 단위의 감정 조합을 갖는 텍스트를 수신하는 것을 특징으로 하는 인공지능 기반 대화 이미지 생성 방법."}
{"patent_id": "10-2021-0168053", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서,상기 대화 이미지를 생성하는 단계는,상기 객체의 얼굴 이미지와 상기 수신된 매칭 텍스트를 순차 나열하여 대화형 이미지로 생성하는 것을 특징으로하는 인공지능 기반 대화 이미지 생성 방법."}
{"patent_id": "10-2021-0168053", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2023-0054211-3-제 1 항에 있어서,상기 인식하는 단계에서 연속하여 입력된 이미지 내 인식된 객체가 동일한 경우,상기 매칭 텍스트를 수신하는 단계는 이전 이미지에 대하여 추출된 매칭 후보 텍스트 내 감정 조합 정보를 이용하여 추출된 매칭 텍스트를 수신하는 것을 특징으로 하는 인공지능 기반 대화 이미지 생성 방법."}
{"patent_id": "10-2021-0168053", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항 내지 제 7 항 중 어느 한 항에 따른 대화 이미지 생성 방법을 수행하는 프로그램이 저장된 컴퓨터 판독가능한 기록 매체."}
{"patent_id": "10-2021-0168053", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 딥러닝을 이용한 감정인식을 통해 대화형 이미지를 생성하는 방법에 관한 것으로 본 발명에 따른 인공 지능 기반 대화 이미지 생성 방법은 입력된 이미지의 객체를 인식하는 단계; 상기 인식된 객체의 객체 별 감정을 학습된 신경망을 통해 인식하는 단계; 상기 인식된 감정의 조합 정보와 상기 매칭 후보 텍스트 내 문장 단위의 감정 조합 정보를 비교하여 추출된 매칭 텍스트를 수신하는 단계; 및 상기 객체의 적어도 일부와 상기 텍스트를 매핑하여 대화 이미지를 생성하는 단계를 포함한다. 본 발명에 따르면, 임베딩 기반의 판단 모델과 신경망 모델 을 이용함으로써, 감정 정보를 보다 정확하게 판단 및 분류할 수 있다."}
{"patent_id": "10-2021-0168053", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝을 이용한 감정인식을 통해 대화형 이미지를 생성하는 방법에 관한 것이다."}
{"patent_id": "10-2021-0168053", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스마트폰과 모바일 통신 기술의 발달에 힘입어 사용자들은 과거에 오프라인을 통해 수행하던 기능을 언제 어디 서나 간편하고 편리하게 이용할 수 있게 되었고, 다른 사용자들과 언제 어디서나 다양한 채널을 통해 의사 소통 이 가능하게 되었다. 사용자는 소셜 네트워크 서비스를 통하여 자신의 일상을 기록하거나, 다른 사 용자의 일상과 관련된 피드에 공 감하거나 이를 재 공유하는 등 활발한 정보의 공유 가 가능해졌으며 텍스트 뿐만 아니라 사진이나 동영상 등도 손쉽게 공유할 수 있게 되었다. 나아가, 인공지능 기술의 발달은 스마트폰의 보급과 함께 더욱 다양한 서비스 를 제공할 수 있게 되었다. 최근 에는 사용자의 얼굴을 인식하고 얼굴에 직접 메이 크업을 가상으로 생성하거나, 다양한 변신이 가능하도록 함으 로써 단순한 기능적 기능 외에도 흥미를 유발할 수 있는 요소로도 인공지능 기술이 활용되고 있다. 이렇게 발달한 소셜 네트워크는 그 파급력을 바탕으로 최근에는 중요한 마케팅 채널로 이용되고 있으며, 직접적 인 광고 정보를 제공하기 보다는 사용자의 참여 를 유발하고 참여를 통해 보다 흥미로운 컨텐츠들을 생산함으로 써 보다 적극적인 광고 효과를 제공하고자 하는 노력이 발생하고 있다."}
{"patent_id": "10-2021-0168053", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 모바일 기반의 감정 인식 모델을 이용하면서 이미지에 따른 감정과 매칭되는 감정 정보를 추출하는 것을 목적으로 한다. 보다 구체적으로, 본 발명은 딥러닝 기반의 자연어 처리를 통해 텍스트의 감정을 분류하고, 이미지의 감정에 매 칭되는 텍스트로 대화 이미지를 생성하는 것을 목적으로 한다. 또한, 본 발명은 개인화된 이미지의 장소나 배경 자체의 특징을 반영하고, 개인정보의 이용을 최소화한 대화 이 미지 생성 방법을 제안하는 것을 목적으로 한다."}
{"patent_id": "10-2021-0168053", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명에 따른 인공지능 기반 대화 이미지 생성 방법은 입력된 이미지의 객 체를 인식하는 단계; 상기 인식된 객체의 객체 별 감정을 학습된 신경망을 통해 인식하는 단계; 상기 인식된 감 정의 조합 정보와 상기 매칭 후보 텍스트 내 문장 단위의 감정 조합 정보를 비교하여 추출된 매칭 텍스트를 수 신하는 단계; 및 상기 객체의 적어도 일부와 상기 텍스트를 매핑하여 대화 이미지를 생성하는 단계를 포함한다."}
{"patent_id": "10-2021-0168053", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 임베딩 기반의 판단 모델과 신경망 모델을 이용함으로써, 감정 정보를 보다 정확하게 판단 및 분류할 수 있다.또한, 본 발명은 임베딩 기반의 판단 모델을 이용함으로써, 저사양 모바일에서도 용이하게 이용할 수 있다. 또한, 사용자의 이미지를 신경망을 학습시킴으로써 사용자의 특성에 따른 감정 정보에 대한 적응성을 높임과 동 시에 학습을 위한 개인정보의 이용을 최소화할 수 있다."}
{"patent_id": "10-2021-0168053", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 내용은 단지 발명의 원리를 예시한다. 그러므로 당업자는 비록 본 명세서에 명확히 설명되거나 도시 되 지 않았지만 발명의 원리를 구현하고 발명의 개념과 범위에 포함된 다양한 장치를 발명할 수 있는 것이다. 또한, 본 명세서에 열거된 모든 조건부 용어 및 실시 예들은 원칙적으로, 발명의 개념이 이해되도록 하기 위한 목적으로만 명백히 의도되고, 이외같이 특별히 열거된 실시 예들 및 상태들에 제한적이지 않는 것으로 이해되어 야 한다. 상술한 목적, 특징 및 장점은 첨부된 도면과 관련한 다음의 상세한 설명을 통하여 보다 분명해질 것이며, 그에"}
{"patent_id": "10-2021-0168053", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "따라 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 발명의 기술적 사상을 용이하게 실시할 수 있을 것 이다. 또한, 발명을 설명함에 있어서 발명과 관련된 공지 기술에 대한 구체적인 설명이 발명의 요지를 불필요하게 흐 릴 수 있다고 판단되는 경우에 그 상세한 설명을 생략하기로 한다. 이하에는 첨부한 도면을 참조하여 본 발명의 바람직한 실시 예에 대해 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 대화 이미지 생성 방법을 수행하는 시스템의 구성을 나타낸 도이다. 도 1을 참조하면, 딥러닝 모델을 이용하여 이미지에서 감정 정보를 판단하기 위해 사용자 단말기의 이미지 입력부는 이미지를 입력 받는다. 감정 인식부는 입력된 이미지 내 객체, 바람직하게는 사람의 표정을 통해 감정을 인식한다. 다음, 대화형 이미지를 생성하기 위해 사용자 단말기는 획득된 감정 정보를 포함하는 이미지 정보를 서버 로 송신한다. 이미지 정보에는 감정 정보 외에 이미지의 촬영 장소와 관련된 정보, 촬영 시간 또는 장소와 관련된 위치 태그 정보들이 포함될 수 있다. 서버는 수신한 이미지 정보를 통해 매칭되는 텍스트를 추출하고 매칭 텍스트를 다시 사용자 단말기에 송신한다. 사용자 단말기는 수신한 매칭 텍스트와 이미지를 이용하여 대화형 이미지로 재구성할 수 있으며 이를 사용 자에게 제공한다. 구체적으로 사용자 단말기의 감정 인식부는 학습된 신경망을 통해 사람의 얼굴 표정을 인식하고, 감정 분 류 결과를 출력할 수 있다. 나아가 본 실시예에서 서버는 이러한 대화 이미지를 생성하기 위해 미리 텍스트 정보들을 수집하고 감정 정보들을 분류하여 DB화할 수 있다.도 2를 참조하면, 도 2는 본 실시예에 따른 서버의 구성을 나타내는 것으로 소설이나 시나리오 등의 텍스 트들을 수집한 서버는 텍스트 DB에 텍스트를 감정별로 분류 할 수 있다. 구체적으로 텍스트 내 문장을 단위로 문장에 포함된 감정들을 분류할 수 있으며, 바람직하게는 신경망을 이용하 여 감정을 상술한 이미지 내 감정 분류와 동일한 분류에 따라 분류한다. 또한, 본 실시예에서 텍스트를 분류하는 신경망은 순환 신경망 구조를 통해 이전 문장의 분류 결과를 현재의 문 장 분류 결과에 반영하도록 학습 시킬 수 있으며 분류 결과와 함께 텍스트 내 장소 나 배경에 대한 정보를 추가 로 수집하여 저장하는 것도 가능하다. 또한, 신경망의 분류 없이 직접 소설이나 시나리오의 원작자가 문장 단위로 레이블링한 텍스트를 DB에 저장하는 것도 가능하다. 이상의 DB로부터 서버는 1차적으로 매칭 후보 텍스트를 추출한다. 매칭 후보 텍스트 추출부는 위치 정보, 예를 들어 GPS, 장소태그, 이미지 내 배경객체 들의 정보를 통해 전체 텍스트 중에서 대화 이미지 생성에 이용될 매칭 후보 텍스트를 추출한다. 배경객체는 장소를 인식하는데 단서를 제공할 수 있는 사물이나 시설들로서, 예를 들어 촬영된 이미지의 장소가 건물 내부인지 또는 외부인지, 공원인지 사무실 인지 등을 인식할 수 있는 다양한 객체들을 포함한다. 구체적으로 매칭 후보 텍스트는 다양한 소설이나 시나리오를 단위 또는 보다 세부적으로 소설의 챕터나 시나리 오의 신(Scene)을 단위로 추출될 수 있다. 다음 매칭 텍스트 추출부는 추출된 매칭 후보 텍스트 중에서 구체적으로 이미지 감정과 매칭되는 문장들을 추출 할 수 있다. 이상의 과정을 통해 최종 추출된 문장은 다시 사용자 단말기로 전달됨으로써 사용자 단말기는 이를 이용하 여 대화 이미지를 생성할 수 있다. 이하 도 3을 참조하여 사용자 단말기 상에서 수행되는 본 발명의 일 실시예에 따른 대화 이미지 생성 방법에 대 하여 설명한다. 입력된 이미지의 객체를 인식한다(S100). 구체적으로 본 실시예에서는 이미지 내 사람을 인식할 수 있으며 특히 사람의 감정이 표현된 얼굴을 이미지 내 에서 검출할 수 있다. 다음, 인식된 객체의 객체 별 감정을 학습된 신경망을 통해 인식한다(S200). 검출된 얼굴에 대하여 감정을 분류 한다. 구체적으로 신경망은 이미지 내 얼굴을 검출하고 얼굴 내 눈, 코, 입 등의 형상이나 색깔을 통해 감정을 분류하도록 학습될 수 있다. 본 실시예에서 감정은 행복, 슬픔, 놀람, 경멸, 공포, 역겨움, 화남의 7가지로 분류될 수 있으며 구체적인 분류 결과는 분류별 확률값으로 신경망에서 출력될 수 있다. 다음, 인식된 감정의 조합 정보와 상기 매칭 후보 텍스트 내 문장 단위의 감정 조합 정보를 비교하여 추출된 매 칭 텍스트를 수신한다(S300). 즉, 본 실시예에서는 적어도 2인의 사람이 이미지로부터 검출됨을 전제로, 검출된 사람의 각각의 감정 상태가 조합 정보로 생성될 수 있다. 감정을 인식하는 단계는 사람의 이미지 내 위치에 따른 감정의 순차적인 정보를 추출한다. 도 4를 참조하면, 본 실시예에서 신경망은 이미지 내 객체를 미리 결정된 순서에 따라 구분하여 인식한다. 예를 들어 좌측 상단을 가장 우선으로 객체의 상대적인 위치에 따라 구분할 수 있으며 구분된 순서에 따라 감정의 조 합 정보가 생성될 수 있다. 본 실시예에서 사람 1의 감정은 행복이 가장 높은 확률로 분류될 수 있으며, 사람 2의 감정은 놀람이 가장 높은 확률로 분류 되어 감정 조합 정보는 행복- 놀람의 순서로 결정될 수 있다. 결정된 감정 조합 정보의 순서에 따라 매칭되는 텍스트들을 서버로부터 수신한다. 이를 위하 사용자는 사용자 단말기를 이용하여 감정 정보를 서버로 송신한다. 이미지를 직접 서버로 보내는 대신 감정 조합 정보 만을 서버로 송신함에 따라 개인정보의 이용과 유출의 위험을 최소화 할 수 있다. 다음, 서버로부터 추출된 감정 조합 정보와 매칭된 텍스트를 객체의 적어도 일부와 매핑하여 대화 이미지를 생 성한다(S400). 이때, 서버의 경우 상술한 바와 같이 매칭 텍스트를 추출하여 사용자 단말기로 제공하기 위해 미리 데이터베이 스를 구성할 수 있다. 데이터베이스를 구성하기 위하여 학습된 신경망을 이용하여 텍스트 내 문장들의 감정을 분류할 수 있다. 도 5를 참고하면 신경망은 순환신경망 구조로 이전의 문장의 결과를 가중치에 따라 반영하여 현재 문장의 감정 분류에 이용하는 것으로 구성될 수 있으며, 텍스트의 문장 별로 감정들의 분류 결과를 출력할 수 있다. 예를 들어, 본 실시예에서는 텍스트 1이라고 하는 문학에 대하여 문장 1의 분류 결과는 행복, 문장 2의 분류 결 과는 놀람, 문장 3의 분류 결과는 슬픔으로 신경망이 출력할 수 있다. 이상의 분류 결과에 따라 생성된 DB로부터 서버는 매칭 텍스트를 추출한다. 나아가, 본 실시예에서는 매칭 텍 스트를 추출할 후보 군을 1차적으로 선별하는 것도 가능하다. 이를 위해 서버는 입력된 이미지의 위치 정보를 이용할 수 있다. 구체적으로 매칭 텍스트는 상기 이미지 내 위치 정보 또는 상기 인식된 객체 중 이미지내 장소를 정의하는 배경 요소 정보를 이용하여 추출된 매칭 후보 텍스트로부터 추출될 수 있다. 따라서 서버는 우선적으로 장소가 유사한 텍스트의 문장들을 추출함으로써 이미지와 텍스트의 매칭도를 높일 수 있으며, 감정 조합 정보를 탐색하는데 드는 리소스를 줄일 수 있다. 다음, 매칭 텍스트를 수신하는 단계는, 상기 이미지로부터 인식된 감정의 순차적인 정보와 일치하는 순서를 갖 는 문장 단위의 감정 조합 정보를 갖는 텍스트를 수신한다. 즉, 상술한 이미지의 감정 조합 정보가 행복-놀람 이므로 텍스트 1이 매칭 후보 텍스트에 포함된다면, 매칭 후 보 텍스트 문장 1, 2가 매칭 텍스트로 추출될 수 있다. 따라서, 사용자 단말기는 문장 1, 2를 이용하여 대화 이미지를 생성한다. 또한 본 실시예에서는 대화 이미지를 생성함에 있어서 보다 복합적인 감정 정보를 이용하는 것도 가능하다. 즉, 가장 1순위의 감정 분류 결과만 이용하는 것이 아니라, 감정 분류 결과의 각 확률을 이용하여 매칭되는 텍 스를 추출하는 것도 가능하다. 따라서, 이미지로부터 인식된 감정 조합 정보는 객체 별 제1 순위 감정과 제2 순위 감정의 복수의 조합으로 구 성되는 경우 상기 매칭 텍스트를 수신하는 단계는 상기 제1 순위 및 상기 제2 순위 감정의 순차적인 정보와 일 치하는 순서를 갖는 문장 단위의 감정 조합을 갖는 텍스트를 수신할 수 있다. 도 6을 참조하면 사람 1과 사람 2의 감정 분류 결과 중 복수의 감정 분류 결과를 이용하여 가장 매칭되는 문장 조합을 선별하는 것도 가능하다. 예를 들어 Top 2에 해당하는 이미지 내 객체의 감정의 분류 확률을 포함하여 각 문장 별 대응되는 감정의 분류 확률 값의 매칭도를 판단하여 가장 매칭도가 높은 문장 조합을 매칭 텍스트로 추출하는 것도 가능하다. 매 칭도는 매칭되는 감정의 확률 값의 곱들의 합으로 산출될 수 있으며 가장 높은 값이 산출된 텍스트를 매칭 텍스 트로 추출할 수 있다. 다음, 상기 대화 이미지를 생성하는 단계는, 상기 객체의 얼굴 이미지와 상기 수신된 매칭 텍스트를 순차 나열 하여 대화형 이미지로 생성한다. 예를 들어 도 7을 참조하면 이미지 내 얼굴만을 추출하여 상호 대화를 순차적 으로 나열하여 대화 이미지를 생성할 수 있다. 추가적으로 본 실시예에서 사용자가 이미지를 연속하여 입력함으로써 감정 조합 정보가 순차적으로 생성되며, 입력된 이미지 내 인식된 객체가 동일한 경우 이를 통해 더욱 긴 대화 이미지를 생성하는 것도 가능하다. 따라서, 이때 매칭 텍스트를 수신하는 단계는 이전 이미지에 대하여 추출된 매칭 후보 텍스트 내 감정 조합 정 보를 이용하여 추출된 매칭 텍스트를 수신할 수 있다. 도 7을 참조하면, 사용자의 연속된 이미지 2장이 입력된 경우 각각의 감정 상태의 순서와 매칭되는 소설 어린 왕자의 대사 문장들을 추출하여 대화 이미지로 생성할 수 있다. 이어서, 도 8을 참조하여 상술한 대화 이미지 생성 방법을 수행하는 사용자 단말기의 구성에 대해서 설명 한다. 도 8은 본 발명의 일 실시예에 따른 사용자 단말기의 구조를 나타낸 블록도이다. 도 8을 참조하면, 딥러닝 모델을 이용하여 이미지에서 감정 정보를 판단하기 위해 사용자 단말기는 이미지 입력부, 감정 인식부 및 대화 이미지 생성부를 포함한다. 먼저 이미지 입력부는 이미지를 입력 받는다. 입력되는 이미지는 사용자가 직접 촬영하는 이미지 또는 저 장된 이미지를 업로드하는 것일 수 있으며 바람직하게 본 실시예에서 이미지는 사람의 표정을 식별할 수 있을 정도의 얼굴이 포함된 이미지일 수 있다. 또한 본 실시예에서는 대화 이미지를 생성하기 위하여 대화가 가능한 객체가 복수로 포함된 이미지 일 수 있다. 객체는 사람 외에 감정 상태의 파악이 가능하여 의인화된 동물이나 기타 객체를 포함한다. 따라서, 추가적인 실시예로 이미지 내 하나의 객체가 포함된 경우 가상의 객체를 임의로 생성하여 이미지 내 대 화가 가능한 상대 객체로 이용하는 것도 가능하다. 상대 객체로 생성된 가상의 객체는 버츄얼 휴먼 또는 아바타와 같이 감정을 표정으로 표현 가능하며 따라서 랜 덤하게 생성된 가상의 객체의 감정과 이미지 내 포함된 객체의 감정 조합을 통해 대화를 생성할 수 있다. 감정 인식부는 입력된 이미지 내 객체, 바람직하게는 사람의 표정 또는 가상의 객체의 표정을 통해 감정을 인식한다. 다음, 대화형 이미지를 생성하기 위해 사용자 단말기는 획득된 감정 정보를 포함하는 이미지 정보를 서버 로 송신한다. 이미지 정보에는 감정 정보 외에 이미지의 촬영 장소와 관련된 정보, 촬영 시간 또는 장소와 관련된 위치 태그 정보들이 포함될 수 있다. 서버는 수신한 이미지 정보를 통해 매칭되는 텍스트를 추출하고 매칭 텍스트를 다시 사용자 단말기에 송신한다. 대화 이미지 생성부는 수신한 매칭 텍스트와 이미지를 이용하여 대화형 이미지로 재구성할 수 있으며 이를 사용자에게 제공한다. 구체적으로 사용자 단말기의 감정 인식부는 학습된 신경망을 통해 사람의 얼굴 표정을 인식하고, 감정 분 류 결과를 출력할 수 있다. 상술한 본원 발명에 따르면, 임베딩 기반의 판단 모델과 신경망 모델을 이용함으로써, 감정 정보를 보다 정확하 게 판단 및 분류할 수 있다. 또한, 본 발명은 임베딩 기반의 판단 모델을 이용함으로써, 저사양 모바일에서도 용이하게 이용할 수 있다. 또한, 사용자의 이미지를 신경망을 학습시킴으로써 사용자의 특성에 따른 감정 정보에 대한 적응성을 높임과 동 시에 학습을 위한 개인정보의 이용을 최소화할 수 있다. 나아가, 여기에 설명되는 다양한 실시예는 예를 들어, 소프트웨어, 하드웨어 또는 이들의 조합된 것을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 여기에 설명되는 실시예는 ASICs (application specific integrated circuits), DSPs (digital signal processors), DSPDs (digital signal processing devices), PLDs (programmable logic devices), FPGAs (field programmable gate arrays, 프로세서(processors), 제어기(controllers), 마이크로 컨 트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적인 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시예들이 제어 모듈 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시예들은 별도의 소프트웨어 모 듈들로 구현될 수 있다. 상기 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 적절한 프로그램 언어로 쓰여진 소프트웨어 어플리케이션으로 소프트웨어 코드가 구현될 수 있다. 상기 소프트 웨어 코드는 메모리 모듈에 저장되고, 제어모듈에 의해 실행될 수 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위 내에서 다양한 수정, 변경 및 치환이 가능할 것이다. 따라서, 본 발명에 개시된 실시 예 및 첨부된 도면들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명 하기 위한 것이고, 이러한 실시 예 및 첨부된 도면에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니 다. 본 발명의 보호 범위는 아래의 청구 범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기 술 사상은 본 발명의 권리 범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0168053", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 대화 이미지 생성 시스템 구조를 나타낸 개요도이다. 도 2는 본 발명의 일 실시예에 따른 대화 이미지 생성 서버를 나타낸 개요도이다. 도 3은 본 발명의 일 실시예에 따른 대화 이미지 생성 방법을 나타낸 흐름도이다. 도 4는 본 발명의 일 실시예에 따른 대화 이미지 생성 방법을 수행하는 신경망 구성을 나타낸 예시도이다. 도 5는 본 발명의 일 실시예에 따른 대화 이미지 생성 방법을 수행하는 서버측 신경망 구성을 나타낸 예시도이 다. 도 6은 본 발명의 일 실시예에 따른 신경망 모델의 결과를 통한 매칭 예를 나타낸 예시도이다. 도 7은 본 발명의 다른 실시예에 따라 생성된 대화 이미지를 나타낸 예시도이다. 도 8은 본 발명의 일 실시예에 따른 사용자 단말기의 구성을 나타낸 블록도이다."}
