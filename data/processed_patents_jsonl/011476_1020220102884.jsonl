{"patent_id": "10-2022-0102884", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0024641", "출원번호": "10-2022-0102884", "발명의 명칭": "표정 변화 기반의 위변조 탐지 방법 및 이를 실행하기 위해 기록 매체에 저장된 컴퓨터 프로", "출원인": "주식회사 카카오뱅크", "발명자": "곽영준"}}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "안면 데이터가 포함된 제1 영상을 획득하는 단계;신경망 모델을 이용하여 상기 획득된 제1 영상 내 표정에 대한 제1 표정 예측값을 산출하는 단계;표정을 안내하는 표정 가이드 데이터를 생성하는 단계;상기 표정 가이드 데이터에 따른 제2 영상을 획득하는 단계; 및상기 신경망 모델을 이용하여 수신된 제2 영상 내 표정에 대한 제2 표정 예측값을 산출하는 단계;를 컴퓨팅 장치에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 신경망 모델은 영상 내 표정을 인식하여 상기 표정의 분류 별 표정 예측 확률들이 포함된 표정 예측값을산출하도록 기 학습된 것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 제1 표정 예측값을 기초로 제1 영상 내 표정인 현재 표정을 판단하는 단계;를 더 포함하고,상기 현재 표정을 판단하는 단계는 상기 제1 표정 예측값 내 가장 높은 표정 예측 확률에 대응되는 표정을 상기제1 영상의 현재 표정으로 판단하는 것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 표정 가이드 데이터를 생성하는 단계는 상기 판단된 현재 표정과 다른 표정으로 결정된 목표 표정을 표현하도록 안내하는 표정 가이드 데이터를 생성하는 것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 제1 표정 예측값 및 상기 제2 표정 예측값을 기초로 안면 데이터가 포함된 영상의 위변조 여부를 판단하는단계를 더 포함하는 것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 위변조 여부를 판단하는 단계는상기 제1 표정 예측값 내 상기 현재 표정과 목표 표정에 각각 대응되는 표정 예측 확률을 기초로 제1 표정 스코어를 생성하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,공개특허 10-2024-0024641-3-상기 위변조 여부를 판단하는 단계는상기 제2 표정 예측값 내 상기 현재 표정과 목표 표정에 각각 대응되는 표정 예측 확률을 기초로 제2 표정 스코어를 산출하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6 항에 있어서,상기 위변조 여부를 판단하는 단계는상기 제2 표정 예측값 내 상기 현재 표정과 상기 현재 표정 이외의 표정에 각각 대응되는 표정 예측 확률을 기초로 제2 표정 스코어를 산출하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서,상기 위변조 여부를 판단하는 단계는상기 제1 표정 스코어 및 상기 제2 표정 스코어를 기초로 종합 표정 스코어를 산출하고, 종합 표정 스코어를 기초로 위변조 여부를 판단하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨팅 장치에서 수행되는 표정 변화를 기반으로 영상 내 위변조 탐지 방법에 있어서,사용자 단말로부터 안면 데이터가 포함된 제1 영상을 수신하는 단계;신경망 모델을 이용하여 상기 수신된 제1 영상 내 표정에 대한 제1 표정 예측값을 산출하는 단계;상기 사용자 단말로 다른 표정을 표현하도록 표정 가이드 데이터를 생성하여 전송하는 단계;상기 사용자 단말로부터 상기 표정 가이드 데이터에 따른 제2 영상을 수신하는 단계; 및상기 신경망 모델을 이용하여 수신된 제2 영상 내 표정에 대한 제2 표정 예측값을 산출하는 단계;를 포함하는것을 특징으로 하는 위변조 탐지 방법."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 제1 표정 예측값 및 상기 제2 표정 예측값을 기초로 영상의 위변조 여부를 판단하는 단계를 더 포함하는것을 특징으로 하는 위변조 탐지 방법."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 영상의 위변조 여부를 판단하는 단계는,상기 제1 표정 예측값 내 현재 표정과 목표 표정에 각각 대응되는 표정 예측 확률을 기초로 제1 표정 스코어를생성하는 단계; 및상기 제2 표정 예측값 내 상기 현재 표정과 목표 표정에 각각 대응되는 표정 예측 확률을 기초로 제2 표정 스코어를 산출하는 단계를 더 포함하는 것을 특징으로 하는 위변조 탐지 방법."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 영상의 위변조 여부를 판단하는 단계는,상기 제1 표정 예측값 내 현재 표정과 목표 표정에 각각 대응되는 표정 예측 확률을 기초로 제1 표정 스코어를생성하는 단계; 및공개특허 10-2024-0024641-4-상기 제2 표정 예측값 내 상기 현재 표정과 현재 표정 이외의 표정에 각각 대응되는 표정 예측 확률을 기초로제2 표정 스코어를 산출하는 단계를 더 포함하는 것을 특징으로 하는 위변조 탐지 방법."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12 항에 있어서,상기 영상의 위변조 여부를 판단하는 단계는,상기 제1 표정 스코어 및 상기 제2 표정 스코어를 기초로 종합 표정 스코어를 산출하고, 종합 표정 스코어를 기초로 위변조 여부를 판단하는 단계를 더 포함하는 것을 특징으로 하는 위변조 탐지 방법."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11 항에 있어서,상기 사용자 단말로 상기 위변조 여부를 판단한 위변조 판단값을 전송하는 단계;를 더 포함하는 것을 특징으로하는 위변조 탐지 방법."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "프로세서;상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 로드하는 메모리; 및상기 컴퓨터 프로그램을 저장하는 스토리지를 포함하되,상기 컴퓨터 프로그램은,사용자 단말로부터 안면 데이터가 포함된 제1 영상을 수신하는 동작;신경망 모델을 이용하여 상기 수신된 제1 영상 내 표정에 대한 제1 표정 예측값을 산출하는 동작;상기 사용자 단말로 다른 표정을 표현하도록 표정 가이드 데이터를 생성하여 전송하는 동작;상기 표정 가이드 데이터에 따른 제2 영상을 수신하는 동작; 및상기 신경망 모델을 이용하여 수신된 제2 영상 내 표정에 대한 제2 표정 예측값을 산출하는 동작;을 포함하는것을 특징으로 하는 위변조 탐지 서버."}
{"patent_id": "10-2022-0102884", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "컴퓨터 판독 가능한 기록 매체에 저장되어 제 10 항 내지 제 15 항 중 어느 한 항에 따른 위변조 탐지 방법을실행시키는 프로그램."}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 표정 변화 기반의 위변조 탐지 방법에 관한 것으로, 본 발명에 따른 영상 내 위변조 여부 판단 방법은 사용자 단말로부터 안면 데이터가 포함된 제1 영상을 수신하는 단계; 신경망 모델을 이용하여 상기 수신된 제1 영상 내 표정에 대한 제1 표정 예측값을 산출하는 단계; 상기 사용자 단말로 다른 표정을 표현하도록 표정 가이 드 데이터를 생성하여 전송하는 단계; 상기 사용자 단말로부터 상기 표정 가이드 데이터에 따른 제2 영상을 수신 하는 단계; 및 상기 신경망 모델을 이용하여 수신된 제2 영상 내 표정에 대한 제2 표정 예측값을 산출하는 단계 를 포함한다. 본 발명에 따르면, 표정 변화를 기반으로 영상 내 위변조를 효과적으로 탐지할 수 있다."}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 표정 변화를 기반으로 영상 내 위변조를 탐지하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스마트폰과 모바일 통신 기술의 발달에 힘입어 사용자들은 과거에 오프라인을 통해 수행하던 기능을 언제 어디 서나 간편하고 편리하게 이용할 수 있게 되었다. 일 예로 일상생활에서 금융 활동의 편의성을 더욱 향상시키고자 스마트폰의 어플리케이션을 통해 금융 업무를 비대면(非對面)으로 처리하는 기술이 개발되어 서비스되고 있으며, 서비스 과정에서 비대면으로 사용자의 본인 을 확인하기 위하여 사용자의 얼굴 영상을 이용한 인증 방식이 사용되고 있다. 또한, 최근에는 발달된 인공지능 기술 들이 사회의 전 분야로 확장되어 적용되고 있으며 사람의 기존 업무를 대 신하거나, 보다 신속한 업무처리를 수행할 수 있는 기술들이 금융 서비스에도 적용되고 있다. 하지만, 무분별한 인공지능 기술의 이용은 기존의 목적에서 벗어난 다른 목적으로 활용될 수 있으며 예상하지 못한 다양한 피해들이 발생할 수 있다. 예를 들어, 인공지능 기술을 이용한 합성 기술로 이른바 딥페이크 (Deepfake)기술을 통해 생성되는 가짜 영상의 품질이 육안으로도 구분이 어려울 정도로 고도화되고 있는데, 이 러한 가짜 영상을 생성하는 인공지능 기술이 금융 서비스의 비대면 상태의 본인 인증과정에서 신분의 위변조를 위한 도구로 활용될 수 있다. 따라서, 위변조된 영상을 이용하여 본인 인증을 하는 것을 방지하기 위한 방법이 고안될 필요가 있다."}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 표정 변화를 기반으로 영상 내 위변조를 탐지하는 방법을 제안하는 것을 목적으로 한다. 보다 구체적으로, 본 발명은 표정 변화를 가이드하고, 가이드에 따라 변화된 표정을 이용하여 효율적인 위변조 를 탐지하는 방법을 제안하는 것을 목적으로 한다. 또한, 본 발명은 표정 변화 과정에서 산출된 예측 확률의 상대적인 관계를 이용하여 보다 효과적인 위변조 탐지 를 수행하는 방법을 제안하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위해 고안된 본 발명의 일 실시예에 따른 영상 내 위변조 탐지 방법을 컴퓨팅 장 치에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램은 안면 데이터가 포함된 제1 영 상을 수신하는 단계, 신경망 모델을 이용하여 상기 수신된 제1 영상 내 표정에 대한 제1 표정 예측값을 산출하 는 단계, 표정을 안내하는 표정 가이드 데이터를 생성하는 단계, 상기 표정 가이드 데이터에 따른 제2 영상을 수신하는 단계, 및 상기 신경망 모델을 이용하여 수신된 제2 영상 내 표정에 대한 제2 표정 예측값을 산출하는 단계를 포함할 수 있다. 또한, 상기 신경망 모델은 영상 내 표정을 인식하여 상기 표정의 분류 별 표정 예측 확률들이 포함된 표정 예측 값을 산출하도록 기 학습될 수 있다. 또한, 상기 제1 표정 예측값을 기초로 제1 영상 내 표정인 현재 표정을 판단하는 단계를 더 포함하고, 상기 현 재 표정을 판단하는 단계는 상기 제1 표정 예측값 내 가장 높은 표정 예측 확률에 대응되는 표정을 상기 제1 영 상의 현재 표정으로 판단할 수 있다. 또한, 상기 표정 가이드 데이터를 생성하는 단계는 상기 판단된 현재 표정과 다른 표정인 목표 표정을 표현하도 록 표정 가이드 데이터를 생성할 수 있다. 또한, 상기 제1 표정 예측값 및 상기 제2 표정 예측값을 기초로 영상의 위변조 여부를 판단하는 단계를 더 포함 할 수 있다. 또한, 상기 위변조 여부를 판단하는 단계는 상기 제1 표정 예측값 내 상기 현재 표정과 목표 표정에 각각 대응 되는 표정 예측 확률을 기초로 제1 표정 스코어를 산출하는 단계를 더 포함할 수 있다. 또한 상기 위변조 여부를 판단하는 단계는 상기 제2 표정 예측값 내 상기 현재 표정과 목표 표정에 각각 대응되 는 표정 예측 확률을 기초로 제2 표정 스코어를 산출하는 단계를 더 포함할 수 있다. 또한, 상기 위변조 여부를 판단하는 단계는 상기 제2 표정 예측값 내 상기 현재 표정과 상기 현재 표정 이외의 표정에 각각 대응되는 표정 예측 확률을 기초로 제2 표정 스코어를 산출하는 단계를 더 포함할 수 있다. 또한, 상기 위변조 여부를 판단하는 단계는 상기 제1 표정 스코어 및 상기 제2 표정 스코어를 기초로 종합 표정 스코어를 산출하고, 종합 표정 스코어를 기초로 위변조 여부를 판단하는 단계를 더 포함할 수 있다. 상기 기술적 과제를 해결하기 위해 컴퓨팅 장치에서 수행되는 표정 변화를 기반으로 영상 내 위변조를 탐지하는 방법은 사용자 단말로부터 안면 데이터가 포함된 제1 영상을 수신하는 단계; 신경망 모델을 이용하여 상기 수신 된 제1 영상 내 표정에 대한 제1 표정 예측값을 산출하는 단계, 상기 사용자 단말로 다른 표정을 표현하도록 표 정 가이드 데이터를 생성하여 전송하는 단계, 상기 표정 가이드 데이터에 따른 제2 영상을 수신하는 단계, 상기 신경망 모델을 이용하여 수신된 제2 영상 내 표정에 대한 제2 표정 예측값을 산출하는 단계를 포함할 수 있다. 또한, 상기 제1 표정 예측값 및 상기 제2 표정 예측값을 기초로 영상의 위변조 여부를 판단하는 단계를 더 포함 할 수 있다. 또한, 상기 영상의 위변조 여부를 판단하는 단계는, 상기 제1 표정 예측값 내 상기 현재 표정과 목표 표정에 각 각 대응되는 표정 예측 확률을 기초로 제1 표정 스코어를 생성하는 단계, 및 상기 제2 표정 예측값 내 상기 현 재 표정과 목표 표정에 각각 대응되는 표정 예측 확률을 기초로 제2 표정 스코어를 산출하는 단계를 더 포함할 수 있다. 또한, 상기 영상의 위변조 여부를 판단하는 단계는, 상기 제1 표정 스코어 및 상기 제2 표정 스코어를 기초로 종합 표정 스코어를 산출하고, 종합 표정 스코어를 기초로 위변조 여부를 판단하는 단계를 더 포함할 수 있다. 또한, 상기 사용자 단말로 상기 위변조 예측값을 전송하는 단계를 더 포함할 수 있다. 한편, 위변조 탐지 서버는 프로세서, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 로드하는 메모리 및 상 기 컴퓨터 프로그램을 저장하는 스토리지를 포함하되, 상기 컴퓨터 프로그램은, 사용자 단말로부터 안면 데이터 가 포함된 제1 영상을 수신하는 동작, 신경망 모델을 이용하여 상기 수신된 제1 영상 내 표정에 대한 제1 표정 예측값을 산출하는 동작, 상기 사용자 단말로 다른 표정을 표현하도록 표정 가이드 데이터를 생성하여 전송하는 동작, 상기 표정 가이드 데이터에 따른 제2 영상을 수신하는 동작, 상기 신경망 모델을 이용하여 수신된 제2 영 상 내 표정에 대한 제2 표정 예측값을 산출하는 동작을 포함할 수 있다."}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 표정 변화를 기반으로 영상 내 위변조를 탐지할 수 있다. 또한, 본 발명은 현재 표정을 기반으로 제공되는 인터페이스를 통해 표정 변화를 가이드함으로써 진정 사용자인 지 여부를 탐지하고, 보다 정확하게 영상 내 위변조(예컨대, 인쇄물 등을 이용한 본인 위변조)를 탐지할 수 있 다. 또한, 본 발명은 표정 변화에서 산출되는 각각의 확률을 이용하여 보다 정밀한 위변조 가능성을 판단할 수 있다."}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 내용은 단지 발명의 원리를 예시한다. 그러므로 당업자는 비록 본 명세서에 명확히 설명되거나 도시 되 지 않았지만 발명의 원리를 구현하고 발명의 개념과 범위에 포함된 다양한 장치를 발명할 수 있는 것이다. 또한, 본 명세서에 열거된 모든 조건부 용어 및 실시 예들은 원칙적으로, 발명의 개념이 이해되도록 하기 위한 목적으로만 명백히 의도되고, 이외같이 특별히 열거된 실시 예들 및 상태들에 제한적이지 않는 것으로 이해되어 야 한다. 상술한 목적, 특징 및 장점은 첨부된 도면과 관련한 다음의 상세한 설명을 통하여 보다 분명해질 것이며, 그에"}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "따라 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 발명의 기술적 사상을 용이하게 실시할 수 있을 것 이다. 또한, 발명을 설명함에 있어서 발명과 관련된 공지 기술에 대한 구체적인 설명이 발명의 요지를 불필요하게 흐 릴 수 있다고 판단되는 경우에 그 상세한 설명을 생략하기로 한다. 이하에는 첨부한 도면을 참조하여 본 발명의 바람직한 실시 예에 대해 상세하게 설명한다. <제1 실시예 - 사용자 단말의 위변조 탐지> 도 1은 본 발명의 제1 실시예에 따른 영상 내 위변조 탐지 서비스를 수행하는 시스템 내 사용자 단말 의 동작을 나타낸 예시도이다. 도 1을 참조하면, 본 실시예에 따른 위변조 탐지 서비스는 사용자 단말에서 구동되는 어플리케이션을 이용하여 사용자의 안면 데이터가 포함된 영상을 입력 받음으로써 수행될 수 있다. 본 실시예에 따른 위변조 탐지 서비스는 순차적으로 입력되는 복수의 영상(11a, 11b)에 대한 표정의 판단을 통 해 수행될 수 있으며, 영상의 입력 과정에서 의도적인 표정의 연출을 사용자에게 요구함으로써 위변조 여부를 보다 정확히 탐지할 수 있도록 한다. 따라서 사용자 단말은 입력된 영상(11a) 내 사용자의 표정을 분석하고, 다른 표정을 유도하기 위한 표 정 가이드 데이터를 생성하여 사용자에게 제공할 수 있다. 다음, 사용자 단말은 사용자로부터 표정 가이드 데이터를 기초로 새로운 표정을 짓는 사용자의 안 면 데이터가 포함된 영상(11b)을 입력 받고, 입력된 영상 내 사용자의 표정을 분석함으로써 위변조 여부를 판단한다. 구체적으로 사용자 단말은 수신된 영상(11b)에 포함된 표정에 대한 분류별 예측값을 산출하고, 산출된 예측값을 기초로 영상의 위변조 여부를 판단할 수 있다. 이때, 사용자 단말에는 영상이 실시간으로 입력될 수 있으며 사용자 단말은 입력된 영상 내 표정의 변화를 실시간으로 판단함으로써 목표 표정에 맞는 표정이 연출되는 경우 위변조 되지 않은 것으로 판단하며 이 를 근거로 본인 인증에 의한 서비스를 제공할 수 있다. 이하 사용자 단말 상에서 수행되는 구체적인 위변조 탐지 방법에 대해 도면을 참고하여 보다 상세히 설명 한다. 도 2는 본 발명의 일 실시예에 따른 영상 내 위변조를 탐지하는 방법을 나타낸 흐름도이다. 도 2를 참조하면, 먼저 사용자 단말은 사용자의 안면 데이터가 포함된 제1 영상을 획득할 수 있다(S10). 사용자 단말은 내부에 탑재된 카메라 모듈을 통해 사용자를 촬영하여 제1 영상을 획득할 수 있다. 다음 사용자 단말은 학습된 신경망 모델을 이용하여 수신된 제1 영상 내 표정에 대한 제1 표정 예측값을 산출할 수 있다(S20). 본 실시예에서 신경망 모델은 영상 내 표정을 인식하여 표정의 분류 별 예측 확률로서 표정 예측값을 출력하도 록 미리 학습될 수 있다. 표정의 분류로는 감정에 따라 무표정, 기쁨을 나타내는 웃는 표정, 슬픔을 나타내는 슬픈 표정, 분노를 나타내 는 화난 표정, 놀라거나 흥분 상태를 나타내는 놀란 표정 및 짜증난 상태를 나타내는 짜증난 표정 등이 포함될 수 있다. 신경망 모델에서 출력되는 분류별 표정 예측값은 신경망 모델의 학습을 위한 데이터 셋의 분류에 따라 결정되므로, 본 실시예에서 표정을 구분하는 기준은 하나의 예시로써 반드시 해당 분류에 따라 구분되어야 함을 정하고자 하는 목적이 아니며 언급한 표정의 분류 외에도 감정 상태를 더욱 세분화하여 구분하거나, 서비스의 구현에 따라 단순화하는 것도 가능하다. 이하에서는 일 예로써 표정을 무표정, 웃는 표정, 슬픈 표정 및 화난 표정으로 구분하여 위변조를 탐지하는 과 정에 대하여 설명한다. 본 실시예 따라 제1 표정 예측값 산출 단계(S20)에서 사용자 단말은 신경망 모델을 통해 영상에서 표정에 대한 특징 데이터를 추출하고, 추출된 표정에 대한 특징 데이터를 기초로 표정 분류 별 예측 확률을 포함하는 표정 예측값을 출력할 수 있다. 신경망 모델은 표정을 구분하기 위해 영상 내 포함된 사용자의 해부학적 특징 요소들이 구성하는 패턴으로 눈, 코, 입 등의 위치와 상대적인 크기의 변화, 또는 얼굴 근육의 변화에 대한 특징 값들을 강화하도록 학습될 수 있다. 구체적인 신경망 모델의 구성과 관련하여 도 3a를 참조하여 설명한다. 도 3a를 참조하면, 본 실시예에 따른 신경망 모델은 입력된 영상에 대하여 복수의 컨볼루션 연산을 수행하 는 레이어로 구성된 CNN(Convolution Neural Network) 모델로 구성될 수 있다. 제1 영상이 신경망 모델에 입력되면, 영상 내 특징 값들은 신경망 모델 내부의 레이어들을 거치면 서 강조될 수 있다. 구체적으로 제1 영상 내에 포함된 표정의 판단을 위해 이용되는 픽셀 값들은 레이어 들 의 필터와 합성곱을 통하여 특징 값으로 산출된다. 산출된 제1 영상 내 특징 값들은 순차적인 컨볼루션 레이어를 거치면서 특징 맵의 형태로 생성되며 반복 연산을 통해 축약된 최종 특징 맵은 분류 결과의 출력을 위해 1차원 형태의 배열로 평탄화(Flatten)될 수 있다. 평탄화된 특징 값들은 완전 연결 레이어(Fully-connected layer)로 입력됨으로써 각 표정 분류별 각각의 예측 확률로 출력될 수 있다. 평탄화된 특징 값들은 완전 연결 레이어 내의 Relu와 같은 활성화 함수에 따라 활성화된 후 소프트맥스 (Softmax) 함수에 따라 미리 정의된 표정 별 예측 확률로써 제1 표정 예측값으로 출력될 수 있다. 도 3a를 참고하면 신경망 모델로부터 출력된 제1 표정 예측값에는 무표정 0.8, 웃는 표정 0.05, 슬픈 표정 0.05, 화난 표정 0.1과 같은 표정 분류 별 표정 예측 확률들이 포함될 수 있다. 이어서 사용자 단말은 산출된 제1 표정 예측값을 기초로 사용자의 표정을 유도하기 위한 목표 값으로 목표 표정을 판단할 수 있다(S30). 본 실시예에서 현재 표정은 제1 영상 내 예측 확률을 기초로 가장 높은 확률을 갖는 사용자의 표정일 수 있다. 반면, 목표 표정은 현재 표정을 기준으로 위변조를 판단하기 위해 사용자로부터 유도할 목표가 되는 표정을 의 미한다. 목표 표정은 제1 표정 예측값으로 판단된 현재 표정과 다른 표정으로 결정되는 것이 바람직하며, 신경망의 분류 내에서 현재 표정을 제외한 표정 중 어느 하나의 표정으로 결정될 수 있다. 구체적으로, 목표 표정은 표정 예측 값 내 분류 별 확률을 이용하여 결정될 수 있다. 예를 들어, 도 3a와 같이 제1 표정 예측값이 산출된 경우, 사용자 단말은 제1 영상의 현재 표정을 가장 높은 확률인 무표정(0.8)으로 판단할 수 있으며, 사용자 단말은 제1 표정 예측값 내 차순위의 표정 예측 확률에 대응되는 표정을 목표 표정으로 판단할 수 있다. 사용자 단말은 차순위의 표정 예측 확률을 가지는 표정을 목표 표정으로 설정하되 현재 표정과 목표 표정 의 예측 확률의 상대적인 변화를 위변조 판단에 이용함으로써 사용자로 하여금 보다 정확한 목표 표정의 연출을 요구할 수 있다. 따라서, 도 3a와 같이 제1 표정 예측값이 산출된 경우, 사용자 단말은 목표 표정을 화난 표정(0.1)으 로 설정할 수 있다. 이어서, 사용자 단말은 판단된 목표 표정에 따라 현재 표정과 다른 표정을 사용자가 연출하도록 표정 가이 드 데이터를 생성하고, 생성된 표정 가이드 데이터를 표시할 수 있다(S40). 표정 가이드 데이터는 목표 표정을 설명하기 위한 정보로서 직접적인 표정의 분류 명으로 표시되는 것도 가능하 나, 본 실시예에서는 목표 표정을 나타내는 가상의 캐릭터(예컨대, 이미지 또는 영상)를 이용하여 안내하는 것 도 가능하다. 예를 들어, 사용자 단말은 유도하는 목표 표정을 '웃는 표정'과 같은 텍스트 형태로 직접적으로 나타내는 것 외에, 목표 표정을 가지고 있는 캐릭터 영상을 가이드로 이용함으로써 사용자의 흥미와 집중을 유발할 수 있 다. 또한, 가이드에 이용되는 캐릭터는 사용자의 영상 내 안면 데이터를 기초로 판단된 성별이나 나이 등의 개인 데 이터를 이용하여 선별될 수 있다.또는 보다 위변조 탐지 과정의 신뢰성을 높이기 위해 캐릭터 영상을 직접 생성하는 경우 랜덤한 노이즈 값을 입 력하거나 또는 결정된 목표 표정에 대한 특징 값을 입력으로 하는 적대적 생성 신경망(GAN:Generative Adversarial Network)을 이용하여 가이드 영상을 생성하는 것도 가능하다. 다음, 사용자 단말은 표정 가이드 데이터에 따른 안면 데이터가 포함된 제2 영상을 획득할 수 있다 (S50). 사용자 단말은 신경망 모델을 이용하여 수신된 제2 영상 내 표정에 대한 제2 표정 예측값을 산출 할 수 있다(S60). 구체적으로, 제2 표정 예측값 산출 단계(S60)에서 사용자 단말은 상술한 제1 영상의 표정 예측값을 출 력하는 방법과 동일한 방법으로 신경망 모델에 제2 영상을 입력함으로써 사용자의 변화된 표정에 대한 제2 표정 예측값을 산출할 수 있다. 도 3b를 참조하면 제2 영상을 신경망 모델에 입력함으로써 사용자 단말은 표정 분류 별 표정 예측 확률들을 포함하는 제2 표정 예측값을 산출할 수 있다. 이때. 제2 영상은 표정 가이드 데이터에 대응하여 실시간으로 변화하는 사용자의 표정을 포함하는 동영상 형태로 수신되고(S50), 동영상의 각 프레임에 대한 표정 분류 결과를 제2 표정 예측값으로 산출하는 것도 가능 하다(S60). 따라서, 표정 가이드 데이터를 생성하여 표시하는 단계(S40) 내지 제2 표정 예측값을 산출하는 단계(S60)는 실 시간으로 수집되는 영상에 대하여 반복적으로 수행될 수 있다. 사용자 단말은 사용자의 표정이 목표 표정 으로 변화하는 과정에서 지속적으로 수신되는 영상 내 사용자의 실시간 표정의 변화와 그에 따른 분류 값을 표 정 가이드 데이터와 함께 제공할 수 있다. 도 4를 참고하면 사용자 단말은 원형 도표(Pie chart) 형태로 사용자의 실시간 표정의 변화가 어떻게 나타나고 있는지를 캐릭터를 통해 표현되는 표정 가이드 데이터와 함께 생성하여 제공할 수 있다. 사용자는 사용자 단말을 통해 제공되는 표정 가이드 데이터를 기초로 목표 표정을 확인하고, 해당 표 정을 묘사하도록 자신의 표정을 변화시키되 원형 도표를 통해 표정을 확인함으로써 목표 표정의 연출을 정확히 수행할 수 있다. 또한, 사용자는 자신의 표정 변화 과정이 인증에 이용되고 있음을 인식하고, 목표 표정으로 자신의 표정이 가까 워지고 있음을 통해 인증 절차가 종료됨을 인식하도록 함으로써 사용 편의성을 높일 수 있다. 이어서, 사용자 단말은 산출된 제2 얼굴 표정 예측값을 이용하여 위변조 여부를 판단한다(S70). 구체적으로 사용자 단말은 표정의 분류 별 예측 확률의 변화를 이용하여 위변조를 판단할 수 있다. 먼저, 도 5를 참조하여 현재 표정과 목표 표정의 두 표정 간의 상대적인 확률 변화에 따라 위변조를 탐지하는 방법에 대해 설명한다. - 사용자 단말의 제1 위변조 탐지 방법 도 5는 본 발명의 일 실시예에 따른 영상 내 위변조를 탐지하는 방법을 나타낸 흐름도이다. 도 5를 참조하면, 사용자 단말은 산출된 제1 표정 예측값 내 현재 표정과 목표 표정에 각각 대응되는 표정 예측 확률을 기초로 제1 표정 스코어를 생성할 수 있다(S108). 구체적으로, 제1 표정 스코어 산출 단계(S108)에서 사용자 단말은 아래의 수학식 1을 이용하여 제1 표정 스코어를 산출한다.수학식 1"}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 1에서 은 제1 표정 스코어, 는 제1 영상(img1)으로부터 산출된 제1 표 정 예측값 내 현재 표정에 대응되는 표정 예측 확률, 는 제1 표정 예측값 내 목표 표정에 대 응되는 표정 예측 확률을 의미한다. 예를 들어 도 3a와 같이 제1 표정 예측값이 산출되고, 현재 표정은 무표정, 목표 표정은 화난 표정인 경우, 제1 표정 스코어는 와 같이 산출될 수 있다. 다음, 사용자 단말은 제2 영상(img2)으로부터 산출된 제2 표정 예측값 내 현재 표정과 목표 표정에 각 각 대응되는 표정 예측 확률을 기초로 제2 표정 스코어를 산출할 수 있다(S109). 구체적으로, 제2 표정 스코어 산출 단계(S109)에서 사용자 단말은 아래의 수학식 2를 이용하여 제2 표정 스코어를 산출할 수 있다. 수학식 2"}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 2에서 은 제2 표정 스코어, 는 제2 영상(img2)으로부터 산출된 제2 표 정 예측값 내 현재 표정에 대응되는 표정 예측 확률, 는 제2 표정 예측값 내 목표 표정에 대 응되는 표정 예측 확률을 의미한다. 예를 들어 도 3b와 같이 제2 표정 예측값이 산출되고, 현재 표정은 무표정, 목표 표정은 화난 표정인 경우, 제2 표정 스코어는 와 같이 산출될 수 있다. 이어서, 사용자 단말은 제1 표정 스코어 및 제2 표정 스코어를 기초로 종합 표정 스코어를 산출한다 (S110). 사용자 단말은 아래의 수학식 3을 이용하여 종합 표정 스코어를 산출할 수 있다. 수학식 3"}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 3에서 은 제1 표정 예측값, 은 제2 표정 예측값, 는 종합 표정 스코어 를 의미한다. 이상의 수학식으로 산출되는 종합 표정 스코어는 현재 표정과 목표 표정에 대한 예측 확률 간의 비율로 계산되 되, 목표 표정의 제1 영상 내 예측 확률과 제2 영상 내 현재 표정의 예측 확률을 함께 이용함으로써 두 표정 간의 변화 정도에 보다 포커싱된 스코어를 산출할 수 있다. 다음, 사용자 단말은 이상의 과정에서 산출된 종합 표정 스코어를 기초로 영상의 위변조 여부를 판단한다 (S111). 위변조의 판단은 예를 들어 사용자 단말은 종합 표정 스코어와 기 결정된 기준값의 비교를 통해 수행될 수 있다. 본 실시예에서 기준값은 영상의 위변조를 판단하는 기준이 되는 임계값으로써, 임계 영상의 품질, 사용자 의 개인 데이터, 해당 사용자의 과거 종합 표정 스코어 등에 따라 가변적으로 결정될 수 있으며 기준값 이하의 종합 표정 스코어가 산출된 경우 위변조되지 않은 것으로 판단할 수 있다. 이어서 도 6을 참고하여 본 실시예에서 사용자 단말이 표정의 가이드 후 표정의 분류 별 표정 변화를 고려 하여 위변조를 탐지하는 방법에 대해 설명한다. - 사용자 단말의 제2 위변조 탐지 방법 도 6을 참조하면, 사용자 단말은 상술한 수학식 1을 통해 산출된 제1 표정 예측값 내 현재 표정과 목표 표 정에 각각 대응되는 표정 예측 확률에 따른 제1 표정 스코어를 생성할 수 있다(S208). 또한, 사용자 단말은 제2 표정 예측값 내 목표 표정과 목표 표정 이외의 표정에 각각 대응되는 표정 예측 확률에 따른 제2 표정 스코어를 생성할 수 있다(S209). 구체적으로, 사용자 단말은 아래의 수학식 4를 이용하여 제2 표정 스코어를 생성할 수 있다. 수학식 4"}
{"patent_id": "10-2022-0102884", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 4에서 은 제2 표정 스코어, 는 제2 표정 예측값 내 현재 표정에 대응되는 표정 예측 확률, T는 표정의 총 개수, 는 목표 표정 이외의 표정에 각각 대응되는 표정 예측 확률의 합을 의미한다. 예를 들어 제2 영상에 따른 제2 표정 예측값이 아래 표 1과 같이 산출된 경우 제1 영상에서 현재 표정은 무 표정이며, 목표 표정은 화난 표정으로 결정된 경우, 제2 표정 스코어는 와 같이 산출될 수 있다. 표 1 무표정 0.2 웃는 표정 0.45 슬픈 표정 0.15 화난 표정 0.2이때, 각 표정 예측 확률의 합산 시 표정 간의 관계를 고려하여 설정된 가중치를 이용한 가중합으로 제2 표정 스코어를 산출하는 것도 가능하다. 이어서, 사용자 단말은 제1 표정 스코어와 제2 표정 스코어를 기초로 상술한 수학식 3을 통해 종합 표정 스코어를 산출(S210)하고, 종합 표정 스코어를 기초로 위변조 여부를 판단한다(S211). 한편, 사용자 단말은 영상의 품질, 사용자의 개인 데이터, 해당 사용자의 과거 종합 표정 스코어 등을 기 초로 제1 위변조 판단 방법 및 제2 위변조 판단 방법 중 하나를 선택하여 영상 내 위변조 여부를 탐지할 수 있 으며, 두가지 방법을 통해 생성된 종합 표정 스코어 각각을 합산하여 영상 내 위변조 여부를 탐지하는 것도 가 능하다. 이상 본 발명에 따르면, 사용자 단말은 위변조 탐지 모듈이 포함된 어플리케이션을 통해 자체적으로 표정 변화를 기반으로 영상 내 위변조를 탐지할 수 있다. <제2 실시예 - 서버와 연동을 통한 사용자 단말의 위변조 탐지> 나아가, 사용자 단말에서 영상의 위변조 여부를 단독으로 직접 판단하는 것 외에 보다 풍부한 자원으로 복 잡한 연산이 가능한 위변조 탐지 서버와 사용자 단말이 연동하여 위변조 여부를 탐지하는 것도 가능 하다. 이에 대해서는 도 7을 참조하여 설명한다. 도 7은 본 발명의 제2 실시예에 따라 영상 내 위변조 탐지 서비스를 수행하는 서버와 사용자 단말로 구성된 위 변조 탐지 시스템을 나타낸 예시도이다. 도 7을 참조하면, 본 실시예에 따른 위변조 탐지 시스템은 사용자 단말에서 구동되는 어플리케이션을 이용 하여 사용자의 안면 데이터가 포함된 영상을 입력 받고, 입력된 영상을 위변조 탐지 서버로 전송하는 과정으로 수행될 수 있다. 본 실시예에 따른 위변조 탐지 방법은 상술한 제1 실시예와 같이 순차적으로 입력되는 복수의 영상(11a, 11b)에 대한 표정의 판단을 통해 수행될 수 있으며, 영상의 입력 과정에서 의도적인 표정의 연출을 사용자에게 요구함 으로써 위변조를 탐지할 수 있도록 한다. 위변조 탐지 서버는 수신된 영상(11a) 내 사용자의 표정을 분석하고, 다른 표정을 유도하기 위한 표정 가이드 데이터를 생성하여 사용자 단말로 제공할 수 있다. 다음, 사용자 단말은 위변조 탐지 서버에서 생성된 표정 가이드 데이터를 사용자에게 제공함으로 써 새로운 표정을 짓는 사용자의 안면 데이터가 포함된 영상을 입력 받고 위변조 탐지 서버로 영상을 전송할 수 있다. 위변조 탐지 서버는 전송된 영상(11a, 11b)을 수신하고, 수신된 영상 내 사용자의 표정을 분석한다. 구체적으로 위변조 탐지 서버는 수신된 각 영상들(11a, 11b) 내 표정에 대한 예측값을 분석 결과로 학습된 신경망 모델을 이용하여 출력하고 이로부터 최종 판단된 위변조 판단값을 사용자 단말로 전송함으로써, 사용자 단말에서 영상의 위변조 여부를 판단하도록 한다. 나아가 위변조 탐지 서버는 사용자 단말에서 촬영된 복수의 영상을 실시간으로 수신할 수 있으며 위 변조 탐지 서버는 수신된 영상 내 표정의 변화를 동적으로 판단함으로써 목표 표정에 맞는 표정이 연출되 는 경우 본인 인증에 의한 서비스를 제공할 수 있다. 이하 도 8을 참조하여 본 실시예에 영상 내 위변조를 탐지하는 방법에 대하여 보다 상세히 설명한다. 도 8은 본 발명의 실시예에 따라 위변조 탐지 서버에서 수행되는 영상 내 위변조를 탐지하는 방법을 나타 낸 흐름도이다. 도 8을 참조하면, 위변조 탐지 서버는 사용자 단말로부터 사용자의 안면 데이터가 포함된 제1 영상 을 수신할 수 있다(S301). 위변조 탐지 서버는 상술한 신경망 모델을 이용하여 수신된 제1 영상 내 표정에 대한 제1 표정 예 측값을 산출할 수 있다(S302). 다음, 위변조 탐지 서버는 산출된 제1 표정 예측값을 사용자 단말로 전송할 수 있다(S303). 이어서 위변조 탐지 서버는 산출된 제1 표정 예측값을 기초로 제1 영상 내 현재 표정과 목표 표정을 판단한다(S304). 본 실시예에서 현재 표정은 제1 영상 내 예측 확률을 기초로 가장 높은 확률을 갖는 사용자의 표정이며, 목표 표정은 현재 표정을 기준으로 위변조를 판단하기 위해 사용자로부터 표정 변화를 유도할 목표가 되는 표정을 의미한다. 이어서, 위변조 탐지 서버는 사용자 단말로 판단된 목표 표정에 따라 현재 표정과 다른 표정을 사용 자가 연출하도록 표정 가이드 데이터를 생성하고, 생성된 표정 가이드 데이터를 전송한다(S305). 다음, 위변조 탐지 서버는 표정 가이드 데이터에 따른 안면 데이터가 포함된 제2 영상을 수신할 수 있 다(S306). 위변조 탐지 서버는 신경망 모델을 이용하여 수신된 제2 영상 내 표정에 대한 제2 표정 예측값을 산출 한다(S307). 구체적으로, 위변조 탐지 서버는 상술한 제1 영상의 표정 예측값을 출력하는 신경망 모델에 제2 영상을 입력함으로써 사용자의 변화된 표정에 대한 제2 표정 예측값을 산출할 수 있다. 다음, 위변조 탐지 서버는 산출된 제1 표정 예측값 및 제2 표정 예측값을 기초로 영상의 위변조 여부를 판 단하고(S308), 위변조 탐지 서버는 사용자 단말로 영상의 위변조 판단값을 전송한다(S309). 이하, 상술한 표정의 분류 별 예측 확률의 변화를 이용하여 위변조를 판단하는 방법에 대하여 보다 상세히 설명 한다. 먼저, 도 9를 참조하여 현재 표정과 목표 표정의 두 표정 간의 상대적인 관계에 따라 위변조를 탐지하는 방법에 대해 설명한다. - 위변조 탐지 서버의 제1 위변조 판단 방법 도 9는 본 발명의 일 실시예에 따른 영상 내 위변조를 탐지하는 방법을 나타낸 타이밍도이다. 도 9를 참조하면, 사용자 단말은 어플리케이션을 통해 사용자의 안면 데이터가 포함된 제1 영상을 입 력받고(S1010), 입력받은 제1 영상을 위변조 탐지 서버로 전송할 수 있다(S1020). 위변조 탐지 서버는 위변조 탐지를 위한 표정의 판단 전에 우선하여 사용자 단말로부터 입력되는 영 상이 위변조의 판단에 이용 가능한지를 판단할 수 있으며 이를 위해 수신된 영상의 상태를 판단할 수 있다 (S1030). 위변조 탐지 서버는 수신된 제1 영상이 표정 예측에 활용 가능한 경우, 신경망 모델을 이용하여 수신된 제1 영상 내 표정에 대한 제1 표정 예측값을 산출(S1040)하고, 산출된 제1 표정 예측값을 사용자 단 말로 전송할 수 있다(S1050). 다음, 위변조 탐지 서버는 제1 표정 예측값을 기초로 제1 영상 내 표정인 현재 표정 및 목표 표정을 판단한다(S1060). 위변조 탐지 서버는 제1 영상 내 표정이 다른 표정으로 변화되도록 목표 표정을 결정하되, 상술한 바 와 같이 제1 표정 예측값을 기초로 결정된 목표 표정을 표정 가이드 데이터로 생성할 수 있다(S1070). 이어서, 위변조 탐지 서버는 생성된 표정 가이드 데이터를 사용자 단말로 전송하고(S1080), 사용자 단말은 표정 가이드 데이터를 기초로 사용자로부터 연출된 표정을 촬영한 제2 영상을 입력 받을 수 있 다(S1090).다음, 사용자 단말은 제2 영상을 위변조 탐지 서버로 전송하고(S1100), 위변조 탐지 서버는 신경망 모델을 이용하여 수신된 제2 영상 내 표정에 대한 제2 표정 예측값을 산출할 수 있다(S1110). 그리고, 위변조 탐지 서버는 산출된 제1 표정 예측값 내 현재 표정과 목표 표정에 각각 대응되는 표정 예 측 확률을 기초로 제1 표정 스코어를 생성할 수 있다(S1120). 제1 표정 스코어 산출 단계(S1120)에서 위변조 탐지 서버는 상술한 수학식 1을 이용하여 제1 표정 스코어 를 산출할 수 있다. 다음, 위변조 탐지 서버는 제2 영상으로부터 산출된 제2 표정 예측값 내 현재 표정과 목표 표정에 각 각 대응되는 표정 예측 확률을 기초로 제2 표정 스코어를 산출할 수 있다(S1130). 제2 표정 스코어 산출 단계(S1120)에서 위변조 탐지 서버는 상술한 수학식 2를 이용하여 제2 표정 스코어 를 산출할 수 있다. 이어서, 위변조 탐지 서버는 제1 표정 스코어 및 제2 표정 스코어를 기초로 종합 표정 스코어를 산출할 수 있다(S1140). 구체적으로, 위변조 탐지 서버는 상술한 수학식 3을 이용하여 종합 표정 스코어를 생성할 수 있다. 이상의 수학식으로 산출되는 종합 표정 스코어는 현재 표정과 목표 표정에 대한 예측 확률 간의 비율로 계산되 되, 목표 표정의 제1 영상 내 예측 확률과 제2 영상 내 현재 표정의 예측 확률을 함께 이용함으로써 두 표정 간의 변화에 집중된 스코어를 산출할 수 있다. 위변조 탐지 서버는 이상의 과정에서 산출된 종합 표정 스코어를 기초로 영상의 위변조 여부를 판단한다 (S1150). 위변조 탐지 서버는 종합 표정 스코어와 기 결정된 기준값의 비교를 통해 영상의 위변조 여부를 판단할 수 있다. 본 실시예에서 기준값은 영상의 위변조를 판단하는 기준이 되는 임계값으로써, 임계 영상의 품질, 사용자 의 개인 데이터, 해당 사용자의 과거 종합 표정 스코어 등에 따라 가변적으로 결정될 수 있으며 기준값 이하의 종합 표정 스코어가 산출된 경우 위변조되지 않은 것으로 판단할 수 있다. 위변조 탐지 서버는 이상의 판단 결과로 위변조 판단 값을 사용자 단말로 전송하며(S1160), 위변조 판단 값은 위변조 여부에 대한 바이너리 값으로 결정될 수 있다. 또한, 위변조 탐지 서버는 표정의 가이드 후 각 항목 별 표정 변화를 고려하여 위변조를 탐지하는 것도 가 능하다. - 위변조 탐지 서버의 제2 위변조 판단 방법 도 10을 참조하면, 도 10에 따른 프로세스 중 S2010 내지 S2120는 상술한 도 9에서 대응되는 단계 S1010 내지 S1120단계와 동일한 방법으로 수행되므로 이하에서는 설명을 생략한다. 위변조 탐지 서버는 제2 표정 예측값 내 목표 표정과 목표 표정 이외의 표정에 각각 대응되는 표정 예측 확률을 기초로 제2 표정 스코어를 생성할 수 있다(S2130). 구체적으로, 위변조 탐지 서버는 상술한 수학식 4를 이용하여 제2 표정 스코어를 생성할 수 있다. 이어서, 위변조 탐지 서버는 제1 표정 스코어와 제2 표정 스코어를 기초로 상술한 수학식 3을 통해 종합 표정 스코어를 산출(S2140)하고, 종합 표정 스코어를 기초로 위변조 여부를 판단할 수 있다(S2150). 다음, 위변조 탐지 서버는 영상의 위변조 판단값을 사용자 단말로 전송할 수 있다. 이때, 위변조 탐지 서버는 상술한 제1 위변조 판단 방법 및 제2 위변조 판단 방법 중 어느 하나를 선택하 여 영상 내 위변조 여부를 탐지하는 것외에도 두가지 방법을 통해 생성된 종합 표정 스코어 각각을 합산하여 영 상 내 위변조 여부를 탐지하는 것도 가능하다.이상의 본 발명에 따르면, 위변조 탐지 서버는 사용자 단말로 수신된 영상 내 표정 변화를 기반으로 영상 내 위변조를 탐지할 수 있으며, 이에 따른 결과를 사용자 단말로 전송함으로써 위변조를 통한 부정 사용을 정지시키고 추가적인 피해를 방지할 수 있다. 이하 본 발명의 다른 실시예에 따른 위변조 탐지 방법을 수행하는 위변조 탐지 서버의 구체적인 하드웨어 구현에 대하여 설명한다. 도 11를 참조하면, 본 발명의 몇몇 실시예들에 위변조 탐지 서버는 컴퓨팅 장치의 형태로 구현될 수 있다. 위변조 탐지 서버를 구성하는 각각의 모듈 중 하나 이상은 범용 컴퓨팅 프로세서 상에서 구현되며 따라서 프로세서(processor), 입출력 I/O, 메모리 장치(memory), 인터페이스(interface) 및 버스 (214, bus)를 포함할 수 있다. 프로세서, 입출력 장치, 메모리 장치 및/또는 인터페이스는 버스를 통하여 서로 결합될 수 있다. 버스는 데이터들이 이동되는 통로(path)에 해당한다. 구체적으로, 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit), 마이크로프로세서, 디지털 신호 프로세스, 마이크로컨트롤 러, 어플리케이션 프로세서(AP, application processor) 및 이들과 유사한 기능을 수행할 수 있는 논리 소자들 중에서 적어도 하나를 포함할 수 있다. 입출력 장치는 키패드(keypad), 키보드, 터치스크린 및 디스플레이 장치 중 적어도 하나를 포함할 수 있다. 메모리 장치는 데이터 및/또는 프로그램 등을 저장할 수 있다. 인터페이스는 통신 네트워크로 데이터를 전송하거나 통신 네트워크로부터 데이터를 수신하는 기능을 수행 할 수 있다. 인터페이스는 유선 또는 무선 형태일 수 있다. 예컨대, 인터페이스는 안테나 또는 유무 선 트랜시버 등을 포함할 수 있다. 도시하지 않았지만, 메모리 장치는 프로세서의 동작을 향상시키기 위한 동작 메모리로서, 고속의 디램 및/또는 에스램 등을 더 포함할 수도 있다. 내부의 스토리지는 여기에 설명된 일부 또는 모든 모듈의 기능을 제공하는 프로그래밍 및 데이터 구성을 저장한다. 예를 들어, 상술한 위변조 탐지 방법의 선택된 양태들을 수행하도록 하는 로직을 포함할 수 있다. 나아가, 여기에 설명되는 다양한 실시예는 예를 들어, 소프트웨어, 하드웨어 또는 이들의 조합된 것을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 여기에 설명되는 실시예는 ASICs (application specific integrated circuits), DSPs (digital signal processors), DSPDs (digital signal processing devices), PLDs (programmable logic devices), FPGAs (field programmable gate arrays, 프로세서(processors), 제어기(controllers), 마이크로 컨 트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적인 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시예들이 제어 모듈 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시예들은 별도의 소프트웨어 모 듈들로 구현될 수 있다. 상기 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 적절한 프로그램 언어로 씌여진 소프트웨어 어플리케이션으로 소프트웨어 코드가 구현될 수 있 다. 상기 소프트웨어 코드는 메모리 모듈에 저장되고, 제어모듈에 의해 실행될 수 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위 내에서 다양한 수정, 변경 및 치환이 가능할 것이다. 따라서, 본 발명에 개시된 실시 예 및 첨부된 도면들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명 하기 위한 것이고, 이러한 실시 예 및 첨부된 도면에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니 다. 본 발명의 보호 범위는 아래의 청구 범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기 술 사상은 본 발명의 권리 범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3a 도면3b 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2022-0102884", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 영상 내 위변조를 탐지하는 시스템을 나타낸 예시도이다. 도 2는 본 발명의 일 실시예에 따른 영상 내 위변조를 탐지하는 방법을 나타낸 흐름도이다. 도 3a 및 3b는 본 발명의 일 실시예에 따른 신경망 모델을 나타낸 예시도이다. 도 4는 본 발명의 일 실시예에 따른 원형 도표 형태로 제공되는 사용자 인터페이스를 나타낸 예시도이다. 도 5 및 도 6은 본 발명의 일 실시예에 따른 영상 내 위변조를 탐지하는 방법을 나타낸 흐름도이다. 도 7은 본 발명의 다른 실시예에 따른 영상 내 위변조를 탐지하는 시스템을 나타낸 예시도이다. 도 8은 본 발명의 다른 실시예에 따른 영상 내 위변조를 탐지하는 방법을 나타낸 흐름도이다. 도 9 및 도 10은 본 발명의 다른 실시예에 따른 영상 내 위변조를 탐지하는 방법을 나타낸 타이밍도이다. 도 11은 본 발명의 다른 실시예들에 따른 영상 내 위변조를 탐지하는 방법을 수행하는 컴퓨팅 장치의 구현을 나 타낸 예시도이다."}
