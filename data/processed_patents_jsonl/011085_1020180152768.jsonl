{"patent_id": "10-2018-0152768", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0134967", "출원번호": "10-2018-0152768", "발명의 명칭": "정책망 및 가치망을 이용한 온라인 쇼핑몰에서의 프로모션 이미지 수정 장치", "출원인": "남기헌", "발명자": "남기헌"}}
{"patent_id": "10-2018-0152768", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 온라인 쇼핑몰에 대한 프로모션 속성 데이터 및 성과 데이터를 기초로 기학습된 프로모션 성과예측 인공신경망 모듈, 프로모션 속성을 추천하는 프로모션 추천 모듈 및 프로모션 이미지의 색감을 수정하는프로모션 이미지 수정 모듈의 프로그램 코드를 저장하는 메모리 모듈; 및상기 프로모션 성과 예측 인공신경망 모듈, 상기 프로모션 추천 모듈 및 상기 프로모션 이미지 수정 모듈의 프로그램 코드를 처리하여 특정 프로모션 속성을 추천하고 프로모션 이미지의 색감을 수정하는 처리 모듈;을 포함하고, 상기 프로모션 추천 모듈의 상기 프로그램 코드는,상기 프로모션 성과 예측 인공신경망 모듈에서 특정 프로모션 속성에 대해 예측된 프로모션 성과에 대한 정보인프로모션 성과 예측 데이터를 수신하는 프로모션 성과 예측 단계;에피소드 t에 대한 제1상태 정보(st)를 수신하는 상태 정보 수신 단계;상기 제1상태 정보 및 상기 프로모션 성과 예측 데이터를 기초로 가치망에서 보상 가능성 정보를 생성한 뒤, 상기 보상 가능성 정보를 기초로 정책망에서 복수개의 액션(action)인 추천 프로모션 속성 확률을 출력하는 속성확률 출력 단계;상기 복수개의 추천 프로모션 속성 확률을 기초로 최적 프로모션 탐색을 통해 상기 에피소드 t에 대한 추천 프로모션 속성 데이터(at)를 선정하여 출력하는 추천 프로모션 속성 데이터 출력 단계;상기 추천 프로모션 속성 데이터에 따른 프로모션이 적용된 뒤, 에피소드 t+1에 대한 제2상태 정보(st+1) 및 상기 추천 프로모션 속성 데이터(at)에 대한 보상 정보(rt+1)를 수신하는 상태 및 보상 정보 수신 단계; 및수신된 상기 제2상태 정보(st+1) 및 상기 보상 정보(rt+1)를 기초로 상기 정책망과 상기 가치망을 업데이트하는정책망 및 가치망 업데이트 단계; 를 포함하여 컴퓨터 상에서 수행되도록 구성되고,상기 프로모션 이미지 수정 모듈의 상기 프로그램 코드는,상기 프로모션 이미지를 수신하는 프로모션 이미지 수신 단계;VAE 또는 GAN을 포함하는 이미지 제너레이터에 의해 상기 프로모션 이미지의 색감을 수정하여 수정 프로모션 이미지를 생성하는 제너레이션 단계;상기 수정 프로모션 이미지를 인코딩하여 상기 추천 프로모션 속성 데이터 내의 추천 프로모션 이미지 색상 정보와의 에러를 계산하는 비교 단계; 및상기 에러를 기초로 상기 이미지 제너레이터를 업데이트하는 업데이트 단계;를 포함하여 컴퓨터 상에서 수행되도록 구성되며,상기 제1상태 정보 및 제2상태 정보는 성과 데이터(판매수량(Quantity), 매출액(Sales Amount), 유입량(PageView), 전환율(Conversion Rate), 평균판매단가(Average Sales Price) 또는 매출이익) 및 환경 데이터(날짜 정보, 요일 정보, 날씨 정보, 프로모션 진행 중인 제품 정보, 쇼핑몰 정보 또는 쇼핑몰의 다른 제품 정보)를 의미하며, 상기 추천 프로모션 속성 데이터는 추천 프로모션 이미지 색상 정보를 포함하고, 상기 보상 정보는 특정 기간 동안의 상기 성과 데이터의 상승 또는 하강을 의미하며, 공개특허 10-2019-0134967-3-상기 정책망은 각 상태에서 상기 추천 프로모션 속성 확률을 출력하는 인공신경망이고, 상기 정책망의 Costfunction은 아래 수학식 1과 같이 구성되며, 상기 가치망은 각 상태에서 보상(Reward)을 달성할 가능성인 상기 보상 가능성 정보를 생성하는인공신경망이고, 상기 가치망의 Cost function은 아래 수학식 2와 같이 구성되는 것을 특징으로 하는,정책망 및 가치망을 이용한 온라인 쇼핑몰에서의 프로모션 이미지 수정 장치:[수학식 1][수학식 2]상기 수학식 1에서, π는 정책 함수, θ는 정책망 파라미터, πθ(ai│si)는 현재 에피소드에서 특정 액션(특정속성의 프로모션)을 할 가능성, V는 가치 함수, w는 가치망 파라미터, si는 현재 에피소드인 i의 상태 정보,Si+1은 다음 에피소드인 i+1의 상태 정보, ri+1은 다음 에피소드에서 획득하는 것으로 예상되는 보상, Vw(si)는 현재 에피소드에서의 보상 가능성, Vw(si+1)는 다음 에피소드에서의 보상 가능성, γ는 감가율을 의미,상기 수학식 2에서, V는 가치 함수, w는 가치망 파라미터, si는 현재 에피소드인 i의 상태 정보, Si+1은 다음 에피소드인 i+1의 상태 정보, ri+1은 다음 에피소드에서 획득하는 것으로 예상되는 보상, Vw(si)는 현재 에피소드에서의 보상 가능성, Vw(si+1)는 다음 에피소드에서의 보상 가능성, γ는 감가율을 의미."}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 온라인 쇼핑몰에서의 프로모션 이미지 수정 장치에 관한 것이다. 본 발명의 일실시 예에 따르면, 인공지능의 학습에 의해 온라인 쇼핑몰의 프로모션 이미지의 색감이 정교하게 수정됨으로써 프로모 션의 효과가 상승하는 효과가 발생된다."}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 온라인 쇼핑몰에서의 프로모션 이미지 수정 장치에 관한 것이다."}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "온라인 쇼핑몰에서의 프로모션은 제품 할인, 경품 이벤트, 할인 쿠폰 지급, 마일리지 지급 등의 형태로 진행된 다. 이러한 프로모션은 온라인 쇼핑몰의 입장에서 항상 순익의 감소를 야기하기 때문에 프로모션의 종류, 프로 모션 기간, 프로모션의 정도 등이 해당 페르소나에 맞게 정밀하게 설계되어야 한다. 하지만 기존에는 프로모션 의 설계가 모두 온라인 쇼핑몰의 운영자나 프로모션 대행사 등에 의해 경험적으로 결정되는 실정이었다. 대한민국의 온라인 쇼핑은 오픈마켓/소셜커머스/종합쇼핑몰/대형마트쇼핑몰/카드포인트몰 등 다양한 형태의 회 사들이 존재하고 있고, 대부분의 판매자들은 위의 온라인 쇼핑몰에 복수로 입점하여 판매를 하고 있어서, 통일 된 데이터를 바탕으로 한 판매 성과를 분석하기 어려운 문제가 발생하고 있다. 프로모션의 구성요소는 프로모션의 일시 및 조건들과 관련된 내용으로 프로모션 결과치와 인과관계를 이루고 있 으나, 구성요건의 하나인 일시를 예를 들어도 계절, 월, 요일, 시간, 기간, 공휴일 등의 다양한 사항들이 포함 되어 있어서 결과치를 바탕으로 구성요소가 기여한 기여도 등을 사람이 계산하는 것은 매우 어려운 실정이다. 특히, 소비자에게 혜택으로 작용할 프로모션 감가율의 경우, 감가율이 커질수록 구매 혜택이 커지는 결과를 가 져오므로 매출 수량이 늘어나서 매출이 증가할 것이다. 하지만, 제품의 원가를 고려했을 때 매출수량 증가분과 감가율의 적정 지점에서 균형있게 적용하는 것이 중요하고, 이때 기대한 매출 이익을 달성할 수 있게 될 것 인 지에 대해 사람이 계산하는 것은 매우 어려운 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 신경망을 가지는 협업 필터링 시스템을 이용하여 클릭패턴에 기초한 웹 광고 추천 방법 및 그 시스템, 대한민국 등록특허 10-0792700, 네이버 주식회사"}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명의 목적은 기존에 경험적으로 설계되던 온라인 쇼핑몰의 프로모션의 낮은 정밀도를 해결하기 위 하여, 인공지능을 이용하여 프로모션의 성과를 예측하고 프로모션의 특성을 추천하는, 인공지능을 이용한 온라 인 쇼핑몰에서의 프로모션 성과 예측 및 추천 장치 및 방법을 제공하는 데에 있다."}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이하 본 발명의 목적을 달성하기 위한 구체적 수단에 대하여 설명한다. 본 발명의 목적은, 제품 속성 데이터, 프로모션 속성 데이터, 기타 성과 데이터 및 프로모션 를 기초로 기학습 된 인공신경망의 프로그램 코드를 저장하는 메모리 모듈; 및 상기 인공신경망의 프로그램 코드를 처리하여 특정 프로모션의 성과를 예측하는 처리 모듈; 을 포함하고, 상기 프로그램 코드는, 제품 속성 데이터, 프로모션 속성 데이터, 성과 데이터를 입력 받는 입력 단계; 상기 제품 속성 데이터, 상기 프로모션 속성 데이 터 및 상기 성과 데이터를 기초로 상기 특정 프로모션에 대한 성과를 예측하여 프로모션 성과 예측 데이터를 생 성하는 성과 예측 단계; 및 예측된 상기 프로모션 성과 예측 데이터를 출력하는 출력 단계;를 포함하여 컴퓨터 상에서 수행되도록 구성되는, 인공지능을 이용한 온라인 쇼핑몰에서의 프로모션 성과 예측 및 추천 장치를 제공 하여 달성될 수 있다. 또한, 프로모션 속성 데이터 및 성과 데이터를 기초로 기학습된 프로모션 성과 예측 인공신경망 모듈 및 프로모 션 추천 모듈의 프로그램 코드를 저장하는 메모리 모듈; 및 상기 프로모션 성과 예측 인공신경망 모듈 및 상기 프로모션 추천 모듈의 프로그램 코드를 처리하여 특정 프로모션의 성과를 예측하고 프로모션 속성을 추천하는 처리 모듈;을 포함하고, 상기 프로모션 추천 모듈의 상기 프로그램 코드는, 상기 프로모션 성과 예측 인공신경 망 모듈에서 특정 프로모션 속성에 대해 예측된 프로모션 성과에 대한 정보인 프로모션 성과 예측 데이터를 수 신하는 프로모션 성과 예측 단계; 에피소드 t에 대한 상태 정보(st)를 수신하는 상태 정보 수신 단계; 상기 상 태 정보 및 상기 프로모션 성과 예측 데이터를 기초로 가치망에서 보상 가능성 정보를 생성한 뒤, 상기 보상 가 능성 정보를 기초로 정책망에서 복수개의 액션(action)인 추천 프로모션 속성 확률을 출력하는 속성 확률 출력 단계; 상기 복수개의 추천 프로모션 속성 확률을 기초로 최적 프로모션 탐색을 통해 에피소드 t에 대한 추천 프 로모션 속성 데이터(at)를 선정하여 출력하는 추천 프로모션 속성 데이터 출력 단계; 상기 추천 프로모션 속성 데이터에 따른 프로모션이 적용된 뒤, 에피소드 t+1에 대한 상태 정보(st+1) 및 at에 대한 보상 정보(rt+1)를 수 신하는 상태 및 보상 정보 수신 단계; 및 수신된 상기 상태 정보(st+1) 및 상기 보상 정보(rt+1)를 기초로 상기 정책망과 상기 가치망을 업데이트하는 정책망 및 가치망 업데이트 단계; 를 포함하여 컴퓨터 상에서 수행되도록 구성되고, 상기 상태 정보는 성과 데이터(판매수량(Quantity), 매출액(Sales Amount), 유입량(Page View), 전 환율(Conversion Rate), 평균판매단가(Average Sales Price) 또는 매출이익) 및 환경 데이터(날짜 정보, 요일 정보, 날씨 정보, 프로모션 진행 중인 제품 정보, 쇼핑몰 정보 또는 쇼핑몰의 다른 제품 정보)를 의미하며, 상 기 추천 프로모션 속성 데이터는 프로모션 카테고리, 프로모션 기간, 프로모션 쇼핑몰, 노출구좌 또는 프로모션 이미지 색상을 의미하고, 상기 보상 정보는 특정 기간 동안의 상기 성과 데이터의 상승 또는 하강을 의미하는 것을 특징으로 하는, 인공지능을 이용한 온라인 쇼핑몰에서의 프로모션 성과 예측 및 추천 장치를 제공하여 달 성될 수 있다. 본 발명의 다른 목적은, 프로모션 추천 모듈이 프로모션 성과 예측 인공신경망 모듈에서 특정 프로모션 속성에 대해 예측된 프로모션 성과에 대한 정보인 프로모션 성과 예측 데이터를 수신하는 프로모션 성과 예측 단계; 상 기 프로모션 추천 모듈이 에피소드 t에 대한 상태 정보(st)를 수신하는 상태 정보 수신 단계; 상기 프로모션 추 천 모듈이 상기 상태 정보 및 상기 프로모션 성과 예측 데이터를 기초로 가치망에서 보상 가능성 정보를 생성한 뒤, 상기 보상 가능성 정보를 기초로 정책망에서 복수개의 액션(action)인 추천 프로모션 속성 확률을 출력하는 속성 확률 출력 단계; 상기 프로모션 추천 모듈이 상기 복수개의 추천 프로모션 속성 확률을 기초로 최적 프로 모션 탐색을 통해 에피소드 t에 대한 추천 프로모션 속성 데이터(at)를 선정하여 출력하는 추천 프로모션 속성 데이터 출력 단계; 상기 추천 프로모션 속성 데이터에 따른 프로모션이 적용된 뒤, 상기 프로모션 추천 모듈이 에피소드 t+1에 대한 상태 정보(st+1) 및 at에 대한 보상 정보(rt+1)를 수신하는 상태 및 보상 정보 수신 단계; 및 상기 프로모션 추천 모듈이 수신된 상기 상태 정보(st+1) 및 상기 보상 정보(rt+1)를 기초로 상기 정책망과 상 기 가치망을 업데이트하는 정책망 및 가치망 업데이트 단계; 를 포함하여 컴퓨터 상에서 수행되도록 구성되고, 상기 상태 정보는 성과 데이터(판매수량(Quantity), 매출액(Sales Amount), 유입량(Page View), 전환율 (Conversion Rate), 평균판매단가(Average Sales Price) 또는 매출이익) 및 환경 데이터(날짜 정보, 요일 정보, 날씨 정보, 프로모션 진행 중인 제품 정보, 쇼핑몰 정보 또는 쇼핑몰의 다른 제품 정보)를 의미하며, 상 기 추천 프로모션 속성 데이터는 프로모션 카테고리, 프로모션 기간, 프로모션 쇼핑몰, 노출구좌 또는 프로모션 이미지 색상을 의미하고, 상기 보상 정보는 특정 기간 동안의 상기 성과 데이터의 상승 또는 하강을 의미하는 것을 특징으로 하는, 인공지능을 이용한 온라인 쇼핑몰에서의 프로모션 성과 예측 및 추천 방법을 제공하여 달 성될 수 있다. 본 발명의 다른 목적은, 적어도 하나의 온라인 쇼핑몰에 대한 프로모션 속성 데이터 및 성과 데이터를 기초로 프로모션 속성을 추천하는 프로모션 추천 모듈 및 프로모션 이미지의 색감을 수정하는 프로모션 이미지 수정 모 듈의 프로그램 코드를 저장하는 메모리 모듈; 및 상기 프로모션 추천 모듈 및 상기 프로모션 이미지 수정 모듈 의 프로그램 코드를 처리하여 특정 프로모션 속성을 추천하고 프로모션 이미지의 색감을 수정하는 처리 모듈; 을 포함하고, 상기 프로모션 추천 모듈의 상기 프로그램 코드는, 에피소드 t에 대한 제1상태 정보(st)를 수신하 는 상태 정보 수신 단계; 상기 제1상태 정보를 기초로 보상 가능성 정보를 생성한 뒤, 상기 보상 가능성 정보를 기초로 상기 에피소드 t에 대한 추천 프로모션 속성 데이터(at)를 선정하여 출력하는 추천 프로모션 속성 데이터 출력 단계; 상기 추천 프로모션 속성 데이터에 따른 프로모션이 적용된 뒤, 에피소드 t+1에 대한 제2상태 정보 (st+1) 및 상기 추천 프로모션 속성 데이터(at)에 대한 보상 정보(rt+1)를 수신하는 상태 및 보상 정보 수신 단계; 및 수신된 상기 제2상태 정보(st+1) 및 상기 보상 정보(rt+1)를 기초로 상기 추천 프로모션 속성 데이터 출력 단 계의 가중치를 업데이트하는 가중치 업데이트 단계; 를 포함하여 컴퓨터 상에서 수행되도록 구성되고, 상기 프 로모션 이미지 수정 모듈의 상기 프로그램 코드는, 상기 프로모션 이미지를 수신하는 프로모션 이미지 수신 단 계; VAE 또는 GAN을 포함하는 이미지 제너레이터에 의해 상기 프로모션 이미지의 색감을 수정하여 수정 프로모 션 이미지를 생성하는 제너레이션 단계; 상기 수정 프로모션 이미지를 인코딩하여 상기 추천 프로모션 속성 데 이터 내의 추천 프로모션 이미지 색상 정보와의 에러를 계산하는 비교 단계; 및 상기 에러를 기초로 상기 이미 지 제너레이터를 업데이트하는 업데이트 단계; 를 포함하여 컴퓨터 상에서 수행되도록 구성되며, 상기 제1상태 정보 및 제2상태 정보는 성과 데이터(판매수량(Quantity), 매출액(Sales Amount), 유입량(Page View), 전환율 (Conversion Rate), 평균판매단가(Average Sales Price) 또는 매출이익) 및 환경 데이터(날짜 정보, 요일 정보, 날씨 정보, 프로모션 진행 중인 제품 정보, 쇼핑몰 정보 또는 쇼핑몰의 다른 제품 정보)를 의미하며, 상 기 추천 프로모션 속성 데이터는 추천 프로모션 이미지 색상 정보를 포함하고, 상기 보상 정보는 특정 기간 동 안의 상기 성과 데이터의 상승 또는 하강을 의미하는 것을 특징으로 하는, 인공지능을 이용한 온라인 쇼핑몰에 서의 프로모션 이미지 수정 장치를 제공하여 달성될 수 있다. 본 발명의 다른 목적은, 적어도 하나의 온라인 쇼핑몰에 대한 프로모션 속성 데이터 및 성과 데이터를 기초로 프로모션 속성을 추천하는 프로모션 추천 모듈이, 에피소드 t에 대한 제1상태 정보(st)를 수신하는 상태 정보 수 신 단계; 상기 프로모션 추천 모듈이, 상기 제1상태 정보를 기초로 보상 가능성 정보를 생성한 뒤, 상기 보상 가능성 정보를 기초로 상기 에피소드 t에 대한 추천 프로모션 속성 데이터(at)를 선정하여 출력하는 추천 프로모션 속성 데이터 출력 단계; 상기 프로모션 추천 모듈이, 상기 추천 프로모션 속성 데이터에 따른 프로모션이 적 용된 뒤, 에피소드 t+1에 대한 제2상태 정보(st+1) 및 상기 추천 프로모션 속성 데이터(at)에 대한 보상 정보 (rt+1)를 수신하는 상태 및 보상 정보 수신 단계; 및 상기 프로모션 추천 모듈이, 수신된 상기 제2상태 정보 (st+1) 및 상기 보상 정보(rt+1)를 기초로 상기 추천 프로모션 속성 데이터 출력 단계의 가중치를 업데이트하는 가중치 업데이트 단계; 를 포함하고, 프로모션 이미지의 색감을 수정하는 프로모션 이미지 수정 모듈이, 상기 프로모션 이미지를 수신하는 프로모션 이미지 수신 단계; VAE 또는 GAN을 포함하는 이미지 제너레이터에 의해 상기 프로모션 이미지의 색감을 수정하여 수정 프로모션 이미지를 생성하는 제너레이션 단계; 상기 수정 프로모 션 이미지를 인코딩하여 상기 추천 프로모션 속성 데이터 내의 추천 프로모션 이미지 색상 정보와의 에러를 계 산하는 비교 단계; 및 상기 에러를 기초로 상기 이미지 제너레이터를 업데이트하는 업데이트 단계; 를 포함하며, 상기 제1상태 정보 및 제2상태 정보는 성과 데이터(판매수량(Quantity), 매출액(Sales Amount), 유입 량(Page View), 전환율(Conversion Rate), 평균판매단가(Average Sales Price) 또는 매출이익) 및 환경 데이터 (날짜 정보, 요일 정보, 날씨 정보, 프로모션 진행 중인 제품 정보, 쇼핑몰 정보 또는 쇼핑몰의 다른 제품 정보)를 의미하며, 상기 추천 프로모션 속성 데이터는 추천 프로모션 이미지 색상 정보를 포함하고, 상기 보상 정보는 특정 기간 동안의 상기 성과 데이터의 상승 또는 하강을 의미하는 것을 특징으로 하는, 인공지능을 이용 한 온라인 쇼핑몰에서의 프로모션 이미지 수정 방법을 제공하여 달성될 수 있다."}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같이, 본 발명에 의하면 이하와 같은 효과가 있다. 첫째, 본 발명의 일실시예에 따르면, 인공지능의 학습에 의해 온라인 쇼핑몰의 프로모션이 정교해지고 정밀해짐 으로써 프로모션의 효과가 상승하는 효과가 발생된다. 둘째, 본 발명의 일실시예에 따르면, 가치망에 따라 추천 프로모션 속성의 확률을 출력하는 정책망의 업데 이트가 매 에피소드마다 진행될 수 있는 효과가 발생된다. 기존의 강화학습에서는 강화학습 모델의 업데이트가 모든 에피소드가 종료된 이후에 진행되는 문제가 있어서, 프로모션 추천 모델에 적용하는데는 어려움이 있었다. 셋째, 본 발명의 일실시예에 따르면, 프로모션의 추천은 단기 및 장기 목표들이 존재하므로 MDP의 가정이 성립 하지 않아서 기존의 DQN 적용에 어려움이 있음에도 불구하고, 정책망 및 가치망의 의존적 관계에 의해 프로모션 추천에도 강화학습을 진행할 수 있게 되는 효과가 발생된다. 넷째, 본 발명의 일실시예에 따르면, 정책망 및 가치망이 프로모션 성과 예측 인공신경망 장치와 연결되어 프로 모션 성과 예측 데이터를 기초로 학습되기 때문에 학습 속도가 향상되는 효과가 발생된다."}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작원리를 상세하게 설명함에 있 어서 관련된 공지기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 특정 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 특정 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 인공지능을 이용한 온라인 쇼핑몰에서의 프로모션 성과 예측 및 추천 장치 및 방법 도 1은 본 발명의 일실시예에 따른 인공지능을 이용한 온라인 쇼핑몰에서의 프로모션 성과 예측 및 추천 장치 를 도시한 것이다. 도 1에 도시된 바와 같이, 본 발명의 일실시예에 따른 인공지능을 이용한 온라인 쇼핑몰 에서의 프로모션 성과 예측 및 추천 장치는 제품 속성 데이터, 프로모션 속성 데이터, 성과 데이터 및 프로모션 을 기초로 기학습된 프로모션 성과 예측 인공신경망 장치 및 프로모션 추천 장치를 포함할 수 있다. 프로모션 성과 예측 인공신경망 장치 관련, 도 2는 본 발명의 일실시예에 따른 프로모션 성과 예측 인공신 경망 장치의 학습 과정을 도시한 모식도, 도 3은 본 발명의 일실시예에 따른 프로모션 성과 예측 인공신경망 장 치의 추론 과정을 도시한 모식도이다. 도 2, 3에 도시된 바와 같이, 인공지능을 이용한 온라인 쇼핑몰에서의 프 로모션 성과 예측 방법은 제품 속성 데이터, 프로모션 속성 데이터, 성과 데이터를 수신하여 프 로모션 성과 예측 인공신경망 장치를 학습시키고, 기학습된 프로모션 성과 예측 인공신경망 장치에 제 품 속성 데이터 및 프로모션 속성 데이터를 입력하여 예측되는 프로모션 성과 예측 데이터을 출 력할 수 있다. 특히, 프로모션 성과 예측 인공신경망 장치의 학습시에는 프로모션 성과 데이터와 출력 데이 터와의 에러(error)를 기초로 hidden layer의 weight를 업데이트하는 방법으로 진행될 수 있다. 도 2에서 제품 속성 데이터 및 프로모션 속성 데이터를 구성하는 각 속성은 x1, x2, x3와 같은 input layer의 각 노 드에 입력되고, w1과 같은 weight을 기반으로 h1, h2, h3와 같은 hidden layer를 지나 softmax 등의 cost function 기반으로 예측된 프로모션 성과 예측 데이터가 y1인 output layer로 출력되게 된다. 예측된 성과 데이터와 실제 성과 데이터와의 에러(error, -Sigma(yi log pi))를 기반으로 프로모션 성과 예측 인공신경 망 장치의 weight가 back propagation으로 업데이트 될 수 있다. 또는, 각각의 제품에 대해 별도의 프로모션 성과 예측 인공신경망 장치를 구성하고, 프로모션 속성 데이터 , 성과 데이터를 수신하여 프로모션 성과 예측 인공신경망 장치를 학습시키고, 기학습된 프로모 션 성과 예측 인공신경망 장치에 프로모션 속성 데이터를 입력하여 예측되는 프로모션 성과 예측 데이터 을 출력할 수 있다. 이 때 이용될 수 있는 인공신경망 이외에도 다층 퍼셉트론(Multi-layer perceptron), 나이브 베이지안 분류(Naive-Bayesian Classification), 랜덤 포레스트 분류(Random Forest Classification) 등의 기계학습이 이용될 수 있다. 제품 속성 데이터는 제품 카테고리, 제품 판매가격, 제품원가 등을 포함할 수 있다. 프로모션 속성 데이터는 프로모션 카테고리(할인 프로모션, 사은품 프로모션 등), 프로모션 기간, 프로모 션 쇼핑몰, 노출구좌, 프로모션 이미지 등을 포함할 수 있다. 본 발명의 일실시예에 따른 프로모션 속성 데이터 중 프로모션 이미지 데이터는 기학습된 CNN(Convolutional Neural Network)을 통해 특정 분위기 카테고리, 특정 색감 카테고리로 분류된 결과값을 의미할 수 있다. 성과 데이터는 판매수량(Quantity), 매출액(Sales Amount), 유입량(Page View), 전환율(Conversion Rate), 평균판매단가(Average Sales Price), 매출이익 등을 포함할 수 있다. 본 발명의 일실시예에 따르면, 성 과 데이터의 다중공선성(Multicollinearity)에 따른 문제를 방지하기 위하여 성과 데이터를 구성하는각각의 데이터에 대해 PCA를 적용하여 diagnol matrix의 형태로 공선성을 상쇄해줄 수 있다. 프로모션 속성 추천과 관련하여, 상기 프로모션 성과 예측 인공신경망 장치를 이용하여 가장 높은 프로모션 성 과 예측 데이터가 출력되도록 하는 추천 프로모션 속성 데이터를 출력하는 프로모션 추천 장치가 구성 될 수 있다. 본 발명의 일실시예에 따른 프로모션 추천 장치의 프로모션 추천은 강화학습을 이용하여 수행될 수 있다. 도 4는 본 발명의 일실시예에 따른 프로모션 추천 장치를 도시한 모식도이다. 도 4에 도시된 바와 같이, 본 발명의 일실시예에 따른 프로모션 추천 장치는 특정 상태에서의 가치를 출력하는 가치 함수를 학습하는 인 공신경망인 가치망 및 추천 프로모션 속성의 확률을 출력하는 정책 함수를 학습하는 정책망을 포함할 수 있고, 본 발명의 일실시예에 따른 정책망 및 가치망은 프로모션 성과 예측 인공신경망 장치에 연결되도록 구성될 수 있다. 또한, 정책망과 가치망은 최적 프로모션 탐색 모듈과 연결되어 추천 프로모션 속성 데이터를 출력할 수 있다. 강화학습의 관점에서, 본 발명의 일실시예에 따른 프로모션 추천 장치의 Objective는 프로모션의 성과를 향 상시키는 것이고, 상태(State)는 현재 성과 데이터(판매수량(Quantity), 매출액(Sales Amount), 유입량(Page View), 전환율(Conversion Rate), 평균판매단가(Average Sales Price), 매출이익 등) 및 환경 데이터(날짜, 요 일, 날씨, 현재 프로모션 진행 중인 제품, 쇼핑몰, 쇼핑몰의 다른 제품 정보)를 의미할 수 있고, 액션(Action) 은 프로모션 속성 데이터(프로모션 카테고리(할인 프로모션, 사은품 프로모션 등), 프로모션 기간, 프로모션 쇼 핑몰, 노출구좌, 프로모션 이미지 색상 등)을 의미할 수 있으며, 보상(Reward)은 특정 기간 동안의 성과 데이터 의 상승 또는 하강을 의미할 수 있다. 정책망은 프로모션 추천 장치의 각 상태에서 추천 프로모션의 특정 속성들의 확률을 결정하는 인공신 경망이고, 정책 함수를 학습하여 추천 프로모션 속성 확률을 출력하게 된다. 정책망의 Cost function은 정책함 수와 가치망의 Cost Function을 곱하여 크로스 엔트로피(Cross Entropy)를 계산한 뒤 Policy gradient를 취한 함수일 수 있고, 예를 들면, 아래 수학식 1과 같이 구성될 수 있다. 정책망은 크로스 엔트로피와 가치망의 cost function인 시간차 에러의 곱을 기초로 back propagation 될 수 있다. 수학식 1"}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서, π는 정책 함수, θ는 정책망 파라미터, πθ(ai│si)는 현재 에피소드에서 특정 액션(특정 속성의 프로모션)을 할 가능성, V는 가치 함수, w는 가치망 파라미터, si는 현재 에피소드인 i의 상태 정보, Si+1은 다 음 에피소드인 i+1의 상태 정보, ri+1은 다음 에피소드에서 획득하는 것으로 예상되는 보상, Vw(si)는 현재 에피 소드에서의 보상 가능성, Vw(si+1)는 다음 에피소드에서의 보상 가능성, γ는 감가율을 의미할 수 있다. 이때, ri+1은 프로모션 성과 예측 인공신경망 장치에서 수신하도록 구성될 수 있다. 결국, 본 발명의 일실시예에 따른 정책망은 Policy gradient를 통해 초기에는 사용자의 프로모션 히스토리를 모사하는 프로모션 속성을 출력하게 된다. 본 발명의 일실시예에 따른 정책망은 강화학습이 진행되기 이전에 기존의 프로모션 속성 데이터와 이에 따 른 성과 데이터를 기초로 지도학습(Supervised Learning)되어 정책망의 weight가 업데이트 됨으로써 정책의 기 초를 학습할 수 있다. 즉, 정책망의 weight는 기존의 프로모션 속성 데이터 및 성과 데이터를 토대로 지도학습 되어 설정될 수 있다. 이에 따르면, 기존의 프로모션의 기록에 의해 정책망이 매우 빠르게 학습될 수 있는 효과 가 발생된다. 또한, 본 발명의 일실시예에 따르면 정책망의 지도학습 시에 랜덤 벡터를 포함하여 기존의 프로모션 속성 데이터와 이에 따른 성과 데이터를 기초로 지도학습이 되도록 구성될 수 있다. 랜덤 벡터는 예를 들면 가우시안확률 분포(Gaussian distribution)를 이용할 수 있다. 이에 따르면, 정책망이 랜덤한 확률로 도전적인 프로모션 정책을 출력할 수 있게 되는 효과가 발생된다. 정책망의 지도학습 시에 기존의 프로모션 속성 데이터와 이 에 따른 성과 데이터를 기초로 지도학습이 되도록 구성하면 프로모션의 추천이 기존의 정책 내에서 최적화되는 결과가 나타나게 된다. 하지만, 본 발명의 일실시예에 따라 정책망의 지도학습 시에 랜덤 벡터를 포함하게 되면 강화학습이 진행될수록 정책망이 기존의 정책보다 더 효과적인 프로모션을 학습할 수 있게 되는 효과가 발생된 다. 가치망은 프로모션 추천 장치가 가질 수 있는 각 상태(State)에서 보상(Reward)을 달성할 가능성을 도 출하는 인공신경망이고, 가치 함수를 학습하게 된다. 가치망은 에이전트(agent)인 프로모션 추천 장치(1 1)가 어떤 방향으로 업데이트 될 지에 대한 방향성을 제시해주게 된다. 이를 위해, 가치망의 입력 변수는 프로모션 추천 장치의 상태에 대한 정보인 상태 정보로 설정되고, 가치망의 출력 변수는 프로모션 추 천 장치가 보상을 달성할 가능성인 보상 가능성 정보로 설정될 수 있다. 본 발명의 일실시예에 따른 보상 가능성 정보는 아래 수학식과 같은 Q-function으로 계산될 수 있다. 수학식 2"}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "위 수학식 2에서 Qπ는 특정 정책 π에서 상태 s, 액션 a인 경우 미래에 예상되는 전체 보상 가능성 정보를 의미 하고, R은 특정 기간의 보상, gamma는 감가율을 의미할 수 있다. St는 시간 t의 상태, At는 시간 t의 액션, E는 기대값을 의미할 수 있다. 본 발명의 일실시예에 따른 보상 가능성 정보(Q value)는 정책망의 업데이트 방 향 및 크기를 규정하게 된다. 이때, 가치망의 Cost function은 가치 함수에 대한 MSE(Mean Square error) 함수일 수 있고, 예를 들면 아래 수학식 3과 같이 구성될 수 있다. 가치망은 가치망의 cost function인 시간차 에러를 기초로 back propagation 될 수 있다. 수학식 3"}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 2에서, V는 가치 함수, w는 가치망 파라미터, si는 현재 에피소드인 i의 상태 정보, Si+1은 다음 에피소 드인 i+1의 상태 정보, ri+1은 다음 에피소드에서 획득하는 것으로 예상되는 보상, Vw(si)는 현재 에피소드에서의 보상 가능성, Vw(si+1)는 다음 에피소드에서의 보상 가능성, γ는 감가율을 의미할 수 있다. 이때, ri+1은 프로모 션 성과 예측 인공신경망 장치에서 수신하도록 구성될 수 있다. 이에 따라, 가치망은 프로모션 추천 장치의 상태가 변경될 때 수학식 1의 Cost Function을 Gradient descent 시 키는 방향으로 업데이트 할 수 있다. 본 발명의 일실시예에 따르면 가치망을 정책망과 별도로 학습시키면서, 가치망의 Q value가 랜덤에서 시작하지 않고 Supervised되게 되므로 빠른 학습이 가능해지는 효과가 발생된다. 이에 따르면 매우 복잡도가 높은 프로모 션 속성의 조합을 선택하는 액션(action)에 있어서 탐구(exploration) 부담을 크게 줄일 수 있게 되는 효과가 발생된다. 본 발명의 일실시예에 따른 프로모션 추천 장치에 따르면, 지도학습을 마친 정책망이 현재 에피소드 i 의 프로모션 속성을 추천하게 되면 가치망이 추천된 프로모션 속성을 진행할 경우의 보상을 예측하도록 학 습된다. 학습을 마친 프로모션 추천 장치의 정책망과 가치망은 최적 프로모션 탐색 모듈을활용한 시뮬레이션과 조합되어 최종적으로 프로모션 속성을 선정하는데 활용된다. 또한, 본 발명의 일실시예에 따른 가치망에 따르면 추천 프로모션 속성의 확률을 출력하는 정책망의 업데 이트가 매 에피소드마다 진행될 수 있는 효과가 발생된다. 기존의 강화학습에서는 강화학습 모델의 업데이트가 모든 에피소드가 종료된 이후에 진행되는 문제가 있어서, 프로모션 추천 모델에 적용하는데는 어려움이 있었다. 최적 프로모션 탐색 모듈은 정책망과 가치망에서 계산되는 복수의 에이전트(agent)를 기초로 다양한 상태 및 다양한 액션에 대한 복수회의 시뮬레이션을 진행하여 최적의 프로모션 속성을 탐색하는 구성이다. 본 발명의 일실시예에 따른 최적 프로모션 탐색 모듈은, 예를 들어, 몬테카를로 트리 탐색을 활용할 수 있고, 트리의 각 노드는 상태(state)를, 각 연결(edge)은 해당 상태에 대한 특정 액션에 따라 예상되는 가치(value)를 나타내며, 현재 상태를 뿌리 노드로 두고 새로운 액션을 취해 새로운 상태로 전이될 때 마다 잎(leaf) 노드가 확장되는 구 조이다. 본 발명의 일실시예에 따른 최적 프로모션 탐색 모듈에서 최적 프로모션 탐색은 몬테카를로 트리 탐색 이 활용되는 경우, Selection, Expansion, Evaluation, Backup의 4 단계로 처리될 수 있다. 최적 프로모션 탐색 모듈의 Selection 단계는, 현재 상태로부터 잎 노드가 나올 때까지 선택 가능한 액션 중 가장 가치가 높은 액션을 선택하며 진행하는 단계이다. 이 때 연결(edge)에 저장해 둔 가치함수의 값과 탐구 -이용 균형을 맞추기 위한 방문빈도 값을 이용한다. Selection 단계에서 액션 선택을 위한 수학식은 아래와 같 다. 수학식 4"}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "위 수학식 4에서 at는 시간t에서의 액션(프로모션 수행)이고, Q(st,a)는 트리에 저장된 가치함수의 값이며, u(st,a)는 해당 상태-액션 쌍의 방문횟수에 반비례하는 값으로 탐구(exploration)와 이용의 균형을 맞추기 위해 사용된 것이다. 최적 프로모션 탐색 모듈의 Expansion 단계는, 시뮬레이션이 잎 노드까지 진행되면 지도학습으로 학습된 정책망의 확률에 따라 액션하여 새로운 노드를 잎 노드로 추가하는 단계이다. 최적 프로모션 탐색 모듈의 Evaluation 단계는, 새로 추가된 잎 노드로부터 가치망을 사용해 판단한 가치 (보상 가능성)와 잎 노드로부터 정책망을 사용해 프로모션 에피소드가 끝날 때까지 진행해 얻은 보상을 통해 잎 노드의 가치를 평가하는 단계이다. 아래 수학식은 새로운 잎 노드의 가치를 평가하는 예시이다. 수학식 5"}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "위 수학식 5에서 V(sL)은 잎 노드의 가치, λ는 mixing 파라미터, vθ(sL)은 가치망을 통해 얻은 가치, zL은 시뮬 레이션을 계속하여 얻은 보상을 의미할 수 있다. 최적 프로모션 탐색 모듈의 Backup 단계는, 새로 추가된 잎 노드의 가치를 반영하여 시뮬레이션 중 방문한 노드들의 가치를 재평가하고 방문 빈도를 업데이트하는 단계이다. 아래 수학식은 노드 가치 재평가 및 방문 빈 도 업데이트의 예시이다. 수학식 6"}
{"patent_id": "10-2018-0152768", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "위 수학식 6에서 sLi는 i번째 시뮬레이션에서의 잎 노드를, 1(s,a,i)는 i번째 시뮬레이션에서 연결 (s,a)를 방문 했는지를 나타내고, 트리 탐색이 완료되면 알고리즘은 뿌리 노드로부터 가장 많이 방문된 연결(s,a)을 선택하도 록 구성될 수 있다. 본 발명의 일실시예에 따른 최적 프로모션 탐색 모듈에 따르면 정책망에 의해 선별되 는 복수의 프로모션 속성에 대해 가치망을 기초로 복수회 시뮬레이션을 선행하여 최적의 프로모션 속성을 선택 할 수 있게되는 효과가 발생된다. 본 발명의 일실시예에 따르면, 복수의 에이전트(Agent)가 구성되도록 프로모션 추천 장치가 구성될 수 있다. 복수의 에이전트가 구성되면 특정 상태, 특정 프로모션 속성 각각에 대해 프로모션 추천 장치가 추천하는 프로모션이 상호 경쟁하여, 일정한 예산 내에서 가장 최적의 제품 및 그에 대한 프로모션을 추천할 수 있게 되 는 효과가 발생된다. 도 5는 본 발명의 일실시예에 따른 프로모션 추천 장치의 동작예를 도시한 흐름도이다. 도 5에 도시된 바와 같이, 복수의 인터넷 쇼핑몰에서 상태 데이터를 트래킹하는 인터넷 쇼핑몰 데이터 허브 장치에 의해 상태 s(t)가 입력되면 가치망에 의해 정책망의 복수개의 에이전트(agent)들에 의해 다양한 프로모션 속성 들이 최적 프로모션 탐색 모듈에 입력되고, 최적 프로모션 탐색 모듈에 의해 출력되는 액션(action) 인 추천 프로모션 속성 확률 a(t)에 의해 프로모션이 진행되는 것으로 에피소드 t가 종료되고 에피소드 t+1이 시작된다. 에피소드 t+1에서는 다시 a(t)에 의한 상태 변화인 s(t+1)이 인터넷 쇼핑몰 데이터 허브 장치에 의해 입력되고, a(t)에 따른 보상인 r(t+1)이 곧바로 입력되어 가치망 및 정책망을 업데이트하게 된 다. 또한, 본 발명의 일실시예에 따르면, 추천 프로모션 속성 데이터에 포함되는 데이터 중 프로모션 이미지 색상 정보의 경우, 본 발명의 일실시예에 따르면 실제 프로모션 이미지를 인공지능을 이용한 온라인 쇼핑몰에서 의 프로모션 성과 예측 및 추천 장치가 수신하여 프로모션 이미지 색상 정보을 기초로 프로모션 이미지의 색 감을 수정하여 수정된 프로모션 이미지를 출력할 수 있다. 도 6은 본 발명의 일실시예에 따른 프로모션 이미지 수정 장치를 도시한 모식도이다. 도 6에 도시된 바와 같이, 프로모션 이미지 수정 장치는 제너레이터와 ConvNet 인코더를 포함하도록 구성될 수 있다. 제너레이터는 VAE, GAN 등의 인코더 및 디코더로 구성된 이미지 제너레이터로 구성될 수 있고, 실제 프로모션 이미지를 수신하여 색상이 변경된 생성된 프로모션 이미지를 출력할 수 있다. 생성된 프로모션 이미 지는 다시 ConvNet 인코더에 수신되고, ConvNet 인코더는 인코딩된 프로모션 이미지를 출력하여 추천 프로모션 속성 데이터의 프로모션 이미지 색상 정보와 Cross entropy 계산되어 에러를 출력할 수 있다. 이 러한 에러는 제너레이터에 다시 피드(feed)되어 생성된 프로모션 이미지가 더 프로모션 이미지 색상 정보 에 맞게 생성(generate)되도록 업데이트 될 수 있다. 도 7은 본 발명의 일실시예에 따른 ConvNet 인코더의 예를 도시한 모식도이다. 도 7에 도시된 바와 같이, ConvNet 인코더는 [INPUT-CONV-RELU-POOL-FC]으로 구축할 수 있다. 입력 데이터인 생성된 프로모션 이미지 의 경우, INPUT 입력 이미지가 가로 32, 세로 32, 그리고 RGB 채널을 가지는 경우 입력의 크기는[32x32x3]이다. CONV 레이어(Conv. Filter, 101)는 입력 이미지의 일부 영역과 연결되어 있으며, 이 연결된 영 역과 자신의 가중치의 내적 연산(dot product)을 계산하게 된다. 결과 볼륨은 [32x32x12]와 같은 크기를 갖게 된다. RELU 레이어는 max(0,x)와 같이 각 요소에 적용되는 액티베이션 함수(activation function)이다. RELU 레이어는 볼륨의 크기를 변화시키지 않는다([32x32x12]). 그 결과 Activation map 1 을 생성한다. POOL 레이어(pooling, 103)는 \"가로,세로\" 차원에 대해 다운샘플링(downsampling)을 수행해 [16x16x12]와 같이 줄어 든 볼륨(Activation map 2, 104)을 출력한다. FC (fully-connected) 레이어는 클래스 점수들을 계산해 [1x1x10]의 크기를 갖는 볼륨(output layer, 106)을 출력한다. \"10\"은 10개 카테고리에 대한 클래스 점수(본 발명의 일실시예에 따른 프로모션 이미지 색상 정보)에 해당한다. FC 레이어는 이전 볼륨의 모든 요소와 연결되 어 있다. 이와 같이, ConvNet은 픽셀 값으로 이뤄진 원본 이미지를 각 레이어를 거치며 클래스 점수(본 발명의 일실시예 에 따른 프로모션 이미지 색상 정보)로 변환(transform)시킨다. 어떤 레이어는 모수 (parameter)를 갖지만 어떤 레이어는 모수를 갖지 않는다. 특히 CONV/FC 레이어들은 단순히 입력 볼륨만이 아니라 가중치(weight)와 바이어 스(bias)도 포함하는 액티베이션(activation) 함수이다. 반면 RELU/POOL 레이어들은 고정된 함수이다. CONV/FC 레이어의 모수 (parameter)들은 각 이미지에 대한 클래스 점수가 해당 이미지의 레이블과 같아지도록 그라디언 트 디센트(gradient descent)로 학습된다. CONV 레이어의 모수(parameter)들은 일련의 학습가능한 필터들로 이뤄져 있다. 각 필터는 가로/세로 차원으로는 작지만 깊이 (depth) 차원으로는 전체 깊이를 아우른다. 포워드 패스(forward pass) 때에는 각 필터를 입력 볼 륨의 가로/세로 차원으로 슬라이딩시키며(정확히는 convolve시키며) 2차원의 액티베이션 맵 (activation map)을 생성한다. 필터를 입력 위로 슬라이딩 시킬 때, 필터와 입력 볼륨 사이에서 내적 연산(dot product)이 이뤄진다. 이러한 과정으로 ConvNet은 입력 데이터의 특정 위치의 특정 패턴에 대해 반응하는(activate) 필터를 학습하게 된다. 이런 액티베이션 맵(activation map)을 깊이(depth) 차원으로 쌓은 것이 곧 출력 볼륨이 된다. 그러므로 출력 볼륨의 각 요소들은 입력의 작은 영역만을 취급하고, 같은 액티베이션 맵 내의 뉴런들은 같은 필 터를 적용한 결과이므로 같은 모수들을 공유한다. 도 8은 본 발명의 일실시예에 따른 프로모션 추천 방법을 도시한 흐름도이다. 도 8에 도시된 바와 같이, 본 발 명의 일실시예에 따른 프로모션 추천 방법은, 프로모션 성과 예측 단계(S10), 상태 정보 수신 단계(S11), 추천 프로모션 속성 데이터 출력 단계(S12), 상태 및 보상 정보 수신 단계(S13), 정책망 및 가치망 업데이트 단계 (S14)를 포함할 수 있다. 프로모션 성과 예측 단계(S10)는 프로모션 성과 예측 인공신경망 장치가 기존의 프로모션 속성 데이터, 성과 데 이터를 수신하여 특정 프로모션 속성에 대한 프로모션 성과를 예측한 뒤 프로모션 추천 장치에 송신하는 단 계이다. 예측된 프로모션 성과 데이터는 정책망과 가치망의 초기값으로 이용될 수 있다. 상태 정보 수신 단계(S11)는 프로모션 추천 장치가 인터넷 쇼핑몰 데이터 허브 장치에서 에피소드 t에 대한 상태 정보(st)를 수신하는 단계이다. 추천 프로모션 속성 데이터 출력 단계(S12)는 프로모션 추천 장치가 최적 프로모션 탐색 모듈을 통해 에피소드 t에 대한 추천 프로모션 속성 확률을 포함하는 추천 프로모션 속성 데이터(at)를 출력하는 단계이다. 상태 및 보상 정보 수신 단계(S13)는 추천 프로모션 속성 데이터에 따라 인터넷 쇼핑몰에 프로모션이 적용된 뒤, 프로모션 추천 장치가 인터넷 쇼핑몰 데이터 허브 장치에서 에피소드 t+1에 대한 상태 정보(st+1) 및 at 에 대한 보상 정보(rt+1)를 수신하는 단계이다. 정책망 및 가치망 업데이트 단계(S14)는 수신된 상태 정보(st+1) 및 at에 대한 보상 정보(rt+1)를 기초로 정책망 과 가치망을 업데이트하는 단계이다. 강화학습의 관점에서, 본 발명의 일실시예에 따른 프로모션 추천 방법의 Objective는 프로모션의 성과를 향상시 키는 것이고, 상태(State)는 현재 성과 데이터(판매수량(Quantity), 매출액(Sales Amount), 유입량(Page View), 전환율(Conversion Rate), 평균판매단가(Average Sales Price), 매출이익 등) 및 환경 데이터(날짜, 요 일, 날씨, 현재 프로모션 진행 중인 제품, 쇼핑몰, 쇼핑몰의 다른 제품 정보)를 의미할 수 있고, 액션(Action) 은 프로모션 속성 데이터(프로모션 카테고리(할인 프로모션, 사은품 프로모션 등), 프로모션 기간, 프로모션 쇼핑몰, 노출구좌, 프로모션 이미지 색상 등)을 의미할 수 있으며, 보상(Reward)은 특정 기간 동안의 성과 데이터 의 상승 또는 하강을 의미할 수 있다. 이상에서 설명한 바와 같이, 본 발명이 속하는 기술 분야의 통상의 기술자는 본 발명이 그 기술적 사상이나 필 수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 상술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범 위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함하는 것으로 해석되어야 한다. 본 명세서 내에 기술된 특징들 및 장점들은 모두를 포함하지 않으며, 특히 많은 추가적인 특징들 및 장점들이 도면들, 명세서, 및 청구항들을 고려하여 당업자에게 명백해질 것이다. 더욱이, 본 명세서에 사용된 언어는 주 로 읽기 쉽도록 그리고 교시의 목적으로 선택되었고, 본 발명의 주제를 묘사하거나 제한하기 위해 선택되지 않 을 수도 있다는 것을 주의해야 한다. 본 발명의 실시예들의 상기한 설명은 예시의 목적으로 제시되었다. 이는 개시된 정확한 형태로 본 발명을 제한 하거나, 빠뜨리는 것 없이 만들려고 의도한 것이 아니다. 당업자는 상기한 개시에 비추어 많은 수정 및 변형이 가능하다는 것을 이해할 수 있다. 그러므로 본 발명의 범위는 상세한 설명에 의해 한정되지 않고, 이를 기반으로 하는 출원의 임의의 청구항들에 의해 한정된다. 따라서, 본 발명의 실시예들의 개시는 예시적인 것이며, 이하의 청구항에 기재된 본 발명의 범 위를 제한하는 것은 아니다."}
{"patent_id": "10-2018-0152768", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 발명의 상세한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어 해석되어서는 아니 된다. 도 1은 본 발명의 일실시예에 따른 인공지능을 이용한 온라인 쇼핑몰에서의 프로모션 성과 예측 및 추천 장치 를 도시한 것, 도 2는 본 발명의 일실시예에 따른 프로모션 성과 예측 인공신경망 장치의 학습 과정을 도시한 모식도, 도 3은 본 발명의 일실시예에 따른 프로모션 성과 예측 인공신경망 장치의 추론 과정을 도시한 모식도, 도 4는 본 발명의 일실시예에 따른 프로모션 추천 장치를 도시한 모식도, 도 5는 본 발명의 일실시예에 따른 프로모션 추천 장치의 동작예를 도시한 흐름도, 도 6은 본 발명의 일실시예에 따른 프로모션 이미지 수정 장치를 도시한 모식도, 도 7은 본 발명의 일실시예에 따른 ConvNet 인코더의 예를 도시한 모식도,도 8은 본 발명의 일실시예에 따른 프로모션 추천 방법을 도시한 흐름도이다."}
