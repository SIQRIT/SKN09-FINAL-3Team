{"patent_id": "10-2020-0082595", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0005142", "출원번호": "10-2020-0082595", "발명의 명칭": "인공지능 네트워크를 이용한 바람 벡터 예측 방법 및 분석장치", "출원인": "이화여자대학교 산학협력단", "발명자": "최용상"}}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "분석장치가 기상 영상을 입력받는 단계;상기 분석장치가 상기 기상 영상에 포함된 복수의 수증기 흡수 채널들 중 적어도 하나의 수증기 흡수 채널에 대한 제1 시점의 제1 기준 영상 및 상기 제1 시점과 다른 시점의 레퍼런스 영상을 제1 학습 네트워크에 입력하는단계; 및상기 분석장치가 상기 제1 학습 네트워크에서 출력하는 정보를 기준으로 상기 적어도 하나의 수증기 흡수 채널에 대하여 상기 제1 시점 이후의 제2 시점의 바람 벡터를 예측하는 단계를 포함하고,상기 제1 학습 네트워크는 상기 제1 기준 영상과 상기 레퍼런스 영상을 이용하여 상기 제2 시점의 영상 정보를출력하는 학습 네트워크인 인공지능 네트워크를 이용한 바람 벡터 예측 방법."}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 레퍼런스 영상은 상기 제1 기준 영상의 과거 시점 영상이고, 상기 제1 학습 네트워크는 상기 제1 기준 영상과 상기 레퍼런스 영상의 차이를 기준으로 상기 바람 벡터를 예측하거나,상기 레퍼런스 영상은 상기 제1 기준 영상의 미래 시점 영상이고, 상기 제1 학습 네트워크는 상기 제1 기준 영상과 상기 레퍼런스 영상의 차이를 기준으로 상기 제1 기준 영상과 상기 레퍼런스 영상 사이 시점인 상기 바람벡터를 예측하는 인공지능 네트워크를 이용한 바람 벡터 예측 방법."}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 분석장치는 상기 적어도 하나의 수증기 흡수 채널에서 상기 제2 시점 이후의 제3 시점의 제2 기준 영상 및레퍼런스 영상을 제2 학습 네트워크에 입력하여 상기 제2 시점의 바람 벡터를 예측하는 단계; 및상기 분석 장치가 상기 제1 기준 영상을 기준으로 예측된 바람 벡터와 상기 제2 기준 영상을 기준으로 예측된바람 벡터를 평균하여 최종적인 바람 벡터를 예측하는 단계를 더 포함하는 인공지능 네트워크를 이용한 바람 벡터 예측 방법."}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 학습네트워크는 GAN(Generative Adversarial Network), ACN(Adaptive convolution network) 또는 컨볼루셔널 인코더-디코더(convolutional encoder-decoder) 중 어느 하나인 인공지능 네트워크를 이용한 바람 벡터 예측 방법."}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제1 학습네트워크는 상기 제1 기준 영상을 입력받아 제1 특징 맵을 생성하는 제1 인코더;상기 제1 기준 영상과 상기 레퍼런스 영상의 차분 영상을 입력받아 제2 특징 맵을 생성하는 제2 인코더;상기 제2 특징 맵을 입력받아 상기 제2 시점의 제3 특징 맵을 생성하는 컨볼루션 LSTM(Long Short termmemory); 및공개특허 10-2022-0005142-3-상기 제1 특징 맵 및 상기 제3 특징 맵을 합산한 값을 입력받아 상기 바람 벡터에 대한 정보를 생성하는 디코더를 포함하는 인공지능 네트워크를 이용한 바람 벡터 예측 방법."}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 학습 네트워크가 출력하는 정보는 상기 바람 벡터에 대한 영상 또는 상기 바람 벡터에 대한 플로우 벡터인 인공지능 네트워크를 이용한 바람 벡터 예측 방법."}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제1 학습 네트워크는 지면의 복사량을 나타내는 채널에 대한 상기 제1 시점의 영상을 더 이용하여 구름 영역에 대한 어텐션(attention)을 입렵받는 인공지능 네트워크를 이용한 바람 벡터 예측 방법."}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "분석장치가 지면의 복사량을 나타내는 채널의 영상 및 수증기 흡수 채널의 영상을 입력받는 단계;상기 분석장치가 지면의 복사량을 나타내는 채널에 대한 영상을 세크먼테이션 네트워크에 입력하여 상기 영상에서 구름 영역과 구름이 없는 영역을 구분하는 단계;상기 분석장치가 상기 수증기 흡수 채널의 영상을 이용하여 상기 구름이 없는 영역에 대한 바람 벡터를 생성하는 단계;상기 분석장치가 상기 수증기 흡수 채널에 대한 제1 시점의 제1 기준 영상 및 상기 제1 시점과 다른 시점의 레퍼런스 영상을 제1 학습 네트워크에 입력하는 단계; 및상기 분석장치가 상기 제1 학습 네트워크에서 출력하는 정보를 기준으로 상기 수증기 흡수 채널에 대하여 상기제1 시점 이후의 제2 시점의 바람 벡터를 예측하는 단계를 포함하고,상기 제1 학습 네트워크는 상기 제1 기준 영상과 상기 레퍼런스 영상을 이용하여 상기 제2 시점의 영상 정보를출력하는 학습 네트워크인 인공지능 네트워크를 이용한 바람 벡터 예측 방법."}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제1 학습 네트워크는 보간 예측(interpolation prediction) 또는 보외 예측(extrapolation prediction)을수행하는 인공지능 네트워크를 이용한 바람 벡터 예측 방법."}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 분석장치는 상기 적어도 하나의 수증기 흡수 채널에서 상기 제2 시점 이후의 제3 시점의 제2 기준 영상 및레퍼런스 영상을 제2 학습 네트워크에 입력하여 상기 제2 시점의 바람 벡터를 예측하는 단계; 및상기 분석 장치가 상기 제1 기준 영상을 기준으로 예측된 바람 벡터와 상기 제2 기준 영상을 기준으로 예측된바람 벡터를 평균하여 최종적인 바람 벡터를 예측하는 단계를 더 포함하는 인공지능 네트워크를 이용한 바람 벡터 예측 방법"}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 제1 학습 네트워크는 지면의 복사량을 나타내는 채널에 대한 상기 제1 시점의 영상을 더 이용하여 구름 영역에 대한 어텐션공개특허 10-2022-0005142-4-(attention)을 입렵받는 인공지능 네트워크를 이용한 바람 벡터 예측 방법"}
{"patent_id": "10-2020-0082595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "적어도 하나의 수증기 흡수 채널에 대한 제1 시점의 제1 기준 영상 및 상기 제1 시점과 다른 시점의 레퍼런스영상을 입력받는 입력장치;상기 제1 기준 영상과 상기 레퍼런스 영상을 이용하여 상기 제2 시점의 영상 정보를 출력하는 학습 네트워크를저장하는 저장장치; 및상기 제1 기준 영상 및 상기 레퍼런스 영상을 상기 학습 네트워크에 입력하여 출력되는 정보를 기준으로 상기적어도 하나의 수증기 흡수 채널에 대하여 상기 제1 시점 이후의 제2 시점의 바람 벡터를 예측하는 연산 장치를포함하되,상기 학습 네트워크는 보간 예측(interpolation prediction) 또는 보외 예측(extrapolation prediction)을 수행하는 인공지능 네트워크를 이용하여 바람 벡터를 예측하는 분석 장치."}
{"patent_id": "10-2020-0082595", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 네트워크를 이용한 바람 벡터 예측 방법은 분석장치가 기상 영상을 입력받는 단계, 상기 분석장치가 상 기 기상 영상에 포함된 복수의 수증기 흡수 채널들 중 적어도 하나의 수증기 흡수 채널에 대한 제1 시점의 제1 기준 영상 및 상기 제1 시점과 다른 시점의 레퍼런스 영상을 제1 학습 네트워크에 입력하는 단계 및 상기 분석장 치가 상기 제1 학습 네트워크에서 출력하는 정보를 기준으로 상기 적어도 하나의 수증기 흡수 채널에 대하여 상 기 제1 시점 이후의 제2 시점의 바람 벡터를 예측하는 단계를 포함한다."}
{"patent_id": "10-2020-0082595", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하 설명하는 기술은 학습모델을 이용하여 기상 영상으로부터 바람 벡터를 예측하는 기법에 관한 것이다."}
{"patent_id": "10-2020-0082595", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기상학은 지상 관측, 항공 관측 및 위성 관측을 이용하여 구름 분류, 강수량 산출, 바람장 산출 등을 수행한다. 위성 바람장(Atmospheric Motion Vector, AMV)은 전체 지구 영역에 대하여 실시간으로 바람 정보를 제공한다. 위성 바람장은 실시간 기상 분석 및 수치 예보 모델 자료로 활용된다. 바람 벡터는 바람의 속도 및 방향을 나타 낸다. 바람 벡터는 두 개의 위성 영상을 이용하여 변위를 계산하여 산출할 수 있다. 선행기술문헌 비특허문헌 (비특허문헌 0001) 김소명 외 4인, 정지기상위성자료를 이용한 중규모 바람장 산출 알고리즘 최적화, Atmosphere. Korean Meteorological Society Vol. 22, No. 1 pp. 1-12"}
{"patent_id": "10-2020-0082595", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "위성 영상 중 수증기 흡수 채널은 수증기 특성을 기준으로 바람 벡터를 산출하는데 이용될 수 있다. 그러나, 수 증기 흡수 채널은 구름이 존재하지 않는 청정 영역에서만 바람 벡터 산출에 이용될 수 있다. 이하 설명하는 기술은 위성 영상을 입력데이터로 사용하는 인공지능 네트워크를 이용하여 바람 벡터를 예측하는 기술을 제공하고자 한다."}
{"patent_id": "10-2020-0082595", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "인공지능 네트워크를 이용한 바람 벡터 예측 방법은 분석장치가 기상 영상을 입력받는 단계, 상기 분석장치가 상기 기상 영상에 포함된 복수의 수증기 흡수 채널들 중 적어도 하나의 수증기 흡수 채널에 대한 제1 시점의 제 1 기준 영상 및 상기 제1 시점과 다른 시점의 레퍼런스 영상을 제1 학습 네트워크에 입력하는 단계 및 상기 분 석장치가 상기 제1 학습 네트워크에서 출력하는 정보를 기준으로 상기 적어도 하나의 수증기 흡수 채널에 대하 여 상기 제1 시점 이후의 제2 시점의 바람 벡터를 예측하는 단계를 포함한다. 다른 측면에서 인공지능 네트워크를 이용한 바람 벡터 예측 방법은 분석장치가 지면의 복사량을 나타내는 채널 의 영상 및 수증기 흡수 채널의 영상을 입력받는 단계, 상기 분석장치가 지면의 복사량을 나타내는 채널에 대한 영상을 세크먼테이션 네트워크에 입력하여 상기 영상에서 구름 영역과 구름이 없는 영역을 구분하는 단계, 상기분석장치가 상기 수증기 흡수 채널의 영상을 이용하여 상기 구름이 없는 영역에 대한 바람 벡터를 생성하는 단 계, 상기 분석장치가 상기 수증기 흡수 채널에 대한 제1 시점의 제1 기준 영상 및 상기 제1 시점과 다른 시점의 레퍼런스 영상을 제1 학습 네트워크에 입력하는 단계 및 상기 분석장치가 상기 제1 학습 네트워크에서 출력하는 정보를 기준으로 상기 수증기 흡수 채널에 대하여 상기 제1 시점 이후의 제2 시점의 바람 벡터를 예측하는 단계 를 포함한다."}
{"patent_id": "10-2020-0082595", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이하 설명하는 기술은 구름 영역이 있어 바람 벡터를 예측하기 어려운 경우에도 바람 벡터를 예측할 수 있어 정 확한 기상 예측에 기여한다."}
{"patent_id": "10-2020-0082595", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시례를 가질 수 있는 바, 특정 실시례들을 도면 에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 이하 설명하는 기술을 특정한 실시 형태에 대해 한정하려 는 것이 아니며, 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하 는 것으로 이해되어야 한다. 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 해당 구성요소들은 상기 용어 들에 의해 한정되지는 않으며, 단지 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예 를 들어, 이하 설명하는 기술의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 본 명세서에서 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함 하는 것으로 이해되어야 하고, \"포함한다\" 등의 용어는 설명된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요 소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의 해 전담되어 수행될 수도 있음은 물론이다. 또, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기 재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 위성 영상은 기상 정보를 포함하는 영상을 의미한다. 이하 설명하는 기술은 위성 영상을 이용하여 바람 벡터를 예측하는 기술이다. 위성 영상에서 구름이 존재하는 영역을 구름 영역이라고 하고, 구름이 없는 영역을 청정 영역이라고 명명한다. 이하 설명하는 기술은 학습모델을 사용하여 바람 벡터를 예측한다. 학습모델은 널리 알려진 바와 같이 다양한 모델이 있다. 이하 대표적인 학습 모델인 인공신경망(artificial neural network)을 사용하여 바람 벡터를 예측 한다고 가정한다. 한편, 인공신경망은 다양한 모델이 있다. 예컨대, 인공신경망은 CNN(Convolutional Neural Network), 오코인토더(auto encoder), 컨볼루셔널 인코더-디코더(convolutional encoder/decoder), RNN(Recurrent Neural Network) 등이 있다. 이하, 위성 영상을 처리하는 학습모델을 학습 네트워크라고 명명한 다. 학습 네트워크의 종류 및 구조는 다양할 수 있다. 이하 인공신경망을 이용하여 바람 벡터를 예측하는 주체는 분석장치라고 명명한다. 분석장치는 일정한 데이터 처리 및 연산이 가능한 컴퓨터 장치에 해당한다. 예컨대, 분석장치는 PC, 스마트기기, 서버 등과 같은 장치로 구현될 수 있다. 분석장치는 사전에 학습된 인공신경망 모델을 이용하여 입력 영상을 처리한다. 분석장치는 입 력 영상을 기준으로 보간된(interpolated) 영상 내지 보외된(extrapolated) 영상을 생성할 수 있다. 분석 장치는 다양한 형태의 위성 영상 중 적어도 하나를 사용하여 바람 벡터를 예측할 수 있다. 이하, 설명의 편의를 위하여 국내에서 사용하는 천리안 2A호의 관측 자료를 기준으로 설명한다. 입력데이터는 천리안2A호(2018년 12월에 발사, GK2A)에 탑재된 기상영상기(Advanced Meteorological Imager, AMI) 관측자료를 사용할 수 있다. 아래 표 1은 AMI의 16개 채널의 중심파장, 해상도, 주된 사용처에 대해 설명 하고 있다. 아래와 같이 위성 영상을 다양한 채널의 데이터를 포함할 수 있다. 표 1 채널 중심파장 (㎛) 해상도 (km)활용도 (Meteo-France, 2013) 최소값최대값 VNIR10.43100.4790 1 dust 20.50250.5175 1 30.62500.66000.5 cloud, water, land 40.84950.8705 1 land/sea mask, vegetation 5 1.3731.383 2 cirrus 6 1.6011.619 2 cloud phase MWIR7 3.7403.960 2 cloud screening, smoke 8 6.0616.425 2 water vapor 9 6.8907.010 2 water vapor 107.2587.433 2 water vapor 118.4408.760 2 cloud phase LWIR129.5439.717 2 1310.2510.61 2 cloud particle size 1411.0811.32 2 SST, cloud, rainfall, dust, … 1512.1512.45 2 low-level WV, volcanic ash 1613.2113.39 2CO2 상기 16개의 채널 중 4개의 채널을 사용하여 바람 벡터를 예측하는 기술로 설명한다. 3개의 채널(채널 8, 채널 9 및 채널 10)은 수증기 흡수 채널이고, 나머지 하나의 채널(채널 13)은 적외 대기창 영역의 채널이다. 이하, 수증기 흡수 채널은 바람 벡터를 예측하는 기본적인 입력 데이터로 사용하고, 적외 대기창 영역의 채널은 구름 존재 여부를 판단하는 용도의 데이터로 사용한다. 각 채널에 대하여 간략하게 설명한다. 채널 8 중심파장이 6.2 ㎛인 채널 8은 \"상층 수증기 흡수 채널\"로 알려진 적외관측채널이다. 따라서, 상층의 바람, 제 트의 궤도 등을 파악하는데 유용하다. 뿐만 아니라 높이 발달한 허리케인, 스톰의 움직임, 악가상을 모니터링하는데 도움이 되며, 상층의 수증기량 측정에도 도움이 된다. 분석장치는 채널 8의 수증기의 모니터링을 통해 상 층의 바람 벡터를 산출할 수 있다. 다만, 이 채널에서 광학적으로 두꺼운 구름 영역은 대기 중 수증기의 특성을 관측하는데 방해가 되어 산출이 어렵다. 채널 9 중심파장이 6.9 ㎛로, \"중층 수증기 흡수 채널\"로 알려진 적외관측채널이다. 기능은 채널 8과 같으며, 차이점은 관측되는 고도이다. 따라서 분석장치는 채널 9의 수증기의 모니터링을 통해 상층의 바람 벡터를 산출할 수 있다. 다만, 이 채널에서 광학적으로 두꺼운 구름 영역은 대기 중 수증기의 특성을 관측하는데 방해가 되어 산 출이 어렵다. 채널 10 중심파장이 7.3 ㎛으로, \"하층 수증기 흡수 채널\"로 알려진 적외관측채널이다. 즉, 이 채널은 주로 500-750 hPa (중위도의 경우) 쪽의 수증기 특성을 보여준다. 분석장치는 채널 10의 수증기의 모니터링을 통해 상층의 바람 벡터를 산출할 수 있다. 다만, 이 채널에서 광학적으로 두꺼운 구름 영역은 대기 중 수증기의 특성을 관측하는 데 방해가 되어 산출이 어렵다. 채널 13 중심파장이 10.4 ㎛으로 AMI의 16개 채널 중 대기의 오존과 수증기의 흡수가 가장 적은 대기창 적외채널이다. 대기 중 어떤 기체에 영향을 받지 않고 관측 타겟의 특성을 반영하므로, 구름의 분별, 분류 등이 가능하다. 분 석장치는 구름 영역과 청천 영역의 구별을 위해 채널 13을 사용할 수 있다. 입력 데이터 전처리 위성 영상의 데이터는 사전에 일정하게 전처리될 필요가 있다. 학습 네트워크는 입력되는 데이터는 다음과 같은 전처리 과정을 거칠 수 있다. 위성에서 관측된 디지털 카운트 값을 의미있는 물리량(반사도/복사량)으로 전환하기 위하여는 다음과 같은 식을 사용하며, 필요한 계수는 표 2와 같다. 수학식 1"}
{"patent_id": "10-2020-0082595", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "표 2 Channel Gain Offset 8 -0.0108914673328399 44.177703857421800000 9 -0.00818779878318309 66.74807739257810000 10 -0.0096982717514038 79.060852050781200000 13 -0.01981969550251960 161.58013916015600000 복사량은 일정한 밝기 온도로 전환될 수 있다. 복사량을 밝기온도로 전환하는 식은 다음 표3과 같다. 표 3"}
{"patent_id": "10-2020-0082595", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이와 같은 전처리 과정을 거치면 영상의 채널들은 각각 일정한 밝기를 갖는 영상으로 변환된다. 도 1은 위성 영상을 이용하여 바람 벡터를 예측하는 시스템에 대한 예이다. 도 1(A)는 분석 서버 형태의 분석 장치에 대한 예이다. 시스템은 위성, 클라이언트 및 분석 서 버를 포함한다. 위성은 전술한 위성 영상을 획득하여 클라이언트에 전달한다. 클라이언트 는 필요한 경우 위성 영상을 전처리하여 분석 서버에 전달할 수 있다. 클라이언트는 서로 다른 시간 대의 위성 영상들(t1과 t2)을 분석 서버에 전달한다. 설명의 편의를 위하여 영상 2개를 표현한 것이다. 클 라이언트는 바람 벡터 예측이 필요한 시점의 인접 시간의 영상들을 분석 서버에 전달한다. 분석 서버 는 입력 데이터를 전처리할 수도 있다. 분석 서버는 입력받은 영상을 이용하여 특정 시간의 바람 벡 터를 예측한다. 분석 서버는 예측 결과를 클라이언트에 전달할 수 있다. 도 1(B)는 컴퓨터 단말 형태의 분석 장치에 대한 예이다. 시스템은 위성 및 컴퓨터 장치를 포함 한다. 위성은 전술한 위성 영상을 획득하여 컴퓨터 장치에 전달한다. 컴퓨터 장치는 필요한 경 우 위성 영상을 전처리할 수 있다. 컴퓨터 장치는 서로 다른 시간대의 위성 영상들(t1과 t2)을 이용하여 바람 벡터를 예측한다. 컴퓨터 장치는 바람 벡터 예측이 필요한 시점의 인접 시간의 영상들을 이용하여 특 정 시간의 바람 벡터를 예측한다. 컴퓨터 장치는 예측 결과를 출력할 수 있다. 학습 네트워크는 바람 벡터에 대한 정보를 영상 또는 플로우 벡터(flow vector) 형태로 출력할 수 있다. 학습 네트워크는 다양한 구조 중 어느 하나를 가질 수 있다. 이하 설명의 편의를 위하여 컨볼루션 인코더-디코더 구 조 또는 변형된 컨볼루션 인코더-디코더 구조를 중심으로 설명한다. 도 2는 컨볼루셔널 인코더-디코더에 대한 예이다. 컨볼루셔널 인코더-디코더는 컨볼루셔널 인코더 및 컨볼루셔 널 디코더로 구성된다. 컨볼루셔널 인코더-디코더는 컨볼루션널 계층과 역컨볼루션널 계층(deconvolutional layer)의 쌍으로 이루어진 네트워크 구조이다. 도 2는 각각 5개의 컨볼루셔널 계층과 5개의 역컨볼루셔널 계층 을 갖는 구조이다. 컨볼루셔널 인코더는 컨볼루셔널 계층과 풀링 계층을 포함한다. 역컨볼루셔널 계층은 역 컨 볼루셔널 계층과 언풀링 계층(unpooling layer)을 포함한다. 역컨볼루셔널 계층은 컨볼루셔널 계층의 역동작을 수행한다. 역컨볼루셔널 계층은 컨볼루셔널 계층과 반대 방 향으로 컨볼루션 연산을 수행한다. 역컨볼루셔널 계층은 입력으로 특징맵을 받아 커널을 이용한 컨볼루션 연산 으로 출력 영상을 생성한다. 스트라이드를 1로 하면 역컨볼루셔널 계층은 특징맵의 가로, 세로 크기가 출력의 가로, 세로와 동일한 영상을 출력한다. 스트라이드를 2로 하면 역컨볼루셔널 계층은 특징맵의 가로, 세로 크기 대비 절반 크기의 영상을 출력한다. 언풀링 계층은 풀링 계층의 반대 방향으로 업샘플링(upsampling)을 진행한다. 언풀링 계층은 풀링 계층과 다르 게 반대로 차원을 확대하는 역할을 한다. 학습 네트워크는 비디오 보간법 (Video Interpolation)에 기반하여 바람 벡터를 예측할 수 있다. 또한, 학습 네 트워크는 비디오 보외법 (Video Extrapolation)에 기반하여 바람 벡터를 예측할 수 있다. 1) 비디오 보간법 (Video Interpolation)은 과거 및 미래의 비디오로부터 현재의 비디오를 추정하는 방법이다. 예컨대, 비디오 보 간법은 시간 t-1과 t+1의 프레임이 주어질 때 시간 t에서의 프레임을 예측하여 생성할 수 있다. 비디오 보 외법 (Video Extrapolation)은 과거 및 현재의 비디오로부터 미래의 비디오를 예측하는 방법이다. 예컨대, 비디 오 보외법은 시간 t-2과 t-1의 프레임이 주어질 때 시간 t에서의 프레임을 예측하여 생성할 수 있다. 비디오 보 간버 및 비디오 보외법은 연속적인 프레임에 대한 예측에 활용될 수도 있다. 한편, 시간 t의 영상을 입력받아 시간 t+1의 영상을 예측하는 모델은 정방향 예측(forward prediction) 모델이 라고 한다. 반대로, 시간 t+2의 영상을 입력받아 시간 t+1의 영상을 예측하는 모델은 역방향 예측(backward prediction) 모델이라고 한다. 정방향 예측 모델과 역방향 예측 모델은 예측하고자 하는 시간의 방향이 반대이 지만, 모델 구조는 동일하거나 유사할 수 있다. 도 3은 학습 네트워크를 이용한 바람 벡터 예측 과정에 대한 예이다. 도 3에서 제1 학습 네트워크 (A)는 정방향 예측 모델이고, 제2 학습 네트워크 (B)는 역방향 예측 모델에 해당한다. 도 3에서 x는 영상을 의미하고, 첨자 t 는 시점을 의미한다. 설명의 편의를 위하여 t+1 시점의 영상을 생성하는 경우에 대하여 설명한다. 분석장치는 t시점의 xt 영상 및 t-1 시점의 xt-1 영상을 제1 학습 네트워크(A)에 입력하여 t+1 시점의 영상 x't+1 영상을 생성할 수 있다. 분석장치는 x't+1 영상을 바람 벡터 예측 결과로 출력할 수 있다(①). 이 경우 제1 학습 네트워크(A)는 비디오 보외법에 기반한 모델이다. 한편, 분석장치는 t시점의 xt 영상 및 t+2 시점의 xt+2 영상을 제1 학습 네트워크(A)에 입력하여 t+1 시점의 영상 x't+1 영상을 생성할 수 있다. 분석장치는 x't+1 영상을 바람 벡터 예측 결과로 출력할 수 있다. 이 경우 제1 학습 네트워크(A)는 비디오 보간법에 기반한 모델이다. 또한, 분석 장치는 t+2시점의 xt+2 영상 및 t+3 시점의 xt+3 영상을 제2 학습 네트워크(B)에 입력하여 t+1 시점의 영상 x''t+1 영상을 생성할 수 있다. 분석장치는 x''t+1 영상을 바람 벡터 예측 결과로 출력할 수 있다(②). 이 경우 제1 학습 네트워크(A)는 비디오 보외법에 기반한 모델이다. 한편, 분석장치는 t시점의 xt+2 영상 및 t 시점 의 xt 영상을 제1 학습 네트워크(A)에 입력하여 t+1 시점의 영상 x''t+1 영상을 생성할 수 있다. 분석장치는 x''t+1 영상을 바람 벡터 예측 결과로 출력할 수 있다. 이 경우 제1 학습 네트워크(A)는 비디오 보간법에 기반한 모델이다. 나아가, 분석장치는 제1 학습 네트워크 (A)를 이용하여 예측한 x't+1 영상과 제2 학습 네트워크 (B)를 이용하여 예측한 x''t+1 영상을 평균합산하여 x^t+1 영상을 바람 벡터 예측 결과로 출력할 수 있다(③) 제1 학습네트워크 및/또는 제2 학습네트워크는 전술한 바와 같이 컨볼루셔널 인코더-디코더 구조로 구현될 수 있다. 또한, 제1 학습네트워크 및/또는 제2 학습네트워크는 GAN(Generative Adversarial Network)으로 구현될 수 있 다. 보간법을 기준으로 설명하면, 생성기는 두 개의 영상 프레임을 입력받아 보간된 영상을 예측하여 생성하고, 판별기는 생성된 영상과 두 개의 영상 프레임 사이(중간)에 위치한 영상과 비교한다. 학습된 학습네트워크는 두 개의 영상 프레임에 대한 보간된 영상을 생성하게 된다. 또한, 제1 학습네트워크 및/또는 제2 학습네트워크는 ACN(Adaptive convolution network)으로 구현될 수 있다. 보간법을 기준으로 설명하면, ACN은 커널을 CNN을 이용하여 학습하고 종단 간 학습으로 영상 예측과 픽셀 보간 을 한 번에 진행을 한다. ACN은 커널 함수 K가 사전에 마련되어야 한다. 이하 학습 네트워크(제1 학습네트워크 및/또는 제2 학습네트워크)의 구조에 대하여 설명한다. 설명의 편의를 위 하여 비디오 보간법을 기준으로 설명한다. 도 4는 학습 네트워크의 구조에 대한 예이다. 학습 네트워크는 인코더, 컨볼루션 LSTM 및 디코더를 포함한다. 인코더는 두 개의 서브 인코더(311 및 312)를 포함한다. 두 개의 서브 인코더는각각 복수의 컨볼루셔널 계층과 풀링 계층을 갖는 CNN 구조이다. 두 개의 서브 인코더를 각각 제1 서브 인코더 과 제2 서브 인코더로 명명한다. 두 개의 서브 인코더는 각각 복수의 컨볼루셔널 계층, 풀링 계층 및 비선형 연산 계층으로 구성될 수 있다. 제1 서브 인코더는 시간 t의 영상 프레임 xt을 입력받는다. 이때 입력 데이터는 복수의 수증기 흡수 채널 중 적어도 하나의 채널 영상일 수 있다. 도 4는 채널8(CH8), 채널9(CH9) 및 채널10(CH10)을 모두 입력한 예이다. 즉, 채널 8, 9, 10을 넣게 되면 각 채널의 가로 및 세로 길이가 W, H라고 할 때, W x H x 3의 영상 블 록이 입력으로 들어간다. 제1 서브 인코더는 시간 t의 영상 프레임 xt을 입력받아 처리한다. 제1 서브 인코더는 입력 영상 xt에 대한 특징 맵 s(t)를 추출한다. 제1 서브 인코더가 입력되는 영상을 기준 영상이라고 명명한다. 학습 네트 워크는 기준 영상의 다음 영상(예컨대, 다음 프레임 영상)을 생성할 수 있다. 제2 서브 인코더는 xt과 xt-1에 대한 차분 영상(residual video)을 입력받는다. 이때 입력 데이터는 제1 서 브 인코더가 입력받은 채널 영상과 동일하다. 도 4는 채널8(CH8), 채널9(CH9) 및 채널10(CH10)을 모두 입 력한 예이다. 제2 서브 인코더는 원본 영상에서 움직임이 있는 객체(또는 영역)에 대한 특징 맵 r(t)를 생 성한다. 이를 위해 제2 서브 인코더는 입력 영상의 프레임 사이의 차이(잔차 영상)를 이용하여 사전에 학 습되어야 한다. LSTM(Long Short term memory)에 대하여 먼저 간략하게 설명한다. RNN은 현재 들어온 입력 데이터와 과거에 입 력 받았던 데이터를 학습에 동시에 고려한다. RNN은 LSTM으로 구현될 수 있다. LSTM은 여러 게이트(gate)가 붙 어있는 셀(cell)로 이루어져 있다. 해당 셀에 연결된 게이트의 값 또는 가중치(weight)를 확인하여 어떤 값을 저장할지, 언제 정보를 내보내거나 삭제할지를 결정한다. 셀마다 이 가중치 값을 학습하며 학습 성능을 높인다. 컨볼루션 LSTM를 이용하면 시계열 정보를 학습하는 RNN의 구조에 LSTM을 활용하여 비디오 생성할 수 있다. 컨볼 루션 LSTM은 입력과 은닉벡터 간 연결을 컨볼루션 필터로 대체하여 기존 LSTM 대비 더 적은 양의 파라미터를 학 습시킬 수 있고 지역적 특성 잘 반영할 수 있다. 컨볼루션 LSTM은 제2 서브 인코더가 출력하는 특징 벡터를 시간 흐름을 고려하여 일정하게 변경한다. 컨볼루션 LSTM은 RNN의 구조에 LSTM을 활용하여 제2 서브 인코더가 출력하는 특징 벡터를 시간의 흐 름에 따라 변경하게 된다. 이를 위해 컨볼루션 LSTM은 사전에 연속적인 훈련 프레임에서 이동 객체에 대한 움직임 내지 특징 벡터로 학습되어야 한다. 보다 구체적인 동작은 이하 설명한다. 영상 생성 네트워크는 x0:t-1 비디오 프레임(시퀀스)를 사용한다고 가정한다. \"0:t-1\"은 \"시간 0 ~ t-1\"을 의미한다. 이때 잔차 영상 y0:t-1라고 할 수 있다. 제1 서브 인코더는 각 시간에 xt로부터 특징 벡터 st를 출력한다. 제2 서브 인코더는 각 시간에 yt로 부터 특징 벡터 rt를 출력한다. st,rt∈ 이다. fh는 필터 맵의 높이, fw는 필터 맵의 너비, fc는 필 터맵이 개수를 의미한다. 각 컨볼루셔널 계층에서 fw = w/2λ이고, fh = h/2λ이다. λ는 풀링 계층의 개수이다. 각 컨볼루셔널 계층의 필터 크기는 3×3일 수 있다. 컨볼루셔널 계층에서 필터 맵의 개수는 64 × 2λ일 수 있다. 풀링 계층 다음에 Relu와 같은 전달 함수가 위치할 수 있다. 또한 출력되는 특징 벡터는 일정하게 후처리 (normalization)될 수도 있다. 제2 서브 인코더도 제1 서브 인코더와 동일한 구조를 가질 수 있다. 컨볼루션 LSTM은 제2 서브 인코더가 출력하는 특징 벡터 r(t)를 t+1 시점의 추정값 r(t+1)으로 변경 한다. r(t+1)은 영상 프레임 xt 및 xt-1 기준으로 시간의 흐름에 따라 예측되는 프레임의 특징 벡터이다. LSTM 모듈은 메모리 셀 ct의 정보를 보유한 상태에서 r(t)를 수신한다. 그리고 LSTM 모듈은 수신한 정보를 이용하여 예측을 위한 정보를 업데이트한다. LSTM은 r(t+1)을 출력한다. 디코더는 제1 서브 인코더의 출력 벡터 st 및 컨볼루션 LSTM이 출력하는 출력 벡터 r(t+1)를 합 산(sum)한 값을 입력받는다. 디코더는 st+r(t+1)를 일정한 영상으로 재구성한다. 디코더는 xt+1을 출 력한다. xt+1는 xt 다음에 위치하는 것으로 예측된 프레임이다. 도 4는 3개의 채널에 대한 예측 영상을 출력하는 예이다.도 5는 학습 네트워크의 구조에 대한 다른 예이다. 학습 네트워크는 영상이 아닌 플로우 벡터 맵을 출력한다. 학습 네트워크는 인코더, 컨볼루션 LSTM 및 디코더를 포함한다. 인코더는 두 개의 서브 인코더(411 및 312)를 포함한다. 두 개의 서브 인코더는 각각 복수의 컨볼루셔널 계층과 풀링 계 층을 갖는 CNN 구조이다. 두 개의 서브 인코더를 각각 제1 서브 인코더과 제2 서브 인코더로 명명한 다. 두 개의 서브 인코더는 각각 복수의 컨볼루셔널 계층, 풀링 계층 및 비선형 연산 계층으로 구성될 수 있다. 제1 서브 인코더는 시간 t의 영상 프레임 xt을 입력받는다. 이때 입력 데이터는 복수의 수증기 흡수 채널 중 적어도 하나의 채널 영상일 수 있다. 도 5는 채널8(CH8), 채널9(CH9) 및 채널10(CH10)을 모두 입력한 예이다. 즉, 채널 8, 9, 10을 넣게 되면 각 채널의 가로 및 세로 길이가 W, H라고 할 때, W x H x 3의 영상 블 록이 입력으로 들어간다. 제1 서브 인코더는 시간 t의 영상 프레임 xt을 입력받아 처리한다. 제1 서브 인코더는 입력 영상 xt에 대한 특징 맵 s(t)를 추출한다. 제1 서브 인코더가 입력되는 영상을 기준 영상이라고 명명한다. 학습 네트 워크는 기준 영상의 다음 영상(예컨대, 다음 프레임 영상)을 생성할 수 있다. 제2 서브 인코더는 xt과 xt-1에 대한 차분 영상(residual video)을 입력받는다. 이때 입력 데이터는 제1 서 브 인코더가 입력받은 채널 영상과 동일하다. 도 4는 채널8(CH8), 채널9(CH9) 및 채널10(CH10)을 모두 입 력한 예이다. 제2 서브 인코더는 원본 영상에서 움직임이 있는 객체(또는 영역)에 대한 특징 맵 r(t)를 생 성한다. 이를 위해 제2 서브 인코더는 입력 영상의 프레임 사이의 차이(잔차 영상)를 이용하여 사전에 학 습되어야 한다. 컨볼루션 LSTM를 이용하면 시계열 정보를 학습하는 RNN의 구조에 LSTM을 활용하여 비디오 생성할 수 있다. 컨볼 루션 LSTM은 입력과 은닉벡터 간 연결을 컨볼루션 필터로 대체하여 기존 LSTM 대비 더 적은 양의 파라미터를 학 습시킬 수 있고 지역적 특성 잘 반영할 수 있다. 컨볼루션 LSTM은 제2 서브 인코더가 출력하는 특징 벡터를 시간 흐름을 고려하여 일정하게 변경한다. 컨볼루션 LSTM은 RNN의 구조에 LSTM을 활용하여 제2 서브 인코더가 출력하는 특징 벡터를 시간의 흐 름에 따라 변경하게 된다. 이를 위해 컨볼루션 LSTM은 사전에 연속적인 훈련 프레임에서 이동 객체에 대한 움직임 내지 특징 벡터로 학습되어야 한다. 컨볼루션 LSTM은 제2 서브 인코더가 출력하는 특징 벡터 r(t)를 t+1 시점의 추정값 r(t+1)으로 변경 한다. r(t+1)은 영상 프레임 xt 및 xt-1 기준으로 시간의 흐름에 따라 예측되는 프레임의 특징 벡터이다. LSTM 모듈은 메모리 셀 ct의 정보를 보유한 상태에서 r(t)를 수신한다. 그리고 LSTM 모듈은 수신한 정보를 이용하여 예측을 위한 정보를 업데이트한다. LSTM은 r(t+1)을 출력한다. 디코더는 제1 서브 인코더의 출력 벡터 st 및 컨볼루션 LSTM이 출력하는 출력 벡터 r(t+1)를 합 산(sum)한 값을 입력받는다. 디코더는 st+r(t+1)를 일정한 플로우 백터 맵으로 재구성한다. 디코더가 출력한 플로우 벡터는 영상의 화소가 다른 프레임에서 어떠한 위치로 이동하는지를 의미한다. 분석 장치는 플로 우 벡터로 원 채널 영상의 화소를 와핑(warping)하여 다음 시점의 프레임을 구성하는데 사용한다. 도 5는 3개의 채널에 대하여 각각 플오우 벡터를 원 채널 영상에 와필하여 t+1 시점의 영상 xt+1을 생성하는 예이다. 도 6은 학습 네트워크의 구조에 대한 또 다른 예이다. 학습 네트워크는 어텐션(attention) 모델에 해 당한다. 어텐션은 딥러닝 모델이 입력자료를 해석할 때 어떠한 영역을 보다 집중해서 분석해야 하는지 선택하는 과정을 지칭한다. 딥러닝 모델이 입력자료를 해석할 때 어떠한 영역을 보다 집중해서 분석해야 하는지 선택하는 과정을 지칭한다. 어텐션을 부여하는 방법이나 구조는 다양할 수 있다. 채널 13을 이용하여 어텐션을 부여할 수 있다. 채널 13은 지면에서 방출되는 복사량이 대기에 흡수되지 않고 위 성에 도달한다. 이 복사량의 밝기온도를 통해 관측 타켓의 지면 온도 추정이 가능하다. 따라서 채널 13의 밝기 온도는 구름이 있을 경우와 없을 경우에 달라지게 된다. 구름이 있는 경우는 없는 경우보다 채널 13의 밝기 온 도가 상대적으로 낮다. 예컨대, 채널 13의 밝기 온도 285 K보다 높은 곳을 청천 영역, 285 K보다 낮은 곳을 구 름 영역으로 정의할 수 있다. 즉, 채널 13을 이용하여 구름 영역과 청정 영역에 대한 별도의 가중치를부여하여, 구름 영역을 집중적으로 분석하게 할 수 있다. 도 6은 어텐션 맵을 모델의 중간 채널로 활용하는 예 이다. 학습 네트워크는 인코더, 컨볼루션 LSTM 및 디코더를 포함한다. 인코더는 두 개의 서 브 인코더(511 및 312)를 포함한다. 두 개의 서브 인코더는 각각 복수의 컨볼루셔널 계층과 풀링 계층을 갖는 CNN 구조이다. 두 개의 서브 인코더를 각각 제1 서브 인코더과 제2 서브 인코더로 명명한다. 두 개의 서브 인코더는 각각 복수의 컨볼루셔널 계층, 풀링 계층 및 비선형 연산 계층으로 구성될 수 있다. 제1 서브 인코더는 시간 t의 영상 프레임 xt을 입력받는다. 이때 입력 데이터는 복수의 수증기 흡수 채널 중 적어도 하나의 채널 영상일 수 있다. 도 6은 채널8(CH8), 채널9(CH9) 및 채널10(CH10)을 모두 입력한 예이다. 즉, 채널 8, 9, 10을 넣게 되면 각 채널의 가로 및 세로 길이가 W, H라고 할 때, W x H x 3의 영상 블 록이 입력으로 들어간다. 제1 서브 인코더는 시간 t의 영상 프레임 xt을 입력받아 처리한다. 제1 서브 인코더는 입력 영상 xt에 대한 특징 맵 s(t)를 추출한다. 제1 서브 인코더가 입력되는 영상을 기준 영상이라고 명명한다. 학습 네트 워크는 기준 영상의 다음 영상(예컨대, 다음 프레임 영상)을 생성할 수 있다. 이때 제1 서브 인코더 는 채널 13에 기반한 어텐션 맵을 중간 채널로 이용하여 구름 영역에 대하여 집중할 수 있다. 제2 서브 인코더는 xt과 xt-1에 대한 차분 영상(residual video)을 입력받는다. 이때 입력 데이터는 제1 서 브 인코더가 입력받은 채널 영상과 동일하다. 도 4는 채널8(CH8), 채널9(CH9) 및 채널10(CH10)을 모두 입 력한 예이다. 즉, 제2 서브 인코더는 원본 영상에서 움직임이 있는 객체(또는 영역)에 대한 특징 맵 r(t)를 생성한다. 이를 위해 제2 서브 인코더는 입력 영상의 프레임 사이의 차이(잔차 영상)를 이용하여 사전에 학습되어야 한다. 이때 제2 서브 인코더는 채널 13에 기반한 어텐션 맵을 중간 채널로 이용하여 구름 영역에 대하여 집중할 수 있다. 컨볼루션 LSTM은 제2 서브 인코더가 출력하는 특징 벡터를 시간 흐름을 고려하여 일정하게 변경한다. 컨볼루션 LSTM은 RNN의 구조에 LSTM을 활용하여 제2 서브 인코더가 출력하는 특징 벡터를 시간의 흐 름에 따라 변경하게 된다. 이를 위해 컨볼루션 LSTM은 사전에 연속적인 훈련 프레임에서 이동 객체에 대한 움직임 내지 특징 벡터로 학습되어야 한다. 컨볼루션 LSTM은 제2 서브 인코더가 출력하는 특징 벡터 r(t)를 t+1 시점의 추정값 r(t+1)으로 변경 한다. r(t+1)은 영상 프레임 xt 및 xt-1 기준으로 시간의 흐름에 따라 예측되는 프레임의 특징 벡터이다. LSTM 모듈은 메모리 셀 ct의 정보를 보유한 상태에서 r(t)를 수신한다. 그리고 LSTM 모듈은 수신한 정보를 이용하여 예측을 위한 정보를 업데이트한다. LSTM은 r(t+1)을 출력한다. 디코더는 제1 서브 인코더의 출력 벡터 st 및 컨볼루션 LSTM이 출력하는 출력 벡터 r(t+1)를 합 산(sum)한 값을 입력받는다. 디코더는 st+r(t+1)를 일정한 영상으로 재구성한다. 디코더는 xt+1을 출 력한다. xt+1는 xt 다음에 위치하는 것으로 예측된 프레임이다. 도 6은 3개의 채널에 대한 예측 영상을 출력하는 예이다. 도 6은 어텐션 맵을 학습 네트워크의 채널로 이용하는 예이다. 이와 달리, 입력 데이터를 채널 13을 이용하여 구성할 수 있다. 예컨대, 기본 입력 데이터인 채널 8, 채널 9 또는/및 채널 10에 미리 채널 13을 곱한 값을 입 력 데이터로 사용할 수 있다. 도 7은 학습 네트워크의 구조에 대한 또 다른 예이다. 도 7은 세그멘테이션 맵(segmentation map)을 사용 하는 예이다. 세그멘테이션은 입력 영상에서 특정 객체나 영역을 구분하는 과정을 의미한다. 세그멘테이션을 위 한 다양한 신경망 모델이 연구되었다. 예컨대, 컨볼루셔널 인코더-디코더 구조를 이용하여 세그멘테이션을 할 수 있다. 학습 네트워크는 인코더, 컨볼루션 LSTM, 세그멘테이션 신경망 및 디코더를 포함한다. 인코더는 두 개의 서브 인코더(611 및 312)를 포함한다. 두 개의 서브 인코더는 각각 복수의 컨 볼루셔널 계층과 풀링 계층을 갖는 CNN 구조이다. 두 개의 서브 인코더를 각각 제1 서브 인코더과 제2 서브 인코더로 명명한다. 두 개의 서브 인코더는 각각 복수의 컨볼루셔널 계층, 풀링 계층 및 비선형 연산 계층으로 구성될 수 있다. 제1 서브 인코더는 시간 t의 영상 프레임 xt을 입력받는다. 이때 입력 데이터는 복수의 수증기 흡수 채널 중 적어도 하나의 채널 영상일 수 있다. 도 7은 채널8(CH8), 채널9(CH9) 및 채널10(CH10)을 모두 입력한 예이다. 즉, 채널 8, 9, 10을 넣게 되면 각 채널의 가로 및 세로 길이가 W, H라고 할 때, W x H x 3의 영상 블 록이 입력으로 들어간다. 제1 서브 인코더는 시간 t의 영상 프레임 xt을 입력받아 처리한다. 제1 서브 인코더는 입력 영상 xt에 대한 특징 맵 s(t)를 추출한다. 제1 서브 인코더가 입력되는 영상을 기준 영상이라고 명명한다. 학습 네트 워크는 기준 영상의 다음 영상(예컨대, 다음 프레임 영상)을 생성할 수 있다. 제2 서브 인코더는 xt과 xt-1에 대한 차분 영상(residual video)을 입력받는다. 이때 입력 데이터는 제1 서 브 인코더가 입력받은 채널 영상과 동일하다. 도 4는 채널8(CH8), 채널9(CH9) 및 채널10(CH10)을 모두 입 력한 예이다. 즉, 제2 서브 인코더는 원본 영상에서 움직임이 있는 객체(또는 영역)에 대한 특징 맵 r(t)를 생성한다. 이를 위해 제2 서브 인코더는 입력 영상의 프레임 사이의 차이(잔차 영상)를 이용하여 사전에 학습되어야 한다. 컨볼루션 LSTM은 제2 서브 인코더가 출력하는 특징 벡터를 시간 흐름을 고려하여 일정하게 변경한다. 컨볼루션 LSTM은 RNN의 구조에 LSTM을 활용하여 제2 서브 인코더가 출력하는 특징 벡터를 시간의 흐 름에 따라 변경하게 된다. 이를 위해 컨볼루션 LSTM은 사전에 연속적인 훈련 프레임에서 이동 객체에 대한 움직임 내지 특징 벡터로 학습되어야 한다. 컨볼루션 LSTM은 제2 서브 인코더가 출력하는 특징 벡터 r(t)를 t+1 시점의 추정값 r(t+1)으로 변경 한다. r(t+1)은 영상 프레임 xt 및 xt-1 기준으로 시간의 흐름에 따라 예측되는 프레임의 특징 벡터이다. LSTM 모듈은 메모리 셀 ct의 정보를 보유한 상태에서 r(t)를 수신한다. 그리고 LSTM 모듈은 수신한 정보를 이용하여 예측을 위한 정보를 업데이트한다. LSTM은 r(t+1)을 출력한다. 세그멘테이션 신경망은 채널 13 영상 데이터를 입력받아 구름 영역과 청정 영역을 구분한다. 세그멘테이션 신경망은 세그멘테이션 맵을 출력한다. 도 7은 세그멘테이션 맵이 디코더 단에 적용되는 예이다. 디코더는 제1 서브 인코더의 출력 벡터 st 및 컨볼루션 LSTM이 출력하는 출력 벡터 r(t+1)를 합산(sum)한 값을 입력받는다. 디코더는 세그멘테 이션 맵을 이용하여 구름 영역을 중심으로 바람 벡터를 예측하는 정보를 출력할 수 있다. 디코더는 st+r(t+1)를 일정한 영상으로 재구성한다. 디코더는 xt+1을 출력한다. xt+1는 xt 다음에 위치하는 것으로 예 측된 프레임이다. 도 7은 3개의 채널에 대한 예측 영상을 출력하는 예이다. 즉, 분석 장치는 청정 영역에 대해서는 획득 가능한 영상을 기준으로 바람 벡터를 연산하고, 구름 영역에 대해 서만 전술한 학습 네트워크를 이용하여 바람 벡터를 예측하게 된다. 도 8은 분석 장치에 대한 구성의 예이다. 분석장치는 전술한 위성 영상을 이용하여 바람 벡터를 예측 하는 장치이다. 분석장치는 물리적으로 다양한 형태로 구현될 수 있다. 예컨대, 분석장치는 PC와 같 은 컴퓨터 장치, 네트워크의 서버, 영상 처리 전용 칩셋 등의 형태를 가질 수 있다. 컴퓨터 장치는 스마트 기기 등과 같은 모바일 기기를 포함할 수 있다. 분석장치는 저장 장치, 메모리, 연산장치, 인터페이스 장치, 통신 장치 미 출력 장치를 포함한다. 저장 장치는 영상 처리를 위한 학습 네트워크를 저장한다. 예컨대, 저장 장치는 바람 벡터 예측을 위 하여 전술한 학습 네트워크를 저장할 수 있다. 저장된 학습 네트워크는 사전에 학습된 모델이다. 나아가 저장 장치는 영상 처리에 필요한 프로그램 내지 소스 코드 등을 저장할 수 있다. 저장 장치는 입력 영상 및 출력된 영상 내지 플로우 벡터 등을 저장할 수 있다.메모리는 입력 영상 및 영상 생성과정에서 생성되는 데이터 및 정보 등을 저장할 수 있다. 인터페이스 장치는 외부로부터 일정한 명령 및 데이터를 입력받는 장치이다. 인터페이스 장치는 물리 적으로 연결된 입력 장치 또는 외부 저장 장치로부터 위성 영상(수증기 흡수 채널 및 대기창 적외채널)을 입력 받을 수 있다. 인터페이스 장치는 영상 처리를 위한 각종 신경망 모델을 입력받을 수 있다. 인터페이스 장 치는 신경망 모델 생성을 위한 학습데이터, 정보 및 파라미터값을 입력받을 수도 있다. 통신 장치는 유선 또는 무선 네트워크를 통해 일정한 정보를 수신하고 전송하는 구성을 의미한다. 통신 장 치는 외부 객체로부터 위성 영상(수증기 흡수 채널 및 대기창 적외채널)을 수신할 수 있다. 통신 장치 는 각종 신경망 모델 및 모델 학습을 위한 데이터도 수신할 수 있다. 통신 장치는 생성한 정보를 외 부 객체로 송신할 수 있다. 통신 장치 내지 인터페이스 장치는 외부로부터 일정한 데이터 내지 명령을 전달받는 장치이다. 통신 장치 내지 인터페이스 장치를 입력장치라고 명명할 수 있다. 연산 장치는 저장장치에 저장된 학습 네트워크 내지 프로그램을 이용하여 바람 벡터를 예측한다. 연 산 장치는 위성 영상을 전술한 바와 같이 일정하게 전처리할 수 있다. 연산 장치는 주어진 학습 데이 터를 이용하여 영상 처리 과정에 사용되는 신경망 모델을 학습할 수 있다. 연산 장치는 입력 영상을 학습 네트워크에 입력하여 바람 벡터 예측을 위한 정보(영상 또는 플로우 벡터 등)을 출력할 수 있다. 연산 장치는 플로우 벡터를 원본 영상에 적용하여 바람 벡터를 나타내는 영상을 생 성할 수도 있다. 연산 장치는 데이터를 처리하고, 일정한 연산을 처리하는 프로세서, AP, 프로그램이 임베 디드된 칩과 같은 장치일 수 있다. 출력장치는 바람 벡터 분석을 위한 과정의 인터페이스 화면을 출력할 수 있다. 출력장치는 예측된 바 람 벡터 정보(영상 등)를 출력할 수 있다. 또한, 상술한 바와 같은 바람 벡터 예측 방법은 컴퓨터에서 실행될 수 있는 실행가능한 알고리즘을 포함하는 프 로그램(또는 어플리케이션)으로 구현될 수 있다. 상기 프로그램은 일시적 또는 비일시적 판독 가능 매체(non- transitory computer readable medium)에 저장되어 제공될 수 있다. 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상 술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM (read-only memory), PROM (programmable read only memory), EPROM(Erasable PROM, EPROM) 또는 EEPROM(Electrically EPROM) 또는 플래시 메모리 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있 다. 일시적 판독 가능 매체는 스태틱 램(Static RAM，SRAM), 다이내믹 램(Dynamic RAM，DRAM), 싱크로너스 디램 (Synchronous DRAM，SDRAM), 2배속 SDRAM(Double Data Rate SDRAM，DDR SDRAM), 증강형 SDRAM(Enhanced SDRAM ，ESDRAM), 동기화 DRAM(Synclink DRAM，SLDRAM) 및 직접 램버스 램(Direct Rambus RAM，DRRAM) 과 같은 다양 한 RAM을 의미한다. 본 실시례 및 본 명세서에 첨부된 도면은 전술한 기술에 포함되는 기술적 사상의 일부를 명확하게 나타내고 있 는 것에 불과하며, 전술한 기술의 명세서 및 도면에 포함된 기술적 사상의 범위 내에서 당업자가 용이하게 유추 할 수 있는 변형 예와 구체적인 실시례는 모두 전술한 기술의 권리범위에 포함되는 것이 자명하다고 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2020-0082595", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 위성 영상을 이용하여 바람 벡터를 예측하는 시스템에 대한 예이다. 도 2는 컨볼루셔널 인코더-디코더에 대한 예이다. 도 3은 학습 네트워크를 이용한 바람 벡터 예측 과정에 대한 예이다. 도 4는 학습 네트워크의 구조에 대한 예이다. 도 5는 학습 네트워크의 구조에 대한 다른 예이다. 도 6은 학습 네트워크의 구조에 대한 또 다른 예이다. 도 7은 학습 네트워크의 구조에 대한 또 다른 예이다. 도 8은 분석 장치에 대한 구성의 예이다."}
