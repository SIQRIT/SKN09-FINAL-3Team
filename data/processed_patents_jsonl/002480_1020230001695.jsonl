{"patent_id": "10-2023-0001695", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0058737", "출원번호": "10-2023-0001695", "발명의 명칭": "수어를 음성 신호로 변환하는 장치 및 방법", "출원인": "에스에스엠엠 주식회사", "발명자": "곽원준"}}
{"patent_id": "10-2023-0001695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "수어를 음성 신호로 변환하는 장치에 있어서,수어 영상을 획득하여 상기 수어 영상에서 수지 영역 및 비수지 영역을 추출하는 획득부;상기 추출된 수지 영역에서 포인트 좌표를 가지는 복수의 수지 특징점 추출하는 제1 특징점 추출부;상기 추출된 비수지 영역에서 포인트 좌표를 가지는 복수의 비수지 특징점을 추출하는 제2 특징점 추출부;상기 수지 특징점을 제1 뉴럴 네트워크에 입력하여 텍스트 데이터를 생성하는 텍스트 생성부;상기 비수지 특징점을 제2 뉴럴 네트워크에 입력하여 음성 신호 정보를 생성하는 변환 정보 생성부 및상기 음성 신호 정보를 기반으로 상기 생성된 텍스트를 음성으로 변환하는 음성 변환부를 포함하는 수어를 음성신호로 변환하는 장치."}
{"patent_id": "10-2023-0001695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 획득부는,상기 수어 영상에서 손, 팔 및 어깨를 포함하는 수지 영역을 추출하는 수지 영역 추출부 및상기 수어 영상에서 얼굴표정, 머리의 움직임, 시선, 입모양, 몸의 움직임 중 적어도 하나를 포함하는 비수지영역을 추출하는 비수지 영역 추출부를 포함하는 수어를 음성 신호로 변환하는 장치."}
{"patent_id": "10-2023-0001695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 음성 변환부는,상기 음성 신호 정보를 기반으로 상기 생성된 텍스트와 더불어, 화자 정보 및 청자 정보에 기초하여 음성을 변환하는, 수어를 음성 신호로 변환하는 장치."}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "수어를 음성 신호로 변환하는 장치가 개시된다. 수어를 음성 신호로 변환하는 장치는 수어 영상을 획득하여 상기 수어 영상에서 수지 영역 및 비수지 영역을 추 출하는 획득부, 상기 추출된 수지 영역에서 포인트 좌표를 가지는 복수의 수지 특징점 추출하는 제1 특징점 추출 부, 상기 추출된 비수지 영역에서 포인트 좌표를 가지는 복수의 비수지 특징점을 추출하는 제2 특징점 추출부, 상기 수지 특징점을 제1 뉴럴 네트워크에 입력하여 텍스트 데이터를 생성하는 텍스트 생성부, 상기 비수지 특징 점을 제2 뉴럴 네트워크에 입력하여 음성 신호 정보를 생성하는 변환 정보 생성부 및 상기 음성 신호 정보를 기 반으로 상기 생성된 텍스트를 음성으로 변환하는 음성 변환부를 포함할 수 있다."}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하에서는 수어를 음성 신호로 변환하는 장치 및 방법이 개시된다. 상세하게는 수어 영상을 획득하여 영상에서 수지 영역과 비수지 영역을 나눠 각 영역에서 특징점을 추출해 음성 신호로 변환하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "수어는 농인들이 가장 선호하는 의사소통 수단으로 손과 비수지신호(non-manual signal)를 사용하는 시각언어로 써 비음성언어에 해당된다. 수어도 음성언어처럼 자연스럽게 생성된 공식적이고 사회적이며 함의적이고 규칙적 인 지배를 받는 기호체계를 갖는다. 비수지신호는 손의 움직임에 대응하는 수지신호와 함께 사용되는 얼굴표정, 머리의 움직임, 시선, 입모양, 몸의 움직임 등으로 정의된다. 농인은 의사소통 과정에서 수어의 손동작 못지 않게 비수지신호에 중점을 두고 있는데이는 수어의 형태론과 통사론 등과 같은 문법적 역할을 비수지신호가 담당하기 때문이다. 수어를 해석하여 음성 신호로 변환하고자 하는 연구는 앞서 진행되었지만, 선행 연구들은 비수지신호를 반영하 지 못한다는 문제점이 있다."}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이하에서 개시되는 적어도 하나의 실시 예는 상기의 종래 기술의 문제를 해결하기 위한 것으로, 수어를 음성 신 호로 변환하는 장치 및 방법을 제공하는 것을 목적으로 한다. 일 실시예에 따른 수어를 음성 신호로 변환하는 장치는 수어 영상에는 수지 영역과 비수지 영역을 추출하여 각 각의 특징점을 추출하고 추출된 특징점을 신경망에 입력하여 생성된 정보를 기반으로 음성을 생성할 수 있다. 구체적으로, 수지 영역에서 추출한 수지 특징점을 제1 뉴럴 네트워크에 입력하여 텍스트 데이터를 생성하고 비 수지 영역에서 추출한 비수지 특징점을 제2 뉴럴 네트워크에 입력하여 음성 신호 정보를 생성해 텍스트 데이터 를 음성 신호 정보에 기반하여 음성으로 변환할 수 있다. 이를 통해, 비언어적 표현이 반영된 음성 신호를 생성 하여 음성에 전달자의 감정이나 의도가 정확하게 표현될 수 있도록 할 수 있다. 이를 통해 농인들의 의사소통이 보다 원활해지도록 도울 수 있다. 본"}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 수어를 음성 신호로 변환하는 장치는 수어 영상을 획득하여 상기 수어 영상에서 수지 영역 및 비수지 영역을 추출하는 획득부, 상기 추출된 수지 영역에서 포인트 좌표를 가지는 복수의 수지 특징점 추출하 는 제1 특징점 추출부, 상기 추출된 비수지 영역에서 포인트 좌표를 가지는 복수의 비수지 특징점을 추출하는 제2 특징점 추출부, 상기 수지 특징점을 제1 뉴럴 네트워크에 입력하여 텍스트 데이터를 생성하는 텍스트 생성 부, 상기 비수지 특징점을 제2 뉴럴 네트워크에 입력하여 음성 신호 정보를 생성하는 변환 정보 생성부 및 상기 음성 신호 정보를 기반으로 상기 생성된 텍스트를 음성으로 변환하는 음성 변환부를 포함할 수 있다. 상기 획득부는 상기 수어 영상에서 손, 팔 및 어깨를 포함하는 수지 영역을 추출하는 수지 영역 추출부 및 상기 수어 영상에서 얼굴표정, 머리의 움직임, 시선, 입모양, 몸의 움직임 중 적어도 하나를 포함하는 비수지 영역을 추출하는 비수지 영역 추출부를 포함할 수 있다. 상기 음성 신호 정보는 음성의 속도, 음색, 어조, 크기 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "가 상술한 효과들로 제한되는 것은 아니며, 언급되지 아니한 효과들은 본 명세서 및 첨부된 도면"}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "과제의 해결 수단 일 실시예에 따른 수어를 음성 신호로 변환하는 장치는 수어 영상을 획득하여 상기 수어 영상에서 수지 영역 및 비수지 영역을 추출하는 획득부, 상기 추출된 수지 영역에서 포인트 좌표를 가지는 복수의 수지 특징점 추출하 는 제1 특징점 추출부, 상기 추출된 비수지 영역에서 포인트 좌표를 가지는 복수의 비수지 특징점을 추출하는 제2 특징점 추출부, 상기 수지 특징점을 제1 뉴럴 네트워크에 입력하여 텍스트 데이터를 생성하는 텍스트 생성 부, 상기 비수지 특징점을 제2 뉴럴 네트워크에 입력하여 음성 신호 정보를 생성하는 변환 정보 생성부 및 상기 음성 신호 정보를 기반으로 상기 생성된 텍스트를 음성으로 변환하는 음성 변환부를 포함할 수 있다. 상기 획득부는 상기 수어 영상에서 손, 팔 및 어깨를 포함하는 수지 영역을 추출하는 수지 영역 추출부 및 상기 수어 영상에서 얼굴표정, 머리의 움직임, 시선, 입모양, 몸의 움직임 중 적어도 하나를 포함하는 비수지 영역을 추출하는 비수지 영역 추출부를 포함할 수 있다. 상기 음성 신호 정보는 음성의 속도, 음색, 어조, 크기 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 4, "content": "발명의 효과 본 개시의 몇몇 실시예에 따르면, 수어의 비언어적 표현이 반영된 음성 신호를 생성할 수 있다. 이를 통하여, 전달자의 감정이나 의도를 명확하게 전달할 수 있어 농인들의 의사 소통 편의성을 증진시킬 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 5, "content": "아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명의 목적들, 기술적 해법들 및 장점들을 분명하게 하기 위하여 본 발명이 실시될 수 있는 특정 실시 예를 예시로서 도시하는 첨부 도면을 참조한다. 이들 실시 예는 통상의 기술자가 본 발명을 실시할 수 있도록 상세히 설명된다. 본 발명의 상세한 설명 및 청구항들에 걸쳐, '포함하다'라는 단어 및 그 변형은 다른 기술적 특징들, 부가물들, 구성요소들 또는 단계들을 제외하는 것으로 의도된 것이 아니다. 또한, '하나' 또는 '한'은 하나 이상의 의미 로 쓰인 것이며, '또 다른'은 적어도 두 번째 이상으로 한정된다. 또한, 본 발명의 '제1', '제2' 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로서, 순서를 나타내는 것으로 이해되지 않는 한 이들 용어들에 의하여 권리범위가 한정되어서는 아니 된다. 예를 들 어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 이와 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다고 언급된 때에는 그 다른 구성요소에 직접 연결될 수도 있지 만 중간에 다른 구성요소가 개재할 수도 있다고 이해되어야 할 것이다. 반면에 어떤 구성요소가 다른 구성요소 에 \"직접 연결되어\" 있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉, \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이 웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 각 단계들에 있어서 식별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용된 것으로 식별부호는 논리 상 필연적으로 귀결되지 않는 한 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 명기된 순서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며, 반대의 순서로 수행될 수도 있다. 통상의 기술자에게 본 발명의 다른 목적들, 장점들 및 특성들이 일부는 본 설명서로부터, 그리고 일부는 본 발 명의 실시로부터 드러날 것이다. 아래의 예시 및 도면은 실례로서 제공되며, 본 발명을 한정하는 것으로 의도된 것이 아니다. 따라서, 특정 구조나 기능에 관하여 본 명세서에 개시된 상세 사항들은 한정하는 의미로 해석되 어서는 아니되고, 단지 통상의 기술자가 실질적으로 적합한 임의의 상세 구조들로써 본 발명을 다양하게 실시하 도록 지침을 제공하는 대표적인 기초 자료로 해석되어야 할 것이다. 더욱이 본 발명은 본 명세서에 표시된 실시 예들의 모든 가능한 조합들을 망라한다. 본 발명의 다양한 실시 예 는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있는 특정 형상, 구조 및 특성은 일 실시 예에 관련하여 본 발명의 사상 및 범위를 벗어나지 않으면서 다른 실시 예로 구 현될 수 있다. 또한, 각각의 개시된 실시 예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 사상 및 범위 를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미로서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모든 범 위와 더불어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하거나 유사한 기능을 지칭한다. 본 명세서에서 달리 표시되거나 분명히 문맥에 모순되지 않는 한, 단수로 지칭된 항목은, 그 문맥에서 달리 요 구되지 않는 한, 복수의 것을 아우른다. 또한, 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 이하, 통상의 기술자가 본 발명을 용이하게 실시할 수 있도록 하기 위하여, 본 발명의 바람직한 실시 예들에 관 하여 첨부된 도면을 참조하여 상세히 설명하기로 한다. 본 발명은 수어를 음성 신호로 변환하는 장치에 관한 것으로, 수어 영상과 그와 관련된 스크립트 등의 데이터를 이용하여 학습된 복수의 뉴럴 네트워크를 이용하여 변환된 음성을 제공할 수 있다. 특히, 비언어적 표현을 반영 한 음성 데이터를 생성하여 전달자의 감정이나 의도가 명확하게 전달되도록 도울 수 있다. 도 1a은 인공 신경망(Artificial Neural Network)를 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 딥러닝(Deep Learning) 등을 포함하는 인공지능(AI) 알고리즘은 인공 신경망(Artificial Neural Network, AN N)에 입력 데이터를 입력하고, 컨볼루션 등의 연산을 통해 출력 데이터를 생성하도록 학습되고, 학습된 뉴럴 네트워크를 이용하여 특징을 추출할 수 있다. 뉴럴 네트워크는 생물학적 뇌를 모델링한 컴퓨터 과학적 아 키텍쳐(Computational Architecture)를 의미할 수 있다. 뉴럴 네트워크 내에서, 뇌의 뉴런들에 해당되는 노드 들은 서로 연결되어 있고, 입력 데이터를 처리하기 위하여 집합적으로 동작한다. 다양한 종류의 뉴럴 네트워크 들을 예로 들면, 컨볼루션 뉴럴 네트워크(Convolutional Neural Network, CNN), 회귀 뉴럴 네트워크(Recurrent Neural Network, RNN), 딥 빌리프 네트워크(Deep Belief Network, DBN), 제한된 볼츠만 기계(Restricted Boltzman Machine, RBM) 방식 등이 있으나, 이에 제한되지 않는다. 피드-포워드(feed-forward) 뉴럴 네트워크 에서, 뉴럴 네트워크의 뉴런들은 다른 뉴런들과의 연결들(links)을 갖는다. 이와 같은 연결들은 뉴럴 네트워크 를 통해, 한 방향으로, 예를 들어 순방향(forward direction)으로 확장될 수 있다. 도 1a은 입력 데이터를 입력 받아 출력 데이터를 출력하는 뉴럴 네트워크 (예를 들어, 컨볼루션 뉴럴 네트워크(Convolution Neural Network, CNN))의 구조를 도시한다. 인공 신경망은 2개 이상의 레이어 (layer)를 보유한 딥 뉴럴 네트워크(deep neural network)일 수 있다. 본 실시예에서 입력 데이터는 수어 영상일 수 있다. 실시예에 따라서 수어 영상에 수지 영역과 비수지 영역을 추출하고 추출된 영상에서 특징점이 결정된 데이터가 입력 데이터로 활용될 수 있다. 뉴럴 네트워크는 입력 데이터로부터 테두리, 선 색 등과 같은 \"특징들(features)\"을 추출하기 위해 이 용될 수 있다. 뉴럴 네트워크는 복수의 레이어를 포함할 수 있다. 각각의 레이어는 데이터를 수신할 수 있고, 해당 레이어에 입력되는 데이터를 처리하여 해당 레이어에서 출력되는 데이터를 생성할 수 있다. 레이어 에서 출력되는 데이터는, 뉴럴 네트워크에 입력된 이미지 또는 입력된 특징맵(feature map)을 필터(filter) 웨이트(weight) 값과 컨볼루션 연산하여 생성한 특징맵일 수 있다. 뉴럴 네트워크의 초기 레이어들은 입력 으로부터 에지들 또는 그레디언트들과 같은 낮은 레벨의 특징들을 추출하도록 동작될 수 있다. 뉴럴 네트워크 의 다음 레이어들은 이미지 내의 눈, 코 등과 같은 점진적으로 더 복잡한 특징들을 추출할 수 있다. 도 1b는 일 실시 예에 따른 복수의 뉴럴 네트워크를 설명하기 위한 도면이다. 도 1b를 참조하면, 일 실시 예에 따른 신경망 학습 장치는 뉴럴 네트워크(인공신경망과 동일한 의미를 지 칭)를 생성하거나, 뉴럴 네트워크를 훈련(train)(또는 학습(learn))하거나, 뉴럴 네트워크를 재훈련(retrain)하 는 기능들과 같은 다양한 프로세싱 기능들을 갖는 컴퓨팅 디바이스에 해당된다. 예를 들어, 신경망 학습 장치 는 PC(personal computer), 서버 디바이스, 모바일 디바이스 등의 다양한 종류의 디바이스들로 구현될 수 있다. 신경망 학습 장치는 주어진 초기 뉴럴 네트워크를 반복적으로 훈련(학습)시킴으로써, 훈련된 뉴럴 네트워 크를 생성할 수 있다. 훈련된 뉴럴 네트워크를 생성하는 것은 뉴럴 네트워크 파라미터를 결정하는 것을 의미할 수 있다. 여기서, 파라미터들은 예를 들어 뉴럴 네트워크의 입/출력 액티베이션들, 웨이트들, 바이 어스들 등 뉴럴 네트워크에 입/출력되는 다양한 종류의 데이터를 포함할 수 있다. 뉴럴 네트워크의 반복적인 훈련이 진행됨에 따라, 뉴럴 네트워크의 파라미터들은 주어진 입력에 대해 보다 정확한 출력을 연산하기 위해 조정될(tuned) 수 있다. 일 실시예에 따른 훈련된 뉴럴 네트워크는 복수의 뉴럴 네트워크로 구성될 수도 있다. 구체적으로, 훈련 된 뉴럴 네트워크는 제1 뉴럴 네트워크와 제2 뉴럴 네트워크를 포함할 수 있다. 예를 들어, 제1 뉴럴 네 트워크는 기존의 수어 영상들에서 추출한 수지 영역 데이터를 통해 학습될 수 있다. 이를 통해 제1 뉴럴 네트워크는 수지 특징점을 입력으로 하여 텍스트 데이터를 생성할 수 있다. 제2 뉴럴 네트워크는 비수지 특징점으로 음성 신호 정보를 출력하도록 학습될 수 있다. 제1 뉴럴 네트워크와 제2 뉴럴 네트워크는 독립적으 로 학습될 수도 있고, 서로 연관되어 학습될 수도 있다. 신경망 학습 장치는 훈련된 뉴럴 네트워크를 수어를 음성 신호로 변환하는 장치에 전달할 수 있 다. 수어를 음성 신호로 변환하는 장치 는 모바일 디바이스, 임베이스(embedded) 디바이스 등에 포함될 수 있다. 수어를 음성 신호로 변환하는 장치는 뉴럴 네트워크의 구동을 위한 전용 하드웨어일 수 있다. 수어를 음성 신호로 변환하는 장치는 훈련된 뉴럴 네트워크를 그대로 구동하거나, 훈련된 뉴럴 네트 워크가 가동(예를 들어, 양자화)된 뉴럴 네트워크를 구동할 수 있다. 가공된 뉴럴 네트워크를 구동하는 수어를 음성 신호로 변환하는 장치는, 신경망 학습 장치와는 별도로 독립적인 디바이스에서 구현될 수 있다. 하지만, 이에 제한되지 않고, 수어를 음성 신호로 변환하는 장치는 신경망 학습 장치와 동일한 디바이스 내에도 구현될 수 있다. 도 2는 일 실시예에 따른 수어를 음성 신호로 변환하는 방법이 수행되는 환경을 도시한 개념도이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 수어를 음성 신호로 변환하는 방법이 수행되는 환경은 통신망 , 수어를 음성 신호로 변환하는 장치, 사용자 단말 및 외부 서버를 포함할 수 있다. 즉, 수어를 음성 신호로 변환하는 장치 , 사용자 단말 및 외부 서버가 통신망을 통해 서로 연 결된 상태일 수 있다. 통신망은 전용선 등을 포함하는 유선 인터넷, 무선 인터넷, 이동통신망, 위성통신망 등을 포함할 수 있다. 수어를 음성 신호로 변환하는 장치 는 본 발명의 일 실시예에 따른 수어를 음성 신호로 변환하는 방법을 주도적으로 수행하는 장치를 의미할 수 있으며, 뉴럴 네트워크를 이용하여 수어를 음성 신호로 변환하는 장치일 수 있다. 수어를 음성 신호로 변환하는 장치는 통신망을 통해 사용자 단말이나 외부서버로부터 수 어 영상을 획득할 수 있다. 일 실시예에 따라, 수어를 음성 신호로 변환하는 장치에 의하여 실행되는 프로그램 코드는 메모리 장치에 저장될 수 있다. 수어를 음성 신호로 변환하는 장치 는 기타 외부 장치(예를 들어, 퍼스널 컴퓨터 또는 네트워크, 프린터 등)에 연결되고, 데이터를 교환할 수 있다. 수어를 음성 신호로 변환하는 장치는 서버 에 탑재될 수 있다. 사용자 단말은 본 발명의 일 실시예에 따른 수어를 음성 신호로 변환하는 방법을 통해 변환된 음성을 제공 받고자 하는 대상(즉, 사용자 등)의 장치를 의미할 수 있다. 구체적으로, 사용자 단말은 수어 영상을 음성 으로 변환하고자 하는 사용자의 장치를 의미할 수 있다. 다시 말해, 사용자 단말은 수어를 음성 신호로 변환하고자 하는 대상인 사용자의 장치를 의미할 수 있으며, 요청 정보 및 수어 영상을 수어를 음성 신호로 변환하는 장치에 제공할 수 있다. 외부서버는 통신망을 통해 수어를 음성 신호로 변환하는 장치 와 연결되어 복수의 뉴럴 네트워 크를 학습시키기 위해 필요한 정보를 제공할 수 있다. 즉, 외부서버는 수어 영상과 관련된 스크립트나 음 성 정보를 수어를 음성 신호로 변환하는 장치에 제공할 수 있다. 도 3은 일 실시예에 따른 수어를 음성 신호로 변환하는 장치를 설명하기 위한 블록도이다. 도 3을 참고하면, 수어를 음성 신호로 변환하는 장치는 획득부, 특징점 추출부, 텍스트 생성부 , 변환 정보 생성부 및 음성 변환부을 포함할 수 있다. 일 실시예에 따라, 획득부, 특징점 추출부, 텍스트 생성부, 변환 정보 생성부 및 음성 변환부는 하나의 서버 내의 구성요소를 이루거나, 각각 독립적인 서버로 구성되어 상호 동작을 하도록 구현될 수 있다. 또한, 획득부, 특징점 추 출부, 텍스트 생성부, 변환 정보 생성부 및 음성 변환부는 통신 버스(미도시)를 통해 서로 통신할 수 있다. 획득부은 수어 영상을 획득하여 상기 수어 영상에서 수지 영역 및 비수지 영역을 추출할 수 있다. 상기 획득부는 상기 수어 영상에서 손, 팔 및 어깨를 포함하는 수지 영역을 추출하는 수지 영역 추출부 및 상기 수어 영상에서 얼굴표정, 머리의 움직임, 시선, 입모양, 몸의 움직임 중 적어도 하나를 포함하는 비수지 영역을 추출하는 비수지 영역 추출부를 포함할 수 있다. 특징점 추출부는 복수의 영역에서 각각 특징점을 추출할 수 있다. 즉, 특징점 추출부는 상기 추출된 수지 영역에서 포인트 좌표를 가지는 복수의 수지 특징점 추출하는 제1 특징점 추출부 및 상기 추출된 비수지 영역에서 포인트 좌표를 가지는 복수의 비수지 특징점을 추출하는 제2 특징점 추출부를 포함할 수 있다. 예시적으로, 제1 특징점 추출부는 convolution layer에서 출력되는 좌,우 손 이미지에서 중요 특징 포인트를 추 출할 수 있다. 이를 통해 특징이 하나로 합쳐진 특징 맵을 생성할 수 있다. 텍스트 생성부는 상기 수지 특징점을 제1 뉴럴 네트워크에 입력하여 텍스트 데이터를 생성할 수 있다. 텍스트 생성부는 특징 맵에 출력 활성화 함수를 적용하여 텍스트를 생성할 수 있다. 변환 정보 생성부는 상기 비수지 특징점을 제2 뉴럴 네트워크에 입력하여 음성 신호 정보를 생성할 수 있 다. 음성 변환부는 상기 음성 신호 정보를 기반으로 상기 생성된 텍스트를 음성으로 변환할 수 있다. 음성 신 호 정보는 음성의 속도, 음색, 어조, 크기 중 적어도 하나를 포함할 수 있다. 음성 변환부은 비언어적 수어 정보를 음성 언어의 비언어적 표현에 해당하는 음성의 속도, 음색, 어조, 크 기로 변환하되, 인식가능한 감정 또는 의도의 종류 및 크기를 전체 벡터공간으로 하고 상기 비언어적 수어 정보 에 포함된 감정 또는 의도의 종류 및 크기를 지시하도록 형성된 One-Hot Vector 형태의 특성벡터로 비언어 음성 표현을 생성하여 텍스트에 접목시켜 텍스트를 음성을 변환할 수 있다. 도 4는 일 실시예에 따른 수어를 음성 신호로 변환하는 방법을 도시한 흐름도이다. 도 4를 참고하면, 수어를 음성 신호로 변환하는 장치는 변환하고자 하는 수어 영상을 획득하고(S410), 수 어 영상에서 수지 영역 및 비수지 영역을 추출하고(S420), 수지 영역 및 비수지 영역에서 각각의 특징점을 추출 하고(S430), 수지 특징점을 제1 신경망에 입력하여 텍스트 데이터를 생성하고(S440), 비수지 특징점을 제2 신경 망에 입력하여 음성 신호 정보를 생성하고(S450), 생성된 텍스트 데이터를 음성 신호 정보를 기반으로 변환할 수 있다(S460). 단계 (S410)에서 획득부는 사용자 단말로부터 변환하고자 하는 수어 영상을 획득할 수 있다. 획득부 는 수어 영상에서 흐려짐 보상 전처리를 수행할 수 있다. 이는, 동영상에서 수화자의 움직임이 빠른 경우, 객 체-예컨대, 손가락 등-의 형상에 잔상이 반영될 수 있기 때문이다. 일 실시예에 따르면, 획득부는 타깃 영역의 종류에 따라 복수의 추가 영상을 획득할 수 있다. 예를 들어, 비수지 영역을 획득하기 위한 얼굴 영상 의 경우, 표정, 입모양 등을 원활하게 추출하기 위하여 기존 수어 영상에 비해 확대된 영상에 대응되는 추가 영 상이 획득될 수 있다. 단계 (S420)에서 획득부는 수어 영상에서 수지 영역 및 비수지 영역을 추출할 수 있다. 구체적으로, 수지 영역 추출부는 수어 영상에서 손, 팔 및 어깨를 포함하는 수지 영역을 추출하고, 비수지 영역 추출부는 수어 영 상에서 얼굴표정, 머리의 움직임, 시선, 입모양, 몸의 움직임 중 적어도 하나를 포함하는 비수지 영역을 추출할 수 있다. 비수지 영역의 경우 앞서 설명된 추가 영상에 기초하여 획득됨으로써 보다 정확도 높은 특징점 획득 이 가능할 수 있다. 단계 (S430)에서 특징점 추출부는 수지 영역 및 비수지 영역에서 각각의 특징점을 추출할 수 있다. 구체적 으로 제1 특징점 추출부는 추출된 수지 영역에서 포인트 좌표를 가지는 복수의 수지 특징점 추출할 수 있다. 제 2 특징점 추출부는 추출된 비수지 영역에서 포인트 좌표를 가지는 복수의 비수지 특징점을 추출할 수 있다. 단계 (S430)는 수어를 해석하기 위해 사용되는 요소에 특징점을 추출하기 위한 단계로 손 및 팔의 동작을 결정 하기 위한 손 및 팔의 각 마디에 대한 특징점과, 얼굴의 표정을 인식하기 위한 얼굴의 각 특징점이 추출될 수 있다. 단계 (S440)에서 텍스트 생성부는 수지 특징점을 제1 뉴럴 네트워크에 입력하여 텍스트 데이터를 생성할 수 있다. 단계 (S450)에서 변환 정보 생성부은 비수지 특징점을 제2 뉴럴 네트워크에 입력하여 음성 신호 정보를 생 성할 수 있다. 단계 (S460)에서 음성 변환부는 음성 신호 정보를 기반으로 상기 생성된 텍스트를 음성으로 변환할 수 있 다. 단계 (S460)에서 음성 변환부는 음성 신호 정보를 분류 및 라벨링하여 One-Hot Vector 형태의 특성벡 터로 비언어 음성표현을 생성하여 텍스트에 접목시켜 텍스트를 음성을 변환할 수 있다. 예를 들어, 은성 변환 부는 특성 벡터 및 텍스트를 입력으로 하여 변환된 음성을 생성하도록 미리 학습된 제3 뉴럴 네트워크에 기초하여 변환된 음성을 생성할 수 있다. 일 실시예에 따르면, 음성 변환부는 음성을 변환하는 과정에서 화자 정보, 청자 정보 및 상황 정보를 이용하여 화자, 청자, 상황 별로 커스토마이즈된 음성 변환을 수행할 수 있다. 화자 정보는 화자의 성별, 나이, 직업, 지위 등 화자와 관련된 임의의 정보를 포함할 수 있으며, 청자 정보는 화자의 성별, 나이, 직업, 지위 등 청자와 관련된 임의의 정보를 포함할 수 있다. 또한, 상황 정보는, 두 화자의 발화 상황(예를 들어, 발표 상황, 사적 대화 상황, 비밀 대화 상황, 화를 내야 하는 상황 등 대화가 이루어지는 임의의 상황에 대응될 수 있음.)을 포함할 수 있다. 또한, 상황 정보는 껌이나 음식을 먹으며 대화 하는 상황을 더 포함할 수 있으며, 이를 통해 수어를 보다 생동감 있게 표현할 수 있는 수단이 제공될 수 있다.일 실시예에 따르면, 제3 뉴럴 네트워크는 특성 벡터, 텍스트, 화자 정보, 청자 정보, 상황 정보를 입력으로하 여 변환된 음성을 생성하도록 미리 학습될 수 있다. 이를 위하여, 학습 데이터는 화자, 청자, 상황에 따라 서 로 다른 음성을 생성하도록 라벨링되어, 보다 현실감있는 수어 변환이 이루어질 수 있는 수단을 제공할 수 있다. 예를 들어, 본원 발명에 따르면, 화를 내는 상황에서도 아이가 청자인 상황과, 직장에서 부하 직원에게 화를 내는 상황에서는 다른 어조로 음성 변환이 이루어질 수 있으며, 공적인 상황과 사적인 상황에서 동일한 대 상에 대해서도 지칭되는 단어나 존대 표현 등이 상이하게 선택될 수 있다. 또한, 수어를 음성 신호로 변환하는 장치는 수어 영상에서 특정 영역을 강조하는 소정의 지시자(예를 들어, 특 정 몸짓, 또는 장치에 대한 소정의 입력)를 입력받을 수 있으며, 이를 통해 해당 영역에 강조(예를 들어, 해당 영역의 소리가 커지거나, 해당 영역에 대한 발화 속도가 느리게 조절되는 등)하는 형태로 음성 변환이 이루어지 는 기능을 제공할 수도 있다. 이외에도 수어를 음성 신호로 변환하는 장치는 특정한 지시자에 기반하여 동일한 음성이 반복적으로 변환되어 한번의 수어로 동일한 복수회의 음성이 생성되는 기능을 제공할 수도 있다. 일 실시예에 따르면, 수어를 음성 신호로 변환하는 장치는 음성 변환이 제대로 되었는 지 확인하기 위한 확인 기능을 제공할 수 있다. 보다 구체적으로, 수어를 음성 신호로 변환하는 장치는 변환된 음성 신호를 음성 신호 를 수어 영상으로 변환하도록 미리 학습된 제4 인공 신경망에 입력하여 생성된 수어 영상을 사용자에게 다시 제 공하여, 의도한 바대로 수어가 음성으로 변환되었는 지를 확인할 수 있는 수단을 추가적으로 제공할 수 있다."}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위 실시 예의 설명에 기초하여 해당 기술분야의 통상의 기술자는, 본 발명의 방법 및/또는 프로세스들, 그리고 그 단계들이 하드웨어, 소프트웨어 또는 특정 용례에 적합한 하드웨어 및 소프트웨어의 임의의 조합으로 실현될 수 있다는 점을 명확하게 이해할 수 있다. 더욱이 본 발명의 기술적 해법의 대상물 또는 선행 기술들에 기여하 는 부분들은 다양한 컴퓨터 구성요소를 통하여 수행될 수 있는 프로그램 명령어의 형태로 구현되어 기계 판독 가능한 기록 매체에 기록될 수 있다. 상기 기계 판독 가능한 기록 매체는 프로그램 명령어, 데이터 파일, 데이 터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 기계 판독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 분야의 통상의 기술자에게 공지되어 사용 가능한 것일 수도 있다. 기계 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM, DVD, Blu-ray와 같은 광기록 매체, 플롭티컬 디스크(floptical disk) 와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저 장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령어의 예에는, 전술한 장치들 중 어 느 하나뿐만 아니라 프로세서, 프로세서 아키텍처 또는 상이한 하드웨어 및 소프트웨어의 조합들의 이종 조합, 또는 다른 어떤 프로그램 명령어들을 실행할 수 있는 기계 상에서 실행되기 위하여 저장 및 컴파일 또는 인터프 리트될 수 있는, C와 같은 구조적 프로그래밍 언어, C++ 같은 객체지향적 프로그래밍 언어 또는 고급 또는 저급 프로그래밍 언어(어셈블리어, 하드웨어 기술 언어들 및 데이터베이스 프로그래밍 언어 및 기술들)를 사용하여 만들어질 수 있는바, 기계어 코드, 바이트코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 이에 포함된다. 따라서 본 발명에 따른 일 태양에서는, 앞서 설명된 방법 및 그 조합들이 하나 이상의 연산 장치들에 의하여 수 행될 때, 그 방법 및 방법의 조합들이 각 단계들을 수행하는 실행 가능한 코드로서 실시될 수 있다. 다른 일 태양에서는, 상기 방법은 상기 단계들을 수행하는 시스템들로서 실시될 수 있고, 방법들은 장치들에 걸쳐 여러 가지 방법으로 분산되거나 모든 기능들이 하나의 전용, 독립형 장치 또는 다른 하드웨어에 통합될 수 있다. 또 다른 일 태양에서는, 위에서 설명한 프로세스들과 연관된 단계들을 수행하는 수단들은 앞서 설명한 임의의 하드 웨어 및/또는 소프트웨어를 포함할 수 있다. 그러한 모든 순차 결합 및 조합들은 본 개시서의 범위 내에 속하도 록 의도된 것이다. 예를 들어, 상기 하드웨어 장치는 본 발명에 따른 처리를 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동 하도록 구성될 수 있으며, 그 역도 마찬가지이다. 상기 하드웨어 장치는, 프로그램 명령어를 저장하기 위한 ROM/RAM 등과 같은 메모리와 결합되고 상기 메모리에 저장된 명령어들을 실행하도록 구성되는 MPU, CPU, GPU, TPU와 같은 프로세서를 포함할 수 있으며, 외부 장치와 신호를 주고받을 수 있는 입출력부를 포함할 수 있다. 덧붙여, 상기 하드웨어 장치는 개발자들에 의하여 작성된 명령어들을 전달받기 위한 키보드, 마우스, 기타 외부 입력장치를 포함할 수 있다. 이상에서 본 발명이 구체적인 구성요소 등과 같은 특정 사항들과 한정된 실시 예 및 도면에 의해 설명되었으나, 이는 본 발명의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 발명이 상기 실시 예들에 한정되는 것은"}
{"patent_id": "10-2023-0001695", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "아니며, 본 발명이 속하는 기술분야에서 통상적인 지식을 가진 사람이라면 이러한 기재로부터 다양한 수정 및변형을 꾀할 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등하게 또는 등가적으로 변형된 모든 것들은 본 발명의 사상의 범주에 속한다고 할 것이다. 그와 같이 균등하게 또는 등가적으로 변형된 것에는, 예컨대 본 발명에 따른 방법을 실시한 것과 동일한 결과를 낼 수 있는, 논리적으로 동치(logically equivalent)인 방법이 포함될 것인바, 본 발명의 진의 및 범위는 전술 한 예시들에 의하여 제한되어서는 아니되며, 법률에 의하여 허용 가능한 가장 넓은 의미로 이해되어야 한다."}
{"patent_id": "10-2023-0001695", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 실시 예의 설명에 이용되기 위하여 첨부된 아래 도면들은 본 발명의 실시 예들 중 단지 일부일 뿐이"}
{"patent_id": "10-2023-0001695", "section": "도면", "subsection": "도면설명", "item": 2, "content": "며, 본 발명의 기술분야에서 통상의 지식을 가진 사람(이하 \"통상의 기술자\"라 함)에게 있어서는 발명에 이르는 추가 노력 없이 이 도면들에 기초하여 다른 도면들이 얻어질 수 있다. 도 1a는 인공 신경망(Artificial Neural Network)를 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 도 1b는 일 실시 예에 따른 복수의 뉴럴 네트워크를 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 수어를 음성 신호로 변환하는 방법이 수행되는 환경을 도시한 개념도이다.도 3은 일 실시예에 따른 수어를 음성 신호로 변환하는 장치를 설명하기 위한 블록도이다. 도 4는 일 실시예에 따른 수어를 음성 신호로 변환하는 방법을 도시한 흐름도이다."}
