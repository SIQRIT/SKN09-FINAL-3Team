{"patent_id": "10-2020-0174295", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0084628", "출원번호": "10-2020-0174295", "발명의 명칭": "학습 데이터 수집 시스템 및 방법", "출원인": "네이버랩스 주식회사", "발명자": "이승현"}}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라를 통해, 자유도 센서가 각각 구비된 복수의 대상물에 대한 초기 영상을 수신하는 단계;상기 초기 영상에 포함된 상기 복수의 대상물 각각에 대응되는 이미지 객체에 근거하여, 상기 복수의 대상물 마다 서로 다른 라벨(label)을 설정하는 단계;상기 복수의 대상물 각각에 구비된 자유도 센서의 식별 정보와 상기 복수의 대상물 각각에 설정된 라벨을 일대일 매핑하는 단계;상기 카메라를 통해 수신되는 후속 영상으로부터 상기 복수의 대상물을 추적하여, 상기 복수의 대상물 마다 설정된 라벨에 각각 대응되는 세그멘테이션 마스크(segmentation mask)를 추출하는 단계; 및상기 복수의 대상물 마다 설정된 라벨을 기준으로, 상기 세그멘테이션 마스크와 상기 자유도 센서로부터 센싱되는 자유도 정보를 포함하는 학습 데이터를 수집하는 단계를 포함하는 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 후속 영상은 초(second) 당 기 설정된 수의 프레임(frame)을 포함하는 동영상이고,상기 세그멘테이션 마스크를 추출하는 단계에서는,상기 후속 영상에 포함된 연속되는 프레임 중 기 설정된 간격 마다 상기 복수의 대상물에 각각 대응되는 세그멘테이션 마스크를 추출하며,상기 학습 데이터를 수집하는 단계에서는,상기 세그멘테이션 마스크가 추출된 프레임이 촬영된 시점과 대응되는 시점에 상기 자유도 센서로부터 센싱된자유도 정보를, 상기 세그멘테이션 마스크와 매칭하여 저장하는 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 복수의 대상물은 제1 대상물 및 제2 대상물을 포함하고,상기 세그멘테이션 마스크를 추출하는 단계에서는,상기 기 설정된 간격의 프레임 마다 상기 제1 대상물에 대응되는 제1 세그멘테이션 마스크와 상기 제2 대상물에대응되는 제2 세그멘테이션 마스크를 추출하고,상기 학습 데이터를 수집하는 단계에서는,상기 제1 대상물에 구비된 제1 자유도 센서로부터 수집된 제1 자유도 정보와 상기 제1 세그멘테이션 마스크를매칭하여 상기 제1 대상물에 대한 학습 데이터로서 저장하고,상기 제2 대상물에 구비된 제2 자유도 센서로부터 수집된 제2 자유도 정보와 상기 제2 세그멘테이션 마스크를매칭하여 상기 제2 대상물에 대한 학습 데이터로서 저장하는 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1 및 제2 자유도 정보 각각은,공개특허 10-2022-0084628-3-상기 제1 및 제2 대상물 각각에 대한 3차원 위치 정보 및 3차원 자세 정보 중 적어도 하나를 포함하는 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제1 대상물은,상기 후속 영상이 수신되는 동안에 외력에 의하여 위치 및 자세 중 적어도 하나가 변경되며,상기 제1 대상물에 대한 학습 데이터는,변경된 상기 적어도 하나의 위치 및 자세에 대응되는 3차원 위치 정보 및 3차원 자세 정보를 포함하는 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서,상기 자유도 센서의 센싱 주파수는 상기 동영상의 FPS(Frame Per Second)와 대응되는 것을 특징으로 하는 학습데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 라벨을 설정하는 단계에서는,딥러닝 알고리즘에 기반하여, 상기 후속 영상으로부터 상기 복수의 대상물에 대한 추적이 가능하도록, 상기 초기 영상에서 상기 복수의 대상물 각각에 대응되는 이미지 객체의 초기 위치를 특정하기 위한 단위 영역이 지정되는 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 단위 영역은, 상기 초기 영상에서 상기 복수의 대상물 각각에 대응되는 이미지 객체 마다 각각 특정되고,각각의 단위 영역에는, 상기 복수의 대상물 각각에 대응되는 이미지 객체 중 상기 각각의 단위 영역에 대응되는어느 하나의 이미지 객체가 포함된 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 복수의 대상물 마다 설정된 서로 다른 라벨은, 상기 각각의 단위 영역에 상기 복수의 대상물을 기준으로설정된 라벨인 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 라벨을 설정하는 단계에서는,상기 각각의 단위 영역에 포함된 이미지 객체에 대한 세그멘테이션을 수행하여, 상기 각각의 단위 영역에 포함된 이미지 객체 마다의 세그멘테이션 마스크를 추출하는 단계를 포함하고,상기 이미지 객체 마다 추출된 세그멘테이션 마스크의 라벨은, 상기 각각의 단위 영역에 설정된 라벨에 근거하여 특정되는 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2022-0084628-4-제10항에 있어서,상기 복수의 대상물은 제1 대상물 및 제2 대상물을 포함하고,상기 제1 대상물에 구비된 제1 자유도 센서의 식별 정보는, 상기 각각의 단위 영역 중 상기 제1 대상물에 대응되는 제1 이미지 객체가 포함된 제1 단위 영역에 설정된 제1 라벨과 매핑되고,상기 제2 대상물에 구비된 제2 자유도 센서의 식별 정보는, 상기 각각의 단위 영역 중 상기 제2 대상물에 대응되는 제2 이미지 객체가 포함된 제2 단위 영역에 설정된 제2 라벨과 매핑되는 것을 특징으로 하는 학습 데이터수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 초기 영상에서 추출된 세그멘테이션 마스크 중 상기 제1 이미지 객체에 대응되는 제1 세그멘테이션 마스크의 제1 마스크 라벨은, 상기 제1 라벨에 대응되고,상기 제2 이미지 객체에 대응되는 제2 세그멘테이션 마스크의 제2 마스크 라벨은, 상기 제2 라벨에 대응되는 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 후속 영상에서 추출되는 상기 제1 대상물에 대응되는 세그멘테이션 마스크의 마스크 라벨은 상기 제1 마스크 라벨에 해당하고, 상기 후속 영상에서 추출되는 상기 제2 대상물에 대응되는 세그멘테이션 마스크의 마스크 라벨은 상기 제2 마스크 라벨에 해당하는 것을 특징으로 하는 학습 데이터 수집 방법."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "복수의 대상물에 각각 구비되어, 상기 복수의 대상물 각각에 대한 자유도 정보를 센싱하는 센서들을 포함하는센싱부;상기 복수의 대상물을 촬영하도록 이루어지는 카메라부;상기 카메라로부터 수신된 초기 영상에 포함된 상기 복수의 대상물 각각에 대응되는 이미지 객체에 근거하여,상기 복수의 대상물 마다 서로 다른 라벨(label)을 설정하고,상기 복수의 대상물 각각에 구비된 센서의 식별 정보와 상기 복수의 대상물 각각에 설정된 라벨을 일대일 매핑하는 제어부를 포함하고,상기 제어부는,상기 카메라를 통해 수신되는 후속 영상으로부터 상기 복수의 대상물을 추적하여, 상기 복수의 대상물 마다 설정된 라벨에 각각 대응되는 세그멘테이션 마스크(segmentation mask)를 추출하고,상기 복수의 대상물 마다 설정된 라벨을 기준으로, 상기 세그멘테이션 마스크와 상기 센서들로부터 수집되는 자유도 정보를 학습 데이터로서 수집하는 것을 특징으로 하는 학습 데이터 수집 시스템."}
{"patent_id": "10-2020-0174295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "전자기기에서 하나 이상의 프로세스에 의하여 실행되며, 컴퓨터로 판독될 수 있는 기록매체에 저장 가능한 프로그램으로서, 상기 프로그램은,카메라를 통해, 자유도 센서가 각각 구비된 복수의 대상물에 대한 초기 영상을 수신하는 단계;상기 초기 영상에 포함된 상기 복수의 대상물 각각에 대응되는 이미지 객체에 근거하여, 상기 복수의 대상물 마다 서로 다른 라벨(label)을 설정하는 단계;공개특허 10-2022-0084628-5-상기 복수의 대상물 각각에 구비된 자유도 센서의 식별 정보와 상기 복수의 대상물 각각에 설정된 라벨을 일대일 매핑하는 단계;상기 카메라를 통해 수신되는 후속 영상으로부터 상기 복수의 대상물을 추적하여, 상기 복수의 대상물 마다 설정된 라벨에 각각 대응되는 세그멘테이션 마스크(segmentation mask)를 추출하는 단계; 및상기 복수의 대상물 마다 설정된 라벨을 기준으로, 상기 세그멘테이션 마스크와 상기 자유도 센서로부터 수집되는 자유도 정보를 학습 데이터로서 저장하는 단계를 수행하도록 하는 명령어들을 포함하는 특징으로 하는 컴퓨터로 판독될 수 있는 기록매체에 저장 가능한 프로그램."}
{"patent_id": "10-2020-0174295", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능에서 학습의 대상이 되는 학습 데이터 수집 시스템 및 수집 방법에 관한 것이다. 본 발명에 따른 학습 데이터 수집 시스템은, 복수의 대상물에 각각 구비되어, 상기 복수의 대상물 각각에 대한 자유도 정보 를 센싱하는 센서들을 포함하는 센싱부, 상기 복수의 대상물을 촬영하도록 이루어지는 카메라부, 상기 카메라로 부터 수신된 초기 영상에 포함된 상기 복수의 대상물 각각에 대응되는 이미지 객체에 근거하여, 상기 복수의 대 상물 마다 서로 다른 라벨(label)을 설정하고, 상기 복수의 대상물 각각에 구비된 센서의 식별 정보와 상기 복수 의 대상물 각각에 설정된 라벨을 일대일 매핑하는 제어부를 포함할 수 있다."}
{"patent_id": "10-2020-0174295", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능에서 학습의 대상이 되는 학습 데이터 수집 시스템 및 이를 이용한 학습 데이터 수집 방법에 관한 것이다."}
{"patent_id": "10-2020-0174295", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능의 사전적 의미는, 인간의 학습능력과 추론능력, 지각능력, 자연언어의 이해능력 등을 컴퓨터 프로그램 으로 실현한 기술이라 할 수 있다. 이러한 인공지능은 머신러닝에 인간의 뇌를 모방한 신경망 네트워크를 더한 딥러닝으로 인하여 비약적인 발전을 이루었다. 딥러닝(deep learning)이란, 컴퓨터가 인간처럼 판단하고 학습할 수 있도록 하고, 이를 통해 사물이나 데이터를 군집화하거나 분류하는 기술로서, 최근에는 텍스트 데이터 뿐만 아니라 영상 데이터에 대한 분석까지 가능해져, 매우 다양한 산업분야에 적극적으로 활용되고 있다. 예를 들어, 로봇 분야, 자율 주행 분야, 의료 분야 등 다양한 산업분야에서는 딥러닝 기반의 학습 네트워크(이 하, “딥러닝 네트워크”라 명명함)를 통하여, 학습 대상 데이터를 기반으로 학습을 수행하고, 의미 있는 학습 결과를 도출함으로써, 각 산업분야에 유용하게 활용되고 있다. 일 예로서, 로봇 분야에서는, 로봇이 수행하는 작업에 대한 이해를 위하여, 로봇 주변의 상황 또는 로봇 주변에 배치된 작업 대상물에 대한 정확한 판단이 가능해야 하며, 이를 위해, 딥러닝 기반의 영상인식 기술(예를 들어, 로봇 비전(vision)기술)이 적극 활용되고 있다. 한편, 딥러닝 뿐만 아니라 머신러닝과 같은 인공지능 분야에서는, 보다 많은 양에 대한 데이터에 대해 학습을 수행함에 따라, 정확도가 높아지고, 보다 양질의 결과물을 도출하는 것이 가능하다. 따라서, 인공지능 분야에서 는, 학습의 대상이 되는 데이터를 수집하는 것이 필수적이다. 특히, 영상 데이터를 기반으로 한 딥러닝 네트워크 또는 머신러닝 네트워크는, 영상 데이터에 대응되는 물체의 위치 또는 자세를 추정할 수 있으며, 이러한 추정을 위해서는 영상 데이터와 함께, 물체의 자유도 정보(위치 정 보 및 자세 정보)가 학습 데이터로서 확보되어야 한다. 종래, 영상 데이터 및 이에 대응되는 자유도 정보를 학습 데이터로서 수집하기 위해서는, 영상 데이터에 대해 라벨링을 수행하고(예를 들어, 영상 데이터에서 물체에 대응되는 특정 이미지 객체를 식별시키기 위한 작업), 특정 이미지 객체와 자유도 정보를 일일이 매핑하는 수작업이 이루어져야 하므로, 학습 데이터를 확보하기 위한 엄청난 노동력이 필요했다. 예를 들어, 대한민국 등록특허 10-2010085호 에서는 수퍼픽셀을 이용한 미세조직의 라벨링 이미지 생성방법 및 생성장치를 개시하고 있으며, 이는 물체에 대응되는 특정 이미지 객체에 대한 라벨링을 간소화하기 위한 것에 불과하여, 특정 이미지 객체와 자유도 정보의 매핑을 위해서는 여전히 수작업이 필요하다. 이에, 물체의 자유도 정보를 포함한 학습 데이터를 자동화 방식으로 수집하는 방법에 대한 개선이 매우 절실한 상황이다."}
{"patent_id": "10-2020-0174295", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2020-0174295", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은, 인공지능 네트워크의 학습을 위한 학습 데이터를 수집하는 학습 데이터 수집 시스템 및 방법에 관한 것이다. 보다 구체적으로, 본 발명은, 자유도 정보를 포함하는 학습 데이터를 수집하는 학습 데이터 수집 시스템 및 방 법에 관한 것이다. 나아가, 본 발명은, 자유도 정보를 포함하는 학습 데이터를 자동으로 수집할 수 있는 학습 데이터 수집 시스템 및 방법에 관한 것이다. 더 나아가, 본 발명은 다양한 자세를 갖는 물체에 대한 학습 데이터를 수집하는 학습 데이터 수집 시스템 및 방 법에 관한 것이다. 나아가, 본 발명은 학습 데이터를 수집하는데 소요되는 시간 및 노동력을 최소화할 수 있는 학습 데이터 수집 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2020-0174295", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "위에서 살펴본 과제를 해결하기 위하여, 본 발명에 따른 학습 데이터 수집 방법은, 카메라를 통해, 자유도 센서 가 각각 구비된 복수의 대상물에 대한 초기 영상을 수신하는 단계, 상기 초기 영상에 포함된 상기 복수의 대상 물 각각에 대응되는 이미지 객체에 근거하여, 상기 복수의 대상물 마다 서로 다른 라벨(label)을 설정하는 단계, 상기 복수의 대상물 각각에 구비된 자유도 센서의 식별 정보와 상기 복수의 대상물 각각에 설정된 라벨을 일대일 매핑하는 단계, 상기 카메라를 통해 수신되는 후속 영상으로부터 상기 복수의 대상물을 추적하여, 상기 복수의 대상물 마다 설정된 라벨에 각각 대응되는 세그멘테이션 마스크(segmentation mask)를 추출하는 단계 및 상기 복수의 대상물 마다 설정된 라벨을 기준으로, 상기 세그멘테이션 마스크와 상기 자유도 센서로부터 센싱되 는 자유도 정보를 포함하는 학습 데이터를 수집하는 단계를 포함할 수 있다. 나아가, 본 발명에 따른 학습 데이터 수집 시스템은, 복수의 대상물에 각각 구비되어, 상기 복수의 대상물 각각 에 대한 자유도 정보를 센싱하는 센서들을 포함하는 센싱부, 상기 복수의 대상물을 촬영하도록 이루어지는 카메 라부, 상기 카메라로부터 수신된 초기 영상에 포함된 상기 복수의 대상물 각각에 대응되는 이미지 객체에 근거 하여, 상기 복수의 대상물 마다 서로 다른 라벨(label)을 설정하고, 상기 복수의 대상물 각각에 구비된 센서의 식별 정보와 상기 복수의 대상물 각각에 설정된 라벨을 일대일 매핑하는 제어부를 포함할 수 있다. 이러한 제어부는, 상기 카메라를 통해 수신되는 후속 영상으로부터 상기 복수의 대상물을 추적하여, 상기 복수 의 대상물 마다 설정된 라벨에 각각 대응되는 세그멘테이션 마스크(segmentation mask)를 추출하고, 상기 복수 의 대상물 마다 설정된 라벨을 기준으로, 상기 세그멘테이션 마스크와 상기 센서들로부터 수집되는 자유도 정보 를 학습 데이터로서 수집할 수 있다. 나아가, 본 발명에 따른, 전자기기에서 하나 이상의 프로세스에 의하여 실행되며, 컴퓨터로 판독될 수 있는 기 록매체에 저장 가능한 프로그램은, 카메라를 통해, 자유도 센서가 각각 구비된 복수의 대상물에 대한 초기 영상 을 수신하는 단계, 상기 초기 영상에 포함된 상기 복수의 대상물 각각에 대응되는 이미지 객체에 근거하여, 상 기 복수의 대상물 마다 서로 다른 라벨(label)을 설정하는 단계, 상기 복수의 대상물 각각에 구비된 자유도 센 서의 식별 정보와 상기 복수의 대상물 각각에 설정된 라벨을 일대일 매핑하는 단계, 상기 카메라를 통해 수신되 는 후속 영상으로부터 상기 복수의 대상물을 추적하여, 상기 복수의 대상물 마다 설정된 라벨에 각각 대응되는 세그멘테이션 마스크(segmentation mask)를 추출하는 단계 및 상기 복수의 대상물 마다 설정된 라벨을 기준으로, 상기 세그멘테이션 마스크와 상기 자유도 센서로부터 수집되는 자유도 정보를 학습 데이터로서 저장 하는 단계를 수행하도록 하는 명령어들을 포함할 수 있다."}
{"patent_id": "10-2020-0174295", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "위에서 살펴본 것과 같이, 본 발명에 따른 학습 데이터 수집 시스템 및 방법은, 학습의 대상이 되는 물체에 자 유도 정보 수집을 위한 센서를 구비하여, 물체에 대한 영상 데이터와 함께 물체의 자유도 정보를 함께 수집할 수 있다. 이때, 본 발명에서는 영상 데이터에서 물체 각각을 기준으로, 물체 각각에 대응되는 이미지 객체에 대 해 세그멘테이션(segmentation)을 수행할 수 있다. 나아가, 본 발명에서는 세그멘테이션된 마스크에 해당하는 마스크 라벨과 각각의 물체에 대한 자유도 정보를 매핑함으로써, 물체에 대해 영상을 촬영하는 것만으로도, 물 체에 대한 영상 데이터와 자유도 정보를 한번에 수집할 수 있다. 이를 통해, 본 발명에 의하면, 종래 물체에 대응되는 영상 데이터와 자유도 정보를 일일이 수작업으로 매핑함으로써 소모되었던 노동력과 시간을 절대적으로 줄일 수 있다. 나아가, 본 발명에 따른 학습 데이터 수집 시스템 및 방법은, 카메라의 화각 내에 복수의 물체를 둠으로써, 각 각의 이미지 프레임 마다 복수의 물체 각각에 대한 학습 데이터를 확보할 수 있다. 이와 같이, 본 발명에 의하 면, 여러 물체에 대해 학습 데이터를 수집하는데 소요되는 시간을 절대적으로 줄일 수 있다."}
{"patent_id": "10-2020-0174295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소에는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설 명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼 용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실 시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 발명은, 인공지능 네트워크의 학습을 위한 학습 데이터를 수집하는 학습 데이터 수집 시스템 및 방법에 관한 것으로서, 특히 자유도 정보를 포함하는 학습 데이터를 자동으로 수집할 수 있는 학습 데이터 수집 방법 및 시 스템에 대한 것이다. 앞서 살펴본 것과 같이, 인공지능의 발전에 힘입어 영상인식 기술은 다양한 산업분야에 활용되고 있다. 특히, 로봇 분야에서는, 인공지능 기반의 영상 인식 기술(예를 들어, 딥러닝 기반의 영상인식 기술)에 기반하여, 로봇 이 속한 작업 환경을 분석 및 이해하고, 이를 기반으로 로봇이 목표로 하는 작업을 수행하고 있다. 예를 들어, 도 1에 도시된 것과 같이, 로봇(R)에게 특정 작업(예를 들어, 설거지(dish-washing)이 주어진 경우, 로봇(R) 또는 로봇(R) 주변에 배치된 카메라(미도시됨)는 로봇(R)의 작업 환경에 해당하는 영상을 촬영할 수 있 다. 그리고, 로봇(R)의 제어부는, 촬영된 영상에 기반하여, 로봇(R)이 특정 작업을 수행하기 위하여, 어떻게 동 작해야 하는지에 대한 판단을 내리고, 판단에 따라 동작하도록 로봇(R)을 제어할 수 있다. 이 경우, 로봇(R)의 제어부는, 촬영된 영상에서 작업의 대상이 되는 대상물(A, 또는 객체(object), 예를 들어, 그릇(a1, a2))을 인식하고, 대상물(A)의 위치 및 자세(또는 포즈, pose)를 분석하여, 로봇(R)이 대상물에 대해목표로 하는 작업을 수행할 수 있도록 로봇(R)을 제어해야 한다. 이를 위하여, 로봇(R)의 제어부는, 촬영된 영상으로부터 다양한 정보를 수집하여야 하며, 예를 들어, i) 작업의 대상이 되는 대상물의 종류, ii) 작업의 대상이 되는 대상물의 크기, iii) 작업의 대상이 되는 대상물의 형상, iv) 작업의 대상이 되는 대상물의 위치(예를 들어, 도 1에 도시된 것과 같이, 그릇(a1)이 싱크대(sink) 의 어디 쯤에 놓여져 있는지 등), v) 작업의 대상이 되는 대상물의 자세(예를 들어, 도 1에 도시된 것과 같이, 그릇(a 1)이 싱크대에 놓여져 있는 자세(ex: 비스듬히 기울어져 있는지 등))에 대한 정보 중 복수의 정보를 이용하여, 로봇(R)을 정확하게 제어할 수 있다. 여기에서, 작업의 대상이 되는 대상물의 위치 및 자세는 “자유도” 또는 “자유도 정보”라고도 표현될 수 있 으며, 자유도 정보는 위치 정보 및 자세 정보를 포함한 개념으로 이해되어 질 수 있다. 이러한, 자유도 정보는, 3차원 위치(x, y, z)에 해당하는 위치 정보(또는 3차원 위치 정보) 및 3차원 자세(r(roll), θ(pitch), (yaw))에 해당하는 자세 정보(또는 3차원 자세 정보)를 포함할 수 있다. 한편, 로봇(R)이 작업의 대상이 되는 대상물에 대하여 정확하게 작업을 수행하기 위해서는 자유도 정보를 파악 하는 것이 매우 중요하다. 예를 들어, 로봇(R)의 제어부는 작업의 대상이 되는 대상물(a1, a2)을 잡기 위하여, 로봇 팔(R1, R2)을 어떤 각 도로 제어하고, 어떤 자세로 파지를 해야 하는지를 결정해야 하며, 이는 작업의 대상이 되는 대상물의 자세 및 위치 중 적어도 하나에 근거하여 결정되기 때문이다. 이때, 촬영된 영상으로부터 작업의 대상이 되는 대상물(예를 들어, a1, a2)이 인식된 것만으로, 대상물의 자유 도 정보까지 인지할 수 있다면, 작업의 정확도 뿐만 아니라, 작업의 효율을 확보할 수 있다. 이를 위하여, i)촬영된 영상에 포함된 대상물의 특정 형상에 대한 정보 및 ii)특정 형상일때 대상물이 어떤 위 치 또는 어떤 자세를 갖는지에 대한 정보가 상호 매칭된 학습 데이터가 활용될 수 있다. 한편, 로봇(R)이 정확한 작업을 수행하기 위해서는, 방대한 학습 데이터를 기반으로 학습된 인공지능 알고리즘 (예를 들어, 딥러닝 알고리즘 또는 딥러닝 네트워크)이 필요하다. 따라서, 본 발명에서는, 학습 데이터를 수집 하는 방법에 대하여 첨부된 도면과 함께 보다 구체적으로 살펴본다. 도 2는 본 발명에 따른 학습 데이터 수집 시스템을 설명하기 위한 개념도이고, 도 3은 본 발명에 따른 학습 데이터 수집 방법을 설명하기 위한 흐름도이 다. 나아가, 도 4, 도 5a, 도 5b, 도 6, 도 7, 도 8 및 도 9는 학습 데이터를 수집하는 방법을 설명하기 위한 개념도들이다. 본 발명에 대한 설명에 앞서, 본 명세서에서 언급되는 “대상물”은, 그 종류에 제한이 없으며, 매우 다양한 물 체로 해석되어 질 수 있다. 대상물은 시각적 또는 물리적으로 구분이 가능한 구체적인 형태를 가지고 있는 것으 로서, 물건 뿐만 아니라, 사람 또는 동물의 개념까지 포함하는 것으로 이해되어 질 수 있다. 도 2에 도시된 것과 같이, 본 발명에 따른 학습 데이터 수집 시스템은 카메라, 센싱부, 저장부 , 통신부 및 제어부 중 적어도 하나를 포함할 수 있다. 카메라는 영상을 촬영하기 위한 수단으로서, 본 발명에 따른 시스템 내에 포함되거나, 또는 별도로 구비될 수 있다. 본 발명에서 카메라는 “이미지 센서”라고도 명명될 수 있다. 카메라는 정적인 영상 및 동적인 영상 중 적어도 하나를 촬영하도록 이루어질 수 있으며, 단수 또는 복수 로 구비될 수 있다. 카메라는 대상물(또는 피사체)의 깊이 정보를 획득할 수 있는 3차원 깊이 카메라(3D depth camera) 또는 RGB-깊이 카메라(RGB-depth camera) 등으로 이루어질 수 있다. 카메라가 3차원 깊이 카메라로 이루어진 경 우, 촬영된 영상을 이루는 각 픽셀(pixel)의 깊이 값을 알 수 있으며, 이를 통하여 대상물의 깊이 정보가 획득 될 수 있다. 다음으로 센싱부는, 복수의 센서(120a, 120b, 120c)를 포함할 수 있다. 센싱부에 포함된 복수의 센서 (120a, 120b, 120c) 각각은 도 2에 도시된 것과 같이, 대상물(200, 201, 202, 203)에 각각 구비될 수 있다. 도 2에서는, 설명의 편의상, 제1, 제2 및 제3 대상물(201, 202, 203)에 대해서만 도면 부호를 부여하고, 이에 각각 구비된 제1, 제2 및 제3 센서(120a, 120b, 120c)에 대해서만 도면 부호를 부여하였다. 그러나, 도 2에 도 시된 것과 같이, 본 발명에 따른 설명은, 도 2에 도시된 대상물들(예를 들어, 도 2에 도시된 제1, 제2 및 제3대상물(201, 202, 203)을 포함한 9개의 물체를 포함)에 대해 동일하게 적용됨은 당업자에게 자명할 것이다. 한편, 센싱부는 대상물에 각각 구비되어, 대상물의 자유도 정보를 센싱할 수 있다. 도시와 같이, 제1 대상물에는 제1 센서(120a)가 구비되고, 제2 대상물에는 제2 센서(120b)가 구비되 며, 제3 대상물에는 제3 센서(120c)가 구비될 수 있다. 나아가, 도면부호를 부여하지 않은 다른 대상물에 도, 마찬가지로 각각 적어도 하나의 센서가 구비될 수 있다. 한편, 본 명세에서는 대상물 마다 1개의 센서(또는 자유도 센서)가 구비된 것으로 설명하나, 본 발명은 이에 한 정되지 않는다. 즉, 경우에 따라 대상물에는 복수의 센서가 구비되는 것 또한 가능하다. 본 발명에 의하면, 센싱부를 통해 대상물 각각의 3차원 위치(x, y, z)에 해당하는 위치 정보(또는 3 차원 위치 정보(병진 운동의 자유도에 해당함)) 및 3차원 자세(r(roll,롤), θ(pitch,피치), (yaw,요우))에 해당하는 자세 정보(또는 3차원 자세 정보(회전 운동의 자유도에 해당함))를 센싱할 수 있다. 여기에서, 센싱부는 자유도(Degree of Freedom) 센서 또는 DoF(Degree of Freedom) 센서라고도 명명될 수 있다. 센싱부는 IMU(Inertial Measurement Unit, 관성(慣性) 측정 장치)로 이루어질 수 있다. 다음으로, 저장부는 본 발명에 따른 다양한 정보를 저장하도록 이루어질 수 있다. 저장부의 종류는 매우 다양할 수 있으며, 적어도 일부는, 외부 서버(클라우드 서버 및 데이터베이스(database: DB) 중 적어도 하 나)를 의미할 수 있다. 즉, 저장부와 관련된 정보가 저장되는 공간이면 충분하며, 물리적인 공간에 대한 제약은 없는 것으로 이해될 수 있다. 저장부에는 i)본 발명에 따른 데이터 수집 시스템에 의해 수집된 학습 데이터, ii) 카메라를 통해 촬 영된 영상, iii) 영상에 포함된 대상물에 대응되는 이미지 객체의 세그멘테이션 마스크, iv) 세그멘테이션 마스 크의 라벨(label, 또는 라벨 정보), v) 센싱부를 통해 수집된 센싱 정보(예를 들어, 자유도 정보) 중 적어 도 하나가 저장될 수 있다. 다음으로, 통신부는 유선 또는 무선 통신 중 적어도 하나를 수행하도록 이루어질 수 있다. 통신부는 통신이 가능한 다양한 대상과 통신을 수행하도록 이루어질 수 있다. 예를 들어, 통신부는 카메라 및 센싱부 중 적어도 하나와 통신을 수행할 수 있다. 통신부는 카메라와의 통신을 통해, 카메라를 통해 촬영(또는 센싱)되는 영상을 수신할 수 있다. 나아가, 통신부는 센싱부와의 통신을 통해, 센싱부를 통해 수신되는 센싱 정보(예를 들어, 자유 도 정보)를 수신할 수 있다. 나아가, 통신부는 적어도 하나의 외부 서버와 통신하도록 이루어질 수 있다. 여기에서, 외부 서버는, 앞서 살펴본 것과 같이, 저장부의 적어도 일부의 구성에 해당하는 클라우드 서버 또는 데이터베이스 중 적어도 하나를 포함할 수 있다. 한편, 외부 서버에서는, 제어부의 적어도 일부의 역할을 수행하도록 구성될 수 있 다. 즉, 데이터 처리 또는 데이터 연산 등의 수행은 외부 서버에서 이루어지는 것이 가능하며, 본 발명에서는 이러한 방식에 대한 특별한 제한을 두지 않는다. 한편, 통신부는 통신하는 대상의 통신 규격에 따라 다양한 통신 방식을 지원할 수 있다. 예를 들어, 통신부는, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G(5th Generation Mobile Telecommunication ), 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra-Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 통신을 수행하도록 이루어질 수 있다. 다음으로 제어부는 본 발명과 관련된 학습 데이터 수집 시스템의 전반적인 동작을 제어하도록 이루어 질 수 있다. 제어부는 인공지능 알고리즘을 처리 가능한 프로세서(processor, 또는 인공지능 프로세서)를 포함할 수 있다. 제어부)는 딥러닝 알고리즘에 기반하여, 카메라를 통해 촬영되는 영상에서, 카메라 에 의해 촬영된 대상물을 인식 및 추적할 수 있다. 이러한 작업은 트래킹(tracking)이라고도 명명될 수 있다. 제어부는 카메라를 통해 복수의 대상물(201, 202, 203)이 촬영된 경우, 카메라를 통해촬영된 영상으로부터 복수의 대상물 각각을 인식하고, 각각의 대상물을 추적하는 것 또한 가능하다. 따라서, 제어부는 카메라를 통해 복수의 대상물(201, 202, 203)을 촬영하고 있는 상태에서, 복수의 대상물(201, 202, 203) 중 적어도 하나의 위치 및 자세가 변경되더라도, 복수의 대상물 각각을 실시간 또는 기 설정된 시간 간격으로 추적할 수 있다. 한편, 영상으로부터 대상물을 인식 및 추적하는 딥러닝 기법은 매우 다양하며, 본 발명에서는 이에 대한 특별한 한정을 두지 않는다. 이하에서는, 위에서 살펴본 본 발명에 따른 학습 데이터 수집 시스템의 구성에 기반하여, 학습 데이터를 수집하 는 방법에 대하여 보다 구체적으로 살펴본다. 먼저, 본 발명에 따른 학습 데이터 수집 방법에 의하면, 카메라를 통해 자유도 센서가 각각 구비된 대상물 에 대한 초기 영상을 수신하는 과정이 진행될 수 있다(S310). 보다 구체적으로, 초기 영상을 획득하는 S310 과정에서는, 도 4의 (a)에 도시된 것과 같이, 카메라를 통해 복수의 대상물(201, 202, 203)에 대한 촬영을 수행할 수 있다. 본 발명에서, 대상물은 카메라에 의해 촬영 의 대상이 되는 물체로서, “피사체”라고도 명명될 수 있다. 한편, 본 명세서에서는, 발명의 설명을 위하여, 카메라에 의해 촬영되는 영상을 “초기 영상” 및 “후속 영상 ”으로 구분하여 설명한다. 본 발명에서 “초기 영상”은 후속에서 설명될 대상물에 대한 라벨링을 수행하는데 활용되는 영상으로서, 반드 시 최초로 수신된 영상을 의미하지 않는다. 즉, 초기 영상은 영상에 포함된 이미지 객체(촬영의 대상이 된 대상 물에 대응되는 이미지를 의미함)에 근거하여, 본 발명에 따른 학습 데이터를 수집하기 위한 설정(세팅)을 하기 위한 대상이 될 수 있다. 나아가, “후속 영상”은 학습 데이터가 직접적으로 수집되는 대상이 되는 영상으로서, 초기 영상이 수신된 이 후에 수신되는 영상을 의미할 수 있다. 제어부는 후속 영상에 포함된 이미지 객체 및 대상물에 구비된 센 서(또는 자유도 센서)를 이용하여, 대상물에 대한 학습 데이터를 수집할 수 있다. 본 발명에서, 초기 영상 및 후속 영상은 정적인 영상 및 동적인 영상 중 적어도 하나일 수 있다. 나아가, 초기 영상 및 후속 영상은 복수의 영상(또는 프레임(frame)인 것 또한 가능하다. 도 4의 (b)에 도시된 것과 같이, 카메라를 통해 대상물에 대한 초기 영상이 수신되면, 본 발명 에서는 초기 영상에서 복수의 대상물에 대한 라벨링을 수행하는 과정이 진행될 수 있다(S320). 본 발명에서 복수의 대상물에 대한 라벨링을 수행하는 과정에서는, 후속 영상에서, i)복수의 대상물 각각을 추적(또는 트래킹)하기 위한 설정, ii) 복수의 대상물 각각에 구비된 센서와 복수의 대상물 각각에 대한 단위 영역을 일대일 매핑하기 위한 설정, iii)복수의 대상물 각각에 대한 세그멘테이션 마스 크(segmentation mask)를 추출하기 위한 설정, iv) 복수의 대상물 각각에 구비된 센서와 복수의 대상물 각각에 대한 세그멘테이션 마스크를 일대일 매핑하기 위한 설정 등이 이루어질 수 있다. 먼저, 본 발명에서 복수의 대상물 각각을 추적하기 위한 설정은, 복수의 대상물의 자세 및 위치가 변경되 더라도, 후속 영상으로부터 복수의 대상물 각각을 인식시키기 위한 설정을 의미할 수 있다. 이를 위하여, 본 발명에서는, 도 4의 (b)에 도시된 것과 같이, 딥러닝 알고리즘에 기반하여, 상기 후속 영상으 로부터 복수의 대상물에 대한 추적이 가능하도록, 초기 영상에서 상기 복수의 대상물 각각에 대 응되는 이미지 객체의 초기 위치를 특정하기 위한 단위 영역(200a)이 지정될 수 있다. 본 발명에서 단위 영역(200a)은 “박스(box)” 또는 “바운딩 박스(bounding box)”라고도 명명될 수 있다. 제어부는, 도 4의 (b)에 도시된 것과 같이, 상기 복수의 대상물 각각에 대응되는 이미지 객체가 단위 영역(200a) 내에 포함되도록, 이미지 객체의 초기 위치를 특정할 수 있다. 즉, 단위 영역(200a)은, 초기 영상에서 복수의 대상물 각각에 대응되는 이미지 객체 마다 각각 특정될 수 있다. 제어부는 사용자 또는 작업자의 선택에 근거하여, 이미지 객체가 위치하는 영역을 단위 영역(200a)으 로서 설정할 수 있다. 나아가, 제어부는 영상 인식 알고리즘에 근거하여, 초기 영상에 포함된 이미지 객체를 인식하고, 각각의 이미지 객체들(401, 402, 403)에 대해 단위 영역(201a, 202a, 203a)을 설정할수 있다. 따라서, 각각의 단위 영역(200a)에는, 복수의 대상물 각각에 대응되는 이미지 객체 중 상기 각각의 단위 영역(200a)에 대응되는 어느 하나의 이미지 객체가 포함된 될 수 있다. 예를 들어, 도 4의 (b)에 도시된 것과 같이, 제1 단위 영역(201a)에는 제1 대상물에 대응되는 제1 이미지 객체가 포함되고, 제2 단위 영역(202a)에는 제2 대상물에 대응되는 제2 이미지 객체가 포함될 수 있다. 그리고, 제3 단위 영역(203a)에는 제3 대상물에 대응되는 제3 이미지 객체가 포함될 수 있 다. 이 경우, 각각의 이미지 객체는 단위 영역(200a) 내에 완전히 포함되지 않아도 되며, 적어도 일부만 포함되는 것 또한 가능하다. 한편, 본 발명에서, 단위 영역(200a)의 형상은 사각형으로 묘사되었으나, 이에 특별한 한정을 두지 않는다. 예 를 들어, 단위 영역(200a)은 이미지 객체의 형상을 따라, 이미지 객체의 가장자리에 설정될 수 있다. 이와 같이, 이미지 객체 각각에 대해 단위 영역(200a)이 설정되면, 각각의 단위 영역(200a)에는, 서로 다 른 라벨이 설정될 수 있다. 단위 영역(200a)마다 라벨이 설정된다고 함은, 복수의 대상물 마다 라벨이 설정되는 것과 동일 또는 유사 한 의미로 이해되어 질 수 있다. 이는, 복수의 대상물 각각을 기준으로, 단위 영역(200a)이 각각 설정되기 때문이다. 도 5a에 도시된 것과 같이, 단위 영역(200a) 각각에는, 복수의 대상물을 기준으로, 서로 다른 라벨이 설정 될 수 있다(도 5a, 도 5b, 도 6, 도 8은 설명의 편의상 라벨(예를 들어, BOX_01, BOX_02, ID_01, ID_02)을 도 시하였다, 이러한 도시는 설명의 편의를 위한 것일 뿐, 실제 획득되는 데이터에는 위의 라벨을 표시한 이미지가 존재하지 않을 수 있음은 당업자에게 자명하다). 제어부는 도 5a에 도시된 것과 같이, 복수의 대상물에 대응되는 이미지 객체를 각각 포함한 단 위 영역(200a)에 대해 서로 다른 라벨을 설정할 수 있다. 여기에서, 라벨(label)은 “식별정보” 라고도 이해되 어 질 수 있다. 즉, 라벨은 각각의 단위 영역을 구분하기 위한 식별 정보로서, 서로 다른 단위 영역은 서로 다 른 라벨, 즉 식별 정보를 갖는다. 제어부는 각각의 단위 영역(200a)을 기준으로, 각각의 단위 영역(200a)에 포함된 이미지 객체에 대응 되는 대상물을 추적할 수 있다. 따라서, 각각의 대상물을 추적하기 위해서는, 각각의 대상물을 구분하는 것이 필수적이며, 제어부는 단위 영역(200a)을 기준으로 추적의 대상이 되는 대상물 인식하고, 추적할 수 있다. 따라서, 도 5a에 도시된 것과 같이, 제1 대상물에 대응되는 제1 이미지 객체가 포함된 단위 영역(201a)에 는 제1 라벨이 설정 또는 특정될 수 있다. 마찬가지로, 다른 단위 영역들에도, 각각 서로 다른 라벨이 설 정 또는 특정될 수 있다. 한편, S320과정에 서와 같이, 각각의 단위 영역(200a)에 대한 라벨링이 수행되면, 본 발명에서는 복수의 대상물 각각에 구비된 자유도 센서의 식별 정보와 복수의 대상물 각각에 설정된 라벨을 일대일 매핑하는 과정이 진행될 수 있다(S330). 즉, 본 발명에서는, 본 발명에서는 복수의 대상물 각각에 구비된 자유도 센서의 식별 정보와 단위 영역에 설정 된 라벨을 일대일 매핑(mapping)하는 과정이 진행될 수 있다. 이러한 일대일 매핑은 복수의 대상물을 기준으로 이루어진다. 즉, 어느 단위 영역에 어느 자유도 센서(또는 센 서)의 식별 정보를 일대일 매핑할 것인지 여부는, 복수의 대상물 각각을 기준으로 이루어질 수 있다. 예를 들어, 도 2, 도 4 및 도 5b에 도시된 것과 같이, 제1 대상물에 제1 자유도 센서(120a)가 구비된 경우, 제1 대상물에 대응되는 제1 이미지 객체(200a)가 포함된 제1 단위 영역(201a)에는, 제1 자유도 센서 (120a)의 식별 정보(502, 예를 들어, “ID_01”)가 매핑될 수 있다. 따라서, 제1 단위 영역(201a)에 대응되는 제1 라벨(501, 예를 들어, “BOX_01”)에는 제1 자유도 센서(120a)의 식별 정보(502, 예를 들어, “ID_01”)가 매핑될 수 있다. 마찬가지로, 제2 단위 영역(202a)에 대응되는 제2 라벨(예를 들어, “BOX_02”)에는 제2 자유도 센서(120b)의 식별 정보(예를 들어, “ID_02”)가 매핑될 수 있다. 이와 같은 방법으로, 촬영의 대상이 되는 다른 대상물에 대해서도, 다른 대상물에 각각 구비된 자유도 센서의 식별정보와, 다른 대상물 각각에 대응되는 단위 영역의 식별 정보가 각각 매핑될 수 있다. 따라서, 도 7에 도시된 것과 같이, 제어부는 복수의 대상물 각각에 대응되는 단위 영역의 라벨 (BOX_ID)과, 자유도 센서의 식별 정보(센서 ID)가 상호 매핑된(또는 매칭된) 정보를 수집할 수 있다. 이러한 매 핑 정보는 저장부에 저장될 수 있다. 이를 통해, 대상물의 위치 또는 자세가 변경되더라도, 단위 영역을 기준으로 대상물을 추적하고, 이에 대한 자유도 정보가 수집될 수 있다. 한편, 단위 영역의 라벨과, 자유도 센서의 식별정보의 매핑은 제어부의 제어 하에 이루어질 수 있다. 제어 부는 단위 영역이 지정된 순서에 따라, 자유도 센서의 식별정보를 순차적으로 매핑할 수 있다. 예를 들어, 제어부는 제1 번째 지정된 단위 영역의 라벨(예를 들어, ID_01)에, 복수의 자유도 센서 중 제1 번째 식별 정보(ID_01)를 갖는 제1 자유도 센서의 식별 정보(ID_01)를 매핑할 수 있다. 그리고, 제어부는 제2 번째 지정된 단위 영역의 라벨(예를 들어, ID_02)에, 복수의 자유도 센서 중 제2 번째 식별 정보를 갖는 제2 자유도 센서의 식별 정보(ID_02)를 매핑할 수 있다. 자유도 센서의 식별 정보의 순서는 오름 차순 또는 내림 차순에 근 거할 수 있다. 한편, 본 발명에서 제어부는, 도 6의 (a) 및 (b)에 도시된 것과 같이, 각각의 단위 영역(200a)에 포함된 이미지 객체에 대한 세그멘테이션(segmentation)을 수행하여, 각각의 단위 영역(200a)에 포함된 이미지 객체 마 다의 세그멘테이션 마스크(segmentation mask 또는 세그멘테이션된 마스크, 300)를 추출할 수 있다. 본 발명에서 세그멘테이션은, 영상에서 대상물을 기준으로 이미지 객체를 인식 및 추출하는 작업으로서, 제어부 는 서로 다른 대상물에 각각 대응되는 서로 다른 이미지 객체를 별개의 종류 또는 클래스(class)로 인식하 는 인스턴스(instance segmentation)을 수행할 수 있다. 예를 들어, 도 6에 도시된 것과 같이, 초기 영상에 대해 세그멘테이션이 수행되는 경우, 제어부는 이 미지 객체 각각을 별개의 의미 있는 주체로서 인식하고, 각각의 이미지 객체를 기준으로 세그멘테이션 마스크 를 생성할 수 있다. 즉, 제어부는, 단위 영역에 포함된 이미지 객체를 기준으로, 대상물 각각을 인식 및 추적하며, 단위 영역 내에 포함된 이미지 객체에 대한 세그멘테이션 마스크를 생성 및 추출하여, 대상물 각각에 대한 형상 정보를 확 보할 수 있다. 따라서, 제어부는 초기 영상에서 제1 단위 영역(201a)에 포함된 제1 대상물에 대응되는 제1 이 미지 객체에 대한 제1 세그멘테이션 마스크를 추출할 수 있다. 그리고, 제어부는 제2 단위 영역 (202a)에 포함된 제2 대상물에 대응되는 제2 이미지 객체에 대한 제2 세그멘테이션 마스크를 추 출할 수 있다. 이와 같은 방식으로 제어부는 모든 대상물에 대해 각각 대응되는 세그멘테이션 마스크를 추 출할 수 있다. 한편, 추출된 세그멘테이션 마스크 각각은 서로 다른 라벨(또는 마스크 라벨)을 가질 수 있다. 이때, 세그멘테 이션 마스크의 라벨은, 상기 각각의 단위 영역에 설정된 라벨에 근거하여 결정될 수 있다. 제어부는 단위 영역의 라벨과 세그멘테이션 마스크의 라벨을 동일하거나, 서로 대응되도록 설정할 수 있다. 예를 들어, 도 7에 도시된 것과 같이, 제1 단위 영역의 라벨이 BOX_01인 경우, 제1 단위 영역에 포함된 이미지 객체에 대응되는 제1 세그멘테이션 마스크의 라벨 역시 BOX_01일 수 있다. 제어부는 도 7에 도시된 것과 같이, 각각의 대상물을 기준으로, 단위 영역, 자유도 센서, 세그멘테이션 마 스크를 서로 매핑할 수 있다. 따라서, 도 7에 도시된 것과 같이, i)제1 대상물에 구비된 제1 자유도 센서 (120a)의 식별 정보(ID_01), ii)제1 대상물에 대응되는 제1 이미지 객체가 포함된 제1 단위 영역 (201a)의 라벨(BOX_01), iii)제1 대상물에 대응되는 제1 이미지 객체의 제1 세그멘테이션 마스크 , iv)제1 대상물에 대응되는 제1 이미지 객체의 제1 세그멘테이션 마스크의 라벨(단위 영 역의 라벨과 동일 또는 유사할 수 있음)이 상호 매핑되어, 매핑 정보가 저장부에 저장될 수 있다. 위에서 살펴본 매핑은, 모든 대상물에 대하여 동일하게 이루어질 수 있다. 따라서, 제어부는 후속 영상에 서 대상물의 위치 또는 자세가 변경되더라도, 대상물에 대한 추적이 가능하며, 그에 따른 세그멘테이션 마스크 및 물체의 자유도 정보를 학습 데이터로서 수집할 수 있다. 즉, 세그멘테이션의 추출은 후속 영상에서도 연속적으로 이루어질 수 있다. 제어부는 후속 영상에서 단위 영역을 기준으로 각각의 대상물을 추적하고, 각각의 단위 영역에 포함된 이미지 객체를, 추적된 대상물에 대한세그멘테이션 마스크로서 수집할 수 있다. 한편, 제어부는, 단위 영역을 기준으로 실시간 또는 기 설정된 간격으로 대상물을 추출하고, 추적이되는 현재 시점 이전의 대상물에 대한 위치 및 세그멘테이션 마스크에 대한 정보를 가지고 있다. 따라서, 제어부는 특정 대상물이 다른 대상물에 가려져 임의의 시점에 후속 영상에서 특정 대상물에 대한 이미지 객체가 존재하지 않더라도, 가려짐이 제거되어 다시 후속 영상에서 특정 대상물에 대한 이미지 객체가 나타난 경우, 연속적으로 특정 대상물에 대한 추적을 진행할 수 있다. 한편, 제어부는, 도 7에 도시된 것과 같이, 대상물에 구비된 자유도 센서로부터 자유도 정보를 수집할 수 있다. 이러한 자유도 정보는, 대상물의 3차원 위치 정보 및 3차원 자세 정보 중 적어도 하나를 포함할 수 있다. 나아가, 수집된 자유도 정보는, 각각의 자유도 센서의 식별 정보에 매핑된 단위 영역의 라벨과 매핑하여 저장되 므로, 제어부는 대상물에 대한 자유도 정보를 세그멘테이션 마스크와 함께 획득할 수 있다. 예를 들어, 제 1 자유도 센서로부터 수집된 자유도 정보(또는 센싱 정보)는, 제1 자유도 센서의 식별 정보(ID_01)와 매핑된 제 1 단위 영역의 라벨(BOX_01) 및 제1 세그멘테이션 마스크와 매핑될 수 있다. 한편, 도 7에 도시된 것과 같이, 자유도 센서로부터 수신되는 센싱 정보(또는 자유도 정보)는, 자유도 센서의 식별 정보(센서_ID)와 매핑된 통신 포트(PORT)로부터 수신되면, 이러한 통신 포트에 대한 식별 정보(PORT ID) 역시, 자유도 센서의 식별 정보(센서_ID)와 매핑될 수 있다. 따라서, 제어부는 통신 포트를 통해 수신되는 자유도 정보를, 각각의 통신 포트에 매핑된 자유도 센서의 식별 정보에 매핑되도록 저장할 수 있다. 도 7에 도시된 것과 같이, 초기 영상을 이용하여, 단위 영역의 라벨, 자유도 센서의 식별 정보, 통신 포트, 대 상물의 초기 위치 정보 및 자세 정보 및 세그멘테이션 마스크, 세그멘테이션 마스크의 라벨 중 적어도 두개 간 의 일대일 매핑이 완료되면, 학습 데이터 수집을 위한 설정이 완료될 수 있다. 이러한 설정이 완료된 경우, 제어부는 후속 영상으로부터, 각각의 대상물을 기준으로 대상물을 추적하고, 추적된 대상물에 대한 세그멘테이션 마스크를 추출하며, 나아가, 추적된 대상물에 대한 자유도 정보를 수집할 수 있다. 그리고, 후속 영상에서 추출된 세그멘테이션 마스크와, 대상물의 자유도 정보는 상호 매핑될 수 있다. 따라서, 대상물의 위치 및 자세가 변경되는 경우라도, 제어부는 대상물을 기준으로, 대상물의 변경된 자세 에 대한 세그멘테이션 마스크를 추출하고, 이때의 대상물의 자유도 정보를 수집할 수 있다. 따라서, 제어부 는 다양한 자세를 갖는 대상물에 대한 학습 데이터를 수집할 수 있다. 보다 구체적으로 본 발명에서는, 후속 영상에, 복수의 대상물에 대한 세그멘테이션을 수행하고(S340), 자유도 센서(또는 센서)로부터 수집(또는 수신)되는 자유도 정보(또는 센싱 정보)와 세그멘테이션 수행의 결과 추출된 세그멘테이션 마스크를 학습데이터로서 저장하는 과정을 수행할 수 있다(S350). 제어부는 도 8의 (a)에 도시된 것과 같이, 카메라를 통해 수신되는 후속 영상으로부터 상기 복수의 대상물을 추적하여, 도 8의 (b)에 도시된 것과 같이, 상기 복수의 대상물마다 설정된 라벨(예를 들어, 단위 영의 라벨 또는 세그멘테이션 마스크의 라벨)에 각각 대응되는 세그멘테이션 마스크(segmentation mask, 300a)를 추출할 수 있다. 후속 영상에서 추출되는 세그멘테이션 마스크의 라벨은, 초기 영상에서 설정된 세그멘테이션 마스크의 라벨과 동일하다. 이 경우, 세그멘테이션 마스크의 라벨은 단위 영역은 라벨과 동일 또는 유사할 수 있다. 제어부는 복수의 대상물 마다 설정된 라벨을 기준으로, 도 9에 도시된 것과 같이, 각각의 대상물에 대응되 는 세그멘테이션 마스크(300a)와 자유도 센서로부터 센싱되는 자유도 정보(도 9의 “자유도”항목 참조)를 포함 하는 학습 데이터를 수집할 수 있다. 제어부는, 각각의 세그멘테이션 마스크가 추출된 프레임이 촬영된 시점과 대응되는 시점에 자유도 센서로 부터 센싱된 자유도 정보를, 각각의 세그멘테이션 마스크와 매칭하여 저장할 수 있다. 후속 영상이 동영상인 경우, 자유도 센서의 센싱 주파수(Hz)는 동영상의 FPS(Frame Per Second)와 대응될 수 있 다. 즉, 30FPS를 갖는 동영상의 경우, 자유도 센서의 센싱 주파수 역시 30Hz로 구성될 수 있으며, 이 경우, 각 각의 프레임이 촬영되는 시점은 자유도 센서에서 물체의 자유도 정보가 센싱되는 시점과 일치할 수 있다. 한편, 본 발명에서 후속 영상은 초(second) 당 기 설정된 수의 프레임(frame)을 포함하는 동영상으로 이루어지 거나, 기 설정된 시간 간격으로 촬영되는 복수의 영상을 포함할 수 있다. 이러한 복수의 영상은 프레임으로 명 명될 수 있다. 제어부는, 후속 영상에 포함된 프레임 모두에 대해 세그멘테이션 마스크를 추출하여 학습 데이터를 생성하 거나, 또는 후속 영상을 구성하는 복수의 프레임 중 기 설정된 간격(또는 시간 간격) 마다 상기 복수의 대상물 에 각각 대응되는 세그멘테이션 마스크를 추출하여 학습 데이터를 생성하는 것 또한 가능하다. 따라서, 제어부는 i)기 설정된 간격 또는 매 프레임 마다 복수의 대상물 중 제1 대상물에 대응 되는 제1 세그멘테이션 마스크(301a)와, 제2 대상물에 대응되는 제2 세그멘테이션 마스크(302a)를 추출하 고, ii)상기 제1 대상물에 구비된 제1 자유도 센서(ID_01)로부터 수집된 제1 자유도 정보와 상기 제1 세그멘테 이션 마스크(301a)를 매칭하여 상기 제1 대상물에 대한 학습 데이터로서 저장하고, iii)상기 제2 대상물 에 구비된 제2 자유도 센서(ID_02)로부터 수집된 제2 자유도 정보와 상기 제2 세그멘테이션 마스크(302a) 를 매칭하여 상기 제2 대상물에 대한 학습 데이터로서 저장할 수 있다. 이는, 초기 영상에서 복수의 대상물에 대한 동시 추적 및 세그멘테이션 마스크의 추출이 가능하도록, 복수의 대 상물 각각에 대해 단위 영역을 설정하였기 때문에 가능하다. 이와 같이, 제어부는 후속 영상에서 도 9에 도시된 것과 같이, 후속 영상에서 각각의 대상물에 대한 세그 멘테이션 마스크를 추출하고, 해당 세그멘테이션 마스크를 가질 때의 대상물의 자유도 정보를 상호 매칭하여 저 장함으로써, 복수의 대상물에 대한 방대한 양의 학습 데이터를 효율적으로 수집할 수 있다. 나아가, 본 발명에서는, 복수의 대상물 중 적어도 하나에 대하여 외력을 가함으로써(예를 들어, 복수의 대상물 의 자세 및 위치 중 적어도 하나를 의도적으로 변경하기 위한 외력(예를 들어, 복수의 대상물을 섞기 위한 동작 등)), 의도적으로 복수의 대상물 각각에 대해 서로 다른 형상을 갖는 세그멘테이션 마스크 및 이에 따른 자유도 정보를 학습 데이터로서 수집할 수 있다. 한편, 본 발명에 따른 제어부는 복수의 대상물 각각에 대한 세그멘테이션 마스크 및 이에 대한 자유도 정 보만을 상호 매칭하여 저장하는 것 뿐만 아니라, 각각의 대상물 주변에 배치된 다른 대상물(예를 들어, 인접하 거나, 중첩된 대상물 등)에 대한 세그멘테이션 마스크 및 자유도 정보를 함께 저장하여, 복수의 대상물 간의 상 호 위치관계에 대한 정보까지 학습 데이터로서 확보하도록 할 수 있다. 예를 들어, 제어부는 도 8의 (a)에 도시된 것과 같이, 제2 대상물에 대한 세그멘테이션 마스크(302a) 및 자유도 정보와 함께, 제2 대상물 주변에 배치된 제1 및 제3 대상물(411, 413)에 해당하는 세그멘테이션 마스크(301a, 303a) 및 자유도 정보를, 제2 대상물에 대한 학습 데이터로서 포함시킬 수 있다. 나아가, 제어부는 특정 대상물이 다른 대상물에 가려져 있는 경우, 이에 대한 정보 역시 학습 데이터로서 함께 저장할 수 있다. 이를 통하여, 본 발명에서는 주변 상황까지 고려할 수 있는 대상물에 대한 학습 데이터를 확보할 수 있다. 위에서 살펴본 것과 같이, 본 발명에 따른 학습 데이터 수집 시스템 및 방법은, 학습의 대상이 되는 물체에 자 유도 정보 수집을 위한 센서를 구비하여, 물체에 대한 영상 데이터와 함께 물체의 자유도 정보를 함께 수집할 수 있다. 이때, 본 발명에서는 영상 데이터에서 물체 각각을 기준으로, 물체 각각에 대응되는 이미지 객체에 대 해 세그멘테이션(segmentation)을 수행할 수 있다. 나아가, 본 발명에서는 세그멘테이션된 마스크에 해당하는 마스크 라벨과 각각의 물체에 대한 자유도 정보를 매핑함으로써, 물체에 대해 영상을 촬영하는 것만으로도, 물 체에 대한 영상 데이터와 자유도 정보를 한번에 수집할 수 있다. 이를 통해, 본 발명에 의하면, 종래 물체에 대 응되는 영상 데이터와 자유도 정보를 일일이 수작업으로 매핑함으로써 소모되었던 노동력과 시간을 절대적으로 줄일 수 있다. 나아가, 본 발명에 따른 학습 데이터 수집 시스템 및 방법은, 카메라의 화각 내에 복수의 물체를 둠으로써, 각 각의 이미지 프레임 마다 복수의 물체 각각에 대한 학습 데이터를 확보할 수 있다. 이와 같이, 본 발명에 의하 면, 여러 물체에 대해 학습 데이터를 수집하는데 소요되는 시간을 절대적으로 줄일 수 있다. 한편, 위에서 살펴본 본 발명은, 컴퓨터에서 하나 이상의 프로세스에 의하여 실행되며, 이러한 컴퓨터로 판독될 수 있는 매체(또는 기록 매체)에 저장 가능한 프로그램으로서 구현될 수 있다. 나아가, 위에서 살펴본 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드 또는 명령어로서 구 현하는 것이 가능하다. 즉, 본 발명은 프로그램의 형태로 제공될 수 있다. 한편, 컴퓨터가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 나아가, 컴퓨터가 읽을 수 있는 매체는, 저장소를 포함하며 전자기기가 통신을 통하여 접근할 수 있는 서버 또 는 클라우드 저장소일 수 있다. 이 경우, 컴퓨터는 유선 또는 무선 통신을 통하여, 서버 또는 클라우드 저장소 로부터 본 발명에 따른 프로그램을 다운로드 받을 수 있다. 나아가, 본 발명에서는 위에서 설명한 컴퓨터는 프로세서, 즉 CPU(Central Processing Unit, 중앙처리장치)가 탑재된 전자기기로서, 그 종류에 대하여 특별한 한정을 두지 않는다. 한편, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2020-0174295", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따라 수집된 학습 데이터가 활용되는 예를 설명하기 위한 개념도이다. 도 2는 본 발명에 따른 학습 데이터 수집 시스템을 설명하기 위한 개념도이다. 도 3은 본 발명에 따른 학습 데이터 수집 방법을 설명하기 위한 흐름도이다. 도 4, 도 5a, 도 5b, 도 6, 도 7, 도 8 및 도 9는 학습 데이터를 수집하는 방법을 설명하기 위한 개념도들이다."}
