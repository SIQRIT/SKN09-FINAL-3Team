{"patent_id": "10-2022-0076352", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0175007", "출원번호": "10-2022-0076352", "발명의 명칭": "적대적 학습 시스템 및 적대적 학습 방법", "출원인": "숭실대학교산학협력단", "발명자": "최대선"}}
{"patent_id": "10-2022-0076352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학습용 원본 이미지 및 상기 학습용 원본 이미지에 노이즈가 추가되어 생성된 학습용 적대적 변형 이미지를 수신하도록 구성되는 이미지 수신부;딥러닝 모델을 이용하여 상기 학습용 원본 이미지로부터 원본 이미지 특징을 추출하고, 상기 학습용 적대적 변형 이미지로부터 적대적 변형 이미지 특징을 추출하도록 구성되는 이미지 특징 추출부;상기 원본 이미지 특징 및 상기 적대적 변형 이미지 특징을 기초로 상기 딥러닝 모델을 학습하도록 구성되는 기계학습부를 포함하는 적대적 학습 시스템."}
{"patent_id": "10-2022-0076352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 딥러닝 모델을 이용하여 상기 원본 이미지 특징을 기초로 상기 학습용 원본 이미지에 대한 라벨 값을 생성하고, 상기 적대적 변형 이미지 특징을 기초로 상기 학습용 적대적 변형 이미지에 대한 라벨 값을 생성하도록구성되는 라벨 분류부를 더 포함하고,상기 기계학습부는,상기 원본 이미지 특징, 상기 적대적 변형 이미지 특징, 상기 학습용 원본 이미지의 라벨 값 및 상기 학습용 적대적 변형 이미지의 라벨 값을 기초로 상기 딥러닝 모델을 학습하도록 구성되는, 적대적 학습 시스템."}
{"patent_id": "10-2022-0076352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 기계학습부는:상기 원본 이미지 특징 및 상기 적대적 변형 이미지 특징을 기초로 제1 손실 함수를 연산하고;상기 학습용 원본 이미지의 라벨 값 및 상기 학습용 원본 이미지의 정답 라벨 값을 기초로 제2 손실 함수를 연산하고; 그리고상기 학습용 적대적 변형 이미지의 라벨 값 및 상기 학습용 적대적 변형 이미지의 정답 라벨 값을 기초로 제3손실 함수를 연산하도록 구성되는, 적대적 학습 시스템."}
{"patent_id": "10-2022-0076352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 기계학습부는,상기 제1 손실 함수, 상기 제2 손실 함수 및 상기 제3 손실 함수를 기초로 제4 손실 함수를 연산하고; 그리고상기 제4 손실 함수가 감소하게 상기 딥러닝 모델을 학습하도록 구성되는, 적대적 학습 시스템."}
{"patent_id": "10-2022-0076352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 기계학습부는,상기 제1 손실 함수에 미리 설정된 상수가 곱해진 값에 상기 제2 손실 함수 및 상기 제3 손실 함수를 합해서 상기 제4 손실 함수를 연산하도록 구성되는, 적대적 학습 시스템."}
{"patent_id": "10-2022-0076352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0175007-3-제3항에 있어서,상기 기계학습부는,상기 원본 이미지 특징 및 상기 적대적 변형 이미지 특징의 차이를 나타내는 값을 상기 제1 손실 함수로 연산하고;상기 제1 손실 함수가 학습이 반복하면서 감소하게 상기 딥러닝 모델을 학습하도록 구성되는, 적대적 학습 시스템."}
{"patent_id": "10-2022-0076352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 이미지 수신부는,검사 대상 이미지를 수신하도록 구성되고,상기 이미지 특징 추출부는,상기 딥러닝 모델을 이용하여 상기 검사 대상 이미지로부터 검사 대상 이미지 특징을 추출하도록 구성되고,상기 라벨 분류부는,상기 딥러닝 모델을 이용하여 상기 검사 대상 이미지 특징을 기초로 상기 검사 대상 이미지에 대한 라벨 값을생성하도록 구성되는, 적대적 학습 시스템."}
{"patent_id": "10-2022-0076352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "적대적 학습 시스템의 동작방법으로서,학습용 원본 이미지 및 상기 학습용 원본 이미지에 노이즈가 추가되어 생성된 학습용 적대적 변형 이미지를 수신하는 단계;딥러닝 모델을 이용하여 상기 학습용 원본 이미지로부터 원본 이미지 특징을 추출하고, 상기 학습용 적대적 변형 이미지로부터 적대적 변형 이미지 특징을 추출하는 단계;상기 딥러닝 모델을 이용하여 상기 원본 이미지 특징을 기초로 상기 학습용 원본 이미지에 대한 라벨 값을 생성하고, 상기 적대적 변형 이미지 특징을 기초로 상기 학습용 적대적 변형 이미지에 대한 라벨 값을 생성하는 단계; 및상기 원본 이미지 특징, 상기 적대적 변형 이미지 특징, 상기 학습용 원본 이미지의 라벨 값 및 상기 학습용 적대적 변형 이미지의 라벨 값을 기초로 상기 딥러닝 모델을 학습하는 단계를 포함하는, 적대적 학습 방법."}
{"patent_id": "10-2022-0076352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 딥러닝 모델을 학습하는 단계는:상기 원본 이미지 특징 및 상기 적대적 변형 이미지 특징을 기초로 제1 손실 함수를 연산하는 단계;상기 학습용 원본 이미지의 라벨 값 및 상기 학습용 원본 이미지의 정답 라벨 값을 기초로 제2 손실 함수를 연산하는 단계;상기 학습용 적대적 변형 이미지의 라벨 값 및 상기 학습용 적대적 변형 이미지의 정답 라벨 값을 기초로 제3손실 함수를 연산하는 단계;상기 제1 손실 함수, 상기 제2 손실 함수 및 상기 제3 손실 함수를 기초로 제4 손실 함수를 연산하는 단계; 및상기 제4 손실 함수가 감소하게 상기 딥러닝 모델을 학습하는 단계를 포함하는, 적대적 학습 방법."}
{"patent_id": "10-2022-0076352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항 및 제9항 중 어느 한 항의 적대적 학습 방법을 실행시키도록 컴퓨터로 판독 가능한 비일시적 기록매체에공개특허 10-2023-0175007-4-저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "개시된 발명의 일 측면에 따른 적대적 학습 시스템은, 학습용 원본 이미지 및 상기 학습용 원본 이미지에 노이즈 가 추가되어 생성된 학습용 적대적 변형 이미지를 수신하도록 구성되는 이미지 수신부; 딥러닝 모델을 이용하여 상기 학습용 원본 이미지로부터 원본 이미지 특징을 추출하고, 상기 학습용 적대적 변형 이미지로부터 적대적 변 형 이미지 특징을 추출하도록 구성되는 이미지 특징 추출부; 상기 원본 이미지 특징 및 상기 적대적 변형 이미지 특징을 기초로 상기 딥러닝 모델을 학습하도록 구성되는 기계학습부를 포함할 수 있다."}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 원본 이미지 및 적대적 변형 이미지에 대해서 높은 분류 정확도를 가지는 딥러닝 모델을 학습할 수 있는 학습 시스템 및 학습 방법에 관한 것이다."}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "적대적 변형된 이미지란 이미지 분류를 위한 심층 신경망(Deep Neural Network; DNN)이 원래 클래스가 아닌 다 른 클래스로 오인식하도록 입력 이미지에 사람이 인식할 수 없는 적대적 변형(Adversarial perturbation)을 추 가하여 생성되는 이미지를 의미하며, 적대적 예제(Adversarial Example)라 부르기도 한다. 심층 신경망에 대한 공격자는 네트워크 구조, 학습 데이터셋과 같은 공격 대상인 딥러닝 모델에 관한 어떠한 정 보를 알지 못하는 경우가 대부분이다. 이때 공격자는 전이 공격(Transfer attack)을 수행하여 실제 환경에 배치 된 딥러닝 모델을 속일 수 있다. 이는 딥러닝 모델들이 유사한 특징을 학습하여 유사한 분류 경계를 형성한다는 특성 및 한 모델을 속이는 적대적 예제가 다른 모델을 속일 수 있다는 특성을 이용하는 것이다. 적대적 학습(Adversarial training) 방법은 이러한 전이 공격을 포함한 적대적 공격에 대응하기 위한 효과적인 방법 중 하나이다. 적대적 학습은 반복적으로 적대적 예제를 생성하고, 딥러닝 모델은 생성된 적대적 예제를 정 확하게 분류하도록 학습된다. 하지만, 종래의 적대적 학습 방법은 딥러닝 모델을 적대적 예제만 올바르게 분류 하도록 학습하기 때문에 일반적인 학습 방법에 비해 원본 데이터에 대한 분류 정확도가 떨어진다는 문제가 있다."}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 종래의 일반적인 딥러닝 모델 학습 방법보다 정확하게 적대적 예제를 분류할 수 있는 적대적 학습 시 스템 및 적대적 학습 방법을 제공하기 위한 것이다. 또한, 본 발명은 적대적 예제만 올바르게 분류하도록 학습하던 종래의 적대적 학습 방법보다 적대적 변형이 가 해지지 않은 원본 데이터에 대한 분류 정확도가 높은 적대적 학습 시스템 및 적대적 학습 방법을 제공하기 위한 것이다. 또한, 본 발명은 전이 가능한 적대적 공격을 받더라도 정확한 분류를 통해 자율 주행 자동차의 주변 객체 오인 식에 의한 인명피해 또는 얼굴 오인식에 의한 금전적인 피해를 방지할 수 있는 적대적 학습 시스템 및 적대적 학습 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "개시된 발명의 일 측면에 따른 적대적 학습 시스템은, 학습용 원본 이미지 및 상기 학습용 원본 이미지에 노이 즈가 추가되어 생성된 학습용 적대적 변형 이미지를 수신하도록 구성되는 이미지 수신부; 딥러닝 모델을 이용하 여 상기 학습용 원본 이미지로부터 원본 이미지 특징을 추출하고, 상기 학습용 적대적 변형 이미지로부터 적대 적 변형 이미지 특징을 추출하도록 구성되는 이미지 특징 추출부; 상기 원본 이미지 특징 및 상기 적대적 변형 이미지 특징을 기초로 상기 딥러닝 모델을 학습하도록 구성되는 기계학습부를 포함할 수 있다. 또한, 상기 딥러닝 모델을 이용하여 상기 원본 이미지 특징을 기초로 상기 학습용 원본 이미지에 대한 라벨 값 을 생성하고, 상기 적대적 변형 이미지 특징을 기초로 상기 학습용 적대적 변형 이미지에 대한 라벨 값을 생성 하도록 구성되는 라벨 분류부를 더 포함하고, 상기 기계학습부는, 상기 원본 이미지 특징, 상기 적대적 변형 이 미지 특징, 상기 학습용 원본 이미지의 라벨 값 및 상기 학습용 적대적 변형 이미지의 라벨 값을 기초로 상기 딥러닝 모델을 학습하도록 구성될 수 있다. 또한, 상기 기계학습부는: 상기 원본 이미지 특징 및 상기 적대적 변형 이미지 특징을 기초로 제1 손실 함수를 연산하고; 상기 학습용 원본 이미지의 라벨 값 및 상기 학습용 원본 이미지의 정답 라벨 값을 기초로 제2 손실 함수를 연산하고; 그리고 상기 학습용 적대적 변형 이미지의 라벨 값 및 상기 학습용 적대적 변형 이미지의 정답 라벨 값을 기초로 제3 손실 함수를 연산하도록 구성될 수 있다. 또한, 상기 기계학습부는, 상기 제1 손실 함수, 상기 제2 손실 함수 및 상기 제3 손실 함수를 기초로 제4 손실 함수를 연산하고; 그리고 상기 제4 손실 함수가 감소하게 상기 딥러닝 모델을 학습하도록 구성될 수 있다. 또한, 상기 기계학습부는, 상기 제1 손실 함수에 미리 설정된 상수가 곱해진 값에 상기 제2 손실 함수 및 상기 제3 손실 함수를 합해서 상기 제4 손실 함수를 연산하도록 구성될 수 있다. 또한, 상기 기계학습부는, 상기 원본 이미지 특징 및 상기 적대적 변형 이미지 특징의 차이를 나타내는 값을 상 기 제1 손실 함수로 연산하고; 상기 제1 손실 함수가 학습이 반복하면서 감소하게 상기 딥러닝 모델을 학습하도 록 구성될 수 있다. 또한, 상기 이미지 수신부는, 검사 대상 이미지를 수신하도록 구성되고, 상기 이미지 특징 추출부는, 상기 딥러 닝 모델을 이용하여 상기 검사 대상 이미지로부터 검사 대상 이미지 특징을 추출하도록 구성되고, 상기 라벨 분 류부는, 상기 딥러닝 모델을 이용하여 상기 검사 대상 이미지 특징을 기초로 상기 검사 대상 이미지에 대한 라 벨 값을 생성하도록 구성될 수 있다. 개시된 발명의 일 측면에 따른 적대적 학습 방법은, 적대적 학습 시스템의 동작방법으로서, 학습용 원본 이미지 및 상기 학습용 원본 이미지에 노이즈가 추가되어 생성된 학습용 적대적 변형 이미지를 수신하는 단계; 딥러닝 모델을 이용하여 상기 학습용 원본 이미지로부터 원본 이미지 특징을 추출하고, 상기 학습용 적대적 변형 이미 지로부터 적대적 변형 이미지 특징을 추출하는 단계; 상기 딥러닝 모델을 이용하여 상기 원본 이미지 특징을 기 초로 상기 학습용 원본 이미지에 대한 라벨 값을 생성하고, 상기 적대적 변형 이미지 특징을 기초로 상기 학습 용 적대적 변형 이미지에 대한 라벨 값을 생성하는 단계; 및 상기 원본 이미지 특징, 상기 적대적 변형 이미지 특징, 상기 학습용 원본 이미지의 라벨 값 및 상기 학습용 적대적 변형 이미지의 라벨 값을 기초로 상기 딥러닝 모델을 학습하는 단계를 포함할 수 있다. 또한, 상기 딥러닝 모델을 학습하는 단계는: 상기 원본 이미지 특징 및 상기 적대적 변형 이미지 특징을 기초로 제1 손실 함수를 연산하는 단계; 상기 학습용 원본 이미지의 라벨 값 및 상기 학습용 원본 이미지의 정답 라벨 값을 기초로 제2 손실 함수를 연산하는 단계; 상기 학습용 적대적 변형 이미지의 라벨 값 및 상기 학습용 적대 적 변형 이미지의 정답 라벨 값을 기초로 제3 손실 함수를 연산하는 단계; 상기 제1 손실 함수, 상기 제2 손실 함수 및 상기 제3 손실 함수를 기초로 제4 손실 함수를 연산하는 단계; 및 상기 제4 손실 함수가 감소하게 상기 딥러닝 모델을 학습하는 단계를 포함할 수 있다. 또한, 개시된 발명의 일 측면에 따른 컴퓨터 프로그램은, 상기 스테레오 카메라 입력 기반의 관절 위치 추정 방 법을 실행시키도록 컴퓨터로 판독 가능한 기록매체에 저장될 수 있다."}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 발명의 일 측면에 따르면, 종래의 일반적인 딥러닝 모델 학습 방법보다 정확하게 적대적 예제를 분류할 수 있다. 또한, 본 발명의 실시예에 의하면, 적대적 예제만 올바르게 분류하도록 학습하던 종래의 적대적 학습 방법보다 적대적 변형이 가해지지 않은 원본 데이터에 대한 분류 정확도가 높을 수 있다. 마지막으로, 본 발명의 실시예에 의하면, 전이 가능한 적대적 공격을 받더라도 정확한 분류를 통해 자율 주행 자동차의 주변 객체 오인식에 의한 인명피해 또는 얼굴 오인식에 의한 금전적인 피해를 방지할 수 있다."}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 명세서가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 개시된 발명이 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생 략한다. 명세서에서 사용되는 '~부'라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따 라 복수의 '~부'가 하나의 구성요소로 구현되거나, 하나의 '~부'가 복수의 구성요소들을 포함하는 것도 가능하 다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 제1, 제2 등의 용어는 하나의 구성요 소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아 니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 개시된 발명의 작용 원리 및 실시예들에 대해 설명한다. 도 1은 일 실시예에 따른 적대적 학습 시스템의 구성도이다. 도 1을 참조하면, 본 발명의 실시예에 따른 적대적 학습 시스템은 이미지 수신부, 이미지 특징 추출 부, 라벨 분류부, 기계학습부 및 메모리를 포함할 수 있다. 적대적 학습 시스템은 수신된 이미지를 분류하는데 이용되는 딥러닝 모델을 학습하도록 구성되는 시 스템일 수 있다. 본 발명의 실시예에 따른 적대적 학습 시스템은 따로 마련된 이미지 분류 장치에 마련된 시스템일 수도 있고, 서버에 마련된 시스템일 수도 있다. 이미지 수신부는 학습용 원본 이미지 및 학습용 적대적 변형 이미지를 수신할 수 있다. 이미지 수신부가 이미지들을 수신하는 것은 사용자가 입력 단말을 통해 입력한 이미지들을 입력 단말로부터 전달 받는 방식으로 수신하는 것일 수 있으나 이에 한정되지 않는다. 예를 들어, 이미지 수신부는 메모리 에 미리 저장되어 있던 이미지들을 전달받거나, 적대적 학습 시스템에 포함된 통신부가 서버로부터 수신한 이미지들을 전달받는 방식으로 학습용 원본 이미지 및 학습용 적대적 변형 이미지를 수신할 수도 있 다. 이미지 수신부는 수신한 학습용 원본 이미지 및 학습용 적대적 변형 이미지를 이미지 특징 추출부로 전달할 수 있다. 학습용 원본 이미지 및 학습용 적대적 변형 이미지는 이미지 분류에 이용되는 딥러닝 모델의 학 습에 이용되는 복수의 학습용 이미지일 수 있다. 학습용 적대적 변형 이미지는 학습용 원본 이미지에 노이즈가 추가되어 생성되는 이미지일 수 있다. 일 실시예에 따른 딥러닝 기반의 이미지 분류 기술은 이미지로부터 추출되는 특징(feature)의 데이터를 기반으 로 미리 학습된 딥러닝 모델을 이용하여 이미지를 분류하는 기술일 수 있다. 이때, 이미지로부터 특징을 추출하는 방식을 학습하기 위해 여러 단계의 컨볼루션 계층(convolution layer)을 쌓은 CNN(Convolutional Neural Networks) 구조가 활용될 수 있으나 이미지로부터 특징을 추출하는 방식이 이에 한정되는 것은 아니다. 이미지 특징 추출부는 이미지 수신부로부터 전달받은 이미지로부터 특징을 추출할 수 있다. 어떤 특 정한 이미지의 특징은 해당 이미지에 대한 다양한 특성을 나타내는 정보일 수 있다. 예를 들어, 특정한 이미지 의 특징은 해당 이미지의 각 픽셀 단위에서의 색상, 명도, 경계 등에 대한 정보일 수 있으나 이에 한정되는 것 은 아니다. 이미지 특징 추출부는 딥러닝 모델을 이용하여 학습용 원본 이미지로부터 원본 이미지 특징 을 추출하고, 학습용 적대적 변형 이미지로부터 적대적 변형 이미지 특징을 추출할 수 있다. 이 미지 특징 추출부는 원본 이미지 특징 및 적대적 변형 이미지 특징을 라벨 분류부 및 기계 학습부로 전달할 수 있다. 기계학습부는 원본 이미지 특징 및 적대적 변형 이미지 특징을 기초로 딥러닝 모델을 학습 하도록 구성될 수 있다. 기계학습부는 반복적인 기계 학습(Machine Learning)을 통해 딥러닝 모델을 학습할 수 있다. 학습되는 딥러닝 모델은 메모리에 저장될 수 있다. 기계 학습이란 다수의 파라미터로 구성된 모델을 이용하며, 주어진 데이터로 파라미터를 최적화하는 것을 의미 할 수 있다. 기계 학습은 학습 문제의 형태에 따라 지도 학습(supervised learning), 비지도 학습 (unsupervised learning), 강화 학습(reinforcement learning)을 포함할 수 있다. 지도 학습(supervisedlearning)은 입력과 출력 사이의 매핑을 학습하는 것이며, 입력과 출력 쌍이 데이터로 주어지는 경우에 적용할 수 있다. 비지도 학습(unsupervised learning)은 입력만 있고 출력은 없는 경우에 적용하며, 입력 사이의 규칙 성 등을 찾아낼 수 있다. 다만, 일 실시예에 따른 기계 학습이 반드시 전술한 학습 방식으로 한정되는 것은 아 니다. 라벨 분류부는 이미지 특징 추출부로부터 전달받은 이미지의 특징을 기초로 딥러닝 모델을 이용 하여 적대적 학습 시스템이 수신한 이미지에 대한 라벨 값을 생성할 수 있다. 어떤 이미지에 대한 라벨 값 은 해당 이미지에 대한 분류 결과에 관련된 수치 값일 수 있다. 즉, 적대적 학습 시스템은 수신한 복수의 이미지들 각각에 대해 라벨 값을 생성하는 방식으로 각각의 이미지들을 분류할 수 있다. 라벨 분류부는 원본 이미지 특징을 기초로 학습용 원본 이미지에 대한 라벨 값을 생성할 수 있 다. 또한, 라벨 분류부는 적대적 변형 이미지 특징을 기초로 학습용 적대적 변형 이미지에 대한 라벨 값을 생성할 수 있다. 라벨 분류부는 생성된 라벨 값들을 기계학습부로 전달할 수 있다. 기계학습부는 원본 이미지 특징, 적대적 변형 이미지 특징, 학습용 원본 이미지의 라벨 값 및 학습용 적대적 변형 이미지의 라벨 값을 기초로 딥러닝 모델을 학습할 수 있다. 이렇게 전술한 방 식으로 적대적 학습 시스템이 수신한 복수의 학습용 원본 이미지 및 복수의 학습용 적대적 변형 이미 지의 쌍들에 대해서 기계학습부는 반복하여 딥러닝 모델을 학습할 수 있다. 반복되는 기계학습이 완료되면, 적대적 학습 시스템은 검사 대상 이미지에 대해서 이미지 분류를 수 행할 수 있다. 검사 대상 이미지는 사용자가 학습단계 이후 실제로 분류를 원하는 대상이 되는 이미지일 수 있다. 이미지 수신부는 검사 대상 이미지를 수신할 수 있다. 이미지 수신부는 검사 대상 이미지 를 이미지 특징 추출부로 전달할 수 있다. 이미지 특징 추출부는 미리 학습된 딥러닝 모델을 이용하여 검사 대상 이미지로부터 검사 대상 이미지 특징을 추출할 수 있다. 이미지 특징 추출부는 검사 대상 이미지 특징을 라벨 분류부로 전달 할 수 있다. 라벨 분류부는 미리 학습된 딥러닝 모델을 이용하여 검사 대상 이미지 특징을 기초로 검 사 대상 이미지에 대한 라벨 값을 생성할 수 있다. 일 실시예에 따른 적대적 학습 시스템에서 이용되는 딥러닝 모델은 단순히 학습용 원본 이미지 만 학습용 데이터로 쓰는 것이 아니라 해당 원본 이미지를 적대적 변형한 이미지도 한 쌍으로서 학습용 데이터 로 쓸 수 있다. 이로 인해 일 실시예에 따른 적대적 학습 시스템은 블랙박스 공격을 통한 전이 공격에 보 다 효과적으로 대응할 수 있다. 도 2는 블랙박스 공격을 통한 전이 공격의 특징을 설명하기 위한 도면이다. 도 2를 참조하면, 원본 이미지에 노이즈가 추가되어 생성되는 적대적 이미지에 의해 전이 공격이 가능한 것을 확인할 수 있다. 적대적 변형 이미지란 이미지 분류를 위한 심층 신경망이 원래 클래스가 아닌 다른 클래스로 오인식하도록 입력 이미지에 사람이 인식할 수 없는 적대적 변형 (Adversarial perturbation)을 추가하여 생성된 이미지이다. 이미지를 분석하거나 탐지하는 기술 중에서는 이웃 픽셀 간에 유사한 값을 가지는 이미지의 특성을 활용한 탐지 기법(예를 들어, Steganalysis 기반 탐지 기술)이 있다. 이러한 이웃 픽셀 간에 유사한 값을 가지는 이미지의 특성을 활용한 탐지 기법은 탐지 대상 이미지에 노이즈가 추가되어 있는 적대적 변형 이미지에 대해서는 탐지 성능이 떨어지게 된다. 구체적으로, 이웃 픽셀 간에 유사한 값을 가지는 이미지의 특성을 활용한 탐지 기법은 각 픽셀의 8방향 인접 픽셀 중 2방향 이상 값의 차이가 크면 경계로 판단하는데, 이미지 내 객체의 경계 부분에 노이즈가 있으면 이러한 탐지를 회피할 수 있게 된다. 이미지 수정자(Modifier)는 정상 이미지에 노이즈(Perturbation)가 추가되는 방식으로 적대적 변형 이미지를 생 성할 수 있다. 이렇게 생성된 적대적 변형 이미지는 이웃 픽셀 간에 유사한 값을 가지는 이미지의 특성을 활용 한 탐지 기법에 의해서는 객체의 경계를 경계로 인식 못하게 될 수 있다. 적대적 변형 이미지가 이미지 분류 장 치에 입력되면 성능 좋은 이미지 분류 장치라 해도 이미지 분류 성능이 떨어진다는 문제가 발생할 수 있다. 뿐 만 아니라 특정한 인공지능 모델에 대해서 적대적 변형 이미지에 의한 의도적인 전이 공격의 문제가 발생할 수 있다.어떠한 인공지능 모델에 대해서 공격자는 네트워크 구조, 학습 데이터 셋과 같은 공격 대상인 인공지능 모델에 관한 어떠한 정보도 알고 있지 않으므로 일반적인 공격이 불가능하다. 즉, 화이트박스(white-box) 방식의 공격 은 일반적으로 불가능하다. 하지만, 공격자가 어떤 인공지능 모델(Model A)에 대해서 적대적 변형 이미지를 통 한 공격을 성공시키면, 전이성(Transferability)의 특성을 이용하여 다른 비슷한 모델(Model B)에 대해서도 적 대적 변형 이미지를 통한 공격을 성공시킬 수 있다. 즉, 하나의 인공지능 모델을 속이는 적대적 예제는 다른 인 공지능 모델을 속일 수 있다는 문제가 있다. 이러한 적대적 변형 이미지에 의한 문제를 해결하기 위한 종래의 적대적 학습 관련 연구들은 학습 데이터를 변 조하여 생성한 적대적 예제를 학습에 활용하여 적대적 예제를 정상 클래스로 분류하도록 학습한다. 이렇게 학습 된 모델은 더욱 정교한 분류 경계를 갖게 되어 적대적 예제에 내성을 갖게 된다. 하지만 종래의 적대적 학습 관 련 연구들은 정상 데이터를 사용하지 않기 때문에 변형되기 전의 원본 이미지만 사용하는 학습 방식에 비해 적 대적으로 변형되지 않은 검사 대상 이미지들에 대한 분류 정확도가 떨어진다는 단점이 있다. 도 3은 일 실시예에 따른 딥러닝 모델을 학습하는 과정을 설명하기 위한 도면이다. 도 3을 참조하면, 기계학습부는 학습용 원본 이미지 및 학습용 적대적 변형 이미지 쌍에 대한 제1 손실 함수( ), 제2 손실 함수( ) 및 제3 손실 함수( )를 연산할 수 있다. 이미지 특징 추출부(Feature Extractor)는 컨볼루션 계층을 이용한 DNN(Deep Neural Networks) 기반 딥러 닝 모델을 통해 수신된 이미지에 대한 특징을 추출할 수 있다. 이때, 어떠한 이미지에 대한 특징은 DNN 기 반 딥러닝 모델의 마지막 컨볼루션 계층의 출력 값일 수 있다. 즉, 원본 이미지 특징은 학습용 원본 이미지에 대한 DNN 기반 딥러닝 모델의 마지막 컨볼루션 계층의 출력 값( )이고, 적대적 변형 이 미지 특징은 학습용 적대적 변형 이미지에 대한 DNN 기반 딥러닝 모델의 마지막 컨볼루션 계층 의 출력 값( )일 수 있다. 기계학습부는 원본 이미지 특징 및 적대적 변형 이미지 특징을 기초로 제1 손실 함수 ( )를 연산할 수 있다. 구체적으로, 기계학습부는 원본 이미지 특징 및 적대적 변형 이미지 특징의 차이를 나타내는 값을 제1 손실 함수( )로서 연산할 수 있다. [방정식 1]"}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[방정식 1]을 참조하면, 제1 손실 함수( )는 학습용 원본 이미지에 대한 마지막 컨볼루션 계층의 출력 값( ) 및 학습용 적대적 변형 이미지에 대한 마지막 컨볼루션 계층의 출력 값( )의 차이를 최소화하는데 이용되는 손실 함수임을 확인할 수 있다. 기계학습부는 제1 손실 함수( )가 학습이 반복하면서 감소하도록 딥러닝 모델을 학습할 수 있다. 라벨 분류부(Label Classifier)는 DNN 기반 딥러닝 모델의 마지막 컨볼루션 계층의 출력 값인 이미지 특징을 기초로 각 이미지에 대한 라벨 값을 생성할 수 있다. 즉, 라벨 분류부는 원본 이미지 특징을 기초 로 학습용 원본 이미지(x)에 대한 라벨 값( )을 생성하고, 적대적 변형 이미지 특징을 기초로 학 습용 적대적 변형 이미지에 대한 라벨 값( )을 생성할 수 있다. 기계학습부는 학습용 원본 이미지의 라벨 값 및 학습용 원본 이미지의 정답 라벨 값을 기초로 제2 손실 함수를 연산할 수 있다. 어느 한 학습용 원본 이미지의 정답 라벨 값은 해당 학습용 원본 이미지 가 어떻게 분류될지에 대해서 미리 정해진 정답 값일 수 있다.[방정식 2]"}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[방정식 2]를 참조하면, 제2 손실 함수( )는 라벨 분류부가 생성한 학습용 원본 이미지(x)에 대한 라벨 값( ) 및 학습용 원본 이미지(x)의 정답 라벨 값(y)을 내적한 값에 로그 값과 음수를 곱하여 도출된 값( )으로 연산될 수 있다. 라벨 분류부가 생성한 학습용 원본 이미지에 대한 라벨 값 ( )이 학습용 원본 이미지의 정답 라벨 값(y)과 유사할수록 이들을 내적한 값에 로그 값과 음수를 곱하 여 도출된 값( )은 감소할 수 있다. 즉, 제2 손실 함수( )는 라벨 분류부가 생성한 학습용 원본 이미지에 대한 라벨 값( ) 및 학습용 원본 이미지의 정답 라벨 값(y)의 차이를 최소화하는 데 이용되는 손실 함수임을 확인할 수 있다. 기계학습부는 학습용 적대적 변형 이미지의 라벨 값 및 학습용 적대적 변형 이미지의 정답 라벨 값을 기초로 제3 손실 함수를 연산할 수 있다. [방정식 3]"}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[방정식 3]를 참조하면, 제3 손실 함수( )는 라벨 분류부가 생성한 학습용 적대적 변형 이미지 (x')에 대한 라벨 값( ) 및 학습용 적대적 변형 이미지(x')의 정답 라벨 값(y)을 내적한 값에 로그 값과 음수를 곱하여 도출된 값( )으로 연산될 수 있다. 라벨 분류부가 생성한 학습용 적대적 변형 이미지에 대한 라벨 값( )이 학습용 적대적 변형 이미지의 정답 라벨 값(y)과 유사할수록 이들을 내적한 값에 로그 값과 음수를 곱하여 도출된 값( )은 감소할 수 있다. 즉, 제3 손실 함수 ( )는 라벨 분류부가 생성한 학습용 적대적 변형 이미지에 대한 라벨 값( ) 및 학습용 적 대적 변형 이미지의 정답 라벨 값(y)의 차이를 최소화하는데 이용되는 손실 함수임을 확인할 수 있다. [방정식 4]"}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "[방정식 4]를 참조하면, 제4 손실 함수( )는 임의의 값(γ)이 곱해진 제1 손실 함수( ), 제2 손실 함수( ) 및 제3 손실 함수( )이 합해진 것일 수 있다. 기계학습부는 제1 손실 함수, 제2 손실 함수 및 제3 손실 함수를 기초로 제4 손실 함수를 연산할 수 있다. 즉, 기계학습부는 제1 손실 함수( )에 미리 설정된 상수(γ)가 곱해진 값에 제2 손실 함수 ( ) 및 제3 손실 함수( )를 합해서 제4 손실 함수( )를 연산할 수 있다. 기계학습부 는 학습을 반복하면서 제4 손실 함수가 감소하도록 딥러닝 모델을 학습할 수 있다. 이상에서 설명된 구성요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구성요소들의 상호 위치는 시스템의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통 상의 지식을 가진 자에게 용이하게 이해될 것이다. 도 4는 일 실시예에 따른 적대적 학습 방법의 순서도이다. 이는 본 발명의 목적을 달성하기 위한 바람직한 실시 예일 뿐이며, 필요에 따라 일부 구성이 추가되거나 삭제될 수 있음은 물론이다. 도 4를 참조하면, 이미지 수신부는 학습용 원본 이미지 및 학습용 원본 이미지에 노이즈가 추가 되어 생성된 학습용 적대적 변형 이미지를 수신할 수 있다. 이미지 특징 추출부는 딥러닝 모델을 이용하여 학습용 원본 이미지로부터 원본 이미지 특징 을 추출하고, 학습용 적대적 변형 이미지로부터 적대적 변형 이미지 특징을 추출할 수 있다 . 라벨 분류부는 딥러닝 모델을 이용하여 원본 이미지 특징을 기초로 학습용 원본 이미지에 대한 라벨 값을 생성하고, 적대적 변형 이미지 특징을 기초로 학습용 적대적 변형 이미지에 대한 라 벨 값을 생성할 수 있다. 기계학습부는 제1 손실 함수, 제2 손실 함수 및 제3 손실 함수를 연산할 수 있다. 이때, 기계학습부 는 원본 이미지 특징 및 적대적 변형 이미지 특징을 기초로 제1 손실 함수를 연산하고, 학습용 원본 이미지의 라벨 값 및 학습용 원본 이미지의 정답 라벨 값을 기초로 제2 손실 함수를 연산하고, 학습용 적대적 변형 이미지의 라벨 값 및 학습용 적대적 변형 이미지의 정답 라벨 값을 기초로 제3 손실 함수를 연산할 수 있다. 기계학습부는 제1 손실 함수, 제2 손실 함수 및 제3 손실 함수를 기초로 제4 손실 함수를 연산할 수 있다 . 이때. 기계학습부는 제1 손실 함수에 미리 설정된 상수가 곱해진 값에 제2 손실 함수 및 제3 손실 함수를 합해서 제4 손실 함수를 연산할 수 있다. 기계학습부는 원본 이미지 특징, 적대적 변형 이미지 특징, 학습용 원본 이미지의 라벨 값 및 학습용 적대적 변형 이미지의 라벨 값을 기초로 딥러닝 모델을 학습할 수 있다. 구체적으로 기계학습부는 학습이 반복될수록 제4 손실 함수가 감소하게 딥러닝 모델을 학습할 수 있다. 이미지 수신부, 이미지 특징 추출부, 라벨 분류부 및 기계학습부는 적대적 학습 시스템 에 포함된 복수개의 프로세서 중 어느 하나의 프로세서를 포함할 수 있다. 또한, 지금까지 설명된 본 발명 의 실시예에 따른 적대적 학습 방법은, 프로세서에 의해 구동될 수 있는 프로그램의 형태로 구현될 수 있다. 여기서 프로그램은, 프로그램 명령, 데이터 파일 및 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 프로그램은 기계어 코드나 고급 언어 코드를 이용하여 설계 및 제작된 것일 수 있다. 프로그램은 상술한 부호 수정을 위한 방법을 구현하기 위하여 특별히 설계된 것일 수도 있고, 컴퓨터 소프트웨어 분야에서 통상의 기술 자에게 기 공지되어 사용 가능한 각종 함수나 정의를 이용하여 구현된 것일 수도 있다. 전술한 정보 표시 방법 을 구현하기 위한 프로그램은, 프로세서에 의해 판독 가능한 비일시적 기록매체에 기록될 수 있다. 이때, 기록 매체는 메모리일 수 있다. 메모리는 전술한 동작 및 후술하는 동작을 수행하는 프로그램을 저장할 수 있으며, 메모리는 저장된 프로그램을 실행시킬 수 있다. 프로세서와 메모리가 복수인 경우에, 이들이 하나의 칩에 집적되는 것도 가 능하고, 물리적으로 분리된 위치에 마련되는 것도 가능하다. 메모리는 데이터를 일시적으로 기억하기 위한 S램(Static Random Access Memory, S-RAM), D랩(Dynamic Random Access Memory) 등의 휘발성 메모리를 포함할 수 있다. 또한, 메모리는 제어 프로그램 및 제어 데이터를 장기간 저장하기 위한 롬(Read Only Memory), 이피롬(Erasable Programmable Read Only Memory: EPROM), 이이피롬(Electrically Erasable Programmable Read Only Memory: EEPROM) 등의 비휘발성 메모리를 포함할 수 있다. 프로세서는 각종 논리 회로와 연산 회로를 포함할 수 있으며, 메모리로부터 제공된 프로그램에 따라 데이터를 처리하고, 처리 결과에 따라 제어 신호 를 생성할 수 있다. 본 발명의 실시예에 따른 적대적 학습 시스템의 성능을 검증하기 위하여, 종래의 딥러닝 학습 방법과 본 발명의 적대적 학습 방법으로 CIFAR-10 및 CIFAR-100의 데이터셋의 이미지를 분류하는 실험을 진행하였다. 도 5는 일 실시예에 따른 적대적 학습 방법이 종래의 딥러닝 학습 방법에 비해 개선된 정도를 나타낸 표이다. 도 5를 참조하면, 일 실시예에 따른 적대적 학습 방법(Feature-based Aeversarial Training; FAT)이 다른 종래 의 방법(Natural training, PGD Training 및 TRADES)보다 분류 성능이 더 뛰어나다는 것을 확인할 수 있다. 구 체적으로, 도 5의 상단의 표는 CIFAR-10의 데이터셋의 이미지를 분류하는 실험 결과이고, 하단의 표는 CIFAR- 100의 데이터셋의 이미지를 분류하는 실험 결과이다. 도시된 표의 각 성분에 표시된 수치들은 해당 행에 대응되는 학습 방법으로 해당 열에 대응되는 데이터 셋에 대 한 분류 정확도를 나타낸다. 예를 들어, 일 실시예에 따른 적대적 학습 방법(Feature-based Aeversarial Training; FAT)은 적대적 변형이 가해지지 않은 원본 이미지 셋(Natural)에 대해서 종래의 일반적인 학습 방법 (Natural Training)보다는 분류 정확도가 낮지만, 종래의 적대적 학습 방법(PGD Training 및 TRADES)보다는 분 류 정확도가 높다. 또한, 일 실시예에 따른 적대적 학습 방법(Feature-based Aeversarial Training; FAT)은 적 대적 변형이 가해진 이미지 셋(FGSM, PGD-20, DeepFool, CW-20 및 MIM-20)에 대해서 종래의 적대적 학습 방법 들(Feature-based Aeversarial Training; FAT)보다 분류 정확도가 높다는 것을 확인할 수 있다. 정리하면, 일 실시예에 따른 적대적 학습 방법(FAT)이 종래의 일반적인 학습 방법(Natural Training)과 종래의 적대적 학습 방법(PGD Training 및 TRADES)보다 적대적 변형이 가해진 이미지 셋(FGSM, PGD-20, DeepFool, CW- 20 및 MIM-20)에 대해서 더 정확하게 분류를 하면서도, 종래의 적대적 학습 방법(PGD Training 및 TRADES)보다 적대적 변형이 가해지지 않은 원본 이미지 셋(Natural)에 대해서 더 정확하게 분류하는 것을 확인할 수 있다."}
{"patent_id": "10-2022-0076352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 발명이 속하는 기술분야에서 통상 의 지식을 가진 자는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 발명이 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2022-0076352", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 적대적 학습 시스템의 구성도이다. 도 2는 블랙박스 공격을 통한 전이 공격의 특징을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 딥러닝 모델을 학습하는 과정을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 적대적 학습 방법의 순서도이다. 도 5는 일 실시예에 따른 적대적 학습 방법이 종래의 딥러닝 학습 방법에 비해 개선된 정도를 나타낸 표이다."}
