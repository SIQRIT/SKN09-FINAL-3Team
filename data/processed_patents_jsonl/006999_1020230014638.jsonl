{"patent_id": "10-2023-0014638", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0122002", "출원번호": "10-2023-0014638", "발명의 명칭": "시맨틱 정보를 활용한 객체 분류 장치 및 방법", "출원인": "건국대학교 산학협력단", "발명자": "조기춘"}}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "시맨틱 정보를 활용한 객체 분류 방법에 있어서,대상 객체에 대응하는 복수의 포인트를 포함하고, 상기 대상 객체에 대한 시맨틱 정보를 포함하는 포인트 클라우드 데이터를 획득하는 단계; 및상기 복수의 포인트를 감싸는 경계 상자의 위치 정보, 상기 복수의 포인트 각각에 대한 피처 정보 및 상기 시맨틱 정보를 이용하여 기 학습된 인공지능 기반의 객체 분류 모델을 통해 상기 대상 객체에 대한 제1객체 분류 정보를 도출하는 단계,를 포함하는, 분류 방법."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 포인트 각각의 객체 유형 별 확률 정보를 이용하여 상기 대상 객체에 대한 제2객체 분류 정보를 도출하는 단계; 및상기 제1객체 분류 정보 및 상기 제2객체 분류 정보 중 적어도 하나에 기초하여 상기 대상 객체의 대표 객체 분류 정보를 출력하는 단계,를 더 포함하는, 분류 방법."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 시맨틱 정보는 상기 대상 객체를 촬영한 이미지 데이터에 대한 의미론적 영역 분할(SemanticSegmentation)을 통해 획득되는 것인, 분류 방법."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 객체 분류 모델은 다층 퍼셉트론(multi-layer perceptron, MLP) 기반의 모델인 것을 특징으로 하는, 분류방법."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 제2객체 분류 정보를 도출하는 단계는,상기 복수의 포인트 각각의 객체 유형 별 확률 정보를 벡터 곱셈 및 정규화를 이용하여 융합하는 것인, 분류 방법."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서,상기 제1객체 분류 정보, 상기 제2객체 분류 정보 및 상기 대표 객체 분류 정보 각각은 승용차, 상용차,이륜차, 자전거 및 보행자를 포함하는 복수의 객체 유형 중 상기 대상 객체에 부합하도록 결정된 객체 유형에대한 정보인 것인, 분류 방법."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2024-0122002-3-시맨틱 정보를 활용한 객체 분류 장치에 있어서,대상 객체에 대응하는 복수의 포인트를 포함하고, 상기 대상 객체에 대한 시맨틱 정보를 포함하는 포인트 클라우드 데이터를 획득하는 입력 획득부; 및상기 복수의 포인트를 감싸는 경계 상자의 위치 정보, 상기 복수의 포인트 각각에 대한 피처 정보 및 상기 시맨틱 정보를 이용하여 기 학습된 인공지능 기반의 객체 분류 모델을 통해 상기 대상 객체에 대한 제1객체 분류 정보를 도출하는 제1분류 수행부,를 포함하는, 분류 장치."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 복수의 포인트 각각의 객체 유형 별 확률 정보를 이용하여 상기 대상 객체에 대한 제2객체 분류 정보를 도출하는 제2분류 수행부; 및상기 제1객체 분류 정보 및 상기 제2객체 분류 정보 중 적어도 하나에 기초하여 상기 대상 객체의 대표 객체 분류 정보를 출력하는 객체 결정부,를 더 포함하는 것인, 분류 장치."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 시맨틱 정보는 상기 대상 객체를 촬영한 이미지 데이터에 대한 의미론적 영역 분할(SemanticSegmentation)을 통해 획득되는 것인, 분류 장치."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 객체 분류 모델은 다층 퍼셉트론(multi-layer perceptron, MLP) 기반의 모델인 것을 특징으로 하는, 분류장치."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 제2분류 수행부는,상기 복수의 포인트 각각의 객체 유형 별 확률 정보를 벡터 곱셈 및 정규화를 이용하여 융합하는 것인, 분류 장치."}
{"patent_id": "10-2023-0014638", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서,상기 제1객체 분류 정보, 상기 제2객체 분류 정보 및 상기 대표 객체 분류 정보 각각은 승용차, 상용차,이륜차, 자전거 및 보행자를 포함하는 복수의 객체 유형 중 상기 대상 객체에 부합하도록 결정된 객체 유형에대한 정보인 것인, 분류 장치."}
{"patent_id": "10-2023-0014638", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "시맨틱 정보를 활용한 객체 분류 장치 및 방법이 개시되며, 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 방법은, 대상 객체에 대응하는 복수의 포인트를 포함하고, 상기 대상 객체에 대한 시맨틱 정보를 포함하는 포인트 클라우드 데이터를 획득하는 단계 및 상기 복수의 포인트를 감싸는 경계 상자의 위치 정보, 상기 복수의 포인트 각각에 대한 피처 정보 및 상기 시맨틱 정보를 이용하여 기 학습된 인공지능 기반의 객체 분류 모델을 통 해 상기 대상 객체에 대한 제1객체 분류 정보를 도출하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0014638", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 시맨틱 정보를 활용한 객체 분류 장치 및 방법에 관한 것이다. 예를 들면, 본원은 시맨틱 정보를 활용하 여 차량에 탑재되는 객체 분류기의 성능을 개선하기 위한 기법에 관한 것이다."}
{"patent_id": "10-2023-0014638", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율주행 차량의 인지 시스템을 통해 획득되는 객체 분류 정보는 차량의 제어 전략을 세분화하기 위한 주요 요 소이므로, 정확한 객체 분류 정보를 획득하는 것이 필요하다. 한편, 자율주행 차량의 인지 시스템이 단일 유형의 센서에서 획득되는 객체 분류 정보에만 의존할 경우 한계점 이 존재하며, 구체적으로 카메라 센서의 경우 터널 환경에서 화이트 홀 현상이 발생하거나 야간 주행 환경 등 조명 조건이 열악한 환경에서는 객체 분류 정보를 정확하게 알아내기 어렵다는 한계가 있고, 라이다 센서의 경 우, 센서로부터의 거리가 멀거나 객체의 크기가 작을수록 획득되는 데이터가 희소하여 객체 분류 정보가 부정확 해질 수 있다는 문제가 있다. 이에 따라, 종래의 단일 유형 센서를 이용한 객체 분류기의 성능을 이종 센서로부터 얻은 추가적인 시맨틱 정보 를 활용하여 개선할 수 있는 기법에 대한 개발이 요구된다. 본원의 배경이 되는 기술은 한국등록특허공보 제10-2313129호에 개시되어 있다."}
{"patent_id": "10-2023-0014638", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 서로 다른 유형의 센서 모듈을 통합 적용하여 객 체 분류 성능을 향상시킬 수 있는 시맨틱 정보를 활용한 객체 분류 장치 및 방법을 제공하려는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2023-0014638", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 방법은, 대상 객체에 대응하는 복수의 포인트를 포함하고, 상기 대상 객체에 대한 시맨틱 정보를 포함하는 포인트 클라우드 데이터를 획득하는 단계 및 상기 복수의 포인트를 감싸는 경계 상자의 위치 정보, 상기 복수의 포인트 각각에 대한 피처 정보 및 상기 시맨틱 정보를 이용하여 기 학습된 인공지능 기반의 객체 분류 모델을 통해 상기 대상 객체에 대한 제1객체 분류 정보를 도출하는 단계를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 방법은, 상기 복수의 포인트 각각의 객체 유형 별 확률 정보를 이용하여 상기 대상 객체에 대한 제2객체 분류 정보를 도출하는 단계 및 상기 제1객체 분류 정 보 및 상기 제2객체 분류 정보 중 적어도 하나에 기초하여 상기 대상 객체의 대표 객체 분류 정보를 출력하는 단계를 포함할 수 있다. 또한, 상기 시맨틱 정보는 상기 대상 객체를 촬영한 이미지 데이터에 대한 의미론적 영역 분할(Semantic Segmentation)을 통해 획득될 수 있다. 또한, 상기 객체 분류 모델은 다층 퍼셉트론(multi-layer perceptron, MLP) 기반의 모델일 수 있다. 또한, 상기 제2객체 분류 정보를 도출하는 단계는, 상기 복수의 포인트 각각의 객체 유형 별 확률 정보를 벡터 곱셈 및 정규화를 이용하여 융합할 수 있다. 또한, 상기 제1객체 분류 정보, 상기 제2객체 분류 정보 및 상기 대표 객체 분류 정보 각각은 승용차, 상용차, 이륜차, 자전거 및 보행자를 포함하는 복수의 객체 유형 중 상기 대상 객체에 부합하도록 결정된 객체 유형에 대한 정보일 수 있다. 한편, 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 장치는, 대상 객체에 대응하는 복수의 포인트 를 포함하고, 상기 대상 객체에 대한 시맨틱 정보를 포함하는 포인트 클라우드 데이터를 획득하는 입력 획득부 및 상기 복수의 포인트를 감싸는 경계 상자의 위치 정보, 상기 복수의 포인트 각각에 대한 피처 정보 및 상기 시맨틱 정보를 이용하여 기 학습된 인공지능 기반의 객체 분류 모델을 통해 상기 대상 객체에 대한 제1객체 분 류 정보를 도출하는 제1분류 수행부를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 장치는, 상기 복수의 포인트 각각의 객체 유형 별 확률 정보를 이용하여 상기 대상 객체에 대한 제2객체 분류 정보를 도출하는 제2분류 수행부 및 상기 제1객 체 분류 정보 및 상기 제2객체 분류 정보 중 적어도 하나에 기초하여 상기 대상 객체의 대표 객체 분류 정보를출력하는 객체 결정부를 포함할 수 있다. 또한, 상기 제2분류 수행부는, 상기 복수의 포인트 각각의 객체 유형 별 확률 정보를 벡터 곱셈 및 정규화를 이 용하여 융합할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2023-0014638", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 서로 다른 유형의 센서 모듈을 통합 적용하여 객체 분류 성능을 향상 시킬 수 있는 시맨틱 정보를 활용한 객체 분류 장치 및 방법을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 자율주행 차량의 인지 시스템에 적용되는 객체 분류기에서 기존에 제 공하지 않는 유형의 객체에 대한 분류 정보를 추가적으로 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 자율주행 차량의 인지 시스템에 적용되는 기존 객체 분류기의 분류 가 능 영역을 확장할 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2023-0014638", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 시맨틱 정보를 활용한 객체 분류 장치 및 방법에 관한 것이다. 예를 들면, 본원은 시맨틱 정보를 활용하 여 차량에 탑재되는 객체 분류기의 성능을 개선하기 위한 기법에 관한 것이다. 도 1은 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 장치를 포함하는 객체 분류 시스템의 개략적 인 구성도이다.도 1을 참조하면, 본원의 일 실시예에 따른 객체 분류 시스템은 본원의 일 실시예에 따른 시맨틱 정보를 활 용한 객체 분류 장치(이하, '객체 분류 장치'라 한다.), 라이다 센서, 이미지 센서 및 사 용자 단말을 포함할 수 있다. 객체 분류 장치, 라이다 센서, 이미지 센서 및 사용자 단말 상호간은 네트워크를 통해 통신할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조 를 의미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네 트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트 워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지 는 않는다. 사용자 단말은 예를 들면, 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 무선 통신 장치일 수 있다. 또한, 본원의 실시예에 관한 설명에서 라이다 센서는 대상 차량에 탑재되어 포인트 클라우드 입력을 객체 분류 장치로 제공하는 센서 모듈이고, 이미지 센서는 대상 차량에 탑재되어 대상 차량 의 주행 또는 정차 중 주변 환경에 대한 이미지 데이터(예를 들면, 차량 전방 이미지, 차량 후방 이미지 등)를 객체 분류 장치로 제공하는 센서 모듈일 수 있다. 또한, 본원의 실시예에 관한 설명에서 사용자 단말은 대상 차량에 구비되는 차량 탑재 단말(미도 시)을 포함하거나, 대상 차량의 소유자, 주행 주체, 대상 차량에 탑승한 운전자 또는 동승자 등이 소지한 단말일 수 있다. 이하에서는 도 2 내지 도 4를 참조하여 객체 분류 장치의 구체적인 기능 및 동작에 대하여 설명하도록 한 다. 도 2는 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 장치의 동작 프로세스를 설명하기 위한 개념 도이다. 도 2를 참조하면, 객체 분류 장치는 먼저 대상 객체에 대응하는 복수의 포인트를 포함하고, 대상 객체에 대한 시맨틱 정보를 포함하는 포인트 클라우드 데이터를 획득할 수 있다. 구체적으로 객체 분류 장치는 주행 중이거나 정차 상태인 대상 차량의 주변 영역(이하, '대상 영 역'으로 지칭하도록 한다.)에 위치하는 객체에 대응하는 복수의 포인트를 포함하는 포인트 클라우드 데이터를 라이다 센서로부터 획득(수신)하되, 포인트 클라우드 데이터에 포함된 각각의 포인트에 대응하는 객체 유 형에 대한 분류 정보(클래스 정보)를 의미하고, 라이다 센서 외의 이종 유형의 센서 모듈(예를 들면, 이미 지 센서 등)을 통해 획득되는 시맨틱 정보를 원본 포인트 클라우드 데이터에 대하여 오버레이 한 의미론적 포인트 클라우드 데이터 및 포인트 클라우드 데이터에 포함된 복수의 포인트를 개별 객체 단위로 군집(그룹 핑)하고, 군집된 복수의 포인트를 감싸도록 정의되는 경계 상자(Bounding box)에 대한 정보를 포함하는 객체 군 집 데이터를 입력으로서 획득할 수 있다. 예를 들면, 시맨틱 정보는 이미지 센서에 의해 대상 영역에 대하여 획득된 이미지 데이터를 인공지능 기반 의 알고리즘(예를 들면, 딥러닝 기반의 YOLO v3 알고리즘 등)에 입력하여 도출한 이미지 데이터 내 각 영역 별 객체 유형(클래스) 정보일 수 있다. 또한, 도 2를 참조하면, 객체 분류 장치는 후술하는 기 학습된 인공지능 기반의 객체 분류 모델을 이용한 객체 분류 정보(제1객체 분류 정보) 및 객체 유형 별 확률 정보를 이용한 객체 분류 정보(제2객체 분류 정보)를 기초로 하여, 입력된 의미론적 포인트 클라우드 데이터 및 객체 군집 데이터의 객체 분류 정확도를 개선 한 출력 포인트 클라우드 데이터를 도출하도록 동작할 수 있다. 구체적으로 객체 분류 장치는 의미론적 포인트 클라우드 데이터 및 객체 군집 데이터를 이용하여 대 상 영역에 존재하는 각각의 객체에 대응하는 경계 상자 내부의 각 포인트의 피처(Feature)를 추출할 수 있다.예를 들어, 객체 분류 장치는 각 포인트의 좌표 정보(x, y, z) 및 각 포인트에 대응하여 예측(추정)된 객 체 유형 정보(label)를 포함하는 피처를 개별 포인트마다 도출할 수 있다. 예를 들어, 좌표 정보는 라이다 센서 에 의해 계측된 거리 정보 및 방향 정보를 기초로 하여 도출되는 것일 수 있고, 객체 유형 정보는 대상 차 량의 주행 환경에 대한 정보(예를 들면, 대상 차량의 위치, 주행 도로 유형, 주행 차선 등)를 고려 하여 예측(추정)되는 것일 수 있다. 또한, 객체 분류 장치는 대상 객체에 대응하는 복수의 포인트를 감싸는 경계 상자의 위치 정보, 대상 객체 에 대응하는 복수의 포인트 각각에 대한 피처 정보 및 시맨틱 정보를 이용하여 기 학습된 인공지능 기반의 객체 분류 모델을 통해 대상 객체에 대한 제1객체 분류 정보를 도출할 수 있다. 이와 관련하여 도 3은 인공지능 기반의 객체 분류 모델의 구조를 예시적으로 나타낸 개념도이다. 도 3을 참조하면, 객체 분류 장치는 기 학습된 인공지능 기반의 객체 분류 모델에 대상 객체에 대응하는 복수의 포인트를 감싸도록 생성된 경계 상자의 위치 정보 및 크기 정보와 해당 경계 상자와 매칭되는 시맨틱 정 보(예측 객체 분류 정보)를 입력하여 대상 객체에 대한 객체 유형 분류를 수행하여 제1객체 분류 정보(도 3의 'Class Prediction')를 도출할 수 있다. 한편, 본원의 일 실시예에 따르면, 객체 분류 모델은 다층 퍼셉트론(multi-layer perceptron, MLP) 기반의 모델 일 수 있다. 이러한 다층 퍼셉트론 모델은 복수 개의 퍼셉트론 층으로 이루어지며, 각 퍼셉트론 층은 입력 데이 터에 가중치를 연산하여 결과를 출력하고, 각 퍼셉트론 층의 입력 데이터는 대상 객체에 대응하는 복수의 포인 트의 개수를 N개라 할 때, Nx3개의 포인트 클라우드 좌표 정보(x, y, z)와 Nx1개의 시맨틱 정보(label)를 포함 할 수 있으며, 전체 객체 모델의 출력 데이터는 해당 복수의 포인트에 대하여 예측한 객체 유형(클래스) 정보일 수 있다. 또한, 객체 분류 장치는 대상 객체에 대응하는 복수의 포인트 각각의 객체 유형 별 확률 정보를 이용하여 대상 객체에 대한 제2객체 분류 정보를 도출할 수 있다. 구체적으로 객체 분류 장치는 복수의 포인트 각각의 객체 유형 별 확률 정보를 벡터 곱셈 및 정규화를 이 용하여 융합할 수 있다. 이와 관련하여, 대상 객체에 대응하는 경계 상자 내에 존재하는 복수의 포인트 각각에 대하여 할당된 객체 유형 정보를 기초로 단순히 가장 많은 수의 포인트에 대하여 할당된 객체 유형을 해당 대상 객체의 클래스로 예측하는 방식(Voting) 기반 방식)을 적용할 경우, 대상 객체에 대한 인식 결과가 부정확할 수 있으므로, 본원에서 개시하는 객체 분류 장치는 각각의 객체 유형(예를 들면, 승용차, 상용차, 이륜차, 자 전거, 보행자 등)에 대한 개별 포인트의 확률 정보를 나타내는 벡터를 포인트마다 정의하고, 복수의 포인트의 개수만큼 정의되는 복수의 벡터에 대한 정규화(regularization)를 수행함으로써 제2객체 분류 정보를 도출할 수 있다. 보다 구체적으로 예시하면, 개별 포인트의 객체 유형 확률을 반영하는 복수의 벡터에 대하여 적용되는 정규화 방식은 L1 Regularization, L2 Regularization, Dropout, Early stopping 등을 포함할 수 있으며, 예시적으로 개별 포인트에 대하여 생성되는 벡터는 승용차, 상용차, 이륜차, 자전거, 보행자 및 기타(Unknown) 클래스 순의 확률에 기초하여 [0.85, 0.01, 0.03, 0.01, 0.1, 0.1] 등의 형태로 정의될 수 있다. 또한, 본원에서 개시하는 객체 분류 장치는 제1객체 분류 정보 및 제2객체 분류 정보 중 적어도 하나에 기 초하여 대상 객체의 대표 객체 분류 정보를 출력할 수 있다. 구체적으로, 딥러닝 기반 방식을 통해 도출된 제1객체 분류 정보와 확률 기반 방식을 통해 도출된 제2객체 분류 정보가 일치하는 경우, 객체 분류 장치는 대표 객체 분류 정보를 해당 객체 분류로 확정할 수 있다. 이와 달리, 제1객체 분류 정보와 제2객체 분류 정보가 불일치하는 경우, 객체 분류 장치는 대상 객체에 대 하여 획득된 복수의 포인트의 개수, 대상 객체에 대하여 특정된 경계 상자의 내부에서 복수의 포인트가 위치하 는 분포 정도, 각각의 포인트에 대하여 할당된 객체 유형별 확률 정보의 평균값 등의 기준 정보를 이용하여 제1 객체 분류 정보 또는 제2객체 분류 정보로 대표 객체 분류 정보를 결정할 수 있다. 예시적으로, 개별 포인트에 대하여 할당된 객체 유형별 확률 값 중 가장 큰 확률 값(예를 들면, 전술한 [0.85, 0.01, 0.03, 0.01, 0.1, 0.1] 벡터의 경우, 0.85(85%)에 해당하는 확률 값)을 복수의 포인트 각각에 대하여 획 득하고, 획득한 최대 확률 값에 대한 평균이 미리 설정된 임계값(예를 들면, 0.75(75%) 등) 이상이면, 객체 분 류 장치는 개별 포인트에 대하여 할당된 확률 정보의 정확도가 상대적으로 높은 것으로 판단하여 제2객체 분류 정보를 제1객체 분류 정보 대비 우선하여 대표 객체 분류 정보로 결정할 수 있으나, 이에만 한정되는 것은아니다. 다른 예로, 경계 상자 내부에 포함된 복수의 포인트의 수가 미리 설정된 임계 개수 미만이면, 객체 분류 장치 는 개별 포인트에 대하여 할당된 확률 정보가 대상 객체 특성을 전체적으로 대표하기에 부적합한 것으로 판단하여, 제1객체 분류 정보를 제2객체 분류 정보 대비 우선하여 대표 객체 분류 정보로 결정할 수 있으나, 이 에만 한정되는 것은 아니다. 또한, 전술한 바와 같이 제1객체 분류 정보 및 제2객체 분류 정보를 개별 도출한 후 이를 종합하여 대표 객체 분류 정보를 도출하는 방식 외에도, 본원의 구현예에 따라서는 객체 분류 장치는 대상 객체에 대한 복수의 포인트를 포함하는 경계 상자가 특정된 후, 해당 경계 상자에 포함된 복수의 포인트의 개수, 대상 객체에 대하 여 특정된 경계 상자의 내부에서 복수의 포인트가 위치하는 분포 정도, 각각의 포인트에 대하여 할당된 객체 유 형별 확률 정보의 평균값 등의 기준 정보를 이용하여 딥러닝 기반 방식을 통해 제1객체 분류 정보를 도출하는 프로세스 또는 확률 기반 방식을 통해 제2객체 분류 정보를 도출하는 프로세스를 선택적으로 수행하도록 동작할 수 있다. 예시적으로, 개별 포인트에 대하여 할당된 객체 유형별 확률 값 중 가장 큰 확률 값(예를 들면, 전술한 [0.85, 0.01, 0.03, 0.01, 0.1, 0.1] 벡터의 경우, 0.85(85%)에 해당하는 확률 값)을 복수의 포인트 각각에 대하여 획 득하고, 획득한 최대 확률 값에 대한 평균이 미리 설정된 임계값(예를 들면, 0.75(75%) 등) 이상이면, 객체 분 류 장치는 개별 포인트에 대하여 할당된 확률 정보의 정확도가 상대적으로 높은 것으로 판단하여 확률 기 반 방식을 통해 제2객체 분류 정보를 도출하는 프로세스를 선택적으로 수행하는 것일 수 있으나, 이에만 한정되 는 것은 아니다. 다른 예로, 경계 상자 내부에 포함된 복수의 포인트의 수가 미리 설정된 임계 개수 미만이면, 객체 분류 장치 는 개별 포인트에 대하여 할당된 확률 정보가 대상 객체 특성을 전체적으로 대표하기에 부적합한 것으로 판단하여, 딥러닝 기반 방식을 통해 제1객체 분류 정보를 도출하는 프로세스를 선택적으로 수행하는 것일 수 있 으나, 이에만 한정되는 것은 아니다. 이하에서는 도 4를 참조하여 대상 객체를 촬영한 이미지 데이터와 포인트 클라우드 데이터를 이용한 캘리브레이 션을 수행한 후, 이미지 데이터로부터 전술한 시맨틱 정보를 획득하는 프로세스를 설명하도록 한다. 이와 관련 하여, 본원의 실시예에 관한 설명에서 시맨틱 정보는 대상 객체를 촬영한 이미지 데이터에 대한 의미론적 영역 분할(Semantic Segmentation)을 통해 획득되는 정보일 수 있다. 도 4는 포인트 클라우드 데이터와 이미지 데이터를 이용한 캘리브레이션 프로세스를 설명하기 위한 도면이다. 구체적으로 도 4의 (a)는 이미지 데이터를 이용하여 수직 객체를 인지한 결과를 나타내고, 도 4의 (b)는 포인트 클라우드 데이터를 이용하여 수직 객체를 인지한 결과를 나타낸다. 도 4를 참조하면, 객체 분류 장치는 수직 객체로 판단된 기준 객체에 대한 복수의 포인트와 기준 객체를 촬영한 이미지 데이터를 이용하여 라이다 센서 및 이미지 센서의 캘리브레이션을 수행할 수 있다. 구체적으로 객체 분류 장치는 동일한 수직 객체를 이미지 데이터를 이용하여 식별한 결과와 포인트 클라우 드 데이터를 이용하여 식별한 결과를 상호 비교하여 라이다 센서에 대하여 적용되는 좌표계와 이미지 센서 에 대하여 적용되는 좌표계 사이의 6자유도 회전, 병진 관계 등을 파악함으로써 캘리브레이션을 수행할 수 있다. 또한, 본원의 일 실시예에 따르면, 객체 분류 장치는 라이다 센서에 대하여 적용되는 좌표계와 이미 지 센서에 대하여 적용되는 좌표계 사이의 6자유도 회전, 병진 관계 등을 파악한 결과에 따라 라이다 센서 및 이미지 센서 중 적어도 하나가 대상 차량에 대하여 비정상적인 장착 상태에 해당하는지 여 부를 감지하고, 이러한 센서 모듈의 비정상 장착 상태에 대한 감지 결과를 사용자 단말 등으로 전송하도록 동작할 수 있다. 즉, 객체 분류 장치는 이미지 데이터 기반의 시맨틱 정보 획득시, 동일한 기준 객체에 대한 복수의 포인트 와 대상 객체를 촬영한 이미지 데이터를 이용하여 라이다 센서 및 이미지 센서의 캘리브레이션을 우 선적으로 수행한 후, 이미지 데이터를 기 보유한 인공지능 기반의 알고리즘(예를 들면, 딥러닝 기반의 YOLO v3 알고리즘 등)에 입력하여 대상 객체의 객체 유형(클래스)에 대한 예측(추정)을 수행함으로써 시맨틱 정보를 획 득할 수 있다. 예시적으로 포인트 클라우드 데이터와 이미지 데이터를 이용한 캘리브레이션을 수행하기 위한 기준 객체는 대상 영역에 위치하는 객체 중 특징이 뚜렷한 수직 객체로 판단된 객체로 설정될 수 있다. 이와 관련하여 객체 분류 장치는 대상 객체에 대한 복수의 포인트에 대하여 주성분 분석(Principal component analysis, PCA)을 수행하여 대상 객체에 대응하는 복수의 주성분 벡터를 도출하고, 복수의 주성분 벡 터 각각의 길이 정보 및 각도 정보 중 적어도 하나를 이용하여 수직 객체를 탐색할 수 있다. 구체적으로 객체 분류 장치는 복수의 포인트의 위치 정보를 이용하여 대상 객체의 추정 중심을 연산하고, 추정 중심을 고려한 대상 객체의 형상 정보를 기초로 하여 특정 객체가 수직 객체에 해당하는지 여부를 판단할 수 있다. 보다 구체적으로 본원의 일 실시예에 따르면, 객체 분류 장치는 대상 객체의 추정 중심 및 복수의 포인트 의 위치 정보를 이용하여 대상 객체의 반지름을 연산하고, 연산된 반지름을 미리 설정된 임계값과 비교함으로써, 특정 객체가 수직 객체에 해당하는지 여부를 판단할 수 있다. 또한, 본원의 일 실시예에 따르면, 객체 분류 장치는 복수의 주성분 벡터 중 적어도 하나의 길이 정보를 이용하여 대상 객체의 연장 길이를 연산하고, 대상 객체의 반지름 및 연장 길이의 비율을 미리 설정된 임계 비 율과 비교함으로써, 대상 객체가 수직 객체에 해당하는지 여부를 판단할 수 있다. 한편, 특정 객체에 대하여 도 출되는 복수의 주성분 벡터는 추정 중심을 원점으로 하는 제1주성분 벡터, 제2주성분 벡터 및 제3주성분 벡터를 포함할 수 있으며, 이 중 제1주성분 벡터는 길이가 가장 큰 벡터이고, 제2주성분 벡터는 중간 길이의 벡터이고, 제3주성분 벡터는 길이가 가장 작은 벡터로 특정될 수 있다. 또한, 본원의 일 실시예에 따르면, 객체 분류 장치는 제2주성분 벡터의 길이에서 제3주성분 벡터의 길이를 감산한 값과 제3주성분 벡터의 길이의 비율에 기초하여 연산되는 평탄성(Flattening) 정보를 기초로 하여 특정 객체가 수직 객체에 해당하는지 여부를 판단할 수 있다. 또한, 본원의 일 실시예에 따르면, 객체 분류 장치는 제1주성분 벡터의 길이와 제2주성분 벡터의 길이의 비율에 기초하여 연산되는 선형성(Linearity) 정보를 기초로 하여 대상 객체가 수직 객체에 해당하는지 여부를 판단할 수 있다. 또한, 본원의 일 실시예에 따르면, 객체 분류 장치는 제1주성분 벡터가 지면에 대하여 이루는 각도에 기초 하여 연산되는 수직성(Verticality) 정보를 기초로 하여 특정 객체가 수직 객체에 해당하는지 여부를 판단할 수 있다. 도 5는 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 장치의 개략적인 구성도이다. 도 5를 참조하면, 객체 분류 장치는 입력 획득부, 제1분류 수행부, 제2분류 수행부 및 객 체 결정부를 포함할 수 있다. 입력 획득부는 대상 객체에 대응하는 복수의 포인트를 포함하고, 대상 객체에 대한 시맨틱 정보를 포함하 는 포인트 클라우드 데이터를 획득할 수 있다. 제1분류 수행부는 대상 객체에 대응하는 복수의 포인트를 감싸는 경계 상자의 위치 정보, 대상 객체에 대 응하는 복수의 포인트 각각에 대한 피처 정보 및 시맨틱 정보를 이용하여 기 학습된 인공지능 기반의 객체 분류 모델을 통해 대상 객체에 대한 제1객체 분류 정보를 도출할 수 있다. 제2분류 수행부는 대상 객체에 대응하는 복수의 포인트 각각의 객체 유형 별 확률 정보를 이용하여 대상 객체에 대한 제2객체 분류 정보를 도출할 수 있다. 구체적으로 제2분류 수행부는 복수의 포인트 각각의 객체 유형 별 확률 정보를 벡터 곱셈 및 정규화를 이 용하여 융합할 수 있다. 객체 결정부는 제1객체 분류 정보 및 제2객체 분류 정보 중 적어도 하나에 기초하여 대상 객체의 대표 객 체 분류 정보를 출력할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 6은 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 방법에 대한 동작 흐름도이다. 도 6에 도시된 시맨틱 정보를 활용한 객체 분류 방법은 앞서 설명된 객체 분류 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 객체 분류 장치에 대하여 설명된 내용은 시맨틱 정보를활용한 객체 분류 방법에 대한 설명에도 동일하게 적용될 수 있다. 도 6을 참조하면, 단계 S11에서 입력 획득부는 대상 객체에 대응하는 복수의 포인트를 포함하고, 대상 객 체에 대한 시맨틱 정보를 포함하는 포인트 클라우드 데이터를 획득할 수 있다. 다음으로, 단계 S12에서 제1분류 수행부는 대상 객체에 대응하는 복수의 포인트를 감싸는 경계 상자의 위 치 정보, 대상 객체에 대응하는 복수의 포인트 각각에 대한 피처 정보 및 시맨틱 정보를 이용하여 기 학습된 인 공지능 기반의 객체 분류 모델을 통해 대상 객체에 대한 제1객체 분류 정보를 도출할 수 있다. 다음으로, 단계 S13에서 제2분류 수행부는 대상 객체에 대응하는 복수의 포인트 각각의 객체 유형 별 확률 정보를 이용하여 대상 객체에 대한 제2객체 분류 정보를 도출할 수 있다. 구체적으로 단계 S13에서 제2분류 수행부는 복수의 포인트 각각의 객체 유형 별 확률 정보를 벡터 곱셈 및 정규화를 이용하여 융합할 수 있다. 다음으로, 단계 S14에서 객체 결정부는 단계 S12에서 도출된 제1객체 분류 정보 및 단계 S13에서 도출된 제2객체 분류 정보 중 적어도 하나에 기초하여 대상 객체의 대표 객체 분류 정보를 출력할 수 있다. 상술한 설명에서, 단계 S11 내지 S14는 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로 그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프 로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이 프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같 은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 또한, 전술한 시맨틱 정보를 활용한 객체 분류 방법은 기록 매체에 저장되는 컴퓨터에 의해 실행되는 컴퓨터 프 로그램 또는 애플리케이션의 형태로도 구현될 수 있다."}
{"patent_id": "10-2023-0014638", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다."}
{"patent_id": "10-2023-0014638", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 장치를 포함하는 객체 분류 시스템의 개략적 인 구성도이다. 도 2는 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 장치의 동작 프로세스를 설명하기 위한 개념 도이다. 도 3은 인공지능 기반의 객체 분류 모델의 구조를 예시적으로 나타낸 개념도이다. 도 4는 포인트 클라우드 데이터와 이미지 데이터를 이용한 캘리브레이션 프로세스를 설명하기 위한 도면이다. 도 5는 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 장치의 개략적인 구성도이다. 도 6은 본원의 일 실시예에 따른 시맨틱 정보를 활용한 객체 분류 방법에 대한 동작 흐름도이다."}
