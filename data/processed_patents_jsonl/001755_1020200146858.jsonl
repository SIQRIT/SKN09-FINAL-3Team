{"patent_id": "10-2020-0146858", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0061312", "출원번호": "10-2020-0146858", "발명의 명칭": "레일로봇장치가 구비된 딥러닝 기반의 건물 관리 시스템", "출원인": "덕산메카시스 주식회사", "발명자": "강대경"}}
{"patent_id": "10-2020-0146858", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "에 따른 건물 모니터링 시스템을 이용하는 방법으로서, 상기 통합서버(300)는, 실화상영상을 구성하는 실화상영상 프레임을 통해, 대상영역의 홍수발생 여부를 판단하는, 제2 판단모듈(320); 을 더 포함하고, (B1) 제2 판단학습부(322)에, 학습용 실화상영상 프레임이 입력되는 단계로서, 상기 학습용 실화상영상 프레임은, 기설정된 블록으로 구획되되, 정상영역 및 홍수영역이 구분된 상태로 입력된 후, 기설정된 방식에 의해, 홍수영역이 학습되는 단계(S210); (B2) 상기 레일로봇장치(200)로부터 실화상영상이 상기 제2 판단모듈(320)로 전송되는 단계(S220); (B3) 상기 제2 판단모듈(320)에 의해, 상기 실화상영상을 구성하는 실화상영상 프레임을 기설정된 블록으로 구획하는 단계로서, 상기 (B1) 단계에서, 학습된 연기영역을 이용하여, 상기 기설정된 블록 중 홍수영역에 해당되는 영역을 블록그룹으로 구분한 후, 상기 블록그룹에 대해 가장자리부를 생성하는 단계(S230); (B4) 상기 (B3) 단계에서, 상기 실화상영상 프레임에서, 복수의 블록그룹이 형성될 경우, 각각의 블록그룹에 대해 생성된 가장자리부를 비교하되, 제1 블록그룹 및 제2 블록그룹 각각의 가장자리부가 겹치는 경우, 상기 제1및 제2 블록그룹을 병합하여 홍수영역을 생성하는 단계(S240); 및 (B5) 상기 (B4) 단계에서 생성된 홍수영역의 면적 및 물의 양을 기설정된 방식에 의해, 연산하는 단계(S250);를 포함하는, 방법."}
{"patent_id": "10-2020-0146858", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 따른 건물 모니터링 시스템을 이용하는 방법으로서, 상기 통합서버(300)는, 실화상영상을 구성하는 실화상영상 프레임을 통해, 대상영역의 연기발생 여부를 판단하는, 제1 판단모듈(310);을 더 포함하고, (A1) 제1 판단학습부(312)에, 학습용 실화상영상 프레임이 입력되는 단계로서, 상기 학습용 실화상영상 프레임은, 기설정된 블록으로 구획되되, 비연기영역 및 연기영역이 구분된 상태로 입력된 후, 기설정된 방식에 의해,연기영역이 학습되는 단계(S110); (A2) 상기 레일로봇장치(200)로부터 실화상영상이 상기 제1 판단모듈(310)로 전송되는 단계(S120); (A3) 상기 제1 판단모듈(310)에 의해, 상기 실화상영상을 구성하는 실화상영상 프레임을 기설정된 블록으로 구획하는 단계로서, 상기 (A1) 단계에서, 학습된 연기영역을 이용하여, 상기 기설정된 블록 중 연기영역에 해당되는 영역을 블록그룹으로 구분한 후, 상기 블록그룹에 대해 가장자리부를 생성하는 단계(S130); (A4) 상기 (A3) 단계에서, 상기 실화상영상 프레임에서, 복수의 블록그룹이 형성될 경우, 각각의 블록그룹에 대해 생성된 가장자리부를 비교하는 단계(S140); (A5) 상기 (A4) 단계에서, 제1 블록그룹 및 제2 블록그룹 각각의 가장자리부가 겹치는 경우, 상기 제1 및 제2블록그룹을 병합하여 연기영역을 생성하는 단계(S150); 및 (A6) 상기 실화상영상에 포함된 제1 내지 제N 실화상영상 프레임에 대해 상기 (A3) 내지 (A5) 단계를 반복하여수행하는 단계(S160); 를 포함하는, 방법. 공개특허 10-2022-0061312-3-청구항 3"}
{"patent_id": "10-2020-0146858", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 따른 건물 모니터링 시스템을 이용하는 방법으로서, 실화상영상을 구성하는 실화상영상 프레임을 통해, 이벤트발생여부를 판단하는 제3 판단모듈(330)로서, 상기 이벤트발생은 대상영역의 화재발생 여부, 불꽃발생 여부 및 침입자발생인, 제3 판단모듈(330); 을 더 포함하고, (C1) 제3 판단학습부(332)에, 학습용 실화상영상 프레임이 입력되는 단계로서, 상기 학습용 실화상영상 프레임은, 딥러닝(deep learning) 기반 심층신경망 모델의 학습이 수행되는 단계(S310); (C2) 상기 (C1) 단계에 의해, 상기 이벤트발생여부에 대한 심층신경망 모델이 형성되는 단계(S320); (C3) 상기 레일로봇장치(200)로부터 실화상영상이 상기 제3 판단모듈(330)로 전송되는 단계로서, 상기 (C2) 단계에 생성된 심층신경망 모델에 상기 실화상영상이 입력되는 단계(S330); 및 (C4) 상기 심층신경망 모델은, 상기 (C3) 단계에서 입력된 실화상영상에 대해, 최종 출력층의 노드를 상이하게형성함으로써, 화재발생, 불꽃발생 및 침입자발생 여부를 판단하는 단계(S340); 를 포함하며, 상기 이벤트발생은, 침입자발생, 화재발생 및 불꽃발생 순서로 관심영역의 범위가 작게 설정되고, 상기 (C4) 단계는, 상기 관심영역의 범위가 작게 설정될수록, 최종 출력층의 노드값은 더 크게 설정된, 방법."}
{"patent_id": "10-2020-0146858", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서, (C5) 상기 이벤트발생으로 판단된 실화상영상 및 상기 열화상카메라모듈(220)로부터 취득된 열화상영상을 비교하는 단계로서, 상기 실화상영상 중 상기 이벤트발생으로 판단된 영역 및 상기 열화상영상에서의 영역별 온도정보를 매칭시킴으로써, 상기 이벤트발생 여부를 판단하는 단계(S350); 를 더 포함하는, 공개특허 10-2022-0061312-4-방법."}
{"patent_id": "10-2020-0146858", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 4에 있어서, 상기 심층신경망 모델은, YOLO(You Only Look Once)의 네트워크 구조를 기반으로, 상기 학습용 실화상영상 프레임을 통해, 학습하는, 방법."}
{"patent_id": "10-2020-0146858", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서, 상기 레일로봇장치(200)는, 위치센서(240)를 더 포함하고, 상기 위치센서(240)로부터 획득된 위치정보는 상기 통신모듈(230)을 통해, 상기통합서버(300)로 전송되고, 상기 통합서버(300)는, 대상영역의 도면정보, 상기 레일의 설계정보 및 상기 대상영역에 구비된 설비의 위치정보가 미리 입력되어 있으며, 상기 도면정보 상에 상기 레일로봇장치(200)의 이동정보를 맵핑하는 맵핑모듈(340); 을 더 포함하며, 상기 건물 모니터링 시스템은, 상기 맵핑모듈(340)로부터 전송된 상기 레일로봇장치(200)의 이동정보를 시각적으로 표시하는 디스플레이부(400); 를 더 포함하며, 상기 디스플레이부(400)를 통해, 상기 레일로봇장치(200)의 이동정보, 상기 대상영역에서의 연기발생 여부, 홍수판단 여부, 화재발생 여부, 불꽃발생 여부 및 침입자발생 여부 중 적어도 하나를 제공하는, 건물 모니터링 시스템."}
{"patent_id": "10-2020-0146858", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서, 상기 레일로봇장치(200)는, 상기 레일(100) 상에 이동 가능하도록 결합되며, 상기 레일(100)에 구비된 전원부(120)로부터 전원을 공급받는,구동부(250); 및 상기 실화상카메라모듈(210) 및 열화상카메라모듈(220)이 구비된 촬영부(260); 로 구성되며, 상기 구동부(250)의 전방 및 후방에는 근접센서(252)가 구비되고, 상기 촬영부(260)는, 수평방향을 기준으로, 360도 회전가능하도록 구성되며, 상하방향으로 촬영각도의 조절이가능하도록 구성된, 건물 모니터링 시스템."}
{"patent_id": "10-2020-0146858", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서, 공개특허 10-2022-0061312-5-상기 레일로봇장치(200)의 통신모듈(230)은, 대상영역 내의 소정의 거리에 있는 개인단말기(500)와 무선연결되도록 구성되고, 상기 건물 모니터링 시스템은, 상기 레일로봇장치(200)로부터 취득된 실화상영상 및 열화상영상의 상기 통합서버(300)로의 전송을 중계하는 중계기부(600)가 구비되며, 상기 개인단말기(500)는, 상기 중계기부(600)를 통해, 무선네트워크망과 연결됨으로써, 상기 통합서버(300)로부터 정보를 송수신하도록구성된, 건물 모니터링 시스템."}
{"patent_id": "10-2020-0146858", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 1에 있어서, 상기 열화상카메라모듈(220)은, 대상영역의 영역별 온도정보를 기설정된 방식으로 이용하여, 상기 대상영역 내의 화재발생 여부, 불꽃발생여부, 설비의 이상발생 여부 및 침입자발생 여부를 판단하는, 건물 모니터링 시스템."}
{"patent_id": "10-2020-0146858", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 천장에 미리 설치된 레일을 따라 이동하는 레일로봇장치를 이용하는 건물 모니터링 시스템으로서, 모니터링 대상이 되는 설비의 위치를 기반으로, 천장 측에 미리 설계된 상기 레일; 실화상카 메라모듈 및 열화상카메라모듈을 구비하는 상기 레일로봇장치로서, 상기 레일을 궤도로 하 (뒷면에 계속)"}
{"patent_id": "10-2020-0146858", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 레일로봇장치가 구비된 딥러닝 기반의 건물 관리 시스템에 관한 기술이다."}
{"patent_id": "10-2020-0146858", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "주택, 아파트, 상가, 상업용 빌딩, 공장, 대형 창고 등의 건물에는 각종 현장 장비, 즉 각종 전기설비, 가스설 비, 냉난방설비, 급수설비, 통신설비, 보안설비, 공조설비, 각종 개폐설비 등의 장비들의 설치된다. 이러한 장 비들의 작동 상태를 확인하기 위하여, 종래에는 관리자가 직접 현장 장비들을 육안으로 살펴 보거나, 현장 장비 를 촬영할 수 있는 고정식 카메라를 설치하여 모니터링하는 것이 일반적이었다. 그러나, 관리자가 직접 현장 장비들을 육안으로 살펴 보는 것은, 관측 시간이 매우 길어지고, 관리에 소요되는 인원이 증가되는 등의 비경제적인 문제점이 있다. 고정식 카메라를 사용할 경우, 관측 대상인 현장 장비의 종류 나 개수가 많아질수록 필요한 카메라의 개수 역시 증대되는 바, 이 역시 매우 비경제적이며, 현실적으로 고정식 카메라는 관측의 사각지대가 존재할 수 있는 바, 관측의 사각지대에서 발생되는 이벤트에 대해 즉각 대응할 수 없는 치명적인 문제가 존재한다. 아울러, 하나의 고정식 카메라로 촬영할 수 있는 관측 영역 역시, 해상도나 현장 설비와의 거리 등에 따라 한계 가 있어서, 보다 정밀하고 보다 정확한 관측이 어려웠었던 문제점이 있었다. 한편, 최근에는 영상분석 기술이 발달함에 따라, 건물의 이벤트 상황을 관리하고, 이에 대한 대처를 하기 위해, 다양한 영상분석 기술이 적용되고 있다. 지능형 영상분석 기술은 영상의 정보를 분석하여 자동으로 이상 행위, 물체를 탐지하고 관리자에게 경보를 전송 하는 기술로써, 사고를 사전에 예방할 수도 있으며, 사고가 발생한 경우에는 신속하게 대응하여 피해를 줄일 수 있다. 이러한 영상분석을 이용하여 사전 정의된 이벤트가 발생될 때, 관리자에게 경보를 생성하여 알려주는 바, 모든 영상을 지속적으로 감시하지 않고, 경보가 발생할 때 해당 화면을 보고 실시간으로 상황을 판단하고 대처하면 된다. 이와 같이, 지능형 영상분석 기술을 사용할 경우, 건물의 관리가 용이하며, 사람의 육안으로 판단하는 것에 비 해, 이벤트 상황을 더욱 정확하게 진단할 수 있는 바, 사고의 사전예방이 가능할 뿐만 아니라, 사고의 발생시에 도 신속하게 인지하여 대응함으로써, 피해를 최소화할 수 있다. 지능형 영상분석 기술을 이용하여 건물을 관리하는 종래기술로는, 한국등록특허 제10-2096175호가 개시된다. 상 기 종래기술은 '천장 레일형 IoT 기반 감시 로봇 장치'로서, 실화상, 열화상 적외선 카메라 영상을 촬영하고, 이를 인공지능 서버로 전송한 후, 합성곱신경망(CNN)을 이용하여 영상의 정상/비정상 여부를 판단하는 구성을 개시한다. 다만, 상기 종래기술은 특정 재난상황(예로, 홍수, 누수, 연기발생, 화재, 스파크 발생)에 최적화된 영상분석 방법을 개시하지는 않고, 합성곱신경망(CNN)을 이용하는 바, 매우 많은 영상 및 작업시간이 수반되어 비용의 측면에서 경제적이지 않다는 단점이 존재한다. 이에 따라, 최근에는, 고정식 카메라가 아닌, 이동식 카메라를 이용하여 실시간으로 촬영된 영상을 전송받고, 상기 영상을 딥러닝을 이용하여 분석하되, 특정 재난상황인 홍수, 누수, 연기발생, 화재 및 스파크 발생 각각에 대해 최적화된 영상분석 기술의 필요성이 증대되는 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-2096175호"}
{"patent_id": "10-2020-0146858", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 종래 기술의 문제점을 해결하기 위해 안출된 것이다. 본 발명은 건물의 설비가 위치된 공간에는 많은 전기장치 또는 설비장치들이 구비되는 바, 이러한 설비들을 보 호함과 동시에, 상기 공간으로의 사람 출입을 최소화함으로써, 사고의 위험으로부터 관리자를 보호하기 위한 기 술을 제안하고자 한다. 또한, 본 발명은 건물의 설비가 위치된 공간을 감시자가 직접 모니터링할 경우, 감시자에 따른 편차가 존재하며, 가령, 누수와 관련하여 소량의 물을 사람이 확인하는 것은 매우 부정확한 바, 사고의 초기 단계부터 사고를 감지할 수 있는 기술을 제안하고자 한다."}
{"patent_id": "10-2020-0146858", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 천장에 미리 설치된 레일을 따라 이동하는 레일로봇장치를 이용하는 건물 모니터링 시스템으로 서, 모니터링 대상이 되는 설비의 위치를 기반으로, 천장 측에 미리 설계된 상기 레일; 실화상카메라모듈 및 열화상카메라모듈을 구비하는 상기 레일로봇장치로서, 상기 레일을 궤도로 하여 기설 정된 규칙에 따라 운행되며, 상기 실화상카메라모듈 및 상기 열화상카메라모듈로부터 대상영역에 대 한 실화상영상 및 열화상영상을 각각 획득하고, 획득된 상기 실화상영상 및 열화상영상을 무선 또는 유선으로 전송하는 통신모듈이 구비된, 레일로봇장치; 및 상기 레일로봇장치의 통신모듈로부터 전송 된 실화상영상 및 열화상영상을 기설정된 인공지능방식으로 분석하는 통합서버; 를 포함하며, 상기 통합서 버는, 인공지능방식 중 심층신경망(Deep Neural Network, DNN)을 이용하여, 실화상영상 및 열화상영상을 분석하되, 상기 실화상영상 및 열화상영상을 통해, 건물의 대상영역의 연기발생 여부, 홍수판단 여부, 화재발생 여부, 불꽃발생 여부 및 침입자발생 여부 중 적어도 하나를 판단하는, 건물 모니터링 시스템을 제공한다. 또한, 본 발명은 전술한 건물 모니터링 시스템을 이용하는 방법으로서, 상기 통합서버는, 실화상영상을 구 성하는 실화상영상 프레임을 통해, 대상영역의 연기발생 여부를 판단하는, 제1 판단모듈; 을 더 포함하고, (A1) 제1 판단학습부에, 학습용 실화상영상 프레임이 입력되는 단계로서, 상기 학습용 실화상영상 프레임은, 기설정된 블록으로 구획되되, 비연기영역 및 연기영역이 구분된 상태로 입력된 후, 기설정된 방식에 의해, 연기영역이 학습되는 단계(S110); (A2) 상기 레일로봇장치로부터 실화상영상이 상기 제1 판단모듈로 전송되는 단계(S120); (A3) 상기 제1 판단모듈에 의해, 상기 실화상영상을 구성하는 실화상영상 프레임을 기설정된 블록으로 구획하는 단계로서, 상기 (A1) 단계에서, 학습된 연기영역을 이용하여, 상기 기설정된 블록 중 연기영역에 해당되는 영역을 블록그룹으로 구분한 후, 상기 블록그룹에 대해 가장자리부를 생성하는 단계 (S130); (A4) 상기 (A3) 단계에서, 상기 실화상영상 프레임에서, 복수의 블록그룹이 형성될 경우, 각각의 블록 그룹에 대해 생성된 가장자리부를 비교하는 단계(S140); (A5) 상기 (A4) 단계에서, 제1 블록그룹 및 제2 블록그 룹 각각의 가장자리부가 겹치는 경우, 상기 제1 및 제2 블록그룹을 병합하여 연기영역을 생성하는 단계(S150); 및 (A6) 상기 실화상영상에 포함된 제1 내지 제N 실화상영상 프레임에 대해 상기 (A3) 내지 (A5) 단계를 반복하 여 수행하는 단계(S160); 를 포함하는, 방법을 제공한다. 또한, 본 발명은 전술한 건물 모니터링 시스템을 이용하는 방법으로서, 상기 통합서버는, 실화상영상을 구 성하는 실화상영상 프레임을 통해, 대상영역의 홍수발생 여부를 판단하는, 제2 판단모듈; 을 더 포함하고, (B1) 제2 판단학습부에, 학습용 실화상영상 프레임이 입력되는 단계로서, 상기 학습용 실화상영상 프레임 은, 기설정된 블록으로 구획되되, 정상영역 및 홍수영역이 구분된 상태로 입력된 후, 기설정된 방식에 의해, 홍 수영역이 학습되는 단계(S210); (B2) 상기 레일로봇장치로부터 실화상영상이 상기 제2 판단모듈로 전 송되는 단계(S220); (B3) 상기 제2 판단모듈에 의해, 상기 실화상영상을 구성하는 실화상영상 프레임을 기 설정된 블록으로 구획하는 단계로서, 상기 (B1) 단계에서, 학습된 연기영역을 이용하여, 상기 기설정된 블록 중 홍수영역에 해당되는 영역을 블록그룹으로 구분한 후, 상기 블록그룹에 대해 가장자리부를 생성하는 단계 (S230); (B4) 상기 (B3) 단계에서, 상기 실화상영상 프레임에서, 복수의 블록그룹이 형성될 경우, 각각의 블록 그룹에 대해 생성된 가장자리부를 비교하되, 제1 블록그룹 및 제2 블록그룹 각각의 가장자리부가 겹치는 경우, 상기 제1 및 제2 블록그룹을 병합하여 홍수영역을 생성하는 단계(S240); 및 (B5) 상기 (B4) 단계에서 생성된 홍 수영역의 면적 및 물의 양을 기설정된 방식에 의해, 연산하는 단계(S250); 를 포함하는, 방법을 제공한다. 또한, 본 발명은 전술한 건물 모니터링 시스템을 이용하는 방법으로서, 실화상영상을 구성하는 실화상영상 프레 임을 통해, 이벤트발생여부를 판단하는 제3 판단모듈로서, 상기 이벤트발생은 대상영역의 화재발생 여부, 불꽃발생 여부 및 침입자발생인, 제3 판단모듈; 을 더 포함하고, (C1) 제3 판단학습부에, 학습용 실 화상영상 프레임이 입력되는 단계로서, 상기 학습용 실화상영상 프레임은, 딥러닝(deep learning) 기반 심층신 경망 모델의 학습이 수행되는 단계(S310); (C2) 상기 (C1) 단계에 의해, 상기 이벤트발생여부에 대한 심층신경 망 모델이 형성되는 단계(S320); (C3) 상기 레일로봇장치로부터 실화상영상이 상기 제3 판단모듈로 전송되는 단계로서, 상기 (C2) 단계에 생성된 심층신경망 모델에 상기 실화상영상이 입력되는 단계(S330); 및 (C4) 상기 심층신경망 모델은, 상기 (C3) 단계에서 입력된 실화상영상에 대해, 최종 출력층의 노드를 상이하게 형성함으로써, 화재발생, 불꽃발생 및 침입자발생 여부를 판단하는 단계(S340); 를 포함하며, 상기 이벤트발생 은, 침입자발생, 화재발생 및 불꽃발생 순서로 관심영역의 범위가 작게 설정되고, 상기 (C4) 단계는, 상기 관심 영역의 범위가 작게 설정될수록, 최종 출력층의 노드값은 더 크게 설정된, 방법을 제공한다. 또한, (C5) 상기 이벤트발생으로 판단된 실화상영상 및 상기 열화상카메라모듈로부터 취득된 열화상영상을 비교하는 단계로서, 상기 실화상영상 중 상기 이벤트발생으로 판단된 영역 및 상기 열화상영상에서의 영역별 온 도정보를 매칭시킴으로써, 상기 이벤트발생 여부를 판단하는 단계(S350); 를 더 포함할 수 있다. 또한, 상기 심층신경망 모델은, YOLO(You Only Look Once)의 네트워크 구조를 기반으로, 상기 학습용 실화상영 상 프레임을 통해, 학습할 수 있다. 또한, 상기 레일로봇장치는, 위치센서를 더 포함하고, 상기 위치센서로부터 획득된 위치정보는 상기 통신모듈을 통해, 상기 통합서버로 전송되고, 상기 통합서버는, 대상영역의 도면정보, 상 기 레일의 설계정보 및 상기 대상영역에 구비된 설비의 위치정보가 미리 입력되어 있으며, 상기 도면정보 상에 상기 레일로봇장치의 이동정보를 맵핑하는 맵핑모듈; 을 더 포함하며, 상기 건물 모니터링 시스템은, 상기 맵핑모듈로부터 전송된 상기 레일로봇장치의 이동정보를 시각적으로 표시하는 디스플레이부 ; 를 더 포함하며, 상기 디스플레이부를 통해, 상기 레일로봇장치의 이동정보, 상기 대상영역에 서의 연기발생 여부, 홍수판단 여부, 화재발생 여부, 불꽃발생 여부 및 침입자발생 여부 중 적어도 하나를 제공 할 수 있다. 또한, 상기 레일로봇장치는, 상기 레일 상에 이동 가능하도록 결합되며, 상기 레일에 구비된 전 원부로부터 전원을 공급받는, 구동부; 및 상기 실화상카메라모듈 및 열화상카메라모듈이구비된 촬영부; 로 구성되며, 상기 구동부의 전방 및 후방에는 근접센서가 구비되고, 상기 촬영 부는, 수평방향을 기준으로, 360도 회전가능하도록 구성되며, 상하방향으로 촬영각도의 조절이 가능하도록 구성될 수 있다. 또한, 상기 레일로봇장치의 통신모듈은, 대상영역 내의 소정의 거리에 있는 개인단말기와 무선 연결되도록 구성되고, 상기 건물 모니터링 시스템은, 상기 레일로봇장치로부터 취득된 실화상영상 및 열화 상영상의 상기 통합서버로의 전송을 중계하는 중계기부가 구비되며, 상기 개인단말기는, 상기 중계기부를 통해, 무선네트워크망과 연결됨으로써, 상기 통합서버로부터 정보를 송수신하도록 구성될 수 있다. 또한, 상기 열화상카메라모듈은, 대상영역의 영역별 온도정보를 기설정된 방식으로 이용하여, 상기 대상영 역 내의 화재발생 여부, 불꽃발생 여부, 설비의 이상발생 여부 및 침입자발생 여부를 판단할 수 있다."}
{"patent_id": "10-2020-0146858", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같은 본 발명은 다음과 같은 효과가 있다. 본 발명은 건물의 설비가 위치된 공간에는 많은 전기장치 또는 설비장치들이 구비되는 바, 이러한 설비들을 보 호함과 동시에, 상기 공간으로의 사람 출입을 최소화함으로써, 사고의 위험으로부터 관리자를 보호할 수 있다. 또한, 건물의 설비가 위치된 공간을 감시자가 직접 모니터링할 경우, 감시자에 따른 편차가 존재하며, 가령, 누 수와 관련하여 소량의 물을 사람이 확인하는 것은 매우 부정확한 바, 사고의 초기 단계부터 사고를 감지할 수 있다."}
{"patent_id": "10-2020-0146858", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명에 따른 건물 모니터링 시스템을 설명한다. 본 발명은 건물의 종류와는 무관하게 모두 적용 가능한 기술로써, 무인화를 통해, 판단의 정확성 및 신속성을 증대시키는 기술이다. 예를 들어, 관리 자가 직접 상주하여 모니터링하기 어려운, 지하 전력구, 변전설비, 의료시설, 통제지역, 철도역사 등과 같은 모 든 장소에 적용될 수 있음을 미리 명시한다. 이하에서 사용되는 '대상영역'이라는 용어는 후술하는 레일로봇장치를 이용하여 모니터링 가능한 영역을 의미한다. 예를 들어, 지하설비실에 레일 및 레일로봇장치가 설치된 경 우, 지하설비실 전체의 공간을 의미한다. 대상영역 내의 일 공간에 모니터링 대상이 되는 설비가 위치되는 바, 대상영역 및 모니터링 대상은 개념적으로 구분된다. 건물 모니터링 시스템의 구성 도 1 및 2를 참조하여, 본 발명에 따른 건물 모니터링 시스템을 설명한다. 건물 모니터링 시스템은, 크게 레일, 레일로봇장치, 통합서버 및 디스플레이부로 구성된다. 레일은 모니터링 대상이 되는 설비의 위치를 기반으로 설계되며, 레일로봇장치가 주행하는 궤도의 역 할을 수행한다. 레일은 대상영역의 천장 측에 설치되는 것이 바람직하다. 다만, 천장이 아니더라도, 기설 치된 배관 등에 결합되도록 구성될 수도 있으며, 대상영역의 모니터링이 가능한 배치라면, 어느 위치라도 가능 하다. 일 예시로, 레일은 최대 25도의 경사도를 갖도록 구성될 수 있고, 곡률반경은 1000mm, 레일의 최대길이는 1Km 미만으로 구성될 수 있다. 레일로봇장치는 무인으로 레일을 주행하면서, 대상영역을 모니터링하는 장치이다. 기설정된 규칙에 따라, 운행되며, 관리자의 설정에 따라, 순차적 순회감시를 수행하는 자동순찰모드를 수행할 수 있다. 또한, 순 찰구간설정 및 이동속도의 조절도 가능하다. 레일로봇장치는 실화상카메라모듈 및 열화상카메라모듈 을 구비한다. 실화상카메라모듈은 실시간으로 대상영역을 촬영하여 실화상영상을 제공한다. 일 예로, 실화상카메라모듈 의 해상도는 1920*1080, 10Hz로 형성될 수 있다. 열화상카메라모듈은 온도분석을 통해, 화재 및 설비 의 이상징후를 감시함과 동시에, 인체의 열까지 감시할 수 있다. 일 예로, 17um pitch의 열상 검출기에서 7.5 내지 13.5um 파장의 적외선을 검출하여 열의 강도에 따른 색상의 변화로 온도를 시각적으로 표현할 수 있다. 적 용 해상도는 336*254, 10Hz로 형성될 수 있다. 또한, 레일로봇장치는 통신모듈을 더 포함한다. 통신모듈은 실화상카메라모듈 및 열화상카 메라모듈로부터 대상영역에 대한 실화상영상 및 열화상영상을 각각 획득하고, 획득된 실화상영상 및 열화 상영상을 무선 또는 유선으로 전송하도록 구성된다. 이 때, 통신모듈은 Wi-Fi모듈로 구성될 수 있는 바, 실화상영상 및 열화상영상을 무선으로 관리자 또는 사용자의 개인단말기로 전송할 수 있다. 또한, 통신모 듈은 후술하는 중계기부와 영상정보를 송수신하도록 구성되는 바, 실화상영상 및 열화상영상을 통합 서버로 전송 가능하도록 구성된다. 레일로봇장치는 음성통화모듈(미도시)을 더 포함할 수 있으며, 음성통화모듈을 통해, 중앙관제실 및/또는 관리자와 음성통화가 가능하도록 구성되는 것이 바람직하다. 대상영역에서(예로, 지하층), 작업자의 개인단말기 사용이 제한된 경우, 매우 유용하게 사용될 수 있는 기능이다. 도 5를 참조하여, 레일로봇장치에 대해 보다 자세히 설명하며, 도 5에는 레일로봇장치의 구성들을 도 시하며, 각각의 기능에 따라, 구분하고 있다. 레일로봇장치는 구동부 및 촬영부로 구분된다. 구동부는 전원부, 센서그룹, 모터그룹, 메인보드모듈, 배터리그룹으로 구분될 수 있다. 메인보드모듈에서는 소정의 연산처리가 수행되며, 중계기부로 영상정보들을 송신하도록 구 성됨과 동시에, 중계기부를 통해 제어명령이 입력되도록 구성되며, 상기 제어명령에 따라, 레일로봇장치 의 동작이 제어된다. 또한, 메인보드모듈에는 스케줄저장부(미도시)가 더 포함될 수 있다. 스케줄저 장부에는 레일로봇장치의 운행시간, 운행방식 등에 대한 정보가 미리 저장될 수도 있고, 관리자에 의해, 수정 가능할 수도 있다. 스케줄저장부에 저장된 정보를 바탕으로, 레일로봇장치는 구동된다. 레일로봇장치는 롤러를 통해, 레일에 장착되며, 롤러는 4륜 구동방식이며, 일 예로, 직경 이 50mm Wheel 우레탄재질을 사용하여 등판능력을 향상시킬 수 있다. 또한, 모터그룹은 고성능 BLDC 모터 및 구동 드라이버를 적용할 수 있고, 일 예시로, 75W 출력의 모터 및 24V/3.6A 구동 드라이버를 적용할 수 있다. 이를 통해, 레일로봇장치는 1m/sec의 속도로 주행 가능하되, 가변 주행이 가능하도록 구성될 수 있 다. 또한, 레일로봇장치 중 구동부의 전방 및 후방에는 각각 근접센서가 구비될 수 있다. 근접센서 를 통해, 레일로봇장치는 레일 끝에 도달시, 자동으로 정지할 수 있으며, 주행하는 과정에서 레 일의 중간에 물체가 있을 경우, 자동으로 정지하도록 구성될 수 있다. 레일로봇장치에는 위치센서가 내장된다. 위치센서는 고성능 엔코더(Encoder) 및 바코드(Barcode)를 포함함으로써, 엔코더를 통해 실시간 위치를 계산하고, 바코드를 통해 절대위치를 계산한 후, 이러한 위치정보 를 통신모듈을 통해 통합서버로 전송하도록 구성된다. 통합서버는 레일로봇장치의 통신모듈로부터 전송된 실화상영상 및 열화상영상을 기설정된 인공 지능방식으로 분석하도록 구성된다. 구체적으로, 통합서버는 제1 내지 제3 판단모듈(310, 320, 330) 및 맵핑모듈을 포함한다. 여기서, 본 원발명에 따른 건물 모니터링 시스템은 인공지능방식인 심층신경망(Deep Neural Network, DNN) 및/또는 합성곱 신경망(Convolutional neural network, CNN)을 이용하는 바, 학습의 선행이 필요하다. 이에 제1 내지 제3 판단 모듈은 각각 대응되는 제1 내지 제3 판단학습부(312, 322, 332)를 포함한다. 통합서버는 통신모듈로부터 전송된 실화상영상 및 열화상영상을 통해, 건물의 대상영역의 연기발생 여부, 홍수판단 여부, 화재발생 여부, 불꽃발생 여부 및 침입자발생 여부를 판단할 수 있으며, 이에 대해서는 후술하도록 한다. 통합서버는 대상영역의 도면정보, 레일의 설계정보(레일의 배치정보) 및 대상영역에 구비된 설비의 위치정 보가 미리 입력되어 있으며, 도면정보 상에 레일로봇장치의 이동정보를 맵핑하는 맵핑모듈을 포함한 다. 즉, 맵핑모듈을 통해, 레일로봇장치의 동선을 실시간으로 생성한다. 레일로봇장치의 이동정 보는 통합서버에 누적하여 저장되는 바, 관리자 내지 사용자는 통합서버로부터 원하는 시간의 동선정 보를 로딩할 수 있다. 이 때, 건물 모니터링 시스템은 맵핑모듈로부터 전송된 레일로봇장치의 이동정 보를 시각적으로 표시하는 디스플레이부를 더 포함하는 바, 상기 디스플레이부를 통해, 관리자 내지 사용자에게 레일로봇장치의 이동정보, 상기 대상영역에서의 연기발생 여부, 홍수판단 여부, 화재발생 여부, 불꽃발생 여부 및 침입자발생 여부를 제공할 수 있다. 디스플레이부는 별도의 공간인 건물의 중앙관 제실에 구비될 수 있으며, 디스플레이부를 통해, 관리자에게 알람을 제공할 수 있다. 다만, 상기의 정보들 은 관리자 내지 사용자의 개인단말기로도 제공될 수 있는 바, 개인단말기가 디스플레이부의 기 능을 수행할 수도 있다. 전술한 바와 같이, 디스플레이부는 설치된 레일을 도식화하며, 레일로봇장치의 현재위치 및 개 별 설비들의 마지막 상태값을 표시할 수 있다. 또한, 최근 1시간 동안의 온도변화를 그래프로 제공하며, 디스플 레이부 상의 최고온도 및 평균온도 역시 기록하여 표시한다. 또한, 통합서버에는 모니터링 대상이 되는 설비의 정보가 더 저장된다. 구체적으로, 각 설비마다 정상온도 의 범위가 개별적으로 설정되며, 설비의 특성에 따라, 모니터링이 필요한 구체적인 방식이 상이할 수 있는 바, 레일로봇장치의 촬영부의 각도, 상승높이 등에 대한 정보가 개별 설비에 최적화되도록 설정된다. 통합서버는 보고서생성모듈(미도시)을 더 포함할 수 있다. 보고서생성모듈은 레일로봇장치의 자동운 행기록을 기반으로, 기설정된 양식에 따라, 관리자에게 보고서를 제공한다. 또한, 통합서버는 자가진단모 듈(미도시)을 더 포함할 수 있다. 레일로봇장치의 자가진단을 통해, 레일의 각 위치마다, 전원공급 및 통신상태를 기록하여 그래프화시켜 관리자에게 제공하며, 전원공급 및 통신상태가 불량한 특정위치는 자동으 로 운행을 회피하도록 설정될 수 있다. 일 예시로, 레일로봇장치의 운행 중 통신불능위치일 경우, 빠르게 해당 위치를 탈출한 후, 다음 제어명령을 대기하도록 설계될 수 있다. 한편, 관리자 및 사용자(또는 작업자)의 편의를 위해, 본 발명에 따른 건물 모니터링 시스템은 이들의 개인단말 기와 무선연결되도록 구성될 수 있다. 먼저, 레일로봇장치에 내장된 통신모듈은 대상영역 내의 소정의 거리에 있는 개인단말기와 무선 연결되도록 구성된다. 전술한 바와 같이, Wi-fi방식으로 연결될 수도 있으나, 연결방식은 이에 제한되지 않으며, 근거리통신방식이 적용될 수 있다. 이 때, 근거리통신방식은 와이파이(WiFi, Wireless-Fidelity), 저전 력 블루투스(Bluetooth Low Energy, BLE), RFID(Radio Frequency Identification), 적외선 통신(IrDA, infrared Data Association), UWB(Ultra-Wideband), ZigBee 기술 중 적어도 하나를 이용하도록 구성될 수 있다. 또한, 무선통신은 CDMA(code division multiple access), FDMA(frequency division multiple access),TDMA(time division multiple access), OFDMA(orthogonal frequency division multiple access), SCFDMA(single carrier frequency division multiple access) 기술 중 적어도 하나를 이용하도록 구성될 수도 있다. 또한, 대상영역이 건물의 지하에 위치하거나, LTE망과 같은 외부 무선네트워크망에 접속되지 않는 위치일 경우, 개인단말기는 중계기부를 통해, 무선네트워크망과 연결될 수 있다. 즉, 개인단말기 자체로 외부 무선네트워크망과 연결이 어려울 때, 중계기부를 경유하여, 무선연결이 활성화됨을 의미한다. 도 6을 참고하여, 이벤트 상황이 발생된 경우를 개략적으로 도시한다. 여기서, 이벤트 상황은 대상영역의 연기 발생, 홍수판단, 화재발생, 불꽃발생 및 침입자발생 및 침수발생을 모두 포함하는 포괄적인 개념이다. 도 6은 본 발명에 따른 일 예시를 도시한다. 대상영역 내에 제1 및 제2 설비가 위치되며, 이러한 설비 위치를 고려하여, 대상영역의 천장 측에는 레일이 설계된다. 레일로봇장치는 레일을 궤도로 하여 자동 으로 순찰을 수행하면서, 실화상영상 및 열화상영상을 촬영하여 통합서버로 전송한다. 제1 설비에서 화재 가 발생됨을 감지한 경우, 화재의 상태를 더욱 정확하게 판단하기 위해, 기설정된 인접한 위치까지 접근하며, 실시간으로 이에 대한 정보를 통합서버 및 개인단말기로 전송한다. 물론, 이 과정에서, 사이렌 또는 별도의 알람이 동작되어 관리자에게 비상상황발생을 알려줄 수 있다. 또한, 이러한 상황은 통합관제실에 위치된 디스플레이부를 통해서도, 제공될 수 있다. 건물 모니터링 시스템을 이용한 방법 도 7 및 8을 참조하여, 건물 모니터링 시스템을 이용하여 연기발생 여부를 판단하는 과정을 설명한다. 통합서버는 실화상영상을 구성하는 실화상영상 프레임을 통해, 대상영역의 연기발생 여부를 판단하는 제1 판단모듈을 포함하며, 제1 판단모듈은 제1 판단학습부에 의해 학습된 모델을 적용한다. 본 방법은 단계(S110) 내지 단계(S160)을 포함한다. 단계(S110)은 제1 판단학습부에, 학습용 실화상영상 프레임이 입력되는 단계로서, 상기 학습용 실화상영상 프레임은, 기설정된 블록으로 구획되되, 비연기영역 및 연기영역이 구분된 상태로 입력된 후, 기설정된 방식에 의해, 연기영역이 학습되는 단계이다. 이 때, 제1 판단모듈은 학습과 테스트를 위해 영상정보를 사용한다. 영상정보가 주어지면 각 영상프레임마 다 먼저 움직이는 전경(이 경우 연기)을 고정 배경과 분리한다. 이 때, OpenCV에서 구현된 가우시안 혼합 기반 배경/전경 분할 알고리즘을 cv:: BackgroundSubtractorMOG2로 사용하는 것이 바람직하다. 제1 판단모듈은, 영상정보의 이미지를 고려하고, 각각을 반복함으로써, 전경을 분리하고 cv:: findContoures를 적용하여 전경을 윤곽으로 분할한다. 각 윤곽선은 40 x 40 개의 이미지 블록으로 분할되며. 연기 및 비연기 물 질이 포함된 블록은 별도로 수집된다. DNN은 도 8과 같이 개발되었으며, DNN은 블록으로 훈련된다. 단계(S120)은 상기 레일로봇장치로부터 실화상영상이 상기 제1 판단모듈로 전송되는 단계이다. 단계(S130)은 상기 제1 판단모듈에 의해, 상기 실화상영상을 구성하는 실화상영상 프레임을 기설정된 블록 으로 구획하는 단계로서, 상기 단계(S110)에서, 학습된 연기영역을 이용하여, 상기 기설정된 블록 중 연기영역 에 해당되는 영역을 블록그룹으로 구분한 후, 상기 블록그룹에 대해 가장자리부를 생성하는 단계이다. 단계(S140)은 상기 단계(S130)에서, 상기 실화상영상 프레임에서, 복수의 블록그룹이 형성될 경우, 각각의 블록 그룹에 대해 생성된 가장자리부를 비교하는 단계이다. 단계(S150)은 상기 단계(S140)에서, 제1 블록그룹 및 제2 블록그룹 각각의 가장자리부가 겹치는 경우, 상기 제1 및 제2 블록그룹을 병합하여 연기영역을 생성하는 단계이다. 단계(S160)은 상기 실화상영상에 포함된 제1 내지 제N 실화상영상 프레임에 대해 상기 단계(S130) 내지 단계 (S150)를 반복하여 수행하는 단계이다. 도 9 및 10을 참조하여, 건물 모니터링 시스템을 이용하여 연기발생 여부를 판단하는 과정을 설명한다. 통합서버는, 실화상영상을 구성하는 실화상영상 프레임을 통해, 대상영역의 홍수발생 여부를 판단하는, 제 2 판단모듈을 더 포함하며, 제2 판단모듈은 제2 판단학습부에 의해 학습된 모델을 적용한다. 본 방법은 단계(S210) 내지 단계(S250)을 포함한다. 단계(S210)은 제2 판단학습부에, 학습용 실화상영상 프레임이 입력되는 단계로서, 상기 학습용 실화상영상 프레임은, 기설정된 블록으로 구획되되, 정상영역 및 홍수영역이 구분된 상태로 입력된 후, 기설정된 방식에 의 해, 홍수영역이 학습되는 단계이다. 단계(S220)은 상기 레일로봇장치로부터 실화상영상이 상기 제2 판단모듈로 전송되는 단계이다. 단계(S230)은 상기 제2 판단모듈에 의해, 상기 실화상영상을 구성하는 실화상영상 프레임을 기설정된 블록 으로 구획하는 단계로서, 상기 (B1) 단계에서, 학습된 연기영역을 이용하여, 상기 기설정된 블록 중 홍수영역에 해당되는 영역을 블록그룹으로 구분한 후, 상기 블록그룹에 대해 가장자리부를 생성하는 단계이다. 단계(S240)은 상기 단계(S230)에서, 상기 실화상영상 프레임에서, 복수의 블록그룹이 형성될 경우, 각각의 블록 그룹에 대해 생성된 가장자리부를 비교하되, 제1 블록그룹 및 제2 블록그룹 각각의 가장자리부가 겹치는 경우, 상기 제1 및 제2 블록그룹을 병합하여 홍수영역을 생성하는 단계이다. 단계(S250)은 단계(S240)에서 생성된 홍수영역의 면적 및 물의 양을 기설정된 방식에 의해, 연산하는 단계 (S250)이다. 좀 더 부연하여 설명하면, 홍수판단은 크게 두 단계로 구분된다. 첫 번째 단계에서는 실화상영상 내에서 바닥영 역이 감지되고 두 번째 단계에서는 바닥영역에서만 물을 감지한다. 제1 판단모듈과 달리 제2 판단모듈 은, 정지된 이미지에서 작동하므로 비디오 클립(동영상을 의미함) 형태의 실화상영상이 필요하지 않는다. 학습 및 판단을 위해 실화상영상 프레임 각각은, 32 x 32 크기의 블록으로 분할된다. 바닥 탐지 부분의 경우, 많은 양의 바닥 이미지 및 상기 바닥 이미지를 제외한 부분의 이미지가 수집되고, 다음 DNN이 이미지 세트의 일부로 훈련된다. 제1 판단모듈의 경우와 마찬가지로 연결된 블록을 찾고 그룹의 구 성 요소 수가 매우 적으면 해당 그룹을 제외한다. 이는 오류의 탐지 플로어 블록을 제거하는 데 도움이 된다. 마지막으로 각 블록 그룹에서 물감지 분류기를 적용하고 바닥의 물의 대략적인 양을 계산한다. 제2 판단모듈 의 구성은 바닥면적감지와 구성과 동일하며, 이는 도 10에 도시된다. 그러나 제2 판단모듈은 물이 포 함된 블록과 빈바닥이 포함된 블록 등 다양한 이미지 블록 세트로 학습된다. 적은 수의 블록을 포함하는 블록 그룹을 필터링하면 적절한 결과를 얻을 수 있다. 본 발명은 누수를 판단하는 제4 판단모듈(미도시)을 더 포함할 수 있다. 제4 판단모듈은 제1 판단모듈 유사하게 비디오 클립에서 작동된다. 처음에는 움직이는 부분(여기서는 물의 흐름)이 고정 부분에서 분리된다. 다만, 제1 판단모듈의 경우와 달리 이동하는 물을 감지하기가 쉽지 않다. 그 이유는 일반적으로 연기가 퍼지려고 하지만, 속도가 낮을 때 물의 흐름이 감지하기 어려운 매우 얇은 빔을 만들기 때문이다. 이에 이미지 시퀀스의 시간 영역에서 1차원 컨볼루션을 적용한 다음, 이미지의 공간 영 역에서 2차원 컨벌루션을 적용한다. 여기서, 1차원 컨볼루션 레이어는 낙하의 모션 패턴을 인코딩하고, 2차원 컨볼루션 레이어는 낙수의 이미지를 인코딩하는 것이 바람직하다. 통합서버는, 실화상영상을 구성하는 실화상영상 프레임을 통해, 이벤트발생여부를 판단하는 제3 판단모듈 로서, 이벤트발생은 대상영역의 화재발생 여부, 불꽃발생 여부 및 침입자발생인, 제3 판단모듈을 더 포함한다. 본 방법은 단계(S310) 내지 단계(S350)을 포함한다. 단계(S310)은 제3 판단학습부에, 학습용 실화상영상 프레임이 입력되는 단계로서, 상기 학습용 실화상영상 프레임은, 딥러닝(deep learning) 기반 심층신경망 모델의 학습이 수행되는 단계이다. 단계(S320)은 상기 단계(S310)에 의해, 상기 이벤트발생여부에 대한 심층신경망 모델이 형성되는 단계이다. 단계(S330)은 상기 레일로봇장치로부터 실화상영상이 상기 제3 판단모듈로 전송되는 단계로서, 상기 단계(S320)에 생성된 심층신경망 모델에 상기 실화상영상이 입력되는 단계이다. 단계(S340)은 상기 심층신경망 모델은, 상기 단계(S330)에서 입력된 실화상영상에 대해, 최종 출력층의 노드를 상이하게 형성함으로써, 화재발생, 불꽃발생 및 침입자발생 여부를 판단하는 단계이다. 단계(S340)에서, 관심영역의 범위가 작게 설정될수록, 최종 출력층의 노드값은 더 크게 설정될 수 있다. 단계(S350)은 상기 이벤트발생으로 판단된 실화상영상 및 상기 열화상카메라모듈로부터 취득된 열화상영상 을 비교하는 단계로서, 상기 실화상영상 중 상기 이벤트발생으로 판단된 영역 및 상기 열화상영상에서의 영역별 온도정보를 매칭시킴으로써, 상기 이벤트발생 여부를 판단하는 단계이다. 여기서, 심층신경망 모델은, YOLO(You Only Look Once)의 네트워크 구조를 기반으로, 상기 학습용 실화상영상 프레임을 통해 학습하도록 구성된다. 구체적으로 설명하면, 화재, 불꽃 및 침입자 감지를 위해 단일모델을 사용한다. 모델을 선택하는 동안 두 가지 요소를 고려한다. 제1 요소는 탐지는 매우 빠르며, 제2 요소는 스파크와 같은 작은 물체와 소량의 화재처럼 침 입자와 같은 큰 물체를 탐지하는 것이다. 이를 통해, 스파크 및 침입자 감지를 위해, YOLO V3를 공통 모델로 결 정하였다. 학습을 위해, 다양한 형태의 불, 불꽃, 사람이 포함 된 약 500개의 이미지가 캡쳐되는 것이 필요하다. 각 이미지에 대해 라벨링 및 경계 상자가 만들어지며, 학습을 위해 약 400개의 이미지가 무작위로 선 택되고, 나머지 이미지는 유효성 검사를 위해 선택된다. 상기의 사항은 본 출원인에 의해 실험된 바 있으며, CUDA 지원 GPU가있는 표준 컴퓨터로 약 3일이 소요되었다. YOLO(You Only Look Once)의 핵심은 한 번의 패스로 사물을 인식 할 수 있다는 것이다. 이것의 목표는 움직이는 카메라에서 시스템을 사용하는 것이고 실시간으로 이상을 감지하는 것이다. 모듈들은 모든 카메라에서 실시간 스트림을 수신하는 더 큰 시스템과 결합됩니다. 주기적으로 많은 이미지 세트가 탐지 모듈로 전달되고 탐지 모 듈은 이상이 있는지 확인하며, 의심스러운 이벤트가 발견되면 경보를 울리고 이에 따라, 관리자가 필요한 조치 를 취하도록 구성된다. 도 12는 YOLO-V3 모델의 아키텍처를 보여준다. 도 12에 도시된 바와 같이, 3가지 다른 척도로 산출물을 추출한 다. 일 예시로써, 침입자와 같은 더 큰 물체는 노드 82에서 생성된 출력에 의해 감지되고, 불꽃 또는 소량의 화 재와 같은 작은 물체는 노드 106에서 생성된 출력에 의해 감지된다. 컨볼루션 레이어에 대해 사전 훈련된 가중치를 사용하더라도 YOLO의 훈련 시간은 매우 길다. 그러나 일단 훈련 을 받으면 탐지가 정말 빠른 효과가 있다. 실험적으로, Titan X GPU가있는 표준 데스크톱 컴퓨터에서 YOLO는 초 당 약 45 프레임을 처리할 수 있다. 초당 15 프레임으로 캡처된 이미지에 감지기를 적용될 수 있다. 물체가 가 까운 터널 내에서 움직이는 카메라를 사용할 때 이상을 감지하려면 높은 감지 속도가 필요하며, 그 결과 촬영을 통해, 캡처한 이미지에서 매우 짧은 시간 동안 유지된다. 이 시스템은 초고해상도 카메라에서 가장 잘 작동하지 만, 일반 IP 카메라로 캡처된 이미지에서 테스트 한 결과 역시 만족스러운 결과를 보였다. 그리고 분명히 이들 과 유사한 카메라를 사용하여 훈련 및 테스트 샘플을 채취할 경우, 성능이 더욱 향상될 수 있다. 이상, 본 명세서에는 본 발명을 당업자가 용이하게 이해하고 재현할 수 있도록 도면에 도시한 실시예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 당업자라면 본 발명의 실시예로부터 다양한 변형 및 균등한 타 실 시예가 가능하다는 점을 이해할 것이다. 따라서 본 발명의 보호범위는 특허청구범위에 의해서 정해져야 할 것이다."}
{"patent_id": "10-2020-0146858", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 건물 모니터링 시스템의 개략적인 모식도이다. 도 2는 본 발명에 따른 건물 모니터링 시스템의 전체 구성을 나타내는 블록도이다. 도 3은 본 발명에 따른 건물 모니터링 시스템에서, 레일에 레일로봇장치가 결합된 상태를 개략적으로 도시하는 사시도이다. 도 4의 (a) 및 (b)는 레일로봇장치의 구동부를 개략적으로 도시한다. 도 5는 본 발명에 따른 건물 모니터링 시스템에서, 레일로봇장치의 전체 구성을 나타내는 블록도이다. 도 6은 본 발명에 따른 건물 모니터링 시스템에서, 이벤트 상황이 발생된 경우를 개략적으로 도시한다. 도 7은 본 발명에 따른 건물 모니터링 시스템을 이용하여 연기발생 여부를 판단하는 방법의 순서도이다. 도 8은 도 7에서 심층신경망을 이용하여 연기발생 여부를 판단하는 과정을 개략적으로 도시하는 개념도이다. 도 9는 본 발명에 따른 건물 모니터링 시스템을 이용하여 홍수발생 여부를 판단하는 방법의 순서도이다. 도 10은 도 9에서 심층신경망을 이용하여 홍수발생 여부를 판단하는 과정을 개략적으로 도시하는 개념도이다. 도 11은 본 발명에 따른 건물 모니터링 시스템을 이용하여 이벤트상황(화재, 불꽃, 침입자) 발생 여부를 판단하 는 방법의 순서도이다. 도 12는 도 11에서 인공지능방식의 일 예시인 YOLO V3 Model을 이용하여 이벤트상황 발생 여부를 판단하는 과정 을 개략적으로 도시하는 개념도이다."}
