{"patent_id": "10-2019-0110441", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0029354", "출원번호": "10-2019-0110441", "발명의 명칭": "전자장치 및 그 제어방법", "출원인": "삼성전자주식회사", "발명자": "서희경"}}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서,수신되는 발화 음성에 대한 발화자 특성을 식별하고,상기 식별된 발화자 특성에 기초하여 복수의 발화자 그룹 중에서 어느 하나의 발화자 그룹을 식별하고,상기 복수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 상기 식별된 발화자 그룹에 대응하는 음성인식모델에 기초한 상기 발화 음성의 복수의 인식결과 중 서로 다른 인식정확도를 가지는 인식결과를 출력하고,상기 출력된 인식 결과에 대하여 상기 발화 음성의 인식 성공 여부를 식별하고,상기 발화 음성의 인식이 성공한 것으로 식별되면, 상기 인식이 성공한 상기 음성인식모델의 인식결과의 인식정확도를 조정하는프로세서를 포함하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는, 인식정확도가 서로 다른 복수의 후보 인식결과 중 상기 인식정확도가 가장 높은 인식결과를획득하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는, 상기 획득된 인식결과에 따른 동작에 대응하여 제2발화 음성이 수신되는 경우, 상기 발화 음성과, 상기 제2발화 음성 간의 유사도에 기초하여 상기 발화 음성에 대한 인식 성공 여부를 식별하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는, 상기 식별된 인식 성공 여부에 기초하여 상기 복수의 후보 인식결과에 대한 인식정확도를 조정하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는, 상기 발화 음성과, 상기 제2발화 음성 간의 유사도가 기설정값 이상인 경우, 상기 복수의 후보 인식결과 중 상기 인식정확도가 차상위인 제2인식결과를 획득하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는, 상기 제2인식결과에 대한 상기 인식 성공 여부에 따라 상기 제2인식결과의 인식정확도가 상기인식결과의 인식정확도보다 상향되도록 조정하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 프로세서는, 상기 제2인식결과에 따른 동작에 대응하여 검색어가 입력되는 경우, 상기 입력된 검색어에 의공개특허 10-2021-0029354-3-한 검색결과에 기초하여 상기 복수의 후보 인식결과에 대한 상기 인식정확도를 조정하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 발화자 특성은, 발화자의 성별, 나이, 이름, 거주지, 국적, 직업 중 적어도 하나를 포함하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는, 상기 수신되는 발화 음성의 톤, 세기, 빠르기 중 적어도 하나에 기초하여 상기 발화자 특성을식별하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 프로세서는, 상기 복수의 음성인식모델 중 적어도 2이상의 음성인식모델에 기초하여 상기 발화 음성의 인식결과를 획득하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,복수의 서버와 통신하는 통신부를 더 포함하며,상기 프로세서는, 상기 통신부를 통하여 상기 발화자 특성에 대응하여 식별된 음성인식모델에 기초한 상기 발화음성에 대한 인식결과를 상기 복수의 서버 중 적어도 하나로부터 수신하는 전자장치."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "전자장치의 제어방법에 있어서,수신되는 발화 음성에 대한 발화자 특성을 식별하는 단계;상기 식별된 발화자 특성에 기초하여 복수의 발화자 그룹 중에서 어느 하나의 발화자 그룹을 식별하는 단계;상기 복수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 상기 식별된 발화자 그룹에 대응하는 음성인식모델에 기초한 상기 발화 음성의 인식결과를 획득하는 단계; 및상기 획득된 인식결과에 따른 동작을 수행하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 인식결과를 획득하는 단계는, 인식정확도가 서로 다른 복수의 후보 인식결과 중 상기 인식정확도가 가장높은 인식결과를 획득하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 획득된 인식결과에 따른 동작에 대응하여 제2발화 음성이 수신되는 경우, 상기 발화 음성과, 상기 제2발화음성 간의 유사도에 기초하여 상기 발화 음성에 대한 인식 성공 여부를 식별하는 단계를 포함하는 전자장치의제어방법."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 식별된 인식 성공 여부에 기초하여 상기 복수의 후보 인식결과에 대한 인식정확도를 조정하는 단계를 포함공개특허 10-2021-0029354-4-하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 인식정확도를 조정하는 단계는, 상기 발화 음성과, 상기 제2발화 음성 간의 유사도가 기설정값 이상인 경우, 상기 복수의 후보 인식결과 중 상기 인식정확도가 차상위인 제2인식결과를 획득하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 제2인식결과를 획득하는 단계는, 상기 제2인식결과에 대한 상기 인식 성공 여부에 따라 상기 제2인식결과의 인식정확도가 상기 인식결과의 인식정확도보다 상향되도록 조정하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서,상기 제2인식결과에 따른 동작에 대응하여 검색어가 입력되는 경우, 상기 입력된 검색어에 의한 검색결과에 기초하여 상기 복수의 후보 인식결과에 대한 상기 인식정확도를 조정하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 발화자 특성은, 발화자의 성별, 나이, 이름, 거주지, 국적, 직업 중 적어도 하나를 포함하는 전자장치의제어방법."}
{"patent_id": "10-2019-0110441", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된기록매체에 있어서, 상기 전자장치의 제어방법은, 수신되는 발화 음성에 대한 발화자 특성을 식별하는 단계;상기 식별된 발화자 특성에 기초하여 복수의 발화자 그룹 중에서 어느 하나의 발화자 그룹을 식별하는 단계;상기 복수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 상기 식별된 발화자 그룹에 대응하는 음성인식모델에 기초한 상기 발화 음성의 인식결과를 획득하는 단계; 및상기 획득된 인식결과에 따른 동작을 수행하는 단계를 포함하는 것을 특징으로 하는 컴퓨터가 읽을 수 있는 프로그램이 기록된 기록매체."}
{"patent_id": "10-2019-0110441", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 발화 음성이 수신되면, 발화자 특성을 식별하고, 식별된 발화자 특성에 기초하여 어느 하나의 발화자 그룹을 식별하고, 복수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 식별된 발화자 그룹에 대응하는 음성 인식모델에 기초하여 발화 음성의 인식결과를 획득하고, 인식결과에 따른 동작을 수행하는 전자장치에 관한 발명 이다."}
{"patent_id": "10-2019-0110441", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 전자장치 및 그 제어방법에 관한 것으로서, 상세하게는, 발화 음성에 대한 인식결과에 따라 동작을 수행하는 전자장치 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2019-0110441", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에 연구가 활발하게 진행되고 있는 음성인식 기능이란, 발화자가 전자장치의 특정 동작을 의도하고, 특정 동작에 대응하는 음성을 발화하면, 인식결과에 따라 특정 동작을 전자장치가 수행하도록 제어하는 기능이다. 발 화 음성에 대한 인식은, 발화 음성에 따른 음성신호를 프로세서 등이 해석 가능한 텍스트 데이터로 변환하기 위 해 사용되는 하드웨어/소프트웨어 컴포넌트인 음성인식모델에 기초하여 수행될 수 있다. 음성인식모델은, 예컨 대, 마르코프 모델(Hidden Markov Model; HMM), 동적 시간 왜곡(Dynamic Time Warping; DTW) 등의 알고리즘에 따라서 발화 음성에 대한 통계적 모델링을 통해 구현되는 음향 모델(Acoustic Model), 말뭉치(언어 연구를 위하 여 컴퓨터가 텍스트를 가공, 처리, 분석할 수 있는 형태로 모아 놓은 자료의 집합) 수집을 통해 구현되는 언어모델(Language Model) 등을 포함할 수 있다. 그러나, 불특정 다수의 발화자에 대해 공통적으로 사용되는, 소위, 범용 음성인식모델에 기초하여 음성인식을 수행하는 경우, 범용 음성인식모델이 현재 발화자의 고유한 특성을 고려하지 못하므로, 범용 음성인식모델에 기 초하여 획득된 인식결과가 발화자의 발화 의도를 정확하게 반영하지 못하는 문제가 발생하기에 이르렀다. 이러한 발화의도와 인식결과 간의 비적합성은, 발화자의 발화 음성이 발화 의도와 일치하지 않는 경우에, 예컨 대, 발화자의 부정확하게 발음하거나 실수로 잘못 발음한 경우 그 비적합성의 정도가 심해지기 마련이다. 발화 의도와 인식결과 간의 비적합성은 전자장치로 하여금 발화자가 의도한 동작이 수행되지 않도록 하거나, 의도하 지 않은 동작이 수행되도록 하는 원인이 되므로, 음성인식 기능 전반에 대한 신뢰도까지 저하시킬 수 있다. 따라서, 발화자의 고유한 특성에 따른 음성인식모델에 기초하여 음성인식을 수행함으로써, 발화 의도와 인식결 과 간의 적합성을 향상시킬 방안이 요청되고 있다. 나아가, 발화자의 발화 음성이 발화 의도와 상이한 경우라도, 발화 의도에 부합하는 인식결과를 획득함으로써, 음성인식 기능에 대한 활용성 및 신뢰성을 향상시킬 수 있는 방안이 요청되고 있다."}
{"patent_id": "10-2019-0110441", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 발화자의 고유한 특성에 따른 음성인식모델에 기초하여 음성인식을 수행함으로써, 발화 의도 와 인식결과 간의 적합성을 향상시키고, 발화자의 발화 음성이 발화 의도와 상이한 경우라도, 발화 의도에 부합 하는 인식결과를 획득함으로써, 음성인식 기능에 대한 활용성 및 신뢰성을 향상시킬 수 있는 전자장치 및 그 제 어방법을 제공하는 것이다."}
{"patent_id": "10-2019-0110441", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 본 발명의 목적은, 수신되는 발화 음성에 대한 발화자 특성을 식별하고, 상기 식별된 발화자 특성에 기 초하여 복수의 발화자 그룹 중에서 어느 하나의 발화자 그룹을 식별하고, 상기 복수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 상기 식별된 발화자 그룹에 대응하는 음성인식모델에 기초한 상기 발화 음성의 복수의 인식결과 중 서로 다른 인식정확도를 가지는 인식결과를 출력하고, 상기 출력된 인식 결과에 대하여 상기 발화 음성의 인식 성공 여부를 식별하고, 상기 발화 음성의 인식이 성공한 것으로 식별되면, 상기 인식이 성공한 상 기 음성인식모델의 인식결과의 인식정확도를 조정하는 프로세서를 포함하는 전자장치에 의해 달성될 수 있다. 상기 프로세서는, 인식정확도가 서로 다른 복수의 후보 인식결과 중 상기 인식정확도가 가장 높은 인식결과를 획득할 수 있다. 상기 프로세서는, 상기 획득된 인식결과에 따른 동작에 대응하여 제2발화 음성이 수신되는 경우, 상기 발화 음 성과, 상기 제2발화 음성 간의 유사도에 기초하여 상기 발화 음성에 대한 인식 성공 여부를 식별할 수 있다. 상기 프로세서는, 상기 식별된 인식 성공 여부에 기초하여 상기 복수의 후보 인식결과에 대한 인식정확도를 조 정할 수 있다. 상기 프로세서는, 상기 발화 음성과, 상기 제2발화 음성 간의 유사도가 기설정값 이상인 경우, 상기 복수의 후 보 인식결과 중 상기 인식정확도가 차상위인 제2인식결과를 획득할 수 있다. 상기 프로세서는, 상기 제2인식결과에 대한 상기 인식 성공 여부에 따라 상기 제2인식결과의 인식정확도가 상기 인식결과의 인식정확도보다 상향되도록 조정할 수 있다. 상기 프로세서는, 상기 제2인식결과에 따른 동작에 대응하여 검색어가 입력되는 경우, 상기 입력된 검색어에 의 한 검색결과에 기초하여 상기 복수의 후보 인식결과에 대한 상기 인식정확도를 조정할 수 있다. 상기 발화자 특성은, 발화자의 성별, 나이, 이름, 거주지, 국적, 직업 중 적어도 하나를 포함할 수 있다. 상기 프로세서는, 상기 수신되는 발화 음성의 톤, 세기, 빠르기 중 적어도 하나에 기초하여 상기 발화자 특성을 식별할 수 있다. 상기 프로세서는, 상기 복수의 음성인식모델 중 적어도 2이상의 음성인식모델에 기초하여 상기 발화 음성의 인 식결과를 획득할 수 있다. 복수의 서버와 통신하는 통신부를 더 포함하며, 상기 프로세서는, 상기 통신부를 통하여 상기 발화자 특성에 대 응하여 식별된 음성인식모델에 기초한 상기 발화 음성에 대한 인식결과를 상기 복수의 서버 중 적어도 하나로부 터 수신할 수 있다. 상기한 본 발명의 목적은, 수신되는 발화 음성에 대한 발화자 특성을 식별하는 단계; 상기 식별된 발화자 특성 에 기초하여 복수의 발화자 그룹 중에서 어느 하나의 발화자 그룹을 식별하는 단계; 상기 복수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 상기 식별된 발화자 그룹에 대응하는 음성인식모델에 기초한 상기 발화 음 성의 인식결과를 획득하는 단계; 및 상기 획득된 인식결과에 따른 동작을 수행하는 단계를 포함하는 전자장치의 제어방법에 의해서도 달성될 수 있다. 상기 인식결과를 획득하는 단계는, 인식정확도가 서로 다른 복수의 후보 인식결과 중 상기 인식정확도가 가장 높은 인식결과를 획득하는 단계를 포함할 수 있다. 상기 획득된 인식결과에 따른 동작에 대응하여 제2발화 음성이 수신되는 경우, 상기 발화 음성과, 상기 제2발화 음성 간의 유사도에 기초하여 상기 발화 음성에 대한 인식 성공 여부를 식별하는 단계를 포함할 수 있다. 상기 식별된 인식 성공 여부에 기초하여 상기 복수의 후보 인식결과에 대한 인식정확도를 조정하는 단계를 포함 할 수 있다. 상기 인식정확도를 조정하는 단계는, 상기 발화 음성과, 상기 제2발화 음성 간의 유사도가 기설정값 이상인 경 우, 상기 복수의 후보 인식결과 중 상기 인식정확도가 차상위인 제2인식결과를 획득하는 단계를 포함할 수 있다. 상기 제2인식결과를 획득하는 단계는, 상기 제2인식결과에 대한 상기 인식 성공 여부에 따라 상기 제2인식결과 의 인식정확도가 상기 인식결과의 인식정확도보다 상향되도록 조정하는 단계를 포함할 수 있다. 상기 제2인식결과에 따른 동작에 대응하여 검색어가 입력되는 경우, 상기 입력된 검색어에 의한 검색결과에 기 초하여 상기 복수의 후보 인식결과에 대한 상기 인식정확도를 조정하는 단계를 포함할 수 있다. 상기 발화자 특성은, 발화자의 성별, 나이, 이름, 거주지, 국적, 직업 중 적어도 하나를 포함할 수 있다. 상기한 본 발명의 목적은, 컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된 기록매체에 있어서, 수신되는 발화 음성에 대한 발화자 특성을 식별하는 단계; 상기 식별된 발화자 특성에 기초하여 복수의 발화자 그룹 중에서 어느 하나의 발화자 그룹을 식별하는 단계; 상기 복 수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 상기 식별된 발화자 그룹에 대응하는 음성인식모델에 기 초한 상기 발화 음성의 인식결과를 획득하는 단계; 및 상기 획득된 인식결과에 따른 동작을 수행하는 단계를 포 함하는 것을 특징으로 하는 컴퓨터가 읽을 수 있는 프로그램이 기록된 기록매체에 의해 달성될 수도 있다."}
{"patent_id": "10-2019-0110441", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 발화자의 고유한 특성에 따른 음성인식모델에 기초하여 음성인식을 수행함으로써, 발화 의도 와 인식결과 간의 적합성을 향상시키고, 발화자의 발화 음성이 발화 의도와 상이한 경우라도, 발화 의도에 부합 하는 인식결과를 획득함으로써, 음성인식 기능에 대한 활용성 및 신뢰성을 향상시킬 수 있는 전자장치 및 그 제 어방법을 제공할 수 있다."}
{"patent_id": "10-2019-0110441", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부도면을 참조하여 본 발명에 따른 실시예들에 관해 상세히 설명한다. 이하 실시예들의 설명에서 는 첨부된 도면들에 기재된 사항들을 참조하는 바, 각 도면에서 제시된 동일한 참조번호 또는 부호는 실질적으 로 동일한 동작을 수행하는 구성요소를 나타낸다. 본 명세서에서의 복수의 구성 중 적어도 하나(at least one) 는, 복수의 구성 전부뿐만 아니라, 복수의 구성 중 나머지를 배제한 각 하나 혹은 이들의 조합 모두를 지칭한다. 도 1은 본 발명의 일 실시예에 따른 전자장치를 도시한다. 도 1에 도시된 바와 같이, 전자장치는 영상 을 표시할 수 있는 디스플레이장치로 구현될 수 있다. 일 예로, 전자장치는 TV, 컴퓨터, 스마트 폰, 태블릿, 휴대용 미디어 플레이어, 웨어러블 디바이스, 비디오 월, 전자액자 등을 포함할 수 있다. 또한, 전자장 치는 디스플레이를 구비하지 않는 셋탑박스 등의 영상처리장치, 냉장고, 세탁기 등의 생활가전, 컴퓨터본체 와 같은 정보처리장치 등 다양한 종류의 장치로 구현될 수 있다. 다만, 이하에서는 설명의 편의를 위해 전자장 치가 TV로 구현되는 경우를 가정하여 설명한다. 전자장치는 음성인식 기능을 수행할 수 있다. 전자장치는 발화자의 발화 음성을 수신하면, 발화 음성에 대한 음성신호를 획득하고, 획득한 음성신호에 대한 음성인식처리를 수행하고, 음성인식처리에 의한 인식결과에 대응하는 동작을 수행할 수 있다. 음성인식처리는 음성신호를 텍스트 데이터로 변환하는 STT(Speech-to-Text) 처리 과정과, 텍스트 데이터가 나타내는 커맨드를 식별하여, 식별된 커맨드가 지시하는 동 작을 수행하는 커맨드 식별 및 수행 과정을 포함한다. 일 예로, 발화 음성이 “볼륨을 높여”인 경우, 전자 장치는 발화 음성을 수신하고, 발화 음성의 음성신호에 대한 텍스트 데이터를 획득하고, 획득한 텍스 트 데이터가 나타내는 커맨드를 식별하고, 식별된 커맨드에 따라서 전자장치의 볼륨을 높일 수 있다. 음성인식처리의 STT 처리 과정과, 커맨드 식별 및 수행 과정은, 전자장치에서 모두 실행될 수도 있다. 그러 나, 이 경우에 전자장치에 필요한 시스템 부하 및 소요 저장용량이 상대적으로 커지게 되므로, 적어도 일부 의 과정은 네트워크를 통해 전자장치와 통신 가능하게 접속되는 적어도 하나의 서버에 의해 수행될 수 있다. 일 예로, 적어도 하나의 서버가 STT 처리 과정을 수행하고, 전자장치가 커맨드 식별 및 수행 과 정을 수행할 수 있다. 또는, 적어도 하나의 서버가 STT 처리 과정과, 커맨드 식별 및 수행 과정을 모두 수행하고, 전자장치는 단지 적어도 하나의 서버로부터 결과를 수신하기만 할 수도 있다. 예컨대, 전자장치는 적어도 하나의 서버 중 STT 처리 과정을 수행하는 제1서버로부터 변환된 텍스트 데이터를 수신하고, 수신된 텍스트 데 이터를 제2서버 또는 제3서버로 전송하여 커맨드 식별 및 수행 과정을 수행하도록 하고, 제2서버 또는 제3서버로부터 결과를 수신할 수 있다. 다만, 이하에서는 설명의 편의를 위해, 전자장치가 STT 처 리 과정과, 커맨드 식별 및 수행 과정을 모두 수행하는 경우를 가정하여 설명한다. 전자장치는 STT 처리 과정을 수행하기 위해 적어도 하나의 음성인식모델을 구비할 수 있다. 음성인식모델은 발화 음성에 따른 음성신호를 프로세서 등이 해석 가능한 텍스트 데이터로 변환하기 위해 사용되는 하드웨어 /소프트웨어 컴포넌트이다. 음성인식모델은 모델 개발에 사용된 발화자 데이터 및 말뭉치 데이터 등에 의해 고 유한 특성, 예컨대, 발화자 특성에 대응하도록 마련될 수 있다. 따라서, 동일한 발화 음성이라도 각 음성인 식모델이 출력하는 인식결과는 상이할 수 있다. 음성인식모델은 발화자에 대응하도록 마련될 수 있다. 복수의 발화자가 있는 경우, 복수의 발화자 각각에 대 응하는 음성인식모델이 마련될 수 있다. 전자장치는 발화자의 발화 음성이 수신되면, 발화 음성의 톤, 세기, 빠르기, 주파수, 주기 중 적어도 하나에 기초하여 발화자가 누구인지를 식별하고, 복수의 음성인 식모델 중 식별된 발화자에 대응하는 음성인식모델을 식별할 수 있다. 다만, 발화자의 식별 방법을 한정 하는 것은 아니므로, 일 예로, 발화자가 직접 자신에 관한 입력하는 경우, 전자장치는 입력된 정보에 기 초하여 발화자를 식별할 수 있으며, 발화자에 관한 이미지를 획득하는 경우, 획득된 이미지에 기초하여 발화자를 식별할 수 있다. 다른 예로, 전자장치는 발화자의 사용 형태 또는 사용 이력 등에 기초하여 발화자를 식별할 수 있다. 이와 같이, 발화자에 대응하는 음성인식모델에 기초하여 음성인식처리를 수행 하면, 발화자만의 고유한 발화 특성을 반영할 수 있으므로, 발화 의도와 인식결과 간의 적합성을 향상시킬수 있다. 특히, 음성인식모델은 복수의 발화자 그룹 별로 마련될 수 있다. 음성인식모델은, 예컨대, 성별, 나이, 이름, 거주지, 국적, 직업 등의 그룹 별로 마련될 수 있다. 성별로 마련된 경우를 예로 들면, 남성 그룹의 음성인식모 델과 여성 그룹의 음성인식모델로 마련될 수 있다. 남성 그룹의 음성인식모델과 여성 그룹의 음성인식모델은 각 각 남성과 여성에 해당하는 그룹에 적용되는 음성인식모델이다. 마찬가지로, 나이 별로 마련된, 예컨대, 20대 그룹의 음성인식모델 50대 그룹의 음성인식모델 등은 각각 20대와 50대에 해당하는 그룹에 적용되는 음성인식모 델이다. 다만, 예컨대, 남성, 여성, 20대, 50대 등의 발화자 그룹 별로, 즉, 남성, 여성, 20대, 50대 등의 각 그룹에 적용되는 음성인식모델에 한정되는 것은 아니므로, 설계 방법에 따라 다양한 종류의 발화자 그룹 별로 마련될 수도 있다. 또한, 음성인식모델은 2이상의 발화자 그룹 별로 마련될 수도 있다. 성별 및 나이 그룹 별로 마련된 경우를 예 로 들면, 20대 남성 그룹의 음성인식모델, 20대 여성 그룹의 음성인식모델 등으로 마련될 수 있다. 20대 남성 그룹의 음성인식모델은 20대 남성 그룹에 대해 최적화된 음성인식모델일 수 있으며, 20대 여성의 음성인식모델 은 20대 여성 그룹에 대해 최적화된 음성인식모델일 수 있다. 또한, 2이상의 발화자 그룹 별로 마련된 음성인식모델은 각 발화자 그룹 별로 마련된 개별 음성인식모델을 조합 한 것일 수 있다. 일 예로, 20대 남성 그룹의 음성인식모델은 하나의 그룹 음성인식모델로서, 20대인 남성 그룹 에 대해 독립적으로 마련될 것일 수 있으나, 20대 그룹의 음성인식모델과 남성 그룹의 음성인식모델을 조합하여 마련된 것일 수 있다. 마찬가지로, 20대 여성의 음성인식모델은 20대 그룹의 음성인식모델과 여성 그룹의 음성 인식모델을 조합하여 마련된 것일 수 있다. 전자장치는 발화자의 발화 음성이 수신되면, 발화자 특성을 식별할 수 있다. 전자장치는 발화 음 성의 톤, 세기, 빠르기, 주파수, 주기 중 적어도 하나에 기초하여, 예컨대, 발화자가 20대 남성 또는 20 대 여성인지를 식별할 수 있다. 다만, 발화자 특성을 식별하는 방법을 한정하는 것은 아니므로, 일 예로, 발화 자가 발화자 특성에 관한 정보를 직접 입력하는 경우, 전자장치는 입력된 정보에 기초하여 발화자 특성 을 식별할 수 있으며, 발화자에 관한 이미지를 획득하는 경우, 획득된 이미지에 기초하여 발화자 특성을 식 별할 수 있다. 다른 예로, 전자장치는 발화자의 사용 형태 또는 사용 이력 등에 기초하여 발화자 특성을 식별할 수 있다. 전자장치는 식별된 발화자 특성에 기초하여 복수의 발화자 그룹 중 어느 하나의 발화자 그룹을 식별할 수 있다. 일 예로, 발화자 특성이 20대 남성인 것으로 식별된 경우, 복수의 발화자 그룹, 예컨대, 성별 및 나이 그 룹 별로 마련된 발화자 그룹 중 20대 남성 그룹을 식별할 수 있으며, 발화자 특성이 20대 여성인 것으로 식별된 경우 복수의 발화자 그룹 중 20대 여성 그룹을 식별할 수 있다. 전자장치는 식별된 발화자 그룹에 대응하는 음성인식모델을 선택할 수 있다. 일 예로, 발화자의 발화자 특성에 기초하여 20대 남성 그룹으로 식별된 경우, 복수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 20 대 남성 그룹에 대응하는 음성인식모델을 선택할 수 있다. 다른 예로, 발화자 그룹 별로 마련된 복수의 음성인 식모델 중 20대 그룹의 음성인식모델과 남성 그룹의 음성인식모델을 선택하여 조합할 수 있다. 전자장치는 식별된 발화자 그룹에 대응하는 음성인식모델에 기초하여 발화 음성에 대한 인식결과를 획득 하고, 획득된 인식결과에 따른 동작을 수행할 수 있다. 일 예로, 발화자 특성이 20대 남성인 것으로 식별된 경 우, 20대 남성 그룹의 음성인식모델에 기초하여 발화 음성에 대한 인식결과를 획득하고, 획득된 인식결과에 따른 동작을 수행할 수 있다. 이와 같이, 본 실시예에 따른 전자장치는 발화자 그룹의 음성인식모델에 기초하여 음성인식처리를 수행함으 로써, 발화자 그룹의 고유한 특성을 고려할 수 있으므로, 발화자에게만 개인화된 음성인식모델에 기초하여 음성인식처리를 수행하는 경우에 비해 발화 의도와 인식결과 간의 적합성을 더욱 향상시킬 수 있다. 도 2는 도 1의 전자장치에 관한 구성의 일 예를 도시한다. 도 2에 도시된 바와 같이, 전자장치은 통신부 , 신호입출력부, 디스플레이부, 사용자입력부, 저장부, 마이크로폰 및 프로세서를 포함할 수 있다. 이하, 전자장치의 구성에 관해 설명한다. 본 실시예서는 전자장치가 TV인 경우에 관해 설명하지만, 전 자장치는 다양한 종류의 장치로 구현될 수 있으므로, 본 실시예가 전자장치의 구성을 한정하는 것은 아 니다. 전자장치가 디스플레이장치로 구현되지 않는 경우도 가능하며, 이 경우의 전자장치는 디스플레이 부와 같은 영상 표시를 위한 구성요소들을 포함하지 않을 수 있다. 예를 들면 전자장치가 셋탑박스로구현되는 경우에, 전자장치는 신호입출력부를 통해 외부의 TV에 영상신호를 출력할 수 있다. 통신부는 다양한 종류의 유선 및 무선 통신 프로토콜에 대응하는 통신모듈, 통신칩 등의 구성요소들 중 적 어도 하나 이상을 포함하는 양방향 통신회로이다. 예를 들면, 통신부는 와이파이 방식에 따라서 AP(Access Point)와 무선통신을 수행하는 무선통신모듈이나, 블루투스 등과 같은 1대 1 다이렉트 무선통신을 수행하는 무 선통신모듈이나, 라우터 또는 게이트웨이에 유선 접속된 랜카드로 구현될 수 있다. 통신부는 네트워크 상의 서버와 통신함으로써, 적어도 하나의 서버와의 사이에 데이터 패킷을 송수신할 수 있다. 통신부는 전자장치의 본체와 분리된 리모트 컨트롤러, 스마트 폰 등과 통신할 수 있다. 일 예로, 리모트 컨트롤러, 스마트 폰 등이 음성신호를 수신하는 경우, 통신부는 리모트 컨트롤러, 스마트 폰 등으로부터 음성신호를 전달받을 수 있다. 이 경우, 스마트 폰 등에는 리모트 컨트롤러 어플리케이션 (Applicaton)이 설치될 수 있다. 통신부는 리모트 컨트롤러, 스마트 폰 등으로부터 음성신호를, 예컨대, 와이파이, 블루투스 등의 방식으로 수신할 수 있다. 또한, 통신부는 리모트 컨트롤러, 스마트 폰 등과 와이파이, 블루투스, 적외선 등의 방식으로 데이터를 송수신하기 위한 구성을 포함할 수 있다. 다만, 통신부가 적어도 하나의 서버와 통신하는 경우, 적어도 하나의 서버와 통신하는 통신부와, 리모트 컨트롤러, 스마트 폰 등과 통신하는 통신부가 같도록 마련될 수 있고, 별개로 마련될 수도 있다. 신호입출력부는 셋탑박스 또는 광학미디어 재생장치와 같은 외부장치와 1:1 또는 1:N(N은 자연수) 방식으로 유선 접속됨으로써, 해당 외부장치로부터 데이터를 수신하거나 또는 해당 외부장치에 데이터를 출력한다. 신호 입출력부는 예를 들면 HDMI 포트, DisplayPort, DVI 포트, 썬더볼트, USB 포트 등과 같이, 기 설정된 전송 규격에 따른 커넥터 또는 포트 등을 포함한다. 디스플레이부는 화면 상에 영상을 표시할 수 있는 디스플레이 패널을 포함한다. 디스플레이 패널은 액정 방 식과 같은 수광 구조 또는 OLED 방식과 같은 자발광 구조로 마련된다. 디스플레이부는 디스플레이 패널의 구조에 따라서 부가적인 구성을 추가로 포함할 수 있는데, 예를 들면, 디스플레이 패널이 액정 방식이라면, 디 스플레이부는 액정 디스플레이 패널과, 광을 공급하는 백라이트유닛과, 액정 디스플레이 패널의 액정을 구 동시키는 패널구동기판을 포함한다. 다만, 디스플레이부는 전자장치가 셋탑박스 등으로 구현되는 경우 생략될 수 있다. 사용자입력부는 사용자의 입력을 수행하기 위해 사용자가 조작할 수 있도록 마련된 다양한 종류의 입력 인 터페이스 관련 회로를 포함한다. 사용자입력부는 전자장치의 종류에 따라서 여러 가지 형태의 구성이 가능하며, 예를 들면 전자장치의 기계적 또는 전자적 버튼부, 터치패드, 디스플레이부에 설치된 터치스 크린 등이 있다. 저장부는 디지털화된 데이터를 저장한다. 저장부는 전원의 제공 유무와 무관하게 데이터를 보존할 수 있는 비휘발성 속성의 스토리지(storage)와, 프로세서에 의해 처리되기 위한 데이터가 로딩되며 전원이 제 공되지 않으면 데이터를 보존할 수 없는 휘발성 속성의 메모리(memory)를 포함한다. 스토리지에는 플래시메모리 (flash-memory), HDD(hard-disc drive), SSD(solid-state drive) ROM(Read Only Memory) 등이 있으며, 메모리 에는 버퍼(buffer), 램(RAM; Random Access Memory) 등이 있다. 저장부는 음성신호의 STT 처리를 위한 음 성인식모델을 포함할 수 있다. 음성인식모델은 다양한 발화자 그룹 별로 다양하게 마련될 수 있다. 마이크로폰 또는 음성입력부는 발화자의 발화 음성을 비롯한 외부 환경의 소리를 수집한다. 마이크로 폰은 수집된 음성신호를 프로세서에 전달한다. 마이크로폰은 전자장치의 본체에 설치될 수도 있고, 전자장치의 본체와 분리된 리모트 컨트롤러에 설치될 수도 있다. 일 예로, 리모트 컨트롤러, 스마트 폰 등에 마련된 마이크로폰을 통해 수집된 음성신호는 디지털화 되어 통신부를 통해 수신될 수 있다. 프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등으로 구현되는 하나 이상의 하드웨어 프 로세서를 포함하며, 설계 방식에 따라서는 SOC(system on chip)로 구현될 수도 있다. 프로세서는 전자장치 가 디스플레이장치로 구현되는 경우에 디멀티플렉서, 디코더, 스케일러, 오디오 DSP(Digital Signal Processor), 앰프 등의 다양한 프로세스에 대응하는 모듈들을 포함한다. 여기서, 이러한 모듈들 중 일부 또는 전체가 SOC로 구현될 수 있다. 예를 들면, 디멀티플렉서, 디코더, 스케일러 등 영상처리와 관련된 모듈이 영상 처리 SOC로 구현되고, 오디오 DSP는 SOC와 별도의 칩셋으로 구현되는 것이 가능하다. 프로세서는 마이크로폰을 통해 획득된 발화 음성의 음성신호에 기초하여 식별된 발화자 특성에 기초 하여 발화자 그룹을 식별하고, 식별된 발화자 그룹을 고려하여 음성인식모델을 선택하고, 선택된 음성인식모델 에 기초하여 음성신호에 대한 음성인식처리를 수행할 수 있다. 그리고, 프로세서는 음성인식처리에 의한 인 식결과로서, 텍스트 데이터를 획득하고, 텍스트 데이터에 따라 동작을 수행할 수 있다. 다만, 음성신호에 대한 음성인식처리를 적어도 하나의 서버에서 수행하는 경우, 프로세서는 마이크로폰을 통해 획득된 음 성신호를 통신부를 통해 서버에 전달하고, 음성신호의 인식결과인 텍스트 데이터를 적어도 하나의 서버 로부터 통신부를 통해 수신하고, 적어도 하나의 서버로부터 수신된 텍스트 데이터를 처리하여, 텍 스트 데이터가 지시하는 동작을 수행할 수 있다. 다만, 전자장치는 상기한 구성 중 일부를 제외하거나, 상기한 구성 이외의 구성을 포함할 수 있다. 예컨대, 카메라 등과 같은 이미지획득부를 더 포함하여, 발화자의 발화 음성에 대응하여 발화자에 대한 이미지 를 획득하고, 획득된 이미지에 대한 신호를 프로세서로 전달할 수 있다. 프로세서는 전달받은 신호에 기초하여 발화자를 식별하거나, 발화자의 발화자 특성, 예컨대, 20대 남성인지 여부를 식별할 수 있다. 이하, 서버의 구성에 관해 설명한다. 서버는 서버통신부, 서버저장부, 서버프로세서를 포 함할 수 있다. 서버통신부는 다양한 종류의 유선 및 무선 통신 프로토콜에 대응하는 통신모듈, 통신칩 등의 구성요소들 중 적어도 하나 이상을 포함하는 양방향 통신회로이다. 서버통신부는 전자장치의 통신부에 대응하는 통신규격을 지원함으로써, 광역 네트워크를 통해 전자장치을 비롯한 다양한 종류의 클라이언트와 네트워크 를 통해 통신할 수 있다. 서버저장부는 서버프로세서에 의해 데이터의 독취, 기록, 수정, 삭제, 갱신 등의 동작이 수행된다. 서 버저장부는 플래시메모리, HDD, SSD, 버퍼, 램 등의 다양한 비휘발성 메모리 및 휘발성 메모리를 포함한다. 서버저장부는 음성신호의 STT 처리를 위한 음성인식모델을 포함할 수 있다. 음성인식모델은 다양한 발화자 그룹 별로 다양하게 마련될 수 있다. 서버프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등으로 구현되는 하나 이상의 하드웨어 프로세서를 포함하며, 설계 방식에 따라서는 SOC로 구현될 수도 있다. 서버프로세서는 전자장치로부터 수신되는 정보에 기반하여 다양한 처리를 수행할 수 있다. 예를 들면, 서버프로세서는 전자장치로부터 발화 음성의 음성신호를 수신하면, 발화 음성에 의한 발화자 특성을 식별하고, 서버저장부에 저장된 복수의 음성인식모델, 즉, 복수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 발화자 특성에 기초하여 식 별된 발화자 그룹에 대응하는 음성인식모델을 식별하고, 음성인식모델에 기초하여 발화 음성에 대한 텍스트 데이터를 획득할 수 있다. 서버프로세서는 획득된 테스트 데이터를 전자장치에 전송하여, 텍스트 데이 터에 대응하는 동작을 수행하도록 할 수 있다. 한편, 프로세서 또는 서버프로세서는 발화 음성에 대한 발화자 특성을 식별하거나, 식별된 발화자 특성에 기초하여 발화자 그룹을 식별하거나, 식별된 발화자 그룹에 대응하는 음성인식모델을 식별하거나, 식별 된 음성인식모델에 기초하여 발화 음성에 대한 인식결과를 획득하거나, 획득된 인식결과에 따른 동작을 수행 하기 위한 데이터 분석, 처리, 및 결과 정보 생성 중 적어도 일부를 규칙 기반 또는 인공지능(Artificial Intelligence) 알고리즘으로서 기계학습, 신경망 네트워크(neural network), 또는 딥러닝 알고리즘 중 적어도 하나를 이용하여 수행할 수 있다. 일 예로, 프로세서 또는 서버프로세서는 학습부 및 인식부의 기능을 함께 수행할 수 있다. 학습부는 학 습된 신경망 네트워크를 생성하는 기능을 수행하고, 인식부는 학습된 신경망 네트워크를 이용하여 데이터를 인 식(또는, 추론, 예측, 추정, 판단)하는 기능을 수행할 수 있다. 학습부는 신경망 네트워크를 생성하거나 갱신할 수 있다. 학습부는 신경망 네트워크를 생성하기 위해서 학습 데이터를 획득할 수 있다. 일 예로, 학습부는 학습 데이터를 저장부 또는 서버저장부로부터 획득하거나, 외부로부터 획득할 수 있다. 학습 데이터는, 신경 망 네트워크의 학습을 위해 이용되는 데이터일 수 있으며, 상기한 동작을 수행한 데이터를 학습데이터로 이용하 여 신경망 네트워크를 학습시킬 수 있다. 학습부는 학습 데이터를 이용하여 신경망 네트워크를 학습시키기 전에, 획득된 학습 데이터에 대하여 전처리 작 업을 수행하거나, 또는 복수 개의 학습 데이터들 중에서 학습에 이용될 데이터를 선별할 수 있다. 일 예로, 학 습부는 학습 데이터를 기 설정된 포맷으로 가공하거나, 필터링하거나, 또는 노이즈를 추가/제거하여 학습에 적 절한 데이터의 형태로 가공할 수 있다. 학습부는 전처리된 학습 데이터를 이용하여 상기한 동작을 수행하도록 설정된 신경망 네트워크를 생성할 수 있다.학습된 신경망 네트워크는, 복수의 신경망 네트워크(또는, 레이어)들로 구성될 수 있다. 복수의 신경망 네트워 크의 노드들은 가중치를 가지며, 복수의 신경망 네트워크들은 일 신경망 네트워크의 출력 값이 다른 신경망 네 트워크의 입력 값으로 이용되도록 서로 연결될 수 있다. 신경망 네트워크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN (Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네 트워크 (Deep Q-Networks)과 같은 모델을 포함할 수 있다. 한편, 인식부는 상기한 동작을 수행하기 위해, 타겟 데이터를 획득할 수 있다. 타겟 데이터는 저장부 또는 서버저장부로부터 획득하거나, 외부로부터 획득할 수 있다. 타겟 데이터는 신경망 네트워크의 인식 대상이 되는 데이터일 수 있다. 인식부는 타겟 데이터를 학습된 신경망 네트워크에 적용하기 전에, 획득된 타겟 데이터 에 대하여 전처리 작업을 수행하거나, 또는 복수 개의 타겟 데이터들 중에서 인식에 이용될 데이터를 선별할 수 있다. 일 예로, 인식부는 타겟 데이터를 기 설정된 포맷으로 가공하거나, 필터링 하거나, 또는 노이즈를 추가/ 제거하여 인식에 적절한 데이터의 형태로 가공할 수 있다. 인식부는 전처리된 타겟 데이터를 신경망 네트워크에 적용함으로써, 신경망 네트워크로부터 출력되는 츨력값을 획득할 수 있다. 인식부는 출력값과 함께, 확률값 또 는 신뢰도값을 획득할 수 있다. 도 3은 도 1의 전자장치에 대한 제어방법의 일 예를 도시한다. 도 3의 각 동작은 전자장치의 프로세서 에 의해 실행될 수 있다. 도 3에 도시된 바와 같이, 프로세서는 수신되는 발화 음성에 대한 발화자 특성 을 식별할 수 있다(S31). 또한, 프로세서는 식별된 발화자 특성에 기초하여 복수의 발화자 그룹 중 어느 하나의 발화자 그룹을 식별 할 수 있다(S32). 또한, 프로세서는 복수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 식별된 발화자 그룹에 대응하는 음성인식모델에 기초하여 발화 음성의 인식결과를 획득할 수 있다(S33). 또한, 프로세서는 획득된 인식결과에 따른 동작을 수행할 수 있다. 이와 같이, 본 실시예의 제어방법에 따르면, 발화자 그룹의 음성인식모델에 기초하여 음성인식처리를 수행할 수 있으므로, 발화자에게만 개인화된 음성인식모델에 기초하여 음성인식처리를 수행하는 경우에 비해 발화 의도 와 인식결과 간의 적합성을 더욱 향상시킬 수 있다. 도 4는 도 3의 동작 S33과 관련하여, 인식결과를 획득하는 일 예를 도시한다. 이하에서는, 발화자가 발화 음 성으로서 \"슈트\"를 발화한 경우를 가정하여, 프로세서가 \"슈트\"에 대한 인식결과를 획득하는 과정에 대 해 자세히 설명한다. 프로세서는 발화 음성에 기초하여 발화자 특성을 식별할 수 있다. 프로세서는 발화 음성에 기초 하여 발화자 특성이, 예컨대, 20대 남성이거나, 20대 여성임을 식별할 수 있다. 이 경우, 프로세서는 각 발 화자 특성을 식별하기 위한 발화 음성의 톤, 세기, 빠르기 등에 관한 정보를 참조할 수 있으며, 이러한 정보 는 룩업테이블의 형태로 저장부 또는 서버저장부에 저장된 것일 수 있다. 프로세서는 발화자 그룹 별 음성인식모델 중 발화자 특성에 기초하여 식별된 발화자 그룹에 대응하는 음성인식모델을 선택할 수 있다. 일 예로, 발화자 그룹 별 음성인식모델은 성별과 나이 별로 마련될 수 있 으며, 예컨대, 도 4에 도시된 바와 같이, 20대 남성 그룹에 대응하는 제3음성인식모델과 20대 여성 그룹에 대응하는 제4음성인식모델이 마련될 수 있다. 다만, 제3음성인식모델과 제4음성인식모델은 적어도 2이상의 음성인식모델, 예컨대, 20대 그룹의 음성인식모델 및 남성 그룹의 음성인식모델의 조합과, 20대 그룹의 음성인식모델 및 여성 그룹의 음성인식모델의 조합으로 각각 마련될 수 있다. 만일, 발화자 특성이 20대 남성인 것으로 식별된 경우, 프로세서는 20대 남성 그룹에 대응하는 제3음성인식 모델을 선택하고, 제3음성인식모델에 기초하여 발화 음성 \"슈트\"에 대한 음성인식처리를 수행할 수 있다. 반면에, 발화자 특성이 20대 여성인 것으로 식별된 경우, 프로세서는 20대 여성 그룹에 대응하는 제4 음성인식모델을 선택하고, 제4음성인식모델에 기초하여 발화 음성 \"슈트\"에 대한 음성인식처리를 수 행할 수 있다. 좀더 구체적으로, 발화자 그룹 별 음성인식모델은 발화 음성에 대한 복수의 후보 인식결과와, 각 후보 인식결과에 대한 인식정확도에 관한 정보를 포함할 수 있다. 후보 인식결과는 발화 음성에 대한 텍스트 데이 터와 소정 유사도 이상인 텍스트 데이터를 포함할 수 있으며, 인식정확도는 각 후보 인식결과가 발화 의도에 따라 정확하게 인식된 정도, 다시 말해, 발화 의도에 대한 각 후보 인식결과의 발화 의도 적합성을 의미할 수 있 다. 복수의 후보 인식결과와 각 후보 인식결과에 대한 인식정확도는 발화자 그룹 별로 마련된 음성인식모델 별로 상 이할 수 있다. 일 예로, 도 4에 도시된 바와 같이, 제3음성인식모델에 따르면, 발화 음성 \"슈트\"에 대한 후보 인식결과는 \"슛\", \"슈츠\", \"슈트\"가 될 수 있으며, 각 후보 인식결과 \"슛\", \"슈츠\", \"슈트\"에 대한 인식정 확도는 각각 0.9, 0.3, 0.1이 될 수 있다. 다만, 후보 인식결과와 각 후보 인식결과의 인식정확도는 설명의 편 의를 위한 것이므로, 설계 방법에 따라 다양하게 마련될 수 있다. 여기서, 각 후보 인식결과 \"슛\", \"슈츠\", \"슈 트\" 각각에 대한 인식정확도 0.9, 0.3, 0.1는 각 후보 인식결과 \"슛\", \"슈츠\", \"슈트\" 각각에 대한 20대 남성 그룹의 발화 의도에 적합한 정도를 나타낼 수 있다. 이 경우, 프로세서는 발화 음성 \"슈트\"에 대응하여 복수의 후보 인식결과 \"슛\", \"슈츠\", \"슈트\" 중, 예 컨대, 인식정확도가 가장 높은 후보 인식결과 \"슛\"을 인식결과로 획득할 수 있다. 즉, 프로세서는 발화 음 성 \"슈트\"에 대응하여 20대 남성 그룹의 발화 의도에 가장 적합하다고 판단한 인식결과 \"슛\"을 획득할 수 있 다. 반면에, 발화자 특성이 20대 여성인 것으로 식별된 경우, 제4음성인식모델에 따르면, 발화 음성 \"슈트\" 에 대한 후보 인식결과는 \"슈츠\", \"슛\", \"슈트\"가 될 수 있으며, 각 후보 인식결과 \"슈츠\", \"슛\", \"슈트\"에 대 한 인식정확도는 각각 0.8, 0.4, 0.2가 될 수 있다. 여기서, 각 후보 인식결과 \"슈츠\", \"슛\", \"슈트\" 각각에 대 한 인식정확도 0.8, 0.4, 0.2는, 각 후보 인식결과 \"슈츠\", \"슛\", \"슈트\" 각각에 대한 20대 여성 그룹의 발화 의도에 적합한 정도를 나타낼 수 있다. 이 경우, 프로세서는 발화 음성 \"슈트\"에 대응하여 복수의 후보 인식결과는 \"슈츠\", \"슛\", \"슈트\" 중, 예컨대, 인식정확도가 가장 높은 후보 인식결과 \"슈츠\"를 인식결과로 획득할 수 있다. 즉, 프로세서는 발화 음성 \"슈트\"에 대응하여 20대 여성 그룹의 발화 의도에 가장 적합하다고 판단한 인식결과 \"슈츠\"을 획득할 수 있다. 이와 같이, 동일한 발화 음성이라도 발화자 특성에 기초한 발화자 그룹에 따라, 예컨대, 20대 남성 그룹인지, 20대 여성 그룹인지에 따라 상이한 인식결과를 획득할 수 있다. 즉, 본 실시예의 프로세서에 따 르면, 동일한 발화 음성이라도 발화자의 발화 의도에 가장 적합한 인식결과를 획득할 수 있다. 특히, 본 실시예의 프로세서에 따르면, 발화자의 발화 음성이 발화 의도와 상이한 경우라도, 발화 의 도에 부합하는 인식결과를 획득할 수 있다. 일 예로, 발화자인 20대 남성이 \"슛\" 장면을 시청할 의도로 \"슈 트\"라고 발화하는 경우와 같이, 발화 의도와 발화 음성이 일치하지 않을 수 있다. 이 경우, 프로세서는 제3음성인식모델에 기초하여 발화 음성 \"슈트\"에 대해서, 예컨대, 인식정확도가 가장 높은 후보 인식결 과 \"슛\"을 인식결과로 획득할 수 있다. 즉, 제3음성인식모델에 따르면, 발화 음성 \"슈트\"에 대응하여 20대 남성 그룹의 발화 의도에 가장 적합 하다고 판단한 인식결과 \"슛\"을 획득함으로써, 발화자의 발화 의도와 발화 음성 간의 불일치에도 불구하 고, 발화 의도에 가장 적합한 인식결과 \"슛\"을 획득할 수 있다. 또한, 발화 음성 \"슈트\"에 대응하여 인식결과 \"슛\"을 획득함에 있어서, 20대 남성 그룹의 발화 의도에 적합 한 정도를 나타내는 인식정확도를 고려할 수 있으므로, 인식결과 \"슛\"에 대한 획득 용이성과 신뢰성을 보장할 수 있다. 이와 같이, 본 실시예의 프로세서에 따르면, 발화 의도와 발화 음성 간의 불일치에도 불구하고, 발화 의 도에 적합한 인식결과를 획득할 수 있으며, 인식정확도에 기초하여 인식결과를 획득함으로써, 인식결과에 대한 획득 용이성과 신뢰성을 보장할 수 있다. 따라서, 음성인식 기능 전반에 대한 활용성 및 신뢰성을 향상시킬 수 있다. 한편, 앞선 실시예에서는, 발화자 그룹 별로 마련된 음성인식엔진에 기초하여 음성인식처리를 수행하는 경우에 대해서 설명하였으나, 프로세서는 발화자에 개인화된, 즉, 복수의 발화자 별로 마련된 음성인식엔진 중 특정 발화자에 대응하는 음성인식엔진에 기초하여 음성인식처리를 수행함으로써, 발화자의 발화 의도에 적합한 인식결과를 획득할 수 있다. 일 예로, 도 4에 도시된 제3음성인식모델이 발화자에 대응하는 음성인식엔진으로 가정하면, 프로세 서는 발화 음성에 기초하여 발화자를 식별하고, 식별된 발화자에 대응하는 음성인식엔진을 식별할 수 있다. 프로세서는, 예컨대, 발화자의 발화 음성 \"슈트\"에 대하여, 식별된 음성인식엔진 에 기초하여 각 후보 인식결과 \"슛\", \"슈츠\", \"슈트\"에 대한 인식정확도에 따라 최적화된, 즉, 발화자의 발 화 의도에 가장 적합한 인식결과 \"슛\"를 획득할 수 있다. 또한, 발화자가 \"슛\" 장면을 시청할 의도이지만, \"슈트\"라고 발화하는 경우라도, 프로세서는 발화자 에 개인화된 음성인식모델에 기초하여 발화 음성 \"슈트\"에 대해서, 예컨대, 인식정확도가 가장 높은 후 보 인식결과 \"슛\"을 인식결과로 획득할 수 있다. 따라서, 발화자의 발화 의도와 발화 음성 간의 불일치에 도 불구하고, 발화 의도에 가장 적합한 인식결과 \"슛\"을 획득할 수 있다. 도 5는 도 3의 동작 S33과 관련하여, 발화 음성에 대한 인식 성공 여부에 따라 인식정확도를 조정하는 전자장치 에 대한 제어방법의 일 예를 도시한다. 도 5의 각 동작은 전자장치의 프로세서에 의해 실행될 수 있다. 도 5에 도시된 동작 S51과 S52는 도 3의 동작 S31과 S32와 동일하므로, 중복되는 동작에 관한 설명은 생략한다. 도 5를 참조하면, 프로세서는 복수의 발화자 그룹 별로 마련된 복수의 음성인식모델 중 식별된 발화자 그룹 에 대응하는 음성인식모델을 식별하고, 식별된 음성인식모델에 기초하여 인식정확도가 서로 다른 복수의 후보 인식결과 중 인식정확도가 가장 높은 제1인식결과를 획득할 수 있으며(S53), 획득된 제1인식결과에 따른 동작을 수행할 수 있다(S54). 또한, 프로세서는 발화 음성에 대한 인식 성공 여부를 식별할 수 있다(S55). 만일, 발화 음성에 대한 인식에 성공하지 않는 경우, 프로세서는 복수의 후보 인식결과 중 차상위인 제2 인식결과를 획득하고(S56), 획득된 제2인식결과에 따른 동작을 수행할 수 있으며(S57), 제2인식결과의 인식정확 도가 인식결과의 인식정확도보다 상향되도록 조정할 수 있다(S58). 예컨대, 제2인식결과에 대한 인식정확도가 종전 인식정확도보다 상향되도록 조정될 수 있다. 이와 같이, 본 실시예의 전자장치의 제어방법에 따르면, 발화 음성에 대한 인식 성공 여부에 따라 후보 인식결과에 대한 인식정확도를 조정할 수 있으므로, 발화 의도와 인식결과 간의 적합성을 더욱 향상시키고, 나 아가 음성인식 기능에 대한 활용성 및 신뢰성을 더욱 향상시킬 수 있다. 도 6은 도 5의 동작 S55와 관련하여, 발화 의도와 발화 음성이 상이하더라도, 인식정확도를 조정함으로써, 발화 의도에 부합하는 인식결과를 획득하는 일 예를 도시한다. 이하에서는, 발화자의 발화자 특성이 20대 남성이 며, 발화자의 발화 의도는 제목이 \"슈츠\"인 드라마를 시청하는 것이지만, 제1발화 음성 \"슈트\"로 발화한 경우를 가정한다. 프로세서는 제1발화 음성 \"슈트\"에 대응하여 발화자 특성이 20대 남성인 것으로 식별하고, 20대 남성 그룹의 제3음성인식모델에 기초하여 제1발화 음성 \"슈트\"에 대한 음성인식처리를 수행할 수 있다. 즉, 프로세서는 제3음성인식모델에 기초하여 복수의 후보 인식결과 \"슛\", \"슈츠\", \"슈트\" 중, 예컨대, 인식 정확도가 가장 높은 후보 인식결과 \"슛\"을 제1인식결과로 획득할 수 있다. 프로세서는 획득된 제1인식결과 \"슛\"에 따른 동작을 수행할 수 있다. 일 예로, 제1인식결과 \"슛\"을 문자 그 대로 표시하거나, \"슛\" 장면의 영상을 표시할 수 있다. 다만, 인식결과에 따른 동작은 제1인식결과와 관련된 표 시동작에 한정되는 것은 아니므로, 설계 방법에 따라 다양하게 마련될 수 있다. 만일, 발화자가 제1인식결과 \"슛\"에 따른 동작에 대하여 만족하지 않는 경우, 만족할 만한 인식결과를 얻기 위해 \"슈트\"를 재차 발화하는 경우가 있을 수 있다. 이러한 경우를 고려하여, 프로세서는 제1인식결과에 따른 동작에 대응하여, 제1발화 음성 \"슈트\"에 대 한 인식 성공 여부를 식별할 수 있다. 일 예로, 제1인식결과에 따른 동작에 대응하여, 발화자로부터 수신되 는 제2발화 음성에 기초하여 제1발화 음성 \"슈트\"에 대한 인식 성공 여부를 식별할 수 있다. 이 경우, 프로세서는 제1발화 음성과 제2발화 음성 간의 유사도를 고려할 수 있다. 제1발화 음성 과 제2발화 음성 간의 유사도는, 예컨대, 마르코프 모델, 동적 시간 왜곡 등의 알고리즘에 따라 유사도 가 식별되는 경우, 제1발화 음성과 제2발화 음성 간의 유사도를 나타내는 점수를 부여하고, 해당 점수 가 기설정값 이상인 경우 유사한 것으로 식별하는 반면에, 해당 점수가 기설정값 미만인 경우 유사하지 않은 것으로 식별할 수 있다. 다만, 제1발화 음성과 제2발화 음성 간의 유사도를 식별하는 방법은 이에 한정되 는 것은 아니므로, 설계 방법에 따라 다양하게 마련될 수 있다. 제1발화 음성과 제2발화 음성 간의 유사도가 기설정값 미만인 경우, 프로세서는 제1발화 음성 \"슈트\"에 대한 인식에 성공한 것으로 식별할 수 있다. 앞서 가정한 바와 달리, 발화자의 발화 의도가 \"슛\" 장면이지만, 발화 음성 \"슈트\"인 경우에 대응하여, 제1인식결과 \"슛\"이 문자 그대로 표시된다면, 제1인식결 과 \"슛\"이 발화 의도에 부합하므로, 프로세서는, 예컨대, \"맞아\"라는 제2발화 음성을 수신하면, 제1발 화 음성 \"슈트\"가 제2발화 음성 \"맞아\"와 유사하지 않으므로, 제1발화 음성 \"슈트\"에 대한 인식에 성공한 것으로 식별할 수 있다. 반면에, 제1발화 음성과 제2발화 음성 간의 유사도가 기설정값 이상인 경우, 프로세서는 제1발화 음성 \"슈트\"에 대한 인식에 성공하지 않은 것으로 식별할 수 있다. 앞서 가정한 바와 같이, 발화 의도가 제 목이 \"슈츠\"인 드라마를 시청하는 것이지만, 발화 음성 \"슈트\"인 경우에 대응하여, 제1인식결과 \"슛\"이 문 자 그대로 표시된다면, 제1인식결과 \"슛\"이 발화 의도에 부합하지 않으므로, 프로세서는, 예컨대, \"슈트\"라 는 제2발화 음성을 재차 수신할 수 있다. 이 경우, 프로세서는 제1발화 음성 \"슈트\"가 제2발화 음 성 \"슈트\"와 동일하므로, 제1발화 음성 \"슈트\"에 대한 인식에 성공하지 않은 것으로 식별할 수 있다. 이렇게 제1발화 음성과 제2발화 음성 간의 유사도에 기초하여 제1발화 음성에 대한 인식에 성공하 지 않은 것으로 식별되면, 프로세서는 제3음성인식모델에 기초하여 제2인식결과를 획득할 수 있다. 예 컨대, 복수의 후보 인식결과 \"슛\", \"슈츠\", \"슈트\" 중 인식정확도가 두 번째로 높은 후보 인식결과 \"슈츠\"를 제 2인식결과로 획득하고, 획득된 제2인식결과 \"슈츠\"에 따른 동작을 수행할 수 있다. 일 예로, 제2인식결과 \"슈츠\"를 문자 그대로 표시하거나, 제목이 \"슈츠\"인 드라마에 관한 정보를 표시할 수 있다. 프로세서는 제2인식결과 \"슈츠\"에 따른 동작에 대응하여 제2발화 음성 \"슈트\"에 대한 인식 성공 여부를 식별할 수 있다. 제2발화 음성 \"슈트\"에 대한 인식 성공 여부를 식별하는 방법은, 앞서 제1발화 음성에 대한 인식 성공 여부를 식별한 방법, 예컨대, 제2발화 음성과 후속하는 발화 음성 간의 유사도에 기초하여 식별하는 방법과 유사하므로, 중복되는 설명은 생략한다. 만일, 프로세서는 제2발화 음성 \"슈트\"에 대한 인식에 성공한 것으로 식별하는 경우, 제2발화 음성(6 2)에 대한 제2인식결과 \"슈츠\"에 대한 인식정확도를 조정할 수 있다. 예컨대, 하기의 인식정확도 조정식에 기초 하여 제2인식결과 \"슈츠\"에 대한 인식정확도를 조정할 수 있다."}
{"patent_id": "10-2019-0110441", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "인식정확도 조정식에서 weight는 제1인식결과에 대응하여 제2발화 음성의 발화 횟수, 톤, 세기 등을 고려하 여 다양한 방법으로 결정될 수 있다. 따라서, 프로세서는 제2인식결과 \"슈츠\"에 대한 인식정확도를, 예컨대, 인식정확도(ORIG.) 0.3에서 인식정확도(NEW) 0.8로 상향 조정할 수 있으며, 반면에, 제1인식결과 \"슛\" 에 대한 인식정확도를, 예컨대, 인식정확도(ORIG.) 0.9에서 인식정확도(NEW) 0.7로 하향 조정할 수 있다. 따라서, 차후에 발화자 또는 다른 발화자로부터 \"슈트\"라는 발화 음성이 수신되는 경우, 발화자 또는 다 른 발화자의 발화자 특성이 20대 남성으로 식별되면, 프로세서는 인식정확도가 조정된 제3음성인식모델(4 3)에 기초하여 인식결과 \"슈츠\"를 획득할 수 있다. 즉, 발화 의도 \"슈츠\"와 발화 음성 \"슈트\"가 상이하더라도, 발화 의도 \"슈츠\"에 부합하는 인식결과 \"슈츠\"를 획득할 수 있다. 이와 같이, 본 실시예의 프로세서에 따르면, 발화 음성에 대한 인식 성공 여부에 기초하여 음성인식모델의 인식정확도를 조정함으로써, 발화 의도와 발화 음성이 상이하더라도, 발화 의도에 부합하는 인식결과를 획득할 수 있으므로, 발화 의도와 인식결과 간의 적합성을 향상시키고, 음성인식 기능에 대한 활용성 및 신뢰성을 향상 시킬 수 있다. 한편, 프로세서는 발명자 그룹에 대응하는 음성인식엔진에 대한 인식정확도를 조정한 경우, 다른 발명자 그 룹의 음성인식엔진에 대해서도 인식정확도를 조정할 수 있다. 예컨대, 앞서 설명한 바와 같이, 20대 남성 그룹 의 제3음성인식모델에 대하여 제2인식결과 \"슈츠\"에 대한 인식정확도가 상향되고, 제1인식결과 \"슛\"에 대한 인식정확도가 하향된 경우, 프로세서는, 예컨대, 20대 여성 그룹과 같이, 나이에 대하여 그룹 간의 관련성 이 있는 발화자 그룹을 식별할 수 있다. 프로세서는 관련성이 있는 것으로 식별된 20대 여성 그룹의 제4음 성인식엔진의 인식결과에 대해서도 인식정확도를 조정할 수 있다. 일 예로, 제3음성인식모델에 조정된 인식정확도와 동일한 정도로 후보 인식결과 \"슈츠\" 및 \"슛\"의 인식정확도를 조정하거나, 제4음성인식엔진에 서는 후보 인식결과 \"슈츠\" 및 \"슛\"의 인식정확도가 각각 0.8 및 0.7인 점을 고려하여, 제3음성인식모델에 조정된 인식정확도와 비례하도록 0.9 및 0.6으로 각각 조정할 수 있다. 다만, 나이뿐만 아니라, 성별, 이름, 거주지, 국적, 직업 등에 대하여 그룹 간의 관련성이 있는 다른 그룹의 음성인식모델의 인식정확도를 조정할 수 있으며, 설계 방법에 따라 조정 정도를 다양하게 설정할 수 있다. 또한, 앞선 실시예에서는, 발화자 그룹 별로 마련된 음성인식엔진에 기초하여 음성인식처리를 수행하는 경우에 대해서 설명하였으나, 프로세서는 발화자에 개인화된 음성인식엔진에 기초한 음성인식처리에 대하여, 발 화 음성에 대한 인식 성공 여부에 따라 음성인식모델의 인식정확도를 조정할 수 있다. 이하에서는, 도 6을 참조하여, 제3음성인식모델이 발화자에 개인화된 음성인식엔진으로 가정하고, 개인화된 음성인식엔 진에 기초한 음성인식처리의 경우에 대해 설명한다. 다만, 설명의 편의를 위해 중복되는 설명은 생략하고, 상이한 부분 위주로 설명한다. 프로세서는 발화 음성에 기초하여 발화자를 식별하고, 식별된 발화자에 대응하는, 즉, 개인화된 음성인식엔진을 식별할 수 있다. 프로세서는 제1발화 음성과 제2발화 음성 간의 유사도에 따라 제1발화 음성 \"슈트\"에 대한 인식 성공 여부를 식별할 수 있다. 만일, 제1발화 음성과 제2발화 음성 간의 유사도가 기설정값 이상인 경우, 프로세서는 제1발화 음성 \"슈트\"에 대한 인식에 성공하지 않은 것으로 식별할 수 있다. 프로세서는, 예컨대, \"슈트\"라는 제2발화 음성을 재차 수신하면, 제1발화 음성 \"슈트\"가 제2발화 음성 \"슈트\"와 동일하므로, 제1발화 음성 \"슈트\"에 대한 인식에 성공하지 않은 것으로 식별할 수 있다. 이렇게 제1발화 음성과 제2발화 음성 간의 유사도에 기초하여 제1발화 음성에 대한 인식에 성공하 지 않은 것으로 식별되면, 프로세서는 음성인식모델에 기초하여 제2인식결과 \"슈츠\"를 획득할 수 있으 며, 제2인식결과 \"슈츠\"에 따른 동작에 대응하여 제2발화 음성 \"슈트\"에 대한 인식 성공 여부를 식별할 수 있다. 만일, 제2발화 음성 \"슈트\"에 대한 인식에 성공한 것으로 식별되면, 프로세서는 제2발화 음성 에 대한 제2인식결과 \"슈츠\"에 대한 인식정확도를 조정할 수 있다. 이와 같이, 발화자에 개인화된 음성인식엔진에 기초한 음성인식처리에 대하여, 발화 음성에 대한 인식 성 공 여부에 따라 음성인식모델의 인식정확도를 조정할 수 있으므로, 발화 의도에 가장 적합한 인식결과를 획득할 수 있다. 도 7은 도 5의 동작 S55와 관련하여, 검색어가 입력되는 경우 인식정확도를 조정하는 일 예를 도시한다. 이하에 서는, 발화자 특성이 20대 남성인 경우, 발화자의 발화 의도는 제목이 \"슈츠\"인 드라마를 시청하는 것이나, 발화 음성이 \"슈트\"인 경우를 가정하여, 발화 음성 \"슈트\"의 제1인식결과 \"슛\"에 따른 동작에 대응하여 검색어가 입력된 경우, 인식정확도가 조정되는 과정에 대해 설명한다. 즉, 프로세서는 발화 음성 \"슈트\"에 대하여 20대 남성 그룹의 제3음성인식모델에 기초하여, 예컨대, 인식정확도가 가장 높은 후보 인식결과 \"슛\"을 제1인식결과로 획득하고, 획득한 제1인식결과 \"슛\"에 따른 동작 을 수행할 수 있다. 만일, 발화자가 제1인식결과 \"슛\"에 따른 동작에 대하여 만족하지 않는 경우, 브라우저 등의 화면을 통 해 직접 검색어 \"슈트\", \"슈츠\" 등의 검색어을 입력하여 만족할 만한 검색결과를 찾는 경우가 있을 수 있다. 여기서, 검색어 \"슈트\", \"슈츠\" 등은 발화 음성 \"슈트\", \"슈츠\"에 대응하는 텍스트일 수 있다. 이러한 경우를 고려하여, 프로세서는, 예컨대, 제1인식결과 \"슛\"과 검색어 \"슈트\", \"슈츠\" 등 간의 유 사도에 기초하여 발화 음성 \"슈트\"에 대한 인식 성공 여부를 식별할 수 있다. 만일, 검색어 \"슈트\", \"슈 츠\" 등과 제1인식결과 \"슛\" 간의 유사도가 기설정값 이상인 경우, 프로세서는 발화 음성 \"슈트\"에 대한 인식에 성공하지 않은 것으로 식별할 수 있다. 또한, 프로세서는 검색어 \"슈트\", \"슈츠\" 등에 대한 검색 성공 여부를 식별할 수 있다. 일 예로, 검색 결과에 대한 발화자의 사용 형태 또는 사용 이력, 예컨대, 검색어 \"슈츠\"에 대한 검색결과에 검 색어 \"슈츠\"와 관련된 다양한 메뉴가 포함된 경우, 각 메뉴를 선택하는 발화자의 입력이 있다면, 검색어 \"슈츠\"에 대한 검색에 성공한 것으로 식별할 수 있다. 다만, 검색 성공 여부를 식별하는 방법을 한정하는 것은 아니므로, 설계 방법에 따라 다양한 방법으로 검색 성공 여부를 식별할 수 있다. 이렇게, 발화 음성 \"슈트\"에 대한 인식에 성공하지 않고, 검색어 \"슈츠\"에 대한 검색에 성공한 것으로 식별되는 경우, 프로세서는 제3음성인식모델에 있어서, 발화 음성 \"슈트\"에 대한 후보 인식결과 \"슛\"과 검색어 \"슈츠\"에 대응하는 후보 검색결과 \"슈츠\"에 대한 인식정확도를 조정할 수 있다. 후보 인식결 과 \"슈츠\"에 대한 인식정확도는, 예컨대, 0.3에서 0.8로 조정될 수 있으며, 만일, 검색어 \"슈츠\"가 후보 인 식결과에 포함되지 않은 경우, 후보 인식결과에 \"슈츠\"를 추가할 수 있다. 반면에, 인식결과 \"슛\"에 대한 인식정확도는, 예컨대, 0.9에서 0.7로 조정될 수 있다. 따라서, 차후에 발화자 또는 다른 발화자로부터 \"슈트\"라는 발화 음성이 수신되는 경우, 발화자 또는 다른 발화자의 발화자 특성이 20대 남성으로 식별되면, 프로세서는 인식정확도가 조정된 제3음성인식모델 에 기초하여 제1인식결과로서 \"슈츠\"를 획득할 수 있다. 한편, 이하에서는, 도 6을 함께 참조하여, 제3음성인식모델에 있어서, 제1발화 음성 \"슈트\"에 대한 후 보 인식결과가 \"슛\", \"슈트\", \"슈츠\"이며, 각 후보 인식결과에 대한 인식정확도는 각각 0.9, 0.3, 0.1인 경우, 즉, 후보 인식결과 중 \"슈트\"와 \"슈츠\"의 인식정확도가 바뀐 경우를 가정하여, 제2발화 음성 \"슈트\"의 제2 인식결과 \"슈트\"에 따른 동작에 대응하여 검색어가 입력된 경우, 인식정확도가 조정되는 과정에 대해 설명한다. 즉, 프로세서는 제1발화 음성 \"슈트\"의 제1인식결과 \"슛\"에 따른 동작에 대응하여, 제2발화 음성 \"슈트\"가 수신된 경우, 예컨대, 제1발화 음성 \"슈트\"와 제2발화 음성 \"슈트\" 간의 유사도에 기초하여 제1발화 음성 \"슈트\"에 대한 인식에 성공하지 않는 것으로 식별하고, 제2발화 음성 \"슈트\"에 대한 제2 인식결과 \"슈트\"에 따른 동작을 수행할 수 있다. 발화자는 제2발화 음성 \"슈트\"에 대한 제2인식결과 \"슈트\"에 따른 동작에 대하여, 브라우저 등의 화면 을 통해 직접 검색어 \"슈츠\" 등의 검색어을 입력하여 만족할 만한 검색결과를 찾는 경우가 있을 수 있다. 앞선 실시예에서는, 제1인식결과 \"슛\"에 따른 동작에 대응하여, 검색어가 입력된 경우이나, 본 실시 예에서는 제2인식결과 \"슈트\"에 따른 동작에 대응하여 검색어가 입력된 경우인 점에서 차이가 있다. 이러한 경우를 고려하여, 프로세서는, 예컨대, 제2인식결과 \"슈트\"와 검색어 \"슈츠\" 등 간의 유사도에 기초하여 제2발화 음성 \"슈트\"에 대한 인식 성공 여부를 식별할 수 있으며, 검색결과에 대한 사용 형태 또는 사용 이력에 기초하여 검색어 \"슈츠\" 등에 대한 검색 성공 여부를 식별할 수 있다. 만일, 제2발화 음성 \"슈트\"에 대한 인식에 성공하지 않고, 검색어 \"슈츠\"에 대한 검색에 성공한 것으로 식별되는 경우, 프로세서는 제3음성인식모델에 있어서, 검색어 \"슈츠\"에 대응하는 후보 검색결과 \"슈츠\"에 대한 인식정확도를, 예컨대, 최상위가 되도록 조정할 수 있다. 따라서, 차후에 발화자 또는 다른 발화자로부터 \"슈트\"라는 제1발화 음성이 수신되는 경우라도, 발화자 또는 다른 발화자의 발화자 특성이 20대 남성으로 식별되면, 프로세서는 인식정확도가 조정된 제3음성인식모델에 기초하여 제1인식결과로 서 \"슈츠\"를 획득할 수 있다. 이와 같이, 본 실시예의 프로세서에 따르면, 인식결과에 대한 입력 검색어에 따라 인식정확도를 조정함으로 써, 발화 의도와 인식결과 간의 적합성을 향상시키고, 음성인식 기능에 대한 활용성 및 신뢰성을 향상시킬 수 있다. 도 8은 도 5의 동작 S55와 관련하여, 발화자의 대화가 수신되는 경우, 인식정확도를 조정하는 일 예를 도시한다. 이하에서는, 발화자 특성이 20대 남성인 경우, 발화자의 발화 의도는 제목이 \"슈츠\"인 드라마를 시청하는 것이나, 발화 음성이 \"슈트\"인 경우를 가정한다. 이 경우, 발화 음성 \"슈트\"의 제1인식결과 \"슛\"에 따른 동작에 대응하여 대화가 수신됨에 따라 인식정확도가 조정되는 과정에 대해 설명한다. 즉, 프로세서는 발화 음성 \"슈트\"에 대하여 20대 남성 그룹의 제3음성인식모델에 기초하여, 예컨대, 인식정확도가 가장 높은 후보 인식결과 \"슛\"을 제1인식결과로 획득하고, 획득한 제1인식결과 \"슛\"에 따른 동작 을 수행할 수 있다. 제1인식결과 \"슛\"에 따른 동작에 대응하여 발화자와 상대 발화자 간에 제1인식결과 \"슛\"에 따른 동작에 관한 대화가 있을 수 있다. 예컨대, 상대 발화자가 발화자의 발화 음성 \"슈트\"를 듣고, 상대 발화 음 성 \"슈츠야, 슈츠\"을 발화할 수 있다. 이런 경우, 프로세서는 발화자와 상대 발화자 간의 대화, 예컨대, 상대 발화자의 상대 발화 음 성에 기초하여 발화 음성 \"슈트\"에 대한 인식 성공 여부를 식별할 수 있다. 일 예로, 프로세서는 상 대 발화자의 상대 발화 음성에 음성인식처리를 수행함으로써, 상대 발화 음성로부터 키워드 \"슈 츠\"를 식별하고, 예컨대, 제1인식결과 \"슛\"과 키워드 간의 유사도에 기초하여 발화 음성 \"슈트\"에 대한 인식 성공 여부를 식별할 수 있다. 만일, 프로세서는 제1인식결과 \"슛\"과 키워드 \"슈츠\" 간의 유사도가 기설정값 이상인 경우, 발화 음성 \"슈트\"에 대한 인식에 성공하지 않은 것으로 식별하고, 발화 의도가 키워드 \"슈츠\"인 것으로 식별할 수 있다. 이렇게, 발화 음성 \"슈트\"에 대한 인식에 성공하지 않고, 발화 의도가 키워드 \"슈츠\"인 것으로 식별되는 경 우, 후보 인식결과 \"슛\"과 키워드 \"슈츠\"에 대응하는 후보 검색결과 \"슈츠\"에 대한 인식정확도를 조정할 수 있 다. 후보 인식결과 \"슈츠\"에 대한 인식정확도는, 예컨대, 0.3에서 0.8로 조정될 수 있으며, 만일, 키워드 \"슈츠\"가 후보 인식결과에 포함되지 않은 경우, 후보 인식결과에 \"슈츠\"를 추가할 수 있다. 반면에, 인식결과 \"슛\"에 대한 인식정확도는, 예컨대, 0.9에서 0.7로 조정될 수 있다. 따라서, 차후에 발화자 또는 다른 발화자로부터 \"슈트\"라는 발화 음성이 수신되는 경우, 발화자 또는 다른 발화자의 발화자 특성이 20대 남성으로 식별되면, 프로세서는 인식정확도가 조정된 제3음성인식모델 에 기초하여 제1인식결과로서 \"슈츠\"를 획득할 수 있다. 한편, 이하에서는, 도 6을 함께 참조하여, 제3음성인식모델에 있어서, 제1발화 음성 \"슈트\"에 대한 후 보 인식결과가 \"슛\", \"슈트\", \"슈츠\"이며, 각 후보 인식결과에 대한 인식정확도는 각각 0.9, 0.3, 0.1인 경우, 즉, 후보 인식결과 중 \"슈트\"와 \"슈츠\"의 인식정확도가 바뀐 경우를 가정하여, 제2발화 음성 \"슈트\"의 제2 인식결과 \"슈트\"에 따른 동작에 대응하여 대화가 수신된 경우, 인식정확도가 조정되는 과정에 대해 설명한다. 즉, 프로세서는 제1발화 음성 \"슈트\"의 제1인식결과 \"슛\"에 따른 동작에 대응하여, 제2발화 음성 \"슈트\"가 수신된 경우, 예컨대, 제1발화 음성 \"슈트\"와 제2발화 음성 \"슈트\" 간의 유사도에 기초하여 제1발화 음성 \"슈트\"에 대한 인식에 성공하지 않는 것으로 식별하고, 제2발화 음성 \"슈트\"에 대한 제2 인식결과 \"슈트\"에 따른 동작을 수행할 수 있다. 제2발화 음성 \"슈트\"에 대한 제2인식결과 \"슈트\"에 따른 동작에 대응하여, 발화자와 상대 발화자 간 에 제2인식결과 \"슈트\"에 따른 동작에 관한 대화가 있을 수 있다. 예컨대, 상대 발화자가 발화자의 발화 음성 \"슈트\"를 듣고, 상대 발화 음성 \"슈츠야, 슈츠\"을 발화할 수 있다. 이런 경우, 프로세서는 발화자와 상대 발화자 간의 대화, 예컨대, 상대 발화자의 상대 발화 음 성에 기초하여 제2발화 음성 \"슈트\"에 대한 인식 성공 여부를 식별할 수 있다. 일 예로, 프로세서 는 상대 발화자의 상대 발화 음성에 음성인식처리를 수행함으로써, 상대 발화 음성로부터 키워드 \"슈츠\"를 식별하고, 예컨대, 제2인식결과 \"슈트\"와 키워드 \"슈츠\" 간의 유사도에 기초하여 제2발화 음성 \"슈트\"에 대한 인식에 성공하지 않고, 발화 의도가 키워드 \"슈츠\"인 것으로 식별할 수 있다. 이렇게, 제2발화 음성 \"슈트\"에 대한 인식에 성공하지 않고, 발화 의도가 키워드 \"슈츠\"인 것으로 식별되는 경우, 키워드 \"슈츠\"에 대응하는 후보 검색결과 \"슈츠\"에 대한 인식정확도를, 예컨대, 최상위가 되도록 조정할 수 있으며, 만일, 키워드 \"슈츠\"가 후보 인식결과에 포함되지 않은 경우, 후보 인식결과에 \"슈츠\"를 추가할 수 있다. 따라서, 차후에 \"슈트\"라는 제1발화 음성이 수신되는 경우, 발화자 특성이 20대 남성으로 식별되면, 프로세서는 인식정확도가 조정된 제3음성인식모델에 기초하여 제1인식결과로서 \"슈츠\"를 획득할 수 있 다. 이와 같이, 본 실시예의 프로세서에 따르면, 인식결과에 대응하여 수신된 대화에 따라 인식정확도를 조정함 으로써, 발화 의도와 인식결과 간의 적합성을 향상시키고, 음성인식 기능에 대한 활용성 및 신뢰성을 향상시킬 수 있다. 한편, 도 7 및 도 8의 실시예에서는, 발화자 그룹 별로 마련된 음성인식엔진에 기초하여 음성인식처리를 수행하 는 경우에 대해서 설명하였으나, 프로세서는 발화자에 개인화된 음성인식엔진에 기초한 음성인식처리에 대하여, 발화 음성에 대한 인식결과와, 검색어 또는 상대 발화 음성로부터의 키워드 간의 유사도에 기초하여, 발화 음성에 대한 인식 성공 여부를 식별할 수 있다. 만일, 발화 음성에 대한 인식에 성공하지 않은 것으로 식별되지만, 검색어에 대한 검색에 성공한 것으로 식별되거나, 상대 발화 음성로부터의 키 워드가 발화 의도인 것으로 식별된 경우, 프로세서는 발화 음성에 대한 인식결과와, 검색어 또는 상 대 발화 음성로부터의 키워드에 각각 대응하는 후보 인식결과의 인식정확도를 조정할 수 있다. 본 문서에 개시된 다양한 실시예들은 전자장치와 같은 기기(Machine)가 읽을 수 있는 저장 매체(Storage Medium)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어로서 구현될 수 있다. 일 예로, 전자장치의 프로세서는 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행 할 수 있다. 이것은 전자장치와 같은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능 을 수행하도록 운영되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(Non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적’은 저장매체가 실재(tangible)하는 장치이고, 신호(예컨대, 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영 구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 예로, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(Computer Program Product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예컨대, CD-ROM)의 형태로 배포되거나, 또는 어플리케이션 스 토어(예컨대, 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예컨대, 스마트폰들) 간에 직접, 온라인으 로 배포(예컨대, 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일 부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 이상, 바람직한 실시예를 통하여 본 발명에 관하여 상세히 설명하였으나, 본 발명은 이에 한정되는 것은 아니며 특허청구범위 내에서 다양하게 실시될 수 있다."}
{"patent_id": "10-2019-0110441", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 전자장치를 도시한다. 도 2는 도 1의 전자장치에 관한 구성의 일 예를 도시한다. 도 3은 도 1의 전자장치에 대한 제어방법의 일 예를 도시한다. 도 4는 도 3의 동작 S33과 관련하여, 인식결과를 획득하는 일 예를 도시한다. 도 5는 도 3의 동작 S33과 관련하여, 발화 음성에 대한 인식 성공 여부에 따라 인식정확도를 조정하는 전자장치 에 대한 제어방법의 일 예를 도시한다. 도 6은 도 5의 동작 S55와 관련하여, 발화 의도와 발화 음성이 상이하더라도, 인식정확도를 조정함으로써, 발화 의도에 부합하는 인식결과를 획득하는 일 예를 도시한다. 도 7은 도 5의 동작 S55와 관련하여, 검색어가 입력되는 경우 인식정확도를 조정하는 일 예를 도시한다. 도 8은 도 5의 동작 S55와 관련하여, 발화자의 대화가 수신되는 경우, 인식정확도를 조정하는 일 예를 도시한다."}
