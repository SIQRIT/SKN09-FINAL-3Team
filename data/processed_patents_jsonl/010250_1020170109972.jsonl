{"patent_id": "10-2017-0109972", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0023749", "출원번호": "10-2017-0109972", "발명의 명칭": "사용자 감성 인식 장치 및 방법", "출원인": "(주)휴머노이드시스템", "발명자": "서재용"}}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자의 얼굴 표정을 기반으로 분석한 사용자의 감정 상태 정보를 적응형 뉴로 퍼지 추론부(300)의 입력에 대한 소속함수로 제공하는 퍼지 논리 분류부(100);사용자의 음성 및 영상을 미리 설정된 감정 상태 프로그램으로 분석한 사용자의 감정 상태 정보를 적응형 뉴로퍼지 추론부(300)의 입력에 대한 소속함수로 제공하는 감정 상태 분석부(200); 및상기 퍼지 논리 분류부(100)와 감정 상태 분석부(200)에서 제공되는 입력 정보에 대한 출력을 계산하고, 상기계산된 값과 목표 출력의 오차가 감소되도록 매개변수를 조정하여 평균 제곱근 에러(Root Mean Square: RMS) 값이 미리 설정된 기준값 이하가 되도록 학습과정을 수행하며, 상기 학습결과를 이용하여 사용자의 감정 상태를인식하는 적응형 뉴로 퍼지 추론부(300)를 포함하는 사용자 감성 인식 장치."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 사용자 감성 인식 장치는 사용자의 심방 박동수, 사용자의 접촉 및 터치 시간, 사용자의 동작 속도 중 적어도 하나 이상을 검출하여 사용자의 감정 상태에 대한 소속함수로 상기 적응형 뉴로 퍼지 추론부(300)로 출력하는 센서부(400)를 더 포함하는 것을 특징으로 하는 사용자 감성 인식 장치."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 퍼지 논리 분류부(100)의 얼굴 표정은 눈썹의 위치, 입의 모양, 머리의 위치 및 방향, 눈의 위치 및 방향을 포함하는 것을 특징으로 하는 사용자 감성 인식 장치."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 퍼지 논리 분류부(100)는 얼굴 표정을 미리 설정된 입력과 출력의 룰 베이스에 따라 퍼지화(Fuzzification)하여 감정 상태를 추출하는 것을 특징으로 하는 사용자 감성 인식 장치."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 퍼지 논리 분류부(100)는 퍼지화를 통해 추론된 감정 상태를 비퍼지화(Defuzzification)하여 일반적인 수치 값으로 출력하는 것을 특징으로 하는 사용자 감성 인식 장치."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 퍼지 논리 분류부(100)는 사용자의 감정 상태를 화남(Ang), 공포(Fer), 슬픔(Sad), 보통(Nor), 부끄러움(Sha), 놀라움(Sup), 기쁨(Joy)으로 구분하는 것을 특징으로 하는 사용자 감성 인식 장치."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 적응형 뉴로 퍼지 추론부(300)는 각 입력 소속함수의 중심과 폭을 조정하여 입력과 출력의 룰 베이스를 재조정하는 학습과정을 수행하는 것을 특징으로 하는 사용자 감성 인식 장치.공개특허 10-2019-0023749-3-청구항 8 제 7 항에 있어서,상기 적응형 뉴로 퍼지 추론부(300)는 학습이 종료되면, 전건부 소속함수의 중심과 폭의 값, 후건부의 가중치값을 저장하고, 재시작 또는 재학습을 수행하는 과정에 초기화 데이터로 사용하는 것을 특징으로 하는 사용자감성 인식 장치."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서,상기 적응형 뉴로 퍼지 추론부(300)는 역전파 학습과정을 수행하는 것을 특징으로 하는 사용자 감성 인식 장치."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "a) 퍼지 논리 분류부(100)와 감정 상태 분석부(200)가 입출력 데이터 쌍을 정의하여 준비하는 단계;b) 적응형 뉴로 퍼지 추론부(300)가 소속함수를 초기화하고, 상기 a) 단계에서 정의한 입출력 데이터를 입력받아 평균 제곱근 오차(RMSE) 값을 검출하는 단계;c) 상기 적응형 뉴로 퍼지 추론부(300)가 역전파 학습 알고리즘을 이용하여 학습을 수행하는 단계;d) 학습이 종료되면, 상기 적응형 뉴로 퍼지 추론부(300)가 전건부 소속함수의 중심 및 폭과 후건부 소속함수의선형 계수값을 조정하고, 상기 평균 제곱근 오차 값이 미리 설정된 기준값 이하인지 여부를 판단하는 단계; 및e) 상기 판단결과, 평균 제곱근 오차 값이 기준값 이하면, 상기 조정된 전건부 소속함수의 중심 및 폭과 후건부소속함수의 선형 계수값을 데이터 베이스(500)에 저장하는 단계를 포함하는 사용자 감성 인식 방법."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 d) 단계의 학습 종료는 발생되는 평균 제곱근 오차 값이 미리 설정된 수렴 조건값 이하면 종료되는 것을특징으로 하는 사용자 감성 인식 방법."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서,상기 e) 단계는 상기 평균 제곱근 오차 값이 기준값 이상이면, 학습률을 조정하여 상기 c) 및 d) 단계를 재수행하는 것을 특징으로 하는 사용자 감성 인식 방법."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,상기 e) 단계에서 저장된 전건부 소속함수의 중심 및 폭과 후건부 소속함수의 선형 계수값은 상기 적응형 뉴로퍼지 추론부(300)가 재시작 또는 재학습을 수행할 경우 소속함수의 초기화 데이터로 사용되는 것을 특징으로 하는 사용자 감성 인식 방법."}
{"patent_id": "10-2017-0109972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10 항에 있어서,상기 e) 단계는 학습이 완료된 다음 감성인식 서비스 과정에서 입력되는 입출력 데이터를 실시간으로 저장되고,상기 저장된 입출력 데이터는 감성인식 서비스의 휴지기에 추가 학습을 수행하는 단계를 더 포함하는 것을 특징으로 하는 사용자 감성 인식 방법."}
{"patent_id": "10-2017-0109972", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사용자의 감정 상태를 판단하기 위한 다양한 입력 정보를 역전파 학습을 통해 적응형 뉴로 퍼지 추론 부의 각 입력 소속함수의 중심 및 폭과 입력 및 출력의 룰 베이스를 조정하여 사용자의 감정 상태를 정확하게 판 단하는 사용자 감성 인식 장치 및 방법을 제공하는 것을 목적으로 한다. 본 발명은 사용자의 얼굴 표정을 기반으 (뒷면에 계속)"}
{"patent_id": "10-2017-0109972", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사용자 감성 인식 장치 및 방법에 관한 발명으로서, 더욱 상세하게는 사용자의 감정 상태를 판단하기 위한 다양한 입력 정보를 역전파 학습을 통해 적응형 뉴로 퍼지 추론부의 각 입력 소속함수의 중심 및 폭과 입 력 및 출력의 룰 베이스를 조정하여 사용자의 감정 상태를 정확하게 판단하는 사용자 감성 인식 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2017-0109972", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어, 삶 속에서 사용자의 편의를 도모하기 위해 사용자가 의도하는 해당 작업을 돕는 로봇 분야에 대한 개발이 활발하게 이루어지고 있다. 특히, 사용자와 로봇 간에 상호작용을 통해 로봇이 지능적으로 판단하고 그 결과에 따른 동작을 수행할 수 있는 지능형 로봇 분야에 관심이 모아지고 있다. 현재 개발되고 있는 지능형 로봇은 단순한 외적 센서 정보를 이용하여 미리 정의된 조건에 따라 해당 감성을 생 성하거나 해당하는 행동을 표현하는 등의 인간과 보다 유사한 감성을 생성 및 표현하는 분야로 개발되고 있다. 또한, 지능형 로봇은 카메라를 통해 촬영한 영상을 통해 인간의 감성 상태를 파악하여 감성 생성에 반영함으로 써, 인간과의 상호 작용이 가능한 형태의 연구가 활발히 이루어지고 있다. 이와 같이, 카메라를 통해 촬영한 영상의 인식 정보를 이용하여 인간의 감성을 파악하거나, 마이크를 이용한 음 성 인식을 통해 음성의 강도, 템포, 및 억양 등을 파악하여 감성을 파악하는 것은 그 정확도 측면에서 한계가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록특허공보 등록번호 제10-0850352호(발명의 명칭: 상태 정보를 이용하여 감성을 표현 하기 위한 지능형 로봇의 감성 표현 장치 및 방법)"}
{"patent_id": "10-2017-0109972", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이러한 문제점을 해결하기 위하여, 본 발명은 사용자의 감정 상태를 판단하기 위한 다양한 입력 정보를 역전파 학습을 통해 적응형 뉴로 퍼지 추론부의 각 입력 소속함수의 중심 및 폭과 입력 및 출력의 룰 베이스를 조정하 여 사용자의 감정 상태를 정확하게 판단하는 사용자 감성 인식 장치 및 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2017-0109972", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위하여 본 발명은 사용자의 얼굴 표정을 기반으로 분석한 사용자의 감정 상태 정보를 적응형 뉴로 퍼지 추론부의 입력에 대한 소속함수로 제공하는 퍼지 논리 분류부; 사용자의 음성 및 영상을 미리 설정된 감정 상태 프로그램으로 분석한 사용자의 감정 상태 정보를 적응형 뉴로 퍼지 추론부의 입력에 대한 소 속함수로 제공하는 감정 상태 분석부; 및 상기 퍼지 논리 분류부와 감정 상태 분석부에서 제공되는 입력 정보에 대한 출력을 계산하고, 상기 계산된 값과 목표 출력의 오차가 감소되도록 매개변수를 조정하여 평균 제곱근 에 러(Root Mean Square: RMS) 값이 미리 설정된 기준값 이하가 되도록 학습과정을 수행하며, 상기 학습결과를 이 용하여 사용자의 감정 상태를 인식하는 적응형 뉴로 퍼지 추론부를 포함한다. 또한, 본 발명에 따른 상기 사용자 감성 인식 장치는 사용자의 심방 박동수, 사용자의 접촉 및 터치 시간, 사용 자의 동작 속도 중 적어도 하나 이상을 검출하여 사용자의 감정 상태에 대한 소속함수로 상기 적응형 뉴로 퍼지 추론부로 출력하는 센서부를 더 포함하는 것을 특징으로 한다. 또한, 본 발명에 따른 상기 퍼지 논리 분류부의 얼굴 표정은 눈썹의 위치, 입의 모양, 머리의 위치 및 방향, 눈 의 위치 및 방향을 포함하는 것을 특징으로 한다.또한, 본 발명에 따른 상기 퍼지 논리 분류부는 얼굴 표정을 미리 설정된 입력과 출력의 룰 베이스에 따라 퍼지 화(Fuzzification)하여 감정 상태를 추출하는 것을 특징으로 한다. 또한, 본 발명에 따른 상기 퍼지 논리 분류부는 퍼지화를 통해 추론된 감정 상태를 비퍼지화(Defuzzification) 하여 일반적인 수치 값으로 출력하는 것을 특징으로 한다. 또한, 본 발명에 따른 상기 퍼지 논리 분류부는 사용자의 감정 상태를 화남(Ang), 공포(Fer), 슬픔(Sad), 보통 (Nor), 부끄러움(Sha), 놀라움(Sup), 기쁨(Joy)으로 구분하는 것을 특징으로 한다. 또한, 본 발명에 따른 상기 적응형 뉴로 퍼지 추론부는 각 입력 소속함수의 중심과 폭을 조정하여 입력과 출력 의 룰 베이스를 재조정하는 학습과정을 수행하는 것을 특징으로 한다. 또한, 본 발명에 따른 상기 적응형 뉴로 퍼지 추론부는 학습이 종료되면, 전건부 소속함수의 중심과 폭의 값, 후건부의 가중치 값을 저장하고, 재시작 또는 재학습의 수행하는 과정에 초기화 데이터로 사용하는 것을 특징으 로 한다. 또한, 본 발명에 따른 상기 적응형 뉴로 퍼지 추론부는 역전파 학습과정을 수행하는 것을 특징으로 한다. 또한, 본 발명은 a) 퍼지 논리 분류부와 감정 상태 분석부가 입출력 데이터 쌍을 정의하여 준비하는 단계; b) 적응형 뉴로 퍼지 추론부가 소속함수를 초기화하고, 상기 a) 단계에서 정의한 입출력 데이터를 입력받아 평균 제곱근 오차(RMSE) 값을 검출하는 단계; c) 상기 적응형 뉴로 퍼지 추론부가 역전파 학습 알고리즘을 이용하여 학습을 수행하는 단계; d) 학습이 종료되면, 상기 적응형 뉴로 퍼지 추론부가 전건부 소속함수의 중심 및 폭과 후건부 소속함수의 선형 계수값을 조정하고, 상기 평균 제곱근 오차 값이 미리 설정된 기준값 이하인지 여부를 판단하는 단계; 및 e) 상기 판단결과, 평균 제곱근 오차 값이 기준값 이하면, 상기 조정된 전건부 소속함수의 중심 및 폭과 후건부 소속함수의 선형 계수값을 데이터 베이스에 저장하는 단계를 포함한다. 또한, 본 발명에 따른 상기 d) 단계의 학습 종료는 발생되는 평균 제곱근 오차 값이 미리 설정된 수렴 조건값 이하면 종료되는 것을 특징으로 한다. 또한, 본 발명에 따른 상기 e) 단계는 상기 평균 제곱근 오차 값이 기준값 이상이면, 학습률을 조정하여 상기 c) 및 d) 단계를 재수행하는 것을 특징으로 한다. 또한, 본 발명에 따른 상기 e) 단계에서 저장된 전건부 소속함수의 중심 및 폭과 후건부 소속함수의 선형 계수 값은 상기 적응형 뉴로 퍼지 추론부가 재시작 또는 재학습을 수행할 경우 소속함수의 초기화 데이터로 사용되는 것을 특징으로 한다. 또한, 본 발명에 따른 상기 e) 단계는 학습이 완료된 다음 감성인식 서비스 과정에서 입력되는 입출력 데이터를 실시간으로 저장되고, 상기 저장된 입출력 데이터는 감성인식 서비스의 휴지기에 추가 학습을 수행하는 단계를 더 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2017-0109972", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 사용자의 감정 상태를 판단하기 위한 다양한 입력 정보를 역전파 학습을 통해 적응형 뉴로 퍼지 추론 부의 각 입력 소속함수의 중심 및 폭과 입력 및 출력의 룰 베이스를 조정하여 사용자의 감정 상태를 정확하게 판단할 수 있는 장점이 있다."}
{"patent_id": "10-2017-0109972", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명에 따른 사용자 감성 인식 장치 및 방법의 바람직한 실시예를 상세하게 설명한다. 도 1은 본 발명에 따른 사용자 감성 인식 장치를 나타낸 블록도이고, 도 2는 도 1에 따른 사용자 감성 인식 장 치의 퍼지 논리 분류부를 나타낸 블록도이다. 도 1 및 도 2에 나타낸 바와 같이, 본 발명에 따른 사용자 감성 인식 장치는 퍼지 논리 분류부와, 감정 상 태 분석부와, 적응형 뉴로 퍼지 추론부와, 센서부와, 데이터 베이스와, 재학습부를 포함하여 구성된다. 상기 퍼지 논리 분류부는 사용자의 얼굴 표정을 기반으로 분석한 사용자의 감정 상태 정보를 적응형 뉴로 퍼지 추론부의 입력에 대한 소속함수로 제공하는 구성으로서, 카메라(미도시) 등의 영상 입력 수단, 3차원 이미지 센서 등으로부터 검출한 사용자의 눈썹 위치, 입의 모양 및 위치, 머리의 위치 및 방향, 눈의 위치 및 방향을 포함한 얼굴 표정을 이용하여 사용자의 감정상태를 분석하기 위한 정보로 제공될 수 있도록 한다. 또한, 상기 퍼지 논리 분류부는 얼굴 표정을 미리 설정된 입력과 출력의 룰 베이스에 따라 퍼지화 (Fuzzification)하여 사용자의 감정 상태가 추출될 수 있도록 한다. 또한, 상기 퍼지 논리 분류부는 퍼지화를 통해 추론된 감정 상태를 비퍼지화(Defuzzification)하여 일반적 인 수치 값으로 출력함으로써, 서로 다른 입력 데이터들의 공간을 동일한 공간에서 처리할 수 있도록 한다. 또한, 상기 퍼지 논리 분류부는 눈썹 위치, 입의 모양 및 위치, 머리의 위치 및 방향, 눈의 위치 및 방향 등의 정보를 이용하여 사용자의 감정 상태를 화남(Ang), 공포(Fer), 슬픔(Sad), 보통(Nor), 부끄러움(Sha), 놀 라움(Sup), 기쁨(Joy)으로 구분한다. 상기한 감정 상태는 7가지 이외에 미묘한 감정 상태를 구분할 수 있도록 퍼지 규칙과 소속함수를 추가하여 더욱 구체적인 감정으로 구분할 수도 있다. 상기 퍼지 논리 분류부를 더욱 상세하게 설명하면, 3차원 이미지 센서 등을 이용하여 사용자의 얼굴을 추 출하고, 깊이(Depth) 정보를 이용하여 사용자의 눈썹 상태(Expression Brow), 입 상태(Expression Mouth), 머 리 상태(Expression Head), 눈 상태(Expression Eye)에 해당되는 정보를 정량적으로 획득하고, 상기 획득한 사 용자 얼굴표정에 기반하여 감정의 상태를 결정하고, 그 결과는 다음의 수학식 1과 같은 연산을 수행하여 적응형 뉴로 퍼지 추론부의 입력으로 제공하며, 눈썹 상태 분류부와, 입 상태 분류부와, 머리 상태 분류부와, 눈 상태 분류부를 포함하여 구성된다. 수학식 1"}
{"patent_id": "10-2017-0109972", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, Y는 퍼지 추론 엔진의 출력벡터이고, W는 가중치 벡터이며, B는 눈썹 상태, M은 입 상태, H는 머리 상 태, E는 눈 상태이다. 상기 눈썹 상태 분류부는 얼굴 표정 중에서 눈썹의 상태를 이용하여 감정 상태를 추출할 수 있도록 동작한 다. 도 3은 사용자 감성 인식 장치에 입력되는 눈썹 상태 입력 퍼지 변수의 소속함수를 나타낸 예시도로서, 도 3 (a)는 왼쪽 눈썹이 올라간 상태에 따른 소속함수이고, 도 3(b)는 오른쪽 눈썹이 올라간 상태에 따른 소속함수이 며, 도 3(c)는 왼쪽 눈썹이 내려간 상태에 따른 소속함수이고, 도 3(d)는 오른쪽 눈썹이 내려간 상태에 따른 소 속함수이다. 사용자는 상기 눈썹 상태 분류부를 통해 상기 도 3(a) 내지 도 3(d)의 소속함수를 3가지 종류로 구분하여 정의될 수 있도록 하며, S(Small), M(Medium), L(Large) 표기를 사용하여 정의한다. 사용자 얼굴 표정 정보는 다음의 표 1과 같이 정의한다. 표 1 얼굴부위 변수명 정의 의미 눈썹 상태 (EXP_BROW)BRL(Brow Raiser Left) 왼쪽 눈썹이 올라간 상태 BRR(Brow Raiser Right) 오른쪽 눈썹이 올라간 상태 BLL(Brow Lowerer Left) 왼쪽 눈썹이 내려간 상태 BLR(Brow Lowerer Right) 오른쪽 눈썹이 내려간 상태 입 상태 (EXT_MOUTH)MTS(Mouth Smile) 얼굴의 웃는 정도 MTK(Mouth Kiss) 키스 동작 MTO(Mouth Open) 입을 연 상태 TGO(Tongue Out) 혀를 내민 상태 머리 상태 (EXP_HEAD)HTL(Head Turn Left) 머리가 왼쪽 방향으로 향한 상태 HTR(Head Turn Right) 머리가 오른쪽 방향으로 향한 상태 HUP(Head Up) 머리가 위 방향으로 향한 상태 HDN(Head Down) 머리가 아래 방향으로 향한 상태 HIL(Head tIlt Left) 머리가 왼쪽으로 기운 상태 HIR(Head tIlt Right) 머리가 오른쪽으로 기운 상태 눈 상태 (EXP_EYE)ECL(Eye Close Left) 왼쪽 눈을 감은 상태 ECR(Eye Close Right) 오른쪽 눈을 감을 상태 ETL(Eye Turn Left) 양쪽 눈동자가 왼쪽으로 이동한 상태 ETR(Eye Turn Right) 양쪽 눈동자가 오른쪽으로 이동한 상태 EUP(Eye UP) 양쪽 눈동자가 위로 이동한 상태 EDN(Eye Down) 양쪽 눈동자가 아래로 이동한 상태 도 4는 눈썹 상태 출력의 소속함수를 나타낸 예시도로서, 퍼지화를 통해 추론된 감정 상태를 화남(Ang), 공포 (Fer), 슬픔(Sad), 보통(Nor), 부끄러움(Sha), 놀라움(Sup), 기쁨(Joy)의 7가지로 정의하여, 각각의 감정 상태 가 출력될 수 있도록 한다. 도 5는 사용자 감성 인식 장치의 눈썹 상태에 대한 퍼지 룰 베이스를 정의하는 화면을 나타낸 예시도로서, 룰 베이스 설정 화면에서, 사용자가 눈썹의 상태를 정의하기 위한 입력 조건 정의를 선택하여, 눈썹의 상태에 따른 다수의 조건문을 설정하고, 이러한 입력 조건 정의는 도 6과 같이 눈썹 상태에 대한 퍼 지 룰 베이스에 의해 설정된 조건문을 3차원 공간으로 나타낼 수도 있다.도 7은 슬픈 감정 상태에서 눈썹 상태에 대한 비퍼지화 결과를 나타낸 예시도로서, 퍼지화를 통해 추론된 감정 상태를 각각의 감정 상태에 따라 비퍼지화(Defuzzification)하여 일반적인 수치 값으로 출력될 수 있도록 한다. 도 8은 사용자 감성 인식 장치의 눈썹 상태에 대한 퍼지 룰 베이스를 정의하는 화면을 나타낸 예시도로서, 상기 입 상태 분류부를 통해 눈썹 상태의 설정과 같이, 입 상태에 따른 소속함수를 3가지 종류로 구분하여 정의 될 수 있도록 하며, S(Small), M(Medium), L(Large) 표기를 사용하여 정의하고, 퍼지화를 통해 추론된 감정 상 태를 화남(Ang), 공포(Fer), 슬픔(Sad), 보통(Nor), 부끄러움(Sha), 놀라움(Sup), 기쁨(Joy)의 7가지로 정의하 여, 각각의 감정 상태가 출력 소속함수를 통해 제공될 수 있도록 입력 조건 정의를 통한 조건문을 설정한다. 도 9는 사용자 감성 인식 장치의 머리 상태에 대한 퍼지 룰 베이스를 정의하는 화면을 나타낸 예시도로서, 상기 머리 상태 분류부를 통해 머리 상태에 따른 소속함수를 3가지 종류로 구분하여 정의하며, S(Small), M(Medium), L(Large) 표기를 사용하여 정의하고, 퍼지화를 통해 추론된 감정 상태를 화남(Ang), 공포(Fer), 슬 픔(Sad), 보통(Nor), 부끄러움(Sha), 놀라움(Sup), 기쁨(Joy)의 7가지로 정의하여, 각각의 감정 상태가 출력 소 속함수를 통해 제공될 수 있도록 입력 조건 정의를 통한 조건문을 설정한다. 도 10은 사용자 감성 인식 장치의 눈 상태에 대한 퍼지 룰 베이스를 정의하는 화면을 나타낸 예시도로서, 상기 눈 상태 분류부를 통해 눈 상태에 따른 소속함수를 3가지 종류로 구분하여 정의하며, S(Small), M(Medium), L(Large) 표기를 사용하여 정의하고, 퍼지화를 통해 추론된 감정 상태를 화남(Ang), 공포(Fer), 슬 픔(Sad), 보통(Nor), 부끄러움(Sha), 놀라움(Sup), 기쁨(Joy)의 7가지로 정의하여, 각각의 감정 상태가 출력 소 속함수를 통해 제공될 수 있도록 입력 조건 정의를 통한 조건문을 설정한다. 상기 감정 상태 분석부는 사용자의 음성 및 영상을 미리 설정된 감정 상태 프로그램으로 분석한 사용자의 감정 상태 정보를 적응형 뉴로 퍼지 추론부의 입력에 대한 소속함수로 제공하는 구성으로서, 예를 들면, 사용자의 대화 목소리가 인터페이스 장치(예를 들면, 대화형 로봇)에 설치된 마이크에 인가되면, 디지털 음성 스트리밍 데이터로 가공되어 상기 인터페이스 장치 또는 원격지의 서버(예를 들면, 인공지능 클라이언 서버)에 전달되고, 상기 인터페이스 장치 또는 서버에 설치된 감정 상태 분석 프로그램에서 상기 전달된 음성 정보를 바 탕으로 음성을 이용한 대화자의 감정 상태를 분석한 결과를 수신하여 적응형 뉴로 퍼지 추론부의 소속함수 로 제공되도록 한다. 또한, 상기 감정 상태 분석부는 사용자의 얼굴이 인터페이스 장치에 설치된 카메라에 촬영되면, 상기 사용 자 얼굴을 디지털 영상 스트리밍 데이터로 가공되어 상기 인터페이스 장치 또는 원격지의 서버에 전달되고, 상 기 인터페이스 장치 또는 서버에 설치된 감정 상태 분석 프로그램에서 상기 전달된 영상 정보를 바탕으로 영상 을 이용한 대화자의 감정 상태를 분석한 결과를 수신하여 적응형 뉴로 퍼지 추론부의 소속함수로 제공되도 록 한다. 상기 적응형 뉴로 퍼지 추론부는 상기 퍼지 논리 분류부와 감정 상태 분석부에서 제공되는 도 11 내지 도 13과 같은 입력 소속함수 정보에 대하여 퍼지 규칙(Fuzzy Rule)과, 추론 과정(The process of fuzzy reasoning)을 신경망(Neural network) 구조로 이루어진 추론 모델을 이용하여 출력을 계산하고, 상기 계 산된 값과 목표 출력의 오차가 감소되도록 매개변수를 조정하여 평균 제곱근 에러(Root Mean Square: RMS) 값이 미리 설정된 기준값 이하가 되도록 학습과정을 수행하며, 상기 학습결과를 이용하여 사용자의 감정 상태를 인식 한다. 상기 추론 모델은 전건부(premise part)와, 후건부(consequence part)로 구분되고, 상기 전건부는 입력 변수를 전체 집합 상으로 설정하기 위한 층과, 전건부의 각 입력 변수에 소속함수(membership funcrion)를 할당하여 입 력이 주어졌을 때, 그 소속정도를 출력하며, 상기 후건부는 실제 제어량 발생을 위한 최종 추론값을 계산한다. 또한, 상기 적응형 뉴로 퍼지 추론부는 역전파 학습 프로그램을 통해 학습과정을 수행하는데, 입력 데이터 에 대한 실제 출력을 전방향 단계를 통해 계산하고, 목표 출력과의 오차를 최소화하도록 역방향 단계를 통해 조 정 매개변수, 즉 전건부 소속함수의 위치 및 폭과 후건부 선형식의 계수 등을 조정한다. 즉 상기 적응형 뉴로 퍼지 추론부는 각 입력 소속함수의 중심과 폭을 조정하여 입력과 출력의 룰 베이스를 재조정하는 학습과정을 수행하고, 학습이 종료되면, 전건부 소속함수의 중심과 폭의 값, 후건부의 가중치 값을 저장하고, 재시작 또는 재학습을 수행하는 과정에 초기화 데이터로 사용되도록 한다. 한편, 본 발명에 따른 상기 사용자 감성 인식 장치는 사용자의 심방 박동수, 사용자의 접촉 및 터치 시간, 사용 자의 동작 속도 중 적어도 하나 이상을 검출하여 사용자의 감정 상태에 대한 소속함수로 상기 적응형 뉴로 퍼지 추론부로 출력하는 센서부를 더 포함하여 구성된다. 상기 센서부는 사용자의 심장 박동수, 접촉 여부 등을 감지할 수 있는 센서로서, 사용자의 심장 박동을 측 정할 수 있는 센서가 인터페이스 장치 또는 대화형 로봇에 설치되어 사용자의 심장 박동이 측정되면, 상기 사용 자의 심장 박동수를 측정하여 소속함수로 정의하여 도 14와 같이, 적응형 뉴로 퍼지 추론부의 입력 소속함 수로 제공될 수 있도록 한다. 또한, 상기 센서부는 사용자의 접촉 여부를 감지할 수 있는 센서로서, 사용자의 접촉 여부를 감지할 수 있 는 센서가 인터페이스 장치 또는 대화형 로봇의 예를 들면, 머리, 어깨, 가슴 등에 설치되어 사용자의 접촉 여 부를 감지하면, 터치 여부와 터치 시간을 이용하여 입력 데이터로서, 소속함수를 정의하여 적응형 뉴로 퍼지 추 론부의 입력 소속함수로 제공될 수 있다. 또한, 2개 이상의 센서가 사용될 경우 센서 터치 시간의 평균값을 계산하여 사용할 수 있도록 한다. 상기 데이터 베이스는 사용자의 감성 정보를 저장하는 구성으로서, 학습이 완료된 시스템의 전건부 소속함 수 정보(예를 들면, 소속함수의 중심과 폭의 값)와 후건부 출력 함수의 가중치(계수) 값 등을 저장한다. 상기 재학습부는 관리자에 의해 설정된 학습 조건이나, 미리 설정된 자동 재학습 조건이나, 사용자의 서비 스 불만족도가 증가하여 관리자가 사용을 중지하고 임의로 재학습을 실행하는 경우 적응형 뉴로 퍼지 추론부 로 재학습의 진행을 요청한다. 다음은 본 발명에 따른 사용자 감성 인식장치의 동작과정을 설명한다. 사용자가 퍼지 논리 분류부와 감정 상태 분석부의 입출력 데이터 쌍을 정의하여 준비(S100)하고, 적 응형 뉴로 퍼지 추론부는 소속함수를 초기화(S110)한다. 상기 S110 단계를 수행한 다음, 상기 적응형 뉴로 퍼지 추론부는 상기 S100 단계에서 정의한 입출력 데이 터 쌍을 입력(S120)받아 평균 제곱근 오차(RMSE) 값을 검출(S130)한다. 상기 적응형 뉴로 퍼지 추론부는 상기 S130 단계에서 계산된 값과 목표 출력의 오차가 감소되도록 매개변 수를 조정하여 평균 제곱근 에러(Root Mean Square: RMS) 값이 미리 설정된 기준값 이하가 되도록 역전파 학습 알고리즘을 이용하여 수행(S140)한다. 상기 S140 단계의 역전파 학습 알고리즘에 의한 학습과정을 통해 적응형 뉴로 퍼지 추론부는 전방향 단계 를 통해 입력 데이터에 대한 실제 출력을 계산하고, 목표 출력과의 오차를 최소화하도록 역방향 단계를 통해 전 건부 소속함수의 중심 위치 및 폭을 조정(S150)하고, 후건부 소속함수의 선형 계수값을 조정(S160)하며, 평균 제곱근 오차 값이 미리 설정된 기준값 이하인지 여부를 판단(S170)한다. 상기 S170 단계의 판단결과, 상기 S170 단계의 평균 제곱근 오차 값이 기준값 이하면, 상기 S150 단계 및 S160 단계에서 조정된 전건부 소속함수의 중심 위치와 폭의 값, 후건부의 가중치 값을 저장(S180)하고, 재시작 또는 재학습을 수행하는 과정에 초기화 데이터로 사용(S190)될 수 있도록 하며, 상기 S170 단계의 평균 제곱근 오차 값이 기준값 이상이면, 미리 설정된 학습률을 조정(S200)하여 상기 S130 단계 내지 S160 단계가 재수행되도록 한다. 상기 S180 단계를 수행한 다음, 학습이 완료된 감성인식 장치는 오프라인에 설치된 로봇 등의 감성인식 서비스 시스템에 설치되어 실시간으로 동작하며, 감성인식 서비스 과정에서 발생되는 입출력 데이터는 실시간으로 데이 터 베이스 또는 로컬의 임의의 저장위치에 저장한다. 또한, 상기 저장된 입출력 데이터는 감성인식 서비스의 휴지기에 자동으로 재학습을 수행한다. 상기 재학습 조건은 관리자에 의해 설정 가능하고, 로봇이 자동으로 재학습을 수행하였지만, 사용자의 서비스 불만족도 증가시 관리자가 사용을 중지하고 임의로 재학습을 수행할 수 있다. 따라서 사용자의 감정 상태를 판단하기 위한 다양한 입력 정보를 역전파 학습을 통해 각 입력 소속함수의 중심 및 폭과 입력 및 출력의 룰 베이스를 조정하여 사용자의 감정 상태를 정확하게 판단할 수 있게 된다. 상기와 같이, 본 발명의 바람직한 실시 예를 참조하여 설명하였지만 해당 기술 분야의 숙련된 당업자라면 하기 의 특허청구범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수 정 및 변경시킬 수 있음을 이해할 수 있을 것이다.또한, 본 발명의 실시예를 설명하는 과정에서 도면에 도시된 선들의 두께나 구성요소의 크기 등은 설명의 명료 성과 편의상 과장되게 도시되어 있을 수 있으며, 상술된 용어들은 본 발명에서의 기능을 고려하여 정의된 용어 들로서 이는 사용자, 운용자의 의도 또는 관례에 따라 달라질 수 있으므로, 이러한 용어들에 대한 해석은 본 명 세서 전반에 걸친 내용을 토대로 내려져야 할 것이다."}
{"patent_id": "10-2017-0109972", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 사용자 감성 인식 장치를 나타낸 블록도. 도 2는 도 1에 따른 사용자 감성 인식 장치의 퍼지 논리 분류부를 나타낸 블록도. 도 3은 본 발명에 따른 사용자 감성 인식 장치에 입력되는 눈썹 상태 입력 퍼지 변수의 소속함수를 나타낸 예시 도. 도 4는 본 발명에 따른 사용자 감성 인식 장치의 출력 퍼지 변수의 소속함수를 나타낸 예시도. 도 5는 본 발명에 따른 사용자 감성 인식 장치의 눈썹 상태에 대한 퍼지 룰 베이스를 정의하는 화면을 나타낸 예시도. 도 6은 도 5에 따른 눈썹 상태에 대한 퍼지 룰 베이스의 3차원 공간을 나타낸 예시도.도 7은 도 5에 따른 눈썹 상태에 대한 비퍼지화 결과의 일 예를 나타낸 예시도. 도 8은 본 발명에 따른 사용자 감성 인식 장치의 입 상태에 대한 퍼지 룰 베이스를 정의하는 화면을 나타낸 예 시도. 도 9는 본 발명에 따른 사용자 감성 인식 장치의 머리 상태에 대한 퍼지 룰 베이스를 정의하는 화면을 나타낸 예시도. 도 10은 본 발명에 따른 사용자 감성 인식 장치의 눈 상태에 대한 퍼지 룰 베이스를 정의하는 화면을 나타낸 예 시도. 도 11은 본 발명에 따른 사용자 감성 인식 장치의 적응형 뉴로 퍼지 추론부의 입력으로 사용되는 퍼지 논리 분 류부의 소속함수를 나타낸 예시도. 도 12는 본 발명에 따른 사용자 감성 인식 장치의 적응형 뉴로 퍼지 추론부의 입력으로 사용되는 음성인식 결과 의 소속함수를 나타낸 예시도. 도 13은 본 발명에 따른 사용자 감성 인식 장치의 적응형 뉴로 퍼지 추론부의 입력으로 사용되는 영상인식 결과 의 소속함수를 나타낸 예시도. 도 14는 본 발명에 따른 사용자 감성 인식 장치의 적응형 뉴로 퍼지 추론부의 입력으로 사용되는 심장 박동수의 소속함수를 나타낸 예시도. 도 15는 본 발명에 따른 사용자 감성 인식 장치의 동작과정을 나타낸 흐름도."}
