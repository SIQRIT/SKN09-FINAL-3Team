{"patent_id": "10-2024-0013261", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0051531", "출원번호": "10-2024-0013261", "발명의 명칭": "근접 음성 입력 방법 및 장치", "출원인": "주식회사 브이터치", "발명자": "김석중"}}
{"patent_id": "10-2024-0013261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "버튼 및 마이크를 구비하는 근접 음성 입력 장치에서의 근접 음성 입력 방법으로서,버튼에서 입력되는 버튼 입력에 관한 버튼 입력 신호를 수신하는 단계,마이크에서 입력되는 음성에 관한 음성 신호를 수신하는 단계 및상기 버튼 입력 신호에 기초하여 음성 입력 모드를 결정하는 단계를 포함하는근접 음성 입력 방법."}
{"patent_id": "10-2024-0013261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 음성 입력 모드는(a) 대화 상대 또는 제어 대상 기기의 지정, 대화 언어, 대화 목소리, 대화 말투, 대화 방식, 대화 기록 및 대화 통역 중 적어도 하나의 기능을 실행하기 위한 설정 모드,(b) 입력된 음성을 수정하기 위한 수정 모드,(c) 인공지능과의 대화를 제안하기 위한 제안 모드 및(d) 긴급 데이터 송수신을 위한 긴급 모드중 적어도 하나를 포함하는, 근접 음성 입력 방법."}
{"patent_id": "10-2024-0013261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 버튼 입력은 상기 근접 음성 입력 장치의 버튼을 눌렀다 떼는 클릭 입력 및 버튼을 누르고 유지하는 프레스 입력 중 적어도 하나를 포함하는, 근접 음성 입력 방법."}
{"patent_id": "10-2024-0013261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 버튼 입력 신호는 상기 클릭 입력 및 상기 프레스 입력의 횟수와 조합에 따라 생성되는, 근접 음성 입력방법."}
{"patent_id": "10-2024-0013261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 음성 신호는 상기 버튼 입력과 동시에 또는 상기 버튼 입력 후에 입력되는 음성에 관한 신호인, 근접 음성입력 방법."}
{"patent_id": "10-2024-0013261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 근접 음성 입력 장치의 센서부로부터의 센싱 신호를 수신하는 단계 및상기 센싱 신호에 기초하여 상기 마이크에서 입력되는 음성이 근접 음성인지 여부를 판단하는 단계공개특허 10-2025-0051531-3-를 더 포함하는근접 음성 입력 방법."}
{"patent_id": "10-2024-0013261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 센싱 신호는 상기 근접 음성 입력 장치의 근접 정보 및 이동 정보 중 적어도 하나를 포함하고,상기 근접 음성 여부를 결정하는 단계에서는, 상기 근접 정보 및 상기 이동 정보 중 적어도 하나에 기초하여 상기 마이크에서 입력되는 음성이 근접 음성인지여부를 결정하는, 근접 음성 입력 방법."}
{"patent_id": "10-2024-0013261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "근접 음성 입력 장치로서,버튼 입력을 위한 버튼,음성 입력을 위한 마이크 및상기 버튼으로부터의 버튼 입력 신호와 상기 마이크로부터의 음성 신호를 수신하여 처리하기 위한 프로세서를 포함하고,상기 프로세서는 상기 버튼 입력 신호에 기초하여 음성 입력 모드를 결정하는, 근접 음성 입력 장치."}
{"patent_id": "10-2024-0013261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 버튼 입력 신호는 상기 버튼을 눌렀다 떼는 클릭 입력 및 상기 버튼을 누르고 유지하는 프레스 입력의 횟수와 조합에 따라 생성되는, 근접 음성 입력 장치."}
{"patent_id": "10-2024-0013261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,근접 음성 입력 장치의 근접 여부 및 이동 여부를 감지하는 센서부를 더 포함하고,상기 센서부는 근접 음성 입력 장치의 근접 정보 및 이동 정보 중 적어도 하나를 포함하는 센싱 정보를 생성하며,상기 프로세서는 상기 센싱 정보에 기초하여 상기 마이크에서 입력되는 음성이 근접 음성인지 여부를 판단하는, 근접 음성 입력 장치."}
{"patent_id": "10-2024-0013261", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 근접 음성 입력 방법 및 장치에 관한 것이다. 본 개시의 일 실시예에 따른 근접 음성 입력 방법은 버 튼 및 마이크를 구비하는 근접 음성 입력 장치에서의 근접 음성 입력 방법으로서, 버튼에서 입력되는 버튼 입력 에 관한 버튼 입력 신호를 수신하는 단계, 마이크에서 입력되는 음성에 관한 음성 신호를 수신하는 단계 및 버튼 입력 신호에 기초하여 음성 입력 모드를 결정하는 단계를 포함한다."}
{"patent_id": "10-2024-0013261", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 근접 음성 입력 방법 및 장치에 관한 것으로, 보다 상세하게는 버튼 입력을 통해 음성 입력 모드를 설정할 수 있는 근접 음성 입력 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2024-0013261", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사용자 인터페이스에 대한 관심이 높아지고 음성 처리 기술이 발전함에 따라, 음성 인식 기능이 내장된 IT 기기 가 늘어가고 있다. 또한, 최근에는 대형 언어 모델(Larger Language Model, LLM)의 성장과 함께 다양한 대화형 인공지능 서비스의 이용이 급격하게 증가하고 있다. 스마트폰 등 IT 기기의 그래픽 사용자 인터페이스(Graphic User Interface, GUI)에서 음성 입력 및 대화형 인공 지능 서비스를 이용하는 경우, 일반적으로 애플리케이션 실행 후 페이지 및 입력 필드 선택을 거쳐 음성을 입력 하게 된다. 또한, 검색, 설정 등의 다른 기능 역시 그래픽 사용자 인터페이스를 통해 관련 페이지 및 입력 필드 선택 후 음성 입력을 통해 수행될 수 있다. 한편, 거치형 AI 스피커, 웨어러블 이어셋, 헤드셋 등 다양한 전자기기에서 디스플레이를 구비하지 않는 음성 사용자 인터페이스(Voice User Interface, VUI)의 사용이 늘어나고 있다. 이러한 음성 사용자 인터페이스의 경 우에는 그래픽 사용자 인터페이스와 달리 음성 입력만으로 다양한 기능들을 실행하는 데에 제약이 따를 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제2020-0058612호 (2020.05.28)"}
{"patent_id": "10-2024-0013261", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 종래기술의 문제점을 해결하기 위한 것이다. 본 개시는 그래픽 사용자 인터페이스의 사용 없이도 대화형 인공지능 서비스를 이용하거나 전자기기의 다양한 기능을 수행할 수 있도록 하는 근접 음성 입력 방법 및 장치를 제공하는 것에 목적이 있다. 또한, 본 개시는 음성 사용자 인터페이스에서 간단한 조작으로 다양한 음성 입력 모드를 설정할 수 있는 근접 음성 입력 방법 및 장치를 제공하는 것에 목적이 있다."}
{"patent_id": "10-2024-0013261", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른 근접 음성 입력 방법은 버튼 및 마이크를 구비하는 근접 음성 입력 장치에서의 근 접 음성 입력 방법으로서, 버튼에서 입력되는 버튼 입력에 관한 버튼 입력 신호를 수신하는 단계, 마이크에서 입력되는 음성에 관한 음성 신호를 수신하는 단계 및 버튼 입력 신호에 기초하여 음성 입력 모드를 결정하는 단 계를 포함한다. 본 개시의 일 실시예에 따르면, 음성 입력 모드는 (a) 대화 상대 또는 제어 대상 기기의 지정, 대화 언어, 대화 목소리, 대화 말투, 대화 방식, 대화 기록 및 대화 통역 중 적어도 하나의 기능을 실행하기 위한 설정 모드, (b) 입력된 음성을 수정하기 위한 수정 모드, (c) 인공지능과의 대화를 제안하기 위한 제안 모드 및 (d) 긴급 데이터 송수신을 위한 긴급 모드 중 적어도 하나를 포함할 수 있다. 본 개시의 일 실시예에 따르면, 버튼 입력은 근접 음성 입력 장치의 버튼을 눌렀다 떼는 클릭 입력 및 버튼을 누르고 유지하는 프레스 입력 중 적어도 하나를 포함할 수 있다. 또한, 버튼 입력 신호는 클릭 입력 및 프레스 입력의 횟수와 조합에 따라 생성될 수 있다. 본 개시의 일 실시예에 따르면, 음성 신호는 버튼 입력과 동시에 또는 버튼 입력 후에 입력되는 음성에 관한 신 호일 수 있다. 본 개시의 일 실시예에 따른 근접 음성 입력 방법은 근접 음성 입력 장치의 센서부로부터의 센싱 신호를 수신하 는 단계 및 센싱 신호에 기초하여 상기 마이크에서 입력되는 음성이 근접 음성인지 여부를 판단하는 단계를 더 포함할 수 있다. 본 개시의 일 실시예에 따르면, 센싱 신호는 근접 음성 입력 장치의 근접 정보 및 이동 정보 중 적어도 하나를 포함할 수 있다. 또한, 근접 음성 여부를 결정하는 단계에서는, 근접 정보 및 이동 정보 중 적어도 하나에 기 초하여 마이크에서 입력되는 음성이 근접 음성인지여부를 결정할 수 있다. 본 개시의 일 실시예에 따른 근접 음성 입력 장치는 버튼 입력을 위한 버튼, 음성 입력을 위한 마이크 및 버튼 으로부터의 버튼 입력 신호와 마이크로부터의 음성 신호를 수신하여 처리하기 위한 프로세서를 포함하고, 프로 세서는 버튼 입력 신호에 기초하여 음성 입력 모드를 결정한다. 본 개시의 일 실시예에 따르면, 버튼 입력 신호는 버튼을 눌렀다 떼는 클릭 입력 및 상기 버튼을 누르고 유지하 는 프레스 입력의 횟수와 조합에 따라 생성될 수 있다.본 개시의 일 실시예에 따른 근접 음성 입력 장치는 근접 음성 입력 장치의 근접 여부 및 이동 여부를 감지하는 센서부를 더 포함할 수 있다. 또한, 센서부는 근접 음성 입력 장치의 근접 정보 및 이동 정보 중 적어도 하나 를 포함하는 센싱 정보를 생성할 수 있고, 프로세서는 센싱 정보에 기초하여 마이크에서 입력되는 음성이 근접 음성인지 여부를 판단할 수 있다. 이 외에도, 본 개시를 구현하기 위한 다른 방법 및 다른 장치가 더 제공될 수 있다."}
{"patent_id": "10-2024-0013261", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 버튼과 마이크를 구비하는 근접 음성 입력 장치를 통해 그래픽 사용자 인터페이 스 없이도 인공지능 대화 및 전자기기의 제어가 가능하게 된다. 또한, 본 개시의 일 실시예에 따르면, 근접 음성 입력 장치의 버튼 입력을 통해 음성 입력 모드를 설정할 수 있 어, 음성 사용자 인터페이스에서도 음성 입력 모드 설정 및 변경을 통해 다양한 기능을 수행할 수 있다."}
{"patent_id": "10-2024-0013261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부 도면을 참조하여 본 개시의 실시예에 관하여 상세히 설명한다. 이하에서는, 본 개시의 요지를 불필 요하게 흐릴 우려가 있다고 판단되는 경우, 이미 공지된 기능 및 구성에 관한 구체적인 설명을 생략한다. 또한, 이하에서 설명하는 내용은 어디까지나 본 개시의 일 실시예에 관한 것일 뿐 본 개시가 이로써 제한되는 것은 아님을 알아야 한다. 본 개시에서 사용되는 용어는 단지 특정한 실시예를 설명하기 위해 사용되는 것으로 본 개시를 한정하려는 의도 에서 사용된 것이 아니다. 예를 들면, 단수로 표현된 구성요소는 문맥상 명백하게 단수만을 의미하지 않는다면 복수의 구성요소를 포함하는 개념으로 이해되어야 한다. 본 개시에서 사용되는 \"및/또는\"이라는 용어는, 열거 되는 항목들 중 하나 이상의 항목에 의한 임의의 가능한 모든 조합들을 포괄하는 것으로 이해되어야 한다. 본 개시에서 사용되는 '포함하다', '구비하다' 또는 '가지다' 등의 용어는 본 개시 상에 기재된 특징, 숫자, 단계, 모션, 구성 요소 또는 이들을 조합한 것이 존재함을 지정하려는 것일 뿐이며, 이러한 용어의 사용에 의해 하나 이상의 다른 특징, 숫자, 단계, 모션, 구성 요소 또는 이들을 조합한 것들의 존재 또는 부가 가능성이 배제되는 것은 아니다. 본 개시의 실시예에 있어서 '모듈' 또는 '부'는 적어도 하나의 기능이나 모션을 수행하는 기능적 부분을 의미하 며, 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 '모듈' 또는 '부'는, 특정한 하드웨어로 구현될 필요가 있는 '모듈' 또는 '부'를 제외하고는, 적어도 하나의 소 프트웨어 모듈로 일체화되어 적어도 하나의 프로세서에 의해 구현될 수 있다. 덧붙여, 본 개시에서 사용되는 모든 용어들은, 달리 정의되지 않는 한 기술적 또는 과학적인 용어를 포함하여, 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의된 용어들은, 관련 기술의 문맥상 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 개시에서 명백하게 달리 정의하지 않는 한 과도하게 제한 또는 확장하여 해석되지 않는 것으로 이해되어야 한다. 도 1은 그래픽 사용자 인터페이스에서의 음성 입력 과정을 예시적으로 나타내는 도면으로서, 스마트폰의 그래픽 사용자 인터페이스를 예시적으로 나타낸 것이다. 도 1을 참조하면, 그래픽 사용자 인터페이스(GUI)에서 소정의 기능을 수행하기 위하여는 먼저 해당 애플리케이 션을 실행해야 한다(도 1의 (a) 참조). 예를 들어, 대화형 인공지능 서비스에 관한 애플리케이션을 선택하여 실행시킨다. 애플리케이션이 실행되면, 음성 입력을 위하여 입력 필드를 선택하고 음성 입력 시작 버튼을 입력 한 후 음성을 입력하게 된다(도 1의 (b)) 참조). 음성 입력 시 음성이 입력되는 상황이 표시될 수 있으며, 입 력 완료 버튼을 통해 음성 입력 신호를 제공할 수 있다(도 1의 (c) 참조). 하지만, 위와 달리 음성 사용자 인터페이스(VUI)에서는, 디스플레이 상에서의 애플리케이션의 실행, 입력 필드 의 선택과 같은 과정을 수행할 수 없으며, 이에 따라 실행되는 애플리케이션의 전환이나 각각의 애플리케이션 내의 다양한 기능을 전환하고 수행하는 데에 제약이 따를 수 있다. 본 개시는 음성 사용자 인터페이스에서도 다양한 애플리케이션 또는 기능을 제약 없이 수행하기 위한 것으로서, 이하에서 도면을 참조하여 본 개시에 따른 실시예를 상세히 설명한다. 도 2는 본 개시의 일 실시예에 따른 근접 음성 입력을 위한 전체 시스템 환경을 개략적으로 나타내는 도면이다. 도 2를 참조하면, 근접 음성 입력을 위한 전체 시스템 환경은 근접 음성 입력 장치, 통신망, 사 용자 단말 및 서버를 포함할 수 있다. 본 개시의 일 실시예에 따른 근접 음성 입력 장치는 음성 입력 및 통신 기능을 구비한 전자 장치일 수 있 다. 근접 음성 입력 장치는 사용자가 휴대할 수 있는 휴대용 장치이거나, 사용자가 착용할 수 있는 웨어 러블 장치일 수 있다. 일 실시예에서, 근접 음성 입력 장치는 반지 형태의 스마트 링일 수 있다. 본 개시의 일 실시예에 따르면, 근접 음성 입력 장치는 통신망을 통해 사용자 단말과 통신할 수 있다. 일 실시예에서, 근접 음성 입력 장치는 버튼 프레스, 음성 등의 사용자 입력을 수신할 수 있고, 근 접 음성 입력 장치에서 수신된 사용자 입력에 관한 신호는 통신망을 통해 사용자 단말로 전달될 수 있다. 본 개시의 일 실시예에 따른 통신망은 임의의 유선 또는 무선 통신망, 예컨대 TCP/IP 통신망을 포함할 수 있다. 본 개시의 일 실시예에 따르면, 통신망은 근거리 통신망(Local Area Network, LAN), 도시권 통신망 (Metropolitan Area Network, MAN), 광역 통신망(Wide Area Network, WAN), 인터넷망 등으로 구성될 수 있으나, 본 개시가 이에 제한되는 것은 아니다. 예를 들어, 통신망은 무선 데이터 통신망으로서, 와이파 이(WiFi) 통신, 와이파이 다이렉트(WiFi-Direct) 통신, 롱텀 에볼루션(LTE, LongTerm Evolution) 통신, 5G 통 신, 블루투스 통신(저전력 블루투스(BLE; Bluetooth Low Energy) 통신 포함), 적외선 통신, 초음파 통신 등과 같은 종래의 통신 방법을 적어도 그 일부분에 있어서 구현하는 것일 수 있으며, 다른 예를 들면, 통신망은 광 통신망으로서 라이파이(LiFi, Light Fidelity) 등과 같은 종래의 통신 방법을 적어도 그 일부분에 있어서 구 현하는 것일 수 있다. 본 개시의 일 실시예에 따른 사용자 단말은 통신망을 통해 근접 음성 입력 장치와 통신할 수 있 는 기기이다. 사용자 단말은 메모리 수단을 구비하고, 마이크로 프로세서를 탑재하여 연산 능력을 갖춘 디지털 기기로서, 예를 들어 스마트폰일 수 있다. 본 개시의 사용자 단말은 도시된 바에 한정되는 것은 아니며, 사용자 단말은 스마트 패드, 노트북 컴퓨터, 피디에이(PDA), 데스크탑일 수도 있고, 이 밖에도 본 개시의 목적을 달성할 수 있는 기기라면 본 개시의 사용자 단말로 사용될 수 있다. 본 개시의 일 실시예에 따르면, 사용자 단말은 통신망을 통해 근접 음성 입력 장치로부터 사용 자 입력에 관한 신호를 수신할 수 있고, 사용자 입력에 따른 기능을 수행할 수 있다. 예를 들어, 근접 음성 입 력 장치에서 근접 음성이 감지되면, 해당 음성 신호가 통신망을 통해 사용자 단말에 전달되고, 사용자 단말은 음성 신호로부터 인식된 음성에 따라 응답 신호 또는 제어 신호를 생성할 수 있다. 본 개시의 일 실시예에 따른 서버는 통신망을 통해 사용자 단말과 통신할 수 있는 서버 시스템 이다. 서버는 독립적인 물리적 서버일 수 있으며, 클라우드 서버 등의 가상 서버일 수도 있다. 본 개시의 일 실시예에 따르면, 서버는 인공지능 서버로서, 사용자 단말로부터 음성 신호를 전송받고 이에 대한 음성 인식을 수행한 후 피드백을 생성할 수 있다. 일 실시예에서, 서버는 생성된 피드백을 사 용자 단말에 제공하고, 사용자 단말은 피드백을 참조하여 응답 신호 및/또는 제어 신호를 생성할 수 있다. 본 개시의 일 실시예에 따르면, 사용자 단말은 인식된 음성에 따른 응답 신호를 생성하여 외부 기기 로 전송할 수 있다. 일 실시예에서, 응답 신호가 전송되는 외부 기기는 이어셋, 헤드셋 또는 스피커일 수 있다. 예를 들어, 사용자 단말은 사용자가 착용한 이어셋으로 응답 신호를 전송할 수 있고, 해당 이어셋 을 통해 사용자가 입력한 음성에 대해 응답할 수 있다. 본 개시의 일 실시예에 따르면, 사용자 단말은 인식된 음성에 따른 제어 신호를 생성하여 외부 기기 로 전송할 수 있다. 일 실시예에서, 제어 신호가 전송되는 외부 기기는 스마트 TV, 에어컨, 냉장고 등 가 전제품, 스마트 자동차 등일 수 있다. 예를 들어, 사용자 단말은 음성 신호로부터 파악되는 사용자의 의 도 내지 요청에 따라 제어 신호를 생성하여 스마트 TV로 전송할 수 있고, 제어 신호에 따라 스마트 TV가 제어 (전원 온/오프, 채널 내지 음량 변경 등)될 수 있다. 한편, 응답 신호 및/또는 제어 신호가 전송되는 외부 기기는 위 예시된 바에 한정되지 않으며, 사용자에게 청각적, 시각적 응답을 제공할 수 있는 전자 기기 또는 무선 통신 기능을 갖추고 사용자의 의도에 따라 제어될 수 있는 전자 기기는 모두 포함되는 것으로 이해되어야 한다. 도시된 실시예에서는 근접 음성 입력 장치가 사용자 단말과 통신하고, 사용자 단말이 서버(24 0)와 통신하는 것으로 설명되었으나, 이와 달리 구현될 수도 있다. 예를 들면, 근접 음성 입력 장치가 서 버와 직접 통신할 수 있다. 이 경우, 근접 음성 입력 장치는 통신망을 통해 감지된 음성 신호 를 서버로 전송하고, 서버는 음성 신호로부터 음성을 인식한 후 응답 신호 및/또는 제어 신호를 생성 하여 전송할 수 있다. 다른 예를 들면, 사용자 단말이 온디바이스(On-Device) AI로서 기능하여, 서버 와 통신 없이 직접 음성 신호로부터 음성을 인식하고 응답 신호 및/또는 제어 신호를 생성할 수 있다. 또 다른 예를 들면, 근접 음성 입력 장치가 사용자 단말 또는 서버가 아닌 다른 IoT 기기, 예를 들 어 AI 스피커와 직접 통신할 수 있다. 이밖에, 근접 음성 입력 장치가 음성 인식, 응답 신호 및/또는 제어 신호의 생성 등의 연산을 수행할 수 있도록 구성되어, 해당 연산이 사용자 단말, 서버 등의 외부 기기에서 수행되는 대신에 근접 음성 입 력 장치에서 처리될 수도 있다. 도 3은 본 개시의 일 실시예에 따른 근접 음성 입력 장치를 나타내는 도면이고, 도 4는 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 기능적 구성을 나타내는 도면이다. 우선 도 3을 참조하면, 본 개시의 일 실시예에 따른 근접 음성 입력 장치는 반지 형태의 웨어러블 스마트 링으로서, 버튼과 마이크를 포함한다. 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 버튼은 버튼 입력을 위한 것으로서, 사용자가 누 를 수 있도록 구성되며, 사용자로부터 버튼 입력을 받아 버튼 입력 신호를 생성하는 기능을 수행할 수 있다. 여기에서, 버튼 입력은 사용자가 버튼을 눌렀다 떼는 클릭(click) 입력, 버튼을 누르고 그 상태를 유지하는 프 레스(press) 입력 등으로 구분될 수 있다. 일 실시예에서, 버튼 입력 신호는 클릭 입력과 프레스 입력의 횟수 와 조합에 따라 생성될 수 있다. 예를 들어, 연속적인 클릭 입력의 횟수, 프레스 입력의 횟수, 클릭 입력과 프 레스 입력의 조합 등에 따라 서로 다른 버튼 입력 신호가 생성될 수 있다. 한편, 본 실시예에서는 버튼이 눌리는 구조로 이루어지는 것을 예시하고 있으나, 이와 달리 버튼은 터치 방식으로도 구현될 수 있다. 예를 들어, 버튼은 정전식 터치 버튼 또는 감압식 터치 버튼으로 구현될 수 있다. 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 마이크는 음성 입력을 위한 것으로서, 사용자 음 성을 감지하여 음성 신호를 생성하는 기능을 수행할 수 있다. 도시된 바와 같이, 마이크는 근접 음성 입 력 장치의 일측에 설치되어 외부 음성을 감지하도록 구성될 수 있다. 본 개시의 일 실시예에 따르면, 마이크는 노이즈의 입력을 최소화하기 위하여 소정의 조건이 충족될 때 활 성화될 수 있다. 일 실시예에서, 마이크는 근접 음성 입력 장치가 근접 음성을 입력할 준비가 된 경 우 활성화될 수 있다. 예를 들어, 마이크는 근접 음성 입력 장치가 객체(예컨대, 사용자의 입)에 근 접한 것으로 판단된 경우 활성화될 수 있다. 다른 실시예에서, 마이크는 버튼 입력과 동시에 또는 버튼 입력 이후에 활성화될 수 있다. 예를 들어, 마이크는 버튼 입력을 통해 버튼 입력 신호가 생성되면 사용자 음성을 감지할 수 있도록 활성화될 수 있다. 이어서 도 4를 참조하면, 본 개시의 일 실시예에 따른 근접 음성 입력 장치는 버튼과 마이크 이 외에 센서부, 프로세서 및 통신부를 더 포함할 수 있다. 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 센서부는 근접 음성 입력 장치의 근접 여부 및/또는 이동 여부를 감지하기 위한 것으로서, 근접 정보 및/또는 이동 정보에 관한 센싱 신호를 생성하는 기능 을 수행할 수 있다. 본 개시의 일 실시예에 따르면, 센서부는 근접 센서를 포함할 수 있다. 근접 센서는 근접 음성 입력 장치 와 객체 사이의 거리를 감지할 수 있으며, 센서부는 근접 센서에 감지한 근접 음성 입력 장치의 근접 정보에 따라 센싱 신호를 생성할 수 있다. 근접 센서는 광학(optical) 센서, 광전(photoelectric) 센서, 초음파(ultrasonic) 센서, 유도(inductive) 센서, 정전 용량(capacitive) 센서, 저항막(resistive) 센서, 와전 류(eddy current) 센서, 적외선(infrared) 센서, 마그네틱(magnetic) 센서 중 적어도 하나일 수 있다. 본 개시의 일 실시예에 따르면, 센서부는 IMU 센서를 포함할 수 있다. IMU 센서는 근접 음성 입력 장치 의 이동(예를 들어, 높이 변화)을 감지할 수 있으며, 센서부는 IMU 센서에서 감지한 근접 음성 입력 장치의 이동 정보에 관한 센싱 신호를 생성할 수 있다. 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 프로세서는 버튼에서 입력되는 버튼 입력에 관한 버튼 입력 신호, 마이크에서 입력되는 음성에 관한 음성 신호 및 센서부에서의 센싱 신호 중 적 어도 하나를 수신하고 처리하는 기능을 수행할 수 있다. 일 실시예에서, 버튼에서의 버튼 입력 신호, 마 이크에서의 음성 신호, 센서부에서의 센싱 신호는 프로세서로 전달되어 처리되고, 통신부 를 통해 사용자 단말 또는 서버로 송신될 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 버튼 입력 신호를 참조하여 음성 입력 모드를 결정할 수 있다. 음성 입력 모드는 사용자 단말 또는 서버에서 응답 신호 및/또는 제어 신호를 생성하기 위한 전제가 되는 것으로, 음성 입력 모드에는 일반 모드(normal mode), 설정 모드(setup mode), 수정 모드(correction mode), 제안 모드(suggestion mode), 긴급 모드(emergency mode) 등이 있을 수 있다. 버튼 입력에 따라 음성 입력 모드가 설정되는 다양한 실시 형태에 대하여는 뒤에서 자세히 설명하기로 한다. 일 실시예에서, 프로세서는 버튼 입력 신호를 사용자 단말 또는 서버에 탑재된 생성형 인공지능 (Generative Artificial Intelligence)과 소통하기 위한 프롬프트(prompt)로서 처리할 수 있다. 즉, 생성형 인공지능과의 대화에서 반복적으로 사용하는 프롬프트의 입력을 버튼 입력으로 대체할 수 있다. 예를 들어, 생 성형 인공지능의 발언을 제안하기 위한 \"what's up\"이라는 입력을 버튼 입력으로 대신할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는 센싱 신호에 기초하여 마이크로부터의 음성 신호가 근접 음성인지 여부를 판단할 수 있다. 구체적으로, 프로세서는 근접 음성 입력 장치의 근접 정보 및 이 동 정보 중 적어도 하나에 기초하여 마이크에서 입력되는 음성이 근접 음성인지 여부를 판단할 수 있다. 여기에서, 근접 음성은 사용자가 의도적으로 근접 음성 입력 장치에 입력한 음성을 의미하는 것으로, 마이 크를 통해 입력되는 음성에서 근접 음성이 아닌 것으로 판단된 음성은 노이즈로 분류될 수 있다. 일 실시예에서, 프로세서는 근접 센서를 통해 획득되는 근접 정보에 기초하여 근접 음성 입력 장치와 객체(예를 들어, 사용자의 입 또는 입술) 사이의 거리 변화를 산출할 수 있고, 산출된 거리 변화를 참조하여 근 접 음성 여부를 판단할 수 있다. 예를 들어, 프로세서는 근접 음성 입력 장치가 객체와 점진적으로 가까워져 사전 설정된 거리 이내에 근접한 시점 이후에 입력되는 음성을 근접 음성으로 판단할 수 있다. 다른 예를 들면, 프로세서는 근접 음성 입력 장치가 사용자의 입 또는 입술과 사전 설정된 거리 이내에 근 접한 상태에서 거리가 일정하게 유지된 시간이 사전 설정된 시간에 도달하는 시점 이후에 입력되는 음성을 근접 음성으로 판단할 수 있다. 일 실시예에서, 프로세서는 근접 센서를 통해 획득되는 근접 정보에 기초하여 근접 음성 입력 장치와 객체(예를 들어, 사용자의 입 또는 입술) 사이의 거리 변화를 산출할 수 있고, IMU 센서를 통해 획득되는 이동 정보에 기초하여 근접 음성 입력 장치의 이동 방향을 산출할 수 있으며, 산출된 거리 변화와 이동 방향을 참조하여 근접 음성 여부를 판단할 수 있다. 예를 들어, 프로세서는 근접 음성 입력 장치가 상방향 으로 이동하면서 객체와 사전 설정된 거리 이내에 근접한 시점 이후에 입력되는 음성을 근접 음성으로 판단할 수 있다. 다른 예를 들면, 프로세서는 근접 음성 입력 장치가 상방향으로 이동한 후 감속하여 정지하면서 객체와 사전 설정된 거리 이내에 위치한 시점 이후에 입력되는 음성을 근접 음성으로 판단할 수 있다. 위와 같이, 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 프로세서는 버튼 입력 신호에 기초하 여 음성 입력 모드를 결정할 수 있고, 센싱 신호에 기초하여 입력되는 음성이 근접 음성인지 여부를 결정할 수 있다. 한편, 본 실시예에서는 프로세서가 근접 음성 입력 장치 내에 구비되는 것으로 예시되었으나, 프로세 서의 기능 중 적어도 일부 또는 전부는 외부 전자기기, 예를 들어 사용자 단말 또는 서버에서 수행될 수 있는 것으로 이해되어야 한다. 반대로, 사용자 단말 또는 서버의 기능 중 적어도 일부 또 는 전부가 프로세서에서 수행될 수도 있는 것으로 이해되어야 한다. 예를 들어, 프로세서는 음성 인 식, 음성 입력 모드에 따른 응답 신호 및/또는 제어 신호의 생성 및 처리 등의 기능 중 적어도 일부 또는 전부 를 수행할 수 있도록 구성될 수 있다. 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 통신부는 근접 음성 입력 장치가 외부 통신 망과 통신할 수 있도록 기능할 수 있다. 예를 들어, 통신부는 버튼 입력 신호 또는 버튼 입력 신호에 의해 결정된 음성 입력 모드에 관한 신호와 음성 신호를 사용자 단말 또는 서버로 전송하는 기능을 수행할 수 있다. 본 개시의 일 실시예에 따른 근접 음성 입력 장치는 저장부(미도시)를 더 포함할 수 있다. 본 개시의 일 실시예에 따르면, 저장부는 근접 음성 입력 장치의 기기 정보, 사용자 정보 등을 저장할 수 있고, 이밖에 근접 음성 입력 장치로 입력되는 음성 등을 저장할 수도 있다. 도 5는 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 착용 형태를 예시적으로 나타내는 도면이다. 도시 된 바와 같이, 본 개시의 일 실시예에 따른 근접 음성 입력 장치는 반지 형태로 이루어져 사용자의 손가락 에 착용될 수 있다. 도시된 실시예에서는 근접 음성 입력 장치가 사용자의 검지 손가락에 착용되는 것을 예시 하고 있으나, 근접 음성 입력 장치는 사용자의 편의를 위해 다른 손가락에 착용될 수 있으며, 손가락에 착용되 지 않은 상태로 사용되는 것도 가능할 것이다. 도 6은 본 개시의 일 실시예에 따른 근접 음성 입력 장치에서 버튼을 입력하는 과정을 예시적으로 나타내는 도 면이다. 도 6을 참조하면, 사용자는 근접 음성 입력 장치를 손가락에 착용한 상태에서 버튼을 입력할 수 있다. 도시된 바와 같이, 근접 음성 입력 장치가 검지 손가락에 착용될 수 있고, 이때 근접 음성 입력 장치의 버튼이 엄지 손 가락을 향하도록 착용되는 것이 바람직하다. 이에 따라, 근접 음성 입력 장치를 착용한 상태에서 엄지 손가락 을 통해 버튼 입력을 수행하여 사용자 편의성을 향상시킬 수 있다. 근접 음성 입력 장치를 검지 손가락이 아닌 다른 손가락에 착용하는 경우에도 엄지 손가락을 이용하여 버튼 입력을 쉽게 수행할 수 있으며, 손가락에 착용 하지 않은 상태에서 버튼을 클릭 또는 프레스하여 버튼 입력을 수행하는 것도 가능하다. 도 7은 본 개시의 일 실시예에 따른 근접 음성 입력 장치를 통해 음성을 입력하는 모습을 예시적으로 나타내는 도면이다. 근접 음성 입력 장치의 음성 입력은 버튼 입력 없이, 버튼 입력과 동시에, 또는 버튼 입력 후에 이루어질 수 있다. 본 실시예에서의 음성 입력은 도시된 바와 같이 근접 음성 입력 장치를 입에 가까이 가져간 상태에서 이루어질 수 있다. 이처럼 근접 음성 입력 장치를 입에 가까이 가져간 상태에서 음성을 입력하는 경우 입력되 는 음성은 근접 음성으로 판단되고, 따라서 사용자의 의도에 따라 음성 신호가 정상적으로 처리될 수 있다. 상술한 바와 같이, 본 개시의 일 실시예에서는 근접 음성 입력 장치의 버튼 입력에 의한 신호에 따라 음성 입력 모드가 결정된다. 버튼 입력은 버튼을 눌렀다 떼는 클릭 입력 버튼을 누르고 유지하는 프레스 입력으로 구분될 수 있으며, 클릭 입력 횟수, 클릭 입력의 횟수, 프레스 입력의 횟수, 클릭 입력과 프레스 입력의 조합 등에 따 라 버튼 입력이 구분되어 버튼 입력 신호가 달리 생성되어 음성 입력 모드가 결정될 수 있다. 예를 들어, 버튼 입력이 이루어지는 동작으로는 버튼 1회 클릭, 2회 또는 그 이상의 클릭, 프레스, 클릭 후 프레스 등이 있을 수 있으며, 이러한 버튼 입력에 따라 서로 다른 음성 입력 모드가 결정될 수 있다. 도 8 내지 도 12는 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 음성입력 모드를 예시적으로 나타내는 도면으로서, 이하에서는 도면을 참조하여 버튼 입력에 따라 음성 입력 모드가 결정되는 다양한 모습을 설명한다. 본 개시의 일 실시예에 따르면, 사용자가 근접 음성 입력 장치의 버튼을 1회 클릭하는 경우 이에 대응하는 버튼 입력 신호가 생성되고, 이에 의해 음성 입력 모드는 설정 모드(setup mode)로 결정될 수 있다. 설정 모드에서 는 대화 상대나 제어 대상 기기를 탐색하고 선택할 수 있다. 예를 들어, 대화 상대는 연락처에 저장된 사람이 나 가상 회의실에 위치하는 사람일 수 있으며, 또는 사용자의 위치에 기반하여 마주하고 있거나 주변에 있는 사 람을 대화 상대로 할 수도 있다. 제어 대상 기기는 TV, 스피커 등 무선 통신이 가능한 IoT 기기일 수 있다. 도 8은 설정 모드에서 가상 회의실에서의 대화 상대를 탐색하고 선택하는 모습을 나타내는 것으로, 가상회의실 에 Josh와 Peter가 위치하고 있는 상황을 도시한다. 사용자는 설정 모드에서 사용자 단말 또는 서버 에 탑재된 인공지능(예컨대, 생성형 인공지능)과 대화할 수 있다. 예를 들어, 사용자가 설정 모드에서 \"Who's in the meeting room?\"이라는 음성을 입력하면, 인공지능은 예컨대 사용자가 착용한 이어셋 또는 헤드셋을 통해 \"There's Josh, and Peter.\"라고 응답하게 되고, 사용자가 \"Connect me to Peter.\"라는 음성을 입력하면, 대화 상대를 Peter로 지정, 연결된다. 일 실시예에서, 사용자는 설정 모드에서 대화 상대의 탐색 없이 대화 상대를 직접 선택할 수도 있다. 예를 들 어, 사용자가 설정 모드에서 \"Connect me to Samantha\", \"Mom\", \"In front of me\", \"Manager of this shop\", \"This shop's official account\" 등과 같이 대화 상대를 직접 선택하면, 인공지능은 대화 상대를 지정하고 \"Yes, connected.\"와 같이 응답할 수 있다. 도 9는 설정 모드에서 사용자가 제어하고자 하는 IoT 기기를 선택하는 모습을 나타낸다. 사용자는 설정 모드에 서 무선 통신을 통해 제어 가능한 기기, 예컨대 TV, 스피커, 창문, 커튼, 에어컨, 벽난로 중 하나 이상을 선택할 수 있다. 도 8에서와 유사하게, 사용자는 설정 모드에서 제어 대상 기기를 탐색한 후에 선택할 수 있다. 또는, 사용자가 제어 대상 기기의 명칭, ID, 정보 등을 미리 알고 있는 경우, 제 어 대상 기기의 탐색 없이 직접 선택할 수도 있다. 일 실시예에 의할 때, 설정 모드에서 대화 상대 내지 제어 대상 기기가 선택되면, 일반 모드에서 음성 입력을 통해 대화 상대와 대화를 진행하거나 제어 대상 기기의 동작에 관한 제어 명령을 보낼 수 있다. 대화 상대 또 는 제어 대상 기기는 재차 설정 모드로 진입하여 변경할 수 있으며, 이러한 변경이 없는 경우에는 대화 내지 제 어가 종료되기까지 해당 설정이 유지될 수 있다. 본 개시의 일 실시예에 따르면, 설정 모드에서는 대화 상대 내지 제어 대상 기기의 선택 이외에 대화 언어, 대 화 목소리 또는 말투 등을 설정하거나 변경할 수 있다. 예를 들어, 설정 모드에서 \"Now answer in Spanish.\"라 는 음성을 입력하면 인공지능의 대화 언어가 스페인어로 변경되고, \"Soft and husky female voice.\"라는 음성을 입력하면 인공지능의 대화 목소리가 부드럽고 허스키한 여자 목소리로 변경된다. 다른 예를 들어, 설정 모드에 서 \"Formal conversation.\"이라는 음성을 입력하면 말투가 포멀하게 변경되며, \"Talk to me like an old friend\"라는 음성을 입력하면 오랜 친구처럼 친근한 캐릭터의 말투로 변경된다. 이 밖에도, 설정 모드에서는 인공지능과의 대화에 있어서 대화 방식을 포함한 다양한 설정이 가능하다. 예를 들어, \"short answer.\"라는 음성을 입력하면 인공지능의 답변의 길이가 예컨대 25% 정도 짧아질 수 있고, \"keep this conversation off the record.\"라는 음성 입력이 있으면 대화 내용을 기록하지 않게 된다. 본 개시의 일 실시예에 따르면, 설정 모드에서는 대화 상대와의 대화를 번역하여 제공하는 통역에 관한 설정도 가능하다. 도 10은 설정 모드에서 통역이 이루어지는 모습을 나타낸 것으로, 설정 모드에서 통역할 언어를 선택하고 대화 상대를 선택하여 대화를 진행하면, 도시된 바와 같이 사용자의 음성은 설정한 언어로 통역되어 대화 상대에게 출력될 수 있다. 반대로, 대화 상대의 음성 역시 사용자가 사용하는 언어로 통역되어 출력될 수 있다. 예를 들어, 버튼을 1회 클릭한 설정 모드에서 \"Translate to French.\"라는 음성 입력을 통해 통역할 언어를 선 택한 후 다시 설정 모드로 진입(즉, 버튼을 1회 클릭)하여 \"Connect me to Marie.\"와 같이 대화 상대를 선택할 수 있다. 이후, 일반 모드에서 \"It's been a long time, like over two years?\"라는 음성을 입력하면, 해당 음성은 사용자 단말 또는 서버에 탑재된 인공지능 모델을 통해 \"Cela fait longtemps, plus de deux ans?\"와 같이 프랑스어로 번역된 후 대화 상대(Marie)가 착용한 이어셋으로 출력된다. 여기에서, 입력된 음성의 번역은 입력 음성의 텍스트 변환(speech to text, STT), 변환 텍스트의 번역 언어(프랑스어)로의 번역, 번역 텍스트의 음성 변환(text to speech, TTS)을 거쳐 이루어질 수 있다. 위와 같이 설정 모드에서 통역 언어가 설정된 경우에는 대화 상대가 입력한 음성 역시 통역되어 사용자에게 출 력될 수 있다. 예를 들어, 대화 상대(Marie)가 \"Je suis ravie de vous voir. Retrouvons-nous aprs letravail et prenons un repas ensemble.\"라는 음성을 입력하면, 해당 음성은 사용자 단말 또는 서버에 탑재된 인공지능 모델을 통해 \"I'm so glad to see you. Let's meet up after work and have a meal together.\"와 같 이 사용자가 입력하는 언어인 영어로 번역된 후 사용자의 이어셋으로 출력된다. 여기에서, 대화 상대가 입력된 음성의 번역 역시 위와 동일한 과정을 거쳐 이루어질 수 있다. 한편, 설정 모드에서의 통역은 서로 상대방의 목소리로 이루어질 수 있다(즉, 상대방의 목소리로 번역된 언어의 음성이 출력됨). 또한, 본 개시에 따른 근접 음성 입력 장치를 구비하지 않은 대화 상대가 공지의 음성 입력 장치(예를 들어, 스마트폰, 마이크를 구비한 이어셋 등)를 통해 음성을 입력하면 설정된 언어로 통역이 이루어 질 수 있다. 본 개시의 일 실시예에 따르면, 사용자가 근접 음성 입력 장치의 버튼을 2회 클릭하는 경우 이에 대응하는 버튼 입력 신호가 생성되고, 이에 의해 음성 입력 모드는 수정 모드(correction mode)로 결정될 수 있다. 수정 모드 는 사용자가 입력한 음성에서 오입력 또는 오인식된 단어 또는 문구가 있는 경우 이를 수정할 수 있는 모드이다. 일 실시예에서, 사용자는 음성 입력 후 바로 수정 모드로 진입하여 오입력 또는 오인식된 단어 또는 문구를 수 정할 수 있다. 예를 들어, 사용자가 \"How much is this short?\"와 같이 \"shirt\"를 \"short\"로 오입력한 경우, 근접 음성 입력 장치의 버튼을 2회 클릭하여 수정 모드로 진입한 후 수정 단어(즉, 본래 의도한 단어)인 \"shirt\"를 입력할 수 있으며, 이에 따라 입력된 음성에서 수정 단어와 유사한 단어인 \"short\"가 수정 단어인 \"shirt\"로 수정되어 \"How much is this shirt?\"와 같이 입력 음성을 바로잡게 된다. 다른 실시예에서, 사용자는 음성을 입력한 후 수정 모드에서 입력된 음성에서 오입력 또는 오인식된 단어 또는 문구를 탐색한 후 수정할 수 있다. 예를 들어, 사용자가 \"Do you have any mail for me?\"와 같이 \"meal\"을 \"mail\"로 오입력한 경우, 근접 음성 입력 장치의 버튼을 2회 클릭하여 수정 모드로 진입하면 입력된 음성 중 오 인식될 가능성이 높은 단어를 탐색하고 오인식 가능성이 높은 단어 \"mail\"을 확인할 수 있다. 이때, 오인식 가 능성이 높은 단어의 확인은 사용자의 이어셋 등을 통해 출력된 음성, 사용자 단말을 통해 출력된 텍스트 등으로 확인할 수 있다. 이후, 수정할 단어(즉, 본래 의도한 단어)인 \"meal\"을 재입력하면, 오인식 가능성이 높은 단 어 \"mail\"이 재입력 단어인 \"meal\"로 수정되어, \"Do you have any meal for me?\"와 같이 입력 음성을 바로잡게 된다. 또 다른 실시예에서, 사용자는 음성을 입력한 후 수정 모드에서 입력된 음성을 확인하고 오입력 또는 오인식된 단어 또는 문구를 수회 탐색한 후 수정할 수 있다. 예를 들어, 사용자가 \"I want to travel to Paris next some.\"과 같이 \"summer\"를 \"some\"으로 오입력한 경우, 근접 음성 입력 장치의 버튼을 2회 클릭하여 수정 모드로 진입하면 입력된 음성 중 오인식될 가능성이 높은 단어를 탐색하고 오인식 가능성이 높은 단어로 \"travel\"을 확 인할 수 있다. 하지만, \"travel\"은 원래 입력한 단어에 해당하기에, 다른 단어를 탐색하기 위하여 재차 수정 모드로 진입(즉, 버튼 2회 클릭)하면 오인식 가능성이 높은 다른 단어 \"some\"을 탐색하여 확인할 수 있다. 마 찬가지로, 오인식 가능성이 높은 단어의 확인은 사용자의 이어셋 등을 통해 출력된 음성, 사용자 단말을 통해 출력된 텍스트 등으로 확인할 수 있다. 이후, 수정할 단어(즉, 본래 의도한 단어)인 \"summer\"를 재입력하면, 오인식 가능성이 높은 것으로 탐색된 단어 \"some\"이 재입력 단어인 \"summer\"로 수정되어, \"I want to travel to Paris next summer.\"와 같이 입력 음성을 바로잡게 된다. 입력된 음성에서 오입력 또는 오인식된 일부 단어 또는 문구를 탐색, 수정하는 수정 모드와 달리, 입력된 음성 을 모두 취소하고 재입력하는 방식으로 수정하는 수정 모드도 가능하다. 수정 방식에 따른 수정 모드를 구분하 기 위하여 전자의 수정 모드를 제1 수정 모드로, 후자의 수정 모드를 제2 수정 모드라 칭한다. 본 개시의 일 실시예에 따르면, 사용자가 근접 음성 입력 장치의 버튼을 1회 클릭한 후 프레스(즉, 버튼을 누르 고 유지)하는 경우 이에 대응하는 버튼 입력 신호가 생성되고, 이에 의해 음성 입력 모드는 제2 수정 모드로 결 정될 수 있다. 제2 수정 모드는 사용자가 입력한 음성에서 오입력 또는 오인식된 단어 또는 문구가 있는 경우 입력된 음성을 취소하고 이를 재입력할 수 있는 수정 모드이다. 일 실시예에서, 사용자는 음성 입력 후 바로 제2 수정 모드로 진입하여 음성을 재입력할 수 있다. 예를 들어, 사용자가 \"I need some bred and mother for breakfast.\"와 같이 복수의 단어(bred, mother)를 오입력한 경우, 근접 음성 입력 장치의 버튼을 1회 클릭한 후 프레스하여 제2 수정 모드로 진입한 후 \"I need some bread and butter for breakfast.\"와 같이 음성을 재입력하여 오입력 또는 오인식된 단어를 바로잡을 수 있다. 한편, 제1 수정 모드와 제2 수정 모드를 명확히 구분하기 위하여, 제2 수정 모드에서의 음성 입력은 버튼의 1회 클릭 후프레스한 상태에서 이루어질 수 있다. 본 개시의 일 실시예에 따르면, 사용자가 근접 음성 입력 장치의 버튼을 3회 클릭하는 경우 이에 대응하는 버튼 입력 신호가 생성되고, 이에 의해 음성 입력 모드는 제안 모드(suggestion mode)로 결정될 수 있다. 제안 모드 는 인공지능과 대화를 시작하기 위해 인공지능의 발언을 제안하는 모드이다. 도 11은 제안 모드에서 음성 입력이 이루어지는 모습을 나타내는 도면으로서, 도시된 바와 같이 사용자는 사용 자 단말 또는 서버에 탑재된 인공지능과의 대화를 시작하기 위하여 버튼을 3회 클릭하여 제안 모드로 진입할 수 있다. 이때, 제안 모드를 위한 버튼 입력은 \"What's up\"과 같은 음성 입력과 동일한 입력으로 처리될 수 있다. 제안 모드에 따라 인공지능은 사용자의 스케줄, 위치, 메일 등의 사용자 정보, 현재 시간, 날씨 등의 환경 정보 등을 활용하여 적절한 대화를 시작할 수 있다. 예를 들어, 인공지능은 사용자의 스케줄을 확인하여 \"You know you have an appointment in an hour, right?\"과 같이 응답할 수 있고, 이는 사용자의 이어셋을 통해 출력될 수 있다. 다른 예를 들면, 인공지능은 사용자의 메일함을 확인하여 \"You got an important email from Steve 30 minutes ago, do you want me to summarize it?\"과 같이 응답할 수 있다. 또 다른 예를 들면, 인공지능은 현재 시간을 참조하여 \"It's almost time for dinner, do you want me to look up nearby restaurants?\"과 같 이 응답할 수 있으며, 날씨 정보를 참조하여 \" It's going to be a little chilly in the evening, so you might want to pack a coat to wear in the evening.\"과 같이 응답할 수도 있다. 본 개시의 일 실시예에 따르면, 사용자가 근접 음성 입력 장치의 버튼을 5회 클릭하는 경우 이에 대응하는 버튼 입력 신호가 생성되고, 이에 의해 음성 입력 모드는 긴급 모드(emergency mode)로 결정될 수 있다. 긴급 모드 는 위급한 상황에서 미리 지정한 긴급 연락처 또는 경찰서 등의 유관 기관에 신호를 제공하기 위한 모드이다. 본 실시예에서는 버튼을 5회 클릭하는 경우 긴급 모드로 진입하는 것으로 설명되었으나, 5회를 초과하여 클릭하 는 경우에도 긴급 모드로 진입할 수 있다. 도 12는 긴급 모드에서의 데이터 송수신이 이루어지는 모습을 나타내는 도면으로서, 도시된 바와 같이 사용자는 긴급 모드를 사용하기 위하여 근접 음성 입력 장치의 버튼을 5회 또는 그 이상 클릭할 수 있다. 이처럼, 버튼 입력에 의해 긴급 모드로 진입한 경우, 근접 음성 입력 장치의 마이크에서 입력되는 소리가 사용자 단말에 전송 되면서 저장될 수 있다. 또한, 사용자 단말의 위치 정보(예를 들어, GPS 정보, 기지국 정보 등)가 저장될 수 있고, 동시에 사용자 단말의 카메라가 활성화되어 사진 및 비디오가 저장될 수 있다. 이러한 소리(음성), 위치 및 사진/비디오 데이터, 즉 긴급 데이터는 미리 지정한 긴급 연락처 및 경찰서 등의 유관 기관 중 적어도 하나 에 전달될 수 있다. 도시된 실시예에서는 우측의 긴급 연락처가 우측의 수신자 단말로 표기되었다. 긴급 모드 에서의 소리(음성) 녹음 시간, 위치 정보 획득 주기, 사진 촬영 주기, 비디오 녹화 시간 등은 사전에 정해질 수 있으며, 이처럼 업데이트되는 긴급 데이터는 지속적으로 긴급 연락처 등에 전송될 수 있다. 긴급 연락처 등의 수신자 단말에서는 긴급 데이터를 수신한 후 추가 수신 설정(즉, 추가 수신 요청)하거나 긴급 데이터의 설정을 변경할 수 있다. 또한, 긴급 연락처 등의 수신자 단말에서는 사용자 단말, 사용자의 이어셋, 스피커, 기타 시각적/청각적 표시 장치로 음성, 문자 메시지를 전송할 수 있으며, 이외에 사용자 단말 등의 소 정의 기능을 제어할 수 있다. 한편, 사용자는 긴급 모드 숨김 설정을 할 수 있으며, 이 경우에는 긴급 모드에 진입하더라도 사용자 단말 등에 긴급 모드가 켜져 있음이 시각적/청각적으로 표현되지 않는다. 본 개시의 일 실시예에 따르면, 사용자가 근접 음성 입력 장치의 버튼을 클릭 또는 프레스하지 않은 경우에는 음성 입력 모드는 일반 모드(normal mode)로 설정될 수 있다. 일반 모드에서는, 입력되는 음성이 사용자의 근 접 음성으로 판단되는 경우, 입력 음성으로 대화 상대와 대화가 이루어지거나 제어 대상 기기에 대한 제어 명령 이 내려질 수 있다. 본 개시의 일 실시예에 따르면, 사용자가 근접 음성 입력 장치의 버튼을 클릭 없이 프레스하는 경우에도 음성 입력 모드가 일반 모드로 결정될 수 있다. 일 실시예에서, 설정 모드, 긴급 모드 등 특정 모드가 적용된 상태 에서 버튼을 프레스하는 버튼 입력이 있는 경우, 음성 입력 모드가 일반 모드로 전환될 수 있다. 예를 들어, 설정 모드에서 통역 언어를 설정하여 통역이 이루어지는 중에 프레스 버튼 입력이 있게 되면 통역이 해제되고 일반 모드로 전환될 수 있다. 또 다른 예를 들어, 긴급 모드로 진입하여 긴급 데이터의 송수신이 이루어지는 중에 프레스 버튼 입력이 있게 되면 긴급 모드가 해제되고 일반 모드로 전환될 수 있다. 위와 같이, 본 개시의 일 실시예에 따른 근접 음성 입력 장치는 버튼 입력에 의해 설정 모드(대화 상대 또는 제 어 대상 기기의 지정, 통역 설정 등), 수정 모드(오입력 또는 오인식된 입력 음성의 수정 등), 제안 모드(사용 자 정보 등에 기초한 인공지능과의 대화 제안 등), 긴급 모드(긴급 데이터의 송수신 등), 일반 모드(일반적인대화 또는 제어 명령 입력 등)를 포함한 다양한 음성 입력 모드를 구현할 수 있다. 이에 따라, 스마트폰 등의 그래픽 사용자 인터페이스(GUI)를 사용하지 않더라도, 음성 사용자 인터페이스(VUI)를 통해 근접 음성 입력 장 치의 버튼 입력과 음성 입력만으로 다양한 기능을 수행할 수 있다. 이상에서는 근접 음성 입력 장치가 반지 형태의 스마트 링인 것으로 설명하였으나, 근접 음성 입력 장치는 다른 형태로 구현될 수도 있다. 도 13은 본 개시의 다른 실시예에 따른 근접 음성 입력 장치를 나타내는 도면이다. 도 13을 참조하면, 근접 음 성 입력 장치는 반지 형태 이외에 버튼과 마이크를 구비한 리모컨(1300a), 스타일러스 펜(1300b), 스마트 워치 (1300c) 등의 형태를 가질 수 있다. 도시된 바와 같이, 근접 음성 입력 장치(1300a, 1300b, 1300c)는 버튼 (1301a, 1301b, 1301c) 및 마이크(1303a, 1303b, 1303c)를 구비하여 버튼 입력과 음성 입력(근접 음성 입력)이 가능하도록 구성된다. 이 밖에도, 본 개시에 따른 근접 음성 입력 장치는 버튼 입력과 음성 입력이 가능한 버 튼 및 마이크를 구비하면 예시된 바와 다른 다양한 형태로도 구현될 수 있다. 도 14는 본 개시의 일 실시예에 따른 근접 음성을 입력하는 과정을 보여주는 동작 흐름도이다. 본 실시예에서 의 근접 음성 입력 방법의 각 단계는 반드시 도시된 순서로 수행되어야 하는 것은 아니며, 각 단계가 반드시 필 수적인 것을 의미하는 것은 아니다. 즉, 본 실시예에 따른 근접 음성 입력 방법의 각 단계는 도시된 바와 다른 순서로 수행될 수 있고, 일부 단계가 생략되거나 다른 단계가 추가될 수도 있는 것으로 이해되어야 한다. 단계에서 버튼 입력 신호를 수신할 수 있다. 구체적으로, 근접 음성 입력 장치의 버튼에서 입 력되는 버튼 입력에 관한 버튼 입력 신호를 수신할 수 있다. 일 실시예에서, 버튼 입력은 근접 음성 입력 장치 의 버튼을 눌렀다 떼는 클릭 입력 및 버튼을 누르고 유지하는 프레스 입력 중 적어도 하나를 포 함할 수 있으며, 버튼 입력 신호는 클릭 입력의 횟수 및 프레스 입력의 횟수 및 그 조합에 따라 생성될 수 있다. 단계에서 센싱 신호를 수신할 수 있다. 구체적으로, 근접 음성 입력 장치의 센서부로부터의 센싱 신호를 수신할 수 있으며, 센싱 신호는 근접 음성 입력 장치의 근접 정보 및 이동 정보 중 적어도 하 나를 포함할 수 있다. 일 실시예에서, 근접 음성 입력 장치의 근접 정보는 센서부의 근접 센서로부 터 획득할 수 있고, 근접 음성 입력 장치의 이동 정보는 센서부의 IMU 센서로부터 획득할 수 있다. 단계에서 음성 신호를 수신할 수 있다. 구체적으로, 근접 음성 입력 장치의 마이크에서 입력 되는 음성에 관한 음성 신호를 수신할 수 있다. 단계에서 버튼 입력 신호에 기초하여 음성 입력 모드를 결정할 수 있다. 구체적으로, 음성 입력 모드는 근접 음성 입력 장치의 버튼에 대한 클릭 입력 및 프레스 입력의 횟수와 조합에 따라 생성되는 버튼 입력 신호에 기초하여 결정될 수 있다. 일 실시예에서, 음성 입력 모드는 (a) 대화 상대 또는 제어 대상 기기 의 지정, 대화 언어, 대화 목소리, 대화 말투, 대화 방식, 대화 기록 및 대화 통역 중 적어도 하나의 기능을 실 행하기 위한 설정 모드, (b) 입력된 음성을 수정하기 위한 수정 모드, (c) 인공지능과의 대화를 제안하기 위한 제안 모드 및 (d) 긴급 데이터 송수신을 위한 긴급 모드 중 적어도 하나를 포함할 수 있다. 예를 들어, 설정 모드는 버튼을 1회 클릭하는 버튼 입력에 의해, 수정 모드는 버튼을 2회 클릭하는 버튼 입력 또는 버튼을 1회 클릭하고 프레스하는 버튼 입력에 의해, 제안 모드는 버튼을 3회 클릭하는 버튼 입력에 의해, 긴급 모드는 버튼 을 5회 또는 그 이상 클릭하는 버튼 입력에 의해 결정될 수 있다. 한편, 버튼 입력이 없거나 버튼을 프레스하 는 버튼 입력이 있는 경우에는 음성 입력 모드가 일반 모드로 결정될 수 있다. 단계에서 센싱 신호에 기초하여 입력된 음성이 근접 음성인지 여부를 판단할 수 있다. 구체적으로, 센싱 신호에 포함되는 근접 음성 입력 장치의 근접 정보 및 이동 정보 중 적어도 하나에 기초하여 마이크 에서 입력되는 음성이 근접 음성인지 여부를 판단할 수 있다. 일 실시예에서, 입력 음성이 근접 음성으로 판단 되면 결정된 음성 입력 모드에서 해당 음성을 인식, 처리할 수 있고, 입력 음성이 근접 음성이 아닌 것으로 판 단되면 이는 노이즈로 분류될 수 있다. 이상 본 개시를 구체적인 구성요소 등과 같은 특정 사항들과 한정된 실시예에 의해 설명하였으나, 상기 실시예 는 본 개시의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 개시가 이에 한정되는 것은 아니며, 본 개"}
{"patent_id": "10-2024-0013261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "시가 속하는 기술분야에서 통상적인 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변형을 꾀할 수 있 다. 예를 들어, 근접 음성 입력 장치의 프로세서의 기능의 일부 또는 전부는 사용자 단말 또는 서버에 분배될 수 있다. 또한, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 설명된 구성요소 들이 설명된 방법과 다른 형태로 결합되거나 다른 구성요소 또는 균등물에 의해 대치 또는 치환되더라도 적절한결과가 달성될 수 있다. 따라서, 본 개시의 사상은 앞서 설명된 실시예에 국한되어 정해져서는 아니 되며, 후술하는 청구범위뿐만 아니 라 이 청구범위와 균등하게 또는 등가적으로 변형된 모든 것들은 본 개시의 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2024-0013261", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 그래픽 사용자 인터페이스에서의 음성 입력 과정을 예시적으로 나타내는 도면이다. 도 2는 본 개시의 일 실시예에 따른 근접 음성 입력을 위한 전체 시스템 환경을 개략적으로 나타내는 도면이다. 도 3은 본 개시의 일 실시예에 따른 근접 음성 입력 장치를 나타내는 도면이다. 도 4는 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 기능적 구성을 나타내는 도면이다. 도 5는 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 착용 형태를 나타내는 도면이다. 도 6은 본 개시의 일 실시예에 따른 근접 음성 입력 장치에서 버튼을 입력하는 과정을 나타내는 도면이다. 도 7은 본 개시의 일 실시예에 따른 근접 음성 입력 장치를 통해 음성을 입력하는 모습을 나타내는 도면이다. 도 8 내지 도 12는 본 개시의 일 실시예에 따른 근접 음성 입력 장치의 음성입력 모드를 예시적으로 나타내는 도면이다. 도 13은 본 개시의 다른 실시예에 따른 근접 음성 입력 장치를 나타내는 도면이다. 도 14는 본 개시의 일 실시예에 따른 근접 음성을 입력하는 과정을 보여주는 동작 흐름도이다."}
