{"patent_id": "10-2021-0169438", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0081402", "출원번호": "10-2021-0169438", "발명의 명칭": "서버와 전자 장치 사이의 영상 콘텐트를 스트리밍하는 방법, 영상 콘텐트를 스트리밍하는 서", "출원인": "삼성전자주식회사", "발명자": "그래즈샥 그르지고르즈 파웰"}}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버가 영상 콘텐트를 스트리밍하는 방법에 있어서,전자 장치에서 실행 중인 상기 영상 콘텐트의 N개의 프레임들을 획득하는 단계;상기 N개의 프레임들에 관련하여 사용자에 의해 입력 가능한 복수의 사용자 입력들을 식별하는 단계;상기 복수의 사용자 입력들에 대응되는 K개의 예측 프레임 세트들을 생성하되, 상기 예측 프레임 세트들 각각은상기 N개의 프레임들 이후에 디스플레이될 수 있는 M개의 예측 프레임들을 포함하는 단계;상기 N개의 프레임들 및 상기 K개의 예측 프레임 세트들로부터 메타 데이터를 획득하는 단계;상기 K개의 예측 프레임 세트들 및 상기 메타 데이터 중 적어도 하나에 기초하여, 상기 전자 장치에 제공될 상기 영상 콘텐트의 스트리밍 데이터를 생성하는 단계;상기 생성된 스트리밍 데이터를 상기 전자 장치에 전송하는 단계;를 포함하는, 서버가 영상 콘텐트를 스트리밍하는 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 예측 프레임은, 상기 N개의 프레임에 관련된 사용자 입력에 따라 상기 N개의 프레임 이후에 디스플레이될것으로 예측되는 프레임인 것인, 서버가 영상 콘텐트를 스트리밍하는 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 예측 프레임은, 상기 프레임들 및 사용자 입력의 종류에 따라, 상기 프레임들 이후의 상기 예측 프레임을생성하도록 훈련된 인공지능 모델을 이용하여 생성되는 것인, 서버가 영상 콘텐트를 스트리밍하는 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 N개의 프레임은, 상기 전자 장치의 화면 상에 디스플레이 중인 상기 영상 콘텐트의 현재 영상에 대응되는것인, 서버가 영상 콘텐트를 스트리밍하는 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 예측 프레임 세트 내의 상기 예측 프레임들의 개수 M은 상기 서버 및 상기 전자 장치 간의 현재 네트워크의 지연 시간에 따라 결정되는, 서버가 영상 콘텐트를 스트리밍하는 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 메타데이터는 프레임 내의 오브젝트, 형태, 및 속성 중 적어도 하나에 대한 정보를 포함하는, 서버가 영상콘텐트를 스트리밍하는 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,공개특허 10-2023-0081402-3-상기 스트리밍 데이터를 생성하는 단계는,예측 프레임을 다운스케일링하는 단계;상기 다운스케일된 예측 프레임을 이용해서 상기 스트리밍 데이터를 생성하는, 서버가 영상 콘텐트를 스트리밍하는 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 예측 프레임은 프레임 전체가 다운스케일되거나 프레임 중 일부 영역이 다운스케일되는, 서버가 영상 콘텐트를 스트리밍하는 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 스트리밍 데이터를 생성하는 단계는상기 예측 프레임 내의 객체들에 대응되는 객체 정보를 마킹하는 단계를 포함하는, 서버가 영상 콘텐트를 스트리밍하는 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 스트리밍 데이터를 생성하는 단계는, 예측 프레임들 중 일부를 이용해서 스트리밍 데이터를 생성하는 단계를 포함하는, 서버가 영상 콘텐트를 스트리밍하는 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치에서의 영상 콘텐트의 스트리밍 방법에 있어서,서버로부터 상기 영상 콘텐트의 스트리밍 데이터를 수신하는 단계;상기 수신된 스트리밍 데이터로부터, 상기 전자 장치에서 실행 중인 상기 영상 콘텐트의 N개의 프레임들을 디스플레이하는 단계;상기 서버와 상기 전자 장치 사이의 현재 네트워크의 지연 시간을 식별하는 단계;상기 지연 시간과 현재 사용자 입력에 따라, 상기 수신된 스트리밍 데이터로부터, 가능한 복수의 사용자 입력들에 대응하는 K개의 예측 프레임 세트들 중 상기 현재 사용자 입력에 대응하는 예측 프레임 세트에 포함된 M개의예측 프레임들의 디스플레이 여부를 결정하는 단계;디스플레이하는 것으로 결정되면, 상기 M개의 예측 프레임들을 디스플레이하는 단계; 및디스플레이하지 않는 것으로 결정되면, 상기 현재 사용자 입력에 대한 제2 스트리밍 데이터의 수신을 대기하는단계;를 포함하는, 전자 장치에서의 영상 콘텐트의 스트리밍 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 M개의 예측 프레임들을 디스플레이하는 도중에 상기 제2 스트리밍 데이터가 수신되면,상기 M개의 예측 프레임들의 디스플레이가 중단되고,수신된 제2 스트리밍 데이터의 프레임들이 디스플레이되는, 전자 장치에서의 영상 콘텐트의 스트리밍 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,공개특허 10-2023-0081402-4-상기 수신된 제2 스트리밍 데이터가 저해상도이면, 제2 스트리밍 데이터 및 상기 스트리밍 데이터에 기초하여 상기 영상이 고해상도로 복원되는, 전자 장치에서의영상 콘텐트의 스트리밍 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 지연 시간이 미리정해진 시간 이상이면, 이미 수신된 제2 스트리밍 데이터 및 상기 스트리밍 데이터에 기초하여 예측된 프레임이 디스플레이되는, 전자 장치에서의 영상 콘텐트의 스트리밍 방법."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "전자 장치에 영상 콘텐트의 스트리밍 데이터를 전송하기 위한 통신부;메모리; 및적어도 하나의 프로세서;를 포함하고,상기 적어도 하나의 프로세서는: 상기 전자 장치에서 실행 중인 상기 영상 콘텐트의 N개의 프레임들을 획득하고,상기 N개의 프레임들에 관련하여 사용자에 의해 입력 가능한 복수의 사용자 입력들을 식별하고,상기 복수의 사용자 입력들에 대응되는 K개의 예측 프레임 세트들을 생성하되, 상기 예측 프레임 세트들 각각은상기 N개의 프레임들 이후에 디스플레이될 수 있는 M개의 예측 프레임들을 포함하고,상기 N개의 프레임들 및 상기 K개의 예측 프레임 세트들로부터 메타 데이터를 획득하고,상기 K개의 예측 프레임 세트들 및 상기 메타 데이터 중 적어도 하나에 기초하여, 상기 전자 장치에 제공될 상기 영상 콘텐트의 스트리밍 데이터를 생성하고,상기 생성된 스트리밍 데이터를 상기 전자 장치에 전송하는, 서버."}
{"patent_id": "10-2021-0169438", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "서버로부터 영상 콘텐트의 스트리밍 데이터를 수신하기 위한 통신부;디스플레이부;메모리; 및적어도 하나의 프로세서;를 포함하고,상기 적어도 하나의 프로세서는:서버로부터 상기 영상 콘텐트의 스트리밍 데이터를 수신하고,상기 수신된 스트리밍 데이터로부터, 상기 전자 장치에서 실행 중인 상기 영상 콘텐트의 N개의 프레임들을 복원하여 상기 디스플레이부에 디스플레이하고,상기 서버와 상기 전자 장치 사이의 현재 네트워크의 지연 시간을 식별하고,상기 지연 시간과 현재 사용자 입력에 따라, 상기 수신된 스트리밍 데이터로부터, 가능한 복수의 사용자 입력들에 대응하는 K개의 예측 프레임 세트들 중 상기 현재 사용자 입력에 대응하는 예측 프레임 세트에 포함된 M개의예측 프레임들의 디스플레이 여부를 결정하고,디스플레이하는 것으로 결정되면, 상기 M개의 예측 프레임들을 복원하여 상기 디스플레이부에 디스플레이하고,디스플레이하지 않는 것으로 결정되면, 상기 현재 사용자 입력에 대한 제2 스트리밍 데이터의 수신을 대기하는,전자 장치.공개특허 10-2023-0081402-5-"}
{"patent_id": "10-2021-0169438", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치에서 실행 중인 영상 콘텐트의 N개의 프레임들을 획득 하는 단계; N개의 프레임들에 관련하여 사용자에 의해 입력 가능한 복수의 사용자 입력들을 식별하는 단계; 복수의 사용자 입력들에 대응되는 K개의 예측 프레임 세트들을 생성하되, 상기 예측 프레임 세트들 각각은 상기 N개의 프레임들 이후에 디스플레이될 수 있는 M개의 예측 프레임들을 포함하는 단계; N개의 프레임들 및 K개의 예측 프레임 세트들로부터 메타 데이터를 획득하는 단 계; K개의 예측 프레임 세트들 및 메타 데이터 중 적어도 하나에 기초하여, 전자 장치에 제공될 상기 영상 콘텐 트의 스트리밍 데이터를 생성하는 단계; 생성된 스트리밍 데이터를 전자 장치에 전송하는 단계;를 포함하는, 영 상 콘텐트를 스트리밍하는 방법을 제공한다."}
{"patent_id": "10-2021-0169438", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 서버와 전자 장치 사이의 영상 콘텐트를 스트리밍하는 방법, 영상 콘텐트를 스트리밍하여 스트리밍 데이터를 전송하는 서버, 및 스트리밍 데이터를 수신하는 전자 장치에 관한 것으로, 보다 상세하게는, 영상 콘 텐트의 현재 상태에 기초하여 복수개의 프레임을 획득하고, 복수개의 프레임 및 가능한 복수의 사용자 입력에 기초하여 복수의 예측 프레임을 생성하고, 복수개의 프레임 및 복수의 예측 프레임들로부터 메타 데이터를 획득 하고, 복수의 예측 프레임들 및 메타 데이터 중 적어도 하나에 기초하여 영상 콘텐트의 스트리밍 데이터를 생성 하여 전송하는, 영상 콘텐트를 스트리밍하는 방법, 서버, 및 전자 장치에 관한 것이다."}
{"patent_id": "10-2021-0169438", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "과거에는 클라이언트 측의 렌더링이 있는 게임만 웹을 통해 사용할 수 있었지만, 낮은 네트워크 레이턴시 (latency)와 데이터 센터의 높은 성능으로 온라인 게임 스트리밍과 같은 영상 콘텐트 서비스가 가능해짐에 따라, 현재는 게임 스트리밍 플랫폼(예를 들어, 엔비디아 지포스 나우 (Nvidia GeForce Now), 플레이스테이션 나우 (PlayStation Now), 구글 스타디아 (Google Stadia))에 등록한 사용자는 전문 하드웨어가 요구되는 게임의 매우 역동적인 장면에서 캐릭터를 제어할 수 있다. 즉, 사용자는 게임 스트리밍 서비스에 등록하고, 서비스 제 공자는 기본적으로 비디오 스트림인 게임 스트림을 생성한다. 사용자는 터치스크린 또는 마우스 등으로 입력을 서비스 제공자의 서버에 전송하여 게임을 제어한다. 이러한 게임 스트리밍에는 대역폭을 줄이고 품질을 향상시 키기 위해 이미지 업스케일링 기술과 저해상도(VGA, SVGA)로 설계된 오래된 게임의 해상도와 화질을 향상시키는 기술들이 이용된다. 게임 스트리밍 서비스에서 높은 레이턴시는 게임의 리얼리티를 반영할 수 없기 때문에, 게임 스트리밍 서비스 제공자는 사용자를 만족시키기 위해 레이턴시(대부분의 게임에서 20ms 내지 10ms의 핑(ping)이 적합하다)를 낮 추어야 한다. 또한, 게임을 이용하는 클라이언트와 서버 양측 모두 저해상도 게임에 대한 최소 1 Mbps 내지 4K 의 업로딩 또는 다운로딩의 경우에 대한 30 Mbps의 대역폭에 있어야 하고, 만약 대역폭이 저하되면 게임 스트리 밍 사용자는 간헐적으로 해상도 드랍을 경험한다. 게임 스트리밍 서비스 사용자에 대한 모든 통신은 서비스 제 공자의 데이터 센터(서버)로 직접 연결되어, 데이터 센터는 모든 단일 사용자에게 개별의 비디오 스트림을 다시 생성하여 전송해야 한다. 스트리밍 관련 기술 및 인공지능(artificial intelligence) 관련 기술의 발달과 고해상도/고화질의 영상을 재생, 저장할 수 있는 하드웨어의 개발 및 보급에 따라, 영상 콘텐트의 스트리밍에 있어서, 전자 장치에서 서버 로부터 전송되는 영상 콘텐트를 지연(예를 들어, 렉) 없이 사용자 입력에 대하여 즉각적으로 응답하여 재생할 수 있는 영상 스트리밍 방법, 영상 콘텐트를 스트리밍하는 서버, 및 전자 장치에 대한 필요성이 증대하고 있다."}
{"patent_id": "10-2021-0169438", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 실시예는, 서버와 전자 장치 간의 영상 콘텐트의 스트리밍에서 스트리밍 지연을 방지하기 위해, 서버에서 현재 실행 중인 영상 콘텐트에 대한 가능한 사용자 입력에 대응하는 예측 프레임들을 생성하고, 현재 실행 중인 영상 콘텐트에 대한 프레임들과 예측 프레임들에 기초하여 메타 데이터를 획득하고, 예측 프레임들과 메타 데이터 중 적어도 하나를 기초하여 인공지능 모델을 이용하여 생성된 스트리밍 데이터를 전송하고, 전자 장치에서 인공지능 모델을 이용하여 수신된 스트리밍 데이터를 복원하고, 서버와 전자 장치 사이의 지연 시간과 현재 사용자 입력에 기초하여 복원된 예측 프레임의 디스플레이 여부를 결정하여 예측 프레임을 디스플레이함으 로써, 스트리밍 데이터를 효율적으로 변환하고, 사용자 입력에 대하여 빠르게 반응하여 영상 콘텐트를 디스플레 이하는 것을 기술적 과제로 한다."}
{"patent_id": "10-2021-0169438", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 서버가 영상 콘텐트를 스트리 밍하는 방법에 있어서, 전자 장치에서 실행 중인 상기 영상 콘텐트의 N개의 프레임들을 획득 하는 단계; 상기 N 개의 프레임들에 관련하여 사용자에 의해 입력 가능한 복수의 사용자 입력들을 식별하는 단계; 상기 복수의 사 용자 입력들에 대응되는 K개의 예측 프레임 세트들을 생성하되, 상기 예측 프레임 세트들 각각은 상기 N개의 프레임들 이후에 디스플레이될 수 있는 M개의 예측 프레임들을 포함하는 단계; 상기 N개의 프레임들 및 상기 K개 의 예측 프레임 세트들로부터 메타 데이터를 획득하는 단계; 상기 K개의 예측 프레임 세트들 및 상기 메타 데이 터 중 적어도 하나에 기초하여, 상기 전자 장치에 제공될 상기 영상 콘텐트의 스트리밍 데이터를 생성하는 단계; 상기 생성된 스트리밍 데이터를 상기 전자 장치에 전송하는 단계;를 포함하는, 서버가 영상 콘텐트를 스 트리밍하는 방법을 제공할 수 있다. 또한, 본 개시의 제2 측면은, 전자 장치에서의 영상 콘텐트의 스트리밍 방법에 있어서, 서버로부터 상기 영상 콘텐트의 스트리밍 데이터를 수신하는 단계; 상기 수신된 스트리밍 데이터로부터, 상기 전자 장치에서 실행 중 인 상기 영상 콘텐트의 N개의 프레임들을 디스플레이하는 단계; 상기 서버와 상기 전자 장치 사이의 현재 네트 워크의 지연 시간을 식별하는 단계; 상기 지연 시간과 현재 사용자 입력에 따라, 상기 수신된 스트리밍 데이터 로부터, 가능한 복수의 사용자 입력들에 대응하는 K개의 예측 프레임 세트들 중 상기 현재 사용자 입력에 대응 하는 예측 프레임 세트에 포함된 M개의 예측 프레임들 의 디스플레이 여부를 결정하는 단계; 디스플레이하는 것으로 결정되면, 상기 M개의 예측 프레임들을 디스플레이하는 단계; 및 디스플레이하지 않는 것으로 결정되면, 상기 현재 사용자 입력에 대한 제2 스트리밍 데이터의 수신을 대기하는 단계;를 포함하는, 전자 장치에서의 영 상 콘텐트의 스트리밍 방법을 제공할 수 있다. 또한, 본 개시의 제3 측면은, 전자 장치에 영상 콘텐트의 스트리밍 데이터를 전송하기 위한 통신부; 메모리; 및 적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로세서는: 상기 전자 장치에서 실행 중인 상기 영 상 콘텐트의 N개의 프레임들을 획득하고, 상기 N개의 프레임들에 관련하여 사용자에 의해 입력 가능한 복수의 사용자 입력들을 식별하고, 상기 복수의 사용자 입력들에 대응되는 K개의 예측 프레임 세트들을 생성하되, 상기 예측 프레임 세트들 각각은 상기 N개의 프레임들 이후에 디스플레이될 수 있는 M개의 예측 프레임들을 포함하고, 상기 N개의 프레임들 및 상기 K개의 예측 프레임 세트들로부터 메타 데이터를 획득하고, 상기 K개의 예측 프레임 세트들 및 상기 메타 데이터 중 적어도 하나에 기초하여, 상기 전자 장치에 제공될 상기 영상 콘텐 트의 스트리밍 데이터를 생성하고, 상기 생성된 스트리밍 데이터를 상기 전자 장치에 전송하는, 서버를 제공할 수 있다. 또한, 본 개시의 제4 측면은, 서버로부터 영상 콘텐트의 스트리밍 데이터를 수신하기 위한 통신부; 디스플레이 부; 메모리; 및 적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로세서는: 서버로부터 상기 영상 콘텐트의 스트리밍 데이터를 수신하고, 상기 수신된 스트리밍 데이터로부터, 상기 전자 장치에서 실행 중인 상 기 영상 콘텐트의 N개의 프레임들을 복원하여 상기 디스플레이부에 디스플레이하고, 상기 서버와 상기 전자 장 치 사이의 현재 네트워크의 지연 시간을 식별하고, 상기 지연 시간과 현재 사용자 입력에 따라, 상기 수신된 스 트리밍 데이터로부터, 가능한 복수의 사용자 입력들에 대응하는 K개의 예측 프레임 세트들 중 상기 현재 사용자 입력에 대응하는 예측 프레임 세트에 포함된 M개의 예측 프레임들의 디스플레이 여부를 결정하고, 디스플레이하 는 것으로 결정되면, 상기 M개의 예측 프레임들을 복원하여 상기 디스플레이부에 디스플레이하고, 디스플레이하 지 않는 것으로 결정되면, 상기 현재 사용자 입력에 대한 제2 스트리밍 데이터의 수신을 대기하는, 전자 장치를 제공할 수 있다."}
{"patent_id": "10-2021-0169438", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전자 장치에서 현재 실행 중인 영상 콘텐트의 N개의 프레임, 복수개의 가능한 사용자 입력들에 대응하는 K개의 예측 프레임 세트들, 및 메타 데이터에 기초하여 실시간으로 영상 콘텐트를 디스플레이함으로써, 네트워크의 지 연이 발생하더라도 사용자의 동작(입력)에 즉각적으로 반응하여 영상 콘텐트에 대한 사용자의 경험을 개선하고 영상 콘텐트를 전자 장치에서 스무스하게 디스플레이할 수 있다. 또한, 메타 데이터를 이용함으로써 영상 콘텐 트 스트리밍 서비스의 대역폭 사용량이 크게 절감될 수 있다."}
{"patent_id": "10-2021-0169438", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시는 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고, 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 개시의 실시 형태에 대해 한정 하려는 것이 아니며, 본 개시는 여러 실시예들의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 실시예를 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있 다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제 1, 제 2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에서 '~부(유닛)', '모듈' 등으로 표현되는 구성요소는 2개 이상의 구성요소가 하나의 구성요소 로 합쳐지거나 또는 하나의 구성요소가 보다 세분화된 기능별로 2개 이상으로 분화될 수도 있다. 또한, 이하에 서 설명할 구성요소 각각은 자신이 담당하는 주기능 이외에도 다른 구성요소가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성요소 각각이 담당하는 주기능 중 일부 기능이 다른 구성요소 에 의해 전담되어 수행될 수도 있음은 물론이다. 또한, 본 명세서에서, '영상(image)' 또는 '픽처'는 정지영상, 복수의 연속된 정지영상(또는 프레임)으로 구성 된 동영상, 또는 비디오를 나타낼 수 있다. 본 명세서에서, “영상 콘텐트”는 게임 영상 콘텐트, VR (Virtual Reality) 게임 영상 콘텐트, AR (Augmented Reality) 게임 영상 콘텐트, 영상 콘텐트, VR 영상 콘텐트, AR 영상 콘텐트 등을 의미한다. 본 개시에서, '증강 현실(AR: Augmented Reality)'은 현실 세계의 물리적 환경 공간 내에 가상 이미지를 함께 보여주거나 현실 객체와 가상 이미지를 함께 보여주는 것을 의미한다. 본 개시에서, '가상 현실(VR: Virtual Reality)'은 실제와 유사한 환경을 갖는 컴퓨터 그래픽으로 만들어진 환 경 또는 상황에서, 사람의 감각 기관을 통해 느끼게 하고, 실제로 상호작용하고 있는 것처럼 만들어주는 것을 의미한다. 사용자는 전자 장치의 조작을 통하여 가상 현실과 실시간 상호 작용할 수 있고, 실제와 유사한 감각 적 체험을 할 수 있다. 또한, 본 명세서에서 'DNN(deep neural network)'은 뇌 신경을 모사한 인공신경망 모델의 대표적인 예시로써, 특정 알고리즘을 사용한 인공신경망 모델로 한정되지 않는다. 도 1은 일 실시예에 따른 서버와 전자 장치 사이의 영상 콘텐트를 스트리밍하는 과정을 설명하기 위한 도면이다. 도 1에서 도시된 바와 같이, 본 개시의 일 실시예에 따르면, 서버는 먼저 전자 장치에서 현재 실행 중인 영상 콘텐트의 N개의 프레임들을 획득한다. N개의 프레임은 전자 장치의 화면 상에 디스플레이 중인 영상 콘텐트의 현재 영상에 대응되는 것이다. 그리고, 서버와 전자 장치 사이의 네트워크의 지 연 시간이 길어지는 경우, 즉, 렉(lag)이 발생하는 경우를 대비하여, 서버는 N개의 프레임들과 관련하여 사용자에 의해 입력가능한 복수의 사용자 입력들을 식별하고, 복수의 사용자 입력들에 대응하는 K개의 예 측 프레임 세트들을 생성한다. 예측 프레임 세트들 각각은 N개의 프레임들 이후에 디스플레이될 수 있는 M 개의 예측 프레임들을 포함한다. 서버는 N개의 프레임들에 기초하여 가능한 사용자 입력들 각각에 대응하 는 예측 프레임들을 생성한다. 서버는 N개의 프레임들과 K개의 예측 프레임 세트들로부터 메타 데이터를 추출하고, K개의 예측 프레임 세트들 및 메타 데이터 중 적어도 하나에 기초하여 스트리밍 데이터를 생성 하고, 스트리밍 데이터를 전자 장치에 전송한다. “입력가능한 사용자 입력”은 현재 실행 중인 영상 콘텐트에서 허용되는 사용자 입력을 의미한다. 예를 들어, 영상 콘텐트가 카 레이싱 게임 영상 콘텐트인 경우, 사용자 입력은 상, 하, 좌, 우의 방향에 대한 입력, 속도를 높이는 입력, 속도를 줄이는 입력을 포함할 수 있다. 또한, 아무것도 입력하지 않는 경우도 사용자 입력에 포함 될 수 있다. 또한, 멀티 플레이어 게임의 경우, 입력가능한 사용자 입력은 다른 플레이어에 의해 수행된 동작일 수도 있다. 예측 프레임 세트에 포함되는 예측 프레임은 N개의 프레임에 관련된 사용자 입력에 따라 N개의 프레임 이후에 디스플레이될 것으로 예측되는 프레임이다. 또한, 예측 프레임은 프레임들 및 사용자 입력의 종류에 따라, 프레 임들 이후의 예측 프레임을 생성하도록 훈련된 인공지능 모델, 즉, DNN을 이용하여 생성되는 것일 수 있다. 구 체적으로, 서버는 예측 프레임을 생성하는데 필요한 인공지능 모델의 훈련 데이터를 전자 장치에 제 공할 수 있고, 전자 장치는 이러한 훈련 데이터에 기초하여 서버가 생성한 예측 프레임들을 효과적으 로 복원할 수 있다. 게임에서 가능한 상태들 및 사용자의 동작들을 예측하는데 이용되는 인공지능 모델을 훈련함에 있어서, 가능한 사용자 입력이 무엇인지 명확하게 하는 것이 중요하다. 예를 들어, 사용자 입력은 계속해서 하나의 키를 누르고 있는 것, 계속 누르고 있다가 놓는 것일 수 있다. 또한, 사용자가 2개의 키를 함께 누를 가능성이 없는 경우에, 사용자 입력에 대한 예측은 key_up를 누르는 것에 대한 예측, key_down을 누르는 것에 대한 예측, 및 아무 것도 누르지 않는 것에 대한 예측이 준비될 수 있다. 이와 같이, 가능한 사용자 입력에 대한 정보를 명확히 함으로써, 이러한 정보에 기초하여 훈련되는 인공지능 모 델을 이용하면 더 나은 프레임 예측이 수행되고, 사용자에게 전달되는 데이터의 양이 제한될 수 있다. 예측 프레임 세트 내의 예측 프레임들의 개수(M)는 서버 및 전자 장치 간의 현재 네트워크의 지연 시 간에 따라 결정되는 것일 수 있다. 구체적으로, 지연 시간이 일정 시간 이상이면, 즉, 렉이 심하면(예를 들면, ping이 일정 크기 이상인 경우), 많은 수의 예측 프레임들이 필요하지만, 지연시간이 일정 시간 미만이면, 즉, 렉이 심하지 않으면((예를 들면, ping이 일정 크기 미만인 경우, 현재 입력에 대한 추가적인 스트리밍 데이터를 빨리 수신할 수 있어, 적은 수의 예측 프레임만이 필요하기 때문이다. 또한, 예측 프레임들의 개수(M)는 영상 콘텐트를 제공하는 서비스 제공자에 의해 제한되어 정의될 수도 있다. 이를 통해, 예측 데이터를 준비할 때, 복잡성과 전력 소비가 절감될 수 있다. 이러한 방식은 터치스크린 (예를 들어, 1920*1080)을 통해 사용자 입력이 입력되는 경우에, 예측 가능한 경우의 수가 극단적으로 커질 수 있기 때문에 중요하다. 이러한 경우에는 미리 정의된 영역(예를 들어, 화면 상의 유저 인터페이스 영역) 또는 로우 스케일 그리드 영역(예를 들어, 10*10, 19*10의 그리드 영역)에 대한 사용자 입력을 예측하여 예측의 경우의 수 를 절감시킬 수 있다. 메타 데이터는 프레임 내의 오브젝트, 형태, 및 속성 중 적어도 하나에 대한 정보를 포함할 수 있다. 구체적으 로, 영상 콘텐트 내의 얼굴들, 사람의 신체, 벽들, 나무들, 차들, 하늘, 또 다른 전형적인 형태의 예측하기 쉬 운 오브젝트들과 같은 영역들일 수 있다. 이러한 영역들은 형태들 및 속성들로 묘사된다. 화면 상의 영역, 즉 사람의 머리 형태일 수 있고, 속성은 오브젝트의 스타일, 예를 들어, 그래픽 형식으로 표시되는 숫자 값에 따른 색상 정보, 패턴 정보 등일 수 있다. 또한, 속성은 최초 프레임 1부터 최종 프레임 N+M까지의 형태가 어떻게 변 화하는지를 나타내는 것일 수 있고, 최초 프레임 1부터 최종 프레임 N+M까지의 스타일이 어떻게 변화하는지를 나타내는 것일 수 있고, 가능한 사용자 입력 각각에 따라 영역들이 어떻게 변화하는지를 나타낼 수 있다. 메타 데이터는 각 영역의 예측에 대한 정보와 각각의 예측 시나리오에 따라 영상 콘텐트가 디스플레이되는 방식 에 대한 정보를 포함할 수 있다. 이에 따라, 메타 데이터는 하나 이상의 예측 시나리오에 적용될 수 있다. 예를들어, 위, 아래, 왼쪽, 오른쪽으로의 컨트롤러를 통한 사용자 입력에 따라, 서로 다른 4개의 사용자 동작에 대 한 4개의 프레임 예측이 수행될 수 있다. K개의 예측 프레임 세트들 및 메타 데이터 중 적어도 하나에 기초하여 스트리밍 데이터를 생성하는 방법은 아래와 같은 방식으로 영상 콘텐트를 변환하여 생성하는 것일 수 있다. 1번째로, 예측 프레임을 다운스케일링하고, 다운스케일된 예측 프레임을 이용해서 스트리밍 데이터를 생성할 수 있다. 여기서, 다운스케일의 비율 및 다운스케일 방법에 대한 정보가 메타 데이터에 추가될 수 있다. 또한, 다 운스케일의 대상은 예측 프레임 전체이거나 프레임 중 일부 영역만이 다운스케일될 수 있다. 또한, 다운스케일 은 입력된 프레임들을 효과적으로 다운스케일하도록 훈련된 인공지능 모델을 이용하여 수행될 수 있다. 다운스케일을 이용하여 이미지 또는 비디오의 크기가 감소됨으로써 서버에서 영상 콘텐트의 사용자까지의 대역 폭 용량이 절감되고, 네트워크의 레이턴시가 낮아지고, 영상 콘텐트의 지연이 제거될 수 있다. 2번째로, 예측 프레임 내의 객체들에 대응되는 객체 정보를 마킹하여 스트리밍 데이터를 생성할 수 있다. 예를 들어, 하늘 영역이 스트리밍 데이터에 포함되어 있지 않더라도, 미리정해진 룰에 따라 해당 영역이 하늘임을 나 타내는 객체 정보가 마킹되어 전송되면, 전자 장치에서 영상 복원 시에 객체 정보에 따라 해당 영역이 하 늘 영역임을 알고, 하늘로 복원될 수 있다. 이러한 방식은 훈련된 GAN(Generative Adversarial Network)를 통 해 수행될 수 있다. 즉, GAN을 이용하여 마킹된 객체 정보를 이용하여 소정 영역을 복원할 수 있다. 3번째로, 예측 프레임들 중 일부를 이용해서 스트리밍 데이터를 생성할 수 있다. 구체적으로, 훈련된 GAN을 통 해 최초 프레임, 중간 프레임, 최종 프레임과 메타 데이터들을 전송한다. 그 후, 전자 장치에서, 최초 프 레임, 중간 프레임, 최종 프레임과 메타 데이터들을 이용하여 GAN을 통해 나머지 프레임들을 복원할 수 있다. 4번째로, 비디오 프레임 없이 영역들에 대한 메타 데이터만을 제공할 수 있다. 전자 장치는 영역들에 대한 메타 데이터들을 이용하여 프레임들을 복원할 수 있다. 이러한 방식 또한 훈련된 인공지능 모델을 통해 수행될 수 있다. 예를 들어, 게임 영상 콘텐트를 스트리밍하는 서비스에서, 예를 들어, 클라우드(cloud)에서 실행된 게 임 엔진은 게임 속 세계를 유지하고, 플레이어의 동작에 응답하여 플레이어들 및 개체의 위치, 그들의 속성 등 을 변경하고, 서버는 영상을 렌더링하지 않고, 전자 장치에서 화면에 표시되는 2D 그래픽을 생성하는데 이용되 는 메타 데이터를 전송하고, 전자 장치는 메타 데이터를 이용하여 전자 장치에서 플레이어의 화면에 디스플레이 되는 영상을 완전히 렌더링한다. 이와 같이, 영상 대신 메타 데이터만을 전송하면, 게임 스트리밍 서비스에서의 대역폭 사용량이 절감될 수 있다. 또한, 영상을 렌더링하는 역할이 서버에서 전자 장치로 넘어가면 게임 엔진을 실행하는 서버가 상대적으로 적은 컴퓨팅 성능(computing power)을 필요로 하므로, 클라우드 하드웨어의 사용량 을 최적화할 수 있다. 멀티 플레이어 게임의 경우, 하나의 인스턴스 게임 스트리밍 서버가 게임을 처리하고 동 일한 메타 데이터를 모든 플레이어들에게 전송할 수 있다. 또한, 대역폭의 최적화, 해상도의 최적화, 프레임 속도의 최적화, 레이턴시 최적화 등의 서비스 제공자 전략에 따라 위의 방식들이 혼합되어 적용될 수 있다. 본 개시의 일 실시예에 따르면, 전자 장치는 서버로부터 스트리밍 데이터를 수신한다. 전자 장 치는 서버로부터 수신된 스트리밍 데이터에 포함된 프레임들 및 메타데이터 중 적어도 하나에 기초하 여 영상 콘텐트에 대한 프레임을 복원할 수 있다. 전자 장치는 먼저, 수신된 스트리밍 데이터로부터, 전자 장치에서 현재 실행 중인 상기 영상 콘텐트의 N개의 프레임들을 디스플레이한다. N개의 프레임들은 전자 장치에 이전에 입력된 사용자 입력에 대한 서버의 응답 결과일 수 있다. 전자 장치는 서버 와 전자 장치 사이의 현재 네트워크의 지연 시간을 식별한다. 전자 장치는 지연 시간과 현 재 사용자 입력에 따라, 수신된 스트리밍 데이터로부터, 가능한 복수의 사용자 입력들에 대응하는 K개의 예측 프레임 세트들 중 상기 현재 사용자 입력에 대응하는 예측 프레임 세트에 포함된 M개의 예측 프레임들의 디스플 레이 여부를 결정한다. 현재 사용자 입력은 스크린 상의 클릭, 키보드의 입력, 마우스의 입력, 컨트롤러의 입력, 스티어링 휠(steering wheel)의 입력 등일 수 있다. 전자 장치는 M개의 예측 프레임들을 디스플레이 하는 것으로 결정되면, M개의 예측 프레임들을 디스플레이한다. 예측 프레임은 전자 장치에 의해 서 버로부터 전송된 스트리밍 데이터가 예측 프레임을 생성하기 위해 훈련된 인공지능 모델에 입력됨으로써 생성될 수 있다. 전자 장치는 M개의 예측 프레임들을 디스플레이하지 않는 것으로 결정되면, 현재 사용자 입력에 대한 제2 스트리밍 데이터의 수신을 대기한다. 또한, M개의 예측 프레임들이 디스플레이되는 도중에 현재 사용자 입력에 대한 제2 스트리밍 데이터가 수신되면, 전자 장치는 M개의 예측 프레임들의 디스플레이를 중단하고, 수신된 제2 스트리밍 데이터의 프레임들을 디스플레이할 수 있다. 예를 들어, 예측 프레임 N+1 내지 예측 프레임 N+M의 중간 프레임이 디스플레 이되는 도중에, 제2 스트리밍 데이터가 수신되면, 전자 장치는 예측 프레임들의 디스플레이를 중단하고, 예측 프레임들을 현재 사용자 입력에 대한 N개의 프레임들로 대체하여 N개의 프레임들을 디스플레이할 수 있다. 또한, 수신된 제2 스트리밍 데이터가 저해상도이면, 전자 장치는 제2 스트리밍 데이터 및 스트리밍 데이터 에 기초하여 영상을 고해상도로 복원할 수 있다. 또한, 전자 장치는 제2 스트리밍 데이터가 수신되었더라 도 지연 시간이 일정 시간 이상이면, 이미 수신된 제2 스트리밍 데이터 및 스트리밍 데이터에 기초하여 예측된 프레임을 디스플레이할 수 있다. 예를 들어, 전자 장치는 현재 사용자 입력에 대한 제2 스트리밍 데이터의 프레임들과 제2 스트리밍 데이터 이전에 수신된 스트리밍 데이터에 기초한 예측 프레임에 기초하여 새로운 예측 프레임들을 생성하여 디스플레이할 수 있다. 또한, 프레임 누락과 같은 지연이 감지되면, 전자 장치는 현재 사용자 입력에 기초하여 이전 프레임과 예 측 프레임에 기초하여 영상 콘텐트를 디스플레이할 수 있다. 예를 들어, 전자 장치는 사용자의 시점에서 예를 들어, 스티어링 휠의 회전 입력에 따라, 이전 프레임 내의 영역이 회전하는 경우, 회전하는 입력에 대한 예측 프레임들을 디스플레이할 수 있다. 전자 장치는 서버와 전자 장치의 성능, 대역폭, 지연 제거, 영상 품질 중 적어도 하나를 최적화 하기 위해, 사용자의 전자 장치에게 전송할 예측 및 데이터를 조정하는 서비스 제공자의 서버에 전자 장치의 그래픽 처리 장치(Graphic Processing Unit, GPU), 신경망 처리 장치(Neural Processing Unit, NPU)에 대한 정보 및 전자 장치에서 지원하는 라이브러리 및 모델에 대한 정보를 전송할 수 있다. GPU 및 NPU 각각은 가장 효율적인 방식으로 활용될 수 있다. 예들 들어, GPU 및 NPU 중 하나가 이미지를 업스케일일하 도록 설계된 경우, 업스케일링하는 경우에 활용되고, GPU 및 NPU 중 나머지 하나도 자신의 역할에 따라 활용되 거나, 범용 처리 장치인 GPGPU (General-Purpose computing on Graphics Processing Units)로 활용될 수 있다. 고해상도를 딥 러닝 방법들은 모든 종류의 영상에 보편적으로 적용되지 않고, 각각의 장단점이 있기 때문에 각 각의 설계에 맞는 역할에 따라 활용될 수 있다. 서버에서 예측한 예측 전략들 중 둘 이상의 예측 전략이 현재 상황(현재 사용자 입력)에 적절한 경우, 전 자 장치는 둘 이상의 예측 전략들 중 하나를 구현하거나, 정의된 방법들 또는 공식들에 따라 둘 이상의 예 측 전략들을 혼합하여 구현할 수 있다. 이러한 경우, 전자 장치는 실제 결과와 예측 결과 사이의 오류율 (error rate)를 최소화하여야 한다. 전자 장치가 서버에서 예측한 예측을 사용할 수 없는 경우, 전자 장치는 마지막 프레임을 표시 하거나, 가장 가능한 예측 시나리오 또는 가장 선호하는 예측 시나리오 중 하나를 선택하여 새로운 프레임을 생 성할 수 있다. 현재 오류율이 전자 장치가 허용할 수 있는 오류율의 임계값 미만인 경우에도, 전자 장치 는 마지막 프레임을 표시하거나, 가장 가능한 예측 시나리오 또는 가장 선호하는 예측 시나리오 중 하나를 선택하여 새로운 프레임을 생성할 수 있다. 전자 장치가 수신한 스트리밍 데이터의 복원은 서버에서의 스트리밍 데이터의 생성 방법에 따라 수행 될 수 있다. 1번째로, 스트리밍 데이터가 다운스케일되어 전송된 것인 경우, 스트리밍 데이터에 포함된 다운스케일의 비율 및 다운스케일 방법에 대한 정보를 통해 다운스케일의 비율 및 다운스케일 방법에 대응하는 방식으로 영상이 업 스케일될 수 있다. 또한, 영상의 일부 영역만이 다운스케일된 경우, 영상의 일부 영역만이 업스케일될 수 있다. 또한, 업스케일은 서버로부터 전송된 다운스케일 관련 정보에 기초하여, 프레임들을 효과적으로 업스케일 하도록 훈련된 인공지능 모델을 이용하여 수행될 수 있다. 2번째로, 예측 프레임 내의 객체들에 대응되는 객체 정보를 마킹하여 스트리밍 데이터를 생성하여 전송된 것인 경우, 전자 장치는 스트리밍 데이터에 포함된 객체 정보에 따라 해당 영역이 훈련된 GAN을 통해 복원될 수 있다. 예를 들어, 영상의 일부 영역이 바다인 것으로 객체 정보가 마킹된 경우, 해당 영역이 훈련된 GAN을 통해 바다로 복원될 수 있다. 3번째로, 스트리밍 데이터에 예측 프레임들 중 일부와 메타 데이터들이 포함되어 전송된 것일 수 있다. 구체적 으로, 최초 프레임, 중간 프레임, 최종 프레임과 메타 데이터들이 전송된 경우, 전자 장치는 최초 프레임, 중간 프레임, 최종 프레임과 메타 데이터들 이용하여 GAN을 통해 나머지 프레임들이 복원될 수 있다. 4번째로, 스트리밍 데이터에 비디오 프레임 없이 영역들에 대한 메타 데이터만이 포함되어 전송될 수 있다. 전 자 장치는 프레임 없이 프레임의 각 영역들에 대한 메타 데이터들을 이용하여 프레임들을 복원할 수 있다.이러한 방식은 훈련된 인공지능 모델을 통해 수행될 수 있다. 또한, 스트리밍 데이터가 위의 방식들이 혼합되어 전송된 경우, 각 방식에 맞게 영상이 복원될 수 있다. 이를 통해, 영상 콘텐트를 스트리밍하는 서버와 전자 장치 사이의 네트워크의 지연 시간이 일정 시간 이상인 경우, 서버에서 준비된 예측 프레임 세트들 중 전자 장치에 입력된 현재 사용자 입력에 대응 하는 하나의 예측 프레임 세트를 디스플레이하여, 렉의 발생을 느끼지 못하게 하여 사용자의 영상 콘텐트에 대 한 사용자 경험을 개선하고, 영상을 스무스하게 디스플레이할 수 있다. 즉, 사용자 입력과 화면 상의 결과 사이 의 긴 응답 시간이 없기 때문에, 동적인 게임 스트리밍(예를 들어, 레이싱 게임)에서 긴 지연 시간으로 인한 충 돌 또는 잘못된 이동 경로로 인해 사용자 경험을 망치는 것을 방지할 수 있다. 또한, 영상 콘텐트를 스트리밍하 기 위해 훈련된 인공지능 모델을 활용할 수 있는 스마트 TV 등과 같은 전자 장치에서 영상 콘텐트들이 효과적으 로 스트리밍될 수 있다. 또한, 인공지능 모델을 이용하여 전자 장치에서 영상 콘텐트를 복원함으로써, 스트리밍 서버 측의 부담을 경감하여 영상 스트리밍 시의 대역폭을 절감시킬 수 있다. 도 2는 일 실시예에 따른 예측 프레임을 생성하는 방법을 설명하기 위한 도면이다. 도 2를 참고하면, 전자 장치에서 현재 실행중인 영상 콘텐트에 대한 N개의 프레임, 즉, 프레임 1 내 지 프레임 N 이 디스플레이되고, 서버와 전자 장치 사이의 네트워크의 지연 시간이 일정 시간보 다 짧아 서버가 전자 장치에서의 현재 사용자 입력에 즉각적으로 응답할 수 있다면, 현재 사용자 입 력에 대한 응답에 대응하는 M개의 프레임, 즉, 프레임 N+1 내지 프레임 N+M 이 디스플레이된다. 그러나, 서버와 전자 장치 사이의 지연 시간이 일정 시간 이상인 경우에는 서버가 전자 장치에 서의 현재 사용자 입력에 즉각적으로 응답할 수 없기 때문에, 서버는 N개의 프레임에 기초하여 전자 장치에서 가능한 복수의 사용자 입력 각각에 대응하는 M개의 예측 프레임, 즉, 복수의 사용자 입력 중 제1 사용자 입력에 대응하는 예측 프레임 N+1 내지 예측 프레임 N+M , ..., 복수의 사용자 입력 중 제K 사용자 입력에 대응하는 예측 프레임 N+1 내지 예측 프레임 N+M 등을 생성할 수 있다. 서버는 N개의 프레임 들과 K개의 예측 프레임 세트들로부터 메타 데이터를 추출하고, K개의 예측 프레임 세트들 및 메타 데이터 중 적어도 하나에 기초하여 스트리밍 데이터를 생성하여 전자 장치에 전송한다. 이에 따라, 전자 장치는 지연 시간이 일정 시간 이상인 경우에, 예측 프레임들의 세트와 메타 데이터의 적어도 하나에 기초하여 현재 사 용자 입력에 대응하는 예측 프레임들을 생성하여 프레임 N+1 내지 프레임 N+M 을 생성된 예측 프레 임들로 대체한다. 도 3은 일 실시예에 따른 서버가 프레임 및 예측 프레임을 준비하는 방법을 설명하기 위한 도면이다. 도 3을 참고하면, 서버는 영상 콘텐트(예를 들어, 게임)의 현재 상태에 기초하여 프레임을 준비한다. 그 후, 서버는 현재 가능한 동작과 상태들의 리스트에 따라 다음 프레임들을 예측한다. 가능한 동작에 따라 예측 1 , 예측 2 , ..., 예측 K 에 맞게 예측 프레임을 준비(331, 332, 333)한다. 서버 는 준비된 예측 프레임에 기초하여 프레임의 영역들의 모양, 설명, 패턴, 시프트에 대한 메타 데이터를 추 출한다. 서버는 준비된 프레임, 준비된 예측 프레임, 메타 데이터 중 적어도 하나에 기초하여 데이터를 압축한 다. 도 4는 일 실시예에 따른 서버에서 예측 프레임 세트들 및 메타 데이터 중 적어도 하나에 기초하여 스트리밍 데 이터를 생성하는 예시들을 설명하기 위한 도면이다. 도 4를 참고하면, 레이싱 게임에서의 영상 콘텐트 는 하늘 영역 , 나무 영역 , 집 영역 , 사람이 다니는 인도 영역 , 차가 다니는 차도 영역 , 차 영역 , 잔디 영역 등을 포함하고 있다. 영상 콘텐트의 프레임들 사이의 색상, 패턴, 및 변형(이동, 늘이기 등)에 대한 속성이 영상 콘텐트 내의 영역들에 추가될 수 있다. 이러한 정보들은 데이터 대기 시간이 길어지는 경우 화면 정지(screen freeze) 를 제거하기 위해 사용된다. 전자 장치는 이전 프레임(프레임 1 내지 프레임 N)과 각 영역들에 대한 메타 데이 터 및 예측 데이터에 기초하여 추가적인 예측 프레임들(예측 프레임 N+1 내지 예측 프레임 N+M)을 생성한다. 이 를 통해 동적인 게임 스트리밍에서 긴 네트워크 지연으로 인해 화면이 정지되어 사용자에게 실망스러운 경험을 하게 하여, 사용자 경험을 악화시키는 것을 방지하고, 사용자에게 지연 없는 스무스한 게임을 기대하게 한다. 서버에서 영상 콘텐트의 스트리밍 데이터를 생성하는 방법 중 하나로 영상 콘텐트 를 인공지능 모델에 기 초하여 영상 콘텐트 전체를 다운스케일하여 스트리밍 데이터를 생성하면서, 메타 데이터에 다운스케일 비율에 대한 정보를 포함시킬 수 있다. 또한, 인공지능 모델에 기초하여 영상 콘텐트 에 포함된 영역들 중 일부 영역, 예를 들어, 하늘 영역 , 차도 영역 , 잔디 영역 만을 다운스케일하여 스트리밍 데이 터를 생성하면서, 메타 데이터에 일부 영역과 일부 영역의 다운스케일 비율에 대한 정보를 포함시킬 수 있다. 다운스케일링을 이용함으로써, 서버로부터 전자 장치까지의 대역폭을 개선할 수 있고, 레이턴시를 줄 여 영상 콘텐트의 렉을 제거할 수 있다. 스트리밍 데이터를 생성하는 방법 중 다른 하나로, 영상 콘텐트 의 각 객체들에 대응되는 객체 정보를 마 킹할 수 있다. 구체적으로, 영상 콘텐트 내의 객체들이 무엇인지 마킹하여 마킹된 정보를 메타 데이터로 전송할 수 있다. 예를 들어, 영상 콘텐트 내의 하늘 영역 에 대하여 하늘에 대한 데이터가 스트리밍 데이터에 포함되지 않더라도, 하늘 영역이 하늘 임을 나타내는 어떤 수치(예를 들어, \"0\"은 하늘)로 표시 하고, 객체 정보로 마킹하여 메타 데이터에 포함시켜 전송할 수 있다. 이에 따라, 전자 장치에서는, 미리 정해 진 룰에 따라 인공지능 모델을 이용하여 해당 영역을 하늘 영역으로 생성할 수 있다. 스트리밍 데이터를 생성하는 방법 중 다른 하나로, 영상 콘텐트의 프레임들 중 일부와 메타 데이터를 이용하여 스트리밍 데이터를 생성할 수 있다. 예를 들어, 프레임들 중 최초 프레임, 중간 프레임, 및 최종 프레임과 영상 콘텐트의 각 영역들에 대한 메타 데이터를 포함하여 스트리밍 데이터로 전송할 수 있다. 스트리밍 데이터를 생성하는 방법 중 다른 하나로, 영상 콘텐트에 대한 메타데이터 만을 포함하도록 스트리밍 데이터를 생성할 수 있다. 또한, 전술된 방법들을 혼합하여 스트리밍 데이터를 생성할 수 있다. 도 5는 일 실시예에 따른 전자 장치에서 예측 프레임 세트들 및 메타 데이터 중 적어도 하나에 기초하여 스트리 밍 데이터를 복원하는 예시들을 설명하기 위한 도면이다. 도 5를 참고하면, 이미지 내의 포함된 메타 데이터와 프레임 중 적어도 하나에 기초하여 인공지능 모 델에 따라, 영상 콘텐트를 복원할 수 있다. 일 예로, 다운스케일된 프레임과 다운스케일에 대한 정보를 포함하는 메타 데이터를 이용하여 다운스케일된 프 레임을 인공지능 모델에 따라 다운스케일된 프레임을 업스케일하여 영상 콘텐트를 복원할 수 있다. 또한, 프레 임 중 일부 영역만 다운스케일된 경우, 다운스케일된 일부 영역, 일부 영역에 대한 정보, 다운스케일에 대한 정 보를 이용하여 인공지능 모델에 따라, 다운스케일된 일부 영역을 업스케일하고 영상 콘텐트를 복원할 수 있다. 다른 예로, 영상 콘텐트의 각 객체들에 대응되는 마킹된 객체 정보에 기초하여 인공지능 모델에 따라 영상 콘텐 트를 복원할 수 있다. 다른 예로, 스트리밍 데이터 내의 영상 콘텐트의 프레임들 중 일부와 메타 데이터를 이용하여 인공지능 모델에 따라, 영상 콘텐트를 복원할 수 있다. 예를 들어, 프레임들 중 최초 프레임, 중간 프레임, 및 최종 프레임과 영 상 콘텐트의 각 영역들에 대한 메타 데이터를 이용하여 인공지능 모델에 따라, 영상 콘텐트를 복원할 수 있다. 다른 예로, 스트리밍 데이터에 포함된 영상 콘텐트에 대한 메타데이터만을 이용하여 인공지능 모델에 따라, 영 상 콘텐트를 복원할 수 있다. 또 다른 예로, 서버에서 전송된 스트리밍 데이터가 여러 방법이 혼합되어 생성된 경우, 각 방법에 맞게 전송된 스트리밍 데이터를 영상 콘텐트로 복원할 수 있다. 도 6a는 인공지능 모델을 이용하지 않고 스트리밍 상태가 좋지 않은 경우 영상 스트리밍의 일 예를 설명하기 위 한 도면이다. 도 6a를 참고하면, 영상 콘텐트 스트리밍(예를 들어, 게임 스트리밍) 중에 영상 해상도 드랍이 발생하면, 영상 콘텐트 내의 텍스트들의 화질이 떨어져 읽기 힘들어질 수 있다. 예를 들어, 게임 영상 콘텐트 내의 캐릭터 의 체력 게이지 바를 나타내는 텍스트 및 속도를 나타내는 텍스트 의 화질이 흐릿해져 사용자가 텍스 트를 읽을 수 없어, 게임 스트리밍 서비스를 이용하는 사용자에게 불편함을 줄 수 있다. 도 6b는 일 실시예에 따른 영상 스트리밍의 일 예를 설명하기 위한 도면이다. 도 6a와 달리, 도 6b를 참고하면, 인공지능 모델을 이용하면 네트워크 상태가 좋지 않아 해상도 드랍이 발생하 더라도, 메타 데이터와 예측 프레임에 기초하여 인공지능 모델(예를 들어, GAN)에 따라 판독가능한 실제 수치를 나타내는 고품질 영상 콘텐트로 복원할 수 있다. 예를 들어, 네트워크 상태가 좋지 않아 해상도 드랍이 발생하더라도, 인공지능 모델에 따라 게임 영상 콘텐트 내의 캐릭터의 체력 게이지 바를 나타내는 텍스트 및 속도를 나타내는 텍스트 가 뚜렷하게 복원될 수 있다. 또한, 특수한 GAN을 이용하여 서비스 제공자가 정의한 원하는 폰트, 포맷, 위치, 및 배경으로 텍스트가 렌더링될 수 있다. 도 7은 영상 콘텐트의 일 예를 설명하기 위한 도면이다. 도 7을 참고하면, 영상 콘텐트는 게임 영상 콘텐트 뿐만 아니라, VR 게임 영상 콘텐트, AR 게임 영상 콘텐트, VR 영상 콘텐트, AR 영상 콘텐트를 포함할 수 있다. AR 게임 또는 VR 게임을 스트리밍하는 경우에는 상당한 대 역폭이 필요하지만, 다른 참가자의 얼굴이 스트리밍되는 경우에 콘텐트의 대역폭 및 화질을 줄이는 것은 허용될 수 없다. 따라서, 서비스 제공자(service provider)는 예측 프레임들 및 메타 데이터와 같은 추가 데이터를 제 공하여 전자 장치에서 콘텐트를 생성하도록 할 수 있다. 구체적으로, 2명의 플레이어가 VR 게임을 플레이 하는 경우에, VR 게임 영상 콘텐트가 디스플레이될 때, 사용자가 머리를 움직이면, 전자 장치는 그에 맞게 즉각적인 응답을 취하기 위해, 이미 전달된 콘텐트와 콘텐트 내의 영역들에 대한 메타 데이터를 기초로 하여 새 로운 프레임들을 생성할 수 있다. 즉, VR 게임 영상 콘텐트에서는 사용자가 머리를 움직이는 동작이 사용 자 입력이 될 수 있다. 그 후, 사용자의 움직임에 따른 새로 업데이트된 스트림 데이터가 서버로부터 사용자가 착용한 전자 장치에 수신되면, 생성된 프레임을 서버에서 수신된 프레임으로 교체할 수 있다. 도 8은 일 실시예에 따른 서버가 전자 장치에 영상 콘텐트의 스트리밍 데이터를 전송하는 방법의 흐름도이다. 도 8을 참고하면, 단계 810에서, 서버는 전자 장치에서 실행 중인 영상 콘텐트의 N개의 프레임들을 획득한다. 단계 820에서, 서버는 N개의 프레임들에 관련하여 사용자에 의해 입력 가능한 복수의 사용자 입력들을 식 별한다. 일 실시예에 따라, N개의 프레임은, 전자 장치의 화면 상에 디스플레이 중인 영상 콘텐트의 현재 영상에 대응되 는 것일 수 있다. 단계 830에서, 서버는 복수의 사용자 입력들에 대응되는 K개의 예측 프레임 세트들을 생성한다. 예측 프레 임 세트들 각각은 N개의 프레임들 이후에 디스플레이될 수 있는 M개의 예측 프레임들을 포함한다. 일 실시예에 따라, 예측 프레임은, N개의 프레임에 관련된 사용자 입력에 따라 N개의 프레임 이후에 디스플레이 될 것으로 예측되는 프레임일 수 있다. 또한, 일 실시예에 따라, 예측 프레임은, 프레임들 및 사용자 입력의 종류에 따라, 프레임들 이후의 예측 프레 임을 생성하도록 훈련된 인공지능 모델을 이용하여 생성되는 것일 수 있다. 일 실시예에 따라, 예측 프레임 세트 내의 상기 예측 프레임들의 개수 M은 상기 서버 및 상기 전자 장치 간의 현재 네트워크의 지연 시간에 따라 결정될 수 있다. 단계 840에서, 서버는 N개의 프레임들 및 K개의 예측 프레임 세트들로부터 메타 데이터를 획득한다. 일 실시예에 따라, 메타데이터는 프레임 내의 오브젝트, 형태, 및 속성 중 적어도 하나에 대한 정보를 포함할 수 있다. 단계 850에서, 서버는 K개의 예측 프레임 세트들 및 메타 데이터 중 적어도 하나에 기초하여, 전자 장치 에 제공될 영상 콘텐트의 스트리밍 데이터를 생성한다. 일 실시예에 따라, 스트리밍 데이터는 예측 프레임을 다운스케일링하고, 다운스케일된 예측 프레임을 이용해서 생성될 수 있다. 또한, 예측 프레임은 프레임 전체가 다운스케일되거나 프레임 중 일부 영역이 다운스케일될 수 있다. 메타 데이터에는 다운스케일링 비율에 대한 정보가 포함될 수 있다. 일 실시예에 따라, 스트리밍 데이터는 예측 프레임 내의 객체들에 대응되는 객체 정보를 마킹하여 생성될 수 있 다. 일 실시예에 따라, 스트리밍 데이터는 예측 프레임들 중 일부를 이용하여 생성될 수 있다. 일 실시예에 따라, 스트리밍 데이터는 메타 데이터만을 이용하여 생성될 수 있다. 단계 860에서, 서버는 생성된 스트리밍 데이터를 전자 장치에 전송한다. 도 9는 일 실시예에 따른 서버의 블록도이다. 도 9를 참고하면, 본 개시의 일 실시예에 따른 서버는 메모리, 프로세서, 및 통신부를 포 함할 수 있다. 메모리는 후술할 프로세서에 의해 실행될 프로그램을 저장할 수 있고, 서버로 입력되거나 서버 로부터 출력되는 데이터를 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, 프레임 획득 모듈, 사용자 입력 식별 모듈 , 예측 프레임 생성 모듈, 메타 데이터 획득 모듈 , 데 이터 생성 모듈 , 및 데이터 전송 모듈 를 포함할 수 있다. 프로세서는 서버의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 메모리에 저장된 프 로그램들을 실행함으로써, 메모리 및 통신부를 전반적으로 제어할 수 있다. 프로세서는 메모리에 저장된 프레임 획득 모듈을 실행함으로써, 전자 장치에서 실행 중인 영상 콘텐트의 N개의 프레임들을 획득할 수 있다. 프로세서는 메모리에 저장된 사용자 입력 식별 모듈을 실행함으로써, N개의 프레임들에 관련하 여 사용자에 의해 입력 가능한 복수의 사용자 입력들을 식별할 수 있다. 프로세서는 메모리에 저장된 예측 프레임 생성 모듈을 실행함으로써, 복수의 사용자 입력들에 대응되는 K개의 예측 프레임 세트들을 생성할 수 있다. 프로세서는 메모리에 저장된 메타 데이터 획득 모듈을 실행함으로써, N개의 프레임들 및 K개의 예측 프레임 세트들로부터 메타 데이터를 획득할 수 있다. 프로세서는 메모리에 저장된 데이터 생성 모듈을 실행함으로써, K개의 예측 프레임 세트들 및 메타 데이터 중 적어도 하나에 기초하여, 전자 장치에 제공될 영상 콘텐트의 스트리밍 데이터를 생성할 수 있다. 프로세서는 메모리에 저장된 데이터 전송 모듈을 실행함으로써, 통신부를 통해 생성된 스 트리밍 데이터를 전자 장치에 전송할 수 있다. 통신부는 서버가 생성한 스트리밍 데이터를 전자 장치에 전송하기 위한 통신 수단을 의미한다. 또한, 통신부는 전자 장치가 사용자로부터 수신한 사용자 입력에 대한 정보를 서버에서 수신하 기 위한 통신 수단이다. 도 10은 일 실시예에 따른 전자 장치가 서버로부터 영상 콘텐트의 스트리밍 데이터를 수신하는 방법의 흐름도이 다. 도 10을 참고하면, 단계 1010에서, 전자 장치는 서버로부터 영상 콘텐트의 스트리밍 데이터를 수신 한다. 단계 1020에서, 전자 장치는 수신된 스트리밍 데이터로부터, 전자 장치에서 현재 실행 중인 영상 콘텐트의 N개의 프레임들을 디스플레이한다. 단계 1030에서, 전자 장치는 서버와 전자 장치 사이의 현재 네트워크의 지연 시간을 식별한다. 단계 1040에서, 전자 장치는 지연 시간과 현재 사용자 입력에 따라, 수신된 스트리밍 데이터로부터, 가능 한 복수의 사용자 입력들에 대응하는 K개의 예측 프레임 세트들 중 현재 사용자 입력에 대응하는 예측 프레임 세트에 포함된 M개의 예측 프레임들의 디스플레이 여부를 결정한다. 단계 1050에서, 전자 장치는 디스플레이하는 것으로 결정되면, M개의 예측 프레임들을 디스플레이한다. 일 실시예에 따라, M개의 예측 프레임들을 디스플레이하는 도중에 상기 제2 스트리밍 데이터가 수신되면, M개의 예측 프레임들의 디스플레이가 중단되고, 수신된 제2 스트리밍 데이터의 프레임들이 디스플레이될 수 있다. 일 실시예에 따라, 상기 수신된 제2 스트리밍 데이터가 저해상도이면, 제2 스트리밍 데이터 및 상기 스트리밍 데이터에 기초하여 상기 영상이 고해상도로 복원될 수 있다. 일 실시예에 따라, 지연 시간이 미리정해진 시간 이상이면, 이미 수신된 제2 스트리밍 데이터 및 스트리밍 데이 터에 기초하여 예측된 프레임이 디스플레이될 수 있다. 단계 1060에서, 전자 장치는 디스플레이하지 않는 것으로 결정되면, 현재 사용자 입력에 대한 제2 스트리 밍 데이터의 수신을 대기한다. 일 실시예에 따라, 제2 스트리밍 데이터는 서버가 전자 장치에 입력된 현재 사용자 입력에 대한 응 답으로 생성된 스트리밍 데이터일 수 있다. 도 11은 일 실시예에 따른 전자 장치의 블록도이다. 도 11를 참고하면, 본 개시의 일 실시예에 따른 전자 장치는 메모리, 프로세서, 통신부 , 디스플레이부, 및 입력부를 포함할 수 있다. 메모리는 후술할 프로세서에 의해 실행될 프로그램을 저장할 수 있고, 전자 장치로 입력되거 나 전자 장치로부터 출력되는 데이터를 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, 수신 모듈, 지연시간 식별 모듈, 디스플레이 결정 모듈을 포함할 수 있다. 프로세서는 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 메모리에 저장된 프로그램들을 실행함으로써, 메모리, 통신부, 디스플레이부, 및 입력부를 전반 적으로 제어할 수 있다. 프로세서는 메모리에 저장된 수신 모듈을 실행함으로써, 통신부를 통해 서버로부 터 영상 콘텐트의 스트리밍 데이터를 수신할 수 있다. 프로세서는 메모리에 저장된 지연시간 식별 모듈을 실행함으로써, 서버와 전자 장치 사이의 현재 네트워크의 지연 시간을 식별할 수 있다. 프로세서는 메모리에 저장된 디스플레이 결정 모듈을 실행함으로써, 수신된 스트리밍 데이터 로부터, 전자 장치에서 실행 중인 영상 콘텐트의 N개의 프레임들을 복원하여 디스플레이부에 디스플레이 할 수 있다. 또한, 지연 시간과 현재 사용자 입력에 따라, 상기 수신된 스트리밍 데이터로부터, 가능한 복수의 사용자 입력들에 대응하는 K개의 예측 프레임 세트들 중 상기 현재 사용자 입력에 대응하는 예측 프레임 세트에 포함된 M개의 예측 프레임들의 디스플레이 여부를 결정할 수 있다. 디스플레이하는 것으로 결정되면, M개의 예 측 프레임들을 복원하여 디스플레이부에 디스플레이하고, 디스플레이하지 않는 것으로 결정되면, 상기 현 재 사용자 입력에 대한 제2 스트리밍 데이터의 수신을 대기할 수 있다. 통신부는 서버가 생성한 스트리밍 데이터를 전자 장치에서 수신하기 위한 통신 수단을 의미한 다. 또한, 통신부는 전자 장치에 사용자가 입력한 사용자 입력에 대한 정보를 서버에 전송하 기 위한 통신 수단이다. 디스플레이부는 전자 장치가 서버로부터 수신한 스트리밍 데이터를 복원한 영상 콘텐트를 표 시한다. 입력부는 사용자가 전자 장치를 제어하기 위한 데이터를 입력하는 수단으로, 영상 콘텐트에 대한 사용자의 입력을 수신할 수 있다. 예를 들어, 입력부는 키 패드(key pad), 돔 스위치 (dome switch), 터 치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠 또는 조그 스위치 중 적어도 하나를 포함할 수 있으나 이에 한정되는 것은 아니다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2021-0169438", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 서버와 전자 장치 사이의 영상 콘텐트를 스트리밍하는 과정을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 서버가 예측 프레임을 생성하는 예시를 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 서버가 프레임 및 예측 프레임을 준비하는 방법을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 서버에서 예측 프레임 세트들 및 메타 데이터 중 적어도 하나에 기초하여 스트리밍 데 이터를 생성하는 예시들을 설명하기 위한 도면이다.도 5는 일 실시예에 따른 전자 장치에서 예측 프레임 세트들 및 메타 데이터 중 적어도 하나에 기초하여 스트리 밍 데이터를 복원하는 예시들을 설명하기 위한 도면이다. 도 6a는 네트워크 상태가 좋지 않은 경우 영상 스트리밍의 일 예를 설명하기 위한 도면이다. 도 6b는 일 실시예에 따른 영상 스트리밍의 일 예를 설명하기 위한 도면이다. 도 7은 영상 콘텐트의 일 예를 설명하기 위한 도면이다. 도 8은 일 실시예에 따른 서버가 전자 장치에 영상 콘텐트의 스트리밍 데이터를 전송하는 방법의 흐름도이다. 도 9는 일 실시예에 따른 서버의 블록도이다. 도 10은 일 실시예에 따른 전자 장치가 서버로부터 영상 콘텐트의 스트리밍 데이터를 수신하는 방법의 흐름도이 다. 도 11은 일 실시예에 따른 전자 장치의 블록도이다."}
