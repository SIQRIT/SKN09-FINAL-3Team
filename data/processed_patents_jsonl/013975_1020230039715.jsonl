{"patent_id": "10-2023-0039715", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0146139", "출원번호": "10-2023-0039715", "발명의 명칭": "표시 장치 및 그의 구동 방법", "출원인": "삼성디스플레이 주식회사", "발명자": "김동우"}}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "렌즈의 표시 영역에 대응하도록 배치된 글라스;근적외선 광을 방출하는 광원부;레드 픽셀, 그린 픽셀, 블루 픽셀, 및 포토 다이오드를 포함하는 센서 픽셀을 포함하되, 상기 센서 픽셀의 개수는 상기 레드 픽셀, 상기 그린 픽셀, 및 상기 블루 픽셀 각각의 개수보다 작은 표시 패널;상기 표시 패널로부터 방출된 디스플레이 광을 상기 글라스 방향으로 반사시키는 반사 부재;상기 근적외선 광을 방출하는 광원부; 및프로세서를 포함하고, 상기 프로세서는,상기 광원부가 상기 근적외선 광을 방출하도록 제어하고,사용자의 눈에 의해 반사된 상기 근적외선 광을 상기 센서 픽셀을 통해 입력받고,상기 센서 픽셀에 입력된 정보를 데이터화하여 이미지 데이터를 생성하고,학습 알고리즘을 이용하여 이미지 데이터와 유사한 눈 특징 모델들을 생성하고,상기 생성된 눈 특징 모델들 중에서 상기 이미지 데이터의 눈 영역과 가장 유사한 눈 특징 모델을 결정하고,상기 결정된 눈 특징 모델에 기반하여, 눈동자 중심의 움직임을 추적하고, 및상기 추적된 눈동자 중심의 공간 좌표를 이용하여 사용자의 시선 방향에 대응하는 중심시 영역에 고해상도 화면을 표시하고, 상기 중심시 영역을 제외한 주변시 영역에 저해상도 화면을 표시하는,표시 장치."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 프로세서는,상기 근적외선 광을 방출한 시점으로부터 지정된 시간이 경과되었는지 결정하고,상기 지정된 시간이 경과되면, 상기 지정된 시간 동안 생성된 눈 특징 모델들 각각과 상기 이미지 데이터의 눈영역을 비교하고,상기 비교 결과에 기반하여, 눈 특징 모델들 각각에 대하여 상기 이미지 데이터의 눈 영역의 유사성을 나타내는스코어를 산출하고,상기 스코어가 가장 높은 눈 특징 모델을 선택하는,표시 장치."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 프로세서는,상기 학습 알고리즘에 입력되는 입력 변수로서, 상기 이미지 데이터, 상기 이미지 데이터의 공간 좌표, 상기 공간 좌표에 매핑되는 상기 이미지 데이터의 영역별 광 세기 값을 설정하는,표시 장치.공개특허 10-2024-0146139-3-청구항 4 제3 항에 있어서,상기 학습 알고리즘은, 메모리에 저장된 인공지능 어플리케이션이 프로세서에 의해 실행됨으로써 학습을 수행하는,표시 장치."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 학습 알고리즘은,눈 영역을 검출하는 동작, 눈동자 영역을 검출하는 동작, 및 눈동자 중심을 추출하는 동작을 수행함으로써, 눈특징 모델을 생성하는,표시 장치."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 학습 알고리즘은 Haar-like feature를 이용하여 눈의 크기, 눈의 형태, 및 눈의 특징점을 포함하는 눈 특징을 추출하는,표시 장치."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 학습 알고리즘은 Haar-like feature를 이용해 생성된 눈 특징 모델을 AdaBoost(adaptive boost) 알고리즘을 이용해 학습하는,표시 장치."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서,상기 Haar-like feature는,하나의 화이트 영역 및 하나의 블랙 영역을 포함하고, 상기 화이트 영역 및 상기 블랙 영역이 나란하게 배치되는 edge features 형태에 따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설정된,표시 장치."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6 항에 있어서,상기 Haar-like feature는,한쌍의 화이트 영역 및 상기 한쌍의 화이트 영역 사이에 배치되는 블랙 영역을 포함하는 line features 형태에따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설정된,표시 장치."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6 항에 있어서,상기 Haar-like feature는,공개특허 10-2024-0146139-4-하나의 블랙 영역 및 상기 하나의 블랙 영역의 외곽을 둘러싸도록 배치된 화이트 영역을 포함하는 center-surround features 형태에 따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설정되고,상기 블랙 영역 및 상기 화이트 영역은 사각형 또는 원형으로 설정되는,표시 장치."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "표시 장치의 구동 방법에 있어서,상기 표시 장치는, 렌즈의 표시 영역에 대응하도록 배치된 글라스, 근적외선 광을 방출하는 광원부, 레드 픽셀,그린 픽셀, 블루 픽셀, 및 포토 다이오드를 포함하는 센서 픽셀을 포함하되, 상기 센서 픽셀의 개수는 상기 레드 픽셀, 상기 그린 픽셀, 및 상기 블루 픽셀 각각의 개수보다 작은 표시 패널, 상기 표시 패널로부터 방출된디스플레이 광을 상기 글라스 방향으로 반사시키는 반사 부재, 및 상기 근적외선 광을 방출하는 광원부를 포함하고,상기 표시 장치의 구동 방법은,상기 광원부가 상기 근적외선 광을 방출하도록 제어하는 동작,사용자의 눈에 의해 반사된 상기 근적외선 광을 상기 센서 픽셀을 통해 입력받는 동작,상기 센서 픽셀에 입력된 정보를 데이터화하여 이미지 데이터를 생성하는 동작,학습 알고리즘을 이용하여 이미지 데이터와 유사한 눈 특징 모델들을 생성하는 동작,상기 생성된 눈 특징 모델들 중에서 상기 이미지 데이터의 눈 영역과 가장 유사한 눈 특징 모델을 결정하는 동작,상기 결정된 눈 특징 모델에 기반하여, 눈동자 중심의 움직임을 추적하는 동작, 및상기 추적된 눈동자 중심의 공간 좌표를 이용하여 사용자의 시선 방향에 대응하는 중심시 영역에 고해상도 화면을 표시하는 동작, 상기 중심시 영역을 제외한 주변시 영역에 저해상도 화면을 표시하는 동작을 포함하는,표시 장치의 구동 방법."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 이미지 데이터의 눈 영역과 가장 유사한 눈 특징 모델을 결정하는 동작은,상기 근적외선 광을 방출한 시점으로부터 지정된 시간이 경과되었는지 결정하는 동작,상기 지정된 시간이 경과되면, 상기 지정된 시간 동안 생성된 눈 특징 모델들 각각과 상기 이미지 데이터의 눈영역을 비교하는 동작,상기 비교 결과에 기반하여, 눈 특징 모델들 각각에 대하여 상기 이미지 데이터의 눈 영역의 유사성을 나타내는스코어를 산출하는 동작, 및상기 스코어가 가장 높은 눈 특징 모델을 선택하는 동작을 포함하는,표시 장치의 구동 방법."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항에 있어서,상기 학습 알고리즘에 입력되는 입력 변수로서, 상기 이미지 데이터, 상기 이미지 데이터의 공간 좌표, 상기 공간 좌표에 매핑되는 상기 이미지 데이터의 영역별 광 세기 값을 설정하는 동작을 더 포함하는,표시 장치의 구동 방법."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2024-0146139-5-제13 항에 있어서,상기 학습 알고리즘은, 메모리에 저장된 인공지능 어플리케이션이 프로세서에 의해 실행됨으로써 학습을 수행하는,표시 장치의 구동 방법."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서,상기 학습 알고리즘은,눈 영역을 검출하는 동작, 눈동자 영역을 검출하는 동작, 및 눈동자 중심을 추출하는 동작을 수행함으로써, 눈특징 모델을 생성하는,표시 장치의 구동 방법."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 학습 알고리즘은 Haar-like feature를 이용하여 눈의 크기, 눈의 형태, 및 눈의 특징점을 포함하는 눈 특징을 추출하는,표시 장치의 구동 방법."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서,상기 학습 알고리즘은 Haar-like feature를 이용해 생성된 눈 특징 모델을 AdaBoost(adaptive boost) 알고리즘을 이용해 학습하는,표시 장치의 구동 방법."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16 항에 있어서,상기 Haar-like feature는,하나의 화이트 영역 및 하나의 블랙 영역을 포함하는 동작, 상기 화이트 영역 및 상기 블랙 영역이 나란하게 배치되는 edge features 형태에 따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설정된,표시 장치의 구동 방법."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16 항에 있어서,상기 Haar-like feature는,한쌍의 화이트 영역 및 상기 한쌍의 화이트 영역 사이에 배치되는 블랙 영역을 포함하는 line features 형태에따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설정된,표시 장치의 구동 방법."}
{"patent_id": "10-2023-0039715", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제16 항에 있어서,상기 Haar-like feature는,하나의 블랙 영역 및 상기 하나의 블랙 영역의 외곽을 둘러싸도록 배치된 화이트 영역을 포함하는 center-공개특허 10-2024-0146139-6-surround features 형태에 따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설정되고,상기 블랙 영역 및 상기 화이트 영역은 사각형 또는 원형으로 설정되는,표시 장치의 구동 방법."}
{"patent_id": "10-2023-0039715", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "표시 장치 및 그의 구동 방법이 제공된다. 일 실시예에 따른 표시 장치는, 광원부가 근적외선 광을 방출하도록 제어하고, 사용자의 눈에 의해 반사된 상기 근적외선 광을 센서 픽셀을 통해 입력받고, 상기 센서 픽셀에 입력된 정보를 데이터화하여 이미지 데이터를 생성하고, 학습 알고리즘을 이용하여 이미지 데이터와 유사한 눈 특징 모 델들을 생성하고, 상기 생성된 눈 특징 모델들 중에서 상기 이미지 데이터의 눈 영역과 가장 유사한 눈 특징 모 델을 결정하고, 상기 결정된 눈 특징 모델에 기반하여, 눈동자 중심의 움직임을 추적하고, 및 상기 추적된 눈동 자 중심의 공간 좌표를 이용하여 사용자의 시선 방향에 대응하는 중심시 영역에 고해상도 화면을 표시하고, 상기 중심시 영역을 제외한 주변시 영역에 저해상도 화면을 표시한다."}
{"patent_id": "10-2023-0039715", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 표시 장치 및 그의 구동 방법에 관한 것이다."}
{"patent_id": "10-2023-0039715", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "안경이나 헬멧 형태로 개발되어, 사용자의 눈앞 가까운 거리에 초점이 형성되는 웨어러블 장치가 개발되고 있다. 예를 들어, 웨어러블 장치는 HMD(head mounted display) 장치 또는 AR 글라스(glass)일 수 있다. 이러한 웨어러블 장치는 증강 현실(augmented reality, 이하 \"AR\") 화면 또는 또는 가상 현실(virtual reality, 이하 \"VR\") 화면을 사용자에게 제공한다. HMD 장치 또는 AR 글라스와 같은 웨어러블 장치는 사용자가 어지러움증 없이 장시간 사용하도록 하기 위해 최 소 2000 PPI(인치 당 픽셀 수)의 디스플레이 스펙이 요구되며, 이를 위하여 고해상도의 소형 유기 발광 표시 장 치인 OLEDoS(Organic Light Emitting Diode on Silicon) 기술이 대두되고 있다. OLEDoS(Organic Light Emitting Diode on Silicon)는 CMOS(Complementary Metal Oxide Semiconductor)가 배치된 반도체 웨이퍼 기판 상에 발광 다이오드(Organic Light Emitting Diode, OLED)를 배치하는 기술이다. 한편, 웨어러블 장치에 적용되는 표시 장치는 AR 화면 또는 VR 화면을 표시할 때, 사용자의 눈의 움직임을 추적 하고, 추적된 사용자의 눈의 움직임에 기반하여 화면의 해상도를 가변한다. 예를 들어, 표시 장치는 눈 추적 기 능을 이용해 사용자의 시선의 방향을 감지하고, 시선에 대응하는 중심시 영역과 중심시 영역을 제외한 주변시 영역을 결정한다. 표시 장치는 중심시 영역에 고해상도의 화면을 표시하고, 주변시 영역에 저해상도의 화면을 표시하는 포비티드 렌더링(foveated rendering) 기술을 적용할 수 있다. 표시 장치는 사용자의 눈의 움직임을 추적하기 위하여 출력 파장 약 780 nm 내지 약 1400 nm의 근적외선 광을 사용자의 눈에 조사하고, 사용자의 눈 으로부터 반사된 근적외선 광을 감지할 수 있다."}
{"patent_id": "10-2023-0039715", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 눈 추적 기능을 위해 반사 광을 감지하는 센서 픽셀로 인한 화면 품질 저하 를 방지할 수 있는 표시 장치 및 그의 구동 방법을 제공하고자 하는 것이다. 또한, 본 발명이 해결하고자 하는 과제는 보다 향상된 눈 추적 기능을 제공하는 표시 장치 및 그의 구동 방법을 제공하고자 하는 것이다. 본 발명의 과제들은 이상에서 언급한 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0039715", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위한 일 실시예에 따른 표시 장치는, 렌즈의 표시 영역에 대응하도록 배치된 글라스, 근 적외선 광을 방출하는 광원부, 레드 픽셀, 그린 픽셀, 블루 픽셀, 및 포토 다이오드를 포함하는 센서 픽셀을 포 함하되, 상기 센서 픽셀의 개수는 상기 레드 픽셀, 상기 그린 픽셀, 및 상기 블루 픽셀 각각의 개수보다 작은 표시 패널, 상기 표시 패널로부터 방출된 디스플레이 광을 상기 글라스 방향으로 반사시키는 반사 부재, 상기 근적외선 광을 방출하는 광원부, 및 프로세서를 포함하고, 상기 프로세서는, 상기 광원부가 상기 근적외선 광을 방출하도록 제어하고, 사용자의 눈에 의해 반사된 상기 근적외선 광을 상기 센서 픽셀을 통해 입력받고, 상기 센서 픽셀에 입력된 정보를 데이터화하여 이미지 데이터를 생성하고, 학습 알고리즘을 이용하여 이미지 데이터 와 유사한 눈 특징 모델들을 생성하고, 상기 생성된 눈 특징 모델들 중에서 상기 이미지 데이터의 눈 영역과 가 장 유사한 눈 특징 모델을 결정하고, 상기 결정된 눈 특징 모델에 기반하여, 눈동자 중심의 움직임을 추적하고, 및 상기 추적된 눈동자 중심의 공간 좌표를 이용하여 사용자의 시선 방향에 대응하는 중심시 영역에 고해상도화면을 표시하고, 상기 중심시 영역을 제외한 주변시 영역에 저해상도 화면을 표시한다. 상기 프로세서는, 상기 근적외선 광을 방출한 시점으로부터 지정된 시간이 경과되었는지 결정하고, 상기 지정된 시간이 경과되면, 상기 지정된 시간 동안 생성된 눈 특징 모델들 각각과 상기 이미지 데이터의 눈 영역을 비교 하고, 상기 비교 결과에 기반하여, 눈 특징 모델들 각각에 대하여 상기 이미지 데이터의 눈 영역의 유사성을 나 타내는 스코어를 산출하고, 상기 스코어가 가장 높은 눈 특징 모델을 선택한다. 상기 프로세서는, 상기 학습 알고리즘에 입력되는 입력 변수로서, 상기 이미지 데이터, 상기 이미지 데이터의 공간 좌표, 상기 공간 좌표에 매핑되는 상기 이미지 데이터의 영역별 광 세기 값을 설정한다. 상기 학습 알고리즘은, 메모리에 저장된 인공지능 어플리케이션이 프로세서에 의해 실행됨으로써 학습을 수행한 다. 상기 학습 알고리즘은, 눈 영역을 검출하는 동작, 눈동자 영역을 검출하는 동작, 및 눈동자 중심을 추출하는 동 작을 수행함으로써, 눈 특징 모델을 생성한다. 상기 학습 알고리즘은 Haar-like feature를 이용하여 눈의 크기, 눈의 형태, 및 눈의 특징점을 포함하는 눈 특 징을 추출한다. 상기 학습 알고리즘은 Haar-like feature를 이용해 생성된 눈 특징 모델을 AdaBoost(adaptive boost) 알고리즘 을 이용해 학습한다. 상기 Haar-like feature는, 하나의 화이트 영역 및 하나의 블랙 영역을 포함하고, 상기 화이트 영역 및 상기 블 랙 영역이 나란하게 배치되는 edge features 형태에 따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설정된다. 상기 Haar-like feature는, 한쌍의 화이트 영역 및 상기 한쌍의 화이트 영역 사이에 배치되는 블랙 영역을 포함 하는 line features 형태에 따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설정된다. 상기 Haar-like feature는, 하나의 블랙 영역 및 상기 하나의 블랙 영역의 외곽을 둘러싸도록 배치된 화이트 영 역을 포함하는 center-surround features 형태에 따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설 정되고, 상기 블랙 영역 및 상기 화이트 영역은 사각형 또는 원형으로 설정된다. 상기 과제를 해결하기 위한 일 실시예에 따른 표시 장치의 구동 방법에 있어서, 상기 표시 장치는, 렌즈의 표시 영역에 대응하도록 배치된 글라스, 근적외선 광을 방출하는 광원부, 레드 픽셀, 그린 픽셀, 블루 픽셀, 및 포토 다이오드를 포함하는 센서 픽셀을 포함하되, 상기 센서 픽셀의 개수는 상기 레드 픽셀, 상기 그린 픽셀, 및 상 기 블루 픽셀 각각의 개수보다 작은 표시 패널, 상기 표시 패널로부터 방출된 디스플레이 광을 상기 글라스 방 향으로 반사시키는 반사 부재, 및 상기 근적외선 광을 방출하는 광원부를 포함하고, 상기 표시 장치의 구동 방 법은, 상기 광원부가 상기 근적외선 광을 방출하도록 제어하는 동작, 사용자의 눈에 의해 반사된 상기 근적외선 광을 상기 센서 픽셀을 통해 입력받는 동작, 상기 센서 픽셀에 입력된 정보를 데이터화하여 이미지 데이터를 생 성하는 동작, 학습 알고리즘을 이용하여 이미지 데이터와 유사한 눈 특징 모델들을 생성하는 동작, 상기 생성된 눈 특징 모델들 중에서 상기 이미지 데이터의 눈 영역과 가장 유사한 눈 특징 모델을 결정하는 동작, 상기 결정 된 눈 특징 모델에 기반하여, 눈동자 중심의 움직임을 추적하는 동작, 및 상기 추적된 눈동자 중심의 공간 좌표 를 이용하여 사용자의 시선 방향에 대응하는 중심시 영역에 고해상도 화면을 표시하는 동작, 상기 중심시 영역 을 제외한 주변시 영역에 저해상도 화면을 표시하는 동작을 포함한다. 상기 이미지 데이터의 눈 영역과 가장 유사한 눈 특징 모델을 결정하는 동작은, 상기 근적외선 광을 방출한 시 점으로부터 지정된 시간이 경과되었는지 결정하는 동작, 상기 지정된 시간이 경과되면, 상기 지정된 시간 동안 생성된 눈 특징 모델들 각각과 상기 이미지 데이터의 눈 영역을 비교하는 동작, 상기 비교 결과에 기반하여, 눈 특징 모델들 각각에 대하여 상기 이미지 데이터의 눈 영역의 유사성을 나타내는 스코어를 산출하는 동작, 및 상 기 스코어가 가장 높은 눈 특징 모델을 선택하는 동작을 포함한다. 상기 학습 알고리즘에 입력되는 입력 변수로서, 상기 이미지 데이터, 상기 이미지 데이터의 공간 좌표, 상기 공 간 좌표에 매핑되는 상기 이미지 데이터의 영역별 광 세기 값을 설정하는 동작을 더 포함한다. 상기 학습 알고리즘은, 메모리에 저장된 인공지능 어플리케이션이 프로세서에 의해 실행됨으로써 학습을 수행한 다. 상기 학습 알고리즘은, 눈 영역을 검출하는 동작, 눈동자 영역을 검출하는 동작, 및 눈동자 중심을 추출하는 동 작을 수행함으로써, 눈 특징 모델을 생성한다. 상기 학습 알고리즘은 Haar-like feature를 이용하여 눈의 크기, 눈의 형태, 및 눈의 특징점을 포함하는 눈 특 징을 추출한다. 상기 학습 알고리즘은 Haar-like feature를 이용해 생성된 눈 특징 모델을 AdaBoost(adaptive boost) 알고리즘 을 이용해 학습한다. 상기 Haar-like feature는, 하나의 화이트 영역 및 하나의 블랙 영역을 포함하는 동작, 상기 화이트 영역 및 상 기 블랙 영역이 나란하게 배치되는 edge features 형태에 따른 프로토타입을 단순합하여 눈 특징 모델을 생성하 도록 설정된다. 상기 Haar-like feature는, 한쌍의 화이트 영역 및 상기 한쌍의 화이트 영역 사이에 배치되는 블랙 영역을 포함 하는 line features 형태에 따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설정된다. 상기 Haar-like feature는, 하나의 블랙 영역 및 상기 하나의 블랙 영역의 외곽을 둘러싸도록 배치된 화이트 영 역을 포함하는 center-surround features 형태에 따른 프로토타입을 단순합하여 눈 특징 모델을 생성하도록 설 정되고, 상기 블랙 영역 및 상기 화이트 영역은 사각형 또는 원형으로 설정된다. 기타 실시예의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2023-0039715", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예들에 따른 표시 장치, 및 그의 구동 방법에 의하면, 눈 추적 기능을 위해 반사 광을 감지하는 센서 픽셀 로 인한 화면 품질 저하를 방지할 수 있다. 또한, 보다 향상된 눈 추적 기능을 제공함으로써, 고품질의 AR 화면 및/또는 VR 화면을 제공할 수 있다. 실시예들에 따른 효과는 이상에서 예시된 내용에 의해 제한되지 않으며, 더욱 다양한 효과들이 본 명세서 내에 포함되어 있다."}
{"patent_id": "10-2023-0039715", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2023-0039715", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 소자(elements) 또는 층이 다른 소자 또는 층의 \"상(on)\"으로 지칭되는 것은 다른 소자 바로 위에 또는 중간에 다른 층 또는 다른 소자를 개재한 경우를 모두 포함한다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소 를 지칭한다. 실시예들을 설명하기 위한 도면에 개시된 형상, 크기, 비율, 각도, 개수 등은 예시적인 것이므로 본 발명이 도시된 사항에 한정되는 것은 아니다. 비록 제1, 제2 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한 되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물 론이다. 본 발명의 여러 실시예들의 각각 특징들이 부분적으로 또는 전체적으로 서로 결합 또는 조합 가능하고, 기술적 으로 다양한 연동 및 구동이 가능하며, 각 실시예들이 서로에 대하여 독립적으로 실시 가능할 수도 있고 연관 관계로 함께 실시할 수도 있다. 이하 첨부된 도면을 참조하여 구체적인 실시예들에 대해 설명한다. 본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2023-0039715", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 소자(elements) 또는 층이 다른 소자 또는 층의 \"상(on)\"으로 지칭되는 것은 다른 소자 바로 위에 또는 중간에 다른 층 또는 다른 소자를 개재한 경우를 모두 포함한다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소 를 지칭한다. 실시예들을 설명하기 위한 도면에 개시된 형상, 크기, 비율, 각도, 개수 등은 예시적인 것이므로 본 발명이 도시된 사항에 한정되는 것은 아니다. 비록 제1, 제2 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한 되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물 론이다. 본 발명의 여러 실시예들의 각각 특징들이 부분적으로 또는 전체적으로 서로 결합 또는 조합 가능하고, 기술적 으로 다양한 연동 및 구동이 가능하며, 각 실시예들이 서로에 대하여 독립적으로 실시 가능할 수도 있고 연관 관계로 함께 실시할 수도 있다. 이하 첨부된 도면을 참조하여 구체적인 실시예들에 대해 설명한다. 도 1은 일 실시예에 따른 표시 장치를 포함하는 웨어러블 장치의 전면을 도시한다. 도 2는 도 1에 도 시된 웨어러블 장치의 후면을 도시한다. 도 1 및 도 2를 참조하면, 일 실시예에 따른 표시 장치는 HMD 장치에 포함된 표시 장치일 수 있다. HMD 장 치는 본체 내부에 표시 장치가 배치되며, 본체의 후면에는 화면을 표시하는 렌즈가 배치될 수 있다. 렌즈는 사용자의 좌안에 대응하는 좌안 렌즈, 및 사용자의 우안에 대응하는 우안 렌즈를 포함할 수 있다. 좌안 렌즈 및 우안 렌즈 각각은 표시 장치로부터 출력된 화면을 표시하기 위한 글라스 를 포함할 수 있다. 표시 장치가 글라스를 통해 화면을 표시하는 방법은 도 5 및 도 9를 참조하여 구체적으 로 후술하기로 한다. 도 3은 일 실시예에 따른 표시 장치를 포함하는 웨어러블 장치의 다른 예를 도시한다. 도 3을 참조하면, 일 실시예에 따른 표시 장치는 AR 글라스에 포함된 표시 장치일 수 있다. AR 글라스는 안 경 형태를 갖고 있으며, 시스루(see-through) 렌즈를 포함할 수 있다. 시스루 렌즈는 사용자의 좌안에 대응하는좌안 렌즈, 및 사용자의 우안에 대응하는 우안 렌즈를 포함할 수 있다. 좌안 렌즈 및 우안 렌즈 각각은 표시 장치로부터 출력된 화면을 표시하기 위한 글라스를 포함할 수 있다. 표시 장치가 글 라스를 통해 화면을 표시하는 방법은 도 5 및 도 9를 참조하여 구체적으로 후술하기로 한다. 도 4는 일 실시예에 따른 표시 장치의 구성 블록도이다. 도 5는 일 실시예에 따른 디스플레이 모듈의 구성 도이다. 예를 들어, 도 5는 표시 장치의 표시 패널로부터 출력된 디스플레이 광이 이동하는 광학 경로 를 도시한다. 도 4 및 도 5에 도시된 표시 장치는 도 1 및 도 2에 도시된 HMD 장치 또는 도 3에 도시된 AR 글라스에 적용 될 수 있다. 도 4 및 도 5를 참조하면, 일 실시예에 따른 표시 장치는 디스플레이 모듈, 센서 모듈, 글라스 , 배터리, 카메라, 통신 모듈, 메모리, 및 프로세서를 포함할 수 있다. 표시 장치는, 도 4에 도시되지 않았지만, 본 개시에서 설명하는 다른 구성요소를 더 포함할 수 있다. 표시 장치 는 도 4에 도시된 적어도 일부 구성요소를 생략할 수 있다. 프로세서는 메모리에 저장된 명령어들을 실행하여 표시 장치의 구성요소들(예: 디스플레이 모듈 , 센서 모듈, 배터리, 카메라, 및 통신 모듈)의 동작을 제어할 수 있다. 프로세서 는 디스플레이 모듈, 센서 모듈, 배터리, 카메라, 및 통신 모듈와 전기적으로 및/또는 작동적으로 연결될 수 있다. 프로세서는 소프트웨어를 실행하여 프로세서에 연결된 적어도 하나의 다른 구성요소들(예: 디스플레이 모듈, 센서 모듈, 배터리, 카메라, 및 통신 모듈 )을 제어할 수 있다. 프로세서는 표시 장치에 포함된 구성요소들로부터 명령을 획득할 수 있고, 획득된 명령을 해석할 수 있으며, 해석된 명령에 따라 다양한 데이터를 처리 및/또는 연산할 수 있다. 일 실시 예에 따르면, 프로세서는 디스플레이 드라이버 IC(display driver IC)(DDI)로 대체될 수 있다. 예를 들어, 본 개시에서 프로세서에 의해 수행되는 표시 장치의 적어도 일부 동작들은 DDI에 의해 수행되는 동작 일 수 있다. 메모리는 표시 장치의 구성요소, 예컨대 프로세서 또는 센서 모듈에 의해 사용되는 다양한 데이터를 저장할 수 있다. 여기서, 데이터는 어플리케이션 프로그램과 같은 소프트웨어, 및 이와 관련된 명령에 대한 입력 데이터, 또는 출력 데이터를 포함할 수 있다. 메모리는 휘발성 메모리 및 비휘발성 메모리를 포 함할 수 있다. 메모리는 눈 추적 기능을 수행하기 위한 인공지능 어플리케이션을 저장할 수 있다. 표 시 장치는 메모리에 저장된 인공지능 어플리케이션을 실행하고, 실행된 인공지능 어플리케이션 에 기반하여 인공지능 모델을 생성할 수 있다. 인공지능 모델은 기계 학습에 의해 생성될 수 있고, 이러한 학습은 표시 장치 자체에서 수행되거나, 서버(미도시)와 같은 외부 장치와 연동하여 수행될 수 있다. 학습 알고리즘은, 예를 들어, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준 지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경망(DNN: deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 표시 장치는 외부 장치(예: 스마트폰, 또는 태블릿 PC)에 내장된 프로세서를 통해 처리된 데이터를 외 부 장치(미도시)로부터 수신할 수 있다. 예를 들어, 표시 장치는 카메라를 통해 객체(예: 현실 객체 또는 사용자의 눈)를 촬영할 수 있고, 촬영한 영상을 통신 모듈를 통해 외부 장치로 전송할 수 있다. 표시 장치는 외부 장치로부터 표시 장치가 촬영한 영상에 기반한 데이터를 수신할 수 있다. 외부 장치는 표 시 장치로부터 수신된 촬영된 객체의 정보(예: 형태, 색상, 또는 위치)에 기반하여 증강 현실과 관련된 이 미지 데이터를 생성하고, 표시 장치로 전송할 수 있다. 표시 장치는 카메라를 통해 객체(예: 현실 객체 또는 사용자의 눈)를 촬영한 영상에 기반한 추가적인 정보를 외부 장치로 요청할 수 있고, 외부 장치로부 터 추가적인 정보를 수신할 수 있다. 디스플레이 모듈은 표시 패널(예: 도 5의 표시 패널), 및 표시 패널로부터 방출된 광을 글라스 의 일부분으로 전달하는 광 전달 부재(예: 도파관(520, 530))을 포함할 수 있다. 본 개시에서 표시 패널 은 도파관(예: 도 5의 520, 530)에 입력되는 디스플레이 광을 생성하는 광원부를 의미할 수 있다. 표시 패널은 OLEDoS(Organic Light Emitting Diode on Silicon) 기술이 적용된 표시 패널일 수 있다. 예를 들어, 표시 패널은 CMOS(Complementary Metal Oxide Semiconductor)가 배치된 반도체 웨이퍼 기판 상에 배치된 OLED 를 포함할 수 있다. 디스플레이 모듈의 표시 패널은 프로세서의 제어에 기초하여 증강 현실 이미지(또는 가상 현실 이미지)를 표시하기 위한 디스플레이 광을 방출할 수 있다. 예를 들어, 표시 패널로부터 방출된 디스플레 이 광은 도파관(520, 530)을 통해 렌즈(도 2의 200 또는 도 3의 200)의 표시 영역으로 전달되고, 이에 따라 사 용자는 상기 디스플레이 광을 볼 수 있다. 표시 장치(예: 프로세서)는 사용자의 입력에 응답하여 표시 패널을 제어할 수 있다. 사용자의 입력의 유형은 버튼 입력, 터치 입력, 음성 입력, 및/또는 제스처 입력 을 포함할 수 있으며, 이에 제한되지 않고 표시 패널의 동작을 제어할 수 있는 다양한 입력 방법이 포함될 수 있다. 표시 장치는 사용자의 눈의 움직임을 추적하기 위해 광원부를 더 포함할 수 있다. 광원부는 표시 패널이 방출하는 디스플레이 광과 상이한 광을 방출하도록 구성될 수 있다. 광원부는, 출력 파 장 약 780 nm 내지 약 1400 nm의 근적외선 광을 사용자의 눈에 조사하도록 구성될 수 있다. 광원부로 부터 방출된 근적외선 광은 사용자의 눈에서 반사되고, 반사된 근적외선 광은 표시 패널로 입력 될 수 있다. 표시 패널은 입력된 반사광을 이용하여 사용자의 눈의 움직임을 추적하기 위한 광학 센 서로서 시선 추적 센서(예: 도 6의 센서 픽셀(SS))를 포함할 수 있다. 여기서, 시선 추적 센서는 표시 패널 의 센서 픽셀에 배치된 포토 다이오드(도 8의 PD)를 포함할 수 있다. 표시 장치는 AR 화면 또는 VR 화면을 표시할 때, 포토 다이오드(도 8의 PD)를 이용해 사용자의 눈의 움직임 을 추적하고, 추적된 사용자의 눈의 움직임에 기반하여 화면의 해상도를 가변한다. 예를 들어, 표시 장치는 눈 추적 기능을 이용해 사용자의 시선의 방향을 감지하고, 시선에 대응하는 중심시 영역과 중심시 영역을 제외 한 주변시 영역을 결정한다. 표시 장치는 중심시 영역에 고해상도의 화면을 표시하고, 주변시 영역에 저해 상도의 화면을 표시하는 포비티드 렌더링(foveated rendering) 기술을 적용할 수 있다. 표시 장치는 인공지 능 어플리케이션의 학습 기능을 이용해 눈 추적 기능을 수행할 수 있다. 글라스는 웨어러블 장치의 렌즈(도 2의 200 또는 도 3의 200)의 표시 영역에 대응하도록 배치될 수 있다. 예를 들어, 글라스는 좌안 렌즈(도 1의 210 또는 도 3의 210) 및 우안 렌즈(도 1의 220 또는 도 3의 220) 각각에 포함될 수 있다. 글라스는, 반사 부재로서, 도파관(520, 530)을 포함할 수 있고, 도파관(520, 530)은 디스플레이 도파관 및 시선 추적 도파관 중 적어도 하나를 포함할 수 있다. 디스플레이 도파관(예: 제1 도파관)은 표시 패널으로부터 방출된 디스플레이 광이 렌즈(도 2의 200 또는 도 3의 200)의 표시 영역으로 방출되도록 광을 유도함으로써 광의 경로를 형성할 수 있다. 예를 들어, 렌 즈(도 2의 200 또는 도 3의 200)의 표시 영역은 디스플레이 도파관 내부에서 전파되는 광이 방출되는 영역 일 수 있다. 디스플레이 도파관은 적어도 하나의 회절 요소 또는 반사 요소(예: 반사 거울) 중 적어도 하나를 포함할 수 있다. 디스플레이 도파관은 디스플레이 도파관에 포함된 적어도 하나의 회절 요소 또는 반사 요소 를 이용하여 표시 패널으로부터 방출된 디스플레이 광을 사용자의 눈으로 유도할 수 있다. 예를 들어, 회절 요소는 입출력 그레이팅(input/output grating), 반사 요소는 전반사(TIR(total internal reflection))를 포함할 수 있다. 광학용 소재(예: glass)를 웨이퍼 형태로 가공하여 디스플레이 도파관으 로 사용할 수 있으며, 디스플레이 도파관의 굴절률은 약 1.5 내지 약 1.9로 다양할 수 있다. 디스플레이 도파관은 디스플레이 광이 사용자의 눈으로 유도되기 위해, 디스플레이 광을 전 반사할 수 있는 소재(예: 유리 또는 플라스틱)를 포함할 수 있다. 디스플레이 도파관의 소재는 상술한 예시에 제 한되지 않을 수 있다. 디스플레이 도파관은 표시 패널으로부터 방출된 디스플레이 광을 파장(예: 파란색, 녹색, 또는 빨간 색)에 따라 분광하여 각각 디스플레이 도파관 내의 별도의 경로로 이동하게 할 수 있다. 디스플레이 도파관은 글라스의 일부분에 배치될 수 있다. 예를 들어, 글라스의 중심점과 사용자 의 눈의 중심점이 일치되는 가상의 축 및 가상의 축과 글라스의 중심점에서 직교하는 가상의 선을 기 준으로, 디스플레이 도파관은 글라스의 상단에 배치될 수 있다. 디스플레이 도파관이 배치되는 영역은 글라스의 상술한 영역에 제한되지 않을 수 있으며, 디스플레이 도파관이 배치되는 영역은 사용자의 눈에 반사된 광의 광량이 기준 값 이상이 되도록 하는 글라스의 영역 중 임의의 영역에 배치 될 수 있다. 센서 모듈은 적어도 하나의 센서(예: 시선 추적 센서 및/또는 조도 센서)를 포함할 수 있다. 적어도 하나 의 센서는 상술한 예시에 제한되지 않을 수 있다. 예를 들어, 적어도 하나의 센서는 사용자가 표시 장치를 착용했는지를 감지할 수 있는 근접 센서 또는 접촉 센서를 더 포함할 수 있다. 표시 장치는 근접 센서 또는 접촉 센서를 통해서 사용자가 표시 장치를 착용한 상태인지 감지할 수 있다. 사용자가 표시 장치를 착 용한 상태로 감지한 경우, 표시 장치는 다른 전자 장치(예: 스마트 폰)과 수동적으로 및/또는 자동적으로 페어링(pairing)할 수 있다. 시선 추적 센서는 프로세서의 제어에 기초하여 사용자의 눈으로부터 반사된 반사 광을 감지할 수 있 다. 표시 장치는 시선 추적 센서를 통해서 감지된 반사 광을 전기 신호로 변환할 수 있다. 표시 장치는 변환된 전기 신호를 통해서 사용자의 안구 이미지를 획득할 수 있다. 표시 장치는 획득된 사용자의 안구 이 미지를 이용하여 사용자의 시선을 추적할 수 있다. 조도 센서는 프로세서의 제어에 기초하여 표시 장치 주변의 조도(또는 밝기), 표시 패널에서 방출된 디스플레이 광의 광량, 사용자의 눈 주위의 밝기 또는 사용자의 눈에 반사된 반사 광의 광량을 감지 할 수 있다. 조도 센서는 시선 추적 센서의 적어도 일부로 구성될 수 있다. 표시 장치는 조도 센서를 이용해 사용자 주변의 조도(또는 밝기)를 감지할 수 있다. 표시 장치는 감지 된 조도(또는 밝기)에 기초하여, 디스플레이(예: 표시 패널)의 광량(또는 밝기)을 조절할 수 있다. 시선 추적 도파관(예: 제2 도파관)은 사용자의 눈에서 반사된 반사 광이 센서 모듈로 입력되도 록 광을 유도함으로써 광의 경로를 형성할 수 있다. 시선 추적 도파관은 반사 광을 시선 추적 센서로 전달 하기 위해 이용될 수 있다. 시선 추적 도파관은 디스플레이 도파관과 동일한 요소 또는 상이한 요소 로 형성될 수 있다. 시선 추적 도파관은 글라스의 일부분에 배치될 수 있다. 예를 들어, 글라스의 중심점과 사용자 의 눈의 중심점이 일치되는 가상의 축 및 가상의 축과 글라스의 중심점에서 직교하는 가상의 선을 기 준으로, 시선 추적 도파관은 글라스의 하단에 배치될 수 있다. 시선 추적 도파관이 배치되는 영 역은 글라스의 상술한 영역에 제한되지 않을 수 있으며, 글라스의 영역 중 임의의 영역에 배치될 수 있다. 배터리는 표시 장치의 적어도 하나의 구성요소들에 전력을 공급할 수 있다. 배터리는 외부 전원 과 유선 또는 무선으로 연결되어 충전될 수 있다. 카메라는 표시 장치의 주변의 영상을 촬영할 수 있다. 예를 들어, 카메라는 사용자의 눈 이 미지를 촬영하거나 표시 장치 외부의 현실 객체 이미지를 촬영할 수 있다. 통신 모듈은 유선 인터페이스 또는 무선 인터페이스를 포함할 수 있다. 통신 모듈은 표시 장치와 외부 장치(예: 스마트폰, 또는 태블릿 PC)간의 직접 통신(예: 유선 통신) 또는 간접 통신(예: 무선 통신)의 수 행을 지원할 수 있다. 통신 모듈은 무선 통신 모듈(예: 셀룰러 통신 모듈, 근거리 무선 통신 모듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예: LAN(local area network) 통신 모듈, 또는 전력선 통 신 모듈)을 포함할 수 있다. 무선 통신 모듈은 4G 네트워크 이후의 5G 네트워크 및 차세대 통신 기술, 예를 들어, NR 접속 기술(new radio access technology)을 지원할 수 있다. NR 접속 기술은 고용량 데이터의 고속 전송(eMBB(enhanced mobile broadband)), 단말 전력 최소화와 다수 단말의 접속(mMTC(massive machine type communications)), 또는 고신 뢰도와 저지연(URLLC(ultra-reliable and low-latency communications))을 지원할 수 있다. 무선 통신 모듈 은, 예를 들어, 높은 데이터 전송률 달성을 위해, 고주파 대역(예: mmWave 대역)을 지원할 수 있다. 무선 통신 모듈은 근거리 무선 통신 모듈을 포함할 수 있다. 근거리 통신은 WiFi(wireless fidelity), 블루투스, 블루투스 저전력(BLE), 지그비(Zigbee), NFC(near field communication), 자력 시큐어 트랜스미션 (Magnetic Secure Transmission), 라디오 프리퀀시(RF), 또는 보디 에어리어 네트워크(BAN) 중 적어도 하나를 포함할 수 있다.도 5를 참조하면, 디스플레이 모듈은 디스플레이 광을 출력하는 표시 패널, 도파관(520, 530), 및 프 로젝션 렌즈(projection lens)를 포함한다. 프로젝션 렌즈는 표시 패널로부터 방출된 광을 도파관(520, 530)에 입력하도록 구성될 수 있다. 도 5 에서는 표시 패널에서 방출되는 광속 중 일부가 프로젝션 렌즈를 통해 도파관(520, 530)에 입력되는 것이 도시되어 있다. 도파관(520, 530)은 플레이트(plate)의 형태를 가질 수 있다. 도파관(520, 530)은 플레이트의 일부 영역에 DOE(diffraction optical elements)나 HOE(holographic optical elements) 등 회절 기능을 하는 그레이팅 (grating)을 포함할 수 있다. 도파관(520, 530)의 그레이팅(grating)의 주기와 깊이 또는 굴절률은 출력 영상 화각, 또는 플레이트 매질의 굴절률 등의 조건에 기반하여 다양하게 가변될 수 있다. 도파관(520, 530)은 표시 패널로부터 입력된 광 신호(즉, 디스플레이 광)의 일부를 도파관 내부로 전달하고, 광 신호의 다른 일부는 도파관(520, 530)의 외부로 출력되도록 광 신호를 분배할 수 있다. 도 5에서는 도파관(520, 530)의 예시로서 회절형 광학 소자를 설명하였으나, 도파관은 빔스플리터 (Beamsplitter)와 같은 반사형 광학 소자로 대체될 수 있다. 도 6은 일 실시예에 따른 표시 패널의 평면도이다. 도 7은 일 실시예에 따른 표시 패널의 발광 영역 을 도시한 단면도이다. 도 8은 일 실시예에 따른 표시 패널의 센서 픽셀(SS)을 도시한 단면도이다. 도 6을 참조하면, 일 실시예에 따른 표시 패널은 복수의 센서 픽셀(SS)들과 복수의 픽셀 그룹(P)들을 포함 할 수 있다. 복수의 센서 픽셀(SS)들은 표시 패널의 최외곽에서 표시 패널을 둘러싸도록 배치될 수 있다. 예를 들 어, 복수의 픽셀 그룹(P)들은 표시 패널의 안쪽에 배치되고, 복수의 센서 픽셀(SS)들에 의해 둘러싸이도록 배치될 수 있다. 복수의 센서 픽셀(SS)들은 표시 패널의 상측 경계부, 하측 경계부, 좌측 경계 부, 및 우측 경계부 각각에 인접하도록 배치될 수 있다. 복수의 픽셀 그룹(P)들은 표시 패널의 평면 상에서 매트릭스 형태로 배열될 수 있다. 예를 들어, 표시 패 널은 m*n 개의 픽셀 그룹(P)(예: 단위 픽셀)들을 포함할 수 있고, 이들의 외곽에는 복수의 센서 픽셀(SS) 들이 배치될 수 있다. 여기서, m, n 각각은 1보다 큰 정수일 수 있다. 본 문서에서 부호 \"*\"은 곱셈 부호를 의 미한다. 복수의 픽셀 그룹(P)들 각각은 i*i 개의 서브 영역들로 나뉘고, 서브 영역들에는 레드 픽셀(SR), 그린 픽셀 (SG), 블루 픽셀(SB)이 적어도 하나씩 배치될 수 있다. 여기서, i는 1보다 큰 정수일 수 있다. 예를 들어, 하나 의 픽셀 그룹(P)은 2*2 개의 서브 영역들을 포함하고, 각 서브 영역들에는 레드 픽셀(SR), 그린 픽셀(SG), 블루 픽셀(SB) 중 어느 하나가 배치될 수 있다. 이러한 도 6의 실시예는 모든 서브 영역들 각각에 레드 픽셀(SR), 그 린 픽셀(SG), 및 블루 픽셀(SB) 중 어느 하나와 포토 다이오드(PD)를 배치하는 비교예와 비교할 때, 센싱 성능 을 높이고 이미지의 선명도(Sharpness)가 향상될 수 있다. 즉, 비교예는 레드 픽셀(SR), 그린 픽셀(SG), 및 블 루 픽셀(SB) 각각의 일부분에 도트(dot) 형태의 포토 다이오드(PD)를 배치할 수 있으나, 이러한 비교예는 표시 패널을 구동할 때 화면에서 도트(dot) 형태의 얼룩이 감지될 수 있다. 반면에, 도 6의 실시예는 센서 픽셀 (SS)과 화상을 표시하기 위한 레드 픽셀(SR), 그린 픽셀(SG), 및 블루 픽셀(SB)을 별도로 배치함으로써, 센싱 성능을 높이면서도 도트(dot) 형태의 얼룩을 방지하여 이미지의 선명도(Sharpness)를 향상시킬 수 있다. 이와 같이, 표시 패널은 센서 픽셀(SS)을 포함하되, 센서 픽셀(SS)의 해상도는 레드 픽셀(SR), 그린 픽셀 (SG), 블루 픽셀(SB) 각각의 해상도보다 낮을 수 있다. 센서 픽셀(SS)의 해상도가 낮아지면 눈 추적 기능을 수 행할 때 정확도가 낮아질 수 있으나, 본 발명은 도 9 내지 도 14를 결부하여 설명하는 학습 알고리즘을 이용함 으로써 눈 추적 기능의 정확도를 높일 수 있다. 표시 패널에서 센서 픽셀(SS)의 해상도는 레드 픽셀(SR), 그린 픽셀(SG), 블루 픽셀(SB) 각각의 해상도보다 낮다는 것은 표시 패널에서 센서 픽셀(SS)의 개수 또는 배치 밀도가 레드 픽셀(SR), 그린 픽셀(SG), 블루 픽셀(SB) 각각의 개수 또는 배치 밀도보다 작다는 것을 의미 한다. 도 6에서는 하나의 픽셀 그룹(P)이, 하나의 레드 픽셀(SR), 하나의 그린 픽셀(SG), 2개의 블루 픽셀(SB)을 포함 하는 것을 예시하고 있으나, 각 픽셀 그룹(P)에 포함된 픽셀들의 배열 형태는 다양하게 변경 및 설계될 수 있다. 레드 픽셀(SR)은 레드 컬러 필터(CF1)를 포함하고, 레드 컬러 필터(CF1)가 레드 광을 투과함에 따라 레드 광을 방출하도록 구성된다. 다른 실시예에 따르면, 레드 픽셀(SR)은 발광층(EL)이 직접적으로 레드 광을 방출하도록 구성될 수 있고, 이 경우 레드 컬러 필터(CF1)는 생략될 수 있다. 그린 픽셀(SG)은 그린 컬러 필터(CF2)를 포함하고, 그린 컬러 필터(CF2)가 그린 광을 투과하는 것에 의해 그린 광을 방출하도록 구성된다. 다른 실시예에 따르면, 그린 픽셀(SG)은 발광층(EL)이 직접적으로 그린 광을 방출하 도록 구성될 수 있고, 이 경우 그린 컬러 필터(CF2)는 생략될 수 있다. 블루 픽셀(SB)은 블루 컬러 필터(CF3)를 포함하고, 블루 컬러 필터(CF3)가 블루 광을 투과하는 것에 의해 블루 광을 방출하도록 구성된다. 다른 실시예에 따르면, 블루 픽셀(SB)은 발광층(EL)이 직접적으로 블루 광을 방출하 도록 구성될 수 있고, 이 경우 블루 컬러 필터(CF3)는 생략될 수 있다. 센서 픽셀(SS)은 포토 다이오드(PD)를 포함하고, 사용자의 눈으로부터 반사된 반사 광을 감지할 수 있다. 포토 다이오드(PD)는 감지된 반사 광을 전기 신호로 변환하고, 변환된 전기 신호를 센서 모듈에 공급할 수 있다. 도 7을 참조하면, 표시 패널은 반도체 웨이퍼 기판, 반도체 웨이퍼 기판 상에 배치된 OLED, OLED 상에 배치된 컬러 필터(CF1, CF2, CF3)를 포함할 수 있다. OLED와 컬러 필터(CF1, CF2, CF3) 사이에는 OLED의 발광층(EL)을 덮는 봉지층(TFE)이 배치될 수 있다. 컬러 필터(CF1, CF2, CF3) 상에는 커버 윈도우(CO V)가 배치될 수 있다. 커버 윈도우(COV)는 OCA(optically clear adhesive) 필름과 같은 투명 접착 부재(미도시)에 의해 컬러 필터(CF1, CF2, CF3) 상에 부착될 수 있다. 반도체 웨이퍼 기판은 베이스 기판 및 베이스 기판 상에 배치된 트랜지스터(TR)를 포함할 수 있 다. 베이스 기판은 실리콘 기판일 수 있다. 베이스 기판은 실리콘 기판 상에 반도체 패턴이 형성된 것일 수 있다. 예를 들어, 베이스 기판은 CMOS(Complementary Metal Oxide Semiconductor) 공정을 통해 형성된 실리콘 반도체 기판일 수 있다. 베이스 기판은 단결정 실리콘 웨이퍼, 다결정 실리콘 웨이퍼, 및/또는 비 정질 실리콘 웨이퍼 중 어느 하나를 포함할 수 있다. 베이스 기판 상에 배치된 트랜지스터(TR)는 게이트 전극(GE), 소스 전극(SE), 및 드레인 전극(DE)을 포함 할 수 있다. 트랜지스터(TR)는 복수의 픽셀 그룹(P)들 각각에 포함된 레드 픽셀(SR), 그린 픽셀(SG), 및 블루 픽셀(SB)을 독립적으로 제어하도록 구성될 수 있다. 베이스 기판 상에는 트랜지스터(TR)와 전기적으로 연 결되는 연결 전극(CM), 도전 배선(미도시)들 및 도전 패드(미도시)들이 더 배치될 수 있다. 연결 전극(CM), 도 전 배선들 및 도전 패드들은 전도성 물질, 예를 들어, 금속 물질을 포함할 수 있다. 도 8을 참조하면, 센서 픽셀(SS)은 포토 다이오드(PD)를 포함할 수 있다. 포토 다이오드(PD)는 사용자의 눈 으로부터 반사된 반사 광을 감지하고, 감지된 반사 광을 전기 신호로 변환할 수 있다. 포토 다이오드(PD) 는 전기 신호의 출력을 제어하는 게이트 전극(GE) 및 전기 신호를 리드 아웃 배선(RL)으로 출력하는 드레인 전 극(DE)을 포함할 수 있다. 포토 다이오드(PD)는 게이트 전극(GE)에 입력된 제어 신호에 응답하여, 감지된 반사 광에 대응하는 전기 신호를 드레인 전극(DE)을 통해 출력할 수 있다. 포토 다이오드(PD)의 전기 신호는 리드 아 웃 배선(RL)을 통해 표시 패널 외부의 프로세서에게 전달될 수 있다. 반도체 웨이퍼 기판 상에는 제1 전극(E1), 발광층(EL), 및 제2 전극(E2)을 포함하는 OLED가 배치될 수 있 다. 제1 전극(E1)들은 반도체 웨이퍼 기판의 연결 전극(CM) 및 그에 연결된 적어도 하나의 콘택홀을 통해 트랜 지스터(TR)와 전기적으로 연결될 수 있다. 제1 전극(E1)들은 레드 픽셀(SR), 그린 픽셀(SG), 및 블루 픽셀(SB) 을 각각의 발광층(EL)을 구동하기 위한 애노드(anode) 전극들일 수 있다. 제1 전극(E1)들은 반사형 전극일 수 있다. 예를 들어, 제1 전극(E1)들은 발광층(EL)으로부터 아래 방향으로 방출된 빛을 반사할 수 있다. 제1 전극 (E1)들은 광 반사율이 높은 금속 물질을 포함할 수 있다. 예를 들어, 제1 전극(E1)들은 Al, Al/Cu, Al/TiN 중 어느 하나를 포함할 수 있다. 도 8에 도시된 바와 같이, 제1 전극(E1)들은 센서 픽셀(SS)에 형성되지 않을 수 있다. 즉, 센서 픽셀(SS)은 제1 전극(E1)들을 포함하지 않을 수 있다. 발광층(EL)은 제1 전극(E1)들 상에 배치될 수 있다. 발광층(EL)은 단일층 또는 복수의 적층 구조를 포함할 수 있다. 발광층(EL)은 백색광을 방출하도록 구성될 수 있다. 백색광은 일 예로 청색광, 녹색광, 및 적색광이 혼합 된 빛일 수 있다. 또는, 백색광은 청색광 및 황색광이 혼합된 빛일 수 있다. 도 8에 도시된 바와 같이, 발광층 (EL)은 센서 픽셀(SS)에 형성되지 않을 수 있다. 즉, 센서 픽셀(SS)은 발광층(EL)을 포함하지 않을 수 있다.제2 전극(E2)은 발광층(EL) 상에 배치될 수 있다. 제2 전극(E2)은 공통 전극으로서, 예를 들면, 캐소드 (cathode) 전극일 수 있다. 제2 전극(E2)은 투과형 또는 반투과형 전극일 수 있다. 예를 들어, 제2 전극(E2)은 발광층(EL)으로부터 방출된 빛을 투과시킬 수 있다. 제2 전극(E2)은 전도성 물질을 포함할 수 있다. 예를 들어, 제2 전극(E2)은 일함수가 낮은 Li, Ca, LiF/Ca, LiF/Al, Al, Mg, BaF, Ba, Ag, Au, Cu 또는 이들의 화합물이나 혼합물을 포함할 수 있다. 도 8에 도시된 바와 같이, 제2 전극(E2)은 센서 픽셀(SS)에 형성되지 않을 수 있다. 즉, 센서 픽셀(SS)은 제2 전극(E2)을 포함하지 않을 수 있다. OLED 상에는 봉지층(Thin-film encapsulation layer)(TFE)이 배치될 수 있다. 봉지층(TFE)은 발광층(EL)에 산 소 또는 수분이 침투하는 것을 방지하기 위해 발광층(EL)을 봉지하도록 구성될 수 있다. 봉지층(TFE)은 발광층 (EL)의 상면과 측면들 상에 배치될 수 있다. 봉지층(TFE)은 발광층(EL)에 산소 또는 수분이 침투되는 것을 방지 하기 위해 적어도 하나의 무기막을 포함할 수 있다. 또한, 봉지층(TFE)은 먼지와 같은 이물질로부터 발광층(E L)을 보호하기 위하여 적어도 하나의 유기막을 포함할 수 있다. 봉지층(TFE)의 무기막은 실리콘 나이트라이드층, 실리콘 옥시 나이트라이드층, 실리콘 옥사이드층, 티타늄옥사이드층, 및 알루미늄옥사이드층 중 하나 이상의 무기막이 교번하여 적층된 다중막으로 형성될 수 있다. 봉지층(TFE)의 유기막은 아크릴 수지 (acryl resin), 에폭시 수지(epoxy resin), 페놀 수지(phenolic resin), 폴리아미드 수지(polyamide resin), 폴리이미드 수지(polyimide resin) 등의 유기막일 수 있다. 봉지층(TFE) 상에는 컬러 필터(CF1, CF2, CF3)가 배치될 수 있다. 컬러 필터(CF1, CF2, CF3)는 레드 광을 투과 시키는 레드 컬러 필터(CF1)(예: 제1 컬러 필터), 그린 광을 투과시키는 그린 컬러 필터(CF2)(예: 제2 컬러 필 터), 및 블루 광을 투과시키는 블루 컬러 필터(CF3)(예: 제3 컬러 필터)를 포함할 수 있다. 레드 컬러 필터 (CF1)는 레드 픽셀(SR)에 대응하도록 배치되어, 레드 픽셀(SR)의 발광층(EL)으로부터 방출된 백색 광 중에서 레 드 광을 투과시킬 수 있다. 그린 컬러 필터(CF2)는 그린 픽셀(SG)에 대응하도록 배치되어, 그린 픽셀(SG)의 발 광층(EL)으로부터 방출된 백색 광 중에서 그린 광을 투과시킬 수 있다. 블루 컬러 필터(CF3)는 블루 픽셀(SB)에 대응하도록 배치되어, 블루 픽셀(SB)의 발광층(EL)으로부터 방출된 백색 광 중에서 블루 광을 투과시킬 수 있다. 도 8에 도시된 바와 같이, 컬러 필터(CF1, CF2, CF3)는 센서 픽셀(SS)에 형성되지 않을 수 있다. 즉, 센 서 픽셀(SS)은 컬러 필터(CF1, CF2, CF3)를 포함하지 않을 수 있다. 도 9는 일 실시예에 따른 표시 장치의 동작을 설명한 흐름도이다. 도 10a 내지 도 10d는 Haar-like feature 에 이용되는 프로토타입의 예시이다. 도 11a 내지 도 11h는 Haar-like feature에 이용되는 프로토타입의 다른 예시이다. 도 12a 내지 도 12d는 Haar-like feature에 이용되는 프로토타입의 다른 예시이다. 도 13은 센서 픽 셀(SS)을 통해 획득되는 이미지 데이터의 예시이다. 도 14는 일 실시예에 따른 표시 장치에 의해 식별된 눈 영역을 나타낸 예시이다. 도 15는 일 실시예에 따른 표시 장치에 의해 수행되는 포비티드 렌더링 (foveated rendering)을 설명하기 위한 개념도이다. 도 9에 도시된 동작들은 표시 장치의 프로세서에 의해 수행될 수 있다. 예를 들어, 프로세서는 메모리에 저장된 인공지능 어플리케이션의 실행에 기반하여 표시 장치가 도 9에 도시된 동작들을 수행하도록 제어할 수 있다. 도 9에 도시된 동작들 중에서 적어도 일부는 생략될 수 있다. 도 9에 도시된 적어 도 일부 동작들의 이전 또는 이후에는 본 개시에서 다른 도면을 참조하여 언급한 적어도 일부 동작들이 추가 삽 입 될 수 있다. 이하, 도 9 및 도 10a 내지 도 15를 참조하여 일 실시예에 따른 표시 장치의 동작을 설명한다. 동작 910에서, 일 실시예에 따른 표시 장치는, 눈 추적 기능을 수행하기 위하여 근적외선 광을 방출할 수 있다. 표시 장치는 눈 추적 기능을 이용해 사용자의 눈의 움직임을 추적한다. 표시 장치는 인공지능 어플리케이션의 학습 알고리즘을 이용해 눈 추적 기능을 수행한다. 이를 위해, 표시 장치의 광원부(도 5의 550)는 출력 파장 약 780 nm 내지 약 1400 nm의 근적외선 광을 사용자의 눈에 조사하도록 구성될 수 있다. 동작 920에서, 일 실시예에 따른 표시 장치는, 사용자의 눈에 의해 반사된 반사광을 표시 패널의 센서 픽셀 (SS)을 통해 입력받을 수 있다. 광원부로부터 방출된 근적외선 광은 사용자의 눈에서 반사되고, 반사된 근적외선 광(이하, \"반사광\")은 표시 패널로 입력될 수 있다. 표시 장치는 센서 픽셀(SS)을 이 용해 사용자의 눈 주위의 밝기 또는 사용자의 눈에 반사된 반사광의 광량을 감지할 수 있다. 표시 장 치는 센서 픽셀(SS)을 통해 감지된 광을 전기 신호로 변환할 수 있다. 표시 장치는 변환된 전기 신호에 기반하여 사용자의 안구 및 사용자의 안구 주변에 대응하는 이미지 데이터(도 13의 1300)를 획득할 수 있다.동작 930에서, 일 실시예에 따른 표시 장치는, 센서 픽셀(SS)을 통해 입력된 정보를 데이터화하여 이미지 데이터를 생성할 수 있다. 표시 장치는 입력된 정보를 데이터화함으로써 이미지 데이터를 생성 하고, 학습 알고리즘에 적용하기 위한 변수를 설정한다. 예를 들어, 표시 장치는 입력된 데이터를 전처리하 고, 전처리된 데이터에 기반하여 이미지 데이터를 생성한다. 표시 장치는 학습 알고리즘을 사용하여 눈 영역 식별 및 눈동자 추적을 포함한 눈 추적을 수행할 수 있다. 표시 장치는 학습 알고리즘에 적용하기 위한 변수로서, 이미지 데이터, 이미지 데이터의 공간 좌표, 공간 좌표에 매핑되는 이미지 데이터의 영역별 광 세기 값을 설정할 수 있다. 표시 장치는 이미지 데이터의 각 영역별로 공간 좌표를 설정한다. 예를 들어, 표시 장치는 이미 지 데이터에 대한 x 축 좌표, y 축 좌표, 및/또는 z 축 좌표를 설정할 수 있다. 여기서 이미지 데이터 의 각 영역별로 공간 좌표를 설정한다는 것은, 이미지 데이터의 복수의 영역들과 x 축 좌표, y 축 좌표, 및/또는 z 축 좌표를 포함하는 공간 좌표를 연관짓는 것을 의미할 수 있다. 표시 장치는 이미지 데이터의 영역별 공간 좌표와 해당 영역에서의 광 세기(예: 도 14의 1401, 140 2)를 매핑할 수 있다. 여기서, 광 세기가 크다는 것은, 입력된 반사광의 세기가 크다는 것을 의미한다. 예를 들 어, 표시 장치는 이미지 데이터의 각 영역별로 광 세기를 나타내는 광 세기 값을 매핑할 수 있다. 동작 940에서, 일 실시예에 따른 표시 장치는, 학습 알고리즘을 이용하여 이미지 데이터와 유사한 눈 특징 모델들을 생성할 수 있다. 표시 장치는 설정된 변수를 학습 알고리즘에 대입하고, 학습 알고리즘이 이 미지 데이터와 유사한 눈 특징 모델들을 생성하도록 학습시킬 수 있다. 표시 장치는 학습 알고리즘을 이용하여 이미지 데이터와 유사한 눈 특징 모델을 생성하는 동작은, 눈 영역(도 14의 1320)을 검출하는 동작, 눈동자 영역을 검출하는 동작, 및 눈동자 중심(도 14의 1411)을 추 출하는 동작을 포함할 수 있다. 표시 장치는 학습 알고리즘에 변수를 입력하고, 이때 입력되는 변수는 이미지 데이터, 이미지 데이터 의 공간 좌표, 공간 좌표에 매핑되는 이미지 데이터의 영역별 광 세기 값을 포함한다. 학습 알고리 즘은 입력된 변수에 기반하여 눈 검출, 및 눈 특징점 검출, 및 눈 형태의 정규화 과정을 반복적으로 수행함으로 써 눈 특징 모델들을 생성할 수 있다. 학습 알고리즘은 Haar-like feature를 이용하여 눈 특징을 추출(또는 분류)한다. 눈 특징은, 눈의 크기, 눈 형 태, 및 눈 특징점을 의미한다. 여기서, 눈 특징점은, 눈의 윤곽선으로 추정되는 점들의 조합을 의미할 수 있다. Haar-like feature 는 지정된 프로토타입(prototype)의 단순합과 인식 영역을 비교하면서, 인식 영역과 가장 유 사한 특징 값을 산출하는 방법이다. 여기서, 인식 영역은 이미지 데이터의 적어도 일부분인 부분 영역을 의미한다. 도 10a 내지 도 12d는 Haar-like feature에 이용되는 프로토타입의 예시들을 도시한다. 학습 알고리즘은 이미지 데이터의 부분 영역인 인식 영역과 도 10a 내지 도 12d에 도시된 바와 같은 지정된 프로토타입 (prototype)의 단순합을 비교하고, 인식 영역과 지정된 프로토타입의 단순합 간의 유사도를 연산할 수 있다. 학 습 알고리즘은 상기 유사도가 지정된 임계값 이상으로 높은 프로토타입의 조합들을 추출(또는 분류)할 수 있다. 예를 들어, 학습 알고리즘은 지정된 프로토타입의 단순합을 반복적으로 변경해가면서 입력된 이미지 데이터 와 가장 유사한 눈 특징 모델을 선택할 수 있다. 도 10a 내지 도 12d에 도시된 프로토타입에 대해서는 도 9의 동작들을 모두 설명한 이후에 구체적으로 후술하기로 한다. 학습 알고리즘은 Haar-like feature 연산을 이용해 추출된 눈 특징 모델을 Boost 알고리즘(또는 AdaBoost 알고 리즘)을 이용해 학습한다. 예를 들어, AdaBoost(adaptive boost) 알고리즘이 이용될 수 있으며, 이는 Boost 알 고리즘 중에서도 가장 단순하면서도 효율적인 알고리즘인 것으로 알려져 있다. AdaBoost 알고리즘은 초기 모형 을 약한 모형(weak learner)으로 설정하고, 학습이 반복될수록 이전 모형의 약점을 보완하는 새로운 모형을 도 출하는 방식으로 최종적인 눈 특징 모델을 생성시킨다. 학습 알고리즘은 생성되는 눈 특징 모델들을 그룹화하여 성능을 높일 수 있다. 예를 들어, 학습 알고리즘은 인 식되는 눈 특징 모델들을 복수의 그룹들로 나누고, 복수의 그룹별로 눈 특징, 즉 눈의 크기, 눈 형태, 및 눈 특 징점을 정규화할 수 있다. 이때, 학습 알고리즘은 인식 영역의 면적을 점진적으로 줄이면서 AdaBoost 알고리즘 을 적용하고, 이에 따라 이미지 데이터로부터 눈 영역 및 눈동자 영역을 검출할 수 있다. 도 13을 참조하면, 눈 영역은 사용자의 얼굴의 적어도 일부분을 포함하는 이미지 데이터에서 눈이 위치한 일부 영역을 의미한다. 예를 들어, 학습 알고리즘은 사용자의 얼굴의 적어도 일부분을 포함 하는 이미지 데이터에서 눈 영역과 눈 영역을 제외한 얼굴 영역을 구분하는 학습을 수행할 수 있다. 눈 영역은, 사용자의 얼굴에서 눈과 그의 주변을 포함한 일부 영역을 의미할 수 있다. 도 14를 참조하면, 눈동자 영역은 눈 영역에서 눈동자가 위치한 영역을 의미한다. 표시 장치는 눈 영역에 대응하는 이미지 데이터의 일부분에서 눈동자(즉, 동공)와 흰자위막(즉, 공막)(도 14의 1420)을 포함하는 눈동자를 구분하는 학습을 수행할 수 있다. 일 실시예에 따르면, 학습 알고리즘은 눈 영역 및 눈동자 영역이 검출되면 눈동자 중심을 식 별할 수 있다. 도 14에 도시된 바와 같이, 학습 알고리즘은 Haar-like feature를 통해 얻어낸 눈 영역 중 에서 절반의 영역을 이용해 눈동자 중심을 식별할 수 있다. 학습 알고리즘은 Haar-like feature를 통해 얻어낸 눈 영역 중에서 상측에 위치하고 50% 비율의 면적을 갖는 상측 영역을 이용해 눈동자 중심 을 식별할 수 있다. 학습 알고리즘은 상측 영역에서 영역별로 매핑된 광 세기 값을 분석하고, 광 세기 값이 가장 큰 지점을 눈동자 중심으로 결정할 수 있다. 일 실시예에 따르면, 학습 알고리즘은 Haar-like feature를 통해 얻어낸 눈 영역 중에서 좌측에 위치하고 50% 비율의 면적을 갖는 좌측 영역을 이용해 눈동자 중심을 식별할 수 있다. 학습 알고리즘은 좌측 영역 에서 영역별로 매핑된 광 세기 값을 분석하고, 광 세기 값이 가장 큰 지점을 눈동자 중심으 로 결정할 수 있다. 상기 예시에서 표시 장치가 상측 영역 또는 좌측 영역을 이용해 눈동자 중심을 식별하는 것은 하나의 예시일 뿐, 본 발명은 이에 국한되지 않는다. 예를 들어, 본 발명은 눈 영역 중에서 하측에 위치 하고 50% 비율의 면적을 갖는 하측 영역을 이용해 눈동자 중심을 식별하거나, 또는 눈 영역 중에서 우측에 위치하고 50% 비율의 면적을 갖는 우측 영역을 이용해 눈동자 중심을 식별할 수 있다. 일 실시예에 따르면, 본 발명은 눈 영역의 대칭성을 이용해 눈동자 중심을 식별할 수 있다. 예를 들어, 눈 영역에서 감지되는 광 세기는 눈동자 중심을 기준으로 대칭성을 가질 수 있다. 학습 알고 리즘은 이러한 대칭성을 이용하여 눈동자 중심을 추정할 수 있다. 예를 들어, 학습 알고리즘은 눈 영역 의 광 세기의 분포를 산출하고, 눈 영역의 광 세기의 분포가 특정 영역을 중심으로 대칭성을 갖는 경우 상기 특정 영역을 눈동자 중심인 것으로 결정할 수 있다. 동작 950에서, 일 실시예에 따른 표시 장치는, 눈 추적 기능을 수행한 시점으로부터 지정된 시간이 경과되 었는지 결정할 수 있다. 표시 장치는 눈 추적 기능을 수행한 시점으로부터 지정된 시간이 경과되면(예: 동 작 950의 결과가 \"예\") 동작 960을 수행하고, 눈 추적 기능을 수행한 시점으로부터 지정된 시간이 경과되지 않 으면(예: 동작 950의 결과가 \"아니오\") 동작 910 내지 동작 940을 다시 수행하여 눈 특징 모델들을 생성할 수 있다. 지정된 시간은, 예를 들어, 약 50 ms 내지 약 100 ms 이내의 시간으로 설정될 수 있다. 동작 960에서, 일 실시예에 따른 표시 장치는, 생성된 눈 특징 모델들 중에서 이미지 데이터의 눈 영 역과 가장 유사한 눈 특징 모델을 결정할 수 있다. Haar-like feature 및 Boost 알고리즘을 이용한 눈 특징 모델의 정확성은 연산의 반복 횟수가 증가하고 연산을 수행하는 시간이 경과할수록 높아질 수 있다. 그러나, 사용자에게 고품질의 포비티드 렌더링(foveated rendering) 영상을 제공하기 위해서는 눈 추적을 수행하는 시간이 제한적이다. 예를 들어, 표시 장치는 동 적으로 포비티드 렌더링을 수행하기 위하여 눈 추적 기능을 약 50 ms 또는 약 100 ms 이내에 완료하는 것이 필 요할 수 있다. 따라서, 표시 장치는 지정된 제한 시간 동안 눈 특징 모델들을 생성하고, 지정된 제한 시간 동안 생성된 눈 특징 모델들 중에서 최적의 눈 특징 모델을 선택할 수 있다. 여기서, 최적의 눈 특징 모델은 이 미지 데이터의 눈 영역과 가장 유사하게 학습된 눈 특징 모델을 의미할 수 있다. 이를 위해, 표시 장치는 눈 추적 기능을 수행한 시점, 예컨대 동작 910에서 근적외선 광을 처음으로 방출한 시점으로부 터 지정된 시간이 경과하면, 생성된 눈 특징 모델들 중에서 이미지 데이터의 눈 영역과 가장 유사 하게 학습된 눈 특징 모델을 선택할 수 있다. 표시 장치는 생성된 눈 특징 모델들과 이미지 데이터의 눈 영역을 비교하고, 그들 간의 유사성 을 나타내는 스코어를 산출할 수 있다. 예컨대, 상기 스코어가 높을수록 해당 눈 특징 모델과 이미지 데이터 의 눈 영역 간의 유사성이 높을 수 있다. 표시 장치는 상기 스코어가 가장 높은 눈 특징 모델 을 결정할 수 있다. 동작 970에서, 일 실시예에 따른 표시 장치는, 결정된 눈 특징 모델에 기반하여, 눈동자 중심의 움직 임을 추적할 수 있다. 표시 장치는 결정된 눈 특징 모델에서 눈동자 중심에 대응하는 공간 좌표를 결 정할 수 있다. 표시 장치는 눈동자의 움직임을 동적으로 감지하고, 결정된 눈 특징 모델에 기반하여 눈동자 의 움직임에 대응하는 공간 좌표의 변화를 감지할 수 있다. 학습 알고리즘은, 눈동자 중심의 움직임을 추적함에 있어서, 밀집 Optical flow 기법인 Pyramid Lucas- Kanade Optical flow 알고리즘을 이용할 수 있다. Pyramid Lucas-Kanade Optical flow는 원본 영상으로부터 영 상 피라미드를 구성하고, 상위 계층에서부터 시작하여 하위 계층으로 추적을 실행하는 방법이다. 그러나, 본 발 명은 이에 제한되지 않으며, 희소 Optical flow 기법을 이용하여 눈동자 중심의 움직임을 추적할 수 있다. 동작 980에서, 일 실시예에 따른 표시 장치는, 추적된 눈동자 중심의 공간 좌표를 이용하여 포비티드 렌더링(foveated rendering)을 수행할 수 있다. 표시 장치는, 추적된 눈동자 중심의 공간 좌표를 이 용하여 표시 화면의 적어도 일부분의 해상도를 조정할 수 있다. 표시 장치는 눈동자 중심의 공간 좌표를 이용하여 사용자의 시선 방향에 대응하는 시선 벡터를 결정 하고, 시선에 대응하는 중심시 영역과 중심시 영역을 제외한 주변시 영역을 결정한다. 표시 장치는 중심시 영역에 고해상도의 화면을 표시하고, 주변시 영역에 저해상도의 화면을 표시하는 포비티드 렌더링(foveated rendering) 기술을 적용할 수 있다. 예를 들어, 도 15는 표시 장치가 제공하는 VR 화면(또는 AR 화 면)의 예시를 도시하고 있다. 사용자는 표시 장치가 제공하는 VR 화면 중에서 일부분을 응시할 수 있고, 표시 장치는 이를 감지하기 위하여 동작 910 내지 동작 980을 수행할 수 있다. 표시 장치는 눈동자 중심의 공간 좌표를 이용하여 사용자의 시선 방향에 대응하는 시선 벡터를 결정하고, 시선 벡터에 대응하는 중심시 영역과 중심시 영역을 제외한 주변시 영역을 결정한다. 표시 장치는 중심시 영역에 고해상도의 화면을 표시하고, 주변시 영역에 저해상도 화면을 표시할 수 있다. 만약, 사용자가 시선을 움직인 경우, 표시 장치는 눈동자 중심의 이동을 동적으로 감지함으로써 중심 시 영역의 이동을 결정할 수 있다. 예를 들어, 중심시 영역이 도 15의 1511 영역으로부터 1512 영역으로 이동한 경우, 표시 장치는 이동된 1512 영역을 중심으로 해상도를 조정할 수 있다. 이하, 도 10a 내지 도 12d는 Haar-like feature에 이용되는 프로토타입의 다양한 실시예들을 설명하기로 한다. 도 10a 내지 도 10d를 참조하면, Haar-like feature에 이용되는 프로토타입은, 하나의 화이트 영역 및 하 나의 블랙 영역을 포함하고, 그들이 서로 나란하게 배치되는 edge features 를 포함할 수 있다. 도시된 바와 같이, edge features 형태에 따른 프로토타입은 하나의 화이트 영역 및 하나의 블랙 영역을 포함하고, 화이트 영역 및 블랙 영역의 면적은 동일할 수 있다. 화이트 영역은 이미지 데이 터의 일부분에서 흰자위막(즉, 공막)을 추정하는데 이용될 수 있다. 블랙 영역은 이미지 데이터 의 일부분에서 눈동자(즉, 동공)를 추정하는데 이용될 수 있다. 도 10a는 edge features의 프로토타입 중에서도 화이트 영역 및 블랙 영역이 좌우측 각각에 배치되 는 형태를 예시적으로 나타내고 있다. 이 경우, 화이트 영역이 블랙 영역의 좌측에 배치될 수 있으 나, 본 발명은 이에 국한되지 않는다. 도 10b는 edge features의 프로토타입 중에서도 화이트 영역 및 블랙 영역이 상하측 각각에 배치되 는 형태를 예시적으로 나타내고 있다. 이 경우, 화이트 영역이 블랙 영역의 상측에 배치될 수 있으 나, 본 발명은 이에 국한되지 않는다. 도 10c 및 도 10d는 edge features의 프로토타입 중에서도 화이트 영역 및 블랙 영역이 대각선 방 향으로 배열되는 형태를 예시적으로 나타내고 있다. 도 11a 내지 도 11h를 참조하면, Haar-like feature에 이용되는 프로토타입은, 한쌍의 화이트 영역 및 한 쌍의 화이트 영역 사이에 배치되는 블랙 영역을 포함하는 line features 를 포함할 수 있다. 도시 된 바와 같이, line features 형태에 따른 프로토타입은 한쌍의 화이트 영역 및 하나의 블랙 영역 을 포함한다. 이때, 화이트 영역 및 블랙 영역 각각의 폭과 길이를 상이할 수 있다. 화이트 영역 은 이미지 데이터의 일부분에서 흰자위막(즉, 공막)을 추정하는데 이용될 수 있다. 블랙 영역 은 이미지 데이터의 일부분에서 눈동자(즉, 동공)를 추정하는데 이용될 수 있다. 도 11a 및 도 11b는 line features의 프로토타입 중에서도 화이트 영역이 블랙 영역의 좌우측 각각 에 배치되는 형태를 예시적으로 나타내고 있다. 이 경우, 블랙 영역의 폭은 화이트 영역의 폭보다클 수 있으나, 본 발명은 이에 국한되지 않는다. 도 11c 및 도 11d는 line features의 프로토타입 중에서도 화이트 영역이 블랙 영역의 상하측 각각 에 배치되는 형태를 예시적으로 나타내고 있다. 이 경우, 블랙 영역의 폭은 화이트 영역의 폭보다 클 수 있으나, 본 발명은 이에 국한되지 않는다. 도 11e 및 도 11h는 line features의 프로토타입 중에서도 화이트 영역 및 블랙 영역이 대각선 방 향으로 배치되는 형태를 예시적으로 나타내고 있다. 예를 들어, 화이트 영역 및 블랙 영역은 가상 의 가로 선으로부터 지정된 각도를 갖도록 연장될 수 있다. 이 경우, 블랙 영역의 폭은 화이트 영역 의 폭보다 클 수 있으나, 본 발명은 이에 국한되지 않는다. 도 12a 내지 도 12d를 참조하면, Haar-like feature에 이용되는 프로토타입은, 하나의 블랙 영역 및 상기 하나의 블랙 영역의 외곽을 둘러싸도록 배치되는 화이트 영역을 포함하는 center-surround features 를 포함할 수 있다. 도시된 바와 같이, center-surround features 형태에 따른 프로토타입은 한쌍의 화이트 영역 및 하나의 블랙 영역을 포함한다. 이때, 화이트 영역 및 블랙 영역 각각 의 폭과 길이를 상이할 수 있다. 화이트 영역은 이미지 데이터의 일부분에서 흰자위막(즉, 공막)을 추정하는데 이용될 수 있다. 블랙 영역은 이미지 데이터의 일부분에서 눈동자(즉, 동공)를 추정하 는데 이용될 수 있다. 도 12a 및 도 12b는 center-surround features의 프로토타입 중에서도 화이트 영역이 블랙 영역 각각이 사각형인 형태를 예시적으로 나타내고 있다. 이 경우, 블랙 영역의 폭은 화이트 영역의 폭 보다 클 수 있으나, 본 발명은 이에 국한되지 않는다. 도 12c 및 도 12d는 center-surround features의 프로토타입 중에서도 화이트 영역이 블랙 영역 각각이 사각형 또는 원형인 형태를 예시적으로 나타내고 있다. 예를 들어, 도 12c에 도시된 바와 같이, 블랙 영 역은 사각형 형태를 갖고, 그의 외곽에는 원형인 화이트 영역이 배치될 수 있다. 예를 들어, 도 12d에 도시된 바와 같이, 블랙 영역은 원형의 형태를 갖고, 그의 외곽에는 원형인 화이트 영역이 배치될 수 있다."}
{"patent_id": "10-2023-0039715", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명의 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정 적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2023-0039715", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 표시 장치를 포함하는 웨어러블 장치의 전면을 도시한다. 도 2는 도 1에 도시된 웨어러블 장치의 후면을 도시한다. 도 3은 일 실시예에 따른 표시 장치를 포함하는 웨어러블 장치의 다른 예를 도시한다. 도 4는 일 실시예에 따른 표시 장치의 구성 블록도이다. 도 5는 일 실시예에 따른 디스플레이 모듈의 구성도이다. 도 6은 일 실시예에 따른 표시 패널의 평면도이다. 도 7은 일 실시예에 따른 표시 패널의 발광 영역을 도시한 단면도이다. 도 8은 일 실시예에 따른 표시 패널의 센서 영역을 도시한 단면도이다. 도 9는 일 실시예에 따른 표시 장치의 동작을 설명한 흐름도이다. 도 10a 내지 도 10d는 Haar-like feature에 이용되는 프로토타입의 예시이다. 도 11a 내지 도 11h는 Haar-like feature에 이용되는 프로토타입의 다른 예시이다. 도 12a 내지 도 12d는 Haar-like feature에 이용되는 프로토타입의 다른 예시이다. 도 13은 센서 픽셀을 통해 획득되는 이미지 데이터의 예시이다. 도 14는 일 실시예에 따른 표시 장치에 의해 식별된 눈 영역을 나타낸 예시이다. 도 15는 일 실시예에 따른 표시 장치에 의해 수행되는 포비티드 렌더링(foveated rendering)을 설명하기 위한 개념도이다."}
