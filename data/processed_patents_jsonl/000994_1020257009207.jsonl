{"patent_id": "10-2025-7009207", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0055558", "출원번호": "10-2025-7009207", "발명의 명칭": "모델 트레이닝 방법 및 장치, 전자 디바이스, 컴퓨터가 판독 가능한 매체 그리고 컴퓨터 프로", "출원인": "텐센트 테크놀로지", "발명자": "정 지아웨이"}}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 디바이스에 의해 수행되는 모델 트레이닝 방법으로서,데이터 세트를 획득하는 단계 - 상기 데이터 세트는 제1 도메인 데이터와 제2 도메인 데이터를 포함하고, 상기제1 도메인 데이터는 적어도 하나의 객체와 제1 도메인에서 각 객체가 관심 있는 제1 리소스 데이터를포함하며, 상기 제2 도메인 데이터는 상기 적어도 하나의 객체와 제2 도메인에서 각 객체가 관심 있는 제2 리소스 데이터를 포함함 -;관심 정렬 모델을 호출하여 상기 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현을 획득하고, 상기 관심 정렬 모델을 호출하여 상기 제2 도메인 데이터에 대한 특징 추출을 수행하여 제2 도메인 특징표현을 획득하는 단계;상기 관심 정렬 모델을 호출하여, 상기 제1 도메인 특징 표현과 상기 제2 도메인 특징 표현을 기반으로 상기 제1 도메인과 상기 제2 도메인 간의 관심 정렬 처리를 수행하는 처리를 수행하는 단계; 및제1 손실과 제2 손실이 감소하는 방향에 따라 상기 관심 정렬 모델을 트레이닝하여 트레이닝된 관심 정렬 모델을 획득하는 단계 - 상기 제1 손실은 상기 특징 추출에 대응하는 손실이고, 상기 제2 손실은 상기 관심 정렬 처리에 대응하는 손실이며, 상기 트레이닝된 관심 정렬 모델은 상기 제2 도메인에서 타깃 객체에게 리소스 데이터추천을 하도록 구성됨 -를 포함하는 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 관심 정렬 모델을 호출하여 상기 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현을획득하는 것은, 상기 제1 도메인 데이터에 기반하여 상기 제1 도메인의 객체 리소스 그래프를 구성하는 단계 - 상기 제1 도메인의 객체 리소스 그래프는 각 객체와 각 제1 리소스 데이터가 노드이고 상기 객체와 상기 제1 리소스 데이터 간의 제1 관심 관계가 연결 에지인 그래프임 -;상기 관심 정렬 모델을 호출하여 상기 제1 도메인의 객체 리소스 그래프에 대한 그래프 인코딩 처리를수행하여, 각 객체의 제1 객체 특징 표현과 각 제1 리소스 데이터의 제1 리소스 특징 표현을 획득하는 단계; 및각 객체의 상기 제1 객체 특징 표현과 각 제1 리소스 데이터의 상기 제1 리소스 특징 표현을 사용하여 상기 제1도메인 특징 표현을 형성하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 관심 정렬 모델을 호출하여 상기 제2 도메인 데이터에 대한 특징 추출을 수행하여 제2 도메인 특징 표현을획득하는 것은, 상기 제2 도메인 데이터에 기반하여 상기 제2 도메인의 객체 리소스 그래프를 구성하는 단계 - 상기 제2 도메인의 객체 리소스 그래프는 각 객체와 각 제2 리소스 데이터가 노드이고 상기 객체와 상기 제2 리소스 데이터 간의 제2 관심 관계가 연결 에지인 그래프임 -;상기 관심 정렬 모델을 호출하여 상기 제2 도메인의 객체 리소스 그래프에 대한 그래프 인코딩 처리를수행하여, 각 객체의 제2 객체 특징 표현과 각 제2 리소스 데이터의 제2 리소스 특징 표현을 획득하는 단계; 및공개특허 10-2025-0055558-3-각 객체의 상기 제2 객체 특징 표현과 각 제2 리소스 데이터의 상기 제2 리소스 특징 표현을 사용하여 상기 제2도메인 특징 표현을 형성하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 적어도 하나의 객체 중 어느 하나가 트레이닝 객체로 표현되고, 상기 관심 정렬 모델을 호출하여 상기 제2 도메인의 객체 리소스 그래프에 대한 그래프 인코딩 처리를 수행하여각 객체의 제2 객체 특징 표현을 획득하는 것은,상기 제2 도메인에서의 상기 트레이닝 객체의 초기 특징 표현과 상기 트레이닝 객체가 관심 있는 각 제2 리소스데이터의 초기 특징 표현을 획득하는 단계; 및상기 관심 정렬 모델을 호출하여, 상기 트레이닝 객체의 초기 특징 표현과 상기 트레이닝 객체가 관심 있는 각제2 리소스 데이터의 초기 특징 표현에 따라, 상기 트레이닝 객체와 상기 트레이닝 객체가 관심 있는 각 제2 리소스 데이터 간의 상관도를 계산하는 처리를 수행하는 단계; 및상기 트레이닝 객체와 상기 트레이닝 객체가 관심 있는 각 제2 리소스 데이터 간의 상관도, 상기 제2 도메인에서의 상기 트레이닝 객체의 초기 특징 표현, 상기 트레이닝 객체가 관심 있는 각 제2 리소스 데이터의 초기 특징 표현에 기반하여, 상기 트레이닝 객체의 제2 객체 특징 표현을 결정하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 데이터 세트는 대응하는 관심 있는 제2 리소스 데이터에 대한 각 객체의 실제 주목 정도(true attentiondegree)를 포함하고, 상기 모델 트레이닝 방법은,각 객체의 제1 객체 특징 표현과 제2 객체 특징 표현을 융합하여 각 객체의 융합된 특징 표현을 획득하는 단계;각 객체의 상기 융합된 특징 표현과 대응하는 객체가 관심 있는 상기 제2 리소스 데이터의 제2 리소스 특징 표현에 대한 스플라이싱 연산(splicing operation)을 수행하여 상기 대응하는 관심 있는 제2 리소스 데이터에 대한 각 객체의 예측된 주목 정도를 획득하는 단계; 및상기 대응하는 관심 있는 제2 리소스 데이터에 대한 각 객체의 실제 주목 정도와 상기 예측된 주목 정도 간의차이에 기반하여 상기 관심 정렬 모델의 제1 손실을 구성하는 단계를 더 포함하는 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 관심 정렬 처리는 크로스-도메인 정렬 처리를 포함하고, 상기 제1 도메인 특징 표현이 상기 제1 도메인 데이터에서의 각 객체의 제1 객체 특징 표현을 포함하며, 상기 제2 도메인 특징 표현은 상기 제2 도메인 데이터에서의 각 객체의 제2 객체 특징 표현을 포함하고,상기 관심 정렬 모델을 호출하여, 상기 제1 도메인 특징 표현과 상기 제2 도메인 특징 표현을 기반으로 상기 제1 도메인과 상기 제2 도메인 간의 관심 정렬 처리를 수행하는 처리를 수행하는 단계는, 상기 관심 정렬 모델을 호출하여 각 객체의 제1 객체 특징 표현을 기반으로 상기 제1 도메인 내 두 객체 간의제1 주목 유사도를 결정하는 단계;상기 관심 정렬 모델을 호출하여 각 객체의 제2 객체 특징 표현을 기반으로 상기 제2 도메인 내 두 객체 간의제1 주목 유사도를 결정하는 단계; 및공개특허 10-2025-0055558-4-상기 제2 도메인 내 두 객체 간의 제2 주목 유사도를 상기 제1 도메인 내 대응하는 두 객체 간의 제1 주목 유사도와 맞춰 정렬하는(aligning) 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 관심 정렬 모델을 호출하여 각 객체의 제1 객체 특징 표현을 기반으로 상기 제1 도메인 내 두 객체 간의제1 주목 유사도를 결정하는 단계는, 복수의 객체 중 각 두 객체의 제1 객체 특징 표현에 대해 거리 연산을 수행하여 각 두 객체의 제1 객체 특징 표현 간의 거리 정보를 획득하는 단계; 및각 두 객체의 제1 객체 특징 표현 간의 상기 거리 정보에 대한 확률 변환을 수행하여 각 두 객체 간의 상기 제1주목 유사도를 획득하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 제1 도메인 내 각 두 객체 간의 제1 주목 유사도에 기반하여 상기 제1 도메인의 주목 유사도 분포를 결정하는 단계;상기 제2 도메인 내 각 두 객체 간의 제2 주목 유사도에 기반하여 상기 제2 도메인의 주목 유사도 분포를 결정하는 단계; 및상기 제1 도메인의 주목 유사도 분포와 상기 제2 도메인의 주목 유사도 분포의 차이에 기반하여 상기 관심 정렬모델의 크로스-도메인 정렬 손실을 구성하고, 상기 크로스-도메인 정렬 손실을 상기 제2 손실로 사용하는 단계를 더 포함하는 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 관심 정렬 처리가 인트라-도메인 정렬 처리를 포함하고,상기 관심 정렬 모델을 호출하여, 상기 제1 도메인 특징 표현과 상기 제2 도메인 특징 표현에 기반하여 상기 제1 도메인과 상기 제2 도메인 간의 관심 정렬 처리를 수행하는 처리를 수행하는 단계는,각 객체의 융합된 특징 표현, 상기 제1 도메인의 객체 리소스 그래프, 및 상기 제2 도메인의 객체 리소스 그래프를 획득하는 단계;상기 관심 정렬 모델을 호출하여, 각 객체의 상기 융합된 특징 표현에 대해 상기 제1 도메인에 관한 그래프 디코딩 처리와 제2 도메인에 관한 그래프 디코딩 처리를 수행하여, 상기 제1 도메인의 객체 그래프와 상기 제2 도메인의 객체 그래프를 획득하는 단계 - 객체 그래프는 각 객체가 노드로 사용되고 객체 간의 제2 관심 관계가연결 에지로 사용되는 그래프임 -; 및상기 제1 도메인의 객체 그래프를 상기 제1 도메인의 객체 리소스 그래프에 맞춰 정렬하고, 상기 제2 도메인의객체 그래프를 상기 제2 도메인의 객체 리소스 그래프에 맞춰 정렬하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 관심 정렬 모델을 호출하여, 각 객체의 상기 융합된 특징 표현에 대해 상기 제1 도메인에 관한 그래프 디코딩 처리와 제2 도메인에 관한 그래프 디코딩 처리를 수행하여, 상기 제1 도메인의 객체 그래프와 상기 제2 도공개특허 10-2025-0055558-5-메인의 객체 그래프를 획득하는 단계는, 상기 제1 도메인의 그래프 디코딩 가중치를 획득하고, 상기 관심 정렬 모델을 호출하여, 상기 제1 도메인의 그래프 디코딩 가중치와 각 객체의 상기 융합된 특징 표현을 기반으로 상기 제1 도메인의 객체 그래프를 재구성하는 단계; 및상기 제2 도메인의 그래프 디코딩 가중치를 획득하고, 상기 관심 정렬 모델을 호출하여, 상기 제2 도메인의 그래프 디코딩 가중치와 각 객체의 상기 융합된 특징 표현을 기반으로 상기 제2 도메인의 객체 그래프를 재구성하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 제1 도메인의 객체 그래프와 대응하는 객체 리소스 그래프의 차이에 기반하여 상기 제1 도메인의 인트라-도메인 정렬 손실을 획득하는 단계;상기 제2 도메인의 객체 그래프와 대응하는 객체 리소스 그래프의 차이에 기반하여 상기 제2 도메인의 인트라-도메인 정렬 손실을 획득하는 단계; 및상기 제1 도메인의 인트라-도메인 정렬 손실과 상기 제2 도메인의 인트라-도메인 정렬 손실을 병합하여 상기 관심 정렬 모델의 인트라-도메인 정렬 손실을 획득하고, 상기 인트라-도메인 정렬 손실을 상기 제2 손실로 사용하는 단계를 더 포함하는 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 관심 정렬 처리가 크로스-도메인 정렬 처리 및 인트라-도메인 정렬 처리를 포함하고, 상기 관심 정렬 모델을 호출하여, 상기 제1 도메인 특징 표현과 상기 제2 도메인 특징 표현을 기반으로 상기 제1 도메인과 상기 제2 도메인 간의 관심 정렬 처리를 수행하는 처리를 수행하는 단계는,상기 관심 정렬 모델을 호출하여, 상기 제1 도메인 특징 표현과 상기 제2 도메인 특징 표현에 기반하여 상기 제1 도메인과 상기 제2 도메인 간의 크로스-도메인 정렬 처리를 수행하는 처리를 수행하는 단계; 및상기 관심 정렬 모델을 호출하여, 상기 제1 도메인 특징 표현과 상기 제2 도메인 특징 표현에 기반하여 상기 제1 도메인과 상기 제2 도메인 간의 인트라-도메인 정렬 처리를 수행하는 처리를 수행하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 크로스-도메인 정렬 처리에 대응하는 크로스-도메인 정렬 손실을 획득하고, 상기 인트라-도메인 정렬 처리에 대응하는 인트라-도메인 정렬 손실을 획득하는 단계; 및상기 크로스-도메인 정렬 손실과 상기 인트라-도메인 정렬 손실을 사용하여 상기 제2 손실을 형성하는 단계를 더 포함하는 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항 내지 제13항 중 어느 한 항에 있어서,상기 관심 정렬 모델은 제1 특징 추출 모듈, 제2 특징 추출 모듈, 크로스-도메인 정렬 모듈, 및 인트라-도메인정렬 모듈을 포함하고,상기 제1 특징 추출 모듈은 상기 제1 도메인 데이터에 대한 특징 추출을 수행하도록 구성되고, 상기 제1 특징공개특허 10-2025-0055558-6-추출 모듈은 사전 트레이닝을 통해 획득되며,상기 제2 특징 추출 모듈은 상기 제2 도메인 데이터에 대한 특징 추출을 수행하도록 구성되고, 상기 크로스-도메인 정렬 모듈은 상기 제2 도메인 내 두 객체 간의 제2 주목 유사도와 상기 제1 도메인 내 대응하는 두 객체 간의 제1 주목 유사도 간의 관심 정렬 처리를 수행하도록 구성되며,상기 인트라-도메인 정렬 모듈은 상기 제1 도메인의 객체 그래프와 상기 제1 도메인의 객체 리소스 그래프 간의관심 정렬 처리를 수행하고, 상기 제2 도메인의 객체 그래프와 상기 제2 도메인의 객체 리소스 그래프 간의 관심 정렬 처리를 수행하도록 구성되는, 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제2 손실은 크로스-도메인 정렬을 통해 획득되는 크로스-도메인 정렬 손실 및 인트라-도메인 정렬을 통해획득되는 인트라-도메인 정렬 손실을 포함하고,상기 제1 손실과 제2 손실이 감소하는 방향에 따라 상기 관심 정렬 모델을 트레이닝하여 트레이닝된 관심 정렬모델을 획득하는 단계는,상기 관심 정렬 모델의 제1 손실, 상기 크로스-도메인 정렬 손실, 및 상기 인트라-도메인 정렬 손실을 더하여상기 관심 정렬 모델의 타깃 손실을 획득하는 단계; 및상기 타깃 손실이 감소하는 방향에 따라 상기 관심 정렬 모델을 트레이닝하는 단계를 포함하고,상기 타깃 손실이 감소하는 방향에 따라 상기 관심 정렬 모델을 트레이닝하는 프로세스에서, 상기 크로스-도메인 정렬 손실에 기반한 상기 제1 특징 추출 모듈의 트레이닝이 단축되는, 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항 내지 제15항 중 어느 한 항에 있어서,리소스 데이터가 배포될 타깃 객체의 객체 속성과 상기 제2 도메인에서 배포될 각 후보 리소스 데이터의 리소스특징 표현을 획득하는 단계;상기 트레이닝된 관심 정렬 모델을 호출하여 상기 타깃 객체의 객체 속성에 기반한 특징 추출을 수행하여 상기타깃 객체의 융합된 특징 표현을 획득하는 단계; 상기 타깃 객체의 융합된 특징 표현과 각 후보 리소스 데이터의 상기 리소스 특징 표현 간의 유사도 비교를 수행하여 상기 타깃 객체와 각 후보 리소스 데이터 간의 유사도 비교 결과를 획득하는 단계; 및유사도 비교 결과가 리소스 추천 규칙을 충족하는 후보 리소스 데이터를 상기 타깃 객체와 연관된 배포 대상 제2 리소스 데이터로 사용하는 단계를 더 포함하는 모델 트레이닝 방법."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "모델 트레이닝 장치로서,데이터 세트를 획득하도록 구성된 획득 유닛 - 상기 데이터 세트는 제1 도메인 데이터와 제2 도메인 데이터를포함하고, 상기 제1 도메인 데이터는 적어도 하나의 객체와 제1 도메인에서 각 객체가 관심 있는 제1 리소스 데이터를 포함하며, 상기 제2 도메인 데이터는 상기 적어도 하나의 객체와 제2 도메인에서 각 객체가 관심 있는제2 리소스 데이터를 포함함 -; 및관심 정렬 모델을 호출하여 상기 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현을 획득하고, 상기 관심 정렬 모델을 호출하여 상기 제2 도메인 데이터에 대한 특징 추출을 수행하여 제2 도메인 특징표현을 획득하도록 구성된 처리 유닛을 포함하고,공개특허 10-2025-0055558-7-상기 처리 유닛은 추가로, 상기 관심 정렬 모델을 호출하여, 상기 제1 도메인 특징 표현과 상기 제2 도메인 특징 표현에 기반하여 상기 제1 도메인과 상기 제2 도메인 간의 관심 정렬 처리를 수행하는 처리를 수행하도록 구성되며,상기 처리 유닛은 추가로, 제1 손실과 제2 손실이 감소하는 방향에 따라 상기 관심 정렬 모델을 트레이닝하여트레이닝된 관심 정렬 모델을 획득하도록 구성되고, 상기 제1 손실은 상기 특징 추출에 대응하는 손실이고, 상기 제2 손실은 상기 관심 정렬 처리에 대응하는 손실이며, 상기 트레이닝된 관심 정렬 모델은 상기 제2 도메인에서 타깃 객체에 대한 리소스 데이터 추천을 하도록구성되는, 모델 트레이닝 장치."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "전자 디바이스로서,컴퓨터가 실행 가능한 명령어를 실행하도록 구성된 프로세서; 및컴퓨터가 판독 가능한 저장 매체를 포함하고,상기 컴퓨터가 판독 가능한 저장 매체에는 상기 컴퓨터가 실행 가능한 명령어가 저장되어 있으며, 상기 컴퓨터가 실행 가능한 명령어가 상기 프로세서에 의해 실행될 때, 제1항 내지 제16항 중 어느 하나에 따른 모델 트레이닝 방법이 구현되는, 전자 디바이스."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "컴퓨터가 판독 가능한 저장 매체로서, 상기 컴퓨터가 판독 가능한 저장 매체에는 컴퓨터가 실행 가능한 명령어가 저장되어 있으며, 상기 컴퓨터가 실행 가능한 명령어가 실행될 때, 제1항 내지 제16항 중 어느 하나에 따른 모델 트레이닝 방법이 구현되는, 컴퓨터가 판독 가능한 저장 매체."}
{"patent_id": "10-2025-7009207", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터 프로그램 제품으로서,상기 컴퓨터 프로그램 제품은 컴퓨터가 실행 가능한 명령어를 포함하고, 상기 컴퓨터가 실행 가능한 명령어가프로세서에 의해 실행될 때, 제1항 내지 제16항 중 어느 하나에 따른 모델 트레이닝 방법이 구현되는, 컴퓨터프로그램 제품."}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "모델 트레이닝 방법 및 장치, 전자 디바이스, 컴퓨터가 판독 가능한 저장 매체, 그리고 컴퓨터 프로그램 제품. 이 방법은: 데이터 세트를 획득하는 단계 - 데이터 세트는 제1 도메인 데이터와 제2 도메인 데이터를 포함하고, 제1 도메인 데이터는 적어도 하나의 객체와 제1 도메인에서 각 객체가 관심 있는 제1 리소스 데이터를 포함하며, (뒷면에 계속)"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2022년 11월 29일에 출원된 중국 특허 출원 번호 제202211507481.6호에 기반하여 제안되었으며, 위의 중국 특허에 대한 우선권을 주장하는 바이며, 이러한 문헌의 내용은 원용에 의해 전체적으로 본 명세서에 포함 된다. 본 출원은 컴퓨터 기술 분야, 구체적으로 기계 학습(machine learning, ML) 분야에 관한 것으로, 특히 모델 트 레이닝 방법 및 장치, 전자 디바이스, 컴퓨터가 판독 가능한 저장 매체 그리고 컴퓨터 프로그램 제품에 관한 것 이다."}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "개인화된 추천자 시스템(recommender system)은 사용자(즉, 객체)에게 개인화된 리소스를 추천하도록 구성된 플 랫폼이다. 예를 들어, 비디오 시나리오에서 개인화된 추천자 시스템은 사용자에게 관심 있는 비디오 리소스를 추천하는 것을 지원한다. 현재, 개인화 추천자 시스템은 사용자(즉, 객체)의 대량의 행동 데이터(예컨대, 사용자 데이터와 리소스 데이터 간의 상호작용 데이터)를 수집하고 설계된 추천 알고리즘을 사용하는 것에 의해 리소스 추천 모델의 구축을 지원하여, 구축된 리소스 추천을 통해 객체에 대한 특정 추천 목록을 생성하며, 이에 따라 개인화된 추천이라는 목적을 달성한다. 그러나 실제로, 개인화된 추천자 시스템은 모든 객체에 대한 풍부한 데이터를 보유하고 있지 않은 것으로 나타났다. 이 경우, 객체의 대량의 상호작용 데이터에 기반한 트레이닝을 통해 획득되는 리소스 추 천 모델은 상호작용 데이터가 적은 객체에 대한 리소스 추천에는 적합하지 않아서, 리소스 추천 모델의 추천 효 과가 떨어진다. 본 출원의 실시예는 모델 트레이닝 방법 및 장치, 전자 디바이스, 컴퓨터가 판독 가능한 저장 매체 그리고 컴퓨 터 프로그램 제품을 제공한다. 관심 정렬 모델(interest alignment model)은 관심 정렬 모델의 성능을 보장하기 위해 객체 간의 관심 관계(interest relationship)를 사용하여 트레이닝될 수 있다. 본 출원의 실시예는 전자 디바이스에 의해 수행되는 모델 트레이닝 방법을 제공하며, 본 방법은: 데이터 세트를 획득하는 단계 - 데이터 세트는 제1 도메인 데이터 및 제2 도메인 데이터를 포함하고, 제1 도메 인 데이터는 적어도 하나의 객체와 제1 도메인에서 각 객체가 관심 있는 제1 리소스 데이터(first resource data of interest to each object)를 포함하며, 제2 도메인 데이터는 적어도 하나의 객체와 제2 도메인에서 각 객체가 관심 있는 제2 리소스 데이터를 포함한다. 관심 정렬 모델을 호출하여, 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현(domain feature representation)을 획득하고, 관심 정렬 모델을 호출하여 제2 도메인 데이터에 대한 특징 추출을 수행 하여 제2 도메인 특징 표현을 획득하는 단계; 관심 정렬 모델을 호출하여, 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메 인 간의 관심 정렬 처리를 수행하는 처리를 수행하는 단계; 및 제1 손실과 제2 손실이 감소하는 방향에 따라 관심 정렬 모델을 트레이닝하여 트레이닝된 관심 정렬 모델을 획 득하는 단계를 포함하며, 제1 손실은 특징 추출에 대응하는 손실이고, 제2 손실은 관심 정렬 처리에 대응하는 손실이며, 트레이닝된 관심 정렬 모델은 제2 도메인에서 타깃 객체에게 리소스 데이터 추천을 하도록 구성된다. 본 출원의 실시예는 모델 트레이닝 장치를 제공한다. 본 장치는: 데이터 세트를 획득하도록 구성된 획득 유닛 - 데이터 세트는 제1 도메인 데이터 및 제2 도메인 데이터를 포함 하고, 제1 도메인 데이터는 적어도 하나의 객체와 제1 도메인에서 각 객체가 관심 있는 제1 리소스 데이터를 포 함하며, 제2 도메인 데이터는 적어도 하나의 객체와 제2 도메인에서 각 객체가 관심 있는 제2 리소스 데이터를 포함함 -; 및 관심 정렬 모델을 호출하여 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현을 획득하고, 관심 정렬 모델을 호출하여 제2 도메인 데이터에 대한 특징 추출을 수행하여 제2 도메인 특징 표현을 획득하도 록 구성된 처리 유닛을 포함하고, 처리 유닛은 추가로, 관심 정렬 모델을 호출하여, 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제 1 도메인과 제2 도메인 간의 관심 정렬 처리를 수행하는 처리를 수행하도록 구성되며, 처리 유닛은 추가로, 제1 손실과 제2 손실이 감소되는 방향에 따라 관심 정렬 모델을 트레이닝하여 트레이닝된 관심 정렬 모델을 획득하도록 구성되고, 제1 손실은 특징 추출에 대응하는 손실이고, 제2 손실은 관심 정렬 처리에 대응하는 손실이며, 트레이닝된 관심 정렬 모델은 제2 도메인에서 타깃 객체에 대한 리소스 데이터 추천을 하도록 구성된다. 본 출원의 실시예는 전자 디바이스를 제공한다. 전자 디바이스는: 컴퓨터가 실행 가능한 명령어를 로딩하고 실행하도록 구성된 프로세서; 및 컴퓨터가 판독 가능한 저장 매체를 포함하고, 컴퓨터가 판독 가능한 저장 매체에는 컴퓨터가 실행 가능한 명령 어가 저장되어 있으며, 컴퓨터가 실행 가능한 명령어가 프로세서에 의해 실행될 때 전술한 모델 트레이닝 방법 이 구현된다. 본 출원의 실시예는 컴퓨터가 판독 가능한 저장 매체를 제공하며, 컴퓨터가 판독 가능한 저장 매체에는 컴퓨터 가 실행 가능한 명령어가 저장되어 있으며, 컴퓨터가 실행 가능한 명령어는 모델 트레이닝 방법을 구현하기 위 해 프로세서에 의해 로딩되고 실행되도록 적응된다. 본 출원의 실시예는 컴퓨터 프로그램 제품을 제공한다. 컴퓨터 프로그램 제품은 컴퓨터가 실행 가능한 명령어를 포함한다. 컴퓨터가 실행 가능한 명령어는 컴퓨터가 판독 가능한 저장 매체에 저장되어 있다. 전자 디바이스의 프로세서는 컴퓨터가 판독 가능한 저장 매체로부터 컴퓨터가 실행 가능한 명령어를 읽는다. 컴퓨터가 실행 가능 한 명령어가 프로세서에 의해 실행될 때, 전술한 모델 트레이닝 방법이 구현된다. 본 출원의 실시예에서는, 대응하는 도메인에서 적어도 하나의 객체가 관심 있는 리소스 데이터를 복수의 도메인 으로부터 획득하는 것, 예를 들어, 제1 도메인으로부터 제1 도메인 데이터를 획득하고 제2 도메인으로부터 제2 도메인 데이터를 획득하는 것이 지원되며, 여기서 제1 도메인은 상호작용 데이터(interaction data)가 풍부한 도메인이고 제2 도메인은 상호작용 데이터가 부족한 도메인일 수 있다. 그런 다음, 관심 정렬 모델을 호출하여 제1 도메인 데이터와 제2 도메인 데이터에 대해 개별적으로 특징 추출을 수행하여 제1 도메인 특징 표현과 제2 도메인 특징 표현을 추출한다. 관심 정렬 모델은 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 두 도메인에서 관심 정렬 처리를 수행하도록 호출되며, 마지막으로 특징 추출 프로세스의 제1 손실과 관심 정렬 처 리 프로세스의 손실을 감소시키는 방향에 따라 관심 정렬 모델을 트레이닝하는 것이 지원된다. 본 출원의 실시 예는 객체 간의 관심 유사도(interest similarity degree)를 충분히 고려하고, 객체 간의 관심 유사도를 맞춰 정렬하는 방식으로 관심 정렬 모델의 트레이닝을 지원함으로써, 관심 정렬 모델이 상호작용 데이터가 적은 도메 인에 적용될 때에도, 정확한 특징 표현이 객체에 대해 생성될 수 있다. 예를 들어, 제1 도메인에 많은 상호작용 데이터가 있는 것을 고려하면, 풍부한 상호작용 데이터에 기반하여 추출된 제1 도메인 특징 표현이 더 정확하다. 따라서 관심 정렬 모델은 상호작용 데이터가 적은 제2 도메인 내 두 객체 간의 관심 유사도와 상호작 용 데이터가 많은 제1 도메인 내 두 객체 간의 관심 유사도를 맞춰 정렬하는 방식으로 트레이닝된다. 제2 도메 인의 상호작용 데이터가 적을 때에도 트레이닝된 관심 정렬 모델이 객체에 대한 높은 정확도의 특징 표현을 생 성할 수 있으므로, 정확한 특징 표현에 기반하여 객체에 추천되는 리소스 데이터가 객체의 개인화된 요구를 충 족시키며, 정확한 리소스 추천이 구현된다. 본 출원의 실시예에서, 특징 추출 프로세스의 제1 손실과 관심 정렬 처리 프로세스의 손실을 이용하여 관심 정렬 모델을 공동으로 트레이닝하는 방식은, 관심 정렬 모델의 전반적인 학습 목표를 풍부하게 하고, 다중 목표 학습을 통해 관심 정렬 모델의 성능을 보장할 수 있다."}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 출원의 실시예에서의 기술적 솔루션은 첨부 도면을 참조하여 이하에서 명확하게 설명된다. 분명히, 설명될 실시예는 본 출원의 모든 실시예라기보다는 단지 일부일 뿐이다. 본 개시의 실시예에 기반하여 이 기술 분야의 통상의 지식을 가진 자가 창의적인 노력 없이 획득한 모든 다른 실시예는 본 개시의 보호 범위에 속한다. 본 출원의 실시예에서는 모델 트레이닝 솔루션이 제공되며, 구체적으로는 리소스 추천 시나리오에서의 관심 정 렬 모델의 트레이닝 및 적용 솔루션이 제공된다. 이하에서는 본 출원의 실시예에서 제공하는 모델 트레이닝 솔 루션에 관련된 기술 용어와 관련 개념을 간략하게 소개한다. 1. 인공지능(Artificial Intelligence, AI). AI는 디지털 컴퓨터 또는 디지털 컴퓨터에 의해 제어되는 기계를 사용하여 인간의 지능을 시뮬레이션, 확장 및 확대하고, 환경을 인식하며, 지식을 획득하고, 지식을 사용하여 최적의 결과를 획득하는 이론, 방법, 기술 및 애플리케이션 시스템을 포함한다. AI 기술은 포괄적인 학문이며, 하드웨어 수준 기술과 소프트웨어 수준 기술을 모두 포함하는 광범위한 분야와 관련이 있다. 기본적인 AI 기술에는 일반적으로 센서, 전용 AI 칩, 클라우드 컴 퓨팅, 분산 스토리지, 빅데이터 처리 기술, 운영/상호작용 시스템, 전기기계 통합과 같은 기술이 포함된다. AI 소프트웨어 기술은 주로 컴퓨터 비전 기술, 음성 처리 기술, 자연어 처리 기술, ML/심층학습과 같은 몇 가지 주 요 방향을 포함한다. ML은 다분야의 학제간 융합(interdiscipline)이며, 확률 이론, 통계학, 근사 이론, 볼록 분석 및 알고리즘 복잡도 이론과 같이 복수의 학문과 관련되고, 컴퓨터가 인간의 학습 행동을 어떻게 시뮬레이 션하거나 구현하여 신규 지식이나 스킬을 획득하는 데 특화되어 있으며, 기존 지식 구조를 재구성하여 성능을 지속적으로 개선한다. ML과 심층 학습에는 일반적으로 인공 신경망, 신념 네트워크, 강화 학습, 전이 학습, 귀 납적 학습, 데모를 통한 학습, 메타 학습과 같은 기술이 포함된다. 본 출원의 실시예에서 제공하는 모델 트레이닝 솔루션은 주로 ML 및 전이 학습에서의 인공 신경망을 포함한다. 아래에서는 인공 신경망과 전이 학습을 별도로 간략하게 설명한다. 인공 신경망은 ML의 태스크(task)를 구현하기 위한 방법이다. ML 분야에서 논의되는 신경망은 일반적으로 \"신경망 학습\"이라고 한다. 이는 많은 간단한 엘리먼트로 구성된 네트워크 구조이다. 네트워크 구조는 생물학 적 신경 시스템과 유사하며, 생명체와 자연 환경 간의 상호작용을 시뮬레이션하도록 구성된다. 네트워크 구조가 많을수록 신경망의 기능이 더욱 풍부해진다는 것을 지시한다. 신경망은 비교적 큰 개념이며, 음성, 텍스트, 이 미지와 같은 서로 다른 학습 태스크에 대해, 그래프 신경망(graph neural network, GNN)과 같이 특정 학습 태스 크에 더 적합한 신경망 모델이 도출된다. GNN은 심층 학습 모델을 사용하여 그래프 구조 데이터에 대한 특징 마 이닝(feature mining)과 추출을 수행하는 알고리즘이며, 구체적으로 그래프 구조 데이터를 학습하고 그래프 구 조 데이터에서 특징과 패턴을 추출 및 발견하는 것에 의해 클러스터링, 분류, 예측, 세분화(segmentation), 생 성과 같은 그래프 학습 태스크 요건을 충족할 수 있는 알고리즘의 총칭이다. 예를 들어, 그래프 학습 태스크 요 건을 충족하는 GNN은 그래프 합성곱 네트워크(graph convolutional network, GCN), 그래프 순환 네트워크 (graph recurrent network, GRN), 그래프 주목 네트워크(graph attention network, GAT) 등을 포함할 수 있지 만, 이에 제한되지는 않는다. 본 출원의 실시예는 특히 GNN에 포함된 GAT와 관련된다. GAT은 주목 메커니즘을 포함한다. 주목 메커니즘 (attention mechanism)을 통해, 신경망은 태스크 학습에 필요한 정보에만 주목하여 특정 입력을 선택할 수 있다. 다시 말해, GAT에 주목 메커니즘을 도입하면. 신경망이 태스크와 더 관련된 그래프 구조 데이터(예컨대, 그래프에 포함된 노드와 에지(edge))에 주목하게 되며, 이에 따라 트레이닝의 효과와 테스트 정확도가 향상된다. 주목 메커니즘은 인간의 시각적 주의(visual attention)를 시뮬레이션하는 것에 의해 생성된다. 예를 들어, 인간 눈의 시야는 비교적 열려 있지만 시야가 주목되는 초점 범위는 일반적으로 작다. 다시 말해, 인간의 눈은 시야에서 중요한 영역(즉, 관심 영역)에 더 많은 주목을 한다. 따라서 인간의 시각적 주의와 유사하게, 주 목 메커니즘은 태스크에서 중요한 정보에 주목하고 중요하지 않은 정보는 무시하는 것을 목표로 한다. 주목 메 커니즘은 추가로, 셀프-주목 메커니즘, 멀티-헤드 셀프-주목 메커니즘, 글로벌-주목 메커니즘 등으로 세분화될 수 있다. 전이 학습은 트레이닝 데이터 및/또는 주석이 부족한 경우에 대처하기 위해 널리 사용되는 기술이다. 구체 적으로, 학습된 신규 태스크는 학습된 관련 태스크로부터 지식을 전이하는(transfer) 것에 의해 개선되며, 예를 들어, (현재가 아닌 태스크의 데이터와 주석을 사용하여) 사전 트레이닝된 모델의 파라미터가 신규 네트워크 모델로 전이(복사)되어 트레이닝을 지원한다. 대부분의 ML 알고리즘이 단일 태스크를 해결하도록 설계되었지만, 전이 학습을 용이하게 하는 알고리즘의 개발은 ML 커뮤니티가 지속적으로 주목하는 주제이다. 전이 학습에는 도메인 개념이 포함된다. 도메인은 전이 학습의 주요 주체이며, 데이터 특징과 특징 분포로 구성 된다. 리소스 추천 시나리오에서, 도메인은 일반적으로 쇼핑, 영화, 책 읽기, 비디오, 소셜 퍼블릭 계정, 문서, 라이브 스트리밍과 같은 서로 다른 응용 분야를 지칭하는 데 사용된다. 전술한 내용에서 알 수 있듯이, 전이 학 습의 태스크는 문제 간의 유사성을 시작으로 이전 도메인에 의해 학습된 모델을 신규 도메인에 적용하는 것이다. 따라서 전이 학습에 관련된 도메인은 일반적으로 적어도 2개의 도메인 즉, 소스 도메인과 타깃 도메인 을 포함한다. 소스 도메인은 트레이닝 대상 모델의 샘플 데이터(즉, 리소스 데이터)가 속한 도메인과 상이한 도 메인이다. 소스 도메인에는 일반적으로 풍부한 지도 정보(supervisory information)(즉, 모델 트레이닝을 위한 풍부한 리소스 데이터)가 포함된다. 타깃 도메인은 트레이닝 대상 모델의 샘플 데이터가 속한 도메인과 동일한 도메인이다. 타깃 도메인에는 일반적으로 모델 트레이닝을 위한 소량의 리소스 데이터만 포함된다. 2. 리소스 추천. 리소스 추천은 리소스 배포(distribution)라로도 지칭되며, 또한 리소스 추천 플랫폼(또는 리소스 추천 시스템, 또는 언급된 개인화된 추천자 시스템)에서, 플랫폼에 포함된 리소스 데이터를 플랫폼 객체(예를 들어, 플랫폼 계정에 등록되거나 플랫폼에 일시적으로 로그인한 하나 이상의 리소스 수신자(recipient))에 배포하는 프로세스 를 지칭할 수 있다. 리소스 추천 플랫폼에 포함된 리소스 데이터는 인터넷 리소스(또는 줄여서 리소스)라고 지 칭될 수 있으며, 여기에는 비디오(비디오의 시간 길이에 따라 긴 비디오와 짧은 비디오로 구분할 수 있음), 오 디오(예컨대, 음악이나 음성 오디오), 애니메이션, 문서(예컨대, 저널이나 논문) 등이 포함되지만 이에 제한되 지는 않는다. 본 출원의 실시예에서는 리소스 데이터의 리소스 유형이 제한되지 않는다. 리소스 데이터의 리소 스 유형은 리소스 데이터를 배포하는 리소스 추천 플랫폼이 속한 도메인(즉, 전술한 도메인)과 연관되어 있다. 서로 다른 도메인에 분산된 리소스 데이터의 리소스 유형은 서로 다를 수 있다. 예를 들어, 라이브 스트리밍 도 메인에서의 리소스 데이터의 리소스 유형은 비디오이고, 문서 도메인에서의 리소스 데이터의 리소스 유형은 문 서이다. 본 출원의 실시예에서는 리소스 데이터의 리소스 유형이 제한되지 않는다. 리소스 추천 플랫폼은 리소스 데이터의 배포 또는 추천을 지원하는 애플리케이션 프로그램을 지칭할 수 있다. 애플리케이션 프로그램은 하나 이상의 특정 작업(job)을 완료하는 컴퓨터 프로그램일 수 있다. 애플리케이션 프 로그램은 서로 다른 차원(예컨대, 애플리케이션의 실행 방식 및 기능)에 따라 분류되며, 서로 다른 차원에서 동 일한 애플리케이션의 유형이 획득될 수 있다. 예를 들어, 애플리케이션 프로그램의 실행 방식에 따라 분류할 때, 애플리케이션 프로그램은 단말에 설치된 클라이언트, 다운로딩 및 설치 없이도 사용할 수 있는 애플릿(클라 이언트의 서브프로그램), 브라우저를 통해 열리는 웹(World Wide Web) 애플리케이션 프로그램 등을 포함할 수 있지만, 이에 제한되지는 않는다. 또 다른 예로, 애플리케이션 프로그램을 기능 유형에 따라 분류할 때, 애플리 케이션 프로그램은 인스턴트 메시징(instant messaging, IM) 애플리케이션 프로그램, 콘텐츠 상호작용 애플리케 이션 프로그램 등을 포함할 수 있지만, 이에 제한되지는 않는다. IM 애플리케이션 프로그램은 인터넷 기반의 인 스턴트 메시지 교환 및 소셜 상호작용 애플리케이션 프로그램을 지칭한다. IM 애플리케이션 프로그램에는 커뮤 니케이션 기능을 포함하는 소셜 애플리케이션 프로그램, 소셜 상호작용 기능을 포함하는 맵(map) 애플리케이션 프로그램, 게임 애플리케이션 프로그램 등이 포함될 수 있지만, 이에 제한되지는 않는다. 콘텐츠 상호작용 애플 리케이션 프로그램은 콘텐츠 상호작용을 구현할 수 있는 애플리케이션 프로그램을 지칭하며, 예를 들어 온라인 뱅킹, 공유 플랫폼, 개인 공간 또는 뉴스와 같은 애플리케이션 프로그램일 수 있다. 리소스 추천 플랫폼은 다르게는 리소스 추천을 지원하면서 또한 위에서 언급된 애플리케이션 프로그램에 포함되 는 플러그인(plug-in)(또는 기능)일 수 있다. 예를 들어, 애플리케이션 프로그램이 클라이언트 형태의 IM 애플 리케이션 프로그램이면, 리소스 배포 플랫폼은 대응하는 IM 애플리케이션 프로그램에 포함된 리소스 배포 플러 그일 수 있다. 예를 들어, 리소스 데이터가 짧은 비디오일 때, IM 애플리케이션 프로그램에 의해 제공되는 리소 스 추천 기능은 짧은 비디오 추천 기능이다. 이런 방식으로, 타깃 객체(예를 들어, IM 애플리케이션 프로그램을 사용하는 임의의 객체)는 애플리케이션 점프(예를 들어, IM 애플리케이션 프로그램에서 독립적인 리소스 추천 애플리케이션 프로그램으로 점프)를 수행하지 않고도, IM 애플리케이션 프로그램을 사용하는 소셜 상호작용 중 에 리소스 브라우징 및 게시(publishing)와 같은 기능을 여전히 수행할 수 있다. 동일한 리소스 추천 플랫폼에 의해 배포되는 리소스 데이터의 유형은 하나의 유형으로 제한되지 않는다. 예를 들어, 동일한 리소스 추천 플랫폼에 의해 배포가 지원되는 리소스 데이터의 리소스 유형은 비디오와 문서 모두 를 포함할 수 있다. 또한, 리소스 추천 플랫폼에 의해 배포되는 리소스 데이터의 리소스 유형, 그리고 전술한애플리케이션 프로그램의 유형 중 리소스 추천 플랫폼이 특별히 제공하는 애플리케이션 프로그램 또는 리소스 추천 기능을 제공하는 애플리케이션 프로그램의 유형은 본 출원의 실시예에서는 제한되지 않는다. 설명의 편의 를 위해, 리소스 추천 플랫폼(또는 리소스 추천 시스템)에 의해 배포되는 리소스가 짧은 비디오인 예를 사용하 여 이하의 실시예를 설명한다. 전술한 전이 학습 및 리소스 추천에 관한 관련 설명에 기반하여, 본 출원의 실시예는 모델 트레이닝 솔루션을 제공한다. 모델 트레이닝 솔루션에는 크로스-도메인 추천(cross-domain recommendation)이 포함된다. 크로스-도 메인 추천은 복수의 도메인의 데이터를 결합하고, 다른 도메인(예를 들어, 적어도 하나의 소스 도메인)의 정보 를 도입하여 지원하며, 다른 도메인에 있는 객체의 상호작용 데이터를 분석하여 특정 측면에서 객체의 선호도 (preference)나 관심을 파악하는 것을 목표로 함으로써, 타깃 도메인 및 복수의 도메인에 대해 더 나은 추천을 제공할 수 있다. 특정 구현에서, 본 출원의 실시예에서 제공되는 모델 트레이닝 솔루션은 관심 정렬 모델에 대한 트레이닝 솔루 션이다. 관심 정렬 모델은 크로스-도메인 추천 모델 등으로 지칭될 수 있다. 구체적으로, 관심 정렬 트레이닝은 객체 간의 관심 관계, 즉 크로스-도메인 객체 관심 관계와 인트라-도메인(intra-domain) 객체 관심 관계를 포함 하는, 리소스 데이터에 관심이 있는 서로 다른 객체 간의 관계(예를 들어, 객체 A가 관심 있는 리소스 데이터는 객체 B가 관심 있는 리소스 데이터와 유사함)를 이용하여 관심 정렬 모델에 대해 수행되며, 이에 따라 타깃 도 메인에서의 관심 학습을 유도하는 목적을 달성한다. 모델 트레이닝 솔루션의 대략적인 트레이닝 절차는: 모델 트레이닝을 수행하기 위한 데이터 세트를 획득하는 단계 - 데이터 세트는 제1 도메인의 제1 도메인 데이터와 제 2 도메인의 제2 도메인 데이터를 포함함 -; 및 그런 다음 관심 정렬 모델을 호출하여 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현(즉, 임베딩 벡터(embedding vector))을 획득하고, 관심 정렬 모델 을 호출하여 제2 도메인에 대한 특징 추출을 수행하여 제2 도메인 표현을 획득하는 단계; 제1 도메인 특징 표현 과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메인 간의 관심 정렬 처리(또는 관심 유사도 정렬 처 리라고 함) - 크로스-도메인 정렬 처리 및 인터-도메인(inter-domain) 정렬 처리를 포함함 -를 수행하는 단계; 및 마지막으로 특징 추출 프로세스의 제1 손실과 관심 정렬 처리 프로세스의 손실을 감소시키는 방향에 따라 관 심 정렬 모델을 트레이닝하여 트레이닝된 관심 정렬 모델을 획득하는 단계를 포함할 수 있다. 트레이닝된 관심 정렬 모델은 전술한 모델 트레이닝 프로세스에 기반하여 획득될 수 있다. 관심 정렬 모델은 제 2 도메인에서 타깃 객체(예를 들어, 리소스 데이터가 배포될 임의의 객체)에 대한 리소스 데이터 추천을 하도록 구성된다. 구체적으로, 트레이닝된 관심 정렬 모델이 획득된 후, 본 출원의 실시예는 추가로, 트레이닝된 관심 정렬 모델을 호출하여 리소스 추천 플랫폼에 로그인한 타깃 객체에게 리소스 데이터를 추천하는 것을 지원한다. 구체적으로, 관심 정렬 모델은 리소스 데이터가 배포될 타깃 객체에 대한 정확한 객체 특징 표현(즉, 타깃 객체 의 속성이나 특징을 나타낼 수 있는 임베딩 벡터)을 생성하는 데 사용된다. 그 다음에, 객체 특징 표현에 따라 리소스 추천 플랫폼의 데이터베이스로부터 타깃 객체의 관심사 또는 취미를 충족하는 리소스 데이터의 일부를 선택하여, 이어서 리소스 데이터의 일부로부터 리소스 데이터를 선택하고 선택된 리소스 데이터를 타깃 객체에 게 추천한다. 본 출원의 실시예에서는 전이 학습을 참조하여, 제1 도메인 내의 풍부한 지식 및 정보를 사용하여 제2 도메인 내의 데이터를 풍부하게 하고, 이용 가능한 정보를 증가시키며, 제2 도메인에서의 희소한 샘플 수량 문제를 완 화하고, 트레이닝된 관심 정렬 모델의 모델 성능을 보장하는 것을 알 수 있다. 트레이닝된 관심 정렬 모델을 상 호작용 데이터가 적은 제2 도메인에 적용할 때에도, 객체에 대해 더 정확한 특징 표현을 생성할 수 있으므로, 정확한 특징 표현에 기반하여 객체에 추천되는 리소스 데이터가 객체의 개인화된 요구를 충족시키고, 정확한 리 소스 추천이 구현된다. 본 출원의 실시예에서 제공하는 모델 트레이닝 솔루션을 쉽게 이해할 수 있도록 하기 위해, 이하에서는 도 1a에 도시된 리소스 추천 시스템을 참조하여 본 출원의 실시예에 관련된 리소스 추천 시나리오를 간략히 설명한다. 도 1a에 도시된 바와 같이, 리소스 추천 시스템은 단말, 서버, 서버를 포함한다. 본 출원의 실 시예에서는 단말, 서버, 서버의 수량과 명칭이 제한되지 않는다. 단말은 리소스 추천 플랫폼에 등록되어 있으면서 또한 리소스 데이터가 배포될 리소스 수신자가 사용하는 단말 디바이스일 수 있다. 단말 디바이스는 스마트폰(예를 들어, 안드로이드 시스템이 설치된 스마트폰 또는 인 터네트워킹 운영 체제(internetworking operating system, IOS)가 설치된 스마트폰), 태블릿 컴퓨터, 휴대용 개인용 컴퓨터, 모바일 인터넷 디바이스(mobile Internet device, MID), 차량 장착 디바이스, 헤드 장착 디바이 스 등을 포함할 수 있지만, 이에 제한되지는 않는다. 본 출원의 실시예에서는 단말 디바이스의 유형이 제한되지않는다. 설명은 다음과 같다. 리소스 추천 플랫폼, 특히 리소스 추천 플랫폼을 탑재한 애플리케이션 프로그램은 단말 디바이스에 배포된다. 리소스 추천 플랫폼은 제2 도메인 내의 추천 플랫폼일 수 있다. 이런 방식으로, 리 소스 수신자는 단말 디바이스에 배치된 리소스 추천 플랫폼을 통해 제2 도메인 내의 리소스 데이터를 수신하는 등의 작동(operation)을 수행할 수 있다. 서버는 단말에 대응하는 서버, 구체적으로 단말에 배치된 리소스 추천 플랫폼의 백엔드 서버이 며, 단말과 상호작용하여 단말 내의 리소스 추천 플랫폼에 대한 컴퓨팅 및 애플리케이션 서비스 지원 을 제공하도록 구성된다. 서버는 제1 도메인에 대한 리소스 추천 플랫폼에 대응하는 백엔드 서버일 수 있 다. 서버는 모델 트레이닝을 위한 제1 도메인 데이터를 제공하기 위해 서버와 데이터 통신을 수행할 수 있다. 서버(예를 들어, 서버 및 서버)는 독립적인 물리적 서버일 수도 있고, 복수의 물리적 서버 로 형성된 서버 클러스터 또는 분산 시스템일 수도 있으며, 클라우드 서비스, 클라우드 데이터베이스, 클라우드 컴퓨팅, 클라우드 기능, 클라우드 스토리지, 네트워크 서비스, 클라우드 통신, 미들웨어 서비스, 도메인 이름 서비스, 보안 서비스, 콘텐츠 전송 네트워크(Content Delivery Network, CDN), 빅데이터, AI 플랫폼과 같은, 기본적인 클라우드 컴퓨팅 서비스를 제공하는 클라우드 서버일 수 있다. 단말과 서버는 유선 또는 무선 통 신 방식으로 직접 또는 간접적으로 연결될 수 있다. 이는 본 출원에서 제한되지 않는다. 서버는 데이터베이스를 더 포함한다. 데이터베이스는 제2 도메인(즉, 타깃 도메인)의 리소스 추천 플랫폼에 포함된 모든 리소스 데이터, 객체, 객체와 리소스 데이터 간의 객체(사용자-항목) 상호작용 데이 터 등을 저장하도록 구성될 수 있다. 예를 들어, 비디오 추천 시나리오에서, 비디오 플랫폼은 객체 1과 객체 2 를 포함하며, 객체 1은 비디오 1과 비디오 2를 클릭하고, 객체 2는 비디오 1과 비디오 3을 클릭한다. 이 경우, 객체 1-비디오 1(객체 1이 비디오 1을 트리거함을 지시함), 객체 1-비디오 2(객체 1이 비디오 2를 트리거함을 지시함), 객체 2-비디오 1(객체 2가 비디오 1을 트리거함을 지시함), 객체 2-비디오 2(객체 2가 비디오 2를 트 리거함을 지시함)와 같은 객체와 비디오 간의 상호작용 데이터가 데이터베이스에 저장될 수 있다. 마찬가지로, 서버는 데이터베이스도 포함한다. 데이터베이스는 제1 도메인(즉, 소스 도메인)의 리소스 추 천 플랫폼에 포함된 모든 리소스 데이터, 객체, 객체와 리소스 데이터 간의 객체 상호작용 데이터를 저장하도록 구성될 수 있다. 객체 상호작용 데이터의 구체적인 내용에 대해서는 제2 필드에 대한 관련 설명을 참조할 수 있 으며, 여기에서는 자세한 내용을 다시 설명하지 않는다. 리소스 추천 시스템에는 데이터 희소성 문제와 콜드 스타트(cold start) 문제라는 두 가지 장기적인 문제가 있 다. 데이터 희소성 문제는 객체와 리소스 데이터 간의 객체 상호작용 데이터가 거의 없다는 것을 의미한다. 이 로 인해 적은 양의 객체 상호작용 데이터만으로는 객체의 관심사나 리소스 데이터의 특징을 잘 포착하기 어렵다. 콜드 스타트 문제는 리소스 추천 플랫폼에 새로 등록되거나 로그인된 객체, 또은 리소스 추천 플랫폼에 새로 업로딩되거나 게시된 리소스 데이터에 대한 객체 상호작용 데이터가 없는 경우를 지칭한다. 콜드 스타트에 서는 데이터가 희소하고 객체 상호작용 데이터가 부족하기 때문에, 객체와 리소스 데이터 간의 객체 상호작용 데이터에 기반하여 추천을 하는 기존 추천 알고리즘은 두 경우 모두에 적절한 추천을 하기 어렵다. 이와 달리, 본 출원의 실시예는 전이 학습을 참조하여 관심 정렬 모델의 모델 트레이닝을 수행하며, 즉, 제1 도메인 내의 풍부한 지식과 정보를 활용하여 제2 도메인의 성능을 향상시키고 제2 도메인에서 필요한 트레이닝 샘플의 수량 을 감소시키는 것을 지원함으로써, 추천 시나리오에서 데이터 희소성과 콜드 스타트로 인해 발생하는 적은 수량 의 트레이닝 샘플 문제가 잘 해결된다. 이런 방식으로, 크로스-도메인 트레이닝을 통해 획득되는 관심 정렬 모 델을 제2 도메인에 적용하더라도, 객체 상호작용 데이터 없거나 객체 상호작용 데이터가 희소한 객체에 대해서 도 정확한 특징 표현을 생성하고, 정확한 특징 표현에 기반하여 사용자에게 리소스 데이터(즉, 타깃 도메인에 포함된 리소스)를 추천할 수 있다. 본 출원의 실시예에서 제공하는 모델 트레이닝 솔루션은 리소스 추천 시나리 오에 적용될 수 있으며, 특히 데이터 희소성 시나리오나 콜드 스타트 시나리오에 적용할 경우 모델 트레이닝에 더 나은 효과가 있다는 것을 알 수 있다. 본 출원의 실시예에서 제공되는 모델 트레이닝 솔루션은 도 1a에 도시된 아키텍처에서 단말과 서버 중 하나 또는 둘 다에 의해 수행될 수 있다. 다시 말해, 본 출원의 실시예에서 실행 주체로서의 전자 디바이스 는 단말 및 서버 중 적어도 하나일 수 있다. 전술한 관심 정렬 모델의 트레이닝 프로세스는 서버 에 의해 수행된다. 도 1a에 도시된 바와 같이, 트레이닝된 관심 정렬 모델은 서버에 직접 배포될 수 있으므로, 서버는 리소스가 배포될 때마다 트레이닝된 관심 정렬 모델을 호출하여 리소스 추천을 구현할 수 있다. 이러한 구현에 따르면, 본 출원의 실시예에서 제공된 솔루션을 수행하도록 구성된 실행 주체로서의 전 자 디바이스는 서버이다. 트레이닝된 관심 정렬 모델은 다르게는 단말에 배치될 수 있다. 도 1b에 도 시된 바와 같이, 관심 정렬 모델이 서버에서 트레이닝된 후, 트레이닝된 관심 정렬 모델은 단말로 전송되고, 트레이닝된 관심 정렬 모델은 단말에 배포된다. 이 경우, 본 출원의 실시예에서 제공하는 모델 트 레이닝 솔루션의 실행 주체로서의 전자 디바이스는 단말과 서버를 포함한다. 관심 정렬 모델이 단말 에 의해 트레이닝되면, 트레이닝된 관심 정렬 모델은 단말에 직접 배포될 수 있다. 이 경우, 본 출원 의 실시예에서 제공하는 모델 트레이닝 솔루션의 실행 주체로서의 전자 디바이스는 단말을 포함한다. 도 1a 및 도 1b는 각각 본 출원의 실시예에 따른 단순한 예시적 리소스 추천 시스템의 아키텍처의 개략도이다. 실제 적용에서는 아키텍처가 적응적으로 변경될 수 있다. 예를 들어, 본 출원의 실시예에서는 복수의 제1 도메 인이 제공될 수 있다. 다시 말해, 본 출원의 실시예는 복수의 소스 도메인에 적응할 수 있다. 이런 방식으로 더 많은 도메인에 대한 정보를 사용하여 타깃 도메인에 대한 학습을 지원할 수 있다. 이 경우, 아키텍처에 포함되 는 서버의 수량도 그에 따라 증가한다. 또한, 본 출원의 실시예를 특정 제품이나 기술에 적용할 때, 예를 들어, 리소스 데이터에 대한 리소스 추천을 수행할 때, 타깃 객체의 속성 정보(나이, 성별, 이름 또는 기타 정보 등) 는 필연적으로 획득되어야 한다. 이 경우에는 타깃 객체의 허가 또는 동의를 받아야 하며, 관련 데이터의 수집, 이용, 처리에 있어서는 관련 국가, 지역의 관련 법률, 규정, 표준을 준수해야 한다. 기술한 모델 트레이닝 솔루션에 기반하여, 본 출원의 실시예에서 제공하는 모델 트레이닝 솔루션은 주로 두 가 지 측면을 포함한다는 것을 알 수 있다. 일 측면에서, 트레이닝된 관심 정렬 모델은 모델 트레이닝을 통해 획득 된다. 다른 측면에서는, 트레이닝된 관심 정렬 모델(즉, 모델 적용)을 사용하여 리소스 추천이 수행된다. 본 출 원의 실시예에서 이후 제공되는 모델 트레이닝 방법의 방법 작동을 더 잘 이해할 수 있도록, 본 출원의 실시예 에 따른 관심 정렬 모델의 모델 구조의 개략도를 먼저 도 2를 참조하여 아래에서 제시된다. 도 2에 도시된 바와 같이, 본 출원의 이 실시예에서 제공하는 관심 정렬 모델(또는 객체 관심 정렬 모델이라 함)은 단일-도메인 특 징 추출 모듈, 크로스-도메인 정렬 모듈, 및 인트라-도메인 정렬 모듈을 포함할 수 있다. 단일-도메인 특징 추출 모듈은 단일 도메인(예를 들어, 특정 도메인) 내의 도메인 데이터에 대한 특징 추출을 수행하여 단일 도메인의 도메인 특징 표현을 획득하도록 구성된다. 실제 적용에서 사용되는 도메인의 수량이 상 이하므로, 단일-도메인 특징 추출 모듈의 수량도 상이하다. 예를 들어, 하나의 소스 도메인(즉, 제1 도메인)과 하나의 타깃 도메인(즉, 제2 도메인)이 포함될 때, 단일-도메인 특징 추출 모듈은 제1 특징 추출 모듈과 제2 특 징 추출 모듈을 포함할 수 있다. 제1 특징 추출 모듈은 제1 도메인 내의 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현을 획득하도록 구성되고, 제2 특징 추출 모듈은 제2 도메인 내의 제2 도메인 데 이터에 대한 특징 추출을 수행하여 제2 도메인 특징 표현을 획득하도록 구성된다. 제1 도메인에 대응하는 제1 특징 추출 모듈은 사전 트레이닝(pre-training)을 통해 획득된다. 구체적으로, 사전 트레이닝 스테이지에서는 제1 특징 추출 모듈이 제1 도메인의 객체의 관심사나 취미를 트레이닝하도록 사전 트레이닝될 수 있다. 이런 방 식으로, 제1 도메인의 객체 상호작용 데이터의 도움으로, 제1 특징 추출 모듈과 제1 도메인의 객체 및 리소스 데이터의 특징 표현이 최적화될 수 있다. 제2 도메인에서 태스크 학습이 수행될 때, 사전 트레이닝된 제1 특징 추출 모듈은 제2 도메인의 학습 태스크로 직접 전이된다. 다시 말해, 본 출원의 실시예에서는 트레이닝된 제1 특징 추출 모듈을 전이 학습의 아이디어에 기반한 초기점으로 사용하고, 제2 도메인의 태스크 학습을 위한 모델 을 개발하는 프로세스에서 재사용한다. 이런 방식으로, 트레이닝된 제1 특징 추출 모듈에 기반하여 생성된 객체 의 특징 표현은 관심 정렬 모델을 최적화하기 위한 지도 학습을 위한 실제 레이블(true label)로 사용될 수 있 다. 크로스-도메인 정렬 모듈 또는 크로스-도메인 관심 정렬 모듈, 인터-도메인 정렬 모듈 또는 이와 유사한 것으로 지칭되는 것은, 제2 도메인 내 두 객체 간의 관심 관계(본 출원의 이 실시예에서는 제2 주목 유사도라고 지칭될 수 있음)와 제1 도메인 내 대응하는 두 객체 간의 관심 관계(본 출원의 이 실시예에서는 제1 주목 유사도라고 지칭될 수 있음) 간의 관심 정렬 처리를 수행하도록 구성될 수 있다. 다시 말해, 본 출원의 이 실시예에서, 인 터-도메인 정렬 모듈은 제2 도메인 내 객체 간의 관심 유사도를 제1 도메인 내 객체 간의 관심 유사도와 맞춰 정렬시키도록 설계된다. 이런 방식으로, 제1 도메인 내 객체 간의 관심 관계를 제2 도메인으로 전이할 수 있으 며, 이에 따라 제2 도메인의 관심 학습 프로세스를 안내할 수 있다. 또는 인트라-도메인 관심 정렬 모듈이라고도 하는 인트라-도메인 정렬 모듈은 제1 도메인의 객체 그래프(객체의 이미지만 포함)와 제1 도메인의 객체 리소스 그래프(객체 및 객체가 관심 있는 리소스 데이터 포함) 간의 관심 정렬 처리를 수행하고, 제2 도메인의 객체 그래프와 제2 도메인의 객체 리소스 그래프 간의 관심 정렬 처리를 수행하도록 구성될 수 있다. 다시 말해, 본 출원의 이 실시예에서, 인트라-도메인 정렬 모듈은 단일 도메인 내 객체들의 관심 관계를 정렬하도록 설계됨으로써, 단일 도메인 내에서 유사한 관심사나 취미를 가진 객체 간의 특징 표현이 서로 더 가깝게 된다. 따라서 이후 관심 정렬 모델을 사용할 때, 객체에 객체 상호작용 데이터가 없거나 객체 상호작용 데이터가 거의 없더라도, 그 객체와 객체 상호작용 데이터가 있는 다른 객체 간의 관심관계를 여전히 분석하여, 다른 객체의 정확한 특징 표현에 기반하여 그 객체에 대한 정확한 특징 표현을 생성할 수 있다. 본 출원의 실시예에서 제공하는 모델 트레이닝 솔루션에서, 객체의 관심 정렬은 인터-도메인 관심 정렬 및 인트 라-도메인 관심 정렬을 포함할 수 있다. 인터-도메인 관심 정렬은 제2 도메인 내 두 객체 간의 관심 유사성을 제1 도메인 내 두 객체 간의 관심 유사성과 맞춰 정렬하고, 인트라-도메인 관심 정렬은 두 객체 간의 예측된 관 심 유사성을 단일 도메인에 대한 두 객체 간의 실제 관심 유사성과 맞춰 정렬시키는 것이다. 실제 적용에서, 모 델 트레이닝 솔루션에는 위에 제시된 두 가지 유형의 관심 정렬 중 적어도 하나가 포함될 수 있다. 설명의 편의 를 위해, 다음 실시예는 모델 트레이닝 솔루션에 인터-도메인 관심 정렬과 인트라-도메인 관심 정렬이 모두 포 함된 예를 사용하여 설명된다. 설명은 다음과 같다. 도 2를 참조하는 관심 정렬 모델의 모델 구조에 대한 간단한 설명에 기반하여, 이하에서는 첨부 도면을 참조하 여 본 출원의 실시예에서 제공하는 보다 세부적인 모델 트레이닝 방법의 방법 작동을 설명하며, 구체적으로 모 델 트레이닝 방법에 포함되는 모델 트레이닝 프로세스 및 모델 적용 프로세스를 설명한다. 전이 학습의 트레이닝 방법에 따른 관심 정렬 모델의 트레이닝에 대한 구체적인 트레이닝 프로세스는 도 3을 참 조할 수 있다. 도 3은 본 출원의 실시예에 따른 모델 트레이닝 방법의 개략적인 흐름도이다. 모델 트레이닝 방 법은 전술한 전자 디바이스에 의해 수행될 수 있다. 본 방법에는 작동(S301 내지 S304)이 포함될 수 있지만 이 에 제한되지는 않는다. S301: 데이터 세트를 획득한다. 데이터 세트는 관심 정렬 모델을 트레이닝하기 위해 구성된 샘플 세트이다. 데이터 세트는 제1 도메인의 제1 도 메인 데이터와 제2 도메인의 제2 도메인 데이터를 포함할 수 있다. 제1 도메인은 풍부한 객체 상호작용 데이터 를 포함하는 소스 도메인이고, 제2 도메인은 적은 객체 상호작용 데이터를 포함하는 학습 대상(to-be-learned) 타깃 도메인이다. 제1 도메인의 제1 도메인 데이터는 적어도 하나의 객체와 제1 도메인에서 각 객체가 관심 있 는 제1 리소스 데이터를 포함한다. 제1 도메인 데이터에 포함되는 적어도 하나의 객체는 제1 도메인에 대응하는 리소스 추천 플랫폼에 등록되어 있거나 일시적으로 로그인되어 있는 객체이다. 제1 도메인 내 적어도 하나의 객 체 각각이 관심 있는 제1 리소스 데이터는 제1 도메인 내 객체에 의해 트리거된 부분 리소스 데이터를 참조한다. 여기에서 설명하는 객체가 제1 리소스 데이터를 트리거하는 것은 다음을 포함할 수 있지만 이에 제한 되지는 않는다: 객체가 제1 리소스 데이터를 클릭하며, 객체가 제1 리소스 데이터에 댓글을 달고(또는 전달하거 나, 수집하거나 또는 좋아요를 누름), 객체가 지속 기간 임계값(예를 들어, 10초)을 초과하는 지속 기간 동안 제1 리소스 데이터를 탐색한다. 마찬가지로, 제2 도메인의 제2 도메인 데이터은 적어도 하나의 객체와 제2 도메 인에서 각 객체가 관심 있는 제2 리소스 데이터를 포함한다. 제2 도메인 데이터에 포함된 적어도 하나의 객체는 위에 언급된 제1 도메인 데이터에 포함된 적어도 하나의 객체와 동일하다. 다시 말해, 제1 도메인 데이터와 제2 도메인 데이터에 포함된 중복 데이터는 객체이다. 이런 방식으로, 제2 도메인 내 객체에 대한 객체 상호작용 데 이터가 적더라도, 제1 도메인 내 객체에 대한 풍부한 객체 상호작용 데이터를 여전히 사용하여 제2 도메인에서 지도 학습을 안내할 수 있다. 대응하는 객체와 관련된 제2 리소스 데이터의 관련 내용에 대해서는 제1 도메인에 관한 전술한 관련 설명을 참조할 수 있으며, 여기서는 자세한 내용을 다시 설명하지 않는다. 데이터 세트 내의 제1 도메인 데이터와 제2 도메인 데이터는 그래프 형태로 존재할 수 있다. 여기에서 그래프는 노드와 연결 에지(또는 줄여서 에지)로 구성된 네트워크 구조 데이터를 지칭한다. 그래프의 노드에는 객체, 제1 리소스 데이터, 제2 리소스 데이터가 포함될 수 있다. 연결 에지란 노드 사이의 연결선, 구체적으로는 객체 노 드와 객체가 관심 있는 리소스 데이터 노드를 연결하여 획득되는 연결선을 지칭한다. 데이터 세트에 포함된 데 이터가 객체, 제1 리소스 데이터, 제2 리소스 데이터와 같은 유형을 포함하고, 즉 노드 유형과 연결 에지 유형 의 합이 2보다 크다는 점을 고려하면, 본 출원의 이 실시예에서 구성된 그래프는 이기종 그래프(또는 이기종 네 트워크라고 함)이다. 이기종 그래프의 노드와 연결선의 유형은 단일하지 않고 다양하다. 데이터 세트 내의 제1 도메인 데이터와 제2 도메인 데이터가 이기종 그래프 형태로 존재하는 개략도에 대해서는 위에 주어진 도 2를 참조할 수 있다. 도 2에 도시된 바와 같이, 데이터 세트에는 삼각형, 원, 사각형과 같은 세 가지 유형의 노드가 포함된다. 삼각형은 제1 도메인 데이터 내의 제1 리소스 데이터 노드를 나타내고, 원은 객 체 노드(예를 들어, 노드 u1은 객체 1에 대응하고, 노드 u2는 객체 2에 대응하며, 노드 u3은 객체 3에 대응함) 를 나타내며, 사각형은 제2 도메인 데이터 내의 제2 리소스 데이터 노드를 나타낸다. 삼각형 노드와 원형 노드 사이의 연결 에지는 연결 에지에 의해 연결된 삼각형 노드에 대응하는 제1 리소스 데이터에서 원형 노드에 대응 하는 객체가 관심 대상임을 지시한다. 마찬가지로, 원형 노드와 사각형 노드 사이의 연결 에지는 연결 에지로연결된 사각형 노드에 대응하는 제2 리소스 데이터에서 원형 노드에 대응하는 객체가 관심 대상임을 지시한다. 트레이닝된 관심 정렬 모델(즉, 객체 관심 정렬에 기반한 크로스-도메인 추천 알고리즘)을 배포하는 온라인 효 과를 테스트하기 위해(콜드 스타트 시나리오에서 객체에 대한 리소스 추천이 의도되면, 콜드 스타트 객체의 추 천 효과는 주로 온라인 테스트 동안 관찰됨), 본 출원의 실시예는 리소스 추천 플랫폼의 리콜(recall) 모듈에서 관심 정렬 모델을 배포하는 것을 지원한다. 이런 방식으로, 업데이트된 객체 상호작용 데이터를 스트리밍하는 것을 관심 정렬 모델에 대한 모델 트레이닝을 수행하는 샘플 데이터로 사용할 수 있다. 다시 말해, 본 출원의 실시예에서는 리소스 추천 플랫폼 내의 스트리밍 업데이트된 객체 상호작용 데이터를 모델 트레이닝을 위한 데 이터 세트로 획득한다. 다시 말해, 데이터 세트에 포함된 제1 도메인 데이터와 제2 도메인 데이터는 동적으로 업데이트된다. 따라서 관심 정렬 모델이 동적으로 업데이트된 데이터 세트에 따라 트레이닝될 때, 관심 정렬 모 델도 동적으로 변경된다. 따라서 관심 정렬 모델은 리소스 추천 플랫폼에서 객체의 관심사나 취미의 변화에 동 적으로 적응할 수 있고, 이에 따라 관심 정렬 모델이 리소스 추천 플랫폼에서 객체에 대한 정확한 특징 표현을 항상 생성하고, 객체의 동적으로 변화하는 개인화된 리소스 요건을 충족하는 것을 보장할 수 있다. S302: 관심 정렬 모델을 호출하여 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현을 획 득하고; 관심 정렬 모델을 호출하여 제2 도메인 데이터에 대한 특징 추출을 수행하여 제2 도메인 특징 표현을 획득한다. 관심 정렬 모델을 트레이닝하기 위한 데이터 세트가 획득된 후, 본 출원의 실시예는 대응하는 데이터 세트를 사 용하여 단일 도메인 특징 표현을 수행하는 것을 지원한다. 다시 말해, 데이터 세트에 기반하여 제1 도메인 데이 터와 제2 도메인 데이터에 대한 특징 추출(또는 특징 표현이라고 함)을 각각 수행하여, 제1 도메인의 제1 도메 인 특징 표현과 제2 도메인의 제2 도메인 특징 표현을 획득한다. 임베딩 벡터를 사용하여 임의의 도메인의 도메인 특징 표현을 구현할 수 있다. 따라서 특징 표현은 임베딩 표현 이라고도 지칭될 수 있다. 임베딩 벡터는 객체의 특징이나 속성을 나타내는 데 사용되는 저차원 벡터이다. 임의 의 두 객체의 임베딩 벡터 사이의 거리는 임의의 두 객체 간의 유사도를 나타낼 수 있다. 예를 들어, 두 객체의 임베딩 벡터 사이의 거리가 거리 임계값보다 작으면, 두 객체는 비교적 유사하다(예를 들어, 특징이나 속성이 유사함). 두 객체의 임베딩 벡터 사이의 거리가 거리 임계값보다 크거나 같으면, 두 객체 간의 유사도는 상대적 으로 낮다. 본 출원의 실시예에서, 임의의 도메인의 도메인 특징은 객체의 특징 표현과 임의의 도메인 내의 리 소스 데이터의 특징 표현을 포함할 수 있다. 예를 들어, 제1 도메인의 제1 도메인 특징은 객체의 특징 표현과 제1 리소스 데이터의 특징 표현을 포함할 수 있다. 객체의 특징 표현은 객체의 특징이나 속성(예를 들어, 제1 도메인에서 객체의 관심사나 취미)을 나타내기 위해 구성될 수 있다. 제1 리소스 데이터의 특징 표현은 리소스 데이터의 특징이나 속성(예를 들어, 리소스 데이터의 리소스 유형)을 나타내기 위해 구성될 수 있다. 임의의 두 객체의 특징 표현 사이의 거리는 임의의 두 객체 간의 관심 유사성을 나타내기 위해 구성될 수 있다. 본 출원의 실시예에서 단일-도메인 데이터에 대한 특징 추출 프로세스는 유사하다. 다시 말하자면, 제1 도메인 데이터에서 특징을 추출하여 제1 도메인 특징 표현을 획득하는 프로세스는 제2 도메인 데이터에서 특징을 추출 하여 제2 도메인 특징 표현을 획득하는 프로세스와 유사하다. 다음은 제1 도메인의 특징 표현과 제2 도메인의 특징 표현에 대한 대략적인 특징 추출 프로세스를 각각 제공하고, 제2 도메인 데이터에 대한 특징 추출을 수행 하는 구체적인 구현 프로세스를 제2 도메인의 특징 표현을 예로 들어 자세히 설명한다. 제1 도메인 데이터에 대 한 특징 표현을 수행하여 제1 도메인 특징 표현을 획득하는 프로세스는: 제1 도메인 데이터에 기반하여 제1 도 메인의 객체 리소스 그래프를 구성하는 단계 - 제1 도메인의 객체 리소스 그래프는 각 객체와 각 제1 리소스 데 이터가 노드이고 객체와 제1 리소스 데이터 간의 제1 관심 관계가 연결 에지인 그래프이고, 객체와 제1 리소스 데이터 간에 제1 관심 관계가 있다는 것은 객체가 제1 리소스 데이터에 대한 상호작용 데이터를 생성한다는 것 을 의미할 수 있음 -; 관심 정렬 모델을 호출하여 제1 도메인의 객체 리소스 그래프에 대한 그래프 인코딩 처리 를 수행하여, 각 객체의 제1 객체 특징 표현과 각 제1 리소스 데이터의 제1 리소스 특징 표현을 획득하는 단계; 및 각 객체의 제1 객체 특징 표현과 각 제1 리소스 데이터의 제1 리소스 특징 표현을 사용하여 제1 도메인 특징 표현을 형성하는 단계를 포함한다. 제2 도메인 데이터에 대한 특징 표현을 수행하여 제2 도메인 특징 표현을 획득하는 프로세스는 작동 및 작 동 를 포함할 수 있지만 이에 제한되지 않는다. 제2 도메인 데이터에 기반하여 제2 도메인의 객체 리소스 그래프를 구성하며, 제2 도메인의 객체 리소스 그 래프는 각 객체와 각 제2 리소스 데이터가 노드이고 객체와 제2 리소스 데이터 간의 제2 관심 관계가 연결 에지 인 그래프이다. 여기에서 제2 도메인의 객체 리소스 그래프는 제2 도메인의 이분 그래프(bipartite graph)(또는특수한 이기종 그래프인 바이그래프(bigraph)라고도 함)를 지칭할 수 있다. 위에서 설명한 바와 같이, 데이터 세트는 이기종 그래프의 형태로 표현될 수 있다. 이기종 그래프의 임의의 노드에 대해, 임의의 노드에 대한 연 결 에지를 갖는 노드를 임의의 노드의 이웃 노드라고 한다. 도 2에 도시된 u1 노드의 이웃 노드는 u1 노드에 대 한 연결 에지를 갖는 두 개의 제1 리소스 데이터와 두 개의 제2 리소스 데이터를 포함한다. 이 경우, 여기에서 제2 도메인 데이터에 기반하여 제2 도메인의 객체 리소스 그래프를 구성하는 프로세스는 다음을 포함할 수 있다: 데이터 세트의 이기종 그래프에 대해 이웃 샘플링을 수행하여 제1 도메인의 객체 리소스 그래프를 획득한 다. 이웃 샘플링에는 데이터 세트의 이기종 그래프에서 객체 노드의 모든 이웃 노드(이 경우, 제1 리소스 데이 터 노드와 제2 리소스 데이터 노드)로부터 일부 이웃 노드를 선택하는 프로세스가 포함될 수 있다. 이 경우, 본 출원의 실시예는 데이터 세트의 이기종 그래프에서 각 객체 노드의 이웃 샘플링을 지원하여, 각 객체 노드와 샘 플링된 각 제2 리소스 데이터에 기반하여 제2 도메인의 객체 리소스 그래프를 구성한다. 도 4에 도시된 바와 같이, 데이터 세트는 객체 노드 u1, 객체 노드 u2, 및 객체 노드 u3를 포함한다. 또한, 객 체 노드 u1의 이웃 노드는 제1 리소스 데이터 노드 j1, 제1 리소스 데이터 노드 j2, 제2 리소스 데이터 노드 i1, 및 제2 리소스 데이터 노드 i2를 포함하고, 객체 노드 u2의 이웃 노드는 제1 리소스 데이터 노드 j2, 제1 리소스 데이터 노드 j3, 및 제2 리소스 데이터 노드 i1을 포함하며, 객체 노드 u3의 이웃 노드는 제1 리소스 데 이터 노드 j3, 제1 리소스 데이터 노드 j4, 제2 리소스 데이터 노드 i1, 및 제2 리소스 데이터 노드 i2를 포함 한다. 그 다음에, 제2 도메인 데이터에 기반하여 데이터 세트의 이기종 그래프에 대해 이웃 샘플링을 수행한 후, 샘플링을 통해, 객체 노드 u1의 이웃 노드가 제2 리소스 데이터 노드 i1과 제2 리소스 데이터 노드 i2이고, 객체 노드 u2의 이웃 노드가 제2 리소스 데이터 노드 i1이며, 객체 노드 u3의 이웃 노드가 제2 리소스 데이터 노드 i1과 제2 리소스 데이터 노드 i2임을 알 수 있다. 이 경우, 제2 도메인의 객체 리소스 그래프는 객체 노드 와 각 객체 노드가 관심 있는 제2 리소스 데이터에 기반하여 구성될 수 있다. 객체 리소스 그래프에서 객체 노 드와 제2 리소스 데이터 노드 사이의 연결 에지는, 객체 노드에 대응하는 객체가 제2 리소스 데이터 노드에 대 응하는 제2 리소스 데이터와 상호작용적인 행동을 한다는 것을 지시한다. 관심 정렬 모델을 호출하여 제2 도메인의 객체 리소스 그래프에 대한 그래프 인코딩 처리를 수행하여, 각 객체의 제2 객체 특징 표현과 각 제2 리소스 데이터의 제2 리소스 특징 표현을 획득한다. 구체적으로, 본 출원 의 실시예는 그래프 인코더를 사용하여 객체 리소스 그래프의 풍부한 의미 정보를 캡처하고, 노드 수준 주목 메 커니즘을 추가하여 각 이웃 노드의 중요성을 구분하는 것을 지원한다. 예시적인 그래프 인코딩 학습 아키텍처 (또는 제2 특징 추출 모듈의 아키텍처)의 개략도에 대해서는 도 5를 참조할 수 있다. 도 5에 도시된 바와 같이, 제2 특징 추출 모듈은 GAT를 포함한다. GAT에 포함된 주목 메커니즘을 통해, 제2 도메인의 입력된 객체 리소스 그래프에서 각 주목 노드에 대한 특징 표현이 수행될 수 있다. 여기에서의 주목 노드는 객체 리소스 그래프 내 의 임의의 노드, 예컨대 임의의 객체 노드나 임의의 제2 리소스 데이터 노드를 지칭할 수 있다. 제2 도메인의 객체 리소스 그래프가 제2 특징 추출 모듈에 입력된 후, GAT는 객체 노드와 제2 리소스 데이터 노 드를 각각 주목 노드로 사용하도록 호출되어 주목 노드의 이웃 노드의 중요성을 구별하고, 이에 따라 각 주목 노드의 특징 표현을 획득할 수 있다. 주목 노드가 객체 노드일 때, 객체 노드의 이웃 노드는 객체 노드에 대한 연결 에지를 갖는 제2 리소스 데이터 노드를 지칭한다. 각 이웃 노드의 중요성을 구별하는 것은, 각 제2 리소스 데이터에 대해 객체 노드에 대응하는 객체의 호감도(liking degree)(또는 관심 또는 취미의 정도라고도 함)를 결정하는 것을 의미할 수 있다. 주목 노드가 제2 리소스 데이터 노드일 때, 이웃 노드는 제2 리소스 데이터 노 드에 대한 연결 에지를 갖는 객체 노드를 지칭한다. 각 이웃 노드의 중요성을 구별하는 것은, 제2 리소스 데이 터 노드에 대응하는 제2 리소스 데이터에 대한 각 객체 노드에 대응하는 객체의 호감도를 결정하는 것을 의미할 수 있다. GAT를 호출하여 각 주목 노드의 특징 표현을 결정하는 구체적인 구현 프로세스들은 유사하다. 본 출원의 실시예 에서는, 제2 도메인 데이터에 포함된 적어도 하나의 객체 중 임의의 하나를 트레이닝 객체로 나타내는 예를 사 용하여, 그래프 주목 메커니즘을 호출하여 트레이닝 객체의 각 이웃 노드의 중요성을 구분하여, 트레이닝 객체 에 대응하는 제2 객체 특징 표현을 획득하는 구체적인 구현 프로세스가 주어진다. 구현 프로세스에는 작동(s11 ~ s13)이 포함될 수 있지만 이에 제한되지는 않는다. s11: 제2 도메인에서 트레이닝 객체의 초기 특징 표현을 획득하고 제2 도메인에서 트레이닝 객체가 관심 있는 각 제2 리소스 데이터의 초기 특징 표현을 획득한다. 트레이닝 객체의 초기 특징 표현은 트레이닝 객체의 속성 정보(예컨대, 기본 객체 정보(예컨대, 나이, 성별, 선택된 카테고리 레이블 또는 기타 정보))에 기반하여 결정 된다. 제2 리소스 데이터의 초기 특징 표현은 제2 리소스 데이터의 속성 정보(예컨대, 제2 리소스 데이터의 업로딩 시간, 업로딩 중에 선택한 카테고리 레이블)에 기반하여 결정된다. s12: 관심 정렬 모델을 호출하여, 트레이닝 객체의 초기 특징 표현과 트레이닝 객체가 관심 있는 각 제2 리소스 데이터의 초기 특징 표현에 따라, 트레이닝 객체와 트레이닝 객체가 관심 있는 각 제2 리소스 데이터 간의 상관 도(correlation degree)를 계산한다. 트레이닝 객체와 트레이닝 객체가 관심 있는 임의의 제2 리소스 데이터 간 의 상관도는 다음: 임의의 제2 리소스 데이터에 대한 트레이닝 객체의 호감도를 나타내기 위해 구성될 수 있다. 상관도는 확률의 형태일 수 있다. 예를 들어, 상관도가 20%이며, 이는 트레이닝 객체가 제2 트레이닝 리소스 데 이터에 대한 호감도 낮음을 지시한다. 트레이닝 객체와 트레이닝 객체가 관심 있는 임의의 제2 리소스 데이터 간의 상관도를 계산하는 수식은 다음과 같다:"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 는 객체 노드 u와 제2 리소스 데이터 노드 i 간의 상관도(즉, 상관 관계)를 나타내고, 는 객체 노 드 u에 대응하는 트레이닝 객체의 초기 특징 표현을 나타내며, 는 제2 리소스 데이터 노드 i에 대응하는 제2 리소스 데이터의 초기 특징 표현을 나타내고; 는 객체 노드 u의 이웃 세트를 나타내며, 이웃 세트는 객체 노 드 u와 연결 에지를 갖는 모든 제2 리소스 데이터 노드를 포함하고, 는 객체 노드 u의 이웃 세트에 있는 임의 의 제2 리소스 데이터 노드를 나타내며, 즉, 제2 리소스 데이터 노드 i는 객체 노드 u의 이웃 세트에 있는 임의 의 제2 리소스 데이터 노드이고; LeakReLU 함수는 활성화 함수이다. 수식 에 기반하여, 본 출원의 실시예는 트레이닝 객체와 트레이닝 객체의 각 이웃의 제2 리소스 데이터 간의 상관도를 계산하는 것을 지원한다는 것을 알 수 있다. 예를 들어, 트레이닝 객체에 대응하는 객체 노드 u와 제2 리소스 데이터에 대응하는 제2 리소스 데이터 노드 i 사이의 유사도 가 계산된다. 구체적으로, 객체 노드 u 와 제2 리소스 데이터 노드 i 사이의 상관 관계가 분자로 사용되고, 객체 노드 u와 모든 이웃 제2 리소스 데이 터 노드 간의 상관 관계의 합이 분모로 사용된다. 이러한 방식으로, 제2 리소스 데이터 i에 대한 상관 관계 를 분자로 사용하고, 모든 이웃 노드의 상관 관계의 합을 분모로 사용하며, 이는 트레이닝 객체가 관심 있는 모 든 제2 리소스 데이터에서 제2 리소스 데이터 노드 i에 대응하는 제2 리소스 데이터의 비율을 빠르게 결정하는 데 도움이 되며, 이에 따라 트레이닝 객체에 대한 제2 리소스 데이터의 중요도를 결정할 수 있다. s13: 트레이닝 객체와 트레이닝 객체가 관심 있는 각 제2 리소스 데이터 간의 상관도, 제2 도메인에서의 트레이 닝 객체의 초기 특징 표현, 트레이닝 객체가 관심 있는 각 제2 리소스 데이터의 초기 특징 표현에 기반하여, 트 레이닝 객체의 제1 객체 특징 표현을 획득한다. 다시 말해, 작동(s12)에 기반하여 트레이닝 객체와 각 이웃의 제2 리소스 데이터 간의 상관도가 획득된 후, 각 제2 리소스 데이터에 대한 트레이닝 객체의 호감도가 대략적으 로 결정될 수 있다. 트레이닝 객체의 제1 객체 특징 표현, 즉 트레이닝 객체의 전반적인 관심이나 선호도를 획 득하기 위해서는, 트레이닝 객체의 제1 객체 특징 표현을 트레이닝 객체와 각 이웃의 제2 리소스 데이터 간의 상관도와 제2 리소스 데이터의 초기 특징 표현 및 트레이닝 객체에 기반하여 추가로 표현해야 하며, 이에 따라 트레이닝 객체의 전반적인 관심이나 선호도(예를 들어, 특정 유형의 리소스 데이터에 대한 선호도)를 획득할 수 있다. 트레이닝 객체의 제2 객체 특징 표현을 결정하기 위한 계산 수식은 다음과 같다:"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 는 트레이닝 객체의 제1 객체 특징 표현을 나타내고, 는 활성화 함수를 나타낸다. 위의 내용을 토대로, 기술된 작동(S11 내지 s13)에 나타낸 구체적인 구현 프로세스를 통해, GAT를 호출하여 객 체 리소스 그래프의 풍부한 의미 정보(semantic information)를 캡처할 수 있으며, 이에 따라 객체 노드에 대응 하는 객체의 관심사 또는 선호도를 설명하기 위해 각 객체 노드에 대응하는 객체의 제2 객체 특징 표현을 결정 할 수 있다. 제2 도메인의 객체 리소스 그래프에 있는 각 제2 리소스 데이터 노드에 대응하는 제2 리소스 데이터의 제2 리소 스 특징 표현을 획득하기 위해 GAT를 호출하는 구체적인 구현 프로세스는, 위에서 설명한 제1 객체 특징 표현을 획득하는 구체적인 구현 프로세스와 유사하다. 유일한 차이점은 제2 리소스 데이터의 제2 리소스 특징 표현이 계산될 때, 이웃 세트는 객체 리소스 그래프에서 제2 리소스 데이터의 제2 리소스 데이터 노드에 인접한 모든객체 노드라는 것이다. 여기서는 제2 리소스 데이터의 제2 리소스 특징 표현을 결정하는 구체적인 구현 프로세 스에 대해 자세히 설명하지 않는다. 마찬가지로, 관심 정렬 모델에서 제1 특징 추출 모듈(구체적으로 제1 특징 추출 모듈에 포함된 GAT)에 기반하여 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현(제 1 객체 특징 표현과 제1 리소스 특징 표현 포함)을 획득하는 구체적인 구현 프로세스는 위에서 제시한 제1 객체 특징 표현을 획득하는 구체적인 구현 프로세스와 유사하며, 여기서는 다시 자세한 내용을 설명하지 않는다. 제1 도메인에 대응하는 제1 특징 추출 모듈은 사전 트레이닝되며, 즉, 제1 특징 추출 모듈은 사전 트레이닝 스 테이지에서 제1 도메인의 풍부한 객체 상호작용 데이터를 사용하여 최적화되었다. 따라서 관심 정렬 모델을 트 레이닝하는 프로세스에서는 제1 도메인 데이터의 예측된 제1 도메인 특징 표현에 따라 제1 특징 추출 모듈을 최 적화할 필요가 없다. 그러나 제2 도메인에서는 객체 상호작용 데이터가 부족하다. 따라서, 트레이닝된 제1 특징 추출 모듈은 관심 정렬 모델의 모델 트레이닝 프로세스로 마이그레이션되어(migrate), 제2 특징 추출 모듈을 더 잘 최적화하는 데 도움이 된다. 이를 토대로, 전술한 작동에 기반하여 제2 도메인에서 제2 리소스 데이터 노드의 특징 표현과 객체 노드의 특징 표현을 획득한 후, 제2 리소스 데이터에 대한 객체의 호감도를 추가로 트레이닝할 필요가 있다. 구체적으로, 관 심 있는 제2 리소스 데이터에 대한 각 객체의 호감도를 예측한다. 또한, 관심 정렬 모델은 관심 있는 제2 리소 스 데이터에 대한 객체의 예측된 호감도와 대응하는 관심 있는 제2 리소스 데이터에 대한 대응하는 객체의 실제 호감도의 차이에 기반하여 트레이닝된다. 구체적으로, 제2 특징 추출 모듈은 제2 특징 추출 모듈의 특징 추출 성능을 향상시키도록 최적화되며, 즉, 최적화된 제2 특징 추출 모듈은 객체에 대한 더 정확한 객체 특징 표현을 예측할 수 있다. 첫째, 본 출원의 실시예는 제1 도메인에서의 각 객체의 제1 객체 특징 표현과 제2 도메인에서의 각 객체의 제2 객체 특징 표현을 융합하여 각 객체의 융합된 특징 표현을 획득하는 것을 지원한다. 제1 도메인에서의 객체의 관심 특징(feature of interest)과 제2 도메인에서의 객체의 관심 특징이 조합되어 객체의 관심의 표현을 보다 보완적으로 형성한다. 예를 들어, 제1 도메인에서 객체 노드 u의 제1 객체 특징 표현은 이고, 제2 도메인에 서 객체 노드 u의 제2 객체 특징 표현은 이다. 이 경우, 객체 노드 u의 제1 객체 특징 표현 과 제2 객체 특징 표현 가 더해지고, 객체 노드 u의 융합된 특징 표현이 획득될 수 있다(본 출원의 이 실시예에서, 는 객체 노드 u의 융합된 특징 표현을 나타냄). 그런 다음, 각 객체의 융합된 특징 표현과 대응하는 객체가 관심 있는 제2 리소스 데이터의 제2 리소스 특징 표 현에 대해 스플라이싱 연산을 수행하여, 대응하는 관심 있는 제2 리소스 데이터에 대한 각 객체의 예측된 주목 정도(predicted attention degree)(즉, 예측된 호감도)를 획득한다. 대응하는 관심 있는 제2 리소스 데이터에서 각 객체의 예측된 주목 정도를 획득하기 위한 계산 수식은 다음과 같다:"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 는 객체 노드 u의 융합된 특징 표현을 나타내고, 는 객체 노드 u가 관심 있는 제2 리소스 데이터 노드 i에 대응하는 제2 리소스 데이터의 제2 리소스 특징 표현을 나타내며, 는 스플라이싱 연산을 나타내고, 는 활성화 함수를 나타내며, 는 제2 리소스 데이터 노드 i에 대응하는 제2 리소스 데이터에서 객체 노드 u에 대응하는 객체의 예측된 주목 정도를 나타낸다. 마지막으로, 데이터 세트는 대응하는 관심 있는 제2 리소스 데이터의 각 객체의 실제 주목 정도를 포함하므로, 관심 있는 제2 리소스 데이터 내의 각 객체의 실제 주목 정도가 데이터 세트로부터 획득될 수 있으며, 그리고 관심 정렬 모델의 제1 손실은 대응하는 관심 있는 제2 리소스 데이터에 대한 각 객체의 실제 주목 정도와 예측 된 주목 정도의 차이에 기반하여 구성되며, 이후 제1 손실에 기반하여 관심 정렬 모델을 트레이닝한다. 본 출원 의 실시예는 최소 제곱 오차를 통해 관심 있는 제2 리소스 데이터에 대한 객체의 관심이나 선호도를 학습하는 것을 지원한다. 최소 제곱 오차의 수식은 다음과 같다:"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 R은 객체-제2 리소스 데이터 상호작용 행렬을 나타내고; 는 제2 리소스 데이터에 대한 객체의 실제 주 목 정도를 나타내며, 실제 주목 정도는 리소스 추천 플랫폼을 통해 객체가 제2 리소스 데이터를 점수 매기는 것 에 의해 획득된다. 설명한 바와 같이, 제1 도메인에 대응하는 제1 특징 추출 모듈은 사전 트레이닝된다. 제1 특징 추출 모듈이 사 전 트레이닝 스테이지에서 사전 트레이닝될 때, 제1 리소스 데이터에서 객체의 예측 주목 정도와 손실을 결정하 는 프로세스는 위에서 설명한 제2 도메인에서의 모델 트레이닝 프로세스와 유사하며, 여기서는 자세한 내용을 다시 설명하지 않는다. 구별의 용이성을 위해, 본 출원의 이 실시예에서, 제2 도메인의 제1 손실은 로 표현 된다. 설명이 다음에 제공된다. S303: 관심 정렬 모델을 호출하여 다음 처리를 수행한다: 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반 하여 제1 도메인과 제2 도메인 간의 관심 정렬 처리를 수행한다. 전술한 설명으로부터, 본 출원의 이 실시예는 도메인 간의 객체의 관심 유사도 정렬 및/또는 도메인 내의 객체 의 관심 유사도 정렬을 지원한다는 것을 알 수 있다. 아래에서는 두 가지 유형의 관심 유사도 정렬에 대한 구체 적인 구현을 각각 설명한다. 인터-도메인 관심 유사도 정렬. 본 출원의 이 실시예에서, 크로스-도메인 정렬 모듈(또는 인터-도메인 정렬 모듈이라 함)은, 도메인에서 객체들의 관심사 또는 취미 사이에 유사성이 존재한다는 현상, 즉 제1 도메인에서 관심사가 유사한 두 객체는 제2 도메인에서도 관심사가 유사한 현상에 기반하여 설계된다. 구체적으로, 제1 도 메인에는 객체에 대한 풍부한 객체 상호작용 데이터가 있고, 제1 도메인의 제1 특징 추출 모듈이 사전 트레이닝 된다는 점(즉, 특징 표현 성능이 좋다는 점)을 고려하여, 인터-도메인 객체 관심 유사도 정렬이 크로스-도메인 정렬 모듈을 사용하여 구현된다. 인터-도메인 객체 관심 유사도 정렬은 제1 도메인 내 두 객체 간의 관심 유사 도를 참 레이블(true label)로 사용하고, 제2 도메인 내 두 객체 간의 관심 유사도와 제1 도메인에서의 관심 유 사도 사이에서 객체 관심 유사도 정렬을 수행하며, 이에 따라 제2 도메인에서 관심 유사도의 학습을 안내하는 것을 의미한다. 다시 말해, 본 출원의 이 실시예에서는 객체 간의 관심 관계가 충분히 고려되고, 제1 도메인의 객체 관심 유사도가 제2 도메인으로 마이그레이션되며, 즉 제2 도메인의 객체 관심 유사도가 제1 도메인, 즉 소 스 도메인의 객체 관심 유사도와 맞춰 정렬되며, 이에 따라 제2 도메인의 관심 학습을 안내하는 목적을 달성한 다. 구체적인 구현에서, 전술한 작동을 기반으로, 제1 도메인 특징 표현에는 제1 도메인 데이터에서의 각 객체의 제 1 객체 특징 표현이 포함되고, 제2 도메인 특징 표현에는 제2 도메인 데이터에서의 각 객체의 제2 객체 특징 표 현이 포함된다는 것을 알 수 있다. 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메인 간의 관심 정렬 처리를 수행하기 위해 관심 정렬 모델을 호출하는 구체적인 구현 프로세스를 도 6을 참 조하여 아래에서 설명한다. 이 경우, 관심 정렬 처리에는 크로스-도메인 정렬 처리가 포함된다. 크로스-도메인 정렬 처리에는 작동(s21 및 s22)이 포함되지만 이에 제한되지는 않는다. s21: 관심 정렬 모델(특히, 크로스-도메인 정렬 모듈)을 호출하여, 단일 도메인에서의 각 객체의 객체 특징 표 현에 기반하여, 단일 도메인 내 각 두 객체 간의 주목 유사도를 결정한다. 구체적으로, 관심 정렬 모델이 호출 되어, 각 객체의 제1 객체 특징 표현에 기반하여 제1 도메인 내 각 두 객체 간의 제1 주목 유사도를 결정하고, 관심 정렬 모델이 호출되어, 각 객체의 제2 객체 특징 표현에 기반하여 제2 도메인 내 각 두 객체 간의 제2 주 목 유사도를 결정한다. 단일 도메인의 개인화의 상이한 정도를 고려하여, 서로 다른 도메인에서 객체 간의 관심 유사도가 크게 달라진 다. 예를 들어, 특정 단일 도메인(예를 들어, 책 도메인 또는 영화 도메인)은 개인화 정도(personalization degree)(즉, 단일 도메인에서 리소스 데이터의 리소스 유형이 크게 상이함)가 높으며, 객체 관심 유사도(동일한 리소스 데이터에서 서로 다른 객체의 관심사나 취미)는 낮다. 또 다른 예로, 특정 단일 도메인(예를 들어, 뉴스 도메인)은 개인화 정도가 낮고(즉, 단일 도메인에서 리소스 데이터의 리소스 유형이 약간 상이함), 객체 관심 유사도(즉, 동일한 리소스 데이터에서 서로 다른 객체의 관심사나 취미)가 높다. 따라서 객체의 관심 유사도를 직접 정렬하는 값은 도메인의 속성에 영향을 받으며, 따라서 객체 간의 실제 관심 유사도를 반영할 수 없다. 이 를 바탕으로, 본 출원의 실시예는 객체의 객체 특징 표현 간의 거리를 객체 간의 관심 유사도를 나타내는 확률 의 형태로 변환하는 것을 지원하며, 이에 따라 도메인 속성의 영향을 제거한다. 제1 도메인과 제2 도메인에서 각 두 객체 간의 주목 유사도를 결정하는 구체적인 구현 프로세스는 유사하다. 관 심 정렬 모델이 호출되어, 각 객체의 제1 객체 특징 표현에 기반하여 제1 도메인 내 두 객체 간의 제1 주목 유 사도를 결정하는 구체적인 구현 프로세스는, 제1 도메인 내 두 객체 간의 제1 주목 유사도가 결정되는 예를 사용하여 아래에서 설명된다. 먼저, 복수의 객체 중 각 두 객체의 제1 객체 특징 표현에 대해 거리 연산을 수행하여, 각 두 객체의 제1 객체 특징 표현 간의 거리 정보를 획득한다. 여기에서 거리 연산은 유클리드(Euclidean) 거리 연산이다. 다시 말하자 면, 제1 객체 특징 표현은 벡터 형태이며, 두 벡터 사이의 벡터 거리를 계산하여 두 벡터 사이의 거리 정보를 획득한다. 도 6에 도시된 바와 같이, 적어도 하나의 객체가 객체 u1, 객체 u2, 객체 u3을 포함하고, 객체 u1의 제1 객체 특징 표현이 이며, 객체 u2의 제1 객체 특징 표현이 이고, 객체 u3의 제1 객체 특징 표현이 라고 가정한다. 그러면, 객체 특징 표현에 유클리드 거리 연산을 수행하는 것에 의해, 객체 u1의 제1 객체 특징 표현 과 객체 u2의 제1 객체 특징 표현 사이의 유클리드 거리가 이고, 객체 u1의 제 1 객체 특징 표현 과 객체 u3의 제1 객체 특징 표현 사이의 유클리드 거리가 이며, 객체 u2의 제1 객체 특징 표현 와 객체 u3의 제1 객체 특징 표현 사이의 유클리드 거리가 임 을 알 수 있다. 그 다음, 각 두 객체의 제1 객체 특징 표현 사이의 거리 정보에 대해 확률 변환을 수행하여 각 두 객체의 제1 주목 유사도를 획득한다. 다시 말해, 객체들의 객체 특징 표현들 간의 유클리드 거리를 확률의 형태로 변환하여 주목 유사도를 나타내며, 이는 도메인의 개인화 정도가 정렬 결과에 영향을 미쳐서 객체 간의 실제 관심 유사도 를 실제로 반영할 수 없는 문제를 방지할 수 있다. 유클리드 거리를 관심 유사도를 나타내는 확률 형태로 변환 하는 수식은 다음과 같다:"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 는 객체 ui의 제1 객체 특징 표현을 나타내고, 는 객체 uj의 제1 객체 특징 표현을 나타내며; 는 객체 uj'의 제1 객체 특징 표현을 나타내고, 객체 uj'는 적어도 하나의 객체 중 어느 하나이며; 그리고 α는 학생 t의 분포 자유도를 나타내고, 는 사용자 ui와 사용자 uj 간의 관심 유사도를 나타낸다. s22: 위에서 설명한 작동(s21)에 나타낸 구체적인 구현 프로세스에 기반하여, 제1 도메인 내 각 두 객체 간의 제1 주목 유사도가 획득될 수 있으며, 임의의 두 객체 간의 제1 주목 유사도는 제1 도메인 내 임의의 두 객체의 관심사 또는 취미 간의 유사도를 나타내기 위해 구성되고; 제1 도메인 내 각 두 객체 간의 제1 주목 유사도에 기반하여 제1 도메인의 주목 유사도 분포 P가 결정될 수 있으며, 주목 유사도 분포 P는 제1 도메인 내 각 두 객 체 간의 제1 주목 유사도로 구성된 확률 분포이다. 마찬가지로, 위에서 설명한 작동(S21)에 나타낸 구체적인 구 현 프로세스에 기반하여, 제2 도메인 내 각 두 객체 간의 제2 주목 유사도를 획득할 수 있으며, 임의의 각 두 객체 간의 제2 주목 유사도는 제2 도메인 내 임의의 두 객체의 관심사 또는 취미 간의 유사도를 나타내기 위해 구성되고; 제2 도메인 내 각 두 객체 간의 제2 주목 유사도에 기반하여 제2 도메인의 주목 유사도 분포 Q가 결 정될 수 있으며, 주목 유사도 분포 Q는 제2 도메인 내 각 두 객체 간의 제2 주목 유사도로 구성된 확률 분포이 다. 본 출원의 이 실시예에서 크로스-도메인 정렬 모듈의 학습 목표는 제1 도메인의 주목 유사도 분포 P와 제2 도메 인의 주목 유사도 분포 Q 사이의 차이(또는 갭(gap))를 최소화하는 것이다. 본 출원의 실시 예는 KL 발산 (divergence)을 손실 함수로 사용하고, 제1 도메인의 주목 유사도 분포 P와 제2 도메인의 주목 유사도 분포 Q의 차이에 기반하여 관심 정렬 모델의 크로스-도메인 정렬 손실을 구성하며, 크로스-도메인 정렬 손실을 제2 손실 로 사용하여, 이에 따라 크로스-도메인 정렬 손실을 최소화함으로써 관심 정렬 모델을 최적화하는 것을 지원한 다. 상대 엔트로피라고 하는 KL 발산은 두 확률 분포 간 차이의 비대칭적 측정이다. 본 출원의 이 실시예에서, KL 발산을 손실 함수로 사용하여 관심 정렬 모델의 크로스-도메인 정렬 손실을 획득하기 위한 계산 수식은 다음 과 같다: 여기서 P는 제1 도메인의 주목 유사도 분포를 나타내고, 는 제1 도메인에서 객체 ui와 객체 uj 간의 제1 주목 유사도를 나타내며; Q는 제2 도메인의 주목 유사도 분포를 나타내고, 는 제2 도메인에서 객체 ui와 객 체 uj 간의 제2 주목 유사도를 나타낸다. 위의 내용에 기반하여, 작동(s21 및 s22)에 나타낸 특정 구현 프로세스를 기반으로 관심 정렬 모델의 크로스-도 메인 정렬 손실이 구성될 수 있다. 도메인 내 관심 유사도 정렬. 본 출원의 실시예는 주로 그래프 디코딩 타깃을 도메인 내 객체 간의 관심 유 사도를 맞춰 정렬하고, 유사한 관심사나 취미를 가진 객체들의 특징 표현을 단일 도메인에 더욱 가깝게 만든다. 따라서 모델 적용 중에, 리소스 데이터를 배포할 객체가 콜드 스타트 객체이더라도, 콜드 스타트 객체와 유사한 관심사나 취미를 가진 다른 객체의 객체 특징 표현을 분석하여 콜드 스타트 객체의 객체 특징 표현의 정확성을 보장할 수 있다. 단일-도메인 특징 추출 모듈에 입력된 도메인 데이터(이분 그래프 형태)에는 단일 도메인 내의 객체 간의 관심 유사도 관계가 포함되어 있는 것을 고려하여, 도 5에 도시된 객체 노드 u1과 객체 노드 u2가 모두 제2 리소스 데이터 i1에 연결되어 있으면, 객체 노드 u1에 대응하는 객체와 객체 노드 u2에 대응하는 객체는 유사한 관심사 또는 취미를 가지고 있는 것으로 결정된다. 단일 도메인에서 유사한 관심사나 취미를 가진 객체의 특징 표현을 보다 가깝게 만들기 위해, 본 출원의 실시예는 인트라-도메인 객체 관심 유사도 정렬을 지원한다. 인트라-도메 인 객체 관심 유사도 정렬은 단일-도메인 특징 추출 모듈의 입력 정보(단일-도메인 도메인 데이터)가 실제 레이 블로 사용된다는 것을 의미한다. 구체적으로, 단일-도메인 특징 추출 모듈에 입력된 도메인 데이터 내 두 객체 간의 관심 유사도가 실제 레이블로 사용된다. 단일 도메인 내 두 객체 간의 예측된 관심 유사도는 관심 유사도 에 맞춰 정렬되며, 즉, 도메인 내 객체들의 관심사가 맞춰 정렬되고, 도메인에서 관심사나 취미가 비슷한 객체 들의 객체 특징 표현이 더욱 가깝게 된다. 이를 바탕으로, 본 출원의 이 실시예에서는 객체들의 융합된 특징 표 현에 기반하여 객체 간의 관심 관계 그래프를 재구성할 수 있는 것이 바람직하다. 관심 관계 그래프는 제1 도메 인의 객체 간의 관심 관계 그래프와 제2 도메인의 객체 간의 관심 관계 그래프를 각각 포함한다. 관심 관계 그 래프는 객체 노드만 포함하는 객체-객체 그래프이므로, 모델에 입력된 객체 리소스 그래프와 재구성된 객체-객 체 그래프에 기반하여 인트라-도메인 정렬 학습을 수행할 수 있다. 도 7을 참조하여 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메인 각각에서 관심 정렬 처리를 수행하기 위해 관심 정렬 모델을 호출하는 구체적인 구현 프로세스를 설명한다. 이 경우, 관 심 정렬 처리에는 인트라-도메인 정렬 처리가 포함되며, 인트라-도메인 정렬 처리에는 작동(s31 내지 s33)이 포 함되지만, 이에 제한되지는 않는다. s31: 각 객체의 융합된 특징 표현, 제1 도메인의 객체 리소스 그래프, 제2 도메인의 객체 리소스 그래프를 획득 한다. 임의의 객체의 융합된 특징 표현은 제1 도메인에서의 임의의 객체의 제1 객체 특징 표현과 제2 도메인에 서의 임의의 객체의 제2 객체 특징 표현을 융합하여 획득된다. 제1 객체 특징 표현과 제2 객체 특징 표현을 융 합하는 것에 의해 객체의 보완적인 특징 표현이 형성될 수 있으며, 이에 따라 제2 도메인에서 객체 상호작용 데 이터가 적어 발생하는 문제를 완화할 수 있다. 제1 도메인의 객체 리소스 그래프와 제2 도메인의 객체 리소스 그래프는 관심 정렬 모델의 입력 정보이다. 객체 리소스 그래프의 관련 내용에 대해서는 전술한 관련 설명을 참 조할 수 있다. 여기서는 자세한 내용을 다시 설명하지 않는다. s32: 관심 정렬 모델(구체적으로는 관심 정렬 모델에 포함된 인트라-도메인 정렬 모듈)을 호출하여, 각 객체의 융합된 특징 표현에 대해 제1 도메인에 관한 그래프 디코딩 처리와 제2 도메인에 관한 그래프 디코딩 처리를 수 행하여 제1 도메인의 객체 그래프와 제2 도메인의 객체 그래프를 획득한다. 여기에서 객체 그래프는 위에 설명 한 객체-객체 그래프이며, 객체 그래프는 각 객체를 노드로 사용하고 객체 간의 제2 관심 관계를 연결 에지로 사용하는 그래프이며, 객체 간의 제2 관심 관계는 두 객체가 동일한 리소스 데이터에 대해 상호작용 데이터를 생성하는 것을 의미할 수 있다. 예로서, 제1 도메인의 객체 그래프와 제2 도메인의 객체 그래프를 재구성하기 위해, 제1 도메인의 그래프 디코 딩 가중치를 획득하고, 관심 정렬 모델을 호출하여 제1 도메인의 그래프 디코딩 가중치와 각 객체의 융합된 특 징 표현에 기반하여 제1 도메인의 객체 그래프를 재구성하며; 제2 도메인의 그래프 디코딩 가중치를 획득하고, 관심 정렬 모델을 호출하여 제2 도메인의 그래프 디코딩 가중치와 각 객체의 융합된 특징 표현에 기반하여 제2 도메인의 객체 그래프를 재구성하는 것이 지원된다. 다시 말해, 본 출원의 실시예는 그래프 디코더를 사용하여 단일-도메인 객체 그래프를 재구성하고, 객체 그래프에 기반하여, 두 객체가 단일 도메인에서 동일한 리소스 데이터에 대해 상호작용 데이터를 생성하는지를 예측하는 것을 지원한다. 두 객체가 동일한 리소스 데이터에 대해 상호작용 데이터를 생성하면, 객체 그래프에서 두 객체 사이에 연결 에지가 존재한다. 이 경우, 두 객체는 유사 한 관심사나 취미를 가지고 있다고 여겨진다. 따라서 두 객체의 객체 특징 표현이 더 가깝다(즉, 임베딩 벡터의 거리가 더 가깝다)고 예상된다. 각 도메인은 서로 다른 그래프 디코더에 대응하며, 구체적으로 그래프 디코더에 구현된 그래프 디코딩 가중치는 상이하다. 그래프 디코더는 로 표현되며, 서로 다른 도메인에 대응하는 객체와 그래프 디코더의 융합 된 특징 표현에 기반하여 대응하는 도메인의 객체 그래프를 재구성하는 수식은 다음과 같다:"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서 는 그래프 디코더의 가중치이고; D는 임베딩 차원(즉, 특징 표현의 차원)이며; 는 도메인에 대해 재구성된 객체 그래프에서 객체 간의 제2 관심 관계이다. 그래프 재구성은 이진 분류 태스크이고, 즉 재구 성된 객체 그래프에는 객체 간의 연결과 객체 간의 비연결이라는 두 가지 경우가 포함된다. 임의의 두 객체 사 이에 제2 관심 관계가 존재할 때, 객체 그래프에서 두 객체 사이에 연결 에지가 존재한다. 이 경우 에서, 두 객체에 대해 임이 결정된다. 반면, 임의의 두 객체 사이에 제2 관심 관계가 존재하지 않을 때, 객체 그 래프에서 두 객체 사이에 연결 에지는 존재하지 않는다. 이 경우 에서 두 객체에 대해 임이 결정된다. 도 8에 도시된 바와 같이, 객체의 융합된 특징 표현이 제1 도메인에 대응하는 그래프 디코더에 입력된 후, 제1 도메인의 객체 그래프 GS가 재구성될 수 있다. 제1 도메인의 객체 리소스 그래프와 객체 그래프를 비교하는 것에 의해, 제1 도메인에서 객체 간의 2차 관계(second-order relationship)가 1차(first-order) 관계로 변환(즉, 객체 리소스 그래프의 메타 경로)는 것을 알 수 있으며: 객체-제1 리소스 데이터-객체가 객체 그래프의 메타 경 로: 객체-객체로 변환되고, 메타 경로는 두 개 이상의 노드를 연결하는 특정 경로일 수 있으며, 노드 간의 복합 관계를 설명하는 데 사용될 수 있으며, 서로 다른 메타 경로는 서로 다른 의미를 표현함)되어, 제1 도메인 내 두 객체 간의 관심 유사성을 설명할 수 있다는 것을 알 수 있다. 마찬가지로, 객체의 융합된 특징 표현이 제2 도메인에 대응하는 그래프 디코더에 입력된 후, 제2 도메인의 객체 그래프 GT가 재구성될 수 있다. 객체 그래프 GT와 관련된 내용에 대해서는 전술한 객체 그래프 GS에 대한 관련 설명을 참조할 수 있다. 여기서는 자세한 내용 을 다시 설명하지 않는다. s33: 제1 도메인의 객체 그래프를 제1 도메인의 객체 리소스 그래프에 맞춰 정렬하고, 제2 도메인의 객체 그래 프를 제2 도메인의 객체 리소스 그래프에 맞춰 정렬하여, 인트라-도메인 정렬 처리를 구현한다. 구체적으로, 전 술한 작동에 기반하여 제1 도메인의 객체 그래프와 제2 도메인의 객체 그래프를 재구성한 후, 객체 그래프를 예 측된 객체 대 객체 관계로 사용하고 대응하는 도메인의 객체 리소스 그래프를 실제 객체 대 객체 관계로 사용하 여, 실제 객체 대 객체 관계와 예측된 객체 대 객체 관계의 차이에 따라 관심 정렬 모델을 트레이닝한다. 예로서, 제1 도메인의 인트라-도메인 정렬 손실은 제1 도메인의 객체 그래프와 대응하는 객체 리소스 그래프의 차이에 기반하여 획득되고, 제2 도메인의 인트라-도메인 정렬 손실은 제2 도메인의 객체 그래프와 대응하는 객 체 리소스 그래프의 차이에 기반하여 획득된다. 그런 다음, 복수의 도메인의 객체 그래프가 존재한다는 것을 고 려하면, 제1 도메인의 인트라-도메인 정렬 손실과 제2 도메인의 인트라-도메인 정렬 손실을 병합하여 관심 정렬 모델의 인트라-도메인 정렬 손실을 획득하며, 인트라-도메인 정렬 손실을 제2 손실로 사용한다. 위에서 설명한 바와 같이, 그래프 재구성이 이진 분류 태스크이면, 이진 분류 크로스-엔트로피 손실을 그래프 재구성 손실로 사용하는 것이 지원되고, 복수의 도메인(즉, 제1 도메인 및 제2 도메인)으로 구성된 관심 정렬 모델의 인트라- 도메인 정렬 손실은 다음과 같다:"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서 는 제1 도메인의 정렬 손실이고 는 제2 도메인의 정렬 손실이다. 및 는 각각 다음과 같이 표현된 다: 여기서 는 제1 도메인의 재구성된 객체 그래프에서 객체 ui와 객체 uj 사이의 연결을 나타낸다. 제1 도메인 의 객체 그래프에서 객체 ui와 객체 uj 사이에 연결 에지가 있으면 = 1이고, 그렇지 않으면 = 0이다. 마찬가지로 는 제1 도메인의 객체 리소스 그래프에서 객체 ui와 객체 uj 사이의 연결을 나타낸다. 제1 도메 인의 객체 리소스 그래프에서 객체 ui와 객체 uj 사이에 연결 에지가 있으면 = 1이고, 그렇지 않으면 = 0이다. 는 제2 도메인의 재구성된 객체 그래프에서 객체 ui와 객체 uj 사이의 연결을 나타낸다. 제2 도메 인의 객체 그래프에서 객체 ui와 객체 uj 사이에 연결 에지가 있으면 = 1이고, 그렇지 않으면 = 0이 다. 마찬가지로 는 제2 도메인의 객체 리소스 그래프에서 객체 ui와 객체 uj 사이의 연결을 나타낸다. 제2 도메인의 객체 리소스 그래프에서 객체 ui와 객체 uj 사이에 연결 에지가 있으면 = 1이고, 그렇지 않으면 = 0이다. 위의 내용을 바탕으로, 작동(s31~s33)에 나타낸 구체적인 구현 프로세스에 기반하여, 관심 정렬 모델의 인트라- 도메인 정렬 손실을 구성할 수 있다. 계산 복잡도를 줄이기 위해, 데이터 세트(또는 제1 도메인 데이터와 제2 도메인)이 대량의 객체 및 리소스 데이 터를 포함한다는 점을 고려하여, 본 출원의 실시예는 단일 도메인 도메인 데이터를 복수의 데이터 서브세트(배 치(batch))로 분할하는 것을 지원하며, 각 데이터 서브세트는 일부 객체 및 리소스 데이터를 포함하므로, 모든 객체에 기반하여 객체 그래프를 구성하는 대신에 일부 객체 노드의 객체 그래프를 구성할 수 있으며, 이에 따라 계산 복잡도를 감소시키고 모델 트레이닝 효율성 및 속도를 개선할 수 있다. 예를 들어, 하나의 데이터 서브세 트(배치)에 n개의 객체가 포함되어 있고, n ≤ N이며, N이 모든 객체의 수량이라고 가정하면, 모든 N개의 객체 에 기반하여 객체 그래프를 구성하는 것에 비해 계산 복잡도를 에서 으로 감소시킬 수 있다. 일부 실시예에서, 관심 정렬 처리에는 크로스-도메인 정렬 처리와 인트라-도메인 정렬 처리가 포함되고, 관심 정렬 모델을 호출하여 다음 처리를 수행한다: 작동에서 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메인 간에 관심 정렬 처리를 수행하는 것은 다음 기술적 솔루션을 통해 구현될 수 있다: 관심 정렬 모델을 호출하여 다음 처리를 수행한다: 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반 하여 제1 도메인과 제2 도메인 간에 크로스-도메인 정렬 처리를 수행한다 -; 그리고 관심 정렬 모델을 호출하여 다음 처리를 수행한다: 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메인 간 에 인트라-도메인 정렬 처리를 수행한다. 여기에서 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메인 간의 크로스-도메 인 정렬 처리를 수행하는 구현에 대해서는 작동(s21) 및 작동(s22)의 구현을 참조할 수 있다. 여기에서 제1 도 메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메인 간의 인트라-도메인 정렬 처리를 수행하는 것에 대해서는 작동(s31) 내지 작동(s33)의 구현을 참조할 수 있다. 일부 실시예에서, 크로스-도메인 정렬 처리에 대응하는 크로스-도메인 정렬 손실을 획득하고, 인트라-도메인 정 렬 처리에 대응하는 인트라-도메인 정렬 손실을 획득하며; 크로스-도메인 정렬 손실과 인트라-도메인 정렬 손실 을 사용하여 제2 손실을 형성한다. S304: 특징 추출 프로세스의 제1 손실과 관심 정렬 처리 프로세스의 손실을 감소시키는 방향에 따라 관심 정렬 모델을 트레이닝한다. 전술한 설명으로부터, 본 출원의 실시예에서 제공하는 모델 트레이닝 방법의 전반적인 학습 목표는 세 부분으로 나눌 수 있다는 것을 알 수 있다: a) 제2 도메인에서의 추천 타깃화된 학습(targeted learning). 다시 말하자면, 제2 도메인에서 객체의 관심사나 선호도는 객체와 제2 리소스 데이터 간의 객체 상호작용 데이터에 따라 학습된다. 타깃화된 학습 하에서, 관심 정렬 모델의 제1 손실이 구성될 수 있다. b) 크로스-도메인 관심 정렬 타깃화된 학습. 다시 말하자면, 객체 상호작용 데이터가 풍부한 제1 도메인에서의 객체 관심 유사도를 객 체 상호작용 데이터가 희소한 제2 도메인으로 마이그레이션하고, 제2 도메인의 객체 관심 유사도를 제1 도메인 의 객체 관심 유사도와 맞춰 정렬시키며, 이에 따라 제2 도메인의 관심 학습을 안내하는 목적을 달성한다. 타깃화된 학습 하에서, 관심 정렬 모델의 크로스-도메인 정렬 손실이 구성될 수 있다. c) 인트라-도메인 관심 정렬 타깃화된 학습. 다시 말하자면, 도메인에서의 객체의 관심사나 선호도를 그래프 디코딩 타깃을 사용하여 맞춰 정렬하여, 도메인에서 관심사가 유사한 객체의 객체 특징 표현을 더욱 가깝게 만든다. 타깃화된 학습 하에서, 관심 정렬 모델의 인트라-도메인 정렬 손실이 구성될 수 있다. 특징 추출 프로세스에서의 손실은 위에서 언급된 관심 정렬 모델의 제1 손실을 지칭할 수 있으며, 관심 정렬 처 리 프로세스에서의 손실은 크로스-도메인 정렬 손실 및 인트라-도메인 정렬 손실 중 적어도 하나를 포함할 수 있다. 관심 정렬 모델에 포함된 서로 다른 모듈에 따라, 특징 추출 프로세스의 제1 손실과 관심 정렬 처리 프로 세스의 손실을 감소시키는 방향에 따라 관심 정렬 모델을 트레이닝하는 프로세스들이 상이하다. 관심 정렬 모델은 단일-도메인 특징 추출 모듈과 크로스-도메인 정렬 모듈만 포함할 수 있다. 이러한 구현 하에 서, 특징 추출 프로세스의 제1 손실과 관심 정렬 처리 프로세스의 손실을 감소시키는 방향에 따라 관심 정렬 모 델을 트레이닝하는 프로세스는 다음을 포함할 수 있다: 전술한 작동에 기반하여 획득되는 관심 정렬 모델의 제1 손실과 관심 정렬 모델의 크로스-도메인 정렬 손실을 사용하여 관심 정렬 모델을 공동으로 트레이닝한다. 보다 구체적으로, 관심 정렬 모델의 제1 손실과 관심 정렬 모델의 크로스-도메인 정렬 손실을 더하여 관심 정렬 모델 의 타깃 손실을 획득하며, 관심 정렬 모델은 타깃 손실이 감소되는 방향에 따라 트레이닝된다. 타깃 손실을 계 산하는 수식은 다음과 같다:"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서 L은 관심 정렬 모델의 전체 손실을 나타내고, 는 제2 도메인과 관련하여 관심 정렬 모델의 제1 손실 을 나타내며, 는 관심 정렬 모델의 크로스-도메인 정렬 손실을 나타낸다. 관심 정렬 모델은 단일-도메인 특징 추출 모듈과 인트라-도메인 정렬 모듈만 포함할 수 있다. 이러한 구현 하에 서, 특징 추출 프로세스의 제1 손실과 관심 정렬 처리 프로세스의 손실을 감소시키는 방향에 따라 관심 정렬 모 델을 트레이닝하는 프로세스는 다음을 포함할 수 있다: 전술한 작동에 기반하여 획득되는 관심 정렬 모델의 제1 손실과 관심 정렬 모델의 인트라-도메인 정렬 손실을 사용하여 관심 정렬 모델을 공동으로 트레이닝한다. 보다 구체적으로, 관심 정렬 모델의 제1 손실과 관심 정렬 모델의 인트라-도메인 정렬 손실을 더하여 관심 정렬 모델 의 타깃 손실을 획득하고, 관심 정렬 모델은 타깃 손실이 감소되는 방향에 따라 트레이닝된다. 타깃 손실을 계 산하는 수식은 다음과 같다:"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "는 관심 정렬 모델의 인트라-도메인 정렬 손실을 나타낸다. 관심 정렬 모델은 단일-도메인 특징 추출 모듈, 크로스-도메인 정렬 모듈, 및 인트라-도메인 정렬 모듈을 포함 할 수 있다. 이러한 구현 하에서, 특징 추출 프로세스의 제1 손실과 관심 정렬 처리 프로세스의 손실을 감소시 키는 방향에 따라 관심 정렬 모델을 트레이닝하는 프로세스는 다음을 포함할 수 있다: 전술한 작동에 기반하여 획득되는 관심 정렬 모델의 제1 손실, 관심 정렬 모델의 크로스-도메인 정렬 손실, 및 관심 정렬 모델의 인트라 -도메인 정렬 손실을 사용하여 관심 정렬 모델을 공동으로 트레이닝한다. 보다 구체적으로, 관심 정렬 모델의 제1 손실, 크로스-도메인 정렬 손실, 인트라-도메인 정렬 손실을 더하여 관심 정렬 모델의 타깃 손실을 획득하 고, 관심 정렬 모델은 타깃 손실이 감소되는 방향에 따라 트레이닝된다. 타깃 손실을 계산하는 수식은 다음과 같다:"}
{"patent_id": "10-2025-7009207", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "본 출원의 실시예는 공동 트레이닝 방식으로 관심 정렬 모델을 지원하며, 구체적으로 관심 정렬 모델에 포함된 모듈의 모델 파라미터를 조정함으로써, 모델 파라미터가 조정된 관심 정렬 모델의 예측 성능이 더욱 정확해진다 는 것을 알 수 있다. 제1 도메인에는 객체 상호작용 데이터가 풍부한 반면, 제2 도메인에는 객체 상호작용 데이 터가 거의 없으며, 본 출원의 실시예는 제1 도메인에서의 객체 상호작용 데이터를 사용하여 제2 도메인에서의 학습을 안내하는 것을 목표로 한다. 따라서, 특징 추출 프로세스의 제1 손실과 관심 정렬 처리 프로세스의 손실 의 하강 방향(descending direction)에 따라 관심 정렬 모델을 트레이닝하는 프로세스에서, 제1 도메인의 주목 유사도 분포 P를 앵커(anchor)로 사용하고, 크로스-도메인 정렬 손실에 따른 제1 특징 추출 모듈의 그레이디언 트 역전파(gradient back-propagation)를 절단하는 것이 지원되며, 즉, 크로스-도메인 정렬 손실에 기반하여 제1 특징 추출 모듈의 파라미터를 조정할 필요가 없다. 그러나 본 출원의 실시예는 여전히 인트라-도메인 정렬 손 실에 기반하여 제1 도메인 특징 추출 모듈을 파인-튜닝(fine-tuning)하는 것을 지원함으로써, 제1 도메인의 제1 도메인 특징 표현이 제2 도메인의 제1 손실에 기여할 수 있다. 본 출원의 실시예는 객체 간의 관심 유사도를 충분히 고려하고, 객체 간의 관심 유사도를 맞춰 정렬하는 방식으 로 관심 정렬 모델의 트레이닝을 지원함으로써, 관심 정렬 모델이 상호작용 데이터가 적은 도메인에 적용되는 경우에도 객체에 대한 정확한 특징 표현을 여전히 생성할 수 있다. 예를 들어, 제1 도메인에 많은 상호작용 데 이터가 있다는 것을 고려하면, 풍부한 상호작용 데이터에 기반하여 추출된 제1 도메인 특징 표현이 더 정확하다. 따라서 관심 정렬 모델은 상호작용 데이터가 적은 제2 도메인 내 두 객체 간의 관심 유사도와 상호작 용 데이터가 많은 제1 도메인 내 두 객체 간의 관심 유사도를 맞춰 정렬하는 방식으로 트레이닝된다. 제2 도메 인 내 상호작용 데이터가 적은 경우에도 트레이닝된 관심 정렬 모델이 객체에 대한 높은 정확도의 특징 표현을 생성할 수 있으므로, 정확한 특징 표현에 기반하여 객체에게 추천되는 리소스 데이터가 객체의 개인화된 요구를 충족시키고, 정확한 리소스 추천이 구현된다. 본 출원의 실시예에서, 특징 추출 프로세스의 제1 손실과 관심 정 렬 처리 프로세스의 손실을 이용하여 관심 정렬 모델을 공동으로 트레이닝하는 방식은, 관심 정렬 모델의 전반 적인 학습 목표를 풍부하게 하고, 다중 목표 학습을 통해 관심 정렬 모델의 성능을 보장할 수 있다. 도 3에 도시된 실시예는 주로 관심 정렬 모델의 모델 트레이닝부분을 세부적으로 설명한다. 다음은 관심 정렬 모델의 모델 적용 부분을 설명한다. 구체적인 구현에서, 전술한 작동에 기반하여 트레이닝된 관심 정렬 모델을 획득한 후, 본 출원의 실시예는 트레이닝된 관심 정렬 모델이 리소스 추천 플랫폼에 배포되고, 구체적으로는 리 소스 추천 플랫폼의 리소스 리콜 스테이지에 적용되는 경우를 지원한다. 따라서 관심 정렬 모델은 리소스 리콜 모델이라고도 지칭될 수 있다. 리소스 리콜 스테이지는 주로 대규모 리소스 데이터베이스로부터 객체가 관심 있 는 리소스 데이터의 일부를 빠르게 선택하고, 이후 리소스 데이터의 일부를 정확하게 정렬하여 객체에게 추천을 하게 하는 것이다. 관심 정렬 모델을 적용하여 모델 적용(즉, 리소스 추천)을 수행하는 예시적인 개략적 흐름도 는 도 8을 참조할 수 있다. 도 8에 도시된 바와 같이, 타깃 객체(예를 들어, 임의의 객체)가 리소스 분배 요건 을 가질 때, 타깃 객체의 객체 특징(또는 나이, 성별 또는 다른 정보와 같은 속성 정보)을 획득할 수 있고, 리 소스 추천 플랫폼에서 타깃 객체와 다른 객체 간의 상호작용 데이터에 기반하여 객체 리소스 그래프를 구성하며; 그런 다음, 리소스 리콜 스테이지에서, 본 출원의 이 실시예에서 트레이닝된 관심 정렬 모델을 사용 하여 타깃 객체에 대한 특징 표현과 리소스 추천 플랫폼에서의 리소스 데이터에 대한 특징 표현을 생성한다. 타 깃 객체의 특징 표현과 각 리소스 데이터의 특징 표현 간의 매칭이 수행된다. 구체적으로, 타깃 객체의 특징 표 현과 각 리소스 데이터 간의 유사도를 계산한 다음, 유사도 결과에 따라, 복수의 리소스 데이터를 후보 풀 (candidate pool)로 선택하여 세부 순위를 매기고(ranking), 이를 후속 정렬 스테이지에서 사용한다. 도 9는 본 출원의 실시예에 따른 또 다른 모델 트레이닝 방법의 개략적 흐름도이다. 모델 트레이닝 방법은 전술 한 전자 디바이스에 의해 수행될 수 있다. 본 방법에는 작동(S901 내지 S907)이 포함될 수 있지만 이에 제한되 지는 않는다. S901: 데이터 세트를 획득한다. S902: 관심 정렬 모델을 호출하여 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현을 획 득하고, 관심 정렬 모델을 호출하여 제2 도메인 데이터에 대한 특징 추출을 수행하여 제2 도메인 특징 표현을 획득한다. S903: 관심 정렬 모델을 호출하여, 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메인에서 관심 정렬 처리를 수행한다. S904: 특징 추출 프로세스의 제1 손실과 관심 정렬 처리 프로세스의 손실을 감소시키는 방향에 따라 관심 정렬 모델을 트레이닝한다. 작동(S901 내지 S904)에 나타낸 구체적인 구현 프로세스에 대해서는, 도 3에 도시된 전술한 실시예의 작동(S301 내지 S304)에 도시된 구체적인 구현 프로세스의 관련 설명을 참조할 수 있다. 여기서는 자세한 내용을 다시 설 명하지 않는다. S905: 트레이닝된 관심 정렬 모델을 호출하여, 리소스 데이터가 분배될 타깃 객체에 대한 특징 추출을 수행하여 타깃 객체의 융합된 특징 표현을 획득한다. 트레이닝된 관심 정렬 모델이 리소스 추천 플랫폼에 배포된 후, 리소스 데이터가 배포될 타깃 객체가 리소스 추 천 플랫폼에 존재하면, 예를 들어, 타깃 객체가 리소스 추천 플랫폼에 방금 등록된 객체이면, 리소스 데이터가배포될 타깃 객체의 객체 속성을 획득할 수 있다. 여기에서 객체 속성에는 타깃 객체가 리소스 추천 플랫폼에 등록할 때 입력되는 관련 속성 정보(예를 들어, 설정된 별명, 나이, 성별 또는 선택된 리소스 유형 레이블)가 포함될 수 있다. 그런 다음, 트레이닝된 관심 정렬 모델을 호출하여 타깃 객체의 객체 속성을 기반으로 특징 추 출을 수행하여, 타깃 객체의 융합된 특징 표현을 획득한다. 구체적으로, 관심 정렬 모델에 포함된 제1 특징 추출 모듈은 제1 도메인에서 타깃 객체의 제1 객체 특징 표현을 예측하도록 호출되고, 관심 정렬 모델에 포함된 제2 특징 추출 모듈은 제2 도메인에서 타깃 객체의 제2 객체 특 징 표현을 예측하도록 호출된다. 그런 다음, 타깃 객체의 제1 객체 특징 표현과 제2 객체 특징 표현을 융합하여 타깃 객체의 융합된 특징 표현을 획득한다. 제1 특징 추출 모듈이 타깃 객체의 제1 객체 특징 표현을 예측하는 (또는 제2 특징 추출 모듈이 타깃 객체의 제2 객체 특징 표현을 예측하는) 구체적인 구현 프로세스에 대해서는, 도 3에 도시된 실시예의 관련 설명을 참조할 수 있다. 여기서는 자세한 내용을 다시 설명하지 않는다. S906: 타깃 객체의 융합된 특징 표현과 각 후보 리소스 데이터의 리소스 특징 표현 간의 유사도 비교를 수행한 다. S907: 유사도 비교 결과가 비교 결과 임계값보다 큰 후보 리소스 데이터를 타깃 객체와 연관된 배포 대상 제2 리소스 데이터로 사용한다. 작동(S906) 및 작동(S907)에서, 리소스 데이터가 배포될 타깃 객체의 융합된 특징 표현은 전술한 작동에 기반하 여 획득될 수 있다. 융합된 특징 표현은 타깃 객체의 속성이나 특징을 나타내기 위해 구성(예를 들어, 타깃 객 체가 특정 리소스 데이터 유형에 관심이 있음을 나타내기 위해 구성됨)될 수 있다. 그 다음에, 제2 도메인에서 의 배포될 후보 리소스 데이터의 리소스 특징 표현을 획득할 수 있다. 임의의 후보 리소스 데이터의 리소스 특 징 표현은 후보 리소스 데이터의 속성이나 특징을 나타내기 위해 구성(예를 들어, 과거 시간 내에서 후보 리소 스 데이터의 트리거 상태를 나타내기 위해 구성됨)될 수도 있다. 리소스 특징 표현이 타깃 객체의 융합된 특징 표현에 더 가까운 후보 리소스 데이터는, 타깃 객체가 관심 있는 리소스 데이터일 가능성이 더 높다고 여겨진다. 따라서 타깃 객체의 융합된 특징 표현과 각 후보 리소스 데이터 의 리소스 특징 표현 간의 유사도 매칭을 수행하여, 타깃 객체와 각 후보 리소스 데이터 간의 유사도 비교 결과 를 획득하는 것이 지원된다. 유사도 매칭의 목적은 타깃 객체의 융합된 특징 표현에 가까운 후보 리소스 데이터 를 찾는 것이다. 마지막으로, 유사도 비교 결과가 리소스 추천 규칙을 충족하는 후보 리소스 데이터는 타깃 객 체와 연관된 배포 대상 리소스 데이터로 사용된다. 관심 정렬 모델이 리소스 추천 플랫폼의 리소스 리콜 스테이 지에 배포될 때, 유사도 비교 결과가 비교 결과 임계값보다 큰 후보 리소스 데이터를 배포 대상 리소스 데이터 로 사용하여, 세부 순위를 매기기 위한 후보 풀에 배치하여, 이후의 세부 순위 매기기 및 추천을 용이하게 할 수 있다. 리소스 추천 규칙은 서비스 요건에 따라 서비스 담당자에 의해 사용자 정의될 수 있다. 예를 들어, 리 소스 추천 규칙에는 다음이 포함된다. 유사도 비교 결과가 비교 결과 임계값보다 큰 후보 리소스 데이터를 타깃 객체와 연관된 배포 대상 리소스 데이터로 사용한다. 또 다른 예로, 리소스 추천 규칙에는 다음이 포함된다: 결 과 값을 내림차순으로 정렬하고, 상위 k개의 후보 리소스 데이터를 타깃 객체와 연관된 배포 대상 리소스 데이 터로 사용하는 방식 등이다. 본 출원의 실시예에서는 리소스 추천 규칙의 구체적인 내용이 제한되지 않는다. 타깃 객체의 융합된 특징 표현과 각 후보 리소스 데이터의 리소스 특징 표현 간의 매칭을 수행하는 예시적인 개 략도에 대해서는, 도 10을 참조할 수 있다. 도 10에 도시된 바와 같이, 제2 도메인의 배포 대상 후보 리소스 데 이터는 후보 리소스 데이터 1, 후보 리소스 데이터 2, 후보 리소스 데이터 3, 및 후보 리소스 데이터 4를 포함 한다. 타깃 객체의 융합된 특징 표현과 후보 리소스 데이터 1의 리소스 특징 데이터 간의 유사도 비교 결과가 60%(또는 점수나 소수점 등의 수치 값 형태)이고, 타깃 객체의 융합된 특징 표현과 후보 리소스 데이터 2의 리 소스 특징 데이터 간의 유사도 비교 결과가 50%이며, 타깃 객체의 융합된 특징 표현과 후보 리소스 데이터 3의 리소스 특징 데이터 간의 유사도 비교 결과가 20%이고, 타깃 객체의 융합된 특징 표현과 후보 리소스 데이터 4 의 리소스 특징 데이터 간의 유사도 비교 결과가 70%인 것으로 가정한다. 리소스 추천 규칙에 다음: 결과 값을 내림차순으로 정렬하고, 상위 k(k=2)개의 후보 리소스 데이터를 타깃 객체와 연관된 배포 대상 리소스 데이터로 사용하는 것이 포함되면, 4개의 후보 리소스 데이터 간의 순위: 후보 리소스 데이터 4 → 후보 리소스 데이터 1 → 후보 리소스 데이터 2 → 후보 리소스 데이터 3를 획득할 수 있다. 그 다음에, 순위에서 상위에 있는 후보 리소스 데이터 4와 후보 리소스 데이터 1이 타깃 객체와 연관된 배포 대상 리소스 데이터로 사용될 수 있다. 실제 적용에서, 본 출원의 실시예에서 트레이닝된 관심 정렬 모델은 리소스 추천 플랫폼의 리콜 모듈에 배포되 고, 리소스 추천 플랫폼에서 수백만 개의 온라인 객체에 대한 리소스 추천을 하도록 구성될 수 있다. 업계에서 모델이 정확한 추천을 하는지를 측정하는 중요한 인덱스를 사용하여 관심 정렬 모델의 모델 효과를 평가한 결과에 대해서는 표 1을 참조할 수 있다. 표 1 평가 인덱스 Uctr180Uctr60Uctr30Pctr60Pctr30보기(viewing) 지속 기간dau 증가 규모 (Increase magnitude)+1.543%+1.196%+1.065%+1.775%+0.593%+1.214% +1.246% 표 1에서 사용자 클릭률(user-click-through-rate)은 간단히 \"Uctr\"이라고도 한다. 평가 인덱스는 클릭 행동 (click-through behavior)을 하는 객체의 수량과 리소스 데이터에 액세스하는 객체의 수량을 비교하는 것에 의 해 획득된다. 예를 들어, 본 출원의 실시예에서 제공하는 관심 정렬 모델을 사용하여 리소스 데이터를 추천한 후, 리소스 데이터에 액세스하는 객체의 수량은 100이고, 리소스 데이터에 대한 클릭 행동을 하는 사용자는 13 명이다. 이 경우, Uctr은 13/100*% = 13%이다. UctrX는 비디오 추천 시나리오에서 비디오 재생 지속 기간이 X초 일 때 비디오가 클릭되는 증가 규모를 나타낸다. 표 1에 나타낸 바와 같이, X의 값은 180, 60 또는 30이 될 수 있다. Pctr은 \"페이지 클릭률(page-click-through-rate)\"이라고도 한다. 일일 활성 사용자는 줄여서 \"dau\"라고 하며, 리소스 추천 플랫폼에서 일일 활성 객체의 상태를 반영하도록 구성될 수 있다. 위의 내용을 토대로, 본 출원의 실시예에서 트레이닝된 관심 정렬 모델을 갖는 리소스 추천 플랫폼은 객체에 대한 객체 특징 표현을 더 욱 정확하게 생성할 수 있고, 이를 통해 객체에게 리소스 데이터를 정확하게 추천할 수 있으며, 이에 따라 리소 스 추천 플랫폼의 홍보를 촉진할 수 있다. 본 출원의 이 실시예에서는 사용자 정보와 같은 관련 데이터가 포함된다. 본 출원의 이 실시예를 특정 제품이나 기술에 적용할 때, 사용자의 허가 또는 동의를 얻어야 하며, 관련 데이터의 수집, 사용, 처리 등은 관련 국가 및 지역의 관련 법률, 규정, 표준을 준수해야 한다. 본 출원의 실시예에서의 방법은 위에서 자세히 설명되어 있다. 본 출원의 실시예에서 방법을 보다 잘 구현할 수 있도록, 이에 따라 본 출원의 실시예에서 장치를 제공한다. 도 11은 본 출원의 실시예에 따른 모델 트레이닝 장치의 개략적인 구조도이다. 모델 트레이닝 장치는 전자 디바 이스에서 실행되는 컴퓨터가 실행 가능한 명령어(프로그램 코드 포함)일 수 있다. 모델 트레이닝 장치는 도 3 및 도 9에 도시된 방법 실시예에서의 일부 또는 모든 작동을 수행하도록 구성될 수 있다. 모델 트레이닝 장치는 다음 유닛: 데이터 세트를 획득하도록 구성된 획득 유닛 - 데이터 세트는 제1 도메인 데이터와 제2 도메 인 데이터를 포함하며, 제1 도메인 데이터는 적어도 하나의 객체와 제1 도메인에서 각 객체가 관심 있는 제1 리 소스 데이터를 포함하고, 제2 도메인 데이터는 적어도 하나의 객체와 제2 도메인에서 각 객체가 관심 있는 제2 리소스 데이터를 포함함 -; 및 관심 정렬 모델을 호출하여 제1 도메인 데이터에 대한 특징 추출을 수행하여 제1 도메인 특징 표현을 획득하고, 관심 정렬 모델을 호출하여 제2 도메인 데이터에 대한 특징 추출을 수행하여 제2 도메인 특징 표현을 획득하도록 구성된 처리 유닛을 포함한다. 처리 유닛은 추가로, 관심 정렬 모 델을 호출하여, 제1 도메인 특징 표현과 제2 도메인 특징 표현을 기반으로 제1 도메인과 제2 도메인 간의 관심 정렬 처리를 수행하는 처리를 수행하도록 구성된다. 처리 유닛은 추가로, 제1 손실과 제2 손실이 감소되 는 방향에 따라 관심 정렬 모델을 트레이닝하여 트레이닝된 관심 정렬 모델을 획득하도록 구성된다. 제1 손실은 특징 추출에 대응하는 손실이고, 제2 손실은 관심 정렬 처리에 대응하는 손실이며, 트레이닝된 관심 정렬 모델 은 제2 도메인에서 타깃 객체에게 리소스 데이터 추천을 하도록 구성된다. 일부 실시예에서, 처리 유닛은 추가로, 제1 도메인 데이터에 기반하여 제1 도메인의 객체 리소스 그래프 를 구성하고 - 제1 도메인의 객체 리소스 그래프는 각 객체와 각 제1 리소스 데이터가 노드이고 객체와 제1 리 소스 데이터 간의 제1 관심 관계가 연결 에지인 그래프임 -; 관심 정렬 모델을 호출하여 제1 도메인의 객체 리 소스 그래프에 대한 그래프 인코딩 처리를 수행하여 각 객체의 제1 객체 특징 표현과 각 제1 리소스 데이터의 제1 리소스 특징 표현을 획득하며; 각 객체의 제1 객체 특징 표현과 각 제1 리소스 데이터의 제1 리소스 특징 표현을 사용하여 제1 도메인 특징 표현을 형성하도록 구성된다. 일부 실시예에서, 처리 유닛은 추가로, 제2 도메인 데이터에 기반하여 제2 도메인의 객체 리소스 그래프 를 구성하고 - 제2 도메인의 객체 리소스 그래프는 각 객체와 각 제2 리소스 데이터가 노드이고 객체와 제2 리 소스 데이터 간의 제2 관심 관계가 연결 에지인 그래프임 -; 관심 정렬 모델을 호출하여 제2 도메인의 객체 리 소스 그래프에 대한 그래프 인코딩 처리를 수행하여 각 객체의 제2 객체 특징 표현과 각 제2 리소스 데이터의 제2 리소스 특징 표현을 획득하며; 각 객체의 제2 객체 특징 표현과 각 제2 리소스 데이터의 제2 리소스 특징표현을 사용하여 제2 도메인 특징 표현을 형성하도록 구성된다. 일부 실시예에서, 적어도 하나의 객체 중 임의의 하나는 트레이닝 객체로 표현되고; 처리 유닛은 추가로, 제2 도메인에서의 트레이닝 객체의 초기 특징 표현 및 트레이닝 객체가 관심 있는 각 제2 리소스 데이터의 초기 특징 표현을 획득하고; 관심 정렬 모델을 호출하여 트레이닝 객체의 초기 특징 표현 및 트레이닝 객체가 관심 있는 각 제2 리소스 데이터의 초기 특징 표현에 따라 트레이닝 객체와 트레이닝 객체가 관심 있는 각 제2 리소 스 데이터 간의 상관도를 계산하며; 트레이닝 객체와 트레이닝 객체가 대한 관심 있는 각 제2 리소스 데이터 간 의 상관도, 제2 도메인에서의 트레이닝 객체의 초기 특징 표현, 및 트레이닝 객체가 관심 있는 각 제2 리소스 데이터의 초기 특징 표현에 기반하여 트레이닝 객체의 제2 객체 특징 표현을 획득하도록 구성된다. 일부 실시예에서, 데이터 세트는 대응하는 관심 있는 제2 리소스 데이터에 대한 각 객체의 실제 주목 정도를 포 함하고, 특징 추출 프로세스의 제1 손실을 획득하는 프로세스는: 각 객체의 제1 객체 특징 표현과 제2 객체 특 징 표현을 융합하여 각 객체의 융합된 특징 표현을 획득하는 단계; 각 객체의 융합된 특징 표현과 대응하는 객 체가 관심 있는 제2 리소스 데이터에 대한 제2 리소스 특징 표현에 대해 스플라이싱 연산을 수행하여 대응하는 관심 있는 제2 리소스 데이터에 대한 각 객체의 예측 주목 정도를 획득하는 단계; 및 대응하는 관심 있는 제2 리소스 데이터에 대한 각 객체의 실제 주목 정도와 예측된 주목 정도의 차이에 기반하여 관심 정렬 모델의 제1 손실을 구성하는 단계를 포함한다. 일부 실시예에서, 관심 정렬 처리에는 크로스-도메인 정렬 처리가 포함되고, 제1 도메인 특징 표현에는 제1 도 메인 데이터에서 각 객체의 제1 객체 특징 표현이 포함되며, 제2 도메인 특징 표현에는 제2 도메인 데이터에서 각 객체의 제2 객체 특징 표현이 포함되며; 처리 유닛은 추가로, 관심 정렬 모델을 호출하여 각 객체의 제1 객체 특징 표현을 기반으로 제1 도메인 내 각 두 객체 간의 제1 주목 유사도를 결정하고; 관심 정렬 모델을 호출하여 각 객체의 제2 객체 특징 표현을 기반으로 제2 도메인 내 각 두 객체 간의 제2 주목 유사도를 결정하 며; 제2 도메인 내 두 객체 간의 제2 주목 유사도를 제1 도메인의 대응하는 두 객체 간의 제1 주목 유사도와 맞 춰 정렬하도록 구성된다. 일부 실시예에서, 처리 유닛은 추가로, 복수의 객체 중 각 두 객체의 제1 객체 특징 표현에 대해 거리 연 산을 수행하여 각 두 객체의 제1 객체 특징 표현 간의 거리 정보를 획득하고; 각 두 객체의 제1 객체 특징 표현 간의 거리 정보에 대한 확률 변환을 수행하여 각 두 객체 간의 제1 주목 유사도를 획득하도록 구성된다. 일부 실시예에서, 관심 정렬 처리 프로세스의 손실을 획득하는 프로세스는: 제1 도메인 내 각 두 객체 간의 제1 주목 유사도에 기반하여 제1 도메인의 주목 유사도 분포를 결정하는 단계; 제2 도메인 내 각 두 객체 간의 제2 주목 유사도에 기반하여 제2 도메인의 주목 유사도 분포를 결정하는 단계; 및 제1 도메인의 주목 유사도 분포와 제2 도메인의 주목 유사도 분포의 차이에 기반하여 관심 정렬 모델의 크로스-도메인 정렬 손실을 구성하고, 크 로스-도메인 정렬 손실을 제2 손실로 사용하는 단계를 포함한다. 일부 실시예에서, 처리 유닛은 추가로, 각 객체의 융합된 특징 표현, 제1 도메인의 객체 리소스 그래프, 및 제2 도메인의 객체 리소스 그래프를 획득하고; 관심 정렬 모델을 호출하여 각 객체의 융합된 특징 표현에 대 해 제1 도메인에 관한 그래프 디코딩 처리와 제2 도메인에 관한 그래프 디코딩 처리를 수행하여 제1 도메인의 객체 그래프와 제2 도메인의 객체 그래프를 획득하며 - 객체 그래프는 각 객체가 노드로 사용되고 객체 간의 제 2 관심 관계가 연결 에지로 사용되는 그래프임 -; 제1 도메인의 객체 그래프를 제1 도메인의 객체 리소스 그래 프와 맞춰 정렬하고, 제2 도메인의 객체 그래프를 제2 도메인의 객체 리소스 그래프와 맞춰 정렬하도록 구성된 다. 일부 실시예에서, 처리 유닛은 추가로, 제1 도메인의 그래프 디코딩 가중치를 획득하고, 관심 정렬 모델 을 호출하여 제1 도메인의 그래프 디코딩 가중치와 각 객체의 융합된 특징 표현을 기반으로 제1 도메인의 객체 그래프를 재구성하며; 제2 도메인의 그래프 디코딩 가중치를 획득하고, 관심 정렬 모델을 호출하여 제2 도메인 의 그래프 디코딩 가중치와 각 객체의 융합된 특징 표현을 기반으로 제2 도메인의 객체 그래프를 재구성하도록 구성된다. 일부 실시예에서, 관심 정렬 처리 프로세스의 제2 손실을 획득하는 프로세스는: 제1 도메인의 객체 그래프와 대 응하는 객체 리소스 그래프의 차이에 기반하여 제1 도메인의 인트라-도메인 정렬 손실을 획득하는 단계; 제2 도 메인의 객체 그래프와 대응하는 객체 리소스 그래프의 차이에 기반하여 제2 도메인의 정렬 손실을 획득하는 단 계; 및 제1 도메인의 정렬 손실과 제2 도메인의 정렬 손실을 병합하여 관심 정렬 모델의 인트라-도메인 정렬 손 실을 획득하고, 인트라-도메인 정렬 손실을 제2 손실로 사용하는 단계를 포함한다. 일부 실시예에서, 관심 정렬 처리에는 크로스-도메인 정렬 처리와 인트라-도메인 정렬 처리가 포함되고, 처리 유닛은 추가로, 관심 정렬 모델을 호출하여, 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메인 간의 크로스-도메인 정렬 처리를 수행하는 처리를 수행하며; 관심 정렬 모델을 호출하 여, 제1 도메인 특징 표현과 제2 도메인 특징 표현에 기반하여 제1 도메인과 제2 도메인 간의 인트라-도메인 정 렬 처리를 수행하는 처리를 수행하도록 구성된다. 일부 실시예에서, 관심 정렬 처리 프로세스의 제2 손실을 획득하는 프로세스는: 크로스-도메인 정렬 처리에 대 응하는 크로스-도메인 정렬 손실을 획득하고, 인트라-도메인 정렬 처리에 대응하는 인트라-도메인 정렬 손실을 획득하는 단계; 및 크로스-도메인 정렬 손실과 인트라-도메인 정렬 손실을 사용하여 제2 손실을 형성하는 단계 를 포함한다. 일부 실시예에서, 관심 정렬 모델은 제1 특징 추출 모듈, 제2 특징 추출 모듈, 크로스-도메인 정렬 모듈, 및 인 트라-도메인 정렬 모듈을 포함하며; 제1 특징 추출 모듈은 제1 도메인 데이터에 대한 특징 추출을 수행하도록 구성되고, 제1 특징 추출 모듈은 사전 트레이닝을 통해 획득되며; 제2 특징 추출 모듈은 제2 도메인 데이터에 대한 특징 추출을 수행하도록 구성되고; 크로스-도메인 정렬 모듈은 제2 도메인 내 두 객체 간의 제2 주목 유사 도와 제1 도메인 내 대응하는 두 객체 간의 제1 주목 유사도 간의 관심 정렬 처리를 수행하도록 구성되며; 인트 라-도메인 정렬 모듈은 제1 도메인의 객체 그래프와 제1 도메인의 객체 리소스 그래프 간의 관심 정렬 처리를 수행하고, 제2 도메인의 객체 그래프와 제2 도메인의 객체 리소스 그래프 간의 관심 정렬 처리를 수행하도록 구 성된다. 일부 실시예에서, 관심 정렬 처리 프로세스의 손실은: 크로스-도메인 정렬을 통해 획득되는 크로스-도메인 정렬 손실 및 인트라-도메인 정렬을 통해 획득되는 인트라-도메인 정렬 손실을 포함하고; 처리 유닛은 추가로, 관심 정렬 모델의 제1 손실, 크로스-도메인 정렬 손실, 및 인트라-도메인 정렬 손실을 더하여 관심 정렬 모델의 타깃 손실을 획득하고, 타깃 손실이 감소하는 방향에 따라 관심 정렬 모델을 트레이닝하도록 구성되며, 타깃 손 실이 감소하는 방향에 따라 관심 정렬 모델을 트레이닝하는 프로세스에서, 크로스-도메인 정렬 손실에 기반한 제1 특징 추출 모듈의 트레이닝은 단축된다. 일부 실시예에서, 처리 유닛은 추가로, 리소스 데이터가 분배될 타깃 객체의 객체 속성 및 제2 도메인에 서의 분배될 각 후보 리소스 데이터의 리소스 특징 표현을 획득하고; 트레이닝된 관심 정렬 모델을 호출하여 타 깃 객체의 객체 속성에 기반하여 특징 추출을 수행하여 타깃 객체의 융합된 특징 표현을 획득하며; 타깃 객체의 융합된 특징 표현과 각 후보 리소스 데이터의 리소스 특징 표현 간의 유사도 비교를 수행하여 타깃 객체와 각 후보 리소스 데이터 간의 유사도 비교 결과를 획득하고; 유사도 비교 결과가 리소스 추천 규칙을 충족하는 후보 리소스 데이터를 타깃 객체와 연관된 분배 대상 제2 리소스 데이터로 사용하도록 구성된다. 일부 실시예에서, 도 11에 도시된 모델 트레이닝 장치의 유닛들은 개별적으로 또는 전체적으로 하나 또는 여러 개의 다른 유닛으로 조합될 수 있으며, 또는 하나(또는 그 이상)의 유닛들이 추가로 더 작은 기능을 갖는 복수 의 유닛으로 분할될 수 있고, 이는 본 출원의 실시예의 기술적 효과의 구현에 영향을 미치지 않고 동일한 작동 을 구현할 수 있다. 전술한 유닛들은 논리적 기능에 따라 분할된다. 실제 적용에서는 하나의 유닛의 기능이 복 수의 유닛으로 구현될 수도 있고, 복수의 유닛의 기능이 하나의 유닛으로 구현될 수도 있다. 본 출원의 다른 실 시예에서, 모델 트레이닝 장치는 다른 유닛을 포함할 수도 있다. 실제 적용에서는 이러한 기능은 다른 유닛의 도움을 받아 구현될 수도 있고, 복수의 유닛이 협력하여 구현될 수도 있다. 본 출원의 또 다른 실시예에 따르면, 도 3 및 도 9에 도시된 대응하는 방법에 관련된 작동을 수행할 수 있는 컴퓨터 프로그램(프로그램 코드 포함)은 중앙 처리 유닛(central processing unit, CPU), 랜덤 액세스 저장 매체(RAM), 읽기 전용 저장 매체 (ROM)와 같은 처리 엘리먼트 및 저장 엘리먼트를 포함하는 컴퓨터와 같은 범용 전자 디바이스에서 실행되어, 도 11에 도시된 모델 트레이닝 장치를 구성하고 본 출원의 실시예에서의 모델 트레이닝 방법을 구현할 수 있다. 컴 퓨터 프로그램은 예를 들어, 컴퓨터가 판독 가능한 기록 매체에 기록될 수 있으며, 컴퓨터가 판독 가능한 기록 매체를 사용하여 전술한 전자 디바이스에 로딩되어 전자 디바이스에서 실행될 수 있다. 본 출원의 실시예는 객체 간의 관심 유사도를 충분히 고려하고, 객체 간의 관심 유사도를 정렬하는 방식으로 관 심 정렬 모델의 트레이닝을 지원하므로, 관심 정렬 모델이 상호작용 데이터가 적은 도메인에 적용되는 경우에도, 객체에 대한 정확한 특징 표현을 여전히 생성할 수 있다. 예를 들어, 제1 도메인에 많은 상호작용 데 이터가 있다는 것을 고려하면, 풍부한 상호작용 데이터에 기반하여 추출한 제1 도메인 특징 표현이 더 정확하다. 따라서 관심 정렬 모델은 상호작용 데이터가 적은 제2 도메인 내 두 객체 간의 관심 유사도와 상호작 용 데이터가 많은 제1 도메인 내 두 객체 간의 관심 유사도를 맞춰 정렬하는 방식으로 트레이닝된다. 제2 도메인의 상호작용 데이터가 적은 경우에도 트레이닝된 관심 정렬 모델이 객체에 대한 높은 정확도의 특징 표현을 여전히 생성할 수 있으므로, 정확한 특징 표현에 기반하여 객체에게 추천되는 리소스 데이터가 객체의 개인화된 요구를 충족시키고, 정확한 리소스 추천이 구현된다. 본 출원의 실시예에서, 특징 추출 프로세스의 제1 손실과 관심 정렬 처리 프로세스의 손실을 이용하여 관심 정렬 모델을 공동으로 트레이닝하는 방식은, 관심 정렬 모델 의 전반적인 학습 목표를 풍부하게 하고, 다중 목표 학습을 통해 관심 정렬 모델의 성능을 보장할 수 있다. 도 12는 본 출원의 실시예에 따른 전자 디바이스의 개략적인 구조도이다. 도 12를 참조하면, 전자 디바이스는 프로세서, 통신 인터페이스, 및 컴퓨터가 판독 가능한 저장 매체를 포함한다. 프로세서 , 통신 인터페이스, 및 컴퓨터가 판독 가능한 저장 매체는 버스를 통해 또는 다른 방식으로 연결될 수 있다. 통신 인터페이스는 데이터를 수신하고 전송하도록 구성된다. 컴퓨터가 판독 가능한 저장 매체는 전자 디바이스의 메모리에 저장될 수 있다. 컴퓨터가 판독 가능한 저장 매체는 컴퓨터 프로 그램을 저장하도록 구성된다. 컴퓨터 프로그램에는 프로그램 명령어가 포함되어 있다. 프로세서는 컴퓨터 가 판독 가능한 저장 매체에 저장된 프로그램 명령어를 실행하도록 구성된다. 프로세서(또는 중앙 처리 유닛(CPU)이라고도 함)는 전자 디바이스의 컴퓨팅 코어 및 제어 코어이며, 하나 이상의 명령어를 구현하도 록 구성되고, 특히 하나 이상의 명령어를 로딩하여 실행하여 대응하는 방법 프로세스 또는 대응하는 기능을 구 현하도록 구성된다. 본 출원의 실시예는 또한 컴퓨터가 판독 가능한 저장 매체(메모리)를 제공한다. 컴퓨터가 판독 가능한 저장 매 체는 전자 디바이스의 메모리 디바이스이며, 프로그램과 데이터를 저장하도록 구성된다. 여기에서 컴퓨터가 판 독 가능한 저장 매체에는 전자 디바이스의 내부 저장 매체가 포함될 수 있으며, 전자 디바이스가 지원하는 확장 저장 매체도 포함될 수 있다. 컴퓨터가 판독 가능한 저장 매체는 저장 공간을 제공하고, 저장 공간에는 전자 디 바이스의 처리 시스템이 저장되어 있다. 또한, 프로세서에 의해 로딩되고 실행되는 하나 이상의 명령어가 저장 공간에 추가로 저장된다. 이러한 명령어는 하나 이상의 컴퓨터 프로그램(프로그램 코드 포함)일 수 있다. 여기에서 컴퓨터가 판독 가능한 저장 매체는 고속 RAM 메모리일 수도 있고, 예를 들어 적어도 하나의 자기 디스 크 메모리와 같은 비휘발성 메모리일 수도 있으며, 또는 전술한 프로세서로부터 원격으로 위치한 적어도 하나의 컴퓨터가 판독 가능한 저장 매체일 수도 있다. 일부 실시예에서, 컴퓨터가 판독 가능한 저장 매체에는 하나 이상의 명령어가 저장되어 있다. 프로세서는 컴퓨터가 판독 가능한 저장 매체에 저장된 하나 이상의 명령어를 로딩하고 실행하여, 전술한 모델 트레이닝 방 법 실시예에서의 대응하는 작동을 구현한다. 본 출원의 실시예는 또한 컴퓨터 프로그램 제품을 제공한다. 컴퓨터 프로그램 제품에는 컴퓨터가 실행 가능한 명령어가 포함되어 있다. 컴퓨터가 실행 가능한 명령어는 컴퓨터가 판독 가능한 저장 매체에 저장된다. 전자 디 바이스의 프로세서는 컴퓨터가 판독 가능한 저장 매체로부터 컴퓨터가 실행 가능한 명령어를 읽고, 프로세서는 전자 디바이스가 전술한 모델 트레이닝 방법을 수행하도록, 컴퓨터가 실행 가능한 명령어를 실행한다. 본 출원에 개시된 실시예를 참조하여 기술된 예시적인 유닛 및 알고리즘 작동은 전자 하드웨어 또는 컴퓨터 소 프트웨어와 전자 하드웨어의 조합으로 구현될 수 있다는 것을 본 기술 분야의 통상의 기술자는 알 수 있다. 이 러한 기능이 하드웨어나 소프트웨어로 실행되는지는 특정 애플리케이션과 기술 솔루션의 설계 제약에 따라 달라 진다. 본 기술 분야의 통상의 기술자는 각각의 특정 애플리케이션에 대해 설명된 기능을 구현하기 위해 서로 다 른 방법을 사용할 수 있지만, 그 구현이 본 출원의 범위를 벗어난다고 간주되어서는 안 된다. 앞서 언급된 실시예의 일부 또는 전부는 소프트웨어, 하드웨어, 펌웨어 또는 이들의 조합을 사용하여 구현될 수 있다. 소프트웨어가 구현을 위해 구성될 때, 구현은 전체적 또는 부분적으로 컴퓨터 프로그램 제품의 형태로 수 행될 수 있다. 컴퓨터 프로그램 제품에는 하나 이상의 컴퓨터가 실행 가능한 명령어가 포함되어 있다. 컴퓨터 프로그램 명령어가 컴퓨터에 로딩되어 실행될 때, 본 개시의 실시예에 따른 프로세스 또는 기능의 일부 또는 전 부가 생성된다. 컴퓨터는 범용 컴퓨터, 전용 컴퓨터, 컴퓨터 네트워크 또는 다른 프로그래밍 가능 디바이스일 수 있다. 컴퓨터가 실행 가능한 명령어는 컴퓨터가 판독 가능한 저장 매체에 저장되거나 컴퓨터가 판독 가능한 저장 매체를 통해 전송될 수 있다. 컴퓨터가 실행 가능한 명령어는 유선(예를 들어, 동축 케이블, 광섬유, 디지 털 가입자 회선(digital subscriber line, DSL)) 또는 무선(예를 들어, 적외선, 라디오, 마이크로파) 방식으로 웹사이트, 컴퓨터, 서버 또는 데이터 센터에서 다른 웹사이트, 컴퓨터, 서버 또는 데이터 센터로 전송될 수 있 다. 컴퓨터가 판독 가능한 저장 매체는 컴퓨터가 액세스할 수 있는 모든 이용 가능한 매체일 수 있거나, 서버 및 데이터 센터와 같이 이용 가능한 매체에 의해 통합된 하나 이상의 데이터 처리 디바이스를 포함할 수 있다. 이용 가능한 매체는 자기 매체(예를 들어, 소프트 디스크, 하드 디스크 또는 자기 테이프), 광 매체(예를 들어,DVD), 반도체 매체(예를 들어, 솔리드 스테이트 드라이브(solid state drive, SSD)) 또는 이와 유사한 것일 수 있다. 설명은 본 출원의 특정 구현에 불과하며, 본 출원의 보호 범위를 제한하려는 것은 아니다. 본 출원에 개시된 기 술적 범위 내에서 본 기술 분야의 기술자가 쉽게 생각해 낼 수 있는 모든 변형 또는 대체는 본 출원의 보호 범 위에 속한다. 따라서 본 출원의 보호 범위는 첨부된 청구항에 따른다."}
{"patent_id": "10-2025-7009207", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 출원의 실시예 또는 관련 기술의 기술적 솔루션을 보다 명확하게 설명하기 위해, 이하에서는 실시예 또는 관 련 기술을 설명하기 위한 첨부 도면을 간략히 소개한다. 명백히, 다음 설명에 첨부된 도면은 단지 본 출원의 일 부 실시예를 보여주는 것일 뿐이며, 이 기술 분야에 통상의 지식을 가진 자라면 창의적인 노력 없이도 첨부된 도면으로부터 다른 도면을 도출해낼 수 있을 것이다. 도 1a는 본 출원의 실시예에 따른 리소스 추천 시스템의 아키텍처의 개략도이다. 도 1b는 본 출원의 실시예에 따른 또 다른 리소스 추천 시스템의 아키텍처의 개략도이다. 도 2는 본 출원의 실시예에 따른 관심 정렬 모델의 모델 구조의 개략도이다. 도 3은 본 출원의 실시예에 따른 모델 트레이닝 방법의 개략적인 흐름도이다. 도 4는 본 출원의 실시예에 따른 제2 도메인의 객체 리소스 그래프를 구성하는 개략도이다. 도 5는 본 출원의 실시예에 따른 그래프 인코딩 학습 아키텍처의 개략도이다. 도 6은 본 출원의 실시예에 따른 제1 도메인과 제2 도메인 간의 관심 정렬 처리를 수행하는 개략도이다. 도 7은 본 출원의 실시예에 따른 제1 도메인 및 제2 도메인 각각에서 관심 정렬 처리를 수행하는 개략도이다. 도 8은 본 출원의 실시예에 따른 그래프 재구성의 개략도이다. 도 9는 본 출원의 실시예에 따른 또 다른 모델 트레이닝 방법의 개략적인 흐름도이다. 도 10은 본 출원의 실시예에 따른 타깃 객체의 융합된 특징 표현과 각 후보 리소스 데이터의 리소스 특징 표현 간의 매칭을 수행하는 개략도이다. 도 11은 본 출원의 실시예에 따른 모델 트레이닝 장치의 개략적인 구조도이다.도 12는 본 출원의 실시예에 따른 전자 디바이스의 개략적인 구조도이다."}
