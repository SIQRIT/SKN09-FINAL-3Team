{"patent_id": "10-2022-0123166", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0043999", "출원번호": "10-2022-0123166", "발명의 명칭": "인공지능 네트워크를 위한 학습 데이터 생성 장치 및 방법", "출원인": "주식회사 라온버드", "발명자": "천세욱"}}
{"patent_id": "10-2022-0123166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "객체를 촬영한 영상 프레임을 생성하고 상기 객체의 배경에 대한 위치 정보를 획득하는 데이터 취득모듈;상기 데이터 취득 모듈로부터 생성된 영상 프레임으로부터 상기 객체의 마스크를 추출하고, 상기 객체의 배경에대한 위치 정보를 이용하여 상기 추출한 객체의 마스크를 가상 배경에 합성한 합성 데이터를 생성하는 합성 데이터 생성모듈; 및상기 합성 데이터 생성모듈로부터 생성된 합성 데이터로부터 상기 객체를 레이블링한 학습 데이터를 생성하는학습데이터 셋 생성모듈;을 포함하는 인공지능 네트워크를 위한 학습 데이터 생성 장치."}
{"patent_id": "10-2022-0123166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 데이터 취득모듈은,상기 객체가 실제로 배치될 기구 내부와 같은 형상, 사이즈 및 색상으로 구현되는 객체 배치 공간부;상기 객체 배치 공간부의 내부에 위치하며, 턴 테이블 형태로 구현되어 상기 객체를 적재한 상태로 회전 기동하는 객체 기동부;상기 객체 배치 공간부의 내부를 탑 다운 뷰 방식으로 촬영하여 상기 객체에 대한 영상 프레임을 생성하는 객체촬영부; 및상기 객체 촬영부에 의해 촬영된 영상 프레임을 실시간 디스플레이하고, 상기 객체의 배경에 대한 위치 정보로서 상기 객체가 상기 객체 기동부의 어느 지점에 위치하는지에 대한 위치 정보를 획득하는 객체 정보 표시부;를포함하는 인공지능 네트워크를 위한 학습 데이터 생성 장치."}
{"patent_id": "10-2022-0123166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 합성 데이터 생성모듈은,컴퓨터 비전 알고리즘을 통해 상기 데이터 취득모듈로부터 전송된 영상 프레임에서 배경과 노이즈가 일부 제거된 1차 마스크를 추출하고, 상기 1차 마스크를 입력으로 하는 딥러닝 네트워크를 통해 배경 및 노이즈가 정밀제거된 2차 마스크를 출력하며, 상기 출력한 2차 마스크로부터 상기 객체의 마스크 및 바운딩 박스를 추출하는마스크 획득부;상기 객체의 배경에 대한 위치정보를 이용하여 상기 마스크 획득부로부터 추출된 상기 객체의 마스크를 상기 가상 배경에 합성한 합성 데이터를 생성하는 객체 합성부; 및상기 객체 합성부가 생성한 합성 데이터에 대해 회전, 이동, 어핀, 자르기, 지우기, 폐색 중 임의의 연산을 수행한 합성 증폭 데이터를 상기 합성 데이터로 추가 생성하는 데이터 증폭부;를 포함하는 인공지능 네트워크를위한 학습 데이터 생성 장치."}
{"patent_id": "10-2022-0123166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 마스크 획득부는,상기 컴퓨터 비전 알고리즘으로 영상 차감법, 이진화법, 비지역 평균 알고리즘 및 반복적 침식 연산과 팽창 연산을 순차적으로 수행하여 상기 1차 마스크를 추출하는 것을 특징으로 하는 인공지능 네트워크를 위한 학습 데이터 생성 장치."}
{"patent_id": "10-2022-0123166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 마스크 획득부는,상기 딥러닝 네트워크로 중요 물체 검출 모델 중 유 스퀘어넷(U2-Net) 또는 바스넷(BASNet)을 이용하여 상기 2공개특허 10-2024-0043999-3-차 마스크를 출력하는 것을 특징으로 하는 인공지능 네트워크를 위한 학습 데이터 생성 장치."}
{"patent_id": "10-2022-0123166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "데이터 취득모듈이 객체를 촬영한 영상 프레임을 생성하고 상기 객체의 배경에 대한 위치 정보를 획득하는 제1단계;합성 데이터 생성모듈이 상기 데이터 취득 모듈로부터 생성된 영상 프레임으로부터 상기 객체의 마스크를 추출하는 제2 단계;상기 합성 데이터 생성모듈이 상기 객체의 배경에 대한 위치 정보를 이용하여 상기 추출한 객체의 마스크를 가상 배경에 합성한 합성 데이터를 생성하는 제3 단계; 및학습 데이터 셋 생성모듈이 상기 합성 데이터 생성모듈로부터 생성된 합성 데이터로부터 상기 객체를 레이블링한 학습 데이터를 생성하는 제4 단계;를 포함하는 인공지능 네트워크를 위한 학습 데이터 생성 방법."}
{"patent_id": "10-2022-0123166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 제1 단계는,객체 배치 공간부의 저면에 위치한 객체 기동부가 상기 객체를 적재한 상태로 회전 기동하는 단계;객체 촬영부가 상기 객체 배치 공간부의 내부를 탑 다운 뷰 방식으로 촬영하여 기동하는 상기 객체에 대한 영상프레임을 생성하는 단계;객체 정보 표시부가 상기 생성한 영상 프레임에 따라 상기 객체 기동부 상 상기 객체가 위치하는 지점을 상기객체의 배경에 대한 위치 정보로 획득하는 단계; 및상기 객체 정보 표시부가 상기 생성한 영상 프레임 및 상기 획득한 객체의 배경에 대한 위치 정보를 상기 합성데이터 생성 모듈로 전송하는 단계;를 포함하는 인공지능 네트워크를 위한 학습 데이터 생성 방법."}
{"patent_id": "10-2022-0123166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 제2 단계는,마스크 획득부가 상기 데이터 취득 모듈로부터 생성된 영상 프레임에 대해 이미지 영상 차감법 및 이진화법 처리를 통해 영상 프레임 내 움직이는 객체를 파악하고 배경을 제거한 바이너리 이미지를 생성하는 단계;.상기 마스크 획득부가 비지역적 평균 알고리즘을 이용하여 상기 생성한 바이너리 이미지 상의 노이즈를 제거하는 전처리를 수행하는 단계;상기 마스크 획득부가 상기 전처리된 바이너리 이미지에 대해 침식 연산 및 팽창 연산을 소정 횟수 반복 수행하는 단계;상기 마스크 획득부가 상기 침식 연산 및 팽창 연산 과정이 반복 수행된 바이너리 이미지에 대해서 컨투어 프로세스를 수행하여 상기 객체에 대한 1차 마스크를 추출하는 단계; 및상기 마스크 획득부가 상기 1차 마스크를 유 스퀘어넷의 입력으로 하여 출력된 2차 마스크를 상기 객체의 마스크로 추출하는 단계;를 포함하는 인공지능 네트워크를 위한 학습 데이터 생성 방법."}
{"patent_id": "10-2022-0123166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서, 상기 제3 단계는,객체 합성부가 상기 객체의 배경에 대한 위치 정보에 기초하여 상기 추출한 객체의 마스크가 배치될 상기 가상배경 상의 위치를 결정하는 단계; 상기 객체 합성부가 상기 추출한 객체의 마스크를 상기 결정한 가상 배경 상의 위치에 합성한 합성 데이터를 생성하는 단계;데이터 증폭부가 상기 객체 합성부에서 생성된 합성 데이터를 증폭한 합성 증폭 데이터를 생성하는 단계; 상기 객체 합성부가 상기 생성한 합성데이터를 학습 데이터 셋 생성모듈로 전송하는 단계; 및공개특허 10-2024-0043999-4-상기 데이터 증폭부가 상기 생성한 합성 증폭 데이터를 상기 학습 데이터 생성 모듈로 전송하는 단계;를 포함하는 포함하는 인공지능 네트워크를 위한 학습 데이터 생성 방법."}
{"patent_id": "10-2022-0123166", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 네트워크를 위한 학습 데이터 생성 장치가 개시된다. 상기 학습 데이터 생성 장치는 객체를 촬영한 영 상 프레임을 생성하고 상기 객체의 배경에 대한 위치 정보를 획득하는 데이터 취득모듈과 상기 데이터 취득 모듈 로부터 생성된 영상 프레임으로부터 상기 객체의 마스크를 추출하고, 상기 객체의 배경에 대한 위치 정보를 이용 하여 상기 추출한 객체의 마스크를 가상 배경에 합성한 합성 데이터를 생성하는 합성 데이터 생성모듈 및 상기 합성 데이터 생성모듈로부터 생성된 합성 데이터로부터 상기 객체를 레이블링한 학습 데이터를 생성하는 학습데 이터 셋 생성모듈을 포함한다."}
{"patent_id": "10-2022-0123166", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 개념에 따른 실시 예는 인공지능 네트워크의 학습을 위한 데이터셋을 생성하는 기술에 대한 것으로, 보다 상세하게는 취득한 영상 또는 이미지들로부터 물체를 추출하고, 추출한 물체를 배경 이미지 상 대응하는 위치에 적절히 배치하여 합성 데이터(synthetic data)를 생성하며, 생성한 합성 데이터를 학습 데이터(training data)로 이용함으로써 사람의 데이터 라벨링이 필요없는 학습 데이터를 생성할 수 있는 기술에 대한 것이다."}
{"patent_id": "10-2022-0123166", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 네트워크의 학습을 위해서는 방대한 양의 학습 데이터를 확보해야 하는데, 충분치 못한 학습 데이터로 학습을 진행하는 경우 오브젝트에 대한 특징을 제대로 찾지 못하고 주어진 데이터에만 과적합 되는 오버피팅 (overfitting) 현상이 발생할 수 있다. 이를 해결하기 위한 다양한 방법이 존재하지만 역시 가장 근본적인 방법 은 학습 데이터를 충분히 넣어주는 방법이다. 그러나 이러한 학습 데이터를 확보하기 위해서는 대량의 원천 데 이터 수집이 필요하며 대량의 원천 데이터를 수집하는 것 자체의 현실적인 어려움 뿐만 아니라, 사람이 직접 수 작업으로 데이터 라벨링을 수행해야 하기 때문에 작업 시간과 인건비가 많이 소요되고, 또한 여러 사람에 의해 라벨링이 이루어지기 때문에 일관된 기준에 따라 정확히 라벨링이 되었는지를 담보할 수도 없었다. 그럼에도 불 구하고 학습 데이터의 확보는 매우 중요한 문제이기에 현재 데이터 라벨링을 위한 각종 교육이나 구인, 민간 자 격증 광고까지도 나타나고 있다."}
{"patent_id": "10-2022-0123166", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적인 과제는 사람의 별도 데이터 레이블링없이도 다양한 시나리오에 따른 방대 한 양의 합성 데이터를 학습 데이터로서 생성할 수 있는 장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0123166", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 인공지능 네트워크를 위한 학습 데이터 생성 장치는 객체를 촬영한 영상 프레임을 생성하고 상기 객체의 배경에 대한 위치 정보를 획득하는 데이터 취득모듈과 상기 데이터 취득 모듈로부터 생성 된 영상 프레임으로부터 상기 객체의 마스크를 추출하고, 상기 객체의 배경에 대한 위치 정보를 이용하여 상기 추출한 객체의 마스크를 가상 배경에 합성한 합성 데이터를 생성하는 합성데이터 생성모듈 및 상기 합성 데이터 생성모듈로부터 생성된 합성 데이터로부터 상기 객체를 레이블링한 학습 데이터를 생성하는 학습데이터 셋 생성 모듈을 포함한다. 상기 데이터 취득모듈은 상기 객체가 실제로 배치될 기구 내부와 같은 형상, 사이즈 및 색상으로 구현되는 객체 배치 공간부와 상기 객체 배치 공간부의 내부에 위치하며, 턴 테이블 형태로 구현되어 상기 객체를 적재한 상태 로 회전 기동하는 객체 기동부와 상기 객체 배치 공간부의 내부를 탑 다운 뷰 방식으로 촬영하여 상기 객체에 대한 영상 프레임을 생성하는 객체 촬영부 및 상기 객체 촬영부에 의해 촬영된 영상 프레임을 실시간 디스플레 이하고, 상기 객체의 배경에 대한 위치 정보로서 상기 객체가 상기 객체 기동부의 어느 지점에 위치하는지에 대 한 위치 정보를 획득하는 객체 정보 표시부를 포함할 수 있다. 실시 예에 따라, 상기 합성 데이터 생성모듈은 컴퓨터 비전 알고리즘을 통해 상기 데이터 취득모듈로부터 전송 된 영상 프레임에서 배경과 노이즈가 일부 제거된 1차 마스크를 추출하고, 상기 1차 마스크를 입력으로 하는 딥 러닝 네트워크를 통해 배경 및 노이즈가 정밀 제거된 2차 마스크를 출력하며, 상기 출력한 2차 마스크로부터 상 기 객체의 마스크 및 바운딩 박스를 추출하는 마스크 획득부와 상기 객체의 배경에 대한 위치정보를 이용하여 상기 마스크 획득부로부터 추출된 상기 객체의 마스크를 상기 가상 배경에 합성한 합성 데이터를 생성하는 객체 합성부 및 상기 객체 합성부가 생성한 합성 데이터에 대해 회전, 이동, 어핀, 자르기, 지우기, 폐색 중 임의의 연산을 수행한 합성 증폭 데이터를 상기 합성 데이터로 추가 생성하는 데이터 증폭부를 포함할 수 있다. 실시 예에 따라, 상기 마스크 획득부는 상기 컴퓨터 비전 알고리즘으로 영상 차감법, 이진화법, 비지역 평균 알 고리즘 및 반복적 침식 연산과 팽창 연산을 순차적으로 수행하여 상기 1차 마스크를 추출하는 것을 특징으로 할 수 있다. 또한, 실시 예에 따라 상기 마스크 획득부는 상기 딥러닝 네트워크로 중요 물체 검출 모델 중 유 스퀘어넷(U2- Net) 또는 바스넷(BASNet)을 이용하여 상기 2차 마스크를 출력하는 것을 특징으로 할 수도 있다. 본 발명의 일 실시 예에 따른 인공지능 네트워크를 위한 학습 데이터 생성 방법은 데이터 취득모듈이 객체를 촬 영한 영상 프레임을 생성하고 상기 객체의 배경에 대한 위치 정보를 획득하는 제1 단계와 합성 데이터 생성모듈 이 상기 데이터 취득 모듈로부터 생성된 영상 프레임으로부터 상기 객체의 마스크를 추출하는 제2 단계와 상기 합성 데이터 생성모듈이 상기 객체의 배경에 대한 위치 정보를 이용하여 상기 추출한 객체의 마스크를 가상 배 경에 합성한 합성 데이터를 생성하는 제3 단계 및 학습 데이터 셋 생성모듈이 상기 합성 데이터 생성모듈로부터 생성된 합성 데이터로부터 상기 객체를 레이블링한 학습 데이터를 생성하는 제4 단계를 포함한다. 실시 예에 따라, 상기 제1 단계는 객체 배치 공간부의 저면에 위치한 객체 기동부가 상기 객체를 적재한 상태로 회전 기동하는 단계와 객체 촬영부가 상기 객체 배치 공간부의 내부를 탑 다운 뷰 방식으로 촬영하여 기동하는 상기 객체에 대한 영상 프레임을 생성하는 단계와 객체 정보 표시부가 상기 생성한 영상 프레임에 따라 상기 객 체 기동부 상 상기 객체가 위치하는 지점을 상기 객체의 배경에 대한 위치 정보로 획득하는 단계 및 상기 객체 정보 표시부가 상기 생성한 영상 프레임 및 상기 획득한 객체의 배경에 대한 위치 정보를 상기 합성 데이터 생 성 모듈로 전송하는 단계를 포함할 수 있다. 실시 예에 따라, 상기 제2 단계는 마스크 획득부가 상기 데이터 취득 모듈로부터 생성된 영상 프레임에 대해 이 미지 영상 차감법 및 이진화법 처리를 통해 영상 프레임 내 움직이는 객체를 파악하고 배경을 제거한 바이너리 이미지를 생성하는 단계와 상기 마스크 획득부가 비지역적 평균 알고리즘을 이용하여 상기 생성한 바이너리 이 미지 상의 노이즈를 제거하는 전처리를 수행하는 단계와 상기 마스크 획득부가 상기 전처리된 바이너리 이미지 에 대해 침식 연산 및 팽창 연산을 소정 횟수 반복 수행하는 단계와 상기 마스크 획득부가 상기 침식 연산 및 팽창 연산 과정이 반복 수행된 바이너리 이미지에 대해서 컨투어 프로세스를 수행하여 상기 객체에 대한 1차 마 스크를 추출하는 단계 및 상기 마스크 획득부가 상기 1차 마스크를 유 스퀘어넷의 입력으로 하여 출력된 2차 마 스크를 상기 객체의 마스크로 추출하는 단계를 포함할 수 있다. 실시 예에 따라, 상기 제3 단계는 객체 합성부가 상기 객체의 배경에 대한 위치 정보에 기초하여 상기 추출한 객체의 마스크가 배치될 상기 가상 배경 상의 위치를 결정하는 단계와 상기 객체 합성부가 상기 추출한 객체의 마스크를 상기 결정한 가상 배경 상의 위치에 합성한 합성 데이터를 생성하는 단계와 데이터 증폭부가 상기 객 체 합성부에서 생성된 합성 데이터를 증폭한 합성 증폭 데이터를 생성하는 단계와 상기 객체 합성부가 상기 생 성한 합성데이터를 학습 데이터 셋 생성모듈로 전송하는 단계 및 상기 데이터 증폭부가 상기 생성한 합성 증폭 데이터를 상기 학습 데이터 생성 모듈로 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0123166", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기와 같이 본 발명의 일 실시 예에 따른 인공지능 네트워크를 위한 학습 데이터 생성 장치 및 생성 방법은 취 득한 영상 또는 이미지들로부터 객체를 추출하고, 추출한 객체를 배경 이미지 상 대응하는 위치에 적절히 배치 한 합성 데이터를 학습 데이터로 이용함으로써 사람의 개입없이 빠른 시간안에 적은 비용으로 학습 데이터 셋을 생성할 수 있는 효과가 있다. 나아가 생성한 합성 데이터를 다양하게 변형, 증폭한 합성 증폭 데이터를 추가 생성할 수 있으므로 인공지능 네 트워크의 학습시 필요한 다양한 변수에 대응할 수 있는 효과가 있다."}
{"patent_id": "10-2022-0123166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 또는 기능적 설명들은 단 지 본 발명의 개념에 따른 실시 예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시 예들은 다양한 형태들로 실시될 수 있으며 본 명세서에 설명된 실시 예들에 한정되지 않는다. 본 발명의 개념에 따른 실시 예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시 예들을 도면에 예시하고 본 명세서에 상세하게 설명하고자 한다. 그러나 이는 본 발명의 개념에 따른 실시 예들 을 특정한 개시 형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 만, 예컨대 본 발명의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1구성요소는 제2구성요소로 명명될 수 있고, 유사하게 제2구성요소는 제1구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함한다\" 또는 \"갖는다\" 등의 용어는 설명된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구 성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한 다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미가 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 포함하는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형 식적인 의미로 해석되지 않는다. 이하, 첨부한 도면을 참조하여 본 발명의 바람직한 실시 예를 설명함으로써, 본 발명을 상세히 설명한다. 도 1은 본 발명의 일 실시 예에 따른 인공지능 네트워크를 위한 학습 데이터 생성 장치(이하, '학습 데이터 생 성 장치'라 함)의 구성을 나타내는 블럭도이다. 도 1을 참조하면, 학습 데이터 생성 장치는 데이터 취득모듈, 합성 데이터 생성모듈 및 학습데이 터 셋 생성모듈을 포함하여 구성된다. 이하, 학습 데이터 생성 장치의 각 구성요소(100, 300 및 500)에 대해서 상세히 설명한다. 도 2는 도 1에 도시된 객체 취득 모듈의 구성을 나타내는 블럭도이다. 도 1 및 도 2를 참조하면, 데이터 취득 모듈은 객체 배치 공간부, 객체 기동부, 객체 촬영부 및 객체 정보 표시부를 포함한다. 객체 배치 공간부는 제품이나 물체 등의 객체(object)가 학습 데이터로 이용될 수 있도록 해당 객체가 촬 영되는 공간이며, 객체 배치 공간부의 내부는 해당 객체가 실제로 배치될 위치(예컨대, 진열대)나 기구(예 컨대, 냉장고) 등의 내부와 유사한 형상, 사이즈 및 색상으로 구현될 수 있다. 예컨대, 캔음료라는 특정한 객체가 냉장고라는 특정한 전자 제품에 배치되는 것을 상정하는 경우, 객체 배치 공 간부의 내부는 상기 냉장고 내부의 형상, 사이즈 및 색상과 유사하게 구현될 수 있다. 실시 예에 따라서 객체 배치 공간부는 해당 객체가 실제로 배치될 위치(예컨대, 진열대)나 기구(예컨대, 냉장고)가 될 수도 있다. 객체 기동부는 객체 배치 공간부의 내부에 위치하며 촬영하고자 하는 특정 객체를 적재할 수 있다. 이때 상기 특정 객체는 단독의 객체일 수도 있고 복수의 객체들일 수도 있으며, 복수의 객체들인 경우 동일 클 래스의 객체들 또는 이종 클래스의 객체들일 수도 있다. 실시 예에 따라, 객체 기동부는 객체 배치 공간부의 내부 바닥면에 턴 테이블(turn table)형태로 구 현되어 회전할 수 있으며, 따라서 객체 기동부는 상기 적재된 특정 객체를 기동할 수 있다. 이때, 턴 테이블의 직경은 턴 테이블이 원활하게 회전함과 동시에 최대한 객체 배치 공간부 내부 바닥면의 어느 위치에도 특정 객체가 위치할 수 있도록, 객체 배치 공간부의 내부 가로 또는 세로 길이보다 미세하 게 작게 형성되는 것이 바람직하다. 실시 예에 따라 상기 객체 기동부는 30초 내지 60초 당 1 회전할 수 있도록 설정될 수 있다. 객체 촬영부는 동영상(Video)을 촬영할 수 있는 카메라를 포함하며, 상기 카메라를 통해 객체 배치 공간부 의 내부를 상부에서 하부(예컨대, 바닥면 또는 객체 기동부)를 바라보는 탑 다운 뷰(Top-Down View) 방식으로 촬영하여 객체에 대한 영상 프레임(Image Frames)을 생성한다. 이때, 객체 촬영부의 상기 카메라는 초당 24 프레임(24fps) 또는 30 프레임(30fps)으로 해당 객체에 대한 영상 프레임을 생성할 수 있으며, 객체 촬영부는 생성한 영상 프레임을 객체 정보 디스플레이부로 전 송한다. 실시 예에 따라, 객체 촬영부는 객체 배치 공간부의 내부를 정면에서 바라보는 프론트 뷰(Front View) 방식으로 촬영하여 객체에 대한 영상 프레임을 생성할 수도 있으며, 상기 카메라를 3축(x축, y축 및 z 축)에 따라 이동하며 해당 객체에 대한 영상 프레임을 생성할 수도 있다. 객체 정보 표시부는 디스플레이 디바이스를 통해 객체 촬영부에 의해 촬영된 영상 프레임을 실시간 디스플레이하고, 객체 기동부 상 어느 지점에 해당 객체가 놓여져 있는지 객체의 위치 정보(예컨대, 턴 테 이블 중심으로부터의 거리와 각도에 대한 정보)를 획득하며, 합성 데이터 생성모듈로 생성된 영상 프레임 과 획득한 객체의 위치 정보(Location information)를 전송한다. 도 3은 도 1에 도시된 합성 데이터 생성모듈의 내부 구성을 나타내는 블럭도이다. 도 1 내지 도 3을 참조하면, 합성 데이터 생성모듈은 마스크 획득부, 객체 합성부 및 데이터 증 폭부를 포함하며, 데이터 취득 모듈로부터 전송된 영상 프레임으로부터 다양한 합성 데이터 (Synthetic Data)를 생성하는 역할을 수행한다. 합성 데이터 생성모듈이 포함하는 마스크 획득부는 데이터 취득모듈로부터 전송된 영상 프레임 으로부터 배경(background)을 제거하고, 전경(foreground)인 객체의 마스크(Mask) 또는 바운딩 박스(Bounding Box)를 추출할 수 있다. 실시 예에 따라, 마스크 획득부는 다양한 컴퓨터 비전 알고리즘(Computer Vision Algorithm)을 사용하여 배경 및 노이즈가 개략적으로 제거된 객체에 대한 1차 마스크를 추출하고, 딥러닝 네트워크(Deep Learnig network)를 사용하여 상기 1차 마스크에서 배경 및 노이즈가 정밀하게 제거된 2차 마스크를 추출할 수 있다. 우선, 마스크 획득부는 상기의 컴퓨터 비전 알고리즘 중 이미지 영상 차감법(image subtraction) 및 이진 화법(thresholding)을 통해 영상 프레임 내에서 움직이는 객체를 파악하고 배경을 제거한 바이너리(binary) 이 미지를 생성한다. 또한, 마스크 획득부는 생성한 바이너리 이미지 상의 객체에 포함되어 있는 노이즈를 제거하는 전처리 (preprocessing)를 수행한다. 이러한 전처리 과정에 있어서, 마스크 획득부는 로컬 픽셀들만 참조하여서 노이즈를 제거하는 일반적인 가 우시안 필터(Gaussian Filter)나 메디안 필터(Median Filter) 또는 양방향 필터(Bilateral Filter)를 사용하지 않고, 비지역적 평균 알고리즘(Non-Local Means 또는 NLMeans)을 이용하여 노이즈를 제거한다. 도 4는 마스크 획득부가 비지역적 평균 알고리즘(NLMeans)을 이용하여 전처리를 수행한 예시도이다. 순차적으로 마스크 획득부는 보다 정밀하게 노이즈를 제거하고 충분한 바운딩 박스를 얻기 위해 상기 전처 리된 이미지에 대해 침식 연산(Erosion) 및 팽창 연산(Dilatioin)을 반복(예컨대, 침식 연산 7회, 팽창 연산 7 회) 수행한다. 이때, 침식 연산(Erosion)은 노이즈를 제거하기 위한 프로세스이고, 팽창 연산(Dilatioin)은 충분한 크기의 바 운딩 박스를 획득할 수 있도록 하는 프로세스라고 할 수 있다. 실시 예에 따라, 마스크 획득부은 침식 연산 후 팽창 연산을 반복 적용하는 오프닝(opening) 기법 또는 팽 창 연산 후 침식 연산을 반복 적용하는 클로징(closing) 기법을 적절히 조합하여 노이즈를 제거할 수 있다. 도 5는 마스크 획득부가 오프닝 기법 및 클로징 기법을 조합하여 노이즈를 제거한 예시도이다. 이후, 마스크 획득부는 상기와 같은 침식 연산 및 팽창 연산 과정이 반복 수행된 이미지에 대해서 컨투어 (Contour) 프로세스를 수행하여 해당 객체에 대한 러프(rough)한 마스크인 1차 마스크를 추출한다. 그리고 마스크 획득부는 추출한 1차 마스크에 대해 볼록껍질(Convex Hull) 프로세스를 수행하여 해당 객체 에 대한 바운딩 박스를 생성할 수 있다. 한편, 마스크 획득부는 상기와 같은 컴퓨터 비전 알고리즘을 통해 배경 및 노이즈가 개략적으로 제거된 1 차 마스크에 대해 딥러닝 네트워크(Deep Learnig network)를 통해 배경 및 노이즈를 더 정밀하게 제거한 2차 마 스크를 추출할 수 있다. 이는 상기와 같은 NLMeans, 오프닝/클로징 기법 등의 컴퓨터 비전 알고리즘 만을 이용하여 배경을 분리 제거하 는 경우에 배경과 객체의 색상이 비슷하면 객체 일부가 배경으로 인식되어 소실되는 경우가 다수 발생할 수 있 기 때문이다. 예컨대, 유리병, 플라스틱, 비닐 등과 같이 내부가 비쳐 배경의 색으로 보일 수 있는 특수한 재질의 객체는 상 기와 같은 오류가 자주 발생할 수 있다. 이에 마스크 획득부는 상기의 컴퓨터 비전 알고리즘을 통한 과정 뿐만 아니라 딥러닝 네트워크를 이용하여 이러한 문제를 해결한다. 마스크 획득부가 사용하는 상기 딥러닝 네트워크는 영상에서 배경이 아닌 전경, 즉 객체를 추정하는 중요 물체 검출(Salient Object Detectioin, SOD) 모델이며, 실시 예에 따라 상기 중요 물체 검출 모델은 유 스퀘어 넷(U-squared Net, U2-Net) 또는 바스넷(Boundary-Aware Salient Object Detecion Network, BASNet)일 수 있 다. 즉, 마스크 획득부는 상기 1차 마스크를 상기 중요 물체 검출 모델(여컨대, 유 스퀘어넷)의 입력(input)으 로 하고 배경 및 노이즈가 더 정밀하게 제거된 2차 마스크를 출력(output)으로 취득한다. 실시 예에 따라, 마스크 획득부는 추출한 2차 마스크에 대해 볼록껍질(Convex Hull) 프로세스를 수행하여 해당 객체에 대한 바운딩 박스를 생성할 수도 있다. 결국, 마스크 획득부는 상기와 같은 컴퓨터 비전 알고리즘 및 딥러닝 네트워크를 통해 데이터 취득모듈 로부터 전송된 이미지 또는 프레임에서 배경(back ground)을 제거한 객체의 마스크(1차 마스크 및 2차 마 스크)를 추출하고 물체 합성부로 전송한다. 객체 합성부는 마스크 획득부로부터 전송된 배경이 제거된 객체의 마스크(예컨대, 2차 마스크)를 실 제 공간(예컨대, 냉장고 안)과 유사한 가상의 배경에 합성한 합성 데이터(Synthetic Data)를 생성하는 역할을수행한다. 즉, 객체 합성부는 해당 객체를 가상 배경에 합성한 합성 데이터를 생성하며, 실시 예에 따라 상기 가상 배경은 해당 객체가 실제로 배치될 위치(예컨대, 진열대)나 기구 내부(예컨대, 냉장고 내부)가 될 수 있다. 이때. 객체 합성부는 마스크 획득부로부터 전송된 객체의 마스크가 가상 배경의 어느 위치에 배치되 야 하는지를 결정하여 합성하고, 이러한 결정을 위해 객체 정보 표시부로부터 전송된 해당 객체의 위치 및 각도 정보를 이용한다. 한편, 앞서 도 2에서 설명한 객체 배치 공간부는 해당 객체가 실제로 배치될 위치나 기구(예컨대, 냉장고) 등의 내부와 유사한 형상, 사이즈 및 색상으로 구현될 수 있기 때문에, 상기 가상의 배경은 객체 배치 공간부 의 내부와도 대비될 수 있다. 이에 따라, 객체 합성부는 객체 배치 공간부의 내부 바닥면에 구현된 객체 기동부 상에 적재되 어 촬영된 특정 객체의 위치를 상기 가상 배경에서 해당 객체가 배치될 근사적 위치로 결정할 수 있다. 즉, 객체 합성부는 마스크 획득부로부터 전송된 객체의 2차 마스크와 해당 객체가 객체 기동부 상 어느 지점에 적재되어 있었는지에 대한 위치 정보(예컨대, 턴 테이블 중심으로부터의 거리와 각도에 대한 정 보)를 알고 있기 때문에 상기 가상 배경에서 해당 객체가 배치되어야 할 근사적 위치를 결정할 수 있다. 도 6은 객체 합성부가 특정 객체의 마스크를 가상의 배경에 합성한 예시도이다. 이 때, 도 6의 (a)는 해당 객체의 위치 정보없이 객체 마스크를 가상 배경에 합성한 예를 나타내고, 도 6의 (b)는 해당 객체의 위치 정보를 이용하여 객체 마스크를 가상 배경에 합성한 예를 나타낸다. 도 6의 (a)를 참조하면, 가상의 배경 내에 배치된 여러 객체들 중 이들 사이에 물리적으로는 불가능한 상태로 배치된 객체들을 확인할 수 있으며, 이에 비해 도 6의 (b)를 참조하면 모든 객체가 가상 배경 내에서 매우 자연 스럽게 배치된 것을 확인할 수 있다. 결국 객체 합성부는 해당 객체에 대한 2차 마스크를 해당 객체의 위치 및 각도 정보를 이용하여 상기 가상 의 배경의 최적화된 위치에 합성함으로써 상기 합성 데이터를 생성한다. 한편, 데이터 증폭부는 인공지능 네트워크를 학습시키기 위해 발생할 수 있는 수 많은 시나리오를 커버할 수 있도록 객체 합성부가 생성한 합성 데이터를 증폭(Augmentation)하는 역할을 수행한다. 예컨대, 데이터 증폭부는 객체의 회전(Rotation, Perspective), 크기 변환(Scale, Zoom), 이동(Shift), 어핀(Affine), 자르기(Crop)나 지우기(Erasing) 등의 일반적인 증폭 뿐만 아니라. 객체의 일부가 다른 객체에 의해 가려지는 폐색(Occlusion), 객체가 유리나 거울 등에 반사되어 보이는 경우 등을 가정하여 데이터를 증폭 한 합성 증폭 데이터(Augmented Data)를 생성할 수 있다. 이와 같이 데이터 증폭부는 객체 합성부가 생성한 합성 데이터를 다양하게 변형, 증폭함으로써 다양 한 변수에 인공지능 네트워크가 대응할 수 있도록 한다. 다시 도 1을 참조하면, 학습 데이터 셋 생성모듈은 합성 데이터 생성모듈로부터 생성된 합성 데이터 또는 데이터 증폭부에서 생성된 합성 증폭 데이터로부터 객체를 레이블링(Labeling 또는 Annotation)한 학 습 데이터 셋을 생성하는 역할을 수행한다. 이때, 마스크 획득부로부터 추출된 해당 객체에 대한 바운딩 박스(1차 마스크에 대한 바운딩 박스 또는 2 차 마스크에 대한 바운딩 박스)를 이용하여 자동으로 해당 객체를 레이블링할 수 있다. 따라서 종래의 데이터 레이블링은 사람이 직접 객체를 촬영하고 레이블링을 해주어야 하기 때문에 많은 시간과 비용이 발생하지만, 본 발명의 실시 예에 따른 학습 데이터 셋 생성모듈는 합성 데이터를 이용하기 때문에 사람의 개입없이 빠른 시간안에 적은 비용으로 학습 데이터 셋(Training Data Set) 생성이 가능하다. 도 7은 본 발명의 일 실시 예에 따른 인공지능 네트워크를 위한 학습 데이터 생성 방법(이하, '학습 데이터 생 성 방법'이라 함)를 구체적으로 설명하기 위한 순서도이다. 도 1 내지 도 7을 참조하면, 데이터 취득모듈은 객체를 촬영한 영상 프레임을 생성하고 해당 객체의 배경 에 대한 위치 정보를 획득한다(Step 1). 도 8은 Step 1을 보다 상세히 설명하기 위한 순서도이며, 이하 도 8을 참조하여 상기 Step 1에 대해 상세히 설 명한다. 객체 배치 공간부의 저면에 위치하고, 해당 객체가 적재된 객체 기동부가 회전 기동한다(S110). 이때, 객체 배치 공간부는 제품이나 물체 등의 객체가 학습 데이터로 이용될 수 있도록 객체가 촬영되는 공간을 의미하며, 해당 객체가 실제로 배치될 위치나 기구(예컨대, 냉장고)가 될 수 있다. 객체 촬영부는 객체 배치 공간부의 내부를 탑 다운 뷰(Top-Down View) 방식으로 촬영하여 객체에 대 한 영상 프레임(Image Frames)을 생성한다(S130). 이후 객체 촬영부는 생성한 영상 프레임을 객체 정보 표시부로 전송한다(S135). 실시 예에 따라, 객체 촬영부는 객체 배치 공간부의 내부를 정면에서 바라보는 프론트 뷰(Front View) 방식으로 촬영하여 객체에 대한 영상 프레임을 생성할 수도 있으며, x축, y축 및 z축에 따라 이동하며 해 당 객체에 대한 영상 프레임을 생성할 수도 있다. 객체 정보 표시부는 디스플레이 디바이스를 통해 객체 촬영부에 의해 촬영된 영상 프레임을 실시간 디스플레이하고(S150), 객체 기동부 상 어느 지점에 해당 객체가 놓여져 있는지 객체의 위치 정보(예컨대, 턴 테이블 중심으로부터의 거리와 각도에 대한 정보)를 획득하며(S160), 합성 데이터 생성모듈로 생성된 영상 프레임과 획득한 객체의 위치 정보를 전송한다(S170). 순차적으로 합성 데이터 생성모듈은 데이터 취득 모듈로부터 전송된 영상 프레임으로부터 객체의 마 스크(1차 마스크 및 2차 마스크)를 추출한다(Step 2). 도 9는 Step 2를 보다 상세히 설명하기 위한 순서도이며, 이하 도 9를 참조하여 상기 Step 2에 대해 상세히 설 명한다. 합성 데이터 생성모듈이 포함하는 마스크 획득부는 데이터 취득 모듈의 객체 정보 표시부 로부터 전송된 영상 프레임에 대해 이미지 영상 차감법 및 이진화법 처리를 통해 영상 프레임 내에서 움직이는 객체를 파악하고 배경을 제거한 바이너리 이미지를 생성한다(S210). 이후 마스크 획득부는 비지역적 평균 알고리즘(NLMeans)을 이용하여 생성한 바이너리 이미지 상의 객체에 포함되어 있는 노이즈를 제거하는 전처리를 수행한다(S230). 순차적으로 마스크 획득부는 보다 정밀하게 노이즈를 제거하고 충분한 바운딩 박스를 얻기 위해 상기 전처 리된 이미지에 대해 침식 연산(Erosion) 및 팽창 연산(Dilatioin)을 반복 수행한다(S250). 이때 마스크 획득부은 침식 연산 후 팽창 연산을 반복 적용하는 오프닝(opening) 기법 또는 팽창 연산 후 침식 연산을 반복 적용하는 클로징(closing) 기법을 적절히 조합하여 노이즈를 제거할 수 있다. 마스크 획득부는 상기와 같은 침식 연산 및 팽창 연산 과정이 반복 수행된 이미지에 대해서 컨투어 (Contour) 프로세스를 수행하여 해당 객체에 대한 1차 마스크를 추출한다(S270). 그리고 마스크 획득부는 추출한 1차 마스크에 대해 볼록껍질(Convex Hull) 프로세스를 수행하여 해당 객체 에 대한 1차 바운딩 박스를 생성한다(S275). 순차적으로 마스크 획득부는 1차 마스크를 딥러닝 네트워크(Deep Learnig network)의 입력(Input)으로 하 여 배경 및 노이즈가 더 정밀하게 제거된 2차 마스크를 출력(Output)으로서 추출한다(S280). 마스크 획득부가 사용하는 상기 딥러닝 네트워크는 중요 물체 검출(SOD) 모델이며, 실시 예에 따라 상기 중요 물체 검출 모델은 유 스퀘어넷(U2-Net) 또는 바스넷(BASNet)일 수 있다. 즉, 마스크 획득부는 상기 1차 마스크를 상기 중요 물체 검출 모델(여컨대, 유 스퀘어넷)의 입력(input)으 로 하고 배경 및 노이즈가 더 정밀하게 제거된 2차 마스크를 출력(output)으로 취득한다. 그리고 마스크 획득부는 추출한 2차 마스크에 대해 볼록껍질(Convex Hull) 프로세스를 수행하여 해당 객체 에 대한 바운딩 박스를 생성한다(S285). 결국, 마스크 획득부는 다양한 컴퓨터 비전 알고리즘을 사용하여 배경 및 노이즈가 개략적으로 제거된 객 체에 대한 1차 마스크를 추출하고(S270), 중요 물체 검출 모델을 사용하여 상기 1차 마스크에서 배경 및 노이 즈가 정밀하게 제거된 2차 마스크를 추출한다(S280).이후 마스크 획득부는 추출한 객체에 대한 마스크(1차 마스크 및 2차 마스크)를 객체 합성부로 전송 한다(S290). 순차적으로 합성 데이터 생성모듈은 전송된 객체에 대한 마스크를 실제 공간(예컨대, 냉장고 안)과 유사한 가상의 배경(또는 해당 객체가 실제로 배치될 위치)에 합성한 합성 데이터를 생성한다(Step 3). 도 10은 Step 3을 보다 상세히 설명하기 위한 순서도이며, 이하 도 10을 참조하여 상기 Step 3에 대해 상세히 설명한다. 우선 합성 데이터 생성모듈이 포함하는 객체 합성부는 마스크 획득부로부터 전송된 객체의 마스 크가 가상 배경의 어느 위치에 배치되야 하는지를 결정한다(S310). 이때. 객체 합성부는 객체 정보 표시부로부터 전송된 해당 객체의 위치 정보에 기초하여, 마스크 획 득부로부터 전송된 객체의 마스크가 가상 배경의 어느 위치에 배치되야 하는지를 결정한다(S310). 그리고 상기 가상 배경은 해당 객체가 실제로 배치될 위치(예컨대, 진열대)나 기구 내부(예컨대, 냉장고 내부) 가 될 수 있다. 객체 합성부는 마스크 획득부로부터 전송된 객체의 2차 마스크와 해당 객체가 객체 기동부 상 어느 지점에 적재되어 있었는지에 대한 위치 정보(예컨대, 턴 테이블 중심으로부터의 거리와 각도에 대한 정 보)를 알고 있기 때문에 상기 가상 배경에서 해당 객체가 배치되어야 할 근사적 위치를 결정할 수 있다. 이후 객체 합성부는 해당 객체에 대한 2차 마스크를 상기 결정한 가상 배경에서의 근사적 위치에 합성함으 로써 합성 데이터를 생성한다(S350). 순차적으로 데이터 증폭부는 인공지능 네트워크를 학습시키기 위해 발생할 수 있는 수 많은 시나리오를 커 버할 수 있도록 객체 합성부가 생성한 합성 데이터를 증폭(Augmentation)한 합성 증폭 데이터를 생성한다 (S370). 데이터 증폭부는 객체의 회전(Rotation, Perspective), 크기 변환(Scale, Zoom), 이동(Shift), 어핀 (Affine), 자르기(Crop)나 지우기(Erasing) 등의 일반적인 증폭 뿐만 아니라. 특히 객체의 일부가 다른 객체에 의해 가려지는 폐색(Occlusion), 객체가 유리나 거울 등에 반사되어 보이는 경우 등을 가정하여 데이터를 증폭 한 합성 증폭 데이터를 생성한다(S370). 이와 같이 데이터 증폭부는 객체 합성부가 생성한 합성 데이터를 다양하게 변형, 증폭함으로써 다양 한 변수에 인공지능 네트워크가 대응할 수 있도록 한다. 이후 객체 합성부는 생성한 합성 데이터를 학습 데이터 셋 생성모듈로 전송하고(S385), 데이터 증폭 부는 생성한 합성 증폭 데이터를 학습 데이터 셋 생성모듈로 전송한다(S390). 순차적으로 학습 데이터 셋 생성모듈은 합성 데이터 생성모듈로부터 생성된 합성 데이터 또는 데이터 증폭부에서 생성된 합성 증폭 데이터로부터 객체를 레이블링(Labeling 또는 Annotation)한 학습 데이터 셋 을 생성한다(Step 4). 즉, 학습 데이터 셋 생성모듈은 마스크 획득부로부터 추출된 해당 객체에 대한 바운딩 박스(1차 마스 크에 대한 바운딩 박스 또는 2차 마스크에 대한 바운딩 박스)를 이용하여 자동으로 해당 객체를 레이블링하여 학습데이터 셋을 생성한다(Step 4). 따라서 사람이 직접 객체를 촬영하고 레이블링하는 종래의 데이터 레이블링방법에 비해, 본 발명의 실시 예에 따른 학습 데이터 셋 생성 방법(Step 4)은 합성 데이터 또는 합성 증폭 데이터를 이용하여 사람의 개입없이 빠 른 시간안에 적은 비용으로 학습 데이터 셋(Training Data Set)을 생성할 수 있는 효과가 있다."}
{"patent_id": "10-2022-0123166", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위한 각 도면의 상세한 설명이 제공된다. 도 1은 본 발명의 일 실시 예에 따른 인공지능 네트워크를 위한 학습 데이터 생성 장치의 구성을 나타내는 블럭 도이다. 도 2는 도 1에 도시된 객체 취득 모듈의 내부 구성을 나타내는 블럭도이다. 도 3은 도 1에 도시된 합성 데이터 생성모듈의 내부 구성을 나타내는 블럭도이다. 도 4는 마스크 획득부가 비지역적 평균 알고리즘을 이용하여 전처리를 수행한 예시도이다.도 5는 마스크 획득부가 오프닝 기법 및 클로징 기법을 조합하여 노이즈를 제거한 예시도이다. 도 6은 객체 합성부가 특정 객체의 마스크를 가상의 배경에 합성한 예시도이다. 도 7은 본 발명의 일 실시 예에 따른 인공지능 네트워크를 위한 학습 데이터 생성 방법을 구체적으로 설명하기 위한 순서도이다. 도 8은 도 7에 도시된 Step 1을 보다 상세히 설명하기 위한 순서도이다. 도 9는 도 7에 도시된 Step 2를 보다 상세히 설명하기 위한 순서도이다. 도 10은 도 7에 도시된 Step 3을 보다 상세히 설명하기 위한 순서도이다."}
