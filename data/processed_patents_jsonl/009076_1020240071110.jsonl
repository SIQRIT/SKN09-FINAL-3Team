{"patent_id": "10-2024-0071110", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0026730", "출원번호": "10-2024-0071110", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "박운성"}}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서, 하나 이상의 명령어를 저장하는 메모리; 및 하나 이상의 프로세서;를 포함하고, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,입력 영상에 포함된 연속된 복수의 프레임에 대응되는 복수의 특징맵(feature map)을 획득하고, 상기 복수의 특징맵 각각에 기 설정된 크기의 윈도우를 적용하여 각 윈도우 내에서 로컬 윈도우 어텐션(localwindow attention)을 수행하고 상기 복수의 특징맵 각각에서 식별된 복수의 그리드 영역에 기초하여 글로벌 그리드 어텐션(global grid attention)을 수행하여 복수의 인핸스드 특징맵을 획득하고,상기 복수의 인핸스드 특징맵에 기초하여 상기 입력 영상에 대응되는 광학 흐름(optical flow) 정보를획득하는, 전자 장치."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 복수의 특징맵 각각에 상기 기 설정된 크기의 윈도우를 적용하여 각 윈도우 내에서 제1 로컬 윈도우 어텐션(local window attention)을 수행한 후 상기 기 설정된 크기의 시프트 윈도우를 적용하여 각 윈도우 내에서제2 로컬 윈도우 어텐션을 수행하는, 전자 장치."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,각 윈도우 내에서 상기 제2 로컬 윈도우 어텐션을 수행한 후 상기 복수의 특징맵을 상기 기 설정된 크기보다 큰상기 복수의 그리드 영역으로 식별하고, 상기 복수의 그리드 영역에서 동일한 위치의 픽셀들에 상기 글로벌 그리드 어텐션을 적용하여 상기 복수의 인핸스드 특징맵을 획득하는, 전자 장치."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 제2 로컬 윈도우 어텐션을 통해 임계 거리 내의 상기 복수의 특징맵 각각에 포함된 픽셀의 주변 픽셀과의정보를 교환하고 상기 글로벌 그리도 어텐션을 통해 상기 임계 거리 외의 이격 픽셀과의 정보를 교환하여 상기복수의 인핸스드 특징맵을 획득하는, 전자 장치."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 복수의 특징맵 각각에 포함된 픽셀의 위치 정보를 변경하여 상기 로컬 윈도우 어텐션 및 상기 글로벌 그리드 어텐션을 수행하여 상기 복수의 인핸스드 특징맵을 획득하는, 전자 장치. 공개특허 10-2025-0026730-3-청구항 6 제5항에 있어서, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 복수의 특징맵 각각에 포함된 상기 픽셀의 위치 정보를 픽셀 그룹 단위로 시프트하고, 상기 픽셀의 위치정보를 픽셀 단위로 시프트하고, 상기 픽셀의 위치 정보를 픽셀 그룹 단위로 스케일링하여 상기 로컬 윈도우 어텐션 및 상기 글로벌 그리드 어텐션을 수행하는, 전자 장치."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 복수의 프레임을 제1 네트워크 모델에 입력하여 상기 복수의 특징맵을 획득하고, 상기 복수의 특징맵 및 상기 복수의 특징맵 각각에 포함된 픽셀의 위치 정보를 제2 네트워크 모델에 입력하여상기 복수의 인핸스드 특징맵을 획득하는, 전자 장치."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 복수의 인핸스드 특징맵에 포함된 제1 픽셀에 대응되는 코스트 볼륨을 획득하고, 상기 코스트 볼륨에 기초하여 식별된 상기 제1 픽셀의 좌표에 기초하여 상기 광학 흐름 정보를 획득하는, 전자장치."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 제1 픽셀에 대응되는 수평 방향의 제1 코스트 볼륨(cost volume) 및 수직 방향의 제2 코스트 볼륨을 획득하고, 상기 제1 코스트 볼륨 및 상기 제2 코스트 볼륨의 무게 중심에 기초하여 상기 제1 픽셀의 좌표를 식별하고, 상기 제1 픽셀의 좌표에 기초하여 상기 1차원 특징 매칭을 수행하여 상기 광학 흐름 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 복수의 특징맵 및 상기 광학 흐름 정보에 기초하여 상기 복수의 프레임 중 적어도 하나에서 가려지는 제2픽셀이 식별되면, 상기 제2 픽셀의 주변 픽셀 중 상기 픽셀과 유사도가 상대적으로 높은 픽셀의 광학 흐름 값을상기 픽셀의 광학 흐름 값으로 업데이트하여 상기 입력 영상에 대응되는 인핸스드 광학 흐름 정보를 획득하는,전자 장치."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치의 제어 방법에 있어서, 입력 영상에 포함된 연속된 복수의 프레임에 대응되는 복수의 특징맵(feature map)을 획득하는 단계; 상기 복수의 특징맵 각각에 기 설정된 크기의 윈도우를 적용하여 각 윈도우 내에서 로컬 윈도우 어텐션(localwindow attention)을 수행하고 상기 복수의 특징맵 각각에서 식별된 복수의 그리드 영역에 기초하여 글로벌 그공개특허 10-2025-0026730-4-리드 어텐션(global grid attention)을 수행하여 복수의 인핸스드 특징맵을 획득하는 단계; 및상기 복수의 인핸스드 특징맵에 기초하여 상기 입력 영상에 대응되는 광학 흐름(optical flow) 정보를 획득하는단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 복수의 인핸스드 특징맵을 획득하는 단계는, 상기 복수의 특징맵 각각에 상기 기 설정된 크기의 윈도우를 적용하여 각 윈도우 내에서 제1 로컬 윈도우 어텐션(local window attention)을 수행한 후 상기 기 설정된 크기의 시프트 윈도우를 적용하여 각 윈도우 내에서제2 로컬 윈도우 어텐션을 수행하는, 제어 방법."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 복수의 인핸스드 특징맵을 획득하는 단계는, 각 윈도우 내에서 상기 제2 로컬 윈도우 어텐션을 수행한 후 상기 복수의 특징맵을 상기 기 설정된 크기보다 큰상기 복수의 그리드 영역으로 식별하고, 상기 복수의 그리드 영역에서 동일한 위치의 픽셀들에 상기 글로벌 그리드 어텐션을 적용하여 상기 복수의 인핸스드 특징맵을 획득하는, 제어 방법."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 복수의 인핸스드 특징맵을 획득하는 단계는, 상기 제2 로컬 윈도우 어텐션을 통해 임계 거리 내의 상기 복수의 특징맵 각각에 포함된 픽셀의 주변 픽셀과의정보를 교환하고 상기 글로벌 그리도 어텐션을 통해 상기 임계 거리 외의 이격 픽셀과의 정보를 교환하여 상기복수의 인핸스드 특징맵을 획득하는, 제어 방법."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서, 상기 복수의 인핸스드 특징맵을 획득하는 단계는, 상기 복수의 특징맵 각각에 포함된 픽셀의 위치 정보를 변경하여 상기 로컬 윈도우 어텐션 및 상기 글로벌 그리드 어텐션을 수행하여 상기 복수의 인핸스드 특징맵을 획득하는, 제어 방법."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 복수의 인핸스드 특징맵을 획득하는 단계는, 상기 복수의 특징맵 각각에 포함된 상기 픽셀의 위치 정보를 픽셀 그룹 단위로 시프트하고, 상기 픽셀의 위치정보를 픽셀 단위로 시프트하고, 상기 픽셀의 위치 정보를 픽셀 그룹 단위로 스케일링하여 상기 로컬 윈도우 어텐션 및 상기 글로벌 그리드 어텐션을 수행하는, 제어 방법."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서, 상기 복수의 특징맵을 획득하는 단계는,상기 복수의 프레임을 제1 네트워크 모델에 입력하여 상기 복수의 특징맵을 획득하고, 상기 복수의 인핸스드 특징맵을 획득하는 단계는, 상기 복수의 특징맵 및 상기 복수의 특징맵 각각에 포함된 픽셀의 위치 정보를 제2 네트워크 모델에 입력하여공개특허 10-2025-0026730-5-상기 복수의 인핸스드 특징맵을 획득하는, 전자 장치."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서, 상기 광학 흐름 정보를 획득하는 단계는, 상기 복수의 인핸스드 특징맵에 포함된 제1 픽셀에 대응되는 코스트 볼륨을 획득하는 단계; 및 상기 코스트 볼륨에 기초하여 식별된 상기 제1 픽셀의 좌표에 기초하여 상기 광학 흐름 정보를 획득하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 광학 흐름 정보를 획득하는 단계는, 상기 제1 픽셀에 대응되는 수평 방향의 제1 코스트 볼륨(cost volume) 및 수직 방향의 제2 코스트 볼륨을 획득하는 단계;상기 제1 코스트 볼륨 및 상기 제2 코스트 볼륨의 무게 중심에 기초하여 상기 제1 픽셀의 좌표를 식별하는단계; 및 상기 제1 픽셀의 좌표에 기초하여 상기 1차원 특징 매칭을 수행하여 상기 광학 흐름 정보를 획득하는 단계;를포함하는, 제어 방법."}
{"patent_id": "10-2024-0071110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "전자 장치의 프로세서에 의해 실행되는 경우 상기 전자 장치가 동작을 수행하도록 하는 컴퓨터 명령을 저장하는비일시적 컴퓨터 판독 가능 매체에 있어서,상기 동작은,입력 영상에 포함된 연속된 복수의 프레임에 대응되는 복수의 특징맵(feature map)을 획득하는 단계; 상기 복수의 특징맵 각각에 기 설정된 크기의 윈도우를 적용하여 각 윈도우 내에서 로컬 윈도우 어텐션(localwindow attention)을 수행하고 상기 복수의 특징맵 각각에서 식별된 복수의 그리드 영역에 기초하여 글로벌 그리드 어텐션(global grid attention)을 수행하여 복수의 인핸스드 특징맵을 획득하는 단계; 및상기 복수의 인핸스드 특징맵에 기초하여 상기 입력 영상에 대응되는 광학 흐름(optical flow) 정보를 획득하는단계;를 포함하는, 비일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치는, 하나 이상의 명령어를 저장하는 메모리 및 하나 이상의 프로세서를 포함하고, 하나 이상의 프로세 서는, 상기 하나 이상의 명령어를 실행함으로써, 입력 영상에 포함된 연속된 복수의 프레임에 대응되는 복수의 특징맵(feature map)을 획득하고, 복수의 특징맵 각각에 기 설정된 크기의 윈도우를 적용하여 각 윈도우 내에서 로컬 윈도우 어텐션(local window attention)을 수행하고 복수의 특징맵 각각에서 식별된 복수의 그리드 영역에 기초하여 글로벌 그리드 어텐션(global grid attention)을 수행하여 복수의 인핸스드 특징맵을 획득하고, 복수의 인핸스드 특징맵에 기초하여 상기 입력 영상에 대응되는 광학 흐름(optical flow) 정보를 획득한다."}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 제어 방법에 관한 것으로, 더욱 상세하게는 영상의 광학 흐름 정보를 획득하는 전자 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "광학 흐름 예측(Optical Flow estimation, OFE)은 두 장의 연속적인 입력 영상에 대해, 첫번째 입력 영상의 각 픽셀이 두번째 입력 영상에서 어느 위치로 이동하였는지 예측하는 기술이다. 광학 흐름는 초해상화, 비디오 프 레임 보간, 동작 인식, 자율 주행 시스템 상 움직임 감지 등 다양한 응용에 이용될 수 있다. 하지만, 종래의 딥러닝 기술들은 높은 예측 성능을 달성하기 위해 높은 연산 복잡도와 큰 메모리 공간을 사용하"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "기 때문에 실제 제품에 적용하는데 있어 한계가 있었다. 발명의 내용"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "하나 이상의 실시 예에 따른 전자 장치는, 하나 이상의 명령어를 저장하는 메모리; 및 하나 이상의 프로세서;를 포함하고, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 입력 영상에 포함된 연속된 복수의 프레임에 대응되는 복수의 특징맵(feature map)을 획득하고, 상기 복수의 특징맵 각각에 기 설정된 크기 의 윈도우를 적용하여 각 윈도우 내에서 로컬 윈도우 어텐션(local window attention)을 수행하고 상기 복수의 특징맵 각각에서 식별된 복수의 그리드 영역에 기초하여 글로벌 그리드 어텐션(global grid attention)을 수행 하여 복수의 인핸스드 특징맵을 획득하고, 상기 복수의 인핸스드 특징맵에 기초하여 상기 입력 영상에 대응되는 광학 흐름(optical flow) 정보를 획득한다. 하나 이상의 실시 예에 따르면, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 상기 복수의 특징맵 각각에 상기 기 설정된 크기의 윈도우를 적용하여 각 윈도우 내에서 제1 로컬 윈도우 어텐션 (local window attention)을 수행한 후 상기 기 설정된 크기의 시프트 윈도우를 적용하여 각 윈도우 내에서 제2 로컬 윈도우 어텐션을 수행할 수 있다. 하나 이상의 실시 예에 따르면, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 각 윈 도우 내에서 상기 제2 로컬 윈도우 어텐션을 수행한 후 상기 복수의 특징맵을 상기 기 설정된 크기보다 큰 상기 복수의 그리드 영역으로 식별하고, 상기 복수의 그리드 영역에서 동일한 위치의 픽셀들에 상기 글로벌 그리드 어텐션을 적용하여 상기 복수의 인핸스드 특징맵을 획득할 수 있다. 하나 이상의 실시 예에 따르면, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 상기 제2 로컬 윈도우 어텐션을 통해 임계 거리 내의 상기 복수의 특징맵 각각에 포함된 픽셀의 주변 픽셀과의 정보 를 교환하고 상기 글로벌 그리도 어텐션을 통해 상기 임계 거리 외의 이격 픽셀과의 정보를 교환하여 상기 복수 의 인핸스드 특징맵을 획득할 수 있다. 하나 이상의 실시 예에 따르면, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 상기 복수의 특징맵 각각에 포함된 픽셀의 위치 정보를 변경하여 상기 로컬 윈도우 어텐션 및 상기 글로벌 그리드 어 텐션을 수행하여 상기 복수의 인핸스드 특징맵을 획득할 수 있다. 하나 이상의 실시 예에 따르면, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 상기 복수의 특징맵 각각에 포함된 상기 픽셀의 위치 정보를 픽셀 그룹 단위로 시프트하고, 상기 픽셀의 위치 정보를 픽셀 단위로 시프트하고, 상기 픽셀의 위치 정보를 픽셀 그룹 단위로 스케일링하여 상기 로컬 윈도우 어텐션 및 상기 글로벌 그리드 어텐션을 수행할 수 있다. 하나 이상의 실시 예에 따르면, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 상기 복수의 프레임을 제1 네트워크 모델에 입력하여 상기 복수의 특징맵을 획득하고, 상기 복수의 특징맵 및 상기 복수의 특징맵 각각에 포함된 픽셀의 위치 정보를 제2 네트워크 모델에 입력하여 상기 복수의 인핸스드 특징맵 을 획득할 수 있다. 하나 이상의 실시 예에 따르면, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 상기 복수의 인핸스드 특징맵에 포함된 제1 픽셀에 대응되는 코스트 볼륨을 획득하고, 상기 코스트 볼륨에 기초하여 식별된 상기 제1 픽셀의 좌표에 기초하여 상기 광학 흐름 정보를 획득할 수 있다. 하나 이상의 실시 예에 따르면, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 상기 제1 픽셀에 대응되는 수평 방향의 제1 코스트 볼륨(cost volume) 및 수직 방향의 제2 코스트 볼륨을 획득하고, 상기 제1 코스트 볼륨 및 상기 제2 코스트 볼륨의 무게 중심에 기초하여 상기 제1 픽셀의 좌표를 식별하고, 상 기 제1 픽셀의 좌표에 기초하여 상기 1차원 특징 매칭을 수행하여 상기 광학 흐름 정보를 획득할 수 있다. 하나 이상의 실시 예에 따르면, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 상기 복수의 특징맵 및 상기 광학 흐름 정보에 기초하여 상기 복수의 프레임 중 적어도 하나에서 가려지는 제2 픽셀 이 식별되면, 상기 제2 픽셀의 주변 픽셀 중 상기 픽셀과 유사도가 상대적으로 높은 픽셀의 광학 흐름 값을 상 기 픽셀의 광학 흐름 값으로 업데이트하여 상기 입력 영상에 대응되는 인핸스드 광학 흐름 정보를 획득할 수 있 다. 하나 이상의 실시 예에 따른 전자 장치의 제어 방법은, 입력 영상에 포함된 연속된 복수의 프레임에 대응되는 복수의 특징맵(feature map)을 획득하는 단계; 상기 복수의 특징맵 각각에 기 설정된 크기의 윈도우를 적용하 여 각 윈도우 내에서 로컬 윈도우 어텐션(local window attention)을 수행하고 상기 복수의 특징맵 각각에서 식 별된 복수의 그리드 영역에 기초하여 글로벌 그리드 어텐션(global grid attention)을 수행하여 복수의 인핸스 드 특징맵을 획득하는 단계; 및 상기 복수의 인핸스드 특징맵에 기초하여 상기 입력 영상에 대응되는 광학 흐름 (optical flow) 정보를 획득하는 단계;를 포함할 수 있다. 하나 이상의 실시 예에 따른 전자 장치의 프로세서에 의해 실행되는 경우 상기 전자 장치가 동작을 수행하도록 하는 컴퓨터 명령을 저장하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 동작은, 입력 영상에 포함된 연 속된 복수의 프레임에 대응되는 복수의 특징맵(feature map)을 획득하는 단계; 상기 복수의 특징맵 각각에 기 설정된 크기의 윈도우를 적용하여 각 윈도우 내에서 로컬 윈도우 어텐션(local window attention)을 수행하고 상기 복수의 특징맵 각각에서 식별된 복수의 그리드 영역에 기초하여 글로벌 그리드 어텐션(global grid attention)을 수행하여 복수의 인핸스드 특징맵을 획득하는 단계; 및 상기 복수의 인핸스드 특징맵에 기초하여 상기 입력 영상에 대응되는 광학 흐름(optical flow) 정보를 획득하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 사례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, A 만을 포함, B 만을 포함, 또는 A 및 B 모두를 포함하 는 경우를 모두 지칭할 수 있다.본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어(operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때 에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연 결될 수 있다고 이해되어야 할 것이다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작 을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 실시 예에 있어서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정 한 하드웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하 나의 프로세서(미도시)로 구현될 수 있다. 한편, 도면에서의 다양한 요소와 영역은 개략적으로 그려진 것이다. 따라서, 본 발명의 기술적 사상은 첨부한 도면에 그려진 상대적인 크기나 간격에 의해 제한되지 않는다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 하나 이상의 실시 예에 따른 광학 흐름 예측을 설명하기 위한 도면이다. 광학 흐름(또는 광학 흐름) 예측(Optical Flow estimation, OFE)은 두 장의 연속적인 입력 영상에 대해, 첫번째 입력 영상의 각 픽셀이 두번째 입력 영상에서 어느 위치로 이동하였는지 예측하는 기술이다. 광학 흐름는 초해 상화, 비디오 프레임 보간, 동작 인식, 자율 주행 시스템 상 움직임 감지 등 다양한 응용에 이용될 수 있다. 종래의 광학 흐름 예측 기술은 딥러닝을 이용하여 높은 정확도로 광학 흐름를 예측할 수 있었다. 일반적으로 종 래 기술에서는 높은 예측 정확도를 달성하기 위해 전역화소쌍연관값(all-pair correlation values)을 계산하는 데, 이는 두 입력 영상의 모든 픽셀 사이의 유사도를 측정한 정보로 해당 전역화소쌍연관값들을 합성곱 신경망 (convolutional neural networks)에 통과시켜 광학 흐름 예측을 진행한다. 또한, 최신 광학 흐름 예측 기술들은 게이트 순환 유닛(gated recurrent unit network)을 활용하여 반복적으로 예측된 광학 흐름 벡터를 업데이트하 여 더욱 정확한 광학 흐름 예측을 가능하게 하였다. 하지만, 게이트 순환 유닛을 활용한 반복적인 광학 흐름 업 데이트 방식 또한 연산 복잡도면에서 불리하다. 예를 들어, 높은 정확도의 광학 흐름을 예측하기 위해 게이트 순환 유닛을 12회에서 31회까지 반복적으로 통과시키기 때문에 많은 연산을 필요로 한다. 이에 따라 최근 제안된 글로벌 매칭을 통한 광학 흐름 예측은 게이트 순환 유닛을 사용하지 않고 전역화소쌍연 관값으로부터 직접 광학 흐름 예측을 가능하게 하였다. 해당 방법은 전역화소쌍연관값을 이용하여 가장 높은 값 을 가지는 위치가 해당 픽셀의 대응점이 될 확률이 높다는 사실에 기반하여, 첫번째 입력 영상의 모든 픽셀마다 전역화소쌍연관값들을 계산하여, 해당 전역화소쌍연관값들의 무게 중심을 대응점으로 가정해 광학 흐름을 예측 한다. 하지만, 전역화소쌍연관값들은 두 입력 영상의 모든 픽셀 사이의 유사도로서 메모리에 저장되기 때문에, 입력 영상 해상도의 제곱에 비례하는 메모리 공간 및 연산 복잡도가 발생하게 된다. 입력 영상의 제곱에 비례하는 메 모리 공간/연산 복잡도는 최근 디스플레이의 출력 해상도의 증가로 2K/4K 영상에 대한 광학 흐름 예측 수요가 늘어난 현 상황에서 매우 불리하게 작용될 수 있다. 또한, 글로벌 매칭을 통한 광학 흐름 예측은 학습 영상의 해상도에 과적합(over-fitting)되어 실제 광학 흐름 예측을 진행하고자 하는 영상의 해상도가 학습 영상의 해상 도와 다를 경우, 광학 흐름 예측 값에 많은 오류가 발생될 수 있다는 문제가 있다. 이에 따라 이하에서는, 전역화소쌍연관값에 기반하되 메모리 공간 및 연산 복잡도를 감소시키고 학습 영상의 해 상도에 과적합되지 않는 광학 흐름 예측을 제공하는 다양한 실시 예에 대해 설명하도록 한다. 도 2a는 일 실시 예에 따른 전자 장치의 구성을 나타내는 블럭도이다. 도 2a에 따르면 전자 장치은 메모리 및 하나 이상의 프로세서를 포함한다. 전자 장치는 TV, 모니터, PC, 키오스크, 태블릿 PC, 전자 액자, 휴대폰, HMD(Head mounted Display), NED(Near Eye Display), LFD(large format display), Digital Signage(디지털 간판), DID(Digital Information Display), 비디오 월(video wall), 프로젝터 디스플레이 등과 같은 다양한 유형의 디스플레이 장치 또는 디스플레이 장치로 영상을 제공하는 영상 처리 장치(예를 들어, set-top box, one connected box)로 구현 될 수 있다. 메모리는 다양한 실시 예를 위해 필요한 데이터를 저장할 수 있다. 메모리는 데이터 저장 용도에 따 라 전자 장치(100')에 임베디드된 메모리 형태로 구현되거나, 전자 장치에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어,전자 장치의 구동을 위한 데이터의 경우 전자 장치(100')에 임베디드된 메모 리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나 로 구현될 수 있다. 또한, 전자 장치(100')에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 일 예에 따라 메모리는 전자 장치를 제어하기 위한 적어도 하나의 인스트럭션(instruction) 또는 인 스트럭션들을 포함하는 컴퓨터 프로그램을 저장할 수 있다. 다른 예에 따라 메모리는 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB), 외부 서버 (예를 들어 웹 하드) 등으로부터 수신된 영상, 즉 입력 영상을 저장할 수 있다. 또는 메모리는 전자 장치 에 구비된 카메라를 통해 획득된 영상을 저장할 수 있다. 여기서, 영상은 2D 동영상이 될 수 있으나 이에 한정되는 것은 아니다. 또 다른 예에 따라, 메모리는 화질 처리에 필요한 다양한 정보, 예를 들어 Noise Reduction, Detail Enhancement, Tone Mapping, Contrast Enhancement, Color Enhancement 또는 Frame rate Conversion 중 적어 도 하나를 수행하기 위한 정보, 알고리즘, 화질 파라미터 등을 저장할 수 있다. 또한, 메모리는 영상 처리 에 의해 생성된 중간 영상, 뎁스 정보를 기초로 생성된 영상을 저장할 수도 있다. 일 실시 예에 따르면, 메모리는 본 개시에 따른 다양한 동작들에서 생성되는 데이터를 저장하는 단일 메모 리로 구현될 수 있다. 다만, 다른 실시 예에 따르면, 메모리는 상이한 타입의 데이터를 각각 저장하거나, 상이한 단계에서 생성되는 데이터를 각각 저장하는 복수의 메모리를 포함하도록 구현될 수도 있다. 상술한 실시 예에서는 다양한 데이터가 프로세서의 외부 메모리에 저장되는 것으로 설명하였으나, 상 술한 데이터 중 적어도 일부는 전자 장치 또는 프로세서 중 적어도 하나의 구현 예에 따라 프로세서 내부 메모리에 저장될 수도 있다. 하나 이상의 프로세서는 전자 장치의 동작을 전반적으로 제어한다. 구체적으로, 하나 이상의 프로세 서는 전자 장치의 각 구성과 연결되어 전자 장치의 동작을 전반적으로 제어할 수 있다. 예를 들 어, 하나 이상의 프로세서는 메모리와 동작적(operatively)으로 연결되어 전자 장치의 전반적인동작을 제어할 수 있다. 하나 이상의 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 하나 이상의 프로세서는 메모리에 저장된 적어도 하나의 인스트럭션(instruction)을 실행함으로써, 다양한 실시 예에 따른 전자 장치의 동작을 수행할 수 있다. 하나 이상의 프로세서는 CPU (Central Processing Unit), GPU (Graphics Processing Unit), APU (Accelerated Processing Unit), MIC (Many Integrated Core), DSP (Digital Signal Processor), NPU (Neural Processing Unit), 하드웨어 가속기 또는 머신 러닝 가속기 중 하나 이상을 포함할 수 있다. 하나 이상의 프로 세서는 전자 장치의 다른 구성요소 중 하나 또는 임의의 조합을 제어할 수 있으며, 통신에 관한 동작 또는 데이터 처리를 수행할 수 있다. 하나 이상의 프로세서는 메모리에 저장된 하나 이상의 프로그램 또는 명령 어(instruction)을 실행할 수 있다. 예를 들어, 하나 이상의 프로세서는 메모리에 저장된 하나 이상의 명령어를 실행함으로써, 본 개시의 하나 이상의 실시 예에 따른 방법을 수행할 수 있다. 본 개시의 하나 이상의 실시 예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 프로세서에 의해 수행될 수도 있고, 복수의 프로세서에 의해 수행될 수도 있다. 예를 들어, 하나 이상의 실시 예에 따른 방 법에 의해 제1 동작, 제2 동작, 제3 동작이 수행될 때, 제1 동작, 제2 동작, 및 제3 동작 모두 제1 프로세서에 의해 수행될 수도 있고, 제1 동작 및 제2 동작은 제1 프로세서(예를 들어, 범용 프로세서)에 의해 수행되고 제3 동작은 제2 프로세서(예를 들어, 인공지능 전용 프로세서)에 의해 수행될 수도 있다. 하나 이상의 프로세서는 하나의 코어를 포함하는 단일 코어 프로세서(single core processor)로 구현될 수 도 있고, 복수의 코어(예를 들어, 동종 멀티 코어 또는 이종 멀티 코어)를 포함하는 하나 이상의 멀티 코어 프 로세서(multicore processor)로 구현될 수도 있다. 하나 이상의 프로세서가 멀티 코어 프로세서로 구현되 는 경우, 멀티 코어 프로세서에 포함된 복수의 코어 각각은 캐시 메모리, 온 칩(On-chip) 메모리와 같은 프로세 서 내부 메모리를 포함할 수 있으며, 복수의 코어에 의해 공유되는 공통 캐시가 멀티 코어 프로세서에 포함될 수 있다. 또한, 멀티 코어 프로세서에 포함된 복수의 코어 각각(또는 복수의 코어 중 일부)은 독립적으로 본 개 시의 하나 이상의 실시 예에 따른 방법을 구현하기 위한 프로그램 명령을 판독하여 수행할 수도 있고, 복수의 코어 전체(또는 일부)가 연계되어 본 개시의 하나 이상의 실시 예에 따른 방법을 구현하기 위한 프로그램 명령 을 판독하여 수행할 수도 있다. 본 개시의 하나 이상의 실시 예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 멀티 코어 프로세 서에 포함된 복수의 코어 중 하나의 코어에 의해 수행될 수도 있고, 복수의 코어에 의해 수행될 수도 있다. 예 를 들어, 하나 이상의 실시 예에 따른 방법에 의해 제1 동작, 제2 동작, 및 제3 동작이 수행될 때, 제1 동작, 제2 동작, 및 제3 동작 모두 멀티 코어 프로세서에 포함된 제1 코어에 의해 수행될 수도 있고, 제1 동작 및 제2 동작은 멀티 코어 프로세서에 포함된 제1 코어에 의해 수행되고 제3 동작은 멀티 코어 프로세서에 포함된 제2 코어에 의해 수행될 수도 있다. 본 개시의 실시 예들에서, 프로세서는 하나 이상의 프로세서 및 기타 전자 부품들이 집적된 시스템 온 칩(SoC), 단일 코어 프로세서, 멀티 코어 프로세서, 또는 단일 코어 프로세서 또는 멀티 코어 프로세서에 포함된 코어를 의미할 수 있으며, 여기서 코어는 CPU, GPU, APU, MIC, DSP, NPU, 하드웨어 가속기 또는 기계 학습 가속기 등으 로 구현될 수 있으나, 본 개시의 실시 예들이 이에 한정되는 것은 아니다. 이하에서는 설명의 편의를 위하여 하 나 이상의 프로세서를 프로세서로 명명하도록 한다. 일 실시 예에 따르면, 전자 장치는 다양한 압축 영상 또는 다양한 해상도의 영상을 수신할 수 있다. 예를 들어, 전자 장치는 MPEG(Moving Picture Experts Group)(예를 들어, MP2, MP4, MP7 등), JPEG(joint photographic coding experts group), AVC(Advanced Video Coding), H.264, H.265, HEVC(High Efficiency Video Codec) 등으로 압축된 형태로 영상을 수신할 수 있다. 또는 전자 장치는 SD(Standard Definition), HD(High Definition), Full HD, Ultra HD 영상 중 어느 하나의 영상을 수신할 수 있다. 일 예에 따라 프로세서는 입력 영상을 영상 처리한 후, 영상 처리된 영상에 기초하여 광학 흐름 정보를 획 득할 수 있다. 여기서, 영상 처리는 영상 개선(image enhancement), 영상 복원(image restoration), 영상 변환 (image transformation), 영상 분석(image analysis), 영상 인식(image understanding), 영상 압축(image compression), 영상 디코딩(image decoding) 또는 스케일링(scaling) 중 적어도 하나를 포함하는 디지털 영상 처리가 될 수 있다. 일 예에 따라 입력 영상에 대한 뎁스 정보 획득 전에 다양한 전처리가 수행될 수 있으나, 이하에서는 설명의 편 의를 위하여 입력 영상과 전처리된 영상을 구분하지 않고, 입력 영상이라고 명명하도록 한다. 본 개시에서 \"영역(region)\"은 영상의 한 부분을 지칭하는 용어로써 적어도 하나의 픽셀 블록 또는 픽셀 블록들의 집합을 의미 한다. 또한, \"픽셀 블록(pixel block)\"은 적어도 하나의 픽셀을 포함하는 인접한 픽셀들의 집합을 의미한다. 도 2b는 하나 이상의 실시 예에 따른 전자 장치의 구성을 구체적으로 나타내는 블럭도이다. 도 2b에 따르면, 전자 장치(100')은 메모리, 하나 이상의 프로세서, 디스플레이, 통신 인터페이 스, 사용자 인터페이스, 스피커 및 카메라를 포함할 수 있다. 도 2b에 도시된 구성 중 도 2a에 도시된 구성과 중복되는 구성에 대해서는 자세한 설명을 생략하도록 한다. 디스플레이는 자발광 소자를 포함하는 디스플레이 또는, 비자발광 소자 및 백라이트를 포함하는 디스플레 이로 구현될 수 있다. 예를 들어, LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플 레이, LED(Light Emitting Diodes), 마이크로 LED(micro LED), Mini LED, PDP(Plasma Display Panel), QD(Quantum dot) 디스플레이, QLED(Quantum dot light-emitting diodes) 등과 같은 다양한 형태의 디스플레이 로 구현될 수 있다. 디스플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 일 예에 따라 디스플레이의 전면에는 터치 필름, 터치 시트, 터치 패드 등의 형태를 가지고 터치(touch) 동작 을 감지하는 터치 센서가 배치되어 다양한 유형의 터치 입력을 감지할 수 있도록 구현될 수 있다. 예를 들어, 디스플레이는 사용자 손에 의한 터치 입력, 스타일러스 펜과 같은 입력 장치에 의한 터치 입력, 특정 정전 물질에 의한 터치 입력 등 다양한 유형의 터치 입력을 감지할 수 있다. 여기서, 입력 장치는 전자 펜, 스타일러 스 펜, S-펜 등 다양한 용어로 지칭될 수 있는 펜 형의 입력 장치으로 구현될 수 있다. 일 예에 따라 디스플레 이는 평면(flat) 디스플레이, 커브드(curved) 디스플레이, 폴딩(folding) 또는/및 롤링(rolling) 가능한 플렉서블 디스플레이 등으로 구현될 수 있다. 통신 인터페이스는 전자 장치(100')의 구현 예에 따라 다양한 인터페이스로 구현될 수 있음은 물론이다. 예를 들어 통신 인터페이스는 블루투스(Bluetooth), AP 기반의 Wi-Fi(와이파이, Wireless LAN 네트워크), 지그비(Zigbee), 유/무선 LAN(Local Area Network), WAN(Wide Area Network), 이더넷(Ethernet), IEEE 1394, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), MHL(Mobile High-Definition Link), AES/EBU(Audio Engineering Society/ European Broadcasting Union), 옵티컬(Optical), 코액셜 (Coaxial) 등과 같은 통신 방식을 통해 외부 장치, 외부 저장 매체(예를 들어, USB 메모리), 외부 서버(예를 들 어 웹 하드) 등과 통신을 수행할 수 있다. 일 예에 따라 통신 인터페이스는 타 전자 장치, 외부 서버 및/ 또는 원격 제어 장치 등과 통신을 수행할 수 있다. 사용자 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린 등으로 구현될 수 있다. 스피커는 각종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시지 등을 출력하는 구성일 수 있다. 프로세서는 본 개시의 다양한 실시 예에 따른 피드백 또는 각종 알림을 오디오 형태로 출력하도록 스피커 를 제어할 수 있다. 카메라는 기 설정된 이벤트에 따라 턴 온 되어 촬영을 수행할 수 있다. 카메라는 촬상된 영상을 전기 적인 신호로 변환하고 변환된 신호에 기초하여 영상 데이터를 생성할 수 있다. 예를 들어, 카메라는 일반 (또는 기본) 카메라 및 초광각 카메라 중 적어도 하나를 포함할 수 있다. 그 밖에 전자 장치(100')는 구현 예에 따라 센서 및 마이크 등을 포함할 수 있다. 센서는 터치 센서, 근접 센서, 가속도 센서(또는 중력 센서), 지자기 센서, 자이로 센서, 압력 센서, 위치 센서, 거리 센서, 조도 센서 등과 같은 다양한 유형의 센서를 포함할 수 있다. 마이크는 사용자 음성이나 기타 소리를 입력받아 오디오 데이터로 변환하기 위한 구성이다. 다만, 다른 실시 예 에 따라 전자 장치(100')는 외부 장치를 통해 입력된 사용자 음성을 통신 인터페이스를 통해 수신할 수 있 다. 도 3은 하나 이상의 실시 예에 따른 광학 흐름 정보 획득 방법을 설명하기 위한 흐름도이다. 도 3에 도시된 흐름도에 따르면, 동작 310에서, 전자 장치는 입력 영상에 포함된 연속된 복수의 프레임에 대응되는 복수의 특징맵(feature map)을 획득할 수 있다. 일 예에 따라 전자 장치는 입력 영상에 포함된 연속된 복수의 프레임을 제1 네트워크 모델에 입력하여 복수의 특징맵을 획득할 수 있다. 특징맵은 네트워크 모델의 각 레이어(또는 계층)에서 필터를 이용하여 입력 영상의 특정 패턴이나 특성을 추출 한 결과일 수 있다. 예를 들어, 각 필터는 입력 영상의 특정 특징(또는 피쳐)을 추출하도록 학습될 수 있다. 예 를 들어, 초기 레이어에서는 에지(Edge)나 간단한 형태와 같은 저 레벨 특징을 추출하고, 심층 레이어로 갈수록 더 복잡한 패턴이나 객체의 부분 등을 인식할 수 있다. 일 예에 따라 첫 번째 특징맵은 이미지의 각 픽셀에 대 해 경계선을 추출하고, 두 번째 특징맵은 이전 특징맵의 정보를 결합하여 좀 더 고 레벨의 특징(예를 들어, 질 감, 패턴 등)을 추출하도록 학습될 수 있다. 일 예에 따라 특징 맵은 네트워크의 출력을 생성하기 위해 완전히 연결된 층으로 전달되기 전에 여러 단계의 합성 과정을 거칠 수 있다. 예를 들어, 네트워크 모델은 CNN(Convolutuional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), LSTM(Long Short Term Memory Network), GRU(Gated Recurrent Units) 또는 GAN(Generative Adversarial Networks), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 중 적어도 하 나의 모델로 구현될 수 있다. 여기서, 네트워크 모델이 학습된다는 것은, 기본 학습 네트워크 모델(예를 들어 임의의 랜덤한 파라미터를 포함 하는 네트워크 모델)이 학습 알고리즘에 의하여 다수의 훈련 데이터들을 이용하여 학습됨으로써, 원하는 특성 (또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 학습 네트워크 모델이 만들어짐을 의미한다. 이러 한 학습은 별도의 서버 및/또는 시스템을 통해 이루어질 수 있으나, 이에 한정되는 것은 아니며 전자 장치(10 0)에서 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습 (unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learnin g)이 있으나, 전술한 예에 한정되지 않는다. 동작 320에서, 전자 장치는 복수의 특징맵을 어텐션 처리하여 복수의 인핸스드 특징맵을 획득할 수 있다. 일 예에 따라 전자 장치는 복수의 특징맵 각각을 어텐션 처리하여 복수의 특징맵 각각에 대응되는 인핸스 드 특징맵을 획득할 수 있다. 인핸스드 특징맵은 원래 특징맵이 가지는 정보에서 유용한 정보를 더 두드러지게 하고 불필요한 부분을 억제함으로써, 네트워크 모델이 더 정확하고 효율적으로 학습할 수 있다. 일 예에 따라 전자 장치는 복수의 특징맵에 로컬 윈도우 어텐션(local window attention) 및 글로벌 그리 드 어텐션(global grid attention)을 순차적 또는 동시에 수행하여 복수의 인핸스드 특징맵을 획득할 수 있다. 일 예에 따라 전자 장치는 복수의 특징맵 각각에 기 설정된 크기의 윈도우를 적용하여 각 윈도우 내에서 로컬 윈도우 어텐션(local window attention)을 수행할 수 있다. 일 예에 따라 전자 장치는 복수의 특징맵 각각에서 식별된 복수의 그리드 영역에 기초하여 글로벌 그리드 어텐션(global grid attention)을 수행하여 복 수의 인핸스드 특징맵을 획득할 수 있다. 예를 들어, 전자 장치는 로컬 윈도우 어텐션이 수행된 복수의 특 징 맵에 글로벌 그리드 어텐션을 수행하여 복수의 인핸스드 특징맵을 획득할 수 있다. 어텐션(attention)은 주어진 입력에 대한 중요한 부분에 집중하여 그것들을 처리하는 메커니즘으로, 입력 시퀀 스의 각 요소 간의 상호 작용을 계산하는 동작일 수 있다. 즉, 어텐션은 각 입력 요소가 다른 요소와 얼마나 관 련이 있는지 계산할 수 있다. 예를 들어, 어텐션은 입력으로부터 쿼리(Query), 키(Key), 값(Value) 세트를 생성 하고, 각 쿼리와 키 사이의 유사도를 계산(즉, 입력의 각 요소 간의 관련성을 측정)하고, 유사도에 따라 값에 가중치를 부여하여 가중합을 계산(입력의 각 요소에 대한 중요도 계산)할 수 있다. 일 실시 예에 따르면, 동작 320에서, 전자 장치는 복수의 특징맵 각각에 기 설정된 크기의 윈도우를 적용 하여 각 윈도우 내에서 제1 로컬 윈도우 어텐션(local window attention)을 수행한 후 기 설정된 크기의 시프트 윈도우를 적용하여 각 윈도우 내에서 제2 로컬 윈도우 어텐션을 수행할 수 있다. 일 예에 따르면, 동작 320에서, 전자 장치는 각 윈도우 내에서 제2 로컬 윈도우 어텐션을 수행한 후 복수 의 특징맵을 기 설정된 크기보다 큰 복수의 그리드 영역으로 식별하고, 복수의 그리드 영역에서 동일한 위치의 픽셀들에 글로벌 그리드 어텐션을 적용하여 복수의 인핸스드 특징맵을 획득할 수 있다. 일 예에 따르면, 동작 320에서, 전자 장치는 제2 로컬 윈도우 어텐션을 통해 임계 거리 내의 복수의 특징 맵 각각에 포함된 픽셀의 주변 픽셀과의 정보를 교환하고 글로벌 그리드 어텐션을 통해 임계 거리 외의 이격 픽 셀과의 정보를 교환하여 복수의 인핸스드 특징맵을 획득할 수 있다. 일 실시 예에 따르면, 동작 320에서, 전자 장치는 복수의 특징맵 각각에 포함된 픽셀의 위치 정보를 변경 하여 로컬 윈도우 어텐션 및 글로벌 그리드 어텐션을 수행하여 복수의 인핸스드 특징맵을 획득할 수 있다. 일 예에 따르면, 동작 320에서, 전자 장치는 복수의 특징맵 각각에 포함된 픽셀의 위치 정보를 픽셀 그룹 단위로 시프트하고, 픽셀의 위치 정보를 픽셀 단위로 시프트하고, 픽셀의 위치 정보를 픽셀 그룹 단위로 스케일 링하여 로컬 윈도우 어텐션 및 글로벌 그리드 어텐션을 수행할 수 있다. 일 실시 예에 따르면, 동작 320에서, 전자 장치는 복수의 특징맵 및 복수의 특징맵 각각에 포함된 픽셀의 위치 정보를 제2 네트워크 모델에 입력하여 복수의 인핸스드 특징맵을 획득할 수 있다. 동작 330에서, 전자 장치는 복수의 인핸스드 특징맵에 기초하여 입력 영상에 대응되는 광학 흐름(optical flow) 정보를 획득할 수 있다. 광학 흐름 정보는 영상에서 각각의 픽셀이 어떻게 움직이는지 추적하여 획득한 시간에 따른 이동 정보일 수 있 다. 예를 들어, 광학 흐름 정보는 객체의 이동 방향 정보 및 속도 정보를 포함할 수 있다. 예를 들어, 광학 흐 름 정보는 각 픽셀에 대응되는 광학 흐름 값을 포함하는 광학 흐름 맵(map) 형태일 수 있으나 이에 한정되는 것 은 아니다. 광학 흐름 맵(map)은, 각 픽셀 블럭에 대응되는 광학 흐름 값이 픽셀 블록 단위의 행렬 형태로 배열 되는 구조일 수 있다. 일 실시 예에 따르면, 동작 330에서, 전자 장치는 복수의 인핸스드 특징맵에 포함된 픽셀에 대응되는 코스 트 볼륨을 생성할 수 있다. 예를 들어, 코스트 볼륨은 두 특징 벡터 간 상관 관계에 의해 산출될 수 있다. 예를 들어, 두 개의 이미지에서 동일한 스캔 라인 상의 각 픽셀에 대해 다양한 디스패리티(disparity) 값으로 계산된 일치 비용을 통해 1차원 코스트 볼륨을 생성하고, 1차원 코스트 볼륨은 스캔 라인 상의 각 위치와 디스패리티 값에 대한 일치 비용을 포함하는 2차원 배열로 표현할 수 있다. 일 예에 따라 전자 장치는 복수의 인핸스드 특징맵에 포함된 제1 픽셀에 대응되는 수평 방향의 제1 코스트 볼륨(cost volume) 및 수직 방향의 제2 코스트 볼륨을 생성할 수 있다. 일 예에 따라 전자 장치는 제1 코 스트 볼륨 및 제2 코스트 볼륨의 무게 중심에 기초하여 제1 픽셀의 좌표를 식별하고, 제1 픽셀의 좌표에 기초하 여 1차원 특징 매칭을 수행하여 광학 흐름 정보를 획득할 수 있다. 코스트 볼륨의 무게 중심은 일종의 가중 평 균으로 일치 비용이 낮은(즉, 잘 일치하는) 디스패리티 값에 더 큰 가중치를 부여함에 따라 획득될 수 있다. 일 예에 따르면, 동작 330에서, 전자 장치는 복수의 특징맵 및 광학 흐름 정보에 기초하여 복수의 프레임 중 적어도 하나에서 가려지는 제2 픽셀이 식별되면, 제2 픽셀의 주변 픽셀 중 픽셀과 유사도가 상대적으로 높은 픽셀(예를 들어, 동일한 객체로 판단되는 영역의 픽셀)의 광학 흐름 값을 픽셀의 광학 흐름 값으로 업데이트하 여 입력 영상에 대응되는 인핸스드 광학 흐름 정보를 획득할 수 있다. 가려지는 픽셀이란 복수의 프레임의 시점 차이(disparity Difference) 또는 깊이 차이(Depth Discontinuity)에 의해 복수의 프레임 중 적어도 하나에서 가려지는 픽셀로 \"오클루전(occlusion)\"이라고도 명명할 수 있다. 오클루전은 두 이미지에서 동일한 장면을 볼 때 한쪽 카메라에서 보이는 부분이 다른 카메라에서는 보이지 않는 경우에 대응되는 픽셀일 수 있다. 픽셀 유사 도는 두 픽셀이 얼마나 비슷한지를 나타내는 개념으로 절대 차이, 제곱 차이, 정규화 상관 계수, 색상 공간에서 의 픽셀 간 거리, 구조 간 유사도 등에 기초하여 식별될 수 있다. 일 실시 예에 따르면, 전자 장치는 입력 영상에 기초하여 제1 특징맵(feature map)을 획득하고, 제1 특징 맵에 기 설정된 크기의 윈도우를 적용하여 각 윈도우 내에서 제1 로컬 윈도우 어텐션(local window attention) 을 수행하여 제2 특징맵을 획득할 수 있다. 이어서, 전자 장치는 제2 특징맵에 기 설정된 크기의 시프트 윈도우를 적용하여 각 윈도우 내에서 제2 로컬 윈도우 어텐션을 수행하여 제3 특징맵을 획득할 수 있다. 이어서, 전자 장치는 제3 특징맵을 복수의 그리드로 식별하고 복수의 그리드에서 동일한 위치의 픽셀들에 글로벌 그리드 어텐션(global grid attention)을 수행하여 제4 특징맵을 획득할 수 있다. 이어서, 전자 장치 는 제4 특징맵에 기초하여 입력 영상의 광학 흐름(optical flow) 정보를 획득할 수 있다. 한편, 도 3에서는 설명의 편의상 모든 단계에 대해 순서를 맵핑하였지만, 순서에 관계가 없거나 병렬적으로 수 행 가능한 단계 등의 순서를 해당 순서에 반드시 한정되는 것은 아님은 물론이다. 도 4a 및 도 4b는 하나 이상의 실시 예에 따른 광학 흐름 예측 방법을 설명하기 위한 도면들이다. 도 4a에 따르면, 전자 장치는 특징 추출 모듈, 특징 인핸스 모듈, 광학 흐름 예측 모듈 및 광학 흐름 인핸스 모듈을 포함할 수 있다. 예를 들어, 각 모듈은 적어도 하나의 소프트웨어, 적어도 하나 의 하드웨어 및/또는 이들의 조합으로 구현될 수 있다. 예를 들어, 특징 추출 모듈, 특징 인핸스 모듈, 광학 흐름 예측 모듈 및 광학 흐름 인핸스 모듈 중 적어도 하나는 기 정의된 알고리즘, 기 정의된 수식 및/또는 학습된 네트워크 모델을 이용하도록 구현될 수 있다. 특징 추출 모듈, 특징 인핸스 모듈, 광학 흐름 예측 모듈 및 광학 흐름 인핸스 모 듈은 전자 장치 내에 포함될 수 있으나, 일 예에 따라 적어도 하나의 외부 장치에 분산될 수 있다. 특징 추출 모듈은 입력 영상에 포함된 연속된 복수의 프레임에 대응되는 복수의 특징맵(feature map)을 획 득할 수 있다. 일 예에 따라 전자 장치는 입력 영상에 포함된 연속된 복수의 프레임을 제1 네트워크 모델 에 입력하여 복수의 특징맵을 획득할 수 있다. 특징 인핸스 모듈은 복수의 특징맵을 어텐션 처리하여 복수의 인핸스드 특징맵을 획득할 수 있다. 일 예에 따라 전자 장치는 복수의 특징맵 각각을 어텐션 처리하여 복수의 특징맵 각각에 대응되는 인핸스드 특징맵 을 획득할 수 있다. 일 실시 예에 따르면 특징 인핸스 모듈은 복수의 특징맵에 로컬 윈도우 어텐션(local window attention) 및 글로벌 그리드 어텐션(global grid attention)을 순차적 또는 동시에 수행하여 복수의 인핸스드 특징맵을 획 득할 수 있다. 일 예에 따라 특징 인핸스 모듈은 복수의 특징맵 각각에 기 설정된 크기의 윈도우를 적용하 여 각 윈도우 내에서 로컬 윈도우 어텐션(local window attention)을 수행할 수 있다. 일 예에 따라 특징 인핸 스 모듈은 복수의 특징맵 각각에서 식별된 복수의 그리드 영역에 기초하여 글로벌 그리드 어텐션(global grid attention)을 수행하여 복수의 인핸스드 특징맵을 획득할 수 있다. 예를 들어, 특징 인핸스 모듈은 로컬 윈도우 어텐션이 수행된 복수의 특징 맵에 글로벌 그리드 어텐션을 수행하여 복수의 인핸스드 특징맵을 획 득할 수 있다. 일 예에 따르면, 특징 인핸스 모듈은 복수의 특징맵 및 복수의 특징맵 각각에 포함된 픽셀의 위치 정보를 제2 네트워크 모델에 입력하여 복수의 인핸스드 특징맵을 획득할 수 있다. 광학 흐름 예측 모듈은 복수의 인핸스드 특징맵에 기초하여 입력 영상에 대응되는 광학 흐름(optical flow) 정보를 획득할 수 있다. 일 실시 예에 따르면, 광학 흐름 예측 모듈은 복수의 인핸스드 특징맵에 포함된 픽셀에 대응되는 코스트 볼륨을 생성할 수 있다. 일 예에 따라 광학 흐름 예측 모듈은 복수의 인핸스드 특징맵에 포함된 제1 픽셀에 대응되는 수평 방향의 제1 코스트 볼륨(cost volume) 및 수직 방향의 제2 코스트 볼륨을 생성할 수 있다. 일 예에 따라 전자 장치 는 제1 코스트 볼륨 및 제2 코스트 볼륨의 무게 중심에 기초하여 제1 픽셀의 좌표를 식별하고, 제1 픽셀의 좌표에 기초하여 1차원 특징 매칭을 수행하여 광학 흐름 정보를 획득할 수 있다. 일 실시 예에 따르면, 광학 흐름 인핸스 모듈은 광학 흐름 정보에 포함된 광학 흐름 값을 업데이트하여 인 핸스드 광학 흐름 정보를 획득할 수 있다. 일 예에 따라 광학 흐름 예측 모듈은 복수의 특징맵 및 광학 흐름 정보에 기초하여 복수의 프레임 중 적어 도 하나에서 가려지는 제2 픽셀이 식별되면, 제2 픽셀의 주변 픽셀 중 픽셀과 유사도가 상대적으로 높은 픽셀의 광학 흐름 값을 픽셀의 광학 흐름 값으로 업데이트하여 입력 영상에 대응되는 인핸스드 광학 흐름 정보를 획득 할 수 있다. 도 4b에 따르면, 두 연속된 영상. 예를 들어, 두 연속된 프레임이 특징 추출 모듈로 입력되고 특징 인핸스 모듈및 광학 흐름 예측 모듈을 거쳐 광학 흐름 인핸스 모듈로부터 두 영상 사이의 광학 흐름 예 측 값이 출력될 수 있다. 특징 추출 모듈은 두 연속된 영상, 예를 들어, 두 연속된 프레임(11, 12)에 대한 특징 추출 경량화 동작을 수행하여 특징맵(21, 22)을 출력할 수 있다. 일 예에 따르면, 특징 추출 모듈은 특징 추출 경량화 동작을 수행하도록 학습된 제1 네트워크 모델(411-1, 411-2)을 포함할 수 있다. 도 5는 하나 이상의 실시 예에 따른 특징 추출 방법을 설명하기 위한 도면이다. 도 5에 도시된 실시 예에 따르면, 특징 추출 모듈로 입력되는 두 연속 프레임은 I1, I2 이고, 특징 추출 모 듈로부터 출력되는 특징맵은 두 연속 프레임에 대응되는 특징맵 F1, F2일 수 있다. 일 예에 따르면, 특징 추출 모듈은 N개의 합성곱 계층(convolution layers)으로 구성되며, 첫번째 합성곱 계층을 제외한 나머지 N-1개의 합성곱 계층은 깊이 별 합성곱(depth-wise convolution) 및 위치 별 합성곱 (point-wise convolution)으로 구성될 수 있다. 예를 들어, 기존 3x3 Conv layer를 각각 3x3 DWConv + 1x3PWConv로 교체되도록 구현될 수 있으나 반드시 이에 한정되는 것은 아니다. 일 예에 따르면, 첫번째 합성곱 계 층 : 7x7 Conv layer으로 구성되며, stride 2로 수행함으로써 특징 추출 모듈로부터 출력되는 특징맵(21, 22)의 크기는 입력 영상 프레임(11, 12) 해상도의 가로 및 세로 크기의 1/2로 감소될 수 있다. 특징 인핸스 모듈은 특징맵(21, 22)에 대한 특징 인핸스 동작을 수행하여 인핸스드 특징맵(31, 32)를 출력 할 수 있다. 일 예에 따르면, 특징 인핸스 모듈은 특징 인핸스 동작을 수행하도록 학습된 제2 네트워크 모 델을 포함할 수 있다. 예를 들어, 제2 네트워크 모델은 MaxVit layer로 구현될 수 있으나 이에 한정 되는 것은 아니며 Swin layer로도 구현 가능하다. 광학 흐름 예측 모듈은 1차원 특징 매칭을 통해 광학 흐름를 예측할 수 있다. 예를 들어, 광학 흐름 예측 모듈은 두 영상의 인핸스드 특징맵을 입력으로 수신하여 광학 흐름 예측값을 출력할 수 있다. 예를 들어, 글로벌 매칭(Global matching)을 1 차원(또는 1D) 코스트 볼륨(1 dimensional cost volume)으로 분리하여 각 축(예를 들어, x축 및 y축)에서 진행할 수 있다. 광학 흐름 인핸스 모듈은 광학 흐름 정보 및 첫번째 영상의 향상된 특징맵 을 입력으로 수신하여 인핸 스드 광학 흐름 정보를 출력할 수 있다. 일 예에 따라 광학 흐름 인핸스 모듈은 광학 흐름 예측 값을 업데 이트하여 인핸스드 광학 흐름 예측 값을 출력할 수 있다. 일 예에 따라 광학 흐름 인핸스 모듈은 두 입력 영상 중 하나의 영상에서 대응되는 픽셀이 가려지더라도 높은 정확도의 광학 흐름을 예측할 수 있도록 광학 흐 름 정보를 인핸스 처리할 수 있다. 도 6a 내지 도 6c는 하나 이상의 실시 예에 따른 특징 인핸스 방법을 설명하기 위한 도면들이다. 도 6a는 일 예에 따른 로컬 윈도우 어텐션을 설명하기 위한 도면이다. 도 6a에 따르면, 특징 인핸스 모듈 은 특징 맵을 일정한 크기의 윈도우(window)로 분할하고, 동일한 윈도우 내에서 어텐션을 수행할 수 있다. 이와 같은 로컬 어텐션을 수행함에 따라 연산량을 감소시킬 수 있게 된다. 도 6b 및 도 6c는 일 예에 따른 글로벌 그리드 어텐션을 설명하기 위한 도면이다. 도 6b에 따르면, 특징 인핸스 모듈은 특징 맵을 일정한 개수의 파티션(partition)(또는 그리드(grid))으로 분할하고 각 파티션에서 동일 위치의 픽셀들을 모아 어텐션을 수행할 수 있다. 이에 따라 로컬 어텐션으로 인한 수용 영역 감소를 상쇄시킬 수 있게 된다. 도 6c에 도시된 바와 같이 동일한 로컬 윈도우 또는 글로벌 그리드에 속하지 않더라도 모든 픽셀들이 간접적으 로 정보를 전달할 수 있게 된다. 도 7은 하나 이상의 실시 예에 따른 특징 인핸스 방법을 설명하기 위한 도면이다. 도 7에 따르면, 특징 인핸스 모듈은 윈도우 어텐션, 시프트 윈도우 어텐션 및 글로벌 그리드 어텐션을 순 차적으로 수행할 수 있다. 일 예에 따라 특징 인핸스 모듈은 윈도우 어텐션, 시프트 윈도우 어텐션 및 글 로벌 그리드 어텐션 순서로 self/cross attention을 수행할 수 있다. 일 예에 따라 특징 인핸스 모듈은 윈 도우 어텐션, 시프트 윈도우 어텐션 및 글로벌 그리드 어텐션을 순차적으로 반복하여 기 설정된 횟수만큼 수행 할 수 있다. 일 예에 따라 특징 인핸스 모듈은 시프트 윈도우 어텐션을 통해 주변 픽셀과의 정보를 교환하 고, 글로벌 그리드 어텐션을 통해 멀리 이격된 픽셀과의 정보를 교환할 수 있다. 도 7에 도시된 일 예에 따르면, 특징 인핸스 모듈은 W×H 크기의 입력 영상을 w×h 크기의 N×M개의 로컬 윈도우로 분할하여 로컬 윈도우 어텐션을 수행할 수 있다. 이어서, 특징 인핸스 모듈은 W×H 크기의 입력 영상을 w×h 크기의 N×M개의 시프트 로컬 윈도우로 분할하여 시프트 윈도우 어텐션을 수행할 수 있다. 이어서, 특징 인핸스 모듈은 W×H 크기의 입력 영상을 N×M 크기의 w×h 개의 글로벌 그리드로 분할하여 글로벌 그 리드 어텐션을 수행할 수 있다. 예를 ㄷ들어, W/N이고, h=H/M일 수 있다. 도 8은 하나 이상의 실시 예에 따른 특징 인핸스 방법을 설명하기 위한 도면이다. 일 실시 예에 따르면, 특징 인핸스 모듈은 Positional Embedding(PE) 방법에 기초하여 어텐션을 수행할 수 있다. Positional embedding은 어텐션 연산시 픽셀의 위치 정보를 임베딩에 추가하여 네트워크 모델이 순서를 이해하도록 하는 방식이다. 예를 들어, 특징 인핸스 모듈은 윈도우 어텐션 및 글로벌 그리드 어텐션 수행 시 픽셀의 위치 정보를 임베딩하여 어텐션을 수행할 수 있다. 일 예에 따라 특징 인핸스 모듈은 sinusoidal PE에 기초하여 PE를 수행할 수 있다. sinusoidal PE는 사인 (sine)과 코사인(cosine) 함수에 기반하여 위치 정보를 생성하는 방식이다. 예를 들어, 특징 인핸스 모듈 은 sinusoidal PE에 기초하여 PE를 수행하되, 입력 그리드(input grid)에 대해 augmentation을 추가해 실제 학 습에 사용되지 않은 해상도(resolution)의 PE도 모델의 학습에 활용할 수 있다. 일 예에 따라 도 8에 도시된 바 와 같이 글로벌 시프트, 로컬 시프트, 글로벌 스케일링을 통해 다양한 해상도의 PE를 모델의 학습에 활용할 수 있다. 이에 따라 학습 영상의 해상도와 다른 입력 영상에 대해 강건한 특징맵을 획득할 수 있게 된다. 도 9는 하나 이상의 실시 예에 따른 광학 흐름 예측 방법을 설명하기 위한 도면이다. 일 실시 예에 따르면, 광학 흐름 예측 모듈은 1차원 특징 매칭을 통해 광학 흐름를 예측할 수 있다. 일 예 에 따라 광학 흐름 예측 모듈은 글로벌 매칭(Global matching)을 1 차원 코스트 볼륨(1 dimensional cost volume)으로 분리하여 x축 및 y축 각각에서 진행할 수 있다. 예를 들어, 광학 흐름 예측 모듈은 코스트 볼 륨을 각각 수평 방향 및 수직 방향으로 생성하고, 수평/수직 방향 코스트 볼륨의 무게 중심을 산출하고, 산출된 좌표를 대응점의 x, y 좌표로 가정하여 광학 흐름을 예측할 수 있다. 이에 따라 흐름 전파(Flow propagation)를 로컬 윈도우 내에서 수행하여 메모리 사용량 및 연산량 감소시킬 수 있게 된다. 도 10은 하나 이상의 실시 예에 따른 광학 흐름 예측을 위한 일 구현 예를 설명하기 위한 도면이다. 도 10에 따르면, 특징 추출(Feature Extraction, FeExt), 특징 인핸스(Feature Enhancement)(FeEhm), 광학 흐 름 예측(또는 1차원 매칭)(1D Mctiching, 1DMat), 광학 흐름 인핸스(Opticlal Flow Enhancement, FlEhm)의 단 계를 거쳐 광학 흐름 예측이 수행될 수 있다. 일 예에 따르면, 특징 추출 단계에서, 특징 추출 모듈(또는 FeExt 모듈)은 여러 잔여 단계(residual stages)를 이용하여 이미지 쌍으로부터 관련 특징(pertinent features)을 추출할 수 있다. 특징 인핸스 단계에서, 특징 인핸스 모듈(또는 FeEhm)은 특징 추출 단계에서 추출된 특징에 대한 인핸스 처리를 통해 추출된 특징의 차별성을 강화시킬 수 있다. 광학 흐름 예측 단계(또는 1차원 매칭 단계)에서, 광학 흐름 예측 모듈(또는 1DMat 모듈)은 1차원(수평 및 수직) 방식으로 특징 매칭을 처리하는 1D 매칭이 수행할 수 있다. 일 예에 따라 1차원 매칭 단계에서는 단일 샷 에서 1D 코스트 볼륨의 광학 흐름을 추정할 수 있다. 광학 흐름 인핸스 단계에서, 광학 흐름 인핸스 모듈(또는 FlEhm 모듈)은, 일련의 CNN 레이어에 의해 보완된 흐 름 전파(flow propagation) 기술을 적용하여 추정된 광학 흐름을 인핸스 처리할 수 있다. 일 예에 따르면, 특징 추출 모듈은, 2개의 1/8 크기 특징맵을 생성하는 3개의 계단식 잔여 블록(cascaded residual blocks)으로 구성될 수 있다. 하나는 소스 이미지 Fext src용이고 다른 하나는 참조 이미지 Fext ref용일 수 있다. FeEhm, 1DMat 및 FlEhm 모듈에 사용된 특정 메커니즘 및 FeEhm-1DMat-FlEhm 연산(operation)을 반복하여 추가적인 성능 향상을 위한 인핸스 단계와 학습에 사용된 목적 함수(objective function)에 대해 설명하도록 한 다. <1D MATCHING> 1) GLOBAL MATCHING GLOBAL MATCHING의 기본 원리는 두 입력 이미지 Isrc와 Iref 간의 상관 관계를 비교하는 것이다. 그런 다음 상관 관계 또는 코스트 규모는 하기 수학식 1에 의해 산출될 수 있다. 수학식 1"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, Fsrc 및 Fref는 각각 CNN(컨벌루션 신경망) 인코더 및 추가 특징 인핸스 레이어를 통해 획득된 Isrc와 Iref 에서 추출된 특징일 수 있다. 또한, (i, j)는 Fsrc 내의 좌표를 나타내고, D는 코스트 볼륨을 표준화하는데 이용되는 Fsrc와 Fref의 채널 크기이며, H와 W는 Fsrc 및 Fref의 높이와 너비일 수 있다. Cij는 Fsrc의 (i, j) 좌표에 대 응되는 코스트 볼륨일 수 있다. 2) 1D COST VOLUME CONSTRUCTION 수학식 1에서 코스트 볼륨 Cij는 음수 및 양수 값을 가질 수 있다. 따라서 Cij는 하기 수학식 2와 같이 0과 1 사 이의 Mij로 확률적으로 정규화될 수 있다. 수학식 2"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, Softmax(·)는 소프트맥스 오퍼레이터이고, Fsrc의 각 특징에 대한 correspondences는 하기 수학식 3와 같이 정규화된 코스트 볼륨 Mij에 2D 그리드를 적용하여 식별될 수 있다. 수학식 3"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "특징 도메인(feature domain)에서 수행되는 1D 매칭은 이전의 1D 코스트 볼륨 구성을 기반으로 할 수 있다. 1D 매칭 접근 방식에 대한 수평 코스트 볼륨을 구성하기 위하여 Fsrc의 각 픽셀에 대한 수평 코스트 볼륨의 최대 값 이 Fref의 일치 픽셀의 x 좌표에 대응되는지 확인할 수 있다. 이를 위해서 Fref의 동일한 열을 따라 특징을 집계 (aggregation)해야 하므로 단일 수평 코스트 볼륨 구성 내에서도 여러 행의 코스트 볼륨에 영향을 미칠 수 있다. 도 11a는 1-D(수평) 코스트 볼륨 구성의 예를 도시하며, 이 집계를 하기 수학식 4와 같이 Fref의 열별 선형 조합 으로 공식화할 수 있다. 수학식 4"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, h와 w의 범위는 각각 [0,H-1] 및 [0, W-1]이며, Fver ref(h,w)는 열을 따라 Fref의 집계된 특성을 나타내고, fver i,h,w는 이 선형 조합의 가중치일 수 있다. 가중치 fver i,h,w는 좌표(h,w)에서 집계된 특징 Fver ref를 구성하기 위해 Iref의 각 픽셀의 중요성을 나타내는 중요 한 역할을 할 수 있다. 이러한 가중치는 동일한 수직 좌표 h를 공유하는 Isrc의 특징에 크게 의존하며, 이 문제 를 해결하기 위해 먼저 Fsrc를 행 단위로 집계할 수 있다. 수학식 5"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 Fhor src(h,w)는 행 전체에 걸쳐 집계된 Fsrc를 나타낼 수 있다. 이 단계는 Fsrc의 모든 특징이 수직 교차 어 텐션 메커니즘(vertical cross-attention mechanism)에 기여하도록 할 수 있다. 하기 수학식 6과 같이 가중치 fi,h,w는 다음과 같이 집계된 특징인 Fhor src 및 Fref를 사용하여 파생될 수 있다. 수학식 6"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수평 상관 관계(horizontal correlation) 또는 코스트 볼륨은 이후 하기 수학식 7과 같이 산출될 수 있다. 수학식 7"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서 Chor(i,h,w)는 (h,w)의 소스 특징과 i번째 열의 참조 특징에 해당하는 수평 코스트 볼륨을 나타낼 수 있 다. 수직 코스트 볼륨은 수직 1D 셀프 어텐션(self-attention)과 수평 1D 크로스 어텐션(horizontal 1D cross- attention)을 사용하여 구성할 수 있다. 도 11b는 OFE에 대한 1D 매칭 방법을 도시한다. 도 11b에 도시된 바와 같이 1D 매칭은 도 11b에서 구성된 1D 코 스트 볼륨에 대해 수행되며 실제로는 전역 매칭 기술(global matching technique)의 차원(dimensional) 수정일 수 있다. 1D 수평 코스트 볼륨의 구성을 통해 소스 이미지의 각 픽셀은 적절한 행과 열 내에 국한된 참조 이미 지의 대응되는 픽셀과 정보를 효과적으로 교환할 수 있다. 이를 통해 대응되는 픽셀이 동일한 행이나 열에 존재 하지 않더라도 1D 코스트 볼륨 내에서 대응되는 픽셀의 존재를 계속 참고할 수 있다. 이어서, 계산된 수평 코스 트 볼륨 Chor 및 수직 코스트 볼륨 Cver의 픽셀별 무게 중심이 각각 대응되는 픽셀의 x 및 y 좌표로 할당될 수 있 다. 또한 코스트 볼륨 Chor ij는 음수 값과 양수 값을 가질 수 있다. 따라서 Chor ij는 하기 수학식 8과 같이 소프트 맥스 연산자를 사용하여 Mhor ij로 정규화될 수 있다. 수학식 8 Fsrc의 각 특징에 대한 수평 대응(horizontal correspondence)은 정규화된 코스트 볼륨 Mhor ij로에 1D 수평 그리 드를 하기 수학식 9와 같이 적용하여 식별될 수 있다. 수학식 9"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서 Ghor는 1차원(수평) 좌표의 행렬 형태일 수 있다. 수직 대응(vertical correspondence) 픽셀 cver ij도 비 슷한 방식으로 찾을 수 있다. 결과적으로 2차원 correspondences 픽셀 cij를 하기 수학식 10과 같이 찾을 수 있 다. 수학식 10"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서 oij는 원본 이미지의 (i, j)번째 특징 위치에서의 광학 흐름 예측을 나타낼 수 있다. <FEATURE ENHANCEMENT> 코스트 볼륨의 중심을 계산하는 것은 대응되는 픽셀을 결정하기 위한 실행 가능한 접근 방식이지만 CNN 네트워 크에서 파생된 기능에만 의존하면 최적의 결과를 획득할 수 없다. 이러한 제한은 피처 내에서 연속적인 패턴이 나 동질적인 영역에 차별적인 차이가 없기 때문에 발생할 수 있다. 이를 극복하기 위해서 비전 트랜스포머를 활 용해 기능을 강화할 수 있다. 예를 들어, Swin 레이어가 특징 인핸스를 위해서 이용될 수 있고, 특징 인팬스 뿐 만 아니라 특징 간 인식을 촉진하기 위해 자기 및 교차어텐션 메커니즘(self and cross attention mechanism s)이 적용될 수 있다. 그러나 큰 움직임 감지에는 그에 상응하는 윈도우 크기 증가가 필요하며, 이로 인해 이미지 해상도의 제곱에 비 례하여 계산 및 메모리 요구 사항이 상당히 높아질 수 있다. 이러한 문제를 해결하기 위해 MaxViT 레이어가 Swin 레이어의 대안으로 이용될 수 있다. 도 12에서 볼 수 있듯이 MaxVit 레이어는 이미지를 로컬 윈도우과 글 로벌 그리드로 구분하며, 이미지 해상도에 따라 선형적으로 확장되는 계산 효율성을 유지하면서 글로벌 수용 필 드(global receptive field)를 달성할 수 있다. 이 글로벌 수용 필드는 이미지 사이의 큰 움직임을 감지하고 특 징에 대한 자체 정보를 향상시키는 데 중요한 역할을 할 수 있다. 소스 이미지와 참조 이미지의 향상된 특징을 각각 Fehm src 및 Fehm ref로 나타낼 수 있다. 그러나 단순화를 위해 Fsrc 및 Fref와 같은 1D 매칭 섹션에서는 위 첨자를 생략할 수 있다. 또한, 성능 향상과 이미지 해상도 변화에 대한 모델 견고성을 위해 위치 인코딩에 연속 증가(ontinuous augmentation)를 적용할 수 있다. 특징 인핸스 모듈에서는 트랜스포머 구조(transformer structure)가 활용되 므로 특징 추출 모듈에서 획득된특징에 위치 인코딩을 추가할 수 있다. 하지만, 각 데이터 세트에 대해 고정된 목표 해상도에서만 훈련을 수행하고 실제 추론이 서로 다른 해상도의 이미지에 대해 수행되는 경우 네트워크는 대응되는 해상도에 대한 위치 인코딩을 학습하지 못하여 성능이 저하될 수 있다. 이에 sinusoidal positional encoding을 생성하는 데 이용되는 고정 그리드에 글로벌 시프트, 로컬 시프트 및 글로벌 스케일링 증가를 적용 할 수 있다. 글로벌 시프트는 절대 위치 정보를 숨기고 상대적인 관계만 고려할 수 있다. 이 변환은 하기 수학 식 11과 같이 동일한 크기 △x,△y ∼ U(-△max,△max)를 사용하여 그리드를 수평 및 수직으로 랜덤으로 이동할 수 있다. 수학식 11"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "여기서 U(x, y)는 x와 y 사이의 균일한 분포(uniform distribution)를 나타낼 수 있다. 네트워크가 위치 인코딩 간격을 기억(memorization)하는 것을 방지하기 위해 로컬 시프트와 글로벌 스케일링을 추가로 적용할 수 있다. 글로벌 시프트를 통해 위치 인코딩을 이동함으로써 네트워크는 다양한 위치 인코딩에 대해 훈련되지만 각 인코 딩 간의 간격은 일관되게 유지될 수 있다. 이러한 일관성은 추론 해상도가 증가하거나 감소할 때 위치 인코딩 창 내 변화율이 훈련 중 변화율과 달라지며 추론 성능도 저하될 수 있음을 의미할 수 있다. 이 문제를 해결하기 위해 각 그리드를 다르게 이동하는 로컬 이동과 그리드 사이의 간격을 더욱 늘리는 글로벌 스케일링을 적용할 수 있다. 위치 (i, j)에서 수평 및 수직 방향의 로컬 이동은 하기 수학식 12와 같이 샘플링된 노이즈 εx,i ∼ U(-εx,max, εx,max) 및 εy,j ∼ U(-εy,max, εy,max)를 사용하여 획득할 수 있다. 수학식 12"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "위치 임베딩 그리드 사이의 거리 기억을 방지하기 위해 하기 수학식 13과 같이 log λ ∼ U(-log λmax, log λ max)에서 임의의 글로벌 스케일 λ를 도입할 수 있다. 수학식 13"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "일 예에 따라 △max, εx,max, εy,max, λmax가 각각 0.5, 1/W, 1/H, 1.4로 설정될 수 있으나, 이에 한정되는 것은 아니다. <FLOW ENHANCEMENT> 흐름 인핸스 모듈은 흐름 전파(flow propagation) 및 흐름 헤드(flow head)라는 두 가지 주요 구성 요소로 구분 될 수 있다. 1) FLOW PROPAGATION 1D 매칭 모듈의 정확도 성능은 원본 이미지의 각 픽셀에 대한 참조 이미지 내 대응되는 픽셀의 존재 여부에 따 라 달라질 수 있다. 실제 시나리오에서 폐색과 경계를 벗어난 움직임은 종종 correspondences의 존재를 방해할 수 있다. 폐색된 픽셀에 대한 정확한 흐름 추정을 보장하기 위해 MaxFlow는 흐름 전파 레이어를 채택합니다. 이 레이어는 폐색이나 경계 제약으로 인해 가려진 실제 흐름을 복제하는 것을 목표로 픽셀 correspondences이 부족 한 영역으로 광학 흐름을 확장할 수 있다. 니다. 흐름 전파 레이어는 Fsrc의 자기 유사성을 측정하고 correspondences이 존재하는 매우 정확한 흐름을 correspondences이 없는 영역으로 전파할 수 있다. 자기 유사 성 기반 흐름 전파(self-similarity-based flow propagationself-similarity-based flow propagation)는 매우 유사한 두 영역이 동일한 컨텍스트 또는 객체에 있고 대응되는 흐름이 유사하다는 가정 하에 수행될 수 있다. 또한, 로컬 윈도우 내에서 흐름 전파를 제한하여 예측 정확도를 유지하면서 계산 부하를 크게 감소시킬 수 있다. 2) FLOW HEAD 흐름 헤드 요소는 흐름 전파에서 파생된 광학 흐름을 개선하는 역할을 할 수 있다.이는 흐름을 더욱 향상시키는 여러 CNN 레이어로 구성될 수 있다. 좌표 영역에서 동작하는 1D 매칭 및 흐름 전파와 달리 흐름 헤드는 동일한 객체 내에서 광학 흐름의 연속성을 어드레스할 수 있다. 인핸스된된 소스 이미지 특징과 함께 흐름 전파 단계의 광학 흐름을 처리하여 고유한 특성을 보다 정확하게 반영하는 광학 흐름 리프리젠테이션(optical flow representation)을 완성할 수 있다. D. OFE-BOOSTING MaxFlow는 특징 인핸스, 1D 매칭 및 흐름 인핸스 단계를 한 번 더 반복하여 OFE의 예측 정확도를 높이기 위해 OFE boosting 단계를 통합할 수 있다. 이 OFE boosting은 먼저 기준 이미지 특징을 하기 수학식 14와 같이 예비 광학 흐름에 의해 소스 이미지 특징으로 워핑하는 동작을 포함할 수 있다. 수학식 14"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "여기서 OFW(·)는 대응되는 참조 특징 요소를 소스 특징 요소에 더 가깝게 가져오는 역방향 와핑 작업을 나타낼 수 있다. 이는 요소 간의 보다 효과적인 정보 전달을 촉진하여 보다 정제된 광학 흐름을 예측하는 데 기여할 수 있다. 와핑된 특징은특징 인핸스, 1D 매칭, 흐름 인핸스 순으로 진행될 수 있다. E. LOSS MaxFlow framework 는 초기에 기본 단계에서 1D 매칭을 통해 광학 흐름을 도출할 수 있다. 이러한 흐름은 이후 1D 매칭과 흐름 인핸스를 통해 두 번, OFE 부스팅 단계에서 또 다시 두 번 정제될 수 있다. 단순화를 위해 최종 출력(광 흐름 추정)만 감독하는 것이 가능하지만, 광학 흐름 생성의 각 단계를 감독하면 네트워크 목표에 부합 하고 안정적인 훈련을 촉진할 수 있다. 1D 매칭의 출력인 광학 흐름과 초기 및 OFE 부스팅 단계 모두의 흐름 인 핸스가 실제 광학 흐름과 비교되어 훈련에 대한 손실을 계산할 수 있다. 이는 하기 수학식 15와 같이 총 손실 함수 L을 사용하여 정량화될 수 있다. 수학식 15"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "여기서 γ는 OFE의 각 단계에 적용 가능한 스케일링 인자, Ogt는 Ground Truth Optical Flow, Oi(i = 1, 2, 3 및 4)는 제1 1-D 매칭 모듈, 제1 흐름 인핸스 모듈, 제2 1-D 매칭 모듈, 제2 흐름 인핸스의 출력 등 각 단계에 서 획득된 광학 흐름 맵을 나타낼 수 있다. 상술한 다양한 실시 예에 따르면, 광학 흐름 예측의 높은 정확도를 유지하면서 메모리 사용량을 줄이고 연산 복 잡도를 감소시킬 수 있게 된다. 또한, 순환 게이트 유닛을 사용하지 않고 광학 흐름을 예측함으로써 보다 효율 적인 광학 흐름 예측을 제공할 수 잇게 된다. 또한, 학습 해상도에 과적합된 결과를 보이지 않기 위해 연속 증 강 위치 임베딩(positional embedding) 기술을 적용하여 다양한 해상도를 가진 입력 영상에 대해 강건한 광학 흐름 예측이 가능하게 된다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치 및/또는 서버에 대한 소프트웨어 업그레이드, 또는 하드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다.기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실 시 예들에 따른 전자 장치(예: 전자 장치(A))를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세 서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 대응되는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저 장 매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신 호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시 적으로 저장됨을 구분하지 않는다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2024-0071110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2024-0071110", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 특정 실시 예의 상기 및 다른 측면, 특징 및 이점은 첨부 도면과 함께 취해진 다음의 설명으로부터 더욱 명백해질 것이다. 도 1은 하나 이상의 실시 예에 따른 광학 흐름 예측을 설명하기 위한 도면이다. 도 2a는 일 실시 예에 따른 전자 장치의 구성을 나타내는 블럭도이다. 도 2b는 하나 이상의 실시 예에 따른 전자 장치의 구성을 구체적으로 나타내는 블럭도이다. 도 3은 하나 이상의 실시 예에 따른 광학 흐름 정보 획득 방법을 설명하기 위한 흐름도이다. 도 4a 및 도 4b는 하나 이상의 실시 예에 따른 광학 흐름 예측 방법을 설명하기 위한 도면들이다. 도 5는 하나 이상의 실시 예에 따른 특징 추출 방법을 설명하기 위한 도면이다. 도 6a 내지 도 6c는 하나 이상의 실시 예에 따른 특징 인핸스 방법을 설명하기 위한 도면들이다. 도 7은 하나 이상의 실시 예에 따른 특징 인핸스 방법을 설명하기 위한 도면이다. 도 8은 하나 이상의 실시 예에 따른 특징 인핸스 방법을 설명하기 위한 도면이다. 도 9는 하나 이상의 실시 예에 따른 광학 흐름 예측 방법을 설명하기 위한 도면이다. 도 10은 하나 이상의 실시 예에 따른 광학 흐름 예측을 위한 일 구현 예를 설명하기 위한 도면이다. 도 11a 및 도 11b는 하나 이상의 실시 예에 따른 1차원 매칭 예시를 설명하기 위한 도면들이다. 도 12는 하나 이상의 실시 예에 따른 특징 인핸스 예시를 설명하기 위한 도면이다."}
