{"patent_id": "10-2018-0035407", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0113140", "출원번호": "10-2018-0035407", "발명의 명칭": "물류 센터의 피킹 자동화 시스템 및 이를 이용한 피킹 자동화 방법", "출원인": "한국철도기술연구원", "발명자": "김영주"}}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 신경망을 이용하여, 물체 영역 검출, 물체 접촉점 정보 및 물체 분류에 대한 학습을 수행하는 학습부; 피킹(picking) 대상이 되는 물체에 대한 2차원 및 3차원 이미지를 획득하는 영상 입력부; 및상기 수행된 학습 내용을 바탕으로 상기 획득된 이미지를 이용하여 피킹 대상이 되는 상기 물체의 영역, 상기물체의 접촉점의 위치, 및 피킹시 상기 물체에 대한 접근 방향 중 적어도 하나에 대한 정보를 획득하는 연산부를 포함하는 피킹 자동화 시스템."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 학습부는, 2차원 이미지를 이용하여 상기 학습을 수행하는 것을 특징으로 하는 피킹 자동화 시스템."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 학습부는, 상기 물체 영역 검출, 물체 접촉점 정보 및 물체 분류에 대하여 순차적으로 학습하거나, 일률적으로 한 번에 학습하는 것을 특징으로 하는 피킹 자동화 시스템."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 연산부는, 상기 영상 입력부에서 획득한 3차원 이미지를 상기 학습부가 학습한 2차원 이미지에 투영하는 이미지 투영부;및상기 학습부에서 학습된 물체 접촉점 정보를 바탕으로, 상기 투영된 3차원 이미지에서 접촉점을 계산하는 접촉점 계산부를 포함하는 것을 특징으로 하는 피킹 자동화 시스템."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 연산부는, 상기 계산된 접촉점 주위의 일정 영역에서의 점군집 데이터를 기반으로 접촉면을 산출하고, 상기 접촉면과 수직한 법선 벡터를 계산하는 접근 방향 계산부를 더 포함하는 것을 특징으로 하는 피킹 자동화 시스템."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 연산부는, 상기 계산된 접촉점을 바탕으로, 기 설정된 접근 방향에 관한 정보를 바탕으로 접근 방향에 대한 정보를 제공하는 접근 방향 계산부를 더 포함하는 것을 특징으로 하는 피킹 자동화 시스템."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "인공 신경망을 이용하여, 물체 영역 검출, 물체 접촉점 정보 및 물체 분류에 대한 학습을 수행하는 단계; 피킹(picking) 대상이 되는 물체에 대한 2차원 및 3차원 이미지를 획득하는 단계; 상기 수행된 학습 내용을 바탕으로 상기 획득된 이미지를 이용하여 피킹 대상이 되는 상기 물체의 접촉점의 위치를 연산하는 단계;상기 물체의 피킹시 상기 물체에 대한 접근 방향에 대한 정보를 연산하거나 기 설정된 접근 방향에 대한 정보를적용하는 단계; 및공개특허 10-2019-0113140-3-상기 연산된 상기 접촉점 및 상기 접근 방향을 바탕으로 상기 물체를 파지하는 단계를 포함하는 피킹 자동화 방법."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 학습을 수행하는 단계는, 학습의 대상이 되는 물체 대한 2차원 이미지를 획득하는 단계; 상기 2차원 이미지로부터 상기 물체의 영역을 검출하는 것을 학습하는 단계; 상기 물체에서 피킹이 수행되는 접촉점을 연산하는 것을 학습하는 단계; 및분류기(classifier)를 이용하여 상기 물체를 분류하는 것을 학습하는 단계를 포함하는 것을 특징으로 하는 피킹자동화 방법."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 학습을 수행하는 단계는, 상기 물체의 영역을 검출하는 학습 단계, 상기 접촉점을 연산하는 학습 단계, 및 상기 물체를 분류하는 학습 단계를 별도의 인공 신경망으로 학습시키며, 새로운 제품이 추가되면, 선택에 따라 추가된 제품에 대한 접촉점을 연산하는 학습 단계만 추가로 학습하는 것을 특징으로 하는 피킹 자동화 방법."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 학습을 수행하는 단계는, 상기 물체의 영역을 검출하는 학습 단계, 상기 접촉점을 연산하는 학습 단계, 및 상기 물체를 분류하는 학습 단계를 하나의 인공 신경망으로 학습시키는 것을 특징으로 하는 피킹 자동화 방법."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서, 상기 물체의 접촉점의 위치를 연산하는 단계는, 상기 획득된 3차원 이미지를 상기 학습을 수행하는 단계에서 사용되는 2차원 이미지에 투영하는 단계; 및상기 학습부에서 학습된 물체 접촉점 정보를 바탕으로, 상기 투영된 3차원 이미지에서 접촉점을 계산하는 단계를 포함하는 것을 특징으로 하는 피킹 자동화 방법."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 접촉점을 계산하는 단계에서, 영상 입력부에서 상기 물체에 대하여 획득된 3차원 이미지의 깊이 정보, 및 상기 영상 입력부의 위치정보를 바탕으로 상기 접촉점의 3차원 위치를 계산하는 것을 특징으로 하는 피킹 자동화 방법."}
{"patent_id": "10-2018-0035407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 물체의 접근 방향에 대한 정보는, 상기 계산된 물체의 접촉점 주위의 일정 영역에서 점군집 데이터를 기반으로 접촉면을 산출하는 단계; 상기 접촉면과 수직한 법선 벡터를 계산하는 단계; 및상기 법선 벡터를 상기 접근 방향으로 선정하는 단계를 통해 연산되는 것을 특징으로 하는 피킹 자동화 방법."}
{"patent_id": "10-2018-0035407", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "물류 센터의 피킹 자동화 시스템 및 이를 이용한 피킹 자동화 방법에서, 상기 피킹 자동화 시스템은 학습부, 영 상 입력부 및 연산부를 포함한다. 상기 학습부는 인공 신경망을 이용하여, 물체 영역 검출, 물체 접촉점 정보 및 물체 분류에 대한 학습을 수행한다. 상기 영상 입력부는 피킹(picking) 대상이 되는 물체에 대한 2차원 및 3 차원 이미지를 획득한다. 상기 연산부는 상기 수행된 학습 내용을 바탕으로 상기 획득된 이미지를 이용하여 피 킹 대상이 되는 상기 물체의 영역, 상기 물체의 접촉점의 위치, 및 피킹시 상기 물체에 대한 접근 방향 중 적어 도 하나에 대한 정보를 연산한다."}
{"patent_id": "10-2018-0035407", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 피킹 자동화 시스템 및 이를 이용한 피킹 자동화 방법에 관한 것으로, 더욱 상세하게는 물류 센터에 서 다양한 물체를 피킹(picking)하는 공정을 자동화하기 위해 카메라를 이용하여 획득된 이미지 정보를 바탕으 로 물체를 인식하고 인식된 물체를 피킹할 수 있는 물류 센터의 피킹 자동화 시스템 및 이를 이용한 피킹 자동 화 방법에 관한 것이다."}
{"patent_id": "10-2018-0035407", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "물류 센터에서 수행되는 작업은 크게, 이송, 피킹 및 분배 공정으로 구분할 수 있는데, 이 중 피킹(picking) 공 정은 가장 시간이 많이 필요한 공정으로, 이러한 피킹 공정을 자동화하기 위한 다양한 기술들이 개발되어 왔다. 이러한 피킹 공정의 자동화에서는, 물체 인식 기술이 기본적으로 필요한데, 종래의 물체 인식 기술에서는, 도 1 에 도시된 바와 같은 특징 정합(feature matching)에 기반 하는 것이 일반적이었다. 즉, 특징 정합 기반의 물 체 인식에서는, 촬영된 이미지로부터 추출된 물체의 특징을 데이터베이스에 존재하는 여러 물체들의 특징과 비 교하여 오차를 계산하고, 계산된 오차를 바탕으로 물체의 종류를 파악하는 것을 특징으로 한다. 그러나 이러한 특징 정합 기반의 물체 인식에서는, 인식하고자 하는 물체의 특징에 대한 방대한 양의 데이터베 이스가 필요하며, 새롭게 인식되어야 하는 추가 물체에 대응하는 것이 어려운 문제가 있다. 그리하여, 제품의 종류가 제한적인 생산 공정 등에서의 적용은 가능하나, 물류센터와 같이 취급하여야 하는 물 품의 종류가 다양한 경우에는 적용이 어려운 한계가 있다. 나아가, 물류센터에서의 피킹 공정을 위해서는 이러한 물체 인식 외에, 물체의 파지를 위한 접촉점에 대한 정보 도 획득하여야 하지만, 촬영된 이미지와 데이터베이스들 사이에서 이러한 접촉점에 대한 정보를 획득하기 위해 서는 충분한 데이터베이스를 구축하여야 하며 접촉점 도출을 위한 방대한 양의 연산이 수행되어야 하는 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-1197125호"}
{"patent_id": "10-2018-0035407", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에, 본 발명의 기술적 과제는 이러한 점에서 착안된 것으로 본 발명의 목적은 인공지능을 기반으로 접촉점과 접근 방향을 연산함으로써 복잡한 연산과정을 단순화하면서도 정확한 피킹을 수행할 수 있어 피킹 공정의 속도 를 향상시킬 수 있는 물류 센터의 피킹 자동화 시스템에 관한 것이다. 본 발명의 다른 목적은 상기 피킹 자동화 시스템을 이용한 피킹 자동화 방법에 관한 것이다."}
{"patent_id": "10-2018-0035407", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 본 발명의 목적을 실현하기 위한 일 실시예에 따른 피킹 자동화 시스템은 학습부, 영상 입력부 및 연산 부를 포함한다. 상기 학습부는 인공 신경망을 이용하여, 물체 영역 검출, 물체 접촉점 정보 및 물체 분류에 대 한 학습을 수행한다. 상기 영상 입력부는 피킹(picking) 대상이 되는 물체에 대한 2차원 및 3차원 이미지를 획 득한다. 상기 연산부는 상기 수행된 학습 내용을 바탕으로 상기 획득된 이미지를 이용하여 피킹 대상이 되는 상기 물체의 영역, 상기 물체의 접촉점의 위치, 및 피킹시 상기 물체에 대한 접근 방향 중 적어도 하나에 대한 정보를 획득한다. 일 실시예에서, 상기 학습부는, 2차원 이미지를 이용하여 상기 학습을 수행할 수 있다. 일 실시예에서, 상기 학습부는, 상기 물체 영역 검출, 물체 접촉점 정보 및 물체 분류에 대하여 순차적으로 학 습하거나, 일률적으로 한 번에 학습할 수 있다. 일 실시예에서, 상기 연산부는, 상기 영상 입력부에서 획득한 3차원 이미지를 상기 학습부가 학습한 2차원 이미 지에 투영하는 이미지 투영부, 및 상기 학습부에서 학습된 물체 접촉점 정보를 바탕으로, 상기 투영된 3차원 이미지에서 접촉점을 계산하는 접촉점 계산부를 포함할 수 있다. 일 실시예에서, 상기 연산부는, 상기 계산된 접촉점 주위의 일정 영역에서의 점군집 데이터를 기반으로 접촉면 을 산출하고, 상기 접촉면과 수직한 법선 벡터를 계산하는 접근 방향 계산부를 더 포함할 수 있다. 일 실시예에서, 상기 연산부는, 상기 계산된 접촉점을 바탕으로, 기 설정된 접근 방향에 관한 정보를 바탕으로 접근 방향에 대한 정보를 제공하는 접근 방향 계산부를 더 포함할 수 있다. 상기한 본 발명의 목적을 실현하기 위한 일 실시예에 따른 피킹 자동화 방법에서, 인공 신경망을 이용하여, 물 체 영역 검출, 물체 접촉점 정보 및 물체 분류에 대한 학습을 수행한다. 피킹(picking) 대상이 되는 물체에 대 한 2차원 및 3차원 이미지를 획득한다. 상기 수행된 학습 내용을 바탕으로 상기 획득된 이미지를 이용하여 피 킹 대상이 되는 상기 물체의 접촉점의 위치를 연산한다. 상기 물체의 피킹시 상기 물체에 대한 접근 방향에 대 한 정보를 연산하거나 기 설정된 접근 방향에 대한 정보를 적용한다. 상기 연산된 상기 접촉점 및 상기 접근 방향을 바탕으로 상기 물체를 파지한다. 일 실시예에서, 상기 학습을 수행하는 단계는, 학습의 대상이 되는 물체 대한 2차원 이미지를 획득하는 단계, 상기 2차원 이미지로부터 상기 물체의 영역을 검출하는 것을 학습하는 단계, 상기 물체에서 피킹이 수행되는 접 촉점을 연산하는 것을 학습하는 단계, 및 분류기(classifier)를 이용하여 상기 물체를 분류하는 것을 학습하는 단계를 포함할 수 있다. 일 실시예에서, 상기 학습을 수행하는 단계는, 상기 물체의 영역을 검출하는 학습 단계, 상기 접촉점을 연산하 는 학습 단계, 및 상기 물체를 분류하는 학습 단계를 별도의 인공 신경망으로 학습시키며, 새로운 제품이 추가 되면, 선택에 따라 추가된 제품에 대한 접촉점을 연산하는 학습 단계만 추가로 학습할 수 있다. 일 실시예에서, 상기 학습을 수행하는 단계는, 상기 물체의 영역을 검출하는 학습 단계, 상기 접촉점을 연산하 는 학습 단계, 및 상기 물체를 분류하는 학습 단계를 하나의 인공 신경망으로 학습시킬 수 있다. 일 실시예에서, 상기 물체의 접촉점의 위치를 연산하는 단계는, 상기 획득된 3차원 이미지를 상기 학습을 수행 하는 단계에서 사용되는 2차원 이미지에 투영하는 단계, 및 상기 학습부에서 학습된 물체 접촉점 정보를 바탕으 로, 상기 투영된 3차원 이미지에서 접촉점을 계산하는 단계를 포함할 수 있다. 일 실시예에서, 상기 접촉점을 계산하는 단계에서, 영상 입력부에서 상기 물체에 대하여 획득된 3차원 이미지의 깊이 정보, 및 상기 영상 입력부의 위치정보를 바탕으로 상기 접촉점의 3차원 위치를 계산할 수 있다. 일 실시예에서, 상기 물체의 접근 방향에 대한 정보는, 상기 계산된 물체의 접촉점 주위의 일정 영역에서 점군 집 데이터를 기반으로 접촉면을 산출하는 단계, 상기 접촉면과 수직한 법선 벡터를 계산하는 단계, 및 상기 법 선 벡터를 상기 접근 방향으로 선정하는 단계를 통해 연산될 수 있다."}
{"patent_id": "10-2018-0035407", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 의하면, 인공 신경망을 이용한 학습을 바탕으로, 실제 피킹 대상이 되는 물체의 접촉점 위치 및 접근 방향에 대한 정보를 연산할 수 있으므로, 종래 접촉점 위치 및 접근 방향에 대한 정보를 획득하기 위한 방대한 량의 연산을 수행하지 않을 수 있어, 피킹 속도를 보다 향상시킬 수 있다. 특히, 학습부에서는 2차원 이미지를 이용하여 학습을 수행하되, 물체 영역 검출, 물체 접촉점 정보 및 물체 분 류에 대한 학습을 수행함으로써, 3차원 이미지를 통한 학습보다 용이한 학습이 수행되며, 실제 피킹을 위해 필 요한 공정 각각에 대한 학습을 수행할 수 있어 피킹에서의 적용성이 우수하다. 한편, 2차원 이미지를 이용한 학습의 결과를 적용하기 위해, 실제 물체에 대한 3차원 정보는 2차원 이미지로 투 영되어야 하지만, 3차원 정보에 이미 해당 물체에 대한 깊이 정보가 포함되고 있으므로, 2차원 이미지에 대한 학습으로도 필요한 연산을 충분히 수행할 수 있다. 나아가, 접근 방향에 대한 정보 획득을 위해, 접촉점을 연산한 이후, 접촉점 주위에서만 점군집 데이터를 기반 으로 접촉면을 산출하면 충분하므로, 종래 계측된 물체의 모든 형상에 대하여 점군집 데이터를 기반으로 접촉점 및 접근 방향에 대한 정보를 획득하는 것과 대비하여 연산 시간을 줄일 수 있어 피킹 공정을 신속히 수행할 수 있다."}
{"patent_id": "10-2018-0035407", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있는 바, 실시예들을 본문에 상세하게 설명하 고자 한다. 그러나 이는 본 발명을 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 각 도면을 설명하면서 유 사한 참조부호를 유사한 구성요소에 대해 사용하였다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 본 출원에서 사용한 용 어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"이루어진다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 도 2는 본 발명의 일 실시예에 의한 물류 센터의 피킹 자동화 시스템을 도시한 블록도이다. 도 2를 참조하면, 본 실시예에 의한 피킹 자동화 시스템은 학습부, 영상 입력부 및 연산부 를 포함한다. 상기 학습부는 인공 신경망을 이용하여 학습을 수행하되, 수행되는 학습은, 물체 영역 검출 학습, 물 체 접촉점 정보 학습 및 물체 분류 학습을 포함한다. 상기 학습부에서의 학습이란, 후술되는 연산부에서의 연산을 수행하기 위한 전제로서, 물체의 인식을 용이하게 수행할 수 있는 인공지능 학습을 의미하며, 학습 데이터를 바탕으로 학습을 수행하게 된다. 상기 학습 데이터는, 본 학습이 물체의 피킹을 용이하게 수행하기 위한 학습이므로, 피킹의 대상이 되는, 즉 물 류센터에서 취급되는 다양한 상품들의 이미지에 대한 촬영 정보이다. 이 경우, 상기 이미지는 2차원 이미지로서, 상기 이미지에는 다양한 상품들의 종류별, 접촉점의 위치에 대한 정 보가 포함되어야 한다. 이러한 인공지능 기법의 예로서는, CNN(Convolution Neural Network)을 이용할 수 있으며, 종래 CNN을 이용하 여 이미지 내에서 대상체(object)들의 위치나 대상체들을 분류하는 기법들은 다수 개발된 상태이고, 이에 따라 본 실시예에서의 상기 학습부는 이러한 CNN을 이용하여 학습을 수행하게 된다. 보다 구체적인 상기 학습부의 학습 단계에 대하여는 후술한다. 상기 영상 입력부는 물류센터에서 피킹(picking)의 대상이 되는 물체에 대한 2차원 및 3차원 이미지를 획 득한다. 상기 영상 입력부는 카메라 및 거리센서를 포함하여, 상기 카메라를 통해 상기 2 차원 및 3차원 이미지를 획득할 수 있으며, 이와 동시에 상기 거리센서를 통해 상기 물체까지의 거리 또는 깊이 정보를 획득하게 된다. 한편, 실제 물류센터에서는 상기 피킹의 대상이 되는 물체는 다른 물체들과 섞인 상태로 위치하게 되므로, 상기 영상 입력부를 통해 획득되는 이미지는 다양한 물체들이 포함된 이미지일 수 있다. 따라서, 상기 연산부에서는 상기 획득된 이미지로부터 피킹의 대상이 되는 물체를 식별하고 해당 물체를 피킹하기 위한 정보를 연산하게 된다. 이 경우, 상기 피킹 대상 물체를 피킹하기 위한 정보는, 물체를 식별 및 특정하여 피킹하기 위해 필요한 정보로 서, 피킹 대상 물체의 영역, 피킹 대상 물체의 접촉점의 위치, 피킹 대상 물체의 피킹을 위한 접근 방향 등을 포함한다. 즉, 상기 연산부는 상기와 같은 피킹 대상 물체를 피킹하기 위한 정보로서, 물체의 영역, 물체의 접촉점의 위치 및 물체에 대한 접근 방향에 대한 정보를 획득하며, 이러한 획득에서 상기 학습부에서의 학습 결과를 이용하게 된다. 이와 달리, 상기 연산부는 상기 물체의 영역, 상기 물체의 접촉점의 위치, 및 피킹시 상기 물체에 대한 접 근 방향 중 적어도 하나에 대한 정보를 연산할 수 있으며, 다른 정보는 기 설정되거나 기 연산된 결과를 사용할 수도 있다. 즉, 상기 연산부에서는 상기 물체에 대한 접근 방향에 대한 정보를 직접 연산하지는 않고, 상기 물체의 접 촉점의 위치에 대한 정보가 연산되면, 상기 연산된 접촉점에 대한 정보를 바탕으로 기 설정된 접근 방향에 대한 정보를 바탕으로 상기 물체에 대한 접근 방향에 대한 정보를 제공할 수도 있다. 이를 위해, 도시하지는 않았으나, 별도의 데이터베이스에, 물체의 접촉점의 위치에 따라 해당 접촉점으로의 최 적 접근 방향에 대한 정보가 기 저장될 수 있으며, 이에 따라, 접촉점에 대한 정보가 연산되면 상기 데이터베이 스로부터 최적 접근 방향에 대한 정보를 적용할 수도 있다. 다만, 이하에서는 상기 연산부가 상기 물체에 대한 접근 방향에 대한 정보를 연산하는 것에 대하여 상세히 설명한다. 보다 구체적으로, 상기 연산부는 이미지 투영부, 접촉점 계산부 및 접근 방향 계산부를 포 함한다. 그리하여, 상기 이미지 투영부에서는, 상기 영상 입력부에서 획득된 3차원 이미지를, 상기 학습부 가 학습한 2차원 이미지에 투영한다. 이 경우, 상기 영상 입력부에서 2차원 이미지도 동시에 획득하 므로, 2차원 이미지가 획득되는 경우라면 상기 학습부가 학습한 2차원 이미지에 투영은 필요 없으며 대응 시키는 것으로 충분할 수 있다. 상기 학습부에서는 학습의 용이성을 위해 2차원 이미지로 학습을 수행하였는바, 상기 이미지 투영부 에서는 3차원 이미지를 2차원 이미지로 투영하는 것이 필요하다. 상기 접촉점 계산부는 상기 학습부에서 학습된 물체 접촉점 정보를 바탕으로, 상기 투영된 3차원 이 미지에서 접촉점을 계산한다. 이 경우, 상기 학습부는 이미 특정 물체의 접촉점에 대한 정보를 학습한 상 태이므로, 투영된 3차원 이미지로부터 피킹 대상이 되는 물체가 식별 또는 특정되면, 해당 물체에 최적의 접촉 점이 어디인지를 즉각적으로 연산하여 도출할 수 있다. 따라서, 종래에서와 같이, 방대한 량의 데이터 처리를 생략할 수 있으며, 접촉점에 대한 정보를 즉각적으로 추 출할 수 있다. 상기 접근 방향 계산부는 상기 추출된 접촉점에 대한 정보를 바탕으로 접촉면을 산출하여 법선 벡터를 계 산한다. 즉, 상기 접근 방향 계산부는 상기 접촉점 계산부에서 계산된 접촉점에 대한 정보를 바탕으로 상기 접촉점 주위의 일정 영역에서의 점군집 데이터를 추출한다. 이후, 상기 접촉점 주위의 점군집 데이터를 기반으 로 접촉면을 산출하고, 상기 접촉면과 수직한 법선 벡터를 계산한다. 비록 상기 접근 방향 계산부에서는 점군집 데이터를 바탕으로 접촉면을 산출하는 연산을 수행하여야 하지 만, 접촉점 주위의 일정 영역에서의 점군집 데이터만을 고려하면 충분한 것으로, 종래의 물체 전체의 형상이나 위치를 추출하기 위한 점군집 데이터를 연산과 비교하면 연산량은 상대적으로 매우 적다고 할 수 있다. 이상과 같이, 상기 접근 방향 계산부에서 법선 벡터를 계산하면, 그리퍼는 상기 계산된 법선 벡터의 반대 방향으로 접근하여 물체를 파지하여 피킹을 수행하게 된다. 한편, 앞서 설명한 바와 같이, 상기 접근 방향 계산부에서는, 별도의 연산을 수행하지 않고, 상기 데이터 베이스를 통해 연산된 접촉점에 대한 정보로부터 기 설정된 최적의 접근 방향에 대한 정보를 제공할 수도 있다. 이하에서는, 상기 피킹 자동화 시스템을 이용한 피킹 자동화 방법에 대하여 보다 상세하게 설명한다. 도 3은 도 2의 피킹 자동화 시스템을 이용한 피킹 자동화 방법을 도시한 흐름도이다. 도 4는 도 3의 학습부의 학습 단계를 도시한 흐름도이다. 도 5는 도 4의 학습 단계의 일 예를 도시한 이미지이다. 도 6은 도 4의 학습 단계의 다른 예를 도시한 이미지이다. 도 7은 도 3의 접촉점 연산 단계를 도시한 흐름도이다. 도 8a 및 도 8b 는 도 7의 접촉점 연산 단계의 예를 도시한 이미지들이다. 도 9는 도 3의 접근 방향 연산 단계를 도시한 흐름 도이다. 도 10은 도 9의 접근 방향 연산 단계의 예를 도시한 이미지이다. 도 11은 도 3의 그리퍼의 파지 단계 의 예를 도시한 이미지이다. 도 3 및 도 4를 참조하면, 본 실시예에 의한 피킹 자동화 방법에서는, 우선, 상기 학습부에서 학습을 수행 한다(단계 S10). 이 경우, 수행되는 학습은 앞서 설명한 바와 같이, 인공 신경망을 이용하여 물체 영역을 검출 하는 학습, 물체 접촉점 정보를 획득하는 학습, 물체 분류에 대한 학습일 수 있다. 보다 구체적으로, 도 4 및 도 5를 참조하면, 상기 학습 수행 단계에서는(단계 S10), 우선, 학습의 대상이 되는 물체에 대한 2차원 이미지를 획득한다(단계 S11). 여기서, 학습의 대상되는 물체는 실제 물류센터에서 피킹의 대상이 될 수 있는 물체인 것이 바람직하며, 다 양한 종류의 물체들에 대한 학습을 각각 수행하는 것이 필요하다. 또한, 상기 물체에 대하여 획득되는 2차원 이미지는, 반드시 본 실시예에서의 상기 영상 입력부를 통 해 획득되는 2차원 이미지가 아니어도 무방하며 별도의 영상 획득부(미도시)를 통해 획득되는 2차원 이미지일 수 있고, 나아가 학습을 위해 별도로 촬영되어 저장된 데이터 베이스에 포함된 2차원 이미지일 수 있다. 이 후, 도 4 및 도 5를 참조하면, 상기 학습부에서는, 상기 2차원 이미지로부터 상기 물체의 영역을 검출하는 것을 학습한다(단계 S12). 즉, 상기 학습부에서는 'object network', 즉, 존재하는 물체(object)에서 해당 물체의 영역을 검출하는 것에 대한 내용을 학습한다. 이는 도 5에 도시된 바와 같이, 2차원 이미지 상의 물체에 대한 정보로부터 해당 물체의 영역을 검출하는 방법에 대한 내용을 학습하는 것을 의미한다. 이러한 'object network'에 대한 학습을 통해, 상기 학습부는 특정 물체가 포함된 2차원 이미지가 입력되 면 해당 이미지로부터 특정 물체가 차지하는 영역을 검출할 수 있게 된다. 이 후, 도 4 및 도 5를 참조하면, 상기 학습부에서는, 상기 물체에서 피킹이 수행되는 접촉점을 연산 하는 것을 학습한다(단계 S13). 즉, 상기 학습부에서는 '접촉점 network', 즉, 특정 물체에 대하여 해당 물체를 피킹하기 위한 접촉점을 추출하는 것에 대한 내용을 학습한다. 이는 도 5에 도시된 바와 같이, 피킹의 대상이 되는 물체의 영역 이 검출된 경우 해당 물체의 피킹시 접촉점을 추출하는 방법에 대한 내용을 학습하는 것을 의미한 다. 이러한 '접촉점 network'에 대한 학습을 통해, 상기 학습부는 특정 물체가 차지하는 영역이 검출되면, 해 당 영역의 물체에 대하여 피킹시 접촉점을 검출할 수 있게 된다. 이 후, 도 4 및 도 5를 참조하면, 상기 학습부에서는, 분류기(classifier)를 이용하여 상기 물체를 분 류하는 것을 학습한다. 즉, 상기 학습부에서는 상기 물체에 대한 인식을 바탕으로, 물체의 종류, 형태, 크기 등의 외형으로부 터 물체를 종류별, 형태별, 크기별 등으로 분류하는 방법에 대하여 학습하게 되며, 이러한 학습을 통해 상기 학 습부는 물체의 분류법을 터득하게 된다. 한편, 도 5를 참조하여 설명한 상기 학습방법에서는, 각각의 학습단계, 즉 'object network'학습, '접촉점 network'학습, 및 '분류 학습'을 별도의 네트워크를 통해 학습시키는 것을 특징으로 한다. 따라서, 상기 학습부는 새로운 제품(물체)에 대한 학습시, 상기 각각의 학습단계들을 모두 학습하지 않고, 여타의 학습이 불필요하다면 선택에 따라'접촉점 network'학습만을 수행시킬 수 있다. 이에 따라, 상기 학습부 의 학습의 결과는 선택에 따라 보다 용이하게 업데이트될 수 있어, 학습 시간을 절감시킬 수 있다. 이와 달리, 도 6에 도시된 바와 같이, 상기 학습단계들, 즉 'object network'학습, '접촉점 network'학습, 및 '분류 학습'을 하나의 학습단계로 묶어 학습을 수행시킬 수 있다. 상기 학습부의 학습의 단계에 대하여 도 4에서는 'object network'학습, '접촉점 network'학습, 및 '분류 학습'을 구분하여 각각 수행되는 것을 설명하였으나, 상기 각각의 학습단계들은 하나의 학습단계로서 수행될 수 있다. 즉, 도 6을 참조하면, 2차원 이미지가 획득된 이후(단계 S11), 상기 2차원 이미지에 포함된 물체의 영역 을 검출하고, 상기 검출된 영역에서 상기 물체의 접촉점을 연산하며, 상기 물체를 종류, 형상, 크기 등을 기준으로 분류하는 것을 일련의 과정으로서 하나의 학습 네트워크를 통해 학습시킬 수 있고, 이에 따라 상기 학습부는 상기 일련의 과정을 하나의 학습 네트워크로 학습받을 수 있다. 이와 같은 학습 방법에서는, 새로운 제품에 대하여 학습 데이터를 갱신하기 위해서는 새로운 제품(물체)에 대한 2차원 이미지, 물체의 영역, 접촉점 및 분류에 대한 정보를 모두 이용하여 학습을 시키는 것이 필 요하게 된다. 이상과 같이, 상기 학습부에서는, 인공 신경망을 이용하여 학습을 수행하게 되며, 다양한 종류의 물체나 제품에 대하여, 물체의 영역을 검출하는 방법, 피킹이 수행되는 접촉점을 연산하는 방법 및 물체를 분류하는 방 법에 대한 학습 내용을 축적하게 된다. 이와 같은, 학습부에서의 학습 단계가 종료되면, 도 3을 참조하면, 상기 영상 입력부를 통해 물류센 터에서 피킹의 대상이 되는 물체에 대한 2차원 및 3차원 이미지를 획득한다(단계 S20). 이 경우, 상기 2차원 및 3차원 이미지는 카메라 등의 영상 촬영 장치를 통해 획득될 수 있으며, 이미지에 대한 정보 외에, 거리 센서 등을 통해 상기 영상 입력부로부터 피킹의 대상이 되는 물체에 대한 거리 또는 깊이 정보도 동시에 획득한다. 한편, 상기 영상 입력부를 통해 획득된 2차원 이미지는, 앞서 설명한 바와 같이, 상기 학습부에서의 학습용 이미지로 활용될 수도 있다. 이 후, 도 3 및 도 7을 참조하면, 상기 연산부는 접촉점을 연산한다(단계 S20). 즉, 상기 연산부에 서는, 상기 영상 입력부에서 획득된 이미지로부터 피킹의 대상이되는 물체의 접촉점의 위치를 연산하는데, 이러한 연산에서 상기 학습부를 통해 수행된 학습 내용을 적용하게 된다. 이를 위해, 상기 학습부에서의 학습 정보 및 학습 결과는 상기 연산부로 제공되어 상기 연산부 가 연산에 그대로 활용할 수 있으며, 이와 달리, 상기 학습부는 상기 연산부와 일체로서 상기 학습부 의 학습 정보 및 학습 결과는 상기 연산부에 의해 그대로 활용될 수도 있다. 보다 구체적으로, 상기 접촉점의 연산 단계(단계 S20)에서는, 도 7 및 도 8a를 참조하면, 상기 연산부의 이미지 투영부에서는, 상기 영상 입력부를 통해 획득된 3차원 이미지를 상기 학습을 수행하는 단계에 서 사용되는 2차원 이미지에 투영한다(단계 S31). 상기 학습부에서 수행된 학습에서는, 이미 설명한 바와 같이, 2차원 이미지를 바탕으로 각각의 학습단계를 수행하였으므로, 상기 학습부에서의 학습 결과를 그대로 적용하기 위해서는 상기 영상 입력부를 통해 획득된 3차원 이미지는 우선 2차원 이미지로 투영되도록 변형되어야 한다. 이 경우, 상기 영상 입력부를 통해 획득되는 이미지가 2차원 이미지라면 별도의 이미지 투영 단계는 생략 될 수 있다. 이 후, 도 7, 도 8a 및 도8b를 참조하면, 상기 연산부의 접촉점 계산부에서는, 상기 학습부에서 학습된 물체 접촉점 정보를 바탕으로, 상기 투영된 3차원 이미지에서 접촉점을 계산한다(단계 S32). 즉, 상기 접촉점 계산부는 학습의 결과를 그대로 적용하여, 상기 투영된 2차원 이미지(도 8a 참조)로부터 피킹 대상이 되는 물체의 영역을 검출하고, 검출된 물체의 영역에서 접촉점을 추출 또는 계산한다. 나아가, 상기 접촉점 계산부에서는 상기 학습의 결과를 그대로 적용하여, 도 8b에 도시된 바와 같이, 상기 물체를 그 종류, 형상, 크기 등의 기준으로 분류할 수도 있다. 한편, 상기 접촉점 계산부에서는 2차원 이미지로 투영된 상태에서 접촉점을 계산한 상태이므로, 이를 3차 원 이미지에서의 접촉점의 위치로 변환할 필요가 있다. 따라서, 상기 접촉점 계산부에서는, 상기 영상 입력부의 거리센서 등을 통해 입력된 피킹 대상 이 되는 물체까지의 깊이 또는 거리 정보를, 상기 2차원 이미지로 투영된 상태에서의 접촉점 위치 정보에 추가 하여, 상기 피킹 대상이 되는 물체의 3차원 이미지에서의 접촉점의 위치, 즉 실제 피킹 대상이 되는 물체의 접 촉점의 공간 좌표 상의 위치를 계산한다. 이와 같이, 상기 접촉점 계산부를 통해 피킹 대상 물체의 3차원 공간 상의 접촉점의 위치 정보가 획득되면, 도 3 및 도 9를 참조하면, 상기 연산부의 접근방향 계산부에서는 상기 피킹 대상이 되는 물체로의 접근 방향을 연산한다(단계 S40). 보다 구체적으로, 도 9 및 도 10을 참조하면, 상기 접근방향의 연산 단계(단계 S40)에서는, 우선, 상기 계산된 물체의 접촉점 주위의 일정 영역에서 점군집 데이터를 기반으로 접촉면을 산출한다(단계 S41). 일반적으로 접촉점은 접촉면에 포함되는 임의의 점이므로, 상기 접촉점이 포함되는 접촉면을 도출하기 위해서는 접촉점 주위의 점군집 데이터를 활용하여 상기 점군집 데이터가 형성하는 접촉면을 계산하는 것이 필요하다. 이에 따라, 도 10에 도시된 바와 같이, 상기 접촉점 주위의 일정 영역에서의 점군집 데이터가 소정의 접촉면을 형성한다면, 해당 접촉면을 계산할 수 있다. 또한, 이렇게 계산된 상기 접촉면은 상기 물체에서 상기 접촉점이 위치하는 부분을 형성하는 면으로 정의될 수 있다. 본 실시예에서는, 앞선 단계를 통해 도출된 물체의 접촉점 주위의 일정 영역에 대하여만 점군집 데이터(5 0)를 이용하여 접촉면을 산출하므로, 불필요한 연산을 최소화하면서도 접촉 방향을 연산하기 위한 정확한 데이터를 획득할 수 있다. 이 후, 도 9 및 도 10을 참조하면, 상기 도출된 접촉면과 수직한 법선 벡터를 계산한다(단계 S42). 상 기 법선벡터는 상기 접촉면에 수직인 벡터로서 상기 접촉점으로부터 시작되는 벡터로 정의될 수 있 다. 이 후, 도 9 및 도 10을 참조하면, 상기 법선 벡터의 방향을 상기 접근 방향으로 선정한다(단계 S43). 즉, 상기 물체의 피킹을 위한 접근 방향은 상기 법선 벡터 방향, 즉 상기 법선 벡터와 반대 방향으로 상기 법선 벡터에 평행하며 상기 접촉면을 향하는 방향으로 선정된다. 한편, 앞서 설명한 바와 같이, 별도의 데이터베이스에, 물체의 접촉점의 위치에 따라 해당 접촉점으로의 최적 접근 방향에 대한 정보가 기 저장될 수 있으며, 이에 따라, 상기 접촉점에 대한 정보가 연산되면 상기 데이 터베이스로부터 최적 접근 방향에 대한 정보를 적용할 수도 있다. 이에 따라, 상기 물체에 대한 접근 방향에 대한 정보가 선정된다. 이와 같이, 상기 접근 방향이 선정되면, 도 3 및 도 11을 참조하면, 상기 접근 방향을 따라, 상기 접촉점을 향 해, 그리퍼가 접근하여 피킹 대상이 되는 물체를 파지하게 된다(단계 S50). 이렇게 파지된 상기 물체는 상기 그리퍼에 파지된 상태로 필요한 위치로 이동하게 된다. 상기와 같은 본 발명의 실시예들에 의하면, 인공 신경망을 이용한 학습을 바탕으로, 실제 피킹 대상이 되는 물 체의 접촉점 위치 및 접근 방향에 대한 정보를 연산할 수 있으므로, 종래 접촉점 위치 및 접근 방향에 대한 정 보를 획득하기 위한 방대한 량의 연산을 수행하지 않을 수 있어, 피킹 속도를 보다 향상시킬 수 있다. 특히, 학습부에서는 2차원 이미지를 이용하여 학습을 수행하되, 물체 영역 검출, 물체 접촉점 정보 및 물체 분 류에 대한 학습을 수행함으로써, 3차원 이미지를 통한 학습보다 용이한 학습이 수행되며, 실제 피킹을 위해 필 요한 공정 각각에 대한 학습을 수행할 수 있어 피킹에서의 적용성이 우수하다. 한편, 2차원 이미지를 이용한 학습의 결과를 적용하기 위해, 실제 물체에 대한 3차원 정보는 2차원 이미지로 투 영되어야 하지만, 3차원 정보에 이미 해당 물체에 대한 깊이 정보가 포함되고 있으므로, 2차원 이미지에 대한 학습으로도 필요한 연산을 충분히 수행할 수 있다. 나아가, 접근 방향에 대한 정보 획득을 위해, 접촉점을 연산한 이후, 접촉점 주위에서만 점군집 데이터를 기반 으로 접촉면을 산출하면 충분하므로, 종래 계측된 물체의 모든 형상에 대하여 점군집 데이터를 기반으로 접촉점 및 접근 방향에 대한 정보를 획득하는 것과 대비하여 연산 시간을 줄일 수 있어 피킹 공정을 신속히 수행할 수 있다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 산업상 이용가능성 본 발명에 따른 물류 센터의 피킹 자동화 시스템 및 이를 이용한 피킹 자동화 방법은 물류센터에 사용될 수 있 는 산업상 이용 가능성을 갖는다."}
{"patent_id": "10-2018-0035407", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래기술에 의한 특징 정합 기반의 물체 인식의 예를 도시한 이미지이다. 도 2는 본 발명의 일 실시예에 의한 물류 센터의 피킹 자동화 시스템을 도시한 블록도이다. 도 3은 도 2의 피킹 자동화 시스템을 이용한 피킹 자동화 방법을 도시한 흐름도이다. 도 4는 도 3의 학습부의 학습 단계를 도시한 흐름도이다. 도 5는 도 4의 학습 단계의 일 예를 도시한 이미지이다. 도 6은 도 4의 학습 단계의 다른 예를 도시한 이미지이다. 도 7은 도 3의 접촉점 연산 단계를 도시한 흐름도이다. 도 8a 및 도 8b는 도 7의 접촉점 연산 단계의 예를 도시한 이미지들이다. 도 9는 도 3의 접근 방향 연산 단계를 도시한 흐름도이다. 도 10은 도 9의 접근 방향 연산 단계의 예를 도시한 이미지이다. 도 11은 도 3의 그리퍼의 파지 단계의 예를 도시한 이미지이다."}
