{"patent_id": "10-2021-0027665", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0064871", "출원번호": "10-2021-0027665", "발명의 명칭": "전자 장치 및 그의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "박상준"}}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,마이크로폰; TTS 모델 및 복수의 평가용 텍스트가 저장된 메모리; 및사용자가 발화한 사용자 음성이 상기 마이크로폰을 통해 수신되면, 상기 사용자 음성의 레퍼런스 벡터를 획득하고, 상기 레퍼런스 벡터에 기초하여 복수의 후보 레퍼런스 벡터를 생성하고,상기 복수의 후보 레퍼런스 벡터 및 상기 복수의 평가용 텍스트를 상기 TTS 모델에 입력하여, 복수의 합성음을획득하고,상기 복수의 합성음 및 상기 사용자 음성 간의 유사도 및 상기 복수의 합성음의 특성에 기초하여, 상기 복수의합성음 중 적어도 하나의 합성음을 식별하고,상기 적어도 하나의 합성음의 레퍼런스 벡터를 상기 TTS 모델을 위한 상기 사용자에 대응되는 레퍼런스 벡터로상기 메모리에 저장하는 프로세서;를 포함하는 전자 장치."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 후보 레퍼런스 벡터는, 상기 레퍼런스 벡터에 기초하여 랜덤하게 선택된 적어도 하나의 레퍼런스 벡터, 상기 레퍼런스 벡터 및 상기TTS 모델의 훈련에 이용된 레퍼런스 벡터에 기초하여 생성된 적어도 하나의 레퍼런스 벡터 및 마스킹 벡터를 상기 레퍼런스 벡터에 적용하여 생성된 적어도 하나의 레퍼런스 벡터를 포함하는 전자 장치."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 후보 레퍼런스 벡터 및 상기 복수의 평가용 텍스트를 상기 TTS 모델에 입력하여, 상기 복수의 후보레퍼런스 벡터 각각에 기초하여 상기 복수의 평가용 텍스트 각각에 대해 생성된 상기 복수의 합성음을 획득하는전자 장치."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 프로세서는, 상기 복수의 합성음 중 상기 사용자 음성과의 유사도가 기설정된 임계 값 이상인 후보 합성음을 식별하고,상기 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나에 기초하여, 상기 후보 합성음 중 상기 적어도 하나의 합성음을 식별하는 전자 장치."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는,공개특허 10-2022-0064871-3-상기 후보 합성음 각각에 대한 운율 점수, 발음 점수 및 음질 점수를 산출하고, 상기 후보 합성음 중 상기 운율 점수, 발음 점수 및 음질 점수 각각이 기설정된 임계 값 이상인 상기 적어도 하나의 합성음을 식별하는 전자 장치."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 복수의 평가용 텍스트는, 복수의 도메인 각각에 속한 적어도 하나의 평가용 텍스트를 포함하고,상기 프로세서는,상기 복수의 후보 합성음 각각이 속한 도메인에 기초하여, 상기 복수의 도메인에 따라 상기 복수의 후보 합성음을 구분하고, 각 도메인에 속한 적어도 하나의 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나의 기초하여, 도메인별로 상기 적어도 하나의 합성음을 식별하는 전자 장치."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 식별된 적어도 하나의 합성음의 레퍼런스 벡터는 각 평가용 텍스트가 속한 도메인에 따라 상기 메모리에저장되는, 전자 장치."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,스피커 및 디스플레이 중 적어도 하나를 포함하는 출력 인터페이스;를 더 포함하고,상기 프로세서는,상기 복수의 도메인 중 상기 적어도 하나의 합성음의 레퍼런스 벡터가 존재하지 않는 도메인을 판단하고, 상기판단된 도메인에 속한 적어도 하나의 후보 합성음에 대해 산출된 운율 점수, 발음 점수 및 음질 점수에 기초하여, 운율, 발음 및 음질 중 상대적으로 낮은 점수가 산출된 합성음의 특성을 판단하며,상기 판단된 특성에 기초하여 생성된 문장의 발화를 요청하는 음성을 상기 스피커를 통해 출력하는 전자 장치."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,스피커;를 더 포함하고,상기 프로세서는,상기 사용자의 후속 사용자 음성이 상기 마이크로폰을 통해 수신되면, 상기 후속 사용자 음성에 대한 응답을 위한 텍스트를 획득하고,상기 획득된 텍스트 및 상기 메모리에 저장된 상기 사용자에 대응되는 적어도 하나의 레퍼런스 벡터 중 하나를상기 TTS 모델에 입력하여, 상기 레퍼런스 벡터에 기초하여 상기 텍스트에 대해 생성된 음성을 획득하고,상기 획득된 음성을 출력하도록 상기 스피커를 제어하는 전자 장치."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 프로세서는,상기 메모리에 저장된 상기 사용자에 대응되는 적어도 하나의 레퍼런스 벡터 중 합성할 텍스트의 특성에 기초하여 산출된 점수가 가장 높은 레퍼런스 벡터를 획득하는 전자 장치.공개특허 10-2022-0064871-4-청구항 11 TTS 모델 및 복수의 평가용 텍스트가 저장된 메모리를 포함하는 전자 장치의 제어 방법에 있어서,사용자가 발화한 사용자 음성이 마이크로폰을 통해 수신되면, 상기 사용자 음성의 레퍼런스 벡터를 획득하는 단계; 상기 레퍼런스 벡터에 기초하여 복수의 후보 레퍼런스 벡터를 생성하는 단계;상기 복수의 후보 레퍼런스 벡터 및 상기 복수의 평가용 텍스트를 상기 TTS 모델에 입력하여, 복수의 합성음을획득하는 단계;상기 복수의 합성음 및 상기 사용자 음성 간의 유사도 및 상기 복수의 합성음의 특성에 기초하여, 상기 복수의합성음 중 적어도 하나의 합성음을 식별하는 단계; 및상기 적어도 하나의 합성음의 레퍼런스 벡터를 상기 TTS 모델을 위한 상기 사용자에 대응되는 레퍼런스 벡터로상기 메모리에 저장하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 복수의 후보 레퍼런스 벡터는, 상기 레퍼런스 벡터에 기초하여 랜덤하게 선택된 적어도 하나의 레퍼런스 벡터, 상기 레퍼런스 벡터 및 상기TTS 모델의 훈련에 이용된 레퍼런스 벡터에 기초하여 생성된 적어도 하나의 레퍼런스 벡터 및 마스킹 벡터를 상기 레퍼런스 벡터에 적용하여 생성된 적어도 하나의 레퍼런스 벡터를 포함하는, 제어 방법."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 복수의 합성음을 획득하는 단계는,상기 복수의 후보 레퍼런스 벡터 및 상기 복수의 평가용 텍스트를 상기 TTS 모델에 입력하여, 상기 복수의 후보레퍼런스 벡터 각각에 기초하여 상기 복수의 평가용 텍스트 각각에 대해 생성된 상기 복수의 합성음을획득하는, 제어 방법."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 적어도 하나의 합성음을 식별하는 단계는,상기 복수의 합성음 중 상기 사용자 음성과의 유사도가 기설정된 임계 값 이상인 후보 합성음을 식별하는 단계;및상기 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나에 기초하여, 상기 후보 합성음 중 상기 적어도 하나의 합성음을 식별하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 적어도 하나의 합성음을 식별하는 단계는,상기 후보 합성음 각각에 대한 운율 점수, 발음 점수 및 음질 점수를 산출하는 단계; 및상기 후보 합성음 중 상기 운율 점수, 발음 점수 및 음질 점수 각각이 기설정된 임계 값 이상인 상기 적어도 하나의 합성음을 식별하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,공개특허 10-2022-0064871-5-상기 복수의 평가용 텍스트는, 복수의 도메인 각각에 속한 적어도 하나의 평가용 텍스트를 포함하고,상기 적어도 하나의 합성음을 식별하는 단계는,상기 복수의 후보 합성음 각각이 속한 도메인에 기초하여, 상기 복수의 도메인에 따라 상기 복수의 후보 합성음을 구분하는 단계; 및 각 도메인에 속한 적어도 하나의 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나의 기초하여, 도메인별로 상기 적어도 하나의 합성음을 식별하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 식별된 적어도 하나의 합성음의 레퍼런스 벡터는 각 평가용 텍스트가 속한 도메인에 따라 상기 메모리에저장되는, 제어 방법."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 전자 장치는 스피커 및 디스플레이 중 적어도 하나를 포함하는 출력 인터페이스를 더 포함하고,상기 제어 방법은,상기 복수의 도메인 중 상기 적어도 하나의 합성음이 존재하지 않는 도메인을 판단하고, 상기 판단된 도메인에속한 적어도 하나의 후보 합성음에 대해 산출된 운율 점수, 발음 점수 및 음질 점수에 기초하여, 운율, 발음 및음질 중 상대적으로 낮은 점수가 산출된 합성음의 특성을 판단하는 단계; 및상기 판단된 특성에 기초하여 생성된 문장의 발화를 요청하는 정보를 출력하도록 상기 출력 인터페이스를 제어하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 전자 장치는, 스피커를 포함하고,상기 제어 방법은,상기 사용자의 후속 사용자 음성이 상기 마이크로폰을 통해 수신되면, 상기 후속 사용자 음성에 대한 응답을 위한 텍스트를 획득하는 단계;상기 획득된 텍스트 및 상기 메모리에 저장된 상기 사용자에 대응되는 적어도 하나의 레퍼런스 벡터 중 하나를상기 TTS 모델에 입력하여, 상기 레퍼런스 벡터에 기초하여 상기 텍스트에 대해 생성된 음성을 획득하는 단계;및상기 획득된 음성을 출력하도록 상기 스피커를 제어하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2021-0027665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 음성을 획득하는 단계는,상기 메모리에 저장된 상기 사용자에 대응되는 적어도 하나의 레퍼런스 벡터 중 합성할 텍스트의 특성에 기초하여 산출된 점수가 가장 높은 레퍼런스 벡터를 획득하는 단계를 포함하는, 제어 방법."}
{"patent_id": "10-2021-0027665", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에서는 전자 장치 및 그 제어 방법이 제공된다. 본 개시의 일 실시 예에 따른 전자 장치는 마이크로폰, TTS 모델 및 복수의 평가용 텍스트가 저장된 메모리 및 사용자가 발화한 사용자 음성이 마이크로폰을 통해 수신 되면, 사용자 음성의 레퍼런스 벡터를 획득하고, 레퍼런스 벡터에 기초하여 복수의 후보 레퍼런스 벡터를 생성하 (뒷면에 계속)"}
{"patent_id": "10-2021-0027665", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그의 제어 방법에 관한 것으로, 보다 상세하게는 TTS(Text to Speech) 서비스를 제공하 기 위한 전자 장치 및 그의 제어 방법에 관한 것이다."}
{"patent_id": "10-2021-0027665", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "TTS(Text to Speech)는 기계가 텍스트를 사람의 음성으로 합성(또는 변환)하는 음성 합성(speech synthesis) 기술을 말한다. TTS 서비스를 통해 목표 화자의 음성과 유사한 스타일(예: 높낮이, 강세, 전달 속도, 억양, 발음, 말하기 습관 등)의 음성을 제공하기 위해서는, 사전에 목표 화자가 발화하는 음성을 녹음하고, 녹음된 음성 데이터를 처리하 는 과정이 요구된다. 다양한 텍스트에 대해 목표 화자와 유사한 스타일의 자연스러운 음성을 구현하기 위해서는 적어도 200개 이상의 문장(또는 1시간 이상의 대본 등)의 목표 화자의 발화 음성에 기초하여 모델 적응, 전이 학습 등의 방법을 통한 모델 학습이 요구된다. 이와 같이 목표 화자의 음성을 TTS 서비스의 음성으로 등록하기 위해서는 목표 화자가 매우 많은 수의 문장을 긴 시간 동안 정확한 발음으로 발화해야 한다는 점에서, 일반 사용자의 음성을 TTS 서비스의 음성으로 제공하는 개인화된 TTS 서비스를 제공하기에는 어려움이 있다. 한편, 개인화 TTS를 제공하기 위하여 목표 화자의 음성으 로부터 레퍼런스 벡터를 획득하고, 텍스트 및 레퍼런스 벡터를 TTS 모델에 입력하여 목표 화자의 음성 특성을 가지는 합성음을 얻는 방법이 있다. 이 경우, 모델을 훈련(zero-shot/few-shot learning)하지 않을 수 있는 장 점이 있지만, 해당 레퍼런스 벡터가 최적의 성능(음질/운율/발음/화자 유사도 등)을 가지는지 알 수 없다는 단 점이 있다."}
{"patent_id": "10-2021-0027665", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은 일반 사용자의 목소리를 이용하여 TTS 서비스를 제공하기 위한 전자 장치 및 그의 제어 방법 을 제공함에 있다."}
{"patent_id": "10-2021-0027665", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 전자 장치는 마이크로폰, TTS 모델 및 복수의 평가용 텍스트가 저장된 메모리 및 사용자가 발화한 사용자 음성이 마이크로폰을 통해 수신되면, 사용자 음성의 레퍼런스 벡터를 획득하고, 레퍼런 스 벡터에 기초하여 복수의 후보 레퍼런스 벡터를 생성하고, 복수의 후보 레퍼런스 벡터 및 복수의 평가용 텍스 트를 TTS 모델에 입력하여, 복수의 합성음을 획득하고, 복수의 합성음 및 사용자 음성 간의 유사도 및 복수의 합성음의 특성에 기초하여, 복수의 합성음 중 적어도 하나의 합성음을 식별하고, 적어도 하나의 합성음의 레퍼 런스 벡터를 TTS 모델을 위한 사용자에 대응되는 레퍼런스 벡터로 메모리에 저장하는 프로세서를 포함할 수 있 다. 복수의 후보 레퍼런스 벡터는, 레퍼런스 벡터에 기초하여 랜덤하게 선택된 적어도 하나의 레퍼런스 벡터, 레퍼 런스 벡터 및 TTS 모델의 훈련에 이용된 레퍼런스 벡터에 기초하여 생성된 적어도 하나의 레퍼런스 벡터 및 마 스킹 벡터를 레퍼런스 벡터에 적용하여 생성된 적어도 하나의 레퍼런스 벡터를 포함할 수 있다. 프로세서는, 복수의 후보 레퍼런스 벡터 및 복수의 평가용 텍스트를 TTS 모델에 입력하여, 복수의 후보 레퍼런 스 벡터 각각에 기초하여 복수의 평가용 텍스트 각각에 대해 생성된 복수의 합성음을 획득할 수 있다. 프로세서는, 복수의 합성음 중 사용자 음성과의 유사도가 기설정된 임계 값 이상인 후보 합성음을 식별하고, 후 보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나에 기초하여, 후보 합성음 중 적어도 하나의 합성음을 식 별할 수 있다. 프로세서는, 후보 합성음 각각에 대한 운율 점수, 발음 점수 및 음질 점수를 산출하고, 후보 합성음 중 운율 점 수, 발음 점수 및 음질 점수 각각이 기설정된 임계 값 이상인 적어도 하나의 합성음을 식별할 수 있다. 복수의 평가용 텍스트는, 복수의 도메인 각각에 속한 적어도 하나의 평가용 텍스트를 포함하고, 프로세서는, 복 수의 후보 합성음 각각이 속한 도메인에 기초하여, 복수의 도메인에 따라 복수의 후보 합성음을 구분하고, 각 도메인에 속한 적어도 하나의 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나의 기초하여, 도메인 별로 적어도 하나의 합성음을 식별할 수 있다. 여기에서 식별된 적어도 하나의 합성음의 레퍼런스 벡터는 각 평가용 텍스트가 속한 도메인에 따라 메모리에 저 장될 수 있다.전자 장치는 스피커 및 디스플레이 중 적어도 하나를 포함하는 출력 인터페이스를 더 포함하고, 프로세서는 복 수의 도메인 중 적어도 하나의 합성음의 레퍼런스 벡터가 존재하지 않는 도메인을 판단하고, 상기 판단된 도메 인에 속한 적어도 하나의 후보 합성음에 대해 산출된 운율 점수, 발음 점수 및 음질 점수에 기초하여, 운율, 발 음 및 음질 중 상대적으로 낮은 점수가 산출된 합성음의 특성을 판단하며, 판단된 특성에 기초하여 생성된 문장 의 발화를 요청하는 음성을 스피커를 통해 출력할 수 있다. 전자 장치는 스피커를 더 포함하고, 프로세서는 사용자의 후속 사용자 음성이 마이크로폰을 통해 수신되면, 후 속 사용자 음성에 대한 응답을 위한 텍스트를 획득하고, 획득된 텍스트 및 메모리에 저장된 사용자에 대응되는 적어도 하나의 레퍼런스 벡터 중 하나를 TTS 모델에 입력하여, 레퍼런스 벡터에 기초하여 텍스트에 대해 생성된 음성을 획득하고, 획득된 음성을 출력하도록 스피커를 제어할 수 있다. 프로세서는, 메모리에 저장된 사용자에 대응되는 적어도 하나의 레퍼런스 벡터 중 합성할 텍스트의 특성에 기초 하여 산출된 점수가 가장 높은 레퍼런스 벡터를 획득할 수 있다. 본 개시의 일 실시 예에 따른, TTS 모델 및 복수의 평가용 텍스트가 저장된 메모리를 포함하는 전자 장치의 제 어 방법은 사용자가 발화한 사용자 음성이 마이크로폰을 통해 수신되면, 사용자 음성의 레퍼런스 벡터를 획득하 는 단계, 레퍼런스 벡터에 기초하여 복수의 후보 레퍼런스 벡터를 생성하는 단계, 복수의 후보 레퍼런스 벡터 및 복수의 평가용 텍스트를 TTS 모델에 입력하여, 복수의 합성음을 획득하는 단계, 복수의 합성음 및 사용자 음 성 간의 유사도 및 복수의 합성음의 특성에 기초하여, 복수의 합성음 중 적어도 하나의 합성음을 식별하는 단계 및 적어도 하나의 합성음의 레퍼런스 벡터를 TTS 모델을 위한 사용자에 대응되는 레퍼런스 벡터로 메모리에 저 장하는 단계를 포함할 수 있다. 복수의 후보 레퍼런스 벡터는, 레퍼런스 벡터에 기초하여 랜덤하게 선택된 적어도 하나의 레퍼런스 벡터, 레퍼 런스 벡터 및 TTS 모델의 훈련에 이용된 레퍼런스 벡터에 기초하여 생성된 적어도 하나의 레퍼런스 벡터 및 마 스킹 벡터를 레퍼런스 벡터에 적용하여 생성된 적어도 하나의 레퍼런스 벡터를 포함할 수 있다. 복수의 합성음을 획득하는 단계는, 복수의 후보 레퍼런스 벡터 및 복수의 평가용 텍스트를 TTS 모델에 입력하여, 복수의 후보 레퍼런스 벡터 각각에 기초하여 복수의 평가용 텍스트 각각에 대해 생성된 복수의 합성 음을 획득할 수 있다. 적어도 하나의 합성음을 식별하는 단계는, 복수의 합성음 중 사용자 음성과의 유사도가 기설정된 임계 값 이상 인 후보 합성음을 식별하는 단계 및 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나에 기초하여, 후보 합성음 중 적어도 하나의 합성음을 식별하는 단계를 포함할 수 있다. 적어도 하나의 합성음을 식별하는 단계는, 후보 합성음 각각에 대한 운율 점수, 발음 점수 및 음질 점수를 산출 하는 단계 및 후보 합성음 중 운율 점수, 발음 점수 및 음질 점수 각각이 기설정된 임계 값 이상인 적어도 하나 의 합성음을 식별하는 단계를 포함할 수 있다. 복수의 평가용 텍스트는, 복수의 도메인 각각에 속한 적어도 하나의 평가용 텍스트를 포함하고, 적어도 하나의 합성음을 식별하는 단계는, 복수의 후보 합성음 각각이 속한 도메인에 기초하여, 복수의 도메인에 따라 복수의 후보 합성음을 구분하는 단계 및 각 도메인에 속한 적어도 하나의 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나의 기초하여, 도메인 별로 적어도 하나의 합성음을 식별하는 단계를 포함할 수 있다. 여기에서 식별된 적어도 하나의 합성음의 레퍼런스 벡터는 각 평가용 텍스트가 속한 도메인에 따라 메모리에 저 장될 수 있다. 전자 장치는 스피커 및 디스플레이 중 적어도 하나를 포함하는 출력 인터페이스를 더 포함하고, 제어 방법은 복 수의 도메인 중 적어도 하나의 합성음이 존재하지 않는 도메인을 판단하는 단계, 판단된 도메인에 속한 적어도 하나의 후보 합성음에 대해 산출된 운율 점수, 발음 점수 및 음질 점수에 기초하여, 운율, 발음 및 음질 중 상 대적으로 낮은 점수가 산출된 합성음의 특성을 판단하는 단계 및 상기 판단된 도메인에 속하는 문장의 발화를 요청하는 정보를 출력하도록 출력 인터페이스를 제어하는 단계를 더 포함할 수 있다. 전자 장치는 스피커를 포함하고, 제어 방법은 사용자의 후속 사용자 음성이 마이크로폰을 통해 수신되면, 후속 사용자 음성에 대한 응답을 위한 텍스트를 획득하는 단계, 획득된 텍스트 및 메모리에 저장된 사용자에 대응되 는 적어도 하나의 레퍼런스 벡터 중 하나를 TTS 모델에 입력하여, 레퍼런스 벡터에 기초하여 텍스트에 대해 생 성된 음성을 획득하는 단계 및 획득된 음성을 출력하도록 스피커를 제어하는 단계를 포함할 수 있다. 음성을 획득하는 단계는, 메모리에 저장된 사용자에 대응되는 적어도 하나의 레퍼런스 벡터 중 합성할 텍스트의 특성에 기초하여 산출된 점수가 가장 높은 레퍼런스 벡터를 획득하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0027665", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시 예에 따르면, 일반 사용자의 목소리를 이용하여 TTS 서비스를 제공하기 위한 전자 장치 및 그의 제어 방법을 제공할 수 있다. 또한, 본 개시의 일 실시 예에 따르면 TTS 서비스의 목소리를 등록하기 위해 발화가 요구되는 문장의 수를 최소 화하면서 최적의 성능을 가지도록 시스템을 구성할 수 있다. 또한, 본 개시의 일 실시 예에 따르면 사용자마다 TTS 모델을 재훈련하지 않아도 사용자의 목소리를 통해 개인화된 TTS 서비스를 제공할 수 있다."}
{"patent_id": "10-2021-0027665", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그에 대한 상세한 설명은 생략한다. 덧붙여, 하기 실시 예는 여러 가지 다른 형 태로 변형될 수 있으며, 본 개시의 기술적 사상의 범위가 하기 실시 예에 한정되는 것은 아니다. 오히려, 이들 실시 예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본 개시의 기술적 사상을 완전하게 전달하기 위 하여 제공되는 것이다. 본 개시에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시의 실시 예의 다양한 변경 (modifications), 균등물(equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 상기 구성요소들을 한정하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \" 포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 상기 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메 모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 상기 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 도면이다. 도 1을 참조하면, 본 개시의 일 실시 예에 따른 전자 장치는 대화형 시스템으로 구현될 수 있다. 여기서, 전자 장치는 스마트폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전화기(mobile phone), 영상 전화기, 전자책 리더기(e-book reader), 데스크탑 PC(desktop personal computer), 랩탑 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 워크스테이션(workstation), 서버, PDA(personal digital assistant), PMP(portable multimedia player), MP3 플레이어, 모바일 의료기기, 카메라 (camera), 또는 웨어러블 장치(wearable device), 로봇 중 적어도 하나를 포함할 수 있다. 다양한 실시 예에 따 르면, 웨어러블 장치는 액세서리형(예: 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD)), 직물 또는 의류 일체형(예: 전자 의복), 신체 부착형(예: 스킨 패드(skin pad) 또는 문신), 또는 생체 이식형(예: implantable circuit) 중 적어도 하나로서 구현될 수 있다. 다만, 이는 일 실시 예일 뿐이며, 전자 장치는 이에 제한되지 아니하고 다양한 형태 및 다양한 용도를 갖는 전자 장치 로 구현될 수 있다. 대화형 시스템은 사용자 음성을 통해 사용자의 의도를 파악하고 사용자의 의도에 대응되는 응답을 출력하는 등 과 같이 대화를 통해 사용자와 상호작용할 수 있는 시스템을 말한다. 구체적인 일 실시 예로서, 전자 장치는 ASR 모듈, NLP 모듈, TTS 모듈을 포함할 수 있다. 또한, 전자 장치는 사용자 음성을 수신하기 위한 마이크로폰 및 사용자 음성에 응답하는 정보를 출력하기 위한 출력 인터페이스를 포함할 수 있다. 예를 들어, 출력 인터페이스는 소리를 출력하기 위한 스피 커를 포함할 수 있다. ASR(Automatic Speech Recognition) 모듈은 마이크로폰을 통해 수신된 음성 신호(즉, 사용자 음성)를 언어 모델(Language Model)과 음향 모델(Acoustic Model)을 이용하여 단어(word) 또는 음소(phoneme) 시퀀스 등의 텍스트(문자열)로 변환할 수 있다. 언어 모델은 단어 또는 음소 시퀀스에 확률을 할당하는 모델이고, 음향 모델은 음성 신호 및 음성 신호에 대한 텍스트 간의 관계를 나타내는 모델일 수 있다. 이들 모델은 확률 통계 또는 인공 신경망을 기반으로 구성될 수 있다. NLP(Natural Language Processing) 모듈은 사용자 음성에 대응되는 텍스트에 대해 형태소 분석 (morphological analysis), 구문 분석(syntactic analysis), 의미적 분석(semantic analyze) 등의 다양한 분석 방식을 이용하여 사용자 음성에 대응되는 텍스트를 구성하는 단어 또는 문장의 의미를 식별하고, 식별된 의미를 기초로 사용자의 의도를 파악하고, 이에 대응되는 응답 정보를 획득할 수 있다. 이때, 응답 정보는 텍스트 형태일 수 있다. TTS(Text to Speech) 모듈은 텍스트를 음성 신호로 변환하여 출력 인터페이스(예: 스피커)를 통해 출력 할 수 있다. 즉, NLP 모듈에서 획득되는 응답 정보는 TTS 모듈을 통해 텍스트 형태에서 음성 신호의 형태 로 변환될 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치는 개인화된 TTS 서비스를 제공할 수 있다. 개인화된 TTS 서 비스란 TTS 모듈을 통해 사용자 개인(또는 타 사용자)의 음성을 이용하여 텍스트를 음성 신호로 변환(또는 합성)하는 것을 말한다. 이를 위해, 사용자의 음성을 사전에 전자 장치에 등록하는 과정이 요구될 수 있다. 본 개시의 전자 장치는 TTS 서비스의 목소리를 등록하기 위해 사용자에 의해 발화가 요구되는 문장 의 수를 최소화할 수 있다. 또한, 본 개시의 일 실시 예에 따르면 사용자마다 TTS 모델을 재훈련하지 않아도 사 용자의 목소리를 통해 개인화된 TTS 서비스를 제공할 수 있다. 이에 대한 구체적인 내용은 첨부된 도면을 참조 하여 설명하도록 한다. 도 2 및 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 구성별 동작을 설명하기 위한 블록도이다. 도 3은 적 어도 하나의 평가용 텍스트의 평가 기준을 만족하는 레퍼런스 벡터가 존재하지 않는 경우의 동작을 나타낸다. 도 2를 참조하면, 본 개시의 일 실시 예에 따른 전자 장치는 마이크로폰, 메모리 및 프로세서 를 포함할 수 있다. 마이크로폰은 사용자 음성을 수신할 수 있다. 메모리는 복수의 평가용 텍스트를 저장할 수 있다. 예를 들어, 복수의 평가용 텍스트는 메모리 내에 평가용 텍스트 데이터베이스에 저장될 수 있다. 평가용 텍스트의 단위는 하나의 문장일 수 있으나 이는 일 실시 예일 뿐이며, 평가용 텍스트의 단위는 다양하게 변형될 수 있다. 또한, 메모리는 TTS 모델의 화자로 등록된 사용자의 레퍼런스 벡터를 저장할 수 있다. 등록된 사용자 의 레퍼런스 벡터는 메모리 내에 레퍼런스 벡터 저장 모듈에 저장될 수 있다. 등록된 사용자의 레퍼 런스 벡터는 등록된 사용자의 고유한 음성 특징에 가장 부합하는 레퍼런스 벡터를 나타낼 수 있다. 프로세서는 사용자의 음성으로 텍스트를 합성하기 위해 사용자의 음성으로부터 최적의 레퍼런스 벡터를 추 출하여 사용자의 레퍼런스 벡터로 등록할 수 있다. 이를 위해, 프로세서는 화자 인코더 모듈, 후보 레퍼런스 벡터 생성 모듈, TTS 모델, 합성음 평가 모듈 각각에 포함된 인스트럭션을 실행함으로써 각 인스트럭션에 해당하는 동작을 수행할 수 있다. 여 기서, 화자 인코더 모듈, 후보 레퍼런스 벡터 생성 모듈, TTS 모델, 합성음 평가 모듈는 메모 리에 저장되거나, 또는 프로세서 내부의 메모리에 저장되어 있을 수 있다. 구체적으로, 프로세서는 사용자 A가 발화한 사용자 음성이 마이크로폰을 통해 수신되면, 화자 인코더 모듈을 통해 수신된 사용자 음성으로부터 사용자 음성의 레퍼런스 벡터를 획득할 수 있다. 예를 들어, 프로세서는 TTS 모델의 사용자 등록을 위한 사용자A의 요청(예: 사용자 A의 터치 입력, 음 성 명령 등의 형태)이 수신되면, 프로세서는 사용자 A가 발화하도록 기설정된 레퍼런스 텍스트(Reference text, r)를 제공할 수 있다. 이후, 프로세서는 사용자 A가 발화한 사용자 음성이 마이크로폰을 통해 수신되면, 화자 인코더 모듈을 통해 수신된 사용자 음성으로부터 레퍼런스 벡터를 획득할 수 있다. 다만, 이는 일 실시 예일 뿐, 기설정된 레퍼런스 텍스트에 대한 제공 없이 사용자 A가 자연어를 발화하면 해당 자연어 를 레퍼런스 텍스트로 인식하는 것 또한 가능하다. 여기서, 레퍼런스 벡터(Reference vector; RV, )는 레퍼런스 텍스트(Reference text, r)를 발화한 사용자 A(화자 A)의 사용자 음성( )에서 나타나는 음성 특징을 다차원(즉, 2이상)의 벡터(또는 벡터열)로 정의한 것 을 말한다. 레퍼런스 벡터의 각 차원(또는 열)은 운율, 발음, 주파수 대역, 화자의 나이, 화자의 성별 등의 음 성 특징을 나타낼 수 있다. 레퍼런스 텍스트는 사용자가 발화하는 문장(또는 단어 등)을 말하며, 발화하는 방식 에 따른 도메인(예: 낭독체, 대화체, 뉴스체 등)이 할당될 수 있다. 도 5를 참조하여, 마이크로폰에서 수신된 아날로그 형태의 음향 신호는 ADC(Analog-to-Digital Converter)를 통해 디지털 형태의 음향 신호로 변환될 수 있다. 여기서 음향 신호에는 레퍼런스 텍스트(r)를 발 화한 사용자 A의 사용자 음성( )이 포함될 수 있다. 한편, ADC는 마이크로폰 또는 프로세서에 내장된 형태로 구현되거나, 별도의 장치로 구현되는 등 다양한 변형 실시 예가 가능하다. 이 경우, 프로세서는 에너지 레벨에 기초하여 음향 신호에서 사용자 음성( )에 해당하는 구간의 음향 신 호를 식별할 수 있다. 그리고, 프로세서는 사용자 음성( )에 해당하는 구간의 음향 신호를 프레임(예: 20ms, 40ms 등) 단위로 구분하고, 각 프레임에 푸리에 변환(Fourier Transform)을 적용하여 스펙트럼을 산출할 수 있다. 여기서, 음향 신호는 시간에 따른 진폭(또는 음압)과 같은 시간 영역(time domain)으로 표현되는 파형(waveform)을 나타내며, 스펙트럼(spectrum)은 주파수에 따른 진폭(또는 음압)과 같은 주파수 영역(frequency domain)으로 표현되는 파 형일 수 있다. 예를 들어, 음향 신호는 가로축이 시간이고 세로축이 진폭인 관계로 파형을 나타내며, 스펙트럼 은 가로축이 주파수이고 세로축이 진폭인 관계로 파형을 나타낼 수 있다. 이때, 스펙트럼은 일반적인 주파수 영 역의 스펙트럼이거나, 사람이 민감하게 인식하는 주파수의 관계를 나타내는 멜 스케일(Mel Scale)에 기반한 필 터 뱅크(Filter Bank)를 스펙트럼에 적용한 멜 스펙트럼(Mel Spectrum), 주파수 축 및 진폭 축의 관계를 갖는 스펙트로그램(spectrogram; SPG) 등의 다양한 종류의 스펙트럼일 수 있다. 또한, 스펙트럼은 스펙트럼으로부터 변형될 수 있는 캡스트럼(cepstrum)이나, 멜 캡스트럼(Mel Cepstrum)일 수 있고, 음높이/하모닉 정보를 가지는 pitch lag 나 pitch correlation을 포함할 수 있다. 다만, 이는 일 실시 예일 뿐이며, 스펙트럼은 음성의 특징 을 가지는 다양한 음향 특징벡터일 수 있다. 그리고, 프로세서는 스펙트럼에서 레퍼런스 벡터를 획득할 수 있다. 일 실시 예로서, 프로세서는 레 퍼런스 벡터는 멜 스펙트럼을 화자 인식기에 입력하여 레퍼런스 벡터( )를 획득할 수 있다. 다만, 이는 일 실 시 예일 뿐, 프로세서는 켑스트럼(Cepstrum), 선형 예측 코딩(Linear Predictive Coefficient, LPC) 및 필터 뱅크 에너지(Filter Bank Energy), Wav2Vec, SincNet, PASE 등의 다양한 알고리즘(또는 뉴럴 네트워크) 중 하나를 사용하여 레퍼런스 벡터( )를 획득할 수 있다. 이때, 획득되는 레퍼런스 벡터( )는 i-vector, d-vector, x-vector 등 다양한 형태의 벡터일 수 있다. 한편, 화자 인코더 모듈을 통해 레퍼런스 벡터를 획득하는 구체적인 방법에 대해서는 도 5와 함께 후술하여 설명하도록 한다. 그리고, 프로세서는 후보 레퍼런스 벡터 생성 모듈을 통해, 레퍼런스 벡터( )에 기초하여 복수의 후보 레퍼런스 벡터( )를 생성할 수 있다. 여기에서, 복수의 후보 레퍼런스 벡터는, 제1 실시 예로서 레퍼런스 벡터에 기초하여 랜덤하게 선택된 레퍼런스 벡터, 제2 실시 예로서 레퍼런스 벡터 및 TTS 모델의 훈련에 이용된 레퍼런스 벡터에 기초하여 생성된 레퍼 런스 벡터, 및 제3 실시 예로서 마스킹 벡터를 레퍼런스 벡터에 적용하여 생성된 레퍼런스 벡터 중 하나 또는 이들의 조합을 포함할 수 있다. 구체적인 내용은 도 6a 내지 도 6c를 참조하여 설명하도록 한다. 도 6a 내지 도 6c는 본 개시의 일 실시 예에 따른 후보 레퍼런스 벡터를 생성하는 방법을 설명하기 위한 도면이 다. 도 6a 내지 도 6c은 평면(610, 620, 630) 상에 레퍼런스 벡터를 표현한 것이며, 평면(610, 620, 630) 상에 레퍼런스 벡터의 위치가 가까울수록 레퍼런스 벡터의 특성은 유사한 것을 의미한다. 도 6a를 참조하여, 본 개시의 제1 실시 예로서, 복수의 후보 레퍼런스 벡터( )는 레퍼런스 벡터 ( )에 기초하여 랜덤하게 선택된 적어도 하나의 레퍼런스 벡터를 포함할 수 있다. 예를 들어, 프로세서는 다음의 수학식 1에 따라 레퍼런스 벡터( )에 노이즈를 합산하여 적어도 하 나의 후보 레퍼런스 벡터( )를 생성할 수 있다. [수학식 1]"}
{"patent_id": "10-2021-0027665", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 노이즈는 정규 분포(Normal distribution) 또는 연속균등 분포 (Uniform distribution) 또는 다양한 확률 분포를 따르는 랜덤한 값이며, 레퍼런스 벡터( )의 차원 중 적어도 하나의 차원에 대한 값일 수 있다. 또한, 노이즈는 기설정된 범위 이내의 값을 가질 수 있다. 이 경우, 도 6a에서와 같이 후보 레퍼런스 벡터 ( )는 레퍼런스 벡터( )를 기준으로 기설정된 반경 이내에 존재하는 벡터가 될 수 있다. 한편 도 6b를 참조하여, 본 개시의 제2 실시 예로서, 복수의 후보 레퍼런스 벡터( )는 레퍼런스 벡터 ( ) 및 TTS 모델의 훈련에 이용된 레퍼런스 벡터에 기초하여 생성된 적어도 하나의 레퍼런스 벡터 를 포함할 수 있다. 예를 들어, 프로세서는 레퍼런스 벡터( ) 및 TTS 모델의 훈련에 이용된 복수의 화자의 레퍼런스 벡 터(예: 화자 B의 레퍼런스 벡터 , 화자 C의 레퍼런스 벡터 등) 간의 거리를 비교하여, 복수의 화자의 레 퍼런스 벡터 중에서 거리가 가장 근접한 하나의 레퍼런스 벡터(예: 화자 B의 레퍼런스 벡터 )를 식별할 수 있다. 그리고, 프로세서는 다음의 수학식 2에 따라 레퍼런스 벡터( ) 및 TTS 모델의 훈련에 이용된 레퍼 런스 벡터 중 거리가 가장 근접한 레퍼런스 벡터(예: 화자 B의 레퍼런스 벡터 )에 대해 보간법 (Interpolation)을 적용하여 적어도 하나의 후보 레퍼런스 벡터( )를 생성할 수 있다. [수학식 2]"}
{"patent_id": "10-2021-0027665", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 및 는 두 레퍼런스 벡터( )를 지나는 함수(예: 1차 함수, 2차 함수 등) 상에 후보 레퍼런 스 벡터( )가 위치하도록 하는 임의의 계수를 나타낸다. 예를 들어, 1차 함수인 경우 는 0.9 및 는 0.1, 는 0.8 및 는 0.2, 는 0.7 및 는 0.3 등이 적용될 수 있다. 한편 본 개시의 제3 실시 예로서, 복수의 후보 레퍼런스 벡터( )는 마스킹 벡터를 레퍼런스 벡터( )에 적 용하여 생성된 적어도 하나의 레퍼런스 벡터를 포함할 수 있다. 예를 들어, 프로세서는 다음의 수학식 3에 따라 마스킹 벡터(W)를 레퍼런스 벡터( )에 적용하여 적어도 하나의 후보 레퍼런스 벡터( )를 생성할 수 있다. [수학식 3]"}
{"patent_id": "10-2021-0027665", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, W는 마스킹 벡터이며, 0 또는 1, 또는 0 내지 1 사이의 값,또는 다양한 값을 갖는 행렬로 구성될 수 있 다. 한편, 본 개시의 일 실시 예에 따른 복수의 후보 레퍼런스 벡터( )는 제1 내지 제3 실시 예들의 적어도 하나 의 조합일 수 있다. 즉, 복수의 후보 레퍼런스 벡터( )는 레퍼런스 벡터( )에 기초하여 랜덤하게 선택된 적어도 하나의 레퍼런스 벡터, 레퍼런스 벡터( ) 및 TTS 모델의 훈련에 이용된 레퍼런스 벡터에 기초하여 생성된 적어도 하나의 레퍼런스 벡터 및 마스킹 벡터를 레퍼런스 벡터( )에 적용하여 생성된 적어도 하나의 레퍼런스 벡터 중에서 적어도 하나를 포함할 수 있다. 예를 들어, 제1 실시 예 및 제2 실시 예의 조합은 도 6c 와 같이 나타날 수 있다. 그리고, 프로세서는 복수의 후보 레퍼런스 벡터( ) 및 메모리에 저장된 복수의 평 가용 텍스트( )를 TTS 모델에 입력하여, 복수의 합성음( )을 획득할 수 있다. 구체적으로, 프로세서는 복수의 후보 레퍼런스 벡터( ) 및 복수의 평가용 텍스트 ( )를 TTS 모델에 입력하여, 복수의 후보 레퍼런스 벡터 각각( )에 기초하여 복수의 평가용 텍스트 각각( )에 대해 생성된 복수의 합성음( )을 획득할 수 있다. 여기서, 생성 되는 합성음 은 후보 레퍼런스 벡터 및 평가용 텍스트 를 합성하여 생성된 것을 나타낸다. 이때, 후 보 레퍼런스 벡터의 수가 N개이고, 평가용 텍스트의 수가 M개인 경우, 생성되는 합성음의 수는 N x M개 일 수 있다. 여기서, 복수의 평가용 텍스트( )는 복수의 도메인(예: 낭독체, 대화체, 뉴스체 등) 각각에 속한 적어도 하나의 평가용 텍스트를 포함할 수 있다. 즉, 복수의 평가용 텍스트( ) 각각에는 도메인이 기할당되어 있을 수 있다. 예를 들어, 도메인은 텍스트의 스타일에 따라 낭독체, 대화체, 의문문, 감탄문 등의 종류를 포함할 수 있으며, 텍스트의 컨텐츠에 따라 챗봇, NLG(Natural Language Generation), 뉴스, 사전, Wiki, 음악(노래제목, 가수, 가사 등), 가전제품(예를 들어 에어컨), Bigdata(웹 크롤링 내용), 동화책, 소설책 등의 종류를 포함할 수 있다. 다만, 이는 일 실시 예일 뿐이며, 도메인은 이에 제한되지 아니하고 다양한 실시 예로 변형될 수 있다. 일 실시 예로서, TTS(Text to Speech) 모델은 음향 모델(acoustic model; AM) 및 보코더(vocoder; Voice Decoder)를 포함할 수 있다. 한편, TTS 모델에 대한 구체적인 설명은 도 7과 함께 후술하여 설명하도록 한 다. 음향 모델은 Tacotron, Tacotron 2, Transformer, text2mel, DCTTS(Deep Convolutional TTS) 등의 다양한 알고 리즘 중 적어도 하나를 이용하여 텍스트 및 레퍼런스 벡터를 음향 특징(acoustic feature)으로 변환할 수 있다. 이 때, 생성되는 음향 특징은 레퍼런스 벡터, 즉 해당 화자의 특징(예: 음색, 음의 높이, 세기, 발음 등)을 가 질 수 있다. 여기서, 음향 특징은 음성 구간(예: 프레임 단위, 또는 문장 단위)에서의 소리의 고유한 특징(예: 음색, 음의 높이, 세기, 발음 등)을 나타낼 수 있다. 예를 들어 음향 특징은 파형(waveform)과 스펙트럼 (spectrum)이 조합되는 스펙트로그램 (Spectrogram), 멜 스펙트로그램(Mel-spectrogram), Cepstrum, pitch lag, pitch correlation, MCME(Mel-frequency Cepstrum Modualtion Energy), MFCC(Mel frequency cepstral coefficient) 등의 형식 중 하나 또는 이들의 조합으로 구현될 수 있다. 보코더는 WaveNet, Parallel Wavenet, WaveGlow, WaveRNN, LPCNet 등의 다양한 알고리즘을 통해 레퍼런스 벡터 및 음향 특징을 합성하여 합성음을 생성할 수 있다. 예를 들어, 보코더는 멜 스펙트럼 등의 음향 특징 및 레퍼 런스 벡터를 입력하면 합성음을 출력하도록 학습된 뉴럴 네트워크 기반의 인공 지능 모델일 수 있다. 그리고, 프로세서는 합성음 평가 모듈을 통해, 복수의 합성음( ) 및 사용자 음성 간의 유 사도 및 복수의 합성음( )의 특성에 기초하여, 복수의 합성음( ) 중 적어도 하나의 합성 음을 식별할 수 있다. 구체적으로, 프로세서는 복수의 합성음( ) 중 사용자 음성( )과의 유사도(즉, 화자 유사도) 가 기설정된 임계 값 이상인 후보 합성음을 식별할 수 있다. 이에 대한 구체적인 내용은 도 8a 및 도 8b를 참조 하여 설명하도록 한다. 그리고, 프로세서는 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나에 기 초하여, 후보 합성음 중 적어도 하나의 합성음을 식별할 수 있다. 이에 대한 구체적인 내용은 도 8c 및 도 8d를 참조하여 설명하도록 한다. 도 8a 내지 8d는 본 개시의 일 실시 예에 따른 합성음을 식별하는 방법을 설명하기 위한 도면이다. 도 8a를 참조하여, 일 실시 예로서 프로세서는 복수의 합성음( ) 각각을 화자 인코더 모듈(1 0)에 입력하면, 화자 인코더 모듈로부터 각각 출력된 복수의 합성음( )에 대한 레퍼런스 벡터 ( )를 획득할 수 있다. 그리고, 프로세서는 복수의 합성음( )에 대한 레퍼런스 벡 터 각각( )을 사용자 음성( )에 대한 레퍼런스 벡터( )와 비교하여 유사도를 판단할 수 있다. 여기서, 사용자 음성( )에 대한 레퍼런스 벡터( )는 화자 인코더 모듈에 사용자 음성( )을 입력하 면, 화자 인코더 모듈로부터 출력되어 획득된 것이다.여기서, 유사도는 유클리드 거리, 코사인 유사도 방식 등의 다양한 방식을 통해 산출될 수 있다. 또한, 레퍼런 스 벡터 간의 유사도는 합성음 간의 화자 유사도로 간주될 수 있다. 즉, 프로세서는 복수의 합성음 ( )에 대한 레퍼런스 벡터( ) 중에서 유사도가 기설정된 임계 값 이상인 레퍼런스 벡터 를 갖는 합성음을 후보 합성음으로 식별할 수 있다. 한편, 복수의 합성음( )은 복수의 합성음( )을 생성하는데 이용된 후보 레퍼런스 벡터 ( ) 단위의 그룹으로 분류될 수 있다. 예를 들어, 제1 후보 레퍼런스 벡터 및 제1 내지 제M 평 가용 텍스트 를 통해 생성된 합성음 )은 동일한 그룹으로 분류될 수 있다. 즉, 1개의 후보 레퍼런스 벡터 및 M개의 평가용 텍스트를 통해 생성된 합성음은 동일한 그룹으로 분류될 수 있다. 이 경우, 프로세서는 복수의 합성음( )에 대한 레퍼런스 벡터( )를 그룹 단위로 레 퍼런스 벡터의 편차(또는 분포도)를 판단할 수 있다. 그리고, 프로세서는 편차가 가장 작은 그룹의 레퍼런 스 벡터를 식별할 수 있다. 이 경우, 프로세서(130는 편차가 가장 작은 그룹의 레퍼런스 벡터를 통해 합성된 합 성음을 후보 합성음으로 식별할 수 있다. 예를 들어, 제1 후보 레퍼런스 벡터 및 제1 내지 제M 평가용 텍스트 를 통해 생성된 합성음 )은 제1 그룹( )으로 분류되고, 제2 후보 레퍼런스 벡터 및 제1 내지 제M 평가용 텍스트 를 통해 생성된 합성음 )은 제2 그룹( )으로 분류되고, 제3 후보 레퍼런스 벡터 및 제1 내지 제M 평가용 텍스트 를 통해 생성된 합성음 )은 제3 그룹( )으로 분류된 경우에, 제1 내지 제3 그룹이 도 8a의 평면과 같이 위치한 경우를 가정할 수 있다. 이 경우, 프로 세서는 사용자 음성( )에 대한 레퍼런스 벡터( )을 기준으로 편차가 가장 작은 제3 그룹( )의 레 퍼런스 벡터 를 식별할 수 있다. 이 경우, 프로세서는 제3 그룹( )의 레퍼런스 벡터 를 통해 합성된 합성음 )을 후보 합성음으로 식별할 수 있다. 한편, 도 8b와 같이 본 개시의 일 실시 예에 따른 프로세서는 복수의 화자 인코더 모듈(10-1 내지 10-3)을 이용하여 후보 합성음을 식별할 수 있다. 예를 들어, 제1 내지 제3 화자 인코더 모듈(10-1 내지 10-3)은 서로 다른 종류의 레퍼런스 벡터(예: i-vector, d-vector, x-vector 등)을 출력하도록 모델링된 것일 수 있다. 프로세서는 복수의 합성음( ) 및 사용자 음성( )을 제1 화자 인코더 모듈(10-1)에 입력하면, 제1 화자 인코더 모듈(10-1)로부터 출력된 복수의 합성음( )에 대한 제1 레퍼런스 벡터 ( ) 및 사용자 음성( )에 대한 제1 레퍼런스 벡터( )를 획득하고, 이들을 비교하여 제1 유사도 를 판단할 수 있다. 또한, 프로세서는 복수의 합성음 ( ) 및 사용자 음성( )을 제2 화자 인코더 모듈(10-2)에 입력하면, 제2 화자 인코더 모듈(10-2)로부터 출력된 복수의 합성음 ( )에 대한 제2 레퍼런스 벡터 ( ) 및 사용자 음성( )에 대한 제2 레퍼런스 벡터( )를 획득하고, 이들을 비교하여 제2 유사도를 판단할 수 있다. 또한, 프로세서는 복수의 합성음 ( ) 및 사용자 음성( )을 제3 화자 인코더 모듈(10-3)에 입력하면, 제3 화자 인코더 모듈(10-3)로부터 출력된 복수의 합성음 ( )에 대한 제3 레퍼런스 벡터 ( ) 및 사용자 음성( )에 대한 제3 레퍼런스 벡터( )를 획득하고, 이들을 비교하여 제3 유사도 를 판단할 수 있다. 그리고, 프로세서는 제1 내지 제3 유사도 중에서 가장 성능이 뛰어난 레퍼런스 벡터를 식별하고, 식별된 레퍼런스 벡터를 통해 합성된 합성음을 후보 합성음으로 식별할 수 있다. 가장 성능이 뛰어난 레퍼런스 벡터는 편차 값이 가장 작은 벡터이거나, 제1 내지 제3 유사도 각각에 대해 기설정된 임계 값을 초과하는 벡터일 수 있 다. 그리고, 프로세서는 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나에 기초하여, 후보 합성음 중 적어도 하나의 합성음을 식별할 수 있다. 즉, 프로세서는 후보 합성음 각각의 운율, 발음 및 음질 중 하나 또는 이들의 조합을 통해 합성음을 식별할 수 있다. 구체적으로, 프로세서는, 후보 합성음 각각에 대한 운율 점수, 발음 점수 및 음질 점수를 산출하고, 후보 합성음 중 운율 점수, 발음 점수 및 음질 점수 각각이 기설정된 임계 값 이상인 적어도 하나의 합성음을 식별할 수 있다. 일 예로서, 프로세서는 후보 합성음 각각에 대한 운율 점수를 산출하고, 운율 점수가 기설정된 임계 값 이 상인 적어도 하나의 합성음을 식별할 수 있다. 예를 들어, 프로세서는 평가용 텍스트 에 기설정된 음소 별 길이, 발화 속도, 시간에 따른 피치를 나타내는 피치 컨투어(pitch contour)와 평가용 텍스트 에 대응되 는 후보 합성음 의 음소별 길이, 발화 속도, 피치 컨투어를 비교하여 운율 점수를 산출할 수 있다. 일 예로서, 프로세서는 후보 합성음 각각에 대한 발음 점수를 산출하고, 발음 점수가 기설정된 임계 값 이 상인 적어도 하나의 합성음을 식별할 수 있다. 도 8c의 과 같이, 본 개시의 일 실시 예에 따른 프로세서는 합성음 을 ASR 모듈에 입력하여 텍 스트를 획득하고, 합성음 에 대응되는 평가용 텍스트 를 기준으로 획득된 텍스트가 일치하는 정도를 비교 하여 발음 점수를 산출할 수 있다. ASR 모듈은 전술한 바와 같이 다양한 알고리즘을 이용하여 음성을 분석하 여 음성의 내용을 텍스트의 형식으로 변환할 수 있다. 도 8c의 와 같이, 본 개시의 일 실시 예에 따른, 프로세서는 합성음 을 강제 정렬(Forced Alignment) 모듈에 입력하여 음성-음소, 음성-단어의 경계를 식별하고, 식별된 경계를 합성음 에 대응 되는 평가용 텍스트 에서의 음성-음소, 음성-단어의 경계와 비교하여 우도(Likelihood)를 산출할 수 있다. 이때, 우도는 발음 점수로서 활용될 수 있다. 일 실시 예로서, 프로세서는 후보 합성음 각각에 대한 음질 점수를 산출하고, 음질 점수가 기설정된 임계 값 이상인 적어도 하나의 합성음을 식별할 수 있다. 예를 들어, 프로세서는 SNR(Signal-to-Noise Ratio), HNR(Harmonic-to-Noise Ratio), Room 특성 추정을 통한 음질평가 등의 다양한 알고리즘을 통해 합성음 에 대한 음질 점수를 산출할 수 있다. 한편, 프로세서는 복수의 후보 합성음 각각이 속한 도메인(즉, 해당 합성음 생성에 이용되는 평가용 텍스 트의 도메인)에 기초하여, 복수의 도메인에 따라 복수의 후보 합성음을 구분할 수 있다. 프로세서는 각 도 메인에 속한 적어도 하나의 후보 합성음 각각의 유사도, 운율, 발음 및 음질 중 적어도 하나의 기초하여, 도메 인 별로 적어도 하나의 합성음을 식별할 수 있다. 구체적으로 도 8d를 참조하여, 합성음 평가 모듈에서 복수의 합성음( ) 및 사용자 음성 간의 유 사도 및 복수의 합성음( )의 특성에 기초하여 최적의 레퍼런스 벡터를 선정하는 일 실시 예에 대해 설명하도록 한다. 도 8d의 내지 의 표에서 각 행은 각각의 도메인이 부여된 평가용 텍스트 ( )를 나타내며, 각 열은 후보 레퍼런스 벡터 를 나타낸다. 각 행과 열의 조합은 평가용 텍스트 및 후보 레퍼 런스 벡터의 조합에 따라 생성되는 합성음의 점수(화자 유사도, 운율 점수, 발음 점수, 음질 점수 등)을 나타낸 다.일 실시 예로서, 도 8d의 과 같이 1개의 후보 레퍼런스 벡터 및 복수의 평가용 텍스트가 조합된 복수의 합성 음의 화자 유사도(즉, 동일한 열의 값)가 모두 기설정된 값(예: 60점) 이상이면 해당 후보 레퍼런스 벡터는 화 자 유사도에 대한 평가 기준을 만족한 것으로 판단하고, 화자 유사도가 하나라도 기설정된 값(예: 60점) 미만이 면 해당 후보 레퍼런스 벡터는 화자 유사도에 대한 평가 기준을 불만족한 것으로 판단할 수 있다. 일 실시 예로서, 도 8d의 과 같이 1개의 후보 레퍼런스 벡터 및 복수의 평가용 텍스트가 조합된 복수의 합성 음의 운율 점수가 하나라도 기설정된 값(예: 80점) 이상이면 해당 후보 레퍼런스 벡터는 운율 점수에 대한 평가 기준을 만족한 것으로 판단하고, 복수의 합성음의 운율 점수가 모두 기설정된 값(예: 80점) 미만이면 해당 후보 레퍼런스 벡터는 운율 점수에 대한 평가 기준을 불만족한 것으로 판단할 수 있다. 일 실시 예로서, 도 8d의 과 같이 1개의 후보 레퍼런스 벡터 및 복수의 평가용 텍스트가 조합된 복수의 합성 음의 발음 점수가 하나라도 기설정된 값(예: 90점) 이상이면 해당 후보 레퍼런스 벡터는 발음 점수에 대한 평가 기준을 만족한 것으로 판단하고, 복수의 합성음의 발음 점수가 모두 기설정된 값(예: 90점) 미만이면 해당 후보 레퍼런스 벡터는 발음 점수에 대한 평가 기준을 불만족한 것으로 판단할 수 있다. 일 실시 예로서, 도 8d의 와 같이 1개의 후보 레퍼런스 벡터 및 복수의 평가용 텍스트가 조합된 복수의 합성 음의 음질 점수(즉, 동일한 열의 값)가 모두 기설정된 값(예: 80점) 이상이면 해당 후보 레퍼런스 벡터는 음질 점수에 대한 평가 기준을 만족한 것으로 판단하고, 음질 점수가 하나라도 기설정된 값(예: 90점) 미만이면 해당 후보 레퍼런스 벡터는 음질 점수에 대한 평가 기준을 불만족한 것으로 판단할 수 있다. 그리고, 프로세서는 식별된 적어도 하나의 합성음의 레퍼런스 벡터( )를 TTS 모델을 위한 사 용자 A에 대응되는 레퍼런스 벡터( 로 메모리에 저장할 수 있다. 즉, 복수의 후보 레퍼런 스 벡터 중에서 평가 기준을 만족하는 레퍼런스 벡터를 사용자 A의 레퍼런스 벡터로 등록하여 메모리의 레 퍼런스 벡터 저장 모듈에 저장할 수 있다. 이와 같이, 본 개시의 일 실시 예에 따른 전자 장치는 동일한 사용자의 레퍼런스 벡터는 일정 범위 내의 분포를 갖는다는 점을 이용하여, 사용자가 매우 적은 수(예: 1 내지 5개 등)의 텍스트를 발화하더라도 이를 통 해 획득되는 레퍼런스 벡터만으로 다양한 텍스트에 최적화된 레퍼런스 벡터를 구할 수 있다. 즉 기존과 달리, 합성음 평가를 통해 좋은 성능을 보장할 수 있고, 사용자가 한 번만 발화하더라도 그로부터 복수 개의 레퍼런스 벡터를 획득할 수 있다. 개인화된 TTS 서비스를 제공하기 위해 발화하는 텍스트의 수가 매우 적다는 점에서 개 인화된 TTS 서비스를 등록하는 사용자의 편의성을 향상시킬 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치는 사용자 A의 레퍼런스 벡터로 등록하는 과정에서 사용자 A 가 발화한 사용자 음성만으로 개인화된 TTS 서비스를 제공하기가 충분하지 않은 경우에 사용자 A에게 피드백을 제공할 수 있다. 도 8d를 예로 들면, 모든 평가용 텍스트에 대해 기설정된 값(예: 60점) 이상의 화자 유사도를 만족하는 후보 합 성음의 레퍼런스 벡터는 이며, 적어도 하나의 평가용 텍스트에 대해 기설정된 값(예: 80점) 이상의 운 율 점수를 만족하는 후보 합성음의 레퍼런스 벡터는 이며, 적어도 하나의 평가용 텍스트에 대해 기설정된 값(예: 90점) 이상의 발음 점수를 만족하는 후보 합성음의 레퍼런스 벡터는 이며, 모든 평가용 텍스트에 대해 기설정된 값(예: 80점) 이상의 음질 점수를 만족하는 합성음의 후보 레퍼런스 벡터는 으로 식별될 수 있다. 이 경우, 프로세서는 합성음 평가 모듈을 통해 모든 평가 기준을 만족하는 식별된 후보 합성음의 레퍼 런스 벡터( )를 사용자 A에 대응되는 레퍼런스 벡터로 메모리의 레퍼런스 벡터 저장 모듈에 저장할 수 있다. 그리고, 프로세서는 복수의 후보 합성음 각각이 속한 도메인에 기초하여, 복수의 도메인에 따라 복수의 후 보 합성음을 구분할 수 있다. 여기서, 후보 합성음( , , )은 레퍼런스 벡터( ) 및 복수의 평가용 텍스트( )의 조합을 통해 생성된 것이며, 후보 합성음( , , )이 속 한 도메인은 후보 합성음의 생성에 이용되는 평가용 텍스트( )에 부여된 도메인일 수 있다. 그리고, 프로세서는 각 도메인에 속한 적어도 하나의 후보 합성음 각각의 화자 유사도, 운율, 발음 및 음 질 중 적어도 하나의 기초하여, 도메인 별로 적어도 하나의 합성음을 식별할 수 있다. 그리고, 여기에서 식별된 적어도 하나의 합성음의 레퍼런스 벡터는 각 평가용 텍스트가 속한 도메인에 따라 메모리에 저장될 수 있 다. 구체적으로, 프로세서는 특정한 도메인에 대해 평가 기준(예: 화자 유사도, 운율, 발음 및 음질 중 적어도 하나)을 만족하는 합성음이 존재하는지 여부를 판단할 수 있다. 예를 들어, 도 8d와 같이 프로세서는 평가용 텍스트 및 레퍼런스 벡터 의 조합에 따라 생성된 후보 합성음은 운율 점수 및 발음 점수가 기설정된 값을 만족하는 후보 합성음으로 식별할 수 있다. 또한, 프로세서 는 평가용 텍스트 및 레퍼런스 벡터 의 조합에 따라 생성된 후보 합성음은 운율 점수 및 발음 점수 가 기설정된 값을 만족하는 후보 합성음으로 식별할 수 있다. 이때, 평가용 텍스트 의 운율 점수 및 발음 점수 를 만족하는 레퍼런스 벡터 를 평가용 텍스트 의 도메인을 커버할 수 있는 레퍼런스 벡터로 평가(선정)할 수 있다. 또한, 프로세서는 평가용 텍스트 의 운율 점수 및 발음 점수를 만족하는 레퍼런스 벡터 를 평가용 텍스트 의 도메인을 커버할 수 있는 레퍼런스 벡터로 평가(선정)할 수 있다. 도 3을 참조하여, 프로세서는 합성음 평가 모듈을 통해 특정한 도메인에 대해 평가 기준(예: 화자 유 사도, 운율, 발음 및 음질 중 적어도 하나)을 만족하는 적어도 하나의 합성음이 존재하지 않는 경우, 특정한 도 메인에 속하는 문장(r`)의 발화를 요청하는 정보를 출력하도록 출력 인터페이스(140, 도 9b 참조)를 제어할 수 있다. 예를 들어, 도 8d와 같이 프로세서는 평가용 텍스트 의 운율 점수 및 발음 점수를 만족하는 합성음(또는 레퍼런스 벡터)가 존재하지 않는 경우, 평가용 텍스트 에 부여된 도메인에 속하는 문장(r`)을 사용자에게 피드 백할 수 있다. 여기서, 피드백되는 문장(r`)은 평가용 텍스트 의 도메인을 커버하기 위해 사용자가 음성으로 발화하도록 유도하는 문장 또는 단어 등을 포함할 수 있다. 예를 들어, 평가용 텍스트 가 뉴스 도메인이라면, 피드백되는 문장(r`)은 또는 뉴스 도메인 텍스트 일 수 있다. 일 실시 예를 들어, 프로세서는 복수의 도메인 중 적어도 하나의 합성음이 존재하지 않는 도메인에 속한 적어도 하나의 후보 합성음을 판단하고, 판단된 후보 합성음에 대해 산출된 운율 점수, 발음 점수 및 음질 점수 에 기초하여, 운율, 발음 및 음질 중 상대적으로 낮은 점수가 산출된 합성음의 특성을 판단할 수 있다. 프로세 서는 판단된 특성에 기초하여 생성된 문장의 발화를 요청하는 음성을 스피커를 통해 출력할 수 있다. 이와 같이 본 개시의 전자 장치는 사용자의 음성을 TTS 모델의 음성으로 등록하는 과정에서 다양한 평 가 기준에 따른 평가를 수행할 수 있다. 이에 따라, 최적의 성능을 갖는 레퍼런스 벡터를 사용자의 레퍼런스 벡 터로서 결정할 수 있다. 또한, 사용자가 발화한 사용자 음성만으로 개인화된 TTS 서비스를 제공하기가 충분하지 않은 경우에 사용자에게 피드백을 제공함으로써 다양한 유형의 텍스트를 커버할 수 있는 레퍼런스 벡터를 획득 할 수 있다. 한편, 전자 장치는 사용자의 음성이 TTS 모델에 등록된 이후, 등록된 사용자 음성을 이용하여 음성 신 호를 합성할 수 있다. 이에 대해서는 도 4를 참조하여 구체적으로 설명하도록 한다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치의 구성별 동작을 설명하기 위한 블록도이다. 도 4는 사용자의 음성이 TTS 모델에 등록된 이후에 사용자 음성을 이용하여 음성 신호를 합성하는 과정을 나타낸다. 도 4를 참조하여, 프로세서로 입력 데이터(예: 텍스트 t)가 제공되는 경우를 가정하기로 한다. 입력 데이터는 후속 사용자 음성에 대해 음성 인식을 수행한 결과로서 획득되는 텍스트 t일 수 있다. 또는 입력 데이터는 입력 장치(예: 키보드 등)를 통해 입력된 텍스트 t일 수 있다. 일 예를 들어, 프로세서는 사용자의 후속 사용자 음성이 마이크로폰을 통해 수신되면, 후속 사용자 음성에 대한 응답을 위한 텍스트 t를 획득할 수 있다. 이때, 텍스트 t는 ASR 모듈 및 NLP 모듈을 통해 획 득되는 텍스트일 수 있다. 그리고, 프로세서는 레퍼런스 벡터 선택 모듈을 통해, 메모리의 레퍼런스 벡터 저장 모듈에 저장된 사용자 A에 대응되는 적어도 하나의 레퍼런스 벡터 중에서 텍스트 t의 도메인에 속하는 레퍼런스 벡 터를 선택할 수 있다. 여기서, 프로세서는 텍스트 의 도메인에 속하는 레퍼런스 벡터가 복수 개로 선택되는 경우, 복수의 레퍼 런스 벡터 중에서 텍스트 의 도메인에 속하는 평가용 텍스트와 합성한 합성음의 특성에 기초하여 산출된 점수 (예: 운율 점수, 발음 점수 등)가 가장 높은 합성음의 레퍼런스 벡터를 획득할 수 있다. 여기서, 텍스트 의 도 메인에 속하는 평가용 텍스트와 합성한 합성음의 특성에 기초하여 산출된 점수는 사용자 A의 사용자 음성을 등 록하는 과정에서 메모리에 저장된 것일 수 있다. 예를 들어, 낭독체에 속하는 평가용 텍스트와 합성된 합성음 중에서 점수가 가장 높은 합성음의 레퍼런스 벡터 가 이고, 대화체에 속하는 평가용 텍스트와 합성된 합성음의 중에서 점수가 가장 높은 합성음의 레퍼런스 벡 터가 인 것으로 가정하면, 입력 데이터인 텍스트 의 도메인이 낭독체인 경우, 저장된 사용자 A에 대응 되는 적어도 하나의 레퍼런스 벡터 중 레퍼런스 벡터 를 텍스트 의 도메인에 속하는 레퍼런스 벡터 ( )로서 선택할 수 있다. 한편, 프로세서는 임의의 통계 모델(DNN, HMM, GMM 등)을 활용하여 주어진 텍 스트 t에 대해 최적 성능을 가지는 를 선택하는 것 또한 가능하다. 그리고, 프로세서는 입력 데이터인 텍스트 및 선택된 레퍼런스 벡터( )를 TTS 모델에 입력하 여, 레퍼런스 벡터( )에 기초하여 텍스트 에 대해 생성된 음성을 획득할 수 있다. 이 경우, 프로세서는 획득된 음성을 출력하도록 스피커(141, 도 9b 참조)를 제어할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 레퍼런스 벡터를 획득하는 방법을 설명하기 위한 도면이다. 화자 인코더 모듈은 사용자 음성을 통해 레퍼런스 벡터를 획득할 수 있다. 여기서, 화자 인코더 모듈은 Reference encoder, GST(Global Style Token), VAE(Variational AutoEncoder), I-vector, Neural Network 모 듈 등과 같이 다양한 방식의 모듈로 구성될 수 있다. 일 실시 예로서, 도 5를 참조하면, 화자 인코더 모듈은 음향 특징 추출부 및 RNN 모듈(13-1 내지 13- T)를 포함할 수 있다. 음향 특징 추출부는 프레임 단위의 음향 특징을 추출할 수 있다. 이때, 음향 특징의 차원은 (T x D)로 나타 낼 수 있다. 예를 들어 1 프레임이 10ms이고, 80 차원의 음향 특징을 추출할 때, 3초의 음성 파형이 입력된다면 T는 300, D는 80이 되어 (300 x 80)의 음향 특징이 출력될 수 있다. 일반적으로 음향 특징은 TTS 모델의 디 자인 시에 고정되며, 이에 따라 D는 음성 입력에 관계 없이 고정된 값을 가질 수 있다. RNN(Recurrent Neural Network) 모듈(13-1 내지 13-T)은 T에 관계 없이 고정된 차원의 벡터를 출력할 수 있다. 예를 들어, 레퍼런스 벡터가 256차원이라고 가정하면, T, D에 상관없이 항상 256차원의 벡터를 출력할 수 있다. 레퍼런스 벡터는 해당 음성에 포함된 음소정보(local 정보)보다는 운율이나 음색 정보(global 정보)등이 압축되 어 출력될 수 있다. 이 경우, RNN 모듈(13-1 내지 13-T)의 마지막 상태(state)를 본 개시의 레퍼런스 벡터로서 사용할 수 있다 도 7은 본 개시의 일 실시 예에 따른 TTS 모델을 설명하기 위한 도면이다. 도 7을 참조하면, 본 개시의 일 실시 예에 따른 TTS 모델은 언어처리부 및 음향 특징 추출부를 통 해 텍스트 및 음성 파형에 대해 전처리를 수행하여 음소(Phoneme) 및 음향 특징(Acoustic Features)을 추출하고, Neural Network 기반의 AM(Acoustic Model) 및 보코더를 전처리가 수행된 음소 및 음향 특 징을 학습 데이터로 하여 학습시킬 수 있다. 이후, TTS 모델은 언어 처리부를 통해 텍스트에서 음소를 추출하고, 학습된 AM에 추출된 음소를 입 력하여 그 출력으로서 예상 음향 특징을 획득하고, 학습된 보코더에 획득된 음향 특징을 입력하여 그 출력 으로서 합성음을 획득할 수 있다. 다만, 상술한 실시 예는 일 실시 예일 뿐이며, 이에 제한되지 아니하고 다양한 변형 실시 예가 가능하다 할 것 이다. 도 9a는 본 개시의 일 실시 예에 따른 전자 장치의 하드웨어 구성을 설명하기 위한 도면이다. 도 9a를 참조하면, 본 개시의 일 실시 예에 따른 전자 장치는 마이크로폰, 메모리 및 프로세서 를 포함할 수 있다. 마이크로폰은 아날로그 형태의 음향 신호를 수신하기 위한 구성이다. 마이크로폰은 사용자 음성을 포 함하는 음향 신호를 수신할 수 있다. 음향 신호는 진동수, 진폭 등의 정보를 갖는 음파(wave)를 나타낼 수 있다. 메모리는 전자 장치의 구성요소들의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 전자 장치의 구성요소와 관련된 다양한 데이터를 저장하기 위한 구성이다. 메모리는 전기적 방식 또는 자기적 방식 등의 다양한 방식으로 정보를 저장할 수 있다. 메모리에 저장된 데이터는 프로세서(13 0)에 의해 액세스되며, 프로세서에 의해 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 이를 위해, 메모리는 데이터 또는 정보를 일시적 또는 영구적으로 저장하기 위한 하드웨어로 구성될 수 있 다. 예를 들어, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(Flash Memory), 하드디스크 드라 이브(HDD) 또는 솔리드 스테이트 드라이브(SSD), RAM, ROM 등 중에서 적어도 하나의 하드웨어로 구현될 수 있다. 프로세서는 CPU(Central Processing Unit), AP(Application Processor) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit) 등과 같은 그래픽 전용 프로세서, NPU(Neural Processing Unit)와 같은 인공지능 전용 프로세서 등으로 구현될 수 있다. 또한, 프로세서는 적어도 하나 의 인스트럭션 또는 모듈을 로드하기 위한 휘발성 메모리를 포함할 수 있다. 도 9b는 본 개시의 일 실시 예에 따른 전자 장치의 부가적인 하드웨어 구성을 설명하기 위한 도면이다. 도 9b를 참조하면, 본 개시의 일 실시 예에 따른 전자 장치는 마이크로폰, 메모리 및 프로세서 외에도, 출력 인터페이스, 입력 인터페이스, 통신 인터페이스, 센서, 전원부 중 적어도 하나를 포함할 수 있다. 출력 인터페이스는 정보를 출력할 수 있는 구성이다. 출력 인터페이스는 스피커 및 디스플레이 중 적어도 하나를 포함할 수 있다. 스피커는 오디오 처리부(미도시)에 의해 디코딩이나 증폭, 노이 즈 필터링과 같은 다양한 처리 작업이 수행된 각종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시지를 직접 소리로 출력할 수 있다. 디스플레이는 정보 또는 데이터를 시각적인 형태로 출력할 수 있다. 디스플 레이는 이미지 프레임을 픽셀로 구동될 수 있는 디스플레이의 일 영역 또는 전체 영역에 표시할 수 있다. 이를 위해, 디스플레이는 LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플레 이, Micro LED 디스플레이, QLED(Quantum dot LED) 디스플레이 등으로 구현될 수 있다. 또한, 디스플레이(14 3)의 적어도 일부는 플렉서블 디스플레이(flexible display)의 형태로 구현될 수도 있으며, 플렉서블 디스플레 이는 종이처럼 얇고 유연한 기판을 통해 손상 없이 휘거나 구부리거나 말 수 있는 것을 특징으로 할 수 있다. 입력 인터페이스는 다양한 사용자 명령을 수신하여 프로세서로 전달할 수 있다. 즉, 프로세서는 입력 인터페이스를 통해 사용자로부터 입력된 사용자 명령을 인지할 수 있다. 여기서, 사용자 명령은 사용 자의 터치 입력(터치 패널), 키(키보드) 또는 버튼(물리 버튼 또는 마우스 등) 입력 등 다양한 방식으로 구현될 수 있다. 통신 인터페이스는 다양한 유형의 통신 방식에 따라 다양한 유형의 외부 장치와 통신을 수행하여 다양한 유형의 데이터를 송수신할 수 있다. 통신 인터페이스는 다양한 방식의 무선 통신을 수행하는 회로로서 블 루투스 모듈(블루투스 방식), 와이파이 모듈(와이파이 방식), 무선 통신 모듈(3G, 4G, 5G 등의 셀룰러 방식), NFC 모듈(NFC 방식), IR 모듈(적외선 방식), Zigbee 모듈(Zigbee 방식) 및 초음파 모듈(초음파 방식) 등과 유선 통신을 수행하는 이더넷 모듈, USB 모듈, HDMI(High Definition Multimedia Interface), DP(DisplayPort), D- SUB(D-subminiature), DVI(Digital Visual Interface), 썬더볼트(Thunderbolt) 및 컴포넌트 중 적어도 하나를 포함할 수 있다. 센서는 카메라, 근접 센서, 조도 센서, 모션 센서, ToF 센서, GPS 센서 등 다양한 센서로 구현될 수 있다. 예를 들어, 카메라는 빛을 픽셀 단위로 구분하고, 각 픽셀마다 R(Red), G(Green), B(Blue) 색상에 대한 빛의 세 기를 감지하여, 빛의 세기를 전기적 신호로 변환하여 객체의 색상, 형상, 명암 등을 표현하는 데이터를 획득할수 있다. 이때, 데이터의 타입은 복수의 픽셀 각각에 대해 R, G, B 색상 값을 갖는 이미지일 수 있다. 근접 센 서(proximity sensor)는 주변 물체의 존재를 감지하여, 주변 물체의 존재 여부 또는 주변 물체의 근접 여부에 대한 데이터를 획득할 수 있다. 조도 센서는 전자 장치의 주변 환경에 대한 광량(또는 밝기)을 감지하여, 조도에 대한 데이터를 획득할 수 있다. 모션 센서는 전자 장치의 이동 거리, 이동 방향, 기울기 등을 감지 할 수 있다. 이를 위해, 모션 센서는 가속도 센서, 자이로(gyro) 센서, 지자기 센서 등의 결합으로 구현될 수 있다. TOF(Time Of Flight) 센서는 특정한 속도를 갖는 다양한 전자기파(예: 초음파, 적외선, 레이저, UWB(Ultra-Wideband) 등)를 방출한 후 되돌아오는 비행 시간을 감지하여, 대상과의 거리(또는 위치)에 대한 데 이터를 획득할 수 있다. GPS(Global Positioning System) 센서는 복수의 위성으로부터 전파 신호를 수신하고, 수신된 신호의 전달 시간을 이용하여 각 위성과의 거리를 각각 산출하고, 산출된 거리를 삼각측량을 이용하여 전자 장치의 현재 위치에 대한 데이터를 획득할 수 있다. 다만, 상술한 센서의 구현 예는 일 실시 예 일 뿐이며, 이에 제한되지 아니하고 다양한 유형의 센서로 구현되는 것이 가능하다 할 것이다. 전원부는 전자 장치에 전원을 공급할 수 있다. 예를 들어, 전원부는 외부 상용 전원 또는 배터 리를 통해 전자 장치의 각 구성에 전원을 공급할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법에 대한 흐름도이다. 도 10을 참조하면, 전자 장치의 제어 방법은 사용자가 발화한 사용자 음성이 마이크로폰을 통해 수신 되면, 사용자 음성의 레퍼런스 벡터를 획득하는 단계(S1010), 레퍼런스 벡터에 기초하여 복수의 후보 레퍼런스 벡터를 생성하는 단계(S1020), 복수의 후보 레퍼런스 벡터 및 복수의 평가용 텍스트를 TTS 모델에 입력하여, 복수의 합성음을 획득하는 단계(S1030), 복수의 합성음 및 사용자 음성 간의 유사도 및 복수의 합성 음의 특성에 기초하여, 복수의 합성음 중 적어도 하나의 합성음을 식별하는 단계(S1040) 및 적어도 하나의 합성 음의 레퍼런스 벡터를 TTS 모델을 위한 사용자에 대응되는 레퍼런스 벡터로 메모리에 저장하는 단계 (S1050)를 포함할 수 있다. 구체적으로, 본 개시의 전자 장치의 제어 방법은 사용자가 발화한 사용자 음성이 마이크로폰을 통해 수신되면, 사용자 음성의 레퍼런스 벡터를 획득할 수 있다(S1010). 그리고, 레퍼런스 벡터에 기초하여 복수의 후보 레퍼런스 벡터를 생성할 수 있다(S1020). 여기서, 복수의 후보 레퍼런스 벡터는 레퍼런스 벡터에 기초하여 랜덤하게 선택된 적어도 하나의 레퍼런스 벡터, 레퍼런스 벡터 및 TTS 모델의 훈련에 이용된 레퍼런스 벡터에 기초하여 생성된 적어도 하나의 레퍼런 스 벡터 및 마스킹 벡터를 레퍼런스 벡터에 적용하여 생성된 적어도 하나의 레퍼런스 벡터를 포함할 수 있다. 그리고, 복수의 후보 레퍼런스 벡터 및 복수의 평가용 텍스트를 TTS 모델에 입력하여, 복수의 합성음을 획 득할 수 있다(S1030). 구체적인 일 실시 예로서, 복수의 후보 레퍼런스 벡터 및 복수의 평가용 텍스트를 TTS 모델에 입력하여, 복 수의 후보 레퍼런스 벡터 각각에 기초하여 복수의 평가용 각각에 대해 생성된 복수의 합성음을 획득할 수 있다. 그리고, 복수의 합성음 및 사용자 음성 간의 유사도 및 복수의 합성음의 특성에 기초하여, 복수의 합성음 중 적 어도 하나의 합성음을 식별할 수 있다(S1040). 구체적인 일 실시 예로서, 복수의 합성음 중 사용자 음성과의 유사도가 기설정된 임계 값 이상인 후보 합성음을 식별할 수 있다. 그리고, 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나에 기초하여, 후보 합성음 중 적어도 하나의 합성음을 식별할 수 있다. 구체적으로, 후보 합성음 각각에 대한 운율 점수, 발음 점수 및 음질 점수를 산출할 수 있다. 그리고, 후보 합 성음 중 운율 점수, 발음 점수 및 음질 점수 각각이 기설정된 임계 값 이상인 적어도 하나의 합성음을 식별할 수 있다. 한편, 복수의 평가용 텍스트는, 복수의 도메인 각각에 속한 적어도 하나의 평가용 텍스트를 포함할 수 있다. 이 경우, 적어도 하나의 합성음을 식별하는 단계는, 복수의 후보 합성음 각각이 속한 도메인에 기초하여, 복수 의 도메인에 따라 복수의 후보 합성음을 구분할 수 있다. 그리고, 각 도메인에 속한 적어도 하나의 후보 합성음 각각의 운율, 발음 및 음질 중 적어도 하나의 기초하여, 도메인 별로 적어도 하나의 합성음을 식별할 수 있다. 그리고, 적어도 하나의 합성음의 레퍼런스 벡터를 TTS 모델을 위한 사용자에 대응되는 레퍼런스 벡터로 메 모리에 저장할 수 있다(S1050). 한편, 본 개시의 일 실시 예에 따른 전자 장치는 스피커 및 디스플레이 중 적어도 하나를 포함 하는 출력 인터페이스를 더 포함할 수 있다. 이 경우, 전자 장치의 제어 방법은 복수의 도메인 중 적어도 하나의 합성음이 존재하지 않는 도메인을 판 단할 수 있다. 그리고, 합성음이 존재하지 않는 도메인이 판단되는 경우, 판단된 도메인에 속하는 문장의 발화 를 요청하는 정보를 출력하도록 출력 인터페이스를 제어할 수 있다. 구체적으로, 복수의 도메인 중 적어도 하나의 합성음이 존재하지 않는 도메인에 속한 적어도 하나의 후보 합성 음을 판단할 수 있다. 그리고, 합성음이 존재하지 않는 도메인이 판단되는 경우, 판단된 후보 합성음에 대해 산 출된 운율 점수, 발음 점수 및 음질 점수에 기초하여, 운율, 발음 및 음질 중 상대적으로 낮은 점수가 산출된 합성음의 특성을 판단할 수 있다. 그리고, 판단된 특성에 기초하여 생성된 문장의 발화를 요청하는 정보를 출력 하도록 출력 인터페이스를 제어할 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치는 스피커를 포함할 수 있다. 이 경우, 전자 장치의 제어 방법은 사용자의 후속 사용자 음성이 마이크로폰을 통해 수신되면, 후속 사용자 음성에 대한 응답을 위한 텍스트를 획득할 수 있다. 그리고, 획득된 텍스트 및 메모리에 저장된 사용자에 대응되는 적어도 하나의 레퍼런스 벡터 중 하나를 TTS 모델에 입력하여, 레퍼런스 벡터에 기초하여 텍스트에 대해 생성된 음성을 획득할 수 있다. 이를 위해, 메모리에 저장된 사용자에 대응되는 적어도 하나의 레퍼런스 벡터 중 합성음의 특성에 기초하 여 산출된 점수가 가장 높은 합성음의 레퍼런스 벡터를 획득할 수 있다. 그리고, 획득된 음성을 출력하도록 스피커를 제어할 수 있다. 이상과 같은 본 개시의 다양한 실시 예에 따르면, 일반 사용자의 목소리를 이용하여 TTS 서비스를 제공하기 위 한 전자 장치 및 그의 제어 방법을 제공할 수 있다. 또한, 본 개시의 일 실시 예에 따르면 TTS 서비스의 목소리 를 등록하기 위해 발화가 요구되는 문장의 수를 최소화할 수 있다. 또한, 본 개시의 일 실시 예에 따르면 사용 자마다 TTS 모델을 재훈련하지 않아도 사용자의 목소리를 통해 개인화된 TTS 서비스를 제공할 수 있다. 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는 저장 매체로부터 저장된 명령 어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치(예: 전자 장치)를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세 서의 제어 하에 다른 구성요소들을 이용하여 상기 명령에 상기하는 기능을 수행할 수 있다. 명령은 컴파일러 또 는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는 비일시적 (non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하 지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분 하지 않는다. 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽 을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 상기 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 상기 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행 할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 부호의 설명100: 전자 장치"}
{"patent_id": "10-2021-0027665", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성별 동작을 설명하기 위한 블록도이다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 구성별 동작을 설명하기 위한 블록도이다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치의 구성별 동작을 설명하기 위한 블록도이다. 도 5는 본 개시의 일 실시 예에 따른 레퍼런스 벡터를 획득하는 방법을 설명하기 위한 도면이다. 도 6a는 본 개시의 일 실시 예에 따른 후보 레퍼런스 벡터를 생성하는 방법을 설명하기 위한 도면이다. 도 6b는 본 개시의 일 실시 예에 따른 후보 레퍼런스 벡터를 생성하는 방법을 설명하기 위한 도면이다. 도 6c는 본 개시의 일 실시 예에 따른 후보 레퍼런스 벡터를 생성하는 방법을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시 예에 따른 TTS 모델을 설명하기 위한 도면이다. 도 8a는 본 개시의 일 실시 예에 따른 합성음을 식별하는 방법을 설명하기 위한 도면이다. 도 8b는 본 개시의 일 실시 예에 따른 합성음을 식별하는 방법을 설명하기 위한 도면이다. 도 8c는 본 개시의 일 실시 예에 따른 합성음을 식별하는 방법을 설명하기 위한 도면이다. 도 8d는 본 개시의 일 실시 예에 따른 합성음을 식별하는 방법을 설명하기 위한 도면이다. 도 9a는 본 개시의 일 실시 예에 따른 전자 장치의 하드웨어 구성을 설명하기 위한 도면이다. 도 9b는 본 개시의 일 실시 예에 따른 전자 장치의 부가적인 하드웨어 구성을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법에 대한 흐름도이다."}
