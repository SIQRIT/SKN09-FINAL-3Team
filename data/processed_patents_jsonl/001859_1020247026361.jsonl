{"patent_id": "10-2024-7026361", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0125688", "출원번호": "10-2024-7026361", "발명의 명칭": "주기적 데이터를 이용한 기계 학습", "출원인": "레몬 인크.", "발명자": "양, 잉시앙"}}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법에 있어서,주기성을 가진 입력 데이터를 처리하도록 구성된 예측 모델로부터, 입력 데이터 샘플의 특징 표현(featurerepresentation)을 획득하는 단계, 상기 입력 데이터 샘플은 일정 주기 내 시점에서 생성된 상기 입력 데이터의샘플이고;상기 특징 표현을 제1 매핑 모델에 적용함으로써 푸리에 전개(Fourier expansion) 중 제1 성분에 대한 제1 푸리에 계수를 결정하는 단계, 상기 푸리에 전개는 상기 시점 및 상기 특징 표현에 의존하고, 상기 푸리에 전개는상기 주기성을 가지며;상기 특징 표현을 제2 매핑 모델에 적용함으로써 상기 푸리에 전개 중 제2 성분에 대한 제2 푸리에 계수를 결정하는 단계;상기 푸리에 전개 중의 상기 제1 푸리에 계수와 상기 제2 푸리에 계수를 기반으로 푸리에 전개 결과를 결정하는단계; 및상기 푸리에 전개 결과를 기반으로 상기 입력 데이터 샘플에 대한 예측 결과를 결정하는 단계;를 포함하는방법."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 푸리에 전개는 미리 정해진 개수의 항을 갖는 절단형 푸리에 전개를 포함하고, 상기 제1 푸리에 계수의 개수와 상기 제2 푸리에 계수의 개수는 상기 미리 정해진 개수를 기반으로 하는 방법."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 성분은 상기 시점에 의존하고 상기 주기성을 갖는 사인 함수를 기반으로 하고, 상기 제2 성분은 상기주기성을 갖는 코사인 함수를 기반으로 하며, 상기 푸리에 전개 결과를 결정하는 단계는,상기 사인 함수의 주파수를 미리 정해진 횟수만큼 이동시킴으로써 상기 제1 성분에 대한 제1 성분 값 세트를 결정하는 단계;상기 코사인 함수의 주파수를 상기 미리 정해진 횟수만큼 이동시킴으로써 상기 제2 성분에 대한 제2 성분 값 세트를 결정하는 단계; 및상기 제1 푸리에 계수와 상기 제1 성분 값을 각각 곱하고, 상기 제2 푸리에 계수와 상기 제2 성분 값을 곱하여상기 푸리에 전개 결과를 결정하는 단계;를 포함하는 방법."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제1 푸리에 계수와 상기 제1 성분 값을 각각 곱하고, 상기 제2 푸리에 계수와 상기 제2 성분 값을 곱하여상기 푸리에 전개 결과를 결정하는 단계는,공개특허 10-2024-0125688-3-상기 제1 푸리에 계수와 상기 제1 성분 값을 곱하여 제1 곱(product)을 계산하는 단계;상기 제2 푸리에 계수와 상기 제2 성분 값을 곱하여 제2 곱을 계산하는 단계;제3 매핑 모델을 이용하여 상기 제1 곱을 제1 중간 전개 결과에 매핑하고, 제4 매핑 모델을 이용하여 상기 제2곱을 제2 중간 전개 결과에 매핑하는 단계; 및상기 제1 중간 전개 결과와 상기 제2 중간 전개 결과를 집산하여 상기 푸리에 전개 결과를 결정하는 단계;를 포함하는 방법."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서,상기 푸리에 전개 결과를 기반으로 상기 입력 데이터 샘플에 대한 상기 예측 결과를 결정하는 단계는,상기 푸리에 전개 결과로부터 제1 중간 예측 결과를 결정하는 단계;상기 특징 표현을 기반으로 상기 예측 모델의 출력 레이어(layer)로부터 생성된 제2 중간 예측 결과를 획득하는단계; 및상기 제1 중간 예측 결과와 상기 제2 중간 예측 결과를 집산하여 상기 예측 결과를 결정하는 단계;를 포함하는방법."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 예측 모델은 상기 입력 데이터 샘플로부터 복수의 특징 표현을 추출하도록 구성된 복수의 서브모델(sub-model)을 포함하고, 상기 특징 표현을 획득하는 단계는,상기 복수의 서브모델로부터 상기 복수의 특징 표현을 획득하는 단계;상기 복수의 특징 표현을 집산하여 상기 특징 표현을 생성하는 단계;를 포함하는 방법."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 제1 매핑 모델과 상기 제2 매핑 모델은 활성화 함수 없이 구축된 방법."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "시스템에 있어서,적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신적으로 연결되는 적어도 하나의 메모리를 포함하되, 상기 적어도 하나의 메모리는 컴퓨터 판독가능 명령어를 포함하고, 상기 명령어는 상기 적어도 하나의 프로세서에 의해 실행되는 경우상기 적어도 하나의 프로세서가 작업을 실행하게 하고, 상기 작업은,주기성을 가진 입력 데이터를 처리하도록 구성된 예측 모델로부터, 입력 데이터 샘플의 특징 표현(featurerepresentation)을 획득하고, 상기 입력 데이터 샘플은 일정 주기 내 시점에서 생성된 상기 입력 데이터의 샘플이고;상기 특징 표현을 제1 매핑 모델에 적용함으로써 푸리에 전개 (Fourier expansion) 중 제1 성분에 대한 제1 푸리에 계수를 결정하고, 상기 푸리에 전개는 상기 시점 및 상기 특징 표현에 의존하고, 상기 푸리에 전개는 상기공개특허 10-2024-0125688-4-주기성을 가지며;상기 특징 표현을 제2 매핑 모델에 적용함으로써 상기 푸리에 전개 중 제2 성분에 대한 제2 푸리에 계수를 결정하고;상기 푸리에 전개 중의 상기 제1 푸리에 계수와 상기 제2 푸리에 계수를 기반으로 푸리에 전개 결과를결정하고; 및상기 푸리에 전개 결과를 기반으로 상기 입력 데이터 샘플에 대한 예측 결과를 결정하게 하는 시스템."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 푸리에 전개는 미리 정해진 개수의 항을 갖는 절단형 푸리에 전개를 포함하고, 상기 제1 푸리에 계수의 개수와 상기 제2 푸리에 계수의 개수는 상기 미리 정해진 개수를 기반으로 하는 시스템."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제1 성분은 상기 시점에 의존하고 상기 주기성을 갖는 사인 함수를 기반으로 하고, 상기 제2 성분은 상기주기성을 갖는 코사인 함수를 기반으로 하며, 상기 푸리에 전개 결과를 결정하는 단계는,상기 사인 함수의 주파수를 상기 미리 정해진 횟수만큼 이동시킴으로써 상기 제1 성분에 대한 제1 성분 값 세트를 결정하고;상기 코사인 함수의 주파수를 상기 미리 정해진 횟수만큼 이동시킴으로써 상기 제2 성분에 대한 제2 성분 값 세트를 결정하고; 및상기 제1 푸리에 계수와 상기 제1 성분 값을 각각 곱하고, 상기 제2 푸리에 계수와 상기 제2 성분 값을 곱하여상기 푸리에 전개 결과를 결정하는 것을 포함하는 시스템."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 제1 푸리에 계수와 상기 제1 성분 값을 각각 곱하고, 상기 제2 푸리에 계수와 상기 제2 성분 값을 곱하여상기 푸리에 전개 결과를 결정하는 것은,상기 제1 푸리에 계수와 상기 제1 성분 값을 곱하여 제1 곱(product)을 계산하고;상기 제2 푸리에 계수와 상기 제2 성분 값을 곱하여 제2 곱을 계산하고;제3 매핑 모델을 이용하여 상기 제1 곱을 제1 중간 전개 결과에 매핑하고, 제4 매핑 모델을 이용하여 상기 제2곱을 제2 중간 전개 결과에 매핑하고; 및상기 제1 중간 전개 결과와 상기 제2 중간 전개 결과를 집산하여 상기 푸리에 전개 결과를 결정하는 것을 포함하는 시스템."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항 내지 제11항 중 어느 한 항에 있어서,상기 푸리에 전개 결과를 기반으로 상기 입력 데이터 샘플에 대한 상기 예측 결과를 결정하는 것은,상기 푸리에 전개 결과로부터 제1 중간 예측 결과를 결정하고;공개특허 10-2024-0125688-5-상기 특징 표현을 기반으로 상기 예측 모델의 출력 레이어(layer)로부터 생성된 제2 중간 예측 결과를획득하고; 및상기 제1 중간 예측 결과와 상기 제2 중간 예측 결과를 집산하여 상기 예측 결과를 결정하는 것을 포함하는 시스템."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항 내지 제12항 중 어느 한 항에 있어서,상기 예측 모델은 상기 입력 데이터 샘플로부터 복수의 특징 표현을 추출하도록 구성된 복수의 서브모델(sub-model)을 포함하고, 상기 특징 표현을 획득하는 것은,상기 복수의 서브모델로부터 상기 복수의 특징 표현을 획득하고;상기 복수의 특징 표현을 집산하여 상기 특징 표현을 생성하는 것을 포함하는 시스템."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항 내지 제13항 중 어느 한 항에 있어서,상기 제1 매핑 모델과 상기 제2 매핑 모델은 활성화 함수 없이 구축된 시스템."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨터 판독가능 명령어를 저장하는, 비-일시적 컴퓨터 판독가능 저장 매체로서,상기 명령어는 컴퓨팅 디바이스에 의해 실행되는 경우, 상기 컴퓨팅 디바이스가 작업을 실행하게 하고, 상기 작업은,주기성을 가진 입력 데이터를 처리하도록 구성된 예측 모델로부터, 입력 데이터 샘플의 특징 표현(featurerepresentation)을 획득하고, 상기 입력 데이터 샘플은 일정 주기 내 시점에서 생성된 입력 데이터의 샘플이고;상기 특징 표현을 제1 매핑 모델에 적용함으로써 푸리에 전개(Fourier expansion) 중 제1 성분에 대한 제1 푸리에 계수를 결정하고, 상기 푸리에 전개는 상기 시점 및 상기 특징 표현에 의존하고, 상기 푸리에 전개는 상기주기성을 가지며;상기 특징 표현을 제2 매핑 모델에 적용함으로써 상기 푸리에 전개 중 제2 성분에 대한 제2 푸리에 계수를 결정하고;상기 푸리에 전개 중의 상기 제1 푸리에 계수와 상기 제2 푸리에 계수를 기반으로 푸리에 전개 결과를결정하고; 및상기 푸리에 전개 결과를 기반으로 상기 입력 데이터 샘플에 대한 예측 결과를 결정 하는 비-일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 푸리에 전개는 미리 정해진 개수의 항을 갖는 절단형 푸리에 전개를 포함하고, 상기 제1 푸리에 계수의 개수와 상기 제2 푸리에 계수의 개수는 상기 미리 정해진 개수를 기반으로 하는 비-일시적 컴퓨터 판독가능 저장매체.공개특허 10-2024-0125688-6-청구항 17 제16항에 있어서,상기 제1 성분은 상기 시점에 의존하고 상기 주기성을 갖는 사인 함수를 기반으로 하고, 상기 제2 성분은 상기주기성을 갖는 코사인 함수를 기반으로 하며, 상기 푸리에 전개 결과를 결정하는 것은,상기 사인 함수의 주파수를 미리 정해진 횟수만큼 이동시킴으로써 상기 제1 성분에 대한 제1 성분 값 세트를 결정하고;상기 코사인 함수의 주파수를 상기 미리 정해진 횟수만큼 이동시킴으로써 상기 제2 성분에 대한 제2 성분 값 세트를 결정하고; 및상기 제1 푸리에 계수와 상기 제1 성분 값을 각각 곱하고, 상기 제2 푸리에 계수와 상기 제2 성분 값을 곱하여상기 푸리에 전개 결과를 결정하는 것을 포함하는 비-일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 제1 푸리에 계수와 상기 제1 성분 값을 각각 곱하고, 상기 제2 푸리에 계수와 상기 제2 성분 값을 곱하여상기 푸리에 전개 결과를 결정하는 것은,상기 제1 푸리에 계수와 상기 제1 성분 값을 곱하여 제1 곱(product)을 계산하고;상기 제2 푸리에 계수와 상기 제2 성분 값을 곱하여 제2 곱을 계산하고;제3 매핑 모델을 이용하여 상기 제1 곱을 제1 중간 전개 결과에 매핑하고, 제4 매핑 모델을 이용하여 상기 제2곱을 제2 중간 전개 결과에 매핑하고; 및상기 제1 중간 전개 결과와 상기 제2 중간 전개 결과를 집산하여 상기 푸리에 전개 결과를 결정하는 것을 포함하는 비-일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항 내지 제18항 중 어느 한 항에 있어서,상기 푸리에 전개 결과를 기반으로 상기 입력 데이터 샘플에 대한 상기 예측 결과를 결정하는 것은,상기 푸리에 전개 결과로부터 제1 중간 예측 결과를 결정하고;상기 특징 표현을 기반으로 상기 예측 모델의 출력 레이어(layer)로부터 생성된 제2 중간 예측 결과를획득하고; 및상기 제1 중간 예측 결과와 상기 제2 중간 예측 결과를 집산하여 상기 예측 결과를 결정하는 것을 포함하는 비-일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-7026361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항 내지 제19항 중 어느 한 항에 있어서,상기 예측 모델은 상기 입력 데이터 샘플로부터 복수의 특징 표현을 추출하도록 구성된 복수의 서브모델(sub-model)을 포함하고, 상기 특징 표현을 획득하는 것은,상기 복수의 서브모델로부터 상기 복수의 특징 표현을 획득하고;상기 복수의 특징 표현을 집산하여 상기 특징 표현을 생성하는 것을 포함하는 비-일시적 컴퓨터 판독가능 저장매체.공개특허 10-2024-0125688-7-"}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 실시예는 주기적 데이터를 이용한 기계 학습에 관한 것이다. 본 개시의 실시예에 따르면, 입력 데이터 샘플의 특징 표현은 예측 모델로부터 획득된다. 특징 표현을 제1 매핑 모델에 적용하여 푸리에 전개 중 제1 성분 에 대한 제1 푸리에 계수를 결정하고, 특징 표현을 제2 매핑 모델에 적용하여 푸리에 전개 중 제2 성분에 대한 제2 푸리에 계수를 결정한다. 푸리에 전개 중의 제1 푸리에 계수와 제2 푸리에 계수를 기반으로 푸리에 전개 결 과를 결정하며, 푸리에 전개 결과를 기반으로 입력 데이터 샘플에 대한 예측 결과를 결정한다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2022년 2월 7일자로 출원된 발명의 명칭이 “MACHINE LEARNING WITH PERIODIC DATA”인 미국 특허 출원 번호 17/666,076의 이익을 주장하며, 이 출원은 그 전체 내용이 참조로 본 명세서에 포함 된다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "주기적(periodic) 또는 순환(cyclic) 데이터는 광범위한 기계 학습 시나리오에서 자주 발생한다. 예를 들어 추 천 시스템에서는 사용자가 통상적으로 매일 상대적으로 고정된 시간 창(예: 잠자리에 들기 전이나 퇴근 후) 내 에 애플리케이션에 로그인하는 것으로 관찰된다. 그 결과 사용자에게 추천하는 데 있어서 강력한 순환 패턴이 나타낸다. 금융 시장에서는 자산 가격이 매년 주기적으로 오르락내리락할 수 있다. 이는 보통 “계절성”으로 알려진 현상이다. 검색엔진에서는 특정 키워드의 조회수도 주기적인 패턴을 나타낼 수 있다. 따라서 더 나은 예 측 모델을 학습하기 위해 훈련 데이터 내 주기성을 활용하는 방법은 이러한 애플리케이션에 대해 중요한 문제이 다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 원리는 이제 일부 실시예를 참조하여 설명될 것이다. 이들 실시예는 예시의 목적으로만 설명되었으며, 본 개시의 범위에 대한 어떠한 제한도 제시하지 않고, 당업자가 본 개시를 이해하고 구현하는 데 도움을 준다는 것이 이해되어야 한다. 본 문에서 설명되는 개시내용은 아래에서 설명되는 것 외에도 다양한 방 식으로 구현될 수 있다. 다음 설명 및 청구범위에서는, 달리 정의되지 않는 한, 여기에 사용된 모든 기술 및 과학 용어는 본 개시 내용 이 속하는 기술 분야의 통상의 기술자에 의해 일반적으로 이해되는 것과 동일한 의미를 갖는다. 본 개시에서 \"일 실시예\", \"실시예\", \"예시적인 실시예\" 등의 언급은 설명된 실시예가 특정 특징, 구조 또는 특 성을 포함할 수 있지만 모든 실시예가 해당 특정 특징, 구조 또는 특성을 포함할 필요는 없음을 나타낸다. 또한, 이러한 문구는 반드시 동일한 실시예를 언급하는 것은 아니다. 더 나아가, 특정 특징, 구조 또는 특성이 예시적인 실시예와 관련하여 설명될 때, 명시적으로 설명되었는지와 무관하게, 다른 실시예와 관련하여 그러한 특징, 구조 또는 특성에 영향을 미치는 것은 당업자의 지식 내에 있다고 제출된다. 본 명세서에서는 \"제1\" 및 \"제2\" 등의 용어가 다양한 요소를 설명하기 위해 사용될 수 있지만, 이러한 요소가 이러한 용어에 의해 제한되어서는 안 된다는 것이 이해되어야 한다. 이 용어는 한 요소를 다른 요소와 구별하는 데에만 사용된다. 예를 들어, 예시적인 실시예의 범위를 벗어나지 않으면서 제1 요소는 제2 요소로 명명될 수 있고, 유사하게 제2 요소도 제1 요소로 명명될 수 있다. 본 문에 사용된 용어 \"및/또는\"은 나열된 용어 중 하나 이상의 임의 또는 모든 조합을 포함한다. 본 명세서에서 사용된 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 예시적인 실시예를 한정하려 는 의도가 아니다. 본 문에서 사용된 단수형 \"a\", \"an\" 및 \"the\"는 문맥상 명백하게 달리 나타내지 않는 한 복 수형도 포함하도록 의도된다. 본 문에서 사용되는 용어 \"포함한다(comprises)\", \"포함하는(comprising)\", \"갖다 (has)\", \"가지는(having)\", \"포괄한다(include)\" 및/또는 \"포괄하는(including)\"은 언급된 특징, 요소 및/또는 구성요소 등의 존재를 지정한다는 것이 이해될 것이다. 그러나 하나 이상의 다른 특징, 요소, 구성요소 및/또는 이들의 조합의 존재 또는 추가를 배제하지는 않는다. 본 문에서, “모델”이라는 용어는 학습 데이터로부터 학습된 입력과 출력 간의 연관성을 의미하며, 이에 따라 학습 후 주어진 입력에 대해 대응되는 출력이 생성될 수 있다. 연관성은 입력을 처리하고 출력을 생성하는 함수 로 표현될 수 있다. 모델의 생성은 기계 학습 기술을 기반으로 할 수 있다. 기계 학습 기술은 인공지능(AI) 기 술이라고도 할 수 있다. 일반적으로 입력 정보를 받아 이를 기반으로 예측하는 기계 학습 모델을 구축할 수 있 다. 이러한 기계 학습 모델을 예측 모델이라 부를 수 있다. 예를 들어, 분류 모델은 미리 정해진 클래스 세트 중에서 입력 정보의 클래스를 예측하고, 추천 모델은 사용자와 관련된 콘텍스트 정보를 기반으로 사용자에게 추 천 결과를 예측하고, 검색 엔진에 적용되는 모델은 사용자 행동에 기반하여 특정 키워드의 조회의 확률을 예측 한다. 본 문에서 사용되는 “모델”은 “기계 학습 모델”, “학습 모델”, “기계 학습 네트워크” 또는 “학 습 네트워크”로도 지칭될 수 있으며, 이는 본 문에서 상호교환적으로 사용된다. 일반적으로 기계 학습에는 훈련 단계, 검증 단계, 및 적용 단계(추론 단계라고도 함)의 세 단계가 포함될 수 있 다. 훈련 단계에서, 주어진 기계 학습 모델은 모델이 훈련 데이터로부터 인간 지능이 할 수 있는 것과 유사한 일관된 추론을 얻을 수 있을 때까지 대량의 훈련 데이터를 사용하여 반복적으로 훈련(또는 최적화)을 거칠 수 있다. 훈련 중에 모델의 파라미터 값 세트는 훈련 목적에 도달할 때까지 반복적으로 업데이트 된다. 훈련 과정 을 통해, 기계 학습 모델은 훈련 데이터로부터 입력과 출력 사이의 연관성(입력-출력 매핑이라고도 함)을 학습 할 수 있는 것으로 간주할 수 있다. 검증 단계에서는 훈련된 기계 학습 모델에 검증 입력을 적용하여 모델이 정 확한 출력을 제공할 수 있는지 테스트하고 모델의 성능을 결정한다. 적용 단계에서는 결과적인 기계 학습 모델 을 사용하여 훈련 과정에서 얻은 파라미터 값 세트를 기반으로 실제 모델 입력을 처리 하고 해당 모델 출력을 결정할 수 있다. 전체 훈련 데이터 세트를 한 번에 학습하는 최적 기계 학습 모델을 생성하는 배치(Batch) 학습 기법과 달리, 온 라인(online) 기계 학습은 훈련 데이터를 순차적으로 이용 가능하게 하여 각 단계에서 미래 데이터에 대한 최적 의 기계 학습 모델을 업데이트하는 데 사용되는 기계 학습의 방법이다. 예제 환경 언급한 바와 같이 더 나은 예측 모델을 학습하기 위해 훈련 데이터 내의 주기성을 활용할 것으로 예상된다. 기 계 학습 기법에 따라 예측 모델을 구축하고 활용한다. 기계 학습 환경을 설명하기 위해 도 1을 참조한다. 도 1은 본 개시의 실시예가 구현될 수 있는 환경의 블록도를 도시한다. 환경에서는 예측 작업을 위해 기계 학습 모델을 훈련하고 적용할 것으로 기대된다. 기계 학습 모델은 임의의 기계 학습 또는 딥 러 닝 아키텍처, 예를 들어 신경망일 수 있다. 실제 시스템에서, 기계 학습 모델은 입력 데이터 샘플을 처리하고 입력 데이터 샘플에 대한 예측 결과를 생성하도록 구성될 수 있다. 예측 작업은 기계 학습 모델이 적용되는 실제 애플리케이션에 따라 정의될 수 있다. 예를 들어, 추천 시스템에서 예측 작업은 사용자가 관심을 갖는 하나 이상의 항목이나 대상을 예측하고 예측을 기반으로 사용자에게 추천을 제공하는 것이다. 이 예에서, 기계 학습 모델에 대한 입력 데이터 샘 플은 사용자 정보, 사용자의 이력 상호 작용 등과 같은 사용자와 관련된 컨텍스트 정보와 추천할 항목과 관련된 정보를 포함할 수 있다. 기계 학습 모델의 출력은 사용자가 어떤 항목 또는 어떤 유형의 항목에 관심을 가 질 것인지를 나타내는 예측 결과이다. 또 다른 예로, 금융 애플리케이션에서 예측 작업은 향후 제품 판매를 예 측하는 것이다. 이 예에서, 기계 학습 모델에 대한 입력 데이터 샘플은 추가 시간, 제품 및/또는 기타 관 련 제품과 관련된 정보, 제품 및/또는 기타 관련 제품의 판매 이력, 목적 지역과 관련된 정보 그리고 제품의 대 상 사용자 등을 포함할 수 있다. 위에 나열된 예는 제한된 수임이 이해될 것이며, 기계 학습 모델은 임의의 다른 예측 작업을 구현하도록 구성될 수 있다. 기계 학습 모델은 입력 데이터를 처리하여 예측 결과로서 출력을 생성하는 함수로 구성될 수 있다. 기계 학습 모델은 훈련 과정을 통해 훈련 데이터로부터 그 값을 학습할 파라미터 세트로 구성될 수 있다. 도 1 에서, 모델 훈련 시스템은 훈련 데이터세트에 기초하여 기계 학습 모델을 훈련하기 위한 훈련 과정을 구현하도록 구성된다. 초기 단계에서, 기계 학습 모델은 초기 파라미터 값으로 구성될 수 있다. 훈 련 과정에서, 기계 학습 모델의 초기 파라미터 값은 학습 목적이 달성될 때까지 반복적으로 업데이트될 수 있다. 훈련 데이터세트는 기계 학습 모델에 제공되는 다수의 입력 데이터 샘플과 입력 데이터 샘플에 대한 대응하는 진실(groundtruth) 레이블을 지시하는 레이블링 정보를 포함할 수 있다. 일부 실시예에서, 기계 학습 모델의 출력과 진실 레이블 사이의 오차(또는 거리)를 측정 하기 위해 목적함수가 사용된다. 이러한 오차 를 기계 학습의 손실(loss)이라고도 하며, 목적함수를 손실함수라고도 할 수 있다. 손실함수는 와 같이 표현될 수 있다. 여기서 x는 입력 데이터 샘플을 나타내고, f()는 기계 학습 모델을 나타내고, f(x)는 기계 학습 모델의 출력을 나타내고, y는 x에 대한 진실 레이블을 나타낸다. 훈련 중에 기계 학습 모델의 파라미터 값은 목적함수로부터 계산된 오차를 줄이기 위해 업데이트된다. 학습 목적은 목적함 수가 최적화될 때까지, 예를 들어 계산된 오차가 최소화되거나 원하는 역치값에 도달할 때 까지 달성될 수 있다. 훈련 과정 후에, 업데이트된 파라미터 값으로 구성된 훈련된 기계 학습 모델은, 현실 입력 데이터 샘플 을 기계 학습 모델에 적용하여 입력 데이터 샘플에 대한 예측 결과를 출력하는 모델 적용 시스템에 제공될 수 있다. 도 1에서, 모델 훈련 시스템 및 모델 적용 시스템은 컴퓨팅 능력을 갖추는 임의의 시스템일 수 있다. 도 1에 도시된 환경의 구성요소 및 배열은 단지 예시일 뿐이며, 본 문에 설명된 주제에 설명된 예시적인 구현을 구현하는 데 적합한 컴퓨팅 시스템은 하나 이상의 다른 구성요소, 기타 구성요소 및/또는 다른 배열 방식을 포 함할 수 있음을 이해해야 한다. 예를 들어, 모델 훈련 시스템과 모델 적용 시스템은 별개로 도시되었 으나, 동일한 시스템 또는 디바이스에 통합될 수도 있다. 본 개시의 실시예는 이 점에 제한되지 않는다. 어떤 경우에는 기계 학습 모델에 의해 처리되는 입력 데이터가 특정 주기성을 가질 수 있다. 이러한 데이터를 주기적 또는 순환적 데이터라고 한다. 예를 들어, 애플리케이션 사용자는 통상적으로 매일 상대적으로 고정된 시간 창(예: 잠자리에 들기 전과 퇴근 후) 내에 애플리케이션에 로그인하고 다른 날 동일한 시간 창에 동일한 관심을 나타낼 수 있다. 이러한 순환 패턴은 사용자에게 다른 예측 추천 사항을 제공할 수 있다. 따라서, 기계 학습 모델은 훈련 데이터 내의 주기성을 이용하도록 훈련될 수 있을 것으로 기대 된다. 더 나은 예측 모델을 학습하기 위해 훈련 데이터 내의 주기성을 활용 하는 문제는 다음과 같이 설정될 수 있다. 삼중항으로 표시된 주어진 샘플 에 있어서 는 입력 데이터 샘플 의 특징이 며, 는 입력 데이터 샘플에 대한 예측 결과 이고, 은 입력 데이터 샘플이 생성되는 시점 이므로, 임의의 주어진 시점t에서 로 를 예측할 수 있는 예측 모델을 학습할 것으로 기대된다 ( 로표시). 데이터 샘플이 순환적인 방식으로 도착할 수 있다. 좀 더 구체적으로는, t 와 t + δ에 서의 모델의 두번 연속 업데이트사이에서, [ t , t + δ ) 구간에 도착한 샘플만 훈련에 사용할 수 있다. 또한 가 시간 의존형 분포 에서 생성 되면 모든 t 에 대해 하도록T의 주기성이 존재 한다. 임의의 에 대해 삼중항 이 연합(joint) 분포 에서 샘플링된다는 추가 가정 하에서, 목적은 손실함수 에 대한 다음과 같은 최적화 문제 세트를 해결하는 것이다. 와 는 볼록세트 및 컴팩트세트로 가정하며, 손실함수 는 모든 에 대해 에 관해서 강하게 볼록한다. 상기 수식의 최적화 문제 세트는 다음과 같이 해결될 수 있다. 유한 에너지와 연속 함수 (예상되는 예측 모델을 나타냄)세트를 학습하여 각 시점 의 예상 손실을 최소 화한다. 최적화는 상에서 정의된 모든 유한 에너지 함수를 포함하는 함수 공간인 공간 내에서 수행된다. 주기성 개념은 수식에서 중요한 역할을 한다. 특히, 주기성으로 인해 시점 t에 대한 함수 는 t + n T (여기서 n은 0보다 큰 정수)에서 솔루션이 되는 것이 보장된다. 이는 시간 t에서 학습된 예측 모델이 t + n T 에서의 예측 정확도를 향상시키는 데 유용한 정보를 제공할 수 있다는 것을 의미한다. 따라서, 발명자들은 데 이터의 순환적 특성에 의해 제공되는 유용한 정보를 효과적으로 활용할 수 있는 학습 알고리즘을 설계하려는 동 기를 갖게 되었다. 놀랍게도 기존 최적화 및 기계 학습 기술은 빅 데이터 설정에서 수식을 효율적으로 해결하기 위해 훈련 데이 터 내의 주기성을 활용하는 방법에 대한 견해를 거의 제공하지 않는다. 반면, 산업 시스템은 훈련 데이터 내의 주기성을 단순히 과소평가하는 알고리즘을 구현한다. 주기적 데이터에 대한 기계 학습에 직면했을 때 주기성을 모델 구조에 인코딩하는 직관적인 설계 중 하나는 단 순히 t를 모델 입력으로 포함하고 함수 를 학습하는 것이다. 불행하게도 이 방식을 직접 바로(out- of-the-box) 작동할 수 없다. 함수 를 기계 학습 모델로 표현할 때 특별한 활성화 함수를 사용하지 않으면 주기성을 학습하지 못하는 것으로 나타났다. 가 주기적 커널을 갖는 재생 커널 Hilbert 공간 (RKHS) 또는 주기적 스플라인을 갖는 Sobolev-Hilbert 공간과 같은 주기성을 인코딩하는 논파라메트릭(non- parametric) 계열에 속하는 경우, 주기성은 모든 입력 차원에 걸쳐 자동으로 인코딩된다. 하지만 수식에서 는 x에 대해 비주기적일 수 있다. 이 방식의 증강된 버전은 시간 t를 전처리 하고 대신 의 단일 주기에 초점을 맞추는 로 표현되는 함수를 학습하는 것이다. 비록 mod( t ,T )로의 t의 전처리가 추론 단계 에서는 주기성을 보장하지만 특히 x가 고차원적이고 가 복잡한 디자인을 가지고 있는 경우 여전히 어 려운 특징 엔지니어링(laborious feature engineering)이 필요한다. 수식에 대한 또 다른 방식은 단순히 모든 t에 대해 예측 모델을 학습하는 것이다. 이는 항상 실천적으로 불 가능하기 때문에 시간 축이 종종 이산화되어 학습자는 여러 개의 이산된 시점에 대해 유한한 모델 세트만 학습 하면 되므로 다원적 방식(pluralistic approach)이 이루어 졌다. 기계 학습 시스템의 경우 이 모델 세트는 신경 망의 \"기본\" 부분을 공유할 수 있으며 마지막 몇 개의 레이어에서만 다르다. 긍정적인 측면에서, 시간 의존형 분포 가 시간에 따라 부분적으로(piece-wise) 일정한 경우(예: ) , 이 방식을 사용하면 각 개별 모델이 시간 과 동시에 최적으로 수렴할 수 있다. 그러나 한편으로는,이와 같은 다원적 방식을 사용하려면 다수의 모델을 저장해야 하는데, 이는 저장하는 데 종종 테라바이트의 메 모리 공간이 필요한 대규모 산업 시스템에 맞게 확장하기가 어렵다. 계산적으로 효율적인 방법이 존재하지만(예 를 들어 모델 사이에서 부분적으로 네트워크 구조를 공유) 일반적으로 트레이드오프로 이론적 보장을 타협한다. 순차적인(sequential) 데이터를 사용하여 예측 모델을 훈련하기 위한 추가 솔루션은 새로 생성된 주기 데이터가 모델 최적화에 적용되는 온라인 학습 프로토콜을 따르는 것이다. 학습 알고리즘의 성능은, 일반적으로 도착하는 데이터의 최신 배치의 레이블을 일관하고 정확하게 예측하는 모델의 능력을 측정하는, 동적 회귀(dynamic regret) 개념을 사용하여 평가된다. 조잡하게 말하자면, t가 이산(discretized)된 값의 세트를 취하면 동적 회 귀는 을 측정한다. 이는 학습된 모델의 손실과 수식에서 정 의된 의 최적 손실 간의 차이의 누적 합계이다. 동적 회귀 분석을 개선하기 위해 많은 최적화 알고리즘 이 제안되었지만 그 중 어느 것도 훈련 데이터 내의 주기성을 활용하는 방식에 대해 밝히지 않았다. 더군다나, t가 발산함에 따라 가 고정 분포로 수렴하지 않을 때 동적 회귀는 t에서 선형적으로 스케일링된다. 이는 데이터가 주기적이라고 알려진 경우에도 학습된 모델과 원하는 최적과의 사이의 갭(gap)이 사라지지 않은 것일 의미한다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "요약하면, 더 나은 모델을 훈련하기 위해 데이터 분포의 순환 패턴을 활용하는 문제는 대규모 셋팅에서 대체로 해결되지 않은 문제로 남아 있다. 작업원리 및 이론 분석 본 개시의 실시예에 따르면, 순환 데이터를 이용한 기계 학습의 과제를 해결하기 위한 개선된 솔루션이 제공된 다. 이 솔루션은 푸리에 학습이라고 불리는 새로운 학습 프레임워크를 제안한다. 푸리에 학습은 주기적 데이터 가 생성되는 다양한 애플리케이션에서 사용하는 예측 모델을 학습하는 데에 적용될 수 있다. 예측 모델에 푸리에 학습을 적용하는 방법을 설명하기 전에 먼저 푸리에 학습이 훈련 데이터 내의 주기성을 활 용하여 더 나은 예측 모델을 학습하는 문제(예: 수식의 최적화 문제)를 해결하는 방식을 이론적으로 분석하 고 증명한다. 본 개시의 실시예에서, 제안된 푸리에 학습은 수식의 최적화 문제 세트를 시간-주기 함수를 자연스럽게 포함 하는 함수 공간에서의 단일 최적화 문제로서 해결할 수 있다. 특히, 함수 공간은 하나는 고정된 시점의 모델 스 냅샷을 포함하고 다른 하나는 시간-주기 함수를 포함하는 두 개의 Hilbert공간의 텐서 곱(tensor product)일 수 있다. 아래에서 설명하는 바와 같이 이는 이러한 함수에 대한 부분적인 푸리에 전개로 이어진다는 것이 밝혀졌 다. 볼록 분석 설정하에 스트리밍 확률적 그라디언트 하강법(streaming-stochastic gradient descent, SGD)을 사용하여 푸리에 계수를 학습하는 것도 가능하다. 이론적으로 제안된 푸리에 학습 프레임워크는 두 가지 다른 측면에서 지원될 수 있다: (i) 모델링 관점에서 푸리에 학습은 강하게 볼록하고 실현 가능한 셋팅 하에서 수식 의 최적화 문제와 동등한 함수적 최적화 문제에서 자연스럽게 도출된다; (ii) 최적화 측면에서 스트리밍-SGD 로 업데이트된 계수 함수는 주파수 영역에서 수렴하는 것으로 입증되었다. 실천적인 애플리케이션에 대해서, 푸 리에 학습을 다양한 예측 모델에 통합하여 예측 모델이 보다 정확한 예측 결과를 제공할 수 있도록 한다. 푸리 에 학습과 통합 하면 하나의 단일 모델 프레임워크로 주기적 데이터 예측에 충분할 수 있다. 함수 최적화 문제에 대한 자연 솔루션으로 도출될 수 있는 제안된 푸리에 학습의 이론적 기초가 먼저 소개된다. 본 개시의 실시예에서, 수식의 학습 문제 세트는 Hilbert 공간에서 하나의 단일 학습 문제로 재구성된다. 실 제로 이를 통해 x 와 t를 모두 입력으로 사용하는 통합 모델을 학습할 수 있게 한다. 구체적으로 학습 목적은 아래의 수식와 같은 형태를 취한다. 여기서 기대값은 실행상 데이터세트에 대한 경험적 평균으로 대체될 수 있다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수식에서 는 시점 t에서 생성된 입력 데이터x의 주기성을 활용하기 위해 학습할 모델이며, 는 x 에 대한 진실 레이블이고 , 삼중항 은 시간 의존형 분포 로부터 생성된다.여기서 는 의 분포이고, 는 에 대한 시점 t (예: )의 분포이다. 수식에 따르면 Hilbert공간 에서 손실함수 를 최소화 할 수 있는 모델 을 찾을 것으로 예상된다. 손실함수의 손실은 모델 로부터의 예측 결과와 진실 레이블 사이에서 계산된다. 수식에서 중요한 요소는 을 탐색하는 Hilbert 공간 의 설계이다. 순환 데이터를 이용한 학습 문제의 경우, 연속적이고 주기적이며 단일 시간구간에 유한한 에너지를 갖는 Hilbert공간의 함수에 특히 초점을 맞춘다. 다음 Lemma 1을 통해 발명자들은 수식의 통일된 목적이 수식과 관련되어 있음을 발견하였다. Lemma 1. For in Equation , let"}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": ". If , then minimizes the loss function in . Lemma 1 에서 T는 x의 주기성을 표시한다. 위의 Lemma 1 의 증명 은 다음과 같다. 수식로부터 시작하여 , 임의의 에 대해,"}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 임의의 에 대해, 부등(inequality)은 다음과 같은 가정에서 비롯된다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "Lemma 1은 에 유일한 최소자가 있고, 가 x와 t 모두의 함수로 간주할 때 Hilbert 공간 에 속하 면, 의 최소자는 수식의 솔루션으로 이어진다는 것을 의미한다. 따라서 실현 가능한 셋팅에서 수식는 수식을 푸는 데 프록시 역할을 한다. 위의 증명에 따르면, 실현 가능한 셋팅 및 Lemma 1에 사용된 엄격한 볼 록성(strictly convexity)하에서, 수식에서 지정된 프록시 손실을 최소화하여 수식에 대해 원하는 솔루션 세트를 얻는 것이 가능하다는 것을 나타낸다. 의 또 다른 중요한 요소는 의 설계이다. 여기서는 특히 연속적이고 시간상 주기적이며 단일 구간에 유한 한 에너지를 갖는 함수에 중점을 둔다. 또한, 모든 고정된 t에 대해 수식에서 지정된 바와 같이 중 함수 는 로 퇴화(degenerate)되어야 한다. 이러한 설계에 필요한 두 가지 중요한 요소를 소개하였다. 또한 원(circle)상에서 함수를 정의하는 것은 주기적 함수를 특성화하는 중요한 방법이다. 원 위의 점에 대해 정의되므로 이러한 함수는 점의 각도 정보를 입력으로 사용하므로 당연히 원의 원주에 따라 결정되는 주기를 갖 는다. 최적화를 용이하게 하기 위해 원을 끝점이 서로 붙어 있는 선분으로 보는 직감을 기반으로 이러한 함수에 대해 Hilbert 공간 구조를 추가로 정의한다. 수식는 함수f는 함수f가 유한한 에너지를 갖는, 즉 인 공간에 매핑되고 함수f는 주 기성T를 가지는 주기적 함수, 즉 임을 나타낸다. 밝혀진 바에 따르면, 만약 이면, 가 Hilbert공간을 형성한다. 이 Hilbert 공간은 모델에 대한 입력 특징이 없는 특별한 케이스의 경우, 즉 가 t에만 의존하는 경 우의 요구 사항을 충족한다. x와 t 모두에 의존하는 함수를 포함하는 Hilbert 공간으로 을 더욱 보강(augment)하려면, Hilbert 공간 간의 텐서 곱(tensor product) 개념이 필요한다. 이는 유클리드(Euclidean) 공간의 벡터 간 크로네커 곱 (Kronecker product) 개념에 대한 직접적인 함수 공간 확장이다. 구체적으로, 와 로 각각 표시된 두 개의 Hilbert 공간이 주어지면"}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "와 의 텐서 곱은 이중선형 매핑 으로 결합된 Hilbert 공간 이다. 와 는 함께 다음 특성을 만족시킨다. (i) 및 를 가지는 벡터 세트 는 의 전체 하위 세 트를 형성해야 한다. 이는 이다. (ii) 의 내적(inner product) 은, 임의의 및 에 대 해 을 만족한다. 및 에 대하여 두 개의 정규 직교 기저 함수 세트 및 를 채택하고, 앞서 언급한 특 성을 사용하면 임의의 요소 를 로 확장할 수 있다. 여기서 및 이다. 더욱이 위 문제와 같이, 및 의 경우 동형(isomorphism)이 존재하므로 . 이는 의 선형 결합인 함수를 포함하는 의 동 형을 고려하는 것이 가능함을 의미한다(즉, ). 의 텐서 곱 기반 설계 와의 텐서 곱을 사용하여 를 보강(augment)하려면 Hilbert 공간 의 자연 선택을 로 설정한다. 여기서 and"}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이 는 원주 T의 원(circle)상에서 정의된 t의 추가 차원으로 를 확장하고 이는 를 임의의 고정된 에 대해 시간 t에 대한 주기 함수로 자연스럽게 제한한다. 발 명자들은 다음과 같은 Lemma 2를 발견했는데, 이는 가 Hilbert 공간임을 증명하고 와 사이의 동형을 사용하여 기저 함수를 특징짓는다.Lemma 2. 를 수식에서 정의 된 것으로 한다. 에 대해,"}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "로 하면, 는 Hilbert공간이다. 게다가 와 사이에는 동형이 존 재한다. 즉, 만약 와 가 각각 그리고 에 대한 두 개의 정 규 직교 기저 세트이면, 이고, 여기서 는 에 대한 정규 직교 기저 함수 세트이다. 상기 lemma는 다음에 소개될 에서 의 기본 확장을 통해 를 최적화하는 이론적으로 보장된 알고리 즘에 위한 길을 열어준다. 한편, 는 가벼운 가정 하에서 수식의 솔루션에 의해 점별(point-wise)로 정의 된 함수 가 에 속한다는 점에서 학습 목적에 충분히 일반적이다. 일부 정의와 가정은 아래와 같 이 소개된다. 정의 3(전체 변동 하에서의 연속성). 를 하에서 주어진 x의 y의 조건부 분포로 한다. 임의의 고정 된 t 및 > 0 에 대해 때 하도록 하는 δ > 0이 존재 하는 경우, 는 전체 변동 거리하에서 t에서 연속적인 것으로 간주된다. 가정 4. 다음을 가정한다: (i) 와 는 컴팩트하고 볼록한 세트이다; (ii) 정의 3에서의 는 모두에 대한 전체 변동하에서 연속적이다; (iii) 손실함수 는 모두에 대한 첫 번째 인수(argument)에서 σ-강한-볼록이다; (iv) 의 f(x)는 유계(bounded)이고 일부 상수 K에 대해 이다. 가정 4는 다양한 기계 학습 시스템에 의해 쉽게 충족될 수 있다. 예를 들어 심층 신경망(DNN)은 일반적으로 최 종 출력에 대한 클리핑이 시행될 때 유계한 출력을 갖는다. 손실함수의 균일하고 강한 볼록성은 평균 제곱 손실과 같은 넓은 범위의 *에도 적용된다. 위의 정의와 가정을 통해 발명자들은 또 다른 Lemma인 Lemma 5를 발견하 였다. Lemma 5 . 가정 4에서, 는 주어진 임의의 에 대해 t에서 연속적이다. 또한, . Lemma 5는 가정 4에서 수식의 최적 솔루션 이 에 속함을 의미한다. Lemmas 1과 5를 결합하 면 가정4를 만족하면 수식를 풀어서 원하는 수식의 솔루션 세트를 얻을 수 있음을 알 수 있다. 주기적 데이터를 이용한 푸리에 학습 이제 계속하여 학습 프레임워크인 푸리에 학습을 소개 한다. 이는 데이터 분포의 주기성을 부분 푸리에 전개를 통해 모델 구조에 하드적으로 연결(hard-wire)하고 이의 푸리에 계수 함수를 학습하여 모델을 학습한다. 이를 위해 모델링 측면에서 Lemma 2가 호출 되고 는 다음과 같은 기본 전개로 표현될 수 있다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서 는 i에 대한 의 합이다. 에 대한 기저 함수 세 트는 기본 주파수 1/T를 갖는 삼각 함수 라는 것이 주목된다. 발명자들은 다음 정리(Theorem)에 도달하였다. 정리 6. 인 모든 함수는 푸리에 전개로 표현될 수 있다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "여기서 , 그리고 이다. 정리 6은 주기적 모델을 설계하는 명시적인 방법을 제공하고 시간 특징을 활용할 수 있는 방법을 지정한다. 참 고로, 주기성을 보장하기 위해 원(circle)상에서 정의된 가중된 공간으로 를 구축하는 것은 전적으로 가 능하다. 이를 통해 삼각 함수에서 벗어나 잠재적으로 다른 주기 함수를 사용하여 주기성을 인코딩할 수 있다. 수식으로 표현되는 을 이용하여, 수식의 문제의 솔루션은 와 (즉, 이 제 t와 독립되고 x에만 의존하는 의 푸리에 계수)를 학습하는 것으로 축소되었다. 또한 사인 및 코 사인 성분은 t에 의존한다. 수식은 의 부분 푸리에 전개 형태를 취하므로, 이러한 학습 방법을 \"푸리에 학습\"이라고 부를 수 있다. 푸리에 학습을 통해 디자이너는 원래 모델 디자인을 유지할 수 있지만 동시에 마지막 히든 레이어의 전문가의 조언을 시간 의존적인 방식으로 혼합할 수 있다. 예측 모델에서 t의 명시적 역할은 특징 t가 의 형 태로 모델에 암시적으로 추가될 때 요구되는 어려운 특징 엔지니어링을 우회한다. 목표는 이제 주파수 영역에서 계수 함수를 학습하는 쪽으로 이동한다. 다루기 쉬운 학습을 위해 컷오프 주파수 가 도입될 수 있으므로 의 절단형 푸리에 전개가 대신 다음과 같이 표현될 수 있다:"}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "여기서 N은 미리 정해진 수로 1보다 큰 정수 이다. 수식의 절단형 푸리에 전개는 수식의 푸리에 전개에 대한 근사치이다. 수식에서 모두에 대한 근사 오차는 다음과 같이 결정될 수 있는 와 같이 표시될 수 있다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "실제 시스템에서는 모든 에 대해 보통적으로 0을 가정할 수 있다. 따 라서 적절하게 N을 선택하면 모델 파라미터의 양뿐만 아니라 근사 오차도 제한될 수 있다. 수식의 푸리에 학습을 위한 푸리에 전개에서, 모델 의 예측 결과를 생성하기 위해서는 푸리에 계 수 및 를 결정해야 한다. 푸리에 계수 및 는 다양한 체제 (regime)하에서 학습할 수 있는 x에 의존하는 계수 함수로 간주될 수 있다. 예를 들어, 이들은 함수 최적화 알 고리즘을 사용하여 논파라메트릭적으로(non-parametrically) 학습될 수 있다. 일부 실시예에서, 푸리에 계수 및 가 신경망과 같은 파라메트릭 형태를 갖는 다면, 확 률적 그라디언트 하강법은 표준 가정하에서 특정 속도로 정지점으로 수렴하는 것으로 알려져 있으며, 이에 대해 서는 아래에서 자세히 소개한다. 일부 실시예에서, 위의 파라메트릭 프레임워크외에, 푸리에 학습은 논파라메트 릭 체제에도 적합하며, 이에 대해서는 아래에서 자세히 소개한다. 푸리에 학습 기반의 기계 학습 시스템 다음에서는 대규모 기계 학습 시나리오에 푸리에 학습을 적용하기 위한 신경망을 이용한 및 의 파라미터화에 대해 설명한다. 위의 이론 분석은 푸리에 학습을 기반으로 구축된 모델은 훈련 데이터의 주기성을 직관적으로 활용할 수 있으며 주기적 함수로 표현될 수 있음을 나타낸다. 따라서 푸리에 학습은 기계 학습 기반 예측 모델에 적용할 수 있다. 본 발명의 실시예에서는 수식의 의 푸리에 전개에 따라 를 특정 시점 t에서 생성된 입력 데 이터 샘플과 관련된 정보로 보는 것을 제안한다. 입력 데이터 샘플은 주기적 데이터의 데이터 샘플일 수 있다. 푸리에 전개 결과는 푸리에 전개에 기초하여 결정될 수 있으며 입력 데이터 샘플에 대한 예측 결과는 푸리에 전 개 결과에 기초하여 결정된다. 본 개시의 일부 예시적인 실시예에 따른 푸리에 학습을 이용한 기계 학습 시스템의 블록도를 도시하는 도 2를 참조한다. 기계 학습 시스템은 환경에서 기계 학습 모델로서 구현될 수 있다. 도시된 바와 같이, 기계 학습 시스템은 예측 모델 및 푸리에 레이어를 포함한다. 예측 모델은 예측 작업을 구현하기 위해 임의의 모델 아키텍처로 구성될 수 있다. 본 개시의 실시예에서, 예측 모델에 의해 처리될 입력 데이터는 특정 주기성(T로 표시됨)을 갖는 주기적 데이터이다. 예측 모델 에 대한 입력은 특정 시점 t에서 생성된 입력 데이터 샘플이다. 푸리에 레이어는 입력 데이터 내의 주기성을 고려하여 보다 정확한 예측 결과를 생성할 수 있도록 도입되었다. 예측 모델은 입력 데이터의 주 기성을 활용할 수도 있고 활용하지 않을 수도 있는 임의의 방식으로 구성될 수 있다. 두 케이스는 모두 푸리에레이어를 추가하면 더 나아가서 주기성을 활용할 수 있기 때문이다. 푸리에 레이어는 다음 직관에 의해 설계된다: x가 오리지널 예측 모델의 마지막 히든 레리어의 출력으로 간주하면 수식은 도 2에서 나타낸 아키텍처를 갖는 네트워크의 출력 레이어로 볼 수 있다. 구체적으로, 푸 리에 레이어는 먼저 x를 와 로 변환 한 다음 요소별로 기저 벡터 SIN 및 COS와 곱 하여 (2N + 1) 차원 결과를 얻는다. 이 결과를 합산하여 스칼라 출력(scalar output)을 얻는다. 특히, 모든 n ≥ 1에 대해 = =0일 때 최종 출력은 과 같고, 이는 그 자체로 오리지널 모델의 출력으로 해석될 수 있다. 이는 오리지널 모델의 출력 레이어를 푸리에 레이어로 대체함으로써 용량을 증 가시키며 어려운 특징 엔지니어링을 회피할 수 있음을 의미한다. 특히, 푸리에 레이어는 예측 모델에 의해 추출된 입력 데이터 샘플의 특징 표현을 수신한다. 예측 모 델은 일반적으로 두 부분으로 구성되는 것으로 간주할 수 있다. 하나는 입력 데이터 샘플 내의 히든 특징 을 추출하는 부분이고 다른 하나는 최종 히든 특징을 기반으로 모델 출력을 결정하는 부분이다. 일부 실시예에 서, 예측 모델은 입력 데이터 샘플을 수신하기 위한 입력 레이어, 입력 데이터 샘플을 처리하고 입력 데이 터 샘플 내의 히든 특징을 특성화하기 위한 특징 표현을 생성하는 하나 이상의 히든 레이어 및 모델 출력을 생 성하기 위한 출력 레이어를 포함하는 복수의 레이어를 포함할 수 있다. 예측 모델의 레이어들은 레이어별 로 연결되어 있으며, 한 레이어의 출력이 다음 레이어의 입력으로 제공된다. 일부 실시예에서, 예측 모델의 마지막 히든 레이어에서 추출된 특징 표현은 입력으로서 푸리에 레이 어에 제공된다. 이 특징 표현은 로 표시된다. 일반적으로 입력 데이터 샘플은 중복 정보를 포함할 수 있으며 더 높은 차원일 수 있다. 예측 모델에서의 특징 추출을 통해 특징 표현은 상대적으로 작은 차원으로 입 력 데이터 샘플 내의 유용한 특징 정보를 특성화할 수 있다. 푸리에 레이어는 특징 표현 를 추가로 처리 하여 입력 데이터 샘플에 대한 예측 결과를 생성할 수 있다. 특징 표현 는 차원 d1이고, 입력 데이터 샘플에 대한 예측 결과는 차원 d2인 것을 가정한다. 특징 표현 의 차원과 예측 결과(d2)의 차원은 예측 모델의 구성에 의존한다. 일반적으로 d1은 1보다 크고, d2는 1 또는 그 이상일 수 있다. 예를 들어, 예측 결과는 사용자가 타겟 아이템에 관심을 가질 확률을 나타내는 1차원 출력일 수도 있고, 사용자 복수의 아이템에 관심을 가질 확률을 나타내는 다차원 출력일 수도 있다. 푸리에 레이어의 입력(즉, 특징 표현 )과 출력(즉, 예측 결과)이 주어진 경우, 푸리에 레이어의 처 리는 d1의 차원을 가지는 입력을 d2의 차원을 가지는 출력으로 매핑하는 것으로 간주할 수 있다. 푸리에 레이어 의 모델 구조는 푸리에 전개에 기초하여 이러한 매핑을 구현하도록 설계될 수 있다. 도시된 바와 같이, 푸리에 레이어는 푸리에 전개 중의 푸리에 계수 를 생성하기 위한 매핑 모델 , 및 푸리에 전개 중의 푸리에 계수 를 생성하기 위한 매핑 모델을 포함한다. 미리 정해진 수 (N+1)개의 항을 갖는 수식의 절단형 푸리에 전개 다음, 매핑 모델은 d1의 차원을 가지는 특징 표현 를 N의 차원을 가지는 출력으로 변환하도록 구성될 수 있고, 매핑 모델은 d1의 차원을 가지는 특징 표 현 를 (N+1)의 차원을 가지는 출력으로 변환하도록 구성될 수 있다. 매핑 모델의 출력 중 N개의 요소는 N개의 푸리에 계수 로 결정될 수 있다. 매핑 모델의 출력 중 (N+1)개 요소는 (N+1)개의 푸리에 계수 로 결정될 수 있다. 매핑 모델 및 매핑 모델은 임의의 기계 학습 아키텍처에 기초하여 구성될 수 있다. 일부 실시예에서, 매핑 모델 및 매핑 모델은 활성화 함수 없이 구성될 수 있다. 일반적으로 기계 학습 모델에 적용되는 활성화 함수(예: 시그모이드 함수, tanh 함수, ReLU 함수)는 모델 출력의 진폭을 특정 범위로 제한할 수 있다. 푸리에 전개에서는 푸리에 계수의 진폭에 대한 명시적인 제한이 없으므로 매핑 모델과 매핑 모델은활성화가 없이 구성될 수 있다. 푸리에 전개는 일반적으로 사인 함수 기반 성분과 코사인 함수 기반 성분으로 구성된다. 따라서, 도 2에 도시된 바와 같이, 푸리에 레이어는 푸리에 전개 중 사인 성분에 대한 값을 결정하기 위한 사인 함수 유닛 및 푸리에 전개 중 코사인 성분에 대한 값을 결정하기 위한 코사인 함수 유닛을 더 포함한다. 수식에 서 나타난 바와 같이, 사인 성분은 T의 주기성을 갖는 주기 함수인 시점t에 의존한 사인 함수를 기반으로 하며, 코사인 성분은 T의 주기성을 갖는 주기 함수인 시점t에 의존한 코사인 함수를 기반으로 한다. 사인 함수 유닛은 사인 성분 값의 세트를 열 벡터 로 제공할 수 있고, 코사인 함수 유닛은 코사인 성분 값의 세트를 열 벡터 로 제공할 수 있다. 일부 실시예에서, 시간은 에서 가변적이다. 즉, 입력 데이터 샘플이 생성된 실제 시점은 예를 들어 mod 연산을 통해 T 주기 내의 점으로 변환된다. N개의 사인 성분 값 는 사인 함수의 주파수를 N 회 이동시킴 으로써 생성될 수 있으며, (N +1)개의 코사인 성분 값 는 사인 함수의 주파수를 (N +1)회만큼 이동시킴으로 써 생성될 수 있다. 0의 위상부터 시작하여 위상이 이동할 때마다 사인 함수와 코사인 함수에 의 위상 변이가 적용된다. 사인 함수와 코사인 함수는 동일한 횟수 (N +1)회만큼 위상 변이될 수 있으나, 초기에는 제로 위상의 사인 성분 값이 0이라는 점에 유의한다. 푸리에 레이어에서는 각 시점에서 생성된 입력 데이터 샘플에 대응하여 푸리에 계수 및 는 실시간으로 결정된다. 일부 실시예에서, 사인 및 코사인 성분 값 및 은 미리 계산되어 사용을 위해 메모리에 저장될 수 있다. N개의 사인 성분 값과 N개의 푸리에 계수는 승산기에 제공된다. 승산기는 N개의 곱을 생성하기 위한 N개의 사인 성분 값과 N개의 푸리에 계수에 대한 요소별 곱셈을 수행하도록 구성된다. (N +1)개의 코사인 성분 값과 (N +1)개의 푸리에 계수는 승산기에 제공된다. 승산기는 (N+1)개의 곱을 생성하기 위한 (N+1)개 의 코사인 성분 값과 (N +1)개의 푸리에 계수에 대한 요소별 곱셈을 수행하도록 구성된다. (2N +1)의 곱은 푸리 에 전개와 관련된 개별 항에 해당한다. d2 차원의 예측 결과를 얻기 위해 승산기로부터의 N개의 곱은 매핑 모델에 입력될 수 있으며, 승산기 로부터의 (N +1)개의 곱은 매핑 모델에 입력될 수 있다. 매핑 모델은 승산기로부터의 N개 의 곱을 d2차원을 갖는 제1 중간 전개 결과로 변환하도록 구성될 수 있다. 매핑 모델은 승산기로부터 의 (N +1)개의 곱을 d2차원을 갖는 제2 중간 전개 결과로 변환하도록 구성될 수 있다. 제1 및 제2 중간 전개 결 과는 푸리에 전개 결과를 제공하기 위해 제1 및 제2 중간 전개 결과에 대한 요소별 합산을 수행하도록 구성된 집산기(aggregator)에 제공될 수 있다. 상기 푸리에 전개 결과는 d2차원을 갖는 입력 데이터 샘플에 대한 예측 결과로 결정될 수 있다. 일부 실시예 에서 , 예측 결과가 1차원 출력인 경우, 푸리에 레이어에서 매핑 모델(236, 246)이 생략될 수 있다. 이 경우, 승산기(234, 244)로부터의 곱은 합산되어 예측 결과로 결정되는 푸리에 전개 결과를 제공할 수 있다. 일부 실시예에서, 매핑 모델 및 매핑 모델은 MLP(Multi-Layer Perceptron) 모델로 구성 될 수 있다. 일부 실시예에서, 매핑 모델 및 매핑 모델은 MLP 모델로 구성 될 수 있다. 따라서 푸리에 레이어는 푸리에-MLP(F-MLP)레이어로 간주할 수 있다. 푸리에 레이어 중 매핑 모델(220, 240, 236, 246)의 파라미터 값은 훈련 과정을 통해 결정될 수 있다. 일 부 실시예에서, 이러한 매핑 모델은 예측 모델로 훈련될 수 있다. 훈련 데이터는 예측 모델에 대한 입력 데이터 샘플 및 해당 입력 데이터 샘플에 대한 대응되는 진실 레이블을 나타내는 레이블링 정보를 포함할 수 있다. 일부 실시예에서, 푸리에 레이어의 매핑 모델은 예측 모델로 엔드-투-엔드 방식으로 훈련될 수 있다. 일부 실시예에서, 예측 모델은 먼저 훈련된 다음 푸리에 레이어 중 매핑 모델과 함께 재훈련 될 수 있다.. 일부 실시예 에서 , 푸리에 레이어는 와 같이 일반화될 수 있다 . 입력 차원 d1 및 출력 차원 d2 를 갖는 F-MLP의 경우 처리는 다음과 같이 표현될 수 있다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "여기서 는 푸리에 레이서에 대한 입력이고, 는 x를 N차원 벡터로 매핑하는 활성화 없는 정규적인 MLP이다. 는 파라미터 값이다. SIN과 COS는 행 벡터 와 로 총 d2 번 쌓인 매트릭스이다. 연산자 는 하다 마드(Hadamard) 곱이다. d2 =1일 때(출력이 1차원임을 의미함) 과 는 및 로 병합될 수 있고, 이는 각각 수식에서의 과 의 역할를 한다. 푸리에 분석과 딥러닝 시스템을 결합하는 것을 제안하는 몇 가지 방식이 있다. 그러나 이러한 방식의 대부분은 시간에 따른 분포의 주기성에 초점을 맞추기보다는 입력 데이터 자체의 분포 내에서 고유한 고주파 성분의 학습 을 목표로 하고 있다. 특히, 발명자들은 예측 모델의 기존 설계에서 본 개시의 푸리에 레이어를 구현 하면 모델 의 각 처리 유닛의 물리적 의미가 근본적으로 변경된다는 점을 관찰 했다. 정규적인 모델에서 각 처리 유닛은 시간이 지남에 따라 결정을 변경하는 전문가이고; 본 개시의 푸리에 레이어 하에서, 각 처리 유닛은 주어진 주 파수에서 시간이 지남에 따라 자신의 결정을 얼마나 급격하게 변경하는지 결정하는 전문가의 주파수 성분을 보 유한다. 전자는 각 전문가에 대해 지속적으로 변화하는 최적값을 추적하기 위한 온라인 학습 알고리즘을 설계해 야 하는 반면, 후자의 경우 삼각함수를 이용한 보간법을 사용하여 미래 최적값을 예측할 수 있다. 이는 온라인 학습 방식에 비해 이점을 제공한다. 도 2의 예시적인 실시예에서, 푸리에 레이어는 예측 모델에 대한 출력 레이어로 도입되어, 따라서 그 출력이 입력 데이터 샘플에 대한 예측 결과로 결정된다. 일부 실시 예에서, 푸리에 레이어는 완전한 예측 모델(그 자신의 출력 레이어을 포함함)과 같이 동작할 수 있고, 푸리에 레이어로부터의 출력과 예측 모델로부터의 출력이 집산(aggregate)되어 최종 예측 결과를 생성한다. 도 3은 이러한 실시예에 따른 기계 학습 시스템을 도시한다. 도 3에 도시된 바와 같이, 예측 모델은 다른 레이어들 중에서 마지막 히든 레이어로부터 특징 표현 를 수신하는 출력 레이어를 포함한다. 예측 모델의 출력 레이어는 특징 표현 를 처리하고, 중간 예측 결과를 생성할 수 있다. 출력 레이어에서의 처리는 예측 모델의 구성에 따라 달라질 수 있 으며, 이는 서로 다른 예측 작업에서 달라질 수 있다. 도 2와 관련된 실시예에 따라 논의된 바와 같이, 푸리에 레이어도 마지막 히든 레이어로부터 특징 표현 를 수신 하고 푸리에 전개 결과에 기초하여 중간 예 측 결과를 생성할 수 있다. 기계 학습 시스템은 예측 모델과 푸리에 레이어로부터의 두 개의 중간 예측 결과를 혼합하도록 구성된 집산기를 더 포함할 수 있다. 예를 들어, 집산기는 두 개의 중간 예측 결과의 가중 합을 결정 할 수 있다. 중간 예측 결과의 집산은 다음과 같이 표현될 수 있다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "여기서 는 입력 데이터 샘플에 대한 예측 결과를 나타낸다. 는 예측 모델의 출력 레이어에 의한 중간 예측 결과를 나타내고; 는 푸리에 레이어에 의해 생성된 중간 예측 결과를 나타낸다. 는 두 개의 중간 예측 결과에 가중치를 부여하는 데 사용되는 파라미터이다. 는 미리 정해진 값, 예를 들어 0.5 또는 임의의 다른 값일 수 있다. 일부 실시예에서, 예측 모델은 복잡한 구조를 가질 수 있으며, 예를 들어, 서로 다른 모델 구조를 갖는 복 수의 서브모델을 포함할 수 있다. 이 경우, 푸리에 레이어에 대한 입력은 신중하게 설계될 수 있다. 도 3 은 그러한 실시예에 따른 기계 학습 시스템을 도시한다. 도 4에 예시된 바와 같이, 예측 모델은 서브모델(410-1), 쪋, 서브모델(410-K)(논의의 목적으로 통합적으 로 또는 개별적으로 서브모델로 지칭됨)과 같은 복수의 서브모델(예를 들어, K 개의 서브모델)을 포함할 수 있다. K는 1보다 큰 정수이다. 서브모델의 출력은 모델의 출력을 제공하기 위해 예측 모델의 출력 레이 어에서 합산될 수 있다. 이 경우 , 출력 레이어는 K개의 서브모델로부터의 각각의 출력에 대한 합산을 수행하기 위한 집산기를 포함할 수 있다. 따라서 예측 모델은 와 같이 같이 표현될 수 있다. 여기서 는 m 번째 서브모델 의 출력을 나타낸다. 도 4에 도시된 예측 모델의 구조를 살펴보면, 서브모델은 마지막 히든 레이어에서 입력 데이터 샘플 로부터 특징 표현을 추출하고 상기 특징 표현에 기초하여 출력 레이어에서 자신의 출력을 결정할 수 있다. 서브 모델로부터의 특징 표현은 특징표현 를 생성하여 푸리에 레이어로 입력되기 위해 집산될 수 있다. 일부 실시예에서, 서브모델로부터의 특징 표현은 서로 다른 차원일 수 있다. 도 4의 실시예에서, 서브모델 로부터의 특징 표현을 집산하기 위해, 기계 학습 모델은 서브모델로부터의 서로 다른 차원을 갖 는 각각의 특징 표현을 동일한 차원을 갖는 특징 표현으로 변환하기 위해 차원 정렬 레이어를 더 포함할 수 있다. 일부 실시예에서, 차원 정렬 레이어는 서브모델 중 하나의 특징 표현을 동일한 차원을 갖는 특징 표현으로 변환하도록 각각 구성된 복수의 MLP를 포함할 수 있다. 푸리에 레이어은 입력에 대해 선형 변환을 수행하므로, 차원 정렬 레이어에서 생성된 동일한 차원의 특징 표현을 합산하여 특징 표현 를 얻어 푸리에 레이어로 입력할 수 있다. 이 경우, 차원 정렬 레이어 는 서브모델로부터의 서로 다른 차원을 갖는 특징 표현을 d1 차원의 특징 표현으로 변환할 수 있다. 도 4에서는, 푸리에 레이어로부터의 출력이 도 3과 같은 집산기에 의해 예측 모델로부터의 출력 과 집산되는 것이 도시되어 있다. 다른 실시예에서, 특징 표현에 대한 처리는 도 2에 도시된 시스템에 통 합될 수 있다. 기계 학습 시스템의 훈련 푸리에 레이어의 훈련은 스트리밍-SGD 절차를 따라 예측 모델과 연합하여 수행된다. 이 절차는 실제로 샘 플 데이터 가 필요하는 표준 SGD와 다르다. 하지만, 데이터가 순차적 으로 도착하는 실시간 업데이트 요구 사항으로 인해 많은 온라인 애플리케이션에 있어서 로부터의 샘플링 이 어렵다. 여기서는 스트리밍-SGD를 사용하면 여전히 우수한 실천 성능과 수렴을 보장하면서 상기 이슈를 방지 할 수 있음을 보여준다.훈련 절차는 다음과 같다. 및 는 각각 및 에 의해 파라미터화 될 수 있고, 여기서 및 는 신경망 파라미터이다. 순환 데이터의 경우, 데이터의 τ-번째 미니 배치는 k-번째 순환(cycle)에서 수집될 수 있으며, 모델은 다음 업데이트 규칙으로 업데이트 될 수 있다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "여기서 및 는 수집된 데이터의 미니 배치를 사용하여 계산된 그라디언트이다:"}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "여기서 는 수식로 계산되며, 는 이 데이터의 미니 배치상의 수식의 손실의 경험적 버전"}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "이다. 전체적인 훈련 절차는 도 5와 같은 알고리즘 500에 요약되어 있다. 이에 대한 수렴 분석은 다음 과 같다. 스트리밍-SGD를 사용하여 푸리에 학습을 기반으로 하는 기계 학습 시스템을 훈련할 경우의 수렴 특성을 다음과 같이 논의된다. 앞서 설명한 바를 다시 돌이키면, 절단형 를 사용하면 수식의 문제가 주파 수 영역에서 아래 수식의 최적을 찾는 것으로 축소된다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "수식의 최적 계수 함수 세트는 와 로 표시된다. 해당 모델 는 다음과 같이 표현될 수 있다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "다음에서는 먼저 일반적인 비볼록 셋팅하에서 스트리밍-SGD에 대한 그라디언트 노름 수렴(gradient norm convergence) 결과를 보여 준다. 그 다음 강한 볼록성의 가정하의 글로벌 수렴 결과를 도입한다. 그 전에 몇 가 지 추가 가정이 도입된다. 가정 7. 다음을 가정한다: (i) 모든 에 대해 업데이트 방향의 두 번째 모멘트는 일부 에 대한 와 같이 제한되고 여 기서 는 모든 및 에 대해 및 에 의해 생성된 최소 σ-대수(algebra)이다. 또한, 모든 에 대해 하도록 하는 이 존재하는 것으로 가정된 다. 가정 7은 업데이트 방향의 제한된 두 번째 모멘트와 그라디언트의 Lipschitzness를 가정한다. 이 들은 일반적으 로 SGD 유형 알고리즘의 수렴 분석에 필요한다. 다음 결과는 적절한 학습률을 갖는 스트리밍-SGD가 비볼록함과 강한 볼록함의 셋팅하에서 수렴을 달성하는 것을 보여준다. 정리 8 (스트리밍-SGD의 수렴). 가정 4의 (i) 및 (ii) 그리고 가정 7이 유지되도록 하고, 를 모든 및 을 결합하는 연합 파라미터 벡터에 대한 그라디언트로 정 의한다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "하도록 하면, 이다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 22, "content": "하도록 하면, 이다. 더욱이, L이 및 에 대해 σ-강한 볼록인 경우, 인 를 취하고, 를 회득하되, 여기서 를 가정한다. 간단히 말해서, 학습 프레임워크는 일반적인 비볼록 셋팅하세어 의 수렴율을 제공하고 강한 볼록 셋팅하에서 의 수렴율을 제공한다. 가 더 도출되면, 의 전반적인 학습 오차는 임의로 작게 구동될 수 있다. 동적 회귀가 데이터 생성 분포의 변화 속도와 확률적 그 라디언트의 분산(variance) 두 가지 모두에 의해 영향을 받는 온라인 학습 벤치마크에 비해, 푸리에 학습은 훨 씬 작은 학습 오차를 제공하므로 많은 실천 시나리오에서 잠재적으로 훨씬 더 나은 성능을 제공한다. 위의 파라메트릭 프레임워크와 별도로, 일부 실시예에서 제안된 푸리에 학습은 논파라메트릭 체제에도 적합한다. 여기서 an 및 bn은 아래와 같이 직접 업데이트된다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 23, "content": "의 기능적 그라디언트는 종종 Dirac의 δ-함수가 포함되어 불연속 업데이트가 발생하므로 대신 기능적 그 라디언트를 커널 임베딩으로 대체한다. 구체적으로 말하면 는 최소 고유 값이 0에서 멀어지게 제한된 양의 정부호 커널(positive definite kernel)인 경우, 아래 수식으로 한다."}
{"patent_id": "10-2024-7026361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 24, "content": "커널 임베딩이 각 반복에서 지속적인 및 의 업데이트를 생성하는 것은 쉽게 검증할 수 있다. 동시에 및 는 정확한 그라디언트에 \"충분히 가깝고\" 수렴 보장을 유지한다(Yang et al., 2019). 및 를 0으로 초기화 하면 및 는 유한한 커널 세트의 선형 결합으로 작성할 수 있다. 논파라메트릭 케이스에 대한 수렴 결과는 아래 정리 9에서 주어진다. 정리 9. 가정 4와 가정 7이 유지되도록 한다. 수식에서 정의된 바와 같이 및 이 반복 ( k,τ )에서의 를 이용한 기능적 그라디언트의 커널 임베딩이 되도록 한다. 하도록 한다. 다음, 그리고 이고, 여기서 및 는 수식에서 정의 된다. 예시 프로세스 도 6은 본 개시의 일부 예시적인 실시예에 따른 푸리에 학습을 위한 프로세스의 흐름도를 도시한다. 프로 세스는 기계 학습 시스템에서 구현될 수 있거나, 입력 데이터를 기계 학습 시스템에 적용하여 대응하는 예측 작업을 수행 할 수 있는 모델 적용 시스템에 의해 구현될 수 있다. 논의의 목적으로, 프로 세스를 논의하기 위해 도 1을 참조한다. 블록에서, 모델 적용 시스템은 예측 모델로부터 입력 데이터 샘플의 특징 표현을 획득한다. 예측 모 델은 주기성을 가진 입력 데이터를 처리하도록 구성된다. 입력 데이터 샘플은 일정 주기 내 시점에서 생성된 입 력 데이터의 샘플이다. 블록에서, 모델 적용 시스템은 특징 표현을 제1 매핑 모델에 적용함으로써 푸리에 전개 중 제1 성분 에 대한 제1 푸리에 계수를 결정한다. 상기 푸리에 전개는 주기성을 가지고, 상기 시점 및 상기 특징 표현에 의 존한다. 블록에서, 모델 적용 시스템은 특징 표현을 제2 매핑 모델에 적용함으로써 푸리에 전개 중 제2 성분에 대한 제2 푸리에 계수를 결정한다. 블록에서, 모델 적용 시스템은 푸리에 전개 중 제1 푸리에 계수와 상기 제2 푸리에 계수를 기반으로 푸리에 전개 결과를 결정한다. 블록에서, 모델 적용 시스템은 푸리에 전개 결과를 기반으로 입력 데 이터 샘플에 대한 예측 결과를 결정한다. 일부 실시예에서, 푸리에 전개는 미리 정해진 개수의 항을 갖는 절단형 푸리에 전개를 포함하고, 제1 푸리에 계 수의 개수와 제2 푸리에 계수의 개수는 상기 미리 정해진 개수에 기초한다. 일부 실시예에서, 제1 성분은 상기 시점에 의존하고 상기 주기성을 갖는 사인 함수에 기초하고, 제2 성분은 상 기 주기성을 갖는 코사인 함수에 기초한다. 일부 실시예에서, 푸리에 전개 결과를 결정하기 위해, 모델 적용 시스템은 사인 함수의 주파수를 미리 정 해진 횟수만큼 이동시킴으로써 상기 제1 성분에 대한 제1 성분 값 세트를 결정하고, 코사인 함수의 주파수를 상 기 미리 정해진 횟수만큼 이동시킴으로써 상기 제2 성분에 대한 제2 성분 값 세트를 결정한다. 모델 적용 시스템은 제1 푸리에 계수와 제1 성분 값을 각각 곱하고, 제2 푸리에 계수와 제2 성분 값을 곱하여 푸리에 전 개 결과를 결정한다. 푸리에 전개 결과를 결정하기 위해, 모델 적용 시스템 제1 푸리에 계수와 제1 성분 값을 곱하여 제1 곱 (product)을 계산하고, 제2 푸리에 계수와 제2 성분 값을 곱하여 제2 곱을 계산한다. 모델 적용 시스템은 제3 매핑 모델을 이용하여 제1 곱을 제1 중간 전개 결과에 매핑하고, 제4 매핑 모델을 이용하여 제2 곱을 제2 중간 전개 결과에 매핑한다. 모델 적용 시스템은 제1 중간 전개 결과와 제2 중간 전개 결과를 집산하여 상기 푸리에 전개 결과를 결정한다. 일부 실시예에서, 예측 결과를 결정하기 위해, 모델 적용 시스템은 푸리에 전개 결과로부터 제1 중간 예측 결과를 결정하고, 특징 표현을 기반으로 예측 모델의 출력 레이어(layer)로부터 생성된 제2 중간 예측 결과를 획득한다. 모델 적용 시스템은 제1 중간 예측 결과와 제2 중간 예측 결과를 집산하여 예측 결과를 결정한 다. 일부 실시예에서, 예측 모델 예측 모델은 입력 데이터 샘플로부터 복수의 특징 표현을 추출하도록 구성된 복수 의 서브모델(sub-model)을 포함한다. 일부 실시예에서, 모델 적용 시스템은 복수의 서브모델로부터 복수의 특징 표현을 획득하고, 복수의 특징 표현을 집산하여 특징 표현을 생성한다. 일부 실시예에서, 제1 매핑 모델과 제2 매핑 모델은 활성화 함수 없이 구축된다. 일부 실시예에서, 제3 매핑 모 델 및 제4 매핑 모델은 활성화 함수 없이 구축된다. 일부 실시예에서, 매핑 모델은 예측 모델과 연합하여 훈련 된다. 예시 시스템/디바이스 도 7은 본 개시의 예시적인 실시예를 구현하는데 적합한 예시적인 컴퓨팅 시스템/디바이스의 블록도를 도 시한다. 모델 적용 시스템 및/또는 모델 훈련 시스템은 시스템/디바이스로서 구현되거나 시스템 /디바이스에 포함될 수 있다. 시스템/디바이스는 범용 컴퓨터 또는 컴퓨터 시스템, 물리적 컴퓨팅 시 스템/디바이스, 또는 휴대용 전자 디바이스이거나 분산형 클라우드 컴퓨팅 환경에서 실행될 수 있다. 분산형 클 라우드 컴퓨팅 환경에서는 통신 네트워크를 통해 연결된 원격 처리 디바이스에 의해 작업이 수행된다. 시스템/ 디바이스는 도 6 의 프로세스를 구현하는데 사용될 수 있다. 도시된 바와 같이 , 시스템/디바이스는 읽기 전용 메모리(ROM)에 저장된 프로그램 또는 저장 유닛 으로부터 랜덤 접근 메모리(Random Access Memory, RAM)로 로드된 프로그램에 따라, 다양한 프로세스를 수 행할 수 있는 프로세서를 포함한다. RAM에는 프로세서가 다양한 처리 등을 수행할 때 필요한 데 이터도 필요에 따라 저장된다. 프로세서, ROM 및 RAM은 버스를 통해 서로 연결된다. 입출 력(I/O) 인터페이스도 버스에 연결된다. 프로세서는 로컬 기술 네트워크에 적합한 임의의 유형일 수 있으며 비제한적인 예로서 다음 중 하나 이상 을 포함할 수 있다: 범용 컴퓨터, 전용 컴퓨터, 마이크로프로세서, 디지털 시그널 프로세서(DSP), 그래픽 처리 유닛(GPU), 공동 프로세서, 멀티코어 프로세서 아키텍처에 기반한 프로세서. 시스템/디바이스는 메인 프로 세서를 동기화하는 클록에 시간적으로 종속되는 애플리케이션별 집적회로 칩과 같은 다중 프로세서를 가질 수 있다. 시스템/디바이스의 복수의 구성요소는, 키보드, 마우스 등과 같은 입력 유닛; 음극선관(CRT), 액정 디스플레이(LCD) 등과 같은 디스플레이를 포함하는 출력 유닛; 스피커 등;을 포함하는 I/O인터페이스(70 5)와 연결되고, 디스크, 광디스크 등과 같은 저장 유닛 및 네트워크 카드, 모뎀, 무선 트랜시버 등과 같은 통신 유닛과 연결된다. 통신 유닛은 시스템/디바이스가 인터넷, 각종 통신망 등의 통신 네트워 크를 통해 다른 디바이스들과 정보/데이터를 교환할 수 있도록 한다. 프로세스와 같이 위에 설명된 방법 및 프로세스는 프로세서에 의해 수행될 수도 있다. 일부 실시예에 서, 프로세스는 컴퓨터 소프트웨어 프로그램 또는 컴퓨터 판독 가능 매체(예: 저장 유닛)에 유형적으 로 포함된 컴퓨터 프로그램 제품으로 구현될 수 있다. 일부 실시예에서, 컴퓨터 프로그램은 ROM 및/또는 통신 유닛을 통해 시스템/디바이스에 부분적으로 또는 완전히 로드 및/또는 구현될 수 있다. 컴퓨터 프로그램은 연관된 프로세서에 의해 실행되는 컴퓨터 실행 가능 명령어를 포함한다. 컴퓨터 프로그램이 RAM에 로드되고 프로세서에 의해 실행될 때, 위에서 설명된 프로세스의 하나 이상의 동작이 구 현될 수 있다. 대안적으로, 프로세서는 다른 실시예에서 프로세스를 실행하기 위해 임의의 다른 적절한 방식(예를 들어, 펌웨어 수단)을 통해 구성될 수 있다. 본 개시의 일부 예시적인 실시예에 따르면, 장치의 프로세서에 의해 실행될 때 장치로 하여금 위에서 설명된 방 법 중 어느 하나의 단계를 수행하게 하는 명령어를 포함하는 컴퓨터 프로그램 제품이 제공 된다. 본 개시의 일부 예시적인 실시예에 따르면, 장치로 하여금 적어도 위에서 설명된 방법 중 어느 하나의 단계를 수행하게 하는 프로그램 명령어를 포함하는 컴퓨터 판독 가능 매체가 제공 된다. 컴퓨터 판독 가능 매체는 일부 실시예에서 비일시적 컴퓨터 판독 가능 매체일 수 있다. 제8 측면에서, 본 개시의 예시적인 실시예는 장치로 하여금 적어도 위에서 설명된 제2 측면의 방법을 수행하게 하는 프로그램 명령어을 포함하는 컴퓨터 판독 가능 매체를 제공한다. 컴퓨터 판독 가능 매체는 일부 실시예에 서 비일시적 컴퓨터 판독 가능 매체일 수 있다. 본 개시의 다양한 예시적인 실시예는 하드웨어나 전용 회로, 소프트웨어, 로직 또는 이들의 임의의 조합으로 구 현될 수 있다. 일부 측면은 하드웨어로 구현될 수 있는 반면, 다른 측면은 컨트롤러, 마이크로프로세서 또는 기 타 컴퓨팅 디바이스에 의해 실행될 수 있는 펌웨어 또는 소프트웨어로 구현될 수 있다. 본 개시의 예시적인 실 시예의 다양한 측면이 블록도, 흐름도로서 또는 일부 다른 도면적인 표현을 사용하여 도시되고 설명되지만 , 본 문에서 설명된 블록, 장치, 시스템, 기술 또는 방법은 비제한적인 예로서, 하드웨어, 소프트웨어, 펌웨어, 전용 회로 또는 로직, 범용 하드웨어 또는 컨트롤러 또는 기타 컴퓨팅 디바이스, 또는 이들의 일부 조합으로 구현될 수 있다는 점이 이해 될 것이다. 본 개시는 또한 비일시적 컴퓨터 판독 가능 저장 매체에 유형으로 저장되는 적어도 하나의 컴퓨터 프로그램 제 품을 제공한다. 컴퓨터 프로그램 제품은 위에 설명된 방법/프로세스를 수행하기 위해 타겟 실제 또는 가상 프로 세서의 디바이스에서 실행되는 프로그램 모듈에 포함된 것과 같은 컴퓨터 실행 가능 명령어를 포함한다. 일반적 으로 프로그램 모듈에는 특정 작업을 수행하거나 특정 추상 유형을 구현하는 루틴, 프로그램, 라이브러리, 개체, 클래스, 구성요소, 데이터 구조 등이 포함된다. 프로그램 모듈의 기능은 다양한 실시예에서 원하는 대로 프로그램 모듈 간에서 결합되거나 분할될 수 있다. 프로그램 모듈에 대한 컴퓨터 실행 가능 명령어은 로컬 또는 분산 디바이스 내에서 실행될 수 있다. 분산 디바이스에서 프로그램 모듈은 로컬 및 원격 저장 매체에 모두 위 치할 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터 판독 가능 시그널 매체 또는 컴퓨터 판독 가능 저장 매체일 수 있다. 컴퓨터 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선, 반도체 시스템, 장치, 디바이스 또는 이들의 임의의 적절 한 조합을 포함할 수 있지만 이에 국한되지는 않는다. 컴퓨터 판독 가능 저장 매체의 보다 구체적인 예에는 하 나 이상의 전선을 갖는 전기 연결, 휴대용 컴퓨터 디스켓, 하드 디스크, RAM(Random Access Memory), ROM(Read-Only Memory), 소거 가능한 프로그램 가능 읽기 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, 휴 대용 컴팩트 디스크 읽기 전용 메모리(CD-ROM), 광학 저장 디바이스, 자기 저장 디바이스 또는 이들의 적절한 조합을 포함한다. 본 문에 개시된 방법을 실행하기 위한 컴퓨터 프로그램 코드는 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터, 기타 프로그램 가능한 데이터 처리 장치의 프로세 서나 컨트롤러에 제공되어, 프로그램 코드가 프로세서나 컨트롤러에 의해 실행될 때 흐름도 및/또는 블록도에서 지정한 기능/작동을 구현한다. 프로그램 코드는 컴퓨터에서 전체적으로, 컴퓨터에서 부분적으로, 독립 실행형 소프트웨어 패키지로서, 컴퓨터에서 부분적으로, 원격 컴퓨터에서 부분적으로 또는 원격 컴퓨터나 서버에서 전 체적으로 실행될 수 있다. 프로그램 코드는 본 문에서 일반적으로 \"모듈\"이라고 지칭될 수 있는 특별히 프로그 래밍된 디바이스에 배포될 수 있다. 모듈의 소프트웨어 구성요소 부분은 임의의 컴퓨터 언어로 작성될 수 있으 며 모놀리식 코드 베이스의 일부일 수 있거나 객체 지향 컴퓨터 언어에서 일반적인 것과 같이 보다 개별적인 코 드 부분으로 개발될 수 있다. 또한, 모듈은 복수의 컴퓨터 플랫폼, 서버, 단말기, 모바일 디바이스 등에 걸쳐 배포될 수 있다. 주어진 모듈은 설명된 기능이 별도의 프로세서 및/또는 컴퓨팅 하드웨어 플랫폼에 의해 수행되 도록 구현될 수도 있다. 동작은 특정 순서로 설명되어 있지만, 원하는 결과를 얻기 위해 이러한 동작이 표시된 특정 순서 또는 순차적 순서로 수행되거나 설명된 모든 동작이 수행되어야 함을 요구하는 것으로 이해되어서는 안 된다. 특정 상황에서 는 멀티태스킹과 병렬 처리가 유리할 수 있다. 마찬가지로, 여러 특정 구현 세부 사항이 위의 논의에 포함되어 있지만, 이는 본 개시의 범위에 대한 제한으로 해석되어서는 안 되며 오히려 특정 실시예에 특정할 수 있는 특 징에 대한 설명으로 해석되어야 한다. 별도의 실시예와 관련하여 설명된 특정 특징은 단일 실시예에서 조합하여구현될 수도 있다. 반대로, 단일 실시예의 맥락에서 설명된 다양한 특징은 여러 실시예에서 개별적으로 또는 임 의의 적절한 하위 조합으로 구현 될 수도 있다. 구조적 특징 및/또는 방법론적 동작에 특정적인 언어로 설명되었지만, 첨부된 청구범위에 정의된 본 개시는 위 에서 설명한 특정 특징이나 동작에 반드시 제한되는 것은 아니라는 것이 이해되어야 한다. 오히려, 위에서 설명 된 특정 특징 및 동작은 청구범위를 구현하는 예시적인 형태로서 개시된다."}
{"patent_id": "10-2024-7026361", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부 도면을 참조한 아래 상세한 설명을 통해, 본 명세서에 개시된 예시적인 실시예의 상기 목적 및 기타 목적, 특징 및 이점이 더욱 이해될 것이다. 도면에서, 본 문에 개시된 몇몇 예시적인 실시예가 예시적이고 비제한적인 방식으로 예시될 것이다. 도 1은 본 개시의 실시예가 구현될 수 있는 환경의 블록도를 도시한다; 도 2는 본 개시의 일부 예시적인 실시예에 따른 푸리에 학습을 이용한 기계 학습 시스템의 블록도를 도시한다; 도 3은 본 개시의 일부 다른 예시적인 실시예에 따른 푸리에 학습을 이용한 기계 학습 시스템의 블록도를 도시 한다; 도 4는 본 개시의 일부 추가 예시적인 실시예에 따른 푸리에 학습을 이용한 기계 학습 시스템의 블록도를 도시 한다; 도 5는 본 개시의 일부 실시예에 따른 의사 그라디언트 하강법(pseudo gradient descent)을 이용한 푸리에 학습 을 위한 예시적인 알고리즘의 다이어그램을 도시한다; 도 6은 본 개시의 일부 예시적인 실시예에 따른 푸리에 학습 프로세스의 흐름도를 도시한다; 및 도 7은 본 개시의 예시적인 실시예를 구현하는 데 적합한 예시적인 컴퓨팅 시스템/디바이스의 블록도를 도시한 다."}
