{"patent_id": "10-2021-0098950", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0017454", "출원번호": "10-2021-0098950", "발명의 명칭": "비대면 평가에서의 부정행위 방지 방법, 장치 및 프로그램", "출원인": "(주)비센스바움", "발명자": "이승한"}}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "수험자의 촬영 영상으로부터 추출된 안면 이미지를 기초로 신원을 확인하는 제1 부정 행위 검출 단계; 및상기 수험자의 촬영 영상으로부터 상기 수험자의 동공이 응시하는 스크린 좌표를 산출하고, 상기 산출된 스크린좌표를 기초로 부정 행위 해당 여부를 판단하는 제2 부정 행위 검출 단계;를 포함하며,상기 제2 부정 행위 검출 단계는,상기 산출된 스크린 좌표가 스크린 내측 영역에 위치하는 경우, 부정 행위에 해당하지 않는 것으로 판단하고, 상기 산출된 스크린 좌표가 스크린 외측 영역에 위치하는 경우, 부정 행위에 해당하는 것으로 판단하는 것을 특징으로 하는 비대면 평가에서의 부정행위 방지 방법."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 부정 행위 검출 단계는, 상기 수험자의 촬영 영상으로부터 추출된 제1 안면 영역과, \"상기 수험자의 신분증으로부터 추출된 제2 안면 영역 및 상기 수험자가 제출한 최근 사진으로부터 추출된 제3 안면 영역 중 적어도 하나\"를 비교함으로써 수행되는 것을 특징으로 하는 비대면 평가에서의 부정행위 방지 방법."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 부정 행위 검출 단계는,상기 제1 안면 영역 내지 상기 제3 안면 영역으로부터 각각 벡터값을추출하고, 상기 추출된 벡터값들의 유클리디안 거리를 비교함으로써 수험자의 신원을 확인하는 것을 특징으로하는 비대면 평가에서의 부정행위 방지 방법."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제2 부정 행위 검출 단계는, 스크린을 바라보고 있는 수험자의 동공이 스크린의 어느 영역에 위치하는지 판단하기 위해 학습된 인공 신경망모델을 이용하여 상기 스크린 좌표를 산출하는 것을 특징으로 하는 비대면 평가에서의 부정행위 방지 방법."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 수험자의 동공이 응시하는 영역은 스크린의 중앙 영역과 스크린의 가장자리 영역 및 스크린 밖의 외부 영역으로 구분되고, 상기 스크린의 중앙 영역 및 상기 스크린의 가장자리 영역은 부정행위에 해당되는 않는 안전 영역으로, 상기 스크린 밖의 외부 영역은 부정행위에 해당되는 비안전 영역으로 설정된 것을 특징으로 하는 비대면 평가에서의 부정행위 방지 방법."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 인공 신경망 모델은 수험자의 동공이 스크린 내측에 위치한 안전 영역을 응시하는지, 스크린 외측에 위치공개특허 10-2023-0017454-3-한 비안전 영역을 응시하는지 및 수험자가 눈을 감았는지에 대한 복수의 클래스를 소프트맥스(softmax) 계층으로 설정함으로써, 수험자의 동공이 응시하는 스크린 좌표를 산출하는 것을 특징으로 하는 비대면 평가에서의 부정행위 방지 방법."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 수험자 촬영 영상으로부터 인식된 객체 인식 데이터를 기초로 제3 부정 행위를 검출하는 제3 부정 행위 검출 단계;를 더 포함하고,상기 제3 부정 행위 검출 단계는, 상기 수험자의 촬영 영상으로부터 사람을 인식하 객체 인식 데이터를 추출하고,상기 객체 인식 데이터로부터 상기 수험자의 관절 데이터를 추출하고,상기 수험자의 관절 데이터가 기설정된 안전 행동 범위를 벗어나면 부정행위에 해당하는 것으로 판단함으로써수행되는 것을 특징으로 하는 비대면 평가에서의 부정행위 방지 방법."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 수험자의 촬영 영상으로부터 추출된 소리 데이터를 기초로 부정행위 해당 여부를 판단하는 제4 부정행위검출 단계;를 더 포함하고, 상기 제4 부정행위 검출 단계는,상기 수험자의 촬영 영상으로부터 소리 데이터를 측정하고,상기 소리 데이터의 데시벨(dB)이 기설정된 안전 데시벨 범위를 벗어나면 부정행위에 해당하는 것으로 판단함으로써 수행되는 것을 특징으로 하는 비대면 평가에서의 부정행위 방지 방법."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제4 부정행위 검출 단계는,상기 측정된 소리 데이터에 음성이 포함된 것을 감지하면 부정행위에 해당하는 것으로 판단함으로써 수행되는것을 특징으로 하는 비대면 평가에서의 부정행위 방지 방법."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제1 부정 행위 검출 단계, 상기 제2 부정 행위 검출 단계, 상기 제3 부정 행위 검출 단계 및 상기 제4 부정 행위 검출 단계 적어도 하나라도 만족하지 못하는 경우, 상기 수험자를 부정 행위로 판단하는 것을 특징으로하는 비대면 평가에서의 부정행위 방지 방법."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "수험자의 촬영 영상으로부터 상기 수험자의 안면 이미지를 검출하기 위한 안면 검출모듈;상기 수험자의 촬영 영상으로부터 상기 수험자의 동공 이미지를 검출하기 위한 동공 검출모듈;상기 수험자의 촬영 영상으로부터 상기 수험자의 관절 데이터를 검출하기 위한 관절 검출모듈;상기 수험자의 촬영 영상으로부터 소리 데이터를 검출하기 위한 소리 검출모듈; 및상기 수험자의 부정행위를 판단하기 위해 상기 안면 검출모듈, 상기 동공 검출모듈, 상기 관절 검출모듈 및 상기 소리 검출모듈을 제어하는 제어부;를 포함하며,상기 제어부는, 공개특허 10-2023-0017454-4-상기 수험자의 촬영 영상으로부터 상기 수험자의 동공이 응시하는 스크린 좌표를 산출하고, 상기 산출된 스크린좌표가 스크린 내측 영역에 위치하는 경우 부정 행위에 해당하지 않는 것으로 판단하고, 상기 산출된 스크린 좌표가 스크린 외측 영역에 위치하는 경우 부정 행위에 해당하는 것으로 판단하는 것을 특징으로 하는 비대면 평가에서의 부정행위 방지 장치."}
{"patent_id": "10-2021-0098950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항 내지 제10항 중 어느 한 항에 기재된 비대면 평가에서의 부정행위 방지 방법을 실행하기 위한 프로그램코드를 포함하는 기록 매체에 저장된 프로그램."}
{"patent_id": "10-2021-0098950", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "비대면 평가에서의 부정행위 방지 방법이 개시된다. 본 방법은 수험자의 촬영 영상으로부터 추출된 안면 이미지 를 기초로 신원을 확인하는 제1 부정 행위 검출 단계 및 수험자의 촬영 영상으로부터 수험자의 동공이 응시하는 스크린 좌표를 산출하고, 산출된 스크린 좌표를 기초로 부정 행위 해당 여부를 판단하는 제2 부정 행위 검출 단 계포함하고, 제2 부정 행위 검출 단계는 산출된 스크린 좌표가 스크린 내측 영역에 위치하는 경우 부정 행위에 해당하지 않는 것으로 판단하고, 산출된 스크린 좌표가 스크린 외측 영역에 위치하는 경우 부정 행위에 해당하는 것으로 판단한다."}
{"patent_id": "10-2021-0098950", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 비대면 평가에서의 부정행위 방지 방법에 관한 것으로, 보다 상세하게는 수험자의 촬영 영상으로부터 추출된 안면 이미지, 동공 이미지, 관절 데이터 및 소리 데이터 중 적어도 하나를 이용하여 수험자의 부정행위 를 검출함으로써, 비대면 평가에서 부정행위가 이루어지는 것을 방지하기 위한 방법, 장치 및 프로그램에 관한 것이다."}
{"patent_id": "10-2021-0098950", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터 기술과 인터넷 기술이 점차 발달함에 따라, 대중들에게 다양한 교육 과정에 대한 온라인 교육 내지 온라 인 평가가 이루어질 수 있다. 구체적으로, 온라인 교육 내지 온라인 평가는 수험자가 컴퓨터 플랫폼 내지 스마트 모바일 어플리케이션을 통해 온라인 교육 웹사이트 내지 온라인 평가 웹사이트에 연결하고, 관리자가 제공하는 온라인 교육 기능 내지 온라 인 평가 기능을 사용하게 함으로써 수행될 수 있다. 한편, 수험자가 정해진 장소에 직접 방문할 필요없이 온라인 평가를 수행하는 비대면 평가 방식은, 수험자가 정 해진 장소에 직접 방문하여 평가를 수행하는 대면 평가 방식에 비해, 평가에 대한 접근성과 수험자의 편의성이 증대될 수 있다는 장점이 있으며, 대면 평가에서 일어날 수 있는 사고 발생, 질병 감염 등의 위험이 예방될 수 있다는 효과를 가지고 있다. 하지만, 감독관 등의 인원이 평가 현장에서 수험자를 직접 관찰할 수 있는 대면 평가 방식에 비해, 수험자 본인 만이 평가에 참여하는 비대면 평가 방식은, 특유의 높은 개방성에 의해 다양한 방식의 부정행위가 일어날 수 있 으나, 이러한 부정행위를 객관적으로 방지하기 위한 방안은 부족한 실정이다."}
{"patent_id": "10-2021-0098950", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 다양한 과제 중 하나는, 수험자의 촬영 영상으로부터 추출된 데이터를 기초로 비대면 평가에서의 부 정행위를 방지하는 방법을 제공하는 것이다. 본 발명의 다양한 과제 중 하나는, 수험자의 촬영 영상으로부터 추출된 데이터를 기초로 비대면 평가에서의 부 정행위를 방지하기 위한 장치를 제공하는 것이다. 본 발명의 다양한 과제 중 하나는, 수험자의 촬영 영상으로부터 추출된 데이터를 기초로 비대면 평가에서의 부 정행위를 방지하는 방법을 실행하기 위한 프로그램 코드를 포함하는 기록 매체에 저장된 프로그램을 제공하는 것이다. 본 발명의 다양한 과제 중 하나는, 수험자의 안면 이미지를 분석하여 부정행위를 검출하는 방법을 제공하는 것 이다. 본 발명의 다양한 과제 중 하나는, 수험자의 동공 이미지를 분석하여 부정행위를 검출하는 방법을 제공하는 것 이다. 본 발명의 다양한 과제 중 하나는, 수험자의 관절 데이터를 분석하여 부정행위를 검출하는 방법을 제공하는 것 이다.본 발명의 다양한 과제 중 하나는, 수험자의 소리 데이터를 분석하여 부정행위를 검출하는 방법을 제공하는 것 이다."}
{"patent_id": "10-2021-0098950", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위한 본 발명의 일 실시 예에 따른 비대면 평가에서의 부정행위 방지 방법은 수험자의 촬영 영상으로부터 추출된 안면 이미지를 기초로 신원을 확인하는 제1 부정 행위 검출 단계 및 상기 수험자의 촬영 영상으로부터 상기 수험자의 동공이 응시하는 스크린 좌표를 산출하고, 상기 산출된 스크린 좌표를 기초로 부정 행위 해당 여부를 판단하는 제2 부정 행위 검출 단계를 포함하며, 상기 제2 부정 행위 검출 단계는, 상기 산출된 스크린 좌표가 스크린 내측 영역에 위치하는 경우, 부정 행위에 해당하지 않는 것으로 판단하고, 상기 산출된 스크린 좌표가 스크린 외측 영역에 위치하는 경우, 부정 행위에 해당하는 것으로 판단할 수 있다. 그리고, 상기 제1 부정 행위 검출 단계는, 상기 수험자의 촬영 영상으로부터 추출된 제1 안면 영역과, \"상기 수 험자의 신분증으로부터 추출된 제2 안면 영역 및 상기 수험자가 제출한 최근 사진으로부터 추출된 제3 안면 영 역 중 적어도 하나\"를 비교함으로써 수행될 수 있다. 또한, 상기 제1 부정 행위 검출 단계는,상기 제1 안면 영역 내지 상기 제3 안면 영역으로부터 각각 벡터값을 추 출하고, 상기 추출된 벡터값들의 유클리디안 거리를 비교함으로써 수험자의 신원을 확인할 수 있다. 그리고, 상기 제2 부정 행위 검출 단계는, 스크린을 바라보고 있는 수험자의 동공이 스크린의 어느 영역에 위치 하는지 판단하기 위해 학습된 인공 신경망 모델을 이용하여 상기 스크린 좌표를 산출할 수 있다. 또한, 상기 수험자의 동공이 응시하는 영역은 스크린의 중앙 영역과 스크린의 가장자리 영역 및 스크린 밖의 외 부 영역으로 구분되고, 상기 스크린의 중앙 영역 및 상기 스크린의 가장자리 영역은 부정행위에 해당되는 않는 안전 영역으로, 상기 스크린 밖의 외부 영역은 부정행위에 해당되는 비안전 영역으로 설정될 수 있다. 그리고, 상기 인공 신경망 모델은 수험자의 동공이 스크린 내측에 위치한 안전 영역을 응시하는지, 스크린 외측 에 위치한 비안전 영역을 응시하는지 및 수험자가 눈을 감았는지에 대한 복수의 클래스를 소프트맥스(softmax) 계층으로 설정함으로써, 수험자의 동공이 응시하는 스크린 좌표를 산출할 수 있다. 또한, 상기 수험자 촬영 영상으로부터 인식된 객체 인식 데이터를 기초로 제3 부정 행위를 검출하는 제3 부정 행위 검출 단계를 더 포함하고, 상기 제3 부정 행위 검출 단계는, 상기 수험자의 촬영 영상으로부터 사람을 인 식하 객체 인식 데이터를 추출하고, 상기 객체 인식 데이터로부터 상기 수험자의 관절 데이터를 추출하고, 상기 수험자의 관절 데이터가 기설정된 안전 행동 범위를 벗어나면 부정행위에 해당하는 것으로 판단함으로써 수행될 수 있다. 그리고, 상기 수험자의 촬영 영상으로부터 추출된 소리 데이터를 기초로 부정행위 해당 여부를 판단하는 제4 부 정행위 검출 단계를 더 포함하고, 상기 제4 부정행위 검출 단계는, 상기 수험자의 촬영 영상으로부터 소리 데이 터를 측정하고, 상기 소리 데이터의 데시벨(dB)이 기설정된 안전 데시벨 범위를 벗어나면 부정행위에 해당하는 것으로 판단함으로써 수행될 수 있다. 또한, 상기 제4 부정행위 검출 단계는, 상기 측정된 소리 데이터에 음성이 포함된 것을 감지하면 부정행위에 해 당하는 것으로 판단함으로써 수행될 수 있다. 그리고, 상기 제1 부정 행위 검출 단계, 상기 제2 부정 행위 검출 단계, 상기 제3 부정 행위 검출 단계 및 상기 제4 부정 행위 검출 단계 적어도 하나라도 만족하지 못하는 경우, 상기 수험자를 부정 행위로 판단할 수 있다. 한편, 상술한 목적을 달성하기 위한 본 발명의 일 실시 예에 따른 비대면 평가에서의 부정행위 방지 장치는 수 험자의 촬영 영상으로부터 상기 수험자의 안면 이미지를 검출하기 위한 안면 검출모듈, 상기 수험자의 촬영 영 상으로부터 상기 수험자의 동공 이미지를 검출하기 위한 동공 검출모듈, 상기 수험자의 촬영 영상으로부터 상기 수험자의 관절 데이터를 검출하기 위한 관절 검출모듈, 상기 수험자의 촬영 영상으로부터 소리 데이터를 검출하 기 위한 소리 검출모듈 및 상기 수험자의 부정행위를 판단하기 위해 상기 안면 검출모듈, 상기 동공 검출모듈, 상기 관절 검출모듈 및 상기 소리 검출모듈을 제어하는 제어부를 포함하며, 상기 제어부는, 상기 수험자의 촬영 영상으로부터 상기 수험자의 동공이 응시하는 스크린 좌표를 산출하고, 상기 산출된 스크린 좌표가 스크린 내측 영역에 위치하는 경우 부정 행위에 해당하지 않는 것으로 판단하고, 상기 산출된 스크린 좌표가 스크린 외측 영 역에 위치하는 경우 부정 행위에 해당하는 것으로 판단할 수 있다. 또한, 상술한 목적을 달성하기 위한 본 발명의 일 실시 예에 따른 기록 매체에 저장된 프로그램은 상술한 비대 면 평가에서의 부정행위 방지 방법을 실행하기 위한 프로그램 코드를 포함할 수 있다."}
{"patent_id": "10-2021-0098950", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 예시적인 실시예들에 따른 비대면 평가에서의 부정행위 방지 방법은 수험자의 촬영 영상으로부터 추 출된 데이터를 기초로 본인 인증 확인, 시선 추적, 행동 인식 및 소리 감지를 통해 수험자의 부정행위를 방지할 수 있다. 따라서, 비대면 평가에서의 부정행위 발생이 방지될 수 있고, 평가 신뢰성이 향상될 수 있으며, 평가 결과의 공 정성이 확립될 수 있다."}
{"patent_id": "10-2021-0098950", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 구체적인 실시형태를 설명하기로 한다. 이하의 상세한 설명은 본 명세서에서 기술된 방법, 장 치 및/또는 시스템에 대한 포괄적인 이해를 돕기 위해 제공된다. 그러나 이는 예시에 불과하며 본 발명은 이에 제한되지 않는다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다.또한, 본 발명의 실시예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질이나 차례 또는 순서 등이 한정되지 않는다. 도 1은 본 발명의 예시적인 실시예들에 따른 비대면 평가의 수행 방법을 설명하기 위한 순서도이다. 도 1을 참조하면, 본 발명의 예시적인 실시예들에 따른 비대면 평가는 평가 접수 단계(S1), 사전 점검 단계 (S2), 평가 준비 단계(S3) 및 시험 진행 단계(S4)를 포함할 수 있으며, 평가 접수 단계(S1), 사전 점검 단계 (S2), 평가 준비 단계(S3) 및 시험 진행 단계(S4)는 순차적으로 수행될 수 있다. 본 발명의 예시적인 실시예들에 따른 비대면 평가는 데스크탑 PC, 노트북, 넷북 등과 같은 컴퓨터와, 태블릿 PC, 스마트폰 등과 같은 휴대용 전자기기를 함께 사용하여 수행될 수 있으나, 본 발명의 개념은 반드시 이에 한 정되지 않는다. 즉, 본 발명의 예시적인 실시예들에 따른 비대면 평가는 컴퓨터와 휴대용 전자기기 중 적어도 하나의 장치를 이용해서만 수행될 수도 있으며, 이 경우 후술되는 수험자의 App 접속 관련 과정은 생략될 수 있 다. 이하에서는, 도 2 내지 도 5를 기초로 평가 접수 단계(S1), 사전 점검 단계(S2), 평가 준비 단계(S3) 및 시험 진행 단계(S4) 각각에 대해 상세히 설명하기로 한다. 도 2는 상기 비대면 평가에서의 평가 접수 단계를 설명하기 위한 순서도이고, 도 3은 상기 비대면 평가에서의 사전 점검 단계를 설명하기 위한 순서도이며, 도 4는 상기 비대면 평가에서의 평가 준비 단계를 설명하기 위한 순서도이고, 도 5는 상기 비대면 평가에서의 시험 진행 단계를 설명하기 위한 순서도이다. 도 2를 참조하면, 본 발명의 예시적인 실시예들에 따른 평가 접수 단계(S1)는 수험자로부터 개인정보를 등록 (S11)받고, 개인정보 이용동의에 대한 수험자의 동의를 수집(S12)하고, 상기 수험자의 신분증 사진을 등록(S1 3)받고, 신분증 진위를 확인함으로써 수행될 수 있다. 비록 도시하지는 않았으나, 평가 접수 단계(S1)는 개인정보 이용동의 과정(S12)이 수행되기 이전에, 상기 수험 자가 접수 페이지에 접속한 상태에서 개인정보 이용에 대한 안내 사항을 제공하는 과정을 더 포함할 수 있으며, 개인정보 이용동의 과정(S12)이 완료되지 않는 경우에는 상기 개인정보 이용에 대한 안내 사항을 제공하는 과정 으로 회귀하도록 제어될 수 있다. 또한, 평가 접수 단계(S1)는 상기 수험자로부터 보안 서약에 대한 동의를 수 집하는 과정을 더 포함할 수 있으며, 개인정보 이용동의 과정(S12)이 완료된 경우에는 상기 보안 서약에 대한 동의를 수집하는 과정이 수행될 수 있다. 예시적인 실시예들에 있어서, 상기 평가 접수 단계(S1)는 신분증 진위 확인(S14) 과정이 완료된 이후에, 수험자 의 최근 사진을 등록한 후 신분증 사진과 매칭시키는 과정(S15)을 더 포함할 수 있다. 신분증 사진 등록 과정(S13)은 상기 수험자로부터 신분증을 촬영한 파일을 제출 받은 후, 상기 신분증의 진위 확인을 수행하고, 상기 신분증 사진의 얼굴 영역(또는, 다른 표현으로는 안면 영역)을 추출함으로써 수행될 수 있다. 이때, 상기 신분증 촬영 파일의 제출은 신분증 촬영 가이드를 통해, 상기 수험자의 신분증이 가이드 라인 내에 신분증이 들어오도록 안내한 후 반사광이 없도록 촬영하도록 안내함으로써 수행될 수 있다. 상기 신분증 촬영 파일의 제출이 완료되면, 상기 신분증 촬영 파일에 대해 전처리 과정이 수행될 수 있다. 상기 전처리 과정은 상기 신분증 촬영 파일에 대해 노이즈를 제거하고, 사각영역 검출 및 평면화를 수행하고, 신분증의 종류마다 설정된 ROI(Region Of Interest) 분할을 수행함으로써 이루어질 수 있다. 상기 신분증 촬영 파일의 전처리 과정이 완료되면, 상기 전처리된 신분증 촬영 파일에 대해 특징 추출 과정이 수행될 수 있다. 상기 특징 추출 과정은 상기 신분증 촬영 파일의 이미지 영역와 글자 영역를 각각 추출함으로써 수행될 수 있다. 예시적인 실시예들에 있어서, 상기 이미지 영역추출은 인공 신경망 모델을 이용하여 상기 수험자의 얼굴영역을 추출한 후 랜드마크(Facial Landmark)를 추출하고 임베딩(embedding)을 생성함으로써 수행될 수 있다. 일 실시 예에 있어서, 상기 이미지 영역추출은 추출된 얼굴영역의 개수가 1개인지 또는 2개이상인지 여부를 더 검출함으 로써 수행될 수 있다.예시적인 실시예들에 있어서, 상기 글자 영역추출은 OCR(Optical character recognition)을 통해 수행될 수 있 다. 상기 특징 추출 과정이 완료되면, 특정 기관을 통해 추출된 신분증 정보를 기초를 신분증의 진위를 확인하는 신 분증 진위 확인 과정(S14)이 수행될 수 있다. 상기 신분증 진위 확인 과정(S14)은, 서버를 통해 상기 추출된 신 분증 정보를 상기 특정 기관으로 송신한 이후에 상기 특정 기관으로부터 진위 확인 결과를 수신함으로써 수행될 수 있으나, 본 발명의 개념은 반드시 이에 한정되지 않는다. 즉, 상기 신분증 진위 확인 과정(S14)은 상기 추출 된 신분증 정보를 상기 서버의 데이터베이스(Data Base; DB)에 기저장된 정보들과 비교함으로써 수행될 수도 있 다. 상기 신분증 정보는 이름, 주민등록번호, 발급일자, 운전면허번호, 여권번호, 외국인 등록번호 등을 포함할 수 있다. 상기 특정 기관은 정부24와 같은 대한민국 정보 관리 포털, 경찰청 산하의 도로교통공단 포털, 하이코 리아와 같은 외국인 정보 관리 포털 등을 포함할 수 있다. 상기 신분증 진위 확인 과정(S14)이 완료되지 않는 경우에는 신분증 사진 등록 과정(S13)으로 회귀하도록 제어 될 수 있으며, 상기 신분증 진위 확인 과정(S14)이 완료되는 경우에는 최근 사진 등록 및 신분증 사진과의 매칭 과정(S15)이 수행될 수 있다. 상기 최근 사진의 등록은 신분증 사진 등록 과정(S13)과 유사하게, 상기 수험자로부터 최근 사진을 제출 받은 후, 상기 최근 사진의 얼굴 영역 내지 안면 영역을 추출함으로써 수행될 수 있다. 이때, 상기 최근 사진의 얼굴 영역 내지 안면 영역의 추출은 상기 전처리된 신분증 촬영 파일의 이미지 영역추출과 실질적으로 동일하거나 유 사하게 수행될 수 있다. 즉, 상기 최근 사진의 얼굴 영역 내지 안면 영역의 추출은 인공 신경망 모델을 통해 상 기 수험자의 얼굴영역을 추출한 후 랜드마크(Facial Landmark)를 추출하고 임베딩(embedding)을 생성함으로써 수행될 수 있다. 이후, 상기 최근 사진의 안면 영역과 상기 신분증 사진의 안면 영역 각각으로부터 벡터값을 각각 추출하고, 상 기 최근 사진의 안면 영역으로부터 추출된 벡터값들이 가지는 유클리디안 거리(Euclidean Distance)와 상기 신 분증 사진의 안면 영역으로부터 추출된 벡터값들이 가지는 유클리디안 거리를 비교함으로써, 상기 최근 사진 등 록 및 신분증 사진과의 매칭 과정(S15)이 완료될 수 있다. 이와는 달리, 상기 최근 사진 등록 및 신분증 사진과 의 매칭 과정(S15)은 상기 최근 사진의 안면 영역으로부터 추출된 특정 벡터값과 상기 신분증 사진의 안면 영역 으로부터 추출된 특정 벡터값 사이의 유클리디안 거리를 비교함으로써 수행될 수도 있다. 이때, 상기 최근 사진 과 상기 신분증 사진의 매칭이 완료되기 위한 유클리디안 거리(d)는 1보다 작을 수 있으며, 바람직하게는 0.4보 다 작을 수 있다. 이러한 인공신경망 모델 기반 안면 인증에 대해서는 이후 도 6 내지 7을 참조하여 보다 구체적으로 설명하기로 한다. 한편, 상기 최근 사진 등록 및 신분증 사진과의 매칭 과정(S15)이 완료되면, 상기 최근 사진과 상기 신분증 사 진의 매칭율을 산정하는 매칭율 판단 과정(S16)이 수행될 수 있다. 예시적인 실시예들에 있어서, 상기 수험자의 최근 사진과 상기 수험자의 신분증 사진의 매칭율이 특정 매칭율 (A)에 미달하는 경우에는, 관리자를 통해 상기 수험자의 평가 접수 확인(S17)을 수행하게 할 수 있으며, 이 경 우 평가 접수 단계(S1)는 완료되지 않은 상태로 보류될 수 있다. 이때, 상기 특정 매칭율(A)은 60%보다 크고 80%보다 작은 값, 예를 들어, 70%일 수 있다. 일 실시예에 있어서, 상기 관리자의 평가 접수 확인 과정(S17)을 통해 신분증 사진과 최근 사진의 인물이 동일 인이라고 판단되면 DB Flag를 정상 처리하여 평가 접수 단계(S1)가 완료될 수 있다. 이와는 달리, 상기 관리자 의 평가 접수 확인 과정(S17)을 통해 신분증 사진과 최근 사진의 인물이 동일인이 아니라고 판단되면 DB Flag를 비정상 처리한 후 문자나 전화 등을 통해 수험자에게 소명을 요구하는 과정이 더 수행될 수 있다. 한편, 상기 수험자의 최근 사진과 상기 수험자의 신분증 사진의 매칭율이 상기 특정 매칭율(A)을 넘어서는 경우 에는, 평가 접수 단계(S1)가 완료될 수 있으며, 상기 수험자에게 사전 점검 단계(S2)에 대한 안내가 수행될 수 있다. 도 3을 참조하면, 본 발명의 예시적인 실시예들에 따른 사전 점검 단계(S2)는 상기 수험자가 Test Page에 접속 (S21)한 후, 필수 프로그램을 설치(S22)하고, 상기 필수 프로그램의 설치가 완료된 것을 확인(S23)함으로써 수 행될 수 있다.이때, 필수 프로그램의 설치 완료 확인 과정(S23)은 장치 검사를 통해 수행될 수 있다. 보다 구체적으로, 필수 프로그램의 설치 완료 확인 과정(S23)은 상기 장치 검사를 통해 평가 보안 프로그램, 카 메라 제어 프로그램 및 마이크 제어 프로그램이 각각 정상적으로 동작하는지 여부를 확인함으로써 수행될 수 있 으며, 상기 프로그램들 중 제대로 동작하지 않는 프로그램에 대한 설치를 안내함으로써 수행될 수 있다. 이때, 평가 보안 프로그램, 카메라 제어 프로그램 및 마이크 제어 프로그램이 제대로 설치되었음에도 제대로 기능하지 않는 경우에는, 상기 수험자에게 Q/A 내지 관리자 채팅을 통해 관리자가 문제를 해결하도록 안내할 수 있다. 또한, 필수 프로그램의 설치 완료 확인 과정(S23)은 상기 장치 검사를 통해 부정 프로그램, 화면 공유 프로그램, 키보드 제어 프로그램 및 모니터 제어 프로그램이 감지되는지 더 확인함으로써 수행될 수도 있으며, 부정 프로그램, 화면 공유 프로그램, 키보드 제어 프로그램 및 모니터 제어 프로그램이 감지되면 이들을 종료하 도록 안내할 수 있다. 추가적으로, 모니터 제어와 관련하여 싱글 모니터만을 이용하도록 강제 잠금을 설정할 수 있으며, 이러한 강제 잠금이 제대로 기능하지 않는 경우에는 듀얼 모니터 사용을 중지하는 안내를 수행할 수 있 다. 또한, 카메라 제어와 관련하여 카메라가 제대로 기능하지 않는 경우에는 카메라 점검 메시지를 안내할 수도 있으며, 마이크 제어와 관련하여 마이크가 제대로 기능하지 않는 경우에는 마이크의 동작 On과 마이크 음량을 기설정된 값으로 강제 고정하는 과정을 수행할 수도 있다. 이때, 부정 프로그램, 화면 공유 프로그램, 키보드 제어 프로그램 및 모니터 제어 프로그램의 설정값이 기저장된 비대면 평가 매뉴얼과 다른 경우에는, 상기 수험 자에게 Q/A 내지 관리자 채팅을 통해 관리자가 문제를 해결하도록 안내할 수 있다. 비대면 평가에서 사용되는 카메라의 종류는 특별히 제한되지 않는다. 예시적인 실시예들에 있어서, 상기 카메라 는 CCD(charge coupled device) 영상센서(image sensor), CMOS(complementary metal oxide semi-conductor) 영상센서, CPD(charge priming device) 영상센서 및 CID(charge injection device) 영상센서, 적외선 영상센서 등과 같은 영상센서들 중 어느 하나의 영상센서로 구현될 수 있다. 필수 프로그램의 설치 완료 확인 과정(S23)이 완료되면, 상기 수험자의 휴대전화로 비대면 평가 접속 링크를 전 송한 후, 상기 수험자의 App 접속이 확인되면 사전 점검 단계(S2)가 완료될 수 있다. 이때, 상기 수험자의 App 접속이 확인되지 않는 경우에는, 상기 수험자에게 Q/A 내지 관리자 채팅을 통해 관리자가 문제를 해결하도록 안 내할 수 있다. 도 4를 참조하면, 본 발명의 예시적인 실시예들에 따른 평가 준비 단계(S3)는 상기 수험자가 N시간 전 평가 사 이트에 접속(S31)하고, 장치의 점검 및 설정이 완료되었는지 확인(S32)하고, 상기 수험자의 App 접속을 확인 (S33)하고, 상기 수험자의 본인 확인을 완료(S34)하고, 상기 촬영 영상으로부터 상기 수험자의 시선을 보정 (S35)함으로써 수행될 수 있다. 상기 장치의 점검 및 설정 완료 확인 과정(S32)은 도 3을 참조로 설명한 사전 점검 단계(S2)와 실질적으로 동일 하거나 유사한 방식으로 수행될 수 있으며, 확인이 이루어지는 플랫폼이 Test Page인지 또는 평가 사이트인지 여부에 있어서만 차이가 있을 수 있다. 상기 App 접속 확인 과정(S33)은 상기 수험자의 휴대전화 앱을 통해 평가 페이지 링크를 전송하고, 상기 수험자 가 상기 평가 페이지의 접속했는지 여부를 확인하고, 상기 수험자에게 방해금지모드 등의 비대면 평가 모드를 실행하도록 가이드한 후, 컴퓨터와 휴대용 전자기기 상호간의 인증 코드를 확인함으로써 수행될 수 있다. 상기 수험자의 본인 확인 과정(S34)은 컴퓨터의 스크린에 웹캠 가이드를 출력하고, 상기 수험자에게 상기 웹캠 가이드 내에 본인의 얼굴이 위치하도록 안내하고, 상기 수험자의 얼굴이 상기 웹캠 가이드 내에 위치하는지 확 인하고, 상기 수험자의 얼굴을 촬영한 후, 상기 수험자의 안면 촬영 이미지와 상기 수험자의 신분증 사진 및/또 는 상기 수험자의 최근 사진을 비교하여 매칭율이 특정 매칭율(B) 이사인지 여부를 확인함으로써 수행될 수 있 다. 예시적인 실시예들에 있어서, 상기 수험자의 안면 촬영 이미지와 상기 수험자의 신분증 사진 및/또는 상기 수험 자의 최근 사진 사이의 매칭율이 특정 매칭율(B)에 미달하는 경우에는 상기 수험자의 본인 확인 과정(S34)이 처 음부터 수행되도록 가이드될 수 있다. 이때, 상기 수험자의 본인 확인 과정(S34)이 3회 반복하여 수행되었음에 도 상기 수험자의 안면 촬영 이미지와 상기 수험자의 신분증 사진 및/또는 상기 수험자의 최근 사진 사이의 매 칭율이 특정 매칭율(B)에 미달하는 경우에는, 관리자를 통해 상기 수험자의 본인 확인 과정(S34)을 수행하게 할 수 있다. 이때, 상기 특정 매칭율(B)은 90%보다 크고 100%보다 작은 값, 예를 들어, 95%일 수 있다. 여기서, 매칭 과정은 인공 신경망 모델을 이용하여 수행될 수 있고, 이대해서는 이후 도 6 내지 7을 참조하여 보다 구체적 으로 설명하기로 한다. 상기 수험자의 안면 촬영 이미지와 상기 수험자의 신분증 사진 및/또는 상기 수험자의 최근 사진 사이의 매칭율 이 특정 매칭율(B)을 넘어서는 경우에는, 상기 수험자의 본인 확인 과정(S34)이 완료될 수 있으며, 이후 상기 촬영 영상으로부터 상기 수험자의 시선을 보정하는 과정(S35)이 수행될 수 있다. 상기 수험자의 시선 보정 과정(S35)은 상기 컴퓨터의 스크린에 상기 웹캠 가이드를 출력하고, 상기 수험자에게 상기 웹캠 가이드 내에 본인의 얼굴이 위치하도록 안내하고, 보정된 화면을 노출시킨 후 상기 수험자의 얼굴이 상기 웹캠 가이드에 위치하는지 여부를 확인하고, 상기 수험자의 눈동자 좌표를 추출하고, 보정 이전의 스크린 과 보정 이후의 스크린을 순차적으로 노출시킨 후, 보정 전후의 상기 눈동자 좌표들 사이에 원근변환 (Perspective Projection)을 수행함으로써 이루어질 수 있다. 상기와 같은 시선 보정 과정(S35)을 통해, 상기 수험자의 눈동자 좌표들의 위치가 보다 명확하게 추출될 수 있 으며, 이에 따라 후술되는 수험자의 시선 추적이 보다 효과적으로 이루어질 수 있다. 도 5를 참조하면, 본 발명의 예시적인 실시예들에 따른 시험 진행 단계(S4)는 부정행위 탐지 시작 과정(S40), 본인 인증 과정(S41), 시선 추적 과정(S43), 행동 인식 과정(S45), 및 소리 감지 과정(S47)을 포함할 수 있으며, 부정행위 탐지 시작 과정(S40), 본인 인증 과정(S41), 시선 추적 과정(S43), 행동 인식 과정(S45), 및 소리 감지 과정(S47)은 하나의 사이클을 구성하여 본 발명에 따른 비대면 평가가 진행되는 동안에 특정 주기마 다 수행되도록 제어될 수 있다. 이때, 상기 특정 주기는 초 단위의 주기, 예를 들어, 수 초에서 수십 초까지 다 양한 주기로 구성될 수 있으며, 필요에 따라 분 단위의 주기, 예를 들어, 수 분에서 수십 분까지 다양한 주기로 구성될 수도 있다. 시험 진행 단계(S4)에서 상기 비대면 평가가 완료되기 전까지, 본인 인증 과정(S41), 시선 추적 과정(S43), 행 동 인식 과정(S45), 및 소리 감지 과정(S47)이 모두 정상적으로 수행되면, 상기 비대면 평가를 정상적으로 종료 하는 시험 완료 단계(S49)가 수행될 수 있다. 다만, 시험 진행 단계(S4)에서 상기 비대면 평가가 완료되기 전까지, 본인 인증 과정(S41), 시선 추적 과정 (S43), 행동 인식 과정(S45), 및 소리 감지 과정(S47) 중 적어도 하나라도 만족하지 못하는 경우, 수험자가 부 정행위 상황에 있다고 판단할 수 있다. 그리고, 시험 진행 단계(S4)에서 상기 비대면 평가가 완료되기 전까지, 본인 인증 과정(S41), 시선 추적 과정(S43), 행동 인식 과정(S45), 및 소리 감지 과정(S47) 중 적어도 하나의 과정이 정상적으로 수행되지 않으면, 상기 수험자에게 부정행위 탐지 사실을 알린 후 대시보드에 라벨링(S42)하 고, 상기 관리자를 통해 상기 수험자의 행위가 부정행위에 해당하는지 여부를 확인(S44)할 수 있다. 이때, 상기 수험자의 부정행위가 확인되면 평가를 몰수하는 과정(S46)이 수행될 수 있으며, 이와는 달리 상기 수험자의 부 정행위가 확인되지 않으면 부정행위 탐지 시작 과정(S40)으로 회귀하도록 제어될 수 있다. 이하에서는, 도 6 내지 도 13을 기초로 본인 인증 과정(S41), 시선 추적 과정(S43), 행동 인식 과정(S45), 및 소리 감지 과정(S47)을 상세히 설명하기로 한다. 도 6은 본 발명의 예시적인 실시예들에 따른 본인 인증 과정을 이용한 부정행위 검출 단계를 설명하기 위한 순 서도이다. 도 6을 참조하면, 본 발명의 예시적인 실시예들에 따른 본인 인증 과정(S41)은 스크린에 웹캠 가이드를 출력하 고(S410), 상기 가이드 안에 수험자의 안면이 위치하도록 안내하고(S411), 상기 수험자의 안면이 상기 가이드 안에 위치하는지 확인하고(S412), 특정 시간동안 정지를 안내한 후 상기 수험자의 안면을 촬영하고(S413), 상기 촬영된 수험자의 안면 이미지와 사전 제출한 수험자의 사진을 매칭시키고(S414), 상기 촬영된 수험자의 안면 이 미지와 상기 사전 제출한 수험자의 사진의 매칭율과 기설정된 특정 매칭율(B)을 비교(S415)함으로써 수행될 수 있다. 이때, 상기 특정 매칭율(B)은 90%보다 크고 100%보다 작은 값, 예를 들어, 95%일 수 있고, 상기 사전 제 출한 수험자의 사진은 상기 수험자의 신분증 이미지 및/또는 상기 수험자의 최근 사진 이미지일 수 있으며, 상 기 특정 시간은 3초 이내의 시간일 수 있다. 구체적으로, 촬영된 수험자의 안면 이미지와 사전 제출한 수험자의 사진을 매칭시키는 과정(S414)은 상기 수험 자의 촬영 영상으로부터 추출된 제1 안면 영역, 상기 수험자의 신분증으로부터 추출된 제2 안면 영역 및/또는상기 수험자가 제출한 최근 사진으로부터 추출된 제3 안면 영역을 매칭시키고, 상기 제1 안면 영역 내지 상기 제3 안면 영역으로부터 각각 벡터값을 추출한 후, 추출된 벡터값들이 가지는 유클리디안 거리를 비교함으로써 수행될 수 있다. 이때, 촬영된 수험자의 안면 이미지와 사전 제출한 수험자의 사진을 매칭시키는 과정(S414)이 완료되기 위한 유클리디안 거리(d)는 1보다 작을 수 있으며, 바람직하게는 0.4보다 작을 수 있다. 이러한 본 발명에 따른 본인 인증 과정(S41)은 인공 신경망 모델을 이용하여 수행될 수 있다. 구체적으로, 본 발명에 따르면, 실시간으로 안면을 인식하고 인식된 안면에서 동공의 위치를 추정할 수 있는 인공 신경망 모델 을 이용할 수 있다. 여기서, 인공 신경망 모델은, 일 예로, VGG 신경망 기반의 ResNet(Residual Network)일 수 있고, 이에 제한되는 것은 아니다. 이러한 본 발명에 따른 인공 신경망 모델을 이용한 안면 인증은 안면 검출, 랜드마크(landmark) 검출, 안면 특 징점 추출의 단계로 구성될 수 있다. 구체적으로 인공 신경망 모델은 카메라로부터 입력되는 영상에서 실시간 얼굴 검출을 위해 실시간 얼굴 검출이 가능한 학습 모델을 이용하여 안면 검출을 수행할 수 있다. 여기서, 학습 모델은, 일 예로, Dlib-model 일 수 있고, 이에 제한되는 것은 아니다. 그리고, 인공신경망 모델은 Shape Prediction을 통해 눈썹, 눈, 코, 입 및 얼굴 외곽을 표현하는 랜드마크를 검 출할 수 있다. 일 예로, 검출된 랜드마크는 도 7과 같이 68개의 랜드마크로 구성될 수 있다. 그리고, 인공신경망 모델은 검출된 랜드마크 파라미터를 입력받아 Encoded Vector를 통해 벡터 형태로 변환하여 안면 인식 벡터 정보를 추출할 수 있다. 여기서, 추출된 안면 인식 벡터 정보는 수험자의 인증에 사용될 수 있 다. 한편, 인공 신경망 모델을 이용하여 검출된 얼굴 영역에 안경이 착용된 것으로 판단된 경우, CycleGAN 기반의 디블러링(Deblurring) 모듈을 통해 안경을 제거하고, 제거된 영상으로부터 랜드마크를 추출할 수 있다. 한편, 상술한 신분증 진위 확인(S14), 최근사진 등록 및 신분증 사진과 매칭(S15~16), 본인 확인(S34) 및 본인 인증 과정(S41)은 신분증으로부터 획득된 수험자의 얼굴과 시험 과정에서 실시간으로 촬영된 수험자의 얼굴의 매칭율 비교를 통해 인증 성공 여부가 결정될 수 있다. 이에 따라, 본 발명에 따른 인공 신경망 모델은 상술한 각종 수험자 인증 과정을 안면 인식 벡터 정보의 비교를 통해 수행할 수 있다. 일 예로, 본인 인증 과정(S41)은 신분증 영상 이미지를 캡처하여 안면 영역을 추출하고, 인공 신경망 모델을 통 해 안면 인식 벡터 정보를 추출할 수 있다. 그리고, 수험자 본인 인증 과정(S41)은 카메라로부터 촬영에 따른 수험자의 안면에서 인공 신경망 모델을 통해 안면 인식 벡터 정보를 추출할 수 있다. 그리고, 신분증 영상 이미 지로부터 생성된 벡터 정보와 카메라 촬영에 따른 수험자의 얼굴로부터 생성된 벡터 정보를 기초로 유클리디안 거리를 산출함으로써 수험자 본인 인증을 수행할 수 있다. 일 실시예에 있어서, 생성된 벡터의 유클리디안 거리 가 0.4 이상인 경우, 영상으로부터 촬영된 안면 이미지와 신분증 캡처 이미지와 동일하지 않은 것으로 판단하고 인증 실패로 판단할 수 있다. 이와는 달리, 생성된 벡터의 유클리디안 거리가 0.4 미만인 경우, 영상으로부터 촬영된 안면 이미지와 신분증 캡처 이미지가 서로 동일한 것으로 판단하고 인증 성공으로 판단할 수 있다. 한편, 본 발명의 일 예시에 따르면, 수험자의 신원 확인 과정은 동일인을 학습하기 위해 사용된 학습 이미지가 신분증 이미지 1장에 불과함으로, 신분증 안면 이미지와 카메라에서 추출한 안면 이미지의 동일 유무를 확인하 기 위해 원샷 학습(One-shotLearning)을 이용할 수 있다. 여기서, 원샷 학습은 한 개의 데이터로 학습하는 방법 일 수 있으며, 인공신경망을 이용하여 유사도 함수(d(img1,img2) = 두 이미지의 차이 반환)를 학습시킨 후, 유 사도 함수 값이 기설정된 기준치보다 크면 두 이미지가 서로 다른 것으로 인식하고, 상기 유사도 함수값이 기설 정된 기준치보다 작으면 비슷한 것으로 인식하도록 설정될 수 있다. 이와 같이, 본 발명에 따르면, 인공신경망 모델을 이용한 안면 인식을 수행함으로써, 별도의 장비나 센서 없이 일반 카메라를 통해 영상 분석이 가능하므로, 장비로 인한 비용 감소 효과를 가질 수 있고, 단일 영상이 아닌 대용량 영상 데이터에 대해 실시간 분석이 가능함으로 투입되는 인력 대비 처리 효율 및 정확도가 각각 향상될 수 있다. 일 실시예에 있어서, 본인 인증 과정(S41)은 추출된 얼굴영역의 개수가 1개인지 또는 2개이상인지 여부를 더 검 출함으로써 수행될 수 있으며, 상기 추출된 얼굴영역의 개수가 1개이면 부정행위에 해당하지 않는 것으로 판단하고, 상기 추출된 얼굴영역의 개수가 2개이상이면 부정행위에 해당하는 것으로 판단하도록 제어될 수 있다. 이후, 매칭율 비교 과정(S415)에서 상기 촬영된 수험자의 안면 이미지와 상기 사전 제출한 수험자의 사진의 매 칭율이 상기 특정 매칭율(B)에 미달하는 경우에는, 관리자를 통해 수험자 알림 및 대시보드 라벨링 과정(S42) 및 부정행위 확인 과정(S44)이 수행될 수 있으며, 부정행위 확인 과정(S44)의 결과에 따라 평가 몰수 과정(S4 6)이 수행되거나 혹은 부정행위 탐지 시작 과정(S40)으로 회귀될 수 있다. 이와는 달리, 매칭율 비교 과정(S415)에서 상기 촬영된 수험자의 안면 이미지와 상기 사전 제출한 수험자의 사 진의 매칭율이 상기 특정 매칭율(B)을 넘어서는 경우에는, 상기 수험자의 본인 확인 인증이 완료(S416)될 수 있 으며, 이후 시선 추적 과정(S43), 행동 인식 과정(S45) 및 소리 감지 과정(S47)이 수행될 수 있다. 도 8은 본 발명의 예시적인 실시예들에 따른 시선 추적을 이용한 부정행위 검출 단계를 설명하기 위한 순서도이 다. 도 8을 참조하면, 본 발명의 예시적인 실시예들에 따른 시선 추적 과정(S43)은 수험자의 안면 및 동공을 추 출하고(S430), 추출된 안면의 개수가 1개인지 판단하고(S431), 상기 수험자의 동공 좌표를 검출하고(S432), 상 기 동공이 응시하는 스크린 좌표를 산출하고(S433), 상기 산출된 스크린 좌표가 상기 안전 영역에 위치하는지 여부를 판단함으로써(S434) 수행될 수 있다. 여기서, 수험자의 안면 및 동공 추출 과정(S430)에 대해서는 도 9를 참조하여 보다 구체적으로 설명하기로 한다. 도 9는 본 발명의 일 실시 예에 따른 랜드마크를 이용한 얼굴 영역 및 양쪽 눈 영역 추출 과정을 설명하기 위한 예시도이다. 도 9를 참조하면, 동공 추출하는 과정은, 상술한 도 6 내지 7의 ResNet을 이용하여 추출된 랜드마 크를 이용하여 얼굴 영역 및 양쪽 눈 영역을 추출할 수 있다. 한편, 추출된 안면의 개수 판단은 전술한 본인 인증 과정(S41)과 실질적으로 동일한 방법을 통해 수행될 수 있 으므로, 이에 대한 자세한 설명은 생략한다. 상기 수험자의 동공 추출 과정(S430)이 완료된 이후에, 상기 수험자의 동공 좌표 검출 과정(S432)이 수행될 수 있다. 이때, 동공 좌표 검출 과정(S432)은 기설정된 2차원 혹은 3차원 형태의 눈 모델링을 수행한 후, 모델링 방식에 따라 동공의 위치를 추정하는 모델 기반 기법을 통해 수행될 수 있다. 이와는 달리, 동공 좌표 검출 과 정(S432)은 명동 공법 또는 암동 공법을 통해 상기 수험자의 동공이나 홍채로부터 소정의 특징을 추출하여 동공 중심을 추정하는 외형 기반 기법을 통해 수행될 수도 있다. 일 실시예에 있어서, 동공 좌표 검출 과정(S432)은 원 피팅(circle fitting) 및 타원 피팅(ellipse fitting) 등의 동공 검출 알고리즘을 통해 추출될 수 있다. 여기서, 동공 좌표 검출 과정(S432)을 통해 산출된 동공 좌표는 수험자의 시선 보정을 수행하는데 이용될 수 있 다. 즉, 본 발명의 일 실시 예에 따르면, 변환행렬을 이용하여 카메라의 중심축과 동공의 중심축 간의 기준 각 도 오차 보정을 수행함으로써, 시선 보정을 수행할 수 있다. 한편, 스크린 좌표 산출 과정(S433)은 상기 수험자의 동공이 응시하는 스크린 좌표를 산출할 수 있다. 여기서, 수험자의 동공이 응시하는 영역은 수험자의 시선이 향하는 영역과 동일한 의미일 수 있다. 이러한 수험자의 동공이 응시하는 영역은 스크린의 중앙 영역과 스크린의 가장자리 영역 및 스크린 밖의 영역으 로 구분될 수 있고, 상기 구분된 각각의 영역에 스크린 좌표를 할당하여 수험자가 응시하는 스크린 좌표를 산출 할 수 있다. 여기서, 본 발명의 일 실시 예에 따르면, 스크린을 바라보고 있는 수험자의 동공이 스크린의 어느 영역 응시하 고 있는지 판단하기 위해 학습된 \"시선 위치 추적 인공 신경망 모델\"을 이용하여 수험자의 스크린 좌표를 산출 할 수 있다. 이에 대해서는 도 10을 참조하여 보다 구체적으로 설명하기로 한다. 도 10은 수험자의 동공이 응시하는 영역을 분류하기 위한 스크린 좌표의 배치 구조를 설명하기 위한 도면이다. 도 10을 참조하면, 수험자의 동공이 응시하 는 영역은 스크린의 중앙 영역과 스크린의 가장자리 영역 및 스크린 밖의 외부 영역으로 구분될 수 있다. 본 발명의 일 실시 예에 따르면, 중앙 영역에는 스크린 좌표 \"1\"을 할당하고, 좌측 상단 영역에는 스크린 좌표 \"2\"를 할당하며, 가운데 영역의 상단 영역에는 스크린 좌표 \"3\"을 할당하며, 우측 상단 영역에는 스크린 좌표 \"4\"를 할당하고, 가운데 영역의 좌측에는 스크린 좌표 \"5\"를 할당하고, 가운데 영역의 우측에는 스크린 좌표 \"6\"을 할당하며, 좌측 하단 영역에는 스크린 좌표 \"7\"을 할당하고, 가운데 영역의 하단 영역 에는 스크린 좌표 \"8\"을 할당하고, 우측 하단 영역에는 스크린 좌표 \"9\"를 할당하고, 외부 영역에는 스크 린 좌표 \"10\"을 할당할 수 있다. 여기서, 스크린 좌표 \"1 내지 9\"가 할당된 스크린의 가운데 영역과 스크린의 가장자리 영역은 안전 영역으로 통칭되고, 스크린 좌표 \"10\"이 할당된 스크린의 외부 영역의 비안전 영역으로 통칭될 수 있다. 본 발명의 일 실시 예에 따른 시선 위치 추적 인공 신경망 모델은 도 9와 같은 동공 이미지들에 대하여 수험자 가 스크린 내측에 위치한 9개의 안전 영역(510,520)을 응시하는지, 스크린 외측에 위치한 1개의 비안전 영역 을 응시하는지 및 수험자가 눈을 감았는지를 레이블링하여 학습된 모델일 수 있다. 일 예로, i) 스크린 화면에 나타난 \"1\" 내지 \"10\"의 영역을 안내에 따라 수험자가 하나씩 마우스로 클릭하고, ii) 마우스로 \"1\" 내지 \"10\"을 순차적으로 클릭하면서 해당 클릭 시점에 카메라에 의해 촬영된 동공 이미지에 대응되는 스크린 좌표 \"1\" 내지 \"10\"매칭하고, iii) 순차적 클릭을 마친 후 랜덤하게 클릭하면서 해당 클릭 시 점에 카메라에 의해 촬영된 동공 이미지에 대응되는 스크린 좌표 \"1\" 내지 \"10\"매칭하고, iv) 상기 스크린 좌표 와 동공 이미지의 매칭 데이터를 학습 데이터로 이용하여 시선 위치 추적 인공 신경망 모델을 생성할 수 있다. 이러한 본 발명에 따른 시선 위치 추적 인공 신경망 모델은 수험자가 스크린 내측에 위치한 9개의 안전 영역 (510,520)을 응시하는지, 스크린 외측에 위치한 1개의 비안전 영역을 응시하는지 및 수험자가 눈을 감았는 지에 대한 11개 클래스를 소프트맥스(softmax) 계층으로 설정함으로써, 수험자의 동공 수험자의 동공이 응시하 는 스크린 좌표를 산출할 수 있다. 한편, 상술한 예시에 따르면, 스크린 내부의 스크린 좌표는 9개로 구성되는 것을 예로 설명하였으나, 본 발명의 개념은 반드시 이에 한정되지 않으며, 상기 스크린 좌표는 이보다 적거나 많은 개수로 이루어질 수도 있다. 또 한, 스크린 외부에 대한 스크린 좌표의 개수 역시 필요에 따라 1개 또는 이보다 많거나 적은 개수로 이루어질 수 있다. 한편, 수험자의 시선이 안전 영역에 위치하는지 여부를 판단하는 과정(S434)은 상기 수험자의 동공이 안전 영역 (510,520)을 응시하는지, 비안전 영역을 응시하는지를 판단함으로써 수행될 수 있다. 구체적으로, 본 발명 에 따르면, 상기 산출된 스크린 좌표가 스크린 내측 영역에 대응되는\"1번 내지 9번\"인 경우, 수험자의 동공이 안전 영역(510,520)에 위치하는 것으로 판단할 수 있다. 다만, 상기 산출된 스크린 좌표가 스크린 외측 영역에 대응되는\"10번\"인 경우, 수험자의 동공이 비안전 영역에 위치하는 것으로 판단할 수 있다. 만약, 수험자의 동공이 안전 영역 내(510,520)에 위치하면 부정행위에 해당하지 않는 것으로 판단하여 시선 추 적 완료 과정(S435)이 수행될 수 있으며, 상기 수험자의 동공이 비안전 영역에 위치하면 부정행위에 해당 하는 것으로 판단할 수 있다. 수험자가 동공이 안전 영역에 위치하는지 여부를 판단하는 과정(S434)을 통해 상기 수험자의 행동이 부정행위에 해당하는 것으로 판단되면, 관리자를 통해 수험자 알림 및 대시보드 라벨링 과정(S42) 및 부정행위 확인 과정 (S44)이 수행될 수 있으며, 부정행위 확인 과정(S44)의 결과에 따라 평가 몰수 과정(S46)이 수행되거나 혹은 부 정행위 탐지 시작 과정(S40)으로 회귀될 수 있다. 도 11 내지 도 12는 본 발명의 예시적인 실시예들에 따른 행동 인식을 이용한 부정행위 검출 단계를 설명하기 위한 도면들이다. 도 11을 참조하면, 본 발명의 예시적인 실시예들에 따른 행동 인식 과정(S45)은 상기 수험자를 촬영한 영상으로 부터 사람 객체를 인식하고(S450), 인식된 사람의 수가 1명 이상인지 판단하고(S451), 인식된 사람 객체에 대해 경계 박스를 설정한 후 이미지를 크롭하고(S452), 상기 크롭된 이미지로부터 관절 데이터를 추출하고(S453), 상 기 추출된 관절 데이터를 기초로 상기 수험자의 행동이 안전 행동에 해당하는지 여부를 판단함으로써(S454) 수 행될 수 있다. 상기 수험자를 촬영한 영상으로부터 사람 객체를 인식하는 과정(S450)은 객체 인식 인공 신경망 모델을 통해 사 람, 연필, 노트 등 다양한 객체를 인식한 후, 상기 객체의 위치를 추정하여 바운딩 박스(Bounding box)로 분류하는 과정을 포함할 수 있다. 특히, 본 발명에 따른 객체 인식 인공 신경망 모델은 부정행위 감시 대상인 사람의 효과적인 추출을 위해 데이 터셋을 통해 학습될 수 있다. 한편, 안전 행동에 해당하는지 여부를 판단하는 과정(S454)은 추출된 수험자의 관절 데이터의 행동 반경이 기설 정된 안전 행동 범위를 벗어나는지 여부를 검출함으로써 수행될 수 있다. 구체적으로, 안전 행동에 해당하는지 여부를 판단하는 과정(S454)은, 관절 데이터 추출 과정(S453)으로부터 추 출된 추출된 수험자의 관절 데이터와, 상기 안전행동 자세를 기초로 기추출된 관절 데이터를 비교함으로써, 상 기 수험자의 관절 데이터의 행동 반경이 기설정된 안전 행동 범위를 벗어나는지 여부를 검출함으로써 수행될 수 있다. 본 발명의 일 실시 예에 따르면, 안전 행동에 해당하는지 여부를 판단하는 과정(S454)은, 비대면 평가를 수행중 인 수험자의 관절 데이터에서 손의 이동 형태를 인공 신경망 모델을 통해 정상행동과 부정행위로 판별함으로써 수행될 수 있다. 여기서, 인공 신경망 모델은 어떤 특정 부분이 반복되는 구조를 통해 순서를 학습면서 데이터 에서 규칙적인 패턴을 인식하고 과거의 정보를 통해 현재의 정보를 파악하는데 효과적인 딥러닝 기법인 RNN(Recurrent Neural Network)일 수 있고, RNN을 통해 정상행동과 부정행위로 판별할 수 있다. 일 예로, 도 12와 같이, 본 발명에 따른 인공 신경망 모델은 수험자의 손이 화면을 이탈하는 상황이 발생하면, 안전 행동을 벗어난 것으로 판단할 수 있다. 안전 행동에 해당하는지 여부를 판단하는 과정(S454)을 통해 상기 수험자의 행동이 부정행위에 해당하는 것으로 판단되면, 관리자를 통해 수험자 알림 및 대시보드 라벨링 과정(S42) 및 부정행위 확인 과정(S44)이 수행될 수 있으며, 부정행위 확인 과정(S44)의 결과에 따라 평가 몰수 과정(S46)이 수행되거나 혹은 부정행위 탐지 시작 과정(S40)으로 회귀될 수 있다. 일 실시예에 있어서, 행동 인식 과정(S45)은, 안전 행동에 해당하는지 여부를 판단하는 과정(S454)이 수행되기 이전에 수행되며, 상기 수험자에게 안전행동 자세에 대해 안내하는 과정을 더 포함할 수 있다. 도 13은 본 발명의 예시적인 실시예들에 따른 소리 감지를 이용한 부정행위 검출 단계를 설명하기 위한 순서도 이다. 도 13을 참조하면, 본 발명의 예시적인 실시예들에 따른 소리 감지 과정(S47)은 웹캠 마이크의 동작을 확인한 후 데시벨을 측정하고(S470), 측정된 소리의 데시벨이 안전 데시벨 범위(D)에 해당하는지 여부를 판단하고 (S471), 상기 소리가 발생한 구간을 획득하고(S472), 상기 획득된 소리 구간에 대해 음성 작동 감지를 수행하고 (S473), 상기 획득된 소리 구간에 음성이 감지되는지 여부를 판단함으로써(S474) 수행될 수 있다. 이때, 상기 안전 데시벨 범위(D)는 생활 소음을 수집한 값들의 평균값에 기저장된 오차범위를 더하고 뺀 값의 범위일 수 있으며, 상기 소리 구간은 10ms, 20ms, 30ms 등 10 ms의 단위로 획득될 수 있다. 예시적인 실시예들에 있어서, 상기 웹캠 마이크로부터 측정된 소리 데이터의 데시벨(dB)이 기설정된 안전 데시 벨 범위를 벗어나거나, 또는 상기 웹캠 마이크로부터 측정된 소리 데이터에 음성이 포함된 것을 감지하면 부정 행위에 해당하는 것으로 판단할 수 있으며, 이 경우 관리자를 통해 수험자 알림 및 대시보드 라벨링 과정(S42) 및 부정행위 확인 과정(S44)이 수행될 수 있으며, 부정행위 확인 과정(S44)의 결과에 따라 평가 몰수 과정(S4 6)이 수행되거나 혹은 부정행위 탐지 시작 과정(S40)으로 회귀될 수 있다. 이상에서는, 비대면 평가에서의 부정행위 방지 방법에 있어서, 본인 인증 과정(S41), 시선 추적 과정(S43), 행 동 인식 과정(S45) 및 소리 감지 과정(S47)이 순차적으로 수행하는 것을 설명하였으나, 본 발명의 개념은 반드 시 이에 한정되지 않는다. 즉, 본인 인증 과정(S41), 시선 추적 과정(S43), 행동 인식 과정(S45) 및 소리 감지 과정(S47)은 동시에 수행되거나 또는 기설명된 순서와 다르게 수행될 수도 있다. 전술한 바와 같이, 본 발명의 예시적인 실시예들에 따른 비대면 평가에서의 부정행위 방지 방법은 수험자의 촬 영 영상으로부터 추출된 데이터를 기초로 본인 인증 확인(S41), 시선 추적(S43), 행동 인식(S45) 및 소리 감지 (S45)를 통해 수험자의 부정행위를 방지할 수 있으며, 이에 따라 비대면 평가에서의 부정행위 발생이 방지될 수 있고, 평가 신뢰성이 향상될 수 있으며, 평가 결과의 공정성이 확립될 수 있다. 도 14는 본 발명의 예시적인 실시예들에 따른 비대면 평가에서의 부정행위 방지 방법을 실행시키기 위한 구성을 설명하기 위한 순서도이다.도 14를 참조하면, 본 발명의 예시적인 실시예들에 따른 비대면 평가에서의 부정행위 방지 방법을 수행하기 위 한 장치는 안면 검출모듈, 동공 검출모듈 및 관절 검출모듈을 통해 수행될 수 있으며, 상 기 안면 검출모듈, 상기 동공 검출모듈 및 상기 관절 검출모듈은 상기 컴퓨터에 일체로 설치된 카메라 또는 상기 컴퓨터와 별개로 설치된 카메라로부터 출력되는 수험자의 촬영 영상으로부터 상기 수험자의 얼굴영역 , 동공영역 및 관절영역을 검출하고 각각의 영역에 대한 데이터를 생성하도록 구비될 수 있다. 이때, 상기 안면 검출모듈, 상기 동공 검출모듈 및 상기 관절 검출모듈은 각각 아다부스트(adaboost) 및 서포트 벡터 머신(support vector machine, SVM), 신경망(neural network) 등의 얼굴 검출 알고리즘을 이용하여 수 있다. 특히, 상기 동공 검출모듈은 원 피팅(circle fitting) 및 타원 피팅(ellipse fitting) 등의 동공 검출 알고리 즘을 이용하여 동공 영역을 검출할 수 있다. 또한, 본 발명의 예시적인 실시예들에 따른 비대면 평가에서의 부정행위 방지 방법을 수행하기 위한 장치 는 소리 검출모듈을 더 포함할 수 있으며, 소리 검출모듈은 상기 컴퓨터에 일체로 설치된 웹캠 마이크 또는 상 기 컴퓨터와 별개로 설치된 웹캠 마이크로부터 출력되는 소리 데이터으로부터 데시벨(dB)을 측정하고 사람의 음 성을 감지하도록 구비될 수 있다. 예시적인 실시예들에 있어서, 안면 검출모듈, 동공 검출모듈 관절 검출모듈 및 소리 검출모듈 은 각각 본인 인증 과정(S41), 시선 추적 과정(S43), 행동 인식 과정(S45), 및 소리 감지 과정(S47)을 수 행하도록 구비될 수 있다. 한편, 본 발명의 예시적인 실시예들에 따른 비대면 평가에서의 부정행위 방지 방법을 수행하기 위한 장치 는 안면 검출모듈, 동공 검출모듈 관절 검출모듈, 및 소리 검출모듈를 제어하기 위한 제어 부, 안면 검출모듈, 동공 검출모듈 관절 검출모듈, 및 소리 검출모듈로부터 생성된 데이터를 저장하기 위한 저장부, 및 상기 데이터를 서버로 송신하거나 상기 서버로부터 정보를 수신하기 위한 통신부를 더 포함할 수 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위 내에서 다양한 수정, 변경 및 치환이 가능할 것이다. 따라서, 본 발명에 개시된 실시 예 및 첨부된 도면들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명 하기 위한 것이고, 이러한 실시 예 및 첨부된 도면에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니 다. 본 발명의 보호 범위는 아래의 청구 범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기 술 사상은 본 발명의 권리 범위에 포함되는 것으로 해석되어야 할 것이다. 한편, 상술한 본 발명의 다양한 실시 예들에 따른 방법은 프로그램으로 구현되어 서버 또는 기기들에 제공될 수 있다. 이에 따라 각 장치들은 프로그램이 저장된 서버 또는 기기에 접속하여, 상기 프로그램을 다운로드 할 수 있다. 또한, 상술한 본 발명의 다양한 실시 예들에 따른 방법은 프로그램으로 구현되어 다양한 비일시적 판독 가능 매 체(non-transitory computer readable medium)에 저장되어 제공될 수 있다. 비일시적 판독 가능 매체란 레지스 터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등과 같은 비일시적 판독 가 능 매체에 저장되어 제공될 수 있다. 또한, 이상에서는 본 발명의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2021-0098950", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14"}
{"patent_id": "10-2021-0098950", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 예시적인 실시예들에 따른 비대면 평가의 수행 방법을 설명하기 위한 순서도이다. 도 2는 상기 비대면 평가에서의 평가 접수 단계를 설명하기 위한 순서도이다. 도 3은 상기 비대면 평가에서의 사전 점검 단계를 설명하기 위한 순서도이다. 도 4는 상기 비대면 평가에서의 평가 준비 단계를 설명하기 위한 순서도이다. 도 5는 상기 비대면 평가에서의 시험 진행 단계를 설명하기 위한 순서도이다. 도 6은 본 발명의 예시적인 실시예들에 따른 본인 인증 과정을 이용한 부정행위 검출 단계를 설명하기 위한 순 서도이다. 도 7은 본 발명의 예시적인 실시예들에 따른 인공지능 기반 안면 인증에 대해 보다 구체적으로 설명하기 위한 도면이다. 도 8은 본 발명의 예시적인 실시예들에 따른 시선 추적을 이용한 부정행위 검출 단계를 설명하기 위한 도면이다. 도 9는 본 발명의 일 실시 예에 따른 랜드마크를 이용한 얼굴 영역 및 양쪽 눈 영역 추출 과정을 설명하기 위한 예시도이다. 도 10은 수험자의 동공이 응시하는 영역을 분류하기 위한 스크린 좌표의 배치 구조를 설명하기 위한 도면이다. 도 11 내지 도 12는 본 발명의 예시적인 실시예들에 따른 행동 인식을 이용한 부정행위 검출 단계를 설명하기 위한 도면들이다. 도 13은 본 발명의 예시적인 실시예들에 따른 소리 감지를 이용한 부정행위 검출 단계를 설명하기 위한 순서도 이다. 도 14는 본 발명의 예시적인 실시예들에 따른 비대면 평가에서의 부정행위 방지 방법을 실행시키기 위한 구성을 설명하기 위한 블록도이다."}
