{"patent_id": "10-2024-7011114", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0052056", "출원번호": "10-2024-7011114", "발명의 명칭": "캐시 메모리, 로컬 데이터 저장소 및 레지스터 파일 간의 저장소 공유 프로세싱 디바이스 및", "출원인": "어드밴스드 마이크로 디바이시즈, 인코포레이티드", "발명자": "카자코프 막심 브이."}}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "가속 프로세싱 디바이스로서,복수의 컴퓨트 유닛들 - 상기 복수의 컴퓨트 유닛들 각각은:각각이 레지스터 파일을 포함하는 복수의 SIMD(single-instruction multiple-data) 유닛들; 및상기 SIMD 유닛들 각각과 통신하는 로컬 데이터 저장소(LDS)를 포함함 -; 및컴퓨트 유닛의 상기 복수의 SIMD 유닛들 각각과 통신하는 제1 부분 및 상기 복수의 컴퓨트 유닛들 중 둘 이상에의해 공유되는 제2 부분을 포함하는 캐시 메모리를 포함하고,상기 컴퓨트 유닛들은 실행 동안 SIMD 유닛의 상기 레지스터 파일, 캐시 메모리의 상기 제1 부분 및 상기 LDS중 적어도 하나의 저장 부분이 상기 레지스터 파일, 캐시 메모리의 상기 제1 부분 및 상기 LDS 중 다른 하나의일부로서 예약되는 프로그램을 실행하도록 구성되는, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 저장 부분은 상기 프로그램의 컴파일링 시에 상기 저장 부분을 인스턴스화함으로써 상기레지스터 파일, 캐시 메모리의 상기 제1 부분 및 상기 LDS 중 상기 다른 하나의 일부로서 예약되는, 프로세싱디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 가속 프로세싱 디바이스는 GPU, 컴퓨트 프로세서 및 인공 지능 프로세서 중 하나인, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 레지스터 파일, 캐시 메모리의 상기 제1 부분 및 상기 LDS 중 다른 하나의 일부로서 예약된 상기 저장 부분은 상기 실행되는 프로그램에 기초하여 결정되는, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 레지스터 파일의 상기 저장 부분은 캐시 메모리의 상기 제1 부분의 일부로서 예약되고,상기 컴퓨트 유닛은:상기 레지스터 파일의 다른 저장 부분의 데이터를 사용하여 상기 프로그램의 제1 부분을 실행하고;상기 레지스터 파일의 상기 다른 저장 부분으로부터의 데이터를 캐시 메모리의 상기 제1 부분의 일부로서 예약된 상기 레지스터 파일의 상기 저장 부분에 저장하고;상기 프로그램의 제2 부분을 실행하기 위해 캐시 메모리의 상기 제1 부분의 일부로서 예약된 상기 레지스터 파일의 상기 저장 부분으로부터 상기 레지스터 파일의 상기 다른 저장 부분으로 상기 데이터를 재로딩하도록 구성되는, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 프로그램의 상기 제1 부분 및 상기 프로그램의 상기 제2 부분은 웨이브프론트들인, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 레지스터 파일의 상기 저장 부분은 상기 컴퓨트 유닛의 다른 SIMD 유닛들에 의해 공유되공개특허 10-2024-0052056-3-는, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서, 상기 저장 부분은 상기 레지스터 파일의 SRAM(Static Random Access Memory)의 일부인, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 레지스터 파일은 레지스터들의 뱅크들을 포함하고,캐시 메모리의 상기 제1 부분의 일부로서 예약된 상기 레지스터 파일의 상기 저장 부분은 적어도 하나의 레지스터들의 뱅크를 포함하는, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "프로그램을 실행하는 방법으로서,레지스터 파일의 제1 부분의 데이터를 사용하여 가속 프로세싱 디바이스의 컴퓨트 유닛에서 상기 프로그램의 제1 부분을 실행하는 단계;상기 레지스터 파일의 상기 제1 부분으로부터 제1 레벨 캐시 메모리의 일부로서 인스턴스화된 상기 레지스터 파일의 제2 부분으로 데이터를 저장하는 단계; 및상기 프로그램의 제2 부분을 실행하기 위해 상기 레지스터 파일의 상기 제2 부분에 저장된 상기 데이터를 상기레지스터 파일의 상기 제1 부분에 재로딩하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 컴퓨트 유닛의 제1 SIMD(single-instruction-multiple-data) 유닛에서 상기 프로그램의상기 제1 부분 및 상기 프로그램의 상기 제2 부분을 실행하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 프로그램의 상기 제1 부분 및 상기 프로그램의 상기 제2 부분은 웨이브프론트들인,방법."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 레지스터 파일의 상기 제2 부분은 컴파일링 시에 상기 제1 레벨 캐시 메모리의 일부로서인스턴스화되는, 방법."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서, 상기 레지스터 파일은 컴퓨트 유닛의 SIMD(single-instruction-multiple-data) 유닛의 일부이고,상기 레지스터 파일의 상기 제2 부분은 상기 컴퓨트 유닛의 다른 SIMD 유닛들에 의해 공유되는, 방법."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 레지스터 파일의 상기 제2 부분으로부터 상기 다른 SIMD 유닛들 중 하나의 레지스터 파일로 데이터를 로딩하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "프로세싱 디바이스로서,메모리; 및가속 프로세싱 디바이스로서, 상기 가속 프로세싱 디바이스는:복수의 컴퓨트 유닛들 - 상기 복수의 컴퓨트 유닛들 각각은:공개특허 10-2024-0052056-4- 각각이 레지스터 파일을 포함하는 복수의 SIMD(single-instruction multiple-data) 유닛들; 및 상기 SIMD 유닛들 각각과 통신하는 로컬 데이터 저장소(LDS)를 포함함 - 을 포함하는, 상기 가속 프로세싱 디바이스; 및상기 SIMD 유닛들 각각과 통신하는 제1 레벨 및 상기 컴퓨트 유닛들 사이에 공유되는 제2 레벨을 포함하는 캐시메모리를 포함하고,상기 컴퓨트 유닛들은 SIMD 유닛의 상기 레지스터 파일, 상기 제1 레벨 캐시 메모리, 및 상기 LDS 중 적어도 하나의 저장 부분이 상기 레지스터 파일, 상기 제1 레벨 캐시 메모리, 및 상기 LDS 중 다른 하나의 일부로서 예약되는 프로그램을 실행하도록 구성되는, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 레지스터 파일의 상기 저장 부분은 상기 제1 레벨 캐시 메모리의 일부로서 예약되고,상기 컴퓨트 유닛은:상기 레지스터 파일의 다른 저장 부분의 데이터를 사용하여 상기 프로그램의 제1 부분을 실행하고;상기 레지스터 파일의 상기 다른 저장 부분으로부터의 데이터를 상기 제1 레벨 캐시 메모리의 일부로서 예약된상기 레지스터 파일의 상기 저장 부분에 저장하고;상기 프로그램의 제2 부분을 실행하기 위해 상기 제1 레벨 캐시 메모리의 일부로서 예약된 상기 레지스터 파일의 상기 저장 부분으로부터 상기 레지스터 파일의 상기 다른 저장 부분으로 상기 데이터를 재로딩하도록 구성되는, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 레지스터 파일의 상기 저장 부분과 상기 레지스터 파일의 상기 다른 저장 부분 사이의제1 대역폭은 상기 레지스터 파일과 상기 제2 레벨 캐시 메모리 사이의 제2 대역폭보다 큰, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서, 상기 레지스터 파일의 상기 제2 부분으로부터 다른 SIMD 유닛들 중 하나의 레지스터 파일로데이터를 로딩하는 것을 더 포함하는, 프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 실행될 상기 프로그램에 기초하여 상기 레지스터 파일, 상기 제1 레벨 캐시 메모리 및 상기LDS 중 다른 하나의 일부로서 예약된 상기 저장 부분의 양을 결정하는 중앙 프로세싱 유닛(CPU)을 더 포함하는,프로세싱 디바이스."}
{"patent_id": "10-2024-7011114", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "각각이 복수의 SIMD 유닛들을 포함하는 복수의 컴퓨트 유닛들을 포함하는 가속 프로세싱 디바이스가 제공되고, 각각의 SIMD 유닛은 레지스터 파일을 포함한다. 가속 프로세싱 디바이스는 또한 SIMD 유닛들 각각과 통신하는 LDS를 포함한다. 가속 프로세싱 디바이스는 또한 SIMD 유닛들 각각과 통신하는 캐시 메모리의 제1 부분 및 컴퓨 트 유닛들에 의해 공유되는 캐시 메모리의 제2 부분을 포함한다. 컴퓨트 유닛들은, SIMD 유닛의 레지스터 파일, 캐시 메모리의 제1 부분 및 LDS 중 적어도 하나의 저장 부분이 레지스터 파일, 캐시 메모리의 제1 부분 및 LDS 중 다른 하나의 일부로서 예약되는 프로그램을 실행하도록 구성된다."}
{"patent_id": "10-2024-7011114", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원에 대한 상호 참조 본 출원은 2021년 9월 3일에 출원된 미국 정규특허출원 제17/467,104호의 이익을 주장하며, 그 내용은 본 명세 서에 참고로 포함된다."}
{"patent_id": "10-2024-7011114", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "그래픽 프로세싱 유닛들(graphical processing units; GPU들), 인공 지능 프로세서들 및 컴퓨트 프로세서들과 같은 가속 프로세싱 디바이스들(Accelerated processing devices; APD들)은 병렬 프로세싱 에 적합한 연산들 (예를 들어, 그래픽 연산들)의 프로세싱을 가속화하는 데 사용된다. GPU들은 단일 명령어 다중 데이터(single- instruction-multiple-data; SIMD) 패러다임에 따라 병렬 방식으로 연산들을 수행하는 복수의 프로세서 코어들 (예를 들어, 컴퓨트 유닛들(compute units; CU들))을 포함한다."}
{"patent_id": "10-2024-7011114", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "GPU들은, CU들에 더하여, 상이한 레벨 캐시들(예를 들어, 레벨 1 캐시(L1 캐시) 및 레벨 2 캐시(L2 캐시))을 포 함한다. 각각의 CU는 L1 캐시 및 로컬 데이터 저장소(local data storage; LDS)를 포함한다. L1 캐시 및 LDS는 CU의 SIMD 유닛들 사이에서 공유된다. L1 캐시는 (다른 CU들에 의해 공유되는) 레벨 2 캐시 및 메인 메모리를 또한 포함하는 GPU 메모리의 일부이다. 일부 구현예들에서, L1 캐시 저장소는 HW 캐시 로직에 의해 관리된다. LDS 저장소는 CU 상에서 실행되는 소프트 웨어 커널에 의해 관리된다. CU와 L1 캐시 사이의 대역폭이 CU와 메모리의 다른 부분들 (예를 들어, L2 캐시 및 메인 메모리) 사이의 대역폭보다 크기 때문에, L1 캐시는 CU들에 의해 빈번하게 액세스되는 데이터를 저장하는 데 사용된다. 마찬가지로, CU와 LDS 사이의 대역폭은 CU의 SIMD 유닛들 사이에서 데이터를 공유하기에는 상대적 으로 크다. L1 캐시는 전형적으로 16KB와 32KB 사이의 용량을 갖는다. LDS는 전형적으로 GPU가 준수하는 표준들 (예를 들어, 그래픽 표준들)에 의해 정의된 고정된 용량(예를 들어, 64KB 이상)을 갖는다. L1 캐시의 용량을 증가시키는 것은 L1 캐시가 더 빈번하게 액세스되는 데이터를 저장할 수 있게 한다. 그러나, L1 캐시 및 LDS 둘 모두는 각각 CU에서 실리콘 영역을 점유한다. 따라서, L1 캐시가 더 빈번하게 액세스되는 데 이터를 저장할 수 있도록 L1 캐시의 용량을 증가시키는 것은 또한 GPU에서 L1 캐시의 영역을 증가시킨다. 일부 종래의 가속 프로세서들에서, L1 캐시 및 LDS의 데이터 저장소들은 서로 공유된다. 예를 들어, LDS의 더 적은 저장 공간이 사용되어야 한다고 결정되면, LDS의 64KB의 일부(예를 들어, 16KB)는 LDS에 의한 사용을 위해 예약될 수 있고, LDS의 64KB의 나머지 부분은 더 빈번하게 액세스되는 데이터를 저장하기 위해 L1 캐시에 의해 사용될 수 있다. 이러한 종래의 가속 프로세서들은 전체 영역이 더 효율적으로 사용될 수 있게 하지만, 일부 애 플리케이션들은 L1 캐시의 훨씬 더 많은 저장 용량을 사용하는 것이 이로울 것이다. 프로그램의 일부(예를 들어, 명령어(instruction)들의 블록)는 전형적으로 웨이브프론트(wavefront)들로 분할되 며, 이들 각각은 동일한 제어 흐름 경로를 따르는 다수의 작업-아이템들 또는 스레드들을 포함한다. 레지스터 파일들은 CU의 각각의 SIMD 유닛에 할당되고, 블록 내의 각각의 웨이브프론트는 할당된 레지스터 파일들을 사용 하여 CU의 SIMD 유닛들 상에서 스케줄링되고 프로세싱된다. 웨이브프론트당 레지스터 파일 풋프린트의 크기(즉, 웨이브프론트를 프로세싱하기 위해 할당된 레지스터의 수)가 컴파일링 시에 결정된다. 웨이브프론트당 레지스터 파일 풋프린트가 감소될 때, 더 많은 웨이브들이 병렬로 프로세싱될 수 있고, 이는, 프로세싱되고 있는 다른 웨 이브프론트들이 메모리로부터의 데이터를 기다리고 있는 동안(즉, 메모리 액세스들) 더 많은 웨이브프론트들이 CU에 의해 병렬로 스케줄링 및 프로세싱될 수 있기 때문에, 전체 레이턴시를 감소시킬 수 있다. 웨이브프론트당 레지스터 파일 풋프린트가 증가될 때, 메모리 액세스들의 전체 수는 감소되지만, 더 적은 웨이브프론트들이 CU 에 의해 병렬로 프로세싱될 수 있다. 런타임 시에, 블록의 웨이브프론트들은 웨이브프론트당 결정된 레지스터 파일 풋프린트에 따라 스케줄링되고, CU의 상이한 SIMD 유닛들 상에서 병렬로 프로세싱되거나 또는 동일한 SIMD 유닛 상에서 직렬로 프로세싱된다. CU들의 레지스터 파일들의 용량은 256 KB 내지 512 KB의 범위이다. 즉, 레지스터 파일들의 용량과 그 영역이 L1 캐시와 LDS의 용량과 영역보다 크다. 그러나, 레지스터 파일들의 저장소는 GPU에서 실행되는 프로그램의 상이한 부분들(예를 들어, 웨이브프론트들) 사이에서 쉽게 공유되지 않으며, 일부 경우들에서, 레지스터 파일들은 완전 히 점유되지 않는다. 예를 들어, 종래의 아키텍처에서, 레지스터 파일들의 정적 랜덤 액세스 메모리(SRAM)의 부 분들은 SIMD 유닛들 사이에서 공유되지 않는다. 따라서, 프로그램의 실행이 제1 SIMD 유닛의 레지스터들의 데이 터를 제2 SIMD 유닛에 이용 가능하게 하는 것을 포함할 때, 제1 SIMD 유닛은 먼저 데이터를 LDS, L1 캐시 또는 메모리의 다른 부분에 푸시하고, 이로부터 그런 다음 데이터가 제2 SIMD 유닛에 의해 액세스된다. 따라서, 웨이브프론트의 스레드는 메모리(예를 들어, 메인 메모리)를 통해 동일한 웨이브프론트의 다른 스레드 에 간접적으로 액세스할 수 있지만, 데이터에 직접 액세스하는 것보다 더 큰 레이턴시 기간을 갖는다. 그러나 웨이브프론트의 스레드는 레지스터 파일을 통해 동일한 웨이브프론트의 다른 스레드에 직접 액세스할 수 없다. 본 개시의 특징들은 L1 캐시, LDS 및 레지스터 파일들의 조합된 저장소를 공유함으로써 프로그램의 효율적인 프 로세싱을 위한 디바이스들 및 방법들을 제공한다. 종래의 아키텍처에서 다른 SIMD 유닛들에 의해 공유되지 않는 레지스터 파일들의 SRAM의 부분들은 L1 캐시 및 LDS를 위해 예약되고 CU의 SIMD 유닛들 사이에서 공유된다. L1 캐시 및 LDS에 대해 예약되는 레지스터 파일들의 부분들의 양 또는 크기는 실행될 애플리케이션에 기초한다. 즉, L1 캐시, LDS 및 레지스터 파일들 사이의 파티셔닝(partitioning)은 실행될 특정 애플리케이션에 맞게 조정된다. 예를 들어, 실행될 애플리케이션이 큰 L1 캐시 용량을 요구하지만 더 큰 레지스터 파일을 요구 하지 않는 애플리케이션인 것으로 결정될 때, 레지스터 파일들의 더 큰 부분이 추가적인 L1 캐시 저장소로서 사 용하기 위해 예약된다. 대안적으로, 실행될 애플리케이션이 더 큰 레지스터 파일을 요구하지만 큰 L1 캐시 용량 또는 LDS를 요구하지 않는 애플리케이션인 것으로 결정될 때, 레지스터 파일들의 더 작은 부분이 L1 캐시 또는 LDS에 대해 예약되거나 또는 레지스터 파일들의 어떠한 부분도 예약되지 않는다. 각각이 복수의 SIMD 유닛들을 포함하는 복수의 컴퓨트 유닛들을 포함하는 가속 프로세싱 디바이스가 제공되고, 각각의 SIMD 유닛은 레지스터 파일을 포함한다. 가속 프로세싱 디바이스는 또한 SIMD 유닛들 각각과 통신하는 LDS를 포함한다. 가속 프로세싱 디바이스는 또한 SIMD 유닛들 각각과 통신하는 캐시 메모리의 제1 부분 및 컴퓨 트 유닛들에 의해 공유되는 메모리의 제2 캐시 부분을 포함한다. 컴퓨트 유닛들은, SIMD 유닛의 레지스터 파일, 캐시 메모리의 제1 부분 및 LDS 중 적어도 하나의 저장 부분이 레지스터 파일, 캐시 메모리의 제1 부분 및 LDS 중 다른 하나의 일부로서 예약되는 프로그램을 실행하도록 구성된다. 레지스터 파일의 제1 부분의 데이터를 사용하여 가속 프로세싱 디바이스의 컴퓨트 유닛에서 프로그램의 제1 부 분을 실행하는 단계, 레지스터 파일의 제1 부분으로부터의 데이터를 제1 레벨 캐시 메모리의 일부로서 인스턴스 화된 레지스터 파일의 제2 부분에 저장하는 단계, 및 프로그램의 제2 부분을 실행하기 위해 레지스터 파일의 제 2 부분에 저장된 데이터를 레지스터 파일의 제1 부분에 재로딩하는 단계를 포함하는, 프로그램을 실행하는 방법 이 제공된다. 가속 프로세싱 디바이스를 포함하는 프로세싱 디바이스가 제공된다. 가속 프로세싱 디바이스는 메모리 및 복수 의 컴퓨트 유닛을 포함하고, 각각의 컴퓨트 유닛은 복수의 SIMD 유닛을 포함하고, 각각의 SIMD 유닛은 레지스터 파일을 포함한다. 가속 프로세싱 디바이스는 또한 SIMD 유닛들 각각과 통신하는 LDS를 포함한다. 가속 프로세싱 디바이스는 또한 SIMD 유닛들 각각과 통신하는 제1 레벨 및 컴퓨트 유닛들 사이에 공유되는 제2 레벨을 포함하 는 캐시 메모리를 포함한다. 컴퓨트 유닛들은 SIMD 유닛의 레지스터 파일, 제1 레벨 캐시 메모리, 및 LDS 중 적 어도 하나의 저장 부분이 레지스터 파일, 제1 레벨 캐시 메모리 및 LDS 중 다른 하나의 일부로서 예약되는 프로 그램을 실행하도록 구성된다. 도 1은 본 개시의 하나 이상의 특징이 구현될 수 있는 예시적인 디바이스의 블록도이다. 디바이스는 예를 들어, 컴퓨터, 게이밍 디바이스, 핸드헬드 디바이스, 셋톱 박스, 텔레비전, 모바일 폰, 또는 태블릿 컴퓨 터를 포함할 수 있다. 디바이스는 프로세서, 메모리, 저장소, 하나 이상의 입력 디바이스 , 및 하나 이상의 출력 디바이스를 포함한다. 디바이스는 또한 선택적으로 입력 드라이버 및 출력 드라이버를 포함할 수 있다. 디바이스는 도 1에 도시되지 않은 추가적인 컴포넌트들을 포함 할 수 있다는 것이 이해된다. 다양한 대안들에서, 프로세서는 중앙 프로세싱 유닛(CPU), GPU, 동일한 다이 상에 위치된 CPU 및 GPU, 또 는 하나 이상의 프로세서 코어들을 포함하고, 각각의 프로세서 코어는 CPU 또는 GPU일 수 있다. 다양한 대안들 에서, 메모리는 프로세서와 동일한 다이 상에 위치되거나 또는 프로세서와 별도로 위치된다. 메 모리는 휘발성 또는 비휘발성 메모리, 예를 들어, 랜덤 액세스 메모리(RAM), 동적 RAM(DRAM), 또는 캐시를 포함한다. 저장소는 고정 또는 제거 가능한 저장소, 예를 들어, 하드 디스크 드라이브, 솔리드 스테이트 드라이브, 광학 디스크, 또는 플래시 드라이브를 포함한다. 입력 디바이스들은 키보드, 키패드, 터치 스크린, 터치 패드, 검출기, 마이크로폰, 가속도계, 자이로스코프, 바이오메트릭 스캐너, 또는 네트워크 연결(예를 들어, 무 선 IEEE 802 신호들의 송신 및/또는 수신을 위한 무선 로컬 영역 네트워크 카드)을 포함하지만, 이에 제한되지 않는다. 출력 디바이스들은 디스플레이, 스피커, 프린터, 햅틱 피드백 디바이스, 하나 이상의 조명들, 안테나, 또는 네트워크 연결(예를 들어, 무선 IEEE 802 신호들의 송신 및/또는 수신을 위한 무선 로컬 영역 네트 워크 카드)을 포함하지만, 이에 제한되지 않는다. 입력 드라이버는 프로세서 및 입력 디바이스들과 통신하고, 프로세서가 입력 디바이스들 로부터 입력을 수신하도록 허용한다. 출력 드라이버는 프로세서 및 출력 디바이스들과 통 신하고, 프로세서가 출력 디바이스들에 출력을 발송하도록 허용한다. 입력 드라이버 및 출력 드 라이버는 선택적인 컴포넌트들이며, 입력 드라이버 및 출력 드라이버가 존재하지 않는 경우에 디바이스는 동일한 방식으로 동작할 것이라는 점에 유의한다. 출력 드라이버는 디스플레이 디바이스 에 결합된 APD를 포함한다. APD는 프로세서로부터의 컴퓨트 커맨드들(commands) 및 그래픽 렌더 링 커맨드들을 수락하고, 이들 컴퓨트 및 그래픽 렌더링 커맨드들을 프로세싱하고, 디스플레이를 위해 디스플레 이 디바이스에 픽셀 출력을 제공하도록 구성된다. 아래에서 더 상세히 설명되는 바와 같이, APD는 SIMD 패러다임에 따라 계산들을 수행하도록 구성된 하나 이상의 병렬 프로세싱 유닛들을 포함한다. 따라서, 다 양한 기능성(functionality)이 APD에 의해 또는 그와 함께 수행되는 것으로 본 명세서에서 설명되지만, 다 양한 대안들에서, APD에 의해 수행되는 것으로 설명된 기능성은 호스트 프로세서(예를 들어, 프로세서 )에 의해 구동되지 않고 디스플레이 디바이스에 그래픽 출력을 제공하도록 구성되는 유사한 능력들을 갖는 다른 컴퓨팅 디바이스들에 의해 추가적으로 또는 대안적으로 수행된다. 예를 들어, SIMD 패러다임에 따라 프로세싱 태스크들(tasks)을 수행하는 임의의 프로세싱 시스템이 본 명세서에서 설명된 기능성을 수행하도록 구 성될 수 있다는 것이 고려된다. 대안적으로, SIMD 패러다임에 따라 프로세싱 태스크들을 수행하지 않는 컴퓨팅 시스템들이 본 명세서에서 설명된 기능성을 수행하는 것이 고려된다. 도 2는 APD 상에서 프로세싱 태스크들의 실행과 관련된 추가적인 세부사항들을 예시하는 장치의 블록 도이다. 프로세서는 프로세서에 의한 실행을 위해 시스템 메모리에 하나 이상의 제어 로직 모듈 들을 유지한다. 제어 로직 모듈들은 운영 체제, 커널 모드 드라이버 및 애플리케이션들을 포함 한다. 이러한 제어 로직 모듈들은 프로세서 및 APD의 동작의 다양한 특징들을 제어한다. 예를 들어, 운영 체제는 하드웨어와 직접 통신하고 프로세서 상에서 실행되는 다른 소프트웨어를 위해 하드웨어 에 대한 인터페이스를 제공한다. 커널 모드 드라이버는 예를 들어, APD의 다양한 기능성에 액세스하 기 위해 프로세서 상에서 실행되는 소프트웨어(예를 들어, 애플리케이션)에 애플리케이션 프로그래밍 인터페이스(\"API\")를 제공함으로써, APD의 동작을 제어한다. 커널 모드 드라이버는 또한 APD의 프로세싱 컴포넌트(아래에서 더 상세히 논의되는 SIMD 유닛과 같은)에 의한 실행을 위한 프로그램을 컴파 일하는 저스트 인타임 컴파일러(Just-in-Time compiler)를 포함한다. APD는 병렬 프로세싱에 적합할 수 있는 비-그래픽 연산들 뿐만 아니라 그래픽 연산들과 같은 선택된 기능 들을 위한 커맨드들 및 프로그램들을 실행한다. APD는 픽셀 연산들(pixel operations), 기하학적 계산과 같은 그래픽 파이프라인 연산들을 실행하고 프로세서로부터 수신된 커맨드들에 기초하여 디스플레이 디바 이스에 이미지를 렌더링하는 데 사용될 수 있다. APD는 또한 프로세서로부터 수신된 커맨드에 기초하여 비디오, 물리 시뮬레이션, 전산 유체 역학, 또는 다른 태스크와 관련된 연산들과 같은 그래픽 연산들 과 직접 관련되지 않은 컴퓨팅 프로세싱 연산들을 실행한다. APD는 SIMD 패러다임에 따라 병렬 방식으로 프로세서의 요청에 따라 동작들을 수행하는 하나 이상의 SIMD 유닛들을 포함하는 컴퓨트 유닛들을 포함한다. SIMD 패러다임은 다수의 프로세싱 엘리먼트들이 단일 프로그램 제어 플로우 유닛 및 프로그램 카운터를 공유하여 동일한 프로그램을 실행하지만 상이한 데이터 로 그 프로그램을 실행할 수 있다. 일 예에서, 각각의 SIMD 유닛은 16개의 레인들을 포함하고, 여기서 각 각의 레인은 SIMD 유닛 내의 다른 레인들과 동일한 시간에 동일한 명령어를 실행하지만 상이한 데이터로 그 명령어를 실행할 수 있다. 모든 레인이 주어진 명령어를 실행할 필요가 없는 경우 레인은 예측(predicatio n)으로 스위칭 오프될 수 있다. 예측은 또한 발산 제어 흐름(divergent control flow)으로 프로그램을 실행하는 데 사용될 수 있다. 보다 구체적으로, 제어 흐름이 개별 레인에 의해 수행되는 계산들에 기초하는 조건부 브랜 치 또는 다른 명령어들을 갖는 프로그램들에 대해, 현재 실행되고 있지 않은 제어 흐름 경로들에 대응하는 레인 들의 예측, 및 상이한 제어 흐름 경로들의 직렬 실행은 임의의 제어 흐름을 허용한다. 컴퓨트 유닛들에서의 실행의 기본 유닛은 작업-아이템(work-item)이다. 각각의 작업-아이템은 특정 레인에 병렬로 실행될 프로그램의 단일 인스턴스화(instantiation)를 나타낸다. 작업-아이템들은 단일 SIMD 프로세싱 유닛 상에서 웨이브프론트로서 동시에 실행될 수 있다. 하나 이상의 웨이브프론트들은 동일한 프로그램을 실행하도록 지정된 작업-아이템들의 컬렉션을 포함하는 작업 그룹에 포함된다. 작업 그룹을 구성하는 각각의 웨 이브프론트를 실행함으로써 작업 그룹을 실행할 수 있다. 대안적으로, 웨이브프론트들은 단일 SIMD 유닛상에서 순차적으로 또는 상이한 SIMD 유닛들 상에서 부분적으로 또는 완전히 병렬로 실행된다. 웨이브프론 트들은 단일 SIMD 유닛 상에서 동시에 실행될 수 있는 작업-아이템들의 최대 컬렉션으로 간주될 수 있다. 따라서, 프로세서로부터 수신된 커맨드들이 특정 프로그램이 단일 SIMD 유닛 상에서 동시에 실행될 수 없는 정도로 병렬화되어야 한다고 표시하면, 그 프로그램은 둘 이상의 SIMD 유닛들 상에서 병렬화되거 나 동일한 SIMD 유닛 상에서 직렬화되는(또는 필요에 따라 병렬화되고 직렬화되는 둘 모두) 웨이브프론트 들로 분할된다. 스케줄러는 상이한 컴퓨트 유닛들 및 SIMD 유닛들 상에서 다양한 웨이브프론트 들을 스케줄링하는 것과 관련된 동작들을 수행한다. 컴퓨트 유닛들에 의해 제공되는 병렬성(parallelism)은 픽셀 값 계산들, 정점 변환들(vertex transformations), 및 다른 그래픽 연산들과 같은 그래픽 관련 연산들에 적합하다. 따라서, 일부 경우들에서, 프로세서로부터 그래픽 프로세싱 커맨드들을 수용하는 그래픽 파이프라인은 병렬로 실행하기 위해 계 산 태스크들을 컴퓨트 유닛들에 제공한다. 컴퓨트 유닛들은 또한 그래픽들과 관련되지 않거나 또는 그래픽 파이프라인의 정상 동작의 일부로서 수행되지 않은 계산 태스크들(예를 들어, 그래픽 파이프라인의 동작을 위해 수행되는 프로세싱을 보충하기 위해 수행되는 커스텀 동작들)을 수행하기 위해 사용된다. 프로세서 상에서 실행되는 애플리케이션 또는 다른 소프트웨어는 실행을 위해 이러한 계산 태스크를 정의하는 프로그램을 APD로 송신한다. 아래에서 더 상세히 설명되는 바와 같이, APD는 L1 캐시, LDS 및 레지스터 파일들의 조합된 저장소를 공유 하도록 구성된다. 메모리 블록들 중 하나 이상의 부분들(즉, 레지스터 파일의 SRAM, LDS 및 L1 캐시)은 실행될 애플리케이션에 기초하여 다른 메모리 블록들 중 하나 이상에 대해 예약(즉, 인스턴스화)된다. L1 캐시, LDS 및 레지스터 파일들 사이의 파티셔닝은 애플리케이션에 의한 L1 캐시, LDS 및 레지스터 파일들의 특정 사용에 맞게 조정된다. 도 3은 본 개시의 하나 이상의 특징들을 구현하기 위한 도 2에 도시된 APD의 CU의 예시적인 컴포넌트 들을 예시하는 블록도이다. 간략화된 설명을 위해, APD는 APD의 예인 GPU로서 설명된다. 도 3에 도시된 바와 같이, 컴퓨트 유닛의 각각의 SIMD 유닛은 레지스터 파일의 뱅크들을 포함한다. 도 3의 예에 도시된 바와 같이, 각각의 레지스터 파일은 128KB 저장 용량을 갖고, 각각 32KB 저 장 용량을 갖는 4개의 뱅크를 포함한다. 도 3에 도시된 SIMD 유닛들의 수 및 각 레지스터 파일의 뱅크의 수는 예시적인 것에 불과하다. 본 개시의 특징들은 임의의 수의 뱅크들을 갖는 레지스터 파일들 및 임의의 수의 SIMD 유닛들을 갖는 CU들을 사용하여 구현될 수 있다. 또한, 도 3에 도시된 레지스터 파일들 및 뱅크들의 용량 은 예시적인 것에 불과하다. 본 개시의 특징들은 도 3에 도시된 것들과 상이한 용량들로 구현될 수 있다. CU는 또한 상호접속부(interconnect)를 통해 4개의 SIMD 유닛들 각각과 통신하고 GPU의 다음 레벨 메모리(예를 들어, L2 캐시, L3 캐시, 메인 메모리)와 통신하는 L1 캐시를 포함한다. 따라서, 임의의 SIMD 유닛은 L1 캐시 또는 메모리의 임의의 다른 부분으로부터 데이터를 요청할 수 있다. LDS는 상호접속부의 사용을 통해 4개의 SIMD 유닛들 각각과 통신하고, 임의의 SIMD 유닛들(13 8)에 의해 액세스가능하고 데이터를 공유할 수 있다. 따라서, 임의의 SIMD 유닛이 데이터를 LDS로 푸 시할 수 있고 다른 SIMD 유닛이 LDS로부터 그 데이터를 풀링할 수 있다. 대조적으로, 종래의 아키텍 처에서, 각각의 SIMD 유닛의 레지스터 파일들은 각각의 SIMD 유닛들에 프라이빗(private)하고 다른 SIMD 유닛들에 의해 공유되지 않는다. 따라서, SIMD 유닛이 데이터를 다른 SIMD 유닛들에 이용가능하게 하기를 원하는 경우, SIMD 유닛은 데이터를 LDS, L1 캐시 (또는 더 긴 레이턴시를 초래할 메모리의 다른 부분)에 푸시하여 다른 SIMD 유닛에 액세스될 수 있게 한다. 본 개시의 특징들은, 전형적으로 다른 SIMD 유닛들에 의해 공유되지 않는 레지스터 파일들의 SRAM의 부분 들을, 상호접속부를 통한 L1 캐시 및 상호접속부를 통한 LDS에 대해 예약하므로, 그리고, 따라서, SIMD 유닛들 사이에서 공유 가능하다. L1 캐시 및 LDS에 대해 예약되는 레지스터 파일 들의 부분들의 양 또는 크기는 실행될 애플리케이션에 기초한다. 3개의 하드웨어 블록에 걸쳐 공유함으로써 저장된 데이터는 애플리케이션에 더욱 효율적으로 재사용된다. 애플 리케이션이 메모리 블록들(즉, L1 캐시, LDS 및 레지스터 파일들) 중 하나의 더 많은 용량 및 대역폭을 사용한다고 결정될 때, 다른 메모리 블록들 중 하나 이상의 메모리 블록들의 부분들은 하나의 메모리 블록에 대해 예약된다. 예를 들어, 애플리케이션이 실행을 위해 더 많은 레지스터들을 사용한다고 결정될 때, L1 캐시 및/또는 LDS의 부분들은 레지스터 파일들을 위해 예약된다. 애플리케이션이 실행을 위해 더 많은 캐시 메모리를 사용한다고 결정될 때, 레지스터 파일들 및/또는 LDS의 부분들(예를 들어, 하나 이상의 뱅크들)은 추가적인 L1 캐시 저장소로서 사용하기 위해 예약된다. 애플리케이션이 더 많은 LDS 용량을 사용한다고 결정될 때, 레지스터 파일들 및/또는 L1 캐시의 부분들(예를 들어, 하나 이상 의 뱅크들)은 추가적인 LDS 저장소로서 사용하기 위해 예약된다. 즉, L1 캐시, LDS 및 레지스터 파일들 사이의 파티셔닝은 실행될 특정 애플리케이션에 맞게 조정된다. 도 4는 특정 애플리케이션에 기초하여 공유 저장소를 위해 메모리 블록들을 파티셔닝하는 방법을 결정하는 예시 적인 방법을 예시하는 흐름도이다. 도 4에 도시된 예는 프로그램의 부분들을 웨이브프론트들로서 설명한다. 그러나, 본 개시의 특징들은 프로그램의 다른 유형들의 부분들을 실행함으로써 구현될 수 있다. 도 4에 도시된 예는 실행될 애플리케이션의 특정 사용 사례에 기초하여 메모리 블록들을 파티셔닝하는 방법에 대한 상이한 결정(determination)들(즉, 결정(decision)들)을 포함한다. 도 4에서 결정들이 이루어지는 순서는 단지 예일 뿐이다. 본 개시의 특징들은 도 4에 도시된 결정들을 도 4에 도시된 순서와 다른 순서로 함으로써 구 현될 수 있다. 도 4에 도시된 결정들은 완전한 것이 아니며, 메모리 블록들을 파티셔닝하는 다른 조합들이 애플 리케이션을 더 효율적으로 실행하기 위해 사용될 수 있다는 것이 또한 인식될 수 있다. 블록에 도시된 바와 같이, 애플리케이션은 실행을 시작한다. 애플리케이션은, 예를 들어, 그래픽 연산들 뿐만 아니라 병렬 프로세싱에 적합한 비-그래픽 연산들을 포함하는 애플리케이션이다. 애플리케이션이 실행될 때, 프로세싱 디바이스(예를 들어, CPU)는 메모리 블록들(즉, 레지스터 파일, L1 캐시 및 LDS)을 어떻게 파티셔 닝할지를 결정한다. 결정 블록에 도시된 바와 같이, 방법은 애플리케이션이 0이 아닌 크기의 LDS를 사용하는지 여부를 결 정하는 단계를 포함한다. 블록에서, 0이 아닌 크기의 LDS가 프로그램을 실행하는 데 사용된다고 결정될 때 (예 결정), 블록에서 레지스터 파일의 일부가 LDS 저장소를 포함하도록(즉, LDS에 데이터를 저장하도록) 예약된다. 그런 다음, 블록에서 애플리케이션에 의해 특정된 L1 캐시 크기에 기초하여 레지스터 파일의 일 부가 L1 캐시를 위해 예약된다. 블록에서 애플리케이션을 실행하기 위해 LDS 저장소가 사용되지 않는다고 결정될 때(아니오 결정), 블록 에서 LDS 저장소를 포함하도록 레지스터 파일의 일부를 예약하지 않고, 애플리케이션에 의해 특정된 L1 캐 시 크기에 기초하여 레지스터 파일의 일부가 L1 캐시를 위해 예약된다. 예를 들어, 애플리케이션을 실행하기 위 해 LDS 저장소가 사용되지 않는 경우, 0이 아닌 크기의 LDS가 프로그램을 실행하기 위해 사용되는 경우보다 레 지스터 파일의 더 큰 부분이 L1 캐시를 위해 예약될 수 있다. 블록에서 레지스터 파일의 일부가 L1 캐시에 대해 예약된 후, 레지스터 파일의 나머지(즉, L1 캐시 및/또 는 LDS 저장소에 대해 예약되지 않은 레지스터들)가 블록에서 웨이브폼(waveform)들을 실행하기 위해 할당 된다. L1 캐시 및/또는 LDS 저장소에 대해 예약된 레지스터 파일의 부분의 크기(레지스터들의 수)는, 예를 들어, L1 캐시 및/또는 LDS의 용량 및 대역폭과 같은 상이한 팩터들에 기초하여 결정된다. 도 5는 본 개시의 특징들에 따른 프로그램을 실행하는 예시적인 방법을 예시하는 흐름도이다. 도 5에 도시 된 방법은 실행될 특정 애플리케이션에 기초하여 L1 캐시의 일부로서 CU의 레지스터 파일의 일부를 인스턴 스화하기로 결정이 이루어질 때 본 개시의 특징들에 따라 프로그램을 실행하는 일 예에 불과하다. 프로그램을 실행하는 다른 방법들은 실행될 특정 애플리케이션에 기초하여 L1 캐시의 일부로서 CU의 레지스터 파일의 일부 를 인스턴스화하기 위해 메모리 블록들을 파티셔닝하는 방법에 대해 상이한 결정이 이루어질 때 도 5에 도시된 방법과 유사하게 수행될 수 있다는 것이 인식될 수 있다. 도 5에 도시된 예는 프로그램의 부분들을 웨이브프론트들로서 설명한다. 그러나, 본 개시의 특징들은 프로그램 의 다른 유형들의 부분들을 실행함으로써 구현될 수 있다. 블록에 도시된 바와 같이, 방법은 제1 웨이브프론트의 실행을 시작하는 단계를 포함한다. 즉, 제1 웨 이브프론트는 도 3에 도시된 SIMD 유닛들 중 하나에 의해 실행된다. 블록에 도시된 바와 같이, 방법은 레지스터 파일의 제1 부분에 데이터를 로딩하는 단계를 포함한다. 즉, 데이터는 도 3에 도시된 레지스터 파일들 중 하나의 레지스터들에 로딩된다. 예를 들어, 데이터는 ALU 들(도시되지 않음)에 의해 사용되어 웨이브프론트를 실행하기 위해 레지스터 파일의 제1 부분의 레지스터들에 로딩된 데이터를 사용하여 계산들을 수행한다. 위에서 설명한 바와 같이, 이 예에서, CU의 레지스터 파일의 일부(즉, 제2 부분)는 실행될 특정 애플리케이션에 기초하여 L1 캐시의 일부로서 인스턴스화된다. 예를 들어, 애 플리케이션은 실행을 위해 대용량 레지스터 파일을 사용하지 않는 애플리케이션으로 결정된다. 따라서, 애플리 케이션은 레지스터 파일의 제2 부분들에 의해 추가적인 L1 캐시 용량을 생성함으로써 실행된다. 블록에 도시된 바와 같이, 방법은 레지스터 파일의 제1 부분으로부터 L1 캐시의 일부로서 인스턴스화 된(예약된) 레지스터 파일의 제2 부분으로 데이터를 저장하는 단계를 포함한다. 예를 들어, 데이터는 제2 웨이 브프론트를 실행하기 위해 레지스터 파일의 제1 부분에서의 공간을 확보하기 위해 스필 동작(spill operation) 의 일부로서 레지스터 파일의 제2 부분에 저장된다. 블록에 도시된 바와 같이, 방법은 제2 웨이브프론트를 실행하기 위해 레지스터 파일의 제2 부분으로 부터 레지스터 파일의 제1 부분으로 데이터를 재로딩하는 단계를 포함한다. 데이터 재로딩은 레지스터 대 레지 스터 전송을 포함하며, 이는 L1 캐시 대 레지스터 전송보다 더 큰 대역폭 및 L2 캐시(또는 메인 메모리) 대 레 지스터 전송보다 훨씬 더 높은 대역폭을 갖는다. 따라서, 레이턴시가 감소된다. 추가적으로 또는 대안적으로, 블록에서 가상선으로 도시된 바와 같이, 레지스터 파일의 제2 부분의 데이터 는 다른 SIMD 유닛의 레지스터 파일의 일부에 로딩될 수 있다. 즉, 레지스터 파일의 제2 부분은 L1 캐시의 일부 로서 인스턴스화되고 CU의 다른 SIMD 유닛들에 의해 공유된다. 따라서, 데이터는 레지스터들과 L2 캐시 사이의 전송들보다 더 큰 대역폭을 갖는 동일한 CU의 SIMD 유닛들 사이에서 전송될 수 있다. 따라서, 메모리 블록들에 의해 점유되는 영역을 증가시키지 않고도 애플리케이션이 보다 효율적으로 실행될 수 있다. 본 명세서의 개시에 기초하여 많은 변형들이 가능하다는 것이 이해되어야 한다. 특징 및 엘리먼트가 특정 조합 으로 위에서 설명되었지만, 각각의 특징 또는 엘리먼트는 다른 특징 및 엘리먼트 없이 단독으로 또는 다른 특징 및 엘리먼트를 갖거나 갖지 않는 다양한 조합으로 사용될 수 있다. 도면들에 예시되고 그리고/또는 본 명세서에 설명된 다양한 기능 유닛들(프로세서, 입력 드라이버, 입력 디바이스들, 출력 드라이버, 출력 디바이스들, 가속 프로세싱 디바이스, 레지스터 파 일 및 ALU들의 할당된 레지스터들 및 레지스터 캐시를 포함하지만 이에 제한되지 않음)은 범용 컴퓨터, 프로세서, 또는 프로세서 코어로서, 또는 범용 컴퓨터, 프로세서, 또는 프로세서 코어에 의해 실 행가능한, 비일시적 컴퓨터 판독가능 매체 또는 다른 매체에 저장된 프로그램, 소프트웨어, 또는 펌웨어로서 구 현될 수 있다. 제공된 방법들은 범용 컴퓨터, 프로세서, 또는 프로세서 코어에서 구현될 수 있다. 적합한 프로 세서들은, 예를 들어, 범용 프로세서, 특수 목적 프로세서, 종래의 프로세서, 디지털 신호 프로세서(DSP), 복수 의 마이크로프로세서들, DSP 코어와 연관된 하나 이상의 마이크로프로세서들, 제어기, 마이크로제어기, ASICs(Application Specific Integrated Circuits), FPGAs(Field Programmable Gate Arrays) 회로들, 임의의 다른 유형의 집적 회로(IC), 및/또는 상태 머신을 포함한다. 이러한 프로세서들은 프로세싱된 하드웨어 기술 언 어(HDL) 명령어들의 결과들 및 넷리스트들을 포함하는 다른 중간 데이터(이러한 명령어들은 컴퓨터 판독가능 매 체 상에 저장될 수 있음)를 사용하여 제조 프로세스를 구성함으로써 제조될 수 있다. 이러한 프로세싱의 결과는 본 개시의 특징을 구현하는 프로세서를 제조하기 위해 반도체 제조 공정에 사용되는 마스크워크일 수 있다. 본 명세서에 제공된 방법들 또는 흐름도는 범용 컴퓨터 또는 프로세서에 의한 실행을 위해 비일시적 컴퓨터 판 독가능 저장 매체에 통합된 컴퓨터 프로그램, 소프트웨어 또는 펌웨어로 구현될 수 있다. 비일시적 컴퓨터 판독 가능 저장 매체의 예로는 판독 전용 메모리(ROM), 랜덤 액세스 메모리(RAM), 레지스터, 캐시 메모리, 반도체 메 모리 디바이스, 내부 하드 디스크 및 이동식 디스크와 같은 자기 매체, 자기 광학 매체, CD-ROM 디스크 및 디지 털 다목적 디스크(DVD)와 같은 광학 매체를 포함한다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2024-7011114", "section": "도면", "subsection": "도면설명", "item": 1, "content": "더 상세한 이해는 첨부된 도면과 함께 예로서 주어진 다음의 설명으로부터 얻을 수 있다. 도 1은 본 개시의 하나 이상의 특징들이 구현될 수 있는 예시적인 디바이스의 블록도이다. 도 2는 본 개시의 하나 이상의 특징들을 구현하기 위한 예시적인 컴포넌트들을 예시하는 블록도이다. 도 3은 본 개시의 하나 이상의 특징들을 구현하기 위한 도 2에 도시된 APD의 CU의 예시적인 컴포넌트들을 예시 하는 블록도이다. 도 4는 본 개시의 특징들에 따른 특정 애플리케이션에 기초하여 공유 저장소를 위한 메모리 블록들을 파티셔닝 하는 예시적인 방법을 예시하는 흐름도이다. 도 5는 본 개시의 특징들에 따른 프로그램을 실행하는 예시적인 방법을 예시하는 흐름도이다."}
