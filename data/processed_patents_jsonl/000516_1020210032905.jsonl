{"patent_id": "10-2021-0032905", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0128181", "출원번호": "10-2021-0032905", "발명의 명칭": "인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법 및 장치", "출원인": "(주)디오비스튜디오", "발명자": "오제욱"}}
{"patent_id": "10-2021-0032905", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 얼굴 소스 데이터와, 적어도 하나의 얼굴 배경 데이터를 입력 받아 딥러닝을 통해 추론 얼굴과 실존 얼굴에 대한 비교 및 학습을 수행하는 학습부; 및하나의 얼굴 배경 데이터를 입력 받아 상기 비교 및 학습된 모델을 통해 상기 복수의 얼굴 소스 데이터로부터추론된 얼굴과 상기 하나의 얼굴 데이터의 특징이 합쳐진 가상의 얼굴 데이터를 생성하는 추론부;를 포함하는것을 특징으로 하는 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 장치."}
{"patent_id": "10-2021-0032905", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "가상 얼굴 생성 장치에서 복수의 얼굴 소스 데이터와, 적어도 하나의 얼굴 배경 데이터를 입력 받아 딥러닝을통해 추론 얼굴과 실존 얼굴에 대한 비교 및 학습을 수행하는 단계; 및하나의 얼굴 배경 데이터를 입력 받아 상기 비교 및 학습된 모델을 통해 상기 복수의 얼굴 소스 데이터로부터추론된 얼굴과 상기 하나의 얼굴 데이터의 특징이 합쳐진 가상의 얼굴 데이터를 생성하는 단계;를 포함하는 것을 특징으로 하는 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법."}
{"patent_id": "10-2021-0032905", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 얼굴 배경 데이터는,얼굴 내에서 표정, 눈/코/입모양, 눈 깜빡임 중 적어도 하나를 포함하는 것을 특징으로 하는 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법."}
{"patent_id": "10-2021-0032905", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 얼굴 데이터는, 얼굴 이미지 및 얼굴 영상 중 적어도 하나를 포함하는 특징으로 하는 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법."}
{"patent_id": "10-2021-0032905", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 비교 및 학습을 수행하는 단계는,상기 가상 얼굴 생성 장치의 인코더에서 상기 복수의 얼굴 소스 데이터와, 적어도 하나의 얼굴 배경 데이터를입력 받아 다층 컨볼류션 레이어로 인코딩하는 단계;인터네트워크부에서 상기 인코딩된 데이터로 소스 데이터와 배경 데이터의 분포 영역을 각각 생성하는 단계; 디코더에서 상기 인터네트워크부로부터 전달된 데이터들을 다층 디컨볼루션 레이어로 디코딩하는 단계; 및상기 복구된 데이터를 원본 데이터와 비교하여 학습하는 단계;를 포함하는 것을 특징으로 하는 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법."}
{"patent_id": "10-2021-0032905", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 가상의 얼굴 데이터를 생성하는 단계는,상기 가상 얼굴 생성 장치의 인코더에서 하나의 얼굴 배경 데이터를 입력 받아 인코딩하는 단계;공개특허 10-2022-0128181-3-인터네트워크부에서 상기 인코딩된 데이터를 상기 비교 및 학습된 모델에 통과시킨 후, 가상 얼굴의 분포 영역을 도출하여 디코더로 전달하는 단계; 및상기 디코더에서 추론 얼굴과 배경 얼굴의 특징이 포함된 가상 얼굴 데이터를 생성하는 디코딩 단계;를 포함하는 것을 특징으로 하는 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법."}
{"patent_id": "10-2021-0032905", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 장치는 복수의 얼굴 소스 데이 터와, 적어도 하나의 얼굴 배경 데이터를 입력 받아 딥러닝을 통해 추론 얼굴과 실존 얼굴에 대한 비교 및 학습 을 수행하는 학습부 및 하나의 얼굴 배경 데이터를 입력 받아 상기 비교 및 학습된 모델을 통해 상기 복수의 얼 굴 소스 데이터로부터 추론된 얼굴과 상기 하나의 얼굴 데이터의 특징이 합쳐진 가상의 얼굴 데이터를 생성하는 추론부를 포함할 수 있다."}
{"patent_id": "10-2021-0032905", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법 및 장치에 관한 발명으로서, 보 다 상세하게는 인공신경망을 이용하여 동일한 인물에 대해 다양한 표정을 가지는 가상의 얼굴을 생성할 수 있는 기술에 관한 발명이다."}
{"patent_id": "10-2021-0032905", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "카메라 등으로부터 획득한 얼굴 영상을 기초로 가상의 얼굴을 생성하는 방법으로는 단순한 컴퓨터 그래픽 기술 에 의존한 이미지 모자이크(mosaic) 기법이나 이미지 와핑(warping) 기법 등을 이용해서 얼굴 영상을 생성하는 방법이 있다. 상기 이미지 모자이크 기법은 전체 이미지에 두 개 또는 그 이상의 이미지를 결합하여 변형된 이미지를 얻는 기 법이고, 상기 이미지 와핑 기법은 왜곡필터(distortion filter) 등에 수학식을 적용하여 이미지를 왜곡시킴으로 써 이미지의 픽셀(pixel)들이 새로운 위치 값을 갖도록 변형시키는 기법으로서, 후자의 기법이 전자의 기법보다 보다 더 생생한 얼굴을 생성할 수 있지만, 실제 사람의 얼굴과 같은 느낌을 구현하기에는 많이 부족한 실정이었 다. 그러나 최근 생체인식(Biometrics) 기술과 인공지능 기술이 발달함에 따라 이러한 기술을 활용하여 얼굴을 합성 하는 다양한 프로그램이 개발되고 있는데, 대표적으로 얼굴 합성 어플리케이션(예컨대, 스노우(Snow), 라인 에 그(Line Egg) 등)이 존재한다. 구체적으로, 얼굴 합성 기술의 경우 얼굴의 주요 특징점을 검출하고, 사용자가 수동적으로 선택한 콘텐츠를 얼 굴에 합성해주는 방법으로 이루어지며, 얼굴에 특정 콘텐츠를 합성하여 제공하기 때문에 사용자에게 다양한 재 미를 제공해 줄 수 있는 장점이 존재한다. 그러나, 종래 기술에 따른 얼굴 합성 기술의 경우 사용자가 입을 벌릴 때 등의 단편적인 상황에서 추가 효과를 제공하는 제한적인 인터랙티브 얼굴 합성 기능만 제공할 뿐, 사용자의 다양한 표정을 담을 수 없는 문제가 존재 하였다. 또한, 실제 사람의 얼굴을 기준으로 합성을 하는 경우 합성된 얼굴이 음란물이나, 가짜뉴스 등에 악용될 가능성 이 존재하며, 특정 인물에 대해 악용이 없이 선한 목적으로 합성하였다 하여도 그 특정인물에 대한 초상권의 문 제 등을 초래할 위험성이 존재하는 실정이다. 따라서, 실제 존재하는 인물을 합성한다는 기술은 위험 부담이 크 다는 단점을 가지고 있다."}
{"patent_id": "10-2021-0032905", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 일 실시예에 따른 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법 및 장치는 앞서 설명한 문제점을 해결하게 위해 고안된 발명으로서, 인공지능 기술을 활용하여 실제 인물과 같은 느낌을 느끼면 서도 세상에 존재하지 않은 가상의 인물을 생성하는데 그 목적이 있다. 보다 구체적으로는, 인공지능 기술을 이용하여 가상의 얼굴을 생성하되, 하나의 가상의 얼굴을 기준으로 다양한 표정을 표현할 수 있는 가상의 인물을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2021-0032905", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 장치는, 복수의 얼굴 소스 데 이터와, 적어도 하나의 얼굴 배경 데이터를 입력 받아 딥러닝을 통해 추론 얼굴과 실존 얼굴에 대한 비교 및 학 습을 수행하는 학습부 및 하나의 얼굴 배경 데이터를 입력 받아 상기 비교 및 학습된 모델을 통해 상기 복수의 얼굴 소스 데이터로부터 추론된 얼굴과 상기 하나의 얼굴 데이터의 특징이 합쳐진 가상의 얼굴 데이터를 생성하 는 추론부를 포함할 수 있다. 일 실시예에 따른 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법은, 가상 얼굴 생성 장치 에서 복수의 얼굴 소스 데이터와, 적어도 하나의 얼굴 배경 데이터를 입력 받아 딥러닝을 통해 추론 얼굴과 실 존 얼굴에 대한 비교 및 학습을 수행하는 단계 및 하나의 얼굴 배경 데이터를 입력 받아 상기 비교 및 학습된 모델을 통해 상기 복수의 얼굴 소스 데이터로부터 추론된 얼굴과 상기 하나의 얼굴 데이터의 특징이 합쳐진 가 상의 얼굴 데이터를 생성하는 단계를 포함한다. 상기 비교 및 학습을 수행하는 단계는, 상기 가상 얼굴 생성 장치의 인코더에서 상기 복수의 얼굴 소스 데이터 와, 적어도 하나의 얼굴 배경 데이터를 입력 받아 다층 컨볼류션 레이어로 인코딩하는 단계, 인터네트워크부에 서 상기 인코딩된 데이터로 소스 데이터와 배경 데이터의 분포 영역을 각각 생성하는 단계, 디코더에서 상기 인 터네트워크부로부터 전달된 데이터들을 다층 디컨볼루션 레이어로 디코딩하는 단계 및 상기 복구된 데이터를 원 본 데이터와 비교하여 학습하는 단계를 포함할 수 있다. 상기 가상의 얼굴 데이터를 생성하는 단계는, 상기 가상 얼굴 생성 장치의 인코더에서 하나의 얼굴 배경 데이터 를 입력 받아 인코딩하는 단계, 인터네트워크부에서 상기 인코딩된 데이터를 상기 비교 및 학습된 모델에 통과 시킨 후, 가상 얼굴의 분포 영역을 도출하여 디코더로 전달하는 단계 및 상기 디코더에서 추론 얼굴과 배경 얼 굴의 특징이 포함된 가상 얼굴 데이터를 생성하는 디코딩 단계를 포함할 수 있다. 상기 얼굴 배경 데이터는, 얼굴 내에서 표정, 눈/코/입모양, 눈 깜빡임 중 적어도 하나를 포함할 수 있다. 상기 얼굴 데이터는, 얼굴 이미지 및 얼굴 영상 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2021-0032905", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따른 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법 및 장치는 실제 인물과 같은 느낌이 있으면서도 실제 존재하지 않는 가상의 얼굴을 생성하므로 특정 인물에 대한 초상권 문제, 악용사 례 등의 위험 부담이 없는 가상의 얼굴을 생성할 수 있는 장점이 존재한다. 또한, 여러 사람의 데이터를 토대로 기초로 다양한 표정을 가지는 하나의 가상 인물을 생성할 수 있어, 사진, 동영상, 에니메이션 등 다양한 분야에서 본 기술이 효과적으로 적용될 수 있는 장점이 존재한다."}
{"patent_id": "10-2021-0032905", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고"}
{"patent_id": "10-2021-0032905", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상세한 설명에 상세하게 설명하고자 한다. 본 발명의 효과 및 특징, 그리고 그것들을 달성하는 방법은 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 다양한 형태로 구현될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 실시예에서, 제1, 제2 등의 용어는 한정적인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별 하는 목적으로 사용되었다. 이하의 실시예에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 실시예에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 또는 구성요소가 존재함을 의 미하는 것이고, 하나 이상의 다른 특징들 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 이하의 실시예에서, 막, 영역, 구성 요소 등의 부분이 다른 부분 위에 또는 상에 있다고 할 때, 다른 부분의 바 로 위에 있는 경우뿐만 아니라, 그 중간에 다른 막, 영역, 구성 요소 등이 개재되어 있는 경우도 포함한다. 도면에서는 설명의 편의를 위하여 구성 요소들이 그 크기가 과장 또는 축소될 수 있다. 예컨대, 도면에서 나타 난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나타내었으므로, 본 발명이 반드시 도시된 바에 한정 되지 않는다. 본 발명은 인공지능 기술을 활용하여 세상에 존재하지 않는 가상인물을 일관되게 생성하는 기술이다. 본 명세서 에서 발명의 명칭은 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 장치로 기재하였으나, 이하 설명의 편의를 위해 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 장치는 가상 얼굴 생성 장 치로 축약하여 지칭하기로 한다. 도 1은 본 발명의 일 실시예에 따른 가상 얼굴 생성 장치를 도시한 도면이다. 도 1을 참조하면, 가상 얼굴 생성 장치는 학습부 및 추론부를 포함할 수 있다. 학습부는 복수의 얼굴 소스(source) 데이터와, 적어도 하나의 얼굴 배경(destination) 데이터를 입력 받아 딥러닝을 통해 추론 얼굴과 실존 얼굴에 대한 비교 및 학습을 수행할 수 있다. 여기서 여러 사람에 대한 복수의 얼굴 소스 데이터는 가상의 얼굴 생성에 사용될 수 있으며, 적어도 하나의 얼굴 배경 데이터는 얼굴 내에서 표 정, 눈/코/입모양, 눈 깜빡임 중 적어도 하나에 대한 정보를 담고 있는 데이터가 될 수 있다. 즉, 얼굴 배경 데 이터는 한 사람에 대한 다양한 얼굴의 눈, 코, 입, 눈썹 등의 형태와 움직임을 나타낼 수 있는 정보를 포함할 수 있으며, 한 사람이 아닌 복수의 사람들에 대한 얼굴 내 동적 특징 정보를 포함할 수 있다. 추론부는 학습부를 통해 가상얼굴 생성 모델이 생성된 후, 하나의 얼굴 배경 데이터를 입력 받아 가 상얼굴 생성 모델을 통해 복수의 얼굴 소스 데이터로부터 추론된 얼굴과 하나의 얼굴 배경 데이터의 특징이 합 쳐진 가상의 얼굴 데이터를 생성할 수 있다. 이러한 학습부 및 추론부는 가상 얼굴 생성 장치에서의 구성요소 혹은 단계별 프로세스가 될 수 있으며, 가상 얼굴 생성 장치 내 구성요소들을 서로 공유하여 사용할 수 있다. 그리고 가상 얼굴 생성 장치는 인공지능의 한 분야인 딥러닝의 오토 인코더 기술을 활용하여 세상에 존재 하지 않는 가상인물을 일관되게 생성할 수 있다. 오토인코더는 신경망의 각 층을 단계적으로 학습하여 최종 출 력이 최초 출력을 재현하도록 하는 것으로, 입력과 출력층의 차원은 동일하나, 은닉층은 입력과 출력 층보다 낮 은 차원으로 설계된다. 이에 오토인코더에서는 입력 데이터들을 압축하여 특징을 추출하고, 추출한 특징을 기반 으로 입력을 최대한 재현한 데이터를 출력할 수 있다. 그리고 오토인코더는 저차원을 가지는 히든 레이어에 의해 입력을 그대로 출력으로 복사할 수 없기 때문에, 출 력이 입력과 같은 것을 출력하기 위해 학습해야 한다. 이러한 학습을 통해 오토인코더는 입력 데이터에서 가장 중요한 특성(feature)을 학습하도록 만들 수 있다. 가상 얼굴 생성 장치의 구체적인 학습 및 추론 방식에 대해서는 도 2 및 도 3에서 구체적으로 설명하도록 한다. 도 2는 본 발명의 일 실시예에 따른 가상 얼굴 생성 장치에서의 학습 방식을 도시한 도면이다. 도 2를 참조하면, 가상 얼굴 생성 장치의 학습부는 얼굴 데이터에 대한 학습을 수행하며, 인코더 , 인터네트워크부 및 디코더를 포함할 수 있다. 구체적으로 가상 얼굴 생성장치는 공유 가 중치를 가지는 인코더와 디코더 및 두 개의 독립적인 인터 모델을 포함하는 인터네트워크부를 포함할 수 있다. 인코더는 다층의 컨볼루션(multi-layer convolution)으로 구성되어 소스 이미지와, 배경 이미지를 입력 받 아 이를 축약시키는 인코딩 과정을 통해 인터네트워크부로 전달한다. 한편, 가상얼굴 생성 장치는 입력된 소스 이미지에서 얼굴 감지, 얼굴 정렬 및 얼굴 분할 중 적어도 하나의 추출 과정을 진행할 수 있다. 그 리고 배경 이미지에 대해서도 소스 이미지와의 매칭을 위해 기본적으로 전체 얼굴에 대해 정렬을 수행할 수 있 다. 인터네트워크부에서는 인터AB부와 인터B부의 네트워크를 통과할 수 있다. 인터AB부는 소스 이미지와, 배경 이미지를 한번씩 학습한 네트워크이고, 인터B부는 배경 이미지만 학습시킨 네트워크이다. 다시 말해 인터AB부는 소스 이미지 데이터와, 배경 이미지 데이터로부터 추출된 특징(latent coding)을 생 성( )하고, 인터B부는 배경 이미지로부터만 추출된 특징을 생성( )한다. 이에 인터네트워크부에서는 축약된 이미지를 인터AB부와 인터B부의 네트워크에 통과시키며, 배 경이미지 분포 영역과, 소스 이미지 분포 영역을 만들 수 있다. 그리고 인터네트워크부에서 다층 디컨볼루 션(multi-layer deconvolution)으로 구성된 디코더로 전달된 이미지들은 디코딩 과정을 통해 원래의 이미 지로 복구될 수 있다. 이후 복구된 이미지들은 원본 이미지와 비교하여 손실값을 계산하며 계산된 손실값은 딥 러닝의 역전파 기술에 따라 학습을 수행하며, 이를 통해 가상얼굴 생성 모델을 생성할 수 있다. 한편, 학습 수행 시 얼굴을 각 부분에 대해 서로 다른 가중치를 부여할 수도 있다. 예를 들어, 얼굴에서 볼 보 다 눈 영역에 더 많은 가중치를 부여함으로써 좀더 생생한 눈을 가진 얼굴 생성을 수행할 수 있다. 도 3은 본 발명의 일 실시예에 따른 가상 얼굴 생성 장치에서의 추론 방식을 도시한 도면이다. 도 3을 참조하면, 가상 얼굴 생성 장치의 추론부는 입력된 이미지의 특징을 포함하는 가상얼굴을 생 성하며, 인코더, 인터네트워크부 및 디코더를 포함할 수 있다. 인코더는 특정 인물의 얼굴에 대한 배경 이미지를 입력 받아 이를 축약시키는 인코딩 과정을 수행하여, 인 터네트워크부로 전달될 수 있다. 인터네트워크부에서는 인터AB부 네트워크만을 통과할 수 있다. 인터B부는 학습시에만 통과시키고, 추론시에는 인터AB부의 네트워크를 통과시킬 수 있다. 이를 통해 얼굴의 표정, 입모양, 눈 모양 등의 정보를 얻을 수 있으며, 이러한 특징 정보( )를 포함하는 이미지들로부터 여러명의 소스 이미지를 통해 만들어낸 가상 인물의 분포 영역을 찾아낼 수 있다. 그리고 인터네트워크부에서 디코더로 전달된 이미지들은 다층의 디컨볼루션 레이어의 디코딩 과정을 통해 추론한 소스의 얼굴과 배경 이미지의 특징이 합쳐진 가상 얼굴 이미지를 생성할 수 있다. 생성된 이미지는 소스 이미지중 동일한 얼굴이 아니며, 소스 이미지가 혼합된 형태의 새로운 가상인물을 생성할 수 있다. 그러고 이러한 가상얼굴을 한 가상인물은 단순히 무표정의 사람이 아닌 배경 이미지의 표정, 입모양, 눈모양 등을 따라 하는 사람으로 생성할 수 있다. 도 4는 본 발명의 일 실시예에 따른 가상 얼굴 생성 장치에서의 가상 얼굴 생성 방식을 도시한 도면이다. 도 4를 참조하면, 가상얼굴 생성 장치의 학습부에 가상 얼굴로 사용될 다양한 사람들의 얼굴 이미지 가 소소 이미지로서 입력되고, 표정, 입모양, 눈 깜빡임 등의 정보를 담고 있는 적어도 한사람의 배경 얼 굴 이미지가 배경 이미지로서 입력 된다. 이에 가상얼굴 생성 장치에서는 원본 이미지와 비교하며 학 습을 통해 가상얼굴 생성용 모델을 생성하게 된다. 이후, 가상얼굴 생성 장치의 추론부에 한사람의 배경 얼굴 이미지가 입력되는 경우, 가상얼굴 생성 장치에서는 다양한 사람들의 얼굴 이미지를 통해서 추론한 얼굴과, 한사람의 배경 얼굴 이미지 의 특징이 합쳐진 가상 얼굴 이미지를 출력하게 된다. 본 실시예에서는 각각의 이미지를 사용하였으 나, 각각의 이미지 대신 동영상 데이터의 사용이 가능함은 물론이다. 도 5는 본 발명의 일 실시예에 따른 가상 얼굴 생성 방법을 도시한 순서도이다. 도 5를 참조하면, S500단계에서 가상 얼굴 생성 장치의 인코더에 복수의 얼굴 소스 이미지와, 얼굴의 특징 정보를 가진 배경 이미지로서 입력되는 경우, 이를 인코딩하여 인터 네트워크부로 전달하게 된다. S510단계에서 인터 네트워크부에서는 소송 이미지 분포 영역과, 배경 이미지 분포 영역을 생성하게 된다. 그리고 S520단계에서 디코딩을 통해 이미지를 복구하며, 복구된 이미지를 원본 이미지와 비교하며, 학습을 수행 하게 된다.이후 S530단계에서 가상 얼굴 생성 장치의 인코더에 배경 이미지가 입력되는 경우 이를 인코딩하고, S540단계에서 인터 네트워크부의 소스이미지와 배경 이미지가 한번씩 학습된 네트워크를 통과하게 된다. 그리고 S550단계에서 디코더를 통해 디코딩되어 추론된 소스 이미지와 배경 이미지의 특징이 합쳐진 가상 인물의 얼굴을 이미지를 생성하게 된다. 즉, 종래의 가상얼굴 생성 방식은 인지가능한 특정 인물의 얼굴이 그대로 나올 뿐 새로운 사람을 생성하지 못하 며, 새로운 얼굴을 생성하더라도 그 결과물이 랜덤으로 나오므로 하나의 가상인물을 일관되게 사용할 수가 없다 는 문제점이 있었다. 본 발명의 일 실시예에 따른 인공지능을 활용한 가상 얼굴 생성 방법은, 도 4와 같이 어느 한 시점에 학습된 가 상얼굴 생성 장치에 하나의 배경 얼굴 이미지 혹은 영상을 입력시키는 경우, 동일한 가상인물을 생성시킬 수 있으며, 기존 인물과 다른 가상 인물을 생성하여, 생성된 얼굴이 특정 인물에 국한되지 않으므로 특정 인물 을 겨냥한 악용사례와 특정 인물의 초상권 문제 모두를 극복할 수 있다. 또한 여러 사람의 데이터를 토대로 우 리가 이전에 만나보지 못한 새로운 가상 인물을 경우의 수를 활용하여 조합함으로써 다양한 가상인물을 생성해 낼 수 있다. 결국 특정 연예인을 얼굴 합성 기술로 생성하여 문제가 되었던 과거의 단점들을 가상인물 생성으로 해결할 수 있으므로 얼굴 합성 기술의 선례를 적극 활용할 수 있으며 향후 드라마, 영화, 뉴스 등 다양한 컨텐 츠에서 활용될 가능성을 가질 수 있는 이점이 있다. 한편, 본 명세서에 기재된 \"~부\"로 기재된 구성요소들, 유닛들, 모듈들, 컴포넌트들 등은 함께 또는 개별적이지 만 상호 운용 가능한 로직 디바이스들로서 개별적으로 구현될 수 있다. 모듈들, 유닛들 등에 대한 서로 다른 특 징들의 묘사는 서로 다른 기능적 실시예들을 강조하기 위해 의도된 것이며, 이들이 개별 하드웨어 또는 소프트 웨어 컴포넌트들에 의해 실현되어야만 함을 필수적으로 의미하지 않는다. 오히려, 하나 이상의 모듈들 또는 유 닛들과 관련된 기능은 개별 하드웨어 또는 소프트웨어 컴포넌트들에 의해 수행되거나 또는 공통의 또는 개별의 하드웨어 또는 소프트웨어 컴포넌트들 내에 통합될 수 있다. 특정한 순서로 작동들이 도면에 도시되어 있지만, 이러한 작동들이 원하는 결과를 달성하기 위해 도시된 특정한 순서, 또는 순차적인 순서로 수행되거나, 또는 모든 도시된 작동이 수행되어야 할 필요가 있는 것으로 이해되지 말아야 한다. 임의의 환경에서는, 멀티태스킹 및 병렬 프로세싱이 유리할 수 있다. 더욱이, 상술한 실시예에서 다양한 구성요소들의 구분은 모든 실시예에서 이러한 구분을 필요로 하는 것으로 이해되어서는 안되며, 기술된 구성요소들이 일반적으로 단일 소프트웨어 제품으로 함께 통합되거나 다수의 소프트웨어 제품으로 패키징될 수 있다는 것이 이해되어야 한다. 컴퓨터 프로그램(프로그램, 소프트웨어, 소프트웨어 어플리케이션, 스크립트 또는 코드로도 알려져 있음)은 컴 파일되거나 해석된 언어나 선험적 또는 절차적 언어를 포함하는 프로그래밍 언어의 어떠한 형태로도 작성될 수 있으며, 독립형 프로그램이나 모듈, 컴포넌트, 서브루틴 또는 컴퓨터 환경에서 사용하기에 적합한 다른 유닛을 포함하여 어떠한 형태로도 전개될 수 있다. 부가적으로, 본 특허문헌에서 기술하는 논리 흐름과 구조적인 블럭도는 개시된 구조적인 수단의 지원을 받는 대 응하는 기능과 단계의 지원을 받는 대응하는 행위 및/또는 특정한 방법을 기술하는 것으로, 대응하는 소프트웨 어 구조와 알고리즘과 그 등가물을 구축하는 데에도 사용 가능하다. 본 명세서에서 기술하는 프로세스와 논리 흐름은 입력 데이터 상에서 작동하고 출력을 생성함으로써 기능을 수 행하기 위하여 하나 이상이 컴퓨터 프로그램을 실행하는 하나 이상이 프로그래머블 프로세서에 의하여 수행 가 능하다. 본 기술한 설명은 본 발명의 최상의 모드를 제시하고 있으며, 본 발명을 설명하기 위하여, 그리고 당업자가 본 발명을 제작 및 이용할 수 있도록 하기 위한 예를 제공하고 있다. 이렇게 작성된 명세서는 그 제시된 구체적인 용어에 본 발명을 제한하는 것이 아니다. 이상에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자 또는 해당 기술 분야에 통상의 지식을 갖는 자라면, 후술될 특허청구범위에 기재된 본 발명의 사상 및 기술 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 따라서, 본 발명의 기술적 범위는 명세서의 상세한 설명에 기재된 내용으로 한정되는 것이 아니라 특허청구범위에 의해 정해져야 할 것이다부호의 설명 100: 가상얼굴 생성 장치 110: 인코더 120: 인터네트워크부 130: 디코더 200: 학습부 300: 추론부"}
{"patent_id": "10-2021-0032905", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 장치의 일 구성요소를 도시한 블럭도이다. 도 2는 일 실시예에 따른 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법의 학습 방식을 도시한 도면이다. 도 3은 일 실시예에 따른 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 방법의 추론 방식을 도시한 도면이다. 도 4는 일 실시예에 따른 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 장치의 가상 얼굴 생 성 방식을 도시한 도면이다. 도 5는 일 실시예에 따른 인공신경망을 활용하여 다양한 표정을 가지는 가상의 얼굴 생성 장치의 가상 얼굴 생 성 방법을 도시한 순서도이다."}
