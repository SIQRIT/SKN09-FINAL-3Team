{"patent_id": "10-2022-7033779", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0147662", "출원번호": "10-2022-7033779", "발명의 명칭": "빅 데이터의 전달을 제어하는 경량 인공 지능 레이어", "출원인": "마이크론 테크놀로지, 인크.", "발명자": "골로브, 길"}}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법으로서,소스 애플리케이션에 의해 생성된 데이터를 수신하는 단계;상기 데이터를 예측 모델에 입력하는 단계로서, 상기 예측 모델은 상기 데이터를 위한 예측 출력을 생성하는,상기 입력하는 단계;상기 예측 출력에 기초하여 선택된 전처리 전략을 사용하여 상기 데이터를 전처리하는 단계; 및전처리된 데이터를 네트워크를 통해 상기 데이터를 처리하기 위한 서버로 전송하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 전송하는 단계 전에 상기 데이터의 일부를 폐기하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 데이터를 세그먼트화하는 단계 및 세그먼트화된 데이터를 상기 전처리된 데이터로서 사용하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 분류에 기초하여 압축 레벨을 선택하는 단계 및 상기 압축 레벨에 기초하여 상기 데이터의 일부를 압축하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 비디오 데이터를 수신하는 단계를 더 포함하되, 상기 소스 애플리케이션은 비디오 캡처 애플리케이션, 비디오 압축 애플리케이션, 또는 둘 다를 포함하는, 방법."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 비디오 데이터에서의 복수의 영역을 식별하는 단계;상기 복수의 영역에 기초하여 상기 비디오 데이터를 크로핑하는(cropping) 단계; 및크로핑된 비디오 데이터를 상기 전처리된 데이터로서 사용하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,프레임의 서브 세트 및 프레임의 나머지를 포함하는 비디오 데이터에서 상기 프레임의 서브 세트를 식별하는 단계;복수의 프레임을 상기 전처리된 데이터로서 사용하는 단계; 및상기 프레임의 나머지를 폐기하는 단계를 더 포함하는, 방법.공개특허 10-2022-0147662-3-청구항 8 컴퓨터 프로세서에 의해 실행될 수 있는 컴퓨터 프로그램 명령어를 유형적으로 저장하기 위한 비일시적 컴퓨터판독 가능 저장 매체로서, 상기 컴퓨터 프로그램 명령어는,소스 애플리케이션에 의해 생성된 데이터를 수신하는 단계;상기 데이터를 예측 모델에 입력하는 단계로서, 상기 예측 모델은 상기 데이터를 위한 예측 출력을 생성하는,상기 입력하는 단계;상기 예측 출력에 기초하여 선택된 전처리 전략을 사용하여 상기 데이터를 전처리하는 단계; 및전처리된 데이터를 네트워크를 통해 상기 데이터를 처리하기 위한 서버로 전송하는 단계를 규정하는, 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 컴퓨터 프로그램 명령어는 상기 전송하는 단계 전에 상기 데이터의 일부를 폐기하는 단계를 더 규정하는, 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 컴퓨터 프로그램 명령어는 분류에 기초하여 압축 레벨을 선택하는 단계 및 상기 압축 레벨에 기초하여 상기 데이터의 일부를 압축하는 단계를 더 규정하는, 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 컴퓨터 프로그램 명령어는 분류에 기초하여 압축 레벨을 선택하는 단계 및 상기 압축 레벨에 기초하여 상기 데이터의 일부를 압축하는 단계를 더 규정하는, 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 상기 컴퓨터 프로그램 명령어는 비디오 데이터를 수신하는 단계를 더 규정하되, 상기 소스 애플리케이션은 비디오 캡처 애플리케이션, 비디오 압축 애플리케이션, 또는 둘 다를 포함하는, 컴퓨터 판독 가능저장 매체."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 컴퓨터 프로그램 명령어는,상기 비디오 데이터에서의 복수의 영역을 식별하는 단계;상기 복수의 영역에 기초하여 상기 비디오 데이터를 크로핑하는 단계; 및크로핑된 비디오 데이터를 상기 전처리된 데이터로서 사용하는 단계를 더 규정하는, 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 상기 컴퓨터 프로그램 명령어는,프레임의 서브 세트 및 프레임의 나머지를 포함하는 비디오 데이터에서 상기 프레임의 서브 세트를 식별하는 단계;복수의 프레임을 상기 전처리된 데이터로서 사용하는 단계; 및상기 프레임의 나머지를 폐기하는 단계를 더 규정하는, 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2022-0147662-4-장치로서,프로세서; 및상기 프로세서에 의한 실행을 위해 프로그램 로직을 유형적으로 저장하기 위한 저장 매체를 포함하되, 저장된프로그램 로직은, 상기 프로세서로 하여금,소스 애플리케이션에 의해 생성된 데이터를 수신하는 동작; 상기 데이터를 예측 모델에 입력하는 동작으로서, 상기 예측 모델은 상기 데이터를 위한 예측 출력을생성하는, 상기 입력하는 동작;상기 예측 출력에 기초하여 선택된 전처리 전략을 사용하여 상기 데이터를 전처리하는 동작; 및전처리된 데이터를 네트워크를 통해 상기 데이터를 처리하기 위한 서버로 전송하는 동작을 수행하게 하는, 장치."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 동작은 상기 전송하는 동작 전에 상기 데이터의 일부를 폐기하는 동작을 더 포함하는,장치."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서, 상기 동작은 상기 데이터를 세그먼트화하는 동작 및 세그먼트화된 데이터를 상기 전처리된 데이터로서 사용하는 동작을 더 포함하는, 장치."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 상기 동작은 분류에 기초하여 압축 레벨을 선택하는 동작 및 상기 압축 레벨에 기초하여 상기데이터의 일부를 압축하는 동작을 더 포함하는, 장치."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서, 상기 동작은,상기 비디오 데이터에서의 복수의 영역을 식별하는 동작;상기 복수의 영역에 기초하여 상기 비디오 데이터를 크로핑하는 동작; 및크로핑된 비디오 데이터를 상기 전처리된 데이터로서 사용하는 동작을 더 포함하는, 장치."}
{"patent_id": "10-2022-7033779", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서, 상기 동작은,프레임의 서브 세트 및 프레임의 나머지를 포함하는 비디오 데이터에서 상기 프레임의 서브 세트를 식별하는 동작;복수의 프레임을 상기 전처리된 데이터로서 사용하는 동작; 및상기 프레임의 나머지를 폐기하는 동작을 더 포함하는, 장치."}
{"patent_id": "10-2022-7033779", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전송 전에 경량 인공지능(AI) 레이어를 사용하여 데이터를 분석하는 것에 의해 네트워크 혼잡을 감소시키는 방법, 시스템 및 장치가 설명된다. AI 모델은 전송될 필요가 없는 데이터를 예측적으로 선택하고, 일부 실시형태 에서, 전송될 데이터를 추가로 처리할 수 있다. 그 결과, 네트워크를 통해 전송되는 데이터의 총 크기와 양은 감 소될 수 있는 반면에, 수신 디바이스의 데이터 요구는 여전히 충족될 수 있다. 예를 들어, 소스 애플리케이션에 의해 생성된 데이터는 수신되어 데이터를 위한 예측 출력을 생성할 수 있는 예측 모델에 입력될 수 있다. 데이터 는 예측 출력에 기초하여 선택된 전략을 사용하여 전처리될 수 있고, 전처리된 데이터는 네트워크를 통해 서버로 전송될 수 있다."}
{"patent_id": "10-2022-7033779", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원 본 출원은 미국 특허 출원 제16/836,562호(출원일: 2020년 3월 31일, 명칭: \"Lightweight Artificial Intelligence Layer to Control the Transfer of Big Data\")에 대한 우선권을 주장하며, 이의 전체 개시내용은 참조에 의해 본 명세서에 원용된다. 기술 분야 개시된 실시형태는 빅 데이터 처리 시스템, 및 분산 데이터 감소를 위한 경량 인공 지능 시스템에 관한 것이다."}
{"patent_id": "10-2022-7033779", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "머신 러닝(ML) 또는 인공 지능(AI) 모델의 성능과 정확도를 개선하기 위해, 상당한 양의 트레이닝 데이터가 필 요하다. 일반적으로, 수집된 트레이닝 데이터가 많을수록 이러한 모델의 성능이 향상된다. 또 다른 예로서, 원 시(raw) 오디오 데이터는 종종 디지털 홈 어시스턴트(digital home assistant)에 의해 캡처되어, 음성 검출을 개선하기 위한 트레이닝 데이터로서 사용된다. 유사하게, 자율 및 비자율 차량으로부터의 비디오 데이터는 수집 되어 컴퓨터 비전 시스템을 개선하기 위한 트레이닝 데이터로서 사용될 수 있다."}
{"patent_id": "10-2022-7033779", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "네트워크를 통한 전송을 위해 빅 데이터를 지능적으로 전처리하기 위한 실시형태가 개시된다. 간단히 말해서, 개시된 실시형태는 네트워크를 통해 전송하기 전에 데이터를 분석하는 경량 인공 지능(AI) 레이어를 기술한다. AI 모델은 전송될 필요가 없는 데이터를 예측적으로 선택하고, 일부 실시형태에서 전송될 데이터를 추가로 처리 한다. 그 결과, 네트워크를 통해 전송되는 데이터의 총 크기와 양은 감소될 수 있는 반면에, 수신 디바이스의 데이터 요구는 여전히 충족될 수 있다. 다른 시스템은 벌크 데이터 수집에 의지할 수 있다. 이러한 시스템은 네트워크를 통해 전송되는 데이터의 크기 를 무시하고 스토리지 크기를 강조하며, 종종 대용량 저장소 규모의 컴퓨팅 아키텍처를 사용한다. 그러나, 이러 한 시스템은 종종 신호보다 더 많은 노이즈를 수집한다. 결과적인 수집 기술은 네트워크의 대역폭을 상당히 \"막 으며\", 이는 셀룰러 네트워크와 같은 더 낮은 대역폭 네트워크에 의해 악화되는 문제이다. 그러나, 이러한 시스 템은 이러한 감소가 수집된 데이터의 총 양을 줄이고 잠재적으로 트레이닝 프로세스를 약화시킬 수 있음에 따라 서 데이터의 양을 감소시키는 시도를 하지 않을 수 있다. 개시된 실시형태는 데이터 소스에서 경량 AI 레이어를 제공하고 AI 레이어에 의해 착수된 분류에 기초하여 트레 이닝 데이터를 원격 서버에 선택적으로 전송하는 것에 의해 이들 및 다른 기술적 문제를 해결한다. 도 1A는 본 개시내용의 일부 실시형태에 따른 네트워크 컴퓨터 시스템의 블록도이다. 예시된 실시형태에서, 데이터 소스는 네트워크 인터페이스 카드(NIC)를 사용하여 하이파이 데이터 를 서버에 전송한다. 예시된 실시형태에서, 데이터 소스는 데이터를 생성할 수 있는 임의의 컴 퓨팅 디바이스를 포함할 수 있다. 데이터 소스의 예는 개인용 컴퓨팅 디바이스(데스크탑, 랩톱 등), 모바 일 컴퓨팅 디바이스, 사물 인터넷(IoT) 디바이스, 서버 컴퓨팅 디바이스, 자동차 컴퓨팅 디바이스, 및 일반적으 로 모든 유형의 (도 5에 도시된 바와 같은) 컴퓨팅 디바이스를 포함한다. 일부 실시형태에서, 데이터 소스(10 2)는 이러한 컴퓨팅 디바이스뿐만 아니라 디바이스 자체를 구동하는 소프트웨어를 포함한다. 예를 들어, 데이터소스는 카메라(미도시)를 사용하여 비디오 또는 이미지를 캡처하기 위한 소프트웨어를 포함할 수 있다. 예시된 실시형태에서, 데이터 소스에 의해 생성된 데이터는 NIC를 사용하여 전송된다. NIC의 유 형이나 디자인에는 제한이 없다. 일반적으로, NIC는 통신 채널의 하위 레벨 세부사항과 상호 작용하는 역 할을 한다. 일부 실시형태에서, NIC는 유선 채널(예를 들어, 이더넷) 또는 무선 채널(예를 들어, Wi-Fi, 셀룰러, 위성 등)과 접속한다. 비록 단일 NIC로서 예시되어 있을지라도, 데이터 소스는 다수의 NIC를 가질 수 있다. 대안적으로, 또는 전술한 것과 관련하여, NIC는 다수의 이종 데이터 채널을 통해 통신하도 록 구성될 수 있다. 대안적으로, 또는 전술한 것과 관련하여, NIC는 단일 통신 채널을 통해 다수의 연결을 처리하도록 구성될 수 있다. 도 1A에 도시된 실시형태에서, NIC는 주로 데이터 소스로부터 서버에 연결하는 채널로 데이터를 라우팅하는 역할을 한다. 예시된 실시형태에서, NIC는, 데이터 소스에 의해 생성된 데이터를 단순 패 키징하고 네트워크를 통해 데이터를 전송하는 상용 기성품(commercial off-the-shelf: COTS) NIC를 포함 할 수 있다. 예시된 바와 같이, 이러한 데이터는 하이파이(\"hi-fi\") 데이터로 지칭되지만 \"빅 데이터\"로도 지칭될 수 있다. 일반적으로, 하이파이 데이터는 데이터 소스에 의해 생성된 원시 또는 풀피처(full- featured) 데이터를 포함한다. 하나의 예로서, 데이터 소스가 비디오 레코딩 애플리케이션을 포함하면, 하 이파이 데이터는 데이터 소스에 의해 캡처된 풀 프레임 데이터를 포함할 수 있다. 대안적으로, 데이 터 소스가 개인용 홈 어시스턴트이면, 하이파이 데이터는 원시 음성(즉, 오디오) 데이터를 포함할 수 있다. 대안적으로, 데이터 소스가 IoT 디바이스를 포함하면, 하이파이 데이터는 원시 센서 판독값을 포함할 수 있다. 특히, 일부 실시형태에서, 하이파이 데이터는 대용량 데이터 또는 고속 데이터를 포함한 다. 일부 실시형태에서, 대용량은 데이터 소스에 의해 생성된 큰 파일 크기로 인해 축적된다. 대용량 데이 터 소스의 일반적인 예는 비디오 애플리케이션을 포함한다. 일부 실시형태에서, 고속은 데이터가 생성되는 속도로 인해 생성된다. 고속 데이터 소스의 예는 자동차 시스템 및 IoT 디바이스 또는 네트워크이다. 일부 실시 형태에서, 데이터 소스는 또한 고도로 가변적인 데이터 소스일 수 있다. 이러한 시나리오에서, 데이터 소 스는 다양한 유형의 콘텐츠를 생성할 수 있다. 따라서, 일부 실시형태에서, 데이터 소스는 대용량 데 이터 및 고속 데이터를 생성할 수 있다. 이러한 유형의 데이터 소스의 예는 이러한 시스템이 다수의 데이 터 생성기를 가질 때 차량 또는 IoT 시스템(예를 들어, 컴퓨터 비전 시스템 또는 이종 IoT 디바이스의 홈 네트 워크와 결합된 자동차 시스템)을 또한 포함할 수 있다. 예시된 실시형태에서, NIC 또는 데이터 소스는 gzip 또는 유사한 알고리즘을 사용하여 데이터의 나이 브( ) 압축과 같이 전송 전 하이파이 데이터에 대한 기초적인 동작을 수행할 수 있다. 그러나, 이 러한 접근 방식이 네트워크를 통해 데이터의 크기를 약간 감소시켜도, 전송된 데이터를 서버에 의해 필요 로 하는 데이터로만 적절하게 제한하는데 실패한다. 예를 들어, 모든 데이터를 압축하는 것은 전체 용량을 감소 시킬 수 있지만, 여전히 상대적으로 큰 데이터 용량(일부 경우에는 고속)을 초래한다. 더욱이, 가변 데이터의 압축은 데이터의 구조를 고려할 때 사용이 제한될 수 있다. 또한, 일부 서버 애플리케이션은 고해상도 데이터에 대한 풀피처를 요구하며, 그러므로 압축은 시각적 아티팩트(visual artifact) 및 기타 네트워크 전송 또는 압축 이상의 위험으로 인해 바람직하지 않다. 예시된 바와 같이, 서버는 데이터 소스로부터 데이터를 수신한다. 본 명세서에서 더 상세히 설명된 다양한 실시형태에서, 서버는 머신 러닝 알고리즘 또는 AI 알고리즘을 트레이닝시키기 위한 하나 이상의 애플리케이션을 포함할 수 있다. 예를 들어, 서버는 인공 신경망(ANN)을 트레이닝시키기 위해 데이터 소스(10 2)로부터의 데이터를 사용할 수 있다. 컨볼루션 신경망(CNN), 순환 신경망(RNN), 자동 인코더 등과 같은 다른 유형의 신경망이 사용될 수 있다. 대안적으로, 또는 전술한 것과 관련하여, 지원 벡터 머신(SVM), 의사결정 트 리 또는 나이브 베이즈 분류기와 같은 다른 비신경망 모델이 사용될 수 있다. 서버에 의해 트레이닝된 모 델의 유형 및 수는 제한이 없다. 도 1B는 본 개시내용의 일부 실시형태에 따른 개선된 네트워크 컴퓨터 시스템의 블록도이다. 도 1A에서와 같이, 도 1B에 도시된 시스템은 데이터 소스, NIC, 및 서버를 포함한다. 이들 구성 요소는 본 명세서에 설명된 수정에 따라 도 1A에 설명된 구성요소와 유사하거나 동일하게 동작한다. 이들 구성 요소(102, 104, 106)에 대한 추가 세부사항에 대해서는 도 1A를 참조하며, 이러한 세부사항은 본 명세서에서 반 복되지 않는다. 도시된 바와 같이, 데이터 모델러는 데이터 소스와 NIC 사이에 위치된다. 일부 실시형태에서, 데이터 모델러는 데이터 소스와 NIC, 궁극적으로 서버 사이에서 전송되는 데이터를 중재하는 전용 하드웨어 디바이스를 포함한다. 예를 들어, 데이터 모델러는 경량 인공 지능 가속기를 포함할 수 있다. 다른 실시형태에서, 데이터 모델러는 데이터 소스에서 구동되는 소프트웨어 애플리케이션을 포 함한다. 예를 들어, 데이터 모델러는 네트워크 드라이버의 일부로서 구현될 수 있다. 대안적으로, 데이터 모델러는 데이터 소스에서 애플리케이션에 의해 선택적으로 사용될 수 있는 동적으로 링크된 라이브 러리 객체를 포함할 수 있다. 또 다른 실시형태에서, 데이터 모델러는 NIC에서 구현될 수 있다. 다른 실시형태에서와 같이, 데이터 모델러가 NIC에서 구현되면, 이것은 하드웨어 코프로세서로서 또는 소 프트웨어 또는 펌웨어 애플리케이션으로서 구현될 수 있다. 예시된 실시형태에서, 데이터 모델러는 데이터 소스로부터 원시 데이터(예를 들어, 하이파이 데이 터)를 수신하고, NIC를 통해 서버로 관련 데이터를 선택적으로 전달한다. 실제로, 일부 시나리 오에서, 관련 데이터는 하이파이 데이터를 포함할 수 있다. 설명되는 바와 같이, 관련 데이터는 데이터 모델러에서 구현된 AI 모델의 출력에 기초한 가변 용량, 속도 및 가변성의 데이터를 포함한다. 일 부 실시형태에서, 데이터 모델러는 데이터 페이로드가 변경 없이 전송되어야 한다고 예측할 수 있고, 따라 서 NIC는 관련 데이터로서 하이파이 데이터를 전송할 것이다. 다른 실시형태에서, 데이터 모델러 는 하이파이 데이터를 수정하여, 하이파이 데이터의 일부만을 나타내거나 하이파이 데이터의 압축된 버전 을 포함하는 새로운 데이터를 생성할 수 있다. NIC는 그런 다음 이러한 부분 또는 압축된 데이터를 관련 데이터로서 전송한다. 이러한 동작의 예는 관심 객체를 포함하는 비디오 프레임의 서브 세트를 추출하고 배경 픽셀을 제거하는 동작을 포함한다. 일부 실시형태에서, 데이터 모델러는 데이터를 완전히 폐기할 수 있으며, 그 결과 어떠한 관련 데이터도 네트워크를 통해 전송되지 않는다. 이러한 동작의 예는 IoT 디바이 스에 의해 전송된 외부 로그 데이터 또는 예측 모델에 의해 예측된 바와 같은 관심 객체를 포함하지 않는 이미 지의 예측 배제를 포함한다. 도 1A에서 논의된 바와 같이, 서버는 하나 이상의 ML/AI 모델을 트레이닝시키기 위해 데이터 소스로부터의 데이터를 사용할 수 있다. 예시된 실시형태에서, 서버에 의해 트레이닝된 모델(들)은 데이터 소스에 의해 사용되는 모델을 포함할 수 있다. 이 실시형태에서, 서버는 모델을 지속적으로 재트레이닝시키고, 재 트레이닝된 모델을 사용하도록 데이터 모델러를 주기적으로 업데이트할 수 있다. 이러한 방식으로, 서버 및 데이터 소스는 자체 강화된다. 데이터 모델러의 구조에 대한 실시형태는 도 2에서 더 상세히 설명되고, 데이터 모델러의 동작은 도 3 및 도 4에서 더 자세히 설명된다. 이들 도면을 수반하는 설명은 본 명세서에서 반복되지 않고 그 전체가 통합 된다. 도 2는 본 개시내용의 일부 실시형태에 따른 데이터 모델러를 예시하는 블록도이다. 예시된 실시형태에서, 데이터 소스 및 NIC는 도 1B에서 대응하여 식별된 요소를 포함하며, 이에 대한 설명은 본 명세서에서 반복되지 않는다. 예시된 실시형태에서, 데이터 모델러는 데이터그램 분류기, 데이터그램 프로세서, ML 모델 저장부, 및 제어기를 포함한다. 예시된 실시형태에서, 데이터그램 분류기는 데이터 소스에 의해 생성된 원시 데이터를 수신한다. 이 러한 원시 데이터의 예는 센서 데이터, 이미지 데이터, 비디오 데이터, 오디오 데이터, 및 대체로 모든 유형의 데이터를 포함한다. 데이터그램 분류기는 ML 모델 저장부로부터 모델 파라미터를 로딩한다. 일부 실 시형태에서, ML 모델 저장부는 신경망 계수, 하이퍼파라미터(예를 들어, 은닉 레이어의 수, 학습률, 활성 화 함수 등) 및 전략(예를 들어, 데이터 정상화, 정규화 등)과 같은 모델 파라미터를 저장한다. 예시된 실시형 태에서, 데이터그램 분류기는 이러한 파라미터를 로딩하고 예측 모델(예를 들어, ML 모델)을 초기화한다. 일부 실시형태에서, ML 모델 저장부는 모델 파라미터 및 다른 값의 다수의 세트를 포함한다. 일부 실시형 태에서, 이들 다수의 모델은 상이한 유형의 데이터와 상관될 수 있다. 따라서, ML 모델 저장부는 비디오 데이터를 처리하기 위한 모델, 센서 데이터를 처리하기 위한 모델, 오디오 데이터를 처리하기 위한 모델 등을 포함할 수 있다. 또한, 모델은 개별 애플리케이션과 관련될 수 있고; 따라서 ML 모델 저장부는 특정 유형의 카 메라(또는 특정 배향)에 의해 캡처된 비디오 데이터에 대한 모델과, 카메라의 다른 모델(또는 다른 배향)에 대 한 제2 모델을 가질 수 있다. 데이터그램 분류기는 그런 다음 데이터의 소스를 식별하고 ML 모델 저장부 에 저장된 적절한 모델을 선택하도록 구성된다. 그런 다음, 원시 데이터를 수신할 때, 데이터그램 분류기는 원시 데이터를 ML 모델에 입력하고 예측된 출 력을 수신한다. 예측 출력의 콘텐츠의 유형은 다음에 설명되는 바와 같이 사용된 모델에 의존하여 달라진다. 데이터그램 분류기는 모델 출력, 원시 데이터, 및 사용된 모델의 식별자를 데이터그램 프로세서로 전송 한다. 데이터그램 프로세서는 모델 및 데이터에 기초하여 전략 저장 디바이스에 저장된 처리 전략을 식별한 다. 일부 실시형태(미도시)에서, 데이터그램 프로세서는 ML 모델의 출력에 기초하여 수신된 데이터에 대해 선택되고 실행될 수 있는 복수의 처리 전략을 저장한다. 일부 실시형태에서, ML 모델은 처리 전략에 불가지론적 이며, 대신 예측된 데이터 값을 출력한다. 일부 실시형태에서, 처리 전략은 네트워크를 통해 원시 데이터를 전송할 때를 결정하기 위한 규칙의 세트를 포 함할 수 있다. 이러한 실시형태에서, 전략은 데이터를 전송할 때를 결정하기 위한 임계값으로서 ML 모델의 신뢰 출력(confidence output)을 사용한다. 예를 들어, 객체 검출을 수행할 때, 분류기가 어떤 객체도 검출하지 않으면(또는 매우 낮은 신뢰로 객체를 검출하면), 전략은 프로세서에게 전송으로부터 데이터를 삭제하도록 지시할 수 있다. 대안적으로, 분류기가 충분한 신뢰로 하나 이상의 객체를 검출하면, 프로세서는 NIC를 통해 서버로 데이터를 스트리밍할 수 있다. 따라서, 유용한 데이터만 전송된다. 다른 예로서, 비디오 데이터를 처리할 때, 전략은 ML 모델 출력에 기초하여 압축 레벨 또는 다른 처리 단계를 조정할 수 있다. 예를 들어, 비디오 데이터에 어떤 객체도 존재하지 않는다고 모델이 예측하면, 프로세서 는 데이터에 높은 압축 알고리즘을 적용할 수 있다. 대안적으로, 객체가 존재한다고 ML 모델이 예측하면, 프로 세서는 비디오 데이터에 낮은 압축을 적용하거나 심지어 네트워크를 통해 원시 데이터를 전송할 수 있다. 데이터 모델러는 제어기를 더 포함한다. 예시된 실시형태에서, 제어기는 데이터 모델러의 동작 을 조정한다. 소프트웨어 기반 구현에서, 제어기는 감독자 프로세스 또는 다른 프로세스를 생성하는 유사 한 프로세스를 포함할 수 있다. 하드웨어 구현에서, 제어기는 모델러를 관리하기 위한 전용 펌웨어를 실행하는 전용 마이크로제어기를 포함할 수 있다. 예시된 실시형태에서, 제어기는 주로 모델 저장부 및 전략 저장부를 관리한다. 예시된 실시형태에서, 처리 전략 및 모델은 원격 컴퓨팅 디바이스에 의해 업데이트되고 제어기를 통해 모 델러에 전송될 수 있다. 제어기는 그런 다음 각각의 저장 디바이스(202, 212)에 저장된 모델 및 전략 을 업데이트할 수 있다. 일부 실시형태에서, 데이터 모델러는 자체 강화될 수 있다. 즉, 저장부에 저 장된 모델은 분류기 및 프로세서에 의해 생성된 트레이닝 데이터를 사용하여 원격 서버(예를 들어, 106)에 의해 트레이닝될 수 있다. 객체 검출 예를 계속하면, ML 모델은 임의의 이미지에서 객체를 식별하기 위한 일반 적인 모델을 포함한다. 이 모델은 중앙의 원격 서버에 의해 연속적으로 재트레이닝될 수 있다. 데이터 모델러 는 잠재적인 트레이닝 데이터를 연속적으로 생성하는 차량에서 구현될 수 있다. 그러나, 트레이닝 목적을 위해, 모든 프레임은 일반적으로 모델 가중치를 미세 조정하는데 필요하지 않는다. 따라서, 차량은 서버로 전송 하기 위한 관련 데이터 트레이닝 데이터를 생성하기 위해 이미지를 전송하는 것을 선제적으로 생략한다. 서버는 그런 다음 이러한 관련 이미지를 트레이닝 데이터로서 사용하고, 모델을 재트레이닝시킨 후 업데이트된 모델을 차량으로 다시 전송한다. 특히, 예시된 실시형태에서, 모델러에서 구현된 ML 모델은 경량 AI 모델이다. 즉, ML 모델은 중앙 서버나 저장소에서 동작하는 보다 정교한 AI 프레임워크에 비해 최소한의 하드웨어에서 실행되도록 설계되었으며 낮은 복잡성의 소프트웨어이다. 도 3은 본 개시내용의 일부 실시형태에 따른 트레이닝 데이터를 선택적으로 전송하기 위해 경량 AI 레이어를 사 용하기 위한 방법을 예시하는 흐름도이다. 블록에서, 방법은 데이터 페이로드를 수신한다. 전술한 바와 같이, 이 데이터 페이로드는 컴퓨팅 디바이스 또는 시스템에 의해 생성될 수 있다. 일부 실시형태에서, 데이터 페이로드는 이미지 데이터, 비디오 데이터, 센 서 데이터 등을 포함한다. 일반적으로, 임의의 데이터가 블록에서 수신될 수 있다. 일부 실시형태에서, 수 신된 데이터는 AI 트레이닝 목적을 위해 서버로 전송될 데이터를 포함할 수 있다. 이들 실시형태에서, 방법은 이러한 전송 전에만 실행될 수 있고, 모든 다른 전송에 대해 우회될 수 있다. 블록에서, 방법은 예측 모델을 사용하여 데이터 페이로드를 분석한다. 일 실시형태에서, 예측 모델은 ML 또는 AI 모델을 포함한다. 일부 실시형태에서, 모델은 인공 신경망, 순환 신 경망, 컨볼루션 신경망, 또는 다른 유형의 신경망을 포함할 수 있다. 예시된 실시형태에서, 방법은 경량 AI/ML 레이어를 사용하여 블록을 실행한다. 일부 실시형태에서, 경량 AI/ML 레이어는 상용 하드웨어에서 동작하는 소프트웨어 지향 AI/ML 레이어를 포함할 수 있다. 일부 실시형태에 서, 경량 AI/ML 레이어는 광범위한 트레이닝에 기초하여 미세 조정되지 않는 일반적인 AI/ML 시스템을 포함할 수 있다. 예를 들어, 상용 기성품(COTS) 분류기는 경량 AI/ML 레이어로서 사용될 수 있는 반하여, 중앙 집중식 AI/ML 레이어는 미세 조정된 신경망을 포함할 수 있다. 경량 AI/ML 레이어와 무거운 AI/ML 레이어 사이를 구분 하는 다양한 예가 아래에 제공된다. 일 실시형태에서, 경량 AI/ML 레이어는 단일 스테이지 객체 검출기를 포함한다. 이 시나리오에서, 경량 AI/ML 레이어는 You Only Look Once(\"YOLO\") 모델, Single Shot Detector(SSD) 모델, RetinaNet 또는 유사한 단일 스 테이지 객체 검출 모델을 포함할 수 있다. 대조적으로, 무거운 AI/ML은 지역적인 CNN(R-NN), Fast or Faster R-CNN 또는 기타 유사한 복잡한 모델과 같은 2-스테이지 객체 검출 모델을 포함할 수 있다. 일반적으로, 더 복 잡한 모델은 경량 AI/ML 레이어가 없는 지역적인 제안 스테이지를 포함할 것이다. 특히, 두 모델 모두 동일한 일반적인 출력을 예측하려고 시도한다. 그러나, 경량 AI/ML 레이어는 더 높은 위양성율(false positive rate)의 수용으로 최대한 빠르게 설계되었다. 일반적으로, 블록의 주요 목적은 더 무거운 AI/ML 레이어의 트레이닝 속도를 향상시키는 추가 트레이닝으로부터 명백하게 잘못된 위양성을 필터링하는 것이다. 주로 객체 검출의 맥 락에서 설명되었지만, 원칙은 다른 AI/ML 레이어로 확장될 수 있다. 예시된 실시형태에서, 예측 모델의 출력은 일반적으로 분류 또는 결과 및 신뢰 수준을 포함할 것이다. 예를 들 어, 객체 검출 시나리오에서, 예측 모델은 객체의 경계 상자 좌표와 예측의 정확도에 대한 신뢰 수준을 출력한 다. 블록에서, 방법은 예측이 긍정적 또는 부정적인지를 결정한다. 긍정적 또는 부정적 예측은 사용된 모델의 유형에 의존할 수 있다. 예를 들어, 이진 분류기는 (객체 검출 모델의 출력에 비해) 긍정적 또는 부정적 분류를 출력한다. 그러나, 일반적인 원칙은 모든 ML 모델에 적용된다. 블록에서, 방법은 출력이 부정적이면 데이터를 폐기한다. 본 명세서에서 사용된 바와 같이, 부정적인 예측 은 모델이 예측하려고 시도하는 것과 입력 데이터가 일치하지 않는다고 예측하는 ML 모델을 지칭할 수 있다. 예 를 들어, 객체 검출 시나리오에서, 부정적인 예측은 어떠한 객체도 검출되지 않았다는 것을 의미한다. 대안적으 로 또는 전술한 것과 관련하여, 부정적인 예측은 컷오프 임계값 미만의 신뢰 수준을 가지는 예측을 의미할 수 있다. 따라서, 이전 예에서, 객체가 이미지에서 존재한다고 모델이 예측하지만 그 예측의 신뢰가 임계값 미만이 면, 방법은 데이터를 폐기할 수 있다. 도 4에서 설명되는 바와 같이, 일부 실시형태에서, 방법은 예를 들어 데 이터를 압축하는 것에 의해 데이터를 폐기하는 대신 데이터를 처리할 수 있다. 블록에서, 대안적인 방법은 예측이 긍정적이면 전체 데이터를 전송한다. 본 명세서에 사용된 바와 같이, 긍정적인 예측은 입력 데이터가 모델이 예측하려고 시도하는 것과 일치한다고 예측하는 ML 모델을 지칭할 수 있 다. 예를 들어, 객체 검출 시나리오에서, 긍정적인 예측은 적어도 하나의 객체가 검출되었다는 것을 의미한다. 대안적으로, 또는 전술한 것과 관련하여, 긍정적인 예측은 컷오프 임계값보다 높은 신뢰 수준을 가진다는 예측 을 의미할 수 있다. 따라서 이전 예에서, 객체가 이미지에서 존재한다고 모델이 예측하고 해당 예측의 신뢰가 임계값 이상이면, 방법은 날짜를 전송할 수 있다. 일부 실시형태에서, 방법은 블록에서 수신된 바와 같은 원시 데이터를 전송한다. 대안적으로, 방법은 압축의 양을 긍정적인 검출로 감소시키기 위해 압축 레벨을 변경 할 수 있다. 예시된 방법에서, 경량 ML/AI 모델은 중앙 서버로 전송할 데이터를 신속하게 분류하도록 사용된다. 데이터가 관 심 데이터라고 경량 ML/AI 모델이 예측하면(긍정적인 예측으로 인해), 방법은 데이터를 서버로 전송할 수 있다. 반대로, 데이터가 유용하지 않는다고 경량 ML/AI 모델이 예측하면(부정적인 예측으로 인해), 방법은 데이터를 폐기할 수 있으며, 그러므로 네트워크 대역폭과 서버측 계산 리소스를 절약할 수 있다. 도 4는 본 개시내용의 일부 실시형태에 따른 비디오 트레이닝 데이터를 선택적으로 전송하기 위해 경량 AI 레이 어를 사용하기 위한 방법을 예시하는 흐름도이다. 블록에서, 방법은 비디오 페이로드를 수신한다. 일 실시형태에서, 비디오 페이로드는 비디오를 구성하는 하나 이상의 이미지 프레임을 포함한다. 일 실시형태에서, 비디오 데이터는 자동차 카메라에 의해 생성된 스트 리밍 비디오 데이터를 포함할 수 있다. 다른 실시형태에서, 비디오 데이터는 보안 카메라 또는 유사한 카메라로 부터의 비디오 데이터를 포함할 수 있다. 비디오 데이터의 특정 소스는 제한되지 않는다. 블록에서, 방법은 AI/ML 모델을 로딩한다. 예시된 실시형태에서, AI/ML 모델은 이전에 설명된 바와 같은 경량 AI/ML 모델을 포함한다. 일부 실시형태에서, AI/ML 모델은 소프트웨어로 구현되고, AI/ML 모델을 로딩하는단계는 저장 디바이스로부터 모델을 한정하는 파라미터를 로딩하는 단계를 포함한다. 블록에서, 방법은 경량 AI/ML 모델을 사용하여 비디오 페이로드를 처리한다. 일 실시형태에서, AI/ML 모델 을 사용한 비디오 페이로드의 처리는 비디오 페이로드에서 객체 검출을 수행하는 것을 포함한다. 일부 실시형태 에서, 객체 검출은 비-배경 객체(예를 들어, 사람, 차량 등)를 포함하는 경계 상자의 세트를 생성하는 것을 포 함한다. 전술한 바와 같이, 출력은 0개 이상의 예측 및 각각에 대한 신뢰 수준을 포함할 수 있다. 객체 검출 예 에서, 예측은 객체를 캡처하는 경계 상자를 포함한다. 블록에서, 방법은 블록에서 생성된 예측에 기초하여 비디오 페이로드 전처리를 조정한다. 본 명세서 에서 설명된 바와 같이 다양한 조정이 이루어질 수 있다. 제1 조정에서, 방법은 비디오 페이로드를 폐기할 수 있다. 이 시나리오에서, 방법은 블록 후에 종료된다. 일 실시형태에서, 방법은 블록에서 어떠한 예측도 만들어지지 않을 때 비디오 페이로드를 폐기한다. 예를 들어, 경량 AI/ML 모델이 비디오 페이로드에 존재하는 어떤 객체도 예측하지 않으면, 예측의 횟수는 0이다. 다 른 실시형태에서, 방법은 트리거 임계값을 초과하는 신뢰 수준을 가지는 예측이 존재하지 않으면 비디오 페이로 드를 폐기할 수 있다. 제2 조정에서, 방법은 예측 출력에 기초하여 비디오 데이터의 압축 레벨을 조정할 수 있다. 예를 들어 경량 AI/ML 모델이 어떠한 객체도 예측하지 않으면, 방법은 비디오 페이로드에 최대 압축을 적용할 수 있다. 경량 AI/ML 모델이 낮은 신뢰를 가지는 객체를 예측하면, 방법은 비디오 페이로드에 중간 압축을 적용할 수 있다. 경 량 AI/ML 모델이 높은 신뢰 수준을 가지는 객체를 예측하면, 방법은 비디오 페이로드에 낮은 압축을 적용하거나 일부 실시형태에서 어떠한 압축도 적용하지 않을 수 있다. 일 실시형태에서, 방법은 경량 AI/ML 모델이 높은 신뢰 수준을 가지는 예측을 출력하면 블록을 우회할 수 있다. 이 시나리오에서, 경량 AI/ML 모델은 비디오 페이로드가 유용한 정보를 가진다고 합리적으로 예측한다. 예를 들어, 비디오 페이로드가 높은 신뢰 수준을 가지는 객체를 포함한다고 경량 AI/ML 모델이 예측하면, 방법 은 블록을 우회하고 블록으로 직접 진행할 수 있다. 블록에서, 방법은 처리된 데이터를 서버로 전송한다. 일부 실시형태에서, 위에서 논의된 바와 같이, 이 단 계는 선택적이다. 선택적이면, 방법은 종료된다. 예시된 실시형태에서, 방법은 블록의 설명에서 전술한 바 와 같이 처리되지 않은 비디오 데이터 또는 처리된 비디오 데이터를 전송한다. 예시된 실시형태에서, 방법은 NIC 또는 유사한 디바이스를 사용하여 데이터를 전송한다. 블록에서, 서버는 처리된 데이터를 수신한다. 위에서 논의된 바와 같이, 일부 실시형태에서, 처리된 데이 터는 원시 비디오 페이로드 데이터를 포함할 수 있거나 동일한 비디오 페이로드의 압축된 버전을 포함할 수 있 다. 두 가지 유형의 데이터는 모두 \"처리된 데이터\"로 지칭된다. 블록에서, 방법은 처리된 데이터를 무거운 AI/ML 모델을 위해 트레이닝 데이터 세트에 추가한다. 위에서 설명된 바와 같이, 무거운 AI/ML 모델은 블록에서 예측된 것과 동일한 출력을 예측하도록 사용되는 더 복 잡한 모델을 포함할 수 있다. 즉, 두 블록에서, 관련된 모델이 동일한 기능을 수행하도록 사용되며; 그러나, 서 버측 AI/ML 모델은 기능을 수행하기 위한 보다 정교한 알고리즘을 포함한다. 하나의 예로서, 서버측 모델은 최 적화된 하드웨어(예를 들어, TPU 또는 GPU)를 활용할 수 있으며, 모델을 연속적으로 트레이닝 및 재트레이닝시 키기에 충분한 저장 및 처리 능력을 포함한다. 예시된 실시형태에서, 방법은 서버측 모델을 트레이닝시키기 위 한 트레이닝 데이터를 저장하는 저장 디바이스(또는 저장 디바이스의 네트워크)를 유지한다. 블록에서, 방 법은 수신된 데이터를 이러한 코퍼스(corpus)에 삽입한다. 일부 실시형태에서, 방법은 처리된 데이터의 일부로 서 경량 AI/ML 모델의 출력을 수신하고, 이 출력을 처리된 데이터와 함께 저장한다. 블록에서, 방법은 수신된 처리된 데이터를 사용하여 서버측 모델을 재트레이닝시킨다. 예시된 실시형태에 서, 재트레이닝은 신경망과 같은 예측 모델을 재트레이닝시키는 분야에서 공지된 임의의 방식으로 수행될 수 있 다. 일반적으로, 블록에 저장된 각각의 처리된 데이터 엔트리는 트레이닝 코퍼스로 조합되고 모델 오프라 인을 트레이닝시키도록 사용된다. 블록에서, 방법은 트레이닝 후에 업데이트된 모델 파라미터를 클라이언트로 전송한다. 일부 실시형태에서, 이 단계는 선택적이다. 블록이 실행되는 실시형태에서, 경량 AI/ML 모델 및 서버측 AI/ML은 유사한 모델을 포함할 수 있고, 따라서 파라미터를 재사용할 수 있다. 예를 들어, 서버에서의 2-스테이지 모델은 경량 1-스테 이지 모델에서 사용하기 위해 1-스테이지 파라미터를 클라이언트에 전송할 수 있다. 그러나, 다른 실시형태에서, 블록은 모델이 상이한 방식으로 조정되고 상이한 파라미터를 가짐에 따라서 실행되지 않는다. 대안적인 실시형태에서, 방법은 더 무거운 서버측 모델과 함께 경량 AI/ML 모델의 서버측 복사본을 동시에 트레 이닝시킬 수 있다. 이 시나리오에서, 방법은 경량 AI/ML 모델의 서버측 트레이닝의 결과를 사용하여 전체 경량 AI/ML 모델을 업데이트할 수 있다. 블록에서, 방법은 서버측 경량 AI/ML 모델을 저장한다. 방법이 서버측 경량 AI/ML 모델을 생성하면, 방법 은 마찬가지로 해당 모델을 저장한다. AI/ML 모델의 저장은 잘 알려져 있으며, 어떠한 유형의 저장 메커니즘도 이러한 모델을 저장하도록 사용될 수 있다. 도 5는 본 개시내용의 일부 실시형태에 따른 컴퓨팅 디바이스의 블록도이다. 처리 디바이스는 도 5에 도시된 구성요소보다 더 많거나 더 적은 구성요소를 포함할 수 있다. 예를 들어, 앞서 언급한 예는 오디오 인터페이스, 디스플레이, 키패드, 조명기 또는 카메라/센서를 요구하지 않을 수 있다. 그러 나, 도시된 구성요소는 본 개시내용을 구현하기 위한 예시적인 실시형태를 개시하기에 충분하다. 또한, 일부 실 시형태에서, 도 5에 예시된 디바이스는 가상 머신으로서 구현될 수 있는 반면, 다른 실시형태에서, 디바이스는 물리적 머신으로서 구현될 수 있다. 일부 실시형태에서, 디바이스는 도 5에 도시된 디바이스에서 실행되는 가상 머신에 의해 둘 다로서 구현된다. 도 5에 도시된 바와 같이, 디바이스는 버스를 통해 대용량 메모리와 통신하는 처리 유닛 (CPU)을 포함한다. 디바이스는 또한 하나 이상의 네트워크 인터페이스, 오디오 인터페이스 , 디스플레이, 키패드, 조명기, 입력/출력 인터페이스 및 카메라(들) 또는 기타 광학, 열 또는 전자기 센서를 포함한다. 디바이스는 당업자에 의해 이해되는 바와 같이 하나의 카메 라/센서 또는 복수의 카메라/센서를 포함할 수 있다. 디바이스는 선택적으로 기지국(미도시)과 통신하거나 다른 컴퓨팅 디바이스와 직접 통신할 수 있다. 네트 워크 인터페이스는 디바이스를 하나 이상의 네트워크에 연결하기 위한 회로를 포함하고, 하나 이상의 통신 프로토콜 및 기술과 함께 사용하도록 구성된다. 네트워크 인터페이스는 트랜시버, 트랜시버 디바이스 또는 네트워크 인터페이스 카드(NIC)로서 공지되어 있다. 오디오 인터페이스는 인간 음성과 같은 오디오 신호를 생성하고 수신하도록 배열된다. 예를 들어, 오디오 인터페이스는 다른 사람들과의 원격 통신을 가능하게 하고 어떤 동작에 대한 오디오 수령 통지를 생성하기 위해 스피커 및 마이크로폰(미도시)에 결합될 수 있다. 디스플레이는 액정 디스플레이(LCD), 가스 플라즈 마, 발광 다이오드(LED), 또는 컴퓨팅 디바이스와 함께 사용되는 임의의 다른 유형의 디스플레이일 수 있다. 디 스플레이는 또한 스타일러스와 같은 물체로부터의 입력 또는 사람의 손으로부터의 숫자를 수신하도록 배열 된 터치 감지 스크린을 포함할 수 있다. 키패드는 사용자로부터 입력을 수신하도록 배열된 임의의 입력 디바이스를 포함할 수 있다. 예를 들어, 키 패드는 푸시 버튼 숫자 다이얼 또는 키보드를 포함할 수 있다. 키패드는 또한 이미지를 선택하고 전 송하는 것과 관련된 명령어 버튼을 포함할 수 있다. 조명기는 상태 표시를 제공하고, 조명을 제공할 수 있 다. 조명기는 특정 기간 동안 또는 이벤트에 응답하여 활성 상태를 유지할 수 있다. 예를 들어, 조명기 는 활성화될 때 디바이스에 전원이 공급되는 동안 키패드 상의 버튼을 백라이팅하고 유지할 수 있다. 또한, 조명기는 다른 처리 디바이스를 다이얼링하는 것과 같은 동작이 수행될 때 이러한 버튼을 다 양한 패턴으로 백라이팅할 수 있다. 조명기는 디바이스의 투명 또는 반투명 케이스 내에 위치되는 동 안 동작에 응답하여 광원이 조명되도록 할 수 있다. 디바이스는 또한 도 5에 도시되지 않은 외부 디바이스와 통신하기 위한 입력/출력 인터페이스를 포함 한다. 입력/출력 인터페이스는 USB, 적외선, Bluetooth™ 등과 같은 하나 이상의 통신 기술을 이용할 수 있다. 대용량 메모리는 RAM, ROM 및 기타 저장 수단을 포함한다. 대용량 메모리는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보를 저장하기 위한 컴퓨터 저장 매체의 다른 예를 예시한다. 대용량 메모리는 처리 디바이스의 저수준 동작을 제어하기 위한 기본 입력/출력 시스템(\"BIOS\")을 저장한다. 대용량 메모리는 또한 처리 디바이스의 동작을 제어하기 위한 운영 체제 를 저장할 수 있다. 이 구성요소는 UNIX 또는 LINUX™의 버전과 같은 범용 운영 체제 또는 Windows Client™ 또 는 Symbian® 운영 체제와 같은 특수 클라이언트 통신 운영 체제를 포함할 수 있다는 것이 이해될 것이다. 운영 체제는 Java 애플리케이션 프로그램을 통해 하드웨어 구성요소 및 운영 체제 동작의 제어를 가능하게 하는 Java가상 머신 모듈을 포함하거나 이와 접속할 수 있다. 메모리는 전술한 방법의 일부 또는 전부를 구현하기 위한 하나 이상의 소프트웨어 애플리케이션을 포함한다. 그러나, 위에 개시된 요지는 다양한 상이한 형태로 구현될 수 있고, 따라서 적용되거나 청구된 요지는 본 명세 서에서 설명된 임의의 예시적인 실시형태로 제한되지 않는 것으로 해석되도록 의도되며; 예시적인 실시형태는 단지 예시를 위해 제공된다. 마찬가지로, 청구되거나 적용되는 요지에 대한 합리적으로 넓은 범위가 의도된다. 무엇보다도, 예를 들어, 요지는 방법, 디바이스, 구성요소 또는 시스템으로서 구현될 수 있다. 따라서, 실시형 태는 예를 들어 하드웨어, 소프트웨어, 펌웨어 또는 이들의 임의의 조합(소프트웨어 자체는 제외)의 형태를 취 할 수 있다. 그러므로, 다음의 상세한 설명은 제한적인 의미로 받아들여지도록 의도되지 않는다. 명세서 및 청구범위 전체에 걸쳐, 용어는 명시적으로 언급된 의미를 넘어 문맥에서 제안되거나 암시된 미묘한 의미를 가질 수 있다. 마찬가지로, 본 명세서에서 사용된 \"일 실시형태에서\"라는 문구는 반드시 동일한 실시형 태를 지칭하는 것은 아니며, 본 명세서에서 사용되는 \"다른 실시형태에서\"라는 문구가 반드시 다른 실시형태를 지칭하는 것은 아니다. 예를 들어, 청구된 요지는 전체 또는 부분적으로 예시적인 실시형태의 조합을 포함하도 록 의도된다. 일반적으로, 용어는 문맥상의 용법으로부터 적어도 부분적으로 이해될 수 있다. 예를 들어, 본 명세서에 사용된 바와 같이, \"및\", \"또는\", 또는 \"및/또는\"과 같은 용어는 이러한 용어가 사용되는 문맥에 적어도 부분적으로 의 존할 수 있는 다양한 의미를 포함할 수 있다. 전형적으로, \"또는\"은 A, B 또는 C와 같은 목록을 관련시키도록 사용되면 본 명세서에서 포괄적인 의미로 사용되는 A, B 및 C와 본 명세서에서 배타적인 의미로 사용되는 A, B 또는 C를 의미하도록 의도된다. 아울러, 본 명세서에 사용된 바와 같이, \"하나 이상\"이라는 용어는 적어도 부분 적으로 문맥에 따라 단수 의미로 임의의 특징, 구조 또는 특성을 설명하도록 사용될 수 있거나, 또는 복수 의미 로 특징, 구조 또는 특성의 조합을 설명하도록 사용될 수 있다. 유사하게, \"단수 표현\"과 같은 용어는 적어도 부분적으로 문맥에 따라 단수 용법을 전달하거나 복수 용법을 전달하는 것으로 이해될 수 있다. 또한, \"~에 기 초한\"이라는 용어는 배타적인 세트의 요인을 전달하도록 반드시 의도된 것은 아닌 것으로 이해될 수 있으며, 대 신에 적어도 부분적으로 문맥에 따라 반드시 명시적으로 설명되지 않은 추가 요인의 존재를 허용할 수 있다. 본 명세서에서 설명된 차량은 차량이 달리 지정되지 않는 한 임의의 유형의 차량일 수 있다는 것을 이해해야 한 다. 차량은 자동차, 트럭, 보트 및 비행기뿐만 아니라 군사, 건설, 농업 또는 레크리에이션용 차량 또는 차량 장비를 포함할 수 있다. 차량, 차량 부품 또는 차량의 운전자나 승객에 의해 사용되는 전자 기기는 차량 전자 기기로 간주될 수 있다. 차량 전자 기기는 엔진 관리, 점화, 라디오, 카푸터(carputer), 텔레매틱스, 차량내 엔 터테인먼트 시스템, 및 차량의 다른 부분을 위한 전자 기기를 포함할 수 있다. 차량 전자 기기는 가스 동력 자 동차, 트럭, 오토바이, 보트, 비행기, 군용 차량, 지게차, 트랙터 및 굴착기와 같은 내연 기관 구동 기계류를 가지는 차량에서 볼 수 있는 점화 및 엔진 및 변속기 제어부와 함께 또는 이에 의해 사용될 수 있다. 또한, 차 량 전자 기기는 하이브리드 또는 전기 자동차와 같은 하이브리드 및 전기 차량에서 발견되는 전기 시스템의 제 어를 위해 관련 요소에 의해 또는 이와 함께 사용될 수 있다. 예를 들어, 전기 자동차는 배터리 시스템 관리뿐 만 아니라 주 추진 모터 제어를 위한 전력 전자 기기를 사용할 수 있다. 그리고, 자율주행 차량은 거의 전적으 로 차량 전자 기기에 의지한다. 본 개시내용은 방법 및 디바이스의 블록도 및 동작 예시를 참조하여 설명된다. 블록도 또는 동작 예시의 각각의 블록, 및 블록도 또는 동작 예시에서의 블록의 조합은 아날로그 또는 디지털 하드웨어 및 컴퓨터 프로그램 명령 어에 의해 구현될 수 있다는 것을 이해해야 한다. 이들 컴퓨터 프로그램 명령어는 범용 컴퓨터의 프로세서에 제 공되어, 본 명세서에서 설명된 기능을 변경하거나, 특수 목적 컴퓨터, ASIC 또는 기타 프로그래밍 가능한 데이 터 처리 장치에 제공될 수 있어서. 컴퓨터 또는 기타 프로그램 가능한 데이터 처리 장치의 프로세서를 통해 실 행될 수 있는 명령어는 블록도 또는 동작 블록 또는 블록들에서 지정된 기능/행위를 구현한다. 일부 대안적인 구현에서, 블록에 언급된 기능/행위는 작동 예시에 언급된 순서와 다르게 일어날 수 있다. 예를 들어, 연속적으 로 도시된 2개의 블록은 실제로 실질적으로 동시에 실행될 수 있거나 또는 블록은 때때로 관련된 기능/행위에 따라 역순으로 실행될 수 있다. 이들 컴퓨터 프로그램 명령어는 특수 목적으로 그 기능을 변경하기 위하여 범용 컴퓨터; 특수 목적 컴퓨터; ASIC; 또는 다른 프로그램 가능한 디지털 데이터 처리 장치의 프로세서 제공될 수 있어서, 컴퓨터 또는 다른 프 로그램 가능한 데이터 처리 장치의 프로세서를 통해 실행되는 명령어는 블록도 또는 동작 블록 또는 블록들에 지정된 기능/행위를 구현하고, 이에 의해 본 명세서에서의 실시형태에 따라서 기능을 변환한다. 본 개시내용의 목적을 위해, 컴퓨터 판독 가능 매체(또는 컴퓨터 판독가능 저장 매체/매체들)는 컴퓨터 데이터 를 저장하고, 이 데이터는 컴퓨터에 의해 실행 가능한 컴퓨터 프로그램 코드(또는 컴퓨터 실행 가능 명령어)를 기계 판독 가능한 형태로 포함할 수 있다. 제한이 아닌 예로서, 컴퓨터 판독 가능 매체는 데이터의 유형적 또는 고정 저장을 위한 컴퓨터 판독 가능 저장 매체, 또는 코드 포함 신호의 일시적 해석을 위한 통신 매체를 포함할 수 있다. 본 명세서에 사용된 바와 같이, 컴퓨터 판독 가능 저장 매체는 물리적 또는 유형적 저장(신호에 대비 되는 것으로서)을 지칭하며, 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 유형적 저장을 위한 임의의 방법 또는 기술로 구현되는 휘발성 및 비휘발성, 이동식 및 비이동식 매체를 제한 없이 포함한다. 컴퓨터 판독 가능한 저장 매체는 RAM, ROM, EPROM, EEPROM, 플래시 메모리 또는 기타 솔리 드 스테이트 메모리 기술, CD-ROM, DVD 또는 기타 광학 저장 장치, 자기 카세트, 자기 테이프, 자기 디스크 저 장 장치, 또는 기타 자기 저장 디바이스, 또는 원하는 정보, 데이터 또는 명령어를 유형적으로 저장하도록 사용 될 수 있고 컴퓨터 또는 프로세서에 의해 액세스될 수 있는 임의의 기타 물리적 또는 물질적 매체를 포함하지만 이에 제한되지 않는다. 본 개시내용의 목적을 위해, 모듈은 (인간 상호 작용 또는 증강의 유무에 관계없이) 본 명세서에서 설명된 프로 세스, 특징 및/또는 기능을 수행하거나 용이하게 하는 소프트웨어, 하드웨어 또는 펌웨어(또는 이들의 조합) 시 스템, 프로세스 또는 기능, 또는 이들의 구성요소이다. 모듈은 서브 모듈을 포함할 수 있다. 모듈의 소프트웨어 구성요소는 프로세서에 의한 실행을 위해 컴퓨터 판독 가능 매체에 저장될 수 있다. 모듈은 하나 이상의 서버에 통합되거나 하나 이상의 서버에 의해 로딩되어 실행될 수 있다. 하나 이상의 모듈을 엔진 또는 애플리케이션으 로 그룹화될 수 있다. 당업자는 본 개시내용의 방법 및 시스템이 많은 방식으로 구현될 수 있고 그 자체가 전술한 예시적인 실시형태 및 예에 의해 제한되지 않는다는 것을 인식할 것이다. 다시 말해서, 하드웨어 및 소프트웨어 또는 펌웨어의 다 양한 조합 및 개별 기능에서 단일 또는 다중 구성요소에 의해 수행되는 기능 요소는 클라이언트 수준 또는 서버 수준 또는 둘 다에서 소프트웨어 애플리케이션 사이에 분산될 수 있다. 이와 관련하여, 본 명세서에서 설명된 상이한 실시형태의 임의의 수의 특징은 단일 또는 다수의 실시형태로 조합될 수 있고, 본 명세서에서 설명된 모 든 특징보다 적거나 많은 대안적인 실시형태가 가능하다. 기능은 또한 현재 알려져 있거나 알려질 방식으로 전체 또는 부분적으로 다수의 구성요소 사이에 분산될 수 있 다. 따라서, 여기에 설명된 기능, 특징, 인터페이스 및 선호도를 달성하는데 무수한 소프트웨어/하드웨어/펌웨 어 조합이 가능하다. 더욱이, 본 개시내용의 범위는 설명된 특징 및 기능 및 인터페이스뿐만 아니라 현재 및 이 후의 당업자에 의해 이해되는 바와 같이 본 명세서에 설명된 하드웨어 또는 소프트웨어 또는 펌웨어 구성요소에 대해 이루어질 수 있는 변형 및 수정을 수행하기 위한 통상적으로 공지된 방식을 커버한다. 또한, 본 개시내용에서 흐름도로서 제시되고 설명된 방법의 실시형태는 기술의 보다 완전한 이해를 제공하기 위 해 예로서 제공된다. 개시된 방법은 본 명세서에서 제시된 동작 및 논리적 흐름에 제한되지 않는다. 다양한 동 작의 순서가 변경되고 더 큰 동작의 일부인 것으로 설명된 서브 동작이 독립적으로 수행되는 대안적인 실시형태 가 고려된다. 다양한 실시형태가 본 개시내용의 목적을 위해 설명되었지만, 이러한 실시형태는 본 개시내용의 교시를 이러한 실시형태로 제한하는 것으로 간주되어서는 안 된다. 다양한 변경 및 수정이 본 개시내용에서 설명된 시스템 및 프로세스의 범위 내에 있는 결과를 얻기 위해 위에서 설명된 요소 및 동작에 대해 만들어질 수 있다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2022-7033779", "section": "도면", "subsection": "도면설명", "item": 1, "content": "실시형태는 유사한 도면 부호가 유사한 요소를 나타내는 첨부 도면에서 제한이 아니라 예시의 방식으로 예시된 다. 도 1A는 본 개시내용의 일부 실시형태에 따른 네트워크 컴퓨터 시스템의 블록도이다. 도 1B는 본 개시내용의 일부 실시형태에 따른 개선된 네트워크 컴퓨터 시스템의 블록도이다. 도 2는 본 개시내용의 일부 실시형태에 따른 데이터 모델러(data modeler)를 예시하는 블록도이다. 도 3은 본 개시내용의 일부 실시형태에 따른 트레이닝 데이터를 선택적으로 전송하기 위해 경량 AI 레이어를 사 용하기 위한 방법을 예시하는 흐름도이다. 도 4는 본 개시내용의 일부 실시형태에 따른 비디오 트레이닝 데이터를 선택적으로 전송하기 위해 경량 AI 레이 어를 사용하기 위한 방법을 예시하는 흐름도이다. 도 5는 본 개시내용의 일부 실시형태에 따른 컴퓨팅 디바이스의 블록도이다."}
