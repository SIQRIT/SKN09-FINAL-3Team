{"patent_id": "10-2017-0157627", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0054505", "출원번호": "10-2017-0157627", "발명의 명칭": "매장 관리 장치, 그 방법 및 매장 관리 로봇", "출원인": "주식회사 로보러스", "발명자": "김대훈"}}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능형 매장 관리 장치로서, 매장 내 정해진 지점의 매장 영상을 촬영하는 영상 촬영부, 상기 매장 영상을 이용한 매장 관리를 수행하는 프로그램을 저장하는 저장부, 그리고상기 프로그램을 실행하는 프로세서를 포함하고,상기 프로그램은,신경망 모델을 사용하여 매장 영상에 대응되는 매장 상태를 학습하고, 학습 결과를 사용하여 실시간으로 촬영되는 매장 영상으로부터 매장 상태를 인식하며, 매장 상태 인식 결과로부터 기 정의된 매장 상태를 판단하여 외부로 출력하는 명령어들(instructions)을 포함하는, 매장 관리 장치."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 프로그램은, 상기 영상 촬영부가 서로 다른 복수의 각도 및 복수의 시간에 촬영하여 획득한 서로 다른 종류의 매장 영상을,상기 매장 영상과 전혀 다른 대조군의 매장 영상을 통한 딥(deep) 신경망 모델 학습을 통하여 후보 영역에서 매장 상태를 구분하는 특징 정보를 추출하여 매장 상태 인식을 위한 학습 정보로 상기 저장부에 저장하고,상기 학습 정보에 기초하고, 상기 영상 촬영부가 실시간 촬영하는 매장 영상을 입력으로 상기 신경망 모델을 사용하여 매장 상태를 인식하는 명령어들을 포함하는, 매장 관리 장치."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에서,상기 프로그램은, 매장 상태 인식 결과를 기 정의된 기준값과 대응시켜 매장 상태를 판단하는 명령어들을 포함하는, 매장 관리 장치."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에서,상기 기준값은,영상속 카운트된 사람수, 테이블 위에 컵이 있는지 유무 및 의자에 사람이 있는지 유무 중 적어도 하나를 포함하여 설정되고, 상기 매장 상태는,매장 혼잡도를 포함하는, 매장 관리 장치."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로그램은,매장 영상을 신경망 모델을 사용한 학습이 가능한 외부의 클라우드 서버로 전달하여 매장 영상에 대응되는 감정공개특허 10-2018-0054505-3-학습을 수행시킨 후,실시간 촬영된 매장 영상을 상기 클라우드 서버로 전달하여 상기 매장 영상에 대응되는 매장 상태 인식을 요청한 후 상기 클라우드 서버로부터 전달되는 매장 상태 인식 결과를 수신하며, 수신한 매장 상태 인식 결과로부터 상기 매장 상태를 판단하는 명령어들을 포함하는, 매장 관리 장치."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항서,상기 신경망 모델은,합성곱 신경망(Convolutional Neural Network, CNN) 모델인, 매장 관리 장치."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "적어도 하나의 프로세서에 의해 동작하는 매장 관리 장치에서 수행되는 매장관리 방법으로서,복수의 매장 영상에 대응되는 매장 상태를 신경망 모델을 사용하여 학습하는 단계,상기 학습의 정보에 기초하여, 실시간으로 촬영된 매장 영상에 대응되는 매장 상태를 인식하는 단계, 그리고상기 매장 상태의 인식 결과로부터 기 정의된 매장 상태를 판단하여 외부로출력하는 단계를 포함하는 매장 관리 방법."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에서,상기 출력하는 단계는,매장 상태 인식 결과를 기 정의된 기준값과 대응시켜 매장 상태를 판단하는 단계를 포함하는, 매장 관리 방법."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에서,상기 학습하는 단계는,학습을 위한 준비된 매장 영상과 전혀 다른 대조군의 매장 영상을 통한 딥(deep) 신경망 모델 학습을 수행하는단계, 그리고상기 학습을 통하여 후보 영역에서 매장 상태를 구분하는 특징 정보를 추출하여 매장 상태 인식을 위한 학습 정보로 추출하여 저장하는 단계를 포함하는 매장 관리 방법."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에서,상기 학습하는 단계는,학습을 위한 준비된 매장 영상을 신경망 모델을 사용한 학습이 가능한 외부의 클라우드 서버로 전달하여 매장영상에 대응되는 감정 학습을 수행시키는 단계를 포함하는 매장 관리 방법."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에서,상기 인식하는 단계는,실시간으로 촬영되는 매장 영상을 상기 클라우드 서버로 전달하여 매장 영상에 대응되는 매장 상태 인식을 요청공개특허 10-2018-0054505-4-하는 단계, 그리고상기 클라우드 서버로부터 전달되는 매장 인식 결과 수신하여 출력하는 단계를 포함하는, 매장 관리 방법."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에서,상기 신경망 모델은 합성곱 신경망(Convolutional Neural Network, CNN) 모델 모델이고,상기 합성곱 신경망 모델은,입력되는 매장 영상에 대해 사람수, 테이블 점유 유무, 의자에 사람이 앉아있는지 유무 및 테이블 위에 놓인 컵의 유무 및 컵의 개수 중 적어도 하나를 매장 상태로 인식하는, 매장 관리 방법."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "로봇 장치로서,소정의 형상을 가진 본체, 상기 본체에 장착되어 데이터를 화면에 출력하는 디스플레이 장치,상기 본체에 장착되어, 음성을 출력하는 스피커,상기 본체에 장착되어, 매장 영상을 촬영하는 카메라,상기 본체의 내부에 장착되어 프로그램을 저장하는 저장 장치, 그리고상기 프로그램을 실행하는 적어도 하나의 프로세서로 구성된 제어부를 포함하고, 상기 제어부는,매장 내 정해진 지점의 매장 영상을 촬영하여 신경망 모델을 사용하여 상기 매장 영상에 대응되는 매장 상태를학습하고, 학습 결과를 사용하여 실시간으로 촬영되는 매장 영상으로부터 매장 상태를 인식하며, 매장 상태 인식 결과로부터 기 정의된 매장 상태를 판단하고,상기 매장 상태를 판단한 결과를 자연어 처리하고 상기 자연어에 대응되는 대화 문장을 생성하여 음성으로 출력하거나, 또는, 상기 매장 상태를 판단한 결과에 기초하여 기 정의된 컨시어지 서비스 데이터를 생성하여 상기디스플레이 장치로 출력하는 명령어들(instructions)을 포함하는, 로봇 장치."}
{"patent_id": "10-2017-0157627", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에서,근거리 통신 또는 인터넷 연결을 수행하는 통신 장치를 더 포함하고,상기 제어부는,상기 매장 상태를 판단한 결과 또는 상기 컨시어지 서비스 데이터를 상기 근거리 통신 또는 인터넷망을 통해 출력하는 명령어들을 포함하는, 로봇 장치."}
{"patent_id": "10-2017-0157627", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "매장 관리 장치, 그 방법 및 로봇 장치가 제공된다. 이 장치는, 인공 지능형 매장 관리 장치로서, 매장 내 정해 진 지점의 매장 영상을 촬영하는 영상 촬영부, 상기 매장 영상을 이용한 매장 관리를 수행하는 프로그램을 저장 하는 저장부, 그리고 상기 프로그램을 실행하는 프로세서를 포함하고, 상기 프로그램은, 신경망 모델을 사용하여 매장 영상에 대응되는 매장 상태를 학습하고, 학습 결과를 사용하여 실시간으로 촬영되는 매장 영상으로부터 매 장 상태를 인식하며, 매장 상태 인식 결과로부터 기 정의된 매장 상태를 판단하여 외부로 출력하는 명령어들 (instructions)을 포함한다."}
{"patent_id": "10-2017-0157627", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 매장 관리 장치, 그 방법 및 매장 관리 로봇에 관한 것이다."}
{"patent_id": "10-2017-0157627", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간에게 서비스를 제공하는 지능형 로봇은 가정 이외에도 식당과 같은 공간에서 그 활용도가 높을 것으로 보이 며 이에 적합한 로봇의 연구가 진행되고 있는 상황이다. 로봇 산업화 시대를 맞아 레스토랑 등과 같은 서비스 제공 장소에서의 로봇의 활용에 대한 기대가 커지고 있는 시점에서 고객의 만족을 높이고 고객의 이용 성향 등에 따른 차별화된 서비스가 요구된다. 그러나, 종래에 로봇 기술은 사용자의 특정 입력에 로봇의 출력을 사전에 정의하기 때문에, 로봇의 행동이 단순 반복적으로 되풀이될 뿐이어서, 사용자와 커뮤니케이션 하는 것이 아니라 지시한 바를 출력하는 단순 작업이 이 루어지는 것에 불과하다. 따라서, 사람의 편리를 위한 서비스 로봇은 사용자의 다양한 요구에 적합하게 대응할 수 있는 지능적인 작업 수행과 사용자와의 상호작용이 필요하게 되었다."}
{"patent_id": "10-2017-0157627", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 학습된 신경망 기술을 토대로 실시간으로 촬영되는 매장 영상으로부터 매장 상태를 인식 및 판단하여 매장 관리에 이용할 수 있도록 하는 매장 관리 장치, 그 방법 및 매장 관리 로봇을 제 공하는 것이다."}
{"patent_id": "10-2017-0157627", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 한 특징에 따르면, 매장 관리 장치는 인공 지능형 매장 관리 장치로서, 매장 내 정해진 지점의 매장 영상을 촬영하는 영상 촬영부, 상기 매장 영상을 이용한 매장 관리를 수행하는 프로그램을 저장하는 저장부, 그 리고 상기 프로그램을 실행하는 프로세서를 포함하고, 상기 프로그램은, 신경망 모델을 사용하여 매장 영상에 대응되는 매장 상태를 학습하고, 학습 결과를 사용하여 실시간으로 촬영되는 매장 영상으로부터 매장 상태를 인 식하며, 매장 상태 인식 결과로부터 기 정의된 매장 상태를 판단하여 외부로 출력하는 명령어들(instructions) 을 포함한다. 상기 프로그램은, 상기 영상 촬영부가 서로 다른 복수의 각도 및 복수의 시간에 촬영하여 획득한 서로 다른 종 류의 매장 영상을, 상기 매장 영상과 전혀 다른 대조군의 매장 영상을 통한 딥(deep) 신경망 모델 학습을 통하 여 후보 영역에서 매장 상태를 구분하는 특징 정보를 추출하여 매장 상태 인식을 위한 학습 정보로 상기 저장부 에 저장하고, 상기 학습 정보에 기초하고, 상기 영상 촬영부가 실시간 촬영하는 매장 영상을 입력으로 상기 신 경망 모델을 사용하여 매장 상태를 인식하는 명령어들을 포함할 수 있다. 상기 프로그램은, 매장 상태 인식 결과를 기 정의된 기준값과 대응시켜 매장 상태를 판단하는 명령어들을 포함 할 수 있다. 상기 기준값은, 영상속 카운트된 사람수, 테이블 위에 컵이 있는지 유무 및 의자에 사람이 있는지 유무 중 적어 도 하나를 포함하여 설정되고, 상기 매장 상태는, 매장 혼잡도를 포함할 수 있다. 상기 프로그램은, 매장 영상을 신경망 모델을 사용한 학습이 가능한 외부의 클라우드 서버로 전달하여 매장 영 상에 대응되는 감정 학습을 수행시킨 후, 실시간 촬영된 매장 영상을 상기 클라우드 서버로 전달하여 상기 매장 영상에 대응되는 매장 상태 인식을 요청한 후 상기 클라우드 서버로부터 전달되는 매장 상태 인식 결과를 수신 하며, 수신한 매장 상태 인식 결과로부터 상기 매장 상태를 판단하는 명령어들을 포함할 수 있다. 상기 신경망 모델은, 합성곱 신경망(Convolutional Neural Network, CNN) 모델일 수 있다. 본 발명의 다른 특징에 따르면, 매장 관리 방법은 적어도 하나의 프로세서에 의해 동작하는 매장 관리 장치에서 수행되는 매장관리 방법으로서, 복수의 매장 영상에 대응되는 매장 상태를 신경망 모델을 사용하여 학습하는 단 계, 상기 학습의 정보에 기초하여, 실시간으로 촬영된 매장 영상에 대응되는 매장 상태를 인식하는 단계, 그리 고 상기 매장 상태의 인식 결과로부터 기 정의된 매장 상태를 판단하여 외부로출력하는 단계를 포함한다. 상기 출력하는 단계는, 매장 상태 인식 결과를 기 정의된 기준값과 대응시켜 매장 상태를 판단하는 단계를 포함 할 수 있다. 상기 학습하는 단계는, 학습을 위한 준비된 매장 영상과 전혀 다른 대조군의 매장 영상을 통한 딥(deep) 신경망 모델 학습을 수행하는 단계, 그리고 상기 학습을 통하여 후보 영역에서 매장 상태를 구분하는 특징 정보를 추출 하여 매장 상태 인식을 위한 학습 정보로 추출하여 저장하는 단계를 포함할 수 있다. 상기 학습하는 단계는, 학습을 위한 준비된 매장 영상을 신경망 모델을 사용한 학습이 가능한 외부의 클라우드 서버로 전달하여 매장 영상에 대응되는 감정 학습을 수행시키는 단계를 포함할 수 있다. 상기 인식하는 단계는, 실시간으로 촬영되는 매장 영상을 상기 클라우드 서버로 전달하여 매장 영상에 대응되는 매장 상태 인식을 요청하는 단계, 그리고 상기 클라우드 서버로부터 전달되는 매장 인식 결과 수신하여 출력하 는 단계를 포함할 수 있다. 상기 신경망 모델은 합성곱 신경망(Convolutional Neural Network, CNN) 모델 모델이고, 상기 합성곱 신경망 모델은, 입력되는 매장 영상에 대해 사람수, 테이블 점유 유무, 의자에 사람이 앉아있는지 유무 및 테이블 위에 놓인 컵의 유무 및 컵의 개수 중 적어도 하나를 매장 상태로 인식할 수 있다. 본 발명의 또 다른 특징에 따르면, 로봇 장치는 소정의 형상을 가진 본체, 상기 본체에 장착되어 데이터를 화면 에 출력하는 디스플레이 장치, 상기 본체에 장착되어, 음성을 출력하는 스피커, 상기 본체에 장착되어, 매장 영 상을 촬영하는 카메라, 상기 본체의 내부에 장착되어 프로그램을 저장하는 저장 장치, 그리고 상기 프로그램을 실행하는 적어도 하나의 프로세서로 구성된 제어부를 포함하고, 상기 제어부는, 매장 내 정해진 지점의 매장 영 상을 촬영하여 신경망 모델을 사용하여 상기 매장 영상에 대응되는 매장 상태를 학습하고, 학습 결과를 사용하 여 실시간으로 촬영되는 매장 영상으로부터 매장 상태를 인식하며, 매장 상태 인식 결과로부터 기 정의된 매장 상태를 판단하고, 상기 매장 상태를 판단한 결과를 자연어 처리하고 상기 자연어에 대응되는 대화 문장을 생성 하여 음성으로 출력하거나, 또는, 상기 매장 상태를 판단한 결과에 기초하여 기 정의된 컨시어지 서비스 데이터 를 생성하여 상기 디스플레이 장치로 출력하는 명령어들(instructions)을 포함한다. 상기 로봇 장치는 근거리 통신 또는 인터넷 연결을 수행하는 통신 장치를 더 포함하고, 상기 제어부는, 상기 매 장 상태를 판단한 결과 또는 상기 컨시어지 서비스 데이터를 상기 근거리 통신 또는 인터넷망을 통해 출력하는 명령어들을 포함할 수 있다."}
{"patent_id": "10-2017-0157627", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 학습된 신경망 기술을 토대로 매장 상태를 실시간으로 파악하여 고객에게 최적화된 맞춤형 서비스를 신속히 제공하는 AI 기반의 차별화된 지능화 서비스를 통한 경쟁력 강화와 수익구조를 개선할 수 있다."}
{"patent_id": "10-2017-0157627", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였 다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재 된 \"…부\", \"…기\", \"…모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하 드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 이제, 도면을 참조하여 본 발명의 실시예에 따른 매장 관리 장치, 그 방법 및 매장 관리 로봇에 대하여 설명한 다.도 1은 본 발명의 한 실시예에 따른 매장 관리 장치의 구성도이다. 도 1을 참조하면, 매장 관리 장치는 영상 촬영부, 매장 상태 인식부, 매장 상태 판단부, 출력부, 저장부 및 제어부를 포함한다. 영상 촬영부는 미리 지정된 지점의 매장 영상을 촬영하여 영상에 대응되는 영상 신호를 출력한다. 영상 촬 영부로는 팬 틸트 줌 기능(Pan-Tilt-Zoom, PTZ) 카메라가 사용될 수 있다. 영상 촬영부는 매장 전체를 커버할 수 있도록 카메라 화각(FoV, Field of View)을 분해하고, 분해한 카메 라 화각을 지정된 시간에 따라 조정하여 미리 지정한 위치에 대한 영상을 촬영한다. 매장 상태 인식부는 딥러닝 기술의 신경망 모델, 특히, 합성곱 신경망(Convolutional Neural Network, CNN) 모델을 이용하여 영상 촬영부에서 출력되는 영상을 학습하여 매장 상태에 대한 학습 정보를 생성할 수 있다. 이후, 매장 상태 인식부는 매장 상태에 대한 학습 정보에 기초하여, 영상 촬영부에서 출력 되는 영상을 입력으로 하여 CNN 모델을 사용하여 매장 상태를 인식할 수 있다. 예를들면, 영상 속에 이미지를 통해 사람 얼굴을 인식하여 사람수가 몇명인지 카운트하고, 테이블이 빈테이블인지 점유된 테이블인지 구분하며, 의자에 사람이 않아 있는지 아닌지를 인식할 수 있다. 매장 상태 인식부는 영상 촬영부가 다양한 각도에서 그리고 다양한 시간에 촬영하여 획득한 서로 다 른 종류의 매장 이미지와, 이러한 이미지와 전혀 다른 대조군의 이미지를 통한 딥(deep) CNN 학습을 통하여 후 보 영역에서 매장 상태를 구분하는 특징 정보를 추출해서 숫자로 표현되는 암호화를 수행하여 학습 정보로서 저 장한다. 이때, 사용되는 서로 다른 종류의 매장 이미지는, 예를 들면 매장내 테이블의 치워진 상태의 이미지와 컵들이 올려진 상태의 이미지 각각에 대해 회전에 의한 변형, 이동에 의한 변형, 이미지의 일부를 잘라내는 크 롭(crop)과 좌우반전(flip)을 통한 변형, 조명의 밝기 조정을 통해 획득한 다양한 매장 이미지들일 수 있다. 매장 상태 인식부는 영상 촬영부에서 출력된 영상에서 기 정의된 후보 영역을 검출하고, 검출한 후보 영역의 특징 정보를 계산한다. 여기서, 특징 정보는 HOG(Histogram Of Gradient), 하알 유사(Haar-like), 웨이 블릿(Wavelet) 등일 수 있고, 혹은 이러한 특징들이 복합된 것일 수 있다. 그러나, 이는 예시적인 것이며 특징 값은 이들에 한정되지 않는다. 매장 상태 인식부는 학습된 CNN 모델을 사용하여 검출한 후보 영역의 특징 정보를 분류하여, 테이블이 존 재하는지, 테이블이 비어있는지, 테이블에 사람이 있는지, 테이블에 컵이 놓여져 있는지 등의 매장 상태 인식 정보를 출력한다. 이때, 매장 상태 인식부는 공지된 객체 인식 기술을 응용하여 사용할 수 있다. 이때, 매장 상태 인식부는 출력한 매장 상태 인식 정보를 학습하여 학습 정보로 저장할 수 있다. 매장 상태 판단부는 매장 상태 인식부에서 출력되는 매장 상태 인식 정보를 기준값에 따라 구분하여 최종적으로 매장 상태 정보를 출력한다. 매장 상태 판단부는 매장 상태 인식 정보에 기초하여 영상속 카운트 된 사람수가 기 정의된 기준값 이면 혼잡으로 판단하고, 기 정의된 기준값에 해당하지 않으면, 한가함으로 판단할 수 있다. 매장 상태 판단부는 테이블 위에 컵이 있는지와, 의자에 사람이 있는지를 기준값으로 설정하고, 매장 상태 인식 정보를 기준값과 대응시켜 테이블 점유상태를 판단할 수 있다. 매장 상태 판단부는 의자 점유 상황을 기준값으로 설정하고, 매장 상태 인식 정보를 기준값과 대응시켜 빈 테이블 수를 추정할 수 있다. 출력부는 매장 상태 판단부에서 판단한 매장 상태 정보를 모니터링 시스템(미도시)에 출력한다. 또는 자체 구비한 화면에 출력할 수 있다. 저장부는 매장 관리 장치의 동작 수행을 위한 명령어(Instruction) 등을 저장할 수도 있다. 저장부는 매장 관리 장치가 동작하는데 필요한 데이터와 프로그램 등을 저장할 수 있다. 저장부는 매장 상태 인식부에서의 학습 정보, 매장 상태 인식 결과, 매장 상태 판단부의 매장 상태 판단 결과를 각각 저장할 수 있다. 이러한 저장부는 플래시 메모리 타입(Flash Memory Type), 하드 디스크 타입(Hard Disk Type), 멀티미디어 카드 마이크로 타입(Multimedia Card Micro Type), 카드 타입의 메 모리(예를 들면, SD 또는 XD 메모리 등), 자기 메모리, 자기 디스크, 광디스크, 램(Random Access Memory, RAM), SRAM(Static Random Access Memory), 롬(Read-Only Memory, ROM), PROM(Programmable Read-OnlyMemory), EEPROM(Electrically Erasable Programmable Read-Only Memory) 중 적어도 하나의 저장매체를 포함 할 수 있다. 제어부는 매장 관리 장치의 각 구성요소, 즉 영상 촬영부, 매장 상태 인식부, 매장 상태 판단부, 출력부, 저장부 간에 전달되는 신호를 처리한다. 이러한 매장 관리 장치를 사용하여 매장 상태를 학습하여 인식하고 판단하는 매장 관리 방법에 대해 설명 한다. 도 2는 본 발명의 실시예에 따른 매장 관리 방법의 흐름도이다. 도 2를 참조하면, 영상 촬영부를 통해 촬영한 매장 영상 또는 외부 장치(미도시)로부터 입력받은 매장 영 상에 대해 전술한 CNN 모델을 사용하여 매장 상태를 인식하는 학습을 수행(S101)한 후, 저장부에 저장한다 (S103). 물론 이러한 학습은 여러 번에 걸쳐서 서로 다른 종류의 다수의 매장 영상을 입력하여 수행될 것이다. 이때, 촬영한 매장 영상은 영상 촬영부가 정해진 시간에 따라 다양한 카메라 화각으로 미리 지정한 위치에 대하여 촬영한 영상일 수 있다. 이후, 영상 촬영부를 통해 매장 영상을 촬영한다(S105). 그리고 S105 단계에서 촬영된 매장 영상에 대해 S103 단계에서 저장된 학습 정보를 토대로 매장 상태를 인식한다(S107). 이때, 인식되는 매장 상태로는 테이블 점유 유무, 의자에 앉은 사람수, 테이블위에 놓인 컵의 유무, 컵의 개수 등을 포함할 수 있다. 다음, 매장 상태 판단부를 통해 매장 상태 인식 결과를 기 정의된 기준값과 비교하여 매장 상태를 판단한 다(S109). 이때, 판단되는 매장 상태로는 다양한 매장 상태를 정의하여 사용할 수 있으며, 본 발명의 실시예에 따르면, 매장 혼잡도가 될 수 있다. 다음, 출력부를 통하여 매장 상태 분류 결과를 외부로 출력한다(S111). 이때, 전술한 것처럼, 모니터링 시 스템(미도시)의 화면에 출력할 수 있다. 혹은, 매장 내 대기 고객의 단말로 메시지 서비스를 이용하여 전송할 수도 있다. 한편, 도 1 및 도 2에서는 매장 관리 장치가 직접 학습 및 인식을 수행하는 것으로 설명하였지만, 본 발명 의 기술적 범위는 여기에 한정되지 않는다. 예를 들어, 매장 영상을 사용하여 외부의 인공지능 클라우드 서버를 통한 학습과, 매장 상태 인식을 수행할 수도 있다. 최근에는 각종 자료를 사용자의 컴퓨터나 스마트폰 등 내부 저장 공간이 아닌 외부 클라우드 서버에 저장한 뒤 에 다운로드받는 서비스인 클라우드 서비스가 각광을 받고 있으며, 이러한 클라우드 서비스는 인공지능 기술을 제공하는 클라우드 서버에 의해서도 제공될 수 있다. 예를 들어, IBM사의 인공지능 기술인 왓슨(Watson)이나 구 글사의 텐서플로우(TesnorFlow) 등이 오픈 소프트웨어로서 잘 알려져 있다. 이들은 인공지능을 활용해 자연어 질문을 알아듣고, 방대한 데이터로부터 관련 있는 사항을 분석, 종합해 적절한 답변을 제공하는 기술이다. 이들 은 API(Application Programming Interface)를 통해 인공지능 기술을 사용할 수 있는 클라우드 서비스를 제공 하고 있다. 따라서, 본 발명의 다른 실시예에 따른 매장 관리 장치에서는 매장 영상을 통한 매장 상태 인식 학습과, 이러한 학습 결과에 기초한 매장 상태 인식을 매장 관리 장치에서 직접 수행하지 않고 API를 통해 접속되는 외부의 클 라우드 서버에게 영상 정보를 전달하여 이에 대응되는 매장 상태 인식 결과를 제공받아서 사용할 수 있다. 이러 한 내용에 대해 다음 실시예를 통해 설명한다. 도 3은 본 발명의 다른 실시예에 따른 매장 관리 장치가 사용되는 시스템 구조를 개략적으로 도시한 도면이다. 도 3을 참조하면, 본 발명의 다른 실시예에 따른 매장 관리 장치는 학습을 위한 매장 영상을 네트워크 를 통해 외부의 클라우드 서버로 전달하여, 매장 영상을 사용하여 인식하는 학습을 수행시킨다. 학습 후, 매장 관리 장치는 서비스 시점에 매장 영상을 촬영하여 클라우드 서버로 전달하고, 클라우 드 서버로부터 매장 상태 인식 정보를 제공받아서 이를 통해 판단한 매장 상태 정보를 외부로 표시할 수 있다. 여기서, 클라우드 서버는 IBM사의 왓슨이나 구글사의 텐서플로우와 같이 딥러닝 기술의 CNN 모델에 따른 정보 학습 및 학습 결과를 이용한 매장 상태 인식이 가능한 서버를 말한다. 또한, 외부의 클라우드 서버가 매장 영상에 대응되는 매장 상태 인식 및 매장 상태 인식을 위한 학습과, 그 학습 정보를 사용하여 매장 영상에대응되어 실시간으로 매장 상태를 인식하는 기술에 대해서는 API를 제공하여 클라우드 서버로서 동작 가능 한 클라우드 서버 고유의 기능으로 이에 대해서는 잘 알려져 있으므로 여기에서는 구체적인 설명을 생략한 다. 도 4는 도 3에 도시된 매장 관리 장치의 구성을 도시한 도면이다. 도 4를 참조하면, 매장 관리 장치는 영상 촬영부, 서버 인터페이스, 매장 상태 인식부, 매 장 상태 판단부, 표시부, 저장부 및 제어부를 포함한다. 여기서, 영상 촬영부, 매장 상태 인식부, 매장 상태 판단부, 표시부, 저장부 및 제어부는 도 1을 참조하여 설명 한 기능과 동작이 동일하므로 여기에서는 이들에 대한 구체적인 설명을 생략하고, 그 기능과 동작이 상이한 구 성요소들에 대해서만 설명한다. 서버 인터페이스는 외부의 클라우드 서버가 제공한 API를 사용하여 네트워크를 통해 클라우드 서버에 접속되어 정보의 송수신이 가능하도록 하는 기능을 수행한다. 매장 상태 인식부는 서버 인터페이스를 통하여 클라우드 서버로 매장 영상을 전달하여 매장 상 태 인식에 대한 학습을 수행시킨다. 클라우드 서버를 통한 매장 상태 인식에 대한 학습이 완료된 후, 매장 상태 인식부는 영상 촬영부 에서 출력되는 영상을 서버 인터페이스를 통해 클라우드 서버에게 전달하고, 전달된 영상에 대 응되어 클라우드 서버로부터 제공되는 매장 상태 인식 결과를 사용하여 매장 상태 인식을 수행할 수 있다. 저장부는 기본적으로는 도 1에서 설명한 매장 관리 장치의 저장부와 유사하지만, 본 발명의 다 른 실시예에서는 매장 상태 인식에 대한 학습을 수행하지 않으므로 이러한 학습 정보를 저장하지 않다. 또한, 제어부는 매장 영상에 대응되는 매장 상태 인식 및 매장 상태 인식에 대한 학습을 위한 신호 전달 제어는 수행하지 않는다. 이하, 상기한 매장 관리 장치를 사용하여 매장 상태를 인식하고 판단하는 매장 관리 방법에 대해 설명한다. 도 5는 본 발명의 다른 실시예에 따른 매장 관리 방법의 흐름도이다. 도 5를 참조하면, 영상 촬영부를 통해 촬영(S201)한 매장 영상 또는 외부 장치(미도시)로부터 입력(S201) 받은 매장 영상을 외부의 클라우드 서버로 전달(S203)하여 매장 상태 인식에 대한 학습을 수행시킨다 (S205). 물론, 이러한 학습은 여러 번에 걸쳐서 얼굴 영상을 입력하여 수행될 것이다. 이와 같이 상기한 과정을 통해, 매장 관리 장치는 매장 영상에 대응되는 매장 상태 인식을 외부의 클라우드 서버를 통해 학습 할 수 있다. 이후, 매장 영상이 촬영되면(S207), 실시간으로 촬영되는 매장 영상을 외부의 클라우드 서버로 전달하여 대응되는 매장 상태 인식을 요청한다(S209). 클라우드 서버로부터, 전달된 매장 영상에 대응되어 수행된 매장 상태 인식 결과를 수신한다(S211). 즉, 이러한 매장 상태 인식 결과가 매장 상태 인식부에서의 매장 상태 인식 결과가 된다. 다음, 도 2에서도 설명한 것처럼, 매장 상태 판단부를 통해 매장 상태 인식 결과를 기 정의된 기준값과 비 교하여 매장 상태를 판단한다(S215). 그리고 출력부를 통하여 매장 상태 분류 결과를 외부로 출력한다 (S217). 이와 같이, 본 발명의 다른 실시예에 따른 매장 관리 장치에서는 매장 영상에 대응되는 매장 상태 인식 및 매장 상태 인식에 대한 학습을 수행하는 기능을 외부의 클라우드 서버를 사용하여 수행함으로써, 매장 관 리 장치의 구성이 간단해져서 컨시어지 로봇에의 탑재가 용이해질 뿐만 아니라, 이미 검증되어 있고 매우 다양하고 많은 정보를 갖고 있는 클라우드 서버를 사용함으로써 매장 관리 장치에 대한 신뢰를 제공 할 수 있다. 한편, 전술한 매장 관리 장치(100, 200)는 컨시어지 서비스(Concierge Service)를 제공하는 로봇에 이용될 수 있다. 여기서, 컨시어지 서비스는 고객의 편의를 위해 고객의 요구를 판단하고 이행하는 비서와 같은 서비스로 서, 고객과 대면하는 일종의 관문 서비스이다. 이러한 컨시어지 서비스는 예를들면, 레스토랑, 커피전문점, 패 스트푸드점, 호텔, 매장 등에서 제공될 수 있다. 도 6은 본 발명의 또 다른 실시예에 따른 매장 관리 로봇 장치의 개략적인 구성도이다. 도 6에서는 설명의 편의 상 본 발명의 특징과 관련 없는 로봇 장치의 일반적인 구성 및 그 동작에 대한 설명은 생략하였다. 도 6을 참조하면, 본 발명의 또 다른 실시예에 따른 로봇 장치는 매장 관리 장치, 음성 대화 장치 , 컨시어지 서비스 처리 장치, 저장부 및 제어부를 포함한다. 매장 관리 장치는 매장 영상을 토대로 매장 상태를 인식하고, 매장 상태를 판단한다. 이러한 매장 관리 장 치는 도 1 ~ 도 5에서 설명한 내용과 동일하다. 음성 대화 장치는 외부의 사람 등으로부터 입력되는 음성 입력을 받아서 그에 대응되는 음성 대화를 위한 음성을 출력한다. 그리고 매장 관리 장치가 출력하는 매장 상태 정보를 자연어 처리하고, 자연어에 대응되 는 대화 문장을 생성하여 음성으로 출력할 수 있다. 이때, 대화 문장은 다양한 방식, 예를 들어, 인공지능 방식 등을 사용하여 생성할 수 있으며, 이러한 방식은 로봇 장치의 동작 방식에 따라 다양하게 구성될 수 있으 며, 그 구체적인 구성은 본 실시예에서의 특징과는 관련이 없으므로 여기에서는 구체적인 설명을 생략한다. 컨시어지 서비스 처리 장치는 매장 관리 장치에서 출력되는 매장 상태 판단 결과를 토대로 대응하는 컨시어지 서비스를 제공한다. 한 실시예에 따르면, 매장 상태 판단 결과와, 매장 상태 판단 결과에 따른 대기 시간을 피지컬 웹 유알엘(URL)로 구성하여 매장 내 브로드캐스팅할 수 있다. 그러면, 피지컬 웹 유알엘(URL)을 스캔한 사용자 단말(미도시)은 매장 상태 및 대기 시간을 안내받을 수 있다. 이러한 방식은 로봇 장치의 컨시어지 서비스 시나리오에 따라 다양하게 구성될 수 있으며, 그 구체적인 구성은 본 실시예에서의 특징과는 관련이 없으므로 여기에서는 구체적인 설명을 생략한다. 저장부는 로봇 장치의 동작 수행을 위한 명령어(Instruction), 동작하는데 필요한 데이터와 프로그램 등을 저장할 수 있다. 제어부는 로봇 장치의 각 구성요소, 즉 매장 관리 장치, 음성 대화 장치, 컨시어지 서비스 처리 장치, 저장부 간에 전달되는 신호를 처리한다. 이와 같은, 로봇 장치는 도 7과 같이 구현될 수 있다. 도 7은 본 발명의 또 다른 실시예에 따른 로봇 장치 의 사시도이다. 도 7을 참조하면, 로봇 장치는 사람과 유사하게 머리와 몸통을 지닌 로봇 형상을 가지는 본체의 머리 부분에 마이크가 장착되고, 본체의 얼굴 부분에 매장 영상을 촬영하기 위한 PTZ 카메라가 장착 될 수 있다. 본체의 몸통 전면에는 매장 상태 판단 결과, 매장 상태 판단 결과에 따른 컨시어지 서비스 데이터 등을 출 력하기 위한 모니터 화면을 구비하는 디스플레이 장치가 장착된다. 본체의 몸통을 둘러싸인 부분에 매장 상태 판단 결과, 매장 상태 판단 결과에 따른 컨시어지 서비스 데이터 등에 대응되는 대화 문장을 음성으 로 출력하기 위한 스피커가 장착될 수 있다. 이때, 본체의 내부에는 전술한 매장 관리 장치(100, 200)가 포함된다. 한편, 도 8은 본 발명의 또 다른 실시예에 따른 매장 관리 장치 또는 로봇 장치의 하드웨어 구성을 나타낸 블록 도이다. 도 8을 참조하면, 매장 관리 장치 또는 로봇 장치는 근거리 통신 또는 인터넷 연결을 수행하는 통신 장치 와, 마이크, 카메라, 외부 장치와 연결되어 데이터를 송수신하는 입출력 포트 등으로 구성된 입력 장치 와, 화면에 데이터를 시각적으로 표시하는 디스플레이부, 음성을 출력하는 스피커 등으로 구성된 출력 장 치와, 저장 장치 및 프로세서 등을 포함하는 하드웨어로 구성되고, 지정된 장소에 하드웨어와 결합되어 실행되는 프로그램이 저장된다. 하드웨어는 도 1 내지 도 7에서 설명한 실시예들에 따른 구성 및/또는 방법을 실행할 수 있는 구성과 성능을 가진다. 프로그램은 도 1 내지 도 8에서 설명한 실시예들에 따른 구성 및 /또는 방법을 실행할 수 있는 명령어들(instructions)을 포함하고, 저장 장치 및 프로세서 등의 하드 웨어와 결합하여 본 발명을 구현한다. 이상에서 설명한 본 발명의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 발명의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2017-0157627", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 한 실시예에 따른 매장 관리 장치의 구성도이다. 도 2는 본 발명의 실시예에 따른 매장 관리 방법의 흐름도이다. 도 3은 본 발명의 다른 실시예에 따른 매장 관리 장치가 사용되는 시스템 구조를 개략적으로 도시한 도면이다. 도 4는 도 3에 도시된 매장 관리 장치의 구성을 도시한 도면이다. 도 5는 본 발명의 다른 실시예에 따른 매장 관리 방법의 흐름도이다. 도 6은 본 발명의 또 다른 실시예에 따른 로봇 장치의 개략적인 구성도이다. 도 7은 본 발명의 또 다른 실시예에 따른 로봇 장치의 사시도이다. 도 8은 본 발명의 또 다른 실시예에 따른 매장 관리 장치의 하드웨어 구성을 나타낸 블록도이다."}
