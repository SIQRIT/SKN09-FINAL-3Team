{"patent_id": "10-2020-7030695", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0136961", "출원번호": "10-2020-7030695", "발명의 명칭": "관심 대상에 대한 이미지 검색을 촉진하기 위해 사용자와 상호 작용하는 방법 및 시스템", "출원인": "아비질론 코포레이션", "발명자": "앨칸타라 튤리오 데 소우자"}}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "트레이닝 이미지가 트레이닝 이미지에 공통된 패싯 타입을 묘사하는, 그와 같은 트레이닝 이미지를 포함하는 패싯 이미지 트레이닝 세트를 생성하고, 이때 상기 트레이닝 이미지는 트레이닝 이미지에 공통된 객체타입과 협력하여 패싯 타입을 묘사하도록 하는 단계; 패싯 이미지 트레이닝 세트를 사용하여, 패싯 타입을 포함하는 샘플 이미지가 인공 신경 네트워크에 입력될 때패싯 타입을 분류하기 위해 상기 인공 신경 네트워크를 트레이닝하는 단계; 상기 인공 신경 네트워크를 사용하여 동일한 이미지를 분류함으로써 상기 샘플 이미지가 패싯 타입을 묘사하는가를 분석하는 단계; 그리고 상기 샘플 이미지가 분류된 이후에, 상기 패싯 타입에 대한 샘플 이미지를 검색하는 단계를 포함하는, 패싯 검색을 수행하는 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 인공 신경 네트워크가 컨볼루션 신경 네트워크를 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항 또는 제 2 항에 있어서, 상기 인공 신경 네트워크를 트레이닝 시키는 단계는 상기 트레이닝 중에 인공신경 네트워크의 서로 다른 상태에 대응하는 인공 신경 네트워크의 상태 데이터를 기록하는 단계를 포함하는,방법"}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 상태 데이터는 인덱스되어서, 패싯의 타입, 트레이닝을 수행하는 사용자의 식별 자격증명, 트레이닝 이미지, 트레이닝 이미지를 캡처하는 데 사용되는 카메라, 트레이닝 이미지의 타임 스탬프 및트레이닝이 시작된 시간 중 적어도 하나를 포함하는 데이터를 인덱스하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항 또는 4항에 있어서, 인공 신경 네트워크의 초기 상태에 해당하는 인덱스 데이터를 수신하는 단계; 그리고 이전 상태에 해당하는 인덱스 데이터로 인덱스된 상태 데이터를 적재함에 의해 인공 신경 네트워크의 이전상태로 되돌리는 단계를 더욱 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 3 항 내지 제 5 항 중 어느 한 항에 있어서, 상기 인공 신경 네트워크는 서로 다른 사용자에 의해 트레이닝되고, 상기 인공 신경 네트워크의 서로 다른 상태는 서로 다른 사용자에 각각 대응하는 사용자 상태를포함하고, 상기 검색은 사용자 상태 중 둘 이상을 사용하여 수행되는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 상기 둘 이상의 사용자 상태를 사용하여 수행된 검색이 상기 둘 이상의 사용자 상태에 각각대응하는 중간 검색 결과를 발생시키고, 중간 검색 결과에서 발생하는 빈도에 기초하여 중간 검색 결과에서의 서로 다른 이미지에 가중치를 부여하는 단계; 그리고상기 가중치에 기초하여 상이한 이미지를 포함하는 최종 검색 결과를 결정하는 단계를 더욱 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2020-0136961-3-제 1 항 내지 제 7 항 중 어느 한 항에 있어서, 상기 패싯 타입은 연령, 성별, 의복 타입, 의복 컬러, 의복에표시된 패턴, 헤어 컬러, 신발 컬러 또는 의복 액세서리를 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항 내지 제 7 항 중 어느 한 항에 있어서, 상기 패싯의 타입이 컬러, 제조사, 모델 또는 구성을 포함하는,방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항 내지 제 9 항 중 어느 한 항에 있어서, 상기 트레이닝 이미지 중 적어도 하나는 카메라에 의해 캡처된이미지로부터 유도된 이미지 칩을 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항 내지 제 10 항 중 어느 한 항에 있어서, 샘플 이미지가 패싯 타입을 묘사하는지 여부를 평가하기 위해인공 신경 네트워크를 사용하여 샘플 이미지를 분류하는 단계는 샘플 이미지가 패싯 타입을 묘사하는지 여부를나타내는 메타 데이터를 생성하고 저장하는 단계를 포함하고, 패싯 타입에 대한 샘플 이미지 검색은 상기 메타데이터를 사용하여 수행되는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1 항 내지 제 11 항 중 어느 한 항에 있어서,패싯 검색이 시작될 것임을 나타내는 패싯 검색 시작 사용자 입력을 수신하는 단계-상기 검색은 상기 패싯 검색 시작 사용자 입력을 수신함에 응답하여 수행됨-; 그리고 패싯을 묘사하는 패싯 이미지 검색 결과를 디스플레이에서 표시하는 단계 -패싯 이미지 검색 결과는 하나 이상의 비디오 기록으로부터 선택되며, 상기 이미지 검색 결과가 상기 이미지 검색 결과에 공통인 객체타입과 함께 패싯을 묘사함-,를 더욱 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "패싯 검색이 시작될 것임을 나타내는 패싯 검색 시작 사용자 입력을 수신하는 단계; 패싯 검색 시작 사용자 입력에 응답하여, 패싯에 대한 하나 이상의 비디오 기록을 검색하는 단계; 그리고 패싯을 묘사하는 패싯 이미지 검색 결과를 디스플레이에 표시하는 단계 - 상기 패싯 이미지 검색 결과는 하나이상의 비디오 기록으로부터 선택되며, 상기 이미지 검색 결과는 이미지 검색 결과에 공통인 관심 대상타입과함께 패싯을 묘사함-,을 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서, 상기 패싯 이미지 검색 결과를 디스플레이 한 후, 관심 대상에 대한 검색이 시작될 것이라는 것을 나타내는 관심 대상 검색 시작 사용자 입력을 수신하는 단계;관심 대상 검색 시작 사용자 입력에 응답하여, 관심 대상에 대한 하나 이상의 비디오 레코딩을 검색하는 단계;관심 대상을 묘사하는 관심 대상 검색 결과를 디스플레이에 표시하는 단계를 더욱 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서, 검색되는 하나 이상의 비디오 레코딩은 패싯 이미지 검색 결과가 선택되는 하나 이상의 비디오 레코딩이고, 상기 관심 대상 검색 결과는 하나 이상의 비디오 레코딩으로부터 선택되며, 이와 같은 비디오레코딩으로부터 패싯 이미지 검색 결과가 선택되고 관심 대상 검색 결과가 관심 대상및 패싯을 나타내는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항 또는 제 15 항에 있어서, 상기 관심 대상 검색 결과를 디스플레이 한 후, 업데이트 된 패싯 검색이 시작될 것임을 나타내는 업데이트 된 패싯 검색 시작 사용자 입력을 수신하는 단계; 업데이트 된 패싯 검색 시작 사용자 입력에 응답하여, 하나 이상의 비디오 레코딩을 검색하는 단계 - 상기 하나이상의 비디오 레코딩으로부터 패싯 검색에서 검색된 것과 상이한 타입 또는 수의 패싯에 대한 관심 대상 검색공개특허 10-2020-0136961-4-결과가 선택됨-; 그리고 ;상이한 타입 또는 수의 패싯 및 관심 대상을 묘사하는 업데이트 된 패싯 검색 결과를 디스플레이상에 표시하는단계 - 상기 업데이트 된 패싯 검색 결과는 하나 이상의 비디오 레코딩으로부터 선택되며, 상기 하나 이상의 비디오 레코딩으로부터 관심 대상 검색 결과가 선택됨- 를 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 13 항에 있어서, 상기 패싯 이미지 검색 결과를 표시하기 전에, 관심 대상에 대한 검색이 시작될 것이라는것을 나타내는 관심 대상 검색 시작 사용자 입력을 수신하는 단계; 관심 대상 검색 시작 사용자 입력에 응답하여, 관심 대상에 대한 하나 이상의 비디오 레코딩을 검색하는 단계;디스플레이 상에, 관심 대상을 묘사하는 관심 대상 검색 결과를 표시하는 단계-여기서 관심 대상 검색 결과는하나 이상의 비디오 레코딩으로부터 선택되며, 상기 패싯 검색 시작 사용자 입력은 관심 대상 검색 결과가 표시된 후에 수신되고, 패싯에 대해 검색되는 하나 이상의 비디오 레코딩은 상기 관심 대상 검색 결과가 하나 이상의 비디오 레코딩으로부터 선택됨-를 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서, 패싯 검색 시작 사용자 입력을 수신하기 전에, 관심 대상 검색 결과에 나타나는 패싯 목록을 표시하는 단계; 그리고 패싯 검색 시작 사용자 입력으로서 패싯 목록을 포함하는 패싯의 선택을 수신하는 단계를 더욱 포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 13 항 내지 제 18 항 중 어느 한 항에 있어서, 상기 패싯 검색 시작 사용자 입력은 자연 언어 텍스트 질의를포함하는, 방법."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "디스플레이; 입력 장치; 디스플레이 및 입력 장치에 통신 가능하게 결합된 프로세서;상기 프로세서에 통신 가능하게 결합되는 메모리로서, 그와 같은 프로세서에 의해 실행 가능한 컴퓨터 프로그램코드를 저장한 메모리를 포함하며, 상기 컴퓨터 프로그램 코드가 상기 프로세서에 의해 실행될 때 프로세서가제 1 항 내지 제 19 항 중 어느 한 항의 방법을 수행 하게하는, 시스템."}
{"patent_id": "10-2020-7030695", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "프로세서에 의해 실행될 수 있고 프로세서에 의해 실행될 때 프로세서로 하여금 제 1 항 내지 제 19 항 중 어느한 항의 방법을 수행하게 하는 컴퓨터 프로그램 코드를 저장한 비 일시적 컴퓨터 판독 가능 기록매체."}
{"patent_id": "10-2020-7030695", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "패싯 검색을 수행하는 방법, 시스템 및 기술이 패싯 검색이 시작될 것임을 나타내는 패싯 검색 시작 사용자 입력 을 수신하는 단계; 패싯 검색 시작 사용자 입력에 응답하여, 패싯에 대한 하나 이상의 비디오 레코딩을 검색하는 단계; 및 디스플레이 상에, 패싯을 묘사하는 패싯 이미지 검색 결과를 디스플레이하는 단계를 포함하며, 패싯 이 미지 검색 결과는 하나 이상의 비디오 기록으로부터 선택된다. 인공 신경 네트워크가 패싯 검색을 위해 사용될 수 있고, 그와 같은 네트워크는, 트레이닝 이미지가 트레이닝 이미지에 공통된 패싯 타입을 묘사하는, 그와 같은 트레이닝 이미지를 포함하는 패싯 이미지 트레이닝 세트를 생성함으로써; 그리고 패싯 이미지 트레이닝 세트를 사용하여, 패싯 타입을 포함하는 샘플 이미지가 상기 네트워크에 입력될 때 패싯 타입을 분류하기 위해 해당 신 경 네트워크를 트레이닝 시킴으로써, 트레이닝될 수 있다."}
{"patent_id": "10-2020-7030695", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "35 U.S.C. §119(e)에 입각하여, 본 출원은 미국 가 특허 출원 번호. 62/647,305, \"관심 대상에 대한 이미지 검 색을 용이하게 하기 위해 사용자와의 인터페이스를 위한 방법 및 시스템\"이라는 제목으로 2018 년 3 월 23 일에 출원되었으며, 그 전체가 본 명세서에서 참조로 포함된다. 본 명세서 개시 내용은 관심 대상에 대한 이미지 검색을 용이하게 하기 위해 사용자와 인터페이싱 하는 방법, 시스템 및 기술에 관한 것이다."}
{"patent_id": "10-2020-7030695", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "레코딩된 비디오의 지능형 처리 및 재생은 종종 비디오 감시 시스템에 포함되는 중요한 기능이다. 예를 들어, 비디오 감시 시스템은 각각 비디오를 레코딩하는 많은 카메라를 포함할 수 있다. 이러한 카메라로 레코딩된 총비디오 양(대부분이 일반적으로 동시에 레코딩됨)은 레코딩된 비디오에 나타나는 관심 대상의 수동 위치 및 추 적에 의존하는 것을 비효율적으로 만든다. 이에 따라 비디오 감시 시스템을 사용하여 관심 대상을 식별할 수 있 는 효율성을 높이기 위해 비디오의 지능적인 처리 및 재생, 특히 자동 검색 기능을 사용할 수 있다."}
{"patent_id": "10-2020-7030695", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 한 특징에 따라, 트레이닝 이미지가 트레이닝 이미지에 공통된 패싯 타입을 묘사하는, 그와 같은 트 레이닝 이미지를 포함하는 패싯 이미지 트레이닝 세트를 생성하는 단계; 패싯 이미지 트레이닝 세트를 사용하여, 패싯 타입을 포함하는 샘플 이미지가 인공 신경 네트워크에 입력될 때 패싯 타입을 분류하기 위해 상 기 인공 신경 네트워크를 트레이닝하는 단계; 상기 인공 신경 네트워크를 사용하여 동일한 이미지를 분류함으 로써 상기 샘플 이미지가 패싯 타입을 묘사하는가를 분석하는 단계; 그리고 상기 샘플 이미지가 분류된 이후에, 상기 패싯 타입에 대한 샘플 이미지를 검색하는 단계를 포함하는, 방법이 제공된다. . 상기 인공 신경 네트워크는 컨볼루션 신경 네트워크를 포함할 수 있다. 상기 인공 신경 네트워크를 트레이닝시키는 것은 트레이닝 중에 인공 신경 네트워크의 상이한 상태에 대응하는 인공 신경 네트워크의 상태 데이터를 기록하는 것을 포함할 수 있다. 상기 상태 데이터는 인덱스되어서, 패싯의 타입, 트레이닝을 수행하는 사용자의 식별 자격 증명, 트레이닝 이미 지, 트레이닝 이미지를 캡처하는 데 사용되는 카메라, 트레이닝 이미지의 타임 스탬프 및 트레이닝이 시작된 시 간 중 적어도 하나를 포함하는 데이터를 인덱스하도록 한다. , 상기 방법은 인공 신경 네트워크의 초기 상태에 해당하는 인덱스 데이터를 수신하는 단계; 그리고 이전 상태에 해당하는 인덱스 데이터로 인덱스된 상태 데이터를 적재함에 의해 인공 신경 네트워크의 이전 상태로 되돌리 는 단계를 더욱 포함한다. 상기 인공 신경 네트워크는 서로 다른 사용자에 의해 트레이닝 될 수 있고, 상기 인공 신경 네트워크의 서로 다 른 상태는 서로 다른 사용자에 각각 대응하는 사용자 상태를 포함하고, 그리고 상기 검색은 사용자 상태 중 둘 이상을 사용하여 수행될 수 있다. 상기 검색이 상기 둘 이상의 사용자 상태를 사용하여 수행될 수 있으며, 상기 검색이 상기 둘 이상의 사용자 상 태에 각각 대응하는 중간 검색 결과를 발생시키고, 그리고 상기 방법이 중간 검색 결과에서 발생하는 빈도에 기 초하여 중간 검색 결과에서의 서로 다른 이미지에 가중치를 부여하는 단계; 그리고 상기 가중치에 기초하여 상이한 이미지를 포함하는 최종 검색 결과를 결정하는 단계를 더욱 포함할 수 있다. 상기 관심 대상은 사람 일 수 있으며, 상기 패싯 타입은 연령, 성별, 의복 타입, 의복 컬러, 의복에 표시된 패 턴, 헤어 컬러, 신발 컬러 또는 의복 액세서리를 포함할 수 있다. 추가적으로 또는 대안적으로, 상기 관심 대상은 차량일 수 있으며, 패싯 타입은 컬러, 제조업체, 모델 또는 구 성을 포함할 수 있다. 상기 트레이닝 이미지 중 적어도 하나는 카메라에 의해 캡처된 이미지로부터 유도된 이미지 칩을 포함할 수 있 다. 샘플 이미지가 패싯 타입을 묘사하는지 여부를 평가하기 위해 인공 신경 네트워크를 사용하여 샘플 이미지를 분 류하는 단계는 샘플 이미지가 패싯 타입을 묘사하는지 여부를 나타내는 메타 데이터를 생성하고 저장하는 단계 를 포함하고, 패싯 타입에 대한 샘플 이미지 검색은 상기 메타 데이터를 사용하여 수행될 수 있다. 상기 방법은 패싯 검색이 시작될 것임을 나타내는 패싯 검색 시작 사용자 입력을 수신하는 단계를 더욱 포함하 고, 상기 검색은 상기 패싯 검색 시작 사용자 입력을 수신함에 응답하여 수행되며, 그리고 패싯을 묘사하는 패 싯 이미지 검색 결과를 디스플레이에 표시하는 단계를 더욱 포함하며, 상기 패싯 이미지 검색 결과는 하나 이상 의 비디오 기록으로부터 선택되며, 상기 이미지 검색 결과는 이미지 검색 결과에 공통인 관심 대상타입과 함께패싯을 묘사한다. 본 발명의 또 다른 특징에 따라, 패싯 검색 시작 사용 입력에 응답하여, 패싯에 대한 검색이 시작할 것임을 나 타내는 패싯 검색 시작 사용자 입력을 수신하는 단계; 상기 패싯에 대한 하나 이상의 비디오 레코딩을 검색하는 단계; 그리고 디스플레이에서 상기 패싯을 묘사하는 패싯 이미지 검색 결과를 디스플레이하는 단계를 포함하며, 상기 패싯 이미지 검색 결과는 하나 이상의 비디오 레코딩으로부터 선택되는 방법이 제공된다. 상기 방법은 패싯 이미지 검색 결과를 디스플레이 한 후: 관심 대상에 대한 검색이 시작될 것이라는 것을 나타 내는 관심 대상 검색 시작 사용자 입력을 수신하는 단계; 관심 대상 검색 시작 사용자 입력에 응답하여, 관심 대상에 대한 하나 이상의 비디오 레코딩을 검색하는 단계; 그리고 관심 대상을 묘사하는 관심 대상 검색 결과를 디스플레이에 표시하는 단계를 더욱 포함한다. . 검색되는 하나 이상의 비디오 레코딩은 패싯 이미지 검색 결과가 선택되는 하나 이상의 비디오 레코딩이고, 상 기 관심 대상 검색 결과는 하나 이상의 비디오 레코딩으로부터 선택되며, 이와 같은 비디오 레코딩으로부터 패 싯 이미지 검색 결과가 선택되고 관심 대상 검색 결과가 관심 대상 및 패싯을 나타낼 수 있다. 상기 방법은 상기 관심 대상 검색 결과를 디스플레이 한 후, 업데이트 된 패싯 검색이 시작될 것임을 나타내는 업데이트 된 패싯 검색 시작 사용자 입력을 수신하는 단계; 업데이트 된 패싯 검색 시작 사용자 입력에 응답하 여, 하나 이상의 비디오 레코딩을 검색하는 단계 - 상기 하나 이상의 비디오 레코딩으로부터 패싯 검색에서 검 색된 것과 상이한 타입 또는 수의 패싯에 대한 관심 대상 검색 결과가 선택됨-; 그리고 상이한 타입 또는 수의 패싯 및 관심 대상을 묘사하는 업데이트 된 패싯 검색 결과를 디스플레이상에 표시하는 단계 - 상기 업데이트 된 패싯 검색 결과는 하나 이상의 비디오 레코딩으로부터 선택되며, 상기 하나 이상의 비디오 레코딩으로부터 관심 대상 검색 결과가 선택됨-을 포함한다. 상기 방법은 패싯 이미지 검색 결과를 디스플레이하기 전에: 관심 대상에 대한 검색이 시작될 것임을 나타내는 관심 대상 검색 시작 사용자 입력을 수신하는 단계; 관심 대상 검색 시작 사용자 입력에 응답하여, 관심 대상에 대한 하나 이상의 비디오 레코딩을 검색하는 단계; 및 디스플레이 상에, 관심 대상을 묘사하는 관심 대상 검색 결과를 디스플레이하는 단계를 포함하고, 상기 관심 대상 검색 결과는 하나 이상의 비디오 레코딩으로부터 선택 되며, 패싯 검색 시작 사용자 입력이 관심 대상 검색 결과가 디스플레이 된 후 수신되며, 그리고 패싯에 대하여 검색된 하나 이상의 비디오 레코딩은 관심 대상 검색 결과가 선택된 하나 이상의 비디오 레코딩으로 구성된다. 상기 방법은 패싯 검색 시작 사용자 입력을 수신하기 전에, 관심 대상 검색 결과에 나타나는 패싯 목록을 디스 플레이하는 단계; 및 패싯 검색 시작 사용자 입력으로서 패싯 목록을 포함하는 패싯의 선택을 수신하는 단계를 더욱 포함한다. 상기 패싯 검색 시작 사용자 입력은 자연 언어 텍스트 쿼리를 포함할 수 있다. 또 다른 특징에 따르면, 위에서 설명된 특징들 중 임의의 적절한 것에 따라 설명된 바와 같이 패싯 이미지 트레 이닝 세트를 사용하여 인공 신경 네트워크가 트레이닝 되며, 트레이닝 된 네트워크가 사용되어 상기 기술한 툭 징들 중 임의의 적절한 것에 따라 설명된 패싯 검색을 수행하는 방법이 제공된다. 본 발명의 또 다른 특징에 따라, 디스플레이; 입력 장치; 디스플레이 및 입력 장치에 통신 가능하게 결합된 프 로세서; 상기 프로세서에 통신 가능하게 결합되는 메모리로서, 그와 같은 프로세서에 의해 실행 가능한 컴퓨터 프로그램 코드를 저장한 메모리를 포함하며, 상기 컴퓨터 프로그램 코드가 상기 프로세서에 의해 실행될 때, 상 기 프로세서가 본 발명의 적절한 조합의 특징을 갖는 방법을 수행할 수 있도록 한다. 본 발명의 또 다른 특징에 따르면, 프로세서에 의해 실행될 수 있고 프로세서에 의해 실행될 때 프로세서가 상 기 특징 중 임의의 하나 또는 이들의 적절한 조합을 수행하도록 하는 컴퓨터 프로그램 코드가 저장된 비 일시적 컴퓨터 판독 가능 매체가 제공된다."}
{"patent_id": "10-2020-7030695", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 요약은 반드시 모든 특징의 전체 범위를 설명하는 것은 아니다. 다른 측면, 특징 및 장점은 특정 실시 예에 대한 다음 설명을 검토하면 당업자에게 명백 할 것이다."}
{"patent_id": "10-2020-7030695", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 한 요소가 다른 요소와 \"연결된\", \"통신 하는\"또는 \"결합된\"것으로 언급 될 때, 다른 요소와 직 접 연결되거나 다른 요소 또는 중간 요소와 통신하거나 또는 직접 연결될 수 있음을 이해할 수 있을 것이다. 이 와 달리, 한 요소가 다른 요소에 \"직접 연결\", \"직접 통신 중\" 또는 \"직접 연결\"되는 것으로 언급 될 때, 개입 요소가 존재하지 않는다. 요소들 간의 관계를 설명하는 데 사용되는 다른 단어는 유사한 방식으로 해석되어야 한다.(예들 들면, \"사이\"와 \"직접 사이\", \"인접\" 대 \"직접 인접\"등). 당업자에 의해 이해되는 바와 같이, 본원 명세서에서 설명된 다양한 예시적인 실시 예는 방법, 시스템, 또는 컴 퓨터 프로그램 제품으로서 구현될 수 있다. 따라서, 다양한 예시적인 실시 예는 예를 들어 전체적으로 소프트웨 어 실시 예(펌웨어, 레지던트 소프트웨어, 마이크로 코드 등을 포함)의 형태를 취할 수 있거나, 다른 예로서, 모두 일반적으로 할 수 있는 소프트웨어 및 하드웨어 측면을 결합한 실시 예의 형태를 취할 수 있다. 본 명세서 에서는 \"모듈\" 또는 \"시스템\"이라고 한다. 더욱이, 다양한 예시적인 실시 예들은 매체에서 구현된 컴퓨터 이용 가능 프로그램 코드를 갖는 컴퓨터 이용 가능 저장 매체상의 컴퓨터 프로그램 제품의 형태를 취할 수 있다. 임의의 적절한 컴퓨터 사용 가능 또는 컴퓨터 판독 가능 매체가 이용될 수 있다. 컴퓨터 사용 가능 또는 컴퓨터 판독 가능 매체는 예를 들어 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치, 디바이스 또는 전파 매체일 수 있지만 이에 제한되지는 않는다. 이 문서의 맥락에서, 컴퓨터 사용 가능 또는 컴퓨터 판독 가능 매체 는 명령 실행 시스템, 장치 또는 디바이스에 의해 또는 이와 관련하여 사용하기 위해 프로그램을 포함, 저장, 통신, 전파 또는 전송할 수 있는 임의의 매체 일 수 있다. 다양한 실시 예의 동작을 수행하기 위한 컴퓨터 프로그램 코드는 자바, 스몰 토크, C ++ 등과 같은 객체지향 프 로그래밍 언어로 작성 될 수 있다. 그러나, 다양한 예시적인 실시 예의 동작을 수행하기 위한 컴퓨터 프로그램 코드는 또한 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 종래의 절차적 프로그래밍 언어로 작성 될 수 있다. 선택된 실제 프로그래밍 언어는 설계 선택의 문제이며, 당업자에 의해 이해되는 바와 같이, 임의의 적절한 프로그래밍 언어가 사용될 수 있다. 다양한 예시적인 실시 예가 다양한 실시 예에 따른 방법, 장치(시스템) 및 컴퓨터 프로그램 제품의 흐름도 예시 (들) 및/또는 블록도를 참조하여 아래에서 설명된다. 당업자는 흐름도 예시(들) 및/또는 블록 다이어그램의 다 양한 블록, 및 흐름도 예시(들) 및/또는 블록 다이어그램의 블록 조합이 컴퓨터 프로그램 명령에 의해 구현될 수 있음을 이해할 것이다. 이러한 컴퓨터 프로그램 명령은 범용 컴퓨터, 특수 목적 컴퓨터 또는 기타 프로그래 밍 가능한 데이터 처리 장치의 프로세서에 제공되어 컴퓨터 또는 기타 프로그램 가능한 데이터 처리 장치의 프 로세서를 통해 실행되는 명령과 같이 기계를 생성할 수 있다. 흐름도 및/또는 블록 다이어그램 블록 또는 블록 에 지정된 기능/동작을 구현하기 위한 수단을 생성한다. 이러한 컴퓨터 프로그램 명령어는 또한 컴퓨터 또는 다른 프로그램 가능한 데이터 처리 장치가 특정 방식으로 기능하도록 지시할 수 있는 컴퓨터 판독 가능 메모리에 저장될 수 있으며, 컴퓨터 판독 가능 메모리에 저장된 명령어가 순서도 및/또는 블록 다이어그램 블록 또는 블록에 지정된 기능/동작을 구현하는 명령을 포함하는 제 조 아티클을 생성한다. 본 발명 개시는 다양한 예시적인 실시 예를 설명한다. 본 명세서에서 설명된 임의의 예시적인 실시 예의 임의의 부분은 본 명세서에서 설명된 임의의 다른 예시적인 실시 형태의 임의의 부분으로 구현되거나 그와 같은 부분과 결합될 수 있다. 도 1은 예시적인 실시 예에 따른 방법이 수행 될 수 있는 예시적인 감시 시스템의 블록도를 도시한다. 예 시 된 감시 시스템 내에는 하나 이상의 컴퓨터 단말기 및 서버 시스템이 포함된다. 일부 예시적 인 실시 예에서, 컴퓨터 단말기는 개인용 컴퓨터 시스템이고; 그러나 다른 예시적인 실시 예에서 컴퓨터 단말기는 다음 중 선택된 하나 이상이다: 예를 들어, 태블릿, 패블릿, 스마트 폰 또는 PDA와 같은 핸드 헬 드 장치; 노트북 컴퓨터; 스마트 텔레비전; 및 기타 적절한 장치. 서버 시스템과 관련하여, 이것은 단일 물리적 기계 또는 다중 물리적 기계를 포함할 수 있다. 서버 시스템이 단일 섀시 내에 포함될 필요는 없고, 서버 시스템을 위한 단일 위치가 반드시 존재할 필요는 없다는 것을 이해할 것이다. 당업자에 의해 이해되는 바와 같이, 적어도 서버 시스템의 일부 기능은 서버 시스템 내에서가 아니라 컴퓨터 단말기 내에서 구현 될 수 있다 컴퓨터 단말기는 하나 이상의 네트워크를 통해 서버 시스템과 통신한다. 이러한 네트워크는 인터넷, 또는 네트워크 스위치 또는 기타 통신 요소에 의해 함께 결합된 하나 이상의 기타 공용/사설 네트워크를 포함할 수 있다. 네트워크(들)는 예를 들어 클라이언트-서버 네트워크, 피어-투-피어 네트워크 등의 형태 일 수 있다. 컴퓨터 터미널과 서버 시스템 사이의 데이터 연결은, 전화접속 직렬회선 인터페이스 프로토콜/지점 간 프로토콜(SLIP/PPP), 통합 서비스 디지털 네트워크(ISDN), 전용 임대회선 서비스, 광 대역(예를 들면: 케이 블) 액세스, 디지털 가입자 회선(DSL), 비동기 전송 모드(ATM), 프레임 릴레이 또는 기타 알려진 액세스 기술 (예를 들면: 무선 주파수(RF) 링크) 와 같은 데이터 통신 네트워크에 액세스하기 위한 임의의 수의 알려진 장치 일 수 있다. 적어도 하나의 예시적인 실시 예에서, 컴퓨터 단말 및 서버 시스템은 동일한 근거리 통 신망 (LAN) 내에 있다. 컴퓨터 단말기는 컴퓨터 단말기의 전체 동작을 제어하는 적어도 하나의 프로세서를 포함한다. 프로세 서는 예를 들어 입력 장치(예를 들어 키보드, 마우스, 터치 패드, 롤러 볼 및 음성 제어 수단 중 선 택된 하나 이상), 랜덤 액세스 메모리(RAM), 비 휘발성 스토리지, 디스플레이 컨트롤러 서브 시스템 및 기타 서브 시스템[도시되지 않음]과 같은 다양한 서브 시스템과 상호 작용한다.. 디스플레이 컨트롤러 서브 시스템은 디스플레이와 상호 작용하고 디스플레이 상에 그래픽 및/또는 텍스트를 만든다. 여전히 감시 시스템의 컴퓨터 단말기를 참조하면, 프로세서에 의해 사용되는 운영 체제 및 다양한 소프트웨어 애플리케이션이 비 휘발성 스토리지에 저장된다. 비 휘발성 스토리지는 예를 들어, 하나 이상의 하드 디스크, 솔리드 스테이트 드라이브, 또는 컴퓨터 단말기가 꺼진 후에 기록된 정보 를 유지하는 다른 적절한 형태의 컴퓨터 판독가능 매체이다. 운영 체제와 관련하여, 이것은 컴퓨터 단말기 의 컴퓨터 하드웨어 및 소프트웨어 자원을 관리하고 컴퓨터 프로그램에 대한 공통 서비스를 제공하는 소프 트웨어를 포함한다. 또한, 당업자는 운영 체제, 클라이언트 측 비디오 리뷰 애플리케이션 및 기타 애 플리케이션 또는 그 일부가 RAM과 같은 휘발성 스토리지에 일시적으로 적재될 수 있음을 인식 할 것 이다. 운영 체제 기능에 더하여, 프로세서는 컴퓨터 단말기에서 다양한 소프트웨어 애플리케이션 실 행을 가능하게 할 수 있다. 비디오 리뷰 애플리케이션의 더 자세한 사항은 도 2의 블록 도에 도시되어있다. 비디오 리뷰 애플리케이션 은 컴퓨터 단말기에서 실행될 수 있으며, 컴퓨터 단말기 사용자가 입력, 특히 복수의 상이한 비디오 레코딩에서 출현하는 동일한 개인 또는 객체를 식별하는 것을 용이하게 하기 위한 입력 제공과 관련된 작업을 수행할 수 있도록, 검색세션 관리자 모듈과 협력하기 위한 검색 사용자 인터페이스(UI) 모듈을 포함 한다. 이러한 상황에서, 컴퓨터 단말기의 사용자는 디스플레이 상에 생성된 사용자 인터페이스를 제 공받으며,이를 통해 사용자는 비디오 레코딩과 관련된 정보를 입력하고 수신한다. 비디오 리뷰 애플리케이션은 또한 위에서 언급한 검색세션 관리자 모듈을 포함한다. 검색세션 관리자 모듈은 검색 UI 모듈과 서버 시스템의 쿼리 관리자 모듈(도 1) 사이의 통신 인터페이스를 제공한다. 적어도 일부 예들에서, 검색세션 관리자 모듈은 원격 프로시저 호출(RPC)의 사용을 통해 쿼리 관리자 모듈와 통신한다. 쿼리 관리자 모듈 외에, 서버 시스템은 서버 시스템의 다른 기능을 수행하기 위한 여러 소프트 웨어 구성 요소를 포함한다. 예를 들어, 서버 시스템은 미디어 서버 모듈을 포함한다. 미디어 서버 모듈은 감시 시스템에서 비디오 카메라에 의해 촬영된 비디오의 저장 및 검색과 관련된 클라이 언트 요청을 처리한다. 서버 시스템은 또한 분석엔진 모듈을 포함한다. 분석엔진 모듈은 일부 예에서 수학적 계산(및 기타 연산)을 수행하여 비디오 레코딩의 서로 다른 부분 사이(또는 임의의 참조 이미지 와 비교되는 이미지와 상기 참조 이미지 사이)와 동일한 개인 또는 객체의 컴퓨터화된 매치(match)를 시도하는, 상업적으로 이용 가능한 알려진 임의의 적절한 소프트웨어 일 수 있다. 예를 들어, 분석엔진 모듈은 특정 예에서 Avigilon Corporation에 의해 판매되는 Avigilon Control Center ™ 서버 소프트웨어의 소프트웨어 구 성 요소일 수 있다. 일부 예들에서 분석엔진 모듈은 사람 또는 객체의 외모의 설명적 특징을 사용할 수 있 다. 이러한 특징의 예로는 사람이나 객체의 모양, 크기, 질감 및 컬러가 있다. 서버 시스템은 또한 다수의 다른 소프트웨어 구성 요소를 포함한다. 이러한 다른 소프트웨어 구성 요 소는 전체 시스템 내의 서버 시스템의 요구 사항에 따라 변할 것이다. 하나의 예로서, 다른 소프트웨어 컴 포넌트는 특별한 테스트 및 디버깅 소프트웨어, 또는 서버 시스템 내의 모듈의 버전 업데이트를 용이 하게 하는 소프트웨어를 포함할 수 있다. 서버 시스템은 또한 하나 이상의 데이터 스토리지를 포함한 다. 일정 예에서, 데이터 스토리지는 기록된 비디오의 조직화된 저장을 용이하게 하는 하나 이상의 데이터 베이스를 포함한다. 비디오 카메라와 관련하여, 이들 각각은 카메라 모듈을 포함한다. 일부 예에서, 카메라 모듈은 서버 시스템에 의해 수신되기 전에 비디오의 처리 및 인코딩을 용이하게 하기 위해 하나 이상의 특수 집적 회로 칩을 포함한다. 예를 들어, 특수 집적 회로 칩은 인코더와 중앙 처리 장치(CPU) 및/또는 비전 처리 장치(VPU) 모두를 포함하는 시스템0온-칩(System-on-Chip) 솔루션 일 수 있다. 이것들은 카메라 모듈이 프로세싱 및 인코딩 기능을 수행하도록 허용한다. 또한, 일부 예에서, 카메라 모듈의 처리 기능의 일부는 기록된 비디 오에 대한 메타 데이터를 생성하는 것을 포함한다. 예를 들어, 메타 데이터는 카메라 모듈이 검출한 하나 이상의 포어그라운드 영역과 관련하여 생성될 수 있고, 메타 데이터는 이미지 프레임 내의 포어그라운드 시각적 객체의 위치 및 기준 좌표를 정의할 수 있다. 예를 들어, 위치 메타 데이터는 검출된 포어그라운드 시각적 객체 의 윤곽을 그리는 일반적으로 직사각형 모양의 경계 상자를 생성하는 데 더욱 사용될 수 있다. 경계 상자 내의 이미지는 메타 데이터에 포함하기 위해 추출될 수 있다. 추출된 이미지는 경계 상자에 있는 것보다 더 작거나 경계 상자에 있는 것보다 더 클 수 있다. 추출되는 이미지의 크기는 검출된 객체의 실제 경계에 가깝지만 외부 에 있을 수도 있다. 일부 예들에서, 카메라 모듈은 예를 들어, 객체검출 서브 모듈, 시간적 객체분류 서브 모듈, 시간 객체분 류 서브 모듈 및 객체추적 서브 모듈과 같은 비디오 분석을 위한 다수의 서브 모듈을 포함한다. 객체검출 서브 모듈과 관련하여, 이러한 서브 모듈은 카메라의 시야에 나타나는 객체를 감지하기 위해 제공될 수 있다. 객체검출 서브 모듈은 예를 들어, 모션 및/또는 블랍(blob) 검출과 같은 당업자에 의해 이해되는 다양한 객체검 출 방법 중 임의의 방법을 채용할 수 있다. 카메라 모듈의 일부를 형성할 수 있는 객체추적 서브 모듈과 관련하여, 이 같은 서브 모듈은 객체검출 서 브 모듈 및 시간적 객체분류 서브 모듈 모두에 동작할 수 있도록 결합될 수 있다. 객체추적 서브 모듈은 객체검 출 서브 모듈에 의해 검출된 객체의 인스턴스를 일시적으로 연관시킬 목적으로 포함될 수 있다. 객체추적 서브 모듈은 또한 추적하는 시각적 객체에 해당하는 메타 데이터를 생성할 수도 있다. 카메라 모듈의 일부를 형성할 수 있는 순간 객체분류 서브 모듈과 관련하여, 이것은 객체검출 서브 모듈에 동작 가능하게 결합될 수 있고 객체의 단일 인스턴스에 기초하여 시각적 객체타입(예를 들어, 인간, 차량 또는 동물)을 결정하기 위해 사용될 수 있다. 순간 객체분류 서브 모듈에 대한 입력은 선택적으로 전체 이미지 프레 임이 아니라 관심대상 시각적 객체가 위치하는 이미지의 하위 영역일 수 있다. 카메라 모듈의 일부를 형성할 수 있는 시간적(temporal) 객체분류 서브 모듈과 관련하여, 이것은 순간 객 체분류 서브 모듈에 동작 가능하게 결합될 수 있고 일정 기간 동안 객체의 클래스 정보를 유지하기 위해 사용될 수 있다. 시간적 객체분류 서브 모듈은 객체의 수명 동안 일정 시간 순간 분류 서브 모듈이 제공하는 객체의 순 간 클래스 정보를 평균할 수 있다. 즉, 시간적 객체분류 서브 모듈은 다중 프레임에서의 외형에 따라 객체의 타 입을 결정할 수 있다. 예를 들어, 사람이 걷는 방식에 대한 보행 분석은 사람을 분류하는 데 유용할 수 있고, 사람의 다리 분석은 자전거를 타는 사람을 분류하는 데 유용할 수 있다. 시간적 객체분류 서브 모듈은 객체의 궤적(예를 들어, 궤적이 부드럽거나 혼란스러운지, 객체가 움직이거나 움직이지 않는지 여부)에 관한 정보와 다 중 프레임에 걸쳐 평균화된 순간 객체분류 서브 모듈에 의해 만들어진 분류의 신뢰도에 관한 정보를 결합할 수 있다. 예를 들어, 결정된 분류 신뢰 값은 객체 궤적의 부드러움에 기초하여 조정될 수 있다. 시간적 객체분류 서브 모듈은 충분한 횟수와 미리 정해진 개수의 통계가 수집된 후, 순간 객체분류 서브 모듈에 의해 시각적 객 체가 분류될 때까지 알 수 없는 클래스에 객체를 할당할 수 있다. 객체를 분류 할 때, 시간적 객체분류 서브 모 듈은 객체가 시야에 얼마나 오래 있었는지를 고려할 수도 있다. 시간적 객체분류 서브 모듈은 상기 기술한 정보 에 기초하여 객체의 클래스에 대한 최종 결정을 릴 수 있다. 시간적 객체분류 서브 모듈은 또한 객체의 클래스 를 변경하기 위해 히스테리시스 접근법을 사용할 수 있다. 보다 구체적으로, 객체의 분류를 알 수 는 클래스에 서 확실한 클래스로 전환하기 하기 위한 임계 값이 설정될 수 있으며, 그 임계 값은 반대 전환(예를 들어, 인간 으로부터 알 수 없음으로)에 대한 임계 값보다 클 수 있다. 시간적 객체분류 서브 모듈은 순간 객체분류 서브 모듈에 의해 이루어진 분류를 합계할 수 있다. 일부 예들에서, 카메라 모듈은 인간을 검출하고 관련 비디오와 함께 서버 시스템으로 전송될 수 있는 메타 데이터에 포함시키기 위해 인간 객체의 윤곽을 그리는 각각의 경계 상자로 인간을 검출하고 인간의 이미지 를 추출할 수 있다. 시스템에서, 미디어 서버 모듈은 추출된 이미지를 처리하고 객체를 나타내는 서 명(예를 들어, 특징 벡터)을 생성할 수 있다. 컴퓨터 비전에서 특징 설명자는 일반적으로 이미지를 가져와 특징 설명 또는 특징 벡터를 출력하는 알고리즘으로 알려져 있다. 특징 설명자는 정보, 즉 이미지를 일련의 숫자로 인코딩하여 하나의 특징을 다른 특징과 구별하는 데 사용할 수 있는 숫자 \"지문\" 역할을 한다. 이상적으로 이 정보는 이미지 변환 시 변하지 않으므로 동일한 객체의 다른 이미지에서 이 같은 특징을 다시 찾을 수 있다. 특 징 설명자 알고리즘의 예로는 SIFT(크기_ 불변 특징 변환), HOG(지향적 기울기 히스토그램) 및 SURF(Speeded Up Robust Features)가 있다. 적어도 일부 예들에 따르면, 특징 벡터는 컴퓨터에 의해 처리될 수 있는 객체의 이미지를 나타내는 수치 특징 (숫자)의 n 차원 벡터이다. 한 객체의 제 1 이미지의 특징 벡터를 제 2 이미지의 특징 벡터와 비교함으로써, 컴 퓨터 구현 가능 프로세스는 제 1 이미지와 제 2 이미지가 동일한 객체의 이미지인지 여부를 결정할 수 있다. 유사성 계산은 앞서 설명된 경우의 확장일 수 있다. 구체적으로, 하나 이상의 카메라에 의해 캡처된 두 이 미지의 두 특징 벡터 사이의 유클리드 거리(Euclidean distane)를 계산함으로써, 컴퓨터 구현 가능 프로세스는 두 이미지가 얼마나 유사할 수 있는지를 나타 내기 위해 유사성 점수를 결정할 수 있다. 일부 예들에서, 카메라 모듈은 관련 비디오와 함께 서버 시스템으로 전송될 수 있는 메타 데이터에 포함시키기 위해 인간 객체의 윤곽을 그리는 각각의 경계 상자를 갖는 인간을 검출하고 인간 이미지를 추출할 수 있다. 서버 시스템에서, 미디어 서버 모듈은 추출된 이미지를 처리하고 객체를 나타내는 서명(예 를 들어, 특징 벡터)을 생성할 수 있다. 이 같은 예시적인 구현에서, 미디어 서버 모듈은 학습 기계를 사용하여 경계 박스를 처리하여 비디오에서 캡처된 객체의 이미지 특징 벡터 또는 서명을 생성하도록 한다. 학습 기계는 예를 들어 그래픽 처리 장치(GPU)에서 실행되는 컨볼루션 신경 네트워크(CNN)와 같은 신경 네트워크이다. CNN은 수백만 쌍의 유사하거나 유사하지 않은 이미지를 포함하는 트레이닝 데이터 세트를 사용하 여 트레이닝 될 수 있다. 예를 들어 CNN은 신경 네트워크를 트레이닝하기 위해 대비 손실 함수(contrastive loss function)로 트레이닝 된 샴 네트워크 아키텍처이다. 샴 네트워크의 예는 Bromley, Jane, et al. \"'샴' 시간 지연 신경 네트워크를 사용한 서명 검증.\" 패턴 인식 및 인공 지능 국제 저널 7.04: 669-688에서 설 명된다. 미디어 서버 모듈은 모든 트레이닝이 외모 검색 시스템(appearance search system)에서 사용되기 전에 수 행되는 배치 학습(batch learning)으로 알려진 트레이닝된 모델을 배치한다. 이 실시 예에서 트레이닝 된 모델 은 하나의 가능한 매개 변수 세트를 갖는 CNN 학습 모델이다. 즉, 주어진 학습 모델에 대해 가능한 매개 변수 세트는 무한하다. 최적화 방법(예를 들면: 확률적 경사 하강법(stochastic gradient descent)과 같은) 및 수치 적 경사 계산 방법(예를 들면, 역 전파와 같은)을 사용하여 목적 함수(손실 함수라고도 함)를 최소화하는 매개 변수 집합을 찾을 수 있다. 대조 손실 함수(contrastive loss function)는 객관적인 함수로서 사용될 수 있다. 대조 손실 함수는 현재 트레이닝 된 모델이 덜 정확할 때 높은 값을 사용하고(유사한 쌍에 높은 거리를 할당하 거나 유사하지 않은 쌍에 낮은 거리를 할당), 현재 트레이닝 된 모델이 더 정확할 때 낮은 값을 사용하도록 정 의된다(유사한 쌍에 낮은 거리 및 유사하지 않은 쌍에 높은 거리). 따라서 트레이닝 과정은 최소화 문제로 축소 된다. 가장 정확한 모델을 찾는 과정은 트레이닝 과정이고, 매개 변수 세트가 있는 결과 모델은 트레이닝 된 모 델이며, 매개 변수 세트는 외모 검색 시스템에 배포된 후에는 변경되지 않는다. 적어도 일부 대안적인 예시적인 실시 예에서, 미디어 서버 모듈은 온라인 기계 학습 알고리즘으로 알려진 것을 사용하여 학습 기계를 구현함으로써 특징 벡터를 결정할 수 있다. 미디어 서버 모듈은 초기 파라미터 세트를 사용하여 학습 머신을 배치한다; 그러나 외모 검색 시스템은 일부 진실 소스(예를 들면: 관심 대상의 이 미지 선택에서 사용자 피드백)에 기초하여 모델의 매개 변수를 계속 업데이트한다. 이러한 학습 기계에는 컨볼 루션 신경 네트워크뿐만 아니라 다른 타입의 신경 네트워크도 포함한다. 적어도 일부 예에 따르면, 감시 시스템 내의 특징 벡터의 저장이 고려된다. 예를 들어, 특징 벡터는 각각 의 비디오와 함께 데이터베이스내에 인덱싱되고 저장될 수 있다. 특징 벡터는 또한 각각의 객체의 추출된 이미지가 각각의 비디오에 위치하는 기준 좌표와 연관될 수 있다. 저장은 예를 들어 타임 스탬프, 카메라 식별, 특징 벡터 및 기준 좌표를 갖는 메타 데이터 등으로 비디오를 저장함을 포함할 수 있다. 도 3 내지 도 8b에는 일 실시 예에 따라 검색 UI 모듈이 클라이언트 측 비디오 리뷰 애플리케이션의 사용자에게 디스플레이 하는 다양한 사용자 인터페이스 페이지가 도시된다. 도 2 ~ 8B에서 도시된 실시 예는 애 플리케이션의 144 사용자가 관심 있는 사람에 대한 검색을 시작하고 이미지 검색 결과를 검토하는 동안 사용자 가 관심 있는 사람을 식별하는 데 도움을 주기 위해 표시되는 관심 있는 사람의 얼굴 썸네일과 바디 썸네일을 가질 수 있도록 한다. 본 명세서에서 사용된 바와 같이, \"관심 있는 사람\"은 애플리케이션의 144 사용자가 감시 시스템을 사용하여 찾으려고 시도하는 사람이며; 사람의 \"바디 썸네일\"은 그 사람의 토르소(몸통)의 적어 도 일부를 표시하고; 그리고 사람의 \"얼굴 섬네일\"은 그 사람의 얼굴의 적어도 일부를 표시한다. 도시된 예시적 인 실시 예에서, 사람의 바디 썸네일은 그 사람의 헤어와 토르소(몸통)을 표시하고, 그 사람의 얼굴 썸네일은 썸네일의 전체 면적에 대한 비율로서 그 사람의 바디 썸네일에서 보여주는 것 보다 그 사람의 얼굴을 더욱 많이 보여준다. 도 2 내지 8B의 실시 예에서 서버 시스템은. 관심 있는 사람의 바디 및 얼굴 중 하나 또는 둘 모두에 기초하여 임의의 하나 이상의 카메라를 사용하여 하나 이상의 비디오 레코딩 컬렉션을 검색할 수 있다; 상기 비디오 레코딩의 수집은 카메라에 의해 동시에 생성될 수도 있고 생성되지 않을 수도 있다. 따 라서 검색하는 동안 사용되는 바디 및 얼굴을 허용하는 것은, 특히 관심 있는 사람 바디가 다른 레코딩에서 또 는 다른 시간에 외모를 변경하는 때(예를 들면, 관심 있는 사람이 의복을 갈아 입은 결과), 서버 시스템과 사용자 모두가 관심 있는 사람을 식별하는 데 도움이 될 수 있다. 이제 특히 도 3을 참조하면, 애플리케이션의 사용자가 관심 있는 사람에 대한 검색을 시작할 수 있도 록 하는 선택된 비디오 레코딩의 이미지 프레임을 포함하는 사용자 인터페이스 페이지가 도시되어 있 다. 도 3에 도시된 선택된 비디오 레코딩은 사용자가 애플리케이션을 통해 액세스할 수 있는 서로 다른 카 메라를 사용하여 얻은 비디오 레코딩 모음 중 하나이다. 애플리케이션은 단말기 디스플레이 에서 페이지를 표시한다. 사용자는 입력 장치를 통해 애플리케이션에 입력을 제공하며, 도 3의 예시적인 실시 예에서 상기 입력 장치는 마우스 또는 터치 패드를 포함한다. 도 3에서, 이미지 프레임(30 6)을 디스플레이 하는 것은 이미지 프레임을 정지 이미지로 디스플레이 하는 애플리케이션을 포함하지만, 상이한 실시 예에서 이미지 프레임을 디스플레이 하는 것은 선택된 비디오 레코딩을 재생하는 것을 포함할 수 있다. 선택된 비디오 레코딩의 이미지 프레임은 페이지의 우측 상단 사분 면의 전체를 차지하고 그 이상으 로 확장된다. 프레임은 여러 사람이 존재하는 장면을 묘사한다. 서버 시스템은 검색의 대상이 될 수 있는 장면에 나타나는 사람을 자동으로 식별하며, 따라서 잠재적인 관심 있는 사람을 사용자에게 식별시키 고 경계 박스 내 각각의 모두 또는 일부를 포함시킴으로써 그와 같은 사람 각각을 강조한다. 도 3에 도시 된 바와 같이, 사용자는 최하위 경계 상자에 위치한 사람을 관심 잇는 사람으로 식별하고 그 사람 주 위의 경계 상자를 선택하여 검색을 시작하는 데 사용될 수 있는 컨텍스트 메뉴를 불러낸다. 컨텍스트 메뉴는 사용자에게 관심 있는 사람에 대한 이미지 프레임 이후에 항상 비디오 레코딩 컬렉션을 검색하는 하나의 옵션과 이미지 프레임 이전에 항상 비디오 레코딩 컬렉션을 검색하는 다른 옵션을 제공한 다. 사용자는 서버 시스템이 관심 있는 사람에 대한 검색을 시작하도록 이러한 옵션 중 하나를 선택 할 수 있다. 사용자가 관심 있는 사람에 대한 검색을 시작하기 위해 애플리케이션을 통해 서버 시스템 에 제공하는 입력은 관심의 대상은 \"검색 시작 사용자 입력\"이다. 도 3에서, 사용자는 사용자가 그 이미지 프레임을 편리하게 재 방문할 수 있도록 카메라 중 어느 카 메라가 그 이미지 프레임 및 그 이미지 프레임 시간 인덱스를 획득했는지에 따라 이미지 프레임을 북 마크 했다. 이미지 프레임 바로 아래에는 이름 및 지속 시간과 같은 선택된 비디오 레코딩에 대해 선택된 메타 데이터를 제공하는 북마크 메타 데이터가 있다. 북마크 메타 데이터의 오른쪽 및 이미지 프레임 아래에는 사용자가 비디오 레코딩을 익스포트(내보내고) 레코딩에 대한 모션 검색을 수행하는 것과 같은, 선택된 비디오 레코딩에 대해 특정 동작을 수행할 수 있도록 하는 액션 버튼이 있다. 이미지 프레임의 바로 왼쪽에는 사용자의 모든 북마크를 보여주는 북마크 목록이 있으며, 이미지 프 레임에 대응하는 선택된 북마크가있다. 북마크 목록 바로 아래에는 하나 이상의 북마크를 잠그 거나 잠금 해제하여 이들이 변경되는 것을 방지하고, 이들이 변경되는 것을 허용하고, 하나 이상의 북마크를 익 스포트 하고(내보내고), 북마크 중 임의의 하나 이상을 삭제하는 것과 같은, 액션을 사용자가 수행하도록 한다. 북마크 옵션 바로 아래에 페이지의 좌측 하단 가장자리에 접하는 비디오 제어 버튼은 사용자가 선택된 비디오 레코딩을 재생, 일시 정지, 빨리 감기 및 되감기를 허용한다. 비디오 제어 버튼의 바로 오 른쪽에는 이미지 프레임에 해당하는 날짜와 시간을 표시하는 비디오 시간 표시기가 있다. 페이지 의 하단 가장자리의 대부분을 따라 확장하면, 선택된 비디오 레코딩 및 비디오 레코딩 수집에 의해 집합 적으로 표시되는 비디오를 통해. 사용자가 스크롤 할 수 있는 타임 라인이 있다. 도 8a 및 8b에 도시된 바 와 같이, 타임 라인은 검색을 용이하게 하기 위해 페이지상의 다른 특징들과 조정되는 방식으로 크기 가 조정될 수 있다. 이제 도 4에서, 사용자 인터페이스 페이지는 서버 시스템이 관심 있는 사람에 대한 검색 완료 이후가 도시된다. 상기 페이지는 사용자가 페이지의 오른쪽 가장자리 경계의 검색을 시작하기 위해 사용된 선택된 비디오 레코딩의 이미지 프레임; 이미지 프레임의 바로 왼쪽에서 잠재적으로 관심 있 는 사람에 대응하는 것으로서 서버 시스템에 의해 비디오 레코딩의 컬렉션으로부터 선택된 이미지 검 색 결과; 그리고, 이미지 검색 결과의 바로 왼쪽에서 페이지의 왼쪽 가장자리 경계하여, 관심 있는 사람의 얼굴 썸네일 및 바디 썸네일을 동시에 디스플레이 한다. 비디오가 레코딩되는 동안, 카메라 및 서버 시스템 중 적어도 하나는 실시간으로 잠재적인 관심 있는 사람인 사람들이 레코딩되고 있는 때를 식별하고, 이들에 대해, 각각의 얼굴을 식별하려고 시도한다. 서버 시스템은 상기 기술한 바와 같이 식별된 사람들의 얼굴(식별된 경우) 및 바디(body)에 기초하여 서명을 생 성한다. 서버 시스템은 얼굴이 식별되었는지에 대한 정보 그리고 서명을 비디오 레코딩과 함께 메타 데이 터로서 저장한다. 검색 시작 사용자 입력에 응답하여 사용자는 도 3의 컨텍스트 메뉴를 사용하여 제공한다. 서버 시스템 은 관심 있는 사람에 대한 비디오 레코딩 컬렉션을 검색하여 이미지 검색 결과를 생성한다. 서 버 시스템은 관심 있는 사람의 바디와 얼굴에 대해 각각 기록된 메타 데이터를 사용하여, 비디오 레 코딩 컬렉션에 대해 바디 검색 및 얼굴 검색을 포함하는 통합 검색을 수행한다. 보다 구체적으로, 서버 시스템 은 시스템이 표시한 다른 사람에 대하여, 사용자가 바디 및 얼굴 서명에 대하여 검색하기를 원한다고 표시한 관심 있는 사람의 바디 및 얼굴 서명을 비교한다. 서버 시스템은 애플리케이션이 페이지 를 생성하기 위해 사용하는 바디 및 얼굴 검색의 결과의 조합을 포함하는 검색 결과를 리턴 한다. 바디 및 얼굴 검색을 수행하기 위해 임의의 적절한 방법이 사용될 수 있다; 예를 들어, 서버 시스템은 바디 검색을 수행할 때 컨볼루션 신경 네트워크를 사용할 수 있다. 예시적인 한 실시 예에서, 얼굴 검색은 얼굴에 대한 비디오 레코딩 모음을 검색함으로써 수행된다. 얼굴이 식별 되면 얼굴을 경계하는 경계 상자의 좌표(예를 들면, 상자의 한 모서리와 상자의 너비 및 높이를 식별하는 (x, y) 좌표의 관점에서)와 헤어 포즈의 추정치(예를 들면, 요(yaw), 피치 및 롤 측면에서)가 생성된다. 예를 들어, 얼굴 각각에 대해 눈꼬리 사이의 거리, 눈 중앙 사이의 거리, 코 너비, 눈 소켓 깊이, 광대뼈 형상, 턱 선 형상, 턱 형상, 헤어 색깔, 그리고 얼굴 털의 존재와 색이 메트릭스로 사용될 수 있다. 얼굴에 대한 특징 벡터 가 생성되면, 서로 다른 얼굴에 대한 벡터 간의 유클리드 거리가 결정되고 얼굴 유사성을 평가하는 데 사용될 수 있다. 다른 예로서, 특징 벡터는 상기 기술한 바와 같이 미디어 서버 모듈에 의해 생성될 수 있다. 적어도 하나의 예시적인 실시 예에서, 카메라는 실시간으로 또는 거의 실시간으로 메타 데이터 및 관련 특 징 벡터를 생성하고, 서버 시스템은 후속적으로 이러한 특징 벡터를 사용하여 얼굴 유사성을 평가한다. 그 러나, 적어도 하나의 대안적인 예시적인 실시 예에서 카메라 및 서버 시스템에 의해 수행되는 기능은 상이할 수 있다. 예를 들어, 기능은 상기 기술한 것과 다른 방식으로 서버 시스템과 카메라 사이에서 분할될 수 있다. 대안적으로, 서버 시스템 및 카메라 중 하나는 특징 벡터를 생성하고 얼굴 유사성을 평가할 수 있다. 도 4에서 도시된 바와 같이, 애플리케이션은 관심 있는 사람을 강조하는 경계 상자 내에 포함된 이미 지 프레임의 적어도 일부를 바디 썸네일로서 사용한다. 애플리케이션은 그 결과가 관심 있는 사 람의 얼굴에 대응할 최소 가능성을 만족하는 얼굴 검색 결과 중 하나의 적어도 일부를 얼굴 썸네일로 서 사용하고; 예시적인 한 실시 예에서, 얼굴 썸네일은 관심 있는 사람의 얼굴에 대응할 가능성이 가 장 높은 얼굴 검색의 결과로부터 도출된다. 추가적으로 또는 대안적으로, 얼굴 썸네일의 기초로 사용되는 결과는 결과가 관심 있는 사람의 바디에 대응할 최소 가능성을 만족하는 바디 검색 결과 중 하나이다. 다 른 예시적인 실시 예에서, 얼굴 썸네일은 도 4에서 관심 있는 사람를 강조하는 경계 상자 내에 포함된 이미지 프레임의 적어도 일부로서 선택될 수 있다. 도 4에 도시된 바와 같이, 이미지 검색 결과는 n 개의 행 및 m 개의 열을 포함하는 어레이에 배 열된 다수의 이미지를 포함하고, n = 1은 어레이의 최상단 행에 대응하고 m = 1은 어레이의 가장 좌측 열 에 대응한다. 그 결과는 사용자가 어레이를 스크롤할 수 있게 하는 스크롤 바를 연장하는 우측 및 하단 에지를 따라 위치한 윈도우에 위치한다. 도 4에서, 어레이는 적어도 4 x 5 개의 이미지를 포함하는데, 이는 어떠한 스크롤 없이도 볼 수 있는 어레이의 부분이기 때문이며 스크롤 바를 사용한다. 이미지 검색 결과의 열 각각은 비디오 레코딩 수집의 상이한 기간에 대응한다. 도 4에서, 열 각 각은 3 분 기간에 대응하고, 가장 왼쪽 열은 오후 1시 9 분에서 오후 1시 11 분(포함)까지의 검색 결과 를 나타내며, 가장 오른쪽 열은 오후 1시 21 분에서 오후 1시 23 분(포함)까지의 검색 결과를 나타내고, 중간 세 개의 열은 오후 1시 12 분에서 오후 1시 20 분(포함)까지의 검색 결과를 나타낸다. 또한, 도 4의 실시 예에서, 이미지 검색 결과 각각은 이미지 검색 결과가 관심 있는 사람 에 대응할 가능성에 따라 디스플레이 상에 위치된다. 도 4에 도시된 바와 같이, 애플리케이션은 이미지 검색 결과가 관심 대상에 대응할 가능성에 비례하여 어레이에서 이미지 검색 결과의 높 이를 만듦으로써 이 기능을 구현한다. 따라서, 각각의 열에 대해, 최 상단 행(n = 1)에 위치한 검색 결과는 n이 증가함에 따라 일치 가능성이 감소하는 관심 있는 사람에 대응할 가능성이 가장 높은 열 에 대응하는 기간에 대한 결과이다. 도시된 실시 예에서, 모든 검색 결과는 그들이 관심 있는 사람에 대응할 최소 가능성을 만족시킨다; 예를 들어, 특정 실시 예에서, 애플리케이션은 관심 있는 사람에 대응하는 25% 이상의 가능성(\"일치 가능성 임계 값\")을 갖는 검색 결과만을 디스플레이 한다. 그러나, 특정한 다른 실시 예에서, 애플리케이 션은 일치 가능성 임계 값을 고려하지 않고 모든 검색 결과를 표시하거나, 25 %가 아닌 0이 아닌 일 치 가능성 임계 값을 사용할 수 있다. 도 4에 도시된 바와 같이, 바디 및 얼굴 썸네일(404, 402)은 각각 이미지 검색 결과의 일부를 포함하는 제 1 이미지(408a) 및 제 2 이미지(408b)의 적어도 일부를 포함한다. 제 1 및 제 2 이미지(408a, b) 및 이에 따라 바디 및 얼굴 썸네일(404, 402)은도 4에서 다르다. 그러나, 상이한 실시 예(도시되지 않음)에서, 섬네일(404, 402)은 동일한 이미지에 기초할 수 있다. 제 1 및 제 2 표시기(410a, b) 각각은 제 1 및 제 2 이미지(408a, b) 상에 중첩되며, 이는 제 1 및 제 2 이미지가 바디 및 얼굴 썸네일(404, 402)의베이스임을 나타낸다. 도 4에서제 1 및 제 2 표시기(410a, b)는 동일한 별이지만, 상이한 실시 예(도시되지 않음)에서 상기 표시기(410a, b)는 다를 수 있다. 선택된 비디오 레코딩의 이미지 프레임 바로 아래에는 사용자가 선택된 비디오 레코딩을 재생하고 일시 정 지할 수 있도록 하는 재생 제어가 위치한다. 이미지 검색 결과 아래의 수평 스크롤 바 바로 아 래에는 사용자가 추가 검색 결과에 대한 애플리케이션을 프롬프트할 수 있도록 하는 더욱 많은 결과 적재 버튼이 있다. 예를 들어, 일 실시 예에서, 애플리케이션은 추가 검색 결과가 일치 가능성 임계 값을 초과하더라도 기껏해야 특정 수의 결과를 초기에 전달할 수 있다. 이와 같은 실시 예에서, 사용 자는 더 많은 결과 적재 버튼을 선택함으로써 일치 가능성 임계 값을 초과하는 또 다른 결과 부분을 요청할 수 있다. 특정 다른 실시 예에서, 애플리케이션은 이러한 추가 결과가 일치 가능성 임계 값 이하인 경우에도 사용자가 버튼을 선택함에 응답하여 추가 결과를 표시하도록 구성될 수 있다. 필터 토글은 사용자가 애플리케이션에 일치 확인 사용자 입력을 제공함으로써 사용자가 관심 있는 사람 에 해당한다고 확인한 결과로 이미지 검색 결과를 제한할 수 있도록 하며, 이 같은 필터 토글이 썸네일(402,404) 아래에 위치한다. 이들에 대한 설명이 아래에서 더 논의된다. 페이지의 폭에 걸쳐 있고 썸네일(402, 404), 검색 결과 및 이미지 프레임 아래에 위치하는 것은 막대 그래프 형태의 관심 있는 사람에 대한 출현 가능성 플롯이다. 막대 그래프는 관심 있는 사 람이 주어진 시간 범위에 걸쳐 비디오 레코딩 컬렉션에 나타날 가능성을 묘사한다. 도 4에서 시간 범위는 하루의 기간들로 나뉘며, 전체 시간 범위는 약 3 일(8 월 23 일 ~ 25 일 포함)이다. 각각의 기간은 추가로 별개 의 시간 간격으로 나뉘며, 이들 각각은 막대 그래프의 하나의 막대로 표시된다. 아래에서 더 자세히 논의되는 바와 같이, 시간 범위, 기간 및 시간 간격 중 임의의 하나 이상은 특정 실시 예에서 조정 가능하다. 막대 그래프는 사용자가 막대 그래프를 따라 시간상 앞뒤로 스크롤 할 수 있도록 하는 막대 그래프 스크롤 제어에 의해 그 끝에서 북 마크 된다. 막대 그래프를 결정하기 위해, 서버 시스템은 시간 간격 각각에 대해 관심 있는 사람 상기 시간 간격 동안 비디오 레코딩 모음에 나타날 가능성을 결정하며, 다음에 그 같은 시간 간격에 대한 바의 높이 로서 그 가능성을 나타낸다. 이 같은 예시적인 실시 예에서, 서버 시스템은 관심 있는 사람이 그와 같은 시간 간격 동안 비디오 레코딩 모음 중 어느 하나에 나타날 가능성을 최대 가능성으로서 결정한다. 다른 실시 예에서, 그와 같은 가능성은 다르게 결정될 수 있다. 예를 들어, 하나의 다른 실시 예에서, 서버 시스템 은 관심 있는 사람이 일치 가능성 임계 값을 만족하는 이미지 검색 결과에 나타날 가능성을 평 균 가능성으로서 결정한다. 도 4에서는, 애플리케이션이 이미지 검색 결과상에 표시되는 제 1 및 제 2 인디케이터(410a, b)가 제 1 및 제 2 이미지(408a, b)가 카메라에 의해 캡쳐되는 시간 간격에 대응하는 막대 바에 의해 막대 그 래프상에 표시되며, 그와 같은 시간 간격에 대응하는 위치에서 타임 라인상에 표시된다. 이와 같이하 여 애플리케이션의 사용자가 썸네일(402, 404)에 대한 베이스로서 사용된 이미지(408a, b)를 신속하게 식 별할 수 있을 뿐 만 아니라, 그와 같은 이미지(408a, b)가 캡처된 시기에 대한 정보를 세 가지 다른 방식으로 시각적으로 제시할 수 있게 한다. 이 같은 사실은 제 1 이미지(408a) 그리고 제 2 이미지(408b) 어느 것도 현재 디스플레이에 표시되지 않을 때 특히 유용할 수 있으며(예를 들어, 이미지 검색 결과의 일부를 포함 할 수 있지만 이를 보기 위해 사용자가 스크롤 해야 함), 따라서 표시기(410a, b)는 막대 그래프 및 타임 라인 중 하나 또는 둘 모두에서만 볼 수 있다. 도시된 실시 예에서 출현 가능성 플롯이 막대 그래프를 포함하는 것으로 도시되어 있지만, 다른 실시 예 (도시되지 않음)에서 플롯은 다른 형태를 취할 수 있다. 예를 들어, 상이한 실시 예에서 플롯은 상이한 시간 간 격에서의 출현 가능성에 대응하는 선 그래프상의 상이한 포인트를 갖는 선 그래프를 포함하거나 상이한 출현 가 능성을 나타내기 위해 상이한 컬러를 사용할 수 있다. 도 3에서와 같이, 도 4의 페이지은 또한 타임 라인, 비디오 제어 버튼 및 페이지의 하단을 따라 연장되는 비디오 시간 표시기를 포함한다. 애플리케이션은 사용자가 이미지 검색 결과 중 적어도 하나가 관심 있는 사람을 묘사하는지 여 부에 관한 일치 확인 사용자 입력을 제공하도록 허용한다. 사용자는 예를 들어, 이미지 검색 결과 중 하 나를 선택하여 일치 확인 사용자 입력을 제공하여, 사용자가 검색 결과가 관심 있는 사람를 묘사하는 지 여부를 확인할 수 있도록 하는 컨텍스트 메뉴(도시되지 않음)를 불러오도록 한다. 일치 확인 사용자 입력에응답하여, 도시된 실시 예에서 서버 시스템은 임의의 일치 가능성이 변경되는지 여부 및 그에 따라 일치 확인 사용자 입력에 응답하여 이미지 검색 결과의 위치가 변경되는지 여부를 결정한다. 예를 들어, 일 실 시 예에서 사용자가 결과 중 하나가 일치함을 확인하는 경우, 서버 시스템은 얼굴 및 바디 검색 중 하나 또는 둘 모두를 수행할 때 비교를 위한 참조로서 그와 같이 확인된 이미지를 사용할 수 있다. 이미지 검색 결과의 위치가 변경되어야 할 때, 애플리케이션은 일치 확인 사용자 입력에 응답하여 이미지 검색 결과 의 위치를 업데이트한다. 예를 들어, 애플리케이션은 사용자가 표시한 어떠한 결과도 관심 있는 사람 을 포함하지 않는다는 것을 이미지 검색 결과로부터 삭제하고 그에 따라 나머지 결과를 재 배열 할 수 있다. 일 예시적인 실시 예에서, 얼굴 및 바디 썸네일(402, 404) 중 하나 또는 둘 모두는 일치 확인 사용 자 입력에 응답하여 변경될 수 있다. 또 다른 예시적인 실시 예에서, 서버 시스템이 처음에 관심 있는 사 람의 임의의 얼굴을 식별 할 수 없고 이에 따라 애플리케이션이 얼굴 썸네일을 표시하지 않는 경우, 서버 시스템은 일치 확인 사용자 입력을 수신 한 후 관심 있는 사람을 식별 할 수 있으며, 다음에 상기 애플리케이션은 얼굴 썸네일을 보여줄 수 있다. 일치 확인 사용자 입력이 선택된 이미지 검색 결과 중 어느 하나가 관심 있는 사람를 묘사하고 있음 을 나타낼 때, 애플리케이션은 사용자가 확인하는 선택된 이미지 결과 각각에 대하여 제 3 표시기 (410c)가 관심 있는 사람에 해당함을 표시한다. 도 5의 사용자 인터페이스 페이지에 도시된 바와 같 이, 이는 사용자가 일치 확인 사용자 입력을 제공 한 후 도 4의 페이지를 나타내는 것이며, 도시된 실시 예에서 제 3 표시기(410c)는 별이고 제 1 및 제 2 표시기(410a, b)와 동일하다. 도 5의 모든 3 개의 표시기 (410a-c).검색 결과 어레이의 가장 좌측 3 개의 열 및 제 1 행에 있다. 상이한 실시 예(도시되지 않음)에 서, 제 1 내지 제 3 표시기(410a-c) 중 임의의 하나 이상은 서로 상이할 수 있다. 도 5의 페이지는 또한 막대 그래프 및 타임 라인에 각각 중첩된 출현 가능성 플롯 크기 조절 가 능 선택 윈도우(502a) 및 타임 라인 크기 조절 가능 선택 윈도우(502b)을 도시한다. 사용자는 입력 장치를 사용하여 윈도우 크기 조정 사용자 입력을 제공함으로써 윈도우(502a, b) 각각의 폭을 변경하고 패닝(pan)할 수 있다. 도 8a 및 8b에서 더 상세히 논의되는 바와 같이, 선택 윈도우(502a, b)는 특정 시간 범위를 커버하도록 윈도우(502a, b) 중 하나의 크기를 조정하면 애플리케이션이 윈도우(502a, b) 중 다른 하나의 크기도 자동 으로 조정하여 상기 특정 시간 범위와 동일한 시간 범위를 커버하도록 동기화된다. 추가로, 상기 애플리케이션 은 선택 윈도우(502a, b)가 커버하는 특정 시간 범위에 대응하는 비디오 레코딩의 컬렉션으로부터만 이미 지 검색 결과를 선택한다. 이러한 방식으로, 사용자는 선택 윈도우(502a, b) 중 하나를 재배치하고 상기 애플리케이션이 선택 윈도우(502a, b) 중 다른 하나의 크기를 자동으로 조정하고 그에 따라 검색 결과 를 업데이트할 수 있다. 도 8a 및 8b에서는, 도 3의 사용자 인터페이스 페이지가, 제 1 기간(도 8a, 8 월 24 일에 대한 검색 결과 의 일부만이 선택됨) 및 더 긴 제2 기간(도 8b, 8 월 24 일에 대한 실질적인 모든 검색 결과가 선택 됨) 범위에 대하여 선택된 크기를 조정할 수 있는 선택 윈도우(502a, b)를 갖는 것으로 도시된다. 상기 설명한 바와 같이, 도 8a 및 8b각각에서의 윈도우(502a, b)는 윈도우(502a, b) 중 하나의 크기를 조정하는 사용자에 응 답하여 애플리케이션이 다른 하나의 크기를 자동으로 조정하기 때문에 동일한 기간을 나타낸다. 추가적으 로, 애플리케이션이 디스플레이하는 검색 결과의 어레이는 윈도우(502a, b)에 의해 선택된 기간에 따 라 상이하며, 이는 상기 기간이 검색 결과에 대한 기초로 사용될 수 있는 비디오 레코딩 컬렉션의 일부분 에 영향을 미치기 때문이다. 이제 도 6을 참조하면, 도 5의 에는 사용자가 필터 토글을 토글한 후 도 5의 사용자 인터페이스 페이지 가 도시되어있으며, 표시된 검색 결과를 사용자가 일치 확인 사용자 입력을 제공하여 결과가 관 심 있는 사람을 표시함을 확인하는 것들로 제한하도록 하고, 얼굴과 바디의 썸네일(402,404)에 대한 베이 스로서 사용된 것들로 제한하도록 한다. 상기 기술한 바와 같이, 상기 어레이에서 검색 결과를 강조하기 위해 사용된 표시기(410a-c)는 또한 그 결과가 획득되었을 때 막대 그래프 및 타임 라인에서 강 조하기 위해 사용된다. 도 7은 관심 있는 사람의 이미지 검색 결과, 얼굴 썸네일 및 바디 썸네일을 포함하는 사용 자 인터페이스 페이지를 도시하고, 상기 이미지 검색 결과는 관심 있는 사람이 도. 3-6에서 와는 다 른 의복을 입고 있는 것을 보여준다. 도 7에서, 선택 윈도우(502a, b)는 상기 이미지 검색 결과가 8월 25일로부 터의 이미지로 제한되고, 도 3-6에서 묘사된 상기 검색 결과가 8월 24일로부터의 이미지로 제한되도록 조 정되었다. 상기 언급한 바와 같이, 상기 도시된 실시 예에서 서버 시스템은 얼굴 및 바디 검색을 사용하여 관심 있는 사람에 대한 비디오 레코딩 컬렉션을 검색하며, 상기 바디 검색은 관심 있는 사람의 의복을 고려한다. 그에 따라 특히 관심 있는 사람의 의복이 비디오 레코딩 컬렉션의 하나 이상에서 다른 시간에 다 르거나 상기 비디오 레코딩 컬렉션을 포함하는 다른 레코딩에 걸쳐 다를 때, 얼굴 검색을 통합하면 서버 시스템 이 관심 있는 사람을 식별하는 데 도움이 된다. 도 7의 결과 내 관심 있는 사람이 도 3-6에서와 는 상이한 의복을 착용하고 그에 따라 바디 출현이 변경되기 때문에, 도 7의 이미지 검색 결과 내에 보여 지는 관심 있는 사람(관심 있는 사람이 줄무늬 셔츠를 착용하고 있는 결과에서와 같이)은 그에 '따라 바디 검색과든 달리 우선적으로 얼굴 검색을 사용하여 식별된다. 이제 도 9를 참조하면, 다른 예시적인 실시 예에 따라 관심 있는 사람에 대한 이미지 검색을 용이하게 하 기 위해 사용자와 인터페이싱하는 방법이 도시된다. 상기 방법은 애플리케이션을 구현하고 단말 기의 비 휘발성 스토리지에 저장되는 컴퓨터 프로그램 코드로 표현될 수 있다. 런타임에, 프로세서 는 컴퓨터 프로그램 코드를 RAM 내에 로드하고 코드를 실행함으로써, 이에 따라 방법을 수행한 다. 상기 방법은 블록에서 시작하고, 그 다음 프로세서는 블록으로 진행하고 동시에 디스플레 이, 얼굴 썸네일, 바디 썸네일 및 관심 있는 사람의 이미지 검색 결과를 디스플레이 한다. 상기 프로세서는 일정 형태의 사용자 입력을 수신하는 블록으로 진행한다; 사용자 입력의 예로는 위 에서 설명한 일치 확인 사용자 입력 및 검색 시작 사용자 입력이 있다. 추가적으로 또는 대안적으로, 사용자 입 력은 재생 제어, 막대 그래프 및 타임 라인과의 상호 작용 중 임의의 하나 이상과 같은, 또 다 른 타입의 사용자 입력을 포함할 수 있다. 사용자 입력을 수신한 후, 상기 프로세서는 블록으로 진행하여 서버 시스템이 블록에서 수신된 사용자 입력을 처리해야 하는지 여부를 결정한다. 예를 들어, 사용자 입력이 스크롤 바를 사용하여 이미지 결과를 스크롤 하는 경우, 서버 시스템은 필요하지 않으며 프로세서는 사용자 입력 자체를 처리 하는 블록으로 직접 진행한다. 스크롤링의 형태로 입력을 처리할 때, 프로세서는 스크롤링에 응답하 여 이미지 결과의 어레이를 업데이트하는 방법을 결정한 다음, 그에 따라 디스플레이를 실제로 업데 이트하는 블록으로 진행한다. 특정 예들에서, 프로세서는 서버 시스템이 사용자 입력을 적절하게 처리하기 위해 필요하다고 결정한 다. 예를 들어, 사용자 입력은 검색 시작 사용자 입력을 포함할 수 있으며, 이는 서버 시스템이 관심 있는 사람에 대한 비디오 레코딩 컬렉션의 새로운 검색을 시작하게 한다. 이 같은 예에서, 프로세서는 블 록으로 진행하며, 예를 들어, 원격 프로시저 호출(procedure call)의 형태로 검색 시작 사용자 입력을 처 리하기 위해 서버 시스템으로 요청을 전송한다. 블록에서 프로세서는, 이미지 검색 결과 및 관련 이미지의 업데이트 된 어레이를 포함할 수 있는, 서버 시스템으로부터 결과를 수신한다. 프로세서는 이어서 블록으로 진행하여 업데이트된 검색 결과 및 블록에서 서버 시스템 으로부터 수신된 이미지를 고려하여 디스플레이를 업데이트하는 방법을 결정하고, 이어서 블록 으로 진행하여 디스플레이를 실제로 업데이트 하도록 한다. 프로세서가 블록(910 및 912)에서 임의의 동작을 수행하기 위해 서버 시스템에 의존하는지 여부에 관 계없이, 본원 발명에서 동작을 수행하는 프로세서 또는 애플리케이션에 대한 참조는 프로세서 또는 애플리케이션이 서버 시스템으로부터의 도움과 함께 수행하는 동작 그리고 프로세서 또는 애플리케이션이 서버 시스템의 도움 없이 수행하는 동작을 포함한다. 블록을 완료한 후, 프로세서가 사용자 입력에 응답하여 서버 시스템과 통신했는지 여부에 관계 없이, 프로세서는 방법이 종료되는 블록으로 진행한다. 프로세서는 블록 또는 블록 에서 방법을 다시 시작함으로써 원하는 대로 방법을 반복할 수 있다. 패싯 검색(Facet Search) 적어도 일부 예시적인 실시 예에서, 본 명세서에 설명된 방법, 시스템 및 기술은 관심 대상(object-of- interest)을 검색하기 위해 아래에서 추가로 설명되는 바와 같이 적용된다. 관심 대상은 도 1 및 도 2와 관련하 여 위에서 설명된 관심 있는 사람을 포함할 수 있다. 추가적으로 또는 대안적으로, 관심 대상은 차량과 같 은 사람이 아닌 대상을 포함할 수 있다. 특히, 적어도 일부 예시적인 실시 예에서 서버 시스템은 \"패싯 검 색\"을 수행하도록 구성되며, 여기서 \"패싯\"은 관심 대상의 특정 시각적 특성을 설명하는 데이터 구조이다. 적어 도 일부 예시적인 실시 예에서 시스템은 \"설명자\"및 \"태그\"를 포함하는 것으로서 스토리지내에 패싯데이터 구조를 저장한다. 패싯 설명자는 패싯 타입을 설명하는 텍스트 문자열을 포함할 수 있는 반면, 패싯 태 그는 해당 패싯의 특성을 나타내는 값을 포함할 수 있다. 예를 들어, 패싯이 헤어 컬러인 경우 패싯 설명자는 \"헤어 컬러\"일 수 있고 패싯 태그는 \"갈색\"또는 컬러 목록에서 추출된 다른 컬러 일 수 있다. 유사하게, 패싯 이 의복 타입일 때, 패싯 설명자는 \"의복 타입\"일 수 있고 패싯 태그는 \"재킷\"또는 의복 타입 목록에서 추출된 다른 의복 타입일 수 있다. 적어도 일부 예시적인 실시 예에서, \"패싯\"에 대한 참조는 따라서 설명자: 태그 쌍 에 대한 참조이다. 관심 대상이 차량인 경우 적어도 일부 예시적인 실시 예에서, 패싯 설명자는 컬러, 제조사, 모델 또는 구성일 수 있다. 시스템이 관심 있는 사람을 검색하는 데 사용될 때, 관심 있는 사람의 \"설명자\"는 예를 들어, 그 사람의 성별, 그 사람의 나이, 그 사람이 입는 의복의 타입, 그 의복의 컬러, 그 의복에 표시된 패턴, 그 사람의 헤어 컬러, 그 사람의 헤어 길이, 그 사람의 신발 컬러, 그 사람의 의복 액세서리(예를 들면: 지갑 또는 가방)일 수 있다. 적어도 일부 예시적인 실시 예에서 그리고 도 10a 내지도 11e에서 도시된 바와 같이, 서버 시스템은 도 3 내지 도 8B와 관련하여 설명된 타입의 이미지 검색 이전 또는 이후에 패싯 검색이 수행되도록 구성된다. 도 10a 내지 도 11e와 관련하여 설명된 \"패싯 검색\" 작업 흐름과는 대조적으로, 도 3내지 도 8B와 관련하여 설명된 이 미지 검색은 관심 있는 사람의 바디 또는 얼굴에 기초하여 수행되므로, 본원 명세서에서는 \"바디/얼굴 검 색\"이라고 설명한다. 이제 도 10a-10E와 관련하여, 적어도 하나의 예시적인 실시 예에 따라 패싯 검색이 수행되는 동안 다양한 상태 의 사용자 인터페이스 페이지 또는 그 일부가 도시되어있다. 도 10a에서, 페이지는 제 1 검색 메뉴 (1002a) 및 제 2 검색 메뉴(1002b)를 포함하고, 사용자가 패싯 검색을 시작하기 위해 이들 중 어느 하나와 상호 작용할 수 있다. 제 1 검색 메뉴(1002a)는 컨텍스트 메뉴의 예이고, 제 2 메뉴(1002b)는 드롭 다운 메뉴의 예이 다. 사용자는 메뉴(1002a, b) 중 하나에서 \"출현\"옵션을 선택하여 패싯 검색을 시작할 수 있다. 도 10a에서 \"출현\"을 선택한 후. 사용자 인터페이스는 도 10b에서 도시된 바와 같이 패싯 검색 메뉴를 디 스플레이 한다. 메뉴는. 도 10b에서 사용자가 사람(도 10b에서 선택되는 바와 같이) 또는 차량의 형태로 관심 대상을 선택할 수 있도록 하는 무선 버튼인 관심 대상 선택기; 성별 선택기, 연령 선택기 및 다양한 추가 태그 선택기와 같은 다양한 태그 선택기; 사용자가 패싯 검색을 지정된 날짜 범위로 제 한할 수 있도록 하는 날짜 범위 선택기; 사용자가 패싯 검색을 특정 지정된 카메라로 제한할 수 있도록 하는 카메라 선택기; 및 사용자에 의해 선택될 때, 패싯 검색이 시작될 것임을 나타내는 패싯 검색 시작 사용자 입력을 포함하는 검색 버튼을 포함한다. 도 12a 및 도 12b에 도시 된 바와 같이, 적어도 하나의 다른 예시적인 실시 예에서, 메뉴는 사용자가 패싯 설명자 및/또는 태그를 선택할 수 있도록 다른 헤어 스타일, 상체 및 하체 의복 타입 및 다른 컬러의 사용자 선택 가능한 이미지를 그래픽으로 묘사할 수 있다. 예 를 들어, 도 12a에서 사용자는 성별, 나이, 헤어 스타일 및/또는 헤어 컬러와 같은 설명자에 대한 태그를 선택 할 수 있다. 그리고 도 12b에서, 사용자는 상체 의복 타입 및 컬러; 하체 의복 타입 및 컬러; 그리고 신발 컬러 와 같은 설명자에 대한 태그를 선택할 수 있다. 태그 선택기(1010, 1016, 1018)는 사용자가 관심 있는 사람의 성별(도 10a에서 남성이 되도록 선택됨) 연 령(도 10a에 명시되지 않음); 의복 타입(청바지 및 티셔츠를 포함하도록 도 10a에서 선택됨); 의복 컬러 및/또 는 패턴(도 10a에서 적색으로 선택됨); 헤어 컬러(도 10a에 명시되지 않음); 신발 컬러(도 10a에 명시되지 않음); 및 예를 들어, 관심 있는 사람이 지갑을 들고 있거나 모자를 쓰고 있는지 여부와 같은 액세서리(도 10a에 명시되지 않음) 중 하나 이상을 조정할 수 있도록 한다. 다른 예시적인 실시 예(도시되지 않음)에서, 도 10a에 나열된 것보다 더 많거나, 더 적거나, 다른 패싯이 선택될 수 있다. 도 10c는 예시적인 의복 타입 메뉴(1020a) 및 예시적인 의복 컬러 및/또는 패턴 메뉴(1020b)를 도시하며, 이는 도 10b에서 예시적인 추가 태그 선택기로서 도시된다. 의복 타입 메뉴(1020a)는 사용자가 청바지, 반바지 /치마, 스웨터 및 티셔츠 중 임의의 하나 이상을 패싯으로 선택할 수 있게 하고, 의복 컬러 및/또는 패턴 메뉴 (1020b)는 사용자가 관심 있는 사람 의복으로 적용되는 것으로서 검정, 파랑, 녹색, 회색, 어두운(하의), 밝은(하의), 격자 무늬, 빨강, 흰색 및 노란색 패싯 중 임의의 하나 이상을 선택할 수 있도록 한다. .적어도 일 부 예시적인 실시 예에서, 컬러 및/또는 패턴 메뉴(1020b)의 하의 선택기는 사용자가 의복 타입 메뉴(1020a)에 서 하체 의복을 역시 선택한 경우에 사용자만이 또한 선택할 수 있다. 도 10c에 도시 된 바와 같이, 사용자가 의복 타입 메뉴(1020a)에서 \"청바지\"를 선택하였으므로, 사용자는 컬러 및/또는 패턴 메뉴(1020b)에서 청바지가 밝은 지 어두운 지 여부를 자유롭게 지정할 수 있다. 적어도 몇몇 다른 예시적인 실시 예들에서, 사용자는 패싯설명자가 선택되었는지 여부에 관계없이 패싯 태그(예를 들어, 의복의 컬러 및/또는 패턴)를 선택할 수 있다. 도시 된 예시적인 실시 예에서, 패싯 설명자는 \"의복 타입\"이고, \"패싯 태그\"는 드롭 다운 메뉴(1020a, b)에서 다양한 컬러 및 타입을 포함한다. 적어도 몇몇 다른 예시적인 실시 예(도시되지 않은)에서, 사용자 인터페이스는 도시된 것과 다를 수 있다. 예를 들어, 도 10a 내지 도 10c에 도시 된 텍스트 기반 드롭 다운 메뉴(1020a, b) 대신에. UI 모듈은 검색될 수 있는 패싯을 나타내는 사용자 선택 가능한 이미지의 어레이를 사용자에게 제공 할 수 있으며, 이는 도 12a 및 도 12c에 표시된 것과 유사하다. 추가적으로 또는 대안적으로, 적어도 일부 예시적인 실시 예에서, 의복 타입 메뉴(1020a)는 \"상체 의복\" 및 \"하체 의복\"중 적어도 하나를 포함하고, \"상체 의복 컬러\" 및 \"하체 의복 컬러\" 중 대응하는 적어도 하나가 의복 컬러 및/또는 패턴 메뉴에서 묘사된다 사용자가 검색 버튼을 선택함으로써 제공하는 패싯 검색 시작 사용자 입력에 응답하여, 시스템은 패 싯에 대한 하나 이상의 비디오 레코딩을 검색한다. 시스템은 바디/얼굴 검색을 위해 상기 기술한 바와 같 이 컨볼루션 신경 네트워크와 같은 적절하게 트레이닝 된 인공 신경 네트워크를 사용하여 검색을 수행할 수 있 다. 시스템은 패싯을 묘사하는 패싯 이미지 검색 결과를 디스플레이에 표시하며, 상기 패싯 이미지 검색 결과는 검색된 하나 이상의 비디오 레코딩으로부터 선택된다. 적어도 도시 된 예시적인 실시 예에서, 패싯 이미 지 검색 결과는 이미지 검색 결과에 공통적 인 관심 대상의 타입과 함께 패싯을 묘사한다. 위에서 언급한 바와 같이, 컨벌루션 신경 네트워크와 같은 신경 네트워크는 검색 결과를 생성하는 데 사용될 수 있다. 적어도 일부 예시적인 실시 예에서, 신경 네트워크는 패싯 자체뿐만 아니라 그와 같은 패싯 각각에 대한 신뢰 수준을 결과로서 출력한다. 시스템은 패싯 각각에 대한 신뢰 수준을 일치 가능성 임계 값과 비교할 수 있고 일치 가능성 임계 값을 초과하는 결과만을 표시 할 수 있다. 시스템이 다중 패싯(예를 들면: 성별 : 남성 [제 1 패싯] 및 의복 타입: 티셔츠[제 2 패싯])을 검색하는 경우, 시스템은 패싯 각각의 신뢰 수준을 합산 하여 검색 결과에 대한 전체 점수를 결정하며, 적어도 일부 실시 예에서 전체 점수가 일치 가능성 임계 값을 초 과하는 경우에만 결과를 표시 할 수 있다. 예를 들어 성별: 남성 및 의복 타입: 티셔츠에 대한 패싯 검색이 수 행되고 검색 결과의 이미지 중 하나가 패싯 각각에 대해 85%의 일치 신뢰 수준을 리턴하는 경우, 그와 같 은 이미지는 패싯 중 하나에 대해 85%, 다른 패싯에 대해 75%의 일치 신뢰 수준을 리턴 하는 경쟁 이미지보다 높게 등급이 매겨진다. 도 10d는 도 4-8b 에 도시된 것과 유사한 인터페이스를 사용하여 패싯 이미지 검색 결과를 도시하는 페이지 를 도시한다. 앞서 설명한 바디/얼굴 검색과 유사하게, 결과를 포함하는 이미지 검색 결과는 n 개의 행과 m 개의 열로 구성된 배열로 배열되며, 상기 이미지 검색 결과는 패싯을 도시할 가능성이 낮은 이미지 검색 결과 보다 높은 열에 도시된 패싯을 도시할 가능성이 높다. 도 4-8b의 실시 예와는 대조 적으로, 패싯 이미지 검색 결과가 배열되는 상이한 열은 상이한 기간에 대응하지 않는다; 대신 상기 결과 의 각 행에 있는 결과는 신뢰도에 따라 왼쪽(높은 신뢰도)에서 오른쪽(낮은 신뢰도)으로 정렬된다. 도 10d"}
{"patent_id": "10-2020-7030695", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "에서, 시스템은 검색된 패싯 목록에 요약된 바와 같이, 청바지와 티셔츠를 입고 있는 남자 형 태의 관심 있는 사람을 검색하였으며, 도 10b에 도시된 메뉴의 사용자에 의해 명시된 바와 같다. 검색된 패싯 목록의 엔티티 각각은 사용자가 선택할 수 있는 \"X\"를 표시하고, 사용자가 선택하면 목록 의 해당 항목이 사라진다. 이러한 방식으로 목록으로부터 패싯을 제거하는 것은 업데이트된 패싯 검색 시작 사용자 입력을 나타내며, 시스템이 패싯의 업데이트 된 목록을 검색함으로써 패싯 이미지 검색 결과를 업데이트하게 한다. 이 같은 업데이트된 검색의 결과는 이미지 검색 결과의 n x m 어레이로 표시된 다. 적어도 일부 예시적인 실시 예에서, 이러한 방식으로 목록으로부터 패싯을 제거하는 행위는 제거된 패싯과 연관된 태그의 콘텐츠를 삭제하는 시스템에 의해 구현된다. 검색된 패싯 목록 아래에는 패싯 디스크립터에 의해 식별되는 일련의 메뉴가 있으며, 사용자가 도 10b의 메뉴에 대해 설명한 것과 유사한 방식으로 태그를 추가하거나 제거하여 검색할 패싯 태그를 추가로 수정할 수 있도록 한다. 이러한 방식으로 태그를 추가하거나 제거하는 것은 또한 업데이트된 패싯 검색 시작 사 용자 입력의 예이며, 따라서 시스템이 업데이트된 태그를 갖는 패싯을 검색함으로써 패싯 이미지 검색 결 과를 업데이트 하게한다. 도 10d의 메뉴는. 도 13a 및 13b에서 도시된 것과 같은 적어도 일부 다른 예시 적인 실시 예에서는 드롭 다운 메뉴를 포함하며, 가능한 태그를 도시하는 다양한 사용자 선택 가능 이미지는 드 롭 다운 메뉴 대신 사용자에게 제시된다. 사용자는 도 10d의 페이지로부터 직접 바디/얼굴 검색을 시작할 수 있다. 도 10d에서 도시된 바와 같이, 사용자는 제 1 이미지(410a)에있는 바디/얼굴 검색의 대상이 될 관심 있는 사람를 직접 선택할 수 있으며,컨텍스트 메뉴(도 10d에 미 도시)를 통해 관심 있는 사람에 대한 바디/얼굴 검색을 직접 시작한다. 이와 같은 실시 예에서, 컨텍스트 메뉴를 통해 검색을 시작하라는 신호를 사용자로부터 수신하는 시스템은 관심 대상 검색 시작 사용자 입력의 일례이다. 관심 대상 검색 시작 사용자 입력에 응답하여, 시스템은 관심 대상에 대해 하나 이상의 비디오 레코딩을 검색한다. 적어도 일부 예시적인 실시 예에서, 검색은 패싯 이미지 검색 결과가 선택된 하나 이상의 비디오 레 코딩으로 제한되지 않으며; 예를 들어, 시스템은 패싯 검색을 수행할 때 검색된 동일한 비디오 레코딩을 검색할 수 있다. 적어도 일부 다른 예시적인 실시 예에서, 검색되는 하나 이상의 비디오 레코딩은 패싯 이미지 검색 결과가 선택된 하나 이상의 비디오 레코딩이고, 관심 대상 검색 결과는 이들 하나 이상의 비디오 레코딩으 로부터 선택된다. 시스템이 관심 대상 검색을 수행한 후, 디스플레이에서 관심 대상 검색 결과를 표시한다. 패싯 검색을 수행할 때도 검색된 비디오 레코딩에 대해 관심 대상 검색이 수행되는 이러한 예시적인 실시예 중 적어도 일부에서, 관심 대상 검색 결과는 관심 대상 및 패싯을 도시한다. 상기 관심 대상 검색 결과 는 도 4-8b에 도시된 페이지와 유사한 도 10e의 사용자 인터페이스 페이지에 도시 된다. 도 10e는 또한 선택될 때 도 10d의 패싯 목록 및 메뉴를 불러오는 패싯 수정 요소를 도시하 며, 사용자가 원하는 경우 패싯 검색을 수정하고 다시 실행할 수 있도록 한다. 적어도 일부 예시적인 실시 예 에서, 사용자가 패싯 수정 요소를 선택하는 것에 응답하여, 목록 및 메뉴가 불러들여지며, 도시된 패싯 검색 결과가 가초로 하는 패싯 태그를 보여 준다. 바로 앞서 설명한 관심 대상 검색은 하나 이상의 패싯 검색 후에 수행된다. 적어도 일부 예시적인 실시 예에서, 관심 대상검색은 패싯 검색이 수행되기 전에 수행될 수 있다. 예를 들어, 바디/얼굴 검색이 수행될 수 있고, 이 러한 이미지 검색 결과는 도 4-8b 의 실시 예에 따라 표시된다. 적어도 일부 예시적인 실시 예에서, 시스템 은 그 이미지 검색 결과에 나타나는 패싯을 식별하고, 디스플레이에 이러한 패싯의 목록을 표시한다. 그런 다음 사용자는 패싯 검색 시작 사용자 입력을 나타내는 패싯 목록에서 패싯을 선택한다. 그 다음, 시스템 은 패싯에 대한 관심 대상 검색 결과가 선택되는 하나 이상의 비디오 레코딩을 검색하고, 이어서 그와 같은 패 싯과 함께 관심 대상을 보여주는 패싯 검색 결과를 디스플레이 한다. 이제 도 11a-11e에서, 다른 예시적인 실시 예에 따라, 자연 언어(natural language) 패싯 검색이 수행될 때 다 양한 상태의 사용자 인터페이스 페이지 또는 그 일부가 도시된다. 도 11a는 사용자로부터 자연 언어 텍스 트 쿼리(text query)를 수신하도록 구성된 자연 언어 검색 박스를 포함하는 페이지를 도시한다. 사 용자는 키보드 및/또는 받아쓰기 도구와 같은 입력 장치를 사용하여 쿼리를 입력할 수 있다. 적어도 일부 예시 적인 실시 예에서, 자연 언어 검색 처리 엔진은 컨텍스트 프리 문법 분석 트리, 종속성 문법 파서(grammar parser), 확률 파서 및 단어 임베딩 중 임의의 하나 이상을 사용할 수 있다. 도 11b는 시스템이 처리할 수 있는 예시적인 자연 언어 검색 질의를 나열하는 텍스트 박스를 도시한 다. 한 가지 쿼리 예는 \"오늘 오전 10 시 부터 11시 사이에 흰색 스웨터를 입은 노인 여성\"이다. 여기서 관심 대상은 사람이고 패싯은 그녀의 나이(노인), 성별(여성), 그녀의 의복 타입(스웨터), 의복의 컬러(흰색)이다. 또 다른 쿼리 예는 \"오늘 [00:00] 경에 적색 셔츠를 입은 갈색 헤어 남자\"이다. 여기서 관심 대상은 다시 사람 이고 패싯은 그의 헤어 컬러(갈색), 그의 의복 타입(셔츠), 의복의 컬러(적색)이다. 시스템은 비 패싯 제 한으로 검색을 추가로 제한하는데, 이는 이들 두 예에서 검색될 비디오 레코딩의 시간 및 날짜를 포함한다. 도 11d는 유사하게 \"적색 셔츠를 입고 콧수염을 가진 남자가 오늘 오후 8시 - 9시\"에 대한 예시적인 자연 언어 검 색 쿼리를 도시한다. 이 예에서 관심 대상은 사람이고 패싯은 얼굴 털(콧수염), 의복 타입(셔츠), 의복 컬러(적 색)이며 시간과 날짜에 대한 추가 검색 제약이 있다. 도 11c는 자연 언어 검색 질의에 응답하여 검색될 수 있는 다양한 데이터 수집을 도시한다. 비디오에 더 하여, 시스템은 모션, 이벤트, 번호판, 이미지 섬네일, 텍스트, 알람 및 북마크 중 임의의 하나 이상을 검 색할 수 있다. 적어도 일부 예시적인 실시 예에서, 시스템은 도 11b-11d 에 도시된 타입의 질의를 수신 한 직후에 패싯 검색을 수행한다. 적어도 몇몇 다른 예시적인 실시 예에서, 시스템은 먼저 도 11e 의 패싯 검색 메뉴 를 사용자에게 디스플레이 하여서 시스템이 자연 언어 검색 쿼리로부터 수집한 데이터를 확인하도록 한다. 도 11e의 메뉴는 검색 쿼리를 한마디 한마디 그대로 표시하고, 시스템은 질의를 해석하 는 방법에 따라 태그 선택기(1010,1016,1018)를 설정한다. 사용자는 원하는 대로 선택기(1010, 1016, 1018)를 수동으로 조정할 수 있다. 메뉴는 또한 일단 선택되면 시스템이 상기 기술한 바와 같이 패싯 검색을 수행하게 하는 검색 버튼을 포함한다. 도 12a 및 12b 에 도시된 것과 같은 적어도 일부 상이한 예시적인실시 예에서. 가능한 패싯을 도시하는 다양한 사용자 선택 가능 이미지가 도 11e에 도시된 드롭 다운 메뉴 대신 사용자에게 제공된다. 상술한 패싯 검색은 다음에 설명하는 바와 같이 트레이닝 된 인공 신경 네트워크를 이용하여 수행될 수 있다. 후술하는 실시예를 포함하는 적어도 일부 예시적인 실시 예에서, 인공 신경 네트워크는 컨볼루션 신경 네트워크 를 포함한다. 적어도 일부 예시적인 실시 예에서, 트레이닝 이미지는 컨볼루션 신경 네트워크를 트레이닝하기 위해 사용된다. 사용자는 예를 들어 트레이닝 이미지에 걸쳐 공통되는 패싯 타입과 함께 표시되는 관심 대상 타입을 묘사하는 이미지를 선택함으로써 트레이닝 이미지를 포함하는 패싯 이미지 트레이닝 세트를 생성한다. 예를들어, 적어도 일부 예시적인 실시 예에서 시스템은 이미지의 집합을 사용자에게 디스플레이하고, 사용자는 사용자가 시 스템이 인식하도록 트레이닝 시키고자 하는 패싯 타입을 묘사하는 이미지를 선택한다. 예를 들어, 시스템 은 사용자에게 잠재적인 트레이닝 이미지 세트를 보여줄 수 있으며, 이 같은 이미지의 서브 세트는 갈색 헤어(패싯)를 가진 사람(대상)을 묘사한다. 그런 다음 사용자는 트레이닝 세트를 구성하는 트레이닝 이미지로서 갈색 헤어를 가진 사람을 보여주는 이미지만 선택한다. 모든 트레이닝 이미지가 공통 타입의 패싯과 함께 공통 타입의 객체를 표시하지만 다른 트레이닝 이미지는 다른 사람을 표시할 수 있다. 상기 트레이닝 이미지는 카메 라 중 하나에 의해 캡처된 이미지로부터 유도된 이미지 칩을 포함할 수 있으며, 여기서 \"칩\"은 경계 박스 내의 부분과 같은 선택된 비디오 레코딩의 프레임 부분에 대응하는 영역이다. 패싯 이미지 트레이닝 세트가 생성되면, 그 같은 타입의 패싯을 포함하는 샘플 이미지가 네트워크에 입력될 때 그 같은 트레이닝 세트를 포함하는 트레이닝 이미지에 묘사된 패싯 타입을 분류하기 위해 인공 신경 네트워크를 트레이닝 시키는 데 상기 패싯 이미지 트레이닝 세트가 사용된다. \"샘플 이미지\"의 예는 위에서 설명한 패싯 검 색에서와 같이 네트워크가 트레이닝 된 후 검색된 비디오 레코딩 중 하나의 일부를 포함하는 이미지이다. 트레 이닝 중에는 최적화 방법(예를 들면: 확률적 경사 하강법과 같은) 및 수치적 경사 계산 방법(예를 들면: 역 전 파)을 사용하여 목적 함수(손실 함수라고도 함)를 최소화하는 매개 변수 집합을 찾는다. 교차 엔트로피 함수는 도시된 예시적인 실시 예에서 목적 함수로서 사용된다. 이 같은 함수는 현재 학습된 모델이 덜 정확한 때(즉, 패싯을 잘못 분류하는 때) 높은 값을 사용하고, 현재 트 레이닝 된 모델이 더욱 정확한 때(즉, 패싯을 올바르게 분류되는 때) 낮은 값을 사용하도록 정의된다. 따라서 트레이닝 과정은 최소화 문제로 축소된다. 가장 정확한 모델을 찾는 과정은 트레이닝 과정이고, 매개 변수 집합 이 있는 결과 모델은 트레이닝 된 모델이며, 매개 변수 집합은 일단 배포되면 변경되지 않는다. 일부 예시적인 실시 예에서 사용자는 트레이닝 세트를 생성하지만, 다른 예시적인 실시 예에서는 트레이닝 세트가 트레이닝을 위해 인공 신경 네트워크에 제공된다. 예를 들어, 제 3자가 트레이닝 세트를 제공할 수 있고, 다음에 사용자는 그 트레이닝 세트를 인공 신경 네트워크에 제공 할 수 있다. 트레이닝 동안, 시스템은 컨벌루션 신경 네트워크의 상이한 상태에 대응하는 상태 데이터를 기록한다. 적 어도 일부 예시적인 실시 예들에서, 상태 데이터는 트레이닝 이미지들에게 공통인 패싯 타입 적어도 하나, 트레 이닝을 수행하는 사용자의 식별 자격 증명, 트레이닝 이미지, 캡처에 사용되는 카메라들에 걸쳐 공통된 패싯 타 입 중 적어도 하나, 트레이닝 이미지, 트레이닝 이미지의 타임 스탬프, 트레이닝이 시작된 시간과 같은 데이터 를 인덱스 하도록 한다. 예를 들어, 적어도 일부 예시적인 실시 예에서 시스템은 네트워크의 이전 상태에 대응하는 인덱스 데이터를 수신하고, 그와 같은 이전 상태에 대한 인덱스 데이터에 인덱싱된 상태 데이터를 적 재함으로써 그와 같은 이전 상태로 복귀한다. 이를 통해 사용자가 실패했다고 판단하는 경우 네트워크 트레이닝 을 취소 할 수 있다. 예를 들어, 사용자가 특정 타입의 패싯이 현재 관련성이 없다고 결정하면 상기 네트워크는 그 같은 타입의 패싯을 분류하도록 트레이닝 되기 이전의 이전 상태로 되돌려진다. 이와 유사하게, 시간에 기 초하여 이전 네트워크 상태로의 복귀가 바람직할 수 있으며, 이 경우 인덱스 데이터는 원하지 않는 트레이닝이 시작되기 이전의 시간 또는 다른 사용자에 의해 수행된 불량한 트레이닝을 효과적으로 제거하기 위해 운영자 자 격 증명을 포함할 수 있다. 적어도 일부 예시적인 실시 예에서, 시스템은 둘 이상의 사용자가 컨볼루션 신경 네트워크를 트레이닝시키 는 것을 허용할 수 있다. 특히, 시스템은 사용자 단위로 상태 데이터를 기록한다. 네트워크에 다른 트레이 닝 입력을 제공하는 네트워크를 트레이닝 하는 사용자마다 다르게 트레이닝할 수 있다. 트레이닝 후, 시스템 은 신경 네트워크를 다르게 트레이닝 한 각각의 사용자로부터 발생하는 상이한 사용자 상태와 함께 신경 네트워크의 상이한 상태(각각 \"사용자 상태\")를 적절히 저장할 수 있다. 적어도 일부 예시적인 실시 예에서, 상 이한 사용자는 네트워크를 트레이닝 할 때 동일한 트레이닝 이미지 중 적어도 일부를 사용한다. 검색은 신경 네트워크의 여러 사용자 상태가 사용될 수 있는 경우 하나 이상의 방법으로 수행될 수 있다. 적어도 일부 예시적인 실시 예에서, 검색은 신경 네트워크의 단일 상태만을 사용하여 수행될 수 있다. 예를 들 어, 네트워크가 특정 사용자 상태에 있도록 이전에 네트워크를 트레이닝 시킨 사용자는 검색에 해당 사용자 상 태만 사용하기를 원할 수 있다. 따라서 네트워크는 한 세트의 사용자 상태만 적용하여 생성되는 그 같은 검색 결과 세트만을 출력한다. . 일부 다른 예시적인 실시 예에서, 검색은 다수의 사용자 상태를 사용하여 수행될 수 있다. 이러한 예시적인 실 시 예들 중 적어도 일부에서, 패싯 검색에 응답하여, 네트워크는 패싯 이미지 검색 결과의 경쟁 세트를 출력하 며, 이들 각각의 세트(각각 \"중간 결과\")가 상이한 사용자 상태를 적용함으로써 발생한다. 시스템은 중간 결과에 기초하여 단일의 최종 세트인 패싯 이미지 검색 결과를 검색을 요청한 사용자에게 생성하고 출력한다. 이것은 여러 가지 방법으로 수행될 수 있다. 시스템은 경쟁하는 중간 검색 결과에 가중치를 할당하고 이러한 가중치에 기초하여 최종 검색 결과를 결정 할 수 있다. 예를 들어, 적색 모자를 쓴 사람에 대해 패싯 검색이 수행될 수 있다. 세 명의 다른 사용자에 의해 트레이닝된 신경 네트워크는 시스템이 각각 중간 검색 결과를 생성하기 위해 비디오 레코딩을 검색하는 데 사용하는 세 가지 다른 사용자 상태를 갖는다. 첫 번째 중간 결과는 이미지 1, 이미지 2 및 이미지 3으로 구성 된다. 두 번째 중간 결과는 이미지 1, 이미지 2 및 이미지 4를 포함한다. 세 번째 중간 결과는 이미지 1, 이미 지 5 및 이미지 6을 포함한다. 이미지 1이 중간 결과에서 세 번 나타나므로, 가중치 3이 할당된다. 유사하게 이 미지 2에는 가중치 2가 할당되고 각 이미지 따라서 시스템은 이미지 1이 적색 모자를 묘사할 가능성이 가 장 높은 것으로 최종 패싯 이미지 검색 결과를 결정한다. 이미지 2는 적색 모자를 묘사할 가능성이 두 번째로 높은 것이다. 이미지 3-6은 동점이며, 적색 모자를 묘사할 가능성이 가장 낮다. 적어도 일부 예시적인 실시 예 에서, 시스템은 임계 가중치를 만족하는 중간 결과로부터의 이미지만을 최종 결과로서 디스플레이 할 수 있다. 예를 들어 임계 값 가중치가 2이면 이미지 1과 2 만 최종 결과로 표시된다. 위에서 언급한 바와 같이, 신경 네트워크는 검색 결과에 반환되는 각 이미지와 함께 신뢰 수준을 반환합니다. 신경 네트워크에 여러 사용자 상태가있는 경우 각 상태의 네트워크는 결과로 반환되는 각 이미지에 대한 신뢰 수준을 반환합니다. 최종 검색 결과에서 이미지의 신뢰 수준을 결정하기 위해 각 사용자 상태에서 네트워크가 반환 한 해당 이미지에 대한 신뢰 수준의 단순 평균을 취합니다. 예를 들어, 바로 앞의 예에서 일치 가능성 임 계 값이 25 %라고 가정하면 이미지 2의 경우 세 가지 사용자 상태에 의해 반환 된 신뢰 수준은 첫 번째 중간 결 과에 대해 50 %, 두 번째 중간 결과에 대해 40 %, 세 번째 중간 결과에 대한 %로, 전체 신뢰 수준은 55 %입니다 일단 신경 네트워크가 트레이닝 되면 하나 이상의 샘플 이미지를 분류하는 데 사용할 수 있다. 예를 들어, 트레 이닝 후 신경 네트워크는 네트워크가 식별하도록 트레이닝 된 패싯 타입을 묘사하는지 여부를 평가하기 위해 비 디오 레코딩으로부터 가져온 여러 샘플 이미지를 분류하는 데 사용될 수 있다. 시스템은 이 같은 분류의 결과를 메타 데이터에 저장한다. 샘플 이미지가 분류된 후, 시스템은 검색된 샘플 이미지 중 어느 것이 네 트워크가 식별하도록 트레이닝 된 패싯을 묘사하는 것인가(만약 있다면)를 결정하기 위해, 메타 데이터에 액세 스함으로써 상기 기술한 바와 같이 사용자로부터의 패싯 검색 시작 입력에 응답하여 하나 이상의 샘플 이미지를 검색할 수 있다. 신경 네트워크가 서로 다른 사용자 상태를 갖는 예시적인 실시 예에서, 샘플 이미지를 분류함 으로부터 기인하는 메타 데이터는 서로 다른 상태를 구별할 수 있고, 결과적으로 이러한 서로 다른 상태 중 임 의의 하나 이상에 기초하여 검색이 수행되도록 허용 할 수 있다. 설명된 실시 예의 특정 적응 및 수정이 이루어질 수 있다. 예를 들어, 클라이언트 측 비디오 리뷰 애플리케이션 (도 1 및 2)과 관련하여, 이들은 본 명세서에서 컴퓨터 단말기에 설치된 패키징된 소프트웨어로서 설 명되었다; 그러나 일부 대안적인 예시적인 실시 예에서 UI의 구현은 웹 브라우저 애플리케이션(예를 들어,도 1 에 도시 된 다른 애플리케이션 중 하나)의 사용을 통해 덜 설치된 소프트웨어로 달성될 수 있다. 웹 브라 우저 애플리케이션은 문서(예를 들면: 웹 페이지)를 보고, 다운로드하고, 업로드하고, 검색하고, 기타 다른 방 식으로 액세스하는 데 사용되는 프로그램이다. 일부 예에서 브라우저 애플리케이션은 잘 알려진 Microsoft® Internet Explorer® 일 수 있다. 물론 Google® Chrome ™과 같은 다른 타입의 브라우저 애플리케이션도 동일 하게 사용할 수 있다. 브라우저 애플리케이션은 마크업된 페이지를 판독한다(예를 들면: HTML). 또한 브라우저 애플리케이션은 마크업된 페이지를 사용자가 웹 페이지로 렌더링 되는 것으로 해석한다. 브라우저 애플리케이션 은 컴퓨터 터미널에서 실행되어 서버 시스템의 소프트웨어 구성 요소와 협력하여 컴퓨터 터미널 사용 자가 복수의 상이한 비디오 레코딩에 나타나는 동일한 개인 또는 객체를 식별하는 것을 용이하게 하기 위해 입 력을 제공하는 것과 관련된 동작을 수행할 수 있도록 한다. 이러한 상황에서, 컴퓨터 단말기의 사용자는사용자가 비디오 레코딩과 관련하여 정보를 입력하고 수신하는 대안적인 예시적인 사용자 인터페이스를 제공 받 는다. 예시적인 실시 예가 검색을 위한 참조 이미지가 레코딩 된 비디오 내의 이미지로부터 취해진 것으로 기술되었지 만, 일부 예시적인 실시 예에서, 스캔된 사진 또는 디지털 카메라에 의해 촬영된 정지 이미지를 기반으로 검색 을 수행하는 것이 가능할 수 있다. 예를 들어 의복과 출현이 비디오 레코딩에서 볼 수 있는 것과 같을 수 있을 정도로 사진이나 기타 이미지가 최근에 촬영된 경우 특히 그렇다. 본 명세서에서 논의된 임의의 특징 또는 실시예의 임의의 부분은 본 명세서에서 논의된 임의의 다른 특징 또는 실시 형태의 임의의 부분으로 구현되거나 이들과 조합될 수 있다. 따라서, 상기 논의 된 실시예는 제한적이지 않고 예시적인 것으로 간주되며, 본 발명은 첨부 된 청구 범위에 의 해서만 제한되는 것으로 해석되어야 한다."}
{"patent_id": "10-2020-7030695", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이제 예로서 첨부된 도면을 참조할 것이다 도 1은 예시적인 실시 예에 따른 방법이 수행될 수 있는 예시적인 비디오 감시 시스템의 블록 도를 도시한다. 도 2는 도 1의 예시적인 감시 시스템 내에서 제공될 수 있는 특정 예시적인 실시 예에 따른 클라이언트 측 비디 오 리뷰 애플리케이션의 블록도를 도시한다. 도 3은 도 2의 클라이언트 측 비디오 리뷰 애플리케이션을 사용하여 구현 된 예시적인 실시 예에 따라 사용자가 관심 있는 사람에 대한 검색을 시작할 수 있도록 하는 비디오 레코딩의 이미지 프레임을 포함하는 사용자 인터 페이스 페이지를 도시한다. 도 4는 도2의 클라이언트 측 비디오 리뷰 애플리케이션을 사용하여 구현된 예시적인 실시 예에 따라, 관심 대상 사람 검색이 시작된 후 그리고 사용자가 매치 확인 사용자 입력을 제공하기 전에 생성된 이미지 검색 결과를 포 함하는 사용자 인터페이스 페이지, 얼굴 엄지 손톱 및 관심 대상 사람의 바디 엄지 손톱을 도시한다. 도 5는 도2의 클라이언트 측 비디오 리뷰 애플리케이션을 사용하여 구현된 예시적인 실시 예에 따라, 클라이언 트 측 비디오를 사용하여 구현된 예시적인 실시 예에 따라 사용자가 매치 확인 사용자 입력을 제공한 후 생성된 이미지 검색 결과, 페이스 썸네일 및 관심 사람의 바디 썸네일을 포함하는 사용자 인터페이스 페이지를 도시한 다. 도 6은 도2의 클라이언트 측 비디오 리뷰 애플리케이션을 사용하여 구현된 예시적인 실시 예에 따라, 이미지 검 색 결과를 포함하는 사용자 인터페이스 페이지, 페이스 썸네일, 그리고 관심 사람의 바디 썸네일을 도시하며, 상기 이미지 검색 결과는 사용자가 표시한 것으로 제한된다. 도 7은 도2의 클라이언트 측 비디오 리뷰 애플리케이션을 사용하여 구현된 예시적인 실시 예에 따라, 이미지 검 색 결과를 포함하는 사용자 인터페이스 페이지, 페이스 썸네일, 그리고 관심 사람의 바디 썸네일을 도시하며, 상기 이미지 검색 결과는 도 3 -6에서와는 다른 의복을 입고 있는 관심 사람을 도시한다. 도 8a 및 도 8b는 도 2의 클라이언트 측 비디오 리뷰 애플리케이션을 사용하여 구현된 예시적인 실시 예에 따라, 이미지 검색 결과를 포함하는 사용자 인터페이스 페이지, 페이스 썸네일, 그리고 관심 사람의 바디 썸네 일을 도시하며, 출현 가능성을 나타내는 막대 그래프 위에 배치된 크기 조정 가능한 윈도우가 사용되어, 제 1 기간(도 8a) 및 제 2의 긴 기간(도 8b)동안에 이미지 검색 결과를 선택하도록 한다. 도 9는 다른 예시적인 실시 예에 따라, 관심 사람에 대한 이미지 검색을 용이하게 하기 위해 사용자와 인터페이 싱하는 방법을 도시한다. 도 10a-10e은 다른 예시적인 실시 예에 따라 패싯 검색이 수행되는 동안 다양한 상태의 사용자 인터페이스 페이 지 또는 그 일부를 도시한다. 도 11a -11e는 다른 예시적인 실시 예에 따라, 자연 어 패싯 검색이 수행될 때 다양한 상태의 사용자 인터페이 스 페이지 또는 그 일부를 도시한다. 도 12a, 12b, 13a 및 13b는 추가적인 예시적인 실시 예에 따라 사용자가 다양한 패싯을 선택할 수 있는 메뉴를 도시한다. . 유사하거나 동일한 참조 번호가 도면에 도시된 유사한 예시적인 특징을 나타내기 위해 상이한 도면에서 사용될 수 있다."}
