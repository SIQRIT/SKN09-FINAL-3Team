{"patent_id": "10-2023-0063670", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0166196", "출원번호": "10-2023-0063670", "발명의 명칭": "복수의 음향 입력 신호들을 이용한 음향 처리 방법", "출원인": "주식회사 이엠텍", "발명자": "이규하"}}
{"patent_id": "10-2023-0063670", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제 1 음향 획득부에 의해 획득된 제 1 음향 입력 신호와 제 2 음향 획득부에 의해 획득된 제 2 음향 입력 신호각각을 기설정된 게인을 지닌 프리앰프 각각에 의해 하드웨어적으로 증폭시키는 하드웨어 증폭 단계와;증폭된 제 1 및 제 2 음향 입력 신호 각각을 아날로그-디지털 컨버터 각각에 의해 디지털 신호들 각각으로 변환시키는 아날로그-디지털 변환 단계와;아날로그-디지털 변환 단계에서의 디지털 신호들을 기설정된 믹싱비율에 따라서 믹서에 의해 혼합시키는 믹싱단계와;믹싱 단계에서 생성된 혼합 신호에 대하여 소프트웨어적으로 기설정된 게인만큼 증폭시키는 소프트웨어 게인 제어 단계와;소프트웨어 게인 제어 단계의 출력 신호인 증폭된 혼합 신호에 포함된 잡음을 복수개의 인공 지능 모듈들을 이용하여 제거하는 인공 지능 잡음 제거 단계와;인공 지능 잡은 제거 단계에서의 출력 신호의 무음성 구간에서 잡음을 제거하는 무음성 구간 잡음 제거 단계와;무음성 구간 잡음 제거 단계의 출력 신호를 음향 출력부에 인가하여 음 방출시키는 단계를 포함하는 것을 특징으로 하는 복수의 음향 입력 신호들을 이용한 음향 처리 방법."}
{"patent_id": "10-2023-0063670", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 인공 지능 잡음 제거 단계는 시간축 도메인 신호인 증폭된 혼합 신호를 주파수축 도메인 신호인 입력 신호(MF)로 변환시키는 단계와, 입력 신호(MF)를 입력값으로 하여 주파수 크기값의 분포에 음성이 분포되는 정도인 0과1 사이의 값인 주파수별 출력값(마스크값)을 출력하는 제 1 인공 지능 모듈을 구동시키고, 제 1 인공 지능 모듈의 주파수별 출력값(마스크값)과 입력 신호(MF)를 곱셈 연산하여 제 1 입력 신호(MF1)를 생성하는 단계와, 제 1입력 신호(MF1)를 입력값으로 하여 주파수 크기값의 분포에 음성이 분포되는 정도인 0과 1 사이의 값인 주파수별 출력값(마스크값)을 출력하는 제 2 인공 지능 모듈을 구동시키고, 제 2 인공 지능 모듈의 주파수별 출력값(마스크값)과 제 1 입력 신호(MF1)를 곱셈 연산하여 제 2 입력 신호(MF2)를 생성하는 단계와, 주파수축 도메인신호인 제 2 입력 신호(MF2)를 시간축 도메인으로 변환하여 입력 신호(MT)를 생성하는 단계와, 시간축 도메인신호인 입력 신호(MT)를 입력값으로 하여 음성이 분포되는 정도인 0과 1 사이의 값인 출력값(마스크값)을 출력하는 제 3 인공 지능 모듈을 구동시키고, 제 3 인공 지능 모듈의 출력값(마스크값)과 입력 신호(MT)를 곱셈 연산하여 제 1 출력 신호를 생성하여 출력 신호로 출력하는 단계를 포함하는 것을 특징으로 하는 복수의 음향 입력 신호들을 이용한 음향 처리 방법."}
{"patent_id": "10-2023-0063670", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 무음성 구간 잡음 제거 단계는 시간축 도메인 신호인 증폭된 혼합 신호를 기설정된 크기의 프레임 단위로 주파수축 도메인으로 변환하는 단계와, 주파수축 도메인 신호인 혼합 신호(Y(m,n))(여기서, m은 프레임이고, n은 주파수 빈)를 입력값으로 하고 잡음 추정값(N(m,n))을 출력하는 잡음 추정 알고리즘을 동작시키는 단계와, 잡음추정값(N(m,n)을 이용하여 음성 존재 확률(speech presence probability: SPP)를 계산하는 단계와, 잡음 추정값(N(m,n))을 이용하여 사후 SNR을 추정하는 단계와,시간축 도메인 신호인 증폭된 혼합 신호의 음향 압력 레벨(Sound Pressure Level: SPL)을 산정하는 단계와,음성 존재 확률(P(m,n))(SPP)와, 제 1 인공 지능 모듈의 주파수별 출력값들의 평균값(ai_mask2_avg)과, 사후SNR(SNRseq)을 이용하여 현재 프레임에 음성이 감지되는지를 판단하는 단계와, 공개특허 10-2024-0166196-3-현재 프레임에 음성이 감지된 것으로 판단된 경우, 제 1 출력 신호의 현재 프레임을 그대로 유지하는 바이패스모드를 적용하여, 현재 프레임의 제 1 출력 신호를 제 2 출력 신호로 저장하는 제 1 단계와, 현재 프레임에 음성이 감지되지 않은 것으로 판단된 경우, 제 1 출력 신호의 현재 프레임에 감쇄 처리를 위한게인을 곱셈 연산하여 제 2 출력 신호를 생성하는 제 2 단계와, 제 1 단계의 제 2 출력 신호나 제 2 단계의 제 2 출력 신호를 디지털-아날로그 컨버터(DAC)로 출력하는 단계를포함하는 것을 특징으로 하는 복수의 음향 입력 신호들을 이용한 음향 처리 방법."}
{"patent_id": "10-2023-0063670", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 현재 프레임에 음성이 감지되는지를 판단하는 단계는 음성 존재 확률(P(m,n))(SPP)과 임계값(a1)을 비교하는 제1 비교 과정과, 제 1 인공 지능 모듈의 주파수별 출력값들의 평균값(ai_mask2_avg)과 임계값(a2)을 비교하는 제2 비교 과정과, 사후 SNR(SNRseq)과 임계값(a3)을 비교하는 제 3 비교 과정을 수행하고,산정된 음성 존재 확률(P(m,n))(SPP)이 임계값(a1) 이상이고, 산정된 평균값(ai_mask2_avg)이 임계값(a2) 이상이고, 추정된 사후 SNR(SNRseq)이 임계값(a3) 이상인 경우, 음성이 감지된 것으로 판단하고, 그렇지 않으면 음성이 감지되지 않은 것으로 판단하는 것을 특징으로 하는 복수의 음향 입력 신호들을 이용한 음향 처리 방법."}
{"patent_id": "10-2023-0063670", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 음향 처리 방법은 음향 압력 레벨(SPL)과 사후 SNR에 대한 임계값(a3) 간의 관계 데이터를 이용하여 산정된 음향 압력 레벨에 대응하는 사후 SNR에 대한 임계값(a3)을 결정하는 단계를 포함하는 것을 특징으로 하는 복수의음향 입력 신호들을 이용한 음향 처리 방법."}
{"patent_id": "10-2023-0063670", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서, 음향 처리 방법은 제 1 단계에서, 현재 프레임 이후의 기설정된 개수의 프레임들에 대해서는 음성이 감지된 것으로 하여 바이패스 모드를 적용하거나 수행하는 것을 특징으로 하는 복수의 음향 입력 신호들을 이용한 음향처리 방법."}
{"patent_id": "10-2023-0063670", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 음향 처리 방법은 혼합 신호에 하울링이 포함되거나 발생된 경우에는 하울링 제거를 수행하고 하울링 제거된 혼합 신호를 소프트웨어 게인 제어 단계로 인가하거나, 혼합 신호에 하울링이 포함되지도 발생되지도 않을 경우에는 혼합 신호를 그대로 소프트웨어 게인 제어 단계로 인가하여 하울링 제거 단계를 포함하는 것을 특징으로 하는 복수의 음향 입력 신호들을 이용한 음향 처리 방법."}
{"patent_id": "10-2023-0063670", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 하울링 제거 단계에서, 기설정된 기준 주파수 범위에서 시작 주파수부터 종료 주파수까지 기설정된 기준 간격범위에 해당되는 주파수 대역별로 에너지를 산정하고, i는 기준 간격 범위의 주파수 대역의 순서이며, i는 0(시작값)부터 종료값까지의 범위의 정수이며, 하울링 제거 단계는 해당 프레임의 i번째 주파수 대역의 에너지(hw_fe)를 계산하고, i번째 주파수 대역 이외의기준 주파수 범위의 에너지(hw_reminder)를 계산하는 단계와, 에너지(hw_fe)가 에너지(hw_reminder)보다 크고, 에너지(hw_fe)가 최저 에너지(hw_re)보다 크면 하울링이 발생된 것으로 판단하고, 그렇지 않으면 하울링이 발생되지 않은 것으로 판단하는 단계를 포함하는 것을 특징으로공개특허 10-2024-0166196-4-하는 복수의 음향 입력 신호들을 이용한 음향 처리 방법."}
{"patent_id": "10-2023-0063670", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 음향 처리 방법은 하드웨어 증폭 단계와, 아날로그-디지털 변환 단계와, 믹싱 단계와, 소프트웨어 게인 제어 단계와, 디지털-아날로그 변환 단계와, 음 방출시키는 단계를 수행하는 일반 수행 모드와, 하드웨어 증폭 단계와, 아날로그-디지털 변환 단계와, 믹싱 단계와, 소프트웨어 게인 제어 단계와, 인공 지능잡음 제거 단계와, 무음성 구간 잡음 제거 단계와, 음 방출시키는 단계를 모두 수행하는 인공 지능 수행 모드중의 어느 하나의 수행 모드를 수행하는 것을 특징으로 하는 복수의 음향 입력 신호들을 이용한 음향 처리방법."}
{"patent_id": "10-2023-0063670", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예인 복수의 음향 입력 신호들을 이용한 음향 처리 방법은 제 1 음향 획득부에 의해 획득된 제 1 음향 입력 신호와 제 2 음향 획득부에 의해 획득된 제 2 음향 입력 신호 각각을 기설정된 게인을 지닌 프리앰프 각각에 의 해 하드웨어적으로 증폭시키는 하드웨어 증폭 단계와, 증폭된 제 1 및 제 2 음향 입력 신호 각각을 아날로그-디 (뒷면에 계속)"}
{"patent_id": "10-2023-0063670", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "실시예는 복수의 음향 입력 신호들을 이용한 음향 처리 방법에 관한 것으로서, 특히 무음성 구간에서는 잡음을 완전 제거하고 음성 구간에서는 잡음을 상당 부분 제거할 수 있는 복수의 음향 입력 신호들을 이용한 음향 처리 방법에 관한 것이다."}
{"patent_id": "10-2023-0063670", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "마이크로폰에 입력된 음향 입력 신호 중 음성 신호를 획득하기 위하여 잡음 신호를 추정하는 기술은 양방향 음 성 통신 시스템에서 음성 품질을 향상시키는 데 필수적인 요소이다. 추정된 잡음 신호는 양방향 통신 시스템뿐만 아니라 음향 환경 식별(acoustic environment identification), 음성 인식(speech recognition) 및 화자 식별(speaker identification) 등 다양한 시스템에서 사용될 수 있다. 마이크로폰에 입력된 잡음 신호는 정상적(stationary) 특성 및 비정상적(non-stationary) 특성을 모두 가지고 있으므로, 잡음 신호를 완벽하게 추정하는 것은 어렵다. 예를 들어, 정상적 특성을 갖는 잡음 신호는 백색 잡음 일 수 있다. 비정상적 특성을 갖는 잡음 신호는 길거리 소음 또는 카페 소음일 수 있다. 대부분의 잡음 제거 기술은 주파수 영역에서 계산된 이득 함수를 사용하여 잡음 신호를 제거하는데, 이러한 이 득 함수는 잡음 신호의 추정 값에 의존하므로 추정값만으로는 잡음을 완전히 제거하거나 상당히 제거하는 것이 곤란한 문제점이 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2017-0060108"}
{"patent_id": "10-2023-0063670", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예는 무음성 구간에서는 잡음을 완전 제거하고 음성 구간에서는 잡음을 상당 부분 제거할 수 있는 복수의 음향 입력 신호들을 이용한 음향 처리 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2023-0063670", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예인 복수의 음향 입력 신호들을 이용한 음향 처리 방법은 제 1 음향 획득부에 의해 획득된 제 1 음향 입력 신호와 제 2 음향 획득부에 의해 획득된 제 2 음향 입력 신호 각각을 기설정된 게인을 지닌 프리앰프 각각에 의 해 하드웨어적으로 증폭시키는 하드웨어 증폭 단계와, 증폭된 제 1 및 제 2 음향 입력 신호 각각을 아날로그-디 지털 컨버터 각각에 의해 디지털 신호들 각각으로 변환시키는 아날로그-디지털 변환 단계와, 아날로그-디지털 변환 단계에서의 디지털 신호들을 기설정된 믹싱비율에 따라서 믹서에 의해 혼합시키는 믹싱 단계와, 믹싱 단계에서 생성된 혼합 신호에 대하여 소프트웨어적으로 기설정된 게인만큼 증폭시키는 소프트웨어 게인 제어 단계와, 소프트웨어 게인 제어 단계의 출력 신호인 증폭된 혼합 신호에 포함된 잡음을 복수개의 인공 지능 모듈 들을 이용하여 제거하는 인공 지능 잡음 제거 단계와, 인공 지능 잡은 제거 단계에서의 출력 신호의 무음성 구 간에서 잡음을 제거하는 무음성 구간 잡음 제거 단계와, 무음성 구간 잡음 제거 단계의 출력 신호를 음향 출력 부에 인가하여 음 방출시키는 단계를 포함한다. 또한, 인공 지능 잡음 제거 단계는 시간축 도메인 신호인 증폭된 혼합 신호를 주파수축 도메인 신호인 입력 신 호(MF)로 변환시키는 단계와, 입력 신호(MF)를 입력값으로 하여 주파수 크기값의 분포에 음성이 분포되는 정도 인 0과 1 사이의 값인 주파수별 출력값(마스크값)을 출력하는 제 1 인공 지능 모듈을 구동시키고, 제 1 인공 지 능 모듈의 주파수별 출력값(마스크값)과 입력 신호(MF)를 곱셈 연산하여 제 1 입력 신호(MF1)를 생성하는 단계 와, 제 1 입력 신호(MF1)를 입력값으로 하여 주파수 크기값의 분포에 음성이 분포되는 정도인 0과 1 사이의 값 인 주파수별 출력값(마스크값)을 출력하는 제 2 인공 지능 모듈을 구동시키고, 제 2 인공 지능 모듈의 주파수별 출력값(마스크값)과 제 1 입력 신호(MF1)를 곱셈 연산하여 제 2 입력 신호(MF2)를 생성하는 단계와, 주파수축 도메인 신호인 제 2 입력 신호(MF2)를 시간축 도메인으로 변환하여 입력 신호(MT)를 생성하는 단계와, 시간축 도메인 신호인 입력 신호(MT)를 입력값으로 하여 음성이 분포되는 정도인 0과 1 사이의 값인 출력값(마스크값) 을 출력하는 제 3 인공 지능 모듈을 구동시키고, 제 3 인공 지능 모듈의 출력값(마스크값)과 입력 신호(MT)를 곱셈 연산하여 제 1 출력 신호를 생성하여 출력 신호로 출력하는 단계를 포함하는 것이 바람직하다. 또한, 무음성 구간 잡음 제거 단계는 시간축 도메인 신호인 증폭된 혼합 신호를 기설정된 크기의 프레임 단위로 주파수축 도메인으로 변환하는 단계와, 주파수축 도메인 신호인 혼합 신호(Y(m,n))(여기서, m은 프레임이고, n 은 주파수 빈)를 입력값으로 하고 잡음 추정값(N(m,n))을 출력하는 잡음 추정 알고리즘을 동작시키는 단계와, 잡음 추정값(N(m,n)을 이용하여 음성 존재 확률(speech presence probability: SPP)를 계산하는 단계와, 잡음 추정값(N(m,n))을 이용하여 사후 SNR을 추정하는 단계와, 시간축 도메인 신호인 증폭된 혼합 신호의 음향 압력 레벨(Sound Pressure Level: SPL)을 산정하는 단계와, 음성 존재 확률(P(m,n))(SPP)와, 제 1 인공 지능 모듈의 주파수별 출력값들의 평균값(ai_mask2_avg)과, 사후 SNR(SNRseq)을 이용하여 현재 프레임에 음성이 감지되는지 를 판단하는 단계와, 현재 프레임에 음성이 감지된 것으로 판단된 경우, 제 1 출력 신호의 현재 프레임을 그대 로 유지하는 바이패스 모드를 적용하여, 현재 프레임의 제 1 출력 신호를 제 2 출력 신호로 저장하는 제 1 단계 와, 현재 프레임에 음성이 감지되지 않은 것으로 판단된 경우, 제 1 출력 신호의 현재 프레임에 감쇄 처리를 위 한 게인을 곱셈 연산하여 제 2 출력 신호를 생성하는 제 2 단계와, 제 1 단계의 제 2 출력 신호나 제 2 단계의 제 2 출력 신호를 디지털-아날로그 컨버터(DAC)로 출력하는 단계를 포함하는 것이 바람직하다. 또한, 현재 프레임에 음성이 감지되는지를 판단하는 단계는 음성 존재 확률(P(m,n))(SPP)과 임계값(a1)을 비교 하는 제 1 비교 과정과, 제 1 인공 지능 모듈의 주파수별 출력값들의 평균값(ai_mask2_avg)과 임계값(a2)을 비 교하는 제 2 비교 과정과, 사후 SNR(SNRseq)과 임계값(a3)을 비교하는 제 3 비교 과정을 수행하고, 산정된 음성 존재 확률(P(m,n))(SPP)이 임계값(a1) 이상이고, 산정된 평균값(ai_mask2_avg)이 임계값(a2) 이상 이고, 추정된 사후 SNR(SNRseq)이 임계값(a3) 이상인 경우, 음성이 감지된 것으로 판단하고, 그렇지 않으면 음 성이 감지되지 않은 것으로 판단하는 것이 바람직하다. 음향 처리 방법은 음향 압력 레벨(SPL)과 사후 SNR에 대한 임계값(a3) 간의 관계 데이터를 이용하여 산정된 음 향 압력 레벨에 대응하는 사후 SNR에 대한 임계값(a3)을 결정하는 단계를 포함하는 것이 바람직하다. 또한, 음향 처리 방법은 제 1 단계에서, 현재 프레임 이후의 기설정된 개수의 프레임들에 대해서는 음성이 감지 된 것으로 하여 바이패스 모드를 적용하거나 수행하는 것이 바람직하다. 또한, 음향 처리 방법은 혼합 신호에 하울링이 포함되거나 발생된 경우에는 하울링 제거를 수행하고 하울링 제 거된 혼합 신호를 소프트웨어 게인 제어 단계로 인가하거나, 혼합 신호에 하울링이 포함되지도 발생되지도 않을 경우에는 혼합 신호를 그대로 소프트웨어 게인 제어 단계로 인가하여 하울링 제거 단계를 포함하는 것이 바람직 하다. 또한, 하울링 제거 단계에서, 기설정된 기준 주파수 범위에서 시작 주파수부터 종료 주파수까지 기설정된 기준 간격 범위에 해당되는 주파수 대역별로 에너지를 산정하고, i는 기준 간격 범위의 주파수 대역의 순서이며, i는 0(시작값)부터 종료값까지의 범위의 정수이며, 하울링 제거 단계는 해당 프레임의 i번째 주파수 대역의 에너지(hw_fe)를 계산하고, i번째 주파수 대역 이외의 기준 주파수 범위의 에너지(hw_reminder)를 계산하는 단계와, 에너지(hw_fe)가 에너지(hw_reminder)보다 크고,에너지(hw_fe)가 최저 에너지(hw_re)보다 크면 하울링이 발생된 것으로 판단하고, 그렇지 않으면 하울링이 발생 되지 않은 것으로 판단하는 단계를 포함하는 것이 바람직하다. 또한, 음향 처리 방법은 하드웨어 증폭 단계와, 아날로그-디지털 변환 단계와, 믹싱 단계와, 소프트웨어 게인 제어 단계와, 디지털-아날로그 변환 단계와, 음 방출시키는 단계를 수행하는 일반 수행 모드와, 하드웨어 증폭 단계와, 아날로그-디지털 변환 단계와, 믹싱 단계와, 소프트웨어 게인 제어 단계와, 인공 지능 잡음 제거 단계와, 무음성 구간 잡음 제거 단계와, 음 방출시키는 단계를 모두 수행하는 인공 지능 수행 모드 중의 어느 하나의 수행 모드를 수행하는 것이 바람직하다."}
{"patent_id": "10-2023-0063670", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예는, 복수의 인공 지능 모듈들의 구동에 의해서, 증폭된 신호에 포함된 잡음을 제거하면서, 무음성 구간에 서는 잡음을 완전 제거하고 음성 구간에서는 잡음을 상당 부분 제거할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0063670", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 실시예들은 도면을 통하여 상세하게 설명된다. 그러나, 이는 특정한 실시 형태에 대해 한정하려는 것 이 아니며, 설명되는 실시예들은 그 실시예들의 다양한 변경(modification), 균등물(equivalent), 및/또는 대체 물(alternative)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유 사한 참조 부호가 사용될 수 있다. 본 문서에서, \"가진다\", \"가질 수 있다\", \"포함한다\", 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 문서에서, \"A 또는 B\", \"A 또는/및 B 중 적어도 하나\", 또는 \"A 또는/및 B 중 하나 또는 그 이상\" 등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B\", \"A 및 B 중 적어도 하나\", 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 문서에서 사용된 \"제1\", \"제2\", \"첫째\", 또는 \"둘째\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 예를 들면, 제1 사용자 기기와 제2 사용자 기기는, 순서 또는 중요도와 무관하게, 서로 다른 사용자 기기를 나타낼 수 있다. 예를 들면, 본 문서에 기재된 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 바꾸어 명명될 수 있다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 문서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하도 록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성(또는 설정)된\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\"것만 을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성(또는 설정)된 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장 치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서 (generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 문서에서 사용된 용어들은 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다른 실시 예의 범위를 한 정하려는 의도가 아닐 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 문서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 문서에 사용된 용어 들 중 일반적인 사전에 정의된 용어들은 관련 기술의 문맥 상 가지는 의미와 동일 또는 유사한 의미로 해석될 수 있으며, 본 문서에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 경우에 따라서, 본 문서에서 정의된 용어일지라도 본 문서의 실시 예들을 배제하도록 해석될 수 없다. 복수의 음향 입력 신호들을 이용한 음향 처리 방법을 수행하는 음향 처리 장치는 스마트폰이나 테블릿 등과 같 은 전자 통신 장치나, 이어버드나 헤드셋 등의 스피커 장치나, 보청기 등과 같은 청음 보조 장치 등을 포함한다. 음향 처리 장치는 음향을 서로 다른 위치에서 각각 획득하여 제 1 내지 제 N 음향 입력 신호를 생성하여 프로세 서에 인가하는 음향 획득부(예를 들면, 복수의 마이크로폰들 등)와, 프로세서로부터 출력 신호(또는 최종 출력 신호)를 인가하여 음 방출하는 음향 출력부(예를 들면, 스피커 등)와, 시간 영역 또는 주파수 영역의 신호를 인 가 받아 마스크값을 각각 생성하는 복수의 인공 지능 모듈들을 구비하며, 음향 획득부로부터의 시간 영역의 제 1 내지 제 N 음향 입력 신호를 입력 받아 복수의 인공 지능 모듈들을 이용하여 잡음을 제거하는 기능과, 무음성 구간에서의 잡음 제거 기능 및 하울링 제거 기능 등을 수행하는 프로세서 등을 포함하여 구성된다. 복수의 인공 지능 모듈들 각각은 시간영역이나 주파수 영역의 신호를 입력값으로 인가 받아 잡음을 제거하는 마 스크값을 각각 추론하고, 추론된 마스크값을 각각 프로세서에 인가한다. 여기서, 복수의 인공 지능 모듈들 각각 은 예를 들면, RNN를 이용하여 딥러닝이나 기계 학습을 수행하는 알고리즘이거나, 그러한 알고리즘에 따른 연산 을 수행하여 출력하는 실행기로 구현될 수 있다. 복수의 인공 지능 모듈들 각각이 수행하는 기능들에 대해서는 하기에서 상세하게 기재된다. 프로세서는 고속 푸리에 변환(FFT) 기능과 인버스 고속 푸리에 변환(IFFT) 기능을 구비하며, 연산 기능(예를 들 면, 곱셈 기능, 아마다르 곱(element-wise multiplication 기능 등) 및 저장 기능(예를 들면, 메모리 등)을 구 비하는 전자적 및/또는 전기적 회로 장치이다. 프로세서 수행하는 음성 처리 방법은 하기에서 상세하게 설명된다. 도 1은 실시예에 따른 복수의 음향 입력 신호들을 이용한 음향 처리 방법의 순서 블록도이다. 본 실시예에서는 제 1 및 제 2 음향 획득부(10_1), (10_2)가 예시적으로 기재되고 있으나, 3개 이상의 음향 획득부들이 구비될 수도 있으며, 그에 대응하여 프리앰프(Pre-amp)와 아날로그-디지털 컨버터(ADC)도 추가적으로 구비된다. 음향 처리 방법은 제 1 음향 획득부(10_1)에 의해 획득된 제 1 음향 입력 신호(SI1)와 제 2 음향 획득부(10_2) 에 의해 획득된 제 2 음향 입력 신호(SI2) 각각을 기설정된 게인(gain)을 지닌 프리앰프 각각에 의해 하드웨어 적으로 증폭시키는 하드웨어 증폭 단계(S20_1), (S20_2)와, 증폭된 제 1 및 제 2 음향 입력 신호(SI1), (SI2) 각각을 아날로그-디지털 컨버터(ADC) 각각에 의해 디지털 신호들 각각으로 변환시키는 아날로그-디지털 변환 단 계(S22_1), (S22_2)와, 아날로그-디지털 변환 단계(S22_1), (S22_2)에서의 디지털 신호들을 기설정된 믹싱비율 에 따라서 믹서(Mixer)에 의해 혼합시키는 믹싱 단계(S24)와, 믹싱 단계(S24)에서 생성된 혼합 신호에 대하여 소프트웨어적으로 기설정된 게인(gain)만큼 증폭시키는 소프트웨어 게인 제어 단계(S30)와, 단계(S30)의 출력 신호인 증폭된 혼합 신호에 포함된 잡음을 복수개의 인공 지능 모듈들을 이용하여 제거하는 인공 지능 잡음 제 거 단계(S40)와, 단계(S40)에서의 출력 신호의 무음성 구간에서 잡음을 완전하게 제거하는 무음성 구간 잡음 제 거 단계(S50)와, 단계(S50)의 출력 신호를 음향 출력부에 인가하여 음 방출시키는 단계(S70)를 포함한다. 음향 처리 방법은 프로세서에 의해서 수행되며, 프로세서는 이러한 음향 처리 방법을 수행하는 전기적 및/또는 전자적 회로로 구현될 수 있다.제 1 음향 입력 신호(SI1)와 제 2 음향 입력 신호(SI2) 각각은 음성 이외에 잡음을 포함할 수 있는 신호들이다. 먼저, 단계(S20_1), (S20_2)에서, 프로세서는 제 1 음향 획득부(10_1)에 의해 획득된 제 1 음향 입력 신호(SI 1)와 제 2 음향 획득부(10_2)에 의해 획득된 제 2 음향 입력 신호(SI2) 각각을 기설정된 게인(gain)을 지닌 프 리앰프 각각을 이용하여 하드웨어적으로 증폭시킨다. 다음으로, 단계(S22_1), (S22_2)에서, 프로세서는 증폭된 제 1 및 제 2 음향 입력 신호(SI1), (SI2) 각각을 아 날로그-디지털 컨버터(ADC) 각각을 이용하여 디지털 신호들 각각으로 변환시킨다. 다음으로, 단계(S24)에서, 프로세서는 단계(S22_1), (S22_2)에서의 디지털 신호들을 기설정된 믹싱비율(예를 들 면, 1:1 등)에 따라서 믹서(Mixer)를 이용하여 혼합시켜서 혼합 신호를 생성한다. 다음으로, 단계(S30)에서, 프로세서는 단계(S24)에서 생성된 혼합 신호에 대하여 소프트웨어적으로 기설정된 게 인(gain)만큼 증폭시켜서 증폭된 혼합 신호를 생성한다. 단계(S20_1), (S20_2)에서의 하드웨어적인 게인 제어 시에는 음향이 너무 강하거나 약한 경우가 발생될 수 있으므로, 음향의 세밀한 조절을 위해 프로세서는 소프트 웨어적인 게인 제어를 수행한다. 다음으로, 단계(S40)에서, 프로세서는 증폭된 혼합 신호에 포함된 잡음을 복수개의 인공 지능 모듈들을 이용하 여 제거한다. 단계(S40)은 하기의 도 2에서 상세하게 설명된다. 도 2는 도 1의 인공 지능 잡음 제거 단계(S40)의 상세 순서도이다. 단계(S402)에서, 프로세서는 시간축 도메인 신호인 증폭된 혼합 신호를 주파수축 도메인 신호인 입력 신호(MF) 로 변환시키고 단계(S404)로 진행한다. 입력 신호(MF)는 주파수별 주파수 크기값을 포함한다. 단계(S404)에서, 프로세서는 입력 신호(MF)를 입력값으로 하여 주파수 크기값의 분포에 음성이 분포되는 정도인 0과 1 사이의 값인 주파수별 출력값(마스크값)을 출력하는 제 1 인공 지능 모듈을 구동시킨다. 주파수별 출력값 (마스크값)은 1에 가까울수록 해당 주파수의 음향이 음성에 가깝고 0에 가까울수록 해당 주파수의 음향이 잡음 에 가깝다는 것을 나타낸다. 프로세서는 주파수별 출력값(마스크값)과 입력 신호(MF)를 곱셈 연산하여 제 1 입 력 신호(MF1)를 생성하고 단계(S406)로 진행한다. 단계(S404)는 주파수 크기값인 입력 신호(MF)에서의 잡음을 제거하는 과정이다. 단계(S406)에서, 프로세서는 제 1 입력 신호(MF1)를 입력값으로 하여 주파수 크기값의 분포에 음성이 분포되는 정도인 0과 1 사이의 값인 주파수별 출력값(마스크값)을 출력하는 제 2 인공 지능 모듈을 구동시킨다. 프로세서 는 출력값(마스크값)과 제 1 입력 신호(MF1)를 곱셈 연산하여 제 2 입력 신호(MF2)를 생성하고, 단계(S408)로 진행한다. 단계(S406)는 제 1 인공 지능 모듈에 의해 잡음이 제거된 제 1 입력 신호(MF1)에서의 왜곡을 감소시 키는 과정이다. 단계(S408)에서, 프로세서는 주파수축 도메인 신호인 제 2 입력 신호(MF2)를 시간축 도메인으로 변환하여 입력 신호(MT)를 생성하고 단계(S410)로 진행한다. 단계(S410)에서, 프로세서는 시간축 도메인 신호인 입력 신호(MT)를 입력값으로 하여 음성이 분포되는 정도인 0 과 1 사이의 값인 출력값(마스크값)을 출력하는 제 3 인공 지능 모듈을 구동시킨다. 프로세서는 주파수별 출력 값(마스크값)과 입력 신호(MT)를 곱셈 연산하여 제 1 출력 신호를 생성하고, 종료한다. 단계(S410)에서의 출력 값(마스크값)은 주파수축 도메인에서의 잡음 제거 과정(단계(S404), (S406))에서의 출력 신호인 제 2 입력 신호 (MF2)를 다시 시간축 도메인으로 변환하면서 생기는 신호의 왜곡들(또는 음성 왜곡들)을 제거하거나 개선하는 기능으로서, 제 1 출력 신호는 이러한 왜곡이 개선된 신호이며, 출력 신호로서 무음성 구간 잡음 제거 단계(4 0)에서 처리된다. 상술된 단계(S404) 및 (S406)에서와 같이, 프로세서는 복수의 인공 지능 모듈들을 직렬적으로 구동시킴으로써 잡음을 보다 정확하게 추론하거나 추정하여 제거한다. 다음으로, 단계(S40)에서, 프로세서는 단계(S40)의 출력 신호인 제 1 출력 신호의 무음성 구간에서 잡음을 완전 하게 제거한다. 하기의 도 3에서 보다 상세하게 설명된다. 도 3은 도 1의 무음성 구간 잡음 제거 단계(S50)의 상세 순서도이다. 프로세서는 제 1 출력 신호의 각 프레임이 음성을 포함할 경우에는 음성 감지 인자를 '1'로 설정하여 저장하고, 음성을 포함하지 않을 경우에는 음성 감지 인자를 '0'으로 설정하여 저장한다. 또한, 프로세서는 음성 감지(speech detection) 인자의 개수를 나타내는 음성 감지 횟수(speech detection count) 인자를 저장한다. 단계(S502)에서, 프로세서는 시간축 도메인 신호인 증폭된 혼합 신호를 기설정된 크기의 프레임 단위로 주파수 축 도메인으로 변환하고 단계(S504)로 진행한다. 단계(S504)에서, 프로세서는 주파수축 도메인 신호인 혼합 신호(Y(m,n))(여기서, m은 프레임이고, n은 주파수 빈)를 입력값으로 하고 잡음 추정값(N(m,n))을 출력하는 잡음 추정 알고리즘(예를 들면, IMCRA(Improved Minima Contolled Recursive Averaging)을 동작시킨다. 프로세서는 단계(S504)를 수행하고 단계(S506) 및 단계(S508) 각각으로 진행한다. 단계(S506)에서, 프로세서는 잡음 추정값(N(m,n)을 이용하여 음성 존재 확률(speech presence probability: SPP)를 계산한다. 프로세서는 하기의 수학식 1을 이용하여 음성 존재 확률(P(m,n))을 산정한다. 수학식 1"}
{"patent_id": "10-2023-0063670", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 혼합 신호(Y(m,n))는 음성 이외에 잡음을 포함할 수 있는 음향 신호이고, 이고, 이며, TS는 S(m,n)의 임계점으로, 1보다 큰 값으로 설정되며, TR는 R(m,n)의 임계점이며, 이들 임계점들은 환경에 따라서 가변될 수 있다. 또한, 잡음이 제거된 음향 신호 은 하기의 수학식 2를 이용하여 산정된다. 수학식 2"}
{"patent_id": "10-2023-0063670", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "프로세서는 산정된 음성 존재 확률(P(m,n))(SPP)을 저장하고 단계(S508)로 진행한다. 단계(S508)에서, 프로세서는 단계(S504)에서의 잡음 추정값(N(m,n))을 이용하여 사후 SNR을 추정한다. 프로세서 는 하기의 수학식 3을 이용하여 사후 SNR을 추정한다. 수학식 3 프로세서는 사후 SNR(SNRseq)을 저장하고 단계(S510)를 수행한다. 단계(S510)에서, 프로세서는 시간축 도메인 신호인 증폭된 혼합 신호의 음향 압력 레벨(Sound Pressure Level: SPL)을 산정한다. 프로세서는 단계(S510)를 수행하고, 단계(S512)로 진행한다. 단계(S512)에서, 프로세서는 음향 압력 레벨과 사후 SNR에 대한 임계값(a3) 간의 관계 데이터를 이용하여 산정 된 음향 압력 레벨에 대응하는 사후 SNR에 대한 임계값(a3)을 결정한다. 하기의 표 1은 음향 압력 레벨과 사후 SNR에 대한 임계값(a3) 간의 관계 데이터의 예시이다. 표 1 SPL(dB) 관계식(x는 SPL, y는 사후 SNR에 대한 임계값(a3) 34~39 y=-0.2377x+16.0807 39~45 y=-0.8516x+39.8702 45~48 Y=-0.4588x+22.3409 표 1에서와 같이, 사후 SNR에 대한 임계값(a3)은 고정된 값이 아니라, 산정된 현재의 음향 압력 레벨에 따라서, 즉 주변 음향 환경에 따라서 결정된다. 음향 압력 레벨과 사후 SNR에 대한 임계값(a3) 간의 관계 데이터에 포함 되는 관계식들은 복수의 음향 압력 레벨 범위들 각각에서 서로 상이한 기울기를 지니게 된다. 프로세서는 단계(S512)를 수행하고, 단계(S514)로 진행한다. 단계(S514)에서, 프로세서는 현재 프레임에 음성이 감지되는지를, 즉 현재 프레임이 음성 구간인지를 판단한다. 프로세서는 3개의 파라미터들을 이용한다. 3개의 파라미터들은 음성 존재 확률(P(m,n))(SPP)와, 제 1 인공 지능 모듈의 주파수별 출력값들의 평균값(ai_mask2_avg)과, 사후 SNR(SNRseq)을 포함한다. 프로세서는 음성 존재 확률(P(m,n))(SPP)과 임계값(a1)을 비교하는 제 1 비교 과정과, 제 1 인공 지능 모듈의 주파수별 출력값들의 평균값(ai_mask2_avg)과 임계값(a2)을 비교하는 제 2 비교 과정과, 사후 SNR(SNRseq)과 임 계값(a3)을 비교하는 제 3 비교 과정을 수행한다. 제 1 비교 과정에서, 음성 존재 확률(P(m,n))(SPP)은 단계(S506)에서 산정된 것이고, 임계값(a1)은 실험적으로 결정된 값으로 예를 들면, 0.40798이다. 산정된 음성 존재 확률(P(m,n))(SPP)이 임계값(a1) 이상인 경우, 프로 세서는 음성이 감지된 것으로 판단한다. 제 2 비교 과정에서, 프로세서는 제 1 인공 지능 모듈의 주파수별 출력값들의 평균값(ai_mask2_avg)을 산정하고, 임계값(a2)은 실험적으로 결정된 값으로 예를 들면, 0.50747이다. 산정된 평균값(ai_mask2_avg)이 임 계값(a2) 이상인 경우, 프로세서는 음성이 감지된 것으로 판단한다. 제 3 비교 과정에서, 사후 SNR(SNRseq)은 단계(S508)에서 추정된 것이고, 임계값(a3)은 단계(S512)에서 설정된 값이다. 추정된 사후 SNR(SNRseq)이 임계값(a3) 이상인 경우, 프로세서는 음성이 감지된 것으로 판단한다. 프로세서는 제 1 내지 제 3 비교 과정에서, 모두 음성이 감지된 것으로 판단할 경우에는, 단계(S516)로 진행하 고, 그렇지 않으면 단계(S518)로 진행한다. 단계(S516)에서, 프로세서는 현재 프레임에 음성이 감지된 것으로, 즉 현재 프레임이 음성 구간인 것으로 판단 하고, 현재 프레임의 음성 감지 인자를 '1'로 설정하여 저장하며, 음성 감지 횟수 인자를 '1'만큼 증가시킨다. 프로세서는 단계(S516)를 수행하고 단계(S518)로 진행한다. 단계(S518)에서, 프로세서는 제 1 출력 신호의 현재 프레임에 음성이 포함되어 있으므로, 감쇄 처리 없이 제 1 출력 신호의 현재 프레임을 그대로 유지하는 바이패스 모드를 적용하고, 현재 프레임의 제 1 출력 신호를 제 2 출력 신호로 저장하고, 단계(S524)로 진행한다. 단계(S520)에서, 프로세서는 현재 프레임에 음성이 감지되지 않은 것으로, 즉 현재 프레임이 무음성 구간인 것으로 판단하고, 현재 프레임의 음성 감지 인자를 '0'로 설정하여 저장하며, 음성 감지 횟수 인자를 이전과 동일 하게 유지시킨다. 프로세서는 단계(S520)를 수행하고 단계(S522)로 진행한다. 단계(S522)에서, 프로세서는 제 1 출력 신호의 현재 프레임에 게인(-90Db)을 곱셈 연산하여 게인을 적용하여, 감쇄 처리를 수행하여 제 2 출력 신호를 생성한다. 즉, 프로세서는 게인(-90dB)을 적용하여 무음성 구간에서의 잡음을 완전하게 제거한다. 프로세서는 단계(S522)를 수행하고 단계(S524)로 진행한다. 단계(S524)에서, 프로세서는 단계(S518)에서의 제 2 출력 신호나 단계(S522)에서의 제 2 출력 신호를 음향 출력 부에 인가하여 음 방출시킨다. 음성 감지 인자들이 예를 들면, '0101'일 경우, 제 2 출력 신호는 감쇄 처리 모드 - 바이패스 모드 - 감쇄 처리 모드 - 바이패스 모드의 순서로 처리된 음향이 음 방출된다. 이러한 빈번한 모드 변경이 있을 경우, 음향이 꺼 졌다가 켜졌다 하는 것과 같이, 사용자가 음향이 끊어지는 것을 느끼게 된다. 이러한 점을 방지하기 위해, 프로 세서는 하기와 같이 바이패스 모드를 수행한다. 프로세서는 현재 프레임에서 음성 감지가 된 경우, 현재 프레임 이후의 기설정된 개수(예를 들면, 125개)의 프 레임들에 대해서는 단계(S516) 및 (S518)에서와 같이, 음성이 감지된 것으로 하여 바이패스 모드를 적용하거나 수행한다. 그리고, 프로세서는 기설정된 개수의 프레임들 이후의 프레임에서 단계(S502) 내지 (S514)를 수행하 여, 그 프레임에서 음성이 감지가 되지 않은 경우에는 단계(S520) 내지 (S524)를 수행하고, 그 프레임에서 음성 이 감지가 된 경우에는 그 이후의 기설정된 개수의 프레임들에 대해서는 단계(S516) 및 (S518)에서와 같이, 음 성 감지가 된 것으로 하여 바이패스 모드를 적용하거나 수행한다. 예를 들면, 제 1 프레임-음성 감지 인자, 제 2 프레임-음성 감지 인자, 제 3 프레임-음성 감지인 경우 에, 프로세서는 제 3 프레임의 음성 감지 인자를 음성 감지 인자로 변경하는 방식으로 제 126 프레임까지 는 음성 감지 인자를 모두 로 설정하며, 즉 제 2 프레임부터 제126프레임까지의 음성 감지 인자가 모두 로 설정된다. 프로세서는 제 3 내지 제 126 프레임 각각에 대하여 단계(S514)에서의 음성 감지 여부를 판단할 수도 있고, 판단하지 않을 수도 있다. 프로세서는 음성 감지 인자의 개수를 산정하여 저장하며, 제 2 프레임~제126프레임까지의 음성 감지 인자가 모두 로 설정됨에 따라서, 제 2 프레임에서 음성 감지 인자의 개수는 1로 변경되며, 제 126 프레임까지 음성 감지 인자의 개수가 증가하여 125에 도달하면, 프로세서는 음성 감지 인자의 개수를 0으로 초기화한다. 프로세 서는 제 1 출력 신호의 제 127 프레임부터는 단계(S514)를 다시 수행하여 음성 감지 인자를 설정한다. 음 방출 단계(S70)에서, 프로세서는 아날로그 신호인 제 2 출력 신호를 음향 출력부로 인가하여 음 방출 시킨다. 다음으로, 하울링 제거 단계(S80)에 대해서 설명된다. 음향 획득부와 음향 출력부 간의 거리가 가까우면 하울링 발생빈도가 높게 되거나, 하드웨어 게인 제어(단계(S20_1), (S20_2) 등) 또는 소프트웨어 게인 제어(단계(S3 0))에 의해서도 하울링 발생빈도가 높아질 수 있다. 프로세서는 기설정된 크기의 프레임 단위로 혼합 신호에 하울링이 발생되었는지를 판단한다. 프로세서는 하울링 발생 여부를 확인하기 위해, 기설정된 기준 주파수 범위(0Hz ~ 8,000Hz)(샘플링 속도가 16000hz인 경우)에서 시 작 주파수(1,000Hz)부터 종료 주파수(8,000Hz)까지 기설정된 기준 간격 범위(320Hz)에 해당되는 주파수 대역별 로 에너지를 산정한다. 본 실시예에서, i는 기준 간격 범위의 주파수 대역의 순서를 나타내며, i는 0(시작값)부 터 22(종료값)까지의 범위의 정수이다. 예를 들면, i=0번째인 경우는 1000Hz~1320Hz의 주파수 대역이고, i=1번 째인 경우는 1320~1640Hz의 주파수 대역이다. 프로세서는 i번째 주파수 대역의 에너지(hw_fe)를 계산하고, i번 째 주파수 대역 이외의 기준 주파수 범위의 에너지(hw_reminder)를 계산한다. 또한, 프로세서는 하울링이 발생 된 경우의 기준 간격 범위의 주파수 대역의 기설정된 최저 에너지(hw_re)를 저장한다. 도 1의 음향 처리 방법은 단계(S24)와 단계(S30) 사이에, 하울링 제거 단계(S80)를 추가적으로 포함할 수 있다. 음향 처리 방법은 단계(S24)에서의 혼합 신호에 하울링이 포함되거나 발생된 경우에는 하울링 제거를 수행하고 하울링 제거된 혼합 신호를 단계(S30)로 인가하거나, 혼합 신호에 하울링이 포함되지도 발생되지도 않을 경우에 는 혼합 신호를 그대로 단계(S30)로 인가하여 단계(S30)를 수행한다. 도 4는 도 1의 하울링 제거 단계(S80)의 상세 순서도이다. 프로세서는 프레임 단위로 단계(S24)에서의 혼합 신 호에 대하여 하기의 하울링 제거 단계(S80)를 수행한다. 시작 단계에서, i는 0으로 설정된 상태이다. 단계(S804)에서, 프로세서는 해당 프레임의 i(현재는 0)번째 주파수 대역의 에너지(hw_fe)를 계산하고, i(현재 는 0)번째 주파수 대역 이외의 기준 주파수 범위의 에너지(hw_reminder)를 계산하고, 단계(S806)로 진행한다. 단계(S806)에서, 프로세서는 에너지(hw_fe)와 에너지(hw_reminder)를 서로 비교하고, 에너지(hw_fe)와 최저 에 너지(hw_re)를 서로 비교한다. 프로세서는 에너지(hw_fe)가 에너지(hw_reminder)보다 크고, 에너지(hw_fe)가 최 저 에너지(hw_re)보다 크면 하울링이 발생된 것으로 판단하여 단계(S808)로 진행하고, 그렇지 않으면 하울링이 발생되지 않은 것으로 판단하여 단계(S810)로 진행한다. 프로세서는 단계(S806)에서, 하울링이 포함된 주파수 대역의 에너지가 그 이외의 주파수 대역의 에너지와 최저 에너지보다 크다는 점을 이용한다. 단계(S808)에서, 프로세서는 해당 프레임의 혼합 신호에 포함된 하울링을 제거하기 위해, 혼합 신호에 게인(- 90dB)를 곱하여 게인을 적용하고, 해당 프레임에 대한 하울링 제거를 종료한다. 단계(S810)에서, 프로세서는 i번째 주파수 대역에는 하울링이 포함되지 않았기에, i(현재 0)를 '1'만큼 증가시 켜 i로 저장하고, 단계(S812)로 진행한다. 단계(S812)에서, 프로세서는 현재의 i가 22(최대값)보다 큰 지를 판단한다. 즉, 프로세서는 단계(S812)에서, i 가 22(최대값)인 경우까지의 주파수 대역에 하울링이 포함되었는지의 판단 과정을 수행했는지를 확인한다. 만약 i가 22보다 크면, 해당 프레임에 대한 하울링 발생 여부에 대한 판단이 모두 수행된 경우이므로, 단계(S814)로 진행하고, 그렇지 않으면 단계(S804)로 진행하여 i번째 주파수 대역에 하울링이 발생되었는지를 계속 확인한다. 단계(S814)에서, 프로세서는 해당 프레임에 하울링 발생되지 않았으므로, 혼합 신호를 그대로 유지하여 출력하 는 바이패스 모드를 수행한다. 음향 처리 장치는 사용자가 도 1의 음향 처리 방법을 수행하는 인공 지능 수행 모드(하드웨어 증폭 단계와, 아 날로그-디지털 변환 단계와, 믹싱 단계와, 소프트웨어 게인 제어 단계와, 인공 지능 잡음 제거 단계와, 무음성 구간 잡음 제거 단계와, 음 방출시키는 단계를 포함함)와, 하드웨어 증폭 단계와, 아날로그-디지털 변환 단계와, 믹싱 단계와, 소프트웨어 게인 제어 단계와, 디지털-아날로그 변환 단계와, 음 방출시키는 단계를 수행 하는 일반 수행 모드 중의 어느 하나를 선택할 수 있도록 한다. 음향 처리 장치는 입력부를 구비하고, 입력부는 사용자에 의해서 선택된 인공 지능 수행 모드와 일반 수행 모드 중의 하나의 모드 선택 입력을 프로세서에 인가 한다. 프로세서는 모드 선택 입력에 대응하는 모드를 수행한다. 다양한 실시 예에 따른 장치(예: 프로세서 또는 그 기능들) 또는 방법(예: 동작들)의 적어도 일부는, 예컨대, 프로그램 모듈의 형태로 컴퓨터로 읽을 수 있는 저장매체(computer-readable storage media)에 저장된 명령어로 구현될 수 있다. 상기 명령어가 프로세서에 의해 실행될 경우, 상기 하나 이상의 프로세서가 상기 명령어에 해 당하는 기능을 수행할 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 예를 들면, 메모리가 될 수 있다. 컴퓨터로 판독 가능한 기록 매체는, 하드디스크, 플로피디스크, 마그네틱 매체(magnetic media)(예:자기테이 프), 광기록 매체(optical media)(예: CD-ROM, DVD(Digital Versatile Disc), 자기-광 매체 (magnetoopticalmedia)(예: 플롭티컬 디스크(floptical disk)), 하드웨어 장치(예: ROM, RAM, 또는 플래시 메 모리 등)등을 포함할 수 있다. 또한, 프로그램 명령에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐 만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 상술 한 하드웨어 장치는 다양한 실시 예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성 될 수 있으며, 그 역도 마찬가지다. 다양한 실시 예에 따른 프로세서 또는 프로세서에 의한 기능들은 전술한 구성요소들 중 적어도 하나 이상을 포 함하거나, 일부가 생략되거나, 또는 추가적인 다른 구성요소를 더 포함할 수 있다. 다양한 실시 예에 따른 모듈, 프로그램 모듈 또는 다른 구성요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱 (heuristic)한 방법으로 실행될 수 있다. 또한, 일부 동작은 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상 설명한 바와 같이, 상술한 특정의 바람직한 실시예들에 한정되지 아니하며, 청구범위에서 청구하는 요지를 벗어남이 없이 당해 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 누구든지 다양한 변형의 실시가 가능한 것은 물론이고, 그와 같은 변경은 청구범위 기재의 범위 내에 있게 된다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2023-0063670", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 복수의 음향 입력 신호들을 이용한 음향 처리 방법의 순서 블록도이다. 도 2는 도 1의 인공 지능 잡음 제거 단계(S40)의 상세 순서도이다. 도 3은 도 1의 무음성 구간 잡음 제거 단계(S50)의 상세 순서도이다. 도 4는 도 1의 하울링 제거 단계(S80)의 상세 순서도이다."}
