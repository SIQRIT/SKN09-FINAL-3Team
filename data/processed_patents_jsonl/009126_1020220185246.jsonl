{"patent_id": "10-2022-0185246", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0103250", "출원번호": "10-2022-0185246", "발명의 명칭": "영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "이형극"}}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 방법에 있어서,상기 영상 콘텐츠로부터 복수의 특징 정보를 추출하는 과정;추출된 복수의 특징 정보를 인코딩하는 과정;인코딩된 복수의 특징 정보를 기반으로 하여 상기 영상 콘텐츠의 감정 및 분위기를 단계적으로 분석하는 과정;및분석 결과를 기반으로 하여 상기 영상 콘텐츠의 감정 및 분위기를 인식하는 과정을 포함하는 영상 콘텐츠에서감정 및 분위기 정보를 인식하는 방법."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 단계적으로 분석하는 과정은,콘텐츠 기본 정보를 분석하는 과정;프레임 별 시각적인 정보 및 청각적인 정보를 분석하는 과정;움직임 정보 및 픽셀 모션 정보를 분석하는 과정;전체 프레임에서 청각적인 정보를 분석하는 과정; 및상기 전체 프레임에서 등장인물 및 대화 분위기를 분석하는 과정을 포함하는 영상 콘텐츠에서 감정 및 분위기정보를 인식하는 방법."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 콘텐츠 기본 정보를 분석하는 과정은,메타데이터를 분석하는 과정; 및 상기 메타데이터를 통해 등장인물, 연출자를 포함하는 제작 정보를 분석하는 과정을 포함하는 영상 콘텐츠에서감정 및 분위기 정보를 인식하는 방법."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 프레임 별 시각적인 정보 및 청각적인 정보를 분석하는 과정은,일정 간격의 프레임을 선택하는 과정; 및상기 프레임 별 밝기 정보 및 소리 정보를 분석하는 과정을 포함하는 영상 콘텐츠에서 감정 및 분위기 정보를인식하는 방법."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 움직임 정보 및 픽셀 모션 정보를 분석하는 과정은,상기 프레임을 선택하는 과정; 및상기 프레임 별 인물 별 움직임 정보 및 픽셀 모션 정보를 분석하는 과정을 포함하는 영상 콘텐츠에서 감정 및분위기 정보를 인식하는 방법."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,공개특허 10-2024-0103250-3-상기 영상 콘텐츠의 감정 및 분위기를 인식하는 과정은,상기 움직임 정보에 따라 인접 프레임간 차이를 계산하는 과정;모션 벡터 및 옵티컬 플로우 값 중 적어도 하나를 계산하는 과정; 및계산된 값들의 절대량을 기반으로 하여 감정과 분위기를 인식하는 과정을 포함하는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 방법."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서, 상기 장면 별 청각적인 정보를 분석하는 과정은,상기 전체 프레임에서 배경음악 및 효과음 정보를 분석하는 과정을 포함하는 영상 콘텐츠에서 감정 및 분위기정보를 인식하는 방법."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서, 상기 장면 별 등장인물을 분석하는 과정은,상기 전체 프레임에서 등장인물의 표정 및 상기 등장인물 간 대화의 맥락과 감정을 통해 분위기를 분석하는 과정을 포함하는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 방법."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제2항에 있어서, 상기 감정 및 분위기를 인식하는 과정은,각 분석 과정에 대한 결과값을 생성하는 과정; 및각 결과값을 선형적 또는 비선형적으로 결합하여 지도 학습을 통해 상기 각 결과값을 통합하는 과정을 포함하는영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 방법."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제2항에 있어서, 상기 감정 및 분위기를 인식하는 과정은,각 분석 과정에 대한 결과값을 생성하는 과정; 및각 결과값을 쾌락, 긴장, 활기로 분류 및 통합하는 과정을 포함하는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 방법."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 장치에 있어서,상기 영상 콘텐츠로부터 복수의 특징 정보를 추출하는 추출부;추출된 복수의 특징 정보를 인코딩하는 인코딩부;인코딩된 복수의 특징 정보를 기반으로 하여 상기 영상 콘텐츠의 감정 및 분위기를 단계적으로 분석하는분석부; 및분석 결과를 기반으로 하여 상기 영상 콘텐츠의 감정 및 분위기를 인식하는 감정 인식부를 포함하는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 장치."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 분석부는,콘텐츠 기본 정보를 분석하고;프레임 별 시각적인 정보 및 청각적인 정보를 분석하고;움직임 정보 및 픽셀 모션 정보를 분석하고;공개특허 10-2024-0103250-4-전체 프레임에서 청각적인 정보를 분석하고; 및상기 전체 프레임에서 등장인물 및 대화 분위기를 분석하는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는장치."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 분석부는,메타데이터를 분석하고, 및 상기 메타데이터를 통해 등장인물, 연출자를 포함하는 제작 정보를 분석하는 영상콘텐츠에서 감정 및 분위기 정보를 인식하는 장치."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 상기 분석부는,일정 간격의 프레임을 선택하고; 및상기 프레임 별 밝기 정보 및 소리 정보를 분석하는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 장치."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서, 상기 분석부는,상기 프레임을 선택하고; 및상기 프레임 별 인물 별 움직임 정보 및 픽셀 모션 정보를 분석하는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 장치."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 감정 인식부는,상기 움직임 정보에 따라 인접 프레임간 차이를 계산하고, 모션 벡터 및 옵티컬 플로우 값 중 적어도 하나를 계산하고, 및 계산된 값들의 절대량을 기반으로 하여 감정과 분위기를 인식하는 영상 콘텐츠에서 감정 및 분위기정보를 인식하는 장치."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서, 상기 분석부는,상기 전체 프레임에서 배경음악 및 효과음 정보를 분석하는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는장치."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서, 상기 분석부는,상기 전체 프레임에서 등장인물의 표정 및 상기 등장인물 간 대화의 맥락과 감정을 통해 분위기를 분석하는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 장치."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서, 상기 감정 인식부는,각 분석 과정에 대한 결과값을 생성하고; 및각 결과값을 선형적 또는 비선형적으로 결합하여 지도 학습을 통해 상기 각 결과값을 통합하는 영상 콘텐츠에서감정 및 분위기 정보를 인식하는 장치."}
{"patent_id": "10-2022-0185246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항에 있어서, 상기 감정 인식부는,공개특허 10-2024-0103250-5-각 분석 과정에 대한 결과값을 생성하고; 및각 결과값을 쾌락, 긴장, 활기로 분류 및 통합하는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 장치."}
{"patent_id": "10-2022-0185246", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 영상 콘텐츠에서 감정과 분위기 정보를 단계적으로 인식하는 방법 및 장치를 제공한다. 본 개시의 실 시 예는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 방법에 있어서, 상기 영상 콘텐츠로부터 복수의 특징 정보를 추출하는 과정; 추출된 복수의 특징 정보를 인코딩하는 과정; 인코딩된 복수의 특징 정보를 기반으로 하 여 상기 영상 콘텐츠의 감정 및 분위기를 단계적으로 분석하는 과정; 및 분석 결과를 기반으로 하여 상기 영상 콘텐츠의 감정 및 분위기를 인식하는 과정을 포함한다."}
{"patent_id": "10-2022-0185246", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 방법 및 장치 에 관한 것이다."}
{"patent_id": "10-2022-0185246", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에 기술되는 내용은 단순히 본 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구성하는 것이 아니 다. 컴퓨터 비전 기술은 인간의 눈과 뇌를 통해서 처리되는 시각인지 기능을 IT 디바이스와 분석 소프트웨어를 이용 하여 실현하는 기술 분야이다. 상기 컴퓨터 비전 기술 분야가 발전하면서 인공지능 기술을 이용하여 영상 콘텐츠 내의 정보를 자동으로 인식하 는 기술이 보편화되고 있다. 다시 말해, 영상 콘텐츠를 인공지능을 기반으로 분석하여 콘텐츠를 구성하는 장소, 시간, 객체, 인물 및 행위의 종류를 자동으로 도출하려는 기술이 발전하고 있다. 그 중 콘텐츠 또는 콘텐츠의 장면 내에서 나타나는 감정과 분위기를 분석하는 것은 주관적인 판단이나 인식하는 부분이 반영되기 때문에 상 대적으로 어려운 기술로 분류할 수 있다. 상기 감정과 분위기는 콘텐츠가 명시적으로 표현하는 정보가 아니고, 장면에서 사건이나 대화 등을 통해 설명하 는 내용이나 시각적, 청각적으로 나타내는 정보 등을 통해 간접적으로 나타내는 정보이다. 따라서 상기 감정과 분위기는 인공지능을 활용하더라도 쉽게 판단할 수 없다. 따라서, 콘텐츠의 감정과 분위기를 간접적으로 표현하는 요소들을 단계적으로 분석하여 장면 및 콘텐츠의 감정 과 분위기를 인식하는 방법이 요구된다."}
{"patent_id": "10-2022-0185246", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 영상 콘텐츠 등에 특화된 감정과 분위기 정보를 판별하는 방법 및 장치를 제공한다. 본 개시는, 영상 콘텐츠를 구성하는 프레임 내 시각적 정보와 청각적 정보를 단계적으로 취합하여 감정과 분위 기 정보를 인식하는 방법 및 장치를 제공한다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제 들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0185246", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시 예는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 방법에 있어서, 상기 영상 콘텐츠로부터 복수의 특징 정보를 추출하는 과정; 추출된 복수의 특징 정보를 인코딩하는 과정; 인코딩된 복수의 특징 정보를 기반으로 하여 상기 영상 콘텐츠의 감정 및 분위기를 단계적으로 분석하는 과정; 및 분석 결과를 기반으로 하여 상기 영상 콘텐츠의 감정 및 분위기를 인식하는 과정을 포함한다. 본 개시의 실시 예는 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 장치에 있어서, 상기 영상 콘텐츠로부터 복수의 특징 정보를 추출하는 추출부; 추출된 복수의 특징 정보를 인코딩하는 인코딩부; 인코딩된 복수의 특징 정보를 기반으로 하여 상기 영상 콘텐츠의 감정 및 분위기를 단계적으로 분석하는 분석부; 및 분석 결과를 기반 으로 하여 상기 영상 콘텐츠의 감정 및 분위기를 인식하는 감정 인식부를 포함한다."}
{"patent_id": "10-2022-0185246", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시는, 영상 콘텐츠를 자동으로 분석하여 기존에 인력을 통해 감정과 분위기 정보를 분류하는 것에 비해 시 간, 자원 등을 절감할 수 있다.본 개시는, 분류된 감정과 분위기 정보를 통해서 유사한 감정 정보와 연관된 콘텐츠 관리, 유사한 감정과 분위 기를 가지고 있는 콘텐츠의 추천 등 다양한 미디어 관련 부가 서비스에 대한 활용성을 높일 수 있다. 본 개시의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재 로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0185246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 일부 실시예들을 예시적인 도면을 이용해 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면 상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 개시를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 개시에 따른 실시예의 구성요소를 설명하는 데 있어서, 제1, 제2, i), ii), a), b) 등의 부호를 사용할 수 있다. 이러한 부호는 그 구성요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 부호에 의해 해당 구성요소의 본질 또는 차례나 순서 등이 한정되지 않는다. 명세서에서 어떤 부분이 어떤 구성요소를 '포함' 또는 '구비'한 다고 할 때, 이는 명시적으로 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 개시의 예시적인 실시형태를 설명하고자 하는 것이며, 본 개시가 실시될 수 있는 유일한 실시형태를 나타내고자 하는 것이 아니다. 본 개시의 실시 예는 다양한 OTT(Over the top) 영상 콘텐츠가 생겨나고, 이를 기반으로 한 후속 서비스나 새로 운 유행이 되고 있어, 영상 콘텐츠의 새로운 제작뿐만 아니라 기존에 제작된 영상 콘텐츠를 활용하여 부가적으 로 다양한 맞춤형 서비스 제공을 위해서는 영상 콘텐츠에 포함되어 있는 정보를 지능적으로 추출할 수 있는 기 술을 제공할 수 있는 방법 가운데, 콘텐츠 내 분위기, 감정 등을 인식할 수 있는 미디어 기반 분석 방법 및 장 치를 제공한다. 보다 구체적으로, 본 개시의 실시 예는 방송, OTT, 유튜브 등 다양한 영상 콘텐츠를 이용하여 방송 콘텐츠 등에 특화된 감정과 분위기 정보를 판별할 수 있도록, 장면 또는 콘텐츠 내용을 설명하는 사건과 대화 정보 및 장면 과 콘텐츠 내용을 구성하는 시각적 정보와 청각적 정보를 단계적으로 취합하여 감정과 분위기 정보를 인식하는 방법 및 장치를 제공한다. 도 1은 본 개시의 실시 예에 따른 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 장치 블록 구성도이다. 본 개시의 실시 예에 따른 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 장치는 제어부, 추출부 , 인코딩부, 분석부, 감정 인식부 등을 포함하여 구성될 수 있다. 상기 제어부는 본 개시의 실시 예에 따른 영상 콘텐츠에서 감정 및 분위기 정보를 인식하도록 추출부 , 인코딩부, 분석부, 감정 인식부 등을 각각 제어하도록 구성될 수 있다. 상기 추출부는 영상 콘텐츠로부터 복수의 특징 정보를 추출하도록 구성될 수 있다. 복수의 특징 정보는 프 레임 별 밝기 정보 정보 및 소리 정보, 프레임 별 움직임 정보 및 픽셀 모션 정보, 장면 별 소리 정보, 및 장면 별 등장인물 표정 및 대화 분위기 정보 등을 포함할 수 있다. 상기 인코딩부는 추출된 복수의 특징 정보를 인코딩하도록 구성될 수 있다. 상기 분석부는 인코딩된 복수의 특징 정보를 기반으로 하여 영상 전체의 감정 및 분위기를 분석하도록 구 성될 수 있다. 상기 감정 인식부는 상기 분석부의 분석 결과를 기반으로 하여, 감정 및 분위기를 인식하도록 구성될 수 있다. 도 2는 본 개시의 실시 예에 따른 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 전반적인 방법을 나타낸 흐 름도이다. 상기 추출부는 201 단계에서 영상 콘텐츠로부터 복수의 특징 정보를 추출한다. 복수의 특징 정보는 프레임 별 밝기 정보 정보 및 소리 정보, 프레임 별 움직임 정보 및 픽셀 모션 정보, 장면 별 소리 정보, 및 장면 별 등장인물 표정 및 대화 분위기 정보 등을 포함할 수 있다. 상기 인코딩부는 202 단계에서 추출된 복수의 특징 정보를 인코딩한다. 상기 분석부는 203 단계에서 인코딩된 복수의 특징 정보를 기반으로 하여 영상 전체의 감정 및 분위기를 분석한다. 상기 감정 인식부는 204 단계에서 분석 결과를 기반으로 하여, 감정 및 분위기를 인식한다. 도 3은 본 개시의 실시 예에 따른 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 구체적인 방법을 나타낸 흐 름도이다. 도 3은 콘텐츠의 시간적인 분량에 따라 또는 분석하는 데에 사용할 수 있는 연산 자원에 따라 단계적 으로 감정과 분위기를 인식할 수 있는 절차를 구분한 것이다. 각 단계별 감정과 분위기를 인식하는 방법은 후술 될 도 4 내지 8에서 다시 설명하도록 한다. 상기 분석부는 301 단계에서 콘텐츠 기본 정보를 분석한다. 콘텐츠 기본 정보는 제작 정보를 포함하는 메 타데이터 등을 포함할 수 있다. 여기서, 제작 정보는 연출자(감독) 및 등장 인물 등을 포함할 수 있다. 상기 분석부는 302 단계에서 프레임의 일정 구간을 선택한 후, 프레임 별 밝기 정보 및 소리 정보 등을 분 석한다. 상기 분석부는 303 단계에서 매 프레임 별 등장인물의 움직임 또는 모션 벡터 및 옵티컬 플로우(Optical Flow)를 분석한다. 옵티컬 플로우는 관찰자와 장면 사이의 상대적인 움직임에 의해 유발되는 시각적 장면에서의 물체, 표면 및 가장자리의 명백한 움직임의 패턴을 의미한다. 즉, 옵티컬 플로우는 영상 내 물체의 움직임 패턴 을 의미한다. 상기 분석부는 304 단계에서 장면 별 소리(배경음악, 효과음 등)를 분석한다. 상기 분석부는 305 단계에서 장면 별 등장인물의 표정 및 대화 내용과 대화의 분위기 등을 분석한다. 일반적으로 미디어 콘텐츠는 등장인물의 설명이나 인물 간 대화, 또는 인물 간 이루어지는 사건 등으로 콘텐츠 의 주제와 내용을 직접적으로 표현하곤 한다. 하지만 미디어 콘텐츠가 포함하고 있는 감정과 분위기는 주관적인 성격의 정보이기도 하고, 감정과 분위기는 직접적으로 표현하기 어려운 정보이기 때문에 최근에 활발히 이용되 고 있는 인공지능 기술로 직접 추출해내기 어렵다. 감정과 분위기는 다음과 같은 방법 등으로 표현될 수 있다. 우선, 콘텐츠의 장르가 무엇인지에 따라 감정과 분위기가 정해진다. 일반적으로 다큐나 뉴스 등 시사 장르는 차 분하고 긴장감이 유지되는 반면, 예능 장르는 쾌활하고 활동적인 감정과 분위기를 전달한다. 또한 드라마는 성 격에 따라 차분하고 우울한 감정을 전달하기도, 긴박하고 불안함을 전달하기도 한다. 또한 연출자(감독)나 등장인물이 누구인지에 따라서도 감정과 분위기를 전달할 수 있다. 주로 로맨틱 코미디를 제작해온 연출자가 만드는 콘텐츠라면 쾌활하고 활발한 감정과 분위기를 포함하는 경우가 많을 수 있다. 다큐 장르를 많이 만든 연출자의 콘텐츠는 상대적으로 분위기가 무거울 수 있다. 등장인물도 꾸준한 감정과 분위기를 전달하는 연기자 또는 배우 들이 있기 때문에 특정 인물이 등장하는 것만으로도 전반적인 감정과 분위기를 짐작할 수 있다. 그리고 장면의 밝기나 소리의 크기 등으로도 감정과 분위기를 짐작할 수 있다. 활기찬 분위기를 가진 콘텐츠는 상대적으로 밝기가 높은 상태이고 전반적으로 음성, 음향 및 음악이 큰 경우가 많다. 장면 내에 움직임 정도를 이용하여 분위기를 예측할 수 있는데, 움직임이 많다면 보통 쾌활한 느낌과 활동적인 감정을 전달하게 된다. 장 면의 분위기와 감정을 가장 많이 나타내는 지표는 청각적 정보가 주를 이룬다. 이를테면 배경음악(음악)과 효과 음(음향)이 어떠한 감정과 분위기를 표현하는지에 따라 콘텐츠 또는 해당 장면의 분위기를 좌우하는 경우가 있 다. 그리고 등장인물의 표정이나 대화의 맥락과 감정이 해당 장면의 분위기를 좌우하는 경우가 있기 때문에 해 당 정보도 미디어 콘텐츠 분석에서 고려해야할 요소이기도 하다. 하지만, 등장인물의 표정을 분석하거나 나누고 있는 대화의 맥락과 감정을 분석하는 것은 프레임의 밝기나 소리 의 크기를 분석하는 작업에 비해 상대적으로 많은 연산량을 요구한다. 따라서 단계적으로 감정과 분위기를 인식 하는 방법과 절차에 차이를 두고, 연산량을 많이 요구하는 작업을 점진적으로 늘여가는 것이 효율적일 수 있다. 도 4는 본 개시의 실시 예에 따른 영상 콘텐츠에 포함된 사전에 제작된 메타데이터를 기반으로 전체적인 감정과 분위기를 인식하는 방법을 나타낸 예시도이다. 참조번호 410과 같이, 콘텐츠 메타데이터에 포함된 정보 가운데 콘텐츠의 장르 정보 등을 통해 콘텐츠가 차분한 분위기를 가지는지(다큐 장르), 활동적이며 쾌활한 분위기를 가지는지(예능 장르), 긴박하고 우울한 분위기를 가지는지(드라마) 등을 파악할 수 있다. 또한 참조번호 410과 같이 메타데이터를 이용하여 연출자(감독)가 예를 들어, 행복하고 차분한 분위기와 감정을 전달하는 작품을 기존에 만들었는지를 보고 해당 영상 콘텐츠의 감정과 분위기를 인식할 수가 있다. 도 5는 본 개시의 실시 예에 따른 영상 콘텐츠의 샘플링된 프레임이 가지고 있는 시각적 정보(밝기 등)와 청각 적 정보(음성, 음향, 음악의 크기 등)를 기반으로 감정과 분위기를 인식하는 방법을 나타낸 예시도이다. 영상 콘텐츠의 시각적 정보나 청각적 정보는 해당 장면의 분위기를 간접적으로 표현하는 경우가 많다. 예를 들 어, 밝고 화창한 장면이 나타내는 분위기는 쾌활하거나 행복한 정보일 확률이 높으며, 활동적인 장면에서는 음 악(소리)의 크기(음량)가 큰 경우가 대부분이다. 따라서, 참조번호 510과 같이, 일정 간격의 프레임(520, 530, 540)을 선택한 후, 시각적 정보 및 청각적 정보를 이용하여 영상 콘텐츠의 감정과 분위기를 인식할 수 있다. 즉, 본 개시의 실시 예는 밝기 정보 및 음량 정보 등 을 기반으로 해당 영상 콘텐츠의 감정과 분위기를 인식할 수가 있다. 이때, 전체 프레임을 일일이 확인할 필요 없이 샘플링된 몇몇 프레임(예컨대, 520, 530, 540 중 적어도 어느 하나)의 시각적 정보와 청각적 정보를 확인 하여도 대체적인 감정과 분위기를 인식할 수가 있다. 도 6은 본 개시의 실시 예에 따른 영상 콘텐츠의 프레임 간에 일어나는 등장인물 또는 배경의 움직임 정보(모션 벡터, 옵티컬 플로우 등)를 기반으로 감정과 분위기를 인식하는 방법을 나타낸 예시도이다. 이때, 참조번호 610과 같이, 움직임 정보의 특성에 따라 인접 프레임간(620-670) 차이를 계산하고, 모션 벡터나 옵티컬 플로우 값을 계산하고 이 값들의 절대량(Magnitude)을 바탕으로 감정과 분위기를 인식할 수가 있다. 움직임 정보가 적다면 차분하거나 편안하다는 분위기가 주를 이룰 것이고 움직임 정보가 크다면 활동적이거나 기민한 분위기를 나타낼 것이다. 움직임 정보를 계산해야 하는 방법의 특성 상, 도 5에서 설명한 샘플링된 프레 임의 시각적 및 청각적 정보를 기반으로 감정과 분위기 정보를 인식하는 것 보다 더 많은 연산량을 요구할 수 있다. 도 7은 본 개시의 실시 예에 따른 영상 콘텐츠의 청각적 정보(배경음악, 효과음 정보 등)를 기반으로 감정과 분 위기를 인식하는 방법을 나타낸 예시도이다. 참조번호 710과 같이, 배경음악과 효과음이 나타내는 감정과 분위기 정보가 해당 콘텐츠 및 해당 장면의 감정과 분위기를 대표하는 일이 많기 때문에 해당 방법을 사용할 수가 있다. 효과음과 배경음악을 분석해야 하기 때문 에 프레임을 샘플링하는 방법을 사용할 수가 없어, 연산량 또한 상기 도 5와 도 6의 방법보다 많을 수 있다. 도 8은 본 개시의 실시 예에 따른 영상 콘텐츠 또는 장면 내 등장인물의 표정이나 등장인물 간 대화의 맥락과 분위기를 기반으로 전체의 감정과 분위기를 인식하는 방법을 나타낸 예시도이다. 참조번호 810과 같이, 영상 콘텐츠나 장면에 나와있는 동장인물의 표정이나 등장인물 간 대화의 맥락과 분위기 는 전체 영상 콘텐츠나 장면의 감정과 분위기를 표현 할 수 있다. 즉, 본 개시의 실시 예에서는 전체 프레임 에서 표정과 대화의 맥락과 감정을 이용하여 영상 콘텐츠의 감정과 분위기를 인식할 수 있다. 상대적으로 이전에 사용한 방법 보다는 연산량이 많이 요구될 수 있다. 그래서 도 4에서 설명하는 감정 및 분위 기 인식 방법에서부터 점진적으로 인식할 때에 연산량이 증가한다는 것을 알 수가 있다. 하기 표 1은 영상 콘텐츠 내 정보를 기반으로 인식한 감정의 분류 결과값을 나타낸다. 표 1 감정 분류(쾌락) 감정 분류(긴장) 감정 분류(활기) 쾌활한 불안한 활동적인 만족한 긴박한 기만한 행복한 불안한 활발한 중립적인 중립적인 중립적인 우울한 차분한 피로한 슬픈 편안한 소극적인 인식 결과는 표 1의 예시에 나타낸 바와 같이, 쾌락(Hedonic tone) 관련 감정 분류, 긴장(Tense arousal) 관련 감정 분류 및 활기(Energetic arousal) 관련 감정 분류 등 3 가지 측면에서 감정 및 분위기를 인식하여 해당 정 보를 기록하고, 이 내용을 취합하여 결과적으로 영상 콘텐츠의 감정과 분위기를 나타낼 수 있다. 앞서 서술한 상기 5 가지 감정 및 분위기 인식 방법을 선형적 또는 비선형적으로 결합하여 지도 학습을 통해 결합 계수 등을 도출하여 최종 결과값을 통합하거나, 만들어 낼 수 있다. 본 개시의 예시적인 실시예들에 기술된 적어도 일부의 구성요소들은 DSP(Digital Signal Processor), 프로세서, 컨트롤러, ASIC(Application-Specific IC), 프로그래머블 로직소자(FPGA 등), 기타 전자소자 중의 적어도 하나 또는 이들의 조합이 포함되는 하드웨어 요소로써 구현될 수 있다. 또한, 예시적인 실시예들에서 기술된 적어도 일부의 기능(function)들 또는 처리과정(process)들은 소프트웨어로 구현될 수 있으며, 소프트웨어는 기록매체 에 저장될 수 있다. 본 개시의 예시적인 실시예들에 기술된 적어도 일부의 구성요소들, 기능들, 그리고 처리과 정들은 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시의 예시적인 실시예들에 따른 방법은 컴퓨터에서 실행될 수 있는 프로그램으로 작성될 수 있고, 마그네 틱 저장매체, 광학적 판독매체, 디지털 저장매체 등 다양한 기록 매체로도 구현될 수 있다. 본 명세서에 설명된 각종 기술들의 구현들은 디지털 전자 회로조직으로, 또는 컴퓨터 하드웨어, 펌웨어, 소프트 웨어로, 또는 그들의 조합들로 구현될 수 있다. 구현들은 데이터 처리 장치, 예를 들어 프로그램가능 프로세서, 컴퓨터, 또는 다수의 컴퓨터들의 동작에 의한 처리를 위해, 또는 이 동작을 제어하기 위해, 컴퓨터 프로그램 제 품, 즉 정보 캐리어, 예를 들어 기계 판독가능 저장 장치(컴퓨터 판독가능 매체) 또는 전파 신호에서 유형적으 로 구체화된 컴퓨터 프로그램으로서 구현될 수 있다. 상술한 컴퓨터 프로그램(들)과 같은 컴퓨터 프로그램은 컴 파일된 또는 인터프리트된 언어들을 포함하는 임의의 형태의 프로그래밍 언어로 기록될 수 있고, 독립형 프로그 램으로서 또는 모듈, 구성요소, 서브루틴, 또는 컴퓨팅 환경에서의 사용에 적절한 다른 유닛으로서 포함하는 임 의의 형태로 전개될 수 있다. 컴퓨터 프로그램은 하나의 사이트에서 하나의 컴퓨터 또는 다수의 컴퓨터들 상에 서 처리되도록 또는 다수의 사이트들에 걸쳐 분배되고 통신 네트워크에 의해 상호 연결되도록 전개될 수 있다. 컴퓨터 프로그램의 처리에 적절한 프로세서들은 예로서, 범용 및 특수 목적 마이크로프로세서들 둘 다, 및 임의 의 종류의 디지털 컴퓨터의 임의의 하나 이상의 프로세서들을 포함한다. 일반적으로, 프로세서는 판독 전용 메 모리 또는 랜덤 액세스 메모리 또는 둘 다로부터 명령어들 및 데이터를 수신할 것이다. 컴퓨터의 요소들은 명령 어들을 실행하는 적어도 하나의 프로세서 및 명령어들 및 데이터를 저장하는 하나 이상의 메모리 장치들을 포함 할 수 있다. 일반적으로, 컴퓨터는 데이터를 저장하는 하나 이상의 대량 저장 장치들, 예를 들어 자기, 자기-광 디스크들, 또는 광 디스크들을 포함할 수 있거나, 이것들로부터 데이터를 수신하거나 이것들에 데이터를 송신하 거나 또는 양쪽으로 되도록 결합될 수도 있다. 컴퓨터 프로그램 명령어들 및 데이터를 구체화하는데 적절한 정 보 캐리어들은 예로서 반도체 메모리 장치들, 예를 들어, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(Magnetic Media), CD-ROM(Compact Disk Read Only Memory), DVD(Digital Video Disk)와 같은 광 기록 매체(Optical Media), 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체(Magneto-Optical Media), 롬 (ROM, Read Only Memory), 램(RAM, Random Access Memory), 플래시 메모리, EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM) 등을 포함한다. 프로세서 및 메모리는 특수 목적 논리 회로조직에 의해 보충되거나, 이에 포함될 수 있다. 프로세서는 운영 체제(Operating System) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리케이션을 수행 할 수 있다. 또한, 프로세서 디바이스는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 프로세서 디바이스는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2022-0185246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 프로세서 디바이스가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 프로세서 디바이스는 복수 개의 프 로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processo r)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 또한, 비-일시적 컴퓨터 판독가능 매체(non-transitory computer-readable media)는 컴퓨터에 의해 액세스될 수 있는 임의의 가용매체일 수 있고, 컴퓨터 저장매체 및 전송매체를 모두 포함할 수 있다. 본 명세서는 다수의 특정한 구현물의 세부사항들을 포함하지만, 이들은 어떠한 발명이나 청구 가능한 것의 범위 에 대해서도 제한적인 것으로서 이해되어서는 안되며, 오히려 특정한 발명의 특정한 실시형태에 특유할 수 있는 특징들에 대한 설명으로서 이해되어야 한다. 개별적인 실시형태의 문맥에서 본 명세서에 기술된 특정한 특징들 은 단일 실시형태에서 조합하여 구현될 수도 있다. 반대로, 단일 실시형태의 문맥에서 기술한 다양한 특징들 역 시 개별적으로 혹은 어떠한 적절한 하위 조합으로도 복수의 실시형태에서 구현 가능하다. 나아가, 특징들이 특 정한 조합으로 동작하고 초기에 그와 같이 청구된 바와 같이 묘사될 수 있지만, 청구된 조합으로부터의 하나 이 상의 특징들은 일부 경우에 그 조합으로부터 배제될 수 있으며, 그 청구된 조합은 하위 조합이나 하위 조합의 변형물로 변경될 수 있다. 마찬가지로, 특정한 순서로 도면에서 동작들을 묘사하고 있지만, 이는 바람직한 결과를 얻기 위하여 도시된 그 특정한 순서나 순차적인 순서대로 그러한 동작들을 수행하여야 한다거나 모든 도시된 동작들이 수행되어야 하는 것으로 이해되어서는 안 된다. 특정한 경우, 멀티태스킹과 병렬 프로세싱이 유리할 수 있다. 또한, 상술한 실시 형태의 다양한 장치 컴포넌트의 분리는 그러한 분리를 모든 실시형태에서 요구하는 것으로 이해되어서는 안되며, 설명한 프로그램 컴포넌트와 장치들은 일반적으로 단일의 소프트웨어 제품으로 함께 통합되거나 다중 소프트웨어 제품에 패키징 될 수 있다는 점을 이해하여야 한다. 한편, 본 명세서와 도면에 개시된 본 개시의 실시 예들은 이해를 돕기 위해 특정 예를 제시한 것에 지나지 않으 며, 본 발명의 범위를 한정하고자 하는 것은 아니다. 여기에 개시된 실시 예들 이외에도 본 발명의 기술적 사상"}
{"patent_id": "10-2022-0185246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자 에게 자명한 것이다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0185246", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시 예에 따른 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 장치 블록 구성도이다. 도 2는 본 개시의 실시 예에 따른 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 전반적인 방법을 나타낸 흐 름도이다. 도 3은 본 개시의 실시 예에 따른 영상 콘텐츠에서 감정 및 분위기 정보를 인식하는 구체적인 방법을 나타낸 흐 름도이다. 도 4는 본 개시의 실시 예에 따른 영상 콘텐츠에 포함된 콘텐츠 기본 정보를 기반으로 전체적인 감정과 분위기 를 인식하는 방법을 나타내는 예시도, 도 5는 본 개시의 실시 예에 따른 영상 콘텐츠의 샘플링된 프레임이 가지고 있는 시각적 정보(밝기 등)와 청각 적 정보(음성, 음향, 음악의 크기 등)를 기반으로 감정과 분위기를 인식하는 방법을 나타내는 예시도, 도 6은 본 개시의 실시 예에 따른 영상 콘텐츠의 프레임 간에 일어나는 등장인물 또는 배경의 움직임 정보(모션 벡터, 옵티컬 플로우 등)를 기반으로 감정과 분위기를 인식하는 방법을 나타내는 예시도, 도 7은 본 개시의 실시 예에 따른 영상 콘텐츠의 청각적 정보(배경음악, 효과음 정보 등)를 기반으로 감정과 분 위기를 인식하는 방법을 나타내는 예시도, 도 8은 본 개시의 실시 예에 따른 영상 콘텐츠 또는 장면 내 등장인물의 표정이나 등장인물 간 대화의 맥락과 분위기를 기반으로 전체의 감정과 분위기를 인식하는 방법을 나타내는 예시도."}
