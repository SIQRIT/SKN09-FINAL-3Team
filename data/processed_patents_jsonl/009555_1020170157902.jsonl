{"patent_id": "10-2017-0157902", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0096483", "출원번호": "10-2017-0157902", "발명의 명칭": "전자 장치, 이의 제어 방법 및 비일시적인 컴퓨터 판독가능 기록매체", "출원인": "삼성전자주식회사", "발명자": "황인철"}}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 제어 방법에 있어서,사용자 음성을 입력받는 단계;상기 사용자 음성으로부터 텍스트 데이터를 획득하며, 상기 획득된 텍스트 데이터로부터 목표 성분 및 파라미터성분을 결정하는 단계; 상기 목표 성분 및 상기 파라미터 성분을 바탕으로 상기 사용자 음성에 대응되는 동작을 결정하는 단계;상기 결정된 동작의 수행이 불가능하다고 판단된 경우, 상기 목표 성분 및 상기 파라미터 성분 중 적어도 하나를 바탕으로 상기 결정된 동작을 대체하기 위한 대체 동작을 결정하는 단계; 및상기 대체 동작을 안내하기 위한 메시지를 제공하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 사용자 음성에 대응되는 동작을 결정하는 단계는,상기 결정된 목표 성분을 바탕으로 상기 사용자 음성에 대응되는 동작의 유형을 결정하고, 상기 파라미터 성분을 바탕으로 상기 사용자 음성에 대응되는 동작의 내용을 결정하는 제어 방법."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 목표 성분을 바탕으로 상기 동작의 유형이 결정된 경우, 상기 파라미터 성분을 바탕으로 결정된 동작의 내용이 수행 가능한지 여부를 판단하는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 대체 동작을 결정하는 단계는,상기 결정된 동작의 내용이 수행 불가능한 것으로 판단된 경우, 상기 결정된 동작의 내용을 바탕으로 상기 결정된 동작을 대체할 수 있는 복수의 대체 동작 중 하나를 대체 동작으로 결정하는 제어 방법."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 결정된 동작과 상기 복수의 대체 동작은 서로 매칭되어 기 저장되는 제어 방법."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 대체 동작을 결정하는 단계는,상기 결정된 동작의 내용이 수행 불가능한 것으로 판단된 경우, 상기 결정된 동작의 내용을 학습된 대체 동작판단 모델에 입력하여 대체 동작을 결정하는 제어 방법."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2018-0096483-3-제1항에 있어서,상기 대체 동작을 안내하기 위한 메시지는 자연어 형태로 처리되는 제어 방법."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "전자 장치에 있어서,사용자 음성을 입력받는 입력부; 및상기 입력부를 통해 입력된 상기 사용자 음성으로부터 텍스트 데이터를 획득하며, 상기 획득된 텍스트 데이터로부터 목표 성분 및 파라미터 성분을 결정하고, 상기 목표 성분 및 상기 파라미터 성분을 바탕으로 상기 사용자음성에 대응되는 동작을 결정하며, 상기 동작의 수행이 불가능하다고 판단된 경우, 상기 목표 성분 및 상기 파라미터 성분 중 적어도 하나를 바탕으로 상기 결정된 동작을 대체하기 위한 대체 동작을 결정하고, 상기 대체동작을 안내하기 위한 메시지를 제공하는 프로세서;를 포함하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 프로세서는,상기 결정된 목표 성분을 바탕으로 상기 사용자 음성에 대응되는 동작의 유형을 결정하고, 상기 파라미터 성분을 바탕으로 상기 사용자 음성에 대응되는 동작의 내용을 결정하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 프로세서는,상기 목표 성분을 바탕으로 상기 동작의 유형이 결정된 경우, 상기 파라미터 성분을 바탕으로 결정된 동작의 내용이 수행 가능한지 여부를 판단하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 프로세서는,상기 결정된 동작의 내용이 수행 불가능한 것으로 판단된 경우, 상기 결정된 동작의 내용을 바탕으로 상기 결정된 동작을 대체할 수 있는 복수의 대체 동작 중 하나를 대체 동작으로 결정하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 결정된 동작과 상기 복수의 대체 동작을 서로 매칭하여 저장하는 메모리;를 더 포함하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 프로세서는,상기 결정된 동작의 내용이 수행 불가능한 것으로 판단된 경우, 상기 결정된 동작의 내용을 학습된 대체 동작판단 모델에 입력하여 대체 동작을 결정하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서,상기 프로세서는,상기 대체 동작을 안내하기 위한 메시지를 자연어 형태로 처리하여 제공하는 전자 장치.공개특허 10-2018-0096483-4-청구항 15 인공지능 신경망(Neural Network) 모델을 이용하는 전자 장치에 있어서,사용자 음성을 입력받는 입력부; 및상기 입력부를 통해 입력된 상기 사용자 음성으로부터 텍스트 데이터를 획득하며, 상기 획득된 텍스트 데이터로부터 목표 성분 및 파라미터 성분을 결정하고, 상기 목표 성분 및 상기 파라미터 성분을 바탕으로 상기 사용자음성에 대응되는 동작을 결정하며, 상기 동작의 수행이 불가능하다고 판단된 경우, 상기 목표 성분 및 상기 파라미터 성분 중 적어도 하나를 인공지능 신경망 모델에 입력하여 상기 결정된 동작을 대체하기 위한 대체 동작을 결정하고, 상기 대체 동작을 안내하기 위한 메시지를 제공하는 프로세서;를 포함하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 프로세서는,상기 결정된 목표 성분을 상기 인공지능 신경망 모델에 입력하여 상기 사용자 음성에 대응되는 동작의 유형을결정하고, 상기 파라미터 성분을 상기 인공지능 신경망 모델에 입력하여 상기 사용자 음성에 대응되는 동작의내용을 결정하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 프로세서는,상기 목표 성분을 상기 인공지능 신경망 모델에 입력하여 상기 동작의 유형이 결정된 경우, 상기 파라미터 성분을 인공지능 신경망 모델에 입력하여 결정된 동작의 내용이 수행 가능한지 여부를 판단하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 프로세서는,상기 결정된 동작의 내용이 수행 불가능한 것으로 판단된 경우, 상기 결정된 동작의 내용을 상기 인공지능 신경망 모델에 입력하여 상기 결정된 동작을 대체할 수 있는 복수의 대체 동작 중 하나를 대체 동작으로 결정하는전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 결정된 동작과 상기 복수의 대체 동작을 서로 매칭하여 저장하는 메모리;를 더 포함하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서,상기 프로세서는,상기 대체 동작을 안내하기 위한 메시지를 자연어 형태로 처리하여 제공하는 전자 장치."}
{"patent_id": "10-2017-0157902", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 딥러닝 등의 기계 학습 알고리즘을 활용하는 인공지능(AI) 시스템 및 그 응용에 관련된 것이다. 특히, 본 개시의 전자 장치의 제어 방법은, 사용자 음성을 입력받고, 사용자 음성으로부터 텍스트 데이터를 획득하며, 획득된 텍스트 데이터로부터 목표 성분 및 파라미터 성분을 결정하고, 목표 성분 및 상기 파라미터 성분을 바탕 으로 사용자 음성에 대응되는 동작을 결정하며, 결정된 동작의 수행이 불가능하다고 판단된 경우, 목표 성분 및 파라미터 성분 중 적어도 하나를 바탕으로 결정된 동작을 대체하기 위한 대체 동작을 결정하고, 대체 동작을 안 내하기 위한 메시지를 제공한다."}
{"patent_id": "10-2017-0157902", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치, 이의 제어 방법 및 비일시적인 컴퓨터 판독가능 기록매체에 관한 것으로, 더욱 구체적으 로, 사용자 음성에 대응되는 동작이 수행 불가능할 경우, 대체 동작을 안내하는 가이드를 제공하는 전자 장치,이의 제어 방법 및 비일시적인 컴퓨터 판독가능 기록매체에 관한 것이다. 또한, 본 개시는 딥러닝 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인 공지능(AI) 시스템 및 그 응용에 관련된 것이다."}
{"patent_id": "10-2017-0157902", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 규칙 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 규칙 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분 야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조 작 제어(행동 제어) 등을 포함한다. 한편, 최근 모바일 장치, 음성 인식 장치, 홈네트워크 허브 장치, 서버 등의 기능이 향상됨에 따라, 이들 장치 를 이용하는 사용자의 수가 증가하고 있다. 특히, 이와 같은 전자 장치는 사용자의 음성을 인식하고 그에 대응 되는 정보를 제공하거나 동작을 수행하는 지능형 비서(Intelligent Assistant) 또는 가상 개인 비서(Virtual Personal Assistant, VPA) 기능을 제공한다. 기존의 지능형 비서 기능은 사용자의 음성을 분석하여 동작을 수행 가능한 형태로 해석되지 않을 경우, 에러 발 생을 안내하는 에러 메시지만을 제공하였다. 특히, 사용자 음성에 대응되는 동작은 판단되나 판단된 동작이 수 행 불가능한 경우, 단순히 에러 메시지만을 제공한다면 사용자가 의도하는 동작을 수행하기 위하여 어떠한 사용 자 음성을 입력해야 하는지 알 수 없는 문제가 발생한다."}
{"patent_id": "10-2017-0157902", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은 사용자 음성에 대응되는 동작이 수행 불가능할 경우, 사용자 음성에 대응되는 동작을 대체할 수 있는 대체 동작을 안내하기 위한 전자 장치, 이의 제어 방법 및 비일시적인 컴퓨터 판독가능 기록매체에 관 한 것이다."}
{"patent_id": "10-2017-0157902", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 개시의 일 실시예에 따른, 전자 장치의 제어 방법은, 사용자 음성을 입력받는 단 계; 상기 사용자 음성으로부터 텍스트 데이터를 획득하며, 획득된 텍스트 데이터로부터 목표 성분 및 파라미터 성분을 결정하는 단계; 상기 목표 성분 및 상기 파라미터 성분을 바탕으로 상기 사용자 음성에 대응되는 동작을 결정하는 단계; 상기 결정된 동작의 수행이 불가능하다고 판단된 경우, 상기 목표 성분 및 상기 파라미터 성분 중 적어도 하나를 바탕으로 상기 결정된 동작을 대체하기 위한 대체 동작을 결정하는 단계; 및 상기 대체 동작 을 안내하기 위한 메시지를 제공하는 단계;를 포함한다. 한편, 상기 목적을 달성하기 위한 본 개시의 일 실시예에 따른, 전자 장치는 사용자 음성을 입력받는 입력부; 및 상기 입력부를 통해 입력된 상기 사용자 음성으로부터 텍스트 데이터를 획득하며, 상기 획득된 텍스트 데이 터로부터 목표 성분 및 파라미터 성분을 결정하고, 상기 목표 성분 및 상기 파라미터 성분을 바탕으로 상기 사용자 음성에 대응되는 동작을 결정하며, 상기 동작의 수행이 불가능하다고 판단된 경우, 상기 목표 성분 및 상 기 파라미터 성분 중 적어도 하나를 바탕으로 상기 결정된 동작을 대체하기 위한 대체 동작을 결정하고, 상기 대체 동작을 안내하기 위한 메시지를 제공하는 프로세서;를 포함한다. 한편, 상기 목적을 달성하기 위한 본 개시의 일 실시예에 따른,인공지능 신경망(Neural Network) 모델을 이용하 는 전자 장치는, 사용자 음성을 입력받는 입력부 및 상기 입력부를 통해 입력된 상기 사용자 음성으로부터 텍스 트 데이터를 획득하며, 상기 획득된 텍스트 데이터로부터 목표 성분 및 파라미터 성분을 결정하고, 상기 목표 성분 및 상기 파라미터 성분을 바탕으로 상기 사용자 음성에 대응되는 동작을 결정하며, 상기 동작의 수행이 불 가능하다고 판단된 경우, 상기 목표 성분 및 상기 파라미터 성분 중 적어도 하나를 인공지능 신경망 모델에 입 력하여 상기 결정된 동작을 대체하기 위한 대체 동작을 결정하고, 상기 대체 동작을 안내하기 위한 메시지를 제공하는 프로세서를 포함한다."}
{"patent_id": "10-2017-0157902", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같은 본 개시의 실시예에 따라, 실행 불가능한 동작을 대체할 수 있는 대체 동작을 안내함으로써, 지능형 비서 기능을 처음 이용하거나 익숙하지 않은 사용자라도 더욱 쉽고 자연스럽게 지능형 비서 기능을 이용 할 수 있게 된다."}
{"patent_id": "10-2017-0157902", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 개시의 바람직한 실시 예가 첨부된 도면을 참조하여 상세히 설명한다. 본 개시를 설명함에 있어 서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단된 경우 그 상세한 설명은 생략한다. 그리고 후술되는 용어들은 본 개시에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 용어들에 의해 한정되지는 않는다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 항목들의 조합 또는 복수의 관련된 항목들 중의 어느 하나의 항목을 포함한다. 본 명세서에서 사용한 용어는 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 제한 및/또는 한정하려는 의 도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 숫자, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다.실시 예에 있어서 '모듈' 혹은 '부'는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 또는 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 '모듈' 혹은 복수의 '부'는 특 정한 하드웨어로 구현될 필요가 있는 '모듈' 혹은 '부'를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프로세서로 구현될 수 있다. 이하에서는 첨부된 도면을 이용하여 본 개시에 대하여 구체적으로 설명한다. 도 1은 본 개시의 일 실시 예에 따 른 전자 장치의 구성을 설명하기 위한 개략적인 블록도이다. 전자 장치는 도 1에 도시된 바와 같이, 단독으로 지능형 비서 서비스를 제공할 수 있다. 전자 장치가 단독으로 지능형 비서 서비스를 제공할 경우, 스마트 폰, 타블렛 PC, 노트북 PC, 데스크탑 PC, 스마트 와치와 같은 웨어러블 장치, 전자 액자, 인간형 로봇, 오디오 장치, 스마트 TV 등과 같은 다양한 전자 장치로 구현될 수 있다. 다른 예로, 전자 장치는 도 7에 도시된 바와 같이, 서버로 구현되어 외부의 사용자 단말과 연동하여 사용자에게 지능형 비서 서비스를 제공할 수도 있다. 본 명세서에서 사용되는 용어 '지능형 비서'는, 인공지능 기술과 음성 인식 기술의 결합으로 사용자의 언어를 이해하고 사용자가 원하는 지시사항을 수행하는 소프트웨어 어플리케이션을 말한다. 예를 들어, 지능형 비서는 딥러닝을 포함하는 머신러닝, 음성 인식, 문장 분석, 상황 인지와 같은 인공지능 기능을 수행할 수 있다. 지능 형 비서는 사용자의 습관 또는 패턴을 학습하여 개인에 필요한 맞춤형 서비스를 제공할 수 있다. 지능형 비서의 예로는 S voice, Bixby를 들 수 있다. 지능형 비서는 다른 용어로 가상 개인 비서, 대화형 에이전트 등으로 불 릴 수도 있다. 한편, 본 개시에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지 능 전자 장치)를 지칭할 수 있다. 도 1에 도시된 바와 같이, 전자 장치는 입력부 및 프로세서를 포함한다. 입력부는 사용자 음성을 수신한다. 이때, 입력부는 마이크로 구현될 수 있으며, 마이크를 통해 사용 자 음성을 수신할 수 있다. 또한, 입력부는 사용자 음성 외에 사용자 음성에 대응하는 텍스트를 수신할 수 있다. 프로세서는 전자 장치의 전반적인 동작을 제어할 수 있다. 구체적으로, 프로세서는 입력부(11 0)를 통해 입력된 사용자 음성으로부터 텍스트 데이터를 획득하며, 획득된 텍스트 데이터로부터 목표 성분 및 파라미터 성분을 결정할 수 있다. 그리고, 프로세서는 목표 성분 및 파라미터 성분을 바탕으로 사용자 음 성에 대응되는 동작을 결정할 수 있다. 결정된 동작의 수행이 불가능하다고 판단된 경우, 프로세서는 목표 성분 및 파라미터 성분 중 적어도 하나를 바탕으로 결정된 동작을 대체하기 위한 대체 동작을 결정하고, 대체 동작을 안내하기 위한 메시지를 제공할 수 있다. 구체적으로, 프로세서는 입력부를 통해 입력된 사용자 음성을 분석하여 사용자 음성에 대응되는 텍스 트 데이터를 획득할 수 있다. 그리고, 프로세서는 텍스트 데이터로부터 목표(Goal) 성분 및 파라미터 (Parameter) 성분을 결정할 수 있다. 이때, 목표 성분은 사용자가 사용자 음성을 이루고자 하는 동작의 의도를 나타내며, 파라미터 성분은 사용자가 의도하는 동작을 구체적인 내용(예를 들어, 어플리케이션 종류, 시간, 대 상 등)을 나타낼 수 있다. 그리고, 프로세서는 결정된 목표 성분 및 파라미터 성분을 바탕으로 사용자 음성에 대응되는 동작(Task)를 결정할 수 있다. 이때, 프로세서는 결정된 목표 성분을 바탕으로 사용자 음성에 대응되는 동작의 유형을 결정하고, 파라미터 성분을 바탕으로 사용자 음성에 대응되는 동작의 내용을 결정할 수 있다. 동작이 결정된 경우, 프로세서는 결정된 동작 수행 가능 여부를 판단할 수 있다. 구체적으로, 목표 성분을 바탕으로 동작의 유형이 결정된 경우, 프로세서는 파라미터 성분을 바탕으로 결정된 동작의 내용이 수행 가능한지 여부를 판단할 수 있다. 결정된 동작의 내용이 수행 불가능한 것으로 판단된 경우, 프로세서는 목표 성분 및 파라미터 성분 중 적 어도 하나를 바탕으로 결정된 동작을 대체할 수 있는 대체 동작을 판단할 수 있다. 구체적으로, 결정된 동작의 내용이 수행 불가능한 것으로 판단된 경우, 프로세서는 파라미터 성분을 통해 결정된 동작의 내용을 바탕으로 결정된 동작을 대체할 수 있는 복수의 대체 동작 중 하나를 대체 동작으로 결정할 수 있다. 이때, 결정된 동작과 복수의 대체 동작이 서로 매칭되어 저장될 수 있다. 또한, 결정된 동작의 내용이 수행 불가능한 것으로 판단된 경우, 프로세서는 결정된 동작의 내용을 학습된 대체 동작 판단 모델에 입력하여 대체 동작을 결정할 수 있다. 이때, 대체 동작 판단 모델은 특정 동작을 대체 하기 위한 대체 동작을 인식하기 위한 모델로서, 미리 구축될 수 있다. 그리고, 프로세서는 대체 동작을 안내하기 위한 메시지를 자연어 형태로 처리하여 제공할 수 있다. 이때, 전자 장치가 스마트 폰과 같은 형태로 구현되는 경우, 프로세서는 디스플레이를 통해 메시지를 제공 할 수 있다. 또한, 전자 장치가 서버로 구현되는 경우, 프로세서는 외부의 사용자 단말로 메시지를 제공할 수 있다. 또한 본 개시에 따른 다양한 실시예에 의할 때. 전자 장치는 입력된 사용자 음성으로부터 텍스트 데이터를 획득하고, 획득된 텍스트 데이터를 분석하여 목표 성분 및 파라미터 성분을 결정할 수 있다. 이때, 전자 장치 는 목표 성분 및 파라미터 성분을 인식 모델의 입력 데이터로 사용하여 사용자 음성에 대응되는 동작을 결 정할 수 있다. 본 개시에서 학습된 인식 모델은 인식 모델의 적용 분야 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있다. 학습된 객체 인식 모델은, 예로, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 객 체 인식 모델은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 뉴런이 시냅 스(synapse)를 통하여 신호를 주고 받는 뉴런의 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계를 형성할 수 있다. 또한 객체 인식 모델은, 일 예로, 신경망 모델, 또는 신경망 모델에서 발전한 딥 러닝 모델을 포함할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드들은 서로 다른 깊이(또는, 레이어)에 위치하면서 컨볼루션 (convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 객체 인식 모델의 예에는 DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 등이 있을 수 있으나 이에 한정되지 않는다. 상술한 객체 인식 모델의 구체적인 적용예는 후술한다. 또한, 전자 장치는 상술한 바와 같은 동작을 수행하기 위하여 인공지능 에이전트(Artificial intelligence agent)를 이용할 수 있다. 이때, 인공지능 에이전트는 AI(Artificial Intelligence) 기반의 서비스(예를 들어, 음성 인식 서비스, 비서 서비스, 번역 서비스, 검색 서비스 등)를 제공하기 위한 전용 프로그램으로서, 기존의 범용 프로세서(예를 들어, CPU) 또는 별도의 AI 전용 프로세서(예를 들어, GPU 등)에 의해 실행될 수 있다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 상세히 설명하기 위한 블록도이다. 도 2를 참조 하면, 전자 장치는 입력부, 디스플레이, 프로세서, 음성 출력부, 통신부 및 메 모리를 포함할 수 있다. 도 2의 실시 예에 도시된 구성 요소 이외에도 전자 장치는 영상 수신부(미도 시), 영상 처리부(미도시), 전원부(미도시) 등 다양한 구성을 포함할 수 있다. 또한, 전자 장치가 반드시 도 2에 도시된 구성을 모두 포함하여 구현되는 것으로 한정되지 않음은 물론이다. 예를 들어, 전자 장치가 서버로 구현되는 경우, 디스플레이, 음성 출력부가 구비되지 않을 수 있음을 물론이다. 입력부는 사용자 음성을 수신할 수 있다. 특히, 입력부는 사용자 음성을 입력받는 음성 입력부(예를 들어, 마이크)를 포함할 수 있다. 음성 입력부는 사용자가 발화한 사용자 음성을 입력받을 수 있다. 예를 들어, 음성 입력부는 전자 장치의 상측이나 전면 방향, 측면 방향 등에 일체화된 일체형으로 구현될 수도 있고, 별도의 수단으로 마련되어 전자 장치와 유선 또는 무선 인터페이스로 연결될 수도 있다. 또한, 음성 입력부는 복수 개로 구성되어, 서로 다른 위치에서 음성을 입력 받아 복수의 음성 신호를 생성할 수 있다. 복수의 음성 신호를 이용하여, 전자 장치는 음성 인식 기능 수행 이전의 전처리(pre-processing) 과 정에서 강화된 단일 음성 신호를 생성할 수 있다. 구체적으로, 음성 입력부는 마이크, ADC(Analog-Digital Converter), 에너지 판단부, 노이즈 제거부, 음성신호 생성부를 포함한다. 마이크는 사용자 음성이 포함된 아날로그 형태의 오디오 신호를 입력받는다. 그리고, ADC는 마이크로부터 입력 된 다채널 아날로그 신호를 디지털 신호로 변환한다. 그리고, 에너지 판단부는 변환된 디지털 신호의 에너지를 계산하여, 디지털 신호의 에너지가 기설정된 값 이상인지 여부를 판단한다. 디지털 신호의 에너지가 기설정된 값 이상인 경우, 에너지 판단부는 입력된 디지털 신호를 노이즈 제거부로 전송하고, 디지털 신호의 에너지가 기 설정된 값 미만인 경우, 에너지 판단부는 입력된 디지털 신호를 외부로 출력하지 않고, 다른 입력을 기다린다. 이에 의해, 음성 신호가 아닌 소리에 의해 전체 오디오 처리 과정이 활성화되지 않아, 불필요한 전력 소모를 방지할 수 있다. 노이즈 제거부에 입력된 디지털 신호가 입력된 경우, 노이즈 제거부는 노이즈 성분과 사용자 음 성 성분이 포함된 디지털 신호 중 노이즈 성분을 제거한다. 이때, 노이즈 성분은 가정 환경에서 발생할 수 있는 돌발성 잡음으로써, 에어컨 소리, 청소기 소리, 음악 소리 등이 포함될 수 있다. 그리고, 노이즈 제거부는 노이 즈 성분이 제거된 디지털 신호를 음성 신호 생성부로 출력한다. 음성 신호 생성부는 Localization/Speaker Tracking 모듈을 이용하여 음성 입력부를 기준으로 360° 범위 내에 존재하는 사용자의 발화 위치를 추적하여 사용자 음성에 대한 방향 정보를 구한다. 그리고, 음성 신호 생성부는 Target Spoken Sound Extraction 모듈을 통해 노이즈가 제거된 디지털 신호와 사용자 음성에 대한 방향 정보를 이용하여 음성 입력부를 기준으로 360° 범위 내에 존재하는 목표 음원을 추출한다. 음성 입력부가 전자 장치와 무선으로 연결된 경우, 음성 신호 생성 부는 사용자 음성을 전자 장치로 전송하기 위한 형태의 사용자 음성 신호로 변환하고, 무선 인터페이스를 이용 하여 전자 장치의 본체로 사용자 음성 신호를 전송한다. 그 밖에, 입력부는 사용자 음성 이외에 다양한 형태의 사용자 명령을 입력받을 수 있다. 예를 들어, 입력 부는 가이드 UI에 표시된 복수의 후보 동작 중 하나를 선택하는 사용자 명령을 입력받을 수 있다. 또한, 입력부는 버튼, 모션 인식 장치, 터치 패드 등으로 구현될 수 있다. 또한, 입력부가 터치 패드로 구 현되는 경우, 터치 패널과 디스플레이가 서로 결합되어 상호 레이어 구조를 이루는 터치 스크린의 형태로 구현될 수 있다. 터치 스크린은 터치 입력 위치, 면적, 터치 입력의 압력 등을 검출할 수 있다. 디스플레이는 전자 장치에서 제공되는 각종 가이드, 영상 컨텐츠, 정보, UI 등을 표시할 수 있다. 디 스플레이는 액정 표시 장치(Liquid Crystal Display, LCD), 유기 전기 발광 다이오드(Organic Light Emitting Display, OLED) 또는 플라즈마 표시 패널(Plasma Display Panel, PDP) 등으로 구현되어, 전자 장치 를 통해 제공 가능한 다양한 화면을 표시할 수 있다. 디스플레이는 프로세서의 음성 판단 결과에 대응되는 영상을 제공할 수 있다. 예를 들어, 디스플레이 는 사용자의 음성 판단 결과를 텍스트로 표시할 수 있다. 그리고 디스플레이는 대체 동작을 안내하는 메시지를 표시할 수 있다. 음성 출력부는 음성을 출력할 수 있다. 예를 들어, 음성 출력부는 각종 오디오 데이터뿐만 아니라 알 림 음이나 음성 메시지를 출력할 수 있다. 본 발명의 일 실시 예에 따른 전자 장치는 대화형 지능형 비서 기능을 제공하기 위한 출력부의 하나로 음성 출력부를 포함할 수 있다. 자연언어 처리된 음성 메시지를 음 성 출력부를 통해 출력함으로써, 전자 장치는 사용자에게 전자 장치와 대화하는 듯한 사용자 경 험을 제공할 수 있다. 음성 출력부는 전자 장치에 내장될 수도 있으며, 잭 등과 같은 출력 포트의 형 태로 구현될 수도 있다. 통신부는 외부 장치와 통신을 수행한다. 예를 들어, 외부 장치는 다른 전자 장치, 서버, 클라우드 저장소, 네트워크 등으로 구현될 수 있다. 통신부는 외부 장치에 음성 판단 결과를 송신하고, 대응되는 정보를 외 부 장치로부터 수신할 수 있다. 통신부는 음성 인식을 위한 언어 모델, 동작 결정을 위한 학습 모델을 외 부 장치로부터 수신할 수도 있다. 본 발명의 일 실시예로, 통신부는 음성 판단 결과를 서버로 전송하고, 서버에서 대응 동작을 수 행하기 위한 제어 신호 또는 대체 동작을 안내하는 메시지를 수신할 수 있다. 이를 위해, 통신부는 근거리 무선 통신 모듈(미도시), 무선 통신 모듈(미도시) 등과 같은 다양한 통신 모 듈을 포함할 수 있다. 여기에서, 근거리 무선 통신 모듈이란 블루투스(Bluetooth), 지그비(Zigbee) 등과 같은 근거리 무선 통신 방식에 따라, 근거리에 위치한 외부 기기와 통신을 수행하기 위한 모듈이다. 또한, 무선 통신 모듈이란 WiFi, WiFi direct, IEEE 등과 같은 무선 통신 프로토콜에 따라 외부 네트워크에 연결되어 통신을 수 행하는 모듈이다. 이 밖에 무선 통신 모듈은 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evoloution), LTE-A(LTE Advanced) 등과 같은 다양한 이동 통신 규격에 따라 이동 통신망에 접 속하여 통신을 수행하는 이동 통신 모듈을 더 포함할 수도 있다. 메모리는 전자 장치를 구동하기 위한 다양한 모듈, 소프트웨어, 데이터를 저장할 수 있다. 예를 들어, 메모리에는 사용자의 음성을 인식하는데 이용될 수 있는 음향 모델(Acoustic Model, AM) 및 언어 모 델(Language Model, LM)이 저장될 수 있다. 또한, 메모리에는 대체 동작을 결정하기 위해 학습된 대체 동 작 판단 모델이 저장될 수 있다. 그리고 메모리에는 자연언어생성(Natural Language Generation, NLG)를 위한 모델이 저장될 수 있다. 메모리에는 디스플레이에 표시될 각종 화면을 구성하기 위한 프로그램 및 데이터가 저장될 수 있다. 또한, 메모리에는 특정 서비스를 수행하기 위한 프로그램, 어플리케이션 및 데이터가 저장될 수 있다. 메모리는 사용자의 음성에 대응되는 각종 응답 메시지를 음성 또는 텍스트 데이터로 기저장하고 있을 수 있다. 전자 장치는 수신된 사용자 음성(특히, 사용자 제어 명령)에 대응되는 음성 및 텍스트 데이터 중 적 어도 하나를 메모리로부터 독출하여 디스플레이 또는 음성 출력부로 출력할 수도 있다. 이를 통 해, 전자 장치는 자연언어생성 모델을 거치지 않고도, 간단하거나 자주 사용되는 메시지를 사용자에게 제 공할 수 있다. 메모리는 전자 장치를 동작시키기 위해 필요한 각종 프로그램 등이 저장되는 저장매체로서, 플래쉬 메모리, HDD(Hard Disk Drive), SSD (Solid State Drive) 등의 형태로 구현 가능하다. 예를 들어, 메모리(16 0)는 전자 장치의 동작 수행을 위한 프로그램을 저장하기 위한 ROM, 전자 장치의 동작 수행에 따른 데이터를 일시적으로 저장하기 위한 RAM을 구비할 수 있다. 한편, 메모리는 사용자 음성에 대응되는 동작을 수행하기 위한 복수의 소프트웨어 모듈을 저장할 수 있다. 구체적으로, 메모리는 도 3에 도시된 바와 같이, 텍스트 획득 모듈, 텍스트 분석 모듈, 동작 결 정 모듈, 동작 수행 판단 모듈, 동작 수행 모듈, 대체 동작 판단 모듈 및 대체 동작 안내 모듈을 포함할 수 있다. 텍스트 획득 모듈은 사용자 음성을 포함하는 음성 신호로부터 텍스트 데이터를 획득한다. 텍스트 분석 모듈은 텍스트 데이터를 분석하여 사용자 음성의 목적 성분 및 파라미터 성분을 결정한다. 텍스트 결정 모듈은 목적 성분 및 파라미터 성분을 바탕으로 사용자 음성에 대응하는 동작을 결정한다. 특 히, 텍스트 결정 모듈은 목적 성분을 이용하여 사용자 음성에 대응되는 동작의 유형을 결정하고, 파라미터 성분을 이용하여 사용자 음성에 대응되는 동작의 내용을 결정할 수 있다. 동작 수행 판단 모듈은 결정된 동작을 수행할 수 있을지 여부에 대해 판단한다. 구체적으로, 동작 수행 판 단 모듈은 파라미터 성분을 이용하여 결정된 동작의 내용을 바탕으로 동작 수행이 가능한지 여부를 판단할 수 있다. 예를 들어, 동작 수행 판단 모듈은 파라미터 성분을 이용하여 결정된 동작의 내용이 동작 불가능 한 내용이거나 파라미터 성분을 이용하여 결정된 동작의 내용 중 일부 내용이 빠진 경우, 동작 수행이 불가능한 것으로 판단할 수 있다. 결정된 동작이 수행 가능한 것으로 판단된 경우, 동작 수행 모듈은 결정된 동작을 수행한다. 결정된 동작이 수행 불가능한 것으로 판단된 경우, 대체 동작 판단 모듈은 목적 성분 및 파라미터 성분을 이용하여 결정된 동작을 대체할 수 있는 대체 동작을 결정할 수 있다. 이때, 대체 동작 판단 모듈은 결정 된 동작과 매칭된 기저장된 대체 동작 또는 기학습된 대체 동작 판단 모델을 이용하여 대체 동작을 결정할 수 있다. 대체 동작 안내 모듈은 결정된 대체 동작을 안내하기 위한 메시지를 제공한다. 이때, 대체 동작을 안내하 기 위한 메시지는 청각적 형태 또는 시각적 형태일 수 있으며, 자연어 형태로 처리되어 제공될 수 있다. 프로세서는 전자 장치의 상술한 구성들을 제어할 수 있다. 예를 들어, 프로세서는 메모리 에 저장된 복수의 소프트웨어 모듈을 이용하여 사용자 음성에 대응되는 동작을 대체할 수 있는 대체 동작을 결 정하고, 결정된 대체 동작을 안내하기 위한 메시지를 제공할 수 있다. 프로세서는 단일 CPU로 구현되어 음성 인식 동작, 언어 이해 동작, 대화 관리 동작, 대체 동작 검색 동작, 필터링 동작, 응답 생성 동작 등을 수행할 수도 있고, 복수의 프로세서 및 상기 메모리에 저장된 복수의 소프트 웨어 모듈 중 적어도 하나의 기능과 같은 동작을 수행하는 전용 프로세서로 구현될 수도 있다. 프로세서는 전통적인 은닉 마코프 모델(Hidden Markov Model, HMM) 기반의 음성 인식을 수행할 수도 있고, 딥 신경망(Deep Neural Network, DNN)과 같은 딥러닝 기반의 음성 인식을 수행할 수도 있다. 또한, 프로세서는 음성 인식 및 대체 동작 결정에 빅데이터 및 사용자별 히스토리 데이터를 이용할 수 있 다. 이를 통해, 프로세서는 빅데이터로 학습된 음성 인식 모델 및 대체 동작을 결정하기 위한 대체 동작 판단 모델을 사용함과 동시에 음성 인식 모델 및 대체 동작 판단 모델을 개인화시킬 수 있다. 이하에서는 도 4a 내지 도 5를 참조하여 본 발명에 대해 상세히 설명하기로 한다. 본 발명의 일 실시예로, 입력부를 통해 \"어제 찍은 사진 갤러리에서 찾아서 길동이에게 메시지로 보내줘\" 라는 사용자 음성이 입력된 경우, 프로세서는 텍스트 획득 모듈을 제어하여 사용자 음성으로 부터 텍 스트 데이터를 획득할 수 있다. 그리고, 프로세서는 텍스트 분석 모듈을 제어하여 획득된 텍스트 데이터를 분석하여 목적 성분과 파 라미터 성분을 결정할 수 있다. 예를 들어, 프로세서는 텍스트 분석 모듈을 제어하여 텍스트 데이터 인 \"어제 찍은 사진 갤러리에서 찾아서 길동이에게 메시지로 보내줘\"를 분석하여 아래와 같이, 목적 성분과 파 라미터 성분을 결정할 수 있다. <Goal: 사진 전송> <Para1(Time): 어제, Para2(AppName): 갤러리 어플리케이션, Para3(Person.to): 길동, Para4(AppName): 메시지 어플리케이션> 그리고, 프로세서는 동작 결정 모듈을 제어하여 목적 성분 및 파라미터 성분을 바탕으로 사용자 음성 에 대응되는 동작을 결정할 수 있다. 구체적으로, 프로세서는 동작 결정 모듈을 제어하여 목적 성분 을 바탕으로 동작의 유형이 \"사진 전송\"임을 결정할 수 있고, 동작의 내용이 \"어제 찍은 사진을 갤러리 어플리 케이션에서 찾아서 메시지로 보내기\"로 결정할 수 있다. 그리고, 프로세서는 동작 수행 판단 모듈을 제어하여 결정된 동작이 수행 가능한지 여부를 판단할 수 있다. 결정된 동작이 수행 가능한 경우, 프로세서는 동작 수행 모듈을 제어하여 결정된 동작을 수행 하거나 결정된 동작에 대응하는 제어 신호를 외부 장치로 전송할 수 있다. 예를 들어, \"어제 찍은 사진을 갤러 리 어플리케이션에서 찾아서 메시지로 보내기\"가 수행 가능한 경우, 프로세서는 동작 수행 모듈을 제 어하여 어제 찍은 사진을 갤러리 어플리케이션에서 검색하여 메시지에 첨부하여 길동이에 대응하는 외부 장치로 전송할 수 있다. 그러나, 결정된 동작이 수행 불가능한 경우, 프로세서는 대체 동작 판단 모듈을 제어하여 목적 성분 및 파라미터 성분을 바탕으로 결정된 동작을 대체할 수 있는 대체 동작을 결정할 수 있다. 예를 들어, 메시지로 전송할 수 있는 사진의 개수가 5개인데 반해, 갤러리 어플리케이션에서 검색된 어제 찍은 사진이 10개인 경우, 프로세서는 동작 수행 판단 모듈을 제어하여 결정된 동작이 수행 가능하지 않음을 판단할 수 있다. 프로세서는 대체 동작 판단 모듈을 제어하여 동작 수행 불가능한 이유가 10장의 사진을 메시지 전송 이 불가능함을 판단하고, 사용자 음성에 대응하는 동작의 대체 동작이 있는지 여부를 판단할 수 있다. 이때, 대체 동작에는 사용자 음성에 대응되는 동작과 동일한 동작의 유형을 가지나 상이한 동작의 내용을 가지 는 동작 또는 사용자 음성에 대응되는 동작과 상이한 동작의 유형 및 상이한 동작의 내용을 가지는 동작이 포함 될 수 있다. 예를 들어, 프로세서는 대체 동작 판단 모듈을 제어하여 사진 전송이라는 동일한 유형을 가지나, 동 작 내용이 메시지를 이용하여 전송하는 것이 아닌 다른 채팅 어플리케이션을 이용하여 사진을 전송하는 동작을 대체 동작으로 결정할 수 있다. 즉, 프로세서는 대체 동작 판단 모듈을 제어하여 동작의 유형이 \"사 진 전송\"이고, 동작의 내용이 \"어제 찍은 사진을 갤러리 어플리케이션에서 찾아서 채팅 어플리케이션으로 보내 기\"라는 대체 동작을 결정할 수 있다. 또 다른 예로, 프로세서는 대체 동작 판단 모듈을 제어하여 사진 전송이 아닌 캡쳐 화면 전송이라는 상이한 동작의 유형을 가지는 동작을 대체 동작으로 결정할 수 있다. 즉, 프로세서는 대체 동작 판단 모듈 을 제어하여 동작의 유형이 \"캡쳐 화면 전송\"이고, 동작의 내용이 \"어제 찍은 사진을 갤러리 어플리케이션 에서 찾아서 화면을 캡쳐하여 메시지로 전송\"이라는 대체 동작을 결정할 수 있다. 특정 동작에 대응하는 복수의 대체 동작은 기저장될 수 있다. 예를 들어, 메모리는 \"사진 전송\"의 대체 동 작으로, \"캡쳐 화면 전송\", \"메시지 전송\" 등을 \"사진 전송\"과 매칭하여 기저장할 수 있다. 이때, 프로세서 는 대체 동작 판단 모듈 을 제어하여 에러 원인을 바탕으로 기저장된 적어도 하나의 대체 동작 중 하 나를 사용자 음성에 대응하는 동작의 대체 동작으로 결정할 수 있다. 예를 들어, 전송 가능한 사진의 개수 초과 로 사용자 음성에 대응되는 동작이 불가능한 경우, 프로세서는 대체 동작 판단 모듈을 제어하여 \"캡 쳐 화면 전송\"을 대체 동작으로 결정하고, 전송 가능한 데이터의 초과로 사용자 음성에 대응되는 동작이 불가능 한 경우, 프로세서는 대체 동작 판단 모듈을 제어하여 \"메시지 전송\"을 대체 동작으로 결정할 수 있 다. 이때, 에러 원인과 대체 동작 역시 매칭되어 기 저장될 수 있다. 또는, 프로세서는 대체 동작 판단 모듈을 제어하여 기학습된 대체 동작 판단 모델을 이용하여 사용자 음성에 대응하는 동작을 대체하기 위한 대체 동작을 결정할 수 있다. 즉, 프로세서는 대체 동작 판단 모듈 을 제어하여 사용자 또는 타인에 의해 기학습된 대체 동작 판단 모델에 결정된 동작을 입력하여 결정된 동 작에 대응하는 대체 동작을 결정할 수 있다. 대체 동작 판단 모델에 대해서는 도 9 내지 도 10b를 참조하여 상 세히 설명하기로 한다. 대체 동작이 결정된 경우, 프로세서는 대체 동작 안내 모듈을 제어하여 대체 동작을 안내하기 위한 메시지를 제공할 수 있다. 이때, 대체 동작을 안내하기 위한 메시지에는 사용자 음성에 대응하는 동작을 수행하 지 못하는 원인과 대체 동작 중 적어도 하나를 안내하기 위한 메시지가 포함될 수 있다. 프로세서는 대체 동작 안내 모듈 을 제어하여 대체 동작을 안내하기 위한 메시지를 표시할 수 있으며, 메시지를 오디오 형 태로 출력할 수 있다. 또한, 프로세서는 대체 동작 안내 모듈을 제어하여 대체 동작을 안내하기 위한 메시지를 자연어 형태 로 처리하여 제공할 수 있다. 구체적으로, 동작의 유형이 \"사진 전송\"이고, 동작의 내용이 \"어제 찍은 사진을 갤러리 어플리케이션에서 찾아서 채팅 어플리케이션으로 보내기\"인 대체 동작의 경우, 프로세서는 대체 동 작 안내 모듈을 제어하여 도 4a에 도시된 바와 같이, \"메시지로 보내는 것이 불가능하여 xxx톡으로 보낼까 요\"라는 자연어 형태의 메시지를 디스플레이에 표시할 수 있다. 또한, 동작의 유형이 \"합성 이미지 전송\" 이고, 동작의 내용이 \"어제 찍은 사진을 갤러리 어플리케이션에서 찾아서 사진을 1장의 이미지로 합성하여 메시 지로 전송\"인 대체 동작의 경우, 프로세서는 대체 동작 안내 모듈을 제어하여 도 4b에 도시된 바와 같이, \"모든 사진을 보낼 수가 없어 10장 사진을 1 장으로 합성하여 메시지로 보낼까요\"라는 자연어 형태의 메 시지를 디스플레이에 표시할 수 있다. 이때, 프로세서는 대체 동작 안내 모듈을 제어하여 기저장된 자연어 형태의 메시지를 제공할 수 있으 나, 이는 일 실시예에 불과할 뿐, 자연어 처리를 위한 언어 모델을 이용하여 자연어 형태의 메시지를 생성하여 제공할 수 있다. 본 발명의 다른 실시예로, 입력부를 통해 \"내일 모임 일정 잡아줘\"라는 사용자 음성이 입력된 경우, 프로 세서는 텍스트 획득 모듈을 제어하여 사용자 음성으로부터 텍스트 데이터를 획득할 수 있다. 그리고, 프로세서는 텍스트 분석 모듈을 제어하여 획득된 텍스트 데이터를 분석하여 목적 성분과 파 라미터 성분을 결정할 수 있다. 예를 들어, 프로세서는 텍스트 분석 모듈을 제어하여 텍스트 데이터 인 \"내일 일정 잡아줘\"를 분석하여 아래와 같이, 목적 성분과 파라미터 성분을 결정할 수 있다. <Goal: 일정 잡기> <Para1(Time): 내일, Para2(AppName): 스케줄 어플리케이션, Para3(Person.to): non> 그리고, 프로세서는 동작 결정 모듈을 제어하여 목적 성분 및 파라미터 성분을 바탕으로 사용자 음성 에 대응되는 동작을 결정할 수 있다. 구체적으로, 프로세셔는 동작 결정 모듈을 제어하여 목적 성분 을 바탕으로 동작의 유형이 \"일정 잡기\"임을 결정할 수 있고, 동작의 내용이 \"내일 모임을 스케줄 어플리케이션 에 등록하기\"로 결정할 수 있다. 그리고, 프로세서는 동작 수행 판단 모듈을 제어하여 결정된 동작이 수행 가능한지 여부를 판단할 수 있다. 결정된 동작이 수행 불가능한 경우, 프로세서는 대체 동작 판단 모듈을 제어하여 목적 성분 및 파라미터 성분을 바탕으로 결정된 동작을 대체할 수 있는 대체 동작을 결정할 수 있다. 예를 들어, 누구와의 모 임인지 여부를 나타내는 파라미터 성분이 없으므로, 프로세서는 동작 수행 판단 모듈을 제어하여 결 정된 동작이 수행 가능하지 않음을 판단할 수 있다. 프로세서는 대체 동작 판단 모듈을 제어하여 사용자 음성에 대응하는 동작의 대체 동작이 있는지 여 부를 판단할 수 있다. 예를 들어, 누구와의 모임인지 여부에 대한 정보가 없으므로, 프로세서는 대체 동작 판단 모듈을 제어하여 \"일정 잡기\"가 아닌 \"메모 남기기\"라는 상이한 동작의 유형을 가지는 대체 동작을 결정할 수 있다. 즉, 프로세서는 대체 동작 판단 모듈을 제어하여 동작의 유형이 \"메모 남기기\"이고, 동작의 내용이 \"내일 모임 일정을 메모로 작성\"이라는 대체 동작을 결정할 수 있다. 대체 동작이 결정된 경우, 프로세서는 대체 동작 안내 모듈을 제어하여 대체 동작을 안내하기 위한 메시지를 제공할 수 있다. 예를 들어, 동작의 유형이 \"메모 남기기\"이고, 동작의 내용이 \"내일 모임 일정을 메 모로 작성하기\"인 대체 동작의 경우, 프로세서는 대체 동작 안내 모듈을 제어하여 도 5에 도시된 바 와 같이, \"누구와 모임을 가지나요? 메모로 남길까요?\"라는 자연어 형태의 메시지를 디스플레이에 표시할수 있다. 한편, 상술한 바와 같이 프로세서는 기존의 범용 프로세서(예: CPU 또는 application processor)가 상술한 동작들을 수행할 수 있지만, 특정 동작들에 대하여는 인공 지능(AI; artificial intelligence)을 위한 전용 하 드웨어 칩이 동작을 수행할 수 있다. 도 6은 본 개시의 일 실시예에 따른, 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 우선, 전자 장치는 사용자 음성을 입력받는다(S610). 그리고, 전자 장치는 사용자 음성으로부터 텍스트 데이터를 획득한다(S620). 그리고, 전자 장치는 획득된 텍스트 데이터로부터 목표 성분 및 파라미터 성분을 결정한다(S630). 그리고, 전자 장치는 목표 성분 및 파라미터 성분을 바탕으로 사용자 음성에 대응되는 동작을 결정한다 (S640). 이때, 전자 장치는 목표 성분을 이용하여 사용자 음성에 대응하는 동작의 유형을 결정하고, 파라 미터 성분을 이용하여 사용자 음성에 대응하는 동작의 내용을 결정할 수 있다. 그리고, 전자 장치는 결정된 동작의 수행 가능 여부를 판단한다(S650). 결정된 동작의 수행이 가능하다고 판단된 경우(S650-Y), 전자 장치는 결정된 동작을 수행한다(S660). 반면, 결정된 동작의 수행이 불가능하다고 판단된 경우(S650-N), 전자 장치는 결정된 동작을 대체하기 위 한 대체 동작을 결정한다(S670). 이때, 전자 장치는 결정된 동작과 대칭되어 기 저장된 복수의 대체 동작 중 하나를 대체 동작으로 결정할 수 있으며, 결정된 동작을 대체 동작 판단 모델에 입력하여 대체 동작을 결정 할 수 있다. 그리고, 전자 장치는 대체 동작을 안내하기 위한 메시지를 제공한다(S680). 이때, 전자 장치는 대체 동작을 안내하기 위한 메시지를 자연어 형태로 처리하여 제공할 수 있다. 도 7은 본 개시의 다른 실시예에 따른, 사용자 단말과 지능형 비서 기능을 수행하기 위한 서버를 포함하는 지능 형 비서 시스템을 도시한 도면이다. 도 7을 참조하면, 지능형 비서 시스템은 사용자 단말 및 서버 를 포함할 수 있다. 한편, 상술한 실시예에서 설명한 전자 장치는 도 7에서 서버로 구현될 수 있다. 사용자 단말은 사용자가 발화한 사용자 음성을 획득하여 사용자 음성을 외부의 서버로 전송할 수 있 다. 서버는 수신된 사용자 음성에 대응하는 동작 또는 대체 동작을 결정하고, 제어 신호 또는 대체 동작을 안내하기 위한 메시지를 사용자 단말로 전송할 수 있다. 이와 같이, 사용자 단말과 서버가 연동 하여 지능형 비서 서비스를 제공할 수 있다. 즉, 사용자 단말은 단순히 사용자의 음성을 수신하고 메시지를 제공하는 입출력장치로서의 역할만을 수행 하고, 서버가 지능형 비서 서비스의 대부분을 처리하는 형태로 구현될 수도 있다. 특히, 도 7에 도시된 것 과 같이 사용자 단말이 스마트 워치와 같은 소형 웨어러블 장치로 구현되어 가용 리소스가 한정되는 경우 에, 대체 동작 결정 및 자연언어생성과 같은 과정은 리소스가 풍부한 서버에서 수행할 수 있다. 도 8은 본 개시의 일 실시예에 따른, 지능형 비서 시스템의 제어 방법을 설명하기 위한 시퀀스도이다. 이때, 사용자 단말은 범용 프로세서를 포함하고, 서버는 인공지능 전용 프로세서를 포함할 수 있다. 또는, 사용자 단말은 적어도 하나의 어플리케이션을 포함할 수 있고, 서버는 운영 체제(operating system)를 포함할 수 있다. 서버는 사용자 단말보다 더 집적화되거나, 전용화되거나, 딜레이(delay) 가 작거나, 성능이 우수하거나 또는 많은 리소스를 가진 구성 요소로서 인식 모델의 생성, 갱신 또는 적용 시에 요구되는 많은 연산을 사용자 단말보다 신속하고 효과적으로 처리 가능한 구성 요소가 될 수 있다. 이 경우, 사용자 단말 및 서버 간에 데이터를 송/수신하기 위한 인터페이스가 정의될 수 있다. 예로, 인식 모델에 적용할 학습 데이터를 인자 값(또는, 매개 값 또는 전달 값)으로 갖는 API(application program interface)가 정의될 수 있다. API는 어느 하나의 프로토콜(예로, 사용자 단말에서 정의된 프로토 콜)에서 다른 프로토콜(예로, 서버에서 정의된 프로토콜)의 어떤 처리를 위해 호출할 수 있는 서브 루틴 또는 함수의 집합으로 정의될 수 있다. 즉, API를 통하여 어느 하나의 프로토콜에서 다른 프로토콜의 동작이 수행될 수 있는 환경을 제공될 수 있다. 사용자 단말은 사용자 음성을 획득한다(S810). 이때, 사용자 단말은 사용자 단말에 구비되거나 사용자 단말과 연결된 마이크로부터 사용자 음성을 획득할 수 있다. 그리고, 사용자 단말은 사용자 음성을 외부의 서버로 전송한다(S820). 구체적으로, 사용자 단말(20 0)은 사용자 음성에 대응하는 음성 신호를 외부의 서버로 전송할 수 있다. 그리고, 서버는 수신된 사용자 음성으로부터 텍스트 데이터를 획득한다(S830). 그리고, 서버는 텍스트 데이터를 분석하고(S840), 사용자 음성에 대응하는 동작을 결정한다(S850). 구체적 으로, 서버는 텍스트 데이터로부터 목적 성분 및 파라미터 성분을 결정하고, 목적 성분으로부터 사용자 음 성에 대하는 동작의 유형을 결정하고, 파라미터 성분으로부터 사용자 음성에 대하는 동작의 내용을 결정할 수 있다. 사용자 음성에 대응하는 동작이 수행 불가능하다고 판단된 경우, 서버는 사용자 음성에 대응하는 동작을 대체할 수 있는 대체 동작을 결정한다(S860). 이때, 서버는 기 저장된 대체 동작들 중 하나를 대체 동작으 로 결정할 수 있으며, 학습된 대체 동작 판단 모델을 이용하여 대체 동작을 결정할 수 있다. 서버는 대체 동작을 안내하기 위한 메시지를 생성한다(S870). 이때, 서버는 자연어 형태로 메시지를 생성할 수 있다. 서버는 메시지를 사용자 단말로 전송하고(S880), 사용자 단말은 수신된 메시지를 출력한다 (S890). 상술한 바와 같은 본 개시의 실시예에 따라, 실행 불가능한 동작에 대한 대체 동작을 안내함으로써, 지능형 비 서 기능을 처음 이용하거나 익숙치 않는 사용자라도 더욱 쉽고 자연스럽게 지능형 비서 기능을 이용할 수 있게 된다. 도 9는 본 개시의 일부 실시 예에 따른 프로세서의 블록도이다. 도 9를 참조하면, 일부 실시 예에 따른 프 로세서는 데이터 학습부 및 대체 동작 판단부를 포함할 수 있다. 데이터 학습부는 대체 동작 결정을 위한 기준을 학습할 수 있다. 프로세서는 학습된 기준에 따라 입 력된 동작을 분석하여 사용자 음성에 대응되는 동작을 대체할 수 있는 대체 동작을 결정할 수 있다. 데이터 학 습부는 대체 동작을 결정하기 위하여 어떠한 데이터(또는 파라미터 성분)를 이용할 것인지 결정할 수 있다. 또한, 데이터 학습부는 학습에 이용될 데이터를 획득하고, 획득된 데이터를 후술할 대체 동작 판단 모델에 적용함으로써 대체 동작을 위한 기준을 학습할 수 있다. 대체 동작 판단부는 기학습된 대체 동작 판단 모델을 이용하여, 소정의 데이터로부터 사용자 음성에 대응 하는 동작을 대체할 수 있는 대체 동작을 판단할 수 있다. 대체 동작 판단부는 학습에 의한 기설정된 기준 에 따라 소정의 데이터(예를 들어, 결정된 동작의 목적 성분 및 파라미터 성분 중 적어도 하나)를 획득하고, 획 득된 데이터를 입력값으로 하여 대체 동작 판단 모델을 이용할 수 있다. 또한, 대체 동작 판단부는 입력된 데이터를 대체 동작 판단 모델에 적용하여 대체 동작에 대한 결과값을 획득할 수 있다. 그리고, 대체 동작 판단 부는 입력값 및 출력값에 대한 사용자 피드백을 바탕으로 대체 동작 판단 모델을 갱신할 수 있다. 데이터 학습부 및 대체 동작 판단부 중 적어도 하나는, 하나 또는 복수의 하드웨어 칩 형태로 제작되 어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부 및 대체 동작 판단부 중 적어도 하 나는 인공 지능(Artifical Intelligence, AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 기존의 범용 프로세서(예를 들어, CPU 또는 application processor) 또는 특정 기능을 위한 IP의 일부로 제작되어 전술한 각 종 전자 장치에 탑재될 수도 있다. 도 9의 실시 예에서는 데이터 학습부 및 대체 동작 판단부가 모두 전자 장치에 탑재된 경우를 도시하였으나, 이들은 각각 별개의 장치에 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 대체 동작 판 단부 중 하나는 전자 장치에 포함되고, 나머지 하나는 사용자 단말에 포함될 수 있다. 또한 데 이터 학습부 및 대체 동작 판단부는 서로 유선 또는 무선으로 연결되어, 데이터 학습부가 구축 한 대체 동작 판단 모델에 대한 정보가 대체 동작 판단부로 제공될 수 있고, 대체 동작 판단부로 입 력된 데이터가 추가 학습 데이터로 데이터 학습부로 제공될 수도 있다.한편, 데이터 학습부 및 대체 동작 판단부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데 이터 학습부 및 대체 동작 판단부 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭션을 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 비일시적 컴퓨터 판독가능 기록매체에 저장될 수 있다. 적 어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 어플리케이션에 의해 제공될 수 있다. 또는 적어도 하나의 소프트웨어 모듈 중 일부는 OS에 의해 제공되고, 나머지 일부는 소정의 어플리케 이션에 의해 제공될 수도 있다. 도 10a는 본 개시의 일부 실시 예에 따른 데이터 학습부의 블록도이다. 도 10a를 참조하면, 일부 실시 예 에 따른 데이터 학습부는 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습 부(131-4) 및 모델 평가부(131-5)를 포함할 수 있다. 데이터 획득부(131-1)는 대체 동작을 판단하기 위해 필요한 데이터를 획득할 수 있다. 특히, 데이터 획득부 (131-1)는 사용자 음성에 대응하는 동작을 결정할 수 있는 데이터를 학습 데이터로 획득할 수 있다. 예를 들어, 입력부를 통해 입력된 사용자 음성에 대응되는 신호, 사용자 음성에 대응하는 텍스트 데이터, 텍스트 데이 터로부터 결정된 목적 성분 및 파라미터 성분 중 적어도 하나를 입력받을 수 있다. 전처리부(131-2)는 대체 동작 판단을 위한 학습에 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리 할 수 있다. 전처리부(131-2)는 후술할 모델 학습부(131-4)가 대체 동작 판단을 위한 학습을 위하여 획득된 데 이터를 이용할 수 있도록, 획득된 데이터를 기설정된 포맷으로 가공할 수 있다. 예를 들어, 전처리부(131-2)는 입력된 사용자 음성에 대해 인식 대상이 되는 구간을 추출할 수 있다. 그리고, 전처리부(131-2)는 사용자 음성에 대응하는 신호에 대해 잡음 제거, 특징 추출 등을 수행하고, 텍스트 데이터로 변환할 수 있다. 다른 예로, 전처리부(131-2)는 입력된 사용자 음성의 주파수 성분을 분석하여 일부 주파수 성분을 강화하고, 나 머지 주파수 성분을 억제하는 방식으로 음성 인식에 적합하도록 음성 데이터를 생성할 수도 있다. 학습 데이터 선택부(131-3)는 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 데이터 는 모델 학습부(131-4)에 제공될 수 있다. 학습 데이터 선택부(131-3)는 대체 동작 판단을 위한 기설정된 기준 에 따라, 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 또한, 학습 데이터 선택부(131-3)는 후술할 모델 학습부(131-4)에 의한 학습에 의해 기설정된 기준에 따라 데이터를 선택할 수도 있다. 예를 들어, 학습 데이터 선택부(131-1)는 입력된 텍스트 데이터로부터 목적 성분 및 파라미터 성분만을 선택할 수 있다. 모델 학습부(131-4)는 학습 데이터에 기초하여 대체 동작을 어떻게 판단할지에 관한 기준을 학습할 수 있다. 또 한, 모델 학습부(131-4)는 대체 동작 판단을 위하여 어떤 학습 데이터를 이용해야 하는지에 대한 기준을 학습할 수도 있다. 모델 학습부(131-4)는 대체 동작 판단에 이용되는 대체 동작 판단 모델을 학습 데이터를 이용하여 학습시킬 수 있다. 이 경우, 대체 동작 판단 모델은 미리 구축된 모델일 수 있다. 예를 들어, 대체 동작 판단 모델은 기본 학습 데이터을 입력 받아 미리 구축된 모델일 수 있다. 다른 예로, 대체 동작 판단 모델은 빅데이터를 이용하여 미리 구축된 모델일 수 있다. 대체 동작 판단 모델은, 인식 모델의 적용 분야, 학습의 목적 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있다. 대체 동작 판단 모델은, 예를 들어, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 예컨대, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델이 대체 동작 판단 모델로서 사용될 수 있으나, 이에 한정되지 않는다. 다양한 실시 예에 따르면, 모델 학습부(131-4)는 미리 구축된 대체 동작 판단 모델이 복수 개가 존재하는 경우, 입력된 학습 데이터와 기본 학습 데이터의 관련성이 큰 대체 동작 판단 모델을 학습할 대체 동작 판단 모델로 결정할 수 있다. 이 경우, 기본 학습 데이터는 데이터의 타입별로 기분류되어 있을 수 있으며, 대체 동작 판단 모델은 데이터의 타입별로 미리 구축되어 있을 수 있다. 예를 들어, 기본 학습 데이터는 학습 데이터가 생성된 지역, 학습 데이터가 생성된 시간, 학습 데이터의 크기, 학습 데이터의 장르, 학습 데이터의 생성자, 학습 데이 터 내의 오브젝트의 종류 등과 같은 다양한 기준으로 기분류되어 있을 수 있다. 또한, 모델 학습부(131-4)는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 대체 동작 판단 모델을 학습시킬 수 있다. 예를 들어, 모델 학습부(131-4)는 학습 데이터를 입력 값으로 하는 지도 학습(supervised learning) 을 통하여 대체 동작 판단 모델을 학습시킬 수 있다. 다른 예로, 모델 학습부(131-4)는 별도의 지도 없이 대체 동작 판단 을 위해 필요한 데이터의 종류를 스스로 학습함으로써 대체 동작 판단을 위한 기준을 발견하는 비지도 학습 (unsupervised learning)을 통하여, 대체 동작 판단 모델을 학습시킬 수 있다. 또 다른 예로, 모델 학습부(131- 4)는 학습에 따른 대체 동작 판단의 결과가 올바른지에 대한 피드백을 이용하는 강화 학습(reinforcement learning)을 통하여, 대체 동작 판단 모델을 학습시킬 수 있다. 또한, 대체 동작 판단 모델이 학습되면, 모델 학습부(131-4)는 학습된 대체 동작 판단 모델을 저장할 수 있다. 이 경우, 모델 학습부(131-4)는 학습된 대체 동작 판단 모델을 전자 장치의 메모리에 저장할 수 있다. 이 경우, 학습된 대체 동작 판단 모델이 저장되는 메모리는 전자 장치의 적어도 하나의 다른 구성요 소에 관계된 명령 또는 데이터를 함께 저장할 수도 있다. 또한, 메모리는 소프트웨어 및/또는 프로그램을 저장할 수도 있다. 예를 들어, 프로그램은 커널, 미들웨어, 어플리케이션 프로그래밍 인터페이스(API) 및/또는 어플리케이션 프로그램(또는 \"어플리케이션\") 등을 포함할 수 있다. 모델 평가부(131-5)는 대체 동작 판단 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 판단 결과 가 소정 기준을 만족하지 못하는 경우, 모델 학습부(131-4)로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평 가 데이터는 대체 동작 판단 모델을 평가하기 위한 기설정된 데이터일 수 있다. 예를 들어, 모델 평가부(131-5)는 평가 데이터에 대한 학습된 대체 동작 판단 모델의 판단 결과 중에서, 판단 결과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족 하지 못한 것으로 평가할 수 있다. 예컨대, 소정 기준이 비율 2%로 정의되는 경우, 학습된 대체 동작 판단 모델 이 총 1000개의 평가 데이터 중의 20개를 초과하는 평가 데이터에 대하여 잘못된 판단 결과를 출력하는 경우, 모델 평가부(131-5)는 학습된 대체 동작 판단 모델이 적합하지 않은 것으로 평가할 수 있다. 한편, 학습된 대체 동작 판단 모델이 복수 개가 존재하는 경우, 모델 평가부(131-5)는 각각의 학습된 대체 동작 판단 모델에 대하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 대체 동작 판단 모 델로서 결정할 수 있다. 이 경우, 소정 기준을 만족하는 모델이 복수 개인 경우, 모델 평가부(131-5)는 평가 점 수가 높은 순으로 미리 설정된 어느 하나 또는 소정 개수의 모델을 최종 대체 동작 판단 모델로서 결정할 수 있 다. 한편, 데이터 학습부 내의 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학 습부(131-4) 및 모델 평가부(131-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치 에 탑재될 수 있다. 예를 들어, 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학 습부(131-4) 및 모델 평가부(131-5) 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예를 들어, CPU 또는 application processor) 또는 특정 기능을 위한 IP의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습부(131-4) 및 모델 평가 부(131-5)는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습부(131-4) 및 모델 평가 부(131-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 한편, 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습부(131-4) 및 모델 평가 부(131-5) 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습부(131-4) 및 모델 평가부(131-5) 중 적어도 하나가 소프트웨어 모듈(또는, 인 스트럭션을 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 비일시적 컴퓨터 판독가능 기록매체 에 저장될 수 있다. 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 어플리 케이션에 의해 제공될 수 있다. 또는 적어도 하나의 소프트웨어 모듈 중 일부는 OS에 의해 제공되고, 나머지 일 부는 소정의 어플리케이션에 의해 제공될 수도 있다. 도 10b는 본 개시의 일부 실시 예에 따른 대체 동작 판단부의 블록도이다. 도 10b를 참조하면, 일부 실시 예에 따른 대체 동작 판단부는 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신부(132-5)를 포함할 수 있다 데이터 획득부(132-1)는 대체 동작 판단에 필요한 데이터를 획득할 수 있으며, 전처리부(132-2)는 대체 동작 판 단을 위해 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 전처리부(132-2)는 후술할판단 결과 제공부(132-4)가 대체 동작 판단을 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기설 정된 포맷으로 가공할 수 있다. 데이터 선택부(132-3)는 전처리된 데이터 중에서 대체 동작 판단에 필요한 데이터를 선택할 수 있다. 선택된 데 이터는 판단 결과 제공부(132-4)에게 제공될 수 있다. 데이터 선택부(132-3)는 대체 동작 판단을 위한 기설정된 기준에 따라, 전처리된 데이터 중에서 일부 또는 전부를 선택할 수 있다. 또한, 데이터 선택부(132-3)는 후술할 모델 학습부(142-4)에 의한 학습에 의해 기설정된 기준에 따라 데이터를 선택할 수도 있다. 판단 결과 제공부(132-4)는 선택된 데이터를 대체 동작 판단 모델에 적용하여 사용자 음성에 대응되는 동작을 대체할 수 있는 대체 동작을 판단할 수 있다. 판단 결과 제공부(132-4)는 데이터 선택부(132-3)에 의해 선택된 데이터를 입력 값으로 이용함으로써, 선택된 데이터를 대체 동작 판단 모델에 적용할 수 있다. 또한, 판단 결과 는 대체 동작 판단 모델에 의해 결정될 수 있다. 예를 들어, 판단 결과 제공부(132-4)는 사용자 음성에 대응되 는 동작을 판단할 수 있는 데이터를 대체 동작 판단 모델에 입력하여 사용자 음성에 대응되는 동작을 대체할 수 있는 동작을 판단할 수 있다. 모델 갱신부(132-5)는 판단 결과 제공부(132-4)에 의해 제공되는 판단 결과에 대한 평가에 기초하여, 대체 동작 판단 모델이 갱신되도록할 수 있다. 예를 들어, 모델 갱신부(132-5)는 판단 결과 제공부(132-4)에 의해 제공되 는 판단 결과를 모델 학습부(131-4)에게 제공함으로써, 모델 학습부(131-4)가 대체 동작 판단 모델을 갱신하도 록 할 수 있다. 한편, 대체 동작 판단부 내의 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신부(132-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장 치에 탑재될 수 있다. 예를 들어, 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신부(132-5) 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예를 들어, CPU 또는 application processor) 또는 특정 기능을 위한 IP의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신 부(132-5) 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신 부(132-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 전자 잗치와 연동하는 서버에 포함될 수 있다. 한편, 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신 부(132-5) 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부(132-1), 전처리부(132-2), 데이 터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신부(132-5) 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭션을 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 비일시적 컴퓨터 판독가능 기록매 체에 저장될 수 있다. 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 어플 리케이션에 의해 제공될 수 있다. 또는 적어도 하나의 소프트웨어 모듈 중 일부는 OS에 의해 제공되고, 나머지 일부는 소정의 어플리케이션에 의해 제공될 수도 있다. 본 개시에서 사용된 용어 \"~부\"는 하드웨어, 소프트웨어 또는 펌웨어로 구성된 유닛을 포함하며, 예를 들면, 로 직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또 는 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수 있다. 예를 들면, 모듈은 ASIC(application-specific integrated circuit)으로 구성될 수 있다. 본 문서의 다양한 실시예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호 출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시예들에 따른 전자 장치(예: 전자 장치(A)) 를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세서의 제어하 에 다른 구성요소들을 이용하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리 터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않 으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다.일시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경 우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다 양한 실시예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차 적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다."}
{"patent_id": "10-2017-0157902", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른, 전자 장치의 구성을 간략히 도시한 블럭도, 도 2는 본 개시의 일 실시예에 따른, 전자 장치의 구성을 상세히 도시한 블럭도, 도 3은 본 개시의 일 실시예에 따른, 지능형 비서 기능을 수행하기 위한 구성을 도시한 블럭도, 도 4a 내지 도 5는 본 개시의 일 실시예에 따른, 대체 동작을 안내하기 위한 메시지를 도시한 도면, 도 6은 본 개시의 일 실시예에 따른, 전자 장치의 제어 방법을 설명하기 위한 도면, 도 7은 본 개시의 다른 실시예에 따른, 사용자 단말과 지능형 비서 기능을 수행하기 위한 서버를 포함하는 지능 형 비서 시스템을 도시한 도면, 도 8은 본 개시의 일 실시예에 따른, 지능형 비서 시스템의 제어 방법을 설명하기 위한 시퀀스도, 도 9는 본 개시의 일 실시 예에 따른, 프로세서의 구성을 도시한 블록도 도 10a는 본 개시의 일 실시 예에 따른, 데이터 학습부의 구성을 도시한 블록도, 도 10b는 본 개시의 일 실시 예에 따른 대체 동작 판단부의 구성을 도시한 블록도이다."}
