{"patent_id": "10-2021-0155956", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0069700", "출원번호": "10-2021-0155956", "발명의 명칭": "이산 개체의 가중치 측정 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "이종률"}}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수개의 레이어로 구성된 신경망 모델에서 수행되는 방법에 있어서,이산 개체의 인덱스로 구성된 데이터를 입력받는 단계;상기 입력된 데이터를 임베딩 레이어를 통해 각각의 인덱스에 상응하는 임베딩 벡터로 변환하는 단계;마스크 벡터와 상기 임베딩 벡터의 요소별 곱셈을 통해 마스킹 된 벡터를 생성하는 단계;상기 마스킹 된 벡터에 기반한 출력을 이용하여 손실도를 계산하는 단계; 및상기 손실도에 기반하여 모델을 학습시키는 단계;를 포함하는 것을 특징으로 하는 이산 개체의 가중치 측정 방법."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 마스킹 된 벡터를 생성하는 단계는상기 이산 개체에 대한 가중치 값에 대하여 내림(floor) 연산을 수행하는 단계;상기 내림 연산 결과 값보다 작거나 같은 정수에 상응하는 위치(index)에 1을 할당하는 단계; 및상기 내림 연산 값보다 큰 정수에 상응하는 위치에 0을 할당하는 단계;를 포함하는 것을 특징으로 하는 이산 개체의 가중치 측정 방법."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 마스크 벡터는 상기 임베딩 벡터의 요소들 중 사용할 값은 1로 표현하고, 사용하지 않을 값은 0으로 표현하는 것을 특징으로하는 이산 개체의 가중치 측정 방법."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 2에 있어서,상기 마스킹 된 벡터를 생성하는 단계는상기 가중치 값을 학습하기 위한 게이트 함수에 상응하는 값을 상기 마스킹 된 벡터의 요소에 각각 더하는 단계를 더 포함하는 것을 특징으로 하는 이산 개체의 가중치 측정 방법."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 게이트 함수는상기 가중치 값의 학습이 가능하도록 상기 게이트 함수 값이 0에 가까운 값을 가지고, 기설정된 구간에서 미분가능한 함수에 상응하는 것을 특징으로 하는 이산 개체의 가중치 측정 방법."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,공개특허 10-2023-0069700-3-상기 게이트 함수는하기 수학식 1의 함수에 상응하고, 하기 L은 1000 이상의 양의 정수에 상응하는 것을 특징으로 하는 이산 개체의 가중치 측정 방법:[수학식 1]"}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 5에 있어서,상기 손실도를 계산하는 단계는상기 신경망 모델의 출력과 정답의 차이에 상응하는 제1 손실도, 및 상기 이산 개체에 대한 각각의 가중치 값으로 구성된 가중치 벡터에 기반하여 생성된 마스킹 벡터의 희소도와 목표 희소도의 차이에 상응하는 제2 손실도에 기반하여 최종 손실도를 계산하는 것을 특징으로 하는 이산 개체의 가중치 측정 방법."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 마스킹 된 벡터를 생성하는 단계는상기 임베딩 벡터에 대한 마스킹 적용으로 인한 출력의 급격한 변화를 보정하는 단계를 더 포함하는 것을 특징으로 하는 이산 개체의 가중치 측정 방법."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 프로그램이 기록된 메모리; 및상기 프로그램을 실행하는 프로세서를 포함하며,상기 프로그램은이산 개체의 인덱스로 구성된 데이터를 입력받는 단계;상기 입력된 데이터를 임베딩 레이어를 통해 각각의 인덱스에 상응하는 임베딩 벡터로 변환하는 단계;마스크 벡터와 상기 임베딩 벡터의 요소별 곱셈을 통해 마스킹 된 벡터를 생성하는 단계;상기 마스킹 된 벡터에 기반한 출력을 이용하여 손실도를 계산하는 단계; 및상기 손실도에 기반하여 모델을 학습시키는 단계;의 수행을 위한 명령어들을 포함하는 것을 특징으로 하는 이산 개체의 가중치 측정 장치."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "에 있어서,상기 마스크 벡터는 상기 임베딩 벡터의 요소들 중 사용할 값은 1로 표현하고, 사용하지 않을 값은 0으로 표현하는 것을 특징으로하는 이산 개체의 가중치 측정 장치."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 10에 있어서,상기 마스킹 된 벡터를 생성하는 단계는상기 가중치 값을 학습하기 위한 게이트 함수에 상응하는 값을 상기 마스킹 된 벡터의 요소에 각각 더하는 단계를 더 포함하는 것을 특징으로 하는 이산 개체의 가중치 측정 장치."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 12에 있어서,상기 게이트 함수는상기 가중치 값의 학습이 가능하도록 상기 게이트 함수 값이 0에 가까운 값을 가지고, 기설정된 구간에서 미분가능한 함수에 상응하는 것을 특징으로 하는 이산 개체의 가중치 측정 장치."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13에 있어서,상기 게이트 함수는하기 수학식 1의 함수에 상응하고, 하기 L은 1000 이상의 양의 정수에 상응하는 것을 특징으로 하는 이산 개체의 가중치 측정 장치:[수학식 1]"}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 13에 있어서,상기 손실도를 계산하는 단계는상기 신경망 모델의 출력과 정답의 차이에 상응하는 제1 손실도, 및 상기 이산 개체에 대한 각각의 가중치 값으로 구성된 가중치 벡터에 기반하여 생성된 마스킹 벡터의 희소도와 목표 희소도의 차이에 상응하는 제2 손실도에 기반하여 최종 손실도를 계산하는 것을 특징으로 하는 이산 개체의 가중치 측정 장치."}
{"patent_id": "10-2021-0155956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 15에 있어서,상기 마스킹 된 벡터를 생성하는 단계는상기 임베딩 벡터에 대한 마스킹 적용으로 인한 출력의 급격한 변화를 보정하는 단계를 더 포함하는 것을 특징으로 하는 이산 개체의 가중치 측정 장치.공개특허 10-2023-0069700-5-"}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 복수개의 레이어로 구성된 신경망 모델에서 수행되는 이산 개체의 가중치 측정 방법은 이산 개체의 인덱스로 구성된 데이터를 입력받는 단계, 상기 입력된 데이터를 임베딩 레이어를 통해 각각의 인덱스에 상응하는 임베딩 벡터로 변환하는 단계, 마스크 벡터와 상기 임베딩 벡터 의 요소별 곱셈을 통해 마스킹 된 벡터를 생성하는 단계, 상기 마스킹 된 벡터에 기반한 출력을 이용하여 손실도 를 계산하는 단계, 및 상기 손실도에 기반하여 모델을 학습시키는 단계를 포함한다."}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 임베딩 벡터로 표현되는 이산 개체를 입력으로 하는 신경망 모델의 중요도 계산 방법에 관한 것이다. 구체적으로, 본 발명은 이산 개체의 개별 중요도를 고려한 모델 경량화 기술에 관한 것이다."}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 주로 서버에서 이루어지던 신경망 모델의 추론이 경량 디바이스(예: 스마트폰, 로봇, TV 등)에서 수행되 는 것으로 변해가면서 신경망 모델이 차지하는 메모리 및 연산량을 줄이기 위한 경량화 연구가 활발히 진행되고 있다. 같은 이유로 이산 개체를 다루는 대표적인 신경망 모델인 자연어 처리 모델, 지식 그래프 기반 추론 모델, 추천 시스템 모델을 위한 경량화 기법도 많이 연구되고 있다. 특히, 자연어 처리 모델의 단어, 지식 그래프 기반 추론 모델의 노드 임베딩, 추천 시스템 모델 내에 아이템과 같은 이산 개체를 처리하기 위한 임베딩 행렬의 크기가 일반적으로 매우 크기 때문에 이를 효과적으로 경량화하 는 방법들이 많이 제안되었다. 그러나, 기존 방법들은 개체의 개별 중요도는 고려하지 않은 행렬 근사 방법 또는 양자화(quantization) 방법에 기반을 두거나, 빈도와 같은 단순 휴리스틱에 의존하여 중요도를 선정한 뒤 이를 가중치로 하여 경량화하는 방 식을 취하기 때문에 성능상 효과적이지도 않고, 태스크(task)에 따라 부적합한 경우도 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내 공개특허공보 제10-2021-0067499호(발명의 명칭: 딥러닝 기반 엔드투엔드 음성 합성 시스 템의 음성 합성 경량화 방법)"}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 이산 개체를 처리하는 신경망 모델에서 각 개체가 갖는 최적 중요도를 측정하는 방법을 제공 하는 것이다. 또한, 본 발명의 목적은 임베딩 레이어 경량화 방법을 효과적으로 적용할 수 있도록 이산 개체별 중요도를 제공 하는 것이다."}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 복수개의 레이어로 구성된 신경망 모델에서 수행되는 이산 개체의 가중치 측정 방법은 이산 개체의 인덱스로 구성된 데이터를 입력받는 단계, 상기 입력된 데이터를 임베딩 레이어를 통해 각각의 인덱스에 상응하는 임베딩 벡터로 변환하는 단계, 마스크 벡터와 상기 임베딩 벡 터의 요소별 곱셈을 통해 마스킹 된 벡터를 생성하는 단계, 상기 마스킹 된 벡터에 기반한 출력을 이용하여 손 실도를 계산하는 단계, 및 상기 손실도에 기반하여 모델을 학습시키는 단계를 포함한다. 이때, 상기 마스킹 된 벡터를 생성하는 단계는 상기 이산 개체에 대한 가중치 값에 대하여 내림(floor) 연산을 수행하는 단계, 상기 내림 연산 결과 값보다 작거나 같은 정수에 상응하는 위치(index)에 1을 할당하는 단계, 및 상기 내림 연산 값보다 큰 정수에 상응하는 위치에 0을 할당하는 단계를 포함할 수 있다. 이때, 상기 마스크 벡터는 상기 임베딩 벡터의 요소들 중 사용할 값은 1로 표현하고, 사용하지 않을 값은 0으로 표현할 수 있다. 이때, 상기 마스킹 된 벡터를 생성하는 단계는 상기 가중치 값을 학습하기 위한 게이트 함수에 상응하는 값을 상기 마스킹 된 벡터의 요소에 각각 더하는 단계를 더 포함할 수 있다.이때, 상기 게이트 함수는 상기 가중치 값의 학습이 가능하도록 상기 게이트 함수 값이 0에 가까운 값을 가지고, 기설정된 구간에서 미분 가능한 함수에 상응할 수 있다. 이때, 상기 게이트 함수는 하기 수학식 1의 함수에 상응하고, 하기 L은 1000이상의 양의 정수에 상응할 수 있다. [수학식 1]"}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "이때, 상기 손실도를 계산하는 단계는 상기 신경망 모델의 출력과 정답의 차이에 상응하는 제1 손실도, 및 상기 이산 개체에 대한 각각의 가중치 값으로 구성된 가중치 벡터에 기반하여 생성된 마스킹 벡터의 희소도와 목표 희소도의 차이에 상응하는 제2 손실도에 기반하여 최종 손실도를 계산할 수 있다. 이때, 상기 마스킹 된 벡터를 생성하는 단계는 상기 임베딩 벡터에 대한 마스킹 적용으로 인한 출력의 급격한 변화를 보정하는 단계를 더 포함할 수 있다. 또한, 상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 이산 개체의 가중치 측정 장치는 적어도 하나 의 프로그램이 기록된 메모리, 및 상기 프로그램을 실행하는 프로세서를 포함하며, 상기 프로그램은 이산 개체 의 인덱스로 구성된 데이터를 입력받는 단계, 상기 입력된 데이터를 임베딩 레이어를 통해 각각의 인덱스에 상 응하는 임베딩 벡터로 변환하는 단계, 마스크 벡터와 상기 임베딩 벡터의 요소별 곱셈을 통해 마스킹 된 벡터를 생성하는 단계, 상기 마스킹 된 벡터에 기반한 출력을 이용하여 손실도를 계산하는 단계, 및 상기 손실도에 기 반하여 모델을 학습시키는 단계의 수행을 위한 명령어들을 포함한다. 이때, 상기 마스킹 된 벡터를 생성하는 단계는 상기 이산 개체에 대한 가중치 값에 대하여 내림(floor) 연산을 수행하는 단계, 상기 내림 연산 결과 값보다 작거나 같은 정수에 상응하는 위치(index)에 1을 할당하는 단계, 및 상기 내림 연산 값보다 큰 정수에 상응하는 위치에 0을 할당하는 단계를 포함할 수 있다. 이때, 상기 마스크 벡터는 상기 임베딩 벡터의 요소들 중 사용할 값은 1로 표현하고, 사용하지 않을 값은 0으로 표현할 수 있다. 이때, 상기 마스킹 된 벡터를 생성하는 단계는 상기 가중치 값을 학습하기 위한 게이트 함수에 상응하는 값을 상기 마스킹 된 벡터의 요소에 각각 더하는 단계를 더 포함할 수 있다. 이때, 상기 게이트 함수는 상기 가중치 값의 학습이 가능하도록 상기 게이트 함수 값이 0에 가까운 값을 가지고, 기설정된 구간에서 미분 가능한 함수에 상응할 수 있다. 이때, 상기 게이트 함수는 하기 수학식 1의 함수에 상응하고, 하기 L은 1000 이상의 양의 정수에 상응할 수 있 다. [수학식 1]"}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "이때, 상기 손실도를 계산하는 단계는 상기 신경망 모델의 출력과 정답의 차이에 상응하는 제1 손실도, 및 상기 이산 개체에 대한 각각의 가중치 값으로 구성된 가중치 벡터에 기반하여 생성된 마스킹 벡터의 희소도와 목표 희소도의 차이에 상응하는 제2 손실도에 기반하여 최종 손실도를 계산할 수 있다. 이때, 상기 마스킹 된 벡터를 생성하는 단계는 상기 임베딩 벡터에 대한 마스킹 적용으로 인한 출력의 급격한 변화를 보정하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 이산 개체를 처리하는 신경망 모델에서 각 개체가 갖는 최적 중요도를 측정하는 방법을 제공 할 수 있다. 또한, 본 발명은 임베딩 레이어 경량화 방법을 효과적으로 적용할 수 있도록 이산 개체별 중요도를 제공할 수 있다."}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 비록 \"제1\" 또는 \"제2\" 등이 다양한 구성요소를 서술하기 위해서 사용되나, 이러한 구성요소는 상기와 같은 용 어에 의해 제한되지 않는다. 상기와 같은 용어는 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용될 수 있다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있다. 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세 서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 또는 \"포함하는(comprising)\"은 언급된 구성요소 또는 단계가 하나 이상의 다른 구성요소 또는 단 계의 존재 또는 추가를 배제하지 않는다는 의미를 내포한다."}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 해석될 수 있다. 또한, 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 본 발명은 인공지능, 기계학습 방법론에 속하며, 세부적으로는 임베딩 벡터로 표현되는 이산 개체(예: 단어, 그 래프 노드, 상품 등)를 입력으로 받는 신경망 모델에 대해 모델이 추론하는데 있어서 각 이산 개체의 중요도를계산하는 기술이다. 해당 중요도는 이산 개체들의 임베딩 행렬을 경량화 또는 압축 할 때 각 개체에 대응하는 점수(score)로 사용될 수 있다. 도 1은 이산 개체를 임베딩 레이어를 통해 다루는 일반적인 신경망 모델 구조를 나타낸 도면이다. 도 1을 참조하면, 학습 데이터셋으로부터 받은 입력은 각 이산 개체의 인덱스 번호로 구성되어 있고, 이는 임베딩 레이어를 통과하면서 임베딩 테이블 내 해당 인덱스에 위치한 임베딩 벡터로 변환된다. 변환된 임베딩 벡터들은 중간 레이어들를 거쳐 최종 출력 레이어로 전달되며, 출력된 결과와 정답 레 이블이 다른 정도를 계산하여 손실도로 표현한다. 이 손실도를 경사 하강법과 같은 최적화 방법 을 통해 최소화함으로써 모델이 학습된다. 본 발명은 도 1과 같이 일반적인 이산 개체를 다루는 신경망 모델에서 임베딩 레이어에 적용되어 모델의 추론에 있어서 각 개체 별 중요도를 자동으로 최적 추론하는 기술에 대한 것이다. 도 2는 본 발명의 일실시예에 따른 이산 개체의 가중치 측정 방법을 나타낸 흐름도이다. 구체적으로, 본 발명의 일실시예에 따른 이산 개체의 가중치 측정 방법은 복수개의 레이어로 이루어진 신경망 모델에서 수행될 수 있다. 이때, 복수개의 레이어는 임베딩 레이어, 보정 레이어, 중간 레이어, 출력 레이어, 손실함수 측정부 등을 포함 할 수 있다. 이때, 상기 레이어의 종류 및 개수는 예시적인 것이며 본 발명의 범위가 이에 한정되는 것은 아니다. 도 2를 참조하면, 이산 개체의 가중치 측정 장치에서 수행되는 방법은 이산 개체의 인덱스로 구성된 데이터를 입력받는다(S110). 다음으로, 상기 입력된 데이터를 임베딩 레이어를 통해 각각의 인덱스에 상응하는 임베딩 벡터로 변환한다 (S120). 다음으로 마스크 벡터와 상기 임베딩 벡터의 요소별 곱셈(element-wise multiplication)을 통해 마스킹 된 벡터 를 생성한다(S130). 이때, 상기 마스크 벡터는 어떤 임베딩 벡터에 대해 특정 방법에 따라서 해당 벡터의 요소들 중에서 사용 할 값은 1로 표현하고, 사용하지 않을 값은 0으로 표현한 벡터에 상응할 수 있다. 이때, 상기 마스킹 된 벡터를 생성하는 단계(S130)는 상기 이산 개체에 대한 가중치 값에 대하여 내림(floor) 연산을 수행하는 단계, 상기 내림 연산 결과 값보다 작거나 같은 정수에 상응하는 위치(index)에 1을 할당하는 단계, 및 상기 내림 연산 값보다 큰 정수에 상응하는 위치에 0을 할당하는 단계를 포함할 수 있다. 예를 들어, 특정 이산 개체의 가중치 값이 2.1에 상응하는 경우, 2.1에 대하여 내림 연산을 수행하고, 내림 연 산 결과 값인 2보다 작거나 같은 정수에 상응하는 위치에 1을 할당하고, 2보다 큰 정수에 상응하는 위치에 0을 할당할 수 있다. 이때, 상기 마스킹 된 벡터를 생성하는 단계(S130)는 상기 가중치 값을 학습하기 위한 게이트 함수에 상응하는 값을 상기 마스킹 된 벡터의 요소에 각각 더하는 단계를 더 포함할 수 있다. 이때, 상기 게이트 함수는 상기 가중치 값의 학습이 가능하도록 상기 게이트 함수 값이 0에 가까운 값을 가지고, 기설정된 구간에서 미분 가능한 함수에 상응할 수 있다. 예를 들어, 상기 게이트 함수의 함수 값은 기설정된 구간에서 0.001이하의 값을 가지도록 설정할 수 있다. 즉, 함수 값이 0에 가까우면서도 미분한 결과가 0이 아닌 값을 가지는 게이트 함수를 이용하여 일반적으로 학습 이 불가능한 마스크 벡터에 대한 학습을 가능하게 할 수 있다. 예를 들어, 상기 게이트 함수는 하기 수학식 1의 함수에 상응할 수 있다. 이때, 하기 수학식 1의 L은 상기 게이 트 함수의 함수 값이 0에 근사하도록 충분히 큰 값을 가지는 양의 값에 상응할 수 있다. 예를 들어, 하기 수학 식 1의 L은 1000 이상의 양의 정수에 상응할 수 있다.[수학식 1]"}
{"patent_id": "10-2021-0155956", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이때, 상기 마스킹 된 벡터를 생성하는 단계(S130)는 상기 임베딩 벡터에 대한 마스킹 적용으로 인한 출력의 급 격한 변화를 보정하는 단계를 더 포함할 수 있다. 다음으로, 상기 마스킹 된 벡터에 기반한 출력을 이용하여 손실도를 계산한다(S140). 이때, 상기 손실도를 계산하는 단계(S140)는 상기 신경망 모델의 출력과 정답의 차이에 상응하는 제1 손실도, 및 상기 이산 개체에 대한 각각의 가중치 값으로 구성된 가중치 벡터에 기반하여 생성된 마스킹 벡터의 희소도 와 목표 희소도의 차이에 상응하는 제2 손실도에 기반하여 최종 손실도를 계산할 수 있다. 즉, 제1 손실도 및 제2 손실도를 하이퍼파라미터를 통해 가중 덧셈을 수행하여 최종 손실도를 계산할 수 있다. 다만, 최종 손실도를 구하는 방법은 다양하게 차용될 수 있으며 상술한 구성에 의해 한정되지 않는다. 다음으로, 상기 손실도에 기반하여 모델을 학습시킨다(S150). 이때, 상기 학습과정(S150)은 손실도를 최소화하는 방향으로 경사 하강법과 같은 최적화 방법을 통해 수행될 수 있다. 도 3은 이산 개체들의 임베딩 벡터를 모은 임베딩 행렬의 예시도이다. 도 3을 참조하면, 임베딩 행렬은 각 이산 객체를 나타나는 인덱스에 따라 임베딩 벡터를 행으로 가지 고 있으므로 이산 개체의 숫자만큼의 임베딩 벡터를 가진다. 일반적으로 모델이 다루고자 하는 이산 개체의 개 수가 많기 때문에 이 임베딩 행렬의 크기는 모델의 전체 크기 대비 상당 수준을 차지한다. 도 4는 임베딩 행렬 내에 임베딩 벡터와 이 벡터에 대한 마스크 벡터, 그리고 마스킹 된 벡터의 예시도이다. 도 4를 참조하면, 어떤 임베딩 벡터에 대해 특정 방법에 따라서 해당 벡터의 요소들 중에서 사용할 값은 1 로 표현하고, 사용하지 않을 값은 0으로 표현한 마스크 벡터가 있고, 둘 간에 요소별 곱셈(element-wise multiplication)을 통해 마스킹 된 벡터를 얻을 수 있다. 도 5는 각 이산 개체에 대하여 마스크 벡터를 곱하여 생성된 임베딩 행렬을 나타낸 도면이다. 도 5를 참조하면, 마스킹 된 임베딩 행렬에서 마스크가 적용된 위치는 0을 값으로 갖고, 그 밖에 위 치는 원래 임베딩 행렬에서의 값과 동일한 값을 갖는다. 도 6은 본 발명의 일실시예에 따른 방법의 임베딩 행렬을 예시적으로 나타낸 도면이다. 도 5의 임베딩 행렬은 임의의 마스크 벡터 생성 방식으로 만들어진 일반적인 임베딩 행렬을 표현한 예시이 고, 본 발명에서는 끝에서부터 연속적으로 0을 갖도록 조정된 마스크 벡터들을 가지고 마스킹 된 임베딩 행렬 을 만들어내는 기술을 제안한다. 도 6의 임베딩 행렬은 끝에서부터 연속적으로 0을 갖도록 조정된 마스크 벡터들로 마스킹 되어있기 때문에, 이 행렬의 열을 기준으로 끝에서부터 영 벡터를 최대한 갖도록 부분 행렬를 정의하면, 임베 딩 행렬의 계수(rank)는 마스킹 전 임베딩 행렬의 계수 보다 부분 행렬의 열 벡터 개수만큼 작 은 값을 갖는 특성이 있다. 이 특성을 통해 각 이산 개체의 마스크 벡터의 0의 개수를 조절하여 효과적으로 개체별로 정보의 할당된 크기를 제한할 수 있다. 도 7은 이산 개체의 중요도를 의미하는 가중치 값을 통해 마스크 벡터를 생성하고 임베딩 벡터에 적용하는 것을 나타낸 도면이다.도 7을 참조하면, w에 대한 중요도를 의미하는 0보다 큰 스칼라 값을 갖는 파라미터 xw가 주어졌을 때, 끝에서 부터 연속적으로 0을 갖는 마스크 벡터 mw를 만들어내는 과정을 확인할 수 있다. 이산 개체 w에 대해 0보다 큰 스칼라 값을 갖는 가중치 파라미터 xw 가 주어지면, 이 값보다 작은 정수 중 에서 가장 큰 정수를 찾는 연산을 수행한 뒤 이 값보다 작거나 같은 위치(index)에는 1을 부여하고, 큰 위 치에는 0을 할당하는 모듈이 마스크 벡터 mw를 계산한다. 이렇게 만들어진 마스크 벡터는 w의 임베딩 벡터 vw와 요소별 곱셈을 수행하여 마스킹 된 벡터을 얻어낼 수 있다. 도 8은 학습 가능한 마스크 벡터와 이를 적용한 마스킹 된 임베딩 벡터를 예시적으로 나타낸 도면이다. 도 8을 참조하면, 이산 개체 w에 대해 0보다 큰 스칼라 값을 갖는 파라미터 xw 가 주어지면, 이 값보다 작 은 정수 중에 가장 큰 정수를 찾는 연산를 수행하고, 이 정수보다 작거나 같은 위치에는 1을 부여하고, 큰 위치에는 0을 할당하여 마스크 벡터 mw를 계산한다. 여기에 학습 시 상위 레이어에서 전달받은 gradient 값을 xw 로 전달하여 xw가 학습되도록 만들기 위한 게이트 함수를 mw의 각 요소(element)에 더한다. 이를 위한 게이트 함수는 다양한 방식으로 정의될 수 있는데, 이 함수는 거의 0에 가깝되 미분한 결과가 0이 아 닌 값을 가지면 된다. 예를 들어 상기 수학식 1과 같은 함수가 게이트 함수로 사용될 수 있다. 게이트 함수를 mw의 각 요소에 더해 만들어진 학습 가능한 마스크 벡터와 임베딩 벡터 간 요소 별 곱셈을 계산하여 만들어진 벡터는 게이트 함수의 값이 거의 0에 가깝기 때문에 도 7에서 계산된 마스킹 된 임베딩 벡터에 근사한 값을 가진다. 그럼에도 게이트 함수는 0이 아닌 그래디언트 값을 xw에 전달할 수 있어서 주어진 환경에서 최적화된 xw을 모델 학습을 통해 찾을 수 있게 한다. 도 9는 본 발명의 일실시예에 따른 학습 가능한 마스크 벡터들이 적용된 임베딩 레이어를 사용하는 신경망 모델 을 예시적으로 나타낸 도면이다. 도 9를 참조하면, 도 1의 신경망 모델과 동일하게 학습 데이터셋으로부터 받은 입력은 각 이산 개체 의 인덱스 번호로 구성되어 있고, 이는 임베딩 레이어를 통과하면서 임베딩 테이블 내 해당 인덱스에 위치한 임베딩 벡터로 변환된다. 변환된 임베딩 벡터들은 중간 레이어들를 거쳐 최종 출력 레이어로 전달되며, 출력된 결과와 정답 레 이블이 다른 정도를 계산하여 손실도로 표현한다. 이때, 도 9의 신경망 모델은 도 1의 임베딩 레이어 대신 도 8의 게이트 함수 기반 학습 가능한 마스크 벡 터들이 적용된 임베딩 레이어를 사용한다. 이때, 임베딩 레이어는 도 8에서 설명된 것처럼 마스크 벡터를 생성하기 위해 총 이산 개체 개수만큼의 학 습 가능한 파라미터를 갖는데, 이는 가중치 벡터로 표현될 수 있다. 임베딩 레이어의 임베딩 행렬의 크기를 알고 있기 때문에, 가중치 벡터의 각 요소 값에 따라 마 스킹 벡터를 생성하여 희소도(Sparsity)를 계산할 수 있고, 목표 희소도 대비 그 차이를 손실로 계산(81 0)하여 이 결과를 모델의 출력과 정답 간 손실도와 더하는 과정을 수행하여 최종 손실도을 얻는 다. 이때, 더하는 과정은 하이퍼파라미터를 통해 가중(weighted) 덧셈을 수행하는 것도 가능하다. 계산된 최종 손실도를 최소화 하는 방향으로 경사 하강법과 같은 최적화 방법을 통해 모델 학습이 진행되 면, 학습 데이터셋에 부합하는 신경망 모델이 계산되면서 목표 희소도에 가까운 희소도를 만들어내는 마스 킹 가중치 벡터를 얻게 된다. 이때, 목표 희소도에 매우 높은 값을 할당하게 되면, 신경망 모델은 학습 과정에서 이산 개체의 중요도에 따라 선별적인 마스킹을 하도록 자동 학습된다.예를 들어, 중요한 단어는 마스킹을 덜하게 되고, 중요하지 않은 단어는 마스킹을 더 많이 하게 된다. 즉, 학습이 끝난 후에 마스킹 정도에 따라서 주어진 신경망 모델에 중요한 단어와 중요하지 않은 단어를 자동으 로 구분할 수 있게 된다. 도 10은 마스킹 된 임베딩 벡터를 보정하는 보정 레이어를 적용하는 방식을 예시적으로 나타낸 도면이다. 도 10은 도 7에서 소개된 예시도에 보정 레이어를 추가하여 만들어진 것으로, 여기서 보정 레이어은 도6에서 소개된 마스킹 된 임베딩 벡터을 입력으로 하는 레이어이며 완전 연결(fully-connected) 레이어의 형태를 가질 수 있지만 이에 한정되지는 않는다. 신경망 모델은 학습을 통해 모델의 정확도를 높이는 방향으로 보정 레이어의 값을 결정한다. 도 10의 보정 레이어을 추가함으로써 임베딩 행렬에 마스킹 적용으로 임베딩 레이어 이후 신경망 레이어들 의 출력이 급격하게 변화하는 것을 방지할 수 있다. 도 11은 본 발명의 일실시예에 따른 보정 레이어가 적용된 신경망 모델을 예시적으로 나타낸 도면이다. 도 11을 참조하면, 도 9에 도시된 신경망 모델과 같이 학습 데이터셋으로부터 받은 입력은 각 이산 개체의 인덱스 번호로 구성되어 있고, 이는 임베딩 레이어를 통과하면서 임베딩 테이블 내 해당 인 덱스에 위치한 임베딩 벡터로 변환된다. 이때, 도 11에 도시된 신경망 모델은 도 9와 달리 보정 레이어가 추가된 것을 알 수 있다. 이때, 보정 레이어는 임베딩 레이어의 출력(이산 개체의 임베딩 벡터)을 입력으로 하여 중간 레이 어와 최종 출력 레이어에 대한 영향을 보정하는 역할을 한다. 보정된 임베딩 벡터들은 중간 레이어들를 거쳐 최종 출력 레이어로 전달되며, 출력된 결과와 정답 레이블이 다른 정도를 계산하여 손실도로 표현한다. 이때, 임베딩 레이어는 마스크 벡터를 생성하기 위해 총 이산 개체 개수만큼의 학습 가능한 파라미터를 갖는데, 이는 가중치 벡터로 표현될 수 있다. 임베딩 레이어의 임베딩 행렬의 크기를 알고 있기 때문에, 가중치 벡터의 각 요소 값에 따라 마스킹 벡터를 생성하여 희소도(Sparsity)를 계산할 수 있고, 목표 희소도 대비 그 차이를 손실로 계산 하여 이 결과를 모델의 출력과 정답 간 손실도와 더하는 과정을 수행하여 최종 손실도(101 4)을 얻는다. 이때, 더하는 과정은 하이퍼파라미터를 통해 가중 (weighted) 덧셈을 수행하는 것도 가능하다. 계산된 최종 손실도를 최소화 하는 방향으로 경사 하강법과 같은 최적화 방법을 통해 모델 학습이 진행되 면, 학습 데이터셋에 부합하는 신경망 모델이 계산되면서 목표 희소도에 가까운 희소도를 만들어내는 마 스킹 가중치 벡터를 얻게 된다. 도 12은 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다. 실시예에 따른 이산 개체의 가중치 측정 장치는 컴퓨터로 읽을 수 있는 기록매체와 같은 컴퓨터 시스템에 서 구현될 수 있다. 컴퓨터 시스템은 버스를 통하여 서로 통신하는 하나 이상의 프로세서, 메모리, 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치 및 스토리지를 포함할 수 있다. 또한, 컴퓨터 시스템은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있다. 프로세서 는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로그램 또는 프로세싱 인스트럭션들 을 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 휘발성 매체, 비휘발성 매체, 분리형 매체, 비분리형 매체, 통신 매체, 또는 정보 전달 매체 중에서 적어도 하나 이상을 포함하는 저장 매체일 수 있 다. 예를 들어, 메모리는 ROM이나 RAM을 포함할 수 있다.상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 이산 개체의 가중치 측정 장치는 적어도 하나의 프로 그램이 기록된 메모리, 및 상기 프로그램을 실행하는 프로세서를 포함하며, 상기 프로그램은 이산 개체의 인덱 스로 구성된 데이터를 입력받는 단계, 상기 입력된 데이터를 임베딩 레이어를 통해 각각의 인덱스에 상응하는 임베딩 벡터로 변환하는 단계, 마스크 벡터와 상기 임베딩 벡터의 요소별 곱셈을 통해 마스킹 된 벡터를 생성하 는 단계, 상기 마스킹 된 벡터에 기반한 출력을 이용하여 손실도를 계산하는 단계, 및 상기 손실도에 기반하여 모델을 학습시키는 단계의 수행을 위한 명령어들을 포함한다. 이때, 상기 마스킹 된 벡터를 생성하는 단계는 상기 이산 개체에 대한 가중치 값에 대하여 내림(floor) 연산을 수행하는 단계, 상기 내림 연산 결과 값보다 작거나 같은 정수에 상응하는 위치(index)에 1을 할당하는 단계, 및 상기 내림 연산 값보다 큰 정수에 상응하는 위치에 0을 할당하는 단계를 포함할 수 있다. 이때, 상기 마스크 벡터는 상기 임베딩 벡터의 요소들 중 사용할 값은 1로 표현하고, 사용하지 않을 값은 0으로 표현할 수 있다. 이때, 상기 마스킹 된 벡터를 생성하는 단계는 상기 가중치 값을 학습하기 위한 게이트 함수에 상응하는 값을 상기 마스킹 된 벡터의 요소에 각각 더하는 단계를 더 포함할 수 있다. 이때, 상기 게이트 함수는 상기 가중치 값의 학습이 가능하도록 상기 게이트 함수 값이 0에 가까운 값을 가지고, 기설정된 구간에서 미분 가능한 함수에 상응할 수 있다. 이때, 상기 게이트 함수는 상기 수학식 1의 함수에 상응하고, 상기 L은 충분히 큰 값을 가지는 양의 값에 상응 할 수 있다. 이때, 상기 손실도를 계산하는 단계는 상기 신경망 모델의 출력과 정답의 차이에 상응하는 제1 손실도, 및 상기 이산 개체에 대한 각각의 가중치 값으로 구성된 가중치 벡터에 기반하여 생성된 마스킹 벡터의 희소도와 목표 희소도의 차이에 상응하는 제2 손실도에 기반하여 최종 손실도를 계산할 수 있다. 이때, 상기 마스킹 된 벡터를 생성하는 단계는 상기 임베딩 벡터에 대한 마스킹 적용으로 인한 출력의 급격한 변화를 보정하는 단계를 더 포함할 수 있다. 기존 중요도 측정 방법들은 빈도수(frequency)와 같은 휴리스틱 방법을 통해 이산 개체의 중요도를 결정하는 한 계가 있으나, 본 발명에서 제안하는 기술은 학습 데이터를 기반으로 최적화를 통해 신경망 모델이 추론하는데 있어서 각 이산 개체가 기여하는 중요도를 결정한다. 따라서, 본 발명의 일실시예에 따른 방법은 주어진 실제 학습 데이터를 기반으로 최적화하여 중요도가 결정되기 때문에 태스크에 상관없이 항상 효과적인 중요도 분포를 찾아낼 수 있다. 또한, 본 발명은 태스크 애그노스틱(task-agnostic)하기 때문에 임의의 이산 개체를 다루는 분야에서 개체의 중 요도 판별에 사용될 수 있다. 또한, 본 발명에서 제안하는 방법은 임베딩 행렬을 압축하는 임의의 방법에 항상 적용할 수 있다. 주어진 임베딩 행렬에 대해 개체의 중요도를 기준으로 여러 부분 행렬로 분할하고, 각 부분 행렬에 어떤 압축 방법을 적용한다고 가정하면, 이때 각 부분 행렬 별로 평균 중요도를 계산하여 압축 정도를 결정하는데 사용하 는 방식이 가능하다. 즉, 본 발명의 기술은 모델에 있어서 개체의 중요도를 최적 계산했기 때문에 일반적으로 압축 방법에 상관없이 성능 향상을 기대할 수 있다. 본 발명에서 설명하는 특정 실행들은 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어시스템들, 소프트웨어, 상기 시스템들의 다른 기능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재 들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “ 필수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요 소가 아닐 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐만 아 니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2021-0155956", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 이산 개체를 임베딩 레이어를 통해 다루는 일반적인 신경망 모델 구조를 나타낸 도면이다. 도 2는 본 발명의 일실시예에 따른 이산 개체의 가중치 측정 방법을 나타낸 흐름도이다. 도 3은 이산 개체들의 임베딩 벡터를 모은 임베딩 행렬의 예시도이다. 도 4는 임베딩 행렬 내에 임베딩 벡터와 이 벡터에 대한 마스크 벡터, 그리고 마스킹 된 벡터의 예시도이다. 도 5는 각 이산 개체에 대하여 마스크 벡터를 곱하여 생성된 임베딩 행렬을 나타낸 도면이다. 도 6은 본 발명의 일실시예에 따른 방법의 임베딩 행렬을 예시적으로 나타낸 도면이다. 도 7은 이산 개체의 중요도를 의미하는 가중치 값을 통해 마스크 벡터를 생성하고 임베딩 벡터에 적용하는 것을 나타낸 도면이다. 도 8은 학습 가능한 마스크 벡터와 이를 적용한 마스킹 된 임베딩 벡터를 예시적으로 나타낸 도면이다. 도 9는 본 발명의 일실시예에 따른 학습 가능한 마스크 벡터들이 적용된 임베딩 레이어를 사용하는 신경망 모델 을 예시적으로 나타낸 도면이다. 도 10은 마스킹 된 임베딩 벡터를 보정하는 보정 레이어를 적용하는 방식을 예시적으로 나타낸 도면이다. 도 11은 본 발명의 일실시예에 따른 보정 레이어가 적용된 신경망 모델을 예시적으로 나타낸 도면이다. 도 12는 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다."}
