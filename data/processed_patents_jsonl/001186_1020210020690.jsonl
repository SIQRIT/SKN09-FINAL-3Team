{"patent_id": "10-2021-0020690", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0117057", "출원번호": "10-2021-0020690", "발명의 명칭": "오디오의 존재 및 비존재에 따른 비디오 품질 평가 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "바이잘 아난트"}}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비디오 품질 평가 장치에 있어서, 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 비디오 프레임 및 상기 비디오 프레임과 함께 출력되는 오디오 프레임을 기반으로, 상기 비디오 프레임에 대한제1 품질 점수를 획득하고, 상기 오디오 프레임 없이 상기 비디오 프레임을 기반으로, 상기 비디오 프레임에 대한 제2 품질 점수를 획득하고, 상기 제1 품질 점수 및 상기 제2 품질 점수로부터 상기 비디오 프레임에 대한 최종 품질 점수를 획득하는, 비디오 품질 평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 비디오 프레임 및 상기 오디오 프레임을 기반으로, 상기 비디오 프레임에서 시청자의 주의를 끄는 세일리언시(saliency) 영역을 나타내는 오디오 기반 세일리언시 맵을 획득하고, 상기 비디오 프레임 및 상기 오디오 기반 세일리언시 맵으로부터 상기 제1 품질 점수를 획득하는, 비디오 품질평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 오디오 프레임 없이 상기 비디오 프레임을 기반으로, 상기 비디오 프레임에서 시청자의 주의를 끄는 세일리언시 영역을 나타내는 비주얼(visual) 세일리언시 맵을 획득하고, 상기 오디오 프레임 및 상기 비주얼 세일리언시 맵으로부터 상기 오디오 기반 세일리언시 맵을 획득하는, 비디오 품질 평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 오디오 신호를 고려할 때와 고려하지 않을 때의 세일리언시 영역의 차이를 학습한 뉴럴 네트워크를 이용하여,상기 오디오 프레임 및 상기 비주얼 세일리언시 맵으로부터 상기 오디오 기반 세일리언시 맵을 획득하는, 비디오 품질 평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서, 상기 뉴럴 네트워크는 오디오 신호 특성에 따라 달라지는 세일리언시 영역을 학습한 뉴럴 네트워크이고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 뉴럴 네트워크를 이용하여 상기 오디오 프레임으로부터 오디오 신호 특성을 획득하고, 상기 획득한 오디오신호 특성을 고려하여 상기 오디오 기반 세일리언시 맵을 획득하고, 상기 오디오 신호 특성은 오디오 장르(genre), 주제(theme), 볼륨(volume), 해상도(resolution), 정보량공개특허 10-2022-0117057-3-(entropy), 선명도(sharpness), 다이나믹스(dynamics), 대역 밸런스(tonal balance), 음색(tone color), 위상(phase), 음상(sound image), 음장(sound staging), 임장감(presence) 중 적어도 하나를 포함하는, 비디오 품질 평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 오디오 기반 세일리언시 맵 및 디스플레이 장치 특성 정보 중 적어도 하나에 기반하여 최종 가중치를 획득하고, 상기 최종 가중치를 이용하여 상기 제1 품질 점수 및 상기 제2 품질 점수의 가중합(weighted sum)을 획득하는,비디오 품질 평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 오디오 기반 세일리언시맵으로부터 획득한 세일리언시 영역의 통계학적 특성으로부터 제1 가중치를 획득하고,상기 디스플레이 장치 특성 정보로부터 제2 가중치를 획득하고, 상기 제1 가중치 및 상기 제2 가중치 중 적어도 하나를 기반으로 상기 최종 가중치를 획득하는, 비디오 품질 평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서, 상기 세일리언시 영역의 통계학적 특성은 상기 오디오 기반 세일리언시 맵에 포함된 상기 세일리언시 영역이 상기 비디오 프레임에 포함된 비율(proportion), 상기 세일리언시 영역의 산포도(spread) 또는중심 경향치(central tendency) 중 적어도 하나인, 비디오 품질 평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 디스플레이 장치 특성정보를 상기 비디오 품질 평가 장치에 기 저장된 매핑 테이블로부터 추출하여 획득하고, 상기 디스플레이 장치 특성 정보는, 스크린 모델 매핑 정보, 스크린 설정 매핑 정보, 및 환경 정보 중 적어도하나를 포함하는, 비디오 품질 평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서, 상기 스크린 모델 매핑 정보는 평가자 디스플레이 장치의 스크린 모델과 상기 사용자 디스플레이 장치의 스크린 모델 차이에 따른 점수 관계를 포함하고, 상기 스크린 모델 차이는 스크린 사이즈 및 스크린 해상도 중 적어도 하나의 차이인, 비디오 품질 평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9 항에 있어서, 상기 스크린 설정 매핑 정보는 상기 사용자 디스플레이 장치의 스크린에 대한 디폴트 설정 값과 사용자로부터 선택된 설정 값의 차이에 따른 점수 관계를 나타내고, 상기 설정 값은 스크린의 밝기(brightness), 대조도(contrast), 감마(gamma), 백라이트 밝기, 선명도(sharpness), 색상(Color), 색조(tint)중 적어도 하나에 대한 값을 포함하는, 비디오 품질 평가 장치."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9 항에 있어서, 상기 환경 정보는 주변 밝기 정보 및 시청 위치 정보 중 적어도 하나를 포함하고, 상기 주변 밝기 정보는 상기 사용자 디스플레이 장치 주변 밝기와 평가자 디스플레이 장치 주변 밝기 간의 관계를 포함하고,상기 시청 위치 정보는 상기 사용자의 시청 위치 및 평가자의 시청 위치 간의 관계를 포함하고, 상기 시청 위치는 디스플레이 장치와의 거리, 방위각, 및 고도각 중 적어도 하나를 포함하는, 비디오 품질 평가 장치.공개특허 10-2022-0117057-4-청구항 13 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법에 있어서,비디오 프레임 및 상기 비디오 프레임과 함께 출력되는 오디오 프레임을 기반으로, 상기 비디오 프레임에 대한제1 품질 점수를 획득하는 단계; 상기 오디오 프레임 없이 상기 비디오 프레임을 기반으로, 상기 비디오 프레임에 대한 제2 품질 점수를 획득하는 단계; 및상기 제1 품질 점수 및 상기 제2 품질 점수로부터 상기 비디오 프레임에 대한 최종 품질 점수를 획득하는 단계를 포함하는, 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서, 상기 제1 품질 점수를 획득하는 단계는상기 비디오 프레임 및 상기 오디오 프레임을 기반으로, 상기 비디오 프레임에서 시청자의 주의를 끄는 세일리언시(saliency) 영역을 나타내는 오디오 기반 세일리언시 맵을 획득하는 단계; 및상기 비디오 프레임 및 상기 오디오 기반 세일리언시 맵으로부터 상기 제1 품질 점수를 획득하는 단계를 포함하는, 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서, 상기 오디오 기반 세일리언시 맵을 획득하는 단계는상기 오디오 프레임 없이 상기 비디오 프레임을 기반으로, 상기 비디오 프레임에서 시청자의 주의를 끄는 세일리언시 영역을 나타내는 비주얼(visual) 세일리언시 맵을 획득하는 단계; 및상기 오디오 프레임 및 상기 비주얼 세일리언시 맵으로부터 상기 오디오 기반 세일리언시 맵을 획득하는 단계를포함하는, 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서, 상기 오디오 기반 세일리언시 맵을 획득하는 단계는오디오 신호를 고려할 때와 고려하지 않을 때의 세일리언시 영역의 차이를 학습한 뉴럴 네트워크를 이용하여,상기 오디오 프레임 및 상기 비주얼 세일리언시 맵으로부터 상기 오디오 기반 세일리언시 맵을 획득하는 단계를포함하는, 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서, 상기 뉴럴 네트워크는 오디오 신호 특성에 따라 달라지는 세일리언시 영역을 학습한 뉴럴 네트워크이고,상기 오디오 기반 세일리언시 맵을 획득하는 단계는 상기 뉴럴 네트워크를 이용하여 상기 오디오 프레임으로부터 오디오 신호 특성을 획득하는 단계; 및상기 획득한 오디오 신호 특성을 고려하여 상기 오디오 기반 세일리언시 맵을 획득하는 단계를 포함하고, 상기 오디오 신호 특성은 오디오 장르(genre), 주제(theme), 볼륨(volume), 해상도(resolution), 정보량(entropy), 선명도(sharpness), 다이나믹스(dynamics), 대역 밸런스(tonal balance), 음색(tone color), 위상(phase), 음상(sound image), 음장(sound staging), 임장감(presence) 중 적어도 하나를 포함하는, 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14 항에 있어서, 상기 최종 품질 점수를 획득하는 단계는 상기 오디오 기반 세일리언시 맵 및 디스플레이 장치 특성 정보 중 적어도 하나에 기반하여 최종 가중치를 획득하는 단계; 및공개특허 10-2022-0117057-5-상기 최종 가중치를 이용하여, 상기 제1 품질 점수 및 상기 제2 품질 점수의 가중합(weighted sum)을 획득하는단계를 포함하는, 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18 항에 있어서, 상기 최종 가중치를 획득하는 단계는상기 오디오 기반 세일리언시 맵으로부터 획득한 세일리언시 영역의 통계학적 특성으로부터 제1 가중치를 획득하는 단계; 상기 사용자 디스플레이 장치의 특성 정보로부터 제2 가중치를 획득하는 단계; 및상기 제1 가중치 및 상기 제2 가중치 중 적어도 하나를 기반으로 상기 최종 가중치를 획득하는 단계를포함하는, 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법."}
{"patent_id": "10-2021-0020690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "비디오 프레임 및 상기 비디오 프레임과 함께 출력되는 오디오 프레임을 기반으로, 상기 비디오 프레임에 대한제1 품질 점수를 획득하는 단계; 상기 오디오 프레임 없이 상기 비디오 프레임을 기반으로, 상기 비디오 프레임에 대한 제2 품질 점수를 획득하는 단계; 및상기 제1 품질 점수 및 상기 제2 품질 점수로부터 상기 비디오 프레임에 대한 최종 품질 점수를 획득하는 단계를 포함하는, 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법을 구현하기 위한 프로그램이 기록된컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0020690", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "비디오 품질 평가 장치가 개시된다. 비디오 품질 평가 장치는, 하나 이상의 인스트럭션을 저장하는 메모리 및 메 모리에 저장된 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 비디오 프레임 및 비디오 프레임과 함께 출력되는 오디오 프레임을 기반으로, 비디오 프레임에 대 한 제1 품질 점수를 획득하고, 오디오 프레임 없이 비디오 프레임을 기반으로, 비디오 프레임에 대한 제2 품질 점수를 획득하고, 제1 품질 점수 및 제2 품질 점수로부터 비디오 프레임에 대한 최종 품질 점수를 획득할 수 있 다."}
{"patent_id": "10-2021-0020690", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 다양한 실시 예들은 오디오의 존재 및 비존재에 따른 비디오 품질 평가 방법 및 장치에 관한 것으로, 보다 상세하게는 오디오를 고려할 때와 오디오를 고려하지 않을 때의 각각의 품질 점수를 기반으로 비디오의 품 질을 평가하는, 오디오의 존재 및 비존재에 따른 비디오 품질 평가 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2021-0020690", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "비디오 영상은 생성, 압축, 저장, 전송, 재생산 등의 과정에서 왜곡을 수반하게 된다. 왜곡된 영상은 사람이 지 각할 수 있는 범위 내에서 재생 되어야 한다. 따라서, 영상이 재생되기 전에, 이러한 왜곡이 사람이 지각하는 화질에 어떠한 영향을 미치는지를 이해하기 위해 화질을 측정하고 평가할 필요가 있다. 영상 화질 평가(Quality Assessment) 기술은 주관적 화질 평가(subjective quality assessment) 방법과 객관적 화질 평가(objective quality assessment) 방법으로 나눌 수 있다. 주관적 화질 평가 방법은 평가자가 직접 비 디오를 보고 화질을 평가하는 방법으로서 사람의 화질 인지 특성을 잘 반영할 수 있다. 그러나 주관적 화질 평 가 방법은 개인별로 평가 치가 다르고 시간과 비용이 많이 소요될 뿐 아니라, 실시간으로 매번 영상의 화질을 평가하기 어렵다는 단점이 있다. 객관적 화질 평가 방법은 사람의 시신경으로 지각된 화질(perceived quality)을 측정하는 알고리즘을 구현하고 이를 이용하여 압축 영상의 화질 열화 정도를 평가하는 방법이다. 객관적 화질 평가 방법은 왜곡된 영상과 비교할 수 있는 기준 영상(reference image)을 이용하는 전 기준 화질 평가(Full-Reference Quality Assessment)방식과, 기준 영상 자체가 아닌 기준 영상에 관한 일부 정보, 예를 들면, 워터 마킹(watermarking)이나 보조 채널(auxiliary channel) 등을 이용하여 화질 평가를 수행하는 감소 기준 화질 평가(Reduced Reference Quality Assessment) 방식, 및 기준 영상의 어떠한 정보도 이용하지 않고 왜곡된 영상만을 이용하여 화질 추정을 수행하는 무 기준 화질 평가(No-Reference Quality Assessment)방식으로 나뉠 수 있다. 무 기준 화질 평가 방식은 기준 영상 정보를 필요로 하지 않기 때문에, 화질 측정이 요구되는 어떠한 응용에도 이용될 수 있다는 장점이 있다. 일반적으로 화질 평가 방법은 시각적인 정보만을 사용하여 수행된다. 그러나, 실제로 사용자는 비디오를 시청할 때 비디오와 함께 출력되는 오디오 또한 함께 이용하게 된다."}
{"patent_id": "10-2021-0020690", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다양한 실시 예들은 오디오를 고려할 때와 오디오를 고려하지 않을 때의 각각의 품질 점수를 기반으로 최종 품 질 점수를 획득하는 비디오 품질 평가 방법 및 장치를 제공하기 위한 것이다. 다양한 실시 예들은 오디오를 고려할 때와 오디오를 고려하지 않을 때의 세일리언시 맵의 차이를 이용하여 최종 품질 점수를 획득하는 비디오 품질 평가 방법 및 장치를 제공하기 위한 것이다. 다양한 실시 예들은 오디오 기반 세일리언시 맵과 디스플레이 장치의 특성 정보로부터 가중치를 획득하고, 이를 오디오를 고려할 때와 오디오를 고려하지 않을 때의 각각의 품질 점수에 적용하여 최종 품질 점수를 획득하는 비디오 품질 평가 방법 및 장치를 제공하기 위한 것이다."}
{"patent_id": "10-2021-0020690", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시 예에 따른 비디오 품질 평가 장치는 하나 이상의 인스트럭션을 저장하는 메모리 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션 을 실행함으로써, 비디오 프레임 및 상기 비디오 프레임과 함께 출력되는 오디오 프레임을 기반으로, 상기 비디 오 프레임에 대한 제1 품질 점수를 획득하고, 상기 오디오 프레임 없이 상기 비디오 프레임을 기반으로, 상기 비디오 프레임에 대한 제2 품질 점수를 획득하고, 상기 제1 품질 점수 및 상기 제2 품질 점수로부터 상기 비디 오 프레임에 대한 최종 품질 점수를 획득할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 비디오 프레임 및 상기 오디 오 프레임을 기반으로, 상기 비디오 프레임에서 시청자의 주의를 끄는 세일리언시(saliency) 영역을 나타내는 오디오 기반 세일리언시 맵을 획득하고, 상기 비디오 프레임 및 상기 오디오 기반 세일리언시 맵으로부터 상기 제1 품질 점수를 획득할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 오디오 프레임 없이 상기 비 디오 프레임을 기반으로, 상기 비디오 프레임에서 시청자의 주의를 끄는 세일리언시 영역을 나타내는 비주얼 (visual) 세일리언시 맵을 획득하고, 상기 오디오 프레임 및 상기 비주얼 세일리언시 맵으로부터 상기 오디오 기반 세일리언시 맵을 획득할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 오디오 신호를 고려할 때와 고려 하지 않을 때의 세일리언시 영역의 차이를 학습한 뉴럴 네트워크를 이용하여, 상기 오디오 프레임 및 상기 비주 얼 세일리언시 맵으로부터 상기 오디오 기반 세일리언시 맵을 획득할 수 있다. 실시 예에서, 상기 뉴럴 네트워크는 오디오 신호 특성에 따라 달라지는 세일리언시 영역을 학습한 뉴럴 네트워 크이고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 뉴럴 네트워크를 이용하여 상기 오디오 프레임으로부터 오디오 신호 특성을 획득하고, 상기 획득한 오디오 신호 특성을 고려하여 상기 오디오 기반 세일리언시 맵을 획득하고, 상기 오디오 신호 특성은 오디오 장르(genre), 주제(theme), 볼륨(volume), 해 상도(resolution), 정보량(entropy), 선명도(sharpness), 다이나믹스(dynamics), 대역 밸런스(tonal balance), 음색(tone color), 위상(phase), 음상(sound image), 음장(sound staging), 임장감(presence) 중 적어도 하나 를 포함할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 오디오 기반 세일리언시 맵 및 디스플레이 장치 특성 정보 중 적어도 하나에 기반하여 최종 가중치를 획득하고, 상기 최종 가중치를 이용하 여 상기 제1 품질 점수 및 상기 제2 품질 점수의 가중합(weighted sum)을 획득할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 오디오 기반 세일리언시 맵 으로부터 획득한 세일리언시 영역의 통계학적 특성으로부터 제1 가중치를 획득하고, 상기 디스플레이 장치 특성 정보로부터 제2 가중치를 획득하고, 상기 제1 가중치 및 상기 제2 가중치 중 적어도 하나를 기반으로 상기 최종 가중치를 획득할 수 있다. 실시 예에서, 상기 세일리언시 영역의 통계학적 특성은 상기 오디오 기반 세일리언시 맵에 포함된 상기 세일리 언시 영역이 상기 비디오 프레임에 포함된 비율(proportion), 상기 세일리언시 영역의 산포도(spread) 또는 중 심 경향치(central tendency) 중 적어도 하나일 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 디스플레이 장치 특성 정보 를 상기 비디오 품질 평가 장치에 기 저장된 매핑 테이블로부터 추출하여 획득하고, 상기 디스플레이 장치 특성 정보는, 스크린 모델 매핑 정보, 스크린 설정 매핑 정보, 및 환경 정보 중 적어도 하나를 포함할 수 있다. 실시 예에서, 상기 스크린 모델 매핑 정보는 평가자 디스플레이 장치의 스크린 모델과 상기 사용자 디스플레이 장치의 스크린 모델 차이에 따른 점수 관계를 포함하고, 상기 스크린 모델 차이는 스크린 사이즈 및 스크린 해 상도 중 적어도 하나의 차이일 수 있다. 실시 예에서, 상기 스크린 설정 매핑 정보는 상기 사용자 디스플레이 장치의 스크린에 대한 디폴트 설정 값과 사용자로부터 선택된 설정 값의 차이에 따른 점수 관계를 나타내고, 상기 설정 값은 스크린의 밝기 (brightness), 대조도(contrast), 감마(gamma), 백라이트 밝기, 선명도(sharpness), 색상(Color), 색조(tint) 중 적어도 하나에 대한 값을 포함할 수 있다. 실시 예에서, 상기 환경 정보는 주변 밝기 정보 및 시청 위치 정보 중 적어도 하나를 포함하고, 상기 주변 밝기 정보는 상기 사용자 디스플레이 장치 주변 밝기와 평가자 디스플레이 장치 주변 밝기 간의 관계를 포함하고, 상 기 시청 위치 정보는 상기 사용자의 시청 위치 및 평가자의 시청 위치 간의 관계를 포함하고, 상기 시청 위치는 디스플레이 장치와의 거리, 방위각, 및 고도각 중 적어도 하나를 포함할 수 있다. 실시 예에 따른 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법은 비디오 프레임 및 상기 비디오 프레임과 함께 출력되는 오디오 프레임을 기반으로, 상기 비디오 프레임에 대한 제1 품질 점수를 획득하는 단계, 상기 오디오 프레임 없이 상기 비디오 프레임을 기반으로, 상기 비디오 프레임에 대한 제2 품질 점수를 획득하는 단계 및 상기 제1 품질 점수 및 상기 제2 품질 점수로부터 상기 비디오 프레임에 대한 최종 품질 점수 를 획득하는 단계를 포함할 수 있다. 실시 예에 따른 컴퓨터로 판독 가능한 기록 매체는 비디오 프레임 및 상기 비디오 프레임과 함께 출력되는 오디 오 프레임을 기반으로, 상기 비디오 프레임에 대한 제1 품질 점수를 획득하는 단계, 상기 오디오 프레임 없이 상기 비디오 프레임을 기반으로, 상기 비디오 프레임에 대한 제2 품질 점수를 획득하는 단계 및 상기 제1 품질 점수 및 상기 제2 품질 점수로부터 상기 비디오 프레임에 대한 최종 품질 점수를 획득하는 단계를 포함하는, 비 디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체일 수 있다."}
{"patent_id": "10-2021-0020690", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예에 따른 비디오 품질 평가 방법 및 장치는 오디오를 고려할 때와 오디오를 고려하지 않을 때의 각각 의 품질 점수를 기반으로 최종 품질 점수를 획득할 수 있다. 일 실시 예에 따른 비디오 품질 평가 방법 및 장치는 오디오를 고려할 때와 오디오를 고려하지 않을 때의 세일 리언시 맵의 차이를 이용하여 최종 품질 점수를 획득할 수 있다. 일 실시 예에 따른 비디오 품질 평가 방법 및 장치는 오디오 기반 세일리언시 맵과 디스플레이 장치의 특성 정 보로부터 가중치를 획득하고, 이를 오디오를 고려할 때와 오디오를 고려하지 않을 때의 각각의 품질 점수에 적 용하여 최종 품질 점수를 획득할 수 있다."}
{"patent_id": "10-2021-0020690", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시 예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시에서 사용되는 용어는, 본 개시에서 언급되는 기능을 고려하여 현재 사용되는 일반적인 용어로 기재되었 으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 다양한 다른 용어를 의미할 수 있다. 따라서 본 개시에서 사용되는 용어는 용어의 명칭만으로 해석되어서는 안되며, 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 해석되어야 한다. 또한, 본 개시에서 사용된 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것이며, 본 개시를 한정하려는 의도로 사용되는 것이 아니다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 본 명세서, 특히, 특허 청구 범위에서 사용된 “상기” 및 이와 유사한 지시어는 단수 및 복수 모두를 지시하는 것일 수 있다. 또한, 본 개시에 따른 방법을 설명하는 단계들의 순서를 명백하게 지정하는 기재가 없다면, 기재 된 단계들은 적당한 순서로 행해질 수 있다. 기재된 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아니 다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시 예에서\" 또는 \"일 실시 예에서\" 등의 어구는 반드시 모두 동일 한 실시 예를 가리키는 것은 아니다. 본 개시의 일부 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술 을 채용할 수 있다. “매커니즘”, “요소”, “수단” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다.또한, 명세서에서 “사용자”라는 용어는 비디오 품질 평가 장치를 이용하여 비디오 품질 평가 장치의 기능 또 는 동작을 제어하는 사람을 의미하며, 평가자, 시청자, 소비자, 관리자 또는 설치 기사를 포함할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 실시 예에 따라, 사용자 디스플레이 장치가 비디오 영상의 품질 점수를 획득하고, 이에 따라 처리 된 화질을 갖는 영상을 화면에 출력하는 것을 설명하기 위한 도면이다. 도 1을 참조하면, 사용자 디스플레이 장치는 영상을 처리하여 출력할 수 있는 전자 장치일 수 있다. 사용 자 디스플레이 장치는 고정형 또는 이동형일 수 있으며, 디지털 방송 수신이 가능한 디지털 TV일 수 있으 나, 이에 한정되지 않으며, 디스플레이를 포함하는 다양한 형태의 전자 장치로 구현될 수 있다. 실시예들에서, 사용자 디스플레이 장치는, 이하에서 설명되는, 평가자가 비디오 품질 평가를 위해 이용하는 평 가자 디스플레이 장치와 구분하기 위해 “사용자” 디스플레이 장치로 언급되지만, 이에 한정되는 것은 아니다. 사용자 디스플레이 장치는 디스플레이 장치 또는 전자 장치로 언급될 수도 있다. 사용자 디스플레이 장치는 데스크톱, 스마트 폰(smartphone), 태블릿 PC(tablet personal computer), 이 동 전화기(mobile phone), 화상 전화기, 전자 북 리더기(e-book reader), 랩톱 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 디지털 카메라, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 캠코더, 네비게이션, 웨어러블 장치(wearable device), 스마트 와치(smart watch), 홈 네트워크 시스 템, 보안 시스템, 의료 장치 중 적어도 하나를 포함할 수 있다. 사용자 디스플레이 장치는 평면(flat) 디스플레이 장치뿐만 아니라, 곡률을 가지는 화면인 곡면(curved) 디스플레이 장치 또는 곡률을 조정 가능한 가변형(flexible) 디스플레이 장치로 구현될 수 있다. 사용자 디스플 레이 장치의 출력 해상도는 예를 들어, HD(High Definition), Full HD, Ultra HD, 또는 Ultra HD 보다 더 선명한 해상도를 포함할 수 있다. 사용자 디스플레이 장치는 비디오를 출력할 수 있다. 비디오는 복수의 프레임들로 구성될 수 있다. 비디오 는, 콘텐츠 프로바이더들(contents providers)이 제공하는 텔레비전 프로그램이나 VOD 서비스를 통한 각종 영화 나 드라마 등의 아이템을 포함할 수 있다. 콘텐츠 프로바이더는 소비자에게 비디오를 포함한 각종 콘텐츠를 제 공하는 지상파 방송국이나 케이블 방송국, 또는 OTT 서비스 제공자, IPTV 서비스 제공자를 의미할 수 있다. 비디오는 캡쳐 된 후 압축되어 사용자 디스플레이 장치로 전송되고, 사용자 디스플레이 장치에 의해 서 복원되어 출력된다. 비디오를 캡처하는데 사용되는 기기의 물리적 특성의 한계와 제한된 대역폭 등으로 인해 정보가 손실되면서 영상의 왜곡이 발생하게 된다. 왜곡된 비디오는 품질이 저하될 수 있다. 실시 예에서, 사용자 디스플레이 장치는 비디오 품질 평가 장치를 포함할 수 있다. 비디오 품질 평가 장치 는 무 기준 화질 평가 방식으로 비디오의 화질을 객관적으로 평가할 수 있다. 비디오 품질 평가 장치는 적어도 하나의 하드웨어 칩 형태나 전자 장치 형태로 제작되어 사용자 디스플레이 장치에 포함될 수 있다. 또는 비디오 품질 평가 장치는 사용자 디스플레이 장치에서 소프트웨어 모듈로 구현될 수도 있다. 실시 예에 따라, 비디오 품질 평가 장치를 포함하는 사용자 디스플레이 장치는 비디오 품질 평가 방법을 수행할 수 있다. 사용자 디스플레이 장치는 입력 비디오를 수신하고 이를 화면을 통해 출력하기 전에 먼저 비디오에 대한 품질 평가를 수행할 수 있다. 사용자 디스플레이 장치는 비디오에 포함된 복수의 프레임들 각각에 대 해 점수를 획득할 수 있다. 일반적으로, 비디오 품질을 평가할 때, 복수의 평가자들은 오디오에 대한 고려 없이, 비디오만을 이용하여 비디 오의 품질을 평가하게 된다. 그러나, 실제 사용자는 비디오를 시청할 때, 비디오뿐 아니라 오디오도 함께 이용 한다. 오디오를 고려하지 않고 비디오만을 고려하여 비디오의 품질을 평가한 경우와, 오디오와 비디오를 함께 고려하 여 비디오의 품질을 평가한 경우, 그 품질 점수는 서로 다를 수 있다. 이는 비디오를 볼 때, 오디오의 유무에 따라 사람이 화면에서 보는 영역이 달라질 수 있기 때문이다. 즉, 평가자, 또는 사용자가 오디오 없이 비디오만 을 볼 때와, 비디오에 동기화된 오디오를 청취하며 비디오를 볼 때, 평가자 또는 사용자의 관심 영역은 변경될 수 있고, 그에 따라 비디오에 대한 품질 점수 또한 달라질 수 있다. 실시 예에서, 사용자 디스플레이 장치는 오디오를 고려하여 비디오 프레임에 대한 품질 점수를 획득할 수 있다. 이를 위해, 사용자 디스플레이 장치는 세일리언시 맵(saliency map)을 이용할 수 있다. 세일리언시 맵은 세일리언시 영역을 다른 영역과 구별하여 표현하는 맵을 의미할 수 있다. 세일리언시 영역은 비디오 프레 임에서 사용자의 관심을 끄는 영역, 즉, 시각적 집중도가 높은 영역을 의미할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 사용자가 오디오 없이 비디오를 시청할 때 사용자의 관심을 끄는 세일리언시 영역과, 사용자가 오디오를 들으며 비디오를 시청할 때 사용자의 관심을 끄는 세일리언시 영역의 차 이를 고려하여 비디오에 대한 품질 점수를 획득할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 오디오 프레임 없이 비디오 프레임만을 기반으로, 비디오 프레임 에서 시청자의 주의를 끄는 세일리언시 영역을 나타내는 비주얼(visual) 세일리언시 맵을 획득할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 비주얼 세일리언시 맵과, 오디오 프레임을 함께 고려하여, 사용자 가 오디오를 들으며 비디오를 시청할 때 사용자의 주의를 끄는 세일리언시 영역을 나타내는, 오디오 기반 세일 리언시 맵을 획득할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 비디오 프레임 및 오디오 기반 세일리언시 맵으로부터 제1 품질 점수를 획득할 수 있다. 또한, 실시 예에서, 사용자 디스플레이 장치는 오디오 프레임에 대한 고려 없이, 비디오 프레임만을 기반 으로, 비디오 프레임에 대한 제2 품질 점수를 획득할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 제1 품질 점수 및 제2 품질 점수를 함께 고려하여 비디오 프레임 에 대한 최종 품질 점수를 획득할 수 있다. 보다 구체적으로, 사용자 디스플레이 장치는 제1 품질 점수 및 제2 품질 점수에 가중치를 적용하여 최종 품질 점수를 획득할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 오디오 기반 세일리언시 맵 및 디스플레이 장치 특성 정보 중 적 어도 하나에 기반하여 최종 가중치를 획득할 수 있다. 사용자 디스플레이 장치는 제1 품질 점수 및 제2 품질 점수에 최종 가중치를 적용하여 최종 품질 점수를 획득할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 각 비디오 프레임 별로 획득한 최종 품질 점수를 소정 시간 동안 누적하여 복수의 프레임들을 포함하는 비디오에 대한 최종 비디오 품질 점수를 획득할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 최종 비디오 품질 점수에 따라 비디오에 포함된 프레임들에 대해 화질 처리를 수행할 수 있다. 도 1에서, 사용자 디스플레이 장치는 최종 비디오 품질 점수를 기반으로, 입 력 비디오를 출력 비디오와 같이 향상시킬 수 있다. 사용자 디스플레이 장치는 디스플레이를 통 해 품질이 향상된 출력 비디오를 출력할 수 있다. 다른 실시 예에서, 비디오 품질 평가 장치는 사용자 디스플레이 장치에 포함되지 않고, 사용자 디스플레이 장치와 별개의 장치로 구현될 수도 있다. 즉, 사용자 디스플레이 장치는 통신망(미도시)를 통해 비디 오 품질 평가 장치와 통신할 수 있다. 이 경우, 사용자 디스플레이 장치는 통신망을 통해 비디오를 외부의 비디오 품질 평가 장치로 전송할 수 있다. 외부의 비디오 품질 평가 장치는 사용자 디스플레이 장치로부터 복수의 프레임들을 포함하는 비디오를 수신하고, 프레임 별로 품질 점수를 획득할 수 있다. 또한, 비디오 품질 평가 장치는 사용자 디스플레이 장치로부터 사용자 디스플레이 장치에 포함된 디 스플레이 장치 특성 정보를 수신할 수 있다. 비디오 품질 평가 장치는 디스플레이 장치 특성 정보와, 오디오 기 반 세일리언시 맵으로부터 가중치를 획득하고, 이를 품질 점수에 적용하여 프레임에 대한 최종 품질 점수를 획 득할 수 있다. 비디오 품질 평가 장치는 복수의 프레임들에 대한 시계열 데이터를 누적하여 전체 비디오에 대한 최종 비디오 품질 점수를 획득하고, 이를 통신망을 통해 사용자 디스플레이 장치로 전송할 수 있다. 사용자 디스플레이 장치는 비디오 품질 평가 장치로부터 수신한 점수에 기반하여, 비디오의 화질을 처리하여 출력할 수 있다. 또는 비디오 품질 평가 장치는 획득한 점수를 기반으로 비디오의 화질을 직접 처리한 후 이를 사용자 디스플레 이 장치로 전송할 수도 있다. 사용자 디스플레이 장치는 비디오 품질 평가 장치로부터 수신한 개선된 화질의 비디오를 출력할 수 있다. 이와 같이, 실시 예에 의하면, 비디오 품질 평가 장치는 오디오 고려 없이 비디오만을 이용하여 비디오 프레임 에 대한 품질 점수를 획득하고, 또한, 비디오와 오디오를 함께 고려하여 비디오 프레임에 대한 품질 점수를 각 각 획득할 수 있다. 또한, 실시 예에 의하면, 비디오 품질 평가 장치는 오디오 고려 없이 획득한 품질 점수와 오디오를 고려하여 획 득한 품질 점수에 가중치를 적용하여 최종 품질 점수를 획득할 수 있다. 따라서, 비디오 품질 평가 장치는 오디오의 유무에 따른 품질 점수의 차이를 고려할 수 있다. 또한, 비디오 품 질 평가 장치는 오디오를 고려할 때의 오디오 기반 세일리언시 맵 및 디스플레이 장치 특성 정보가 최종 품질 점수에 반영되도록 할 수 있다. 도 2는 실시 예에 따른 비디오 품질 평가 장치의 내부 블록도이다. 도 2를 참조하면, 비디오 품질 평가 장치는 프로세서 및 메모리를 포함할 수 있다. 도 2의 비디 오 품질 평가 장치는 도 1에 도시된 사용자 디스플레이 장치에 포함되거나, 또는 사용자 디스플레이 장치와 통신망을 통해 연결될 수 있다. 실시 예에서, 비디오 품질 평가 장치는 인공지능 기술(Artificial Intelligence, AI)을 이용하여 비디오의 품질 점수를 획득할 수 있다. 비디오 품질 평가 장치는 입력 비디오에 포함된 복수의 프레임들 각각에 대 해 적어도 하나의 뉴럴 네트워크를 이용하여 모델 기반 품질 점수를 획득할 수 있다. AI 기술은 기계학습(딥 러닝) 및 기계 학습을 활용한 요소 기술들로 구성될 수 있다. AI 기술은 알고리즘을 활 용하여 구현될 수 있다. 여기서, AI 기술을 구현하기 위한 알고리즘 또는 알고리즘의 집합을 신경망(Neural Network, 뉴럴 네트워크)이라 한다. 신경망은 입력 데이터를 입력 받고, 분석 및 분류를 위한 연산을 수행하여, 결과 데이터를 출력할 수 있다. 뉴럴 네트워크는 연산을 수행하는 내부의 계층이 복수 개일 수 있다. 뉴럴 네트워크는 각 계층들로부터 서로 다 른 특징 맵(feature map)을 획득할 수 있다. 실시 예에서, 비디오 품질 평가 장치는 비디오 품질 평가를 위해 복수개의 뉴럴 네트워크를 이용할 수 있 다. 실시 예에서, 비디오 품질 평가 장치가 이용하는 뉴럴 네트워크는 비디오 품질 평가를 위해 사전 훈련 된 모델일 수 있다. 실시 예에 따른 메모리는, 적어도 하나의 인스트럭션을 저장할 수 있다. 메모리는 프로세서가 실행하는 적어도 하나의 프로그램을 저장하고 있을 수 있다. 실시 예에서, 메모리에는 적어도 하나의 뉴럴 네트워크 및/또는 기 정의된 동작 규칙이나 AI 모델이 저장 될 수 있다. 또한 메모리는 비디오 품질 평가 장치로 입력되거나 비디오 품질 평가 장치로부터 출력되는 데이터를 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 실시 예에서, 비디오 품질 평가 장치가 사용자 디스플레이 장치에 포함되어 있는 경우, 메모리 에는 디스플레이 장치 특성 정보가 저장될 수 있다. 디스플레이 장치 특성 정보는, 사용자 디스플레이 장치 와 평가자의 디스플레이 장치 간의 차이를 보상하기 위한 정보로, 스크린 모델 매핑 정보, 스크린 설정 매 핑 정보, 및 환경 정보 중 적어도 하나를 포함할 수 있다. 제조사는 사용자 디스플레이 장치에 대한 디스플레이 장치 특성 정보를 획득하고 이를 사용자 디스플레이 장치의 메모리에 매핑 테이블이나 매핑 함수, 룩업 테이블 형태 등으로 미리 저장할 수 있다. 또는 사용자 디스플레이 장치는 제조사가 운영하는 서버 등으로부터 디스플레이 장치 특성 정보를 다운로드하여 이를 메모리에 저장할 수도 있다. 비디오 품질 평가 장치가 사용자 디스플레이 장치에 포함되어 있지 않은 경우, 비디오 품질 평가 장 치는 통신망(미도시)을 통해 사용자 디스플레이 장치로부터 사용자 디스플레이 장치에 저장되어 있는 디스플레이 장치 특성 정보를 수신하고 이를 메모리에 저장할 수 있다. 또는 비디오 품질 평가 장치 는 사용자 디스플레이 장치에 대한 디스플레이 장치 특성 정보를 외부 서버 등으로부터 다운로드하여이를 메모리에 저장할 수도 있다. 디스플레이 장치 특성 정보는 스크린 모델 매핑 정보, 스크린 설정 매핑 정보 및 환경 정보 중 적어도 하나를 포함할 수 있다. 스크린 모델 매핑 정보는 평가자 디스플레이 장치의 스크린 모델과 사용자 디스플레이 장치의 스크린 모델 차이에 따른 점수 관계를 포함할 수 있다. 스크린 모델 차이는 스크린의 사이즈 및 해상도 중 적어도 하나의 차 이일 수 있다. 스크린 설정 매핑 정보는 사용자 디스플레이 장치의 스크린에 대한 디폴트 설정 값과 사용자로부터 선택된 설정 값의 차이에 따른 점수 관계를 포함할 수 있다. 설정 값은 사용자 디스플레이 장치의 스크린에 대한 밝기 (brightness), 대조도(contrast), 감마(gamma), 백라이트 밝기, 선명도(sharpness), 색상(Color), 색조(tint) 중 적어도 하나에 대한 값을 포함할 수 있다. 환경 정보는 평가자 디스플레이 장치 주변의 밝기와 사용자 디스플레이 장치 주변의 밝기의 차이에 따른 점수 관계를 포함할 수 있다. 환경 정보는 평가자 디스플레이 장치를 이용하여 평가자가 평가를 수행할 때의 평 가자의 위치와 사용자 디스플레이 장치를 시청하는 사용자의 위치의 차이에 다른 점수 관계를 포함할 수 있다. 프로세서는 비디오 품질 평가 장치의 전반적인 동작을 제어한다. 프로세서는 메모리에 저 장된 하나 이상의 인스트럭션을 실행함으로써, 비디오 품질 평가 장치가 기능하도록 제어할 수 있다. 실시 예에서, 프로세서는 복수의 프레임을 포함하는 비디오에 대해 품질 평가를 수행할 수 있다. 실시 예 에서, 프로세서는 적어도 하나의 뉴럴 네트워크를 이용하여 비디오 프레임에 대한 모델 기반 품질 점수를 획득할 수 있다. 실시 예에서, 비디오 품질 평가 장치에 포함된 뉴럴 네트워크는 평가자의 시선을 추적하여 얻어진 세일리 언시 영역을 미리 학습한 모델일 수 있다. 실시 예에서, 비디오 품질 평가 장치에 포함된 뉴럴 네트워크는 오디오를 고려하지 않고, 비디오만을 고려 할 때 비디오를 바라보는 사람의 시선을 추적하여 획득한 세일리언시 맵과, 오디오와 비디오를 함께 고려할 때 비디오를 바라보는 사람의 시선에 따른 세일리언시 맵을 미리 학습한 뉴럴 네트워크일 수 있다. 실시 예에서, 비디오 품질 평가 장치에 포함된 뉴럴 네트워크는 동일한 비디오에 대해, 오디오를 고려하 지 않을 때와 오디오를 고려할 때 사람의 시선을 추적하여 획득한 세일리언시 맵을 각각 학습하고, 또한 두 맵 간의 차이를 학습한 뉴럴 네트워크일 수 있다. 실시 예에서, 비디오 품질 평가 장치에 포함된 뉴럴 네트워크는 입력된 비디오 프레임으로부터 획득되는 평균 의견 점수(Mean Opinion Score, MOS)를 학습한 뉴럴 네트워크일 수 있다. MOS는 사람의 주관적 평가를 통 해 획득되는 것으로, 다수의 평가자들이 평가한 비디오 품질에 대한 개별 매개 변수를 종합하여 획득한 평균 점 수를 의미할 수 있다. 실시 예에서, 프로세서는 뉴럴 네트워크를 이용하여, 오디오를 고려했을 때의 세일리언시 영역을 반영한 제1 품질 점수를 획득할 수 있다. 보다 구체적으로, 프로세서는 비디오 프레임 및 비디오 프레임과 동기화 되어 함께 출력되는 오디오 프레임을 고려하여, 비디오 프레임에서 시청자의 주의를 끄는 세일리언시(saliency) 영역을 나타내는 오디오 기반 세일리언시 맵을 획득할 수 있다. 실시 예에서, 프로세서는 뉴럴 네트워크를 이용하여 오디오 기반 세일리언시 맵을 고려하여, 비디오 프레임에 대한 제1 품질 점수를 획득할 수 있다. 또한, 실시 예에서, 프로세서는 뉴럴 네트워크를 이용하여, 오디오를 고려하지 않고, 비디오만을 고려하여 비디오 프레임에 대한 제2 품질 점수를 획득할 수 있다. 실시 예에서, 프로세서는 오디오 기반 세일리언시 맵 및 디스플레이 장치 특성 정보 중 적어도 하나에 기 반하여 가중치를 획득할 수 있다. 실시 예에서, 프로세서는 가중치를 획득하기 위해, 비디오와 오디오를 함께 고려할 때 획득되는 오디오 기 반 세일리언시 맵으로부터 세일리언시 영역의 통계학적 특성을 획득할 수 있다. 실시 예에서, 프로세서는 세일리언시 영역의 통계학적 특성으로부터 제1 가중치를 획득할 수 있다. 세일리언시 영역의 통계학적 특성은 오디오 기반 세일리언시 맵으로부터 획득한 세일리언시 영역의 산포도(spread) 및 중심경향치(central tendency) 중 적어도 하나일 수 있다. 실시 예에서, 프로세서는 디스플레이 장치 특성 정보로부터 제2 가중치를 획득할 수 있다. 디스플레이 장 치 특성 정보는, 사용자 디스플레이 장치와 평가자의 디스플레이 장치 간의 서로 다른 스크린 사양이나 스 크린 파라미터 설정 값, 주변 환경 등에 따른 차이를 보상하기 위한 정보를 의미할 수 있다. 디스플레이 장치 특성 정보는 스크린 모델에 따른 매핑 정보, 스크린 설정에 따른 매핑 정보, 환경 정보 중 적어도 하나를 포함 할 수 있다. 실시 예에서, 프로세서는 디스플레이 장치 특성 정보로부터 제2 가중치를 획득할 수 있다. 프로세서 는 제1 가중치 및 제2 가중치 중 적어도 하나를 이용하여 최종 가중치를 획득할 수 있다. 실시 예에서, 프로세서는 제1 품질 점수 및 제2 품질 점수에 최종 가중치를 적용할 수 있다. 예컨대, 프로 세서는 최종 가중치를 이용하여 제1 품질 점수와 제2 품질 점수의 가중합을 획득함으로써 비디오 프레임에 대한 최종 품질 점수를 획득할 수 있다. 이와 같이, 실시 예에 따르면, 비디오 품질 평가 장치는 뉴럴 네트워크를 이용하여 동일한 비디오 프레임 에 대해 오디오 유무에 따른 제1 품질 점수 및 제2 품질 점수를 각각 획득하고, 이로부터 최종 품질 점수를 획 득할 수 있다. 또한, 실시 예에 따르면, 비디오 품질 평가 장치는 최종 가중치를 구하고 이를 제1 품질 점수 및 제2 품질 점수에 적용하여, 비디오 프레임에 대한 최종 품질 점수를 획득함으로써, 오디오 유무에 따른 비디오 프레임의 품질 점수를 함께 고려할 수 있다. 또한, 실시 예에 의하면, 비디오 품질 평가 장치는 오디오 기반 세일리언시 맵의 통계학적 특성과, 디스플 레이 장치 특성 정보를 통해 획득한 최종 가중치가 제1 품질 점수 및 제2 품질 점수에 반영되도록 함으로써 최 종 품질 점수를 획득할 수 있다. 도 3은 실시 예에 따른, 도2의 프로세서의 내부 블록도이다. 도 3을 참조하면, 프로세서는 제1 품질 점수 획득부, 제2 품질 점수 획득부 및 최종 품질 점수 획득부를 포함할 수 있다. 실시 예에서, 제1 품질 점수 획득부는 비디오 프레임에 대해 제1 품질 점수를 획득할 수 있다. 제1 품질 점수는 비디오 프레임 및 비디오 프레임과 함께 동기화되어 출력되는 오디오 프레임을 함께 고려할 때 획득되는 품질 점수일 수 있다. 보다 구체적으로, 제1 품질 점수는, 비디오 프레임과 오디오 프레임이 함께 고려될 때 사 용자의 주의를 끄는 오디오 기반 세일리언시 영역을 반영하여 획득되는 비디오 프레임에 대한 품질 점수일 수 있다. 실시 예에서, 제1 품질 점수 획득부는 오디오 프레임에 대한 고려 없이, 비디오 프레임만 고려할 때 비디 오 프레임에서 시청자의 주의를 끄는 세일리언시 영역을 나타내는 비주얼(visual) 세일리언시 맵을 획득할 수 있다. 보다 구체적으로, 제1 품질 점수 획득부는 제1 뉴럴 네트워크를 이용하여, 비디오 프레임으로부터 다양한 특징들을 획득하고 이를 기반으로 비주얼 세일리언시 맵을 획득할 수 있다. 비주얼 세일리언시 맵은, 오 디오에 대한 고려 없이, 비디오 프레임만을 보고 획득된 세일리언시 맵을 의미할 수 있다. 실시 예에서, 제1 품질 점수 획득부는 오디오 프레임 및 비주얼 세일리언시 맵으로부터 오디오 기반 세일 리언시 맵을 획득할 수 있다. 제1 품질 점수 획득부는 제2 뉴럴 네트워크를 이용하여, 오디오 프레임 및 제1 뉴럴 네트워크가 획득한 비주얼 세일리언시 맵을 입력 받고, 그로부터 오디오 기반(audio-based) 세일리언 시 맵을 획득할 수 있다. 오디오 기반 세일리언시 맵은 비디오와 오디오를 함께 고려할 때의 시청자의 관심을 끄는 영역을 표현하는 세일리언시 맵을 의미할 수 있다. 실시 예에서, 제1 품질 점수 획득부가 이용하는 제2 뉴럴 네트워크는 오디오 신호를 고려할 때와 오디오 신호를 고려하지 않을 때의 세일리언시 영역의 차이를 학습한 뉴럴 네트워크일 수 있다. 또한, 제2 뉴럴 네트워 크는 오디오 신호를 고려할 때, 오디오 신호의 특성에 따라 달라지는 세일리언시 영역을 학습한 뉴럴 네트워크 일 수 있다. 제2 뉴럴 네트워크는 오디오 프레임으로부터 오디오 신호의 특성을 획득하고, 획득한 오디오 신호 의 특성을 고려하여 오디오 기반 세일리언시 맵을 획득할 수 있다. 실시 예에서, 오디오 신호의 특성은 오디오의 장르(genre), 주제(theme), 볼륨(volume), 해상도(resolution), 정보량(entropy), 선명도(sharpness), 다이나믹스(dynamics), 대역 밸런스(tonal balance), 음색(tone color), 위상(phase), 음상(sound image), 음장(sound staging), 임장감(presence) 중 적어도 하나를 포함할 수 있다. 실시 예에서, 제1 품질 점수 획득부는 제3 뉴럴 네트워크를 이용하여, 오디오 기반 세일리언시 맵과, 비디 오 프레임을 입력 받고, 그로부터 제1 품질 점수를 획득할 수 있다. 제3 뉴럴 네트워크는 비디오 프레임 및 오 디오 기반 세일리언시 맵으로부터 특징 벡터를 획득하고, 특징 벡터와 평균 의견 점수(Mean Opinion Score, MOS)간의 상관 관계를 미리 학습한 뉴럴 네트워크일 수 있다. 실시 예에서, 제2 품질 점수 획득부는 제4 뉴럴 네트워크를 이용하여, 비디오 프레임에 대한 제2 품질 점 수를 획득할 수 있다. 제2 품질 점수 획득부는 오디오에 대한 고려 없이, 또한, 세일리언시 맵 고려 없이, 비디오 프레임 전체에 대한 품질 평가를 수행할 수 있다. 따라서, 제2 품질 점수 획득부가 제4 뉴럴 네트 워크를 이용하여 비디오 프레임에 대해 획득하는 품질 점수는 오디오를 고려하여 획득되는 제1 품질 점수와 구 별될 수 있다. 실시 예에서, 제4 뉴럴 네트워크는 비디오에 대한 특징 벡터와 평균 의견 점수 간의 상관 관계를 미리 학습한 뉴럴 네트워크일 수 있다. 실시 예에서, 제4 뉴럴 네트워크가 비디오로부터 획득하는 특징 벡터는 블러 관련 특 징, 모션 관련 특징, 컨텐트 관련 특징, 딥 특징, 통계적인 특징, 개념적인 특징, 공간적인 특징, 변형된 도메 인 특징 중 적어도 하나를 포함할 수 있다. 실시 예에서, 제4 뉴럴 네트워크는 비디오 프레임으로부터 품질 점수에 영향을 줄 수 있는 요인과 관련된 하나 이상의 정보를 획득할 수 있다. 실시 예에서, 품질 점수에 영향을 줄 수 있는 요인은 비디오 프레임에 포함된 오브젝트가 전경(foreground)인지 배경(background)인지에 대한 정보, 비디오의 장르에 대한 정보, 오브젝트의 시맨틱(semantic) 정보, 오브젝트의 위치 정보, 컨텐트 정보 중 적어도 하나를 포함할 수 있다. 사람은 전경에 있는 오브젝트의 왜곡 정도를 후경에 있는 오브젝트의 왜곡 정도보다 크게 인식하는 경향이 있다. 또한, 사람은 비디오 프레임이 속한 장르가 무엇인지에 따라 왜곡의 정도를 다르게 인식하는 경향이 있다. 예컨대, 사람은 움직임이 많고 그 움직임에 집중을 요하는 스포츠 경기와 정적인 화면에 동일한 왜곡이 포함되어 있어도, 스포츠 경기에 포함된 왜곡을 더 크게 인식하는 경향이 있다. 사람의 이러한 인식은 품질 점 수에 영향을 줄 수 있다. 또한, 사람은 비디오를 볼 때 화면의 중앙 부분을 가장자리 부분보다 더 많이 보는 경향이 있으므로, 중앙 부분 에 왜곡이 있는 비디오 프레임과 가장자리 부분에 왜곡이 있는 프레임에서 왜곡의 정도를 다르게 인식하게 된다. 또한, 사람은 프레임에 포함된 오브젝트의 시맨틱(semantic) 정보를 고려하여 비디오를 보는 경향이 있다. 이는 해당 비디오 프레임에 포함된 오브젝트가 무엇인지에 따라, 즉, 그 오브젝트가 프레임에서 갖는 의미에 따라 오 브젝트의 왜곡을 인식하는 정도가 달라질 수 있음을 의미한다. 실시 예에서, 제2 품질 점수 획득부는 제4 뉴럴 네트워크를 이용하여 품질 점수에 영향을 줄 수 있는 요인 과 관련된 하나 이상의 정보를 서브 영역 별로 획득하고, 이로부터 비디오 프레임 전체에 대한 모델 기반 품질 점수를 제2 품질 점수로 획득할 수 있다. 실시 예에서, 최종 품질 점수 획득부는 제1 품질 점수 획득부가 획득한 제1 품질 점수와, 제2 품질 점수 획득부가 획득한 제2 품질 점수를 기반으로 최종 품질 점수를 획득할 수 있다. 실시 예에서, 최종 품 질 점수 획득부는 제1 품질 점수와 제2 품질 점수에 가중치를 부여함으로써, 비디오 프레임에 대한 최종 품질 점수를 획득할 수 있다. 도 4는 실시 예에 따른, 도 3의 제1 품질 점수 획득부의 내부 블록도이다. 실시 예에서, 제1 품질 점수 획득부는 오디오 기반 세일리언시 맵을 고려하여 비디오 프레임에 대한 제1 품질 점수를 획득할 수 있다. 도 4를 참조하면, 제1 품질 점수 획득부는 비주얼 세일리언시 맵 획득부, 오디오 기반 세일리언시 맵 획득부 및 품질 점수 획득부를 포함할 수 있다. 비주얼 세일리언시 맵 획득부는 비디오 프레임을 입력 받을 수 있다. 실시 예에서, 비주얼 세일리언 시 맵 획득부는 제1 뉴럴 네트워크를 이용하여, 비디오 프레임으로부터 다양한 특징들을 획득하고 이 를 기반으로 비주얼 세일리언시 맵을 획득할 수 있다. 실시 예에서, 비주얼 세일리언시 맵 획득부에 포함된 제1 뉴럴 네트워크는 입력 데이터를 분석 및 분류하 여 입력된 데이터로부터 시청자의 주의를 끄는 세일리언시 영역을 나타내는 세일리언시 맵을 추출하도록 학습된모델일 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 입력된 비디오 프레임으로부터 세일리언시 맵을 획득하도록 학습된 뉴럴 네 트워크일 수 있다. 예컨대, 제1 뉴럴 네트워크는 입력된 비디오 프레임에 포함된 픽셀들 각각 또는 유사한 특징 을 갖는 복수 픽셀들을 포함하는 픽셀 그룹의 색 변화나 분포, 엣지(edges), 공간 주파수, 구조, 분포, 히스토 그램, 텍스쳐(texture) 등을 고려하여 입력된 비디오 프레임에 대한 세일리언시 맵을 획득하도록 학습된 뉴럴 네트워크일 수 있다. 또한, 실시 예에서, 제1 뉴럴 네트워크는 오디오 프레임 고려 없이, 비디오 프레임만을 고려할 때, 비디오 프레 임에 대한 사용자의 시선을 추적하여 사용자의 주의를 끄는 비주얼 세일리언시 영역이 어디인가를 미리 학습한 뉴럴 네트워크일 수 있다. 제1 뉴럴 네트워크는 입력된 비디오 프레임에서 특징을 추출하는 알고리즘, 또는 알고리즘의 집합, 알고리 즘의 집합을 실행하는 소프트웨어 및/또는 알고리집의 집합을 실행하는 하드웨어일 수 있다. 제1 뉴럴 네트워크 는 입력된 비디오 프레임으로부터 획득한 특징들을 기반으로, 비주얼 세일리언시 맵을 획득할 수 있 다. 도 4에 도시된 바와 같이, 실시 예에서, 비주얼 세일리언시 맵은 하얀색과 검정색으로 표현될 수 있다. 도 4의 비주얼 세일리언시 맵은 하나의 실시 예로, 사용자가 비디오 프레임을 볼 때 사용자의 시선을 끄 는 영역은 하얀 색으로 표현되고, 사용자의 시선을 끌지 않는 나머지 영역은 검정 색으로 표현된 것을 도시한다. 도 4의 비주얼 세일리언시 맵에 도시된 바와 같이, 오디오 프레임를 고려하지 않고, 비디오 프레임 만을 고려했을 때, 사용자의 시선은 비디오 프레임 내에 포함된 두 사람을 주로 향하고 있음을 알 수 있다. 실시 예에서, 오디오 기반 세일리언시 맵 획득부는 제2 뉴럴 네트워크를 이용하여, 오디오 기반(audio- based) 세일리언시 맵을 획득할 수 있다. 실시 예에서, 제2 뉴럴 네트워크 또한 제1 뉴럴 네트워크와 마찬가지로 입력 데이터를 분석 및 분류하여 입력된 데이터로부터 시청자의 주의를 끄는 세일리언시 영역을 나타내는 세일리언시 맵을 추출하도록 학습된 모델일 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 학습 단계에서, 제1 뉴럴 네트워크와는 달리, 비디오 프레임과 오디오 프레 임을 함께 입력 받고 입력된 비디오 프레임과 오디오 프레임의 특징을 분석 및 분류하여, 비디오 프레임에 대한 사용자의 시선을 추적하여 사용자의 주의를 끄는 오디오 기반 세일리언시 영역이 어디인가를 학습한 뉴럴 네트 워크일 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 동일한 비디오 프레임에 대해, 오디오 프레임이 있을 때와 오디오 프레임이 없을 때, 비디오 프레임에 대해 획득되는 세일리언시 맵의 차이를 미리 학습할 수 있다. 즉, 제2 뉴럴 네트워크 는 비주얼 세일리언시 맵과 오디오 기반 세일리언시 맵의 차이를 미리 학습한 뉴럴 네트워크일 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 비주얼 세일리언시 맵 획득부로부터 받은 비주얼 세일리언시 맵과, 비디오 프레임과 동기화되어 출력되는 오디오 프레임을 입력 받고, 그로부터 오디오 프레 임이 비디오 프레임과 함께 출력될 때 사용자의 관심 영역을 고려한 오디오 기반 세일리언시 맵(41 7)을 획득할 수 있다. 도 4에서, 하나의 실시 예로, 비디오 프레임과 함께 출력되는 오디오 프레임이 폭발음을 포함하는 경 우를 가정한다. 도 4에서, 오디오 기반 세일리언시 맵은 비주얼 세일리언시 맵과 달리, 비디오 프레 임 내의 두 사람뿐 아니라, 두 사람 뒤의 폭발 장면 또한 하얗게 표현된 것을 알 수 있다. 이는, 사용자가 폭발음을 포함하는 오디오 프레임을 들으면서 비디오 프레임을 보는 경우, 비디오 프레임에 포 함된 두 명의 사람만을 보지 않고, 두 사람 뒤의 폭발 장면까지 함께 보는 것을 의미할 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 오디오 프레임을 이용하여 비주얼 세일리언시 맵을 수정함으로써 오디오 기반 세일리언시 맵을 획득할 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 오디오 프레임이 입력 될 때, 오디오 프레임을 분석 및 분류하여, 오디오의 특성을 추출하는 알고리즘, 또는 알고리즘의 집합, 알고리즘의 집합을 실행하는 소프트웨어 및/또는 알고리집의집합을 실행하는 하드웨어일 수 있다. 제2 뉴럴 네트워크는 오디오 프레임으로부터 획득한 오디오 프레임의 특 성을 고려하여, 비주얼 세일리언시 맵을 오디오 기반 세일리언시 맵으로 수정할 수 있다. 실시 예에서, 오디오 신호의 특성은 오디오 장르(genre), 볼륨(volume), 해상도(resolution), 정보량 (entropy), 선명도(sharpness), 다이나믹스(dynamics), 대역 밸런스(tonal balance), 음색(tone color), 위상 (phase), 음상(sound image), 음장(sound staging), 임장감(presence) 중 적어도 하나를 포함할 수 있다. 오디오 장르는 오디오의 특색에 따라 오디오를 오케스트라, 피아노, 재즈, 보컬 등으로 구분하는 정보이거나, 또는 오디오를 클래식(classic), 힙팝(hiphop), 재즈(jazz), 락(rock), 음성(speech), 동물소리, 기계소리, 악 기소리, 폭풍우나 지진 소리, 폭발음 소리, 등으로 구분하는 정보일 수 있다. 오디오 장르가 무엇인지에 따라 사용자의 관심 영역은 달라질 수 있다. 예컨대, 비디오 프레임에 강아지와 사람이 함께 포함되어 있는 경우, 오 디오가 배경음인지, 사람의 음성인지, 또는 강아지가 짖는 소리인지 등에 따라 비디오를 시청하는 사용자의 관 심 영역은 달라질 수 있다. 오디오 볼륨은 소리의 크기를 나타낼 수 있다. 소리의 크기에 따라 비디오를 시청하는 사용자의 관심 영역은 달 라질 수 있다. 예컨대, 도 4에 도시된 비디오 프레임에서 폭발음의 크기가 클수록 사용자의 관심 영역을 폭발 장면을 더 많이 포함하게 된다. 유사하게, 오디오 특성은 다양한 요인들을 포함할 수 있다. 오디오 특성 중, 오디오 해상도는 미세한 소리를 얼마나 선명히 표현하는지를 의미할 수 있다. 오디오 해상도는 소리의 주파수 대역의 분포 정도에 따라 달라질 수 있다. 오디오 정보량은 소스가 얼마나 많은 데이터를 가지고 있는지를 의미할 수 있다. 오디오 정보량이 많을수록 소 리가 풍부하고 자연스럽게 표현될 수 있다. 오디오 선명도는 오디오 해상도와 밀접한 관계를 가지며, 소리가 또렷한 정도를 의미할 수 있다. 선명도는 소리 의 특성을 자세히 표현하는 정보로, 선명도가 지나치면 소리가 날카로워지고, 선명도가 낮으면 음질을 구분하기 힘들어질 수 있다. 오디오 다이나믹스는 짧은 시간에 음의 강약을 원활하게 재생하는 능력을 의미할 수 있다. 오디오 다이나믹스가 뛰어나면 악기의 실재감이 커지게 된다. 오디오 대역 밸런스는 스피커가 가청 주파수 대역을 나누어 재생할 때, 나누는 대역간의 밸런스를 의미할 수 있 다. 오디오 음색은 오디오의 전체적인 소리의 어두움이나 가벼움, 울림 등의 특징을 표현할 수 있다. 오디오 위상은 소리가 귀에 도달하는 시간과 관련된 지표를 의미할 수 있다. 오디오 음상은 오디오가 모노 신호인지, 스테레오 신호인지, 또는 3차원 효과를 갖는 입체음인지 등을 의미할 수 있다. 오디오 음장은 오디오가 그려내는 입체적인 가장 공간의 크기와 모양을 의미할 수 있다. 오디오 임장감은 실제 공연장과 같은 느낌을 주는 요소를 의미할 수 있다. 실시 예에서, 제2 뉴럴 네트워크는 상술한, 오디오 장르나 볼륨, 소리 음색 등과 같이 다양한 오디오 특성에 따 라 달라지는 사용자의 관심 영역을 미리 학습한 뉴럴 네트워크일 수 있다. 학습이 끝난 후, 제2 뉴럴 네트워크 는 입력된 오디오 신호로부터 오디오 신호의 다양한 특성들을 획득하고, 특성들과 관련된 세일리언시 영역을 획 득하여, 오디오 기반 세일리언시 맵을 획득할 수 있다. 실시 예에서, 품질 점수 획득부는 제3 뉴럴 네트워크를 이용하여, 오디오 기반 세일리언시 맵와 비디 오 프레임을 입력 받고, 그로부터 제1 품질 점수를 획득할 수 있다. 실시 예에서, 제3 뉴럴 네트워크는 비디오 프레임 및 오디오 기반 세일리언시 맵에서 특징을 추출하는 알고리즘, 또는 알고리즘의 집합, 알고리즘의 집합을 실행하는 소프트웨어 및/또는 알고리집의 집합을 실행하는 하드웨어일 수 있다. 제3 뉴럴 네트워크는 비디오 프레임 및 오디오 기반 세일리언시 맵으로부터 특징 벡터를 획득하고, 특징 벡터와 평균 의견 점수간의 상관 관계를 미리 학습한 뉴럴 네트워크일 수 있다. 제3 뉴럴 네트워크는 입력된 비디오 프레임 및 오디오 기반 세일리언시 맵으로부터 획득한 특징들을 기반으로, 비디오 프레임에 대한 제1 품질 점수를 획득할 수 있다. 도 5는 실시 예에 따른, 도 3의 최종 품질 점수 획득부의 내부 블록도이다. 도 5를 참조하면, 최종 품질 점수 획득부는 제1 가중치 획득부, 제2 가중치 획득부, 최종 가중 치 획득부 및 최종 가중치 적용부를 포함할 수 있다. 실시 예에서, 제1 가중치 획득부는 오디오를 고려할 때 시청자의 관심을 끄는 세일리언시 영역에 대한 품 질 점수가 최종 품질 점수에 미치는 영향을 나타내는 제1 가중치를 획득할 수 있다. 실시 예에서, 제1 가중치 획득부는 펑션(function)을 이용하거나, 또는 뉴럴 네트워크를 이용하여, 오디오 기반 세일리언시 맵으로부터 제1 가중치를 획득할 수 있다. 오디오를 고려할 때의 세일리언시 영역에 대한 품질 점수와 최종 품질 점수 간의 관련성을 알기 위해서는 소정 의 실험을 통해 미리 데이터를 준비하는 과정이 선행되어야 한다. 이를 위해, 평가자는 오디오 기반 세일리언시 맵 영역에만 왜곡이 포함된 비디오 프레임과, 오디오 기반 세일리언시 맵 영역뿐 아니라 다른 영역에도 왜곡이 포함된 비디오 프레임을 각각 평가할 수 있다. 이하, 도 6을 참조하여, 제1 가중치 획득부가 제1 가중치를 획득하기 위해, 소정의 실험을 통해 학습 데이 터를 준비하는 내용을 설명하기로 한다. 도 6은 실시 예에 따라 오디오 기반 세일리언시 맵으로부터 제1 가중치를 획득하는 것을 설명하기 위한 도면이 다. 도 6에서, 제1 비디오 프레임은 왜곡이 없는 깨끗한 비디오 프레임을 도시한다. 참조 부호 620은 제1 비디 오 프레임으로부터 획득한 오디오 기반 세일리언시 맵을 도시한다. 전술한 바와 같이, 실시 예에서, 오디오 기반 세일리언시 맵은 뉴럴 네트워크를 이용하여 획득될 수 있다. 오디오 기반 세일리언시 맵은 비디오 프레임 외에 오디오 프레임도 고려하여, 비디오 프레임과 오디오 프 레임을 분석 및 분류하여, 비디오 프레임에 대한 사용자의 시선을 추적하여 사용자의 주의를 끄는 오디오 기반 세일리언시 영역이 어디인가를 학습한 뉴럴 네트워크를 이용하여 획득될 수 있다. 실시 예에서, 오디오 기반 세일리언시 맵은 비주얼 세일리언시 맵과, 오디오 프레임을 입력 받고, 그로부 터 오디오 프레임이 함께 출력될 때 사용자의 관심 영역의 변화를 학습한 뉴럴 네트워크를 이용하여 획득될 수 있다. 도 6에서, 오디오 기반 세일리언시 맵은 동물의 부리와 눈, 앞치마, 나뭇잎 일부 등은 하얀색이고 나머지 는 검정색인 것을 알 수 있다. 이는 오디오를 고려하여 비디오를 볼 때 사용자의 시선을 끄는 영역이 동물의 부 리와 눈, 앞치마 등이라는 것을 의미할 수 있다. 소정 실험에서, 평가자는 오디오 프레임과 비디오 프레임을 함께 고려하여, 오디오 기반 세일리언시 맵 영역에 만 왜곡이 포함된 비디오 프레임에 대해 평가할 수 있다. 도 6에서, 제2 비디오 프레임은 제1 비디오 프레임에서, 오디오 기반 세일리언시 영역에만 왜곡이 추 가된 프레임을 도시한다. 도 6에 도시된 바와 같이, 제2 비디오 프레임은 오디오 기반 세일리언시 맵(62 0)으로부터 사용자의 관심을 끄는 오디오 기반 세일리언시 영역인 동물의 부리, 눈, 앞치마, 나뭇잎 등에만 왜 곡을 포함하고 있음을 알 수 있다. 평가자는 오디오 프레임과 제2 비디오 프레임을 함께 고려하여, 오디오 기반 세일리언시 영역에만 왜곡이 포함된 제2 비디오 프레임에 대해 평가할 수 있다. 또한, 평가자는 오디오 프레임을 고려하지 않고 비디오 프레임만을 고려하여, 전체 프레임에 왜곡이 포함된 비 디오 프레임을 평가할 수 있다. 도 6에서, 제3 비디오 프레임은 제1 비디오 프레임 전체에 왜곡이 포함된 경우를 도시한다. 제3 비디 오 프레임은 오디오 기반 세일리언시 영역에 대한 고려 없이, 제1 비디오 프레임 전체에 왜곡을 가하 여 획득될 수 있다. 평가자는 오디오 프레임에 대한 고려 없이, 제3 비디오 프레임 만을 고려하여, 제3 비디오 프레임에 대해 평가할 수 있다. 복수의 평가자들이 오디오 기반 세일리언시 맵 영역에만 왜곡이 포함된 제2 비디오 프레임에 대해 평가한 평가 점수를 제1 MOS, 전체 영역에 왜곡이 포함된 제3 비디오 프레임에 대한 평가 점수를 제2 MOS라고 하면, 제1 MOS와 제2 MOS는 동일하지 않을 수 있다. 이는 오디오 프레임을 고려할 때와 오디오 프레임을 고려하지 않을 때 평가자의 시선을 끄는 세일리언시 영역이 달라지게 되기 때문이다. 즉, 오디오 프레임을 고려할 때 평 가자의 시선이 위치하는 오디오 기반 세일리언시 맵 영역에 왜곡이 포함된 경우, 평가자가 그 영역에 포함된 왜 곡을 다른 영역에 포함된 왜곡보다 더 크게 인식하게 된다. 다시, 도 5로 돌아와서, 실시 예에서, 제1 가중치 획득부는 전체 비디오 프레임에 왜곡이 포함된 경우와 오디오 기반 세일리언시 맵 영역에만 왜곡이 포함된 경우의 MOS 값 간의 상관 관계를 고려하여 가중치 펑션을 생성할 수 있다. 또는 제1 가중치 획득부는 전체 비디오 프레임에 왜곡이 포함된 경우와 오디오 기반 세일 리언시 맵 영역에만 왜곡이 포함된 경우의 각각의 MOS 값 및 두 MOS 값 간의 상관 관계를 학습한 뉴럴 네트워크 를 이용할 수 있다. 제1 가중치 획득부는 가중치 펑션이나 뉴럴 네트워크를 이용하여 오디오 기반 세일리언시 맵으로부터 오디 오를 고려할 때 시청자의 관심을 끄는 세일리언시 영역에 대한 품질 점수가 최종 품질 점수에 미치는 영향을 나 타내는 제1 가중치를 획득할 수 있다. 또한, 오디오 기반 세일리언시 맵의 영역에만 왜곡이 포함된 경우에도, 오디오 기반 세일리언시 맵의 통계적 특 성에 따라 평가자의 평가 점수는 달라질 수 있다. 예컨대, 오디오 기반 세일리언시 맵의 영역이 전체 비디오 프 레임에서 80 퍼센트를 차지하는 경우와 20퍼센트를 차지하는 경우, 오디오 기반 세일리언시 맵 영역에 포함된 왜곡에 대한 평가자의 왜곡 인식 정도는 달라질 수 있다. 또한, 오디오 기반 세일리언시 맵의 영역의 분포에 따 라 평가자의 평가 점수는 달라질 수 있다. 예컨대, 오디오 기반 세일리언시 맵의 영역이 프레임 전반에 걸쳐 흩 어져 있을 때 평가자가 프레임 전반에 걸쳐 흩어져 있는 왜곡을 인식하는 정도보다 오디오 기반 세일리언시 맵 의 영역이 특정 위치에 집중되어 있는 경우 평가자는 그 특정 위치에 포함된 왜곡을 더 크게 인식하게 된다. 제1 가중치 획득부는 오디오 기반 세일리언시 맵을 기반으로 가중치 펑션을 생성할 수 있다. 가중치 펑션 은 전체 비디오 프레임에 왜곡이 포함된 경우와 오디오 기반 세일리언시 맵 영역에만 왜곡이 포함된 경우의 각 각의 MOS 값 간의 상관 관계에 따라 가중치를 구하는 함수일 수 있다. 가중치 펑션은 오디오 기반 세일리언시 맵을 기반으로 세일리언시 영역의 통계학적 특성을 고려한 함수일 수 있 다. 세일리언시 영역의 통계학적 특성은 오디오 기반 세일리언시 맵에 포함된 세일리언시 영역이 비디오 프레임 에 포함된 비율(proportion), 세일리언시 영역의 산포도(spread) 및 중심 경향치(central tendency) 중 적어도 하나일 수 있다. 예컨대, 가중치 펑션은 비디오 프레임의 몇 퍼센트가 세일리언시 영역인지를 고려한 함수일 수 있다. 가중치 펑 션은 비디오 프레임 내에 포함된 오디오 기반 세일리언시 영역의 집중도(concentration)나 중심 경향치(central tendency), 또는 산포도(spread) 등을 고려한 함수일 수 있다. 세일리언시 영역의 집중도 내지 중심 경향치는 세일리언시 영역이 얼마나 집중되어 있는지를 나타낸 것으로, 평균 값, 최빈값, 중앙값 중 적어도 하나로 표현 될 수 있다. 세일리언시 영역의 산포도는 세일리언시 영역이 얼마나, 및/또는 어떻게 퍼져있는지를 나타낸 것으 로, 범위, 사분위간 범위(interquartile range), 분산, 표준 편차, 절대 편차 중 적어도 하나로 표현될 수 있다. 가중치 펑션은 오디오 기반 세일리언시 맵으로부터 추출된 하나 이상의 이러한 특징 또는 통계와 평가자들의 MOS 값 간의 관계를 기반으로 가중치를 구하는, 통계적 곡선 피팅 함수(statistical curve fitting function) 일 수 있다. 실시 예에서, 제1 가중치 획득부는 가중치 펑션 대신 뉴럴 네트워크를 이용하여 제1 가중치를 획득할 수도 있다. 이 경우, 제1 가중치 획득부가 이용하는 뉴럴 네트워크는 오디오 기반 세일리언시 맵 영역에만 왜곡 이 포함된 비디오 프레임과, 전체 비디오 프레임에 왜곡이 포함된 비디오 프레임에 대한 평가자들의 MOS 값을 미리 학습할 수 있다. 뉴럴 네트워크는 전체 비디오 프레임에 왜곡이 포함된 경우와 오디오 기반 세일리언시 맵 영역에만 왜곡이 포함된 경우의 MOS 값의 차이를 학습하고, MOS 값의 차이를 고려하여 가중치를 획득하도록 학 습될 수 있다. 또한, 제1 가중치 획득부가 이용하는 뉴럴 네트워크는 오디오 기반 세일리언시 맵으로부터 오디오 기반 세일리언시 맵의 여러 특징들을 획득하고, 이러한 특징들로부터 제1 가중치를 획득하도록 학습될 수 있다. 실시 예에서, 제1 가중치 획득부는 가중치 펑션 또는 뉴럴 네트워크를 이용하여, 오디오 기반 세일리언시 맵으로부터 제1 가중치를 획득할 수 있다. 실시 예에서, 제1 가중치 획득부는 비디오 프레임을 서브 영역들로 나누고, 각 서브 영역 별로 제1 가중치 를 획득할 수 있다. 제1 가중치 획득부는 서브 영역 별로 획득한 제1 가중치를 최종 가중치 획득부로 전송할 수 있다. 실시 예에서, 제2 가중치 획득부는 디스플레이 장치 특성 정보를 기반으로 제2 가중치를 획득할 수 있다. 제2 가중치 획득부는 비디오 품질 평가 장치에 기 저장되어 있는 디스플레이 장치 특성 정보를 추출 하고, 이를 기반으로 제2 가중치를 획득할 수 있다. 디스플레이 장치의 특성 정보는 스크린 모델 매핑 정보, 스 크린 설정 매핑 정보, 및 환경 정보 중 적어도 하나를 포함할 수 있다. 전술한 바와 같이, 비디오 품질 평가 장치는 복수개의 뉴럴 네트워크를 이용하여 비디오를 평가함으로써 제1 품질 점수 및 제2 품질 점수를 획득할 수 있다. 이 때, 비디오 품질 평가 장치가 이용하는 뉴럴 네트 워크는 비디오 품질 평가를 위해 입력된 데이터로부터 MOS를 획득하도록 사전 훈련 된 모델일 수 있다. 이 때 뉴럴 네트워크가 학습한 MOS는 특정 환경에서, 특정한 모델의 스크린을 갖는 평가자 디스플레이 장치를 이용하 여 획득된 것일 수 있다. 그러나, 실제 사용자가 이용하는 사용자 디스플레이 장치는 평가자 디스플레이 장치와는 여러 사양이 다를 수 있다. 실시 예에서, 제2 가중치 획득부는 평가자 디스플레이 장치와 실제 사용자가 이용하는 사용자 디스플레이 장치의 특성 정보 차이를 보상하기 위해 제2 가중치를 생성할 수 있다. 실시 예에서, 제2 가중치 획득부는 평가자 디스플레이 장치와 사용자 디스플레이 장치의 스크린 모델 에 따른 화면 사이즈나 해상도 차이, 사용자 디스플레이 장치의 스크린 설정 값의 차이, 주변 환경의 차이 등을 고려하여 제2 가중치를 획득할 수 있다. 실시 예에서, 제2 가중치 획득부는 비디오 프레임을 복수의 서브 영역들로 나누고, 각 서브 영역 별로 제2 가중치를 획득할 수 있다. 실시 예에서, 최종 가중치 획득부는 제1 가중치 획득부 및 제2 가중치 획득부가 각각 획득한 제 1 가중치 및 제2 가중치를 이용하여 최종 가중치를 획득할 수 있다. 예컨대, 최종 가중치 획득부는 제1 가 중치 획득부가 획득한 서브 영역 별 제1 가중치와 제2 가중치 획득부가 획득한 서브 영역 별 제2 가 중치를 각각 곱하여 서브 영역 별 최종 가중치를 획득할 수 있다. 최종 가중치 획득부는 서브 영역 별 최 종 가중치를 주변 서브 영역들의 최종 가중치를 참조하여 수정하거나, 또는 전체 서브 영역 들의 최종 가중치의 평균 값 등을 구하여, 비디오 프레임 전체에 대한 최종 가중치를 획득할 수 있다. 실시 예에서, 최종 가중치는 0보다 크거가 같고 1보다 작거나 같은 값을 가질 수 있다. 실시 예에서, 최종 가중치 적용부는 최종 가중치 획득부가 획득한, 비디오 프레임 별 최종 가중치를 품질 점수에 적용하여 최종 점수를 획득할 수 있다. 예컨대, 최종 가중치 적용부는 제1 품질 점수 획득부 가 획득한 제1 품질 점수에 최종 가중치를 곱하고, 제2 품질 점수 획득부가 구한 제2 품질 점수에 1 과 최종 가중치의 차이를 곱한 후, 가중치가 적용된 두 품질 점수를 더하여 가중합을 구할 수 있다. 예컨대, 최 종 가중치 값이 0.7인 경우, 최종 가중치 적용부는 제1 품질 점수에 0.7을 곱하고, 제2 품질 점수에 1과 0.7의 차이인 0.3을 곱한 후, 0.7이 곱해진 제1 품질 점수와 0.3이 곱해진 제2 품질 점수를 더하여 최종 품질 점수를 획득할 수 있다. 도 7은 실시 예에 따른 사용자 디스플레이 장치의 내부 블록도이다. 도 7의 사용자 디스플레이 장치는 도 2의 비디오 품질 평가 장치의 구성 요소를 포함할 수 있다. 도 7을 참조하면, 사용자 디스플레이 장치는 프로세서 및 메모리 외에, 튜너부, 통신부 , 감지부, 입/출력부, 비디오 처리부, 디스플레이, 오디오 처리부, 오디오 출 력부, 및 사용자 인터페이스를 포함할 수 있다. 튜너부는 유선 또는 무선으로 수신되는 방송 콘텐츠 등을 증폭(amplification), 혼합(mixing), 공진 (resonance)등을 통하여 많은 전파 성분 중에서 사용자 디스플레이 장치에서 수신하고자 하는 채널의 주파 수만을 튜닝(tuning)시켜 선택할 수 있다. 튜너부를 통해 수신된 콘텐츠는 디코딩되어 오디오, 비디오 및/ 또는 부가 정보로 분리된다. 분리된 오디오, 비디오 및/또는 부가 정보는 프로세서의 제어에 의해 메모리 에 저장될 수 있다. 통신부는 프로세서의 제어에 의해 사용자 디스플레이 장치를 외부 장치나 서버와 연결할 수 있 다. 사용자 디스플레이 장치는 통신부를 통해 외부 장치나 서버 등으로부터 사용자 디스플레이 장치 가 필요로 하는 프로그램이나 어플리케이션(application)을 다운로드하거나 또는 웹 브라우징을 할 수 있다. 또한, 통신부는 외부 장치로부터 콘텐츠를 수신할 수 있다. 통신부는 사용자 디스플레이 장치의 성능 및 구조에 대응하여 무선 랜, 블루투스, 및 유선 이더넷(Ethernet) 중 적어도 하나를 포함할 수 있다. 통신부는 프로세서의 제어에 의해 리모컨 등과 같은 제어 장치(미도시)를 통한 제어 신호를 수신할 수 있다. 제어 신호는 블루투스 타입, RF 신호 타입 또는 와이파이 타입으로 구현될 수 있다. 통신부는 블루투스 외에 다른 근거리 통신(예를 들어, NFC(near field communication, 미도시), BLE(bluetooth low energy, 미도시))를 더 포함할 수 있다. 실시 예 에 따라, 통신부는 블루투스나 BLE와 같은 근거리 통신을 통하여 외부 장치 등과 연결 신호를 송수신 할 수도 있다. 실시 예에서, 통신부는 다양한 통신 모듈을 이용하여 사용자의 위치 등을 파악할 수 있다. 또한, 도 7에는 도시하지 않았으나, 통신부는 UWB 모듈이 포함될 수 있다. UWB 모듈은 복수개의 안테나를 이용하여, 사용 자의 생체 신호를 획득하고, 이를 통해 사용자의 위치 등을 파악할 수 있다. 감지부는 사용자의 음성, 사용자의 영상, 또는 사용자의 인터랙션을 감지하며, 마이크, 카메라부 , 및 광 수신부를 포함할 수 있다. 마이크는 사용자의 발화(utterance)된 음성을 수신할 수 있 고 수신된 음성을 전기 신호로 변환하여 프로세서로 출력할 수 있다. 카메라부는 센서(미도시) 및 렌즈(미도시)를 포함하고, 화면에 맺힌 이미지를 촬영할 수 있다. 광 수신부 는, 광 신호(제어 신호를 포함)를 수신할 수 있다. 실시 예에서, 카메라부는 사용자 이미지로부터 사 용자의 위치나, 사용자의 시청 각도 등에 대한 정보를 획득할 수 있다. 광 수신부는 리모컨이나 핸드폰 등과 같은 제어 장치(미도시)로부터 사용자 입력(예를 들어, 터치, 눌림, 터치 제스처, 음성, 또는 모션)에 대응되는 광 신호를 수신할 수 있다. 수신된 광 신호로부터 프로세서의 제어에 의해 제어 신호가 추출될 수 있다. 또한, 도 7에는 도시하지 않았으나, 사용자 디스플레이 장치는 조도 센서를 더 포함할 수 있다. 조도 센서 는 사용자 디스플레이 장치 주변의 밝기 등을 감지할 수 있다. 입/출력부는 프로세서의 제어에 의해 사용자 디스플레이 장치 외부의 기기 등으로부터 비디오 (예를 들어, 동영상 신호나 정지 영상 신호 등), 오디오(예를 들어, 음성 신호나, 음악 신호 등) 및 메타데이터 등의 부가 정보를 수신할 수 있다. 메타데이터는, 콘텐츠에 대한 HDR 정보, 콘텐츠에 대한 설명이나 콘텐츠 타 이틀, 콘텐츠 저장 위치 등을 포함할 수 있다. 입/출력부는 HDMI 포트(High-Definition Multimedia Interface port, 741), 컴포넌트 잭(component jack, 742), PC 포트(PC port, 743), 및 USB 포트(USB port, 744) 중 하나를 포함할 수 있다. 입/출력부는 HDMI 포트, 컴포넌트 잭, PC 포트, 및 USB 포트의 조합을 포함할 수 있다. 비디오 처리부는, 디스플레이에 의해 표시될 영상 데이터를 처리하며, 영상 데이터에 대한 디코딩, 렌더링, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 및 해상도 변환 등과 같은 다양한 영상 처리 동작을 수 행할 수 있다. 실시 예에서, 비디오 처리부는, 화질 처리 기능도 수행할 수 있다. 즉, 비디오 처리부는 프로세서 가 획득한 프레임 별 점수 또는 전체 비디오의 최종 품질 점수에 기반하여 비디오 및/또는 프레임의 품질 을 향상시킬 수 있다. 비디오 처리부는 복수의 뉴럴 네트워크 모델들 중, 품질 점수에 따라 화질 처리 모 델을 선택하고 이에 따라 프레임/비디오의 품질을 향상시킬 수 있다. 또는 비디오 처리부는 점수에 따라 화질 처리 모델 적용 횟수를 결정하고, 결정된 횟수만큼 프레임에 화질 처리 모델을 반복하여 적용함으로써 프레임/비디오의 품질을 향상시킬 수 있다. 또는 비디오 처리부는 점수에 따라 필터를 설계하고, 이를 프레임/비디오에 적용하여 프레임/비디오의 품 질을 향상시킬 수 있다. 또는 비디오 처리부는 점수에 따라 하이퍼파라미터 값을 수정하고, 수정된 하이퍼파라미터 값을 갖는 뉴럴 네트워크를 이용하여 프레임의 품질을 향상시킬 수 있다. 디스플레이는 방송국으로부터 수신하거나 외부 서버, 또는 외부 저장 매체 등으로부터 수신한 콘텐츠를 화 면에 출력할 수 있다. 콘텐츠는 미디어 신호로, 비디오 신호, 이미지, 텍스트 신호 등을 포함할 수 있다. 또한 디스플레이는 HDMI 포트를 통해 수신한 비디오 신호나 이미지를 화면에 표시할 수 있다. 실시 예에서, 디스플레이는 비디오 처리부가 비디오나 프레임의 품질을 향상시킨 경우, 향상된 품질 의 비디오나 프레임을 출력할 수 있다. 디스플레이가 터치 스크린으로 구현되는 경우, 디스플레이는 출력 장치 이외에 입력 장치로 사용될 수 있다. 그리고, 사용자 디스플레이 장치의 구현 형태에 따라, 사용자 디스플레이 장치는 디스플레 이를 2개 이상 포함할 수 있다. 오디오 처리부는 오디오 데이터에 대한 처리를 수행한다. 오디오 처리부에서는 오디오 데이터에 대한 디코딩이나 증폭, 노이즈 필터링 등과 같은 다양한 처리가 수행될 수 있다. 오디오 출력부는 프로세서의 제어에 의해 튜너부를 통해 수신된 콘텐츠에 포함된 오디오, 통신 부 또는 입/출력부를 통해 입력되는 오디오, 메모리에 저장된 오디오를 출력할 수 있다. 오디오 출력부는 스피커, 헤드폰 출력 단자 또는 S/PDIF(Sony/Philips Digital Interface) 출력 단자 중 적어도 하나를 포함할 수 있다. 사용자 인터페이스는 사용자 디스플레이 장치를 제어하기 위한 사용자 입력을 수신할 수 있다. 실시 예에서, 사용자는 사용자 인터페이스를 통하여, 디스플레이의 스크린 설정 파라미터를 선택하고, 선택된 설정 파라미터 값을 변경할 수 있다. 사용자 인터페이스는 사용자의 터치를 감지하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용자 의 회전 조작을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch), 음성 인식을 위한 마이크, 모션 을 센싱하는 모션 감지 센서 등을 포함하는 다양한 형태의 사용자 입력 디바이스를 포함할 수 있으나 이에 제한 되지 않는다. 또한, 사용자 디스플레이 장치가 원격 제어 장치(remote controller)(미도시)에 의해서 조작 되는 경우, 사용자 인터페이스는 원격 제어 장치로부터 수신되는 제어 신호를 수신할 수도 있을 것이다. 도 8 내지 12는 실시 예에 따른 디스플레이 특성 정보를 설명하기 위한 도면이다. 도 8은 실시 예에 따른 스크린 모델 매핑 정보를 설명하기 위한 도면이다. 도 8을 참조하면, 좌측에는 평가자 디스플레이 장치가 도시되어 있고, 우측에는 사용자 디스플레이 장치 가 도시되어 있다. 복수의 평가자들은 평가자 디스플레이 장치를 이용하여 비디오를 시청하고 비디오 품질을 평가할 수 있다. 복수의 평가자들이 평가한 점수는 MOS로 환산되어 뉴럴 네트워크의 학습 데이터로 이용될 수 있다. 사용자 디스플레이 장치는 MOS를 학습한 뉴럴 네트워크를 이용하여, 비디오에 대해 모델 기반 품질 점수를 획득할 수 있다. 평가자 디스플레이 장치와 사용자 디스플레이 장치에 포함된 스크린은 서로 다른 모델일 수 있다. 스 크린은 모델 별로 화면 사이즈 또는 해상도가 다르므로, 평가자 디스플레이 장치에 포함된 스크린과 사용 자 디스플레이 장치에 포함된 스크린은 사이즈 및/또는 해상도가 서로 다를 수 있다. 사용자 디스플레이 장치와 평가자 디스플레이 장치의 스크린 사이즈가 다른 경우 동일한 비디오를 시 청하더라도 그에 대한 평가 점수는 달라질 수 있다. 일반적으로 화면 사이즈가 클수록 영상에 포함된 왜곡이 더 잘 보이게 되고, 화면 사이즈가 작을수록 왜곡이 덜 인식되기 때문이다. 또한, 동일한 스크린 사이즈를 통해 비디오를 시청하더라도 사용자 디스플레이 장치와 평가자 디스플레이 장치의 스크린 해상도가 다른 경우 평가 점수는 달라질 수 있다. 해상도가 클수록 스크린에 포함된 픽셀 수가 많아져 영상이 더 깨끗하게 보이게 되므로, 사람 눈이 왜곡을 더 민감하게 인식하기 때문이다. 따라서, 평가자 디스플레이 장치를 이용하여 획득한 점수를 학습 데이터로 이용하여 훈련한 뉴럴 네트워크 가 획득한 프레임의 품질 점수는 스크린의 사이즈 및/또는 해상도가 다른 사용자 디스플레이 장치에서 평 가하는 품질 점수와 다를 수 있다. 실시 예에서, 사용자 디스플레이 장치에는 평가자 디스플레이 장치의 모델과 사용자 디스플레이 장치 의 모델이 달라 발생하는 품질 평가 점수의 관계가 미리 저장되어 있을 수 있다. 즉, 사용자 디스플레이 장치를 제조하는 제조사는, 복수의 평가자들이 평가자 디스플레이 장치를 이용하여 비디오 품질 점수 를 산출하도록 하고, 또한 평가자 디스플레이 장치와는 다른 모델의 사용자 디스플레이 장치를 이용 하여 비디오의 품질 점수를 산출하도록 한 후, 평가자 디스플레이 장치에서의 품질 점수와 사용자 디스플레이 장치에서의 품질 점수 간의 관계를 매핑하는 스크린 모델 매핑 정보를 생성할 수 있다. 예컨대, 복수의 평가자들이 평가자 디스플레이 장치를 이용하여 비디오를 평가할 때의 평균 의견 점 수가 A이고, 복수의 평가자들이 평가자 디스플레이 장치와는 다른 모델을 갖는 사용자 디스플레이 장 치를 이용하여 동일한 비디오를 평가할 때의 평균 의견 점수가 B인 경우, 제조사는 평가자 디스플레이 장 치와 사용자 디스플레이 장치 간의 점수 관계, 즉, A와 B 간의 관련성을 스크린 모델 매핑 정보로 사 용자 디스플레이 장치에 저장할 수 있다. 제조사는 각각의 사용자 디스플레이 장치 모델 별로 동일한 방법을 수행하여, 평가자 디스플레이 장치와 각 모델 별 사용자 디스플레이 장치에서의 평가 점수를 연관 짓는 스크린 모델 매핑 정보를 생성하고 이를 각 모델의 디스플레이 장치에 저장할 수 있다. 스크린 모델 매핑 정보는, 스크린 모델에 따른 평균 의견 점수 간 관련성을 나타낸 것으로, 룩업 테이블, 매핑 테이블이거나 또는 매핑 함수 형태일 수 있다. 사용자 디스플레이 장치는 스크린 모델 매핑 정보를 이용하여 가중치를 획득하고 이를 모델 기반 품질 점 수에 적용함으로써 스크린 모델의 차이에 따른 품질 평가의 차이를 보상할 수 있다. 도 9는 실시 예에 따른 스크린 설정 매핑 정보를 설명하기 위한 도면이다. 사용자 디스플레이 장치와 평가자 디스플레이 장치의 스크린이 서로 같은 사양을 갖는 경우, 두 장치를 이용하 여 획득되는 품질 점수는 같을 수 있다. 그러나, 평가자 디스플레이 장치의 스크린 설정 파라미터 값과 사용자 디스플레이 장치의 스크린 설정 파라미터 값이 다른 값을 갖는 경우, 평가자 디스플레이 장치를 이용하여 획득 된 점수를 학습 데이터로 이용하여 훈련한 뉴럴 네트워크가 획득한 프레임의 품질 점수는 사용자 디스플레이 장 치에서 평가하는 품질 점수와 다를 수 있다. 또한, 전술한 바와 같이 사용자 디스플레이 장치와 평가자 디스플레이 장치의 스크린이 서로 다른 사양을 갖는 경우, 제조사는 스크린 모델 매핑 정보를 생성하기 위해 사용자 디스플레이 장치를 이용하여 비디오 품질 점수 를 획득하게 된다. 제조사는 사용자 디스플레이 장치의 스크린 설정 값을 디폴트 값으로 설정한 상태로 비디오 품질 점수를 획득할 수 있다. 이후, 사용자가 사용자 디스플레이 장치의 스크린 설정 값을 디폴트 값이 아닌 다 른 값으로 변경하여 이용하는 경우, 디폴트 값이 스크린 설정 파라미터 값을 갖는 사용자 디스플레이 장치에서 평가하는 품질 점수는 다를 수 있다. 도 9에는 사용자 디스플레이 장치의 스크린에 출력되는 OSD(On Screen Display) 메뉴가 도시되어 있다. 사 용자는 OSD 메뉴를 이용하여 스크린 설정 파라미터 값을 변경할 수 있다. 사용자는 복수의 스크린 설정 파 라미터들 중 원하는 파라미터를 선택하고, 선택된 파라미터의 값을 원하는 값으로 변경할 수 있다. 스크린 설정 파라미터는 사용자 디스플레이 장치의 스크린에 대한 밝기(brightness), 대조도(contrast), 감마 (gamma), 백라이트 밝기, 선명도(sharpness), 색상(color), 색조(tint) 중 적어도 하나를 포함할 수 있다. 스크린 설정 파라미터 값이 바뀌는 경우, 사용자가 보는 비디오는 화질 느낌이 달라질 수 있다. 이 경우, 변경 된 설정 파라미터 값을 갖는 스크린을 이용하여 평가한 품질 점수는, 설정 파라미터가 디폴트 값일 때 획득한 품질 점수와 서로 다를 수 있다. 예컨대, 사용자가 스크린 설정 파라미터 중 밝기의 값을 디폴트 값보다 더 어 두운 값으로 설정한 경우, 어두운 스크린을 통해 출력되는 비디오에서는 왜곡이 잘 보이지 않기 때문에 이 때의 비디오 평가 점수는 밝기 값이 디폴트 값일 때의 비디오 평가 점수보다 더 높아질 수 있다. 실시 예에서, 제조사는 평가자들이 동일한 모델을 갖는 사용자 디스플레이 장치를 이용하여 비디오 품질을 평가 할 때, 스크린 설정 파라미터가 디폴트 값으로 고정된 상태에서 품질을 평가하도록 할 수 있다. 또한, 제조사는 스크린 설정 파라미터가 디폴트 값이 아닌 다른 값을 갖도록 설정하고, 각각의 경우에 평가자가 품질을 평가하 도록 할 수 있다. 제조사는 이러한 파라미터 값의 차이에 따른 품질 평가 점수 차이를 매핑 함수나 매핑 테이블, 룩업 테이블 형태로 저장할 수 있다. 제조사는 각 파라미터 별로, 또한 동일한 파라미터에서도 그 파라미터의 설정 값들 별로, 각각 품질 점수를 획 득하고, 이로부터 디폴트 값과 다른 설정 값에 따른 평가 점수의 차이를 관련 짓는 스크린 설정 매핑 정보를 생 성하여 이를 사용자 디스플레이 장치에 저장할 수 있다. 도 10은 실시 예에 따른 스크린 모델 매핑 정보 중 스크린 사이즈를 설명하기 위한 도면이다. 스크린 모델 매핑 정보는 스크린 사이즈 및 스크린 사이즈에 따른 서브 영역 별 점수에 대한 정보를 포함할 수 있다. 도 10을 참조하면, 사용자 디스플레이 장치는 다양한 스크린 사이즈를 가질 수 있다. 도 10에는 세 개의 스크린 이 도시되어 있으며 제1 스크린부터 제2 스크린 및 제3 스크린 순서대로 사이즈가 작아진다. 일반적으로, 사람이 비디오를 볼 때 비디오에 포함된 왜곡을 인식하는 정도는 화면의 위치에 따라 달라질 수 있 다. 사람은 보통 화면의 중앙 부분을 가장자리 부분보다 더 많이 보는 경향이 있다. 따라서, 왜곡의 정도가 같 더라도 스크린의 중앙에 왜곡이 있는 경우와 스크린의 가장자리 부분에 왜곡이 있는 경우, 사람은 왜곡의 정도 를 다르게 인식하게 된다. 또한, 사람은 화면의 사이즈가 소정 크기 이상 큰 경우에는 중앙 부분을 위주로 보나, 화면의 사이즈가 크지 않 은 경우에는 전체 영역을 한꺼번에 보는 경향이 있다. 실시 예에서, 제조사는 사용자 디스플레이 장치에 스크린 정보를 저장할 때, 스크린 사이즈가 소정 크기 이상인 스크린에 대해서는 스크린 정보에 서브 영역 별 점수를 더 포함시킬 수 있다. 이를 위해, 제조사는 복수의 평가자들이 사용자 디스플레이 장치를 이용하여 비디오의 품질 점수를 산출할 때, 프레임의 각 서브 영역 별로 왜곡이 있는 비디오들을 출력할 수 있다. 즉, 제조사는 프레임의 아래 부분만 왜곡 이 포함된 비디오와 프레임의 왼쪽 부분만 왜곡이 포함된 비디오 등과 같이, 프레임, 또는, 스크린에 포함된 복 수의 서브 영역 각각에서만 왜곡이 포함된 비디오를 평가자에게 보여주고, 그에 따른 점수를 획득할 수 있다. 예컨대, 제조사는 도 10에 도시된 스크린 중 제2 스크린을 이용하여 비디오의 품질 점수를 산출할 때, 제 2 스크린을 아홉 개의 서브 영역으로 나누고, 각각 하나의 서브 영역에만 왜곡이 포함된 비디오들을 평가 자들에게 출력하고 이를 평가하도록 할 수 있다. 예를 들어, 아홉 개의 서브 영역 중 정 가운데 영역에서만 왜곡이 있는 비디오에 대해 평가자들로부터 획 득한 평가 점수가 1점이고, 왼쪽 가운데 영역에서만 동일한 왜곡이 있는 비디오에 대해 평가자들로부터 획득한 평가 점수가 4점이라고 가정한다. 이는 평가자들이 왼쪽 가운데 영역보다는 정 가운데 영역(102 1)을 더 많이 본다는 것을 의미할 수 있다. 제조사는 이를 고려하여, 왼쪽 가운데 영역에 대해서는 서브 영역 점수 0.2를 부여하고, 정 가운데 영역에는 서브 영역 점수 0.8를 부여하여, 스크린의 각 서브 영역 이 비디오 품질 평가에 영향을 주는 정도를 구할 수 있다. 제조사는 스크린의 서브 영역 각각에 대해 각 영역이 비디오 품질 평가에 영향을 주는 정도를 나타내는 서브 영역 별 점수를 생성하고 이를 스크린 정보에 포함시켜 저장할 수 있다. 화면 사이즈가 큰 경우와 달리, 화면 사이즈가 소정 크기보다 작은 경우, 예컨대, 도 10에 도시된 스크린 중 태 블릿 크기의 화면을 갖는 제3 스크린의 경우, 사용자는 화면 전체의 영역에 대해 거의 비슷한 정도로 왜 곡을 인식하게 된다. 이 경우, 제조사는 스크린 정보에 스크린에 포함된 서브 영역 별 점수를 별도로 포함시키 지 않을 수 있다. 즉, 실시 예에서, 스크린 정보는 스크린 사이즈가 소정 크기 이상인 경우에만 스크린 정보에 서브 영역 별 점수를 더 포함할 수 있다. 예컨대, 제조사는 태블릿이나 핸드폰의 스크린과 같이, 스크린 사이즈 가 소정 크기보다 작은 경우, 스크린 정보에, 화면 전체에 대한 하나의 점수만을 포함시키고, 서브 영역 별 점 수를 포함시키지 않을 수 있다. 도 11은 실시 예에 따른 환경 정보를 설명하기 위한 도면이다. 실시 예에서, 환경 정보는 사용자의 시청 위치 정보를 포함할 수 있다. 비디오를 평가할 때의 평가자 위치는 실제 사용자 디스플레이 장치를 시청할 때의 사용자의 위치와 동일 할 수도 있지만 동일하지 않을 수도 있다. 평가자의 위치와 사용자의 위치가 다른 경우, 평가자 디스플레이 장치를 시청 할 때의 평가자의 시청 앵 글 및/또는 평가자와 평가자 디스플레이 장치 간의 거리 등은, 사용자 디스플레이 장치를 시청 할 때의 사용자의 시청 앵글 및/또는 사용자와 사용자 디스플레이 장치 간의 거리 등과 달라지게 된다. 이 경우, 평가자와 사용자가 화면에서 중요하게 보는 영역이 서로 달라지게 되어 동일 비디오에 대한 품질 점수에 영향을 미치게 된다. 시청 앵글은, 예컨대, 평가자와 평가자 디스플레이 장치의 중심을 잇는 가상의 선을 기준으로, 평가자와 평가자 디스플레이 장치가 이루는 방위각(azimuth)이나 고도각(elevation angle) 중 적어도 하나를 포함할 수 있다.실시 예에서, 사용자 디스플레이 장치에는 평가자가 비디오를 평가할 때의 평가 위치와 사용자가 실제 사 용자 디스플레이 장치를 시청할 때의 위치 차이에 따른 품질 평가 점수의 관계를 나타내는 정보가 미리 저장되어 있을 수 있다. 이를 위해, 제조사는 평가자들이 비디오를 평가할 때, 다양한 위치에서 비디오를 평가 하도록 할 수 있다. 예컨대, 도 11에 도시된 바와 같이, 제조사는 평가자들이 각각 제1 위치, 제2 위치 , 제3 위치에서 동일한 비디오를 시청하고 비디오 품질을 평가하도록 할 수 있다. 다만, 이는 설명 의 편의를 위한 것으로, 제조사는 평가자들이 평가자 디스플레이 장치로부터 더 멀리 떨어진 위치나 더 가까운 위치, 평가자 디스플레이 장치보다 더 높은 위치나 더 낮은 위치 등에서도 비디오 품질을 평가하 도록 할 수 있다. 제조사는 평가자들의 평가 위치 별로 비디오 평가 점수를 획득할 수 있다. 제조사는 평가 위치와 평가 점수 간 의 관련성을 나타내는 룩업 테이블이나 매핑 함수 등을 생성하고, 이를 사용자 디스플레이 장치에 미리 저장할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 사용자의 위치에 대한 정보를 획득할 수 있다. 실시 예에서, 사 용자 디스플레이 장치에는 사용자의 위치를 센싱하는 센서를 포함할 수 있다. 센서는 카메라 를 이용하여 사용자의 이미지를 실시간으로 획득하여 사용자의 위치를 파악할 수 있다. 센서는 UWB(Ultra-wideband) 모듈 등을 이용하여 복수의 안테나로 사용자의 생체 신호를 획득하고 이로부 터 사용자의 위치를 파악할 수 있다. 기타, 센서는 다양한 방법으로 사용자의 홍채 움직임 등을 파악하고, 이를 통해 사용자의 시청 각도 등을 감지할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 사용자의 위치가 룩업 테이블에 기 저장되어 있는 평가자들의 평 가 위치 중 어느 위치와 가장 근접한지를 판단할 수 있다. 예컨대, 도 11에서, 사용자 디스플레이 장치는 사용자의 현재 위치가 평가자들의 평가 위치 중 제2 위치와 유사하다고 판단할 수 있다. 사용자 디 스플레이 장치는 제2 위치에 대응하여 저장된 평가 점수를 고려하여 가중치를 획득하고 이를 모델 기반 품질 점수에 적용함으로써 평가 위치의 차이에 따른 품질 평가의 차이를 보상할 수 있다. 도 12는 실시 예에 따른 환경 정보를 설명하기 위한 도면이다. 실시 예에서, 환경 정보는 사용자 디스플레이 장치 주변 밝기 정보를 포함할 수 있다. 평가자가 비디오를 평가할 때 그 주변의 밝기는 실제 사용자가 화면을 시청할 때의 사용자 주변의 밝기와 동일 할 수도 있지만 동일하지 않을 수도 있다. 도 12에 도시된 바와 같이, 평가자 디스플레이 장치가 위치하는 곳의 주변 밝기는 사용자 디스플레 이 장치가 위치하는 곳의 사용자 주변의 밝기와 다를 수 있다. 평가자 주변의 밝기와 사용자 주변의 밝기가 다른 경우, 평가자와 사용자가 인식하는 품질 점수는 달라질 수 있다. 예컨대, 평가자가 영화관과 같이 어두운 환경에서 비디오를 평가하여 품질 점수를 매긴 경우, 평가자는 어두운 주변 환경에 비해 상대적으로 더 밝게 인식되는 스크린을 통해 비디오의 왜곡 또한 더 잘 인식할 수 있다. 이 경우, 평가자가 평가한 품질 점수는 밝은 환경에서 비디오를 시청하는 사용자가 느끼는 품질 점수와 동일하지 않을 수 있다. 실시 예에서, 제조사는 평가자들이 비디오를 평가할 때 주변의 밝기를 단계 별로 변경할 수 있다. 제조사는 다 양한 주변 밝기 하에서 평가자들이 각각 비디오를 평가하도록 하고, 주변 밝기 별로 비디오 평가 점수를 획득할 수 있다. 제조사는 주변 밝기에 따른 품질 점수의 관련성을 나타내는 룩업 테이블이나 매핑 함수 등을 생성하고 이를 사용자 디스플레이 장치에 미리 저장시킬 수 있다. 실시 예에서, 사용자 디스플레이 장치는 사용자 주변의 밝기에 대한 정보를 획득할 수 있다. 실시 예에서, 사용자 디스플레이 장치에는 사용자 주변의 밝기를 센싱하는 센서를 이용할 수 있다. 센서는 예컨대 조도 센서일 수 있다. 사용자 디스플레이 장치는 조도 센서를 이용하여 사용자 주변 의 밝기를 감지할 수 있다. 조도 센서는 주변의 빛의 양을 측정하여 빛의 양에 따라 밝기를 측정하는 센 서로, RGB 센서(illuminance sensor)나 포토 센서(Photo Resistor) 등을 포함할 수 있다. 실시 예에서, 사용자 디스플레이 장치는 룩업 테이블에서 사용자 주변의 밝기와 가장 근접한 밝기 를 식별할 수 있다. 사용자 디스플레이 장치는 사용자 주변의 밝기와 가장 근접한 밝기에 대응하여 저장된 평가 점수를 고려하여 가중치를 획득하고 이를 모델 기반 품질 점수에 적용함으로써 주변 밝기의 차이에 따른 품질 평가의 차이를 보상할 수 있다. 도 13은 실시 예에 따른 비디오 품질 평가 방법을 도시한 순서도이다. 도 13을 참조하면, 비디오 품질 평가 장치는 비디오 프레임 및 오디오 프레임을 고려하여, 오디오 기반 세일리 언시 맵을 획득할 수 있다(단계 1310). 즉, 비디오 품질 평가 장치는 비디오 프레임과 동기화되어 함께 출력되 는 오디오 프레임을 고려하여, 비디오 프레임에서 시청자의 관심을 끄는 영역이 어디인가를 파악할 수 있다. 비디오 품질 평가 장치는 오디오 기반 세일리언시 맵을 고려하여, 비디오 프레임에 대한 제1 품질 점수를 획득 할 수 있다(단계 1320). 제1 품질 점수는 비디오 프레임과 오디오 프레임이 함께 고려될 때 사용자의 주의를 끄는 오디오 기반 세일리언 시 영역을 반영하여 획득되는 비디오 프레임에 대한 품질 점수일 수 있다. 비디오 품질 평가 장치는 비디오 프 레임에 대해 품질 평가 점수를 획득할 때, 비디오 프레임뿐 아니라 오디오 기반 세일리언시 맵을 함께 고려함으 로써 오디오 기반 세일리언시 영역을 고려한 품질 점수를 획득할 수 있다. 또한, 비디오 품질 평가 장치는 오디오 프레임 고려 없이, 비디오 프레임에 대한 제2 품질 점수를 획득할 수 있 다(단계 1330). 제2 품질 점수는 오디오에 대한 고려나, 사용자의 관심 영역에 대한 고려 없이, 비디오 프레임 전체에 대한 품 질 평가를 통해 획득될 수 있다. 비디오 품질 평가 장치는 제1 품질 점수 및 제2 품질 점수에 기반하여, 최종 품질 점수를 획득할 수 있다(단계 1340). 도 14는 실시 예에 따라, 오디오 기반 세일리언시 맵을 획득하는 과정을 도시한 순서도이다. 도 14를 참조하면, 비디오 품질 평가 장치는 비주얼 세일리언시 맵을 먼저 획득할 수 있다(단계 1410). 비디오 품질 평가 장치는 오디오 프레임 없이 비디오 프레임만을 기반으로, 비디오 프레임에서 시청자의 주의를 끄는 세일리언시 영역을 나타내는 비주얼 세일리언시 맵을 획득할 수 있다. 비주얼 세일리언시 맵은, 오디오에 대한 고려 없이, 비디오 프레임만을 보고 획득된 세일리언시 맵을 의미할 수 있다. 예컨대, 비디오 품질 평가 장치는 제1 뉴럴 네트워크를 이용하여, 비디오 프레임으로부터 다양한 특징들을 획득 하고 이를 기반으로 비주얼 세일리언시 맵을 획득할 수 있다. 비디오 품질 평가 장치는 비주얼 세일리언시 맵과 오디오 프레임을 함께 고려하여, 오디오 기반 세일리언시 맵 을 획득할 수 있다(단계 1420). 예컨대, 비디오 품질 평가 장치는 제2 뉴럴 네트워크를 이용하여, 오디오 프레임 및 제1 뉴럴 네트워크가 획득 한 비주얼 세일리언시 맵을 입력 받고, 그로부터 비디오와 오디오를 함께 고려할 때의 시청자의 관심을 끄는 영 역을 표현하는 오디오 기반 세일리언시 맵을 의미할 수 있다. 실시 예에서, 비디오 품질 평가 장치가 이용하는 제2 뉴럴 네트워크는 오디오 신호를 고려할 때와 오디오 신호 를 고려하지 않을 때 동일한 비디오에 대한 세일리언시 영역의 차이를 미리 학습한 뉴럴 네트워크일 수 있다. 또한, 제2 뉴럴 네트워크는 오디오 신호의 특성에 따라 달라지는 오디오 기반 세일리언시 영역을 학습한 뉴럴 네트워크일 수 있다. 도 15는 실시 예에 따라, 가중치를 획득하는 과정을 도시한 순서도이다. 도 15를 참조하면, 비디오 품질 평가 장치는 오디오 기반 세일리언시 맵의 통계학적 특성으로부터 제1 가중치를 획득할 수 있다(단계 1510). 오디오 기반 세일리언시 맵의 통계학적 특성은 오디오 기반 세일리언시 맵에 포함된 세일리언시 영역에 대한 특 성으로, 오디오 기반 세일리언시 영역이 전체 비디오 프레임에 포함된 비율, 세일리언시 영역의 산포도, 세일리 언시 영역의 중심 경향치 중 적어도 하나를 포함할 수 있다. 비디오 품질 평가 장치는 디스플레이 장치의 특성 정보로부터 제2 가중치를 획득할 수 있다(단계 1520). 디스플 레이 장치의 특성 정보는, 스크린 모델 매핑 정보, 스크린 설정 매핑 정보, 및 환경 정보 중 적어도 하나를 포함할 수 있다. 스크린 모델 매핑 정보는 평가자 디스플레이 장치의 스크린 모델과 사용자 디스플레이 장치의 스크린 모델 차이 에 따른 점수 관계를 포함하고, 스크린 모델 차이는 스크린 사이즈 및 스크린 해상도 중 적어도 하나의 차이를 의미할 수 있다. 스크린 설정 매핑 정보는 사용자 디스플레이 장치의 스크린에 대한 디폴트 설정 값과 사용자로부터 선택된 설정 값의 차이에 따른 점수 관계를 나타내고, 설정 값은 스크린의 밝기(brightness), 대조도(contrast), 감마 (gamma), 백라이트 밝기, 선명도(sharpness), 색상(Color), 색조(tint) 중 적어도 하나에 대한 값을 포함할 수 있다. 환경 정보는 주변 밝기 정보 및 시청 위치 정보 중 적어도 하나를 포함할 수 있다. 주변 밝기 정보는 사용자 디 스플레이 장치 주변 밝기와 평가자 디스플레이 장치 주변 밝기 간의 관계를 포함하고, 시청 위치 정보는 사용자 의 시청 위치 및 평가자의 시청 위치 간의 관계를 포함할 수 있다. 시청 위치는 디스플레이 장치와의 거리, 방 위각, 및 고도각 중 적어도 하나를 포함할 수 있다. 비디오 품질 평가 장치는 제1 가중치 및 제2 가중치로부터 최종 가중치를 획득할 수 있다(단계 1530). 예컨대, 비디오 품질 평가 장치는 제1 가중치와 제2 가중치를 곱하여, 최종 가중치를 획득할 수 있다. 비디오 품질 평가 장치는 최종 가중치를 제1 품질 점수와 제2 품질 점수에 적용함으로써, 비디오 프레임에 대한 최종 품질 점수를 획득할 수 있다. 일부 실시 예에 따른 오디오의 존재 및 비존재에 따른 비디오 품질 평가 방법 및 장치는 컴퓨터에 의해 실행되 는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비 휘발성 매체, 분리형 및 비 분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비 휘발성, 분리형 및 비 분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전 달 매체를 포함한다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 또한, 전술한 본 개시의 실시 예에 따른 오디오의 존재 및 비존재에 따른 비디오 품질 평가 방법 및 장치는 비 디오 프레임 및 상기 비디오 프레임과 함께 출력되는 오디오 프레임을 기반으로, 상기 비디오 프레임에 대한 제 1 품질 점수를 획득하는 단계, 상기 오디오 프레임 없이 상기 비디오 프레임을 기반으로, 상기 비디오 프레임에 대한 제2 품질 점수를 획득하는 단계 및 상기 제1 품질 점수 및 상기 제2 품질 점수로부터 상기 비디오 프레임 에 대한 최종 품질 점수를 획득하는 단계를 포함하는, 비디오 품질 평가 장치에서 수행하는 비디오 품질 평가 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체를 포함하는 컴퓨터 프로그램 제품으 로 구현될 수 있다."}
{"patent_id": "10-2021-0020690", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 설명은 예시를 위한 것이며, 발명이 속하는 기술분야의 통상의 지식을 가진 자는 발명의 기술적 사상이 나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한 다. 예를 들어, 단일 형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15"}
{"patent_id": "10-2021-0020690", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시 예에 따라, 사용자 디스플레이 장치가 비디오 영상의 품질 점수를 획득하고, 이에 따라 처리 된 화질을 갖는 영상을 화면에 출력하는 것을 설명하기 위한 도면이다. 도 2는 실시 예에 따른 비디오 품질 평가 장치의 내부 블록도이다. 도 3은 실시 예에 따른, 도2의 프로세서의 내부 블록도이다. 도 4는 실시 예에 따른, 도 3의 제1 품질 점수 획득부의 내부 블록도이다. 도 5는 실시 예에 따른, 도 3의 최종 품질 점수 획득부의 내부 블록도이다.도 6은 실시 예에 따라 오디오 기반 세일리언시 맵으로부터 제1 가중치를 획득하는 것을 설명하기 위한 도면이 다. 도 7은 실시 예에 따른 사용자 디스플레이 장치의 내부 블록도이다. 도 8은 실시 예에 따른 스크린 모델 매핑 정보를 설명하기 위한 도면이다. 도 9는 실시 예에 따른 스크린 설정 매핑 정보를 설명하기 위한 도면이다. 도 10은 실시 예에 따른 스크린 모델 매핑 정보 중 스크린 사이즈를 설명하기 위한 도면이다. 도 11은 실시 예에 따른 환경 정보를 설명하기 위한 도면이다. 도 12는 실시 예에 따른 환경 정보를 설명하기 위한 도면이다. 도 13은 실시 예에 따른 비디오 품질 평가 방법을 도시한 순서도이다. 도 14는 실시 예에 따라, 오디오 기반 세일리언시 맵을 획득하는 과정을 도시한 순서도이다. 도 15는 실시 예에 따라, 가중치를 획득하는 과정을 도시한 순서도이다."}
