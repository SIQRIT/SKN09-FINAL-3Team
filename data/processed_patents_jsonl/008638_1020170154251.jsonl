{"patent_id": "10-2017-0154251", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0056880", "출원번호": "10-2017-0154251", "발명의 명칭": "진단 영상을 변환하기 위한 장치, 이를 위한 방법 및 이 방법을 수행하는 프로그램이 기록된", "출원인": "안영샘", "발명자": "김성빈"}}
{"patent_id": "10-2017-0154251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "진단 영상을 변환하기 위한 장치에 있어서, CT 영상이 입력되면, 상기 CT 영상이 촬영된 단층의 위치에 따라 복수의 분류 중 어느 하나의 분류로 상기 CT영상을 분류하는 분류부; 및 상기 분류에 따라 미리 학습된 인공신경망을 통해 상기 CT 영상을 MRI 영상으로 변환하는 변환부;를 포함하는것을 특징으로 하는 진단 영상을 변환하기 위한 장치."}
{"patent_id": "10-2017-0154251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 변환부는 학습 데이터인 CT 영상이 입력되면, 복수의 연산을 수행하여 MRI 영상을 생성하는 MRI 생성자; 학습 데이터인 MRI 영상이 입력되면, 복수의 연산을 수행하여 CT 영상을 생성하는 한다. CT 생성자; 상기 MRI 생성자가 생성한 MRI 영상과 학습 데이터인 MRI 영상을 포함하는 영상이 입력되면, 복수의 연산을 수행하여 입력된 영상이 MRI 영상일 확률과 MRI 영상이 아닐 확률을 출력하는 MRI 판별자; 상기 CT 생성자가 생성한 CT 영상과 학습 데이터인 CT 영상을 포함하는 영상이 입력되면, 복수의 연산을 수행하여 입력된 영상이 CT 영상일 확률과 CT 영상이 아닐 확률을 출력하는 CT 판별자; 상기 MRI 영상일 확률과 MRI 영상이 아닐 확률의 기대치와 출력치의 차이인 확률 손실을 산출하는 MRI 확률손실측정자; 상기 CT 영상일 확률과 CT 영상이 아닐 확률의 기대치와 출력치의 차이인 확률 손실을 산출하는 CT 확률손실측정자; 상기 MRI 생성자가 생성한 MRI 영상과 학습 데이터인 MRI 영상의 차이인 기준 손실을 산출하는 MRI 기준손실측정자; 및 상기 CT 생성자가 생성한 CT 영상과 학습 데이터인 CT 영상의 차이인 기준 손실을 산출하는 CT 기준손실측정자;를 포함하는 것을 특징으로 하는 진단 영상을 변환하기 위한 장치."}
{"patent_id": "10-2017-0154251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 변환부는 상기 확률 손실 및 상기 기준 손실이 최소가 되도록 역전파(back-propagation) 알고리즘을 통해 상기 MRI 생성자, CT 생성자, MRI 판별자 및 CT 판별자에 포함된 복수의 연산의 가중치를 수정하는 것을 특징으로 하는 진단영상을 변환하기 위한 장치."}
{"patent_id": "10-2017-0154251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 분류부는 뇌의 최상단부터 뇌의 최하단까지 단층 촬영된 영상에서 뇌의 최상단부터 안구가 나타나기 이전까지 영상을 제1층 영상으로 구분하고, 안구가 나타나기 시작한 영상부터 측뇌실이 나타나기 이전까지 영상을 제2층 영상으로 구분하고, 공개특허 10-2019-0056880-3-측뇌실이 나타나기 시작한 영상부터 뇌실이 사라지기 전까지 영상을 제3층 영상으로 구분하고, 뇌실이 사라진 후 뇌의 최하단까지의 영상을 제4층 영상으로 구분하는 것을 특징으로 하는 진단 영상을 변환하기 위한 장치."}
{"patent_id": "10-2017-0154251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 변환된 MRI 영상이 CT 영상일 확률과 MRI 영상일 확률을 출력하는 평가부;를 더 포함하는 것을 특징으로하는 진단 영상을 변환하기 위한 장치."}
{"patent_id": "10-2017-0154251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "진단 영상을 변환하기 위한 방법에 있어서, CT 영상이 입력되면, 상기 CT 영상이 촬영된 단층의 위치에 따라 복수의 분류 중 어느 하나의 분류로 상기 CT영상을 분류하는 단계; 및 상기 분류에 따라 미리 학습된 인공신경망을 통해 상기 CT 영상을 MRI 영상으로 변환하는 단계;를 포함하는 것을 특징으로 하는 진단 영상을 변환하기 위한 방법."}
{"patent_id": "10-2017-0154251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 따른 진단 영상을 변환하기 위한 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2017-0154251", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 진단 영상을 변환하기 위한 장치, 이를 위한 방법 및 이 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록매체에 관한 것으로, 이러한 본 발명은 CT 영상이 입력되면, 상기 CT 영상이 촬영된 단층의 위 치에 따라 복수의 분류 중 어느 하나의 분류로 상기 CT 영상을 분류하는 분류부와, 상기 분류에 따라 미리 학습 된 인공신경망을 통해 상기 CT 영상을 MRI 영상으로 변환하는 변환부를 포함하는 것을 특징으로 하는 진단 영상 을 변환하기 위한 장치와, 이를 위한 방법 및 이 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록매 체를 제공한다."}
{"patent_id": "10-2017-0154251", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 진단 영상 기술에 관한 것으로, 보다 상세하게는, 진단 영상을 이종의 진단 영상으로 변환하기 위한 장치, 이를 위한 방법 및 이 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록매체에 관한 것이다."}
{"patent_id": "10-2017-0154251", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "진단 영상 기술은 의료 분과의 하나로, 초음파, CT, MRI 등을 이용하여 병을 진단하고 치료하는 임상의학이자 진료보조분과이다. 인공지능의 발전 덕택에 의료영상의 완전 자동화된 분석이 가능해졌는데 연구에 따라 다르지 만 대개 프로그램들이 일반 전문의보다 낮은 오진율을 보이고 있다. 하지만, CT 및 MRI는 서로 유사해 보이지만 다른 특징을 가지고 있다. 예컨대, 환자가 뇌 질환으로 쓰러질 시, 뇌 출혈과 뇌 경색을 구분하기 위해 CT촬영을 하게 된다. 이후, 정확한 질환 부위를 정확히 파악하고, 치료 선 택 및 예후 관찰을 위해 MRI 촬영을 하게 된다. CT는 가격이 저렴하고 빠르지만 보기 힘든 질환이 있으며, MRI 는 가격이 비싸고 느리지만 더 많은 것을 볼 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제2017-0085756호 2017년 07월 25일 공개 (명칭: MRI와 CT를 결합한 MRCT 진단 장치)"}
{"patent_id": "10-2017-0154251", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 MRI 영상을 얻기 위한 비용과 시간을 감소시키기 위해 CT로부터 MRI 영상을 얻을 수 있는 진 단 영상을 변환하기 위한 장치, 이를 위한 방법 및 이 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록매체를 제공함에 있다."}
{"patent_id": "10-2017-0154251", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 바와 같은 목적을 달성하기 위한 본 발명의 바람직한 실시예에 따른 진단 영상을 변환하기 위한 장치는 CT 영상이 입력되면, 상기 CT 영상이 촬영된 단층의 위치에 따라 복수의 분류 중 어느 하나의 분류로 상기 CT 영상을 분류하는 분류부와, 상기 분류에 따라 미리 학습된 인공신경망을 통해 상기 CT 영상을 MRI 영상으로 변 환하는 변환부를 포함한다. 상기 변환부는 학습 데이터인 CT 영상이 입력되면, 복수의 연산을 수행하여 MRI 영상을 생성하는 MRI 생성자와, 학습 데이터인 MRI 영상이 입력되면, 복수의 연산을 수행하여 CT 영상을 생성하는 한다. CT 생성자와, 상기 MRI 생성자가 생성한 MRI 영상과 학습 데이터인 MRI 영상을 포함하는 영상이 입력되면, 복수의 연산을 수행하여 입 력된 영상이 MRI 영상일 확률과 MRI 영상이 아닐 확률을 출력하는 MRI 판별자와, 상기 CT 생성자가 생성한 CT 영상과 학습 데이터인 CT 영상을 포함하는 영상이 입력되면, 복수의 연산을 수행하여 입력된 영상이 CT 영상일 확률과 CT 영상이 아닐 확률을 출력하는 CT 판별자와, 상기 MRI 영상일 확률과 MRI 영상이 아닐 확률의 출력치 와 기대치의 차이인 확률 손실을 산출하는 MRI 확률손실측정자와, 상기 CT 영상일 확률과 CT 영상이 아닐 확률 의 출력치와 기대치의 차이인 확률 손실을 산출하는 CT 확률손실측정자와, 상기 MRI 생성자가 생성한 MRI 영상 과 학습 데이터인 MRI 영상의 차이인 기준 손실을 산출하는 MRI 기준손실측정자와, 상기 CT 생성자가 생성한 CT 영상과 학습 데이터인 CT 영상의 차이인 기준 손실을 산출하는 CT 기준손실측정자를 포함하는 것을 특징으로 한 다. 상기 변환부는 상기 확률 손실 및 상기 기준 손실이 최소가 되도록 역전파(back-propagation) 알고리즘을 통해 상기 MRI 생성자, CT 생성자, MRI 판별자 및 CT 판별자에 포함된 복수의 연산의 가중치를 수정하는 것을 특징으 로 한다. 상기 분류부는 뇌의 최상단부터 뇌의 최하단까지 단층 촬영된 영상에서 뇌의 최상단부터 안구가 나타나기 이전 까지 영상을 제1층 영상으로 구분하고, 안구가 나타나기 시작한 영상부터 측뇌실이 나타나기 이전까지 영상을 제2층 영상으로 구분하고, 측뇌실이 나타나기 시작한 영상부터 뇌실이 사라지기 전까지 영상을 제3층 영상으로 구분하고, 뇌실이 사라진 후 뇌의 최하단까지의 영상을 제4층 영상으로 구분하는 것을 특징으로 한다. 본 발명의 실시예에 따른 진단 영상을 변환하기 위한 장치는 상기 변환된 MRI 영상이 CT 영상일 확률과 MRI 영 상일 확률을 출력하는 평가부를 더 포함한다. 상술한 바와 같은 목적을 달성하기 위한 본 발명의 바람직한 실시예에 따른 진단 영상을 변환하기 위한 방법은 CT 영상이 입력되면, 상기 CT 영상이 촬영된 단층의 위치에 따라 복수의 분류 중 어느 하나의 분류로 상기 CT 영상을 분류하는 단계와, 상기 분류에 따라 미리 학습된 인공신경망을 통해 상기 CT 영상을 MRI 영상으로 변환 하는 단계를 포함한다. 또한, 전술한 본 발명의 바람직한 실시예에 따른 진단 영상을 변환하기 위한 방법을 수행하는 프로그램이 기록 된 컴퓨터 판독 가능한 기록매체를 제공한다."}
{"patent_id": "10-2017-0154251", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 인공신경망을 이용하여 CT로부터 MRI 영상을 얻을 수 있어 MRI 영상을 얻기 위한 비용과 시 간을 감소시킬 수 있다."}
{"patent_id": "10-2017-0154251", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 상세한 설명에 앞서, 이하에서 설명되는 본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거 나 사전적인 의미로 한정해서 해석되어서는 아니 되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명 하기 위해 용어의 개념으로 적절하게 정의할 수 있다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의 미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시예와 도면에 도시된 구성은 본 발명의 가장 바람직한 실시예에 불과할 뿐, 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원시점에 있어서 이들을 대체할 수 있는 다양한 균등물과 변형 예들이 있을 수 있음을 이해하여야 한다. 이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예들을 상세히 설명한다. 이때, 첨부된 도면에서 동일한 구성 요소는 가능한 동일한 부호로 나타내고 있음을 유의해야 한다. 또한, 본 발명의 요지를 흐리게 할 수 있는 공지 기능 및 구성에 대한 상세한 설명은 생략할 것이다. 마찬가지의 이유로 첨부 도면에 있어서 일부 구성요소 는 과장되거나 생략되거나 또는 개략적으로 도시되었으며, 각 구성요소의 크기는 실제 크기를 전적으로 반영하 는 것이 아니다. 먼저, 본 발명의 실시예에 따른 진단 영상을 변환하기 위한 장치의 구성에 대해서 설명하기로 한다. 도 1은 본 발명의 실시예에 따른 진단 영상을 변환하기 위한 장치의 구성을 설명하기 위한 블록도이다. 도 2는 도 1의 진 단 영상을 변환하기 위한 장치 중 분류부의 동작을 설명하기 위한 블록도이다. 도 3은 진단 영상을 변환하기 위 한 장치 중 분류부가 분류하는 영상의 일례를 설명하기 위한 도면이다. 도 4 및 도 5는 본 발명의 실시예에 따 른 진단 영상을 변환하기 위한 장치 중 변환부의 세부구성을 설명하기 위한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 진단 영상 변환 장치는 기본적으로, 뇌를 촬영한 CT 영상을 MRI 영 상으로 변환하여 제공한다. 이러한 진단 영상 변환 장치는 전처리부, 분류부, 변환부, 후처리부 및 평가부를 포함한다. 전처리부는 CT 영상을 입력 받고, 입력 받은 CT 영상에 대한 전처리를 수행하여 분류부에 제공한다. 여기서, 전처리는 정규화(Normalization), 회색조변환(Gray scaling) 및 크기조절(Resize)를 포함한다. 예컨대, 전처리부는 다음의 수학식 1과 같이 입력된 CT 영상의 각 픽셀값을 다음과 같이 최대최소 정규화 (Min-Max Normalization)를 수행하여 기 설정된 범위 내이 픽셀값으로 변환한다. 수학식 1"}
{"patent_id": "10-2017-0154251", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, v는 입력된 CT 영상의 픽셀값이며, v'는 픽셀값 v를 정규화한 픽셀값이다. 또한, min_a 및 max_a는 입 력된 CT의 최소 및 최대 픽셀값이며, min_b 및 max_b는 정규화하고자 하는 범위의 최소 및 최대 픽셀값이다. 정 규화 후, 전처리부는 CT 영상의 영상 채널 수를 1로 조정하는 회색조변환(Gray scaling)을 수행한다. 그런 다음, 전처리부는 CT 영상의 크기를 기 설정된 크기로 조절(Resize)한다. 예컨대, 전처리부는 CT 영 상의 크기를 256ㅧ256ㅧ1 크기로 조절할 수 있다. 분류부는 입력된 CT 영상을 기 설정된 4개의 분류 중 어느 하나의 분류로 분류한다. 뇌 CT 영상은 CT 촬영 의 대상인 피검자가 누운 상태에서 뇌의 수직 단면을 촬영한다. 본 발명의 실시예에 따르면, 뇌의 단면을 안구 부분이 속하는지 여부 및 측뇌실 및 뇌실(ventricle)이 속하는지 여부에 따라 4개의 층으로 구분한다. 이에 따 라, 분류부는 뇌의 최상단부터 뇌의 최하단까지 단층 촬영된 영상에서 안구 부분이 속하는지 여부 및 측뇌 실 및 뇌실(ventricle)이 속하는지 여부에 따라 4개의 층으로 구분한다. 도 3을 참조하여 보다 자세히 설명하면 다음과 같다. 도 3의 m1은 제1층 영상의 일례이다. 분류부는 뇌의 최상단부터 안구가 나타나기 이전까지 영상을 제1층 영상(m1)으로 구분할 수 있다. 이와 같이, 제1층 영상(m1)은 뇌의 최상단부터 순차적으로 뇌의 안구 부분이 보 이기 전까지 촬영된 영상으로, a1 부분을 살펴보면, 뇌의 안구 부분이 전혀 보이지 않는다. 도 3의 m2는 제2층 영상의 일례이다. 분류부는 안구가 나타나기 시작한 영상부터 측뇌실이 나타나기 이전 까지 영상을 제2층 영상(m2)으로 구분한다. 제2층 영상(m2)은 영상에서 a2 부분에 보인 바와 같이, 안구가 보이기 시작한 후부터 b1 부분에 보인 바와 같이, 측뇌실(Lateral ventricle)이 보이기 전까지의 영상이기 때문에 영상에서 안구 부분 존재하며, 측뇌실은 보이지 않는다. 도 3의 m3은 제3층 영상의 일례이다. 분류부는 측뇌실이 나타나기 시작한 영상부터 뇌실이 사라지기 전까 지 영상을 제3층 영상(m3)으로 구분한다. 이와 같이, 제3층 영상(m3)은 측뇌실이 보이기 시작한 후부터 뇌실이 사라지기 전까지의 영상이기 때문에 영상 내에 측뇌실 혹은 뇌실이 존재한다. 도 3의 m4는 제4층 영상의 일례이다. 분류부는 뇌실이 사라진 후 뇌의 최하단까지의 영상을 제4층 영상 (m4)으로 구분한다. 이와 같이, 제4층영상은 뇌실이 사라진 후, 뇌의 최하단까지의 영상으로 영상 내에 측뇌실 혹은 뇌실이 존재하지 않는다. 한편, 도 3에서는 CT 영상을 예시하였다. 하지만, 본 발명에서 사용되는 MRI 영상 또한 CT 영상과 마찬가지로 전술한 분류에 따라 구분될 수 있다. 분류부는 인공신경망(artificial neural network)을 포함한다. 이러한 인공신경망은 CNN(convolutional neural network)이 될 수 있다. 이에 따라, 분류부는 제1층 내지 제4층 영상(m1, m2, m3, m4)을 학습 데 이터로 하여 제1층 내지 제4층 영상(m1, m2, m3, m4)을 학습할 수 있다. 이에 따라, 분류부는 CT 영상이 입력되면, 해당 CT 영상을 각 층 영상(m1, m2, m3, m4)으로 구분할 수 있다. 도 2에 도시된 바와 같이, 변환부는 제1 내지 제4 변환모듈(310, 320, 330, 340)을 포함한다. 제1 내지 제 4 변환모듈(310, 320, 330, 340) 각각은 제1층 영상 내지 제4층 영상(m1, m2, m3, m4)에 대응한다. 이에 따라, 분류부는 입력되는 CT 영상을 제1 내지 제4층 영상(m1, m2, m3, m4)으로 구분한 후, 제1 내지 제4 변환모 듈(310, 320, 330, 340) 중 대응하는 모듈에 전달한다. 변환부는 분류부로부터 입력되는 CT 영상을 MRI 영상으로 변환한다. 전술한 바와 같이, 변환부 는 제1 내지 제4 변환모듈(310, 320, 330, 340)을 포함하며, 각 모듈은 각 층 영상(m1, m2, m3, m4)에 대응한 다. 제1 내지 제4 변환모듈(310, 320, 330, 340) 각각은 인공신경망(artificial neural network)을 포함한다. 이러 한 인공신경망은 GAN(generative adversarial networks)가 될 수 있다. 본 발명의 실시예에 따른 제1 내지 제4 변환모듈(310, 320, 330, 340) 각각에 공히 포함되는 인공신경망의 세부 구성이 도 4 및 도 5에 도시되었다. 제1 내지 제4 변환모듈(310, 320, 330, 340) 각각의 인공신경망은 MRI 생성자(G), CT 생성자(F), MRI 판별자 (MD), CT 판별자(CD), MRI 확률손실측정자(MSL), CT 확률손실측정자(CSL), MRI 기준손실측정자(MLL) 및 CT 기 준손실측정자(CLL)를 포함한다. MRI 생성자(G), CT 생성자(F), MRI 판별자(MD) 및 CT 판별자(CD) 각각은 개별적인 인공신경망이며, CNN(Convolutional neural network)이 될 수 있다. MRI 생성자(G), CT 생성자(F), MRI 판별자(MD) 및 CT 판별 자(CD) 각각은 복수의 계층을 포함하며, 각 계층은 복수의 연산을 포함한다. 또한, 복수의 연산 각각은 가중치 를 포함한다. 복수의 계층은 입력층(input layer), 컨볼루션층(convolution layer), 풀링층(polling layer), 완전연결층(fully-connected layer) 및 출력층(output layer) 중 적어도 하나를 포함한다. 복수의 연산은 컨볼 루션 연산, 풀링 연산, 시그모드(Sigmode) 연산, 하이퍼탄젠셜 연산 등을 포함한다. 이러한 각각의 연산은 이전 계층의 연산의 결과를 입력받아 연산을 수행하고, 각 연산은 가중치를 포함한다. 도 4 및 도 5를 참조하면, MRI 생성자(G)는 CT 영상이 입력되면, 복수의 연산을 수행하여 MRI 영상을 생성한다. 즉, MRI 생성자(G)는 픽셀 단위의 복수의 연산을 수행하며, 입력된 CT 영상의 픽셀을 복수의 연산을 통해 MRI 영상의 픽셀로 변환하여 MRI 영상을 생성한다. CT 생성자(F)는 MRI 영상이 입력되면, 복수의 연산을 수행하여 CT 영상을 생성한다. 즉, CT 생성자(F)는 픽셀 단위의 복수의 연산을 수행하며, 입력된 MRI 영상의 픽셀을 복수 의 연산을 통해 CT 영상의 픽셀로 변환하여 CT 영상을 생성한다. 도 4를 참조하면, MRI 판별자(MD)는 영상이 입력되면, 입력된 영상이 복수의 연산을 수행하여 입력된 영상이 MRI 영상일 확률과 MRI 영상이 아닐 확률을 출력한다. 여기서, MRI 판별자(MD)에 입력되는 영상은 MRI 생성자 (G)가 생성한 MRI 영상(cMRI) 혹은 학습 데이터인 MRI 영상(rMRI)이 입력된다. MRI 확률손실측정자(MSL)는 MRI 판별자(MD)로부터 MRI 판별자(MD)의 출력치인 MRI 판별자(MD)에 입력된 영상이 MRI 영상일 확률과 MRI 영상이 아닐 확률을 입력받고, MRI 영상일 확률과 MRI 영상이 아닐 확률의 출력치와 기 대치의 차이인 확률 손실을 산출한다. 이때, 확률 손실을 산출하기 위하여 softmax 함수를 이용할 수 있다. MRI 판별자(MD)에는 MRI 생성자(G)가 생성한 MRI 영상 혹은 학습 데이터인 MRI 영상이 입력되며, MRI 생성자(G)가충분히 학습된 상태라면, MRI 판별자(MD)는 MRI 생성자(G)가 생성한 MRI 영상 혹은 학습 데이터인 MRI 영상 모 두 MRI 영상으로 판별하는 것을 기대할 수 있다. 이러한 경우, MRI 판별자(MD)는 MRI 영상일 확률이 MRI 영상이 아닐 확률 보다 높으면서 MRI 영상일 확률이 소정 수치 이상이고, MRI 영상이 아닐 확률이 소정 수치 미만으로 출력할 것으로 기대할 수 있다. 하지만, 충분히 학습이 이루어지지 않은 경우 MRI 판별자(MD)의 출력치와 기대 치는 차이가 있으며, MRI 확률손실측정자(MSL)는 이러한 출력치와 기대치의 차이를 산출한다. 한편, MRI 생성자(G)가 MRI 생성자(G)에 입력된 CT 영상(rCT)으로부터 MRI 영상(cMRI)을 생성하면, CT 생성자 (F)는 생성된 MRI 영상(cMRI)으로부터 CT 영상(cCT)을 다시 생성할 수 있다. CT 기준손실측정자(CLL)는 CT 생성 자(F)가 다시 생성한 CT 영상(cCT)과 이의 기초가된 MRI 생성자(G)에 입력된 CT 영상(rCT)의 차이인 기준 손실 을 산출한다. 이러한 기준 손실은 L2 norm 연산을 통해 산출될 수 있다. 도 5를 참조하면, CT 판별자(CD)는 영상이 입력되면, 입력된 영상이 복수의 연산을 수행하여 입력된 영상이 CT 영상일 확률과 CT 영상이 아닐 확률을 출력한다. 여기서, CT 판별자(CD)에 입력되는 영상은 CT 생성자(F)가 생 성한 CT 영상(cCT) 혹은 학습 데이터인 CT 영상(rCT)이 입력된다. CT 확률손실측정자(CSL)는 CT 판별자(CD)로부터 CT 판별자(CD)의 출력치인 CT 판별자(CD)에 입력된 영상이 CT 영상일 확률과 CT 영상이 아닐 확률을 제공받고, CT 영상일 확률과 CT 영상이 아닐 확률의 출력치와 기대치의 차이인 확률 손실을 산출한다. 이때, 확률 손실을 산출하기 위하여 softmax 함수를 이용할 수 있다. CT 판별자 (CD)에는 CT 생성자(F)가 생성한 MRI 영상 혹은 학습 데이터인 MRI 영상이 입력되며, CT 생성자(F)가 충분히 학 습된 상태라면, CT 판별자(CD)는 CT 생성자(F)가 생성한 CT 영상(cCT) 혹은 학습 데이터인 CT 영상(rCT) 양자 모두 CT 영상으로 판별하는 것을 기대할 수 있다. 이러한 경우, CT 판별자(CD)는 CT 영상일 확률이 CT 영상이 아닐 확률 보다 높으면서 CT 영상일 확률이 소정 수치 이상이고, CT 영상이 아닐 확률이 소정 수치 미만으로 출 력할 것으로 기대할 수 있다. 하지만, 충분히 학습이 이루어지지 않은 경우 CT 판별자(CD)의 출력치와 기대치는 차이가 있으며, CT 확률손실측정자(CSL)는 이러한 출력치와 기대치의 차이를 산출한다. 한편, CT 생성자(F)가 CT 생성자(F)에 입력된 MRI 영상(rMRI)으로부터 CT 영상(cCT)을 생성하면, MRI 생성자 (G)는 생성된 CT 영상(cCT)으로부터 MRI 영상(cMRI)을 다시 생성할 수 있다. MRI 기준손실측정자(MLL)는 MRI 생 성자(G)가 다시 생성한 MRI 영상(cMRI)과 이의 기초가 된 CT 생성자(F)에 입력된 MRI 영상(rMRI)의 차이인 기준 손실을 산출한다. 이러한 기준 손실은 L2 norm 연산을 통해 산출될 수 있다. 기본적으로, 변환부의 인공신경망은 CT 영상을 MRI 영상으로 변환하기 위한 것이다. 이를 위하여, MRI 생 성자(G)는 CT 영상이 입력되면, 복수의 연산을 수행하여 MRI 영상을 생성한다. 이를 위하여, MRI 생성자(G)에 대한 학습(deep learning)이 요구된다. 그러면, 전술한 MRI 생성자(G)를 비롯한 CT 생성자(F), MRI 판별자 (MD), CT 판별자(CD), MRI 확률손실측정자(MSL), CT 확률손실측정자(CSL), MRI 기준손실측정자(MLL) 및 CT 기 준손실측정자(CLL)를 통한 학습 방법에 대해서 설명하기로 한다. CT 영상 및 MRI 영상은 동일하게 뇌의 단면을 촬영하지만, CT와 MRI의 장치 특성 상 정확하게 매칭되는 단면을 촬영할 수 없다. 따라서 CT 영상과 그 단면이 동일한 MRI 영상은 존재하지 않는다. 따라서 CT 영상을 MRI 영상 으로 변환하는 것을 학습하기 위하여 도 4와 같은 순방향 프로세스와, 도 5에 도시된 바와 같은 역방향 프로세스를 통해 확률 손실과, 기준 손실을 구하고, 확률 손실과, 기준 손실이 최소화되도록 역전파(back-propagation)을 통해 MRI 생성자(G), CT 생성자 (F), MRI 판별자(MD) 및 CT 판별자(CD)에 포함된 복수의 연산의 가중치를 수정한다. 보다 상세한 학습 절차에 대해서는 아래에서 보다 상세하게 설명될 것이다. 제1 내지 제4 변환모듈(310, 320, 330, 340) 각각의 인공신경망이 충분히 학습된 변환부는 제1 내지 제4층 영상(m1, m2, m3, m4) 중 어느 하나의 CT 영상이 입력되면, 제1 내지 제4 변환모듈(310, 320, 330, 340) 중 대 응하는 모듈의 인공신경망을 통해 MRI 영상으로 변환한다. 이와 같이, 변환된 MRI 영상은 후처리부에 제공 된다. 후처리부는 변환부가 변환한 MRI 영상에 대한 후처리를 수행한다. 후처리는 이미지 품질(Quality)을 향상시키기 위한 디컨볼루션(Deconvolution)이 될 수 있다. 여기서, 디컨볼루션은 역필터링, 초점 맞추기 등이 될 수 있다. 이러한 후처리부는 선택적인 구성으로, 필요에 따라 생략할 수 있다. 평가부는 변환부가 변환한 MRI 영상 혹은 후처리부를 거친 MRI 영상이 MRI 영상일 확률과 CT 영 상일 확률을 출력한다. 평가부는 인공신경망을 포함하며, 이러한 인공신경망은 CNN(Convolutional neural network)이 될 수 있다. 평가부는 입력층(input layer), 컨볼루션층(convolution layer), 풀링층(pollinglayer), 완전연결층(fully-connected layer) 및 출력층(output layer) 중 적어도 하나를 포함하며, 각 층은 복 수의 연산, 즉, 풀링 연산, 시그모드(Sigmode) 연산, 하이퍼탄젠셜 연산 중 적어도 하나를 포함한다. 특히, 각 연산은 가중치를 가진다. 학습 데이터는 CT 영상 혹은 MRI 영상이 될 수 있다. 인공신경망에 학습 데이터로 CT 영상이 입력되면, 인공신 경망의 출력은 MRI 영상일 확률 보다 CT 영상일 확률이 높게 출력될 것으로 기대되며, 학습 데이터로 MRI 영상 이 입력되면, 인공신경망의 출력은 CT 영상일 확률 보다 MRI 영상일 확률이 높게 출력될 것으로 기대된다. 학습 시, 이러한 출력에 대한 기대치는 실체 출력치와 차이가 있다. 따라서 학습 데이터를 입력한 후, 이러한 기대치 와 출력치의 차이를 구하고, 기대치와 출력치의 차이가 최소가 되도록 연전파 알고리즘을 통해 평가부의 인공신경망의 복수의 연산의 가중치를 수정한다. 어떠한 학습 데이터를 입력한 경우에도 기대치와 출력치의 차 이가 소정 수치 미만이면서 변동이 없으면, 충분히 학습된 것으로 판단한다. 충분히 학습이 수행된 후, 평가부 는 변환부가 변환한 MRI 영상이 MRI 영상인지 여부를 판단하기 위해 사용된다. 특히, 평가부는 변환부의 학습이 충분히 수행되었는지 여부를 판단하기 위해 사용될 수 있다. 변환부에 CT 영상을 입 력하고, 변환부가 출력한 영상에 대해 평가부가 MRI 영상일 확률과 CT 영상일 확률을 출력하는 테스 트 과정을 복수 번 반복한다. 이때, 반복되는 테스트 과정에서 지속적으로 MRI 영상일 확률이 소정 수치 이상인 경우, 변환후의 학습이 충분히 이루어진 것으로 판단할 수 있다. 그러면, 보다 자세히 본 발명의 실시예에 따른 학습 방법에 대해서 설명하기로 한다. 도 6은 본 발명의 실시예 에 따른 진단 영상을 변환하기 위한 장치의 학습 방법을 설명하기 위한 흐름도이다. 이하, 설명의 편의를 위하 여, MRI 기기가 촬영한 영상을 실제 MRI 영상(rMRI)이라고 칭하고, MRI 생성자(G)가 생성한 MRI 영상을 변환 MRI 영상(cMRI)이라고 칭하며, CT 기기가 촬영한 영상을 실제 CT 영상(rCT)이라고 칭하고, CT 생성자(F)가 생성 한 CT 영상을 변환 CT 영상(cCT)이라고 칭하기로 한다. 앞서 설명된 바와 같이, 본 발명의 실시예에 따른 변환부의 인공신경망에 대한 학습은 도 4와 같은 순방향 프로세스와, 도 5에 도시된 바와 같은 역방향 프로세스를 통해 확률 손실과, 기준 손실을 구하고, 확률 손실과, 기준 손실이 최소화되도록 역전파(back-propagation)을 통해 MRI 생성자(G), CT 생성자(F), MRI 판별자(MD) 및 CT 판별자(CD)에 포함된 복수의 연산의 가중치를 수정하는 절차이다. 먼저, 도 4 및 도 6을 참조하여 순방향 프로세스에 대해 설명하면, 변환부는 S110 단계에서 학습 데이터인 실제 CT 영상(rCT)을 MRI 생성자(G)에 입력한다. MRI 생성자(G)는 S120 단계에서 실제 CT 영상(rCT)으로부터 변 환 MRI 영상(cMRI)을 생성한다. 변환부는 S130 단계에서 변환 MRI 영상(cMRI) 및 실제 MRI 영상(rMRI) 각 각을 MRI 판별자(MD)에 입력한다. 그러면, MRI 판별자(MD)는 S140 단계에서 변환 MRI 영상(cMRI) 및 실제 MRI 영상(rMRI) 각각에 대해 MRI 영상일 확률과 MRI 영상이 아닐 확률을 출력한다. 이어서, MRI 확률손실측정자 (MSL)는 S150 단계에서 MRI 판별자(MD)로부터 MRI 영상일 확률과 MRI 영상이 아닐 확률을 입력받고, MRI 영상일 확률과 MRI 영상이 아닐 확률의 기대치와 출력치의 차이인 확률 손실을 산출한다. 한편, 변환부는 S160 단계에서 MRI 생성자(G)가 출력한 변환 MRI 영상(cMRI)을 CT 생성자(F)에 입력한다. 그러면, CT 생성자(F)는 S170 단계에서 변환 MRI 영상(cMRI)으로부터 변환 CT 영상(cCT)을 생성한다. 그러면, CT 기준손실측정자(CLL)는 S180 단계에서 CT 생성자(F)가 생성한 변환 CT 영상(cCT)과 앞서(S110) 입력된 학습 데이터인 실제 CT 영상(rCT)과의 차이인 기준 손실을 산출한다. 다음으로, 도 5 및 도 6을 참조하여 역방향 프로세스에 대해 설명하면, 변환부는 S210 단계에서 학습 데이 터인 실제 MRI 영상(rMRI)을 CT 생성자(F)에 입력한다. CT 생성자(F)는 S220 단계에서 실제 MRI 영상(rMRI)으 로부터 변환 CT 영상(cCT)을 생성한다. 변환부는 S230 단계에서 변환 CT 영상(cCT) 및 실제 CT 영상(rCT) 각각을 CT 판별자(CD)에 입력한다. 그러면, CT 판별자(CD)는 S240 단계에서 변환 CT 영상(cCT) 및 실제 CT 영상 (rCT) 각각에 대해 CT 영상일 확률과 CT 영상이 아닐 확률을 출력한다. 이어서, CT 확률손실측정자(CSL)는 S250 단계에서 CT 판별자(CD)로부터 CT 영상일 확률과 CT 영상이 아닐 확률을 입력받고, CT 영상일 확률과 CT 영상이 아닐 확률의 기대치와 출력치의 차이인 확률 손실을 산출한다. 한편, 변환부는 S260 단계에서 CT 생성자(F)가 출력한 변환 CT 영상(cCT)을 MRI 생성자(G)에 입력한다. 그 러면, MRI 생성자(G)는 S270 단계에서 변환 CT 영상(cCT)으로부터 변환 MRI 영상(cMRI)을 생성한다. 그러면, MRI 기준손실측정자(MLL)는 S280 단계에서 MRI 생성자(G)가 생성한 변환 MRI 영상(cMRI)과 앞서(S210) 입력된 학습 데이터인 실제 MRI 영상(rMRI)과의 차이인 기준 손실을 산출한다. 다음으로 변환부는 S300 단계에서 순방향 프로세스의 S150 단계와 S180 단계에서 산출된 확률 손실과 기준 손실 및 순방향 프로세스의 S250 단계와 S280 단계에서 산출된 확률 손실과 기준 손실이 최소화되도록 역전파 (back-propagation) 알고리즘을 통해 MRI 생성자(G), CT 생성자(F), MRI 판별자(MD) 및 CT 판별자(CD)에 포함 된 복수의 연산의 가중치를 수정한다. 일 실시예에 따르면, 전술한 학습 과정은 복수의 학습 데이터, 즉, 실제 CT 영상(rCT) 및 실제 MRI 영상(rMRI) 를 이용하여 확률 손실과 기준 손실이 기 설정된 수치 미만이 될 때까지, 반복적으로 수행된다. 따라서 변환부 는 전술한 순방향 프로세스 및 역방향 프로세스 결과, 확률 손실과 기준 손실이 기 설정된 수치 미만이 되 면, 충분히 학습이 완료된 것으로 판단하고 학습 절차를 종료한다. 한편, 대안적인 실시예에 따르면, 전술한 학습 과정의 종료는 평가부에 의해 결정될 수 있다. 즉, 평가부 는 변환부의 학습이 충분히 수행되었는지 여부를 판단하기 위해 사용될 수 있다. 변환부에 CT 영상을 입력하고, 변환부가 출력한 영상에 대해 평가부가 MRI 영상일 확률과 CT 영상일 확률을 출력 하는 테스트 과정을 복수 번 반복한다. 이때, 반복되는 테스트 과정에서 지속적으로 MRI 영상일 확률이 소정 수 치 이상인 경우, 변환후의 학습이 충분히 이루어진 것으로 판단하고, 학습 절차를 종료할 수 있다. 다음으로, 본 발명의 실시예에 따른 진단 영상을 변환하기 위한 방법을 설명하기로 한다. 도 7은 본 발명의 실 시예에 따른 진단 영상을 변환하기 위한 방법을 설명하기 위한 흐름도이다. 도 7을 참조하면, S410 단계에서 CT 영상이 입력되면, 전처리부는 S420 단계에서 CT 영상에 대해 전처리를 수행한다. 여기서, 전처리는 정규화(Normalization), 회색조변환(Gray scaling) 및 크기조절(Resize)를 포함한 다. 이러한 S420 단계의 전처리는 생략될 수 있다. 다음으로, 분류부는 S430 단계에서 입력된 CT 영상을 기 설정된 4개의 분류 중 어느 하나의 분류로 구분하 고, 변환부의 제1 내지 제4 변환모듈(310, 320, 330, 340) 중 대응하는 변환모듈에 제공한다. 이때, 분류 부는 뇌의 최상단부터 안구가 나타나기 이전까지 영상을 제1층 영상(m1)으로 구분하고, 안구가 나타나기 시작한 영상부터 측뇌실이 나타나기 이전까지 영상을 제2층 영상(m2)으로 구분하고, 측뇌실이 나타나기 시작한 영상부터 뇌실이 사라지기 전까지 영상을 제3층 영상(m3)으로 구분하고, 뇌실이 사라진 후 뇌의 최하단까지의 영상을 제4층 영상(m4)으로 구분한다. 다음으로, 변환부는 S440 단계에서 분류부가 분류한 CT 영상을 제1 내지 제4 변환모듈(310, 320, 330, 340) 중 대응하는 변환모듈을 통해 MRI 영상으로 변환한다. 여기서, 대응하는 변환모듈(310, 320, 330, 340 중 어느 하나)은 인공신경망을 포함하며, 이러한 인공신경망은 앞서, 도 4, 도 5 및 도 6에서 설명된 바와 같이, CT 영상을 MRI 영상으로 변환하도록 학습된 것이다. 특히, 제1 내지 제4 변환모듈(310, 320, 330, 340) 각각의 인공신경망의 학습 데이터로 사용되는 CT 영상 및 MRI 영상은 도 3에서 설명된 제1층 내지 제4층 영상 (m1, m2, m3, m4) 중 대응하는 계층의 영상을 사용하며, CT 영상 및 MRI 영상 양자 모두가 동일한 계층의 영상 을 사용한다. 예컨대, 제3 변환모듈의 학습을 위해 에 사용되는 영상은 CT 영상 및 MRI 영상 모두 제3층 영상(m3)을 이용한다. 이와 같이, 뇌 영상을 복수의 영역으로 구분하여, 특화된 학습을 수행할 수 있고, 보다 정확한 변환 결과를 제공할 수 있다. 이어서, 후처리부는 S450 단계에서 변환된 MRI 영상에 대해 후처리를 수행한다. 후처리는 이미지 품질 (Quality)을 향상시키기 위한 디컨볼루션(Deconvolution)이 될 수 있다. 이러한 S450 단계의 후처리는 생략될 수 있다. 다음으로, 평가부는 S460 단계에서 변환부에 의해 변환된 MRI 영상을 검증한다. 평가부는 입력 된 영상, 즉, 변환부에 의해 변환된 MRI 영상이 MRI 영상일 확률과 CT 영상일 확률을 산출한다. 이에 따라, 평가부는 MRI 영상일 확률이 기 설정된 수치 이상이면, 해당 영상의 검증에 성공한 것으로 판단한다. 검증에 성공한 경우, 평가부는 S470 단계에서 해당 MRI 영상을 출력한다. 한편, 앞서 설명된 본 발명의 실시예에 따른 다양한 방법들은 다양한 컴퓨터수단을 통하여 판독 가능한 프로그 램 형태로 구현되어 컴퓨터로 판독 가능한 기록매체에 기록될 수 있다. 여기서, 기록매체는 프로그램 명령, 데 이터 파일, 데이터구조 등을 단독으로 또는 조합하여 포함할 수 있다. 기록매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 예컨대 기록매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광 기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치를 포함한다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은기계어 와이어뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 와이어를 포함 할 수 있다. 이러한 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하 도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상 본 발명을 몇 가지 바람직한 실시예를 사용하여 설명하였으나, 이들 실시예는 예시적인 것이며 한정적인"}
{"patent_id": "10-2017-0154251", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "것이 아니다. 이와 같이, 본 발명이 속하는 기술분야에서 통상의 지식을 지닌 자라면 본 발명의 사상과 첨부된 특허청구범위에 제시된 권리범위에서 벗어나지 않으면서 균등론에 따라 다양한 변화와 수정을 가할 수 있음을 이해할 것이다."}
{"patent_id": "10-2017-0154251", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 진단 영상을 변환하기 위한 장치의 구성을 설명하기 위한 블록도이다. 도 2는 도 1의 진단 영상을 변환하기 위한 장치 중 분류부의 동작을 설명하기 위한 블록도이다. 도 3은 진단 영상을 변환하기 위한 장치 중 분류부가 분류하는 영상의 일례를 설명하기 위한 도면이다. 도 4 및 도 5는 본 발명의 실시예에 따른 진단 영상을 변환하기 위한 장치 중 변환부의 세부구성을 설명하기 위 한 도면이다. 도 6은 본 발명의 실시예에 따른 진단 영상을 변환하기 위한 장치의 학습 방법을 설명하기 위한 흐름도이다. 도 7은 본 발명의 실시예에 따른 진단 영상을 변환하기 위한 방법을 설명하기 위한 흐름도이다."}
