{"patent_id": "10-2022-0087969", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0010807", "출원번호": "10-2022-0087969", "발명의 명칭": "비디오 검색을 위한 영상 특징 서술자 추출 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "김준수"}}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 특징 서술자 추출 방법에 있어서,사용자로부터 검색 요청 영상을 획득하는 단계;상기 검색 요청 영상에 대해 시공간 변환을 수행하는 단계;상기 시공간 변환을 수행한 영상으로부터 특징맵을 추출하는 단계; 및상기 특징맵에 TNIP(Temporal Nested Invariance Pooling)를 적용하여 영상 특징 서술자를 추출하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 영상 특징 서술자를 추출하는 단계는 반복적인 풀링 작업을 수행하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 반복적인 풀링 작업을 수행하는 단계는 시공간 영역 풀링, 스케일 내부 풀링, 멀티스케일 풀링 또는 시공간 변환 풀링 중 적어도 하나 이상을 수행하는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 특징맵은 영상 처리 필터를 활용하여 추출되는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 특징맵은 다양한 인공신경망 네트워크를 활용하여 추출되는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서, 상기 특징맵은 적어도 하나 이상의 시공간 차원과 채널 차원을 가지는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서,공개특허 10-2024-0010807-3-상기 검색 요청 영상의 시공간 변환은 미리 정의된 영상 변환 함수 모음을 통해 수행되는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 시공간 변환은 공간 변환 및 시간 변환 중 적어도 하나 이상을 수행하는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 시공간 변환이 가해진 각 영상들은 모두 동일한 영상 특징 추출 네트워크에 입력됨으로써 특징맵을 추출하는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 네트워크에 입력된 영상들을 통해 다수의 4차원 특징맵이 추출되는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 3항에 있어서,상기 시공간 영역 풀링은 사전에 정의된 시공간 윈도우를 시공간 축을 따라 풀링하는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 시공간 영역 풀링은 2개 이상의 서로 다른 시공간 윈도우가 사용되는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 3항에 있어서,상기 시공간 영역 풀링은 주어진 시공간 윈도우에 대해 p-norm pooling(default: p=2)을 수행하는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 3항에 있어서,상기 스케일 내부 풀링은 상기 시공간 영역 풀링된 벡터들에 대해 다시 p-norm pooling(default: p=∞)을 수행하는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 3항에 있어서,상기 멀티스케일 풀링은 상기 스케일 내부 풀링된 벡터들을 모든 윈도우 스케일에 대해 p-norm공개특허 10-2024-0010807-4-pooling(default: p=1)을 수행하는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 3항에 있어서,상기 시공간 변환 풀링은 상기 멀티스케일 풀링된 벡터들을 서로 다른 시공간 변환 인덱스에 대해 p-normpooling(default: p=∞)을 수행함으로써, TNIP 영상 특징 서술자를 얻는 방법."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "영상 특징 서술자 추출 장치에 있어서,사용자로부터 검색 요청 영상을 획득하는 검색 요청 영상 획득부;상기 검색 요청 영상에 대해 시공간 변환을 수행하는 시공간 변환부;상기 시공간 변환을 수행한 영상으로부터 특징맵을 추출하는 특징맵 추출부; 및상기 특징맵에 TNIP를 적용하여 영상 특징 서술자를 추출하는 TNIP 수행부를 포함하는 장치."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17항에 있어서,상기 TNIP 수행부에서 반복적인 풀링 작업을 수행하는,영상 특징 서술자 추출 장치."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18항에 있어서,상기 반복적인 풀링 작업은 시공간 영역 풀링, 스케일 내부 풀링, 멀티스케일 풀링 또는 시공간 변환 풀링 중적어도 하나 이상을 수행하는,영상 특징 서술자 추출 장치."}
{"patent_id": "10-2022-0087969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 17항에 있어서,상기 검색 요청 영상의 시공간 변환은 미리 정의된 영상 변환 함수 모음을 통해 수행되는,영상 특징 서술자 추출 장치."}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 비디오 검색을 위한 영상 특징 서술자 추출 방법 및 장치가 개시된다. 상기 영상 특징 서술자 추출 방 법은 사용자로부터 검색 요청 영상을 획득하는 단계; 상기 검색 요청 영상에 대해 시공간 변환을 수행하는 단계; 상기 시공간 변환을 수행한 영상으로부터 특징맵을 추출하는 단계; 및 상기 특징맵에 TNIP를 적용하여 영상 특징 서술자를 추출하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 비디오 검색을 위한 영상 특징 서술자 추출 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "콘텐츠 기반 영상 검색 (Content-based image/video retrieval)은 이미지나 비디오 내의 정보를 기반으로 검색 요청 영상과 관련이 있는 영상을 검색하는 기술이다. MPEG에서 시각적 유사도에 기반한 이미지 검색을 위하여 이미지 서술자 추출 표준 기술인 CDVS(Compact Descriptors for Visual Search)를 개발하였으며, 이는 비디오 서술자 추출 표준기술인 CDVA(Compact Descriptors for Video Analysis)에서도 채용되었다. CDVA는 비디오에서 키프레임(key frame)을 선별한 뒤에 이 프레임들에 대해 CDVS 서술자를 추출한다. 최근, 비디오 인식 기술의 발 달에 힘입어 키프레임 단위가 아닌 프레임 묶음을 동시에 분석함으로써 더욱 개선된 인식 성능을 기대할 수 있 게 되었다. 이에 따라, 단일 입력 프레임에 대한 공간적 변환 불변성 외에도 다수의 입력 프레임에 대해 시공간 적 변환에 불변하는 영상 특징을 추출하는 기술이 연구되고 있다. 본 개시는 미리 정의된 범주의 시공간적 변환 에 강인한 영상 특징을 추출하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 과제는, 검색 요청 영상과 유사한 영상을 검색하기 위하여 영상의 시각적 특징 정보를 추출하 는 것을 목적으로 한다. 또한, 본 개시의 목적은, 다양한 시공간 변환을 고려한 영상 특징 집적(feature aggregation)을 통해 시간적 변 환에 대한 강인성을 가지는 딥 특징 서술자 추출을 목적으로 한다. 또한, 본 개시의 목적은, 복수의 동영상 프레임으로부터 추출된 특징맵(feature map) 모음으로부터 원하는 길이 의 영상 특징 서술자를 추출하는데 있다. 또한, 본 개시의 목적은, 추출된 서술자가 입력 데이터의 공간적, 시간적 변환에 대한 불변성을 가지도록 유도 하는데 있다. 본 개시에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시예에 따르면, 비디오 검색을 위한 영상 특징 서술자 추출 방법 및 장치가 개시된다. 본 개시의 일 실시예에 따른 영상 특징 서술자 추출 방법은, 사용자로부터 검색 요청 영상을 획득하는 단계; 상 기 검색 요청 영상에 대해 시공간 변환을 수행하는 단계; 상기 시공간 변환을 수행한 영상으로부터 특징맵을 추 출하는 단계; 및 상기 특징맵에 TNIP(Temporal Nested Invariance Pooling)를 적용하여 영상 특징 서술자를 추 출하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따르면, 상기 영상 특징 서술자를 추출하는 단계는 반복적인 풀링 작업을 수행하는 단계 를 포함할 수 있다. 본 개시의 일 실시예에 따르면, 상기 반복적인 풀링 작업을 수행하는 단계는 시공간 영역 풀링, 스케일 내부 풀 링, 멀티스케일 풀링 또는 시공간 변환 풀링 중 적어도 하나 이상을 수행할 수 있다. 본 개시의 일 실시예에 따르면, 상기 특징맵은 영상 처리 필터를 활용하여 추출될 수 있다. 본 개시의 일 실시예에 따르면, 상기 특징맵은 다양한 인공신경망 네트워크를 활용하여 추출될 수 있다. 본 개시의 일 실시예에 따르면, 상기 특징맵은 적어도 하나 이상의 시공간 차원과 채널 차원을 가질 수 있다. 본 개시의 일 실시예에 따르면, 상기 검색 요청 영상의 시공간 변환은 미리 정의된 영상 변환 함수 모음을 통해 수행될 수 있다. 본 개시의 일 실시예에 따르면, 상기 시공간 변환은 공간 변환 및 시간변환 중 적어도 하나 이상을 수행할 수 있다. 본 개시의 일 실시예에 따르면, 상기 시공간 변환이 가해진 각 영상들은 모두 동일한 영상 특징 추출 네트워크 에 입력됨으로써 특징맵을 추출할 수 있다. 본 개시의 일 실시예에 따르면, 상기 네트워크에 입력된 영상들을 통해 다수의 4차원 특징맵이 추출될 수 있다. 본 개시의 일 실시예에 따르면, 상기 시공간 영역 풀링은 사전에 정의된 시공간 윈도우를 시공간 축을 따라 풀 링할 수 있다. 본 개시의 일 실시예에 따르면, 상기 시공간 영역 풀링은 2개 이상의 서로 다른 시공간 윈도우가 사용될 수 있 다. 본 개시의 일 실시예에 따르면, 상기 시공간 영역 풀링은 주어진 시공간 윈도우에 대해 p-norm pooling(default: p=2)을 수행할 수 있다. 본 개시의 일 실시예에 따르면, 상기 스케일 내부 풀링은 상기 시공간 영역 풀링된 벡터들에 대해 다시 p-norm pooling(default: p=∞)을 수행할 수 있다. 본 개시의 일 실시예에 따르면, 상기 멀티스케일 풀링은 상기 스케일 내부 풀링된 벡터들을 모든 윈도우 스케일 에 대해 p-norm pooling(default: p=1)을 수행할 수 있다. 본 개시의 일 실시예에 따르면, 상기 시공간 변환 풀링은 상기 멀티스케일 풀링된 벡터들을 서로 다른 시공간 변환 인덱스에 대해 p-norm pooling(default: p=∞)을 수행함으로써, TNIP 영상 특징 서술자를 얻을 수 있다. 본 개시의 일 실시예에 따른 영상 특징 서술자 추출 장치는, 사용자로부터 검색 요청 영상을 획득하는 검색 요 청 영상 획득부; 상기 검색 요청 영상에 대해 시공간 변환을 수행하는 시공간 변환부; 상기 시공간 변환을 수행 한 영상으로부터 특징맵을 추출하는 특징맵 추출부; 및 상기 특징맵에 TNIP를 적용하여 영상 특징 서술자를 추 출하는 TNIP 수행부를 포함할 수 있다. 본 개시의 일 실시예에 따르면, 상기 TNIP 수행부에서 반복적인 풀링 작업을 수행할 수 있다. 본 개시의 일 실시예에 따르면, 상기 반복적인 풀링 작업은 시공간 영역 풀링, 스케일 내부 풀링, 멀티스케일 풀링 또는 시공간 변환 풀링 중 적어도 하나 이상을 수행할 수 있다. 본 개시의 일 실시예에 따르면, 상기 검색 요청 영상의 시공간 변환은 미리 정의된 영상 변환 함수 모음을 통해 수행될 수 있다."}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시에 대하여 위에서 간략하게 요약된 특징들은 후술하는 본 개시의 상세한 설명의 예시적인 양상일 뿐이며, 본 개시의 범위를 제한하는 것은 아니다."}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 검색 요청 영상과 유사한 영상을 검색하기 위하여 영상의 시각적 특징 정보를 추출할 수 있 다. 본 개시에 따르면, 다양한 시공간 변환을 고려한 영상 특징 집적(feature aggregation)을 통해 시간적 변환에 대한 강인성을 가지는 영상 특징 서술자를 추출할 수 있다. 본 개시에 따르면, 추출된 서술자가 입력 데이터의 공간적, 시간적 변환에 대한 불변성을 가지도록 유도할 수 있다. 본 개시에 따르면, 입력 데이터의 공간적, 시간적 변환에 대한 불변성을 통해 비디오 검색을 위한 영상 특징 추 출을 더욱더 강건하게 수행할 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 있어서, 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\" 또는 \"접속\"되어 있다고 할 때, 이는 직접 적인 연결 관계 뿐만 아니라, 그 중간에 또 다른 구성요소가 존재하는 간접적인 연결관계도 포함할 수 있다. 또 한 어떤 구성요소가 다른 구성요소를 \"포함한다\" 또는 \"가진다\"고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 배제하는 것이 아니라 또 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 있어서, 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용되 며, 특별히 언급되지 않는 한 구성요소들 간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 개시의 범 위 내에서 일 실시 예에서의 제1 구성요소는 다른 실시 예에서 제2 구성요소라고 칭할 수도 있고, 마찬가지로 일 실시 예에서의 제2 구성요소를 다른 실시 예에서 제1 구성요소라고 칭할 수도 있다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위한 것일 뿐, 구성요소들이 반드시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수 도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 개시의 범위에 포함된 다. 본 개시에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들은 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 개시의 범위에 포함된다. 또한, 다양한 실시예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 본 명세서에 사용되는 위치 관계의 표현, 예컨대 상부, 하부, 좌측, 우측 등은 설명의 편의 를 위해 기재된 것이고, 본 명세서에 도시된 도면을 역으로 보는 경우에는, 명세서에 기재된 위치 관계는 반대 로 해석될 수도 있다. 본 개시는, 비디오 검색을 위한 영상 특징 서술자 추출 방법 및 장치에 관한 것이다. 구체적으로, 본 개시는 검 색 요청 영상과 시각적으로 유사한 영상을 데이터베이스에서 검색하기 위해 영상의 특징 정보를 추출하는 방법 에 관한 것이다. 본 개시에 따른 콘텐츠 기반 영상 검색(Content-based image/video retrieval) 방법 및 장치는 이미지나 비디오 내의 정보를 기반으로 검색 요청 영상과 관련이 있는 영상을 검색하는 기술이다. 여기에서 말하는 콘텐츠는 영상의 시각적 정보 외에도 자막, 음성 등의 정보를 모두 포함할 수 있다. 여기서, 검색 대상 이 영상인 경우에는 시각적 유사도가 매우 중요한 역할을 하는 경우가 많을 수 있다. 본 개시 또한 시각적 유사 도 기반 동영상 검색에 관한 것이며, 이에 따라 이하에서는 영상의 시각적 특징을 추출하는 기술에 대해 설명하 도록 한다. 본 개시에 따른 비디오 검색을 위한 영상 특징 서술자 추출 방법에는 시각적 유사도 기반 이미지 검색을 위한 이미지 서술자 추출 표준기술인 CDVS(Compact Descriptors for Visual Search) 및 비디오 서술자 추출 표준 기 술인 CDVA(Compact Descriptors for Video Analysis)이 있다. CDVS 서술자는 이미지에서 추출된 국소 특징점 정보와 국소 특징점 서술자들을 결합한 피셔 벡터(Fisher vector)로 구성될 수 있다. 여기서, 국소 특징점 정보는 좌표 및/또는 HoG 서술자일 수 있다. 또한, 피셔 벡터"}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 이미지의 전역적인 시각적 특징을 요약할 수 있고, 피셔 벡터의 유사도를 산출하여 이미지의 전반적인 유사 도를 측정할 수 있다. 상기 국소 특징점 정보는 전반적인 유사도가 높은 이미지에 대한 기하학적 구조 검증 (geometric verification)에 활용될 수 있으며, 이를 통해 좀 더 높은 정확도로 이미지를 검색할 수 있다. 본 개시는 이러한 기술적 내용을 포함할 수 있다. 상기 CDVA는 비디오에서 키프레임을 선별한 뒤, 이 프레임들에 대해 CDVS 서술자를 추출할 수 있다. 여기서, 키 프레임은 일정 간격으로 추출된 프레임 중 컬러 히스토그램이 일정 수준으로 유사한 프레임을 배제하는 방식으 로 선정될 수 있다. 또한, 여러 개의 서술자를 효율적으로 부호화하기 위해 영상 유사도 기반 세그먼트 분할, 세그먼트 내 예측 부호화 등이 적용될 수 있다. 한편, CDVA는 각 키프레임에 대해 기존의 CDVS 서술자 외에 딥 특징 서술자를 추출하여 CDVA 서술자 비트스트림에 포함시킬 수 있다. 여기서, 상기 딥 특징 서술자는 각 키프 레임에 대해 고정된 길이의 영상 특징 벡터일 수 있다. 또한, 상기 딥 특징 서술자는 임의의 인공신경망 네트워 크를 사용하여 추출할 수 있다. CDVA 헤더는 딥 특징 서술자 추출에 사용된 인공신경망 네트워크에 대한 메타데 이터를 포함할 수 있다. 이에 따라, 검색 요청 수신측은 딥 영상 특징 벡터의 호환성을 판단할 수 있다. 또한, CDVA는 VGG16 네트워크의 pool5 레이어 출력을 pooling하여 512차원 벡터를 산출할 수 있다. 특히, 기본 딥 영 상 특징 벡터는 공간적 변환(스케일, 회전, 평행이동 등)에 대해 일정 수준 이상의 강건성을 담보하기 위해 NIP 방식을 채용할 수 있다. NIP는 2D CNN(Convolutional Neural Network) 출력에 대해 묘사되어 있으나, 각 키프 레임에 대응되는 딥 특징 서술자가 추출되기만 한다면 최근 비디오 인식에 많이 사용되는 3D CNN 구조에 대해서 도 적용이 가능하다. 비디오 인식 기술의 발달에 힘입어 키프레임 단위가 아닌 프레임 묶음을 동시에 분석함으로써 더욱 개선된 인식 성능을 기대할 수 있다. 이에 따라, 단일 입력 프레임에 대한 공간적 변환 불변성 외에도 다수의 입력 프레임에 대해 시공간적 변환에 불변하는 영상 특징을 추출하는 기술이 연구되고 있다. 이하, 본 개시는 미리 정의된 범 주의 시공간적 변환에 강인한 영상 특징 서술자 추출 방법에 대해 도면을 참고하여 설명한다. 도 1은 본 개시에 따른 비디오 검색을 위한 영상 특징 서술자 추출 방법을 제공하는 시스템의 구조를 예를 들어 도시한 도면이다. 도 1을 참고하면, 시스템은 통신망에 연결된 사용자 장치(110a), 사용자 장치(110b), 서버를 포함한다. 도 1은 2개의 사용자 장치들(110a, 110b)을 예시하였으나, 3개 이상의 사용자 장치들이 존재할 수 있다. 사용자 장치(110a) 및 사용자 장치(110b)는 본 개시의 실시예에 따른 플랫폼을 이용하여 비디오 검색을 위한 영 상 특징 서술자를 추출하고자 하는 사용자에 의해 사용된다. 사용자 장치들(110a, 110b)은 입력 데이터(예: 검 색 요청 영상, 이미지 등)를 획득하고, 입력 데이터를 통신 망을 통해 서버로 송신할 수 있고, 서버 와 상호 작용할 수 있다. 사용자 장치들(110a, 110b) 각각은 통신을 위한 통신부, 데이터 및 프로그램을 저장하 는 저장부, 정보를 표시하기 위한 표시부, 사용자의 입력을 위한 입력부, 제어를 위한 프로세서를 포함할 수 있 다. 예를 들어, 사용자 장치들(110a, 110b) 각각은 플랫폼 접속을 위한 어플리케이션 또는 프로그램을 설치한 범용 장치(예: 스마트폰, 타블렛, 랩탑 컴퓨터, 데스크답 컴퓨터) 또는 플랫폼 전용 접속 단말일 수 있다. 서버는 본 개시의 실시예들에 따른 플랫폼을 제공한다. 서버는 영상 특징 서술자 추출 플랫폼을 위한 다양한 기능들을 제공하며, 인공지능 모델을 운용할 수 있다. 본 개시에 적용 가능한 인공 신경망의 일 예는 이 하 도 2를 참고하여 설명된다. 또한, 서버는 학습 데이터를 이용하여 인공지능 모델을 위한 학습을 수행할 수 있다. 본 개시의 다양한 실시예들에 따라, 서버는 비디오 검색을 위한 영상 특징 서술자 추출 절차에포함되는 다양한 분석 업무들을 위한 복수의 인공지능 모델들을 저장하고, 필요에 따라 인공지능 모델들 중 적 어도 하나를 선택적으로 사용한다. 여기서, 서버는 로컬 네트워크에 존재하는 로컬 서버이거나, 외부 망을 통해 연결되는 원격 접속 서버(예: 클라우드 서버)일 수 있다. 서버는 통신을 위한 통신부, 데이터 및 프 로그램을 저장하는 저장부, 제어를 위한 프로세서를 포함할 수 있다. 도 2는 시스템에 적용 가능한 인공 신경망의 구조를 도시한 도면이다. 도 2와 같은 인공 신경망은 서버에 저장된 인공지능(AI) 모델들의 구조로 이해될 수 있다. 도 2를 참고하 면, 인공 신경망은 입력 계층(input layer), 적어도 하나의 은닉 계층(hidden layer), 출력 계층 (output layer)으로 이루어진다. 계층들(210, 220, 230) 각각은 복수의 노드(node)들로 구성되어 있으며, 노드들 각각은 이전 계층에 속한 적어도 하나의 노드의 출력과 연결되어 있다. 각 노드는 이전 계층의 노드들의 각 출력 값과 그에 상응하는 연결 가중치(weight)를 내적(inner product)한 값을 계산한 후, 비선형(non- linear)인 활성화 함수(activation function)와 곱한 출력 값을 다음 계층의 적어도 하나의 뉴런에게 전달한다. 도 2와 같은 인공 신경망은 학습(예: 기계 학습(machine learning), 딥 러닝(deep learning) 등)에 의해 형성 될 수 있다. 또한, 본 개시의 다양한 실시예에서 사용되는 인공 신경망 모델은 완전 합성곱 신경망(fully convolutional neural network), 합성곱 신경망(convolutional neural network), 순환 신경망(recurrent neural network), 제한 볼츠만 머신(restricted Boltzmann machine, RBM) 및 심층 신뢰 신경망(deep belief neural network, DBN) 중 적어도 하나를 포함할 수 있으나, 이에 한정되지 않는다. 또는, 딥러닝 이외의 머신 러닝 방법도 포함할 수 있다. 또는 딥 러닝과 머신 러닝을 결합한 하이브리드 형태의 모델도 포함할 수 있다. 예컨대, 딥 러닝 기반의 모델을 적용함으로써, 영상의 특징을 추출하고, 추출된 특징에 기초하여 영상을 분류하 거나 인식할 때는 머신 러닝 기반의 모델을 적용할 수도 있다. 머신 러닝 기반의 모델은 서포트 벡터 머신 (Support Vector Machine, SVM), 에이다부스트(AdaBoost) 등을 포함할 수 있으나, 이에 한정되지 않는다. 도 3은 영상 특징 서술자 추출 순서도를 도시한 도면이다. 본 개시에 따른 영상 특징 서술자 추출 과정은 검색 요청 영상이 입력되는 단계(S310), 시공간 변환 단계 (S320), 특징맵 추출 단계(S330) 및 TNIP 수행 단계(S340)가 포함될 수 있다. 상기 영상 특징 서술자 추출 과정을 수행하는 본 개시에 따른 영상 특징 서술자 추출 장치는, 예를 들어 상기 서버 이거나 또는 상기 사용자 장치들(110a, 110b)일 수 있다. 예를 들어, 상기 사용자 장치(110a)의 비디 오 검색 요청에 대해 상기 서버 또는 다른 사용자 장치(110b)가 도 3의 영상 특징 서술자 추출 과정을 수 행할 수 있다. 또한, 다른 실시예로 상기 서버의 비디오 검색 요청에 대해 상기 사용자 장치들(110a, 110b)이 각각 도 3의 영상 특징 서술자 추출 과정을 수행하는 것도 가능하다. 도 3을 참고하면, S310 단계에서, 본 개시에 따른 영상 특징 서술자 추출 장치는 검색 요청 영상을 입력 받을 수 있다. 여기서, 검색 요청 영상은 사용자에 의해 입력될 수 있다. 또한, 상기 장치에 입력되는 검색 요청 영 상 전체 또는 일부는 고정된 길이를 가지는 짧은 영상의 모음일 수 있다. 본 개시에서 말하는 검색 요청 영상은 'Query' 또는 이와 동등한 기술적 의미를 가지는 다른 용어로 지칭될 수 있다. 또한, 본 개시에서 말하는 짧은 영상은 '클립(clip)' 또는 이와 동등한 기술적 의미를 가지는 다른 용어로 지칭될 수 있다. S320 단계에서, 상기 장치는 검색 요청 영상에 대해 시공간 변환을 수행할 수 있다. 검색 요청 영상의 시공간 변환은 미리 정의된 영상 변환 함수 모음을 통해 수행될 수 있다. 또한, 시공간 변환은 공간 변환, 시간 변환 또는 두 변환의 조합 중 하나를 포함할 수 있다. 본 개시에 따른 시공간 변환 과정은 이하 도 4a 및 도 4b를 참 고하여 후술한다. S330 단계에서, 상기 장치는 특징맵을 추출할 수 있다. 구체적으로, S320 단계에서 시공간 변환된 각 영상들은 영상 특징 추출 네트워크에 입력될 수 있다. 이때, 상기 영상 특징 추출 네트워크는 모두 동일한 네트워크일 수 있으며, 이에 한정되지 않는다. 이에 따라, 상기 장치는 다수의 4차원 특징맵을 추출할 수 있다. 구체적인 4차 원 특징맵 추출 과정은 이하 도 4c를 참고하여 후술한다. S340 단계에서, 상기 장치는 TNIP를 수행할 수 있다. 구체적으로, 상기 장치는 S330 단계에서 추출된 특징맵들 에 대해 TNIP를 적용하여 영상 특징 서술자를 추출할 수 있다. 여기서, TNIP는 특징맵들에 적용되는 반복적인풀링 작업일 수 있다. 구체적인 TNIP 수행 방법은 이하 도 4d 및 도 4e를 참고하여 후술한다. 본 개시의 일 실시예에 따르면, 영상 특징을 추출하고자 하는 전체 비디오를 프레임의 집합 X={xi|i=0,1, 2,...}으로 표현할 수 있다. 이에 따라, 영상 특징 서술자는 비디오 전체 또는 X의 부분집합에 대해 추출될 수 있다. 예를 들면, 부분집합은 CDVA 레퍼런스 소프트웨어에서 선별된 키프레임 전후로 일정 간격(I)을 두고 t개 의 프레임을 선택한 것일 수 있다. 이하, 구체적인 영상 특징 서술자 추출 방법을 설명한다. 도 4a는 검색 요청 영상의 공간적 변환 과정을 도시한 도면이다. 구체적으로, 본 개시에 따른 영상 특징 서술자 추출 장치는 입력된 클립 영상에 대하여 공간적 변환을 수 행할 수 있다. 예를 들어, 공간적 변환을 수행하기 위해, 상기 장치는 클립 영상을 구성하는 각 프레임 (frame)들을 360/N도씩 회전시킬 수 있다. 이에 따라, 상기 장치는 N개의 클립들을 획득할 수 있다. 상기 N개의 클립들은 이후 특징맵 추출 과정에 사용될 수 있다. 도4b는 클립 영상의 시간적 변환 과정을 도시한 도면이다. 구체적으로, 본 개시에 따른 영상 특징 서술자 추출 장치는 입력된 클립 영상에 대하여 시간적 변환을 수 행할 수 있다. 예를 들어, 시간적 변환을 수행하기 위해, 상기 장치는 검색 요청 영상을 구성하는 프레임셋 (frameset)을 M개의 구간으로 분할할 수 있다. 또한, 상기 장치는 상기 M개로 분할된 프레임들에 대해 순 환 셔플을 적용함으로써 M개의 클립들을 획득할 수 있다. 여기서, 순환 셔플 적용 과정은 M개의 구간으로 분할된 각 프레임 묶음에 대해 맨 마지막 구간의 프레임 묶음을 가장 앞으로 배치함으로써 하나의 클립을 획득 할 수 있다. 이러한 규칙을 반복적으로 수행하여 M개의 클립들을 획득할 수 있다. 이에 따라, 상기 M개의 클립들은 이후 특징맵 추출 과정에 사용될 수 있다. 즉, 상기 장치는 공간적 변환을 통해 획득한 N개의 클 립들과 시간적 변환을 통해 획득한 M개의 클립들을 합한 총 N+M개의 클립들을 이용하여 특징맵 추출 과정을 수행할 수 있다. 본 개시의 다른 실시예에 따르면, 공간적 변환 또는 시간적 변환 중 하나만을 수행함으 로써, N개 또는 M개의 클립들을 이용하여 특징맵 추출 과정을 수행할 수도 있다. 도 4c는 4차원 특징맵 추출 과정을 도시한 도면이다. 본 개시에 따른 특징맵 추출 과정은 시공간 변환을 수행한 클립들을 영상 특징 추출 네트워크에 입력함으 로써 수행될 수 있다. 이에 따라, 다수의 4차원 특징맵들이 추출될 수 있다. 여기서, 상기 추출된 특징맵 모음은 [수학식 1]로 표현될 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, [수학식 1]의 괄호 안에 포함된 인덱스는 동일한 형상의 텐서(tensor)들을 묶은 번들(bundle)에서 각 텐서의 순번을 의미한다. 여기서, 상기 텐서는 다차원 데이터의 배열을 의미할 수 있다. 즉, 본 개시에 따르면, 상기 텐서는 다차원 특징맵 데이터의 배열을 의미할 수 있다. 또한, 괄호 밖의 인덱스는 개별 텐서의 요소 (element)에 접근하기 위한 인덱스를 의미한다. 구체적으로, i는 i번째 시공간 변환을 의미한다. 또한, h, w, t, c는 각각 높이, 너비, 시간, 채널 인덱스를 나타낸다. 도 4d는 TNIP 수행 과정을 도시한 도면이다. 본 개시에 따른 TNIP 수행 과정은 반복적인 풀링 과정을 의미할 수 있다. 구체적으로, 상기 장치는 특징맵(44 1)들에 대해 시공간 풀링(442, Spatio-Temporal Pooling)을 수행할 수 있다. 이후, 시공간 풀링을 수행한 데이 터에 대해 최대 풀링(Max Pooling)을 수행함으로써 영상 특징 서술자가 추출될 수 있다. 여기서, 상 기 최대 풀링은 윈도우(window) 내의 값 중 최대값을 빼내는 연산을 의미한다. 다만, 본 개시의 다른 실시예에 따르면, 시공간 풀링을 수행한 데이터에 대해 p-norm pooling을 수행할 수도 있으며, 본 개시는 이에 한정 되지 않는다. 마지막으로, 상기 장치는 상기 영상 특징 서술자를 병치(concatenation)하여 최종 영상 특징 서술자(TNIP feature) 를 추출할 수 있다. 본 개시의 일 실시예에 따르면, 공간적 변환을 통해 획득한 N개의 클립들과 시간적 변환을 통해 획득한 M개의 클립들 각각에 대해 TNIP 영상 특징 서술자를 추출한 후, 이들을 병치하여 최종 TNIP 영상 특징 서술자를 추출할 수 있다. 이 경우 TNIP 영상 특징 서술자의 크기는 2xC일 수 있다. 여기서 C는 4차원 특징맵의 채널 방향 크 기일 수 있다. 보다 구체적인 특징맵 시공간 풀링 과정은 도 4e를 통해 후술한다. 도 4e는 개별 클립에 대한 시공간 특징 풀링(Spatio-temporal pooling)을 수행하는 구체적인 과정을 도시한 도 면이다. 본 개시에 따른 시공간 특징 풀링 수행 과정은 각 특징맵들에 대해 반복적인 풀링을 수행하는 과정일 수 있다. 구체적으로, 3D Region Square-root Pooling은 시공간 영역 풀링, 스케일 내부 풀링, 멀티스케일 풀링이 순차적으로 진행될 수 있다. 또한, 상기 풀링 과정들은 개별적인 p값에 대응되는 p-norm pooling 연산을 통해 수행될 수 있다. 다만, 본 개시는 상기 풀링 순서에 한정되지 않으며, 시공간 영역 풀링, 스케일 내부 풀 링 또는 멀티스케일 풀링 중 적어도 하나 이상이 수행될 수도 있다. 도 5는 TNIP 특징 추출 절차를 도시한 도면이다. 본 개시에 따른 TNIP 특징 추출은 4가지의 풀링 과정을 포함할 수 있다. 구체적으로, 시공간 영역 풀링(S510), 스케일 내부 풀링(S520), 멀티스케일 풀링(S530) 및 시공간 변환 풀링(S540)이 순차적으로 진행될 수 있다. 도 5를 참고하면, 시공간 영역 풀링(S510)은 사전에 정의된 윈도우 (예를 들어, window(, , ) 를 시공간 축을 따라 스윕(sweep)하면서 풀링을 수행하는 과정이다. 여기서, 상기 윈도우는 2개 이상의 서로 다 른 시공간 윈도우가 사용될 수 있으며, 이 경우 각각의 윈도우에 대해 각각 스윕을 수행할 수 있다. 구체적으로, 주어진 시공간 윈도우에 대한 풀링은 [수학식2]와 같은 p-norm pooling (default: p=2)으로 표현될 수 있다. [수학식2]"}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, , , 는 윈도우의 중심점 위치를 의미한다. 또한, 는 시공간 윈도우의 인덱스를, 그리고 , , 는 번째 윈도우의 너비, 높이, 길이를 의미한다. 스케일 내부 풀링(S520)은 각 시공간 윈도우 인덱스 에 대해 시공간 영역 풀링된 C-차원 벡터들에 다시 p- norm pooling (default: p=∞)를 적용하여 단일한 C-차원 벡터로 결합할 수 있다. 여기서 C는 4차원 특징맵의 채널 방향 크기를 의미한다. 상기 p-norm pooling (default: p=∞)은 [수학식3]으로 표현될 수 있다. [수학식3]"}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, , , 는 윈도우 스윕 인덱스를 의미한다. 상기 스케일 내부 풀링(S520)을 통해, 이후 이 어지는 멀티스케일 풀링(S530)에서 모든 스케일을 동일한 가중치로 고려할 수 있게 된다. 멀티 스케일 풀링(S530)은 스케일 내부 풀링(S520)된 벡터들을 모든 윈도우 스케일에 대해 p-norm pooling (default: p=1)하여 C-차원 벡터를 얻을 수 있다. 상기 p-norm pooling (default: p=1)은 [수학식4]로 표현될 수 있다.[수학식4]"}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, S는 시공간 윈도우 스케일의 개수를 의미한다. 마지막 단계인 시공간 변환 풀링(S540)은 멀티스케일 풀링(S530)된 벡터들을 서로 다른 시공간 변환 인덱스에 대해 p-norm pooling (default: p=∞)하여 최종 TNIP 영상 특징 서술자를 얻을 수 있다. 여기서, p-norm pooling (default: p=∞)은 [수학식5]로 표현될 수 있다. [수학식5]"}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, N은 시공간 변환의 전체 개수를 의미한다. 이 벡터는 추가적으로 차원 축소되거나, 반대로 고차원 공간 에 임베딩(embedding)되어 원하는 크기로 변환될 수 있다. 본 개시의 일 실시예에 따르면, 시공간 변환을 2개 이상의 그룹(group)으로 나눌 수 있는 경우, 상기 장치는 그 룹별로 시공간 풀링을 수행할 수 있다. 이와 같이, 본 개시는 그룹 별로 시공간 풀링을 수행하여 다수의 그룹 TNIP 영상 특징 서술자를 얻을 수 있으며, 이후 이들을 병치(concatenation)하여 최종 TNIP 영상 특징 서술자를 얻을 수 있다. 예를 들면, 상기 장치는 공간 변환 그룹과 시간 변환 그룹에 대해 각각 그룹 TNIP 영상 특징 서 술자를 추출할 수 있다. 각 그룹 TNIP 영상 특징 서술자들은 아래의 [수학식6]에 의해 얻어질 수 있다. 여기서, g는 각 그룹을 의미한다. 이렇게 얻어진 각 그룹의 TNIP 영상 특징 서술자들은 아래의 [수학식7]에 의해 병치 (concatenation)되어 최종 TNIP 영상 특징 서술자를 얻을 수 있다. 이 경우, TNIP 영상 특징 서술자의 크기는 GxC일 수 있다. [수학식6]"}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "[수학식7]"}
{"patent_id": "10-2022-0087969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 9, "content": "도 6은 본 개시에 따른 영상 특징 서술자 추출 장치를 도시한 도면이다. 상기 영상 특징 추출 장치에는 검색 요 청 영상 획득부, 시공간 변환부, 특징맵 추출부 및 TNIP 수행부을 포함할 수 있다. 도 6을 참고하면, 검색 요청 영상 획득부는 상기 장치가 검색 요청 영상을 사용자로부터 획득할 수 있다. 상기 장치가 획득한 검색 요청 영상 전체 또는 일부는 고정된 길이를 가지는 짧은 영상의 모음일 수 있다. 또한, 본 개시에서 말하는 검색 요청 영상은 'Query' 또는 이와 동등한 기술적 의미를 가지는 다른 용어로 지칭 될 수 있다. 또한, 본 개시에서 말하는 짧은 영상은 '클립(clip)' 또는 이와 동등한 기술적 의미를 가지는 다른 용어로 지칭될 수 있다. 시공간 변환부는 상기 장치가 획득한 검색 요청 영상의 시공간 변환을 수행할 수 있다. 검색 요청 영상의 시공간 변환은 미리 정의된 영상 변환 함수 모음을 통해 수행될 수 있다. 또한, 시공간 변환은 공간 변환, 시간 변환 또는 두 변환의 조합 중 하나를 포함할 수 있다. 특징맵 추출부는 상기 시공간 변환된 각 클립들에 대하여 특징맵을 추출할 수 있다. 구체적으로, 상기 시 공간 변환된 각 클립들은 영상 특징 추출 네트워크에 입력될 수 있다. 이때, 상기 영상 특징 추출 네트워크는 모두 동일한 네트워크일 수 있으며, 이에 한정되지 않는다. 이에 따라, 특징맵 추출부는 다수의 4차원 특징맵을 추출할 수 있다. TNIP 수행부는 상기 특징맵에 대하여 TNIP를 수행할 수 있다. 구체적으로, TNIP 수행부는 특징맵들에 TNIP를 적용하여 영상 특징 서술자를 추출할 수 있다. 여기서, TNIP는 특징맵들에 적용되는 반복적인 풀링 작업 일 수 있다. 또한, 상기 반복적인 풀링 작업은 시공간 영역 풀링, 스케일 내부 풀링, 멀티스케일 풀링 및 시공 간 변환 풀링을 순차적으로 진행하는 것을 의미할 수 있다. 다만, 본 개시는 상기 풀링 순서에 한정되지 않으며, 상기 반복적인 풀링 작업은 시공간 영역 풀링, 스케일 내부 풀링, 멀티스케일 풀링 또는 시공간 변환 풀링 중 적어도 하나 이상을 수행하는 것을 의미할 수도 있다. 도 7은 본 개시의 일 실시예에 의한 영상 특징 서술자 추출 기능이 포함된 디바이스의 구성도를 도시한 도 면이다. 관련하여, 도 7의 디바이스는 영상 특징 서술자 추출 기능을 포함하는 다양한 사용자 디바이스 중 하나일 수 있다. 또한, 도 7의 디바이스는 도 1의 서버 또는 사용자 장치(110a, 110b)일 수 있다. 예 를 들어, 도 7의 디바이스는, 스마트폰, 웨어러블 기기, 노트북, PC, 모니터링 장치, 서버 등이 될 수 있 다. 본 개시에 따른 영상 특징 서술자 추출 기능이 포함된 디바이스는 주변 장치, 메모리, 프로세서 및 송수신부를 포함할 수 있다. 이때, 일 예로, 주변 장치는 본 개시에 따른 검색 요청 영상을 입력하기 위한 장치, 시공간 변환을 수행하기 위한 장치, 특징맵 추출을 위한 장치 또는 TNIP 수행을 위한 장치 중 적어도 하나 이상을 포함할 수 있다. 또한, 주변 장치는 그 밖의 장치를 포함할 수 있으며, 상술한 실 시예로 한정되지 않는다. 메모리는 정보를 저장할 수 있는 기억 장치이다. 메모리는 ROM(read only memory) 및 RAM(random access memory)를 포함할 수 있다. 여기서, RAM은 데이터를 불러올 수 있으며, 필요한 일을 처리한 후 변경된 내용을 다시 저장할 수 있다. ROM은 읽기 전용 기억 장치로써, ROM에 저장된 데이터는 영구적 또는 반영구적으 로 보관될 수 있다. 또한, 메모리는 그 밖에 관련 정보들을 저장할 수 있다. 프로세서는 디바이스 내에서 각종 정보를 처리 및/또는 가공하는 기능을 가진 하드웨어이다. 프로세 서는 중앙 처리 장치(central processing unit, CPU), 메모리 및/또는 저장 장치에 저장된 명령을 실행하는 반도체 장치일 수 있다. 예를 들어, 상기 프로세서는 전술한 도 3 내지 도 5에 개시된 영상 특징 서술자 추출 과정을 수행할 수 있다. 송수신부는 메모리에 저장된 정보를 전송할 수 있다. 즉, 송수신부는 데이터나 정보를 송수신하기 위 한 구성일 수 있다. 또한, 데이터 통신에서 다른 장치 또는 시스템과 데이터를 주고받기 위한 데이터 전송 장치 일 수 있다. 송수신부에는 데이터 입출력 장치 또는 통신 제어 장치가 포함될 수 있다. 예를 들어, 송수신 부는 데이터 시스템과 다른 장치들 간의 음성, 영상, 문자 데이터 등의 통신이 가능할 수 있다.도면 도면1 도면2 도면3 도면4a 도면4b 도면4c 도면4d 도면4e 도면5 도면6 도면7"}
{"patent_id": "10-2022-0087969", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 비디오 검색을 위한 영상 특징 서술자 추출 방법을 제공하는 시스템의 구조를 도시한 도면이다. 도 2는 시스템에 적용 가능한 인공 신경망의 구조를 도시한 도면이다. 도 3은 영상 특징 서술자 추출 순서도를 도시한 도면이다. 도 4a는 검색 요청 영상의 공간적 변환 과정을 도시한 도면이다. 도 4b는 검색 요청 영상의 시간적 변환 과정을 도시한 도면이다. 도 4c는 4차원 특징맵 추출 과정을 도시한 도면이다. 도 4d는 TNIP 수행 과정을 도시한 도면이다. 도 4e는 개별 클립에 대한 시공간 특징 풀링(Spatio-temporal pooling)을 수행하는 구체적인 과정을 도시한 도 면이다. 도 5는 TNIP 특징 추출 절차를 도시한 도면이다. 도 6은 영상 특징 서술자 추출 장치를 도시한 도면이다. 도 7은 비디오 검색을 위한 영상 특징 서술자 추출 장치가 적용되는 디바이스 구성도를 도시한 도면이다."}
