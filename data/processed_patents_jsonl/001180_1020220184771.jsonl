{"patent_id": "10-2022-0184771", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0103139", "출원번호": "10-2022-0184771", "발명의 명칭": "인공지능 모델 기반 매립지 침출수 발생량을 예측하는 전자 장치의 제어 방법, 컴퓨터 프로그", "출원인": "강원대학교산학협력단", "발명자": "안종화"}}
{"patent_id": "10-2022-0184771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 제어 방법에 있어서,상기 전자 장치가, 침출수 발생량을 예측하도록 학습된 인공지능 모델에 일정 기간동안 획득된 매립지에 대한데이터를 입력하는 단계; 및상기 전자 장치가, 상기 인공지능 모델의 출력을 바탕으로, 상기 매립지에 대한 침출수 발생량을 획득하는단계;를 포함하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0184771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 인공지능 모델은,폐기물 매립량, 매립가스 발생량, 및 기상 데이터 중 적어도 하나의 입력용 학습 데이터, 및 출력용 학습 데이터인 침출수 발생량을 바탕으로 학습되고,상기 기상 데이터는,강수량, 풍속, 일사량, 온도, 및 상대습도 중 적어도 하나를 포함하는 것을 특징으로 하는, 전자 장치의 제어방법."}
{"patent_id": "10-2022-0184771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 학습 데이터는,일정 주기 별로 선형보간법 및 평균법 중 적어도 하나를 적용하여 획득된, 결측치 및 이상치(outlier) 중 적어도 하나가 제거된 것을 특징으로 하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0184771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 인공지능 모델은,게이트 순환 유닛(gated recurrent unit, GRU)이고,선형보간법이 적용되는 제1 모델; 및평균법이 적용되는 제2 모델; 중 적어도 하나를 포함하는 것을 특징으로 하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0184771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 제1 모델은,입력층(input layer), 노드 300개의 은닉층(hidden layer) 1층, 및 출력층(output layer)을 포함하여, 활성화함수는 eLU(exponential linear unit), 검증분할(validation split)은 0.1, 학습 반복 횟수(epoch)는 25회로구성하면서, 가중치 규제를 통해 과적합을 방지하고,상기 제2 모델은,입력층, 노드 500개의 은닉층 1층, 및 출력층을 포함하여, 활성화 함수는 eLU, 검증분할은 0.1, 학습 반복 횟수공개특허 10-2024-0103139-3-는 25회로 구성하면서, 가중치 규제를 통해 과적합을 방지하는 것을 특징으로 하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0184771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4 항에 있어서,상기 매립지에 대한 데이터를 입력하는 단계는,상기 매립지에 대한 데이터를 상기 제1 모델로 입력하고,상기 침출수 발생량을 획득하는 단계는,상기 침출수 발생량이 임계량을 초과하면, 상기 제2 모델로 상기 매립지에 대한 데이터를 재입력하여, 상기 제2모델로부터 상기 매립지에 대한 침출수 발생량을 재획득하는 것을 특징으로 하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0184771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4 항에 있어서,상기 전자 장치의 제어 방법은,상기 인공지능 모델을 통한, 상기 매립지에 대한 침출수 발생량 예측 횟수가 일정 횟수를 초과하면, 상기 전자장치가, 상기 제1 모델의 출력값을 출력한 제1 횟수, 및 상기 제2 모델의 출력값을 출력한 제2 횟수를 산출하는단계;상기 전자 장치가, 상기 제1 횟수에 상기 제1 모델에 따른 제1 가중치를 적용한 제1 값을 획득하는 단계;상기 전자 장치가, 상기 제2 횟수에 상기 제2 모델에 따른 제2 가중치를 적용한 제2 값을 획득하는 단계;상기 전자 장치가, 상기 제1 값 및 상기 제2 값의 합산 값을 산출하는 단계; 및상기 합산 값이 임계값을 초과하면, 상기 전자 장치가, 상기 상기 매립지에 대해 누적 획득된 데이터를 바탕으로 상기 제1 모델 및 상기 제2 모델을 각각 재학습시키는 단계;를 더 포함하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2022-0184771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "하드웨어인 컴퓨터와 결합되어, 제1 항의 방법을 수행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장된컴퓨터 프로그램."}
{"patent_id": "10-2022-0184771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "폐기물 매립량, 매립가스 발생량, 및 기상 데이터 중 적어도 하나의 입력용 학습 데이터, 및 출력용 학습 데이터인 침출수 발생량을 바탕으로, 침출수 발생량을 예측하도록 훈련된 인공지능 모델을 포함하는, 메모리;적어도 하나의 단말과 통신하는, 통신부; 및상기 메모리, 및 상기 통신부 각각과 연결되는, 프로세서;를 포함하고,상기 프로세서는,상기 통신부를 통해, 매립지에 대해 기 등록된 사용자 단말과 통신하고,상기 사용자 단말로부터, 일정 기간동안 획득된 상기 매립지에 대한 데이터를 획득하면, 상기 매립지에 대한 데이터를 상기 인공지능 모델에 입력하여, 상기 매립지에 대한 침출수 발생량을 획득하는, 전자 장치."}
{"patent_id": "10-2022-0184771", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서,상기 학습 데이터는,일정 주기 별로 선형보간법 및 평균법 중 적어도 하나를 적용하여 획득된, 결측치 및 이상치(outlier) 중 적어도 하나가 제거된 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 인공지능 모델 기반 매립지 침출수 발생량을 예측하는 전자 장치의 제어 방법, 컴퓨터 프로그램, 및 전자 장치에 관한 것으로, 특히, 전자 장치의 제어 방법에 있어서, 전자 장치가, 침출수 발생량을 예측하도록 학 습된 인공지능 모델에 일정 기간동안 획득된 매립지에 대한 데이터를 입력하는 단계, 및 전자 장치가, 인공지능 모델의 출력을 바탕으로, 매립지에 대한 침출수 발생량을 획득하는 단계를 포함한다."}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델 기반 매립지 침출수 발생량을 예측하는 전자 장치의 제어 방법, 컴퓨터 프로그램, 및 전자 장치에 관한 것으로, 상세하게는, 선형보간법이 적용된 시계열 데이터를 사용하여 침출수 발생을 예측하는 GRU 모델이 , , 등 오차지표를 통해 비교하였을 때, 인공지능 모델 중, 가장 적합한 모델임에 따 라, 결측치 및 이상치 처리에 따른 입력 데이터의 GRU 모델 입력 및 그에 대한 출력에 따른 정확한 침출수 발생 량을 예측하는 기술이다."}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "침출수 발생량을 예측하는 것은 침출수 집수 시설 및 처리 시설의 유지 관리에 중요한데, 일반적으로 사용되는 water balance model과 hydraulic evaluation of landfill performance model은 매립지에서 발생하는 물리적, 생화학적 작용 및 기후요인 등 복잡한 과정과 폐기물 특성의 높은 변동성 때문에 예측이 어렵고 복잡하다는 단 점이 있으므로 보다 개선된 예측이 필요하다."}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "한편, 상기의 배경기술로서 설명된 사항들은 본 발명의 배경에 대한 이해 증진을 위한 것일 뿐, 이 기술분야에 서 통상의 지식을 가진 자에게 이미 알려진 종래기술에 해당함을 인정하는 것으로 받아들여져서는 안 될 것이다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2018-0083620호, 2018.07.23."}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 선형보간법을 적용하여 결측치가 제거된 데이터를 바탕으로 인공지능 모델을 학습시킴으로써, 정확한 출력을 획득하는 것이 가능한 인공지능 모델 기반 매립지 침출수 발생량을 예측하는 전 자 장치의 제어 방법, 컴퓨터 프로그램, 및 전자 장치에 관한 것이다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 일 면에 따른 전자 장치의 제어 방법에 있어서, 전자 장치가, 침출수 발생량을 예측하도록 학습된 인공지능 모델에 일정 기간동안 획득된 매립지에 대한 데이터를 입력하는 단계, 및 전자 장치가, 인공지능 모델의 출력을 바탕으로, 매립지에 대한 침출수 발생량을 획득하는 단계를 포함한다. 추가로, 인공지능 모델은, 폐기물 매립량, 매립가스 발생량, 및 기상 데이터 중 적어도 하나의 입력용 학습 데 이터, 및 출력용 학습 데이터인 침출수 발생량을 바탕으로 학습되고, 기상 데이터는, 강수량, 풍속, 일사량, 온 도, 및 상대습도 중 적어도 하나를 포함하는 것을 특징으로 할 수 있다. 추가로, 학습 데이터는, 일정 주기 별로 선형보간법 및 평균법 중 적어도 하나를 적용하여 획득된, 결측치 및 이상치(outlier) 중 적어도 하나가 제거된 것을 특징으로 할 수 있다. 추가로, 인공지능 모델은, 게이트 순환 유닛(gated recurrent unit, GRU)이고, 선형보간법이 적용되는 제1 모델, 및 평균법이 적용되는 제2 모델, 중 적어도 하나를 포함하는 것을 특징으로 할 수 있다. 추가로, 제1 모델은, 입력층(input layer), 노드 300개의 은닉층(hidden layer) 1층, 및 출력층(output laye r)을 포함하여, 활성화 함수는 eLU(exponential linear unit), 검증분할(validation split)은 0.1, 학습 반복 횟수(epoch)는 25회로 구성하면서, 가중치 규제를 통해 과적합을 방지하고, 제2 모델은, 입력층, 노드 500개의 은닉층 1층, 및 출력층을 포함하여, 활성화 함수는 eLU, 검증분할은 0.1, 학습 반복 횟수는 25회로 구성하면서,가중치 규제를 통해 과적합을 방지하는 것을 특징으로 할 수 있다. 추가로, 매립지에 대한 데이터를 입력하는 단계는, 매립지에 대한 데이터를 상기 제1 모델로 입력하고, 침출수 발생량을 획득하는 단계는, 침출수 발생량이 임계량을 초과하면, 제2 모델로 매립지에 대한 데이터를 재입력하 여, 제2 모델로부터 매립지에 대한 침출수 발생량을 재획득하는 것을 특징으로 할 수 있다. 추가로, 전자 장치의 제어 방법은, 인공지능 모델을 통한, 매립지에 대한 침출수 발생량 예측 횟수가 일정 횟수 를 초과하면, 전자 장치가, 제1 모델의 출력값을 출력한 제1 횟수, 및 제2 모델의 출력값을 출력한 제2 횟수를 산출하는 단계, 전자 장치가, 제1 횟수에 제1 모델에 따른 제1 가중치를 적용한 제1 값을 획득하는 단계, 전자 장치가, 제2 횟수에 제2 모델에 따른 제2 가중치를 적용한 제2 값을 획득하는 단계, 전자 장치가, 제1 값 및 제 2 값의 합산 값을 산출하는 단계, 및 합산 값이 임계값을 초과하면, 전자 장치가, 매립지에 대해 누적 획득된 데이터를 바탕으로 제1 모델 및 제2 모델을 각각 재학습시키는 단계를 더 포함할 수 있다. 본 발명은, 하드웨어인 컴퓨터와 결합되어, 본 발명에 따른 전자 장치의 제어 방법을 수행할 수 있도록 컴퓨터 에서 독출가능한 기록매체에 저장된 컴퓨터 프로그램을 포함한다. 본 발명은, 폐기물 매립량, 매립가스 발생량, 및 기상 데이터 중 적어도 하나의 입력용 학습 데이터, 및 출력용 학습 데이터인 침출수 발생량을 바탕으로, 침출수 발생량을 예측하도록 훈련된 인공지능 모델을 포함하는, 메모 리, 적어도 하나의 단말과 통신하는, 통신부, 및 메모리, 및 통신부 각각과 연결되는, 프로세서를 포함하고, 프 로세서는, 통신부를 통해, 매립지에 대해 기 등록된 사용자 단말과 통신하고, 사용자 단말로부터, 일정 기간동 안 획득된 매립지에 대한 데이터를 획득하면, 매립지에 대한 데이터를 인공지능 모델에 입력하여, 매립지에 대 한 침출수 발생량을 획득하는, 전자 장치를 포함한다. 추가로, 학습 데이터는, 일정 주기 별로 선형보간법 및 평균법 중 적어도 하나를 적용하여 획득된, 결측치 및 이상치(outlier) 중 적어도 하나가 제거된 것을 특징으로 할 수 있다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 인공지능 모델 기반 매립지 침출수 발생량을 예측하는 전자 장치의 제어 방법, 컴퓨터 프로그램, 및 전자 장치에 의하면, 선형보간법을 사용하여 데이터 부족 및 누락에도 효과적인 대응이 가능하고 인자 간의 비 선형적 관계의 표현이 가능해지고, 침출수 발생량의 예측을 통해 효과적인 침출수 관리가 가능하고 침출수 집수 시설 및 처리시설의 유지 관리뿐만 아니라 저류조의 규모와 펌프 용량을 산정할 때 활용할 수 있고, 선형보간법 이 적용된 GRU 모델은 데이터 부족에도 효과적인 대응이 가능할 뿐만 아니라 보다 정확한 침출수 발생량을 예측 이 가능하므로 침출수 저장 및 처리시 효율적인 침출수 관리가 가능하며, 특히 매립지 관리 및 폐기물처리의 중 요성이 커지므로 이에 대한 수요가 증가할 것이다."}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 명세서에서 사용되는 \"부\" 또는 “모듈”이라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소 를 의미하며, \"부\" 또는 “모듈”은 어떤 역할들을 수행한다. 그렇지만 \"부\" 또는 “모듈”은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. \"부\" 또는 “모듈”은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수 도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\" 또는 “모 듈”은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라 이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 \"부\" 또는 “모듈”들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 \"부\" 또는 “모듈”들로 결합되거나 추가적인 구성요소들과 \"부\" 또는 “모듈”들로 더 분리될 수 있다. 공간적으로 상대적인 용어인 \"아래(below)\", \"아래(beneath)\", \"하부(lower)\", \"위(above)\", \"상부(upper)\" 등 은 도면에 도시되어 있는 바와 같이 하나의 구성요소와 다른 구성요소들과의 상관관계를 용이하게 기술하기 위 해 사용될 수 있다. 공간적으로 상대적인 용어는 도면에 도시되어 있는 방향에 더하여 사용시 또는 동작시 구성 요소들의 서로 다른 방향을 포함하는 용어로 이해되어야 한다. 예를 들어, 도면에 도시되어 있는 구성요소를 뒤 집을 경우, 다른 구성요소의 \"아래(below)\"또는 \"아래(beneath)\"로 기술된 구성요소는 다른 구성요소의 \"위 (above)\"에 놓일 수 있다. 따라서, 예시적인 용어인 \"아래\"는 아래와 위의 방향을 모두 포함할 수 있다. 구성요 소는 다른 방향으로도 배향될 수 있으며, 이에 따라 공간적으로 상대적인 용어들은 배향에 따라 해석될 수 있다. 본 명세서에서, 컴퓨터는 적어도 하나의 프로세서를 포함하는 모든 종류의 하드웨어 장치를 의미하는 것이고, 실시 예에 따라 해당 하드웨어 장치에서 동작하는 소프트웨어적 구성도 포괄하는 의미로서 이해될 수 있다. 예 를 들어, 컴퓨터는 스마트폰, 태블릿 PC, 데스크톱, 노트북 및 각 장치에서 구동되는 사용자 클라이언트 및 애 플리케이션을 모두 포함하는 의미로서 이해될 수 있으며, 또한 이에 제한되는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치 구성도이다. 도 1에 도시된 바와 같이, 전자 장치는 폐기물 매립량, 매립가스 발생량, 및 기상 데이터 중 적어도 하나 의 입력용 학습 데이터, 및 출력용 학습 데이터인 침출수 발생량을 바탕으로, 침출수 발생량을 예측하도록 훈련 된 인공지능 모델을 포함하는, 메모리, 적어도 하나의 단말과 통신하는, 통신부, 및 메모리, 및 통신부 각각과 연결되는, 프로세서를 포함할 수 있다. 일 실시예로, 전자 장치는, 서버, 스마트폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전 화기(mobile phone), 영상 전화기, 랩탑 PC(laptop PC), 넷북 컴퓨터(netbook computer), 노트북 컴퓨터 (notebook computer), 웨어러블 장치(wearable device) 중 적어도 하나를 포함할 수 있다. 한편, 메모리는 전자 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리(11 0)는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브 (HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 통신부는 외부 장치와 통신을 수행할 수 있다. 특히, 통신부는 와이파이 칩, 블루투스 칩, 무선 통신 칩, NFC칩, 저전력 블루투스 칩(BLE 칩) 등과 같은 다양한 통신 칩을 포함할 수 있다. 이때, 와이파이 칩, 블루 투스 칩, NFC 칩은 각각 LAN 방식, WiFi 방식, 블루투스 방식, NFC 방식으로 통신을 수행한다. 와이파이 칩이나블루투스칩을 이용하는 경우에는 SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신 하여, 이를 이용하 여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 무선 통신칩은 IEEE, 지그비, 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), 5G(5th Generation) 등과 같은 다양 한 통신 규격에 따라 통신을 수행하는 칩을 의미한다. 프로세서는 메모리에 저장된 각종 프로그램을 이용하여 전자 장치의 전반적인 동작을 제어할 수 있다. 프로세서는 RAM, ROM, 그래픽 처리부, 메인 CPU, 제1 내지 n 인터페이스 및 버스로 구성될 수 있다. 이때, RAM, ROM, 그래픽 처리부, 메인 CPU, 제1 내지 n 인터페이스 등은 버스를 통해 서로 연결될 수 있다. RAM은 O/S 및 어플리케이션 프로그램을 저장한다. 구체적으로, 전자 장치가 부팅되면 O/S가 RAM에 저장되 고, 사용자가 선택한 각종 어플리케이션 데이터가 RAM에 저장될 수 있다. ROM에는 시스템 부팅을 위한 명령어 세트 등이 저장된다. 턴 온 명령이 입력되어 전원이 공급되면, 메인 CPU는 ROM에 저장된 명령어에 따라 메모리에 저장된 O/S를 RAM에 복사하고, O/S를 실행시켜 시스템을 부팅시킨다. 부팅이 완료되면, 메인 CPU는 메모리에 저장된 각종 어플리케이션 프로그램을 RAM에 복사하고, RAM에 복사된 어플리케이션 프로그램을 실행시켜 각종 동작을 수행한다. 그래픽 처리부는 연산부(미도시) 및 렌더링부(미도시)를 이용하여 아이템, 이미지, 텍스트 등과 같은 다양한 객 체를 포함하는 화면을 생성한다. 여기서, 연산부는 입력부로부터 수신된 제어 명령을 이용하여 화면의 레이아웃 에 따라 각 객체들이 표시될 좌표값, 형태, 크기, 컬러 등과 같은 속성값을 연산하는 구성일 수 있다. 그리고, 렌더링부는 연산부에서 연산한 속성값에 기초하여 객체를 포함하는 다양한 레이아웃의 화면을 생성하는 구성이 일 수 있다. 이러한 렌더링부에서 생성된 화면은 디스플레이의 디스플레이 영역 내에 표시될 수 있다. 메인 CPU는 메모리에 액세스하여, 메모리에 저장된 OS를 이용하여 부팅을 수행한다. 그리고, 메인 CPU는 메모리에 저장된 각종 프로그램, 컨텐츠, 데이터 등을 이용하여 다양한 동작을 수행한다. 제1 내지 n 인터페이스는 상술한 각종 구성요소들과 연결된다. 제1 내지 n 인터페이스 중 하나는 네트워크를 통 해 외부 장치와 연결되는 네트워크 인터페이스가 될 수도 있다. 한편, 나아가, 프로세서는 인공지능 모델을 제어할 수 있다. 이 경우, 프로세서는 인공지능 모델을 제어하기 위 한 그래픽 전용 프로세서(예: GPU)를 포함할 수 있음은 물론이다. 한편, 본 발명에 따른 인공지능 모델은 지도학습(supervised learning) 또는 비지도학습(unsupervised learning)기반의 모델일 수 있다. 나아가, 본 발명에 따른 인공지능 모델은 SVM(support vector machine), Decision tree, neural network, RF(Random Forest) 등 및 이들이 응용된 방법론을 포함할 수 있다. 일 실시예로, 본 발명에 따른 인공지능 모델은 학습데이터를 입력하여 학습된 합성곱 신경망(Convolutional deep Neural Networks, CNN) 기반의 인공지능 모델일 수 있다. 다만, 이에 한정되는 것은 아니며, 다양한 인공 지능 모델이 본 발명에 적용될 수 있음은 물론이다. 예컨대, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델이 인공지능 모델로서 사용될 수 있으나, 이에 한정되지 않는다. 이때, 합성곱 신경망(Convolutional deep Neural Networks, CNN)은 최소한의 전처리(preprocess)를 사용하도록 설계된 다계층 퍼셉트론(multilayer perceptrons)의 한 종류이다. 합성곱 신경망은 하나 또는 여러개의 합성곱 계층(convolutional layer)과 그 위에 올려진 일반적인 인공신경망 계층들로 이루어져 있으며, 가중치와 통합 계층(pooling layer)들을 추가로 활용한다. 이러한 구조 덕분에 합성곱 신경망은 2차원 구조의 입력 데이터를 충분히 활용할 수 있다. 또한, 합성곱 신경망은 표준 역전달을 통해 훈련될 수 있다. 합성곱 신경망은 다른 피 드포워드 인공신경망 기법들보다 쉽게 훈련되는 편이고 적은 수의 매개변수를 사용한다는 이점이 있다. 또한, 심층 신경망(Deep Neural Networks, DNN)은 입력 계층(input layer)과 출력 계층(output layer) 사이에 복수개의 은닉 계층(hidden layer)들로 이뤄진 인공신경망(Artificial Neural Network, ANN)이다. 이때, 심층 신경망의 구조는 퍼셉트론(perceptron)으로 구성될 수 있다. 퍼셉트론은 여러 개의 입력 값(input) 과 하나의 프로세서(prosessor), 하나의 출력 값으로 구성된다. 프로세서는 여러 개의 입력 값에 각각 가중치를 곱한 후, 가중치가 곱해진 입력 값들을 모두 합한다. 그 다음 프로세서는 합해진 값을 활성화함수에 대입하여 하나의 출력 값을 출력한다. 만약 활성화함수의 출력 값으로 특정한 값이 나오기를 원하는 경우, 각 입력 값에 곱해지는 가중치를 수정하고, 수정된 가중치를 이용하여 출력 값을 다시 계산할 수 있다. 이때, 각각의 퍼셉트 론은 서로 다른 활성화함수를 사용할 수 있다. 또한 각각의 퍼셉트론은 이전 계층에서 전달된 출력들을 입력으로 받아들인 다음, 활성화 함수를 이용해서 출력을 구한다. 구해진 출력은 다음 계층의 입력으로 전달된다. 상 술한 바와 같은 과정을 거치면 최종적으로 몇 개의 출력 값을 얻을 수 있다. 순환 신경망(Reccurent Neural Network, RNN)은 인공신경망을 구성하는 유닛 사이의 연결이 Directed cycle을 구성하는 신경망을 말한다. 순환 신경망은 앞먹임 신경망과 달리, 임의의 입력을 처리하기 위해 신경망 내부의 메모리를 활용할 수 있다. 장단기 메모리(Long Short-Term Memory, LSTM)는 순환 신경망 기법의 하나로 셀, 입력 게이트, 출력 게이트, 망 각 게이트를 이용해 기존 순환 신경망의 문제인 기울기 소멸 문제(vanishing gradient problem)를 방지하도록 개발되었다. 게이트 순환 유닛(Gated Recurrent Unit, GRU)은 장단기 메모리의 장기 의존성 문제에 대한 해결책을 유지하면 서, 은닉 상태를 업데이트하는 계산을 줄여, 업데이트 게이트와 리셋 게이트 두 가지 게이트만이 존재함에 따라, 성능은 장단기 메모리과 유사하면서 복잡했던 장단기 메모리의 구조를 간단화 한 것이다. 심층 신뢰 신경망(Deep Belief Networks, DBN)이란 기계학습에서 사용되는 그래프 생성 모형(generative graphical model)으로, 딥 러닝에서는 잠재변수(latent variable)의 다중계층으로 이루어진 심층 신경망을 의미 한다. 계층 간에는 연결이 있지만 계층 내의 유닛 간에는 연결이 없다는 특징이 있다. 심층 신뢰 신경망은 생성 모형이라는 특성상 선행학습에 사용될 수 있고, 선행학습을 통해 초기 가중치를 학습 한 후 역전파 혹은 다른 판별 알고리즘을 통해 가중치의 미조정을 할 수 있다. 이러한 특성은 훈련용 데이터가 적을 때 굉장히 유용한데, 이는 훈련용 데이터가 적을수록 가중치의 초기값이 결과적인 모델에 끼치는 영향이 세지기 때문이다. 선행학습된 가중치 초기값은 임의로 설정된 가중치 초기값에 비해 최적의 가중치에 가깝게 되 고 이는 미조정 단계의 성능과 속도향상을 가능케 한다. RF는, 분류, 회기 분석 등에 사용되는 앙상블 학습 방법의 일종으로, 훈련 과정에서 구성한 다수의 결정 트리로 부터 분류 또는 평균 예측치(회귀 분석)를 출력함으로써 동작하며, 가장 큰 특징은 랜덤성(randomness)에 의해 트리들이 서로 조금씩 다른 특성을 갖는다는 점이다. 이 특성은 각 트리들의 예측(prediction)들이 비상관화 (decorrelation) 되게하며, 결과적으로 일반화(generalization) 성능을 향상시킨다. 또한, 랜덤화 (randomization)는 포레스트가 노이즈가 포함된 데이터에 대해서도 강인하게 만들어 준다. 랜덤화는 각 트리들 의 훈련 과정에서 진행되며, 랜덤 학습 데이터 추출 방법을 이용한 앙상블 학습법인 배깅(bagging)과 랜덤 노드 최적화(randomized node optimization)가 자주 사용된다. 이 두 가지 방법은 서로 동시에 사용되어 랜덤화 특성 을 더욱 증진시킬 수 있다. 상술한 인공지능 및 그 학습방법에 관한 내용은 예시를 위하여 서술된 것이며, 상술한 실시 예들에서 이용되는 인공지능 및 그 학습방법은 제한되지 않는다. 예를 들어, 당 업계의 통상의 기술자가 동일한 과제해결을 위하여 적용할 수 있는 모든 종류의 인공지능 기술 및 그 학습방법이 개시된 실시 예에 따른 시스템을 구현하는 데 활 용될 수 있다. 한편, 프로세서는 하나 이상의 코어(core, 미도시) 및 그래픽 처리부(미도시) 및/또는 다른 구성 요소와 신호를 송수신하는 연결 통로(예를 들어, 버스(bus) 등)를 포함할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 본 발명과 관련하여 설명된 방법을 수행한다. 예를 들어, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써 신규 학습용 데이터 를 획득하고, 학습된 모델을 이용하여, 상기 획득된 신규 학습용 데이터에 대한 테스트를 수행하고, 상기 테스 트 결과, 라벨링된 정보가 소정의 제1 기준값 이상의 정확도로 획득되는 제1 학습용 데이터를 추출하고, 상기 추출된 제1 학습용 데이터를 상기 신규 학습용 데이터로부터 삭제하고, 상기 추출된 학습용 데이터가 삭제된 상 기 신규 학습용 데이터를 이용하여 상기 학습된 모델을 다시 학습시킬 수 있다. 한편, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저 장하는 램(RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포함할 수 있다. 또한, 프로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템온칩(SoC: system on chip) 형태로 구현될 수 있다. 메모리에는 프로세서의 처리 및 제어를 위한 프로그램들(하나 이상의 인스트럭션들)을 저장할 수 있 다. 메모리에 저장된 프로그램들은 기능에 따라 복수 개의 모듈들로 구분될 수 있다. 도 2는 본 개시의 일 실시예에 따른 시스템 구성도이다. 사용자 단말은, 전자 장치이 거나, 전자 장치와는 별개의, 매립지에 대해 기 등록된 전자 장치 일 수 있으며, 이 경우, 도 2에 도시된 바와 같이, 전자 장치는, 통신부를 통해, 매립지에 대해 기 등록된 사용자 단말과 통신하고, 사용자 단말로부터, 일정 기간동안 획득된 매립지에 대한 데이터를 획득하면, 매립지에 대한 데이터를 인공지능 모델에 입력하여, 매립지에 대한 침출수 발생량을 획득할 수 있다. 사용자 단말은, 데이터의 입력 및 출력을 위한 입출력 모듈을 포함할 수 있으며, 입출력 모듈은 키보드, 마우스, 리모컨, 디스플레이 등을 포함할 수 있다. 디스플레이는 다양한 정보를 시각적으로 출력하기 위한 구성이다. 디스플레이는 LCD(Liquid Crystal Display), PDP(Plasma Display Panel), OLED(Organic Light Emitting Diodes), TOLED(Transparent OLED), Micro LED 등으로 구현될 수 있으나, 이에 한정되는 것은 아니고 이밖에 종래 알려진 다양한 형태의 디스플레이를 포함할 수 있다. 디스플레이는, 사용자의 터치 조작을 감지할 수 있는 터치스크린 형태로 구현될 수 있으며, 접히거나 구부러질 수 있는 플렉서블 디스플레이로 구현될 수도 있다. 도 3은 본 개시의 일 실시예에 따른 기본 흐름도이다. 도 3에 도시된 바와 같이, 전자 장치는, 침출수 발생량을 예측하도록, 폐기물 매립량, 매립가스 발생량, 및 기상 데이터 중 적어도 하나의 입력용 학습 데이터, 및 출력용 학습 데이터인 침출수 발생량을 바탕으로 학 습된 인공지능 모델에 일정 기간동안 획득된 매립지에 대한 데이터를 입력(S310)하여, 인공지능 모델의 출력을 바탕으로, 매립지에 대한, 예측된 침출수 발생량을 획득(S320)할 수 있다. 일정 기간동안 획득된 매립지에 대한 데이터는, 일정 기간 동안 각각 누적 획득된, 폐기물 매립량, 매립가스 발 생량, 및 기상 데이터 중 적어도 하나의 데이터이다. 기상 데이터는, 강수량, 풍속, 일사량, 온도, 및 상대습도 중 적어도 하나를 포함할 수 있다. 한편, 전자 장치는, 학습 데이터를 입력하여 인공지능 모델을 학습시키는데 있어서, 일정 주기(ex. 주, 월, 년 등) 별로 획득된 학습 데이터에 선형보간법 및 평균법 중 적어도 하나를 적용함으로써, 결측치 및 이상 치(outlier) 중 적어도 하나가 획득되면, 획득된 값을 제거한 학습 데이터를 인공지능 모델에 입력할 수 있다. 이때, 인공지능 모델은, 게이트 순환 유닛(gated recurrent unit, GRU)이다. 또한, 인공지능 모델은, 선형보간법이 적용되는 제1 모델, 및 평균법이 적용되는 제2 모델, 중 적어도 하나를 포함할 수 있다. 예컨대, 전자 장치에 의해, 결측치 및 이상치 제거를 위해 선형보간법이 적용된 입력 데이터는 제1 모델에 입력되고, 평균법이 적용된 입력 데이터는 제2 모델에 입력될 수 있다. 제1 모델은, 입력층(input layer), 노드 300개의 은닉층(hidden layer) 1층, 및 출력층(output layer)을 포함 하여, 활성화 함수는 eLU(exponential linear unit), 검증분할(validation split)은 0.1, 학습 반복 횟수 (epoch)는 25회로 구성하면서, 가중치 규제를 통해 과적합을 방지할 수 있다. 제2 모델은, 입력층, 노드 500개의 은닉층 1층, 및 출력층을 포함하여, 활성화 함수는 eLU, 검증분할은 0.1, 학 습 반복 횟수는 25회로 구성하면서, 가중치 규제를 통해 과적합을 방지할 수 있다. 이에 따라, 단계 S310을 수행함에 있어서, 전자 장치는, 선형보간법에 의해 결측치 및 이상치가 제거된, 매립지에 대한 데이터를 제1 모델에 입력할 수 있다. 이때, 단계 S320을 수행함에 있어서, 제1 모델의 출력에 따라 획득된 침출수 발생량이 임계량를 초과하는 경우, 평균법에 의해 결측치 및 이상치가 제거된, 매립지에 대한 데이터를 제2 모델에 재입력하여, 제2 모델의 출력을 바탕으로, 매립지에 대한 침출수 발생량을 재획득할 수 있다. 실시예로, 전자 장치는, 제1 모델의 출력 및 제2 모델의 출력을 비교할 수 있다. 구체적으로, 제1 모델 및 제2 모델 각각에 의해 예측된 침출수 발생량의 차이가 임계차를 초과하되, 제2 모델의 출력이 매립지의 실제 침출수 발생량과의 오차가 임계 오차 미만인 경우, 전자 장치는, 예측된 침출수 발 생량의 입력 데이터를 저장할 수 있다.이후, 저장된 입력 데이터에 포함된 각각의 데이터와의 오차가 일정 오차 미만인, 저장된 입력 데이터에 포함된 각각의 데이터와 유사한 데이터들이 획득되면, 전자 장치는, 획득된 유사한 데이터들을 제1 모델이 아닌, 제2 모델에 입력함으로써, 하나의 입력 데이터의 재입력에 따라 발생하는, 인공지능 모델의 2회 판단에 의한 로 드를 줄일 수 있다. 실시예로, 단계 S320을 수행함에 있어서, 제2 모델로부터 획득된 침출수 발생량이 일정 양을 초과하는 경우, 전 자 장치는, 매립지에 대해 기 등록된 사용자 단말을 통해 사용자에게 예측된 침출수 발생량을 제공하고, 사용자 입력에 따라 사용자 단말을 통해, 침출수의 처리 여부에 대한 정보인, 처리 정보를 획득할 수 있다. 처리 정보가 획득되면, 전자 장치는, 매립지에 대한 데이터를 수집하는 일정 기간을, 처리 정보가 발생한 시점으로부터 설정하여, 예측을 위한 데이터의 수집 기간을 리셋하는 것이 가능하다. 이때, 일정 양은, 매립지에 대한 데이터가 수집되는 일정 기간 별로 침출수를 처리하는, 처리량에 비례하거나 동일한 값일 수 있으며, 처리 정보는, 일정 기간에 따른 것이 아닌, 별도의 처리에 따라 침출수가 처리된 양, 해당 처리가 수행된 시점 등을 포함할 수 있다. 한편, 인공지능 모델을 통한, 매립지에 대한 침출수 발생량 예측 횟수가 일정 횟수를 초과하면, 전자 장치(10 0)는, 제1 모델의 출력값을 출력한 제1 횟수, 및 제2 모델의 출력값을 출력한 제2 횟수를 산출할 수 있다. 이에 따라, 전자 장치는, 제1 횟수에 제1 모델에 따른 제1 가중치를 적용한 제1 값, 및 제2 횟수에 제2 모 델에 따른 제2 가중치를 적용한 제2 값을 획득하여, 제1 값 및 제2 값의 합산 값을 산출할 수 있다. 이때, 합산 값이 임계값을 초과하면, 전자 장치는, 매립지에 대해 누적 획득된 데이터를 바탕으로 제1 모 델 및 제2 모델을 각각 재학습시킬 수 있다. 여기서, 제1 횟수를 산출함에 있어서, 전자 장치는, 제1 모델 및 제2 모델 각각을 통해 출력이 중복으로 획득된 일 입력 데이터인, 중복 데이터가 적어도 하나 식별되면, 중복 데이터가 발생한 횟수를 제1 횟수에 감산 적용하여, 감산된 제3 횟수를 획득할 수 있다. 이에 따라, 제1 값을 획득함에 있어서, 전자 장치는 제3 횟수에 제1 가중치를 적용한 제3 값을 획득하여, 제3 값과의 합산 값을 산출할 수 있다. 한편, 본 발명은, 하드웨어인 컴퓨터와 결합되어, 본 발명에 따른 전자 장치의 제어 방법을 수행할 수 있 도록 컴퓨터에서 독출가능한 기록매체에 저장된 컴퓨터 프로그램을 포함한다. 도 4 내지 도 14는 본 개시의 일 실시예에 따른 출력 비교에 따른 인공지능 모델 선정과 관련한 도면이다. 구체적으로, 도 4는 Summary of daily input parameters, 도 5는 Performance comparison of random forest, artificial neural network, long short-term memory, and gated recurrent unit according to missing value handling techniques, 도 6은 Prediction results of landfill leachate generation for test dataset using random forest, artificial neural network, long short-term memory, and gated recurrent unit with linear interpolation and mean method, 도 7은 Comparison of previous studies on machine learning-based models for forecasting landfill leachate generation, 도 8은 A photo of the Incheon landfill site 2 in Korea, 도 9 내지 10은 Structure of (a) random forest, (b) artificial neural network, (c) long short-term memory, and (d) gated recurrent unit, 도 11 내지 도 14는 Prediction results of landfill leachate generation for test dataset using random forest, artificial neural network, long short-term memory, and gated recurrent unit with linear interpolation and mean method에 관한 것이다. 이하, 출력 비교에 따른 인공지능 모델 선정과 관련한 실험 과정 및 실험 결과를 설명한다. 침출수 발생량 예측에는 일반적으로 water balance model과 hydraulic evaluation of landfill performance model를 적용하고 있다. 하지만 침출수는 매립지에서 발생하는 물리적, 생화학적 작용 및 기후요인 등 복잡한 과정과 폐기물 특성에 따른 높은 변동성 때문에 기계학습, 심층학습 등 인공지능을 적용한 데이터 기반 예측모 델을 사용하여 모델링을 개선하고 높은 예측값을 보이고 있다. 랜덤 포레스트와 게이트 순환 유닛을 사용한 매 립지 침출수 발생량 예측 사례는 찾을 수 없었다. 한편, 데이터의 형상에 따라 전처리 방식이 필요할 수 있으며 누락 데이터가 있거나 측정인자간의 시간 차이가 존재하는 경우 결측치 처리방식(missing value handling technique)을 사용할 수 있다. 결측치 처리방식으로는 평균을 계산하여 대체하는 평균법(mean), 중앙값을 이용하여 대체하는 방법, 2개의 인접한 데이터를 줬을 때 임의적인 직선을 가정하여 계산하는 방법인 선형보간법(linear interpolation), 전체구간을 소구간 별로 나누어 다항식으로 매끄러운 함수를 구하는 방법인 스플라인 보간법(spline interpolation) 등이 사용되고 있다. 보간 법은 수치 분석 및 수학적 분야에서 유용하게 사용되는 추정의 한 기법으로, 알려진 데이터를 기반으로 하여 새 로운 데이터를 구성하는 방법이다. 이는 누락된 데이터가 있는 공간 또는 시간 데이터를 유추하는 데 유용하게 사용된다. 하지만, 선형보간법으로 전처리하여 침출수 발생량을 예측하는 사례는 확인할 수 없었다. 선형보간법은 사용 데 이터의 양을 늘려 모델의 성능 향상에 기여할 수 있다. 본 실험에서는 침출수 발생량 예측을 위한 최적 모델을 제시하기 위하여 선형보간법과 평균법을 이용하여 RF, ANN, LSTM, GRU 등의 모델을 이용하였다. 실험방법 데이터 설정과 입력인자 본 실험은 도 8에 도시된 바와 같이, 인천광역시 서구에 위치하는 수도권매립지관리공사에서 관리 중인 매립이 완료된 제2매립지를 대상으로 하였다. 침출수를 예측하기 위해 침출수 발생량, 폐기물 매립량, 매립가스 발생량, 기상데이터(강수량, 풍속, 일사량, 온도, 상대습도)를 입력인자로 사용하였다. 기상데이터는 기상청 산 하 기상자료개방 포털을 이용하여 본 실험 지점에 인접한 인천광역시 중구 인천기상대 종관기상관측(automated synoptic observing system) 데이터를 사용하였다. 침출수 발생량, 폐기물 매립량, 매립가스 발생량 데이터는 수도권매립지관리공사 통계연감 데이터를 사용하였다. 매립시작은 2000년 10월 13일이지만 가스발생량 데이터를 2002년 6월부터 받아 모든 입력데이터의 사용 기간을 2002년 6월 1일부터 2018년 10월 31일로 하였다. 선행연구 와 예비 실험을 기반으로 최종 입력인자를 선정하여 실험을 진행하였으며 최종 입력인자로는, 도 4 및 도 5에 도시된 바와 같은, 침출수 발생량, 폐기물 매립량, 매립가스 발생량, 강수량, 풍속, 일사량, 온도, 상대습도 등 8가지를 이용하였다. 데이터 전처리 인공지능 모델에 사용되는 데이터는 예측에 있어 중요한 부분을 차지한다. 하지만 입력인자로 사용되는 데이터 는 상황에 따라 기계 고장, 유지보수, 관측기구의 위치변경, 인적오류 등에 의해 결측값을 가질 수 있다. 이럴 때 연속 데이터를 요구하는 시계열 예측 방식에 어려움을 가져올 수 있다. 이러한 문제를 해결하기 위해 결측치 처리방식을 이용할 수 있다. 본 실험에서는 폐기물 매립량과 매립가스 발생량은 월별로 선형적으로 연결하여 일 일 결측치를 추정하는 선형보간법과 월간 데이터를 일일 평균값으로 계산하여 사용한 평균법을 사용하였다. 일 부 결측값과 이상치(outlier)는 제거하였다. 선형보간법 선형보간법은 1차 보간법이라고도 하며, 두 개의 점이 주어졌을 때 그 두 점을 지나는 함수를 직선의 방정식으 로 나타내는 것을 말한다(수학식 1) 점 사이의 간격이 작을수록 더욱 정확한 근사해를 얻을 수 있다. 수학식 1"}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 는 독립 변수의 집합이고, 과 는 알고 있는 독립 변수, 는 에 대한 종속 변수이다. 평균법 설정된 구간의 합을 데이터 개수로 나누어 모든 데이터의 평균값으로 전환한다(수학식 2) 본 실험에서는 한 달 간격으로 평균법을 실시하였다.수학식 2"}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 은 데이터의 개수, 는 개별 데이터의 값, 는 개별 데이터의 합을 데이터의 개수로 나눈 값이다. 기계학습 및 심층학습 모델 랜덤포레스트 랜덤포레스트는 Breiman에 의해 제안된 앙상블 모델로, 도 9의 (a)와 같이, 일반적인 의사결정 나무 모델과 다 르게 하나의 나무를 사용하지 않고 여러 개의 나무를 사용하여 기계학습을 진행한다. 전체 데이터 중 일부 데이 터를 무작위로 중복 추출하고(bagging) 데이터를 여러 개로 구성하여 임의성을 가지게 된다. 이를 통해 일반화 성능이 향상되고 분산을 감소시켜 과적합(overfitting)을 방지하는 데 도움을 준다. 따라서, 트리 개수를 수정 하며 해당 모델에 적합하도록 최적화를 진행하였다 인공신경망 도 9의 (b)에 도시된, ANN은 인간의 뇌를 모방하여 인간의 사고방식을 컴퓨터에 학습시키는 알고리즘으로 뇌의 기본단위인 뉴런과 유사하다. 이는 연결된 노드의 뉴런들로부터 정보를 받아 고유한 방식으로 처리하는 모델로 McCulloch와 Pitts가 최초의 인공신경망 구조를 제안하였으며 Rosenblatt은 여기에 퍼셉트론을 이용한 신경망으 로 발전시켰다. 이 모델은 입력층(input layer), 은닉층(hidden layer), 출력층(output layer)에서 여러 가지 하이퍼파라미터의 상호작용을 통해 작동하며 모든 은닉층을 통과하여 하나의 출력층을 통과 후 최종결과를 도출 한다. 장단기메모리 도 10의 (c)에 도시된, LSTM은 Hochreiter와 Schmidhuber에 의해 고안되었으며 기존 순환신경망의 장기화 예측 에 한계점의 원인인 경사 하강 소실 문제(gradient vanishing)를 해결할 수 있다는 장점이 있다. 셀은 망각 게 이트, 입력 게이트, 출력 게이트의 세 가지 게이트로 구성되어 있다. 첫 번째 단계인 망각 게이트의 연산은 셀 상태 는 이전 상태 과 입력값 을 보고 어떤 정보를 버릴지 시그모이드 함수로 계산하여 결정한다. 그 후 입력 게이트에서 시그모이드 층은 갱신할 값 을 결정하며 tanh 층은 셀 상태에서 더해질 수 있는 새로운 후 보 값 백터인 를 만든다. 그 후 와 을 합쳐 셀 상태 을 새로운 셀 상태 로 갱신한다. 마지막으로 출력 게이트에서 시그모이드 층은 셀 상태에서 어떤 정보를 출력할지 결정하고 정해진 방향으로 출력되어 다음 층의 노드에서 동일한 계산을 수행하게 된다. 게이트 순환 유닛 도 10의 (b)에 도시된, GRU는 순환신경망의 일종이며 LSTM과 마찬가지로 경사 하강 소실 문제를 해결하기 위해 고안되었으며 이는 LSTM과 달리 리셋 게이트(reset gate), 업데이트 게이트(update gate) 두 개의 게이트로 단 순화시켰다는 특징이 있다. 따라서 입, 출력 파라미터가 감소하고, 게이트가 줄어들어 장단기메모리보다 간결하 게 연산을 수행할 수 있다. 이에 대한 계산 과정은 수학식 3 내지 6과 같다.수학식 3"}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 4"}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 5"}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 6"}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, 는 입력 벡터, 는 출력 벡터(hidden state), 는 리셋 게이트, 는 업데이트 게이트, 는 기억 벡터, 는 가중치, 는 sigmoid 함수를 의미한다. 모델 최적화와 성능지표 선형보간법과 평균법을 사용하여 전처리한 데이터를 여러 단일모델에 적용한 후 최적화를 진행하였다. 본 연구 의 최적화 인자로는 랜덤포레스트의 경우 트리수 그 외 모델의 경우 입력층과 출력층 사이의 은닉층, 전체 데이 터 내 학습 테스트 비율, 신경망에서 최소단위인 노드, 모델의 학습 반복 횟수(epoch), 모델을 검증하기 위한 검증분할(validation split), 과적합 방지를 위한 earlystop, dropout, 가중치 규제 등을 사용하였다. 예측성 능평가를 위해 결정계수(square of the correlation coefficient, ), 평균 제곱근 오차(root mean square error, ), 평균 절대 오차(mean absolute error, )를 사용하였다. 수학식 7"}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 8 수학식 9"}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, 는 관측값, 는 모델을 통한 예측값, 는 관측값의 평균이다. 실험 결과 및 고찰 랜덤포레스트 RF 모델에서 선형보간법과 평균법으로 전처리한 데이터를 사용하여 모델을 최적화하였다. 도 5에 도시된 바와 같이, 선형보간법의 경우 전체 데이터 중에서 학습데이터 75%, 테스트데이터 25%로 설정하고 트리 개수를 50개 에서 개수를 늘리며 진행하였다. 도 6 및 도 11의 (a-1)에 도시된 바와 같이, 트리 개수가 150개 이상에서 테스 트 결정계수 값의 변동을 보이지 않아 150개에서 최적값을 결정하였다(test = 0.700, test = 323.1, test = 204.6). 도 5 및 도 11의 (a-2)에 도시된 바와 같이, 평균법으로 전처리한 데이터의 경우 학습데 이터 80%, 테스트데이터 20%로 예측을 시도했을 때 가장 높은 성능을 보였으며 트리 개수는 선형보간법과 마찬 가지로 150개 이상에서 테스트 결정계수 값이 유지되어 150개에서 최적임을 확인하였다(test = 0.665, test = 347.1, test = 210.9). 학습 값의 경우, 선형보간법(train = 0.941)과 평균법(train = 0.940)은 유사하였지만, 테스트 값은 선형보간법이 우수하였다. 인공신경망 도 5에 도시된 바와 같이, ANN 모델의 최적값은 전처리단계에서 선형보간법을 사용한 경우 학습데이터 90%, 테 스트데이터 10%로 설정하였다. 도 6에 도시된 바와 같이, 입력층, 은닉층 3층(노드 : 300, 200, 100)과 출력층 으로 구성하였다. 활성화 함수의 경우 exponential linear unit(eLU)로 설정하였을 때 sigmoid와 rectified linear unit(ReLU)에 비해 높은 성능을 보였다. 도 11의 (b-1)에 도시된 바와 같이, 검증분할은 0.1, epoch의 경우 50회로 설정하였고, 과적합 방지를 위해 dropout과 earlystop, 가중치 규제를 적용하였으나 가중치 규제만 사용하는 것이 결과가 향상되었다(test = 0.862, test = 151.5, test = 103.0). 도 11의 (b- 2)에 도시된 바와 같이, 전처리단계에서 평균법을 적용하였을 때 학습데이터 90%, 테스트데이터 10%로 설정하였 고 입력층, 은닉층 2층(노드 : 300, 300)과 출력층으로 구성하고 활성화함수는 eLU, epoch 50, 검증분할 0.1로 설정하였으며 과적합 방지를 위해 가중치 규제를 사용하였다(test = 0.828, test = 169.7, test = 121.2). 도 5에 도시된 바와 같이, 훈련 값, 테스트 값, 오차지표에서 모두 선형보간법이 평균법보다 우세하게 나타났다. 장단기메모리 도 5에 도시된 바와 같이, LSTM 모델은 선형보간법을 적용 시 학습데이터 90%, 테스트데이터 10%에서 가장 적합 하였으며, 도 6에 도시된 바와 같이, 입력층, 은닉층 3층(노드 : 500, 500, 500)과 출력층으로 구성하였다. 활 성화 함수는 ReLU로 설정 시 최적의 성능을 보였다. 도 13의 (c-1)에 도시된 바와 같이, 검증분할은 0.1, epoch 의 경우 25회로 설정하였고, 과적합 방지를 위해 dropout, earlystop, 가중치 규제를 사용하였으나 이 중 가중 치 규제만 사용하는 것이 가장 효과적으로 과적합에 대응하는 것으로 나타났다(test = 0.779, test = 192.6, test = 140.4). 도 13의 (c-2)에 도시된 바와 같이, 평균법을 적용 시 학습데이터 90%, 테스트 데이터 10%에서 가장 적합하였으며 입력층, 은닉층 3층(노드 : 500, 500, 500)과 출력층으로 구성하고 활성화함 수 ReLU, epoch 25, 검증분할 0.1로 설정하였으며 과적합 방지를 위해 가중치 규제를 사용하였다(test =0.762, test = 199.8, test = 148.8). 도 5에 도시된 바와 같이, LSTM의 경우 시계열 데이터 예측 에 효과적이나 해당 연구에서는 ANN에 비해 낮은 성능을 보였다. 게이트 순환 유닛 도 5에 도시된 바와 같이, GRU 모델의 최적값은 전처리단계에서 선형보간법을 사용한 경우 학습데이터 90%, 테 스트데이터 10%로 설정하였다. 도 6에 도시된 바와 같이, 입력층, 은닉층 1층(노드 : 300)과 출력층으로 구성하 였다. 활성화 함수의 경우 eLU로 설정하였을 때 sigmoid와 ReLU에 비해 높은 성능을 보였다. 도 14의 (d-1)에 도시된 바와 같이, 검증분할은 0.1에서 0.3까지 조정하였으나 0.1에서 가장 모델에 적합하였으며, epoch의 경우 25회로 설정하였고, dropout, earlystop, 가중치 규제를 통해 과적합 방지를 시도하였고 이 중 가중치 규제를 사용하는 것이 가장 적합하였다(test = 0.867, test = 149.2, test = 98.2). 평균법의 경우, 학습데이터 90%, 테스트데이터 10%로 하고 입력층, 은닉층 1층(노드 : 500)과 출력층으로 구성하였다. 도 14의 (d-2)에 도시된 바와 같이, 활성화함수는 eLU, epoch 25, 검증분할 0.1로 설정하였으며 과적합 방지를 위해 가 중치 규제를 사용한 경우가 가장 효과적이었다(test = 0.839, test = 164.2, test = 117.8)). GRU 모델은 시계열 데이터 예측에 효과적인 모델로 해당 연구에서 가장 높은 예측률을 보여 침출수 발생량 예측 시 가장 적합한 것으로 판단한다. 모델 비교 및 기존 논문과 비교 도 5에 도시된 바와 같이, 모델별 test 는 선형보간법의 경우 RF 0.700, ANN 0.862, LSTM 0.779, GRU 0.867, 평균법의 경우는 RF 0.665, ANN 0.828, LSTM 0.762, GRU 0.839로 본 실험에 사용한 모든 모델에서 선형보간법 을 사용한 경우가 평균법을 사용한 경우보다 성능이 우수하였다. 또한, 선형보간법의 test 는 RF 323.1, ANN 151.5, LSTM 192.6, GRU 149.2이고, 평균법의 test 는 RF 347.1, ANN 169.7, LSTM 199.8, GRU 164.2이었다. 선형보간법 test 는 RF 204.6, ANN 103.0, LSTM 140.4, GRU 98.2이고, 평균법 test 는 RF 210.9, ANN 121.2, LSTM 148.8, GRU 117.8로 선형보간법에서 모델의 성능지표가 더 좋았다. 따라서 모델의 성능은 GRU > ANN > LSTM > RF 순으로 나타났다. 학습 횟수는 GRU의 경우 ANN에 비해 적은 횟수인 25회로 효과 적인 학습이 가능하였다. 도 11 내지 도 14에 따르면, 침출수 발생량 1,500 m3/d을 기준으로 발생량이 적을 때 는 선형보간법, 많을 때는 평균법을 사용한 모델에서 높은 예측률을 보였다. RF, ANN, LSTM, GRU 모델 모두 높 은 예측률을 보였지만 RF를 제외한 모델은 학습 과정에서 과적합 문제가 있었다. 과적합 되는 경우 높은 학습을 보이지만 모델이 특정 데이터에만 편향되어 다른 데이터에는 사용할 수 없게 된다. 이를 해결하기 위해서 dropout, earlystop, 가중치 규제 등을 도입하였으며 이 중 가중치 규제 방법이 가장 효과적으로 과적합에 대응 할 수 있었다. 본 실험을 통해 침출수 발생량 예측에 선형보간법을 사용한 GRU 모델이 더 간결하고 빠른 연산이 가능하며 정확한 예측을 보였다. 도 7에 도시된 바와 같이, 일본 훗카이도 지역에서 침출수 발생량을 예측했던 논문(K. Ishii, M. Sato, S. Ochiai, Prediction of leachate quantity and quality from a landfill site by the long short-term memory model, J. Environ. Manage., 310, 114733.)의 경우 본 실험과 같이 사용 데이터를 일 평균 데이터로 변환하여 모델을 구축하였으며 LSTM 모델에 시계열 데이터를 사용하였다. 이에 비해 본 실험에서는 동일한 데이터를 이용하여 LSTM과 GRU에 적용하였다는 점에서 선행논문과 차이가 있다. 말레이시 아 셀랑고루주 지역의 침출수 발생량 예측 논문(T. Abunama, F. Othman, M. Ansari, A. El-Shafie, Leachate generation rate modeling using artificial intelligence algorithms aided by input optimization method for an MSW landfill, Environ. Sci. Pollut. Res., 26, 3368-3381.)의 경우 월별 데이터를 사용하였 지만, 본 실험은 결측치 처리방식으로 선형보간법과 평균법을 사용하여 월별 데이터를 일별 데이터로 바꾸어 사 용한 점에서 차이가 있다. 본 실험에서는 침출수 발생량을 예측하기 위해서 결측치 처리방식으로 선형보간법과 평균법을 사용하여 여러 단 일모델을 비교하였다. 선형보간법과 평균법을 사용한 모델 모두 전반적으로 성능은 우수하였으나, 선형보간법에 서 성능이 더 우수하였다. 하지만 침출수 발생량에 따라 평균법이 더 적합한 경우도 있었다. 선형보간법을 사용 한 모델은 GRU > ANN > LSTM > RF 순으로 GRU가 성능이 가장 우수하였다.본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 또한, 본 발명의 서로 다른 실시예들은 상호 보완되거나 결합될 수 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler), 파이썬(Python) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되 는 알고리즘으로 구현될 수 있다."}
{"patent_id": "10-2022-0184771", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2022-0184771", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치 구성도이다. 도 2는 본 개시의 일 실시예에 따른 시스템 구성도이다. 도 3은 본 개시의 일 실시예에 따른 기본 흐름도이다. 도 4 내지 도 14는 본 개시의 일 실시예에 따른 출력 비교에 따른 인공지능 모델 선정과 관련한 도면이다."}
