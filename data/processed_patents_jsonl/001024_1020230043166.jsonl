{"patent_id": "10-2023-0043166", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0147342", "출원번호": "10-2023-0043166", "발명의 명칭": "부호형 비트 슬라이스 생성기 및 그 방법과, 부호형 비트 슬라이스 연산기와, 이들을 적용한", "출원인": "한국과학기술원", "발명자": "유회준"}}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터를 분할하되, 상기 입력데이터의부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할하는 분할부;상기 비트 슬라이스 마다 부호비트를 추가하는 부호비트 추가부;상기 비트 슬라이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력데이터의 부호값으로 설정하고, 나머지비트 슬라이스들의 부호비트를 양의 부호값으로 설정하는 부호값설정부; 및상기 부호형 비트 슬라이스들 각각에 대하여 희소 데이터 압축을 실시하는 희소데이터 압축부를 포함하는 것을특징으로 하는 부호형 비트 슬라이스 생성기."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 부호형 비트 슬라이스들 각각에서 0값을 갖는 비트 슬라이스의 수를 증가시키기 위해, 전체 길이 데이터의부호비트 값을, 각 부호형 비트 슬라이스의 LSB에 더하고, 바로 하위에 인접한 부호형 비트슬라이스의 부호비트에서 빼는 연산과정을 반복하는 부호비트 연산부를 더 포함하는 것을 특징으로 하는 부호형 비트 슬라이스 생성기."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 부호비트 연산부는양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 하기 위해, 부호형 비트 슬라이스 값이 미리 설정된 특정값인 경우, 상기 연산과정을 스킵하는 것을 특징으로 하는 부호형 비트 슬라이스 생성기."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "비트 슬라이스 생성기의 비트 슬라이스 생성방법에 있어서, 상기 비트 슬라이스 생성기가, N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터를분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할하는분할단계;상기 비트 슬라이스 생성기가, 상기 비트 슬라이스마다 부호비트를 추가하는 부호비트추가단계; 상기 비트 슬라이스 생성기가, 상기 비트 슬라이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력데이터의부호값으로 설정하고, 나머지 비트 슬라이스들의 부호비트를 양의 부호값으로 설정하는 부호설정단계; 및상기 비트 슬라이스 생성기가, 상기 부호형 비트 슬라이스들 각각에 대하여 희소 데이터 압축을 실시하는 희소데이터 압축단계를 포함하는 것을 특징으로 하는 부호형 비트 슬라이스 생성방법."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 부호형 비트 슬라이스들 각각에서 0값을 갖는 비트 슬라이스의 수를 증가시키기 위해, 전체 길이 데이터의부호비트 값을, 각 부호형 비트 슬라이스의 LSB에 더하고, 바로 하위에 인접한 부호형 비트슬라이스의 부호비트에서 빼는 연산과정을 반복하는 부호비트 연산단계를 더 포함하는 것을 특징으로 하는 부호형 비트 슬라이스 생성방법."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0147342-3-제5항에 있어서, 상기 부호비트 연산단계는양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 하기 위해, 부호형 비트 슬라이스 값이 미리 설정된 특정값인 경우, 상기 연산과정을 스킵하는 것을 특징으로 하는 부호형 비트 슬라이스 생성방법."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "비트 슬라이스 연산기에 있어서, 부호비트를 각각 포함하여 그 길이가 동일하게 생성된 복수개의 M비트 부호형 비트슬라이스를 입력으로 받아 곱셈연산하는 곱셈연산기;상기 곱셈연산기의 연산결과를 누적하는 덧셈연산기; 및상기 덧셈연산기의 연산결과를 저장하는 레지스터를 포함하는 것을 특징으로 하는 비트 슬라이스 연산기."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "인공지능 신경망 가속장치에 있어서,N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터로부터 소정개의 부호형 비트 슬라이스를 생성한 후 압축 관리하는 데이터 관리 유닛(DMU Core);상기 부호형 비트 슬라이스의 곱셈 및 덧셈 연산과, 비트 슬라이스 단위의 데이터 스키핑 연산을 수행하는 스키핑 연산 유닛(Zero-slice-skip PE); 및외부 제어 명령에 의해, 상기 스키핑 연산 유닛(Zero-slice-skip PE)의 연산결과를 축적하여 저장하는 축적유닛(Accumulation Unit)을 포함하는 것을 특징으로 하는 인공지능 신경망 가속장치."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 데이터 관리 유닛(DMU Core)은상기 부호형 비트 슬라이스를 생성하는 부호형 비트 슬라이스 생성유닛(SBR Unit); 및상기 부호형 비트 슬라이스를 압축하는 부호형 비트 슬라이스 압축유닛(RLE Unit)을 포함하되,상기 부호형 비트 슬라이스 생성유닛(SBR Unit)은N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터를 분할하되, 상기 입력데이터의부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할하는 분할부;상기 비트 슬라이스 마다 부호비트를 추가하는 부호비트 추가부; 및상기 비트 슬라이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력데이터의 부호값으로 설정하고, 나머지비트 슬라이스들의 부호비트를 양의 부호값으로 설정하는 부호값설정부를 포함하는 것을 특징으로 하는 인공지능 신경망 가속장치."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 부호형 비트 슬라이스 압축유닛(RLE Unit)은상기 부호형 비트 슬라이스들 각각에 대하여, 희소 입력 데이터를 압축하고, 0값이 아닌 데이터와 이 데이터의위치를 나타내는 인덱스를 생성하는 것을 특징으로 하는 인공지능 신경망 가속장치."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 부호형 비트 슬라이스 압축유닛(RLE Unit)은상기 스키핑 연산 유닛(Zero-slice-skip PE)의 스키핑 연산 결과 중 최상위의 비트 슬라이스에 대한 스키핑 연산 결과에 대한 맥스 풀링 결과로 얻어진 출력 바이너리 마스크를 이용하여 상기 희소 입력 데이터를 압축하는것을 특징으로 하는 인공지능 신경망 가속장치."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2024-0147342-4-제8항에 있어서, 상기 스키핑 연산 유닛(Zero-slice-skip PE)은 상기 데이터 관리 유닛(DMU Core)으로부터 압축된 부호형 비트 슬라이스인 입력 비트 슬라이스를 전달받아 저장하는 입력버퍼(IBUF);상기 입력 비트 슬라이스의 저장 위치인 압축 인덱스를 저장하는 인덱스버퍼(IDXBUF);상기 부호형 비트 슬라이스로 구현된 가중치 데이터를 저장하는 가중치버퍼(WBUF);상기 압축 인덱스에 의거하여, 가중치 데이터를 불러와야 할 상기 가중치버퍼(WBUF)의 주소를 계산하는 스키핑부(Zero-skip Unit); 및다수의 부호형 비트 슬라이스 연산기들을 포함하고, 상기 입력버퍼(IBUF)로부터 입력 비트 슬라이스를읽어오고, 상기 스키핑부(Zero-skip Unit)에서 계산된 주소 정보에 의해 상기 가중치버퍼(WBUF)로부터 가중치데이터를 읽어와서 곱셈 및 축적 연산을 수행하는 연산기 어레이를 포함하는 것을 특징으로 하는 인공지능 신경망 가속장치."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 부호형 비트 슬라이스 연산기는상기 입력 비트 슬라이스와 상기 가중치 데이터에 대하여 순차적으로 곱셈연산을 수행하는 곱셈연산기;상기 곱셈연산기의 연산결과를 누적하는 덧셈연산기; 및상기 덧셈연산기의 연산결과를 저장하는 레지스터를 포함하는 것을 특징으로 하는 인공지능 신경망 가속장치."}
{"patent_id": "10-2023-0043166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 상기 입력 데이터와 상기 가중치 데이터의 희소성을 비교하고 상기 입력 데이터 보다 상기 가중치 데이터의 희소성이 더 높을 경우, 가중치 스키핑 연산을 수행하도록 상기 데이터 관리 유닛(DMU Core), 상기 스키핑 연산유닛(Zero-slice-skip PE), 및 상기 축적유닛(Accumulation Unit)의 동작을 제어하는 가중치 스키핑 연산 컨트롤러를 더 포함하고, 가중치 스키핑 연산 컨트롤러는 상기 가중치 데이터를 압축하여 압축된 부호형 비트 슬라이스인 가중치 비트 슬라이스를 출력하도록 상기 데이터 관리 유닛(DMU Core)을 제어하고,상기 가중치 비트 슬라이스를 입력버퍼(IBUF)에 저장하고, 상기 가중치 비트 슬라이스의 저장 위치인 압축 인덱스를 인덱스 버퍼에 저장하고, 상기 부호형 비트 슬라이스로 구현된 입력데이터를 가중치 버퍼(WBUF)에 저장하도록 상기 스키핑 연산 유닛(Zero-slice-skip PE)을 제어하고,상기 스키핑 연산 유닛(Zero-slice-skip PE)의 출력데이터를 재정렬하여 출력버퍼(OBUF)에 저장하도록 상기 축적유닛(Accumulation Unit)의 동작을 제어하는 것을 특징으로 하는 인공지능 신경망 가속장치."}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 부호형 비트 슬라이스 생성기는 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입 력데이터를 분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할하 는 분할부; 상기 비트 슬라이스 마다 부호비트를 추가하는 부호비트 추가부; 상기 비트 슬라이스들 중 최상위 비 (뒷면에 계속)"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 신경망을 가속하기 위한 기술에 관한 것으로서, 보다 상세하게는, 부호형 비트 슬라이스 (Signed Bit-slice)를 생성하는 장치 및 그 방법과, 상기 방법으로 생성된 부호형 비트 슬라이스를 연산하기 위 한 부호형 비트 슬라이스 연산기, 및 이를 적용한 인공지능 신경망 가속장치에 관한 것이다."}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 신경망 가속장치의 가속 효율을 높이기 위해, 소정 비트 길이의 데이터를 다수의 비트 슬라이스로 분 할하여 연산하는 비트 슬라이스 하드웨어 아키텍처가 사용되고 있으며(참고문헌 1, 2), 이러한 비트 슬라이스 하드웨어 아키텍처의 연산 성능을 향상시키기 위한 기술들이 추가적으로 제안되고 있다.예를 들어, 참고문헌 3에서는, 소정 비트 길이의 데이터를 비트 슬라이스로 분할하는 과정에서 0값을 가지는 비 트 슬라이스 간의 연산 과정을 스키핑하는 하드웨어 아키텍처가 개시되고, 참고문헌 4에서는, 상위 비트 슬라이 스를 먼저 계산하여 출력값의 크기를 예상한 후 남은 하위 비트 슬라이스 연산을 스키핑하는 하드웨어 아키텍처 가 개시되고 있다. 그러나 상기와 같은 종래의 하드웨어 아키텍처들은 다음과 같은 한계가 있다. 먼저, 참고문헌 3에 개시된 하드웨어 아키텍처를 2의 보수데이터에 적용할 경우, 0값을 가지는 비트 슬라이스가 양수데이터에 한정되므로 하드웨어 성능 향상에 제한이 있다. 이는, 2의 보수데이터에서 비트 슬라이스를 만들 경우, 0값 근처 양수데이터의 상위 비트 슬라이스 값은 0값을 가지지만, 0값 근처 음수데이터의 상위 비트 슬라 이스 값은 -1값을 가지기 때문이다. 한편, 인공지능 신경망 입력 및 가중치의 데이터 분포를 보면 데이터가 0값 근처에 몰려 있으며, 이 중, 0값 근처의 음수데이터 분포가 50% 이상 차지한다. 따라서 참고문헌 3의 기술은, 이와 같이 많은 양을 차지하는 0값 근처의 음수데이터의 희소성을 활용할 수 없음으로써 하드웨어 성능 향상에 한계가 있다. 또한, 참고문헌 4에 개시된 하드웨어 아키텍처를 2의 보수데이터에 적용할 경우, 상위 비트 슬라이스를 먼저 계 산하여 출력값을 예측하는 출력 추측법에 많은 추측 오차를 야기하는 문제가 있다. 이는, 2의 보수 표현에서 음 수데이터가 양수데이터보다 하나가 더 많기 때문에, 전체 비트의 데이터에서 부호만 다르고 크기값은 서로 같더 라도 상위 비트 슬라이스의 크기값에는 차이가 나기 때문이다. 예시로, -25 (=1100_111)과 25 (=0011_001)의 상위 4-비트 슬라이스는 -4 (=1100)와 3 (=0011)로 서로 다른 값을 가지며, 이러한 문 제는 VoteNet 인공지능 신경망의 맥스 풀링 최댓값 추측에 19.9% 만큼의 큰 출력값 추측 오차를 야기한다. 마지막으로, 종래의 비트 슬라이스 하드웨어 아키텍처는 전반적으로 큰 로직 면적을 차지한다. 이는, 전체 비트 0값 데이터를 스키핑을 지원하는 하드웨어 아키텍처의 경우 데이터 스키핑을 한 번만 수행하지만, 0값 비트 슬 라이스 스키핑을 지원하는 하드웨어 아키텍처의 경우 비트슬라이스 수 만큼 데이터 스키핑을 해야 하기 때문에 비트 슬리라이스 수 만큼의 스키핑 로직이 추가로 필요하기 때문이다. 또한 종래의 방식에서는 부호를 포함하는 상위 비트 슬라이스와 달리 하위 비트 슬라이스들은 부호를 가지고 있 지 않기 때문에, 부호를 가지도록 부호 연장 로직이 추가로 필요하며, 부호 연장으로 인한 비트 길이가 연장된 연산기가 필요하다. 이러한 추가 로직으로 인해, 종래의 비트 슬라이스 하드웨어 아키텍처는, 큰 로직 면적을 차지하게 된다. 예를 들어, 4-비트 슬라이스 아키텍처가 전체 8-비트 아키텍처보다 동일 산출량 기준 2.07배 큰 면적을 차지한다. 이와 같이 종래에는, 다양한 인공지능 신경망의 비트 정밀도를 가속하기 위한 방법으로 대표되는 비트 슬라이스 연산 방식에 있어, 비트 슬라이스 표현법과 비트 슬라이스 연산 하드웨어 아키텍처에 큰 문제가 있기 때문에 이 의 개선이 필요하다. 선행기술문헌 비특허문헌 (비특허문헌 0001) 참고문헌 1 : J.-W. Jang, et al., \"Sparsity-aware and re-configurable npu architecture for samsung flagship mobile soc,\" ISCA, pp. 15-28, 2021. (비특허문헌 0002) 참고문헌 2 : C.-H. Lin, et al., \"3.4-to-13.3 tops/w 3.6 tops dual-core deep- learning accelerator for versatile ai applications in 7nm 5g smartphone soc,\" ISSCC, pp. 134-136, 2020. (비특허문헌 0003) 참고문헌 3 : D. Han, et al., \"Hnpu: An adaptive dnn training processor utilizing stochastic dynamic fixedpoint and active bit-precision searching,\" IEEE JSSC, 2018. (비특허문헌 0004) 참고문헌 4 : M. Song, et al., \"Prediction based execution on deep neural networks,\" ISCA, pp. 752-763, 2018."}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서 본 발명에서는, N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터를 M(이 때, M은 자연수 이고, M < N 임) 비트 슬라이스로 나눌 때, 각 비트 슬라이스가 모두 부호 비트를 가지는 동일 길이의 부호형 비트 슬라이스를 생성함으로써, 비트 슬라이스의 곱셈 및 축적연산(MAC: multiply and accumulate)시 부호 연장 을 하지 않아도 되고, 이로 인해 비트 길이가 연장된 연산기를 사용하지 않음으로써 연산로직의 면적을 줄일 수 있는 장치 및 방법을 제공하고자 한다. 또한, 본 발명은, 전체 길이 데이터의 부호비트 값을, 각 부호형 비트 슬라이스의 LSB에 더한 후 바로 하위에 인접한 부호형 비트 슬라이스의 부호비트에서 빼는 과정을 반복함으로써, 상기 부호형 비트 슬라이스들 각각에 서 0값을 갖는 비트수를 증가시키고, 이로 인해 희소 데이터 압축시 데이터 압축률을 높이고, 희소 데이터 스키 핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 장치 및 방법을 제공하고자 한다. 또한, 본 발명은 상기 부호형 비트 슬라이스를 연산함으로써, 2의 보수데이터에서 0값 근처의 양수데이터와 0값 근처의 음수데이터 모두의 희소성을 활용할 수 있고, 이로 인해, 희소 데이터 압축시 데이터 압축률을 높이고, 희소 데이터 스키핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 장치 및 방법을 제공하고 자 한다. 또한, 본 발명은 상기 부호형 비트 슬라이스의 값이 대칭이 되도록 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 함으로써, 상위 비트 슬라이스 연산을 통한 출력값 추측 오차를 줄이고, 이로 인해 추측 연산으로 인한 인공지능 신경망의 정확도를 향상시킬 수 있는 부호형 비트 슬라이스 연산기, 및 이를 적용 한 인공지능 신경망 가속장치를 제공하고자 한다. 또한, 본 발명은 희소 입력 스키핑 연산을 통해 상위 비트 슬라이스 연산을 수행하고 그 결과값을 바탕으로 최 종 출력값의 크기를 추측한 후 하위 비트 슬라이스 연산시 추측된 희소 출력 위치에 해당하는 입력값들을 희소 화함으로써, 희소 입력 비트 슬라이스와 희소 출력 데이터 연산을 동시에 스키핑 연산하고, 이로 인해 연산속도 를 향상시킬 수 있는 인공지능 신경망 가속장치를 제공하고자 한다. 또한, 본 발명은 희소 출력 위치에 해당하는 입력값들을 희소화시켜 연산하기 때문에, 희소 입력 비트 슬라이스 압축과 희소 출력 데이터 압축 방식을 통일시킬 수 있고, 이로 인해 연산 속도를 향상시킬 수 있는 인공지능 신 경망 가속장치를 제공하고자 한다. 또한, 본 발명은 동일 개수의 입력 데이터와 가중치 데이터를 불러와 곱셈 및 축적연산을 수행함으로써 입력데 이터와 가중치 데이터 간의 스키핑 전환이 용이하고, 이로 인해 입력 데이터와 가중치 데이터 중 더욱 희소한 데이터를 스키핑하여 인공지능 신경망 연산을 가속화함으로써, 인공지능 신경망 연산 속도를 향상시킬 수 있는 인공지능 신경망 가속장치를 제공하고자 한다."}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위해, 본 발명에서 제공하는 인공지능 신경망 가속장치는 N(이 때, N은 자연수 임) 비 트 정밀도를 가지는 2의 보수데이터인 입력데이터로부터 소정개의 부호형 비트 슬라이스를 생성한 후 압축 관리 하는 데이터 관리 유닛(DMU Core); 상기 부호형 비트 슬라이스의 곱셈 및 덧셈 연산과, 비트 슬라이스 단위의 데이터 스키핑 연산을 수행하는 스키핑 연산 유닛(Zero-slice-skip PE); 및 외부 제어 명령에 의해, 상기 스키 핑 연산 유닛(Zero-slice-skip PE)의 연산결과를 축적하여 저장하는 축적유닛(Accumulation Unit)을 포함하는 것을 특징으로 한다. 바람직하게, 상기 데이터 관리 유닛(DMU Core)은 상기 부호형 비트 슬라이스를 생성하는 부호형 비트 슬라이스 생성유닛(SBR Unit); 및 상기 부호형 비트 슬라이스를 압축하는 부호형 비트 슬라이스 압축유닛(RLE Unit)을 포 함하되, 상기 부호형 비트 슬라이스 생성유닛(SBR Unit)은 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터를 분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비트들을 소정개의 비트 슬 라이스로 분할하는 분할부; 상기 비트 슬라이스 마다 부호비트를 추가하는 부호비트 추가부; 및 상기 비트 슬라 이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력데이터의 부호값으로 설정하고, 나머지 비트 슬라이스 들의 부호비트를 양의 부호값으로 설정하는 부호값설정부를 포함할 수 있다. 바람직하게, 상기 스키핑 연산 유닛(Zero-slice-skip PE)은 상기 데이터 관리 유닛(DMU Core)으로부터 압축된 부호형 비트 슬라이스인 입력 비트 슬라이스를 전달받아 저장하는 입력버퍼(IBUF); 상기 입력 비트 슬라이스의저장 위치인 압축 인덱스를 저장하는 인덱스버퍼(IDXBUF); 상기 부호형 비트 슬라이스로 구현된 가중치 데이터 를 저장하는 가중치버퍼(WBUF); 상기 압축 인덱스에 의거하여, 가중치 데이터를 불러와야 할 상기 가중치버퍼 (WBUF)의 주소를 계산하는 스키핑부(Zero-skip Unit); 및 다수의 부호형 비트 슬라이스 연산기들을 포함하고, 상기 입력버퍼(IBUF)로부터 입력 비트 슬라이스를 읽어오고, 상기 스키핑부(Zero-skip Unit)에서 계산된 주소 정보에 의해 상기 가중치버퍼(WBUF)로부터 가중치 데이터를 읽어와서 곱셈 및 축적 연산을 수행하는 연산기 어 레이를 포함할 수 있다. 상기 부호형 비트 슬라이스 연산기는 상기 입력 비트 슬라이스와 상기 가중치 데이터에 대하여 순차적으로 곱셈 연산을 수행하는 곱셈연산기; 상기 곱셈연산기의 연산결과를 누적하는 덧셈연산기; 및 상기 덧셈연산기의 연산 결과를 저장하는 레지스터를 포함할 수 있다. 상기 인공지능 신경망 가속장치는 상기 입력 데이터와 상기 가중치 데이터의 희소성을 비교하고 상기 입력 데이 터 보다 상기 가중치 데이터의 희소성이 더 높을 경우, 가중치 스키핑 연산을 수행하도록 상기 데이터 관리 유 닛(DMU Core), 상기 스키핑 연산 유닛(Zero-slice-skip PE), 및 상기 축적유닛(Accumulation Unit)의 동작을 제어하는 가중치 스키핑 연산 컨트롤러를 더 포함할 수 있다. 한편, 본 발명에서 제공하는 비트 슬라이스 생성방법은, 비트 슬라이스 생성기가, N(이 때, N은 자연수 임) 비 트 정밀도를 가지는 2의 보수데이터인 입력데이터를 분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비 트들을 소정개의 비트 슬라이스로 분할하는 분할단계; 상기 비트 슬라이스 생성기가, 상기 비트 슬라이스마다 부호비트를 추가하는 부호비트추가단계; 상기 비트 슬라이스 생성기가, 상기 비트 슬라이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력데이터의 부호값으로 설정하고, 나머지 비트 슬라이스들의 부호비트를 양의 부 호값으로 설정하는 부호설정단계; 및 상기 비트 슬라이스 생성기가, 상기 부호형 비트 슬라이스들 각각에 대하 여 희소 데이터 압축을 실시하는 희소데이터 압축단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이, 본 발명은 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터를 M(이 때, M은 자연수이고, M < N 임) 비트 슬라이스로 나눌 때, 각 비트 슬라이스가 모두 부호 비트를 가지는 동일 길이의 부호형 비트 슬라이스를 생성함으로써, 비트 슬라이스의 곱셈 및 축적연산(MAC: multiply and accumulate)시 부호 연장을 하지 않아도 되도록 하고, 이로 인해 비트 길이가 연장된 연산기를 사용하지 않음으 로써 연산로직의 면적을 줄일 수 있는 장점이 있다. 또한, 본 발명은, 전체 길이 데이터의 부호비트 값을, 각 부호형 비트 슬라이스의 LSB에 더한 후 바로 하위에 인접한 부호형 비트 슬라이스의 부호비트에서 빼는 과정을 반복함으로써, 상기 부호형 비트 슬라이스들 각각에 서 0값을 갖는 비트수를 증가시키고, 이로 인해 희소 데이터 압축시 데이터 압축률을 높이고, 희소 데이터 스키 핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 장점이 있다. 또한, 본 발명은 상기 부호형 비트 슬라이스를 연산함으로써, 2의 보수데이터에서 0값 근처의 양수데이터와 0값 근처의 음수데이터 모두의 희소성을 활용할 수 있고, 이로 인해, 희소 데이터 압축시 데이터 압축률을 높일 수 있으며, 희소 데이터 스키핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 장점이 있다. 또한, 본 발명은 상기 부호형 비트 슬라이스의 값이 대칭이 되도록 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 함으로써, 상위 비트 슬라이스 연산을 통한 출력값 추측 오차를 줄이고, 이로 인해 추측 연산으로 인한 인공지능 신경망의 정확도를 향상시킬 수 있는 장점이 있다. 또한, 본 발명은 희소 입력 스키핑 연산을 통해 상위 비트 슬라이스 연산을 수행하고 그 결과값을 바탕으로 최 종 출력값의 크기를 추측한 후 하위 비트 슬라이스 연산시 추측된 희소 출력 위치에 해당하는 입력값들을 희소 화함으로써, 희소 입력 비트 슬라이스와 희소 출력 데이터 연산을 동시에 스키핑 연산하고, 이로 인해 연산속도 를 향상시킬 수 있는 장점이 있다. 또한, 본 발명은 희소 출력 위치에 해당하는 입력값들을 희소화시켜 연산하기 때문에, 희소 입력 비트 슬라이스 압축과 희소 출력 데이터 압축 방식을 통일시킬 수 있고, 이로 인해 연산 속도를 향상시킬 수 있는 장점이 있다. 또한, 본 발명은 동일 개수의 입력 데이터와 가중치 데이터를 불러와 곱셈 및 축적연산을 수행함으로써 입력데 이터와 가중치 데이터 간의 스키핑 전환이 용이하고, 이로 인해 입력 데이터와 가중치 데이터 중 더욱 희소한 데이터를 스키핑하여 인공지능 신경망 연산을 가속화함으로써, 인공지능 신경망 연산 속도를 향상시킬 수 있는장점이 있다."}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시 예에 대하여 설명하되, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 한편 도면에서 본 발명을 명확 하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유 사한 도면 부호를 붙였다. 또한 상세한 설명을 생략하여도 본 기술 분야의 당업자가 쉽게 이해할 수 있는 부분 의 설명은 생략하였다. 명세서 및 청구범위 전체에서, 어떤 부분이 어떤 구성 요소를 포함한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 도 1은 본 발명의 일 실시 예에 따른 인공지능 신경망 가속장치에 대한 개략적인 블록도이다. 도 1을 참조하면, 본 발명의 일 실시 예에 따른 인공지능 신경망 가속장치는 데이터 관리 유닛(DMU Core), 스키핑 연산 유닛 (Zero-slice-skip PE), 및 축적유닛(Accumulation Unit)을 포함한다. 데이터 관리 유닛(DMU Core)은 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이 터로부터 소정개의 부호형 비트 슬라이스를 생성한 후 압축 관리한다. 이를 위해, 데이터 관리 유닛(DMU Core)은 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit), 메모리(Global Memory), 및 출 력 바이너리 마스크(Output Binary Mask) 유닛을 포함할 수 있다. 이 때, 상기 부호형 비트 슬라이스(Signed Bit-slice)는 부호비트를 포함하고, 동일한 비트수를 가지는 비트 슬 라이스를 말하며, 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)은 상기 부호형 비트 슬라이스를 생 성한 후 압축한다. 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)의 구성이 도 2에 예시되어 있다. 도 2는 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스 생성/압축 유닛에 대한 개략적인 블록도로서, 도 2 를 참조하면, 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)는 부호형 비트 슬라이스를 생성하는 부 호형 비트 슬라이스 생성유닛(SBR Unit)과 부호형 비트 슬라이스 압축유닛(RLE unit)으로 구성되며, 부 호형 비트 슬라이스 생성유닛(SBR Unit)는 분할부, 부호비트 추가부, 부호값 설정부, 및 부호 비트 연산부를 포함하고, 부호형 비트 슬라이스 압축유닛(RLE unit)는 희소데이터 압축부를 포함할 수 있다. 분할부는 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데이터를 분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할한다. 예를 들어, 분할부 는 7비트 정밀도를 가지는 2의 보수데이터의 경우, 부호를 나타내는 MSB 비트를 제외한 6비트를 2개의 3비트 슬 라이스들, 또는 3개의 2비트 슬라이스로 분할할 수 있다.부호비트 추가부는 분할부에서 분할된 비트 슬라이스들 각각에 부호비트를 추가한다. 분할된 비트 슬라 이스들 중 최상위에 위치하는 비트 슬라이스의 경우, 상기 입력데이터의 부호비트가 존재하므로, 부호비트 추가 부는 최상위의 비트 슬라이스를 제외한 나머지 비트 슬라이스들 모두에 부호비트를 추가한다. 상기 예에서, 7비트의 입력데이터를 2개의 3비트 슬라이스로 분할한 경우, 상위 3비트의 비트 슬라이스에는 입력데이터의 부 호비트가 존재하므로 부호비트 추가부는 하위 3비트의 비트 슬라이스에만 부호비트를 추가한다. 이 경우, 4 비트의 비트 슬라이스가 2개 생성될 것이다. 한편, 7비트의 입력데이터를 2개의 3비트 슬라이스로 분할한 경우, 부호비트 추가부는 최상위 2비트의 비트 슬라이스를 제외한 나머지 2개의 2비트 슬라이스 각각에 부호비트 를 추가한다. 이 경우, 3비트의 비트 슬라이스가 3개 생성될 것이다. 부호값 설정부는 부호비트 추가부에서 추가된 부호비트들 각각의 부호값을 설정한다. 이 때, 소정개의 비트 슬라이스들 중 최상위에 위치한 비트 슬라이스의 부호비트에는 입력데이터의 부호값이 이미 저장되어 있으 므로, 부호값 설정부는 나머지 비트 슬라이스들의 부호비트들 각각의 부호값을 설정하되, 최상위 비트 슬라 이스를 제외한 나머지 비트 슬라이스들은 모두 양수를 나타내므로, 부호값 설정부는 나머지 비트 슬라이스 들의 부호비트들 각각의 부호값을 양의 부호값으로 설정할 수 있다. 부호비트 연산부는 전체 길이 데이터의 부호비트 값을 부호형 비트 슬라이스 각각의 LSB에 더하고, 바로 하 위에 인접한 부호형 비트슬라이스의 부호비트에서 빼는 연산과정을 반복한다. 이는, 상기 부호형 비트 슬라이스 들 각각에서 0값을 갖는 비트수를 증가시키기 위한 것으로서, 부호비트 연산부는 상기 연산과정을 비트 슬 라이스의 수 만큼 반복할 수 있다. 이로 인해, 이러한 비트 슬라이스를 이용한 연산, 또는 인공지능 신경망 가 속시 희소 데이터 압축률 상승 효과를 얻을 수 있게 된다. 한편, 부호비트 연산부는 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 하기 위해, 부호형 비트 슬라이스 값이 미리 설정된 특정값인 경우, 상기 연산과정을 스킵할 수 있다. 즉, 부호비트 연산부 는 부호형 비트 슬라이스 값이 '1000' 인 경우, 상기 연산과정을 스킵할 수 있다. 이는 출력추측법 사용시 출력 추측 오차율을 줄이기 위함이다. 이 때, 상기 ‘출력추측법’이란 출력값이 0인 상황처럼 출력을 추측할 수 있는 인공지능 신경망에서 인공지능 신경망 가속장치의 효율을 향상시키기 위해 통상적으로 수행되는 공지의 기술이다. 따라서, 그 구체적인 처리 과정에 대한 설명은 생략한다. 도 3은 본 발명의 일 실시 예에 따른 부호비트 연산부의 동작을 부연 설명하기 위한 도면으로써, 상기 연산과정 스킵에 의해 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 한 경우(b)와 그렇지 않은 경 우(a)에 대한 오차율을 예시하고 있다. 도 3의 (a)는, '1000' 을 스킵하지 않는 경우, 2의 보수 휠(two's complement Wheel)의 좌우측 대칭이 맞지 않고, 이로 인해, 출력 추측 오차율이 19.9% 임을 예시하고, 도 3의 (b)는, '1000' 을 스킵함으로써 2의 보수 휠(two's complement Wheel)의 좌우측이 대칭을 이루고, 이로 인해, 출력 추측 오차율이 5% 미만임을 예시하고 있다. 희소데이터 압축부는 부호형 비트 슬라이스 생성유닛(SBR Unit)에서 생성된 부호형 비트 슬라이스들 각 각에 대하여 희소 데이터 압축을 실시한다. 이를 위해, 희소데이터 압축부는 런렝스 부호화(Run-Length Encoding) 방식을 적용할 수 있다. 한편, 희소데이터 압축부는 상기 희소 데이터 압축 결과로, 0값이 아닌 데이터와 이 데이터의 위치를 나타 내는 인덱스를 생성한 후, 상기 0값이 아닌 데이터는 후술될 입력버퍼(IBUF)에, 상기 인덱스는 후술될 인 덱스버퍼(IDXBUF)에 각각 저장한다. 이와 같이 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)이 부호형 비트 슬라이스를 생성하기 위한 처리 과정이 도 4에 예시되어 있다. 도 4는 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스를 생성하는 방법에 대한 처리 흐름도로서, 도 2 및 도 4를 참조하여 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스를 생성하는 방법을 설명하면 다음과 같다. 먼저, 단계 S110에서는, 분할부가 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터인 입력데 이터를 분할하되, 상기 입력데이터의 부호비트를 제외한 나머지 비트들을 소정개의 비트 슬라이스로 분할한다. 단계 S120에서는, 부호비트 추가부가 상기 비트 슬라이스마다 부호비트를 추가한다. 단계 S130에서는, 부호값 설정부가 상기 비트 슬라이스들 중 최상위 비트 슬라이스의 부호비트를 상기 입력 데이터의 부호값으로 설정하고, 나머지 비트 슬라이스들의 부호비트를 양의 부호값으로 설정한다. 단계 S140에서는, 부호비트 연산부가 전체 길이 데이터의 부호비트 값을 부호형 비트 슬라이스 각각의 LSB 에 더하고, 바로 하위에 인접한 부호형 비트슬라이스의 부호비트에서 빼는 연산과정을 반복한다. 이는, 상기 부 호형 비트 슬라이스들 각각에서 0값을 갖는 비트수를 증가시키기 위함이다. 한편, 단계 S140에서, 부호비트 연산부는 부호형 비트 슬라이스 값이 미리 설정된 특정값(즉, '1000' )인 경우, 상기 연산과정을 스킵할 수 있다. 이는 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일 하게 함으로써, 출력추측법 사용시 출력 추측 오차율을 줄이기 위함이다. 이와 같은 과정을 거쳐서 생성된 부호형 비트 슬라이스들 각각은, 희소데이터 압축부에서, 희소 데이터 압 축(미도시)을 거쳐 인공지능 신경망 가속장치에 적용될 수 있다. 도 4의 설명에 있어서, 도 2의 장치 설명에 언급된 내용에 대하여는 중복설명을 생략하였다. 도 5는 본 발명의 일 실시 예에 따라 부호형 비트 슬라이스를 생성하는 과정을 예로 들어 설명하기 위한 도면으 로서, 7비트의 2의 보수 데이터(A)인 입력데이터를 본 발명의 일 실시 예에 따른 부호형 비트 슬라이 스로 분할하는 과정을 예로 들어 설명하고 있다. 도 5의 ⒜는 상기 입력데이터가 비트 슬라이스로 분할되기 이전의 상태(즉, 로-데이터(raw data))를 예시하고 있다. 이 때, MSB는 상기 입력데이터의 부호를 나타내는 부호비트이다. 이와 같은 입력데이터를 수학식으로 표 현하면 수학식 1에 예시된 바와 같다. 수학식 1"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 5의 ⒝는 상기 입력데이터를 2개의 비트 슬라이스로 분할한 후, 부호비트(Sign Bit)를 추가하고, 그 부호비 트에 양의 부호값인 0을 설정한 상태를 예시하고 있다. 통상, 특정 데이터를 비트 슬라이스로 분할할 때, 상위 측의 비트 슬라이스는 상기 입력데이터의 부호비트를 포함하지만, 하위측의 비트 슬라이스는 부호비트를 포함하 지 않음으로써, 비트 슬라이스들각각의 길이가 서로 상이한 특징이 있는데, 본 발명에서는 도 5의 ⒝에 예시된 바와 같이, 하위측의 비트 슬라이스에 부호비트를 부가한 후, 부가된 부호비트에 양의 부호값을 설정하는 과정 을 수행함으로써, 비트 슬라이스들 각각의 길이를 동일하게 할 수 있다. 이와 같이, 수학식 1에 예시된 바와 같은 입력데이터를 두 개의 비트 슬라이스로 나누는 과정에서, 하위 비트 슬라이스에 부호비트( )를 추가한 예를 수학식으로 표현하면 수학식 2에 예시된 바와 같다. 수학식 2"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 5의 ⒞는 상기 부호비트의 추가로 그 길이가 동일해진 비트 슬라이스들 각각에서 0값을 갖는 비트 슬라이스 의 수를 증가시키기 위해, 상기 입력데이터의 MSB 비트(즉, 부호비트)값( )을 상위 비트 슬라이스에는 더하고 하위 비트 슬라이스에는 빼는 과정을 수행한 결과를 예시하고 있다. 수학식 3은 이러한 연산 과정을 예시하고 있다. 수학식 3"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 4, "content": "도 5의 ⒟는 상기 과정을 거쳐 생성된 두 개의 비트 슬라이스를 예시하고 있다. 도 5의 ⒟를 참조하면, 상기 두 개의 비트 슬라이스들은 모두 4비트 길이에 부호를 가지게 된다. 특히, 상위 비트 슬라이스의 경우 도 5의 ⒞에 예시된 과정을 거치면서, 1111가 0000로 변환되어 0값 비트 슬라이스(일명, Zero-slice)가 된다. 이와 같이, 상위 비트인 1111 값이 0000값으로 변환되는 부호형 비트 슬라이스의 특성으로 인해, 본 발명은 상 위 비트가 1111 값을 가지는 0값 근처의 음수데이터의 희소성을 활용할 수 있게 되고, 결과적으로 2의 보수데이 터에서 0값 근처의 양수데이터와 0값 근처의 음수데이터 모두의 희소성을 활용할 수 있게 된다. 이를 수학식으로 나타내면 수학식 4에 예시된 바와 같다. 수학식 4"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이와 같은 부호형 비트 슬라이스 표현법은 다양한 비트 길이 정밀도에 다양한 비트 슬라이스 길이로 적용될 수 있다. 먼저, 임의의 2의 보수 N-비트 데이터는 수학식 5에 예시된 바와 같이 표현할 수 있다. 수학식 5"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이 때, 는 0 또는 1 값을 가지며, 은 부호 비트를 나타낸다. 한편, 임의의 N-비트(이 때, N은 M, M+(M-1), M+2*(M-1), … ) 데이터 A에 M-비트 (이 때, M은 2, 3, 4, … )슬라이스를 취할 경우, 수학식 6에 예시된 바와 같이 표현할 수 있다. 수학식 6"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 6에 예시된 바와 같이 표현된 A 데이터를 부호형 M-비트 슬라이스를 만들기 위해, 수학식 7과 같이 (M- 1) 비트를 묶어서 (N-1)/(M-1)개의 그룹으로 정리할 수 있다. 수학식 7"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "한편, 수학식 7과 같이 표현된 A 데이터에 부호 비트인 을 각각 비트 슬라이스 그룹에 더하고 빼면 수학식 8과 같이 정리할 수 있다. 수학식 8"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이로써 각 비트 슬라이스 그룹에 부호 비트가 추가되었고, M-비트의 부호 비트 슬라이스인 A'를 이용하여 상기 수학식 8을 다시 정리하면 수학식 9에 예시된 바와 같다.수학식 9"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "이와 같은 수학식 9를 이용하면, 본 발명의 부호형 비트 슬라이스 표현법은 임의의 2의 보수 데이터에 적용 가 능하다. 구체적인 예시로, 2의 보수 데이터 A를 4-비트 (M=4) 슬라이스로 분할하는 경우, 상기 2의 보수 데이터 A는 세 비트 값을 묶어서 정리될 수 있으며, 상기 수학식 6은 다음의 수학식 10과 같이 표현할 수 있다. 수학식 10"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "이 때, N은 4, 7, 10, 13, … 을 나타낸다. 한편, 상기 수학식 10에 부호 비트인 을 각각 비트 슬라이스 그룹에 더하고 빼면 아래의 수학식 11과 같이 정리할 수 있다. 수학식 11"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "이로써 각 비트 슬라이스 그룹에 부호 비트가 추가되었고, 4-비트의 부호 비트 슬라이스 A'로 상기 수학식 11을 다시 정리하면 수학식 12와 같다.수학식 12"}
{"patent_id": "10-2023-0043166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "이와 같이, 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)은 부호형 비트 슬라이스 표현법을 이용하 여 임의의 2의 보수 데이터를 분할하여 표현할 수 있고, 본 발명의 비트 슬라이스 연산기, 및 인공지능 신경망 가속장치는 이러한 부호형 비트 슬라이스를 이용함으로써, 연산로직의 면적을 줄이고, 결과적으로 하드웨어의 크기를 줄일 수 있으며, 연산속도를 향상시킴과 동시에 전력 소모를 줄일 수 있다. 다시 도 1을 참조하면, 메모리(Global Memory)는 인공지능 신경망을 가속하기 위한 로-데이터(raw data) (즉, 비트 슬라이스로 분할되기 전의 데이터들)를 저장하고, 상기 로-데이터를 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit) 으로 전달함으로써, 부호형 비트 슬라이스를 생성할 수 있도록 한다. 출력 바이너리 마스크(Output Binary Mask) 유닛은 후술될 스키핑 연산 유닛(Zero-slice-skip PE)으 로부터 상위 비트 슬라이스에 대한 스키핑 연산 결과를 입력으로 받아 바이너리 마스크를 생성한다. 이를 위해, 출력 바이너리 마스크 유닛은 상기 스키핑 연산 결과값들 간에 비교 연산을 수행하여 이 값 중 최댓값에 해당하는 값은 1로 표현하고 아닌 값(0값)은 0으로 표현하는 맥스 풀링 출력에 해당하는 바이너리 마스크를 생 성한다. 또한, 출력 바이너리 마스크 유닛은 인공지능 신경망 가속장치에서 출력추측법을 적용시 이를 이 용할 수 있도록, 상기 출력 바이너리 마스크를 부호형 비트 슬라이스 생성/압축 유닛(SBR/RLE Unit)으로 전달한다. SBR/RLE Unit(특히, 희소데이터 압축부)은 상기 출력 바이너리 마스크(Output Binary Mask)를 이용하 여 희소 입력 데이터를 새롭게 압축한다. 도 6은 출력 바이너리 마스크를 이용한 희소 입력 스키핑 연산 및 희소 출력 스키핑 연산과정을 예시하고 있다. 도 6을 참조하면, 출력 바이너리 마스크 유닛은 스키핑 연산 유닛(Zero-slice-skip PE)으로부터 상위 비트 슬라이스에 대한 희소 입력 스키핑 연산 결과를 입력으로 받아 4비트의 바이너리 마스크를 생성하고, SBR/RLE Unit(특히, 희소데이터 압축부)은 상기 출력 바이너리 마스크(Output Binary Mask)를 이용하여 희소 입력 데이터를 새롭게 압축하고, 스키핑 연산 유닛(Zero-slice-skip PE)은 상기 새롭게 압축된 희소 입력 데이터를 전달받아 스키핑 연산을 수행한다. 스키핑 연산 유닛(Zero-slice-skip PE)은 상기 부호형 비트 슬라이스의 곱셈 및 덧셈 연산과, 비트 슬라이 스 단위의 데이터 스키핑 연산을 수행한다. 이를 위해, 스키핑 연산 유닛(Zero-slice-skip PE)은 입력버퍼(IBUF), 인덱스버퍼(IDXBUF), 가 중치버퍼(WBUF), 스키핑부(Zero-skip Unit), 및 연산기 어레이를 포함한다. 입력버퍼(IBUF)는 데이터 관리 유닛(DMU Core)으로부터, 압축된 부호형 비트 슬라이스인 입력 비트 슬라이스를 전달받아 저장한다. 인덱스버퍼(IDXBUF)는 상기 입력 비트 슬라이스의 저장 위치인 압축 인덱스를 저장한다. 가중치버퍼(WBUF)는 상기 부호형 비트 슬라이스로 구현된 가중치 데이터를 저장한다. 스키핑부(Zero-skip Unit)는 상기 압축 인덱스에 의거하여, 가중치 데이터를 불러와야 할 상기 가중치버퍼 (WBUF)의 주소를 계산한다. 연산기 어레이는 다수의 부호형 비트 슬라이스 연산기들로 구성되며, 입력버퍼(IBUF)로부터 입 력 비트 슬라이스를 읽어오고, 스키핑부(Zero-skip Unit)에서 계산된 주소 정보에 의해 상기 가중치버퍼 (WBUF)로부터 가중치 데이터를 읽어와서 곱셈 및 축적 연산을 수행한다. 부호형 비트 슬라이스 연산기는 상기 입력 비트 슬라이스와 상기 가중치 데이터에 대하여 순차적으로 곱셈 연산을 수행하는 곱셈연산기, 곱셈연산기의 연산결과를 누적하는 덧셈연산기, 및 덧셈연산기의 연산결과를 저장하는 레지스터를 포함한다. 부호형 비트 슬라이스 연산기는 부호형 비트 슬 라이스 생성/압축 유닛(SBR/RLE Unit)에서 생성된 부호형 비트 슬라이스를 연산하되, 상기 부호형 비트 슬 라이스는 각각 부호비트를 포함하는 동일길이의 데이터이다. 따라서, 본 발명의 부호형 비트 슬라이스 연산기 는 부호를 연장하기 위한 별도의 로직을 추가로 필요로 하지 않고, 비트 길이가 최적화된 로직으로 구현될 수 있다. 도 7은 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스 연산기를 종래의 비트 슬라이스 연산기와 비교하여 설명하기 위한 도면으로서, 도 7의 (a)는 종래의 비트 슬라이스 연산기 구조의 예를 도시하고, 도 7의 (b) 및 (c)는 본 발명의 제1 및 제2 실시 예에 따른 부호형 비트 슬라이스 연산기 구조의 예들을 도시하고 있다. 도 7의 (a)를 참조하면, 종래에는, 부호를 포함하는 상위 비트 슬라이스(BS1)와 부호를 가지지 않는 하위 비트 슬라이스(BS2)를 연산하기 위해, 하위 비트 슬라이스(BS2)에 부호를 가지도록 부호 연장로직이 추가로 필요 하다. 따라서, 4비트의 상위 비트 슬라이스(BS1) 및 하위 비트 슬라이스(BS2)가 부호 연장로직을 통해 각각 5비트 데이터로 연장되어 출력되고, 곱셈연산기, 덧셈연산기, 및 레지스터 각각은 이와 같이 연장 된 데이터에 적합한 크기로 구성되어야 한다. 즉, 상기 예에서, 덧셈연산기는 곱셈연산기로부터 10비트 의 연산결과를 전달받아 연산한 후, 그 누적 연산결과를 레지스터에 저장하되, 레지스터는 15비트 크기 로 구현된다. 한편, 도 7의 (b) 및 (c)를 참조하면, 본 발명의 부호형 비트 슬라이스 연산기는 상위 부호형 비트 슬라이스 (S_BS1)와 하위 부호형 비트 슬라이스(S_BS2)가 모두 부호 비트를 가지고 있으므로 부호 연장 로직이 필요 없으 며, 이로 인해 비트 길이가 최적화된 곱셈연산기(510a, 510b), 덧셈연산기(520a, 520b), 및 레지스터(530a, 530b)를 사용한다. 즉, 도 7의 (b)에 예시된 곱셈연산기(510a)는 4비트의 부호형 비트 슬라이스들(S_BS1, S_BS2)에 대하여 부호 연 장없이 바로 곱셈 연산한 후 8비트의 연산결과를 출력하고, 덧셈연산기(520a)는 상기 8비트의 연산결과를 누적 하여 13비트의 레지스터(530a)에 저장한다. 한편, 도 7의 (c)에 예시된 곱셈연산기(510b)는 4비트의 부호형 비트 슬라이스들(S_BS1, S_BS2)에 대하여 부호 연장없이 바로 곱셈 연산한 후 7비트의 연산결과를 출력하고, 덧셈연산기(520b)는 상기 7비트의 연산결과를 누 적하여 12비트의 레지스터(530b)에 저장하는데, 이는, 출력 추측법 사용시 출력 추측 오차를 줄이기 위해, 상기 부호형 비트 슬라이스 생성시, 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 생성하였기 때문이다. 즉, 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 생성한 경우, 도 3에 예시 된 바와 같이, 부호형 비트 슬라이스 값이 '1000' 인 경우가 발생하지 않기 때문에, 7비트로 모든 데이터를 표 현할 수 있기 때문이다. 한편, 스키핑 연산 유닛(Zero-slice-skip PE)은 상기 부호형 비트 슬라이스를 이용하여 비트 슬라이스 단 위의 데이터 스키핑 연산을 수행하되, 연속된 여러 비트 슬라이스 데이터가 모두 0값일 경우 스키핑 연산을 수 행한다. 이 때, 데이터 스키핑 연산을 위한 처리 과정은 공지의 기술을 이용할 수 있으므로, 구체적인 설명은 생략한다. 축적유닛(Accumulation Unit)은 스키핑 연산 유닛(Zero-slice-skip PE)의 연산결과를 축적하여 저장 한다. 이를 위해, 축적유닛(Accumulation Unit)은 축적연산을 위한 덧셈트리(Adder Tree), 비트 슬 라이스들의 연산위치를 결정하기 위해 비트-쉬프트를 수행하는 비트 쉬프터(Bit-shifter), 출력 데이터를 버퍼링하는 출력버퍼(OBUF), 및 쓰기컨트롤러(Write Ctrlr)를 포함하고, 외부 제어명령 (Instruction)에 의해 동작할 수 있다. 예를 들어, 축적유닛(Accumulation Unit)은 탑-콘트롤러(top controller)(미도시)로부터 전달된 제어명령(Instruction)에 의해, 상기 연산결과를 축적하여 저장할 수 있다. 한편, 본 발명의 인공지능 신경망 가속장치는 입력 데이터와 가중치 데이터의 희소성을 비교하고, 상기 입력 데 이터 보다 상기 가중치 데이터의 희소성이 더 높을 경우 가중치 스키핑 연산을 수행하도록 동작할 수 있는데, 이를 위해, 본 발명의 인공지능 신경망 가속장치는, 상기 가중치 스키핑 연산을 제어하는 가중치 스키핑 연산 컨트롤러(미도시)를 더 포함할 수 있다. 상기 가중치 스키핑 연산 컨트롤러는 상기 입력 데이터와 상기 가중치 데이터의 희소성을 비교하여 상기 입력 데이터 보다 상기 가중치 데이터의 희소성이 더 높을 경우, 가중치 스키핑 연산을 수행하도록 상기 데이터 관리 유닛(DMU Core), 상기 스키핑 연산 유닛(Zero-slice-skip PE), 및 상기 축적유닛(Accumulation Unit)의 동작을 제어할 수 있다.즉, 입력 데이터 보다 가중치 데이터의 희소성이 더 높은 경우, 상기 가중치 스키핑 연산 컨트롤러는 상기 가중 치 데이터를 압축하여 압축된 부호형 비트 슬라이스인 가중치 비트 슬라이스를 출력하도록 상기 데이터 관리 유 닛(DMU Core)을 제어하고, 상기 가중치 비트 슬라이스를 입력버퍼(IBUF)에 저장하고, 상기 가중치 비트 슬라이 스의 저장 위치인 압축 인덱스를 인덱스 버퍼에 저장하고, 상기 부호형 비트 슬라이스로 구현된 입력데이터를 가중치 버퍼(WBUF)에 저장하도록 상기 스키핑 연산 유닛(Zero-slice-skip PE)을 제어하고, 상기 스키핑 연산 유 닛(Zero-slice-skip PE)의 출력데이터를 재정렬하여 출력버퍼(OBUF)에 저장하도록 상기 축적유닛(Accumulation Unit)의 동작을 제어할 수 있다. 이 때, 가중치 스키핑 연산 컨트롤러는 ‘부호형 비트 슬라이스로 구현된 입력 데이터(압축전)’와 ‘부호형 비 트 슬라이스로 구현된 가중치 데이터(압축전)’의 희소성을 비교한다. 즉, 가중치 스키핑 연산 컨트롤러는 입력 데이터와 가중치 데이터를 부호형 비트 슬라이스로 표현한 후 이를 압축할 때 상기 희소성 비교에 의해 희소 연 산 대상을 결정할 수 있다. 특히, 가중치 스키핑 연산 컨트롤러는 심층 신경망의 레이어 별로, 입력 데이터 전 체와 가중치 데이터 전체의 희소성을 비교하는 것이 아닌, 데이터 일부만 비교하여 해당 레이어의 희소 연산 대 상을 결정한다. 상기 입력 데이터와 가중치 데이터는 모두 DMU 코어의 메모리(Global Memory)에 저장 되어 있으며, 이 위치는 탑-컨트롤러(top controller)(즉, 중앙처리장치)가 알고 있다. 도 8은 본 발명의 일 실시 예에 따른 가중치 스키핑 연산 과정을 설명하기 위한 도면으로서, 도 8의 (a)는 일반 적인 데이터 스키핑 연산(즉, 입력데이터의 스키핑 연산) 과정을 예시하고, 도 8의 (b)는 가중치 스키핑 연산 과정을 예시한다. 도 8의 (a)를 참조하면, 입력데이터의 스키핑 연산을 위해, 스키핑 연산 유닛(Zero-slice-skip PE)은 입력 데이터(I)를 입력버퍼(IBUF)에, 압축 인덱스를 인덱스버퍼에, 가중치데이터(W)를 가중치버퍼에 각각 저장한 후, 연산기 어레이에서 이들을 연산한다. 그리고, 그 결과를 출력버퍼에 저장한다. 도 8의 (b)를 참조하면, 가중치데이터의 스키핑 연산을 위해, 스키핑 연산 유닛(Zero-slice-skip PE)은 가 중치데이터(W)를 입력버퍼(IBUF)(210a)에, 가중치데이터(W)의 압축인덱스를 인덱스버퍼(220a)에, 입력데이터 (I)를 가중치버퍼(230a)에 각각 저장한 후, 연산기 어레이(250a)에서 이들을 연산한다. 한편, 축적유닛 (Accumulation Unit)의 쓰기 컨트롤러(Write Ctrlr)는 상기 연산결과를 재정렬(260a)한 후 출력버퍼 에 저장한다. 이로 인해, 본 발명은 입력 데이터와 가중치 데이터 중 더욱 희소한 데이터를 스키핑하여 인공지능 신경망 연산 을 가속화함으로써, 인공지능 신경망 연산 속도를 더욱 효율적으로 향상시킬 수 있다. 상기한 바와 같이, 본 발명은 N(이 때, N은 자연수 임) 비트 정밀도를 가지는 2의 보수데이터를 M(이 때, M은 자연수이고, M < N 임) 비트 슬라이스로 나눌 때, 각 비트 슬라이스가 모두 부호 비트를 가지는 동일 길이의 부 호형 비트 슬라이스를 생성함으로써, 비트 슬라이스의 곱셈 및 축적연산(MAC: multiply and accumulate)시 부호 연장을 하지 않아도 되도록 하고, 이로 인해 비트 길이가 연장된 연산기를 사용하지 않음으로써 연산로직의 면 적을 줄일 수 있는 특징이 있다. 또한, 본 발명은, 전체 길이 데이터의 부호비트 값을, 각 부호형 비트 슬라이스의 LSB에 더한 후 바로 하위에 인접한 부호형 비트 슬라이스의 부호비트에서 빼는 과정을 반복함으로써, 상기 부호형 비트 슬라이스들 각각에 서 0값을 갖는 비트수를 증가시키고, 이로 인해 희소 데이터 압축시 데이터 압축률을 높이고, 희소 데이터 스키 핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 특징이 있다. 또한, 본 발명은 상기 부호형 비트 슬라이스를 연산함으로써, 2의 보수데이터에서 0값 근처의 양수데이터와 0값 근처의 음수데이터 모두의 희소성을 활용할 수 있고, 이로 인해, 희소 데이터 압축시 데이터 압축률을 높일 수 있으며, 희소 데이터 스키핑 연산시 연산 속도를 향상시킴과 동시에 전력 소모를 낮출 수 있는 특징이 있다. 또한, 본 발명은 상기 부호형 비트 슬라이스의 값이 대칭이 되도록 양수인 비트 슬라이스의 수와 음수인 비트 슬라이스의 수를 동일하게 함으로써, 상위 비트 슬라이스 연산을 통한 출력값 추측 오차를 줄이고, 이로 인해 추측 연산으로 인한 인공지능 신경망의 정확도를 향상시킬 수 있는 특징이 있다. 또한, 본 발명은 희소 입력 스키핑 연산을 통해 상위 비트 슬라이스 연산을 수행하고 그 결과값을 바탕으로 최 종 출력값의 크기를 추측한 후 하위 비트 슬라이스 연산시 추측된 희소 출력 위치에 해당하는 입력값들을 희소 화함으로써, 희소 입력 비트 슬라이스와 희소 출력 데이터 연산을 동시에 스키핑 연산하고, 이로 인해 연산속도 를 향상시킬 수 있는 특징이 있다. 또한, 본 발명은 희소 출력 위치에 해당하는 입력값들을 희소화시켜 연산하기 때문에, 희소 입력 비트 슬라이스 압축과 희소 출력 데이터 압축 방식을 통일시킬 수 있고, 이로 인해 연산 속도를 향상시킬 수 있는 특징이 있다. 또한, 본 발명은 동일 개수의 입력 데이터와 가중치 데이터를 불러와 곱셈 및 축적연산을 수행함으로써 입력데 이터와 가중치 데이터 간의 스키핑 전환이 용이하고, 이로 인해 입력 데이터와 가중치 데이터 중 더욱 희소한 데이터를 스키핑하여 인공지능 신경망 연산을 가속화함으로써, 인공지능 신경망 연산 속도를 향상시킬 수 있는 특징이 있다. 이상의 설명에서는 본 발명의 바람직한 실시예를 제시하여 설명하였으나, 본 발명이 반드시 이에 한정되는 것은 아니며, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경할 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2023-0043166", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 인공지능 신경망 가속장치에 대한 개략적인 블록도이다. 도 2는 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스 생성/압축 유닛에 대한 개략적인 블록도이다. 도 3은 본 발명의 일 실시 예에 따른 부호비트 연산부의 동작을 부연 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스를 생성하는 방법에 대한 처리 흐름도이다. 도 5는 본 발명의 일 실시 예에 따라 부호형 비트 슬라이스를 생성하는 과정을 예로 들어 설명하기 위한 도면이 다. 도 6은 본 발명의 일 실시 예에 따라 출력 바이너리 마스크를 이용하여 희소 입력 스키핑 연산 및 희소 출력 스 키핑 연산을 수행하는 과정을 예시하고 있다. 도 7은 본 발명의 일 실시 예에 따른 부호형 비트 슬라이스 연산기를 종래의 비트 슬라이스 연산기와 비교하여 설명하기 위한 도면이다. 도 8은 본 발명의 일 실시 예에 따른 가중치 스키핑 연산 과정을 설명하기 위한 도면이다."}
