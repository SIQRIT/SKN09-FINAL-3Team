{"patent_id": "10-2019-0107655", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0026623", "출원번호": "10-2019-0107655", "발명의 명칭": "인공지능 모델을 학습시키는 시스템 및 방법", "출원인": "삼성전자주식회사", "발명자": "이병찬"}}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 인공지능 모델을 학습시키는 방법에 있어서,복수의 데이터 포인트들을 포함하는 데이터세트로부터, 데이터 포인트의 속성을 나타내는 레이블(label)이 레이블링(labeling)되지 않은 데이터 포인트들을 획득하는 단계;상기 레이블링되지 않은 데이터 포인트들 중, 소정의 개수의 후보 데이터 포인트들을 선택하는 단계;상기 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력하는 단계; 및상기 입력 요청에 응답한 사용자 입력에 기초하여, 상기 선택된 후보 데이터 포인트들을 레이블링함으로써, 레이블링된 후보 데이터 포인트들을 획득하는 단계;상기 레이블링된 후보 데이터 포인트들을 이용하여 상기 인공지능 모델을 갱신하는 단계;를 포함하는, 인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 인공지능 모델은 확률분포를 가지는 파라미터를 이용하여 레이블링되지 않은 데이터 포인트의 레이블을 예측하는 것을 특징으로 하고,상기 인공지능 모델을 갱신하는 단계는,상기 레이블링된 후보 데이터 포인트들을 이용하여 상기 파라미터의 확률분포를 갱신하는 단계를 포함하는,인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 소정의 개수의 후보 데이터 포인트들을 선택하는 단계는,상기 레이블링되지 않은 데이터 포인트들 각각이 상기 파라미터의 확률분포를 갱신하는 데 기여하는 정도를 예측함으로써, 상기 선택된 후보 데이터 포인트들을 이용하여 상기 파라미터의 확률분포를 갱신한 결과가 상기 데이터세트에 포함된 전체 데이터 포인트들을 이용하여 상기 파라미터의 확률분포를 갱신한 결과에 근접하도록 하기 위하여, 상기 레이블링되지 않은 데이터 포인트들 중에서 상기 소정의 개수의 후보 데이터 포인트들을 선택하는 단계를 포함하는,인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 소정의 개수의 후보 데이터 포인트들을 선택하는 단계는,상기 레이블링되지 않은 데이터 포인트들에 대응되는, 데이터 포인트 벡터들을 획득하는 단계;상기 데이터 포인트 벡터들 중 소정의 개수의 데이터 포인트 벡터들을 선택하는 단계; 및상기 선택된 데이터 포인트 벡터들에 대응되는 데이터 포인트들을 상기 후보 데이터 포인트들로 결정하는 단계;공개특허 10-2021-0026623-3-를 포함하는,인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 데이터 포인트 벡터들은, 상기 레이블링되지 않은 데이터 포인트 각각이 상기 인공지능 모델의 갱신에 기여하는 정도를 예측함으로써 계산되는 것인,인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 데이터 포인트 벡터들 중 상기 소정의 개수의 데이터 포인트 벡터들을 선택하는 단계는, 상기 데이터 포인트 벡터들로부터 상기 데이터세트를 대표하는 벡터를 획득하는 단계; 및상기 데이터 포인트 벡터와 상기 데이터세트를 대표하는 벡터 간의 근접한 정도에 기초하여 상기 소정의 개수의데이터 포인트 벡터들을 선택하는 단계;를 포함하는,인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 데이터 포인트 벡터와 상기 데이터세트를 대표하는 벡터 간의 근접한 정도는, 상기 데이터 포인트 벡터와상기 데이터세트를 대표하는 벡터 간의 가중 내적(weighted inner product)에 기초하여 결정되는 것을 특징으로하는, 인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 소정의 개수의 후보 데이터 포인트들을 선택하는 단계는,베이즈 선형 회귀 (Bayesian linear regression) 방법에 기초하여, 상기 레이블링되지 않은 데이터 포인트들 중에서 상기 소정의 개수의 후보 데이터 포인트들을 선택하는 단계를 포함하는, 인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 소정의 개수의 후보 데이터 포인트들을 선택하는 단계는,프랭크-울프 최적화 (Frank-Wolfe Optimization) 알고리즘을 사용하여, 상기 레이블링되지 않은 데이터 포인트들 중에서 상기 소정의 개수의 후보 데이터 포인트들을 선택하는 단계를 포함하는, 인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 소정의 개수의 후보 데이터 포인트들을 선택하는 단계는,공개특허 10-2021-0026623-4-상기 인공지능 모델의 예측 정확도를 평가하는 단계; 및상기 예측 정확도가 기준 미만으로 평가된 경우, 상기 레이블링되지 않은 데이터 포인트들 중, 상기 소정의 개수의 후보 데이터 포인트들을 선택하는 단계; 를 포함하는,인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 인공지능 모델을 갱신하는 단계는,상기 레이블링된 후보 데이터 포인트들을 한꺼번에 상기 데이터세트에 추가하는 단계; 및상기 레이블링된 후보 데이터 포인트들을, 상기 데이터세트에 포함된 미리 레이블링된 다른 데이터 포인트들과함께 상기 인공지능 모델에 입력함으로써 상기 인공지능 모델을 갱신하는 단계;를 포함하는,인공지능 모델을 학습시키는 방법."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "인공지능 모델을 학습시키는 전자 장치에 있어서,하나 이상의 인스트럭션을 저장하는 메모리; 및상기 하나 이상의 인스트럭션을 실행하는 프로세서; 를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 복수의 데이터 포인트들을 포함하는 데이터세트로부터, 데이터 포인트의 속성을 나타내는 레이블(label)이 레이블링(labeling)되지 않은 데이터 포인트들을 획득하고,상기 레이블링되지 않은 데이터 포인트들 중, 소정의 개수의 후보 데이터 포인트들을 선택하고,상기 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력하고,상기 입력 요청에 응답한 사용자 입력에 기초하여, 상기 선택된 후보 데이터 포인트들을 레이블링함으로써, 레이블링된 후보 데이터 포인트들을 획득하고,상기 레이블링된 후보 데이터 포인트들을 이용하여 상기 인공지능 모델을 갱신하는, 전자 장치."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 인공지능 모델은 확률분포를 가지는 파라미터를 이용하여 레이블링되지 않은 데이터 포인트의 레이블을 예측하는 것을 특징으로 하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 레이블링된 후보 데이터 포인트들을 이용하여 상기 파라미터의 확률분포를 갱신하는,전자 장치."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 공개특허 10-2021-0026623-5-상기 레이블링되지 않은 데이터 포인트들 각각이 상기 파라미터의 확률분포를 갱신하는 데 기여하는 정도를 예측함으로써, 상기 선택된 후보 데이터 포인트들을 이용하여 상기 파라미터의 확률분포를 갱신한 결과가 상기 데이터세트에 포함된 전체 데이터 포인트들을 이용하여 상기 파라미터의 확률분포를 갱신한 결과에 근접하도록 하기 위하여, 상기 레이블링되지 않은 데이터 포인트들 중에서 상기 소정의 개수의 후보 데이터 포인트들을 선택하는,전자 장치."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 레이블링되지 않은 데이터 포인트들에 대응되는, 데이터 포인트 벡터들을 획득하고,상기 데이터 포인트 벡터들 중 소정의 개수의 데이터 포인트 벡터들을 선택하고,상기 선택된 데이터 포인트 벡터들에 대응되는 데이터 포인트들을 상기 후보 데이터 포인트들로 결정하는, 전자장치."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 데이터 포인트 벡터들은, 상기 레이블링되지 않은 데이터 포인트 각각이 상기 인공지능모델의 갱신에 기여하는 정도를 예측함으로써 계산되는 것인, 전자 장치."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 데이터 포인트 벡터들로부터 상기 데이터세트를 대표하는 벡터를 획득하고,상기 데이터 포인트 벡터와 상기 데이터세트를 대표하는 벡터 간의 근접한 정도에 기초하여 상기 소정의 개수의데이터 포인트 벡터들을 선택하는,전자 장치."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 인공지능 모델의 예측 정확도를 평가하고,상기 예측 정확도가 기준 미만으로 평가된 경우, 상기 레이블링되지 않은 데이터 포인트들 중, 상기 소정의 개수의 후보 데이터 포인트들을 선택하는,전자 장치."}
{"patent_id": "10-2019-0107655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 레이블링된 후보 데이터 포인트들을 한꺼번에 상기 데이터세트에 추가하고,상기 레이블링된 후보 데이터 포인트들을, 상기 데이터세트에 포함된 미리 레이블링된 다른 데이터 포인트들과함께 상기 인공지능 모델에 입력함으로써 상기 인공지능 모델을 갱신하는,전자 장치.공개특허 10-2021-0026623-6-청구항 20 제 1 항의 방법을 컴퓨터에서 수행하도록 하는 프로그램이 저장된, 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 모델을 학습시키는 전자 장치가 개시된다. 개시되는 전자 장치가 인공지능 모델을 학습시키는 방법은, 복수의 데이터 포인트들을 포함하는 데이터세트로부터, 데이터 포인트의 속성을 나타내는 레이블(label)이 레이 블링(labeling)되지 않은 데이터 포인트들을 획득하는 단계; 상기 레이블링되지 않은 데이터 포인트들 중, 소정 의 개수의 후보 데이터 포인트들을 선택하는 단계; 상기 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력하는 단계; 상기 입력 요청에 응답한 사용자 입력에 기초하여, 상기 선택된 후보 데이터 포인트 들을 레이블링함으로써, 레이블링된 후보 데이터 포인트들을 획득하는 단계; 및 상기 레이블링된 후보 데이터 포 인트들을 이용하여 상기 인공지능 모델을 갱신하는 단계;를 포함한다."}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능 모델을 학습시키는 시스템 및 방법에 관한 것으로서, 보다 상세하게는 레이블링되지 않은 데이터 포인트들을 이용하여 인공지능 모델을 학습시키는 전자 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 Rule 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 Rule 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론 /예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 한편, 기계학습을 위해서는 일반적으로 데이터의 속성에 대한 올바른 정보를 포함하는 학습 데이터가 제공되어 야 할 필요가 있다. 따라서 입력 데이터에 정보를 할당하는 레이블링(labeling) 작업이 필요하다. 능동 학습 (Active Learning)은 레이블링되지 않은 데이터에 대하여 사용자 등의 외부 정보원에 질의할 수 있는 기계학습 의 한 방법이다. 레이블링되지 않은 데이터 포인트가 대량으로 주어지는 경우, 레이블링할 데이터 포인트를 선택하고, 데이터 포 인트를 레이블링하고, 레이블링된 데이터 포인트를 인공지능 모델에 학습시키는 것을 반복하는 작업은 많은 시 간 및 컴퓨팅 자원을 소모한다. 따라서, 능동 학습을 효율적으로 수행하기 위해서는 레이블링할 데이터 포인트 를 선택하는 과정을 최적화하여야 할 필요가 있다."}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다양한 실시예들은, 레이블링되지 않은 데이터 포인트들을 이용하여 인공지능 모델을 효율적으로 학습시킬 수 있도록 하는 시스템 및 방법을 제공할 수 있다. 또한, 다양한 실시예들은, 인공지능 모델을 효율적으로 학습시키기 위하여, 레이블링되지 않은 데이터 포인트들 중에서 레이블링할 데이터 포인트들을 선택하는 개선된 시스템 및 방법을 제공할 수 있다. 또한, 다양한 실시예들은, 인공지능 모델을 효율적으로 학습시키기 위하여, 사용자의 입력에 기초하여 데이터를 레이블링하고, 레이블링된 데이터 포인트들을 이용하여 인공지능 모델을 학습시키는 개선된 시스템 및 방법을 제공할 수 있다."}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 복수의 데이터 포인트들을 포 함하는 데이터세트로부터, 데이터 포인트의 속성을 나타내는 레이블이 레이블링(labeling)되지 않은 데이터 포 인트들을 획득하는 단계; 상기 레이블링되지 않은 데이터 포인트들 중, 소정의 개수의 후보 데이터 포인트들을 선택하는 단계; 상기 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력하는 단계; 상기 입력 요청에 응답한 사용자 입력에 기초하여, 상기 선택된 후보 데이터 포인트들을 레이블링함으로써, 레이블링 된 후보 데이터 포인트들을 획득하는 단계; 및 상기 레이블링된 후보 데이터 포인트들을 이용하여 상기 인공지 능 모델을 갱신하는 단계; 를 포함하는, 전자 장치가 인공지능 모델을 학습시키는 방법을 제공할 수 있다. 또한, 본 개시의 제2 측면은, 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 하나 이상의 인스트럭션을 실행하는 프로세서; 를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 복수의 데이 터 포인트들을 포함하는 데이터세트로부터, 데이터 포인트의 속성을 나타내는 레이블이 레이블링(labeling)되지 않은 데이터 포인트들을 획득하고, 상기 레이블링되지 않은 데이터 포인트들 중, 소정의 개수의 후보 데이터 포 인트들을 선택하고, 상기 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력하고, 상기 입력 요청에 응답한 사용자 입력에 기초하여, 상기 선택된 후보 데이터 포인트들을 레이블링함으로써, 레이블링 된 후보 데이터 포인트들을 획득하고, 상기 레이블링된 후보 데이터 포인트들을 이용하여 상기 인공지능 모델을 갱신하는, 인공지능 모델을 학습시키는 전자 장치를 제공할 수 있다. 또한, 본 개시의 제3 측면은, 제 1 측면의 방법을 컴퓨터에서 수행하도록 하는 프로그램이 저장된, 컴퓨터로 읽 을 수 있는 기록매체를 제공할 수 있다."}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "다양한 실시예들에 따르면, 레이블링되지 않은 데이터 포인트들 중에서 인공지능 모델을 효율적으로 갱신할 수 있는 후보 데이터 포인트들을 일괄적으로 선택하여 레이블링할 수 있다. 다양한 실시예들에 따르면, 사용자의 입력에 기초하여 레이블링된 데이터 포인트들을 일괄적으로 이용하여 인공 지능 모델을 갱신할 수 있다. 다양한 실시예들에 따르면, 인공지능 모델을 학습시키는 시간 및 비용을 감소시키면서, 인공지능 모델 학습의 효율을 향상시키고, 학습된 모델의 정확도를 높일 수 있다."}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상 세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"…부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프 트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작될 수 있다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동 작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어할 수 있다. 또는, 하나 또는 복수의 프로 세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드 웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어질 수 있다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 이러 한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/또는 시스 템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습 (unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learnin g)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행할 수 있다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결 과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스 트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망 (DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등 이 있으나, 전술한 예에 한정되지 않는다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였 다. 도 1은 일 실시예에 따른, 인공지능 모델을 학습시키는 시스템의 개요도이다. 도 1을 참조하면, 상기 인공지능 모델을 학습시키는 시스템은 전자 장치 및 사용자 인터페이스를 포함할 수 있다. 전자 장치는 데이터세트를 이용하여 인공지능 모델을 학습시키기 위한 장치일 수 있다. 전 자 장치는 인공지능 모델 및 인공지능 모델을 학습시키는 학습 유닛을 포함할 수 있다. 데이터세트는 복수의 데이터 포인트들을 포함하는 데이터의 집합일 수 있다. 데이터 포인트는 데이터세트 를 구성하는 개별 데이터(datum)를 의미한다. 데이터 포인트는 통계 자료, 텍스트, 오디오, 이미지, 비디오 등 을 포함하거나 또는 이들에 대응될 수 있다. 데이터 포인트는 로우 데이터(raw data)를 포함할 수 있다. 데이 터 포인트는 로우 데이터를 전처리하여 획득한, 데이터의 특성을 나타내는 정보를 포함할 수 있다. 데이터세트는 전자 장치 내의 메모리 또는 스토리지에 저장되어 있을 수 있다. 또는, 데이터세트 는 전자 장치 외부의 저장 장치에 저장되어 있을 수 있다. 각 데이터 포인트는 하나 이상의 레이블(label)을 포함할 수 있다. 레이블은 일반적으로 데이터 포인트과 관련 된 유의미한 정보일 수 있다. 레이블은 데이터 포인트의 속성을 나타내거나 정의하는 것일 수 있다. 일 실시 예에서, 레이블은 데이터 포인트에 포함된 정보 또는 데이터 포인트와 연관된 정보일 수 있다. 일 실시예에서, 레이블은 데이터 포인트를 분류하거나 기준에 따라 평가한 결과일 수 있다. 일 실시예에서, 레이블은 데이터 포인트를 기초로 추론 또는 예측을 수행한 결과일 수 있다. 그러나 상기의 실시예에 한정되지 않고, 데이터 포인트와 관련되는 어떤 유의미한 정보도 레이블로서 할당될 수 있다. 레이블링(labeling)은 데이터 포인트에 레이블을 할당하는 작업을 뜻한다. 레이블링된(labeled) 데이터 포인트 는 데이터 포인트와 레이블의 순서쌍으로 나타낼 수 있다. 레이블은 인공지능 모델이 데이터 포인트로부터 도출하여야 하는 명시적인 목표값을 나타낼 수 있다. 인 공지능 모델은 레이블링된(labeled) 데이터 포인트를 학습할 수 있다. 학습된 인공지능 모델은 레 이블링되지 않은(unlabed) 데이터 포인트를 입력받아, 각각의 데이터 포인트에 대한 목표값, 즉 레이블을 출력 할 수 있다. 데이터세트는 복수의 레이블링된 데이터 포인트들 및 복수의 레이블링되지 않은 데이터 포인트들을 포함 하고 있을 수 있다. 데이터세트는 학습 유닛이 인공지능 모델을 학습시키기 위하여 학습 유 닛에 제공될 수 있다. 데이터세트는 인공지능 모델이 동작을 수행하여 목표값을 출력하게 하기 위하여 인공지능 모델에 제공될 수 있다. 인공지능 모델은 복수의 데이터 포인트들을 포함하는 데이터세트를 이용하여 학습될 수 있다. 학 습된 인공지능 모델은 복수의 데이터 포인트들을 포함하는 데이터세트를 이용하여 목표하는 동작을 수행할 수 있다. 예를 들어, 인공지능 모델은 데이터세트에 포함된 데이터 포인트들을 분류할 수 있다. 예를 들어, 인공지능 모델은 일정 기준에 따라 데이터세트에 포함된 데이터 포인트들에 대한 평가를 내릴 수 있다. 예를 들어, 인공지능 모델은 데이터세트에 포함된 데이터 포인트들로부터 도 출되는 결과를 예측할 수 있다. 상기 분류, 평가 또는 예측의 결과는 각 데이터 포인트에 대응되는 목표값, 즉 레이블로 출력될 수 있다. 인공지능 모델은 학습 유닛의 학습 알고리즘에 따라 학습될 수 있다. 인공지능 모델은 데이 터세트에 포함된 데이터 포인트들의 적어도 일부를 이용하여 미리 학습된 것일 수 있다. 일 실시예에서, 인공지능 모델은 데이터세트에 포함된 데이터 포인트들 중 레이블링된 데이터 포인트들을 이용하여 미리 학습된 것일 수 있다. 인공지능 모델은 학습 유닛의 학습 알고리즘에 따라 데이터세트를 이용하여 갱신될 수 있다. 인공지능 모델은 데이터세트에 포함된 데이터 포인트들 중 기존에 학습하지 않은 데이터 포인트들 을 이용하여 갱신될 수 있다. 일 실시예에서, 인공지능 모델은 데이터세트에 포함된 레이블링되지 않은 데이터 포인트들 중, 학습 유닛에 의해 선택된 데이터 포인트들을 이용하여 갱신될 수 있다. 다양한 실시예들에서, 인공지능 모델은 데이터 포인트로부터 목표값을 도출하기 위한 하나 이상의 파라미 터로 구성될 수 있다. 파라미터는 인공지능 모델이 학습하는 데이터에 기초하여 결정되거나 갱신될 수 있 다. 일 실시예에서, 파라미터는 확률분포를 가질 수 있다. 파라미터의 확률분포는 학습 데이터에 기초하여 결 정되거나 갱신될 수 있다. 학습 유닛은 데이터세트를 이용하여 인공지능 모델을 학습시킬 수 있다. 학습 유닛은 데이터세트로부터, 레이블링되지 않은 데이터 포인트들을 획득할 수 있다. 학습 유닛 은 레이블링되지 않은 데이터 포인트들 중, 소정의 개수의 후보 데이터 포인트들을 선택할 수 있다. 선 택된 후보 데이터 포인트들은 사용자에 의해 레이블링되기 위한 후보 데이터 포인트들일 수 있다. 선택된 후보 데이터 포인트들은 인공지능 모델을 갱신하기 위해 사용될 후보 데이터 포인트들일 수 있다. 다양한 실시예들에서, 학습 유닛은 레이블링되지 않은 데이터 포인트들 중에서 인공지능 모델을 가 장 효율적으로 갱신할 수 있는 후보 데이터 포인트들을 소정의 개수만큼 선택할 수 있다. 학습 유닛은 최 적화 알고리즘에 의하여 소정의 개수의 후보 데이터 포인트들을 선택할 수 있다. 일 실시예에서, 학습 유닛 은 레이블링되지 않은 전체 데이터 포인트들 중에서 소정의 개수의 후보 데이터 포인트들을 일괄적으로 선택할 수 있다. 일 실시예에서, 학습 유닛은 레이블링되지 않은 데이터 포인트들 각각이 인공지능 모델을 갱신하는 데 기여하는 정도를 예측할 수 있다. 상기 기여하는 정도를 예측함으로써, 학습 유닛은, 선택된 후보 데 이터 포인트들만을 이용하여 인공지능 모델을 갱신한 결과가 데이터세트에 포함된 레이블링되지 않 은 데이터 포인트들을 모두 이용하여 인공지능 모델을 갱신한 결과를 가장 근접하게 근사하도록, 소정의 개수의 후보 데이터 포인트들을 선택할 수 있다. 학습 유닛은 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력할 수 있다. 학습 유닛은 입력 요청에 응답한 사용자 입력에 기초하여, 선택된 후보 데이터 포인트들을 레이블링함으로써, 레이블링된 후보 데이터 포인트들을 획득할 수 있다. 학습 유닛은 입력 요청을 사용자 인터페이스(300 0)로 전송할 수 있다. 학습 유닛은 입력 요청에 응답한 사용자 입력을 사용자 인터페이스로부터 수신할 수 있다. 일 실시예에서, 학습 유닛은 소정의 개수의 후보 데이터 포인트들에 대한 입력 요청을 일괄적으로(batch) 출력할 수 있다. 학습 유닛은 입력 요청에 응답한 사용자 입력을 일괄적으로 수신할 수 있다. 일 실시예에서, 학습 유닛은 레이블링된 후보 데이터 포인트들을 데이터세트에 추가함으로써 데이 터세트를 갱신할 수 있다. 학습 유닛은 레이블링된 후보 데이터 포인트들을 이용하여 인공지능 모델을 갱신할 수 있다. 학습 유닛은 인공지능 모델에 레이블링된 후보 데이터 포인트들을 입력하여 인공지능 모델을 학습 시킬 수 있다. 일 실시예에서, 학습 유닛은 레이블링된 후보 데이터 포인트들과 레이블의 조합을 입력하여 인공지능 모 델을 학습시킴으로써, 인공지능 모델을 구성하는 파라미터의 확률분포를 갱신할 수 있다. 일 실시예에서, 학습 유닛은 소정의 개수의 레이블링된 후보 데이터 포인트들을 일괄적으로(batch) 인공 지능 모델에 입력하여 인공지능 모델을 갱신할 수 있다. 학습 유닛은 레이블링된 후보 데이 터 포인트들을, 데이터세트에 포함된 미리 레이블링된 다른 데이터 포인트들과 함께 인공지능 모델(101 0)에 입력함으로써 인공지능 모델을 갱신할 수 있다. 사용자는 사용자 인터페이스를 통하여 데이터 포인트를 레이블링할 수 있다. 사용자 인터페이스는, 전자 장치에 대한 사용자 입력을 수신하기 위한 별도의 장치일 수 있다. 사용자 인 터페이스는, 입력 요청 및 입력 결과를 사용자가 인식할 수 있도록 출력하는 출력부 및 사용자 입력을 수 신하는 입력부를 포함할 수 있다. 다양한 실시예들에서, 사용자 인터페이스는 학습 유닛으로부터 선택된 후보 데이터 포인트들을 함 께 레이블링하기 위한 입력 요청을 수신할 수 있다. 다양한 실시예들에서, 사용자 인터페이스는 사용자 로부터 선택된 후보 데이터 포인트들을 레이블링하는 입력을 받아 학습 유닛에 전송할 수 있다. 도 1에 도시된 각각의 구성 요소들은 기능적으로 구분되는 요소들을 나타낸 것으로서, 적어도 하나 이상의 구성 요소가 실제 물리적 환경에서는 서로 통합되는 형태로 구성될 수 있다. 예를 들어, 데이터세트 또는 사 용자 인터페이스는 전자 장치와 동일한 물리적 장치 내에서 구현될 수 있다. 또한, 도 1에 도시된 각각의 구성 요소들은 기능적으로 연결되어 상술한 동작들을 수행하는 하나 이상의 물리적 으로 분리된 장치들의 집합일 수 있다. 예를 들어, 전자 장치 또는 데이터세트는 복수의 물리적 장치들에 분산되어 구현될 수 있다. 도 1에 도시된 각각의 구성 요소들은 네트워크에 의하여 서로 연결되어 있을 수 있다. 네트워크는 근거리 통신 망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 이동 통신망(mobile radio communication network), 위성 통신망 및 이들의 상호 조합을 포함하며, 도 1 에 도시된 각 구성 주체가 서로 원활하게 통신을 할 수 있도록 하는 포괄적인 의미의 데이터 통신망이며, 유선 인터넷, 무선 인터넷 및 모바일 무선 통신망을 포함할 수 있다. 도 2는 일 실시예에 따른, 레이블링되지 않은 데이터 포인트들을 이용하여 인공지능 모델을 학습시키는 장치의 블록도이다. 도 2에 도시된 학습 유닛은 도 9의 전자 장치 또는 전자 장치에 포함된 프로세 서에 대응될 수 있다. 도 2를 참조하면, 학습 유닛은 데이터 포인트 획득부, 데이터 포인트 선택부, 사용자 레이블링 부 및 모델 갱신부를 포함할 수 있다. 데이터 포인트 획득부는 데이터세트로부터 레이블링되지 않은 데이터 포인트들을 획득할 수 있다. 데이터 포인트 선택부는 레이블링되지 않은 데이터 포인트들 중, 소정의 개수의 후보 데이터 포인트들을 선택할 수 있다. 선택된 후보 데이터 포인트들은 사용자에 의해 레이블링되기 위한 후보 데이터 포인트들일 수 있다. 선택된 후보 데이터 포인트들은 인공지능 모델을 갱신하기 위해 사용될 후보 데이터 포인트들일수 있다. 일 실시예에서, 소정의 개수는 사용자에 의하여 미리 정해진 것일 수 있다. 소정의 개수는 사용자에게 한 번에 레이블링을 요청할 수 있는 개수일 수 있다. 또는 소정의 개수는 인공지능 모델이 한 번에 학습할 수 있 는 데이터 포인트의 개수일 수 있다. 일 실시예에서, 소정의 개수는 2 이상의 정수 N로 정해질 수 있다. 다양한 실시예들에서, 데이터 포인트 선택부는 레이블링되지 않은 데이터 포인트들 중에서 인공지능 모델 을 가장 효율적으로 갱신할 수 있는 후보 데이터 포인트들을 소정의 개수만큼 선택할 수 있다. 데이터 포인트 선택부는 최적화 알고리즘에 의하여 소정의 개수의 후보 데이터 포인트들을 선택할 수 있다. 일 실시예에서, 데이터 포인트 선택부는 레이블링되지 않은 전체 데이터 포인트들 중에서 소정의 개수의 후보 데이터 포인트들을 일괄적으로 선택할 수 있다. 일 실시예에서, 데이터 포인트 선택부는 레이블링되지 않은 데이터 포인트들 각각이 인공지능 모델 을 갱신하는 데 기여하는 정도를 예측할 수 있다. 상기 기여하는 정도를 예측함으로써, 데이터 포인트 선택부 는, 선택된 후보 데이터 포인트들만을 이용하여 인공지능 모델을 갱신한 결과가 데이터세트에 포함된 레이블링되지 않은 데이터 포인트들을 모두 이용하여 인공지능 모델을 갱신한 결과를 가장 근접하 게 근사하도록, 소정의 개수의 후보 데이터 포인트들을 선택할 수 있다. 일 실시예에 따르면, 인공지능 모델은 데이터 포인트로부터 목표값을 도출하기 위한 하나 이상의 파라미 터로 구성될 수 있고, 상기 파라미터는 확률분포에 의하여 정의될 수 있다. 파라미터의 확률분포는 인공지능 모 델이 데이터 포인트를 학습함에 따라 갱신될 수 있다. 이 경우 데이터 포인트 선택부는, 레이블링되지 않은 데이터 포인트들 각각이 파라미터의 확률분포를 갱신 하는 데 기여하는 정도를 예측할 수 있다. 상기 기여하는 정도를 예측함으로써, 데이터 포인트 선택부는, 선택된 후보 데이터 포인트들만을 이용하여 파라미터의 확률분포를 갱신한 결과가 데이터세트에 포함된 레이블링되지 않은 데이터 포인트들을 모두 이용하여 파라미터의 확률분포를 갱신한 결과에 가장 근접하도록, 소정의 개수의 후보 데이터 포인트들을 선택할 수 있다. 일 실시예에 따르면, 후보 데이터 포인트들을 선택할 때 최적 조건의 데이터 포인트를 하나씩 선택하는 것을 여 러 번 반복할 수 있다. 그러나 이 경우, 각 선택에서 선택된 데이터 포인트들 간의 관계가 고려되지 않기 때문 에, 선택된 데이터 포인트들의 분포는 전체 데이터세트의 분포에 비하여 편향되어 있을 수 있다. 따라서 선택 된 후보 데이터 포인트들을 이용하여 인공지능 모델을 갱신한 결과는 데이터세트에 포함된 전체 데 이터 포인트들을 이용하여 인공지능 모델을 갱신한 결과와 유사하지 않을 수 있다. 반면, 일 실시예에 따르면, 데이터 포인트가 인공지능 모델을 갱신하는 데 기여하는 정도를 고려하여 복 수의 후보 데이터 포인트들을 일괄적으로 선택함으로써, 전체 데이터세트의 분포와 유사한 분포의 서브세트를 획득할 수 있다. 또한 선택된 후보 데이터 포인트들을 이용하여 인공지능 모델을 갱신함으로써, 데이터 세트에 포함된 전체 데이터 포인트들을 이용하여 인공지능 모델을 갱신한 결과와 유사한 결과를 얻 을 수 있다. 사용자 레이블링부는 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력할 수 있다. 사용자 레이블링부는 입력 요청에 응답한 사용자 입력에 기초하여, 선택된 후보 데이터 포인트들을 레이블링함으로써, 레이블링된 후보 데이터 포인트들을 획득할 수 있다. 사용자 레이블링부는 입력 요청을 사용자 인터페이스로 전송할 수 있다. 사용자 레이블링부는 입력 요청에 응답한 사용자 입력을 사용 자 인터페이스로부터 수신할 수 있다. 일 실시예에서, 사용자 레이블링부는 소정의 개수의 후보 데이터 포인트들에 대한 입력 요청을 일괄적으로 (batch) 출력할 수 있다. 사용자 레이블링부는 입력 요청에 응답한 사용자 입력을 일괄적으로 수신할 수 있다. 모델 갱신부는 레이블링된 후보 데이터 포인트들을 이용하여 인공지능 모델을 갱신할 수 있다. 모 델 갱신부는 인공지능 모델에 레이블링된 후보 데이터 포인트들을 입력하여 인공지능 모델을 학습시킬 수 있다. 일 실시예에서, 모델 갱신부는 레이블링된 후보 데이터 포인트들과 레이블의 조합을 입력하여 인공지능 모 델을 학습시킴으로써, 인공지능 모델을 구성하는 파라미터의 확률분포를 갱신할 수 있다. 일 실시예에서, 모델 갱신부는 소정의 개수의 레이블링된 후보 데이터 포인트들을 일괄적으로(batch) 인공 지능 모델에 입력하여 인공지능 모델을 갱신할 수 있다. 모델 갱신부는 레이블링된 후보 데이 터 포인트들을, 데이터세트에 포함된 미리 레이블링된 다른 데이터 포인트들과 함께 인공지능 모델(101 0)에 입력함으로써 인공지능 모델을 갱신할 수 있다. 도 3은 일 실시예에 따른, 레이블링되지 않은 데이터 포인트들을 이용하여 인공지능 모델을 학습시키는 방법의 흐름도이다. 도 3의 각 동작들은 도 1 및 도 2에 도시된 전자 장치 또는 전자 장치에 포함된 학습 유닛, 또는 도 9에 도시된 전자 장치또는 전자 장치의 프로세서에 의해 수행될 수 있다. 도 3을 참조하면, 동작 S310에서, 전자 장치는 복수의 데이터 포인트들을 포함하는 데이터세트로부 터, 레이블링되지 않은 데이터 포인트들을 획득할 수 있다. 동작 S320에서, 전자 장치는 레이블링되지 않은 데이터 포인트들 중, 소정의 개수의 후보 데이터 포인트 들을 선택할 수 있다. 선택된 후보 데이터 포인트들은 사용자에 의해 레이블링되기 위한 후보 데이터 포인트들 일 수 있다. 선택된 후보 데이터 포인트들은 인공지능 모델을 갱신하기 위해 사용될 후보 데이터 포인트 들일 수 있다. 일 실시예에서, 소정의 개수는 사용자에 의하여 미리 정해진 것일 수 있다. 소정의 개수는 사용자에게 한 번에 레이블링을 요청할 수 있는 개수일 수 있다. 또는 소정의 개수는 인공지능 모델이 한 번에 학습할 수 있 는 데이터 포인트의 개수일 수 있다. 일 실시예에서, 소정의 개수는 2 이상의 정수 N로 정해질 수 있다. 다양한 실시예들에서, 전자 장치는 레이블링되지 않은 데이터 포인트들 중에서 인공지능 모델을 가 장 효율적으로 갱신할 수 있는 후보 데이터 포인트들을 소정의 개수만큼 선택할 수 있다. 전자 장치는 최적화 알고리즘에 의하여 소정의 개수의 후보 데이터 포인트들을 선택할 수 있다. 일 실시예에서, 전자 장치 는 레이블링되지 않은 전체 데이터 포인트들 중에서 소정의 개수의 후보 데이터 포인트들을 일괄적으로 선택할 수 있다. 일 실시예에서, 전자 장치는 레이블링되지 않은 데이터 포인트들 각각이 인공지능 모델을 갱신하 는 데 기여하는 정도를 예측할 수 있다. 상기 기여하는 정도를 예측함으로써, 전자 장치는, 선택된 후보 데이터 포인트들만을 이용하여 인공지능 모델을 갱신한 결과가 데이터세트에 포함된 레이블링되지 않은 데이터 포인트들을 모두 이용하여 인공지능 모델을 갱신한 결과를 가장 근접하게 근사하도록, 소정 의 개수의 후보 데이터 포인트들을 선택할 수 있다. 일 실시예에 따르면, 인공지능 모델은 데이터 포인트로부터 목표값을 도출하기 위한 하나 이상의 파라미 터 θ로 구성될 수 있고, 상기 파라미터 θ는 확률분포 p(θ)에 의하여 정의될 수 있다. 파라미터의 확률분포 p(θ)는 인공지능 모델이 데이터 포인트를 학습함에 따라 갱신될 수 있다. 이 경우 전자 장치는, 레이블링되지 않은 데이터 포인트들 각각이 파라미터의 확률분포 p(θ)를 갱신하는 데 기여하는 정도를 예측할 수 있다. 상기 기여하는 정도를 예측함으로써, 전자 장치는, 선택된 후보 데 이터 포인트들만을 이용하여 파라미터의 확률분포를 갱신한 결과가 데이터세트에 포함된 레이블링되지 않 은 데이터 포인트들을 모두 이용하여 파라미터의 확률분포를 갱신한 결과에 가장 근접하도록, 소정의 개수의 후 보 데이터 포인트들을 선택할 수 있다. 예를 들어, 아무런 데이터도 학습하지 않았을 때 파라미터 θ의 사전분포 p(θ)는 미리 주어진 값일 수 있다. 여기서 인공지능 모델이 레이블링된 데이터 포인트들의 집합 D0만 학습하였을 때, 파라미터 θ의 사후분포 를 p(θ|D0)라고 할 수 있다. 또한 인공지능 모델이 데이터세트에 포함된 레이블링되지 않은 데이 터 포인트들의 집합 Dp를 모두 추가로 학습하여 갱신되었을 때, 파라미터 θ의 새로운 사후분포를 p(θ|D0∪Dp) 라고 할 수 있다. 또한 인공지능 모델이 레이블링되지 않은 데이터 포인트들 중 선택된 후보 데이터 포 인트들의 집합 D*만을 추가로 학습하여 갱신되었을 때, 파라미터 θ의 새로운 사후분포를 p(θ|D0∪D*)로 나타낼 수 있다. 이 경우 전자 장치는, 인공지능 모델이 데이터세트에 포함된 모든 데이터 포인트들을 이용하 여 갱신된 경우의 파라미터의 확률분포 p(θ|D0∪Dp)가, 인공지능 모델이 선택된 후보 데이터 포인트들만 을 이용하여 갱신된 경우의 파라미터의 확률분포 p(θ|D0∪D*)에 가장 가까워지도록 후보 데이터 포인트들을 선택할 수 있다. 레이블링되지 않은 데이터 포인트들을 모두 학습하기 전에는 확률분포 p(θ|D0∪Dp)의 정확한 값을 획득할 수 없 다. 이 경우, 레이블링되지 않은 데이터 포인트의 레이블 yp에 대하여 평균을 취한 Eyp[logp(θ|D0∪Dp)]로 확률 분포 p(θ|D0∪Dp)를 근사할 수 있다. 근사하고자 하는 목표인 Eyp[logp(θ|D0∪Dp)]을 풀어 쓰면 수학식 1과 같 이 나타낼 수 있다. 수학식 1"}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이 때, Lm(θ)는 기존의 확률분포 p(θ|D0)를 새로운 확률분포 p(θ|D0∪Dp)로 갱신함에 있어서, Dp에 속한 레이 블링되지 않은 데이터 포인트 xm이 기여하는 정도를 나타낸다. 즉, 레이블링되지 않은 데이터 포인트들을 모두 이용하여 갱신된 새로운 확률분포 p(θ|D0∪Dp)는, 기존의 확률분포 p(θ|D0)와, 각각의 레이블링되지 않은 데이 터 포인트가 확률분포의 갱신에 기여하는 정도 Lm의 총합에 의하여 예측될 수 있다. 따라서 후보 데이터 포인트 들의 기여도 Lm의 합이 모든 레이블링되지 않은 데이터 포인트의 기여도의 총합 에 가장 근접하 도록 후보 데이터 포인트들을 선택하면, 선택된 후보 데이터 포인트들만을 이용하여 갱신된 확률분포가 레이블 링되지 않은 데이터 포인트들을 모두 이용하여 갱신된 확률분포에 가장 가까워질 수 있다. 일 실시예에서, 전자 장치는 기존의 확률분포에 기초하여 레이블링되지 않은 데이터 포인트가 확률분포의 갱신에 기여하는 정도를 획득할 수 있다. 일 실시예에서, 전자 장치는 데이터 포인트들을 대응되는 데이터 포인트 벡터들로 변환하여 후보 데이터 포인트들을 선택할 수 있다. 전자 장치는 레이블링되지 않은 데이터 포인트들에 대응되는 데이터 포인트 벡터들을 획득하고, 데이터 포인트 벡터들 중 소정의 개수의 데이터 포인트 벡터들을 선택하고, 선택된 데이터 포인트 벡터들에 대응되는 데이터 포인트들을 후보 데이터 포인트들로 결정할 수 있다. 동작 S330에서, 전자 장치는 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력할 수 있다. 전자 장치는 입력 요청을 사용자 인터페이스로 전송할 수 있다. 일 실시예에서, 전자 장치는 소정의 개수의 후보 데이터 포인트들에 대한 입력 요청을 일괄적으로(batch) 출력할 수 있다. 예를 들어, N개의 후보 데이터 포인트들이 선택되었을 경우, 전자 장치는 각각의 후보 데이터 포인트를 레이블링하기 위한 입력 요청을 하나씩 N번 전송하는 대신, N개의 입력 요청을 한꺼번에 전송 할 수 있다. 동작 S340에서, 전자 장치는 입력 요청에 응답한 사용자 입력에 기초하여, 선택된 후보 데이터 포인트들 을 레이블링함으로써, 레이블링된 후보 데이터 포인트들을 획득할 수 있다. 전자 장치는 입력 요청에 응 답한 사용자 입력을 사용자 인터페이스로부터 수신할 수 있다. 일 실시예에서, 전자 장치는 소정의 개수의 후보 데이터 포인트들에 대한 사용자 입력을 일괄적으로 (batch) 수신할 수 있다. 예를 들어, N개의 후보 데이터 포인트들이 선택되었을 경우, 전자 장치는 각각 의 후보 데이터 포인트를 레이블링하는 사용자 입력을 하나씩 N번 수신하는 대신, N개의 사용자 입력을 한꺼번에 수신하여 N개의 후보 데이터 포인트들을 레이블링할 수 있다. 동작 S340에서, 전자 장치는 레이블링된 후보 데이터 포인트들을 이용하여 인공지능 모델을 갱신할 수 있다. 전자 장치는 인공지능 모델에 레이블링된 후보 데이터 포인트들을 입력하여 인공지능 모 델을 학습시킬 수 있다. 일 실시예에서, 전자 장치는 레이블링된 후보 데이터 포인트들과 레이블의 조합을 입력하여 인공지능 모 델을 학습시킴으로써, 인공지능 모델을 구성하는 파라미터의 확률분포를 갱신할 수 있다. 일 실시예에서, 전자 장치는 소정의 개수의 레이블링된 후보 데이터 포인트들을 일괄적으로(batch) 인공 지능 모델에 입력하여 학습시킬 수 있다. 예를 들어, N개의 후보 데이터 포인트들이 선택되어 레이블링 되었을 경우, 전자 장치는 각각의 레이블링된 후보 데이터 포인트를 하나씩 인공지능 모델에 입력 하고 인공지능 모델을 갱신하는 작업을 M번 반복하는 대신, M개의 레이블링된 후보 데이터 포인트들을 한 꺼번에 인공지능 모델에 입력하여 인공지능 모델을 한 번에 갱신할 수 있다. 전자 장치는 레 이블링된 후보 데이터 포인트들을, 데이터세트에 포함된 미리 레이블링된 다른 데이터 포인트들과 함께 인공지능 모델에 입력함으로써 인공지능 모델을 갱신할 수 있다. 도 4는 일 실시예에 따른, 레이블링되지 않은 데이터 포인트들 중 소정의 개수의 후보 데이터 포인트들을 선택 하는 방법의 흐름도이다. 도 4의 각 동작들은 도 1 및 도 2에 도시된 전자 장치 또는 전자 장치에 포함된 학습 유닛, 또는 도 9에 도시된 전자 장치또는 전자 장치의 프로세서에 의해 수 행될 수 있다. 도 4의 동작 S410 내지 S430은 도 3의 동작 S320에 상응할 수 있다. 도 4를 참조하면, 동작 S410에서, 전자 장치는 레이블링되지 않은 데이터 포인트들에 대응되는 데이터 포 인트 벡터들을 획득할 수 있다. 데이터 포인트 벡터는, 데이터 포인트에 대한 함수를 임의의 벡터 공간 상의 벡터로 나타낸 것일 수 있다. 이 경우, 데이터 포인트 벡터들의 크기 또는 데이터 포인트 벡터들 간의 각도는, 상기 데이터 포인트에 대한 함수들 간의 내적(inner product)을 기설정된 기준에 따라 계산함으로써 획득될 수 있다. 일 실시예에서, 상기 데이터 포인트에 대한 함수는, 데이터 포인트가 인공지능 모델의 갱신에 기 여하는 정보를 예측하기 위하여 산출된 함수일 수 있다. 일 실시예에서, 전자 장치는 레이블링되지 않은 데이터 포인트 각각이 인공지능 모델의 갱신에 기 여하는 정도를 예측함으로써 데이터 포인트 벡터를 계산할 수 있다. 예를 들어, 인공지능 모델이 하나 이상의 파라미터 θ로 구성되고, 상기 파라미터 θ는 확률분포 p(θ)에 의하여 정의될 때, 전자 장치는 파라미터의 확률분포 p(θ)의 갱신에 레이블링되지 않은 데이터 포인트 xm이 기여하는 정도를 나타내는 함수 Lm (θ)를 계산하여 데이터 포인트 벡터를 획득할 수 있다. 동작 S420에서, 전자 장치는 데이터 포인트 벡터들 중 소정의 개수의 데이터 포인트 벡터들을 선택할 수 있다. 전자 장치는 최적화 알고리즘에 의하여 소정의 개수의 데이터 포인트 벡터들을 선택할 수 있다. 일 실시예에서, 전자 장치는 전체 데이터 포인트 벡터들의 벡터 공간에서의 분포에 기초하여 소정의 개수 의 데이터 포인트 벡터들을 선택할 수 있다. 일 실시예에서, 전자 장치는 선택된 데이터 포인트 벡터들 의 가중합이 전체 데이터 포인트 벡터들의 가중합에 가장 근접하도록 소정의 개수의 데이터 포인트 벡터들을 선 택할 수 있다. 동작 S430에서, 전자 장치는 선택된 데이터 포인트 벡터들에 대응되는 데이터 포인트들을 후보 데이터 포 인트들로 결정할 수 있다. 도 5는 일 실시예에 따른, 데이터 포인트 벡터들 중 소정의 개수의 데이터 포인트 벡터들을 선택하는 방법의 흐 름도이다. 도 5의 각 동작들은 도 1 및 도 2에 도시된 전자 장치 또는 전자 장치에 포함된 학습 유닛, 또는 도 9에 도시된 전자 장치또는 전자 장치의 프로세서에 의해 수행될 수 있다. 도 5의 동작 S510 및 S520은 도 4의 동작 S420에 상응할 수 있다. 도 5를 참조하면, 동작 S510에서, 전자 장치는 데이터 포인트 벡터들로부터 데이터세트를 대표하는 벡터 를 획득할 수 있다. 일 실시예에서, 상기 데이터세트를 대표하는 벡터는, 데이터세트에 포함된 레이블링 되지 않은 데이터 포인트들을 모두 이용하여 인공지능 모델을 갱신하였을 경우, 인공지능 모델이 기존에 비하여 갱신되는 정도를 나타낼 수 있다. 일 실시예에서, 상기 데이터세트를 대표하는 벡터는, 데이터 세트에 포함된 레이블링되지 않은 데이터 포인트들을 모두 이용하여 인공지능 모델을 갱신하였을 경우, 인공지능 모델의 파라미터의 확률분포가 기존에 비하여 갱신되는 정도를 나타낼 수 있다.일 실시예에서, 데이터세트를 대표하는 벡터는 데이터 포인트 벡터들을 모두 더하여 획득될 수 있다. 예를 들 어, 데이터 포인트 벡터들이 데이터 포인트 xm이 확률분포의 갱신에 기여하는 정도를 나타내는 함수 Lm(θ)를 계 산하여 획득되는 경우, 상기 데이터세트를 대표하는 벡터는 로 계산될 수 있다. 동작 S520에서, 전자 장치는 각 데이터 포인트 벡터와 데이터세트를 대표하는 벡터 간의 근접한 정도에 기초하여 소정의 개수의 데이터 포인트 벡터들을 선택할 수 있다. 다양한 실시예들에서, 데이터 포인트 벡터와 데이터세트를 대표하는 벡터 간의 근접한 정도는, 데이터세트를 대 표하는 벡터와 데이터 포인트 벡터 간의 각도에 기초하여 결정될 수 있다. 다양한 실시예들에서, 데이터 포인 트 벡터와 데이터세트를 대표하는 벡터 간의 근접한 정도는, 데이터 포인트 벡터와 데이터세트를 대표하는 벡터 간의 가중 내적(weighted inner product)에 기초하여 결정될 수 있다. 일 실시예에서, 상기 가중 내적은 가중 피셔 내적(weighted Fisher inner product)일 수 있다. 데이터 포인트 벡터 Ln과 Lm 사이의 가중 피셔 내적 <Ln,Lm>은 수학식 2에 의해 계산될 수 있다. 수학식 2"}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다른 실시예에서, 상기 가중 내적은 가중 유클리드 내적(weighted Euclidian inner product)일 수 있다. 일 실시예에서, 상기 가중 유클리드 내적을 계산하기 위한 데이터 포인트 벡터는, 데이터 포인트에 대한 함수를 유클리드 공간 상의 벡터로 변환하여 획득할 수 있다. 예를 들어, 상기 가중 유클리드 내적을 계산하기 위한 데이터 포인트 벡터 Ln은 수학식 3에 의해 데이터 포인트에 대한 함수에 랜덤 프로젝션 (random projection)을 수행하여 계산될 수 있다. 수학식 3"}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "일 실시예에서, 전자 장치는 가중 내적을 이용하여 선형 회귀(linear regression)를 수행함으로써 소정의 개수의 데이터 포인트 벡터를 선택할 수 있다. 예를 들어, 선형 회귀는 베이즈 선형 회귀 (Bayesian linear regression) 방법에 기초하여 수행될 수 있다. 상기 베이즈 선형 회귀 방법에서, 데이터 포인트 벡터 Ln과 Lm 사이의 가중 피셔 내적 <Ln,Lm>은 수학식 4에 의해 계산될 수 있다.수학식 4"}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "다른 실시예에서, 전자 장치는 가중 내적을 이용하여 로지스틱 회귀(logistic regression)를 수행함으로 써 소정의 개수의 데이터 포인트 벡터를 선택할 수 있다. 상기 로지스틱 회귀에서, 데이터 포인트 벡터 Ln과 Lm 사이의 가중 피셔 내적 <Ln,Lm>은 수학식 5에 의해 계산될 수 있다. 수학식 5"}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이 때, BvN은 이변수 정규누적밀도함수(bi-variate Normal cumulative density function)를 의미한다. 일 실시예에서, 전자 장치는 프랭크-울프 최적화 (Frank-Wolfe Optimization) 알고리즘을 사용하여 소정 의 개수의 데이터 포인트 벡터들을 선택할 수 있다. 전자 장치는 가중치에 기초하여 데이터 포인트 벡터 와 데이터세트를 대표하는 벡터 간의 가중 내적을 계산하고, 계산된 가중 내적이 가장 큰 데이터 포인트 벡터를 선택하고, 선택된 데이터 포인트 벡터에 기초하여 상기 가중치를 갱신하는 동작을 소정의 개수만큼 반복하여, 소정의 개수의 데이터 포인트 벡터를 선택할 수 있다. 도 6a 내지 도 6f는 일 실시예에 따른, 데이터 포인트 벡터들 중 소정의 개수의 데이터 포인트 벡터들을 선택하 는 방법을 나타내는 도면이다. 도 6a 내지 도 6f를 참조하면, 데이터세트에 포함된 레이블링되지 않은 데이터 포인트들 x1, x2, ..., xM- 1, xM에 대응되는 데이터 포인트 벡터들 L1, L2, ..., LM-1, LM 이 임의의 벡터 공간 상의 좌표로 도시된다. 일 실시예에서, 상기 데이터 포인트 벡터들은 인공지능 모델을 구성하는 파라미터의 확률분포의 갱신에 각 데이터 포인트들이 기여하는 정도를 나타내는 함수일 수 있다. 도 6a를 참조하면, 데이터세트를 대표하는 벡터 L이 벡터 공간 상의 좌표로 도시된다. 일 실시예에서, 데 이터세트를 대표하는 벡터 L은 모든 데이터 포인트 벡터들 L1, L2, ..., LM-1, LM 을 더하여 획득된 것 일 수 있다. 즉, 상기 데이터세트를 대표하는 벡터 L은 로 계산될 수 있다. 도 6b를 참조하면, 데이터 포인트 벡터를 선택하기 위한 가중치가 초기화된다. 예를 들어, 상기 가중치는 0으 로 초기화될 수 있다. 가중치에 따라, 벡터 공간 상에서 가중치에 대응되는 기준 좌표가 결정된다. 일 실시예에서, 상기 가중치 에 대응되는 기준 좌표는 수학식 6으로 계산될 수 있다.수학식 6"}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이 때, wm은 각 데이터 포인트 벡터의 가중치, L(w)는 가중치에 대응되는 기준 좌표를 나타낸다. 예를 들어, 가중치 w가 0으로 초기화된 경우, 상기 기준 좌표 L(w) 는 벡터 공간의 원점이 될 수 있다. 도 6c를 참조하면, 가중치에 기초하여, 데이터세트를 대표하는 벡터와 가장 근접한 데이터 포인트 벡터 가 선택된다. 일 실시예에서, 가중치에 기초하여 데이터 포인트 벡터와 데이터세트를 대표하는 벡터 간의 가중 내적이 계산되고, 계산된 가중 내적이 가장 큰 데이터 포인트 벡터가 가장 근접한 데이터 포인트 벡 터로 결정될 수 있다. 예를 들어, 가중치에 대응되는 기준 좌표 L(w)를 기준으로, 데이터세트를 대 표하는 벡터 L과 가장 작은 각도를 이루는 데이터 포인트 벡터가 가장 근접한 데이터 포인트 벡터로 결정될 수 있다. 예를 들어, 가장 근접한 데이터 포인트 벡터는 수학식 7에 의해 결정될 수 있다. 수학식 7"}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이 때, f는 가장 근접한 데이터 포인트 벡터, σn은 데이터 포인트 벡터 Ln의 크기를 의미한다. 수학식 7에서 사 용되는 가중 내적은 수학식 2, 4 또는 5에 의해 계산되는 가중 피셔 내적, 또는 수학식 3에 의해 계산되는 가중 유클리드 내적일 수 있다. 도 6d를 참조하면, 선택된 데이터 포인트 벡터에 기초하여, 가중치가 새로운 가중치로 갱신될 수 있다. 일 실시예에서, 가중치는 기준 좌표를 선택된 데이터 포인트 벡터의 방향으로 일정 거리 이동시키도 록 갱신될 수 있다. 갱신된 가중치에 따라, 새로운 기준 좌표가 설정된다. 예를 들어, 새로운 가중치는 수학식 8에 의해 계산될 수 있다. 수학식 8"}
{"patent_id": "10-2019-0107655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이 때, Lf는 선택된 데이터 포인트 벡터, σf은 선택된 데이터 포인트 벡터 Lf의 크기를 의미한다. 수학식 7에서 사용되는 가중 내적(<Ln, Lm>)은 수학식 2, 4 또는 5에 의해 계산되는 가중 피셔 내적, 또는 수학식 3에 의해 계 산되는 가중 유클리드 내적일 수 있다. 도 6e를 참조하면, 갱신된 가중치에 기초하여, 앞서 선택된 데이터 포인트 벡터들을 제외하고 데이터세트를 대 표하는 벡터와 가장 근접한 데이터 포인트 벡터가 선택된다. 도 6f를 참조하면, 새로 선택된 데이터 포인트 벡터에 기초하여, 가중치가 다시 갱신되고, 갱신된 가중치에 따라 새로운 기준 좌표가 다시 설정된다. 가장 근접한 데이터 포인트 벡터를 선택하고 가중치를 갱신하는 방법은 앞서 도 6c 및 도 6d에서 설 명된 것과 동일하다. 상술한 방법으로, 데이터세트를 대표하는 벡터와 가장 근접한 데이터 포인트 벡터를 선택하고 가중치를 갱 신하는 동작을 소정의 개수만큼 반복할 수 있다. 반복할수록 기준 좌표 L(w)는 데이터세트를 대표하는 벡터 L에 점점 다가가고, 소정의 개수만큼 선택을 반복하였을 때 최종적으로 결정된 L(w)가 L에 대한 근사가 된 다. 따라서, 상술한 방법으로 소정의 개수의 데이터 포인트 벡터들을 선택하였을 때, 선택된 데이터 포인트 벡터들 에 대응되는 후보 데이터 포인트들은, 후보 데이터 포인트들의 기여도 Lm의 합이 모든 레이블링되지 않은 데이터 포인트의 기여도의 총합 에 가장 근접한다는 최적화 요건을 만족한다. 즉, 선택된 소정의 개 수의 데이터 포인트 벡터에 대응되는 소정의 개수의 후보 데이터 포인트들을 이용하여 인공지능 모델을 갱신한 결과는, 레이블링되지 않은 데이터 포인트들을 모두 이용하여 인공지능 모델을 갱신한 결과를 가장 근접하게 근 사할 수 있다. 도 7은 일 실시예에 따른, 레이블링되지 않은 데이터 포인트들을 이용하여 인공지능 모델을 학습시키는 장치의 블록도이다. 도 7에 도시된 학습 유닛은 도 9의 전자 장치 또는 전자 장치에 포함된 프로세 서에 대응될 수 있다. 도 7을 참조하면, 학습 유닛은 데이터 포인트 획득부, 데이터 포인트 선택부, 사용자 레이블링 부, 모델 갱신부 및 모델 평가부를 포함할 수 있다. 데이터 포인트 획득부, 사용자 레이 블링부 및 모델 갱신부는 도 2의 데이터 포인트 획득부, 사용자 레이블링부 및 모델 갱신 부와 동일하게 동작할 수 있으므로, 중복되는 설명은 생략한다. 모델 평가부는 인공지능 모델의 예측 정확도를 평가할 수 있다. 일 실시예에서, 모델 평가부 는 인공지능 모델이 학습하지 않은 데이터 포인트를 인공지능 모델에 입력하여, 예측한 목표값이 정답과 일치하는지 여부에 기초하여 인공지능 모델의의 예측 정확도를 평가할 수 있다. 데이터 포인트 선택부는 도 2의 데이터 포인트 선택부와 동일하게 동작할 수 있고, 이에 더하여, 모 델 평가부가 평가한 예측 정확도에 따라, 인공지능 모델을 계속 학습시킬지 여부를 결정할 수 있다. 일 실시예에서, 데이터 포인트 선택부는 상기 예측 정확도가 기준 미만인 경우, 레이블링되지 않은 데이터 포인트들 중 소정의 개수의 후보 데이터 포인트들을 선택하기로 결정할 수 있다. 일 실시예에서, 데이터 포인 트 선택부는 상기 예측 정확도가 기준 이상인 경우, 후보 데이터 포인트들을 더 선택하지 않고 학습을 종 료하기로 결정할 수 있다. 일 실시예에서, 상기 기준은 미리 정해진 값일 수 있다. 데이터 포인트 선택부, 사용자 레이블링부, 모델 갱신부 및 모델 평가부는, 인공지능 모델 의 예측 정확도가 기준 이상이 될 때까지, 레이블링되지 않은 데이터 포인트들 중 소정의 개수의 후보 데 이터 포인트들을 선택하고, 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력하고, 입 력 요청에 응답한 사용자 입력에 기초하여 선택된 후보 데이터 포인트들을 레이블링함으로써 레이블링된 후보 데이터 포인트들을 획득하고, 레이블링된 후보 데이터 포인트들을 이용하여 인공지능 모델을 갱신하고, 갱신된 인공지능 모델을 평가하는 학습 알고리즘을 반복할 수 있다. 도 8은 일 실시예에 따른, 레이블링되지 않은 데이터 포인트들을 이용하여 인공지능 모델을 학습시키는 방법의 흐름도이다. 도 8의 각 동작들은 도 1 및 도 7에 도시된 전자 장치 또는 전자 장치에 포함된 학습 유닛, 또는 도 9에 도시된 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있 다. 도 8의 동작 S810, S840, S850, 및 S860, 및 S870은 각각 도 3의 동작 S310, S320, S330, S340, 및 S350 에 상응할 수 있다. 도 8을 참조하면, 동작 S810에서, 전자 장치는 복수의 데이터 포인트들을 포함하는 데이터세트로부터, 레 이블링되지 않은 데이터 포인트들을 획득할 수 있다. 동작 S820에서, 전자 장치는 인공지능 모델의 예측 정확도를 평가할 수 있다. 일 실시예에서, 전 자 장치는 인공지능 모델이 학습하지 않은 데이터 포인트를 인공지능 모델에 입력하여, 예측 한 목표값이 정답과 일치하는지 여부에 기초하여 인공지능 모델의 예측 정확도를 평가할 수 있다. 동작 S830에서, 전자 장치는 평가된 예측 정확도를 기준과 비교할 수 있다. 상기 예측 정확도가 기준 이 상인 경우, 전자 장치는 학습 알고리즘을 종료하기로 결정할 수 있다. 일 실시예에서, 상기 기준은 미리정해진 값일 수 있다. 상기 예측 정확도가 기준 미만인 경우, 전자 장치는 동작 S840 단계를 수행할 수 있다. 동작 S840에서, 전자 장치는 레이블링되지 않은 데이터 포인트들 중, 소정의 개수의 후보 데이터 포인트들을 선택하기로 결정할 수 있다. 일 실시예에서, 전자 장치는 레이블링되지 않은 데이터 포인트들에 대응되는, 데이터 포인트 벡터들을 획 득할 수 있다. 일 실시예에서, 전자 장치는 데이터 포인트 벡터들 중 소정의 개수의 데이터 포인트 벡터 들을 선택할 수 있다. 예를 들어, 전자 장치는 데이터 포인트 벡터들로부터 데이터세트를 대표하는 벡터 를 획득하고, 각 데이터 포인트 벡터와 데이터세트를 대표하는 벡터 간의 근접한 정도에 기초하여 소정의 개수 의 데이터 포인트 벡터들을 선택할 수 있다. 일 실시예에서, 전자 장치는 선택된 데이터 포인트 벡터들 에 대응되는 데이터 포인트들을 후보 데이터 포인트들로 결정할 수 있다. 동작 S850에서, 전자 장치는 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력할 수 있다. 동작 S860에서, 전자 장치는 입력 요청에 응답한 사용자 입력에 기초하여, 선택된 후보 데이터 포인트들을 레이블링함으로써, 레이블링된 후보 데이터 포인트들을 획득할 수 있다. 동작 S870에서, 전자 장치는 레이블링된 후보 데이터 포인트들을 이용하여 인공지능 모델을 갱신할 수 있다. 그 후 동작 S820으로 돌아가서, 전자 장치는 갱신된 인공지능 모델에 대하여 다시 예측 정확도를 평가하고, 상기 예측 정확도가 기준 이상이 될 때까지, 상술한 동작 S820 내지 S870을 반복할 수 있다. 도 9는 일 실시예에 따른 전자 장치의 블록도이다. 도 9에 도시된 바와 같이, 일 실시예에 따른 전자 장치는, 통신부, 메모리, 입력부, 출력 부 및 프로세서를 포함할 수 있다. 그러나, 도 9에 도시된 구성 요소 모두가 전자 장치의 필 수 구성 요소인 것은 아니며, 도 9에 도시된 구성 요소보다 많거나 또는 적은 구성 요소에 의해 전자 장치 가 구현될 수도 있다. 통신부는, 데이터세트를 저장하는 외부 장치 및 사용자 인터페이스를 포함하는 외부 장치와 통신을 하게 하는 하나 이상의 구성요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부, 이동 통신부, 및 방송 수신부를 포함할 수 있다. 다양한 실시예들에서, 통신부는 데이터세트에 포함된 데이터 포인트들을 획득하기 위하여 필요한 정 보를 데이터세트를 저장하는 외부 장치와 송수신 할 수 있다. 다양한 실시예들에서, 통신부는 후보 데이터 포인트들을 레이블링하기 위한 입력 요청을 사용자 인터페이스를 포함하는 외부 장치로 전송하고, 입력 요청에 응답한 사용자 입력을 사용자 인터페이스를 포함하는 외부 장치로부터 수신할 수 있다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되거 나 전자 장치로부터 출력되는 데이터를 저장할 수 있다. 다양한 실시예들에서, 메모리는 데이터세트를 저장하고 있을 수 있다. 다양한 실시예들에서, 메모리 는 데이터세트로부터 획득한 레이블링되지 않은 데이터 포인트들을 저장할 수 있다. 다양한 실시예 들에서, 메모리는 레이블링되지 않은 데이터 포인트들 중에서 선택된 후보 데이터 포인트들 및 레이블링된 후보 데이터 포인트들을 저장할 수 있다. 입력부는, 사용자가 프로세서를 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들어, 입 력부에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조 그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 다양한 실시예들에서, 입력부는 후보 데이터 포인트들에 대한 입력 요청에 응답한 사용자 입력을 수신할 수 있다. 다양한 실시예들에서, 입력부는 사용자 인터페이스의 입력부에 해당할 수 있다. 또는 다 른 실시예들에서, 입력부는 사용자 인터페이스의 입력부와 연결되어, 사용자 인터페이스로부 터 사용자 입력을 수신할 수 있다. 출력부는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레이 부 및 음향 출력부를 포함할 수 있다. 다양한 실시예들에서, 출력부는 후보 데이터 포인트들을 레이블링하기 위한 입력 요청을 출력할 수 있다. 다양한 실시예들에서, 출력부는 사용자 인터페이스의 출력부에 해당할 수 있다. 또는 다른 실시예들 에서, 출력부는 사용자 인터페이스의 출력부와 연결되어, 입력 요청을 사용자 인터페이스로 출력할 수 있다. 프로세서는, 통상적으로 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메 모리에 저장된 프로그램들을 실행함으로써, 통신부, 메모리, 입력부, 출력부 등을 전 반적으로 제어할 수 있다. 프로세서는, 통신부, 메모리, 입력부, 출력부 등을 제어 함으로써, 본 개시에서의 전자 장치의 동작을 제어할 수 있다. 구체적으로, 프로세서는, 통신부 또는 메모리를 통하여, 데이터세트로부터 레이블링되지 않은 데이터 포인트들을 획득할 수 있다. 프로세서는 레이블링되지 않은 데이터 포인트들 중, 소정의 개 수의 데이터 포인트들을 선택할 수 있다. 선택된 후보 데이터 포인트들은 사용자에 의해 레이블링되기 위한 후 보 데이터 포인트들일 수 있다. 선택된 후보 데이터 포인트들은 인공지능 모델을 갱신하기 위해 사용될 후보 데이터 포인트들일 수 있다. 일 실시예에서, 프로세서는 레이블링되지 않은 데이터 포인트들 각각이 인공지능 모델을 갱신하는 데 기여하는 정도를 예측할 수 있다. 상기 기여하는 정도를 예측함으로써, 프로세서는, 선택된 후보 데이 터 포인트들만을 이용하여 인공지능 모델을 갱신한 결과가 데이터세트에 포함된 레이블링되지 않은 데이터 포인트들을 모두 이용하여 인공지능 모델을 갱신한 결과를 가장 근접하게 근사하도록, 소정의 개 수의 후보 데이터 포인트들을 선택할 수 있다. 프로세서는 선택된 후보 데이터 포인트들을 레이블링하기 위한 입력 요청을 출력할 수 있다. 프로세서 는 입력 요청에 응답한 사용자 입력에 기초하여, 선택된 후보 데이터 포인트들을 레이블링함으로써, 레이 블링된 후보 데이터 포인트들을 획득할 수 있다. 프로세서는 입력 요청을 통신부 또는 출력부 를 통하여 사용자 인터페이스로 전송할 수 있다. 프로세서는 입력 요청에 응답한 사용자 입력을 통 신부 또는 입력부를 통하여 사용자 인터페이스로부터 수신할 수 있다. 일 실시예에서, 프로세서는 소정의 개수의 후보 데이터 포인트들에 대한 입력 요청을 일괄적으로(batch) 출력할 수 있다. 프로세서는 입력 요청에 응답한 사용자 입력을 일괄적으로 수신할 수 있다. 프로세서는 레이블링된 후보 데이터 포인트들을 이용하여 인공지능 모델을 갱신할 수 있다. 프로세 서는 인공지능 모델에 레이블링된 후보 데이터 포인트들을 입력하여 인공지능 모델을 학습시킬 수 있다. 일 실시예에서, 프로세서는 소정의 개수의 레이블링된 후보 데이터 포인트들을 일괄적으로(batch) 인공지능 모델에 입력하여 인공지능 모델을 학습시킬 수 있다. 일 실시예에서, 프로세서는 인공지능 모델의 예측 정확도를 평가할 수 있다. 프로세서는 상기 예측 정확도가 기준 미만인 경우, 레이블링되지 않은 데이터 포인트들 중, 인공지능 모델을 학습시키는 데 이용할 후보 데이터 포인트들을 선택하기로 결정할 수 있다. 프로세서는 인공지능 모델의 예측 정확도가 기준 이상이 될 때까지, 레이블링되지 않은 데이터 포인트들 중 소정의 개수의 후보 데이터 포인트들 을 선택하고, 선택된 후보 데이터 포인트들을 함께 레이블링하기 위한 입력 요청을 출력하고, 입력 요청에 응답 한 사용자 입력에 기초하여 선택된 후보 데이터 포인트들을 레이블링함으로써 레이블링된 후보 데이터 포인트들 을 획득하고, 레이블링된 후보 데이터 포인트들을 이용하여 인공지능 모델을 갱신하는 학습 알고리즘을 반복할 수 있다. 본 개시의 다양한 실시예들은 기기(machine)(예: 전자 장치) 의해 읽을 수 있는 저장 매체(storage medium)(예: 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어로서 구현될 수 있다. 예를 들면, 기기(예: 전자 장치)의 프로세서(예: 프로세서)는, 저장 매체로부터 저장된 하나 이상의 명령 어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적’은 저장 매체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 실시예에 따르면, 본 개시에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치 들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있다. 다양한 실시예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소 들 또는 동작들이 생략되거나, 또는 하나 이상의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경 우, 통합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상 기 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실 시예들에 따르면, 모듈, 프로그램 또는 다른 구성요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복 적으로, 또는 휴리스틱하게 실행되거나, 상기 동작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또 는 하나 이상의 다른 동작들이 추가될 수 있다."}
{"patent_id": "10-2019-0107655", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른, 인공지능 모델을 학습시키는 시스템의 개요도이다. 도 2는 일 실시예에 따른, 레이블링되지 않은 데이터 포인트들을 이용하여 인공지능 모델을 학습시키는 장치의 블록도이다. 도 3은 일 실시예에 따른, 레이블링되지 않은 데이터 포인트들을 이용하여 인공지능 모델을 학습시키는 방법의 흐름도이다. 도 4는 일 실시예에 따른, 레이블링되지 않은 데이터 포인트들 중 소정의 개수의 후보 데이터 포인트를 선택하 는 방법의 흐름도이다. 도 5는 일 실시예에 따른, 데이터 포인트 벡터들 중 소정의 개수의 데이터 포인트 벡터를 선택하는 방법의 흐름 도이다. 도 6a 내지 도 6f는 일 실시예에 따른, 데이터 포인트 벡터들 중 소정의 개수의 데이터 포인트 벡터들을 선택하 는 방법을 나타내는 도면이다. 도 7은 일 실시예에 따른, 레이블링되지 않은 데이터 포인트들을 이용하여 인공지능 모델을 학습시키는 장치의 블록도이다. 도 8는 일 실시예에 따른, 레이블링되지 않은 데이터 포인트들을 이용하여 인공지능 모델을 학습시키는 방법의 흐름도이다. 도 9는 일 실시예에 따른 전자 장치의 블록도이다."}
