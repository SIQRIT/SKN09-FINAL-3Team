{"patent_id": "10-2022-7038590", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0133755", "출원번호": "10-2022-7038590", "발명의 명칭": "모델 트레이닝 방법 및 장치, 아이덴티티 익명화 방법 및 장치, 디바이스, 저장 매체, 그리고", "출원인": "텐센트 테크놀로지", "발명자": "뤄 위천"}}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 디바이스에 의해 수행되는 모델 트레이닝 방법으로서,타깃 네트워크 모델의 투사 모듈을 사용하여, 제1 트레이닝 이미지를 타깃 공간에 투사하여 N개의 제1 가상 아이덴티티 벡터를 획득하는 단계 - N은 양의 정수임 -;상기 타깃 네트워크 모델의 속성 모듈을 사용하여, 제2 트레이닝 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속성 벡터를 획득하는 단계 - M은 양의 정수임 -;상기 타깃 네트워크 모델의 융합 모듈을 사용하여, 상기 N개의 제1 가상 아이덴티티 벡터 및 상기 M개의 속성벡터에 기반한 이미지 생성을 수행하여 상기 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지(identity-anonymized image)를 획득하는 단계; 및상기 아이덴티티가 익명화된 이미지에 따라 상기 타깃 네트워크 모델의 손실을 결정하고, 상기 손실에 따라 상기 타깃 네트워크 모델을 트레이닝하는 단계를 포함하는 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 투사 모듈은 제1 투사 유닛 및 제2 투사 유닛을 포함하고, 상기 타깃 공간은 제1 공간 및 제2 공간을 포함하며, 상기 타깃 네트워크 모델의 투사 모듈을 사용하여 제1 트레이닝 이미지를 타깃 공간에 투사하여 N개의 제1 가상아이덴티티 벡터를 획득하는 단계는, 상기 제1 트레이닝 이미지의 선험적 아이덴티티 정보(priori identity information)를 추출하는 단계;상기 제1 투사 유닛을 사용하여, 상기 선험적 아이덴티티 정보를 상기 제1 공간에 투사하여 N개의 잠재적(latent) 아이덴티티 벡터를 획득하는 단계; 및상기 제2 투사 유닛을 사용하여, 상기 N개의 잠재적 아이덴티티 벡터를 상기 제2 공간에 투사하여 상기 N개의제1 가상 아이덴티티 벡터를 획득하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 투사 유닛을 사용하여, 상기 선험적 아이덴티티 정보를 상기 제1 공간에 투사하여 N개의 잠재적 아이덴티티 벡터를 획득하는 단계는, 상기 제1 투사 유닛을 사용하여, 상기 선험적 아이덴티티 정보를 상기 제1 공간의 평균 및 분산으로서 투사하는단계; 및상기 제1 공간의 평균과 분산에 기반하여 샘플링을 수행하여 상기 N개의 잠재적 아이덴티티 벡터를 획득하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항 또는 제3항에 있어서,공개특허 10-2023-0133755-3-상기 모델 트레이닝 방법은, 상기 N개의 잠재적 아이덴티티 벡터의 발산 제약(divergence constraint)을 결정하는 단계를 더 포함하고,상기 아이덴티티가 익명화된 이미지에 따라 상기 타깃 네트워크 모델의 손실을 결정하는 단계는, 상기 아이덴티티가 익명화된 이미지 및 상기 발산 제약에 따라 상기 타깃 네트워크 모델의 손실을 결정하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 모델 트레이닝 방법은,제3 트레이닝 이미지를 획득하는 단계 - 상기 제3 트레이닝 이미지와 상기 제1 트레이닝 이미지는 제1 타깃의 2개의 상이한 이미지임 -;상기 타깃 네트워크 모델의 투사 참조 모듈을 사용하여, 상기 제3 트레이닝 이미지를 상기 타깃 공간에 투사하여 N개의 제2 가상 아이덴티티 벡터를 획득하는 단계 - 상기 투사 참조 모듈과 상기 투사 모듈은 동일한 네트워크 구조를 가지며 상기 투사 모듈에 따라 업데이트됨 -; 및상기 N개의 제1 가상 아이덴티티 벡터 및 상기 N개의 제2 가상 아이덴티티 벡터에 따라 아이덴티티 손실을 결정하는 단계를 더 포함하고,상기 아이덴티티가 익명화된 이미지 및 상기 발산 제약에 따라 상기 타깃 네트워크 모델의 손실을 결정하는 단계는,상기 아이덴티티가 익명화된 이미지, 상기 발산 제약, 및 상기 아이덴티티 손실에 따라 상기 타깃 네트워크 모델의 손실을 결정하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 N개의 제1 가상 아이덴티티 벡터 및 상기 N개의 제2 가상 아이덴티티 벡터에 따라 아이덴티티 손실을 결정하는 단계는, 상기 N개의 제2 가상 아이덴티티 벡터 중 i번째 제2 가상 아이덴티티 벡터에 대해, 상기 i번째 제2 가상 아이덴티티 벡터를 사용하여, i번째 동적 리스트에서 상기 제1 타깃에 대응하는 가상 아이덴티티 벡터를 업데이트하는단계 - 상기 i번째 동적 리스트는 i번째 해상도에서 서로 다른 타깃의 가상 아이덴티티 벡터를 포함하며, i는 1내지 N 범위의 양의 정수임 -; 상기 i번째 제1 가상 아이덴티티 벡터 및 업데이트된 i번째 동적 리스트에 따라, 상기 i번째 제1 가상 아이덴티티 벡터에 대응하는 아이덴티티 서브손실을 결정하는 단계; 및상기 N개의 제1 가상 아이덴티티 벡터에 각각 대응하는 아이덴티티 서브손실들의 합을 상기 아이덴티티 손실로결정하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 i번째 제1 가상 아이덴티티 벡터 및 업데이트된 i번째 동적 리스트에 따라, 상기 i번째 제1 가상 아이덴티공개특허 10-2023-0133755-4-티 벡터에 대응하는 아이덴티티 서브손실을 결정하는 단계는, 제1 미리 설정된 값에 대한 상기 i번째 제2 가상 아이덴티티 벡터의 제1 비율을 획득하고, 상기 제1 비율에 상기 i번째 제1 가상 아이덴티티 벡터를 곱하여 제1 결과를 획득하며, 상기 제1 결과에 대해 지수 연산을 수행하여 제1 연산 값을 획득하는 단계;상기 업데이트된 i번째 동적 리스트에서 상기 제1 미리 설정 값에 대한 각각의 제2 가상 아이덴티티 벡터의 제2비율을 획득하고, 각각의 제2 비율에 대해, 상기 제2 비율에 대응하는 i번째 제1 가상 아이덴티티 벡터를 곱하여 제2 결과를 획득하며, 상기 제2 결과에 대해 지수 연산을 수행하여 각각의 제2 가상 아이덴티티 벡터에 대응하는 제2 연산 값을 획득하는 단계;모든 제2 가상 아이덴티티 벡터에 대응하는 제2 연산 값들의 합을 결정하고, 상기 합에 대한 상기 제1 연산 값의 제3 비율을 획득하며, 상기 제3 비율에 대해 로그 연산(logarithmic operation)을 수행하여 제3 연산 값을획득하는 단계; 및상기 제3 연산 값의 음수를 상기 i번째 제1 가상 아이덴티티 벡터에 대응하는 상기 아이덴티티 서브손실로 결정하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 속성 모듈은 인코딩 유닛 및 디코딩 유닛을 포함하고, 상기 타깃 네트워크 모델의 속성 모듈을 사용하여, 제2 트레이닝 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속성 벡터를 획득하는 단계는,상기 인코딩 유닛을 사용하여, 상기 제2 트레이닝 이미지에 대해 특징 추출을 수행하여 상기 제2 트레이닝 이미지의 특징 정보를 획득하는 단계; 및상기 디코딩 유닛을 사용하여, 상기 특징 정보를 디코딩하여 M개의 속성 벡터를 획득하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 융합 모듈은 복수의 상이한 해상도 레이어를 포함하고, 상기 타깃 네트워크 모델의 융합 모듈을 사용하여, 상기 N개의 제1 가상 아이덴티티 벡터 및 상기 M개의 속성벡터에 기반한 이미지 생성을 수행하여 상기 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득하는단계는, 상기 N개의 제1 가상 아이덴티티 벡터에 대응하는 해상도에 따라, 상기 N개의 제1 가상 아이덴티티 벡터를 대응하는 해상도 레이어에 패턴으로 입력하고, 상기 M개의 속성 벡터를 대응하는 해상도 레이어에 노이즈로 입력하여, 상기 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제5항에 있어서, 상기 아이덴티티가 익명화된 이미지, 상기 발산 제약, 및 상기 아이덴티티 손실에 따라 상기 타깃 네트워크 모델의 손실을 결정하는 단계는, 상기 아이덴티티가 익명화된 이미지와 상기 제2 트레이닝 이미지 사이의 재구성 손실을 결정하는 단계; 및상기 재구성 손실, 상기 발산 제약, 및 상기 아이덴티티 손실에 기반하여 상기 타깃 네트워크 모델의 손실을 결정하는 단계공개특허 10-2023-0133755-5-를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 모델 트레이닝 방법은, 상기 아이덴티티가 익명화된 이미지와 상기 제1 트레이닝 이미지 사이의 제1 거리, 상기 아이덴티티가 익명화된이미지와 상기 제2 트레이닝 이미지 사이의 제2 거리, 및 상기 제1 트레이닝 이미지와 상기 제2 트레이닝 이미지 사이의 제3 거리를 결정하는 단계; 및상기 제1 거리, 상기 제2 거리, 및 상기 제3 거리에 따라 콘트라스트 손실을 결정하는 단계를 더 포함하고,상기 재구성 손실, 상기 발산 제약, 및 상기 아이덴티티 손실에 기반하여 상기 타깃 네트워크 모델의 손실을 결정하는 단계는,상기 재구성 손실, 상기 발산 제약, 상기 아이덴티티 손실, 및 상기 콘트라스트 손실에 기반하여 상기 타깃 네트워크 모델의 손실을 결정하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 제1 거리, 상기 제2 거리, 및 상기 제3 거리에 따라 콘트라스트 손실을 결정하는 단계는,상기 제2 거리와 상기 제3 거리의 차의 제곱과 상기 제1 거리의 합을 결정하는 단계; 및미리 설정된 값과 상기 합 사이의 차이를 상기 콘트라스트 손실로 결정하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 융합 모듈이 적대적 네트워크(adversarial network)인 경우, 상기 재구성 손실, 상기 발산 제약, 상기 아이덴티티 손실, 및 상기 콘트라스트 손실에 기반하여 상기 타깃 네트워크 모델의 손실을 결정하는 단계는,상기 아이덴티티가 익명화된 이미지 및 상기 제1 트레이닝 이미지에 따라 적대적 손실을 결정하는 단계; 및상기 재구성 손실과 상기 발산 제약과 상기 아이덴티티 손실과 상기 콘트라스트 손실과 상기 적대적 손실의 가중 합을, 상기 타깃 네트워크 모델의 손실로 결정하는 단계를 포함하는, 모델 트레이닝 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨팅 디바이스에 의해 수행되는 아이덴티티 익명화 방법으로서,타깃 네트워크 모델의 투사 모듈의 타깃 공간에 대해 샘플링을 수행하여 N개의 가상 아이덴티티 벡터를 획득하는 단계 - N은 양의 정수임 -;상기 타깃 네트워크 모델의 속성 모듈을 사용하여, 처리 대상 이미지에 대해 속성 벡터 추출을 수행하여 M개의속성 벡터를 획득하는 단계 - M은 양의 정수임 -; 및상기 타깃 네트워크 모델의 융합 모듈을 사용하여, 상기 N개의 가상 아이덴티티 벡터 및 상기 M개의 속성 벡터에 기반한 이미지 생성을 수행하여, 상기 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득하는 단계공개특허 10-2023-0133755-6-를 포함하는 아이덴티티 익명화 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 타깃 공간은 제1 공간 및 제2 공간을 포함하고, 상기 타깃 네트워크 모델은 제2 투사 유닛을 포함하며,상기 타깃 네트워크 모델의 투사 모듈의 타깃 공간에 대해 샘플링을 수행하여 N개의 가상 아이덴티티 벡터를 획득하는 단계는, 상기 제1 공간에 대해 샘플링을 수행하여 N개의 잠재적 아이덴티티 벡터를 획득하는 단계; 및상기 제2 투사 유닛을 사용하여, 상기 N개의 잠재적 아이덴티티 벡터를 상기 제2 공간에 투사하여 상기 N개의가상 아이덴티티 벡터를 획득하는 단계를 포함하는, 아이덴티티 익명화 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제1 공간의 평균 및 분산은 표준 가우시안 분포를 만족하고, 상기 제1 공간에 대해 샘플링을 수행하여 N개의 잠재적 아이덴티티 벡터를 획득하는 단계는,상기 제1 공간의 평균 및 분산에 기반하여 샘플링을 수행하여 상기 N개의 잠재적 아이덴티티 벡터를 획득하는단계를 포함하는, 아이덴티티 익명화 방법."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "모델 트레이닝 장치로서,타깃 네트워크 모델의 투사 모듈을 사용하여, 제1 트레이닝 이미지를 타깃 공간에 투사하여 N개의 제1 가상 아이덴티티 벡터를 획득하도록 구성된 투사 유닛 - N은 양의 정수임 -;상기 타깃 네트워크 모델의 속성 모듈을 사용하여, 제2 트레이닝 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속성 벡터를 획득하도록 구성된 속성 유닛 - M은 양의 정수임 -;상기 타깃 네트워크 모델의 융합 모듈을 사용하여, 상기 N개의 제1 가상 아이덴티티 벡터 및 상기 M개의 속성벡터에 기반한 이미지 생성을 수행하여 상기 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득하도록 구성된 융합 유닛; 및상기 아이덴티티가 익명화된 이미지에 따라 상기 타깃 네트워크 모델의 손실을 결정하고, 상기 손실에 따라 상기 타깃 네트워크 모델을 트레이닝하도록 구성된 트레이닝 유닛을 포함하는 모델 트레이닝 장치."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "아이덴티티 익명화 장치로서,타깃 네트워크 모델의 투사 모듈의 타깃 공간에 대해 샘플링을 수행하여 N개의 가상 아이덴티티 벡터를 획득하도록 구성된 샘플링 유닛 - N은 양의 정수임 -;상기 타깃 네트워크 모델의 속성 모듈을 사용하여, 처리 대상 이미지에 대해 속성 벡터 추출을 수행하여 M개의속성 벡터를 획득하도록 구성된 속성 유닛 - M은 양의 정수임 -; 및상기 타깃 네트워크 모델의 융합 모듈을 사용하여, 상기 N개의 가상 아이덴티티 벡터 및 상기 M개의 속성 벡터에 기반한 이미지 생성을 수행하여, 상기 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득하도록 구성된 익명화 유닛공개특허 10-2023-0133755-7-을 포함하는 아이덴티티 익명화 장치."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "컴퓨터 디바이스로서,프로세서 및 메모리를 포함하고,상기 메모리는 컴퓨터 프로그램을 저장하도록 구성되고,상기 프로세서는 상기 컴퓨터 프로그램을 실행할 때 제1항 내지 제13항 중 어느 한 항에 따른 방법, 또는 제14항 내지 제16항 중 어느 한 항에 따른 방법을 구현하도록 구성되는, 컴퓨터 디바이스."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터 프로그램을 저장하는, 컴퓨터가 판독 가능한 저장 매체로서, 상기 컴퓨터 프로그램은 실행될 때 컴퓨터 디바이스가 제1항 내지 제13항 중 어느 한 항에 따른 방법 또는 제14항 내지 제16항 중 어느 한 항에 따른 방법을 구현하게 하는, 컴퓨터가 판독 가능한 저장 매체."}
{"patent_id": "10-2022-7038590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "컴퓨터 프로그램 또는 명령어를 포함하는, 컴퓨터 프로그램 제품으로서,상기 컴퓨터 프로그램 또는 상기 명령어는, 프로세서에 의해 실행될 때, 제14항 내지 제16항 중 어느 한 항에따른 방법, 또는 제1항 내지 제13항 중 어느 한 항에 따른 방법을 구현하는, 컴퓨터 프로그램 제품."}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 클라우드 기술, 인공 지능, 지능형 교통 및 보조 운전과 같은 다양한 시나리오에 적용될 수 있는 모델 트레이닝 방법 및 장치, 아이덴티티 익명화 방법 및 장치, 디바이스, 저장 매체, 그리고 프로그램 제품을 제공한 다. 상기 방법은, 타깃 네트워크 모델의 투사 모듈의 타깃 공간에 대해 샘플링을 수행하여 N개의 가상 아이덴티 티 벡터를 획득하는 단계; 타깃 네트워크 모델의 속성 모듈을 사용하여, 처리 대상 이미지에 대해 속성 벡터 추 출을 수행하여 M개의 속성 벡터를 획득하는 단계; 및 타깃 네트워크 모델의 융합 모듈을 사용하여 N개의 가상 아 이덴티티 벡터 및 M개의 속성 벡터에 기반한 이미지 생성을 수행하여, 처리 대상 이미지의 아이덴티티가 익명화 된 이미지를 획득하는 단계를 포함한다."}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2022년 3월 10일에 출원된 중국 특허 출원 번호 제202210234385.2호에 대한 우선권을 주장하며, 이는 그 전체가 참조로 여기에 포함된다. 본 출원은 이미지 처리 기술 분야에 관한 것으로, 특히 모델 트레이닝 방법 및 장치, 아이덴티티 익명화 (identity anonymization) 방법 및 장치, 디바이스, 저장 매체 그리고 프로그램 제품에 관한 것이다."}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "아이덴티티 익명화는 비식별화(de-identification)라고도 하며, 이미지 또는 비디오에서 인식 가능한 아이덴티 티 특징을 제거하지만 다른 아이덴티티가 없는 속성(other identity-free attribute)은 변경하지 않고 유지하고, 익명화된 픽처 또는 비디오가 여전히 시각적으로 현실적으로 유지되도록 한다. 관련 기술에서, 익명화된 픽처를 생성하기 위해 조건부 GAN(generative adversarial network)을 사용하고, 원 본 픽처의 자세 키 포인트(key point)를 추출하며, 원본 픽처의 자세 키 포인트와 제거된 얼굴 영역을 가지는 배경 픽처를 조건으로 모델에 입력하여, 빈 얼굴 영역을 채우는 신규 가상 아이덴티티를 생성한다. 그러나, 이 방법에서, 얼굴 영역이 제거된 배경 픽처를 모델 입력으로 사용하므로, 모델이 생성한 픽처의 품질이 좋지 않다. 본 출원의 실시예는 생성된 아이덴티티가 익명화된 이미지(identity-anonymized image)의 품질을 개선하기 위한 모델 트레이닝 방법 및 장치, 아이덴티티 익명화 방법 및 장치, 컴퓨팅 디바이스, 컴퓨터가 판독 가능한 저장 매체, 그리고 컴퓨터 프로그램 제품을 제공한다. 본 출원의 실시예는 모델 트레이닝 방법을 제공하며, 상기 모델 트레이닝 방법은: 타깃 네트워크 모델의 투사(projection) 모듈을 사용하여, 제1 트레이닝(training) 이미지를 타깃 공간(target space)에 투사하여 N개의 제1 가상 아이덴티티 벡터를 획득하는 단계 - N은 양의 정수임 -; 상기 타깃 네트워크 모델의 속성(attribute) 모듈을 사용하여, 제2 트레이닝 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속성 벡터를 획득하는 단계 - M은 양의 정수임 -; 상기 타깃 네트워크 모델의 융합(fusion) 모듈을 사용하여, 상기 N개의 제1 가상 아이덴티티 벡터 및 상기 M개 의 속성 벡터에 기반한 이미지 생성을 수행하여 상기 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득하는 단계; 및 상기 아이덴티티가 익명화된 이미지에 따라 상기 타깃 네트워크 모델의 손실을 결정하고, 상기 손실에 따라 상 기 타깃 네트워크 모델을 트레이닝하는 단계를 포함한다. 본 출원은 추가로 아이덴티티 익명화 방법을 제공하며, 상기 아이덴티티 익명화 방법은: 타깃 네트워크 모델의 투사 모듈의 타깃 공간에 대해 샘플링을 수행하여 N개의 가상 아이덴티티 벡터를 획득하 는 단계 - N은 양의 정수임 -; 상기 타깃 네트워크 모델의 속성 모듈을 사용하여, 처리 대상 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속성 벡터를 획득하는 단계 - M은 양의 정수임 -; 및 상기 타깃 네트워크 모델의 융합 모듈을 사용하여, 상기 N개의 가상 아이덴티티 벡터 및 상기 M개의 속성 벡터 에 기반한 이미지 생성을 수행하여, 상기 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득하는 단계를 포함한다. 본 출원의 실시예는 모델 트레이닝 장치를 더 제공하며, 상기 모델 트레이닝 장치는: 타깃 네트워크 모델의 투사 모듈을 사용하여, 제1 트레이닝 이미지를 타깃 공간에 투사하여 N개의 제1 가상 아 이덴티티 벡터를 획득하도록 구성된 투사 유닛 - N은 양의 정수임 -; 상기 타깃 네트워크 모델의 속성 모듈을 사용하여, 제2 트레이닝 이미지에 대해 속성 벡터 추출을 수행하여 M개 의 속성 벡터를 획득하도록 구성된 속성 유닛 - M은 양의 정수임 -; 상기 타깃 네트워크 모델의 융합 모듈을 사용하여, 상기 N개의 제1 가상 아이덴티티 벡터 및 상기 M개의 속성 벡터에 기반한 이미지 생성을 수행하여 상기 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득하도 록 구성된 융합 유닛; 및 상기 아이덴티티가 익명화된 이미지에 따라 상기 타깃 네트워크 모델의 손실을 결정하고, 상기 손실에 따라 상 기 타깃 네트워크 모델을 트레이닝하도록 구성된 트레이닝 유닛을 포함한다. 본 출원의 실시예는 아이덴티티 익명화 장치를 더 제공하며, 상기 아이덴티티 익명화 장치는: 타깃 네트워크 모델의 투사 모듈의 타깃 공간에 대해 샘플링을 수행하여 N개의 가상 아이덴티티 벡터를 획득하 도록 구성된 샘플링 유닛 - N은 양의 정수임 -; 상기 타깃 네트워크 모델의 속성 모듈을 사용하여, 처리 대상 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속성 벡터를 획득하도록 구성된 속성 유닛 - M은 양의 정수임 -; 및 상기 타깃 네트워크 모델의 융합 모듈을 사용하여, 상기 N개의 가상 아이덴티티 벡터 및 상기 M개의 속성 벡터 에 기반한 이미지 생성을 수행하여, 상기 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득하도록 구성 된 익명화 유닛을 포함한다. 본 출원의 실시예는 프로세서 및 메모리를 포함하는 컴퓨팅 디바이스를 더 제공한다. 상기 메모리는 컴퓨터 프 로그램을 저장하도록 구성된다. 상기 프로세서는 상기 메모리에 저장된 상기 컴퓨터 프로그램을 호출하고 실행 하여, 본 출원의 실시예에서 제공되는 모델 트레이닝 방법 또는 아이덴티티 익명화 방법을 수행하도록 구성된다. 본 출원의 실시예는 본 출원의 실시예에서 제공되는 모델 트레이닝 방법 또는 아이덴티티 익명화 방법을 구현하 도록 구성된 칩을 더 제공한다. 상기 칩은 메모리로부터 컴퓨터 프로그램을 호출하고 실행하도록 구성된 프로세 서를 포함하므로, 상기 칩이 설치된 디바이스가 본 출원의 실시예에서 제공된 전술한 모델 트레이닝 방법 또는 아이덴티티 익명화 방법을 실행한다. 본 출원의 실시예는 컴퓨터가 판독 가능한 저장 매체를 더 제공한다. 상기 컴퓨터가 판독 가능한 저장 매체는 컴퓨터 프로그램을 저장하도록 구성되며, 상기 컴퓨터 프로그램은 실행될 때 본 출원의 실시예에서 제공되는 모 델 트레이닝 방법 또는 아이덴티티 익명화 방법을 구현한다.본 출원의 실시예는 컴퓨터 프로그램 명령어를 포함하는, 컴퓨터 프로그램 제품을 더 제공하며, 상기 컴퓨터 프 로그램 명령어가 컴퓨터에 의해 실행될 때, 전술한 실시예 중 어느 하나의 모델 트레이닝 방법 또는 아이덴티티 익명화 방법이 구현된다. 본 출원의 실시예는 컴퓨터 상에서 실행될 때 전술한 실시예에 따른 모델 트레이닝 방법 또는 아이덴티티 익명 화 방법을 수행하는 컴퓨터 프로그램을 더 제공한다. 본 발명의 이러한 실시예는 다음과 같은 유익한 효과를 갖는다: 타깃 네트워크 모델의 트레이닝 프로세스에서, 제1 트레이닝 이미지가 타깃 공간에 투사되어 N개의 제1 가상 아 이덴티티 벡터를 획득하므로, 타깃 네트워크 모델이 이미지에서 아이덴티티 정보를 완전히 학습할 수 있으며; 속성 벡터 추출이 제2 트레이닝 이미지에 대해 수행되어 M개의 속성 벡터를 획득하므로, 타깃 네트워크 모델이 이미지에서 속성 정보를 완전히 학습하고; N개의 제1 가상 아이덴티티 벡터 및 M개의 속성 벡터에 기반하여 이 미지 생성이 수행되어 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득한다. 이러한 방식으로 트레 이닝된 모델은 원본 이미지의 속성 정보가 변경되지 않은 상태로 유지되는 것을 보장하면서 가상 아이덴티티 정 보를 운반하는(carrying) 이미지를 생성할 수 있다. 타깃 네트워크 모델의 적용 프로세스에서, 투사 모듈의 타깃 공간에 대해 샘플링이 수행되어 N개의 가상 아이덴 티티 벡터를 획득하므로, 가상 아이덴티티 정보가 생성되고; 속성 벡터 추출이 처리 대상 이미지에 대해 수행되 어 M개의 속성 벡터를 획득하여, 처리 대상 이미지의 속성 특징이 손실되지 않도록 하고, 따라서 생성된 아이덴 티티가 익명화된 이미지의 품질을 보장하며; N개의 가상 아이덴티티 벡터 및 M개의 속성 벡터에 기반한 이미지 생성이 수행되어 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득하므로, 처리 대상 이미지의 속성 정 보가 변경되지 않은 상태로 유지되는 것을 보장하면서, 가상 아이덴티티 정보를 운반하는 즉, 은닉된 실제 아이 덴티티를 갖는 아이덴티티가 익명화된 이미지가 생성된다. 즉, 본 출원의 실시예에서, 아이덴티티 익명화 동안, 이미지에서 얼굴 영역을 제거하지 않고 타깃 네트워크 모델을 사용하여 독립적인 가상 아이덴티티를 생성함으로 써, 아이덴티티 익명화의 충실도 및 해상도를 향상시킨다."}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음은 본 출원의 실시예의 첨부 도면을 참조하여 본 출원의 실시예의 기술적 솔루션을 명확하고 완전하게 설명 한다. 본 출원의 실시예에서, \"B에 대응하는 A\"는 B가 A와 연관되어 있음을 지시하는 것으로 이해되어야 한다. 일 구 현에서, B는 A에 기반하여 결정될 수 있다. 그러나, A에 따라 B를 결정하는 것이 A에 따라서만 B를 결정하는 것 을 의미하지 않고, B가 A 및/또는 다른 정보에 따라 결정될 수 있다는 것을 추가로 이해해야 한다. 본 출원의 실시예의 설명에서, 달리 설명되지 않는 한, \"복수\"는 둘 또는 둘 이상을 의미한다. 또한, 본 출원의 실시예에서의 기술적 솔루션을 명확하게 설명하기 쉽도록, 본 출원의 실시예에서 \"제1\", \"제2\" 및 \"제3\"과 같은 용어는 기본적으로 동일한 기능과 목적을 가진 동일하거나 유사한 항목을 구별하는 데 사용된 다. 당업자는 \"제1\", \"제2\" 및 \"제3\"와 같은 용어가 수량 및 실행 시퀀스를 정의하는 것이 아니라 \"제1\", \"제2\" 및 \" 제3\"과 같은 용어가 명확한 차이를 지시하지 않는다는 것을 이해할 수 있다. 본 출원의 실시예에 대한 이해를 용이하게 하기 위해, 먼저 본 출원의 실시예와 관련된 관련 개념을 간략하게 소개한다. 인공 지능(Artificial intelligence, AI)은 디지털 컴퓨터 또는 디지털 컴퓨터에 의해 제어되는 머신을 사용하 여 인간의 지능을 시뮬레이션, 확장 및 확대하고, 환경을 인식하며, 지식을 획득하고, 정보를 획득하며, 지식을 사용하여 최적의 결과를 획득하는 이론, 방법, 기술 및 응용 시스템이다. 달리 말하면, AI는 컴퓨터 과학의 종 합 기술이다. 이 기술은 지능의 본질을 이해하고 인간의 지능과 유사한 방식으로 반응할 수 있는 신규 지능형 머신을 생산하려고 한다. AI는 다양한 지능형 머신의 설계 원리와 구현 방법을 연구하여 머신이 인식하고, 추론 하며, 그리고 결정을 내릴 수 있도록 하는 것이다. AI 기술은 광범위한 분야와 관련되고 하드웨어 및 소프트웨어 기술을 모두 포함하는 포괄적인 주제이다. 기본 AI 기술은 일반적으로 센서, 전용 AI 칩, 클라우드 컴퓨팅, 분산 스토리지, 빅 데이터 처리 기술, 운영/상호작 용 시스템, 메카트로닉스와 같은 기술을 포함한다. AI 소프트웨어 기술은 주로 CV 기술, 음성 처리 기술, 자연 어 처리 기술, 머신 러닝/딥 러닝(deep learning, DL)과 같은 분야를 포함한다. ML은 다분야 학제(multi-field interdiscipline)이며, 확률 이론, 통계학, 근사 이론, 볼록 해석학 및 알고리 즘 복잡도 이론과 같은 복수의 학제에 관련된다. ML은 컴퓨터가 인간의 학습 행동을 시뮬레이션하거나 구현하여 신규 지식이나 기술을 습득하고 기존 지식 구조를 재구성하여, 성능을 계속 향상시키는 방법을 연구하는 것을 전문으로 한다. ML은 AI의 핵심이며, 컴퓨터를 지능화하는 기본적인 방법으로, AI의 다양한 분야에 적용된다. ML 및 DL은 일반적으로 인공 신경망, 빌리프 네트워크(belief network), 강화 학습, 전이 학습, 귀납 학습 및 데모 학습과 같은 기술을 포함한다. 본 출원의 실시예의 방법은 이미지가 익명화될 필요가 있는 임의의 시나리오에 적용될 수 있다. 예를 들어, 도 1a 내지 도 1d에 도시된 바와 같이, 도 1a는 실제 이미지를 도시하고, 도 1b 내지 도 1d는 도 1a의 아이덴티티 가 익명화된 이미지를 도시한다. 도 1a 및 도 1b 내지 도 1d 사이의 비교를 통해, 도 1b 내지 도 1d에서, 도 1a 의 인식 가능한 아이덴티티 특징(feature)은 제거되고 다른 아이덴티티가 없는 속성은 변경되지 않음을 알 수 있으며, 이미지가 여전히 시각적으로 실제임을 보장한다. 시나리오 1: 본 출원의 실시예는 프라이버시 보호(privacy protection) 시나리오에 적용될 수 있다. 예를 들어, 얼굴 관련 픽처 또는 비디오의 경우, 본 출원의 실시예의 방법은 실제 아이덴티티를 가상 아이덴티티로 대체하 는 데 사용될 수 있으므로, 검출과 같은 후속 작업(task)이 프라이버시 누출 없이 추가로 수행될 수 있다. 또한, 픽처 또는 비디오를 공개할 때, 사용자는 실제 정보의 누출을 피하기 위해 사용자의 아이덴티티 특징에 대해 본 출원의 실시예의 방법을 사용할 수도 있다. 시나리오 2: 본 출원의 실시예는 가상 이미지를 생성하는 시나리오에 적용될 수 있다. 예를 들어, 본 출원의 실 시예의 기술적 솔루션은 가상 아이덴티티, 예를 들어 고정 잠재(fixed latent) 아이덴티티 변수를 생성하고 배 경 픽처를 대체하여, 상이한 시나리오에서 특정 가상 이미지의 픽처 또는 비디오를 생성하는 데 사용할 수 있다. 시나리오 1 및 시나리오 2는 타깃이 얼굴인 예를 사용하여 설명한다. 본 출원의 실시예의 방법은 다르게는, 다 른 비-얼굴 타깃에 대해 아이덴티티 익명화를 수행하는 시나리오, 예를 들어 처리 대상 이미지(to-be-processed image)에서 동물 또는 차량과 같은 임의의 타깃에 대해 아이덴티티 익명화를 수행하는 시나리오에 적용될 수 있 다. 일부 실시예에서, 본 출원의 실시예의 방법은 지능형 운송 시스템에 적용될 수 있다. 지능형 운송 시스템 (Intelligent Transport System, ITS)은 지능형 교통 시스템(Intelligent Transportation System)이라고도 하 며, 첨단 기술(정보 기술, 컴퓨터 기술, 데이터 통신 기술, 센서 기술, 전자 제어 기술, 자동 제어 기술, 인공지능 기술 등)을 교통, 서비스 관제, 차량 제조에 종합적이고 효과적으로 적용하여, 차량과 도로와 사용자 간의 연결을 강화하며, 이에 따라 안전 확보, 효율성 향상, 환경 개선 및 에너지 절약을 위한 통합된 형태를 형성한 다. 예를 들어, 본 출원에서 지능형 트래픽과 조합된 솔루션은 다음과 같을 수 있다: 차량 내 디바이스가 사용 자의 얼굴 이미지를 수집하고, 본 출원의 실시예의 방법을 사용하여 수집된 얼굴 이미지에 대해 아이덴티티 익 명화를 수행하고, 그런 다음, 아이덴티티가 익명화된 이미지를 작업 분석 등을 수행하는, 예를 들어 불법 운전 분석 또는 지능형 운전 분석을 수행하는 다른 디바이스로 전송한다. 도 2는 본 출원의 실시예에 따른 시스템 아키텍처의 개략도이다. 시스템 아키텍처는 사용자 장비, 데이터 수집 디바이스, 트레이닝 디바이스, 실행 디바이스, 데이터베이스, 콘텐츠 라이브러리 , I/O 인터페이스, 및 타깃 네트워크 모델을 포함한다. 데이터 수집 디바이스는 콘텐츠 라이브러리로부터 트레이닝 데이터를 판독하고, 판독된 트레이닝 데 이터를 데이터베이스에 저장하도록 구성된다. 본 출원의 이 실시예와 관련된 트레이닝 데이터는 제1 트레 이닝 이미지, 제2 트레이닝 이미지 및 제3 트레이닝 이미지를 포함하고, 제1 트레이닝 이미지, 제2 트레이닝 이 미지 및 제3 트레이닝 이미지는 모두 타깃 네트워크 모델을 트레이닝하는 데 사용된다. 일부 실시예에서, 사용자 장비는 데이터베이스의 데이터에 대해 주석 작동(annotation operation)을 수행하도록 구성된다. 트레이닝 디바이스는 데이터베이스에 유지된 트레이닝 데이터에 기반하여 타깃 네트워크 모델을 트레이닝하므로, 트레이닝된 타깃 네트워크 모델이 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 생성할 수 있다. 일부 실시예에서, 트레이닝 디바이스에 의해 획득된 타깃 네트워크 모델은 상이한 시스템 또는 디바이스에 적용될 수 있다. 도 2에서, 실행 디바이스는 외부 디바이스와 데이터를 교환하는, 예를 들어, I/O 인터페이스를 사용하여 사용자 장비에 의해 전송된 처리 대상 이미지를 수신하는 I/O 인터페이스를 갖추고 있다. 실행 디바 이스의 컴퓨팅 모듈은 트레이닝된 타깃 네트워크 모델을 사용하여, 입력된 처리 대상 이미지를 처리하여 아이덴티티가 익명화된 이미지를 출력하고, 생성된 익명화된 아이덴티티 정보를 디스플레이를 위해 사 용자 장비에 출력하거나, 또는 생성된 아이덴티티가 익명화된 이미지를 다른 작업 처리를 수행하기 위한 다른 작업 모델에 입력한다. 사용자 장비는 모바일 폰, 태블릿 컴퓨터, 노트북 컴퓨터, 팜탑 컴퓨터, 모바일 인터넷 디바이스(mobile Internet device, MID), 또는 브라우저 설치 기능을 갖는 다른 단말 디바이스를 포함할 수 있다. 실행 디바이스는 서버일 수 있다. 하나 이상의 서버가 있을 수 있다. 복수의 서버가 있을 때, 다음 경우: 적어도 2개의 서버가 상이한 서비스를 제공하도록 구성되는 경우; 또는 적어도 2개의 서버가 동일한 서비스를 제공하도록, 예를 들어 로드 밸런싱 방식으로 동일한 서비스를 제공하도록 구성되는 경우 중 적어도 하나가 있 을 수 있다. 이것은 본 출원의 이 실시예에서 제한되지 않는다. 서버는 독립된 물리적 서버일 수 있고, 또는 복 수의 물리적 서버에 의해 형성된 서버 클러스터 또는 분산 시스템일 수도 있으며, 또는 클라우드 서비스, 클라 우드 데이터베이스, 클라우드 컴퓨팅, 클라우드 기능, 클라우드 스토리지, 네트워크 서비스, 클라우드 통신, 미 들웨어 서비스, 도메인 네임 서비스, 보안 서비스, 콘텐츠 전달 네트워크(content delivery network, CDN), 빅 데이터, AI 플랫폼과 같은 기본적인 클라우드 컴퓨팅 서비스를 제공하는 클라우드 서버일 수 있다. 다르게는, 서버가 블록체인의 노드가 될 수 있다. 이 실시예에서, 실행 디바이스는 네트워크를 통해 사용자 장비에 연결된다. 네트워크는 무선 또는 유 선 네트워크, 예를 들어 인트라넷, 인터넷, GSM(Global System for Mobile Communications) 네트워크, 광대역 코드 분할 다중 액세스(wideband code division multiple access, WCDMA) 네트워크, 4G 네트워크, 5G 네트워크, 블루투스 네트워크, Wi-Fi 네트워크 또는 통화 네트워크일 수 있다. 도 2는 본 출원의 실시예에 따른 시스템 아키텍처의 개략도일 뿐이며, 도면에 도시된 디바이스, 컴포넌트, 모듈 등의 위치 관계는 어떠한 제한도 구성하지 않는다. 일부 실시예에서, 데이터 수집 디바이스, 사용자 장비 , 트레이닝 디바이스, 및 실행 디바이스는 동일한 디바이스일 수 있다. 데이터베이스는 하 나 이상의 서버에 분산될 수 있고, 콘텐츠 라이브러리는 하나 이상의 서버에 분산될 수 있다. 일부 실시예는 본 출원의 실시예의 기술적 솔루션을 상세히 설명하기 위해 아래에 사용된다. 이하의 실시예는 상호 조합될 수 있으며, 일부 실시예에서는 동일하거나 유사한 개념 또는 프로세스가 반복적으로 설명되지 않을수 있다. 본 출원은 타깃 네트워크 모델을 제공하며, 타깃 네트워크 모델은 처리 대상 이미지의 타깃(예: 얼굴)에 대해 아이덴티티 익명화를 수행하여 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 생성하는 데 사용된다. 따 라서, 일부 실시예에서, 타깃 네트워크 모델은 아이덴티티 익명화 모델 또는 아이덴티티 익명화기로 지칭될 수 있다. 먼저, 타깃 네트워크 모델의 트레이닝 프로세스를 설명한다. 도 3은 본 출원의 실시예에 따른 모델 트레이닝 방법의 개략적인 흐름도이다. 본 출원의 이 실시예에서, 상기 방법은 모델 트레이닝 기능을 갖는 장치, 예를 들어 모델 트레이닝 장치에 의해 수행되고, 모델 트레이닝 장치 는 컴퓨팅 디바이스 또는 컴퓨팅 디바이스의 일부일 수 있다. 다음은 상기 방법이 컴퓨팅 디바이스에 의해 수행 되는 예를 사용하여 설명을 제공한다. 도 3에 도시된 바와 같이, 본 출원의 이 실시예의 상기 방법은 다음을 포 함한다: S301: 컴퓨팅 디바이스는 타깃 네트워크 모델의 투사 모듈을 사용하여 제1 트레이닝 이미지를 타깃 공간에 투사 하여 N개의 제1 가상 아이덴티티 벡터를 획득하며, N은 양의 정수이다. 본 출원의 이 실시예에서, 제1 트레이닝 이미지는 트레이닝 데이터의 트레이닝 이미지이다. 제1 트레이닝 이미 지가 얼굴 이미지인 경우에, 제1 트레이닝 이미지가 사용자의 허가(permission)를 받아 획득되며, 관련 이미지 데이터의 수집, 사용 및 처리는 관련 국가 및 지역의 관련 법률, 규정 및 기준을 준수해야 한다. 본 출원의 이 실시예에서, 제1 트레이닝 이미지를 사용하여 모델을 트레이닝하는 프로세스는 기본적으로 유사하 다. 설명의 편의상, 하나의 제1 트레이닝 이미지를 설명의 예로 사용한다. 본 출원의 이 실시예에서, 제1 트레이닝 이미지를 타깃 네트워크 모델을 사용하여 타깃 공간에 투사하여, 제1 트레이닝 이미지의 하나 이상의 가상 아이덴티티 벡터를 획득하므로, 타깃 네트워크 모델은 제1 트레이닝 이미 지의 아이덴티티 정보를 학습한다. 타깃 네트워크 모델이 아이덴티티 정보를 완전히 학습한 후, 실제 아이덴티 티 익명화 동안, 타깃 네트워크 모델의 타깃 공간을 직접 샘플링하여 가상 아이덴티티 벡터를 생성할 수 있다. 본 출원의 이 실시예는 주로 다음 개념: 속성 벡터 및 가상 아이덴티티 벡터에 관한 것이다. 가상 아이덴티티 벡터는 가상 아이덴티티 정보에 대응하는 벡터이며, 가상 아이덴티티 정보는 숨겨진 인식 가능 한 아이덴티티 특징(recognizable identity feature hidden)을 갖는 아이덴티티 정보이며, 예를 들어 숨겨진 얼굴의 인식 가능한 아이덴티티 특징을 갖는 얼굴 정보이다. 속성 벡터는 속성 정보에 대응하는 벡터이며, 이미지에서 인식 가능한 아이덴티티 특징 이외의 특징 정보를 속 성 정보, 예를 들어 배경 정보라고 한다. 본 출원의 이 실시예에서, 타깃 네트워크 모델은 독립적인 가상 아이덴티티 벡터를 생성할 수 있다. 도 4는 본 출원의 실시예에 따른 타깃 네트워크 모델의 개략적인 구조도이다. 도 4에 도시된 바와 같이, 본 출 원의 이 실시예에서 타깃 네트워크 모델은 투사 모듈, 속성 모듈 및 융합 모듈을 포함한다. 투사 모듈은 제1 트레이닝 이미지를 타깃 공간에 투사하여 제1 트레이닝 이미지의 N개의 제1 가상 아이덴티티 벡터를 획득하도록 구성된다. N은 양의 정수이다. N의 값은 본 출원의 이 실시예에서 제한되지 않으며, 실제 요 건에 따라 설정될 수 있다. 속성 유닛은 제2 트레이닝 이미지에 대해 속성 벡터 추출을 수행하여 제2 트레이닝 이미지의 M개의 속성 벡터를 획득하도록 구성된다. M은 양의 정수이다. M의 값은 본 출원의 이 실시예에서 제한되지 않으며, 실제 요건에 따 라 설정될 수 있다. 일부 실시예에서, M은 N과 같다(equal). 융합 모듈은 N개의 제1 가상 아이덴티티 벡터 및 M개의 속성 벡터에 기반하여 이미지 생성을 수행하여 제2 트레 이닝 이미지의 아이덴티티가 익명화된 이미지를 획득하도록 구성된다. N이 1보다 큰 양의 정수인 경우에, N개의 제1 가상 아이덴티티 벡터는 각각 서로 다른 해상도에 대응한다. 본 출원의 이 실시예의 타깃 네트워크 모델에서, 투사 모듈은 제2 트레이닝 이미지에서 타깃의 가상 아이덴티티 벡터를 생성하도록 구성되며, 제2 트레이닝 이미지에서 타깃의 실제 아이덴티티 특징은 가상 아이덴티티 벡터에 숨겨져 있으며, 속성 모듈은 제2 트레이닝 이미지의 속성 벡터를 추출하도록 구성되며, 제2 트레이닝 이미지에 서 타깃의 실제 아이덴티티 특징 이외의 특징은 속성 벡터에 유지된다. 이러한 방식으로, 융합 모듈이 가상 아이덴티티 벡터 및 속성 벡터에 기반하여 이미지 생성을 수행한 후, 제2 트레이닝 이미지에서 타깃의 아이덴티티 가 숨겨져 있는 익명화된 이미지, 즉 아이덴티티가 익명화된 이미지가 획득될 수 있다. 일부 실시예에서, 도 5에 도시된 바와 같이, 투사 모듈은 제1 투사 유닛 및 제2 투사 유닛을 포함하고, 타깃 공 간은 제1 공간(Z) 및 제2 공간(W)을 포함한다. 이 경우, 컴퓨팅 디바이스는 타깃 네트워크 모델의 투사 모듈을 사용하여 다음 방식: 제1 트레이닝 이미지의 선험적 아이덴티티 정보(priori identity information)를 추출하고; 제1 투사 유닛을 사 용하여 선험적 아이덴티티 정보를 제1 공간(Z)에 투사하여 N개의 잠재적 아이덴티티 벡터를 획득하며; 그리고 제2 투사 유닛을 사용하여 N개의 잠재적 아이덴티티 벡터를 제2 공간(W)에 투사하여 N개의 제1 가상 아이덴티티 벡터를 획득하는 방식으로, 제1 트레이닝 이미지를 타깃 공간에 투사하여 N개의 제1 가상 아이덴티티 벡터를 획 득하는 것을 구현할 수 있다. 도 5에 도시된 바와 같이, 먼저, 제1 트레이닝 이미지의 선험적 아이덴티티 정보가 추출되며, 예를 들어, 사전 트레이닝된 인식 모델을 사용하여 제1 트레이닝 이미지의 선험적 아이덴티티 정보가 추출되고; 그런 다음 제1 트레이닝 이미지의 선험적 아이덴티티 정보는 N개의 잠재적 아이덴티티 벡터를 획득하기 위해 제1 투사 유닛을 사용하여 제1 공간(Z)에 투사되고; 그런 다음 N개의 잠재적 아이덴티티 벡터는 N개의 제1 가상 아이덴티티 벡터 를 획득하기 위해 제2 투사 유닛을 사용하여 제2 공간(W)에 투사된다. 제1 공간(Z)과 제2 공간(W)은 서로 다른 잠재 공간일 수 있다. 제1 공간(Z) 및 제2 공간(W)은 본 출원의 이 실 시예에서 제한되지 않는다. 일부 실시예에서, 제1 공간은 잠재 공간 Z이고, 잠재 공간 Z는 표준 가우시안 분포를 따른다. 이 경우, 제1 투사 유닛은 다음 방식: 제1 투사 유닛을 사용하여, 선험적 아이덴티티 정보를 제1 공간의 평균 및 분산으로 투사하고; 그리고 제1 공간 의 평균 및 분산에 기반하여 샘플링을 수행하여 N개의 잠재적 아이덴티티 벡터를 획득하는 방식으로 선험적 아 이덴티티 정보를 제1 공간(Z)에 투사하여 N개의 잠재적 아이덴티티 벡터를 획득할 수 있다. 일부 실시예에서, 제1 투사 유닛은 가변 오토인코더(variational autoencoder, VAE), 예를 들어 조건부 가변 오 토인코더(conditional variational autoencoder, CVAE)이다. 조건부 가변 오토인코더는 생성 네트워크이며, 인 코더를 사용하여 데이터 분포를 학습하여 잠재 변수(latent variable)를 획득한 다음 디코더를 사용하여 잠재 변수를 데이터의 원래 형태로 복원한다. 조건부 가변 오토인코더는 데이터 분포를 학습한 다음 샘플링을 수행하 여 신규 데이터를 생성할 수 있으며, 일반적으로 이미지 생성에 사용된다. 이와 같이, 제1 트레이닝 이미지의 선험적 아이덴티티 정보가 VAE에 입력될 수 있고, VAE는 선험적 아이덴티티 정보를 제1 공간의 평균 및 분산으로 투사한다. 그런 다음, 제1 공간의 평균과 분산에 기반하여 샘플링을 수행 하여 제1 트레이닝 이미지의 N개의 잠재적 아이덴티티 벡터를 획득한다. 이 예에서, 제1 공간은 표준 가우시안 분포를 따르는 잠재 공간 Z이다. 따라서, 잠재 공간의 표현 능력 (expression ability)을 향상시키기 위해, 본 출원의 이 실시예에서, 상이한 잠재 벡터가 상이한 해상도 레이어 에서 생성되며, 예를 들어, N개의 잠재적 아이덴티티 벡터가 생성된다. 이는 복수의 잠재적 아이덴티티 벡터를 포함하는 공간을 구성하는 것과 동등하다. 일부 실시예에서, 제2 공간(W)은 예를 들어, 잠재 공간 Z에 대해 선형 또는 비선형 매핑을 수행하는 것에 의해 획득된 잠재 공간 Z에 기반하여 획득된다. 제2 투사 유닛의 네트워크 구조는 본 출원의 이 실시예에서 제한되지 않는다. 예를 들어, 매핑 네트워크가 사용 되며, 매핑 네트워크는 복수의 완전 연결 레이어를 포함한다. 본 출원의 이 실시예에서, 제1 트레이닝 이미지의 선험적 아이덴티티 정보는 투사 모듈의 잠재 공간(즉, 타깃 공간)에 투사되므로, 투사 모듈은 실제 요건을 충족하는 가상 아이덴티티 벡터를 이후에 생성하기 위해, 제1 트 레이닝 이미지의 아이덴티티 정보를 완전히 학습한다. S302: 타깃 네트워크 모델의 속성 모듈을 사용하여 제2 트레이닝 이미지에 대해 속성 벡터 추출을 수행하여 M개 의 속성 벡터를 획득하며, M은 양의 정수이다. 제2 트레이닝 이미지는 트레이닝 데이터 세트 내의 임의의 이미지이고, 제2 트레이닝 이미지와 제1 트레이닝 이 미지는 동일한 이미지이거나 상이한 이미지일 수 있다. 본 출원의 이 실시예에서, 속성 모듈은 제2 트레이닝 이미지의 속성 정보를 학습하여 M개의 속성 벡터를 생성하 도록 구성된다. 속성 모듈의 네트워크 모델은 본 출원의 이 실시예에서 제한되지 않는다. 일부 실시예에서, 도 6에 도시된 바와 같이, 속성 모듈은 인코딩 유닛 및 디코딩 유닛을 포함한다. 이 경우, 타 깃 네트워크 모델의 속성 모듈을 사용하여 다음 방식: 제2 트레이닝 이미지를 인코딩 유닛에 입력하여 제2 트레이닝 이미지의 특징 정보를 획득하고; 및 특징 정보를 디코딩 유닛에 입력하여 M개의 속성 벡터를 획득하는 방식으로, 제2 트레이닝 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속성 벡터를 획득할 수 있다. 일부 실시예에서, 인코딩 유닛은 복수의 특징 추출 레이어를 포함하고, 디코딩 유닛은 또한 복수의 특징 추출 유닛을 포함하며, 인코딩 유닛의 적어도 하나의 특징 추출 레이어와 디코딩 유닛의 적어도 하나의 특징 추출 레 이어 사이에 스킵 연결(skip connection)이 구현된다. 전술한 단계에 따라 N개의 제1 가상 아이덴티티 벡터 및 M개의 속성 벡터가 생성된 후, 다음 S303이 수행된다. S303: 타깃 네트워크 모델의 융합 모듈을 사용하여, N개의 제1 가상 아이덴티티 벡터 및 M개의 속성 벡터에 기 반한 이미지 생성을 수행하여 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득한다. 예 1: N개의 제1 가상 아이덴티티 벡터를 스플라이싱하여(splice) 스플라이싱된 제1 가상 아이덴티티 벡터를 획 득하고, M개의 속성 벡터를 스플라이싱하여 스플라이싱된 속성 벡터를 획득하며, 스플라이싱된 제1 가상 아이덴 티티 벡터 및 스플라이싱된 속성 벡터가 이미지 생성을 수행하기 위해 사용되고 그런 다음 아이덴티티가 익명화 된 이미지를 생성하기 위해 융합 모듈에 입력된다. 예를 들어, 스플라이싱된 제1 가상 아이덴티티 벡터 및 스플라이싱된 속성 벡터는 아이덴티티가 익명화된 이미 지를 생성하기 위해 연쇄된(concatenated) 후 융합 모듈에 입력된다. 다른 예를 들어, 스플라이싱된 제1 가상 아이덴티티 벡터와 스플라이싱된 속성 벡터는 아이덴티티가 익명화된 이미지를 생성하기 위해 합산되고 그런 다음 융합 모듈에 입력된다. 예 2: 융합 모듈은 복수의 상이한 해상도 레이어를 포함한다. 이 경우, 융합 모듈은 다음 방식: N개의 제1 가상 아이덴티티 벡터에 대응하는 해상도에 따라, N개의 제1 가상 아이덴티티 벡터를 대응하는 해상 도 레이어에 패턴으로 입력하고, M개의 속성 벡터를 대응하는 해상도 레이어에 노이즈로 입력하여, 제2 트레이 닝 이미지의 아이덴티티가 익명화된 이미지를 획득하는 방식으로, N개의 제1 가상 아이덴티티 벡터 및 M개의 속 성 벡터에 기반한 이미지 생성을 수행하여 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득할 수 있다. 예를 들어, N은 3이고, M은 4이며, 융합 모듈은 4개의 서로 다른 해상도 레이어를 포함한다. 3개의 제1 가상 아 이덴티티 벡터는 제1 가상 아이덴티티 벡터 1, 제1 가상 아이덴티티 벡터 2 및 제1 가상 아이덴티티 벡터 3으로 표기된다. 4개의 속성 벡터는 속성 벡터 1, 속성 벡터 2, 속성 벡터 3 및 속성 벡터 4로 표기된다. 4개의 해상 도 레이어는 해상도의 매그니튜드(magnitude)에 따라 순차적으로 해상도 레이어 1, 해상도 레이어 2, 해상도 레 이어 3, 해상도 레이어 4로 표기된다. 제1 가상 아이덴티티 벡터 1은 저해상도의 해상도 레이어 1 및 해상도 레 이어 2에 대응하고, 제1 가상 아이덴티티 벡터 2는 중간 해상도의 해상도 레이어 3에 대응하며, 가상 아이덴티 티 벡터 3은 가장 높은 해상도의 해상도 레이어 4에 대응한다. 4개의 속성 벡터는 해상도의 매그니튜드에 따라 순서대로 4개의 해상도 레이어에 대응한다. 예를 들어, 제1 가상 아이덴티티 벡터 1을 해상도 레이어 1에 입력하여 특징 정보 1을 획득하고; 속성 벡터 1 및 특징 정보 1을 조합한 다음 제1 가상 아이덴티티 벡터 1과 함께 해상도 레이어 2에 입력하여 특징 정보 2를 획득하며; 속성 벡터 2 및 특징 정보 2를 조합한 다음 제1 가상 아이덴티티 벡터 3와 함께 해상도 레이어 3에 입력하여 특징 정보 3를 획득하고; 속성 벡터 3 및 특징 정보 3을 조합한 다음 제1 가상 아이덴티티 벡터 4와 함께 해상도 레이어 4에 입력하여 특징 정보 4를 획득하며; 마지막으로, 특징 정보 4와 속성 벡터 4는 조합 등 의 처리를 거쳐 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 생성한다. 일부 실시예에서, 융합 모듈은 스타일 기반 생성기(style-based generator, StyleGAN2)이다. 도 7에 도시된 바 와 같이, AdaIN 레이어가 융합 모듈의 인접한 두 해상도 레이어 사이에 포함된다. 예를 들어, 아핀 변환(affine transform, AT)은 제1 가상 아이덴티티 벡터 i+1에 대해 수행되고; i번째 해상도 레이어에서 출력된 특징 정보 i와 속성 벡터 i가 조합되고, 그런 다음 아핀 변환을 통해 획득된 제1 가상 아이덴티티 벡터 i+1와 함께 AdaIN 레이어에 입력되며; AdaIN 연산이 수행되고, AdaIN 연산 결과가 (i+1)번째 해상도 레이어에 입력된다. 본 출원의 이 실시예에서 융합 모듈은 다르게는 적대적 모델(adversarial model), 예를 들어 StyleGAN3 또는 ProGAN일 수 있다. 서로 다른 적대적 모델이 융합 모듈로 사용되는 경우, 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지는 서로 다른 방식으로 결정될 수 있다. 이것은 본 출원의 이 실시예에서 제한되지 않는다. 일부 실시예에서, 본 출원의 이 실시예에서의 모델 트레이닝 프로세스는, 제1 투사 유닛이 VAE이고, 제2 투사 유닛이 매핑 네트워크이며, 속성 모듈이 오토인코더이고, 융합 모듈은 StyleGAN2인 예를 사용하여 설명된다. 예를 들어, 도 8에 도시된 바와 같이, 사전 트레이닝된 얼굴 인식 모델을 사용하여 제1 학습 이미지(Xs)에 기반 하여 선험적 아이덴티티 정보를 생성한다. 그런 다음 선험적 아이덴티티 정보가 VAE에 입력되고, VAE는 선험적 아이덴티티 정보를 제1 공간(Z)에 투사하여 N개의 잠재적 아이덴티티 벡터를 획득하며, 예를 들어, 3개의 N 잠 재적 아이덴티티 벡터를 획득하며, 3개의 N 잠재적 아이덴티티 벡터는 세 가지 상이한 해상도: 낮음, 중간 및 높음에 각각 대응한다. 그런 다음, N개의 잠재적 아이덴티티 벡터가 매핑 네트워크에 입력되며, 매핑 네트워크 는 N개의 잠재적 아이덴티티 벡터를 제1 공간(Z)에서 제2 공간(W)으로 투사하여 N개의 제1 가상 아이덴티티 벡 터를 획득한다. 또한, 제2 트레이닝 이미지(Xt)가 오토인코더에 입력되고, 오토인코더는 제2 트레이닝 이미지 (Xt)을 처리하여 M개의 속성 벡터를 생성한다. 마지막으로, M개의 속성 벡터를 StyleGAN2의 레이어에 노이즈로 입력하고, N개의 제1 가상 아이덴티티 벡터를 StyleGAN2의 레이어에 패턴으로 입력하여, StyleGAN2에서 출력되 는, 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지(Ys,t)를 획득한다. 전술한 단계에 따르면, 제1 트레이닝 이미지 및 제2 트레이닝 이미지를 타깃 네트워크 모델에 입력하여, 타깃 네트워크 모델에 의해 출력되는, 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득한다. 그다음, 다 음의 S304를 수행하여 타깃 네트워크 모델을 트레이닝한다. S304: 아이덴티티가 익명화된 이미지에 따라 타깃 네트워크 모델의 손실을 결정하고, 손실에 따라 타깃 네트워 크 모델을 트레이닝한다. 전술한 단계에 따르면, 타깃 네트워크 모델은 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 출력하고, 타깃 네트워크 모델의 손실은 아이덴티티가 익명화된 이미지에 따라 결정된다. 일부 실시예에서, 아이덴티티가 익명화된 이미지는 판단 모델(judgment model)에 입력되고, 판단 모델은 아이덴 티티가 익명화된 이미지의 익명화 정도를 예측할 수 있는 사전 트레이닝된 모델이다. 예를 들어, 아이덴티티가 익명화된 이미지가 판단 모델에 입력되고, 판단 모델은 아이덴티티가 익명화된 이미지에 대해 아이덴티티 인식 을 수행하고, 인식 결과를 타깃 네트워크 모델의 손실로 결정한다. 인식 정확도가 높은 경우, 현재 타깃 네트워 크 모델의 익명화 효과를 원하지 않는다. 이 경우, 타깃 네트워크 모델의 손실에 따라 타깃 네트워크 모델의 파 라미터가 조정된다. 그런 다음, 타깃 네트워크 모델이 트레이닝 종료 조건을 만족할 때까지, 전술한 단계(S301 내지 S304)를 수행하기 위해 신규 제1 트레이닝 이미지 및 신규 제2 트레이닝 이미지가 선택되어, 타깃 네트워 크 모델을 계속 트레이닝한다. 트레이닝 종료 조건은 적어도 미리 설정된 횟수에 도달한 트레이닝 횟수 또는 예 상 효과에 도달한 모델의 익명화 정도를 포함한다. 일부 실시예에서, 도 5에 도시된 제1 공간(Z)이 표준 가우시안 분포를 따르는 잠재 공간인 경우, 본 출원의 이 실시예에서, KL 발산 제약(divergence constraint) 이 제1 공간(Z)의 N개의 잠재적 아이덴티티 벡터에 적용 되어, 아이덴티티 정보가 표준 가우시안 분포로 투사되는 것을 보장한다. 이에 기반하여, 본 출원의 이 실시예에서, N개의 잠재적 아이덴티티 벡터의 발산 제약이 추가로 결정될 수 있다. 이 경우, 아이덴티티가 익명화된 이미지에 따라 타깃 네트워크 모델의 손실을 결정하는 것은, 아이덴티티 가 익명화된 이미지 및 발산 제약에 따라 타깃 네트워크 모델의 손실을 결정하는 것을 포함할 수 있다. 예를 들어, N개의 잠재적 아이덴티티 벡터의 발산 제약 은 다음 수식 을 사용하여 결정될 수 있다:"}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "μi는 N개의 잠재적 아이덴티티 벡터 중 i번째 잠재적 아이덴티티 벡터에 대응하는 평균이고, σi는 N개의 잠재 적 아이덴티티 벡터 중 i번째 잠재적 아이덴티티 벡터에 대응하는 분산이다. 수식 은 예시일 뿐이고, 본 출원의 이 실시예에서 N개의 잠재적 아이덴티티 벡터의 발산 제약을 결정하는 방 식은 수식 을 포함하지만 이에 제한되지 않으며, 예를 들어, 수식 의 변형을 사용하는, 예를 들어, 발산 제약을 계산하는 다른 방식일 수 있다. 본 출원의 이 실시예에서, 발산 제약 이 N개의 잠재적 아이덴티티 벡터에 적용된다. 이런 방식으로, 트레이 닝 후, 투사 모듈은 아이덴티티 정보를 완전히 학습하고 투사 모듈의 제1 공간은 표준 가우스 분포를 만족한다. 따라서, 후속 익명화 동안, 가상 아이덴티티 벡터를 생성하기 위해, 표준 가우시안 분포를 따르는 N개의 잠재적 아이덴티티 벡터를 생성하기 위해 제1 공간이 직접 샘플링될 수 있다. 일부 실시예에서, 제2 공간은 제1 공간에 대해 비선형 매핑을 수행하는 것에 의해 획득되고, 복소 비-가우시안 분포(complex non-Gaussian distribution)이다. 도 5에 도시된 바와 같이, 제1 공간에 아이덴티티 정보를 매핑 한 후, 이 경우에 중간 잠재 공간, 즉 제2 공간( )의 분포가 균일하지 않으며, 실제 아이덴티티 벡터가 서로 다른 복수의 중심에 모이며, 생성된 가상 아이덴티티 벡터를 중첩하지 않는다. 따라서, 가상의 아이덴티티 벡터 에 기반하여 합리적인 얼굴 아이덴티티를 생성할 수 없다. 따라서, 본 출원의 이 실시예는 콘트라스트 손실 (contrast loss)의 사용을 제안하여 제2 공간, 즉 공간의 잠재 벡터(즉, 제1 가상 아이덴티티 벡터)을 제약 하므로, 동일한 아이덴티티로부터의 잠재 벡터가 모여서 상이한 아이덴티티로부터의 잠재 벡터를 밀어내며 (repel), 모든 잠재 벡터가 전체 공간에 고르게 분포된다. 이에 기반하여, 본 출원의 이 실시예에서, 아이덴티티 손실은 다음 방식으로 추가로 결정될 수 있다: 단계 1: 제3 트레이닝 이미지를 획득한다. 단계 2: 투사 참조 모듈을 사용하여 제3 트레이닝 이미지를 처리하여, N개의 제2 가상 아이덴티티 벡터를 획득 한다. 단계 3: N개의 제1 가상 아이덴티티 벡터 및 N개의 제2 가상 아이덴티티 벡터에 따라 아이덴티티 손실을 결정한 다. 제3 트레이닝 이미지와 제1 트레이닝 이미지는 제1 타깃의 서로 다른 두 이미지이다. 예를 들어, 제3 트레이닝 이미지와 제1 트레이닝 이미지는 동일한 사용자의 서로 다른 두 개의 얼굴 이미지이다. 투사 참조(reference) 모듈과 투사 모듈은 동일한 네트워크 구조를 가지며, 투사 모듈에 따라 업데이트된다. 예 를 들어, 투사 참조 모듈은 투사 모듈의 모멘텀(momentum)에 따라 업데이트되며, 즉 투사 참조 모듈은 투사 모 듈의 업데이트와 함께 천천히 업데이트된다. 예를 들어, 투사 참조 모듈은 다음 수식 에 따라 업데이트될 수 있다:"}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "는 t번째 업데이트 이후에 획득된 투사 참조 모듈 파라미터이고, 은 (t-1)번째 업데이트 이후에 획득된 투사 참조 모듈 파라미터이며, 는 t번째 업데이트 이후에 획득된 투사 모듈 파라미터이고, Δ는 작 은 값, 예를 들어, 0.01이다. 도 9에 도시된 바와 같이, 모델 트레이닝 프로세스에서 아이덴티티 손실을 결정하기 위해, 본 출원의 이 실시예 에서, 투사 모듈의 것과 완전히 동일한 네트워크 구조를 갖는 투사 참조 모듈을 설정하여, 투사 모듈에 의해 출 력되는 제1 가상 아이덴티티 벡터를 제약한다. 예를 들어, 제1 트레이닝 이미지를 투사 모듈에 입력하여 제1 트 레이닝 이미지의 N개의 제1 가상 아이덴티티 벡터를 획득하고, 제3 트레이닝 이미지를 투사 참조 모듈에 입력하 여 제3 트레이닝 이미지의 N개의 제2 가상 아이덴티티 벡터를 획득한다. 제1 트레이닝 이미지와 제3 트레이닝 이미지는 동일한 타깃의 이미지이며, 투사 모듈과 투사 참조 모듈은 동일한 네트워크 구조를 갖는다. 이와 같이, 모델 트레이닝이 완료된 후, 제1 트레이닝 이미지에 대응하는 N개의 제1 가상 아이덴티티 벡터와 N개의 제2 가상 아이덴티티 벡터의 차이가 작다. 이에 기반하여, 타깃 네트워크 모델의 투사 모듈은 N개의 제2 가상 아이덴티티 벡터 및 제1 트레이닝 이미지에 대응하는 N개의 제1 가상 아이덴티티 벡터에 따라 트레이닝될 수 있 으므로, 투사 모듈은 요건을 충족하는 가상 아이덴티티 벡터를 생성할 수 있다.단계 1에서 N개의 제1 가상 아이덴티티 벡터 및 N개의 제2 가상 아이덴티티 벡터에 따라 아이덴티티 손실을 결 정하는 방식은 다음 방식을 포함하지만 이에 제한되지는 않는다: 방식 1: 상이한 해상도에서 N개의 제1 가상 아이덴티티 벡터와 N개의 제2 가상 아이덴티티 벡터 사이의 차이를 결정하고, 차이의 합 또는 차이의 평균값을 아이덴티티 손실로 결정한다. 예를 들어, N이 3이고, 제1 가상 아이 덴티티 벡터 1과 제2 가상 아이덴티티 벡터 1 사이의 차이 1이 결정되고, 제1 가상 아이덴티티 벡터 2와 제2 가 상 아이덴티티 벡터 2 사이의 차이 2가 결정되며, 제1 가상 아이덴티티 벡터 3와 제2 가상 아이덴티티 벡터 3 사이의 차이 3이 결정된다. 차이 1과 차이 2와 차이 3의 합을 아이덴티티 손실로 결정하거나, 차이 1과 차이 2 와 차이 3의 평균값을 아이덴티티 손실로 결정한다. 방식 2: 본 출원의 이 실시예에서, N개의 동적 리스트 가 설계되고, 동적 리스트는 제2 공간: + 공간의 전 체 트레이닝 세트에서 모든 상이한 타깃 아이덴티티(예: 얼굴 아이덴티티)의 표현을 저장한다. 이 경우, N개의 제1 가상 아이덴티티 벡터 및 N개의 제2 가상 아이덴티티 벡터에 따라 아이덴티티 손실이 다음과 같이 결정될 수 있다: 단계 31: N개의 제1 가상 아이덴티티 벡터 중 i번째 제1 가상 아이덴티티 벡터에 대해, i번째 제2 가상 아이덴 티티 벡터를 사용하여, i번째 동적 리스트의 제1 타깃에 대응하는 가상 아이덴티티 벡터를 업데이트한다. i번째 동적 리스트는 i번째 해상도에서 서로 다른 타깃의 가상 아이덴티티 벡터를 포함하고, i는 1 내지 N의 범 위의 양의 정수이다. 본 출원의 이 실시예에서, N개의 제2 가상 아이덴티티 벡터 각각은 동적 리스트에 대응한다. 예를 들어, N은 3 이며, 저해상도, 중간 해상도, 고해상도에 대응한다. 이 경우, 3개의 동적 리스트: 저해상도에 대응하는 제1 동 적 리스트, 중간 해상도에 대응하는 제2 동적 리스트, 및 고해상도에 대응하는 제3 동적 리스트가 존재한다. i가 1과 같다고 가정하면, 제1 동적 리스트의 제1 타깃에 대응하는 가상 아이덴티티 벡터가 1번째 제2 가상 아 이덴티티 벡터를 사용하여 업데이트된다. i가 2와 같다고 가정하면, 제2 동적 리스트의 제1 타깃에 대응하는 가상 아이덴티티 벡터는 2번째 제2 가상 아 이덴티티 벡터를 사용하여 업데이트된다. i가 3과 같다고 가정하면, 제3 동적 리스트의 제1 타깃에 대응하는 가상 아이덴티티 벡터는 3번째 제2 가상 아 이덴티티 벡터를 사용하여 업데이트된다. 단계 32: i번째 제1 가상 아이덴티티 벡터 및 업데이트된 i번째 동적 리스트에 따라, i번째 제1 가상 아이덴티 티 벡터에 대응하는 아이덴티티 서브손실을 결정한다. 예를 들어, 도 10에 도시된 바와 같이, 제1 트레이닝 이미지와 제3 트레이닝 이미지는 제1 타깃 j의 2개의 상이 한 이미지이고, 제1 트레이닝 이미지 Xj는 N개의 제1 가상 아이덴티티 벡터 Wj를 획득하기 위해 투사 모듈에 입 력되고, 제3 트레이닝 이미지 Xj'가 N개의 제2 가상 아이덴티티 벡터 Wj'를 획득하기 위해 투사 참조 모듈로 입 력된다. N개의 해상도 중 i번째 해상도에 대해, i번째 동적 리스트 Ki는 i번째 해상도에서 서로 다른 타깃의 제 2 가상 아이덴티티 벡터들을 포함하고, i번째 동적 리스트 Ki는 실시간으로 업데이트된다. 예를 들어, i번째 제 2 가상 아이덴티티 벡터는 i번째 동적 리스트 Ki의 제1 타깃 j에 대응하는 가상 아이덴티티 벡터 kj를 업데이트 하는데 사용되며, 즉, kj는 Wj'로 업데이트된다. 그다음, i번째 제1 가상 아이덴티티 벡터에 대응하는 아이덴티 티 서브손실 i가 i번째 제2 가상 아이덴티티 벡터 및 업데이트된 i번째 동적 리스트에 따라 결정된다. i번째 제1 가상 아이덴티티 벡터에 대응하는 아이덴티티 서브손실을 결정하는 방식은 본 출원의 이 실시예에서 제한되지 않는다. 예를 들어, i번째 제1 가상 아이덴티티 벡터에 대응하는 아이덴티티 서브손실은 손실 방법, 예를 들어 중심 손 실 또는 트리플렛 손실(triplet loss)을 사용하여, i번째 제1 가상 아이덴티티 벡터 및 업데이트된 i번째 동적 리스트에 따라 결정된다. 일부 실시예에서, N개의 제1 가상 아이덴티티 벡터 중 i번째 제1 가상 아이덴티티 벡터에 대응하는 아이덴티티 서브손실을 결정하는 단계는 다음 단계를 포함할 수 있다: 단계 321: 제1 미리 설정된 값에 대한 i번째 제2 가상 아이덴티티 벡터의 제1 비율을 획득하고, 제1 비율에 i번 째 제1 가상 아이덴티티 벡터를 곱하여 제1 결과를 획득하며, 제1 결과에 대해 지수 연산을 수행하여 제1 연산값을 획득한다. 단계 322: 업데이트된 i번째 동적 리스트에서 제1 미리 설정 값에 대한 각각의 제2 가상 아이덴티티 벡터의 제2 비율을 획득하고, 각각의 제2 비율에 대해, 제2 비율에 대응하는 i번째 제1 가상 아이덴티티 벡터를 곱하여 제2 결과를 획득하며, 제2 결과에 대해 지수 연산을 수행하여 각각의 제2 가상 아이덴티티 벡터에 대응하는 제2 연 산 값을 획득한다. 단계 323: 모든 제2 가상 아이덴티티 벡터에 대응하는 제2 연산 값들의 합을 결정하고, 합에 대한 제1 연산 값 의 제3 비율을 획득하며, 제3 비율에 대해 로그 연산(logarithmic operation)을 수행하여 제3 연산 값을 획득한 다. 단계 324: 제3 연산 값의 음수를 i번째 제1 가상 아이덴티티 벡터에 대응하는 아이덴티티 서브손실로 결정한다. 예를 들어, 는 앵커 포인트이고, i의 번째 항목은 양의 샘플이고, 나머지는 음의 샘플이다. InfoNCE(Information Noise Contrastive Noise) 형식의 콘트라스트 손실을 사용하여 아이덴티티 서브손실 을 결정한다. InfoNCE는 상호 정보에 기반하여 자기회귀(autoregression)를 수정하기 위한 손실 함수이다. 예를 들어, i번째 제1 가상 아이덴티티 벡터에 대응하는 아이덴티티 서브 손실 은 다음 수식 에 따라 결정된다."}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "는 제1 타깃 j의 i번째 제1 가상 아이덴티티 벡터이고, 는 제1 타깃 j의 i번째 제2 가상 아이덴티티 벡 터이며, 는 제1 미리 설정 값이고, 은 i번째 동적 리스트에서 k번째에 대응하는 하는 i번째 제2 가상 아 이덴티티 벡터이며, 는 k번째 타깃에 대응하는 하는 제1 가상 아이덴티티 벡터이고, K는 i번째 동적 리스트 에 포함된 타깃의 총 수량이다. 단계 33: N개의 제1 가상 아이덴티티 벡터에 각각 대응하는 아이덴티티 서브손실들의 합을 타깃 네트워크 모델 의 아이덴티티 손실로 결정한다. 단계 32에 따라 i번째 제1 가상 아이덴티티 벡터에 대응하는 아이덴티티 서브손실이 결정된 후, N개의 제1 가상 아이덴티티 벡터에 각각 대응하는 아이덴티티 서브손실들의 합이 아이덴티티 손실로 결정된다. 예를 들어, N은 3이다. 3개의 제1 가상 아이덴티티 벡터 각각에 대응하는 아이덴티티 서브손실을 전술한 방법에 따라 결정한 후, 3개의 제1 가상 아이덴티티 벡터에 대응하는 아이덴티티 서브 손실들의 합을 모델의 아이덴티티 손실로 결 정한다. 본 출원의 이 실시예에서, 모델 트레이닝 프로세스에서 아이덴티티 손실이 전술한 방법에 따라 결정된 후, 아이 덴티티가 익명화된 이미지 및 발산 제약에 따라 타깃 네트워크 모델의 손실을 결정하는 단계는: 아이덴티티가 익명화된 이미지, 발산 제약, 및 아이덴티티 손실에 따라 타깃 네트워크 모델의 손실을 결정하는 단계를 포함한다. 예를 들어, 아이덴티티가 익명화된 이미지와 제2 트레이닝 이미지 사이의 재구성 손실이 결정되고, 재구성 손실, 발산 제약, 및 아이덴티티 손실에 따라 타깃 네트워크 모델의 손실이 결정된다. 일 예에서, 아이덴티티가 익명화된 이미지와 제2 트레이닝 이미지 사이의 차이가 재구성 손실로 결정된다. 예를 들어, 아이덴티티가 익명화된 이미지의 픽셀들과 제2 트레이닝 이미지의 대응하는 픽셀들 사이의 차이들의 합을 재구성 손실로 결정한다. 다른 예에서, 재구성 손실 은 다음 수식 에 따라 결정된다."}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "는 아이덴티티가 익명화된 이미지이고, 는 제2 트레이닝 이미지이며, 는 1-놈(norm) 연산이다. 전술한 단계에 따라 재구성 손실 을 결정한 후, 재구성 손실, 발산 제약, 및 아이덴티티 손실에 따라 타깃 네트워크 모델의 손실을 결정한다. 예를 들어, 재구성 손실과 발산 제약과 아이덴티티 손실의 가중 합이 타깃 네트워크 모델의 최종 손실로 결정된다. 일부 실시예에서, 모델 트레이닝 정확도를 개선하기 위해, 본 출원의 이 실시예는 예를 들어 다음 단계를 포함 하는, 아이덴티티가 익명화된 이미지의 아이덴티티 콘트라스트 손실을 결정하는 단계를 더 포함한다: 단계 A: 아이덴티티가 익명화된 이미지와 제1 트레이닝 이미지 사이의 제1 거리, 아이덴티티가 익명화된 이미지 와 제2 트레이닝 이미지 사이의 제2 거리, 및 제1 트레이닝 이미지와 제2 트레이닝 이미지 사이의 제3 거리를 결정한다. 단계 B: 제1 거리, 제2 거리 및 제3 거리에 따라 콘트라스트 손실을 결정한다. 제1 거리, 제2 거리 및 제3 거리는 임의의 거리 방법, 예를 들어 코사인 거리를 이용하여 결정될 수 있다. 예 1: A 단계에 따라 제1 거리, 제2 거리 및 제3 거리가 결정된 후, 제1 거리와 제2 거리와 제3 거리의 합이 콘 트라스트 손실로 결정된다. 예 2: 제2 거리와 제3 거리 사이의 차이의 제곱과 제1 거리의 합을 획득하고, 미리 설정된 값과 합과의 차이를 콘트라스트 손실로 결정한다. 일 예에서, 콘트라스트 손실 은 다음 수식 에 따라 결정된다."}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "zid는 사전 트레이닝된 얼굴 인식 모델로부터 추출된 이미지 X의 512-차원 아이덴티티 벡터 표현을 지시하며, 는 아이덴티티가 익명화된 이미지와 제1 트레이닝 이미지 사이의 제1 거리이고, 는 아이덴티티가 익명화된 이미지와 제2 트레이닝 이미지 사이의 제1 거리이며, 는 제1 트레이닝 이미지와 제2 트레이닝 이미지 사이의 제3 거리이다. 전술한 단계에 따라 콘트라스트 손실 을 결정한 후, 재구성 손실, 발산 제약, 아이덴티티 손실, 및 콘트라 스트 손실에 따라 타깃 네트워크 모델의 손실을 결정한다. 예를 들어, 재구성 손실과 발산 제약과 아이덴티티 손실과 콘트라스트 손실의 가중 합이 타깃 네트워크 모델의 손실로 결정된다. 일부 실시예에서, 융합 모듈이 적대적 네트워크인 경우, 모델 트레이닝 프로세스에서 모델의 적대적 손실이 추 가로 결정된다. 예를 들어, 아이덴티티가 익명화된 이미지와 제1 트레이닝 이미지에 따라 적대적 손실이 결정된 다. 예를 들어, 적대적 손실 은 다음 수식 에 따라 결정된다."}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "D는 판별자(discriminator)이고, G는 생성기이며, 는 분포 함수의 기대값(expected value)을 지시하고, 는 제1 트레이닝 이미지 에 대한 판별자의 판별 결과이며, 는 아이덴티티가 익명화된 이미지 에 대한 판별자의 판별 결과이다. 전술한 단계에 따라 적대적 손실 을 결정한 후, 재구성 손실, 발산 제약, 아이덴티티 손실, 콘트라스트 손 실, 및 적대적 손실에 따라 타깃 네트워크 모델의 손실을 결정할 수 있다. 예를 들어, 재구성 손실과 발산 제약 과 아이덴티티 손실과 콘트라스트 손실과 적대적 손실의 가중 합을 타깃 네트워크 모델의 손실로 결정한다. 재구성 손실, 발산 제약, 아이덴티티 손실, 콘트라스트 손실, 및 적대적 손실에 대응하는 가중치 값들은 본 출 원의 이 실시예에서 제한되지 않고, 실제 요구에 따라 결정될 수 있다. 일부 실시예에서, 가중 연산을 다음의 수식 에 따라 재구성 손실, 발산 제약, 아이덴티티 손실, 콘트라스트 손실, 및 적대적 손실에 대해 수행하여, 타깃 네트워크 모델의 손실 을 획득한다:"}
{"patent_id": "10-2022-7038590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수식의 각 손실에 대응하는 가중치는 일례이며, 본 출원의 이 실시예에서 각 손실에 대응하는 가중치는 수식 에 나타낸 것을 포함하지만 이에 제한되지 않으며, 필요에 따라 결정될 수 있다. 일부 실시예에서, 타깃 네트워크 모델의 트레이닝 정확도를 개선하기 위해, 전술한 실시예에서 설명된 손실 이 외의 손실이 결정될 수 있다. 이것은 본 출원의 이 실시예에서 제한되지 않으며, 실제 요건에 따라 결정될 수 있다. 본 출원의 이 실시예에서, 아이덴티티 익명화를 구현하기 위해 상이한 해상도에 대응하는 제1 가상 아이덴티티 벡터가 생성된다는 것을 전술한 설명으로부터 알 수 있다. 이것은 익명화에 대한 해상도를 높일 수 있다. 예를 들어, 의 해상도에서 익명화 결과가 생성될 수 있다. 또한, 이미지 아티팩트(artifact)가 거의 발생하지 않고 충실도가 높다. 또한, 본 출원의 이 실시예에서 모델 트레이닝은 키 회귀 모델 또는 세그먼테이션 (segmentation) 모델, 즉 이미지의 얼굴 영역이 제거되지 않고, 원본 픽처의 자세, 세부 정보 및 폐쇄 (occlusion)에 의존하지 않고 유지된다. 본 출원의 이 실시예에서, 타깃 네트워크 모델의 애플리케이션 프로세스에서, 제1 트레이닝 이미지를 투사 모듈 을 사용하여 타깃 공간에 투사하여, N개의 제1 가상 아이덴티티 벡터를 획득하므로, 타깃 네트워크 모델은 이미 지에서 아이덴티티 정보를 완전히 학습할 수 있으며; 속성 벡터 추출을 제2 트레이닝 이미지에 대해 수행하여 M 개의 속성 벡터를 획득하므로, 타깃 네트워크 모델이 이미지에서 속성 정보를 완전히 학습하며; N개의 제1 가상 아이덴티티 벡터 및 M개의 속성 벡터에 기반하여 이미지 생성을 수행하여 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득한다. 이러한 방식으로, 트레이닝된 모델은 원본 이미지의 속성 정보가 변경되지 않은 상태로 유지하는 것을 보장하면서, 가상 아이덴티티 정보를 운반하는 이미지를 생성할 수 있다: 즉, 본 출원은 신규 타깃 네트워크 모델을 제공한다. 위의 트레이닝 방법으로 타깃 네트워크 모델은 제1 트레이닝 이미지에서 아이덴티티 정보를 학습할 수 있으므로, 타깃 네트워크 모델은 가상 아이덴티티를 독립적으로 생성할 수 있으며, 타깃 네트워크 모델은 제2 트레이닝 이미지에서 속성 정보도 완전히 학습할 수 있다. 전체 학습 프로세 스에서 이미지의 얼굴 영역을 제거할 필요가 없으며, 안내(guidance)를 위해 실제 아이덴티티 정보도 필요하지 않다. 또한, 타깃 네트워크 모델은 얼굴 교환 작업(face swapping task)에서 특정 감독 타깃을 사용하여 트레이 닝되며, 이에 따라 타깃 네트워크 모델에 의해 생성된 아이덴티티가 익명화된 이미지의 충실도 및 해상도를 향 상시키므로, 트레이닝된 타깃 네트워크 모델이 고품질의 아이덴티티가 익명화된 이미지를 생성할 수 있다. 이상에서 도 3 내지 도 10을 참조하여 본 출원에서의 모델 트레이닝 방법을 상세히 설명한다. 이하에서는 도 11 내지 도 13을 참조하여 본 출원에서의 아이덴티티 익명화 방법을 상세히 설명한다. 도 11은 본 출원의 실시예에 따른 아이덴티티 익명화 방법의 개략적인 흐름도이다. 도 11에 도시된 아이덴티티 익명화 방법은 전술한 트레이닝된 타깃 네트워크 모델을 사용하여 아이덴티티 익명화를 수행하는 것이다. 도 11 에 도시된 바와 같이, 상기 방법은 다음을 포함한다: S401: 타깃 네트워크 모델에서 투사 모듈의 타깃 공간에 샘플링을 수행하여 N개의 가상 아이덴티티 벡터를 획득 하며, N은 양의 정수이다. 전술한 실시예로부터, 본 출원의 이 실시예에서, 투사 모듈이 제1 트레이닝 이미지를 사용하여 트레이닝되므로, 투사 모듈이 제1 트레이닝 이미지의 아이덴티티 정보를 완전히 학습한다는 것을 알 수 있다. 이러한 방식으로, 실제 사용에서, 투사 모듈의 타깃 공간에 대해 샘플링이 수행되어 N개의 가상 아이덴티티 벡터를 획득할 수 있 다. S401의 구현은 다음을 포함하지만 이에 제한되지는 않는다. 방식 1: 트레이닝된 투사 모듈의 타깃 공간의 평균 및 분산에 기반하여 샘플링을 수행하여 N개의 가상 아이덴티 티 벡터를 획득한다. 예를 들어, 타깃 공간의 분산에 대해 랜덤 샘플링을 수행한 다음, 타깃 공간의 평균에 분 산을 더하여 가상 아이덴티티 벡터를 획득한다. N개의 가상 아이덴티티 벡터를 획득하기 위해 전술한 단계가 반 복적으로 수행될 수 있다. 방식 2: 타깃 공간은 제1 공간 및 제2 공간을 포함하고, 타깃 네트워크 모델은 제2 투사 유닛을 포함한다. 이 경우, N개의 가상 아이덴티티 벡터를 획득하기 위해 다음 방식: 제1 공간에 대해 샘플링을 수행하여 N개의 잠재적 아이덴티티 벡터를 획득하고; 그리고 제2 투사 유닛을 사용하 여 N개의 잠재적 아이덴티티 벡터를 제2 공간에 투사하여 N개의 가상 아이덴티티 벡터를 획득하는 방식으로, 타 깃 네트워크 모델의 투사 모듈의 타깃 공간에 대해 샘플링이 수행될 수 있다. 본 출원의 이 실시예에서, 실제 익명화 동안, 투사 모듈의 제1 투사 유닛은 더 이상 사용되지 않고 투사 모듈의 제2 투사 유닛만이 투사에 사용된다. 예를 들어, 도 12에 도시된 바와 같이, 표준 가우시안 분포를 따르는 제1 공간(Z)에 대해 샘플링을 수행하여 N개의 잠재적 아이덴티티 벡터를 획득한 다음, N개의 잠재적 아이덴티티 벡 터를 제2 투사 유닛에 입력한다. 제2 투사 유닛은 N개의 잠재적 아이덴티티 벡터를 W 공간에 투사하여, N개의 가상 아이덴티티 벡터를 획득한다. 도 12에서, 예를 들어, N은 3이고, 제2 투사 유닛은 매핑 네트워크이다. 그 러나, 본 출원의 이 실시예에서 투사 모듈은 도 12에 도시된 것에 제한되지 않는다. 전술한 내용을 통해 제1 공간은 제1 트레이닝 이미지를 이용하여 트레이닝되므로, 제1 공간의 분산 및 평균이 표준 가우시안 분포를 따르도록 트레이닝될 수 있다. 이 경우, 제1 공간에 대해 샘플링을 먼저 수행하여 N개의 잠재적 아이덴티티 벡터를 생성한다. 예를 들어, 제1 공간의 평균과 분산에 기반하여 샘플링을 수행하여 N개의 잠재적 아이덴티티 벡터를 획득한다. 제1 공간의 분산에 대해 랜덤 샘플링을 수행한 다음 제1 공간의 평균에 분 산을 더하여 잠재적 아이덴티티 벡터를 획득한다. N개의 잠재적 아이덴티티 벡터를 획득하기 위해 전술한 단계 가 반복적으로 수행될 수 있다. 그런 다음, 제2 투사 유닛을 사용하여 N개의 잠재적 아이덴티티 벡터를 제2 공 간에 투사하여, N개의 가상 아이덴티티 벡터를 획득한다. 일부 실시예에서, N개의 가상 아이덴티티 벡터는 각각 상이한 해상도에 대응한다. 예를 들어, N = 3일 때, 1번 째 가상 아이덴티티 벡터는 저해상도에 대응하고, 2번째 가상 아이덴티티 벡터는 중간 해상도에 대응하며, 2번 째 가상 아이덴티티 벡터는 고해상도에 대응한다. 위와 같은 방법으로 N개의 가상 아이덴티티 벡터를 획득한 후, 다음의 단계(S402, S403)를 수행하여 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득한다. S402: 타깃 네트워크 모델의 속성 모듈을 사용하여 처리 대상 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속성 벡터를 획득하며, M은 양의 정수이다. 본 출원의 이 실시예에서, 속성 모듈은 처리 대상 이미지에서 속성 정보를 추출하도록 구성된다. 일부 실시예에서, 속성 모듈은 인코딩 유닛 및 디코딩 유닛을 포함한다. 이 경우, M개의 속성 벡터를 획득하기 위해 다음 방식: 처리 대상 이미지를 인코딩 유닛에 입력하여 처리 대상 이미지의 특징 정보를 획득하고; 그리고 특징 정보를 디 코딩 유닛에 입력하여 M개의 속성 벡터를 획득하는 방식으로, 처리 대상 이미지에 대해 속성 벡터 추출을 수행 할 수 있다. 일부 실시예에서, 인코딩 유닛은 복수의 특징 추출 레이어를 포함할 수 있고, 유사하게 디코딩 유닛은 또한 복 수의 특징 추출 레이어를 포함할 수 있다. 특징 추출 레이어는 컨볼루션 레이어 등을 포함할 수 있다. 일부 실시예에서, 인코딩 유닛의 적어도 하나의 특징 추출 레이어와 디코딩 유닛의 적어도 하나의 특징 추출 레 이어 사이에 스킵 연결이 구현된다. 생성된 M개의 속성 벡터는 상이한 해상도에 대응할 수 있다. 일부 실시예에서, 타깃 네트워크 모델은 오토인코더이다. S403: 타깃 네트워크 모델에서 융합 모듈을 사용하여, N개의 가상 아이덴티티 벡터 및 M개의 속성 벡터에 기반 한 이미지 생성을 수행하여 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득한다. 전술한 단계에 따르면, 생성된 N개의 가상 아이덴티티 벡터 및 M개의 속성 벡터를 융합 모듈에 입력하여, 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득한다. S403의 구현에는 다음 예가 포함되지만 이에 제한되지는 않는다. 예 1: N개의 가상 아이덴티티 벡터를 스플라이싱하고, M개의 속성 벡터를 스플라이싱하며, 스플라이싱된 가상 아이덴티티 벡터와 스플라이싱된 속성 벡터를 조합하여 융합 모듈에 입력한다.예를 들어, 스플라이싱된 가상 아이덴티티 벡터와 스플라이싱된 속성 벡터를 연쇄시켜 융합 모듈에 입력한다. 다른 예로, 스플라이싱된 가상 아이덴티티 벡터와 스플라이싱된 속성 벡터를 합하여 융합 모듈에 입력한다. 예 2: 융합 모듈은 복수의 상이한 해상도 레이어를 포함한다. 이 경우, N개의 가상 아이덴티티 벡터에 대응하는 해상도에 따라 N개의 가상 아이덴티티 벡터를 대응하는 해상도 레이어에 패턴으로 입력하고, M개의 속성 벡터를 대응하는 해상도 레이어에 노이즈로 입력하여, 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득할 수 있다. 일부 실시예에서, 융합 모듈은 StyleGAN2이다. 이 경우, 도 7에 도시된 바와 같이, AdaIN 레이어가 융합 모듈의 인접한 두 해상도 레이어 사이에 포함된다. 예를 들어, 아핀 변환은 제1 가상 아이덴티티 벡터 i+1에 대해 수행 되고; i번째 해상도 레이어에서 출력된 특징 정보와 속성 벡터 i가 조합된 다음 아핀 변환을 통해 획득된 가상 아이덴티티 벡터 i+1과 함께 AdaIN 레이어에 입력되며; AdaIN 연산이 수행되고, AdaIN 연산 결과가 (i+1)번째 해상도 레이어에 입력된다. 본 출원의 이 실시예에서 융합 모듈은 다르게는 적대적 모델, 예를 들어 StyleGAN3 또는 ProGAN일 수 있다. 일 부 실시예에서, 본 출원의 이 실시예에서의 아이덴티티 익명화 프로세스는, 제2 투사 유닛이 매핑 네트워크이고 속성 모듈이 오토인코더이며 융합 모듈이 StyleGAN2인 예를 사용하여 설명된다. 예를 들어, 도 13에 도시된 바와 같이, 샘플링을 투사 모듈의 제1 공간(Z)에 대해 수행하여, N개의 잠재적 아이 덴티티 벡터를 획득하며, 예를 들어 3개의 N 잠재적 아이덴티티 벡터를 획득하여, 3개의 N 잠재적 아이덴티티 벡터는 각각 2개의 상이한 해상도: 저해상도, 중간 해상도, 및 고해상도에 대응한다. 그런 다음, N개의 잠재적 아이덴티티 벡터가 매핑 네트워크에 입력되고, 매핑 네트워크는 N개의 잠재적 아이덴티티 벡터를 제1 공간(Z)에 서 제2 공간(W)으로 투사하여 N개의 가상 아이덴티티 벡터를 획득한다. 또한, 처리 대상 이미지 Xt가 오토인코 더에 입력되고, 오토인코더는 처리 대상 이미지 Xt를 처리하여 M개의 속성 벡터를 생성한다. 마지막으로, M개의 속성 벡터를 StyleGAN2의 레이어에 노이즈로 입력하고, N개의 가상 아이덴티티 벡터를 StyleGAN2의 레이어에 패 턴으로 입력하여, StyleGAN2에 의해 출력되는 처리 대상 이미지의 아이덴티티가 익명화된 이미지 Ys,t를 획득한 다. 본 출원의 이 실시예에서 제공되는 아이덴티티 익명화 방법에서, 타깃 네트워크 모델의 투사 모듈의 타깃 공간 에 대해 샘플링을 수행하여 N개의 가상 아이덴티티 벡터를 획득하고; 타깃 네트워크 모델의 속성 모듈을 사용하 여 처리 대상 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속성 벡터를 획득하며; 타깃 네트워크 모델의 융 합 모듈을 사용하여 N개의 가상 아이덴티티 벡터 및 M개의 속성 벡터에 기반한 이미지 생성을 수행하여 처리 대 상 이미지의 아이덴티티가 익명화된 이미지를 획득한다. 즉, 본 출원의 이 실시예에서 타깃 네트워크 모델은 독 립적인 가상 아이덴티티를 생성할 수 있으며, 처리 대상 이미지에 대한 아이덴티티 익명화 동안 처리 대상 이미 지에서 얼굴 영역을 제거할 필요가 없으며, 이에 따라 아이덴티티 익명화의 충실도를 향상시킨다. 전술한 내용은 도 3 내지 도 13을 참조하여 본 출원의 방법 실시예를 상세히 설명한다. 다음은 도 14 및 도 15 를 참조하여 본 출원의 디바이스 실시예를 상세히 설명한다. 도 14는 본 출원의 실시예에 따른 모델 트레이닝 장치의 개략적인 블록도이다. 트레이닝 장치는 컴퓨팅 디바이스 또는 컴퓨팅 디바이스의 일부일 수 있다. 도 14에 도시된 바와 같이, 모델 트레이닝 장치는: 타깃 네트워크 모델의 투사 모듈을 사용하여 제1 트레이닝 이미지를 타깃 공간에 투사하여 N개의 제1 가상 아이 덴티티 벡터를 획득하도록 구성된 투사 유닛 - N은 양의 정수임 -; 타깃 네트워크 모델의 속성 모듈을 사용하여 제2 트레이닝 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속 성 벡터를 획득하도록 구성된 속성 유닛 - M은 양의 정수임 -; 타깃 네트워크 모델의 융합 모듈을 사용하여 N개의 제1 가상 아이덴티티 벡터 및 M개의 속성 벡터에 기반한 이 미지 생성을 수행하여 제2 트레이닝 이미지의 아이덴티티가 익명화된 이미지를 획득하도록 구성된 융합 유닛 ; 및 아이덴티티가 익명화된 이미지에 따라 타깃 네트워크 모델의 손실을 결정하고, 손실에 따라 타깃 네트워크 모델 을 트레이닝하도록 구성된 트레이닝 유닛을 포함한다. 일부 실시예에서, 투사 모듈은 제1 투사 유닛 및 제2 투사 유닛을 포함하고, 타깃 공간은 제1 공간 및 제2 공간 을 포함하며, 투사 유닛은 추가로, 제1 트레이닝 이미지의 선험적 아이덴티티 정보를 추출하고; 제1 투사 유닛을 사용하여 선험적 아이덴티티 정보를 제1 공간에 투사하여, N개의 잠재적 아이덴티티 벡터를 획득하며;제2 투사 유닛을 사용하여 N개의 잠재적 아이덴티티 벡터를 제2 공간에 투사하여 N개의 제1 가상 아이덴티티 벡 터를 획득하도록 구성된다. 일부 실시예에서, 투사 유닛은 추가로, 제1 투사 유닛을 사용하여, 선험적 아이덴티티 정보를 제1 공간의 평균 및 분산으로서 투사하고; 제1 공간의 평균 및 분산에 기반하여 샘플링을 수행하여, N개의 잠재적 아이덴티 티 벡터를 획득하도록 구성된다. 일부 실시예에서, 트레이닝 유닛은 추가로, N개의 잠재적 아이덴티티 벡터의 발산 제약을 결정하고; 그리고 아이덴티티가 익명화된 이미지 및 발산 제약에 따라 타깃 네트워크 모델의 손실을 결정하도록 구성된다. 일부 실시예에서, N개의 제1 가상 아이덴티티 벡터는 각각 상이한 해상도에 대응한다. 일부 실시예에서, 제1 투사 유닛은 가변 오토인코더이다. 일부 실시예에서, 트레이닝 유닛은 추가로, 제3 트레이닝 이미지를 획득하고 - 제3 트레이닝 이미지 및 제1 트레이닝 이미지는 제1 타깃의 2개의 상이한 이미지임 -; 타깃 네트워크 모델의 투사 참조 모듈을 사용하여 제3 트레이닝 이미지를 타깃 공간에 투사하여 N개의 제2 가상 아이덴티티 벡터를 획득하며 - 투사 참조 모듈과 투사 모듈이 동일한 네트워크 구조를 가지며, 투사 모듈에 따라 업데이트됨 -; N개의 제1 가상 아이덴티티 벡터 및 N 개의 제2 가상 아이덴티티 벡터에 따라 아이덴티티 손실을 결정하고; 그리고 아이덴티티가 익명화된 이미지, 발 산 제약, 및 아이덴티티 손실에 따라 타깃 네트워크 모델의 손실을 결정하도록 구성된다. 일부 실시예에서, 트레이닝 유닛은 추가로, N개의 제2 가상 아이덴티티 벡터 중 i번째 제2 가상 아이덴티티 벡터에 대해, i번째 제2 가상 아이덴티티 벡터를 사용하여, i번째 동적 리스트에서 제1 타깃에 대응하는 가상 아이덴티티 벡터를 업데이트하고 - i번째 동적 리스트는 i번째 해상도에서 서로 다른 타깃의 가상 아이덴티티 벡터를 포함하며, i는 1 내지 N 범위의 양의 정수임 -; i번째 제1 가상 아이덴티티 벡터 및 업데이트된 i번째 동적 리스트에 따라, i번째 제1 가상 아이덴티티 벡터에 대응하는 아이덴티티 서브손실을 결정하며; N개의 제1 가상 아이덴티티 벡터에 각각 대응하는 아이덴티티 서브손실들의 합을 아이덴티티 손실로 결정하도록 구성된다. 일부 실시예에서, 트레이닝 유닛은 추가로, 제1 미리 설정된 값에 대한 i번째 제2 가상 아이덴티티 벡터의 제1 비율을 획득하고, 제1 비율에 i번째 제1 가상 아이덴티티 벡터를 곱하여 제1 결과를 획득하며, 제1 결과에 대해 대해 지수 연산을 수행하여 제1 연산 값을 획득하고; 업데이트된 i번째 동적 리스트에서 제1 미리 설정 값 에 대한 각각의 제2 가상 아이덴티티 벡터의 제2 비율을 획득하고, 각각의 제2 비율에 대해, 제2 비율에 대응하 는 i번째 제1 가상 아이덴티티 벡터를 곱하여 제2 결과를 획득하며, 제2 결과에 대해 지수 연산을 수행하여 각 각의 제2 가상 아이덴티티 벡터에 대응하는 제2 연산 값을 획득하며; 모든 제2 가상 아이덴티티 벡터에 대응하 는 제2 연산 값들의 합을 결정하고, 합에 대한 제1 연산 값의 제3 비율을 획득하며, 제3 비율에 대해 로그 연산 을 수행하여 제3 연산 값을 획득하고; 그리고 제3 연산 값의 음수를 i번째 제1 가상 아이덴티티 벡터에 대응하 는 아이덴티티 서브손실로 결정하도록 구성된다. 일부 실시예에서, 속성 모듈은 인코딩 유닛 및 디코딩 유닛을 포함하고, 속성 유닛은 추가로, 인코딩 유닛 을 사용하여 제2 트레이닝 이미지에 대해 특징 추출을 수행하여 제2 트레이닝 이미지를 획득하고; 그리고 디코 딩 유닛을 사용하여, 특징 정보를 디코딩하여 M개의 속성 벡터를 획득하도록 구성된다. 일부 실시예에서, 인코딩 유닛의 적어도 하나의 특징 추출 레이어와 디코딩 유닛의 적어도 하나의 특징 추출 레 이어 사이에 스킵 연결이 구현된다. 일부 실시예에서, 융합 모듈은 복수의 상이한 해상도 레이어를 포함하고, 융합 유닛은 추가로, N개의 제1 가상 아이덴티티 벡터에 대응하는 해상도에 따라 N개의 제1 가상 아이덴티티 벡터를 대응하는 해상도 레이어에 패턴으로 입력하고, M개의 속성 벡터를 대응하는 해상도 레이어에 노이즈로 입력하여 제2 트레이닝 이미지의 아 이덴티티가 익명화된 이미지를 획득하도록 구성된다. 일부 실시예에서, 트레이닝 유닛은 추가로, 아이덴티티가 익명화된 이미지와 제2 트레이닝 이미지 사이의 재구성 손실을 결정하고; 재구성 손실, 발산 제약, 및 아이덴티티 손실에 기반하여 타깃 네트워크 모델의 손실 을 결정하도록 구성된다. 일부 실시예에서, 트레이닝 유닛은 추가로, 아이덴티티가 익명화된 이미지와 제1 트레이닝 이미지 사이의 제1 거리, 아이덴티티가 익명화된 이미지와 제2 트레이닝 이미지 사이의 제2 거리, 및 제3 트레이닝 이미지와 제2 트레이닝 이미지 사이의 제3 거리를 결정하며; 제1 거리, 제2 거리, 및 제3 거리에 따라 콘트라스트 손실을 결정하고; 재구성 손실, 발산 제약, 아이덴티티 손실, 및 콘트라스트 손실에 기반하여 타깃 네트워크 모델의 손실을 결정하도록 구성된다. 일부 실시예에서, 트레이닝 유닛은 추가로, 제2 거리와 제3 거리 사이의 차이의 제곱과 제1 거리의 합을 결 정하고; 미리 설정된 값과 합 사이의 차이를 콘트라스트 손실로 결정하도록 구성된다. 일부 실시예에서, 융합 모듈이 적대적 네트워크인 경우, 트레이닝 유닛은 추가로: 아이덴티티가 익명화된 이미지 및 제1 트레이닝 이미지에 따라 적대적 손실을 결정하고; 그리고 재구성 손실과 발산 제약과 아이덴티티 손실과 콘트라스트 손실과 적대적 손실의 가중 합을 타깃 네트워크 모델의 손실로 결정하도록 구성된다. 디바이스 실시예 및 방법 실시예는 서로 대응하는 것으로 이해되어야 한다. 유사한 설명에 대해서는 방법 실시 예를 참조한다. 반복을 피하기 위해 세부 사항은 여기에서 다시 설명하지 않는다. 예를 들어, 도 14에 도시된 장치는 도 3에 도시된 모델 트레이닝 방법의 실시예를 수행할 수 있으며, 장치 내의 모듈의 전술한 작동 및/또 는 기능은 별도로 컴퓨팅 디바이스에 대응하는 방법 실시예를 구현하도록 의도된다. 간결함을 위해 세부 사항은 여기에서 다시 설명하지 않는다. 도 15는 본 출원의 일 실시예에 따른 아이덴티티 익명화 장치의 개략적인 블록도이다. 아이덴티티 익명화 장치 는 컴퓨팅 디바이스 또는 컴퓨팅 디바이스의 일부일 수 있다. 도 15에 도시된 바와 같이, 아이덴티티 익명 화 장치는: 타깃 네트워크 모델의 투사 모듈의 타깃 공간에 대한 샘플링을 수행하여 N개의 가상 아이덴티티 벡터를 획득하 도록 구성된 샘플링 유닛 - N은 양의 정수임 -; 타깃 네트워크 모델의 속성 모듈을 사용하여 처리 대상 이미지에 대해 속성 벡터 추출을 수행하여 M개의 속성 벡터를 획득하도록 구성된 속성 유닛 - M은 양의 정수임 -; 및 타깃 네트워크 모델의 융합 모듈을 사용하여 N개의 가상 아이덴티티 벡터 및 M개의 속성 벡터에 기반한 이미지 생성을 수행하여 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득하도록 구성된 익명화 유닛을 포 함한다. 일부 실시예에서, 타깃 공간은 제1 공간 및 제2 공간을 포함하고, 타깃 네트워크 모델은 제2 투사 유닛을 포함 하며, 샘플링 유닛은 추가로, 제1 공간에 대해 샘플링을 수행하여 N개의 잠재적 아이덴티티 벡터를 획득하 고; 제2 투사 유닛을 사용하여 N개의 잠재적 아이덴티티 벡터를 제2 공간에 투사하여 N개의 가상 아이덴티티 벡 터를 획득하도록 구성된다. 일부 실시예에서, 제1 공간의 평균 및 분산은 표준 가우시안 분포를 만족하고, 샘플링 유닛은 추가로, 제1 공간의 평균 및 분산에 기반하여 샘플링을 수행하여, N개의 잠재적 아이덴티티 벡터를 획득하도록 구성된다. 일부 실시예에서, N개의 가상 아이덴티티 벡터는 각각 상이한 해상도에 대응한다. 일부 실시예에서, 속성 모듈은 인코딩 유닛 및 디코딩 유닛을 포함하고, 속성 유닛은 추가로, 인코딩 유닛 을 사용하여 처리 대상 이미지에 대해 특징 추출을 수행하여 처리 대상 이미지의 특징 정보를 획득하며, 디코딩 유닛을 사용하여 특징 정보를 디코딩하여 M개의 속성 벡터를 획득하도록 구성된다. 일부 실시예에서, 인코딩 유닛의 적어도 하나의 특징 추출 레이어와 디코딩 유닛의 적어도 하나의 특징 추출 레 이어 사이에 스킵 연결이 구현된다. 일부 실시예에서, 융합 모듈은 복수의 상이한 해상도 레이어를 포함하고, 익명화 유닛은 추가로, N개의 가 상 아이덴티티 벡터에 대응하는 해상도에 따라 N개의 가상 아이덴티티 벡터를 대응하는 해상도 레이어에 패턴으 로 입력하고, M 속성 벡터를 대응하는 해상도 레이어에 노이즈로 입력하여, 처리 대상 이미지의 아이덴티티가 익명화된 이미지를 획득하도록 구성된다. 디바이스 실시예 및 방법 실시예는 서로 대응하는 것으로 이해되어야 한다. 유사한 설명에 대해서는 방법 실시 예를 참조한다. 반복을 피하기 위해 세부 사항은 여기에서 다시 설명하지 않는다. 예를 들어, 도 15에 도시된 장치는 도 11에 도시된 아이덴티티 익명화 방법의 실시예를 수행할 수 있으며, 장치 내의 모듈의 전술한 작동 및/또는 기능은 별도로 컴퓨팅 디바이스에 대응하는 방법 실시예를 구현하도록 의도된다. 간결함을 위해 세부 사항은 여기에서 다시 설명하지 않는다. 전술한 내용은 첨부된 도면을 참조하여 기능 모듈의 관점에서 본 출원의 실시예의 장치를 설명한다. 기능 모듈 은 하드웨어 형태로 구현될 수도 있고, 명령어에 의해 소프트웨어 형태로 구현될 수도 있으며, 하드웨어와 소프트웨어 모듈의 조합으로 구현될 수도 있다. 예를 들어, 본 출원의 실시예에서 방법 실시예의 단계는 프로세서의 집적 논리 회로 및/또는 소프트웨어 형태의 명령어에 의해 수행될 수 있으며, 본 출원의 실시예를 참조하여 개 시된 방법의 단계는 하드웨어 디코딩 프로세서에 의해 직접 수행될 수 있거나, 디코딩 프로세서에서 하드웨어 및 소프트웨어 모듈의 조합에 의해 수행될 수 있다. 선택적으로, 소프트웨어 모듈은 랜덤 액세스 메모리, 플래 시 메모리, 읽기 전용 메모리, 프로그램 가능 읽기 전용 메모리, 전기적으로 소거 가능한 프로그램 가능 메모리 및 레지스터와 같은 당업계의 성숙한 저장 매체에 위치될 수 있다. 저장 매체는 메모리에 위치된다. 프로세서는 메모리의 정보를 판독하고 하드웨어와 조합하여 전술한 방법 실시예의 단계를 완료한다. 도 16은 본 출원의 실시예에 따른 컴퓨팅 디바이스의 개략적인 블록도이다. 컴퓨팅 디바이스는 전술한 방법 실 시예를 수행하도록 구성된다. 도 16에 도시된 바와 같이, 컴퓨팅 디바이스는: 메모리 및 프로세서를 포함할 수 있으며, 메모리는 컴퓨터 프로그램을 저장하고 프로그램 코드 를 프로세서에 전송하도록 구성된다. 달리 말하면, 프로세서는 메모리로부터 컴퓨터 프로그램 을 호출하고 컴퓨터 프로그램을 실행하여 본 출원의 실시예의 방법을 구현할 수 있다. 예를 들어, 프로세서는 컴퓨터 프로그램의 명령어에 따라 전술한 방법 단계를 수행하도록 구성될 수 있 다. 본 출원의 일부 실시예에서, 프로세서는: 일반 프로세서, 디지털 신호 프로세서(Digital Signal Processing, DSP), 애플리케이션 특정 집적 회로 (Application Specific Integrated Circuit, ASIC), 필드 프로그램 가능 게이트 어레이(Field Programmable Gate Array, FPGA), 다른 프로그램 가능 로직 디바이스, 이산 게이트, 트랜지스터 로직 디바이스 또는 이산 하 드웨어 컴포넌트를 포함할 수 있지만 이에 제한되지는 않는다. 일부 실시예에서, 저장 모듈은: 비휘발성 및/또는 휘발성 메모리를 포함하지만 이에 제한되지 않는다. 비휘발성 메모리는 읽기 전용 메모리 (read-only memory, ROM), 프로그램 가능 읽기 전용 메모리(programmable read-only memory, PROM), 소거 가능 한 프로그램 가능 읽기 전용 메모리(erasable programmable read-only memory, EPROM), 전기적으로 소거 가능 한 프로그램 가능 읽기 전용 메모리(electrically erasable programmable read-only memory, EEPROM) 또는 플 래시 메모리일 수 있다. 휘발성 메모리는 외부 캐시로 사용되는 랜덤 액세스 메모리(random access memory, RAM)일 수 있다. 예를 들어, 제한적이지 않은 설명을 통해, 예를 들어 정적 랜덤 액세스 메모리(static RAM, SRAM), 동적 랜덤 액세스 메모리(dynamic RAM, DRAM), 동기식 동적 랜덤 액세스 메모리(synchronous DRAM, SDRAM), 더블 데이터 레이트 동기 동적 랜덤 액세스 메모리(double data rate SDRAM, DDR SDRAM), 향상된 동기 동적 랜덤 액세스 메모리(enhanced SDRAM, ESDRAM), 동기 링크 동적 랜덤 액세스 메모리(synchlink DRAM, SLDRAM) 및 다이렉트 램버스 동적 랜덤 액세스 메모리(direct rambus RAM, DR RAM)와 같은 많은 형태의 RAM이 사용될 수 있다. 본 출원의 일부 실시예에서, 컴퓨터 프로그램은 하나 이상의 모듈로 분할될 수 있고, 하나 이상의 모듈은 메모리에 저장되고 프로세서에 의해 실행되어 본 출원에서 제공된 페이지 기록 방법을 수행한다. 하나 이상의 모듈은 특정 기능을 수행할 수 있는 일련의 컴퓨터 프로그램 명령어 세그먼트일 수 있고, 명령어 세그먼 트는 컴퓨팅 디바이스에서 컴퓨터 프로그램의 실행 프로세스를 설명하는 데 사용된다. 도 16에 도시된 바와 같이, 컴퓨팅 디바이스는: 트랜시버를 더 포함할 수 있으며, 트랜시버는 프로세서 또는 메모리에 연결될 수 있다. 프로세서는 트랜시버가 다른 디바이스와 통신하도록 제어할 수 있다. 예를 들어, 정보 또는 데이터가 다른 디바이스로 송신되거나 다른 디바이스에 의해 송신된 정보 또는 데이터를 수신할 수 있다. 트랜시버는 송신기 및 수신기를 포함할 수 있다. 트랜시버는 안테나를 더 포함할 수 있고, 안테나의 수량은 하나 이상 일 수 있다. 컴퓨터 디바이스의 다양한 컴포넌트는 버스 시스템을 사용하여 서로 연결된다. 데이터 버스를 포함하는 것 외에도 버스 시스템은 전원 버스, 제어 버스 및 상태 신호 버스를 더 포함한다. 본 출원의 실시예는 컴퓨터 저장 매체를 제공하고, 여기서 컴퓨터 저장 매체는 컴퓨터 프로그램을 저장하며, 컴 퓨터 프로그램이 컴퓨터에 의해 실행될 때, 전술한 실시예 중 어느 하나의 방법이 컴퓨터에 의해 구현되며, 또는, 명령어를 포함하는 컴퓨터 프로그램 제품이 본 출원의 실시예에서 추가로 제공된다. 명령어가 컴퓨터 상에 서 실행될 때, 컴퓨터는 전술한 방법 실시예에서 제공된 방법을 수행하게 된다. 본 출원의 실시예의 측면에 따르면, 컴퓨터 프로그램 제품 또는 컴퓨터 프로그램이 제공되고, 컴퓨터 프로그램 제품 또는 컴퓨터 프로그램은 컴퓨터 명령어를 포함하고, 컴퓨터 명령어는 컴퓨터가 판독 가능한 저장 매체에 저장된다. 컴퓨터 디바이스의 프로세서는 컴퓨터가 판독 가능한 저장 매체로부터 컴퓨터 명령어를 판독한다. 프 로세서는 컴퓨터 명령어를 실행하므로, 컴퓨터 디바이스가 전술한 다양한 방법 실시예의 방법을 수행한다. 전술한 설명은 단지 본 출원의 특정 구현일 뿐이지, 본 출원의 보호 범위를 제한하도록 의도된 것은 아니다. 본 출원에 개시된 기술적 범위 내에서 당업자에 의해 용이하게 파악된 변형 또는 대체는 본 출원의 보호 범위에 속 할 것이다. 따라서 본 출원의 보호 범위는 청구 범위의 보호 범위에 따른다."}
{"patent_id": "10-2022-7038590", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 출원의 실시예에 따른 실제 이미지의 개략도이다. 도 1b 내지 도 1d는 본 출원의 실시예에 따른 도 1a에 대응하는 아이덴티티가 익명화된 이미지의 개략도이다. 도 2는 본 출원의 실시예에 따른 시스템 아키텍처의 개략도이다. 도 3은 본 출원의 실시예에 따른 모델 트레이닝 방법의 개략적인 흐름도이다. 도 4 내지 도 6은 본 출원의 실시예에 따른 타깃 네트워크 모델의 개략적인 구조도이다. 도 7은 본 출원의 실시예에 따른 융합 모듈의 개략적인 구조도이다. 도 8은 본 출원의 실시예에 따른 타깃 네트워크 모델의 개략적인 구조도이다. 도 9 및 도 10은 본 출원의 실시예에 따른 콘트라스트 손실을 결정하는 개략도이다. 도 11은 본 출원의 실시예에 따른 아이덴티티 익명화 방법의 개략적인 흐름도이다. 도 12는 본 출원의 실시예에 따른 투사 모듈의 개략도이다. 도 13은 본 출원의 실시예에 따른 아이덴티티가 익명화된 이미지를 결정하는 개략도이다. 도 14는 본 출원의 실시예에 따른 모델 트레이닝 장치의 개략적인 블록도이다. 도 15는 본 출원의 실시예에 따른 아이덴티티 익명화 장치의 개략적인 블록도이다. 도 16은 본 출원의 실시예에 따른 컴퓨팅 디바이스의 개략적인 블록도이다."}
