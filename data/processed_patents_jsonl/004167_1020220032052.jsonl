{"patent_id": "10-2022-0032052", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0134812", "출원번호": "10-2022-0032052", "발명의 명칭": "감시제어 기반 강화 학습을 이용한 공정 스케줄링 시스템 및 방법", "출원인": "한국과학기술원", "발명자": "이태억"}}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "공정 장비의 상태 정보 및 행동 제약 정보에 기초하여 상기 공정 장비가 수행 가능한 행동 집합을 생성하는 제어부; 및상기 행동 집합 및 상기 상태 정보에 기초하여 상기 공정 장비의 최적 행동을 추출하는 과정을 학습하는 학습부를 포함하는 강화 학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서상기 상태 정보를 포함하는 플랜트 모델 및 상기 행동 제약 정보를 포함하는 행동 제약 모델을 생성하는 모델링부를 더 포함하는 강화 학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 모델링부는 상기 플랜트 모델 및 상기 행동 제약 모델에 기초하여 방향성 그래프 모델을 생성하고, 상기 방향성 그래프 모델은 상기 공정 장비의 상태를 각각을 나타내는 복수의 노드 및 상기 공정 장비의 행동에기초한 상기 복수의 노드 간의 연결 관계를 나타내는 엣지를 포함하는 강화 학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제어부는, 상기 방향성 그래프 모델에 기초하여 상기 복수의 노드 중에서 데드락 노드 및 상기 공정 장비의 현재 상태로부터 접근 불가능한 노드 중 적어도 어느 하나를 제거하여 상기 행동 집합을 생성하는 강화 학습을 이용한 공정스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 모델링부는 유한 상태 머신(Finite State Machine, FSM) 모델에 기초하여 상기 플랜트 모델을 생성하는 강화 학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 공정 장비는 적어도 하나의 서브 모듈을 포함하고, 상기 모델링부는 상기 서브 모듈에 기초한 적어도 하나의 서브 모델을 생성하고, 상기 서브 모델을 포함하는 상기 플랜트 모델을 생성하는 강화 학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 서브 모듈은 진공 이송 모듈(Vacuum Transport Module, VTM), 대기 이송 모듈(Atmosphere TransportModule, ATM), 로드락 모듈(Load Lock Module), 프로세싱 모듈(Processing Module, PM), 정렬 모듈(Allign공개특허 10-2023-0134812-3-Module), 냉각 모듈(Cooling Module) 및 로드 포트 모듈(Load Port Module) 중 적어도 하나를 포함하는 강화학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 학습부가 추출한 최적 행동에 기초하여 상기 공정 장비를 시뮬레이션하는 시뮬레이터를 더 포함하고, 상기 학습부는 상기 시뮬레이션 결과에 기초하여 학습하는 강화 학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 시뮬레이터는,상기 공정 장비의 상기 행동 수행 시간을 계산하고, 상기 행동 수행 시간에 기초하여 시뮬레이션을 수행하는 강화 학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 상태 정보는 웨이퍼 로드 정보, 클리닝 주기 정보 및 로드락(Load Lock) 정보 중 적어도 하나를 포함하는강화 학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 학습부는 추출한 행동에 기초하여 보상을 설정하고, 상기 보상에 기초하여 상기 공정 장비의 사이클 타임(cycle time)을 최소화하도록 학습하는 강화 학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 행동 제약 정보는 이상 사건 제약 정보를 포함하고,상기 이상 사건 제약 정보는 상기 공정 장비의 예방 정비(Preventive Maintenance) 정보를 포함하는 강화 학습을 이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 제어부는 상기 이상 사건 제약 정보에 기초하여 복수의 행동 집합을 생성하고, 데드락 발생 가능성 및 상기 공정 장비의 사이클 타임에 기초하여 상기 복수의 행동 집합 중 최적의 행동 집합을 선택하는 강화 학습을이용한 공정 스케줄링 시스템."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공정 장비의 상태 정보 및 행동 제약 정보에 기초하여 상기 공정 장비가 수행 가능한 행동 집합을 생성하는 단계; 및상기 행동 집합 및 상기 상태 정보에 기초하여 상기 공정 장비의 최적 행동을 추출하는 과정을 학습하는 단계를포함하는 강화 학습을 이용한 공정 스케줄링 방법."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 상태 정보를 포함하는 플랜트 모델 및 상기 행동 제약 정보를 포함하는 행동 제약 모델을 생성하는 단계를공개특허 10-2023-0134812-4-더 포함하는 강화 학습을 이용한 공정 스케줄링 방법."}
{"patent_id": "10-2022-0032052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 공정 장비의 최적 행동을 추출하는 과정을 학습하는 단계에서 추출한 상기 최적 행동에 기초하여 상기 공정 장비를 시뮬레이션하는 단계를 더 포함하고, 상기 공정 장비의 최적 행동을 추출하는 과정을 학습하는 단계는, 상기 시뮬레이션 결과에 기초하여 학습하는강화 학습을 이용한 공정 스케줄링 방법."}
{"patent_id": "10-2022-0032052", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 문서에 개시되는 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 공정 장비의 상태 정보 및 행동 제약 정보에 기초하여 상기 공정 장비가 수행 가능한 행동 집합을 생성하는 제어부; 및 상기 행동 집합 및 상기 상태 정보에 기초하여 상기 공정 장비의 최적 행동을 추출하는 과정을 학습하는 학습부를 포함할 수 있다."}
{"patent_id": "10-2022-0032052", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 문서에 개시된 실시예들은 강화 학습을 이용한 공정 스케줄링 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0032052", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "클러스터 장비는 반도체 제조 공정에 사용되는 장비로 반도체 생산 장비의 70~80%를 차지하고 있다. 클러스터 장비의 스케줄링은 장비 내 모듈들의 작업 순서 및 시점을 결정하는 문제로, 공정 과정에서 모듈들의 작업 순서 및 시점에 따라 생산 시간의 변동 및 생산 효율이 달라지며 웨이퍼 품질이 달라질 수 있다. 일반적인 공정 스케줄링에는 시행착오(Trial and Error)에 기반하여 공정선택규칙(Dispatching Rule)을 결정하 는 방식을 사용하였다. 하지만, 최근 기계학습과 딥러닝의 발달로 공정 스케줄링 과정에서도 기계학을 이용하고 자 하는 시도가 있었으며, 다양한 환경에 적응할 수 있도록 강화 학습(Reinforcement learning)을 이용하고자 하는 시도가 있었다."}
{"patent_id": "10-2022-0032052", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일반적으로 공정의 스케줄링은 클러스터 장비의 구조, 제약 조건 등을 고려하여 시행착오 방식을 통해 개발하는 것이 일반적이었다. 하지만. 시행착오에 기반한 스케줄링의 경우, 다수의 시험이 필요하여 긴 기간이 소요될 뿐 아니라, 제약 조건 또는 환경이 변화할 때마다 매번 새로운 시행착오를 겪어야 한다는 문제점이 있었다. 또한, 공정 스케줄링을 시행착오로 결정하는 경우, 논리적 제어 오류가 발생할 가능성이 있었다. 논리적 제어 오류로 인해 장비의 데드락이 발생한 경우, 일시적으로 장비의 이용이 불가능해지며, 데드락으로부터 탈출하는 제어(예를 들어, 공정 중이던 웨이퍼를 외부로 인출한 뒤 다른 장치로 이송하는 제어)가 추가적으로 필요하여 스케줄링 방법 개발 기간을 증가시키는 문제가 있었다. 또한, 공정 과정에서 발생할 수 있는 다양한 제약 사항 및 상태를 고려하여 스케줄링하기 어렵다는 문제가 있었 다."}
{"patent_id": "10-2022-0032052", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 문서에 개시되는 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 공정 장비의 상태 정보 및 행동 제약 정보에 기초하여 상기 공정 장비가 수행 가능한 행동 집합을 생성하는 제어부; 및 상기 행동 집합 및 상기 상태 정보에 기초하여 상기 공정 장비의 최적 행동을 추출하는 과정을 학습하는 학습부를 포함할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 상태 정보를 포함하는 플랜트 모델 및 상 기 행동 제약 정보를 포함하는 행동 제약 모델을 생성하는 모델링부를 더 포함할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 모델링부는 상기 플랜트 모델 및 상기 행 동 제약 모델에 기초하여 방향성 그래프 모델을 생성하고, 상기 방향성 그래프 모델은 상기 공정 장비의 각 상 태를 나타내는 복수의 노드 및 상기 공정 장비의 행동에 기초한 상기 노드 간의 연결 관계를 나타내는 엣지를 포함할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 제어부는, 상기 방향성 그래프 모델에 기 초하여 데드락 노드 및 상기 공정 장비의 현재 상태로부터 접근 불가능한 노드 중 적어도 어느 하나를 제거하여 상기 행동 집합을 생성할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 모델링부는 유한 상태 머신(Finite State Machine, FSM) 모델에 기초하여 상기 플랜트 모델을 생성할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 공정 장비는 적어도 하나의 서브 모듈을 포함하고, 상기 모델링부는 상기 서브 모듈에 기초한 적어도 하나의 서브 모델을 생성하고, 상기 서브 모델을 포함하는 상기 플랜트 모델을 생성할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 서브 모듈은 진공 이송 모듈(Vacuum Transport Module, VTM), 대기 이송 모듈(Atmosphere Transport Module, ATM), 로드락 모듈(Load Lock Module), 프로세싱 모듈(Processing Module, PM), 정렬 모듈(Allign Module), 냉각 모듈(Cooling Module) 및 로드 포트 모듈(Load Port Module) 중 적어도 하나를 포함할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 학습부가 추출한 행동에 기초하여 상기 공 정 장비를 시뮬레이션하는 시뮬레이터를 더 포함하고, 상기 학습부는 상기 시뮬레이션 결과에 기초하여 학습할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 시뮬레이터는, 상기 공정 장비의 상기 행 동 수행 시간을 계산하고, 상기 행동 수행 시간에 기초하여 시뮬레이션을 수행할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 상태 정보는 웨이퍼 로드 정보, 클리닝 주 기 정보 및 로드락(Load Lock) 정보 중 적어도 하나를 포함할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 학습부는 추출한 행동에 기초하여 보상을 설정하고, 상기 보상에 기초하여 상기 공정 장비의 사이클 타임(cycle time)을 최소화하도록 학습할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 행동 제약 정보는 이상 사건 제약 정보를 포함하고, 상기 이상 사건 제약 정보는 상기 공정 장비의 예방 정비(Preventive Maintenance) 정보를 포함할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은, 상기 제어부는 상기 이상 사건 제약 정보에 기 초하여 복수의 행동 집합을 생성하고, 데드락 발생 가능성 및 상기 공정 장비의 사이클 타임에 기초하여 상기 복수의 행동 집합 중 최적의 행동 집합을 선택할 수 있다. 본 문서에 개시되는 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 방법은, 공정 장비의 상태 정보 및 행 동 제약 정보에 기초하여 상기 공정 장비가 수행 가능한 행동 집합을 생성하는 단계; 및 상기 행동 집합 및 상 기 상태 정보에 기초하여 상기 공정 장비의 최적 행동을 추출하는 과정을 학습하는 단계를 포함할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 방법은, 상기 상태 정보를 포함하는 플랜트 모델 및 상기 행동 제약 정보를 포함하는 행동 제약 모델을 생성하는 단계를 더 포함할 수 있다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 방법은, 상기 공정 장비의 최적 행동을 추출하는 과정을 학습하는 단계에서 추출한 상기 최적 행동에 기초하여 상기 공정 장비를 시뮬레이션하는 단계를 더 포함하고, 상기 공정 장비의 최적 행동을 추출하는 과정을 학습하는 단계는, 상기 시뮬레이션 결과에 기초하여 학습할 수 있다."}
{"patent_id": "10-2022-0032052", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 문서에 개시되는 실시예들에 따른 강화 학습을 이용한 공정 스케줄링 시스템은 공정 과정에서 논리적 오류를 일으키지 않는 제어 동작만을 수행하도록 알고리즘을 구성하여 학습의 속도 및 성능을 향상시킬 수 있다. 본 문서에 개시되는 실시예들에 따른 강화 학습을 이용한 공정 스케줄링 시스템은 일반적인 시행착오 기반의 스 케줄링 개발에 비해 스케줄링 개발까지의 소요 시간을 획기적으로 줄일 수 있다. 본 문서에 개시되는 실시예들에 따른 강화 학습을 이용한 공정 스케줄링 시스템은 강화 학습을 이용하여 스케줄 링 방법을 개발함으로써 장비의 구조, 제약 등이 변경되는 경우에도 그에 대응하여 빠르게 새로운 최적 스케줄 링 방법을 도출할 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2022-0032052", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 발명을 특정한 실시 형 태에 대해 한정하려는 것이 아니며, 본 발명의 실시 예의 다양한 변경(modification), 균등물(equivalent), 및/ 또는 대체물(alternative)을 포함하는 것으로 이해되어야 한다. 본 문서에서 아이템에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이 템 한 개 또는 복수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\",“A 또는 B 중 적어도 하나”, \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나” 및 “A, B, 또는 C 중 적어도 하나\"와 같은 문구 들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제 1\", \"제 2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하 지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제 2) 구성요소에, “기능적으로” 또는 “통신적으로”라는 용어와 함께 또는 이런 용어 없이, “커플드” 또는 “커넥티드”라고 언급된 경우, 그것은 상기 어떤 구성요소 가 상기 다른 구성요소에 직접적으로(예: 유선으로), 무선으로, 또는 제 3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서에서 설명되는 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함 할 수 있다. 다양한 실시 예들에 따르면, 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거 나, 또는 하나 이상의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구 성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따르면, 모듈, 프로그 램 또는 다른 구성요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실 행되거나, 상기 동작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이추가될 수 있다. 본 문서에서 사용되는 용어 \"모듈\", 또는 “...부”는 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함 할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부 가 될 수 있다. 예를 들면, 일 실시 예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형태로 구현될 수 있다. 본 문서의 다양한 실시 예들은 기기(machine) 의해 읽을 수 있는 저장 매체(storage medium)(예: 메모리)에 저 장된 하나 이상의 명령어들을 포함하는 소프트웨어(예: 프로그램 또는 애플리케이션)로서 구현될 수 있다. 예를 들면, 기기의 프로세서는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하 도록 운영되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리 터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non- transitory) 저장 매체의 형태로 제공될 수 있다. 여기서,‘비일시적’은 저장 매체가 실재(tangible)하는 장치 이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 도 1은 본 문서에 개시된 일 실시예에 따른 강화 학습을 이용한 공정 스케줄링 시스템을 보여주는 도면이다. 도 1을 참조하면, 강화 학습을 이용한 공정 스케줄링 시스템은 제어부 및 학습부를 포함할 수 있 다. 실시예에 따르면, 강화 학습을 이용한 공정 스케줄링 시스템은 공정 장비를 스케줄링 할 수 있다. 실시예에 따르면, 공정 장비는 반도체 공정 과정에서 웨이퍼의 이송 또는 가공이 이루어지는 클러스터 장비 를 포함할 수 있다. 클러스터 장비는 웨이퍼의 공정이 이루어지는 프로세싱 모듈(Process Module, PM)과 연결되 어, EFEM(Equipement Front End Module)내의 웨이퍼를 프로세싱 모듈로 이송 및/또는 반송하는 역할을 수행할 수 있다. 예를 들어, 반도체 디바이스들의 제작 시, 프로세싱 모듈 및 진공 이송 모듈(Vacuum Transport Module, VTM)을 갖는 클러스터 장비가 프로세싱 모듈들 사이에서 웨이퍼를 이송하기 위해 사용될 수 있다. 클러스터 장비는 일반적으로 다양한 프로세싱 모듈들에 대해 목표된 압력들과 매칭하도록 진공 조건에서 동작 할 수 있다. 웨이퍼는 대기 이송 모듈(Atmospheric Transfport Module, ATM)을 포함할 수 있는 EFEM(Equipment Front End Module)을 통해 대기로부터 클러스터 장비 내로 이송될 수 있다. 클러스터 장비의 EFEM 및 진공 이송 모듈은 클러스터 장비 내외로 기판이 이송되는 동안 EFEM 또는 진공 이송 모듈의 압력을 유지하는, 로드 락 모듈(Load Lock Module)에 의해 분리될 수 있다. 로드락 모듈은 웨이퍼가 진공 이송 모듈로 이송되기 전에 진공으로 순환적으로 펌핑(pumping)할 수 있고, EFEM으로 이송되기 전에 대기로 벤팅(Venting)할 수 있다. 실시예에 따르면, 클러스터 장비는 적어도 하나의 서브 모듈을 포함할 수 있고, 서브 모듈은 진공 이송 모듈 (Vacuum Transport Module, VTM), 대기 이송 모듈(Atmosphere Transport Module, ATM), 로드락 모듈(Load Lock Module), 프로세싱 모듈(Processing Module, PM), 정렬 모듈(Allign Module), 냉각 모듈(Cooling Module) 및 로드 포트 모듈(Load Port Module) 중 적어도 하나를 포함할 수 있다. 이 외에도 웨이퍼 공정 수행에 사용되는 다양한 서브 모듈이 포함될 수 있다. 이 때, 로드 포트 모듈은 EFEM 내에서 웨이퍼 랏(Lot)을 삽입 및 보관하는 역할을 수행할 수 있고, 정렬 모듈은 EFEM 내에서 웨이퍼의 정렬을 수행할 수 있으며, 냉각 모듈은 프로세싱 모 듈에서 작업이 끝난 웨이퍼를 냉각하는 역할을 수행할 수 있다. 실시예에 따르면, 공정 스케줄링 시스템은 공정 장비(예를 들어, 클러스터 장비)에 포함되어 일 구성으 로서 공정 장비를 스케줄링할 수 있고, 공정 장비 외부에서 공정 장비와 유선 또는 무선으로 통신하여 공정 장비를 스케줄링 할 수도 있다. 실시예에 따르면, 제어부는 공정 장비의 상태 정보 및 행동 제약 정보에 기초하여 공정 장비가 수 행 가능한 행동 집합을 생성할 수 있다. 제어부는 공정 장비의 동작을 선택할 시점마다 행동 집합을 생성할 수 있다. 실시예에 따르면, 공정 장비의 상태 정보는 웨이퍼 로드 정보, 클리닝 주기 정보 및 로드락(Load Lock) 정 보 중 적어도 하나를 포함할 수 있으며, 이 외에도 웨이퍼 혼류 생산 정보, 공정 시간 정보 등 공정 장비와관련된 다양한 상태 정보를 포함할 수 있다. 예를 들어, 클리닝 주기 정보는 프로세싱 모듈이 몇 개의 웨이퍼를 생산할 때마다 클리닝할 것인지에 대한 정보를 포함할 수 있고, 로드락 정보는 로드락이 벤팅 상태인지 펌핑 상 태인지에 대한 정보를 포함할 수 있으며, 프로세싱 모듈의 로드 정보는 각 프로세싱 모듈에 웨이퍼가 로드 되어 있는지 여부에 대한 정보를 포함할 수 있다. 실시예에 따르면, 행동 제약 정보는 공정 장비의 공정 과정에서 제약이 발생할 수 있는 정보를 포함할 수 있다. 예를 들어, 프로세싱 모듈 중 A 프로세싱 모듈에 웨이퍼가 이미 로드 되어 있는 경우, 공정 장비는 현재 상태에서 A 프로세싱 모듈에 웨이퍼를 더 이상 로드할 수 없는 제약이 발생할 수 있다. 또한, 현재 상태에 서 모든 프로세싱 모듈이 언로드 즉, 비어 있는 상태이더라도, 로드락에서 웨이퍼가 이송을 위해 펌핑 중인 상 태라면 공정 장비는 프로세싱 모듈에 웨이퍼를 로드할 수 없는 제약이 발생할 수 있다. 실시예에 따르면, 행동 제약 정보는 이상 사건 제약 정보를 포함할 수 있다. 예를 들어, 이상 사건 제약 정보는 공정 장비의 예방 정비(Preventive Maintenance) 정보를 포함할 수 있다. 예를 들어, 예방 정비(Preventive Maintenance) 정보는 특정 프로세싱 모듈이 다운되었는지 여부에 대한 정보를 포함할 수 있고, 이 경우 다운된 프로세싱 모듈을 이용할 수 없다는 행동 제약이 발생할 수 있다. 실시예에 따르면, 제어부는 공정 장비의 상태 정보 및 행동 제약 정보에 기초하여 공정 장비가 수 행 가능한 행동 집합을 생성할 수 있다. 공정 장비는 스케줄링 과정에서 현재 상태에서 다양한 행동 예를 들어, 로드락 벤팅, 프로세싱 모듈 로딩 등의 행동을 선택할 수 있다. 제어부는 위와 같이 현재 상태에서 공정 장비가 수행 가능한 행동들을 판단하여 행동 집합을 생성할 수 있다. 실시예에 따르면, 학습부는 행동 집합 및 상태 정보에 기초하여 공정 장비의 최적 행동을 추출하는 과 정을 학습할 수 있다. 이 때, 학습부가 추출한 최적 행동의 집합이 공정 장비의 스케줄링을 구성할 수 있다. 실시예에 따르면, 학습부는 적어도 하나의 인공지능 신경망을 포함할 수 있다. 인공지능 신경망은 강화 학 습을 위한 신경망일 수 있다. 예를 들어, 인공지능 신경망은 CNN(Convolutional Neural Network), R- CNN(Region with Convolutional Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restricted Boltzman Machine), FCN(Fully Convolutional Network), LSTM(Long Short-Term Memory) Network, FPN(Feature Pyramid Network), SPP(Spatial Pyramid Pooling), GAN(Generative Adeversarial Network) 등 다양한 종류의 인공지능 모델을 포 함할 수 있으며, 전술한 모델로 제한되는 것은 아니다. 실시예에 따르면, 학습부는 복수의 인공지능 신경망을 포함할 수 있고, 복수의 인공지능 신경망 각각이 서 로 다른 서브 모듈에서의 학습을 담당할 수 있다. 복수의 인공지능 신경망의 학습 결과는 공정 장비의 상태 에 합산되어 반영될 수 있다. 실시예에 따르면, 학습부는 강화 학습을 이용하여 학습을 수행할 수 있다. 강화 학습이란 행동을 취하는 주체인 에이전트(Agent)가 환경에 반응해서 행동하는 학습 기법으로, 다변적인 환경에 맞추어 적응할 수 있다는 장점이 있다. 실시예에 따르면, 학습부는 학습 과정에서 행동에 따른 보상(reward)를 설정하고 보상에 기 초하여 공정 장비의 사이클 타임(Cycle time)을 최소화하도록 학습할 수 있다. 실시예에 따르면, 학습부는 보상 및 누적 보상을 각각"}
{"patent_id": "10-2022-0032052", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "로 설정할 수 있다. 여기서, 는 특정 행동에 따른 보상, 는 누적 보상, 는 감가율, 는 특정 행동을 선택했을 때 소모되는 시간을 의미할 수 있다. 또한, 프로세싱 모 듈을 모듈(i,j)로 표기할 때, i는 몇 번째 공정에 해당하는지, j는 해당 공정 과정에서 몇 번째 프로세싱 모듈 인지를 나타낼 수 있다. 이 때, 는 프로세싱 모듈(i,j)의 워크로드 값을 의미할 수 있으며, 워크로드 값은 웨이퍼 1장 생상하는데 걸리는 이론적 최소 시간을 의미할 수 있다. 또한, 는 프로세싱 모듈(i,j)가 작업 을 하고 있는지 여부를 반환하는 함수로, 작업을 하고 있는 경우 1, 작업을 하지 않고 있는 경우 0을 반환할 수 있다. 즉, 보상 함수는 프로세싱 모듈의 가동률을 1로 만드는 것을 목적으로 하여, 보상에 기초한 학습을 통해 프로세싱 모듈의 가동률을 최대로 하고자 한다. 도 2는 본 문서에 개시된 일 실시예에 따른 모델링부를 더 포함하는 강화 학습을 이용한 공정 스케줄링 시스템 을 보여주는 도면이다. 도 2를 참조하면, 강화 학습을 이용한 공정 스케줄링 시스템은 모델링부를 더 포함할 수 있다. 실시예 에 따르면, 도 2에 도시된 공정 스케줄링 시스템은 도 1에 도시된 공정 스케줄링 시스템과 비교하여 모델 링부를 더 포함할 수 있다. 실시예에 따르면, 모델링부는 상태 정보를 포함하는 플랜트 모델 및 행동 제약 정보를 포함하는 행동 제약 모델을 생성할 수 있다. 모델링부는 공정 장비의 상태 및 행동 제약 정보를 학습부가 학습에 사용하기 용이하도록 모델링 하는 역할을 수행할 수 있다. 예를 들어, 플랜트 모델 및 행동 제약 모델은 그래프 모델을 포함할 수 있다. 실시예에 따르면, 모델링부는 플랜트 모델 및 행동 제약 모델에 기초하여 방향성 그래프 모델을 생성할 수 있다. 예를 들어, 방향성 그래프 모델은 공정 장비의 각 상태를 나타내는 복수의 노드 및 공정 장비의 행동에 기초한 노드 간의 연결 관계를 나타내는 엣지를 포함할 수 있다. 실시예에 따르면, 제어부는 방향성 그래프 모델 및 공정 장비의 현재 상태에 기초하여 데드락 노드 및 현 재 상태로부터 접근 불가능한 노드 중 적어도 어느 하나를 제거하여 행동 집합을 생성할 수 있다. 접근 불가능 한 노드는 현재 노드로부터 유한한 횟수의 이동을 통해 도달할 수 없는 노드를 포함할 수 있다. 데드락 노드란 공정 장비가 교착 상태에 빠질 수 있는 노드를 포함할 수 있으며, 예를 들어, 더 이상 공정을 진행할 수 없 는 노드를 포함할 수 있다. 이와 같이, 접근 불가능한 노드를 제거하여, 불필요한 학습 소요를 줄임으로써 학습 의 효율을 높일 수 있으며, 데드락 노드를 제거하여 공정 장비의 교착으로 인한 생산성 감소를 방지하고, 원활 한 웨이퍼 생산이 가능하게 할 수 있다. 실시예에 따르면, 모델링부는 유한 상태 머신(Finite State Machine) 모델에 기초하여 플랜트 모델을 생성 할 수 있다. 유한 상태 머신은 유한한 상태를 가지고, 기 설정된 상황이 발생하면 해당 상황에 맞는 상태로 변 환되어 행동하는 머신을 포함할 수 있다. 공정 장비의 경우, 유한한 상태를 가지고 공정 장비를 구성하 는 서브 모듈들의 행동에 따라 상태가 변화하므로 유한 상태 머신 모델에 기초하여 플랜트 모델을 생성할 수 있 다. 실시예에 따르면, 모델링부는 공정 장비를 구성하는 서브 모듈에 기초하여 서브 모델들을 포함하는 플랜트 모델을 생성할 수 있다. 즉, 플랜트 모듈은 각 서브 모듈을 블록화 하여 구성할 수 있고, 서브 모듈들의 집합은 플랜트 모듈을 구성할 수 있다. 실시예에 따르면, 서브 모듈은 진공 이송 모듈(Vacuum Transport Module, VTM), 대기 이송 모듈(Atmosphere Transport Module, ATM), 로드락 모듈(Load Lock Module), 프로세싱 모듈(Processing Module, PM), 정렬 모듈 (Allign Module), 냉각 모듈(Cooling Module) 및 로드 포트 모듈(Load Port Module) 중 적어도 하나를 포함할 수 있으며, 이 외에도 공정 장비의 종류, 상태, 제약 조건 등 현장에서의 필요성을 반영하여 목적에 맞게 구성할 수 있다. 이와 같이 서브 모듈에 기초하여 서브 모델을 생성함으로써 학습부의 학습 과정에서 현장 의 요구 및 고려 사항이 반영될 수 있고, 실제 공정 장비에 스케줄링 결과를 적용할 때 공정 효율을 보다 높일 수 있다. 도 3은 본 문서에 개시된 일 실시예에 따른 시뮬레이터를 더 포함하는 강화 학습을 이용한 공정 스케줄링 시스 템을 보여주는 도면이다. 도 3을 참조하면, 강화 학습을 이용한 공정 스케줄링 시스템은 시뮬레이터를 더 포함할 수 있다. 실시 예에 따르면, 도 3에 도시된 공정 스케줄링 시스템은 도 1에 도시된 공정 스케줄링 시스템과 비교하여 시 뮬레이터를 더 포함할 수 있다. 실시예에 따르면, 시뮬레이터는 학습부가 추출한 행동에 기초하여 공정 장비를 시뮬레이션할 수 있다. 스케줄링 과정에서 학습이 충분히 이루어지지 않은 상태에서 추출한 행동을 공정 장비에 직접 적용할 경우, 데드락 노드가 충분히 제거되지 않아, 데드락이 발생한다는 등 의도치 않은 상황이 발생할 수 있다. 또한, 학습 과정에서의 스케줄링을 직접 공정 장비에 적용하는 것은 시간과 비용이 많이 들기에, 시뮬레이터를 통해 가 상의 시뮬레이션을 활용하여 시간적, 비용적 이점을 얻을 수 있다. 이 때, 학습부는 시뮬레이터의 시뮬레 이션 결과에 기초하여 학습할 수 있다. 예를 들어, 시뮬레이션을 통해 공정 장비의 행동 결과에 따라 변화 된 공정 장비의 상태 등을 반영하여, 인공지능 신경망의 밸류(value), 폴리시(policy), 보상(reward) 등을업데이트하여 학습을 진행할 수 있다. 실시예에 따르면, 시뮬레이터는 공정 장비의 행동 수행 시간을 계산하고, 행동 수행 시간에 기초하여 시뮬 레이션을 수행할 수 있다. 예를 들어, 시뮬레이터는 틱(tick) 기반 시뮬레이터일 수 있다. 시뮬레이터 는 공정 과정에서 각 공정의 행동 수행 시간을 계산하고, 행동에 따른 수행 시간을 누적하여 계산함으로써, 공정 장비의 사이클 타임(Cycle Time)을 계산할 수 있다. 실시예에 따르면, 학습 과정에서 시뮬 레이션 결과를 저장하는 저장부 또는 데이터베이스를 포함할 수 있다. 도 4는 본 문서에 개시된 일 실시예에 따른 모델링부가 생성한 방향성 그래프 모델의 예시를 보여주는 도면이다. 도 4를 참조하면, 각 노드는 공정 장비의 상태를 나타내며, 각 노드는 방향을 가지는 엣지로 연결됨을 확인 할 수 있다. 도 5에서, q0 및 qM은 공정 장비의 현재 상태 및 목적 상태를 나타낼 수 있고, 는 공 정 장비의 행동을 나타낼 수 있다. 또한, 도 4에서 데드락 노드 및 접근 불가능한 노드의 표시는 데드락 노 드 및 접근 불가능한 노드의 이해의 편의를 위해 표시해 둔 것으로, 모델링부가 데드락 노드 또는 접근 불 가능한 노드를 판단한다는 등의 의미로 해석해서는 안 될 것이다. 도 5는 본 문서에 개시된 일 실시예에 따른 제어부가 방향성 그래프 모델에 기초하여 행동 집합을 생성하는 예 시를 보여주는 도면이다. 도 5를 참조하면, 제어부는 방향성 그래프 모델에 기초하여 데드락 노드 및 공정 장비의 현재 상태로 부터 접근 불가능한 노드를 제거하여 행동 집합을 생성하는 것을 확인할 수 있다. 이를 통해, 강화 학습을 이용 한 공정 스케줄링 시스템은 공정 과정에서 논리적 오류를 일으키지 않는 제어 동작만을 수행하도록 알고리즘 을 구성하여 학습의 속도 및 성능을 향상시킬 수 있다. 도 6은 본 문서에 개시된 일 실시예에 따른 강화 학습을 이용한 공정 스케줄링 시스템의 학습 결과의 예시를 보 여주는 도면이다. 도 6을 참조하면, 일 실시예에 따른 강화 학습을 이용한 공정 스케줄링 시스템의 스케줄링 결과를 확인할 수 있다. 도 6에 도시된 실험 결과는 클리닝 주기를 고려한 스케줄링에 따른 사이클 타임(Cycle time)을 나타낼 수 있다. m은 프로세싱 모듈의 구조를 나타내며, 예를 들어, [1,3,2]는 공정 스케줄링 시스템이 6개의 프로세싱 모듈 을 1개, 3개, 2개로 분리하여 각 공정 스텝에 사용함을 의미할 수 있다. 즉, 공정 과정에서 첫번째 스텝에는 1 개의 프로세싱 모듈이 사용되고, 두번째 스텝에는 3개의 프로세싱 모듈이 사용되며, 세번째 스텝에는 2개의 프 로세싱 모듈이 사용함을 의미할 수 있다. P는 각 스텝에서 소요된 공정 시간을, C는 각 스텝에서 소요된 클리닝 시간을 의미할 수 있으며, k는 클리닝 주기를 의미할 수 있다. 2열 내지 5열에 기재된 숫자는 공정 장비의 사이클 타임 값을 의미할 수 있으며, Workload는 이론상 가능한 Cylce time의 최소값을 의미할 수 있다. Swap, Swap(Z), Swap(a,Z)는 기존에 사용되던 스케줄링 룰을 의미할 수 있으며, SC-PPO는 강화 학습을 이용한 공정 스케줄링 시스템에 사용된 학습 모델을 의미할 수 있다. Baseline Gap은 기존 학습 모델(Swap, Swap(Z), Swap(a,Z))중 가장 좋은 결과를 낸 모델과 강화 학습을 이용한 공정 스케줄링 시스템의 결과와의 비교 값을 의미할 수 있다. 도 6에 따르면, 강화 학습을 이용한 공정 스케 줄링 시스템은 기존 스케줄링 룰들에 비해 최소 12.4% 더 좋은 효과를 도출하였음을 확인할 수 있다. 도 7은 본 문서에 개시된 일 실시예에 따른 강화 학습을 이용한 공정 스케줄링 시스템의 동작 흐름을 보여주는 도면이다. 도 7에서, 는 각각 현재 상태에서의 밸류(value), 폴리시(policy), 최적 행동을 나타낼 수 있다. 도 7을 참조하면, 제어부는 플랜트 모델 및 행동 제약 모델에 기초하여 행동 집합을 생성할 수 있다. 실시 예에 따르면, 모델링부는 플랜트 모델 및 행동 제약 모델이 기초하여 방향성 그래프 모델을 생성할 수 있 고, 제어부는 방향성 그래프 모델에 기초하여 행동 집합을 생성할 수 있다. 실시예에 따르면, 학습부는 인공지능 신경망을 포함할 수 있고, 상태 정보 및 행동 집합에 기초하여 공정 장비의 최적 행동을 추출하는 과정을 학습할 수 있다. 이 때, 시뮬레이터는 학습부가 추출한 행동에기초하여 공정 장비를 시뮬레이션 할 수 있고, 학습부는 시뮬레이션 결과에 기초하여 학습할 수 있다. 예를 들어, 학습부는 시뮬레이션 결과에 따라 밸류 및 폴리시를 업데이트 할 수 있다. 도 8은 본 문서에 개시된 일 실시예에 따른 강화 학습을 이용한 공정 스케줄링 방법을 설명하기 위한 흐름도이 다. 도 8을 참조하면, 강화 학습을 이용한 공정 스케줄링 방법은 공정 장비의 상태 정보 및 행동 제약 정보에 기초 하여 공정 장비가 수행 가능한 행동 집합을 생성하는 단계(S100) 및 행동 집합 및 상태 정보에 기초하여 현재 상태에서의 최적 행동을 추출하는 과정을 학습하는 단계(S200)를 포함할 수 있다. S100 단계에서, 제어부는 공정 장비의 상태 정보 및 행동 제약 정보에 기초하여 공정 장비가 수행 가능한 행동 집합을 생성할 수 있다. S200 단계에서, 학습부는 행동 집합 및 상태 정보에 기초하여 현재 상태에서의 최적 행동을 추출하는 과정 을 학습할 수 있다. 도 9는 본 문서에 개시된 다른 실시예에 따른 강화 학습을 이용한 공정 스케줄링 방법을 설명하기 위한 흐름도 이다. 도 9를 참조하면, 강화 학습을 이용한 공정 스케줄링 방법은 상태 정보를 포함하는 플랜트 모델 및 행동 제약 정보를 포함하는 행동 제약 모델을 생성하는 단계(S10)를 더 포함할 수 있다. 도 12에서, S100, S200 단계는 도 11에 도시된 S100, S200 단계와 각각 실질적으로 동일할 수 있다. S210 단계에서, 모델링부는 상태 정보를 포함하는 플랜트 모델 및 행동 제약 정보를 포함하는 행동 제약 모델을 생성할 수 있다. 도 10은 본 문서에 개시된 또 다른 실시예에 따른 강화 학습을 이용한 공정 스케줄링 방법을 설명하기 위한 흐 름도이다. 도 10을 참조하면, 강화 학습을 이용한 공정 스케줄링 방법은 추출한 행동에 기초하여 공정 장비를 시뮬레이션 하는 단계(S300)를 더 포함할 수 있다. 도 13에서, S100, S200 단계는 도 11에 도시된 S100, S200 단계와 각각 실질적으로 동일할 수 있다. S300 단계에서, 시뮬레이터는 추출한 행동에 기초하여 공정 장비를 시뮬레이션 할 수 있다. 이상에서, 본 문서에 개시된 실시예를 구성하는 모든 구성 요소들이 하나로 결합하거나 결합하여 동작하는 것으 로 설명되었다고 해서, 본 문서에 개시된 실시예들이 반드시 이러한 실시예에 한정되는 것은 아니다. 즉, 본 문 서에 개시된 실시예들의 목적 범위 안에서라면, 그 모든 구성 요소들이 하나 이상으로 선택적으로 결합하여 동 작할 수도 있다. 또한, 이상에서 기재된 \"포함하다\", \"구성하다\", 또는 \"가지다\" 등의 용어는, 특별히 반대되는 기재가 없는 한, 해당 구성 요소를 내재할 수 있음을 의미하는 것이므로, 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요 소를 더 포함할 수 있는 것으로 해석되어야 한다. 기술적이거나 과학적인 용어를 포함한 모든 용어들은, 다르게 정의되지 않는 한, 본 문서에 개시된 실시예들이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으 로 이해되는 것과 동일한 의미가 있다. 사전에 정의된 용어와 같이 일반적으로 사용되는 용어들은 관련 기술의 문맥상의 의미와 일치하는 것으로 해석되어야 하며, 본 문서에서 명백하게 정의하지 않는 한, 이상적이거나 과 도하게 형식적인 의미로 해석되지 않는다. 이상의 설명은 본 문서에 개시된 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 문서에 개시된 실시 예들이 속하는 기술 분야에서 통상의 지식을 가진 자라면 본 문서에 개시된 실시예들의 본질적인 특성에서 벗어 나지 않는 범위에서 다양한 수정 및 변형이 가능할 것이다. 따라서, 본 문서에 개시된 실시예들은 본 문서에 개 시된 실시예들의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 문 서에 개시된 기술 사상의 범위가 한정되는 것은 아니다. 본 문서에 개시된 기술사상의 보호 범위는 아래의 청구 범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술사상은 본 문서의 권리 범위에 포함되는 것으로 해석되어야 할 것이다. 부호의 설명1 : 강화 학습을 이용한 공정 스케줄링 시스템 10 : 공정 장비 100 : 제어부 200 : 학습부 300 : 모델링부 400 : 시뮬레이터"}
{"patent_id": "10-2022-0032052", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 문서에 개시된 일 실시예에 따른 강화 학습을 이용한 공정 스케줄링 시스템을 보여주는 도면이다. 도 2는 본 문서에 개시된 일 실시예에 따른 모델링부를 더 포함하는 강화 학습을 이용한 공정 스케줄링 시스템 을 보여주는 도면이다. 도 3은 본 문서에 개시된 일 실시예에 따른 시뮬레이터를 더 포함하는 강화 학습을 이용한 공정 스케줄링 시스 템을 보여주는 도면이다. 도 4는 본 문서에 개시된 일 실시예에 따른 모델링부가 생성한 방향성 그래프 모델의 예시를 보여주는 도면이다. 도 5는 본 문서에 개시된 일 실시예에 따른 제어부가 방향성 그래프 모델에 기초하여 행동 집합을 생성하는 예 시를 보여주는 도면이다. 도 6은 본 문서에 개시된 일 실시예에 따른 강화 학습을 이용한 공정 스케줄링 시스템의 학습 결과의 예시를 보 여주는 도면이다. 도 7은 본 문서에 개시된 일 실시예에 따른 강화 학습을 이용한 공정 스케줄링 시스템의 동작 흐름을 보여주는 도면이다. 도 8은 본 문서에 개시된 일 실시예에 따른 강화 학습을 이용한 공정 스케줄링 방법을 설명하기 위한 흐름도이 다. 도 9는 본 문서에 개시된 다른 실시예에 따른 강화 학습을 이용한 공정 스케줄링 방법을 설명하기 위한 흐름도 이다. 도 10은 본 문서에 개시된 또 다른 실시예에 따른 강화 학습을 이용한 공정 스케줄링 방법을 설명하기 위한 흐 름도이다."}
