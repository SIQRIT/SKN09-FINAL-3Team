{"patent_id": "10-2022-0134832", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0054630", "출원번호": "10-2022-0134832", "발명의 명칭": "자세 예측을 통한 컴퓨터 기반의 복장 색상 검출 방법", "출원인": "주식회사 마크애니", "발명자": "박민성"}}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 장치를 이용하여 복장 색상 정보를 검출하는 방법에 있어서,화상으로부터 인체를 식별하는 단계;상기 인체에서 적어도 하나의 관절부를 선택하는 단계;상기 선택된 관절부가 상기 화상에 위치하는 지점의 색상을 추출하는 단계; 및상기 색상에 기반하여 상기 화상과 연관된 복장 색상 정보를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 인체를 식별하는 단계는, 인체 식별 기능부에 의하여 동작하고,상기 인체는 상기 화상에 나타난 적어도 하나의 관절부 위치에 의하여 식별되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 인체 식별 기능부는, 기계학습(machine learning)이 가능한 심층신경망(deep neural network)에 기반한인공지능을 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 인체 식별 기능부에 의하여 인체를 식별하는 단계는,상기 화상을 처리하여 상기 화상에서 적어도 하나의 인체의 관절이 위치할 가능성을 나타내는 히트 맵(heatmap)을 생성하는 단계;상기 히트 맵에 기반하여 상기 화상에 나타난 적어도 하나의 관절부의 위치를 결정하는 단계;상기 관절부간을 연결하는 골격(bone) 정보를 생성하는 단계; 및상기 적어도 하나의 관절부 위치와 상기 적어도 하나의 골격 정보에 기반하여 인체를 식별하는 단계를포함하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 관절부를 선택하는 단계는, 상기 인체의 상반신에 속하는 적어도 하나의 제1관절부와 상기 인체의 하반신에 속하는 적어도 하나의 제2관절부를 선택하는 것을 특징으로 하는, 방법.공개특허 10-2024-0054630-3-청구항 6 제 5 항에 있어서,상기 복장 색상 정보는, 상의(上衣) 색상과 하의(下衣) 색상을 포함하고,상기 상의 색상을, 상기 적어도 하나의 제1관절부가 상기 화상에 위치하는 지점에 기반하여 추출하는 단계; 및상기 하의 색상을, 상기 적어도 하나의 제2관절부가 상기 화상에 위치하는 지점에 기반하여 추출하는 단계를 더포함하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 상의 색상을 추출하는 단계는, 상기 적어도 하나의 제1관절부가 상기 화상에 위치하는 지점에 기반하여 적어도 하나의 제1후보색상을 추출하는 단계; 및 상기 제1후보색상을 색상 병합 함수에 투입하고, 상기 색상 병합함수의 결과를 상기 상의 색상으로 추출하는 단계를 포함하고,상기 하의 색상을 추출하는 단계는, 상기 적어도 하나의 제2관절부가 상기 화상에 위치하는 지점에 기반하여 추출된 적어도 하나의 제2후보색상을 추출하는 단계; 및 색상 병합 함수에 투입하고, 상기 색상 병합 함수의 결과를 상기 하의 색상으로 추출하는 단계를 포함하고,상기 병합 함수는, 적어도 하나의 입력에 대하여 평균, 중위값 선택, 색상 공간 변경, 양자화, 및 단순비교에의한 다수결 중 적어도 하나의 연산과정을 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 제1후보색상을 추출하는 단계는, 상기 적어도 하나의 제1관절부가 상기 화상에 위치하는 지점에 기반하여계산된 상기 적어도 하나의 제1관절부 간에 형성되는 적어도 하나의 제1골격 정보가 상기 화상에 위치하는 지점에 기반하도록 구성되고,상기 제2후보색상을 추출하는 단계는, 상기 적어도 하나의 제2관절부가 상기 화상에 위치하는 지점에 기반하여계산된 상기 적어도 하나의 제2관절부 간에 형성되는 적어도 하나의 제2골격 정보가 상기 화상에 위치하는 지점에 기반하도록 구성되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 5 항에 있어서,상기 제1관절부는, 상기 인체에서 얼굴, 목, 가슴, 오른쪽 어깨, 오른쪽 팔꿈치, 오른쪽 손목, 왼쪽 어깨, 왼쪽팔꿈치, 왼쪽 손목, 등, 허리, 배, 및 척추를 나타내는 관절부 중 적어도 하나를 포함하고,상기 제2관절부는, 상기 인체에서 골반 중앙, 엉덩이, 오른쪽 골반, 오른쪽 무릎, 오른쪽 발목, 왼쪽 골반, 왼쪽 무릎, 및 왼쪽 발목 중 적어도 하나를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 관절부를 선택하는 단계는, 적어도 하나의 후보관절부를 선택하고,상기 색상을 추출하는 단계는,공개특허 10-2024-0054630-4-상기 적어도 하나의 후보관절부의 위치에 기반하여 산술 평균, 기하 평균, 중위값 선택, 함수 연산, 행렬 연산중 적어도 하나를 포함하는 연산방법에 의하여 계산되는 균형점을 계산하는 단계; 및상기 균형점이 상기 화상에 위치하는 지점의 색상을 추출하는 단계를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 복수의 후보관절부는, 상기 화상에서 상기 인체가 아닌 다른 물체에 가려진(obscured) 후보관절부를 제외하고 선택되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1 항, 제 5 항, 또는 제 10 항 중 어느 한 항에 있어서,상기 색상을 추출하는 단계는,상기 지점을 중심으로 하고, 폭, 높이, 및 직경 중 적어도 하나가 제1길이인 구역을 상기 화상에 지정하는단계;상기 구역으로부터 적어도 하나의 후보 색상 정보를 추출하는 단계; 및상기 각각의 후보 색상 정보에 기반하여 산술 평균, 기하 평균, 중위값 선택, 가우시안 연산, 함수 연산, 행렬연산 중 적어도 하나의 연산방법에 의하여 상기 지점의 색상을 계산해 추출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 1 항에 있어서,상기 추출된 색상의 색채(hue), 채도(saturation), 명도(luminosity) 중 적어도 하나의 값에 기반하여 상기 추출된 색상을 후처리하는 단계를 더 포함하고,상기 후처리는, 상기 추출된 색상의 보정, 양자화, 명명(命名) 중 적어도 하나의 과정을 포함하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 1 항에 있어서,영상 데이터로부터 적어도 하나의 프레임을 추출하여 상기 화상을 획득하는 단계; 및상기 결정된 복장 색상 정보를 상기 영상 데이터에서 상기 프레임의 시간적 위치와 연관시켜 기록하는 단계를더 포함하는, 방법."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "복장 색상 정보를 검출하는 컴퓨터 장치에 있어서,화상을 입력 받는 입력부;상기 화상으로부터 적어도 하나의 인체를 식별하고, 상기 인체에서 적어도 하나의 관절부를 선택하는 식별부;상기 관절부가 상기 화상에 위치하는 지점의 색상을 추출하는 샘플링부;상기 색상을 상기 화상과 연관된 복장 색상 정보로 출력하는 출력부;공개특허 10-2024-0054630-5-상기 입력부, 식별부, 샘플링부, 및 출력부 중 적어도 하나의 동작을 실행하는 프로세서; 및상기 프로세서와 연결된 메모리를 포함하는, 장치."}
{"patent_id": "10-2022-0134832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "컴퓨터 장치를 이용하여 복장 색상 정보를 검출하는 목적의 컴퓨터 프로그램에 있어서,화상으로부터 적어도 하나의 인체를 식별하고;상기 인체에서 적어도 하나의 관절부를 선택하고;상기 관절부가 상기 화상에 위치하는 지점의 색상을 추출하고; 그리고상기 색상을 상기 화상과 연관된 복장 색상 정보로 출력하도록 하는, 적어도 하나의 명령어 집합을 포함하는 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0134832", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 이용하여 영상에 촬영된 인간의 복장 색상을 검출하는 기술에 대한 것이다. 또한, 본 발명 은 인공지능을 이용하여 영상에 촬영된 인간의 자세를 예측하고 상기 자세에 기반한 정보처리를 실시하는 기술에 대한 것이다. 상술한 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 의한 컴퓨터 장치를 이용하여 복장 색 상 정보를 검출하는 방법은, 화상으로부터 인체를 식별하는 단계, 상기 인체에서 적어도 하나의 관절부를 선택하 는 단계, 상기 선택된 관절부가 상기 화상에 위치하는 지점의 색상을 추출하는 단계, 및 상기 색상을 상기 화상 과 연관된 복장 색상 정보로 결정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0134832", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용하여 영상에 촬영된 인간의 복장 색상을 검출하는 기술에 대한 것이다. 또한, 본 발 명은 인공지능을 이용하여 영상에 촬영된 인간의 자세를 예측하고 상기 자세에 기반한 정보처리를 실시하는 기 술에 대한 것이다."}
{"patent_id": "10-2022-0134832", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "CCTV는 보안 및 치안의 유지를 목적으로 하는 감시 시스템으로, 민간과 공공의 다양한 영역에서 설치 및 운용되 고 있다. 특히 최근에는 범죄 예방, 교통 안전, 재난 대응 등을 목적으로 하는 공공 목적의 CCTV 시스템이 다수 도입되고 있다. 상기와 같은 공공 CCTV의 유용한 기능 중 하나로 촬영된 영상으로부터 특정한 인물을 검색하는 것이 있다. 미아 또는 배회자의 발견, 그리고 범죄 용의자의 동선 추적과 같이, 특정한 인물이 영상에 등장한 경우를 검색하는 것이다. 그러나 공공 CCTV는 방대한 장소에서 방대한 양의 영상 데이터를 수집하므로, 사람의 노력에 의하여 이 러한 검색을 달성하기란 불가능에 가깝다. 따라서, 공공 CCTV의 관제 시스템에는 자동화된 방법에 의해 상기 인 물 검색 기능을 수행하는 기능이 구축된다. 상기 인물 검색의 방법 중 하나로, 영상에 등장하는 사람의 복장 정보를 식별함으로써 그러한 복장 정보의 키워"}
{"patent_id": "10-2022-0134832", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "드에 의하여 인물을 검색하는 배경기술이 존재한다. 도 1은 영상으로부터 인물의 상하의 색상을 추출하는 방법을 나타내는 개념도이다. CCTV에 의하여 입수된 영상 의 내부에 사람이 촬영된 경우, 상기 사람의 상의 및 하의를 포함하는 복장을 컴퓨터"}
{"patent_id": "10-2022-0134832", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "비전 방법에 의하여 식별할 수 있다. 다양한 배경기술에 의하면, 상기 복장의 색상을 검출할 수 있으며, 또는 상기 복장의 유형(셔츠, 티셔츠, 점퍼, 반바지, 긴바지, 청바지 등)을 검출할 수 있다. 그 결과에 따라, 상의 가 빨간색으로 검출되는 경우, \"TOP: RED\"와 같은 상의 색상 정보가 추출될 수 있고, 하의(11 7)가 파란색으로 검출되는 경우, \"BOTTOM: BLUE\"와 같은 하의 색상 정보가 추출될 수 있다. 상기 각 각의 정보(130, 135)는 데이터베이스에 상기 영상 및 상기 정보(130, 135)가 관찰된 시간 구간과 연 관되어 저장된다. 이후 \"상의가 빨간색인 사람\"의 출현을 검색하는 경우, 상기 데이터베이스에 저장된 상 의 색상 정보(130, 135)를 대조함으로써 해당하는 사람이 촬영된 영상을 반환할 수 있게 된다. 상기와 같은 목적을 실현하기 위한 종래기술의 가장 큰 난관은 사람을 식별한 후 복장의 정확한 범위 및 색상을 추정하는 것이다. 사람이 반드시 정해진 자세로만 카메라에 촬영되는 것이 아니기 때문에, 사람의 존재 사실을 자동적으로 파악하는 기술의 구현은 높은 난이도를 요하게 되고, 그로부터 복장 정보를 추출해내는 것은 더욱 고도의 기술적 구성을 요구한다. 이러한 어려움에서, 복장 정보의 추출을 위하여 인공 신경망과 같은 인공지능 기반의 접근도 시도되고 있다. 그러나 종래의 기술들은 복장 정보만을 정확하게 추출하기 위한 인공지능의 기술구현에 있어서 정확도의 결여 또는 복잡도의 과잉과 같은 다양한 난관에 봉착하고 있다."}
{"patent_id": "10-2022-0134832", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명에서는 종래 복장 정보 추출 방법들의 난점을 해소하고자 한다. 특히 인공지능에 의하여 정확한 복장의 영역을 탐지하기 곤란하고 복장의 다양성에 대하여 취약하다는 본질적 한계를 극복하는 것이 본 발명의 기술적 과제이다."}
{"patent_id": "10-2022-0134832", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 의한 컴퓨터 장치를 이용하여 복장 색상 정보를 검 출하는 방법은, 화상으로부터 인체를 식별하는 단계, 상기 인체에서 적어도 하나의 관절부를 선택하는 단계, 상 기 선택된 관절부가 상기 화상에 위치하는 지점의 색상을 추출하는 단계, 및 상기 색상을 상기 화상과 연관된 복장 색상 정보로 결정하는 단계를 포함할 수 있다. 상기 인체를 식별하는 단계는, 인체 식별 기능부에 의하여 동작하고, 상기 인체는 상기 화상에 나타난 적어도 하나의 관절부 위치에 의하여 식별되는 것을 특징으로 할 수 있다. 상기 인체 식별 기능부는, 기계학습(machine learning)이 가능한 심층신경망(deep neural network)에 기반한 인공지능을 포함하는 것을 특징으로 할 수 있다. 상기 인체 식별 기능부에 의하여 인체를 식별하는 단계는, 상기 화상을 처리하여 상기 화상에서 적어도 하나의 인체의 관절이 위치할 가능성을 나타내는 히트 맵(heat map)을 생성하는 단계, 상기 히트 맵에 기반하여 상기 화상에 나타난 적어도 하나의 관절부의 위치를 결정하는 단계, 상기 관절부간을 연결하는 골격(bone) 정보를 생 성하는 단계, 및 상기 적어도 하나의 관절부 위치와 상기 적어도 하나의 골격 정보에 기반하여 인체를 식별하는 단계를 포함할 수 있다. 상기 관절부를 선택하는 단계는, 상기 인체의 상반신에 속하는 적어도 하나의 제1관절부와 상기 인체의 하반신 에 속하는 적어도 하나의 제2관절부를 선택하는 것을 특징으로 할 수 있다. 상기 복장 색상 정보는, 상의(上衣) 색상과 하의(下衣) 색상을 포함하고, 상기 방법은, 상기 상의 색상을, 상기 적어도 하나의 제1관절부가 상기 화상에 위치하는 지점에 기반하여 추출하는 단계, 및 상기 하의 색상을, 상기 적어도 하나의 제2관절부가 상기 화상에 위치하는 지점에 기반하여 추출하는 단계를 더 포함할 수 있다. 상기 상의 색상을 추출하는 단계는, 상기 적어도 하나의 제1관절부가 상기 화상에 위치하는 지점에 기반하여 적 어도 하나의 제1후보색상을 추출하는 단계; 및 상기 제1후보색상을 색상 병합 함수에 투입하고, 상기 색상 병합 함수의 결과를 상기 상의 색상으로 추출하는 단계를 포함하고, 상기 하의 색상을 추출하는 단계는, 상기 적어도 하나의 제2관절부가 상기 화상에 위치하는 지점에 기반하여 추출된 적어도 하나의 제2후보색상을 추출하는 단계; 및 색상 병합 함수에 투입하고, 상기 색상 병합 함수의 결과를 상기 하의 색상으로 추출하는 단계를 포함 하고, 상기 병합 함수는, 적어도 하나의 입력에 대하여 평균, 중위값 선택, 색상 공간 변경, 양자화, 및 단순비 교에 의한 다수결 중 적어도 하나의 연산과정을 포함하는 것을 특징으로 할 수 있다. 상기 제1후보색상을 추출하는 단계는, 상기 적어도 하나의 제1관절부가 상기 화상에 위치하는 지점에 기반하여 계산된 상기 적어도 하나의 제1관절부 간에 형성되는 적어도 하나의 제1골격 정보가 상기 화상에 위치하는 지점 에 기반하도록 구성되고, 상기 제2후보색상을 추출하는 단계는, 상기 적어도 하나의 제2관절부가 상기 화상에 위치하는 지점에 기반하여 계산된 상기 적어도 하나의 제2관절부 간에 형성되는 적어도 하나의 제2골격 정보가 상기 화상에 위치하는 지점에 기반하도록 구성되는 것을 특징으로 할 수 있다. 상기 제1관절부는, 상기 인체에서 얼굴, 목, 가슴, 오른쪽 어깨, 오른쪽 팔꿈치, 오른쪽 손목, 왼쪽 어깨, 왼쪽 팔꿈치, 왼쪽 손목, 등, 허리, 배, 및 척추를 나타내는 관절부 중 적어도 하나를 포함하고, 상기 제2관절부는, 상기 인체에서 골반 중앙, 엉덩이, 오른쪽 골반, 오른쪽 무릎, 오른쪽 발목, 왼쪽 골반, 왼쪽 무릎, 및 왼쪽 발 목 중 적어도 하나를 포함하는 것을 특징으로 할 수 있다. 상기 관절부를 선택하는 단계는, 복수의 후보관절부를 선택하고, 상기 색상을 추출하는 단계는, 상기 각각의 후 보관절부 위치에 기반하여 산술 평균, 기하 평균, 중위값 선택, 함수 연산, 행렬 연산 중 적어도 하나의 연산방 법에 의하여 균형점을 계산하는 단계, 및 상기 균형점이 상기 화상에 위치하는 지점의 색상을 추출하는 단계를포함할 수 있다. 상기 복수의 후보관절부는, 상기 화상에서 상기 인체가 아닌 다른 물체에 가려진(obscured) 후보관절부를 제외 하고 선택되는 것을 특징으로 할 수 있다. 상기 색상을 추출하는 단계는, 상기 지점을 중심으로 하고, 폭, 높이, 및 직경 중 적어도 하나가 제1길이인 구 역을 상기 화상에 지정하는 단계, 상기 구역으로부터 적어도 하나의 후보 색상 정보를 추출하는 단계, 및 상기 각각의 후보 색상 정보에 기반하여 산술 평균, 기하 평균, 중위값 선택, 가우시안 연산, 함수 연산, 행렬 연산 중 적어도 하나의 연산방법에 의하여 상기 지점의 색상을 계산해 추출하는 단계를 포함할 수 있다. 상기 방법은, 상기 추출된 색상의 색채(hue), 채도(saturation), 명도(luminosity) 중 적어도 하나의 값에 기반 하여 상기 추출된 색상을 후처리하는 단계를 더 포함하고, 상기 후처리는, 상기 추출된 색상의 보정, 양자화, 명명(命名) 중 적어도 하나의 과정을 포함할 수 있다. 상기 방법은, 영상 데이터로부터 적어도 하나의 프레임을 추출하여 상기 화상을 획득하는 단계, 및 상기 결정된 복장 색상 정보를 상기 영상 데이터에서 상기 프레임의 시간적 위치와 연관시켜 기록하는 단계를 더 포함할 수 있다. 상술한 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 의한 복장 색상 정보를 검출하는 컴퓨터 장치는, 화상을 입력 받는 입력부, 상기 화상으로부터 적어도 하나의 인체를 식별하고, 상기 인체에서 적어도 하나의 관 절부를 선택하는 식별부, 상기 관절부가 상기 화상에 위치하는 지점의 색상을 추출하는 샘플링부, 상기 색상을 상기 화상과 연관된 복장 색상 정보로 출력하는 출력부, 상기 입력부, 식별부, 샘플링부, 및 출력부 중 적어도 하나의 동작을 실행하는 프로세서, 및 상기 프로세서와 연결된 메모리를 포함할 수 있다. 상술한 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 의한 컴퓨터 장치를 이용하여 복장 색상 정보를 검 출하는 목적의 컴퓨터 프로그램은, 화상으로부터 적어도 하나의 인체를 식별하고, 상기 인체에서 적어도 하나의 관절부를 선택하고, 상기 관절부가 상기 화상에 위치하는 지점의 색상을 추출하고, 그리고 상기 색상을 상기 화 상과 연관된 복장 색상 정보로 출력하도록 하는, 적어도 하나의 명령어 집합을 포함하는 컴퓨터 판독 가능한 기 록매체에 저장된 컴퓨터 프로그램일 수 있다."}
{"patent_id": "10-2022-0134832", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 높은 정확도가 확보되는 인체 자세 추출 알고리즘을 활용하여 복장의 색상을 추출할 수 있게 됨으로써, 복장 자체의 형상을 학습하고자 하였던 종래의 인공지능 기반 기술의 발전 한계를 극복하고, 종래와 는 다른 수단에 의하여 더욱 정확하고 쉬운 색상 추출이 가능하게 된다."}
{"patent_id": "10-2022-0134832", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제 1, 제 2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 명명될 수 있다. \"및/또는\"이라는 용어는 복수의 관련된 기재된 항 목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함하며, 또한, 달리 지시되지 않는 한 비배 타적이다. 본 출원에 항목을 열거하는 경우 그것은 본 출원 발명의 사상과 가능한 실시 방법들을 용이하게 설명 하기 위한 예시적 서술에 그치며, 따라서, 본 발명의 실시예 범위를 한정하는 의도를 가지지 아니한다. 본 명세서에서 \"A 또는 B(A or B)\"는 \"오직 A\", \"오직 B\" 또는 \"A와 B 모두\"를 의미할 수 있다. 달리 표현하면, 본 명세서에서 \"A 또는 B(A or B)\"는 \"A 및/또는 B(A and/or B)\"으로 해석될 수 있다. 예를 들어, 본 명세서에 서 \"A, B 또는 C(A, B or C)\"는 \"오직 A\", \"오직 B\", \"오직 C\", 또는 \"A, B 및 C의 임의의 모든 조합(any combination of A, B and C)\"를 의미할 수 있다. 본 명세서에서 사용되는 슬래쉬(/)나 쉼표(comma)는 \"및/또는(and/or)\"을 의미할 수 있다. 예를 들어, \"A/B\"는 \"A 및/또는 B\"를 의미할 수 있다. 이에 따라 \"A/B\"는 \"오직 A\", \"오직 B\", 또는 \"A와 B 모두\"를 의미할 수 있다. 예를 들어, \"A, B, C\"는 \"A, B 또는 C\"를 의미할 수 있다. 본 명세서에서 \"적어도 하나의 A 및 B(at least one of A and B)\"는, \"오직 A\", \"오직 B\" 또는 \"A와 B 모두\"를 의미할 수 있다. 또한, 본 명세서에서 \"적어도 하나의 A 또는 B(at least one of A or B)\"나 \"적어도 하나의 A 및/또는 B(at least one of A and/or B)\"라는 표현은 \"적어도 하나의 A 및 B(at least one of A and B)\"와 동 일하게 해석될 수 있다. 또한, 본 명세서에서 \"적어도 하나의 A, B 및 C(at least one of A, B and C)\"는, \"오직 A\", \"오직 B\", \"오직 C\", 또는 \"A, B 및 C의 임의의 모든 조합(any combination of A, B and C)\"를 의미할 수 있다. 또한, \"적어도 하나의 A, B 또는 C(at least one of A, B or C)\"나 \"적어도 하나의 A, B 및/또는 C(at least one of A, B and/or C)\"는 \"적어도 하나의 A, B 및 C(at least one of A, B and C)\"를 의미할 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 이용하여 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 출원에서 발명을 설명함에 있어, 실시예들은 설명된 기능 또는 기능들을 수행하는 단위 블록들의 측면에서 설명되거나 예시될 수 있다. 상기 블록들이란 본 출원에서 하나 또는 복수의 장치, 유닛, 모듈, 부 등으로 표현 될 수 있다. 상기 블록들은 하나 또는 복수의 논리 게이트, 집적 회로, 프로세서, 컨트롤러, 메모리, 전자 부품 또는 이에 한정되지 않는 정보처리 하드웨어의 구현 방법에 의하여 하드웨어적으로 실시될 수도 있다. 또는, 상 기 블록들은 응용 소프트웨어, 운영 체제 소프트웨어, 펌웨어, 또는 이에 한정되지 않는 정보처리 소프트웨어의 구현 방법에 의하여 소프트웨어적으로 실시될 수도 있다. 하나의 블록은 동일한 기능을 수행하는 복수의 블록들 로 분리되어 실시될 수도 있으며, 반대로 복수의 블록들의 기능을 동시에 수행하기 위한 하나의 블록이 실시될 수도 있다. 상기 블록들은 또한 임의의 기준에 의하여 물리적으로 분리되거나 결합되어 실시될 수 있다. 상기블록들은 통신 네트워크, 인터넷, 클라우드 서비스, 또는 이에 한정되지 않는 통신 방법에 의해 물리적 위치가 특정되지 않고 서로 이격되어 있는 환경에서 동작하도록 실시될 수도 있다. 상기의 모든 실시 방법은 동일한 기 술적 사상을 구현하기 위하여 정보통신 기술 분야에 익숙한 통상의 기술자가 취할 수 있는 다양한 실시예의 영 역이므로, 여하의 상세한 구현 방법은 모두 본 출원상 발명의 기술적 사상 영역에 포함되는 것으로 해석되어야 한다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 또한 복수의 실시예들은 서로 배타적이 아니며, 일부 실시예들이 새로운 실시예들을 형성하기 위해 하나 이상의 다른 실시예들과 조합될 수 있음을 전제로 한다. 도 2는 본 발명의 일 실시예에 따른 자세 예측을 통한 컴퓨터 기반의 복장 색상 검출 방법이 사용되는 시스템의 개념도이다. 도 2의 시스템은 촬영기기에 의하여 촬영되는 영상을 입력 받고, 상기 영상에 포함 된 각각의 프레임 화상을 색상 검출 장치에 의하여 분석한 뒤, 상기 색상 검출 장치가 도출한 복장 색상 정보를 기반으로 복장 색상 검출 정보를 생성하여 데이터베이스에 저장하는 동작을 수행하 도록 구성된 것이다. 따라서, 본 발명의 실시 목적에 따라서는, 상기 시스템은 일정한 영역을 지속적으로 촬영하는 복수의 CCTV 카메라를 동시에 감시하는 관제사가 있는 CCTV 관제실의 시스템에서 적용되어, 상기 CCTV 카메라가 기록해 저장 한 영상을 특정 시간대에 특정 색상의 복장을 입은 인물이 존재하였는지를 기준으로 검색할 수 있게 하는, 이른 바 '스마트 CCTV'를 구현하는 데 사용될 수 있는 것이다. 이하 시스템의 동작에 대한 각각의 단계 및/또는 기능부에 대하여 상세히 설명한다. 촬영기기는 영상을 촬영하는 수단으로서, 실시예에 따라서는 CCTV 카메라로 해석될 수 있다. 상기 촬영기 기는 지속적으로, 또는 일정 시간 동안 일정한 공간을 촬영하도록 구성될 수 있다. 상기 촬영기기는, 본 발명의 실시예에 따라서는, 고정되거나 또는 이동할 수 있는 감시 카메라, 예를 들어 실내 또는 실외에 설치 된 CCTV 카메라이거나 감시용 드론, 무인 차량 등에 설치된 카메라일 수 있다. 상기 촬영기기가 촬영한 영상은, 본 발명의 바람직한 일 실시예에 따르면 프레임 단위로 구성된 디지 털 영상 저장 포맷으로 기록될 수 있다. 그러나 영상에 대한 상기 저장 포맷의 유형, 저장에 사용되는 영 상 취급 파라메터, 및 단위시간당 프레임율은 어떻게 결정되어도 무방하다. 또한, 실시방법에 따라서는, 상기 영상은 아날로그 방식으로 구현될 수도 있다. 상기 촬영기기의 촬영 영역에 피사체로서 사람이 나타나는 경우, 상기 사람이 상기 영상에 촬영됨은 자명하다. 용이한 설명을 위하여, 도 2에는 상기 사람이 매 10초 간격으로 촬영된 프레임 가운데 \"00:20\", \"00:30\", 및 \"00:40\"에 이르는 3개 프레임에 포함되어 있는 것으로 예시되어 있다. 이 경우, 상기 \"00:20\"부터 \"00:40\"에 이르는 기간을 상기 사람이 상기 영상에 나타난 시간대역이라고 간주할 수 있다. 상기 영상에 상기 사람은 동시에 두 명 이상 촬영될 수도 있고, 또는 같은 사람이 두 시간대역 에 촬영될 수도 있다. 이러한 경우 각각의 사람과 각각의 촬영 시점에 대하여 각각의 시간대역이 정의될 수 있 다. 본 발명의 취지가 이러한 응용을 제약하지 않음은 통상의 기술자가 쉽게 이해할 수 있을 것이다. 상기 영상은 상기 색상 검출 장치에 의하여 분석될 수 있다. 본 발명의 바람직한 일 실시예에 따르면, 상기 영상의 각 프레임에 나타나는 화상이, 정지 화상의 형태로 된 프레임 화상의 형태 로 추출된 뒤, 상기 색상 검출 장치에 입력될 수 있다. 상기 프레임 화상의 획득 방법은 그 외에도 다양한 형태로 구현될 수 있다. 예를 들어, 본 발명의 일 실시 예에서는, 상기 영상의 매 n번째 프레임의 화상을 선택하여 상기 프레임 화상으로 추출할 수 있다. 본 발명의 다른 실시예에서는, 상기 영상에서 예측 부호화(prediction coding)된 프레임(예를 들어, 예측 프레임(predicted frame; P-frame) 또는 양방향 예측 프레임(bi-directional predicted frame; B-frame))을 제 외하고, 온전한 프레임 화상 정보로 구성된 키 프레임(key frame) 또는 인트라 프레임(intra frame; I-frame)만 을 선택하여 상기 프레임 화상으로 추출할 수 있다. 본 발명의 또다른 실시예에서는, 상기 영상의 각 프레임이 독립된 정지 화상 저장 포맷으로 저장되고, 상기 각 프레임을 그대로 상기 프레임 화상으로서 추출할 수 있다. 그 밖에, 영상 정보의 저장 방법과 상기 영상 정보로부터 특정 시점의 정지 화상을 추출하는 방법은 종래에 알 려진 또는 앞으로 발명될 어떠한 기술적 구성의 조합에 의하여 구성되더라도 본 발명의 실시에는 지장을 주지 아니함은 통상의 기술자가 쉽게 이해할 수 있을 것이다. 상기 색상 검출 장치는 상기 프레임 화상을 입력 받는 입력부, 상기 화상으로부터 적어도 하나 의 인체를 식별하고, 상기 인체에서 적어도 하나의 관절부를 선택하는 식별부, 상기 관절부가 상기 화상에 위치하는 지점의 색상을 추출하는 샘플링부, 및 상기 색상을 상기 화상과 연관된 복장 색상 정보로 출력하 는 출력부를 포함할 수 있다. 또한, 상기 색상 검출 장치는 상기 입력부, 식별부, 샘플링부, 및 출력 부 중 적어도 하나의 동작을 실행하는 프로세서 및 상기 프로세서와 연결된 메모리를 포함하도록 구 성될 수 있다. 상기 식별부는 상기 입력부를 통해 제공된 프레임 화상으로부터 인체를 식별하고 상기 인체의 위치 및 자세를 추정함으로써 인체 자세 정보를 획득하는 기능을 보유하도록 구성될 수 있다. 상기 인체 자세 정보를 획득하는 기능은 종래의 또는 새로이 개발될 다양한 알고리즘에 의하여 실현될 수 있다. 본 발명의 일 실시예에 따르면, 상기 식별부는 기계학습(machine learning)이 가능한 심층신경망(deep neural network)에 기반한 인공지능을 포함하도록 구성될 수 있다. 상기 식별부가 수행하여야 하는 식별 동작의 실현을 위하여, 상기 인공지능은 사전에 지도학습 또는 비지도학습에 의하여 훈련된 자세 인공지능 모델 을 포함할 수 있다. 본 발명의 실시예에 따라서는, 상기 자세 인공지능 모델은 합성곱(covolution) 기반의 신경 망(convolutional neural network, CNN)으로 구현될 수 있다. 본 발명의 바람직한 일 실시예에 따르면, 상기 식별부에 의한 인체 자세 정보의 획득은 상기 화상에서 적 어도 하나의 인체 관절부 위치를 식별함에 따라 이루어질 수 있다. 실시예에 따라서, 상기 관절부 위치에 대한 식별은 상기 인공지능에 포함되는 자세 인공지능 모델에 의하여 이루어질 수 있다. 상기 식별부는 상기 인공지능을 이용하여 상기 화상을 처리하여 상기 화상에서 적어도 하나의 인체의 관절 이 위치할 가능성을 나타내는 히트 맵(heat map)을 생성하고, 상기 히트 맵에 기반하여 상기 화상에 나타난 적 어도 하나의 관절부의 위치를 결정하고, 상기 관절부간을 연결하는 골격(bone) 정보를 생성하고, 상기 적어도 하나의 관절부 위치와 상기 적어도 하나의 골격 정보에 기반하여 인체를 식별하도록 구성될 수 있다. 이하 도 3을 함께 참조하여 설명한다. 도 3은 본 발명의 일 실시예에 따른 인체 자세 정보 획득 과정의 개념도 이다. 예시적으로, 원본 화상에는 적어도 하나의 사람이 촬영되어 있을 수 있다. 상기 원본 화상은 상기 자세 인공지능 모델에 투입되고, 그 결과로 상기 화상에서 적어도 하나의 인체의 관절이 위치할 가능성을 나타내는 히트 맵(heat map)이 생성될 수 있다. 상기 히트 맵은 상기 사람 의 화상에서 인체의 관절이 존재할 가능성이 높은 영역에 높은 값이 부여된 등고선의 형태로 해석될 수 있다. 상기 히트 맵을 기초로, 상기 화상에 나타난 적어도 하나의 인체 관절부 위치를 결정하여 관절부 위치 정보을 획득할 수 있다. 상기 관절부 위치 정보는 다시 상기 자세 인공지능 모델에 투입되고, 그 결과로 상기 관절부가 가질 가능 성이 높은 골격 방향성 정보를 획득할 수 있다. 상기 골격 방향성 정보란, 상기 관절부 간에 어떠한 골격(bone)이 존재하는지를 추정하기 위해 각 관절이 어느 방향의 골격에 연관되는지에 대한 정보일 수 있 다. 상기 골격을 각각의 관절부에 대하여 추정함으로써, 인체의 골격 정보가 획득되면, 상기 관절부 위치 정보와 결합하여 하나의 사람 형상을 식별할 수 있도록 연결된 골격을 획득할 수 있다. 상기 연결된 골격은 결과적으로 하나의 인체로서 식별되어 인체 자세 정보로 저장될 수 있다. 상기 인체 자세 정보에서, 상기 인체에 속하는 각각의 관절부는 상기 인체를 구성하는 적합한 관절부 의 명칭, 이를테면 얼굴, 목, 가슴, 오른쪽 어깨, 오른쪽 팔꿈치, 오른쪽 손목, 왼쪽 어깨, 왼쪽 팔꿈치, 왼쪽 손목, 등, 허리, 배, 척추, 상기 인체에서 골반 중앙, 엉덩이, 오른쪽 골반, 오른쪽 무릎, 오른쪽 발목, 왼쪽 골반, 왼쪽 무릎, 및 왼쪽 발목을 포함하는 관절부 명칭으로 지칭되거나, 또는 이에 상응하는 식별부호 등으로 지칭되는 정보로 저장될 수 있다. 또한, 상기 인체에 속하는 각각의 관절부는 상기 원본 화상에 있어 서 가지는 평면적 위치, 예를 들면 화상의 정보 기준점으로부터의 x-픽셀 거리와 y-픽셀 거리와 같은 정보에 의 하여 그 위치가 확정될 수 있고, 상기 확정된 위치 정보가 저장될 수 있다. 상기 원본 이미지에 만약 복수의 인체가 촬영된 경우라 하여도, 상술한 과정의 전부 또는 일부를 직 렬적 또는 병렬적으로 반복함으로써 복수의 인체를 식별할 수 있고, 따라서 상기 인체 자세 정보는 상기 복수의 인체 각각에 대해서도 상술한 것과 같이 관절부를 지칭하는 정보 및 위치를 확정하는 정보를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 상기 원본 화상은 상술한 절차를 실시하기에 앞서 사전 가공하여 특징값을 생성하는 과정에 투입될 수 있다. 상기 특징값은, 본 발명의 실시예에 따라서는, 상기 자세 인공지능 모델이 학 습하기 용이하고 또한 입력 값으로 처리하기 용이한 형태로 변형된 상기 화상일 수 있다. 본 발명의 일 실시예에 따르면, 상기 식별부의 자세 인공지능 모델은 서로 독립된 복수 자세 인공지능 모 델로 구현될 수 있다. 실시예에 따라, 상기 자세 인공지능 모델은 상기 히트 맵을 생성하는 인공지능 모델, 상기 관절부 위치 정보를 생성하는 인공지능 모델, 상기 골격 정보를 생성하는 인공지능 모델 로 분리되어 구성될 수 있고, 또는 상기와 다른 분리방식 또는 분리된 모델의 숫자에 의하여 구성될 수 있다. 또한, 상기 각각의 인공지능 모델의 입력 값은 반드시 순차적으로 입출력될 필요가 없으며, 상기 원본 화상 의 정보 또는 그로부터 도출된 중간 단계의 정보를 입력으로 받아 처리하도록 구성되어도 무방하다. 예를 들어, 본 발명의 일 실시예에 따르면, 상기 식별부는 원본 화상을 상기 히트 맵과 상기 관절부 위치 정보를 생성하는 제1 인공지능 모델에 입력하고, 또한 병렬적으로 상기 골격 정보를 생성하는 제2 인공지능 모델에도 입력하여, 서로 병렬적으로 상기 관절부 위치 정보 및 상기 골격 정보를 생성 한 뒤 병합하여 상기 인체 자세 정보를 생성하도록 구성될 수도 있다. 다시 도 2를 참조하는 설명으로 돌아가면, 상기 식별부에서 획득된 상기 인체 자세 정보로부터, 상기 샘플링부는 상기 인체의 외면에 노출된 색상을 샘플링(sampling)을 통하여 추출하도록 구성될 수 있다. 이 때, 상기 샘플링부는 상기 인체 자세 정보로부터 적어도 하나의 특정한 관절부를 선택하고, 상기 선 택된 관절부가 상기 원본 화상에 위치하는 지점에 대한 정보를 이용하여, 상기 원본 화상의 적어도 하나의 색상 요소로부터 상기 색상을 추출하도록 구성될 수 있다. 이하 도 4a를 함께 참조하여 설명한다. 도 4a는 본 발명의 일 실시예에 따른 샘플링부의 동작에 대한 개념도이 다. 원본 화상에 상응하여 식별되는 적어도 하나의 인체에 대한 인체 자세 정보에는, 상술한 바와 같 이 각각의 관절부에 대하여 상기 인체의 특정 부위로 해석될 수 있는 지칭 정보가 부여될 수 있다. 따라서, 상 기 인체를 구성하는 각각의 관절부들은 상기 인체의 상반신 영역과 하반신 영역을 구분하기 위하여 사용될 수 있다. 본 발명의 일 실시예에서, 상기 인체의 상반신은 얼굴, 목, 가슴, 오른쪽 어깨, 오른쪽 팔꿈치, 오른쪽 손 목, 왼쪽 어깨, 왼쪽 팔꿈치, 왼쪽 손목, 등, 허리, 배, 및 척추를 나타내는 관절부 중 적어도 하나를 포함하도 록 구분될 수 있다. 또한, 상기 인체의 하반신은 골반 중앙, 엉덩이, 오른쪽 골반, 오른쪽 무릎, 오른쪽 발목, 왼쪽 골반, 왼쪽 무릎, 및 왼쪽 발목 중 적어도 하나를 포함하도록 구분될 수 있다. 특히 상기 상반신 또는 하반신을 나타내는 관절부들 중에서는 상기 상반신을 대표하는 적어도 하나의 관절부 및 상기 하반신을 대표하는 적어도 하나의 관절부가 선택될 수 있다. 예를 들어, 도 4에 도시된 본 발명의 일 실시 예에서는, 상기 인체에 있어서 배를 나타내는 관절부를 상기 상반신을 대표하는 제1관절부(41 6)로서 선택하고, 왼쪽 골반을 나타내는 관절부를 상기 하반신을 대표하는 제2관절부로서 선택 하고 있다. 상기 관절부의 선택에 있어서, 상기 상반신을 대표하는 제1관절부는 상기 인체의 상반신 가운데에서 도 상기 인체가 착용하고 있는 상의(上衣)의 표면에 해당하는 지점일 가능성이 높은 것을 선택하도록 구성 될 수 있고, 마찬가지로 상기 하반신을 대표하는 제2관절부는 상기 인체의 하반신 가운데에서도 상기 인체가 착용하고 있는 하의(下衣)의 표면에 해당하는 지점일 가능성이 높은 것을 선택하도록 구성될 수 있 다. 상술한 것과 같은 원리로 상기 제1관절부 및 상기 제2관절부를 선택함으로써, 본 발명의 목적 중 하 나인 인체의 복장 그 자체에 대한 인식 수단이 없이도 종래의 자세 측정 알고리즘을 이용하여 인체의 상의와 하 의 영역을 특정하는 효과를 획득할 수 있게 됨을 알 수 있다. 상술한 바와 같이 제1관절부 및 제2관절부가 선택되면, 상기 샘플링부는 상기 각각의 관절부가 원본 화상에서 위치하는 지점의 화상 정보로부터 색상을 추출할 수 있다. 따라서, 상기 제1관절부가 상기 원본 화상에 위치하는 지점에서 추출된 제1색상은, 상기 인체가 착용하고 있는 상의의 색 상으로 해석될 수 있고, 마찬가지로, 상기 제2관절부가 상기 원본 화상에 위치하는 지점에서 추출된제2색상은, 상기 인체가 착용하고 있는 하의의 색상으로 해석될 수 있다. 이하 도 4b를 함께 참조하여 설명한다. 도 4b는 본 발명의 다른 실시예에 따른 샘플링부의 동작에 대한 개념도 이다. 도 4a에서 설명하였듯이, 상기 원본 화상의 인체를 구성하는 각각의 관절부들은 상기 인체 의 상반신 영역과 하반신 영역을 구분하기 위하여 사용될 수 있다. 본 발명의 일 실시예에서, 상기 상반신은 얼굴, 목, 가슴, 오른쪽 어깨, 오른쪽 팔꿈치, 오른쪽 손목, 왼쪽 어 깨, 왼쪽 팔꿈치, 왼쪽 손목, 등, 허리, 배, 및 척추를 나타내는 관절부 중 적어도 하나를 포함하는 제1관절부 들에 의하여 구분될 수 있고, 상기 하반신은 골반 중앙, 엉덩이, 오른쪽 골반, 오른쪽 무릎, 오른쪽 발목, 왼쪽 골반, 왼쪽 무릎, 및 왼쪽 발목 중 적어도 하나를 포함하는 제2관절부들에 의하여 구분될 수 있다. 도 4b의 실시예에서, 상기 제1관절부들은 특히 인체의 복부, 양 어깨, 및 양팔을 포함하는 총 7개의 관절 부로, 상기 제2관절부들은 특히 인체의 골반 및 양 다리를 포함하는 총 6개의 관절부로 나타나 있다. 그러 나 상기 도 4b에 이러하게 나타난 것은 도면을 통해 본 발명은 보다 쉽게 설명하기 위한 예시일 뿐으로, 상기 제1관절부들과 상기 제2관절부들의 선택은 본 발명을 실시하는 이에 본 발명의 목적에 부합하는 범위 내에서 자유로이 선택될 수 있다. 상술한 바와 같이 제1관절부들 및 제2관절부들이 선택되면, 상기 샘플링부는 각각의 관절부들이 원본 화상에서 위치하는 지점의 화상 정보로부터 후보 색상을 추출할 수 있다. 따라서, 상기 제1관절부들 각각이 상기 원본 화상에 위치하는 지점에서 추출된 제1후보색상들이 획득되고, 마찬가지로, 상기 제2관절부들가 상기 원본 화상에 위치하는 지점에서 추출된 제2후보색상들이 획득될 수 있 다. 본 발명의 일 실시예에서, 상기 제1후보색상들은 색상 병합 함수에 의하여 계산되어 상기 제1색상 을 도출하도록 구성될 수 있다. 상기 색상 병합 함수는 적어도 하나의 입력에 대하여 평균, 중위값 선택, 색상 공간 변경, 양자화, 및 단순비교에 의한 다수결 중 적어도 하나의 연산과정을 포함할 수 있다. 본 발명의 바람직한 일 실시예에서, 상기 색상 병합 함수는 다음과 같은 단계를 거쳐 실행될 수 있다. 1) 상기 제1후보색상들을 RGB(red, green, blue) 색상 값 포맷으로 획득한다. 2) 상기 제1후보색상들의 RGB 색상 값을 HSV(hue, saturation, value) 색상 값으로 변환한다. 상기 변환 에는, 예를 들어, 하기 수학식 1과 같은 식이 사용될 수 있으며, 이에 한정되지 않고 종래의 또는 신규한 변환 방법들이 적용될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0134832", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "3) 상기 HSV 색상 값들로 변환된 각각의 제1후보색상들을 지정된 색상 다양성 범위 내로 양자화한다. 상기 양자화에는 상기 각각의 제1후보색상들이 가지는 H, S, V값 각각의 범위를 기준으로 양자화된 색상 값을 도출하는 룩-업 테이블(look-up table)이 사용될 수 있다. 상기 룩업 테이블은, 예를 들어, 하기 표 1과 같이 구성될될 수 있으며, 이에 한정되지 않고 종래의 또는 신규한 양자화 방법들이 적용될 수 있다. 표 1 H값 S값 V값 양자화된 색상 값 0<H<360 0<S<1 V<0.1 BLACK 0<H<360 S<0.15 V>0.65 WHITE0<H<360 S<0.15 0.1<V<0.65 GRAY H<11 OR H>351 S>0.7 V>0.1 RED H<11 OR H>351 S>0.7 V>0.1 PINK 310<H<351 S>0.15 V>0.1 PINK 11<H<45 S>0.15 V>0.75 ORANGE 11<H<45 S>0.15 V>0.1<V<0.75 BROWN 45<H<64 S>0.15 V>0.1 YELLOW 64<H<150 S>0.15 V>0.1 GREEN 150<H<180 S>0.15 V>0.1 BLUE-GREEN 180<H<255 S>0.15 V>0.1 BLUE 255<H<310 S>0.5 V>0.1 PURPLE 255<H<310 0.15<S<0.5 V>0.1 LIGHT PURPLE 4) 상기 양자화된 제1후보색상들 중 가장 많은 색상을 상기 제1색상으로 결정한다. 예를 들어, 상기 제1관 절부들로부터 유래하여 상기 양자화된 제1후보색상 7가지가 각각 {WHITE, WHITE, GRAY, WHITE, GRAY, BLACK, BLUE}와 같이 도출된 경우, 상기 제1색상은 단순비교에 의한 다수결에 의하여 \"WHITE\"로 결 정되도록 구성될 수 있다. 상기 제2후보색상들 또한 상술한 것과 유사한 색상 병합 함수에 의하여 계산되어 상기 제2색상을 도 출하도록 구성될 수 있음은 쉽게 알 수 있다. 또한, 상기 색상 병합 함수는 본 발명의 동작원리를 설명하기 위한 바람직한 일 실시예에 의한 예시일 뿐이며, 상기 색상 병합 함수는 상술된 실시 방법 이외에도 종래에 알려진 또는 새로이 발명될 어떠한 알고리즘 또는 함 수로 대체되더라도 무방하다. 이하 도 4c를 함께 참조하여 설명한다. 도 4c는 본 발명의 또다른 실시예에 따른 샘플링부의 동작에 대한 개념 도이다. 도 4a 및 4b에서 설명하였듯이, 상기 원본 화상의 인체를 구성하는 각각의 관절부들은 상기 인체의 상반신 영역과 하반신 영역을 구분하기 위하여 사용될 수 있다. 본 발명의 일 실시예에서, 상기 상반신은 얼굴, 목, 가슴, 오른쪽 어깨, 오른쪽 팔꿈치, 오른쪽 손목, 왼쪽 어 깨, 왼쪽 팔꿈치, 왼쪽 손목, 등, 허리, 배, 및 척추를 나타내는 관절부 중 적어도 하나를 포함하는 제1관절부 들과 상기 제1관절부들의 각각을 연결하는 제1골격들에 의하여 구분될 수 있고, 상기 하반신은 골반 중앙, 엉덩이, 오른쪽 골반, 오른쪽 무릎, 오른쪽 발목, 왼쪽 골반, 왼쪽 무릎, 및 왼쪽 발목 중 적어도 하나를 포함하는 제2관절부들의 각각을 연결하는 제2골격들에 의하여 구분될 수 있다. 따라서, 도 4c의 실시예에서, 상기 상반신은 목, 쇄골, 척추, 양쪽 윗팔, 및 양쪽 팔목으로 구성된 총 7개의 제 1골격들로, 상기 하반신은 골반, 양쪽 허벅지, 및 양쪽 장딴지로 구성된 총 5개의 제2골격들로 나타 나 있다. 그러나 상기 도 4c에 이러하게 나타난 것은 도면을 통해 본 발명은 보다 쉽게 설명하기 위한 예시일 뿐으로, 상기 제1관절부들, 상기 제2관절부들, 상기 제1골격들, 및 상기 제2골격들의 선택 은 본 발명을 실시하는 이에 본 발명의 목적에 부합하는 범위 내에서 자유로이 선택될 수 있다. 상술한 바와 같이 제1관절부들 및 제2관절부들이 선택되면, 상기 샘플링부는 각각의 골격들이 원본 화상에서 위치하는 지점의 화상 정보로부터 후보 색상을 추출할 수 있다. 따라서, 상기 제1골격들 각각이 상기 원본 화상에 위치하는 지점에서 추출된 제1후보색상들이 획득되고, 마찬가지로, 상기 제2골격들이 상기 원본 화상에 위치하는 지점에서 추출된 제2후보색상들이 획득될 수 있다. 따라서, 상기 제1후보색상들은 도 4b에서 서술한 것과 유사한 상기 색상 병합 함수에 의하여 계산되 어 상기 제1색상을 도출하도록 구성되고, 상기 제2후보색상들 또한 유사한 방법에 의하여 상기 제2색 상을 도출하도록 구성될 수 있다. 예를 들어, 상기 제1골격들로부터 유래하여 상기 양자화된 제1후보색상 7가지가 각각 {WHITE, WHITE, GRAY, WHITE, GRAY, BLACK, BLUE}와 같이 도출된 경우, 상기 제1색상은 단순비교에 의한 다수결에 의하여 \"WHITE\"로 결정되도록 구성될 수 있다. 상기 색상 병합 함수의 동작 또한 상술하였던 바와 같이 본 발명 의 동작원리를 설명하기 위한 바람직한 일 실시예에 의한 예시일 뿐, 상기 색상 병합 함수의 실시방법을 한정하 지 아니함은 자명하다.다시 도 2를 참조하면, 결과적으로, 상기 샘플링부는 상기 제1색상을 상의 색상으로서 출력부에 제공하고, 상기 제2색상을 하의 색상으로서 출력부에 제공하도록 구성될 수 있다. 다시 도 4를 참조하면, 본 발명의 응용된 일 실시예에서, 상기 샘플링부에 의하여 색상을 추출하는 방법은, 상기 관절부가 상기 원본 화상에서 위치하는 지점을 중심으로 하고, 폭, 높이, 및 직경 중 적어도 하나가 제1길이인 구역을 상기 원본 화상에 지정하고, 상기 구역으로부터 적어도 하나의 후보 색상 정보를 추출하고, 그리고 상기 각각의 후보 색상 정보에 기반하여 산술 평균, 기하 평균, 중위값 선택, 가우시안 연산, 함수 연산, 행렬 연산 중 적어도 하나의 연산방법에 의하여 상기 지점의 색상을 계산해 추출하는 과정을 포함할 수 있다. 상기 관절부가 위치하는 지점은, 상술한 실시예와 같이 원본 화상의 정보 기준점으로부터의 x-픽셀 거리와 y-픽셀 거리와 같은 정보에 의하여 표현되어 저장된 위치일 수 있다. 상기 원본 화상에 지정되는 구역이란, 본 발명의 실시예에 따라서는, 비트맵 화상의 픽셀(화소, pixel) 단 위에 의하여 구성되는 구역일 수 있다. 물론, 상기 원본 화상의 형상과 그 처리 방법에 의하여 화상의 부 분적 색상 정보를 나타내는 다른 정보 단위들이 공용될 수 있음은 통상의 기술자가 쉽게 알 수 있을 것이다. 이하 도 5를 함께 참조하여 설명한다. 도 5는 본 발명의 다양한 실시예에 따른 색상 추출 구역의 실시방법에 대 한 예시도이다. 도 5에서는 상기 구역을 픽셀 단위로 지정하는 실시예에 기준하여 일부 예시를 도시하고 있다. 도 5의 (a)는 상기 구역이 지정되지 않은 기준 픽셀을 나타내고 있다. 상기 기준 픽셀은, 상술한 바 와 같이, 색상 추출의 대상이 되는 관절부의 위치에 해당하는 픽셀일 수 있다. 이상적으로는, 상기 기준 픽셀 의 색상이 곧 해당 위치의 관절부가 나타내는 상기 인체의 복장 색상으로 간주되어도 무방할 것이나, 원본 화상에는 노이즈, 명암차, 색차와 같은 불규칙성이 발생할 수 있으므로, 본 발명의 실시예에 따라서는 주변의 영역을 더 참조하여 색상을 추출하도록 구현될 수 있는 것이다. 도 5의 (b)는 기준 픽셀을 중심으로 폭이 제1길이인 영역의 예를 나타내고 있다. 상기 도 5에서 제1길이는 7픽셀로 예시되어 있다. 본 발명의 실시예에 따라서는, 상기 영역에 포함되는 총 7개의 픽 셀로부터 색상 정보를 추출하고, 각각의 정보를 상술한 실시예와 같은 다양한 연산방법에 의하여 처리함으로써 기준 픽셀의 색상으로 간주할 수 있는 보다 신뢰할 수 있는 색상 정보를 도출할 수 있다. 도 5의 (c)는 기 준 픽셀을 중심으로 높이가 제1길이인 영역을 나타내고 있으며, 그 실시예는 도 5의 (b)에 상술 한 것과 유사할 수 있다. 도 5의 (d)는 기준 픽셀을 중심으로 높이와 폭이 각각 제1길이인 영역의 한 가지 예를 나타내고 있다. 상기 영역은 픽셀 거리에 의하여 기준 픽셀로부터 제1길이만큼 떨어진 픽셀의 집합으로 이루어진 마름모꼴 영역의 예시를 나타내고 있다. 도 5의 (e)는 기준 픽셀을 중심으로 지름이 제1길이인 영역의 한 가지 예를 나타내고 잇다. 상 기 영역은 기준 픽셀을 중심점으로 그려지는 지름이 제1길이인 원 안에 포함되는 주변 픽셀의 집합으로 이루어진 원형 영역의 예시를 나타내고 있다. 도 5의 (f)는 기준 픽셀을 중심으로 가로 지름이 제1길이이고 세로 지름이 제2길이인 영역(56 1)의 한 가지 예를 나타내고 잇다. 상기 영역은 기준 픽셀을 중심점으로 상기 제1길이 및 상기 제2길이에 의하여 그려지는 타원 안에 포함되는 주변 픽셀의 집합으로 이루어진 타원형 영역의 예시를 나 타내고 있다. 즉, 상기 영역은 반드시 하나의 조건(예를 들어, 제1길이)에 의하여 지정될 필요가 없고, 상기 도 5의 (f)와 같 이 가로와 세로가 다른 길이로 지정될 수 있으며, 또한 그 밖의 더욱 복잡한 영역에 의하여 구성되더라도 본 발 명의 실시에는 지장이 없고, 오히려 더욱 유리한 효과를 가질 수도 있다. 예를 들어, 상기 영역은 미리 비트맵 또는 벡터 형태의 도형으로 지정된 소정의 영역으로서 적용될 수 있다. 또 다른 예를 들어, 상기 영역은 상기 화상에서의 평면적 참조 영역에 더하여, 상기 화상이 속한 상기 영상에서의 전, 후 프레임에 속한 적어도 하나 의 픽셀을 더 참조하는 시간 방향의 영역을 포함하도록 구성될 수 있다. 본 발명의 응용된 다른 실시예에서, 상기 샘플링부에 의하여 색상을 추출하는 방법은, 적어도 둘 이상의 상기 관절부를 선택한 것에 기반할 수 있다. 이하 도 6을 함께 참조하여 설명한다. 도 6은 본 발명의 일 실시예에 따른 복수의 관절부를 선택하는 샘플링부 의 동작에 대한 개념도이다. 원본 화상에 상응하여 식별되는 적어도 하나의 인체를 구성하는 각각의관절부들은, 상술한 바와 같이 상기 인체의 상반신 영역과 하반신 영역을 구분하기 위하여 사용될 수 있다. 이 때, 상기 상반신 또는 하반신을 나타내는 관절부들 중에서는 상기 상반신을 대표하는 적어도 하나의 관절부 및 상기 하반신을 대표하는 둘 이상의 관절부가 선택될 수 있다. 예를 들어, 도 6에 도시된 본 발명의 일 실시 예에서는, 상기 인체에 있어서 왼쪽 어깨를 나타내는 관절부, 오른쪽 어깨를 나타내는 관절부, 및 배를 나타내는 관절부 등 3개의 관절부를 상기 상반신을 대표하는 제1관절부로서 선택하고 있다. 상기와 같이 제1관절부를 구성하는 복수의 관절부를 각각 후보관절부로 칭할 수 있다. 본 발명의 일 실시예에 따라서는, 상기 각각의 후보관절부 위치(616, 617, 618)에 기반하여 산술 평균, 기하 평 균, 중위값 선택, 함수 연산, 행렬 연산 중 적어도 하나의 연산방법에 의하여 균형점을 계산하고, 상기 균 형점이 상기 화상에 위치하는 지점의 색상을 상기 제1관절부로부터 추출된 복장 색상으로 간주 할 수 있다. 이처럼 복수의 후보관절부를 활용함으로써 얻는 이익은, 변동성이 있는 화상으로부터 안정적으로 복장 색상을 추출할 수 있도록 하며, 즉 상기 도 5의 예시와 같은 영역을 지정하는 경우와 유사하게 된다. 본 발명의 다른 실시예에 따라서는, 상기 복수의 후보관절부는 상기 화상에서 상기 인체가 아닌 다른 물체에 가 려진(obscured) 후보관절부를 제외하고 선택될 수 있다. 이하 도 7을 함께 참조하여 설명한다. 도 7은 본 발명의 일 실시예에 따른 복수의 관절부 중 가려진 관절부를 제외하는 샘플링부의 동작에 대한 개념도이다. 원본 화상에 상응하여 식별되는 적어도 하나의 인체를 구성하는 각각의 관절부들은, 상술한 바와 같이 상기 인체의 상반신 영역과 하반신 영역을 구분하기 위하 여 사용될 수 있다. 이 때, 상기 상반신을 나타내는 제1관절부는, 상기 인체에 있어서 왼쪽 어깨를 나타내 는 관절부, 오른쪽 어깨를 나타내는 관절부, 및 배를 나타내는 관절부 등 3개의 후보관절부로 정의되어 있을 수 있다. 도 7의 예시에서, 상기 3개의 후보관절군 가운데 배를 나타내는 관절부는 원본 화상에 포함되는 장애 물에 의하여 가려져 있다. 이러한 경우, 상기 배 관절부를 고려하여 상의의 색상을 추출하는 경우, 상기 장애물의 색상이 혼입될 우려가 생긴다. 따라서, 상기 배 관절부는 상술한 바와 같이 균형점 을 계산하는 데에 제외하도록 구성될 수 있는 것이다. 상기 균형점이 상기 화상에 위치하는 지 점의 색상을 상기 제1관절부로부터 추출된 복장 색상으로 간주할 수 있음은 상술한 실시예와 동일하다. 상기 화상에서 상기 인체가 아닌 다른 물체에 가려진(obscured) 후보관절부를 제외하고 선택될 수 있다. 본 발명의 또다른 실시예에 있어서, 상기 샘플링부는 상기 추출된 색상의 색채, 채도, 명도 중 적어도 하 나를 후처리에 의하여 수정하여 출력(247, 248)하도록 구성될 수 있다. 상기 후처리는 상기 추출된 색상의 보정, 양자화, 명명(命名) 중 적어도 하나의 과정을 포함할 수 있다. 상기 보정의 경우, 상기 원본 화상의 색채(hue), 채도(saturation), 명도(luminosity) 중 적어도 하나의 분포에 기반하여 이루어질 수 있다. 상기 양 자화 및 명명은, 상술하였던 표 1과 같은 룩업 테이블에 의하여 구현될 수 있다. 그러나 상술한 실시예에 한정 되지 않고, 상기 출력된 색상(247, 248)의 추출 정확도를 더욱 높이기 위한 다양한 방법이 후처리 방법으로서 적용될 수 있음은 자명하다. 다시 도 2를 참조하면, 상기 샘플링부가 출력한 상의 색상 및 하의 색상은 상기 출력부로 전달되고, 상기 출력부에 의하여 상기 색상 검출 장치의 출력으로서 출력될 수 있다. 상기 출력부는 상기 복장 색상(247, 248)을 다양한 방식으로 출력할 수 있다. 예를 들면, 본 발명의 실시 예에 따라서는, 상기 출력되는 색상은 RGB(Red, Green, Blue) 성분에 의한 가산혼합 방식의 색상 정보로 구성되 거나, HSB(Hue, Saturation, Brightness) 성분에 의한 색상 벡터 정보로 구성되거나, YCbCr(Luminance, Chroma-blue, Chroma-red) 성분에 의한 색차 신호로 구성되거나, CMYK(Cyan, Magenta, Yellow, Black) 성분에 의한 감산혼합 방신의 색상 정보로 구성되거나, 그 밖의 디지털 또는 아날로그 방식에 의한 색상 정보 표현 값 으로 구성될 수 있다. 본 발명의 다른 실시예에 따라서는, 상기 출력되는 색상은 소정의 색상마다 미리 지정된 문자열, 심볼, 또는 기호에 의하여 구분된 형태로 출력될 수 있다. 예를 들어, 상기 출력부는 소정의 기준 에 의하여 적색 영역으로 판단되는 모든 색상을 \"RED\"라는 식별 문자열로 정하여 출력하도록 구성될 수 있다. 상기 출력부를 통하여 상기 색상 검출 장치의 출력으로 도출된, 본 발명의 바람직한 실시예에 따르면 상의 색상 정보와 하의 색상 정보를 포함하는, 복장 색상 정보는, 상기 영상 데이터에서 상기 복장 색상 정보가 도출된 프레임 화상들의 시간적 위치와 연관시켜 복장 색상 검출 정보를 생성하는 데 사용될 수 있다. 상 기 복장 색상 검출 정보는, 상기 영상의 특정 시간대역에서 상기 복장 색상(247, 248)이 검출되었다는 사실을 나타내는 임의의 정보 표현 방식에 의하여 구성될 수 있다. 예를 들어, 도 2의 예시에서는, 상기 복장 색상 검출 정보가 소정의 json 서식으로 표기되어 있으나, 이는 본 발명의 구현방식을 한정하지 아니 한다. 상기 복장 색상 검출 정보는 최종적으로 상기 영상과 연관되어 상기 데이터베이스에 저장될 수 있다. 상술한 바와 같이, 본 발명의 상기 상기 시스템은 일정한 영역을 지속적으로 촬영하는 복수의 CCTV 카메라를 동시에 감시하는 관제사가 있는 CCTV 관제실의 시스템에서 적용되어, 상기 CCTV 카메라가 기록해 저장 한 영상을 특정 시간대에 특정 색상의 복장을 입은 인물이 존재하였는지를 기준으로 검색할 수 있도록 한다. 상 기와 같은 본 발명의 일 실시예에서, 상기 검색은, 상기 데이터베이스에 검색 대상 시간대역과 검색 대상 복장 색상 중 적어도 하나의 정보를 검색 쿼리(query)로 투입함으로써, 상기 복장 색상 검출 정보를 도출 하고, 그로부터 최종적으로는 상기 영상의 상기 시간대역을 특정하고 이를 열람할 수 있도록 하는 기 능을 제공하는 데 활용될 수 있다. 도 8은 본 발명의 일 실시예에 따른 자세 예측을 통한 컴퓨터 기반의 복장 색상 검출 방법의 순서도이다. 도 8 의 순서도를 통하여 상술한 시스템의 동작 절차를 다시금 상기 각각의 도면과 대응하여 설명하면 다음과 같다. 상기 촬영기기는 지속적으로, 또는 일정 시간 동안 일정한 공간의 영상을 촬영(S910)하도록 구성될 수 있다. 상기 영상은, 본 발명의 바람직한 일 실시예에 따르면 프레임 단위로 구성된 디지털 영상 저장 포맷으로 기록될 수 있다. 상기 영상의 각 프레임에 나타나는 화상은, 정지 화상의 형태로 된 상기 프레임 화상의 형태로 추출(S920)된 뒤, 상기 색상 검출 장치의 상기 입력부에 입력될 수 있다. 상기 식별부는 상기 입력부를 통해 제공된 프레임 화상으로부터 인체를 식별하고 상기 인체의 위치 및 자세를 추정함으로써 인체 자세 정보를 획득하는 기능을 보유하도록 구성될 수 있다. 본 발명의 일 실 시예에 따르면, 상기 식별부는 상기 원본 화상을 상기 히트 맵을 생성(S930)하고 상기 관절부 위치 정보를 생성(S931)하는 제1 인공지능 모델에 입력하고, 또한 병렬적으로 상기 골격 정보를 생성 (S932)하는 제2 인공지능 모델에도 입력하여, 서로 병렬적으로 상기 관절부 위치 정보 및 상기 골격 정보 를 생성한 뒤 병합하여 상기 인체 자세 정보를 생성(S940)하도록 구성될 수도 있다. 상기 식별부에서 획득된 상기 인체 자세 정보로부터, 상기 샘플링부는 상기 인체의 외면에 노출 된 색상을 샘플링을 통하여 추출하도록 구성될 수 있다. 이 때, 상기 샘플링부는 상기 인체 자세 정보 로부터 적어도 하나의 특정한 관절부를 선택하고, 상기 선택된 관절부가 상기 원본 화상에 위치하는 지점에 대한 정보를 이용하여, 상기 원본 화상의 적어도 하나의 색상 요소로부터 상기 색상을 추출하도록 구성될 수 있다. 상기 관절부의 선택에 있어서, 상기 상반신을 대표하는 제1관절부는 상기 인체의 상반신 가운데에서 도 상기 인체가 착용하고 있는 상의(上衣)의 표면에 해당하는 지점일 가능성이 높은 적어도 하나의 관절부 를 상반신의 후보관절부(616, 617, 618)로 선택(S951)하도록 구성될 수 있다. 상기 각각의 후보관절부 위치 (616, 617, 618)에 기반하여 산술 평균, 기하 평균, 중위값 선택, 함수 연산, 행렬 연산 중 적어도 하나의 연산 방법에 의하여 균형점을 계산(S952)하고, 상기 균형점이 상기 화상에 위치하는 지점의 색상 에서 추출된 제1색상을 상기 인체가 착용하고 있는 상의의 색상으로 결정(S953)할 수 있다. 마찬가지로, 상기 하반신을 대표하는 제2관절부는 상기 인체의 하반신 가운데에서도 상기 인체 가 착용하고 있는 하의(下衣)의 표면에 해당하는 지점일 가능성이 높은 적어도 하나의 관절부를 하반신의 후보 관절부로 선택(S961)하도록 구성될 수 있다. 상기 각각의 후보관절부 위치에 기반하여 적어도 하나의 연산방법 에 의하여 균형점을 계산(S962)하고, 상기 균형점이 상기 화상에 위치하는 지점의 색상에서 추출된 제2색 상을 상기 인체가 착용하고 있는 상의의 색상으로 결정(S963)할 수 있다. 상기 상의 색상 정보와 상기 하의 색상 정보는, 상기 영상 데이터에서 상기 복장 색상 정보가 도출된 프레임 화 상들의 시간적 위치를 획득(S933)한 정보와 결합되어 복장 색상 정보를 생성(S970)하는 데 사용될 수 있다. 이 어서, 상기 복장 색상 정보가 특정 복장이 일정 시간 동안 검출된 것을 나타내는 내용으로 해석되는 경우, 상기 시스템은 상기 영상의 특정 시간대역에서 상기 복장 색상(247, 248)이 검출되었다는 사실을 나 타내는 복장 색상 검출 정보를 생성(S981)하고, 상기 데이터베이스에 저장(S982)하도록 구성될 수 있 다. 상기 프레임 화상에 만약 복수의 인체가 식별된 경우(S985), 상술한 과정 중 개별적 인체의 자 세 정보로부터 관절부를 선택하는 과정(S951~S953, S961~S963, S970~S985)을 직렬적 또는 병렬적으로 반복함으 로써 상기 복수의 인체에 대한 복장 색상 검출 정보의 획득 및 저장이 이루어지도록 구성될 수 있다. 상기 일체의 절차는 상기 촬영기기에 의하여 상기 영상이 지속적으로 촬영됨으로써 새로운 프레임 화 상이 공급되고 있는 한(S990) 반복될 수 있다. 이상 본 발명에 대하여 도면 및 실시예를 참조하여 설명하였으나, 이미 상술한 바와 같이 본 발명의 보호범위가 상기 제시된 도면 또는 실시예에 의해 한정되는 것을 의미하지는 않으며, 해당 기술 분야의 숙련된 당업자는 하 기의 특허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하 게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0134832", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 영상으로부터 인물의 상하의 색상을 추출하는 방법을 나타내는 개념도, 도 2는 본 발명의 일 실시예에 따른 자세 예측을 통한 컴퓨터 기반의 복장 색상 검출 방법이 사용되는 시스템의 개념도, 도 3은 본 발명의 일 실시예에 따른 인체 자세 정보 획득 과정의 개념도, 도 4a는 본 발명의 일 실시예에 따른 샘플링부의 동작에 대한 개념도, 도 4b는 본 발명의 다른 실시예에 따른 샘플링부의 동작에 대한 개념도, 도 4c는 본 발명의 또다른 실시예에 따른 샘플링부의 동작에 대한 개념도, 도 5는 본 발명의 다양한 실시예에 따른 색상 추출 구역의 실시방법에 대한 예시도, 도 6은 본 발명의 일 실시예에 따른 복수의 관절부를 선택하는 샘플링부의 동작에 대한 개념도, 도 7은 본 발명의 일 실시예에 따른 복수의 관절부 중 가려진 관절부를 제외하는 샘플링부의 동작에 대한 개념 도, 도 8은 본 발명의 일 실시예에 따른 자세 예측을 통한 컴퓨터 기반의 복장 색상 검출 방법의 순서도이다."}
