{"patent_id": "10-2020-0018574", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0019930", "출원번호": "10-2020-0018574", "발명의 명칭": "디바이스의 음성 인식을 지원하는 서버 및 그의 동작 방법", "출원인": "삼성전자주식회사", "발명자": "김찬우"}}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 인스트럭션들을 저장하는 메모리;상기 메모리에 저장된 상기 하나 이상의 인스트럭션들을 실행하는 프로세서; 및제1 문자열을 디바이스로부터 수신하는 통신부를 포함하고,상기 프로세서는,상기 제1 문자열로부터 복수의 추정 문자열들을 식별하고, 상기 복수의 추정 문자열에 기초하여 제2 문자열을획득하고,상기 제2 문자열을 상기 디바이스에게 전송하도록 상기 통신부를 제어하며,상기 제1 문자열은, 상기 디바이스에 입력된 음성 신호로부터 음성 인식 처리를 거쳐 출력되는 것을 특징으로하는, 서버."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 제1 문자열 내의 각 문자에 대응하는 대체 문자들을 식별하고, 상기 식별된 대체 문자들에 기초하여 상기복수의 추정 문자열들을 식별하고,상기 복수의 추정 문자열들 중에서 하나의 추정 문자열을 상기 제2 문자열로서 획득하며,상기 대체 문자들은 상기 각 문자와 유사한 발음의 문자들인 것을 특징으로 하는, 서버."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 제1 문자열 내의 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가능도 행렬들을 산출하고, 상기가능도 행렬들 내의 가능도 값들에 기초하여 상기 복수의 추정 문자열들을 식별하는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 문자열은, 상기 음성 신호가 소정 시간 간격으로 분할된 음성 신호 프레임들 각각에 대응하는 문자들을 포함하는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 프로세서는,상기 가능도 행렬들 내의 가능도 값들에 기초하여 상기 복수의 추정 문자열들의 가능도를 계산하고,상기 가능도, 사전(dictionary) 정보, 및 언어 모델(language model)에 기초하여, 상기 복수의 추정 문자열 중하나를 선택하고,상기 선택된 추정 문자열에 따라, 상기 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 대체된 상기 제2 문공개특허 10-2021-0019930-3-자열을 획득하는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 각 문자에 대해 획득된 가능도 행렬들은, 상기 각 문자의 이전에 누적된 문자들에 기초하여 산출되는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3 항에 있어서,상기 각 문자에 대해 획득된 가능도 행렬들은,상기 각 문자의 이전에 누적된 문자들에 기초하여 산출되는 사후 확률들, 및 상기 각 문자의 이전에 누적된 문자들에 기초하여 산출되는 문자 배열 확률에 기초하여 산출되는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 사후 확률들은, 복수의 LSTM(long-short term memory) 레이어들 및 소프트맥스(softmax) 레이어를 포함하는 인공 지능 회귀 신경망(recurrent neural network, RNN)을 이용하여 산출되는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제3항에 있어서,상기 각 문자에 대해 획득된 가능도 행렬들은, 미리 결정된 오차 행렬(confusion matrix)에 기초하여 산출되는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 프로세서는, 상기 획득된 제2 문자열에 기초하여, 상기 디바이스에 입력된 음성 신호에 관련된 서비스를 제공하는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "하나 이상의 인스트럭션들을 저장하는 메모리;상기 메모리에 저장된 상기 하나 이상의 인스트럭션들을 실행하는 프로세서; 및 서버와 통신하는 통신부를 포함하고,상기 프로세서는,음성 신호에 대해서 음성 인식을 수행하여 제1 문자열을 획득하고,상기 제1 문자열을 다른 문자열로 대체할 지 여부를 결정하고,상기 결정에 기초하여 상기 제1 문자열을 상기 서버로 전송하도록 상기 통신부를 제어하고, 상기 서버에 의해 상기 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 대체됨으로써 획득된 제2 문자열을상기 서버로부터 수신하도록 상기 통신부를 제어하는 것을 특징으로 하는, 디바이스."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "서버의 동작 방법에 있어서,공개특허 10-2021-0019930-4-제1 문자열을 디바이스로부터 수신하는 단계;상기 제1 문자열로부터 복수의 추정 문자열들을 식별하는 단계;상기 복수의 추정 문자열에 기초하여 제2 문자열을 획득하는 단계; 및상기 제2 문자열을 상기 디바이스에게 전송하는 단계를 포함하고,상기 제1 문자열은, 상기 디바이스에 입력된 음성 신호로부터 음성 인식 처리를 거쳐 출력되는 것을 특징으로하는, 방법."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 제1 문자열로부터 복수의 추정 문자열들을 식별하는 단계는,상기 제1 문자열 내의 각 문자에 대응하는 대체 문자들을 식별하는 단계; 및상기 식별된 대체 문자들에 기초하여 상기 복수의 추정 문자열들을 식별하는 단계를 포함하고,상기 복수의 추정 문자열에 기초하여 제2 문자열을 획득하는 단계는,상기 복수의 추정 문자열들 중에서 하나의 추정 문자열을 상기 제2 문자열로서 획득하는 단계를 포함하며,상기 대체 문자들은 상기 각 문자와 유사한 발음의 문자들인 것을 특징으로 하는, 방법."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 복수의 추정 문자열들을 식별하는 단계는,상기 제1 문자열 내의 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가능도 행렬들을 산출하는 단계;및상기 가능도 행렬들 내의 가능도 값들에 기초하여 상기 복수의 추정 문자열들을 식별하는 단계를 포함하는 것을특징으로 하는, 방법."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 제1 문자열은, 상기 음성 신호가 소정 시간 간격으로 분할된 음성 신호 프레임들 각각에 대응하는 문자들을 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 제2 문자열을 획득하는 단계는,상기 가능도 행렬들 내의 가능도 값들에 기초하여 상기 복수의 추정 문자열들의 가능도를 계산하는 단계;상기 가능도, 사전(dictionary) 정보, 및 언어 모델(language model)에 기초하여, 상기 복수의 추정 문자열 중하나를 선택하는 단계; 및상기 선택된 추정 문자열에 따라, 상기 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 대체된 상기 제2 문자열을 획득하는 단계를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 각 문자에 대해 획득된 가능도 행렬들은, 공개특허 10-2021-0019930-5-상기 각 문자의 이전에 누적된 문자들에 기초하여 산출되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14 항에 있어서,상기 각 문자에 대해 획득된 가능도 행렬들은,상기 각 문자의 이전에 누적된 문자들에 기초하여 산출되는 사후 확률들, 및 상기 각 문자의 이전에 누적된 문자들에 기초하여 산출되는 문자 배열 확률에 기초하여 산출되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 획득된 제2 문자열에 기초하여, 상기 디바이스에 입력된 음성 신호에 관련된 서비스를 제공하는 단계를 더포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2020-0018574", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "디바이스의 동작 방법에 있어서,음성 신호에 대해서 음성 인식을 수행하여 제1 문자열을 획득하는 단계;상기 제1 문자열을 다른 문자열로 대체할 지 여부를 결정하는 단계;상기 결정에 기초하여 상기 제1 문자열을 서버로 전송하는 단계; 및상기 서버에 의해 상기 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 대체됨으로써 획득된 제2 문자열을상기 서버로부터 수신하는 단계를 포함하는 것을 특징으로 하는, 디바이스."}
{"patent_id": "10-2020-0018574", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 서버는, 하나 이상의 인스트럭션들을 저장하는 메모리; 상기 메모리에 저장된 상기 하나 이상의 인스트럭션들을 실행하는 프로세서; 및 제1 문자열을 디바이스로부터 수신하는 통신부를 포함하고, 상기 프로세서는, 상기 제1 문자열로부터 복수의 추정 문자열들을 식별하고, 상기 복수의 추정 문자열에 기초하 여 제2 문자열을 획득하고, 상기 제2 문자열을 상기 디바이스에게 전송하도록 상기 통신부를 제어하며, 상기 제1 문자열은, 상기 디바이스에 입력된 음성 신호로부터 음성 인식 처리를 거쳐 출력되는 것을 특징으로 할 수 있다."}
{"patent_id": "10-2020-0018574", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 디바이스의 음성 인식을 지원하는 서버 및 그의 동작 방법에 관한 것이다. 구체적으로는, 서버 단에 서의 후처리(post-processing)를 이용하여 음성 인식 결과를 강화하는 방법에 관한 것이다."}
{"patent_id": "10-2020-0018574", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "다양한 기능을 복합적으로 수행하는 전자 장치들이 개발됨에 따라, 조작성을 향상시키기 위하여 음성 인식 기능 이 탑재된 전자 장치들이 출시되고 있다. 음성 인식 기능은, 별도의 버튼 조작 또는 터치 모듈의 접촉에 의하지 않고 사용자의 음성을 인식함으로써 장치를 손쉽게 제어할 수 있는 장점을 가진다. 이러한 음성 인식 기능에 의하면, 예를 들어 스마트 폰과 같은 휴대용 단말기 및 TV, 냉장고 등과 같은 가전 제 품에서 별도의 버튼을 누르는 조작 없이 통화 기능을 수행하거나 문자 메시지를 작성할 수 있으며, 길 찾기, 인 터넷 검색, 알람 설정 등 다양한 기능을 손쉽게 설정할 수 있다. 최근에는, 인공 지능(Artificial Intelligence, AI) 기술이 발전함에 따라 음성 인식 기능에도 인공 지능 기술 이 접목됨으로써, 다양한 발화들에 대해서 빠르고 정확한 음성 인식이 가능해졌다. 인공 지능 시스템은 인간 수 준의 지능을 구현하는 컴퓨터 시스템이며, 기존 룰(rule) 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용할 수록 인식률이 향상되고 사용자의 취향을 보다 정 확하게 이해할 수 있게 되어, 기존의 룰 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 디바이스 측에서 음성 인식(Automatic Speech Recognition, ASR)이 수행되는 온-디바이스 음성 인식은 대기 시 간(latency)이 짧고 네트워크가 연결이 되지 않는 경우에도 이용 가능하다는 장점이 있다. 반면에 서버-기반 음 성 인식은, 서버에 저장된 많은 수의 개체명(Named entity)에 기초하여 음성 인식이 수행된다는 장점이 있다."}
{"patent_id": "10-2020-0018574", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2020-0018574", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "온-디바이스 음성 인식과 서버-기반 음성 인식의 장점을 모두 활용할 수 있도록, 디바이스가 두 방식을 선택적 으로 이용하는 방법이 요구된다."}
{"patent_id": "10-2020-0018574", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따르면, 서버는, 하나 이상의 인스트럭션들을 저장하는 메모리; 상기 메모리에 저장된 상기 하나 이상의 인스트럭션들을 실행하는 프로세서; 및 제1 문자열을 디바이스로부터 수신하는 통신부를 포함 하고, 상기 프로세서는, 상기 제1 문자열로부터 복수의 추정 문자열들을 식별하고, 상기 복수의 추정 문자열에 기초하여 제2 문자열을 획득하고, 상기 제2 문자열을 상기 디바이스에게 전송하도록 상기 통신부를 제어하며, 상기 제1 문자열은, 상기 디바이스에 입력된 음성 신호로부터 음성 인식 처리를 거쳐 출력되는 것을 특징으로 할 수 있다. 본 개시의 일 실시 예에 따르면 서버의 동작 방법은, 제 1 문자열을 디바이스로부터 수신하는 단계; 상기 제1 문자열로부터 복수의 추정 문자열들을 식별하는 단계; 상기 복수의 추정 문자열에 기초하여 제2 문자열을 획득 하는 단계; 및 상기 제2 문자열을 상기 디바이스에게 전송하는 단계를 포함하고, 상기 제1 문자열은, 상기 디바 이스에 입력된 음성 신호로부터 음성 인식 처리를 거쳐 출력되는 것을 특징으로 할 수 있다. 본 개시의 일 실시 예에 따르면 디바이스는, 하나 이상의 인스트럭션들을 저장하는 메모리; 상기 메모리에 저장 된 상기 하나 이상의 인스트럭션들을 실행하는 프로세서; 및 서버와 통신하는 통신부를 포함하고, 상기 프로세 서는, 음성 신호에 대해서 음성 인식을 수행하여 제1 문자열을 획득하고, 상기 제1 문자열을 다른 문자열로 대 체할 지 여부를 결정하고, 상기 결정에 기초하여 상기 제1 문자열을 상기 서버로 전송하도록 상기 통신부를 제 어하고, 상기 서버에 의해 상기 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 대체됨으로써 획득된 제2 문자열을 상기 서버로부터 수신하도록 상기 통신부를 제어하는 것을 특징으로 할 수 있다. 본 개시의 일 실시 예에 따르면 디바이스의 동작 방법은, 음성 신호에 대해서 음성 인식을 수행하여 제1 문자열 을 획득하는 단계; 상기 제1 문자열을 다른 문자열로 대체할 지 여부를 결정하는 단계; 상기 결정에 기초하여 상기 제1 문자열을 서버로 전송하는 단계; 및 제2 문자열을 상기 서버로부터 수신하는 단계를 포함하고, 상기 제2 문자열은, 상기 서버에 의해 상기 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 대체됨으로써 획득된 것을 특징으로 할 수 있다."}
{"patent_id": "10-2020-0018574", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 실시 예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시 예의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"...모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또 는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에서 \"문자\"란, 인간의 언어를 눈에 볼 수 있는 형태로 나타내어 적는데 사용하는 기호를 의미한다. 예 를 들어, 문자에는, 한글, 알파벳, 한자, 숫자, 발음 부호, 문장 부호 및 기타 기호가 포함될 수 있다. 본 개시에서 \"문자열\"이란, 문자들의 배열(sequence)을 의미한다. 본 개시에서 “문자소(grapheme)”란, 적어도 하나의 문자로 구성되는, 소리를 나타내는 가장 작은 단위이다. 예를 들어, 알파벳 표기 체계의 경우, 하나의 문자가 문자소가 될 수 있다. 따라서, 본 개시에서 문자는 문자소 를 지칭할 수 있으며, 본 개시에서 문자열은, 문자소들의 배열을 의미할 수 있다. 또한, 본 개시에서 문자열은 텍스트라고 지칭될 수도 있다. \"형태소(morpheme)\"란, 적어도 하나의 문자소로 구성되는, 의미를 가지는 가장 작은 단위이다. \"단어(word)\"란, 적어도 하나의 형태소로 구성되는, 자립적으로 쓰일 수 있거나 문법적 기능을 나타내는 언어의 최소 기본 단위 이다. \"음소\"란 인간의 언어에서 하나의 단어를 다른 단어와 구별하는 소리의 단위이다. 본 개시의 일 실시 예에 따른 음성 인식 모델은, 음성 신호를 문자열로 변환하여 출력할 수 있다. 본 개시의 일 실시 예에 따른 음성 인식 모델이 출력하는 문자열은 \"프레임 동기화된 문자열\"일 수 있다. \"프레임\"이란 음성 신호의 처리를 위하여 음성 신호가 일정한 시간 간격으로 분할되는 단위, 또는 분할된 음성 신호 그 자체를 의미할 수 있다. 본 개시에서 \"프레임 동기화된 문자열\"이란, 음성 신호가 음성 인식 모델에 의해 문자열로 변환 되어 출력됨에 있어서, 음성 신호의 프레임들 각각에 개별적으로 대응하는 문자들을 포함하는 문자열을 의미한 다. 예를 들어, 음성 인식 모델은, 사용자가 \"baseball\"이라고 발음하는 음성 신호를 수신하고, 프레임 동기화된 문 자열인 [b, b, a, , a, a, s, s, e, , b, b, a, a, l]을 출력할 수 있다. 본 개시에서 음성 인식 모델이 음성 신호로부터 소정 문자열을 출력함에 있어서, \"소정 문자열의 신뢰도\"란, 소 정 문자열을 출력한 음성 인식 모델이 얼마나 정확하게 음성 인식을 수행하고 있는 가의 정도를 나타낸다. 예를 들어, 소정 문자열의 신뢰도는, 소정 문자열로부터 획득되는 가능도, 소정 문자열을 추정하는 과정에서 출력되 는 부분 가능도 또는 사후 확률 값 등에 기초하여 미리 결정된 수학식에 따라 산출될 수 있다. 소정 문자열의 신뢰도가 높을수록, 소정 문자열이 음성 인식 모델로부터 정확하게 추정되었다고 판단될 수 있다. 본 개시에서 \"소정 문자열에 대한 평가 정보\"는, 일 실시 예에 따른 서버가 소정 문자열보다 높은 신뢰도를 가 지는 다른 문자열을 추천하여 출력하기 위하여 이용하는 소정 문자열에 대한 정보를 의미할 수 있다. 예를 들어, 소정 문자열에 대한 평가 정보는, 소정 문자열로부터 획득되는 복수의 추정 문자열들의 가능도를 포함할 수 있다. 예를 들어, 일 실시 예에 따른 서버는, 복수의 추정 문자열들 중에서 가능도를 최대로 하는 다른 문자 열을 선택하여 출력할 수 있다. 한편, 본 개시에서 \"가능도(likelihood)\"란, 가능한 정도를 뜻하는 것으로서, \"사건 A에 대한 사건 B의 가능 도\"는, 사건 A가 발생하였을 때 사건 B가 일어날 가능성을 나타내는 조건부 확률 P(B|A)을 의미할 수 있다. 본 개시에서 음성 인식 모델이 음성 신호로부터 소정 문자열을 출력함에 있어서, \"소정 문자열로부터 획득되는 가능도(likelihood)\"란, 소정 문자열로부터 추정되는 복수의 추정 문자열들의 가능도를 의미한다. 소정 문자열 로부터 추정되는 복수의 추정 문자열들은, 소정 문자열 내의 적어도 하나의 문자가 다른 문자로 대체됨으로써 획득되는 복수의 문자열들을 의미할 수 있다. 보다 구체적으로는, 음성 인식이 정확하게 수행되었을 때에 출력되는 문자열을 참값(ground truth) 문자열이라 고 하면, \"소정 문자열로부터 획득되는 가능도\"는, 복수의 추정 문자열들 각각이 참값 문자열이라고 가정하였을 때 음성 인식 결과로서 소정 문자열이 추정될 가능성을 의미할 수 있다. 본 개시의 일 실시 예에 따르면, \"소정 문자열로부터 획득되는 가능도\"는 소정 문자열 내의 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가 능도 행렬들을 포함할 수 있다. 본 개시의 일 실시예에 따르면, \"소정 문자열로부터 획득되는 가능도\"는, 소정 문자열 내의 각 문자와 발음이 유사한 대체 문자들을 식별하고, 식별된 대체 문자들에 기초하여 소정 문자열 내의 적어도 하나의 문자가 다른 문자로 교정된 추정 문자열들을 결정하기 위하여 이용될 수 있다. 더 나아가서는, 결정된 추정 문자열들 중에서, 언어 모델 및 사전 정보 등 미리 저장된 정보에 기초하여 가장 적합한 추정 문자열이 선택되어 소정 문 자열 대신에 추천될 수 있다. 음성 인식 모델이 음성 인식을 수행함에 있어서 앞에서 수행된 음성 인식 결과가 이 후에 수행되는 음성 인식 결과에 영향을 미칠 수 있다. 소정 문자가 발음이 유사한 다른 문자로 잘못 인식 되는 경우, 잘못 인식됨으로 인해 언어적인 정보가 틀어지면서 소정 문자의 뒤에 나오는 문자들 역시 잘못 인식 될 확률이 높아질 수 있다. 즉, 소정 문자가 다른 문자로 오인식 되는 경우, 소정 문자와 뒤에 나오는 문자들을 조합하여 결정되는 단어들 과 오인식된 다른 문자와 뒤에 나오는 문자들을 조합하여 결정되는 단어들이 상이해질 수 있다. 따라서, 본 개시의 일 실시예에 따른 디바이스 또는 서버는, 소정 문자열에 대한 발음 정보와 언어 정보를 함께 고려하여 디코딩함으로써 대체 문자열을 획득하기 위해서, 소정 문자열로부터 획득되는 가능도를 이용할 수 있 다. 본 개시에서 \"소정 문자에 대해서 획득되는 가능도 행렬\"이란, 소정 문자가 대체될 대체 문자들에 대한 가능도 값들을 포함하는 행렬을 의미할 수 있다. \"소정 문자가 대체될 대체 문자에 대한 가능도 값\"이란, 대체 문자가 참값(ground truth) 문자라고 가정하였을 때 음성 인식 결과로서 소정 문자가 추정될 확률을 의미할 수 있다. 예를 들어, 음성 인식 결과 획득되는 문자열 내에 포함되는 문자 \"a\"에 대해서, 참값(ground truth) 문자가 \" a\"일 확률 값, \"b\"일 확률 값, \"c\"일 확률 값, ..., 및 \"z\"일 확률 값을 포함하는 가능도 행렬 [0.4 0.01 0.01 0.01 0.2 ... 0.01]이 획득될 수 있다. 문자열 내에 포함되는 각 문자에 대응하는 대체 문자들에 대한 가능도 값들을 포함하는 가능도 행렬을 획득함에 있어서, 각 문자와 발음이 유사한 대체 문자들에 대해서 높은 가능도값이 부여될 수 있다. 본 개시에서, \"소정 문자열로부터 획득되는 가능도\"는 소정 문자열 내의 각 문자에 대응하는 대체 문자들에 관 한 가능도 값들로부터 획득될 수 있다. 이 때, 소정 문자열 내의 각 문자에 대응하는 대체 문자들에 관한 가능 도 값들은, 각 문자의 이전에 누적된 문자들을 고려하여 계산될 수 있다. 그러나 본 개시는 이에 제한되지 않으 며, 소정 문자열 내의 각 문자에 대응하는 대체 문자들에 관한 가능도 값들은, 각 문자의 이전에 누적된 문자들 을 고려하지 않고, 각 문자 자체만을 고려하여 계산될 수 있다. 본 개시의 일 실시 예에 따르면, 소정 문자열 내의 각 문자의 이전에 누적된 문자들을 고려하여 \"소정 문자열로 부터 획득되는 가능도\"는 \"소정 문자열에 포함되는 각 문자의 사후 확률들(posterior probabilities)\" 및 소정 문자열의 \"문자 배열 확률(sequence probability)\"로부터 계산될 수 있다. 사건 A의 \"사후 확률\"이란, 사건 A와 관련된 사건, 관측 사실 또는 배경 지식을 고려하였을 때 사건 A가 기대 되는 조건부 확률을 의미한다. 본 개시에서 음성 인식 모델이 음성 신호로부터 문자열을 출력함에 있어서, \"문자열 내의 소정 문자의 사후 확 률들\"은, 문자열 내의 소정 문자의 이전 문자들을 고려하였을 때, 음성 인식 모델이 소정 문자를 정확하게 예측 했을 확률 및 다른 문자를 소정 문자로 잘못 예측했을 확률을 포함할 수 있다. 본 개시에서 음성 인식 모델이 음성 신호로부터 문자열을 출력함에 있어서, \"문자열의 문자 배열 확률\"이란, 해 당 문자열에 따라 문자들이 배열될 확률을 의미할 수 있다. 본 개시의 일 실시 예에 따르면, 소정 문자열 내의 각 문자 자체만을 고려하여 \"소정 문자열로부터 획득되는 가 능도\"는, 각 문자들이 잘못 예측됐을 확률 값들을 포함하는 \"오차 행렬(confusion matrix)\"로부터 계산될 수 있 다. 본 개시에서 \"오차 행렬\"이란, 에러 행렬(error matrix)이라고도 지칭되며, 음성 인식 모델이 음성 신호를 소정 문자열로 변환하여 출력함에 있어서, 음성 인식 모델이 소정 문자열에 포함되는 소정 문자를 정확하게 예 측했을 확률 및 다른 문자를 소정 문자로 잘못 예측했을 확률을 포함한다. 예를 들어, 소정 문자와 발음이 유사 한 문자들에 대해서는, 음성 인식 모델에 의해 발음이 유사한 문자들이 소정 문자로 잘못 예측했을 확률이 높게 부여될 수 있다. 본 개시에서 \"음향 모델\"이란, 음성 신호가 어떠한 문자 또는 발음 기호에 매칭되는지 문자소 단위로 판단할 수 있는 정보를 포함하는 모델을 의미할 수 있다. 예를 들어, 본 개시의 일 실시 예에 따른 디바이스는, 음향 모델 에 기초하여 음성 신호와 문자들 각각이 매칭될 확률을 계산할 수 있다. 본 개시에서 \"사전 정보(dictionary information)\"란, 복수의 단어들과 복수의 단어들 각각에 포함되는 문자들 의 매핑 정보를 포함할 수 있다. \"언어 모델\"은, 특정 단어열이 주어졌을 때 다음에 나올 단어들의 확률을 추정 할 수 있도록 단어들 간의 관계를 학습한 인공 지능 모델일 수 있다. 본 개시에서 \"인공 신경망\"이란, 사람 또는 동물 두뇌의 신경망에 착안하여 구현된 컴퓨팅 시스템의 총칭한다. 인공 신경망은, 기계 학습(machine learning)의 세부 방법론 중 하나로, 신경 세포인 뉴런(neuron)이 여러 개 연결된 망의 형태이다. 인공 신경망은 하드웨어로 구현될 수도 있으나, 주로 컴퓨터 소프트웨어로 구현된다. 인 공 신경망은 기초 컴퓨팅 단위인 뉴런 여러 개가 가중된 링크(weighted link)로 연결된 형태이다. 가중된 링크 (weighted link)는 주어진 환경에 적응할 수 있도록 가중치를 조정할 수 있다. 인공 신경망은 자기 조직화 지도(SOM: Self-Organizing Map), 순환 신경망(RNN: Recurrent Neural Network), 콘볼루션 신경망(CNN: Convolutional Neural Network)과 같은 다양한 모델에 대한 총칭으로, 그 종류는 수십 가지에 이른다. 본 개시에서 \"도메인\"이란, 어떠한 속성과 관련된 단어들의 집합을 해당 속성의 도메인이라 한다. 본 개시에서 \"제1 문자열을 교정하는 동작\"은, 제1 문자열에 포함되는 적어도 하나의 문자를 다른 문자로 대체 함으로써, 제1 문자열 보다 높은 신뢰도를 가지는 제2 문자열을 추천하여 출력하는 동작을 의미할 수 있다. 따 라서, 본 개시에서 '문자열의 교정', '문자의 교정', '소정 문자를 다른 문자로 대체', '소정 문자 대신에 다른 문자를 추천', '소정 문자열을 다른 문자열로 대체', 및 '소정 문자열 대신에 다른 문자열을 추천' 하는 표현은 대체되어 이용될 수 있다. 본 개시의 일 실시 예에 따른 음성 인식 시스템에 포함되는 디바이스 또는 서버는, 사용자에게 \"음성 비서 서비 스\"를 제공할 수 있다. 음성 비서 서비스는, 사용자와의 대화를 제공하는 서비스일 수 있다. 음성 비서 서비스는 사용자의 상황, 디바이스의 상황 등을 고려하여 사람이 사용자와 직접 대화하는 것처럼 사용자에게 응답 메 시지를 제공할 수 있다. 또한, 음성 비서 서비스는, 사용자의 개인 비서처럼 사용자가 필요한 정보를 적절하게 생성하여 사용자에게 제공할 수 있다. 음성 비서 서비스는, 예를 들어, 방송 서비스, 콘텐트 공유 서비스, 콘텐 트 제공 서비스, 전력 관리 서비스, 게임 제공 서비스, 채팅 서비스, 문서 작성 서비스, 검색 서비스, 통화 서 비스, 사진 촬영 서비스, 교통 수단 추천 서비스 및 동영상 재생 서비스 등 다양한 서비스와 연계되어 사용자가 필요한 정보 또는 기능을 사용자에게 제공할 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 이하에서는 도면을 참조하여 본 개시의 실시 예들을 상세하게 설명한다. 도 1은 온-디바이스 음성 인식과 서버-기반 음성 인식을 비교하여 설명하기 위한 도면이다. 온-디바이스 음성 인식은, 사용자의 발화에 대한 음성 인식이 디바이스 측에서 수행되는 것을 의미하 고, 서버-기반 음성 인식은, 디바이스에서 수신된 사용자의 발화에 대한 음성 인식이 서버 측에 서 수행되는 것을 의미한다. 엔드-투-엔드(End-to-end) 음성 인식과 압축 기술의 발전으로 온-디바이스 음성 인식 기술이 점점 발전함에 따 라 서버-기반 음성 인식과의 성능 차이가 점점 줄어들고 있다. 특히, 특정 분야에 제한되지 않는 오픈 도메인 (Open Domain)의 발화에 대한 음성 인식이나 일반적인 받아쓰기에 있어서 디바이스와 서버 간의 성능 차이가 거 의 없어 졌다. 일반적인 받아쓰기란, 개체명(Named Entity) 위주의 도메인에 해당하지 않는 발화에 대한 받아쓰 기를 의미한다. 개체명은, 특정 지명, 인명, 기기명, 상표명 등을 포함할 수 있다. 도메인이란, 어떠한 속성과 관련된 단어들의 집합을 해당 속성의 도메인이라 한다. 온-디바이스 음성 인식은 지연 시간(latency)이 약 50ms 미만으로, 수백 ms인 서버-기반 음성 인식의 지연 시간 보다 짧고, 네트워크 연결이 되지 않는 교외, 비행기 내부, 또는 전파 음영 지역 등에서도 이용 가능하다는 장 점이 있다. 또한, 온-디바이스 음성 인식은, 보안 및 사생활 침해 이슈에서 보다 유리하고, 서버를 관리하는 비 용을 줄일 수 있다는 장점이 있다. 한편, 서버-기반 음성 인식은, 지명, 인명, 상표명등과 같은 개체명들을 디바이스보다 많이 저장할 수 있는 서 버에서 구현된다는 장점이 있다. 따라서, 서버-기반 음성 인식에 의하면, 새로운 유행어나 새로운 신곡 제목 등과 관련된 단어들에 보다 높은 가 중치를 부여할 수 있고, 음성 인식이 안 되는 경우 사전에 해당 단어를 추가함으로써 음성 인식의 결함을 복구 하는 핫-픽스(hot-fix)가 가능하다는 장점이 있다. 또한, 서버에서 동작하는 써드 파티(third-party) 애플리케 이션에 최적화된 언어 모델 및 사전 정보 등을 이용하여 음성 인식 결과에 대한 리스코어링(rescoring)이 가능 하다는 장점이 있다. 그러므로, 받아쓰기, 일반적인 명령, 자막 생성 등과 같은 일반적인 목적의 음성 인식은 디바이스에서 수행하되, 특정 도메인에 해당하는 언어 모델 및 사전 정보 등을 이용하여 음성 인식이 수행되어야 하는 경우 서버에서 수행하도록 하는 하이브리드(hybrid) 방식의 음성 인식이 요구된다. 이 때, 전체 음성 인식 과정을 디바이스와 서버가 나누어서 수행할 경우, 디바이스와 서버 사이에 의존성 (dependency)이 생길 수 있다. 일 예로서, 발화에 대해 음향 모델을 적용하는 계산이 디바이스에서 수행되고, 음향 모델로부터 추출된 중간값 에 대해 언어 모델과 사전 정보를 적용한 디코딩 계산이 서버에서 수행되는 방법이 이용될 수 있다. 이러한 방 법에 따르면 디바이스와 서버 사이에는 의존성이 생기게 되므로, 서로 호환되지 않은 디바이스와 서버 간에는 사용할 수 없다는 문제점이 있다. 다른 예로서, 인코딩 계산 및 디코딩 계산 과정을 포함하는 엔드-투-엔드(end-to-end) 음성 인식 방식에 있어서 인코딩 계산만 디바이스에서 수행되고 인코딩 된 데이터에 대한 디코딩 계산이 서버에서 수행되는 방법이 이용 될 수 있다. 디코딩 계산이 수행되기 위해서는 인코딩 방식에 대한 사전 정보가 필요하므로 인코딩을 수행하는 디바이스와 디코딩을 수행하는 서버 사이에는 의존성이 생기게 된다. 따라서, 이러한 방법도 서로 호환되지 않 은 디바이스와 기기 간에는 사용할 수 없다는 문제점이 있다.상술한 문제점을 해결하기 위하여, 도 2a에 도시된 본 개시의 일 실시 예에 따른 음성 인식 시스템이 제안된다. 본 개시의 일 실시 예에 따른 디바이스는, 음성 신호를 제1 문자열로 변환하는 온-디바이스 음성 인식을 수행할 수 있다. 디바이스는, 제1 문자열의 신뢰도에 기초하여, 온-디바이스 음성 인식이 실패하였는 지 여부를 판단할 수 있다. 디바이스는, 온-디바이스 음성 인식이 실패하는 경우, 음성 인식의 결과인 제1 문 자열을 서버에게 전송할 수 있다. 본 개시의 일 실시 예에 따르면, 디바이스가 음성 신호에 대한 정보를 문자열의 형태로 서버에게 전 송함으로써, 디바이스가 어떤 종류의 온-디바이스 음성 인식을 사용하는지에 관계없이 서버가 문자열 을 처리할 수 있다는 장점이 있다. 본 개시의 일 실시 예에 따라 디바이스로부터 서버에게 전송되는 제1 문자열은, 프레임 동기화된 문 자열일 수 있다. ‘프레임’이란 음성 신호의 처리를 위하여 음성 신호가 일정한 시간 간격으로 분할되는 단위, 또는 분할된 음 성 신호 그 자체를 의미할 수 있다. “프레임 동기화된 문자열”이란, 음성 신호가 음성 인식 모델에 의해 문자 열로 변환되어 출력됨에 있어서, 음성 신호의 프레임들 각각에 개별적으로 대응하는 문자들을 포함하는 문자열 을 의미한다. 일 실시 예에 따른 디바이스는, RNN-T나 CTC등의 알고리즘을 이용하여 프레임 동기화된 문자열을 음성 인 식 결과로서 생성할 수 있다. 그러나 본 개시는 이에 제한되지 않으며, 일 실시 예에 따른 디바이스는, 디바이스의 음성 인식 결과 가 프레임 동기화되지 않은 경우에도, 강제 정렬(forced alignment)을 수행함으로써, 프레임 동기화된 문자열을 생성할 수 있다. 프레임 동기화된 문자열 및 강제 정렬에 의해 프레임 동기화된 문자열을 생성하는 구체적인 방 법과 관련하여서는, 후에 도 6을 참조하여 구체적으로 설명한다. 본 개시의 일 실시 예에 따른 디바이스는, 온-디바이스 음성 인식을 이용한 음성 인식 수행 결과에 대한 신뢰도(confidence score)가 충분히 높은 경우, 음성 인식 수행 결과를 그대로 이용할 수 있다. 반면에, 본 개시의 일 실시 예에 따른 디바이스는, 온-디바이스 음성 인식을 이용하여 음성 인식을 수행한 결과의 신뢰도가 충분히 높지 않다고 판단하는 경우, 음성 인식 결과인 문자열을 서버에게 전송할 수 있다. 따라서, 본 개시의 일 실시 예에 따른 디바이스는, 온-디바이스 음성 인식을 이용하여 음성 인식을 수행한 결과의 신뢰도가 충분히 높지 않다고 판단하는 경우, 서버에게 음성 신호를 전송하여 음성 인식 과정을 처 음부터 서버에서 다시 시작하도록 하는 것이 아니므로 처리 시간을 감소시킬 수 있다는 장점이 있다. 본 개시의 일 실시 예에 따른 디바이스는, 온-디바이스 음성 인식을 이용하여 음성 인식을 수행한 결과의 신뢰도가 충분히 높지 않다고 판단하는 경우, 문장 단위, 단어 단위, 구 단위 또는 프레임 단위로 음성 인식 결 과인 문자열을 서버에게 전송할 수 있다. 일 실시 예에 따른 디바이스는, 음성 인식을 수행하여 문장 또는 구(句, phrase)를 구성하는 문자열을 획 득한 경우, 문장 또는 구에 포함되는 문자들을 모두 서버에게 전송하거나, 문장 또는 구에 포함되는 문자 들 중 일부를 서버에게 전송할 수 있다. 디바이스는, 문자열의 신뢰도에 기초하여, 신뢰도가 낮은 일 부의 문자들을 서버에게 전송할 수 있다. 일 실시 예에 따른 디바이스는, 서버에서 교정된 문자열을 수신하고, 교정이 필요 없다고 판단되어 서버에게 전송되지 않았던 문자열을 교정된 문자열과 조합할 수 있다. 일 실시 예에 따른 디바이스는, 조합된 문자열을 출력하거나, 조합된 문자열을 해석한 결과에 기초하여 음성 비서 서비스를 제공할 수 있다. 본 개시의 일 실시 예에 따른 서버는, 문장 단위, 단어 단위, 구 단위 또는 프레임 단위로 음성 인식 결과 인 문자열을 디바이스로부터 수신할 수 있다. 본 개시의 일 실시 예에 따른 서버는, 서버 내에 저장된 언어 모델 및 사전 정보를 이용하여, 수신된 제1 문자열의 오류를 교정할 수 있다. 서버는, 디바이스에 저장되는 언어 모델 보다 많은 양의 정보 를 포함하는 서버 내의 언어 모델을 이용하여, 제1 문자열로부터 제2 문자열을 획득할 수 있다. 서버(20 0)는, 제1 문자열에 포함되는 적어도 하나의 문자를 다른 문자로 대체함으로써 제2 문자열을 획득할 수 있다.제2 문자열은 제1 문자열에 포함되어 있던 오류가 교정된 문자열일 수 있다. 본 개시에서 일 실시 예에 따른 서버는, 디바이스로부터 수신된 제1 문자열에 포함되는 적어도 하나 의 문자를 다른 문자로 대체함으로써, 제1 문자열을 교정하고, 교정된 제1 문자열을 디바이스에게 전송할 수 있다. “제1 문자열을 교정하는 동작”은, 제1 문자열 보다 높은 신뢰도를 가지는 제2 문자열을 추천하여 출력하는 동 작을 의미할 수 있다. 따라서, 본 개시에서 ‘문자열의 교정’, ‘문자의 교정’, ‘소정 문자를 다른 문자로 대체’, ‘소정 문자 대신에 다른 문자를 추천’, ‘소정 문자열을 다른 문자열로 대체’, 및 ‘소정 문자열 대 신에 다른 문자열을 추천’하는 표현은 서로 대체되어 사용될 수 있다. 일 실시 예에 따른 서버는, 문장 또는 구를 구성하는 문자열을 디바이스로부터 획득한 경우, 문장 또 는 구에 포함되는 문자들에 대해서 교정을 수행하거나, 문장 또는 구에 포함되는 문자들 중 일부에 대해서 교정 을 수행할 수 있다. 서버는, 문자열의 신뢰도에 기초하여, 신뢰도가 낮은 일부의 문자들에 대해서 교정을 수행할 수 있다. 일 실시 예에 따른 서버는, 교정이 필요 없다고 판단되어 교정 과정을 거치지 않은 문자열과 교정된 문자 열을 조합할 수 있다. 일 실시 예에 따른 서버는, 조합된 문자열을 디바이스에게 전송할 수 있다. 본 개시의 일 실시 예에 따른 서버는, 도메인 별로 서로 다른 사전 정보 및 언어 모델을 이용하여, 수신된 문자열에 대한 디코딩을 수행하는 것이 가능하다. 본 개시의 일 실시 예에 따르면, 사전 정보가 서버 내에 저장되기 때문에, 신조어나 새로운 개체명을 쉽게 핫픽스 할 수 있다는 장점이 있다. 일 실시 예에 따른 서버는, 디바이스로부터 문자열을 수신하고, 수신된 문자열에 관련된 도메인을 선 택할 수 있다. 일 예로서, 서버는, 디바이스로부터 문자열과 함께 문자열에 관련된 도메인 정보를 수 신하고, 수신된 정보에 기초하여 문자열에 대한 디코딩을 수행할 도메인을 결정할 수 있다. 다른 예로서, 서버 는 디바이스로부터 수신된 문자열에 기초하여, 수신된 문자열에 관련된 도메인을 결정할 수 있다.일 실시예에 따른 서버는, 결정된 도메인에 대응되는 사전 정보 및 언어 모델을 이용하여, 수신된 문자열에 대한 디코딩을 수행할 수 있다. 따라서, 본 개시의 일 실시 예에 따른 서버는, 디바이스로부터 수신된 문자열에 대한 재 디코딩을 통 해 음성 인식 정확도가 높아진 음성 인식 결과를 출력할 수 있다. 예를 들어, 서버는, 디바이스로부 터 제1 문자열을 수신하고, 서버 내의 언어 모델 및 사전 정보를 이용하여 디코딩을 수행함으로써, 제1 문 자열에 포함되는 적어도 하나의 문자가 교정된 제2 문자열을 출력할 수 있다. 서버는, 제2 문자열을 디바이스에게 전송할 수 있다. 디바이스는, 제1 문자열보다 신뢰도가 높 은 제2 문자열을 서버로부터 수신하여 이용함으로써 음성 인식 성능을 높일 수 있다. 일 실시 예에 따른 서버가 문장을 구성하는 문자들을 포함하는 문자열을 디바이스로부터 획득한 경우, 전체 문장에 대해서 오류를 교정하거나, 문장을 구성하는 문자들 중 일부에 대해서 오류를 교정할 수 있 다. 서버는, 문자열의 신뢰도에 기초하여, 신뢰도가 낮은 일부의 문자들에 대해서 오류를 교정할 수 있다. 일 실시 예에 따른 서버는, 교정이 필요 없다고 판단되어 교정되지 않은 문자열을 교정된 문자열과 조합함으로써 제2 문자열을 획득 할 수 있다. 도 2a에 도시된 바와 같이 본 개시의 일 실시 예에 따른 서버는, 제2 문자열 자체를 음성 인식 결과로서 디바이스에게 전송할 수 있다. 그러나 실시 예는 도 2a에 도시된 예에 제한되지 않는다. 도 2b 및 도 2c에 도시된 바와 같이 본 개시의 일 실시 예에 따른 서버는, 제2 문자열에 대한 사용자의 발 화 의도를 파악함으로써 제2 문자열에 기초한 음성 비서 서비스에 관련된 정보를 디바이스에게 전송할 수 있다. 본 개시의 일 실시 예에 따른 서버는, 제1 문자열로부터 획득된 제2 문자열을 이용하여, 디바이스에 게 다양한 종류의 음성 비서 서비스를 제공할 수 있다. 음성 비서 서비스는, 사용자와의 대화를 제공하는 서비 스일 수 있다. 음성 비서 서비스는 사용자의 상황, 디바이스의 상황 등을 고려하여 사람이 사용자와 직접 대화 하는 것처럼 사용자에게 응답 메시지를 제공할 수 있다. 또한, 음성 비서 서비스는, 사용자의 개인 비서처럼 사 용자가 필요한 정보를 적절하게 생성하여 사용자에게 제공할 수 있다. 이 경우, 서버는 문자열에 기초하여 음성 비서 서비스를 제공하기 위하여, 서버 내의 NLU (Natural Language Understanding) 모델, DM (Dialog Mananer) 모델 및 NLG (Natural Language Generating) 모델 등을 이용하여, 사용자와의 대화를 수행하기 위한 정보를 디바이스에게 제공할 수 있다. 일 예로서, 서버는 제2 문자열을 해석한 결과를 바탕으로, 디바이스 또는 다른 디바이스(예를 들어, 스마트 가전, 웨어러블 디바이스 등)를 제어할 수 있다. 도 2b에 도시된 바와 같이, 일 실시예에 따른 서버는 문자열을 해석한 결과를 바탕으로, 디바이스를 제어하기 위한 제어 명령 또는 디바이스가 다른 디바이스를 제어하도록 하기 위한 제어 명령을 생성하고, 생성된 제어 명령을 디바이스에게 제공할 수도 있다. 또한, 도 2c에 도시된 바와 같이, 본 개시의 일 실시 예에 따른 서버는, 다양한 서비스들과 관련된 음성 비서 서비스를 제공할 수 있다. 예를 들어, 방송 서비스, 콘텐트 공유 서비스, 콘텐트 제공 서비스, 전력 관리 서비스, 게임 제공 서비스, 채팅 서비스, 문서 작성 서비스, 검색 서비스, 통화 서비스, 사진 촬영 서비스, 교 통 수단 추천 서비스 또는 동영상 재생 서비스 등의 다양한 서비스와 음성 비서 서비스가 연계되어, 음성 비서 서비스가 사용자가 필요한 정보 또는 기능을 제공할 수 있다. 본 개시의 일 실시 예에 따른 서버는, 제2 문자열에 기초하여 음성 비서 서비스에 관련된 정보를 디바이스 에게 전송할 수 있다. 음성 비서 서비스에 관련된 정보는, 사용자의 상황, 디바이스의 상황 등을 고려하여 사람이 사용자와 직접 대화하는 것처럼 사용자에게 제공되는 응답 메시지 또는 사용자가 필요한 정보를 포함할 수 있다. 또한, 서버는, 제2 문자열에 기초하여 사용자의 발화 의도를 파악하고, 서비스 제공 서버에게 사용자 가 필요로 하는 서비스의 제공을 요청할 수 있다. 서비스 제공 서버는, 방송 서비스, 콘텐트 공유 서비스, 콘텐트 제공 서비스, 전력 관리 서비스, 게임 제공 서비스, 채팅 서비스, 문서 작성 서비스, 검색 서비스, 통화 서비스, 사진 촬영 서비스, 교통 수단 추천 서비스 또는 동영상 재생 서비스 중 적어도 하나의 서비스를 제공할 수 있다. 도 2c에서는 음성 비서 서비스를 제공하는 서버가 하나의 서비스 제공 서버와 연결되는 것으로 도시 되었으나, 본 개시는 도 2c에 도시된 바에 제한되지 않는다. 예를 들어, 본 개시의 일 실시예에 따라 서버(20 0)는, 복수의 서비스 제공 서버들과 연결되며, 사용자의 발화 의도에 따라 사용자가 필요로 하는 서비스를 결정 할 수 있다. 서버는, 결정된 서비스에 대응하는 서비스 제공 서버를 선택하고, 선택된 서비스 제공 서버에 게 서비스 제공 요청을 전송할 수 있다. 일 실시예에 따른 서비스 제공 서버는, 음성 비서 서비스 제공 서버로부터 수신되는 서비스 요청에 기초하여, 요청된 서비스와 관련된 정보를 제공할 수 있다. 예를 들어, 서비스 제공 서버는, 요청된 서비 스와 관련된 정보로서, 방송, 콘텐트, 애플리케이션, 교통 수단 추천 정보, 및 검색 결과 등을 제공할 수 있다. 서비스 제공 서버는, 음성 비서 서비스 제공 서버 또는 디바이스에게 요청된 서비스와 관련된 정보를 제공할 수 있다. 이하에서는, 본 개시의 일 실시 예에 따라 음성 인식 결과인 문자열을 선택적으로 서버에게 전송하여 문자 열의 교정을 요청하는 디바이스 및 수신된 문자열에 대한 교정을 수행하는 서버 각각의 구성 및 동작 방법을 구체적으로 설명한다. 도 3은 일 실시 예에 따른 디바이스의 블록도를 도시한다. 본 개시의 일 실시 예에 따른 디바이스는 컴퓨터 장치로 구현되는 고정형 단말이거나 이동형 단말일 수 있 다. 디바이스는, 예를 들어, 스마트 폰(smart phone), 휴대폰, 내비게이션, 컴퓨터, 노트북, 디지털방송용 단말, 인공 지능 스피커, 스피커, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 및 태블릿 PC 중 적어도 하나일 수 있으나, 이에 한정되지 않는다. 디바이스는, 무선 또는 유선 통신 방식을 이용하여 네트워크를 통해 다른 디바이스 및/또는 서버와 통신할 수 있다. 도 3을 참조하면, 디바이스는, 수신부, 프로세서, 통신부, 메모리, 및 출력부 를 포함할 수 있다. 도 3에 도시된 구성 요소 모두가 디바이스의 필수 구성 요소인 것은 아니다. 도 3에 도시된 구성 요소보다 많은 구성 요소에 의해 디바이스가 구현될 수도 있고, 도 3에 도시된 구성 요소보다 적은 구성 요소에 의해 디바이스가 구현될 수도 있다. 예를 들어, 도 19에 도시된 바와 같이, 일부 실시 예에 따른 디바이스는, 사용자 입력부, 센싱부, 및 A/V 입력부를 더 포함할 수도 있다. 본 개시의 일 실시 예에 따른 수신부는 사용자로부터 음성 신호를 입력 받을 수 있다. 예를 들어, 수신부 는, 마이크로폰(Microphone)에 의해 외부의 소리를 전기적인 음향 데이터로 변환함으로써 음성 신호를 수 신할 수 있다. 도 3에는, 수신부가, 디바이스의 내부에 포함되는 것으로 도시되었으나, 다른 일 실시 예에 따른 수신부는 별도의 디바이스 내에 포함되고 디바이스와는 유, 무선으로 연결되는 형태로 구 현될 수 있다. 본 개시의 일 실시 예에 따른 메모리는, 음성 인식을 수행하기 위한 인스트럭션들, 음성 인식에 이용되는 각종 모델, 신경망, 사전 정보 등을 저장할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 메모리에 저장된 하나 이상의 인스터럭션들을 실행함으로 써, 음성 인식을 수행할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 음성 신호에 대한 음성 인식의 결과로서 제1 문자열을 획득할 수 있다. 예를 들어, 제1 문자열은, 음성 신호가 소정 시간 간격으로 분할된 음성 신호 프레임들 각각에 대응하는 문자들 을 포함하는 프레임 동기화된 문자열일 수 있다. 또는, 제1 문자열은, 음성 신호에 의해 발음되는 각 문자를 하 나씩 포함하도록 라벨 동기화 방식으로 획득된 문자열일 수 있다. 다음으로 본 개시의 일 실시 예에 따른 프로세서는, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정하 고, 결정에 기초하여 통신부를 통해 제1 문자열을 서버에게 전송할 수 있다. 일 실시예에 따른 프로 세서는, 문장 단위, 단어 단위, 구 단위 또는 프레임 단위로 제1 문자열을 서버에게 전송할 수 있다. 일 실시 예에 따른 프로세서는, 음성 인식을 수행하여 문장 또는 구를 구성하는 문자열을 획득한 경우, 문 장 또는 구에 포함되는 문자들을 모두 서버에게 전송하거나, 문장 또는 구에 포함되는 문자들 중 일부를 서버에게 전송할 수 있다. 프로세서는, 문자열의 신뢰도에 기초하여, 신뢰도가 낮은 일부의 문자들을 서버에게 전송할 수 있다. 제1 문자열을 다른 문자열로 대체할 지 여부를 결정한다는 것은, 음성 인식이 실패하였다고 판단하고 제1 문자 열을 다른 문자열로 대체하여 이용할 것을 결정하는 것을 의미할 수 있다. 또는, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정한다는 것은, 서버에서 추가적으로 음성 인식을 수행함으로써 획득된 다른 문자열로 제1 문자열을 대체할 지 여부를 결정한다는 것을 의미할 수 있다. 일 예로서, 프로세서는 제1 문자열의 신뢰도를 결정하고, 신뢰도에 기초하여 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 제1 문자열의 신뢰도는, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도, 및 제1 문자열 내의 적어 도 하나의 문자가 다른 문자로 대체될 사후 확률들 중 적어도 하나에 기초하여 계산될 수 있다. 예를 들어, 프로세서는, 비터비(Viterbi) 디코딩 결과 출력되는 가능도에 기초하여 신뢰도를 계산할 수 있 다. 또는, 프로세서는, 엔드-투-엔드 방식 음성 인식 모델에서 소프트맥스 레이어로부터 출력되는 사후 확 률들에 기초하여 신뢰도를 계산할 수 있다. 또는, 일 실시 예에 따른 프로세서는, 음성 신호에 대한 음성 인식 과정에서 추정되는 복수의 추정 문자열 들을 결정하고, 복수의 추정 문자열들의 상관도에 기초하여, 제1 문자열의 신뢰도를 계산할 수 있다. 제1 문자 열을 포함하는 복수의 추정 문자열들의 상관도가 높을 수록, 제1 문자열의 신뢰도가 높을 수 있다. 다른 예로서, 프로세서는, 디바이스에 미리 저장된 키워드들과 제1 문자열을 비교한 결과에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 예를 들어, 프로세서는, 제1 문 자열에 미리 저장된 키워드들이 포함되지 않는 경우, 제1 문자열을 다른 문자열로 대체할 것을 결정할 수 있다. 또 다른 예로서, 프로세서는, 제1 문자열이 관련된 도메인 또는 제1 문자열 내에 개체명이 포함되는지 여 부에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 예를 들어, 프로세서는, 제1 문자열이 개체명 위주의 도메인과 관련이 있다고 판단되거나 또는 오픈 도메인과 관련이 없다고 판단되는 경우, 제1 문자열을 다른 문자열로 대체할 것을 결정할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 제1 문자열을 다른 문자열로 대체하여야 한다고 결정되는 경우, 이러한 결정에 기초하여 제1 문자열을 서버로 전송하도록 통신부를 제어할 수 있다. 한편, 본 개시의 일 실시 예에 따른 통신부는 유선 통신 또는 무선 통신을 통해 외부 디바이스, 장치 또는 서버와 통신할 수 있다. 통신부는, 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈, 방송 수신 모듈등을 포함할 수 있다. 일 실시 예에 따른 프로세서는, 음성 신호에 대한 음성 인식 결과가 프레임 동기화된 문자열이 아닌 경우, 제1 문자열에 대한 강제 정렬을 수행함으로써 프레임 동기화된 문자열을 생성하여 서버에게 전송할 수 있 다. 일 실시 예에 따른 프로세서는, 제1 문자열에 포함되는 각 문자가 발음되는 음성 신호 구간을 식별하고, 식별된 음성 신호 구간에 포함되는 복수의 음성 프레임들을 식별할 수 있다. 프로세서는, 식별된 음성 프 레임들에 따라 해당 문자를 복수 회 연속하여 배치함으로써, 프레임 동기화된 문자열을 획득할 수 있다. 예를 들어, 프로세서는, 제1 문자열에 포함되는 소정 문자의 발음 시간이 n 프레임(n은 자연수)인 경우, n 개의 소정 문자를 연속하여 나열함으로써 프레임 동기화된 문자열을 획득할 수 있다. 통신부는, 서버로부터 제2 문자열을 수신할 수 있다. 제2 문자열은, 서버에 의해 제1 문자열 내 의 적어도 하나의 문자가 다른 문자로 대체됨으로써 획득된 문자열이다. 또한, 통신부는, 서버에 의 해 제2 문자열에 대한 해석에 기초하여 생성된 응답 메시지를 서버로부터 수신할 수도 있다. 본 개시의 일 실시 예에 따른 프로세서는, 제1 문자열의 교정이 필요하지 않다고 판단되는 경우, 제1 문자 열을 다른 문자열로 대체하지 않을 것을 결정 할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 제1 문자열을 다른 문자열로 대체하지 않을 경우, 제1 문자열을 출력부를 통해 출력할 수 있다. 반면에, 프로세서는, 제1 문자열의 교정이 필요하다고 판단되는 경우, 제1 문자열을 다른 문자열로 대체할 것을 결정 할 수 있다. 제1 문자열을 다른 문자열로 대체하여야 한다고 판단되는 경우, 출력부는, 제1 문 자열 대신에, 서버로부터 수신된 제2 문자열을 출력할 수 있다. 본 개시의 일 실시 예에 따라 디바이스에서 획득되는 제1 문자열은, 제1 사전 정보 및 제1 언어 모델에 기 초하여 획득된 문자열일 수 있다. 본 개시의 일 실시 예에 따라 서버에서 획득되는 제2 문자열은, 서버 내에 저장되는 제2 사전 정보 및 제2 언어 모델에 기초하여 획득된 문자열일 수 있다. 서버 내에 저장되는 제2 사전 정보 및 제2 언어 모델은, 제1 사전 정보 및 제1 언어 모델보다 많은 양의 정보를 포함할 수 있다. 따라서, 서버로부터 수신된 제2 문자열은 제1 문자열보다 높은 신뢰도를 가질 수 있다. 디바이스는, 제1 문자열보다 신뢰도가 높은 제2 문자열을 서버로부터 수신하여 이용함으로써 음성 인식 성능을 높일 수 있다. 본 개시의 일 실시 예에 따른 출력부는, 제1 문자열 또는 제2 문자열을 그대로 출력하거나, 제1 문자열 또 는 제2 문자열로부터 획득되는 단어열을 출력할 수 있다. 예를 들어, 제1 문자열이 프레임 동기화된 문자열인 경우, 출력부는, 제1 문자열로부터 획득된 단어열을 출력할 수 있다. 본 개시의 일 실시 예에 따른 출력부는, 제1 문자열 또는 제2 문자열에 기초하여 음성 인식이 수행된 결과 를 출력 할 수 있다. 출력부는, 음성 인식이 수행된 결과를 사용자에게 알리거나, 외부 디바이스(예를 들 어, 스마트 폰, 가전 제품, 웨어러블 디바이스, 서버 등)에게 전송할 수 있다. 예를 들어, 출력부는, 오디 오 신호를 출력할 수 있는 스피커 또는 비디오 신호를 출력 할 수 있는 디스플레이를 포함할 수 있다. 또는, 출력부는, 음성 인식이 수행된 결과에 대응하는 동작을 수행할 수 있다. 예를 들어, 디바이스 는, 제1 문자열 또는 제2 문자열을 해석하고, 해석 결과에 대응하는 디바이스의 기능을 결정할 수 있다. 디바이스는, 해당 기능을 수행하는 화면을 출력부를 통해 출력할 수 있다. 또는, 디바이스는, 해석 결과에 대응하는 키워드를 외부 서버로 전송하고, 전송된 키워드에 관련된 정보를 서버로부터 수신하여 출 력부를 통해 화면 상에 출력할 수 있다. 또는, 디바이스는, 해석 결과에 기초하여, 음성 신호에 대한 응답 메시지를 생성하고, 응답 메시지를 출력부를 통해 출력할 수 있다. 일 실시예에 따른 디바이스는, 제1 문자열 또는 제2 문자열에 대한 자연어 처리를 통해 사용자의 발화 의 도를 파악함으로써, 음성 비서 서비스에 관련된 정보를 출력부를 통해 출력 할 수 있다. 디바이스는 제1 문자열 또는 제2 문자열에 기초하여 음성 비서 서비스를 제공하기 위하여, 디바이스 내의 NLU (Natural Language Understanding) 모델, DM (Dialog Mananer) 모델 및 NLG (Natural Language Generating) 모델 등을 이용할 수 있다. 또는, 출력부는, 서버로부터 제2 문자열에 기초한 음성 비서 서비스에 관련된 정보를 수신하고, 수신 된 정보를 출력할 수 있다. 예를 들어, 제2 문자열에 기초한 음성 비서 서비스에 관련된 정보는, 제2 문자열에대한 자연어 처리를 통해 사용자의 발화 의도를 해석한 결과를 바탕으로 생성되는 디바이스 또는 다른 디 바이스를 제어하기 위한 제어 명령을 포함할 수 있다. 또는, 예를 들어, 제2 문자열에 기초한 음성 비서 서비스 에 관련된 정보는, 제2 문자열에 대한 자연어 처리를 통해 사용자의 발화 의도를 해석한 결과를 바탕으로 제공 되는 사용자가 필요로 하는 서비스, 또는 사용자가 필요로 하는 정보를 포함할 수 있다. 한편, 일 실시예에 따른 프로세서가, 문장 또는 구에 포함되는 문자들 중 일부만을 서버에게 전송한 경우, 프로세서는, 서버로부터 수신된 교정된 문자열과 교정이 필요 없다고 판단되어 서버에게 전송되지 않았던 문자열을 조합할 수 있다. 프로세서는 조합된 문자열을 출력하거나, 조합된 문자열에 기 초하여 음성 인식이 수행된 결과를 출력하거나, 조합된 문자열을 해석한 결과에 기초하여 음성 비서 서비스를 제공할 수 있다. 이하에서는, 도 4a 및 도 4b를 참조하여 디바이스의 동작 방법을 구체적으로 설명한다. 도 4a는 일 실시 예에 따른 디바이스의 구체적인 블록도를 도시한다. 도 4a에 도시된 바와 같이, 프로세서의 ASR 모듈은 수신부에서 획득된 음성 신호를 수신하고, 음성 신호에 대한 음성 인식을 수행할 수 있다. 도 4a의 ASR 모듈은 엔드-투-엔드 방식으로 음성 신호에 대한 음성 인식을 수행할 수 있다. 엔드-투-엔드 방식이란, 음성 신호를 문자열 또는 단어 열로 직접 매핑할 수 있도록 훈련된 심층 신경망을 이용한 음성 인식 방식이다. 음향모델 및 언어모델 등의 다수의 모델들을 이용하는 다른 음성 인식 방식과 비교하면, 엔드-투-엔 드 방식은 하나의 훈련된 심층 신경망을 이용함으로써 음성 인식 과정을 단순화할 수 있다. 엔드-투-엔드 음성 인식 모델의 하위 실시 예로는, RNN-T 모델, 및 CTC 모델 등이 존재한다. ASR 모듈은, 음성 신호로부터 특징 벡터를 추출할 수 있다. ASR 모듈은, 메모리에 저장된 심층 신경망(DNN)을 이용하여, 특징 벡터로부터 제1 문자열을 출력할 수 있다. 본 개시의 일 실시 예에 따른 프로세서의 결정부는, ASR 모듈에서 출력된 제1 문자열의 신뢰도 에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 결정부는, ASR 모듈로 부터 제1 문자열에 관한 신뢰도 정보를 수신할 수 있다. 일 실시 예에 따른 결정부는, 제1 문자열에 관한 신뢰도 정보로서 ASR 모듈 내의 소프트맥스 레이어 로부터 출력되는 사후 확률 값을 수신할 수 있다. 결정부는, 제1 문자열과 관련된 사후 확률 값에 기초하 여 신뢰도를 계산할 수 있다. 예를 들어, 결정부는, 신뢰도가 임계값 보다 높거나 같으면, 제1 문자열의 교정이 필요하지 않은 것으로 판단하고 제1 문자열을 출력부를 통해 출력할 수 있다. 반면에, 결정부는, 신뢰도가 임계값 보다 작 으면, 제1 문자열의 교정이 필요하다고 판단하고 제1 문자열을 통신부를 통해 서버에게 전송할 수 있 다. 도 4a에서는 설명의 편의를 위하여, 제1 문자열이 출력부를 통해 출력되는 경우를 예로 들어 도시하였지만 본 개시는 이에 제한되지 않는다. 일 실시예에 따른 디바이스는, 제1 문자열에 대한 자연어 처리를 통해 사용자의 발화 의도를 파악함으로써, 음성 비서 서비스에 관련된 정보를 출력부를 통해 출력 할 수 있다. 디바이스는 제1 문자열에 기초하여 음성 비서 서비스를 제공하기 위하여, 디바이스 내의 NLU (Natural Language Understanding) 모델, DM (Dialog Mananer) 모델 및 NLG (Natural Language Generating) 모델 등을 이용할 수 있다. 예를 들어, 디바이스의 프로세서는, 사용자의 상황, 디바이스의 상황 등을 고려하여 사람이 사용자와 직접 대화하는 것처럼, 사용자에게 제1 문자열에 대한 응답 메시지를 생성하고 출력부를 통해 출력할 수 있다. 또는, 예를 들어, 프로세서는, 제1 문자열에 기초하여 사용자가 필요한 정보를 생성하여 출력부 를 통해 사용자에게 제공할 수 있다. 또는, 예를 들어, 프로세서는, 제1 문자열에 기초하여 사용자의 발화 의도를 파악하고, 서비스 제공 서버에게 사용자가 필요로 하는 서비스의 제공을 요청할 수 있다. 출력부 는, 서비스 제공 서버로부터 수신된 정보를 출력할 수 있다. 또한, 일 실시예에 따른 디바이스의 출력부는, 서버로부터 음성 비서 서비스에 관련된 정보를 수신하고, 수신된 정보를 출력할 수 있다. 음성 비서 서비스에 관련된 정보는, 제1 문자열 또는 제1 문자열이 교정된 제2 문자열에 기초하여 서버에 의해 생성되는 정보일 수 있다. 예를 들어, 음성 비서 서비스에 관련된 정보는, 사용자의 음성 신호에 대한 응답 메시지, 사용자가 필요로 하는 서비스, 또는 사용자가 필요한 정 보를 포함할 수 있다. 한편, 도 4b는 다른 일 실시 예에 따른 디바이스의 구체적인 블록도를 도시한다. 도 4b에 도시된 바와 같이, 프로세서의 ASR 모듈은 수신부에서 획득된 음성 신호를 수신하고, 음성 신호에 대한 음성 인식을 수행할 수 있다. 음소열 획득부는, 메모리에 저장된 음향 모델을 이용하여, 음성 신호로부터 음소열을 획득할 수 있다. 음향 모델은, 음성 신호의 파형을 분할하고, 은닉 마르코프 모델, 가우스 혼합 모델, 베이즈 추론, 또는 다층 신경망 등을 이용하여 음소들을 포함하는 음소열을 추정할 수 있다. 프로세서의 문자열 획득부는, 메모리에 저장된 사전 정보 및 언어 모델에 기초하여, 음소열로부터 단어들을 추정하고 추정된 단어들을 포함하는 문자열을 출력할 수 있다. 본 개시의 일 실시 예에 따른 프로세서의 결정부는, ASR 모듈에서 출력된 제1 문자열의 신뢰도 를 계산하고, 계산된 신뢰도에 기초하여 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 결정부 는, ASR 모듈로부터 제1 문자열에 관한 신뢰도 정보를 수신할 수 있다. 일 실시 예에 따른 결정부는, 제1 문자열에 관한 신뢰도 정보로서 ASR 모듈 내의 비터비 디코더로부 터 출력되는 제1 문자열의 부분 가능도 값(partial likelihood)에 기초하여 신뢰도를 계산할 수 있다. 일 실시 예에 따른 결정부는, 신뢰도가 임계값 보다 높거나 같으면, 제1 문자열의 교정이 필요하지 않은 것으로 판단하고 제1 문자열을 출력부를 통해 출력할 수 있다. 반면에, 결정부는, 신뢰도가 임계값 보다 작으면, 제1 문자열의 교정이 필요하다고 판단하고 제1 문자열을 통신부를 통해 서버에게 전송 할 수 있다.도 4b에서는 설명의 편의를 위하여, 제1 문자열이 출력부를 통해 출력되는 경우를 예로 들어 도시하였지만 본 개시는 이에 제한되지 않는다. 일 실시예에 따른 디바이스는, 제1 문자열에 대한 자연어 처리를 통해 사용자의 발화 의도를 파악함으로써, 음성 비서 서비스에 관련된 정보를 출력부를 통해 출력 할 수 있다. 디바이스는 제1 문자열에 기초하여 음성 비서 서비스를 제공하기 위하여, 디바이스 내의 NLU (Natural Language Understanding) 모델, DM (Dialog Mananer) 모델 및 NLG (Natural Language Generating) 모델 등을 이용할 수 있다. 예를 들어, 디바이스의 프로세서는, 사용자의 상황, 디바이스의 상황 등을 고려하여 사람이 사용자와 직접 대화하는 것처럼, 사용자에게 제1 문자열에 대한 응답 메시지를 생성하고 출력부를 통해 출력할 수 있다. 또는, 예를 들어, 프로세서는, 제1 문자열에 기초하여 사용자가 필요한 정보를 생성하여 출력부 를 통해 사용자에게 제공할 수 있다. 또는, 예를 들어, 프로세서는, 제1 문자열에 기초하여 사용자의 발화 의도를 파악하고, 서비스 제공 서버에게 사용자가 필요로 하는 서비스의 제공을 요청할 수 있다. 출력부 는, 서비스 제공 서버로부터 수신된 정보를 출력할 수 있다. 또한, 일 실시예에 따른 디바이스의 출력부는, 서버로부터 음성 비서 서비스에 관련된 정보를 수신하고, 수신된 정보를 출력할 수 있다. 음성 비서 서비스에 관련된 정보는, 제1 문자열 또는 제1 문자열이 교정된 제2 문자열에 기초하여 서버에 의해 생성되는 정보일 수 있다. 예를 들어, 음성 비서 서비스에 관 련된 정보는, 사용자의 음성 신호에 대한 응답 메시지, 사용자가 필요로 하는 서비스, 또는 사용자가 필요한 정 보를 포함할 수 있다. 상술한 바와 같이, 본 개시의 일 실시 예에 따른 디바이스는, 음성 신호에 대한 음성 인식 결과의 신뢰도 에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 그러나 본 개시는 이러한 실시 예 에 제한되지 않으며, 다른 일 실시 예에 따르면, 디바이스는, 디바이스에 미리 저장된 키워드들과 문 자열을 비교한 결과에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 또는, 다른 일 실시 예에 따른 디바이스는, 제1 문자열이 관련된 도메인에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 또는, 다른 일 실시 예에 따른 디바이스는, 자연어 이해 처리를 통해 제1 문자 열의 의미를 해석하고, 해석한 결과에 기초하여 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 도 5a는 일 실시 예에 따라 디바이스가 온-디바이스 음성 인식을 수행할 것을 판단하는 방법을 설명하기 위한 도면이다. 일 예로서, 본 개시의 일 실시 예에 따른 디바이스의 프로세서의 결정부는, 디바이스에 미 리 저장된 키워드들과 제1 문자열을 비교한 결과에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결 정할 수 있다. 일 실시 예에 따른 결정부는, 제1 문자열에 미리 저장된 키워드들 중 적어도 하나가 포함된 경우, 제1 문 자열을 다른 문자열로 대체하지 않을 것을 결정할 수 있다. 따라서, 디바이스는, 서버의 개입 없이, 디바이스의 ASR 모듈에서 수행된 음성 인식 수행 결과를 그대로 이용할 수 있다. 예를 들어, ASR 모듈로부터 출력된 제1 문자열이 “Read me my text”인 경우, 결정부는, 제1 문자열 이 미리 저장된 키워드인 \"text\"를 포함하는 것으로 판단하고, 제1 문자열을 다른 문자열로 대체하지 않을 것을 결정할 수 있다. 다른 예로서, 본 개시의 일 실시 예에 따른 디바이스의 프로세서의 결정부는, 제1 문자열이 관 련된 도메인 또는 제1 문자열 내에 개체명이 포함되는지 여부에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 일 실시 예에 따른 결정부는, 제1 문자열이 개체명 위주의 도메인과 관련이 없고, 오픈 도메인과 관련이 있다고 판단되는 경우, 제1 문자열을 다른 문자열로 대체하지 않을 것을 결정할 수 있다. 따라서, 디바이스 는, 서버의 개입 없이, 디바이스의 ASR 모듈에서 수행된 음성 인식 수행 결과를 그대로 이 용할 수 있다. 예를 들어, ASR 모듈로부터 출력된 제1 문자열이 “Take a picture”인 경우, 결정부는, 제1 문자열 이 오픈 도메인과 관련이 있다고 판단하고, 제1 문자열을 다른 문자열로 대체하지 않을 것을 결정할 수 있다. 일 실시 예에 따른 결정부는, 제1 문자열에 개체명이 포함된다고 판단되는 경우, 제1 문자열을 다른 문자 열로 대체할 것을 결정할 수 있다. 본 개시의 일 실시 예에 따른 결정부는, 메모리에 저장되어 있는 개체명들 중 적어도 하나가 제1 문 자열 내에 포함되는지 여부를 판단할 수 있다. 또는, 개체명에 대한 사전 정보 없이도, 일 실시 예에 따른 결정 부는, 제1 문자열 내에 개체명이 포함되는지 여부를 판단할 수 있다. 예를 들어, 결정부는, 제1 문자 열로부터 식별되는 단어들의 품사 태깅(POS Tagging, Part-Of-Speech Tagging)을 함으로써, 제1 문자열 내에 포함되어 있는 개체명을 식별할 수 있다. 예를 들어, ASR 모듈로부터 출력된 제1 문자열이 “Take a picture”인 경우, 결정부는, 제1 문자열 이 개체명을 포함하지 않는다고 판단하고, 제1 문자열을 다른 문자열로 대체하지 않을 것을 결정할 수 있다. 또 다른 예로서, 본 개시의 일 실시 예에 따른 디바이스의 프로세서의 결정부는, 자연어 이해 처리를 통해 제1 문자열의 의미를 해석하고, 해석한 결과에 기초하여 제1 문자열을 다른 문자열로 대체할 지 여 부를 결정할 수 있다. 일 실시 예에 따른 결정부는, 제1 문자열을 해석한 결과, 음성 신호가 디바이스의 동작과 관련된 일 반적인 명령이라고 판단되는 경우, 제1 문자열을 다른 문자열로 대체하지 않을 것을 결정할 수 있다. 따라서, 디바이스는, 서버의 개입 없이, 디바이스의 ASR 모듈에서 수행된 음성 인식 수행 결과를 그대로 이용할 수 있다. 예를 들어, ASR 모듈로부터 출력된 제1 문자열이 “Do I have any new voice mail?”인 경우, 결정부 는, 제1 문자열이 텍스트 메시지의 확인과 관련된 일반적인 명령이라고 판단하고, 제1 문자열을 다른 문자 열로 대체하지 않을 것을 결정할 수 있다. 한편, 도 5b는 일 실시 예에 따라 디바이스가 서버 기반 음성 인식을 수행할 것을 판단하는 방법을 설명하기 위 한 도면이다. 도 5b에 도시된 바와 같이, 일 실시 예에 따른 디바이스의 프로세서의 결정부는, 제1 문자열을 다른 문자열로 대체하여야 한다고 결정하고, 이러한 결정에 기초하여 제1 문자열을 서버로 전송할 수 있다. 도 5b는, 디바이스의 ASR 모듈이, 사용자가 “The Cardinals baseball team\"을 발음한 음성 신호를 수신하고, 제1 문자열 [the cat and deers baseball team]을 획득한 경우를 예로서 도시한다. 일 예로서, 본 개시의 일 실시 예에 따른 디바이스의 프로세서의 결정부는, 제1 문자열이 미리 저장된 키워드들을 포함하지 않으므로, 제1 문자열을 다른 문자열로 대체할 것을 결정할 수 있다. 다른 예로서, 본 개시의 일 실시 예에 따른 디바이스의 프로세서의 결정부는, 제1 문자열이 스 포츠 도메인과 관련이 있다고 판단되거나 개체명이 포함된다고 판단되는 경우, 제1 문자열을 다른 문자열로 대 체할 것을 결정할 수 있다. 본 개시의 일 실시 예에 따른 결정부는, 메모리에 저장되어 있는 개체명들 중 적어도 하나가 제1 문 자열 내에 포함되는지 여부를 판단할 수 있다. 또는, 개체명에 대한 사전 정보 없이도, 일 실시 예에 따른 결정 부는, 제1 문자열 내에 개체명이 포함되는지 여부를 판단할 수 있다. 예를 들어, 결정부는, 제1 문자 열로부터 식별되는 단어들의 품사 태깅(POS Tagging, Part-Of-Speech Tagging)을 함으로써, 제1 문자열 내에 포함되어 있는 개체명을 식별할 수 있다. 그러나 실시 예는 이에 제한되지 않으며, 다양한 방식의 개체명 인식 (Named Entity Recognition, NER) 방법이 이용될 수 있다. 또 다른 예로서, 본 개시의 일 실시 예에 따른 디바이스의 프로세서의 결정부는, 제1 문자열을 해석한 결과, 음성 신호가 일반적인 명령이 아니라고 판단하고, 제1 문자열을 다른 문자열로 대체할 것을 결정 할 수 있다. 도 5b에 도시된 바와 같이, 일 실시 예에 따른 디바이스의 결정부는, 제1 문자열을 다른 문자열로 대 체하여야 한다고 결정하고, 이러한 결정에 기초하여 제1 문자열을 서버로 전송할 수 있다. 서버는, 디바이스로부터 제1 문자열을 수신하고, 서버 내의 언어 모델 및 사전 정보(예를 들어, 스포츠 도메 인의 사전 정보)을 이용하여 디코딩을 수행할 수 있다. 서버는, 디코딩 결과, 제1 문자열에 포함되는 적어 도 하나의 문자가 수정된 제2 문자열을 획득할 수 있다. 디바이스는, 서버로부터 제2 문자열을 수신 하여 이용함으로써, 음성 인식의 정확도를 높일 수 있다. 한편, 본 개시의 일 실시 예에 따른 디바이스는, 음성 인식을 수행하여 문장 또는 구를 구성하는 문자열을 획득한 경우, 문장 또는 구에 포함되는 문자들을 모두 서버에게 전송하거나, 문장 또는 구에 포함되는 문 자들 중 일부를 서버에게 전송할 수 있다. 디바이스의 프로세서의 결정부는, 문자열의 신 뢰도에 기초하여, 신뢰도가 낮은 일부의 문자들을 서버에게 전송할 것을 결정할 수 있다. 일 실시 예에 따른 디바이스는, 서버에서 교정된 문자열을 수신하고, 교정이 필요 없다고 판단되어 서버에게 전송되지 않았던 문자열을 교정된 문자열과 조합할 수 있다. 일 실시 예에 따른 디바이스는, 조합된 문자열을 출력하거나, 조합된 문자열에 기초하여 음성 인식이 수행된 결과를 출력하거 나, 조합된 문자열을 해석한 결과에 기초하여 음성 비서 서비스를 제공할 수 있다. 또한, 일 실시 예에 따른 디바이스는 서버에게 제1 문자열에 대한 교정을 요청하면서, 디바이스(10 0)의 제1 문자열에 관련된 도메인 정보를 서버에게 제공할 수 있다. 도메인 정보는 도메인을 식별하기 위 한 정보로서, 예를 들어, 도메인의 명칭, 도메인의 식별자를 포함할 수 있으나, 이에 제한되지 않는다. 디바이 스는 디바이스의 ASR 모델로부터 출력된 제1 문자열의 도메인 신뢰도에 기초하여, 제1 문자열에 관련 된 도메인을 식별할 수 있다. 도메인 신뢰도는, 제1 문자열의 적어도 일부가 특정 도메인에 어느 정도 관련되었 는지를 나타내는 수치일 수 있다. 예를 들어, 디바이스는 ASR 모델로부터 출력된 제1 문자열이 디바이스 에 미리 등록된 도메인에 어느 정도 관련성이 있는 지를 나타내는 컨피던스 스코어를 산출할 수 있다. 또 한, 디바이스는 산출된 도메인 신뢰도에 기초하여, 제1 문자열에 관련된 도메인을 식별할 수 있다. 디바이 스는 룰 기반으로 제1 문자열에 관련된 도메인을 식별하거나 도메인 식별을 위해 훈련된 인공 지능 모델을 이용하여 제1 문자열에 관련된 도메인 신뢰도를 획득할 수 있다. 도 6은 일 실시 예에 따른 프레임 동기화된 문자열을 설명하기 위한 도면이다. 도 6에 도시된 바와 같이, 본 개시의 일 실시 예에 따른 디바이스의 ASR 모듈은, 음성 신호가 소정 시간 간격으로 분할된 음성 신호 프레임(F)들 각각에 대응하는 문자들을 포함하는, 프레임 동기화된 문자 열을 출력할 수 있다. 예를 들어, ASR 모듈은, 사용자가 \"baseball\"이라고 발음하는 음성 신호를 수신하고, 프레임 동기화된 문 자열인 [b, b, a, , a, a, s, s, e, , b, b, a, a, l]을 출력할 수 있다. 그러나 본 개시는 이에 제한되지 않으며, 일 실시 예에 따른 ASR 모듈은, 음성 인식 결과로서 프레임 동기 화되지 않은 문자열(즉, 라벨 동기화 문자열)을 출력할 수 있다. 이 경우에도, 디바이스는, 음성 신호로부 터 획득된 문자열에 대한 강제 정렬을 수행함으로써, 프레임 동기화된 문자열을 생성할 수 있다.일 실시 예에 따른 디바이스의 프로세서는, 제1 문자열에 포함되는 각 문자가 발음되는 음성 신호 구 간을 식별하고, 식별된 음성 신호 구간에 포함되는 복수의 음성 프레임들을 식별할 수 있다. 프로세서는, 식별된 음성 프레임들에 따라 해당 문자를 복수 회 연속하여 배치함으로써, 프레임 동기화된 문자열을 획득할 수 있다. 예를 들어, ASR 모듈은 프레임 동기화 되지 않은 문자열인 제1 문자열 [b, a, s, e, b, a, l, l]을 출력 할 수 있다. 이 경우, 프로세서는, 제1 문자열에 포함되는 각 문자가 발음되는 시간에 기초하여, 각 문자 를 복수 회 연속하여 배치할 수 있다. 그 결과, 프로세서는, 프레임 동기화된 문자열인 [b, b, a, , a, a, s, s, e, , b, b, a, a, l]을 획득할 수 있다. 본 개시의 일 실시 예에 따른 디바이스는, 프레임 동기화된 문자열을 서버로 출력할 수 있다. 서버는, 디바이스로부터 수신된 프레임 동기화된 문자열에 대한 디코딩을 수행하고, 디코딩 수 행 결과에 기초하여 획득된 제2 문자열을 디바이스에게 전송할 수 있다. 도 7은 일 실시 예에 따른 서버의 블록도를 도시한다. 본 개시의 일 실시 예에 따른 서버는, 디바이스와 유선 또는 무선으로 연결될 수 있다. 도 7을 참조하면, 서버는, 통신부, 프로세서, 및 메모리를 포함할 수 있다. 도 7에 도시된 구성 요소 모두가 서버의 필수 구성 요소인 것은 아니다. 도 7에 도시된 구성 요소보다 많은 구성 요소에 의해 서버가 구현될 수도 있고, 도 7에 도시된 구성 요소보다 적은 구성 요소에 의해 서버가 구현될 수도 있다. 본 개시의 일 실시 예에 따른 서버의 메모리는, 음성 인식을 수행하기 위한 인스트럭션들, 음성 인식 에 이용되는 각종 모델, 신경망, 사전 정보 등을 저장할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 메모리에 저장된 하나 이상의 인스터럭션들을 실행함으로 써, 음성 인식을 수행할 수 있다. 한편, 본 개시의 일 실시 예에 따른 통신부는 유선 통신 또는 무선 통신을 통해 외부 디바이스, 또는 장치 와 통신할 수 있다. 통신부는, 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈, 방송 수신 모듈 등을 포함할 수 있다. 먼저, 본 개시의 일 실시 예에 따른 서버의 통신부는, 디바이스로부터 제1 문자열을 수신할 수 있다. 제1 문자열은, 디바이스에 입력된 음성 신호로부터 디바이스에 의해 음성 인식 처리를 거쳐 출 력될 수 있다. 일 예로서, 서버에서 수신되는 제1 문자열은, 음성 신호가 소정 시간 간격으로 분할된 음성 신호 프레임들 각각에 대응하는 문자들을 포함하는 프레임 동기화 문자열일 수 있다. 다른 예로서, 서버에서 수신되는 제 1 문자열은, 프레임 동기화되지 않은 문자열일 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 디바이스로부터 수신되는 제1 문자열이 프레임 동기화되지 않은 문자열인 경우, 제1 문자열로부터 프레임 동기화된 문자열을 획득할 수 있다. 프로세서는, 제1 문자 열에 포함되는 적어도 하나의 문자를 소정 시간 간격의 프레임 단위로 연속하여 배치함으로써, 프레임 동기화된 문자열을 획득할 수 있다. 본 개시의 일 실시 예에 따른 서버의 프로세서는, 제1 문자열 내의 적어도 하나의 문자를 다른 문자 로 대체함으로써 제1 문자열로부터 제2 문자열을 획득할 수 있다. 본 개시의 일 실시예에 따라 프로세서는, 제1 문자열 내의 각 문자와 발음이 유사한 대체 문자들을 식별하 고, 식별된 대체 문자들에 기초하여 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 교정된 추정 문자열들 을 결정할 수 있다. 프로세서는, 결정된 추정 문자열들 중에서, 언어 모델 및 사전 정보 등 미리 저장된 정보에 기초하여 가장 적합한 추정 문자열을 선택하여 제2 문자열로서 획득할 수 있다. 이하에서는, 일 실시예에 따른 프로세서가 제2 문자열을 획득하는 방법을 보다 구체적으로 설명한다. 먼저, 프로세서는, 제1 문자열로부터 복수의 추정 문자열들을 식별할 수 있다. 프로세서는, 제1 문자 열 내의 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가능도 행렬들을 산출할 수 있다. 프로세서 는, 가능도 행렬들 내의 가능도 값들에 기초하여, 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 대체된 복수의 추정 문자열들을 식별할 수 있다. 일 실시 예에 따른 프로세서는, 제1 문자열로부터 복수의 추정 문자열들의 가능도를 계산할 수 있다. 프로 세서는, 제1 문자열 내의 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가능도 행렬들 내의 가 능도 값들에 기초하여, 복수의 추정 문자열들의 가능도를 계산할 수 있다. 제1 문자열로부터 획득되는 가능도는, 복수의 추정 문자열들 각각이 참값 문자열이라고 가정하였을 때, 음성 인 식 결과로서 제1 문자열이 추정될 가능성을 의미할 수 있다. 본 개시의 일 실시예에 따르면, 프로세서는, 제1 문자열 내의 각 문자와 발음이 유사한 대체 문자들을 식별하고, 식별된 대체 문자들에 기초하여 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 교정된 추정 문자열들을 결정하기 위하여, 제1 문자열로부터 획득되는 가능도를 이용할 수 있다. 프로세서는, 가능도, 사전 정보, 및 언어 모델에 기초하여, 복수의 추정 문자열들 중 하나인 제2 문자열을 획득할 수 있다. 프로세서는, 계산된 가능도에 기초하여, 제1 문자열을 제2 문자열로 대체할 지를 결정할 수 있다. 프로세서는, 결정에 기초하여, 제1 문자열 내의 적어도 하나의 문자를 다른 문자로 대체함으로써 제1 문자열로부터 제2 문자열을 획득할 수 있다. 일 실시 예에 따른 프로세서는, 후술하는 과정을 거쳐 제1 문자열로부터 가능도를 획득할 수 있다. 일 예로서, 프로세서는, 제1 문자열 내의 각 문자의 이전 문자들에 기초하여, 각 문자의 사후 확률들을 계 산할 수 있다. 제1 문자열 내의 소정 문자의 사후 확률들은, 이전 문자들을 고려하였을 때, 소정 문자가 복수의 다른 문자들로 대체될 확률들을 포함할 수 있다. 즉, 소정 문자의 사후 확률들은, 문자열 내에서 소정 문자의 이전 문자들을 고려하였을 때, 디바이스의 프로세서의 ASR 모듈이 소정 문자를 정확하게 예측했을 확 률 및 다른 문자를 소정 문자로 잘못 예측했을 확률을 포함할 수 있다. 다음으로, 프로세서는, 제1 문자열의 문자 배열 확률을 계산할 수 있다. 문자열의 문자 배열 확률이란, 해 당 문자열에 따라 문자들이 배열될 확률을 의미할 수 있다. 문자 배열 확률은, 문자열의 각 문자의 이 전에 누 적된 문자들에 기초하여 산출될 수 있다. 프로세서는, 각 문자의 사후 확률들 및 문자 배열 확률에 기초하 여, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도를 계산할 수 있다. 사후 확률들을 계산함에 있어서, 일 실시 예에 따른 프로세서는, 복수의 LSTM(long-short term memory) 레이어들 및 소프트맥스(softmax) 레이어를 포함하는 회귀 신경망(recurrent neural network, RNN)을 이용할 수 있다. 사후 확률들을 계산하기 위하여 이용되는 회귀 신경망과 관련하여서는, 후에 도 10a를 참조하여 보다 구체적으로 설명한다. 다른 예로서, 프로세서는, 미리 결정된 오차 행렬(confusion matrix)에 기초하여, 제1 문자열 내의 각 문 자의 사후 확률들을 계산할 수 있다. 프로세서는, 각 문자의 사후 확률들에 기초하여, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도를 계산할 수 있다. 사후 확률들을 계산하기 위하여 이용되는 오차 행 렬과 관련하여서는, 후에 도 10b를 참조하여 보다 구체적으로 설명한다. 또 다른 예로서, 프로세서는, 미리 결정된 확률 값들에 기초하여, 제1 문자열 내의 각 문자의 사후 확률들 을 계산할 수 있다. 프로세서는, 제1 문자열에 포함되는 제1 문자가 실제로도 제1 문자일 확률을 P로 결정 할 수 있다. P는 미리 결정된 값일 수 있다. P는 0 이상 1 이하의 값일 수 있다. 그리고, 프로세서는, 제1 문자열에 포함되는 제1 문자가 실제로는 제1 문자 이외의 다른 문자일 확률을 (1-P)/(N-1)로 결정할 수 있다. N 은 문자들의 개수를 의미하고, 자연수일 수 있다. 즉, 프로세서는, 디바이스의 프로세서의 ASR 모듈이 제1 문자열 내의 제1 문자를 정확하게 예측했을 확률을 P라고 결정하고, 다른 문자를 제1 문자로 잘못 예측했을 확률을 (1-P)/(N-1)로 결정할 수 있다. 예를 들어, 프로세서는, 제1 문자열에 포함되는 제1 문자가 실제로도 제1 문자일 확률을 0.9로 결정하고, 제1 문자가 실제로는 다른 문자일 확률을 0.1/(N-1)로 결정할 수 있다. 일 실시 예에 따른 프로세서는, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도를 계산하는 가 능도 계산부를 포함할 수 있다. 또한, 프로세서는, 사전 정보, 및 언어 모델을 이용하여, 가능도로부터 제 2 문자열을 획득하는 디코더를 포함할 수 있다. 프로세서는, 사전 정보 및 언어 모델을 이용하여, 제1 문 자열로부터 획득되는 가능도에 대한 재 디코딩을 수행함으로써 제2 문자열을 획득할 수 있다. 일 예로서, 프로세서의 디코더는, 서버 내에 저장되는 사전 정보 및 언어 모델을 기반으로 제2 문자 열을 획득할 수 있다. 디코더는, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도가 입력됨에 따라,제2 문자열을 출력할 수 있다. 예를 들어, 프로세서의 디코더는 WFST(weighted Finite State Transducer) 디코더를 포함할 수 있다. 프로세서가 WFST 디코딩을 수행하는 경우, 일 실시 예에 따른 서버는, 문자들 간의 관계(T), 단어와 문자들의 매핑 정보를 포함하는 사전 정보(L), 및 특정 단어열이 주어졌을 때 다음에 나올 단어들의 확률을 추 정하는 언어 모델(G)에 기초하여, WFST로 탐색 공간을 구성하여 디코딩할 수 있다. 다른 예로서, 프로세서의 디코더는, 사전 정보 및 언어 모델에 기초하여, 제1 문자열로부터 획득되는 복수 의 추정 문자열들의 가능도를 재연산할 수 있다. 디코더는, 재 연산된 가능도를 최대로 하는 제2 문자열을 복수 의 추정 문자열들 중에서 결정할 수 있다. 예를 들어, 프로세서의 디코더는, 비터비 디코더를 포함할 수 있다. 비터비 디코더는, 사전 정보 및 언어 모델을 고려하여, 제1 문자열들에 대한 가장 가능성 높은 문자열을 제2 문자열로서 찾아낼 수 있다. 본 개시의 일 실시 예에 따른 통신부는, 제2 문자열을 디바이스에게 전송할 수 있다. 또는, 통신부 는, 프로세서에서 생성된 음성 신호에 대한 응답 메시지를 디바이스에게 전송할 수 있다. 프로 세서는, 자연어 이해(Natural Language Understanding) 모델을 이용하여 제2 문자열을 해석하고, 해석한 결과에 기초하여 음성 신호에 대한 응답 메시지를 생성할 수 있다. 프로세서는, 제2 문자열을 해석한 결과에 대해 DM(Dialog Manager) 모델을 적용하여, 응답 메시지의 유형 을 결정할 수 있다. 프로세서는, NLG(Natural Language Generation) 모델을 이용하여, 결정된 유형의 응 답 메시지를 생성하고 디바이스에게 전송할 수 있다. 또는, 통신부는, 제2 문자열에 기초하여 생성된 음성 비서 서비스에 관련된 정보를 디바이스에게 전 송할 수 있다. 프로세서는 제2 문자열에 기초하여 음성 비서 서비스를 제공하기 위하여, 서버 내의 NLU 모델, DM 모델 및 NLG 모델 등을 이용하여, 사용자와의 대화를 수행하기 위한 정보를 디바이스에게 제 공할 수 있다. 또한, 프로세서는 제2 문자열을 해석한 결과를 바탕으로, 디바이스 또는 다른 디바이 스를 제어하기 위한 제어 명령을 생성하고, 생성된 제어 명령을 디바이스에게 제공할 수도 있다. 이하에서는 도 8a를 참조하여, 일 실시 예에 따른 서버의 각 구성이 디바이스의 음성 인식을 지원하 는 방법을 설명한다. 도 8a는 디바이스의 사용자가 “The Cardinals baseball team”을 발화한 경우를 예 로 들어 설명한다. 먼저, 디바이스는, 사용자의 음성 신호에 대한 음성 인식을 수행하여 [The cat and deers baseball tea m]이라는 제1 문자열을 추정할 수 있다. 디바이스는, 제1 문자열의 신뢰도, 제1 문자열이 관련된 도메인, 제1 문자열의 의미를 해석한 결과, 또는 제1 문자열에 개체명이 포함되는 지 여부에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 디바이스가 제1 문자열을 대체하기 위하여 서버-기반 음성 인식을 수행할 지 여부를 판단하는 구체 적인 방법에 관해서는, 도 4a 내지 도 5b를 참조하여 상술하였으므로 중복되는 설명은 생략한다. 도 8a에서 디바이스는, 제1 문자열을 다른 문자열로 대체하는 것이 필요하다고 판단하고, 제1 문자열 [The cat and deers baseball team]을 서버에게 전송할 수 있다. 제1 문자열을 서버에게 전송함에 있어서, 일 실시예에 따른 디바이스는 음성 신호와 관련된 정보를 제1 문자열과 함께 전송할 수 있다. 일 실시예에 따른 디바이스는, 제1 문자열 내의 각 문자가 나타내는 음성 신호 프레임의 길이와 관련된 정보를 제1 문자열과 함께 전송할 수 있다. 예를 들어, 디바이스는, 음 성 신호 프레임에 동기화된 제1 문자열을 서버에게 전송할 수 있다. 음성 신호 프레임에 동기화된 문자열 이란, 음성 신호가 소정 시간 간격으로 분할된 음성 신호 프레임들 각각에 대응하는 문자들을 포함하는 문자열 을 의미할 수 있다. 그러나 본 개시는 디바이스가 서버에게 프레임 동기화된 문자열을 전송하는 실시예에 제한되지 않는 다. 일 실시예에 따른 디바이스는 프레임 동기화되지 않은 제1 문자열을 서버에게 전송할 수 있다. 프레임 동기화되지 않은 제1 문자열은, 음성 신호에 의해 발음되는 각 문자를 하나씩 포함하도록 라벨 동기화 방식으로 획득된 문자열을 의미할 수 있다. 일 실시예에 따른 디바이스는, 프레임 동기화되지 않은 제1 문자열을 서버에게 전송하되, 음성 신호 와 관련된 정보를 제1 문자열과 함께 전송할 수 있다. 서버는, 음성 신호와 관련된 정보에 기초하여 제1 문자열을 강제 정렬함으로써 프레임 동기화된 문자열을 생성할 수 있다. 예를 들어, 음성 신호와 관련된정보는, 디바이스의 음성 인식 모델이 제1 문자열을 획득한 음성 신호 구간에 대한 정보를 포함할 수 있다. 본 개시의 일 실시 예에 따른 서버는, 통신부를 통해 디바이스로부터 제1 문자열을 수신할 수 있다. 일 실시예에 따른 서버는, 프레임 동기화된 제1 문자열을 수신할 수 있다. 그러나, 상술한 바와 같 이, 서버는, 프레임 동기화되지 않은 제1 문자열을 수신할 수도 있다. 이 경우, 서버는, 디바이스 에 의해 음성 신호로부터 획득된 제1 문자열과 함께 음성 신호와 관련된 정보를 디바이스로부터 수신 할 수 있다. 서버는, 음성 신호와 관련된 정보에 기초하여 제1 문자열을 강제 정렬함으로써 프레임 동기화 된 제1 문자열을 생성할 수 있다. 프로세서는, 제1 문자열로부터 복수의 추정 문자열들을 식별하고, 복수의 추정 문자열들에 기초하여 제2 문자열을 획득할 수 있다. 일 실시예에 따라 프로세서는, 제1 문자열 내의 각 문자와 발음이 유사한 대체 문자들을 식별하고, 식별된 대체 문자들에 기초하여 소정 문자열 내의 적어도 하나의 문자가 다른 문자로 교정된 추정 문자열들을 결정할 수 있다. 프로세서는, 결정된 추정 문자열들 중에서, 언어 모델 및 사전 정보 등 미리 저장된 정보에 기초 하여 가장 적합한 추정 문자열을 선택하여 제2 문자열로서 획득할 수 있다. 이하에서는, 일 실시예에 따른 프로세서가 제2 문자열을 획득하는 방법을 보다 구체적으로 설명한다. 먼저, 프로세서는, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도를 계산할 수 있다. 디바이스에 의해 음성 신호로부터 추정된 제1 문자열은, 음성 신호 프레임들이 임의의 문자들 각각에 대응 할 확률 분포에 대해서, 디바이스에 저장된 언어 모델 및 사전 정보 등을 고려하여 획득된 것이다. 서버 는, 디바이스에 의해 추정된 제1 문자열로부터 디바이스의 언어 모델 및 사전 정보와 관련된 바 이어스를 제거하고, 서버 내에 저장된 언어 모델 및 사전 정보를 이용하여 재 디코딩을 수행할 수 있다. 서버는, 제1 문자열로부터 디바이스의 언어 모델 및 사전 정보에 기초한 바이어스를 제거하기 위하여, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도를 계산할 수 있다. 프로세서는, 제1 문자열로부터 획득되는 가능도에 대해서 메모리에 저장된 사전 정보 및 언어 모델을 적용하여 디코딩을 수행함으로써 제2 문자열을 획득할 수 있다. 프로세서가 서버의 메모리에 저 장된 사전 정보 및 언어 모델을 적용하여 디코딩을 수행할 경우, 방대한 양의 개체명을 포함하는 사전 정보 및 언어 모델을 이용할 수 있으므로, 음성 인식의 정확도가 높아질 수 있다. 예를 들어, 디바이스의 메모리 내의 언어 모델에는 개체명 \"Cardinals\"가 저장되어 있지 않을 수 있다. 따 라서, 디바이스는, 음성 신호“The Cardinals baseball team\"로부터 제1 문자열 [The cat and deers baseball team]을 잘못 추정할 수 있다. 반면에, 도 8a에 도시된 바와 같이, 서버의 메모리 내에는, 스포츠 도메인의 개체명 \"Cardinals\"가 저장되어 있을 수 있다. 따라서, 서버의 프로세서는, 디바이스에서 추정된 'cat and deers'가 실제로는 야구 팀 명칭인 'Cardinals'일 확률이 더 높다고 판단할 수 있다. 프로세서는, 제1 문자열 내의 각 문자와 발음이 유사한 대체 문자들을 식별하고, 식별된 대체 문자들에 기 초하여 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 교정된 제2 문자열을 획득할 수 있다. 따라서, 프로 세서는, 제1 문자열 내의 'cat and deers'가 'Cardinals'로 대체된 제2 문자열 [The Cardinals baseball team]을 획득할 수 있다. 예를 들어, WFST 디코딩 방식을 이용하여, 제1 문자열 [The cat and deers baseball team]으로부터 제2 문자열 [The Cardinals baseball team]을 획득하는 구체적인 방법은 후에 도 17을 참조하여 설명한다. 서버는, 제2 문자열을 디바이스에게 전송할 수 있다. 디바이스는, 디바이스에서 추정된 제 1 문자열을 서버로부터 수신된 제2 문자열로 대체하여 출력할 수 있다. 도 8a에 도시된 바와 같이, 예를 들어, 제1 문자열[The cat and deers baseball team]의 신뢰도는 0.1이고 제2 문자열 [The Cardinals baseball team]의 신뢰도는 0.5일 수 있다. 일 실시 예에 따른 디바이스는, 제1 문자열보다 신뢰도가 높은 제2 문자 열을 서버로부터 수신하여 이용함으로써 음성 인식 성능을 높일 수 있다. 상술한 바와 같이, 일 실시 예에 따른 서버는, 디바이스로부터 프레임 동기화된 문자열을 수신하거나, 디바이스로부터 수신된 문자열로부터 프레임 동기화된 문자열을 생성할 수 있다. 서버는, 음성 신호 프레임 각각에 대응하는 문자 별로 가능도를 획득함으로써 대체 문자열을 결정할 수 있다. 서버 는, 복수의 문자들을 포함하는 문자열 전체를 동시에 수신할 수도 있고, 문자열에 포함되는 적어도 일부 문자들을 순차적으로 수신할 수도 있다. 이하에서는, 도 8b를 참조하여 일 실시 예에 따른 서버가 음성 신호 프레임 각각에 대응하는 문자 별로 가 능도를 획득함으로써 대체 문자열을 결정하는 방법을 보다 구체적으로 설명한다. 일 실시 예에 따른 서버는, 디바이스로부터 프레임 동기화된 제1 문자열을 수신하거나, 디바이스 로부터 수신된 문자열로부터 프레임 동기화된 제1 문자열을 생성할 수 있다. 예를 들어, 서버의 통신부는, 디바이스에 의해 음성 신호로부터 획득된 문자열과 함께 음성 신 호와 관련된 정보를 디바이스로부터 수신할 수 있다. 서버는, 음성 신호와 관련된 정보에 기초하여 문자열을 강제 정렬함으로써 프레임 동기화된 제1 문자열을 생성할 수 있다 서버의 문자열 평가부는, 프레임 동기화된 제1 문자열 내의 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가능도 행렬들을 산출할 수 있다. 일 실시예에 따라 문자열 평가부에서 산출하는 소정 문자에 대한 가능도 행렬이란, 소정 문자가 대체될 대 체 문자들에 대한 가능도 값들을 포함하는 행렬을 의미할 수 있다. 소정 문자가 대체될 대체 문자에 대한 가능 도 값이란, 대체 문자가 참값(ground truth) 문자라고 가정하였을 때 음성 인식 결과로서 소정 문자가 추정될 확률을 의미할 수 있다. 예를 들어, 음성 인식 결과 획득되는 문자열 내에 포함되는 문자 “a”에 대해서, 참값(ground truth) 문자가 “a”일 확률 값, “b”일 확률 값, “c”일 확률 값, …, 및 “z”일 확률 값을 포함하는 가능도 행렬 [0.4 0.01 0.01 0.01 0.2 … 0.01]이 획득될 수 있다. 문자열 내에 포함되는 각 문자에 대응하는 대체 문자들에 대한 가능도 값들을 포함하는 가능도 행렬을 획득함에 있어서, 각 문자와 발음이 유사한 대체 문자들에 대해서 높은 가능도 값이 부여될 수 있다. 서버의 디코더는, 가능도 행렬들에 기초하여, 프레임 동기화된 제1 문자열 내의 적어도 하나의 문자가 대체된 복수의 추정 문자열들 중에서 하나의 추정 문자열을 선택하고, 선택된 추정 문자열을 제2 문자열 로서 획득할 수 있다. 예를 들어, 디코더는, 사전 정보 및 언어 모델에 기초하여, 가능도 행렬들을 재연산할 수 있다. 디코 더는, 재 연산된 가능도를 최대로 하는 제2 문자열을 복수의 추정 문자열들 중에서 결정할 수 있다. 예를 들어, 디코더는, 비터비 디코더를 포함할 수 있다. 비터비 디코더는, 사전 정보 및 언어 모델을 고려하여, 제1 문자열에 대한 가장 가능성 높은 문자열을 제2 문자열로서 찾아낼 수 있다. 서버의 디코더는, 복수의 추정 문자열들의 가능도, 사전 정보, 및 언어 모델에 기초하여, 복수의 추 정 문자열들 중에서 신뢰도가 가장 높은 문자열을 제2 문자열로서 획득할 수 있다. 서버는, 제2 문자열을 디바이스에게 전송할 수 있다. 디바이스는, 제1 문자열보다 신뢰도가 높은 제2 문자열을 서 버로부터 수신하여 이용함으로써 음성 인식 성능을 높일 수 있다. 이하에서는, 도 9 내지 도 11b를 참조하여 서버에서 가능도를 계산하는 방법의 다양한 실시 예들을 구체적 으로 설명한다. 도 9는 일 실시 예에 따른 서버의 구체적인 블록도를 도시한다. 도 9에 도시된 바와 같이, 서버의 통신부는, 디바이스로부터 제1 문자열을 수신할 수 있다. 프로세서의 문자열 평가부는, 디코더가 제1 문자열 보다 높은 신뢰도를 가지는 제2 문자열을 추 천하여 출력할 수 있도록 하는 제1 문자열에 대한 평가 정보를 출력할 수 있다. 예를 들어, 제1 문자열에 대한 평가 정보는, 제1 문자열로부터 산출되는 가능도를 포함할 수 있다. 문자열 평가부는, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도를 계산할 수 있다. 문자열 평가부는, 제1 문자열 내의 각 문자를 다른 문자로 대체함으로써, 복수의 추정 문자열들을 획득할 수 있다. 복수의 추정 문자열들의 가능도란, 제1 문자열로부터 획득되는 복수의 추정 문자열들 각각이 참값 문자열 이라고 가정하였을 때, 음성 인식 모듈로부터 제1 문자열이 추정될 확률을 의미할 수 있다. 문자열 평가부에서 출력되는 제1 문자열로부터 획득되는 가능도는, 제1 문자열 내의 각 문자와 발음이 유 사한 대체 문자들을 식별하고, 식별된 대체 문자들에 기초하여 소정 문자열 내의 적어도 하나의 문자가 다른 문 자로 교정된 추정 문자열들을 결정하기 위하여 이용될 수 있다. 문자열 평가부는, 제1 문자열 내의 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가능도 행렬들 을 산출하고, 가능도 행렬들 내의 가능도 값들에 기초하여 복수의 추정 문자열들을 식별할 수 있다. 문자열 평 가부는, 복수의 추정 문자열들의 가능도로서, 각 문자로부터 획득되는 가능도 행렬들을 출력할 수 있다. 문자열 평가부는, 메모리에 저장된 가능도 계산용 데이터를 이용하여, 제1 문자열로부터 가능도 를 계산할 수 있다. 예를 들어, 가능도 계산용 데이터는, 가능도 계산을 위해 훈련된 신경망 또는 오차 행 렬을 포함할 수 있다. 일 예로서, 문자열 평가부는, 제1 문자열 내의 각 문자의 이전 문자들에 기초하여 각 문자의 사후 확률들 을 계산할 수 있다. 문자열 평가부는, 제1 문자열로부터 문자 배열 확률을 계산할 수 있다. 문자열 평가부 는, 각 문자의 사후 확률들 및 문자 배열 확률에 기초하여, 제1 문자열로부터 획득되는 복수의 추정 문자 열들의 가능도를 계산할 수 있다. 다른 예로서, 문자열 평가부는, 미리 결정된 오차 행렬에 기초하여, 제1 문자열 내의 각 문자의 사후 확률 들을 계산할 수 있다. 문자열 평가부는, 제1 문자열 내의 각 문자의 사후 확률들에 기초하여, 제1 문자열 로부터 획득되는 복수의 추정 문자열들의 가능도를 계산할 수 있다. 문자열 평가부에서 가능도를 계산한 후, 디코더는 사전 정보, 및 언어 모델을 이용하여, 계산된 가능 도에 기초하여 제2 문자열을 획득할 수 있다. 디코더는, 제1 문자열 내의 적어도 하나를 다른 문자로 대체 함으로써 획득되는 복수의 추정 문자열들 중에서, 가능도를 최대로 하는 제2 문자열을 획득할 수 있다. 디코더는, 사전 정보 및 언어 모델을 이용하여, 제1 문자열 내의 적어도 하나의 문자가 다른 문 자로 대체된 제2 문자열을 획득할 수 있다. 예를 들어, 디코더는, 가능도를 입력으로 하는 WFST 디코더 또 는 전통적인 토큰 패싱(token passing) 을 이용하는 비터비 디코더를 포함할 수 있다. 본 개시의 일 실시 예에 따라 서버에 저장된 사전 정보는, 음소열과 단어 간의 관계를 저장하는 일반적인 사전 정보가 아닌, 단어와 문자열 간의 관계를 저장한 사전 정보일 수 있다. 또한, 언어 모델은, 특정 단어열이 주어졌을 때 다음에 나올 단어들의 확률을 추정할 수 있도록 단어들 간의 관계를 학습한 인공 지능 모델일 수 있다. 예를 들어, 언어 모델은, RNN 등의 신경망이거나, 통계적 n-gram일 수 있다. 통신부는 제2 문자열을 디바이스에게 전송할 수 있다. 그러나 본 개시의 실시예는 제2 문자열을 디바 이스에게 전송하는 실시예에 제한되지 않는다. 본 개시의 일 실시 예에 따른 서버는, 제2 문자열에 대한 자연어 처리를 통해 사용자의 발화 의도를 파악함으로써 제2 문자열에 기초한 음성 비서 서비스에 관련된 정보를 통신부를 통해 디바이스에게 전송할 수 있다. 본 개시의 다양한 실시예들에 따라 서버로부터 디바이스에게 전송되는 제2 문자열과 관련된 정보에 대해서는, 도 2b 및 도 2c를 참조하여 상술하였으므로 구체적인 설명은 생략한다. 한편, 본 개시의 일 실시 예에 따른 서버의 디코더는, 도메인 별로 서로 다른 사전 정보 및 언어 모 델을 이용하여, 제1 문자열에 대한 디코딩을 수행할 수 있다. 따라서, 본 개시의 일 실시 예에 따른 서버 는, 디바이스로부터 제1 문자열에 대한 재 디코딩을 통해 음성 인식 정확도가 높아진 음성 인식 결과를 출 력할 수 있다. 일 실시 예에 따른 서버의 프로세서는, 디바이스로부터 제1 문자열을 수신하고, 제1 문자열에 관련된 도메인을 결정할 수 있다. 서버의 디코더는, 결정된 도메인에 대응되는 사전 정보 및 언어 모 델을 이용하여, 제1 문자열에 대한 디코딩을 수행할 수 있다. 일 예로서, 서버의 프로세서는, 디바이스로부터 제1 문자열과 함께 제1 문자열에 관련된 도메인 정보를 수신하고, 수신된 정보에 기초하여 제1 문자열에 대한 디코딩을 수행할 도메인을 결정할 수 있다. 예를 들어, 프로세서는, 디바이스로부터 수신된 정보로부터 식별된 도메인과 동일하거나 유사한 도메인을 디코딩을 수행할 도메인으로서 결정할 수 있다. 다른 예로서, 서버의 프로세서는 디바이스로부터 수신된 제1 문자열에 기초하여, 수신된 제1 문 자열에 관련된 도메인을 결정할 수 있다. 도 9에는 도시되지 않았지만, 서버는 도메인 식별을 위해 훈련된 인공 지능 모델인 도메인 식별 모델을 메모리에 저장할 수 있다. 프로세서는, 도메인 식별 모델을 이용하여, 제1 문자열을 입력 값으로 하여 도메인 신뢰도를 출력할 수 있다. 프로세서는, 도메인 신뢰도에 기초하여, 제1 문자열에 관련된 도메인을 결정할 수 있다. 일 실시예에 따르면, 서버의 문자열 평가부 또는 디코더가 디바이스로부터 수신된 제1 문자열에 기초하여 수신된 제1 문자열에 관련된 도 메인을 결정할 수 있다. 예를 들어, 서버의 디코더는 디바이스로부터 수신된 제1 문자열에 기초하여, 제1 문자열에 관련 된 도메인을 결정할 수 있다. 일 실시예에 따른 디코더는, 수신된 제1 문자열에 대해 결정된 도메인에 특 화된 사전 및 언어 모델을 이용한 디코딩을 수행할 수 있다. 일 실시예에 따른 디코더는 투패스 디코더(2 Pass Decoder)일 수 있다. 투패스 디코더는, 문자열 평가부 로부터 수신되는 제1 문자열에 대한 평가 정보에 대한 1차 디코딩을 수행한 후, 1차 디코딩 결과를 이용하 여 2차 디코딩을 수행할 수 있다. 이 때, 본 개시의 일 실시예에 따른 디코더는, 제1 패스 디코더(1st pass decoder)에 의해, 일반적인 (general) 사전 및 언어 모델을 이용한 디코딩을 수행할 수 있다. 그리고 디코더는, 제2 패스 디코더(2nd pass decoder)에 의해, 수신된 제1 문자열에 대해 결정된 도메인에 특화된 사전 및 언어 모델을 이용한 디코딩 을 수행할 수 있다. 또 다른 예로서, 일 실시예에 따른 서버의 통신부는, 디바이스로부터 제1 문자열과 함께 제1 문 자열에 관련된 도메인을 판단하기 위한 정보를 수신할 수 있다. 예를 들어, 디바이스로부터 수신된 도메인 을 판단하기 위한 정보는 컨텍스트 정보를 포함할 수 있다. 예를 들어, 컨텍스트 정보는, 사용자가 현재 디바이 스 또는 서버 상에서 이용하고 있는 애플리케이션에 대한 정보, 대화 이력 정보, 디바이스 주변 의 상황 정보 또는 트렌드 정보 중 적어도 하나를 포함할 수 있다. 서버의 프로세서는, 컨텍스트 정 보를 기반으로 제1 문자열에 대한 디코딩을 수행할 도메인을 결정할 수 있다. 이하에서는, 컨텍스트 정보 기반 으로 도메인을 결정하는 구체적인 방법을 설명한다. 예를 들어, 프로세서는, 사용자가 현재 이용하고 있는 애플리케이션에 기초하여 도메인을 결정할 수 있다. 프로세서는, 사용자가 디바이스 또는 서버 상에서 지도 애플리케이션을 이용하고 있는 경우, 사 용자의 발화로부터 획득된 문자열에 대한 도메인을 결정함에 있어서 지도와 관련된 도메인을 디코딩을 수행할 도메인으로서 결정할 수 있다. 예를 들어, 프로세서는, 지도 도메인에 더 높은 가중치를 부여하여 디코딩 을 수행할 도메인을 결정하거나, 지도 도메인을 디코딩을 수행할 도메인으로서 결정할 수 있다. 또는, 예를 들어, 프로세서는, 대화 이력 정보에 기초하여 도메인을 결정할 수 있다. 프로세서는, 사 용자의 대화 이력이 '음악'과 관련된다고 판단되는 경우, 사용자의 발화로부터 획득된 문자열에 대한 도메인을 결정함에 있어서 음악과 관련된 도메인을 디코딩을 수행할 도메인으로서 결정할 수 있다. 예를 들어, 프로세서 는, 음악 도메인에 더 높은 가중치를 부여하여 디코딩을 수행할 도메인을 결정하거나, 음악 도메인을 디코 딩을 수행할 도메인으로서 결정할 수 있다. 또는, 예를 들어, 프로세서는, 디바이스에 탑재된 센서에 의해 감지되는 디바이스 주변의 상황 정보에 기초하여 도메인을 결정할 수 있다. 프로세서는, 디바이스의 GPS 정보를 이용하여 식별되는 디바이스의 위치에 기초하여 도메인을 결정할 수 있다. 프로세서는, 사용자가 음식점을 검색하고자 하는 경우, 디바이스의 위치와 관련된 도메인을 디코딩을 수행할 도메인으로서 결정할 수 있다. 프로세서 는, 디바이스의 위치가 영화관 근처인 경우, 영화와 관련된 도메인을 디코딩을 수행할 도메인으로서 결정할 수 있다. 또는, 예를 들어, 프로세서는, 트렌드 정보에 기초하여 도메인을 결정할 수 있다. 프로세서는, 주요 뉴스 또는 포털 사이트를 통한 실시간 검색어와 관련된 도메인을 디코딩을 수행할 도메인으로서 결정할 수 있다. 이하에서는, 일 실시 예에 따른 서버의 문자열 평가부가 제1 문자열 내의 각 문자의 이전에 누적된 문자들에 기초하여 가능도를 획득하는 경우를 구체적으로 설명한다. 일 실시 예에 따른 서버의 통신부는, 프레임 동기화된 제1 문자열 yo[0:l+1]을 디바이스로부터 수신할 수 있다. 프레임 동기화된 문자열과 관련하여서는, 도 6을 참조하여 상술하였으므로, 중복되는 설명은 생략한다. 이하의 설명에서, yo[L]은, 온-디바이스 음성 인식 모듈에 의해 음성 신호로부터 추정되는, 프레임 동기화된 문 자일 수 있다. 프레임 동기화된 문자란, 음성 신호에 포함되는 하나의 음성 프레임으로부터 추정된 문자를 의미 할 수 있다. yo[L]은, 전체 문자들의 집합인 V에 포함된다. yo[0:L+1]은, 0≤L'≤L일 때 yo[L']의 배열(sequence)를 의미한다. L 및 L'는 문자열의 인덱스이다. 통신부는 복수의 문자들을 포함하는 문자열 전체를 동시에 수신할 수도 있고, 문자열에 포함되는 적어도 일부 문자들을 순차적으로 수신할 수도 있다. yp[L]은, 디바이스에 의해 획득된 문자열을 서버에서 후처리하기 위해서 추정되는 프레임 동기화된 문자를 의미 한다. yp[L]은, 문자들의 집합인 V에 포함된다. Wi는 단어열이다. Wi는, 단어들의 집합인 D에 포함되는 단어이다. 일 실시 예에 따른 서버의 문자열 평가부는, 제1 문자열 yo[0:L+1]에 따라 문자들이 나열될 문자 배 열 확률 P(yo[0:L+1])을 계산할 수 있다. 문자 배열 확률 P(yo[0:L+1])는, 문자-레벨 언어 모델로부터 계산될 수 있다. 일 실시 예에 따른 문자열 평가부는, 제1 문자열 yo[0:L+1]이 디바이스에 의해 추정되었을 때, 실제 로는 L번째 문자가 yp[L]일 사후 확률들 P(yp[L]|yo[0:L+1])을 계산할 수 있다. 문자열 평가부는, 제1 문자 열 yo[0:L+1]에 기초하여, 문자 yo[L]의 사후 확률들 P(yp[L]|yo[0:L+1])을 계산할 수 있다. 즉, 사후 확률 계산 부는, 제1 문자열 yo[0:L+1]에 기초하여, 디바이스에 의해 문자 yo[L]가 정확하게 추정되었을 확률 및 문자 yo[L]가 잘못 추정되었을 확률들을 계산할 수 있다. 일 실시 예에 따른 문자열 평가부는, 신경망을 이용해서, 제1 문자열로부터 제1 문자열의 각 문자의 사후 확률들을 계산할 수 있다. 일 실시 예에 따른 문자열 평가부는, 도 10a에 도시된 LSTM 레이어 및 소프트맥스 레이어를 포함하는 회귀 신경망을 이용하여 제1 문자열 내의 각 문자의 사후 확률들을 계산할 수 있다. 도 10a에 도시된 LSTM 레이어는 복수의 적층된 LSTM 레이어들을 포함할 수 있다. 도 10a에서, 제1 문자열 이 LSTM 레이어에 입력되고, LSTM 레이어로부터 출력되는 데이터가 소프트맥스 레이어에 입 력되며, 소프트맥스 레이어는 제1 문자열의 각 문자의 사후 확률들을 출력할 수 있다. 일 실시 예에 따라 문자열 내의 각 문자의 사후 확률들을 계산하는 신경망은, 참값 문자열 및 음성 인식 모듈로 부터 출력되는 오류 문자열을 학습함으로써 훈련될 수 있다. 구체적으로, 신경망은, 음성 인식 모듈로부터 출력 되는 오류 문자열을 입력을 수신하였을 때, 출력되는 출력값이 참값 문자열에 가까워지도록 훈련될 수 있다. 일 실시 예에 따른 문자열 평가부 가 사후 확률들을 획득하기 위해 이용하는 인공 지능 모델은, 특정 음성 인식 모듈의 음성 인식 결과에 과적합(overfitting)되는 것을 막기 위해서, 복수 개의 음성 인식 모듈들의 음성 인식 결과에 기초하여 훈련될 수 있다. 프로세서의 문자열 평가부는, 사후 확률들 P(yp[L]|yo[0:L+1]) 및 문자 배열 확률 P(yo[0:L+1])에 기 초하여, 가능도 P(yo[0:L+1]|yp[L])를 계산할 수 있다. 가능도 P(yo[0:L+1]|yp[L])는, 사후 확률 및 문자 배열 확률에 기초하여 다음의 수학식 1에 의해 계산될 수 있다. [수학식 1]"}
{"patent_id": "10-2020-0018574", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상기 [수학식 1]에서 P(yp[L])은 yp[L]의 사전 확률을 의미한다. 소정 문자 yp[L]의 사전 확률은, 소정 문자가 이용되는 빈도에 기초하여 통계적으로 미리 계산된 값일 수 있다. 일 실시 예에 따른 서버의 디코더는, 사전 정보 및 언어 모델을 이용하여, 가능도 P(yo[0:L+1]|yp[L])로부터 제2 문자열 Wi을 추정할 수 있다. 제2 문자열은, 제1 문자열의 적어도 하나의 문자가다른 문자로 대체된 문자열일 수 있다. 통신부는 제2 문자열 Wi를 디바이스에게 전송할 수 있다. 서 버는, 디바이스로부터 프레임 동기화된 문자열 yo[0:L+1]을 수신하였지만, 단어열의 형태를 가지는 제2 문자열 Wi를 디바이스에게 전송할 수 있다. 한편, 다른 일 실시 예에 따른 서버의 문자열 평가부는, 각 문자의 이전에 누적된 문자들을 고려하지 않고, 각 문자 자체만을 고려하여 가능도를 계산할 수 있다. 다른 일 실시예에 따른 문자열 평가부는, 문 자열 yo[0:L+1] 대신에 문자 yo[L]만을 고려하여 가능도를 계산할 수 있다. 문자열 yo[0:L+1] 대신에 문자 yo[L] 만을 고려하는 경우, 서버의 구조가 매우 간단해지고, 신경망 대신에 문자 레벨의 오차 행렬만 저장하여 이용하므로 계산 과정이 단순해질 수 있다. 서버의 통신부는, 프레임 동기화된 제1 문자열 yo[0:L+1]을 디바이스로부터 수신할 수 있다. 프 레임 동기화된 문자열과 관련하여서는, 도 6을 참조하여 상술하였으므로, 중복되는 설명은 생략한다. 통신부 는 복수의 문자들을 포함하는 문자열 전체를 동시에 수신할 수도 있고, 문자열에 포함되는 적어도 일부 문 자들을 순차적으로 수신할 수도 있다. 다른 일 실시 예에 따른 서버의 문자열 평가부는, 제1 문자열 내의 제1 문자 yo[L]이 디바이스 에 의해 추정되었을 때, 실제로는 L번째 문자가 yp[L]일 사후 확률들 P(yp[L]|yo[L])을 획득할 수 있다. 문자열 평가부는, 제1 문자 yo[L]에 기초하여, 문자 yo[L]의 사후 확률들 P(yp[L]|yo[L])을 획득할 수 있다. 즉, 문자열 평가부는, 제1 문자 yo[L]에 기초하여, 디바이스에 의해 문자 yo[L]가 정확하게 추정되었을 확 률 및 문자 yo[L]가 잘못 추정되었을 확률들을 획득할 수 있다. 일 실시 예에 따른 문자열 평가부는, 오차 행렬을 이용해서 제1 문자열로부터 각 문자의 사후 확률들을 획 득할 수 있다. 도 10b는 일 실시 예에 따라 사후 확률들을 계산하기 위해 이용되는 오차 행렬의 예를 도시한다. 오차 행렬은, 디바이스의 음성 인식 모듈이 문자열에 포함되는 소정 문자를 정확하게 예측했을 확률 및 다른 문자를 소정 문자로 잘못 예측했을 확률을 포함한다. 예를 들어, 문자 \"a\"와 문자 \"e\"는 발음이 유사하기 때문에 음성 인식 모듈이 실제 문자 \"a\"를 \"e\"로 잘못 추정 할 확률이 상대적으로 높을 수 있다. 반면에, 문자 \"a\"와 문자 \"b\"는 발음이 매우 상이하기 때문에 음성 인식 모듈이 실제 문자 \"a\"를 \"b\"로 잘못 추정할 확률이 상대적으로 낮을 수 있다. 따라서, 도 10b에 예시된 바와 같이, 디바이스의 음성 인식 모듈이 실제 문자 \"a\"를 문자 \"e\"로 잘못 추정 할 확률은 0.23이고, 실제 문자 \"a\"를 문자 \"b\"로 잘못 추정할 확률은 0.01일 수 있다. 일 실시 예에 따른 문자열 평가부는, 디바이스에 의해 추정되는 문자가 제1 문자 yo[L]일 때, 실제 문자가 yp[L]일 사후 확률들 P(yp[L]|yo[L])을 도 10b에 오차 행렬로부터 검색하여 획득할 수 있다. 문자열 평가부는, 획득된 사후 확률들 P(yp[L]|yo[L])에 기초하여, 가능도 P(yo[L]|yp[L])를 계산할 수 있 다. 가능도 P(yo[L]|yp[L])는, 사후 확률들에 기초하여 다음의 [수학식 2]에 의해 계산될 수 있다. [수학식 2]"}
{"patent_id": "10-2020-0018574", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 [수학식 2]에서 P(yp[L])은 yp[L]의 사전 확률을 의미한다. 소정 문자 yp[L]의 사전 확률은, 소정 문자가 이용되는 빈도에 기초하여 통계적으로 미리 계산된 값일 수 있다. 다른 일 실시 예에 따른 서버의 디코더는, 사전 정보 및 언어 모델을 이용하여, 가능도 P(yo[L]|yp[L])로부터 제2 문자열 Wi을 추정할 수 있다. 제2 문자열은, 제1 문자열의 적어도 하나의 문자가 다른문자로 대체된 문자열일 수 있다. 통신부는 제2 문자열 Wi를 디바이스에게 전송할 수 있다. 서버 는, 디바이스로부터 프레임 동기화 문자열 yo[0:l+1]을 수신하였지만, 단어열의 형태를 가지는 제2 문자열 Wi를 출력할 수 있다. 상술한 바와 같이 일 실시 예에 따른 서버의 문자열 평가부는, 디바이스로부터 프레임 동기화된 문자열을 수신하고, 음성 신호 프레임 각각에 대응하는 문자 별로 가능도를 획득할 수 있다. 예를 들어, 문자열 평가부는, 음성 신호 프레임에 대응하는 인덱스 L의 문자 yo[L]에 대해서 가능도 P(yo[0:L+1]|yp[L]) 또는 P(yo[L]|yp[L])를 산출할 수 있다. 이하에서는, 도 11a 및 도 11b를 참조하여 일 실시 예에 따른 문자열 평가부가, 디바이스로부터 수신 된 문자열로부터, 음성 신호 프레임 각각에 대응하는 문자 별로 가능도를 획득하는 방법을 구체적으로 설명한다. 도 11a에 도시된 바와 같이 일 실시 예에 따른 문자열 평가부는 프레임 동기화된 문자열을 수신할 수 있다. 문자열 평가부는, 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가능도 행렬을 산출할 수 있다. 도 11b에 도시된 바와 같이, 일 실시 예에 따른 문자열 평가부에서 산출되는 대체 문자들에 관한 가능도 행렬은, 소정 문자가 임의의 문자들 각각일 가능도 값들을 포함하는 행렬로써 표현될 수 있다. 도 11b의 표 에 도시된 바와 같이 임의의 문자들 각각은 가능도 행렬의 인덱스 각각에 매핑될 수 있다. 예를 들어, 가능도 행렬에서 인덱스 a1의 값은, 소정 문자가 인덱스 a1에 대응하는 문자 \"a\"로 대체될 가 능도 값을 나타낼 수 있다. 가능도 행렬에서 인덱스 a2의 값은, 소정 문자가 인덱스 a2에 대응하는 문자 \"b\"로 대체될 가능도 값을 나타낼 수 있다. 가능도 행렬에서 인덱스 a3의 값은, 소정 문자가 인덱스 a3에 대응하는 문자 \"c\"로 대체될 가능도 값을 나타낼 수 있다. 일 실시 예에 따른 문자열 평가부는, 문자열 내의 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가능도 행렬들을 산출할 수 있다. 문자열 평가부는 제1 문자열 내의 적어도 하나의 문자가 대체된 복수의 추정 문자열들의 가능도로서 산출된 가능도 행렬들을 디코더에게 출력할 수 있다. 일 실시 예에 따른 디코더는, 문자열 평가부로부터 수신한 가능도에 기초하여, 사전 정보, 및 언어 모델을 이용하여, 복수의 추정 문자열들 중에서 신뢰도가 가장 높은 문자열을 제2 문자열로서 획득할 수 있다. 상술한 바와 같이 본 개시의 다양한 실시 예들에 따른 음성 인식 시스템은 온-디바이스 음성 인식이 수행되는 경우와 서버-기반 음성 인식이 수행되는 경우를 나누어 선택적으로 수행할 수 있다. 그러나 본 개시는 이에 제 한되지 않으며, 본 개시의 일 실시 예에 따른 디바이스는, 복수의 음성 인식 모듈을 포함하고 상술한 바와 유사한 방식으로 제1 음성 인식 모듈에서 음성 인식이 수행되는 경우와 제2 음성 인식 모듈에서 음성 인식이 수 행되는 경우를 나누어 선택적으로 수행할 수 있다. 도 12는 일 실시 예에 따라 두 개의 음성 인식 모듈들을 선택적으로 이용하는 디바이스의 블록도를 도시한다. 도 12를 참조하면, 디바이스는, 수신부, 프로세서, 메모리 및 출력부를 포함할 수 있 다. 도 12에 도시된 구성 요소 모두가 디바이스의 필수 구성 요소인 것은 아니다. 도 12에 도시된 구성 요 소보다 많은 구성 요소에 의해 디바이스가 구현될 수도 있고, 도 12에 도시된 구성 요소보다 적은 구성 요 소에 의해 디바이스가 구현될 수도 있다. 예를 들어, 도 19에 도시된 바와 같이, 일부 실시 예에 따른 디 바이스는, 사용자 입력부, 센싱부, 및 A/V 입력부를 더 포함할 수도 있다. 본 개시의 일 실시 예에 따른 수신부는 사용자로부터 음성 신호를 입력 받을 수 있다. 예를 들어, 수신부 는, 마이크로폰에 의해 외부의 소리를 전기적인 음향 데이터로 변환함으로써 음성 신호를 수신할 수 있다. 도 12에는, 수신부가, 디바이스의 내부에 포함되는 것으로 도시되었으나, 다른 일 실시 예에 따른 수 신부는 별도의 디바이스 내에 포함되고 디바이스와는 유, 무선으로 연결되는 형태로 구현될 수 있다. 본 개시의 일 실시 예에 따른 메모리는, 음성 인식을 수행하기 위한 인스트럭션들, 음성 인식에 이용되는 각종 모델, 신경망, 사전 정보 등을 저장할 수 있다. 메모리는, 음성 인식에 이용되는 각종 모델, 신경망, 사전 정보 등을 저장할 수 있다. 메모리에 저 장되는 제1 데이터는, 제1 ASR 모듈이 음성 인식을 수행하는 데 이용되는 모델, 신경망, 및 사전 정 보 중 적어도 하나를 포함할 수 있다. 메모리에 저장되는 제2 데이터는, 제2 ASR 모듈이 음성 인식을 수행하는 데 이용되는 모델, 신경망, 및 사전 정보 중 적어도 하나를 포함할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 메모리에 저장된 하나 이상의 인스터럭션들을 실행함으로 써, 음성 인식을 수행할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는 제1 ASR 모듈 및 제2 ASR 모듈을 포함할 수 있다. 본 개시의 일 실시 예에 따른 프로세서의 제1 ASR 모듈은 수신부에서 획득된 음성 신호를 수신 하고, 제1 데이터(예를 들어, 음향 모델, 신경망, 언어 모델, 또는 사전 정보 등)에 기초하여 음성 신호에 대한 음성 인식을 수행할 수 있다. 제1 ASR 모듈은 음성 신호로부터 제1 문자열을 획득할 수 있다. 제1 문 자열은 프레임 동기화된 문자열일 수 있다. 도 12의 제1 ASR 모듈은, 도 4a의 ASR 모듈 또는 도 4b의 ASR 모듈에 대응될 수 있으므로 중복 되는 설명은 생략한다. 본 개시의 일 실시 예에 따른 프로세서의 결정부는, 제1 ASR 모듈로부터 출력된 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 일 예로서, 프로세서의 결정부는 제1 문자열의 신뢰도를 결정하고, 신뢰도에 기초하여 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 예를 들어, 일 실시 예에 따른 프로세서의 결정부는, 제1 문자열의 신뢰도가 임계값 보다 높거나 같 으면, 제1 문자열의 교정이 필요하지 않은 것으로 판단하고 제1 문자열을 출력부를 통해 출력할 수 있다. 반면에, 프로세서의 결정부는, 신뢰도가 임계값 보다 작으면, 제1 문자열의 교정이 필요하다고 판단 하고 제1 문자열을 제2 ASR 모듈에게 전송할 수 있다. 다른 예로서, 프로세서의 결정부는, 디바이스에 미리 저장된 키워드들과 제1 문자열을 비교한 결과에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 또 다른 예로서, 프로세서 의 결정부는, 제1 문자열이 관련된 도메인 또는 제1 문자열 내에 개체명이 포함되는지 여부에 기초하 여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 일 실시 예에 따른 프로세서의 결정부가 제1 문자열을 다른 문자열로 대체할 지 여부를 결정하는 구 체적인 방법과 관련하여서는, 도 3 내지 도 5b와 관련하여 일 실시 예에 따른 디바이스의 프로세서가 제1 문자열을 다른 문자열로 대체할 지 여부를 결정하는 방법이 이용될 수 있다. 중복되는 설명은 생략한다. 본 개시의 일 실시 예에 따른 프로세서의 결정부는, 제1 문자열의 교정이 필요하지 않다고 판단되는 경우, 제1 문자열을 다른 문자열로 대체하지 않을 것을 결정 할 수 있다. 본 개시의 일 실시 예에 따른 프로세 서의 결정부는, 제1 문자열을 다른 문자열로 대체하지 않을 경우, 제1 문자열을 출력부를 통해 출력할 수 있다. 본 개시의 일 실시 예에 따른 프로세서의 결정부는, 제1 문자열을 다른 문자열로 대체하여야 한다고 결정되는 경우, 이러한 결정에 기초하여 제1 문자열을 제2 ASR 모듈로 전송할 수 있다. 일 실시예에 따른 프로세서의 결정부는, 문장 단위, 단어 단위, 구 단위 또는 프레임 단위로 제1 문 자열을 제2 ASR 모듈로 전송할 수 있다. 일 실시 예에 따른 프로세서의 제1 ASR 모듈에서 음성 인식을 수행하여 문장 또는 구를 구성하는 문자열을 획득한 경우, 결정부는, 문장 또는 구에 포함되는 문 자들을 모두 제2 ASR 모듈에게 전송하거나 문장 또는 구에 포함되는 문자들 중 일부를 제2 ASR 모듈 에게 전송할 수 있다. 결정부, 문자열의 신뢰도에 기초하여, 신뢰도가 낮은 일부의 문자들을 제2 ASR 모듈 에게 전송할 수 있다. 본 개시의 일 실시 예에 따른 프로세서의 제2 ASR 모듈은 제1 문자열을 수신하고, 제1 문자열을 처리 할 수 있다. 제2 ASR 모듈은 제2 데이터에 포함되는 언어 모델 및 사전 정보에 기초하여 제1 문자열 에 대한 재 디코딩을 수행함으로써, 제1 문자열 내의 적어도 하나의 문자가 대체된 제2 문자열을 획득할 수 있 다. 제2 ASR 모듈은, 제1 문자열로부터 복수의 추정 문자열들의 가능도를 계산할 수 있다. 제2 ASR 모듈 는, 계산된 가능도에 기초하여, 제1 문자열을 제2 문자열로 대체할 지를 결정할 수 있다. 제2 ASR 모듈는,결정에 기초하여, 제1 문자열 내의 적어도 하나의 문자를 다른 문자로 대체함으로써 제1 문자열로부터 제2 문자 열을 획득할 수 있다. 제2 ASR 모듈는, 가능도, 사전 정보, 및 언어 모델에 기초하여, 복수의 추정 문자열 들 중 하나인 제2 문자열을 획득할 수 있다. 도 12의 제2 ASR 모듈은, 도 7 및 도 9의 프로세서에 대응될 수 있으므로 중복되는 설명은 생략한다. 제2 ASR 모듈은, 제2 문자열을 출력부를 통해 출력할 수 있다. 본 개시의 일 실시 예에 따른 출력부는, 제1 문자열 또는 제2 문자열에 대응하는 음성 인식 결과를 출력 할 수 있다. 출력부는, 음성 인식이 수행된 결과를 사용자에게 알리거나, 외부 디바이스(예를 들어, 스마 트 폰, 가전 제품, 웨어러블 디바이스, 서버 등)에게 전송할 수 있다. 예를 들어, 출력부는, 오디오 신호 를 출력 할 수 있는 스피커 또는 비디오 신호를 출력 할 수 있는 디스플레이를 포함할 수 있다. 또는, 일 실시예에 따른 디바이스는, 제1 문자열 또는 제2 문자열을 해석한 결과에 대응하는 동작을 수행 할 수 있다. 예를 들어, 디바이스는, 음성 인식이 수행된 결과에 대응하는 디바이스의 기능을 결정하 고, 해당 기능을 수행하는 화면을 출력부를 통해 출력할 수 있다. 또는, 디바이스는, 음성 인식이 수 행된 결과에 대응하는 키워드를 외부 서버로 전송하고, 전송된 키워드에 관련된 정보를 서버로부터 수신하여 출 력부를 통해 화면 상에 출력할 수 있다. 또는, 일 실시예에 따른 디바이스는, 제1 문자열 또는 제2 문자열에 대한 자연어 처리를 통해 사용자의 발 화 의도를 파악함으로써, 음성 비서 서비스에 관련된 정보를 출력부를 통해 출력 할 수 있다. 디바이스 는 음성 비서 서비스를 제공하기 위하여, 디바이스 내의 NLU (Natural Language Understanding) 모 델, DM (Dialog Mananer) 모델 및 NLG (Natural Language Generating) 모델 등을 이용할 수 있다. 일 예로서, 디바이스는, 사용자의 상황, 디바이스의 상황 등을 고려하여 사람이 사용자와 직접 대화하는 것처럼, 제1 문자열 또는 제2 문자열에 기초하여 응답 메시지를 생성하고 출력할 수 있다. 다른 예로서, 디바이 스는, 제1 문자열 또는 제2 문자열에 기초하여 사용자가 필요한 정보를 생성하여 출력할 수 있다. 다른 예 로서, 디바이스는, 제1 문자열 또는 제2 문자열에 기초하여 사용자의 발화 의도를 파악하고, 서비스 제공 서버에게 사용자가 필요로 하는 서비스의 제공을 요청할 수 있다. 디바이스는, 서비스 제공 서버로부터 수 신된 정보를 출력부를 통해 전송할 수 있다. 본 개시의 일 실시 예에 따른 제2 ASR 모듈은, 제1 ASR 모듈이 이용하는 제1 데이터에 비하여 많은 양의 언어 모델 및 사전 정보를 포함하는 제2 데이터를 이용할 수 있다. 또한, 제2 데이터는, 제1 데이터에 비하여 지명, 인명, 상표명등과 같은 개체명들을 많이 포함할 수 있다. 따라서, 제2 ASR 모 듈에 의한 음성 인식에 의하면, 방대한 양의 개체명을 포함하는 사전 정보 및 언어 모델을 이용할 수 있으 므로 높은 정확도의 음성 인식을 수행할 수 있다. 그러므로, 도 12의 디바이스는, 지연 시간을 최소화 하기 위하여, 받아쓰기, 일반적인 명령, 자막 생성등 과 같은 일반적인 목적의 음성 인식은 제1 ASR 모듈에서 수행할 수 있다. 반면에, 디바이스는, 제1 ASR 모듈로부터 출력된 제1 문자열의 신뢰도가 충분하지 않다고 판단되는 경우, 제2 ASR 모듈에서 제 1 문자열에 대한 추가적인 처리를 수행할 수 있다. 제2 ASR 모듈은, 제1 데이터 보다 많은 양의 정보 를 포함하는 제2 데이터를 이용함으로써 음성 인식의 정확도를 높일 수 있다. 한편, 일 실시 예에 따른 디바이스의 프로세서는, 제2 ASR 모듈에서 교정된 문자열을 획득하고, 교정이 필요 없다고 판단되어 제2 ASR 모듈에게 전송되지 않았던 문자열을 교정된 문자열과 조합할 수 있 다. 일 실시 예에 따른 디바이스는, 조합된 문자열을 출력하거나, 조합된 문자열에 기초하여 음성 인식이 수행된 결과를 출력하거나, 조합된 문자열을 해석한 결과에 기초하여 음성 비서 서비스를 제공할 수 있다. 또한, 일 실시 예에 따른 프로세서의 결정부는 제2 ASR 모듈에게 제1 문자열에 대한 교정을 요 청하면서, 제1 문자열에 관련된 도메인 정보를 함께 제공할 수 있다. 도메인 정보는 도메인을 식별하기 위한 정 보로서, 예를 들어, 도메인의 명칭, 도메인의 식별자를 포함할 수 있으나, 이에 제한되지 않는다. 디바이스의 결정부는, 제1 ASR 모듈로부터 출력된 제1 문자열의 도메인 신뢰도에 기초하여, 제1 문자열에 관련된 도메인을 식별할 수 있다. 도메인 신뢰도는, 제1 문자열의 적어도 일부가 특정 도메인에 어느 정도 관련되었는지를 나타내는 수치일 수 있다. 예를 들어, 결정부는, 제1 ASR 모듈로부터 출력된 제 1 문자열이 제1 데이터에 미리 등록된 도메인에 어느 정도 관련성이 있는 지를 나타내는 컨피던스 스코어 를 산출할 수 있다. 또한, 디바이스는 산출된 도메인 신뢰도에 기초하여, 제1 문자열에 관련된 도메인을식별할 수 있다. 디바이스는 룰 기반으로 제1 문자열에 관련된 도메인을 식별하거나 도메인 식별을 위해 훈련된 인공 지능 모델을 이용하여 제1 문자열에 관련된 도메인 신뢰도를 획득할 수 있다. 한편, 본 개시의 일 실시 예에 따른 제2 ASR 모듈은, 제2 데이터에 포함되는 도메인 별로 서로 다른 사전 정보 및 언어 모델을 이용하여, 제1 문자열에 대한 디코딩을 수행할 수 있다. 따라서, 본 개시의 일 실시 예에 따른 제2 ASR 모듈은, 제1 문자열에 대한 재 디코딩을 통해 음성 인식 정확도가 높아진 음성 인식 결 과를 출력할 수 있다. 일 실시 예에 따른 제2 ASR 모듈은, 결정부로부터 제1 문자열을 수신하고, 제1 문자열에 관련된 도메 인을 결정할 수 있다. 제2 ASR 모듈은, 결정된 도메인에 대응되는 사전 정보 및 언어 모델을 이용하여, 제 1 문자열에 대한 디코딩을 수행할 수 있다. 일 예로서, 제2 ASR 모듈은, 결정부로부터 제1 문자열과 함께 제1 문자열에 관련된 도메인 정보를 수 신하고, 수신된 정보에 기초하여 제1 문자열에 대한 디코딩을 수행할 도메인을 결정할 수 있다. 예를 들어, 제2 ASR 모듈은, 결정부로부터 수신된 정보로부터 식별된 도메인과 동일하거나 유사한 도메인을 디코딩을 수행할 도메인으로서 결정할 수 있다. 다른 예로서, 제2 ASR 모듈은 결정부로부터 수신된 제1 문자열에 기초하여, 수신된 제1 문자열에 관 련된 도메인을 결정할 수 있다. 디바이스는 도메인 식별을 위해 훈련된 인공 지능 모델인 도메인 식별 모 델을 메모리에 저장할 수 있다. 제2 ASR 모듈은, 도메인 식별 모델을 이용하여, 제1 문자열을 입력 값으로 하여 도메인 신뢰도를 출력할 수 있다. 제2 ASR 모듈은, 도메인 신뢰도에 기초하여, 제1 문자열에 관련된 도메인을 결정할 수 있다.. 또 다른 예로서, 일 실시예에 따른 제2 ASR 모듈은, 결정부로부터 제1 문자열과 함께 제1 문자열에 관련된 도메인을 판단하기 위한 정보를 수신할 수 있다. 결정부로부터 수신된 도메인을 판단하기 위한 정 보는 컨텍스트 정보를 포함할 수 있다. 예를 들어, 컨텍스트 정보는, 사용자가 현재 디바이스 상에서 이용 하고 있는 애플리케이션에 대한 정보, 대화 이력 정보, 디바이스 주변의 상황 정보 또는 트렌드 정보 중 적어도 하나를 포함할 수 있다. 제2 ASR 모듈은, 컨텍스트 정보를 기반으로 제1 문자열에 대한 디코딩을 수행할 도메인을 결정할 수 있다. 컨텍스트 정보 기반으로 도메인을 결정하는 구체적인 방법에 대해서는 도 9의 프로세서의 동작 방법이 적용될 수 있으므로, 중복되는 설명은 생략한다. 이하에서는, 일 실시 예에 따른 디바이스의 동작 방법을 설명한다. 이하에서 서술하는 디바이스의 동 작 방법의 각 단계는, 도 3, 도 4a, 및 도 4b에 도시된 구성들에 의해 수행될 수 있다. 중복되는 설명은 생략한 다. 도 13은 일 실시 예에 따라 디바이스가 음성 인식을 수행하는 방법의 흐름도를 도시한다. 단계 S1310에서 본 개시의 일 실시 예에 따른 디바이스는, 음성 신호에 대한 음성 인식을 수행하여 제1 문 자열을 획득할 수 있다. 본 개시의 일 실시 예에 따른 디바이스는, 다양한 음성 인식 방식을 이용하여 음성 인식을 수행하여 제1 문자열을 추정할 수 있다. 일 예로서, 디바이스는, 음향 모델, 사전 정보 및 언어 모델을 이용하여, 음성 신호로부터 문자열을 획득 할 수 있다. 먼저, 디바이스는, 음향 모델을 이용하여, 음성 신호에 포함되는 음소열을 획득할 수 있다. 예를 들어, 디바이스는, 은닉 마르코프 모델, 가우스 혼합 모델, 베이즈 추론, 및 다층 신경망 등을 이용 하여 음소들을 포함하는 음소열을 추정할 수 있다. 디바이스는, 사전 정보 및 언어 모델에 기초하여, 음소 열로부터 단어들을 추정하고 추정된 단어들을 포함하는 제1 문자열을 획득할 수 있다. 다른 예로서, 디바이스는, 음성 신호로부터 특징 벡터를 추출하고, 심층 신경망(DNN)을 이용하여, 특징 벡 터로부터 제1 문자열을 획득할 수 있다. 예를 들어, 제1 문자열은, 음성 신호가 소정 시간 간격으로 분할된 음성 신호 프레임들 각각에 대응하는 문자들 을 포함하는 프레임 동기화된 문자열일 수 있다. 또는, 예를 들어, 제1 문자열은, 음성 신호에 의해 발음되는 각 문자를 하나씩 포함하도록 라벨 동기화 방식으로 획득된 문자열일 수 있다. 일 실시 예에 따른 디바이스는, 제1 문자열이 프레임 동기화되지 않은 경우, 강제 정렬을 수행함으로써 프 레임 동기화된 문자열을 획득할 수 있다. 프레임 동기화된 문자열 및 강제 정렬에 의해 프레임 동기화된 문자열을 생성하는 구체적인 방법과 관련하여서는, 도 6을 참조하여 상술한 내용이 적용될 수 있다. 중복되는 설명은 생략한다. 단계 S1330에서 본 개시의 일 실시 예에 따른 디바이스는, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 일 예로서, 일 실시 예에 따른 디바이스는, 제1 문자열의 신뢰도를 결정하고, 신뢰도에 기초하여 제1 문자 열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 예를 들어, 디바이스는, 신뢰도가 임계값 보다 높 거나 같으면, 제1 문자열을 다른 문자열로 대체하지 않아도 된다고 결정할 수 있다. 반면에, 디바이스는, 신뢰도가 임계값보다 작으면, 제1 문자열을 다른 문자열로 대체할 것을 결정할 수 있다. 제1 문자열의 신뢰도는, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도, 및 제1 문자열 내의 적어 도 하나의 문자가 다른 문자로 대체될 사후 확률들 중 적어도 하나에 기초하여 계산될 수 있다. 예를 들어, 디바이스는, 비터비(Viterbi) 디코딩 결과 출력되는 가능도에 기초하여 신뢰도를 계산할 수 있 다. 또는, 프로세서는, 엔드-투-엔드 방식 음성 인식 모델에서 소프트맥스 레이어로부터 출력되는 사후 확 률들에 기초하여 신뢰도를 계산할 수 있다. 또는, 일 실시 예에 따른 디바이스는, 음성 신호에 대한 음성 인식 과정에서 추정되는 복수의 추정 문자열 들을 결정하고, 복수의 추정 문자열들의 상관도에 기초하여, 제1 문자열의 신뢰도를 계산할 수 있다. 제1 문자 열을 포함하는 복수의 추정 문자열들의 상관도가 높을 수록, 제1 문자열의 신뢰도가 높을 수 있다. 다른 예로서, 디바이스는, 미리 저장된 키워드들과 제1 문자열을 비교한 결과에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 예를 들어, 디바이스는, 제1 문자열에 미리 저장된 키워 드들이 포함되지 않는 경우, 제1 문자열을 다른 문자열로 대체할 것을 결정할 수 있다. 또 다른 예로서, 디바이스는, 제1 문자열이 관련된 도메인 또는 제1 문자열 내에 개체명이 포함되는지 여 부에 기초하여, 제1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 예를 들어, 디바이스는, 제1 문자열이 개체명 위주의 도메인과 관련이 있다고 판단되는 경우, 제1 문자열을 다른 문자열로 대체할 것을 결정할 수 있다. 제1 문자열을 다른 문자열로 대체할 것을 결정한 경우, 단계 S1340에서 본 개시의 일 실시 예에 따른 디바이스 는 제1 문자열을 서버로 전송할 수 있다. 일 실시 예에 따른 디바이스는, 프레임 동기화된 제1 문자열을 서버로 전송할 수 있다. 디바이스는, 복수의 문자들을 포함하는 문자열 전체를 동시에 전송 할 수도 있고, 문자열에 포함되는 적어도 일부 문자들을 순차적으로 전송할 수도 있다. 또한, 일 실시 예에 따 른 디바이스는, 단어 단위로 또는 문장 단위로 제1 문자열을 전송할 수 있다. 한편, 제1 문자열을 다른 문자열로 대체하지 않을 것을 결정한 경우, 단계 S1370에서 본 개시의 일 실시 예에 따른 디바이스는 제1 문자열을 출력할 수 있다. 일 실시 예에 따른 디바이스는, 제1 문자열을 그대로 출력하거나, 제1 문자열로부터 획득되는 단어열을 출력할 수 있다. 단계 S1350에서 본 개시의 일 실시 예에 따른 디바이스는, 제2 문자열을 서버로부터 수신할 수 있다. 제2 문자열은, 서버에 의해 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 대체됨으로써 획득된 문자 열일 수 있다. 단계 S1360에서 본 개시의 일 실시 예에 따른 디바이스는, 제2 문자열을 출력할 수 있다. 일 실시 예에 따 른 디바이스는, 제2 문자열을 그대로 출력하거나, 제2 문자열로부터 획득되는 단어열을 출력할 수 있다. 본 개시는 도 13에 도시된 바와 같이 디바이스가 제1 문자열 또는 제2 문자열을 그대로 출력하는 실시예에 제한되지 않는다. 일 실시예에 따른 디바이스는, 제1 문자열 또는 제2 문자열에 대한 자연어 처리를 통해 사용자의 발화 의도를 파악함으로써, 음성 비서 서비스에 관련된 정보를 출력 할 수 있다. 디바이스는 제1 문자열 또는 제2 문자열에 기초하여 음성 비서 서비스를 제공하기 위하여, 디바이스 내의 NLU 모델, DM 모델 및 NLG 모델 등을 이용할 수 있다. 예를 들어, 디바이스는, 사용자의 상황, 디바이스의 상황 등을 고려하여 사람이 사용자와 직접 대화하는 것처럼, 제1 문자열 또는 제2 문자열에 기초하여 응답 메시지를 생성하고 출력할 수 있다. 또는, 예를 들어, 디 바이스는, 제1 문자열 또는 제2 문자열에 기초하여 사용자가 필요한 정보를 생성하여 출력할 수 있다. 또 는, 예를 들어, 디바이스는, 제1 문자열 또는 제2 문자열에 기초하여 사용자의 발화 의도를 파악하고, 서비스 제공 서버에게 사용자가 필요로 하는 서비스의 제공을 요청할 수 있다. 디바이스는, 서비스 제공 서 버로부터 수신된 정보를 출력할 수 있다. 한편, 일 실시예에 따른 디바이스는, 서버로부터 제2 문자열을 수신하는 대신에, 제2 문자열에 기초 하여 생성된 음성 비서 서비스에 관련된 정보를 수신하고, 수신된 정보를 출력할 수 있다. 음성 비서 서비스에 관련된 정보는, 제1 문자열이 교정된 제2 문자열에 기초하여 서버에 의해 생성되는 정보일 수 있다. 예를 들어, 음성 비서 서비스에 관련된 정보는, 사용자의 음성 신호에 대한 응답 메시지, 사용자가 필요로 하는 서비 스, 또는 사용자가 필요한 정보를 포함할 수 있다. 도 13에 도시된 바와 같이, 일 실시 예에 따른 디바이스는, 온-디바이스 음성 인식 모듈로부터 출력된 제1 문자열을 다른 문자열로 대체할 지 여부를 판단하고, 판단 결과에 기초하여 서버-기반 후처리를 선택적으로 이 용할 수 있다. 일 실시 예에 따른 디바이스는, 사용자에 의해 발화되는 단어 단위(또는, 문장 단위)로 음성 인식 모듈로 부터 출력된 제1 문자열의 신뢰도를 계산하고, 신뢰도에 기초하여 제1 문자열을 대체할 지 여부를 결정할 수 있 다. 도 14는 일 실시 예에 따라 디바이스가 음성 인식을 수행하는 구체적인 방법에 있어서, 도 13의 단계 S1310을 구체화한 흐름도를 도시한다. 단계 S1411에서 일 실시 예에 따른 디바이스는 음성 신호를 수신하고, 단계 S1413에서 단어의 경계가 검출 되었는지 여부를 판단할 수 있다. 일 실시 예에 따른 디바이스는 단어의 경계가 검출될 때까지 계속적으로 음성 프레임들을 포함하는 음성 신호를 수신할 수 있다. 예를 들어, 디바이스는, 음성 신호로부터 검출되는 퍼즈(pause), 또는 억양 및 강세를 포함하는 운율적 (prosodic) 정보에 기초하여 단어의 경계를 검출할 수 있다. 단어의 경계가 검출되면, 단계 S1415에서 일 실시 예에 따른 디바이스는 음성 신호로부터 제1 문자열을 획 득할 수 있다. 단계 S1431에서 본 개시의 일 실시 예에 따른 디바이스는, 제1 문자열의 신뢰도를 계산할 수 있다. 제1 문 자열의 신뢰도는, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도, 및 제1 문자열 내의 적어도 하나 의 문자가 다른 문자로 대체될 사후 확률들 중 적어도 하나에 기초하여 계산될 수 있다. 예를 들어, 디바이스는, 비터비 디코딩 결과 출력되는 가능도에 기초하여 신뢰도를 계산할 수 있다. 또는, 디바이스는, 엔드-투-엔드 방식 음성 인식 모델에서 소프트맥스 레이어로부터 출력되는 사후 확률들에 기 초하여 신뢰도를 계산할 수 있다. 또는, 일 실시 예에 따른 디바이스는, 음성 신호에 대한 음성 인식 과정에서 추정되는 복수의 추정 문자열 들을 결정하고, 복수의 추정 문자열들의 상관도에 기초하여, 제1 문자열의 신뢰도를 계산할 수 있다. 제1 문자 열을 포함하는 복수의 추정 문자열들의 상관도가 높을 수록, 제1 문자열의 신뢰도가 높을 수 있다. 단계 S1433에서 본 개시의 일 실시 예에 따른 디바이스는, 신뢰도가 임계값보다 작은지 여부를 판단할 수 있다. 제1 문자열의 신뢰도가 임계값보다 작은 경우, 단계 S1340에서 본 개시의 일 실시 예에 따른 디바이스는 제1 문자열을 서버로 전송할 수 있다. 디바이스는, 전송된 제1 문자열에 응답하여, 서버에 의해 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 대체된 제2 문자열을 수신할 수 있다. 디바이스는, 수 신된 제2 문자열을 출력할 수 있다. 반면에, 제1 문자열의 신뢰도가 임계값보다 크거나 같은 경우, 단계 S1370에서 본 개시의 일 실시 예에 따른 디 바이스는 제1 문자열을 출력할 수 있다. 한편, 일 실시예에 따른 디바이스는, 제1 문자열 또는 제2 문자열을 그대로 출력하는 대신에, 제1 문자열 또는 제2 문자열에 대한 자연어 처리를 통해 사용자의 발화 의도를 파악함으로써, 음성 비서 서비스에 관련된 정보를 출력 할 수 있다. 디바이스는 제1 문자열 또는 제2 문자열에 기초하여 음성 비서 서비스를 제공하기 위하여, 디바이스 내의 NLU 모델, DM 모델 및 NLG 모델 등을 이용할 수 있다.예를 들어, 디바이스는, 사용자의 상황, 디바이스의 상황 등을 고려하여 사람이 사용자와 직접 대화하는 것처럼, 제1 문자열 또는 제2 문자열에 기초하여 응답 메시지를 생성하고 출력할 수 있다. 또는, 예를 들어, 디 바이스는, 제1 문자열 또는 제2 문자열에 기초하여 사용자가 필요한 정보를 생성하여 출력할 수 있다. 또 는, 예를 들어, 디바이스는, 제1 문자열 또는 제2 문자열에 기초하여 사용자의 발화 의도를 파악하고, 서 비스 제공 서버에게 사용자가 필요로 하는 서비스의 제공을 요청할 수 있다. 디바이스는, 서비스 제공 서 버로부터 수신된 정보를 출력할 수 있다. 한편, 일 실시예에 따른 디바이스는, 전송된 제1 문자열에 응답하여 서버로부터 제2 문자열을 수신하 는 대신에, 제2 문자열에 기초하여 생성된 음성 비서 서비스에 관련된 정보를 수신할 수 있다. 디바이스는, 서버로부터 수신된 정보를 출력할 수 있다. 음성 비서 서비스에 관련된 정보는, 제1 문 자열이 교정된 제2 문자열에 기초하여 서버에 의해 생성되는 정보일 수 있다. 예를 들어, 음성 비서 서비스에 관련된 정보는, 사용자의 음성 신호에 대한 응답 메시지, 사용자가 필요로 하는 서비스, 또는 사용자가 필요한 정보를 포함할 수 있다. 도 14에 도시된 바와 같이, 본 개시의 일 실시 예에 따른 디바이스는 제1 문자열의 신뢰도에 기초하여, 제 1 문자열을 다른 문자열로 대체할 지 여부를 결정할 수 있다. 디바이스는, 제1 문자열의 신뢰도가 임계값 미만인 경우, 제1 문자열을 서버로 전송할 수 있다. 디바이스는, 서버 내의 사전 정보 및 언어 모델에 기초하여 제1 문자열의 적어도 하나의 문자가 다른 문자로 대체됨으로써 획득된 제2 문자열을 서버(20 0)로부터 획득할 수 있다. 따라서, 일 실시 예에 따른 디바이스는, 제1 문자열보다 높은 신뢰도를 갖는 제 2 문자열을 서버로부터 수신하여 이용함으로써 음성 인식 정확도를 높일 수 있다. 도 14에는 사용자에 의해 발화되는 단어 단위로 음성 인식 결과의 신뢰도를 계산하고, 제1 문자열을 대체할 지 여부를 결정하는 실시 예가 도시된다. 그러나, 본 개시는 도 14에 도시된 예에 제한되지 않으며, 일 실시 예에 따른 디바이스는, 사용자에 의해 발화되는 문장 단위로 음성 인식 결과의 신뢰도를 계산하고, 제1 문자열 을 대체할 지 여부를 결정할 수 있다. 사용자에 의해 발화되는 문장의 종료를 검출하는 방법은 종래의 다양한 방법이 이용될 수 있으며, 본 개시에서는 구체적인 설명은 생략한다. 도 15는 일 실시 예에 따라 서버의 동작 방법의 흐름도를 도시한다. 이하에서 서술하는 서버의 동작 방법의 각 단계는, 도 7 및 도 9에 도시된 구성들에 의해 수행될 수 있다. 중복되는 설명은 생략한다. 단계 S1510에서 본 개시의 일 실시 예에 따른 서버는, 디바이스로부터 제1 문자열을 수신할 수 있다. 제1 문자열은, 디바이스에 의해 음성 신호로부터 음성 인식 처리를 거쳐 출력될 수 있다. 일 예로서, 서버에서 수신되는 제1 문자열은, 음성 신호가 소정 시간 간격으로 분할된 음성 신호 프레임들 각각에 대응하는 문자들을 포함하는 프레임 동기화 문자열일 수 있다. 다른 예로서, 서버에서 수신되는 제 1 문자열은, 프레임 동기화되지 않은 문자열일 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 디바이스로부터 수신되는 제1 문자열이 프레임 동기화되지 않은 문자열인 경우, 제1 문자열로부터 프레임 동기화된 문자열을 획득할 수 있다. 프로세서는, 제1 문자 열에 포함되는 적어도 하나의 문자를 소정 시간 간격의 프레임 단위로 연속하여 배치함으로써, 프레임 동기화된 문자열을 획득할 수 있다. 단계 S1520에서 본 개시의 일 실시 예에 따른 서버는, 제1 문자열로부터 복수의 추정 문자열들에 대한 가 능도를 산출할 수 있다. 일 실시예에 따른 서버는, 제1 문자열 내의 각 문자를 다른 문자로 대체함으로써, 복수의 추정 문자열들을 획득할 수 있다. 복수의 추정 문자열들의 가능도란, 제1 문자열로부터 획득되는 복수의 추정 문자열들 각각이 참값 문자열이라고 가정하였을 때, 음성 인식 모듈로부터 제1 문자열이 추정될 확률을 의 미할 수 있다. 본 개시의 일 실시예에 따르면, 서버는, 제1 문자열 내의 각 문자와 발음이 유사한 대체 문자들을 식별하 고, 식별된 대체 문자들에 기초하여 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 교정된 추정 문자열들 을 결정하기 위하여, 제1 문자열로부터 획득되는 가능도를 획득할 수 있다. 일 실시예에 따른 서버는, 제1 문자열 내의 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가능 도 행렬들을 산출하고, 가능도 행렬들 내의 가능도 값들에 기초하여 복수의 추정 문자열들을 식별할 수 있다. 서버는, 복수의 추정 문자열들에 대한 가능도로서, 각 문자로부터 획득되는 가능도 행렬들을 획득할 수 있 다. 일 예로서, 서버는, 제1 문자열 내의 각 문자의 이전에 누적된 문자들에 기초하여, 제1 문자열로부터 가능 도를 산출 할 수 있다. 일 실시 예에 따른 서버는, 제1 문자열 내의 각 문자의 이전에 누적된 문자들에 기 초하여 각 문자의 사후 확률들을 계산할 수 있다. 서버는, 제1 문자열 내의 각 문자의 이 전에 누적된 문 자들에 기초하여 문자 배열 확률을 계산할 수 있다. 서버는, 각 문자의 사후 확률들 및 문자 배열 확률에 기초하여, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도를 계산할 수 있다. 다른 예로서, 서버는, 제1 문자열 내의 각 문자의 이전에 누적된 문자들을 고려하지 않고, 각 문자만을 고 려하여 제1 문자열로부터 가능도를 산출 할 수 있다. 일 실시예에 따른 서버는, 미리 결정된 오차 행렬에 기초하여, 제1 문자열 내의 각 문자의 사후 확률들을 계산할 수 있다. 서버는, 제1 문자열 내의 각 문자의 사후 확률들에 기초하여, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도를 계산할 수 있다. 단계 S1530에서 본 개시의 일 실시 예에 따른 서버는, 단계 S1520에서 산출된 가능도에 기초하여, 제1 문 자열 내의 적어도 하나의 문자를 다른 문자로 대체함으로써 제1 문자열로부터 제2 문자열을 획득할 수 있다. 일 실시 예에 따른 서버는, 계산된 가능도에 기초하여, 제1 문자열 내의 적어도 하나의 문자가 다른 문자 로 대체된 복수의 추정 문자열들을 식별할 수 있다. 서버는, 식별된 복수의 추정 문자열에 대한 가능도, 언어 모델, 및 사전 정보에 기초하여, 복수의 추정 문자열들 중에서 제2 문자열을 획득할 수 있다. 일 실시 예에 따른 서버는, 계산된 가능도에 기초하여, 제1 문자열을 제2 문자열로 대체할 지를 결정할 수 있다. 서버는, 결정에 기초하여, 제1 문자열 내의 적어도 하나의 문자를 다른 문자로 대체함으로써 제1 문 자열로부터 제2 문자열을 획득할 수 있다. 서버는, 가능도, 사전 정보, 및 언어 모델에 기초하여, 복수의 추정 문자열들 중에서 가능도를 최대로 하는 추정 문자열을 선택할 수 있다. 서버는, 선택된 추정 문자열 에 따라, 제1 문자열 내의 적어도 하나의 문자가 다른 문자로 대체된 제2 문자열을 획득할 수 있다. 일 예로서, 서버는, 서버 내에 저장되는 사전 정보 및 언어 모델을 기반으로 WFST 디코더를 이용하여 제2 문자열을 획득할 수 있다. 서버가 WFST 디코딩을 수행하는 경우, 일 실시 예에 따른 서버는, 문 자들 간의 관계(T), 단어와 문자들의 매핑 정보를 포함하는 사전 정보(L), 및 특정 단어열이 주어졌을 때 다음 에 나올 단어들의 확률을 추정하는 언어 모델(G)에 기초하여, WFST로 탐색 공간을 구성하여 디코딩 할 수 있다. 다른 예로서, 서버는, 사전 정보 및 언어 모델에 기초하여, 제1 문자열로부터 획득되는 복수의 추정 문자 열들의 가능도를 재 연산하는 비터비 디코더를 포함할 수 있다. 비터비 디코더는, 재 연산된 가능도를 최대로 하는 제2 문자열을 복수의 추정 문자열들 중에서 결정할 수 있다. 비터비 디코더는, 사전 정보 및 언어 모델을 고려하여, 제1 문자열들에 대한 가장 가능성 높은 문자열을 제2 문자열로서 찾아낼 수 있다. 단계 S1540에서 본 개시의 일 실시 예에 따른 서버는, 제2 문자열을 디바이스에게 전송할 수 있다. 또한, 일 실시 예에 따른 서버는, 자연어 이해 모델을 이용하여 제2 문자열을 해석하고, 해석한 결과에 기 초하여 사용자의 음성 신호에 대한 응답 메시지를 생성할 수 있다. 서버는, 응답 메시지를 생성하고 디바 이스에게 추가로 전송할 수 있다. 본 개시는 도 15에 도시된 바와 같이 서버가 제2 문자열을 그대로 디바이스에게 전송하는 실시예에 제한되지 않는다. 일 실시예에 따른 서버는, 제2 문자열에 대한 자연어 처리를 통해 사용자의 발화 의도를 파악함으로써, 음성 비서 서비스에 관련된 정보를 전송 할 수 있다. 서버는 제2 문자열에 기초하여 음성 비서 서비스를 제공하기 위하여, 서버 내의 NLU 모델, DM 모델 및 NLG 모델 등을 이용할 수 있다. 일 예로서, 서버는, 제2 문자열을 해석한 결과를 바탕으로, 디바이스 또는 다른 디바이스를 제어하기 위한 제어 명령을 생성하고, 생성된 제어 명령을 디바이스에게 전송할 수도 있다. 다른 예로서, 서버(20 0)는, 사용자의 상황, 디바이스의 상황 등을 고려하여 사람이 사용자와 직접 대화하는 것처럼, 제2 문자열에 기 초하여 응답 메시지를 생성하고 전송할 수 있다. 다른 예로서, 서버는, 제2 문자열에 기초하여 사용자가 필요한 정보를 생성하여 전송할 수 있다. 다른 예로서, 서버는, 제2 문자열에 기초하여 사용자의 발화 의 도를 파악하고, 서비스 제공 서버에게 사용자가 필요로 하는 서비스의 제공을 요청할 수 있다. 서버는, 서 비스 제공 서버로부터 수신된 정보를 전송할 수 있다. 도 16은, 일 실시 예에 따른 서버의 동작 방법에 있어서, 각 문자의 이 전에 누적된 문자들을 고려하여 문자열 로부터 가능도를 획득하는 방법을 구체적으로 도시한다.단계 S1510에서 본 개시의 일 실시 예에 따른 서버는, 디바이스로부터 제1 문자열을 획득할 수 있다. 단계 S1621에서 일 실시 예에 따른 서버는, 제1 문자열 내의 각 문자의 이전 문자들에 기초하여 각 문자의 사후 확률들을 획득할 수 있다. 예를 들어, 서버는, 문자열의 사후 확률을 계산하기 위해 미리 훈련된 신경망을 이용해서, 제1 문자열 내 의 각 문자의 사후 확률들을 계산할 수 있다. 단계 S1623에서 일 실시 예에 따른 서버는, 제1 문자열로부터 문자 배열 확률을 계산할 수 있다. 단계 S1625에서 일 실시 예에 따른 서버는, 단계 S1621에서 계산된 사후 확률들 및 단계 S1623에서 계산된 문자 배열 확률에 기초하여, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도를 계산할 수 있다. 일 실시예에 따른 서버는, 제1 문자열 내의 각 문자에 대하여 각 문자가 대체될 대체 문자들에 관한 가능도 행렬들을 산출하고, 산출된 가능도 행렬들을 포함하는 복수의 추정 문자열들의 가능도를 획득할 수 있다. 일 실시 예에 따른 서버는, 제1 문자열에 포함되는 모든 문자들에 대해서 가능도 행렬이 계산되었는지 여 부를 판단할 수 있다. 일 실시 예에 따른 서버는, 제1 문자열에 포함되는 모든 문자들에 대해서 가능도 행 렬들이 계산될 때까지 단계 S1621, S1623, S1625를 반복하여 수행할 수 있다. 제1 문자열로부터 가능도를 계산하는 구체적인 과정은, 도 9를 참조하여 상술하였으므로, 중복되는 설명은 생략 한다. 단계 S1627에서 일 실시 예에 따른 서버는, 사전 정보 및 언어 모델을 이용하여, 단계 S1625에서 계산된 가능도로부터 제2 문자열을 획득할 수 있다. 제2 문자열은, 제1 문자열의 적어도 하나의 문자가 다른 문자로 대 체된 문자열일 수 있다. 예를 들어, 서버는, 가능도를 입력으로 하는 WFST 디코더 또는 전통적인 토큰 패싱을 이용하는 비터비 디 코더를 이용하여, 사전 정보, 언어 모델, 및 계산된 가능도에 기초하여, 복수의 추정 문자열들 중에서 제2 문자 열을 획득할 수 있다. 단계 S1540에서 일 실시 예에 따른 서버는, 제2 문자열을 디바이스에게 전송할 수 있다. 일 실시예에 따른 서버는, 제2 문자열을 그대로 디바이스에게 전송하는 대신에, 제2 문자열에 대한 자연어 처리를 통해 사용자의 발화 의도를 파악함으로써 음성 비서 서비스에 관련된 정보를 전송 할 수 있다. 중복되는 설명은 생략한다. 도 17은 일 실시 예에 따른 WFST(weighted Finite State Transducer) 디코딩을 설명하기 위한 도면이다. 본 개시의 일 실시 예에 따른 서버는, 디바이스로부터 수신된 제1 문자열로부터 가능도를 계산하고, 계산된 가능도를 입력으로 하여 WFST 디코딩을 수행할 수 있다. 본 개시의 일 실시 예에 따른 서버는, 제1 문자열로부터 획득되는 복수의 추정 문자열들의 가능도(T), 단어와 문자들의 매핑 정보를 포함하는 사전 정보 (L), 및 특정 단어열이 주어졌을 때 다음에 나올 단어들의 확률을 추정하는 언어 모델(G)을 각각 WFST(weighted finite-state transducer)로 모델링함으로써 WFST 디코딩을 수행할 수 있다. 이하에서는, 단어들 'the, cat, and, deer, is, cardinals, baseball, team' 간의 관계에 관한 정보를 저장하 는 언어 모델을 WFST로 모델링한 예를 설명한다. 도 17은 언어 모델에 기초하여 단어들을 조합함으로써 만들 수 있는 유한한 개수의 문자열들을 도시한다. 도 17의 각 원은 상태(state)를 나타내고, 화살표 상에는 언어 모델에 저장되는 단어가 표시된다. WFST 디코더 는 복수의 경로들을 따라 조합되는 복수의 문자열들 각각으로부터 문자열에 대한 신뢰도를 계산할 수 있다. 각 문자열에 대한 신뢰도는, 각 문자열에 대한 가능도, 사전 정보, 및 언어 모델에 기초하여 계산될 수 있다. WFST 디코더는, 신뢰도가 가장 높은 문자열을 선택하고 출력할 수 있다. 예를 들어, 도 8a에 도시된 바와 같이 본 개시의 일 실시 예에 따른 서버는, 디바이스로부터 제1 문 자열 [The cat and deer is baseball team]을 수신할 수 있다. 서버는, 제1 문자열로부터 복수의 추정 문자열들의 가능도를 계산할 수 있다. 계산된 가능도가 서버 의 WFST 디코더에 입력됨에 따라, WFST 디코더는 제2 문자열을 출력할 수 있다. WFST 디코더는, 복수의 추정 문 자열들 중에서 신뢰도가 가장 높은 제2 문자열을 결정하고 출력할 수 있다. 도 8a에 도시된 바와 같이, 서버의 메모리 내에는, 스포츠 도메인의 개체명 \"Cardinals\"가 저장되어 있을 수 있다. 따라서, 서버의 프로세서는, 디바이스에서 추정된 'cat and deer is'가 실제로는 야구 팀 명칭인 'Cardinals'일 확률이 더 높다고 판단할 수 있다. 따라서, 도 17을 참조하면, 일 실시 예에 따른 WFST 디코더는, 복수의 추정 문자열들 [The cat and deers baseball team] 및 [The Cardinals baseball team] 중에서 신뢰도가 가장 높은 문자열인 [The Cardinals baseball team]을 제2 문자열로서 결정하고 출력할 수 있다. 도 18은 일 실시 예에 따라 디바이스 상에 음성 인식 결과가 디스플레이 되는 화면의 예를 도시한다. 일 실시 예에 따른 디바이스는, 사용자로부터 수신된 음성 신호에 대한 음성 인식을 수행하여 추정된 문자 열로부터 획득된 단어열 \"Cat and deers baseball team\"을 출력할 수 있다. 디바이스는, 온-디바이 스 음성 인식이 수행되고 있는 경우, 온-디바이스 음성 인식이 수행되고 있음을 나타내는 영상을 화면 상 에 디스플레이 할 수 있다. 본 개시의 일 실시 예에 따른 디바이스는, 온-디바이스 음성 인식을 이용한 음성 인식 수행 결과에 대한 신뢰도가 충분히 높은 경우, 음성 인식 수행 결과를 그대로 이용할 수 있다. 반면에, 본 개시의 일 실시 예에 따른 디바이스는, 온-디바이스 음성 인식을 이용하여 음성 인식을 수행한 결과의 신뢰도가 충분히 높지 않다고 판단하는 경우, 음성 인식 결과인 문자열을 서버에게 전송할 수 있다. 일 실시 예에 따른 서버는, 디바이스로부터 문자열을 수신하고, 서버 내의 언어 모델 및 사전 정보를 이용하여 디코딩을 수행함으로써, 수신된 문자열에 포함되는 적어도 하나의 문자가 교정된 문자열 \"Caldinals baseball team\"을 획득할 수 있다. 서버는, 디바이스에게 \"Caldinals baseball team \"을 전송할 수 있다. 일 실시 예에 따른 디바이스는, 서버로부터 수신된 문자열 \"Caldinals baseball team\"를 출력 할 수 있다. 디바이스는, 서버-기반 음성 인식이 수행되고 있는 경우, 서버-기반 음성 인식이 수행되고 있 음을 나타내는 영상을 화면 상에 디스플레이 할 수 있다. 도 19는 일 실시 예에 따른 디바이스의 구체적인 블록도를 도시한다. 도 19에 도시된 디바이스는 도 3에서 설명한 디바이스와 동일한 구성 요소를 포함할 수 있다. 예를 들어, 도 19에 도시된 구성 요소 중 제어부는 도 3에 도시된 프로세서와 동일하고, 출력부는 도 3에 도시된 출력부과 동일하다. 또한, 도 19에는 도시되지 않았지만, 도 19의 메모리는, 도 3의 메모리와 같이, 음성 인식을 수행하기 위한 인스트럭션들, 음성 인식에 이용되는 각종 모델, 신경망, 사전 정보 등을 저장할 수 있다. 따라서, 중복되는 설명은 생략하기로 한다. 도 19에 도시된 디바이스는 도 3 내지 도 18에서 설명한 디바이스의 동작 및 기능들을 모두 수행할 수 있다. 따라서, 이하에서는 지금까지 설명되지 않았던 디바이스의 구성 요소들에 대하여 설명하기로 한 다. 도 19를 참조하면, 디바이스는 사용자 입력부, 출력부, 제어부, 센싱부, 통신부 , A/V 입력부, 및 메모리를 포함할 수 있다. 사용자 입력부는, 사용자가 디바이스를 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들 어, 사용자 입력부에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 사용자 입력부는, 사용자에 게 제공할 대화 정보를 생성하기 위하여 필요한 사용자 입력을 수신할 수 있다. 출력부는 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레이 부, 음향 출력부, 및 진동 모터를 포함할 수 있다. 진동 모터는 진동 신호를 출력할 수 있다. 예를 들어, 진동 모터는 오디오 데이터 또는 비디오 데 이터(예컨대, 호신호 수신음, 메시지 수신음 등)의 출력에 대응하는 진동 신호를 출력할 수 있다. 센싱부는, 디바이스의 상태 또는 디바이스 주변의 상태를 감지하고, 감지된 정보를 제어부 로 전달할 수 있다. 센싱부는, 지자기 센서(Magnetic sensor), 가속도 센서(Acceleration sensor), 온/습도 센 서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서, 근 접 센서, 및 RGB 센서(illuminance sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 각 센서들의 기능은 그 명칭으로부터 당업자가 직관적으로 추론할 수 있으므로, 구체적인 설명은 생략하기로 한다. 통신부는, 다른 디바이스와의 통신을 수행하기 위한 구성 요소를 포함할 수 있다. 예를 들어, 통신부 는, 근거리 통신부, 이동 통신부, 방송 수신부를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비 (Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한 다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다 양한 형태의 데이터를 포함할 수 있다. 방송 수신부는, 방송 채널을 통하여 외부로부터 방송 신호 및/또는 방송 관련된 정보를 수신한다. 방송 채널은 위성 채널, 지상파 채널을 포함할 수 있다. 구현 예에 따라서 디바이스가 방송 수신부를 포 함하지 않을 수도 있다. 또한, 통신부는, 제1 사용자에게 제공할 대화 정보를 생성하기 위하여 필요한 정보를, 제2 대화형 전자 장치, 다른 디바이스 및 서버와 송수신할 수 있다. A/V(Audio/Video) 입력부는 오디오 신호 또는 비디오 신호 입력을 위한 것으로, 이에는 카메라와 마이크로폰 등이 포함될 수 있다. 카메라은 화상 통화모드 또는 촬영 모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 화상 프레임을 얻을 수 있다. 이미지 센서를 통해 캡쳐된 이미지는 제어부 또 는 별도의 이미지 처리부(미도시)를 통해 처리될 수 있다. 카메라에서 처리된 화상 프레임은 메모리에 저장되거나 통신부를 통하여 외부로 전송될 수 있다. 카메라는 단말기의 구성 태양에 따라 2개 이상이 구비될 수도 있다. 마이크로폰은, 외부의 음향 신호를 입력 받아 전기적인 음성 데이터로 처리한다. 예를 들어, 마이크로폰 은 외부 디바이스 또는 화자로부터 음향 신호를 수신할 수 있다. 마이크로폰는 외부의 음향 신호를 입력 받는 과정에서 발생 되는 잡음(noise)를 제거하기 위한 다양한 잡음 제거 알고리즘을 이용할 수 있다. 메모리는, 제어부의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 디바이스로 입력되거나 디바이스로부터 출력되는 데이터를 저장할 수도 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램, SRAM, 롬, EEPROM, PROM, 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, UI 모 듈, 터치 스크린 모듈, 알림 모듈 등으로 분류될 수 있다. UI 모듈은, 애플리케이션 별로 디바이스와 연동되는 특화된 UI, GUI 등을 제공할 수 있다. 터치 스 크린 모듈은 사용자의 터치 스크린 상의 터치 제스처를 감지하고, 터치 제스처에 관한 정보를 제어부 로 전달할 수 있다. 일부 실시 예에 따른 터치 스크린 모듈은 터치 코드를 인식하고 분석할 수 있 다. 터치 스크린 모듈은 컨트롤러를 포함하는 별도의 하드웨어로 구성될 수도 있다. 알림 모듈은 디바이스의 이벤트 발생을 알리기 위한 신호를 발생할 수 있다. 디바이스에서 발 생되는 이벤트의 예로는 호 신호 수신, 메시지 수신, 키 신호 입력, 일정 알림 등이 있다. 알림 모듈은 디스플레이부를 통해 비디오 신호 형태로 알림 신호를 출력할 수도 있고, 음향 출력부를 통해 오디 오 신호 형태로 알림 신호를 출력할 수도 있고, 진동 모터를 통해 진동 신호 형태로 알림 신호를 출력할 수도 있다.개시된 실시 예들은 컴퓨터로 읽을 수 있는 저장 매체(computer-readable storage media)에 저장된 명령어를 포 함하는 S/W 프로그램으로 구현될 수 있다. 컴퓨터는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 개시된 실시 예에 따른 동작이 가 능한 장치로서, 개시된 실시 예들에 따른 영상 전송 장치 및 영상 수신 장치를 포함할 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘ 비일시적’은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장 매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 또한, 개시된 실시 예들에 따른 전자 장치 또는 방법은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 S/W 프로그램, S/W 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예, 구글 플레이 스토어, 앱 스 토어)을 통해 전자적으로 배포되는 S/W 프로그램 형태의 상품(예, 다운로더블 앱)을 포함할 수 있다. 전자적 배 포를 위하여, S/W 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저 장 매체는 제조사의 서버, 전자 마켓의 서버, 또는 SW 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 서버 및 단말(예로, 영상 전송 장치 또는 영상 수신 장치)로 구성되는 시스템에서, 서 버의 저장매체 또는 단말의 저장매체를 포함할 수 있다. 또는, 서버 또는 단말과 통신 연결되는 제3 장치(예, 스마트폰)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프 로그램 제품은 서버로부터 단말 또는 제3 장치로 전송되거나, 제3 장치로부터 단말로 전송되는 S/W 프로그램 자 체를 포함할 수 있다. 이 경우, 서버, 단말 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시 예들에 따른 방법을 수행할 수 있다. 또는, 서버, 단말 및 제3 장치 중 둘 이상이 컴퓨터 프로그램 제품을 실행하여 개시된 실시 예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 서버(예로, 클라우드 서버 또는 인공 지능 서버 등)가 서버에 저장된 컴퓨터 프로그램 제품을 실행 하여, 서버와 통신 연결된 단말이 개시된 실시 예들에 따른 방법을 수행하도록 제어할 수 있다. 또 다른 예로, 제3 장치가 컴퓨터 프로그램 제품을 실행하여, 제3 장치와 통신 연결된 단말이 개시된 실시 예에 따른 방법을 수행하도록 제어할 수 있다. 구체적인 예로, 제3 장치는 영상 전송 장치 또는 영상 수신 장치를 원 격 제어하여, 패킹 영상을 전송 하거나 수신하도록 제어할 수 있다. 제3 장치가 컴퓨터 프로그램 제품을 실행하는 경우, 제3 장치는 서버로부터 컴퓨터 프로그램 제품을 다운로드하 고, 다운로드된 컴퓨터 프로그램 제품을 실행할 수 있다. 또는, 제3 장치는 프리로드된 상태로 제공된 컴퓨터 프로그램 제품을 실행하여 개시된 실시 예들에 따른 방법을 수행할 수도 있다.도면 도면1 도면2a 도면2b 도면2c 도면3 도면4a 도면4b 도면5a 도면5b 도면6 도면7 도면8a 도면8b 도면9 도면10a 도면10b 도면11a 도면11b 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19"}
{"patent_id": "10-2020-0018574", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 온-디바이스 음성 인식과 서버-기반 음성 인식을 비교하여 설명하기 위한 도면이다. 도 2a는 일 실시 예에 따른 음성 인식 시스템을 도시한다. 도 2b는 일 실시 예에 따른 음성 인식 시스템을 도시한다. 도 2c는 일 실시 예에 따른 음성 인식 시스템을 도시한다. 도 3은 일 실시 예에 따른 디바이스의 블록도를 도시한다. 도 4a는 일 실시 예에 따른 디바이스의 구체적인 블록도를 도시한다. 도 4b는 일 실시 예에 따른 디바이스의 구체적인 블록도를 도시한다. 도 5a는 일 실시 예에 따라 디바이스가 온-디바이스 음성 인식을 수행할 것을 판단하는 방법을 설명하기 위한 도면이다. 도 5b는 일 실시 예에 따라 디바이스가 서버 기반 음성 인식을 수행할 것을 판단하는 방법을 설명하기 위한 도 면이다. 도 6은 일 실시 예에 따른 프레임 동기화된 문자열을 설명하기 위한 도면이다. 도 7은 일 실시 예에 따른 서버의 블록도를 도시한다. 도 8a는 일 실시 예에 따른 서버가 디바이스의 음성 인식을 지원하는 방법을 설명하기 위한 도면이다. 도 8b는 일 실시 예에 따른 서버가 음성 신호 프레임 각각에 대응하는 문자 별로 가능도를 획득하여 대체 문자열을 결정하는 방법을 설명하기 위한 도면이다. 도 9는 일 실시 예에 따른 서버의 구체적인 블록도를 도시한다. 도 10a는 일 실시 예에 따라 사후 확률을 계산하기 위해 이용되는 인공 지능 회귀 신경망 (recurrent neural network, RNN)의 구조를 도시한다. 도 10b는 일 실시 예에 따라 가능도(likelihood)를 계산하기 위해 이용되는오차 행렬(confusion matrix)의 예를 도시한다. 도 11a는 일 실시 예에 따른 서버가 디바이스로부터 수신하는 제1 문자열내의 각 문자에 대하여 각 문자가 대체 될 대체 문자들에 관한 가능도 행렬을 산출하는 과정을 설명하기 위한 도면이다. 도 11b는 일 실시 예에 따른 서버가 디바이스로부터 수신하는 제1 문자열내의 각 문자에 대하여 각 문자가 대체 될 대체 문자들에 관한 가능도 행렬을 산출하는 과정을 설명하기 위한 도면이다. 도 12는 일 실시 예에 따라 두 개의 음성 인식 모듈들을 선택적으로 이용하는 디바이스의 블록도를 도시한다. 도 13은 일 실시 예에 따라 디바이스가 음성 인식을 수행하는 방법의 흐름도를 도시한다. 도 14는 일 실시 예에 따라 디바이스가 음성 인식을 수행하는 구체적인 방법의 흐름도를 도시한다. 도 15는 일 실시 예에 따라 서버의 동작 방법의 흐름도를 도시한다. 도 16은 일 실시 예에 따라 서버의 구체적인 동작 방법의 흐름도를 도시한다. 도 17은 일 실시 예에 따라 서버에서 수행되는 WFST(weighted Finite State Transducer) 디코딩을 설명하기 위 한 도면이다. 도 18은 일 실시 예에 따라 디바이스 상에 음성 인식 결과가 디스플레이 되는 화면의 예를 도시한다. 도 19는 일 실시 예에 따른 디바이스의 구체적인 블록도를 도시한다."}
