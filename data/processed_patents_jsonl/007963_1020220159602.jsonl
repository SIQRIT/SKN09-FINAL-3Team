{"patent_id": "10-2022-0159602", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0077266", "출원번호": "10-2022-0159602", "발명의 명칭": "종양 데이터 생성 장치 및 방법", "출원인": "서울대학교산학협력단", "발명자": "예성준"}}
{"patent_id": "10-2022-0159602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "종양 데이터 생성 장치에 있어서,종양 데이터 생성 프로그램이 저장된 메모리; 및상기 종양 데이터 생성 프로그램을 실행하는 프로세서를 포함하되,상기 종양 데이터 생성 프로그램은 입력 자기 공명 영상의 식별 정보에 기초하여 종양의 예측 위치를 추론하고,예측 위치를 마스킹하는 종양 마스크를 출력하는 제 1 학습 모델과 상기 입력 자기 공명 영상에 상기 종양 마스크를 배치시킨 영상으로부터 종양 데이터를 생성하는 제 2 학습 모델을 포함하는 것인, 종양 데이터 생성 장치."}
{"patent_id": "10-2022-0159602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제 1 학습 모델은 조건부 변이 자동인코더를 기초로 학습된 것으로서, 종양을 포함하고 있는 실제 자기 공명 영상에 기초하여, 해당 자기 공명 영상의 식별 정보와 종양이 위치하는 부분을 가리는 마스크에 대한 정보를라벨링하여 학습되어, 입력 자기 공명 영상의 식별 정보가 입력되면, 해당 입력 자기 공명 영상에 발생할 것으로 예측되는 상기 종양 마스크를 출력하는 것인, 종양 데이터 생성 장치."}
{"patent_id": "10-2022-0159602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제 2 학습 모델은 생성적 적대 신경망(GAN)을 기초로 학습된 것으로서, 상기 입력 자기 공명 영상에 상기종양 마스크를 배치시킨 영상으로부터 종양 데이터를 생성하는 생성자와 종양을 포함하는 실제 영상을 기초로상기 생성자의 출력 영상의 진위 여부를 판별하는 판별자를 포함하는 것인, 종양 데이터 생성 장치."}
{"patent_id": "10-2022-0159602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 생성자는 제 1 합성 영상을 생성하는 제 1 생성부와 제 1 생성부의 출력으로부터 제 2 합성 영상을 생성하는 제 2 생성부를 포함하되,상기 제 2 합성 영상이 상기 제 1 합성 영상보다 세밀한 스타일을 표현하도록 학습된 것인, 종양 데이터 생성장치."}
{"patent_id": "10-2022-0159602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제 1 생성부는 상기 종양 마스크의 가장자리 영역의 가중치를 증대하는 어텐션 계층(attention layer)을더 포함하는 것인, 종양 데이터 생성 장치."}
{"patent_id": "10-2022-0159602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "종양 데이터 생성 장치를 이용한 종양 데이터 생성 방법에 있어서,입력 자기 공명 영상의 식별 정보에 기초하여 제 1 학습 모델이 종양 마스크를 출력하는 단계 및상기 입력 자기 공명 영상과 상기 종양 마스크에 기초하여 제 2 학습 모델이 종양 데이터를 생성하는 단계를 포함하되,상기 제 1 학습 모델은 입력 자기 공명 영상의 식별 정보에 기초하여 종양의 예측 위치를 추론하고, 예측 위치공개특허 10-2024-0077266-3-를 마스킹하는 종양 마스크를 출력하도록 구축된 것이고,상기 제 2 학습 모델은 상기 입력 자기 공명 영상에 상기 종양 마스크를 배치시킨 영상으로부터 종양 데이터를생성하도록 구축된 것인, 종양 데이터 생성 방법."}
{"patent_id": "10-2022-0159602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제 1 학습 모델은 조건부 변이 자동인코더를 기초로 학습된 것으로서, 종양을 포함하고 있는 실제 자기 공명 영상에 기초하여, 해당 자기 공명 영상의 식별 정보와 종양이 위치하는 부분을 가리는 마스크에 대한 정보를라벨링하여 학습되어, 입력 자기 공명 영상의 식별 정보가 입력되면, 해당 입력 자기 공명 영상에 발생할 것으로 예측되는 상기 종양 마스크를 출력하는 것인, 종양 데이터 생성 방법."}
{"patent_id": "10-2022-0159602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 제 2 학습 모델은 생성적 적대 신경망(GAN)을 기초로 학습된 것으로서, 상기 입력 자기 공명 영상에 상기종양 마스크를 배치시킨 영상으로부터 종양 데이터를 생성하는 생성자와 종양을 포함하는 실제 영상을 기초로상기 생성자의 출력 영상의 진위 여부를 판별하는 판별자를 포함하는 것인, 종양 데이터 생성 방법."}
{"patent_id": "10-2022-0159602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 생성자는 제 1 합성 영상을 생성하는 제 1 생성부와 제 1 생성부의 출력으로부터 제 2 합성 영상을 생성하는 제 2 생성부를 포함하되,상기 제 2 합성 영상이 상기 제 1 합성 영상보다 세밀한 스타일을 표현하도록 학습된 것인, 종양 데이터 생성방법."}
{"patent_id": "10-2022-0159602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제 1 생성부는 상기 종양 마스크의 가장자리 영역의 가중치를 증대하는 어텐션 계층(attention layer)을더 포함하는 것인, 종양 데이터 생성 방법."}
{"patent_id": "10-2022-0159602", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 종양 데이터 생성 장치는, 종양 데이터 생성 프로그램이 저장된 메모리; 및 상기 종양 데이터 생 성 프로그램을 실행하는 프로세서를 포함하되, 상기 종양 데이터 생성 프로그램은 입력 자기 공명 영상의 식별 정보에 기초하여 종양의 예측 위치를 추론하고, 예측 위치를 마스킹하는 종양 마스크를 출력하는 제 1 학습 모델 과 상기 입력 자기 공명 영상에 상기 종양 마스크를 배치시킨 영상으로부터 종양 데이터를 생성하는 제 2 학습 모델을 포함하는 것이다."}
{"patent_id": "10-2022-0159602", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 지능에 기반하여 자기 공명 영상으로부터 종양 데이터를 생성하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0159602", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 기술의 발달로 의료 분야에서 딥러닝 기반의 컴퓨터 보조 진단 도구는 의료 영상 판독 및 분석을 위해 다양한 목적으로 활용되고 있다. 다만, 인공지능 모델의 구축을 위해서는 높은 정확도를 위해 학습 과정에 서 많은 수의 의료 데이터를 필요로 하는데, 종양과 같은 특정 질병 영상은 그 수가 한정적이며 환자 개인 정보 가 노출될 수 있는 문제점이 있다. 인공지능 알고리즘을 활용하지 않는 서로 다른 유형의 이미지 간의 매칭은 잡음(noise), 이미지 스타일의 차이, 형상의 차이와 같은 이미지 간의 차이로 인해 정확도가 매우 떨어진다. 이와 관련한 선행 연구들은 모두 종양 생성 과정에서 생성할 종양의 위치를 지정하기 위해 사용자에 종속적인 파라미터를 매번 요구하는 것으로 알려져 있다. 이러한 파라미터 지정을 위해서는 의료 영상을 판독하고 이해할 수 있는 전문 지식을 필요로 한다는 점에서, 사전 정보가 부재한 경우, 생성 종양이 원 데이터 분포를 벗어나 실존하지 않는 영상(부적절한 클래스 비율의 종양, 뇌 영역을 벗어난 종양 등)이 생성되는 문제가 발생한다. 선행기술문헌특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-2022-0045366호 (발명의 명칭: 인공지능 기반의 의료 영상 합성 장치 및 방법)"}
{"patent_id": "10-2022-0159602", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위하여, 종양이 위치할 확률이 가장 높은 위치에 종양 이미지를 인페인팅 할 수 있는 종양 데이터 생성 장치 및 방법을 제공하는 것을 기술적 과제로 한다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2022-0159602", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위한 기술적 수단으로서, 본 발명의 일 실시예에 따른 종양 데이터 생성 장치는, 종양 데이터 생성 프로그램이 저장된 메모리; 및 상기 종양 데이터 생성 프로그램을 실행하는 프로세서 를 포함하되, 종양 데이터 생성 프로그램은 입력 자기 공명 영상의 식별 정보에 기초하여 종양의 예측 위치를 추론하고, 예측 위치를 마스킹하는 종양 마스크를 출력하는 제 1 학습 모델과 상기 입력 자기 공명 영상에 상기 종양 마스크를 배치시킨 영상으로부터 종양 데이터를 생성하는 제 2 학습 모델을 포함한다. 또한, 본 발명의 다른 실시예에 따른 종양 데이터 생성 장치를 이용한 종양 데이터 생성 방법은, 입력 자기 공 명 영상의 식별 정보에 기초하여 제 1 학습 모델이 종양 마스크를 출력하는 단계 및 상기 입력 자기 공명 영상 과 상기 종양 마스크에 기초하여 제 2 학습 모델이 종양 데이터를 생성하는 단계를 포함하되, 제 1 학습 모델은 입력 자기 공명 영상의 식별 정보에 기초하여 종양의 예측 위치를 추론하고, 예측 위치를 마스킹하는 종양 마스 크를 출력하도록 구축된 것이고, 제 2 학습 모델은 상기 입력 자기 공명 영상에 상기 종양 마스크를 배치시킨 영상으로부터 종양 데이터를 생성하도록 구축된 것이다."}
{"patent_id": "10-2022-0159602", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단에 따르면, 자기 공명 영상의 식별 정보 또는 위치 정보를 바탕으로 적합한 크 기와 위치의 종양 마스크를 획득해 종양 데이터를 생성한다. 이는 종래 종양 데이터 생성시에 사용자에 종속적 인 파라미터를 매번 요구하던 종래 기술의 문제점을 해소할 수 있다. 또한, 종양 데이터에 대한 사전 지식 없이도 안정적인 품질의 합성 영상을 생성할 수 있는 이점을 갖는다. 또한, 제안된 생성 모델은 추가적인 종양 클래스에 대한 정보 없이 고차원의 데이터 정보를 이용하여 주변의 영 역과 자연스럽고 풍부한 종양 데이터의 생성을 가능하게 한다. 또한, 이와 같이 생성된 종양 데이터를 종양 분할 모델의 지도 학습 데이터로 활용할 수 있다."}
{"patent_id": "10-2022-0159602", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여 본 발명을 상세히 설명하기로 한다. 다만, 본 발명은 여러 가지 상이한 형 태로 구현될 수 있으며, 여기에서 설명하는 실시예들로 한정되는 것은 아니다. 또한, 첨부된 도면은 본 명세서 에 개시된 실시예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적사상이 제한되지 않는다. 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 도면에 나타난 각 구성요소의 크기, 형태, 형상은 다양하게 변형될 수 있다. 명세서 전체에 대하여 동일/유사한 부분에 대해서는 동일/유사한 도면 부호를 붙였다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\" 등은 명세서 작성의 용이함만이 고려되어 부 여 되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서 에 개시된 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략하였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결(접속, 접촉 또는 결합)\"되어 있다고 할 때, 이는 \"직접적으로 연결(접속, 접촉 또는 결합)\"되어 있는 경우뿐만 아니라, 그 중간에 다른 부재를 사이에 두고 \"간접적으로 연결 (접속, 접촉 또는 결합)\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함(구비 또는 마 련)\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소 를 더 \"포함(구비 또는 마련)\"할 수 있다는 것을 의미한다. 본 명세서에서 사용되는 제1, 제2 등과 같이 서수를 나타내는 용어들은 하나의 구성 요소를 다른 구성요소로부 터 구별하는 목적으로만 사용되며, 구성 요소들의 순서나 관계를 제한하지 않는다. 예를 들어, 본 발명의 제1구 성요소는 제2구성요소로 명명될 수 있고, 유사하게 제2구성요소도 제1구성 요소로 명명될 수 있다. 도 1은 본 발명의 일 실시예에 따른 종양 데이터 생성 장치를 개략적으로 나타낸 블록도이다. 도 1을 참조하여 본 발명의 일 실시예에 따른 종양 데이터 생성 장치 에 대해 설명한다. 종양 데이터 생성 장치는 종양 데이터 생성 프로그램을 통해, 입력된 자기 공명 영상에 대하여 종양의 예측 위치에 종양 마 스크를 배치하고, 이를 인페인팅하여 종양 데이터를 생성한다. 이를 위해, 종양 데이터 생성 프로그램은 입력 된 자기 공명 영상의 식별 정보에 기초하여 종양의 예측 위치를 추론하고, 예측 위치를 마스킹하는 종양 마스크 를 출력하는 제 1 학습 모델과 상기 입력 자기 공명 영상에 상기 종양 마스크를 배치시킨 영상으로부터 종양 데 이터를 생성하는 제 2 학습 모델을 포함한다. 이를 위해, 종양 데이터 생성 장치는 메모리 및 프로세 서를 포함한다. 한편, 종양 데이터 생성 장치는 네트워크에 접속할 수 있는 컴퓨터나 휴대용 단말기로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱(laptop) 등 을 포함하고, 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 각종 스마트폰, 태 블릿 PC, 스마트 워치 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 또한, 종양 데이터 생성 장치는 생성된 종양 데이터를 제공하는 서버로서 기능할 수 있으며, 이때 서버는 SaaS (Software as a Service), PaaS (Platform as a Service) 또는 IaaS (Infrastructure as a Service)와 같은 클라우드 컴퓨팅 서비스 모델에서 동작하거나, 사설(private) 클라우드, 공용(public) 클라우드 또는 하이 브리드(hybrid) 클라우드와 같은 형태로 구축될 수 있다. 메모리는 앞서 설명한 종양 데이터 생성 프로그램이 저장된다. 메모리는 전원이 공급되지 않아도 저 장된 정보를 계속 유지하는 비휘발성 저장장치 및 저장된 정보를 유지하기 위하여 전력을 필요로 하는 휘발성 저장장치를 통칭하는 것으로 해석되어야 한다. 메모리는 프로세서가 처리하는 데이터를 일시적 또는 영구적으로 저장하는 기능을 수행할 수 있다. 메모리는 저장된 정보를 유지하기 위하여 전력이 필요한 휘 발성 저장장치 외에 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체(flash storage media)를 포함할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 그리고, 프로세서는 메모리에 저장된 종양 데이터 생성 프로그램을 실행하여 종양 데이터를 생성한다. 본 실시예에서, 프로세서는 마이크로프로세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application- specific integrated circuit), FPGA(field programmable gate array) 등의 형태로 구현될 수 있으나, 본 발명 의 범위가 이에 한정되는 것은 아니다. 통신 모듈은 외부 컴퓨팅 장치등과 데이터를 송수신할 수 있다. 통신 모듈은 다른 네트워크 장치와 유무선 연결을 통해 제어 신호 또는 데이터 신호와 같은 신호를 송수신하기 위해 필요한 하드웨어 및 소프트웨 어를 포함하는 장치일 수 있다. 데이터베이스는 프로세서의 제어에 따라, 종양 데이터 생성 프로그램의 실행에 필요한 데이터를 저장 한다. 이러한 데이터베이스는 메모리와는 별도의 구성 요소로서 포함되거나, 또는 메모리의 일부 영역에 구축될 수도 있다. 또한, 데이터베이스는 제 1 학습 모델과 제 2 학습 모델의 구축에 활용되 는 학습 데이터가 저장될 수 있고, 새로운 학습 데이터에 의해 갱신된 학습 모델에 대한 정보도 저장할 수 있다. 도 2와 도 3은 본 발명의 일 실시예에 따른 종양 데이터 생성 프로그램의 상세 구성을 도시한 것이다. 종양 데이터 생성 프로그램은 입력 자기 공명 영상의 식별 정보에 기초하여 종양의 예측 위치를 추론하고, 예측 위치를 마스킹하는 종양 마스크를 출력하는 제 1 학습 모델과 입력 자기 공명 영상에 종양 마스크를 배치시킨 영상으로부터 종양 데이터를 생성하는 제 2 학습 모델을 포함한다. 먼저, 제 1 학습 모델은 조건부 변이 자동인코더(Conditional Variational Auto Encoder) 를 기초로 학습 된 것으로서, 종양을 포함하고 있는 실제 자기 공명 영상에 기초하여, 해당 자기 공명 영상의 식별 정보와 종양 이 위치하는 부분을 가리는 마스크에 대한 정보를 라벨링하여 학습되어, 입력 자기 공명 영상의 식별 정보가 입 력되면, 해당 입력 자기 공명 영상에 발생할 것으로 예측되는 종양 마스크를 출력한다. 여기서, 자기 공명 영상의 식별 정보는 뇌나 심장과 같은 장기별로 3차원 자기 공명 영상을 생성하는 경우, 이 3차원 자기 공명 영상을 구성하는 개별 슬라이스 단위의 영상으로서, 예를 들면, 이와 같은 슬라이스 영상은 Z 축의 방향을 따라 적층 또는 구분되는 것일 수 있다. 본 발명에서는 환자 별 256x256x150 크기의 자기 공명 영 상에서 채널을 나타내는 z축을 10 개의 구역으로 나누고, 입력 자기 공명 영상이 속한 구역에 대한 정보(예를 들면, 1 부터 10 까지의 구역)를 입력 값으로 사용할 수 있다. 이와 같이, 본 발명에서는 종양을 포함하고 있는 실제 자기 공명 영상을 이용하여 제 1 학습 모델을 구축하되, 입력 자기 공명 영상이 z 축 방향을 따라 위 치하고 있는 구역, 또는 입력 자기 공명 영상의 z축 방향의 위치에 대한 정보와, 해당 자기 공명 영상에서 종양 이 위치하는 부분을 가리는(masking) 마스크에 대한 정보를 라벨링하여 학습된다. 이와 같이, 학습된 제 1 학 습 모델은 이후 입력 자기 공명 영상의 위치에 대한 정보 또는 해당 위치를 나타내는 식별 정보가 입력되 면, 해당 입력 자기 공명 영상에 발생할 것으로 예측되는 종양 마스크를 출력하게 된다. 그리고, 제 1 학습 모 델을 통해 샘플링된 종양 마스크에 대한 정보는 제 2 학습 모델로 전달된다. 다음으로, 제 2 학습 모델은 생성적 적대 신경망(GAN)을 기초로 학습된 것으로서, 입력 자기 공명 영상에 대해 제 1 학습 모델이 출력한 종양 마스크를 배치시킨 영상으로부터 종양 데이터를 생성하는 생성자(22 2)와 종양을 포함하는 실제 영상을 기초로 생성자의 출력 영상의 진위 여부를 판별하는 판별자를 포 함한다. 생성적 적대 신경망(GAN)의 구성에 따라 생성자와 판별자에 대한 학습을 교차적으로 진행하 며, 이를 통해 각 레이어의 가중치를 갱신하고, 결과적으로, 생성자가 종양을 포함하고 있는 실제 영상과 매우 비슷한 수준의 종양 데이터를 생성할 수 있게 된다. 이때, 생성자는 제 1 합성 영상을 생성하는 제 1 생성부와 제 1 생성부의 출력으로부터 제 2 합 성 영상을 생성하는 제 2 생성부를 포함하는 형태로 구성될 수 있다. 제 1 생성부는 보다 거친 (coares) 스타일의 영상을 생성하고, 제 2 생성부는 보다 세밀한(fine) 영상을 생성하도록 학습되어, 제 2 합성 영상이 제 1 합성 영상보다 세밀한 스타일을 표현하도록 학습될 수 있다. 또한, 제 1 생성부는 종양 마스크의 가장자리 영역의 가중치를 증대하는 어텐션 계층(attention layer)을 더 포함할 수 있다. 본 발명에서는 인페인팅 과정에서 생성된 종양은 주변 영역과 자연스럽게 연결되는 것이 중요하다. 따라서 본 어텐션 계층은 학습과정에서 가장자리 정보를 추가적으로 제공한다. 도 3에 도시된 바와 같이, 앞서 획득한 이진 종양 마스크로부터 가장자리 영역의 특징을 획득하고 해당 경계 영 역을 중간의 피처맵(feature map)에서 강조되도록 한다. 한편, 본 발명에서는 판별자의 구성에도 특이성을 가진다. 본 발명에서는 다양한 텍스쳐(texture) 정보를 가진 종양 데이터를 생성하기 위해, 판별자의 공간을 유클리디안(Euclidean)공간에서 초구(hypersphere) 공간으로 임베딩시켜, 극점과 샘플간의 거리를 계산하며 모델을 학습하도록 한다. 또한, 이와 같이 최적화된 모델을 통해 고품질의 합성 종양 데이터 또는 종양 영상을 생성하고 이를 종양 분할 지도학습의 추가 데이터로 활용함으로써 증강된 데이터의 효과를 확인하고 성능을 평가한다. 도 4는 본 발명의 일 실시예에 따른 종양 데이터 생성 방법을 도시한 순서도이다. 먼저, 종양 데이터 생성 장치는 입력 자기 공명 영상의 식별 정보에 기초하여 제 1 학습 모델이 종양 마스크를 출력한다(S410). 이때, 제 1 학습 모델은 입력 자기 공명 영상의 식별 정보에 기초하여 종양의 예측 위치를 추론하고, 예측 위치를 마스킹하는 종양 마스크를 출력하도록 구축된 것이다. 보다 구체적으로, 제 1 학습 모델은 조건부 변이 자동인코더를 기초로 학습된 것으로서, 종양을 포함하고 있는 실제 자기 공명 영상에 기초하여, 해당 자기 공명 영상의 식별 정보와 종양이 위치하는 부분을 가리는 마스크에 대한 정보를 라벨링하여 학습되어, 입력 자 기 공명 영상의 식별 정보가 입력되면, 해당 입력 자기 공명 영상에 발생할 것으로 예측되는 종양 마스크를 출 력할 수 있다. 다음으로, 입력 자기 공명 영상과 종양 마스크에 기초하여 제 2 학습 모델이 종양 데이터를 생성한다 (S420). 이때, 제 2 학습 모델은 입력 자기 공명 영상에 상기 종양 마스크를 배치시킨 영상으로부터 종양 데이터를 생성하도록 구축된 것이다. 보다 구체적으로, 제 2 학습 모델은 생성적 적대 신경망(GAN)을 기초로 학습된 것으로서, 입력 자기 공명 영상에 종양 마스크를 배치시킨 영상으로부터 종양 데이터를 생성하는 생성자와 종양 을 포함하는 실제 영상을 기초로 상기 생성자의 출력 영상의 진위 여부를 판별하는 판별자를 포함할 수 있다. 이때, 생성자는 출력 영상의 세밀한 정도에 차이가 있는 복수의 생성부를 캐스케이드 형태로 포함할 수 있다. 그리고, 어느 한 생성부에 종양 마스크의 가장자리 영역의 가중치를 증대하는 어텐션 계층(attention layer)을 더 포함시킬 수 있다. 도 5는 본 발명의 일 실시예에 따른 종양 데이터 생성 장치의 실험 결과를 설명하기 위한 도면이다. 도시된 바와 같이, 정답 영상 픽셀 간의 비교를 통하여 SSIM (Structural Similarity Index Map), PSNR (Peak Signal-to-Noise Ratio), NRMSE(Normalied Root Mean Square Error) 를 측정하고, 데이터의 간의 분포를 FID로 측정해 정량평가를 시행하였다. (a)는 정상 뇌 영상을 나타내는 것이고, (b)는 제 1 학습 모델에서 샘플링을 통 해 획득한 종양 마스크를 배치한 상태를 나타내는 것이며, (c)는 종양이 합성된 종양 데이터를 나타내는 것이다. 선행 연구와의 FID 결과를 비교하여 기존에 제안된 연구보다 향상된 결과를 확인하였다. 이는 영상 합성 과정에 서 필요한 종양 마스크의 입력 파라미터 (e.g. 종양 생성을 위해 활용하는 3클래스 마스크의 중심좌표 x, y와 3 가지 반지름 값)에 의존성이 높았던 종래 기술의 한계점을 극복하여 자동적으로 적합한 마스크를 샘플링 하였을 때 갖는 장점이다. 제안 기술은 다양한 정량 평가 지표들로부터 기존에 제안된 연구보다 정성적, 정량적으로 향상된 결과를 보였다. 특히, 생성 결과 영상에 대응되는 분할 마스크를 부수적으로 획득할 수 있기 때문에 하 위 모델의 학습의 증강 데이터로 활용하여 보다 강건하고 고성능의 의료 영상 보조 시스템을 개발할 수 있다. 본 발명은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매 체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 본 발명의 방법 및 시스템은 특정 실시예와 관련하여 설명되었지만, 그것들의 구성 요소 또는 동작의 일 부 또는 전부는 범용 하드웨어 아키텍쳐를 갖는 컴퓨터 시스템을 사용하여 구현될 수 있다."}
{"patent_id": "10-2022-0159602", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 상술한 설명을 기초로 본 발명의 기술적 사상이나 필수 적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러 므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해되어야만 한다. 본 발명의 범위는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개 념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다. 부호의 설명100: 종양 데이터 생성장치 110: 통신모듈 120: 메모리 130: 프로세서 200: 종양 데이터 생성 프로그램 210: 제 1 학습 모델 220: 제 2 학습 모델"}
{"patent_id": "10-2022-0159602", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 종양 데이터 생성 장치를 개략적으로 나타낸 블록도이다. 도 2와 도 3은 본 발명의 일 실시예에 따른 종양 데이터 생성 프로그램의 상세 구성을 도시한 것이다. 도 4는 본 발명의 일 실시예에 따른 종양 데이터 생성 방법을 도시한 순서도이다. 도 5는 본 발명의 일 실시예에 따른 종양 데이터 생성 장치의 실험 결과를 설명하기 위한 도면이다."}
