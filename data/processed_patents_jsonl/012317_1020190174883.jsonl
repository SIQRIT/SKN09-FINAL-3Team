{"patent_id": "10-2019-0174883", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0082691", "출원번호": "10-2019-0174883", "발명의 명칭": "시멘틱 이미지 추론 방법 및 장치", "출원인": "주식회사 픽스트리", "발명자": "신재섭"}}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력 이미지(Input Image)(I)를 입력받는 과정;상기 입력 이미지(I)를 미리 딥러닝 기반으로 학습된 인공지능 모델을 이용하여 세그멘테이션 맵(Segmentation-Map)(S^)으로 생성하는 과정;상기 인공지능 모델을 이용하여 상기 세그멘테이션 맵(S^)을 기반으로 빈영역을 확장한 세그멘테이션 맵(Extrapolated Segmentation-Map)(S^E)를 생성하는 과정;상기 입력 이미지(I)를 기반으로 확장할 영역을 포함하는 패딩된 이미지(Padded Image)(IP)를 생성하는 과정;상기 인공지능 모델을 이용하여 상기 패딩된 이미지(IP)와 상기 빈영역 확장한 세그멘테이션 맵(S^E)를 결합하여빈영역을 확장한 이미지(Extrapolated Image)(I^E)를 생성하는 과정;을 포함하는 것을 특징으로 하는 시멘틱 이미지 추론 방법."}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 세그멘테이션 맵(S^)을 생성하는 과정은상기 세그멘테이션 맵(S^)을 생성할 때, 인페이팅(Inpainting) 기법을 이용하는 것을 특징으로 하는 시멘틱 이미지 추론 방법."}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 세그멘테이션 맵(S^)을 생성하는 과정은상기 세그멘테이션 맵(S^)을 생성할 때, 딥 러닝 기반으로 학습한 데이터셋이 부족한 경우, 윅클리 슈퍼바이즈러닝(Weakly-Supervised Learning) 기법을 이용하는 것을 특징으로 하는 시멘틱 이미지 추론 방법."}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 빈영역을 확장한 세그멘테이션 맵(S^E)을 생성하는 과정은빈영역을 마스크 상태로 유지하는 것이 아니라 먼저 인터폴레이션(interpolation)을 수행하여 빈영역을 채운 패딩된 세그멘테이션 맵(S^P)를 생성하고,상기 인공지능 모델을 이용하여 상기 패딩된 세그멘테이션 맵(S^P)을 상기 확장한 세그멘테이션 맵(S^E)으로 생성하는 것을 특징으로 하는 시멘틱 이미지 추론 방법."}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,공개특허 10-2021-0082691-3-상기 빈영역을 확장한 세그멘테이션 맵(S^E)을 생성하는 과정은빈영역 내에 정보가 전혀 존재하지 않는 경우, 빈영역과 가장 인접한 가장자리 경계에 위치한 가장자리 픽셀 값을 복사하여 상기 패딩된 세그멘테이션 맵(S^P)을 생성하는 것을 특징으로 하는 시멘틱 이미지 추론 방법."}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 빈영역을 확장한 세그멘테이션 맵(S^E)을 생성하는 과정은상기 확장한 세그멘테이션 맵(S^E) 내에 이미지 내의 확장할 객체 또는 영역이 동일한 객체 또는 영역과 동일한색상으로 표현되도록 하는 것을 특징으로 하는 시멘틱 이미지 추론 방법."}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 빈영역을 확장한 이미지(I^E)를 생성하는 과정은상기 빈영역을 확장한 이미지(I^E)를 생성할 때, 상기 빈영역을 확장한 세그멘테이션 맵(S^E) 내의 정보를 전달하기 위해서 채널 연결(Channel Concatenation), 조건부 비정규화(Conditional Denormalization) 중 적어도 하나이상의 방식을 이용하는 것을 특징으로 하는 시멘틱 이미지 추론 방법."}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 빈영역을 확장한 이미지(I^E)를 생성하는 과정은상기 채널 연결(channel concatenation)을 이용하여 하나의 이미지 별 채널정보가 상기 인공지능 모델로 입력될때, 세그멘테이션 이미지를 같이 합쳐서 상기 인공지능 모델로 입력되도록 하는 것을 특징으로 하는 시멘틱 이미지 추론 방법."}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 빈영역을 확장한 이미지(I^E)를 생성하는 과정은상기 조건부 비정규화(conditional denormalization)를 이용하여 이미지 내에서 클래스들의 통계적 특성을 기반으로 각 객체의 평균과 표준편차가 특정 객체의 평균과 표준편차로 시프트 시키는 것을 특징으로 하는 시멘틱이미지 추론 방법."}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 빈영역을 확장한 이미지(I^E)를 생성하는 과정은Gated Convolution을 이용하여 상기 패딩된 이미지(IP)와 상기 빈영역 확장한 세그멘테이션 맵(S^E)를 결합하여상기 빈영역을 확장한 이미지(I^E)를 생성하는 것을 특징으로 하는 시멘틱 이미지 추론 방법."}
{"patent_id": "10-2019-0174883", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2021-0082691-4-입력 이미지(Input Image)(I)를 입력받는 입력부;상기 입력 이미지(I)를 미리 딥러닝 기반으로 학습된 인공지능 모델을 이용하여 세그멘테이션 맵(Segmentation-Map)(S^)을 생성하는 세그멘테이션부;상기 인공지능 모델을 이용하여 상기 세그멘테이션 맵(S^)을 기반으로 빈영역을 확장한 세그멘테이션 맵(Extrapolated Segmentation-Map)(S^E)를 생성하는 세그멘테이션 확장부;상기 입력 이미지(I)를 기반으로 확장할 영역을 포함하는 패딩된 이미지(Padded Image)(IP)를 생성하는 이미지패딩부;상기 인공지능 모델을 이용하여 상기 패딩된 이미지(IP)와 상기 빈영역 확장한 세그멘테이션 맵(S^E)를 결합하여빈영역을 확장한 이미지(Extrapolated Image)(I^E)를 생성하는 이미지 확장부;을 포함하는 것을 특징으로 하는 시멘틱 이미지 추론 장치."}
{"patent_id": "10-2019-0174883", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "시멘틱 이미지 추론 방법 및 장치를 개시한다. 빈영역을 확장한 세그멘테이션 맵(Segmentation Map)과 인페이팅(Inpainting) 기술을 이용하여 영상을 확장하고 자 하는 빈영역을 생성하는 기술로서, 확장하고자 하는 영상의 빈영역 내에 정보가 없으므로, 입력 영상으로부터 세그멘테이션 맵을 기반으로 빈영역을 확장한 세그멘테이션 맵을 우선 생성한 후 빈영역을 확장한 세그멘테이션 맵과 입력 영상을 기반으로 확장하고자 하는 영상의 빈영역을 정보를 채워넣도록 하는 시멘틱 이미지 추론 방법 및 장치를 제공한다."}
{"patent_id": "10-2019-0174883", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 실시예는 시멘틱 이미지 추론 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0174883", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에 기술되는 내용은 단순히 본 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구성하는 것이 아니 다. 사용자의 편의에 따라 새로운 영상을 형성하기 위해 영상의 단편을 수정하거나 합성하는 영상 편집/합성 기술은 다양한 방법으로 개발되어 왔다. 영상 편집/합성 기술은 일반적으로 원치 않는 영상 부분을 지우거나 원하는 부 분을 분리하고 새로운 부분과 합성하는 목적을 가지고 개발되고 있다. 영상을 합성하기 위하여 이미지 내의 객체 추출이 요구되는데, 객체를 추출하는 영상 분할 기술(Image Segmentation)로는 워터쉐드(Watershed) 알고리즘과 그래프 컷(Graph Cut) 알고리즘 등의 기술들이 개발되어 다 양한 방법으로 활용되고 있다. 영상 크기 조정을 위해 개발된 기술로는 심 카빙(seam carving/insertion) 알고리즘이 있다. 심 카빙 알고리즘 은 원본 영상에서 각각의 화소(pixel)간 중요도를 계산하여, 중요도가 낮은 화소를 연결시킨 심(Seam)을 설정하 고, 중요도가 낮은 순서로 심(Seam)을 제거(Removal)하거나 삽입(Insertion)하여 영상의 크기를 축소하거나 확 장한다. 심 카빙 기술은 본래 다양한 해상도를 갖는 장치에서 이미지를 표시하는 데 있어서 왜곡 없이 나타내기 위한 목적으로 고안되었다. 종래기술들은 단순히 배경영상에 객체영상을 덮어씌워 합성하는 방식을 이용하였다. 영상의 확대 및 축소 과정 에서도 객체영상과 배경영상의 비율 등에 상관없이 단순히 전체 영상을 확대하거나 축소하였기 때문에 영상 편 집/합성에 한계가 있으며, 이에 따라 자연스러운 합성영상을 제공하기 어려운 문제점이 있다."}
{"patent_id": "10-2019-0174883", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 실시예는 빈영역을 확장한 세그멘테이션 맵(Segmentation Map)과 인페이팅(Inpainting) 기술을 이용하여 영 상을 확장하고자 하는 빈영역을 생성하는 기술로서, 확장하고자 하는 영상의 빈영역 내에 정보가 없으므로, 입 력 영상으로부터 세그멘테이션 맵을 기반으로 빈영역을 확장한 세그멘테이션 맵을 우선 생성한 후 빈영역을 확 장한 세그멘테이션 맵과 입력 영상을 기반으로 확장하고자 하는 영상의 빈영역을 정보를 채워넣도록 하는 시멘 틱 이미지 추론 방법 및 장치를 제공하는 데 목적이 있다."}
{"patent_id": "10-2019-0174883", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 실시예의 일 측면에 의하면, 입력 이미지(Input Image)(I)를 입력받는 과정; 상기 입력 이미지(I)를 미리 딥 러닝 기반으로 학습된 인공지능 모델을 이용하여 세그멘테이션 맵(Segmentation-Map)(S^)을 생성하는 과정; 상 기 인공지능 모델을 이용하여 상기 세그멘테이션 맵(S^)을 기반으로 빈영역을 확장한 세그멘테이션 맵 (Extrapolated Segmentation-Map)(S^ E)를 생성하는 과정; 상기 입력 이미지(I)를 기반으로 확장할 영역을 포함 하는 패딩된 이미지(Padded Image)(IP)를 생성하는 과정; 상기 인공지능 모델을 이용하여 상기 패딩된 이미지 (IP)와 상기 빈영역 확장한 세그멘테이션 맵(S^ E)를 결합하여 빈영역을 확장한 이미지(Extrapolated Image)(I^ E)를 생성하는 과정;을 포함하는 것을 특징으로 하는 시멘틱 이미지 추론 방법을 제공한다. 본 실시예의 다른 측면에 의하면, 입력 이미지(Input Image)(I)를 입력받는 입력부; 상기 입력 이미지(I)를 미 리 딥러닝 기반으로 학습된 인공지능 모델을 이용하여 세그멘테이션 맵(Segmentation-Map)(S^)을 생성하는 세그 멘테이션부; 상기 인공지능 모델을 이용하여 상기 세그멘테이션 맵(S^)을 기반으로 빈영역을 확장한 세그멘테이 션 맵(Extrapolated Segmentation-Map)(S^ E)를 생성하는 세그멘테이션 확장부; 상기 입력 이미지(I)를 기반으로 확장할 영역을 포함하는 패딩된 이미지(Padded Image)(IP)를 생성하는 이미지 패딩부; 상기 인공지능 모델을 이 용하여 상기 패딩된 이미지(IP)와 상기 빈영역 확장한 세그멘테이션 맵(S^ E)를 결합하여 빈영역을 확장한 이미지 (Extrapolated Image)(I^ E)를 생성하는 이미지 확장부;를 포함하는 것을 특징으로 하는 시멘틱 이미지 추론 장 치를 제공한다."}
{"patent_id": "10-2019-0174883", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이 본 실시예에 의하면, 빈영역을 확장한 세그멘테이션 맵(Segmentation Map)과 인페이 팅(Inpainting) 기술을 이용하여 영상을 확장하고자 하는 빈영역을 생성하는 기술로서, 확장하고자 하는 영상의 빈영역 내에 정보가 없으므로, 입력 영상으로부터 세그멘테이션 맵을 기반으로 빈영역을 확장한 세그멘테이션 맵을 우선 생성한 후 빈영역을 확장한 세그멘테이션 맵과 입력 영상을 기반으로 확장하고자 하는 영상의 빈영역 을 정보를 채워넣을 수 있는 효과가 있다."}
{"patent_id": "10-2019-0174883", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 본 실시예에 따른 빈영역에 채워질 이미지를 추론하는 시멘틱 이미지 추론 장치를 개략적으로 나타낸 블 럭 구성도이다. 본 실시예에 따른 시멘틱 이미지 추론 장치가 이미지 추론 프로그램을 이용하여 세그멘테이션 맵 (Segmentation Map)과 인페이팅(Inpainting) 기술을 이용하여 영상을 확장하고자 하는 빈영역을 생성한다. 시멘틱 이미지 추론 장치가 이미지 추론 프로그램을 이용하여 입력 영상으로부터 세그멘테이션 맵을 우선 생성한 후 세그멘테이션 맵과 입력 영상의 정보를 기반으로 확장하고자 하는 영상의 빈영역을 정보를 채워 넣는다.시멘틱 이미지 추론 장치는 이미지 추론 프로그램을 탑재하는 사용자 단말기 또는 응용 서버, 서비스 서버, 서버 단말기일 수 있다. 시멘틱 이미지 추론 장치는 각기 (ⅰ) 각종 기기 또는 유무선 통신망과 통신을 수행하기 위한 통신 모뎀 등의 통신 장치, (ⅱ) 시멘틱 이미지를 추론하기 위한 각종 프로그램과 데이터를 저장하기 위한 메모리, (ⅲ) 이미지 추론 프로그램을 실행하여 연산 및 제어하기 위한 마이크로프로세서 등을 구비하는 다양한 장치를 의미할 수 있다. 적어도 일 실시예에 따르면, 메모리는 램(Random Access Memory: RAM), 롬(Read Only Memory: ROM), 플래시 메모리, 광 디스크, 자기 디스크, 솔리드 스테이트 디스크(Solid State Disk: SSD) 등의 컴퓨터로 판독 가능한 기록/저장매체일 수 있다. 적어도 일 실시예에 따르면, 마이크로프로세서는 명세서에 기재된 동작 과 기능을 하나 이상 선택적으로 수행하도록 프로그램될 수 있다. 적어도 일 실시예에 따르면, 마이크로프로세 서는 전체 또는 부분적으로 특정한 구성의 주문형반도체(Application Specific Integrated Circuit: ASIC) 등 의 하드웨어로써 구현될 수 있다. 본 실시예에 따른 시멘틱 이미지 추론 장치가 이미지 추론 프로그램을 이용하여 입력 이미지(I)를 늘 리는 것이 아니라 입력 영상과 유사한 영상을 딥러닝으로 만들어 낸다. 이미지 추론 프로그램은 영상 내 정보가 없는 부분에 대해 채워 넣는 기술로서, 일반적으로 입력 영상으로 부터 곧바로 영상 내 정보가 없는 부분을 채워 넣기가 매우 어렵기 때문에, 입력 이미지(I)로부터 먼저, 세그멘 테이션 맵(S^)을 생성한다. 이후, 이미지 추론 프로그램은 인공지능 모델을 이용하여 세그멘테이션 맵(S^)을 기반으로 빈영역을 확장한 세그멘테이션 맵(S^ E)을 생성하고, 빈영역을 확장한 세그멘테이션 맵(S^ E) 내 의 정보와 입력 영상(I)의 정보를 함께 활용해서 영상 내 정보가 비어있는 부분을 채워 넣는다. 여기서, 인공지 능 모델은 인공지능 네트워크로 구현될 수 있다. 이미지 추론 프로그램은 인공지능 모델을 이용하여 확장하고자 입력 이미지(I)를 확장하고자 하는 빈 영역에다 인공지능으로 패딩된 이미지(IP)를 가이드해서 빈영역에 채워넣는다. 이미지 추론 프로그램은 입 력 이미지(I)의 비노말라이제이션 평균값을 시프트해서 분산값으로 나누면, 전체 칼라 분포값을 산출할 수 있다. 이미지 추론 프로그램은 기준 데이터로서, 입력 이미지(I), 패딩된 이미지(IP)를 입력으로 이용한다. 이미지 추론 프로그램은 인공지능 모델을 이용하여 원본 영상에 대한 이미지, 마스크 위치, 세그먼트 가이드를 합쳐서 최종 영상을 만들 수 있다. 인공지능 모델은 확장시킬 빈영역, 확장된 이미지, 기존 영상 정보를 입력받아 새로운 학습 모델을 생성한 다. 이미지 추론 프로그램은 인공지능 모델을 이용하여 세그멘테이션 맵(S^)을 확장시켜서 빈영역을 확장 한 세그멘테이션 맵(S^ E)으로 만든다. 이미지 추론 프로그램은 입력 이미지(I)에 확장될 영역까지 포함된 패딩된 이미지(IP)를 빈영역을 확장한 세그멘테이션 맵(S^ E)를 합쳐서 빈영역을 확장한 이미지(I^ E)를 생성한다. 이미지 추론 프로그램에서 입력 이미지(I)를 필요한 만큼 확장시켜서 패딩된 이미지(IP)를 생성하며, 빈영 역을 확장한 세그멘테이션 맵(S^ E)를 만들 때, 인공지능 모델에서 확장하고자 하는 빈영역의 크기를 설정한 다. 이미지 추론 프로그램은 인공지능 모델을 이용하여 세그멘테이션 맵(S^)에서 빈영역을 확장한 세그멘 테이션 맵(S^ E)를 만들 때, 확장하고자 하는 경계에 있는 정보를 패딩해서 그 정보를 기반으로 빈영역을 확장한 세그멘테이션 맵(S^ E)를 만든다. 이미지 추론 프로그램은 원본 영상(확장전 영상) 세그멘테이션 맵(S^ E)을 합쳐서 빈영역을 확장한 세그멘테 이션 맵(S^ E)를 만든다. 빈영역을 확장한 세그멘테이션 맵(S^ E)은 영상이 어디에 속하는지에 대한 정보를 포함한 다. 예컨대, 학습 데이터셋에 따라서 빈영역을 확장한 세그멘테이션 맵(S^ E)의 표현된 색깔로 인해 동일한 영역을 표현한다. 이미지 추론 프로그램은 빈영역을 확장한 세그멘테이션 맵(S^ E)과 인페이팅(Inpainting) 기술을 이용하여 영상을 확장하고자 하는 빈영역을 생성한다. 이미지 추론 프로그램은 확장하고자 하는 영상의 빈영역 내에 정보가 없으므로, 입력 영상(I)으로부터 세그멘테이션 맵(S^)을 기반으로 빈영역을 확장한 세그멘테이션 맵(S^ E)을 우선 생성한 후 빈영역을 확장한 세그멘테이션 맵(S^ E)과 입력 영상(I)을 기반으로 확장하고자 하는 영상의 빈영역을 정보를 채워넣는다. 도 2는 본 실시예에 따른 시멘틱 이미지 추론 장치 내에 탑재되는 이미지 추론 프로그램을 개략적으로 나타낸 블럭 구성도이다. 본 실시예에 따른 이미지 추론 프로그램은 입력부, 세그멘테이션부, 세그멘테이션 확장부, 이미지 패딩부, 이미지 확장부를 포함한다. 이미지 추론 프로그램에 포함된 구성요소는 반드시 이에 한정되는 것은 아니다. 이미지 추론 프로그램은 시멘틱 이미지 추론 장치 내에 탑재되어 구동되는 프로그램으로서, 이미지 추론 프로그램에 포함된 각 구성요소는 장치 내부의 소프트웨어적인 모듈 또는 하드웨어적인 모듈을 연결 하는 통신 경로에 연결되어 상호 간에 유기적으로 동작할 수 있다. 이러한 구성요소는 하나 이상의 통신 버스 또는 신호선을 이용하여 통신한다. 도 2에 도시된 이미지 추론 프로그램의 각 구성요소는 적어도 하나의 기능이나 동작을 처리하는 단위를 의 미하며, 소프트웨어적인 모듈, 하드웨어적인 모듈 또는 소프트웨어와 하드웨어의 결합으로 구현될 수 있다. 입력부는 입력 이미지(Input Image)(I)를 입력받는다. 세그멘테이션부는 입력 이미지(I)를 미리 딥러닝 기반으로 학습된 인공지능 모델을 이용하여 세그멘 테이션 맵(Segmentation-Map)(S^)을 생성한다. 세그멘테이션부는 세그멘테이션 맵(S^)을 생성할 때, 인페이팅(Inpainting) 기법을 이용할 수 있으나, 반 드시 이에 한정되는 것은 아니다. 세그멘테이션부는 인공지능 모델을 이용하여 세그멘테이션 맵(S^) 을 생성할 때, 딥 러닝 기반으로 학습한 데이터셋이 부족한 경우, 윅클리 슈퍼바이즈 러닝(Weakly-Supervised Learning) 기법을 이용할 수 있으나, 반드시 이에 한정되는 것은 아니다. 세그멘테이션 확장부는 인공지능 모델을 이용하여 세그멘테이션 맵(S^)을 기반으로 빈영역을 확장한 세그멘테이션 맵(Extrapolated Segmentation-Map)(S^ E)를 생성한다. 세그멘테이션 확장부는 빈영역을 마스크 상태로 유지하는 것이 아니라 먼저 인터폴레이션(interpolation) 을 수행하여 빈영역을 채운 패딩된 세그멘테이션 맵(S^ P)을 생성한다. 세그멘테이션 확장부는 인공지능 모 델을 이용하여 패딩된 세그멘테이션 맵(S^ P)을 확장한 세그멘테이션 맵(S^ E)으로 생성한다. 세그멘테이션 확장부는 빈영역 내에 정보가 전혀 존재하지 않는 경우, 빈영역과 가장 인접한 가장자리 경 계에 위치한 가장자리 픽셀 값을 복사하여 패딩된 세그멘테이션 맵(S^ P)을 생성한다. 세그멘테이션 확장부 는 확장한 세그멘테이션 맵(S^ E) 내에 이미지 내의 확장할 객체 또는 영역이 동일한 객체 또는 영역과 동일한 색 상으로 표현되도록 한다. 이미지 패딩부는 입력 이미지(I)를 기반으로 확장할 영역을 포함하는 패딩된 이미지(Padded Image)(IP)를 생성한다. 이미지 확장부는 인공지능 모델을 이용하여 패딩된 이미지(IP)와 빈영역 확장한 세그멘테 이션 맵(S^ E)를 결합하여 빈영역을 확장한 이미지(Extrapolated Image)(I^ E)를 생성한다. 이미지 확장부는 빈영역을 확장한 이미지(I^ E)를 생성할 때, 빈영역을 확장한 세그멘테이션 맵(S^ E) 내의 정보를 전달하기 위해서 채널 연결(Channel Concatenation), 조건부 비정규화(Conditional Denormalization) 중 적어도 하나 이상의 방식을 이용한다. 이미지 확장부는 채널 연결(channel concatenation)을 이용하여 하나의 이미지 별 채널정보가 인공지능 모 델로 입력될 때, 세그멘테이션 이미지를 같이 합쳐서 인공지능 모델로 입력되도록 한다. 이미지 확장 부는 조건부 비정규화(conditional denormalization)를 이용하여 이미지 내에서 클래스들의 통계적 특성을 기반으로 각 객체의 평균과 표준편차가 특정 객체의 평균과 표준편차로 시프트 시킨다. 이미지 확장부는 Gated Convolution을 이용하여 패딩된 이미지(IP)와 빈영역 확장한 세그멘테이션 맵(S^ E)를 결합하여 빈영역을 확장한 이미지(I^ E)를 생성할 수 있으나, 반드시 이에 한정되는 것은 아니다. 도 3은 본 실시예에 따른 빈영역에 채워질 시멘틱 이미지를 추론하는 방식을 나타낸 도면이다. 이미지 추론 프로그램은 입력 이미지(I)로부터 인공지능 모델을 이용하여 세그멘테이션 맵(S^)을 예 측한다. 이때, 이미지 추론 프로그램은 세그멘테이션 맵(S^)을 만들기 위한 테스트 환경에 적합한 데이터 셋이 부족한 경우, weakly-supervised learning 기법을 이용할 수 있다. 이미지 추론 프로그램은 입력 이미지(I)로부터 세그멘테이션 맵(S^)을 예측할 때, 부가적으로 딥 러닝 기 반으로 학습한 데이터 셋(예컨대, 공연장과 같이 사람이 많은 학습 데이터)을 이용한다. 이미지 추론 프로그램 은 입력 이미지(I)가 공연장과 같이 하늘과 같은 공간이 없고 건물과 사람으로만 이루어진 영상인 경우, 하나의 입력 이미지(I) 자체를 하나의 세그멘테이션 맵(S^)으로 만들 수 있다. 이미지 추론 프로그램은 하 나의 입력 이미지(I) 자체를 하나의 세그멘테이션 맵(S^)으로 만들 때 슈퍼바이즈 러닝 기법을 이용할 수 있다. 이미지 추론 프로그램은 인공지능 모델을 이용하여 세그멘테이션 맵(S^)으로부터 빈영역을 확장한 세 그멘테이션 맵(S^ E)를 예측한다. 이때, 이미지 추론 프로그램은 학습을 안정화시키기 위해서 세그멘테이션 맵(S^) 대신 패딩된 세그멘테이션 맵(S^ P)을 이용할 수 있다. 이미지 추론 프로그램은 패딩된 세그멘테이션 맵(S^ P)을 생성할 때, 가장자리 픽셀 값을 복사하는 방법을 이용할 수 있다. 이미지 추론 프로그램은 세그멘테이션 맵(S^)이 예측되면, 세그멘테이션 맵(S^)을 기반으로 빈영역을 확장 한 세그멘테이션 맵(S^ E)을 생성한다. 이미지 추론 프로그램은 영상의 가장자리만을 확장하는 것이 아니라 채워져야 할 빈영역을 확장한 세그멘테이션 맵(S^ E)을 생성한다. 이미지 추론 프로그램은 빈영역을 마스크 형태로 유지하는 것이 아니라 인터폴레이션(interpolation)을 이 용하여 비워진 영역을 먼저 채워서 패딩된 세그멘테이션 맵(S^ P)를 만든다. 이때, 인공지능 모델은 패딩된 세그멘테이션 맵(S^ P)을 학습에 이용할 수 있다. 예컨대, 이미지 추론 프로그램은 비워진 영역 내에 정보가 전혀 없을 때, 비워진 영역과 인접한 가장자리 경계에 있는 정보를 복사하여 비슷한 정보를 가지도록 패딩된 세 그멘테이션 맵(S^ P)을 생성할 수 있다. 이미지 추론 프로그램은 패딩된 이미지(IP)와 빈영역 확장한 세그멘테이션 맵(S^ E)를 사용해서 빈영역을 확 장한 이미지(I^ E)를 예측한다. 이때, 이미지 추론 프로그램은 빈영역을 확장한 세그멘테이션 맵(S^ E)의 정 보를 전달하기 위해서 채널 연결(Channel Concatenation)을 이용할 수 있다. 이미지 추론 프로그램은 빈영 역을 확장한 세그멘테이션 맵(S^ E)의 정보를 전달하기 위해서 조건부 비정규화(Conditional Denormalization)를 이용할 수 있다. 이미지 추론 프로그램은 패딩된 이미지(IP)와 빈영역을 확장한 세그멘테이션 맵(S^ E)을 이용하여 빈영역을 확장한 이미지(I^ E)를 생성한다. 이미지 추론 프로그램은 패딩된 이미지(IP)와 빈영역을 확장한 세그멘테이 션 맵(S^ E)을 결합하기 위해서, 두 개의 채널을 그대로 채널 연결(channel concatenation)하는 방법을 사용할 수 있다. 채널 연결(channel concatenation)은 하나의 이미지(I)는 3채널을 가지고 있는데, 3채널 이미지가 인 공지능 모델의 컨볼루션 입력으로 들어올 때, 세그멘테이션 이미지를 같이 합치게 되면, 6채널 인공지능 모델에 입력될 수 있도록 한다. 즉, 채널 연결(channel concatenation)을 이용하는 경우, 두 개의 채널 정 보를 결합해서 인공지능 모델에 입력할 수 있다. 이미지 추론 프로그램은 패딩된 이미지(IP)와 빈영역을 확장한 세그멘테이션 맵(S^ E)을 결합하기 위해서, 조건부 비정규화(conditional denormalization)를 이용할 수 있다. 이미지 추론 프로그램은 조건부 비정규화(conditional denormalization)를 이용하여 영상 내에서 클래스들 의 통계적 특성인 서로 다른 특성을 갖는 각 객체의 평균과 표준편차를 특정 객체의 평균과 표준편차로 시프트 시킨다. 이미지 추론 프로그램은 조건부 비정규화(conditional denormalization)를 이용하여 입력으로 들 어오는 영상의 피쳐를 평균을 빼고 표준편차로 나눠서 정규화한다. 정규화된 입력 피쳐 맵이 생성되는데, 이를 비정규화할 때 γ를 곱해서 β를 더해준다. γ와 β는 원본 영상을 기반으로 생성하는 것이 아니라 컨디션으로 전달해주는 맵의 정보를 기반으로 딥러닝 컨볼루션을 통과해서 결정한다. 예컨대, 인스턴스 정규화(Adaptive Instance Normalization)과 공간 정규화(Spatial Adaptive Normalization)이 있다. 이미지 추론 프로그램은 패딩된 이미지(IP)와 빈영역 확장한 세그멘테이션 맵(S^ E)를 결합하여 빈영역을 확 장한 이미지(Extrapolated Image)(I^ E)를 생성할 때, Gated Convolution을 이용할 수 있다. 이미지 추론 프로그램은 Gated Convolution을 이용하여 지워진 부분을 설정하고, CNN에 대해서 컨볼루션 커널로 순차적으로 변화시킨다. 이미지 추론 프로그램은 Gated Convolution을 이용하여 영상에 대해서 동 일한 커널을 적용하며, 정보가 있는 영역에 대해서는 컨볼루션으로 정보를 채운다. 이미지 추론 프로그램 은 Gated Convolution을 이용하여 마스크(정보가 없는 영역)에 대해서는 컨볼루션을 수행하지 않고, 정보가 있 는 영역과 정보가 없는 영역의 경계 영역이 조금씩 채운다. 이미지 추론 프로그램은 확장할 영역(공간)을 채우기 위해서 먼저, 세그먼테이션 맵(S^)을 확장시켜서 빈 영역을 확장한 세그멘테이션 맵(S^ E)을 확장할 영역(공간)에 반영한다. 이미지 추론 프로그램은 빈영역을 확장한 세그멘테이션 맵(S^ E)을 기초로 Gated Convolution을 적용할 수 있으나, 반드시 Gated Convolution으로 한정되는 것은 아니며, 다양한 인공지능 기법이 적용될 수 있다. 이미지 추론 프로그램은 세그멘테이션 맵(S^)을 생성할 때, 인페이팅(Inpainting) 기법을 이용할 수 있다. 도 4는 본 실시예에 따른 빈영역에 채워질 시멘틱 이미지를 추론 방법을 설명하기 위한 순서도이다. 이미지 추론 프로그램은 입력 이미지(Input Image)(I)를 입력받는다(S410). 이미지 추론 프로그램은 입력 이미지(I)를 미리 딥러닝 기반으로 학습된 인공지능 모델을 이용하여 세그멘테이션 맵(S^)을 생성한다(S420). 단계 S420에서, 이미지 추론 프로그램은 세그멘테이션 맵(S^)을 생 성할 때, 인페이팅(Inpainting) 기법을 이용할 수 있으나, 반드시 이에 한정되는 것은 아니다. 이미지 추론 프로그램은 인공지능 모델을 이용하여 세그멘테이션 맵(S^)을 생성할 때, 딥 러닝 기반 으로 학습한 데이터셋이 부족한 경우, 윅클리 슈퍼바이즈 러닝(Weakly-Supervised Learning) 기법을 이용할 수 있으나, 반드시 이에 한정되는 것은 아니다. 이미지 추론 프로그램은 인공지능 모델을 이용하여 세그멘테이션 맵(S^)을 기반으로 빈영역을 확장한 세그멘테이션 맵(S^ E)를 생성한다(S430). 단계 S430에서, 이미지 추론 프로그램은 빈영역을 마스크 상태로 유지하는 것이 아니라 먼저 인터폴레이션(interpolation)을 수행하여 빈영역을 채운 패딩된 세그멘테이션 맵 (S^ P)를 생성한다. 이미지 추론 프로그램은 인공지능 모델을 이용하여 패딩된 세그멘테이션 맵(S^ P)을확장한 세그멘테이션 맵(S^ E)으로 생성한다. 이미지 추론 프로그램은 빈영역 내에 정보가 전혀 존재하지 않는 경우, 빈영역과 가장 인접한 가장자리 경 계에 위치한 가장자리 픽셀 값을 복사하여 패딩된 세그멘테이션 맵(S^ P)을 생성한다. 이미지 추론 프로그램(12 0)은 확장한 세그멘테이션 맵(S^ E) 내에 이미지 내의 확장할 객체 또는 영역이 동일한 객체 또는 영역과 동일한 색상으로 표현되도록 한다. 이미지 추론 프로그램은 입력 이미지(I)를 기반으로 확장할 영역을 포함하는 패딩된 이미지(Padded Image)(IP)를 생성한다(S440). 이미지 추론 프로그램은 인공지능 모델을 이용하여 패딩된 이미지(IP)와 빈영역 확장한 세그멘테이션 맵(S^ E)를 결합하여 빈영역을 확장한 이미지(I^ E)를 생성한다(S450). 단계 S450에서, 이미지 추론 프로그램(12 0)은 빈영역을 확장한 이미지(I^ E)를 생성할 때, 빈영역을 확장한 세그멘테이션 맵(S^ E) 내의 정보를 전달하기 위 해서 채널 연결(Channel Concatenation), 조건부 비정규화(Conditional Denormalization) 중 적어도 하나 이상 의 방식을 이용한다. 이미지 추론 프로그램은 채널 연결(channel concatenation)을 이용하여 하나의 이미지 별 채널정보가 인공 지능 모델로 입력될 때, 세그멘테이션 이미지를 같이 합쳐서 인공지능 모델로 입력되도록 한다. 이미지 추론 프로그램은 조건부 비정규화(conditional denormalization)를 이용하여 이미지 내에서 클래스 들의 통계적 특성을 기반으로 각 객체의 평균과 표준편차가 특정 객체의 평균과 표준편차로 시프트 시킨다. 이미지 추론 프로그램은 Gated Convolution을 이용하여 패딩된 이미지(IP)와 빈영역 확장한 세그멘테이션 맵(S^ E)를 결합하여 빈영역을 확장한 이미지(I^ E)를 생성할 수 있으나, 반드시 이에 한정되는 것은 아니다. 도 4에서는 단계 S410 내지 단계 S450을 순차적으로 실행하는 것으로 기재하고 있으나, 반드시 이에 한정되는 것은 아니다. 다시 말해, 도 4에 기재된 단계를 변경하여 실행하거나 하나 이상의 단계를 병렬적으로 실행하는 것으로 적용 가능할 것이므로, 도 4는 시계열적인 순서로 한정되는 것은 아니다. 전술한 바와 같이 도 4에 기재된 본 실시예에 따른 시멘틱 이미지를 추론 방법은 프로그램으로 구현되고 컴퓨터 로 읽을 수 있는 기록매체에 기록될 수 있다. 본 실시예에 따른 시멘틱 이미지를 추론 방법을 구현하기 위한 프 로그램이 기록되고 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되 는 모든 종류의 기록장치를 포함한다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2019-0174883", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 실시예에 따른 빈영역에 채워질 이미지를 추론하는 시멘틱 이미지 추론 장치를 개략적으로 나타낸 블 럭 구성도이다. 도 2는 본 실시예에 따른 시멘틱 이미지 추론 장치 내에 탑재되는 이미지 추론 프로그램을 개략적으로 나타낸 블럭 구성도이다. 도 3은 본 실시예에 따른 빈영역에 채워질 시멘틱 이미지를 추론하는 방식을 나타낸 도면이다. 도 4는 본 실시예에 따른 빈영역에 채워질 시멘틱 이미지를 추론 방법을 설명하기 위한 순서도이다."}
