{"patent_id": "10-2023-0152938", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0066121", "출원번호": "10-2023-0152938", "발명의 명칭": "무선 통신 시스템에서 기계학습 기반 채널 상태 정보 피드백 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "이안석"}}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "단말의 방법에 있어서,기지국으로부터 채널 상태 정보(channel status information, CSI)를 부호화하여 전송하기 위해 상기 단말에 설정되는 제1 인공 지능(artificial intelligence, AI) 모델의 양자화 구성 정보 중 하나를 지시하는 제1 지시 정보를 포함하는 CSI 피드백 정보 요청 메시지를 수신하는 단계;상기 제1 지시 정보에 기초하여 생성된 CSI 피드백 정보를 양자화하는 단계; 및상기 양자화된 CSI 피드백 정보를 포함하는 CSI 보고 메시지를 상기 기지국으로 전송하는 단계를 포함하는,단말의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 CSI 피드백 정보 요청 메시지는 서브밴드 및 레이어에 대한 제2 지시 정보를 더 포함하며,상기 제2 지시 정보는 (1) 개별 서브밴드, 개별 레이어, (2) 전체 서브밴드, 개별 레이어, (3) 개별 서브밴드, 전체 레이어, 및 (4) 전체 서브밴드, 전체 레이어위의 (1) 내지 (4) 중 어느 하나를 지시하는,단말의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 CSI 피드백 정보 요청 메시지에 전체 서브밴드의 공통 정보 또는 상기 전체 레이어의 공통 정보 중 적어도하나를 요청하는 제3 지시 정보가 포함될 시,상기 CSI 피드백 정보는 전체 서브채널의 공통 정보 및 전체 계층의 공통 정보를 더 포함하며,상기 CSI 피드백 정보 보고 메시지는 상기 전체 서브밴드의 공통 정보 또는 상기 전체 계층의 공통 정보 중 적어도 하나를 포함하는,단말의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 제1 AI 모델 및 상기 CSI피드백 정보를 복호하기 위해 기지국에 설정되는 제2 AI 모델의 학습을 수행하는단계;상기 제2 AI 모델을 상기 기지국으로 전송하는 단계; 및상기 제1 AI 모델의 양자화 구성 정보를 상기 기지국으로 전송하는 단계를 더 포함하며,상기 제1 AI 모델의 양자화 구성 정보는 상기 제1 AI 모델 및 상기 제2 AI 모델의 입력 데이터 세트에 대한 잠공개특허 10-2024-0066121-3-재 변수 분포에 기초하여 생성되는,단말의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 제1 AI 모델의 양자화 구성 정보는 양자화 방법들 각각과 매핑된 참조 번호들을 포함하며,상기 제1 AI 모델의 양자화 방법들은 벡터 양자화 방법, 균등 스칼라 양자화 방법 및 비균등 스칼라 양자화 방법을 포함하는,단말의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 제1 AI 모델의 양자화 구성 정보는,벡터 양자화 수행 시 잠재 변수로 구성되는 코드북 정보, 균등 스칼라 양자화 수행 시 상기 잠재 변수의 차원별 양자화 비트 수와 양자화 구성 정보, 및 비균등 스칼라 양자화 수행 시 상기 잠재 변수의 차원 별 양자화 비트 수와 양자화 구성 정보를 더 포함하는,단말의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 제1 AI 모델의 양자화 구성 정보는 균등 스칼라 양자화 사용 시 필요한 최소 값 및 최대 값 정보를 더 포함하고, 비균등 스칼라 양자화 사용 시 필요한 결정 경계 및 표현값 정보를 더 포함하는,단말의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서,상기 제1 AI 모델 및 상기 CSI 피드백 정보를 복호하여 CSI를 도출하기 위해 기지국에 설정되는 제2 AI 모델의학습 유형 관련 정보를 포함하는 학습 요청 메시지를 상기 기지국으로 전송하는 단계;상기 기지국으로부터 학습 가능을 지시하는 제1 학습 응답 메시지를 수신하는 경우 상기 제1 AI 모델의 학습을수행하는 단계;상기 제2 AI 모델의 학습을 위한 데이터 세트를 생성하는 단계;상기 데이터 세트를 상기 기지국으로 전송하는 단계; 및상기 기지국으로부터 상기 제2 AI 모델의 학습 결과 정보를 포함하는 제2 학습 응답 메시지를 수신하는 단계를더 포함하는,단말의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 학습 유형 관련 정보는, 상기 제1 AI 모델 및 상기 제2 AI 모델의 입력 유형, 입력 차원, 입력 표현 방법,잠재 차원 및 잠재 표현 방법을 포함하는,단말의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2024-0066121-4-기지국의 방법에 있어서,채널 상태 정보(channel status information, CSI)를 부호화하여 전송하기 위해 상기 단말에 설정되는 제1 인공지능(artificial intelligence, AI) 모델의 양자화 구성 정보 중 하나를 지시하는 제1 지시 정보를 포함하는CSI 피드백 정보 요청 메시지를 단말로 전송하는 단계; 및상기 CSI 요청 메시지의 상기 제1 지시 정보에 기초하여 양자화된 CSI 피드백 정보를 포함하는 CSI 보고 메시지를 상기 단말로부터 수신하는 단계를 포함하며,기지국의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서,상기 CSI 피드백 정보 요청 메시지는 서브밴드 및 레이어에 대한 제2 지시 정보를 더 포함하며,상기 제2 지시 정보는 (1) 개별 서브밴드, 개별 레이어, (2) 전체 서브밴드, 개별 레이어, (3) 개별 서브밴드, 전체 레이어, 및 (4) 전체 서브밴드, 전체 레이어위의 (1) 내지 (4) 중 어느 하나를 지시하는,기지국의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 CSI 요청 메시지에 전체 서브밴드의 공통 정보 또는 전체 계층의 공통 정보 중 적어도 하나를 요청하는 제3 지시 정보를 더 포함하며, 상기 CSI 피드백 정보 보고 메시지는 상기 전체 서브밴드의 공통 정보 또는 상기 전체 계층의 공통 정보 중 적어도 하나를 포함하는,기지국의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 10에 있어서,상기 단말로부터 상기 제2 AI 모델을 수신하는 단계; 및상기 제1 AI 모델의 양자화 구성 정보를 상기 단말로부터 수신하는 단계를 더 포함하는,기지국의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 10에 있어서,상기 제1 AI 모델의 양자화 구성 정보는 양자화 방법들 각각과 매핑된 참조 번호들을 포함하며, 및상기 제1 AI 모델의 양자화 방법들은 벡터 양자화 방법, 균등 스칼라 양자화 방법 및 비균등 스칼라 양자화 방법을 포함하는,기지국의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2024-0066121-5-청구항 10에 있어서,상기 제1 AI 모델의 양자화 구성 정보는,벡터 양자화 수행 시 잠재 변수로 구성되는 코드북 정보, 균등 스칼라 양자화 수행 시 상기 잠재 변수의 차원별 양자화 비트 수와 양자화 구성 정보, 및 비균등 스칼라 양자화 수행 시 상기 잠재 변수의 차원 별 양자화 비트 수와 양자화 구성 정보를 더 포함하고, 및상기 제1 AI 모델의 양자화 구성 정보는 균등 스칼라 양자화 사용 시 필요한 최소 값 및 최대 값 정보를 더 포함하고, 비균등 스칼라 양자화 사용 시 필요한 결정 경계 및 표현값 정보를 더 포함하는,기지국의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 10에 있어서,상기 제1 AI 모델 및 상기 제2 AI 모델의 학습 유형 관련 정보를 포함하는 학습 요청 메시지를 상기 단말로부터수신하는 단계;상기 제2 AI 모델의 학습이 가능 여부를 확인하는 단계;상기 제2 AI 모델의 학습이 가능한 경우 학습 가능을 지시하는 제1 학습 응답 메시지를 상기 단말로 전송하는단계;상기 제2 AI 모델의 학습을 위한 데이터 세트를 상기 단말로부터 수신하는 단계;상기 데이터 세트를 이용하여 상기 제2 AI 모델을 학습하는 단계; 및상기 제2 AI 모델의 학습 결과 정보를 포함하는 제2 학습 응답 메시지를 상기 단말로 전송하는 단계를 더 포함하는,기지국의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 16에 있어서,상기 학습 유형 관련 정보는, 상기 제1 AI 모델 및 상기 제2 AI 모델의 입력 유형, 입력 차원, 입력 표현 방법,잠재 차원 및 잠재 표현 방법을 포함하는,기지국의 방법."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "단말에 있어서,적어도 하나의 프로세서를 포함하며,상기 적어도 하나의 프로세서는 상기 단말이:기지국으로부터 채널 상태 정보(channel status information, CSI)를 부호화하여 전송하기 위해 상기 단말에 설정되는 제1 인공 지능(artificial intelligence, AI) 모델의 양자화 구성 정보 중 하나를 지시하는 제1 지시 정보를 포함하는 CSI 피드백 정보 요청 메시지를 수신하고;상기 제1 지시 정보에 기초하여 생성된 CSI 피드백 정보를 양자화하고; 및상기 양자화된 CSI 피드백 정보를 포함하는 CSI 보고 메시지를 상기 기지국으로 전송하도록 야기하는,단말."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 18에 있어서,공개특허 10-2024-0066121-6-상기 적어도 하나의 프로세서는 상기 단말이:상기 제1 AI 모델 및 상기 CSI피드백 정보를 복호하기 위해 기지국에 설정되는 제2 AI 모델의 학습을 수행하고;상기 제2 AI 모델을 상기 기지국으로 전송하고; 및상기 제1 AI 모델의 양자화 구성 정보를 상기 기지국으로 전송하도록 더 야기하며,상기 제1 AI 모델의 양자화 구성 정보는 상기 제1 AI 모델 및 상기 제2 AI 모델의 입력 데이터 세트에 대한 잠재 변수 분포에 기초하여 생성되는,단말."}
{"patent_id": "10-2023-0152938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "청구항 18에 있어서,상기 적어도 하나의 프로세서는 상기 단말이:상기 제1 AI 모델 및 상기 CSI 피드백 정보를 복호하여 CSI를 도출하기 위해 기지국에 설정되는 제2 AI 모델의학습 유형 관련 정보를 포함하는 학습 요청 메시지를 상기 기지국으로 전송하고;상기 기지국으로부터 학습 가능을 지시하는 제1 학습 응답 메시지를 수신하는 경우 상기 제1 AI 모델의 학습을수행하고;상기 제2 AI 모델의 학습을 위한 데이터 세트를 생성하고;상기 데이터 세트를 상기 기지국으로 전송하고; 및상기 기지국으로부터 상기 제2 AI 모델의 학습 결과 정보를 포함하는 제2 학습 응답 메시지를 수신하도록 더 야기하는,단말."}
{"patent_id": "10-2023-0152938", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에 따른 단말의 방법은, CSI를 부호화하여 전송하기 위해 상기 단말에 설정되는 제1 AI 모델 및 상기 CSI 를 복호하여 CSI를 도출하기 위해 기지국에 설정되는 제2 AI 모델의 학습을 수행하는 단계; 상기 제2 AI 모델을 상기 기지국으로 전송하는 단계; 및 상기 제1 AI 모델의 양자화 구성 정보를 상기 기지국으로 전송하는 단계를 포함하며, 상기 양자화 구성 정보는 상기 제1 AI 모델 및 상기 제2 AI 모델의 입력 데이터 세트에 대한 잠재 변 수 분포에 기초하여 생성될 수 있다."}
{"patent_id": "10-2023-0152938", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 채널 상태 정보 피드백 기술에 관한 것으로, 더욱 상세하게는 기계학습에 기반한 채널 상태 정보 피 드백 기술에 관한 것이다."}
{"patent_id": "10-2023-0152938", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "ITU(International Telecommunication Union)에서는 IMT(International Mobile Telecommunication) 프레임워 크 및 표준에 대해서 개발하고 있으며, 최근에는 \"IMT for 2030 and beyond\"라 불리는 프로그램을 통하여 6세대 (6G) 통신을 위한 논의를 진행하고 있다. 6G를 구현하기 위한 기술 중 크게 주목을 받고 있는 분야는 인공 지능(artificial intelligence, AI) 및 기계 학습(machine learning, ML)이며, 3GPP에서는 Air Interface를 위한 AI/ML 기술에 대한 연구를 수행하는 것을 Rel-18에서 시작하였다. 3GPP에서 수행하는 연구의 주요 사용 예(Use case)는 아래와 같다. □ CSI 피드백 향상을 위한 AI/ML(AI/ML for CSI feedback enhancement) □ 빔 관리를 위한 AI/ML(AI/ML for beam management) □ 측위 성능 향상을 위한 AI/ML(AI/ML for positioning performance enhancement) 무선 통신 시스템에서는 수신기가 CSI-RS를 수신한 이후 CSI를 생성하여 이를 다시 송신기로 전달하는 CSI 보고 절차가 수행된다. 이 때, 채널 정보를 정밀하게 표현하기 위해서는 정보량이 매우 커야 하며, 이는 무선 전송 자원의 점유량 및 오버헤드를 증대시켜 시스템 성능을 감소시키는 요인이 된다. 특히, 송신기에서 프리코딩을 결정하기 위한 채널 변화를 표현하기 위한 채널 정보, 또는 적절한 프리코딩 벡터를 수신기에서 추천하기 위한프리코딩 정보를 정밀하게 표현하는 것이 큰 오버헤드를 야기할 수 있다. 이동통신 네트워크에서 이러한 문제를 해결하기 위하여 기계 학습(machine learning, ML) 기술을 이용하여 전송 정보량을 최소화하면서도 높은 정확도로 채널 상태 정보를 송신기에서 획득할 수 있는 기술에 대해 연구가 시작 되었다. 이러한 기술을 5세대 이후 이동 통신 시스템에도 적용하기 위한 논의가 시작되고 있다. 채널 정보를 전 달하기 위한 기계 학습 구조로 오토 인코더(Auto Encoder) 기반 신경망이 제안되었다. 오토 인코더 기반 신경망 은 무선 채널 정보를 이미지 형태로 입력하여 인코더 망을 통하여 저차원 잠재공간의 코드 벡터로 압축하며, 이 를 다시 디코더 망에서 원래의 무선 채널 정보로 복원할 수 있는 컨볼루셔널 신경망(Convolutional Neural Network, CNN) 기반의 인공 신경망이 제안되었다. CNN은 효과적으로 압축 및 복원이 가능하다. 하지만, ML을 이 용하는 경우 채널 정보 전체를 전송하기 때문에 전송해야 할 정보량이 크며, 압축된 저차원의 코드 벡터가 실수 값을 가지기 때문에 실제 시스템의 수신기에서 송신기로 정보를 전달하기 위하여 양자화 과정 등이 추가 고려되 어야 한다. 이러한 문제를 해결하기 위해 양자화를 고려한 압축 송신 및 복구 과정이 제시되어 있다. 하지만, 양자화를 고려한 압축 송신 및 복구 과정은 각 양자화 방법에 따른 학습이 수행되는 경우, 해당 학습 모델은 학 습 시 고려한 양자화 방법만을 지원한다. 따라서, 실제 네트워크에서 다양한 방법의 양자화, 또는 CSI 보고 페 이로드 크기가 고려되는 경우, 각 양자화 방법 또는 CSI 보고 페이로드 크기마다 별도의 학습 모델이 필요한 단 점이 존재한다."}
{"patent_id": "10-2023-0152938", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 요구를 해결하기 위한 본 개시의 목적은, 이동 통신 시스템의 확장성을 지원할 수 있는 기계 학습 기반 채널 상태 정보 피드백 방법 및 장치를 제공하는데 있다."}
{"patent_id": "10-2023-0152938", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 개시의 일 실시예에 따른 단말의 방법은, 기지국으로부터 채널 상태 정보(channel status information, CSI)를 부호화하여 전송하기 위해 상기 단말에 설정되는 제1 인공 지능(artificial intelligence, AI) 모델의 양자화 구성 정보 중 하나를 지시하는 제1 지시 정보를 포함하는 CSI 피드백 정보 요 청 메시지를 수신하는 단계; 상기 제1 지시 정보에 기초하여 생성된 CSI 피드백 정보를 양자화하는 단계; 및 상 기 양자화된 CSI 피드백 정보를 포함하는 CSI 보고 메시지를 상기 기지국으로 전송하는 단계를 포함할 수 있다. 상기 CSI 피드백 정보 요청 메시지는 서브밴드 및 레이어에 대한 제2 지시 정보를 더 포함할 수 있으며, 상기 제2 지시 정보는: 개별 서브밴드, 개별 레이어, 전체 서브밴드, 개별 레이어, 개별 서브밴드, 전체 레이어, 및 전체 서브밴드, 전체 레이어 위의 내지 중 어느 하나를 지시할 수 있다. 상기 CSI 피드백 정보 요청 메시지에 전체 서브밴드의 공통 정보 또는 상기 전체 레이어의 공통 정보 중 적어도 하나를 요청하는 제3 지시 정보가 포함될 시, 상기 CSI 피드백 정보는 전체 서브채널의 공통 정보 및 전체 계층 의 공통 정보를 더 포함할 수 있으며, 상기 CSI 피드백 정보 보고 메시지는 상기 전체 서브밴드의 공통 정보 또는 상기 전체 계층의 공통 정보 중 적 어도 하나를 포함할 수 있다. 상기 제1 AI 모델 및 상기 CSI피드백 정보를 복호하기 위해 기지국에 설정되는 제2 AI 모델의 학습을 수행하는 단계; 상기 제2 AI 모델을 상기 기지국으로 전송하는 단계; 및 상기 제1 AI 모델의 양자화 구성 정보를 상기 기 지국으로 전송하는 단계를 더 포함할 수 있고, 상기 제1 AI 모델의 양자화 구성 정보는 상기 제1 AI 모델 및 상기 제2 AI 모델의 입력 데이터 세트에 대한 잠 재 변수 분포에 기초하여 생성될 수 있다.상기 제1 AI 모델의 양자화 구성 정보는 양자화 방법들 각각과 매핑된 참조 번호들을 포함할 수 있으며, 상기 제1 AI 모델의 양자화 방법들은 벡터 양자화 방법, 균등 스칼라 양자화 방법 및 비균등 스칼라 양자화 방 법을 포함할 수 있다. 상기 제1 AI 모델의 양자화 구성 정보는, 벡터 양자화 수행 시 잠재 변수로 구성되는 코드북 정보, 균등 스칼라 양자화 수행 시 상기 잠재 변수의 차원 별 양자화 비트 수와 양자화 구성 정보, 및 비균등 스칼라 양자화 수행 시 상기 잠재 변수의 차원 별 양자화 비트 수와 양자화 구성 정보를 더 포함할 수 있다. 상기 제1 AI 모델의 양자화 구성 정보는 균등 스칼라 양자화 사용 시 필요한 최소 값 및 최대 값 정보를 더 포 함하고, 비균등 스칼라 양자화 사용 시 필요한 결정 경계 및 표현값 정보를 더 포함할 수 있다. 상기 제1 AI 모델 및 상기 CSI 피드백 정보를 복호하여 CSI를 도출하기 위해 기지국에 설정되는 제2 AI 모델의 학습 유형 관련 정보를 포함하는 학습 요청 메시지를 상기 기지국으로 전송하는 단계; 상기 기지국으로부터 학 습 가능을 지시하는 제1 학습 응답 메시지를 수신하는 경우 상기 제1 AI 모델의 학습을 수행하는 단계; 상기 제 2 AI 모델의 학습을 위한 데이터 세트를 생성하는 단계; 상기 데이터 세트를 상기 기지국으로 전송하는 단계; 및 상기 기지국으로부터 상기 제2 AI 모델의 학습 결과 정보를 포함하는 제2 학습 응답 메시지를 수신하는 단계 를 더 포함할 수 있다. 상기 학습 유형 관련 정보는, 상기 제1 AI 모델 및 상기 제2 AI 모델의 입력 유형, 입력 차원, 입력 표현 방법, 잠재 차원 및 잠재 표현 방법을 포함할 수 있다. 본 개시의 일 실시예에 따른 기지국의 방법은, 채널 상태 정보(channel status information, CSI)를 부호화하여 전송하기 위해 상기 단말에 설정되는 제1 인공 지능(artificial intelligence, AI) 모델의 양자화 구성 정보 중 하나를 지시하는 제1 지시 정보를 포함하는 CSI 피드백 정보 요청 메시지를 단말로 전송하는 단계; 및 상기 CSI 요청 메시지의 상기 제1 지시 정보에 기초하여 양자화된 CSI 피드백 정보를 포함하는 CSI 보고 메시지를 상기 단말로부터 수신하는 단계를 포함할 수 있으며, 상기 제1 AI 모델의 양자화 구성 정보는, 상기 제1 AI 모델 및 단말로부터 수신된 상기 양자화된 CSI 피드백 정 보를 복호하기 위해 상기 기지국에 설정되는 제2 AI 모델의 입력 데이터 세트에 대한 잠재 변수 분포에 기초하 여 생성될 수 있다. 상기 CSI 피드백 정보 요청 메시지는 서브밴드 및 레이어에 대한 제2 지시 정보를 더 포함할 수 있으며, 상기 제2 지시 정보는 개별 서브밴드, 개별 레이어, 전체 서브밴드, 개별 레이어, 개별 서브밴드, 전체 레이어, 및 전체 서브밴드, 전체 레이어 위의 내지 중 어느 하나를 지시할 수 있다. 상기 CSI 요청 메시지에 전체 서브밴드의 공통 정보 또는 전체 계층의 공통 정보 중 적어도 하나를 요청하는 제 3 지시 정보를 더 포함할 수 있으며, 상기 CSI 피드백 정보 보고 메시지는 상기 전체 서브밴드의 공통 정보 또는 상기 전체 계층의 공통 정보 중 적 어도 하나를 포함할 수 있다. 상기 단말로부터 상기 제2 AI 모델을 수신하는 단계; 및 상기 제1 AI 모델의 양자화 구성 정보를 상기 단말로부 터 수신하는 단계를 더 포함할 수 있다 상기 제1 AI 모델의 양자화 구성 정보는 양자화 방법들 각각과 매핑된 참조 번호들을 포함하며, 및 상기 제1 AI 모델의 양자화 방법들은 벡터 양자화 방법, 균등 스칼라 양자화 방법 및 비균등 스칼라 양자화 방법을 포함할 수 있다. 상기 제1 AI 모델의 양자화 구성 정보는, 벡터 양자화 수행 시 잠재 변수로 구성되는 코드북 정보, 균등 스칼라 양자화 수행 시 상기 잠재 변수의 차원 별 양자화 비트 수와 양자화 구성 정보, 및 비균등 스칼라 양자화 수행시 상기 잠재 변수의 차원 별 양자화 비트 수와 양자화 구성 정보를 더 포함할 수 있고, 및 상기 제1 AI 모델의 양자화 구성 정보는 균등 스칼라 양자화 사용 시 필요한 최소 값 및 최대 값 정보를 더 포 함하고, 비균등 스칼라 양자화 사용 시 필요한 결정 경계 및 표현값 정보를 더 포함할 수 있다. 상기 제1 AI 모델 및 상기 제2 AI 모델의 학습 유형 관련 정보를 포함하는 학습 요청 메시지를 상기 단말로부터 수신하는 단계; 상기 제2 AI 모델의 학습이 가능 여부를 확인하는 단계; 상기 제2 AI 모델의 학습이 가능한 경 우 학습 가능을 지시하는 제1 학습 응답 메시지를 상기 단말로 전송하는 단계; 상기 제2 AI 모델의 학습을 위한 데이터 세트를 상기 단말로부터 수신하는 단계; 상기 데이터 세트를 이용하여 상기 제2 AI 모델을 학습하는 단 계; 및 상기 제2 AI 모델의 학습 결과 정보를 포함하는 제2 학습 응답 메시지를 상기 단말로 전송하는 단계를 더 포함할 수 있다. 상기 학습 유형 관련 정보는, 상기 제1 AI 모델 및 상기 제2 AI 모델의 입력 유형, 입력 차원, 입력 표현 방법, 잠재 차원 및 잠재 표현 방법을 포함할 수 있다. 본 개시의 일 실시예에 따른 단말은, 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는 상기 단말이: 기지국으로부터 채널 상태 정보(channel status information, CSI)를 부호화하여 전송하기 위해 상기 단말에 설 정되는 제1 인공 지능(artificial intelligence, AI) 모델의 양자화 구성 정보 중 하나를 지시하는 제1 지시 정 보를 포함하는 CSI 피드백 정보 요청 메시지를 수신하고; 상기 제1 지시 정보에 기초하여 생성된 CSI 피드백 정 보를 양자화하고; 및 상기 양자화된 CSI 피드백 정보를 포함하는 CSI 보고 메시지를 상기 기지국으로 전송하도 록 야기할 수 있다. 상기 적어도 하나의 프로세서는 상기 단말이: 상기 제1 AI 모델 및 상기 CSI피드백 정보를 복호하기 위해 기지국에 설정되는 제2 AI 모델의 학습을 수행하고; 상기 제2 AI 모델을 상기 기지국으로 전송하고; 및 상기 제1 AI 모델의 양자화 구성 정보를 상기 기지국으로 전 송하도록 더 야기할 수 있으며, 상기 제1 AI 모델의 양자화 구성 정보는 상기 제1 AI 모델 및 상기 제2 AI 모델의 입력 데이터 세트에 대한 잠 재 변수 분포에 기초하여 생성될 수 있다. 상기 적어도 하나의 프로세서는 상기 단말이: 상기 제1 AI 모델 및 상기 CSI 피드백 정보를 복호하여 CSI를 도출하기 위해 기지국에 설정되는 제2 AI 모델의 학습 유형 관련 정보를 포함하는 학습 요청 메시지를 상기 기지국으로 전송하고; 상기 기지국으로부터 학습 가 능을 지시하는 제1 학습 응답 메시지를 수신하는 경우 상기 제1 AI 모델의 학습을 수행하고; 상기 제2 AI 모델 의 학습을 위한 데이터 세트를 생성하고; 상기 데이터 세트를 상기 기지국으로 전송하고; 및 상기 기지국으로부 터 상기 제2 AI 모델의 학습 결과 정보를 포함하는 제2 학습 응답 메시지를 수신하도록 더 야기할 수 있다."}
{"patent_id": "10-2023-0152938", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 이동 통신 네트워크에서 AI 모델 및/또는 ML 모들의 학습을 통해 CSI를 보고할 수 있으며, 이때, 양면 학습 모델을 이용할 수 있다. 양자화 되지 않은 잠재 변수를 이용한 AI 모델 및/또는 ML 모들을 사용하는 것을 제안하며, 이를 통하여 단일 기계학습 모델을 이용한 다양한 양자화 기법 및 CSI 보고 페 이로드 크기를 지원할 수 있는 장점이 있다. 본 개시에서는 이를 위해 양면 AI 모델 및/또는 ML 모들을 학습하 고, 학습된 AI 모델 및/또는 ML 모들을 이용한 CSI 보고 절차를 제공할 수 있다. 또한, 본 개시의 일 실시예에 따른 AI 모델 및/또는 ML 모들의 단위 입력으로 서브밴드 등 개별 주파수 단위 및 개별 레이어 단위를 사용할 수 있으며, 이를 반복적으로 사용하여 다양한 서브밴드 및 레이어 개수를 지원할 수 있다. 이를 통해 단일 AI 모델 및/또는 ML 모들을 이용한 다양한 서브밴드 및 레이어 개수의 CSI를 압축하여 전 달할 수 있는 장점이 있다."}
{"patent_id": "10-2023-0152938", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시는 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 개시를 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를 들어, 본 개시의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 개시에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다.다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 개시에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 개시에 따른 실시예들이 적용되는 통신 시스템(communication system)이 설명될 것이다. 본 개시에 따른 실 시예들이 적용되는 통신 시스템은 아래 설명된 내용에 한정되지 않으며, 본 개시에 따른 실시예들은 다양한 통 신 시스템에 적용될 수 있다. 여기서, 통신 시스템은 통신 네트워크(network)와 동일한 의미로 사용될 수 있다. 명세서 전체에서 망(network)은, 예를 들어, WiFi(wireless fidelity)와 같은 무선인터넷, WiBro(wireless broadband internet) 또는 WiMax(world interoperability for microwave access)와 같은 휴대인터넷, GSM(global system for mobile communication) 또는 CDMA(code division multiple access)와 같은 2G 이동통 신망, WCDMA(wideband code division multiple access) 또는 CDMA2000과 같은 3G 이동통신망, HSDPA(high speed downlink packet access) 또는 HSUPA(high speed uplink packet access)와 같은 3.5G 이동통신망, LTE(long term evolution)망 또는 LTE-Advanced망과 같은 4G 이동통신망, 및 5G 이동통신망 등을 포함할 수 있 다. 명세서 전체에서 단말(terminal)은 이동국(mobile station), 이동 단말(mobile terminal), 가입자국 (subscriber station), 휴대 가입자국(portable subscriber station), 사용자 장치(user equipment), 접근 단 말(access terminal) 등을 지칭할 수도 있고, 단말, 이동국, 이동 단말, 가입자국, 휴대 가입자 국, 사용자 장 치, 접근 단말 등의 전부 또는 일부의 기능을 포함할 수도 있다. 여기서, 단말로 통신이 가능한 데스크탑 컴퓨터(desktop computer), 랩탑 컴퓨터(laptop computer), 태블릿 (tablet) PC, 무선전화기(wireless phone), 모바일폰(mobile phone), 스마트 폰(smart phone), 스마트 워치 (smart watch), 스마트 글래스(smart glass), e-book 리더기, PMP(portable multimedia player), 휴대용 게임 기, 네비게이션(navigation) 장치, 디지털 카메라(digital camera), DMB (digital multimedia broadcasting) 재생기, 디지털 음성 녹음기(digital audio recorder), 디지털 음성 재생기(digital audio player), 디지털 영 상 녹화기(digital picture recorder), 디지털 영상 재생기(digital picture player), 디지털 동영상 녹화기 (digital video recorder), 디지털 동영상 재생기(digital video player) 등을 사용할 수 있다. 명세서 전체에서 기지국(base station)은 접근점(access point), 무선 접근국(radio access station), 노드 B(node B), 고도화 노드B(evolved nodeB), 송수신 기지국(base transceiver station), MMR(mobile multihop relay)-BS 등을 지칭할 수도 있고, 기지국, 접근점, 무선 접근국, 노드B, eNodeB, 송수신 기지국, MMR-BS 등의 전부 또는 일부의 기능을 포함할 수도 있다. 이하, 첨부한 도면들을 참조하여, 본 개시의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 개시를 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 통신 시스템의 일 실시예를 도시한 개념도이다. 도 1을 참조하면, 통신 시스템은 복수의 통신 노드들(110-1, 110-2, 110-3, 120-1, 120-2, 130-1, 130-2, 130-3, 130-4, 130-5, 130-6)을 포함할 수 있다. 복수의 통신 노드들은 3GPP(3rd generation partnership project) 표준에서 규정된 4G 통신(예를 들어, LTE(long term evolution), LTE-A(advanced)), 5G 통신(예를 들 어, NR(new radio)) 등을 지원할 수 있다. 4G 통신은 6GHz 이하의 주파수 대역에서 수행될 수 있고, 5G 통신은 6GHz 이하의 주파수 대역뿐만 아니라 6GHz 이상의 주파수 대역에서 수행될 수 있다. 예를 들어, 4G 통신 및 5G 통신을 위해 복수의 통신 노드들은 CDMA(code division multiple access) 기반의 통 신 프로토콜, WCDMA(wideband CDMA) 기반의 통신 프로토콜, TDMA(time division multiple access) 기반의 통신 프로토콜, FDMA(frequency division multiple access) 기반의 통신 프로토콜, OFDM(orthogonal frequency division multiplexing) 기반의 통신 프로토콜, Filtered OFDM 기반의 통신 프로토콜, CP(cyclic prefix)-OFDM 기반의 통신 프로토콜, DFT-s-OFDM(discrete Fourier transform-spread-OFDM) 기반의 통신 프로토콜, OFDMA(orthogonal frequency division multiple access) 기반의 통신 프로토콜, SC(single carrier)-FDMA 기반 의 통신 프로토콜, NOMA(Non-orthogonal Multiple Access), GFDM(generalized frequency division multiplexing) 기반의 통신 프로토콜, FBMC(filter bank multi-carrier) 기반의 통신 프로토콜,UFMC(universal filtered multi-carrier) 기반의 통신 프로토콜, SDMA(Space Division Multiple Access) 기반 의 통신 프로토콜 등을 지원할 수 있다. 또한, 통신 시스템은 코어 네트워크(core network)를 더 포함할 수 있다. 통신 시스템이 4G 통신을 지원하는 경우, 코어 네트워크는 S-GW(serving-gateway), P-GW(PDN(packet data network)-gateway), MME(mobility management entity) 등을 포함할 수 있다. 통신 시스템이 5G 통신을 지원하는 경우, 코어 네트워크는 UPF(user plane function), SMF(session management function), AMF(access and mobility management function) 등을 포함할 수 있다. 한편, 통신 시스템을 구성하는 복수의 통신 노드들(110-1, 110-2, 110-3, 120-1, 120-2, 130-1, 130-2, 130-3, 130-4, 130-5, 130-6) 각각은 다음과 같은 구조를 가질 수 있다. 도 2는 통신 시스템을 구성하는 통신 노드의 일 실시예를 도시한 블록도이다. 도 2를 참조하면, 통신 노드는 적어도 하나의 프로세서, 메모리 및 네트워크와 연결되어 통신을 수행하는 송수신 장치를 포함할 수 있다. 또한, 통신 노드는 입력 인터페이스 장치, 출력 인터 페이스 장치, 저장 장치 등을 더 포함할 수 있다. 통신 노드에 포함된 각각의 구성 요소들은 버 스(bus)에 의해 연결되어 서로 통신을 수행할 수 있다. 다만, 통신 노드에 포함된 각각의 구성요소들은 공통 버스가 아니라, 프로세서를 중심으로 개별 인터페이스 또는 개별 버스를 통하여 연결될 수도 있다. 예를 들어, 프로세서는 메모리, 송수신 장치 , 입력 인터페이스 장치, 출력 인터페이스 장치 및 저장 장치 중에서 적어도 하나와 전용 인터페이스를 통하여 연결될 수도 있다. 프로세서는 메모리 및 저장 장치 중에서 적어도 하나에 저장된 프로그램 명령(program comman d)을 실행할 수 있다. 프로세서는 중앙 처리 장치(central processing unit, CPU), 그래픽 처리 장치 (graphics processing unit, GPU), 또는 본 개시의 실시예들에 따른 방법들이 수행되는 전용의 프로세서를 의미 할 수 있다. 메모리 및 저장 장치 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하 나로 구성될 수 있다. 예를 들어, 메모리는 읽기 전용 메모리(read only memory, ROM) 및 랜덤 액세스 메 모리(random access memory, RAM) 중에서 적어도 하나로 구성될 수 있다. 다시 도 1을 참조하면, 통신 시스템은 복수의 기지국들(base stations)(110-1, 110-2, 110-3, 120-1, 120-2), 복수의 단말들(130-1, 130-2, 130-3, 130-4, 130-5, 130-6)을 포함할 수 있다. 기지국(110-1, 110-2, 110-3, 120-1, 120-2) 및 단말(130-1, 130-2, 130-3, 130-4, 130-5, 130-6)을 포함하는 통신 시스템은 \" 액세스 네트워크\"로 지칭될 수 있다. 제1 기지국(110-1), 제2 기지국(110-2) 및 제3 기지국(110-3) 각각은 매크 로 셀(macro cell)을 형성할 수 있다. 제4 기지국(120-1) 및 제5 기지국(120-2) 각각은 스몰 셀(small cell)을 형성할 수 있다. 제1 기지국(110-1)의 셀 커버리지(cell coverage) 내에 제4 기지국(120-1), 제3 단말(130-3) 및 제4 단말(130-4)이 속할 수 있다. 제2 기지국(110-2)의 셀 커버리지 내에 제2 단말(130-2), 제4 단말(130- 4) 및 제5 단말(130-5)이 속할 수 있다. 제3 기지국(110-3)의 셀 커버리지 내에 제5 기지국(120-2), 제4 단말 (130-4), 제5 단말(130-5) 및 제6 단말(130-6)이 속할 수 있다. 제4 기지국(120-1)의 셀 커버리지 내에 제1 단 말(130-1)이 속할 수 있다. 제5 기지국(120-2)의 셀 커버리지 내에 제6 단말(130-6)이 속할 수 있다. 여기서, 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각은 노드B(NodeB), 고도화 노드B(evolved NodeB), BTS(base transceiver station), 무선 기지국(radio base station), 무선 트랜시버(radio transceiver), 액세스 포인트(access point), 액세스 노드(node), RSU(road side unit), RRH(radio remote head), TP(transmission point), TRP(transmission and reception point), eNB, gNB 등으로 지칭될 수 있다. 복수의 단말들(130-1, 130-2, 130-3, 130-4, 130-5, 130-6) 각각은 UE(user equipment), 터미널(terminal), 액 세스 터미널(access terminal), 모바일 터미널(mobile terminal), 스테이션(station), 가입자 스테이션 (subscriber station), 모바일 스테이션(mobile station), 휴대 가입자 스테이션(portable subscriber station), 노드(node), 다바이스(device), IoT(Internet of Thing) 장치, 탑재 장치(mounted module/device/terminal 또는 on board device/terminal 등) 등으로 지칭될 수 있다. 한편, 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각은 서로 다른 주파수 대역에서 동작할 수 있 고, 또는 동일한 주파수 대역에서 동작할 수 있다. 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각 은 아이디얼 백홀 링크(ideal backhaul link) 또는 논(non)-아이디얼 백홀 링크를 통해 서로 연결될 수 있고, 아이디얼 백홀 링크 또는 논-아이디얼 백홀 링크를 통해 서로 정보를 교환할 수 있다. 복수의 기지국들(110-1,110-2, 110-3, 120-1, 120-2) 각각은 아이디얼 백홀 링크 또는 논-아이디얼 백홀 링크를 통해 코어 네트워크와 연결될 수 있다. 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각은 코어 네트워크로부터 수신한 신 호를 해당 단말(130-1, 130-2, 130-3, 130-4, 130-5, 130-6)에 전송할 수 있고, 해당 단말(130-1, 130-2, 130- 3, 130-4, 130-5, 130-6)로부터 수신한 신호를 코어 네트워크에 전송할 수 있다. 또한, 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각은 MIMO 전송(예를 들어, SU(single user)- MIMO, MU(multi user)-MIMO, 대규모(massive) MIMO 등), CoMP(coordinated multipoint) 전송, CA(carrier aggregation) 전송, 비면허 대역(unlicensed band)에서 전송, 단말 간 직접 통신(device to device communication, D2D)(또는, ProSe(proximity services)) 등을 지원할 수 있다. 여기서, 복수의 단말들(130-1, 130-2, 130-3, 130-4, 130-5, 130-6) 각각은 기지국(110-1, 110-2, 110-3, 120-1, 120-2)과 대응하는 동작, 기 지국(110-1, 110-2, 110-3, 120-1, 120-2)에 의해 지원되는 동작을 수행할 수 있다. 예를 들어, 제2 기지국 (110-2)은 SU-MIMO 방식을 기반으로 신호를 제4 단말(130-4)에 전송할 수 있고, 제4 단말(130-4)은 SU-MIMO 방 식에 의해 제2 기지국(110-2)으로부터 신호를 수신할 수 있다. 또는, 제2 기지국(110-2)은 MU-MIMO 방식을 기반 으로 신호를 제4 단말(130-4) 및 제5 단말(130-5)에 전송할 수 있고, 제4 단말(130-4) 및 제5 단말(130-5) 각 각은 MU-MIMO 방식에 의해 제2 기지국(110-2)으로부터 신호를 수신할 수 있다. 제1 기지국(110-1), 제2 기지국(110-2) 및 제3 기지국(110-3) 각각은 CoMP 방식을 기반으로 신호를 제4 단말 (130-4)에 전송할 수 있고, 제4 단말(130-4)은 CoMP 방식에 의해 제1 기지국(110-1), 제2 기지국(110-2) 및 제 3 기지국(110-3)으로부터 신호를 수신할 수 있다. 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각 은 자신의 셀 커버리지 내에 속한 단말(130-1, 130-2, 130-3, 130-4, 130-5, 130-6)과 CA 방식을 기반으로 신 호를 송수신할 수 있다. 제1 기지국(110-1), 제2 기지국(110-2) 및 제3 기지국(110-3) 각각은 제4 단말(130- 4)과 제5 단말(130-5) 간의 D2D를 제어할 수 있고, 제4 단말(130-4) 및 제5 단말(130-5) 각각은 제2 기지국 (110-2) 및 제3 기지국(110-3) 각각의 제어에 의해 D2D를 수행할 수 있다. 다음으로, 통신 시스템에서 무선 인터페이스의 설정 및 관리 방법들이 설명될 것이다. 통신 노드들 중에서 제1 통신 노드에서 수행되는 방법(예를 들어, 신호의 전송 또는 수신)이 설명되는 경우에도 이에 대응하는 제2 통신 노드는 제1 통신 노드에서 수행되는 방법과 상응하는 방법(예를 들어, 신호의 수신 또는 전송)을 수행할 수 있 다. 즉, 단말의 동작이 설명된 경우에 이에 대응하는 기지국은 단말의 동작과 상응하는 동작을 수행할 수 있다. 반대로, 기지국의 동작이 설명된 경우에 이에 대응하는 단말은 기지국의 동작과 상응하는 동작을 수행할 수 있 다. 한편, 통신 시스템에서 기지국은 통신 프로토콜의 모든 기능들(예를 들어, 원격 무선 송수신 기능, 기저대역 (baseband) 처리 기능)을 수행할 수 있다. 또는, 통신 프로토콜의 모든 기능들 중에서 원격 무선 송수신 기능은 TRP(transmission reception point)(예를 들어, f(flexible)-TRP)에 의해 수행될 수 있고, 통신 프로토콜의 모 든 기능들 중에서 기저대역 처리 기능은 BBU(baseband unit) 블록에 의해 수행될 수 있다. TRP는 RRH(remote radio head), RU(radio unit), TP(transmission point) 등일 수 있다. BBU 블록은 적어도 하나의 BBU 또는 적 어도 하나의 DU(digital unit)를 포함할 수 있다. BBU 블록은 \"BBU 풀(pool)\", \"집중화된(centralized) BBU\" 등으로 지칭될 수 있다. TRP는 유선 프론트홀(fronthaul) 링크 또는 무선 프론트홀 링크를 통해 BBU 블록에 연 결될 수 있다. 백홀 링크 및 프론트홀 링크로 구성되는 통신 시스템은 다음과 같을 수 있다. 통신 프로토콜의 기능 분리(function split) 방식이 적용되는 경우, TRP는 BBU의 일부 기능 또는 MAC(medium access control)/RLC(radio link control)의 일부 기능을 선택적으로 수행할 수 있다. 6G를 구현하기 위한 기술 중 크게 주목을 받고 있는 분야는 인공 지능(artificial intelligence, AI) 및 기계 학습(machine learning, ML)이며, 3GPP에서는 Air Interface를 위한 AI/ML 기술에 대한 연구를 수행하는 것을 3GPP Rel-18에서 시작하였다. 3GPP에서 수행하는 연구의 주요 사용 예(Use case)는 아래와 같다. □ 채널 상태 정보(channel status information, CSI) 피드백 향상을 위한 AI/ML(AI/ML for CSI feedback enhancement) □ 빔 관리를 위한 AI/ML(AI/ML for beam management) □ 측위 성능 향상을 위한 AI/ML(AI/ML for positioning performance enhancement) 본 개시는 위의 사용 예들 중 CSI 피드백(feedback)에 대한 성능을 개선하기 위한 첫 번째 사용 예와 높은 관련 이 있다. 더 세부적으로, 이동 통신 네트워크에서, 송신기는 수신기로 데이터 전송을 수행하기 위하여 데이터 신호의 부호화 레벨, 전력 할당, 그리고 다중 송신 안테나를 이용한 빔포밍 등을 수행할 수 있다. 이를 위하여송신기 및 수신기의 안테나 사이의 무선 채널에 대한 정보를 송신기에서 획득해야 한다. 하지만 송신기로부터 수신기까지의 채널을 송신단에서 직접 관찰할 수 없기 때문에 수신기에서 측정한 채널 정보를 송신기로 보고하 는 절차인 CSI 보고 절차가 필요하다. CSI는 송신기에서 수신기로 데이터 전송을 스케줄링하기 위한 정보이며, 랭크(Rank), 채널 품질 인덱스(Channel Quality Index, CQI) 및 프리코딩(Precoding) 정보가 이에 해당할 수 있다. 수신기에서 채널상태를 측정하기 위하여 CSI-참조 신호(Reference Signal, RS)와 같은 참조 신호가 설계되었으 며, 송신기가 주기적 혹은 비 주기적으로 CSI-RS를 전송할 수 있다. 그리고 송신기는 수신기가 주기적 또는 비 주기적인 CSI-RS를 수신할 수 있도록 전송 관련 정보를 사전에 구성할 수 있다. 무선 통신 시스템에서는 수신기가 CSI-RS를 수신한 이후 CSI를 생성하여 이를 다시 송신기로 전달하는 CSI 보고 절차가 수행된다. 이 때, 채널 정보를 정밀하게 표현하기 위해서는 정보량이 매우 커야 하며, 이는 무선 전송 자원의 점유량 및 오버헤드를 증대시켜 시스템 성능을 감소시키는 요인이 된다. 특히, 송신기에서 프리코딩을 결정하기 위한 채널 변화를 표현하기 위한 채널 정보, 또는 적절한 프리코딩 벡터를 수신기에서 추천하기 위한 프리코딩 정보를 정밀하게 표현하는 것이 큰 오버헤드를 야기할 수 있다. 이동통신 네트워크에서 이러한 문제를 해결하기 위하여 기계 학습(machine learning, ML) 기술을 이용하여 전송 정보량을 최소화하면서도 높은 정확도로 채널 상태 정보를 송신기에서 획득할 수 있는 기술에 대해 연구가 시작 되었다. 이러한 기술을 5세대 이후 이동 통신 시스템에도 적용하기 위한 논의가 시작되고 있다. 채널 정보를 전 달하기 위한 기계 학습 구조로 오토 인코더(Auto Encoder) 기반 신경망이 제안되었다. 오토 인코더 기반 신경망 은 무선 채널 정보를 이미지 형태로 입력하여 인코더 망을 통하여 저차원 잠재공간의 코드 벡터로 압축하며, 이 를 다시 디코더 망에서 원래의 무선 채널 정보로 복원할 수 있는 컨볼루셔널 신경망(Convolutional Neural Network, CNN) 기반의 인공 신경망이 제안되었다. CNN은 효과적으로 압축 및 복원이 가능하다. 하지만, ML을 이 용하는 경우 채널 정보 전체를 전송하기 때문에 전송해야 할 정보량이 크며, 압축된 저차원의 코드 벡터가 실수 값을 가지기 때문에 실제 시스템의 수신기에서 송신기로 정보를 전달하기 위하여 양자화 과정 등이 추가 고려되 어야 한다. 이러한 문제를 해결하기 위해 양자화를 고려한 압축 송신 및 복구 과정이 제시되어 있다. 하지만, 양자화를 고려한 압축 송신 및 복구 과정은 각 양자화 방법에 따른 학습이 수행되는 경우, 해당 학습 모델은 학 습 시 고려한 양자화 방법만을 지원한다. 따라서, 실제 네트워크에서 다양한 방법의 양자화, 또는 CSI 보고 페 이로드 크기가 고려되는 경우, 각 양자화 방법 또는 CSI 보고 페이로드 크기마다 별도의 학습 모델이 필요한 단 점이 존재한다. 이러한 문제를 해소하기 위해 본 개시에서는 이동 통신 네트워크에서 기계 학습 기술을 적용하여 CSI를 보고하 는 기법에서, 단일 모델을 이용하여 서로 다른 양자화 및 페이로드 크기를 지원하기 위한 방법을 제안한다. 또 한 단일 모델을 이용하여 서로 다른 양자화 및 페이로드 크기를 지원하기 위해 양면 기계 학습 모델의 학습 및 동작 방법을 제안한다. 또한, 단일 모델을 이용하여 서로 다른 주파수 및 레이어 크기를 지원하기 위한 방법을 제안한다. 이하에서 설명되는 본 개시의 각 실시예들을 통해 위의 제안 방법들을 보다 상세히 살펴보기로 한다. 이하에서 설명되는 본 개시에서는 무선 통신 시스템의 특정한 하나의 형태인 이동 통신 시스템을 예를 들어 설 명할 것이다. 이는 이하에서 설명되는 본 개시의 이해를 돕기 위한 것일 뿐 본 개시가 이에 한정되는 것이 아니 라는 점에 유의해야 한다. 다시 말해, 무선 통신 시스템은 제1 통신 노드와 제2 통신 노드로 구성될 수 있다. 이때, 제1 통신 노드가 송신기로 동작하는 경우 제2 통신 노드는 수신기로 동작할 수 있고, 제1 통신 노드가 수 신기로 동작하는 경우 제2 통신 노드는 송신기로 동작할 수 있다. 따라서 이하에서 이동 통신 시스템의 기지국 이 송신기로 동작하는 경우 단말은 수신기로 동작할 수 있다."}
{"patent_id": "10-2023-0152938", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[1] 양자화를 고려한 인공 신경망 동작 방법 본 개시는 기지국과 단말로 구성된 이동통신 시스템에서 양면 기계 학습 모델에 기반한 CSI 피드백을 수행하는 경우를 가정한다. 이때, 기지국은 복원 인공 신경망의 입력으로 양자화되지 않은 잠재 변수(Unquantized Latent Variable)를 사용할 수 있다. 그리고 단말은 바이너리(Binary)로 표현된 CSI 보고를 기지국으로 전송할 수 있다. 따라서 기지국은 단말로부터 수신된 바이너리로 표현된 CSI 보고를 수신할 수 있다. 그리고 기지국은 CSI 보고를 역양자화하여 복원 인공 신경망으로 입력함으로써, 최종 CSI를 도출할 수 있다. 도 3은 양면 기계 학습 모델의 개념도이다. 도 3을 참조하면, 인코더과 디코더를 예시하고 있다. 인코더는 입력 데이터를 미리 결정된 부호화 방식으로 부호화할 수 있다. 그리고 부호화된 정보는 잠재 변수로 출력될 수 있다. 잠재 변수(30 2)는 디코더의 입력이 될 수 있다. 디코더는 잠재 변수를 디코딩하고, 그 결과로 출력 데이터 를 출력할 수 있다. 무선 통신 시스템 예컨대, 5G NR 시스템은 도 3에서 설명한 양면 기계 학습 모델을 적용할 수 있다. 5G NR 시스 템 또는 향후 서비스를 제공할 6G 시스템의 기지국과 단말에 도 3의 양면 기계 학습 모델을 적용할 수 있다. 본 개시에서는 CSI 피드백을 위한 방법에 대해서 설명할 것이므로, 이하에서는 무선 통신 시스템에서 CSI 피드 백을 위한 양면 기계 학습 모델에 대해 설명하기로 한다. 도 3에 예시한 양면 기계 학습 모델은 기지국과 단말 각각에서 학습될 수 있다. 또는 기지국만 양면 기계 학습 모델을 학습할 수도 있다. 반대로 단말만 양면 기계 학습 모델을 학습할 수 있다. 또 다른 예로, 양면 기계 학 습 모델은 네트워크 상의 특정 서버에서 학습될 수도 있다. 만일 기지국만 양면 기계 학습 모델을 탑재한 경우, 기지국은 압축 인공 신경망을 단말로 전송할 수 있다. 만일 단말에만 양면 기계 학습 모델을 탑재한 경우, 단말은 복원 인공 신경망을 기지국으로 전송할 수도 있다. 만일 네트워크 상의 특정 서버에 양면 기계 학습 모델이 탑재된 경우, 서버는 압축 인공 신경망을 단말로 전송 하고, 복원 인공 신경망을 기지국으로 전송할 수도 있다. 도 4a는 단일 주파수 단위의 채널 정보의 개념도이고, 도 4b는 단일 주파수 단위의 프리코딩 벡터의 개념도이며, 도 4c는 다중 주파수 단위의 프리코딩 벡터의 개념도이다. 도 4a에서 가로 축은 수신 안테나를 의미하고, 세로 축은 송신 안테나를 의미한다. 도 4a는 단일 주파수에서 채 널 정보를 예시한 경우로, 송신 안테나 수와 수신 안테나 수에 채널 정보가 비례하여 증가함을 예시 한 도면이 될 수 있다. 도 4b에서 가로 축은 계층(Layer)을 의미하고, 세로 축은 송신 안테나를 의미한다. 도 4b는 송신 안테나의 수에 비례하여 각 계층들에 대한 프리코딩 벡터 정보(421, 422, 423, 424)가 비례하여 증가함을 예시한 도면이 될 수 있다. 도 4c에서 가로 축은 계층(Layer)을 의미하고, 세로 축은 서브밴드를 의미한다. 도 4c는 다중 주파수 다시 말해, 각 서브밴드가 증가할수록 각 계층들에 대한 프리코딩 벡터 정보(421, 422, 423, 424)가 비례하여 증가함 을 예시한 도면이 될 수 있다. 한편, 단말에서 실행되는 압축 인공 신경망의 입력은 채널 정보 또는 프리코딩 행렬 정보 등일 수 있다. 채널 정보, 또는 프리코딩 행렬을 입력으로 하는 경우, 입력 정보는 도 4a 및 도 4b에 예시한 바와 같이 전체 주파수 에 대한 정보일 수 있다. 다른 예로, 채널 정보, 또는 프리코딩 행렬을 입력으로 하는 경우, 입력 정보는 도 4c에 예시한 바와 같이 각 단위 주파수에 대한 정보일 수 있다. 단위 주파수의 예는 복수 개의 자원 블록(Resource Block, RB)으로 구성되 는 서브밴드(Subband)일 수 있다. 단위 주파수 입력을 지원하는 압축 인공 신경망이 적용되는 경우, 전체 주파 수에 대한 정보를 압축하기 위하여, 단위 주파수 입력을 반복 수행함으로써, 전체 주파수에 대한 압축을 수행할 수 있다. 만일, 입력 정보가 프리코딩 정보인 경우, 입력 정보는 전체 레이어에 대한 정보이거나 또는 각 개별 계층에 대 한 정보일 수 있다. 이때, 개별 레이어에 대한 프리코딩 정보를 압축하는 인공 신경망이 적용된 경우, 복수 개 의 레이어로 구성되는 전체 프리코딩 행렬을 압축하기 위하여, 개별 레이어로 구성되는 입력을 반복 수행하여, 전체 레이어들에 대한 압축을 수행할 수 있다. 도 5는 기지국에서 CSI 도출 절차를 예시한 개념도이다. 도 5를 참조하기에 앞서 CSI 피드백 정보가 기지국으로 전송되는 절차에 대해 다시 한 번 정리하기로 한다. 먼 저 기지국은 미리 설정된 주기 또는 비주기적으로 CSI-RS를 단말로 송신할 수 있다. 따라서 단말은 기지국이 송 신한 CSI-RS를 수신 및 측정할 수 있다. 그리고 단말은 측정된 CSI-RS에 기초하여 CSI 피드백 정보를 기지국으 로 피드백할 수 있다. 이때, 단말이 송신하는 CSI 피드백 정보는 바이너리 형태의 정보가 될 수 있다. 도 5에 예시된 구성은 기지국에 포함되는 CSI 피드백 정보의 디코딩 절차를 설명하기 위한 일부 예의 구성이 될 수 있다. 도 5를 참조하면, 기지국은 역 양자화기와 디코더를 포함할 수 있다. 역 양자화기는CSI 피드백 정보를 수신할 수 있다. 앞서 설명한 바와 같이 CSI 피드백 정보는 바이너리 형태의 CSI 피드백 데이터가 될 수 있다. 역 양자화기는 CSI 피드백 정보를 역 양자화하여 잠재 변수를 생 성하여 출력할 수 있다. 이때, 잠재 변수는 역 양자화기에서 역 양자화가 이루어진 상태이므로, 양자화되 지 않은(unquantized) 상태의 데이터가 될 수 있다. 잠재 변수는 디코더로 입력될 수 있다. 디코더 는 본 개시에 따른 복원 인공 신경망이 될 수 있다. 따라서 디코더는 잠재 변수 형태로 표현된 CSI 피드백 정보를 디코딩하여 출력 CSI 피드백 정보를 출력할 수 있다. 이때 출력 CSI 피드백 정보는 랭크 정 보, 채널 품질 인덱스(CQI) 및 프리코딩 정보를 포함할 수 있다. 이상에서 설명된 동작을 위해 본 개시에서는 기지국이 단말로 CSI 피드백 정보를 요청할 때, 단말의 인코더 의 동작을 수행하는 압축 인공 신경망의 출력 방법을 지시할 수 있다. 다시 말해 기지국은 단말의 압축 인 공 신경망의 출력 시 출력 잠재 변수의 양자화 방법을 지시할 수 있다. 기지국은 압축 인공 신경망의 출력 잠재 변수의 양자화 방법을 지시하기 위한 양자화 구성 정보를 미리 단말로 전송할 수 있다. 양자화 구성 정보에 포함된 양자화 방법이 둘 이상인 경우 양자화 구성 정보는 양자화 방법 각각에 대응하는 참조 번호 또는 양자화 방법 각각에 대응하여 매핑된 인덱스를 양자화 구성 정보에 포함시켜 전송할 수 있다. 만일 양자화 구성 방법이 4가지인 경우를 가정하면, 아래 표 1과 같은 형태가 될 수 있다. 표 1 인덱스(또는 참조 번호) 양자화 방법/ 양자화 방법에서 필요 정보 00 양자화 방법 #1/ 양자화 방법 #1의 수행 시 필요 정보 01 양자화 방법 #2/ 양자화 방법 #1의 수행 시 필요 정보 10 양자화 방법 #3/ 양자화 방법 #3의 수행 시 필요 정보 11 양자화 방법 #4/ 양자화 방법 #4의 수행 시 필요 정보 기지국은 단말로 표 1에 예시한 바와 같은 양자화 구성 정보를 미리 전송할 수 있다. 그리고 기지국은 단말로 제공한 양자화 구성 정보에 기초하여 특정한 양자화 방법이 사용되어야 할 때, 인덱스 또는 참조 번호를 단말로 전송함으로써 양자화 방법을 지시할 수 있다. 본 개시의 일 실시예에 따르면, 양면 기계 학습 모델의 학습을 기지국에서 수행한 경우를 가정할 수 있다. 기지 국에서 기계 학습 모델의 학습을 수행할 때, 입력 데이터 세트에 대한 잠재 변수 분포를 알 수 있다. 따라서 기 지국은 입력 데이터 세트에 대한 잠재 변수 분포를 이용하여 양자화를 위한 구성 정보를 도출할 수 있다. 예를 들어, 양자화 구성 정보에 포함되는 양자화 방법들은 벡터 양자화가 적용되기 위한 코드북 정보일 수 있다. 다른 예로, 양자화 구성 정보에 포함되는 양자화 방법들은 비균등 스칼라 양자화를 적용하기 위한 결정 경계 및 표현값 정보일 수 있다. 본 개시의 일 실시예에 따라, 양면 기계 학습 모델의 학습을 기지국에서 수행한 경우, 기지국은 단말로 학습된 압축 인공 신경망을 사전에 단말로 전송할 수 있다. 이때, 학습에 기초한 양자화 구성 정보를 함께 또는 추가적 으로 단말로 전송할 수 있다. 이에 기초하여 단말이 수행할 수 있는 양자화는 다음 중 한 가지일 수 있다. □ 벡터 양자화 구성 □ 스칼라 양자화 구성 단말이 벡터 양자화를 수행하는 경우, 모든 이진 CSI 피드백 정보 보고에 대응하는 잠재 변수로 구성되는 코드 북 정보가 필요하다. 스칼라 양자화 방법은 균등 스칼라 양자화 방법과 비균등 스칼라 양자화 방법으로 구분될 수 있다. 스칼라 양자 화 방법은 잠재 변수 차원 별 양자화 비트 수가 양자화 방법의 정보에 포함될 수 있다. 스칼라 양자화 방법 중 균등 스칼라 양자화 방법이 사용되는 경우, 양자화 방법의 정보는 최소 값 및 최대 값 정보를 포함할 수 있다. 스칼라 양자화 방법 중 비균등 스칼라 양자화 방법이 사용되는 경우, 양자화 방법의 정 보는 양자화를 위한 결정 경계 및 표현값 정보가 포함될 수 있다. 스칼라 양자화의 경우, 모든 잠재변수 차원에 대하여 동일한 크기의 양자화를 수행할 수도 있고, 또는 각 차원 에 대하여 다르게 구성되는 양자화를 수행할 수도 있다. 도 6은 CSI 피드백 정보 요청에 기초하여 양자화된 CSI 피드백 정보 보고 메시지 전송 및 CSI 피드백 정보 획득 절차를 예시한 순서도이다. 도 6을 참조하면, 기지국과 단말을 예시하였다. 기지국과 단말 각각은 앞서 도 2에서 설명 한 구성 요소 전부 또는 일부를 포함할 수 있다. 또한 도 6에서는 이동 통신 시스템을 하나의 실시예로써 설명 하기 위해 기지국과 단말를 예시하였음에 유의해야 한다. 다시 말해, 앞서 설명한 바와 같이 기지국 과 단말 각각은 다양한 형태의 무선 통신 시스템에서 제1 통신 노드와 제2 통신 노드로 대체되어 이 해될 수 있다. 한편, 도 6에서는 CSI 측정을 위한 CSI-RS가 전송되는 절차는 생략되어 있음에 유의해야 한다. S600단계에서 기지국은 CSI 피드백 정보 요청 메시지를 단말로 전송할 수 있다. 일반적으로 CSI 피드 백 정보 요청 메시지는 단말에게 CSI-RS를 측정하고, 측정 결과를 요청하는 메시지가 될 수 있다. 본 개시 에 따른 CSI 피드백 정보 요청 메시지는 위의 표 1에서 설명한 바와 같이 양자화 방법 정보를 포함할 수 있다. 양자화 방법은 위에서 설명한 바와 같이 벡터 양자화 구성 또는 다양한 형태의 스칼라 양자화 구성 중 하나가 될 수 있으며, 표 1 및 그 아래에서 설명한 바와 같이 해당 양자화 방법의 수행 시 필요한 정보를 포함할 수 있 다. 해당 양자화 방법 수행 시 필요한 정보로 벡터 양자화의 경우 벡터 양자화를 위한 코드북이 될 수 있다. 또 한 CSI 피드백 정보 요청 메시지는 표 1에서 설명한 바와 같이 인덱스 또는 참조 번호를 통해 해당 양자화 방법 및 양자화 방법의 수행 시 필요한 정보를 지시할 수 있다. 표 1과 같은 양자화 구성 정보는 앞서 설명한 바와 같이 기지국에 의해 미리 단말로 미리 전송될 수 있다. S600단계는 도 3에서 설명한 잠재 변수 의 양자화 방법 및 양자화 방법 수행 시 필요한 정보의 생성을 단말에게 지시하는 절차가 될 수 있다. 따라서 S600단계에서 단말은 위의 정보를 포함하는 CSI 요청 메시지를 수신할 수 있다. S602단계에서 단말은 단말 측 AI 모델 및/또는 ML 모델을 이용하여 CSI 압축을 수행할 수 있다. CSI 피드 백 정보의 압축을 위한 AI 및/또는 ML 모델은 앞서 도 3에서 설명한 인코더에 대응할 수 있다. S604단계에서 단말은 CSI 피드백 정보의 압축을 위한 AI 및/또는 ML 모델에 필요한 방식에 기초하여 양자 화를 수행할 수 있다. 여기서 양자화 방법은 CSI 피드백 정보 요청 메시지에 포함된 인덱스 또는 참조 번호에 기초하여 결정될 수 있다. 다시 말해 S604단계는 표 1에서 설명한 양자화 방법에 기초하여 양자화를 수행하고, 양자화 방법 수행 시 필요한 정보를 생성하는 절차가 될 수 있다. 예를 들어, 기지국이 CSI 피드백 정보 요청 메시지에 양자화 방법 지시를 통해 N 차원의 잠재 변수를 M 비트 길이의 벡터 양자화를 요청한 경우, 단말은 사전에 기지국으로부터 수신된 코드북을 이용하여 잠재 변수를 M 비트 길이의 CSI 피드백 정보 보고 메시지로 변환할 수 있다. 다른 예로, 기지국이 CSI 피드백 정보 요청 메시지에 양자화 방법 지시를 통해 N 차원의 잠재 변수를 각 차원 별 D 비트의 균등 양자화를 요청한 경우, 단말은 잠재 변수의 각 차원 값을 D 비트로 양자화 하고, N*D 비트의 전체 차원 정보를 CSI 피드백 정보 보고 메시지로 변환할 수 있다. S606단계에서 단말은 CSI 피드백 정보 보고 메시지를 기지국으로 전송할 수 있다. 앞서 CSI 피드백 정보 보고 메시지는 CSI-RS의 수신에 대응하여 CSI 피드백 정보 보고 메시지를 전송하는 시점에 전송될 수 있다. 또한 CSI 피드백 정보 보고 메시지는 바이너리 CSI 피드백이 될 수 있다. 따라서 기지국은 CSI 피드백 정보 보고 메시지를 단말로부터 수신할 수 있다. S608단계에서 기지국은 CSI 보고 메시지에 포함된 바이너리 CSI 피드백 정보를 역 양자화할 수 있다. 이때, 역 양자화는 기지국이 CSI 피드백 정보 요청 메시지에서 지시된 방법에 기초하여 역 양자화를 수행 할 수 있다. 이러한 역 양자화 절차는 도 5에서 설명한 역 양자화기에 의해 수행될 수 있다. S610단계에서 기지국은 기지국의 AI 및/또는 ML 모델을 이용하여 CSI를 복원할 수 있다. 이상에서는 기지국에서 양면 모델을 학습하여 양자화 사전 정보를 단말로 전송하는 경우에 대해 설명하였다. 또 한 도 6에서는 이러한 사전 정보에 기초하여 기지국이 특정한 양자화 방법으로 CSI 보고를 요청하고, 단말에서 해당하는 양자화 방법에 기초한 CSI를 보고하는 절차에 대해 설명하였다. 본 개시의 다른 실시예에 따르면, 단말 또는 단말 측의 서버가 CSI 압축 모델에 대한 양자화 구성 정보를 기지 국으로 사전에 전달할 수도 있다. 여기서 단말 측의 서버는 단말의 학습 동작을 대신 수행하는 서버로, 단말에 직접 연결되거나 또는 네트워크 상에서 단말 대신 CSI 압축 모델에 대한 양자화 학습을 위한 구성 정보를 생성 할 수 있는 서버가 될 수 있다. 이하에서는 설명의 편의를 위해 단말에서 학습 동작이 이루어지는 경우를 가정 하여 설명할 것이다. 하지만, 단말 대신 단말 측 서버가 단말에서 수행하는 학습을 대신 수행하는 것으로 대체 하여 이해될 수 있음은 당업자에게 자명할 것이다. 단말은 CSI 압축 모델에 대한 양자화 구성 정보를 생성하여 기지국으로 전송할 수 있다. 해당 정보는 CSI 압축 모델의 부가정보 형태로 전송될 수 있으며, 또는 별도의 제어 시그널링 (예를 들어, 단말의 능력정보 등 RRC Signaling)을 통하여 전송될 수 있다. 따라서 기지국은 단말이 제공한 CSI 피드백 정보 압축 모델에 대한 양자 화 구성 정보를 저장할 수 있다. 이후 CSI 피드백 정보 요청 절차 시, 단말이 제공한 CSI 피드백 정보 압축 모 델에 대한 양자화 구성 정보에 기초하여 CSI 피드백 정보 요청을 수행할 수 있다. 이때에도 앞서 표 1에서 설명 한 바와 같이 단말은 양자화 구성 정보를 인덱스 또는 참조 번호를 통하여 구분할 수 있다. 따라서, 기지국은 CSI 피드백 정보 보고 요청 시 양자화 구성 정보를 인덱스 또는 참조 번호를 이용하여 지정할 수 있다. 도 7은 단말에서 양면 모델 학습을 수행하고 기지국 측 모델을 전송하여 CSI 피드백 정보 요청이 이루어지는 절 차를 예시한 순서도이다. 도 7을 참조하면, 기지국과 단말을 예시하였으며, 기지국과 단말 각각은 앞서 도 6에서 설 명한 바와 동일한 구성을 포함할 수 있다. 따라서 중복 설명은 생략하기로 한다. S700단계에서 단말은 양면 모델 학습을 수행할 수 있다. 단말은 양면 모델 학습을 수행할 때, 입력 데이터 세트에 대한 잠재 변수 분포를 알 수 있다. 따라서 단말은 잠재 변수 분포를 이용하여 양자화를 위 한 양자화 구성 정보를 도출할 수 있다. 양자화 구성 정보의 예는 벡터 양자화가 적용되기 위한 코드북 정보일 수 있으며, 또는 비균등 스칼라 양자화를 적용하기 위한 결정 경계 및 표현값 정보일 수 있다. 다시 말해 앞서 표 1에서 설명한 내용의 정보들이 될 수 있다. 따라서 단말은 이에 대한 정보를 표 1과 같은 형태로 구성 할 수 있다. S702단계에서 단말은 양면 모델 학습에 기초한 기지국 측 AI 및/또는 ML 모델 데이터를 기지국으로 전송할 수 있다. 따라서 기지국은 S702단계에서 단말로부터 양면 모델 학습에 기초한 기지국 측 AI 및/또는 ML 모델 데이터를 수신할 수 있다. S704단계에서 단말은 S700단계에서 생성한 양자화 구성 정보를 기지국으로 전송할 수 있다. 따라서 기지국은 단말로부터 양자화 구성 정보를 수신할 수 있다. S706단계에서 기지국은 CSI 피드백 정보 요청 메시지를 단말로 전송할 수 있다. 이때, CSI 피드백 정 보 요청 메시지는 앞서 도 6의 S600단계에서 설명한 메시지와 동일한 메시지가 될 수 있다. 다만 양자화 구성 정보를 이용한 지시가 S704단계에서 수신된 양자화 구성 정보에 기초하여 지시한다는 점에서 차이가 있을 뿐이 다. 이후 절차는 앞서 도 6에서 설명한 바와 동일하므로, 도 7에서는 생략되었음에 유의해야 한다. 한편, 단말 측 서버에서 위의 동작이 이루어지는 경우 S700단계 내지 S704단계는 단말 측 서버에서 수행될 수 있다. 이후 S710단계 이후는 단말과 기지국 간에 수행되는 동작이 될 수 있다. 뿐만 아니라 단말 측 서버는 단말 측 AI 및/또는 ML 모델을 단말에게 전송해야 하며, 양자화 구성 정보 또한 단말로 전송 해야 한다는 추가 절차가 필요할 수 있다. 다만, 단말이 미리 단말 측 AI 및/또는 ML 모델과 양자화 구성 정보를 가지고 있는 경우라면, 단말 측 서버가 단말로 해당 정보들을 전송하는 절차가 생략될 수 있다. 한편, 본 개시에서는 단말의 압축 인공 신경망 출력 값의 범위를 특정 범위 로 한정할 수 있다. 이때 특정 범위 를 예를 들면, 0 이상 1 이하의 값으로 한정할 수 있다. 이처럼 단말의 압축 인공 신경망의 출력 값 범위를 특 정 범위로 한정하는 경우에 대해 살펴보기로 한다. 본 개시의 일 실시예에 따르면, 기지국은 스칼라 양자화의 균등 양자화 방법을 구성할 때, 각 차원 별 양자화 비트 수 또는 CSI 피드백 정보 보고의 크기 정보만을 이용하여 양자화 정보를 구성할 수 있다. 이때, 인공 신경 망 출력 값의 범위를 한정하는 방법은 아래의 방법 중 하나를 적용할 수 있다. □ 출력 노드의 활성 함수로 시그모이드 함수(Sigmoid function)를 적용 □ 출력 노드의 값을 누적 분포 함수(Cumulative distribution function, CDF)를 적용한 값으로 변환 만약, 출력 노드의 값을 CDF를 적용한 값으로 변환하는 방법을 적용하는 경우, 각 차원 별 분포 정보 또는 분포 정보의 가우시안 근사를 위한 평균 및 분산 정보를 포함한 양자화 구성 정보가 단말로 전달되거나, 또는 단말에 서 기지국으로 전달되어야 한다. 도 8a는 압축 인공 신경망 출력 값의 범위를 한정하기 위한 시그모이드 함수의 일 예로, 하이퍼 탄젠트 함수의 그래프를 예시한 도면이고, 도 8b는 압축 인공 신경망 출력 값의 범위를 한정하기 위한 누적 분포 함수(CDF)의 그래프를 예시한 도면이다. 도 8a를 참조하면, 하이퍼 탄젠트 함수는 x 값이 0 이상인 경우 하이퍼 탄젠트(tanh) 함수 값은 \"0\"에서 \"1\" 사 이의 값을 갖는다. 다만, x 값이 음수인 경우 하이퍼 탄젠트(tanh) 함수 값은 \"0\"에서 \"-1\" 사이의 값을 갖는다. 도 8b를의 누적 분포 함수(CDF)는 양수 값에 대해 도 8a의 하이퍼 탄젠트 함수와 유사한 형태를 취하고 있음을 알 수 있다. 본 개시의 일 실시예에 따르면, 기지국에서 양면 기계 학습 모델을 학습하고, 출력 노드의 값을 도 8b에 예시한 CDF를 적용하는 경우를 가정할 수 있다. 이때, 기지국은 학습한 압축 인공 신경망 및 잠재 변수의 분포 정보를 단말로 전달할 수 있다. 이러한 정보를 전달한 후 기지국은, 단말로 CSI 피드백 정보 보고를 요청할 수 있다. 이때, 기지국은 단말로 차원 별 양자화 비트 수 정보만을 이용하여 양자화 정보를 구성하도록 지시할 수 있다. 예를 들어, 기지국은 단말로 N 차원의 잠재 변수를 모두 D 비트로 양자화 하는 것을 요청할 수 있다. 이를 수신 한 단말은 압축 인공 신경망의 출력 값을 CDF를 적용하여 0과 1사이의 값으로 변환할 수 있다. 그리고 단말은 CDF를 적용하여 변환한 값을 D 비트로 양자화할 수 있다. 그리고 단말은 전체 자원 정보를 N*D 비트를 갖는 CSI 피드백 정보 보고 메시지를 생성하고, CSI 피드백 정보 보고 메시지를 기지국으로 전송할 수 있다. 기지국은 단말이 전송한 CSI 피드백 정보 보고 메시지를 수신할 수 있다. 기지국은 수신한 CSI 피드백 정보 보 고 메시지로부터 CSI 피드백 정보를 획득할 수 있다. 기지국은 CSI 피드백 정보를 각 차원 별로 역양자화를 수 행할 수 있다. 또한 기지국은 각 차원 별로 역 양자화된 값을 다시 역 CDF를 적용하여 잠재 변수를 복원할 수 있다. 그리고 기지국은 복원된 잠재 변수를 복원 인공 신경망으로 입력하여 최종 CSI를 획득(또는 복원)할 수 있다. 본 발명의 다른 실시예에 따르면, 기지국은 출력 노드의 값을 하이퍼탄젠트 (tanh) 활성화 함수를 이용하여 범 위를 한정하는 경우를 가정할 수 있다. 이때, 기지국이 단말로 CSI 보고 요청 시, 전체 CSI 보고의 페이로드 크 기 M을 지정할 수 있다. 예를 들어, 잠재 변수의 차원이 N일 때, CSI 보고의 페이로드 크기 M을 요청하는 경우, 단말은 아래의 수학식에 따라 각 차원 별 양자화 비트 수를 도출할 수 있다. 수학식 1"}
{"patent_id": "10-2023-0152938", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "단말은 출력 노드의 값에 하이퍼탄젠트 (tanh) 함수를 적용하여 범위를 한정한 후, 각 차원 별 도출한 양자화 비트 수(d_i)를 이용하여 차원 정보를 양자화하여 전체 길이 M의 CSI 보고를 생성할 수 있다. 그리고 단말은 생 성된 전체 길이 M의 CSI 보고 정보를 포함하는 CSI 보고 메시지를 기지국으로 전송할 수 있다. 따라서 기지국은 CSI 보고 메시지를 수신하고, 수신된 CSI 보고 메시지에 포함된 전체 길이 M의 CSI 보고 정보를 획득할 수 있다. 기지국은 전체 길이 M의 CSI 보고 정보를 단말이 도출한 각 차원 별 양자화 비트 수를 이용하여 역 양자화를 수 행할 수 있다. 그리고 역 양자화한 값을 다시 하이퍼탄젠트(tanh) 함수의 역함수인 탄젠트(tan) 함수를 적용하 여 잠재 변수를 복원할 수 있다. 잠재 변수 복원이 완료되면 기지국은 복원된 잠재 변수를 복원 인공 신경망으 로 입력하여 최종 CSI를 획득(또는 복원)할 수 있다. 범위를 한정한 함수의 역함수(예를 들면, 하이퍼탄젠트 함 수의 역함수인 탄젠트 함수)를 적용하여 잠재변수를 복원하는 것은 수행되지 않을 수도 있다.[2] 다양한 서브밴드 및 레이어 개수를 지원하기 위한 방법 본 개시의 일 실시예에 따르면, 기지국과 단말로 구성된 이동통신 시스템에서 AI 모델 및/또는 ML 모델에 기반 하여 채널 상태 정보(CSI)를 피드백할 때, 복수 개의 서브밴드 및 복수 개의 레이어에 대한 피드백을 수행할 수 있다. 이때 기지국은 단말로 CSI 피드백 정보 보고 요청 시, 인공 신경망의 입력 단위를 다음 중 어느 한 가지 로 지정할 수 있다. □ 개별 서브밴드, 개별 레이어 □ 전체 서브밴드, 개별 레이어 □ 개별 서브밴드, 전체 레이어 □ 전체 서브밴드, 전체 레이어 만약, 단말에 구성되어 활성화되어 있는 인공 신경망이 하나인 경우 또는 인공 신경망의 입력 단위가 하나만 지 원을 하는 것이 명확한 경우, 입력 단위에 대한 지정이 생략될 수 있다. 도 9a는 단말 측 인코더의 입력이 전체 서브밴드 단위인 경우 입력 및 출력을 예시한 개념도이고, 도 9b는 단말 측 인코더의 입력이 개별 서브밴드 단위인 경우 입력 및 출력을 예시한 개념도이다. 도 9a를 참조하면, 전체 서브밴드에서 측정된 CSI 피브백 정보 모두가 한 번에 인코더로 입력되는 경 우를 예시하고 있다. 예를 들어, 전체 서브밴드는 n개의 서브밴드들로 구성되는 경우 n개의 서브밴드들에 대해 측정된 CSI 피드백 정보가 인코더로 입력될 수 있다. 여기서 인코더는 도 3에 예시한 인코더 에 대응할 수 있다. 다시 말해, 단말에 구비되는 인코더가 될 수 있다. 인코더는 미리 결정된 방식으 로 서브밴드들에 대해 측정된 CSI 피드백 정보를 인코딩하여 잠재 변수를 출력할 수 있다. 이때 출력되는 잠재 변수는 도 3에서 설명한 잠재 변수에 대응할 수 있다. 또한 모든 서브채널에 대한 CSI 피 드백 정보가 인코딩되어 있으므로, 잠재 변수는 단말이 기지국으로 전송하는 CSI 피드백 정보에 대응할 수 있다. 도 9b를 참조하면, 인코더는 한 번에 모든 서브밴드의 값을 인코딩할 수 없는 인코더가 될 수 있다. 따라 서 인코더의 입력은 각 서브밴드마다 개별적으로 입력될 수 있다. 인코더는 앞서 도 3에서 설명한 인 코더의 일부 구성이 될 수 있다. 앞서 도 9a의 예와 동일하게 전체 서브밴드가 n개의 서브밴드들로 구성되는 경우 n개의 서브밴드들 각각은 인코더의 개별적인 입력이 될 수 있다. 따라서 서브밴드 #1에 대해 측정된 CSI 값이 입력될 시 인코더 는 미리 결정된 인코딩 방식에 기초하여 잠재 변수 #1을 출력할 수 있다. 서브밴드 #2에 대해 측정된 CSI 값이 입력될 시 인코더는 미리 결정된 인코딩 방식에 기초하여 잠재 변수 #2를 출력할 수 있다. 동일한 방 식으로 서브밴드 #n에 대해 측정된 CSI 값이 입력될 시 인코더는 미리 결정된 인코딩 방식에 기초하여 잠 재 변수 #n를 출력할 수 있다. 다시 말해 인코더는 각 서브밴드 별 잠재 변수들을 출력할 수 있다. 따라서 각 잠재변수들을 모두 결합(aggregation)하는 절차를 통해 CSI 피드백 정보를 생성할 수 있다. 도 10은 기지국에서 CSI 피드백 정보에 기초하여 각 서브채널 별 CSI를 도출하는 절차를 예시한 개념도이다. 도 10은 앞서 설명한 도 9b와 같이 각 서브채널 별로 구성된 CSI 피드백 정보를 수신하기 위한 기지국의 구성 및/또는 절차가 될 수 있다. 도 10을 참조하면, 수신된 CSI 피드백 정보는 도 9b에서 설명한 바와 같이 각 서브밴드 별로 잠재 변수들 이 결합된 형태가 될 수 있다. 따라서 CSI 피드백 정보는 분해기로 입력될 수 있다. 분해기는 각 서브밴드 별로 잠재 변수가 결합된 CSI 피드백 정보를 각 서브채널에 대응하는 잠재 변수들로 분리 (decomposition)할 수 있다. 다시 말해, 서브채널 #1에 대응하는 잠재 변수 #1, 서브채널 #2에 대응하는 잠재 변수 #2, …, 서브채널 #n에 대응하는 잠재 변수 #n으로 분해할 수 있다. 이처럼 분리된 잠재변수들은 디코더 로 입력될 수 있다. 여기서 디코더는 앞서 도 3에서 설명한 디코더에 대응할 수 있다. 디코더 는 각 잠재변수들을 각 서브채널에 대응하는 CSI 피드백 정보로 디코딩하여 출력할 수 있다. 본 개시의 일 실시예에 따르면, N개의 서브밴드 및 L개의 레이어에 대한 피드백이 요구될 때, 기지국은 개별 서 브밴드 및 개별 레이어 단위의 입력 단위를 지정할 수 있다. 이 경우, 단말은 압축 인공 신경망에 개별 서브밴드 및 개별 레이어 단위의 채널 정보 또는 프리코딩 행렬을 입력할 수 있다. 따라서 개별 서브밴드 및 개별 레 이어 단위의 채널 정보 또는 프리코딩 행렬에 대응하는 잠재 변수를 획득할 수 있다. 그리고 단말은 모든 개별 서브밴드 및 개별 레이어에 대한 잠재 변수를 획득한 경우 이들을 결합한 N*L개의 보고 단위인 CSI 피드백 정보 를 획득할 수 있다. CSI 피드백 정보는 CSI 피드백 보고 메시지에 포함되어 단말에 의해 기지국으로 전송될 수 있다. 따라서 기지국은 CSI 피드백 보고 메시지에 포함된 CSI 피드백 정보를 획득함으로써, 전체 CSI 피드백 정보를 수신할 수 있다. 이때, CSI 피드백 정보는 위에서 설명한 바와 같이 개별 서브밴드 및 개별 레이어가 결합된 형 태이므로, 개별 CSI 피드백 정보로 분리할 수 있다. 다시 말해 개별 서브밴드 및 개별 레이어에 대한 잠재 변수 들을 획득할 수 있다. 그리고 획득된 잠재 변수들을 복원 인공 신경망을 이용하여 개별 CSI 피드백 정보를 복원 (또는 획득)할 수 있다. 개별 CSI 피드백 정보 전체를 취합함으로써 기지국은 전체 CSI 피드백 정보를 구성할 수 있다. 도 11은 서브밴드 및 계층의 공통 정보를 설명하기 위한 개념도이다. 도 11을 참조하면, 가로 축은 계층을 의미하고, 세로 축은 서브밴드들을 예시하였다. 단말과 기지국 간에 통신 은 계층 및 서브밴드에 대응하는 자원을 이용하여 이루어질 수 있다. 기지국은 자원에 대한 CSI 피 드백 정보를 요청할 수 있고, 단말은 자원에 대한 CSI 피드백 정보를 기지국으로 보고할 수 있다. 본 개시의 일 실시예에 따르면, 기지국은 단말에게 전체 서브밴드의 공통 정보를 별도로 요청할 수 있다. 기지국의 요청에 응답하여, 단말은 해당 공통 정보 및 각 개별 CSI 피드백 정보를 별도로 생성하여 기지 국으로 전달할 수 있다. 이때, 전체 서브밴드의 공통 정보는 모든 서브밴드의 채널 정보의 평균값일 수 있다. 따라서 개별 서브밴드 정보는 전체 서브밴드의 공통 정보에서 개별 서브밴드의 채널 정보의 차로 표현될 수 있다. 동일한 방식으로 기지국은 단말에게 전체 계층의 공통 정보를 별도로 요청할 수 있다. 기지국의 요청에 응답하여, 단말은 해당 공통 정보 및 각 개별 CSI 피드백 정보를 별도로 생성하여 기지국으로 전달할 수 있다. 이때, 전체 계층의 공통 정보는 모든 프리코딩 행렬의 평균값일 수 있다. 따라서 개별 계층 정보는 전체 계층 공통 정보에서 개별 계층 정보의 차로 표현될 수 있다. 기지국은 수신한 공통 정보(1120, 1130) 및 각 개별 CSI를 복원한 후, 이를 이용하여 각 서브밴드 및 각 레이어 의 CSI 피드백 정보를 복원할 수 있다. 다시 말해, 기지국은 단말이 보고한 전체 계층 공통 정보, 전체 서브채널 공통 정보 및 개별 CSI 피드백 정보를 이용하여 개별 CSI 피드백 정보를 복원할 수 있다. 그리 고 개별 CSI 피드백 정보를 이용하여 전체 서브밴드의 CSI 피드백 정보로 복원(또는 획득)할 수 있다. 본 개시의 다른 실시예에 따르면, 기지국에서 복원한 단위 CSI 피드백 정보를 입력으로 하는 추가 복원 인공 신 경망을 이용하여, 전체 서브밴드 및 전체 레이어의 최종 CSI를 획득할 수 있다. 도 12는 기지국에서 추가 복원 인공 신경망을 이용한 최종 CSI 피드백 정보 복원 절차를 수행하기 위한 모델의 개념도이다. 도 12를 참조하면, 수신된 CSI 피드백 정보는 도 11에서 설명한 전체 계층의 공통 정보 및/또는 전 체 서브밴드의 공통 정보와 각 서브밴드 별로 잠재 변수가 결합된 형태가 될 수 있다. CSI 피드백 정보는 분해기에서 각 서브밴드 별로 잠재 변수를 구분하여 출력할 수 있다. 이때, 전체 계층의 공통 정보 및/또는 전체 서브밴드의 공통 정보도 각각에 대응하여 함께 분리될 수 있다. 이는 도 10에서 설명한 바 와 다른 형태가 될 수 있다. 만일 전체 서브밴드의 공통 정보가 개별 서브밴드 정보와 함께 전송된 경우 잠재 변수 #1 또는 잠재 변수 #n의 경우 전체 서브밴드의 공통 정보가 될 수 있다. 다른 예로, 전체 계층 공통 정보가 개별 계층 정보와 함께 전송된 경우 잠재 변수 #1 또는 잠재 변수 #n 의 경우 전체 계층 공통 정보가 될 수 있다. 만약, 전체 계층 공통 정보와 전체 서브밴드의 공통 정보가 모든 개별 CSI 피드백 정보의 잠재 변 수들과 함께 수신된 경우 잠재 변수들 중 적어도 하나는 전체 계층 공통 정보와 전체 서브밴드의 공통 정 보에 대한 잠재 변수가 될 수 있다. 이처럼 분리된 잠재변수들은 디코더로 입력될 수 있다. 여기서 디코더는 앞서 도 3에서 설명한 디 코더에 대응할 수 있다. 디코더는 각 잠재변수들을 각 서브채널에 대응하는 CSI 피드백 정보로 디코 딩하여 출력할 수 있다. 도 10과 다르게 도 12에서는 추가적으로 복원 장치(restoration device)를 더 포함할 수 있다. 본 개시에 따른 복원 장치는 개별 서브밴드 CSI 피드백 정보를 입력으로 하는 추가 복원 인공 신경망이 될 수 있다. 이를 통해 최종 CSI 피드백 정보를 복원할 수 있다. 본 개시의 또 다른 실시예에 따르면, 기지국은 단말로 CSI 피드백 정보를 개별 서브밴드 및/또는 개별 레이어 단위로의 CSI 피드백 정보의 생성 및 보고를 요청할 수 있다. 기지국이 전체 서브밴드 및 전체 레이어 중 일부 서브밴드 및/또는 일부 레이어의 CSI 피드백 정보를 요청하는 경우, 단말은 CSI 피드백 정보 요청에 기초하여, 일부 서브밴드 및/또는 일부 레이어의 CSI 피드백 정보를 기지국으로 전송할 수 있다. 기지국은 일부 서브밴드 및/또는 일부 레이어의 CSI 피드백 정보를 이용하여 전체 서브밴드 및 레이어에 대한 최종 CSI를 획득할 수 있 다. 이때, 전체 서브밴드 및 레이어 중 일부 서브밴드 및/또는 레이어를 지정하는 방법은 서브밴드 및/또는 레 이어에 대한 공통 시작 및 간격 정보를 이용하거나, 또는 각 레이어에 대한 서브밴드의 시작 및 간격 정보를 이 용하여 지시할 수 있다. 그러면 이러한 절차를 수행하는 경우를 첨부된 도면을 참조하여 살펴보기로 한다. 도 13은 단말이 일부 서브밴드 및 일부 계층 정보를 CSI 피드백 정보로 보고하는 경우 기지국에서 최종 CSI 획 득을 설명하기 위한 개념도이다. 도 13을 참조하기에 앞서, 위에서 설명한 바와 같이 기지국은 단말로 CSI 피드백 정보 요청 메시지에 개별 서브 밴드 및/또는 개별 레이어 단위로의 생성 및 보고하도록 지시한 경우를 가정한다. 또한 기지국이 개별 서브밴드 및 개별 레이어 단위의 CSI 피드백 정보를 이용하여 6개의 서브밴드 및 2개의 레 이어에 대한 CSI 정보를 획득하고자 하는 경우, 6*2 개의 단위 CSI 피드백 정보가 전달되어야 한다. 이를 효과 적으로 줄이기 위하여, 기지국은 첫번째 레이어에 대해서는 시작 및 간격을 각각 0 및 6으로 설정하고, 두번째 레이어에 대해서는 시작 및 간격을 각각 3 및 6으로 설정하여, 4개의 서브밴드들에 대한 단위 CSI 피드백 정보 만을 전달하도록 지시할 수 있다. 단말은 위와 같이 기지국으로부터 수신된 CSI 피드백 정보 보고 요청 메시지에 기초하여 전체 서브밴드 중 일부 서브밴드들 다시 말해 4개의 개별 서브밴드에 대한 CSI 피드백 정보를 생성할 수 있다. 그리고 단말은 4개의 개별 서브밴드에 대한 CSI를 인코더로 입력하여 해당 서브밴드들에 대한 CSI 피드백 정보를 생성할 수 있다. 그리고 생성된 CSI 피드백 정보는 CSI 피드백 메시지에 포함되어 기지국으로 전송될 수 있다. 따라서 CSI 피드백 정보는 4개의 개별 서브밴드에 대한 CSI 정보를 포함할 수 있다. 기지국은 4개의 개별 서브밴드들에 대한 CSI 피드백 정보를 포함하는 CSI 피드백 메시지를 수신하면, 디코더 를 이용하여 4개의 개별 서브밴드의 CSI 정보를 획득할 수 있다. 도 13에서 참조부호 1350은 전체 서브밴드 중 해칭된 일부 서브밴드에 대해 CSI 피드백 정보를 획득한 경우를 예시한 것이다. 그리고 기지국은 본 개시에 따른 복원 장치로 4개의 개별 CSI 피드백 정보를 입력할 수 있다. 여기서 본 개시에 따른 복원 장치는 추가 복원 인공 신경망을 이용한 장치가 될 수 있다. 복원 장치는 4개의 개별 CSI 피드백 정보를 이용하여 전체 서브밴드 및 전체 레이어에 대하여 복원된 CSI 정보를 획득할 수 있다."}
{"patent_id": "10-2023-0152938", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[3] 분산 학습 방법 본 개시의 일 실시예에 따르면, 기지국 및 단말이 양면 ML 모델 및/또는 양면 AI 모델을 분산적으로 학습할 수 있다. 기지국 또는 단말 측에서 양면 ML 모델 및/또는 양면 AI 모델의 학습 요청을 상대 측으로 전송할 수 있다. 다시 말해 기지국은 단말로 양면 ML 모델 및/또는 양면 AI 모델의 학습을 요청할 수 있고, 마찬가지로 단 말은 기지국으로 양면 ML 모델 및/또는 양면 AI 모델의 학습을 요청할 수 있다. 학습 요청을 수신한 단말 및/또는 기지국은 응답을 학습을 요청한 측(원시 측)으로 전달할 수 있다. 원시 측에 서 상대 측으로 전달하는 학습 요청에는 아래의 정보가 포함될 수 있다. □ 양면 기계학습 모델의 분산 학습 방법 >> 분리학습 >> 순차학습 >> 병렬학습 □ 인공신경망 및 학습 데이터 셋 구조 >> 단말 인공신경망의 입력 및 기지국 인공신경망의 출력의 종류 및 크기 >> 단말 인공신경망의 입력 및 기지국 인공신경망의 출력의 표현 방법 >> 잠재변수 차원 크기 >> 잠재변수의 표현 방법 >> 입력 및 출력의 상동성 여부 또한 상대 단말에서 원시 단말로 전송하는 응답에는 아래의 정보가 포함될 수 있다. □ 학습 수행 가능 여부 □ 학습 수행 불가 이유 (학습 수행 불가 시) >> 인공신경망 구조 지원 불가 >> 학습용 데이터 셋 획득 불가 등 도 14a는 기지국과 단말 간 AI 또는 ML의 순차 학습을 설명하기 위한 개념도이고, 도 14b는 기지국과 단말 간 AI 또는 ML의 순차/병렬 학습을 설명하기 위한 개념도이다. 도 14a를 참조하면, 기지국은 디코더를 포함할 수 있다. 디코더는 본 개시에 따른 AI 모델 및/또는 ML 모델이 될 수 있다. 그리고 단말은 인코더를 포함할 수 있다. 인코더는 본 개시 에 따른 AI 모델 및/또는 ML 모델이 될 수 있다. 이하의 설명에서 디코더와 인코더 각각은 AI 모델 인 경우를 가정하여 설명하기로 한다. 도 14a에서 순차 학습은 단말에서 요청하여 이루어지는 경우를 예시하고 있다. 다시 말해 단말은 기지국으로 CSI 피드백 정보를 보고하기 위한 AI 모델의 학습을 요청할 수 있다. 이에 기지국은 단 말로 학습 응답을 전송할 수 있다. 이후 단말은 인코더의 학습을 수행한 후 학습 데이터를 기지국으로 전송할 수 있다. 이에 따라 기지국은 학습 데이터에 기초하여 디코더를 학습할 수 있다. 그리고 기지국은 학습 응답을 단말로 전송할 수 있다. 이처럼 기지국과 단말 간에 AI 모델의 순차적인 학습이 이루어질 수 있다. 도 14b를 참조하면, 기지국은 디코더 및 인코더를 포함할 수 있다. 디코더 및 인코더 는 본 개시에 따른 AI 모델 및/또는 ML 모델이 될 수 있다. 단말 또한 디코더 및 인코더 를 포함할 수 있다. 디코더 및 인코더는 본 개시에 따른 AI 모델 및/또는 ML 모델이 될 수 있다. 도 14b에 예시한 바와 같이 기지국은 기지국이 가지고 있어야 하는 디코더 뿐 아니라 단말이 가지고 있어야 하는 인코더를 더 포함할 수 있다. 동일하게 단말은 단말이 가지고 있어야 하는 인 코더 뿐 아니라 기지국이 가지고 있어야 하는 디코더를 더 포함할 수 있다. 따라서 실질적으로 기 지국 및 단말 각각에 포함된 디코더들(1412, 1422)는 동일한 AI 모델이 될 수 있고, 기지국 및 단말 각각에 포함된 인코더들(1413, 1423) 또한 동일한 AI 모델이 될 수 있다. 따라서 기지국은 기지국 내부에서 AI 모델의 학습이 진행될 수 있고, 단말은 단말 내부에서 AI 모델의 학습이 진행될 수 있다. 이상에서 설명한 도 14a 및 도 14b의 동작을 좀 더 구체적으로 살펴보기로 한다. 도 15는 CSI 피드백 정보를 송수신하기 위한 AI 모델의 순차 학습 절차를 설명하기 위한 순서도이다. 도 15를 참조하면, 기지국과 단말을 예시하였다. 기지국과 단말 각각은 앞서 도 2에서 설명한 구성 요소 전부 또는 일부를 포함할 수 있다. 또한 도 6에서는 이동 통신 시스템을 하나의 실시예로써 설명하기 위해 기지국과 단말를 예시하였음에 유의해야 한다. 다시 말해, 앞서 설명한 바와 같이 기지국과 단말 각각은 다양한 형태의 무선 통신 시스템에서 제1 통신 노드와 제2 통신 노드로 대체 되어 이해될 수 있다. 단말은 순차 학습을 통하여 양면 AI 모델의 훈련을 시작하고자 할 때, 학습 방법 예를 들어, 인공 신경망 의 학습 유형이 순차적 학습인지 또는 병렬 학습인지에 대한 정보를 설정할 수 있다. 그리고 단말은 인공 신경망의 학습 유형 관련 정보를 설정할 수 있다. 인공 신경망의 학습 유형 관련 정보를 예를 들면 아래와 같은 정보들이 설정될 수 있다. a. 입력 유형(input type): 프리코딩 벡터 b. 입력 차원(input dimension): [송신 안테나의 수 * 2] c. 입력 표현(input representation) 방법: Float32 d. 잠재 차원(latent dimension): [16 X 1] e. 잠재 표현(latent representation) 방법: Float32 위에 예시한 바와 같이 단말 인공 신경망의 입력 유형을 예를 들면, 개별 서브밴드의 프리코딩 벡터로 설정할 수 있다. 또한 단말은 입력 차원을 송신 안테나 수의 2배로 결정할 수 있다. 만일 송신 안테나 수가 32개 인 경우 단말 인공 신경망의 입력 차원은 64차원이 될 수 있다. 이는 결과적으로 개별 서브밴드의 프리코딩 벡 터에 맞춰 지정한 것이 될 수 있다. 또한 단말 인공 신경망의 입력 차원은 기지국 인공 신경망의 출력 차원과 동일할 수 있다. 또한 단말은 잠재 변수의 차원의 크기를 결정할 수 있으며, 잠재 변수의 차원 크기는 예를 들어 16 차원 으로 결정될 수 있다. 그리고 단말은 데이터 세트에 기지국 측 인공 신경망의 출력 및 잠재 변수의 표현 방법을 결정할 수 있으며, 예를 들어, Float32로 결정할 수 있다. 도 15의 실시예에서는 단말이 학습 요청을 트리거하는 경우 다시 말해 단말이 기지국으로 학 습 요청 메시지를 전송하는 경우에 대해 설명할 것이다. 하지만, 도 15와 반대의 경우 다시 말해, 기지국(150 1)이 단말로 학습 요청 메시지를 전송하는 경우도 도 15의 설명에 기초하여 동일한 방식으로 수행될 수 있다. S1500단계에서 단말은 위에서 설명된 인공 신경망의 학습 유형과 인공 신경망의 학습 유형 관련 정보들인 a 내지 e 중 적어도 하나를 포함하는 학습 요청 메시지를 기지국으로 전송할 수 있다. 따라서 기지국 은 S1500단계에서 학습 요청 메시지를 단말로부터 수신할 수 있다. S1502단계에서 기지국은 학습 요청 메시지 수신에 기초하여 학습을 수행 가능 여부를 확인하고, 학습 수 행 가능 여부 정보를 포함하는 제1 학습 응답 메시지를 단말로 전송할 수 있다. 이때, 학습 불가능인 경 우 그 이유를 포함하도록 할 수도 있다. 이하에의 설명에서는 설명의 편의를 위해 기지국이 제1 학습 응 답 메시지를 학습 가능으로 설정하여 단말로 전송한 경우를 가정하여 설명하기로 한다. 따라서 단말 은 기지국으로부터 학습 가능으로 설정된 제1 학습 응답 메시지를 수신할 수 있다. S1504단계에서 단말은 기지국으로부터 수신된 제1 학습 응답 메시지가 학습 가능을 지시하는 경우 에 수행될 수 있다. 단말은 단말 측 AI 모델의 학습을 수행할 수 있다. 이를 도 14a의 예를 참조하면, 단 말은 인코더의 학습을 수행할 수 있다. 이때, 단말은 기지국 측 AI에서 학습할 수 있는 학습 데이터 세트를 생성할 수 있다. 이때 단말에서 생성되는 학습 데이터 세트는 아래와 같은 정보로 구성될 수 있다. □ 학습 데이터 세트 >> 단말 인공 신경망의 입력 및 잠재변수(기지국이 단말로 학습 요청을 전송하는 경우) >> 잠재변수 및 기지국 인공 신경망의 출력(단말이 기지국으로 학습 요청을 전송하는 경우) S1506단계에서 단말은 학습 데이터 세트를 기지국으로 전송할 수 있다. 따라서 기지국은 단 말로부터 데이터 세트를 수신할 수 있다. S1508단계에서 기지국은 단말로부터 수신된 학습 데이터 세트를 이용하여 기지국 측 AI 모델의 학 습을 수행할 수 있다. S1510단계에서 기지국은 제2 학습 응답 메시지를 단말로 전송할 수 있다. 이때, 제2 학습 응답 메 시지는 기지국의 학습 결과 정보를 포함할 수 있다. 다시 말해, 제2 학습 응답 메시지는 기지국에서 기지국 측 AI 모델의 학습을 수행한 결과인 성공 또는 실패를 지시하는 정보를 포함할 수 있다. 따라서 단말 은 S1510단계에서 기지국으로부터 기지국 측 AI 모델의 학습을 수행한 결과인 성공 또는 실패를 지 시하는 정보를 포함하는 제2 학습 데이터를 수신할 수 있다. 도 16은 CSI 피드백 정보를 송수신하기 위한 AI 모델의 병렬 학습 절차를 설명하기 위한 순서도이다. 도 16을 참조하면, 기지국과 단말을 예시하였다. 기지국과 단말 각각은 앞서 도 2에서 설명한 구성 요소 전부 또는 일부를 포함할 수 있으며, 도 15에서 설명한 바와 같이 다양한 형태의 무선 통신 시스템에서 제1 통신 노드와 제2 통신 노드로 대체되어 이해될 수 있다. 도 16의 실시예는 앞서 설명한 도 15의 실시예와 다르게 기지국이 학습 요청 메시지를 단말로 전송 하여 학습이 트리거링되는 경우를 예시하였다. S1600단계에서 기지국은 학습 요청 메시지를 단말로 전송할 수 있다. 이때 학습 요청 메시지는 도 15에서 설명한 학습 요청 메시지와 동일한 구성을 가질 수 있다. 따라서 단말은 S1600단계에서 기지국 로부터 학습 요청 메시지를 수신할 수 있다. S1602단계에서 단말은 학습 요청 메시지 수신에 응답하여 기지국이 학습을 요청한 AI 모델의 학습이 가능 한지 여부를 확인할 수 있다. 그리고 단말은 학습 수행 가능 여부 정보를 포함하는 제1 학습 응답 메시지 를 기지국으로 전송할 수 있다. 도 16에서는 단말이 제1 학습 응답 메시지에 학습 수행 가능을 지 시한 경우를 가정한다. S1604단계에서 단말는 단말 측 AI 모델의 학습을 수행할 수 있다. 이를 도 14b의 예를 이용하여 살펴보기 로 한다. 도 16의 단말은 도 14b의 단말에 대응할 수 있다. 따라서 도 16의 단말은 디코더와 인코더를 모두 포함하고 있으며, AI 모델의 학습이 이루어져야 하는 부분은 인코더이 될 수 있다. 따라서 단말은 내부에 구비된 인코더 및 디코더를 이용하여 단말의 AI 모델 학습을 수행할 수 있다. S1606단계에서 기지국는 기지국 측 AI 모델의 학습을 수행할 수 있다. 이를 도 14b의 예를 이용하여 살펴 보기로 한다. 도 16의 기지국은 도 14b의 기지국에 대응할 수 있다. 따라서 도 16의 기지국 은 디코더와 인코더를 모두 포함하고 있으며, AI 모델의 학습이 이루어져야 하는 부분은 디코더가 될 수 있다. 따라서 기지국은 내부에 구비된 인코더 및 디코더를 이용하여 단말의 AI 모델 학습을 수행할 수 있다. S1604단계 및 S1606단계에서 단말 및 기지국은 각각 자신의 AI 모델의 학습을 병렬로 수행할 수 있 다. 그리고 학습이 완료되면, 단말 및 기지국 각각은 제2 학습 응답 메시지(S1608단계) 및 제3 학습 응 답 메시지(S1610단계)를 상대 측으로 전송할 수 있다. 이때, 제2 학습 응답 메시지 및 제3 학습 응답 메시지는 모두 자신의 AI 모델의 학습을 수행한 결과인 성공 또는 실패를 지시하는 정보를 포함할 수 있다. 입력 및 출력의 상동성이 지원되는 경우, 기지국 또는 단말 측은 전달받는 데이터 세트의 단말 인 공 신경망의 입력, 또는 기지국 인공 신경망의 출력이 각각 기지국 인공 신경망의 출력, 또는 단말 인공 신경망 의 입력과 동일함을 가정할 수 있다. 한편, 본 개시의 다른 실시예에 따르면, 분산 및 순차 학습이 수행될 수 있다. 분산 및 순차 학습이 수행되는 경우, 학습을 위하여 전달하는 데이터 세트의 잠재 변수를 양자화 할 수 있으며, 이를 위하여 학습 요청 정보에 잠재 변수의 양자화 관련 구성 정보를 추가로 포함하여 전송할 수 있다. 잠재 변수의 양자화 관련 구성 정보는 아래의 정보를 포함할 수 있다. □ 인공 신경망 및 학습 데이터 셋 구조 >> 잠재 변수의 양자화 여부 >> 잠재 변수의 양자화 구성 방법(잠재 변수 양자화가 수행되는 경우) 데이터 세트의 잠재 변수에 대해 양자화가 적용되는 경우, 학습 과정에서는 수신한 잠재 변수를 역 양자화하여 학습을 수행할 수 있다.[4] 양자화 인지 학습 방법 본 개시의 일 실시예에 따르면, 비 양자화된 잠재 변수를 기반으로 동작하는 양면 AI 모델 및/또는 ML 모델을 학습할 때, 양자화를 포함한 동작의 성능을 개선할 수 있다. 예를 들어, 기지국의 복원 인공 신경망의 학습 과 정에서 양자화 되지 않은 잠재 변수에 대하여 특정 양자화 방법을 가정하여 양자화 및 역 양자화 과정을 수행할 수 있다. 그리고 특정 양자화 방법을 가정한 양자화 및 역 양자화 결과를 기지국 복원 인공 신경망의 입력으로 사용할 수 있다. 이때, 가정하는 양자화 방법은 실제 동작에서 단말로 지시되는 양자화 방법 중 하나 일 수 있 다. 도 17은 CSI 피드백 정보를 송수신하기 위한 AI 모델에서 양자화 인지 학습 벙법을 설명하기 위한 개념도이다. 본 개시의 일 실시예에 따르면, 기지국 또는 단말 중 어느 특정 개체에서 중앙 집중적으로 양면 AI 모델 및/또 는 ML 모델을 학습하는 경우를 가정한다. 이때, 양면 AI 모델 및/또는 ML 모델은 양자화를 고려하지 않은 학습 을 수행한 후, 특정 양자화 기법이 적용될 수 있다. 이처럼 양자화를 고려하지 않은 양면 AI 모델 및/또는 ML 모델에 양자화가 적용되는 경우 성능 개선이 필요할 수 있다. 따라서 양자화를 고려하지 않은 양면 AI 모델 및/ 또는 ML 모델에 양자화가 적용되는 경우 성능을 개선하기 위해, 해당 양자화 기법을 적용한 양자화 및 역 양자 화된 잠재 변수의 입력을 이용하여 기지국 복원 인공 신경망의 추가 학습을 수행할 수 있다. 이때, 수행되는 양 자화 방법을 예를 들면, 2 비트 균등 양자화 기법이 적용될 수 있다. 도 17을 참조하면, 중앙 집중적으로 양면 AI 모델 및/또는 양면 ML 모델을 학습하는 노드는 기지국, 단말 또는 서버가 될 수 있다. 또한 양면 AI 모델 및/또는 양면 ML 모델에 의한 인코더 및 디코더 각각은 양 자화 기법이 적용되지 않은 상태의 모델들이 될 수 있다. 따라서 본 개시에 따른 양면 AI 모델 및/또는 양면 ML 모델을 학습하는 노드는 서브채널을 인코더에 의해 CSI 보고를 위한 인코딩을 수행하여 잠재 변수 를 생성할 수 있다. 이때, 인코더는 고정된 인코더가 될 있다. 인코더에서 출력된 잠재 변수(172 1)는 양자화/역 양자화 절차를 수행할 수 있다. 양자화/역 양자화 절차를 수행한 잠재 변수 은 양자화/역 양자화 절차 수행 전의 잠재 변수과 동일할 수도 있고, 다른 값이 될 수도 있다. 이 는 양자화/역 양자화 절차를 통해 일정 부분의 양자화/역 양자화에 의한 노이즈가 삽입된 형태로 이해될 수 있다. 따라서 노이즈가 포함된 형태의 잠재 변수를 디코더로 입력할 수 있다. 그러면 디코더 는 디코딩을 통해 전체 서브채널에 대한 최종 CSI를 획득할 수 있다. 이때, 디코더는 노이즈가 포 함된 형태의 잠재 변수를 이용하여 학습이 이루어지기 때문에 양자화 및 역 양자화 절차에 기초한 노이즈 를 상쇄할 수 있는 형태로 학습될 수 있다. 이러한 동작은 참조부호 1700으로 표현한 바와 같이 반복 수행될 수 있으며, 반복 수행 횟수는 미리 설정될 수 있다. 본 개시의 실시 예에 따른 방법의 동작은 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 프로그램 또는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽혀질 수 있 는 정보가 저장되는 모든 종류의 기록장치를 포함한다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연 결된 컴퓨터 시스템에 분산되어 분산 방식으로 컴퓨터로 읽을 수 있는 프로그램 또는 코드가 저장되고 실행될 수 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 롬(rom), 램(ram), 플래시 메모리(flash memory) 등과 같이 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 프로그램 명령은 컴파일러 (compiler)에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터(interpreter) 등을 사용해서 컴퓨 터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 본 개시의 일부 측면들은 장치의 문맥에서 설명되었으나, 그것은 상응하는 방법에 따른 설명 또한 나타낼 수 있 고, 여기서 블록 또는 장치는 방법 단계 또는 방법 단계의 특징에 상응한다. 유사하게, 방법의 문맥에서 설명된 측면들은 또한 상응하는 블록 또는 아이템 또는 상응하는 장치의 특징으로 나타낼 수 있다. 방법 단계들의 몇몇 또는 전부는 예를 들어, 마이크로프로세서, 프로그램 가능한 컴퓨터 또는 전자 회로와 같은 하드웨어 장치에 의 해(또는 이용하여) 수행될 수 있다. 몇몇의 실시 예에서, 가장 중요한 방법 단계들의 적어도 하나 이상은 이와 같은 장치에 의해 수행될 수 있다. 실시 예들에서, 프로그램 가능한 로직 장치(예를 들어, 필드 프로그래머블 게이트 어레이)가 여기서 설명된 방 법들의 기능의 일부 또는 전부를 수행하기 위해 사용될 수 있다. 실시 예들에서, 필드 프로그래머블 게이트 어 레이(field-programmable gate array)는 여기서 설명된 방법들 중 하나를 수행하기 위한 마이크로프로세서(microprocessor)와 함께 작동할 수 있다. 일반적으로, 방법들은 어떤 하드웨어 장치에 의해 수행되는 것이 바 람직하다. 이상 본 개시의 바람직한 실시 예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청 구의 범위에 기재된 본 개시의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 개시를 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2023-0152938", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 통신 시스템의 일 실시예를 도시한 개념도이다. 도 2는 통신 시스템을 구성하는 통신 노드의 일 실시예를 도시한 블록도이다.도 3은 양면 기계 학습 모델의 개념도이다. 도 4a는 단일 주파수 단위의 채널 정보의 개념도이다. 도 4b는 단일 주파수 단위의 프리코딩 벡터의 개념도이다. 도 4c는 다중 주파수 단위의 프리코딩 벡터의 개념도이다. 도 5는 기지국에서 CSI 도출 절차를 예시한 개념도이다. 도 6은 CSI 요청에 기초하여 양자화된 CSI 보고 메시지 전송 및 CSI 획득 절차를 예시한 순서도이다. 도 7은 단말에서 양면 모델 학습을 수행하고 기지국 측 모델을 전송하여 CSI 요청이 이루어지는 절차를 예시한 순서도이다. 도 8a는 압축 인공 신경망 출력 값의 범위를 한정하기 위한 하이퍼 탄젠트 함수의 그래프를 예시한 도면이다. 도 8b는 압축 인공 신경망 출력 값의 범위를 한정하기 위한 누적 분포 함수(CDF)의 그래프를 예시한 도면이다. 도 9a는 단말 측 인코더의 입력이 전체 서브밴드 단위인 경우 입력 및 출력을 예시한 개념도이다. 도 9b는 단말 측 인코더의 입력이 개별 서브밴드 단위인 경우 입력 및 출력을 예시한 개념도이다. 도 10은 기지국에서 CSI 피드백 정보에 기초하여 각 서브채널 별 CSI를 도출하는 절차를 예시한 개념도이다. 도 11은 서브밴드 및 계층의 공통 정보를 설명하기 위한 개념도이다. 도 12는 기지국에서 추가 복원 인공 신경망을 이용한 최종 CSI 복원 절차를 수행하기 위한 모델의 개념도이다. 도 13은 단말이 일부 서브밴드 및 일부 계층 정보를 CSI로 보고하는 경우 기지국에서 최종 CSI 획득을 설명하기 위한 개념도이다. 도 14a는 기지국과 단말 간 AI 또는 ML의 순차 학습을 설명하기 위한 개념도이다. 도 14b는 기지국과 단말 간 AI 또는 ML의 순차/병렬 학습을 설명하기 위한 개념도이다. 도 15는 CSI 피드백 정보를 송수신하기 위한 AI 모델의 순차 학습 절차를 설명하기 위한 순서도이다. 도 16은 CSI 피드백 정보를 송수신하기 위한 AI 모델의 병렬 학습 절차를 설명하기 위한 순서도이다. 도 17은 CSI 피드백 정보를 송수신하기 위한 AI 모델에서 양자화 인지 학습 벙법을 설명하기 위한 개념도이다."}
