{"patent_id": "10-2020-0171437", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0081675", "출원번호": "10-2020-0171437", "발명의 명칭": "원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템", "출원인": "정가영", "발명자": "정가영"}}
{"patent_id": "10-2020-0171437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "원어민 발화 데이터를 재생하여 소리로 출력하고, 사용자의 발화 데이터인 사용자 발화 데이터를 입력받아 상기원어민 발화 데이터와의 비교 결과를 출력하는 사용자 단말; 및적어도 하나의 종류의 문장을 음성으로 발화한 적어도 하나의 원어민 발화 데이터를 데이터베이스로 저장하는저장부, 상기 사용자 단말에서 상기 원어민 발화 데이터를 선택하는 경우 상기 사용자 단말로 실시간 스트리밍되도록 제어하는 제어부, 상기 사용자 단말에서 입력된 상기 사용자 발화 데이터를 수신하여 상기 원어민 발화데이터 간의 비교 결과를 산출하는 산출부, 상기 산출부에서 산출된 비교 결과를 상기 사용자 단말로 전송하는전송부를 포함하는 학습 서비스 제공 서버;를 포함하는 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템."}
{"patent_id": "10-2020-0171437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템은,상기 적어도 하나의 원어민 발화 데이터를 업로드하고, 상기 적어도 하나의 종류의 문장 텍스트를 업로드하는교수자 단말;을 더 포함하는 것을 특징으로 하는 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템."}
{"patent_id": "10-2020-0171437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 학습 서비스 제공 서버는,상기 사용자 단말에서 쉐도잉(Shadowing) 모드를 선택하는 경우, 상기 사용자 단말의 화면에 상기 적어도 하나의 종류의 문장을 출력하고, 상기 적어도 하나의 종류의 문장을 발화한 상기 원어민 발화 데이터를 재생하되,상기 사용자 단말로부터 상기 사용자의 음성 발화가 종료될 때까지 다음 문장의 원어민 발화 데이터의 재생은중지(Pause)시키는 재생조절부;를 더 포함하는 것을 특징으로 하는 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템."}
{"patent_id": "10-2020-0171437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 재생조절부는,상기 사용자 단말의 화면에 상기 적어도 하나의 종류의 문장을 출력할 때, 상기 적어도 하나의 종류의 문장을발화한 상기 원어민 발화 데이터에 대응하는 문장 텍스트의 색상을 변경하도록 싱크를 맞도록 설정하는 것을 특징으로 하는 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템."}
{"patent_id": "10-2020-0171437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2022-0081675-3-제 1 항에 있어서,상기 학습 서비스 제공 서버는,상기 적어도 하나의 종류의 문장을 음성으로 발화한 적어도 하나의 원어민 발화 데이터의 소리 데이터 및 진동데이터를 수집하여 저장하고, 상기 적어도 하나의 종류의 문장을 음성으로 발화한 적어도 하나의 한국인 발화데이터의 소리 데이터 및 진동 데이터를 수집하여 저장하며, 원어민의 소리 데이터 및 진동 데이터와, 상기 한국인의 소리 데이터 및 진동 데이터로부터 특징 데이터를 추출하여 저장하는 인공지능부;를 더 포함하는 것을 특징으로 하는 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템."}
{"patent_id": "10-2020-0171437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 인공지능부는,상기 원어민의 소리 데이터 및 상기 한국인의 소리 데이터를 STFT(Short-Time Fourier Trasnform)을 이용하여스펙트로그램(Spectrogram) 이미지로 변환하고, 상기 변환된 스펙트로그램 이미지를 CNN(Convolutional NeuralNetwork)를 이용하여 특징 데이터를 추출하며, 상기 원어민의 진동 데이터 및 상기 한국인의 진동 데이터를 시간 도메인(Time Domain)에서 XYZ축에 대하여 재구조화를 수행한 후, 상기 CNN을 이용하여 특징 데이터를 추출하는 것을 특징으로 하는 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템."}
{"patent_id": "10-2020-0171437", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템이 제공되며, 원어민 발화 데이터를 재생하여 소리 로 출력하고, 사용자의 발화 데이터인 사용자 발화 데이터를 입력받아 원어민 발화 데이터와의 비교 결과를 출력 하는 사용자 단말 및 적어도 하나의 종류의 문장을 음성으로 발화한 적어도 하나의 원어민 발화 데이터를 데이터 베이스로 저장하는 저장부, 사용자 단말에서 원어민 발화 데이터를 선택하는 경우 사용자 단말로 실시간 스트리 밍되도록 제어하는 제어부, 사용자 단말에서 입력된 사용자 발화 데이터를 수신하여 원어민 발화 데이터 간의 비 교 결과를 산출하는 산출부, 산출부에서 산출된 비교 결과를 사용자 단말로 전송하는 전송부를 포함하는 학습 서 비스 제공 서버를 포함한다."}
{"patent_id": "10-2020-0171437", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템에 관한 것으로, 상대적으로 긴 호흡으 로 발화를 하는 원어민과 같은 말하기를 학습할 수 있는 플랫폼을 제공한다."}
{"patent_id": "10-2020-0171437", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 제2외국어학습에서 인지과정(Cognitive Process)에 관한 연구가 관심을 받고 있다. 지각가설(Noticing Hypothesis)에서 학습자 자신의 학습을 인식하지 못하면 목표언어형태는 습득되지 못할 것이라고 언급하고 있다. 또한, 학습자들이 스스로 자신의 학습을 인식하기 위한 교육에서 중요한 하나의 방법은 목표언어형태의 중요성을 강조하는 것이라고 제언하고 있다. 이러한 학습자의 인지과정에 관한 관심은 말하기영역에서도 강조 되고 잇으며, 말하기 교수법에 있어 가장 최근 경향 중 하나는 학생 자신 또는 타인이 발화한 언어를 평가하고 분석하도록 하는데 중섬을 두는 것이라고 언급하고 있다. 이에 따라 의사소통 중심의 수업에서 자가평가에 관 련된 연구가 진행되고 있으며, 의사소통 뿐만 아니라 시험준비를 위한 수업에서도 자가평가 연구가 시도되고 있 다. 이때, 영어를 원어민과 같은 호흡으로 읽고 말할 수 있도록 도와주는 교수법이 연구 및 개발되었는데, 이와 관 련하여, 선행기술인 한국등록특허 제10-2096965호(2020년04월03일 공고) 및 한국등록특허 제10-1293467호(2013 년08월06일 공고)에는, 영어 단어 및 영어 단어에 대응되어 양동이 돌리기 원리가 적용된 호흡 교정 아이콘을 디스플레이 화면에 표시하고, 영어 단어의 발화 시작 지시에 따라 호흡교정 아이콘이 원형 궤적을 따라 한 바퀴 돌아가도록 함으로써, 양동이 돌리기 원리를 이용하여 발음 및 호흡 방식을 학습하도록 하는 구성과, 영어를 말 하거나 읽을 때 각 음절을 독립적으로 끊어읽을 수 있도록 호흡을 일시적으로 끊어주고 혀 또는 입술의 위치를 미리 준비하도록 알려주는 기능을 수행하는 기호를 영어의 단어 또는 문장에 삽입하여 표시함으로써 호흡이 길 고 끊어지지 못해서 제 타이밍에 맞게 영어발음을 하지 못하고 늘어지는 경우를 교정하는 방법이 각각 개시되어 있다. 다만, 상술한 방법은 콩글리쉬를 고치는 방법이라고 소개하고 있으나, 전형적인 콩글리쉬를 생산하는 방법일 뿐 이다. 즉, 한국의 말하기 호흡은 영미권 말하기 호흡과는 달라서 각 단어별로 잘라 말하거나 어구나 어절을 통 으로 말하는 호흡이 전혀 아니다. 한국어를 모국어로 한 학습자는 하나의 영어 문장을 읽을 때 각 단어별로 끊 어읽으면서 문장이 하나로 이어지지 못하는 문제점을 가지고 있는데, 상술한 방법을 이용하는 경우 더욱 더 한 국인스럽게 발음하게 되고 만다. 현실적으로 영어 입력의 양이 충분히 이루어질 수 있는 여건을 갖춘 영미권환경과는 근본적으로 다른 한국과 같은 EFL 환경에서는 많은 학습자들이 여전히 읽기 성취기준을 달성하기에는 어려움이 많다. 이에, 충분한 입력이 전제됨에도 영미권에서 수 년이 넘게 걸리는 말하기 과정은, 영미권과는 근본적으로 다른 ESL 환경을 가진 한국에서 한국환경에 맞게 개발 및 변형되어야 할 필요성이 존재한다."}
{"patent_id": "10-2020-0171437", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는, 상대적으로 긴 호흡을 가지는 영미권의 호흡법을 이용하여 음절이나 단어 단위로 끊어 지지 않도록 문장을 통으로 연습하게 함으로써, 발음, 연음 및 인토네이션을 함께 학습할 수 있도록 하고, 한 번의 호흡으로 문장을 말하는 연습을 반복적으로 할 수 있도록 쉐도잉을 실시하며, 쉐도잉한 발화 데이터와 원 어민의 발화 데이터 간을 스펙트로그램(Spectrogram)으로 변환한 후 이미지 자체로 CNN(Convolutional Neural Network)에 질의로 입력함으로써 그 차이점을 도출하고 원어민과 학습자 간의 호흡이 차이가 발생하는 부분을 자가인지 및 자가학습할 수 있도록 유사도가 기 설정된 기준값 미만으로 낮아질 때까지 반복루프를 돌도록 하는, 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 방법을 제공할 수 있다. 다만, 본 실시예가 이루 고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2020-0171437", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 발명의 일 실시예는, 원어민 발화 데이터를 재생하 여 소리로 출력하고, 사용자의 발화 데이터인 사용자 발화 데이터를 입력받아 원어민 발화 데이터와의 비교 결 과를 출력하는 사용자 단말 및 적어도 하나의 종류의 문장을 음성으로 발화한 적어도 하나의 원어민 발화 데이 터를 데이터베이스로 저장하는 저장부, 사용자 단말에서 원어민 발화 데이터를 선택하는 경우 사용자 단말로 실 시간 스트리밍되도록 제어하는 제어부, 사용자 단말에서 입력된 사용자 발화 데이터를 수신하여 원어민 발화 데 이터 간의 비교 결과를 산출하는 산출부, 산출부에서 산출된 비교 결과를 사용자 단말로 전송하는 전송부를 포 함하는 학습 서비스 제공 서버를 포함한다."}
{"patent_id": "10-2020-0171437", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 상대적으로 긴 호흡을 가지는 영미권의 호흡법을 이 용하여 음절이나 단어 단위로 끊어지지 않도록 문장을 통으로 연습하게 함으로써, 발음, 연음 및 인토네이션을 함께 학습할 수 있도록 하고, 한 번의 호흡으로 문장을 말하는 연습을 반복적으로 할 수 있도록 쉐도잉을 실시 하며, 쉐도잉한 발화 데이터와 원어민의 발화 데이터 간을 스펙트로그램(Spectrogram)으로 변환한 후 이미지 자 체로 CNN(Convolutional Neural Network)에 질의로 입력함으로써 그 차이점을 도출하고 원어민과 학습자 간의 호흡이 차이가 발생하는 부분을 자가인지 및 자가학습할 수 있도록 유사도가 기 설정된 기준값 미만으로 낮아질 때까지 반복루프를 돌도록 한다."}
{"patent_id": "10-2020-0171437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미하며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 명세서 전체에서 사용되는 정도의 용어 \"약\", \"실질적으로\" 등은 언급된 의미에 고유한 제조 및 물질 허용오차 가 제시될 때 그 수치에서 또는 그 수치에 근접한 의미로 사용되고, 본 발명의 이해를 돕기 위해 정확하거나 절 대적인 수치가 언급된 개시 내용을 비양심적인 침해자가 부당하게 이용하는 것을 방지하기 위해 사용된다. 본 발명의 명세서 전체에서 사용되는 정도의 용어 \"~(하는) 단계\" 또는 \"~의 단계\"는 \"~ 를 위한 단계\"를 의미하지 않는다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 한편, '~부'는 소프트웨어 또는 하드웨어 에 한정되는 의미는 아니며, '~부'는 어드레싱 할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객 체 지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회 로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또 는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 본 명세서에 있어서 단말, 장치 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말, 장치 또는 디바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기 술된 동작이나 기능 중 일부도 해당 서버와 연결된 단말, 장치 또는 디바이스에서 수행될 수도 있다. 본 명세서에서 있어서, 단말과 매핑(Mapping) 또는 매칭(Matching)으로 기술된 동작이나 기능 중 일부는, 단말 의 식별 정보(Identifying Data)인 단말기의 고유번호나 개인의 식별정보를 매핑 또는 매칭한다는 의미로 해석 될 수 있다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템을 설명하기 위한 도면이다. 도 1을 참조하면, 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템은, 적어도 하나의 사용자 단말, 학습 서비스 제공 서버 및 적어도 하나의 교수자 단말을 포함할 수 있다. 다만, 이러한 도 1의 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템은, 본 발명의 일 실시예 에 불과하므로, 도 1을 통하여 본 발명이 한정 해석되는 것은 아니다. 이때, 도 1의 각 구성요소들은 일반적으로 네트워크(Network, 200)를 통해 연결된다. 예를 들어, 도 1에 도시 된 바와 같이, 적어도 하나의 사용자 단말은 네트워크를 통하여 학습 서비스 제공 서버와 연결 될 수 있다. 그리고, 학습 서비스 제공 서버는, 네트워크를 통하여 적어도 하나의 사용자 단말 , 적어도 하나의 교수자 단말과 연결될 수 있다. 또한, 적어도 하나의 교수자 단말은, 네트워 크를 통하여 학습 서비스 제공 서버와 연결될 수 있다. 여기서, 네트워크는, 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의 미하는 것으로, 이러한 네트워크의 일 예에는 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷(WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), 5GPP(5th Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency), 블루투스(Bluetooth) 네트워크, NFC(Near-Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워 크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 하기에서, 적어도 하나의 라는 용어는 단수 및 복수를 포함하는 용어로 정의되고, 적어도 하나의 라는 용어가 존재하지 않더라도 각 구성요소가 단수 또는 복수로 존재할 수 있고, 단수 또는 복수를 의미할 수 있음은 자명 하다 할 것이다. 또한, 각 구성요소가 단수 또는 복수로 구비되는 것은, 실시예에 따라 변경가능하다 할 것이다. 적어도 하나의 사용자 단말은, 원어민 호흡법을 이용한 영어 말하기 학습 서비스 관련 웹 페이지, 앱 페이 지, 프로그램 또는 애플리케이션을 이용하여 원어민 발화 데이터를 스피커로 출력하고, 적어도 하나의 종류의 문장을 화면으로 디스플레이하면서, 사용자가 문장을 읽은 발화를 입력받아 사용자 발화 데이터로 학습 서비스 제공 서버로 전송하는 단말일 수 있고, 학습 서비스 제공 서버로부터 비교결과를 수신하는 단말일 수 있다. 여기서, 적어도 하나의 사용자 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터 로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데 스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 사용자 단말은, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 사용자 단말은, 예 를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 학습 서비스 제공 서버는, 원어민 호흡법을 이용한 영어 말하기 학습 서비스 웹 페이지, 앱 페이지, 프로 그램 또는 애플리케이션을 제공하는 서버일 수 있다. 그리고, 학습 서비스 제공 서버는, 적어도 하나의 교수자 단말로부터 적어도 하나의 문장 데이터 및 적어도 하나의 원어민 발화 데이터를 업로드받아 사용자 단말에서 출력되도록 하는 서버일 수 있다. 또, 학습 서비스 제공 서버는, 사용자 단말로부터 수집된 사용자 발화 데이터를 원어민 발화 데이터와 비교 및 분석한 결과를 사용자 단말로 전송하는 서버 일 수 있다. 여기서, 학습 서비스 제공 서버는, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스 크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 적어도 하나의 교수자 단말은, 원어민 호흡법을 이용한 영어 말하기 학습 서비스 관련 웹 페이지, 앱 페이 지, 프로그램 또는 애플리케이션을 이용하는 교수자의 단말일 수 있다. 이때, 교수자 단말은, 적어도 하 나의 종류의 문장 데이터 및 적어도 하나의 원어민 발화 데이터를 학습 서비스 제공 서버로 업로드하는 단 말일 수 있다. 이때, 문장 데이터는 텍스트가 포함된 파일 포맷으로 입력될 수도 있고, 원어민 발화 데이터는 .mp3, .wav, .vox 등일 수 있으나 이에 한정되지는 않는다. 또, 교수자 단말은, 문장 데이터 외에도 교재 데이터를 업로드할 수도 있다. 여기서, 적어도 하나의 교수자 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터 로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데 스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 교수자 단말은, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 교수자 단말은, 예 를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 도 2는 도 1의 시스템에 포함된 학습 서비스 제공 서버를 설명하기 위한 블록 구성도이고, 도 3 및 도 4는 본 발명의 일 실시예에 따른 원어민 호흡법을 이용한 영어 말하기 학습 서비스가 구현된 일 실시예를 설명하기 위 한 도면이다. 도 2를 참조하면, 학습 서비스 제공 서버는, 저장부, 제어부, 산출부, 전송부, 재생 조절부 및 인공지능부를 포함할 수 있다. 본 발명의 일 실시예에 따른 학습 서비스 제공 서버나 연동되어 동작하는 다른 서버(미도시)가 적어도 하 나의 사용자 단말 및 적어도 하나의 교수자 단말로 원어민 호흡법을 이용한 영어 말하기 학습 서비스 애플리케이션, 프로그램, 앱 페이지, 웹 페이지 등을 전송하는 경우, 적어도 하나의 사용자 단말 및 적어 도 하나의 교수자 단말은, 원어민 호흡법을 이용한 영어 말하기 학습 서비스 애플리케이션, 프로그램, 앱 페이지, 웹 페이지 등을 설치하거나 열 수 있다. 또한, 웹 브라우저에서 실행되는 스크립트를 이용하여 서비스 프로그램이 적어도 하나의 사용자 단말 및 적어도 하나의 교수자 단말에서 구동될 수도 있다. 여기 서, 웹 브라우저는 웹(WWW: World Wide Web) 서비스를 이용할 수 있게 하는 프로그램으로 HTML(Hyper Text Mark-up Language)로 서술된 하이퍼 텍스트를 받아서 보여주는 프로그램을 의미하며, 예를 들어 넷스케이프 (Netscape), 익스플로러(Explorer), 크롬(Chrome) 등을 포함한다. 또한, 애플리케이션은 단말 상의 응용 프로 그램(Application)을 의미하며, 예를 들어, 모바일 단말(스마트폰)에서 실행되는 앱(App)을 포함한다. 도 2를 참조하면, 저장부는, 적어도 하나의 종류의 문장을 음성으로 발화한 적어도 하나의 원어민 발화 데 이터를 데이터베이스로 저장할 수 있다. 교수자 단말은, 적어도 하나의 원어민 발화 데이터를 업로드하고, 적어도 하나의 종류의 문장 텍스트를 업로드할 수 있다. 제어부는, 사용자 단말에서 원어민 발화 데이터를 선택하는 경우 사용자 단말로 실시간 스트리 밍되도록 제어할 수 있다. 이때, 녹음 파일(원어민 발화 데이터) 뿐만 아니라 유튜브에서 선생님이 설명을 해 주는 것과 같이 동영상이나 이미지 또는 사진 등이 실시간으로 중계되거나 스트리밍되어야 하는 경우, HTML5를 이용할 수도 있다. 이때, 실시간으로 스트리밍되는 것은 콘텐츠 데이터일 수 있고, 콘텐츠 데이터는 텍스트, 이미지, 사진 및 동영상 데이터 중 어느 하나 또는 적어도 하나의 조합일 수 있다. 여기서, 웹 페이지 내 동영 상은 HTML5 기반으로 실시간 스트리밍받을 수 있도록 설계될 수도 있다. 여기서, HTML5는, 웹문서 표준인 HTML(Hyoer Text Markup Language)의 최신 규격으로 문서 작성 중심에서 그림, 동영상, 음악 등을 실행하는 기 능이 포함되었다. HTML5는 플러그인 기반의 액티브 엑스(Active-X), Flash 와 같이 프로그램을 별도로 설치할 필요가 없어지게 되 었으며, 이로 인해 발생한 문제는 대부분 해결할 수 있게 되었다. 이때, 종래의 HTML 표준과 HTML5의 가장 큰 차이점은 시맨틱 마크업을 지원하는 점과 추가적인 API를 제공하는 점이다. 시맨틱 마크업은 웹 문서를 의미적 으로 구조화 할 수 있는 새로운 요소이다. 예를 들어, 문서의 내용을 머리말, 본문, 꼬리말로 구분할 수 있도 록 <head>, <section>, <footer> 라는 요소로 문서를 작성하게 되면, 문서의 내용을 구조적으로 명확히 이해할 수 있게 된다. 또한 HTML5에서는 다양한 API를 제공한다. HTML5에서 제공하는 API는 2차원 그래픽을 지원하거 나, 디바이스의 지리적 위치를 확인할 수 있는 기능을 지원하는 등 웹 애플리케이션에 다양한 기능을 추가할 수 있도록 해준다 또한, HTML5는, 웹 페이지를 만들 때 사용이 되는 마크업 언어로 하이퍼링크와 텍스트로 표시하던 HTML을 멀티 미디어 등 다양한 애플리케이션까지 표현하고 제공할 수 있다. HTML5는 웹 문서 구조 설계를 위한 마크업 언 어인 HTML, 디자인 표현을 위한 CSS, 인터랙티브한 동작을 표현하기 위한 자바스크립트(JavaScript) 등을 포함 하여 구현될 수 있고, 기존의 HTML의 태그에 새로운 태그들이 더 추가될 수 있으며, 콘텐츠들을 담기 위한 구조 로 개선되어 플랫폼의 역할까지도 수행할 수 있다. 또, HTML5는 모바일 웹을 위한 표준은 아니지만, 앞서 설명 한 여러 기능 중에서 모바일 웹의 구현에 필요한 기능들을 다수 제공해 주고 있다. 2차원 그래픽, 오디오, 다 양한 웹 폼 등은 모바일 웹의 UI(User Interface)를 풍부하고 다양하게 해줄 수 있다. 즉, 모바일 웹 환경에서 도 멀티미디어 정보를 제공하거나 사용자의 동적인 상호작용을 지원할 수 있게 된다. 모바일 웹 환경에서는 모 바일 환경의 특성상 대용량의 데이터를 전송하는데 한계를 가지고, 인터넷이 연결되지 않는 환경이 자주 발생하 지만, 이러한 제약조건을 극복할 수 있는 것이 웹 클라이언트의 캐시를 이용하여 오프라인 웹 애플리케이션을 구현하거나 로컬에 DB를 저장하여 SQL문으로 질의할 수 있다. 또는, SaaS(Software as a Servcie)를 이용할 수도 있는데, SaaS는 인터넷 어디에서든 쉽게 이용할 수 있고, 웹브라우저만 있으면 어디서든 접근할 수 있다. 이때, 기관, 사용자 및 강사의 요구사항에 따라 BaaS(Backend as a Service)를 더 추가할 수도 있다. 물론, 인프라나 플랫폼 자체가 구비되지 않은 사용자, 기관 및 강사의 경우 IaaS(Infrastructure as a Service)로 서버 운영에 필요한 서버자원, IP, Network, Storage, 전력 등 여러 인프라 자원을 탄력적이고 빠르게 제공할 수 있다. IaaS는 자원을 쉽게 추가하거나 제거할 수 있으며 운영 체제를 제공하므로 친숙한 환경이 주어질 수 있다. 또, PaaS(Platform as a Service)로 서비스를 제공할 수 있 는데, 안정적인 환경과 그 환경을 이용하는 응용 프로그램을 개발할 수 있는 API까지 제공하는 서비스이다. PaaS는 간편하게 원시코드를 빌드 및 배포할 수 있으며 사용량에 따라 스케일 아웃(Scale Out)을 하기 용이하다. BaaS는 모바일 애플리케이션에 특화된 서비스로 모바일 애플리케이션에서 처리하기 힘든 회원관리 및 푸시, 파일 처리 등 서버 측 애플리케이션을 제공할 수 있다. PaaS의 플랫폼을 이용할 수 있고 제공되는 백 앤드 모듈을 REST API나 라이브러리 CALL을 통해 바로 사용할 수 있도록 구성될 수도 있다. 산출부는, 사용자 단말에서 입력된 사용자 발화 데이터를 수신하여 원어민 발화 데이터 간의 비교 결 과를 산출할 수 있다. 이때, 비교결과는 이하의 인공지능부에서 함께 설명하도록 한다. 전송부는, 산출부에서 산출된 비교 결과를 사용자 단말로 전송할 수 있다. 사용자 단말은, 원어민 발화 데이터를 재생하여 소리로 출력하고, 사용자의 발화 데이터인 사용자 발화 데이터를 입력받아 원어민 발화 데이터와의 비교 결과를 출력할 수 있다. 재생조절부는, 사용자 단말에서 쉐도잉(Shadowing) 모드를 선택하는 경우, 사용자 단말의 화면 에 적어도 하나의 종류의 문장을 출력하고, 적어도 하나의 종류의 문장을 발화한 원어민 발화 데이터를 재생하 되, 사용자 단말로부터 사용자의 음성 발화가 종료될 때까지 다음 문장의 원어민 발화 데이터의 재생은 중 지(Pause)시킬 수 있다. 예를 들어, 1 번 문장 내지 10 번 문장을 읽는 원어민의 음성 발화가 하나의 파일로 녹음된 경우에는, 1 번 문장이 끝난 후 사용자의 음성이 기다리는 시간을 두고 다시 2 번 문장이 재생되게 된다. 최근에는 사용자의 음성이 끝난 후 버튼을 누르는 방식으로 변경되어 사용자 편의가 증가하긴 했지만, 이를 누르는 것도 문장이 많은 경우 귀찮아지게 되고, 고객을 귀찮게 하는 UI/UX는 지속성이나 충성도를 가지기 어렵다. 이에 따라, 사용자의 발화를 STT(Speech to Text)로 변환하고 1 번 문장이 모두 끝난 것을 감지한 후 에 원어민의 발화 데이터를 출력하도록 할 수 있다. 이 경우, 네트워킹 자원이나 컴퓨팅 자원을 많이 소모하지 않기 때문에 발화 데이터를 출력하는데 지연이나 간섭이 없고 사용자 단말 단(End)에서도 손 쉽게 구현될 수 있다. 재생조절부는, 사용자 단말의 화면에 적어도 하나의 종류의 문장을 출력할 때, 적어도 하나의 종류의 문장을 발화한 원어민 발화 데이터에 대응하는 문장 텍스트의 색상을 변경하도록 싱크를 맞도록 설정할 수 있다. 재생조절부는, 상술한 예를 계속 인용하면 1 번 내지 10 번 문장을 하나의 페이지에 출력한 경우, 1 번 문장에 대한 음성을 출력하고 또 사용자로부터 음성을 인식하여 받고 있다면, 해당 1 번 문장을 출력하는 동안 1 번 문장을 2 번 내지 10 번 문장과는 다른 색상으로 변경시킬 수 있다. 어떠한 색을 지정하는 것 보다 는 현재 발화되고 인식되고 있는 문장을 다른 색상이나 밑줄 처리 또는 진하게 처리를 함으로써 직관적으로 구 분되도록 설계할 수 있다. 인공지능부는, 적어도 하나의 종류의 문장을 음성으로 발화한 적어도 하나의 원어민 발화 데이터의 소리 데이터 및 진동 데이터를 수집하여 저장하고, 적어도 하나의 종류의 문장을 음성으로 발화한 적어도 하나의 한 국인 발화 데이터의 소리 데이터 및 진동 데이터를 수집하여 저장하며, 원어민의 소리 데이터 및 진동 데이터와, 한국인의 소리 데이터 및 진동 데이터로부터 특징 데이터를 추출하여 저장할 수 있다. 인공지능부는, 원어민의 소리 데이터 및 한국인의 소리 데이터를 STFT(Short-Time Fourier Trasnform)을 이용하여 스펙트로그램(Spectrogram) 이미지로 변환하고, 변환된 스펙트로그램 이미지를 CNN(Convolutional Neural Network)를 이용하여 특징 데이터를 추출하며, 원어민의 진동 데이터 및 한국인의 진동 데이터를 시간 도메인(Time Domain)에서 XYZ축에 대하여 재구조화를 수행한 후, CNN을 이용하여 특징 데이터를 추출할 수 있다. 인공지능부에서 소리 데이터를 스펙트로그램 이미지로 변환할 때, 푸리에 변환(Fourier Transform)의 비정 상적인 신호에 대한 주파수 분석 기법의 오차가 생기는 문제점이 발생하고, 이와 같은 오차가 발생하는 순간에 도 주파수 분석을 할 수 있는 방법이 필요하다. 이에, STFT는, 신호의 안정성을 고려하여 대상 신호를 프레임 단위로 나누어 일정한 크기의 창을 움직이면서 푸리에 변환을 하는 방법인데, 분석하고자 하는 신호에 윈도우 (Window) 함수를 적용한 후 푸리에 변환을 수행하는 것으로 시간 영역에서의 STFT의 수식은 STFT(t,w)=∫x(τ- t)e-jwτ dτ이며, 인테그랄의 범위는 - 무한대에서 + 무한대까지이다. 여기서 x(τ)는 분석하고자 하는 신호이고, w(τ-t)는 윈도우 함수이다. 또, 스펙트로그램(Spectrogram)은, 소 리나 파동을 시각화하여 파악하기 위한 도구로, 파형(Waveform)과 스펙트럼(Spectrum)의 특징이 조합되어 있다.파형에서는 시간축의 변화, 즉 시간 도메인에서의 진폭축의 변화를 볼 수 있고, 스펙트럼에서는 주파수축의 변 화에 따른 진폭축의 변화를 볼 수 있는 반면, 스펙트로그램에서는 시간축과 주파수축의 변화에 따라 진폭의 차 이를 인쇄 농도나 표시 색상의 차이로 나타낸다. 인공지능부는, 변환된 스펙트로그램 이미지를 CNN(Convolutional Neural Network)를 이용하여 특징 데이 터를 추출할 수 있다. 스펙트로그램이 이미지로 출력되기 때문에, 결과적으로 이미지 분석을 통하여 사용자가 녹음한 소리 데이터를, 기 저장된 소리 데이터와 비교를 할 때, 이미지를 이용하여 비교해야 한다. 이때, 서 로 다른 이미지 간에 유사도를 계산하고자 할 때 픽셀 단위의 비교를 통해서는 이미지 사이의 유사한 정도를 판 단하기 어렵기 때문에, 이러한 문제를 해결하기 위해 이미지를 픽셀 단위로 비교하는 것이 아닌 이미지의 특징 을 추출하여 이미지를 비교하는 방법이 존재하는데, 바로 딥러닝 기술, CNN이다. CNN은, 스스로 이미지의 특징을 학습하고 학습된 특징을 바탕으로 이미지의 분류 및 이미지의 패턴을 인식할 수 있고, 컨볼루션 층을 이용한 네트워크 구조로 이미지 처리에 적합하며, 이미지 데이터를 입력으로 하여 이미지 내의 특징을 기반으로 이미지를 분류할 수 있기 때문에 본 발명의 일 실시예에서 이용하도록 한다. 다만, CNN 에 한정되는 것은 아니고 이미지를 구분하고 그 특징을 추출할 수 있는 방법이라면 그 어떠한 것이든 가능하다 할 것이다. CNN은, 스펙트로그램의 특징을 벡터 형태로 추출하고 추출된 특징을 이용하여 이미지 간 유사도를 측정할 수 있다. 스펙트로그램의 특징을 추출하기 위해 본 발명의 일 실시예에서는, 컨볼루션(Convolution) 레이어, 활성 함수 (Activation Function) 레이어, 최대 풀링(Max Pooling) 레이어로 구성된 합성곱 신경망의 기본 구조를 이용한 모델을 이용할 수 있고, 유사도를 측정하기 이전, 이미지를 분류하기 위해사용되는 소프트맥스 레이어(Softmax Layer) 이전의 레이어로부터 스펙트로그램의 특징 벡터를 추출하여 사용할 수 있다. 기본적으로 전결합 레이어 (Fully-Connected Layer)를 가지는 CNN과, 특징 맵(Feature Map) 상의 평균값을 가져오는 GAP 레이어(Global Average Layer)를 가지는 모델로부터 특징을 추출하여 유사도를 측정하는 데 사용할 수 있다. 이미지의 유사도를 측정하기 위한 또 다른 모델로 CNN 기반의 오토인코더 모델을 이용할 수도 있는데, 인코더 (Encoder)는 컨볼루션 신경망 구조로 구성되어 있고, 인코더의 결과로 압축된 데이터를 다시 재구성하기 위한 디코더(Decoder)를 포함할 수 있다. 학습된 오토인코더 모델의 특정 레이어로부터 스펙트로그램의 특징을 추출 하고, 이를 다시 GAP 레이어를 통해 나온 특징 벡터를 이미지 유사도 측정에 사용할 수 있다. 위 세 가지 모델 을 통해 추출된 이미지 특징 벡터로부터 유클리디안거리(Euclidean Distance) 및 코사인 유사도(Cosine Similarity)를 측정할 수 있고, 이를 이용하여 스펙트로그램 별 유사 정도, 즉 유사도에 따라 정렬할 수 있으며, 정렬된 순서를 이용하여 스펙트로그램 별 가장 유사하다고 판단되는 데이터뿐만 아니라 가장 유사하지 않다고 판단되는 데이터까지 확인할 수 있다. 소리 데이터에 대한 특징 데이터가 추출되었으면, 그 다음은 진동 데이터에 대한 특징 데이터를 추출해야 하는 데, 인공지능부는, 수집된 진동 데이터를 시간 도메인(Time Domain)에서 XYZ축에 대하여 재구조화를 수행 한 후, CNN을 이용하여 특징 데이터를 추출할 수 있다. 이에 대한 기본 개념은 시간축(시간 도메인)에 대한 추 의 이동의 원리로 회귀한다. 용수철에 달린 추는 시간이 지남에 따라 상하로 운동하게 되고, 중심점을 기준으 로 상한점과 하한점을 왕복하면서 그래프를 남긴다. 이와 마찬가지로, 사용자가 호흡을 하는 경우 호흡 소리가 사용자 단말의 마이크로 입력되고, 호흡이 언제 발생하는지, 그 세기는 어느 정도인지, 그 패턴은 어떻게 되는지에 대한 데이터 생성 및 그래프 시각화가 가능해진다. 이렇게 생성된 그래프 또한 이미지이므로, 상술한 CNN을 이용하여 인공지능부는 진동 데이터에 대한 특징 데이터를 추출할 수 있다. 인공지능 알고리즘은 데이터의 수집, 전처리, 특징 데이터 추출, 학습 및 테스트의 과정을 거쳐 모델링된다. 모델링 된 후 사용되는 것도 대부분 동일한데 학습 과정만을 거치지 않는 것만이 다르다. 물론, 오류가 발생되 거나 인간의 개입으로 오차가 발생하는 부분에 대하여 재학습을 하는 것도 가능하지만, 모델링이 된 후 실제 사 용할 때에는 수집-전처리-추출-결과 도출의 과정으로 이루어지는 것이 일반적이다. 따라서, 상술한 과정에서 모델링이 된 후 실제 사용하는 과정을 설명했다면, 이하에서는 학습 및 테스트 과정을 거치면서 모델링이 되는 과정을 설명하기로 한다. 인공지능부는, 수집된 원어민의 소리 데이터 및 진동 데이터와, 한국인의 종류별 소리 데이터 및 진동 데 이터로부터 특징 데이터를 추출할 때, 추출된 특징 데이터를 LSTM(Long Short-Term Memory)에 기반하여 특징 데 이터를 재추출할 수 있다. 인공지능부는, 모델링하는 과정에서 차이점은, 기 설정된 기준 데이터인 레이 블과 특징 데이터 간의 오차율을 산출하고, 산출된 오차율이 최소인 가중치를 특징 데이터와 매핑하여 저장하는 구성이다. 인공지능 알고리즘을 학습(Learning)하는 과정은, 특징(Features)이 이미 정해진 데이터를 사용하여학습이 진행되게 되는데, 이때 각 데이터에 정해진 특징을 레이블(Label)이라 하며, 레이블이 있는 데이터들의 집합을 트레이닝 셋(Training Set)이라고도 한다. 예를 들어, 강아지와 강아지 사진을 짝지어둔 데이터가 존재한다고 가정하면, 인공지능 알고리즘 학습 과정은, 강아지를 식별하기 위하여 강아지 사진, 즉 강아지-강아지 사진(트레이닝 셋)을 계속 학습시키는 것이고, 강아 지에 해당하는 사진, 즉 강아지 사진을 계속하여 학습시키다보면, 이후 임의의 사진이 입력(Query)으로 들어온 경우, 해당 사진이 강아지의 사진인지 아닌지, 또, 강아지의 종류는 무엇인지 등을 파악할 수 있게 된다. 또, LSTM은, 과거 학습결과를 현재 학습에 사용하는 딥러닝 네트워크인 RNN(Recurrent Neural Network)의 일종인데, 셀 상태(Cell State)를 통해 학습이 반복됨에 따라 과거 학습 정보가 사라지는 장기 의존성(Long-Term Dependency) 문제를 해결한 알고리즘이다. LSTM은 신경망(Neural Network) 모듈을 반복시키는 체인과 같은 형 태로 구성되고, 인공지능부에서도 CNN 과정 이후에 LSTM 과정이 실행되어 특징을 재추출한다. LSTM의 구조는 순환신경망의 일반적인 신경들을 내부에 작은 메모리를 가진 LSTM 셀로 교체한다. 이 LSTM 셀들 은 일반적인 순환신경망과 같이 연결되어 있어서, 셀 내부의 상태가 여러 단계에 걸친 오류를 기억하는 것을 도 와주며, 상태를 유지하기 위해서 게이트(Gate)들로 이루어져 있다. 입력 게이트와 망각 게이트 및 출력 게이트 등을 이용하여 출력값을 조절할 수 있는데, 입력 게이트는 입력값을 얼마나 받아들일지를 결정하고, 망각 게이 트는 이전의 셀 내부의 상태를 얼마나 잊어버릴지를 결정하며, 출력 게이트는 얼마나 출력할지를 결정한다. 여 기서, 망각 게이트는, 입력 게이트와 동일한 형태로, 단지 곱해지는 가중치가 망각 게이트로 이어지는 가중치로 변화하고, 이전 시간에 있던 입력 데이터의 영향력을 반영할지 혹은 반영하지 않을지를 결정한다. 입력 게이트 는, 현재 시간의 입력 데이터에 입력 게이트로 이어지는 가중치를 곱하여 더한 값과, 이전 시간의 메모리 블럭 의 출력값과 셀 출력값에 입력 게이트로 이어지는 가중치를 곱한 값을 더하여 입력 게이트의 출력값을 계산하게 되고, 현재 시간에 받은 입력 데이터의 영향력을 반영할지의 여부를 결정한다. LSTM은, 이처럼 셀 상태 값을 얼마나 잊어버리고, 새로운 입력 값을 얼마나 받아들일지 결정하여 더하는 구조이 다. 이 과정이 반복되어도 기울기가 소멸하여 학습할 수 없어지는 일이 발생 하지 않는다. LSTM은 표준 순환 신경망과 같은 방법으로 은닉 변수를 거쳐 최종 출력 값을 계산하지만, 은닉 계층의 변수 계산 과정에서 게이트 들을 적절하게 이용하여 정보의 흐름을 조절한다. 이러한 결과로 LSTM 셀을 사용한 순환신경망은 시간축에 따 라 변화하는 시계열데이터라도 기울기 소실 문제없이 처리할 수 있는 구조이다. 상술한 구조로 인하여 이미지 (스펙트로그램)로부터 CNN 및 LSTM을 거쳐 특징을 추출하고, 추출된 특징(특징 데이터)과, 기준값인 레이블을 비교하면서 학습결과가 제대로 되었는지를 오차를 구함으로써 파악하고, 오차가 최소치인 가중치(LSTM에서 사용 됨)를 기억하도록 저장함으로써 이후 쿼리인 질의가 입력되었을 때, 질의에 대응하는 가중치를 적용하고 STFT, CNN, LSTM을 순차적으로 거침으로써 사용자의 호흡이나 발음 또는 연음 등이 어떠한 상태인지를 진단하게 될 수 있다. 이하, 상술한 도 2의 학습 서비스 제공 서버의 구성에 따른 동작 과정을 도 3 및 도 4를 예로 들어 상세히 설명 하기로 한다. 다만, 실시예는 본 발명의 다양한 실시예 중 어느 하나일 뿐, 이에 한정되지 않음은 자명하다 할 것이다. 도 3을 참조하면, (a) 학습 서비스 제공 서버는 적어도 하나의 교수자 단말로부터 문장 데이터, 원어 민 발화 데이터 등을 업로드받을 수 있다. 만약, 저작권의 라이센싱 계약을 하거나 본 발명의 플랫폼의 저작자 가 공유해준 교재가 존재한다면 학습 서비스 제공 서버는 사용자 단말로부터 해당 교재도 업로드받을 수 있다. 이렇게 학습 서비스 제공 서버가 문장 데이터 및 원어민 발화 데이터를 입력받으면, 학습 서비 스 제공 서버는 원어민 발화 데이터를 이용하여 전처리를 한 후 소리 데이터 및 진동 데이터로 나누고 학 습을 진행하여 인공지능 알고리즘을 모델링하는 경우, (b) 이후 사용자가 문장을 읽은 사용자 발화 데이터와 비 교를 한 후 비교결과를 제공할 수 있게 된다. 도 4a 내지 도 4f와 같이 교수자 단말은, 호흡법 및 쉐도잉 등에 대한 영상이나 콘텐츠를 제공하고, 사용 자 단말에서 이를 출력하면서 사용자 단말의 음성 발화를 인식 및 입력받아 바로 학습 서비스 제공 서버로 전달함으로서 그 결과를 사용자 단말에서 받아볼 수 있도록 한다. 교수자 단말은 텍스 트, 파일, 이미지, 사진 및 동영상 등의 콘텐츠를 학습 서비스 제공 서버로 업로드할 수 있고, 학습 서비 스 제공 서버를 통하여 실시간으로 적어도 하나의 사용자 단말로 중계(Live)도 가능할 수 있다. 이와 같은 도 2 내지 도 4의 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 방법에 대해서 설명되지 아 니한 사항은 앞서 도 1을 통해 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 방법에 대하여 설명된 내 용과 동일하거나 설명된 내용으로부터 용이하게 유추 가능하므로 이하 설명을 생략하도록 한다.도 5는 본 발명의 일 실시예에 따른 도 1의 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템에 포 함된 각 구성들 상호 간에 데이터가 송수신되는 과정을 나타낸 도면이다. 이하, 도 5를 통해 각 구성들 상호간 에 데이터가 송수신되는 과정의 일 예를 설명할 것이나, 이와 같은 실시예로 본원이 한정 해석되는 것은 아니며, 앞서 설명한 다양한 실시예들에 따라 도 5에 도시된 데이터가 송수신되는 과정이 변경될 수 있음은 기 술분야에 속하는 당업자에게 자명하다. 도 5를 참조하면, 학습 서비스 제공 서버는, 적어도 하나의 종류의 문장을 음성으로 발화한 적어도 하나의 원어 민 발화 데이터를 데이터베이스로 저장한다(S5100). 그리고, 학습 서비스 제공 서버는, 사용자 단말에서 원어민 발화 데이터를 선택하는 경우 사용자 단말로 실시간 스트리밍되도록 제어하고(S5200), 사용자 단말에서 입력된 사용자 발화 데이터를 수신하여 원어민 발화 데이터 간의 비교 결과를 산출한다(S5300). 마지막으로, 학습 서비스 제공 서버는, 산출된 비교 결과를 사용자 단말로 전송한다(S5400). 상술한 단계들(S5100~S5400)간의 순서는 예시일 뿐, 이에 한정되지 않는다. 즉, 상술한 단계들(S5100~S5400)간 의 순서는 상호 변동될 수 있으며, 이중 일부 단계들은 동시에 실행되거나 삭제될 수도 있다. 이와 같은 도 5의 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 방법에 대해서 설명되지 아니한 사항 은 앞서 도 1 내지 도 4를 통해 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 방법에 대하여 설명된 내용과 동일하거나 설명된 내용으로부터 용이하게 유추 가능하므로 이하 설명을 생략하도록 한다. 도 5를 통해 설명된 일 실시예에 따른 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 방법은, 컴퓨터에 의해 실행되는 애플리케이션이나 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매체 의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그 램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분 리형 및 비분리형 매체를 모두 포함한다. 전술한 본 발명의 일 실시예에 따른 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 방법은, 단말기에 기본적으로 설치된 애플리케이션(이는 단말기에 기본적으로 탑재된 플랫폼이나 운영체제 등에 포함된 프로그램 을 포함할 수 있음)에 의해 실행될 수 있고, 사용자가 애플리케이션 스토어 서버, 애플리케이션 또는 해당 서비 스와 관련된 웹 서버 등의 애플리케이션 제공 서버를 통해 마스터 단말기에 직접 설치한 애플리케이션(즉, 프로 그램)에 의해 실행될 수도 있다. 이러한 의미에서, 전술한 본 발명의 일 실시예에 따른 원어민 호흡법을 이용 한 영어 말하기 학습 서비스 제공 방법은 단말기에 기본적으로 설치되거나 사용자에 의해 직접 설치된 애플리케 이션(즉, 프로그램)으로 구현되고 단말기에 등의 컴퓨터로 읽을 수 있는 기록매체에 기록될 수 있다."}
{"patent_id": "10-2020-0171437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4a 도면4b 도면4c 도면4d 도면4e 도면4f 도면4g 도면5"}
{"patent_id": "10-2020-0171437", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 시스템을 설명하기 위한 도면이다. 도 2는 도 1의 시스템에 포함된 학습 서비스 제공 서버를 설명하기 위한 블록 구성도이다. 도 3 및 도 4는 본 발명의 일 실시예에 따른 원어민 호흡법을 이용한 영어 말하기 학습 서비스가 구현된 일 실 시예를 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시예에 따른 원어민 호흡법을 이용한 영어 말하기 학습 서비스 제공 방법을 설명하기 위 한 동작 흐름도이다."}
