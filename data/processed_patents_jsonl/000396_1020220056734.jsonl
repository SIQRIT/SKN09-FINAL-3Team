{"patent_id": "10-2022-0056734", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0029495", "출원번호": "10-2022-0056734", "발명의 명칭": "클라우드 서버, 엣지 서버 및 이를 이용한 지능 모델 생성 방법", "출원인": "한국전자통신연구원", "발명자": "장민수"}}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "엣지 서버 및 클라우드 서버에서 수행되는 방법에 있어서,엣지 서버가 사용자 단말의 지능 모델 생성 요청을 수신하는 단계;상기 지능 모델 생성 요청에 상응하는 지능 모델을 생성하는 단계; 및상기 생성된 지능 모델을 조정하는 단계;를 포함하는 것을 특징으로 하는 지능 모델 생성 방법."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 지능 모델을 생성하는 단계는엣지 서버가 상기 지능 모델의 생성에 실패하면, 클라우드 서버에 지능 모델 생성을 요청하는 단계;상기 클라우드 서버에서 생성된 지능 모델을 수신하는 단계;를 더 포함하는 것을 특징으로 하는 지능 모델 생성 방법."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 클라우드 서버는 제1 클라우드 서버 및 상기 제1 클라우드 서버보다 큰 용량을 갖는 제2 클라우드 서버를 포함하는 것을 특징으로 하는 지능 모델 생성 방법."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 제1 클라우드 서버는 상기 지능 모델의 생성에 실패하면, 상기 제2 클라우드 서버에 지능 모델 생성을 요청하는 것을 특징으로 하는 지능 모델 생성 방법."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 2에 있어서,상기 지능 모델 생성 요청은태스크 식별자, 원시 데이터, 주석, 데이터 공개 범위 및 목표 레이블을 포함하는 것을 특징으로 하는 지능 모델 생성 방법."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 지능 모델을 생성하는 단계는상기 지능 모델 생성 요청에 기반하여 기본 지능 모델을 선정하는 단계;상기 기본 지능 모델의 레이블 목록을 목표 레이블 목록에 상응하도록 변형하는 단계; 및상기 변형된 지능 모델의 학습을 수행하는 단계;공개특허 10-2023-0029495-3-를 포함하는 것을 특징으로 하는 지능 모델 생성 방법."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 변형된 지능 모델의 학습을 수행하는 단계는기저장된 데이터셋을 이용하는 제1 학습 단계; 및상기 지능 모델 생성 요청에 포함된 원시 데이터를 이용하는 제2 학습 단계;를 더 포함하는 것을 특징으로 하는 지능 모델 생성 방법."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 5에 있어서,상기 클라우드 서버에 지능 모델 생성을 요청하는 단계는상기 데이터 공개 범위에 기반하여 상기 클라우드 서버에 전송할 원시 데이터를 설정하는 것을 특징으로 하는지능 모델 생성 방법."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 생성된 지능 모델을 조정하는 단계는상기 클라우드 서버에 전송되지 않은 원시 데이터를 이용하여 수행되는 것을 특징으로 하는 지능 모델 생성 방법."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "사용자 단말 및 다른 서버와 통신하는 통신부;지능 모델 생성을 위한 데이터가 저장된 저장부;지능 모델 생성 요청에 상응하는 지능 모델을 생성하는 모델 생성부; 및상기 생성된 지능 모델을 조정하는 조정부;를 포함하는 것을 특징으로 하는 엣지 서버."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서,상기 통신부는 상기 모델 생성부가 상기 지능 모델의 생성에 실패하면, 클라우드 서버에 지능 모델 생성을 요청하고, 상기 클라우드 서버에서 생성된 지능 모델을 수신하는 것을 특징으로 하는 엣지 서버."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 클라우드 서버는 제1 클라우드 서버 및 상기 제1 클라우드 서버보다 큰 용량을 갖는 제2 클라우드 서버를 포함하는 것을 특징으로 하는 엣지 서버."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 12에 있어서,상기 제1 클라우드 서버는 상기 지능 모델의 생성에 실패하면, 상기 제2 클라우드 서버에 지능 모델 생성을 요공개특허 10-2023-0029495-4-청하는 것을 특징으로 하는 엣지 서버."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 11에 있어서,상기 지능 모델 생성 요청은태스크 식별자, 원시 데이터, 주석, 데이터 공개 범위 및 목표 레이블을 포함하는 것을 특징으로 하는 엣지 서버."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 10에 있어서,상기 모델 생성부는상기 지능 모델 생성 요청에 기반하여 기본 지능 모델을 선정하고, 상기 기본 지능 모델의 레이블 목록을 목표 레이블 목록에 상응하도록 변형하고, 상기 변형된 지능 모델의 학습을 수행하는 것을 특징으로 하는 엣지 서버."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 14에 있어서,상기 통신부는상기 데이터 공개 범위에 기반하여 상기 원시 데이터를 상기 클라우드 서버에 전송하는 것을 특징으로 하는 엣지 서버."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 16에 있어서,상기 조정부는상기 클라우드 서버에 전송되지 않은 원시 데이터를 이용하여 상기 지능 모델을 조정하는 것을 특징으로 하는엣지 서버."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "엣지 서버의 지능 모델 생성 요청을 수신하는 통신부;지능 모델 생성을 위한 데이터가 저장된 저장부; 및상기 지능 모델 생성 요청에 상응하는 지능 모델을 생성하는 모델 생성부; 를 포함하고,상기 지능 모델 생성 요청은 태스크 식별자, 원시 데이터, 주석, 데이터 공개 범위 및 목표 레이블을 포함하는것을 특징으로 하는 클라우드 서버."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 18에 있어서,상기 통신부는상기 모델 생성부에서 상기 지능 모델의 생성에 실패하면, 다른 클라우드 서버에 지능 모델 생성을 요청하는 것을 특징으로 하는 클라우드 서버."}
{"patent_id": "10-2022-0056734", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "청구항 18에 있어서,공개특허 10-2023-0029495-5-상기 지능 모델 생성 요청의 원시 데이터는상기 엣지 서버에서 상기 데이터 공개 범위에 기반하여 전송되는 것을 특징으로 하는 클라우드 서버."}
{"patent_id": "10-2022-0056734", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 지능 모델 생성 방법은 엣지 서버가 사용자 단말의 지능 모델 생성 요청을 수신하는 단계, 상기 지능 모델 생성 요청에 상응하는 지능 모델을 생성하는 단계 및 상기 생성된 지능 모델을 조정하는 단계를 포함한다."}
{"patent_id": "10-2022-0056734", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 본 발명은 기계학습 기반 지능 모델의 생성, 배포, 관리 기술에 관한 것이다. 구체적으로, 클라우드 서버 및 엣지 서버에서 수행되는 지능 모델 생성 및 배포 방법에 관한 것이다."}
{"patent_id": "10-2022-0056734", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 서비스를 효과적으로 구현하고 실행하기 위해서는 단말의 요구사항과 적용 환경에 최적화된 양질의 지 능 모델을 손쉽게 확보하여 활용할 수 있어야 한다. 종래에 인공지능 모델을 확보하고 활용하기 위해 다양한 방 식을 활용할 수 있다. 먼저, 전문가가 지능 모델 개발의 전 과정을 수행할 수 있다. 인공지능 전문가는 인공지능 모델을 훈련하기 위 한 데이터셋을 확보하고, 인공지능 모델의 구조를 선택하거나 설계하여 구현한 후, 데이터셋을 이용하여 인공지 능 모델이 원하는 수준의 성능으로 동작할 때까지 훈련하고 시험한다. 그 결과로 생성한 지능 모델을 응용 환경 에 설치하고 활용한다. 이때, 지능 모델을 확보하기 위한 데이터 확보, 프로그램 개발, 훈련을 모두 수행해야 하므로 지능 모델 확보 난이도가 높고, 비용이 크며, 시간이 오래 걸린다. 응용과 적용 환경에 최적화된 지능 모델을 확보할 수 있는 장점이 있는 반면, 지능 모델 생성 담당자의 전문성과 생성 방식에 따라 지능 모델의 성능과 품질에 편차가 발 생할 수 있다. 인공지능 전문가가 기공개된 인공지능 모델 중 필요에 적합한 것을 선택하여 활용할 수도 있다. 웹 검색을 통해 적합한 인공지능 모델을 찾고, 모델과 관련 코드를 확보하여 응용 프로그램에 결합하여 활용한다. 수동 개발 훈 련 확보 방법에 비해 난이도가 낮고, 비용이 적으며, 시간을 절약할 수 있다. 그러나, 응용과 적용 환경에 최적화된 모델을 확보하기 힘들다. 최적화된 모델을 확보하려면 대량의 훈련 평가 데이터를 수집 구축해야 하므로 비용과 시간이 많이 든다. 지능 모델의 성능과 품질에 관한 정보가 가용한 경우 참조하여 품질 수준을 확보할 수 있으나, 관련 정보가 제공되지 않는 경우 지능 모델의 성능과 품질을 보장할 수 없다. 인공지능 전문가 또는 일반 개발자가 클라우드 플랫폼 기반 인공지능 서비스를 활용하는 방법도 있다. 클라우 드 플랫폼에서 제공하는 인공지능 서비스 중 필요에 맞는 것을 선정한 후 서비스 제공 업체가 제공하는 클라이 언트-서버 프로그래밍 인터페이스를 활용하여 인공지능 서비스 실행을 요청하고 응답을 받을 수 있다. 이러한 인공지능 모델 서비스의 예로 구글 클라우드(Google Cloud), 마이크로소프트 애저 인지 서비스(Microsoft Azure Cognitive Services), 인텔 왓슨(Intel Watson) 등이 있다. 이 방법은 활용 난이도가 낮아 지능 모델 확보 시간과 비용을 절약할 수 있다. 그러나, 사전 제작된 지능 모델 을 서비스로 활용하므로 사용자가 개발할 응용과 적용 환경에 최적화된 모델을 확보하기 힘들다. 또한, 클라우 드 플랫폼 서비스를 활용하기 위해서는 사용자의 모든 데이터를 클라우드 플랫폼에 전송해야 하기 때문에 데이 터 보안 문제가 발생할 수 있다. 최근 등장한 클라우드 기반 지능 모델 생성 자동화 서비스를 활용하는 방법도 있다. 구글의 AutoML 서비스는 사용자가 제공한 훈련 데이터를 이용하여 지능 모델을 훈련함으로써 사용자가 원하는 최적 지능 모델을 생성하 여 제공한다. 이 방법은 난이도가 낮고, 비용이 적게 들며, 시간이 짧게 걸릴 뿐 아니라 응용과 적용 환경에 최 적화된 모델을 확보하기 용이하다. 전문 기업이 사전 검증된 프로세스에 의해 지능 모델을 생성하므로 성능과 품질도 양호할 수 있다. 단, 지능 모델을 훈련하기에 충분한 양의 데이터셋을 구축하여 제공해야 하므로, 데이터 확보의 측면으로 보면 난이도, 비용, 시간이 모두 적지 않게 소요된다. 데이터가 없다면 지능 모델을 확보할 수 없다. 또한, 데이터를 모두 클라우드 플랫폼에 전송하여 지능 모델을 훈련해야 하므로 데이터 보안 문제가 발생할 수 있다.선행기술문헌 특허문헌 (특허문헌 0001) 국내 공개특허공보 제10-2020-0052449호(발명의 명칭: 인공지능 서비스를 위한 연결된 데이터 아키텍처 시스템 및 이에 대한 제어방법)"}
{"patent_id": "10-2022-0056734", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 클라우드와 엣지로 구성된 복합 컴퓨팅 환경을 통해 지능 모델을 생성하여 배포하는 방법을 제공하는 것이다. 또한, 본 발명의 목적은 낮은 비용으로 빠르게 응용에 최적화된 지능 모델을 확보하는 것이다. 또한, 본 발명의 목적은 데이터가 없거나 소량의 데이터만 보유한 경우에도 응용 서비스와 환경에 최적화된 지 능 모델을 생성하는 것이다. 또한, 본 발명의 목적은 지능 모델 생성 과정을 이원화하여 데이터의 외부 노출을 방지함으로써 보안 문제와 사 생활 침해 문제를 방지하는 것이다."}
{"patent_id": "10-2022-0056734", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 지능 모델 생성 방법은 엣지 서버가 사용자 단말의 지능 모델 생성 요청을 수신하는 단계, 상기 지능 모델 생성 요청에 상응하는 지능 모델을 생성하는 단계 및 상 기 생성된 지능 모델을 조정하는 단계를 포함한다. 이때, 상기 지능 모델을 생성하는 단계는 엣지 서버가 상기 지능 모델의 생성에 실패하면, 클라우드 서버에 지 능 모델 생성을 요청하는 단계 및 상기 클라우드 서버에서 생성된 지능 모델을 수신하는 단계를 더 포함할 수 있다. 이때, 상기 클라우드 서버는 제1 클라우드 서버 및 상기 제1 클라우드 서버보다 큰 용량을 갖는 제2 클라우드 서버를 포함할 수 있다. 이때, 상기 제1 클라우드 서버는 상기 지능 모델의 생성에 실패하면, 상기 제2 클라우드 서버에 지능 모델 생성 을 요청할 수 있다. 이때, 상기 지능 모델 생성 요청은 태스크 식별자, 원시 데이터, 주석, 데이터 공개 범위 및 목표 레이블을 포 함할 수 있다. 이때, 상기 지능 모델을 생성하는 단계는 상기 지능 모델 생성 요청에 기반하여 기본 지능 모델을 선정하는 단 계, 상기 기본 지능 모델의 레이블 목록을 목표 레이블 목록에 상응하도록 변형하는 단계 및 상기 변형된 지능 모델의 학습을 수행하는 단계를 포함할 수 있다. 이때, 상기 변형된 지능 모델의 학습을 수행하는 단계는 기저장된 데이터셋을 이용하는 제1 학습 단계 및 상기 지능 모델 생성 요청에 포함된 원시 데이터를 이용하는 제2 학습 단계를 포함할 수 있다. 이때, 상기 클라우드 서버에 지능 모델 생성을 요청하는 단계는 상기 데이터 공개 범위에 기반하여 상기 클라우 드 서버에 전송할 원시 데이터를 설정할 수 있다. 이때, 상기 생성된 지능 모델을 조정하는 단계는 상기 클라우드 서버에 전송되지 않은 원시 데이터를 이용하여 수행될 수 있다. 또한, 상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 엣지 서버는 사용자 단말 및 다른 서버와 통신 하는 통신부, 지능 모델 생성을 위한 데이터가 저장된 저장부, 지능 모델 생성 요청에 상응하는 지능 모델을 생 성하는 모델 생성부 및 상기 생성된 지능 모델을 조정하는 조정부를 포함한다.이때, 상기 통신부는 상기 모델 생성부가 상기 지능 모델의 생성에 실패하면, 클라우드 서버에 지능 모델 생성 을 요청하고, 상기 클라우드 서버에서 생성된 지능 모델을 수신할 수 있다. 이때, 상기 클라우드 서버는 제1 클라우드 서버 및 상기 제1 클라우드 서버보다 큰 용량을 갖는 제2 클라우드 서버를 포함할 수 있다. 이때, 상기 제1 클라우드 서버는 상기 지능 모델의 생성에 실패하면, 상기 제2 클라우드 서버에 지능 모델 생성 을 요청할 수 있다. 이때, 상기 지능 모델 생성 요청은 태스크 식별자, 원시 데이터, 주석, 데이터 공개 범위 및 목표 레이블을 포 함할 수 있다. 이때, 상기 모델 생성부는 상기 지능 모델 생성 요청에 기반하여 기본 지능 모델을 선정하고, 상기 기본 지능 모델의 레이블 목록을 목표 레이블 목록에 상응하도록 변형하고, 상기 변형된 지능 모델의 학습을 수행할 수 있 다. 이때, 상기 통신부는 상기 데이터 공개 범위에 기반하여 상기 원시 데이터를 상기 클라우드 서버에 전송할 수 있다. 이때, 상기 조정부는 상기 클라우드 서버에 전송되지 않은 원시 데이터를 이용하여 상기 지능 모델을 조정할 수 있다. 또한, 상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 클라우드 서버는 엣지 서버의 지능 모델 생성 요청을 수신하는 통신부, 지능 모델 생성을 위한 데이터가 저장된 저장부, 상기 지능 모델 생성 요청에 상응하 는 지능 모델을 생성하는 모델 생성부를 포함하고, 상기 지능 모델 생성 요청은 태스크 식별자, 원시 데이터, 주석, 데이터 공개 범위 및 목표 레이블을 포함할 수 있다. 이때, 상기 통신부는 상기 모델 생성부에서 상기 지능 모델의 생성에 실패하면, 다른 클라우드 서버에 지능 모 델 생성을 요청할 수 있다. 이때, 상기 지능 모델 생성 요청의 원시 데이터는 상기 엣지 서버에서 상기 데이터 공개 범위에 기반하여 전송 될 수 있다."}
{"patent_id": "10-2022-0056734", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 클라우드와 엣지로 구성된 복합 컴퓨팅 환경을 통해 지능 모델을 생성하여 배포하는 방법을 제공할 수 있다. 또한, 본 발명은 낮은 비용으로 빠르게 응용에 최적화된 지능 모델을 확보할 수 있다. 또한, 본 발명은 데이터가 없거나 소량의 데이터만 보유한 경우에도 응용 서비스와 환경에 최적화된 지능 모델 을 생성할 수 있다. 또한, 본 발명은 지능 모델 생성 과정을 이원화하여 데이터의 외부 노출을 방지함으로써 보안 문제와 사생활 침 해 문제를 방지할 수 있다."}
{"patent_id": "10-2022-0056734", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2022-0056734", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 비록 \"제1\" 또는 \"제2\" 등이 다양한 구성요소를 서술하기 위해서 사용되나, 이러한 구성요소는 상기와 같은 용 어에 의해 제한되지 않는다. 상기와 같은 용어는 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용될 수 있다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있다. 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세 서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 또는 \"포함하는(comprising)\"은 언급된 구성요소 또는 단계가 하나 이상의 다른 구성요소 또는 단 계의 존재 또는 추가를 배제하지 않는다는 의미를 내포한다."}
{"patent_id": "10-2022-0056734", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 해석될 수 있다. 또한, 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 도 1은 본 발명의 일 실시예에 따른 지능 모델 생성 방법을 나타낸 흐름도이다. 본 발명의 일 실시예에 따른 지능 모델 생성 및 배포 방법은 엣지 서버 및 클라우드 서버에서 수행될 수 있다. 단, 사용자 단말의 지능 모델 생성 요청에 따라 지능 모델 생성은 엣지 서버에서만 수행될 수도 있으며, 본 발 명의 범위가 이에 한정되는 것은 아니다. 도 1을 참조하면, 본 발명의 실시예에 따른 방법은 엣지 서버가 사용자 단말의 지능 모델 생성 요청을 수신하는 단계(S110), 상기 지능 모델 생성 요청에 상응하는 지능 모델을 생성하는 단계(S120) 및 상기 생성된 지능 모델 을 조정하는 단계(S130)를 포함한다. 이때, 상기 지능 모델을 생성하는 단계(S120)는 엣지 서버가 상기 지능 모델의 생성에 실패하면, 클라우드 서버 에 지능 모델 생성을 요청하는 단계 및 상기 클라우드 서버에서 생성된 지능 모델을 수신하는 단계를 더 포함할 수 있다. 이때, 상기 클라우드 서버는 제1 클라우드 서버 및 상기 제1 클라우드 서버보다 큰 용량을 갖는 제2 클라우드 서버를 포함할 수 있다.이때, 상기 제1 클라우드 서버는 상기 지능 모델의 생성에 실패하면, 상기 제2 클라우드 서버에 지능 모델 생성 을 요청할 수 있다. 이때, 상기 지능 모델 생성 요청은 태스크 식별자, 원시 데이터, 주석, 데이터 공개 범위 및 목표 레이블을 포 함할 수 있다. 이때, 상기 지능 모델을 생성하는 단계(S120)는 상기 지능 모델 생성 요청에 기반하여 기본 지능 모델을 선정하 는 단계, 상기 기본 지능 모델의 레이블 목록을 목표 레이블 목록에 상응하도록 변형하는 단계 및 상기 변형된 지능 모델의 학습을 수행하는 단계를 포함할 수 있다. 이때, 상기 변형된 지능 모델의 학습을 수행하는 단계는 기저장된 데이터셋을 이용하는 제1 학습 단계 및 상기 지능 모델 생성 요청에 포함된 원시 데이터를 이용하는 제2 학습 단계를 포함할 수 있다. 이때, 상기 클라우드 서버에 지능 모델 생성을 요청하는 단계는 상기 데이터 공개 범위에 기반하여 상기 클라우 드 서버에 전송할 원시 데이터를 설정할 수 있다. 이때, 상기 생성된 지능 모델을 조정하는 단계(S130)는 상기 클라우드 서버에 전송되지 않은 원시 데이터를 이 용하여 수행될 수 있다. 도 2는 본 발명의 일 실시예에 따른 지능 모델 생성 방법을 보다 상세히 나타낸 흐름도이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 지능 모델 생성 방법은 사용자 단말, 엣지 서버 및 클라 우드 서버에서 수행될 수 있다. 사용자 단말은 엣지 서버에 서비스 제공에 필요한 지능 모델의 생성을 요청한다(S11). 지능 모델 생성 요청을 수신한 엣지 서버는 엣지 서버 내에서 지능 모델을 생성할 수 있는지 판단한다(S12). 지능 모델 생성이 가능한 경우(S12) 엣지 서버는 지능 모델을 생성하고(S13) 지능 모델을 미세 조정하여(S20) 사용자 단말 에 전송한다(S21). 이때, 엣지 서버 내에서 지능 모델을 생성하는 경우 상기 지능 모델을 미세 조정하는 단 계(S20)는 생략될 수 있다. 엣지 서버는 지능 모델의 생성이 불가능한 경우(S120) 클라우드 서버에 지능 모델 생성 요청을 전달한 다(S14). 이때, 상기 클라우드 서버는 엣지 서버보다 큰 컴퓨팅 자원을 가진 서버를 지칭하는 것으로, 그 용어에 의해 본 발명의 범위가 제한되는 것은 아니다. 지능 모델 생성 요청을 수신한 클라우드 서버는 지능 모델 생성 가능 여부를 판단하고(S15), 지능 모델 생 성이 가능하면 지능 모델을 생성하여 엣지 서버에 전송한다. 엣지 서버는 수신한 지능 모델을 미세 조정 (S20)하여 사용자 단말에 전송한다(S21). 클라우드 서버에서 지능 모델 생성이 불가능한 경우(S15) 다른 클라우드 서버에 지능 모델의 생성을 요청한다 (S17). 이때, 상기 다른 클라우드 서버는 상기 클라우드 서버보다 큰 컴퓨팅 자원을 갖는 서버에 상응할 수 있다. 다른 클라우드 서버로부터 지능 모델을 수신한(S18) 클라우드 서버는 이를 엣지 서버로 전송한다 (S19). 엣지 서버는 수신한 지능 모델을 미세 조정(S20)하여 사용자 단말에 전송한다(S21). 이때, 상기 다른 클라우드 서버에 지능 모델 생성을 요청하는 단계(S17)는 상기 지능 모델을 생성할 수 있는 클 라우드 서버를 찾을 때까지 반복적으로 또는 계층적으로 수행될 수 있다. 이하, 상세한 실시예를 통해 본 발명 을 자세히 설명하기로 한다. 도 3은 본 발명의 일 실시예에 따른 지능 모델 배포 시스템의 구성을 나타낸 도면이다. 도 3을 참조하면, 본 발명의 실시예에 따른 시스템은 단말, 엣지 서버 및 클라우드 서버로 구성 될 수 있다. 상기 단말은 로봇, 스마트 스피커 등 지능적인 서비스를 제공하는 장치로서 지능 모델을 요청하고 활용한 다. 상기 엣지 서버는 망을 통해 단말과 연결된 컴퓨팅 시스템으로서 일반적으로 단말의 위치와 물리적으로 가까운 장소에 존재한다. 예를 들어, 단말이 식당 서비스 로봇인 경우, 엣지 서버는 로봇을 운영하는 식당안에 설치된 서버 컴퓨터가 될 수 있다. 엣지 서버는 클라우드 서버와 달리 지능 모델을 활용하는 지역, 예를 들어 식당과 같은 매장, 안에서 활용 하고 해당 지역의 운영 주체가 관리할 수 있다. 이때, 엣지 서버는 개인정보보호 법 규정 또는 운영 주체 가 정한 규칙에 따라 지능 모델의 생성과 활용을 위해 제공해야 하는 데이터 중 외부 유출이 가능한 것과 그렇 지 않은 것을 구분하고 외부 유출이 가능한 데이터만 외부 서버로 전송함으로 데이터 보안 문제를 해결할 수 있 다. 본 발명에 의한 지능 모델 생성 방법에 의하면 외부 공개 가능한 데이터로 클라우드에서 생성된 지능 모델을 엣 지 서버에서 보안 데이터로 재훈련하고 최적화함으로써 데이터 보안 문제를 해결하면서 원하는 지능 모델을 확 보할 수 있다. 클라우드 서버는 원격지에서 운영되는 컴퓨팅 장치로서 단말이나 엣지 서버보다 풍부한 컴퓨팅 자원을 지 니고 있으며 다수의 엣지 서버 또는 단말을 대상으로 요청을 처리할 수 있다. 본 발명에 따르면 클라우드 서버 는 여러 단계에 걸쳐 계층적으로 연결될 수 있다. 엣지 서버에 직접 연결된 클라우드 서버에서 지능 모델 생성 과 배포가 불가능한 경우 다음 단계의 클라우드 서버로 요청을 전송해서 처리한다. 바람직하게는 더 멀리 떨어 진, 즉 단계가 높은, 클라우드 서버일 수록 저장소 규모와 컴퓨팅 자원이 더 커서 더 많은 지능 모델과 데이터 셋을 저장할 수 있고 더 방대한 지능 모델 생성 배포가 가능하다. 엣지 서버와 클라우드 서버는 지능 리파지토리, 지능 리파지토리 인터페이스, 지능 관리자 를 통해 지능 모델을 생성하고 배포하는 기능을 수행한다. 지능 리파지토리는 지능 모델을 생성하고 최적화하는데 필요한 정보를 저장 관리한다. 상기 정보는 지능 모델이 다루는 대상들을 지시하는 레이블(Label), 지능 모델을 훈련하고 평가하는데 사용하는 데이터셋 (Dataset), 지능 모델의 구조와 내용, 지능 모델을 기반으로 추론, 훈련, 전이학습 등을 수행하는 프로그램 등 을 모두 포괄한다. 지능 리파지토리 인터페이스는 상기 모든 정보를 저장하고 열람하는데 사용하는 메시지 또는 프로그래밍 인터페이스이다. 지능 관리자는 단말, 엣지 서버 또는 하위 클라우드 서버로부터 요청 받은 지능을 지능 리파지토리를 활용하여 생성하고 배포하는 기능을 수행한다. 이때, 서버 내에서 자체적으로 지능 모델을 생성하지 못하는 경 우 상위 서버로 지능 요구를 전달하여 지능 모델을 배포 받을 수 있다. 지능 요구 프로파일은 단말이 필요로 하는 지능의 사양을 기록한 데이터 구조체로 지능 모델이 수행해야 할 기능과 지능 모델 훈련에 필요한 데이터를 포함한다. 본 발명의 일 실시예에서 지능 모델 전송은 생성한 '지능 모델'과 그 모델을 구동하여 기능을 실행할 수 있는 '프로그램'을 함께 전송하는 방식으로 구현될 수 있다. 단말은 전송 받은 '지능 모델'을 입력하여 '프로 그램'을 실행함으로써 생성된 지능 모델의 추론 기능을 활용할 수 있다. 이하, 본 발명의 실시예에 따른 지능 요구 프로파일의 구조를 상세히 설명한다. 지능 모델의 생성과 배포는 지능 요구 프로파일을 전송하여 이루어진다. 지능 요구 프로파일은 지능 모델을 생성하는데 필요한 단서 정보를 포함한다. 본 발명의 일 실시예에서 지능 요구 프로파일은 태스크 명세와 목적 데이터를 포함한다. 태스크 명세는 지능 모델이 수행해야 하는 작업 내용을 기술하며, 엣지 서버와 클라우드 서버에서 지능 모델을 검색하고 선별하는데 활용한다. 본 발명의 일 실시예에서 태스크 명세는 태스크 식별자, 입력 정보, 출력 정보 를 포함한다. 태스크 구별자는 지능 모델이 수행하는 작업을 지시하는 항목으로서 그 값의 예로 분류(Classification), 검출 (Detection), 의미 분할(Semantic Segmentation), 개체 분할(Instance Segmentation), 자연어 번역(Natural Language Translation), 이미지 캡셔닝(Image Captioning) 등을 포함할 수 있다. 입력 정보는 지능 모델에 입력으로 주어지는 데이터의 형식과 내용을 기술한다. 일실시 예에서 입력 정보는 이 미지(Image), 동영상(Video), 오디오(Audio), 텍스트(Text)와 같이 모달리티를 기반으로 기술할 수 있다. 출력 정보는 지능 모델이 입력을 받아 처리한 뒤 출력하는 출력 데이터의 형식과 내용을 기술한다. 일실시 예에 서 출력 정보는 클래스 구별자(Class ID), 경계 상자(Bounding Box), 픽셀 단위 이미지 마스크(Pixel-wise Image Mask) 등과 같이 기술할 수 있다. 하기 [표 1]은 태스크 명세의 몇 가지 예시를 나타낸다. 표 1 태스크 구별자 입력 출력 설명 classification image class id 이미지를 입력 받아 복수개의 정해진 클래스로 분류 detection image bounding-box 이미지를 입력 받아 특정 사물을 검출하여 영역 좌 표를 출력 detection image (bounding-box, class id)이미지를 입력 받아 사물의 영역과 클래스 아이디를 출력 classification audio class id 오디오 샘플을 입력 받아 정해진 클래스로 분류 classification video class id 비디오 클립을 입력 받아 정해진 클래스로 분류 semantic segmentationimage (image mask, class id)이미지를 입력 받아 특정 부류 별로 사물 영역의 이 미지 마스크를 출력 captioning image sentence 이미지를 입력 받아 이미지 내 장면을 묘사하는 문 장을 출력 captioning video sentence 동영상을 입력 받아 동영상 내 장면을 묘사하는 문 장을 출력 auto-encoding image image 이미지 대상으로 오토인코딩을 수행 목적 데이터(110-2)는 지능 모델을 훈련하거나 최적화하는데 사용할 수 있는 데이터로서 영상, 음성, 텍스트 등 각종 형태의 원시 데이터(110-3), 지능 모델이 원시 데이터를 입력 받아 출력해야 할 정보를 지시하는 데이터 주석(110-4), 각 데이터의 공개 범위(110-5), 그리고 원시 데이터를 제공하지는 않으나 지능 모델이 다뤄야 하 는 대상을 지시하는 목적 정답 레이블(110-6)을 포함한다. 데이터 주석(110-4)은 원시 데이터(110-3) 항목별로 정답을 지시한다. 정답은 분류, 검출, 분할 등 지능 모델 이 수행할 태스크의 종류에 따라 형태가 서로 다를 수 있다. 공개 범위(110-5)는 각 원시 데이터와 데이터 주석을 어느 범위까지 공개할 수 있는지를 표시한다. 데이터 공 개 범위 제한을 통해 지능 모델을 활용하는 개인이나 기업의 사적 정보를 보호하는 목적을 달성할 수 있다. 일 실시예에서 공개 범위는 '지역'과 '전역'으로 기술할 수 있다. 지능 요구 프로파일을 수신한 엣지 서버는 '전역'으로 표시된 데이터는 클라우드 서버로 전송하고 ‘지역’으로 표시된 데이터는 클라우드 서버로 전송하 지 않고 자체 처리함으로 데이터를 보호한다. 목적 정답 레이블 목록(110-6)은 지능 모델이 검출 또는 인식할 대상들의 이름을 포함한다. 지능 모델을 훈련 하는데 활용할 수 있는 데이터가 존재하지 않는 경우 이 목록을 작성하여 프로파일에 포함한다. 도 4는 이미지 분류용 지능 모델을 요청하는 지능 요구 프로파일을 나타낸 예시이다. 도 4를 참조하면, 태스크 명세를 통해 이미지를 입력 받아 분류하고 클래스 구별자를 출력하는 지능 모델을 요 청하고 있음을 알 수 있다. 목적 데이터는 훈련용으로 쓸 수 있는 이미지 파일들을 원시 데이터로 포함하고, 데 이터 주석 안에 각 이미지 파일의 분류 정답을 포함한다. 데이터 보안을 위한 공개 범위도 포함하고 있음을 볼 수 있다. 도 5는 사물 검출 작업용 지능 모델을 요청하는 지능 요구 프로파일을 나타낸 예시이다. 도 5를 참조하면, 태스크 명세를 통해 이미지를 입력 받아 사물을 검출하고 검출된 영역에 클래스 구별자를 부 여하는 지능 모델을 요청하고 있음을 알 수 있다. 목적 데이터는 훈련용으로 쓸 수 있는 이미지 파일들을 원시 데이터로 포함하고, 데이터 주석 안에 각 이미지 안에 포함된 사물의 영역과 클래스 정답을 포함한다. 도 6은 의미 기반 영상 분할 작업용 지능 모델을 요청하는 지능 요구 프로파일을 나타낸 예시이다. 도 6을 참조하면, 태스크 명세를 통해 이미지를 입력 받아 사물 영역을 이미지 마스크의 형태로 분할하고, 분할 한 영역에 클래스 구별자를 부여하는 지능 모델을 요청하고 있음을 알 수 있다. 목적 데이터는 훈련용으로 쓸 수 있는 이미지 파일들을 원시 데이터로 포함하고, 데이터 주석 안에 이미지 마스크로 활용할 이미지의 이름과 클래스 구별자를 포함하고 있다. 도 4 내지 도 6과 같이 다양한 태스크에 적합하게 지능 요구 프로파일을 구성하여 활용할 수 있다. 도 7은 본 발명의 실시예에 따른 지능 리파지토리 구조를 나타낸 블록도이다. 도 7을 참조하면, 지능 리파지토리는 레이블 사전, 데이터셋 저장소, 지능 모델 저장소, 지능 모델 유형 사전, 지능 모델 활용 코드 사전을 포함한다. 레이블 사전은 의미는 같으나 서로 다른 문자열이나 숫자로 표기한 레이블들을 표준 어휘로 변환하기 위한 사전이다. 표준 어휘는 각 레이블을 대표하는 레이블 식별자(301-1)로 표기한다. 예를 들어, UUID와 같은 전역적 유일 식별자를 활용할 수 있다. 일 실시예에 따른 레이블 사전의 내용은 하기의 [표 2]와 같다. 표 2 레이블 식별자 자연어 레이블 L0000001 cat, 고양이, chat L0000002 dog, 개, chien L0000003 말, horse, jument L0000004 호랑이, tiger, tigresse 레이블 사전은 레이블 항목의 목록을 포함하고, 각 레이블 항목은 레이블 식별자와 자연어 레이블을 포함한다. [표 2] 의 사전에 의하면, \"cat\", \"고양이\", \"Chat\"는 모두 'L0000001'이라는 표준 어휘로 변환된다. 레이블 사 전은 이미지넷(ImageNet)의 경우와 같이 워드넷(WordNet) 등 사전 데이터베이스를 기반으로 구축 가능하고 번역 기를 통해 각종 언어로 확장할 수 있다. 레이블 사전을 지능적으로 구축하고 관리하는 방법은 본 발명의 범위에 포함하지 아니한다. 데이터셋 저장소는 지능 모델의 훈련과 평가에 사용하는 데이터셋과 데이터셋을 구성하는 원시 데이 터 항목과 정답 데이터 항목들을 저장한다. 본 발명의 일 실시예에서 데이터셋은 데이터셋 식별자(401-1)와 정답 데이터 목록(401-2)으로 구성된다. 데이터 셋 식별자(401-1)는 데이터셋을 유일하게 구별하여 지시할 수 있는 고유 이름이다. 정답 데이터 목록(401-2)은 정답 데이터 항목을 가리키는 정답 데이터 식별자(403-1)의 목록으로서 이 목록을 참조하면 데이터셋을 구 성하는 모든 원시 데이터 항목과 정답 데이터 항목들을 열람할 수 있다. 원시 데이터 항목은 해당 항목을 고유하게 식별하는 원시 데이터 식별자(402-1), 지능 모델의 훈련과 평가 에 사용할 원본 데이터인 원시 데이터(402-2), 그리고 이미지, 동영상, 오디오 등 원시 데이터의 형식을 기술하 는 원시 데이터 타입(402-3)을 포함한다. 정답 데이터 항목은 해당 항목을 고유하게 식별하는 정답 데이터 식별자(403-1), 해당 정답의 적용 대상인 원시 데이터를 가리키는 원시 데이터 식별자(402-1), 정답 레이블 식별자를 기술한 정답 데이터(403-2), 그리고 해당 정답이 활용될 수 있는 태스크 명세(403-3)를 포함한다. 도 8은 본 발명의 일 실시예에 따른 지능 모델 생성 방법의 데이터셋 예시를 나타낸 도면이다. 도 8을 참조하면, 정답 데이터 항목 A0100111은 원시 데이터 항목 RD1340101이 지시하는 사진에 L0001010(비행 기)를 정답 레이블로 지정한다. A0100111과 A0100133의 예에서 보듯이 여러 정답 데이터 항목에서 하나의 레이 블(L0001010)을 참조할 수 있다. 반대의 경우도 성립할 수 있다. 하나의 원시 데이터에 여러 정답 레이블을 부 여할 수도 있기 때문이다. 하나의 원시 데이터에 서로 다른 태스크의 정답을 여러 개 부여할 수도 있다. 예를 들면, 사진 한 장에 분류(Classification) 정답, 검출(Detection) 정답, 분할(Segmentation) 정답을 부여할 수 있다. 도 8에서 A01000116과 A0100117 는 각각 하나의 원시 데이터(RD1387478)에 서로 다른 정답을 부여한다. A01000116은 얼굴이 포함된 사진에 '얼굴(L1034962)'을 분류 태스크의 정답 레이블로 지정하는 정답이고, A0100117은 사진에 포함된 얼굴 영역을 검출하고 '얼굴'로 분류하는 검출 태스크용 정답이다. 본 발명에 의한실시예에서 하나의 데이터셋은 정답 데이터 항목의 목록을 기술함으로써 구성된다. 도 8의 '데이터셋1'은 이미 지를 입력 받아 비행기, 자동차, 타조, 얼굴 중 하나로 분류하는 지능 모델을 훈련 평가할 수 있는 데이터셋이 다. '데이터셋2'는 이미지로부터 얼굴을 검출하는 지능 모델을 훈련 평가할 수 있는 데이터셋이다. 지능 모델 저장소는 다수의 지능 모델들을 저장한다. 지능 모델은 지능 모델 데이터와 지 능 모델 메타데이터의 쌍으로 구성된다. 지능 모델 데이터는 지능 모델을 실행하는데 필요한 데이터이다. 본 발명의 일 실시예에서 지능 모델 데이 터는 모델을 유일하게 식별하는 지능 모델 식별자(502-1), 모델의 구조를 파악하는데 활용할 수 있는 모델 유형 식별자(502-2), 모델 파라미터 값(502-3), 태스크 명세(502-4)로 구성된다. 지능 모델 식별자(502-1)는 지능 모델을 전역적으로 유일하게 구별하는 아이디로서 UUID와 같은 글로벌 식별자 를 활용하여 지정할 수 있다. 모델 유형 식별자(502-2)는 모델의 구조 명세를 기술하는 지능 모델 유형을 가리키는 값이다. 예를 들어, 인공신경망 기반 지능 모델의 모델 유형은 뉴런(neuron)과 층(layer)이 어떻게 구성되고 연결되는지를 기술한 신경망 구조 정보를 말한다. 모델 파라미터 값(502-3)은 모델을 구성하는 각종 파라미터의 실제 값이다. 신경망 모델의 경우 가중치(weigh t)와 바이어스(bias) 등의 값들이 여기에 포함된다. 신경망과 기계학습 기반 지능 모델의 모델 구조와 파라미터 값을 기술하는 다양한 방법이 존재하므로 이러한 방법을 지능 모델 데이터 기술에 활용하면 된다. 예를 들어, ONNX(Open Neural Network Exchange)는 모델 구조와 파라미터 값을 기술하는 대표적인 업계 표준이다. 태스크 명세(502-4)는 지능 모델이 수행하는 작업이 무엇인지 기술하는 정보로서 지능 요구 프로파일에 포 함된 태스크 명세(110-1)와 동일하다. 지능 요구 프로파일에 기술된 태스크 명세(110-1)와 지능 모델 데이터 에 포함된 태스크 명세(502-4)를 비교함으로써 요구된 기능을 적절히 수행할 수 있는 지능 모델을 선정할 수 있다. 지능 모델 메타데이터는 지능 모델의 생성 방법, 기능, 품질 등의 설명 정보를 포함한다. 지능 모델 메타 데이터는 지능 모델의 선택과 활용에 참고할 수 있을 뿐 아니라, 지능 모델 간 유사성을 판단하여 품질에 문제 가 있는 지능 모델을 걸러내는 단서로 활용할 수 있다. 본 발명의 일 실시예에서 지능 모델 메타데이터는 데이터셋 식별자(503-1), 정답 레이블 목록(503-2), 기반 모델(503-3), 훈련 이력(503-4), 성능 평가 정보 (503-5), 품질 이력(503-6)으로 구성된다. 데이터셋 식별자(503-1)는 지능 모델을 훈련하는데 사용한 데이터셋을 지시한다. 데이터셋 저장소에 저장 된 데이터셋들 중 하나의 데이터셋 식별자(401-1)를 값으로 갖는다. 정답 레이블 목록(503-2)은 지능 모델의 출력값과 레이블 식별자 간 대응 관계를 기술한다. 지능 모델이 클래스 아이디를 출력하는 경우 이 값은 클래스의 인덱스(Index)이다. 예를 들어, 지능 모델이 이미지를 개와 고양이의 두 클래스로 분류하는 태스크를 수행한다고 할 때 지능 모델의 출력값은 0 또는 1이다. 만약 0은 고양 이, 1은 개를 나타낸다고 할 때, 이 대응 관계를 기술한 것이 정답 레이블 목록(503-2)이다. 대응 관계는 클래 스 아이디 별로 레이블 식별자(301-1)를 지정하여 기술한다. [표 2]의 레이블 사전을 기반으로 정답 레이블 목 록(503-2)을 {0:L0000001, 1:L0000002}로 기술해 보면, 지능 모델의 출력이 0이면 레이블 식별자가 L0000001인 \"고양이\"를 의미하고 1이면 레이블 식별자가 L0000002인 \"개\"를 의미한다고 해석할 수 있다. 기반 모델(503-3)은 지능 모델을 훈련하는데 사용한 모델의 고유 아이디이다. 예를 들어, 모델 M을 기반으로 파 인 튜닝(Fine-tuning)이나 기타 전이 학습(Transfer Learning)을 통해 이 모델을 훈련하였다면, M의 지능 모델 식별자(502-1)를 기반 모델 항목에 기술한다. 기반 모델이 없는 경우에는 공백으로 둔다. 훈련 이력(503-4)은 지능 모델을 훈련에 관련된 파라미터 값과 진행 과정에서 발생하는 데이터를 포함한다. 예 를 들어, 학습률(learning rate), 배치 크기(batch size), 신경망의 초기 가중치는 물론 매 훈련 주기(epoch) 마다 어떤 데이터를 입력하여 가중치가 어떻게 변화했고, 학습률 등 훈련 과정을 조정하는 파라미터 값을 어떻 게 변화시켰으며, 손실값(Loss)은 어떻게 변화했는지를 모두 포함할 수 있다. 성능 평가 정보(503-5)는 지능 모델의 성능을 기술한 데이터로서, 평가에 사용한 데이터셋과 성능치를 포함한다. 평가에 사용한 데이터셋 또는 평가 데이터 항목의 고유 아이디, 모델의 평가 척도에 따른 성능치, 평 가 환경을 기술한다. 예를 들어, 이미지 분류 모델의 경우 성능 평가에 사용한 모든 이미지 데이터의 고유 아이 디, 분류 정확도(Accuracy)와 이미지 당 실행 속도(fps) 등의 성능치, 평가를 수행한 시스템의 CPU, GPU, RAM사양 등을 기술할 수 있다. 성능 평가에 사용한 데이터 구성과 평가 환경에 따라 성능치는 달라질 수 있으므로, 데이터와 환경이 다른 경우 성능 평가 정보에 지속적으로 평가 정보를 추가한다. 품질 이력(503-6)은 지능 모델의 활용 과정에서 발생한 각종 문제 데이터를 포함한다. 예를 들어, 품질 이력의 항목은 문제 고유 번호, 문제 사항 설명 정보, 문제 심각 수준 정보를 포함할 수 있다. 문제 심각 수준은 '심각', '보통', '무시가능' 등의 단계로 기재할 수 있다. 각 품질 이력 항목에는 품질 이력 정보를 제공한 사 용자, 사용 시간, 사용 중 자체 평가 성능 등의 정보를 포함하여 항목의 신뢰도를 높일 수 있다. 품질 이력 정 보는 각종 지능 모델을 활용하는 사용자들 간에 공유되고 추적할 수 있도록 별도의 품질 이력 저장소에 저장할 수 있다. 지능 모델 메타데이터 안에는 품질 이력 저장소에 저장된 정보 항목의 고유 번호를 기재함으로써 해당 지능 모델의 품질 이력을 참조하도록 할 수 있다. 지능 모델 유형 사전은 다양한 지능 모델의 구조를 형식적으로 기술한 정보 구조체인 지능 모델 유형(60 1)들을 보관한다. 지능 모델 유형은 모델 유형을 유일하게 구별하여 지시하는데 사용하는 모델 유형 식별 자(601-1), 모델의 구조를 형식적으로 기술한 모델 유형 구조 명세(601-2), 모델 유형이 처리할 수 있는 작업들 을 기술하는 태스크 명세 (601-3)를 포함한다. 모델 유형 구조 명세(601-1)는 지능 모델을 형식적으로 기술한 정보구조체로서 프로그램을 통해 읽어서 지능 모 델을 생성하고 훈련과 시험을 수행할 수 있어야 한다. 본 발명의 일 실시예에서 딥러닝 기반 지능 모델을 계산 그래프(Computational Graph) 구조로 기술하는 ONNX(Open Neural Network Exchange)를 활용할 수 있다. 지능 모델의 구조를 ONNX 형식으로 변환한 후 모델 유형 구조 명세(601-2)로 보관 활용하는 방식이다. 모델 유형 식 별자(601-1)를 이용하여 필요한 지능 모델 유형을 선택한 후 모델 유형 구조 명세(601-2)를 로딩한 후 지능 모 델을 훈련하거나 시험할 수 있다. 또한, 서로 다른 지능 모델 간 구조의 동일 여부와 유사 여부를 판단하는데도 활용할 수 있다. 태스크 식별자(601-3)는 지능 모델의 태스크 명세(502-4)에 포함되는 태스크 식별자와 동일한 정보로서 해 당 모델 유형을 기반으로 훈련한 지능 모델이 처리할 수 있는 작업을 기술한다. 예를 들어, 해당 모 델 유형의 구조 명세(606-2)가 AlexNet 구조이면 분류(Classification) 작업을 처리할 수 있고, R-CNN 구 조이면 검출(Detection) 작업을 처리할 수 있으며, U-Net 구조이면 분할(Segmentation) 작업을 처리할 수 있다. 도 9는 AlexNet 구조를 개념적으로 나타낸 도면이다. 하기의 [표 3]은 도 9의 AlexNet 구조를 ONNX 명세로 변환한 것을 나타낸다. 표 3 graph torch-jit-export ( %input[FLOAT, batch_sizex3x224x224] ) initializers ( %features.0.weight[FLOAT, 64x3x11x11] %features.0.bias[FLOAT, 64] %features.3.weight[FLOAT, 192x64x5x5] %features.3.bias[FLOAT, 192] %features.6.weight[FLOAT, 384x192x3x3] %features.6.bias[FLOAT, 384] %features.8.weight[FLOAT, 256x384x3x3] %features.8.bias[FLOAT, 256] %features.10.weight[FLOAT, 256x256x3x3] %features.10.bias[FLOAT, 256] %classifier.1.weight[FLOAT, 4096x9216] %classifier.1.bias[FLOAT, 4096] %classifier.4.weight[FLOAT, 4096x4096] %classifier.4.bias[FLOAT, 4096] %classifier.6.weight[FLOAT, 1000x4096] %classifier.6.bias[FLOAT, 1000] ) { %17 = Conv[dilations = [1, 1], group = 1, kernel_shape = [11, 11], pads = [2, 2, 2, 2], strides = [4, 4]](%input, %features.0.weight, %features.0.bias) %18 = Relu(%17) %19 = MaxPool[ceil_mode = 0, kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%18) %20 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%19, %features.3.weight, %features.3.bias) %21 = Relu(%20) %22 = MaxPool[ceil_mode = 0, kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%21) %23 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%22, %features.6.weight, %features.6.bias) %24 = Relu(%23) %25 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%24, %features.8.weight, %features.8.bias) %26 = Relu(%25) %27 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%26, %features.10.weight, %features.10.bias) %28 = Relu(%27) %29 = MaxPool[ceil_mode = 0, kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%28) %30 = AveragePool[kernel_shape = [1, 1], strides = [1, 1]](%29) %31 = Flatten[axis = 1](%30) %32 = Gemm[alpha = 1, beta = 1, transB = 1](%31, %classifier.1.weight, %classifier.1.bias) %33 = Relu(%32) %34 = Gemm[alpha = 1, beta = 1, transB = 1](%33, %classifier.4.weight, %classifier.4.bias) %35 = Relu(%34) %output = Gemm[alpha = 1, beta = 1, transB = 1](%35, %classifier.6.weight, %classifier.6.bias) return %output } 본 발명의 실시예에 따른 방법은 도 9의 딥러닝 모델을 ONNX 명세로 변환하고, 지능 모델 유형 사전에 저장할 수 있다. 저장된 지능 모델 유형 구조 명세는 차후 복원 과정을 거쳐 Pytorch 등 딥러닝 프레임워크 모델로 복 원한 후 훈련과 시험에 활용할 수 있다. 지능 모델 활용 코드 저장소는 지능 모델을 대상으로 다양한 작업을 수행하는 프로그램인 지능 모델 활용 코드들을 보관한다. 지능 모델 활용 코드는 코드를 유일하게 식별하는데 사용하는 코드 식별자(701- 1), 코드가 수행하는 작업을 기술하는 코드 유형(701-2), 실행 코드(701-3), 해당 코드로 다룰 수 있는 지능 모 델들을 기록한 호환 모델(701-4)로 구성된다. 본 발명의 일 실시예에서 코드 유형(701-2)의 값은 추론(inference), 훈련(training), 파인튜닝(fine-tuning), 지식증류(knowledge distillation), 압축(compression) 등으로 기술할 수 있다. 추론(inference) 유형의 코드 는 지능 모델을 적재한 뒤 입력 데이터를 받아 지능 모델을 통해 계산한 출력값을 제공하는 기능을 수행한 다. 훈련 유형의 코드는 지능 모델 유형으로 초기 지능 모델을 생성한 뒤 데이터셋 또는 지능 요구 프로파일을 이용하여 지능 모델을 훈련하는 기능을 수행한다. 파인튜닝 유형의 코드는 지능 모델을 적재한 뒤 지능 요구 프로파일에 기재된 목적 정답 레이블(110-2)에 따라 지능 모델 구조를 변형한 다음 데이터셋 또는 목적 데이터(110-1)를 기반으로 지능 모델을 훈련하는 기능을 수행한다. 본 발명의 일 실시예에서 코드(701-3)는 서로 다른 운영 환경으로 인한 호환성 문제를 극복하고 실행 방식을 표 준화할 수 있도록 docker, containerd, CRI-O와 같은 컨테이너 런타임을 활용한다. 예를 들어, Linux OS, CUDA 툴킷, Python, Pytorch 프레임워크 등을 설치하고 AlexNet 모델을 훈련하는 코드를 탑재한 docker 컨테이너를 지능 모델 활용 코드의 코드(701-3)에 저장하고 활용할 수 있다. 또한, 컨테이너를 구동할 수 있는 명령 스크립트를 코드(701-3)에 함께 저장하여 활용할 수 있다. 도 10은 본 발명의 지능 모델 배포 과정을 나타낸 흐름도이다. 도 10을 참조하면, 단말은 지능 모델이 수행할 작업과 훈련 데이터를 포함하는 지능 요구 프로파일을 생성 하여 엣지 서버로 지능 모델 생성과 배포를 요청한다(S1000). 즉 S1000 단계는 단말이 지능 서비스를 제공하는데 필요한 지능 모델을 요청하는 단계이다. 단말의 제작자, 설 치전문가, 사용자 등 지능 서비스 제공에 관여하는 사람은 임의의 사용자 인터페이스(단말, 엣지 서버, 클라우 드 서버가 모두 제공 가능)를 통해 지능 요구 프로파일을 생성한다. 사용자 인터페이스는 웹 인터페이스 (Web Interface), 그래픽 사용자 인터페이스(Graphics User Interface), 챗봇(Chatbot), 커맨드 창(Command Window) 등 다양한 형태로 제공될 수 있다. 단말의 지능 관리자는 지능 요구 프로파일을 엣지 서버로 전송하여 지능 모델 배포를 요청한다. 지능 요구 프로파일의 구조와 내용은 도 3 내지 도 5의 예시에 보인 바와 같다. 엣지 서버의 지능 관리자는 지능 리파지토리 인터페이스를 통해 지능 리파지토리를 참조하면서 수신한 지능 요구 프로파일에 포함된 태스크 명세와 데이터를 기반으로 '기반 지능 모델'을 선정하고 '훈 련/평가용 데이터셋'을 구축하여 훈련함으로써 새로운 지능 모델을 생성한다(S1001). 지능 모델 생성에 성공하 면, 생성된 지능 모델과 데이터셋 정보를 지능 리파지토리에 추가 등록한다. 지능 관리자는 생성한 지능 모델과 해당 지능 모델 구동 프로그램을 단말로 전달하고 단말은 지능 모델을 활용한다. 엣지 서버의 지능 관리자가 지능 모델 생성에 실패한 경우(S1001), 지능 관리자는 데이터 보안 등의 목적에 의해 정한 규칙에 따라 지능 요구 프로파일을 변형한 후 클라우드 서버로 지능 요구 프로파일을 전 송함으로써 지능 모델의 생성과 배포를 요청한다(S1002). 클라우드 서버의 지능 관리자는 엣지 서버의 지능 관리자와 동일한 방식으로 지능 모델 생성을 시도 한다(S1003). 지능 모델 생성에 성공하면 생성한 지능 모델과 관련 데이터셋을 지능 리파지토리에 등록한 다. 지능 모델 생성에 실패하면, 다음 단계의 클라우드 서버로 지능 요구 프로파일을 전송하여 지능 모델 생성 배포를 요청한다(S1002). 클라우드 서버의 지능 관리자는 지능 모델 생성에 성공하면, 배포를 요청한 엣지 서버로 지능 모델과 해당 지능 모델 구동 프로그램을 전송한다(S1004). 엣지 서버는 지능 요구 프로파일을 변형하는 과정에서 별도로 보관한 데이터가 있는 경우 해당 데이터로 지능 모델을 최적화한다. 최적화한 지능 모델은 엣지 서버의 지능 리파지토리에 추가 등록하고, 지능 모델 과 지능 모델 구동 프로그램을 단말로 전송한다(S1005). 단말은 배포 받은 지능 모델과 지능 모델 구동 프로그램을 활용한다(S1006). 도 10의 단계 S1001 및 S1003은 지능 요구 프로파일을 기반으로 지능 모델을 생성하는 과정을 포함한다. 이하, 본 발명의 일 실시예에 의해 분류(Classification) 태스크를 수행하는 지능 모델을 생성하는 과정을 상세 히 설명한다. 도 11은 본 발명의 실시예에 따른 지능 모델 생성 과정을 나타낸 흐름도이다. 도 11을 참조하면, 지능 관리자는 지능 요구 프로파일이 기술하는 작업을 수행할 수 있는 지능 모델 을 생성하기 위해 태스크 명세(110-1)와 목적 데이터(110-2)를 기반으로 지능 리파지토리를 검색하여 호환 지능 모델 M을 선정한다(S2001). 본 발명의 일 실시예에서 호환 지능 모델 선정은 지능 요구 프로파일에 기술된 태스크 명세(110-4)와 지능 모델 저장소에 저장된 지능 모델의 태스크 명세(502-4)를 비교하여 상호 동일한 경우 해당 지능 모델 을 선정하는 방식을 따른다. 이를 1차 선별 작업으로 부른다. 1차 선별에서 선택된 지능 모델이 2개 이상인 경우 지능 요구 프로파일의 목적 데이터(110-2)를 기반으로 2차 선별 작업을 수행한다. 본 발명의 일 실시예에서 이 작업은 표준 목적 레이블 목록과 호환 지능 모델의 정 답 레이블 목록(2000-2) 간 유사도를 계산하여 수행한다. 표준 목적 레이블 목록은 목적 데이터(110-1) 내 정답들과 목적 정답 레이블(110-2) 목록에 포함된 정답 레이블 들을 결합한 후 어휘 해석기를 통해 각 레이블을 표준 어휘로 변환한 결과물이다. 어휘 해석기는 어 휘 변환을 위해 레이블 사전을 참조한다. 어휘 해석에 실패하면 지능 모델 생성에 실패한 것으로 간주한다. 도 12는 표준 정답 레이블 목록을 생성하는 일례이다. 표준 목적 레이블 목록과 호환 지능 모델의 정답 레이블 목록(2000-2) 간 유사도는 다양한 방법으로 계산할 수 있다. 본 발명의 일 실시예에서 두 레이블 목록 간 유사도는 자카드 인덱스 (Jaccard Index)를 통해 계산할 수 있다. 두 레이블 목록 간 유사도가 높을수록 지능 모델의 선정 우선 순위가 높다. 2차 선별 작업을 거친 후 동일한 우선 순위의 지능 모델이 2개 이상인 경우 성능이 우수하고 품질 문제가 없는 모델을 선별하는 3차 선별 작업을 수행한다. 본 발명의 일 실시예에서 3차 선별 과정은 지능 리파지토리의 지능 모델 메타데이터를 기반으로 수행한다. 아래 예시에 설명한 바와 같이 일반 성능과 품질 지수를 참조 하거나, 목적 데이터 대상 성능을 측정하는 방법을 활용할 수 있다. 일반 성능을 참조하는 방법은 지능 모델 메타데이터에 명시된 성능 평가 정보(503-5)를 비교하여 가장 우 수한 지능 모델을 선택한다. 품질 지수를 참조하는 방법은 지능 모델 메타데이터에 명시된 품질 이력(503-6) 정보를 비교하여 품질에 문제 여지가 없는 지능 모델을 선택한다 목적 데이터 대상 성능을 측정하는 방법은 지능 요구 프로파일에 포함된 목적 데이터(110-2)를 대상으로 지능 모델의 성능을 평가하여 성능이 가장 높은 지능 모델을 선택한다. 이를 위해 지능 모델 활용 코드 저장소 에서 평가 대상 지능 모델의 모델 유형을 대상으로 추론(Inference) 작업을 수행할 수 있는 지능 모 델 활용 코드를 선택한 뒤 후보 지능 모델을 통해 목적 데이터(110-1)를 대상으로 추론 기능을 수행 하여 성능을 평가하는 작업을 수행할 수 있다. 목적 데이터 대상 성능, 일반 성능, 품질 지수는 지능의 활용 상황과 환경에 따라 가중치를 달리하여 보다 적합 한 지능 모델이 선정되도록 조정할 수도 있다. 이상의 3단계에 걸친 선별 작업을 통해 우선순위가 가장 높은 지능 모델 M을 선정한다. M을 선정하면 M을 대상 으로 다양한 기능을 수행하는 활용 코드를 열람하여 확보한다. 구체적으로는 지능 모델 활용 코드 저장소 에서 M의 모델 유형(502-2)을 호환 모델(701-4)에 포함하는 지능 모델 활용 코드를 선택하여 코드를 확보 한다. 본 발명의 일 실시예에서 각 코드는 컨테이너(container)와 컨테이너 구동 스크립트의 쌍으로 구성되며, 각 코드는 추론, 훈련, 파인튜닝, 지식 증류 등의 기능을 수행하는데 활용할 수 있다. 즉, 지능 모델 M을 선정 한 후 M을 입력 받아 추론 기능을 수행하는 코드 C1, 훈련 기능을 수행하는 코드 C2, 파인튜닝 기능을 수행하는코드 C3 등을 확보하게 된다. 다음으로, M이 처리할 수 있는 정답 레이블 목록과 표준 목표 정답 레이블 목록이 정확히 일치하지 않는 경우 M 의 구조를 변형하여 M1을 생성한다(S2002). 예를 들어, M이 이미지를 100개의 클래스로 분류하는 지능 모델이라고 할 때, 표준 목적 레이블 목록이 10개의 정답만을 포함하고 있다면 M을 최적화하여 표준 목적 레이블 목록에 포함된 10개의 클래스만 분류할 수 있도록 만드는 것이 본 단계의 목적이다. 만약, M이 분류(Classification) 작업용 Convolutional Neural Network 구조라면 최종 분류 계층의 노드는 100 개이고 Convolution 계층과 완전 연결(Fully Connected) 구조로 이어져 있을 것이다. 본 단계에서 100개의 출력 노드를 포함한 M의 분류 계층을 제거하고 대신 10개의 출력 노드를 포함한 분류 계층을 생성하여 연결한다. 본 발명의 일 실시예에서 M1을 생성할 때 출력 노드를 표준 목표 정답 레이블 개수보다 한 개 더 만들 수 있다. 추가된 노드는 'unknown'을 나타내는 노드로서 표준 목표 정답 레이블에 대응하지 않는 데이터가 지능 모델에 입력되었을 때 활성화되도록 훈련함으로써 오인식(False Positive) 확률을 낮추어 클래스 분류 정확도를 향상할 수 있다. 본 단계(S2002)는 M의 정답 레이블 목록과 표준 목적 레이블 목록의 길이가 동일한 경우에 수행할 필요가 없다. 다음으로, M1을 훈련할 데이터셋 D를 구성한다(S2003). D는 표준 목적 레이블 목록을 기반으로 지능 리파지토리 의 데이터셋 저장소를 열람하여 구축한다. 먼저 M을 훈련하는데 사용한 데이터셋을 식별자(503- 1)를 통해 열람하여 표준 목적 레이블 목록에 포함된 레이블들의 데이터 항목(402,403)들을 수집하여 D를 구축 한다. 만약 표준 목적 레이블 중 이 방법으로 데이터를 확보하지 못한 레이블이 있으면, 데이터셋 저장소 에서 정답 데이터(403-2)가 표준 목적 레이블과 동일한 데이터 항목들을 검색하여 D에 추가한다. D를 구성한 뒤 표준 목적 레이블 목록의 각 레이블과 클래스 인덱스를 짝짓는 테이블 L도 구축한다. 클래스 별 데이터 개수의 평준화, M의 규모에 적합한 클래스 별 데이터 개수 결정, D를 훈련(Training), 검증 (Validation), 시험(Test)용 데이터로 분할하는 등 M의 훈련을 위해 고려해야 할 다양한 사항들을 본 단계에서 고려하여 수행한다. 단계 (S2002)에서 'unknown' 노드가 생성된 경우 표준 목적 레이블에 포함되지 않는 레이블들을 무작위로 선정 하고 해당 데이터들을 수집하여 'unknown' 클래스에 할당함으로써 데이터셋 D를 구성한다. 표준 목적 레이블에 대응하는 클래스에 포함되는 데이터 외의 데이터는 'unknown' 클래스에 속하도록 훈련함으로써 오인식(False Positive) 확률을 낮추어 지능 모델의 분류 정확도를 향상할 수 있다. 다음으로, D를 이용하여 M1을 훈련함으로써 M2를 생성한다(S2004). 지능 모델 유형별로 다양한 훈련 방법이 적 용될 수 있고 앞서 언급한 대로 이러한 코드들은 지능 리파지토리의 지능 모델 활용 코드 저장소를 통해 확보한다. 본 단계의 작업은 앞서 확보한 '훈련'용 코드에 D와 M1을 입력하고 구동함으로써 수행할 수 있 다. 이때, M2와 D를 지능 리파지토리에 등록한다. M2의 지능 모델 데이터와 지능 모델 메타데이터를 적절하게 기재해야 한다. 지능 모델 식별자(502-1)는 신규 생성하여 등록하고, 모델 파라미터 값(502-3), 정답 레이블 목록(503-2), 훈련 이력(503-4), 성능 평가 정보(503-5)는 적절한 정보로 기록해야 한다. 데이터셋 식별 자(503-1)에는 D의 데이터셋 식별자(402-1)를 기록한다. 기반 모델(503-3)에는 M의 지능 모델 식별자(502-1)를 기록한다. D는 새로운 데이터셋 식별자(401-1)를 등록하고 D를 구성하는 정답 데이터 목록(401-2)을 저장함으로 써 기록한다. 단계 (S2002) 내지 (S2004)의 수행을 통해 지능 모델의 규모를 줄이고 지능 모델의 정확도를 향상하는 효과를 획득할 수 있다. 다음으로, 지능 요구 프로파일에 포함된 목적 데이터를 기반으로 M2를 지능 요구에 최적화하는데 활용할 데이터셋 D1을 구성한다(S2005). D1은 원시 데이터(110-3)에 포함된 데이터 항목과 각 항목에 대응하는 데이터 주석(110-4)의 쌍들로 구성된다. 데이터 주석의 정답은 레이블 사전을 통해 표준 어휘로 변환한 후 단계에서 구축한 L을 통해 클래스 인덱스를 구한 다음 각 원시 데이터의 정답으로 삼아야 한다. 다음으로, D1으로 M2를 훈련하여 M3를 생성한다(S2006). 단계 (S2004)에서와 같이 지능 모델 활용 코드 저장소 에서 확보한 '훈련'용 코드에 D1과 M2를 입력하여 구동함으로써 수행할 수 있다. M3와 D1을 지능 리파지토리에 등록한다. M3의 지능 모델 데이터와 지능 모델 메타데이터를 적절 하게 기재해야 한다. 지능 모델 식별자(502-1)는 신규 생성하여 등록하고, 모델 파라미터 값(502-3), 정답 레이 블 목록(503-2), 훈련 이력(503-4), 성능 평가 정보(503-5)는 적절한 정보로 기록해야 한다. 데이터셋 식별자 (503-1)에는 D1의 데이터셋 식별자(402-1)를 기록한다. 기반 모델(503-3)에는 M2의 지능 모델 식별자(502-1)를 기록한다. D1은 새로운 데이터셋 식별자(401-1)를 등록하고 D1을 구성하는 정답 데이터 목록(401-2)을 저장함으 로써 기록한다. 단계 (S2001)의 1차 선별에서 지능 요구 프로파일에 기재된 태스크 명세(110-1)를 만족하는 지능 모델을 지능 모델 저장소에서 찾지 못할 수 있다. 이때, 지능 관리자는 지능 모델 유형 사전에 저장된 지능 모델 유형 중 태스크 식별자(601-3)가 태스크 명세(110-1)의 태스크 식별자와 동일한 것을 선별하여 활용할 수 있다. 지능 모델 유형을 선정한 뒤 모델 유형 구조 명세(601-2)를 복원하여 모델 파라미터 값이 비어있는 초기 모델 BM을 생성한다. 그런 다음 BM을 M 대신 활용할 수 있다. BM은 학습하지 않은 비어있는 모델이므로 단 계 (S2004)를 통해 비로소 제 기능을 하는 모델을 생성하게 된다. 이후의 과정은 전술한 바와 동일하다. 이하, 데이터 보안을 위한 지능 요구 프로파일 변형 방법에 대하여 상세히 설명한다. 단계 (S1002)에서 엣지 서버가 지능 모델 생성에 실패한 경우 지능 요청 프로파일을 클라우드 서버로 전송 하여 지능 생성 작업을 맡긴다. 이때, 엣지 서버의 지능 관리자는 데이터의 공개 범위를 고려하여 지 능 요구 프로파일을 변형하여 클라우드 서버로 전송함으로써 데이터 보호 기능을 수행한다. 도 4의 지능 요구 프로파일을 예로 들어보면, 공개 범위가 '지역'과 '전역'으로 기술되어 있다. 이 경우 엣지 서버가 '지역'으로 한정된 데이터는 클라우드 서버로 전송하지 않도록 규칙을 적용함으로써 고객 또는 엣지 서 버 소유주 또는 서비스 운영사의 데이터를 보호할 수 있다. 엣지 서버가 클라우드 서버로 전송하는 지능 요구 프로파일에는 1) 공개 범위가 '전역'인 목적 데이터 전체, 2) 공개 범위가 '지역'인 목적 데이터 중 정답 레이 블, 그리고 3) 목적 정답 레이블 목록이 포함된다. 엣지 서버는 공개 범위가 '지역'인 목적 데이터를 차후 지능 모델의 지역 최적화를 위해 저장 보관한다. 또 다른 실시예에서 공개 범위는 다단계로 지정할 수 있다. 도 3에서 보인 바와 같이 단말과 최종 클라우드 서 버 사이에는 여러 단계에 걸쳐 중간 서버들이 배치될 수 있으므로, 이런 경우 어느 단계의 서버까지 데이터를 전송할 수 있는지 세밀하게 공개 범위를 정의하여 기술할 수도 있다. 또 다른 실시예에서 공개 범위는 자동으로 지정할 수 있다. 예를 들어, 사진이나 동영상 안에 사람의 존재 여부를 판단할 수 있는 검출기를 설치하고, 지 능 요구 프로파일 안에 포함된 원시 데이터를 대상으로 검출을 수행하여 사람이 포함된 데이터는 모두 공개 범 위를 '지역'으로 설정할 수 있다. 이와 같이 본 발명에 의한 시스템을 관리하거나 사용하는 주체는 특정 사물들 을 지정하여 공개 범위를 설정하고 엣지 서버가 자동으로 데이터 보안 기능을 처리하도록 만들 수 있다. 도 13은 엣지 서버가 도 4의 지능 요구 프로파일을 데이터 공개 범위를 기반으로 변형한 결과 예이다. 공개 범위가 '지역'인 img02.jpg 관련 데이터를 지능 요구 프로파일에서 삭제하고, img02.jpg의 정답 레이블인 '컵'을 목적 정답 레이블에 추가하였다. '컵'에 해당하는 원시 데이터가 프로파일에 없기 때문이다. 본 사례에 서는 공개 범위 항목은 클라우드 서버로 전송할 필요가 없으므로 지능 요구 프로파일에서 제거하였다. 이하, 엣지 서버에서 지능 모델의 최적화 방법에 대하여 상세히 설명한다. 단계 (S1002)에서 엣지 서버는 공개 범위가 '지역'인 원시 데이터(110-3)와 그 데이터 주석(110-4)을 지능 요구 프로파일에서 제거하여 자체 보관하였다. 이렇게 자체 보관한 데이터 항목들을 기반으로 데이터셋 D2를 구 성한다. D2는 원시 데이터 항목과 데이터 주석 내 정답의 쌍으로 이루어진다. 엣지 서버는 지능 모델 M3를 받아서 D2를 이용하여 훈련함으로써 최초 지능 요구 프로파일이 요청한 최종 지능 모델 M4를 생성한다. 훈련 방법은 단계 (S2004), (S2006)와 동일하다. 이를 통해 공개 범위가 한정적 이라 클라우드 서버에서 지능 모델의 최적화에 활용하지 못한 데이터를 지능 모델의 성능 최적화에 적용할 수 있다. D2와 M4도 앞서 D, D1, M2, M3를 등록한 방식과 동일하게 지능 리파지토리에 등록한다. 이하, 지능 모델의 품질 관리 방법에 대하여 상세히 설명한다. 지능 모델 메타데이터에 포함된 품질 이력(503-6) 정보는 문제 발생 이력이 없는 양질의 지능 모델을 선정 하기 위한 참고 자료로 활용될 수 있다. 지능 모델의 품질이 현저히 낮거나 치명적 위험을 발생시킨 경우 중요한 작업에 활용하는 것을 방지할 수 있다. 예를 들어, 모델 M이 특정 상황에서 오류를 발생하여 문제를 일으킨 경우, 해당 상황을 기술한 정보를 지능 리 파지토리 인터페이스를 통해 엣지 서버 또는 클라우드 서버로 전송한다. 전송 중 엣지 서버와 클라우드 서 버는 모델 M의 지능 모델 메타 데이터 내 품질 이력(503-6) 항목에 해당 정보를 추가한다. 향후 이 항목을 열람함으로써 지능 모델의 품질을 가늠할 수 있다. 만약 어떤 지능 모델 M이 특정 상황에서 심각한 성능 저하나 문제를 발생시킨 경우 M과 동일하거나 유사한 모델을 찾아냄으로써 잠재적으로 문제 발생의 여지가 있는 지능 모델을 선별할 수 있다. M과 동일한 모델은 지능 모델 데이터에 포함된 지능 모델 식별자(502-1)를 상호 비교하여 찾아낼 수 있다. 본 발명의 일 실시예에서 M과 유사한 모델은 다음과 같이 찾아낼 수 있다. 1) M의 지능 모델 메타데이터에 기재된 기반 모델(503-3)은 M을 생성하는데 활용한 지능 모델이므로 유사 한 모델로 판단한다. M의 기반 모델은 또 다른 기반 모델로부터 생성되었을 수 있다. 이와 같이 지능 모델의 기 반 모델을 연속적으로 참조하여 M의 유사 모델들을 찾아낼 수 있다. 2) 두 지능 모델 간 지능 모델 데이터의 유사도를 측정함으로써 유사 모델을 찾아낼 수 있다. 두 지능 모델의 모델 유형(502-2), 훈련 데이터셋(503-1), 정답 레이블 목록(503-2), 기반 모델(503-3), 훈련 이력(503-4) 등 을 상호 비교하여 비슷할 수록 유사 모델이라고 판단할 수 있다. 이러한 데이터 간 유사성이 반드시 두 모델의 동작 특성의 유사성을 증빙하지는 못하지만, 문제 발생 가능성을 가늠하는 단서의 역할을 할 수 있다. 이하, [표 4] 내지 [표 8]을 참조하여, 지능 리파지토리의 구성 및 저장 내용을 상세히 설명한다. [표 4]는 지능 요구 프로파일의 일 실시예를 나타낸다. [표 5]는 레이블 사전의 일 실시예를 나타낸다. [표 6]은 지능 모델 유형 사전의 일 실시예를 나타낸다. [표 7]은 지능 모델 저장소의 일 실시예를 나타낸다. [표 8]은 지능 모델 활용 코드 저장소의 일 실시예를 나타낸다. 표 4 태스크명세(110-4) {태스크식별자: detection, 입력: image, 출력: (Bounding-box, class-id)} 목적데이터(110-1)/데이터주석 접시, 컵, 유리병 목적정답레이블(110-2) 칼, 포크, 수저, 젓가락 표 5 레이블식별자 자연어레이블 L0000001 접시 L0000002 컵 L0000003 유리병 L0000004 수저 L0000005 젓가락 L0000006 칼 L0000007 포크 L0000008 얼굴 L0000009 국수 L0000010 테이블표 6 모델 유형 식별자(601-1) 모델 유형 구조 명세(601-2) 태스크 식별자(601-3) IMT00003 alexnet01.onnx classification IMT00002 yolo4_003.onnx detection IMT00005 resnet078.onnx classification 표 7 지능 모델 식별자 (502-1)IM000009 IM000011 IM000015 모델 유형 식별자 (502-2)IMT00003 IMT00002 IMT00005 모델 파라미터값 (502-3)Im000009.onnx Im000011.onnx Im000015.onnx 태스크 명세 (502-4){태스크식별자: classification,입력: image, 출력: class-id}{태스크식별자: detection, 입력: image, 출력: (Bounding-box, class-id)}{태스크식별자: classification, 입력: image, 출력: class-id} 데이터셋 식별자 (503-1)DS000001 DS000004 DS000008 정답 레이블 목록 (503-2){0:L0000001, 1:L0000002, 2:L0000003, 3:L0000004, 4:L0000005, 5:L0000006, 6:L0000007, 7:L0000008, 8:L0000009, 9:L0000010}{0:L0000001, 1:L0000002, 2:L0000003, 3:L0000004, 4:L0000008, 5:L0000009}{0:L0000001, 1:L0000002, 2:L0000003, 3:L0000004, 4:L0000005, 5:L0000006, 6:L0000007} 기반 모델 (503-3)IM000003 IM000003 IM000003 훈련 이력 (503-4){epoch: 100, batch-size: 4096, learning rate: 0.01, drop-out: 0.1}{epoch: 100, batch-size: 4096, learning rate: 0.01, drop-out: 0.1}{epoch: 100, batch-size: 4096, learning rate: 0.01, drop-out: 0.1} 성능 평가 정보 (503- 5){dataset:DS000001, recall:0.992, precision:0.87}{dataset:DS000001, mAP:0.67}{dataset:DS000001, recall:0.96,precision:0.8 9} 품질 이력(503-6)[{2021-07-03, severe, http://imhist.org/28394054 8}] {} {} 표 8 코드 식별자(701-1) 코드 유형(701-2) 코드(701-3) 호환 모델(701-4) CD000001 inference {imcloud/imt00003:inference, script001.bash}IM000009 CD000002 training {imcloud/imt00003:training, script002.bash}IM000009 CD000003 inference {imcloud/imt00002:inference, script003.bash}IM000011 CD000004 training {imcloud/imt00002:training, script004.bash}IM000011 [표 4]의 지능 요구 프로파일은 이미지를 입력으로 받아 7개의 사물 클래스를 검출할 수 있는 지능 모델을 요청하고 있음을 볼 수 있다. 이러한 요청을 만족하는 지능 모델을 선정하기 위해 지능 요구 프로파일의 태스크 명세(110-4)와 지능 모델 저 장소의 각 지능 모델의 태스크 명세(502-4)를 비교하여 동일한 것을 골라낸다. [표 7]을 참조하면, IM000011이 해당 조건을 만족함을 볼 수 있다. 지능 모델 IM000009의 지능 모델 유형 식별자(502-2)를 보면 모델 구조가 IMT00003이고, 지능 모델 유형 사전 을 보면 이 모델의 구조 명세가 alexnet01.onnx에 형식적으로 기술되어 있고 분류(classification) 태스크에 활용될 수 있음을 알 수 있다. alexnet01.onnx 명세는 ONNX 구조로서 호환성 있는 딥러닝 프레임워크를 사 용하면 복원을 통해 해당 모델 구조로 만들어진 학습되기 전 초기 지능 모델을 생성하여 활용할 수 있다. IM000009의 훈련 이력(503-4)을 보면, epoch, batch size, learning rate 등 훈련에 사용한 각종 파라미터의 설정값을 열람할 수 있다. IM000009의 성능 평가 정보(503-5)를 보면, DS000001 데이터셋을 대상으로 Recall 성능은 0.992, Precision 성 능은 0.87을 달성했음을 볼 수 있다. IM000015는 동일 데이터셋을 대상으로 Recall은 0.96, Precision은 0.89 임을 볼 수 있다. 태스크 명세가 동일한 지능 모델들을 대상으로 동일 성능 수치를 상호 비교함으로써 성능을 비교해 볼 수 있다. IM000009 의 품질 이력(503-6)을 보면, 2021-07-03에 보고된 이력이 있으며 상태는 심각(severe)이고 관련 정 보의 URL이 기재되어 있다. 이를 통해 해당 지능 모델이 심각한 문제를 일으킨 바가 있다는 점을 파악할 수 있 다. 지능 모델 활용 코드 저장소에는 IM000009 모델을 대상으로 추론을 수행할 수 있는 코드 CD000001과 훈련 을 수행할 수 있는 코드 CD000002가 있으며 그 구현체는 컨테이너로서 식별자(예: imcloud/imt00003:inference)와 구동 스크립트(예: script001.bash)가 저장되어 있음을 볼 수 있다. IM000009 모델을 활용하여 지능 모델을 생성, 최적화, 활용할 때 해당 코드를 이용하면 된다. 도 14는 본 발명의 일 실시예에 엣지 서버의 구조를 나타낸 블록도이다. 도 14를 참조하면, 본 발명의 일 실시예에 따른 엣지 서버는 사용자 단말 및 다른 서버와 통신하는 통신부, 지능 모델 생성을 위한 데이터가 저장된 저장부, 지능 모델 생성 요청에 상응하는 지능 모델을 생성하는 모 델 생성부 및 상기 생성된 지능 모델을 조정하는 조정부를 포함한다. 이때, 상기 통신부는 상기 모델 생성부가 상기 지능 모델의 생성에 실패하면, 클라우드 서버에 지능 모델 생성을 요청하고, 상기 클라우드 서버에서 생성된 지능 모델을 수신할 수 있다. 이때, 상기 클라우드 서버는 제1 클라우드 서버 및 상기 제1 클라우드 서버보다 큰 용량을 갖는 제2 클라우드 서버를 포함할 수 있다. 이때, 상기 제1 클라우드 서버는 상기 지능 모델의 생성에 실패하면, 상기 제2 클라우드 서버에 지능 모델 생성 을 요청할 수 있다. 이때, 상기 지능 모델 생성 요청은 태스크 식별자, 원시 데이터, 주석, 데이터 공개 범위 및 목표 레이블을 포 함할 수 있다. 이때, 상기 모델 생성부는 상기 지능 모델 생성 요청에 기반하여 기본 지능 모델을 선정하고, 상기 기본 지 능 모델의 레이블 목록을 목표 레이블 목록에 상응하도록 변형하고, 상기 변형된 지능 모델의 학습을 수행할 수 있다. 이때, 상기 통신부는 상기 데이터 공개 범위에 기반하여 상기 원시 데이터를 상기 클라우드 서버에 전송할 수 있다. 이때, 상기 조정부는 상기 클라우드 서버에 전송되지 않은 원시 데이터를 이용하여 상기 지능 모델을 조정 할 수 있다. 도 15는 본 발명의 일 실시예에 클라우드 서버의 구조를 나타낸 블록도이다. 도 15를 참조하면, 본 발명의 일 실시예에 따른 클라우드 서버는 엣지 서버의 지능 모델 생성 요청을 수신하는 통신부, 지능 모델 생성을 위한 데이터가 저장된 저장부, 상기 지능 모델 생성 요청에 상응하는 지능 모델을 생성하는 모델 생성부를 포함하고, 상기 지능 모델 생성 요청은 태스크 식별자, 원시 데이터, 주석, 데이터 공개 범위 및 목표 레이블을 포함할 수 있다. 이때, 상기 통신부는 상기 모델 생성부에서 상기 지능 모델의 생성에 실패하면, 다른 클라우드 서버에 지능 모델 생성을 요청할 수 있다.이때, 상기 지능 모델 생성 요청의 원시 데이터는 상기 엣지 서버에서 상기 데이터 공개 범위에 기반하여 전송 될 수 있다. 도 16은 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다. 실시예에 따른 엣지 서버 및 클라우드 서버는 컴퓨터로 읽을 수 있는 기록매체와 같은 컴퓨터 시스템에서 구현될 수 있다. 컴퓨터 시스템은 버스를 통하여 서로 통신하는 하나 이상의 프로세서, 메모리, 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치 및 스토리지를 포함할 수 있다. 또한, 컴퓨터 시스템은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있다. 프로세서 는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로그램 또는 프로세싱 인스트럭션들 을 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 휘발성 매체, 비휘발성 매체, 분리형 매체, 비분리형 매체, 통신 매체, 또는 정보 전달 매체 중에서 적어도 하나 이상을 포함하는 저장 매체일 수 있 다. 예를 들어, 메모리는 ROM이나 RAM을 포함할 수 있다. 본 발명에서 설명하는 특정 실행들은 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어시스템들, 소프트웨어, 상기 시스템들의 다른 기능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재 들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “ 필수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요 소가 아닐 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐만 아 니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한다 고 할 것이다."}
{"patent_id": "10-2022-0056734", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 지능 모델 생성 방법을 나타낸 흐름도이다. 도 2는 본 발명의 일 실시예에 따른 지능 모델 생성 방법을 보다 상세히 나타낸 흐름도이다. 도 3은 본 발명의 일 실시예에 따른 지능 모델 배포 시스템의 구성을 나타낸 도면이다. 도 4는 이미지 분류용 지능 모델을 요청하는 지능 요구 프로파일을 나타낸 예시이다. 도 5는 사물 검출 작업용 지능 모델을 요청하는 지능 요구 프로파일을 나타낸 예시이다. 도 6은 의미 기반 영상 분할 작업용 지능 모델을 요청하는 지능 요구 프로파일을 나타낸 예시이다. 도 7은 본 발명의 실시예에 따른 지능 리파지토리 구조를 나타낸 블록도이다.도 8은 본 발명의 일 실시예에 따른 지능 모델 생성 방법의 데이터셋 예시를 나타낸 도면이다. 도 9는 AlexNet 구조를 개념적으로 나타낸 도면이다. 도 10은 본 발명의 지능 모델 배포 과정을 나타낸 흐름도이다. 도 11은 본 발명의 실시예에 따른 지능 모델 생성 과정을 나타낸 흐름도이다. 도 12는 표준 정답 레이블 목록을 생성하는 일례이다. 도 13은 엣지 서버가 도 4의 지능 요구 프로파일을 데이터 공개 범위를 기반으로 변형한 결과 예이다. 도 14는 본 발명의 일 실시예에 엣지 서버의 구조를 나타낸 블록도이다. 도 15는 본 발명의 일 실시예에 클라우드 서버의 구조를 나타낸 블록도이다. 도 16은 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다."}
