{"patent_id": "10-2021-0147173", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0062175", "출원번호": "10-2021-0147173", "발명의 명칭": "산업현장의 쓰러짐 감지 감시카메라 시스템 및 이의 동작 방법", "출원인": "(주)연합안전컨설팅", "발명자": "이동훈"}}
{"patent_id": "10-2021-0147173", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "산업현장을 촬영하여 광학영상을 생성하는 카메라모듈; 및 상기 카메라모듈로부터 수신한 상기 광학영상을 분석하여 쓰러진 사람이 존재하는지 판단하는 서버를 포함하는,산업현장의 쓰러짐 감지 감시카메라 시스템."}
{"patent_id": "10-2021-0147173", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 서버는 상기 카메라모듈로부터 수신한 광학영상을 저장하는 저장부; 상기 광학영상을 분석하여 사람이 쓰러진 상태인지 판단하고, 사람이 쓰러진 것으로 판단되는 경우 사람이상 이벤트의 발생을 출력하는 사람이상 판단부; 및 상기 사람이상 판단부에서 사람이상 이벤트의 발생을 출력하는 경우, 이상 이벤트의 발생을 관리자에게 알리는알림부를 포함하는, 산업현장의 쓰러짐 감지 감시카메라 시스템."}
{"patent_id": "10-2021-0147173", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서, 상기 사람이상 판단부는 상기 광학영상에서 프레임을 추출하고, 상기 프레임을 쓰러짐 인식 인공지능 모델에 입력하여, 상기 쓰러짐 인식 인공지능 모델이 상기 프레임 내에 쓰러진 사람이 존재하는 것으로 판단하는 경우, 사람에게 이상 이벤트가발생한 것으로 판단하며,상기 쓰러짐 인식 인공지능 모델은 사람이 쓰러져 있는 이미지가 입력데이터이고 상기 이미지에서 쓰러진 사람을 표시하는 정보가 라벨데이터인 학습데이터를 이용하여 학습되고, 상기 광학영상에서 추출된 프레임을 입력받으면 사람이 쓰러진 상태인지 판단하고 사람이 쓰러진 영역에 박스를 표시하고 클래스 일치도 점수를 표시하여 출력하는, 산업현장의 쓰러짐 감지감시카메라 시스템."}
{"patent_id": "10-2021-0147173", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 상기 쓰러짐 인식 인공지능 모델은 사람, 차량, 동물을 구분하기 위한 목적으로 훈련된 CNN 모델의 네트워크 가중치를 심층전이학습을 적용하여 사람의 쓰러짐을 판단하도록 조정하여 형성된, 산업현장의 쓰러짐 감지 감시카메라 시스템."}
{"patent_id": "10-2021-0147173", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 3에 있어서, 상기 카메라모듈은 감시 영역 중에서 쓰러짐 자세와 상기 카메라모듈과의 위치관계에 따라 달라지는 유효 영역의 적어도 일부가 연속되도록 상기 산업현장에 복수개 배치되는, 산업현장의 쓰러짐 감지 감시카메라 시스템."}
{"patent_id": "10-2021-0147173", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0062175-3-청구항 5에 있어서, 상기 사람이상 판단부는 상기 쓰러짐 인식 인공지능 모델이 출력하는 클래스 일치도 점수가 기준점수보다 높은 경우 사람이 쓰러진 것으로 판단하며,상기 카메라모듈은 상기 기준점수가 높아지는 경우 상기 유효 영역의 면적이 좁아지므로, 상기 기준점수가 높아지는 경우 상기 유효 영역의 적어도 일부가 연속되도록 상기 카메라모듈이 향하는 방향이 변화하고, 상기 기준점수가 낮아지는 경우 상기 유효 영역의 면적이 넓어지므로, 상기 기준점수가 낮아지는 경우 상기 유효 영역의 적어도 일부가 연속되면서 가능한 넓은 영역을 감시하도록 상기 카메라모듈이 향하는 방향이 변화하는, 산업현장의 쓰러짐 감지 감시카메라 시스템."}
{"patent_id": "10-2021-0147173", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "카메라모듈이 산업현장을 촬영하여 광학영상을 생성하고 서버로 전송하는 영상 생성 단계;상기 서버의 사람이상 판단부가 상기 광학영상에서 프레임을 추출하여 쓰러짐 인식 인공지능 모델에 입력하여쓰러진 사람이 존재하면 사람이상 이벤트가 발생한 것으로 판단하는 사람이상 판단단계; 및 상기 사람이상 판단부에서 사람이상 이벤트의 발생을 출력하는 경우, 상기 서버의 알림부가 이상 이벤트의 발생을 관리자에게 알리는 알림단계를 포함하는, 산업현장의 쓰러짐 감지 감시카메라 시스템의 동작방법."}
{"patent_id": "10-2021-0147173", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서, 사람이 쓰러져 있는 이미지가 입력데이터이고 상기 이미지에서 쓰러진 사람을 표시하는 정보가 라벨데이터인 학습데이터세트를 이용하여 학습되고, 상기 광학영상에서 추출된 프레임을 입력받으면 사람이 쓰러진 상태인지 판단하고 사람이 쓰러진 영역에 박스를 표시하고 클래스 일치도 점수를 표시하여 출력하도록 상기 쓰러짐 인식 인공지능 모델을 생성하는 모델생성단계를 더 포함하고, 상기 모델생성단계는 상기 사람이상 판단단계 이전에 미리 수행되는, 산업현장의 쓰러짐 감지 감시카메라 시스템의 동작방법."}
{"patent_id": "10-2021-0147173", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 7에 있어서, 사람이 쓰러진 것으로 판단하는 기준인 클래스 일치도 점수의 기준점수가 높아지는 경우 상기 유효 영역의 면적이 좁아지므로, 상기 기준점수가 높아지는 경우 상기 유효 영역의 적어도 일부가 연속되도록 상기 카메라모듈이향하는 방향이 변화하고, 상기 기준점수가 낮아지는 경우 상기 유효 영역의 면적이 넓어지므로, 상기 기준점수가 낮아지는 경우 상기 유효 영역의 적어도 일부가 연속되면서 가능한 넓은 영역을 감시하도록 상기 카메라모듈이 향하는 방향이 변화하도록 제어되는 기준점수 변경단계를 더 포함하는, 산업현장의 쓰러짐 감지 감시카메라시스템의 동작방법."}
{"patent_id": "10-2021-0147173", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일실시예에 따르면, 산업현장을 촬영하여 광학영상을 생성하는 카메라모듈, 및 상기 카메라모듈로부터 수신한 상기 광학영상을 분석하여 쓰러진 사람이 존재하는지 판단하는 서버를 포함하는, 산업현장의 쓰러짐 감지 감시카메라 시스템 및 이의 동작방법을 제공하며, 사람이 쓰러진 경우 사람이상 이벤트를 관리자에게 알려, 사고 를 미연에 방지하거나 발생한 사고를 빠르게 대처할 수 있다."}
{"patent_id": "10-2021-0147173", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 산업현장의 쓰러짐 감지 감시카메라 시스템 및 이의 동작 방법에 관한 것이다."}
{"patent_id": "10-2021-0147173", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "산업현장에서 사고에 의한 경제적 손실과 인명 손실이 발생하고 있다. 최근 정보통신기술(Information and Communication Technology)의 발전으로 산업현장의 사고를 자동으로 탐지하려는 시도가 존재한다. 종래의 산업 현장 안전 관리 기술은 설비에 설치된 센서로부터 수집된 데이터를 분석하여 사고여부를 감지하는 것으로서 이 용할 수 있는 데이터가 한정되어 있고 이용 범위가 좁은 문제가 있다. 한편, 종래에 산업현장에서 이용되는 감시카메라 시스템(CCTV)은 영상 촬영 및 저장을 통하여 출입을 확인하는 등의 단순 목적으로 이용되어 왔다. 산업현장에서는 화재, 폭발, 유독가스 누출, 고온, 연기발생 등의 다양한 사고가 발생할 수 있다. 산업현장에서 이상여부를 검출하고 사고 발생 전에 미리 대처할 수 있기 위하여 산업현 장에서 이상여부를 감지하기 위한 기술이 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2019-0072703 A"}
{"patent_id": "10-2021-0147173", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일실시예에 따른 목적은, 산업현장을 촬영하는 카메라로부터 수신한 영상을 분석하여 쓰러진 사람이 존재하면 이상 이벤트가 발생한 것으로 판단하고, 관리자에게 알림을 전송하는 산업현장의 쓰러짐 감지 감시카 메라 시스템 및 이의 동작 방법을 제공한다."}
{"patent_id": "10-2021-0147173", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템은, 산업현장을 촬영하여 광학영상을 생 성하는 카메라모듈, 및 상기 카메라모듈로부터 수신한 상기 광학영상을 분석하여 쓰러진 사람이 존재하는지 판 단하는 서버를 포함할 수 있다. 또한, 상기 서버는 상기 카메라모듈로부터 수신한 광학영상을 저장하는 저장부, 상기 광학영상을 분석하여 사람 이 쓰러진 상태인지 판단하고, 사람이 쓰러진 것으로 판단되는 경우 사람이상 이벤트의 발생을 출력하는 사람이 상 판단부, 및 상기 사람이상 판단부에서 사람이상 이벤트의 발생을 출력하는 경우, 이상 이벤트의 발생을 관리 자에게 알리는 알림부를 포함할 수 있다. 또한, 상기 사람이상 판단부는 상기 광학영상에서 프레임을 추출하고, 상기 프레임을 쓰러짐 인식 인공지능 모 델에 입력하여, 상기 쓰러짐 인식 인공지능 모델이 상기 프레임 내에 쓰러진 사람이 존재하는 것으로 판단하는 경우, 사람에게 이상 이벤트가 발생한 것으로 판단할 수 있다. 또한, 상기 쓰러짐 인식 인공지능 모델은 사람이 쓰러져 있는 이미지가 입력데이터이고 상기 이미지에서 쓰러진 사람을 표시하는 정보가 라벨데이터인 학습데이터를 이용하여 학습되고, 상기 광학영상에서 추출된 프레임을 입 력받으면 사람이 쓰러진 상태인지 판단하고 사람이 쓰러진 영역에 박스를 표시하고 클래스 일치도 점수를 표시 하여 출력할 수 있다. 또한, 상기 쓰러짐 인식 인공지능 모델은 사람, 차량, 동물을 구분하기 위한 목적으로 훈련된 CNN 모델의 네트 워크 가중치를 심층전이학습을 적용하여 사람의 쓰러짐을 판단하도록 조정하여 형성될 수 있다. 또한, 상기 카메라모듈은 감시 영역 중에서 쓰러짐 자세와 상기 카메라모듈과의 위치관계에 따라 달라지는 유효 영역의 적어도 일부가 연속되도록 상기 산업현장에 복수개 배치될 수 있다. 또한, 상기 사람이상 판단부는 상기 쓰러짐 인식 인공지능 모델이 출력하는 클래스 일치도 점수가 기준점수보다 높은 경우 사람이 쓰러진 것으로 판단할 수 있다. 또한, 상기 카메라모듈은 상기 기준점수가 높아지는 경우 상기 유효 영역의 면적이 좁아지므로, 상기 기준점수 가 높아지는 경우 상기 유효 영역의 적어도 일부가 연속되도록 상기 카메라모듈이 향하는 방향이 변화하고, 상 기 기준점수가 낮아지는 경우 상기 유효 영역의 면적이 넓어지므로, 상기 기준점수가 낮아지는 경우 상기 유효 영역의 적어도 일부가 연속되면서 가능한 넓은 영역을 감시하도록 상기 카메라모듈이 향하는 방향이 변화할 수 있다. 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 동작방법은, 카메라모듈이 산업현장을 촬영하여 광학영상을 생성하고 서버로 전송하는 영상 생성 단계, 상기 서버의 사람이상 판단부가 상기 광학영상 에서 프레임을 추출하여 쓰러짐 인식 인공지능 모델에 입력하여 쓰러진 사람이 존재하면 사람이상 이벤트가 발생한 것으로 판단하는 사람이상 판단단계, 및 상기 사람이상 판단부에서 사람이상 이벤트의 발생을 출력하는 경 우, 상기 서버의 알림부가 이상 이벤트의 발생을 관리자에게 알리는 알림단계를 포함할 수 있다. 또한, 사람이 쓰러져 있는 이미지가 입력데이터이고 상기 이미지에서 쓰러진 사람을 표시하는 정보가 라벨데이 터인 학습데이터세트를 이용하여 학습되고, 상기 광학영상에서 추출된 프레임을 입력받으면 사람이 쓰러진 상태 인지 판단하고 사람이 쓰러진 영역에 박스를 표시하고 클래스 일치도 점수를 표시하여 출력하도록 상기 쓰러짐 인식 인공지능 모델을 생성하는 모델생성단계를 더 포함할 수 있다. 또한, 상기 모델생성단계는 상기 사람이상 판단단계 이전에 미리 수행될 수 있다. 또한, 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 동작방법은, 사람이 쓰러진 것으로 판단하는 기준인 클래스 일치도 점수의 기준점수가 높아지는 경우 상기 유효 영역의 면적이 좁아지므로, 상기 기준점수가 높아지는 경우 상기 유효 영역의 적어도 일부가 연속되도록 상기 카메라모듈이 향하는 방향이 변화하고, 상기 기준점수가 낮아지는 경우 상기 유효 영역의 면적이 넓어지므로, 상기 기준점수가 낮아지는 경 우 상기 유효 영역의 적어도 일부가 연속되면서 가능한 넓은 영역을 감시하도록 상기 카메라모듈이 향하는 방향 이 변화하도록 제어되는 기준점수 변경단계를 더 포함할 수 있다. 본 발명의 특징 및 이점들은 첨부도면에 의거한 다음의 상세한 설명으로 더욱 명백해질 것이다. 이에 앞서 본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이고 사전적인 의미로 해석되어서는 아니 되며, 발명자가 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념을 적절하게 정의할 수 있다 는 원칙에 입각하여 본 발명의 기술적 사상에 부합되는 의미와 개념으로 해석되어야만 한다."}
{"patent_id": "10-2021-0147173", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일실시예에 따르면, 산업현장에서 쓰러진 사람이 존재하는 경우 이상 이벤트가 발생한 것으로 판단하 고, 관리자에게 이상 이벤트 발생을 자동으로 통보하여 신속하게 사고에 대응하도록 지원할 수 있다."}
{"patent_id": "10-2021-0147173", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 일실시예의 목적, 특정한 장점들 및 신규한 특징들은 첨부된 도면들과 연관되어지는 이하의 상세한 설명과 바람직한 실시예들로부터 더욱 명백해질 것이다. 본 명세서에서 각 도면의 구성요소들에 참조번호를 부 가함에 있어서, 동일한 구성 요소들에 한해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 번호를 가 지도록 하고 있음에 유의하여야 한다. 또한, \"일면\", \"타면\", \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다 른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 상기 용어들에 의해 제한되는 것은 아니다. 이 하, 본 발명의 일실시예를 설명함에 있어서, 본 발명의 일실시예의 요지를 불필요하게 흐릴 수 있는 관련된 공 지 기술에 대한 상세한 설명은 생략한다. 또한, 본 발명에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니며, 단수의 표현은 문맥상 달리 명시하지 않는 한 복수의 표현을 포함한다는 것을 알아야 한다. 이하, 첨부된 도면을 참조하여, 본 발명의 일실시예를 상세히 설명한다. 도 1은 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템과 산업현장을 나타내는 도면이다. 산업현장은 공장, 연구소, 실험실, 화학플랜트, 정유플랜트, 자동화시설, 스마트팩토리 등의 다양한 실내 시 설 뿐만 아니라, 항구, 항만, 물류허브, 하역장 등의 야외 시설들을 포함할 수 있다. 산업현장에는 모터, 히 터, 냉방기, 파이프, 증류기, 등 다양한 설비들이 설치될 수 있다. 산업현장에는 설비를 이용하여 일 하는 작업자, 관리자, 또는 방문자 등 다양한 사람이 있을 수 있다. 산업현장에서 발생하는 사고는 사람 을 다치게 하거나, 설비를 파손시킬 수 있다. 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카 메라 시스템은 산업현장에서 발생할 수 있는 사고를 미리 방지하거나, 사고가 발생한 경우 빠르게 대처 하기 위하여, 사람에게 발생하는 이상 이벤트를 감지하고 관리자에게 이상 이벤트의 발생을 알릴 수 있다. 관리자는 산업현장의 안전책임자, 작업자 등을 포함할 수 있고, 소방서, 구급대, 구청 등의 공무원 등을 포 함할 수 있다. 이상 이벤트는 사람이상 이벤트를 포함할 수 있다. 이상 이벤트는 설비에 이상이 존재하거나, 화재 등이 발생하 는 등 다양한 사고를 포함할 수도 있다. 사람이상 이벤트는 사람이 쓰러진 것을 포함할 수 있다. 예를 들어, 유독가스 유출이나, 감전 등의 사고에 의해 사람이 쓰러지거나, 심장마비, 뇌졸증 등의 질병에 의해 사람 이 쓰러져, 사람이 바닥에 누워있는 경우 사람이상 이벤트가 발생한 것이다. 본 발명의 일실시예는 다양 한 원인으로 인하여 사람이상 이벤트가 발생하여 사람이 쓰러진 상태인지 여부를 감지할 수 있다. 도 2는 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템을 나타내는 블록도이다. 도 1 및 도 2를 함께 참조한다. 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템은, 산업현장을 촬영하여 광학영 상을 생성하는 카메라모듈, 및 카메라모듈로부터 수신한 광학영상을 분석하여 쓰러진 사람이 존재 하는지 판단하는 서버를 포함할 수 있다. 카메라모듈은 설비 또는 사람이 존재하는 공간을 촬영하도록 산업현장에 배치될 수 있다. 카메라 모듈은 산업현장에 복수개 배치될 수 있다. 카메라모듈은 서버로부터 수신하는 제어신호에 따라 촬영 방향을 변경할 수 있다. 카메라모듈은 하나 이상의 광학카메라를 포함할 수 있다. 카메라 모듈은 하나의 모듈에 광학카메라 및 열화상카메라를 함께 포함할 수 있다. 광학카메라는 RGB 방식의 일반적인 디지털 카메라를 포함할 수 있다. 광학카메라는 가시광선 영역에 서 산업현장을 촬영하여 사람의 눈으로 인식가능한 광학영상을 생성할 수 있다. 열화상카메라는 적 외선 영역을 촬영하는 디지털 카메라를 포함할 수 있다. 열화상카메라는 적외선 영역에서 산업현장을 촬영하여, 그레이스케일(GrayScale)의 열화상을 생성할 수 있다. 서버는 산업현장에 설치될 수 있다. 서버는 카메라모듈과 유선 또는 무선 네트워크를 통해 연결되어, 카메라모듈이 생성한 영상을 수신할 수 있고, 카메라모듈을 제어할 수 있다. 서버는 정보처리기능을 갖는 컴퓨터 장치이다. 카메라모듈과 서버는 폐쇄회로(Closed Circuit)로 연결되거나, IP 주소를 이용한 암호화된 네트워크 등을 이용하여 연결될 수 있다. 서버는 카메라모듈로부터 수신한 광학영상 및 열화상을 저장하는 저장부, 광학영상을 분석하여 사람이 쓰러진 상태인지 판단하고, 사람이 쓰러진 것으로 판단되는 경우 사람이상 이벤트의 발생을 출력 하는 사람이상 판단부, 사람이상 판단부에서 사람이상 이벤트의 발생을 출력하는 경우, 이상 이벤트 의 발생을 관리자에게 알리는 알림부를 포함할 수 있다. 서버는 유선 또는 무선 네트워크와 연결되어 데이터를 송수신하는 통신부, 관리자의 명령을 입력받거나 데이터나 정보를 관리자에게 제공하는 인터페이 스부를 더 포함할 수 있다. 저장부는 광학영상, 열화상, 학습된 쓰러짐 인식 인공지능 모델, 본 발명의 일실시예에 따른 산업현 장의 쓰러짐 감지 감시카메라 시스템의 동작방법이 소프트웨어로 구현된 프로그램 코드, 그 밖에 필요한 데 이터를 저장할 수 있다. 저장부는 하드디스크, 메모리, 클라우드 저장장치, 데이터베이스 등을 포함할 수 있다. 통신부는 카메라모듈, 관리자 단말, 서버 사이에서 데이터를 송수신할 수 있도록, 유선 또 는 무선 네트워크에 연결될 수 있다. 통신부는 월드와이드웹(www), 이더넷(ethernet), IPv4, IPv6, LAN, WAN, 등의 알려진 통신방식을 이용할 수 있다. 통신부는 wi-fi, bluetooth, zigbee, 등의 알려진 근거리 통신방식을 이용할 수도 있다. 인터페이스부는 관리자의 명령을 수신할 수 있는 키보드, 마우스, 터치패널, 스위치 등의 입력장치를 포함 할 수 있고, 관리자에게 정보를 제공할 수 있는 디스플레이, 스피커, 프린터 등의 출력장치를 포함할 수 있다. 사람이상 판단부, 알림부는 프로그램 코드로 작성되어 서버의 프로세서(Processor) 또는 그래픽 처리장치(GPU)에서 구동되는 방식으로 구현될 수도 있고, 서버 내에 포함되는 독립된 컴퓨터 장치로 구현 될 수도 있다. 사람이상 판단부는 카메라모듈로부터 실시간으로 수신되는 광학영상 또는 저장부에 실시간으로 저장되는 광학영상을 분석하여 사람이 쓰러진 상태인지 판단할 수 있다. 사람이상 판단부는 광학영상에 서 프레임을 추출하고, 프레임을 쓰러짐 인식 인공지능 모델에 입력하여, 쓰러짐 인식 인공지능 모델(24 1)이 프레임 내에 쓰러진 사람이 존재하는 것으로 판단하는 경우, 사람에게 이상 이벤트가 발생한 것으로 판단할 수 있다. 사람이상 판단부는 쓰러짐 인식 인공지능 모델을 포함할 수 있다. 쓰러짐 인식 인공지능 모델은 사람이 쓰러져 있는 이미지가 입력데이터이고 이미지에서 쓰러진 사람을 표시하는 정보가 라벨데이터인 학습데이터를 이용하여 학습되고, 광학영상에서 추출된 프레임을 입력받으면 사람이 쓰러진 상태인지 판단하 고 사람이 쓰러진 영역에 박스를 표시하고 클래스 일치도 점수를 표시하여 출력할 수 있다. 클래스 일치도 점수는 쓰러짐 인식 인공지능 모델이 추론하여 표시한 박스에 포함된 객체가 쓰러진 사람 에 해당하는 정도를 말한다. 클래스 일치도 점수는 쓰러짐 인식 인공지능 모델의 출력값 중 하나이다. 사람이상 판단부는 쓰러짐 인식 인공지능 모델이 출력하는 클래스 일치도 점수가 기준점수보다 높은 경우 사람이 쓰러진 것으로 판단할 수 있다. 기준점수는 관리자에 의해 변경될 수 있다. 쓰러짐 인식 인공지능 모델은 하나의 프레임에 복수의 사람이 쓰러진 상태로 판단되는 경우, 사람마 다 박스를 표시하고 클래스 일치도 점수를 표시할 수 있다. 알림부는 사람이상 판단부에서 사람이상 이벤트의 발생을 출력하면, 관리자에게 이상 이벤트의 발생 을 알리고, 이상 이벤트의 내용을 알릴 수 있다. 이상 이벤트의 내용은 이상 이벤트를 촬영한 카메라모듈 의 위치, 이상 이벤트 발생 시간, 이상 이벤트가 발생한 것으로 판단된 광학영상의 프레임, 이상 이벤트에 대응 하기 위한 가이드라인, 그 밖에 필요한 정보를 포함할 수 있다. 알림부는 전화, 문자메세지, 이메일 등을 관리자 단말로 자동으로 전송하거나, 디스플레이에 이상 이벤트의 발생을 표시하거나, 스피커를 통해 이상 이벤트의 발생을 소리로 알릴 수 있다. 알림부는 사람이상 이벤트가 발생하면 쓰러짐 인식 인공지능 모델이 쓰러진 사람을 표시한 박스를 광학영상의 프레임에 표시한 이미지를 관리자에게 제공할 수 있다. 예를 들어, 알림부는 쓰러진 사람이 박스로 표시된 이미지를 포함하는 메일을 자동으로 생성하고 관리자의 메일주소로 송신할 수 있다. 알림부는 관리자에게 제공하는 알림에 쓰러진 사람의 수를 포함할 수 있다. 쓰러짐 인식 인공지능 모델 이 하나의 프레임에 복수의 사람이 쓰러진 것으로 판단하는 경우, 알림부는 쓰러진 사람의 수 를 관리자에게 제공할 수 있다. 도 3은 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 동작방법을 나타내는 흐름 도이다. 도 2 및 도 3을 함께 참조한다. 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 동작방법은, 카메라모듈의 광학카메라가 산업현장을 촬영하여 광학영상을 생성하고 서버로 전송하며, 카메라모듈의 열 화상카메라가 산업현장을 촬영하여 열화상을 생성하고 상기 서버로 전송하는 영상 생성 단계 (S21), 서버의 사람이상 판단부가 광학영상에서 프레임을 추출하여 쓰러짐 인식 인공지능 모델 에 입력하여 쓰러진 사람이 존재하면 사람이상 이벤트가 발생한 것으로 판단하는 사람이상 판단단계(S22), 및 사람이상 판단부에서 사람이상 이벤트의 발생을 출력하는 경우, 서버의 알림부가 이상 이벤 트의 발생을 관리자에게 알리는 알림단계(S24)를 포함할 수 있다. 영상 생성 단계(S21), 사람이상 판단단계(S22)는 감시단계(S20)에 포함될 수 있다. 감시단계(S20)는 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 동작방법이 수행되는 동안 실시간으로 반복 수행된다. 알림부는 사람이상 판단부에서 이상 이벤트를 출력하는지 판단(S23)하고, 이상 이벤트가 발생한 경우 알림단계(S24)를 수행한다. 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 동작방법은, 학습데이터를 이용하 여 쓰러짐 인식 인공지능 모델을 생성하는 모델생성단계(S11)를 더 포함할 수 있고,관리자가 사람이상 판 단부에서 사람이 쓰러진 것인지 여부를 판단하는 기준이 되는 기준점수를 변경하고, 그에 따라 카메라 모듈의 방향을 제어하는 기준점수 변경단계(S12)를 더 포함할 수 있다. 모델생성단계(S11)와 기준점수 변 경단계(S12)는 준비단계(S10)에 포함될 수 있다. 준비단계(S10)는 감시단계(S20)를 수행하기 위하여 산업현장의 쓰러짐 감지 감시카메라 시스템을 세팅하는 과정이다. 준비단계(S10)는 감시단계(S20) 이전에 실시될 수 있 다. 준비단계(S10)가 수행되는 동안에는 감시단계(S20)의 동작이 중지될 수 있다. 준비단계(S10) 및 감시단계 (S10)는 서버의 프로세서에서 구동될 수 있는 프로그램코드로 작성되어 저장부에 저장될 수 있다. 모델생성단계(S11)는 사람이상 판단단계(S22) 이전에 미리 수행될 수 있다. 즉, 모델생성단계(S11)는 산업현장 의 쓰러짐 감지 감시카메라 시스템이 산업현장에 설치되기 전에 수행될 수 있다. 모델생성단계(S11)는 산업현장의 쓰러짐 감지 감시카메라 시스템이 산업현장에 설치된 이후에도, 쓰러짐 인식 인공지능 모델 의 성능 향상을 위하여 정기적 또는 비정기적으로 수행될 수도 있다. 모델생성단계(S11)가 수행되어 성능 이 향상된 쓰러짐 인식 인공지능 모델이 생성되면, 서버에 저장된 기존 쓰러짐 인식 인공지능 모델 을 업데이트할 수 있다. 기준점수 변경단계(S12)는 관리자의 판단 또는 쓰러짐 인식 인공지능 모델의 업데이트에 따라 수행될 수 있다. 기준점수가 변경되면 카메라모듈이 감시하는 영역에서 사람의 쓰러짐을 판단할 수 있는 유효 영 역(EA)의 넓이가 달라지므로, 사람이상 판단부는 쓰러진 사람을 인식하지 못하는 사각이 생기지 않도록 카메라모듈의 방향을 변경할 수 있다. 도 4는 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 쓰러짐 인식 인공지능 모 델을 설명하는 도면이다. 도 2, 3을 함께 참조한다. 모델생성단계(S11)는 쓰러짐 인식 인공지능 모델을 생성한다. 모델생성단계(S11)는 서버에서 수행될 수도 있고, 서버와 원격으로 연결된 다른 컴퓨터 장치에서 수행될 수도 있다. 학습데이터로 이용되는 이미지는 사람이 쓰러져 있는 상태를 촬영한 이미지이다. 이미지 획득 단계에서는 학 습데이터로 이용될 이미지를 수집한다. 학습데이터용 이미지는 다양한 경로로 획득할 수 있다. 예를 들어, 웹 크롤링을 이용하여 공개된 이미지들을 수집할 수 있다. 또는 인공지능 학습용으로 수집된 데이터셋(예를 들어, Fallen Person Dataset, Human Pose Dataset 등)에 포함된 이미지들 중에서 사람이 쓰러진 상태를 촬영한 이미지를 선별할 수도 있다. 학습데이터 생성 단계에서는 학습데이터용 이미지를 전처리하여 입력데이터 및 라벨데이터를 생성한다. 입력데 이터는 학습데이터용 이미지의 크기를 조절하여 생성한다. 예를 들어, 학습데이터용 이미지를 전처리하여, 이미 지의 폭이 608픽셀, 높이가 608 픽셀의 RGB방식(3개 채널)의 이미지로 가공할 수 있다. 라벨데이터는 입력데이 터에서 사람이 쓰러진 형태를 표시하는 박스의 위치와, 클래스 네임을 포함하는 문자열로 생성될 수 있다. 예를 들어, 라벨데이터는 클래스 네임(Class name)이 \"Fall\"이고, 사람이 쓰러진 상태를 표시하는 박스의 위 치(Box location)가 숫자로 표시(0.531, 0.529, 0.877, 0.286)될 수 있다. 박스의 위치는 박스의 중심의 폭 방 향 좌표(0.531), 박스의 중심의 높이 방향 좌표(0.529), 박스의 폭(0.877), 박스의 높이(0.286)를 숫자로 순서 대로 나열한 문자열일 수 있다. 하나의 학습데이터용 이미지를 전처리하여, 하나의 입력데이터 이미지와 라벨데 이터 문자열을 생성할 수 있다. 위와 같은 방식으로, 복수의 입력데이터 이미지와 대응하는 복수의 라벨데이터 문자열을 생성할 수 있다. 학습데이터가 생성되면, 학습데이터에 포함된 복수의 입력데이터 및 라벨데이터를 복수의 배치(batch)로 분할하 는 배치 분할을 수행한다. 배치 분할 단계에서 배치 크기(batch size)는 64, 배치 분할(mini batch)는 64로 분 할하여 학습 속도를 향상시킬 수 있다. 학습데이터를 복수개의 배치로 분할한 다음, 모델 훈련 단계를 수행한다. 모델 훈련 단계에서는 심층전이학습 (Deep Transfer Learning)을 이용할 수 있다. 네트워크 설정 파일에는 604x604, 708x708 사이즈의 네트워크 구 조가 설정되어 있다. 쓰러짐 인식 인공지능 모델은 사람, 차량, 동물을 구분하기 위한 목적으로 훈련된 CNN 모델의 네트워크 가중치를 심층전이학습을 적용하여 사람의 쓰러짐을 판단하도록 조정하여 형성될 수 있다. 네트워크 구조는 다양한 객체들, 예를 들어 사람, 차량, 동물 등의 분류를 위해 이용되는 CNN(Convolutional Neural Network) 구조를 이용한다. 기존 네트워크 가중치는 사람, 차량, 동물 등을 분류 하기 위하여 CNN 구조로 미리 학습되어 있는 가중치이다. 기존 네트워크 가중치로 CNN 네트워크 구조를 세팅한 다음, 분할된 학습데이터를 이용하여 추가학습을 수행하여 가중치를 파인튜닝(fine-tuning)하여 쓰러짐 가중치 를 생성한다. 쓰러짐 가중치는 사람이 쓰러진 상태를 포함하는 학습데이터를 이용하여 학습된 결과, 기존 네 트워크 가중치가 파인 튜닝되어 생성된 가중치이다. 파인튜닝 단계에서 604x604 네트워크 구조를 학습률의 초기 값 0.01%, 훈련반복수 6000으로 설정하고 학습을 수행하고, 파인튜닝 단계에서 708x708 네트워크 구조를 학습률 의 초기값 0.01%, 훈련반복수 6000으로 설정하고 학습을 수행하고, 708x708 네트워크 구조를 학습률의 초기값 0.01%, 훈련반복수 6000으로 설정하고 학습을 수행하여, 3개의 학습된 쓰러짐 인식 인공지능 모델을 생성 하였다. 학습을 통해 쓰러짐 인식 인공지능 모델을 생성한 다음, 성능 테스트 단계를 수행한다. 성능 테스트 단계 는 쓰러짐 인식 인공지능 모델이 사람이 쓰러진 상태를 얼마나 잘 판단하는지를 평가한다. 성능 테스트 는 손실, IoU, mAP, 클래스 일치도 점수를 산출하고, 정확도 분포를 생성하여 수행한다. 손실(Loss)은 아래 수학식 1에 따라 계산된다. 수학식 1"}
{"patent_id": "10-2021-0147173", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "yi: 예측 모델의 라벨 값, ti: 실제 모델의 라벨 값, i: 학습데이터 번호, N: 학습데이터 개수 손실을 계산하여 손실이 최소가 되는 상태의 쓰러짐 인식 인공지능 모델의 성능이 가장 좋은 것으로 판단 한다. IoU(Intersection over Union)는 아래 수학식 2에 의해 계산된다. 수학식 2"}
{"patent_id": "10-2021-0147173", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "라벨데이터의 박스는 학습데이터의 입력데이터 이미지에서 사람이 쓰러진 부분을 표시하는 박스이고, 예측된 박스는 쓰러짐 인식 인공지능이 학습데이터의 입력데이터 이미지를 입력받고 사람이 쓰러진 부분이라고 판단 되는 영역을 표시한 박스이다. 두 박스가 완전히 겹치는 경우 IoU는 1이 되며, 본 발명의 일실시예에서 IoU가 0.5인 경우를 검출 지표로 이용한다. mAP(mean Average Precision)는 실제 데이터와 예측 결과를 비교하여 오차 행렬(Confusion Matrix)를 생성하고, AP를 구하여 AP가 클수록 정확도가 높은 모델로 평가하는 방법이다. 오차행렬은 아래 표 1에 따라 산 출된다. 표 1 실제 데이터 (Ground Truth)예측 결과 Positive(목표 객체) Negative(목표하지 않은 객체) Positive (목표 객체)TP(Ture Positive) (목표 객체를 올바르게 검출)FN(False Negative) (목표 객체가 검출되지 않음)Negative (목표하지 않은 객체)FP(False Positive) (목표하지 않은 객체를 검출)TN(True Negative) (목표하지 않은 객체가 검출되지 않 음) 정밀도(Precision)은 전체 검출 결과 중 옳게 검출한 비율을 말하며, Precision=TP/(TP+FP)로 산출되고, 재현율 (Recall)은 실제 옳은 결과물 중 옳다고 예측한 것의 비율을 말하며, Recall=TP/(TP+FN)으로 산출된다. AP는 세 로가 정밀도이고 가로가 재현율인 그래프의 아래 면적으로 구해진다. 클래스 일치도 점수(Class Confidence Score)는 쓰러짐 인식 인공지능 모델이 쓰러진 사람을 얼마나 정확하게 인식하였는지를 나타내는 값이 다. 클래스 일치도 점수는 아래 수학식 3에 의해 계산된다. 수학식 3"}
{"patent_id": "10-2021-0147173", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "클래스 일치도 점수는 conditional class probability와 box confidence의 곱으로 표현된다. conditional class probability는 현재의 object가 classi일 확률을 나타내고, box confidence는 라벨데이터의 박스 위치와 쓰러짐 인식 인공지능 모델이 예상한 박스의 위치의 유사도를 의미한다. 따라서 클래스 일치도 점수는 클 래스 네임을 올바르게 분류하였는지에 관한 정확도와, 박스를 얼마나 정확하게 예상하였는지 여부를 모두 반영 하는 수치이다. 608x608 네트워크 구조로 훈련된 모델은 704x704 네트워크 구조로 훈련된 모델보다 상대적으로 평균 프레임 처 리속도가 빠르다. 네트워크 구조의 크기가 클수록 학습에 소요되는 시간 및 프레임의 처리 시간이 증가한다. 그 러나, 608x608 네트워크 구조로 훈련된 모델보다 704x704 네트워크 구조로 훈련된 모델이 클래스 일치도 점수가 높다. 동일하게 704x704 네트워크 구조이지만, 훈련반복수가 6000인 모델보다 훈련반복수가 20000인 모델이 손 실(Loss)가 낮고, 클래스 일치도 점수가 98%이상으로 가장 높게 나타났다. 따라서 본 발명의 일실시예의 쓰러짐 인식 인공지능 모델은 704x704 네트워크 구조이면서 훈련반복수가 20000인 모델을 이용한다. 정확도 분포는 쓰러짐 인식 인공지능 모델이 사람의 쓰러짐을 판단함에 있어서, 카메라 모듈과 사람 이 쓰러진 자세의 관계 및, 카메라 모듈과 사람이 쓰러진 위치의 관계에 따라 정확도가 달라지는 것을 나 타내는 그래프이다. 도 5는 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 카메라모듈과 쓰러진 자세의 관계를 나타내는 도면이다. 자세 1(Form 1)은 카메라가 촬영하는 방향(화살표 A)에 수직인 방향(화살표 B)으로 사람의 머리와 발이 향하 는 자세이고, 자세 2(Form 2)는 카메라가 촬영하는 방향(화살표 A)에 나란한 방향(화살표 C)으로 사람의 머 리와 발이 향하는 자세이다. 사람이 쓰러지는 자세는 다양하다. 사람이 쓰러지는 자세에 따라 카메라모듈 이 촬영한 광학영상에 포착되는 자세는 다르다. 따라서 쓰러짐 인식 인공지능 모델은 사람이 쓰러 진 자세에 따라 쓰러짐을 인식하는 클래스 일치도 점수가 다를 수 있다. 도 5는 카메라모듈이 촬영하는 감시 영역(MA, Monitoring Area)의 중앙 부분에 쓰러진 사람이 위치하는 것을 도시하였으나, 감시 영역(MA)의 가장자리 부분에 쓰러진 사람이 위치할 수도 있다. 감시 영역(MA)의 가 장자리 부분에 쓰러진 사람이 위치하는 경우 광학영상에 사람이 전부 촬영되지 않는 등의 문제가 존재할 수 있다. 이러한 경우 쓰러짐 인식 인공지능 모델이 쓰러진 사람을 인식할 수 없는 문제가 발생할 수 있다. 따라서 카메라모듈과 쓰러진 사람과의 위치 및 방향에 따라 쓰러짐 인식 정확도가 달라질 수 있 다. 도 6은 자세 1(Form 1)에 따른 쓰러짐 인식 정확도 분포를 나타내는 도면이다. 도 7은 자세 2(Form 2)에 따른 쓰러짐 인식 정확도 분포를 나타내는 도면이다. 도 6 및 도 7은 정확도 분포는 클래스 일치도 점수를 기준으로 20% 부터 90% 까지 10% 간격으로 라인 및 음영을 이용하여 표시된다. 카메라모듈은 지면으로부터 1.8m 높 이에 설치된 상태에서 광학영상을 촬영하여 정확도 분포를 시험하였다. 카메라모듈이 촬영하는 감시 영역 (MA)은 가로 16m 세로 12m을 시험하였다. 도 6의 자세 1(Form 1)에 따른 쓰러짐 인식 정확도 분포에서 기준점수를 90%로 정하면, 90% 이상의 클래스 일치 도 점수를 나타내는 유효 영역(EA, Effective Area)은 카메라모듈로부터 카메라가 촬영하는 방향으로 약 4m 떨어진 위치에서 감시 영역(MA)의 끝인 12m 위치까지이고, 카메라가 촬영하는 방향에 수직한 방향으로 카메 라를 중심으로 좌우 6m 위치까지이며, 전체적으로 카메라로부터 거리가 먼 방향의 변의 넓이가 넓은 사다리꼴 형으로 나타난다. 도 7의 자세 2(Form 2)에 따른 쓰러짐 인식 정확도 분포에서 기준점수를 90%로 정하면, 90% 이상의 클래스 일치 도 점수를 나타내는 유효 영역(EA)은 카메라모듈로부터 카메라가 촬영하는 방향으로 약 5m 떨어진 위치에 서 10m 떨어진 위치까지이고, 카메라가 촬영하는 방향에 수직한 방향으로 카메라를 중심으로 좌우 5m 위치까지 이며, 전체적으로 카메라로부터 가까운 변이 카메라를 중심으로한 부채꼴 형이고 거리가 먼 방향의 변의 넓이가 넓은 사다리꼴 형으로 나타난다. 정리하면, 카메라모듈과 쓰러진 사람의 자세 및 위치에 따라 쓰러짐 인식 정확도가 달라지는 것을 알 수 있다. 카메라모듈이 촬영하는 방향에 수직인 방향으로 사람의 머리와 발이 향하는 자세 1(Form 1)인 경우 쓰러짐 인식 정확도가 높고, 카메라모듈이 촬영하는 방향에 나란한 방향으로 사람의 머리와 발이 향하는 자세 2(Form 2)인 경우 쓰러짐 인식 정확도가 낮다. 그리고, 카메라모듈이 촬영하는 방향에 수직인 방향으로 사람의 머리와 발이 향하는 자세 1(Form 1)에 비하여, 카메라모듈이 촬영하는 방향에 나란한 방향으로 사람의 머리와 발이 향하는 자세 2(Form 2)는 카메라모듈과 가까운 부분에 반원형의 사각 (blind spot)이 존재하고, 전체적으로 유효 영역(EA)의 형태가 불규칙하다. 그리고 쓰러짐 인식 정확도가 높을 수록 감시 영역(MA)에서 유효 영역(EA)이 차지하는 면적이 작아지고, 쓰러짐 인식 정확도가 낮을수록 감시 영역 (MA)에서 유효 영역(EA)이 차지하는 면적이 넓어진다. 따라서 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 카메라모듈은 감시 영역(MA) 중에서 쓰러짐 자세와 카메라모듈과의 위치관계에 따라 달라지는 유효 영역(EA)의 적어도 일부가 연속되도록 산업현장에 복수개 배치될 수 있다. 유효 영역(EA)의 적어도 일부가 연속되도록 카메라모듈(10 0)이 산업현장에 복수개 배치되어야, 사각(blind spot) 없이 쓰러진 사람을 인식할 수 있다. 카메라모듈 의 감시 영역(MA)이 연속되도록 배치하는 경우, 임의의 카메라모듈의 유효 영역(EA)과 인접한 카메라 모듈의 유효 영역(EA) 사이에 쓰러짐 인식 정확도가 매우 낮은 영역이 존재하게 되므로 산업현장을 효 과적으로 모니터링하기 어렵다. 본 발명의 일실시예와 같이 인접한 카메라모듈의 유효 영역(EA)의 적어도 일부가 겹치거나 연속되도록 카메라모듈을 배치하면 유효 영역(EA)의 경계 부분에서도 쓰러진 사람을 효과적으로 인식할 수 있다. 도 8은 쓰러짐 인식 정확도 분포를 고려하여 복수의 카메라모듈을 배치한 상태와 기준점수 변경단계(S12) 를 설명하는 도면이다. 도 8은 산업현장이 사각이고 4개의 카메라모듈이 배치된 상태를 예시적으로 도 시한다. 산업현장의 형태와 설비의 배치에 따라 카메라모듈이 다양하게 배치될 수 있다. 도 8에서 (a)는 기준점수가 70%인 경우 카메라모듈의 감시 영역(MA)과 유효 영역(EA)을 나타낸 도면이다. 인접한 카메라모듈의 유효 영역(EA)들이 일부 겹쳐지도록 카메라모듈의 방향이 고정된 상태이다. 기준점수 변경단계(S12)에서 관리자가 기준점수를 변경하면 유효 영역(EA)의 면적이 변경된다. 도 8에서 (b)는 기준점수가 70%에서 90%로 변경된 경우 카메라모듈의 감시 영역(MA)과 유효 영역(EA)을 나타낸 도면이다. 기준점수가 70%에서 90%로 상향되어, 유효 영역(EA)의 면적이 줄어들고, 인접한 카메라모듈의 유효 영역 (EA)들이 겹쳐지지 않게 되었다. 따라서, 서버의 사람이상 판단부는 카메라모듈의 유효 영역 (EA)들이 일부 겹치도록 카메라모듈의 촬영 방향을 변경하도록 카메라모듈을 제어한다. 도 8에서 (c)는 기준점수가 90%인 상태에서 유효 영역(EA)의 일부가 겹쳐지도록 카메라모듈의 방향이 변경 된 상태를 나타낸다. 카메라모듈의 방향은 유효 영역(EA)의 일부가 겹쳐지도록 이동된다. 카메라모듈(10 0)의 감시 영역(MA)은 서로 더 많이 겹쳐지도록 위치가 이동된다. 카메라모듈은 촬영 방향을 변경할 수 있 도록 모터 등을 포함하는 구동부를 포함할 수 있다. 기준점수 변경단계(S12)에서 관리자가 기준점수를 상향하는 변경을 수행하면 도 8의 (a), (b), (c)에 순서대로 도시된 바와 같이, 줄어든 유효 면적의 일부가 겹치도록 카메라모듈의 촬영 방향을 이동시켜, 사각을 최소화할 수 있다. 도 8에서 (d)는 기준점수가 90%에서 70%로 변경된 상태를 나타낸다. 기준점수가 하향하면 유효 영역(EA)의 면적 이 증가하고, 인접한 카메라모듈의 유효 영역(EA)들이 서로 많이 겹쳐지게 된다. 카메라모듈이 최대 한 넓은 영역을 감시할 수 있도록, 서버의 사람이상 판단부는 인접한 카메라모듈의 유효 영역 (EA)들의 일부가 더 조금 겹쳐지도록 카메라모듈의 방향을 변화시킬 수 있다. 기준점수 변경단계(S12)에서 관리자가 기준점수를 하향하는 변경을 수행하면, 도 8의 (c), (d), (a)에 순서대로 도시된 바와 같이, 늘어난 유효 면적의 일부가 겹쳐지면서 가능한 넓은 영역을 감시하도록 카메라모듈의 촬영 방향을 이동시켜, 사각을 최소화하면서 감시 영역(MA)을 최대화할 수 있다. 정리하면, 카메라모듈은 기준점수가 높아지는 경우 유효 영역(EA)의 면적이 좁아지므로, 기준점수가 높아 지는 경우 유효 영역(EA)의 적어도 일부가 연속되도록 카메라모듈이 향하는 방향이 변화하고, 기준점수가 낮아지는 경우 유효 영역(EA)의 면적이 넓어지므로, 기준점수가 낮아지는 경우 유효 영역(EA)의 적어도 일부가 연속되면서 가능한 넓은 영역을 감시하도록 카메라모듈이 향하는 방향이 변화하도록 제어될 수 있다. 이러 한 제어는 기준점수 변경단계(S12)에서 수행된다. 기준점수 변경단계(S12)는 사람이상 판단부가 수행하며, 사람이 쓰러진 것으로 판단하는 기준인 클래스 일치도 점수의 기준점수가 높아지는 경우 유효 영역(EA)의 면 적이 좁아지므로, 기준점수가 높아지는 경우 유효 영역(EA)의 적어도 일부가 연속되도록 카메라모듈이 향 하는 방향이 변화하고, 기준점수가 낮아지는 경우 유효 영역(EA)의 면적이 넓어지므로, 기준점수가 낮아지는 경 우 유효 영역(EA)의 적어도 일부가 연속되면서 가능한 넓은 영역을 감시하도록 카메라모듈이 향하는 방향 이 변화하도록 제어하는 것이다. 이상 본 발명을 구체적인 실시예를 통하여 상세히 설명하였으나, 이는 본 발명을 구체적으로 설명하기 위한 것으로, 본 발명은 이에 한정되지 않으며, 본 발명의 기술적 사상 내에서 당해 분야의 통상의 지식을 가진 자에 의해 그 변형이나 개량이 가능함은 명백하다고 할 것이다. 본 발명의 단순한 변형 내지 변경은 모두 본 발명의 영역에 속하는 것으로 본 발명의 구체적인 보호 범위는 첨 부된 특허청구범위에 의하여 명확해질 것이다."}
{"patent_id": "10-2021-0147173", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템과 산업현장을 나타내는 도면이다. 도 2는 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템을 나타내는 블록도이다. 도 3은 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 동작방법을 나타내는 흐름도이 다. 도 4는 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 쓰러짐 감지 인공지능 모델을 설명하는 도면이다. 도 5는 본 발명의 일실시예에 따른 산업현장의 쓰러짐 감지 감시카메라 시스템의 카메라모듈과 쓰러진 자세의 관계를 나타내는 도면이다. 도 6은 자세 1에 따른 쓰러짐 인식 정확도 분포를 나타내는 도면이다. 도 7은 자세 2에 따른 쓰러짐 인식 정확도 분포를 나타내는 도면이다. 도 8은 쓰러짐 인식 정확도 분포를 고려하여 복수의 카메라모듈을 배치한 상태와 기준점수 변경단계를 설명하는 도면이다."}
