{"patent_id": "10-2021-0193128", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0102753", "출원번호": "10-2021-0193128", "발명의 명칭": "아바타를 통해 영상의 음성을 수어로 통역하는 방법, 컴퓨터 장치, 및 컴퓨터 프로그램", "출원인": "라인플러스 주식회사", "발명자": "이윤지"}}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 장치에서 실행되는 수어 통역 방법에 있어서,상기 컴퓨터 장치는 메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를포함하고,상기 수어 통역 방법은,상기 적어도 하나의 프로세서에 의해, 인터넷 전화(VoIP) 기반 영상 통화에 참여하는 참여자 각각에 대해 수어통역을 위한 아바타를 설정하는 단계; 및상기 적어도 하나의 프로세서에 의해, 상기 영상 통화 중 발화자의 음성을 수어로 변환하여 상기 발화자의 아바타를 통해 통역하는 단계를 포함하는 수어 통역 방법."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 설정하는 단계는,상기 참여자 각각에 대해 영상 통화 옵션으로서 수어 통역과 아바타를 설정하는 단계를 포함하는 수어 통역 방법."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 설정하는 단계는,상기 참여자 각각에 대해 통화 영상에서 얼굴을 인식하여 인식된 얼굴을 기초로 아바타를 생성하여 상기 수어통역을 위한 아바타로 설정하는 단계를 포함하는 수어 통역 방법."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 통역하는 단계는,상기 발화자의 통화 영상과 통화 음성 중 적어도 하나로부터 상기 발화자의 감정 상태를 분석하는 단계; 및상기 발화자의 감정 상태를 상기 발화자의 아바타의 표정 또는 제스처로 표현하는 단계를 포함하는 수어 통역 방법."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 통역하는 단계는,둘 이상의 참여자가 동시에 발화하는 경우 발화자 각자의 아바타가 함께 등장하여 각 발화자의 음성을 수어로통역하는 단계를 포함하는 수어 통역 방법.공개특허 10-2023-0102753-3-청구항 6 제1항에 있어서,상기 통역하는 단계는,상기 참여자의 통화 영상이 한 화면으로 구성된 영상 통화 화면의 일측에 상기 발화자의 아바타 영상을 오버레이하여 표시하는 단계를 포함하는 수어 통역 방법."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 통역하는 단계는,상기 참여자의 통화 영상이 한 화면으로 구성된 영상 통화 화면 상에 별도의 디스플레이 요소를 통해 상기 발화자의 통화 영상을 구별하여 표시하는 단계를 포함하는 수어 통역 방법."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 표시하는 단계는,둘 이상의 참여자가 동시에 발화하는 경우 발화자 간에 상기 디스플레이 요소를 다르게 표시하되 발화자 각각에대해 아바타의 디스플레이 요소 일부를 상기 발화자 영상에 대한 디스플레이 요소와 통일시켜 표시하는 것을 특징으로 하는 수어 통역 방법."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 수어 통역 방법은,상기 적어도 하나의 프로세서에 의해, 상기 영상 통화 중 통화 영상에서 수어를 인식하여 문자 자막 또는 음성으로 통역하는 단계를 더 포함하는 수어 통역 방법."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터 장치에서 실행되는 수어 통역 방법에 있어서,상기 컴퓨터 장치는 메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를포함하고,상기 수어 통역 방법은,상기 적어도 하나의 프로세서에 의해, 동영상 플랫폼 내 영상을 대상으로 등장 인물 각각에 대해 수어 통역을위한 아바타를 설정하는 단계; 및상기 적어도 하나의 프로세서에 의해, 상기 영상의 재생 중 상기 등장 인물의 음성을 수어로 변환하여 해당 인물의 아바타를 통해 통역하는 단계를 포함하는 수어 통역 방법."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항의 수어 통역 방법을 상기 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독가능한기록 매체에 저장되는 컴퓨터 프로그램.공개특허 10-2023-0102753-4-청구항 12 컴퓨터 장치에 있어서,메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,인터넷 전화(VoIP) 기반 영상 통화에 참여하는 참여자 각각에 대해 수어 통역을 위한 아바타를 설정하는 과정;및상기 영상 통화 중 발화자의 음성을 수어로 변환하여 상기 발화자의 아바타를 통해 통역하는 과정을 처리하는 컴퓨터 장치."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 설정하는 단계는,상기 참여자 각각에 대해 영상 통화 옵션으로서 수어 통역과 아바타를 설정하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,상기 참여자 각각에 대해 통화 영상에서 얼굴을 인식하여 인식된 얼굴을 기초로 아바타를 생성하여 상기 수어통역을 위한 아바타로 설정하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,상기 발화자의 통화 영상과 통화 음성 중 적어도 하나로부터 상기 발화자의 감정 상태를 분석하고,상기 발화자의 감정 상태를 상기 발화자의 아바타의 표정 또는 제스처로 표현하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,둘 이상의 참여자가 동시에 발화하는 경우 발화자 각자의 아바타가 함께 등장하여 각 발화자의 음성을 수어로통역하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,공개특허 10-2023-0102753-5-상기 참여자의 통화 영상이 한 화면으로 구성된 영상 통화 화면의 일측에 상기 발화자의 아바타 영상을 오버레이하여 표시하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,상기 참여자의 통화 영상이 한 화면으로 구성된 영상 통화 화면 상에 별도의 디스플레이 요소를 통해 상기 발화자의 통화 영상을 구별하여 표시하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 적어도 하나의 프로세서는,둘 이상의 참여자가 동시에 발화하는 경우 발화자 간에 상기 디스플레이 요소를 다르게 표시하되 발화자 각각에대해 아바타의 디스플레이 요소 일부를 상기 발화자 영상에 대한 디스플레이 요소와 통일시켜 표시하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2021-0193128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,상기 영상 통화 중 통화 영상에서 수어를 인식하여 문자 자막 또는 음성으로 통역하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2021-0193128", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "아바타를 통해 영상의 음성을 수어로 통역하는 방법, 컴퓨터 장치, 및 컴퓨터 프로그램이 개시된다. 수어 통역 방법은, 인터넷 전화(VoIP) 기반 영상 통화에 참여하는 참여자 각각에 대해 수어 통역을 위한 아바타를 설정하는 단계; 및 상기 영상 통화 중 발화자의 음성을 수어로 변환하여 상기 발화자의 아바타를 통해 통역하는 단계를 포 함할 수 있다."}
{"patent_id": "10-2021-0193128", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 수어 통역 서비스를 제공하는 기술에 관한 것이다."}
{"patent_id": "10-2021-0193128", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 통신 디바이스는 음성 통화 서비스나 문자 서비스 이외에도 무선 인터넷 서비스, 지상파/위성 방송 서비스 등 다양한 서비스를 제공하고 있다. 특히, 영상의 압축 기술과 복원 기술이 발전하고 카메라가 구비된 디바이스가 상용화 됨에 따라 상대방의 얼굴 을 확인하면서 통화를 가능하게 하는 영상 통화 서비스가 제공되고 있다. 영상 통화 서비스를 제공하는 기술의 일례로, 한국등록특허공보 제10-0401262호(등록일 2003년 09월 29일)에는 무선 환경의 이동 전화망에서 이동 전화 단말기 간의 화상 전화 서비스를 제공하는 기술이 개시되어 있다."}
{"patent_id": "10-2021-0193128", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "영상 통화 중 아바타를 이용하여 실시간으로 통화 음성을 수어로 통역할 수 있다. 발화자에 따라서 각 발화자의 아바타를 통해 수어를 제공함으로써 발화의 주체를 쉽게 구분할 수 있다. 통화 영상이나 통화 음성을 분석하여 발화자의 표정이나 감정을 아바타의 표정에 반영할 수 있다."}
{"patent_id": "10-2021-0193128", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "컴퓨터 장치에서 실행되는 수어 통역 방법에 있어서, 상기 컴퓨터 장치는 메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를 포함하고, 상기 수어 통역 방법은, 상기 적어도 하나의 프로세서에 의해, 인터넷 전화(VoIP) 기반 영상 통화에 참여하는 참여자 각각에 대해 수어 통역을 위한 아바타 를 설정하는 단계; 및 상기 적어도 하나의 프로세서에 의해, 상기 영상 통화 중 발화자의 음성을 수어로 변환하 여 상기 발화자의 아바타를 통해 통역하는 단계를 포함하는 수어 통역 방법을 제공한다. 일 측면에 따르면, 상기 설정하는 단계는, 상기 참여자 각각에 대해 영상 통화 옵션으로서 수어 통역과 아바타 를 설정하는 단계를 포함할 수 있다. 다른 측면에 따르면, 상기 설정하는 단계는, 상기 참여자 각각에 대해 통화 영상에서 얼굴을 인식하여 인식된 얼굴을 기초로 아바타를 생성하여 상기 수어 통역을 위한 아바타로 설정하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 통역하는 단계는, 상기 발화자의 통화 영상과 통화 음성 중 적어도 하나로부터 상 기 발화자의 감정 상태를 분석하는 단계; 및 상기 발화자의 감정 상태를 상기 발화자의 아바타의 표정 또는 제 스처로 표현하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 통역하는 단계는, 둘 이상의 참여자가 동시에 발화하는 경우 발화자 각자의 아바 타가 함께 등장하여 각 발화자의 음성을 수어로 통역하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 통역하는 단계는, 상기 참여자의 통화 영상이 한 화면으로 구성된 영상 통화 화면 의 일측에 상기 발화자의 아바타 영상을 오버레이하여 표시하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 통역하는 단계는, 상기 참여자의 통화 영상이 한 화면으로 구성된 영상 통화 화면 상에 별도의 디스플레이 요소를 통해 상기 발화자의 통화 영상을 구별하여 표시하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 표시하는 단계는, 둘 이상의 참여자가 동시에 발화하는 경우 발화자 간에 상기 디 스플레이 요소를 다르게 표시하되 발화자 각각에 대해 아바타의 디스플레이 요소 일부를 상기 발화자 영상에 대 한 디스플레이 요소와 통일시켜 표시할 수 있다. 또 다른 측면에 따르면, 상기 수어 통역 방법은, 상기 적어도 하나의 프로세서에 의해, 상기 영상 통화 중 통화 영상에서 수어를 인식하여 문자 자막 또는 음성으로 통역하는 단계를 더 포함할 수 있다. 컴퓨터 장치에서 실행되는 수어 통역 방법에 있어서, 상기 컴퓨터 장치는 메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를 포함하고, 상기 수어 통역 방법은, 상기 적어도 하나의 프로세서에 의해, 동영상 플랫폼 내 영상을 대상으로 등장 인물 각각에 대해 수어 통역을 위한 아바타를 설정하 는 단계; 및 상기 적어도 하나의 프로세서에 의해, 상기 영상의 재생 중 상기 등장 인물의 음성을 수어로 변환 하여 해당 인물의 아바타를 통해 통역하는 단계를 포함하는 수어 통역 방법을 제공한다. 상기 수어 통역 방법을 상기 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독가능한 기록 매체에 저장되는 컴퓨터 프로그램을 제공한다. 컴퓨터 장치에 있어서, 메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세 서를 포함하고, 상기 적어도 하나의 프로세서는, 인터넷 전화(VoIP) 기반 영상 통화에 참여하는 참여자 각각에 대해 수어 통역을 위한 아바타를 설정하는 과정; 및 상기 영상 통화 중 발화자의 음성을 수어로 변환하여 상기 발화자의 아바타를 통해 통역하는 과정을 처리하는 컴퓨터 장치를 제공한다."}
{"patent_id": "10-2021-0193128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 본 발명의 실시예들은 수어 통역 서비스를 제공하는 기술에 관한 것이다. 본 명세서에서 구체적으로 개시되는 것들을 포함하는 실시예들은 영상 통화 시 아바타를 이용하여 실시간으로 영상의 음성을 수어로 통역할 수 있다. 본 발명의 실시예들에 따른 수어 통역 시스템은 적어도 하나의 컴퓨터 장치에 의해 구현될 수 있으며, 본 발명 의 실시예들에 따른 수어 통역 방법은 수어 통역 시스템에 포함되는 적어도 하나의 컴퓨터 장치를 통해 수행될 수 있다. 이때, 컴퓨터 장치에는 본 발명의 일실시예에 따른 컴퓨터 프로그램이 설치 및 구동될 수 있고, 컴퓨 터 장치는 구동된 컴퓨터 프로그램의 제어에 따라 본 발명의 실시예들에 따른 수어 통역 방법을 수행할 수 있다. 상술한 컴퓨터 프로그램은 컴퓨터 장치와 결합되어 수어 통역 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장될 수 있다. 도 1은 본 발명의 일실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 1의 네트워크 환경은 복수의 전 자 기기들(110, 120, 130, 140), 복수의 서버들(150, 160) 및 네트워크를 포함하는 예를 나타내고 있다. 이러한 도 1은 발명의 설명을 위한 일례로 전자 기기의 수나 서버의 수가 도 1과 같이 한정되는 것은 아니다. 또한, 도 1의 네트워크 환경은 본 실시예들에 적용 가능한 환경들 중 하나의 예를 설명하는 것일 뿐, 본 실시예 들에 적용 가능한 환경이 도 1의 네트워크 환경으로 한정되는 것은 아니다. 복수의 전자 기기들(110, 120, 130, 140)은 컴퓨터 장치로 구현되는 고정형 단말이거나 이동형 단말일 수 있다. 복수의 전자 기기들(110, 120, 130, 140)의 예를 들면, 스마트폰(smart phone), 휴대폰, 내비게이션, 컴퓨터, 노트북, 디지털방송용 단말, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 태블릿 PC 등이 있다. 일례로 도 1에서는 전자 기기의 예로 스마트폰의 형상을 나타내고 있으나, 본 발명의 실시예 들에서 전자 기기는 실질적으로 무선 또는 유선 통신 방식을 이용하여 네트워크를 통해 다른 전자 기 기들(120, 130, 140) 및/또는 서버(150, 160)와 통신할 수 있는 다양한 물리적인 컴퓨터 장치들 중 하나를 의미 할 수 있다. 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용하는 통신 방식뿐만 아니라 기기들 간의 근거리 무선 통신 역시 포함될 수 있다. 예를 들어, 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포함하는 네트 워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 서버(150, 160) 각각은 복수의 전자 기기들(110, 120, 130, 140)과 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 예를 들어, 서버는 네트워크를 통해 접속한 복수의 전자 기기들(110, 120, 130, 140)로 서비스(일례로, 수 어 통역 서비스 등)를 제공하는 시스템일 수 있다. 도 2는 본 발명의 일실시예에 따른 컴퓨터 장치의 예를 도시한 블록도이다. 앞서 설명한 복수의 전자 기기들 (110, 120, 130, 140) 각각이나 서버들(150, 160) 각각은 도 2를 통해 도시된 컴퓨터 장치에 의해 구현될 수 있다. 이러한 컴퓨터 장치는 도 2에 도시된 바와 같이, 메모리, 프로세서, 통신 인터페이스 그리 고 입출력 인터페이스를 포함할 수 있다. 메모리는 컴퓨터에서 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치(permanent mass storage device)를 포함할 수 있다. 여기서 ROM과 디스크 드라이브와 같은 비소멸성 대용량 기록장치는 메모리와는 구분되는 별도의 영구 저장 장치로서 컴퓨터 장치에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드가 저장될 수 있다. 이러한 소프트웨어 구성요 소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 메모리로 로딩될 수 있다. 이러 한 별도의 컴퓨터에서 판독 가능한 기록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴 퓨터에서 판독 가능한 기록매체가 아닌 통신 인터페이스를 통해 메모리에 로딩될 수도 있다. 예를 들어, 소프트웨어 구성요소들은 네트워크를 통해 수신되는 파일들에 의해 설치되는 컴퓨터 프로그램에 기 반하여 컴퓨터 장치의 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 인터페이스에 의해 프로세서로 제공될 수 있다. 예 를 들어 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행 하도록 구성될 수 있다. 통신 인터페이스는 네트워크를 통해 컴퓨터 장치가 다른 장치(일례로, 앞서 설명한 저장 장치들)와 서로 통신하기 위한 기능을 제공할 수 있다. 일례로, 컴퓨터 장치의 프로세서가 메모리 와 같은 기록 장치에 저장된 프로그램 코드에 따라 생성한 요청이나 명령, 데이터, 파일 등이 통신 인터페 이스의 제어에 따라 네트워크를 통해 다른 장치들로 전달될 수 있다. 역으로, 다른 장치로부터의 신 호나 명령, 데이터, 파일 등이 네트워크를 거쳐 컴퓨터 장치의 통신 인터페이스를 통해 컴퓨터 장치로 수신될 수 있다. 통신 인터페이스를 통해 수신된 신호나 명령, 데이터 등은 프로세서나 메모리로 전달될 수 있고, 파일 등은 컴퓨터 장치가 더 포함할 수 있는 저장 매체(상술한 영구 저장 장치)로 저장될 수 있다. 입출력 인터페이스는 입출력 장치와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 마이크, 키보드 또는 마우스 등의 장치를, 그리고 출력 장치는 디스플레이, 스피커와 같은 장치를 포함할 수 있 다. 다른 예로 입출력 인터페이스는 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와 의 인터페이스를 위한 수단일 수도 있다. 입출력 장치는 컴퓨터 장치와 하나의 장치로 구성될 수도 있다. 또한, 다른 실시예들에서 컴퓨터 장치는 도 2의 구성요소들보다 더 적은 혹은 더 많은 구성요소들을 포함 할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 컴퓨 터 장치는 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버 (transceiver), 데이터베이스 등과 같은 다른 구성요소들을 더 포함할 수도 있다. 이하에서는 아바타를 통해 영상의 음성을 수어로 통역하는 방법 및 장치의 구체적인 실시예를 설명하기로 한다. 본 명세서에서 영상 통화는 사용자와 상대방 간에 영상과 음성을 주고받는 영상 전화를 포괄하여 의미할 수 있 고, 일례로 IP 주소를 사용하는 네트워크를 통해 영상과 음성을 디지털 패킷으로 변환하여 전송하는 기술의 인 터넷 전화(VoIP)를 의미할 수 있다. 본 실시예들은 인터넷 전화(VoIP) 상에서 통역 옵션 중 하나로서 수어 통역을 제공할 수 있다. 본 실시예에 따른 컴퓨터 장치는 클라이언트를 대상으로 클라이언트 상에 설치된 전용 어플리케이션이나 컴퓨터 장치와 관련된 웹/모바일 사이트 접속을 통해 수어 통역 서비스를 제공할 수 있다. 컴퓨터 장치 에는 컴퓨터로 구현된 수어 통역 시스템이 구성될 수 있다. 일례로, 수어 통역 시스템은 독립적으로 동작 하는 프로그램 형태로 구현되거나, 혹은 특정 어플리케이션의 인-앱(in-app) 형태로 구성되어 상기 특정 어플리 케이션 상에서 동작이 가능하도록 구현될 수 있다. 컴퓨터 장치의 프로세서는 이하의 수어 통역 방법을 수행하기 위한 구성요소로 구현될 수 있다. 실 시예에 따라 프로세서의 구성요소들은 선택적으로 프로세서에 포함되거나 제외될 수도 있다. 또한, 실시예에 따라 프로세서의 구성요소들은 프로세서의 기능의 표현을 위해 분리 또는 병합될 수도 있다. 이러한 프로세서 및 프로세서의 구성요소들은 이하의 수어 통역 방법이 포함하는 단계들을 수행하도 록 컴퓨터 장치를 제어할 수 있다. 예를 들어, 프로세서 및 프로세서의 구성요소들은 메모리 가 포함하는 운영체제의 코드와 적어도 하나의 프로그램의 코드에 따른 명령(instruction)을 실행하도록구현될 수 있다. 여기서, 프로세서의 구성요소들은 컴퓨터 장치에 저장된 프로그램 코드가 제공하는 명령에 따라 프로 세서에 의해 수행되는 서로 다른 기능들(different functions)의 표현들일 수 있다. 프로세서는 컴퓨터 장치의 제어와 관련된 명령이 로딩된 메모리로부터 필요한 명령을 읽어들일 수 있다. 이 경우, 상기 읽어들인 명령은 프로세서가 이후 설명될 단계들을 실행하도록 제어하기 위한 명 령을 포함할 수 있다. 이후 설명될 단계들은 도시된 순서와 다른 순서로 수행될 수 있으며, 단계들 중 일부가 생략되거나 추가의 과정 이 더 포함될 수 있다. 도 3은 본 발명의 일실시예에 따른 컴퓨터 장치가 수행할 수 있는 방법의 일례를 도시한 흐름도이다. 도 3을 참조하면, 단계(S310)에서 프로세서는 인터넷 전화(VoIP) 기반 영상 통화에 참여하고자 하는 사용 자 각각에 대하여 영상 통화 옵션 중 하나로 수어 통역을 설정할 수 있다. 프로세서는 특정 사용자를 위 한 옵션(예를 들어, 청각 장애를 가진 사용자를 위한 옵션)으로 영상 통화 진입 과정 등 영상 통화와 관련된 환 경 설정을 통해 시각 언어인 수어로의 통역을 요청할 수 있다. 단계(S320)에서 프로세서는 수어 통역을 설정한 영상 통화에 있어서, 영상 통화 참여자 각각에 대하여 수 어 표현을 위한 아바타를 설정할 수 있다. 아바타는 가상 환경에서 사용자를 대신하는 캐릭터로서 복수의 아바 타 구성요소를 포함할 수 있다. 예를 들어, 아바타 구성요소는 아바타의 외형을 정의하는 구성요소(눈 모양, 코 모양, 입 모양, 얼굴형, 체형, 헤어 스타일 등), 아바타의 제스처를 정의하는 구성요소, 아바타가 장착하는 아이템을 정의하는 구성요소(의상, 신발, 안경, 액세서리 등)를 포함할 수 있다. 일례로, 프로세서는 영 상 통화 참여자 각각에 대하여 해당 참여자에 의해 직접 선택된 아바타를 설정할 수 있다. 다른 예로, 프로세 서는 영상 통화 참여자 각각에 대하여 임의 설정을 통해 중복되지 않은 아바타를 자동 설정할 수 있다. 프로세서는 영상 통화 참여자 별 아바타를 설정함에 있어 얼굴인식 및 인공지능(AI) 기술을 바탕으로 통화 영상에서 각 참여자의 얼굴을 인식하여 해당 참여자와 닮은 캐릭터의 아바타를 생성하여 활용할 수 있다. 단계(S330)에서 프로세서는 영상 통화 중 발화자의 음성을 수어로 번역할 수 있다. 이때, 프로세서 는 인터넷 전화(VoIP) 기반 영상 통화 환경에서 음성인식(STT, speech to text) 기술을 통해 통화 음성을 문자 데이터인 텍스트로 변환할 수 있다. 이어, 프로세서는 인공지능(AI) 기반 수어 번역 모델을 통해 상기 변 환된 텍스트를 수어로 변환할 수 있다. 단계(S340)에서 프로세서는 단계(S330)에서 번역된 수어에 해당되는 동작을 해당 발화자의 아바타를 통해 재생할 수 있다. 프로세서는 발화자를 대신하는 아바타의 동작을 번역된 수어 동작으로 표현할 수 있다. 다시 말해, 프로세서는 수어 문장에 대해 사전에 정해진 손동작과 기타 신체 요소의 동작을 아바타의 행동 으로 바꾸어 표현할 수 있다. 프로세서는 손 모양, 손 방향, 손 운동을 포함한 손동작을 비롯하여 입술 움직임, 얼굴 표정, 안색, 눈동 자 움직임, 몸동작 등을 통해 수화 언어를 보다 자연스럽게 표현할 수 있는 아바타 모델을 적용할 수 있다. 일 례로, 프로세서는, 얼굴 검출(face detection) 기술을 바탕으로 발화자의 통화 영상에서 추출된 발화자의 표정을 아바타 모델에 반영할 수 있다. 프로세서는 통화 음성에 포함된 발화 문장이나 억양으로부터 발화자의 감정 상태를 분석하여 분석된 감정 정보를 아바타의 표정이나 제스처에 반영할 수 있다. 통화 음성 이외에도 얼굴 검출 기술을 바탕으로 발화자의 통화 영상을 분석함으로써 발화자의 얼굴에서 드러나는 감정 상태를 추출할 수 있다. 프로세서는 수어 통 역을 제공함에 있어 수어의 손동작 이외에도 발화장의 감정에 따라 시각 언어로 표현 가능한 기타 몸짓, 얼굴표 정, 시선, 자세 등을 아바타의 다양한 행동으로 바꾸어 표현할 수 있다. 프로세서는 상대방의 단말로부터 영상 통화를 위한 상대방 영상을 수신하여 사용자 영상과 상대방 영상을 포함한 영상 통화 화면을 표시할 수 있다. 프로세서는 영상 통화에 참여하는 상대방 영상을 개별 영상으 로 각각 수신한 후 수신된 상대방 영상을 사용자 영상과 함께 한 화면으로 렌더링(rendering) 하여 영상 통화 화면을 구성할 수 있다. 영상 통화 서비스를 제공하는 서버 측에서 복수의 참여자 영상을 포함한 하나의 영상을 만들어 클라이언트 로 제공하는 것이 아니라 각 참여자 영상을 개별 영상으로 전송하고, 클라이언트 측에서 복수의 참여자 화상을개별 영상으로 각각 수신하여 한 화면의 영상 통화 화면으로 구성하는 것이다. 이때, 서버는 수어를 표현하는 아바타 영상을 통화 영상의 일측에 믹싱하여 참여자 영상으로 전송하거나 또는 통화 영상과 아바타 영상을 개별 영상으로 전송할 수 있다. 클라이언트에서는 전자의 경우 일측에 아바타 영상이 믹싱된 참여자 영상으로 영상 통화 화면을 구성할 수 있고, 후자의 경우 통화 영상과 아바타 영상을 정 해진 레이아웃에 따라 조합하여 영상 통화 화면을 구성할 수 있다. 예를 들어, 통화 영상을 한 화면의 영상 통 화 화면으로 구성하고 영상 통화 화면의 일측(예를 들어, 우측 하단)에 수어 통역 아바타 영상을 오버레이할 수 있다. 프로세서는 영상 통화 참여자 별로 서로 다른 캐릭터의 아바타가 설정됨에 따라 발화자마다 다른 아바타, 즉 발화자 별로 각기 설정된 아바타를 통해 수어 통역을 제공할 수 있다. 프로세서는 수어 통역을 제공하는 아바타가 영상 통화 참여자 중 어떤 참여자의 아바타인지, 즉 현재 수어 로 통역되고 있는 음성의 발화자가 누구인지 구분이 용이하도록 별도의 디스플레이 요소를 영상 통화 화면에 적 용할 수 있다. 프로세서는 영상 통화 참여자 중 둘 이상의 참여자가 동시에 발화하는 경우 발화자 각자의 아바타가 함께 등장하여 발화자 각각에 대한 수어 통역을 제공할 수 있다. 본 실시예에 따른 수어 통역 서비스는 영상 통화 중 발화자의 음성을 수어로 통역하는 기능은 물론이고, 통화 영상 속에 등장하는 인물의 몸짓을 인식하여 이를 텍스트 또는 음성으로 제공하는 기능을 포함할 수 있다. 다 시 말해, 인공지능과 영상인식 기술을 바탕으로 영상의 수화 언어를 텍스트로 변환하여 자막으로 통역할 수 있 고, 또는 TTS(text to speech) 기술을 통해 음성으로 통역할 수 있다. 도 4는 본 발명의 일실시예에 있어서 수어 통역을 설정하는 인터페이스 화면의 예시를 도시한 것이다. 도 4는 영상 통화 참여를 위한 설정 화면을 나타내고 있다. 도 4를 참조하면, 영상 통화 설정 화면은 영상 통화와 관련된 각종 환경 설정을 위한 인터페이스를 포함할 수 있으며, 이때 영상 통화 중 수어 통역을 사용할 수 있도록 설정하기 위한 '수어 통역' 메뉴를 포함할 수 있다. 사용자는 영상 통화에 참여하기 이전에 '수어 통역' 메뉴를 이용하여 자신의 통화 음성에 대한 수어 통역 을 설정할 수 있다. 도 5 내지 도 7은 본 발명의 일실시예에 있어서 아바타를 통해 발화자의 음성을 수어로 통역하는 영상 통화 화 면의 예시를 도시한 것이다. 도 5를 참조하면, 프로세서는 사용자가 영상 통화에 참여한 경우 상대방의 단말로부터 영상 통화를 위한 상대방 영상을 수신하여 사용자 영상과 상대방 영상을 포함한 영상 통화 화면을 표시할 수 있다. 이때, 프로세서는 영상 통화에 참여하는 상대방 영상을 개별 영상으로 각각 수신한 후 수신된 상대방 영상을 사용자 영상과 함께 한 화면으로 렌더링함으로써 영상 통화 화면을 구성할 수 있다. 도 6을 참조하면, 프로세서는 영상 통화 중 통화 음성을 수어로 통역할 수 있으며, 이때 발화자에 해당되 는 아바타를 이용하여 해당 발화자의 음성에 대해 수어 통역을 제공할 수 있다. 서버 측에서 참여자 각각의 통화 영상을 개별 영상으로 전송함과 아울러 수어 통역을 제공하는 아바타 의 영상을 함께 전송할 수 있다. 이때, 프로세서는 사용자 영상과 상대방 영상을 한 화면 으로 렌더링한 영상 통화 화면 상에 아바타의 영상을 오버레이하여 표시할 수 있다. 프로세서는 아바타가 영상 통화 참여자 중 어떤 참여자의 아바타인지, 즉 현재 수어로 통역되고 있는 음성의 발화자가 누구인지 영상 통화 화면 상에 별도의 디스플레이 요소를 통해 다른 참여자와 구별 하여 표시할 수 있다. 도 6에서는 영상 통화 화면의 우측 하단에 아바타가 표시되는 것으로 도시되었으나, 다른 예에 따르 면 아바타는, 상대방 영상 내에서 발화자의 영상에 인접하여 표시되거나, 발화자의 영상 내에 오버레 이되어 표시되거나, 발화자의 영상을 대체하여 표시될 수 있다. 프로세서는 영상 통화 중 발화자가 바뀌는 경우, 도 7에 도시한 바와 같이 디스플레이 요소를 통해 현재 발화자를 다른 참여자와 구별하여 표시함과 동시에 현재 발화자의 아바타를 이용하여 통화 음성을 수 어로 통역할 수 있다. 다시 말해, 프로세서는 발화자의 구분이 용이하도록 발화자에 따라 각기 다른 아바타(650, 760)를 통해 수 어 통역을 제공할 수 있다. 도 8 내지 도 9는 본 발명의 일실시예에 있어서 동시에 여러 사람이 발화하는 음성을 수어로 통역하는 영상 통 화 화면의 예시를 도시한 것이다. 도 8을 참조하면, 프로세서는 영상 통화 참여자 중 둘 이상의 참여자가 동시에 발화하는 경우 영상 통화 화면 상에 발화자 각자의 아바타(850, 860)가 함께 등장하여 발화자 각각에 대한 수어 통역을 제공할 수 있다. 프로세서는 동시 발화 환경에서 발화자를 쉽게 식별할 수 있도록 도 9에 도시한 바와 같이 발화자 간에 통 화 영상의 디스플레이 요소(851, 861)를 다르게 구별하여 표시할 수 있으며, 이때 발화자 각각에 대해서는 아바 타(850, 860)의 디스플레이 요소 일부를 통화 영상의 디스플레이 요소(851, 861)와 통일시킬 수 있다. 예를 들어, 사용자 A와 사용자 B가 동시 발화하는 경우, 사용자 A의 통화 영상과 아바타에 빨간색의 윤곽선을 적용하는 한편, 사용자 B의 통화 영상과 아바타에 파란색의 윤곽선을 적용할 수 있다. 따라서, 사용자 A와 사 용자 B의 발화 음성에 대한 수어 통역을 쉽게 분별하여 알아볼 수 있다. 도 9에는 발화 중인 사용자의 아바타만을 표시하는 것으로 도시되었으나, 다른 실시예에 따르면, 수어 통역이 설정된 영상 통화에 대해서는 각 사용자의 아바타가 상대방 영상에 오버레이되어 표시될 수 있다. 이때, 발화자에 대한 아바타는 다른 사용자의 아바타와 구별되도록 다른 크기 또는 색상을 이용하여 표시할 수 있다. 도 10은 본 발명의 일실시예에 있어서 발화자의 감정이 반영된 수어 통역 아바타의 예시를 도시한 것이다. 프로세서는 영상 통화 화면 상에 발화자에 해당되는 아바타가 등장하여 해당 발화자의 음성에 대해 수어 통역을 제공함에 있어 발화자의 통화 영상, 발화 문장이나 억양 등으로부터 발화자의 현재 감정 상태 를 분석하여 분석된 감정 정보를 아바타의 표정이나 제스처에 반영할 수 있다. 도 10에 도시한 바와 같이, 프로세서는 영상 통화 중 발화자가 실제 웃으면서 '감사합니다'라고 발화하는 경우 통화 영상이나 발화 내용으로부터 감정 상태 '기쁨'을 추출할 수 있고, 이때 아바타의 표정 또한 감 정 상태 '기쁨'을 나타내는 웃는 표정으로 표현할 수 있다. 도 11은 본 발명의 일실시예에 있어서 영상에서 인식된 수어를 자막으로 통역하는 영상 통화 화면의 예시를 도 시한 것이다. 프로세서는 영상 통화 중 통화 음성을 수어로 통역하는 것은 물론이고, 통화 영상의 수화 언어를 문자나 음성으로 통역하는 것 또한 가능하다. 도 11을 참조하면, 프로세서는 영상 통화 중 사용자가 수어를 이용하는 경우 사용자 영상에서 사용자 가 표현하는 수어 동작을 인식하여 인식된 수어를 문자로 변환함으로써 수어 통역 결과로서 문자 자막을 제공할 수 있다. 이때, 프로세서는 수어를 이용하는 사용자의 아바타를 이용하여, 아바타에 수어 또는 변 환된 문자에 해당하는 표정이나 제스처를 적용하면서 문자 자막을 제공할 수 있다. 프로세서는 영상의 수화 언어에 대한 통역 결과를 문자 자막으로 제공하는 것은 물론이고, TTS를 통 해 수어 통역 결과를 음성 형태로 제공할 수 있다. 상기한 실시예들은 영상 통화 중에 수어 통역 서비스를 제공하는 것으로 설명하고 있으나, 이에 한정되는 것은 아니며, 시각적인 정보 전달이 가능한 영상 기반 서비스라면 얼마든지 수어 통역 서비스를 적용할 수 있다. 예 를 들어, 동영상 컨텐츠를 공유하는 동영상 플랫폼에서 영상 재생 중에 아바타를 이용하여 영상에 등장하는 인 물의 음성을 수어로 통역하는 것 또한 가능하다. 등장 인물 별로 서로 다른 캐릭터의 아바타를 설정하여 등장 인물의 음성을 해당 인물의 아바타를 통해 수어로 통역할 수 있다. 이처럼 본 발명의 실시예들에 따르면, 영상 통화 중 아바타를 이용하여 실시간으로 영상의 음성을 수어로 통역 할 수 있다. 본 발명의 실시예들에 따르면, 발화자에 따라서 각 발화자의 아바타를 통해 수어를 제공함으로써 발화의 주체를 쉽게 구분할 수 있다. 본 발명의 실시예들에 따르면, 통화 영상이나 통화 음성으로부터 발화자 의 감정을 분석하여 수어 통역을 제공하는 아바타의 표정에 반영할 수 있다.이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 프로세서, 콘트롤 러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2021-0193128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 컴퓨 터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분 산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 이때, 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수 개의 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트 워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같 은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 어플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어 를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다."}
{"patent_id": "10-2021-0193128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2021-0193128", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 2는 본 발명의 일실시예에 따른 컴퓨터 장치의 예를 도시한 블록도이다. 도 3은 본 발명의 일실시예에 따른 컴퓨터 장치가 수행할 수 있는 방법의 일례를 도시한 순서도이다. 도 4는 본 발명의 일실시예에 있어서 수어 통역을 설정하는 인터페이스 화면의 예시를 도시한 것이다. 도 5 내지 도 7은 본 발명의 일실시예에 있어서 아바타를 통해 발화자의 음성을 수어로 통역하는 영상 통화 화 면의 예시를 도시한 것이다.도 8 내지 도 9는 본 발명의 일실시예에 있어서 동시에 여러 사람이 발화하는 음성을 수어로 통역하는 영상 통 화 화면의 예시를 도시한 것이다. 도 10은 본 발명의 일실시예에 있어서 발화자의 감정이 반영된 수어 통역 아바타의 예시를 도시한 것이다. 도 11은 본 발명의 일실시예에 있어서 영상에서 인식된 수어를 자막으로 통역하는 영상 통화 화면의 예시를 도 시한 것이다."}
