{"patent_id": "10-2023-0037824", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0140526", "출원번호": "10-2023-0037824", "발명의 명칭": "신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치 및 이를 이용한 인공지능", "출원인": "주식회사 LG 경영개발원", "발명자": "윤성로"}}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "SNR 값에 따라 구분된 복수의 학습 단계를 기반으로 역방향 변환 과정을 수행하는 인공지능 모델; 및 상기 인공지능 모델의 동작을 제어하는 프로세서; 를 포함하고,상기 프로세서는,상기 SNR 값에 따라 역방향 변환 과정을 복수의 학습 단계로 구분하고,구분된 각 학습 단계에 상이한 가중치를 적용하는, 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 학습 단계는 상기 SNR 값에 따라 순차적으로 구분된 제1 단계, 제2 단계 및 제3 단계를 적어도 포함하며,상기 프로세서는, 상기 학습 단계에 대한 우선순위에 따라 순차적으로 가중치를 적용하는,신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 프로세서는, 학습에 가장 영향을 많이 끼치는 상기 제2 단계에 가장 높은 가중치를 적용하고,잔여 노이즈를 제거하는 상기 제3 단계에서 가장 낮은 가중치를 적용하는, 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 제1 단계의 우선순위는 상기 제3 단계의 우선순위보다 높은, 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3 항에 있어서, 상기 프로세서는, 각 학습 단계에 적용될 목적함수에 하기 식에 따라 산출된 가중치를 적용하며,상기 λt는 종래 가중치이고, λt'는 각 학습 단계의 우선순위가 적용된 가중치이며, k는 작은 SNR 수치에 따른 가중치 폭발을 방지하는 상수이며, 상기 γ는 하향 가중치의 강도를 제어하는 하이퍼파라미터이고, t는 노이공개특허 10-2023-0140526-2-즈 정도를 표시하는 인덱스인, 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 인공지능 모델은 확산 모델을 포함하는,신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 프로세서는,상기 확산 모델에 입력될 데이터 셋(set)에 따라 상기 k와 γ의 값을 조절하는, 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 프로세서는, 상기 데이터 셋의 이미지 해상도(resolution)가 클수록 상기 γ의 값을 크게 조절하는, 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서,상기 프로세서는,상기 인공지능 모델로부터 출력된 생성 이미지의 퀄리티 파라미터를 기반으로 각 학습 단계의 우선순위가 적용된 가중치(λt')를 재조정하는,신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서,상기 퀄리티 파라미터는 상기 생성 이미지의 FID 및 KID 수치를 포함하는,신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "신호 대 잡음비 기반 인공지능 모델 학습 장치를 이용한 인공지능 모델 학습 방법으로서,SNR 값에 따라 상기 학습 모델의 역방향 변환 과정을 복수의 학습 단계로 구분하는 분류단계; 및 구분된 복수의 학습 단계에 대해 각각 상이한 가중치를 적용하여 역방향 변환 과정을 수행하는 역방향변환단계; 를 포함하는,신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 분류단계는 상기 SNR 값에 따라 상기 학습 모델의 역방향 변환 과정을 적어도 제1 단계, 제2 단계 및 제3공개특허 10-2023-0140526-3-단계로 구분하는 단계를 포함하며,상기 역방향 변환단계는, 상기 제2 단계, 상기 제1 단계 및 상기 제3 단계 순서로 우선 순위를 적용하는 단계; 및상기 우선 순위에 따라 상기 제2 단계에서 가장 높은 가중치를 적용하고, 상기 제3 단계에서 가장 낮은 가중치를 적용하여 목적함수를 최적화하는 단계; 를 포함하는,신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,입력 이미지에 적용될 목적함수에 하기 식에 따라 산출된 가중치를 적용하며,상기 λt는 종래 가중치이고, λt'는 각 학습 단계의 우선순위가 적용된 가중치이며, k는 작은 SNR 수치에 따른 가중치 폭발을 방지하는 상수이며, 상기 γ는 하향 가중치의 강도를 제어하는 하이퍼파라미터이고, t는 노이즈 정도를 표시하는 인덱스인,신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 FID 및 KID 수치가 임계치 이상일 경우 상기 λt'를 재조정하여 상기 제2 단계의 가중치를 상향하고, 상기제1 단계 및 상기 제3 단계의 가중치를 하향시키는 단계를 더 포함하며,이때, 상기 제1 단계의 가중치 하향 폭 또는 하향 우선순위가 상기 제 3단계의 가중치 하향 폭 또는 하향 우선순위보다 작은 것을 특징으로 하는, 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0037824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨터와 결합되어, 제11 항 내지 제14 항 중 어느 한 항의 신호 대 잡음비 기반의 우선순위를 적용한 인공지능모델 학습 방법을 실행시키기 위한 프로그램이 저장된 컴퓨터로 판독 가능한 기록매체."}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치는 SNR 값에 따 라 구분된 복수의 학습 단계를 기반으로 역방향 변환 과정을 수행하는 인공지능 모델; 및 상기 인공지능 모델의 동작을 제어하는 프로세서; 를 포함하고, 상기 프로세서는 상기 SNR 값에 따라 역방향 변환 과정을 복수의 학습 단계로 구분하고, 구분된 각 학습 단계에 상이한 가중치를 적용하는 것이다."}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델 학습 장치 및 이를 이용한 인공지능 모델 학습 방법에 관한 것으로, 보다 상세하게는 신호 대 잡음비(SNR, Signal to Noise Ratio) 기반의 우선순위를 적용한 인공지능 모델 학습 장치 및 이를 이용 한 인공지능 모델 학습 방법에 관한 것이다."}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "확산 모델은 초기 상태의 분자들이 시간이 흐름에 따라 흩어지는 것을 나타내는 랑주뱅 동영학에서 아이디어를 얻은 deep generative model 중 하나로, 데이터로부터 노이즈를 조금씩 더해가면서 데이터를 완전한 노이즈로 만드는 정방향 변환과, 노이즈로부터 조금씩 복원해가며 데이터를 만들어내는 역방향 변환을 수행하며, 역방향 변환을 학습함으로써 목표 이미지를 출력할 수 있다. 그러나, 모든 이미지는 동일한 노이즈 레벨을 가지지 않고, 확산 모델이 학습할 때 노이즈 레벨이 낮아 실질적 인 컨텐츠 내용을 학습하는 학습 단계가 있고, 노이즈 레벨이 너무 높아 컨텐츠 내용에 기여하지 않는 영역을 학습하는 학습단계가 포함될 수 있다. 학습 단계에 일괄적으로 동일한 가중치를 적용할 경우, 노이즈 레벨이 낮은 영역에서는 과도한 자원이 사용되고, 노이즈 레벨이 높은 영역에서는 충분한 자원을 사용할 수 없어 이미지 재건(reconstruction) 효율이 떨어지게 된다. 따라서, 재건 효율을 향상시키기 위하여 노이즈 레벨에 따라 확산 모델의 역변환 과정에서 사용되는 가중치를 다르게 적용할 필요성이 대두되었다. 선행기술문헌 특허문헌 (특허문헌 0001) JP 2022-171561 A"}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명에 따른 확산모델은 정방향 변환으로 얻은 이미지를 깨끗한 이미지로 재건 (reconstruction)하도록 학습 된다. 정변환의 정도를 n개의 노이즈 레벨로 표기한다. 확산 모델 학습을 위해 사용되는 손실함수 (loss function)는 n개의 노이즈 레벨로부터 얻은 재건 손실함수 (reconstruction loss)의 가중합이다. 따라서 본 발 명에 따른 확산모델은, 이미지인 MRI 화상에서 노이즈를 제거하도록 입력 화상에서 n개의 가중치를 도출하고, 상기 n개의 가중치를 이용하여 n장의 중간 화상을 가중 평균함으로써 출력 이미지를 생성할 수 있다. 본 발명에 개시된 실시예는 SNR 값에 따라 구분된 확산 모델의 역변환 과정에 우선순위에 따른 가중치를 적용하 는 신호 대 잡음비 기반 인공지능 모델 학습 장치 및 이를 이용한 인공지능 모델 학습 방법을 제공하는데 그 목 적이 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 발명에 따른 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치는 SNR 값에 따라 구분된 복수의 학습 단계를 기반으로 역방향 변환 과정을 수행하는 인공지능 모델; 및 상기 인공지능 모델의 동작을 제어하는 프로세서; 를 포함하고, 상기 프로세서는 상기 SNR 값에 따라 역방향 변환 과정을 복수의 학습 단계로 구분하고, 구분된 각 학습 단계에 상이한 가중치를 적용하는 것이다. 또한, 본 발명에 따른 신호 대 잡음비 기반 인공지능 모델 학습 장치를 이용한 인공지능 모델 학습 방법은, SNR 값에 따라 상기 학습 모델의 역방향 변환 과정을 복수의 학습 단계로 구분하는 분류단계; 및 구분된 복수의 학 습 단계에 대해 각각 상이한 가중치를 적용하여 역방향 변환 과정을 수행하는 역방향 변환단계; 를 포함할 수 있다. 이 외에도, 본 발명을 구현하기 위한 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램이 더 제공될 수 있다. 이 외에도 본 발명을 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록한 컴퓨터로 판독 가능한 기 록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 전술한 과제 해결 수단에 의하면, SNR 값에 따라 구분된 확산 모델의 역변환 과정에 우선순위에 따른 가중치를 적용하여 실질적으로 컨텐츠를 구성하는 영역에 더 많은 가중치를 부여하여 학습함으로써 노이즈 이미 지를 재건하는 목적함수를 최적화하는 효과를 제공한다."}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 발명이 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 발명이 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 ‘부, 모듈, 부재, 블록’이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으 며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수있다. 이하 첨부된 도면들을 참고하여 본 발명의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '본 발명에 따른 장치'는 연산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치들 이 모두 포함된다. 예를 들어, 본 발명에 따른 장치는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 본 발명에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 발명에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 발명의 예시적인 실시예에 따르면, 프로세서는 인공지능을 구현할 수 있다. 인공지능이란 사람의 신경세포 (biological neuron)를 모사하여 기계가 학습하도록 하는 인공신경망(Artificial Neural Network) 기반의 기계 학습법을 의미한다. 인공지능의 방법론에는 학습 방식에 따라 훈련데이터로서 입력데이터와 출력데이터가 같이 제공됨으로써 문제(입력데이터)의 해답(출력데이터)이 정해져 있는 지도학습(supervised learning), 및 출력데 이터 없이 입력데이터만 제공되어 문제(입력데이터)의 해답(출력데이터)이 정해지지 않는 비지도학습 (unsupervised learning), 및 현재의 상태(State)에서 어떤 행동(Action)을 취할 때마다 외부 환경에서 보상 (Reward)이 주어지는데, 이러한 보상을 최대화하는 방향으로 학습을 진행하는 강화학습(reinforcement learning)으로 구분될 수 있다. 또한, 인공지능의 방법론은 학습 모델의 구조인 아키텍처에 따라 구분될 수도있는데, 널리 이용되는 딥러닝 기술의 아키텍처는, 합성곱신경망(CNN; Convolutional Neural Network), 순환신 경망(RNN; Recurrent Neural Network), 트랜스포머(Transformer), 생성적 대립 신경망(GAN; generative adversarial networks) 등으로 구분될 수 있다. 본 장치와 시스템은 인공지능 모델을 포함할 수 있다. 인공지능 모델은 하나의 인공지능 모델일 수 있고, 복수 의 인공지능 모델로 구현될 수도 있다. 인공지능 모델은 뉴럴 네트워크(또는 인공 신경망)로 구성될 수 있으며, 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘을 포함할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해 결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 예시적으로, 장치는 input layer, hidden layer, output layer를 포함할 수 있다. 장치를 구성하는 뉴 럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력(input)으로부터 예측하고자 하는 결과 (output)를 추론할 수 있다. 프로세서는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train, 또는 학습(learn)하거나, 수신되는 입력 데이터를 기초로 연산을 수행하고, 수행 결과를 기초로 정보 신호(information signal)를 생성하거나, 뉴럴 네 트워크를 재훈련(retrain)할 수 있다. 뉴럴 네트워크의 모델들은 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network 등 다양한 종류의 모델들을 포함할 수 있으나 이에 제한되지는 않는다. 프로세서는 뉴럴 네트워크의 모델들에 따른 연산을 수행하기 위한 하나 이상의 프로세서를 포함할 수 있다. 예를 들어 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론(multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함 할 수 있으나 이에 한정되는 것이 아닌 임의의 뉴럴 네트워크를 포함할 수 있음은 통상의 기술자가 이해할 것이다. 본 발명의 예시적인 실시예에 따르면, 프로세서는 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network, Generative Modeling, eXplainable AI, Continual AI, Representation Learning, AI for Material Design, 자 연어 처리를 위한 BERT, SP-BERT, MRC/QA, Text Analysis, Dialog System, GPT-3, GPT-4, 비전 처리를 위한 Visual Analytics, Visual Understanding, Video Synthesis, ResNet 데이터 지능을 위한 Anomaly Detection, Prediction, Time-Series Forecasting, Optimization, Recommendation, Data Creation 등 다양한 인공지능 구 조 및 알고리즘을 이용할 수 있으며, 이에 제한되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 신호 대 잡음비(SNR) 기반의 우선순위를 적용한 인공지능 모델 학습 장치의 블록도를 도시한 것이다. 이하, 도 2 내지 도 11을 참조하여 상기 인공지능 모델 학습 장치의 구체적인 구성을 설명하기로 한다. 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치는 컴퓨팅 환경에서 수행될 수 있다. 상기 컴퓨팅 환경은 컴퓨팅 장치와 인공지능 모델을 포함할 수 있다. 도 1에서는 컴퓨팅 장치와 인공지능 모델이 별개의 장치인 실시예만을 도시하고 있으나, 다른 실시예 로서, 하나의 컴퓨팅 장치가 인공지능 모델의 기능을 수행하는 소프트웨어 또는 하드웨어를 포함할 수 도 있다. 도 1에 도시된 바와 같이, 본 발명의 일 실시예에 따른 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모 델 학습 장치는 SNR 값에 따라 구분된 복수의 학습 단계를 기반으로 역방향 변환 과정을 수행하는 인공지능 모 델, 및 상기 인공지능 모델의 동작을 제어하는 프로세서를 포함하고, 상기 프로세서는 상기 SNR 값에 따라 역방향 변환 과정을 복수의 학습 단계로 구분하고, 구분된 각 학습 단계에 상이한 가중치를 적용 할 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동 작들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력 을 가질 수 있고, 이하에 기술된 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. SNR은 노이즈 대비 신호의 비율을 나타낸 것으로 SNR이 클수록 노이즈가 적고 원본에 가까우며, 반대로 SNR이 작을수록 노이즈가 크다. 상기 역방향 변환 과정에서 SNR이 점점 커지며, 상기 프로세서는 SNR을 특정 범위 에서 구분하여 학습 단계를 분류하고 각 학습 단계에 상이한 가중치를 적용할 수 있다. 일 실시예로서, 상기 인공지능 모델은 확산 모델을 포함할 수 있으며, 확산 모델에 입력된 이미 지로 생성 이미지를 출력하는 역변환 과정을 통해 상기 확산 모델을 학습시킬 수 있다. 확산 모델은 VAE(Variational Auto-Encoder)의 일종으로, 인코더는 학습가능한 신경망이 아니라 고정된 확 산 프로세스고, 디코더는 생성 이미지를 생성하는 학습 가능한 노이즈 제거 프로세스를 수행한다. 노이즈가 포 함된 이미지에서 점진적으로 노이즈를 제거해 나가면서 깨끗한 이미지를 생성하는 역변환 과정에서 학습을 수행 하며, 역변환 과정에서 노이즈를 제거하기 위하여 노이즈 제거 스코어 매칭 손실의 합인 VLB(Variational Lower Bound)를 최적화하여 확산 모델을 훈련시킬 수 있다. 또한, 일 실시예로서, 상기 프로세서는 확산 모델이 역변환 과정을 수행할 때 상기 역변환 과정을 SNR 값에 따라 각 학습 단계로 분류하고, 분류된 학습 단계에 각각 상이한 가중치를 적용할 수 있다. 각 학습 단계 에 대해 상이한 가중치를 적용하여 최적의 목적함수를 획득할 수 있다. 분류된 학습 단계 중 깨끗한 이미지를 얻기 위한 더 중요한 학습 단계에 대해 목적함수의 가중치를 더 할당함으 로써 최적의 목적함수를 적용하고 생성 이미지 재건 효율을 향상시킬 수 있다. 도 2는 신호 대 잡음비(SNR)에 따른 LPIPS(Learned Perceptual Image Patch Similarity) 거리(distance) 그래 프로, LPIPS 거리는 실제 이미지와 잠재 공간으로 투영한 후 생성자에 한번 다시 통과한 이미지 사이의 거리를 의미한다. 도 2에 도시된 바와 같이, 두 개의 서로 다른 깨끗한 이미지 Xo, Xo`와 세 개의 노이즈가 있는 이미지 XtA, XtB~ q(Xt｜Xo), Xt`~ q(Xt｜Xo)가 존재하고, 확산 과정(diffusion process)가 진행될 수록 SNR이 작아진다. XtA VS XtB(점선)은 동일 이미지 Xo를 공유하고 손상된 두 개의 노이즈 이미지 간의 LPIPS 거리, XtA VS Xt`(실 선)은 다른 이미지 Xo, Xo`로부터 합성되고 손상된 두 개의 노이즈 이미지 간의 LPIPS 거리를 의미한다. 확산 과정 초기의 SNR이 클 때에 보이지 않는 작은 노이즈만 가지고 있어 노이즈 이미지(Xt)가 콘텐츠(conten t)에 대한 정보를 많이 보유하고 있어, 확산 과정 초기에 XtA 및 XtB가 지각적으로 유사하고, 반면 XtA 및 Xt' 는 지각적으로 상이함을 간단하게 알 수 있다. 따라서, 확산 모델은 전체적인 맥락 정보 없이도 이미지를 복구할 수 있어 SNR이 클 때는 눈에 보이지 않 는 디테일만 학습하게 된다. 반면, 확산 과정 후반의 SNR이 작을 때는 깨끗한 이미지 Xo, Xo`의 콘텐츠에 대한 정보가 많이 제거되어 XtA VS XtB(점선)과 XtA VS Xt'(실선) 모두 LPIPS 거리가 일정한 상수 값으로 수렴하게 되고, 노이즈 이미지(Xt)에서 하이 레벨의 콘텐츠는 인식하기 어렵게 된다. 따라서, 확산 모델은 지각할 수 있는 풍부한 콘텐츠가 없어 이미지를 복구할 수 있는 사전 지식을 학습하 게 된다. 다시 말해, 확산 과정에서 SNR의 크기가 10-2 내지 100 사이일 때 지각 가능한 콘텐츠가 제거되어 SNR의 크기가 10-2 미만일 때는 입력 이미지가 상이하더라도 LPIPS 거리가 동일하게 수렴되고 손상된 두 개의 이미지가 지각 가능하게 구분되지 않으며, SNR의 크기가 100을 초과할 때 콘텐츠가 명확하게 구분되어 지각 가능함을 알 수 있 다. 따라서, 확산 모델은 SNR이 클 때 역방향 변환을 통한 재건 작업을 수행할 경우 인지할 수 없는 세부 사항 만 학습할 수 있고, SNR이 작을 때, 구체적으로, SNR의 크기가 10-2 내지 100 사이일 때 제거되는 클린 이미지 Xo의 컨텐츠 내용을 학습할 수 있어 지각 가능한 실질적인 컨텐츠를 학습할 수 있다. 도 3에 도시된 바와 같이, 깨끗한 이미지(Xo, Clean data)가 확산 과정 q(Xt｜Xo)을 통해 손상된 노이즈 이미지 (Xt, Corrupted data)가 되고, 노이즈 이미지(Xt)가 디노이징 과정 p( ｜Xt)를 통해 복구 이미지( )가 된다. 상기 학습 단계는 상기 SNR 값에 따라 순차적으로 구분된 제1 단계, 제2 단계 및 제3 단계 를 적어도 포함할 수 있다. 도 3에 도시된 바와 같이, 깨끗한 이미지(Xo, Clean data)가 확산 과정 q(Xt｜Xo)을 통해 손상된 노이즈 이미지 (Xt, Corrupted data)가 되고, 노이즈 이미지(Xt)가 디노이징 과정 p( ｜Xt)를 통해 복구 이미지( )가 된다. 상기 학습 단계는 상기 SNR 값에 따라 순차적으로 구분된 제1 단계, 제2 단계 및 제3 단계 를 적어도 포함할 수 있다. 일 실시예로서, 제1 단계는 coarse 단계로 이미지의 골격(coarse feature)이 정해지는 단계이다. 초반 노 이즈 제거 과정으로 학습 모델이 배경, 색깔, 인물의 외각 구조와 같은 골격을 학습할 수 있다. 성긴 특징 을 학습하는 단계이다. 도 3을 참조하면, 입력과 제1 단계의 이미지는 상당한 차이가 있으며, 전체 색상 구조 정도만 유사함을 알 수 있다. 일 실시예로서, 제2 단계는 content 단계로 이미지의 실질적인 컨텐츠(contents)가 정해지는 단계이다. 중 반 노이즈 제거 과정으로 학습 모델이 이미지 내 사람 얼굴, 동물 얼굴 등 실질적으로 해당 컨텐츠의 내용 을 구성하는 영역을 학습하며, 실질적인 컨텐츠 내용을 학습할 수 있다. 주요 특징을 학습하는 단계이다. 도 3 을 참조하면, 입력과 제2 단계의 이미지가 거의 유사하며, 세부적인 디테일을 제외하고 인지적으로 구별되 는 특징이 동일하다. 일 실시예로서, 제3 단계는 clean-up 단계로, 남은 잔여 노이즈를 제거하는 단계이다. 후반 노이즈 제거 과정으로 인지에 영향을 주지 않는 눈에 띄지 않는 디테일을 학습할 수 있다. 재구성된 이미지와 입력 이미지가 지각적으로 동일한 바, 지각적으로 인식할 수 있는 내용에 기여하지 않는 디테일을 학습하는 단계이다. 도 3을 참조하면, 제3 단계의 이미지가 인지할 수 없는 세부적인 디테일들까지 입력과 동일함을 알 수 있다. 따라서, 상기 제1 단계의 SNR 값은 0 내지 10-2 사이에 있으며, 상기 제2 단계의 SNR 값은 10-2 내지 100 사이에 있으며, 상기 제3 단계의 SNR 값은 100 내지 104사이에 있다. SNR의 수치에 따라 각 학습 단계를 구분 또는 분류할 수 있다. 일 실시예로서, 도 3을 참조하면, 제1 단계의 SNR값은 1.5*10-3 및 6.9*10-3 을 가지며, 제2 단계의 SNR 값은 8.4*10-2 및 6.5*10-1 를 가지며, 제3 단계의 SNR은 8.5*100 를 가져 상술한 각 단계 별 SNR의 수치에 해당함을 확인할 수 있다. 본 발명의 일 실시예에 따른 프로세서는, 상기 학습 단계(301, 302, 303)에 대한 우선순위에 따라 순차적으 로 가중치를 적용할 수 있다. 일 실시예로서, 학습에 가장 영향을 많이 끼치는 상기 제2 단계에 가장 높은 가중치를 적용하고, 잔여 노 이즈를 제거하는 상기 제3 단계에서 가장 낮은 가중치를 적용할 수 있다. 일 실시예로서, 제2 단계는 가장 높은 우선순위를 가지며, 상기 제1 단계의 우선순위는 상기 제3 단 계의 우선순위보다 높고, 프로세서는 우선순위에 따라 제2 단계, 제1 단계, 제3 단계 의 순서로 큰 가중치를 적용할 수 있다. 본 발명의 일 실시예에 따르면, 상기 프로세서는, 하기 식에 따라 상기 학습 단계에서 적용될 목적 함수 (Lsimple)를 종래의 목적함수(Lt)로부터 단순화할 수 있다."}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "식 본 발명의 일 실시예에 따르면, 상기 프로세서는, 각 학습 단계에 적용될 목적함수에 하기 식에 따라 산출된 가중치를 적용할 수 있다. 식 상기 λt는 종래 가중치이고, λt'는 각 학습 단계의 우선순위가 적용된 가중치이며, k는 작은 SNR 수치에 따 른 가중치 폭발을 방지하는 상수이며, 상기 γ(감마)는 하향 가중치의 강도를 제어하는 하이퍼파라미터이고, t 는 노이즈 정도를 표시하는 인덱스이다. 이때 λ는 널리 사용되는 가중치 체계의 일반화로, γ=0일 때 λt에 도달하여 λt를 기준선이라고 할 수 있다. 기존의 목적함수에 적용되는 가중치 λt를 λt'로 대체하여 기존의 확산 모델에도 적용할 수 있다. 따라서, 확산 모델은 각 학습 단계(301, 302, 303)에서 동일한 가중치로 학습하는 것이 아니라 각 학습 단 계(301, 302, 303)의 특성을 고려한 가중치를 상이하게 적용하여 학습을 수행할 수 있다. 또한, 본 발명의 일 실시예에 따른 프로세서는, 상기 인공지능 모델, 예를 들어 확산 모델에 입 력될 데이터 셋(set)에 따라 상기 k와 γ의 값을 조절할 수 있다. k는 분모가 0이 되지 않게 하는 상수이며, 하 이퍼 파라미터인 γ를 조절하여 가중치를 재조정할 수 있다. 구체적으로, 도 4(a)는 일반적인 확산 과정에 따른 SNR 변화를 cosine schedule과 linear schedule로 나타낸 것으로, 확산 과정이 진행될수록 cosine schedule과 linear schedule의 SNR이 작아지고 있음을 확인할 수 있다. 반면, 도 4(b) 및 (c)에 도시된 바와 같이, 본 발명에 따른 인공지능 모델 학습 장치(ours)를 이용할 경 우, 기준선(base line)의 cosine schedule 및 linear schedule의 가중치(weights)보다 제3 단계의 가중치 를 억제하고 있음을 확인할 수 있다. 또한, γ=0.5 일 때보다 γ=1로 γ 값을 더 크게 조절하였을 때 제3 단계의 가중치가 추가적으로 억제됨을 확인할 수 있다. 따라서, 인지할 수 없는 디테일을 학습하는 단계, 예를 들어 제3 단계에서 가중치를 최소로 줄이고 제1 단 계 및 제2 단계에 상대적으로 더 많은 가중치를 부가, 특히 제2 단계에 가장 큰 가중치를 부여 하여 학습함으로써 인지할 수 있는 특징을 더욱 구체화할 수 있다. 도 4를 참조하면, 제2 단계인 콘텐츠 (content) 단계에서 pretext 태스크를 해결함으로써 인지 가능한 풍부한 콘텐츠를 학습할 수 있다는 것을 확인 할 수 있다. 도 5에 도시된 바와 같이, 생성 이미지의 정량적 평가를 위해 FID(Frechet Inception Distance) 지표로 기준선 (base)과 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치(ours)를 비교할 수 있으며, 본 발명의 일 실시 예에 따른 인공지능 모델 학습 장치가 기준선의 cosine shecule 및 linear schedule보다 FID 점수가 낮아 퀄리 티가 더 우수함을 알 수 있다. 더하여, cosine schedule이 linear schedule보다 열등한 FID 점수를 보이고 있어, 제1 단계가 제3 단계 보다 더 많은 데이터를 학습하고 있어 중요성이 더 큰 것을 알 수 있다. 다시 말해, 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치는 제1 단계 및 제2 단계의 가중치 는 가중하고, 제3 단계의 가중치는 억제하여 인공지능 모델, 특히 확산 모델이 더 풍부한 시작 적 컨셉을 학습하도록 할 수 있다. 참고로, 도 5의 학습 과정(traning progress)은 확산 모델이 처리한 이미지의 수를 나타내며, γ=1을 전제 로 가중치를 적용한 것이다. 일 실시예로서, 확산 모델을 학습시킬 때 k=1로 설정하고, γ=0.5 또는 1로 설정하여 λt'를 적용할 수 있 다. 한편, 일 실시예로서, γ의 크기를 조절하여 가중치 효과를 조절할 수 있으며, 프로세서는 데이터 셋의 이 미지 해상도(resolution)가 클수록 상기 γ의 값을 크게 조절할 수 있다. γ가 0이면(λt = λt’), 원본인 입력 이미지이고, γ 값을 늘릴수록 제2 단계에 제1 단계 및 제3 단계보다 더 많은 가중치를 부여할 수 있다. 이미지 해상도가 크면 이미지 내에 더 많은 인지 가능한 정보 들이 존재하는 바, 제2 단계에 가중치를 늘려 재건 효율을 향상시킬 수 있다. 반면, γ가 너무 강하면 제1 단계 및 제3 단계와 같이 제2 단계를 제외한 학습 단계의 학습이 불가능해지며, 이미지 해상도가 적으면 γ 값이 크더라도 제2 단계의 실질적인 컨텐츠를 다른 디테일보다 더 명확하게 지각하는 효과가 떨어지게 된다. 따라서, 이미지 해상도에 따라 γ를 조절하여 학습 단계에 적용될 가중치를 적용할 수 있으며, 제2 단계, 제1 단계, 제3 단계 순서대로 가중치가 부여될 수 있다. 다시 말해, 제2 단계에 가장 큰 가중치를 부여하고, 제1 단계에 제3 단계 보다 큰 가중치를 부 여하는 것이다. 도 6에 도시된 바와 같이, 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치를 이용하여 학습을 수행할 경 우, 도 6의 위쪽에 배치된 이미지와 같이, 학습된 인공지능 모델이 정확한 색감과 객체를 생성할 수 있다. 인공지능 모델은 FFHQ, CelebA-HQ, MetFaces, AFHQ-Dogs, Oxford flowers, CUB Bird 등 다양한 데이터셋 이 입력되더라도 정확한 이미지를 생성할 수 있다. 반면, 종래 인공지능 모델 학습 장치를 이용할 경우, 도 6의 아래쪽에 배치된 기준선(Baseline) 이미지와 같이, 학습된 인공지능 모델이 입력 이미지와 상이한 색감이나 상이한 지각적 특성을 가진 이미지를 생성할 수 있다. 예를 들어, FFHQ 2M이 입력될 경우 본 발명(Ours)은 이미지에 따른 정확한 색감을 복구하지만, 기준선 이미지는 전체적으로 푸른 색감을 가지도록 생성될 수 있다. 또한, FFHQ 4M이 입력될 경우 본 발명과 달리, 기준선 이미 지는 붉은 색감을 가지도록 생성될 수 있으며, MetFaces 1.6M 또한 노이즈가 낀 듯 불명확한 색감을 가지도록 생성될 수 있다. 다시 말해, 본 발명은 학습 단계 별 상이한 가중치 적용을 이용하여 컬러 시프트(color shift) 문제를 해결하고 모델 캐패시티를 낭비하는 것을 방지할 수 있다. 따라서, 학습 단계(301, 302, 303)의 우선순위에 따라 가중치를 상이하게 적용함으로써 입력 이미지와 더 유사 한 생성 이미지를 획득할 수 있으며, 재건 효율을 극대화할 수 있다. 도 7에 도시된 바와 같이, 기준(Base)에 비해 본 발명(Ours)의 FID 및 KID 수치가 더 낮으며, FID 및 KID 수치 가 낮을수록 퀄리티가 더 우수한 것이다. 특히 FFHQ, CUB, AFHQ-D, Flowers, MetFaces 등 다양한 데이터 셋에 기준과 본 발명을 적용하였으나 모든 데이터 셋에서 본 발명의 성능이 더 우수하게 나타났다. 상기 도 7은 256*256 해상도의 데이터 셋을 사용하였고, FFHQ는 500개 샘플링 과정, 그 외에는 250 개의 샘플링 과정을 수행 하였다. 또한, 도 8은 FFHQ, Oxford Flower, CelebA-HQ 데이터 셋에 대해, 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치를 이용한 인공지능 모델 학습 방법과 다른 학습 방법을 다양한 인공지능 모델에 적용하고, FID 점수 에 따라 그 성능을 나열한 것이다. 모든 데이터 셋은 256*256 해상도이고, 노이즈 적용한 횟수 T=1000으로 설정한 학습 결과로, 도 8을 참조하면, 본 발명이 적용된 모든 모델이 다른 모델들보다 감소된 샘플링 단계에서 최상의 성능을 달성했으며, 특히 FFHQ 에 대해서는, 본 발명이 StyleGAN2를 제외하고 가장 많은 모델에서 가장 낮은 FID 점수를 획득하여 우수한 결과 를 달성함을 확인할 수 있다. 더하여, 도 9는 250 단계로 생성된 샘플로, 800k 이미지에 대한 MetFace로 훈련된 모델로서, 본 발명이 다양한 구성의 기준선보다 더 우수한 성능을 지속적으로 달성함을 나타냄을 확인할 수 있다. 도 9를 참조하면, 본 발명 은 인공지능 모델의 구성에 상관없이 효율적임을 알 수 있다. 도 9의 (a)는 본 발명의 디폴트 구성이고, (b)는 BigGAN block이며, (c)는 보틀넥(8*8 해상도)에서 Self-attention만 수행한 구성, (d)는 2개의 residual block 이고, (e)는 학습률 2.5*e-5인 구성을 의미한다. 도 10도 FFHQ 데이터셋으로 훈련된 모델의 다양한 샘플링 단계의 FID 점수를 나타내며, 본 발명으로 훈련된 모 델이 기준선보다 상당한 마진으로 우수한 성능을 내고 있음을 확인할 수 있다. 더하여, 도 11은 스위핑 샘플링 스케쥴(Sweeping sampling schedule)에 따른 FID 와 KID 지표를 나타낸 것으로, 기준 방법으로 스위핑 샘플링 스케쥴을 조절하더라도 다소 성능이 향상되고는 있지만, 본 발명의 성능 을 향상하지는 못하고 있음을 확인할 수 있다. 따라서, 인공지능 모델의 구성 불문, 샘플링 단계 불문, 데이터 셋 종류 불문, 스위핑 샘프링 스케쥴 불문 하고 우수한 성능을 도출할 수 있어 환경에 구애받지 않고 월등한 재건 효율을 발휘할 수 있다. 한편, 본 발명의 일 실시예에 따르면, 상기 프로세서는, 상기 인공지능 모델로부터 출력된 생성 이미 지의 퀄리티 파라미터를 기반으로 각 학습 단계(301,302, 303)의 우선순위가 적용된 가중치(λt')를 재조정할 수 있다. 이때, 상기 퀄리티 파라미터는 상기 생성 이미지의 FID(Frechet Inception Distance) 및 KID(Kernal Inception Distance) 수치를 포함할 수 있다. 일 실시예로서, 상기 FID 및 KID 수치가 임계치 이상일 경우 상기 λt'를 재조정하여 상기 제2 단계의 가 중치를 상향하고, 상기 제1 단계 및 상기 제3 단계의 가중치를 하향시킬 수 있다. 이때, 상기 제1 단 계의 가중치 하향 폭 또는 하향 우선순위가 상기 제 3단계의 가중치 하향 폭 또는 하향 우선순위보다 작을 수 있다. 예를 들어, 제 2단계의 가중치를 상향시키고, 그에 따라 다른 학습 단계의 가중치를 하향시켜야 할 때 우 선 제3 단계의 가중치를 설정치만큼 하향시킬 수 있다. 제3 단계의 가중치를 설정치만큼 하향시켰음에도 추가 가중치 하향이 필요한 경우 제1 단계의 가중치 를 추가 가중치 하향치만큼 하향시킬 수 있다. 한편, 도 12는 본 발명의 일 실시예에 따른 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치 를 이용한 인공지능 모델 학습 방법의 플로우 차트를 도시한 것이다. 본 발명의 일 실시예에 따른 신호 대 잡음비 기반 인공지능 모델 학습 장치를 이용한 인공지능 모델 학습 방법 은 SNR 값에 따라 상기 학습 모델의 역방향 변환 과정을 복수의 학습 단계로 구분하는 단계(S1210) 및 구분된 복수의 학습 단계에 대해 각각 상이한 가중치를 적용하여 역방향 변환 과정을 수행하는 역방향 단계(S1220)를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 상기 단계(S1210)는 상기 SNR 값에 따라 상기 학습 모델의 역방향 변환 과정을 적어도 제1 단계, 제2 단계 및 제3 단계로 구분하는 단계를 포함할 수 있다. 또한, 상기 단계(S1220)는, 상기 제2 단계, 상기 제1 단계 및 상기 제3 단계 순서로 우선 순위 를 적용하는 단계 및 상기 우선 순위에 따라 상기 제2 단계에서 가장 높은 가중치를 적용하고, 상기 제3 단계에서 가장 낮은 가중치를 적용하여 목적함수를 최적화하는 단계를 포함할 수 있다. 더하여, 본 발명의 일 실시예에 따르면, 퀄리티 파라미터인 FID 및 KID 수치가 임계치 이상일 경우 상기 λt'를 재조정하여 상기 제2 단계의 가중치를 상향하고, 상기 제1 단계 및 상기 제3 단계의 가중치를 하향시키는 단계를 더 포함하며, 이때, 상기 제1 단계의 가중치 하향 폭 또는 하향 우선순위가 상기 제 3단계의 가중치 하향 폭 또는 하향 우선순위보다 작을 수 있다. 다시 말해, 학습 단계 별로 가중치를 적용할 떄 가장 먼저 제2 단계의 가중치를 상향하고, 재건 효율이 목 표에 이르지 못하면 그 다음으로 제3 단계의 가중치를 설정치만큼 하향하며, 추가로 부족한 만큼 제1 단계 의 가중치를 부족분만큼 하향하도록 할 수 있다. 제2 단계, 제1 단계 및 제3 단계의 순으 로 우선순위를 가질 수 있다. 상술한 내용과 중복되는 내용은 설명의 명료함을 위해 생략하기로 한다. 본 발명의 일 실시예에 따른 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치는 SNR 값에 따 라 구분된 복수의 학습 단계를 기반으로 역방향 변환 과정을 수행하는 확산 모델을 포함하는 인공지능 모 델 및 상기 인공지능 모델의 동작을 제어하는 프로세서를 포함하고, 상기 프로세서는 상기 SNR 값에 따라 역방향 변환 과정을 복수의 학습 단계로 구분하고, 구분된 각 학습 단계에 상이한 가중치를 적용할 수 있다. 상이한 가중치를 각 단계 별로 적용하고, 특히 content 단계에 가장 높은 가중치를, clean-up 단계에 가장 낮은 가중치를 부여하여 지각 가능한 주요 특징 복구를 학습하도록 학습 효율을 향상시킬 수 있다."}
{"patent_id": "10-2023-0037824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2023-0037824", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치의 블록 도를 도시한 것이다. 도 2는 신호 대 잡음비(SNR)에 따른 LPIPS(Learned Perceptual Image Patch Similarity) 거리(distance) 그래 프를 도시한 것이다. 도 3은 본 발명의 일 실시예에 따른 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치의 학습 단계를 구분한 것이다. 도 4는 기준선(base line)과 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치를 이용한 경우(ours)의 SNR 에 따른 가중치(weights) 적용을 비교한 그래프이다. 도 5는 기준선(base line)과 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치를 이용한 경우(ours)의 학습 과정 진행률에 따른 FID 점수를 나타낸 그래프이다. 도 6은 기준선(base line)과 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치를 이용한 경우(ours)의 생성 이미지 퀄리티를 질적 비교한 것이다. 도 7은 기준선(base line)과 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치를 이용한 경우(ours)의 정량 적 수치를 비교한 표이다. 도 8은 본 발명의 일 실시예에 따른 인공지능 모델 학습 방법을 이용하여 학습을 수행한 인공지능 모델들의 학 습 방법 및 타입에 따른 정량적 수치를 비교한 표이다. 도 9는 본 발명의 일 실시예에 따른 인공지능 모델 학습 방법을 이용하여 학습을 수행한 인공지능 모델들의 모 델 구성에 따른 정량적 수치를 비교한 표이다. 도 10은 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치의 샘플링 단계에 따른 정량적 수치를 나타낸 그 래프이다. 도 11은 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치의 스위핑 샘플링 스케쥴에 따른 정량적 수치를 나타낸 표이다. 도 12는 본 발명의 일 실시예에 따른 신호 대 잡음비 기반의 우선순위를 적용한 인공지능 모델 학습 장치를 이 용한 인공지능 모델 학습 방법의 플로우 차트를 도시한 것이다."}
