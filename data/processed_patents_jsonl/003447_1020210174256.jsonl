{"patent_id": "10-2021-0174256", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0085768", "출원번호": "10-2021-0174256", "발명의 명칭": "동작 유사도 분석 장치 및 방법", "출원인": "주식회사 케이티", "발명자": "최영주"}}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "레퍼런스 영상과 사용자 영상의 동작 유사도를 분석하는 동작 유사도 분석 장치에 있어서,상기 레퍼런스 영상 및 상기 사용자 영상의 각 프레임에서 관절 좌표 및 관절 각도를 추출하는 추출부;상기 레퍼런스 영상 및 상기 사용자 영상 각각에 대해 소정 개수의 연속된 프레임 단위로 상기 관절 좌표 및 상기 관절 각도를 포함하는 단위 모션 벡터를 생성하는 생성부;상기 레퍼런스 영상 및 상기 사용자 영상 간의 단위 모션 벡터들의 비교를 통해 상기 레퍼런스 영상 및 상기 사용자 영상 간의 유사도를 산출하는 산출부; 및상기 유사도에 기초하여 평가 정보를 제공하는 제공부를 포함하는 동작 유사도 분석 장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,미리 메트릭 학습(metric learning)이 수행된 변환 모델을 이용하여 상기 생성부에서 생성된 단위 모션 벡터들을 변환하여 상기 산출부로 출력하는 변환부를 더 포함하는 것을 특징으로 하는 동작 유사도 분석 장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 메트릭 학습은,앵커 단위 모션 벡터와 긍정 단위 모션 벡터 간의 거리는 감소하고, 앵커 단위 모션 벡터와 부정 단위 모션 벡터 간의 거리는 증가하도록 하는 유사도 손실 함수를 이용하여 수행되는 것을 특징으로 하는 동작 유사도 분석장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 메트릭 학습은,복수의 각도에서 동시에 촬영된 복수의 레퍼런스 영상 및 복수의 사용자 영상이 학습 데이터로 이용되는 것을특징으로 하는 동작 유사도 분석 장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 생성부는,시간 순서에 따라 한 프레임씩 이동하며 상기 단위 모션 벡터를 생성하는 것을 특징으로 하는 동작 유사도 분석장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 산출부는,영상의 전 구간에 걸쳐 유사도의 평균을 산출하고,상기 제공부는,공개특허 10-2023-0085768-3-상기 유사도의 평균을, 전문가 평가 점수와 유사도 간의 회귀분석 상관관계에 기초하여, 소정 비율 점수로 환산하여 제공하는 것을 특징으로 하는 동작 유사도 분석 장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 제공부는,영상의 전 구간에 걸쳐 유사도를 시계열 변화에 따라 그룹핑하고, 평균 유사도가 가장 높은 구간과 가장 낮은구간을 각각 베스트/워스트 구간으로 선정하여 제공하는 것을 특징으로 하는 동작 유사도 분석 장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제공부는,평균 유사도가 동일한 구간에 대해서는 구간 길이가 가장 긴 구간을 선정하는 것을 특징으로 하는 동작 유사도분석 장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제5항에 있어서,상기 제공부는,프레임별로 유사도를 그래프로 표시하며 이에 대응하는 레퍼런스 영상 및 사용자 영상을 동시에 재생하는 것을특징으로 하는 동작 유사도 분석 장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제5항에 있어서,상기 제공부는,상기 레퍼런스 영상의 시계열 단위 모션 벡터들과 상기 사용자 영상의 시계열 단위 모션 벡터들 간의 거리가 최소화되도록 매칭하고, 서로 매칭된 프레임들의 시간차를 기초로 박자 평가 정보를 제공하는 것을 특징으로 하는동작 유사도 분석 장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제공부는,각 프레임별 시간차를 시계열 변화에 따라 그룹핑하고, 각 구간별로 시간차의 평균을 박자 정보로 제공하는 특징으로 하는 동작 유사도 분석 장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 추출부는,복수의 각도에서 동시에 촬영된 복수의 레퍼런스 영상 및 복수의 사용자 영상을 이용하여 학습된 추출 모델을이용하는 것을 특징으로 하는 동작 유사도 분석 장치."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "레퍼런스 영상과 사용자 영상의 동작 유사도를 분석하는 방법에 있어서,상기 레퍼런스 영상 및 상기 사용자 영상의 각 프레임에서 관절 좌표 및 관절 각도를 추출하는 단계;상기 레퍼런스 영상 및 상기 사용자 영상 각각에 대해 소정 개수의 연속된 프레임 단위로 상기 관절 좌표 및 상공개특허 10-2023-0085768-4-기 관절 각도를 포함하는 단위 모션 벡터를 생성하는 단계;상기 레퍼런스 영상 및 상기 사용자 영상 간의 단위 모션 벡터들의 비교를 통해 상기 레퍼런스 영상 및 상기 사용자 영상 간의 유사도를 산출하는 단계; 및상기 유사도에 기초하여 평가 정보를 제공하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 산출하는 단계 이전에,미리 메트릭 학습(metric learning)이 수행된 변환 모델을 이용하여 상기 생성된 단위 모션 벡터들을 변환하는단계를 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 메트릭 학습은,앵커 단위 모션 벡터와 긍정 단위 모션 벡터 간의 거리는 감소하고, 앵커 단위 모션 벡터와 부정 단위 모션 벡터 간의 거리는 증가하도록 하는 유사도 손실 함수를 이용하여 수행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 메트릭 학습은,복수의 각도에서 동시에 촬영된 복수의 레퍼런스 영상 및 복수의 사용자 영상이 학습 데이터로 이용되는 것을특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 생성하는 단계는,시간 순서에 따라 한 프레임씩 이동하며 상기 단위 모션 벡터를 생성하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 산출하는 단계는,영상의 전 구간에 걸쳐 유사도의 평균을 산출하는 단계를 포함하고,상기 제공하는 단계는,상기 유사도의 평균을, 전문가 평가 점수와 유사도 간의 회귀분석 상관관계에 기초하여, 소정 비율 점수로 환산하여 제공하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서,상기 제공하는 단계는,영상의 전 구간에 걸쳐 유사도를 시계열 변화에 따라 그룹핑하고, 평균 유사도가 가장 높은 구간과 가장 낮은구간을 각각 베스트/워스트 구간으로 선정하여 제공하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2023-0085768-5-제19항에 있어서,상기 베스트/워스트 구간으로 선정하여 제공하는 단계는,평균 유사도가 동일한 구간에 대해서는 구간 길이가 가장 긴 구간을 선정하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제17항에 있어서,상기 제공하는 단계는,프레임별로 유사도를 그래프로 표시하며 이에 대응하는 레퍼런스 영상 및 사용자 영상을 동시에 재생하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제17항에 있어서,상기 제공하는 단계는,상기 레퍼런스 영상의 시계열 단위 모션 벡터들과 상기 사용자 영상의 시계열 단위 모션 벡터들 간의 거리가 최소화되도록 매칭하고, 서로 매칭된 프레임들의 시간차를 기초로 박자 평가 정보를 제공하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서,상기 박자 평가 정보를 제공하는 단계는,각 프레임별 시간차를 시계열 변화에 따라 그룹핑하고, 각 구간별로 시간차의 평균을 박자 정보로 제공하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제13항에 있어서,상기 추출하는 단계는,복수의 각도에서 동시에 촬영된 복수의 레퍼런스 영상 및 복수의 사용자 영상을 이용하여 학습된 추출 모델을이용하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0174256", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제13항 내지 제24항 중 어느 한 항에 따른 방법을 컴퓨터 시스템을 통해 실행하는 컴퓨터 프로그램으로서 컴퓨터로 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0174256", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "별도의 센서없이, 영상 분석을 통해 레퍼런스 영상과 사용자 영상 간의 동작 유사도를 분석할 수 있는 동작 유사 도 분석 장치 및 방법이 개시된다. 일 측면에 따른, 레퍼런스 영상과 사용자 영상의 동작 유사도를 분석하는 동 작 유사도 분석 장치는, 상기 레퍼런스 영상 및 상기 사용자 영상의 각 프레임에서 관절 좌표 및 관절 각도를 추 출하는 추출부; 상기 레퍼런스 영상 및 상기 사용자 영상 각각에 대해 소정 개수의 연속된 프레임 단위로 상기 관절 좌표 및 상기 관절 각도를 포함하는 단위 모션 벡터를 생성하는 생성부; 상기 레퍼런스 영상 및 상기 사용 자 영상 간의 단위 모션 벡터들의 비교를 통해 상기 레퍼런스 영상 및 상기 사용자 영상 간의 유사도를 산출하는 산출부; 및 상기 유사도에 기초하여 평가 정보를 제공하는 제공부를 포함한다."}
{"patent_id": "10-2021-0174256", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 동작 유사도 분석 장치 및 방법에 관한 것으로, 보다 구체적으로, 레퍼런스 영상과 사용자 영상 간 의 동작 유사도를 분석하는 동작 유사도 분석 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0174256", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 시중에 출시된 춤을 따라하는 서비스는 일반적인 카메라 외에 별도의 센서를 이용해 동작 정보를 획득하거 나 동작을 캡처할 수 있는 추가적인 장치를 신체에 접촉한 형태로 춤을 추도록 하여 사람의 동작을 검출한다. 사람의 관절과 스켈레톤 등을 일정 주기로 캡처하여 사전에 정의해둔 정답 동작을 얼마나 잘 따라 했는지 판별 하고 이를 평가하여 점수로 보여준다.이와 같이 종래의 동작 유사도 분석 서비스는 고가의 별도 장비나 번거롭게 사람이 추가 장치를 신체와 접촉한 상태에서 동작을 취해야 하기에 서비스를 이용할 때 불편하거나 추가 비용이 발생한다. 이에 따라 카메라로 촬 영된 영상을 분석하여 동작 유사도를 분석하는 시도가 이루어지고 있다. 이 시도에서는 동작 인식 및 분류 기술 을 적용한다. 그러나, 종래의 동작 인식 및 분류 기술은, 사전에 정의된 몇몇 특정 동작들에 대해서만 동작들을 인식하거나 분류하는 것으로, 이를 이용해서는 무한한 동작들로 이루어지는 연속적인 댄스 등에 대해 동작 유사 도를 분석하는데 한계가 있다."}
{"patent_id": "10-2021-0174256", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위해 제안된 것으로, 별도의 센서없이, 영상 분석을 통해 연속적인 동작들 로 이루어지는 레퍼런스 영상과 사용자 영상 간의 동작 유사도를 분석할 수 있는 동작 유사도 분석 장치 및 방 법을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2021-0174256", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에 따른, 레퍼런스 영상과 사용자 영상의 동작 유사도를 분석하는 동작 유사도 분석 장치는, 상기 레퍼 런스 영상 및 상기 사용자 영상의 각 프레임에서 관절 좌표 및 관절 각도를 추출하는 추출부; 상기 레퍼런스 영 상 및 상기 사용자 영상 각각에 대해 소정 개수의 연속된 프레임 단위로 상기 관절 좌표 및 상기 관절 각도를 포함하는 단위 모션 벡터를 생성하는 생성부; 상기 레퍼런스 영상 및 상기 사용자 영상 간의 단위 모션 벡터들 의 비교를 통해 상기 레퍼런스 영상 및 상기 사용자 영상 간의 유사도를 산출하는 산출부; 및 상기 유사도에 기 초하여 평가 정보를 제공하는 제공부를 포함한다. 상기 동작 유사도 분석 장치는, 미리 메트릭 학습(metric learning)이 수행된 변환 모델을 이용하여 상기 생성 부에서 생성된 단위 모션 벡터들을 변환하여 상기 산출부로 출력하는 변환부를 더 포함할 수 있다. 상기 메트릭 학습은, 앵커 단위 모션 벡터와 긍정 단위 모션 벡터 간의 거리는 감소하고, 앵커 단위 모션 벡터 와 부정 단위 모션 벡터 간의 거리는 증가하도록 하는 유사도 손실 함수를 이용하여 수행될 수 있다. 상기 메트릭 학습은, 복수의 각도에서 동시에 촬영된 복수의 레퍼런스 영상 및 복수의 사용자 영상이 학습 데이 터로 이용될 수 있다. 상기 생성부는, 시간 순서에 따라 한 프레임씩 이동하며 상기 단위 모션 벡터를 생성할 수 있다. 상기 산출부는, 영상의 전 구간에 걸쳐 유사도의 평균을 산출하고, 상기 제공부는, 상기 유사도의 평균을, 전문 가 평가 점수와 유사도 간의 회귀분석 상관관계에 기초하여, 소정 비율 점수로 환산하여 제공할 수 있다. 상기 제공부는, 영상의 전 구간에 걸쳐 유사도를 시계열 변화에 따라 그룹핑하고, 평균 유사도가 가장 높은 구 간과 가장 낮은 구간을 각각 베스트/워스트 구간으로 선정하여 제공할 수 있다. 상기 제공부는, 평균 유사도가 동일한 구간에 대해서는 구간 길이가 가장 긴 구간을 선정할 수 있다. 상기 제공부는, 프레임별로 유사도를 그래프로 표시하며 이에 대응하는 레퍼런스 영상 및 사용자 영상을 동시에 재생할 수 있다. 상기 제공부는, 상기 레퍼런스 영상의 시계열 단위 모션 벡터들과 상기 사용자 영상의 시계열 단위 모션 벡터들 간의 거리가 최소화되도록 매칭하고, 서로 매칭된 프레임들의 시간차를 기초로 박자 평가 정보를 제공할 수 있 다. 상기 제공부는, 각 프레임별 시간차를 시계열 변화에 따라 그룹핑하고, 각 구간별로 시간차의 평균을 박자 정보 로 제공할 수 있다. 상기 추출부는, 복수의 각도에서 동시에 촬영된 복수의 레퍼런스 영상 및 복수의 사용자 영상을 이용하여 학습 된 추출 모델을 이용할 수 있다. 다른 측면에 따른 레퍼런스 영상과 사용자 영상의 동작 유사도를 분석하는 방법은, 상기 레퍼런스 영상 및 상기 사용자 영상의 각 프레임에서 관절 좌표 및 관절 각도를 추출하는 단계; 상기 레퍼런스 영상 및 상기 사용자 영 상 각각에 대해 소정 개수의 연속된 프레임 단위로 상기 관절 좌표 및 상기 관절 각도를 포함하는 단위 모션 벡터를 생성하는 단계; 상기 레퍼런스 영상 및 상기 사용자 영상 간의 단위 모션 벡터들의 비교를 통해 상기 레퍼 런스 영상 및 상기 사용자 영상 간의 유사도를 산출하는 단계; 및 상기 유사도에 기초하여 평가 정보를 제공하 는 단계를 포함한다."}
{"patent_id": "10-2021-0174256", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은, 별도의 센서없이, 영상 분석을 통해 연속적인 동작들로 이루어진 레퍼런스 영상과 사용자 영상 간의 동작 유사도를 분석할 수 있어, 비용을 줄이고 사용자의 불편을 감소시킬 수 있다. 본 발명은, 소정 개수의 연속된 프레임 단위로 생성되는 단위 모션 벡터들의 비교를 통해 동작 유사도를 분석함 으로써, 노이즈에 강인하고, 동작의 경로 및 박자감을 정확히 분석할 수 있다. 본 발명은, 동작 유사도를 사람이 직관적으로 느낄 수 있는 점수로 환산하여 제공할 수 있어, 동작 유사도 분석 을 이용하는 사용자의 만족도를 높일 수 있다. 본 발명은, 미리 메트릭 학습된 변환 모델을 이용하여 단위 모션 벡터들을 변환하여 동작 유사도를 분석함으로 써, 동작 유사도 분석의 정확도를 높일 수 있다."}
{"patent_id": "10-2021-0174256", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로 서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시예를 설명함 에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단 되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이해할 수 있도 록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사 상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다.단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘어져서 구현될 수도 있다. 도 1은 본 발명의 일 실시예에 따른 동작 유사도 분석 장치의 구성을 나타낸 도면이다. 본 실시예에 따른 동작 유사도 분석 장치는, 메모리, 메모리 제어기, 하나 이상의 프로세서(CPU), 주변 인터페이스, 입출력(I/O) 서브시스템, 디스플레이 장치, 입력 장치 및 통신 회로를 포함할 수 있다. 이러한 구성요소는 하나 이상의 통신 버스 또는 신호선을 통하여 통신할 수 있고, 여러 구성요소는 하나 이상의 신호 처리 및/또는 애플리케이션 전 용 집적 회로(application specific integrated circuit)를 포함하여, 하드웨어나, 소프트웨어로 구현되거나, 또는 하드웨어와 소프트웨어 둘의 조합으로 구현될 수 있다. 도 1을 참조하면, 동작 유사도 분석 장치는, 추출부, 생성부, 산출부 및 제공부를 포함하고, 이들은 프로그램으로 구현되어 메모리에 저장되고 적어도 하나의 프로세서에 의해 실행될 수 있고, 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 추출부는, 레퍼런스 영상 및 사용자 영상을 수신하고, 수신된 레퍼런스 영상 및 사용자 영상의 각 프레임 에서 관절 좌표 및 관절 각도를 추출한다. 레퍼런스 영상 및 사용자 영상은, 동작 유사도 분석 장치의 내 부 저장장치 또는 외부 저장장치로부터 수신될 수 있고, 또는 외부 서버로부터 수신될 수 있다. 일 실시예에서, 레퍼런스 영상은 내부 저장장치에 미리 저장되고, 사용자 영상은 카메라로부터 수신될 수도 있다. 도 2는 본 발 명의 일 실시예에 따른 인체의 관절 좌표 및 관절 각도를 나타낸 도면으로, 도 2를 참조하면, 본 실시예에서는 0부터 12까지의 13개의 관절 좌표가 추출되고, θ0부터 θ12까지의 13개의 관절 각도가 추출될 수 있으나, 반드 시 여기에 제한되는 것은 아니며 인체 포즈 예측 모델에 따라 다른 인체 관절 구성이 사용될 수도 있다. 일반적으로 동작을 구분지을 수 있는 요소는 자세 형태(즉, 토폴로지(topology))의 차이이다. 이러한 자세 형태 의 정보를 담을 수 있는 방법은 다양할 수 있지만 기본적으로 위상의 정보를 표현하는 좌표값을 사용할 수 있다. 이를 위해 본 발명에서는 단일 이미지로부터 인체의 관절을 추출하고 그 관절의 좌표를 이용한다. 이때, 관절 좌표의 값은, 카메라의 거리에 따른 크기 변화량을 제거하고 균일한 범위 안에서 자세 형태의 차이만을 비 교하기 위해 정규화된다. 예를 들어, 각 관절 좌표는 0~1 사이의 값으로 변환되어 정규화된다. 하지만, 이와 같 이 정규화된 좌표값을 사용하면, 사람의 키, 또는 신체 비율에 따라 자세 형태가 왜곡되는 현상이 발생되어 원 래의 자세 형태와 약간 다른 값으로 변환될 수 있다. 본 발명에서는 동작 유사도 분석시 이러한 오류를 보완하 기 위해 관절들 간의 각도를 추가하여 동작 유사도 분석에 이용한다. 생성부는, 상기 레퍼런스 영상 및 상기 사용자 영상 각각에 대해 소정 개수의 연속된 프레임 단위로 상기 관절 좌표 및 상기 관절 각도를 포함하는 단위 모션 벡터를 생성한다. 예를 들어, 16개 내지 20개 프레임 단위 로 단위 모션 벡터를 생성할 수 있다. 동작 유사도 분석시, 프레임을 1대1로 비교할 경우, 노이즈에 강인하지 않고, 특히 하나의 댄스를 평가하는데 있어서 동작의 경로 및 박자감 등을 제대로 분석할 수 없다. 따라서, 본 발명에서는 소정 개수의 연속된 프레임 단위로 단위 모션 벡터를 생성한다. 예를 들어, 하나의 단위 모션 벡터 는, 16개 프레임의 관절 좌표 및 관절 각도를 포함한다. i번째 프레임에서 추출되는 j번째 관절 좌표를 (pxj, pyj)라 하고, k번째 관절 각도를 θk라 할 때, i번째 프레 임에서 추출되는 13개의 관절 좌표들 및 13개의 관절 각도들을 다음과 같이 표현할 수 있다."}
{"patent_id": "10-2021-0174256", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "그리고, 16개 프레임의 관절 좌표들 및 관절 각도들로 구성되는 하나의 단위 모션 벡터는, 다음과 같이 표현할 수 있다. 아래에서 i는 프레임 인덱스이다."}
{"patent_id": "10-2021-0174256", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 3은 본 발명의 일 실시예에 따른 연속된 프레임으로 구성되는 단위 모션 벡터를 나타낸 도면이다. 도 3을 참 조하면, 영상의 1번째 프레임부터 16번째 프레임에서 추출되는 관절 좌표들 및 관절 각도들을 포함하여 제1 단 위 모션 벡터(m0)가 생성되고, 17번째 프레임부터 32번째 프레임에서 추출되는 관절 좌표들 및 관절 각도들을 포함하여 제2 단위 모션 벡터(m1)가 생성되는 방식으로, 복수의 단위 모션 벡터가 생성될 수 있다. 바람직하게, 생성부는, 레퍼런스 영상 및 사용자 영상 각각에서 시간 순서에 따라 한 프레임씩 이동하며 단위 모션 벡터들을 생성할 수 있다. 도 4는 본 발명의 다른 실시예에 따른 연속된 프레임으로 구성되는 단위 모션 벡터를 나타낸 도면이다. 도 4를 참조하면, 영상의 1번째 프레임부터 16번째 프레임에서 추출되는 관절 좌 표들 및 관절 각도들을 포함하여 제1 단위 모션 벡터(m0)가 생성되고, 2번째 프레임부터 17번째 프레임에서 추 출되는 관절 좌표들 및 관절 각도들을 포함하여 제2 단위 모션 벡터(m1)가 생성되며, 3번째 프레임부터 18번째 프레임에서 추출되는 관절 좌표들 및 관절 각도들을 포함하여 제3 단위 모션 벡터(m2)가 생성되는 방식으로, 복 수의 단위 모션 벡터가 생성될 수 있다. 산출부는, 상기 레퍼런스 영상 및 상기 사용자 영상 간의 단위 모션 벡터들의 비교를 통해 상기 레퍼런스 영상 및 상기 사용자 영상 간의 유사도를 산출한다. 여기서 유사도는, 유클리디안 거리(Euclidian distance) 및 /또는 코사인 유사도(cos similarity)일 수 있다. 즉, 산출부는, 레퍼런스 영상의 단위 모션 벡터와, 사용 자 영상의 단위 모션 벡터 간의 유클리디안 거리를 유사도로 산출할 수 있고, 또는 레퍼런스 영상의 단위 모션 벡터와, 사용자 영상의 단위 모션 벡터 간의 코사인 유사도를 유사도로서 산출할 수 있다. 유클리디안 거리는 다음과 같이 표현할 수 있다. , 여기서 ei는 레퍼런스 영상의 단위 모션 벡터이고, ej는 사용자 영상의 단위 모 션 벡터이다. 산출부는, 레퍼런스 영상 및 사용자 영상의 각 대응하는 순번의 단위 모션 벡터마다 유사도를 산출할 수 있고, 또는 단위 모션 벡터들의 유사도 전체 평균을 산출할 수도 있다. 제공부는, 상기 산출부에서 산출된 유사도에 기초하여 평가 정보를 제공한다. 제공부는, 디스플 레이 장치를 통해 평가 정보를 사용자에게 제공할 수 있고, 또는 문자 메시지나, 음성, 또는 이메일 등의 다양 한 수단을 통해 평가 정보를 사용자에게 제공할 수 있다. 일 실시예에서, 제공부는, 상기 산출부에서 산출된 유사도를, 전문가 평가 점수와 유사도 간의 회귀 분석 상관관계에 기초하여, 소정 비율 점수로 환산하여 제공할 수 있다. 예를 들어, 제공부는, 100점 만점 을 기준으로 점수를 환산하여 제공할 수 있다. 상기 산출부에서 산출된 유사도는 인지적 관점에서 사람이 느끼는 점수의 기준과 다를 수 있다. 따라서, 상기 산출부에서 산출된 유사도를 사람이 직관적으로 느낄 수 있는 점수, 즉 전문가의 평가 점수로 환산한다. 이를 위해, 동일한 동작에 대해 상기 산출부에서 산출 된 유사도와 전문가가 평가한 점수의 상관관계를 미리 학습하여 이용한다. 구체적으로, 다량의 레퍼런스 영상 및 사용자 영상에 대해 앞서 설명한 방식으로 유사도를 산출한다. 여기서 유 사도는 유클리디안 거리 또는 코사인 유사도 중 어느 하나일 수 있고, 또는 유클리디안 거리와 코사인 유사도의 쌍일 수 있다. 그리고 동일한 영상들에 대해 전문가 집단이 1~5점 기준으로 점수를 부여하도록 한다. 즉, 레퍼 런스 영상을 보고 동작을 따라하는 사용자 영상에 대해 전문가 집단은 1~5점 기준으로 점수를 부여한다. 따라서, 다량의 (유사도, 전문가 평가 점수)의 데이터 세트가 만들어진다. 이와 같이 만들어진 데이터 세트에 대해 선형 회귀(Linear Regression) 분석을 하여 선형 회귀 함수를 학습한다. 선형 회귀 분석은, 유사도와 전문 가 평가 점수 간의 경향성을 분석하는 것이다. 상기 제공부는, 이와 같이 학습된 선형 회귀 함수에, 상기 산출부에서 산출된 유사도를 입력하고, 선형 회귀 함수에서 출력되는 점수를 100점 기준으로 환산한다. 도 5는 본 발명의 일 실시예에 따른 유사도와 전문가 평가 점수 간의 회귀분석 상관관계를 학습하는 과정을 설 명하는 도면이다. 도 5를 참조하면, 다량의 레퍼런스 영상 및 사용자 영상에 대해 유클리디안 거리(dj)와, 코사 인 유사도(csj)가 산출된다. 그리고 동일한 영상들에 전문가 집단이 1~5점 기준으로 점수를 부여한다. 따라서, 유클리디안 거리(dj) 및 코사인 유사도(csj)의 쌍(xj)들과, 전문가 평가 점수(sj)들의 데이터 세트(S, X)가 만들 어진다. 이 데이터 세트(S, X)에 대해 선형 회귀 분석(Linear regression analysis)을 하여 선형 회귀 함수 (g(X))를 학습한다.이와 같이 학습된 선형 회귀 함수(g(X))에 유클리디안 거리(d)와 코사인 유사도(cs)를 대입 하면, 1~5점 기준의 전문가 평가 점수가 출력된다. 일 실시예에서, 제공부는, 영상의 전 구간에 걸쳐 유사도(유클리디안 거리, 또는 코사인 유사도 또는 전문 가 평가 점수)를 시계열 변화에 따라 그룹핑하고, 평균 유사도가 가장 높은 구간과 가장 낮은 구간을 각각 베스 트/워스트 구간으로 선정하여 제공할 수 있다. 구체적으로, 제공부는, 한 프레임씩 이동하며 산출된 전 구 간에 대한 유사도의 값을 시계열 데이터(time series data)에 대한 클러스터링 기법인 SXA(Symbolic Aggregate A pproximation)을 적용하여, 전체 구간에서 유사한 값을 갖는 연속된 구간을 그룹핑하고, 복수의 구간 중에서 평균 유사도가 가장 높은 구간을 베스트 구간으로 그리고 평균 유사도가 가장 낮은 구간을 워스트 구간으로 선 정한다. 이때, 평균 유사도가 동일한 복수의 후보 구간이 있을 경우, 구간 길이가 가장 긴 곳을 베스트 또는 워 스트 구간으로 선정한다. 도 6은 본 발명의 일 실시예에 따른 영상의 전체 구간에서 베스트/워스트 구간을 나타낸 도면이다. 도 6을 참조 하면, 영상의 전체 구간에 걸쳐서 유사도(도 6에서 score)가 산출된다. 이 유사도의 값에 대해 SXA(Symbolic Aggregate A pproximation)를 적용하여 유사한 값을 갖는 연속된 구간을 그룹핑한다. 이와 같이 만들어지는 복 수의 구간 중에서 평균 유사도가 가장 높은 구간이 베스트(Best) 구간으로 선정되고, 평균 유사도가 가장 낮은 구간이 워스트(Worst) 구간으로 선정된다. 제공부는, 베스트 구간과 워스트 구간에 대한 레퍼런스 영상과 사용자 영상을 함께 디스플레이 장치에 재생할 수 있다. 이를 통해 사용자는 레퍼런스 영상 속의 동작과 자신의 동작을 비교하여 봄으로써 좀 더 상세한 정보를 전달받을 수 있다. 일 실시예에서, 제공부는, 프레임별로 유사도를 그래프로 표시하며 이에 대응하는 레퍼런스 영상 및 사용 자 영상을 동시에 재생할 수 있다. 앞서 설명한 바와 같이, 한 프레임씩 이동하며 유사도가 산출되고, 각 유사 도는 소정 개수, 예를 들어 16개의 프레임들을 기초로 산출되므로, 여기서의 프레임별 유사도는, 최초의 16번째 프레임부터 마지막 프레임까지의 매 프레임마다의 유사도이다. 도 7은 본 발명의 일 실시예에 따른 프레임별로 유사도를 표시하며 영상을 재생하는 예를 나타낸 도면이다. 도 7에 도시된 바와 같이, 프레임별 유사도가 그래프로 표시되고, 사용자가 특정 프레임 위치를 선택할 경우, 그 선택된 프레임 위치에 해당하는 레퍼런스 영상과 사용자 영상이 동시에 재생된다. 이를 통해 사용자는 전 구간 에 걸쳐 레퍼런스 영상 속의 동작과 자신의 동작 간의 유사도를 한눈에 파악할 수 있으며 영상을 통해 동작의 차이를 확인할 수 있다. 일 실시예에서, 제공부는, 레퍼런스 영상의 시계열 단위 모션 벡터들과 사용자 영상의 시계열 단위 모션 벡터들 간의 거리가 최소화되도록 매칭하고, 서로 매칭된 프레임들의 시간차를 기초로 박자 평가 정보를 제공할 수 있다. 구체적으로, 제공부는, 레퍼런스 영상의 시계열 단위 모션 벡터들과, 사용자 영상의 시계열 단위 모션 벡터들 간에 DTW(Dynamic Time Warping) 알고리즘을 적용하여, 패스(path) 매칭을 수행한다. DTW는 길이와 속도가 다른 두 개의 시계열 데이터가 있을 때, 두 시계열 데이터 간에 거리를 최소화하는 방향으 로 움직이면서 매칭시켜 최적의 매칭 패스를 선정하는 알고리즘이다. 한 프레임씩 이동하며 단위 모션 벡터를 생성할 경우, 각 단위 모션 벡터는 어느 한 프레임에 대응할 수 있고, 따라서, 레퍼런스 영상 및 사용자 영상의 서로 매칭된 단위 모션 벡터에 대응하는 프레임 간의 시간차를 분석할 수 있다. 제공부는, 분석된 시간차 를 기초로, 사용자의 동작이 정박자에 이루어졌는지, 아니면 빠르게 이루어졌는지, 또는 느리게 이루어졌는지 분석할 수 있다. 일 실시예에서, 제공부는, 레퍼런스 영상의 시계열 단위 모션 벡터들과 사용자 영상의 시계열 단위 모션 벡터들 간을 매칭하는데 있어서, 단위 모션 벡터들에 대해 주성분 분석(PCA, Principal Component Analysis)를 수행하여 차원을 축소하여 DTW 알고리즘을 적용할 수 있다. 또한, 제공부는, 레퍼런스 영상 및 사용자 영 상의 서로 매칭된 단위 모션 벡터에 대응하는 프레임 간의 시간차를 분석하는데 있어서, 각 프레임별로 산출된 시간차를 시계열 변화에 따라 그룹핑하고, 각 구간별로 시간차의 평균을 박자 정보로서 제공할 수 있다. 이때, 시간차의 시계열 변화에 따른 그룹핑은, SXA(Symbolic Aggregate A pproximation)를 이용할 수 있다. 또한, 제 공부는, 시간차의 전체 평균을 해당 영상에서의 전체적인 박자 정보로서 제공할 수도 있다. 도 8은 본 발명의 일 실시예에 따른 레퍼런스 영상과 사용자 영상의 패스 매칭 및 시간차의 예를 나타낸 도면이 다. 도 8의 (a)는 레퍼런스 영상의 프레임들과 사용자 영상의 프레임들의 패스 매칭 결과이다. 여기서 숫자는 프레임 인덱스이다. 단위 모션 벡터는 소정 개수, 예를 들어 16개 단위로 생성되므로, 프레임 인덱스 0은 16번 째 프레임을 의미하고, 그 다음 프레임 인덱스들은 16번째 프레임 이후의 프레임들을 지칭할 수 있다. 사용자 영상의 프레임 인덱스를 기준으로 보면, 프레임 인덱스 0부터 6, 그리고 16부터 24는 레퍼런스 영상과 시간차 (Time Interval)가 없다. 그러나 프레임 인덱스 7부터 15는 레퍼런스 영상과 시간차가 존재한다. 도 8의 (b)는 이 시간차를 프레임별로 표시한 그래프이다. 각 프레임별로 산출된 시간차는 시계열 변화에 따라 그룹핑되고,각 구간별로 시간차의 평균이 박자 정보로서 계산된다. 도 8의 (c)는 이러한 구간별 박자 정보를 나타낸다. 시 간차 0은 정박을 나타내고, +값의 시간차는 그 값이 커질수록 정박 대비 박자가 느린 것을 의미하며, -값의 시 간차는 그 값이 커질수록 정박 대비 박자가 빠른 것을 의미한다. 이상에서 설명한 동작 유사도 분석 장치의 추출부 및 생성부는, 미리 학습된 추출 및 생성 모델 인 인공지능 신경망을 이용하여 레퍼런스 영상 및 사용자 영상에서 관절 좌표 및 관절 각도를 추출하고 단위 모 션 벡터를 생성할 수 있다. 인공지능 신경망은 미리 구축된 학습 데이터를 이용하여 학습을 하는데, 학습 데이 터를 구축하는데 있어서, 다양한 각도에서 촬영된 영상들로부터 학습 데이터를 구축한다. 특정 동작의 사람을 촬영하는 카메라의 위치 및 각도에 따라 영상에서 추출되는 관절 좌표 및 관절 각도에 오차가 발생할 수 있다. 따라서, 이러한 오차를 줄이기 위해, 다양한 각도에서 촬영된 영상들로부터 학습 데이터를 구축한다. 도 9는 본 발명의 일 실시예에 따른 카메라의 배치 위치를 나타낸 도면이다. 도 9에 도시된 바와 같이, 총 4대 의 카메라를 설치하여 촬영을 한다. 예를 들어, 사람을 정면으로 바라보는 위치(즉, front view), 좌측에서 바 라보는 위치(즉, left view), 우측에서 바라보는 위치(즉, right view), 사선으로 바라보는 위치(즉, perspective view)에 각각 카메라를 설치한다. 이와 같이 카메라들을 설치한 후, k-pop 100곡을 선정하여 각 곡 마다 한 명의 강사와 다수 학생의 댄스 영상을 획득하고, 이와 같이 획득된 댄스 영상을 이용하여 학습 데이터 를 구축하고 학습을 수행한다. 따라서, 실제 하나의 카메라로 학생의 댄스 영상을 촬영하여 강사 영상과 동작 유사도를 분석하는데 있어서 학생을 촬영하는 카메라의 각도 변화에도 강인한 유사도 분석이 가능해진다. 도 10은 본 발명의 다른 실시예에 따른 동작 유사도 분석 장치의 구성을 나타낸 도면이다. 도 10을 참조한 실시 예에서 도 1을 참조하여 설명한 실시예와 동일한 참조부호의 구성요소는 도 1 내지 도 9를 참조하여 설명한 기 능 및 동작을 모두 포함한다. 생성부에서 생성된 단위 모션 벡터들을 이용하여 유사도를 산출하게 되면, 서로 다른 동작을 유사한 동작으로 평가할 수 있다. 즉, 서로 다른 동작 간의 구분력이 떨어져 의미 있는 유사 도를 도출하기 어려울 수 있다. 특히, 레퍼런스 영상을 촬영한 카메라의 위치 및 각도와, 비교대상이 되는 사용 자 영상을 촬영한 카메라의 위치 및 각도가 상이한 경우, 서로 다른 동작 간의 구분력이 더욱 떨어질 수 있다. 따라서 이러한 카메라의 위치 및 각도 변화에도 강인하며 좀더 구분력 있게 단위 모션 벡터를 변환하여 이용하 는 것이 바람직하다. 이를 위해, 도 10을 참조한 실시예의 동작 유사도 분석 장치는, 변환부를 더 포함한다. 변환부는, 미리 메트릭 학습(metric learning)이 수행된 변환 모델을 이용하여 상기 생성부에서 생 성된 단위 모션 벡터들을 구분력이 좋은 임베딩 벡터(embedding vector)로 변환한다. 변환 모델은 메트릭 학습 기반의 신경망으로서, 동일 특징을 갖는 입력 데이터들은 하이퍼 스페이스 상에서 비스한 거리에 뭉쳐 있을 수 있게 해주고, 다른 특징을 갖는 입력 데이터들은 서로 멀리 떨어지도록 변환하는 신경망이다. 변환 모델의 최종 출력은 하이퍼 스페이스 상에 위치하는 클래스 간에 구분력이 좋은 임베딩 벡터가 된다. 본 실시예에서 상기 메트릭 학습은, 앵커 단위 모션 벡터와 긍정 단위 모션 벡터 간의 거리는 감소하고, 앵커 단위 모션 벡터와 부정 단위 모션 벡터 간의 거리는 증가하도록 하는 유사도 손실 함수를 이용하여 수행된다. 여기서 유사도 손실 함수는 예를 들어, Triplet 손실 함수일 수 있고, 변환 모델의 신경망은 예를 들어 siames neural network일 수 있으며, 학습 데이터로는, 상술한 바와 같은, 다양한 각도에서 동시에 촬영된 다량의 레퍼 런스 영상과 사용자 영상이 이용된다. 도 11은 본 발명의 일 실시예에 따른 triplet 손실 함수 및 신경망 구조를 나타낸 도면이고, 도 12는 본 발명의 일 실시예에 따른 메트릭 학습된 변환 모델의 변환 과정의 개념을 설명하는 도면이다. 도 11에 도시된 바와 같이, 신경망은 세 개의 합성곱 신경망(CNN, Convolutional Neural Network)(1110, 1120, 1130)으로 구성되고, 제1 합성곱 신경망에는 앵커(anchor) 단위 모션 벡터가 입력되어 임베딩 벡터로 변 환되고, 제2 합성곱 신경망에는 긍정(positive) 단위 모션 벡터가 입력되어 임베딩 벡터로 변환되며, 제3 합성곱 신경망에는 부정(negative) 단위 모션 벡터가 입력되어 임베딩 벡터로 변환된다. 여기서 앵커는 레퍼런스 영상의 단위 모션 벡터이고, 긍정은 레퍼런스 영상의 동작과 동일한 동작의 사용자 영상의 단위 모션 벡터이며, 부정은 레퍼런스 영상의 동작과 다른 동작의 사용자 영상의 단위 모션 벡터이다. triplet 손실(loss) 함수에서, 제1 합성곱 신경망의 출력과 제2 합성곱 신경망의 출력의 차 와, 제1 합성곱 신경망의 출력과 제3 합성곱 신경망의 출력의 차의 비율이 최대가 되도록, 합성곱 신경망들(1110, 1120, 1130)이 학습된다. triplet 손실(loss) 함수는, 다음 예와 같다. 여기서, A는 앵커 데이터, P는 긍정 데이터, N은 부정 데이터이며, f(*)는 특징 맵 함수, α는 마진(margin)이 다. 도 11을 참조하여 설명한 신경망 구조로 학습된 변환 모델은, 도 12에 도시된 바와 같이, 앵커 단위 모션 벡터 와 긍정 단위 모션 벡터 간의 거리는 가까워지고, 앵커 단위 모션 벡터와 부정 단위 모션 벡터 간의 거리는 멀 어지도록, 단위 모션 벡터를 임베딩 벡터로 변환하여, 벡터들의 구분력이 좋아지도록 한다. 도 13은 본 발명의 일 실시예에 따른 동작 유사도 분석 방법을 설명하는 흐름도이다. 도 13을 참조하여 설명하 는 방법은, 동작 유사도 분석 장치의 프로세서에 의해 수행될 수 있다. 도 13을 참조하면, 단계 S1301에서, 동작 유사도 분석 장치는, 레퍼런스 영상 및 사용자 영상을 수신하고, 수신된 레퍼런스 영상 및 사용자 영상의 각 프레임에서 관절 좌표 및 관절 각도를 추출한다. 레퍼런스 영상 및 사용자 영상은, 동작 유사도 분석 장치의 내부 저장장치 또는 외부 저장장치로부터 수신될 수 있고, 또는 외부 서버로부터 수신될 수 있다. 일 실시예에서, 레퍼런스 영상은 내부 저장장치에 미리 저장되고, 사용자 영 상은 카메라로부터 수신될 수도 있다. 일 실시예에서, 동작 유사도 분석 장치는, 각 관절 좌표를 0~1 사이 의 값으로 변환하여 정규화할 수 있다. 단계 S1302에서, 동작 유사도 분석 장치는, 상기 레퍼런스 영상 및 상기 사용자 영상 각각에 대해 소정 개 수의 연속된 프레임 단위로 상기 관절 좌표 및 상기 관절 각도를 포함하는 단위 모션 벡터를 생성한다. 예를 들 어, 16개 내지 20개 프레임 단위로 단위 모션 벡터를 생성할 수 있다. 바람직하게, 동작 유사도 분석 장치(10 0)는, 레퍼런스 영상 및 사용자 영상 각각에서 시간 순서에 따라 한 프레임씩 이동하며 단위 모션 벡터들을 생 성할 수 있다. 일 실시예에서, 동작 유사도 분석 장치는, 미리 메트릭 학습(metric learning)이 수행된 변환 모델을 이용 하여 상기 생성된 단위 모션 벡터들을 구분력이 좋은 임베딩 벡터(embedding vector)로 변환할 수 있다. 변환 모델은, 메트릭 학습 기반의 신경망으로서, 동일 특징을 갖는 입력 데이터들은 하이퍼 스페이스 상에서 비스한 거리에 뭉쳐 있을 수 있게 해주고, 다른 특징을 갖는 입력 데이터들은 서로 멀리 떨어지도록 변환하는 신경망이 다. 즉, 본 실시예의 변환 모델은, 앵커 단위 모션 벡터와 긍정 단위 모션 벡터 간의 거리는 감소시키고, 앵커 단위 모션 벡터와 부정 단위 모션 벡터 간의 거리는 증가하도록, 단위 모션 벡터를 변환한다. 단계 S1303에서, 동작 유사도 분석 장치는, 상기 레퍼런스 영상 및 상기 사용자 영상 간의 단위 모션 벡터 들의 비교를 통해 상기 레퍼런스 영상 및 상기 사용자 영상 간의 유사도를 산출한다. 여기서 유사도는, 유클리 디안 거리(Euclidian distance) 및/또는 코사인 유사도(cos similarity)일 수 있다. 동작 유사도 분석 장치 는, 레퍼런스 영상 및 사용자 영상의 각 대응하는 순번의 단위 모션 벡터마다 유사도를 산출할 수 있고, 또는 단위 모션 벡터들의 유사도 전체 평균을 산출할 수도 있다. 단계 S1304에서, 동작 유사도 분석 장치는, 산출된 유사도에 기초하여 평가 정보를 제공한다. 동작 유사도 분석 장치는, 디스플레이 장치를 통해 평가 정보를 사용자에게 제공할 수 있고, 또는 문자 메시지나, 음성, 또는 이메일 등의 다양한 수단을 통해 평가 정보를 사용자에게 제공할 수 있다. 일 실시예에서, 동작 유사도 분석 장치는, 상기 산출된 유사도를, 전문가 평가 점수와 유사도 간의 회귀분 석 상관관계에 기초하여, 소정 비율 점수로 환산하여 제공할 수 있다. 예를 들어, 100점 만점을 기준으로 점수 를 환산하여 제공할 수 있다. 여기서 유사도는 유클리디안 거리 또는 코사인 유사도 중 어느 하나일 수 있고, 또는 유클리디안 거리와 코사인 유사도의 쌍일 수 있다. 일 실시예에서, 동작 유사도 분석 장치는, 영상의 전 구간에 걸쳐 유사도(유클리디안 거리, 또는 코사인 유사도 또는 전문가 평가 점수)를 시계열 변화에 따라 그룹핑하고, 평균 유사도가 가장 높은 구간과 가장 낮은 구간을 각각 베스트/워스트 구간으로 선정하여 제공할 수 있다. 구체적으로, 동작 유사도 분석 장치는, 한 프레임씩 이동하며 산출된 전 구간에 대한 유사도의 값을 시계열 데이터(time series data)에 대한 클러스터링 기법인 SXA(Symbolic Aggregate A pproximation)을 적용하여, 전체 구간에서 유사한 값을 갖는 연속된 구간을 그룹핑하고, 복수의 구간 중에서 평균 유사도가 가장 높은 구간을 베스트 구간으로 그리고 평균 유사도가 가장 낮은 구간을 워스트 구간으로 선정한다. 이때, 평균 유사도가 동일한 복수의 후보 구간이 있을 경우, 구간 길이 가 가장 긴 곳을 베스트 또는 워스트 구간으로 선정한다. 동작 유사도 분석 장치는, 베스트 구간과 워스트 구간에 대한 레퍼런스 영상과 사용자 영상을 함께 디스플레이 장치에 재생할 수 있다.일 실시예에서, 동작 유사도 분석 장치는, 프레임별로 유사도를 그래프로 표시하며 이에 대응하는 레퍼런 스 영상 및 사용자 영상을 동시에 재생할 수 있다. 앞서 설명한 바와 같이, 한 프레임씩 이동하며 유사도가 산 출되고, 각 유사도는 소정 개수, 예를 들어 16개의 프레임들을 기초로 산출되므로, 여기서의 프레임별 유사도는, 최초의 16번째 프레임부터 마지막 프레임까지의 매 프레임마다의 유사도이다. 일 실시예에서, 동작 유사도 분석 장치는, 레퍼런스 영상의 시계열 단위 모션 벡터들과 사용자 영상의 시 계열 단위 모션 벡터들 간의 거리가 최소화되도록 매칭하고, 서로 매칭된 프레임들의 시간차를 기초로 박자 평 가 정보를 제공할 수 있다. 구체적으로, 동작 유사도 분석 장치는, 레퍼런스 영상의 시계열 단위 모션 벡 터들과, 사용자 영상의 시계열 단위 모션 벡터들 간에 DTW(Dynamic Time Warping) 알고리즘을 적용하여, 패스 (path) 매칭을 수행한다. 동작 유사도 분석 장치는, 레퍼런스 영상 및 사용자 영상의 서로 매칭된 단위 모 션 벡터에 대응하는 프레임 간의 시간차를 분석하고, 분석된 시간차를 기초로, 사용자의 동작이 정박자에 이루 어졌는지, 아니면 빠르게 이루어졌는지, 또는 느리게 이루어졌는지 분석할 수 있다. 일 실시예에서, 동작 유사도 분석 장치는, 레퍼런스 영상의 시계열 단위 모션 벡터들과 사용자 영상의 시 계열 단위 모션 벡터들 간을 매칭하는데 있어서, 단위 모션 벡터들에 대해 주성분 분석(PCA, Principal Component Analysis)를 수행하여 차원을 축소하여 DTW 알고리즘을 적용할 수 있다. 또한, 동작 유사도 분석 장 치는, 레퍼런스 영상 및 사용자 영상의 서로 매칭된 단위 모션 벡터에 대응하는 프레임 간의 시간차를 분 석하는데 있어서, 각 프레임별로 산출된 시간차를 시계열 변화에 따라 그룹핑하고, 각 구간별로 시간차의 평균 을 박자 정보로서 제공할 수 있다. 이때, 시간차의 시계열 변화에 따른 그룹핑은, SXA(Symbolic Aggregate A pproximation)를 이용할 수 있다. 또한, 동작 유사도 분석 장치는, 시간차의 전체 평균을 해당 영상에서의 전체적인 박자 정보로서 제공할 수도 있다. 본 명세서는 많은 특징을 포함하는 반면, 그러한 특징은 본 발명의 범위 또는 특허청구범위를 제한하는 것으로 해석되어서는 안 된다. 또한, 본 명세서에서 개별적인 실시예에서 설명된 특징들은 단일 실시예에서 결합되어 구현될 수 있다. 반대로, 본 명세서에서 단일 실시예에서 설명된 다양한 특징들은 개별적으로 다양한 실시예에 서 구현되거나, 적절히 결합되어 구현될 수 있다. 도면에서 동작들이 특정한 순서로 설명되었으나, 그러한 동작들이 도시된 바와 같은 특정한 순서로 수행되는 것으로, 또는 일련의 연속된 순서, 또는 원하는 결과를 얻기 위해 모든 설명된 동작이 수행되는 것으로 이해되어 서는 안 된다. 특정 환경에서 멀티태스킹 및 병렬 프로세싱이 유리할 수 있다. 아울러, 상술한 실시예에서 다양 한 시스템 구성요소의 구분은 모든 실시예에서 그러한 구분을 요구하지 않는 것으로 이해되어야 한다. 상술한 프로그램 구성요소 및 시스템은 일반적으로 단일 소프트웨어 제품 또는 멀티플 소프트웨어 제품에 패키지로 구 현될 수 있다. 상술한 바와 같은 본 발명의 방법은 프로그램으로 구현되어 컴퓨터로 읽을 수 있는 형태로 기록매체(시디롬, 램, 롬, 플로피 디스크, 하드 디스크, 광자기 디스크 등)에 저장될 수 있다. 이러한 과정은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있으므로 더 이상 상세히 설명하지 않기로 한다."}
{"patent_id": "10-2021-0174256", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상에서 설명한 본 발명은, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 있어 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경이 가능하므로 전술한 실시예 및 첨부된 도면 에 의해 한정되는 것이 아니다."}
{"patent_id": "10-2021-0174256", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 동작 유사도 분석 장치의 구성을 나타낸 도면이다. 도 2는 본 발명의 일 실시예에 따른 인체의 관절 좌표 및 관절 각도를 나타낸 도면이다. 도 3은 본 발명의 일 실시예에 따른 연속된 프레임으로 구성되는 단위 모션 벡터를 나타낸 도면이다. 도 4는 본 발명의 다른 실시예에 따른 연속된 프레임으로 구성되는 단위 모션 벡터를 나타낸 도면이다. 도 5는 본 발명의 일 실시예에 따른 유사도와 전문가 평가 점수 간의 회귀분석 상관관계를 학습하는 과정을 설 명하는 도면이다. 도 6은 본 발명의 일 실시예에 따른 영상의 전체 구간에서 베스트/워스트 구간을 나타낸 도면이다. 도 7은 본 발명의 일 실시예에 따른 프레임별로 유사도를 표시하며 영상을 재생하는 예를 나타낸 도면이다. 도 8은 본 발명의 일 실시예에 따른 레퍼런스 영상과 사용자 영상의 패스 매칭 및 시간차의 예를 나타낸 도면이 다. 도 9는 본 발명의 일 실시예에 따른 카메라의 배치 위치를 나타낸 도면이다. 도 10은 본 발명의 다른 실시예에 따른 동작 유사도 분석 장치의 구성을 나타낸 도면이다. 도 11은 본 발명의 일 실시예에 따른 triplet 손실 함수 및 신경망 구조를 나타낸 도면이다. 도 12는 본 발명의 일 실시예에 따른 메트릭 학습된 변환 모델의 변환 과정의 개념을 설명하는 도면이다. 도 13은 본 발명의 일 실시예에 따른 동작 유사도 분석 방법을 설명하는 흐름도이다."}
