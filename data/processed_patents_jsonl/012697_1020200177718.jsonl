{"patent_id": "10-2020-0177718", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0057389", "출원번호": "10-2020-0177718", "발명의 명칭": "행동 인식 장치 및 방법", "출원인": "주식회사 딥비전스", "발명자": "민진홍"}}
{"patent_id": "10-2020-0177718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 프로세서들, 및상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치이고, 입력 영상에서 기 설정된 종류의 오브젝트를 인식하고, 인식된 오브젝트에 대해 화이트 마스크 이미지를 생성하는 마스크 이미지 생성 모듈;상기 입력 영상과 상기 화이트 마스크 이미지를 합성하여 영상 합성 이미지를 생성하는 영상 합성 모듈; 및상기 영상 합성 이미지를 입력으로 하여 상기 오브젝트의 행동을 인식하는 행동 인식 모듈을 포함하는, 행동 인식 장치."}
{"patent_id": "10-2020-0177718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 마스크 이미지 생성 모듈은, 상기 입력 영상에서 기 설정된 종류의 오브젝트를 분류하여 인식하고, 인식된 오브젝트의 경계 영역을 검출하도록 학습되는 제1 인공 신경망 모델을 포함하는, 행동 인식 장치."}
{"patent_id": "10-2020-0177718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서, 상기 마스크 이미지 생성 모듈은, 상기 오브젝트의 경계 영역에서 기 설정된 부분까지 확장된 오브젝트 연장 경계 영역을 설정하고, 상기 오브젝트 연장 경계 영역 내의 픽셀 값은 화이트가 되게 하고, 상기 오브젝트 연장 경계 영역 이외의 픽셀 값은 블랙이 되도록 하여 상기 화이트 마스크 이미지를 생성하는, 행동 인식 장치."}
{"patent_id": "10-2020-0177718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 상기 마스크 이미지 생성 모듈은, 상기 오브젝트의 경계 영역의 중심에서 상기 오브젝트의 각 경계까지의 거리인 경계 거리를 산출하고, 상기 오브젝트의 경계 영역의 중심에서 상기 산출된 경계 거리보다 기 설정된 거리만큼 연장된 연장 경계 거리를 산출하며, 상기 연장 경계 거리에 기반하여 상기 오브젝트의 연장 경계를 설정하는, 행동 인식 장치."}
{"patent_id": "10-2020-0177718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 3에 있어서, 상기 영상 합성 모듈은, 공개특허 10-2022-0057389-3-상기 입력 영상과 상기 화이트 마스크 이미지를 AND 연산하여 영상 합성 이미지를 생성하는, 행동 인식 장치."}
{"patent_id": "10-2020-0177718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 3에 있어서, 상기 행동 인식 모듈은, 상기 영상 합성 이미지에서 상기 오브젝트의 행동을 인식하도록 학습되는 제2 인공 신경망 모델을 포함하는, 행동 인식 장치."}
{"patent_id": "10-2020-0177718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서, 상기 제2 인공 신경망 모델은, 상기 영상 합성 이미지를 입력으로 하고, 상기 영상 합성 이미지에서 시공간 특징 벡터를 추출하는 하나 이상의특징 추출 계층;상기 특징 추출 계층과 연결되고, 상기 특징 추출 계층에서 출력되는 시공간 특징 벡터에 풀링(Pooling) 연산을수행하는 풀링 층; 및상기 풀링 층과 연결되고, 상기 풀링 층에서 출력되는 시공간 특징 벡터를 기반으로 상기 오브젝트의 행동에 대한 분류 값을 출력하는 완전 연결층을 포함하는, 행동 인식 장치."}
{"patent_id": "10-2020-0177718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서, 상기 특징 추출 계층은, 기 설정된 제1 필터를 통해 상기 영상 합성 이미지에서 공간적인 특징의 공간 특징 벡터를 추출하는 제1 컨벌루션층; 및상기 제1 컨벌루션층에 연결되고, 기 설정된 제2 필터를 통해 상기 공간 특징 벡터에서 시간적인 특징을 추출하여 상기 영상 합성 이미지에 대한 시공간 특징 벡터를 출력하는 제2 컨벌루션층을 포함하는, 행동 인식 장치."}
{"patent_id": "10-2020-0177718", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "하나 이상의 프로세서들, 및상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되는 방법으로서, 입력 영상에서 기 설정된 종류의 오브젝트를 인식하고, 인식된 오브젝트에 대해 화이트 마스크 이미지를 생성하는 동작;상기 입력 영상과 상기 화이트 마스크 이미지를 합성하여 영상 합성 이미지를 생성하는 동작; 및상기 영상 합성 이미지를 입력으로 하여 상기 오브젝트의 행동을 인식하는 동작을 포함하는, 행동 인식 방법."}
{"patent_id": "10-2020-0177718", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "행동 인식 장치 및 방법이 개시된다. 개시되는 일 실시예에 따른 행동 인식 장치는, 하나 이상의 프로세서들, 및 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치이고, 입력 영상에서 기 설정된 종류의 오브젝트를 인식하고, 인식된 오브젝트에 대해 화이트 마스크 이미지를 생성하 는 마스크 이미지 생성 모듈, 입력 영상과 화이트 마스크 이미지를 합성하여 영상 합성 이미지를 생성하는 영상 합성 모듈, 및 영상 합성 이미지를 입력으로 하여 오브젝트의 행동을 인식하는 행동 인식 모듈을 포함한다."}
{"patent_id": "10-2020-0177718", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 행동 인식 기술과 관련된다."}
{"patent_id": "10-2020-0177718", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 지능형 비디오 감시 시스템 등과 같은 보안 관련 분야나 인간과의 상호 교류 수행 능력을 지는 지능형 로 봇 또는 가전 제품 등의 분야에서 인간의 행동 인식 기술이 적용되고 있다. 기존의 행동 인식 기술은 영상 RGB 데이터를 기반으로 추가적인 장치를 이용하여 기술에 대한 성능을 높이는 방식을 사용하였다. 이 경우, 행동 인 식에 많은 시간과 노력이 소모되게 된다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허공보 제10-1023951호(2011.03.28)"}
{"patent_id": "10-2020-0177718", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시되는 실시예는 새로운 기법의 인공 지능 기반의 행동 인식 기술을 제공하기 위한 것이다."}
{"patent_id": "10-2020-0177718", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "개시되는 일 실시예에 따른 행동 인식 장치는, 하나 이상의 프로세서들, 및 상기 하나 이상의 프로세서들에 의 해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치이고, 입력 영상에서 기 설정된 종류의 오브젝트를 인식하고, 인식된 오브젝트에 대해 화이트 마스크 이미지를 생성하는 마스크 이미지 생성 모 듈; 상기 입력 영상과 상기 화이트 마스크 이미지를 합성하여 영상 합성 이미지를 생성하는 영상 합성 모듈; 및 상기 영상 합성 이미지를 입력으로 하여 상기 오브젝트의 행동을 인식하는 행동 인식 모듈을 포함한다. 상기 마스크 이미지 생성 모듈은, 상기 입력 영상에서 기 설정된 종류의 오브젝트를 분류하여 인식하고, 인식된 오브젝트의 경계 영역을 검출하도록 학습되는 제1 인공 신경망 모델을 포함할 수 있다. 상기 마스크 이미지 생성 모듈은, 상기 오브젝트의 경계 영역에서 기 설정된 부분까지 확장된 오브젝트 연장 경 계 영역을 설정하고, 상기 오브젝트 연장 경계 영역 내의 픽셀 값은 화이트가 되게 하고, 상기 오브젝트 연장 경계 영역 이외의 픽셀 값은 블랙이 되도록 하여 상기 화이트 마스크 이미지를 생성할 수 있다. 상기 마스크 이미지 생성 모듈은, 상기 오브젝트의 경계 영역의 중심에서 상기 오브젝트의 각 경계까지의 거리 인 경계 거리를 산출하고, 상기 오브젝트의 경계 영역의 중심에서 상기 산출된 경계 거리보다 기 설정된 거리만 큼 연장된 연장 경계 거리를 산출하며, 상기 연장 경계 거리에 기반하여 상기 오브젝트의 연장 경계를 설정할 수 있다. 상기 영상 합성 모듈은, 상기 입력 영상과 상기 화이트 마스크 이미지를 AND 연산하여 영상 합성 이미지를 생성 할 수 있다. 상기 행동 인식 모듈은, 상기 영상 합성 이미지에서 상기 오브젝트의 행동을 인식하도록 학습되는 제2 인공 신 경망 모델을 포함할 수 있다. 상기 제2 인공 신경망 모델은, 상기 영상 합성 이미지를 입력으로 하고, 상기 영상 합성 이미지에서 시공간 특 징 벡터를 추출하는 하나 이상의 특징 추출 계층; 상기 특징 추출 계층과 연결되고, 상기 특징 추출 계층에서 출력되는 시공간 특징 벡터에 풀링(Pooling) 연산을 수행하는 풀링 층; 및 상기 풀링 층과 연결되고, 상기 풀링 층에서 출력되는 시공간 특징 벡터를 기반으로 상기 오브젝트의 행동에 대한 분류 값을 출력하는 완전 연결층을 포함할 수 있다.상기 특징 추출 계층은, 기 설정된 제1 필터를 통해 상기 영상 합성 이미지에서 공간적인 특징의 공간 특징 벡 터를 추출하는 제1 컨벌루션층; 및 상기 제1 컨벌루션층에 연결되고, 기 설정된 제2 필터를 통해 상기 공간 특 징 벡터에서 시간적인 특징을 추출하여 상기 영상 합성 이미지에 대한 시공간 특징 벡터를 출력하는 제2 컨벌루 션층을 포함할 수 있다. 개시되는 일 실시예에 따른 행동 인식 방법은, 하나 이상의 프로세서들, 및 상기 하나 이상의 프로세서들에 의 해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되는 방법으로서, 입력 영상에서 기 설정된 종류의 오브젝트를 인식하고, 인식된 오브젝트에 대해 화이트 마스크 이미지를 생성하는 동 작; 상기 입력 영상과 상기 화이트 마스크 이미지를 합성하여 영상 합성 이미지를 생성하는 동작; 및 상기 영상 합성 이미지를 입력으로 하여 상기 오브젝트의 행동을 인식하는 동작을 포함한다."}
{"patent_id": "10-2020-0177718", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시되는 실시예에 의하면, 입력 영상을 기반으로 화이트 마스크 이미지를 생성하고, 입력 영상과 화이트 마스 크 이미지를 합성하여 영상 합성 이미지를 생성하며, 영상 합성 이미지로부터 오브젝트의 행동을 분류함으로써, 별도의 추가 장치 없이 입력 영상만으로 입력 영상 내에 포함된 오브젝트의 행동을 용이하게 분류할 수 있게 된 다."}
{"patent_id": "10-2020-0177718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 구체적인 실시형태를 설명하기로 한다. 이하의 상세한 설명은 본 명세서에서 기술된 방법, 장치 및/또는 시스템에 대한 포괄적인 이해를 돕기 위해 제공된다. 그러나 이는 예시에 불과하며 본 발명은 이에 제한되지 않는다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다. 이하의 설명에 있어서, 신호 또는 정보의 \"전송\", \"통신\", \"송신\", \"수신\" 기타 이와 유사한 의미의 용어는 일 구성요소에서 다른 구성요소로 신호 또는 정보가 직접 전달되는 것뿐만이 아니라 다른 구성요소를 거쳐 전달되 는 것도 포함한다. 특히 신호 또는 정보를 일 구성요소로 \"전송\" 또는 \"송신\"한다는 것은 그 신호 또는 정보의 최종 목적지를 지시하는 것이고 직접적인 목적지를 의미하는 것이 아니다. 이는 신호 또는 정보의 \"수신\"에 있 어서도 동일하다. 또한 본 명세서에 있어서, 2 이상의 데이터 또는 정보가 \"관련\"된다는 것은 하나의 데이터(또 는 정보)를 획득하면, 그에 기초하여 다른 데이터(또는 정보)의 적어도 일부를 획득할 수 있음을 의미한다. 또한, 제1, 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로 사용될 수 있다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성 요소는 제2 구성 요소로 명 명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 도 1은 본 발명의 일 실시예에 따른 인공 지능 기반의 행동 인식 장치를 나타낸 도면이다. 도 1을 참조하면, 행동 인식 장치는 마스크 이미지 생성 모듈, 영상 합성 모듈, 및 행동 인식 모듈을 포함할 수 있다. 행동 인식 장치는 입력되는 영상에서 특정 오브젝트(예를 들어, 사람 또는 동물 등)가 어떤 행동을 하고 있는지를 인식하기 위한 컴퓨팅 장치일 수 있다. 일 실시예에서, 마스크 이미지 생성 모듈, 영상 합성 모듈, 및 행동 인식 모듈은 물리적으로 구 분된 하나 이상의 장치를 이용하여 구현되거나, 하나 이상의 프로세서 또는 하나 이상의 프로세서 및 소프트웨 어의 결합에 의해 구현될 수 있으며, 도시된 예와 달리 구체적 동작에 있어 명확히 구분되지 않을 수 있다. 마스크 이미지 생성 모듈은 입력되는 영상에서 기 설정된 종류의 오브젝트를 인식하고, 인식된 오브젝트 부분에 마스크(Mask)를 형성한 마스크 이미지를 생성할 수 있다. 도 2는 본 발명의 일 실시예에 따른 마스크 이미지 생성 모듈의 구성을 나타낸 블록도이다. 도 2를 참조하 면, 마스크 이미지 생성 모듈은 영상 전처리부, 오브젝트 인식부, 및 마스크 형성부를 포 함할 수 있다. 영상 전처리부는 영상을 입력 받을 수 있다. 여기서, 영상은 RGB 영상일 수 있으나, 이에 한정되는 것은 아니다. 예시적인 실시예에서, 영상은 영상 프레임 단위로 입력될 수 있으나, 이에 한정되는 것은 아니며 기 설 정된 시간 단위로 입력될 수도 있다. 영상 전처리부는 입력되는 영상을 기 설정된 제1 크기로 리사이징 할 수 있다. 예를 들어, 영상 전처리부는 입력되는 영상을 1024×1024의 크기로 리사이징 할 수 있으나, 리사 이징 하는 크기가 이에 한정되는 것은 아니다. 오브젝트 인식부는 영상에서 기 설정된 종류의 오브젝트(예를 들어, 사람 또는 동물 등)를 인식할 수 있다. 예시적인 실시예에서, 오브젝트 인식부는 영상에서 기 설정된 종류의 오브젝트 부분을 분할 (Segmentation) 하도록 학습되는 제1 인공 신경망 모델(113a)을 포함할 수 있다. 여기서, 제1 인공 신경망 모델 은 Mask R-CNN(Convolutional Neural Network) 모델일 수 있으나, 이에 한정되는 것은 아니다. 제1 인공 신경망 모델(113a)은 입력되는 영상에서 기 설정된 종류의 오브젝트를 분류(Classification)하여 인식 하고 인식된 오브젝트의 영역을 검출하도록 학습될 수 있다. 이때, 제1 인공 신경망 모델(113a)은 인식된 오브 젝트를 포함하는 영역에서 이중선형 보간법(Bilinear Interpolation)을 통해 인식된 오브젝트의 경계로 이루어 지는 영역(오브젝트 경계 영역)을 예측하도록 학습될 수 있다. 마스크 형성부는 영상 내 오브젝트 경계 영역에 마스크(Mask)를 형성할 수 있다. 예시적인 실시예에서, 마 스크 형성부는 영상 내 오브젝트 경계 영역이 화이트로 이루어지고, 영상 내 그 이외의 영역이 블랙으로 이루어진 화이트 마스크 이미지를 생성할 수 있다. 즉, 마스크 형성부는 영상 내 오브젝트 경계 영역의 픽 셀 값은 (255, 255, 255)로 하여 화이트가 되도록 하고, 영상 내 그 이외의 영역의 픽셀 값은 (0, 0, 0)로 하여 블랙이 되도록 하여 화이트 마스크 이미지를 생성할 수 있다. 이때, 마스크 형성부는 오브젝트 인식부에서 검출된 오브젝트 경계 영역을 확장하여 화이트 마스크 이미지를 생성할 수 있다. 즉, 마스크 형성부는 영상에서 화이트 부분(픽셀 값이 (255, 255, 255)인 부 분)이 오브젝트 인식부에서 검출된 오브젝트 경계 영역에만 있는 것이 아니라, 오브젝트 경계 영역을 벗어 나서 오브젝트 경계 영역의 주변까지 화이트 부분으로 형성한 화이트 마스크 이미지를 생성할 수 있다. 구체적으로, 마스크 형성부는 오브젝트 인식부에서 검출된 오브젝트 경계 영역의 중심에서 오브젝트 의 각 경계까지의 거리인 경계 거리를 산출할 수 있다. 마스크 형성부는 검출된 오브젝트 경계 영역의 중 심에서 경계 거리 보다 연장된 연장 경계 거리에 연장 경계를 설정할 수 있다. 예를 들어, 연장 경계 거리는 경 계 거리의 1.2배의 거리일 수 있으나, 이에 한정되는 것은 아니다. 마스크 형성부는 연장 경계로 이루어지 는 오브젝트 연장 경계 영역의 픽셀 값을 (255, 255, 255)로 하여 화이트가 되게 하고, 그 이외의 영역의 픽셀 값을 (0, 0, 0)로 하여 블랙이 되도록 함으로써, 오브젝트 경계 영역을 벗어나서 오브젝트 경계 영역의 주변까 지 화이트 부분으로 형성한 화이트 마스크 이미지를 생성할 수 있다. 도 3은 개시되는 일 실시예에 따른 마스크 이미지 생성 모듈이 입력 영상으로부터 화이트 마스크 이미지를 생성하는 상태를 나타낸 도면이다. 영상 합성 모듈은 입력 영상과 마스크 형성부에서 출력되는 화이트 마스크 이미지를 합성하여 영상 합성 이미지를 생성할 수 있다. 즉, 영상 합성 모듈은 마스크 이미지 생성 모듈로 입력된 영상과 마 스크 이미지 생성 모듈에서 출력되는 화이트 마스크 이미지를 합성하여 영상 합성 이미지를 생성할 수 있 다. 예시적인 실시예에서, 영상 합성 모듈은 영상 프레임 마다 입력 영상과 화이트 마스크 이미지를 합성 할 수 있다. 영상 합성 모듈은 입력되는 영상과 화이트 마스크 이미지를 AND 연산하여 합성할 수 있다. 이 경우, 입력 되는 영상에서 화이트 영역(즉, 픽셀 값이 (255, 255, 255)인 영역으로, 오브젝트 연장 경계 영역)만 남게 되고 그 이외의 영역(즉, 픽셀 값이 (0, 0, 0)인 영역)은 사라지게 된다. 도 4는 개시되는 일 실시예에 따른 영상 합성 모듈이 입력 영상과 화이트 마스크 이미지를 합성하여 영상 합성 이미지를 생성하는 상태를 나타낸 도면이다. 행동 인식 모듈은 영상 합성 모듈에서 출력되는 영상 합성 이미지를 기반으로 해당 오브젝트의 행동 을 인식할 수 있다. 여기서 영상 합성 이미지는 입력 영상과 화이트 마스크 이미지가 합성된 이미지이므로, 해 당 오브젝트 및 그 주변의 배경 정보만 있는 형태이기 때문에 이를 기반으로 오브젝트의 행동을 인식하게 되면 인식 성능을 보다 향상시킬 수 있게 된다. 도 5는 본 발명의 일 실시예에 따른 행동 인식 모듈의 구성을 나타낸 블록도이다. 도 5를 참조하면, 행동 인식 모듈은 영상 전처리부 및 행동 인식부를 포함할 수 있다. 영상 전처리부는 영상 합성 모듈로부터 영상 합성 이미지를 입력 받을 수 있다. 영상 전처리부 는 영상 합성 이미지를 기 설정된 제2 크기로 리사이징 할 수 있다. 여기서, 제2 크기는 제1 크기보다 작은 크 기일 수 있다. 예를 들어, 영상 전처리부는 영상 합성 이미지를 128×171의 크기로 리사이징 할 수 있으나, 리사이징 하는 크기가 이에 한정되는 것은 아니다. 영상 전처리부는 리사이징 된 영상 합성 이미지를 기 설정된 제3 크기로 조정할 수 있다. 여기서, 제3 크 기는 제2 크기보다 작은 크기일 수 있다. 영상 전처리부는 리사이징 된 영상 합성 이미지를 크로핑 (Cropping)하여 제3 크기로 조정할 수 있다. 예시적인 실시예에서, 영상 전처리부는 리사이징 된 영상 합 성 이미지를 112×112의 크기가 되도록 크로핑 할 수 있으나, 제3 크기가 이에 한정되는 것은 아니다. 예를 들어, 행동 인식부의 학습 단계에서, 영상 전처리부는 영상 합성 이미지의 무작위 부분을 크로 핑하여 제3 크기로 조정할 수 있다. 또한, 행동 인식부의 예측 단계에서, 영상 전처리부는 영상 합성 이미지의 중심을 기준으로 크로핑하여 제3 크기로 조정할 수 있다. 또한, 행동 인식부의 학습 단계에서, 영상 전처리부는 제3 크기로 조정된 영상 합성 이미지를 반전 (Flip) 시킬 수 있다. 예를 들어, 영상 전처리부는 제3 크기로 조정된 합성 이미지를 무작위한 방향으로 반전(Random Flip)시켜 행동 인식부로 출력할 수 있다. 한편, 행동 인식부의 예측 단계에서, 영상 전 처리부는 제3 크기로 조정된 영상 합성 이미지를 반전시키지 않고 행동 인식부로 출력할 수 있다. 행동 인식부는 영상 전처리부에서 출력되는 영상 합성 이미지를 기반으로 오브젝트의 행동을 인식할 수 있다. 예시적인 실시예에서, 행동 인식부는 영상 합성 이미지에서 오브젝트의 행동을 인식하도록 학습 되는 제2 인공 신경망 모델(123a)을 포함할 수 있다. 도 6은 본 발명의 일 실시예에 따른 제2 인공 신경망 모델(123a)의 구조를 개략적으로 나타낸 도면이다. 도 6을 참조하면, 제2 인공 신경망 모델(123a)은 하나 이상의 특징 추출 계층, 풀링 층, 및 완전 연결층 을 포함할 수 있다. 특징 추출 계층은 제1 컨벌루션층(131a), 정규화 층(131b), 활성화 함수층(131c), 및 제2 컨벌루션층 (131d)을 포함할 수 있다. 예시적인 실시예에서, 특징 추출 계층은 복수 개가 순차적으로 연결되어 마련될 수 있다. 제1 컨벌루션층(131a)은 영상 합성 이미지에서 공간적인 특징을 추출하도록 마련될 수 있다. 예를 들어, 제1 컨 벌루션층(131a)은 기 설정된 제1 필터를 일정 간격으로 이동시키면서 영상 합성 이미지에서 공간적인 특징을 추 출할 수 있다. 제1 필터는 (영상 프레임 개수, 시간 길이, 너비, 높이)의 크기를 가질 수 있다. 제1 필터는 영상 합성 이미지에서 공간적인 특징을 추출하기 위한 필터로서, 상기 시간 길이는 1로 고정될 수 있다. 상기 너비 및 높이는 영상 프레임의 너비 및 높이를 의미한다. 제1 컨벌루션층(131a)은 제1 필터를 통해 영상 합성 이미지에서 공간적인 특징을 가지는 특징 벡터(공간 특징 벡터)를 추출할 수 있다. 정규화 층(131b)은 제1 컨벌루션층(131a)에서 출력하는 특징 벡터 값을 정규화 할 수 있다. 활성화 함수층 (131c)은 정규화된 특징 벡터를 제2 컨벌루션층(131d)으로 전달하기 위한 레이어이다. 활성화 함수층(131c)은 시그모이드 함수(Sigmoid Function) 또는 ReLU 등과 같은 활성화 함수를 포함할 수 있다. 제2 컨벌루션층(131d)은 영상 합성 이미지에서 시간적인 특징을 추출하도록 마련될 수 있다. 여기서, 특징 추출 계층은 제1 컨벌루션층(131a), 정규화 층(131b), 활성화 함수층(131c), 및 제2 컨벌루션층(131d)이 순차적 으로 형성되는 바, 제2 컨벌루션층(131d)은 제1 컨벌루션층(131a)에서 출력되어 정규화 층(131b) 및 활성화 함 수층(131c)을 통과한 공간 특징 벡터에서 시간적인 특징을 추출할 수 있다. 제2 컨벌루션층(131d)은 제2 필터를 이용하여 공간 특징 벡터에서 시간적인 특징을 추출할 수 있다. 즉, 제2 컨 벌루션층(131d)은 공간 특징 벡터에서 시간적인 특징을 추출함으로써, 영상 합성 이미지에서 공간적 특징 및 시 간적 특징을 가지는 특징 벡터(시공간 특징 벡터)를 출력하게 된다. 제2 필터는 (필터 계수(M), 시간 길이, 너비, 높이)의 크기를 가질 수 있다. 제2 필터는 공간 특징 벡터에서 시 간적인 특징을 추출하기 위한 필터로서, 상기 너비 및 높이는 1로 고정될 수 있다. 그리고 필터 계수(M)은 하기 의 수학식을 통해 표현될 수 있다. (수학식)"}
{"patent_id": "10-2020-0177718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "N : 영상 프레임의 개수 Ni : i 번째 영상 프레임 Ni-1 : i-1 번째 영상 프레임 Mi : i 번째 영상 프레임의 필터 계수 t : 시간 길이 d : 영상 프레임의 너비 및 높이(너비 및 높이가 동일한 경우) 이와 같이, 제1 컨벌루션층(131a) 및 제2 컨벌루션층(131d)을 통해 공간적 특징과 시간적 특징을 구분하여 추출 함으로써 시공간 특징 벡터의 비선형성을 증가시킬 수 있게 된다. 풀링 층은 마지막 특징 추출 계층에서 출력되는 시공간 특징 벡터에 대해 풀링(Pooling) 연산을 수행 할 수 있다. 예시적인 실시예에서, 풀링 층은 시공간 특징 벡터에 대해 Average Pooling 연산을 수행할 수 있으나, 이에 한정되는 것은 아니며 Max Pooling 연산을 수행할 수도 있다. 완전 연결(Fully-Connected)층은 풀링 층을 통과한 시공간 특징 벡터를 기반으로 오브젝트의 행동을 분류할 수 있다. 완전 연결층은 오브젝트의 행동에 대한 분류 값을 출력할 수 있다. 제2 인공 신경망 모델 (123a)의 학습 과정에서 영상 합성 이미지와 함께 오브젝트의 행동에 대한 정답 값이 입력될 수 있다. 그러면, 완전 연결층은 풀링 층을 통과한 시공간 특징 벡터를 기반으로 오브젝트의 행동이 어떤 행동인지를 분류할 수 있게 된다. 개시되는 실시예에 의하면, 입력 영상을 기반으로 화이트 마스크 이미지를 생성하고, 입력 영상과 화이트 마스 크 이미지를 합성하여 영상 합성 이미지를 생성하며, 영상 합성 이미지로부터 오브젝트의 행동을 분류함으로써, 별도의 추가 장치 없이 입력 영상만으로 입력 영상 내에 포함된 오브젝트의 행동을 용이하게 분류할 수 있게 된 다. 본 명세서에서 모듈이라 함은, 본 발명의 기술적 사상을 수행하기 위한 하드웨어 및 상기 하드웨어를 구동하기 위한 소프트웨어의 기능적, 구조적 결합을 의미할 수 있다. 예컨대, 상기 \"모듈\"은 소정의 코드와 상기 소정의 코드가 수행되기 위한 하드웨어 리소스의 논리적인 단위를 의미할 수 있으며, 반드시 물리적으로 연결된 코드를 의미하거나, 한 종류의 하드웨어를 의미하는 것은 아니다. 도 7은 본 발명의 일 실시예에 따른 인공 지능 기반의 행동 인식 방법을 설명하기 위한 흐름도이다. 도시된 흐 름도에서는 상기 방법을 복수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되 거나, 다른 단계와 결합되어 함께 수행되거나, 생략되거나, 세부 단계들로 나뉘어 수행되거나, 또는 도시되지 않은 하나 이상의 단계가 부가되어 수행될 수 있다. 도 7을 참조하면, 행동 인식 장치는 입력되는 영상에서 기 설정된 종류의 오브젝트를 분류하여 인식하고 인식된 오브젝트의 경계 영역을 검출한다(S 101). 여기서, 행동 인식 장치는 입력되는 영상을 기 설정된 제1 크기로 리사이징 하고, 리사이징 된 입력 영상을 제1 인공 신경망 모델(113a)로 입력하여 오브젝트 경계 영 역을 검출할 수 있다. 다음으로, 행동 인식 장치는 검출된 오브젝트 경계 영역을 확장하여 화이트 마스크 이미지를 생성한다(S 103). 행동 인식 장치는 검출된 오브젝트 경계 영역의 중심에서 오브젝트의 각 경계까지의 거리인 경계 거 리 보다 연장된 연장 경계 거리에 연장 경계를 설정하고, 설정된 연장 경계에 기반하여 화이트 마스크 이미지를 생성할 수 있다. 다음으로, 행동 인식 장치는 입력 영상과 화이트 마스크 이미지를 합성하여 영상 합성 이미지를 생성한다 (S 105). 행동 인식 장치는 입력 영상과 화이트 마스크 이미지를 AND 연산하여 합성할 수 있다. 다음으로, 행동 인식 장치는 영상 합성 이미지에서 해당 오브젝트의 행동을 분류한다(S 107). 행동 인식 장치는 영상 합성 이미지에 대해 영상 전처리 과정을 수행한 후, 영상 합성 이미지에서 시공간 특징 벡터 를 추출하여 해당 오브젝트의 행동을 분류할 수 있다. 도 8은 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하 기 위한 블록도이다. 도시된 실시예에서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가 질 수 있고, 이하에 기술된 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 일 실시예에서, 컴퓨팅 장치는 행동 인식 장치 일 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있 다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실 행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작 들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메 모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자 기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치 에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다."}
{"patent_id": "10-2020-0177718", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서 본 발명의 대표적인 실시예들을 상세하게 설명하였으나, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 상술한 실시예에 대하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형이 가능함을 이해할 것이다. 그러므로 본 발명의 권리범위는 설명된 실시예에 국한되어 정해져서는 안 되며, 후술하는 특허 청구범위뿐만 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2020-0177718", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공 지능 기반의 행동 인식 장치를 나타낸 도면 도 2는 본 발명의 일 실시예에 따른 마스크 이미지 생성 모듈의 구성을 나타낸 블록도 도 3은 개시되는 일 실시예에 따른 마스크 이미지 생성 모듈이 입력 영상으로부터 화이트 마스크 이미지를 생성 하는 상태를 나타낸 도면 도 4는 개시되는 일 실시예에 따른 영상 합성 모듈이 입력 영상과 화이트 마스크 이미지를 합성하여 영상 합성 이미지를 생성하는 상태를 나타낸 도면 도 5는 본 발명의 일 실시예에 따른 행동 인식 모듈의 구성을 나타낸 블록도 도 6은 본 발명의 일 실시예에 따른 제2 인공 신경망 모델의 구조를 개략적으로 나타낸 도면 도 7은 본 발명의 일 실시예에 따른 인공 지능 기반의 행동 인식 방법을 설명하기 위한 흐름도 도 8은 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위 한 블록도"}
