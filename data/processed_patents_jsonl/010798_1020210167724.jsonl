{"patent_id": "10-2021-0167724", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0080212", "출원번호": "10-2021-0167724", "발명의 명칭": "라이트 필드 영상을 렌더링하기 위한 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "이지혜"}}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 인스트럭션을 저장하는 메모리; 및적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는 상기 적어도 하나의 인스트럭션을 실행하여,제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드(light field) 영상을 획득하고,상기 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득하고,상기 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제1 위치 정보를 획득하고,팩토리제이션(factorization)을 수행하기 위한 인공 지능 모델에 상기 제2 라이트 필드 영상 및 상기 제1 위치정보를 입력하여 제1 레이어 영상을 획득하고,시뮬레이션 모델에 상기 제1 레이어 영상을 입력하여 제3 뷰 수의 뷰 영상들을 포함하는 제3 라이트 필드 영상을 획득하고,상기 제1 라이트 필드 영상 및 상기 제3 라이트 필드 영상을 비교한 결과에 기초하여 상기 인공 지능 모델을 학습시키는, 전자 장치."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 적어도 하나의 프로세서는 상기 제1 라이트 필드 영상으로부터 상기 제2 라이트 필드 영상을 획득할 때,상기 제1 뷰 수의 제1 라이트 필드 영상에 마스킹(masking) 또는 보간법(interpolation)을 수행하여 상기 제2뷰 수의 상기 제2 라이트 필드 영상을 획득하고,상기 제1 뷰 수는 상기 제2 뷰 수와 상이한, 전자 장치."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 상기 적어도 하나의 프로세서는 상기 제1 라이트 필드 영상에 마스킹을 수행하여 상기 제2 뷰수의 상기 제2 라이트 필드 영상을 획득할 때,상기 제1 라이트 필드 영상의 뷰 간 디스패리티(disparity)에 기초하여 상기 제2 뷰 수를 결정하고,상기 제2 뷰 수에 기초하여 마스크를 생성하고,상기 생성된 마스크에 기초하여 상기 제1 라이트 필드 영상에 마스킹을 수행하는, 전자 장치."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서, 상기 적어도 하나의 프로세서는 상기 제1 라이트 필드 영상에 마스킹을 수행하여 상기 제2 뷰수의 상기 제2 라이트 필드 영상을 획득할 때,사용자 입력에 기초하여 상기 제2 뷰 수를 결정하고,상기 제2 뷰 수에 기초하여 마스크를 생성하고,상기 생성된 마스크에 기초하여 상기 제1 라이트 필드 영상에 마스킹을 수행하는, 전자 장치."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 항에 있어서, 상기 적어도 하나의 프로세서는 상기 제1 라이트 필드 영상에 보간법을 수행하여 상기 제2 뷰수의 상기 제2 라이트 필드 영상을 획득할 때,공개특허 10-2023-0080212-3-상기 제1 라이트 필드 영상에 대해 서브샘플링을 수행하여 획득된 라이트 필드 영상에 보간법을 수행하는, 전자장치."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서, 상기 적어도 하나의 프로세서는,제4 뷰 수의 제4 라이트 필드 영상을 획득하고,상기 제4 뷰 수가 디스플레이의 시야각(viewing angle)에 대응하는 뷰 수보다 작은 경우, 상기 제4 라이트 필드영상의 포맷을 변경하여, 상기 디스플레이의 시야각에 대응하는 뷰 수와 동일한 크기의 포맷을 가지는 제5 라이트 필드 영상을 획득하고,상기 제4 라이트 필드 영상 또는 상기 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제2 위치 정보를획득하고,상기 학습된 인공 지능 모델에 상기 제4 라이트 필드 영상 또는 상기 제5 라이트 필드 영상 및 상기 제2 위치정보를 입력하여 제2 레이어 영상을 획득하는, 전자 장치."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서, 상기 적어도 하나의 프로세서는 상기 제5 라이트 필드 영상을 획득할 때,상기 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정하지 않은 경우, 상기 제4 라이트 필드 영상에 마스킹을수행하여 상기 제5 라이트 필드 영상을 획득하는, 전자 장치."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서, 상기 적어도 하나의 프로세서는 상기 제5 라이트 필드 영상을 획득할 때,상기 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정한 경우, 상기 제4 라이트 필드 영상에 마스킹 또는 보간법을 수행하여 상기 제5 라이트 필드 영상을 획득하는, 전자 장치."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6 항에 있어서,상기 전자 장치는 상기 디스플레이를 포함하고,상기 적어도 하나의 프로세서는 상기 제2 레이어 영상을 상기 디스플레이에 렌더링하는, 전자 장치."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6 항에 있어서, 상기 전자 장치는 송수신부(transceiver)를 포함하고,상기 적어도 하나의 프로세서는 상기 송수신부를 통해 상기 제2 레이어 영상을 상기 디스플레이를 포함하는 전자 장치로 송신하고,상기 제2 레이어 영상은 상기 디스플레이에 렌더링되는, 전자 장치."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드 영상을 획득하는 단계;상기 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득하는 단계;상기 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제1 위치 정보를 획득하는 단계;팩토리제이션을 수행하기 위한 인공 지능 모델에 상기 제2 라이트 필드 영상 및 상기 제1 위치 정보를 입력하여제1 레이어 영상을 획득하는 단계;시뮬레이션 모델에 상기 제1 레이어 영상을 입력하여 제3 뷰 수의 뷰 영상들을 포함하는 제3 라이트 필드 영상공개특허 10-2023-0080212-4-을 획득하는 단계; 및상기 제1 라이트 필드 영상 및 상기 제3 라이트 필드 영상을 비교한 결과에 기초하여 상기 인공 지능 모델을 학습시키는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서, 상기 제1 라이트 필드 영상으로부터 상기 제2 뷰 수의 상기 제2 라이트 필드 영상을 획득하는 단계는,상기 제1 뷰 수의 제1 라이트 필드 영상에 마스킹 또는 보간법을 수행하여 상기 제2 뷰 수의 상기 제2 라이트필드 영상을 획득하는 단계를 포함하고,상기 제1 뷰 수는 상기 제2 뷰 수와 상이한, 방법."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서, 상기 제1 라이트 필드 영상에 마스킹을 수행하여 상기 제2 뷰 수의 상기 제2 라이트 필드 영상을 획득하는 단계는,상기 제1 라이트 필드 영상의 뷰 간 디스패리티에 기초하여 상기 제2 뷰 수를 결정하는 단계;상기 제2 뷰 수에 기초하여 마스크를 생성하는 단계; 및상기 생성된 마스크에 기초하여 상기 제1 라이트 필드 영상에 마스킹을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12 항에 있어서, 상기 제1 라이트 필드 영상에 마스킹을 수행하여 상기 제2 뷰 수의 상기 제2 라이트 필드 영상을 획득하는 단계는,사용자 입력에 기초하여 상기 제2 뷰 수를 결정하는 단계;상기 제2 뷰 수에 기초하여 마스크를 생성하는 단계; 및상기 생성된 마스크에 기초하여 상기 제1 라이트 필드 영상에 마스킹을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12 항에 있어서, 상기 제1 라이트 필드 영상에 보간법을 수행하여 상기 제2 뷰 수의 상기 제2 라이트 필드 영상을 획득하는 단계는,상기 제1 라이트 필드 영상에 대해 서브샘플링을 수행하여 획득된 라이트 필드 영상에 보간법을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11 항에 있어서,제4 뷰 수의 제4 라이트 필드 영상을 획득하는 단계;상기 제4 뷰 수가 디스플레이의 시야각에 대응하는 뷰 수보다 작은 경우, 상기 제4 라이트 필드 영상의 포맷을변경하여, 상기 디스플레이의 시야각에 대응하는 뷰 수와 동일한 크기의 포맷을 가지는 제5 라이트 필드 영상을획득하는 단계;상기 제4 라이트 필드 영상 또는 상기 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제2 위치 정보를획득하는 단계; 및상기 학습된 인공 지능 모델에 상기 제4 라이트 필드 영상 또는 상기 제5 라이트 필드 영상 및 상기 제2 위치정보를 입력하여 제2 레이어 영상을 획득하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서, 상기 제5 라이트 필드 영상을 획득하는 단계는,공개특허 10-2023-0080212-5-상기 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정하지 않은 경우, 상기 제4 라이트 필드 영상에 마스킹을수행하여 상기 제5 라이트 필드 영상을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16 항에 있어서, 상기 제5 라이트 필드 영상을 획득하는 단계는,상기 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정한 경우, 상기 제4 라이트 필드 영상에 마스킹 또는 보간법을 수행하여 상기 제5 라이트 필드 영상을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16 항에 있어서,상기 제2 레이어 영상을 상기 디스플레이에 렌더링하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-0167724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11 항 내지 제19 항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을수 있는 기록매체."}
{"patent_id": "10-2021-0167724", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "적어도 하나의 인스트럭션을 저장하는 메모리; 및 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서 는 적어도 하나의 인스트럭션을 실행하여, 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드(light field) 영 상을 획득하고, 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득 하고, 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제1 위치 정보를 획득하고, 팩토리제이션 (factorization)을 수행하기 위한 인공 지능 모델에 제2 라이트 필드 영상 및 제1 위치 정보를 입력하여 제1 레 이어 영상을 획득하고, 시뮬레이션 모델에 제1 레이어 영상을 입력하여 제3 뷰 수의 뷰 영상들을 포함하는 제3 라이트 필드 영상을 획득하고, 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 인공 지능 모델을 학습시키는, 전자 장치가 개시된다."}
{"patent_id": "10-2021-0167724", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 라이트 필드 영상을 렌더링하기 위한 방법 및 그 전자 장치에 관한 것이다."}
{"patent_id": "10-2021-0167724", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 영상의 입체감을 표현하기 위해 적층형 디스플레이(stacked display)를 이용하여 영상을 표시하는 방법이 제안되었다. 적층형 디스플레이는 복수의 디스플레이 패널이 적층되어 구현될 수 있으며, 복수의 디스플레이 패 널 각각에 영상이 표시되어 3차원 뎁스가 반영된 영상을 제공할 수 있다. 구체적으로, 적층형 디스플레이는 팩 토리제이션을 수행하기 위한 인공 지능 모델에 서로 다른 시점(view point)에서 촬영된 라이트 필드(light field) 영상을 입력하여 레이어 영상을 획득하고, 획득한 레이어 영상을 렌더링할 수 있다. 그러나, 종래의 인공 지능 모델은 학습 시 사용된 특정 뷰 수의 라이트 필드 영상에 대해서만 팩토리제이션을 수행할 수 있다는 한계를 가진다. 그에 따라, 입력 라이트 필드 영상이 획득되는 환경이 바뀌어 입력 라이트 필 드 영상의 뷰 수가 변경되는 경우, 인공 지능 모델을 다시 학습시켜야 하는 문제점이 존재한다. 또한, 특정 시 야각을 표현하기 위한 라이트 필드 영상의 뷰 수가 고정되어, 넓은 시야각을 표현하기 위해서는 입력 라이트 필 드 영상의 획득 시간이 증가하는 문제점이 존재한다."}
{"patent_id": "10-2021-0167724", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 라이트 필드 영상을 렌더링하기 위한 방법 및 그 전자 장치를 제공한다."}
{"patent_id": "10-2021-0167724", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면은 적어도 하나의 인스트럭션을 저장하는 메모리; 및 적어도 하나의 프로세서를 포함하고, 적 어도 하나의 프로세서는 적어도 하나의 인스트럭션을 실행하여, 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드(light field) 영상을 획득하고, 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라 이트 필드 영상을 획득하고, 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제1 위치 정보를 획득하고, 팩토리제이션(factorization)을 수행하기 위한 인공 지능 모델에 제2 라이트 필드 영상 및 제1 위치 정보를 입 력하여 제1 레이어 영상을 획득하고, 시뮬레이션 모델에 제1 레이어 영상을 입력하여 제3 뷰 수의 뷰 영상들을 포함하는 제3 라이트 필드 영상을 획득하고, 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 인공 지능 모델을 학습시키는, 전자 장치를 제공할 수 있다. 또한, 본 개시의 일 실시예에서 적어도 하나의 프로세서는 제1 라이트 필드 영상으로부터 제2 라이트 필드 영상 을 획득할 때, 제1 뷰 수의 제1 라이트 필드 영상에 마스킹(masking) 또는 보간법(interpolation)을 수행하여 제2 뷰 수의 제2 라이트 필드 영상을 획득하고, 제1 뷰 수는 제2 뷰 수와 상이한, 전자 장치를 제공할 수 있다. 또한, 본 개시의 일 실시예에서 적어도 하나의 프로세서는 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 제2 라이트 필드 영상을 획득할 때, 제1 라이트 필드 영상의 뷰 간 디스패리티(disparity)에 기초하여 제2 뷰 수를 결정하고, 제2 뷰 수에 기초하여 마스크를 생성하고, 생성된 마스크에 기초하여 제1 라이트 필드 영상 에 마스킹을 수행하는, 전자 장치를 제공할 수 있다. 또한, 본 개시의 일 실시예에서 적어도 하나의 프로세서는 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 제2 라이트 필드 영상을 획득할 때, 사용자 입력에 기초하여 제2 뷰 수를 결정하고, 제2 뷰 수에 기초하여 마스크를 생성하고, 생성된 마스크에 기초하여 제1 라이트 필드 영상에 마스킹을 수행하는, 전자 장치를 제공할 수 있다. 또한, 본 개시의 일 실시예에서 적어도 하나의 프로세서는 제1 라이트 필드 영상에 보간법을 수행하여 제2 뷰 수의 제2 라이트 필드 영상을 획득할 때, 제1 라이트 필드 영상에 대해 서브샘플링을 수행하여 획득된 라이트 필드 영상에 보간법을 수행하는, 전자 장치를 제공할 수 있다. 또한, 본 개시의 일 실시예에서 적어도 하나의 프로세서는, 제4 뷰 수의 제4 라이트 필드 영상을 획득하고, 제4 뷰 수가 디스플레이의 시야각(viewing angle)에 대응하는 뷰 수보다 작은 경우, 제4 라이트 필드 영상의 포맷을 변경하여, 디스플레이의 시야각에 대응하는 뷰 수와 동일한 크기의 포맷을 가지는 제5 라이트 필드 영상을 획득 하고, 제4 라이트 필드 영상 또는 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제2 위치 정보를 획득 하고, 학습된 인공 지능 모델에 제4 라이트 필드 영상 또는 제5 라이트 필드 영상 및 제2 위치 정보를 입력하여 제2 레이어 영상을 획득하는, 전자 장치를 제공할 수 있다. 또한, 본 개시의 일 실시예에서 적어도 하나의 프로세서는 제5 라이트 필드 영상을 획득할 때, 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정하지 않은 경우, 제4 라이트 필드 영상에 마스킹을 수행하여 제5 라이트 필드 영상을 획득하는, 전자 장치를 제공할 수 있다. 또한, 본 개시의 일 실시예에서 적어도 하나의 프로세서는 제5 라이트 필드 영상을 획득할 때, 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정한 경우, 제4 라이트 필드 영상에 마스킹 또는 보간법을 수행하여 제5 라이트 필드 영상을 획득하는, 전자 장치를 제공할 수 있다. 또한, 본 개시의 일 실시예에서 전자 장치는 디스플레이를 포함하고, 적어도 하나의 프로세서는 제2 레이어 영 상을 디스플레이에 렌더링하는, 전자 장치를 제공할 수 있다. 또한, 본 개시의 일 실시예에서 전자 장치는 송수신부(transceiver)를 포함하고, 적어도 하나의 프로세서는 송 수신부를 통해 제2 레이어 영상을 디스플레이를 포함하는 전자 장치로 송신하고, 제2 레이어 영상은 디스플레이 에 렌더링되는, 전자 장치를 제공할 수 있다. 본 개시의 다른 측면은 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드 영상을 획득하는 단계; 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득하는 단계; 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제1 위치 정보를 획득하는 단계; 팩토리제이션을 수행하기 위한 인공 지 능 모델에 제2 라이트 필드 영상 및 제1 위치 정보를 입력하여 제1 레이어 영상을 획득하는 단계; 시뮬레이션 모델에 제1 레이어 영상을 입력하여 제3 뷰 수의 뷰 영상들을 포함하는 제3 라이트 필드 영상을 획득하는 단계; 및 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 인공 지능 모델을 학습시키는 단 계를 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예에서 제1 라이트 필드 영상으로부터 제2 뷰 수의 제2 라이트 필드 영상을 획득하는 단계는, 제1 뷰 수의 제1 라이트 필드 영상에 마스킹 또는 보간법을 수행하여 제2 뷰 수의 제2 라이트 필드 영 상을 획득하는 단계를 포함하고, 제1 뷰 수는 제2 뷰 수와 상이한, 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예에서 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 제2 라이트 필드 영상 을 획득하는 단계는, 제1 라이트 필드 영상의 뷰 간 디스패리티에 기초하여 제2 뷰 수를 결정하는 단계; 제2 뷰 수에 기초하여 마스크를 생성하는 단계; 및 생성된 마스크에 기초하여 제1 라이트 필드 영상에 마스킹을 수행하 는 단계를 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예에서 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 제2 라이트 필드 영상 을 획득하는 단계는, 사용자 입력에 기초하여 제2 뷰 수를 결정하는 단계; 제2 뷰 수에 기초하여 마스크를 생성하는 단계; 및 생성된 마스크에 기초하여 제1 라이트 필드 영상에 마스킹을 수행하는 단계를 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예에서 제1 라이트 필드 영상에 보간법을 수행하여 제2 뷰 수의 제2 라이트 필드 영상 을 획득하는 단계는, 제1 라이트 필드 영상에 대해 서브샘플링을 수행하여 획득된 라이트 필드 영상에 보간법을 수행하는 단계를 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예에서 제4 뷰 수의 제4 라이트 필드 영상을 획득하는 단계; 제4 뷰 수가 디스플레이의 시야각에 대응하는 뷰 수보다 작은 경우, 제4 라이트 필드 영상의 포맷을 변경하여, 디스플레이의 시야각에 대 응하는 뷰 수와 동일한 크기의 포맷을 가지는 제5 라이트 필드 영상을 획득하는 단계; 제4 라이트 필드 영상 또 는 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제2 위치 정보를 획득하는 단계; 및 학습된 인공 지 능 모델에 제4 라이트 필드 영상 또는 제5 라이트 필드 영상 및 제2 위치 정보를 입력하여 제2 레이어 영상을 획득하는 단계를 더 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예에서 제5 라이트 필드 영상을 획득하는 단계는, 제4 라이트 필드 영상의 뷰 간 디스 패리티가 일정하지 않은 경우, 제4 라이트 필드 영상에 마스킹을 수행하여 제5 라이트 필드 영상을 획득하는 단 계를 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예에서 제5 라이트 필드 영상을 획득하는 단계는, 제4 라이트 필드 영상의 뷰 간 디스 패리티가 일정한 경우, 제4 라이트 필드 영상에 마스킹 또는 보간법을 수행하여 제5 라이트 필드 영상을 획득하 는 단계를 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예에서 제2 레이어 영상을 디스플레이에 렌더링하는 단계를 더 포함하는, 방법을 제공 할 수 있다. 또한, 본 개시의 일 실시예에서 적어도 하나의 프로세서는 송수신부를 통해 제2 레이어 영상을 디스플레이를 포 함하는 전자 장치로 송신하는 단계를 더 포함하고, 제2 레이어 영상은 디스플레이에 렌더링되는, 방법을 제공할 수 있다. 본 개시의 또 다른 측면은 전자 장치에 의해 수행되는 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체를 제공할 수 있다."}
{"patent_id": "10-2021-0167724", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 아래에서는 실시예를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략한다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐 리지 않고 더욱 명확히 전달하기 위함이다. 마찬가지 이유로 첨부 도면에 있어서 일부 구성요소는 과장되거나 생략되거나 개략적으로 도시하였다. 또한, 각 구성요소의 크기는 실제 크기를 전적으로 반영하는 것이 아니다. 각 도면에서 동일한 또는 대응하는 구성요소에 는 동일한 참조 번호를 부여하였다. 본 개시의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술될 실시예들을"}
{"patent_id": "10-2021-0167724", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시를 완전하게 하고, 본 개시가 속하는 기술분야에 서 통상의 지식을 가진 자에게 본 개시의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시는 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 이때, 처리 흐름도 도면들의 각 블록과 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수행될 수 있음을 이해할 수 있을 것이다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기 타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능 한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위해 컴 퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장된 인스트 럭션들은 흐름도 블록(들)에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재 되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 수행하는 인스트럭션들은 흐름도 블록(들)에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하 다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 적어도 하나의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또한, 몇 가지 대체 실행 예시들에서는 블록들에서 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록 들은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 본 개시에서, 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 일 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로드 가능한 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토 어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적 으로 생성될 수 있다. 본 개시에서, 하나의 픽셀을 구성하는 서브 픽셀(sub-pixel)은, 해당 픽셀을 구성하는 R, G 및 B 컬러 성분들 중 어느 하나의 컬러 성분의 서브 픽셀을 의미하거나, 해당 픽셀을 구성하는 Y, U 및 V 컬러 성분들 중 어느 하 나의 컬러 성분의 서브 픽셀을 의미할 수 있다. 본 개시에서 복수의 영상들 내의 소정 위치의 서브 픽셀들은, 복수의 영상들 중 동일한 위치의 픽셀들을 구성하는 R, G 및 B 중 어느 하나의 컬러 성분의 서브 픽셀들을 의미 하거나, 동일한 위치의 픽셀들을 구성하는 Y, U 및 V 컬러 성분들 중 어느 하나의 컬러 성분의 서브 픽셀을 의 미할 수 있다. 상기 정의는 본 개시의 실시예가 RGB 컬러 포맷 또는 YUV 컬러 포맷을 따를 경우를 가정한 것으 로, 다른 컬러 포맷을 따르는 경우에도 서브 픽셀은 어느 하나의 컬러 성분의 서브 픽셀을 의미할 수 있다. 도 1은 본 개시의 일 실시예에 따른 전자 장치의 블록도이다. 일 실시예에 따르면, 전자 장치는 프로세서 및 메모리를 포함할 수 있다. 그러나, 전자 장치 의 구성은 전술한 바에 한정되지 않고, 더 많은 구성을 포함하거나 적은 구성을 포함할 수 있다. 프로세서는 메모리 내에 저장된 적어도 하나의 인스트럭션을 실행함으로써 전자 장치의 전반적 인 동작을 제어할 수 있다. 예를 들어, 프로세서는 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드(light field) 영상을 획득할 수 있다. 프로세서는 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획 득할 수 있다. 프로세서는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제1 위치 정보를 획득할 수 있다. 프로세서는 팩토리제이션을 수행하기 위한 인공 지능 모델에 제2 라이트 필드 영상 및 제1 위치 정보를 입 력하여 제1 레이어 영상을 획득할 수 있다. 프로세서는 시뮬레이션 모델에 제1 레이어 영상을 입력하여 제3 뷰 수의 뷰 영상들을 포함하는 제3 라이트 필드 영상을 획득할 수 있다. 프로세서는 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 인공 지능 모델을 학습시킬 수 있다. 메모리는 마스킹(masking) 모듈, 보간법(interpolation) 모듈, 위치 정보 획득 모듈, 팩 토리제이션(factorization) 모듈, 시뮬레이션 모듈 및 인공 지능 모델 학습 모듈을 포함할 수 있다. 마스킹 모듈은 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득하기 위한 인스트럭션들을 저장할 수 있다. 보간법 모듈은 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드 영상에 보간법을 수행하여 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득하기 위한 인스트럭션들을 저장할 수 있다. 위치 정보 획득 모듈은 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 제1 위치 정보를 획득하기 위한 인스트럭션들을 저장할 수 있다. 팩토리제이션 모듈은 팩토리제이션을 수행하기 위한 인공 지능 모델에 제2 라이트 필드 영상 및 제1 위치 정보를 입력하여 제1 레이어 영상을 획득하기 위한 인스트럭션들을 저장할 수 있다. 시뮬레이션 모듈은 시뮬레이션 모델에 제1 레이어 영상을 입력하여 제3 뷰 수의 뷰 영상들을 포함하는 제3 라이트 필드 영상을 획득 획득하기 위한 인스트럭션들을 저장할 수 있다. 인공 지능 모델 학습 모듈은 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 인 공 지능 모델을 학습시키기 위한 인스트럭션들을 저장할 수 있다. 일 실시예에 따르면, 전자 장치는 카메라(미도시)를 포함할 수 있다. 예를 들어, 카메라는 라이트 필드 카 메라를 포함할 수 있고, 라이트 필드 카메라는 제1 뷰 수의 제1 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 디스플레이(미도시)를 포함할 수 있다. 예를 들어, 디스플레이는 적층형 디스플레이를 포함할 수 있다. 적층형 디스플레이는 TV, 모니터, 스마트폰, 휴대용 멀티미디어 장치, 휴대용 통 신장치, 스마트 글래스, 스마트 윈도우, 스마트 워치, HMD(Head Mount Display), 웨어러블 장치(Wearable device), 포터블 장치(Portable device), 핸즈헬드 장치(Handheld device), 사이니지(Signage), 전광판, 광고 판, 시네마 스크린, 비디오 월 등 다양한 형태로 구현될 수 있으며, 그 형태가 한정되지 않는다. 일 실시예에 따르면, 전자 장치가 디스플레이를 포함하는 경우, 전자 장치는 레이어 영상을 디스플레 이에 렌더링할 수 있다. 예를 들어, 적층형 디스플레이는 복수의 패널을 포함할 수 있고, 복수의 패널 각각에 레이어 영상이 표시될 수 있다. 즉, 전자 장치는 적층형 디스플레이 내 패널 각각에 레이어 영상을 표시하 여 입체 영상을 제공할 수 있다. 일 실시예에 따르면, 전자 장치는 송수신부(transceiver, 미도시)를 포함할 수 있다. 송수신부는 외부 장 치와 통신을 수행하여 외부 장치와 데이터를 주거나 받을 수 있다. 예를 들어, 송수신부는, LTE, LTE-A(LTE Advance), CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), 또는 GSM(Global System for Mobile Communications) 등 중 적어도 하나를 사용하는 셀룰러 통신, WiFi(wireless fidelity), 블루투스, 블루투스 저전력(BLE), 지그비(Zigbee), NFC(near field communication) 등의 다양한 방식 중 적어도 하나의 무선 통신 을 수행할 수 있다. 또한, 송수신부는 USB(universal serial bus), HDMI(high definition multimedia interface), DVI(Digital Visual Interface), 썬더볼트, 이더넷, USB 포트, 라이트닝 등의 다양한 방식 중 적어도 하나의 유선 통신을 수행할 수 있다. 일 실시예에 따르면, 전자 장치가 송수신부를 포함하는 경우, 전자 장치는 외부의 라이트 필드 카메 라 또는 외부의 전자 장치(예를 들어, 서버)로부터 라이트 필드 영상을 수신할 수 있다. 또한, 전자 장치 가 송수신부를 포함하는 경우, 전자 장치는 디스플레이를 포함하는 외부의 전자 장치로 레이어 영상을 송 신할 수 있다. 도 2a 및 도 2b는 본 개시의 일 실시예에 따른 라이트 필드 영상 및 레이어 영상의 일 예를 도시한다. 일 실시예에 따르면, 라이트 필드 영상은 라이트 필드 카메라를 통해 적어도 하나의 오브젝트가 서로 다른 시점(view)으로 촬영된 복수의 뷰 영상들의 집합을 의미할 수 있다. 즉, 라이트 필드 영상은 특정한 오브젝트에 서 반사되어 나오는 빛을 서로 다른 복수의 시점(view point)에서 촬영한 복수의 뷰 영상들의 집합을 의미할 수 있다. 일 실시예에 따르면, 레이어 영상은 적층형 디스플레이에 제공되는 영상으로 사용자의 시점(또는 사용자의 위치)에 따라 영상 내 오브젝트의 다른 면이 사용자에게 보이도록 하는 영상을 의미할 수 있다. 예를 들어, 적 층형 디스플레이를 바라보는 사용자가 왼쪽으로 위치를 이동할 경우 레이어 영상에서 오브젝트의 좌측 부 분이 사용자에게 더 많이 보이게 될 수 있다. 한편, 레이어 영상은 레이어 스택(stack)으로 지칭될 수 있다. 일 실시예에 따르면, 레이어 영상은 적층형 디스플레이의 패널들의 개수와 동일한 개수의 영상을 포함할 수 있다. 그에 따라, 적층형 디스플레이의 패널들 각각에 레이어 영상에 포함된 영상이 표시되어 입체 영 상이 제공될 수 있다. 예를 들어, 3 개의 패널들을 포함하는 적층형 디스플레이에 제공되는 레이어 영상은 제1 영상, 제2 영상 및 제3 영상을 포함할 수 있다. 그에 따라, 적층형 디스플레이의 제1 패널에는 제1 영상이 표시되고, 제2 패널에는 제2 영상이 표시되며, 제3 패널에는 제3 영상이 표시되어 입체 영상이 제공될 수 있다. 도 2a를 참조하면, 전자 장치는 일 실시예에 따라 팩토리제이션(factorization, 230)을 수행하는 인공 지 능 모델에 라이트 필드 영상을 입력하여 레이어 영상을 획득할 수 있다. 한편, 인공 지능 모델은 복 수의 신경망 레이어들을 포함할 수 있다. 각 레이어는 복수의 가중치(weight values)을 가지고 있으며, 이전 (previous) 레이어의 연산 결과와 복수의 가중치의 연산을 통해 레이어의 연산을 수행할 수 있다. 신경망의 예 로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks)이 있으며, 본 개시에서의 신경망은 전술한 예에 한정 되지 않는다. 도 2a를 참조하면, 전자 장치는 일 실시예에 따라 시뮬레이션을 수행하여, 레이어 영상으로부터 라이트 필드 영상을 복원할 수 있다. 예를 들어, 라이트 필드 영상의 제1 뷰 영상은 레이어 영상 의 각각의 영상들 내 제1 뷰 영상에 대응하는 픽셀들의 합 또는 곱으로서 복원될 수 있다. 이때, 픽셀들이 제1 뷰 영상에 대응한다는 것은 제1 뷰 영상을 렌더링하기 위한 빛이 상기 픽셀들이 표시되는 디스플레이 패널 을 지나간다는 것을 의미할 수 있다. 도 2b를 참조하면, 라이트 필드 영상은 일 실시예에 따라 다양한 형태로 표현될 수 있다. 일 실시예에 따르면, 라이트 필드 영상은 3X3의 해상도를 가지는 25 개의 뷰 영상들을 포함할 수 있다. 예 를 들어, 라이트 필드 영상은 제1 뷰 영상, 제2 뷰 영상, 제3 뷰 영상, 쪋, 및 제25 뷰 영상 을 포함할 수 있다. 이때, 뷰 영상은 라이트 필드 영상에 포함된 각각의 뷰에 대응되는 영상을 의미할 수 있다. 일 실시예에 따르면, 라이트 필드 영상은 마이크로 렌즈 어레이(micro lens array, MLA) 영상의 형태를 가 지는 라이트 필드 영상으로 표현될 수 있다. 라이트 필드 영상은 라이트 필드 영상의 뷰 영상 각각에 포함된 서브 픽셀들을 위치에 따라 그룹핑함으로써 표현될 수 있다. 예를 들어, 라이트 필드 영상 이 25 개의 뷰 영상들을 포함하므로, 25 개의 뷰 영상들 내 동일한 위치를 가지는 25 개의 서브 픽셀들이 5X5 형태의 영상으로 그룹핑될 수 있다. 그리고 라이트 필드의 뷰 영상들이 3X3의 해상도를 가지므로, 라이트 필드 영상은 5X5 형태의 영상 9 개를 포함할 수 있다. 일 실시예에 따르면, 라이트 필드 영상의 제1 뷰 영상에 포함된 서브 픽셀들(271 내지 279)은 라이트 필드 영상 내 각각의 5X5 형태의 영상의 (0, 0) 좌표에 위치할 수 있다. 또한, 라이트 필드 영상의 제3 뷰 영상에 포함된 서브 픽셀들(281 내지 289)은 라이트 필드 영상 내 각각의 5X5 형태의 영상의(0, 2) 좌표에 위치할 수 있다. 라이트 필드 영상의 제25 뷰 영상에 포함된 서브 픽셀들(291 내지 299)은 라이트 필드 영상 내 각각의 5X5 형태의 영상의 (4, 4) 좌표에 위치할 수 있다. 다만, 이는 일 실 시예에 불과하며, 라이트 필드 영상은 다른 방식으로 표현될 수 있다. 도 3은 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시 키는 과정을 설명하기 위한 도면이다. 일 실시예에 따르면, 전자 장치는 제1 뷰 수의 제1 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치가 라이트 필드 카메라를 포함하는 경우, 전자 장치는 라이트 필드 카메라를 통해 3X3의 해 상도를 가지는 5X5 뷰 수의 제1 라이트 필드 영상을 획득할 수 있다. 또는, 전자 장치가 송수신부를 포함하는 경우, 전자 장치는 외부의 라이트 필드 카메라 또는 외부의 전자 장치로부터 3X3의 해상도를 가 지는 5X5 뷰 수의 제1 라이트 필드 영상을 수신할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상의 뷰 수는 레이어 영상이 렌더링될 디스플레이가 표현할 수 있 는 최대 뷰 수를 의미할 수 있다. 이때, 디스플레이가 표현할 수 있는 최대 뷰 수는 디스플레이가 표현할 수 있 는 시야각에 의해 결정될 수 있다. 예를 들어, 디스플레이가 표현할 수 있는 최대 뷰 수가 5X5인 경우, 제1 라 이트 필드 영상의 뷰 수는 5X5일 수 있다. 다만, 이는 일 실시예에 불과하며, 이에 한정되지 않는다. 일 실시예에 따르면, 제1 라이트 필드 영상의 뷰 간 디스패리티(disparity)가 일정할 수 있다. 제1 라이트 필드 영상의 뷰 간 디스패리티가 일정하다는 것은 제1 라이트 필드 영상의 각각의 인접한 뷰 간의 디 스패리티가 동일한 값을 가진다는 것을 의미할 수 있다. 한편, 뷰 간의 디스패리티는 이웃하는 뷰 내 동일한 객체에 대응하는 픽셀의 위치 차이로 정의될 수 있다. 만일, 뷰 내 복수의 객체들이 존재하는 경우, 뷰 간 디스패리티는 복수의 객체들 각각에 대응하는 픽셀의 위치 차이들 중 절대값이 가장 큰 값을 의미할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]에 기초하여 제2 뷰 수를 결정하거나, 또는 제1 라이트 필드 영상의 뷰 간 디스패리티 등에 기초하여 제2 뷰 수를 결정할 수 있다. 예를 들어, 전자 장치는 [입력 뷰 수, 출력 뷰 수] 또는 뷰 간 디스패리티에 기초하여 제1 라이트 필드 영상에 마스킹 또는 보간법을 수행하여 제2 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 다만, 전 자 장치가 제1 라이트 필드 영상으로부터 제2 라이트 필드 영상을 획득하는 방법은 이에 한정되 지 않는다. 일 실시예에 따르면, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]에 따라 입력 뷰 수를 제2 뷰 수로 결정하고, 제1 라이트 필드 영상으로부터 입력 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응 하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]가 [3X3, 3X5]인 경우, 전자 장치는 제1 라이트 필드 영 상에 마스킹 또는 보간법을 수행하여 3X3 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상 을 획득할 수 있다. 한편, 도 3은 제1 라이트 필드 영상의 뷰 간 디스패리티가 일정한 경우를 도시하나, 일 실시예에 따라 제1 라이트 필드 영상의 뷰 간 디스패리티가 일정하지 않을 수 있다. 제1 라이트 필드 영상의 뷰 간 디스 패리티가 일정하지 않은 경우, 전자 장치는 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 팩토리제이션을 수행하기 위한 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력하여 레이어 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 시뮬레이션 모델에 레이어 영상을 입력하여 제3 뷰 수의 뷰 영상들 을 포함하는 제3 라이트 필드 영상을 획득할 수 있다. 이때, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]에 기초하여, 출력 뷰 수의 뷰 영상들을 포함하는 제3 라 이트 필드 영상을 획득할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의[입력 뷰 수, 출력 뷰 수]가 [3X3, 3X5]인 경우, 전자 장치는 3X5 뷰 수의 제3 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상과 제3 라이트 필드 영상의 뷰 수가 상이한 경우, 전자 장 치는 제1 라이트 필드 영상의 뷰 수가 제3 라이트 필드 영상의 뷰 수와 동일하도록 제1 라이트 필드 영상의 유효 영역을 선택하고, 유효 영역으로 구성된 제1 라이트 필드 영상을 획득할 수 있다. 예를 들어, 제1 라이트 필드 영상의 뷰 수가 5X5이고, 제3 라이트 필드 영상의 뷰 수가 3X5인 경우, 전자 장치는 제1 라이트 필드 영상에서 3X5의 유효 영역을 선택하여 제1 라이트 필드 영상을 획 득할 수 있다. 이후, 전자 장치는 제1 라이트 필드 영상과 제3 라이트 필드 영상을 비교한 결과 에 기초하여 인공 지능 모델을 학습시킬 수 있다. 한편, 도 3은 전자 장치가 손실 함수를 획득하기 전 제1 라이트 필드 영상의 유효 영역을 선택하는 것으로 도시하나, 전자 장치는 손실 함수를 획득하는 과정 에서 제1 라이트 필드 영상의 유효 영역을 선택할 수 있으며, 이에 한정되지 않는다. 일 실시예에 따르면, 전자 장치는 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결 과에 기초하여 인공 지능 모델을 학습시킬 수 있다. 예를 들어, 전자 장치는 제1 라이트 필드 영상과 제3 라이트 필드 영상을 비교하여 손실 함수(loss function)를 획득하고, 손실 함수를 바탕으로 손실 (loss)을 계산하여, 인공 지능 모델을 학습시킬 수 있다. 이때, 손실 함수란 인공 지능 모델의 현재 학습 상태 를 나타내는 지표를 나타낸다. 즉, 손실 함수는 인공 지능 모델에 대한 현재 성능의 나쁨을 나타내는 지표로, 전자 장치는 손실 함수가 감소하는 방향으로 인공 지능 모델을 업데이트할 수 있다. 제1 라이트 필드 영상 과 제3 라이트 필드 영상 간의 손실 함수가 감소하도록, 인공 지능 모델은 제2 라이트 필드 영상 으로부터 레이어 영상을 획득하는 동작을 훈련할 수 있다. 이를 통해, 전자 장치는 제2 라이트 필드 영상으로부터 레이어 영상을 생성하도록 인공 지능 모델을 학습시킬 수 있다. 도 4a 및 도 4b는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 마스킹 또는 보간법을 수 행하는 과정을 설명하는 도면이다. 도 4a를 참조하면, 전자 장치는 일 실시예에 따라 제1 라이트 영상에 마스킹을 수행하여 제2 라이트 필드 영상(440, 450)을 획득할 수 있다. 예를 들어, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수] 또는 제1 라이트 필드 영상의 뷰 간 디스패리티 등에 기초하여 제2 뷰 수를 결정하고, 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상(440, 450)을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수] 또는 제1 라이트 필드 영상의 뷰 간 디스패리티 등에 기초하여 제2 뷰 수를 결정하고, 결정된 제2 뷰 수에 따라 마스크(420, 430)를 생성할 수 있다. 예를 들어, 결정된 제2 뷰 수가 3X3인 경우 전자 장치 는 마스크를 생성할 수 있고, 결정된 제2 뷰 수가 2X2인 경우 전자 장치는 마스크를 생성 할 수 있다. 일 실시예에 따르면, 전자 장치는 생성된 마스크(420, 430)에 기초하여, 제1 라이트 필드 영상에 마 스킹을 수행하여 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상(440, 450)을 획득할 수 있다. 예를 들어, 전자 장치는 마스크에 기초하여 제1 라이트 영상에 마스킹을 수행하여 3X3 뷰 수의 뷰 영 상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 또는, 전자 장치는 마스크에 기초하 여 제1 라이트 영상에 마스킹을 수행하여 2X2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 한편, 제1 라이트 필드 영상에 마스킹을 수행하여 제2 라이트 필드 영상(440, 450)이 획득됨에 따라 제2 라이트 필드 영상(440, 450)의 뷰 수가 제1 라이트 필드 영상의 뷰 수와 상이할 수 있으나, 제2 라이트 필 드 영상(440, 450)의 포맷은 제1 라이트 필드 영상의 포맷과 동일할 수 있다. 예를 들어, 제2 라이트 필드 영상(440, 450) 내 마스킹된 서브 픽셀은 0의 값을 가지므로, 제2 라이트 필드 영상(440, 450)의 뷰 수가 각각 3X3 또는 2X2로 제1 라이트 필드 영상의 뷰 수인 5X5와 상이할 수 있다. 그러나, 제2 라이트 필드 영상 (440, 450)의 포맷은 5X5로 제1 라이트 필드 영상의 포맷과 동일할 수 있다. 도 4b를 참조하면, 전자 장치는 일 실시예에 따라 제1 라이트 영상에 보간법을 수행하여 제2 라이트 필드 영상(480, 490)을 획득할 수 있다. 예를 들어, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수] 또는 제1 라이트 필드 영상의 뷰 간 디스패리티 등에 기초하여제2 뷰 수를 결정하고, 제1 라이트 필드 영상에 보간법을 수행하여 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상(480, 490)을 획득할 수 있다. 이때, 전자 장치는 EPI(epipolar plane image) 보간법을 수행하여 제2 라이트 필드 영상(480, 490)을 획득할 수 있으나, 이에 한정되지 않는다. 일 실시예에 따르면, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수] 또는 제1 라이트 필드 영상의 뷰 간 디스패리티 등에 기초하여 제2 뷰 수를 결정하고, 결정된 제2 뷰 수에 따라 제1 라이트 필드 영상에 대해 서브 샘플링을 수행할 수 있다. 예를 들어, 결정된 제2 뷰 수가 3X3인 경우 전자 장치는 제1 라이트 필드 영상에 대해 서브 샘플링을 수행하여 3X3 뷰 수의 뷰 영상들을 포함하는 라이트 필드 영상을 획득할 수 있다. 또는, 결정된 제2 뷰 수가 2X2인 경우 전자 장치 는 제1 라이트 필드 영상에 대해 서브 샘플링을 수행하여 2X2 뷰 수의 뷰 영상들을 포함하는 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 서브 샘플링을 수행하여 획득된 라이트 필드 영상(460, 470)에 보간법을 수행하여 제2 라이트 필드 영상(480, 490)을 획득할 수 있다. 예를 들어, 전자 장치는 3X3 뷰 수의 라이트 필드 영상에 보간법을 수행하여 제2 라이트 필드 영상을 획득할 수 있다. 또는, 전자 장치는 2X2 뷰 수의 라이트 필드 영상에 보간법을 수행하여 제2 라이트 필드 영상을 획득할 수 있다. 한편, 제1 라이트 필드 영상에 대해 서브샘플링을 수행하여 획득된 라이트 필드 영상(460, 470)에 보간법 을 수행하여 제2 라이트 필드 영상(480, 490)을 획득함에 따라, 제2 라이트 필드 영상(480, 490)의 뷰 수가 제1 라이트 필드 영상의 뷰 수와 상이할 수 있으나, 제2 라이트 필드 영상(480, 490)의 포맷은 제1 라이트 필 드 영상의 포맷과 동일할 수 있다. 예를 들어, 제1 라이트 필드 영상에 대해 서브 샘플링을 수행하여 획득된 라이트 필드 영상(460, 470) 각각의 뷰 수는 3X3 또는 2X2로 제1 라이트 필드 영상의 뷰 수인 5X5 와 상이할 수 있다. 그러나, 라이트 필드 영상(460, 470)에 보간법을 수행하여 획득된 제2 라이트 필드 영상 (480, 490)의 포맷은 5X5로 제1 라이트 필드 영상의 포맷과 동일할 수 있다. 이때, 제2 라이트 필드 영상 (480, 490)의 보간된 서브 픽셀 값들은 주변의 서브 픽셀들로부터 추정된 값으로서, 제2 라이트 필드 영상(480, 490)의 뷰 수에 영향을 주지 않는다. 도 5a 내지 도 5c는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 마스킹을 수행하는 과정 을 설명하는 도면이다. 일 실시예에 따르면, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]에 따라 제2 라이트 필드 영상의 뷰 수를 결정하고, 그에 따라 마스크를 생성할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 입력 뷰 수가 5X5인 경우, 전자 장치는 마 스크를 생성할 수 있다. 또는, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 입력 뷰 수가 3X3 인 경우, 전자 장치는 마스크를 생성할 수 있다. 인공 지능 모델을 이용하여 대응하고자 하는 시나리 오의 입력 뷰 수가 2X2인 경우, 전자 장치는 마스크를 생성할 수 있다. 이때, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오는 레이어 영상이 렌더링될 디스플레이의 용도에 따 라 결정될 수 있다. 예를 들어, 레이어 영상이 렌더링될 디스플레이가 스마트폰에 포함되어 개인을 대상으로 사 용되는지 또는 전광판에 포함되어 다수를 대상으로 사용되는지 등에 따라 시나리오의 [입력 뷰 수, 출력 뷰 수]가 결정될 수 있다. 따라서, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]는 사전 정의되거나, 사용자 입력에 기초하여 변경될 수 있으며, 이에 한정되지 않는다. 일 실시예에 따르면, 전자 장치는 생성된 마스크에 기초하여, 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 마스크에 기초하여 제 1 라이트 영상에 마스킹을 수행하여 5X5 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 또는, 전자 장 치는 마스크에 기초하여 제1 라이트 영상에 마스킹을 수행하여 3X3 뷰 수의 뷰 영상들을 포함하는 제 2 라이트 필드 영상을 획득할 수 있다. 전자 장치는 마스크에 기초하여 제1 라이트 영상에 마스 킹을 수행하여 2X2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 도 5c는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 입력 뷰 수에 기초하여 생성된 마스크의 일 예 를 도시한다. 이때, 전자 장치는 동일한 입력 뷰 수에 기초하여 다양한 형태의 마스크를 생성할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 입력 뷰 수가 1X5인 경우, 전자 장치 는 마스크와 마스크와 같이 상이한 형태의 마스크를 생성할 수 있고, 인공 지능 모델을 이용하여 대 응하고자 하는 시나리오의 입력 뷰 수가 3X5인 경우, 전자 장치는 마스크와 마스크와 같이 상이한 형태의 마스크를 생성할 수 있다. 또한, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 입력 뷰 수 가 5X3인 경우, 전자 장치는 마스크와 마스크와 같이 상이한 형태의 마스크를 생성할 수 있고, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 입력 뷰 수가 5X1인 경우, 전자 장치는 마스크 와 마스크와 같이 상이한 형태의 마스크를 생성할 수 있다. 한편, 전자 장치가 동일한 입력 뷰 수에 기초하여 어떠한 형태의 마스크를 생성할 것인지는 시나리오 상의 사용자의 위치 등에 따라 사전 정의되거나 사용자 입력에 기초하여 변경될 수 있으나, 이에 한정되지 않는다. 도 6a 및 도 6b는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 마스킹을 수행하는 과정을 설명하는 도면이다. 일 실시예에 다르면, 전자 장치는 제1 라이트 필드 영상의 뷰 간 디스패리티 및 디스플레이가 표현 가능한 뷰 간 디스패리티를 식별하고, 그에 기초하여 뷰 수를 결정할 수 있다. 예를 들어, 전자 장치 는 제1 라이트 필드 영상의 뷰 간 디스패리티가 4이고, 디스플레이가 표현 가능한 뷰 간 디스패리티 가 2임을 식별할 수 있다. 인공 지능 모델에 입력되는 라이트 필드 영상의 뷰 간 디스패리티가 디스플레이가 표 현 가능한 뷰 간 디스패리티와 동일해야 한다는 학습 규칙에 따르는 경우, 전자 장치는 제1 라이트 필드 영상의 픽셀들을 한 칸씩 띄워 배치함으로써, 제1 라이트 필드 영상의 뷰 간 디스패리티를 2로 감소 시킬 수 있다. 제1 라이트 필드 영상의 픽셀들을 한 칸씩 띄워 배치하기 위하여, 전자 장치는 제2 라 이트 필드 영상(650, 660, 670)의 뷰 수를 3X3으로 결정할 수 있다. 일 실시예에 따르면, 전자 장치는 결정된 뷰 수에 따라 마스크를 생성할 수 있다. 예를 들어, 결정된 뷰 수가 3X3인 경우, 전자 장치는 마스크를 생성할 수 있다. 일 실시예에 따르면, 전자 장치는 생성된 마스크에 기초하여, 제1 라이트 필드 영상에 마스킹을 수행 하여 제2 라이트 필드 영상(650, 660, 670)을 획득할 수 있다. 예를 들어, 전자 장치는 마스크에 기 초하여 3X3 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상(650, 660, 670)을 획득할 수 있다. 이때, 마스킹을 수행하여 획득된 제2 라이트 필드 영상(650, 660, 670)에 포함되는 서브 픽셀들은 사전 정의되 거나 사용자 입력에 기초하여 변경될 수 있다. 예를 들어, 제2 라이트 필드 영상은 제1 라이트 필드 영상 내 3X3 크기의 제1 영역에 포함되는 서브 픽셀들을 포함할 수 있다. 또는, 제2 라이트 필드 영상 은 제1 라이트 필드 영상 내 3X3 크기의 제2 영역에 포함되는 서브 픽셀들을 포함할 수 있다. 제2 라이트 필드 영상은 제1 라이트 필드 영상 내 3X3 크기의 제3 영역에 포함되는 서브 픽셀들 을 포함할 수 있다. 다만 이는 일 실시예에 불과하며, 이에 한정되지 않는다. 도 7은 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 보간법을 수행하는 과정을 설명하는 도면이다. 일 실시예에 따르면, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]에 따라 제2 라이트 필드 영상의 뷰 수를 결정하고, 그에 따라 제1 라이트 필드 영상에 대해 서브 샘플링을 수행할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 입력 뷰 수 가 3X3인 경우, 전자 장치는 제2 라이트 필드 영상의 뷰 수를 3X3으로 결정하고, 제1 라이트 필드 영상 에 대해 서브 샘플링을 수행하여 3X3 뷰 수의 뷰 영상들을 포함하는 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 라이트 필드 영상의 뷰 간 디스패리티 및 디스플레이가 표현 가능한 뷰 간 디스패리티를 식별하고, 그에 기초하여 뷰 수를 결정할 수 있다. 예를 들어, 전자 장치는 제 1 라이트 필드 영상의 뷰 간 디스패리티가 2이고, 디스플레이가 표현 가능한 뷰 간 디스패리티가 1임을 식 별할 수 있다. 인공 지능 모델에 입력되는 라이트 필드 영상의 뷰 간 디스패리티가 디스플레이가 표현 가능한 뷰 간 디스패리티와 동일해야 한다는 학습 규칙에 따르는 경우, 전자 장치는 제1 라이트 필드 영상의 픽셀들을 한 칸씩 띄워 배치함으로써, 제1 라이트 필드 영상의 뷰 간 디스패리티를 1로 감소시킬 수 있다. 제1 라이트 필드 영상의 픽셀들을 한 칸씩 띄워 배치하기 위하여, 전자 장치는 제2 라이트 필드 영상 의 뷰 수를 3X3으로 결정할 수 있다. 이후, 전자 장치는 결정된 뷰 수에 따라 제1 라이트 필드 영상에 대해 서브 샘플링을 수행하여 라이 트 필드 영상을 획득할 수 있다. 예를 들어, 결정된 뷰 수가 3X3인 경우, 전자 장치는 제1 라이트 필 드 영상에 대해 서브 샘플링을 수행하여 3X3 뷰 수의 라이트 필드 영상을 획득할 수 있다.일 실시예에 따르면, 전자 장치는 서브 샘플링을 수행하여 획득된 라이트 필드 영상에 보간법을 수행 하여 제2 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 3X3 뷰 수의 라이트 필드 영 상에 보간법을 수행하여 3X3 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 도 8a 및 도 8b는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 보간법을 수행하는 과정을 설명하는 도면이다. 도 8a를 참조하면, 전자 장치는 일 실시예에 따라 라이트 필드 영상에 EPI(epipolar plane image) 보간법 을 수행할 수 있다. EPI 보간법을 수행하기 위하여, 전자 장치는 각각의 뷰 영상 내 특정 행에 포함된 픽 셀들을 식별할 수 있다. 예를 들어, 라이트 필드 영상이 n 개의 뷰 영상들을 포함하는 경우, 전자 장치는 제1 뷰 영상 내 m 번째 행에 포함된 픽셀들을 식별할 수 있다. 또한, 전자 장치는 제2 뷰 영상 내 m 번째 행에 포함된 픽셀들을 식별할 수 있고, 제n 뷰 영상 내 m 번째 행에 포함된 픽셀들 을 식별할 수 있다. 도 8b를 참조하면, 전자 장치는 각각의 뷰 영상 내 특정 행에 포함된 픽셀들을 뷰 영상의 순서에 따라 쌓 아 EPI 영상을 획득할 수 있다. 예를 들어, 전자 장치는 m 번째 행에 포함된 픽셀들 집합 n 개를 뷰 영상의 순서에 따라 쌓아 EPI 영상을 획득할 수 있다. 이때, EPI 영상은 특정 객체에 대응하는 픽셀 들의 이동의 경향성을 나타낼 수 있다. 예를 들어, 특정 객체에 대응하는 픽셀들이 형성하는 기울기가 크다는 것은 특정 객체의 뷰에 따른 움직임이 크다는 것을 나타낼 수 있고, 특정 객체에 대응하는 픽셀들이 형성하는 기울기가 작다는 것은 특정 객체의 뷰에 따른 움직임이 작다는 것을 나타낼 수 있다. 일 실시예에 따르면, 전자 장치는 EPI 영상에 EPI 보간법을 수행하여 EPI 보간된(interpolated) 영 상을 획득할 수 있다. 예를 들어, n 개의 뷰 수의 라이트 필드 영상으로부터 (2n-1) 개의 뷰 수의 라이트 필드 영상을 획득하고자 하는 경우, 전자 장치는 EPI 영상에 EPI 보간법을 수행하여, (2n-1) 개의 픽 셀들 집합들을 포함하는 EPI 보간된 영상을 획득할 수 있다. 이때, 전자 장치는 (2n-1) 개의 픽셀들 집합들을 포함하는 EPI 보간된 영상을 획득하기 위하여, EPI 영상에 포함된 n 개의 픽셀들 집합들의 사이에 (n-1) 개의 보간된 픽셀들 집합들을 추가할 수 있다. 한편, 도 8a 및 도 8b는 전자 장치가 라이트 필드 영상의 각각의 뷰 영상 내 특정 행에 포함된 픽셀들을 식별하고, 이에 기초하여 보간법을 수행하는 것으로 도시하나, 전자 장치는 라이트 필드 영상의 각각의 뷰 영상 내 특정 열에 포함된 픽셀들을 식별하고, 이에 기초하여 보간법을 수행할 수 있다. 도 9는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득하는 과정을 설명하기 위한 도면이다. 일 실시예에 따르면, 전자 장치는 제1 라이트 필드 영상으로부터 획득한 제2 라이트 필드 영상 내 서브 픽 셀들 각각에 대응하는 위치 정보를 획득할 수 있다. 예를 들어, 제2 라이트 필드 영상의 포맷이 3X3이고, 해상도가 3X3인 경우, 전자 장치는 제2 라이트 필드 내 서브 픽셀들 각각이 위치한 열(row)에 관한 정보를 포함하는 위치 정보를 획득할 수 있다. 또한, 전자 장치는 제2 라이트 필드 내 서브 픽 셀들 각각이 위치한 행(column)에 관한 정보를 포함하는 위치 정보를 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 팩토리제이션을 수행하기 위한 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보(920, 940)를 입력하여 레이어 영상을 획득할 수 있다. 전자 장치는 제2 라이트 필드 영상과 함께 위치 정보(920, 940)를 입력하여 제2 라이트 필드 영상 내 마스킹된 서브 픽셀 또는 보 간된 서브 픽셀의 위치를 나타냄으로써, 인공 지능 모델의 성능을 향상시킬 수 있다. 도 10은 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시 키는 과정을 설명하기 위한 도면이다. 일 실시예에 따르면, 제1 라이트 필드 영상은 레이어 영상이 렌더링될 디스플레이가 표현할 수 있는 최대 뷰 수의 뷰 영상들을 포함할 수 있다. 예를 들어, 레이어 영상이 렌더링될 디스플레이가 표현할 수 있는 최대 뷰 수가 5X5인 경우, 제1 라이트 필드 영상은 5X5 개의 뷰 영상들을 포함할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상은 레이어 영상이 렌더링될 디스플레이의 해상도를 가지는 뷰 영상들을 포함할 수 있다. 예를 들어, 레이어 영상이 렌더링될 디스플레이의 해상도가 3X3인 경우, 제1 라이트 필드 영상은 3X3의 해상도를 가지는 뷰 영상들을 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수] 또는 제1 라이트 필드 영상의 뷰 간 디스패리티 등에 기초하여 제2 뷰 수를 결정하고, 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]가 [3X3, 5X5]인 경우, 전자 장치는 제2 뷰 수를 3X3으로 결정하고, 결정된 제2 뷰 수에 기초하여 마스크를 생성할 수 있다. 전자 장치는 생성된 마스크에 기초하여 제1 라이트 필드 영상에 마스킹을 수행하여 3X3 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득할 수 있다. 예를 들어, 제2 라이트 필드 영상의 포맷이 5X5이고, 해상도가 3X3인 경우, 전 자 장치는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있 다. 일 실시예에 따르면, 전자 장치는 팩토리제이션을 수행하기 위한 제1 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력하여 레이어 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 시뮬레이션 모델에 레이어 영상을 입력하여 제3 뷰 수의 제3 라이 트 필드 영상을 획득할 수 있다. 이때, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시 나리오의 [입력 뷰 수, 출력 뷰 수]에 기초하여, 출력 뷰 수의 제3 라이트 필드 영상을 획득할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]가 [3X3, 5X5]인 경우, 전자 장치는 5X5 뷰 수의 제3 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 플로우(flow) 값을 획득하기 위한 제2 인공 지능 모델에 제2 라이트 필 드 영상 및 위치 정보를 입력하여 플로우 값을 획득할 수 있다. 플로우 값 또는 픽셀 이동 값은 적층형 디스플레이에서 표현할 수 있는 뎁스 범위를 벗어나는 영역의 화질, 해상도 또는 시야 각의 표현 품질이 저하되지 않도록, 라이트 필드 영상 내 뎁스 범위를 벗어나는 영역의 뎁스를 변경하기 위한 픽셀의 이동 값을 의미할 수 있다. 즉, 플로우 값은 라이트 필드 영상에서 일 영역의 픽셀을 이동 시키기 위한 값을 의미할 수 있다. 한편, 제2 인공 지능 모델은 제2 라이트 필드 영상에 대응되는 픽셀 이동 값을 획득하기 위한 인공 지능 모델로, DNN(Deep Neural Network) 기반의 인공 지능 모델일 수 있다. 다만, 이는 일 실시예에 불과하며, 이에 한정되지 않는다. 일 실시예에 따르면, 전자 장치는 플로우 값에 기초하여 제1 라이트 필드 영상에 와핑 기법을 수행하여 제1 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 제1 라이트 필드 영상 에 포함된 뷰 영상들의 픽셀들을 플로우 값에 따라 이동시켜 제1 라이트 필드 영상을 획득할 수 있다. 한편, 도 10은 전자 장치가 제2 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력 하여 플로우 값을 획득하는 것으로 도시하지만, 전자 장치는 제2 인공 지능 모델에 제1 라이트 필드 영상을 입력하여 플로우 값을 획득할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상과 제3 라이트 필드 영상의 뷰 수가 동일한 경우, 전자 장치는 제1 라이트 필드 영상의 유효 영역을 선택하는 과정을 생략할 수 있다. 예를 들어, 제1 라이 트 필드 영상의 뷰 수가 5X5이고, 제3 라이트 필드 영상의 뷰 수 또한 5X5로 동일한 경우, 전자 장 치는 제1 라이트 필드 영상의 유효 영역을 선택하는 과정을 생략할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 제1 인공 지능 모델을 학습시킬 수 있다. 예를 들어, 전자 장치는 제1 라이트 필드 영상 과 제3 라이트 필드 영상을 비교하여 손실 함수를 획득하고, 손실 함수를 바탕으로 손실을 계산하 여, 제1 인공 지능 모델을 학습시킬 수 있다. 한편, 도 10은 전자 장치가 플로우 값을 획득하고, 플로우 값에 기초하여 와핑 기법을 수행하는 것으로 도시하나, 전자 장치는 플로우 값을 획득하지 않거나 플로우 값에 기초하여 와핑 기법을 수행 하지 않을 수 있다. 이 경우, 전자 장치는 제1 라이트 필드 영상과 제3 라이트 필드 영상을비교한 결과에 기초하여 제1 인공 지능 모델을 학습시킬 수 있다. 도 11은 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시 키는 과정을 설명하기 위한 도면이다. 도 10과 중복되는 동작은 간략히 설명하거나 생략하기로 한다. 일 실시예에 따르면, 제1 라이트 필드 영상은 레이어 영상이 렌더링될 디스플레이가 표현할 수 있는 최대 뷰 수의 뷰 영상들을 포함할 수 있다. 예를 들어, 레이어 영상이 렌더링될 디스플레이가 표현할 수 있는 최대 뷰 수가 5X5인 경우, 제1 라이트 필드 영상은 5X5 개의 뷰 영상들을 포함할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상은 레이어 영상이 렌더링될 디스플레이의 해상도를 가지는 뷰 영상들을 포함할 수 있다. 예를 들어, 레이어 영상이 렌더링될 디스플레이의 해상도가 3X3인 경우, 제1 라이트 필드 영상은 3X3의 해상도를 가지는 뷰 영상들을 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수] 또는 제1 라이트 필드 영상의 뷰 간 디스패리티 등에 기초하여 제2 뷰 수를 결정하고, 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]가 [1X5, 3X5]인 경우, 전자 장치는 제2 뷰 수를 1X5로 결정하고, 결정된 제2 뷰 수에 기초하여 마스크를 생성할 수 있다. 전자 장치는 생성된 마스크에 기초하여 제1 라이트 필드 영상에 마스킹을 수행하여 1X5 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득할 수 있다. 예를 들어, 제2 라이트 필드 영상의 포맷이 5X5이고, 해상도가 3X3인 경우, 전 자 장치는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있 다. 일 실시예에 따르면, 전자 장치는 팩토리제이션을 수행하기 위한 제1 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력하여 레이어 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 시뮬레이션 모델에 레이어 영상을 입력하여 제3 뷰 수의 제3 라이 트 필드 영상을 획득할 수 있다. 이때, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시 나리오의 [입력 뷰 수, 출력 뷰 수]에 기초하여, 출력 뷰 수의 제3 라이트 필드 영상을 획득할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]가 [1X5, 3X5]인 경우, 전자 장치는 3X5 뷰 수의 제3 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 플로우 값을 획득하기 위한 제2 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력하여 플로우 값을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 플로우 값에 기초하여 제1 라이트 필드 영상에 와핑 기법을 수행하여 제1 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 제1 라이트 필드 영상 에 포함된 뷰 영상들의 픽셀들을 플로우 값에 따라 이동시켜 제1 라이트 필드 영상을 획득할 수 있다. 한편, 도 11은 전자 장치가 제2 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력 하여 플로우 값을 획득하는 것으로 도시하지만, 전자 장치는 제2 인공 지능 모델에 제1 라이트 필드 영상을 입력하여 플로우 값을 획득할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상과 제3 라이트 필드 영상의 뷰 수가 상이한 경우, 전자 장치는 제3 라이트 필드 영상의 뷰 수와 동일하도록 제1 라이트 필드 영상의 유효 영역을 선 택하여 제1 라이트 필드 영상을 획득할 수 있다. 예를 들어, 제1 라이트 필드 영상의 뷰 수가 5X5 이고 제3 라이트 필드 영상의 뷰 수는 3X5인 경우, 전자 장치는 제1 라이트 필드 영상에서 3X5의 유효 영역을 선택하여 제1 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 제1 인공 지능 모델을 학습시킬 수 있다. 예를 들어, 전자 장치는 제1 라이트 필드 영상과 제3 라이트 필드 영상을 비교하여 손실 함수를 획득하고, 손실 함수를 바탕으로 손실을 계산하 여, 제1 인공 지능 모델을 학습시킬 수 있다. 한편, 도 11은 전자 장치가 플로우 값을 획득하고, 플로우 값에 기초하여 와핑 기법을 수행하는 것으로 도시하나, 전자 장치는 플로우 값을 획득하지 않거나 플로우 값에 기초하여 와핑 기법을 수행 하지 않을 수 있다. 이 경우, 전자 장치는 제1 라이트 필드 영상에서 유효 영역을 선택하고, 유효 영역이 선택된 제1 라이트 필드 영상과 제3 라이트 필드 영상을 비교한 결과에 기초하여 제1 인공 지능 모델을 학습시킬 수 있다. 도 12는 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시 키는 과정을 설명하기 위한 도면이다. 도 10과 중복되는 동작은 간략히 설명하거나 생략하기로 한다. 일 실시예에 따르면, 제1 라이트 필드 영상은 레이어 영상이 렌더링될 디스플레이가 표현할 수 있는 최대 뷰 수의 뷰 영상들을 포함할 수 있다. 예를 들어, 레이어 영상이 렌더링될 디스플레이가 표현할 수 있는 최대 뷰 수가 5X5인 경우, 제1 라이트 필드 영상은 5X5 개의 뷰 영상들을 포함할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상은 레이어 영상이 렌더링될 디스플레이의 해상도를 가지는 뷰 영상들을 포함할 수 있다. 예를 들어, 레이어 영상이 렌더링될 디스플레이의 해상도가 3X3인 경우, 제1 라이트 필드 영상은 3X3의 해상도를 가지는 뷰 영상들을 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 전자 장치는 인공 지 능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수] 또는 제1 라이트 필드 영상의 뷰 간 디스패리티 등에 기초하여 제2 뷰 수를 결정하고, 제1 라이트 필드 영상에 보간법을 수행하여 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]가 [3X3, 5X5]인 경우, 전자 장치는 제1 라이트 필드 영상에 대해 서브 샘플링을 수행하여 3X3 뷰 수의 라이트 필드 영상을 획득할 수 있다. 전자 장치는 서브 샘플링을 수행하여 획득된 라이트 필드 영상에 보 간법을 수행하여 3X3 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득할 수 있다. 예를 들어, 제2 라이트 필드 영상의 포맷이 5X5이고, 해상도가 3X3인 경우, 전 자 장치는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있 다. 일 실시예에 따르면, 전자 장치는 팩토리제이션을 수행하기 위한 제1 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력하여 레이어 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 시뮬레이션 모델에 레이어 영상을 입력하여 제3 뷰 수의 제3 라이 트 필드 영상을 획득할 수 있다. 이때, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시 나리오의 [입력 뷰 수, 출력 뷰 수]에 기초하여, 출력 뷰 수의 제3 라이트 필드 영상을 획득할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]가 [3X3, 5X5]인 경우, 전자 장치는 5X5 뷰 수의 제3 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 플로우 값을 획득하기 위한 제2 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력하여 플로우 값을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 플로우 값에 기초하여 제1 라이트 필드 영상에 와핑 기법을 수행하여 제1 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 제1 라이트 필드 영상 에 포함된 뷰 영상들의 픽셀들을 플로우 값에 따라 이동시켜 제1 라이트 필드 영상을 획득할 수 있다. 한편, 도 12는 전자 장치가 제2 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력 하여 플로우 값을 획득하는 것으로 도시하지만, 전자 장치는 제2 인공 지능 모델에 제1 라이트 필드 영상을 입력하여 플로우 값을 획득할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상과 제3 라이트 필드 영상의 뷰 수가 동일한 경우, 전자 장치는 제1 라이트 필드 영상의 유효 영역을 선택하는 과정을 생략할 수 있다. 예를 들어, 제1 라이 트 필드 영상의 뷰 수가 5X5이고, 제3 라이트 필드 영상의 뷰 수 또한 5X5로 동일한 경우, 전자 장 치는 제1 라이트 필드 영상의 유효 영역을 선택하는 과정을 생략할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 제1 인공 지능 모델을 학습시킬 수 있다. 예를 들어, 전자 장치는 제1 라이트 필드 영상 과 제3 라이트 필드 영상을 비교하여 손실 함수를 획득하고, 손실 함수를 바탕으로 손실을 계산하 여, 제1 인공 지능 모델을 학습시킬 수 있다. 한편, 도 12는 전자 장치가 플로우 값을 획득하고, 플로우 값에 기초하여 와핑 기법을 수행하는 것으로 도시하나, 전자 장치는 플로우 값을 획득하지 않거나 플로우 값에 기초하여 와핑 기법을 수행 하지 않을 수 있다. 이 경우, 전자 장치는 제1 라이트 필드 영상과 제3 라이트 필드 영상을 비교한 결과에 기초하여 제1 인공 지능 모델을 학습시킬 수 있다. 도 13은 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시 키는 과정을 설명하기 위한 도면이다. 도 10과 중복되는 동작은 간략히 설명하거나 생략하기로 한다. 일 실시예에 따르면, 제1 라이트 필드 영상은 레이어 영상이 렌더링될 디스플레이가 표현할 수 있는 최대 뷰 수의 뷰 영상들을 포함할 수 있다. 예를 들어, 레이어 영상이 렌더링될 디스플레이가 표현할 수 있는 최대 뷰 수가 3X7인 경우, 제1 라이트 필드 영상은 3X7 개의 뷰 영상들을 포함할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상은 레이어 영상이 렌더링될 디스플레이의 해상도를 가지는 뷰 영상들을 포함할 수 있다. 예를 들어, 레이어 영상이 렌더링될 디스플레이의 해상도가 3X2인 경우, 제1 라이트 필드 영상은 3X2의 해상도를 가지는 뷰 영상들을 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수] 또는 제1 라이트 필드 영상의 뷰 간 디스패리티 등에 기초하여 제2 뷰 수를 결정하고, 제1 라이트 필드 영상에 보간법을 수행하여 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영상을 획득할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]가 [3X3, 3X7]인 경우, 전자 장치는 제1 라이트 필드 영상에 대해 서브 샘플링을 수행하여 3X3 뷰 수의 라이트 필드 영상을 획득할 수 있다. 전자 장치는 서브 샘플링을 수행하여 획득된 라이트 필드 영상에 보 간법을 수행하여 3X3 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득할 수 있다. 예를 들어, 제2 라이트 필드 영상의 포맷이 3X7이고, 해상도가 3X2인 경우, 전 자 장치는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있 다. 일 실시예에 따르면, 전자 장치는 팩토리제이션을 수행하기 위한 제1 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력하여 레이어 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 시뮬레이션 모델에 레이어 영상을 입력하여 제3 뷰 수의 제3 라이 트 필드 영상을 획득할 수 있다. 이때, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시 나리오의 [입력 뷰 수, 출력 뷰 수]에 기초하여, 출력 뷰 수의 제3 라이트 필드 영상을 획득할 수 있다. 예를 들어, 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]가 [3X3, 3X7]인 경우, 전자 장치는 3X7 뷰 수의 제3 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 플로우 값을 획득하기 위한 제2 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력하여 플로우 값을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 플로우 값에 기초하여 제1 라이트 필드 영상에 와핑 기법을 수행하여 제1 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 제1 라이트 필드 영상 에 포함된 뷰 영상들의 픽셀들을 플로우 값에 따라 이동시켜 제1 라이트 필드 영상을 획득할 수 있다.한편, 도 13은 전자 장치가 제2 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력 하여 플로우 값을 획득하는 것으로 도시하지만, 전자 장치는 제2 인공 지능 모델에 제1 라이트 필드 영상을 입력하여 플로우 값을 획득할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상과 제3 라이트 필드 영상의 뷰 수가 동일한 경우, 전자 장치는 제1 라이트 필드 영상의 유효 영역을 선택하는 과정을 생략할 수 있다. 예를 들어, 제1 라이 트 필드 영상의 뷰 수가 3X7이고, 제3 라이트 필드 영상의 뷰 수 또한 3X7로 동일한 경우, 전자 장 치는 제1 라이트 필드 영상의 유효 영역을 선택하는 과정을 생략할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 제1 인공 지능 모델을 학습시킬 수 있다. 예를 들어, 전자 장치는 제1 라이트 필드 영상 과 제3 라이트 필드 영상을 비교하여 손실 함수를 획득하고, 손실 함수를 바탕으로 손실을 계산하 여, 제1 인공 지능 모델을 학습시킬 수 있다. 한편, 도 13은 전자 장치가 플로우 값을 획득하고, 플로우 값에 기초하여 와핑 기법을 수행하는 것으로 도시하나, 전자 장치는 플로우 값을 획득하지 않거나 플로우 값에 기초하여 와핑 기법을 수행 하지 않을 수 있다. 이 경우, 전자 장치는 제1 라이트 필드 영상과 제3 라이트 필드 영상을 비교한 결과에 기초하여 제1 인공 지능 모델을 학습시킬 수 있다. 도 14는 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행 하는 과정을 설명하기 위한 도면이다. 일 실시예에 따르면, 전자 장치는 제4 뷰 수의 제4 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치가 라이트 필드 카메라를 포함하는 경우, 전자 장치는 라이트 필드 카메라를 통해 3X3의 해 상도를 가지는 3X3 뷰 수의 제4 라이트 필드 영상을 획득할 수 있다. 또는, 전자 장치가 송수신부를 포함하는 경우, 전자 장치는 외부의 라이트 필드 카메라 또는 외부의 전자 장치로부터 3X3의 해상도를 가 지는 3X3 뷰 수의 제4 라이트 필드 영상을 수신할 수 있다. 일 실시예에 따르면, 전자 장치는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각(viewing angle)에 적합한지 판단할 수 있다. 예를 들어, 전자 장치는 제4 라이트 필 드 영상의 뷰 수와 레이어 영상이 렌더링될 디스플레이의 시야각에 대응하는 뷰 수의 크기를 비교 할 수 있다. 이때, 디스플레이의 시야각에 대응하는 뷰 수는 고정된 시청거리에서 화질 열화가 없도록 결정되거 나, 근사적으로 일정 거리 이상의 시청 거리에서 모두 화질 열화가 없도록 결정될 수 있다. 다만, 이는 일 실시 예에 불과하며, 이에 한정되지 않는다. 일 실시예에 따르면, 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야 각에 대응하는 뷰 수보다 크거나 같은 경우, 전자 장치는 학습된 인공 지능 모델에 제4 라이트 필드 영상 을 입력할 수 있다. 또는, 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플 레이의 시야각에 대응하는 뷰 수보다 작은 경우, 전자 장치는 제4 라이트 필드 영상의 포맷을 변경 하여 제5 라이트 필드 영상(1420, 1430)을 획득하고, 획득한 제5 라이트 필드 영상(1420, 1430)을 학습된 인공 지능 모델에 입력할 수 있다. 한편, 제4 라이트 필드 영상의 포맷을 변경하여 제5 라이트 필드 영상 (1420, 1430)을 획득함에 따라, 제5 라이트 필드 영상(1420, 1430)은 레이어 영상이 렌더링될 디스플레이 의 시야각에 대응하는 뷰 수와 동일한 크기의 포맷을 가질 수 있다. 일 실시예에 따르면, 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야 각에 적합하지 않은 경우, 전자 장치는 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정한 지를 판 단하고 그에 기초하여 제5 라이트 필드 영상(1420, 1430)을 획득할 수 있다. 예를 들어, 제4 라이트 필드 영상 의 뷰 간 디스패리티가 일정하지 않은 경우, 전자 장치는 제4 라이트 필드 영상에 마스킹을 수행하여 제5 라이트 필드 영상을 획득할 수 있다. 또는, 제4 라이트 필드 영상의 뷰 간 디스패리 티가 일정한 경우, 전자 장치는 제4 라이트 필드 영상에 마스킹 또는 보간법을 수행하여 제5 라이트 필드 영상(1420, 1430)을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제4 라이트 필드 영상 또는 제5 라이트 필드 영상(1420, 1430) 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있다. 예를 들어, 제4 라이트 필드 영상 또는 제5 라이트 필드 영상(1420, 1430)의 포맷이 5X5이고, 해상도가 3X3인 경우, 전자 장치는 제4 라이트 필드 영상 또는 제5 라이트 필드 영상(1420, 1430) 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할수 있다. 일 실시예에 따르면, 전자 장치는 학습된 인공 지능 모델에 제4 라이트 필드 영상 또는 제5 라이트 필드 영상(1420, 1430) 및 위치 정보를 입력하여 레이어 영상을 획득할 수 있다. 일 실시예에 따르면, 레이어 영상은 디스플레이에 렌더링될 수 있다. 예를 들어, 전자 장치가 디스 플레이를 포함하는 경우, 전자 장치는 레이어 영상을 디스플레이에 렌더링할 수 있다. 또는, 전자 장치가 송수신부를 포함하는 경우, 전자 장치는 송수신부를 통해 레이어 영상을 디스플레이를 포함 하는 외부의 전자 장치로 송신하고, 레이어 영상 외부의 전자 장치에 의해 디스플레이에 렌더링 될 수 있 다. 도 15는 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행 하는 과정을 설명하기 위한 도면이다. 일 실시예에 따르면, 전자 장치는 제4 뷰 수의 제4 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 3X3의 해상도를 가지는 5X5 뷰 수의 제4 라이트 필드 영상을 수신할 수 있다. 일 실시예에 따르면, 전자 장치는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각에 적합한지 판단할 수 있다. 예를 들어, 디스플레이의 시야각에 대응하는 뷰 수가 5X5인 경우, 제4 라이트 필드 영상의 뷰 수가 디스플레이의 시야각에 대응하는 뷰 수와 같으므로, 전자 장치 는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각에 적합하다 고 판단할 수 있다. 일 실시예에 따르면, 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야 각에 적합한 경우, 전자 장치는 제4 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득할 수 있다. 예를 들어, 제4 라이트 필드 영상의 포맷이 5X5이고, 해상도가 3X3인 경우, 전 자 장치는 제4 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있 다. 일 실시예에 따르면, 전자 장치는 학습된 인공 지능 모델에 제4 라이트 필드 영상 및 위치 정보 를 입력하여 레이어 영상을 획득할 수 있다. 도 16은 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행 하는 과정을 설명하기 위한 도면이다. 일 실시예에 따르면, 전자 장치는 제4 뷰 수의 제4 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 3X3의 해상도를 가지는 3X3 뷰 수의 제4 라이트 필드 영상을 수신할 수 있다. 일 실시예에 따르면, 전자 장치는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각에 적합한지 판단할 수 있다. 예를 들어, 디스플레이의 시야각에 대응하는 뷰 수가 5X5인 경우, 제4 라이트 필드 영상의 뷰 수는 3X3으로서 디스플레이의 시야각에 대응하는 뷰 수와 상이하므로, 전자 장치는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각에 적합하지 않다고 판단할 수 있다. 일 실시예에 따르면, 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야 각에 적합하지 않은 경우, 전자 장치는 전자 장치는 제4 라이트 필드 영상의 뷰 간 디스패리티 가 일정한 지를 판단하고 그에 기초하여 제5 라이트 필드 영상을 획득할 수 있다. 예를 들어, 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정하거나 일정하지 않은 경우, 전자 장치는 제4 라이트 필드 영 상에 마스킹을 수행할 수 있다. 그 결과, 전자 장치는 5X5 포맷을 가지는 3X3 뷰 수의 제5 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득할 수 있다. 예를 들어, 제5 라이트 필드 영상의 포맷이 5X5이고, 해상도가 3X3인 경우, 전 자 장치는 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있 다. 일 실시예에 따르면, 전자 장치는 학습된 인공 지능 모델에 제5 라이트 필드 영상 및 위치 정보 를 입력하여 레이어 영상을 획득할 수 있다.도 17 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행하 는 과정을 설명하기 위한 도면이다. 일 실시예에 따르면, 전자 장치는 제4 뷰 수의 제4 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 3X3의 해상도를 가지는 1X5 뷰 수의 제4 라이트 필드 영상을 수신할 수 있다. 일 실시예에 따르면, 전자 장치는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각에 적합한지 판단할 수 있다. 예를 들어, 디스플레이의 시야각에 대응하는 뷰 수가 5X5인 경우, 제4 라이트 필드 영상의 뷰 수는 1X5로서 디스플레이의 시야각에 대응하는 뷰 수와 상이하므로, 전 자 장치는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각에 적합하지 않다고 판단할 수 있다. 일 실시예에 따르면, 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야 각에 적합하지 않은 경우, 전자 장치는 전자 장치는 제4 라이트 필드 영상의 뷰 간 디스패리티 가 일정한 지를 판단하고 그에 기초하여 제5 라이트 필드 영상을 획득할 수 있다. 예를 들어, 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정하거나 일정하지 않은 경우, 전자 장치는 제4 라이트 필드 영 상에 마스킹을 수행할 수 있다. 그 결과, 전자 장치는 5X5 포맷을 가지는 1X5 뷰 수의 제5 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득할 수 있다. 예를 들어, 제5 라이트 필드 영상의 포맷이 5X5이고, 해상도가 3X3인 경우, 전 자 장치는 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있 다. 일 실시예에 따르면, 전자 장치는 학습된 인공 지능 모델에 제5 라이트 필드 영상 및 위치 정보 를 입력하여 레이어 영상을 획득할 수 있다. 도 18 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행하 는 과정을 설명하기 위한 도면이다. 일 실시예에 따르면, 전자 장치는 제4 뷰 수의 제4 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 3X3의 해상도를 가지는 3X3 뷰 수의 제4 라이트 필드 영상을 수신할 수 있다. 일 실시예에 따르면, 전자 장치는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각에 적합한지 판단할 수 있다. 예를 들어, 디스플레이의 시야각에 대응하는 뷰 수가 5X5인 경우, 제4 라이트 필드 영상의 뷰 수는 3X3로서 디스플레이의 시야각에 대응하는 뷰 수와 상이하므로, 전 자 장치는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각에 적합하지 않다고 판단할 수 있다. 일 실시예에 따르면, 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야 각에 적합하지 않은 경우, 전자 장치는 전자 장치는 제4 라이트 필드 영상의 뷰 간 디스패리티 가 일정한 지를 판단하고 그에 기초하여 제5 라이트 필드 영상을 획득할 수 있다. 예를 들어, 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정한 경우, 전자 장치는 제4 라이트 필드 영상에 보간법을 수행할 수 있다. 그 결과, 전자 장치는 5X5 포맷을 가지는 3X3 뷰 수의 제5 라이트 필드 영상을 획 득할 수 있다. 일 실시예에 따르면, 전자 장치는 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득할 수 있다. 예를 들어, 제5 라이트 필드 영상의 포맷이 5X5이고, 해상도가 3X3인 경우, 전 자 장치는 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있 다. 일 실시예에 따르면, 전자 장치는 학습된 인공 지능 모델에 제5 라이트 필드 영상 및 위치 정보 를 입력하여 레이어 영상을 획득할 수 있다. 도 19 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행하 는 과정을 설명하기 위한 도면이다. 일 실시예에 따르면, 전자 장치는 제4 뷰 수의 제4 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 3X2의 해상도를 가지는 3X3 뷰 수의 제4 라이트 필드 영상을 수신할 수 있다. 일 실시예에 따르면, 전자 장치는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각에 적합한지 판단할 수 있다. 예를 들어, 디스플레이의 시야각에 대응하는 뷰 수가 3X7인 경우, 제4 라이트 필드 영상의 뷰 수는 3X3로서 디스플레이의 시야각에 대응하는 뷰 수와 상이하므로, 전 자 장치는 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야각에 적합하지 않다고 판단할 수 있다. 일 실시예에 따르면, 제4 라이트 필드 영상의 뷰 수가 레이어 영상이 렌더링될 디스플레이의 시야 각에 적합하지 않은 경우, 전자 장치는 전자 장치는 제4 라이트 필드 영상의 뷰 간 디스패리티 가 일정한 지를 판단하고 그에 기초하여 제5 라이트 필드 영상을 획득할 수 있다. 예를 들어, 제4 라이트 필드 영상의 뷰 간 디스패리티가 일정한 경우, 전자 장치는 제4 라이트 필드 영상에 보간법을 수행할 수 있다. 그 결과, 전자 장치는 3X7 포맷을 가지는 3X3 뷰 수의 제5 라이트 필드 영상을 획 득할 수 있다. 일 실시예에 따르면, 전자 장치는 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득할 수 있다. 예를 들어, 제5 라이트 필드 영상의 포맷이 3X7이고, 해상도가 3X2인 경우, 전 자 장치는 제5 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있 다. 일 실시예에 따르면, 전자 장치는 학습된 인공 지능 모델에 제5 라이트 필드 영상 및 위치 정보 를 입력하여 레이어 영상을 획득할 수 있다. 도 20은 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시키는 과정을 나타내는 흐름도이다. S2010 단계에서, 전자 장치는 제1 뷰 수의 뷰 영상들을 포함하는 제1 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치가 라이트 필드 카메라를 포함하는 경우, 전자 장치는 라이트 필드 카메라를 통 해 제1 뷰 수의 제1 라이트 필드 영상을 획득할 수 있다. 또는, 전자 장치가 송수신부를 포함하는 경우, 전자 장치는 외부의 라이트 필드 카메라 또는 외부의 전자 장치로부터 제1 뷰 수의 제1 라이트 필드 영상을 수신할 수 있다. S2020 단계에서, 전자 장치는 제1 라이트 필드 영상으로부터 제2 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필 드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수] 또는 제1 라이트 필드 영상의 뷰 간 디스패리티 등에 기초하여 제2 뷰 수를 결정하고, 제1 라이트 필드 영상에 마스킹 또는 보간법을 수행하여 제2 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 예를 들어, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]에 따라 입력 뷰 수를 제2 뷰 수로 결정하고, 제1 라이트 필드 영상으로부터 입력 뷰 수의 뷰 영상들을 포함하는 제2 라이트 필드 영 상을 획득할 수 있다. 일 실시예에 따르면, 제1 라이트 필드 영상의 뷰 간 디스패리티가 일정하지 않은 경우, 전자 장치는 제1 라이트 필드 영상에 마스킹을 수행하여 제2 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. 또는, 제1 라이트 필드 영상의 뷰 간 디스패리티가 일정한 경우, 전자 장치는 제1 라이트 필드 영상에 마스킹 또는 보간법을 수행하여 제2 뷰 수의 제2 라이트 필드 영상을 획득할 수 있다. S2030 단계에서, 전자 장치는 제2 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보를 획득할 수 있 다. S2040 단계에서, 전자 장치는 팩토리제이션을 수행하기 위한 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력하여 레이어 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 플로우 값을 획득하기 위한 인공 지능 모델에 제2 라이트 필드 영상 및 위치 정보를 입력하여 플로우 값을 획득할 수 있다. 이후, 전자 장치는 플로우 값에 기초하여 제1 라이트 필드 영상 에 와핑 기법을 수행하여 픽셀 값이 이동된 제1 라이트 필드 영상을 획득할 수 있다. S2050 단계에서, 전자 장치는 시뮬레이션 모델에 레이어 영상을 입력하여 제3 뷰 수의 뷰 영상들을 포함하는 제 3 라이트 필드 영상을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 인공 지능 모델을 이용하여 대응하고자 하는 시나리오의 [입력 뷰 수, 출력 뷰 수]에 기초하여, 출력 뷰 수의 제3 라이트 필드 영상을 획득할 수 있다. S2060 단계에서, 전자 장치는 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 인공 지능 모델을 학습시킬 수 있다. 일 실시예에 따르면, 전자 장치는 제1 라이트 필드 영상과 제3 라이트 필드 영상을 비교하여 손실 함수를 획득 하고, 손실 함수를 바탕으로 손실을 계산하여, 인공 지능 모델을 학습시킬 수 있다. 일 실시예에 따르면, 전자 장치가 플로우 값을 획득하고 와핑 기법을 수행한 경우, 전자 장치는 와핑 기법을 수 행하여 획득한 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하여 인공 지능 모델을 학 습시킬 수 있다. 일 실시예에 따르면, 전자 장치는 제1 라이트 필드 영상과 제3 라이트 필드 영상의 뷰 수가 상이한 경우, 전자 장치는 제3 라이트 필드 영상의 뷰 수와 동일하도록 제1 라이트 필드 영상의 유효 영역을 선택할 수 있다. 이후, 전자 장치는 유효 영역이 선택된 제1 라이트 필드 영상 및 제3 라이트 필드 영상을 비교한 결과에 기초하 여 인공 지능 모델을 학습시킬 수 있다."}
{"patent_id": "10-2021-0167724", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치의 블록도이다. 도 2a는 본 개시의 일 실시예에 따른 라이트 필드 영상 및 레이어 영상의 일 예를 도시한다. 도 2b는 본 개시의 일 실시예에 따른 라이트 필드 영상 및 레이어 영상의 일 예를 도시한다. 도 3은 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시키는 과정을 설명하기 위한 도면이다. 도 4a는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 마스킹 또는 보간법을 수행하는 과정을 설명하는 도면이다. 도 4b는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 마스킹 또는 보간법을 수행하는 과정을 설명하는 도면이다. 도 5a는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 마스킹을 수행하는 과정을 설명하는 도면 이다. 도 5b는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 마스킹을 수행하는 과정을 설명하는 도면 이다. 도 5c는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 마스킹을 수행하는 과정을 설명하는 도면 이다. 도 6a는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 마스킹을 수행하는 과정을 설명하는 도면 이다.도 6b는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 마스킹을 수행하는 과정을 설명하는 도면 이다. 도 7은 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 보간법을 수행하는 과정을 설명하는 도면 이다. 도 8a는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 보간법을 수행하는 과정을 설명하는 도면 이다. 도 8b는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상에 보간법을 수행하는 과정을 설명하는 도면 이다. 도 9는 본 개시의 일 실시예에 따라 전자 장치가 라이트 필드 영상 내 서브 픽셀들 각각에 대응하는 위치 정보 를 획득하는 과정을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시키는 과정을 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시키는 과정을 설명하기 위한 도면이다. 도 12는 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시키는 과정을 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시키는 과정을 설명하기 위한 도면이다. 도 14는 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행하는 과정을 설명하기 위한 도면이다. 도 15는 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행하는 과정을 설명하기 위한 도면이다. 도 16은 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행하는 과정을 설명하기 위한 도면이다. 도 17은 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행하는 과정을 설명하기 위한 도면이다. 도 18은 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행하는 과정을 설명하기 위한 도면이다. 도 19는 본 개시의 일 실시예에 따라 전자 장치가 학습된 인공 지능 모델을 이용하여 팩토리제이션을 수행하는 과정을 설명하기 위한 도면이다. 도 20은 본 개시의 일 실시예에 따라 전자 장치가 팩토리제이션을 수행하기 위한 인공 지능 모델을 학습시키는 과정을 나타내는 흐름도이다."}
