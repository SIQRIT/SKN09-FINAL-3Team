{"patent_id": "10-2024-0042985", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0147601", "출원번호": "10-2024-0042985", "발명의 명칭": "AI 모델의 고도화를 자동적으로 수행하기 위한 방법, 장치 및 프로그램", "출원인": "주식회사 티벨", "발명자": "김종균"}}
{"patent_id": "10-2024-0042985", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "AI 모델의 고도화를 자동적으로 수행하기 위한 방법에 있어서,클라이언트로부터 라벨링이 완료된 제1 데이터를 획득하는 단계;상기 제1 데이터를 증강하여 제2 데이터를 생성하는 단계;상기 제1 데이터 및 상기 제2 데이터를 이용하여 적어도 하나의 모델을 학습시키는 단계; 및학습이 완료된 적어도 하나의 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 상기 학습이 완료된적어도 하나의 모델을 배포하는 단계;를 포함하는,AI 모델의 고도화를 자동적으로 수행하기 위한 방법."}
{"patent_id": "10-2024-0042985", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,클라이언트로부터 라벨링이 완료된 제1 데이터를 획득하는 단계는,상기 클라이언트로부터 제1 로우 데이터 및 제1 어노테이션 데이터를 획득하는 단계;를 포함하고,상기 제1 데이터를 증강하여 제2 데이터를 생성하는 단계는,상기 제1 로우 데이터를 증강하여 제2 로우 데이터를 생성하는 단계; 및상기 제1 어노테이션 데이터를 증강하여 제2 어노테이션 데이터를 생성하는 단계;를 포함하는,AI 모델의 고도화를 자동적으로 수행하기 위한 방법."}
{"patent_id": "10-2024-0042985", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,클라이언트로부터 라벨링이 완료된 제1 데이터를 획득하는 단계는,상기 클라이언트로부터 제1 로우 데이터 및 제1 어노테이션 데이터를 획득하는 단계;를 포함하고,상기 제1 데이터를 증강하여 제2 데이터를 생성하는 단계는,상기 제1 로우 데이터를 증강하여, 제2 로우 데이터를 생성하는 단계; 및 상기 제1 어노테이션 데이터를 기초로, 상기 제2 로우 데이터에 대한 어노테이션을 수행하여 제2 어노테이션 데이터를 생성하는 단계;를 포함하는,공개특허 10-2024-0147601-3-AI 모델의 고도화를 자동적으로 수행하기 위한 방법."}
{"patent_id": "10-2024-0042985", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 방법은,상기 적어도 하나의 모델의 학습이 완료된 경우, 불확실한 결과에 대응하는 특정 데이터를 인식하는 단계;상기 특정 데이터에 대한 어노테이션 데이터를 상기 클라이언트로 요청하는 단계;상기 클라이언트로부터 상기 어노테이션 데이터를 수신한 경우, 상기 특정 데이터 및 상기 어노테이션 데이터각각을 증강하여 제3 데이터를 생성하는 단계;상기 제3 데이터를 이용하여, 상기 특정 데이터와 관련된 특정 모델을 재학습시키는 단계; 및재학습이 완료된 상기 특정 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 상기 재학습이 완료된상기 특정 모델을 배포하는 단계;를 더 포함하는,AI 모델의 고도화를 자동적으로 수행하기 위한 방법."}
{"patent_id": "10-2024-0042985", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 방법은,상기 적어도 하나의 모델의 학습이 완료된 경우, 불확실한 결과에 대응하는 특정 데이터를 인식하는 단계;상기 특정 데이터에 대한 특정 어노테이션 데이터를 상기 클라이언트로 요청하는 단계;상기 클라이언트로부터 상기 특정 어노테이션 데이터를 수신한 경우, 상기 특정 데이터를 증강하여, 제3 로우데이터를 생성하는 단계;상기 특정 어노테이션 데이터를 기초로, 상기 제3 로우 데이터에 대한 어노테이션을 수행하여 제3 어노테이션데이터를 생성하는 단계;상기 특정 데이터, 상기 특정 어노테이션 데이터, 상기 제3 로우 데이터 및 상기 제3 어노테이션 데이터를 이용하여 상기 특정 데이터와 관련된 특정 모델을 재학습시키는 단계; 및재학습이 완료된 상기 특정 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 상기 재학습이 완료된상기 특정 모델을 배포하는 단계;를 더 포함하는,AI 모델의 고도화를 자동적으로 수행하기 위한 방법."}
{"patent_id": "10-2024-0042985", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4 항 또는 제5 항에 있어서,상기 불확실한 결과에 대응하는 특정 데이터를 인식하는 단계는,상기 적어도 하나의 모델에서 예측한 클래스들에 대한 확률 값이 기 설정된 확률 값과 기 설정된 크기 이내로차이나는 경우, 상기 클래스에 대응하는 데이터를 상기 특정 데이터로 인식하는 단계; 또는상기 적어도 하나의 모델에서 예측한 가장 높은 확률을 갖는 클래스와 두 번째로 높은 확률을 갖는 클래스 각각에 대한 확률 값의 차이가 기 설정된 값 이하인 경우, 상기 클래스에 대응하는 데이터를 상기 특정 데이터로 인공개특허 10-2024-0147601-4-식하는 단계;를 포함하는,AI 모델의 고도화를 자동적으로 수행하기 위한 방법."}
{"patent_id": "10-2024-0042985", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 방법은,검증 데이터셋을 이용하여, 학습이 완료된 상기 적어도 하나의 모델에 대한 검증을 수행하는 단계;상기 검증을 수행한 결과에서 정확도가 기 설정된 값 이하인 특정 클래스를 인식한 경우, 상기 특정 클래스에대응하는 데이터를 증강하여, 추가 증강 데이터를 생성하는 단계;상기 추가 증강 데이터에 대한 상기 특정 클래스의 어노테이션을 수행하여, 추가 어노테이션 데이터를 생성하는단계; 및상기 추가 증강 데이터 및 상기 추가 어노테이션 데이터를 기초로 상기 특정 클래스와 관련된 특정 모델을 재학습시키는 단계;를 더 포함하는,AI 모델의 고도화를 자동적으로 수행하기 위한 방법."}
{"patent_id": "10-2024-0042985", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 방법은,상기 검증 데이터셋을 이용하여, 재학습이 완료된 상기 특정 모델에 대한 재검증을 수행하는 단계;를 포함하고,상기 재검증을 수행한 결과에서 정확도가 기 설정된 값 이하인 특정 클래스를 인식한 경우, 상기 특정 클래스에대한 가중치를 증가시키거나, 상기 특정 클래스를 분류하기 위한 레이어를 추가하고,상기 재검증을 수행한 결과에서 정확도가 기 설정된 값 이하인 특정 클래스를 인식하지 못한 경우, 상기 특정모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 상기 재학습이 완료된 상기 특정 모델을 배포하는,AI 모델의 고도화를 자동적으로 수행하기 위한 방법."}
{"patent_id": "10-2024-0042985", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,제1 항의 방법을 수행하는, 장치."}
{"patent_id": "10-2024-0042985", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하드웨어인 컴퓨터와 결합되어, 제1 항의 방법을 수행할 수 있도록 컴퓨터에서 독출 가능한 기록매체에 저장된공개특허 10-2024-0147601-5-컴퓨터프로그램."}
{"patent_id": "10-2024-0042985", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 다양한 실시예에 따른 AI 모델의 고도화를 자동적으로 수행하기 위한 방법이 개시된다. 상기 방법은: 클라이언트로부터 라벨링이 완료된 제1 데이터를 획득하는 단계; 상기 제1 데이터를 증강하여 제2 데이터를 생성 하는 단계; 상기 제1 데이터 및 상기 제2 데이터를 이용하여 적어도 하나의 모델을 학습시키는 단계; 및 학습이 완료된 적어도 하나의 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 상기 학습이 완료된 적어도 하나의 모델을 배포하는 단계;를 할 수 있다."}
{"patent_id": "10-2024-0042985", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 AI 모델(artificial intelligence model)의 학습 및 고도화와 관련된 방법, 장치 및 프로그램에 관 한 것으로서, 구체적으로 학습 데이터를 자동으로 구축하거나, AI 모델의 고도화를 자동으로 수행하거나, 데이 터 셋을 구축하는 방법, 장치 및 프로그램에 관한 것이다."}
{"patent_id": "10-2024-0042985", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨팅 장치의 하드웨어적인 성능 향상과 함께 인공지능 기술의 발달로 인하여, 다양한 분야에서 활용 가능한 AI 응용기술에 대한 연구개발이 활발하게 진행되고 있다. 특히, AI 기술의 활용에 의한 업무 효율성 증대 및 생 산성 향상과 같은 가시적인 성과를 거두기 시작하면서 다양한 산업에서 AI 도입에 대한 기대가 모아지고 있다. 이러한, AI 기술을 다양한 산업에 도입하기 위해서는, 머신러닝을 통한 AI 모델 학습이 선행되어야 한다. 여기 서, AI 모델 학습에는 방대한 양의 데이터가 요구되며, 데이터에 라벨을 달아 해당 데이터를 분류(라벨링, Labeling)하는 과정을 필요로 한다. 예를 들어, 이미지에 포함된 객체에 라벨을 달아 AI 모델에 입력하면 인공 지능은 이를 바탕으로 데이터들을 학습하면서 해당 이미지 내의 객체들을 인식한다. 종래의 데이터 라벨링 작업은 자동화되어 있지 않고 사람에 의해 수행되고 있어, 학습 데이터의 정확도가 낮아 질 수 있으며, AI 모델 학습에 대한 효율성이 낮아지는 문제가 발생될 수 있다. 따라서, AI 모델의 학습과 관련된 다양한 작업들을 자동화하는 기술에 대한 수요가 당업계에 존재한다. 이와 관 련하여, 대한민국 공개특허공보 제10-2023-0032574호는 학습 데이터를 자동으로 라벨링하는 학습 데이터 생성 장치, 방법 및 컴퓨터 프로그램을 개시한다."}
{"patent_id": "10-2024-0042985", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 배경기술에 대응하여 안출된 것으로 AI 모델의 학습과 관련된 다양한 작업들을 자동화하는 방 법, 장치 및 프로그램을 제공하고자 하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과 제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0042985", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 바와 같은 과제를 해결하기 위한 본 발명의 일 실시예에 따라, AI 모델의 고도화를 자동적으로 수행하기 위한 방법이 개시된다. 상기 방법은: 클라이언트로부터 라벨링이 완료된 제1 데이터를 획득하는 단계; 상기 제1 데이터를 증강하여 제2 데이터를 생성하는 단계; 상기 제1 데이터 및 상기 제2 데이터를 이용하여 적어도 하나 의 모델을 학습시키는 단계; 및 학습이 완료된 적어도 하나의 모델을 모델 저장소에 저장하고, 모델 서빙 컨테 이너를 통해 상기 학습이 완료된 적어도 하나의 모델을 배포하는 단계;를 포함할 수 있다. 대안적인 실시예에서, 클라이언트로부터 라벨링이 완료된 제1 데이터를 획득하는 단계는, 상기 클라이언트로부 터 제1 로우 데이터 및 제1 어노테이션 데이터를 획득하는 단계;를 포함하고, 상기 제1 데이터를 증강하여 제2 데이터를 생성하는 단계는, 상기 제1 로우 데이터를 증강하여 제2 로우 데이터를 생성하는 단계; 및 상기 제1 어노테이션 데이터를 증강하여 제2 어노테이션 데이터를 성하는 단계;를 포함할 수 있다. 대안적인 실시예에서, 클라이언트로부터 라벨링이 완료된 제1 데이터를 획득하는 단계는, 상기 클라이언트로부 터 제1 로우 데이터 및 제1 어노테이션 데이터를 획득하는 단계;를 포함하고, 상기 제1 데이터를 증강하여 제2 데이터를 생성하는 단계는, 상기 제1 로우 데이터를 증강하여, 제2 로우 데이터를 생성하는 단계; 및 상기 제1 어노테이션 데이터를 기초로, 상기 제2 로우 데이터에 대한 어노테이션을 수행하여 제2 어노테이션 데이터를 생 성하는 단계;를 포함할 수 있다. 대안적인 실시예에서, 상기 방법은, 상기 적어도 하나의 모델의 학습이 완료된 경우, 불확실한 결과에 대응하는 특정 데이터를 인식하는 단계; 상기 특정 데이터에 대한 어노테이션 데이터를 상기 클라이언트로 요청하는 단계; 상기 클라이언트로부터 상기 어노테이션 데이터를 수신한 경우, 상기 특정 데이터 및 상기 어노테이션 데 이터 각각을 증강하여 제3 데이터를 생성하는 단계; 상기 제3 데이터를 이용하여, 상기 특정 데이터와 관련된 특정 모델을 재학습시키는 단계; 및 재학습이 완료된 상기 특정 모델을 모델 저장소에 저장하고, 모델 서빙 컨 테이너를 통해 상기 재학습이 완료된 상기 특정 모델을 배포하는 단계;를 더 포함할 수 있다. 대안적인 실시예에서, 상기 방법은, 상기 적어도 하나의 모델의 학습이 완료된 경우, 불확실한 결과에 대응하는 특정 데이터를 인식하는 단계; 상기 특정 데이터에 대한 특정 어노테이션 데이터를 상기 클라이언트로 요청하는 단계; 상기 클라이언트로부터 상기 특정 어노테이션 데이터를 수신한 경우, 상기 특정 데이터를 증강하여, 제3 로우 데이터를 생성하는 단계; 상기 특정 어노테이션 데이터를 기초로, 상기 제3 로우 데이터에 대한 어노테이 션을 수행하여 제3 어노테이션 데이터를 생성하는 단계; 상기 특정 데이터, 상기 특정 어노테이션 데이터, 상기 제3 로우 데이터 및 상기 제3 어노테이션 데이터를 이용하여 상기 특정 데이터와 관련된 특정 모델을 재학습시 키는 단계; 및 재학습이 완료된 상기 특정 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 상기 재 학습이 완료된 상기 특정 모델을 배포하는 단계;를 더 포함할 수 있다. 대안적인 실시예에서, 상기 불확실한 결과에 대응하는 특정 데이터를 인식하는 단계는, 상기 적어도 하나의 모 델에서 예측한 클래스들에 대한 확률 값이 기 설정된 확률 값과 기 설정된 크기 이내로 차이나는 경우, 상기 클 래스에 대응하는 데이터를 상기 특정 데이터로 인식하는 단계; 또는 상기 적어도 하나의 모델에서 예측한 가장 높은 확률을 갖는 클래스와 두 번째로 높은 확률을 갖는 클래스 각각에 대한 확률 값의 차이가 기 설정된 값 이 하인 경우, 상기 클래스에 대응하는 데이터를 상기 특정 데이터로 인식하는 단계;를 포함할 수 있다. 대안적인 실시예에서, 상기 방법은, 검증 데이터셋을 이용하여, 학습이 완료된 상기 적어도 하나의 모델에 대한 검증을 수행하는 단계; 상기 검증을 수행한 결과에서 정확도가 기 설정된 값 이하인 특정 클래스를 인식한 경우, 상기 특정 클래스에 대응하는 데이터를 증강하여, 추가 증강 데이터를 생성하는 단계; 상기 추가 증강 데 이터에 대한 상기 특정 클래스의 어노테이션을 수행하여, 추가 어노테이션 데이터를 생성하는 단계; 및 상기 추 가 증강 데이터 및 상기 추가 어노테이션 데이터를 기초로 상기 특정 클래스와 관련된 특정 모델을 재학습시키 는 단계;를 더 포함할 수 있다. 대안적인 실시예에서, 상기 방법은, 상기 검증 데이터셋을 이용하여, 재학습이 완료된 상기 특정 모델에 대한 재검증을 수행하는 단계;를 포함하고, 상기 재검증을 수행한 결과에서 정확도가 기 설정된 값 이하인 특정 클래 스를 인식한 경우, 상기 특정 클래스에 대한 가중치를 증가시키거나, 상기 특정 클래스를 분류하기 위한 레이어 를 추가하고, 상기 재검증을 수행한 결과에서 정확도가 기 설정된 값 이하인 특정 클래스를 인식하지 못한 경우, 상기 특정 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 상기 재학습이 완료된 상기 특정 모델을 배포할 수 있다. 상술한 과제를 해결하기 위한 본 발명의 일 실시예에 따라, 장치가 개시된다. 상기 장치는: 하나 이상의 인스트 럭션을 저장하는 메모리; 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하 고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상술한 방법들을 수행할 수 있다. 상술한 과제를 해결하기 위한 본 발명의 일 실시예에 따라, 하드웨어인 컴퓨터와 결합되어, 상술한 방법들을 수 행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장된 컴퓨터프로그램이 개시된다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2024-0042985", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 AI 모델의 학습 및 고도화와 관련된 방법, 장치 및 프로그램은 AI 모델 학습 및 고도화와 관련된 작"}
{"patent_id": "10-2024-0042985", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "업의 효율성을 높일 수 있다.본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0042985", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다양한 실시예들이 이제 도면을 참조하여 설명된다. 본 명세서에서, 다양한 설명들이 본 발명의 이해를 제공하 기 위해서 제시된다. 그러나, 이러한 실시예들은 이러한 구체적인 설명 없이도 실행될 수 있음이 명백하다. 본 명세서에서 사용되는 용어 \"컴포넌트\", \"모듈\", \"시스템\" 등은 컴퓨터-관련 엔티티, 하드웨어, 펌웨어, 소프 트웨어, 소프트웨어 및 하드웨어의 조합, 또는 소프트웨어의 실행을 지칭한다. 예를 들어, 컴포넌트는 프로세서 상에서 실행되는 처리과정(procedure), 프로세서, 객체, 실행 스레드, 프로그램, 및/또는 컴퓨터일 수 있지만, 이들로 제한되는 것은 아니다. 예를 들어, 컴퓨팅 장치에서 실행되는 애플리케이션 및 컴퓨팅 장치 모두 컴포넌 트일 수 있다. 하나 이상의 컴포넌트는 프로세서 및/또는 실행 스레드 내에 상주할 수 있다. 일 컴포넌트는 하 나의 컴퓨터 내에 로컬화 될 수 있다. 일 컴포넌트는 2개 이상의 컴퓨터들 사이에 분배될 수 있다. 또한, 이러 한 컴포넌트들은 그 내부에 저장된 다양한 데이터 구조들을 갖는 다양한 컴퓨터 판독가능한 매체로부터 실행할 수 있다. 컴포넌트들은 예를 들어 하나 이상의 데이터 패킷들을 갖는 신호(예를 들면, 로컬 시스템, 분산 시스 템에서 다른 컴포넌트와 상호작용하는 하나의 컴포넌트로부터의 데이터 및/또는 신호를 통해 다른 시스템과 인 터넷과 같은 네트워크를 통해 전송되는 데이터)에 따라 로컬 및/또는 원격 처리들을 통해 통신할 수 있다. 더불어, 용어 \"또는\"은 배타적 \"또는\"이 아니라 내포적 \"또는\"을 의미하는 것으로 의도된다. 즉, 달리 특정되지 않거나 문맥상 명확하지 않은 경우에, \"X는 A 또는 B를 이용한다\"는 자연적인 내포적 치환 중 하나를 의미하는 것으로 의도된다. 즉, X가 A를 이용하거나; X가 B를 이용하거나; 또는 X가 A 및 B 모두를 이용하는 경우, \"X는 A 또는 B를 이용한다\"가 이들 경우들 어느 것으로도 적용될 수 있다. 또한, 본 명세서에 사용된 \"및/또는\"이라 는 용어는 열거된 관련 아이템들 중 하나 이상의 아이템의 가능한 모든 조합을 지칭하고 포함하는 것으로 이해 되어야 한다. 또한, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 해당 특징 및/또는 구성요소가 존재함을 의미하는 것으로 이해되어야 한다. 다만, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 하나 이상의 다른 특징, 구성요소 및/또 는 이들의 그룹의 존재 또는 추가를 배제하지 않는 것으로 이해되어야 한다. 또한, 달리 특정되지 않거나 단수 형태를 지시하는 것으로 문맥상 명확하지 않은 경우에, 본 명세서와 청구범위에서 단수는 일반적으로 \"하나 또 는 그 이상\"을 의미하는 것으로 해석되어야 한다. 당업자들은 추가적으로 여기서 개시된 실시예들과 관련되어 설명된 다양한 예시적 논리적 블록들, 구성들, 모듈 들, 회로들, 수단들, 로직들, 및 알고리즘 단계들이 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양쪽 모두의 조합 들로 구현될 수 있음을 인식해야 한다. 하드웨어 및 소프트웨어의 상호교환성을 명백하게 예시하기 위해, 다양 한 예시적 컴포넌트들, 블록들, 구성들, 수단들, 로직들, 모듈들, 회로들, 및 단계들은 그들의 기능성 측면에서 일반적으로 위에서 설명되었다. 그러한 기능성이 하드웨어로 또는 소프트웨어로서 구현되는지 여부는 전반적인 시스템에 부과된 특정 어플리케이션(application) 및 설계 제한들에 달려 있다. 숙련된 기술자들은 각각의 특정 어플리케이션들을 위해 다양한 방법들로 설명된 기능성을 구현할 수 있다. 다만, 그러한 구현의 결정들이 본 발명내용의 영역을 벗어나게 하는 것으로 해석되어서는 안된다. 제시된 실시예들에 대한 설명은 본 발명의 기술 분야에서 통상의 지식을 가진 자가 본 발명을 이용하거나 또는 실시할 수 있도록 제공된다. 이러한 실시예들에 대한 다양한 변형들은 본 발명의 기술 분야에서 통상의 지식을 가진 자에게 명백할 것이다. 여기에 정의된 일반적인 원리들은 본 발명의 범위를 벗어남이 없이 다른 실시예들 에 적용될 수 있다. 그리하여, 본 발명은 여기에 제시된 실시예들로 한정되는 것이 아니다. 본 발명은 여기에 제시된 원리들 및 신규한 특징들과 일관되는 최광의의 범위에서 해석되어야 할 것이다. 본 명세서에서, 컴퓨터는 적어도 하나의 프로세서를 포함하는 모든 종류의 하드웨어 장치를 의미하는 것이고, 실시 예에 따라 해당 하드웨어 장치에서 동작하는 소프트웨어적 구성도 포괄하는 의미로서 이해될 수 있다. 예 를 들어, 컴퓨터는 스마트폰, 태블릿 PC, 데스크톱, 노트북 및 각 장치에서 구동되는 사용자 클라이언트 및 애 플리케이션을 모두 포함하는 의미로서 이해될 수 있으며, 또한 이에 제한되는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 본 명세서에서 설명되는 각 단계들은 컴퓨터에 의하여 수행되는 것으로 설명되나, 각 단계의 주체는 이에 제한 되는 것은 아니며, 실시 예에 따라 각 단계들의 적어도 일부가 서로 다른 장치에서 수행될 수도 있다. 도 1은 본 발명의 일 실시예에 따른 시스템을 도시한 도면이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 시스템은 서버, 사용자 단말 및 외부 서버를 포 함할 수 있다. 여기서, 도 1에 도시된 시스템은 일 실시예에 따른 것이고, 그 구성 요소가 도 1에 도시된 실시 예에 한정되는 것은 아니며, 필요에 따라 부가, 변경 또는 삭제될 수 있다. 서버는 예를 들어, 마이크로프로세서, 메인프레임 컴퓨터, 디지털 프로세서, 휴대용 디바이스 및 디바이스 제어기 등과 같은 임의의 타입의 컴퓨터 시스템 또는 컴퓨터 디바이스를 포함할 수 있다. 다만, 이에 한정되는 것은 아니다. 일 실시예에서, 서버는 AI 모델의 고도화를 자동적으로 수행할 수 있다. 예를 들어, 서버는 네트워크 를 통해 사용자 단말과 연결될 수 있고, 사용자 단말로 고도화를 자동적으로 수행하여 학습된 AI 모델을 제공할 수 있으며, 사용자 단말로부터 요구 사항을 수신하여 커스텀 모델을 제공할 수도 있다. 구체적으로, 서버는 클라이언트로부터 라벨링이 완료된 제1 데이터를 획득할 수 있다. 여기서, 제1 데이터 는 로우 데이터 및 어노테이션 데이터를 포함할 수 있다. 또한, 서버는 제1 데이터를 증강하여 제2 데이터 를 생성할 수 있다. 또한, 서버는 제1 데이터 및 제2 데이터를 이용하여 적어도 하나의 모델을 학습시킬 수 있다. 그리고, 서버는 학습이 완료된 적어도 하나의 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이 너를 통해 학습이 완료된 적어도 하나의 모델을 배포할 수 있다. 다양한 실시예에서, 서버는 AI 모델의 학습 및 고도화와 관련된 다양한 작업을 수행할 수 있다. 일례로, 서버는 라벨링이 완료된 학습 데이터를 증강하여 모델을 학습시킬 수 있다. 구체적으로, 서버는 클래 스에 대해 반복적인 오토 라벨링을 수행하며 AI 모델이 지속적으로 재학습되며, 지속적으로 재학습되는 AI 모델 은 고도화될 수 있다. 구체적으로, 서버는 클라이언트로부터 라벨링이 완료된 제1 데이터를 수신할 수 있다. 여기서, 클라이언트 는 사용자 단말일 수 있으며, AI 모델에 대한 고도화를 의뢰하는 사용자의 단말일 수 있다. 서버는 제1 데이터를 수신한 경우, 제1 데이터를 증강하여 제2 데이터를 생성할 수 있다. 예를 들어, 서버 는 제1 데이터에 포함된 데이터에 대해, 미러링, 무작위 크롭, 회전, 시어링 및 로컬 랩핑 중 적어도 하나 를 수행하여, 데이터를 증강할 수 있다. 서버는 제2 데이터를 생성한 경우, 제2 데이터를 이용하여 모델을 학습시킬 수 있다. 다양한 실시예에서, 서버는 학습된 모델을 검증할 수 있다. 그리고, 서버는 클라이언트로 검증이 완 료된 모델을 전송할 수 있다. 한편, 서버는 모델을 클라이언트로 전송한 후, 클라이언트로부터 어노테이션 데이터를 수신할 수 있다. 여 기서, 어노테이션 데이터는 모델 학습에 이용되는 데이터 셋에 메타데이터가 추가된 데이터를 의미할 수 있으나, 이에 한정되는 것은 아니다.서버는 클라이언트로 어노테이션 데이터를 기초로 모델을 커스텀하여, 커스텀 모델을 생성할 수 있다. 그 리고, 커스텀 모델을 클라이언트로 전송할 수 있다. 여기서, 커스텀 모델은 어노테이션 데이터를 기초로 재학습 된 모델을 의미할 수 있다. 또한, 어노테이션 데이터를 수신한 횟수만큼 커스텀 모델은 재학습되어 고도화될 수 있다. 다양한 실시예에서, 서버에 의해 학습된 모델은 모델 저장소에 저장되어, 기존에 사용되던 모델로 롤백이 가능할 수 있다. 또한, 서버는 클라이언트로부터 수신되는 라벨링 데이터 별로 컨테이너를 생성하여 모델 을 학습시킬 수 있다. 또한, 서버는 리소스 제어 스케줄러를 통해 컨테이너 간 유기적으로 결합하도록 제 어하여 자원을 효율적으로 사용할 수 있다. 다양한 실시예에서, 서버는 학습 데이터를 자동으로 구축할 수 있다. 예를 들어, 서버는 입력된 이미 지에 포함된 객체를 추론하고, 추론 결과 값을 오픈 데이터셋 포맷으로 변환할 수 있다. 그리고, 서버는 오픈 데이터셋 포맷으로 변환된 데이터를 시각화하여 오토 라벨링을 수행함으로써, 학습 데이터를 자동으로 구 축할 수 있다. 다양한 실시예에서, 서버는 데이터 품질 향상을 위한 데이터셋을 구축할 수 있다. 예를 들어, 서버는 네트워크를 통해 사용자 단말과 연결될 수 있고, 사용자 단말로 검수 절차를 요청하거나 라벨링 작업을 요청할 수 있다. 여기서, 사용자 단말은 검수자 단말, 작업자 단말 및 프로젝트 오너 단말 중 적어 도 하나를 포함할 수 있다. 다양한 실시예에서, 서버는 웹(Web) 또는 애플리케이션(Application) 기반의 서비스를 제공할 수 있다. 그 러나, 이에 한정되지 않는다. 이하, 서버가 AI 모델의 학습 및 고도화와 관련된 다양한 작업을 수행하는 방법의 일례에 대한 설명은 도 3 내지 도 10을 참조하여 후술한다. 한편, 사용자 단말은 서버에서 제공하는 AI 모델의 학습 및 고도화와 관련된 다양한 작업을 의뢰하는 사용자의 단말일 수 있다. 또한, 사용자 단말은 서버에서 제공하는 AI 모델의 학습 및 고도화와 관련 된 다양한 작업을 돕거나, 검수하는 사용자의 단말일 수 있다. 여기서, 사용자 단말은 예를 들어, 다양한 형태의 컴퓨터 장치를 포함할 수 있다. 자세히 예를 들어, 사용자 단말은 스마트폰, 태블릿 PC, 데스크톱, 노트북과 같은 다양한 단말 장치를 의미할 수 있다. 사용자 단말은 사용자 단말의 적어도 일부분에 디스플레이를 포함하며, 서버로부터 제공되는 애 플리케이션 혹은 확장 프로그램 기반의 서비스 구동을 위한 운영체제를 포함할 수 있다. 예를 들어, 사용자 단 말은 스마트폰(Smart-phone)일 수 있으나, 이에 한정되지 않고, 사용자 단말은, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트 패드(Smartpad), 태블릿 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 네트워크는 컴퓨팅 장치, 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미할 수 있다. 예를 들어, 네트워크는 근거리 통신망(LAN: Local Area Network), 광역 통신망 (WAN: Wide Area Network), 인터넷(WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통 신망 등을 포함한다. 무선 데이터 통신망은 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), 5GPP(5th Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와 이파이(Wi-Fi), 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency), 블루투스(Bluetooth) 네트워크, NFC(Near-Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 일 실시예에서, 외부 서버는 네트워크를 통해 서버와 연결될 수 있으며, 서버가 AI 모델의 학습 및 고도화와 관련된 다양한 작업을 수행하기 위하여 필요한 각종 정보/데이터를 송수신 할 수 있고, 서버가 작업을 수행함에 따라 생성되는 각종 정보/데이터를 저장 및 관리할 수 있다. 예를 들어, 외부 서버는 AI 모델의 학습 및 고도화와 관련된 다양한 작업에서 이용되는 정보(예를 들어, 이미지 데이터)를 저장하거나, 학습된 AI 모델을 저장하는 데이터베이스 서버일 수 있다. 다만, 이에 한정되는 것은 아니다. 이하, 도 2를 참조하여, 서버의 하드웨어 구성에 대해 설명하도록 한다. 도 2는 본 발명의 일 실시예에 따른 컴퓨팅 장치의 하드웨어 구성도이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 서버는 하나 이상의 프로세서, 프로세서에 의하 여 수행되는 컴퓨터 프로그램을 로드(Load)하는 메모리, 버스, 통신 인터페이스 및 컴퓨터 프로그램을 저장하는 스토리지를 포함할 수 있다. 여기서, 도 2에는 본 발명의 실시예와 관련 있는"}
{"patent_id": "10-2024-0042985", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "구성요소들만 도시되어 있다. 따라서, 본 발명이 속한 기술분야의 통상의 기술자라면 도 2에 도시된 구성요소들 외에 다른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 프로세서는 서버의 각 구성의 전반적인 동작을 제어한다. 프로세서는 하나 이상의 코어로 구성 될 수 있으며, 컴퓨팅 장치의 중앙 처리 장치(CPU: central processing unit), 범용 그래픽 처리 장치(GPGPU: general purpose graphics processing unit), 텐서 처리 장치(TPU: tensor processing unit) 등의 데이터 분석, 딥러닝을 위한 프로세서를 포함할 수 있다. 또는 본 발명의 기술 분야에 잘 알려진 임의의 형태의 프로세 서를 포함하여 구성될 수 있다. 또한, 프로세서는 본 발명의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프 로그램에 대한 연산을 수행할 수 있으며, 서버는 하나 이상의 프로세서를 구비할 수 있다. 다양한 실시예에서, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저장하는 램(RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포 함할 수 있다. 또한, 프로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템온칩(SoC: system on chip) 형태로 구현될 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 발명의 다양한 실시예에 따른 방 법/동작을 실행하기 위하여 스토리지로부터 컴퓨터 프로그램을 로드할 수 있다. 메모리에 컴퓨 터 프로그램이 로드되면, 프로세서는 컴퓨터 프로그램을 구성하는 하나 이상의 인스트럭션들을 실행함으로써 상기 방법/동작을 수행할 수 있다. 메모리는 RAM과 같은 휘발성 메모리로 구현될 수 있을 것 이나, 본 발명의 기술적 범위가 이에 한정되는 것은 아니다. 버스는 서버의 구성 요소 간 통신 기능을 제공한다. 버스는 주소 버스(address Bus), 데이터 버 스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 서버의 유무선 인터넷 통신을 지원한다. 또한, 통신 인터페이스는 인터넷 통 신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 발명의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 몇몇 실시예에서, 통신 인터페이스는 생략될 수도 있다. 스토리지는 컴퓨터 프로그램을 비 임시적으로 저장할 수 있다. 서버를 통해 정밀 진단 모듈 제 안 프로세스를 수행하는 경우, 스토리지는 개시된 실시예에 따른 분석을 수행하기 위하여 필요한 각종 정 보를 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드 될 때 프로세서로 하여금 본 발명의 다양한 실시예에 따른 방 법/동작을 수행하도록 하는 하나 이상의 인스트럭션들을 포함할 수 있다. 즉, 프로세서는 상기 하나 이상 의 인스트럭션들을 실행함으로써, 본 발명의 다양한 실시예에 따른 상기 방법/동작을 수행할 수 있다. 일 실시예에서, 컴퓨터 프로그램은 AI 모델의 학습 및 고도화와 관련된 다양한 작업과 관련된 다양한 방법 들을 수행하도록 하는 하나 이상의 인스트럭션을 포함할 수 있다.본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조합 으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 도 3 내지 도 7은 본 발명의 일 실시예에 따른 AI 모델의 고도화를 자동적으로 수행하기 위한 방법의 일례를 설 명하기 위한 도면이다. 도 3은 본 발명의 서버에 의해 처리되는 AI 모델의 고도화를 자동적으로 수행하는 시스템의 일례를 나타낸 개략도이다. 도 3을 참조하면, 시스템의 Web front-end(웹 프론트엔드)에서, 사용자는 웹 인터페이스를 통해 로그인 하고 프로젝트를 관리할 수 있다. 여기서, 웹 인터페이스는 조건부로 원시 이미지 데이터(즉, 로우 데이터)를 받아들여, 필요에 따라 라벨링 과정을 시작할 수 있다. 시스템의 REST API는 웹 프론트엔드로부터의 요청을 처리하여, 데이터의 자동 라벨링, 액티브 러닝, 모 델 내보내기 등의 프로세스를 관리할 수 있다. 시스템의 AI Core(AI 코어)는 수집된 데이터에 대한 데이터 증강, 모델 검증, 그리고 모델 변환 등을 동작을 처리한다. 여기서, 데이터 증강은 초기 데이터를 인공적으로 확대하여 다양성을 증가시키고, 모델 학습 에 더 많은 예시를 제공할 수 있게 된다. 또한, 모델 검증은 학습된 모델의 성능을 평가하는 동작이고, 모델 변 환은 학습된 모델을 배포 가능한 형태로 변환하는 동작을 의미할 수 있다. 시스템의 DL server(딥러닝 서버)는 복수의 Train container(학습 컨테이너)를 포함할 수 있으며, 학 습 컨테이너는 AI 코어에서 전달받은 학습 데이터를 이용하여 모델을 학습시킬 수 있다. 여기서 학습된 모 델은 (Inference client(인퍼런스 클라이언트)에 포함된 서빙 컨테이너(Serving container)로 이동하며, 서빙 컨테이너를 통해 사용자에게 배포되고, 추론을 수행할 수 있다. 시스템의 LocalFS(로컬 파일 시스템)은 모든 이미지 파일(로우 데이터) 및 라벨 데이터(어노테이션 데 이터)를 저장할 수 있다. 또한, 로컬 파일 시스템은 Model Repo(모델 저장소)를 포함하며, 여기에 학습된 모델들을 저장할 수 있다. 본 발명의 AI 모델의 고도화를 자동적으로 수행하는 시스템은 새로운 데이터에 대한 추론 결과와 사용자 피 드백을 통해 지속적으로 학습하여, 모델을 자동적으로 고도화할 수 있다. 이 과정에서 액티브 러닝이 사용되어, 모델이 낮은 확신도로 예측한 데이터에 대해 사용자가 직접 라벨링을 수정하고, 이를 통해 모델을 재학습하여 정확도를 향상시킬 수 있다. 또한, 본 발명의 시스템은 모델 저장소를 통해 사용자의 필요에 따라 이전 모 델로의 롤백도 가능할 수 있다. 본 발명은 이러한 시스템 또는 시스템과 관련된 과정들을 통해 초기 데이터를 기반으로 지속적으로 학 습하고, 모델을 고도화하여 사용자에게 정확도가 높은 AI 모델을 제공할 수 있다. 이하, 도 4 내지 도 7을 참조하여, AI 모델의 고도화를 자동적으로 수행하는 방법에 대해 보다 구체적으로 설명 한다. 도 4를 참조하면, 서버는 클라이언트로부터 라벨링이 완료된 제1 데이터를 획득할 수 있다(S110). 구체적으로, 서버는 클라이언트로부터 라벨링이 완료된 제1 데이터를 획득하는 경우, 클라이언트로부터 제 1 로우 데이터 및 제1 어노테이션 데이터를 획득할 수 있다. 서버는 제1 데이터를 증강하여 제2 데이터를 생성할 수 있다(S120). 구체적으로, 서버는 제1 데이터를 증강하여 제2 데이터를 생성할 때, AI 모델이 사용되는 목적이나 용도에 따라 로우 데이터만 증강하거나, 로우 데이터와 어노테이션 데이터를 함께 증강할 수 있다. 일례로, AI 모델이 객체 감지 또는 세그멘테이션에 활용되는 모델인 경우, 서버는 제1 데이터를 증강하여 제2 데이터를 생성할 때, 제1 로우 데이터를 증강하여 제2 로우 데이터를 생성할 수 있다. 또한, 서버는 제1 어노테이션 데이터를 증강하여 제2 어노테이션 데이터를 생성할 수 있다. 예를 들어, 서버는 제1 로우 데이터가 이미지인 경우, 이미지를 회전시키면서 해당 이미지의 어노테이션 데이터(객체의 경계 상자)도 같이 회전시켜 데이터를 증강할 수 있다. 다른 일례로, AI 모델이 분류에 활용되는 모델인 경우, 서버는 제1 데이터를 증강하여 제2 데이터를 생성 할 때, 제1 로우 데이터를 증강하여, 제2 로우 데이터를 생성할 수 있다. 그리고, 서버는 제1 어노테이션 데이터를 기초로, 제2 로우 데이터에 대한 어노테이션을 수행하여 제2 어노테이션 데이터를 생성할 수 있다. 예를 들어, 서버는 제1 로우 데이터가 이미지인 경우, 이미지를 회전시키거나, 크기 조정하거나 색상을 변 경하여 데이터를 증강하고, 이에 대한 어노테이션을 수행할 수 있다. 서버는 제1 데이터 및 제2 데이터를 이용하여 적어도 하나의 모델을 학습시킬 수 있다(S130). 그리고, 서 버는 학습이 완료된 적어도 하나의 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 학습이 완 료된 적어도 하나의 모델을 배포할 수 있다(S140). 구체적으로, 서버는 제1 데이터 및 제2 데이터를 이용하여 적어도 하나의 모델을 학습시키는 경우, 제1 데 이터와 제2 데이터를 포함하는 학습 데이터셋을 구성할 수 있다. 또한, 서버는 제1 데이터를 이용하여 AI 모델의 초기 학습을 수행할 수 있다. 그리고, 서버는 초기 학습 이후, 제2 데이터를 포함하여 AI 모델을 추가로 학습시킬 수 있다. 이 과정을 통해 AI 모델은 다양한 시나리오와 조건을 학습할 수 있다. 따라서, 서버는 학습 데이터의 다양성과 풍부함을 기반으로 AI 모델의 정확도와 범용성을 향상시킬 수 있 다. 이 과정에서 서버는 다양한 데이터 증강 기술을 적용하여 실제 세계의 다양한 시나리오를 모델에 학습 시키고, 이를 통해 모델이 더욱 정확하게 객체를 감지, 분류, 또는 세그먼트할 수 있도록 한다. 추가적으로, 서 버는 학습 과정 중에 모델의 성능을 지속적으로 모니터링하고, 필요한 경우 학습 파라미터를 조정하여 최 적의 학습 결과를 달성할 수 있으며, 최종적으로 이러한 고도화된 AI 모델을 실제 환경에서의 적용을 위해 배포 할 수 있다. 본 발명의 일 실시예에 따르면, 서버는 AI 모델이 불확실한 결과를 출력한 경우, 해당 데이터에 대해서 재 학습을 시켜 AI 모델의 고도화를 자동적으로 수행할 수 있다. 일례로, 도 5를 참조하면, 서버는 적어도 하나의 모델의 학습이 완료된 경우, 불확실한 결과에 대응하는 특정 데이터를 인식할 수 있다(S210). 또한, 서버는 특정 데이터에 대한 어노테이션 데이터를 클라이언트 로 요청할 수 있다(S220). 서버는 클라이언트로부터 어노테이션 데이터를 수신한 경우, 특정 데이터 및 어노테이션 데이터 각각을 증 강하여 제3 데이터를 생성할 수 있다(S230). 또한, 서버는 제3 데이터를 이용하여, 특정 데이터와 관련된 특정 모델을 재학습시킬 수 있다(S240). 그리고, 서버는 재학습이 완료된 특정 모델을 모델 저장소에 저장 하고, 모델 서빙 컨테이너를 통해 재학습이 완료된 특정 모델을 배포할 수 있다(S250). 일 실시예에 따르면, 서버는 도 5의 단계(S230)에서 로우 데이터인 특정 데이터와 및 어노테이션 데이터를 함께 증강하여, 객체 감지나 세그멘테이션에 이용되는 AI 모델의 고도화를 자동적으로 수행할 수 있다. 예를 들어, 서버는 모델이 야간 조건이나 날씨 변화(비, 안개 등)로 인해 차량을 정확히 감지하지 못하는 상황(불확실한 결과)을 식별할 수 있다. 이러한 상황에서 서버는 해당 환경 조건에서 촬영된 차량 이미지 의 추가 어노테이션 데이터를 클라이언트에게 요청할 수 있다. 그리고, 서버는 수신한 어노테이션 데이터 와 함께 야간 또는 특정 날씨 조건에서 촬영된 차량 이미지(특정 데이터)를 증강하여 제3 데이터를 생성할 수있다. 이어서, 서버는 제3 데이터를 사용하여 모델을 재학습시킬 수 있다. 이러한 과정을 통해 서버 는 모델이 야간이나 특정 날씨 조건에서도 차량을 더 정확히 감지할 수 있도록 모델을 고도화할 수 있다. 다른 예를 들어, 서버는 모델이 특정 유형의 종양(예를 들어, 매우 작거나 특이한 형태의 종양)을 세그멘 테이션하는데 실패하는 경우를 식별할 수 있다. 이 경우, 서버는 해당 유형의 종양이 포함된 추가 의료 영 상에 대한 어노테이션 데이터를 요청하고 수신할 수 있다. 서버는 수신한 어노테이션 데이터와 특정 종양 이미지를 증강하고, 이를 이용해 모델을 재학습시켜, 모델이 다양한 형태와 크기의 종양을 정확하게 세그멘테이 션할 수 있도록 할 수 있다. 이를 통해 서버는 의료진이 더 정확한 진단과 치료 계획을 수립할 수 있도록 도움을 줄 수 있다. 다른 일례로, 도 6을 참조하면, 서버는 적어도 하나의 모델의 학습이 완료된 경우, 불확실한 결과에 대응 하는 특정 데이터를 인식할 수 있다. 또한, 서버는 특정 데이터에 대한 특정 어노테이션 데이터를 클 라이언트로 요청할 수 있다(S320). 서버는 클라이언트로부터 특정 어노테이션 데이터를 수신한 경우, 특정 데이터를 증강하여, 제3 로우 데이 터를 생성할 수 있다(S330). 서버는 특정 어노테이션 데이터를 기초로, 제3 로우 데이터에 대한 어노테이 션을 수행하여 제3 어노테이션 데이터를 생성할 수 있다(S340). 서버는 특정 데이터, 특정 어노테이션 데이터, 제3 로우 데이터 및 제3 어노테이션 데이터를 이용하여 특 정 데이터와 관련된 특정 모델을 재학습시킬 수 있다(S350). 그리고, 서버는 재학습이 완료된 특정 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 재학습이 완료된 특정 모델을 배포할 수 있다(S360). 일 실시예에 따르면, 서버는 도 6의 단계(S330)에서 로우 데이터인 특정 데이터를 증강한 후, 단계(S340) 에서 증강된 제3 로우 데이터에 대한 어노테이션을 수행하여, 분류에 이용되는 AI 모델의 고도화를 자동적으로 수행할 수 있다. 예를 들어, 서버는 특정 조명 조건이나 배경에서 식물 사진을 분류하는데 어려움을 겪는 경우(자세히 예를 들어, 모델이 특정 식물 종을 다른 종으로 잘못 분류하는 경우)를 식별할 수 있다. 서버는 이러한 불확실 한 결과에 대응하기 위해, 문제가 발생한 특정 식물 사진에 대한 정확한 어노테이션 데이터를 클라이언트에게 요청할 수 있다. 서버는 클라이언트로부터 어노테이션 데이터를 수신한 후, 해당 식물 사진(특정 데이터)을 다양한 방식으 로 증강(조명 변화 적용, 배경 노이즈 추가, 이미지 회전 및 확대/축소 등)하여 제3 로우 데이터를 생성할 수 있다. 이후, 서버는 증강된 제3 로우 데이터에 대한 정확한 어노테이션을 수행하여 제3 어노테이션 데이터 를 생성할 수 있다. 그리고, 서버는 증강된 데이터와 정확한 어노테이션을 기초로, 문제가 발생했던 식물 종에 대한 모델을 재학습시킬 수 있다. 이 과정을 통해 서버는 모델이 해당 식물 종을 더 정확하게 분류할 수 있도록 할 수 있다. 도 5 및 도 6을 참조하여 설명한 과정을 통해 서버는 분류 작업에 사용되는 AI 모델의 고도화를 자동적으 로 수행할 수 있으며, 특정 조건에서의 오류를 줄이고 모델의 정확도를 개선할 수 있다. 본 발명의 일 실시예에 따르면, 서버는 도 5의 단계(S210) 및 도 6의 단계(S310)에서, 불확실한 결과에 대 응하는 특정 데이터를 인식하는 경우, 다양한 방법을 이용할 수 있다. 일례로, 서버는 적어도 하나의 모델에서 예측한 클래스들에 대한 확률 값이 기 설정된 확률 값과 기 설정 된 크기 이내로 차이나는 경우, 클래스에 대응하는 데이터를 특정 데이터로 인식할 수 있다. 즉, 서버는 모든 클래스에 대한 확률이 50% 근처인 경우(예를 들어, 모든 클래스에 대해 거의 균등하게 분포), 해당 클래스 와 관련된 데이터를 불확실한 결과에 대응하는 특정 데이터로 인식할 수 있다. 다른 일례로, 서버는 적어도 하나의 모델에서 예측한 가장 높은 확률을 갖는 클래스와 두 번째로 높은 확 률을 갖는 클래스 각각에 대한 확률 값의 차이가 기 설정된 값 이하인 경우, 클래스에 대응하는 데이터를 특정 데이터로 인식할 수 있다. 즉, 서버는 마진 샘플링을 통해 불확실성이 높은 특정 데이터를 인식할 수 있다. 추가적인 일례로, 서버는 모델의 예측이 틀릴 가능성 값(즉, 예측에 대한 손실)이 기 설정된 값을 초과하 는 경우, 클래스에 대응하는 데이터를 특정 데이터로 인식할 수 있다. 즉, 서버는 위험 기반 샘플링을 통 해 모델이 출력한 클래스에 대한 불확실성을 평가할 수 있다.다른 추가적인 일례로, 서버는 복수의 모델(커미티)을 사용하여 동일한 데이터에 대한 예측을 수행하고, 이들 예측 간의 불일치 정도를 파악하여 클래스에 대한 불확실성을 평가할 수 있다. 즉, 서버는 쿼리-바이 -커미티를 통해 모델이 출력한 클래스에 대한 불확실성을 평가할 수 있다. 본 발명의 일 실시예에 따르면, 서버는 검증 데이터셋을 기반으로, 학습이 완료된 모델을 검증하고, 모델 의 평가 결과에 따라 모델을 배포하거나, 모델에 대한 추가적인 재학습을 수행할 수 있다. 도 7을 참조하면, 서버는 검증 데이터셋을 이용하여, 학습이 완료된 적어도 하나의 모델에 대한 검증을 수 행할 수 있다(S410). 예를 들어, 서버는 검증 데이터셋을 이용하여, 모델의 정확도, 정밀도, 재현율 등 다 양한 성능 지표를 측정하여, 학습이 완료된 모델에 대한 전반적인 성능을 파악할 수 있다. 서버는 검증을 수행한 결과에서 정확도가 기 설정된 값 이하인 특정 클래스를 인식하지 못한 경우, 학습이 완료된 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 배포할 수 있다. 한편, 서버는 검증을 수행한 결과에서 정확도가 기 설정된 값 이하인 특정 클래스를 인식한 경우, 특정 클 래스에 대응하는 데이터를 증강하여, 추가 증강 데이터를 생성할 수 있다(S420). 또한, 서버는 추가 증강 데이터에 대한 특정 클래스의 어노테이션을 수행하여, 추가 어노테이션 데이터를 생성할 수 있다(S430). 그리고, 서버는 추가 증강 데이터 및 추가 어노테이션 데이터를 기초로 특정 클래스와 관련된 특정 모델을 재학습시킬 수 있다(S450). 예를 들어, 서버는 교통 표지판을 인식하기 위한 AI 모델의 검증 과정에서 \"정지\" 표지판에 대한 인식률이 낮게 나타난 경우, \"정지\" 표지판 이미지를 다양한 환경 조건을 반영하여 증강할 수 있다. 또한, 서버는 증강한 데이터에 대해 어노테이션을 수행할 수 있다. 그리고, 서버는 증강한 데이터 및 어노테이션 데이터 를 이용하여 \"정지\" 표지판을 더 정확하게 인식할 수 있도록 모델을 재학습시킬 수 있다. 서버는 이러한 검증 과정을 통해, AI 모델의 정확도와 신뢰성을 지속적으로 개선할 수 있으며, 실제 환경 에서의 모델 성능을 향상시킬 수 있다. 다양한 실시예에서, 서버는 검증 결과에 따라 모델에 대한 재학습을 수행한 경우, 검증 데이터셋을 이용하 여, 재학습이 완료된 특정 모델에 대한 재검증을 수행할 수 있다. 서버는 재검증을 수행한 결과에서 정확도가 기 설정된 값 이하인 특정 클래스를 인식한 경우, 특정 클래스 에 대한 가중치를 증가시키거나, 특정 클래스를 분류하기 위한 레이어를 추가할 수 있다. 한편, 서버는 재검증을 수행한 결과에서 정확도가 기 설정된 값 이하인 특정 클래스를 인식하지 못한 경우, 특정 모델을 모델 저장소에 저장하고, 모델 서빙 컨테이너를 통해 재학습이 완료된 특정 모델을 배포할 수 있다. 따라서, 서버는 모델의 성능 평가, 데이터 증강, 어노테이션, 재학습 및 재검증 과정을 통해, 지속적으로 AI 모델의 정확도를 개선하고, 모델의 신뢰성을 강화할 수 있다. 이러한 과정은 변화하는 환경 조건이나 새로운 데이터 유형에 대응하는데 필요한 모델의 적응력을 높일 수 있으며, 사용자에게 지속적으로 최적화된 AI 기반 솔루션을 제공할 수 있도록 한다. 본 발명의 일 실시예에 따르면, 서버는 모델을 배포하는 경우, 서빙 컨테이너를 통해 모델의 추론 기능을 사용자에게 제공할 수 있다. 구체적으로, 서버는 모델의 추론 서비스를 위해 컨테이너화된 환경을 구성하고, 이를 통해 학습된 모델의 API를 제공하여, 최종 사용자나 다른 시스템이 모델을 편리하게 이용할 수 있도록 한다. 즉, 본 발명의 서버는 컨테이너화된 모델 서빙 방식을 통해 모델을 배포할 수 있다. 구체적으로, 컨테이너화된 모델 서빙 방식은 컨테이너 오케스트레이션 도구(예를 들어, 도커(Docker), 쿠버네티 스(Kubernetes))를 사용하여, AI 모델을 하나의 컨테이너로 패키징하고 관리하는 방식을 포함할 수 있다. 이 방 식은 모델과 관련된 모든 종속성과 환경 설정을 컨테이너 내에 포함시켜, 어떤 환경에서든 동일한 방식으로 모 델을 실행할 수 있게 한다. 이를 통해 본 발명은 개발, 테스트, 배포 간 환경 일관성을 보장할 뿐만 아니라, 다 양한 클라우드 플랫폼이나 온프레미스 서버에서의 신속한 모델 배포와 이동성을 가능하게 할 수도 있다.이러한 컨테이너화된 모델 서빙 방식은 모델의 배포, 업데이트, 확장을 용이하게 하며, 다양한 환경에서의 호환 성과 신속한 통합을 가능하게 할 수 있다. 또한, 서버는 모델 서빙 컨테이너를 통해 모델의 성능 모니터링 및 자동 확장 기능을 구현하여, 사용자의 요청량이 증가할 경우 자동으로 리소스를 조정하고, 모델의 응답 시간 과 처리 능력을 최적화할 수 있습니다. 구체적으로, 서버는 모델 서빙 컨테이너를 통해 동적 확장성과 부하 분산 기능을 처리할 수 있다. 예를 들 어, 사용자의 요청량이 증가하는 경우, 서버는 자동으로 추가 컨테이너 인스턴스를 배포하여 처리 능력을 확장할 수 있다. 이는 쿠버네티스 같은 오케스트레이션 도구의 자동 확장(Auto-scaling) 기능을 활용하여 이루 어질 수 있다. 또한, 서버는 로드 밸런서를 사용하여 들어오는 요청을 여러 컨테이너 인스턴스에 균등하게 분산시키고, 각 컨테이너의 리소스 사용량을 모니터링하여, 리소스가 과부하 되지 않도록 관리할 수 있다. 이러 한 방식으로 서버는 모델의 응답 시간을 단축하고, 사용자 경험을 개선하며, 동시에 처리량을 최적화할 수 있습니다. 본 발명의 서버는 이러한 컨테이너화된 모델 서빙 방식과 동적 리소스 조정 및 처리 능력 최적화 기법을 통해 AI 모델의 실시간 추론 성능을 보장하고, 사용자 경험을 향상시키며, 실제 환경에서의 AI 모델의 적용 범 위를 넓힐 수 있다. 도 8은 본 발명의 다양한 실시예에 따른 학습 데이터를 자동으로 구축하는 방법의 일례를 설명하기 위한 도면이 다. 본 발명의 일 실시예에 따르면, 서버는 AI 모델의 학습 및 고도화와 관련된 다양한 작업을 수행할 수 있다. 일례로, 서버는 학습 데이터를 자동으로 구축할 수 있다. 구체적으로, 서버는 데이터에서 항목 의 존재여부와 이미지 내에서 항목의 범위 등을 파악하여 오토 라벨링이 수행되도록 야기할 수 있으며, 이 때, 자동으로 항목을 인식하도록 야기할 수 있다. 도 8을 참조하면, 서버는 입력된 이미지에 포함된 객체를 추론할 수 있다(S510). 구체적으로, 서버는 객체 감지와 관련된 제1 모델, 인스턴스 세그멘테이션과 관련된 제2 모델, 시멘틱 세 그멘테이션과 관련된 제3 모델을 앙상블 파이프라인으로 구축할 수 있다. 그리고, 서버는 앙상블 파이프라 인을 이용하여, 입력된 이미지에 포함된 객체를 추론할 수 있다. 본 발명에서 객체 감지는 객체의 특징을 사전에 추출하고 입력된 이미지 내에서 해당 특징를 검출하는 것을 의 미할 수 있다. 인스턴스 세그멘테이션(Instance segmentation)은 동일한 클래스에 대해 객체 별로 서로 다른 인 스턴스(instance)로 구분하는 것을 의미할 수 있다. 여기서, 인스턴스는 같은 클래스에 속하는 개개의 객체로 하나의 클래스에서 생성된 객체를 의미할 수 있다. 시멘틱 세그멘테이션(Semantic segmentation)은 동일한 클래 스에 대해 하나의 영역 또는 색상으로 구분하는 것을 의미할 수 있다. 한편, 제1 모델, 제2 모델 및 제3 모델을 이용하여 구축한 앙상블 파이프라인은 입력된 이미지에 대해, 제1 모 델을 이용한 객체 검출 작업, 제2 모델을 이용한 인스턴스 구분 작업 및 제3 모델을 이용한 클래스 구분 작업 각각을 특정 순서대로 순차적으로 진행할 수 있다. 예를 들어, 앙상블 파이프라인은, 제1 모델을 이용하여 객체를 검출한 후, 제3 모델을 이용하여 클래스를 구분 할 수 있다. 그리고, 앙상블 파이프라인은 제2 모델을 이용하여 객체 별로 인스턴스를 구분할 수 있다. 다만, 이에 한정되는 것은 아니다. 다양한 실시예에서, 서버는 단계(S110)에서 입력된 이미지에 포함된 객체를 추론할 때, 동적 배치(dynamic batch)를 통해 추론에 이용되는 공유 자원에 대한 할당 및 제거를 수행할 수 있다. 구체적으로, 추론이 수행되는 런타임(runtime)은 동적 배치 기술을 적용하여 실시간으로 다중입력에 대한 처리 를 고속으로 수행할 수 있다. 또한, 서버는 리소스 제어 스케줄러를 통해 추론을 실행하기 위해 사용되는 공유 자원에 대한 할당 및 제거를 수행할 수 있다. 이 경우, 메모리에 대한 유연한 접근이 가능할 수 있다. 서버는 추론을 완료한 경우, 추론 결과 값을 오픈 데이터셋 포맷으로 변환할 수 있다(S520). 그리고, 서버 는 오픈 데이터셋 포맷으로 변환된 데이터를 시각화하여 오토 라벨링을 수행할 수 있다(S530). 예를 들어, 서버는 추론 결과 값을 COCO, YOLO 및 PASCAL VOC 중 적어도 하나의 포맷으로 변환할 수 있으 나, 이에 한정되는 것은 아니다. 이하, 오토 라벨링을 수행하는 방법에 대한 설명은 도 3 및 도 4을 참조하여 후술한다. 다양한 실시예에 따르면, 도 8에서 설명한 단계들은 컨테이너 기반 기술을 이용하여 OS에 종속적이지 않은 별도 의 독립적인 프로세스로써 활용할 수 있다. 또한, 외부 프로세스 및 시스템과의 연계는 HTTP(Hypertext Transfer Protocol) 또는 Grpc(Google Remote Procedure Call) 프로토콜을 사용하여 통신이 가능할 수 있으나 이에 한정되는 것은 아니다. 도 9는 본 발명의 다양한 실시예에 따른 데이터 품질 향상을 위한 데이터셋 구축 방법의 일례를 설명하기 위한 도면이다. 본 발명의 일 실시예에 따르면, 서버는 AI 모델의 학습 및 고도화와 관련된 다양한 작업을 수행할 수 있다. 일례로, 서버는 데이터셋을 구축할 수 있다. 구체적으로, 서버는 워크플로우 기반의 데이터 처 리 플로우를 통해 데이터 수집, 정제, 전처리, 가공 등의 통합적인 데이터 처리 과정을 거쳐 조직 단위로 데이 터셋을 구축할 수 있다. 또한, 서버는 상술한 워크플로우와 관련된 플랫폼을 작업자 및 검수자에게 제공할 수 있다. 도 9를 참조하면, 서버는 이미지 데이터를 수집하고, 수집된 이미지 데이터에서 중복 데이터 및 손상 데이 터를 필터링할 수 있다(S610). 구체적으로, 서버는 클라이언트로부터 이미지 데이터를 수신하거나, 클라이언트로부터 요청된 주제의 이미 지를 웹크롤링하여 이미지 데이터를 수집할 수 있다. 서버는 필터링된 데이터를 검수자 단말로 전송하여 제1 검수 절차를 진행할 수 있다. 서버는 제1 검 수 절차가 완료된 경우, 제1 검수 절차가 완료된 데이터를 AI 모델 학습을 위한 입력 데이터 형식으로 전처리할 수 있다(S620). 예를 들어, 서버는 제1 검수 절차가 완료된 데이터에 대해 Grayscale, Contrast, Resize, Blur, Mosaic 및 Shifting 중 적어도 하나를 변경하여 입력 데이터 형식으로 전처리할 수 있으나, 이에 한정되는 것은 아니다. 서버는 전처리된 데이터를 검수자 단말로 전송하여 제2 검수 절차를 진행할 수 있다. 서버는 제2 검 수 절차가 완료된 경우, 제2 검수 절차가 완료된 데이터를 작업자 단말로 전송하여 라벨링 작업을 요청할 수 있 다(S630). 다양한 실시예에서, 서버는 라벨링 작업을 요청하는 경우, 라벨링 작업의 업무 효율을 높이기 위한 오토 라벨링 기능에 대한 사용 권한을 작업자 단말에게 부여할 수 있다. 여기서, 오토 라벨링 기능은 워크플로우와 관련된 플랫폼에서 제공하는 기능에 포함될 수 있으며, 작업자는 상기 플랫폼을 통해 라벨링 작업을 수행할 수 있다. 예를 들어, 플랫폼은 상술한 기능 외 도 8에 도시된 바와 같은 다양한 기능들을 포함할 수 있다. 서버는 작업자 단말로부터 라벨링 작업된 데이터를 수신하는 경우, 라벨링 작업된 데이터를 검수자 단말로 전송하여 제3 검수 절차를 진행할 수 있다(S640). 그리고, 서버는 제3 검수 절차가 완료된 경우, 제3 검수 절차가 완료된 데이터를 AI 모델 학습을 위한 학습 데이터로 결정할 수 있다(S650). 상술한 바와 같이, 서버는 필터링, 전처리 및 라벨링과 관련된 각 작업 단계가 완료될 때 마다 검수자의 검수 절차가 진행되도록 하여, 각 단계별 데이터 품질에 대한 신뢰도를 높일 수 있다. 도 10은 본 발명의 일 실시예와 관련된 하나 이상의 네트워크 함수를 나타낸 개략도이다. 본 명세서에 걸쳐, 인공지능 모델, 신경망 모델, 신경망, 네트워크 함수, 뉴럴 네트워크(neural network)는 동 일한 의미로 사용될 수 있다. 신경망은 일반적으로 “노드”라 지칭될 수 있는 상호 연결된 계산 단위들의 집합 으로 구성될 수 있다. 이러한 “노드”들은 “뉴런(neuron)”들로 지칭될 수도 있다. 딥 뉴럴 네트워크(DNN: deep neural network, 심층신경망)는 입력 레이어와 출력 레이어 외에 복수의 히든 레이 어를 포함하는 신경망을 의미할 수 있다. 딥 뉴럴 네트워크를 이용하면 데이터의 잠재적인 구조(latent structures)를 파악할 수 있다. 즉, 사진, 글, 비디오, 음성, 음악의 잠재적인 구조(예를 들어, 어떤 물체가 사진에 있는지, 글의 내용과 감정이 무엇인지, 음성의 내용과 감정이 무엇인지 등)를 파악할 수 있다. 딥 뉴럴 네 트워크는 컨볼루션 뉴럴 네트워크(CNN: convolutional neural network), 리커런트 뉴럴 네트워크(RNN: recurrent neural network), 오토 인코더(auto encoder), GAN(Generative Adversarial Networks), 제한 볼츠 만 머신(RBM: restricted boltzmann machine), 심층 신뢰 네트워크(DBN: deep belief network), Q 네트워크, U 네트워크, 샴 네트워크 등을 포함할 수 있다. 전술한 딥 뉴럴 네트워크의 기재는 예시일 뿐이며 본 발명은 이에 제한되지 않는다. 뉴럴 네트워크는 지도 학습(supervised learning), 비지도 학습(unsupervised learning), 및 반지도학습(semi supervised learning) 중 적어도 하나의 방식으로 학습될 수 있다. 뉴럴 네트워크의 학습은 출력의 오류를 최소 화하기 위한 것이다. 뉴럴 네트워크의 학습에서 반복적으로 학습 데이터를 뉴럴 네트워크에 입력시키고 학습 데 이터에 대한 뉴럴 네트워크의 출력과 타겟의 에러를 계산하고, 에러를 줄이기 위한 방향으로 뉴럴 네트워크의 에러를 뉴럴 네트워크의 출력 레이어에서부터 입력 레이어 방향으로 역전파(backpropagation)하여 뉴럴 네트워 크의 각 노드의 가중치를 업데이트 하는 과정이다. 지도 학습의 경우 각각의 학습 데이터에 정답이 라벨링 되어 있는 학습 데이터를 사용하며(즉, 라벨링된 학습 데이터), 비지도 학습의 경우는 각각의 학습 데이터에 정답이 라벨링 되어있지 않을 수 있다. 즉, 예를 들어 데이터 분류에 관한 지도 학습의 경우의 학습 데이터는 학습 데 이터 각각에 카테고리가 라벨링 된 데이터 일 수 있다. 라벨링된 학습 데이터가 뉴럴 네트워크에 입력되고, 뉴 럴 네트워크의 출력(카테고리)과 학습 데이터의 라벨이 비교함으로써 오류(error)가 계산될 수 있다. 다른 예로, 데이터 분류에 관한 비지도 학습의 경우 입력인 학습 데이터가 뉴럴 네트워크 출력과 비교됨으로써 오류 가 계산될 수 있다. 계산된 오류는 뉴럴 네트워크에서 역방향(즉, 출력 레이어에서 입력 레이어 방향)으로 역전 파 되며, 역전파에 따라 뉴럴 네트워크의 각 레이어의 각 노드들의 연결 가중치가 업데이트 될 수 있다. 업데이 트 되는 각 노드의 연결 가중치는 학습률(learning rate)에 따라 변화량이 결정될 수 있다. 입력 데이터에 대한 뉴럴 네트워크의 계산과 에러의 역전파는 학습 사이클(epoch)을 구성할 수 있다. 학습률은 뉴럴 네트워크의 학 습 사이클의 반복 횟수에 따라 상이하게 적용될 수 있다. 예를 들어, 뉴럴 네트워크의 학습 초기에는 높은 학습 률을 사용하여 뉴럴 네트워크가 빠르게 일정 수준의 성능을 확보하도록 하여 효율성을 높이고, 학습 후기에는 낮은 학습률을 사용하여 정확도를 높일 수 있다. 뉴럴 네트워크의 학습에서 일반적으로 학습 데이터는 실제 데이터(즉, 학습된 뉴럴 네트워크를 이용하여 처리하 고자 하는 데이터)의 부분집합일 수 있으며, 따라서, 학습 데이터에 대한 오류는 감소하나 실제 데이터에 대해 서는 오류가 증가하는 학습 사이클이 존재할 수 있다. 과적합(overfitting)은 이와 같이 학습 데이터에 과하게 학습하여 실제 데이터에 대한 오류가 증가하는 현상이다. 예를 들어, 노란색 고양이를 보여 고양이를 학습한 뉴 럴 네트워크가 노란색 이외의 고양이를 보고는 고양이임을 인식하지 못하는 현상이 과적합의 일종일 수 있다. 과적합은 머신러닝 알고리즘의 오류를 증가시키는 원인으로 작용할 수 있다. 이러한 과적합을 막기 위하여 다양 한 최적화 방법이 사용될 수 있다. 과적합을 막기 위해서는 학습 데이터를 증가시키거나, 레귤라이제이션 (regularization), 학습의 과정에서 네트워크의 노드 일부를 생략하는 드롭아웃(dropout) 등의 방법이 적용될 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 본 발명의 기술 분야에서 통상의 지식을 가진 자는 여기에 개시된 실시예들과 관련하여 설명된 다양한 예시적인 논리 블록들, 모듈들, 프로세서들, 수단들, 회로들 및 알고리즘 단계들이 전자 하드웨어, (편의를 위해, 여기에 서 \"소프트웨어\"로 지칭되는) 다양한 형태들의 프로그램 또는 설계 코드 또는 이들 모두의 결합에 의해 구현될 수 있다는 것을 이해할 것이다. 하드웨어 및 소프트웨어의 이러한 상호 호환성을 명확하게 설명하기 위해, 다양한 예시적인 컴포넌트들, 블록들, 모듈들, 회로들 및 단계들이 이들의 기능과 관련하여 위에서 일반적으로 설명 되었다. 이러한 기능이 하드웨어 또는 소프트웨어로서 구현되는지 여부는 특정한 애플리케이션 및 전체 시스템 에 대하여 부과되는 설계 제약들에 따라 좌우된다. 본 발명의 기술 분야에서 통상의 지식을 가진 자는 각각의 특정한 애플리케이션에 대하여 다양한 방식들로 설명된 기능을 구현할 수 있으나, 이러한 구현 결정들은 본 발 명의 범위를 벗어나는 것으로 해석되어서는 안 될 것이다. 여기서 제시된 다양한 실시예들은 방법, 장치, 또는 표준 프로그래밍 및/또는 엔지니어링 기술을 사용한 제조 물품(article)으로 구현될 수 있다. 용어 \"제조 물품\"은 임의의 컴퓨터-판독가능 장치로부터 액세스 가능한 컴 퓨터 프로그램, 캐리어, 또는 매체(media)를 포함한다. 예를 들어, 컴퓨터-판독가능 매체는 자기 저장 장치(예 를 들면, 하드 디스크, 플로피 디스크, 자기 스트립, 등), 광학 디스크(예를 들면, CD, DVD, 등), 스마트 카드, 및 플래쉬 메모리 장치(예를 들면, EEPROM, 카드, 스틱, 키 드라이브, 등)를 포함하지만, 이들로 제한되는 것은 아니다. 또한, 여기서 제시되는 다양한 저장 매체는 정보를 저장하기 위한 하나 이상의 장치 및/또는 다른 기 계-판독가능한 매체를 포함한다. 용어 \"기계-판독가능 매체\"는 명령(들) 및/또는 데이터를 저장, 보유, 및/또 는 전달할 수 있는 무선 채널 및 다양한 다른 매체를 포함하지만, 이들로 제한되는 것은 아니다. 제시된 프로세스들에 있는 단계들의 특정한 순서 또는 계층 구조는 예시적인 접근들의 일례임을 이해하도록 한 다. 설계 우선순위들에 기반하여, 본 발명의 범위 내에서 프로세스들에 있는 단계들의 특정한 순서 또는 계층 구조가 재배열될 수 있다는 것을 이해하도록 한다. 첨부된 방법 청구항들은 샘플 순서로 다양한 단계들의 엘리 먼트들을 제공하지만 제시된 특정한 순서 또는 계층 구조에 한정되는 것을 의미하지는 않는다."}
{"patent_id": "10-2024-0042985", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2024-0042985", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 시스템을 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 컴퓨팅 장치의 하드웨어 구성도이다. 도 3 내지 도 7은 본 발명의 일 실시예에 따른 AI 모델의 고도화를 자동적으로 수행하기 위한 방법의 일례를 설 명하기 위한 도면이다. 도 8은 본 발명의 다양한 실시예에 따른 학습 데이터를 자동으로 구축하는 방법의 일례를 설명하기 위한 도면이 다. 도 9는 본 발명의 다양한 실시예에 따른 데이터 품질 향상을 위한 데이터셋 구축 방법의 일례를 설명하기 위한 도면이다. 도 10은 본 발명의 일 실시예와 관련된 하나 이상의 네트워크 함수를 나타낸 개략도이다."}
