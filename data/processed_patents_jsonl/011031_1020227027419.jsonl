{"patent_id": "10-2022-7027419", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0006445", "출원번호": "10-2022-7027419", "발명의 명칭": "인공신경망을 이용한 영상 처리 방법 및 신경 프로세싱 유닛", "출원인": "주식회사 딥엑스", "발명자": "김녹원"}}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "객체를 포함하는 영상을 수신하는 단계;영상을 입력으로 하여 적어도 하나의 객체를 분류하도록 구성된 인공 신경망 기반의 제1 모델을 이용하여, 상기영상 내에서 상기 적어도 하나의 객체를 분류하는 단계, 및영상을 입력으로 하여 특정 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의복수의 제2 모델 중 적어도 하나의 모델을 이용하여, 상기 적어도 하나의 객체가 분류된 영상을 입력으로 하여상기 적어도 하나의 객체에 따라 향상된 품질의 영상을 획득하는 단계를 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적어도 하나의 객체는, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체이고,상기 복수의 제2 모델은, 상기 복수의 카테고리 각각에 대응하는 영상을 입력으로 하여, 상기 복수의 카테고리에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 복수의 모델이고,상기 방법은,상기 적어도 하나의 객체를 분류하는 단계 이후에,상기 적어도 하나의 객체의 카테고리를 결정하는 단계를 더 포함하고,상기 향상된 품질의 영상을 획득하는 단계는,상기 적어도 하나의 객체의 카테고리에 대응하는 상기 복수의 제2 모델 중 하나의 모델을 이용하여, 상기 향상된 품질의 영상을 획득하는 단계를 더 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 모델은,상기 영상을 입력으로 하여, 상기 적어도 하나의 객체의 영역을 출력하도록 더 구성되고,상기 방법은,상기 수신하는 단계 이후에,상기 제1 모델을 이용하여, 상기 영상 내에서 상기 적어도 하나의 객체의 영역을 결정하는 단계를 더 포함하고,상기 적어도 하나의 객체를 분류하는 단계는,상기 제1 모델을 이용하여, 상기 적어도 하나의 객체의 영역에 기초하여 상기 적어도 하나의 객체를 분류하는단계를 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 향상된 품질의 영상을 획득하는 단계는,상기 제2 모델을 이용하여, 상기 적어도 하나의 객체의 영역의 품질이 향상된 영상을 획득하는 단계를포함하는, 영상 처리 방법.공개특허 10-2023-0006445-3-청구항 5 제3항에 있어서,HMD(Head mount display) 장치로부터 시선 데이터를 수신하는 단계를 더 포함하고,상기 적어도 하나의 객체의 영역을 결정하는 단계는,상기 시선 데이터에 기초하여, 상기 적어도 하나의 객체의 영역을 결정하는 단계를 더 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 모델은 입력 레이어 및 복수 개의 노드(nodes) 로 이루어진 출력 레이어를 포함하고,상기 제2 모델의 개수는, 상기 제1 모델의 출력 레이어의 상기 노드 수에 대응하는, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 적어도 하나의 모델은,디노이징(Denoising) 모델, 디블러링(Deblurring) 모델, 엣지 강화(Edge Enhancement) 모델, 디모자이징(Demosaicing) 모델, 컬러 톤 강화(Color Tone Enhancing) 모델, 화이트 밸런싱(White Balancing) 모델, 초고해상도(Super resolution) 모델, 역광 보정(Wide dynamic range) 모델, 명암 대비 보정(high dynamic range)모델 및 디컴프레션(Decompression) 모델 중 적어도 하나인, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 적어도 하나의 모델은,복수의 상기 제2 모델 중 선택된 적어도 두 개의 모델이 결합된 앙상블 모델인, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체를 포함하는 영상을 수신하는 단계;영상을 입력으로 하여 객체를 분류하도록 구성된 인공 신경망 기반의 제1 모델을 이용하여, 상기 영상 내에서상기 객체의 카테고리를 결정하는 단계;상기 복수의 카테고리 각각에 대하여 미리 결정된 복수의 파라미터 중, 분류된 상기 객체의 카테고리에 대응하는 파라미터를, 영상을 입력으로 하여 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의 제2 모델에 적용하는 단계, 및상기 대응하는 파라미터가 적용된 제2 모델을 이용하여, 상기 카테고리가 결정된 영상을 입력으로 하여 상기 객체의 카테고리에 따라 향상된 품질의 영상을 획득하는 단계를 포함하는, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "객체를 포함하는 영상, 제1 모델 및 제2 모델을 저장하도록 구성된 내부 메모리, 및상기 내부 메모리에 액세스(access)하도록 구성되며, 상기 제1 모델 및 상기 제2 모델의 합성곱을 처리하도록구성된 프로세싱 엘리먼트(processing element; PE), 및상기 내부 메모리, 상기 프로세싱 엘리먼트와 동작 가능하게 연결된 컨트롤러(controller)를 포함하고,상기 제1 모델은, 영상을 입력으로 하여 객체를 분류하도록 구성된 인공 신경망 기반의 모델이고,상기 제2 모델은, 영상을 입력으로 하여 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신공개특허 10-2023-0006445-4-경망 기반의 복수의 모델이고,상기 컨트롤러는,상기 PE로 하여금, 상기 제1 모델을 이용하여 상기 영상 내에서 상기 객체를 분류하고, 복수의 상기 제2 모델중 적어도 하나의 모델을 이용하여 상기 객체가 분류된 영상을 기초로 상기 객체에 따라 향상된 품질의 영상을획득하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제1 모델 및 상기 제2 모델을 저장하도록 구성된 메인 메모리를 더 포함하고, 상기 내부 메모리는 상기 메인 메모리 내의 상기 제1 모델 및 상기 제2 모델을 읽어오도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 객체는, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체이고,상기 제2 모델은, 상기 복수의 카테고리 각각에 대응하는 영상을 입력으로 하여, 상기 복수의 카테고리 각각에 대하여 미리 결정된 처리가 적용된 영상을 출력하도록 구성된 복수의 모델이고,상기 컨트롤러는,상기 PE로 하여금, 상기 객체의 카테고리를 결정하고, 상기 객체의 카테고리에 대응하는 상기 복수의 제2 모델중 하나의 모델을 이용하여, 상기 향상된 품질의 영상을 획득하도록 더 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 복수의 상기 제2 모델 중 적어도 하나의 모델을 선택하도록 구성된 선택 모듈을 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 제1 모델은,상기 영상을 입력으로 하여, 상기 객체의 영역을 출력하도록 더 구성되고,상기 컨트롤러는,상기 PE로 하여금, 상기 제1 모델을 이용하여 상기 영상 내에서 상기 객체의 영역을 결정하고, 상기 제1 모델을이용하여 상기 객체의 영역에 기초하여 상기 객체를 분류하도록 더 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 컨트롤러는,상기 PE로 하여금, 상기 제2 모델을 이용하여 상기 객체의 영역의 품질이 향상된 영상을 획득하도록 더 구성된,신경 프로세싱 유닛."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,공개특허 10-2023-0006445-5-상기 내부 메모리는, HMD(Head mount display) 장치로부터 시선 데이터를 더 저장하고,상기 컨트롤러는,상기 PE로 하여금, 상기 시선 데이터에 기초하여, 상기 객체 영역을 결정하도록 더 구성된, 신경 프로세싱유닛."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,상기 제1 모델은 입력 레이어 및 복수 개의 노드(nodes) 로 이루어진 출력 레이어를 포함하고,상기 제2 모델의 개수는, 상기 제1 모델의 출력 레이어의 상기 노드 수에 대응하는, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,상기 적어도 하나의 모델은,디노이징(Denoising) 모델, 디블러링(Deblurring) 모델, 엣지 강화(Edge Enhancement) 모델, 디모자이징(Demosaicing) 모델, 컬러 톤 강화(Color Tone Enhancing) 모델, 화이트 밸런싱(White Balancing) 모델, 초고해상도(Super resolution) 모델, 역광 보정(Wide dynamic range) 모델, 명암 대비 보정(high dynamic range)모델 및 디컴프레션(Decompression) 모델 중 적어도 하나인, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제10항에 있어서,상기 적어도 하나의 모델은,복수의 상기 제2 모델 중 선택된 적어도 두 개의 모델이 결합된 앙상블 모델인, 영상 처리 방법."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제10항에 있어서,상기 제2 모델 각각에 의해 처리된 영역들을 조합하여, 상기 향상된 품질의 영상을 출력하도록 더 구성된, 신경프로세싱 유닛"}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제11항에 있어서,상기 제1 모델 및 상기 제2 모델 각각은 파라미터를 포함하고,상기 내부 메모리는, 상기 내부 메모리의 용량에 기초하여, 미리 결정된 사이즈로 타일링(tiling)된 상기 제1 모델의 파라미터 또는상기 제2 모델의 파라미터를 상기 메인 메모리로부터 읽어오도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제11항에 있어서,상기 제1 모델 및 상기 제2 모델 각각은 파라미터를 포함하고,상기 내부 메모리는, 상기 제1 모델의 파라미터를 포함하고, 선택적으로 상기 제2 모델의 파라미터를 상기 메인 메모리로부터 읽어오도록 구성된, 신경 프로세싱 유닛.공개특허 10-2023-0006445-6-청구항 23 제10항에 있어서,상기 제2 모델은 파라미터를 포함하고,상기 영상은 복수 개의 영상이고,상기 내부 메모리는, 상기 제1 모델에 의한, 상기 복수 개의 영상 중 선택된 영상에 대한 객체 분류 결과가 이전 영상에 대한 객체분류 결과와 동일할 경우, 상기 이전 영상에 대한 객체 분류 결과에 대응하는 상기 제2 모델의 파라미터를 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체를 포함하는 영상, 제1 모델 및 제2 모델을 저장하도록구성된 내부 메모리, 및상기 내부 메모리에 액세스(access)하도록 구성되며, 상기 제1 모델 및 상기 제2 모델의 합성곱을 처리하도록구성된 프로세싱 엘리먼트(processing element; PE), 및상기 내부 메모리, 상기 프로세싱 엘리먼트와 동작 가능하게 연결된 컨트롤러(controller)를 포함하고,상기 제1 모델은, 영상을 입력으로 하여 객체를 분류하도록 구성된 인공 신경망 기반의 모델이고,상기 제2 모델은, 영상을 입력으로 하여 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의 모델이고,상기 컨트롤러는,상기 PE로 하여금, 상기 제1 모델을 이용하여 상기 영상 내에서 상기 객체를 분류하고, 상기 분류된 객체 각각에 대하여 미리 결정된 복수의 파라미터 중, 분류된 상기 객체의 카테고리에 대응하는 파라미터를 상기 제2 모델에 적용하고, 상기 대응하는 파라미터가 적용된 제2 모델을 이용하여 상기 카테고리가 분류된 영상을 입력으로 하여 상기 객체의 카테고리에 따라 향상된 품질의 영상을 획득하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-7027419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제24항에 있어서,상기 복수의 파라미터를 선택하도록 구성된 선택 모듈을 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-7027419", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 예시에 따른 영상 처리 방법이 제공된다. 상기 방법은 ANN(artificial neural network) 에 대한 동작들을 수행하는 단계를 포함하고, 동작들을 위해, 복수의 채널들은 제 1 채널 및 제 2 채널을 포함하고, 동작 들은, 적어도 하나의 메모리, 일 세트의 가중치, 제 1 채널의 적어도 일부 및 제 2 채널의 적어도 일부를 저장하 는 단계; 그리고 제 1 채널의 적어도 일부 및 제 2 채널의 적어도 일부 각각과 일 세트의 가중치 값들을 계산하 는 단계를 포함한다."}
{"patent_id": "10-2022-7027419", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공신경망을 이용한 영상 처리 방법 및 신경 프로세싱 유닛에 관한 것이다."}
{"patent_id": "10-2022-7027419", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간은 인식(Recognition), 분류(Classification), 추론(Inference), 예측(Predict), 조작/의사결정 (Control/Decision making) 등을 할 수 있는 지능을 갖추고 있다. 인공지능(artificial intelligence: AI)은 인간의 지능을 인공적으로 모방하는 것을 의미한다. 인간의 뇌는 뉴런(Neuron)이라는 수많은 신경세포로 이루어져 있다. 각각의 뉴런은 시냅스(Synapse)라고 불리는 연결부위를 통해 수백에서 수천 개의 다른 뉴런들과 연결되어 있다. 인간의 지능을 모방하기 위하여, 생물학적 뉴런의 동작원리와 뉴런 간의 연결 관계를 모델링한 것을, 인공신경망(Artificial Neural Network, ANN) 모델이 라고 한다. 즉, 인공신경망은 뉴런들을 모방한 노드들을 레이어(Layer: 계층) 구조로 연결시킨, 시스템이다. 한편, 인공신경망은 컨볼루션 채널들과 풀링(pooling) 채널들이 반복되는 형태로 구성된다(예를 들어, 도 1). 컨볼루션 신경망에서 대부분의 연산시간은 컨볼루션 동작이 차지한다. 컨볼루션 신경망은 행렬(Matrix) 형태의 커널(kernel)에 의해 각 채널의 영상의 특징을 추출하고, 풀링(Pooling)에 의해 이동이나 왜곡 등의 항상성을제공하는 방식으로 사물을 인식한다. 각 채널에서는 입력 데이터와 커널의 컨볼루션으로 특징 맵(Feature Map) 을 구한다. 특징 맵에는 ReLU(Rectified Linear Unit) 같은 활성화 함수를 적용하여 해당 채널의 활성화 맵을 생성한다. 이후 활성화 맵에 풀링이 적용될 수 있다. 패턴을 실제로 분류하는 신경망은 특징 추출 신경망의 후 단에 위치하며, 완전 연결 레이어(Fully Connected Layer)라고 한다. 컨볼루션 신경망의 연산 처리에서 대부분 의 연산은 컨볼루션(즉, 컨볼루션) 또는 행렬곱을 통해 수행된다. 이때 필요한 커널들을 메모리로부터 읽어 오 는 빈도가 상당히 빈번하다. 이러한 컨볼루션 신경망 동작의 상당 부분은 각각의 채널에 대응되는 커널들을 메 모리로부터 읽어오는 시간이 차지한다. 최근, 이러한 인공신경망 기반의 모델, 또는 빅데이터를 이용한 기술을 카메라가 장착된 장치에 접목시켜서 카 메라로부터 촬영된 이미지 내의 객체를 탐지하거나 인식하는 연구가 진행되고 있다. 예를 들어, 인공지능 기반 의 객체 인식기는 자율 주행 자동차, 감시카메라, 드론 등의 카메라를 구비한 장치들에 적용될 수 있다. 이러한 인공지능 기반 객체 인식기가 카메라에 의해 촬영된 이미지 내의 객체를 미리 결정된 수준 이상의 인식율로 인 식하였을 때, 이러한 카메라 및 객체 인식기를 구비한 장치들이 인식된 객체를 기초로 자율주행 등과 같은 서비 스를 제공하는 것이 가능하다. 본 개시의 배경이 되는 기술은 본 개시에 대한 이해를 보다 용이하게 하기 위해 작성되었다. 본 개시의 배경이 되는 기술에 기재된 사항들이 선행기술로 존재한다고 인정하는 것으로 이해되어서는 안 된다."}
{"patent_id": "10-2022-7027419", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인공신경망 기반의 모델을 이용한 객체 인식 기술은, 전술한 바와 같이 필요한 커널들을 메모리로부터 읽어오는 빈도가 빈번하여, 높은 소모 전력량이 요구되고, 이로 인해 고성능 범용의 프로세서를 적용하기에 어려움이 있 을 수 있다. 본 개시의 발명자는 하기의 사항들에 대하여 인식하였다. 먼저, 인공신경망 기반의 모델을 이용하여, 영상 내 객체를 인식하고 후처리(post processing)를 수행하여 품질 이 향상된 영상이 획득될 수 있다. 보다 구체적으로, 영상 내에서 객체를 분류하도록 학습된 모델을 제공하고, 상기 객체 분류 모델을 통해 분류된 객체에 따라 영상을 처리하도록 학습된 복수의 독립된 인공신경망 기반의 영상 처리 모델을 이용할 경우, 객체 에 따라 품질이 개선된 영상의 획득이 가능할 수 있다. 특히, 객체(또는 객체의 카테고리) 각각에 대응하고, 객체의 특성에 따라 영상 품질을 향상시키도록 학습된 복 수의 인공신경망 모델이 선택적으로 적용될 수 있다. 즉, 영상 품질을 향상시키도록 학습된 모델의 수는, 분류된 객체의 수에 대응할 수 있다. 또한, 객체 또는 객체의 카테고리에 따라 파라미터 값이 미리 결정될 수 있다. 분류 결과에 따라 대응되는 객체 또는 객체의 카테고리의 파라미터가 선택되고, 영상 품질 향상을 위한 모델에 선택적으로 적용될 수 있다. 한편, 객체를 분류하고 영상의 품질을 향상시키도록 구성된 인공신경망 기반 모델의 추론 연산 시, 신경 프로세 싱 유닛(Neural Processing Unit; NPU)은 빈번하게 인공신경망 기반 모델의 각각의 레이어의 노드 및/또는 가중 치 값을 메모리, 예를 들면, 메인 메모리에서 읽어올 수 있다. 이때, 메인 메모리에 대한 액세스가 아닌 온칩 메모리나 NPU 내부 메모리에 대한 엑세스가 늘어날 수록 NPU의 처리 속도가 빨라지고 에너지 소비가 감소할 수 있다. 즉 NPU와 같은 내부 메모리를 통해 인공신경망 기반 모델을 불러와서 객체 인식을 수행하거나 영상 처리를 수행 할 경우, 영상 처리 속도가 향상될 수 있다. 이에, 본 개시가 해결하고자 하는 과제는 객체를 포함하는 영상을 수신하고, 인공신경망 기반 모델을 이용하여 객체를 분류하고 분류된 객체에 따른 처리를 적용하여, 영상 품질이 향상된 영상을 제공하는 영상 처리 방법 및 프로세싱 유닛을 제공하는 것이다."}
{"patent_id": "10-2022-7027419", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 바와 같은 과제를 해결하기 위하여 본 개시의 일 예시에 따른 영상 처리 방법이 제공된다. 상기 방법은, 객체를 포함하는 영상을 수신하는 단계, 영상을 입력으로 하여 적어도 하나의 객체를 분류하도록 구성된 인공 신경망 기반의 제1 모델을 이용하여, 영상 내에서 적어도 하나의 객체를 분류하는 단계, 및 영상을 입력으로 하여 특정 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의 복수의 제2 모델 중 적어도 하나의 모델을 이용하여, 적어도 하나의 객체가 분류된 영상을 입력으로 하여 적어도 하나 의 객체에 따라 향상된 품질의 영상을 획득하는 단계를 포함할 수 있다. 본 개시에 따르면, 적어도 하나의 객체는, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체이고, 복수 의 제2 모델은 복수의 카테고리 각각에 대응하는 영상을 입력으로 하여, 복수의 카테고리에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 복수의 모델일 수 있다. 이때, 상기 처리 방법은, 적어도 하나의 객체를 분류 하는 단계 이후에, 적어도 하나의 객체의 카테고리를 결정하는 단계를 더 포함할 수 있다. 나아가, 향상된 품질 의 영상을 획득하는 단계는, 적어도 하나의 객체의 카테고리에 대응하는 복수의 제2 모델 중 하나의 모델을 이 용하여, 향상된 품질의 영상을 획득하는 단계를 더 포함할 수 있다. 본 개시의 다른 예에 따르면, 제1 모델은, 영상을 입력으로 하여, 적어도 하나의 객체의 영역을 출력하도록 더 구성되고, 상기 처리 방법은, 수신하는 단계 이후에 제1 모델을 이용하여, 영상 내에서 적어도 하나의 객체의 영역을 결정하는 단계를 더 포함할 수 있다. 이때 적어도 하나의 객체를 분류하는 단계는, 제1 모델을 이용하여, 적어도 하나의 객체의 영역에 기초하여 적어도 하나의 객체를 분류하는 단계를 포함할 수 있다. 본 개시의 또 다른 예에 따르면, 향상된 품질의 영상을 획득하는 단계는, 제2 모델을 이용하여, 적어도 하나의 객체의 영역의 품질이 향상된 영상을 획득하는 단계를 포함할 수 있다. 본 개시의 또 다른 예에 따르면, 상기 처리 방법은, HMD(Head mount display) 장치로부터 시선 데이터를 수신하 는 단계를 더 포함할 수 있다. 이때, 적어도 하나의 객체의 영역을 결정하는 단계는, 시선 데이터에 기초하여, 적어도 하나의 객체의 영역을 결정하는 단계를 더 포함할 수 있다. 본 개시의 또 다른 예에 따르면, 제1 모델은 입력 레이어 및 복수 개의 노드(nodes)로 이루어진 출력 레이어를 포함할 수 있다. 제2 모델의 개수는, 제1 모델의 출력 레이어의 노드 수에 대응할 수 있다. 본 개시의 또 다른 예에 따르면, 적어도 하나의 모델은, 디노이징(Denoising) 모델, 디블러링(Deblurring) 모델, 엣지 강화(Edge Enhancement) 모델, 디모자이징(Demosaicing) 모델, 컬러 톤 강화(Color Tone Enhancing) 모델, 화이트 밸런싱(White Balancing) 모델, 초고해상도(Super resolution) 모델, 역광 보정(Wide dynamic range) 모델, 명암 대비 보정(high dynamic range) 모델 및 디컴프레션(Decompression) 모델 중 적어 도 하나일 수 있다. 본 개시의 또 다른 예에 따르면, 적어도 하나의 모델은, 복수의 제2 모델 중 선택된 적어도 두 개의 모델이 결 합된 앙상블 모델일 수 있다. 전술한 바와 같은 과제를 해결하기 위하여 본 개시의 다른 예시에 따른 영상 처리 방법이 제공될 수 있다. 상기 처리 방법은, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체를 포함하는 영상을 수신하고, 영상 을 입력으로 하여 객체를 분류하도록 구성된 인공 신경망 기반의 제1 모델을 이용하여, 영상 내에서 객체의 카 테고리를 결정하고, 복수의 카테고리 각각에 대하여 미리 결정된 복수의 파라미터 중, 분류된 객체의 카테고리 에 대응하는 파라미터를, 영상을 입력으로 하여 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의 제2 모델에 적용하고, 대응하는 파라미터가 적용된 제2 모델을 이용하여, 카테고리가 결정 된 영상을 입력으로 하여 객체의 카테고리에 따라 향상된 품질의 영상을 획득하는 단계를 포함할 수 있다. 전술한 바와 같은 과제를 해결하기 위하여 본 개시의 일 예시에 따른 프로세싱 유닛이 제공될 수 있다. 상기 프로세싱 유닛은, 객체를 포함하는 영상, 제1 모델 및 제2 모델을 저장하도록 구성된 내부 메모리, 및 내 부 메모리에 액세스(access)하도록 구성되며, 제1 모델 및 제2 모델의 합성곱을 처리하도록 구성된 프로세싱 엘 리먼트(processing element; PE), 및 내부 메모리, 프로세싱 엘리먼트와 동작 가능하게 연결된 컨트롤러 (controller)를 포함할 수 있다. 이때, 제1 모델은, 영상을 입력으로 하여 객체를 분류하도록 구성된 인공 신경 망 기반의 모델이고, 제2 모델은, 영상을 입력으로 하여 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의 복수의 모델일 수 있다. 나아가, 컨트롤러는, PE로 하여금, 제1 모델을 이용하여 영 상 내에서 객체를 분류하고, 복수의 제2 모델 중 적어도 하나의 모델을 이용하여 객체가 분류된 영상을 기초로객체에 따라 향상된 품질의 영상을 획득하도록 구성될 수 있다. 본 개시에 따르면, 상기 프로세싱 유닛은 제1 모델 및 제2 모델을 저장하도록 구성된 메인 메모리를 더 포함할 수 있다. 이때, 내부 메모리는 메인 메모리 내의 제1 모델 및 제2 모델을 읽어오도록 구성될 수 있다. 본 개시의 다른 예에 따르면, 객체는, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체이고, 제2 모델 은 복수의 카테고리 각각에 대응하는 영상을 입력으로 하여, 복수의 카테고리 각각에 대하여 미리 결정된 처리 가 적용된 영상을 출력하도록 구성된 복수의 모델일 수 있다. 이때, 컨트롤러는, PE로 하여금, 객체의 카테고리 를 결정하고, 객체의 카테고리에 대응하는 복수의 제2 모델 중 하나의 모델을 이용하여, 향상된 품질의 영상을 획득하도록 더 구성될 수 있다. 본 개시의 또 다른 예에 따르면, 복수의 제2 모델 중 적어도 하나의 모델을 선택하도록 구성된 선택 모듈을 더 포함할 수 있다. 본 개시의 또 다른 예에 따르면, 제1 모델은, 영상을 입력으로 하여, 객체의 영역을 출력하도록 더 구성될 수 있다. 컨트롤러는, PE로 하여금, 제1 모델을 이용하여 영상 내에서 객체의 영역을 결정하고, 제1 모델을 이용하 여 객체의 영역에 기초하여 객체를 분류하도록 더 구성될 수 있다. 본 개시의 또 다른 예에 따르면, 컨트롤러는, PE로 하여금, 제2 모델을 이용하여 객체의 영역의 품질이 향상된 영상을 획득하도록 더 구성될 수 있다. 본 개시의 또 다른 예에 따르면, 내부 메모리는, HMD(Head mount display) 장치로부터 시선 데이터를 더 저장하 고, 컨트롤러는, PE로 하여금, 시선 데이터에 기초하여, 객체 영역을 결정하도록 더 구성될 수 있다. 본 개시의 또 다른 예에 따르면, 제1 모델은 입력 레이어 및 복수 개의 노드(nodes) 로 이루어진 출력 레이어를 포함하고, 제2 모델의 개수는, 제1 모델의 출력 레이어의 노드 수에 대응할 수 있다. 본 개시의 또 다른 예에 따르면, 적어도 하나의 모델은, 디노이징(Denoising) 모델, 디블러링(Deblurring) 모델, 엣지 강화(Edge Enhancement) 모델, 디모자이징(Demosaicing) 모델, 컬러 톤 강화(Color Tone Enhancing) 모델, 화이트 밸런싱(White Balancing) 모델, 초고해상도(Super resolution) 모델, 역광 보정(Wide dynamic range) 모델, 명암 대비 보정(high dynamic range) 모델 및 디컴프레션(Decompression) 모델 중 적어 도 하나일 수 있다. 본 개시의 또 다른 예에 따르면, 적어도 하나의 모델은, 복수의 제2 모델 중 선택된 적어도 두 개의 모델이 결 합된 앙상블 모델일 수 있다. 본 개시의 또 다른 예에 따르면, 제2 모델 각각에 의해 처리된 영역들을 조합하여, 상기 향상된 품질의 영상을 출력하도록 더 구성될 수 있다. 본 개시의 또 다른 예에 따르면, 제1 모델 및 제2 모델 각각은 파라미터를 포함할 수 있다. 이때, 내부 메모리 는, 내부 메모리의 용량에 기초하여, 미리 결정된 사이즈로 타일링(tiling)된 제1 모델의 파라미터 또는 상기 제2 모델의 파라미터를 상기 메인 메모리로부터 읽어오도록 구성될 수 있다. 본 개시의 또 다른 예에 따르면, 제1 모델 및 제2 모델 각각은 파라미터를 포함하고, 내부 메모리는 제1 모델의 파라미터를 포함하고, 선택적으로 제2 모델의 파라미터를 메인 메모리로부터 읽어오도록 구성될 수 있다. 본 개시의 또 다른 예에 따르면, 제2 모델은 파라미터를 포함하고, 영상은 복수 개의 영상이고, 내부 메모리는 제1 모델에 의한, 복수 개의 영상 중 선택된 영상에 대한 객체 분류 결과가 이전 영상에 대한 객체 분류 결과와 동일할 경우, 이전 영상에 대한 객체 분류 결과에 대응하는 제2 모델의 파라미터를 포함할 수 있다. 전술한 바와 같은 과제를 해결하기 위하여 본 개시의 다른 예시에 따른 프로세싱 유닛이 제공된다. 상기 프로세싱 유닛은, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체를 포함하는 영상, 제1 모델 및 제2 모델을 저장하도록 구성된 내부 메모리, 내부 메모리에 액세스(access)하도록 구성되며, 제1 모델 및 제2 모델의 합성곱을 처리하도록 구성된 프로세싱 엘리먼트(processing element; PE), 및 내부 메모리, 프로세싱 엘 리먼트와 동작 가능하게 연결된 컨트롤러(controller)를 포함한다. 이때, 제1 모델은, 영상을 입력으로 하여 객 체를 분류하도록 구성된 인공 신경망 기반의 모델이고, 제2 모델은, 영상을 입력으로 하여 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의 모델이다. 또한, 컨트롤러는, PE로 하여금, 제1 모델을 이용하여 영상 내에서 객체를 분류할 수 있다. 분류된 객체 각각에 대하여 미리 결정된 복수의 파라미터중, 분류된 객체의 카테고리에 대응하는 파라미터를 제2 모델에 적용하고, 대응하는 파라미터가 적용된 제2 모 델을 이용하여 카테고리가 분류된 영상을 입력으로 하여 객체의 카테고리에 따라 향상된 품질의 영상을 획득하 도록 구성될 수 있다. 본 개시에 따르면, 복수의 파라미터를 선택하도록 구성된 선택 모듈을 더 포함할 수 있다."}
{"patent_id": "10-2022-7027419", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 영상 내에서 객체를 분류하도록 학습된 모델과 분류된 객체에 따라 영상을 처리하도록 학습 된 모델의 독립된 인공신경망 기반의 모델을 제공함에 따라, 객체에 따라 품질이 개선된 영상 제공이 가능할 수 있다. 특히, 본 개시에 따르면, 영상 내에서 객체를 분류하도록 학습된 모델과 분류된 객체에 따라 영상을 처리하도록 학습된 모델의 복수의 독립된 인공신경망 기반의 모델을 제공함에 따라, 객체의 특성에 따라 품질이 개선된 영 상의 획득이 가능할 수 있다. 본 개시에 따르면, 객체를 분류하고 영상의 품질을 향상시키도록 구성된 인공신경망 기반 모델의 추론 연산을 고려한 신경 프로세싱 유닛(Neural Processing Unit; NPU) 기반의 프로세싱 유닛이 제공될 수 있다. 이에, NPU와 같은 내부 메모리를 통해 인공신경망 기반 모델 기반의 처리가 가능함에 따라, 품질이 향상된 영상 획득을 위한 처리 속도가 향상될 수 있다."}
{"patent_id": "10-2022-7027419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 또는 출원에 개시되어 있는 본 개시의 개념에 따른 실시 예들에 대해서 특정한 구조적 내지 단계적 설명들은 단지 본 개시의 개념에 따른 실시 예를 설명하기 위한 목적으로 예시된 것이다. 본 개시의 개념에 따른 실시 예들은 다양한 형태로 실시될 수 있다. 본 개시의 개념에 따른 실시 예들은 다양한 형태로 실시될 수 있다. 본 명세서 또는 출원에 설명된 실시 예들에 한정되는 것으로 해석되어서는 아니 된다. 본 개시의 개념에 따른 실시 예는 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있다. 이에, 특정 실 시 예들을 도면에 예시하고 본 명세서 또는 출원에 상세하게 설명하고자 한다. 그러나, 이는 본 개시의 개념에따른 실시 예를 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 개시의 사상 및 기술 범위에 포함되는 모 든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제 1 및/또는 제 2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로만, 예컨대 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제 1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소 는 제 1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직 접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 문서에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\" 등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 문서에서 사용된 \"제 1,\" \"제 2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 예를 들면, 제 1 사용자 기기와 제 2 사용자 기기는, 순서 또는 중요도와 무관하게, 서로 다른 사용자 기기를 나타낼 수 있다. 예를 들면, 본 문서에 기재된 권리범위를 벗어나지 않으면서 제 1 구성요 소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 바꾸어 명명될 수 있다. 본 문서에서 사용된 용어들은 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다른 예시의 범위를 한정하 려는 의도가 아닐 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인"}
{"patent_id": "10-2022-7027419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "용어를 포함해서 여기서 사용되는 용어들은 본 문서에 기재된 기술분야에서 통상의 지식을 가진 자에 의해 일반 적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 문서에 사용된 용어들 중 일반적인 사전에 정의된 용어들은, 관련 기술의 문맥상 가지는 의미와 동일 또는 유사한 의미로 해석될 수 있으며, 본 문서에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 경우에 따라서, 본 문서에서 정의된 용어일지라도 본 문서의 실시 예들을 배제하도록 해 석될 수 없다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 서술된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가지는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 본 개시의 여러 예시들의 각각 특징들이 부분적으로 또는 전체적으로 서로 결합 또는 조합 가능하며, 당업자가 충분히 이해할 수 있듯이 기술적으로 다양한 연동 및 구동이 가능하며, 각 예시들이 서로에 대하여 독립적으로 실시 가능할 수도 있고 연관 관계로 함께 실시 가능할 수도 있다.실시 예를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략한다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않고 더 욱 명확히 전달하기 위함이다. <용어의 정의> 이하, 본 명세서에서 제시되는 개시들의 이해를 돕고자, 본 명세서에서 사용되는 용어들에 대하여 간략하게 정 리하기로 한다. 제1 모델: 객체를 포함하는 영상을 입력으로 하여 객체를 분류하도록 학습된 모델을 의미할 수 있다. 제1 모델은 영상 내 객체 영역을 분할(segmentation)하는 모델일 수 있다. 제1 모델은 영상 내의 객체를 분류할 수 있는 인공신경망 기반 분류기(classifier)일 수 있다. 제1 모델은 영상 내의 객체를 감지할 수 있는 인공신경망 기반 객체 인식기(object detector)일 수 있다. 제1 모델은 객체의 인식 및 또는 감지에 관한 인공신경망 기반의 모델일 수 있으나, 이에 제한되는 것은 아니다. 예를 들어, 제1 모델은 영상 내에서 픽셀(pixel) 값에 기초하여 객체 영역을 분할하도록 학습된 Segnet, Unet, faster RCNN, FCN 또는 Voxnet 기반의 영상 분할 모델, SVM(support vector machine), 의사 결 정 트리(Decision Tree), 랜덤 포래스트(Random Forest), AdaBoost(Adaptive Boosting) 또는 PLR(Penalized Logistic Regression) 기반의 분류기일 수도 있다. 제2 모델: 영상을 입력으로 하여, 분류된 객체에 따라 미리 결정된 처리가 적용된 영상을 출력하도록 학습된 모 델을 의미할 수 있다. 즉, 제2 모델은 제1 모델에 의해 분류된 객체 각각에 대하여 영상의 품질을 향상시키도록 학습된 복수의 모델일 수 있다. 다시 말해, 제2 모델의 수는 제1 모델의 출력 노드(nodes)의 수에 대응할 수 있 다. 한편, 제2 모델은 디노이징(Denoising) 모델, 디블러링(Deblurring) 모델, 엣지 강화(Edge Enhancement) 모델, 디모자이징(Demosaicing) 모델, 컬러 톤 강화(Color Tone Enhancing) 모델, 화이트 밸런싱(White Balancing) 모델, 초고해상도(Super resolution) 모델, 역광 보정(Wide dynamic range) 모델, 명암 대비 보정 (high dynamic range) 모델 및 디컴프레션(Decompression) 모델 중 적어도 하나일 수 있다. 예를 들어, 제2 모델은 입력된 영상에 대하여 초고해상도(Super Resolution; S/R)처리를 제공하는 제1 객체 모 델, 입력된 영상에 대하여 노이즈 제거, 즉 디노이징(Denoising) 처리를 제공하도록 학습된 제2 객체 모델, 입 력된 영상에 대하여 번짐 현상을 제거하는, 즉 디블러링(Deblurring) 처리를 제공하도록 학습된 제3 객체 모델, 입력된 영상에 대하여 엣지 강화(Edge Enhancement) 처리를 제공하도록 학습된 제4 객체 모델, 입력된 영상에 대하여 풀 컬러 이미지(full color image)를 재구성하는 디모자이징(Demosaicing) 처리를 제공하도록 학습된 제 5 객체 모델, 입력된 영상에 대하여 컬러 톤 강화(Color Tone Enhancing) 처리를 제공하도록 학습된 제6 객체 모델, 입력된 영상에 대하여 화이트 밸런싱(White Balancing) 처리를 제공하도록 학습된 제7 객체 모델 및 입력 된 영상에 대하여 압축을 제거하는 디컴프레션(Decompression) 처리를 제공하도록 학습된 제8 객체 모델 중 적 어도 하나의 영상 처리 모델일 수 있다. 각각의 객체 모델은 특정 처리 기능에 따라 준비된 각각의 트레이닝 데 이터셋으로 각각 학습된 딥러닝 학습된 모델일 수 있다. 나아가, 제2 모델은 영상의 카테고리 별 품질 향상을 제공하는 모델로서, 음식 영상에 대하여 향상된 품질의 영 상을 제공하도록 학습된 음식 영상 모델, 날씨 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 날씨 영 상 모델, 동물 및 곤충 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 동물 및 곤충 영상 모델, 풍경 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 풍경 영상 모델, 스포츠 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 스포츠 영상 모델, 의류 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 의 류 영상 모델, 사람 및 감정 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 사람 및 감정 영상 모델, 및 교통 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 교통 영상 모델의 영상의 카테고리에 따라 특 화된, 향상된 품질의 영상을 출력하도록 학습된 복수의 모델일 수 있다. 각각의 객체 모델은 특정 영상 품질 향 상에 따라 준비된 각각의 트레이닝 데이터셋으로 각각 학습된 딥러닝 학습된 모델일 수 있다. 그러나 이에 제한되는 것은 아니며, 제2 모델은 다양한 객체 모델의 조합이 앙상블된, 영상 품질 향상을 위한 모델일 수 있다. 더욱이, 제2 모델은 복수의 객체 모델이 병렬 또는 직렬로 연결된 모델일 수 있다. 나아가, 제2 모델은 단일 모델로 존재할 수 있다. 예를 들어, 단일의 제2 모델에, 복수의 객체마다 미리 설정된 파라미터가 적용될 수도 있고 이에 분류된 객체에 따라 품질이 향상된 최적의 영상 제공될 수 있다. 여기서, 영 상 품질 향상이란 인간에게 가시적으로 느껴지는 품질의 향상일 수 있으나, 이에 제한되지 않는다. 여기서 파라미터란 각 모델의 각각의 레이어에 적용되는 가중치, 커널의 값일 수 있다. 파라미터는 각각의 객체 모델에 따 라 각각 학습될 수 있다. 특히, 본 명세서에서 영상 품질 향상은 머신 러닝된 모델의 객체 인식률의 향상을 의 미할 수 있다. 인간에게 가시적으로 느껴지는 품질의 향상이 언제나 머신 러닝된 모델에서의 객체 인식률의 향 상을 야기하지는 않는다. 예를 들어, 도로 이미지에서 영상 품질 향상이란 사람 기준으로의 심미감 향상일 수도 있고, 머신 러닝된 모델에서 인식률을 높일 수 있는 품질 향상일 수도 있다. NPU: 신경 프로세싱 유닛(Neural Processing Unit)의 약어로서, CPU(Central processing unit)과 별개로 인공 신경망 기반 모델의 연산을 위해 특화된 프로세서를 의미할 수 있다. 인공신경망 가속기로 지칭되는 것도 가능 하다. 컨트롤러: 컨트롤러, 특히 NPU 컨트롤러는 NPU의 전반적인 타스크(task)를 제어하는 모듈을 의미할 수 있다. 컨 트롤러는 NPU에서 구동을 위해, 컴파일러가 ANN모델의 데이터 지역성을 분석하여 컴파일된 ANN 모델의 연산순서 정보를 제공받아 NPU의 업무 처리 순서를 결정한다. 컨트롤러는 내부 메모리 즉 NPU의 메모리 크기 및 프로세싱 엘리먼트 어레이의 성능을 기초로 ANN 모델의 레이어 별 타일링 정보가 저장될 수 있다. 더욱이 컨트롤러는, NPU 메모리 용량에 따라 외부에 존재하는 메인 메모리로부터 내부 메모리로 제1 모델 및/또는 제2 모델을 읽어 오도록 NPU를 제어할 수 있다. 나아가, 컨트롤러는 레지스터맵을 이용하여 NPU의 전반적인 타스크를 제어할 수 있다. 컨트롤러는 NPU에 포함되거나, NPU 외부에 배치될 수 있다. ANN: 인공신경망(artificial neural network)의 약어로서, 인간의 지능을 모방하기 위하여, 인간 뇌 속의 뉴런 들(Neurons)이 시냅스(Synapse)를 통하여 연결되는 것을 모방하여, 노드들을 레이어(Layer: 계층) 구조로 연결 시킨, 네트워크를 의미할 수 있다. DNN: 심층 신경망(Deep Neural Network)의 약어로서, 보다 높은 인공 지능을 구현하기 위하여, 인공신경망의 은 닉 레이어의 개수를 늘린 것을 의미할 수 있다. CNN: 컨볼루션 신경망(Convolutional Neural Network)의 약어로서, 인간 뇌의 시각 피질에서 영상을 처리하는 것과 유사한 기능을 하는 신경망이다. 컨볼루션 신경망은 영상처리에 적합한 것으로 알려져 있으며, 입력 데이 터의 특징들을 추출하고, 특징들의 패턴을 파악하기에 용이한 것으로 알려져 있다. CNN에서의 가중치는 N x M 크기의 커널을 지칭할 수 있다. 이하, 첨부한 도면을 참조하여 본 개시의 실시 예를 설명함으로써, 본 개시를 상세히 설명한다. 이하, 본 개시 의 실시 예를 첨부된 도면을 참조하여 상세하게 설명한다. 먼저, 도 1을 참조하여 인공신경망 중에서 심층 신경망(DNN)의 한 종류인 컨볼루션 신경망(CNN)에 대하여 설명 하기로 한다. 도 1은 본 개시에 관련된 컨볼루션 신경망을 설명하는 개략적인 개념도이다. 도 1을 참조하면, 컨볼루션 신경망은 적어도 하나의 컨볼루션 레이어, 적어도 하나의 풀링 레이어, 및 적어도 하나의 완전 연결 레이어를 포함한다. 예를 들면, 컨볼루션은, 입력 데이터의 크기(통상적으로 1×1, 3×3 또는 5×5 행렬)와 출력 특징 맵(Feature Map)의 깊이(커널의 수)와 같은 두 개의 주요 파라미터에 의해 정의될 수 있다. 이러한 주요 파라미터는 컨볼루 션에 의해 연산될 수 있다. 이들 컨볼루션은, 깊이 32에서 시작하여, 깊이 64로 계속되며, 깊이 128 또는 256에 서 종료될 수 있다. 컨볼루션 연산은, 입력 데이터인 입력 이미지 행렬 위로 3×3 또는 5×5 크기의 커널 (kernel)을 슬라이딩하여 커널의 각 원소와 겹쳐지는 입력 이미지 행렬의 각 원소를 곱한 후 이들을 모두 더하 는 연산을 의미한다. 여기서, 입력 이미지 행렬은 3차원 패치(3D patch)이며, 커널은 가중치라고 하는 동일한 학습 가중치 행렬을 의미한다. 즉, 인공신경망의 가중치는 특정 인공신경망의 특정 기능을 수행할 수 있는 파라 미터가 될 수 있다. 다시 말해서, 컨볼루션은 3차원 패치가 학습 가중치 행렬과의 텐서(tensor) 곱에 의해 1차원 벡터로 변환되고, 이러한 벡터가 3차원 출력 특징맵으로 공간적으로 재조립되는 동작을 의미한다. 출력 특징맵의 모든 공간 위치 는 입력 특징맵의 동일한 위치에 대응될 수 있다. 컨볼루션 레이어는, 학습 과정 동안 많은 그라디언트 업데이트 반복에 걸쳐 학습되는 커널(즉, 가중치 행렬)과 입력 데이터 간의 컨볼루션을 수행할 수 있다. (m, n)을 커널 크기라고 하고 W를 가중치 값이라고 설정하면, 컨 볼루션 레이어는 내적을 계산함으로써 입력 데이터와 가중치 행렬의 컨볼루션을 수행할 수 있다. 커널이 입력 데이터를 가로질러 슬라이딩하는 단차 크기를 간격이라고 하며, 커널 면적(m×n)을 수용장 (receptive field)이라고 할 수 있다. 동일한 컨볼루션 커널이 입력의 상이한 위치에 걸쳐 적용되며, 이는 학습 되는 커널의 수를 감소시킨다. 이것은, 또한, 위치 불변 학습을 가능하게 하며, 중요한 패턴이 입력에 존재하는 경우, 컨볼루션 필터(즉, 커널)는 시퀀스의 위치에 관계없이 그 패턴을 학습할 수 있다. 이와 같이 생성된 출력 특징맵에 활성화 함수가 적용되어 활성화 맵이 최종적으로 출력될 수 있다. 또한, 현재 레이어에서의 사용된 가중치는 컨볼루션을 통해 다음 레이어에 전달될 수 있다. 풀링 레이어는 출력 데이터(즉, 활성화 맵)을 다운 샘플링하여 특징맵의 크기를 줄이는 풀링 연산을 수행할 수 있다. 예를 들어, 풀링 연산은 최대 풀링(max pooling) 및/또는 평균 풀링(average pooling)을 포함할 수 있으나, 이에 한정되지 않는다. 최대 풀링 연산은 커널을 이용하며, 특징맵과 커널이 슬라이딩되어 커널과 겹쳐지는 특징맵의 영역에서 최대 값을 출 력한다. 평균 풀링 연산은 특징맵과 커널이 슬라이딩되어 커널과 겹쳐지는 특징맵의 영역 내에서 평균값을 출력 한다. 이처럼 풀링 연산에 의해 특징맵의 크기가 줄어들기 때문에 특징맵의 가중치 개수 또한 줄어든다. 완전 연결 레이어는 풀링 레이어를 통해서 출력된 데이터를 복수의 클래스(즉, 추정값)로 분류하고, 분류된 클 래스 및 이에 대한 점수(score)를 출력할 수 있다. 풀링 레이어를 통해서 출력된 데이터는 3차원 특징맵 형태를 이루며, 이러한 3차원 특징맵이 1차원 벡터로 변환되어 완전 연결 레이어로 입력될 수 있다. 컨볼루션 신경망은, 입력 데이터가 특정 출력 추정값으로 이어지도록 조정되거나 학습될 수 있다. 다시 말해서, 컨볼루션 신경망은 출력 추정값이 실측 자료(ground truth)에 점진적으로 일치하거나 근접할 때까지 출력 추정 값과 실측 자료 간의 비교에 기초하여 역전파(back propagation)를 이용하여 조정될 수 있다. 컨볼루션 신경망은, 실측 자료와 실제 출력 간의 차이에 기초하는 뉴런들 간의 가중치를 조정함으로써 학습될 수 있다. 학습이 완료된 가중치는 특정 인공신경망의 파라미터로써 활용될 수 있다. 도 2는 본 개시의 일 예시에 따른 신경 프로세싱 유닛이 포함된 장치를 설명하는 개략적인 개념도이다. 도 2을 참조하면 NPU이 포함된 장치(B)는 온칩 영역(A)을 포함한다. 온칩 영역 외부에는 메인 메모리 가 포함될 수 있다. 메인 메모리는 예를 들어 DRAM등과 같은 시스템 메모리일 수 있다. 도시되지 않았으나, 온칩 영역(A) 외부에는 ROM등을 포함하는 저장부가 포함될 수 있다. 온칩 영역(A)에는 중앙 프로세싱 유닛(CPU)와 같은 범용 프로세싱 유닛과 온칩 메모리 그리고 NPU가 배치된다. CPU는 NPU와 온칩 메모리 그리고 메인 메모리에 동작 가능하 게 연결된다. 단, 본 개시는 이에 제한되지 않으며, CPU 내부에 NPU가 포함되도록 구성되는 것도 가능하다. 온칩 메모리는 반도체 다이에 실장된 메모리로 메인 메모리 액세스와 별도로 캐싱을 위한 메모리일 수 있다. 예를 들면, 온칩 메모리는 다른 온칩 반도체들이 액세스하도록 설정된 메모리일 수도 있다. 예를 들면, 온칩 메모리는 캐시 메모리 또는 버퍼 메모리 일 수 있다. NPU는 내부 메모리를 포함하며, 내부 메모리는 예를 들어 SRAM을 포함할 수 있다. 내부 메모리 는 실질적으로 NPU에서의 연산에만 사용되는 메모리 일 수 있다. 내부 메모리는 NPU 내부 메모 리로 지칭될 수 있다. 여기서 실질적이란, 내부 메모리에는 NPU가 처리하는 인공신경망과 관련된 데 이터, 예를 들어 영상 내에서 객체를 인식하고 분류하는 제1 모델의 파라미터 및 객체에 따라 특화된 영상 처리 를 제공하는 제2 모델의 파라미터를 저장하도록 구성된 것을 의미할 수 있다. 여기서 파라미터는 레지스터맵, 가중치, 커널, 입력 특징 맵, 출력 특징 맵 등을 포함할 수 있다. 예를 들면, 내부 메모리는 NPU 연산에 필요한 가중치, 커널 및/또는 특징맵을 저장하도록 구성된 버 퍼 메모리 및/또는 캐시 메모리 일 수 있다. 단, 이에 제한되지 않는다. 예를 들면, 내부 메모리는 SRAM, MRAM, 레지스터 파일(Register file) 등의 읽고 쓰기가 메인 메모리 보다 상대적으로 더 빠른 메모리 소자로 구성될 수 있다. 단, 이에 제한되지 않는다. NPU이 포함된 장치(B)는 내부 메모리, 온칩 메모리, 메인 메모리 중 적어도 하나를 포 함한다. 이하에서 설명하는 “적어도 하나의 메모리”는 내부 메모리, 및 온칩 메모리중 적어도 하나를 포함 하도록 의도된다. 또한, 온칩 메모리의 기재는 NPU의 내부 메모리 또는 NPU의 외부에 있으나 온칩 영역 (A)에 있는 메모리를 포함하도록 의도될 수 있다. 다만, 적어도 하나의 메모리를 지칭하는 내부 메모리 및/또는 온칩 메모리는 위치적 특성이 아닌 메 모리의 대역폭(bandwidth) 기준으로 메인 메모리와 구분하는 것도 가능하다. 통상적으로 메인 메모리는 대용량의 데이터를 저장하기 용이하나, 메모리 대역폭이 상대적으로 낮고, 전 력 소모가 상대적으로 큰 메모리를 지칭한다. 통상적으로 내부 메모리와 온칩 메모리는 메모리 대역폭이 상대적으로 높고, 전력 소모가 상대적으 로 낮으나, 대용량의 데이터를 저장하기에 비효율 적인 메모리를 지칭한다. 본 개시에서, '내부 메모리'는 'NPU 메모리'와 상호 교환적으로 사용될 수 있다. NPU가 포함된 장치(B)의 각각의 구성요소는 버스를 통해서 통신할 수 있다. 장치(B)의 버스 는 적어도 하나일 수 있다. 버스는 통신 버스, 및/또는 시스템 버스 등으로 지칭될 수 있다. NPU의 내부 메모리와 온 칩 메모리는 인공신경망 기반의 제1 모델 및 제2 모델의 가중치와 특 징맵 처리를 위해 특정 대역폭 이상을 보장하기 위해서 별도의 전용 버스를 더 구비하는 것도 가능하다. 온 칩 메모리와 메인 메모리 사이에는 특정 대역폭 이상을 보장하기 위해서 별도의 전용 버스를 더 구비하는 것도 가능하다. 상기 특정 대역폭은 NPU의 프로세싱 엘리먼트 어레이의 처리 성능을 기준으로 결정될 수 있다. NPU의 내부 메모리와 메인 메모리 사이에는 특정 대역폭 이상을 보장하기 위해서 별도의 전용 버스를 더 구비하는 것도 가능하다. 상기 특정 대역폭은 NPU의 프로세싱 엘리먼트 어레이의 처리 성능을 기준으로 결정될 수 있다. NPU이 포함된 장치(B)는 DMA(Direct Memory Access) 모듈을 더 포함하여, 내부 메모리, 온 칩 메모 리 및/또는 메인 메모리를 직접 제어하도록 구성되는 것도 가능하다. 예를 들면, DMA 모듈은 버스를 직접 제어하여 NPU와 온칩 메모리의 데이터 전송을 직접 제어 하도록 구성될 수 있다. 예를 들면, DMA 모듈은 버스를 직접 제어하여 온칩 메모리와 메인 메모리의 데이터 전송을 직접 제어하도록 구성될 수 있다. 예를 들면, DMA 모듈은 버스를 직접 제어하여 내부 메모리와 메인 메모리의 데이터 전송을 직 접 제어하도록 구성될 수 있다. 신경 프로세싱 유닛(neural processing unit; NPU)은 인공신경망을 위한 동작을 수행하도록 특화된 프로 세서이다. NPU는 AI 가속기로 지칭될 수 있다. 인공신경망은 여러 입력 또는 자극이 들어오면 각각 가중치를 곱해 더해주고, 추가적으로 편차를 더한 값을 활 성화 함수를 통해 변형하여 전달하는 인공 뉴런들이 모인 네트워크를 의미한다. 이렇게 학습된 인공신경망은 입 력 데이터로부터 추론(inference) 결과를 출력하는데 사용될 수 있다. 상기 NPU은 전기/전자 회로로 구현된 반도체일 수 있다. 상기 전기/전자 회로라 함은 수많은 전자 소자, (예컨대 트렌지스터, 커패시터)를 포함하는 것을 의미할 수 있다. 상기 NPU은 프로세싱 엘리먼트 (processing element: PE) 어레이, NPU 내부 메모리, NPU 스케줄러, 및 NPU 인터페이스를 포함할 수 있다. 프로세싱 엘리먼트 어레이, NPU 내부 메모리, NPU 스케줄러, 및 NPU 인터페이스 각각은 수많은 트렌 지스터들이 연결된 반도체 회로일 수 있다. 따라서, 이들 중 일부는 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해서만 식별될 수 있다. 예컨 대, 임의 회로는 프로세싱 엘리먼트 어레이로 동작하기도 하고, 혹은 NPU 스케줄러로 동작될 수도 있다. 상기 NPU은 프로세싱 엘리먼트 어레이, 프로세싱 엘리먼트 어레이에서 추론될 수 있는 인공신경망 기반의 제1 모델 및 제2 모델의 적어도 일부를 저장하도록 구성된 NPU 내부 메모리, 및 인공신경망 기반의 제1 모 델 및 제2 모델의 데이터 지역성 정보 또는 인공신경망 기반의 제1 모델 및 제2 모델의 구조에 대한 정보에 기 초하여 프로세싱 엘리먼트 어레이 및 NPU 내부 메모리를 제어하도록 구성된 NPU 컨트롤러(또는 스케줄러)를 포함할 수 있다. 인공신경망 기반의 제1 모델 및 제2 모델은 인공신경망 기반 모델의 데이터 지역성 정보 또는 구조에 대한 정보 를 포함할 수 있다. 프로세싱 엘리먼트 어레이는 인공신경망을 위한 동작을 수행할 수 있다. 예를 들어, 객체를 포함하는 영상의 입 력 데이터가 입력되었을 때, 프로세싱 엘리먼트 어레이는 제1 모델에 대하여 객체를 분류하고, 제2 모델에 대하 여 분류된 객체에 대하여 영상을 처리하도록 학습을 수행할 수 있다. 학습이 완료된 이후, 입력 데이터가 입력 되었을 때, 프로세싱 엘리먼트 어레이는 학습 완료된 인공신경망 기반의 제1 모델 및 제2 모델을 통해 객체의 종류마다 품질이 향상된 영상을 생성 및 도출하는 동작을 수행할 수 있다. 프로세싱 엘리먼트 어레이는 적어도 하나의 프로세싱 엘리먼트로 변형 실시되는 것도 가능하다. 이때, NPU은 NPU 인터페이스를 통해서 메인 메모리에 저장된 인공신경망 기반의 제1 모델 및 제2 모델의 데이터, 즉 파라미터를 NPU 내부 메모리으로 불러올 수 있다. NPU 인터페이스는 버스를 통해 서 메인 메모리와 통신할 수 있다. NPU 컨트롤러는 NPU의 추론 연산을 위한 프로세싱 엘리먼트 어레이의 연산 및 NPU 내부 메모리의 읽 기 및 쓰기 순서를 제어하도록 구성된다. 또한 NPU 컨트롤러는 채널의 적어도 일부의 크기를 조정하도록 구성된 다. NPU 컨트롤러는 인공신경망 기반의 제1 모델 및 제2 모델의 구조를 분석하거나 또는 인공신경망 기반의 제1 모 델 및 제2 모델의 구조를 제공받을 수 있다. 다음으로, NPU 컨트롤러는 각 레이어 별 연산순서를 순차적으로 결 정할 수 있다. 즉, 인공신경망 기반의 제1 모델 및 제2 모델의 구조가 확정될 경우, 레이어 별 연산순서가 정해 질 수 있다. 이러한 인공신경망 기반의 제1 모델 및 제2 모델의 구조에 따른 연산의 순서 또는 데이터 흐름의 순서를 알고리즘 레벨에서의 인공신경망 기반의 제1 모델 및 제2 모델의 데이터 지역성으로 정의할 수 있다. NPU 컨트롤러는 상기 인공신경망 기반의 제1 모델 및 제2 모델의 구조를 반영하여 각 레이어 별 연산순서를 순 차적으로 결정한다. 즉, 인공신경망 기반의 제1 모델 및 제2 모델의 구조가 확정될 경우, 레이어 별 연산순서가 정해질 수 있다. 이러한 인공신경망 기반의 제1 모델 및 제2 모델의 구조에 따른 연산의 순서 또는 데이터 흐름 의 순서를 알고리즘 레벨에서의 인공신경망 기반의 제1 모델 및 제2 모델의 데이터 지역성 또는 인공신경망 기 반의 제1 모델 및 제2 모델의 데이터 지역성으로 정의할 수 있다. 인공신경망 기반의 제1 모델 및 제2 모델의 데이터 지역성은 각 모델의 구조, 레이어의 개수, 채널의 개수, 및 NPU 구조를 모두 고려하여 결정될 수 있다. 인공신경망 기반의 제1 모델 및 제2 모델이 NPU에서 실행되도록 컴파일러가 인공신경망 기반의 제1 모델 및 제2 모델을 컴파일할 경우, 신경 프로세싱 유닛-메모리 레벨에서의 인공신경망 기반의 제1 모델 및 제2 모델 의 인공신경망 데이터 지역성이 재구성될 수 있다. 예를 들어, 컴파일러는 CPU에 의해 실행될 수 있다. 즉, 컴파일러, 인공신경망 기반의 제1 모델 및 제2 모델에 적용된 알고리즘들, 및 NPU의 동작 특성, 가중 치의 크기, 및 특징맵의 크기에 따라서 내부 메모리에 로딩되는 가중치 값들, 및 채널의 크기가 결정될 수 있다. 예를 들면, 동일한 제1 모델 및 제2 모델의 경우에도 NPU이 해당 제1 모델 및 제2 모델을 연산하는 방식, 예를 들면, 가중치 타일링(weight tiling), 특징맵 타일링(feature map tiling), 프로세싱 엘리먼트의 스테이 셔너리(Stationary) 기법, NPU의 프로세싱 엘리먼트 개수, NPU의 내부 메모리 용량, NPU내 의 메모리 계층 구조, 및 제1 모델 및 제2 모델을 처리하기 위한 NPU의 연산 순서를 스케줄링해 주는 컴 파일러의 알고리즘 특성 등에 따라서 처리하고자 하는 제1 모델 및 제2 모델의 데이터 지역성이 구성될 수 있다. 컴파일러에 의해서 제1 모델 및 제2 모델을 처리하기 위한 NPU의 연산 순서가 스케줄링 되면, 컨트 롤러는 결정된 스케줄링에 의해서 NPU의 각 구성요소를 제어할 수 있다. 이하에서는, 도 3을 참조하여, 본 개시의 다양한 실시예에 이용되는 신경 프로세싱 유닛에 대하여 상세하기 설 명하기로 한다. 도 3은 본 개시의 일 예시에 따른 신경 프로세싱 유닛을 설명하는 개략적인 개념도이다. 신경 프로세싱 유닛(NPU)은 프로세싱 엘리먼트 어레이, 내부 메모리, 컨트롤러 및 특수기 능 유닛(SFU)를 포함할 수 있다.보다 구체적으로, 프로세싱 엘리먼트 어레이는 인공신경망의 노드 데이터와 연결망의 가중치 데이터를 연 산하도록 구성된 복수의 프로세싱 엘리먼트들(PE1…)을 포함하도록 구성된다. 각각의 프로세싱 엘리먼트는 MAC(multiply and accumulate) 연산기 및/또는 ALU(Arithmetic Logic Unit) 연산기를 포함할 수 있다. 단, 본 개시에 따른 예시들은 이에 제한되지 않는다. 제시된 실시예에서 복수의 프로세싱 엘리먼트들(PE1…)이 도시되었지만, 하나의 프로세싱 엘리먼트 내부에 MAC을 대체하여, 복수의 곱셈기(multiplier) 및 가산기 트리(adder tree)로 구현된 연산기들이 병렬로 배치되어 구성되는 것도 가능하다. 이러한 경우, 프로세싱 엘리먼트 어레이는 복수의 연산기를 포함하는 적어도 하 나의 프로세싱 엘리먼트로 지칭되는 것도 가능하다. 제시된 실시예에서 복수의 프로세싱 엘리먼트들(PE1…)은 단지 설명의 편의를 위한 예시이며, 복수의 프로 세싱 엘리먼트들(PE1…)의 개수는 제한되지 않는다. 복수의 프로세싱 엘리먼트들(PE1…)의 개수에 의 해서 프로세싱 엘리먼트 어레이의 크기 또는 개수가 결정될 수 있다. 프로세싱 엘리먼트 어레이의 크기는 N x M 행렬 형태로 구현될 수 있다. 여기서 N 과 M은 0보다 큰 정수이다. 이에, 프로세싱 엘리먼트 어레이는 N x M 개의 프로세싱 엘리먼트를 포함할 수 있다. 즉, 프로세싱 엘리먼트는 1개 이상일 수 있다. 또한, 프로세싱 엘리먼트 어레이는 복수 서브 모듈로 구성되는 것도 가능하다. 이에, 프로세싱 엘리먼트 어레이는 N x M x L 개의 서브 모듈로 구성된 프로세싱 엘리먼트를 포함할 수 있다. 부연 설명하면 L개는 프로세싱 엘리먼트 어레이의 서브 모듈의 개수로, 코어(core), 엔진(engine) 또는 쓰레드(thread) 등으로 지칭 될 수 있다. 프로세싱 엘리먼트 어레이의 크기는 NPU이 작동하는 제1 모델 및 제2 모델의 특성을 고려하여 설계 할 수 있다. 부연 설명하면, 프로세싱 엘리먼트의 개수는 작동할 제1 모델 및 제2 모델의 파라미터의 크기, 요 구되는 동작 속도, 요구되는 소비 전력 등을 고려하여 결정될 수 있다. 제1 모델 및 제2 모델의 파라미터의 크 기는 제1 모델 및 제2 모델의 레이어 수와 각각의 레이어의 가중치의 크기에 대응되어 크기가 결정될 수 있다. 따라서, 본 개시의 일 예시에 따른 프로세싱 엘리먼트 어레이의 크기는 제한되지 않는다. 프로세싱 엘리먼 트 어레이의 프로세싱 엘리먼트들(PE1…)의 개수가 증가할수록 작동하는 제1 모델 및 제2 모델의 병 렬 연산 능력이 증가되나, NPU의 제조 비용 및 물리적인 크기가 증가될 수 있다. 프로세싱 엘리먼트 어레이는 인공신경망 연산에 필요한 덧셈, 곱셈, 누산 등의 기능을 수행하도록 구성된 다. 다르게 설명하면, 프로세싱 엘리먼트 어레이는 MAC(multiplication and accumulation) 연산을 수행하 도록 구성될 수 있다. 즉, 프로세싱 엘리먼트 어레이는 복수의 MAC 연산기로 지칭될 수 있다. 제시된 실시예에서, 프로세싱 엘리먼트 어레이는 복수의 프로세싱 엘리먼트들(PE1….) 외에, 각각의 프로 세싱 엘리먼트들(PE1…)에 대응되는 각각의 레지스터 파일들(RF1…)을 더 포함할 수 있다. 이때, 도 3에 도시된 복수의 프로세싱 엘리먼트들(PE1…) 및 복수의 레지스터 파일들(RF1…)은 단지 설명의 편의를 위한 예시 이며, 복수의 프로세싱 엘리먼트들(PE1…) 및 복수의 레지스터 파일들(RF1…)의 개수는 제한되지 않는다. 즉, 프로세싱 엘리먼트 어레이는 인공신경망을 위한 동작을 수행할 수 있다. 예를 들어, 객체를 포함하는 영상의 입력 데이터가 입력되었을 때, 프로세싱 엘리먼트 어레이는 제1 모델에 대하여 객체를 분류하고, 제2 모델에 대하여 분류된 객체에 대하여 영상을 처리할 수 있다. 프로세싱 엘리먼트 어레이는 학습 완료된 인공신경망 기반의 제1 모델 및 제2 모델을 통해 객체의 종류마다 품 질이 향상된 영상을 생성 및 도출하는 동작을 수행할 수 있다. 한편, 이에 제한되는 것이 아니며 프로세싱 엘리먼트 어레이는, NPU 내부 메모리상의 제1 모델 및 제2 모델을 이용하여 입력된 영상 내의 객체를 분류하고, 객체에 따라 특성화된 처리를 수행할 수 있다. 선택적으로, NPU는 NPU 인터페이스를 통해서 메인 메모리에 저장된 제1 모델(210') 및 제2 모델 (220')의 데이터를 NPU 내부 메모리으로 불러올 수 있고, 프로세싱 엘리먼트 어레이는 내부 메모리 에 읽힌 제1 모델(210') 및 제2 모델(220')의 데이터를 이용하여 입력된 영상 내의 객체를 분류하고, 객체 에 따라 특성화된 처리를 수행할 수도 있다. 본 개시의 일 예시에 따르면, NPU는 NPU 내부 메모리의 용량에 따라, 미리 결정된 사이즈로 타일링 (tiling)된 제1 모델의 파라미터 또는 제2 모델의 파라미터를 메인 메모리로부터 읽어오는 처리를 수행할수 있다. 예를 들어, NPU는 NPU 내부 메모리의 용량이 작을 경우, 메인 메모리상의 제1 모델 및 제2 모 델을 교번하여 NPU 내부 메모리로 읽어올 수 있다. 본 개시의 다른 예시에 따르면, NPU 내부 메모리에 제1 모델의 파라미터가 저장되고, 가용 용량에 따라 선 택적으로 메인 메모리로부터 제2 모델의 파라미터를 읽어오는 처리를 수행할 수 있다. 본 개시의 다른 예시에 따르면, 제1 모델에 의한 영상의 객체 분류 결과가 이전 영상에 대한 객체 분류 결과와 동일할 경우, NPU는 이전 영상에 대한 객체 분류 결과에 대응하는 제2 모델의 파라미터를 NPU 내부 메모 리에 유지시킬 수 있다. 즉, 객체 인식 결과가 이전 영상 결과와 동일하다면, NPU는 NPU 내부 메모리에 저장된 제1 모델의 파라미터를 재사용하도록 구성될 수 있다. 즉, NPU의 메모리의 용량에 따라 제1 모델(210, 210') 및 제2 모델(220, 220')은 NPU의 내부 또는 외부(예를 들어, 메인 메모리)에 존재할 수 있다. 한편, 내부 메모리는 휘발성 메모리일 수 있다. 휘발성 메모리는 전원이 공급된 경우에만 데이터를 저장하 고, 전원 공급이 차단되면 저장된 데이터가 소멸되는 메모리일 수 있다. 휘발성 메모리는 정적 랜덤 액세스 메 모리(Static Random Access Memory; SRAM), 동적 랜덤 액세스 메모리(Dynamic Random Access Memory; DRAM) 등 을 포함할 수 있다. 내부 메모리는 바람직하게는 SRAM일 수 있으나, 이에 한정되지 않는다. 본 개시의 또 다른 예시에 따르면, NPU는, 복수의 제2 모델 각각에 의해 처리된 영역들을 조합하여, 향상 된 품질의 영상을 출력하도록 구성될 수 있다. 즉, 복수의 제2 모델에 의해 영상 처리된 객체의 픽셀들이 조합 되어 하나의 출력 영상이 생성될 수 있다. 다음으로, NPU 컨트롤러는 제1 모델 및 제2 모델의 파라미터, 예를 들면, 가중치 값들의 크기, 특징맵의 크기, 및 가중치 값들과 특징맵의 계산 순서 등을 고려하여 프로세싱 엘리먼트 어레이 및 NPU 내부 메모리 을 제어하도록 구성될 수 있다. NPU 컨트롤러는, 적어도 하나의 프로세싱 엘리먼트로 하여금 제1 모델을 이용하여 영상 내에서 상기 객체 를 분류하고, 복수의 제2 모델 중 적어도 하나의 모델을 이용하여 객체가 분류된 영상을 기초로 객체에 따라 향 상된 품질의 영상을 생성하도록 제어할 수 있다. NPU 컨트롤러는, 적어도 하나의 프로세싱 엘리먼트로 하여금, 제1 모델을 이용하여 영상 내에서 객체를 분 류하고, 객체의 카테고리를 결정하고, 복수의 카테고리 각각에 대하여 미리 결정된 복수의 파라미터 중, 분류된 객체의 카테고리에 대응하는 파라미터를 제2 모델에 적용하고, 대응하는 파라미터가 적용된 제2 모델을 이용하 여 카테고리가 분류된 영상을 입력으로 하여 객체의 카테고리에 따라 향상된 품질의 영상을 생성하도록 제어할 수 있다. 한편, NPU 컨트롤러는 프로세싱 엘리먼트 어레이에서 계산될 가중치 값들의 크기, 특징맵의 크기, 및 가중치 값들과 특징맵의 계산 순서 등을 수신할 수 있다. 이때 인공신경망의 데이터는 각각의 레이어의 노드 데 이터 또는 특징맵, 및 각각의 레이어의 노드를 연결하는 연결망 각각의 가중치 데이터를 포함할 수 있다. 인공 신경망의 데이터 또는 파라미터들 중 적어도 일부는 NPU 컨트롤러 내부에 제공되는 메모리 또는 NPU 내부 메모리에 저장될 수 있다. 인공신경망의 파라미터들 중 특징맵은 배치채널(batch-channel)로 구성될 수 있다. 여기서 복수의 배치채널들은 예를 들어 실질적으로 동일한 기간,(예를 들어 10 또는 100 ms 이내)에 복수의 이미지 센서를 통해 촬영된 객체 영상들일 수 있다. 전술한 것에 제한되지 않고 NPU 컨트롤러는 영상 내의 객체 분류 및 영상 처리를 위한 다양한 컨볼루션 연 산을 위해 프로세싱 엘리먼트 어레이와 내부 메모리를 제어할 수 있다. 한편, 특수기능 유닛(SFU)은 예를 들어, ReLU같은 활성화 함수를 적용하거나 풀링을 위한 연산 유닛을 포함할 수 있으며, 이에 제한되지 않고 컨볼루션 연산을 제외한 다양한 연산을 위한 유닛을 포함할 수 있다. 본 개시에 따르면, NPU는 제1 모델(210, 210')의 객체 분류 결과에 따라, 복수의 제2 모델(220, 220') 중 객체(또는 이의 카테고리)에 대응하는 모델을 선택하거나, 단일의 제2 모델(220, 220')에 대하여 적용 가능 한 복수의 파라미터를 선택하도록 구성된 선택 모듈(미도시)를 더 포함할 수 있다. 이때, 선택 모듈은 컨트롤러 또는 특수기능 유닛에 포함될 수도 있다. 나아가 컨트롤러는 선택 모듈을 제어하도록 더 구성될 수 있다. 이하에서는 도 4를 참조하여 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 구체적으로 설명하 도록 한다. 도 4는 본 개시에 적용될 수 있는 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 개략적인 개념도이다. 도 4를 참조하면, 제 1 프로세싱 엘리먼트(PE1)는 곱셈기(Multiplier), 가산기(Adder), 및 누 산기(Accumulator)를 포함할 수 있다. 단, 본 개시에 따른 예시들은 이에 제한되지 않으며, 프로세싱 엘리 먼트 어레이는 인공신경망의 연산 특성을 고려하여 변형 실시될 수도 있다. 곱셈기는 입력 받은(N)bit 데이터와(M)bit 데이터를 곱한다. 곱셈기의 연산 값은(N+M)bit 데이터로 출력된다. 여기서 N과 M은 0보다 큰 정수이다. (N)bit 데이터를 입력 받는 제 1 입력부는 특징맵을 입력 받도록 구성될 수 있고,(M)bit 데이터를 입력 받는 제 2 입력부는 가중치를 입력 받도록 구성될 수 있다. 특징맵은 프레임마다 값이 바뀌기 때문에 변수 값으로 설정될 수 있다. 학습이 완료된 가중치는 별도의 학습이 수행되지 않는 한 값이 바뀌지 않기 때문에 상수 값으로 설정될 수 있다. 즉, 곱셈기는 하나의 변수와 하나의 상수를 입력 받도록 구성될 수 있다. 부연 설명하면, 제 1 입력부에 입력되는 변수 값은 인공신경망의 입력 특징맵(input feature map)일 수 있다. 제 2 입력부에 입력되는 상수 값 은 인공신경망의 가중치일 수 있다. 한편, 제 1 프로세싱 엘리먼트(PE1)는 곱셈기의 제 1 입력부 및 제 2 입력부 중 하나의 입력부에 0이 입력될 때, 연산을 하지 않더라도 연산 결과가 0인 것을 인지하고 있기 때문에, 곱셈기가 연산을 하지 않 도록 동작을 제한할 수 있다. 예를 들면, 곱셈기의 제 1 입력부 및 제 2 입력부 중 하나의 입력부에 0이 입력될 때, 곱셈기는 제로 스키핑(zero skipping) 방식으로 동작하도록 구성될 수 있다. 곱셈기의 제 1 입력부 및 제 2 입력부에 입력되는 데이터는 인공신경망모델의 각각의 레이어의 특징맵 및 가중치의 양자화에 따라서 비트 폭(bit width)이 결정될 수 있다. 예를 들면, 제 1 레이어의 특징맵이 5bit로 양자화 되고 제 1 레이어의 가중치가 7bit로 양자화되는 경우 제 1 입력부는 5bit 폭의 데이터를 입력 받도록 구성되고, 제 2 입력부는 7bit 폭의 데이터를 입력 받도록 구성될 수 있다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 가산한다. (L)loops가 0일 경우, 누산된 데이 터가 없으므로, 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. (L)loops가 1일 경우, 곱셈 기의 연산 값과 누산기의 연산 값이 가산된 값이 가산기의 연산 값일 수 있다. 누산기는 가산기의 연산 값과 곱셈기의 연산 값이 (L)loops 횟수만큼 누산되도록 가산기의 출력부에서 출력된 데이터를 임시 저장한다. 구체적으로, 가산기의 출력부에서 출력된 가산기의 연산 값은 누산기의 입력부에 입력되고, 입력된 연산 값은 누산기에 임시 저장되었다가 누산기의 출 력부에서 출력된다. 출력된 연산 값은 루프에 의해 가산기의 입력부에 입력된다. 이때, 가산기의 입 력부에는 곱셈기의 출력부에서 새롭게 출력된 연산 값이 함께 입력된다. 즉, 누산기의 연산 값과 곱 셈기의 새로운 연산 값이 가산기의 입력부에 입력되고, 이 값들이 가산기에서 가산되어 가산기 의 출력부를 통해 출력된다. 가산기의 출력부에서 출력된 데이터, 즉 가산기의 새로운 연산 값 은 누산기의 입력부에 입력되며, 이후 동작들은 상술한 동작들과 실질적으로 동일하게 루프 횟수만큼 수행 된다. 이처럼, 누산기는 곱셈기의 연산 값과 가산기의 연산 값을 루프 횟수만큼 누산하기 위해 가산기 의 출력부에서 출력된 데이터를 임시 저장하므로, 누산기의 입력부에 입력되는 데이터 및 출력부에서 출력되는 데이터는 가산기의 출력부에서 출력된 데이터와 같은(N+M+log2(L))bit의 비트 폭을 가질 수 있다. 여기서 L은 0보다 큰 정수이다. 누산기는 누산이 종료되면, 초기화 신호(initialization reset)를 인가받아서 누산기 내부에 저장된 데이터를 0으로 초기화 할 수 있다. 단, 본 개시에 따른 예시들은 이에 제한되지 않는다.누산기의 출력 데이터(N+M+log2(L))bit는 출력 특징맵(output feature map)이 될 수 있다. 이하에서는, 도 5 내지 도 8을 참조하여, 본 개시의 다양한 실시예에 따른 영상 처리 방법에 대하여 설명한다. 도 5는 본 개시의 일 예시에 따른 신경 프로세싱 유닛에 기초한 영상 처리 방법을 설명하는 예시적인 순서도이 다. 도 6 및 7은 본 개시의 일 예시에 따른 신경 프로세싱 유닛에서 제1 모델 및 제2 모델을 이용한 품질이 향 상된 영상 출력 절차를 나타낸 예시적인 개략도이다. 도 8a 내지 8d는 본 개시의 일 예시에 따른 신경 프로세싱 유닛에서 제2 모델의 구조를 설명하는 개략적인 개념도이다. 먼저, 도 5를 참조하면, 객체를 포함하는 영상이 수신된다(S510). 그 다음, 제1 모델에 의해 영상 내에서 객체 가 분류된다(S520). 그 다음, 복수의 제2 모델 중 선택된 하나의 모델을 이용하여, 분류된 객체에 따라 향상된 품질의 영상이 획득된다(S530). 그 다음, 향상된 품질의 영상이 제공된다(S540). 먼저, 객체를 포함하는 영상이 수신되는 단계(S510)에서, 음식, 날씨, 동물, 곤충, 풍경, 자연, 스포츠, 의류, 사람, 감정, 프로그램, 교통수단 등의 카테고리에 대응되는 객체를 포함하는 영상이 수신될 수 있다. 여기서 객 체는 적어도 하나 이상일 수 있다. 즉, 객체를 포함하는 영상이 수신되는 단계(S510)에서, 영상을 향상시키고자 하는 카테고리들은 미리 결정될 수 있다. 이때, 영상 속 개체는 복수의 카테고리들에 매칭될 수도 있다. 즉 하나의 개체가 2개의 카테고리에 대응 될 수 있다. 그 다음, 제1 모델에 의해 영상 내에서 객체가 분류된다(S520). 객체는 적어도 하나일 수 있다. 보다 구체적으로, 영상 내에서 객체가 분류되는 단계(S520)에서, 영상을 입력으로 하여 객체를 분류하도록 학습 된 제1 모델에 의해 객체가 무엇인지 분류될 수 있다. 제1 모델은 기 설정된 카테고리에 대응되는 객체를 분류 하도록 학습된 모델일 수 있다. 따라서, 제1 모델의 파라미터, 예를 들면, 학습된 가중치는 객체에 대응되는 복 수의 카테고리들 중 적어도 하나를 분류하도록 학습된 가중치일 수 있다. 본 개시에 따르면, 영상 내에서 객체가 분류되는 단계(S520) 이후에, 분류된 객체에 대하여 카테고리가 결정되 는 단계가 더 수행될 수도 있다. 그러나, 이에 제한되는 것은 아니며, 제1 모델에 의해 입력된 영상의 카테고리 가 바로 결정될 수도 있다. 즉, 제1 모델은 영상을 입력 받는 입력 레이어와 함께 객체의 이름 또는 객체의 해당 카테고리에 대응하는 복수 의 노드로 이루어진 출력 레이어를 포함할 수 있다. 예를 들어, 도 6을 함께 참조하면, 객체를 포함하는 영상이 수신되는 단계(S510)에서 수신된, 동물 카테고리에 매칭되는 고양이 영상이 수신된다. 영상 내에서 객체가 분류되는 단계(S520)에서, 영상이 제1 모델 에 입력된다. 그 결과, 제1 모델에 의해 영상 속 객체가 '고양이'로 결정될 수 있다. 또한, 제1 모델에 학습된 파라미터에 의해 영상의 카테고리가 '동물' 또는 '포유류'로 결정될 수도 있다. 그러나, 객체의 분류 절차는 이에 제한되는 것은 아니다. 예를 들어, 도 7을 참조하면, 객체를 포함하는 영상이 수신되는 단계(S510)에서 수신된 영상이 제1 모델 에 입력되고, 그 이후에 객체 영역에 대응하는 ROI(region of interest) 가 분할된다. 이후에, ROI 가 다시 제1 모델에 입력되고, 분할된 ROI에 대하여 객체가 분류될 수 있다. 즉, 제1 모델 은, 영상을 입력으로 하여 영역을 분할하는 영역 분할 유닛 및 영상(또는 영역)을 입력으로 하여 객체를 분류하도록 구성된 분류기로 구성될 수도 있다. ROI는 직사각형 일수 있다. 단, 이에 제한되지 않으며, 삼각형, 오각형, 육각형, 다각형, 원형, 타원형, 등 일 수 있다. 이때, 객체의 영역인 ROI의 결정은, HMD(Head mount display) 장치로부터 수신된 사용자의 시선 데이터에 기초하여 수행될 수 있다. 예를 들어, 사용자의 시선이 머무는 시간이 다른 영역보다 상대적으로 높은 영역이 ROI로 결정될 수도 있다. 다시 도 5를 참조하면, 복수의 제2 모델 중 적어도 하나의 모델을 이용하여, 객체에 따라 향상된 품질의 영상이 획득된다(S530). 보다 구체적으로, 객체에 따라 향상된 품질의 영상이 획득되는 단계(S530)에서, 복수의 제2 모델 중 적어도 하 나의 모델이 결정되고, 객체에 따라 향상된 품질의 영상이 제2 모델에 의해 생성(출력)될 수 있다.예를 들어, 도 6을 참조하면, 객체에 따라 향상된 품질의 영상이 획득되는 단계(S530)에서, 제1 모델에 의 해 분류된 객체에 따라 제1 객체 모델(220(a)), 제2 객체 모델(220(b)), 제3 객체 모델(220(c)), … 로 이루어 진 복수의 제2 모델 중 적어도 하나의 모델이 결정된다. 그 다음, 영상이 결정된 적어도 하나의 모델 에 입력된 후, 결정된 적어도 하나의 모델에서 영상이 처리된 영상이 출력된다. 이에 따라 객체 또는 객체 의 카테고리에 따라 품질이 향상된 영상이 획득될 수 있다. 이때, 복수의 모델 중 객체에 대응하는 제2 모 델의 선택은, 별도의 단계로서 실행되는 것이 아니며 선택 모듈(미도시)에 의해 자동으로 수행될 수 있다. 본 개시에 따르면, 제2 모델은 복수의 카테고리 각각에 대응하는 영상을 입력으로 하여, 상기 복수의 카테고리 에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 복수의 모델일 수 있다. 예를 들어, 도 8a를 함께 참조하면, 제2 모델은 음식 영상에 대하여 향상된 품질의 영상을 제공하도록 학 습된 제1 객체 모델(220(a)), 날씨 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 제2 객체 모델 (220(b)), 동물 및 곤충 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 제3 객체 모델(220(c)), 풍경 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 제4 객체 모델(220(d)), 스포츠 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 제5 객체 모델(220(e)), 의류 영상에 대하여 향상된 품질의 영상을 제공하도 록 학습된 제6 객체 모델(220(f)) 사람 및 감정 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 제7 객 체 모델(220(g)) 및 교통 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 제8 객체 모델(220(h)) 의 영 상의 카테고리에 따라 특화된, 향상된 품질의 영상을 출력하도록 학습된 복수의 모델일 수 있다. 각각의 모델은 특화된 가중치, 즉 파라미터를 가진다. 구체 예를 들어, 음식 영상에 대하여 향상된 품질의 영상을 제공하도록 학습된 제1 객체 모델(220(a))의 경우, 영상에 대하여 채도(Saturation)를 향상시키고 선명도(Sharpness)를 향상시키며, 색온도(Color temperature)는 음식의 종류에 따라 따뜻하게 또는 차갑게 변형하도록 학습된 모델일 수 있다. 본 개시에 따르면, 제2 모델은 초고해상도(Super Resolution) 모델, 디노이징(Denoising) 모델, 디블러링 (Deblurring) 모델, 엣지 강화(Edge Enhancement) 모델, 디모자이징(Demosaicing) 모델, 컬러 톤 강화(Color Tone Enhancing) 모델, 화이트 밸런싱(White Balancing) 모델, 역광 보정(Wide dynamic range) 모델, 명암 대 비 보정(high dynamic range) 모델 및 디컴프레션(Decompression) 모델 중 적어도 하나의 영상 처리 모델일 수 있다. 예를 들어, 도 8b를 참조하면, 제2 모델(220'')은, 입력된 영상에 대하여 고해상도(Super Resolution; S/R)처 리를 제공하는 제1 객체 모델(220''(a)), 입력된 영상에 대하여 노이즈 제거, 즉 디노이징(Denoising) 처리를 제공하도록 학습된 제2 객체 모델(220''(b)), 입력된 영상에 대하여 번짐 현상을 제거하는, 즉 디블러링 (Deblurring) 처리를 제공하도록 학습된 제3 객체 모델(220''(c)), 입력된 영상에 대하여 엣지 강화(Edge Enhancement) 처리를 제공하도록 학습된 제4 객체 모델(220''(d)), 입력된 영상에 대하여 디모자이징 (Demosaicing) 처리를 제공하도록 학습된 제5 객체 모델(220''(e)), 입력된 영상에 대하여 컬러 톤 강화(Color Tone Enhancing) 처리를 제공하도록 학습된 제6 객체 모델(220''(f)), 입력된 영상에 대하여 화이트 밸런싱 (White Balancing) 처리를 제공하도록 학습된 제7 객체 모델(220''(g)) 및 입력된 영상에 대하여 디컴프레션 (Decompression) 처리를 제공하도록 학습된 제8 객체 모델(220''(h))의 영상에 대하여 상이한 처리를 수행하도 록 학습된 복수의 모델일 수 있다. 그러나, 이에 제한되는 것은 아니며, 제2 모델은, 객체 영상 내에서 원하지 않는 특정 영역(예를 들어, 객체 이 외의 영역)을 삭제하거나 블러(blur)처리하도록 학습된 영상 처리 모델일 수도 있다. 본 개시에 따르면, 제2 모델은, 복수의 모델이 결합된 앙상블 모델일 수도 있다. 예를 들어, 도 8c를 참조하면, 제1 분류 모델(미도시)에 의해 '날씨' 카테고리 또는 '비', '우산'으로 분류된 영상이 앙상블 모델에 입력된다. 이때, 앙상블 모델은 '날씨' 카테고리 또는 '비', '우산'의 객 체(또는 카테고리)에 따라 특화된 모델로서, 날씨에 관한 제2 객체 모델(220(b)) 및 엣지 강화를 위한 제4 객체 모델(220''(d))이 병렬로 연결된 모델일 수 있다. 즉, 입력된 영상은 제2 객체 모델(220(b)) 및 제4 객체 모델(220''(d))각각에 의해 처리되고, 두 개의 처리된 결과가 앙상블되어 영상이 처리된 영상이 출력될 수 있다. 이때, 품질이 향상된 영상은 두 모델에 의해 처리된 객체 영상들에 대한 픽셀들이 조합되어 생성된 영상일 수 있다. 그러나 전술한 특징에 제한되지 않고, 제2 모델은 복수의 객체 모델이 직렬로 연결된 모델일 수 도 있다. 예를 들어, 도 8d를 더욱 참조하면, 제1 분류 모델(미도시)에 의해 '음식' 카테고리 또는 스시(Sushi))' 또는 '일식(Japanese foods)'으로 분류된 영상이 제2 모델(220''')에 입력된다.이때, 제2 모델(220''')은 '음 식' 카테고리 또는 '스시', '일식'의 객체(또는 카테고리)에 따라 특화된 모델로서, 입력된 영상에 대하여 컬러 톤을 향상시키도록 학습된 제6 객체 모델(220''(f)) 및 입력된 영상에 대하여 선명도를 향상시키도록 학습된 제 9 객체 모델(220''(i))이 직렬로 연결된 모델일 수 있다. 즉, 입력된 영상은 제6 객체 모델(220''(f))에 입 력되어 컬러 톤이 강화된 영상으로 출력된다. 컬러 톤이 강화된 영상은 다시 제9 객체 모델(220''(i)) 에 입력되어 컬러 톤과 선명도가 향상된 영상이 최종 출력될 수 있다. 한편, 제2 모델에서 직렬의 객체 모 델의 연결은, 품질 향상을 목표로 하는 객체의 종류 또는 객체의 카테고리에 따라 그 조합, 또는 순서가 다양하 게 선택될 수 있다. 그러나 이에 제한되지 않고, 객체에 따라 향상된 품질의 영상이 획득되는 단계(S530)에서, 기 결정된 객체 영역 에 대하여 품질이 향상된 영상이 생성될 수 있다. 예를 들어, 도 7을 참조하면, 객체에 따라 향상된 품질의 영상이 획득되는 단계(S530)에서, ROI에 대하여 제1 모델에 의해 분류된 결과에 따라 제1 객체 모델(220(a)), 제2 객체 모델(220(b)), 제3 객체 모델 (220(c)), … 로 이루어진 복수의 제2 모델 중 적어도 하나의 모델이 결정된다. 그 다음, 영상이 적어 도 하나의 모델에 입력된 후, 영상이 처리된 영상이 출력된다. 이때, 품질이 향상된 영상은 ROI에 대해서 영상이 처리된, 즉 품질이 향상된 객체 영역을 포함할 수 있다. 다시 말해, 제2 모델에 의해, 영상 내에서 객체 영역에 대해서만 품질 향상이 수행될 수 있다. 다시 도 5를 참조하면, 향상된 품질의 영상이 제공된다(S540). 즉, 향상된 품질의 영상이 제공되는 단계(S540) 에서는 객체(또는 이의 카테고리)에 따라 최적의 품질로 향상된 영상이 제공될 수 있다. 즉, 본 개시에 따른 영상 처리 방법은, 영상 내에서 객체를 분류하도록 학습된 모델과 분류된 객체에 따라 영상 을 처리하도록 학습된 모델의 복수의 독립된 인공신경망 기반의 모델을 이용함에 따라, 객체의 특성에 따라 최 적의 품질을 갖는 영상을 제공할 수 있다. 한편, 다양한 개시에 따른 제2 모델은 단일 모델로서, 객체의 특성에 따라 미리 설정된 복수의 파라미터 중 적 어도 하나의 파라미터가 적용될 수 있어, 객체 특징에 따라 품질이 향상된 영상 제공이 가능할 수 있다. 여기서 단일 모델은 인공신경망의 레이어 구조, 채널의 개수, 입력 데이터의 크기, 출력 데이터의 크기가 동일한 모델 을 의미할 수 있다. 부연 설명하면, 단일 모델의 학습된 가중치만 교체할 경우, 상기 단일 모델은 교체된 파라 미터에 따라 특정 영상 처리 기능을 수행할 수 있게 된다. 이하에서는, 도 9 내지 도 11을 참조하여, 본 개시의 다양한 실시예에 따른 영상 처리 방법에 대하여 설명한다. 도 9는 본 개시의 다른 예시에 따른 신경 프로세싱 유닛에 기초한 영상 처리 방법을 설명하는 예시적인 순서도 이다. 도 10 및 11은 본 개시의 다른 예시에 따른 신경 프로세싱 유닛에서 제1 모델 및 제2 모델을 이용한 영상 이 처리된 영상 출력 절차를 나타낸 예시적인 개략도이다. 먼저, 도 9를 참조하면, 본 개시의 다른 예시에 따른 신경 프로세싱 유닛에 기초한 영상 처리를 위해, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체를 포함하는 영상이 수신된다(S910). 그 다음, 제1 모델에 의 해 영상 내에서 객체가 분류된다(S920). 그 다음, 객체의 카테고리가 결정된다(S930). 그 다음, 객체의 카테고 리에 대응하는 파라미터가 제2 모델에 적용된다(S940). 그 다음, 제2 모델에 의해 객체의 카테고리에 따라 향상 된 품질의 영상이 획득된다(S950). 마지막으로, 향상된 품질의 영상이 제공된다(S960). 한편, 객체를 포함하는 영상이 수신되는 단계(S910), 영상 내에서 객체가 분류되는 단계(S920)는 도 5, 6 및 7 에서 전술한 객체를 포함하는 영상이 수신되는 단계(S510), 영상 내에서 객체가 분류되는 단계(S520)와 동일한 절차로 수행될 수 있다. 객체의 카테고리가 결정되는 단계(S930)에서, 영상 내에서 객체가 분류되는 단계(S920)를 통해 분류된 객체에 대한 카테고리가 결정된다. 그 다음, 카테고리에 대응하는 파라미터가 제2 모델에 적용되는 단계(S940)에서, 객체의 카테고리에 따라 미리 결정된 파라미터가 제2 모델에 적용될 수 있다. 본 개시의 일 예시에 따르면, 카테고리에 대응하는 파라미터가 제2 모델에 적용되는 단계(S940)에서, 복수의 객 체 파라미터를 포함하는 파라미터 선택 모듈에 의해 수행될 수 있다.예를 들어, 도 10 및 11을 함께 참조하면, 카테고리에 대응하는 파라미터가 제2 모델에 적용되는 단계(S940)에 서, 영상 또는 ROI의 카테고리에 따라, 제1 객체 파라미터(2200(a)), 제2 객체 파라미터(2200(b)), 제 3 객체 파라미터(2200(c)), .. 중 적어도 하나의 파라미터가 결정될 수 있다. 이때, 파라미터의 결정은 제2 모 델 파라미터 선택 모듈에 의해, 분류된 객체의 카테고리에 따라 자동으로 설정될 수 있다. 그 다음, 제2 모델 파라미터 선택 모듈에 의해 결정된 객체 파라미터가 제2 모델에 적용될 수 있다. 다시 도 9를 참조하면, 제2 모델에 의해 향상된 품질의 영상이 획득되고(S950), 향상된 품질의 영상이 제공된다 (S960). 이때, 향상된 품질의 영상이 획득되는 단계(S950), 향상된 품질의 영상이 제공되는 단계(S960)는, 도 5, 6 및 7에서 전술한 향상된 품질의 영상이 획득되는 단계(S530), 향상된 품질의 영상이 제공되는 단계(S540) 와 동일한 절차로 수행될 수 있음에 따라, 이의 설명은 생략하기로 한다. 즉, 이상의 본 개시에 따른 영상 처리 방법은, 단일의 제2 모델에 대하여 객체에 따라 미리 결정된 학습 파라미 터의 객체 파라미터가 다양하게 적용될 수 있어, 객체의 특성을 반영하여 품질이 향상된 영상을 제공할 수 있다. 이하에서는, 도 12를 참조하여, 본 개시의 다양한 예시에 따른 신경 프로세싱 유닛에 기초한 번호판 인식 시스 템을 설명한다. 도 12는 본 개시의 일 예시에 따른 신경 프로세싱 유닛 기반 차량 번호 인식 시스템에 대한 예시도이다. 도 12를 참조하면, 신경 프로세싱 유닛 기반 차량 번호 인식 시스템(C)에서 차량 영상은 제1 모델에 입력 되고, 영상 내 객체는 '번호판'으로 분류될 수 있다. 그러나, 이에 제한되는 것은 아니며 영상의 이용 목적에 따라 제1 모델은 차량 영상을 '자동차', '숫자' 등으로 분류하도록 구성될 수 있다. 이때, 객체 분류, 즉 번호판으로의 분류는 객체 영상이 결정된 이후에 수행될 수도 있다. 그 다음, 객체(또는 카테고리)가 분류된 영 상은, 객체에 대응하는 제2 모델에 입력되고, 번호판 영역만이 강조된 영상이 출력될 수 있다. 이때, 제2 모델은 번호판 영역에 대한 강조뿐만 아니라, 그 이외의 사생활 문제가 발생될 영역에 대한 삭제 또는 블러 (blur) 처리를 수행하도록 학습된 번호판 인식을 위해 특화된 모델일 수 있다. 즉, 신경 프로세싱 유닛 기반 차량 번호 인식 시스템(C)은 원하지 않는 특정 정보를 변조하거나 또는 삭제하도 록 설계될 수도 있다. 이하에서는, 도 13을 참조하여 본 개시의 다양한 예시에 따른 영상 처리 방법의 구현 형태를 설명한다. 도 13은 본 개시의 다양한 예시에 따른 영상 처리 방법의 구현 예시도이다. 보다 구체적으로, 도 13의 (a)를 참조하면, 본 개시의 다양한 예시에 따른 영상 처리 방법은 인코더(Encoder)의 소프트웨어로 구현될 수 있다. 즉, 인코더에 비디오 파일이 입력되면, 영상 처리된 비디오 파일이 출력될 수 있다. 이때, 입력되는 데이터는, 비디오 파일(AVI, MOV 등의 확장자를 갖는 파일) 또는 이미지 파일 (RGB, JPEG, JPG 등의 확장자를 갖는 파일)일 수 있으나, 이에 제한되는 것은 아니다. 도 13의 (b)를 참조하면, 본 개시의 다양한 예시에 따른 영상 처리 방법은 TV로 구현될 수 있다. 보다 구체적 으로 NPU가 포함된 TV의 시스템 보드(System board)에서, NPU에 비디오 파일이 입력되면, 영상 처리된 비디오 파일이 출력되고, 영상 처리된 비디오는 디스플레이(Display) 상에 표시될 수 있다. 이때, 입력되는 데이터는, 비디오 파일(AVI, MOV 등의 확장자를 갖는 파일) 또는 이미지 파일 (RGB, JPEG, JPG 등의 확장자를 갖는 파일) 일 수 있으나, 이에 제한되는 것은 아니다. 도 13의 (c)를 참조하면, 본 개시의 다양한 예시에 따른 영상 처리 방법은 AR/VR로 구현될 수 있다. 보다 구체 적으로 구비된 NPU에 비디오 파일과 함께 시선 추척(Eye tracking) 정보가 입력되면, 영상 처리된 비디오 파일 이 출력되고, 영상 처리된 비디오는 디스플레이 상에 표시될 수 있다. 이러한 구현 방법에 따라, 저-컴퓨터 소 비전력(low computational power) 등으로 연산량이 감소될 수 있다.본 개시의 일 예시에 따른 영상 처리 방법은, 객체를 포함하는 영상을 수신하는 단계 영상을 입력으로 하여 적어도 하나의 객체를 분류하도록 구성된 인공 신경망 기반의 제1 모델을 이용하여, 영상 내에서 적어도 하나의 객체를 분류하는 단계, 및 영상을 입력으 로 하여 특정 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의 복수의 제2 모 델 중 적어도 하나의 모델을 이용하여, 적어도 하나의 객체가 분류된 영상을 입력으로 하여 적어도 하나의 객체 에 따라 향상된 품질의 영상을 획득하는 단계를 포함할 수 있다. 적어도 하나의 객체는, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체이고, 복수의 제2 모델은 복수 의 카테고리 각각에 대응하는 영상을 입력으로 하여, 복수의 카테고리에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 복수의 모델일 수 있다. 이때, 상기 처리 방법은, 적어도 하나의 객체를 분류하는 단계 이후에, 적어도 하나의 객체의 카테고리를 결정하는 단계를 더 포함할 수 있다. 나아가, 향상된 품질의 영상을 획득하는 단계는, 적어도 하나의 객체의 카테고리에 대응하는 복수의 제2 모델 중 하나의 모델을 이용하여, 향 상된 품질의 영상을 획득하는 단계를 더 포함할 수 있다. 제1 모델은, 영상을 입력으로 하여, 적어도 하나의 객체의 영역을 출력하도록 더 구성되고, 상기 처리 방법은, 수신하는 단계 이후에 제1 모델을 이용하여, 영상 내에서 적어도 하나의 객체의 영역을 결정하는 단계를 더 포 함할 수 있다. 이때 적어도 하나의 객체를 분류하는 단계는, 제1 모델을 이용하여, 적어도 하나의 객체의 영역 에 기초하여 적어도 하나의 객체를 분류하는 단계를 포함할 수 있다. 향상된 품질의 영상을 획득하는 단계는, 제2 모델을 이용하여, 적어도 하나의 객체의 영역의 품질이 향상된 영 상을 획득하는 단계를 포함할 수 있다. 상기 처리 방법은, HMD(Head mount display) 장치로부터 시선 데이터를 수신하는 단계를 더 포함할 수 있다. 이 때, 적어도 하나의 객체의 영역을 결정하는 단계는, 시선 데이터에 기초하여, 적어도 하나의 객체의 영역을 결 정하는 단계를 더 포함할 수 있다. 제1 모델은 입력 레이어 및 복수 개의 노드(nodes)로 이루어진 출력 레이어를 포함할 수 있다. 제2 모델의 개수 는, 제1 모델의 출력 레이어의 노드 수에 대응할 수 있다. 적어도 하나의 모델은, 디노이징(Denoising) 모델, 디블러링(Deblurring) 모델, 엣지 강화(Edge Enhancement) 모델, 디모자이징(Demosaicing) 모델, 컬러 톤 강화(Color Tone Enhancing) 모델, 화이트 밸런싱(White Balancing) 모델, 초고해상도(Super resolution) 모델, 초고해상도(Super resolution) 모델 및 디컴프레션 (Decompression) 모델 중 적어도 하나일 수 있다. 적어도 하나의 모델은, 복수의 제2 모델 중 선택된 적어도 두 개의 모델이 결합된 앙상블 모델일 수 있다. 영상 처리 방법은, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체를 포함하는 영상을 수신하고, 영상 을 입력으로 하여 객체를 분류하도록 구성된 인공 신경망 기반의 제1 모델을 이용하여, 영상 내에서 객체의 카 테고리를 결정하고, 복수의 카테고리 각각에 대하여 미리 결정된 복수의 파라미터 중, 분류된 객체의 카테고리 에 대응하는 파라미터를, 영상을 입력으로 하여 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의 제2 모델에 적용하고, 대응하는 파라미터가 적용된 제2 모델을 이용하여, 카테고리가 결정 된 영상을 입력으로 하여 객체의 카테고리에 따라 향상된 품질의 영상을 획득하는 단계를 포함할 수 있다. 프로세싱 유닛은, 객체를 포함하는 영상, 제1 모델 및 제2 모델을 저장하도록 구성된 내부 메모리, 및 내부 메 모리에 액세스(access)하도록 구성되며, 제1 모델 및 제2 모델의 합성곱을 처리하도록 구성된 프로세싱 엘리먼 트(processing element; PE), 및 내부 메모리, 프로세싱 엘리먼트와 동작 가능하게 연결된 컨트롤러 (controller)를 포함할 수 있다. 이때, 제1 모델은, 영상을 입력으로 하여 객체를 분류하도록 구성된 인공 신경 망 기반의 모델이고, 제2 모델은, 영상을 입력으로 하여 객체에 따라 특화된 처리가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의 복수의 모델일 수 있다. 나아가, 컨트롤러는, PE로 하여금, 제1 모델을 이용하여 영 상 내에서 객체를 분류하고, 복수의 제2 모델 중 적어도 하나의 모델을 이용하여 객체가 분류된 영상을 기초로 객체에 따라 향상된 품질의 영상을 획득하도록 구성될 수 있다. 상기 프로세싱 유닛은 제1 모델 및 제2 모델을 저장하도록 구성된 메인 메모리를 더 포함할 수 있다. 이때, 내 부 메모리는 메인 메모리 내의 제1 모델 및 제2 모델을 읽어오도록 구성될 수 있다. 객체는, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체이고, 제2 모델은 복수의 카테고리 각각에 대 응하는 영상을 입력으로 하여, 복수의 카테고리 각각에 대하여 미리 결정된 처리가 적용된 영상을 출력하도록 구성된 복수의 모델일 수 있다. 이때, 컨트롤러는, PE로 하여금, 객체의 카테고리를 결정하고, 객체의 카테고리 에 대응하는 복수의 제2 모델 중 하나의 모델을 이용하여, 향상된 품질의 영상을 획득하도록 더 구성될 수 있다. 복수의 제2 모델 중 적어도 하나의 모델을 선택하도록 구성된 선택 모듈을 더 포함할 수 있다. 제1 모델은, 영상을 입력으로 하여, 객체의 영역을 출력하도록 더 구성될 수 있다. 컨트롤러는, PE로 하여금, 제1 모델을 이용하여 영상 내에서 객체의 영역을 결정하고, 제1 모델을 이용하여 객체의 영역에 기초하여 객체 를 분류하도록 더 구성될 수 있다.컨트롤러는, PE로 하여금, 제2 모델을 이용하여 객체의 영역의 품질이 향상된 영상을 획득하도록 더 구성될 수 있다. 내부 메모리는, HMD(Head mount display) 장치로부터 시선 데이터를 더 저장하고, 컨트롤러는, PE로 하여금, 시 선 데이터에 기초하여, 객체 영역을 결정하도록 더 구성될 수 있다. 제1 모델은 입력 레이어 및 복수 개의 노드(nodes) 로 이루어진 출력 레이어를 포함하고, 제2 모델의 개수는, 제1 모델의 출력 레이어의 노드 수에 대응할 수 있다. 적어도 하나의 모델은, 디노이징(Denoising) 모델, 디블러링(Deblurring) 모델, 엣지 강화(Edge Enhancement) 모델, 디모자이징(Demosaicing) 모델, 컬러 톤 강화(Color Tone Enhancing) 모델, 화이트 밸런싱(White Balancing) 모델, 초고해상도(Super resolution) 모델, 초고해상도(Super resolution) 모델 및 디컴프레션 (Decompression) 모델 중 적어도 하나일 수 있다. 적어도 하나의 모델은, 복수의 제2 모델 중 선택된 적어도 두 개의 모델이 결합된 앙상블 모델일 수 있다. 제2 모델 각각에 의해 처리된 영역들을 조합하여, 상기 향상된 품질의 영상을 출력하도록 더 구성될 수 있다. 제1 모델 및 제2 모델 각각은 파라미터를 포함할 수 있다. 이때, 내부 메모리는, 내부 메모리의 용량에 기초하 여, 미리 결정된 사이즈로 타일링(tiling)된 제1 모델의 파라미터 또는 상기 제2 모델의 파라미터를 상기 메인 메모리로부터 읽어오도록 구성될 수 있다. 제1 모델 및 제2 모델 각각은 파라미터를 포함하고, 내부 메모리는 제1 모델의 파라미터를 포함하고, 선택적으 로 제2 모델의 파라미터를 메인 메모리로부터 읽어오도록 구성될 수 있다. 제2 모델은 파라미터를 포함하고, 영상은 복수 개의 영상이고, 내부 메모리는 제1 모델에 의한, 복수 개의 영상 중 선택된 영상에 대한 객체 분류 결과가 이전 영상에 대한 객체 분류 결과와 동일할 경우, 이전 영상에 대한 객체 분류 결과에 대응하는 제2 모델의 파라미터를 포함할 수 있다. 프로세싱 유닛은, 복수의 카테고리 중 선택된 하나의 카테고리를 갖는 객체를 포함하는 영상, 제1 모델 및 제2 모델을 저장하도록 구성된 내부 메모리, 내부 메모리에 액세스(access)하도록 구성되며, 제1 모델 및 제2 모델 의 합성곱을 처리하도록 구성된 프로세싱 엘리먼트(processing element; PE), 및 내부 메모리, 프로세싱 엘리먼 트와 동작 가능하게 연결된 컨트롤러(controller)를 포함한다. 이때, 제1 모델은, 영상을 입력으로 하여 객체를 분류하도록 구성된 인공 신경망 기반의 모델이고, 제2 모델은, 영상을 입력으로 하여 객체에 따라 특화된 처리 가 적용된 영상을 출력하도록 구성된 인공 신경망 기반의 모델이다. 또한, 컨트롤러는, PE로 하여금, 제1 모델 을 이용하여 영상 내에서 객체를 분류할 수 있다. 분류된 객체 각각에 대하여 미리 결정된 복수의 파라미터 중, 분류된 객체의 카테고리에 대응하는 파라미터를 제2 모델에 적용하고, 대응하는 파라미터가 적용된 제2 모델을 이용하여 카테고리가 분류된 영상을 입력으로 하여 객체의 카테고리에 따라 향상된 품질의 영상을 획득하도록 구성될 수 있다. 복수의 파라미터를 선택하도록 구성된 선택 모듈을 더 포함할 수 있다. 영상 처리 방법은 입력 영상을 수신하는 단계; 상기 입력 영상의 적어도 하나의 객체를 분류하는 단계; 상기 분 류된 객체에 대응되는 인공신경망모델을 적용하는 단계; 및 상기 선택된 인공신경망모델로 상기 입력 영상을 영 상처리하는 단계를 포함할 수 있다. 상기 입력 영상의 적어도 하나의 객체를 분류하는 단계는, 상기 입력 영상의 적어도 하나의 객체를 분류하도록 학습된 제1 모델에 의해서 수행될 수 있다. 제1 모델은 상기 적어도 하나의 객체의 영역을 결정하도록 학습될 수 있다. 적어도 하나의 객체의 영역을 결정하는 방법은 오브젝트 디텍션(object detection) 또는 시멘틱 세그멘테이션 (semantic segmentation)일 수 있다. 분류된 객체에 대응되는 모델을 적용하는 단계는, 제2 모델의 선택 모듈에 의해서 수행될 수 있다. 제2 모델은 제1 모델의 객체 분류 개수에 대응되는 복수의 객체 모델을 포함할 수 있다. 각각의 객체 모델은 특 정 객체에 특정 영상처리가 적용된 학습 데이터세트로 학습된 객체영상처리 모델일 수 있다. 제2 모델은 제1 모델의 객체 분류 개수에 대응되는 객체 파라미터들을 포함하는, 인공신경망 영상처리 방법. 장치는 입력 영상의 적어도 하나의 객체를 분류하도록 학습된 제1 모델; 및 상기 적어도 하나의 객체의 분류에 대응되는 영상처리를 하도록 학습된 제2모델을 포함할 수 있다. 장치는 제1 모델 및 상기 제2 모델을 처리하도록 구성된 신경 프로세싱 유닛을 더 포함할 수 있다. 장치는 상기 입력 영상의 ROI(Region of interest)를 설정하고, 상기 영상처리는 상기 ROI에서 적어도 Super resolution을 처리하도록 구성될 수 있다. 제2 모델은 디노이징(Denoising), 디블러링(Deblurring), 엣지 강화(Edge Enhancement) 모델, 디모자이징 (Demosaicing), 컬러 톤 강화(Color Tone Enhancing), 화이트 밸런싱(White Balancing), 초고해상도(Super resolution), 초고해상도(Super resolution) 및 디컴프레션(Decompression) 중 적어도 하나의 영상처리를 하도 록 학습될 수 있다. 신경 프로세싱 유닛은 제1 모델 및 제2 모델 중 적어도 하나의 적어도 일부를 저장하도록 구성된 NPU 내부 메모 리; 상기 NPU 내부 메모리와 통신하며, 상기 제1 모델 및 상기 제2 모델 중 적어도 하나의 합성곱을 처리하도록 구성된 프로세싱 엘리먼트 어레이를 포함할 수 있다. 장치는 제1 모델 및 제2 모델을 저장하도록 구성된 메인 메모리를 더 포함하고, NPU 내부 메모리는 선택적으로 제1 모델 및 제2 모델을 메인 메모리에서 읽어오도록 구성될 수 있다. 신경 프로세싱 유닛은 제1 모델을 활용하여 객체 인식 오퍼레이션을 수행하도록 구성될 수 있다. 신경 프로세싱 유닛은 제2 모델을 활용하여 영상 처리 오퍼레이션을 수행하도록 구성될 수 있다. 적어도 하나의 프로세싱 엘리먼트는 제1 모델에서 분류된 객체의 개수에 대응되는 제2 모델의 객체영상처리모델 들을 처리하도록 구성될 수 있다. 신경 프로세싱 유닛은 각각의 객체영상처리모델들에서 영상 처리된 영역들을 조합하여 영상 처리된 출력영상을 생성하도록 구성될 수 있다. NPU 내부 메모리의 메모리 크기에 기초하여, NPU 내부 메모리는 제1 모델과 제2 모델 각각의 파라미터를 특정 크기로 타일링한 적어도 일부를 메인 메모리에서 제공받도록 구성될 수 있다. 제1 모델의 파라미터의 적어도 일부는 NPU 내부 메모리에 상주하고, 제2 모델의 파라미터들 중에서 제1 모델의 객체 인식결과에 대응되는 제2 모델의 파라미터의 적어도 일부가 NPU 내부 메모리에 스위칭 될 수 있다. 제1 모델의 객체인식결과가 이전 프레임과 동일할 경우, 제2 모델의 파라미터들 중 적어도 일부는 NPU 내부 메 모리에 상주할 수 있다. 본 명세서와 도면에 게시된 본 개시의 예시들은 본 개시의 기술내용을 쉽게 설명하고 본 개시의 이해를 돕기 위 해 특정 예를 제시한 것뿐이며, 본 명의 범위를 한정하고자 하는 것은 아니다. 여기에 게시된 예시들 이외에도 발명의 기술적 사상에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은 본 개시가 속하는 기술 분야에서 통상 의 지식을 가진 자에게 자명한 것이다. [이 발명을 지원한 국가연구개발사업] [과제고유번호] 1711126253 [과제번호] 2020-0-01297-002 [부처명] 과학기술정보통신부 [과제관리(전문)기관명] 정보통신기획평가원 [연구사업명] 차세대지능형반도체기술개발(설계)(R＆D) [연구과제명] 데이터 재사용 고도화 초저전력 엣지용 딥러닝 프로세서 기술개발 [기여율] 1/1 [과제수행기관명] (주)딥엑스 [연구기간] 2021.01.01 ~ 2021.12.31"}
{"patent_id": "10-2022-7027419", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 예시적인 인공신경망 기반 모델을 설명하는 개략적인 개념도이다. 도 2는 본 개시의 일 예시에 따른 신경 프로세싱 유닛이 포함된 장치를 설명하는 개략적인 개념도이다. 도 3은 본 개시의 일 예시에 따른 신경 프로세싱 유닛을 설명하는 개략적인 개념도이다. 도 4는 본 개시에 적용될 수 있는 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 개략적인 개념도이다. 도 5는 본 개시의 일 예시에 따른 신경 프로세싱 유닛에 기초한 영상 처리 방법을 설명하는 예시적인 순서도이 다. 도 6 및 7은 본 개시의 일 예시에 따른 신경 프로세싱 유닛에서 제1 모델 및 제2 모델을 이용한 품질이 향상된 영상 출력 절차를 나타낸 예시적인 개략도이다. 도 8a 내지 8d는 본 개시의 일 예시에 따른 신경 프로세싱 유닛에서 제2 모델의 구조를 설명하는 개략적인 개념 도이다. 도 9는 본 개시의 다른 예시에 따른 신경 프로세싱 유닛에 기초한 영상 처리 방법을 설명하는 예시적인 순서도 이다. 도 10 및 11은 본 개시의 다른 예시에 따른 신경 프로세싱 유닛에서 제1 모델 및 제2 모델을 이용한 품질이 향 상된 영상 출력 절차를 나타낸 예시적인 개략도이다. 도 12는 본 개시의 일 예시에 따른 신경 프로세싱 유닛 기반 차량 번호 인식 시스템에 대한 예시도이다. 도 13은 본 개시의 다양한 예시에 따른 영상 처리 방법의 구현 예시도이다."}
