{"patent_id": "10-2019-0168892", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0077348", "출원번호": "10-2019-0168892", "발명의 명칭": "데이터 처리 시스템 및 그 동작 방법", "출원인": "에스케이하이닉스 주식회사", "발명자": "진영재"}}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "호스트의 요청에 응답하여 신경망 연산을 수행하는 데이터 처리 장치로서,상기 호스트로부터 입력 데이터, 출력 데이터 및 가중치를 포함하는 파라미터 저장 방식과 상기 가중치 재사용방식을 포함하는 제어정보와 입력 데이터를 전송받으며, 상기 입력 데이터와 상기 가중치를 연산하여 출력 데이터를 생성하는 컨트롤러; 및상기 호스트로부터 상기 가중치가 전송됨에 따라 상기 컨트롤러의 제어에 따라 상기 가중치를 저장하는 메모리장치;를 포함하고,상기 컨트롤러는, 상기 파라미터 저장 방식 및 상기 가중치 재사용 방식에 기초하여 상기 호스트로부터 제공되는 물리 어드레스를 메모리 어드레스로 맵핑하되, 상기 가중치 리드 동작의 대역폭이 최대화되도록 맵핑하도록구성되는 어드레스 변환부를 포함하는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 물리 어드레스는, 상기 가중치와 연산되는 입력 데이터를 지시하는 입력 노드 ID 및 상기 출력 데이터를지시하는 출력 노드 ID를 포함하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 신경망 연산이 상기 가중치를 재사용하는 경우, 상기 어드레스 변환부는, 상기 어드레스를 변경하면서 액세스할 때 제 1 레이턴시를 갖는 제 1 메모리 어드레스에 상기 출력 노드 ID를 맵핑하고, 어드레스를 변경하면서 액세스할 때 상기 제 1 레이턴시보다 큰 제 2 레이턴시를 갖는 제 2 메모리 어드레스에 상기 입력 노드 ID를맵핑하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 신경망 연산이 상기 가중치를 재사용하지 않고, 상기 파라미터 저장 방식이 입력 데이터 유지 방식인경우, 상기 어드레스 변환부는, 상기 어드레스를 변경하면서 액세스할 때 제 1 레이턴시를 갖는 제 1 메모리 어드레스에 상기 출력 노드 ID를 맵핑하고, 어드레스를 변경하면서 액세스할 때 상기 제 1 레이턴시보다 큰 제 2레이턴시를 갖는 제 2 메모리 어드레스에 상기 입력 노드 ID를 맵핑하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 2 항에 있어서,상기 신경망 연산이 상기 가중치를 재사용하지 않고, 상기 파라미터 저장 방식이 출력 데이터 유지 방식인경우, 상기 어드레스 변환부는, 상기 어드레스를 변경하면서 액세스할 때 제 1 레이턴시를 갖는 제 1 메모리 어드레스에 상기 입력 노드 ID를 맵핑하고, 어드레스를 변경하면서 액세스할 때 상기 제 1 레이턴시보다 큰 제 2레이턴시를 갖는 제 2 메모리 어드레스에 상기 출력 노드 ID를 맵핑하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 가중치를 재사용하는 상기 신경망 연산은 합성곱 신경망의 컨볼루션 레이어 연산인 데이터 처리 시스템.공개특허 10-2021-0077348-3-청구항 7 제 1 항에 있어서,상기 가중치를 재사용하지 않는 상기 신경망 연산은 완전연결 신경망 연산 또는 합성곱 신경망의 완전연결 레이어 연산인 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "호스트의 요청에 응답하여 신경망 연산을 수행하는 데이터 처리 시스템으로서,상기 호스트로부터 전송되는 입력 데이터와 가중치를 연산하여 출력 데이터를 생성하는 컨트롤러; 및상기 컨트롤러의 제어에 따라 상기 호스트로부터 전송되는 가중치를 저장하는 메모리 장치;를 포함하고,상기 컨트롤러는, 상기 가중치와 연산되는 입력 데이터를 지시하는 입력 노드 ID 및 상기 가중치와 상기 입력데이터의 연산 결과인 출력 데이터를 지시하는 출력 노드 ID를 포함하는 물리 어드레스를 상기 호스트로부터 가중치 저장 어드레스로 제공받아, 상기 연산을 위해 동시에 리드되는 상기 가중치들의 입력 노드 ID 및 출력 노드 ID의 변화 양상에 따라 상기 물리 어드레스를 메모리 어드레스에 맵핑하도록 구성되는 어드레스 변환부를 포함하는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 물리 어드레스는 상기 입력 노드 ID에 대응하는 제 1 물리 어드레스 및 상기 출력 노드 ID에 대응하는 제2 물리 어드레스를 포함하고,상기 메모리 어드레스는 어드레스를 변경하면서 액세스할 때 제 1 레이턴시를 갖는 제 1 메모리 어드레스와, 어드레스를 변경하면서 액세스할 때 상기 제 1 레이턴시보다 큰 제 2 레이턴시를 갖는 제 2 메모리 어드레스를 포함하며,상기 어드레스 변환부는, 연산에 사용되는 복수의 가중치들의 제 1 및 제 2 물리 어드레스 중 변경 빈도가 높은물리 어드레스를 상기 제 1 메모리 어드레스에 맵핑하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 물리 어드레스는 상기 입력 노드 ID에 대응하는 제 1 물리 어드레스 및 상기 출력 노드 ID에 대응하는 제2 물리 어드레스를 포함하고,상기 어드레스 변환부는, 상기 물리 어드레스로부터 상기 입력 노드 ID에 대응하는 제 1 물리 어드레스 및 상기출력 노드 ID에 대응하는 제 2 물리 어드레스를 추출하는 어드레스 추출부;상기 호스트로부터 상기 입력 데이터, 상기 출력 데이터 및 상기 가중치를 포함하는 파라미터 저장 방식과 상기가중치 재사용 방식을 포함하는 제어정보를 수신하여 선택 신호를 생성하는 선택 신호 생성부; 및상기 선택 신호에 응답하여, 상기 제 1 물리 어드레스와 상기 제 2 물리 어드레스를 메모리 어드레스에 맵핑하는 어드레스 맵핑부;를 포함하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 메모리 어드레스는 어드레스를 변경하면서 액세스할 때 제 1 레이턴시를 갖는 제 1 메모리 어드레스와, 어드레스를 변경하면서 액세스할 때 상기 제 1 레이턴시보다 큰 제 2 레이턴시를 갖는 제 2 메모리 어드레스를 포함하며,상기 어드레스 맵핑부는, 연산에 사용되는 복수의 가중치들의 제 1 및 제 2 물리 어드레스 중 변경 빈도가 높은공개특허 10-2021-0077348-4-물리 어드레스를 상기 제 1 메모리 어드레스에 맵핑하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 신경망 연산이 상기 가중치를 재사용하는 경우, 상기 어드레스 맵핑부는, 상기 제 1 메모리 어드레스에 상기 출력 노드 ID를 맵핑하고, 상기 제 2 메모리 어드레스에 상기 입력 노드 ID를 맵핑하도록 구성되는 데이터처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 신경망 연산이 상기 가중치를 재사용하지 않고, 상기 파라미터 저장 방식이 입력 데이터 유지 방식인경우, 상기 어드레스 맵핑부는, 상기 제 1 메모리 어드레스에 상기 출력 노드 ID를 맵핑하고, 상기 제 2 메모리어드레스에 상기 입력 노드 ID를 맵핑하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11 항에 있어서,상기 신경망 연산이 상기 가중치를 재사용하지 않고, 상기 파라미터 저장 방식이 출력 데이터 유지 방식인경우, 상기 어드레스 맵핑부는, 상기 제 1 메모리 어드레스에 상기 입력 노드 ID를 맵핑하고, 상기 제 2 메모리어드레스에 상기 출력 노드 ID를 맵핑하도록 구성되는 데이터 처리 시스템."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컨트롤러 및 상기 컨트롤러의 제어에 따라 데이터를 저장하는 메모리 장치를 포함하며, 호스트의 요청에 응답하여 신경망 연산을 수행하는 데이터 처리 장치의 동작 방법으로서,상기 호스트로부터 입력 데이터, 출력 데이터 및 가중치를 포함하는 파라미터 저장 방식과 상기 가중치 재사용방식을 포함하는 제어정보, 입력 데이터 및 상기 가중치가 전송됨에 따라, 상기 컨트롤러가, 상기 파라미터 저장 방식 및 상기 재사용 방식에 기초하여 상기 호스트로부터 제공되는 물리어드레스를 메모리 어드레스로 맵핑하되, 상기 가중치 리드 동작의 대역폭이 최대화되도록 맵핑하는 단계;상기 메모리 장치의 상기 메모리 어드레스에 상기 가중치를 저장하는 단계; 및상기 컨트롤러가 상기 입력 데이터와 상기 가중치를 연산하여 출력 데이터를 생성하는 단계;를 포함하도록 구성되는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 물리 어드레스는, 상기 가중치와 연산되는 입력 데이터를 지시하는 입력 노드 ID 및 상기 출력 데이터를지시하는 출력 노드 ID를 포함하는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 맵핑하는 단계는,상기 신경망 연산이 상기 가중치를 재사용하는 경우, 상기 어드레스를 변경하면서 액세스할 때 제 1 레이턴시를갖는 제 1 메모리 어드레스에 상기 출력 노드 ID를 맵핑하고, 어드레스를 변경하면서 액세스할 때 상기 제 1 레이턴시보다 큰 제 2 레이턴시를 갖는 제 2 메모리 어드레스에 상기 입력 노드 ID를 맵핑하는 단계를 포함하도록구성되는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "공개특허 10-2021-0077348-5-제 16 항에 있어서,상기 맵핑하는 단계는,상기 신경망 연산이 상기 가중치를 재사용하지 않고, 상기 파라미터 저장 방식이 입력 데이터 유지 방식인경우, 상기 어드레스를 변경하면서 액세스할 때 제 1 레이턴시를 갖는 제 1 메모리 어드레스에 상기 출력 노드ID를 맵핑하고, 어드레스를 변경하면서 액세스할 때 상기 제 1 레이턴시보다 큰 제 2 레이턴시를 갖는 제 2 메모리 어드레스에 상기 입력 노드 ID를 맵핑하는 단계를 포함하도록 구성되는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2019-0168892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 16 항에 있어서,상기 맵핑하는 단계는,상기 신경망 연산이 상기 가중치를 재사용하지 않고, 상기 파라미터 저장 방식이 출력 데이터 유지 방식인경우, 상기 어드레스를 변경하면서 액세스할 때 제 1 레이턴시를 갖는 제 1 메모리 어드레스에 상기 입력 노드ID를 맵핑하고, 어드레스를 변경하면서 액세스할 때 상기 제 1 레이턴시보다 큰 제 2 레이턴시를 갖는 제 2 메모리 어드레스에 상기 출력 노드 ID를 맵핑하는 단계를 포함하도록 구성되는 데이터 처리 시스템의 동작 방법."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 의한 데이터 처리 시스템은 호스트의 요청에 응답하여 신경망 연산을 수행하는 데이터 처리 장치로 서, 호스트로부터 입력 데이터, 출력 데이터 및 가중치를 포함하는 파라미터 저장 방식과 가중치 재사용 방식을 포함하는 제어정보와 입력 데이터를 전송받으며, 입력 데이터와 가중치를 연산하여 출력 데이터를 생성하는 컨트 롤러 및 호스트로부터 가중치가 전송됨에 따라 컨트롤러의 제어에 따라 가중치를 저장하는 메모리 장치를 포함하 고, 컨트롤러는, 파라미터 저장 방식 및 가중치 재사용 방식에 기초하여 호스트로부터 제공되는 물리 어드레스를 메모리 어드레스로 맵핑하되, 가중치 리드 동작의 대역폭이 최대화되도록 맵핑하도록 구성되는 어드레스 변환부 를 포함할 수 있다."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컴퓨팅 장치에 관한 것으로, 보다 구체적으로는 데이터 처리 시스템 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 어플리케이션 및 빅데이터 분석에 대한 관심과 중요성이 높아지면서, 대용량의 데이터를 효율적으로 처리할 수 있는 컴퓨팅 시스템에 대한 요구가 증가하고 있다. 전통적인 컴퓨팅 시스템이 프로세서 중심 컴퓨팅에 집중하였다면, 최근의 컴퓨팅 시스템은 방대한 데이터를 고 속으로 병렬 처리할 수 있는 데이터 중심 컴퓨팅, 또는 메모리 중심 컴퓨팅으로 진화하였다. 이에 따라 프로세 서와 메모리 간의 데이터 병목 현상을 줄일 수 있어 연산 성능이 극대화되고 있다. 컴퓨팅 장치의 성능 및 속도는 메모리 장치에 데이터를 읽고 쓰는 속도에 의존하므로 대용량 데이터를 더욱 고 속으로 입출력하기 위한 연구가 필요하다."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 기술의 실시예는 데이터 입출력 속도를 향상시킬 수 있는 데이터 처리 시스템 및 그 동작 방법을 제공할 수 있다."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 기술의 일 실시예에 의한 데이터 처리 시스템은 호스트의 요청에 응답하여 신경망 연산을 수행하는 데이터 처리 장치로서, 상기 호스트로부터 입력 데이터, 출력 데이터 및 가중치를 포함하는 파라미터 저장 방식과 상기 가중치 재사용 방식을 포함하는 제어정보와 입력 데이터를 전송받으며, 상기 입력 데이터와 상기 가중치를 연산 하여 출력 데이터를 생성하는 컨트롤러; 및 상기 호스트로부터 상기 가중치가 전송됨에 따라 상기 컨트롤러의 제어에 따라 상기 가중치를 저장하는 메모리 장치;를 포함하고, 상기 컨트롤러는, 상기 파라미터 저장 방식 및 상기 가중치 재사용 방식에 기초하여 상기 호스트로부터 제공되는 물리 어드레스를 메모리 어드레스로 맵핑하되, 상기 가중치 리드 동작의 대역폭이 최대화되도록 맵핑하도록 구성되는 어드레스 변환부를 포함할 수 있다. 본 기술의 일 실시예에 의한 데이터 처리 시스템은 호스트의 요청에 응답하여 신경망 연산을 수행하는 데이터 처리 시스템으로서, 상기 호스트로부터 전송되는 입력 데이터와 가중치를 연산하여 출력 데이터를 생성하는 컨 트롤러; 및 상기 컨트롤러의 제어에 따라 상기 호스트로부터 전송되는 가중치를 저장하는 메모리 장치;를 포함하고, 상기 컨트롤러는, 상기 가중치와 연산되는 입력 데이터를 지시하는 입력 노드 ID 및 상기 가중치와 상기 입력 데이터의 연산 결과인 출력 데이터를 지시하는 출력 노드 ID를 포함하는 물리 어드레스를 상기 호스트로부 터 가중치 저장 어드레스로 제공받아, 상기 연산을 위해 동시에 리드되는 상기 가중치들의 입력 노드 ID 및 출 력 노드 ID의 변화 양상에 따라 상기 물리 어드레스를 메모리 어드레스에 맵핑하도록 구성되는 어드레스 변환부 를 포함할 수 있다. 본 기술의 일 실시예에 의한 데이터 처리 시스템의 동작 방법은 컨트롤러 및 상기 컨트롤러의 제어에 따라 데이 터를 저장하는 메모리 장치를 포함하며, 호스트의 요청에 응답하여 신경망 연산을 수행하는 데이터 처리 장치의 동작 방법으로서, 상기 호스트로부터 입력 데이터, 출력 데이터 및 가중치를 포함하는 파라미터 저장 방식과 상 기 가중치 재사용 방식을 포함하는 제어정보, 입력 데이터 및 상기 가중치가 전송됨에 따라, 상기 컨트롤러가, 상기 파라미터 저장 방식 및 상기 재사용 방식에 기초하여 상기 호스트로부터 제공되는 물리 어드레스를 메모리 어드레스로 맵핑하되, 상기 가중치 리드 동작의 대역폭이 최대화되도록 맵핑하는 단계; 상기 메모리 장치의 상 기 메모리 어드레스에 상기 가중치를 저장하는 단계; 및 상기 컨트롤러가 상기 입력 데이터와 상기 가중치를 연 산하여 출력 데이터를 생성하는 단계;를 포함하도록 구성될 수 있다."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 기술에 의하면 연산에 사용되는 데이터의 사용 방식 및 저장 방식에 적합하게 데이터를 기록 및 리드함에 따 라 데이터 입출력 레이턴시를 최소화할 수 있다."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 기술의 실시예를 보다 구체적으로 설명한다. 도 1은 일 실시예에 의한 데이터 처리 시스템을 포함하는 전자 장치의 구성도이다. 도 1을 참조하면, 전자 장치는 호스트 및 데이터 처리 시스템을 포함할 수 있다. 전자 장치는 개인용 컴퓨터, 서버 컴퓨터, 모바일 컴퓨팅 장치, 자동차의 전자 제어 장치 등 다양한 전자 장 치일 수 있다. 전자 장치는 슈퍼컴퓨터 또는 컴퓨터 클러스터를 사용하여 협력적인 방식으로 연산을 수행하는 고성능 컴퓨 팅(High Performance Computing: HPC) 장치, 또는 개별적으로 데이터를 처리하는 네트워킹된 정보 처리 장치들 또는 서버들의 어레이를 포함할 수 있다. 호스트는 사용자 인터페이스를 통해 사용자에게 다양한 서비스를 제공할 수 있다. 이를 위해 호스트는 데이터 처리 시스템으로 데이터 처리와 관련된 제어정보(CON), 어드레스(ADD), 그리고 필요한 경우 데이터 (DATA)를 전송하고, 그에 대한 처리 결과를 데이터 처리 시스템으로부터 수신할 수 있다.데이터 처리 시스템은 호스트의 요청에 대응하는 동작을 수행하고, 필요한 경우 데이터를 호스트 로 전송할 수 있다. 호스트는 데이터 처리 시스템으로 데이터 입출력을 요청하거나, 데이터 입출력을 수반하는 어플리케이 션을 오프로드하여 처리할 것을 요청할 수 있다. 여기에서, 오프로드란 호스트의 연산을 다른 장치, 예를 들어 데이터 처리 시스템으로 위임하는 것을 의미한다. 호스트는 데이터 처리 시스템으로 특정 어플리케이션의 오프로드 처리를 요청하기 위해 제어 정보 (CON) 및 초기 파라미터를 전송할 수 있다. 신경망 어플리케이션의 오프로드 처리를 요청하는 경우, 초기 파라 미터는 입력 데이터 및 초기 가중치를 포함할 수 있고, 호스트는 컨트롤러로 제어 정보(CON) 및 입력 데이터를 전송하는 한편, 메모리 장치로 초기 가중치를 전송하여 저장할 수 있다. 제어정보(CON)는 데이 터 처리 시스템에서 실행할 어플리케이션의 종류, 어플리케이션의 프로그램 코드 저장 주소, 초기 파라미 터 저장 주소, 파라미터의 저장 방식을 포함할 수 있다. 데이터 처리 시스템은 컨트롤러 및 메모리 장치를 포함할 수 있고, 제어 정보(CON) 및 초기 파 라미터에 응답하여 호스트의 요청을 처리할 수 있다. 메모리 장치는 컨트롤러의 제어에 따라 데이터를 저장하거나 저장된 데이터를 출력할 수 있다. 메모 리 장치는 복수의 메모리 모듈(MM, 300-1~300-N)을 포함할 수 있고, 페이지(바이트) 단위로 접근 가능하게 구성될 수 있다. 즉, 컨트롤러는 메모리 장치에 페이지 단위로 접근할 수 있다. 일 실시예에서, 메모리 모듈(300-1~300-N)은 복수의 뱅크 그룹(BG0~BG3)을 포함할 수 있다. 복수의 뱅크 그룹 (BG0~BG3)은 각각 복수의 뱅크(BANK)를 포함할 수 있다. 각각의 뱅크(BANK)는 복수의 로우라인(ROW)(또는 워드 라인) 및 복수의 컬럼 라인(COLUMN)(또는 비트라인, 또는 스트링) 간에 각각 접속되는 복수의 메모리 셀(Cell) 들을 포함하며, 예를 들어 하나의 워드라인에 접속되는 메모리 셀들이 하나의 페이지를 이룰 수 있다. 메모리 모듈(300-1~300-N)은 휘발성 메모리 모듈을 포함할 수 있고, 이에 더하여 비휘발성 메모리 모듈을 더 포 함할 수 있다 휘발성 메모리 모듈은 예를 들어 DRAM(Dynamic Random Access Memory) 및/또는 SRAM(Static Random Access Memory)을 포함하도록 구성될 수 있다. 비휘발성 메모리 모듈은 예를 들어 EEPROM(Electrically Erasable and Programmable ROM), 낸드(NAND) 플래시 메모리, 노어(NOR) 플래시 메모리, PRAM(Phase-Change RAM), ReRAM(Resistive RAM) FRAM(Ferroelectric RAM), STT-MRAM(Spin Torque Transfer Magnetic RAM)중 적어도 하 나를 포함하도록 구성될 수 있다. 일 실시예에서, 메모리 모듈(300-1~300-N) 각각은 모듈 보드 상에 장착된 다수의 메모리 칩들을 포함하는 SIMM(single in-line memory module) 또는 DIMM(dual inline memory module) 형태의 메모리 모듈 또는, 고 대 역폭 메모리(high bandwidth memory, HBM)일 수 있다. HBM 모듈은 인터포저(Interposer) 상에 장착된 복수의 HBM들 및 적어도 하나의 하드웨어 가속기를 포함할 수 있다. 일 실시예에서, 메모리 모듈(300-1~300-N)은 모듈 보드 상에 컨트롤러를 포함하는 형태로, 또는 HBM 모듈의 경우 베이스 다이에 컨트롤러를 포함하는 형태로 구성될 수 있다. 컨트롤러는 호스트로부터 제공되는 제어 정보(CON)에 따라 어플리케이션 프로그램 코드 저장 주소에 대응하는 메모리 영역으로부터 리드한 프로그램 코드 및 입력 데이터 저장 영역으로부터 리드한 입력 데이터를 내부 메모리에 로딩하는 한편, 메모리 장치로부터 초기 가중치를 리드하고 내부 메모리에 로딩하여 프로그 램 코드를 실행, 즉 연산할 수 있다. 어플리케이션 프로그램 코드는 호스트의 메모리 또는 메모리 장치 의 비휘발성 메모리 모듈에 저장될 수 있다. 어플리케이션의 프로그램 코드를 실행함에 따라 생성된 데이 터들은 메모리 장치에 저장될 수 있다. 예를 들어, 프로그램 코드를 실행하여 생성된 데이터들은 휘발성 메모리 모듈에 임시 저장된 후, 필요에 따라 비휘발성 메모리 모듈에 저장될 수 있다. 일 실시예에서, 호스트는 데이터 처리 시스템으로 기계학습이나 인공지능 어플리케이션, 예를 들어 신 경망 연산을 오프로드하여 처리할 것을 요청할 수 있다. 신경망 연산을 처리하는 동안 사용되는 데이터들, 예 를 들어 가중치는 신경망 모델에 포함된 레이어 별로 구분되어 메모리 장치 내에 저장될 수 있다. 일 실시예에서, 특정 레이어의 연산에 사용되는 가중치는 동일한 로우 어드레스에 저장될 수 있다. 신경망 어 플리케이션을 처리하기 위한 알고리즘은 복수의 레이어로 구성되며, 각 레이어에서 사용되는 가중치를 리드하기 위해 메모리 장치에 접근하는 순서는 가중치가 저장된 순서와 다를 수 있고, 신경망 모델의 연산 방식 및컨트롤러의 구조에 따라 달라질 수 있다. 즉, 가중치의 라이트 순서와 리드 순서가 다른 경우가 존재할 수 있고, 이는 리드 레이턴시에 영향을 미칠 수 있다. 본 기술의 일 실시예에서, 컨트롤러는 호스트가 처리 요청한 작업이 신경망 연산 처리인 경우, 해당 신경망 알고리즘의 가중치 재사용 방식 및 컨트롤러의 파라미터(가중치, 입력 데이터, 출력 데이터) 저장 방식에 기초하여, 호스트가 제공하는 물리 어드레스(PA)를 메모리 어드레스(MA)로 맵핑하여 가중치를 저장 하되, 가중치 리드 동작의 대역폭이 최대화되는 방식으로 맵핑할 수 있다. 일 실시예에서, 가중치 재사용 방식은 가중치 공유 방식 및 가중치 비공유 방식으로 구분될 수 있다. 가중치를 공유한다는 것은 복수의 입력 데이터 각각에 대해 동일한 가중치 셋을 적용하여 출력 데이터를 생성해 내는 방 식을 의미할 수 있다. 예를 들어, 합성곱 신경망(Convolutional Neural Network; CNN)의 컨볼루션 레이어의 연산 과정에서 복수의 입력 데이터 각각에 대해 동일한 가중치 필터를 적용하여 복수의 출력 데이터를 생성하는 연산을 가중치 공유 방식의 연산이라 할 수 있다. 가중치를 공유하지 않는 방식은 복수의 입력 데이터 각각에 대해 상이한 가중치 셋을 적용하여 출력 데이터를 생성하는 방식을 의미할 수 있다. 예를 들어, CNN의 완전 연 결 신경망(Fully Connected Neural Network) 또는 CNN의 완전 연결 레이어에서 복수의 입력 데이터 각각에 대 해 서로 다른 가중치 행렬을 적용하여 복수의 출력 데이터를 생성하는 연산을 가중치 비공유 방식의 연산이라 할 수 있다. 파라미터 저장 방식은 가중치 유지(Weight Stationary) 방식, 입력 데이터 유지(Input Stationary) 방식, 출력 데이터(Output Stationary) 방식으로 구분될 수 있다. 가중치 유지 방식은 한 사이클의 신경망 연산 과정 동안 컨트롤러 내의 캐시 메모리에 가중치가 유지되는 방식일 수 있다. 입력 데이터 유지 방식은 한 사이클의 신경망 연산 과정 동안 입력 데이터가 유지되는 방식일 수 있으며, 출력 데이터 유지 방식은 한 사이클의 신경 망 연산 과정 동안 출력 데이터가 유지되는 방식일 수 있다. 가중치 재사용 방식 및 파라미터 저장 방식의 구체적인 예는 후술할 것이다. 다른 관점에서, 컨트롤러는 가중치와 연산되는 입력 데이터를 지시하는 입력 노드 ID 및 연산 결과인 출력 데이터를 지시하는 출력 노드 ID를 포함하는 물리 어드레스를 가중치 저장 어드레스로 제공받아, 연산을 위해 동시에 리드되는 가중치들의 입출력 노드 ID의 변화 양상에 따라 물리 어드레스를 메모리 어드레스에 맵핑하도 록 구성될 수 있다. 이 때, 입출력 노드의 변화 양상은 신경망 알고리즘의 가중치 재사용 방식 및 컨트롤러 의 파라미터(가중치, 입력 데이터, 출력 데이터) 저장 방식에 기초하여 결정될 수 있다. 일 실시예에 의한 컨트롤러는 각각 입력 노드 ID를 갖는 복수의 입력 데이터와 각각 복수의 가중치로 구성 된 복수의 가중치 셋을 제공받아, 입력 데이터와 가중치 셋을 연산하여 각각 출력 노드 ID를 갖는 복수의 출력 데이터를 생성할 수 있다. 그리고 컨트롤러는 연산 동작시 각각의 가중치 셋과 연관되는 입력 노드 ID 및 출력 노드 ID를 가중치 셋의 물리 어드레스로 제공받아 동시에 리드되는 가중치의 수가 최대가 되도록 물리 어 드레스를 메모리 어드레스에 맵핑하여 메모리 어드레스에 대응하는 메모리 영역에 가중치 셋을 저장할 수 있다. 일 실시예에서, 물리 어드레스는 입력 노드 ID에 대응하는 제 1 물리어드레스 및 출력 노드 ID에 대응하는 제 2 물리 어드레스를 포함하고, 메모리 어드레스는 어드레스를 변경하면서 액세스할 때 제 1 레이턴시를 갖는 제 1 메모리 어드레스와, 어드레스를 변경하면서 액세스할 때 제 1 레이턴시보다 큰 제 2 레이턴시를 갖는 제 2 메모 리 어드레스를 포함하며, 연산에 사용되는 복수의 가중치 셋의 물리 어드레스 중 변경 빈도가 높은 ID의 물리 어드레스를 제 1 메모리 어드레스에 맵핑할 수 있다. 호스트로부터 제공되는 입력 데이터와 가중치 셋, 컨트롤러의 연산 결과로 생성된 출력 데이터는 연산 파라미터를 구성하고, 변경 빈도는 연산에 사용되는 가중치 셋의 재사용 여부 및 연산 동안 컨트롤러 내에 유지되는 연산 파라미터의 종류에 따라 결정될 수 있다. 이와 같이, 연산을 위해 동시에 리드되는 가중치의 리드 대역폭이 최대화되도록 가중치를 저장함으로써 데이터 리드 속도를 향상시킬 수 있다. 도 2는 일 실시예에 의한 컨트롤러의 구성도이다. 도 2를 참조하면, 일 실시예에 의한 컨트롤러는 프로세서, 호스트 인터페이스, ROM, RAM, 메모리 컨트롤러/인터페이스, 가속기 및 어드레스 변환부를 포함할 수 있다.프로세서는 메모리 장치의 동작 전반을 제어할 수 있고, 호스트가 전송하는 명령에 응답하여 호 스트가 요청한 연산을 처리할 수 있다. 호스트가 요청한 연산을 처리하기 위하여 프로세서는 호 스트 또는 메모리 장치로부터 제공되는 데이터를 이용할 수 있다. 일 실시예에서, 프로세서는 전자 장치에서 실행되는 특화된 어플리케이션을 위한 연산을 수행할 수 있 다. 일 실시예에서, 전자 장치는 높은 대역폭을 요구하는 기계학습 어플리케이션, 또는 인공지능 어플리케 이션을 실행할 수 있고 프로세서는 기계학습이나 인공지능 어플리케이션에 특화된 연산을 수행할 수 있다. 호스트 인터페이스는 호스트와 데이터 처리 시스템 간의 인터페이스를 제공할 수 있다. 호스트 인터페이스는 호스트로부터 제공되는 커맨드를 저장, 복호화 및 스케쥴링하여 프로세서로 제공할 수 있다. 호스트 인터페이스는 프로세서의 제어에 따라 호스트로부터 제공되는 데이터를 프로세 서 또는 메모리 컨트롤러/인터페이스로 제공하거나, 메모리 장치로부터 메모리 컨트롤러/인터페 이스를 통해 제공된 데이터를 호스트로 제공할 수 있다. 메모리 컨트롤러/인터페이스는 호스트 인터페이스 또는 프로세서로부터 제공된 데이터를 메모리 장치로 전송하거나, 메모리 장치에서 리드한 데이터를 전달받아 프로세서 또는 호스트 인터페이 스로 제공할 수 있다. 이를 위해, 메모리 컨트롤러/인터페이스는 컨트롤러와 메모리 장치 간의 신호 송수신을 위한 통신 채널을 제공할 수 있다. 메모리 컨트롤러/인터페이스는 호스트가 직접 메모리 장치에 접근하거나 컨트롤러를 통해 접근할 수 있는 경로를 제공할 수 있다. ROM은 컨트롤러의 동작에 필요한 프로그램 코드, 예를 들어 펌웨어 또는 소프트웨어가 저장되고, 프 로그램 코드들이 이용하는 코드 데이터 등이 저장될 수 있다. RAM은 컨트롤러의 동작에 필요한 데이터 또는 컨트롤러에 의해 생성된 데이터를 저장할 수 있 다. 호스트는 데이터 처리 시스템으로 특정 어플리케이션에 대한 연산 처리를 컨트롤러의 가속기 에서 오프로드하여 처리하도록 명령할 수 있고, 프로세서는 오프로드 명령을 추출하고 복호화하여 가 속기를 제어할 수 있다. 가속기는 프로세서로부터 출력된 명령에 응답하여 RAM에 로딩된 어플리케이션 프로그램 코드에 따라 연산을 처리할 수 있다. 가속기의 연산 처리 결과로 생성된 데이터는 메모리 장치의 특정 영역 에 저장되거나 호스트로 전송될 수 있다. 일 실시예에서, 가속기는 산술논리장치(Arithmetic Logic Unit; ALU), 부동소수점장치(Floating-Point Unit; FPU)를 포함할 수 있다. 가속기는 FPGA(Field-programmable gate array), MPPA(Massively parallel processor array), GPU(Graphics processing unit), ASIC(Application-Specific Integrated Circuit), NPU(Neural processing unit), TPU(Tensor Processing Unit) 및 MPSoC(Multi-Processor System-on- Chip) 등의 다양한 종류의 가속기 중에서 선택될 수 있다. 일 실시예에서, 가속기는 메모리 모듈(300- 1~300-N)에 각각에 또는 지정된 개수의 메모리 모듈(300-1~300-x)에 대응하여 구비될 수 있다. 메모리 모듈 (300-1~300-N)은 가속기로부터의 커맨드 및 어드레스에 응답하여 데이터를 입출력할 수 있다. 도시하지 않았지만, 가속기는 커맨드 컨트롤러 및 캐시 메모리를 포함할 수 있다. 신경망 연산을 위한 가 속기의 경우, 연산 대상 입력 데이터와 가중치, 연산 결과가 캐시 메모리에 저장될 수 있음은 물론이다. 신경망 연산 처리시 입력 데이터는 호스트로부터 가속기로 제공되고, 가중치는 호스트로부터 메모 리 모듈(300-1~300-N)의 기 설정된 위치에 저장될 수 있다, 가속기는 메모리 모듈(300-1~300-N)로부터 가 중치를 리드하여 입력 데이터와 함께 연산하고, 이에 따라 갱신된 가중치는 메모리 모듈(300-1~300-n)의 동일 위치에 다시 저장되어, 후속되는 연산에 이용될 수 있다. 일 실시예에서, 호스트는 특정 어플리케이션에 대한 연산 처리를 데이터 처리 시스템으로 오프로드하 기 위해 오프로드하여 처리할 연산의 어플리케이션 종류, 어플리케이션의 프로그램 코드 저장 주소, 초기 파라 미터 저장 주소, 파라미터의 저장 방식을 포함하는 제어 정보(CON)를 전송할 수 있다. 프로세서는 프로그램 코드 저장 주소에 접근하여 예를 들어 RAM에 프로그램 코드를 로딩하며, 가속 기는 프로그램 코드 실행하여 연산을 처리하며, 연산 처리 결과를 메모리 장치에 저장할 수 있다. 일 실시예에서, 가속기는 각각 입력 노드 ID를 갖는 복수의 입력 데이터와 각각 복수의 가중치로 구성된 복수의 가중치 셋을 제공받아, 입력 데이터와 가중치 셋을 연산하여 각각 출력 노드 ID를 갖는 복수의 출력 데이터를 생성할 수 있다. 그리고 어드레스 변환부는 연산 동작시 각각의 가중치 셋과 연관되는 입력 노드 ID 및 출력 노드 ID를 포 함하는 가중치 셋의 물리 어드레스(PA)를 제공받아 동시에 리드되는 가중치의 수가 최대가 되도록, 즉 최대의 리드 대역폭이 보장되도록 호스트의 물리 어드레스를 메모리 어드레스(MA)에 맵핑하여 메모리 어드레스(M A)에 대응하는 메모리 영역에 가중치 셋을 저장할 수 있다. 도 2에는 어드레스 변화부를 프로세서와 별도로 도시하였으나, 어드레스 변환부를 프로세서 내부에 포함하도록, 즉 프로세서가 어드레스 변환부의 기능을 수행할 수 있도록 구성될 수 있 음은 물론이다. 호스트가 데이터 처리 시스템으로 오프로드 처리 요청한 연산의 어플리케이션은 높은 대역폭을 요구하 는 기계학습 어플리케이션, 빅데이터 처리에 특화된 어플리케이션일 수 있다. 이러한 어플리케이션의 실행에 사용되는 데이터들을 메모리 장치에 라이트 또는 리드하기 위하여 신경망 알고리즘의 가중치 사용 방식 및 파라미터 저장 방식을 고려하여 가중치를 저장함에 따라 최대의 대역폭으로 가중치를 리드하므로 리드 레이턴시 를 최소화할 수 있다. 도 3은 일 실시예에 의한 어드레스 변환부의 구성도이다. 도 3을 참조하면, 어드레스 변환부는 어드레스 추출부, 선택 신호 생성부 및 어드레스 맵핑부 를 포함할 수 있다. 어드레스 추출부는 호스트로부터 제공되는 물리 어드레스(PA)로부터 입력 노드 ID(IID) 및 출력 노드 ID(OID)를 추출할 수 있다. 일 실시예에서, 물리 어드레스(PA)는 연산 동작시 각각의 가중치 셋과 연산되는 입 력 데이터를 지시하는 입력 노드 ID 및 연산 결과로 생성된 출력 데이터를 지시하는 출력 노드 ID를 포함하도록 생성될 수 있고, 어드레스 추출부는 물리 어드레스(PA)로부터 입력 노드 ID(IID) 및 출력 노드 ID(OID)를 추출할 수 있다. 이를 위해 호스트는 입력 노드 ID(IID)에 대응하는 제 1 물리 어드레스 및 출력 노드 ID(OID)에 대응하는 제 2 물리 어드레스를 포함하는 가상 어드레스를 생성할 수 있다. 선택 신호 생성부는 호스트로부터 전송되는 제어정보(CON)에 포함된 어플리케이션 종류에 따른 가중치 재사용 방식(WS) 및 파라미터 저장 방식(PS)에 기초하여 선택 신호(SEL)를 생성하도록 구성될 수 있다. 어드레스 맵핑부는 입력 노드 ID(IID) 및 출력 노드 ID(OID)를 제공받으며 선택 신호(SEL)에 따라 구동되 어 동시에 리드되는 가중치의 수가 최대가 되도록 물리 어드레스(PA)를 메모리 어드레스(MA)에 맵핑할 수 있다. 메모리 어드레스(MA)는 어드레스를 변경하면서 액세스할 때 제 1 레이턴시를 갖는 제 1 메모리 어드레스와, 어 드레스를 변경하면서 액세스할 때 제 1 레이턴시보다 큰 제 2 레이턴시를 갖는 제 2 메모리 어드레스를 포함하 며, 어드레스 맵핑부는 연산에 사용되는 복수의 가중치 셋의 물리 어드레스 중 변경 빈도가 높은 ID의 물 리 어드레스를 제 1 메모리 어드레스에 맵핑할 수 있다. 어드레스를 변경하면서 액세스하여 데이터를 리드할 때 리드 속도가 상대적으로 빠른 메모리 어드레스를 자주 변경되는 물리 어드레스에 맵핑시킴에 따라 리드 속도 를 향상시킬 수 있다. 예를 들어 도 1에 도시한 메모리 장치에 대해 호스트는 메모리 장치 각각의 세부 영역(뱅크 그룹, 뱅크, 로우, 컬럼)을 지시하는 어드레스(뱅크 그룹 어드레스, 뱅크 어드레스, 컬럼 어드레스, 로우 어드 레스)를 포함하는 메모리 어드레스를 생성하여 메모리 장치의 타겟 위치에 접근할 수 있다. 메모리 장치 에 접근시 선행하여 접근한 뱅크 그룹과 다른 뱅크 그룹에 접근하는 경우(뱅크 그룹 어드레스가 변경되는 경우), 동일 뱅크 그룹의 동일 뱅크 내 동일한 로우에 접근하는 경우, 동일 뱅크 그룹의 다른 뱅크에 접근하는 경우(뱅크 어드레스가 변경되는 경우), 동일 뱅크 그룹의 동일 뱅크에서 다른 로우에 접근하는 경우(로우 어드 레스만 변경되는 경우) 순으로 레이턴시가 증가할 수 있다. 표로 정리하면 다음과 같다. 표 1 레이턴시 순위 Bank Group Bank Row AC parameter [ns] 1 different - - tRRD_S or tCCD_S = 4ns 2 same same same tCCD_L = 6 3 same different - tRRD_L = 6, (tFAW) 4 same same differenttRC = 50따라서, 물리 어드레스(PA)를 구성하는 입력 노드 ID(IID) 및 출력 노드 ID(OID) 중 변화 빈도가 높은 ID를 메 모리 어드레스에 맵핑하되, 어드레스를 변경하면서 액세스하여도 레이턴시가 보장되는 세부 영역의 어드레스에 맵핑 시키면, 가중치를 리드하는 데 소요되는 시간을 단축시킬 수 있다. 도 4는 일 실시예에 의한 어드레스 맵핑부의 구성도이다. 도 4를 참조하면, 어드레스 맵핑부는 제 1 선택부, 제 2 선택부 물리-메모리 어드레스(PMA) 변 환부를 포함할 수 있다. 제 1 선택부는 입력 노드 ID(IID) 및 출력 노드 ID(OID)를 입력받고, 선택 신호(SEL)에 응답하여 구동되어 입력 신호 중 하나를 제 1 물리 선택 주소(SEL_ID1)로 출력할 수 있다. 제 2 선택부는 입력 노드 ID(IID) 및 출력 노드 ID(OID)를 입력받고, 선택 신호(SEL)에 응답하여 구동되어 입력 신호 중 하나를 제 1 물리 선택 주소(SEL_ID1)로 출력할 수 있다. PMA 변환부는 제 1 물리 선택 주소(SEL_ID1) 및 제 2 물리 선택 주소(SEL_ID2)를 입력받아, 제 1 물리 선 택 주소(SEL_ID1)를 제 1 메모리 어드레스(제 1 MA)에 맵핑시키고, 제 2 물리 선택 주소(SEL_ID2)를 제 2 메모 리 어드레스(제 2 MA)에 맵핑시켜, 결과적인 메모리 어드레스(MA)를 출력하도록 구성될 수 있다. 여기에서, 제 1 메모리 어드레스(제 1 MA)는 어드레스를 변경하면서 액세스할 때 제 2 레이턴시를 갖는 메모리 세부 영역의 어드레스, 예를 들어 로우 어드레스일 수 있다. 제 2 메모리 어드레스(제 2 MA)는 어드레스를 변경하면서 액세 스할 때 제 2 레이턴시보다 낮은 제 1 레이턴시를 갖는 메모리 세부 영역의 어드레스, 예를 들어 뱅크 그룹/뱅 크/컬럼 어드레스일 수 있다. 선택 신호(SEL)가 예를 들어 논리 하이 레벨로 입력될 때, 제 1 선택부로 입력되는 출력 노드 ID(OID)가 제 1 물리 선택 주소(SEL_ID1)로 출력될 수 있고, 제 1 물리 선택 주소(SEL_ID1)는 제 1 MA에 맵핑될 수 있다. 한편, 제 2 선택부로부터는 입력 노드 ID(IID)가 제 2 물리 선택 주소(SEL_ID2)로 출력되어 제 2 MA에 맵 핑될 수 있다. 선택 신호(SEL)가 논리 로우 레벨로 입력되는 경우, 제 1 선택부로 입력되는 입력 노드 ID(IID)가 제 1 물 리 선택 주소(SEL_ID1)로 출력되어 제 1 MA에 맵핑되는 한편, 제 2 선택부로 입력되는 출력 노드 ID(OID) 가 제 2 물리 선택 주소(SEL_ID2)로 출력되어 제 2 MA에 맵핑될 수 있다. 따라서, 어떠한 신경망 연산이 가중치 공유 방식인 경우 또는 입력 데이터 유지 방식인 경우에는 출력 노드 ID 의 변화 빈도가 높을 것이다. 이 경우 선택 신호(SEL)를 논리 로우 레벨로 제공하여 변화 빈도가 높은 출력 노 드 ID인 제 2 물리 선택 주소(SEL_ID2)를 제 2 MA, 예를 들어 뱅크 그룹/뱅크/컬럼 어드레스에 맵핑시킨다. 또 한, 변화 빈도가 낮은 입력 노드 ID인 제 1 물리 선택 신호(SEL_ID1)는 제 1 MA, 예를 들어 로우 어드레스에 맵 핑시키면, 어드레스 변경시 레이턴시가 증가하는 제 1 MA의 변화 빈도를 최소화할 수 있어 리드 속도를 향상시 킬 수 있다. 도 5는 일 실시예에 의한 신경망 모델을 설명하기 위한 도면이다. 도 5는 CNN 모델의 일 예시도이다. 인간은 물체를 인지할 때 픽셀 단위의 값을 수치적으로 이해하기보다 특징을 가지는 물체의 부분 또는 전체를 인지한다. CNN은 이러한 메커니즘을 수학적으로 표현한 구조로, 이미지 데이터 같은 2차원 또는 3차원 데이터 에 주로 사용될 수 있다. 일반적으로 CNN은 컨볼루션 레이어(convolution layer), 풀링 레이어(pooling layer) 및 완전연결 레이어(fully connected layer)로 구성될 수 있다. 컨볼루션 레이어는 입력 데이터의 특성을 추출하기 위한 레이어로, 특징을 추출하기 위한 필터, 필터의 간격인 스트라이드(stride), 특정값을 채워 크기를 조절해 주는 패딩(padding)으로 구성될 수 있다. 도 6 및 도 7은 컨볼루션 레이어의 연산 개념을 설명하기 위한 도면이다. 도 6을 참조하면, 컨볼루션 레이어는 입력 데이터(I0~I4) 각각에 대해 가중치 셋(WOO, WO1, WO2)을 필터로 적용 하여 출력 데이터(O0~O3)를 생성하도록 구성될 수 있다. 수학식으로 표현하면 다음과 같다. 수학식에서 각 가 중치(Wab)의 지수 a는 입력노드 ID를 나타내고 B는 출력 노드 ID를 나타낸다. 입력 데이터(I0~I4) 각각과 연산되는 가중치 셋(W00, W01, W02)이 공유되는 것을 알 수 있다. 컨볼루션 레이어에서는 가속기 내에 공유되는 가중치가 유지되므로 가중치 유지 방식이라 할 수 있다. 도 7과 같이 입력 데이터(I)가 제공될 때. 부분 입력 데이터(I11~I14) 각각에 대해 주어진 스트라이드 (stride=2)로 필터(W)를 적용하여 출력 데이터(O)를 생성할 수 있다. 부분 입력 데이터(I0~I5, I11~I14)에 적 용되는 필터(W), 즉 가중치 셋이 공유되는 것을 알 수 있다. 따라서, 컨볼루션 레이어와 같이 가중치 공유 방식을 사용하는 경우에는 변화 빈도가 높은 출력 노드 ID를 제 2 메모리 어드레스(MA)에 맵핑시키는 것이 리드 속도 측면에서 유지할 수 있다. 풀링 레이어는 컨볼루션 레이어를 통해 추출한 특징에 공간불변성(Spatial invariance) 더해주는 레이어로, 컨 볼루션 레이어의 출력을 축소하는 역할을 한다. CNN 핵심인 컨볼루션 레이어와 풀링 레이어는 신경망의 모수를 비약적으로 줄여 주어 전체 모델의 복잡도를 감 소시킨다. 완전연결 레이어는 풀링 레이어로부터 출력된 특징 추출 결과에 따라 입력 데이터를 분류하여 출력 데이터를 생 성할 수 있다. 도 8 및 도 9는 완전 연결 레이어의 연산 개념을 설명하기 위한 도면이다. 도 8을 참조하면, 완전연결 레이어는 입력 데이터(I0~I4) 각각에 대해 서로 다른 가중치 셋([W00 W10 W20 W30 W40], [W01 W11 W21 W31 W41], [W02 W12 W22 W32 W42])을 곱하여 출력 데이터(O0~O3)를 생성하도록 구성될 수 있다. 수학식으로 표현하면 다음과 같다."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "입력 데이터(I0~I4) 각각과 연산되는 가중치 셋이 공유되지 않는 것을 알 수 있다. 도 9와 같이 입력 데이터(I)가 제공될 때. 가중치(W)를 적용하여 출력 데이터(O)를 생성할 수 있다. 입력 데이 터(I)는 이전 레이어의 활성 노드이며, 이러한 입력 데이터(I)와 가중치(W)를 행렬곱하여 출력 데이터(O)가 얻 어질 수 있다. 완전연결 레이어의 연산 과정에서, 입력 데이터 유지 방식을 사용하는 경우, 즉 입력 데이터(I0~I4)를 가속기 내에 유지시키고 가중치를 변경시켜 연산하는 경우. 하기 수학식과 같이 가중치의 출력 노드 ID 변화 빈 도가 높은 것을 알 수 있다. 따라서, 완전 연결 레이어와 같이 가중치를 공유하지 않으면서 입력 데이터 유지 방식을 사용하는 경우에는 변화 빈도가 높은 출력 노드 ID를 제 2 메모리 어드레스에 맵핑시키는 것이 리드 속 도 측면에서 유지할 수 있다."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "한편, 출력 데이터 유지 방식을 사용하는 경우에는 입력 노드 ID의 변화 빈도가 높은 것을 알 수 있다."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "따라서, 완전 연결 레이어와 같이 가중치를 공유하지 않으면서 출력 데이터 유지 방식을 사용하는 경우에는 변 화 빈도가 높은 입력 노드 ID를 제 2 메모리 어드레스에 맵핑시키는 것이 리드 속도 측면에서 유지할 수 있다.도 10은 일 실시예에 의한 선택 신호 생성 방법을 설명하기 위한 도면이다. 도 3, 도 4 및 도 10을 참조하면, 선택 신호 생성부는 가중치 재사용 방식(WS) 및 파라미터 저장 방식(P S)에 기초하여 선택 신호(SEL)를 생성할 때, 가중치 재사용 방식인 경우(WS=H), 파라미터 저장 방식(PS)과 무관 하게 논리 로우 레벨의 선택 신호(SEL)를 생성할 수 있다. 가중치 재사용 방식이 아닌 경우(WS=L)에는 파라미터 저장 방식이 입력 데이터 유지 방식일 때(PS=H) 선택 신호 (SEL)를 논리 로우 레벨로 생성하고, 출력 데이터 유지 방식일 때(PS=L) 선택 신호(SEL)를 논리 하이 레벨로 생 성할 수 있다. 따라서, 어드레스 맵핑부는 선택 신호(SEL)가 논리 로우 레벨인 경우, 즉 가중치 재사용 방식인 경우나 입 력 데이터 유지 방식의 경우, 변화 빈도가 낮은 입력 노드 ID(IID)를 제 1 메모리 어드레스(로우 어드레스)에 맵핑시키고, 선택 신호(SEL)가 논리 하이 레벨인 경우, 즉 가중치를 재사용하지 않고 출력 데이터 유지 방식의 경우, 변화 빈도가 높은 출력 노드 ID(OID)를 제 1 메모리 어드레스(로우 어드레스)에 맵핑시킬 수 있다. 도 11 내지 도 13은 실시예들에 의한 어드레스 맵핑 개념을 설명하기 위한 도면이다. 도 11은 가중치 재사용 방식의 신경망 연산을 위해 입력 노드 ID(IID)와 출력 노드 ID(OID) 맵핑 개념을 나타낸 다. 도 11의 (a)와 같이 각 가중치 셋이 입력 노드 ID(IID)와 출력 노드 ID(OID)로 인덱싱될 때, 가중치 재사용 방 식의 신경망 연산을 수행하기 위해 입력 노드 ID(IID)를 제 1 MA, 어드레스를 변경하면서 액세스할 때 상대적으 로 작은 제 1 레이턴시를 갖는 제 1 MA에 맵핑하고, 출력 노드 ID(OID)는 어드레스를 변경하면서 액세스할 때 제 1 레이턴시보다 큰 제 2 레이턴시를 갖는 제 2 MA에 맵핑할 수 있다(b). 도 12는 가중치를 재사용하지 않으며 입력 데이터 유지 방식으로 연산하는 경우의 어드레스 맵핑 개념을 나타낸 다. 이 경우에도 출력 노드 ID의 변화 빈도가 높으므로 도 11의 경우와 마찬가지 맵핑 방식을 적용할 수 있다. 도 13은 가중치를 재사용하지 않으며 출력 데이터 유지 방식으로 연산하는 경우의 어드레스 맵핑 개념을 나타낸 다. 도 13의 (a)와 같이 각 가중치 셋이 입력 노드 ID(IID)와 출력 노드 ID(OID)로 인덱싱될 때, 입력 노드 ID(II D)를 어드레스를 변경하면서 액세스할 때 상대적으로 작은 큰 제 2 레이턴시를 갖는 제 2 MA에 맵핑하고, 출력 노드 ID(OID)를 제 1 MA, 어드레스를 변경하면서 액세스할 때 제 2 레이턴시보다 작은 제 1 레이턴시를 갖는 제 1 MA에 맵핑할 수 있다(b). 인공지능은 인간의 지적능력을 모방하기 위한 방법을 연구하는 분야로 컴퓨터 공학 및 반도체를 포함한 여러 분 야에 직간접적으로 많은 영향을 주고 있다. 최근 인공신경망 알고리즘과 기계학습에 대한 활발한 연구 결과로 인해, 이미지 인식, 자연어 처리 등의 정확도 는 인간 수준까지 향상되었으며, 향후 자율주행 자동차, 자동화 시스템 등의 분야에서도 높은 정확도의 인공지 능 기술이 실현될 것으로 예측된다. 인공지능 알고리즘을 처리하는 데 있어서, 본 기술에서와 같이 연산 과정에서 반복적으로 사용하는 가중치를 고 속으로 리드하여 데이터 처리 장치의 전력 효율을 증대시킬 수 있다. 도 14 내지 도 16는 실시예들에 의한 적층형 반도체 장치의 구성도이다. 도 14은 일 실시예에 의한 적층형 반도체 장치의 구성도이다. 일 실시예에 의한 적층형 반도체 장치는 복수의 다이가 적층된 적층 구조체를 포함할 수 있다. 적층 구조체는 복수의 다이를 적층하고, 관통 전극(TSV, Through Silicon Via)을 통해 전기적으로 연결시킴으로 써 입/출력 유닛의 수를 늘려 대역폭(Bandwidth)을 증가시킨 HBM(High Bandwidth Memory) 형태로 구성될 수 있 다. 적층 구조체는 베이스 다이(Base Die) 및 복수의 코어 다이(Core Die)를 포함할 수 있다. 복수의 코어 다이는 베이스 다이 상에 적층될 수 있으며, 관통 전극(TSV)을 통해 서로 연결될 수 있 다. 코어 다이 각각에는 데이터를 저장하기 위한 메모리 셀들 및 메모리 셀의 코어 동작을 위한 회로들이 배치될 수 있다.코어 다이는 관통전극(TSV)을 통해 베이스 다이와 전기적으로 접속되어, 관통전극(TSV)을 통해 베이 스 다이로부터 신호 및 전원 등을 제공받을 수 있다. 베이스 다이는 예를 들어 도 1 내지 도 4에 도시한 것과 같은 컨트롤러를 포함할 수 있다. 베이스 다이는 적층형 반도체 장치 내의 다양한 기능, 예를 들어, 메모리 셀들의 부분적 활성화를 통한 전력 관리 기능 혹은 코어 다이와 베이스 다이 간의 타이밍조절 기능들을 수행할 수 있다. 베이스 다이에 구비되는 물리 영역(PHY)은 어드레스, 명령어, 데이터, 제어신호 등의 입출력 영역일 수 있 다. 물리 영역(PHY)에는 적층형 반도체 장치에 요구되는 데이터 처리 속도를 만족시킬 수 있는 수만큼의 입출력 회로부가 구비될 수 있다. 그리고 베이스 다이의 배면 중 물리 영역(PHY) 부분에는 입출력 동작시 필요한 신호 및 전원을 공급받을 수 있도록 복수의 입출력 단자와 전원공급 단자가 구비될 수 있다. 도 15은 일 실시예에 의한 적층형 반도체 장치의 구성도이다. 도 15을 참조하면, 적층형 반도체 장치는 복수의 코어 다이와 베이스 다이의 적층 구조체, 메모리 호스트 및 인터페이스 기판을 포함할 수 있다. 호스트는 CPU, 또는 GPU, 또는 ASIC(Application Specific Integrated Circuit), 또는 FPGA(Field Programmable Gate Arrays) 등이 될 수 있 다. 베이스 다이는 코어 다이와 호스트 간의 인터페이스를 위한 회로가 실장될 수 있다. 적층 구조 체는 도 14을 참조하여 설명한 것과 유사한 구조를 가질 수 있다. 적층 구조체와 호스트는 인터페이스 기판을 통해 각각의 물리 영역(PHY)이 연결될 수 있다. 인 터페이스 기판은 인터포저(Interposer)가 지칭될 수 있다. 도 16는 일 실시예에 의한 적층형 반도체 장치의 구성도이다. 도 16에 도시한 적층형 반도체 장치는 도 15에 도시한 적층형 반도체 장치를 패키지 기판 상에 배치한 것으로 이해할 수 있다. 패키지 기판과 인터페이스 기판은 접속단자를 통해 전기적으로 접속될 수 있다. 인터페이스 기판 상에 도 14에 도시한 것과 같은 적층 구조체 및 호스트를 적층하고, 이를 패키 지 기판에 장착한 후 패키징함으로써 시스템 인 패키지(System In Package; SiP) 타입의 반도체 장치를 구 현할 수 있다. 도 17은 일 실시예에 의한 네트워크 시스템의 구성도이다. 도 17을 참조하면, 네트워크 시스템은 네트워크를 통해서 연결된 서버 시스템 및 복수의 클 라이언트 시스템들(5410~5430)을 포함할 수 있다. 서버 시스템은 복수의 클라이언트 시스템들(5410~5430)의 요청에 응답하여 데이터를 서비스할 수 있다. 예를 들면, 서버 시스템은 복수의 클라이언트 시스템들(5410~5430)로부터 제공된 데이터를 저장할 수 있 다. 다른 예로서, 서버 시스템은 복수의 클라이언트 시스템들(5410~5430)로 데이터를 제공할 수 있다. 서버 시스템은 호스트 장치 및 메모리 시스템을 포함할 수 있다. 메모리 시스템은 도 1 내지 도 4에 도시한 데이터 처리 시스템으로 구성될 수 있다."}
{"patent_id": "10-2019-0168892", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이와 같이, 본 발명이 속하는 기술분야의 당업자는 본 발명이 그 기술적 사상이나 필수적 특징을 변경하지 않고 서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들 은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범위는 상기 상세 한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 등가개 념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2019-0168892", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 의한 데이터 처리 시스템을 포함하는 전자 장치의 구성도이다. 도 2는 일 실시예에 의한 컨트롤러의 구성도이다. 도 3은 일 실시예에 의한 어드레스 변환부의 구성도이다. 도 4는 일 실시예에 의한 어드레스 맵핑부의 구성도이다. 도 5는 일 실시예에 의한 신경망 모델을 설명하기 위한 도면이다. 도 6 및 도 7은 컨볼루션 레이어의 연산 개념을 설명하기 위한 도면이다. 도 8 및 도 9는 완전 연결 레이어의 연산 개념을 설명하기 위한 도면이다. 도 10은 일 실시예에 의한 선택 신호 생성 방법을 설명하기 위한 도면이다. 도 11 내지 도 13은 실시예들에 의한 어드레스 맵핑 개념을 설명하기 위한 도면이다. 도 14 내지 도 16는 실시예들에 의한 적층형 반도체 장치의 구성도이다. 도 17은 일 실시예에 의한 네트워크 시스템의 구성도이다."}
