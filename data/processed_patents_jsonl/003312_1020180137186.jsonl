{"patent_id": "10-2018-0137186", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0056496", "출원번호": "10-2018-0137186", "발명의 명칭": "포즈 전이 인공지능을 이용한 가상현실 노래방 장치 및 방법", "출원인": "주식회사 더미리", "발명자": "권준언"}}
{"patent_id": "10-2018-0137186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1영상 데이터의 포즈 데이터인 제1포즈 데이터를 기초로 포즈 전이 영상 데이터를 출력하도록 학습되는 포즈전이 모듈의 프로그램 코드를 저장하는 메모리 모듈; 및상기 포즈 전이 모듈의 프로그램 코드를 처리하여 입력되는 제2영상 데이터의 포즈 데이터인 제2포즈 데이터를상기 제1영상 데이터에 전이하고 상기 포즈 전이 영상 데이터를 출력하는 처리 모듈;을 포함하고, 상기 포즈 전이 모듈의 상기 프로그램 코드는,상기 제2포즈 데이터를 수신하는 수신 단계;상기 제2포즈 데이터를 이용하여 상기 제1영상 데이터에 상기 제2포즈 데이터를 전이한 포즈 전이 영상 데이터를 생성하는 포즈 전이 단계; 및생성된 상기 포즈 전이 영상 데이터를 출력하는 출력 단계;를 포함하여 컴퓨터 상에서 수행되도록 구성되고,상기 포즈 전이 모듈은, 상기 제1포즈 데이터 및 상기 포즈 전이 영상 데이터를 Fake로 레이블링하고 상기 제1포즈 데이터 및 상기 제1영상 데이터를 Real로 레이블링하여 Fake와 Real을 구분하도록 학습되는 구분 모듈의손실 데이터인 구분 손실 데이터가 최소화 되도록 손실 함수가 구성되어 학습되고,상기 제1영상 데이터가 가상현실 노래방 사용자의 사용자 영상 데이터인 경우 상기 제2영상 데이터는 상기 가상현실 노래방 사용자가 선곡한 노래에 대응되는 기저장 영상 데이터이며, 상기 제1영상 데이터가 상기 가상현실노래방 사용자가 선곡한 노래에 대응되는 상기 기저장 영상 데이터인 경우 상기 제2영상 데이터는 상기 가상현실 노래방 사용자의 사용자 영상 데이터인 것을 특징으로 하는,포즈 전이 인공지능을 이용한 가상현실 노래방 장치."}
{"patent_id": "10-2018-0137186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 포즈 전이 모듈이, 상기 포즈 전이 영상 데이터와 상기 제1영상 데이터를 비교하는 비교 모듈의 손실 데이터인 비교 손실 데이터 및 상기 구분 손실 데이터가 최소화 되도록 손실 함수가 구성되어 학습되는,포즈 전이 인공지능을 이용한 가상현실 노래방 장치."}
{"patent_id": "10-2018-0137186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 메모리 모듈이 상기 제1포즈 데이터의 얼굴 섹션을 기초로 학습된 얼굴 각도 전이 모듈의 프로그램 코드를더 포함하고, 상기 처리 모듈이 상기 얼굴 각도 전이 모듈의 상기 프로그램 코드를 처리하여 상기 제2포즈 데이터의 얼굴 섹션의 잔차 데이터를 상기 포즈 전이 영상 데이터의 얼굴 섹션에 전이하고 얼굴 전이된 포즈 전이 영상 데이터를생성하며, 상기 얼굴 각도 전이 모듈의 상기 프로그램 코드는,공개특허 10-2020-0056496-3-상기 포즈 전이 모듈에서 생성된 상기 포즈 전이 영상 데이터를 수신하는 수신 단계;상기 제2포즈 데이터의 상기 얼굴 섹션을 이용하여 상기 잔차 데이터를 생성하고, 상기 포즈 전이 영상 데이터의 상기 얼굴 섹션에 상기 잔차 데이터를 전이하여 상기 얼굴 전이된 포즈 전이 영상 데이터의 얼굴 섹션을 생성하는 얼굴 각도 전이 단계;상기 얼굴 전이된 포즈 전이 영상 데이터의 상기 얼굴 섹션을 상기 포즈 전이 영상 데이터와 병합하여 상기 얼굴 전이된 포즈 전이 영상 데이터를 생성하는 병합 단계; 및생성된 상기 얼굴 전이된 포즈 전이 영상 데이터를 출력하는 출력 단계;를 포함하여 컴퓨터 상에서 수행되도록 구성되고,상기 얼굴 각도 전이 모듈은, 상기 제1포즈 데이터 및 상기 얼굴 전이된 포즈 전이 영상 데이터의 상기 얼굴 섹션을 Fake로 레이블링하고 상기 제1포즈 데이터 및 상기 제1영상 데이터의 얼굴 섹션을 Real로 레이블링하여Fake와 Real을 구분하도록 학습되는 얼굴 구분 모듈의 손실 데이터인 얼굴 구분 손실 데이터가 최소화 되도록손실 함수가 구성되어 학습되는,포즈 전이 인공지능을 이용한 가상현실 노래방 장치."}
{"patent_id": "10-2018-0137186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1영상 데이터의 포즈 데이터인 제1포즈 데이터를 기초로 포즈 전이 영상 데이터가 출력되도록 학습하고, 입력되는 제2영상 데이터의 포즈 데이터인 제2포즈 데이터를 상기 제1영상 데이터에 전이하고 상기 포즈 전이 영상데이터를 출력하는 포즈 전이 모듈의 프로그램 코드를 저장하는 메모리 모듈; 및상기 포즈 전이 모듈의 프로그램 코드를 처리하여 상기 제1포즈 데이터를 기초로 상기 포즈 전이 모듈을 학습하고, 상기 제2포즈 데이터를 상기 제1영상 데이터에 전이하여 상기 포즈 전이 영상 데이터를 출력하는 처리모듈;을 포함하고, 상기 포즈 전이 모듈의 상기 프로그램 코드는,상기 제1포즈 데이터를 수신하고, 상기 제1포즈 데이터 및 상기 포즈 전이 영상 데이터를 Fake로 레이블링하고상기 제1포즈 데이터 및 상기 제1영상 데이터를 Real로 레이블링하여 Fake와 Real을 구분하도록 학습되는 구분모듈의 손실 데이터인 구분 손실 데이터가 최소화 되도록 손실 함수가 구성되어 학습되는 학습 단계;상기 제2포즈 데이터를 수신하고, 상기 제2포즈 데이터를 이용하여 상기 제1영상 데이터에 상기 제2포즈 데이터를 전이한 포즈 전이 영상 데이터를 생성하는 포즈 전이 단계; 및생성된 상기 포즈 전이 영상 데이터를 출력하는 출력 단계;를 포함하여 컴퓨터 상에서 수행되도록 구성되고,상기 제1영상 데이터가 가상현실 노래방 사용자의 사용자 영상 데이터인 경우 상기 제2영상 데이터는 상기 가상현실 노래방 사용자가 선곡한 노래에 대응되는 기저장 영상 데이터이며, 상기 제1영상 데이터가 상기 가상현실노래방 사용자가 선곡한 노래에 대응되는 상기 기저장 영상 데이터인 경우 상기 제2영상 데이터는 상기 가상현실 노래방 사용자의 사용자 영상 데이터인 것을 특징으로 하는,포즈 전이 인공지능을 이용한 가상현실 노래방 장치."}
{"patent_id": "10-2018-0137186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "포즈 전이 인공지능을 이용한 가상현실 노래방 장치의 일구성인 포즈 전이 모듈이, 제1영상 데이터의 포즈 데이터인 제1포즈 데이터를 기초로 포즈 전이 영상 데이터를 출력하도록 학습되는 학습 단계;상기 포즈 전이 모듈이, 제2영상 데이터의 포즈 데이터인 제2포즈 데이터를 수신하는 수신 단계;공개특허 10-2020-0056496-4-상기 포즈 전이 모듈이, 상기 제2포즈 데이터를 이용하여 상기 제1영상 데이터에 상기 제2포즈 데이터를 전이한상기 포즈 전이 영상 데이터를 생성하는 포즈 전이 단계; 및상기 포즈 전이 모듈이, 생성된 상기 포즈 전이 영상 데이터를 상기 포즈 전이 인공지능을 이용한 가상현실 노래방 장치에 연결된 디스플레이에 출력하는 출력 단계;를 포함하여 컴퓨터 상에서 수행되도록 구성되고,상기 포즈 전이 모듈은, 상기 제1포즈 데이터 및 상기 포즈 전이 영상 데이터를 Fake로 레이블링하고 상기 제1포즈 데이터 및 상기 제1영상 데이터를 Real로 레이블링하여 Fake와 Real을 구분하도록 학습되는 구분 모듈의손실 데이터인 구분 손실 데이터가 최소화 되도록 손실 함수가 구성되어 학습되고,상기 제1영상 데이터가 가상현실 노래방 사용자의 사용자 영상 데이터인 경우 상기 제2영상 데이터는 상기 가상현실 노래방 사용자가 선곡한 노래에 대응되는 기저장 영상 데이터이며, 상기 제1영상 데이터가 상기 가상현실노래방 사용자가 선곡한 노래에 대응되는 상기 기저장 영상 데이터인 경우 상기 제2영상 데이터는 상기 가상현실 노래방 사용자의 사용자 영상 데이터인 것을 특징으로 하는,포즈 전이 인공지능을 이용한 가상현실 노래방 방법."}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 포즈 전이 인공지능을 이용한 가상현실 노래방 장치 및 방법에 관한 것이다. 이를 위하여, 제1영상 데 이터의 포즈 데이터인 제1포즈 데이터를 기초로 포즈 전이 영상 데이터를 출력하도록 학습되는 포즈 전이 모듈의 프로그램 코드를 저장하는 메모리 모듈; 및 포즈 전이 모듈의 프로그램 코드를 처리하여 입력되는 제2영상 데이 터의 포즈 데이터인 제2포즈 데이터를 제1영상 데이터에 전이하고 포즈 전이 영상 데이터를 출력하는 처리 모 듈;을 포함하고, 포즈 전이 모듈의 프로그램 코드는, 제2포즈 데이터를 수신하는 수신 단계; 제2포즈 데이터를 이용하여 제1영상 데이터에 제2포즈 데이터를 전이한 포즈 전이 영상 데이터를 생성하는 포즈 전이 단계; 및 생 성된 포즈 전이 영상 데이터를 출력하는 출력 단계;를 포함하여 컴퓨터 상에서 수행되도록 구성될 수 있다."}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 포즈 전이 인공지능을 이용한 가상현실 노래방 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존의 노래방 장치는 단순히 곡 선택, 예약, 연주 등의 기능을 구현하기 위한 정보들을 저장하고 있다. 사용자 가 기존의 노래방 장치를 이용하게 되는 경우, 사용자는 책자 또는 노래 서비스 장치의 디스플레이에 표시되는 검색 결과를 이용하여 원하는 곡을 선곡하고, 노래방 장치에 의해 출력되는 반주 및 가사 디스플레이에 의해 선 곡한 노래를 즐길 수 있게 된다. 하지만, 최근 VR(Virtual Reality), AR(Augmented Reality), MR(Mixed Reality)의 등장으로 콘텐츠 시장이 가 상현실의 경험을 극대화하는 방향으로 진보하고 있는 과정에서 이러한 기존의 노래방 장치는 더이상 사용자의 니즈를 충분히 만족시키기 어려운 실정이 되었다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 10-1868855, 주식회사 씨앤더블유커뮤니케이션, 증강현실을 이용한 음악컨 텐츠 서비스 제공방법(music content service providing method using augmented reality) (특허문헌 0002) 대한민국 등록특허 10-1267247, 에스케이플래닛 주식회사, 증강 현실을 이용한 노래방 시스템 및 장치, 이의 노래방 서비스 방법(KARAOKE APPARATUS AND KARAOKE SERVICE METHOD USING AUGMENTED REALITY MARKER-BASED)"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "하지만, 노래방 서비스에 VR, AR, MR 등 가상 현실을 제공하기 위해서는 기존의 2D 콘텐츠가 아닌 3D 콘텐츠의 제작 또는 모션 캡쳐 기술의 이용이 필요하였고, Smart Glass 등의 HUD(Head Up Display), Oculus Rift와 같은 HMD(Head Mount Display) 등이 반드시 필요한 문제가 있었다. 위와 같은 문제는 가상현실 노래방 장치를 개발및 양산하여 많은 노래방 지점에 채용하는데에 매우 큰 비용을 야기하므로, 가상현실 노래방 장치의 확산에 가 장 큰 장벽이 되고 있었다. 따라서, 본 발명의 목적은 기존에 존재하는 뮤직비디오 등의 2D 영상과 사용자의 노래방 영상이 자연스럽게 실 시간으로 합성되어 출력되는, 포즈(Pose) 전이 인공지능을 이용한 가상현실 노래방 장치 및 방법을 제공하는 데 에 있다."}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이하 본 발명의 목적을 달성하기 위한 구체적 수단에 대하여 설명한다. 본 발명의 목적은, 제1영상 데이터의 포즈 데이터인 제1포즈 데이터를 기초로 포즈 전이 영상 데이터를 출력하 도록 학습되는 포즈 전이 모듈의 프로그램 코드를 저장하는 메모리 모듈; 및 상기 포즈 전이 모듈의 프로그램 코드를 처리하여 입력되는 제2영상 데이터의 포즈 데이터인 제2포즈 데이터를 상기 제1영상 데이터에 전이하고 상기 포즈 전이 영상 데이터를 출력하는 처리 모듈;을 포함하고, 상기 포즈 전이 모듈의 상기 프로그램 코드는, 상기 제2포즈 데이터를 수신하는 수신 단계; 상기 제2포즈 데이터를 이용하여 상기 제1영상 데이터에 상기 제2 포즈 데이터를 전이한 포즈 전이 영상 데이터를 생성하는 포즈 전이 단계; 및 생성된 상기 포즈 전이 영상 데이 터를 출력하는 출력 단계;를 포함하여 컴퓨터 상에서 수행되도록 구성되고, 상기 포즈 전이 모듈은, 상기 제1포 즈 데이터 및 상기 포즈 전이 영상 데이터를 Fake로 레이블링하고 상기 제1포즈 데이터 및 상기 제1영상 데이터 를 Real로 레이블링하여 Fake와 Real을 구분하도록 학습되는 구분 모듈의 손실 데이터인 구분 손실 데이터가 최 소화 되도록 손실 함수가 구성되어 학습되고, 상기 제1영상 데이터가 가상현실 노래방 사용자의 사용자 영상 데 이터인 경우 상기 제2영상 데이터는 상기 가상현실 노래방 사용자가 선곡한 노래에 대응되는 기저장 영상 데이 터이며, 상기 제1영상 데이터가 상기 가상현실 노래방 사용자가 선곡한 노래에 대응되는 상기 기저장 영상 데이 터인 경우 상기 제2영상 데이터는 상기 가상현실 노래방 사용자의 사용자 영상 데이터인 것을 특징으로 하는, 포즈 전이 인공지능을 이용한 가상현실 노래방 장치를 제공하여 달성될 수 있다. 또한, 상기 포즈 전이 모듈이, 상기 포즈 전이 영상 데이터와 상기 제1영상 데이터를 비교하는 비교 모듈의 손 실 데이터인 비교 손실 데이터 및 상기 구분 손실 데이터가 최소화 되도록 손실 함수가 구성되어 학습될 수 있 다. 또한, 상기 메모리 모듈이 상기 제1포즈 데이터의 얼굴 섹션을 기초로 학습된 얼굴 각도 전이 모듈의 프로그램 코드를 더 포함하고, 상기 처리 모듈이 상기 얼굴 각도 전이 모듈의 상기 프로그램 코드를 처리하여 상기 제2포 즈 데이터의 얼굴 섹션의 잔차 데이터를 상기 포즈 전이 영상 데이터의 얼굴 섹션에 전이하고 얼굴 전이된 포즈 전이 영상 데이터를 생성하며, 상기 얼굴 각도 전이 모듈의 상기 프로그램 코드는, 상기 포즈 전이 모듈에서 생 성된 상기 포즈 전이 영상 데이터를 수신하는 수신 단계; 상기 제2포즈 데이터의 상기 얼굴 섹션을 이용하여 상 기 잔차 데이터를 생성하고, 상기 포즈 전이 영상 데이터의 상기 얼굴 섹션에 상기 잔차 데이터를 전이하여 상 기 얼굴 전이된 포즈 전이 영상 데이터의 얼굴 섹션을 생성하는 얼굴 각도 전이 단계; 상기 얼굴 전이된 포즈 전이 영상 데이터의 상기 얼굴 섹션을 상기 포즈 전이 영상 데이터와 병합하여 상기 얼굴 전이된 포즈 전이 영 상 데이터를 생성하는 병합 단계; 및 생성된 상기 얼굴 전이된 포즈 전이 영상 데이터를 출력하는 출력 단계;를 포함하여 컴퓨터 상에서 수행되도록 구성되고, 상기 얼굴 각도 전이 모듈은, 상기 제1포즈 데이터 및 상기 얼굴 전이된 포즈 전이 영상 데이터의 상기 얼굴 섹션을 Fake로 레이블링하고 상기 제1포즈 데이터 및 상기 제1영상 데이터의 얼굴 섹션을 Real로 레이블링하여 Fake와 Real을 구분하도록 학습되는 얼굴 구분 모듈의 손실 데이터 인 얼굴 구분 손실 데이터가 최소화 되도록 손실 함수가 구성되어 학습될 수 있다. 본 발명의 다른 목적은, 제1영상 데이터의 포즈 데이터인 제1포즈 데이터를 기초로 포즈 전이 영상 데이터가 출 력되도록 학습하고, 입력되는 제2영상 데이터의 포즈 데이터인 제2포즈 데이터를 상기 제1영상 데이터에 전이하 고 상기 포즈 전이 영상 데이터를 출력하는 포즈 전이 모듈의 프로그램 코드를 저장하는 메모리 모듈; 및 상기 포즈 전이 모듈의 프로그램 코드를 처리하여 상기 제1포즈 데이터를 기초로 상기 포즈 전이 모듈을 학습하고, 상기 제2포즈 데이터를 상기 제1영상 데이터에 전이하여 상기 포즈 전이 영상 데이터를 출력하는 처리 모듈;을 포함하고, 상기 포즈 전이 모듈의 상기 프로그램 코드는, 상기 제1포즈 데이터를 수신하고, 상기 제1포즈 데이 터 및 상기 포즈 전이 영상 데이터를 Fake로 레이블링하고 상기 제1포즈 데이터 및 상기 제1영상 데이터를 Real 로 레이블링하여 Fake와 Real을 구분하도록 학습되는 구분 모듈의 손실 데이터인 구분 손실 데이터가 최소화 되도록 손실 함수가 구성되어 학습되는 학습 단계; 상기 제2포즈 데이터를 수신하고, 상기 제2포즈 데이터를 이용 하여 상기 제1영상 데이터에 상기 제2포즈 데이터를 전이한 포즈 전이 영상 데이터를 생성하는 포즈 전이 단계; 및 생성된 상기 포즈 전이 영상 데이터를 출력하는 출력 단계;를 포함하여 컴퓨터 상에서 수행되도록 구성되고, 상기 제1영상 데이터가 가상현실 노래방 사용자의 사용자 영상 데이터인 경우 상기 제2영상 데이터는 상기 가상 현실 노래방 사용자가 선곡한 노래에 대응되는 기저장 영상 데이터이며, 상기 제1영상 데이터가 상기 가상현실 노래방 사용자가 선곡한 노래에 대응되는 상기 기저장 영상 데이터인 경우 상기 제2영상 데이터는 상기 가상현 실 노래방 사용자의 사용자 영상 데이터인 것을 특징으로 하는, 포즈 전이 인공지능을 이용한 가상현실 노래방 장치를 제공하여 달성될 수 있다. 본 발명의 다른 목적은, 포즈 전이 인공지능을 이용한 가상현실 노래방 장치의 일구성인 포즈 전이 모듈이, 제1 영상 데이터의 포즈 데이터인 제1포즈 데이터를 기초로 포즈 전이 영상 데이터를 출력하도록 학습되는 학습 단 계; 상기 포즈 전이 모듈이, 제2영상 데이터의 포즈 데이터인 제2포즈 데이터를 수신하는 수신 단계; 상기 포즈 전이 모듈이, 상기 제2포즈 데이터를 이용하여 상기 제1영상 데이터에 상기 제2포즈 데이터를 전이한 상기 포즈 전이 영상 데이터를 생성하는 포즈 전이 단계; 및 상기 포즈 전이 모듈이, 생성된 상기 포즈 전이 영상 데이터 를 상기 포즈 전이 인공지능을 이용한 가상현실 노래방 장치에 연결된 디스플레이에 출력하는 출력 단계; 를 포 함하여 컴퓨터 상에서 수행되도록 구성되고, 상기 포즈 전이 모듈은, 상기 제1포즈 데이터 및 상기 포즈 전이 영상 데이터를 Fake로 레이블링하고 상기 제1포즈 데이터 및 상기 제1영상 데이터를 Real로 레이블링하여 Fake 와 Real을 구분하도록 학습되는 구분 모듈의 손실 데이터인 구분 손실 데이터가 최소화 되도록 손실 함수가 구 성되어 학습되고, 상기 제1영상 데이터가 가상현실 노래방 사용자의 사용자 영상 데이터인 경우 상기 제2영상 데이터는 상기 가상현실 노래방 사용자가 선곡한 노래에 대응되는 기저장 영상 데이터이며, 상기 제1영상 데이 터가 상기 가상현실 노래방 사용자가 선곡한 노래에 대응되는 상기 기저장 영상 데이터인 경우 상기 제2영상 데 이터는 상기 가상현실 노래방 사용자의 사용자 영상 데이터인 것을 특징으로 하는, 포즈 전이 인공지능을 이용 한 가상현실 노래방 방법을 제공하여 달성될 수 있다."}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같이, 본 발명에 의하면 이하와 같은 효과가 있다. 첫째, 본 발명의 일실시예에 따르면, 값비싼 3D 콘텐츠나 모션 캡쳐 기술을 이용한 콘텐츠를 별도로 제작하지 않아도 기존의 2D 콘텐츠를 이용하여 충분히 가상 현실을 제공할 수 있게 되는 효과가 발생된다. 둘째, 본 발명의 일실시예에 따르면, 뮤직 비디오 등의 기저장 영상 데이터에서 해당 가수의 안무를 실시간으로 따라하는 가상 현실 영상을 제공할 수 있게 되는 효과가 발생된다. 셋째, 본 발명의 일실시예에 따르면, 뮤직 비디오 등의 기저장 영상 데이터에서 해당 가수가 사용자의 안무를 실시간으로 따라하는 가상 현실 영상을 제공할 수 있게 되는 효과가 발생된다."}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작원리를 상세하게 설명함에 있 어서 관련된 공지기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 특정 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 특정 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 포즈 전이 인공지능을 이용한 가상현실 노래방 장치 및 방법 가상현실 노래방의 전체 구성과 관련하여, 도 1은 본 발명의 일실시예에 따른 가상현실 노래방의 전체 구성을 도시한 모식도이다. 도 1에 도시된 바와 같이, 본 발명의 일실시예에 따른 가상현실 노래방은 카메라, 마이크, TV, 모니터, HUD, HMD 등을 포함하는 디스플레이, 포즈(Pose) 전이 인공지능을 이용한 가상현 실 노래방 장치를 포함할 수 있다. 포즈 전이 인공지능을 이용한 가상현실 노래방 장치는 카메라에서 사용자 영상 데이터을 수신할 수 있고, 마이크에서 사용자 음성 데이터를 수신할 수 있으며, 디스플레이에 포즈가 전이된 영상인 포즈 전이 영상 데이터를 송신하여 출력할 수 있다. 포즈 전이 인공지능을 이용한 가상현실 노래방 장치와 관련하여, 도 2는 본 발명의 일실시예에 따른 포즈 전 이 인공지능을 이용한 가상현실 노래방 장치를 도시한 모식도이다. 도 2에 도시된 바와 같이, 본 발명의 일실시 예에 따른 포즈 전이 인공지능을 이용한 가상현실 노래방 장치는 포즈 추정 모듈, 포즈 표준화 모듈, 포즈 전이 모듈를 포함할 수 있다. 포즈 전이 인공지능을 이용한 가상현실 노래방 장치는 사용자 영상 데이터, 사용자 음성 데이터, 기저장 영상 데이터를 수신하고, 포즈 전이 영상 데이터를 디스플레이에 출력하도록 구성될 수 있 다. 사용자 영상 데이터는 카메라에 의해 촬영되어 생성되는 가상현실 노래방 내에서의 사용자의 영상 을 의미할 수 있다. 본 발명의 범위는 가상현실 노래방에 한정되지 않으며 카메라는 스마트폰 카메라를 활 용하는 경우를 포함할 수 있다. 사용자 음성 데이터는 마이크에 의해 송신되는 사용자의 음성을 의미 할 수 있다. 또한, 본 발명의 범위는 가상현실 노래방에 한정되지 않으며 마이크는 스마트폰 마이크를 활용 하는 경우를 포함할 수 있다. 기저장 영상 데이터는 뮤직비디오나 공연 영상과 같은 사용자의 선곡에 대응 되는 영상을 의미할 수 있다. 포즈 추정 모듈은 사용자 영상 데이터 또는 기저장 영상 데이터를 수신하여 사람의 포즈(Pose)를 디텍션하고 관절 정보를 추정(estimate)하여 벡터화된 스켈레톤 정보인 포즈 데이터를 생성하는 구성이다. 본 발명의 일실시예에 따른 포즈 추정 모듈은 사람 이미지와 관절 및 스켈레톤 이미지를 통하여 SupervisedLearning 또는 Unsupervised Learning으로 기학습된 인공신경망으로 구성될 수 있다. 포즈 추정 모듈의 구체적인 구성과 관련하여, 본 발명의 일실시예에 따른 포즈 추정 모듈은 신체부위 검 출 모듈, 관계 추정 모듈로 구성될 수 있다. 본 발명의 일실시예에 따른 신체부위 검출 모듈은 연속된 복수개의 Convolutional Network으로 구성될 수 있으며 신체부위의 위치가 예측된 2D Confidence map을 출력할 수 있다. 본 발명의 일실시예에 따른 관계 추정 모듈은 연속된 복수개의 Convolutional Network으로 구성될 수 있으며 신 체부위 사이의 관계에 대한 벡터인 2D 관계 벡터를 출력할 수 있다. 신체부위 검출 모듈 및 관계 추정 모듈과 관련하여, 본 발명의 일실시예에 따르면 사용자 영상 데이터 또는 기 저장 영상 데이터를 Fine-tuned 된 10 Layer의 VGG-19 ConvNet(Convolutional Neural Network)에 입력한 뒤 한 세트의 Feature Map(F)을 생성하여 신체부위 검출 모듈 및 관계 추정 모듈에 입력되게 된다. F에는 각 신체부위 에 대한 바운딩 박스가 구성되게 된다. 신체부위 검출 모듈은 F를 입력값으로 하여 각 신체부위에 대한 바운딩 박스에 대해 특정 label(예를 들어, Right hand, Right shoulder 등)에 대응되는 Confidence 값을 예측하는 한 세트의 Detection Confidence Map(S)을 출력하게 된다. 1차 단계에서 신체부위 검출 모듈의 S 출력에 대한 수학식은 아래와 같다. 수학식 1"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위 수학식 1에서 S는 신체부위 검출 모듈에 의해 출력되는 Detection Confidence Map을 의미하고, S1는 1차 단 계의 Detection Confidence Map를 의미한다. 또한, F는 1차 단계의 신체부위 검출 모듈에 입력되는 사용자 영상 데이터 또는 기저장 영상 데이터의 Feature Map을 의미한다. ρ1은 1차 단계의 신체부위 검출 모듈의 ConvNet의 inference를 의미한다. 관계 추정 모듈은 F를 입력값으로 하여 각 신체부위에 대한 관계 벡터(예를 들어, A 포인트와 B 포인트를 연결 하는 벡터로서, 각 포인트의 신체부위 상의 가까움에 대응되는 값)를 예측하는 한 세트의 관계 필드(L)을 출력 하게 된다. 1차 단계에서 관계 추정 모듈의 L 출력에 대한 수학식은 아래와 같다. 수학식 2"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "위 수학식 2에서 L은 관계 추정 모듈에 의해 출력되는 복수개의 관계 벡터를 포함하는 관계 필드를 의미하고, L1 는 1차 단계의 관계 필드를 의미한다. 또한, F는 1차 단계의 신체부위 검출 모듈에 입력되는 사용자 영상 데이 터 또는 기저장 영상 데이터의 Feature Map을 의미한다. φ1은 1차 단계의 관계 추정 모듈의 ConvNet의 inference를 의미한다. 1차 단계에서 신체부위 검출 모듈 및 관계 추정 모듈에 의해 출력되는 예측치인 S와 L은 최초에 입력된 Feature map인 F와 함께 2차 단계 이후의 신체부위 검출 모듈 및 관계 추정 모듈에 입력되어 아래 수학식과 같이 신체부 위 검출 및 각 신체부위의 관계 예측의 정확도를 향상시키는데 이용되게 된다. 수학식 3"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 4"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "위 수학식 3에서 S는 신체부위 검출 모듈에 의해 출력되는 Detection Confidence Map을 의미하고, St는 t차 단 계의 Detection Confidence Map를 의미하고, St-1는 1차 단계의 Detection Confidence Map, Lt-1는 1차 단계의 관계 필드를 의미한다. 또한, F는 1차 단계의 신체부위 검출 모듈에 입력되는 사용자 영상 데이터 또는 기저장 영상 데이터의 Feature Map을 의미한다. ρt은 t차 단계의 신체부위 검출 모듈의 ConvNet의 inference를 의미한 다. 위 수학식 4에서 L은 관계 추정 모듈에 의해 출력되는 복수개의 관계 벡터를 포함하는 관계 필드를 의미하고, Lt 는 t차 단계의 관계 필드를 의미하고, St-1는 1차 단계의 Detection Confidence Map, Lt-1는 1차 단계의 관계 필 드를 의미한다. 또한, F는 1차 단계의 신체부위 검출 모듈에 입력되는 사용자 영상 데이터 또는 기저장 영상 데 이터의 Feature Map을 의미한다. φt은 t차 단계의 관계 추정 모듈의 ConvNet의 inference를 의미한다. 본 발명의 일실시예에 따르면, 신체부위 검출 및 관계 필드의 예측의 정확도를 향상시키기 위해 각 단계의 신체 부위 검출 모듈 및 관계 추정 모듈 각각의 출력값에 대해 각각 Loss Function을 적용할 수 있고, 단계가 진행될 수록 신체부위 검출 모듈 및 관계 추정 모듈 각각의 정확도가 향상되도록 학습시킬 수 있다. 본 발명의 일실시 예에 따라 각 단계의 신체부위 검출 모듈 및 관계 추정 모듈 각각의 출력값에 대해 각각 Loss Function을 적용 하는 경우 주기적으로 gradient가 보충되게 되므로 vanishing gradient problem이 해소되는 효과가 발생된다. 신체부위 검출 모듈 및 관계 추정 모듈의 Loss function은 아래와 같이 구성될 수 있다. 수학식 5"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 6"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "위 수학식 5,6에서, fst는 신체부위 검출 모듈의 t 단계에서의 Loss function, fLt는 관계 추정 모듈의 t 단계에 서의 Loss function을 의미한다. 각각의 손실함수에서 *는 Ground truth를 의미한다. 즉, Sj*는 S의 Ground truth, Lc*는 관계 필드 L의 Ground truth를 의미한다. p는 특정 위치, 즉 특정 신체부위를 의미한다. W는 바이 너리 마스크로서 특정 위치 p에 레이블이 있는 경우에는 1, 특정 위치 p에 레이블이 없는 경우에는 0의 값을 갖 도록 구성될 수 있다. 이러한 바이너리 마스크는 신체부위 검출 모듈 및 관계 추정 모듈의 학습 과정에서의 불 이익을 최소화하는 효과를 가져온다. 포즈 표준화 모듈은 포즈 추정 모듈에서 생성된 포즈 데이터의 발목 관절과 같은 특정 관절 위치와 스켈 레톤 정보의 높이를 표준화하여 표준화된 포즈 데이터를 생성하는 구성이다. 서로 다른 영상 데이터인 사용자 영상 데이터와 기저장 영상 데이터에서 피사체의 사지 비율이 상이하거나, 카메라와의 거리 및 배율이 상이한 문제가 발생된다. 본 발명의 일실시예에 따른 포즈 표준화 모듈은 각 피사체의 포즈에 대한 높이와 발목 위 치를 분석하고 사용자 영상 데이터와 기저장 영상 데이터 사이의 가장 가까운 발목 위치와 가장 먼 발목 위치 사이의 선형 매핑을 사용한다. 이 통계를 수집 한 후에는 해당 포즈 감지를 기반으로 각 프레임의 크기와 변환 을 계산한다. 포즈 표준화 모듈은 이러한 방식으로 포즈를 표준화하여 표준화된 포즈 데이터를 생성하고, 포 즈 전이 모듈에 송신하게 된다. 포즈 전이 모듈은 포즈 표준화 모듈에서 표준화된 포즈 데이터를 수신하고, 사용자 영상 데이터 및 상기 사용자 영상 데이터의 표준화된 포즈 데이터로 학습되고 기저장 영상 데이터의 표준화된 포즈 데이터로 포즈 전이 영상 데이터를 출력하는 구성이다. 이러한 경우, 기저장 영상 데이터에서 출력되 는 특정 가수의 안무가 상기 사용자 영상 데이터에 전이되는 형태로 포즈 전이 영상 데이터가 출력되 게 된다. 본 발명의 일실시예에 따른 포즈 전이 모듈은 인코더와 디코더로 구성된 제너레이터를 포함하여 포즈 전이 영상 데이터를 생성할 수 있고, 본 발명의 일실시예에 따르면 포즈 전이 모듈의 인코더는 256x256x3의 표준화된 포즈 데이터를 수신하여 1x1x512의 잠재변수로 인코딩하는 복수개의 연속된 ConvNet으로 구성될 수 있 으며, 포즈 전이 모듈의 디코더는 1x1x512의 잠재변수를 256x256x3의 영상 데이터로 출력하도록 디코딩하는 복수개의 연속된 네트워크로 구성될 수 있다. 또한, 본 발명의 일실시예에 따른 포즈 전이 모듈은 Training 단계에서 포즈 전이 영상 데이터의 Real과 Fake를 구분하는 구분 모듈과 함께 학습될 수 있다. 포즈 전이 모듈은 구분 모듈과 minimax game 을 구성하도록 Loss function이 구성될 수 있고, 동시에 학습될 수 있다. 또한, 본 발명의 일실시예에 따른 구 분 모듈은 사용자 영상 데이터, 포즈 전이 영상 데이터, 표준화된 포즈 데이터를 수신하고, CONCAT 함수와 복수개의 인코더를 통해 포즈 전이 영상 데이터에 대해 Real과 Fake를 구분할 수 있다. 이하 수학식은 포즈 전이 모듈과 구분 모듈의 Loss fucntion을 기재한 것이다. 수학식 7"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "위 수학식 7에서 G는 포즈 전이 모듈, D는 구분 모듈을 의미하며, x는 입력되는 표준화된 포즈 데이터, y는 영상 데이터(사용자 영상 데이터 또는 기저장 영상 데이터), G(x)는 포즈 전이 영상 데이터를 의미한다. 따 라서, 수학식 7에 따르면 포즈 전이 모듈 및 구분 모듈의 Loss function은, 포즈 전이 모듈이 충분 히 학습되지 않아서 구분 모듈이 표준화된 포즈 데이터 x를 통해 y와 G(x)를 완벽하게 구분해내는 경우에 는 D(x,y)=1, D(x,G(x))=0에 의해 0의 max 값을 갖고, 포즈 전이 모듈의 학습 후에 구분 모듈이 표준 화된 포즈 데이터 x를 통해 y와 G(x)를 구분해내지 못하는 경우 D(x,y)=1/2, D(x,G(x))=1/2에 의해 -log4의 min 값을 갖는다. 즉, 위 Loss function에 의해 포즈 전이 모듈이 표준화된 포즈 데이터 x를 통해 생성한 포 즈 전이 영상 데이터 G(x)와 사용자 영상 데이터 또는 기저장 영상 데이터인 입력 영상 데이터인 y가 동일할 때, 포즈 전이 모듈은 Global minimum을 갖게 되고, 이러한 방향으로 포즈 전이 모듈 및 구분 모듈이 학습되게 된다. 또한, 포즈 전이 모듈은 반대로 기저장 영상 데이터 및 상기 기저장 영상 데이터의 표준화된 포즈 데이터로 학습되고 사용자 영상 데이터의 표준화된 포즈 데이터로 포즈 전이 영상 데이터를 출력할 수 있다. 이러한 경우, 사용자 영상 데이터로 입력되는 사용자의 안무가 상기 기저장 영상 데이터에 전 이되는 형태로 포즈 전이 영상 데이터가 출력되게 된다. 사용자 영상 데이터에 기저장 영상 데이터의 포즈가 전이되는 포즈 전이 인공지능을 이용한 가상현실 노래방 방 법과 관련하여, 트레이닝(Training) 단계, 포즈 전이(Pose Transfer) 단계, 포즈 전이 영상 데이터 출력 단계를 포함할 수 있다. 트레이닝 단계는 포즈 전이 모듈이 사용자 영상 데이터로 트레이닝 되는 단계를 의미하며, 포즈 전이 단계는 포즈 전이 모듈에 기저장 영상 데이터가 입력되어 해당 영상의 포즈를 사용자 영상 데이터 에 전이하는 단계를 의미한다. 포즈 전이 영상 데이터 출력 단계는 생성된 포즈 전이 영상 데이터를 디스플레이 에 출력하는 단계를 의미한다. 포즈 전이 모듈의 트레이닝(Training) 단계와 관련하여, 도 3은 포즈 전이 모듈의 Training 단계를 도시한 모식도이다. 도 3에 도시된 바와 같이, 사용자의 선곡 이전 또는 이후에 사용자 영상 데이터가 카메라(1 1)를 통해 포즈 전이 인공지능을 이용한 가상현실 노래방 장치에 입력되게 되면, 포즈 추정 모듈과 포즈 표준화 모듈을 통해 표준화된 포즈 데이터가 생성되게 된다. 생성된 표준화된 포즈 데이터는 포즈 전이 모듈에 입력되고 포즈 전이 모듈은 표준화된 포즈 데이터를 토대로 포즈 전이 영상 데이터 를 생성하도록 구성된다. 이때, 포즈 전이 모듈에는 예를 들어, VGGNet과 같은 ConvNet 으로 구성된 구분 모 듈이 함께 구성될 수 있는데, 구분 모듈에는 표준화된 포즈 데이터와 생성된 포즈 전이 영상 데 이터가 Fake로 레이블링(Labeling)되어 입력되고, 표준화된 포즈 데이터와 사용자 영상 데이터가 Real로 레이블링되어 입력된 뒤, 구분 모듈이 Fake data와 Real data로 Supervised Learning 되도록 구성 될 수 있다. 즉, 본 발명의 일실시예에 따른 구분 모듈은 포즈 전이 모듈에서 생성되는 포즈 전이 영상 데이터 를 Fake 와 Real로 분류하여 Loss data를 생성하게 된다. 구분 모듈에서 출력되는 손실 데이터(Loss data)는 포즈 전이 모듈을 학습하는 손실함수(Loss function)에 이용되게 되고, 포즈 전이 모듈은 구분 모듈의 손실 데이터를 최소로 하도록 학습되게 된다. 이러한 과정에서 포즈 전이 모듈은 표준화된 포즈 데이터를 토대로 사용자 영상 데이터와 유사한 배경, 유사한 의상 및 유사한 포즈로 포즈 전이 영상 데이터를 생성하도록 학습되게 되며 구분 모듈이 Fake 와 Real을 구분하기 어렵도록 학습되게 된다. 동시에 구분 모듈은 Fake로 레이블링 된 데이터와 Real로 레이블링 된 데이터를 통해 Fake(포즈 전이 영상 데이터)와 Real(사용자 영상 데이터)를 더 잘 구분하도록 지도학습 되기 때문에 포즈 전이 모듈과 구분 모듈 은 상호 적대적 의존관계를 가지며 학습되게 된다. 포즈 전이 모듈과 구분 모듈은 상호 적대적 의 존 관계에 의해 포즈 전이 모듈을 빠르게 최적화 할 수 있는 효과가 발생된다. 본 발명의 일실시예에 따르면, 각각의 가상현실 노래방 사용자의 개인 정보가 포즈 전이 인공지능을 이용한 가 상현실 노래방 장치 또는 그 데이터베이스에 저장되고, 가상현실 노래방 사용자의 개인정보와 함께 해당 사용자 의 포즈에 대응되는 포즈 전이 모듈이 기학습되어 포즈 전이 인공지능을 이용한 가상현실 노래방 장치 또는 그 데이터베이스에 저장될 수 있다. 이에 따르면, 사용자가 1회만 포즈 전이 모듈을 학습시켜놓으면 향후에 는 포즈 전이 모듈의 학습 없이 가상현실 노래방 서비스를 이용할 수 있게 되는 효과가 발생된다."}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "포즈 전이 모듈을 이용하여 포즈를 전이하는 포즈 전이(Pose Transfer) 단계와 관련하여, 도 4는 포즈 전이 모듈의 Transfer 단계를 도시한 모식도이다. 도 4에 도시된 바와 같이, 사용자의 선곡 이후에 기저장 영상 데이 터가 데이터베이스 또는 외부 웹서버, 스트리밍 서버 등을 통해 포즈 전이 인공지능을 이용한 가상현실 노 래방 장치에 입력되게 되면, 포즈 추정 모듈과 포즈 표준화 모듈을 통해 기저장 영상 데이터의 표준화된 포즈 데이터가 생성되게 된다. 생성된 표준화된 포즈 데이터는 포즈 전이 모듈에 입력되고 포즈 전이 모듈은 표준화된 포즈 데이터를 토대로 기저장 영상 데이터의 포즈가 사용자 영상 데이터에 전이된 포즈 전이 영상 데이터를 생성하도록 구성된다. 도 5는 본 발명의 일실시예에 따른 포즈 전이 인공지능을 이용한 가상현실 노래방 장치를 이용하여 사용자 영상 데이터에 기저장 영상 데이터의 포즈가 전이되는 것을 도시한 모식도이다. 도 5에 도시된 바와 같이, 사용자의 선곡 이전 또는 이후에 사용자 영상 데이터가 입력(①Training Input)되어 포즈 전이 모듈를 학습시키 고, 포즈 전이 모듈이 충분히 학습된 이후에 뮤직 비디오와 같은 기저장 영상 데이터가 입력(② Transfer Input)되어 사용자 영상 데이터로 학습된 포즈 전이 모듈에 입력되고, 포즈 전이 모듈이 기저장 영상 데이터를 기초로 생성된 표준화된 포즈 데이터를 이용하여 기저장 영상 데이터의 가수 또는 연예인의 포즈가 사용자 영상 데이터에 전이되는 형태의 포즈 전이 영상 데이터로 생성되어 디스플레 이에 출력(③Transfer Output)되게 된다. 도 5에 도시된 바와 같이, 디스플레이에 포즈 전이 영상 데이 터가 출력되는 경우, 디스플레이의 일측에 PIP(Picture In Picture) 디스플레이가 병합 구성되어 기저장 영상 데이터를 실시간으로 출력하도록 구성될 수 있다. 이에 따르면, 사용자가 뮤직 비디오와 같은 기저장 영상 데이터와 자신의 영상인 사용자 영상 데이터에 해당 뮤직 비디오의 포즈가 전이된 형태 의 포즈 전이 영상 데이터를 함께 시청 및 비교할 수 있게 되므로, 엔터테인먼트 요소가 증대되는 효과가 발생된다. 기저장 영상 데이터에 사용자 영상 데이터의 포즈가 전이되는 포즈 전이 인공지능을 이용한 가상현실 노래방 방법과 관련하여, 트레이닝(Training) 단계, 포즈 전이(Pose Transfer) 단계, 포즈 전이 영상 데이터 출 력 단계를 포함할 수 있다. 트레이닝 단계는 포즈 전이 모듈이 기저장 영상 데이터로 트레이닝 되는 단계를 의미하며, 포즈 전이 단계는 포즈 전이 모듈에 사용자 영상 데이터가 입력되어 해당 영상의 포즈를 기저장 영상 데이터에 전이하는 단계를 의미한다. 포즈 전이 영상 데이터 출력 단계는 생성된 포즈 전이 영상 데이터를 디스플레이에 출력하는 단계를 의미한다. 포즈 전이 모듈의 트레이닝(Training) 단계와 관련하여, 도 6은 포즈 전이 모듈의 Training 단계를 도시한 모식도이다. 도 6에 도시된 바와 같이, 사용자의 선곡 이전 또는 이후에 기저장 영상 데이터가 데이터베이 스 또는 다른 웹서버, 스트리밍 서버 등을 통해 포즈 전이 인공지능을 이용한 가상현실 노래방 장치에 입력 되게 되면, 포즈 추정 모듈과 포즈 표준화 모듈을 통해 기저장 영상 데이터의 표준화된 포즈 데이터 가 생성되게 된다. 생성된 기저장 영상 데이터의 표준화된 포즈 데이터는 포즈 전이 모듈에 입 력되고 포즈 전이 모듈은 표준화된 포즈 데이터를 토대로 포즈 전이 영상 데이터를 생성하도록 구성 된다. 이때, 포즈 전이 모듈에는 예를 들어, VGGNet과 같은 ConvNet 으로 구성된 구분 모듈이 함께 구 성될 수 있는데, 구분 모듈에는 표준화된 포즈 데이터와 생성된 포즈 전이 영상 데이터가 Fake로 레이블링(Labeling)되어 입력되고, 표준화된 포즈 데이터와 기저장 영상 데이터가 Real로 레이블링되 어 입력될 수 있고, 구분 모듈은 Fake data와 Real data로 Supervised Learning 되도록 구성될 수 있다. 즉, 본 발명의 일실시예에 따른 구분 모듈은 포즈 전이 모듈에서 생성되는 포즈 전이 영상 데이터 를 Fake 와 Real로 분류하여 Loss data를 생성하게 된다. 구분 모듈에서 출력되는 손실 데이터(Loss data)는 포즈 전이 모듈을 학습하는 손실함수(Loss function)에 이용되게 되고, 포즈 전이 모듈은 구분 모듈의 손실 데이터를 최소로 하도록 학습되게 된다. 이러한 과정에서 포즈 전이 모듈은 표준화된 포즈 데이터를 토대로 기저장 영상 데이터와 유사한 배경, 유사한 의상 및 유사한 포즈로 포즈 전이 영상 데이터를 생성하도록 학습되게 되며 구분 모듈이 Fake 와 Real을 구분하기 어렵도록 학습되게 된다. 동시에 구분 모듈은 Fake로 레이블링 된 데이터와 Real로 레이블링 된 데이터를 통해 Fake(포즈 전이 영상 데이터)와 Real(기저장 영상 데이터)를 더 잘 구분하도록 지도학습 되기 때문에 포즈 전이 모듈과 구분 모듈 은 상호 적대적 의존관계를 가지며 학습되게 된다. 포즈 전이 모듈과 구분 모듈은 상호 적대적 의 존 관계에 의해 포즈 전이 모듈을 빠르게 최적화 할 수 있는 효과가 발생된다. 본 발명의 일실시예에 따르면, 각 노래에 대응되는 기저장 영상 데이터 각각에 대해 기학습된 포즈 전이 모듈이 포즈 전이 인 공지능 가상현실 노래방 장치에 구성될 수 있다. 이에 따르면, 사용자가 선곡 후 포즈 전이 모듈에 대한 별다른 학습 과정 없이 곧바로 가상현실을 경험할 수 있게 되는 효과가 발생된다. 포즈 전이 모듈을 이용하여 포즈를 전이하는 포즈 전이(Pose Transfer) 단계와 관련하여, 도 7은 포즈 전이 모듈의 Transfer 단계를 도시한 모식도이다. 도 7에 도시된 바와 같이, 사용자의 선곡 이후에 사용자 영상 데이 터가 카메라를 통해 포즈 전이 인공지능을 이용한 가상현실 노래방 장치에 입력되게 되면, 포즈 추 정 모듈과 포즈 표준화 모듈을 통해 사용자 영상 데이터의 표준화된 포즈 데이터가 생성되게 된 다. 생성된 표준화된 포즈 데이터는 포즈 전이 모듈에 입력되고 포즈 전이 모듈은 표준화된 포즈 데 이터를 토대로 사용자 영상 데이터의 포즈가 기저장 영상 데이터에 전이된 포즈 전이 영상 데이 터를 생성하도록 구성된다. 도 8은 본 발명의 일실시예에 따른 포즈 전이 인공지능을 이용한 가상현실 노래방 장치를 이용하여 기저장 영상 데이터에 사용자 영상 데이터의 포즈가 전이되는 것을 도시한 모식도이다. 도 8에 도시된 바와 같이, 사용자의 선곡 이전 또는 이후에 뮤직 비디오와 같은 기저장 영상 데이터가 입력(①Training Input)되어 포즈 전이 모듈를 학습시키고, 포즈 전이 모듈이 충분히 학습된 이후에 사용자 영상 데이터가 입력 (②Transfer Input)되어 기저장 영상 데이터로 학습된 포즈 전이 모듈에 입력되고, 포즈 전이 모듈 이 사용자 영상 데이터를 기초로 생성된 표준화된 포즈 데이터를 이용하여 사용자 영상 데이터의 사용자의 포즈가 기저장 영상 데이터에 전이되는 형태의 포즈 전이 영상 데이터로 생성되어 디스플레 이에 출력(③Transfer Output)되게 된다. 도 5에 도시된 바와 같이, 디스플레이에 포즈 전이 영상 데이 터가 출력되는 경우, 디스플레이의 일측에 PIP(Picture In Picture) 디스플레이가 병합 구성되어 기저장 영상 데이터를 실시간으로 출력하도록 구성될 수 있다. 이에 따르면, 사용자가 뮤직 비디오와 같은 기저장 영상 데이터에 자신의 영상인 사용자 영상 데이터의 포즈가 전이된 형태의 포즈 전이 영상 데 이터와 사용자 영상 데이터를 함께 시청 및 비교할 수 있게 되므로, 엔터테인먼트 요소가 증대되는 효 과가 발생된다. 본 발명의 일실시예에 따른 포즈 전이 인공지능을 이용한 가상현실 노래방 장치는 Loss Network으로 비교 모듈 을 더 포함할 수 있다. 도 9는 본 발명의 일실시예에 따라 비교 모듈을 더 포함한 포즈 전이 모듈의 Training 단계를 도시한 모식도이다. 도 9에 도시된 바와 같이, 포즈 전이 모듈의 손실함수(Loss Function) 에 비교 모듈의 손실 데이터(Loss data)가 포함될 수 있고, 포즈 전이 모듈은 구분 모듈의 손실 데이터 및 비교 모듈의 손실 데이터를 최소화하는 방향으로 학습될 수 있다. 비교 모듈의 손실 데이 터는 생성된 포즈 전이 영상 데이터와 학습 시에 입력된 사용자 영상 데이터 또는 기저장 영상 데이터 를 비교하여 포즈 전이 영상 데이터에서 학습 시에 입력된 사용자 영상 데이터 또는 기저장 영상 데이터로 회귀하는 것에 대한 손실 데이터를 의미하며, 예를 들어 VGGNet 등의 ConvNet이 이용될 수 있다. 이에 따르면, 포즈 전이 모듈의 학습이 일방향적이지 않고 양방향적으로 진행되게 되며, 이에 따라 포즈를 제외한 다른 정보들이 포즈 전이 모듈에 의해 전이되지 않게 되고, 정교하게 포즈만 전이될 수 있도록 구성 되는 효과가 발생된다. 또한, 비교 모듈의 손실 데이터가 포즈 전이 모듈의 Loss function에 포함됨으 로써 보다 고화질의 포즈 전이 영상 데이터를 생성할 수 있게 되는 효과가 발생된다. 본 발명의 일실시예에 따른 포즈 전이 인공지능을 이용한 가상현실 노래방 장치는 얼굴 각도 전이 모듈을 더 포함할 수 있다. 도 10은 본 발명의 일실시예에 따라 얼굴 각도 전이 모듈을 더 포함하는 포즈 전이 인공지능을 이용한 가상현실 노래방 장치를 도시한 모식도이다. 도 10에 도시된 바와 같이, 본 발명의 일실시예에 따른 포 즈 전이 인공지능을 이용한 가상현실 노래방 장치는 포즈 추정 모듈, 포즈 표준화 모듈, 포즈 전이 모 듈 뿐만 아니라 얼굴 각도 전이 모듈을 더 포함할 수 있다. 얼굴 각도 전이 모듈은 포즈 전이 영상 데이터를 보다 더 정교하게 생성하기 위하여 얼굴 섹션에 대해서 만 추가로 얼굴 각도를 전이하는 구성이다. 도 11은 본 발명의 일실시예에 따른 얼굴 각도 전이 모듈의 Training 단계를 도시한 모식도이다. 도 11에 도시 된 바와 같이, 사용자의 선곡 이전 또는 이후에 사용자 영상 데이터가 카메라를 통해 포즈 전이 인공 지능을 이용한 가상현실 노래방 장치에 입력되게 되면, 포즈 추정 모듈과 포즈 표준화 모듈을 통해 표 준화된 포즈 데이터가 생성되게 된다. 생성된 표준화된 포즈 데이터는 포즈 전이 모듈에 입력되고포즈 전이 모듈은 표준화된 포즈 데이터를 토대로 포즈 전이 영상 데이터를 생성하도록 구성된다. 이때 생성된 포즈 전이 영상 데이터는 표준화된 포즈 데이터와 함께 얼굴 섹션 추출 모듈에 입력 되고, 얼굴 섹션만 추출된 포즈 전이 영상 데이터와 표준화된 포즈 데이터는 얼굴 각도 전이 모듈에 입력되어 잔차 데이터가 생성되게 된다. 이때, 잔차 데이터는 얼굴 섹션의 각도에 대한 잔차를 의미할 수 있다. 얼굴 각도 전이 모듈은 잔차 데이터와 얼굴 섹션만 추출된 포즈 전이 영상 데이터를 기초 로 얼굴 각도 전이가 적용된 포즈 전이 영상 데이터의 얼굴섹션을 출력할 수 있다. 이때, 얼굴 각도 전이 모듈에는 예를 들어, VGGNet과 같은 ConvNet 으로 구성된 얼굴 구분 모듈이 함 께 구성될 수 있는데, 얼굴 구분 모듈에는 표준화된 포즈 데이터의 얼굴 섹션과 얼굴 각도 전이가 적 용된 포즈 전이 영상 데이터의 얼굴 섹션이 Fake로 레이블링(Labeling)되어 입력되고, 표준화된 포즈 데이 터의 얼굴 섹션과 사용자 영상 데이터의 얼굴 섹션이 Real로 레이블링되어 입력된 뒤, 얼굴 구분 모듈 이 Fake data와 Real data로 Supervised Learning 되도록 구성될 수 있다. 즉, 본 발명의 일실시예에 따 른 얼굴 구분 모듈은 얼굴 각도 전이 모듈에서 생성되는 포즈 전이 영상 데이터의 얼굴 섹션을 Fake 와 Real로 분류하여 손실 데이터(Loss data)를 생성하게 된다. 얼굴 구분 모듈에서 출력되는 손실 데 이터(Loss data)는 얼굴 각도 전이 모듈을 학습하는 손실함수(Loss function)에 이용되게 되고, 얼굴 각도 전이 모듈은 얼굴 구분 모듈의 손실 데이터를 최소로 하도록 학습되게 된다. 이러한 과정에서 얼굴 각 도 전이 모듈은 표준화된 포즈 데이터의 얼굴 섹션을 토대로 사용자 영상 데이터와 유사한 배경, 유사한 의상 및 유사한 얼굴 각도로 포즈 전이 영상 데이터의 얼굴 섹션을 생성하도록 학습되게 되며 얼굴 구분 모듈이 Fake 와 Real을 구분하기 어렵도록 학습되게 된다. 동시에 얼굴 구분 모듈은 Fake로 레 이블링 된 데이터와 Real로 레이블링 된 데이터를 통해 Fake(포즈 전이 영상 데이터의 얼굴 섹션)와 Real(사용 자 영상 데이터의 얼굴 섹션)를 더 잘 구분하도록 지도학습 되기 때문에 얼굴 각도 전이 모듈과 얼굴 구분 모듈은 상호 적대적 의존관계를 가지며 학습되게 된다. 얼굴 각도 전이 모듈과 얼굴 구분 모듈은 상호 적대적 의존 관계에 의해 얼굴 각도 전이 모듈을 빠르게 최적화 할 수 있는 효과가 발생된다. 도 12는 본 발명의 일실시예에 따른 얼굴 각도 전이 모듈의 Transfer 단계를 도시한 모식도이다. 도 12에 도시 된 바와 같이, 사용자의 선곡 이후에 기저장 영상 데이터가 데이터베이스 또는 외부 웹서버, 스트리밍 서 버 등을 통해 포즈 전이 인공지능을 이용한 가상현실 노래방 장치에 입력되게 되면, 포즈 추정 모듈과 포 즈 표준화 모듈을 통해 기저장 영상 데이터의 표준화된 포즈 데이터가 생성되게 된다. 생성된 표준 화된 포즈 데이터는 포즈 전이 모듈에 입력되고 포즈 전이 모듈은 표준화된 포즈 데이터를 토대 로 기저장 영상 데이터의 포즈가 사용자 영상 데이터에 전이된 포즈 전이 영상 데이터를 생성하 도록 구성된다. 생성된 포즈 전이 영상 데이터와 표준화된 포즈 데이터가 얼굴 섹션 추출 모듈과 기학습된 얼굴 각도 전이 모듈에 입력되게 되고, 얼굴 각도 전이 모듈에서 잔차 데이터가 출력되며, 잔차 데이터가 포즈 전이 영상 데이터의 얼굴 섹션과 함께 병합되어 얼굴 전이된 포즈 전이 영상 데이 터를 출력하게 된다. 보다 더 고화질의 포즈 전이 영상 데이터를 출력하기 위하여, 포즈 전이 모듈의 Loss function에 각 신 체부위 별로 구분 모듈이 입력되는 영상 데이터(사용자 영상 데이터 또는 기저장 영상 데이터)와 출력되는 포즈 전이 영상 데이터의 Real과 Fake를 구분하는 신체부위 손실 함수를 더 포함할 수 있다. 본 발명의 일 실시예에 따른 신체부위 손실 함수는 다음 수학식과 같이 구성될 수 있다. 수학식 8"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "위 수학식 8에서 LBP(G,D)는 Body Parts에 대한 손실 함수인 신체부위 손실 함수, i는 구분 모듈의 i번째 레이어, T는 구분 모듈의 전체 레이어, Ni는 i번째 레이어에서의 신체부위 feature의 개수를 의미할 수 있다. 이에 따라, 구분 모듈이 특정 레이어에서 특정 신체부위의 Real or Fake를 정확하게 구분해내면 ||D(x,y)-D(x,G(x))||=1 이 되고, 입력 영상 데이터 y와 포즈 전이 모듈에 의해 생성된 포즈 전이 영상 데이 터 G(x)의 특정 레이어에서의 특정 신체부위가 구분 모듈에 의해 구분되지 않으면 ||D(x,y)-D(x,G(x))||=0 이 된다. 따라서, 위와 같은 신체부위 손실함수를 적용한 포즈 전이 모듈의 손실함수는 다음과 같이 구성될 수 있다. 수학식 9"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "위 수학식 9에서, λ는 가중치 상수, LBP는 수학식 8의 신체부위 손실함수를 의미할 수 있고, 포즈 전이 모듈 은 신체부위 손실함수를 최소화 하는 방향으로 학습되게 된다. 이에 의해 보다 향상된 고화질의 포즈 전이 영상 데이터가 출력되도록 포즈 전이 모듈이 학습되게 된다. 보다 더 고품질의 포즈 전이 영상 데이터를 출력하기 위하여, 포즈 전이 모듈이 프레임 순서를 고려할 수 있도록 Loss function을 구성할 수 있다. 본 발명의 일실시예에 따르면 포즈 전이 모듈은 특정 시간 t에 서의 표준화된 포즈 데이터 xt와 이전 시간인 t-1에서의 포즈 전이 영상 데이터인 G(xt-1)을 입력데이터로 하여 시간 t에서의 포즈 전이 영상 데이터인 G(xt)를 출력하도록 구성될 수 있다. 결국, 구분 모듈은 (xt-1, xt) 를 통해 Fake sequence인 (G(xt-1), G(xt))와 Real sequence인 (yt-1, yt)를 구분하도록 구성되며, 이를 위한 포 즈 전이 모듈의 손실함수는 아래의 수학식과 같이 구성될 수 있다. 수학식 10"}
{"patent_id": "10-2018-0137186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "위 수학식 10과 같은 손실함수에 따르면 포즈 전이 모듈에 의해 출력되는 포즈 전이 영상 데이터의 프레임과 프레임 사이가 매우 부드러워지는 효과가 발생된다. 이상에서 설명한 바와 같이, 본 발명이 속하는 기술 분야의 통상의 기술자는 본 발명이 그 기술적 사상이나 필 수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 상술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범 위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함하는 것으로 해석되어야 한다. 본 명세서 내에 기술된 특징들 및 장점들은 모두를 포함하지 않으며, 특히 많은 추가적인 특징들 및 장점들이 도면들, 명세서, 및 청구항들을 고려하여 당업자에게 명백해질 것이다. 더욱이, 본 명세서에 사용된 언어는 주 로 읽기 쉽도록 그리고 교시의 목적으로 선택되었고, 본 발명의 주제를 묘사하거나 제한하기 위해 선택되지 않 을 수도 있다는 것을 주의해야 한다. 본 발명의 실시예들의 상기한 설명은 예시의 목적으로 제시되었다. 이는 개시된 정확한 형태로 본 발명을 제한 하거나, 빠뜨리는 것 없이 만들려고 의도한 것이 아니다. 당업자는 상기한 개시에 비추어 많은 수정 및 변형이 가능하다는 것을 이해할 수 있다. 그러므로 본 발명의 범위는 상세한 설명에 의해 한정되지 않고, 이를 기반으로 하는 출원의 임의의 청구항들에 의해 한정된다. 따라서, 본 발명의 실시예들의 개시는 예시적인 것이며, 이하의 청구항에 기재된 본 발명의 범위를 제한하는 것은 아니다."}
{"patent_id": "10-2018-0137186", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 발명의 상세한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어 해석되어서는 아니 된다. 도 1은 본 발명의 일실시예에 따른 가상현실 노래방의 전체 구성을 도시한 모식도, 도 2는 본 발명의 일실시예에 따른 포즈 전이 인공지능을 이용한 가상현실 노래방 장치를 도시한 모식도, 도 3은 포즈 전이 모듈의 Training 단계를 도시한 모식도, 도 4는 포즈 전이 모듈의 Transfer 단계를 도시한 모식도, 도 5는 본 발명의 일실시예에 따른 포즈 전이 인공지능을 이용한 가상현실 노래방 장치를 이용하여 사용자 영상 데이터에 기저장 영상 데이터의 포즈가 전이되는 것을 도시한 모식도,도 6은 포즈 전이 모듈의 Training 단계를 도시한 모식도, 도 7은 포즈 전이 모듈의 Transfer 단계를 도시한 모식도, 도 8은 본 발명의 일실시예에 따른 포즈 전이 인공지능을 이용한 가상현실 노래방 장치를 이용하여 기저장 영상 데이터에 사용자 영상 데이터의 포즈가 전이되는 것을 도시한 모식도, 도 9는 본 발명의 일실시예에 따라 비교 모듈을 더 포함한 포즈 전이 모듈의 Training 단계를 도시한 모식도, 도 10은 본 발명의 일실시예에 따라 얼굴 각도 전이 모듈을 더 포함하는 포즈 전이 인공지능을 이용한 가상현실 노래방 장치를 도시한 모식도, 도 11은 본 발명의 일실시예에 따른 얼굴 각도 전이 모듈의 Training 단계를 도시한 모식도, 도 12는 본 발명의 일실시예에 따른 얼굴 각도 전이 모듈의 Transfer 단계를 도시한 모식도이다."}
