{"patent_id": "10-2020-0066474", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0149437", "출원번호": "10-2020-0066474", "발명의 명칭": "음성 콘텐츠 생성 방법", "출원인": "권택준", "발명자": "권택준"}}
{"patent_id": "10-2020-0066474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "텍스트를 포함하는 원본 콘텐츠로부터 음성 콘텐츠를 생성하는 방법에 있어서,상기 원본 콘텐츠 내의 텍스트를 소정의 단위로 분할하여 하나 이상의 분할 텍스트 콘텐츠를 생성하는 단계;상기 하나 이상의 분할 텍스트 콘텐츠 각각에 대한 음성 변환 방식을 선택하는 단계;선택된 음성 변환 방식에 따라 상기 하나 이상의 분할 콘텐츠 각각에 대응되는 분할 음성 콘텐츠를 생성하는 단계; 및상기 하나 이상의 분할 콘텐츠 각각에 대응되는 분할 음성 콘텐츠를 병합하여 상기 음성 콘텐츠를 생성하는 단계;를 포함하는, 음성 콘텐츠 생성 방법."}
{"patent_id": "10-2020-0066474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서상기 분할 텍스트 콘텐츠를 생성하는 단계는상기 원본 콘텐츠 내의 텍스트를 문장 단위로 분할하여 상기 하나 이상의 분할 텍스트 콘텐츠를 생성하고,상기 음성 변환 방식을 선택하는 단계는제1 유형의 문장에 대해서는 학습된 제1 인공 신경망을 이용하여 음성을 변환하는 방식을 선택하는 단계; 및제2 유형의 문장에 대해서는 사용자의 음성 입력에 기초하여 음성을 변환하는 방식을 선택하는 단계;를 포함하는, 음성 콘텐츠 생성 방법."}
{"patent_id": "10-2020-0066474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서상기 음성 콘텐츠 생성 방법은상기 분할 음성 콘텐츠를 생성하는 단계 이후에,하나 이상의 분할 텍스트 콘텐츠 각각에 대응되는 분할 음성 콘텐츠를 평가하는 단계;를 더 포함하는, 음성 콘텐츠 생성 방법."}
{"patent_id": "10-2020-0066474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서상기 분할 텍스트 콘텐츠가 제1 유형의 문장인 경우상기 분할 음성 콘텐츠를 평가하는 단계는학습된 제2 인공 신경망을 이용하여 상기 분할 음성 콘텐츠에 대응되는 분할 인식 텍스트 콘텐츠를 생성하는 단계;상기 분할 텍스트 콘텐츠와 상기 분할 인식 텍스트 콘텐츠의 유사도에 기반하여 상기 분할 음성 콘텐츠의 정상여부를 평가하는 단계; 및상기 정상 여부에 기초하여 상기 분할 음성 콘텐츠를 처리하는 단계;를 포함하는, 음성 콘텐츠 생성 방법."}
{"patent_id": "10-2020-0066474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서공개특허 10-2021-0149437-3-상기 분할 음성 콘텐츠가 비정상인 것으로 판단되는 경우,상기 분할 음성 콘텐츠를 처리하는 단계는상기 분할 텍스트 콘텐츠를 수정한 수정 분할 텍스트 콘텐츠를 획득하는 단계; 및학습된 제1 인공 신경망을 이용하여 상기 수정 분할 텍스트 콘텐츠에 대응되는 수정 분할 음성 콘텐츠를 생성하는 단계;를 포함하는, 음성 콘텐츠 생성 방법."}
{"patent_id": "10-2020-0066474", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 텍스트를 포함하는 원본 콘텐츠로부터 음성 콘텐츠를 생성하는 방법은, 상기 원본 콘텐츠 내의 텍스트를 소정의 단위로 분할하여 하나 이상의 분할 텍스트 콘텐츠를 생성하는 단계; 상기 하나 이 상의 분할 텍스트 콘텐츠 각각에 대한 음성 변환 방식을 선택하는 단계; 선택된 음성 변환 방식에 따라 상기 하 나 이상의 분할 콘텐츠 각각에 대응되는 분할 음성 콘텐츠를 생성하는 단계; 및 상기 하나 이상의 분할 콘텐츠 각각에 대응되는 분할 음성 콘텐츠를 병합하여 상기 음성 콘텐츠를 생성하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2020-0066474", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예들은 텍스트를 포함하는 원본 콘텐츠로부터 음성 콘텐츠를 생성하는 방법에 관한 것이다."}
{"patent_id": "10-2020-0066474", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자책이라고 불리는 e-book은 전자기기의 화면을 통해 책의 내용을 표시하는 방식으로, 차세대 IT 기술 시대의 총아로 지목받았지만 아직까지 크게 각광받고 있지는 못하다. 대신 요즘에는 '보는 책'이 아닌 '듣는 책', 이른바 오디오북(audio book)이 등장하여 새로운 시장을 창출하고 있다. 오디오북은 테이프, CD, MP3 등의 형태로 제작된 '귀로 듣는 책'으로써, 종이책 대신 성우가 녹음작업으 로 만든 음성 컨텐츠를 말한다. 오디오 북의 경우 이동하면서 들을 수 있고, 귀로 듣기 때문에 언제 어디서나 손쉽게 이용이 가능하며, 휴대폰 과 같이 오디오 파일을 재생 가능한 디바이스를 통해 많은 수의 오디오 북을 청취하는 것도 가능하기 때문에 바 쁜 현대의 직장인들에게 활용도가 매우 높다. 또한 오디오북은 책을 읽는다는 능동적인 행동을 책을 듣는 수동적인 행동으로 변화시킴으로써 독서의 멀티태스 킹이 가능하게 한다. 즉 운전을 하거나, 일을 하면서도 책을 들을 수 있다. 그래서 원래 책을 읽던 사람들을 더 편리하게 해주는 e-book에 비해 오디오북은 원래 책을 읽지 않던 사람들도 책을 듣게 하기에 독서인구를 증가시 키는데 더욱 효과적이다. 또한 시각장애인이나 노안으로 인해 책을 가까이 할 수 없는 노인들에게 유익한 컨텐츠들을 제공함으로써, 교육 과 문화의 기회를 확대시킬 수 있다. 해외에서는 이미 오디오북을 이용한 독서가 널리 확산되어 있으며, 미국의 경우 대부분의 공공도서관에는 오디 오북이 기본적으로 비치되어 있으며 대출률이 가장 높은 장서도 오디오북으로 조사되었다. 그러나 오디오북을 제작하기 위해서는 별도의 장비와 시설을 갖추어야 하고, 원저작물을 각색하기 위한 구성작 가나 실제 오디오북의 녹음에 참여하는 한 명 또는 다수의 전문 성우를 고용해야 하기 때문에 제작비로 소요되 는 비용이 매우 많다. 이에 따라 오디오북의 판매 가격이 내려가지 못하고 있으며, 오디오북에 대한 수요자층이 크게 확산되지 못하고 있다. 최근에는 인공지능을 이용하여 오디오북을 제작하여 상술한 문제점을 해결하고자 하는 시도가 있으나, 인공지능 을 이용하여 제작한 오디오북은 목소리가 어색하여 청취에 피로감을 느끼게 하기 때문에 여전히 수요자층을 확 산시키지 못하는 문제점을 가지고 있다. 또한, 인공지능을 이용한 목소리가 사람들의 대화에서 감정이 들어간 '대화문'에 해당하는 부분을 표현하는데는 한계가 있기 때문에 인공지능과 인간의 협업이 필요하다."}
{"patent_id": "10-2020-0066474", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위한 것으로, 보다 효율적인 오디오북 생성 방법을 제공하고자 한다."}
{"patent_id": "10-2020-0066474", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 텍스트를 포함하는 원본 콘텐츠로부터 음성 콘텐츠를 생성하는 방법은, 상기 원본 콘텐츠 내의 텍스트를 소정의 단위로 분할하여 하나 이상의 분할 텍스트 콘텐츠를 생성하는 단계; 상기 하나 이상의 분할 텍스트 콘텐츠 각각에 대한 음성 변환 방식을 선택하는 단계; 선택된 음성 변환 방식에 따라 상기 하 나 이상의 분할 콘텐츠 각각에 대응되는 분할 음성 콘텐츠를 생성하는 단계; 및 상기 하나 이상의 분할 콘텐츠 각각에 대응되는 분할 음성 콘텐츠를 병합하여 상기 음성 콘텐츠를 생성하는 단계;를 포함할 수 있다. 상기 분할 텍스트 콘텐츠를 생성하는 단계는 상기 원본 콘텐츠 내의 텍스트를 문장 단위로 분할하여 상기 하나 이상의 분할 텍스트 콘텐츠를 생성하고, 상기 음성 변환 방식을 선택하는 단계는 제1 유형의 문장에 대해서는 학습된 제1 인공 신경망을 이용하여 음성을 변환하는 방식을 선택하는 단계; 및 제2 유형의 문장에 대해서는 사 용자의 음성 입력에 기초하여 음성을 변환하는 방식을 선택하는 단계;를 포함할 수 있다. 이때 상기 제1 유형은 평서문 유형이고, 상기 제2 유형은 대화문 유형일 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 방법은 상기 분할 음성 콘텐츠를 생성하는 단계 이후에, 하나 이 상의 분할 텍스트 콘텐츠 각각에 대응되는 분할 음성 콘텐츠를 평가하는 단계;를 더 포함할 수 있다, 상기 분할 텍스트 콘텐츠가 제1 유형의 문장인 경우 상기 분할 음성 콘텐츠를 평가하는 단계는 학습된 제2 인공 신경망을 이용하여 상기 분할 음성 콘텐츠에 대응되는 분할 인식 텍스트 콘텐츠를 생성하는 단계; 상기 분할 텍 스트 콘텐츠와 상기 분할 인식 텍스트 콘텐츠의 유사도에 기반하여 상기 분할 음성 콘텐츠의 정상 여부를 평가 하는 단계; 및 상기 정상 여부에 기초하여 상기 분할 음성 콘텐츠를 처리하는 단계;를 포함할 수 있다. 상기 분할 음성 콘텐츠가 정상인 것으로 판단되는 경우, 상기 분할 음성 콘텐츠를 처리하는 단계는 상기 원본 콘텐츠 내에서의 상기 분할 텍스트 콘텐츠의 위치에 기초하여, 상기 분할 음성 콘텐츠의 순번을 결정하고, 상기 음성 콘텐츠를 생성하는 단계는 상기 순번에 대응되는 위치에 상기 분할 음성 콘텐츠가 추가된 상기 음성 콘텐 츠를 생성할 수 있다. 상기 분할 음성 콘텐츠가 비정상인 것으로 판단되는 경우, 상기 분할 음성 콘텐츠를 처리하는 단계는 상기 분할 텍스트 콘텐츠를 수정한 수정 분할 텍스트 콘텐츠를 획득하는 단계; 및 학습된 제1 인공 신경망을 이용하여 상 기 수정 분할 텍스트 콘텐츠에 대응되는 수정 분할 음성 콘텐츠를 생성하는 단계;를 포함할 수 있다. 상기 분할 텍스트 콘텐츠가 제2 유형의 문장인 경우 상기 분할 음성 콘텐츠를 평가하는 단계는 학습된 제2 인공 신경망을 이용하여 상기 분할 음성 콘텐츠에 대응되는 분할 인식 텍스트 콘텐츠를 생성하는 단계; 상기 분할 텍 스트 콘텐츠와 상기 분할 인식 텍스트 콘텐츠의 유사도에 기반하여 상기 분할 음성 콘텐츠의 재녹음 여부를 평 가하는 단계; 및 상기 재녹음 여부에 기초하여 상기 분할 음성 콘텐츠를 처리하는 단계;를 포함할 수 있다. 상기 음성 콘텐츠를 생성하는 단계는 상기 원본 콘텐츠 내에서의 상기 분할 텍스트 콘텐츠의 위치에 기초하여 결정되는 상기 분할 음성 콘텐츠의 순번을 참조하여, 상기 하나 이상의 분할 텍스트 콘텐츠 각각에 대응되는 분 할 음성 콘텐츠를 순차적으로 병합하는 단계;를 포함할 수 있다. 상기 음성 콘텐츠를 생성하는 단계는 상기 원본 콘텐츠의 내용에 기초하여 상기 음성 콘텐츠에 적어도 하나의 음향 콘텐츠를 추가하는 단계;를 더 포함할 수 있다."}
{"patent_id": "10-2020-0066474", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 보다 효율적으로 오디오북을 생성할 수 있다. 특히 본 발명에 따르면 인공지능을 이용하여 녹음하는 부분과 성우가 녹음하는 부분을 적절하게 분배함으로써 보다 자연스러운 오디오북의 생성이 가능한다. 또한 본 발명에 따르면 인공지능에 의해 녹음된 부분을 평가함으로써, 오디오북의 제작에 있어서 인공지능의 사 용에 따른 문제점을 보완할 수 있다. 또한 본 발명에 따르면 성우에 의해 녹음된 부분도 평가함으로써, 오디오북의 완성도를 향상시킬 수 있다. 또한 본 발명에 따르면 책의 내용에 따른 음향 효과를를 적절히 추가함으로써 보다 생동감 있는 오디오북을 제 작할 수 있다."}
{"patent_id": "10-2020-0066474", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고"}
{"patent_id": "10-2020-0066474", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상세한 설명에 상세하게 설명하고자 한다. 본 발명의 효과 및 특징, 그리고 그것들을 달성하는 방법은 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 다양한 형태로 구현될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 실시예에서, 제1, 제2 등의 용어는 한정적인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별 하는 목적으로 사용되었다. 이하의 실시예에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 실시예에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 또는 구성요 소가 존재함을 의미하는 것이고, 하나 이상의 다른 특징들 또는 구성요소가 부가될 가능성을 미리 배제하는 것 은 아니다. 도면에서는 설명의 편의를 위하여 구성 요소들이 그 크기가 과장 또는 축소될 수 있다. 예컨대, 도 면에서 나타난 각 구성의 크기 및 형태는 설명의 편의를 위해 임의로 나타내었으므로, 본 발명이 반드시 도시된 바에 한정되지 않는다. 도 1은 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 시스템의 구성을 개략적으로 도시한 도면이다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 시스템은 텍스트를 포함하는 원본 콘텐츠로부터 음성 콘텐츠를 생성할 수 있다. 이때 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 시스템은 원본 콘텐츠 내의 텍스트를 소정 의 단위로 분할하고, 분할된 텍스트의 유형에 따라 음성 변환 방식을 선택하여 음성 콘텐츠를 생설할 수 있다. 가령 본 발명의 일 실시예에 따른 시스템은 분할 콘텐츠가 평서문 유형인 경우 학습된 인공 신경망을 이용하여 해당 분할 콘텐츠에 대한 음성 콘텐츠를 생성하고, 분할 콘텐츠가 대화문 유형인 경우 사용자 단말에 해당 분할 콘텐츠에 대한 사용자(또는 성우)의 목소리를 요청하여 해당 분할 콘텐츠에 대한 음성 콘텐츠를 생성할 수 있다. 이와 같은 음성 콘텐츠 생성 시스템은 도 1에 도시된 바와 같이 서버, 제1 사용자 단말, 제2 사용자 단말 및 통신망을 포함할 수 있다. 본 발명의 선택적 실시예에서, 상술한 시스템 구성요소의 적어도 일부는 통합되어 구성될 수 있다. 가령 서버 와 제1 사용자 단말이 통합되어 구성될 수도 있다. 이러한 경우 후술하는 음성 콘텐츠 생성 장치는 서버와 제1 사용자 단말이 통합된 장치에 구비되어 음성 콘텐츠 생성 방법을 수행할 수 있다. 또한 서버, 제1 사용자 단말 및 제2 사용자 단말은 모두 통합되어 구성될 수 있다. 이러한 경우에도 후술하는 음성 콘텐츠 생성 장치는 서버, 제1 사용자 단말 및 제2 사용자 단말이 통합된 장치에 구비되어 음성 콘텐츠 생성 방법을 수행할 수 있다. 다만 이하에서는 설명의 편의를 위해 도 1에 도시된 바와 같이 시스템의 각 구성이 구분되어 구성됨을 전제로 설명한다.본 발명의 일 실시예에 따른 제1 사용자 단말 및 제2 사용자 단말은 사용자가 서버에 의해 제공 되는 다양한 서비스를 이용할 수 있도록 사람과 서버를 매개하는 다양한 형태의 장치를 의미할 수 있다. 본 발명의 일 실시예에 따른 제1 사용자 단말은 음성 콘텐츠 생성 시스템 관리자(또는 음성 콘텐츠를 제작 하는 제작자)의 단말을 의미할 수 있다. 따라서 제1 사용자 단말은 서버로부터 음성 콘텐츠 생성을 위한 인터페이스를 포함하는 웹 페이지 또는 어플리케이션 표시 데이터를 수신하여 표시할 수 있다. 또한 제1 사용자 단말은 제공된 인터페이스에 대한 사용자의 입력을 획득하여 서버로 전송할 수도 있다. 본 발명의 일 실시예에 따른 제2 사용자 단말은 음성을 제공하는 사용자(또는 음성을 제공하는 성우)의 단 말을 의미할 수 있다. 따라서 제2 사용자 단말은 서버로부터 녹음 및/또는 재녹음이 필요한 분할 텍 스트 콘텐츠를 수신하여 표시하고, 표시된 분할 텍스트 콘텐츠에 대한 사용자의 음성을 획득하여 서버로 전송할 수 있다. 이와 같은 사용자 단말(200, 300)은 가령 도 1에 도시된 제1 사용자 단말과 같이 휴대용 단말(201, 202, 203)을 의미할 수도 있고, 컴퓨터를 의미할 수도 있다. 본 발명의 일 실시예에 따른 사용자 단말(200, 300)은 상술한 기능을 수행하기 위해 콘텐츠 등을 표시하기 위한 표시수단, 이러한 콘텐츠에 대한 사용자의 입력을 획득하기 위한 입력수단을 구비할 수 있다. 이 때 입력수단 및 표시수단은 다양하게 구성될 수 있다. 가령 입력수단은 키보드, 마우스, 트랙볼, 마이크, 버튼, 터치패널 등 을 포함할 수 있으나 이에 한정되지 않는다. 도 1에는 제1 사용자 단말과 제2 사용자 단말 각각이 모두 단수개인 것으로 도시되었지만, 이와 같은 수량은 예시적인것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 따라서 제1 사용자 단말 및 제2 사 용자 단말은 복수일 수도 있다. 본 발명의 일 실시예에 따른 통신망은 시스템의 각 구성 간의 데이터 송수신을 매개하는 통신망을 의미할 수 있다. 가령 통신망은 LANs(Local Area Networks), WANs(Wide Area Networks), MANs(Metropolitan Area Networks), ISDNs(Integrated Service Digital Networks) 등의 유선 네트워크나, 무선 LANs, CDMA, 블루 투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 본 발명의 일 실시예에 따른 서버는 원본 콘텐츠 내의 텍스트를 소정의 단위로 분할하고, 분할된 텍스트의 유형에 따라 음성 변환 방식을 선택하여 음성 콘텐츠를 생설할 수 있다. 가령 본 발명의 일 실시예에 따른 시스 템은 분할 콘텐츠가 평서문 유형인 경우 학습된 인공 신경망을 이용하여 해당 분할 콘텐츠에 대한 음성 콘텐츠 를 생성하고, 분할 콘텐츠가 대화문 유형인 경우 제2 사용자 단말에 해당 분할 콘텐츠에 대한 사용자(또는 성우)의 목소리를 요청하여 해당 분할 콘텐츠에 대한 음성 콘텐츠를 생성할 수 있다. 도 2는 본 발명의 일 실시예에 따른 서버에 구비되는 음성 콘텐츠 생성 장치의 구성을 개략적으로 도 시한 도면이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 통신부, 제 어부 및 메모리를 포함할 수 있다. 또한 도면에는 도시되지 않았으나, 본 실시예에 따른 음성 콘텐츠 생성 장치는 입/출력부, 프로그램 저장부 등을 더 포함할 수 있다. 통신부는 음성 콘텐츠 생성 장치가 사용자 단말(200, 300)과 같은 다른 네트워크 장치와 유무선 연결 을 통해 제어 신호 또는 데이터 신호와 같은 신호를 송수신하기 위해 필요한 하드웨어 및 소프트웨어를 포함하 는 장치일 수 있다. 제어부는 프로세서(Processor)와 같이 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있다. 여기 서, '프로세서(Processor)'는, 예를 들어 프로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위 해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드 웨어에 내장된 데이터 처리 장치의 일 예로써, 마이크로프로세서(Microprocessor), 중앙처리장치(Central Processing Unit: CPU), 프로세서 코어(Processor Core), 멀티프로세서(Multiprocessor), ASIC(Application- Specific Integrated Circuit), FPGA(Field Programmable Gate Array) 등의 처리 장치를 망라할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 메모리는 음성 콘텐츠 생성 장치가 처리하는 데이터를 일시적 또는 영구적으로 저장하는 기능을 수행 한다. 메모리는 자기 저장 매체(Magnetic Storage Media) 또는 플래시 저장 매체(Flash Storage Media)를 포함 할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 이하에서는 음성 콘텐츠 생성 장치의 제어부가 원본 콘텐츠로부터 음성 콘텐츠를 생성하는 방법을 중 심으로 설명한다. 본 발명의 일 실시예에 따른 제어부는 원본 콘텐츠로부터 음성 콘텐츠를 생성하기위해 원본 콘텐츠 내의 텍스트를 수집할 수 있다. 또한 본 발명의 일 실시예 따른 제어부는 수집된 원본 콘텐츠 내의 텍스트를 소 정의 단위로 분할하여 하나 이상의 분할 텍스트 콘텐츠를 생성할 수 있다. 도 3 및 도 4는 본 발명의 일 실시예에 따른 제어부가 원본 콘텐츠 내의 텍스트를 수집하여 하나 이상의 분할 텍스트 콘텐츠를 생성하는 과정을 설명하기 위한 도면이다. 본 발명에서 '원본 콘텐츠'는 다양한 유형의 콘텐츠를 포함하는 복합 콘텐츠를 의미할 수 있다. 가령 도 4에 도 시된 바와 같이 원본 콘텐츠(510A)는 텍스트 유형의 콘텐츠와 이미지 유형의 콘텐츠를 포함하는 콘텐츠를 의미 할 수 있다. 또한 원본 콘텐츠는 도 4에 도시된 예시와 다르게, 텍스트 유형의 콘텐츠만 포함하는 콘텐츠일 수도 있고, 텍스트 유형의 콘텐츠, 동영상 유형의 콘텐츠를 포함하는 콘텐츠를 의미할 수도 있다. 또한 원본 콘텐츠는 웹툰 콘텐츠로, 이미지(또는 만화 컷) 유형의 콘텐츠 내에 소정의 형식(예를 들어 말 풍선 형식)으로 텍스트 유형의 콘텐츠를 포함하는 콘텐츠일 수도 있다. 본 발명의 일 실시예에 따른 제어부는 전술한 바와 같이 원본 콘텐츠 내의 텍스트를 수집하여, 텍스 트만 포함하는 원본 콘텐츠를 생성할 수 있다. 가령 도 4에 도시된 바와 같이 제어부는 텍스트 유형 의 콘텐츠와 이미지 유형의 콘텐츠를 포함하는 원본 콘텐츠(510A)로부터 텍스트만 포함하는 원본 콘텐츠(520A) 를 생성할 수 있다. 본 발명의 일 실시예에 따른 제어부는 원본 콘텐츠 내의 텍스트, 즉 텍스트만 포함하는 원본 콘텐츠 를 소정의 단위로 분할하여 하나 이상의 분할 텍스트 콘텐츠를 생성할 수 있다. 가령 제어부는 도 4에 도시된 바와 같이 텍스트만 포함하는 원본 콘텐츠(520A)를 문장 단위로 분할하여 하나 이상의 분할 텍스 트 콘텐츠(530A)를 생성할 수 있다. 이때 텍스트만 포함하는 원본 콘텐츠를 분할하는 단위, 즉 '소정의 단위'는 사용자(제1 사용자)에 의해 적 절하게 결정될 수 있다. 가령 소정의 단위는 후술하는 제1 인공 신경망 및 제2 인공 신경망의 출력 정확도를 향 상시키는 단위로 결정될 수 있다. 다만 이는 예시적인것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 본 발명의 선택적 실시예에서, 원본 콘텐츠가 웹툰 콘텐츠인 경우 제어부는 말풍선 단위로 분할 콘텐 츠를 생성할 수 있다. 다만 이는 예시적인것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 도 5 및 도 6은 본 발명의 일 실시예에 따른 제어부가 하나 이상의 분할 텍스트 콘텐츠(530, 530B) 각각에 대한 음성 변환 방식(540, 540B)을 선택하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 제어부는 생성된 하나 이상의 분할 텍스트 콘텐츠 각각에 대한 음성 변 환 방식을 선택할 수 있다. 가령 본 발명의 일 실시예에 따른 제어부는 문장 단위로 분할한 분할 텍 스트 콘텐츠가 제1 유형의 문장에 해당하는 경우 학습된 제1 인공 신경망을 이용하여 음성을 변환하는 방 식을 선택하고, 제2 유형의 문장에 해당하는 경우 사용자(제2 사용자)의 음성 입력에 기초하여 음성을 변환하는 방식을 선택할 수 있다. 이때 제1 유형은 평서문 유형이고, 제2 유형은 대화문 유형일 수 있다. 본 발명의 일 실시예에 따른 제어부는 하나 이상의 분할 텍스트 콘텐츠 각각이 소정의 형식을 만족하 는지 여부에 기초하여 상술한 바와 같이 하나 이상의 분할 텍스트 콘텐츠 각각의 유형을 결정할 수 있다. 가령 제어부는 하나 이상의 분할 텍스트 콘텐츠 각각이 소정의 특수문자를 포함하거나 소정의 특수문 자를 소정의 방식으로 포함하는 경우 해당 콘텐츠를 제2 유형으로, 그렇지 않은 경우 해당 콘텐츠를 제1 유형으 로 결정할 수 있다. 한편 도 6에 도시된 바와 같이 상술한 '소정의 특수문자'는 따옴표(\"\")일 수 있고, '소정의 방식'은 텍스트 콘 텐츠의 시작과 끝 부분에 소정의 특수문자를 포함하는 방식일 수 있다. 다만 이는 예시적인것으로 본 발명의 사 상이 이에 한정되는 것은 아니며, 특수문자는 따옴표(\"\") 외에, 다양한 종류의 괄호([], {}, ())일 수도 있다. 가령 제어부는 도 6에 도시된 바와 같이 따옴표(\"\")를 시작과 끝에 포함하는 분할 텍스트 콘텐츠는 대화문 방식으로, 나머지 분할 텍스트 콘텐츠는 평서문 방식으로 하나 이상의 분할 텍스트 콘텐츠(530B) 각각에 대한 음성 변환 방식(540B)을 선택할 수 있다. 본 발명의 일 실시예에 따른 제어부는 선택된 음성 변환 방식에 따라 하나 이상의 분할 콘텐츠 각각에 대응되는 분할 음성 콘텐츠를 생성할 수 있다. 도 7은 본 발명의 일 실시예에 따른 제어부가 분할 음성 콘텐츠(550C, 550D)를 생성하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 제어부는 제1 유형으로 선택된 하나 이상의 분할 콘텐츠(530C)에 대해서는 학 습된 제1 인공 신경망을 이용하여 분할 음성 콘텐츠(550C)를 생성할 수 있다. 본 발명에서 '제1 인공 신경망'은 복수의 학습 데이터에 기반하여, 텍스트 콘텐츠의 입력에 따라 입력된 텍스트와 대응되는 음성 콘텐츠(특히 입력된 텍스트에 대한 독음(讀音)을 포함하는 음성 콘텐츠)를 출력하도록 학습된 신경망을 의미할 수 있다. 이때 복수의 학습 데이터는 텍스트 콘텐츠와 해당 텍스트 콘텐츠의 독음을 포 함하는 음성 콘텐츠가 서로 매핑(또는 대응)된 형태의 개별 학습 데이터를 포함할 수 있다. 이와 같은 제1 인공 신경망의 학습은 원본 콘텐츠로부터 텍스트 콘텐츠를 수집하기 이전에 미리 수행될 수 있다. 제1 인공 신경망은 다양한 공지의 신경망 모델(Model)로 구현될 수 있으며, 텍스트 콘텐츠의 입력에 따라 입력된 텍스트에 대응되는 독음을 포함하는 음성 콘텐츠를 출력하는 신경망이라면 본 발명의 제1 인공 신경망 에 해당할 수 있다. 본 발명의 일 실시예에 따른 제어부는 제2 유형으로 선택된 하나 이상의 분할 콘텐츠(530D)에 대해서는 사 용자(제2 사용자)의 음성 입력에 기초하여 분할 음성 콘텐츠(550D)를 생성할 수 있다. 가령 제어부는 하나 이상의 분할 콘텐츠(530D)를 제2 사용자 단말로 전송하고, 제2 사용자 단말로부터 하나 이상의 분할 콘텐츠(530D)에 대한 사용자의 음성을 수신하여 분할 음성 콘텐츠(550D)를 생성할 수 있다. 본 발명의 일 실시예에 따른 제어부는 상술한 과정에 따라 생성된 분할 음성 콘텐츠(550C, 550D)를 평가할 수 있다. 도 8은 본 발명의 일 실시예에 따른 제어부가 분할 음성 콘텐츠(550C)를 평가하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 제어부는 학습된 제2 인공 신경망을 이용하여 분할 음성 콘텐츠(550C)에 대응되는 분할 인식 텍스트 콘텐츠(560C)를 생성할 수 있다. 이때 분할 음성 콘텐츠(550C), 분할 인식 텍스트 콘텐츠(560C) 및 하나 이상의 분할 텍스트 콘텐츠(530C) 각각은 도시된 바와 같이 복수일 수 있으나, 이하에서 는 설명의 편의를 위해 각각이 단수의 콘텐츠인 것으로 가정하여 설명한다. 본 발명에서 '제2 인공 신경망'은 복수의 학습 데이터에 기반하여, 음성 콘텐츠의 입력에 따라 입력된 음 성의 독음을 포함하는 텍스트 콘텐츠를 출력하도록 학습된 신경망을 의미할 수 있다. 이때 복수의 학습 데이터 는 텍스트 콘텐츠와 해당 텍스트 콘텐츠의 독음 (讀音)을 포함하는 음성 콘텐츠가 서로 매핑(또는 대응)된 형태 의 개별 학습 데이터를 포함할 수 있다. 이와 같은 제2 인공 신경망의 학습은 원본 콘텐츠로부터 텍스트 콘텐츠를 수집하기 이전에 미리 수행될 수 있다. 한편 제2 인공 신경망은 다양한 공지의 신경망 모델(Model)로 구현될 수 있으며, 음성 콘텐츠의 입력에 따 라 입력된 음성의 독음을 포함하는 텍스트 콘텐츠를 출력하는 신경망이라면 본 발명의 제2 인공 신경망에 해당할 수 있다. 본 발명의 일 실시예에 따른 제어부는 분할 텍스트 콘텐츠(530C)와 분할 인식 텍스트 콘텐츠(560C)의 유사 도에 기반하여 분할 음성 콘텐츠(550C)의 정상 여부를 평가하고, 정상 여부에 기초하여 분할 음성 콘텐츠(550 C)를 처리할 수 있다. 가령 제어부는 분할 텍스트 콘텐츠(530C)와 분할 인식 텍스트 콘텐츠(560C)의 유사도가 소정의 임계 유사 도 이상인 경우, 분할 음성 콘텐츠(550C)가 정상인 것으로 판단하고, 유사도가 소정의 임계 유사도 미만인 경우, 분할 음성 콘텐츠(550C)가 정상이 아닌 것으로 판단할 수 있다. 이때 유사도는 제1 사용자에 의해 적절하 게 설정될 수 있다. 가령 제1 사용자는 정상이 아닌 것으로 판단되는 분할 음성 콘텐츠(550C)의 비율이 적정한 비율이 되도록 유사도를 적절히 설정할 수 있다. 본 발명의 일 실시예에 따른 제어부는 분할 음성 콘텐츠(550C)가 정상인 것으로 판단되는 경우, 원본 콘텐 츠 내에서의 분할 텍스트 콘텐츠(530C)의 위치에 기초하여, 분할 음성 콘텐츠(550C)의 순번을 결정할 수 있다. 가령 제어부는 분할 음성 콘텐츠(550C)에 원본 콘텐츠 내에서의 분할 텍스트 콘텐츠(530C)의위치를 태깅할 수 있다. 예를 들어 제어부는 \"A책_B페이지_C번째문장\"과 같은 형태로 분할 음성 콘텐츠 (550C)에 태깅을 수행할 수 있다. 이와 같은 태깅 정보는 후술하는 과정에 따라 분할 음성 콘텐츠를 병합하여 음성 콘텐츠를 생성하는데 사용될 수 있다. 물론 태깅 정보는 완성된 음성 콘텐츠에서 위치를 나타내는 인덱스 요소로써 사용될 수도 있다. 한편 본 발명의 일 실시예에 따른 제어부는 분할 음성 콘텐츠(550C)가 정상이 아닌 것으로 판단되는 경우, 분할 텍스트 콘텐츠(530C)를 수정한 수정 분할 텍스트 콘텐츠(530C')를 획득하고, 학습된 제1 인공 신경망(61 0)을 이용하여 수정 분할 텍스트 콘텐츠(530C')에 대응되는 수정 분할 음성 콘텐츠를 생성할 수 있다. 이때 생 성된 수정 분할 음성 콘텐츠는 분할 음성 콘텐츠(550C)에 갈음하여 사용될 수 있다. 도 9는 본 발명의 일 실시예에 따른 제어부가 분할 음성 콘텐츠(550D)를 평가하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 제어부는 학습된 제2 인공 신경망을 이용하여 분할 음성 콘텐츠(550D)에 대응되는 분할 인식 텍스트 콘텐츠(560D)를 생성할 수 있다. 이때 분할 음성 콘텐츠(550D), 분할 인식 텍스트 콘텐츠(560D) 및 하나 이상의 분할 텍스트 콘텐츠(530D) 각각은 도시된 바와 같이 복수일 수 있으나, 이하에서 는 설명의 편의를 위해 각각이 단수의 콘텐츠인 것으로 가정하여 설명한다. 한편 제2 인공 신경망에 대해서는 도 8에서 상세하게 설명하였으므로, 이에 대한 상세한 설명은 생략한다. 본 발명의 일 실시예에 따른 제어부는 분할 텍스트 콘텐츠(530D)와 분할 인식 텍스트 콘텐츠(560D)의 유사 도에 기반하여 분할 음성 콘텐츠(550D)의 재녹음 여부를 평가하고, 재녹음 여부에 기초하여 분할 음성 콘텐츠 (550D)를 처리할 수 있다. 가령 제어부는 분할 텍스트 콘텐츠(530D)와 분할 인식 텍스트 콘텐츠(560D)의 유사도가 소정의 임계 유사 도 이상인 경우 분할 음성 콘텐츠(550D)의 재녹음이 필요 없는 것으로, 유사도가 소정의 임계 유사도 미만인 경 우 분할 음성 콘텐츠(550D)의 재녹음이 필요한 것으로 판단할 수 있다. 이때 유사도는 제1 사용자에 의해 적절 하게 설정될 수 있다. 가령 제1 사용자는 재녹임이 필요한 것으로 판단되는 분할 음성 콘텐츠(550D)의 비율이 적정한 비율이 되도록 유사도를 적절히 설정할 수 있다. 본 발명의 일 실시예에 따른 제어부는 분할 음성 콘텐츠(550D)의 재녹음이 필요 없는 것으로 판단되는 경 우, 원본 콘텐츠 내에서의 분할 텍스트 콘텐츠(530D)의 위치에 기초하여, 분할 음성 콘텐츠(550D)의 순번 을 결정할 수 있다 가령 제어부는 분할 음성 콘텐츠(550D)에 원본 콘텐츠 내에서의 분할 텍스트 콘텐 츠(530D)의 위치를 태깅할 수 있다. 예를 들어 제어부는 \"A책_B페이지_C번째문장\"과 같은 형태로 분할 음 성 콘텐츠(550D)에 태깅을 수행할 수 있다. 이와 같은 태깅 정보는 후술하는 과정에 따라 분할 음성 콘텐츠를 병합하여 음성 콘텐츠를 생성하는데 사용될 수 있다. 물론 태깅 정보는 완성된 음성 콘텐츠에서 위치를 나타내 는 인덱스 요소로써 사용될 수도 있다.. 한편 본 발명의 일 실시예에 따른 제어부는 분할 음성 콘텐츠(550D)의 재녹음이 필요한 것으로 판단된 경 우, 다시 제2 사용자 단말에 분할 음성 콘텐츠(550D)에 대한 재녹음 음성 콘텐츠(550D')를 요청할 수 있다. 요청에 따라 수신된 재녹음 음성 콘텐츠(550D')는 분할 음성 콘텐츠(550D)에 갈음하여 사용될 수 있다. 본 발명의 일 실시예에 따른 제어부는 하나 이상의 분할 콘텐츠(530C, 530D) 각각에 대응되는 분할 음성 콘텐츠(550C, 550D)를 병합하여 음성 콘텐츠를 생성할 수 있다. 도 10은 제어부가 음성 콘텐츠를 생성하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 제어부는 상술한 과정에 따라 생성된 분할 음성 콘텐츠(Partial Voice Contents 1, Partial Voice Contents 2, Partial Voice Contents 3, Partial Voice Contents N)들의 순번(Seq 1, Seq 2, Seq 3, Seq N)을 참조하여, 분할 음성 콘텐츠(Partial Voice Contents 1, Partial Voice Contents 2, Partial Voice Contents 3, Partial Voice Contents N)를 순차적으로 병합할 수 있다. 이때 '순번'은 상술 한 바와 같이 원본 콘텐츠 내에서의 분할 텍스트 콘텐츠의 위치에 기초하여 결정되는 것 일 수 있다. 본 발명의 일 실시예에 따른 제어부는 원본 콘텐츠의 내용에 기초하여 상술한 과정에 따라 병합된 콘텐츠 에 적어도 하나의 음향 콘텐츠를 추가할 수 있다. 이때 '내용'은 원본 콘텐츠에 포함되는 다양한 유형의 콘텐츠 를 참조하여 결정되는 것 일 수 있다. 가령 제어부는 원본 콘텐츠에 포함되는 이미지 콘텐츠에 나타나는 객체를 인식하고, 해당 객체에 대응되는 음향 콘텐츠를 추가할 수 있다. 예를 들어 이미지 콘텐츠에 끓는 주전 자 객체가 포함된 경우 제어부는 물 끓는 소리를 음향 콘텐츠로 추가할 수 있다. 다만 이는 예시적인것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 도 11은 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치에 의해 수행되는 음성 콘텐츠 생성 방법을 설 명하기 위한 흐름도이다. 이하에서는 도 1 내지 도 10을 함께 참조하여 설명하되, 도 1 내지 도 10에 대한 설명 과 중복되는 설명은 생략한다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 각각의 학습 데이터를 이용하여 제1 인공 신경망 및 제2 인공 신경망을 학습시킬 수 있다.(S1110) 본 발명에서 '제1 인공 신경망'은 복수의 학습 데이터에 기반하여, 텍스트 콘텐츠의 입력에 따라 입력된 텍스트와 대응되는 음성 콘텐츠(특히 입력된 텍스트에 대한 독음(讀音)을 포함하는 음성 콘텐츠)를 출력하도록 학습된 신경망을 의미할 수 있다. 이때 복수의 학습 데이터는 텍스트 콘텐츠와 해당 텍스트 콘텐츠의 독음을 포 함하는 음성 콘텐츠가 서로 매핑(또는 대응)된 형태의 개별 학습 데이터를 포함할 수 있다. 제1 인공 신경망은 다양한 공지의 신경망 모델(Model)로 구현될 수 있으며, 텍스트 콘텐츠의 입력에 따라 입력된 텍스트에 대응되는 독음을 포함하는 음성 콘텐츠를 출력하는 신경망이라면 본 발명의 제1 인공 신경망 에 해당할 수 있다. 본 발명에서 '제2 인공 신경망'은 복수의 학습 데이터에 기반하여, 음성 콘텐츠의 입력에 따라 입력된 음 성의 독음을 포함하는 텍스트 콘텐츠를 출력하도록 학습된 신경망을 의미할 수 있다. 이때 복수의 학습 데이터 는 텍스트 콘텐츠와 해당 텍스트 콘텐츠의 독음 (讀音)을 포함하는 음성 콘텐츠가 서로 매핑(또는 대응)된 형태 의 개별 학습 데이터를 포함할 수 있다. 한편 제2 인공 신경망은 다양한 공지의 신경망 모델(Model)로 구현될 수 있으며, 음성 콘텐츠의 입력에 따 라 입력된 음성의 독음을 포함하는 텍스트 콘텐츠를 출력하는 신경망이라면 본 발명의 제2 인공 신경망에 해당할 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 원본 콘텐츠로부터 음성 콘텐츠를 생성하기위해 원 본 콘텐츠 내의 텍스트를 수집할 수 있다.(S1120) 또한 본 발명의 일 실시예 따른 음성 콘텐츠 생성 장치 는 수집된 원본 콘텐츠 내의 텍스트를 소정의 단위로 분할하여 하나 이상의 분할 텍스트 콘텐츠를 생성할 수 있 다.(S1130) 도 3 및 도 4는 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치가 원본 콘텐츠 내의 텍스트를 수집하 여 하나 이상의 분할 텍스트 콘텐츠를 생성하는 과정을 설명하기 위한 도면이다. 본 발명에서 '원본 콘텐츠'는 다양한 유형의 콘텐츠를 포함하는 복합 콘텐츠를 의미할 수 있다. 가령 도 4에 도 시된 바와 같이 원본 콘텐츠(510A)는 텍스트 유형의 콘텐츠와 이미지 유형의 콘텐츠를 포함하는 콘텐츠를 의미 할 수 있다. 또한 원본 콘텐츠는 도 4에 도시된 예시와 다르게, 텍스트 유형의 콘텐츠만 포함하는 콘텐츠일 수도 있고, 텍스트 유형의 콘텐츠, 동영상 유형의 콘텐츠를 포함하는 콘텐츠를 의미할 수도 있다. 또한 원본 콘텐츠는 웹툰 콘텐츠로, 이미지(또는 만화 컷) 유형의 콘텐츠 내에 소정의 형식(예를 들어 말 풍선 형식)으로 텍스트 유형의 콘텐츠를 포함하는 콘텐츠일 수도 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 전술한 바와 같이 원본 콘텐츠 내의 텍스트를 수집하여, 텍스트만 포함하는 원본 콘텐츠를 생성할 수 있다. 가령 도 4에 도시된 바와 같이 음성 콘텐츠 생성 장치는 텍스트 유형의 콘텐츠와 이미지 유형의 콘텐츠를 포함하는 원본 콘텐츠(510A)로부터 텍스트만 포함하는 원본 콘텐츠(520A)를 생성할 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 원본 콘텐츠 내의 텍스트, 즉 텍스트만 포함하 는 원본 콘텐츠를 소정의 단위로 분할하여 하나 이상의 분할 텍스트 콘텐츠를 생성할 수 있다. 가령 음성 콘텐츠 생성 장치는 도 4에 도시된 바와 같이 텍스트만 포함하는 원본 콘텐츠(520A)를 문장 단위로 분할하여 하나 이상의 분할 텍스트 콘텐츠(530A)를 생성할 수 있다. 이때 텍스트만 포함하는 원본 콘텐츠를 분할하는 단위, 즉 '소정의 단위'는 사용자(제1 사용자)에 의해 적 절하게 결정될 수 있다. 가령 소정의 단위는 후술하는 제1 인공 신경망 및 제2 인공 신경망의 출력 정확도를 향 상시키는 단위로 결정될 수 있다. 다만 이는 예시적인것으로 본 발명의 사상이 이에 한정되는 것은 아니다.본 발명의 선택적 실시예에서, 원본 콘텐츠가 웹툰 콘텐츠인 경우 음성 콘텐츠 생성 장치는 말풍선 단위로 분할 콘텐츠를 생성할 수 있다. 다만 이는 예시적인것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 생성된 하나 이상의 분할 텍스트 콘텐츠 각각 에 대한 음성 변환 방식을 선택할 수 있다.(S1140) 도 5 및 도 6은 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치가 하나 이상의 분할 텍스트 콘텐츠 (530, 530B) 각각에 대한 음성 변환 방식(540, 540B)을 선택하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 문장 단위로 분할한 분할 텍스트 콘텐츠가 제1 유형의 문장에 해당하는 경우 학습된 제1 인공 신경망을 이용하여 음성을 변환하는 방식을 선택하고, 제2 유형 의 문장에 해당하는 경우 사용자(제2 사용자)의 음성 입력에 기초하여 음성을 변환하는 방식을 선택할 수 있다. 이때 제1 유형은 평서문 유형이고, 제2 유형은 대화문 유형일 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 하나 이상의 분할 텍스트 콘텐츠 각각이 소정 의 형식을 만족하는지 여부에 기초하여 상술한 바와 같이 하나 이상의 분할 텍스트 콘텐츠 각각의 유형을 결정할 수 있다. 가령 음성 콘텐츠 생성 장치는 하나 이상의 분할 텍스트 콘텐츠 각각이 소정의 특수 문자를 포함하거나 소정의 특수문자를 소정의 방식으로 포함하는 경우 해당 콘텐츠를 제2 유형으로, 그렇지 않 은 경우 해당 콘텐츠를 제1 유형으로 결정할 수 있다. 한편 도 6에 도시된 바와 같이 상술한 '소정의 특수문자'는 따옴표(\"\")일 수 있고, '소정의 방식'은 텍스트 콘 텐츠의 시작과 끝 부분에 소정의 특수문자를 포함하는 방식일 수 있다. 다만 이는 예시적인것으로 본 발명의 사 상이 이에 한정되는 것은 아니며, 특수문자는 따옴표(\"\") 외에, 다양한 종류의 괄호([], {}, ())일 수도 있다. 가령 음성 콘텐츠 생성 장치는 도 6에 도시된 바와 같이 따옴표(\"\")를 시작과 끝에 포함하는 분할 텍스트 콘텐츠는 대화문 방식으로, 나머지 분할 텍스트 콘텐츠는 평서문 방식으로 하나 이상의 분할 텍스트 콘텐츠 (530B) 각각에 대한 음성 변환 방식(540B)을 선택할 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 선택된 음성 변환 방식에 따라 하나 이상의 분 할 콘텐츠 각각에 대응되는 분할 음성 콘텐츠를 생성할 수 있다.(S1150) 도 7은 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치가 분할 음성 콘텐츠(550C, 550D)를 생성하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 제1 유형으로 선택된 하나 이상의 분할 콘텐츠 (530C)에 대해서는 학습된 제1 인공 신경망을 이용하여 분할 음성 콘텐츠(550C)를 생성할 수 있다. 이때 제1 인공 신경망은 단계 S1110에서 학습데이터에 기초하여 미리 학습되어 있을 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 제2 유형으로 선택된 하나 이상의 분할 콘텐츠 (530D)에 대해서는 사용자(제2 사용자)의 음성 입력에 기초하여 분할 음성 콘텐츠(550D)를 생성할 수 있다. 가 령 음성 콘텐츠 생성 장치는 하나 이상의 분할 콘텐츠(530D)를 제2 사용자 단말로 전송하고, 제2 사 용자 단말로부터 하나 이상의 분할 콘텐츠(530D)에 대한 사용자의 음성을 수신하여 분할 음성 콘텐츠 (550D)를 생성할 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 상술한 과정에 따라 생성된 분할 음성 콘텐츠(550C, 550D)를 평가할 수 있다.(S1160) 도 8은 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치가 분할 음성 콘텐츠(550C)를 평가하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 학습된 제2 인공 신경망을 이용하여 분할 음성 콘텐츠(550C)에 대응되는 분할 인식 텍스트 콘텐츠(560C)를 생성할 수 있다. 이때 분할 음성 콘텐츠(550C), 분 할 인식 텍스트 콘텐츠(560C) 및 하나 이상의 분할 텍스트 콘텐츠(530C) 각각은 도시된 바와 같이 복수일 수 있 으나, 이하에서는 설명의 편의를 위해 각각이 단수의 콘텐츠인 것으로 가정하여 설명한다. 또한 제2 인공 신경 망은 단계 S1110에서 학습데이터에 기초하여 미리 학습되어 있을 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 분할 텍스트 콘텐츠(530C)와 분할 인식 텍스트 콘텐 츠(560C)의 유사도에 기반하여 분할 음성 콘텐츠(550C)의 정상 여부를 평가하고, 정상 여부에 기초하여 분할 음성 콘텐츠(550C)를 처리할 수 있다. 가령 음성 콘텐츠 생성 장치는 분할 텍스트 콘텐츠(530C)와 분할 인식 텍스트 콘텐츠(560C)의 유사도가 소 정의 임계 유사도 이상인 경우, 분할 음성 콘텐츠(550C)가 정상인 것으로 판단하고, 유사도가 소정의 임계 유사 도 미만인 경우, 분할 음성 콘텐츠(550C)가 정상이 아닌 것으로 판단할 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 분할 음성 콘텐츠(550C)가 정상인 것으로 판단되는 경우, 원본 콘텐츠 내에서의 분할 텍스트 콘텐츠(530C)의 위치에 기초하여, 분할 음성 콘텐츠(550C)의 순 번을 결정할 수 있다. 한편 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 분할 음성 콘텐츠(550C)가 정상이 아닌 것으로 판단되는 경우, 분할 텍스트 콘텐츠(530C)를 수정한 수정 분할 텍스트 콘텐츠(530C')를 획득하고, 학습된 제1 인공 신경망을 이용하여 수정 분할 텍스트 콘텐츠(530C')에 대응되는 수정 분할 음성 콘텐츠를 생성할 수 있다. 이때 생성된 수정 분할 음성 콘텐츠는 분할 음성 콘텐츠(550C)에 갈음하여 사용될 수 있다. 도 9는 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치가 분할 음성 콘텐츠(550D)를 평가하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 학습된 제2 인공 신경망을 이용하여 분할 음성 콘텐츠(550D)에 대응되는 분할 인식 텍스트 콘텐츠(560D)를 생성할 수 있다. 이때 분할 음성 콘텐츠(550D), 분 할 인식 텍스트 콘텐츠(560D) 및 하나 이상의 분할 텍스트 콘텐츠(530D) 각각은 도시된 바와 같이 복수일 수 있 으나, 이하에서는 설명의 편의를 위해 각각이 단수의 콘텐츠인 것으로 가정하여 설명한다. 한편 제2 인공 신경망에 대해서는 도 8에서 상세하게 설명하였으므로, 이에 대한 상세한 설명은 생략한다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 분할 텍스트 콘텐츠(530D)와 분할 인식 텍스트 콘텐 츠(560D)의 유사도에 기반하여 분할 음성 콘텐츠(550D)의 재녹음 여부를 평가하고, 재녹음 여부에 기초하여 분 할 음성 콘텐츠(550D)를 처리할 수 있다. 가령 음성 콘텐츠 생성 장치는 분할 텍스트 콘텐츠(530D)와 분할 인식 텍스트 콘텐츠(560D)의 유사도가 소 정의 임계 유사도 이상인 경우 분할 음성 콘텐츠(550D)의 재녹음이 필요 없는 것으로, 유사도가 소정의 임계 유 사도 미만인 경우 분할 음성 콘텐츠(550D)의 재녹음이 필요한 것으로 판단할 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 분할 음성 콘텐츠(550D)의 재녹음이 필요 없는 것으 로 판단되는 경우, 원본 콘텐츠 내에서의 분할 텍스트 콘텐츠(530D)의 위치에 기초하여, 분할 음성 콘텐츠 (550D)의 순번을 결정할 수 있다. 한편 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 분할 음성 콘텐츠(550D)의 재녹음이 필요한 것으로 판단된 경우, 다시 제2 사용자 단말에 분할 음성 콘텐츠(550D)에 대한 재녹음 음성 콘텐츠(550D')를 요청할 수 있다. 요청에 따라 수신된 재녹음 음성 콘텐츠(550D')는 분할 음성 콘텐츠(550D)에 갈음하여 사용될 수 있다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 하나 이상의 분할 콘텐츠(530C, 530D) 각각에 대응 되는 분할 음성 콘텐츠(550C, 550D)를 병합하여 음성 콘텐츠를 생성할 수 있다.(S1170) 도 10은 음성 콘텐츠 생성 장치가 음성 콘텐츠를 생성하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 상술한 과정에 따라 생성된 분할 음성 콘텐츠 (Partial Voice Contents 1, Partial Voice Contents 2, Partial Voice Contents 3, Partial Voice Contents N)들의 순번(Seq 1, Seq 2, Seq 3, Seq N)을 참조하여, 분할 음성 콘텐츠(Partial Voice Contents 1, Partial Voice Contents 2, Partial Voice Contents 3, Partial Voice Contents N)를 순차적으로 병합할 수 있다. 이때 '순번'은 상술한 바와 같이 원본 콘텐츠 내에서의 분할 텍스트 콘텐츠의 위치에 기초하여 결정되는 것 일 수 있 다. 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치는 원본 콘텐츠의 내용에 기초하여 상술한 과정에 따라 병합된 콘텐츠에 적어도 하나의 음향 콘텐츠를 추가할 수 있다. 이때 '내용'은 원본 콘텐츠에 포함되는 다양한 유형의 콘텐츠를 참조하여 결정되는 것 일 수 있다. 가령 음성 콘텐츠 생성 장치는 원본 콘텐츠에 포함되 는 이미지 콘텐츠에 나타나는 객체를 인식하고, 해당 객체에 대응되는 음향 콘텐츠를 추가할 수 있다. 예를 들 어 이미지 콘텐츠에 끓는 주전자 객체가 포함된 경우 음성 콘텐츠 생성 장치는 물 끓는 소리를 음향 콘텐츠로 추가할 수 있다. 다만 이는 예시적인것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 이상 설명된 본 발명에 따른 실시예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 컴퓨터로 실행 가능한 프로그램을 저장하는 것일 수 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명 령어가 저장되도록 구성된 것이 있을 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명에서 설명하는 특정 실행들은 일 실시 예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아 니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 상기 시스템들의 다른 기 능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재들 은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가 능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, \"필 수적인\", \"중요하게\" 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소가 아닐 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2020-0066474", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 시스템의 구성을 개략적으로 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 서버에 구비되는 음성 콘텐츠 생성 장치의 구성을 개략적으로 도 시한 도면이다.도 3 및 도 4는 본 발명의 일 실시예에 따른 제어부가 원본 콘텐츠 내의 텍스트를 수집하여 하나 이상의 분할 텍스트 콘텐츠를 생성하는 과정을 설명하기 위한 도면이다. 도 5 및 도 6은 본 발명의 일 실시예에 따른 제어부가 하나 이상의 분할 텍스트 콘텐츠(530, 530B) 각각에 대한 음성 변환 방식(540, 540B)을 선택하는 과정을 설명하기 위한 도면이다. 도 7은 본 발명의 일 실시예에 따른 제어부가 분할 음성 콘텐츠(550C, 550D)를 생성하는 과정을 설명하기 위한 도면이다. 도 8은 본 발명의 일 실시예에 따른 제어부가 분할 음성 콘텐츠(550C)를 평가하는 과정을 설명하기 위한 도면이다. 도 9는 본 발명의 일 실시예에 따른 제어부가 분할 음성 콘텐츠(550D)를 평가하는 과정을 설명하기 위한 도면이다. 도 10은 제어부가 음성 콘텐츠를 생성하는 과정을 설명하기 위한 도면이다. 도 11은 본 발명의 일 실시예에 따른 음성 콘텐츠 생성 장치에 의해 수행되는 음성 콘텐츠 생성 방법을 설 명하기 위한 흐름도이다."}
