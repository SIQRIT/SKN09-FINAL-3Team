{"patent_id": "10-2023-0058802", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0161529", "출원번호": "10-2023-0058802", "발명의 명칭": "성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버 및 그 방법", "출원인": "(주)한국플랫폼서비스기술", "발명자": "이준혁"}}
{"patent_id": "10-2023-0058802", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자로부터 추론용 데이터셋의 성별 및 나이 분류 기능의 추론 쿼리를 입력받는 입출력부;상기 쿼리를 분석하여 상기 쿼리의 기능을 달성하기 위한 복수의 세부 기능으로 추출하는 쿼리 분석부;데이터베이스로서, 복수의 학습 모델 테이블 및 데이터셋 테이블을 구비하는 저장부; 및상기 데이터베이스와 연동하고, 상기 학습 모델 테이블 및 상기 데이터셋 테이블을 이용하여 상기 복수의 세부기능의 딥러닝을 수행하는 프레임워크부;를 포함하는, 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버."}
{"patent_id": "10-2023-0058802", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버 및 그 방법에 관한 것으로서, 딥 러닝 추론에 의해 이미지로부터 인물의 성별 및 나이를 쿼리 분석에 의해 복수의 학습 모델로 분류하는 서버 및 그 방법에 관한 것으로, 성별 및 나이 분류 쿼리를 복수의 세부 기능으로 추출하여, 복수의 세부 기능의 우선 순 위에 따라 딥러닝 추론할 수 있다."}
{"patent_id": "10-2023-0058802", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버 및 그 방법에 관한 것으로서, 딥러닝 추론에 의해 이미지로부터 인물의 성별 및 나이를 쿼리 분석에 의해 복수의 학습 모델로 분류하는 서버 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0058802", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝 기술 기반의 지능을 제공하는 학습엔진을 생성하기 위해서는 딥 네트워크 설계, 학습 함수 설정, 파라미 터 튜닝 등 여러 가지 어려운 난관이 있다. 이러한 문제들은 딥러닝 전문가가 아니면 쉽게 할 수 없어, 누구나 쉽게 딥러닝 기반 학습엔진을 갖기 어렵다. 또한, 학습엔진을 생성할 때마다, 딥러닝의 공통적인 요소를 중복 사용하게 되어, 동일한 과정을 반복 수행해야 하는 문제가 있다. 그리고, 딥러닝 훈련 시 하나의 서버나 장치를 이용하는 경우, 그 데이터의 양에 따라 훈련 및 추론 시간이 많이 소요된다. 또한, 딥러닝 프레임워크 데이터베이스 서버를 통해 다양한 응용이 가능한데, 두 가지 이상의 기능에 대한 응용 이 필요할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2058124 B1"}
{"patent_id": "10-2023-0058802", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 딥러닝에 관한 전문적 지식이 없는 사용자라도 어려움 없이 사용자의 요청 쿼리에 의해 정보 데이터베이스에 저장된 데이터를 딥러닝 방식으로 학습하여 쿼리에 대응하는 데이터를 추론할 수 있도록 하며, 기 학습된 모델을 사용가능하고, 딥러닝 훈련 및 추론 시간을 적게 소요되도록 하며, 이미지로부터 인물의 성별 및 나이를 분류하는 응용이 가능한, 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버 및 방 법을 제공함에 있다."}
{"patent_id": "10-2023-0058802", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버는 사용자로부 터 추론용 데이터셋의 성별 및 나이 분류 기능의 추론 쿼리를 입력받는 입출력부; 상기 쿼리를 분석하여 상기 쿼리의 기능을 달성하기 위한 복수의 세부 기능으로 추출하는 쿼리 분석부; 데이터베이스로서, 복수의 학습 모 델 테이블 및 데이터셋 테이블을 구비하는 저장부; 및 상기 데이터베이스와 연동하고, 상기 학습 모델 테이블 및 상기 데이터셋 테이블을 이용하여 상기 복수의 세부 기능의 딥러닝을 수행하는 프레임워크부;를 포함하고, 상기 쿼리 분석부은 상기 추론 쿼리를 상기 복수의 세부 기능으로서 상위 그룹의 안면 검출 기능 및 하위 그룹 의 성별 및 나이 분류 기능으로 추출하고, 상기 복수의 학습 모델 테이블 중 기 학습된 안면 검출 학습 모델 테 이블, 성별 분류 학습 모델 테이블, 및 나이 분류 학습 모델 테이블을 선택하는 학습 모델 관리 모듈;를 더 포 함하고, 상기 프레임워크부는 상기 안면 검출 학습 모델 테이블, 성별 분류 학습 모델 테이블, 및 나이 분류 학 습 모델 테이블 각각에 연동하여 상기 복수의 세부 기능의 딥러닝 추론을 각각 수행하되, 상기 상위 그룹인 안 면 검출 학습 모델 테이블에 따른 안면 검출 학습 모델을 우선으로 딥러닝 추론할 수 있다. 또한, 상기 추론용 데이터셋을 추론용 데이터셋 테이블로 변환하는 데이터셋 관리 모듈; 및 상기 프레임워크부 에서 상기 안면 검출 학습 모델을 이용하여 상기 추론용 데이터셋 테이블에 구비된 원본 이미지의 안면이 있다 고 추론되면, 상기 안면 부분을 크롭하여 안면 이미지 박스를 생성하고, 상기 안면 이미지 박스의 고유 번호인 박스 ID에 상기 원본 이미지의 고유 번호인 이미지 ID를 연관시키고 상기 안면 이미지 박스의 위치 정보를 매핑 하는 맵핑 정보를 생성하는 보조 관리 모듈을 더 포함할 수 있다. 또한, 상기 보조 관리 모듈은 상기 프레임워크부에서 상기 성별 분류 학습 모델 테이블 및 상기 나이 분류 학습 모델 테이블에 따른 성별 분류 학습 모델 및 나이 분류 학습 모델을 이용하여 상기 안면 이미지 박스의 인물의 성별 및 나이에 대한 딥러닝 추론되면, 상기 딥러닝 추론된 성별 및 나이를 상기 박스 ID와 맵핑할 수 있다. 또한, 상기 데이터셋 관리 모듈은 상기 원본 이미지 및 상기 원본 이미지의 이미지 ID를 구비한 맵핑 정보의 상 기 안면 이미지 박스의 위치 정보를 이용하여, 상기 원본 이미지에 인물의 성멸 및 나이를 부기하여 결과 이미 지를 생성할 수 있다. 또한, 상기 쿼리 분석부는 추론용 데이터셋에 대해 메인 기능인 상기 쿼리 기능의 딥러닝 추론이 필요한지 감지 하는 전처리 감지 기능을 더 추출하고, 상기 저장부는 상기 전처리 감지 기능과 연관된 전처리 감지 학습 모델 테이블을 구비하고, 상기 추론용 데이터셋에 대해 상기 전처리 감지 기능의 딥러닝 추론이 수행되도록 하여, 상 기 추론용 데이터에 상기 메인 기능의 딥러닝 추론이 필요하다고 분류되면, 상기 추론용 데이터셋에 대한 상기 복수의 세부 기능의 딥러닝 추론되도록 하는 제어부를 더 포함할 수 있다. 또한, 상기 복수의 세부 기능에 따른 복수의 학습 모델 중 제1 학습 모델은 복수의 태스크를 구비하고, 상기 복 수의 태스크는 상기 제1 학습 모델 테이블에 구비된 네트워크 테이블의 복수의 행과 대응하고, 상기 복수의 태 스크의 각각은 상기 네트워크 테이블의 행번호에 대응하는 고유 번호를 각각 구비하고, 상기 복수의 태스크 중 일련의 제1 내지 제2 태스크를 복수의 분산 서버 중 제1 분산 서버에서 수행하도록 하여 딥러닝 추론을 분산 수 행하도록 하는 제어부;를 더 포함하고, 상기 복수의 분산 서버는 데이터베이스와 연동되는 딥러닝 프레임워크를 각각 구비하고, 상기 제1 학습 모델 테이블을 구비하고, 상기 제어부는 상기 제1 학습 모델 테이블의 고유 번호, 상기 제1 태스크의 직전 태스크인 제3 태스크의 제3 결과값 리스트, 및 상기 제2 태스크의 고유 번호와 대응하는 상기 네트워크 테이블의 제2 행번호를 상기 제1 분산 서버로 전송할 수 있다. 또한, 상기 제어부는 상기 복수의 분산 서버 중 제2 분산 서버로부터 상기 학습 모델 테이블의 고유 번호, 상기 복수의 태스크 중 제4 태스크의 제4 결과값 리스트를 수신하면, 상기 제4 결과값 리스트를 상기 복수의 태스크 중 일련의 최초 태스크부터 제4 태스크까지 수행된 결과값 리스트로 결정하고, 상기 복수의 네트워크 테이블 중 제5 행번호는 상기 제4 행번호의 직후에 배치된 것이고, 상기 제어부는 상기 제2 분산 서버로부터 태스크 지시 종료행인 제6 행번호를 더 수신하면, 상기 프레임워크부에서 상기 제4 결과값 리스트를 입력으로 하고, 상기 제 5 행번호 내지 상기 제6 행번호의 연산을 수행하도록 할 수 있다. 또한, 상기 학습 모델 관리 모듈은, 상기 복수의 세부 기능 중 제1 세부 기능에 관련된 기 학습된 제1 학습 모 델 테이블이 없는 경우, 상기 제1 세부 기능에 적합한 제2 학습 모델 테이블을 선택하고, 상기 제2 학습 모델 테이블은 이와 관련된 훈련용 데이터셋 테이블을 기초로 상기 제1 세부 기능의 딥러닝 훈련으로 상기 제1 학습 모델 테이블로 변환되고, 상기 딥러닝 훈련은 복수의 분산 서버와 분산 처리되어 수행되고, 상기 복수의 분산 서버는 데이터베이스와 연동되는 딥러닝 프레임워크를 각각 구비할 수 있다. 또한, 상기 훈련용 데이터셋의 배치 사이즈, 상기 제2 학습 모델 테이블, 및 상기 훈련용 데이터셋 테이블을 복 수의 분산 서버로 확산하는 제어부를 더 포함하고, 상기 딥러닝 프레임워크 응용 데이터베이스 서버는 상기 복 수의 분산 서버 중 제1 분산 서버로서 기능하고, 상기 제어부는 상기 훈련용 데이터셋 테이블의 데이터 순서를 랜덤하게 변경한 후 상기 배치 사이즈에 맞게 분할하여 배치 데이터셋 테이블로 변환하고, 상기 프레임워크부는 상기 제2 학습 모델 테이블에 속한 아키텍처 테이블을 이용하여 모델 아키텍처를 구축하고, 상기 제2 학습 모델 테이블에 속한 학습 파라미터 테이블을 초기화한 후 상기 모델 아키텍처에 할당하여 제2 학습 모델을 생성하고, 상기 제2 학습 모델에 대해 상기 배치 데이터셋 테이블의 복수의 미니 배치를 이용하여 딥러닝 훈련을 수행할 수 있다. 또한, 상기 프레임워크부는 상기 복수의 미니 배치 중 하나의 미니 배치에 대한 배치 학습이 종료되면 신 학습 파라미터를 도출하고, 상기 제어부는 상기 신 학습 파라미터를 상기 복수의 분산 서버의 나머지 분산 서버로 확 산하고, 상기 신 학습 파라미터가 생성되면, 상기 신 학습 파라미터와 상기 나머지 분산 서버에서 확산된 적어 도 하나의 학습 파라미터를 통합하여, 다음 배치 학습에 적용할 학습 파라미터로 업데이트하는 통합부를 더 포 함하고, 상기 통합부는 할당된 모든 에포크가 종료되면, 상기 프레임워크부에서 도출한 마지막 학습 파라미터와 상기 나머지 분산 서버에서 마지막으로 확산된 적어도 하나의 학습 파라미터을 통합하여 최종 학습 파라미터를 도출하고, 상기 제어부는 훈련된 모델 아키텍처 및 상기 최종 학습 파라미터를 학습된 상기 제1 학습 모델 테이 블로 변환할 수 있다. 본 발명의 일 실시예에 따른 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버의 추론 방법 은 사용자로부터 추론용 데이터셋의 성별 및 나이 분류 기능의 추론 쿼리를 입력받는 단계; 상기 추론 쿼리를 상위 그룹의 안면 검출 기능 및 하위 그룹의 성별 및 나이 분류 기능인 복수의 세부 기능으로 추출하는 단계; 기 학습된 안면 검출 학습 모델 테이블, 성별 분류 학습 모델 테이블, 및 나이 분류 학습 모델 테이블을 선택하 는 단계; 상기 상위 그룹에 해당하는 기능의 딥러닝 추론 및 상기 하위 그룹에 해당하는 기능의 딥러닝 추론 순 으로 딥러닝 수행하는 단계;를 포함할 수 있다. 또한, 상기 추론용 데이터셋을 추론용 데이터셋 테이블로 변환하는 단계; 상기 안면 검출 학습 모델 테이블에 따른 안면 검출 학습 모델을 이용하여 상기 추론용 데이터셋 테이블에 구비된 원본 이미지에 대한 안면 검출 기 능의 딥러닝 추론하는 단계; 상기 원본 이미지에 안면이 있다고 추론되면, 상기 안면 부분을 크롭하여 안면 이 미지 박스를 생성하는 단계; 상기 안면 이미지 박스의 고유 번호인 박스 ID에 상기 원본 이미지의 고유 번호인 이미지 ID를 연관시켜 맵핑 정보을 생성하는 단계; 및 상기 박스 ID를 구비한 맵핑 정보에 상기 안면 이미지 박 스의 위치 정보를 추가하는 단계;를 더 포함할 수 있다. 또한, 상기 성별 분류 학습 모델 테이블 및 상기 나이 분류 학습 모델 테이블에 따른 성별 분류 학습 모델 및 나이 분류 학습 모델을 이용하여 상기 안면 이미지 박스의 인물의 성별 및 나이에 대한 딥러닝 추론하는 단계; 상기 딥러닝 추론된 성별 및 나이를 상기 박스 ID를 구비한 맵핑 정보에 추가하는 단계; 및 상기 원본 이미지 및 상기 원본 이미지의 이미지 ID를 구비한 맵핑 정보의 상기 안면 이미지 박스의 위치 정보를 이용하여, 상기 원본 이미지에 인물의 성멸 및 나이를 부기하여 결과 이미지를 생성하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-0058802", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 쿼리 기반의 딥러닝 기술을 이용함으로써 딥러닝 프레임워크가 데이터베이스에 플러그인 형 태로 연결되어 사용자의 요청쿼리에 의해서 데이터베이스에 저장된 데이터를 사용하여 딥러닝 훈련 및 추론을 가능하여, 전문 지식이 없는 사용자가 딥러닝 훈련 및 추론을 이용할 수 있다. 딥러닝을 분산 처리하여, 딥러닝 수행에 소요되는 시간을 단축시킬 수 있다. 또한, 이미지로부터 인물의 성별과 나이를 딥러닝 추론을 통해 분류 할 수 있다."}
{"patent_id": "10-2023-0058802", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 또한 네트워크 상의 제1 구성요소와 제2 구성요소가 연결되어 있거나 접속되어 있다는 것은, 유선 또는 무선으로 제1 구성요소와 제 2 구성요소 사이에 데이터를 주고 받을 수 있음을 의미한다. 또한, 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 단순히 본 명세서 작성의 용이함만 이 고려되어 부여되는 것으로서, 그 자체로 특별히 중요한 의미 또는 역할을 부여하는 것은 아니다. 따라서, 상 기 \"모듈\" 및 \"부\"는 서로 혼용되어 사용될 수도 있다. 이와 같은 구성요소들은 실제 응용에서 구현될 때 필요에 따라 2 이상의 구성요소가 하나의 구성요소로 합쳐지 거나, 혹은 하나의 구성요소가 2 이상의 구성요소로 세분되어 구성될 수 있다. 도면 전체를 통하여 동일하거나 유사한 구성요소에 대해서는 동일한 도면 부호를 부여하였고, 동일한 도면 부호를 가지는 구성요소에 대한 자세 한 설명은 전술한 구성요소에 대한 설명으로 대체되어 생략될 수 있다. 또한, 본 발명은 본 명세서에 표시된 실시예들의 모든 가능한 조합들을 망라한다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적이지 않다. 본 명세서에 기술된 특정 형상, 구조, 기능, 및 특성의 일 실시예는 다른실시예로 구현될 수 있다. 예를 들어, 제1 및 제2 실시예에서 언급되는 구성요소는 제1 및 제2 실시예의 모든 기능을 수행할 수 있다. 도 1은 본 발명의 일 실시예에 따른 쿼리 기반 딥러닝 추론 시스템의 전체적인 구성을 개략적으로 나타낸 구성 도이다. 도 2는 본 발명의 일 실시예에 따른 데이터베이스 서버의 제어 구성도이다. 도 3은 본 발명의 일 실시 예에 따른 데이터 관리 구성도이다. 도 4는 본 발명의 일 실시예에 따른 데이터베이스 구조도이다. 도 5는 본 발명의 일 실시예에 따른 변환부의 제어 구성도이다. 도 6 및 도 7은 본 발명의 일 실시예에 따른 변환부의 변 환 동작도이다. 도 8은 본 발명의 실시 예에 따른 쿼리 기반의 기계학습 기술의 수행 흐름을 나타낸 흐름도이다. 도 9는 본 발명의 실시 예에 따른 쿼리 기반 딥러닝 추론 방법을 설명하기 위한 동작 순서도이다. 도 1을 참조하면, 본 발명의 일 실시 예에 따른 쿼리 기반 딥러닝 추론 시스템은 쿼리 기반의 기계학습 기술 을 적용할 수 있다. 이를 위해, 쿼리 기반 딥러닝 추론 시스템은 데이터베이스 서버 및 단말기를 포 함할 수 있다. 여기서, 쿼리 기반의 딥러닝 기술은 사용자가 단말기를 통해 데이터베이스(DB) 서버로 딥러닝 등의 요 청을 쿼리로 전송하면, 데이터베이스 서버가 데이터베이스 서버에 저장된 데이터를 이용하여 데이터베 이스 서버에 연결된 딥러닝 프레임워크가 기계학습, 딥러닝, 추론 등이 수행되는 기술을 의미할 수 있다. 딥러닝은 여러 비선형 변환기법의 조합을 통해 높은 수준의 추상화를 시도하는 머신러닝(기계학습) 알고리즘의 집합일 수 있다. 머신러닝은 인공지능의 한 분야로, 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하 는 분야를 의미할 수 있다. 인공지능은 인간의 지능이 갖고 있는 기능을 갖춘 컴퓨터 시스템을 뜻하며, 인간의 지능을 기계 등에 인공적으로 구현한 것을 의미할 수 있다. 본 명세서에서 '딥러닝'은 딥러닝 기술 그 자체에 한정되지 않고, 기계학습이나 인공지능까지 확장되어 해석될 수 있다. 단말기는 스마트 폰(Smart Phone), 휴대 단말기(Portable Terminal), 이동 단말기(Mobile Terminal), 개인 정보 단말기(Personal Digital Assistant: PDA), PMP(Portable Multimedia Player) 단말기, 텔레매틱스 (Telematics) 단말기, 내비게이션(Navigation) 단말기, 개인용 컴퓨터(Personal Computer), 노트북 컴퓨터, 슬 레이트 PC(Slate PC), 태블릿 PC(Tablet PC), 울트라북(ultrabook), 웨어러블 디바이스(Wearable Device, 예를 들어, 워치형 단말기(Smartwatch), 글래스형 단말기(Smart Glass), HMD(Head Mounted Display) 등 포함), 와이 브로(Wibro) 단말기, IPTV(Internet Protocol Television) 단말기, 스마트 TV, 디지털방송용 단말기, AVN(Audio Video Navigation) 단말기, A/V(Audio/Video) 시스템, 및 플렉시블 단말기(Flexible Terminal) 중 어느 하나이거나 조합된 것일 수 있다. 단말기는 서버 컴퓨터를 더 구비할 수 있다. 단말기는 데이터베이스 서버(이하, DB 서버)에 접속할 수 있다. 사용자나 관리자는 단말기를 통해 DB 서버에 쿼리를 보내거나 쿼리에 따른 결과를 받아볼 수 있다. DB 서버는 데이터베이스를 운용하거나, 데이터베이스와 연결되어 이를 제어하는 서버일 수 있다. DB 서버 는 통합 관리되는 데이터의 집합(데이터베이스) 및, 이를 관리하는 미들웨어가 포함된 개념을 의미할 수 있 다. 데이터베이스 서버는 데이터베이스 관리 시스템(DBMS)을 의미할 수 있다. 데이터베이스는 DB 서버 또는 데이터베이스 관리 시스템(DBMS)의 의미로 사용될 수도 있다. DB 서버는 쿼리에 따라 작업하거나 쿼리에 따른 결과를 생성하는 모든 장치를 의미할 수 있다. 쿼리는 SQL(Structured Query Language) 문법을 따를 수 있다. DB 서버의 데이터베이스는 관계형 데이터베이스인 것이 바람직하다. 단말기는 딥러닝 추론 쿼리를 입력하고, DB 서버로부터 쿼리에 대응된 추론 결과를 수신할 수 있다. 단말기는 쿼리를 통해서 DB 서버에 여러 기능들을 요청하고, DB 서버로부터 결과를 응답 받을 수 있다. 단말기는 쿼리를 통해서 DB 서버에 저장된 데이터를 확인 또는 수정하거나, 새로운 데이터를 추 가할 수 있다. 단말기는 쿼리를 통해서 DB 서버에 저장된 학습 모델을 확인 또는 수정하고 새로운 학습 을 위한 학습 모델을 생성할 수 있다. 단말기는 쿼리를 통해서 데이터와 학습 모델을 선택하고 파라미터를 설정하여 기계학습을 요청하고, 학습 중간 결과 및 최종 결과를 확인할 수 있다. 단말기는 쿼리를 통해서 데이터와 기학습된 학습 모델을 선택하여 기계추론을 요청하고, 추론 결과를 확인할 수 있다. 도 2를 참조하면, DB 서버는 제어부, 저장부, 프레임워크부, 변환부, 및 입출력부 를 포함할 수 있다. 입출력부은 자체적인 인터페이스 장치일 수 있다. 입출력부는 입력 장치와 출력 장치를 각각 별개로 구비할 수 있다. 출력 장치는 비디오 신호 및/또는 오디오 신호를 출력할 수 있다. 출력 장치는 모니터 등의 디스플레이 장치, 및/또는 스피커 등일 수 있다. 입력 장치는 유저가 DB 서버의 동작 제어를 위해 입력하는 입력 데이터를 발생시킬 수 있다. 입력 장치는 키보드, 키 패드, 터치 패드, 마우스 등의 사용자 조작 장치를 구비할 수 있다. 입력 및 출력 장치는 터치 스크린과 같이 하나로 구현될 수 있다. 입력 장치는 오디오 신호 및/또는 비디오 신호를 DB 서버에 입력할 수 있다. 입력 장치는 카메라와 마이크 등을 구비할 수 있다. 입력 장치는 센서 장치를 포함할 수 있다. 센서 장치는 온도 센서, 습도 센서, 밝기 센서, 먼지 센서, 압력 센 서, 진동 센서, 전압 센서, 전류 센서, 평행 센서, 자기 센서, 조도 센서, 근접 센서, 거리 센서, 기울기 센서, 가스 센서, 열감지 센서, 불꽃 감지 센서, 금속 감지 센서, 홀 센서 등을 구비할 수 있다. 센서 장치는 온도, 습도, 밝기, 먼지(탄소), 압력, 진동, 전압, 전류, 평행, 자기, 조도, 근접, 거리, 기울기, 가스, 열감지, 불꽃 감지, 금속 감지, 회전량 데이터를 생성할 수 있다. 입출력부는 DB 서버에 연결되는 모든 외부기기와의 인터페이스 역할을 수행할 수 있다. 외부기기의 예 로는, 유/무선 데이터 포트, 메모리 카드(Memory card) 등과 같은 카드의 소켓, 오디오 I/O(Input/Output) 단 자, 비디오 I/O(Input/Output) 단자 등이 있을 수 있다. 입출력부는 이러한 외부 기기로부터 데이터를 전 송받거나 DB 서버 내부의 데이터가 외부 기기로 전송되도록 할 수 있다. 입출력부는 통신 기능을 수행할 수 있다. 통신은 블루투스(Bluetooth), RFID(Radio Frequency Identification), UWB(Ultra Wideband), 지그비(ZigBee) 등 중 적어도 하나의 근거리 통신 프로토콜이 이용될 수 있다. 통신은 인터넷 접속을 포함할 수 있다. 입출력부는 통신을 통해 외부 장치 예를 들어, 단말기 와 데이터를 주고 받을 수 있다. 본 명세서에서 단말기를 별도의 장치로 도시하였지만, 입출력부는 단말기의 기능을 수행할 수 있 다. 즉, 단말기는 입출력부로 대체(생략)되어, 본 발명이 실시될 수 있다. 입출력부는 사용자의 통신수단(단말기)과의 통신을 담당하며, 사용자의 다양한 형태의 접속수단인 통신 장비 및 전산장비와의 통신프로토콜 및 네트워크상의 데이터 포멧을 제어할 수 있다. 데이터 포맷의 예로 ONNX(Open Neural Network exchange format), NNEF(Neural Network Exchange Format) 또 는 CSV(Comma-separated values) 등이 있을 수 있다. 입출력부는 사용자로부터 제어 명령이나 쿼리를 입력 받고, 사용자에게 결과를 제공하는 채널일 수 있다. 저장부는 DB 서버가 동작하는데 필요한 데이터와 프로그램 등을 저장할 수 있다. 저장부는 제어 부의 처리 및 제어를 위한 프로그램이 저장될 수 있고, 입력되거나 출력되는 데이터들의 임시 저장을 위한 기능을 수행할 수 있다. 저장부는 데이터를 데이터베이스로 저장하는 장치, 또는 데이터베이스를 그 자체를 의미할 수 있다. 저장부는 작업수행 및 기 작업이 수행되었던 내역 및 사용자 등에 대한 정보를 저장할 수 있다. 저장부 는 외부에 별도로 구비되는 저장 장치 또는 외부 전산망에 구비되는 저장장치 등과의 접속을 통하여 정보 및/또는 데이터를 저장할 수 있다. 빅데이터의 특징을 갖는 딥러닝 결과를 분산저장하거나, 외부에 별도로 저장 하여, 요청 시 호출하여 적용할 수 있다. 제어부는 DB 서버의 각 부의 동작을 제어하여 DB 서버의 전반적인 제어 기능을 실행할 수 있다. 제어부는 데이터베이스 내의 데이터를 접근하거나, 데이터를 관리하거나, 데이터를 테이블로 생성할 수 있 다. 데이터 관리는 데이터를 조회, 수정, 및/또는 업로드 등을 의미할 수 있다. 제어부는 사용자의 쿼리를 해석하고 실행하거나, 쿼리에 따른 작업이 수행되거나 결과를 제공하기 위한 모 든 기능을 제어할 수 있다. 도 3 및 도 4를 참조하면, 제어부는 쿼리 분석부, 데이터셋 관리 모듈, 학습 모델 관리 모듈 , 및 결과 관리 모듈을 구비할 수 있으며, 저장부는 쿼리 분석값, 데이터셋, 학습 모델, 및 학습 결과를 저장할 수 있다. 쿼리 분석부는 사용자가 요청한 쿼리를 해석 및/또는 분석하여 이를 쿼리 분석값으로 저장할 수 있다. 쿼리 분석값은 쿼리의 기능 및/또는 내용을 구비할 수 있다. 쿼리은 크게 훈련(학습)과 추론으로 분 류될 수 있다. 쿼리 분석값은 쿼리가 훈련인지 추론인지 구별되는 값을 저장할 수 있다. 쿼리의 기능은 사용자가 딥러닝 수행을 통해 얻으려는 결과값을 도출하기 위한 요청일 수 있다. 예를 들어, 문 자 인식하라는 쿼리는 이미지 데이터로부터 문자를 검출하여 문자의 내용을 분류하라는 기능일 수 있다. 쿼리의 기능은 사용자의 요청에 한정되지 않는다. 예를 들어, 사용자의 요청은 하나이지만, 이를 수행하기 위해 복수의 세부 기능이 필요할 수 있다. 쿼리 분석부는 쿼리를 분석하여 딥러닝 수행에 필요한 복수의 세부 기능을 추출할 수 있다. 복수의 세부 기능은 상위 범주와 하위 범주로 나뉠 수 있다. 예를 들어, 인물의 성별을 구별하라는 쿼리의 경우, 상위 범주의 이미지 데이터에서 안면을 검출하는 세부 기능과 하위 범주의 검출된 안면의 성별을 분류하 는 세부 기능으로 추출될 수 있다. 이 경우, 상위 범주의 세부 기능을 먼저 수행한 후에, 하위 범주의 세부 기 능을 수행할 수 있다. 쿼리의 내용은 기능 외에 부가적인 다양한 것일 수 있다. 예를 들어, 특정 학습 모델을 선택하거나, 훈련용 데 이터셋 또는 추론용 데이터셋을 지정 하는 것 등이 있을 수 있다. 데이터셋 관리 모듈에서 관리되는 데이터셋은 학습 및 추론에 사용될 동일한 형식을 가진 정보 또는 데이터의 집합을 의미한다. 정보 또는 데이터는 숫자, 문자, 이미지, 영상, 및 음성 등을 포함하며, 기계학습에 사용되는 모든 종류의 정보 또는 데이터일 수 있다. 데이터셋으로 군집시킬 수 있는 데이터의 동일한 형식이라 함은 확장자를 기준으로 정의할 수 있다. 예로, 이미지 정보의 경우, 그 확장자가 이미지를 나타내는 확장자일 경우 모두 동일한 카테고리의 데이터셋으로 군집 하게 되는 것이다. 여기서, 예를 위해 이미지 정보를 예를 들어 설명하고 있으나, 사용되는 데이터는 이미지뿐만 아니라 앞서 서술 한 숫자, 문자, 이미지, 영상, 음성 등 기계 학습에 사용될 수 있는 모든 종류의 데이터가 될 수 있다. 데이터셋 관리 모듈은 외부로부터 입력 받은 정보 또는 데이터(이하, '데이터')를 그 형식(예를 들어, 확 장자)으로 동일한 데이터셋으로 군집시키거나, 데이터의 내용으로 분류할 수 있다. 데이터의 내용으로 분류되는 경우, 데이터셋 관리 모듈은 동일한 데이터 형식으로 구분하는 데이터 분류 학습 모델을 이용할 수 있다. 데이터 분류 학습 모델은 DB 서버에 저장되어 필요시 호출되어 이용될 수 있다. 데이터셋 관리 모듈은 데이터셋이 학습 모델에 잘 적용되도록 데이터를 전처리할 수 있다. 데이 터 전처리는 데이터를 학습 모델의 텐서(벡터)에 맞도록 변환할 수 있다. 데이터 전처리의 예로 단어를 딥러닝 에 이용되는 사전의 인덱스 숫자로 변환하는 예가 있을 수 있다. 데이터셋 관리 모듈은 제1 형식의 데이터로부터 제2 형식의 데이터로 변환할 수 있다. 데이터셋 관리 모듈 은 제2 형식의 데이터를 1 군(군집)의 데이터셋으로 관리할 수 있다. 예를 들어, 데이터셋 관리 모듈(12 0)은 영상 데이터를 프레임 별로 이미지를 추출하여 일군의 데이터셋으로 변환(decoding)할 수 있다. 데이터셋 관리 모듈은 일련의 이미지를 영상으로 변환(encoding)할 수 있다. 일련의 이미지는 작업된 이미지일 수 있다. 즉, 데이터셋 관리 모듈은 동영상 데이터를 일군의 이미지 데이터셋으로 변환하고, 작업 처리(모자 이크)된 일군의 이미지 데이터셋을 영상으로 변환할 수 있다. 데이터셋 관리 모듈은 동영상 스트리밍 서비스를 할 수 있다. 예를 들어, 데이터셋 관리 모듈은 일련 의 이미지로부터 인코딩하여 동영상 스트리밍 서비스하거나, 저장된 동영상 파일로부터 스트리밍 서비스할 수 있다. 데이터셋 관리 모듈은 새로운 데이터셋을 생성할 때 새로운 테이블(데이터셋 테이블)을 생성하고, 데이터 셋 테이블에서 데이터를 조회 또는 수정하거나 새로운 데이터를 추가할 수 있다. 데이터셋 관리 모듈은 데이터베이스의 테이블에 접근하여 데이터를 조회할 수 있다. 데이터셋 관리 모듈 은 사용자가 작성한 쿼리를 통해서 데이터베이스의 데이터를 조회한 결과를 사용자에게 보여줄 수 있다. 데이터셋 관리 모듈은 사용자에게 부여된 권한에 따라 데이터를 수정할 수 있는 수준을 제한할 수 있다. 데이터셋 관리 모듈은 사용자로부터 수치데이터를 입력받거나, 하나 이상의 파일을 읽어서 데이터 업로드를 진행할 수 있다. 데이터셋 관리 모듈은 학습 데이터의 레이블을 작성할 수 있는 태깅기능을 제공할 수 있다. 본 명세서에서 데이터셋 테이블과 데이터셋은 서로 동일한 의미로 사용될 수 있다. 특히 관계형 데이터베이스에 서 데이터셋은 데이터셋 테이블로 저장된 관계형 데이터 형식의 데이터 집합을 의미한다. 관계형 데이터 형식은 테이블 형식을 이용하여 데이터를 정의하고 설명하는 모델을 의미한다. 이는 후술하는 학습 모델과 학습 모델 테이블, 학습 결과와 학습 결과 테이블 등에서도 동일하게 적용될 수 있다. 다만 양자의 실체 및/또는 포맷은 달라질 수 있다. 학습 모델(Learning Model; LM) 관리 모듈은 기계학습(딥러닝 등)에 사용되는 학습 모델 테이블을 관 리할 수 있다. 본 실시예에서 학습 모델 테이블은 아키텍처 테이블 및 학습 파라미터 테이블을 구비할 수 있다. 아키텍처 테이블은 네트워크 테이블 및 하이퍼 파라미터 테이블을 구비할 수 있다. 학습 모델 테이블은 프레임워크부에서 이용하는 학습 모델에 대응될 수 있다. 본 실시예에서 학습 모델(학습 네트워크 모델)은 인공지능 알고리즘 기반으로 데이터 셋에 기초하는 학습 될 수 있는 판단 모델로서, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 본 판단 모델은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있다. 판단 모델은 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 뉴런이 시냅스(synapse)를 통하여 신호를 주고 받는 뉴런의 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계를 형성할 수 있다. 본 판단 모델은 기계 학습(Machine Learning) 모델, 신경 망 모델, 및/또는 딥러닝(Deep Learning) 모델을 구비할 수 있다. 학습 네트워크 모델은 ANN(Artificial Neural Network, 인공신경망) 모델, DNN(Deep Neural Network) 모델, CNN(Convolution Neural Network, 컨벌루션 신경망) 모델, 및 RNN(Recurrent Neural Network) 모델 등의 모델 들 중 적어도 하나의 모델을 구현할 수 있다. 예시된 모델은 이에 한정되지 않는다. 예를 들어, LSTM(Long Short Term Memory Network), GRU(Gated Recurrent Units), GAN(Generative Adversarial Networks), SRGAN(Super-resolution GAN) 모델 등이 있을 수 있으며, 이러한 명칭에 한정되지 않는다. 일반적으로 학습 모델은 아키텍처(architecture) 및 파라미터를 포함할 수 있다. 아키텍처(모델 아키텍처)는 기계학습 모델의 구조를 의미한다. 아키텍처는 학습 모델의 구조에 해당하는 층 (layer)의 수, 유닛의 수, 레이어의 종류, 유닛이 연결되는 방법 등을 포함할 수 있다. 이를 아키텍처 구조로 표시할 수 있다. 아키텍처는 학습 모델 테이블의 아키텍처 테이블에 대응될 수 있다. 아키텍처의 구조는 네트워크 모델 또는 네 트워크로 지칭될 수 있다. 아키텍처 구조는 학습 모델 테이블의 네트워크 테이블에 대응될 수 있다. 아키텍처는 아키텍처 구조에 하이퍼 파라미터가 할당된 것을 의미할 수 있다. 아키텍처를 구축하려면, 네트워크 테이블과 하이퍼 파라미터 테이블이 필요할 수 있다. 파라미터는 하이퍼 파라미터와 학습 파라미터를 구비할 수 있다. 하이퍼 파라미터는 입출력과 모델 내부를 정의하고, 학습률, 최적화 방법(학습 방법; 옵티마이저(optimzer)), 레이어의 종류, 입출력 크기, 계산에 필요한 파라미터 등을 구비할 수 있다. 하이퍼 파라미터는 아키텍처가 구 현되도록 할 수 있다. 하이퍼 파라미터는 아키텍처의 일 구성요소로 작동될 수 있다. 하이퍼 파라미터는 휴리스 틱 기반, 즉 사람이 직접 설정할 수 있다. 또한, 하이퍼 파라미터의 최적화는 별도의 옵티마이저 모듈로 구현될 수도 있다. 학습 파라미터는 웨이트(weight) 및/또는 바이어스(bias)를 구비할 수 있다. 웨이트는 입력된 데이터와 상호 작 용에 사용되는 값으로, 모델 아키텍처에 상응하는 모델 웨이트가 존재할 수 있다. 학습 파라미터는 옵티마이저 에 의해 값이 변화될 수 있다. 학습 파라미터는 단순히 '파라미터'라고 지칭될 수 있다. 옵티마이저는 학습 모델이 원하는 기능을 가지도록 학습 파라미터를 변화시킬 수 있다. 학습(딥러닝) 또는 훈련 은 이러한 학습 파라미터의 변화를 의미할 수 있다. 옵티마이저는 프레임워크부나 별도의 요소에 의해 구 현될 수 있다.하이퍼 파라미터 및 학습 파라미터는 상술한 하이퍼 파라미터 테이블 및 학습 파라미터 테이블과 대응될 수 있 다. 학습 모델 관리 모듈은 지원되는 레이어를 추가하고 레이어 파라미터(레이어의 종류, 입출력 크기, 계산에 필요한 파라미터)를 조정하여 새로운 네트워크 모델을 생성할 수 있다. 학습 모델 관리 모듈은 기존에 작성된 네트워크 모델 리스트를 조회할 수 있다. 학습 모델 관리 모듈(13 0)은 기존에 작성된 네트워크 모델에 새로운 레이어를 추가하여 새로운 네트워크 모델을 생성할 수 있다. 이는 하이퍼 파라미터의 조정을 통해 구현될 수 있다. 이러한 일련이 작업들은 사용자의 쿼리에 의해 착수될 수 있다. 학습 모델 관리 모듈은 네트워크 모델을 시각화하여 보여주는 기능을 제공할 수 있다. 이를 통해, 사용자 는 히든 레이어의 구조를 쉽게 살펴볼 수 있다. 학습 모델은 이외에 학습에 사용할 피드백 신호를 정의하는 손실 함수 및 학습 진행 방식을 결정하는 별도 의 옵티마이저 모듈을 더 구비할 수 있다. 손실 함수 및 옵티마이저는 프레임워크부에 구비될 수 있다. 학습 모델은 데이터베이스에서 관계형 데이터 형식인 학습 모델 테이블 포맷으로 저장될 수 있다. 학습 모델의 기능의 예로, 사용자에 의해 입력된 텍스트를 인식하거나, 이미지/오디오/동영상 등에 포함된 음성 이나 텍스트를 인식하거나, 인식된 음성이나 텍스트로 사용자의 의향을 분석하는 기능 등이 있을 수 있다. 학습 모델 관리 모듈은 복수의 학습 모델 테이블 중 쿼리에 적합한 특정 학습 모델 테이블을 선택할 수 있 다. 학습 모델 관리 모듈은 쿼리의 내용 또는 모델 선택 정책 중 어느 하나에 의해 학습 모델 테이블(23 0)을 선택할 수 있다. 쿼리의 내용에 사용자가 지정한 특정 학습 모델이 있는 경우, 학습 모델 관리 모듈은 해당 학습 모델 테이 블을 선택한다. 예를 들어, 훈련 쿼리에 따라 학습된 학습 모델로 추론하라는 쿼리의 내용일 경우, 학습 모델 관리 모듈은 해당 학습 모델 테이블을 선택하는 것이 바람직하다. 모델 선택 정책은 쿼리의 기능 및/또는 쿼리에 연관된 데이터셋 테이블을 기초로 학습 모델 테이블을 선택하는 지침일 수 있다. 예를 들어, 모델 선택 정책에 따라, 학습 모델 관리 모듈이 복수의 학습 모델 테이블의 기능들 중 상기 쿼리 기능과 유사한 학습 모델 테이블을 선택하도록 할 수 있다. 또한, 모델 선택 정책에 따라, 학습 모델 관리 모듈이 상기 쿼리 기능과 유사하고, 상기 쿼리와 연관된 데이터셋 테이블과 유사한 테이터 구조를 가지는 학습 모델 테이블을 선택하도록 할 수 있다. 학습 모델의 주요 기술은 바이너리 분류, 다중 분류, 회귀 분석, 수치 예측, 시계열 예측, 감정 분석, 클러스터 링, 비정상 탐지, 자원 축소, 강화 학습 등이 있을 수 있다. 모델 선택 정책에 따라, 학습 모델 관리 모듈(13 0)은 쿼리의 기능에 맞는 기술을 가지는 학습 모델 테이블을 선택할 수 있다. 학습 모델 관리 모듈은 기존에 학습 했던 학습 모델 테이블을 선택할 수 있다. 이 경우, 학습 모델 관리 모듈은 기존 학습 모델이 제대로 작동하는지 검증 및 테스트를 하여, 제대로 작동하면 딥러닝 훈련 결과로 기존의 학습 모델 테이블을 산출할 수 있다. 검증 및 테스트 결과 제대로 작동하지 않거나 입력 데이터의 포맷 이나 개수가 다를 경우, 선택한 학습 모델 테이블을 새롭게 딥러닝 훈련하여 학습된 학습 모델 테이블을 산출할 수 있다. 도 4를 참조하면, 학습 모델 테이블은 네트워크 테이블(qml_network_t)을 구비할 수 있다. 아키텍처는 데이터베 이스에서 관계형 데이터 형식인 네트워크 테이블(qml_network_t) 포맷으로 변환되어 저장될 수 있다. 네트워크 테이블(qml_network_t)은 학습 모델의 아키텍처로 변환될 수 있다. 이는 변환부에 의해 변환될 수 있 다. 네트워크 테이블은 복수의 서브-네트워크 테이블(qml_s_network_t)을 구비할 수 있다. 예를 들어, Multi GPU(N 개)로 네트워크 모델을 학습하는 경우에 N 개의 서브-네트워크 테이블이 구비될 수 있다. 네트워크 모델을 추론 하는 경우에 1개의 서브-네트워크 테이블이 구비될 수 있다. 네트워크 테이블 또는 서브-네트워크 테이블은 네트워크를 구성하는 레이어에 관한 복수의 레이어 테이블 (qml_layer_t)을 구비할 수 있다. 학습 모델의 아키텍처의 구조를 구성하는 레이어는 레이어 테이블 (qml_layer_t)로 변환되어 저장될 수 있다. 레이어 테이블(qml_layer_t)은 학습 모델의 레이어로 변환될수 있다. 레이어 테이블(qml_layer_t)은 복수의 텐서(tensor) 테이블(qml_tensor_t)을 구비할 수 있다. 텐서 테이블은 NCHW 포맷으로 구성된 4차원 텐서일 수 있다. 텐서 테이블은 dtype, qml_shape_t, data, name 등이 구비될 수 있다. 텐서 테이블 및 학습 모델의 텐서는 서로 변환될 수 있다. 학습 모델의 파라미터는 파라미터 테이블로 저장될 수 있다. 학습 모델의 파라미터와 파라미터 테이 블은 서로 변환될 수 있다. 이는 변환부에 의해 변환될 수 있다. 본 발명에서 미리 설계된 DB 스키마에 따라 모델 아키텍처와 모델 웨이트 등이 DB 테이블에 저장될 수 있다. 기 설계된 DB 스키마는 서로 유사한 데이터셋 테이블과 학습 모델 테이블을 쉽게 분류할 수 있다. 이는 DB 서버 가 새로운 데이터셋을 입력 받으면, 저장되어 있는 관계형 데이터 형식의 학습 모델 중 유사한 학습 모델을 호출하여 새로운 데이터셋에 적용하게 할 수 있다. 예를 들어, '속성(attribute), 도메인(domain), 차수(degree), 튜플(tuple), 카리널리티(cardinality), 릴레이 션(realtion), 키(key), 후보키(candidate key), 기본키(primary)' 등의 테이블의 구성요소의 외형인 차수, 내 용인 속성 및 도메인 등의 유사도에 따라 입력된 데이터셋과 기저장된 학습 모델의 유사도를 정할 수 있다. 이 러한 유사도 판단은 학습 모델 관리 모듈이 할 수 있다. 이는 최초의 관계형 데이터 형식의 학습 모델이 생성되고 사용되어 데이터베이스에 저장된 후, 유사한 형식의 데이터셋이 입력되어 관계형 데이터 형식의 학습 모델을 생성해야 할 경우, 데이터베이스에 저장되어 있는 기존 의 관계형 데이터 형식의 모델 중 유사도가 높은 모델을 검색하여 이를 호출한 후 적용할 수 있다. 이로 인해, 적합한 학습 모델의 생성 시간을 단축하고, 컴퓨팅 자원을 효율적으로 사용할 수 있다. 학습 모델 테이블은 구성요소가 관계형 데이터 형식으로 연결되어, 학습 모델 테이블은 사용자 또는 관리자가 작업 수행시 구성요소가 누락되지 않도록 가이드 역할을 할 수 있다 프레임워크부는 데이터베이스 구조의 테이블로 저장된 요소들은 그대로 이용하거나, 프레임워크부에 서 사용하기 적합하도록 조작한 후 사용할 수 있다. 이러한 조작은 프레임워크부 또는 변환부에서 수 행될 수 있다. 결과 관리 모듈은 기계학습이 진행되는 동안 발생되는 각 레이어의 아웃풋, 중간 출력값, 파라미터 값, 계 산이 진행되는 모델의 평가지표 값(딥러닝 함수의 학습 손실값), 및 기계추론 결과값 등의 학습 결과를 데 이터베이스에 저장하거나 호출하여 사용자가 확인할 수 있도록 관리할 수 있다. 저장부는 데이터셋 테이블, 학습 모델 테이블, 및 학습 결과 테이블 이외에 프로젝트 테이 블(Project Table), 작업 테이블(Job Table), 및 공통 테이블(Common Table)을 더 구비할 수 있다. 작업 테이블은 사용자 정보, 프로젝트의 상태, 로그 등을 포함할 수 있다. 공통 테이블은 레이어 타입, 오류 코 드 등 룩업 테이블을 포함할 수 있다. 프로젝트 테이블은 학습 모델 테이블로부터 복사된 실제 학습 모델이나 추론을 진행할 프로젝트 정보가 저장될 수 있다. 프로젝트가 생성된 후 학습 모델 테이블과 별개의 구성을 가지게 되므로, 프로젝트에 사용된 기반 네 트워크가 수정되더라도 기구축된 학습 모델에 영향이 없다. 저장부는 개수가 많고 가변적인 데이터(입출력 데이터 및 가중치 정보)는 BLOB(Binary Large Object) 또는 text 타입으로 저장할 수 있다. 저장부는 개수가 적고 가변적인 데이터(각 레이어 파라미터 등)는 레코드 를 분할하여 저장할 수 있다. 제어부는 기계학습(훈련) 및 기계추론에 사용된 모든 입출력 데이터가 저장되도록 하고, 기계학습 및 기계 추론에 사용된 모델이 저장되도록 할 수 있다. 제어부는 사용자의 쿼리 요청에 대응하는 프로시저 (procedure)를 제공하여, 사용자 요청에 의한 기계학습을 수행할 수 있다. 프로시저는 인서트 네트워크(Insert Network), 인서트 레이어(Insert Layer), 메이크 프로젝트(Make Project), 입력 데이터 로더(Input Data Loader), 네트워크 초기화(Init Network), 트레인(Train), 모델 저장(Save Model) 및 테스트(Test)를 포함할 수 있다. 인서트 네트워크는 네트워크(아키텍처) 이름, 네트워크 타입, 데이터셋 이름, 옵티마이저 타입, 옵티마이저 파 라미터, 학습률, 배치 크기, 학습 횟수, 출력 레이어 인덱스를 포함하는 네트워크 테이블을 생성할 수 있다. 인서트 레이어는 네트워크 아이디, 레이어 이름, 레이어 타입, 레이어 인덱스, 레이어 파라미터, 입력 레이어 인덱스를 포함하는 레이어 테이블을 등록할 수 있다. 메이크 프로젝트는 프로젝트 이름, 데이터셋 이름, 네트워크 이름, 학습 또는 추론 플래그, GPU 개수를 포함하 는 프로젝트를 생성할 수 있다. 입력 데이터 로더는 사용자 입력의 선택(레이어 인덱스, 쿼리 타입(학습 테이블, 학습 데이터, 검증 테이블, 검 증 데이터)에 따라 데이터를 입력할 수 있다. 네트워크 초기화는 네트워크 모델을 구성할 수 있다. 트레인은 프로젝트 아이디, 학습 세대 수, 배치 사이즈, 이어서 학습 여부, 저장 간격, 검증 간격, GPU 동기화 간격을 포함하는 학습을 시작할 수 있다. 모델 저장은 프로젝트 테이블의 네트워크 정보를 네트워크 테이블로 복사(프로젝트 이름, 네트워크 이름)할 수 있다. 테스트는 프로젝트 아이디, 모든 레이어의 결과 저장 여부 플래그를 포함하는 추론을 시작할 수 있다. 프레임워크부는 다양한 기계학습 프레임워크 또는 딥러닝 프레임워크을 이용하여 기계학습을 수행할 수 있 다. 프레임워크는 응용 프로그램을 개발하기 위한 여러 라이브러리나 모듈 등을 효율적으로 사용할 수 있도록 하나 로 묶어 놓은 일종의 패키지일 수 있다. 개발자 또는 관리자는 이미 검증된 수많은 라이브러리와 사전 학습이 완료된 다양한 딥러닝 알고리즘을 프레임워크를 통해 빠르고 손쉽게 사용할 수 있다. 딥러닝 프레임워크는 TensoFlow, Torch/PyTorch, Deeplearing4j, CNTK(MICROSOFT COGNITIVE TOOLKIT), Keras, ONNX(Open Neural Network Exchange), MXNet, Caffe, QML(Quantum Machine Learning) 등이 있을 수 있다. 프레임워크부는 DB 서버에 플러그 인으로 설치된 딥러닝 프레임워크일 수 있다. 이는 데이터베이스 연 동 프레임워크(딥러닝 프레임워크), 데이터베이스 응용 프레임워크(딥러닝 프레임워크)와 같이 표현될 수 있다. 프레임워크부는 DB 서버의 제어부의 호출로 실행될 수 있다. 프레임워크부는 호출될 때 제 어부로부터 각종 데이터를 인자로 받아 수행결과를 반환할 수 있다. 프레임워크부는 관계형 데이터 포맷으로 정의된 네트워크 모델을 해석하여 프레임워크 내부에 네트워크를 구성할 수 있다. 이러한 해석은 변환 부에서 실행될 수도 있다. 프레임워크부는 제어부로부터 학습 파라미터와 학습 데이터를 인자로 받아 프레임워크 내부에 구성된 네트워크의 학습을 수행하고 학습결과를 반환할 수 있다. 프레임워크부는 제어부로부터 입력 데이터 를 인자로 받아 프레임워크 내부에 구성된 네트워크를 이용하여 기계추론을 수행하고 결과를 반환할 수 있다. 프레임워크부는, 쿼리를 입력받으면, DB 서버에 저장된 학습 모델에 대한 확인, 수정, 및 새로운 학습 을 위한 학습 모델을 생성할 수 있다. 프레임워크부는 입력된 쿼리에 따라 정보 또는 데이터와 학습 모델 을 선택하고 학습 파라미터를 설정하여 기계학습을 할 수 있다. 프레임워크부는 학습 중간 결과 및 최종 결과를 제공할 수 있다. 프레임워크부는 입력된 쿼리를 통하여 데이터와 기 학습된 학습 네트워크 모델을 선택하여 기계추론을 실행하고, 그 추론 결과를 제공할 수 있다. 본 실시예에서 프레임워크부는 내부 프레임워크로 QML 모듈을 구비할 수 있다. 내부 프레임워크는 QML 모듈 이외에 다른 프레임워크를 구비하거나 더 구비할 수 있다. 이는 사용자에게 사용하고자 하는 다 양한 선택지를 제공할 수 있다. QML 모듈은 QML 플러그인 기능을 구현할 수 있다. QML 모듈은 딥러닝을 수행할 수 있는 프레임워크인 QML을 탑재할 수 있다. QML 모듈은 데이터베이스와 UDF(User Defined Function)를 통해 연결되며 호출에 의해 실행될 수 있다. 프레임워크에 정의된 함수들은 각각 UDF를 통해 데이터베이스에 등록되고, 등록된 UDF 호출을 통해서 프레임워 크가 실행될 수 있다. UDF에서 사용할 수 있는 인자 변수의 타입은 integer, real number, string으로 정해져 있다. 이러한 변수들은 QML에서 각각 사용될 수 있다. 예를 들어, 정수(integer) 타입은 네트워크 모델을 구성하는 필수 파라미터 중정수값, QML 내부에 정의된 구조체 메모리의 주소값 등에 이용될 수 있다. Real number 타입은 네트워크 모델을 구성하는 필수 파라미터 중 실수값 등에 이용될 수 있으며, string 타입은 개수가 가변적인 파라미터들과 binary데이터인 blob 데이터에 이용될 수 있다. QML 프레임워크는 채널 우선 데이터 포맷인 NCHW(N:batch, C:channel, H:height, W:width) 포맷을 따를 수 있 다. 레이어 종류는 ONNX에서 사용되는 레이어를 지원하며, 각 레이어에 정의된 파라미터들도 ONNX 포맷을 따를 수 있다. QML 프레임워크는 네트워크 모델을 학습가능하도록 백프로퍼케이션(Back-Propagation)알고리즘을 탑재할 수 있 다. QML 프레임워크는 그라디언트 계산 알고리즘과 모델파라미터(weight, bias)를 업데이트 시키기 위한 옵티마 제이션 알고리즘을 탑재할 수 있다. QML 모듈은 네트워크 모델(아키텍처)을 학습하는 방식중 네트워크 모델를 처음부터 학습시킨 후 각 레이어 의 가중치에 따라 초기화 알고리즘을 통하여 결정하는 Train from scratch 기법과 기 학습된 모델의 가중치 (import 기능을 통해 데이터베이스에 저장되거나, 이전 학습시도를 통해서 구한 가중치)를 읽어와서 레이어의 초기 가중치를 설정하고 학습을 진행하는 Fine tuning 기법을 지원할 수 있다. QML 모듈은 데이터베이스(DB 서버, 서버의 제어부 또는 저장부를 의미하며, 이하 동일)로부 터 받은 정보를 통하여 학습 및 추론을 수행할 수 있다. 데이터베이스로부터 받은 정보는 사용자 Query 질의를 통하여 받은 데이터 조합을 통하여 획득할 수 있다. 변환부는 특정 학습 모델을 다른 형식의 학습 모델로 변환할 수 있다. 구체적으로, 변환부는 특정 학 습 모델을 데이터베이스의 관계형 데이터 형식으로 변환할 수 있다. 변환부는 관계형 데이터 형식의 학습 모델을 특정 학습 모델이나 다른 학습 모델로 변환할 수 있다. 예를 들어, 변환부는 데이터베이스에 테이 블 타입으로 저장된 학습 모델 테이블을 내부 프레임워크인 QML 프레임워크로 변환하거나, 그 역으로도 가능하 다. 변환부는 학습 모델의 아키텍처, 레이어, 및 파라미터를 관계형 데이터 형식인 네트워크 테이블, 레이어 테이블, 및 파라미터 테이블로 변환하거나, 역변환할 수 있다. 도 6을 참조하면, 변환부는 QML 학습 모델 테이블을 QML 모듈에 적합한 학습 모델로 변환할 수 있다. 변환부은 필요시 데이터셋 테이블을 QML 모듈에서 사용하기 적합하게 변환할 수 있다. QML 모듈 (또는 프레임워크부)은 데이터셋과 변환된 QML 학습 모델을 이용하여 학습 및/또는 추론을 하여, 학 습 결과를 출력할 수 있다. 변환부는 QML 모듈에서 출력한 학습 결과를 관계형 데이터 형식으로 변환 하여 학습 결과(output) 테이블로 저장할 수 있다. 이러한 기능은 QML 모듈 및/또는 데이터셋 관리 모듈 중 적어도 어느 하나가 대신 수행하거나, 서로 분담하여 수행할 수 있다. 변환부는 외부 프레임워크와의 호환성을 위해 사용될 수 있다. 변환부는 기존 프레임워크의 기학습된 모델을 가져오거나 데이터베이스에서 정보 또는 데이터를 외부로 내보낼 때 ONNX(Open Neural Network Exchange) 모델 포맷 등의 다른 프레임워크 포맷으로 변환할 수 있다. 도 7을 참조하면, 변환부는 ONNX 모델 포맷에 정의된 망 구조(network structure) 및 모델 데이터(model data)를 데이터베이스의 네트워크 모델 포맷으로 변환(임포트; import)할 수 있다. 변환부는 반대로 데이 터베이스의 네트워크 모델을 ONNX 모델을 포함하는 구조화딘 포맷이나 CSV 파일로 변환(엑스포트; export)할 수 있다. 변환부는 ONNX 모델 포맷 이외에 Open Network Exchange(ONNX), Neural Network Exchange Format(NNEF) 및 하이퍼 파라미터와 학습 파라미터 파일을 구조화된 포맷으로 변환할 수 있다. 사용자는 변환된 ONNX 모델 및 구조화된 포맷을 사용자가 원하는 target 프레임 워크로 변환하여 사용할 수 있 다. 변환부를 통한 컨버팅 작업을 통하여 다른 형태의 딥러닝 프레임 워크에 네트워크 모델을 적용할 수 있다. 이를 통해, DB 서버는 데이터베이스에 저장되어 있는 관계형 데이터 형식의 모델을 호출하여 이와 유사한 형태의 데이터셋에 적용할 수 있다. 변환부는 이러한 변환 작업을 통해, 작업에 소요되는 시간을 최소화 할 수 있다. 도 8은 본 발명의 실시 예에 따른 쿼리 기반의 기계학습 기술의 수행 흐름을 나타낸 흐름도이다. 도 8을 참조하면, 본 발명의 실시 예에 따른 쿼리 기반의 기계학습 기술은 ONNX 포맷 또는 ONNX 포맷으로 변환 된 기학습된 모델을 컨버터를 통해서 QML 포맷으로 변환하고, 단말기로부터 학습 또는 추론 쿼리를 입력받 으며, 데이터베이스에서 정보를 QML 모듈로 전송하여, QML 모듈에서 훈련 및 추론을 수행할 수 있다. 그리고, 훈련(학습) 또는 추론 결과를 데이터베이스에 저장하면, 단말기는 데이터베이스에 저장된 결과를 확인할 수 있다. 이하, 구체적으로 설명한다. 단말기는 학습 모델을 입력(Import)하거나, 데이터베이스로부터 출력(Export)받을 수 있다(①). 학습 모델을 입력 또는 출력할 때, 변환부를 통하여 데이터베이스의 스키마 구조에 맞게 변환할 수 있다 (②). 데이터베이스는 쿼리를 해석하여 적절한 작업을 수행할 수 있다(③). 제어부는 단말기로부터 입력되는 쿼리의 QML의 유형을 분석하고, 이에 따른 결과를 QML 모듈로 전송할 수 있다. 보다 상세하게 설명하면, 입력된 쿼리의 언어 종류를 분석하고, 호환여부 또는 유사한 작업내 역이 저장부에 있는지 파악하는 등의 작업을 수행할 수 있다. 제어부는 각각의 운영체제 또는 기계학습 프레임워크(S/W) 별로 최적의 성능을 구현할 수 있는 프로그램을 선별하고, QML 모듈에 학습 및 추론을 요청할 수도 있다. 예를 들어, 제어부는 훈련이 요구되는 데이 터셋이 이미지일 경우 이미지 훈련에 최적의 성능을 발휘할 수 있는 기계학습 S/W를 선별하고, 선별된 S/W에 훈 련을 요청할 수 있다. 이와 함께, 제어부는 현재 훈련을 위해, 사용중인 서버의 자원을 확인하여, 자원의 규모에 맞게 훈련을 위 한 프레임워크를 적용하거나, 프레임워크 적용 시 구성요소의 선택적 적용을 시행할 수 있다. QML 모듈은 데이터베이스에서 플러그인을 수행하고, 데이터베이스로부터 받은 정보를 통해 훈련 및 추론을 수행할 수 있다(④). 단말기는 쿼리를 통해 데이터베이스로 훈련 또는 추론을 요청할 수 있다(⑤). 단말기는 데이터베이스의 테이블을 조회하여 학습 관련 정보를 조회할 수 있다(⑥). 학습 모델 데이터는 데이터베이스에 QML 스키마로 저장될 수 있다(⑦). 도 9는 본 발명의 실시 예에 따른 쿼리 기반 딥러닝 추론 방법을 설명하기 위한 동작 흐름도이다. 도 9를 참조하면, 본 발명의 실시 예에 따른 쿼리 기반 딥러닝 추론 시스템은, 단말기 및 DB 서버와 연 동하는 프레임워크부에서 쿼리 기반 딥러닝 추론 방법을 실행할 수 있다. 제어부는 사용자 단말기로부터 학습 쿼리(Call Train) 또는 추론 쿼리(Call Inference)를 입력 받을 수 있 다(S410). 제어부는 쿼리를 분석하여, 데이터셋과 적합한 학습 모델을 프레임워크부로 전송할 수 있다. 프레임워크부는 학습 쿼리 또는 추론 쿼리에 따라 네트워크 초기화(Init Network), 네트워크 구성 (Construct Network) 및 네트워크 갱신(Update Network)을 실행할 수 있다(S420). 프레임워크부는 모든 층에 대한 초기화(Initialize all layers)가 이루어지면 학습(Train) 또는 추론 (Test)을 실행할 수 있다(S430). 프레임워크부는 학습 종료시까지 배치 데이터를 획득하고(Get Batch Data) 반복(Iteration)하여 결과 및 모델을 저장 (Store Result & Model)할 수 있다. 프레임워크부는 테스트(Test)를 실행하고, 테스트 데이터를 획득하여(Get Test Data) 피드 포워드 (feedforward)하고 추론 결과를 저장(Store Result)할 수 있다. 프레임워크부는 학습 또는 추론의 종료 시 학습 결과 또는 추론 결과를 사용자 단말기로 제공할 수 있다(S440). 한편, 본 발명의 실시 예에 따른 쿼리 기반 딥러닝 추론 시스템은 다음과 같이 클라이언트, 회원, 데이터셋, 네트워크, 학습 모델, 학습 실행 등을 관리할 수 있다. [클라이언트 관리] 본 발명의 실시 예에 따른 쿼리 기반 딥러닝 추론 시스템은 사용자 단말기로 데이터셋과 기계학습 과정 을 관리하고 결과를 확인하기 위하여 기능을 제공할 수 있다. [회원 관리] 쿼리 기반 딥러닝 추론 시스템은 회원관리를 통해서 데이터베이스의 데이터, 네트워크 모델의 생성, 수 정 권한을 부여하고 변경 이력을 남길 수 있다. [데이터셋 관리] 쿼리 기반 딥러닝 추론 시스템은 데이터셋을 관리하기 위하여 새로운 테이블을 생성하고, 데이터를 조회, 수 정, 업로드하기 위한 기능을 제공할 수 있다. 새로운 데이터셋을 생성할 때 자동으로 새로운 테이블을 생성하고, 데이터를 업로드할 수 있다. 데이터베이스의 테이블에 접근하여 데이터를 조회거나 사용자가 작성한 쿼리를 통해서 데이터베이스의 데이터를 조회한 결과를 보여줄 수 있다. 권한에 따라 데이터를 수정할 수 있다. 사용자로부터 수치데이터를 입력 받거나, 하나 이상의 파일을 읽어서 데이터 업로드를 진행할 수 있다. 학습 데 이터의 레이블을 작성(tagging)하는 기능을 제공할 수 있다. [네트워크 관리] 쿼리 기반 딥러닝 추론 시스템은 다음과 같이 네트워크 모델을 관리하기 위한 기능을 제공할 수 있다. 지원 되는 레이어를 추가하고 레이어 파라미터를 조정하여 새로운 네트워크 모델을 생성할 수 있다. 기존에 작성된 네트워크 모델 리스트를 조회할 수 있다. 기존에 작성된 네트워크 모델에 새로운 레이어를 추가하여 새로운 네 트워크 모델을 생성할 수 있다. 네트워크 모델을 시각화하여 보여주는 기능을 제공할 수 있다. [학습 모델 관리] 쿼리 기반 딥러닝 추론 시스템은 다음과 같이 학습을 관리하기 위한 기능을 제공할 수 있다. 네트워크 모델 과 데이터셋, 학습 파라미터를 조절하여 학습 모델을 생성 또는 수정할 수 있다. 학습이 끝난 네트워크 모델을 컨버터 기능을 통해 출력할 수 있다. 현재 사용중인 서버의 자원을 확인할 수 있다. [학습 실행 관리] 쿼리 기반 딥러닝 추론 시스템은 다음과 같이 학습 및 추론을 수행하고 결과를 확인하기 위한 기능을 제공할 수 있다. 서버의 자원을 확인할 수 있다. 학습 및 추론 수행이 가능한지 여부를 사용자에게 알려줄 수 있다. 현 재 실행 또는 대기 중인 학습계획 리스트를 조회할 수 있다. 등록된 네트워크 모델과 데이터셋, 학습 파라미터 를 설정하여 학습계획을 생성할 수 있다. 현재 실행 또는 대기 중인 학습계획의 학습 파라미터를 확인할 수 있 다. 현재 실행 중인 학습계획의 중간 및 결과를 확인할 수 있다. 현재 실행 중인 학습계획을 멈출 수 있다. 대 기 중인 학습계획을 시작할 수 있다. 등록된 네트워크 모델과 데이터셋을 설정하여 추론계획을 생성할 수 있다. 실행된 추론 계획의 결과를 확인할 수 있다. 전술한 바와 같이 본 발명에 의하면, 딥러닝에 관한 전문적 지식이 없는 사용자라도 어려움 없이 사용자에게 필 요한 정보를 제공할 수 있도록 딥러닝 프레임워크가 정보 데이터베이스에 플러그인 형태로 연결되어, 사용자의 요청 쿼리에 의해 정보 데이터베이스에 저장된 데이터를 딥러닝 방식으로 학습하여 쿼리에 대응하는 데이터를 추론할 수 있도록 하는, 쿼리 기반 딥러닝 추론 시스템을 실현할 수 있다. 도 10은 본 발명의 다른 실시예에 따른 데이터베이스 연동 딥러닝 분산 시스템을 개략적으로 나타낸 구성도이다. 도 11은 도 10에 따른 메인 서버 및 분산 서버의 블록 구성도이다. 도 12는 메인서버의 데이터셋 및 분산서버의 훈련용 데이터셋을 도시한다. 도 13은 도 10의 시스템의 훈련 방법에 대한 순서도이다. 도 14는 도 10의 시스템의 추론 방법에 대한 순서도이다. 도 15 내지 도 17은 도13의 비동기식 분산 서버의 각기 다른 실시예에 따른 신호 흐름도이다. 도 18 및 도 19는 도 13이 동기식 분산 서버의 서로 다른 실시예에 따른 신호 흐름도이다. 도 20은 도 14의 분산 추론에 따른 신호 흐름도이다. 도 21은 학습 모델을 개략적으로 도시한다. 도 22은 도 20에 따른 중간 결과값 테이블의 일부를 도시한다. 도 23은 네트워크 테이블의 일부를 도시한다. 도 1 내지 도 9를 참고한다. 이하, 설명의 편의를 위해 다음과 같이 학습 모델을 정의하기로 한다. 학습 모델(학습 네트워크 모델)은 아키텍 처(모델 아키텍처)와 이에 할당된 학습 파라미터에 의해 구현될 수 있다. 아키텍처는 아키텍처 구조 및 이에 할 당된 하이퍼 파라미터에 의해 구축될 수 있다. 학습 모델과 학습 모델 테이블, 아키텍처와 아키텍처 테이블, 아 키텍처 구조와 네트워크 테이블, 하이퍼 파라미터와 하이퍼 파라미터 테이블, 및 학습 파라미터와 학습 파라미 터 테이블은 각기 서로 대응될 수 있다. 그리고, 학습 모델 테이블은 아키텍처 테이블 및 학습 파라미터 테이블을 구비할 수 있다. 아키텍처 테이블은 네트워크 테이블 및 하이퍼 파라미터 테이블을 구비할 수 있다. 아키텍 처 구조는 레이어 수, 유닛 수, 레이어 종류, 유닛 연결되는 방법을 의미할 수 있다. 유닛은 노드로도 칭할 수 있다. 최초의 노드들에 들어갈 값들은 입력 데이터셋 테이블일 수 있다. 마지막 노드 들에 들어갈 값들은 출력값일 수 있다. 중간 레이어(히든 레이어)의 노드들에 입력되는 입력 값 및 출력 값은 데이터셋 관리 모듈 또는 별도의 모듈에 의해 관리 및 저장될 수 있다. 프레임워크부 또는 내부 프레임워크(이하, '프레임워크부')는 선택된 학습 모델 테이블의 아키텍처 테이블(네트 워크 테이블 및 하이퍼 파라미터 테이블)을 기초로 모델 아키텍처를 구축하고, 학습 파라미터 테이블을 기초로 학습 파라미터를 상기 모델 아키텍처에 할당하여 상기 선택된 학습 모델 테이블과 대응하는 학습 모델을 생성할 수 있다. 프레임워크부는 생성된 학습 모델을 이용하여 훈련용 또는 추론용 데이터셋 테이블을 입력으로 딥러닝 훈련 또는 추론을 수행할 수 있다. 학습 모델 테이블과 학습 모델은 서로 연동되거나, 대응 관계, 변환 관계 등 으로 기술될 수 있으며, 이러한 용어에 한정되지 않는다. 도 10을 참조하면, 본 발명의 일 실시예에 따른 데이터베이스 연동 딥러닝 분산 시스템(이하, '훈련 분산 시스 템')은 쿼리 기반 딥러닝 프레임워크 응용 데이터베이스 서버(이하, '메인 서버'), 및 복수의 분산 서버 (41~43)를 포함할 수 있다. 메인 서버와 복수의 분산 서버(41~43)는 도 1 내지 도 9의 DB 서버의 기능을 적어도 일부를 구비할 수 있다. 메인 서버와 복수의 분산 서버(41~43)의 구성요소 중 DB 서버의 구성요소와 대응하는 구성요소에 대한 설명은 상술한 내용을 참고한다. 메인 서버와 복수의 분산 서버(41~43)는 네트워크로 연결되어 서로 통신을 서로 할 수 있다. 메인 서버는 복수의 분산 서버(41~43)를 관리하여, 딥러닝 학습을 분산하여 훈련할 수 있다. 도 11(a)를 참조하면, 메인 서버는 제어부, 저장부, 및 입출력부를 포함할 수 있다. 메인 서버는 변환부를 더 포함할 수 있다. 메인 서버는 프레임워크부을 더 포함할 수 있다. 도 11(b)를 참조하면, 분산 서버(41~43)는 제어부(100-N), 저장부(200-N), 프레임워크부(300-N), 및 입출력부 (370-N)를 포함할 수 있다. 분산 서버(41~43)는 변환부(360-N)를 더 포함할 수 있다. N은 자연수로, 복수의 분 산 서버(41~43) 중 특정 분산 서버를 다른 분산 서버와 구별하기 위해 사용되었다. 메인 서버 및 분산 서버(41~43)의 각 구성요소는 도 1 내지 도 9에서 기술한 내용을 참고한다. 메인 서버는 도 1 내지 도 9의 데이터베이스 서버의 기능을 구현하며, 분산 기능을 추가로 구현할 수 있다. 예를 들어, 메인 서버는 전체 분산 시스템의 관리 기능을 하며, 추가로 분산 기능을 수행할 수 있다. 다만, 설명의 편의를 위해 메인 서버의 분산 기능은 어느 한 분산 서버에서 수행하는 것으로 취급한다. 도 10에 도시된 메인 서버의 메인 프레임워크부, 및 각 분산 서버의 제1 내지 제3 프레임워크부(51~53)는 상술한 프레임워크부에 각각 대응되는 것으로, 구별의 목적으로 사용되었다. 복수의 분산 서버 중 어느 하나는 복수의 컴퓨터 시스템으로 구현될 수 있다. 메인 서버는 복수의 분산 서버(41~43) 각각이 동일한 환경에서 딥러닝 훈련을 하도록 복수의 분산 서버 (41~43)를 설정할 수 있다. 메인 서버는 복수의 분산 서버(41~43)가 데이터셋, 학습 모델, 프레임워크 중 적어도 일부를 동일하게 할 수 있다. 제1 내지 제3 분산 서버(41~43)는 각각 제1 내지 제3 프레임워크부(51~53)를 구비할 수 있다. 제1 내지 제3 프 레임워크부(51~53)는 훈련할 프레임워크(QML 모듈)를 구비하며, 동일한 학습 모델로 기계학습을 할 수 있다. 제 1 내지 제3 분산 서버(41~43)가 구비하는 각각의 학습 모델이 동일하다는 의미는 적어도 각각의 아키텍처가 동 일하다는 것을 의미할 수 있다. 각 분산서버(41~42)의 학습 파라미터(p1, p2, p3)는 상이할 수 있다. 각 분산서버(41~42)는 각각 학습 파라미터를 초기화하여 서로 다른 초기 학습 파라미터를 구비할 수 있다. 또는 메인 서버에 의해, 복수의 분산 서버(41~43)는 동일한 초기 학습 파라미터를 구비할 수 있다. 즉, 학습 파 라미터의 초기값은 메인 서버에 의해 결정되거나, 복수의 분산 서버(41~43) 각각에서 독립하여 결정될 수 있다. 초기값의 결정은 선택적이거나 데이터셋의 종류, 개수 등의 성격이나, 딥러닝할 목적 등 다양한 요소에 따라 결정될 수 있다. 제1 내지 제3 분산 서버(41~43)는 메인 서버에 구비된 데이터셋과 동일한 데이터셋을 구비할 수 있다. 동일 한 데이터셋은 메인 서버에서 복수의 분산 서버(41~43)로 데이터를 전송하거나, 메인 서버과 복수의 분 산 서버(41~43)의 특정 데이터가 미러링과 같이 동기화 방법에 의해 이루어질 수 있다. 이러한 데이터 이동(확 산) 방식은 데이터셋 뿐만 아니라 다른 자료(학습 파라미터 등)도 해당될 수 있다. 복수의 분산 서버(41~43) 각각의 데이터셋은 학습에 적합하게 학습용 데이터셋(DS)으로 변환될 수 있다. 메인 서버에서 데이터셋을 각각의 복수의 분산 서버(41~43)에 맞게 각각의 학습용 데이터셋(DS)으로 마련하여 전 송하는 것 보다 전송 효율이 더 좋을 수 있다. 브로드캐스팅으로 전송할 수 있기 때문이다. 복수의 분산 서버(41~43)는 도 12(a)의 데이터셋과 동일한 데이터셋을 수신한 후, 각 데이터를 이를 랜덤하게 순서를 변경하는 셔플한 후 배치 사이즈에 맞게 데이터를 미니 배치(b1~b10)로 분할하여 도 12의 (b-1)~(b-3)와 같이 학습용 데이터셋(DS)으로 변환할 수 있다. 배치 사이즈는 메인 서버로부터 수신할 수 있다. 프레임워크부는 상술한 QML 모듈 외에 통합부을 더 구비할 수 있다. 통합부는 분산처리되는 학습 과정 중 도출된 학습 파라미터들을 하나의 학습 파라미터로 통합할 수 있다. 통합부가 통합에 사용하는 함수는 다양할 수 있다. 예를 들어, 통합 함수는 도출된 복수의 학습 파라미터 각각에 가중치를 곱한 후 이들의 평균을 출력으로 할 수 있다. 통합부는 해당 분산 서버에서 도출된 학습 파라미터와 다른 분산 서버로부터 공유된 학습 파라미터 중 어 떤 학습 파라미터를 통합 함수(F)의 인수에 적용함에 있어서, 다양한 인수 정책(또는, '통합 정책')을 정할 수 있다. 옵션인 경우 사용자의 설정에 의해 선택될 수 있다. 통합 정책의 예는 다음과 같다. 통합부는 최신의 학습 파라미터를 통합 함수(F)의 인수로 이용할 수 있다. 즉, 한번 이용된 학습 파라미 터는 새로 공유 받지 않으면, 통합 함수(F)의 인수로 사용될 수 없다. 통합부는 타 분산 서버로부터 학습 파라미터를 받지 못한 경우, 타 학습 파라미터 없이 통합 함수(F)를 실행할 수 있다. 통합부는 자신의 학습 파라미터만 통합 함수(F)의 인수인 경우, 통합 함수(F)를 실행하지 않을 수 있다. 이 경우, 현 단계의 배치 학습에서 도출된 학습 파라미터는 그대로 다음 단계의 배치 학습에서 학습 파라미터로 이용될 수 있다. 통합부는 인수의 개수에 해당하는 모든 학습 파라미터들이 최신인 경우에만 통합 함수(F)를 실행하는 것, 및 타 학습 파라미터들 중 적어도 하나의 학습 파라미터가 최신인 경우에도 통합 함수(F)를 실행하는 것 중 어 느 하나일 수 있다. 인수가 3개인 것으로 가정하면, 전자에서 3개의 학습 파라미터가 모두 최신인 경우에 3개의 학습 파라미터가 인수로 이용되며 그렇지 않은 경우 자신의 학습 파라미터만을 인수로 이용된다. 후자에서 2개 의 학습 파라미터만 최신이라면 해당 2개의 학습 파라미터만 인수로 이용된다. 사용자는 통합 함수(F)의 인수를 전부인 경우에만 실행되거나, 일부인 경우에도 실행되는 것 중 어느 하나를 설정할 수 있다. 이하, 분산 환경에서의 딥러닝을 구체적로 설명한다. 제1 내지 제3 프레임워크부(51~53)는 동일한 아키텍처 구조와 하이퍼 파라미터로 학습 모델 아키텍처를 생성하 여 각각의 학습용 데이터셋(DS)을 이용하여 기계학습을 할 준비를 할 수 있다. 제1 내지 제3 프레임워크부 (51~53)는 학습 모델 중 웨이트나 바이어스와 같은 학습 파라미터(p1, p2, p3)의 초기값을 각각 설정할 수 있다. 딥러닝 훈련 준비가 완료되면, 복수의 프레임워크부(51~53) 각각은 딥러닝 훈련을 수행할 수 있다. 복수의 프레 임워크부(51~53) 각각은 각각의 학습용 데이터셋(DS)을 이용하여 딥러닝 훈련을 반복할 수 있다. 복수의 프레임 워크부(51~53) 각각은 미니 배치(b1~b10) 별로 훈련한 후 파라미터, 특히, 학습 파라미터를 업데이트(도출)할 수 있다. 본 명세서 전반에서, 각 미니 배치의 학습 또는 훈련을 배치 학습 또는 배치 훈련이라고 칭하기로 한 다. 예를 들어, 제1 프레임워크부은 초기 학습 파라미터(p1-1)와 제1 미니 배치(b1)를 이용하여 훈련하여 업데 이트(변환)된 학습 파라미터(p1-1')를 도출할 수 있다. 도출된 학습 파라미터(p1-1')는 제2 내지 제3 분산 서버 (42, 43)로 전송되거나 동기화되는 등 확산될 수 있다. 각 프레임워크부에서 도출된 학습 파라미터는 다양한 방식으로 확산(또는, '공유')될 수 있다. 이는 정책 또는 사용자 설정에 의해 달라질 수 있다. 예를 들어, 어떤 프레임워크부에서 매 배치 학습이 종료되면 해당 최신 학 습 파라미터가 다른 프레임워크부로 확산되는 즉시 공유 정책, 일정 시간이 경과되면 최신 학습 파라미터가 다 른 프레임워크부로 확산되는 시간 주기별 공유 정책, 일정 개수의 배치 학습이 종료되면 최신 학습 파라미터가 확산되는 학습 주기별 공유 정책, 메인 서버에서 정한 규칙 또는 랜덤한 내리는 지시에 의해 확산되는 기타 규칙 정책 등이 있을 수 있다. 제1 프레임워크부의 통합부는 제1 프레임워크부의 도출된 제1 학습 파라미터(p1-1') 외에 제2 및 제3 프레임워크부(52, 53)에서 도출된 제2 및 제3 학습 파라미터를 하나의 학습 파라미터(p1-2)로 통합할 수 있 다. 제1 프레임워크부의 통합부는 제1 프레임워크부에서 산출된 제1 학습 파라미터(p1-1')에 가중 치를 주는 등의 방법으로, 산출된 제1 학습 파라미터(p1-1')가 통합 함수의 출력에 더 많은 영향을 끼치도록 하 는 것이 바람직하다. 제1 프레임워크부는 학습 모델의 학습 파라미터를 통합된 학습 파라미터(p1-2)로 업데이트 한 후, 제2 미니 배치(b2)와 통합된 학습 파라미터(p1-2)를 이용하여 기계학습을 할 수 있다. 1회의 에포크(epoch) 즉, 모든 미 니 배치(학습용 데이터셋(DS))에 대한 학습이 완료되면 정해진 에포크 회수 또는 기설정된 정책에 따른 조건을 만족할 때까지 제1 프레임워크부는 학습을 반복할 수 있다. 1회의 에포크 동안 전체 데이터 크기를 배치 사 이즈로 나눈 개수 만큼의 학습 파라미터의 업데이트(이터레이션(iteration))가 이루어질 수 있다. 도 12(b- 1~3)을 참조하면, 데이터 크기는 80이고 배치 사이즈는 8이므로, 1회의 에포크 동안 10회의 이터레이션이 발생 된다. 제1 프레임워크부는 한 회의 에포크가 종료되면 학습용 데이터셋(DS)가 셔플되도록 할 수 있다. 제1 프레임워크부는 딥러닝 훈련의 하위 과정이 종료되면 아키텍처의 구조나 하이퍼 파라미터를 튜닝할 수 있다. 학습용 데이터셋은 훈련(train) 데이터셋, 검증(validation) 데이터셋, 및 테스트(test) 데이터셋으로 구 분될 수 있다. 딥러닝 훈련의 하위 과정의 예로, 위 구분된 데이터셋의 학습 과정(훈련, 검증, 테스트) 등을 있 을 수 있다. 제1 프레임워크부에서 튜닝된 하이퍼 파라미터는 다른 분산 서버로 확산될 수 있다. 다른 분산 서버는 튜닝 된 하이퍼 파라미터로 학습 모델 아키텍처를 재 구축할 수 있다. 하이퍼 파라미터의 튜닝은 한 분산 서버에서만 수행하는 것이 바람직하다. 새롭게 딥러닝 훈련의 다음 하위 과정이 시작되기 전에, 각각의 학습 파라미터들은 초기화 등 재조정되거나, 직 전 값을 유지될 수 있다. 도 13을 참조하면, 메인 서버는 사용자로부터 특정 기능의 딥러닝 학습 쿼리를 입력 받을 수 있다(S610). 메인 서버는 쿼리를 입출력부을 통해 직접 입력 받거나, 단말기를 통해 입력 받을 수 있다. 메인 서버는 학습 쿼리에 적합한 학습 모델 테이블을 선택할 수 있다(S620). 메인 서버는 쿼리를 분석 하여 적합한 학습 모델 테이블(이하, '학습용 모델 테이블(Tt)')을 복수의 학습 모델 테이블에서 선택할 수 있 다. 학습용 모델 테이블은 상술한 모델 선택 정책에 따라 메인 서버의 학습 모델 관리 모듈에 의해 선 택될 수 있다. 학습용 모델 테이블(Tt)은 변환부에 의해, 외부 프레임워크에서 생성된 학습 모델이 임포트(import)된 것 일 수 있다. 메인 서버는 학습용 데이터셋 테이블을 구비할 수 있다. 메인 서버는 학습용 데이터셋의 데이터를 쿼리 를 통해 입력 받거나, 다른 장치로부터 입력 받을 수 있다. 메인 서버는 복수의 분산 서버(41~43)가 초기화 가동되도록 할 수 있다(S630). 초기화 가동은 딥러닝 훈련의 분산이 적합하도록 분산 환경을 설정하고 복수의 분산 서버(41~43)에서 분산 훈련 이 가능하도록 준비하는 일련의 과정을 의미할 수 있다. 초기화 가동은 사용 가능한 복수의 분산 서버(41~43) 중 적절한 분산 서버를 선택하는 것을 포함할 수 있다. 초 기화 가동은 제1 내지 제3 분산 서버(41~43)와 네트워크 연결하고, 동기화, 비동기화, 및/또는 미러링 등으로 데이터가 제1 내지 제3 분산 서버(41~43)으로 확산되도록 할 수 있다. 분산 환경은 학습용 데이터셋(DS)의 배치 사이즈를 구비할 수 있다. 메인 서버는 분산 서버의 개수, 분산 서버의 사양, 학습용 데이터셋(DS), 및/또는 쿼리에 기초하여, 적절한 배치 사이즈를 결정할 수 있다. 분산 환경은 적절한 에포크(epoch) 횟수를 더 구비할 수 있다. 분산 환경은 학습 쿼리를 더 구비할 수 있다. 분 산 환경에 구비된 학습 쿼리는 분석된 내용, 예를 들어, 쿼리 기능일 수 있다. 메인 서버는 분산 환경, 학습용 모델 테이블(Tt), 및/또는 학습용 데이터셋(DS) 테이블을 제1 내지 제3 분 산 서버(41~43)로 확산할 수 있다. 분산 환경은 관계형 데이터 구조일 수 있다. 분산 환경은 학습용 모델 테이 블에 속할 수 있다. 데이터 확산 후, 제1 내지 제3 분산 서버(41~43)는 동일한 분산 환경, 학습용 모델 테이블(Tt), 및 학습용 데이 터셋(DS) 테이블을 구비할 수 있다. 제1 내지 제3 분산 서버(41~43) 각각은 각각의 학습용 데이터셋(DS) 테이블을 학습에 맞게 변경할 수 있다. 예 를 들어, 제1 분산 서버은 학습용 데이터셋(DS)의 데이터를 랜덤하게 순서를 변경한 후 배치 사이즈에 맞게 분할할 수 있다. 셔플 및 분할된 데이터셋은 배치 테이터셋 테이블로 저장될 수 있다. 배치 데이터셋 테이블의 각각의 배치 사이즈로 분할된 데이터셋을 '배치 데이터' 또는 '미니 배치'로 칭할 수 있다. 제1 내지 제3 분산 서버(41~43)는 각각의 학습 파라미터 테이블의 초기값을 서로 상이하게 하는 것이 바람직하 다. 다양한 학습 파라미터로 딥러닝 훈련을 수행할 수 있기 때문이다. 이를 위해, 제1 내지 제3 분산 서버 (41~43)는 학습 파라미터의 초기값을 무작위하게 정할 수 있다. 학습 파라미터의 초기화는 다양한 초기화 기술 이 이용될 수 있다. 초기화 가동된 제1 내지 제3 분산 서버(41~43) 각각은 상기 적합한 학습 모델 테이블에 속한 아키텍처 테이블을 플러그인으로 설치된 제1 내지 제3 프레임워크부(51~53)에 적합하게 모델 아키텍처를 구축할 수 있다(S640). 제1 내지 제3 프레임워크부(51~53)는 각각 구축된 모델 아키텍처에 초기 학습 파라미터를 할당(S650)하여, 학습 모델을 훈련할 준비를 할 수 있다. 제1 내지 제3 프레임워크부(51~53)(예를 들어, 각각의 QML 모듈)은 학습용 미니 배치와 학습 파라미터가 할당된 모델 아키텍처를 이용하여 훈련할 수 있다(S660). 각 분산 서버에서 업데이트된 각각의 학습 파라미터들의 통합을 위해, 각 분산 서버에서 독립하여 배치 학습하 는 비동기식 학습 방법과 주기적으로 배치 학습의 시작을 같이 하는 동기식 학습 방법이 있을 수 있다. 컴퓨팅 자원이나 사양 등에 의해 분산 서버들의 각 배치 학습들에 소요되는 시간이 다를 수 밖에 없다. 비동기식 학습 방법은 다른 분산 서버에서의 배치 학습 시관과 무관하게 쉬는 시간 없이 계속적인 배치 학습이 가능하여, 컴퓨팅 자원을 효율적으로 사용할 수 있다. 또한, 분산 서버들 중 어느 하나가 기계 학습을 최종적으 로 종료하면 나머지 분산 서버들도 종료하게 하는 정책을 이용하면, 총 학습 시간을 비동기식 방법에 비해 더 줄일 수 있다. 동기식 학습 방법은 각 분산 서버에서 같은 횟수의 배치 학습 후 업데이트된 최종 학습 파라미터를 서로 공유하 므로, 분산 학습의 정도나 효율이 비동기식에 비해 더 좋을 수 있다. 사용자는 기계 학습의 종류나 대상 등에 따라 동기식 및 비동기식 학습 방법 중 어느 하나를 선택할 수 있다. 이하, 동기식 및 비동기식 학습 방법에 대해 구체적으로 살펴본다. 도 15를 참조하여 비동기식 학습 방법의 일 실시예를 서술한다. 도 15는 앞서 언급한 '확산 정책' 중 각 프레임 워크부에서 매 배치 학습이 종료되면 해당 최신 학습 파라미터가 다른 프레임워크부로 확산되는 즉시 공유 정책 에 따른 실시예이다. 통합 정책은 적어도 하나의 타 학습 파라미터가 최신인 경우 인수로 사용되는 실시예이다. 제1 내지 제3 프레임워크부(51~53) 각각은 학습 종료시까지 각각의 배치 데이터(미니 배치(b1~b10))를 획득하고 (Get Batch Data) 반복(Iteration) 학습을 할 수 있다. 각 반복되는 각각의 학습을 '배치 학습'(배치 TR)으로 칭하기로 한다. 제1 프레임워크부는 제1.1 파라미터(p1.1)가 할당된 모델 아키텍처에서 제1.1 배치 학습을 진행할 수 있다. 제1.1 배치 학습이 완료되면, 제1 프레임워크부는 학습된 제1.1' 파라미터(p1.1')를 도출할 수 있다. 제1 프레임워크부는 학습된 제1.1' 파라미터(p1.1')를 제2 및 제3 분산 서버(42, 43)로 확산시킬 수 있다 (S810). 확산은 제1 분산 서버에서 나머지 분산 서버(42, 43)로 직접 전송하거나, 메인 서버를 통해 동 기화하거나 미러링할 수 있다. 데이터 관리의 효율 및 일관성 등을 위해 확산은 동기화나 미러링을 통해 이루어 지는 것이 바람직하다. 본 실시예에서 학습이 종료된 후, 제1 분산 서버의 학습 파라미터가 제2 및 제3 분산 서버(42, 43)로 확산된 것으로 도시하였지만 이에 한정되지 않는다. 예를 들어, 학습에 제일 많은 시간이 소 요된 제3 프레임워크부에서 학습이 종료된 후, 각자의 도출된 학습 파라미터(p1.1', p2.1', p3.1')가 다른 분산 서버(41, 42, 43)로 확산될 수 있다. 제1 프레임워크부의 통합부는 다른 분산 서버(42, 43)에서 배치 학습 후 도출된 최신의 학습 파라미터 (타 학습 파라미터들)와 제1 프레임워크부에서 도출된 학습 파라미터들을 적절한 변환(F)을 거쳐, 다음 배 치 학습에서 사용할 학습 파라미터로 통합할 수 있다. 타 학습 파라미터들 중 최근 종료된 배치 학습 이전에 통합부에서 사용된 것은 제외할 수 있다. 즉, 최신 의 학습 파라미터만 이용될 수 있다. 제1 프레임워크부는 통합된 학습 파라미터를 다음 배치 학습에 적용할 학습 파라미터로 업데이트하고, 다음 배치 학습을 할 수 있다. 예를 들어, 제1 프레임워크부에서 제1.1 배치 학습(TR)이 완료된 경우 다른 분산 서버(42, 43)에서 확산된 학습 파라미터가 없기 때문에, 제1 프레임워크부의 통합부는 제1.1' 파라미터(p1.1')를 다음 학습인 제1.2 배치 학습에 사용되는 제1.2 파라미터(p1.2)로 지정할 수 있다. 제1 프레임워크부는 제1.2 배치 학습이 완료된 후 도출된 제1.2' 파라미터(p1.2')를 중점으로 제2 및 제3 분산 서버(42, 43)에서 확산된 제2.1' 및 제3.1' 파라미터와 통합하여, 제1.3 파라미터(p1.3)를 산출할 수 있다. 통합 과정에서 사용되는 함수(F)는 해당 프레임워크부에서 도출된 학습 파라미터를 중점으로하고, 나머지 타 파 라미터들을 보조로하여 통합하는 것이 바람직하다. 예를 들어, 제1 프레임워크부의 통합부는 제1.2' 파라미터(p1.2')에 높은 가중치를 곱하고, 나머지 파라미터(p2.1', p3.1')에 낮은 가중치를 곱하여, 제1.2 파라 미터(p1.2)로 도출할 수 있다. 이때, 가중치들의 합은 1인 것이 바람직하다. 통합 함술(F)의 인수(학습 파라미 터들)의 개수나 학습 진행 정도에 따라, 각 인수에 곱해지는 가중치들 각각의 크기는 달라질 수 있다. 제1 프레임워크부는 제1.3 파라미터(p1.3)를 이용한 제1.3 배치 학습 후 제1.3' 파라미터(p1.3')를 도출할 수 있다. 제1.3 배치 학습 후 제1 프레임워크부는 제1.3', 제2.2', 및 제3.1' 파라미터(p1.3, p2.2, p3.1')를 최신의 파라미터로 구비한다. 이 때, 제3.1' 파라미터(p3.1')는 제1.2 배치 학습 완료 후 사용된 파라 미터로 이를 제외한다. 따라서, 제1 프레임워크부는 제1.3' 및 제2.2' 파라미터(p1.3', p2.2')를 통합하여 제1.4 파라미터(p1.4)로 산출할 수 있다. 확산된 학습 파라미터 중 최신의 것이어야 하는 것은, 제2 분산 서버의 제2.4 배치 학습 이후의 통합 단계 에서 그 예를 볼 수 있다. 제2.3 배치 학습 후 제2.4 배치 학습 종료 전까지, 제2 프레임워크부는 제1.3' 학습 파라미터(p1.3') 및 제1.4' 학습 파라미터(p1.4')를 제1 분산 서버로부터 확산 받을 수 있다. 제1.4' 학습 파라미터(p1.4')가 최신이므로, 제2 프레임워크부의 통합부는 제1.3' 학습 파라미터(p1.3') 대신 제1.4' 학습 파라미터(p1.4')를 사용하여 통합할 수 있다. 본 실시예에 따르면, 제1 내지 제3 분산 서버(41~43)는 각각의 배치 학습 및 학습 파라미터의 통합을 비동기적 으로 진행할 수 있다. 즉, 제1 분산 서버는 나머지 분산 서버들(42, 43)의 배치 학습의 종료와 무관하게 다 음 배치 학습을 진행할 수 있다. 이에 따라 복수의 분산 서버(41~43)의 컴퓨팅 자원을 효율적으로 사용할 수 있 다. 서버의 사양이나 작동 환경이 상이하여 각각의 배치 학습에 걸리는 시간은 상이할 수 밖에 없다. 본 동기식 학습 방법의 경우, 다른 분산 서버의 배치 학습이 종료되는 것을 기다리지 않아도 되기 때문이다. 최종 훈련된 학습 파라미터(p_last)는 제1 프레임워크부의 통합부에서 산출될 수 있다. 제1 프레임워 크부의 통합부는 제1.l', 제2.m', 및 제3.n' 학습 파라미터(p1.l', p2.m', p3.n') 중 적어도 하나를 기초로 통합(F')하여 훈련된 학습 파라미터(p_last)를 산출할 수 있다(l, m, n은 자연수). 본 최종 통합에 사용 되는 함수(F')는 훈련 중 사용되는 통합 함수(F)와 상이할 수 있다. 최종 통합 함수(F')는 각 인수에 차별적인 가중치를 주지 않는 것이 바람직하다. 최종 통합 함수(F')는 각 인수 에 가중치를 차별하더라도 상기 통합 함수(F) 보다 덜 차별하는 것이 바람직하다. 이 경우, 학습이 먼저 종료된 순으로 높은 가중치를 낮은 가중치로 주는 것이 바람직하다. 본 실시예에서 보듯이, 배치 학습이 가장 빨리 끝나는 제1 분산 서버에서 최종 학습 파라미터(p_last)를 도 출(통합)하는 것이 바람직하다. 즉, 'l' 값이 다른 'm', 및 'n' 보다 큰 값을 가진다. 제1 프레임워크부의 배치 학습이 종료(모든 에포크 종료)되면, 제2 및 제3 프레임워크부(52, 53)의 배치 학습은 남은 이터레이션과무관하게 종료될 수 있다. 이 경우, 같은 환경에서의 동기식 학습 방법 보다 시간이 단축될 수 있다. 도 16을 참조하여 비동기식 학습 방법의 다른 실시예를 서술한다. 도 16은 앞서 언급한 '확산 정책' 중 일정 시 간이 경과되면 최종 업데이트된 학습 파라미터가 다른 프레임워크부로 확산되는 시간 주기별 공유 정책에 따른 실시예이다. 통합 정책은 모든 학습 파라미터가 최신인 경우 인수로 사용되는 실시예이다. 도 15를 참조한다. 제1 내지 제3 프레임워크부(51~53) 각각은 학습 종료시까지 각각의 배치 데이터(미니 배치(b1~b10))를 획득하고, 배치 학습(배치 TR)을 반복할 수 있다. 제1 프레임워크부는 제1.1 파라미터(p1.1)가 할당된 모델 아키텍처에서 제1.1 배치 학습을 진행할 수 있다. 제1.1 배치 학습이 완료되면, 제1 프레임워크부는 학습된 제1.1' 파라미터(p1.1')를 도출할 수 있다. 도출 된 제1.1' 파라미터(p1.1')는 그대로 제1.2 배치 학습에 사용될 수 있다. 즉 제1 프레임워크부의 통합부 는 통합 함수(F)를 실행하지 않을 수 있다. 제1.2 파라미터(p1.2)는 제1.1' 파라미터(p1.1')와 동일한 값 을 가진다. 이와 같이 각 분산 서버(DS1~3)은 학습 파라미터가 확산되기 전까지 독립하여 배치 학습을 진행할 수 있다. 모든 프레임워크부(51~53)는 특정 주기 또는 메인 서버에서 지시하는 특정 시각에 최신의 학습 파라미터를 확산시킬 수 있다(S820). 본 실시예에서, 제1 프레임워크부는 제1.3' 학습 파라미터(p1.3')를, 제2 프레임 워크부는 제2.2' 학습 파라미터(p2.2')를, 및 제3 프레임워크부는 제3.1' 학습 파라미터(p3.1')를 다른 분산 서버로 확산시킬 수 있다. 학습 파라미터의 확산 이후, 각 프레임워크부는 다음 배치 학습 전에 학습 파라미터들을 통합할 수 있다. 예를 들어, 제1 프레임워크부는 제1.3 배치 학습이 완료된 후 도출된 제1.3' 파라미터(p1.3')를 중점으로 제2 및 제3 분산 서버(42, 43)에서 확산된 제2.2' 및 제3.1' 파라미터와 통합하여, 제1.4 파라미터(p1.4)를 산 출할 수 있다. 제2 프레임워크부는 제2.3 배치 학습이 완료된 후 도출된 제2.3' 파라미터(p2.3')를 중점으 로 제3 및 제1 분산 서버(43, 41)에서 확산된 제3.1' 및 제1.3' 파라미터와 통합하여, 제2.4 파라미터(p2.4)를 산출할 수 있다. 제3 프레임워크부는 제3.2 배치 학습이 완료된 후 도출된 제3.2' 파라미터(p3.2')를 중점 으로 제1 및 제2 분산 서버(41, 42)에서 확산된 제1.3' 및 제2.2' 파라미터와 통합하여, 제3.3 파라미터(p3.3) 를 산출할 수 있다. 최종 훈련된 학습 파라미터(p_last)는 제1 프레임워크부의 통합부에서 산출될 수 있다. 제1 프레임워 크부의 통합부는 제1.l', 제2.m', 및 제3.n' 학습 파라미터(p1.l', p2.m', p3.n')를 기초로 통합 (F')하여 훈련된 학습 파라미터(p_last)를 산출할 수 있다(l, m, n은 자연수). 본 최종 통합에 사용되는 함수 (F')는 훈련 중 사용되는 통합 함수(F)와 상이할 수 있다. 최종 통합 함수(F')는 각 인수에 차별적인 가중치를 주지 않는 것이 바람직하다. 최종 통합 함수(F')는 각 인수 에 가중치를 차별하더라도 상기 통합 함수(F) 보다 덜 차별하는 것이 바람직하다. 이 경우, 학습이 먼저 종료된 순으로 높은 가중치를 낮은 가중치로 주는 것이 바람직하다. 본 실시예에서 보듯이, 배치 학습이 가장 빨리 끝나는 제1 분산 서버에서 최종 학습 파라미터(p_last)를 도 출(통합)하는 것이 바람직하다. 즉, 'l' 값이 다른 'm', 및 'n' 보다 큰 값을 가진다. 제1 프레임워크부의 배치 학습이 종료(모든 에포크 종료)되면, 제2 및 제3 프레임워크부(52, 53)의 배치 학습은 남은 이터레이션과 무관하게 종료될 수 있다. 이 경우, 같은 환경에서의 동기식 학습 방법 보다 시간이 단축될 수 있다. 도 17을 참조하여 비동기식 학습 방법의 또 다른 실시예를 서술한다. 도 17은 앞서 언급한 '확산 정책' 중 일정 개수의 배치 학습이 종료되면 최신 학습 파라미터가 확산되는 학습 주기별 공유 정책에 따른 실시예이다. 통합 정책은 모든 학습 파라미터가 최신인 경우 인수로 사용되는 실시예이다. 도 15를 참조한다. 제1 내지 제3 프레임워크부(51~53) 각각은 학습 종료시까지 각각의 배치 데이터(미니 배치(b1~b10))를 획득하고, 배치 학습(배치 TR)을 반복할 수 있다. 제1 프레임워크부는 제1.1 파라미터(p1.1)가 할당된 모델 아키텍처에서 제1.1 배치 학습을 진행할 수 있다. 제1.1 배치 학습이 완료되면, 제1 프레임워크부는 학습된 제1.1' 파라미터(p1.1')를 도출할 수 있다. 도출 된 제1.1' 파라미터(p1.1')는 그대로 제1.2 배치 학습에 사용될 수 있다. 즉 제1 프레임워크부의 통합부 는 통합 함수(F)를 실행하지 않을 수 있다. 제1.2 파라미터(p1.2)는 제1.1' 파라미터(p1.1')와 동일한 값 을 가진다.이와 같이 각 분산 서버(DS1~3)은 학습 파라미터가 확산되기 전까지 독립하여 배치 학습을 진행할 수 있다. 프레임워크부(51~53) 각각은 배치 학습 회수의 특정 주기에 최신의 학습 파라미터를 확산시킬 수 있다(S830). 도면의 굵게 표시된 배치 학습이 종료되면, 최신 학습 파라미터가 확산될 수 있다. 본 실시예에서 2 주기의 배치 학습 종료 이 후에 학습 파라미터가 확산된다고 가정한다. 제1 프레임워크부 는 제1.2' 학습 파라미터(p1.2')를, 제2 프레임워크부는 제2.2' 학습 파라미터(p2.2')를, 및 제3 프레임워 크부는 제3.2' 학습 파라미터(p2.3')를 다른 분산 서버로 각각 확산시킬 수 있다. 학습 파라미터의 확산 이후, 각 프레임워크부는 타 분산 서버에서 최신의 학습 파라미터를 모두 수신한 경우에 학습 파라미터들을 통합할 수 있다. 예를 들어, 제1 프레임워크부는 제1.3 배치 학습이 완료된 후 도출된 제1.3' 파라미터(p1.3')를 중점으로 제2 및 제3 분산 서버(42, 43)에서 확산된 제2.2' 및 제3.2' 파라미터와 통합하여, 제1.4 파라미터(p1.4)를 산 출할 수 있다. 제1 프레임워크부는 제1.2 배치 학습 후에 다른 학습 파라미터를 받지 못한 이유로, 및 제 1.3 배치 학습 후에 하나의 타 최신 학습 파라미터만을 보유한 이유로, 각 배치 학습 이후에 통합 함수(F)를 실 행시키지 않는다. 제2 프레임워크부는 제2.3 배치 학습이 완료된 후 도출된 제2.3' 파라미터(p2.3')를 중점으로 제3 및 제1 분산 서버(43, 41)에서 확산된 제3.2' 및 제1.2' 파라미터와 통합하여, 제2.4 파라미터(p2.4)를 산출할 수 있다. 제3 프레임워크부는 제3.2 배치 학습이 완료된 후 도출된 제3.2' 파라미터(p3.2')를 중점으로 제1 및 제2 분산 서버(41, 42)에서 확산된 제1.2' 및 제2.2' 파라미터와 통합하여, 제3.3 파라미터(p3.3)를 산출할 수 있다. 최종 훈련된 학습 파라미터(p_last)는 제1 프레임워크부의 통합부에서 산출될 수 있다. 제1 프레임워 크부의 통합부는 제1.l', 제2.m', 및 제3.n' 학습 파라미터(p1.l', p2.m', p3.n')를 기초로 통합 (F')하여 훈련된 학습 파라미터(p_last)를 산출할 수 있다(l, m, n은 자연수). 본 최종 통합에 사용되는 함수 (F')는 훈련 중 사용되는 통합 함수(F)와 상이할 수 있다. 최종 통합 함수(F')는 각 인수에 차별적인 가중치를 주지 않는 것이 바람직하다. 최종 통합 함수(F')는 각 인수 에 가중치를 차별하더라도 상기 통합 함수(F) 보다 덜 차별하는 것이 바람직하다. 이 경우, 학습이 먼저 종료된 순으로 높은 가중치를 낮은 가중치로 주는 것이 바람직하다. 본 실시예에서 보듯이, 배치 학습이 가장 빨리 끝나는 제1 분산 서버에서 최종 학습 파라미터(p_last)를 도 출(통합)하는 것이 바람직하다. 즉, 'l' 값이 다른 'm', 및 'n' 보다 큰 값을 가진다. 제1 프레임워크부의 배치 학습이 종료(모든 에포크 종료)되면, 제2 및 제3 프레임워크부(52, 53)의 배치 학습은 남은 이터레이션과 무관하게 종료될 수 있다. 이 경우, 같은 환경에서의 동기식 학습 방법 보다 시간이 단축될 수 있다. 도 18을 참조하여 동기식 학습 방법의 일 실시예를 서술한다. 도 18은 앞서 언급한 '확산 정책' 중 어떤 프레임 워크부에서 매 배치 학습이 종료되면 해당 최신 학습 파라미터가 다른 프레임워크부로 확산되는 즉시 공유 정책 즉시 공유 정책에 따른 실시예이다. 통합 정책은 모든 학습 파라미터가 최신인 경우 인수로 사용되는 실시예이 다. 도 15를 참조한다. 제1 내지 제3 프레임워크부(51~53) 각각은 학습 종료시까지 각각의 미니 배치(b1~b10)에 대해 배치 학습(배치 TR)을 할 수 있다. 제1 프레임워크부는 제1.1 파라미터(p1.1)가 할당된 모델 아키텍처에서 제1.1 배치 학습을 진행할 수 있다. 제1.1 배치 학습이 완료되면, 제1 프레임워크부는 학습된 제1.1' 파라미터(p1.1')를 도출할 수 있다. 제1 프레임워크부는 학습된 제1.1' 파라미터(p1.1')를 제2 및 제3 분산 서버(42, 43)로 확산시킬 수 있다 (S840). 제1 프레임워크부는 다른 분산 서버(42, 43)에서 동일 단계의 배치 학습(제1.1 배치 학습) 후 도출된 학습 파라미터(타 학습 파라미터들)가 제1 분산 서버에 업데이트되었는지 판단할 수 있다. 제1 분산 서버에 타 학습 파라미터가 모두 업데이트되면, 제1 프레임워크부의 통합부는 제1.1 배 치 학습 후 도출된 모든 학습 파라미터(p1.1', p2.1', p3.1')들을 적절한 통합 함수(F)를 이용하여, 다음 배치 학습에서 사용할 학습 파라미터(p1.2)로 통합할 수 있다.통합 함수(F)는 해당 프레임워크부에서 도출된 학습 파라미터를 중점으로하고, 나머지 타 파라미터들을 보조로 하여 통합하는 것이 바람직하다. 예를 들어, 제1 프레임워크부의 통합부는 제1.1' 파라미터(p1.1')에 높은 가중치를 곱하고, 나머지 파라미터(p2.1', p3.1')에 낮은 가중치를 곱하여, 제1.2 파라미터(p1.2)로 도출 할 수 있다. 이때, 가중치들의 합은 1인 것이 바람직하다. 가중치는 학습 진행 정도나 다른 여러 요소로, 가중 치들 각각의 크기는 달라 수 있다. 제1 프레임워크부는 통합된 학습 파라미터(p1.2)를 다음 배치 학습에 적용할 학습 파라미터로 업데이트하고, 다음 배치 학습을 할 수 있다. 제2 및 제3 분산 서버(42, 43)의 제2 및 제3 프레임워크부(52, 53) 각각의 통합부는 각각 제1.1 배치 학습 후 도출된 모든 학습 파라미터(p1.1', p2.1', p3.1')들을 이용하여, 제2.2 및 제3.2 파라미터(p2.1, p3.1)을 각각 통합하여 다음 배치 학습에 적용할 학습 파라미터로 각각 업데이트한 후, 다음 배치 학습을 할 수 있다. 이러한 과정은 통해, 제1 내지 제3 프레임워크부(51~53)는 모든 에포크가 종료될 때까지 테스트를 할 수 있다. 모든 에포크가 종료되면, 복수의 분산 서버(41~43) 중 어느 하나 또는 메인 서버의 통합부는 각각의 마지막 학습 파라미터(p1.n', p2.n', p3.n')를 통합하여, 최종 학습 파라미터(p_last)를 도출할 수 있다(n는 자 연수). 최종 통합 함수(F')는 학습 중 사용된 통합 함수(F)와 상이할 수 있다. 최종 통합 함수(F')는 각 인수에 차별적인 가중치를 주지 않는 것이 바람직하다. 본 동기식 학습 방법은 비동기식 학습 방법에 비해 학습에 시간이 더 소요될 수 있으나, 각 학습 파라미터들을 균형있게 사용할 수 있다. 도 19를 참조하여 동기식 학습 방법의 다른 실시예를 서술한다. 도 19는 앞서 언급한 '확산 정책' 중 시간 주기 별 공유 정책, 학습 주기별 공유 정책, 및 기타 규칙 정책 중 어느 한 정책에 따른 실시예이다. 통합 정책은 모 든 학습 파라미터가 최신인 경우 인수로 사용되는 실시예이다. 도 15, 도 16, 및 도 18를 참조한다. 제1 내지 제3 프레임워크부(51~53) 각각은 학습 종료시까지 각각의 미니 배치(b1~b10)에 대해 배치 학습(배치 TR)을 반복할 수 있다. 제1 프레임워크부는 제1.1 파라미터(p1.1)가 할당된 모델 아키텍처에서 제1.1 배치 학습을 진행할 수 있다. 제1.1 배치 학습이 완료되면, 제1 프레임워크부는 학습된 제1.1' 파라미터(p1.1')를 도출할 수 있다. 도출 된 제1.1' 파라미터(p1.1')는 그대로 제1.2 배치 학습에 사용될 수 있다. 즉 제1 프레임워크부의 통합부 는 통합 함수(F)를 실행하지 않을 수 있다. 제1.2 파라미터(p1.2)는 제1.1' 파라미터(p1.1')와 동일한 값 을 가진다. 이와 같이 각 분산 서버(DS1~3)은 학습 파라미터가 확산되기 전까지 독립하여 배치 학습을 진행할 수 있다. 이 때 각 배치 학습의 시작은 동기되지 않아도 무관하다. 모든 프레임워크부(51~53)는 특정 시간 주기, 학습 주기, 또는 특정 시각에 최신의 학습 파라미터를 확산시킬 수 있다(S820). 본 실시예에서, 모든 프레임워크부(51~53) 각각은 세번째 배치 학습 종료 후에 도출된 제1.3', 제2.3', 및 제3.3' 학습 파라미터(p1.3', p2.3', p3.3')을 다른 분산 서버로 확산시킬 수 있다. 학습 파라미터의 확산 이후, 각 프레임워크부는 다음 배치 학습 전에 학습 파라미터들을 통합하여, 각각 제1.4, 제2.4, 및 제3.4 학습 파라미터(p1.4, p2.4, p3.4)로 업데이트할 수 있다. 이 후 각 프레임워크부(51~53)는 다 음 학습 파라미터 확산 까지 배치 학습을 진행 수 있다. 도 13을 참조하면, 복수의 분산 서버(41~43) 중 어느 하나, 예를 들어, 제1 분산 서버는 훈련된 모델 아키 텍처 및 훈련된 학습 파라미터(p_last)를 아키텍처 테이블 및 학습 파라미터 테이블로 변환하여 이를 훈련된 학 습 모델 테이블(추론용 모델 테이블(Ti))로 저장할 수 있다(S670). 저장된 자료는 메인 서버로 전송되거나 동기화될 수 있다. 도 14를 참조하여, 딥러닝 추론 분산에 대해 설명한다. 이하, 도 10 및 도 11을 참고한다. 단, 딥러닝 추론 분 산 시스템의 메인 서버와 복수의 분산 서버(41~43) 환경은 딥러닝 훈련 분산 시스템의 메인 서버 및 복 수의 분산 서버(41~43) 환경은 상이할 수 있다. 메인 서버와 복수의 분산 서버(41~43)는 각각 통합부(320, 320-N)를 구비하지 않을 수 있다. 메인 서버와 복수의 분산 서버(41~43)는 상호 호환될 수 있다. 도 14를 참조하면, 단말기로부터 학습 쿼리와 동일한 기능의 딥러닝 추론 쿼리를 입력 받을 수 있다(S710). 본 실시예에서 메인 서버는 딥러닝을 할 수 있는 제1 분산 서버과 동일하다고 가정하면, 본 딥러닝 추 론 쿼리는 메인 서버이 수신할 수 있다. 이하, 메인 서버에서 딥러닝 추론이 수행된다고 본다.메인 서버는 저장부에 추론용 데이터셋 테이블을 구비할 수 있다. 메인 서버는 추론용 데이터셋의 데이터를 쿼리를 통해 입력 받거나, 다른 장치로부터 입력 받을 수 있다. 메인 서버는 입력 받은 학습 쿼리와 동일한 기능의 딥러닝 추론 쿼리를 분석하여, 기 학습된 추론용 모델 테이블(Ti)을 선택할 수 있다(S715). 추론용 모델 테이블(Ti)은 딥러닝 추론 쿼리의 내용에 기술되어 있을 수 있다. 메인 서버의 메인 프레임워크부는 추론용 모델 테이블(Ti)의 아키텍처 테이블을 메인 프레임워크부(5 0)에 적합한 추론용 모델 아키텍처로 구축하고, 추론용 모델 아키텍처에 학습 파라미터를 할당하여 추론용 학습 모델을 생성할 수 있다(S720). 메인 서버는 추론 분산이 필요한지 판단할 수 있다(S725). 추론 분산은 딥러닝을 수행하기 위한 복수의 태스크 중 일부를 다른 장치에서 수행하는 것을 의미할 수 있다. 복수의 태스크는 하나의 학습 모델을 위한 일련의 과정이거나, 복수의 학습 모델 각각의 태스크들의 집합일 수 있다. 전자(1개 학습 모델)의 경우 복수의 태스크는 순서대로 진행되어야 하므로, 하나의 장치에서 일부 태스크 를 수행한 후에 다른 장치에서 나머지 태스크들을 수행할 수 있다. 후자(복수 학습 모델)의 경우, 어느 학습 모 델의 태스크들인 태스크 그룹 별로 다른 장치에 수행되도록 할 수 있다. 이 때, 상위 그룹에 속하는 학습 모델 의 태스크 그룹을 먼저 수행한 후, 하위 그룹에 속하는 학습 모델의 태스크 그룹을 수행할 수 있다. 후자는 전 자의 분산 개념을 포함할 수 있다. 본 실시예에서는 전자를 기초로 설명하나, 후자의 개념이 포함됨은 당연하다. 그리고, 기본적으로 분산 처리되는 태스크들은 일련의 태스크들이어야 한다. 일련의 태스크들은 각각 선후 관계이며, 서로 직접 연결되어 있는 것을 의미한다. 예를 들어, 일련의 태스크들에 속하는 어느 태스크의 결과값은 일련의 태스크에 속하는 다음 태스크의 입력값이어야 한다. 추론 분산 필요 환경은 다양할 수 있다. 추론 분산 필요 환경의 제1례로, 메인 서버에서의 일련의 태스크 수행 시간 보다 제1 분산 서버에서의 일련의 태스크 수행 시간이 더 짧은 경우일 수 있다. 이 때, 추론 분산 환경 전송 및 일련의 태스크의 마지막 결과값을 전송하는 시간이 고려될 수 있다. 이를 위해, 메인 서버과 제1 분산 서버는 고속 와이파이나 5G, 6G 등의 고속 이동 통신망으로 연결되는 것이 바람직하다. 메인 서버가 모바일 장치나 임베디드 장치와 같이 컴퓨팅 사양이 낮을 경우, 및/또는 제1 분산 서버의 컴퓨팅 사양이 높을 경우, 추론 분산이 필요할 수 있다. 이러한 환경은 특히, 엣지 컴퓨팅(모바일 엣지 컴퓨팅) 환경에 적합할 수 있다. 엣지 컴퓨닝 환경에서 메 인 서버가 엣지 디바이스이고, 제1 분산 서버이 엣지 서버인 경우, 분산 추론이 바람직할 수 있다. 특 히, 엣지 컴퓨팅 환경의 경우 엣지 디바이스와 엣지 서버와의 통신 속도가 매우 빠르므로, 본 추론 분산에 적합 할 수 있다. 추론 분산 필요 환경의 제2례로, 컴퓨팅 사양은 별도로, 각 장치에서의 주된 성능에 따라 달라질 수 있다. 예를 들어, 특정 태스크들이 메인 서버에서 보다 제1 분산 서버에서 처리 속도가 빠를 경우, 해당 특정 태스 크들은 제1 분산 서버에서 분산 처리되는 것이 바람직하다. 추론 분산 필요 환경의 제3례로, 전체 복수의 태스크 중 분리되어 처리될 수 있는 일련의 태스크들을 다른 분산 서버에서 처리되도록 하는 것이다. 예를 들어, 인물의 성별과 나이를 분류하는 학습 모델의 경우, 이는 성별 분 류 학습 모델과 나이 분류 학습 모델로 분리될 수 있다. 성별 분류는 제1 분산 서버에서 처리하고, 나이 분 류는 제2 분산 서버에서 처리되도록 하면, 딥러닝 수행에 따른 전체 시간을 줄일 수 있다. 추론 분산 필요 환경의 제4례로, 입력 데이터가 많을 경우, 입력 데이터를 분할하여 각 분할된 입력 데이터를 분산하여 처리되도록 할 수 있다. 본 례는 다른 례와 조합하여 이용될 수 있다. 예를 들어, 입력 데이터를 복잡 하지 않은 태스크들로 전처리하는 과정이 있을 경우, 메인 서버에서 전처리 과정을 수행하고 전처리 과정 후 후처리 과정이 필요한 데이터를 다른 분산 서버로 전송할 수 있다. 본 례는 특히, 통신 환경이 빠르지 않을 경우, 유용할 수 있다. 후처리 딥러닝이 필요한 데이터만 분산 서버로 전송하면 되기 때문이다. 추론 분산이 필요하다고 판단되는 경우, 메인 서버는 추론용 모델 테이블(Ti)을 복수의 분산 서버(41~43) 중 적어도 하나로 전송할 수 있다(S730). 메인 서버는 복수의 분산 서버(41~43)에 추론용 모델 테이블(Ti)을 기초로 추론용 학습 모델을 생성하도록 지시할 수 있다. 메인 서버는 추론 분산할 태스크들인 추론 분산 범위 및 추론 분산할 분산 서버를 구비하는 추론 분산 환경 을 결정할 수 있다(S735). 메인 서버는 추론 분산 환경에 기초하여, 추론 분산할 분산 서버에 분산 처리를 지시할 수 있다(S740). 분산 처리 지시에 대한 자세한 설명은 후술한다. 추론 분산이 필요 없거나, 추론 분산을 지시하더라도 메인 서버에서 딥러닝 추론의 일부 태스크를 수행할 필요가 있는 경우, 메인 서버는 딥러닝 추론에 따른 태스크 전체 또는 그 일부를 수행할 수 있다(S750). 메 인 서버는 생성된 추론용 학습 모델을 이용하여, 추론용 데이터셋 테이블의 데이터에 대해 쿼리 기능의 딥 러닝의 전체 또는 일부를 수행할 수 있다. 메인 서버는 자체 또는 다른 분산 서버에서 완료된 딥러닝 추론에 따른 추론 결과를 취득하여, 이를 저장 (S760)하거나 사용자에게 알릴 수 있다. 도 20을 참조하면, 메인 서버는 추론 분산이 필요하다고 판단하면, 제1 및 제2 분산 서버(41, 42)에 추론용 학습 모델 테이블(Ti)을 전송할 수 있다(S730). 제1 및 제2 분산 서버(41, 42)는 메인 서버의 지시에 따라, 추론용 학습 모델 테이블(Ti)을 이용하여 추론 용 학습 모델을 생성할 수 있다. 도 21을 참조하면, 개략적인 학습 모델의 네트워크 구조(신경망)는 입력층(L_I), 은닉층(L1 ~ L_N), 및 출력층 (L_O)을 구비할 수 있다. 입력층은 추론용 데이터셋으로부터 입력 받을 수 있다. 은닉층은 계산이 일어나는 층이다. 은닉층(L1 ~ L_N)은 단일 또는 복수의 레이어로 구성될 수 있다. 원모양은 각 노드를 나타내며, 각 레이어는 노드들의 집합으로 구성될 수 있다. 화살표의 시작은 한 노드의 출력이고, 끝 은 한 노드의 입력일 수 있다. 출력층은 딥러닝의 결과값으로, 분류해야 하는 값의 개수만큼 출력 노드의 개수를 가질 수 있다. 딥러닝 수행은 복수의 태스크를 구비할 수 있다. 즉, 딥러닝 수행은 복수의 태스크에 의해 단계별로 수행될 수 있다. 복수의 태스크 각각은 다른 태스크와 구별되는 고유 번호를 가질 수 있다. 후술하는 복수의 레이어 각각 은 다른 레이어와 구별되는 고유 번호를 가질 수 있다. 복수의 태스크는 어느 한 학습 모델에 종속되지 않고, 쿼리 기능을 수행하기 위한 모든 태스크를 의미할 수 있 다. 쿼리의 기능이 복수의 세부 기능으로 분류되어, 복수의 학습 모델로 딥러닝 추론이 이루어질 수 있다. 이 경우, 복수의 태스크는 복수의 학습 모델 중 제1 학습 모델의 제1 태스크 그룹, 및 제2 학습 모델의 제2 태스크 그룹을 모두 포함할 수 있다. 도 21 내지 도 22를 참조하면, 학습 모델의 복수의 레이어 중 특정 레이어의 노드들에서 연산되는 것은 하나의 태스크와 대응될 수 있다. 예를 들어, 레이어 1(L1)의 제1 출력 값들(R1)은 레이어 2(L2)의 제2 입력 값들이 될 수 있다. 레이어 2(L2)에 서 제1 출력 값들(R1)이 연산되어 제2 출력 값들(R2)로 출력될 수 있다. 제2 입력 값들(R1)에서 제2 출력 값들 (R2)로 연산되는 과정은 태스크 2(T2)로 칭할 수 있다. 제2 출력 값들은 태스크 2(T2)의 결과값 리스트 2(R2)로 칭할 수 있다. 결과값 리스트는 태스크 고유 번호와 대응하며, 다른 결과값 리스트와 구별되는 고유 번호를 구 비할 수 있다. N 개의 레이어가 있다면, N 개의 태스크가 있을 수 있다. 제어부는, 도 22의 우측과 같이, 복수의 태스크 (T1 ~ T_N)의 복수의 결과값 리스트(R1 ~ R_N)를 관계형 구조의 중간 결과값 테이블(T_R)로 저장할 수 있다. 도 23을 참조하면, 은닉층의 각각의 레이어(L1 ~ L_N)는 네트워크 테이블(T_NW)의 행들(H1 ~ H_N)에 대응될 수 있다. 따라서, 복수의 레이어의 고유 번호, 복수의 태스크 고유 번호, 및 복수의 행번호는 서로 대응될 수 있다. 예를 들어, 레이어 2(L2), 태스크 2(T2), 및 행번호 2(H2)는 서로 대응될 수 있다. 추론용 학습 모델 테이블(Ti)은 다른 학습 모델 테이블과 구별되는 고유 번호를 가질 수 있다. 도 20을 참조하면, 메인 서버는 메인 서버에서 태스크 일부(T1 ~ T5)를 수행하고, 제1 분산 서버에 서 제1 내지 제2 태스크(T6 ~ T10)을 분산 처리하게 결정할 수 있다. 제2 태스크는 태스크 N(T_N)일 수 있다. 이를 위해, 메인 서버는 태스크 일부(T1 ~ T5)를 수행(S810)하고, 추론용 학습 모델 테이블(Ti)의 고유 번 호(M_ID), 제1 태스크(T6)의 직전 태스크인 제3 태스크(T5)의 결과값 리스트(R5), 및 제2 태스크의 고유 번호(T10)와 대응하는 네트워크 테이블(T_NW)의 제2 행번호(H10)를 제1 분산 서버로 전송할 수 있다(S812). 사용자의 요청 쿼리는 상위의 제1 세부 기능 및 하위의 제2 세부 기능으로 분석될 수 있다. 예를 들어, 요청 쿼 리가 인물의 성별 분류일 경우, 상위의 입력 데이터의 인물 검출 기능 및 하위의 인식된 인물의 성별 분류 기능 으로 분석될 수 있다. 이 경우, 인물 검출 기능에 대한 딥러닝 추론은 메인 서버에서 수행되고, 검출된 인 물의 성별 분류 기능에 대한 딥러닝 추론은 제1 분산 서버에서 수행될 수 있다. 또 다른 예로, 메인 서버는 추론용 데이터에 대해 전처리 감지 기능의 딥러닝을 수행하여 추론용 데이터에 메인 기능의 딥러닝이 필요한 경우에만, 제1 분산 서버로 쿼리 기능의 딥러닝이 수행되도록 할 수 있다. 전 처리 감지 기능은 메인 기능인 사용자가 요청한 쿼리의 기능의 딥러닝이 필요한지 감지하는 기능을 의미할 수 있다. 예를 들어, 요청 쿼리가 인물 성별 분류일 경우, 전처리 감지 기능은 입력 이미지에 인물이 존재하는 지 감지하는 기능일 수 있다. 인물이 존재하지 않는 이미지는 요청 쿼리의 딥러닝을 수행하지 않으므로, 시간이 단 축되며 통신 대역을 적게 사용할 수 있다. 제1 분산 서버는 메인 서버로부터 추론용 학습 모델 테이블(Ti)의 고유 번호(M_ID), 및 제3 결과값 리 스트(R5)를 수신하면, 제3 결과값 리스트(R5)를 복수의 태스크 중 일련의 최초 태스크(T1) 내지 제4 태스크(T 5)가 수행된 결과값 리스트(R5)로 결정할 수 있다. 복수의 네트워크 테이블 중 제6 행번호(H6)는 제3 행번호(H5)의 직후에 배치된 것이다. 제1 분산 서버는 태스크 지시 종료행인 네트워크 테이블(T_NW)의 제2 행번호(H10)를 더 수신하면, 제1 분산 서버의 제1 프레임워크부에서 제3 결과값 리스트(R5)를 입력으로 하고, 네트워크 테이블(T_NW)의 제6 행번호(H6) 내지 제2 행번호(H10)와 관련된 연산을 수행할 수 있다(S814). 즉 제1 분산 서버는 기 생성된 추론용 학습 모델 중(Ti) 제1 내지 제2 태스크(T6 ~ T10)을 분산 처리할 수 있다. 네트워크 테이블(T_NW)의 제6 행번호(H6) 내지 제2 행번호(H10)의 연산이 종료되면, 제1 분산 서버는 제2 결과값 리스트(R2)를 메인 서버으로 전송할 수 있다(S816-1). 본 실시예는 제2 태스크(T10)가 최종 태스크 인 경우, 또는 메인 서버에서 다른 태스크를 수행할 필요가 있을 때 본 절차가 수행될 수 있다. 다른 실시예로, 메인 서버는 제1 분산 서버가 제2 분산 서버로, 네트워크 테이블 고유 번호(M_ID), 제2 태스크(T10)의 제2 결과값 리스트(R10) 및 태스크 지시 종료행인 제7 행번호(H_N)를 전송하도록 하면, 제1 분산 서버는 제6 행번호(H6) 내지 제2 행번호(H10)의 연산을 수행(S814) 후 메인 서버의 지시를 수행할 수 있다(S816-2). 메인 서버의 쿼리 분석부는 사용자 요청 쿼리를 3단계의 세부 기능으로 분석 및/또 는 추출할 수 있다. 예를 들어, 쿼리가 인물의 성별 분류 기능일 경우, 쿼리 분석부는 요청 쿼리를 상위의 인물 존재 감지 기 능, 다음 단계의 인물 검출 기능, 및 하위의 검출된 인물의 성별 분류 기능으로 추출할 수 있다. 입력 데이터인 이미지 파일에 인물이 존재하는 지 여부는 메인 서버에서 딥러닝 추론하고, 인물이 존재하는 이미지 파일에 서 인물 검출 기능은 제1 분산 서버에서 딥러닝 추론하고, 검출된 이미지의 성별을 분류 기능은 제2 분산 서버에서 딥러닝 추론할 수 있다. 이를 통해, 각 서버에서의 처리양이 줄어 시간이 단축될 수 있으며, 분산 서버에서 인물이 있는 이미지만 처리하므로 처리 시간이 더 단축될 수 있다. 제2 분산 서버는 추론용 학습 모델 테이블(Ti)의 고유 번호(M_ID), 제2 결과값 리스트(R10), 네트워크 테이 블(T_NW)의 제7 행번호(H_N)를 수신하면, 제2 결과값 리스트(R10)를 입력으로 하고 네트워크 테이블(T_NW)의 행 번호 11(H11) 부터 행번호 N(H-N) 까지와 관련된 연산을 수행할 수 있다(S818). 즉, 제2 분산 서버는 기 생 성된 추론용 학습 모델 테이블(Ti)의 태스크 11 내지 N(T11 ~T_N)을 분산 처리할 수 있다. 제2 분산 서버는 분산 처리(S818) 결과인 제7 결과값 리스트(R_N)을 결정하고, 이를 메인 서버으로 전 송할 수 있다(S820). 도 24는 본 발명의 다른 실시예에 따른 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버의 일부 구성의 세부 블록도이다. 도 25는 본 발명의 다른 실시예에 따른 성별 및 나이를 분류하는 방법의 순서도이다. 도 26은 도 24 및 도 25의 중간 데이터를 도시한다. 도 1 내지 도 23을 참고한다. 상술한 구성요소와 동일한 명칭의 내용은 상술한 내용을 참고한다. 본 실시예에 따른 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버는 제어부, 저장부 , 프레임워크부, 변환부, 및 입출력부를 포함할 수 있다. 도 24를 참조하면, 제어부는 쿼리 분석부, 데이터셋 관리 모듈, 학습 모델 관리 모듈, 결 과 관리 모듈, 및 보조 관리 모듈을 포함할 수 있다. 저장부는 쿼리 분석값, 데이터셋 테 이블, 학습 모델 테이블, 학습 결과, 맵핑 정보, 및 안면 이미지 박스을 포함할 수 있다. 도 25 및 도 26을 참조하여, 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버의 성별 및 나 이를 분류하는 딥러닝 추론을 설명한다. 입출력부는 사용자로부터 추론용 데이터셋의 성별 및 나이 분류 기능의 추론 쿼리를 입력받을 수 있다 (S830). 추론용 데이터셋은 추론용 데이터셋 테이블로 저장될 수 있다. 추론용 데이터셋 테이블은 인물이 존부 하는 이미지들의 집합일 수 있다. 이하, 입력 데이터로 원본 이미지가 입력된다고 가정한다. 쿼리 분석부는 사용자 요청 추론 쿼리를 분석하여 쿼리의 기능을 달성하기 위한 복수의 세부 기능으로 추 출할 수 있다(S832). 쿼리 분석부은 추론 쿼리를 복수의 세부 기능으로서 상위 그룹의 안면 검출 기능 및 하위 그룹의 성별 및 나이 분류 기능으로 추출할 수 있다. 성별 및 나이 분류 기능는 하나의 기능, 및 성별과 나이를 각각 분류하는 기능으로 추출될 수 있다. 성별 및 나이 분류는 동일한 순위의 그룹이므로, 하나 또는 두 개 중 어느 것이라도 무방하다. 본 실시예에서는 성별 분류 기능 및 나이 분류 기능의 2 개로 추출된 것으로 가 정한다. 본 실시예에서 안면 검출 기능이라고 표시하였지만, 필요에 따라 얼굴이 아닌 인물 전체를 검출하도록 조정할 수 있다. 쿼리 분석부는 추론용 데이터셋에 대해 메인 기능인 사용자 요청 쿼리 기능의 딥러닝 추론이 필요한지 감 지하는 최상위 그룹의 전처리 감지 기능을 더 추출할 수 있다. 메인 기능은 복수의 세부 기능 전부를 의미할 수 있다. 저장부는 기 학습된, 안면 검출 기능과 연관된 안면 검출 학습 모델 테이블, 성별 분류 기능과 연관된 성 별 분류 학습 모델 테이블, 나이 분류 기능과 연관된 나이 분류 학습 모델 테이블, 및 전처리 감지 기능과 연관 된 전처리 감지 학습 모델 테이블을 구비할 수 있다. 학습된 학습 모델 테이블이 없을 경우, 딥러닝 훈련을 통 해 학습된 학습 모델 테이블을 추가할 수 있다. 학습 모델 관리 모듈은 복수의 학습 모델 테이블 중 기 학습된 전처리 감지 학습 모델, 안면 검출 학습 모 델 테이블, 성별 분류 학습 모델 테이블, 및 나이 분류 학습 모델 테이블을 선택할 수 있다. 프레임워크부는 추론용 데이터셋 테이블에 대해, 전처리 감지 학습 모델, 안면 검출 학습 모델 테이블, 성 별 분류 학습 모델 테이블, 및 나이 분류 학습 모델 테이블 각각에 연동하여, 전처리 감지 기능 및 복수의 세부 기능의 딥러닝 추론을 각각 수행할 수 있다. 프레임워크부는 그룹 순위에 따라 학습 모델의 딥러닝 추론을 하는 것이 바람직하다. 본 실시예에서 각 그룹은 최상위, 상위, 및 하위 그룹 순서로 순위를 가질 수 있다. 즉, 각 모델은 제1 순위인 전처리 감지 기능, 제2 순위인 안면 검출 기능, 및 제3 순위인 성별 및 나이 분류 기능의 순서를 가질 수 있다. 프레임워크부는 제1 순위 학습 모델인 전처리 감지 학습 모델을 이용하여, 원본 이미지에 안면이 있 는지 감지하는 딥러닝 추론을 할 수 있다(S834). 원본 이미지에 안면이 없을 경우(S836), 원본 이미지에 대한 딥러닝을 중지하고, 다음 입력 데이터에 대해 전처리 감지 기능의 딥러닝 추론을 진행할 수 있다. 원본 이미지에 안면이 있을 경우(S836), 나머지 복수의 세부 기능의 딥러닝 추론을 진행할 수 있다. 프레임워크부는 제2 순위 학습 모델인 안면 검출 학습 모델을 이용하여 원본 이미지에 안면을 검출하 는 딥러닝 추론할 수 있다(S836). 안면 검출은 안면이 있는 부분을 포함하는 사각형과 같이 영역을 정의하고, 원본 이미지에서 사각형 영역의 위치 좌표를 추출하는 것을 의미할 수 있다. 보조 관리 모듈은 검출된 안면 부분을 크롭하여 안면 이미지 박스를 생성할 수 있다(S840). 안면 이 미지 박스은 다음 순위의 세부 기능의 딥러닝 추론의 입력값이 될 수 있다. 보조 관리 모듈은 원본 이미지와 안면 이미지 박스의 관계를 맵핑하는 맵핑 정보을 생성할 수 있다(S842). 맵핑 정보는 박스 ID, 이미지 ID, 및 위치 정보를 구비할 수 있다. 맵핑 정보는 관 계형 데이터베이스 형식일 수 있다. 박스 ID는 안면 이미지 박스의 고유 번호로, 식별자로 기능할 수 있다. 이미지 ID는 박스 ID에 연관되며, 원본 이미지의 고유 번호이다. 위치 정보는 박스 ID에 대해, 원본 이미지 에 맵핑되는 안면 이미지 박스의 위치에 대한 정보이다. 안면 이미지 박스가 안면을 구비한 사 각형 영역이라면, 위치 정보는 사각형의 대각하는 두 개의 꼭지점의 x, y 좌표일 수 있다. 프레임워크부는 제3 순위 학습 모델인 성별 분류 학습 모델을 이용하여, 안면 이미지 박스에 대한 성 별을 분류할 수 있다(S844). 보조 관리 모듈은 안면 이미지 박스의 성별에 대한 정보를 맵핑 정보에 맵핑하여, 맵핑 정보 을 갱신할 수 있다(S846). 맵핑은 안면 이미지 박스의 박스 ID에 성별 값을 연관시키는 것 을 의미할 수 있다. 프레임워크부는 제3 순위 학습 모델인 나이 분류 학습 모델을 이용하여, 안면 이미지 박스에 대한 나 이를 분류할 수 있다(S848). 보조 관리 모듈은 안면 이미지 박스의 나이에 대한 정보를 맵핑 정보에 맵핑하여, 맵핑 정보 을 갱신할 수 있다(S850). 맵핑은 안면 이미지 박스의 박스 ID에 나이 값을 연관시키는 것 을 의미할 수 있다. 데이터셋 관리 모듈은 원본 이미지 및 원본 이미지의 이미지 ID를 구비한 맵핑 정보 의 안면 이미지 박스의 위치 정보, 성별 값, 및 나이 값를 이용하여, 상기 원본 이미지 에 인물의 성멸 및 나이를 부기하여 결과 이미지를 생성할 수 있다(S852). 본 실시예에 따른 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버는 상술한 딥러닝 추론에 따른 복수의 태스크 중 일부인 일련의 태스크들을 복수의 분산 서버(41~43) 중 적어도 어느 하나에 수행하도록 하여, 딥러닝 추론을 분산 처리할 수 있다. 또한, 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이 스 서버는 미 학습된 학습 모델에 대해 딥러닝 훈련을 복수의 분산 서버(41~43)와 분산하여 진행 할 수 있다. 상기 본 발명은 하드웨어 또는 소프트웨어에서 구현될 수 있다. 구현은 상기 본 발명은 또한 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 즉, 컴퓨터에 의해 실행 가능한 명 령어를 포함하는 기록 매체의 형태로 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 매체를 포함한다. 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 저장 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터가 읽을 수 있는 명령어, 데이터 구조, 프로그램 모듈, 및 기타 데이터 등 정보 저장을 위한 임의의 방법 또는 기술로서 구현된 모든 저장 가능한 매체를 포함하는 것으로, 휘발성/비휘발성/하이브리드형 메모리 여부, 분리형/비분리형 여부 등에 한정되지 않는다. 통신 저장 매 체 는 반송파와 같은 변조된 데이터 신호 또는 전송 메커니즘, 임의의 정보 전달 매체 등을 포함한다. 그리고 본 발명을 구현하기 위한 기능적인(functional) 프로그램, 코드 및 코드 세그먼트들은 본 발명이 속하는 기술분 야의 프로그래머들에 의해 용이하게 추론될 수 있다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2023-0058802", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안 될 것이다."}
{"patent_id": "10-2023-0058802", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 쿼리 기반 딥러닝 추론 시스템의 전체적인 구성을 개략적으로 나타낸 구성 도이다. 도 2는 본 발명의 일 실시예에 따른 데이터베이스 서버의 제어 구성도이다. 도 3은 본 발명의 일 실시예에 따른 데이터 관리 구성도이다. 도 4는 본 발명의 일 실시예에 따른 데이터베이스 구조도이다. 도 5는 본 발명의 일 실시예에 따른 변환부의 제어 구성도이다.도 6 및 도 7은 본 발명의 일 실시예에 따른 변환부의 변환 동작도이다. 도 8은 본 발명의 실시 예에 따른 쿼리 기반의 기계학습 기술의 수행 흐름을 나타낸 흐름도이다. 도 9는 본 발명의 실시 예에 따른 쿼리 기반 딥러닝 추론 방법을 설명하기 위한 동작 흐름도이다. 도 10은 본 발명의 다른 실시예에 따른 데이터베이스 연동 딥러닝 분산 시스템을 개략적으로 나타낸 구성도이다. 도 11은 도 10에 따른 메인 서버 및 분산 서버의 블록 구성도이다. 도 12는 메인서버의 데이터셋 및 분산서버의 훈련용 데이터셋을 도시한다. 도 13은 도 10의 시스템의 훈련 방법에 대한 순서도이다. 도 14는 도 10의 시스템의 추론 방법에 대한 순서도이다. 도 15 내지 도 17은 도13의 비동기식 분산 서버의 각기 다른 실시예에 따른 신호 흐름도이다. 도 18 및 도 19는 도 13이 동기식 분산 서버의 서로 다른 실시예에 따른 신호 흐름도이다. 도 20은 도 14의 분산 추론에 따른 신호 흐름도이다. 도 21은 학습 모델을 개략적으로 도시한다. 도 22은 도 20에 따른 중간 결과값 테이블의 일부를 도시한다. 도 23은 네트워크 테이블의 일부를 도시한다. 도 24는 본 발명의 다른 실시예에 따른 성별 및 나이를 분류하는 딥러닝 프레임워크 응용 데이터베이스 서버의 일부 구성의 세부 블록도이다. 도 25는 본 발명의 다른 실시예에 따른 성별 및 나이를 분류하는 방법의 순서도이다. 도 26은 도 24 및 도 25의 중간 데이터를 도시한다."}
