{"patent_id": "10-2019-0091168", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0012814", "출원번호": "10-2019-0091168", "발명의 명칭": "BIM 객체 모델을 이용한 인공지능 교통신호 호스트 서버 및 이를 포함하는 제어 시스템 및 제", "출원인": "서울시립대학교 산학협력단", "발명자": "이승재"}}
{"patent_id": "10-2019-0091168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "지역 제어기로부터 수신한 검지 데이터를 전처리 가공하는 지역 컴퓨터로부터 전처리 가공된 검지 데이터를 수신하고, 안정성 검증이 완료된 최적의 신호주기를 상기 지역 컴퓨터로 전송하는 통신모듈;상기 통신모듈을 통해 수신된 전처리 가공된 검지 데이터를 이용하여 교차로 주변의 교통상황을 예측하고 최적의 신호주기를 산출하는 인공지능 딥러닝을 수행하는 딥러닝모듈;상기 딥러닝모듈에 의해 산출된 최적의 신호주기를 3차원 BIM 객체 모델링으로 구현된 가상 시뮬레이션에 적용하여 안정성 검증을 수행하는 BIM 검증모듈;을 포함하는 BIM 객체 모델을 이용한 인공지능 교통신호 호스트 서버."}
{"patent_id": "10-2019-0091168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 딥러닝모듈은,행위자(Agent)가 현재 환경(Environment)의 상태(State)를 인식하여 특정한 행동(Action)을 취하고, 그 결과로달라진 미래 상태(State) 및 행위자에게 주어지는 보상(Reward)을 받는, 강화학습 알고리즘을 이용하여 차량의지체 시간을 최소화하는 신호주기를 산출하는 것을 특징으로 하는 BIM 객체 모델을 이용한 인공지능 교통신호호스트 서버."}
{"patent_id": "10-2019-0091168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 환경은 교차로 네트워크이고, 상기 환경의 상태(St)는 상기 교차로 네트워크에서의 이동류별 지체 시간이며, 상기 행위자는 신호제어 체계이고, 상기 행동(at)은 신호등에 의해 표시되는 신호 현시이며,상기 행위자의 행동결정 기준이 되는 보상치(Rt+1)는 신호 현시 표출 후의 네트워크 상의 이동류별 지체 시간의변화량이고, 상기 강화학습 알고리즘은 상기 보상치를 최대로 하는 신호주기를 산출하는 것을 특징으로 하는 BIM 객체 모델을 이용한 인공지능 교통신호 호스트 서버."}
{"patent_id": "10-2019-0091168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "교차로를 주행하는 차량의 시간대별 차량 교통량을 검지하는 차량 검지부;교차로 주변의 미세먼지 농도, 교차로 주변의 이산화탄소 농도를 포함하는 환경 데이터를 검지하는 환경검지부;상기 차량 검지부와 환경 검지부에 의해 검지된 검지 데이터를 수신하는 지역 제어기;상기 지역 제어기로부터 상기 검지 데이터를 수신하여 전처리 가공하는 지역 컴퓨터; 및,상기 지역 컴퓨터로부터 전처리 가공된 검지 데이터를 수신하고, 상기 전처리 가공된 검지 데이터를 이용하여공개특허 10-2021-0012814-3-인공지능 딥러닝을 수행하여 교차로 주변의 교통상황을 예측하고 최적의 신호주기를 산출한 후, 산출된 최적의신호주기를 3차원 BIM 객체 모델링으로 구현된 가상 시뮬레이션에 적용하여 안정성 검증을 수행하고, 안정성 검증이 완료된 최적의 신호주기를 상기 지역 컴퓨터로 전송하는 호스트 서버;를 포함하는 BIM 객체 모델을 이용한 인공지능 교통신호 제어 시스템."}
{"patent_id": "10-2019-0091168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,날씨, 기온, 미세먼지 농도, 이산화탄소 농도 중 적어도 어느 하나를 포함하는 환경 데이터를 제공하는 외부서버를 더 포함하는 BIM 객체 모델을 이용한 인공지능 교통신호 제어 시스템."}
{"patent_id": "10-2019-0091168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 4에 있어서, 상기 지역 컴퓨터는,상기 지역 제어기로부터 수신된 검지 데이터를 엣지 컴퓨팅 기법으로 전처리 가공하는 것을 특징으로 하는 BIM객체 모델을 이용한 인공지능 교통신호 제어 시스템."}
{"patent_id": "10-2019-0091168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 4에 있어서, 상기 호스트 서버는,상기 지역 컴퓨터와 통신을 수행하는 통신모듈;상기 통신모듈을 통해 수신된 전처리 가공된 검지 데이터를 이용하여 교차로 주변의 교통상황을 예측하고 최적의 신호주기를 산출하는 인공지능 딥러닝을 수행하는 딥러닝모듈;상기 딥러닝모듈에 의해 산출된 최적의 신호주기를 3차원 BIM 객체 모델링으로 구현된 가상 시뮬레이션에 적용하여 안정성 검증을 수행하는 BIM 검증모듈;을 포함하는 BIM 객체 모델을 이용한 인공지능 교통신호 제어 시스템."}
{"patent_id": "10-2019-0091168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서, 상기 딥러닝모듈은,행위자(Agent)가 현재 환경(Environment)의 상태(State)를 인식하여 특정한 행동(Action)을 취하고, 그 결과로달라진 미래 상태(State) 및 행위자에게 주어지는 보상(Reward)을 받는, 강화학습 알고리즘을 이용하여 차량의지체 시간을 최소화하는 신호주기를 산출하는 것을 특징으로 하는 BIM 객체 모델을 이용한 인공지능 교통신호제어 시스템."}
{"patent_id": "10-2019-0091168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 환경은 교차로 네트워크이고, 상기 환경의 상태(St)는 상기 교차로 네트워크에서의 이동류별 지체 시간이며, 상기 행위자는 신호제어 체계이고, 상기 행동(at)은 신호등에 의해 표시되는 신호 현시이며,공개특허 10-2021-0012814-4-상기 행위자의 행동결정 기준이 되는 보상치(Rt+1)는 신호 현시 표출 후의 네트워크 상의 이동류별 지체 시간의변화량이고, 상기 강화학습 알고리즘은 상기 보상치를 최대로 하는 신호주기를 산출하는 것을 특징으로 하는 BIM 객체 모델을 이용한 인공지능 교통신호 제어 시스템."}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 차량들의 지체시간을 최소화할 수 있는 최적의 신호주기를 산출하고, 산출된 최적의 신호주기의 안전 성을 검증할 수 있는 BIM 객체 모델을 이용한 인공지능 교통신호 호스트 서버 및 이를 포함하는 제어 시스템 및 제어 방법에 관한 것으로, (뒷면에 계속)"}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 교통신호 제어 시스템에 관한 것으로, 보다 구체적으로는 차량들의 지체시간을 최소화할 수 있는 최 적의 신호주기를 산출하고, 산출된 최적의 신호주기의 안전성을 검증할 수 있는 BIM 객체 모델을 이용한 인공지 능 교통신호 호스트 서버 및 이를 포함하는 제어 시스템 및 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전통적 교차로 신호 제어 체계는 교차로별 최적 신호시간을 고정하여 사용하는 고정식 신호 제어(Pre-timed control), 시간대별 최적 신호 시간을 적용하는 시간대별 신호 제어(TOD: Time-Of-Day), 차량의 유무에 따라 현 시의 삭제 및 녹색시간의 연장 또는 조기종결이 적용되는 감응식 신호 제어(Actuated Control) 및 준 감응식 신 호 제어(Semi-actuated control)가 존재한다(Koonce et al, 2008; Roess et al, 2011). 고정식 신호 제어 체계는 각 접근로의 교통량 및 용량을 통해 계산한 접근로별 포화도비와 한 주기 당 손실시간 을 통해 한 주기의 시간을 계산하여 도출하며, 각 현시별 녹색 시간은 접근로별 포화도비를 통해 배분한다. 고 정식 신호 제어 체계는 사전에 조사된 교통량 및 교통류의 특성을 통해 시간대별 또는 하루 동안 운영될 신호 전략을 수립하기 때문에 각 접근로의 시간대별 교통량 편차가 크지 않은 곳에 적용하는 것이 적절하다. 감응식 및 준 감응식 신호 제어 체계는 도로 상에 설치된 검지기로부터 정지선까지의 거리 및 접근로의 차량 속 도를 통해 산출한 초기 녹색 시간에 차량이 도착할 때마다 단위 녹색 시간을 연장하여 교차로 신호를 운영한다. 따라서 교통량이 적은 시간대나 주도로와 부도로의 교통량 차이가 클 경우 적용하는 것이 적절하며, 교통량이 많거나 주도로와 부도로의 교통량 수준에 큰 차이가 없을 경우에는 부도로에 주어지는 신호 시간이 과다하게 주 어져 결국 고정식 신호 제어 체계와 동일한 신호 제어가 이루어진다. 이처럼 전통적 신호 제어 체계는 교통량 및 보행량, 도로 기하구조 등을 통해 신호 현시 전략을 미리 수립하거 나, 수립된 신호 현시 전략을 차량의 도착에 따라 미세하게 조정하는 등 미리 조사한 자료에 의존하기 때문에 실시간으로 변하는 교통 패턴에 대응하기 쉽지 않다. 따라서 V2X(Vehicle to Everything) 기술을 탑재한 자율주 행 차량이 상용화되었을 때 자율주행 차량으로부터 수집되는 정보를 이용한 신호 운영이 불가능하며, 이를 해결 할 수 있는 실시간 신호 제어 체계가 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 2018-0016692호"}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 차량들의 지체시간을 최소화할 수 있는 최적의 신호주기를 산출하고, 산출된 최적의 신호주기의 안전 성을 검증할 수 있는 BIM 객체 모델을 이용한 인공지능 교통신호 호스트 서버 및 이를 포함하는 제어 시스템 및 제어 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 호스트 서버는, 지역 제어기로부터 수신한 검지 데이터를 전처리 가공하는 지역 컴퓨터로부터 전처리 가공된 검지 데이터를 수 신하고, 안정성 검증이 완료된 최적의 신호주기를 상기 지역 컴퓨터로 전송하는 통신모듈; 상기 통신모듈을 통 해 수신된 전처리 가공된 검지 데이터를 이용하여 교차로 주변의 교통상황을 예측하고 최적의 신호주기를 산출 하는 인공지능 딥러닝을 수행하는 딥러닝모듈; 상기 딥러닝모듈에 의해 산출된 최적의 신호주기를 3차원 BIM 객 체 모델링으로 구현된 가상 시뮬레이션에 적용하여 안정성 검증을 수행하는 BIM 검증모듈;을 포함한다. 본 발명의 일 양상에 의하면, 상기 딥러닝모듈은, 행위자(Agent)가 현재 환경(Environment)의 상태(State)를 인 식하여 특정한 행동(Action)을 취하고, 그 결과로 달라진 미래 상태(State) 및 행위자에게 주어지는 보상 (Reward)을 받는, 강화학습 알고리즘을 이용하여 차량의 지체 시간을 최소화하는 신호주기를 산출하는 것을 특 징으로 한다. 본 발명의 일 양상에 의하면, 상기 환경은 교차로 네트워크이고, 상기 환경의 상태(St)는 상기 교차로 네트워크 에서의 이동류별 지체 시간이며, 상기 행위자는 신호제어 체계이고, 상기 행동(at)은 신호등에 의해 표시되는 신 호 현시이며, 상기 행위자의 행동결정 기준이 되는 보상치(Rt+1)는 신호 현시 표출 후의 네트워크 상의 이동류별 지체 시간의 변화량이고, 상기 강화학습 알고리즘은 상기 보상치를 최대로 하는 신호주기를 산출하는 것을 특징 으로 한다. 본 발명의 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 제어 시스템은, 교차로를 주행하는 차량의 시간대별 차량 교통량을 검지하는 차량 검지부; 교차로 주변의 미세먼지 농도, 교차 로 주변의 이산화탄소 농도를 포함하는 환경 데이터를 검지하는 환경 검지부; 상기 차량 검지부와 환경 검지부 에 의해 검지된 검지 데이터를 수신하는 지역 제어기; 상기 지역 제어기로부터 상기 검지 데이터를 수신하여 전 처리 가공하는 지역 컴퓨터; 및, 상기 지역 컴퓨터로부터 전처리 가공된 검지 데이터를 수신하고, 상기 전처리 가공된 검지 데이터를 이용하여 인공지능 딥러닝을 수행하여 교차로 주변의 교통상황을 예측하고 최적의 신호주 기를 산출한 후, 산출된 최적의 신호주기를 3차원 BIM 객체 모델링으로 구현된 가상 시뮬레이션에 적용하여 안 정성 검증을 수행하고, 안정성 검증이 완료된 최적의 신호주기를 상기 지역 컴퓨터로 전송하는 호스트 서버;를 포함한다. 본 발명의 일 양상에 의하면, 날씨, 기온, 미세먼지 농도, 이산화탄소 농도 중 적어도 어느 하나를 포함하는 환경 데이터를 제공하는 외부 서버를 더 포함할 수 있다. 본 발명의 일 양상에 의하면, 상기 지역 컴퓨터는, 상기 지역 제어기로부터 수신된 검지 데이터를 엣지 컴퓨팅 기법으로 전처리 가공하는 것을 특징으로 한다. 본 발명의 일 양상에 의하면, 상기 호스트 서버는, 상기 지역 컴퓨터와 통신을 수행하는 통신모듈; 상기 통신모 듈을 통해 수신된 전처리 가공된 검지 데이터를 이용하여 교차로 주변의 교통상황을 예측하고 최적의 신호주기 를 산출하는 인공지능 딥러닝을 수행하는 딥러닝모듈; 상기 딥러닝모듈에 의해 산출된 최적의 신호주기를 3차원 BIM 객체 모델링으로 구현된 가상 시뮬레이션에 적용하여 안정성 검증을 수행하는 BIM 검증모듈;을 포함한다. 본 발명의 일 양상에 의하면, 상기 딥러닝모듈은, 행위자(Agent)가 현재 환경(Environment)의 상태(State)를 인 식하여 특정한 행동(Action)을 취하고, 그 결과로 달라진 미래 상태(State) 및 행위자에게 주어지는 보상 (Reward)을 받는, 강화학습 알고리즘을 이용하여 차량의 지체 시간을 최소화하는 신호주기를 산출하는 것을 특 징으로 한다. 본 발명의 일 양상에 의하면, 상기 환경은 교차로 네트워크이고, 상기 환경의 상태(St)는 상기 교차로 네트워크 에서의 이동류별 지체 시간이며, 상기 행위자는 신호제어 체계이고, 상기 행동(at)은 신호등에 의해 표시되는 신 호 현시이며, 상기 행위자의 행동결정 기준이 되는 보상치(Rt+1)는 신호 현시 표출 후의 네트워크 상의 이동류별 지체 시간의 변화량이고, 상기 강화학습 알고리즘은 상기 보상치를 최대로 하는 신호주기를 산출하는 것을 특징 으로 한다.본 발명의 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 제어 방법은, 차량 검지부가, 교차로를 주행하는 차량의 시간대별 차량 교통량을 검지하는 단계; 환경 검지부가, 교차로 주변 의 미세먼지 농도, 교차로 주변의 이산화탄소 농도를 포함하는 환경 데이터를 검지하는 단계; 상기 차량 검지부 와 환경 검지부가, 검지된 검지 데이터를 지역 제어기로 전송하는 단계; 상기 지역 제어기가, 상기 검지 데이터 를 지역 컴퓨터로 전송하는 단계; 상기 지역 컴퓨터가, 상기 검지 데이터를 수신하여 전처리 가공하여 호스트 서버로 전송하는 단계; 및, 상기 호스트 서버가, 상기 지역 컴퓨터로부터 전처리 가공된 검지 데이터를 수신하 고, 상기 전처리 가공된 검지 데이터를 이용하여 인공지능 딥러닝을 수행하여 교차로 주변의 교통상황을 예측하 고 최적의 신호주기를 산출한 후, 산출된 최적의 신호주기를 3차원 BIM 객체 모델링으로 구현된 가상 시뮬레이 션에 적용하여 안정성 검증을 수행하고, 안정성 검증이 완료된 최적의 신호주기를 상기 지역 컴퓨터로 전송하는 단계;를 포함한다. 본 발명의 일 양상에 의하면, 날씨, 기온, 미세먼지 농도, 이산화탄소 농도 중 적어도 어느 하나를 포함하는 환 경 데이터를 제공하는 외부 서버가 상기 호스트 서버로 환경 데이터를 전송하는 단계를 더 포함할 수 있다. 본 발명의 일 양상에 의하면, 상기 지역 컴퓨터가, 상기 지역 제어기로부터 수신된 검지 데이터를 엣지 컴퓨팅 기법으로 전처리 가공하여 상기 호스트 서버로 전송하는 것을 특징으로 한다. 본 발명의 일 양상에 의하면, 상기 호스트 서버는, 상기 지역 컴퓨터와 통신을 수행하는 통신모듈; 상기 통신모 듈을 통해 수신된 전처리 가공된 검지 데이터를 이용하여 교차로 주변의 교통상황을 예측하고 최적의 신호주기 를 산출하는 인공지능 딥러닝을 수행하는 딥러닝모듈; 상기 딥러닝모듈에 의해 산출된 최적의 신호주기를 3차원 BIM 객체 모델링으로 구현된 가상 시뮬레이션에 적용하여 안정성 검증을 수행하는 BIM 검증모듈;을 포함한다. 본 발명의 일 양상에 의하면, 상기 딥러닝모듈은, 행위자(Agent)가 현재 환경(Environment)의 상태(State)를 인 식하여 특정한 행동(Action)을 취하고, 그 결과로 달라진 미래 상태(State) 및 행위자에게 주어지는 보상 (Reward)을 받는, 강화학습 알고리즘을 이용하여 차량의 지체 시간을 최소화하는 신호주기를 산출하는 것을 특 징으로 한다. 본 발명의 일 양상에 의하면, 상기 환경은 교차로 네트워크이고, 상기 환경의 상태(St)는 상기 교차로 네트워크 에서의 이동류별 지체 시간이며, 상기 행위자는 신호제어 체계이고, 상기 행동(at)은 신호등에 의해 표시되는 신 호 현시이며, 상기 행위자의 행동결정 기준이 되는 보상치(Rt+1)는 신호 현시 표출 후의 네트워크 상의 이동류별 지체 시간의 변화량이고, 상기 강화학습 알고리즘은 상기 보상치를 최대로 하는 신호주기를 산출하는 것을 특징 으로 한다. 기타 본 발명의 다양한 측면에 따른 구현예들의 구체적인 사항은 이하의 상세한 설명에 포함되어 있다."}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 형태에 따르면, 인공지능 딥러닝인 강화학습 알고리즘을 통해 차량들의 지체시간을 최소화할 수 있는 최적의 신호주기를 산출할 수 있다. 또한, 산출된 최적의 신호주기를 3차원 BIM 객체 모델링으로 구현된 가상 시뮬레이션에 적용하여 교통신호의 오류를 미연에 방지하고 안전사고를 예방할 수 있다. 또한, 도시의 신 호등 시스템에 3차원 BIM 객체 모델링을 도입 적용함으로써, 스마트 도시로의 진화를 기대할 수 있다."}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예를 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 발명에서, '포 함하다' 또는 '가지다' 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하, 도면을 참조하여 본 발명의 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 호스트 서버 및 이를 포 함하는 제어 시스템 및 제어 방법을 설명한다. 도 1은 본 발명의 일 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 제어 시스템이 도시된 개념도이 다. 도 1에 도시된 바와 같이, 본 발명의 일 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 제어 시스템 (이하, ‘교통신호 제어 시스템’)은, 차량 검지부, 환경 검지부, 지역 제어기(200, LC: Local Controller ), 지역 컴퓨터(300, RC: Regional Computer), 호스트 서버를 포함한다. 차량 검지부는 도로, 교차로 등을 주행하는 차량의 시간대별 차량 교통량을 검지한다. 차량 검지부는 루프 검지기, 영상 검지기, AVI, 초단파 검지기, 적외선 검지기 중 적어도 어느 하나를 포함할 수 있다. 루프 검지기는 도로에 매설된 루프코일을 차량이 통과할 때 인덕턴스의 변화를 이용하여 교통 파라미터를 측정 하여, 교통량, 점유율, 속도, 대기행렬길이 등을 수집한다. 영상 검지기는 영상처리 기술을 이용하여 검지영역 통과시 교통 파라미터를 측정하여, 교통량, 점유율, 속도, 대기행렬길이, 차량길이, 주행궤적 등을 수집한다. AVI는 영상처리 기술을 이용하여 지점별 차량 번호판을 인식하고 구간속도 및 구간 통행시간 등을 산출한다. 초단파 검지기는 초단파 주파수를 이용하여 초단파가 차량에 충돌한 후 반사되어 오는 반사파를 감지하여 측정 하여, 교통량, 점유율, 속도, 대기행렬, 차두시간 등을 수집한다. 적외선 검지기는 Infrared Beam을 이용한 차량 검지기로서 교통정보 수집 용도의 초소형 차량검지기이며, 교통 량, 점유율, 속도 등을 수집한다. 환경 검지부는 도로, 교차로 주변의 미세먼지 농도, 이산화탄소 농도 등을 포함하는 환경 데이터를 검지한 다. 환경 검지부는 미세먼지 센서, 이산화탄소 센서 등을 포함할 수 있다. 지역 제어기는 차량 검지부와 환경 검지부에 의해 검지된 검지 데이터를 수신한다. 지역 제어기 는 지역 컴퓨터와 통신망으로 연결된다. 지역 제어기는 수신된 검지 데이터를 지역 컴퓨터(30 0)로 전송하고, 지역 컴퓨터의 제어 명령에 따라 신호등의 신호 주기를 제어한다. 불측의 사정에 의해 지 역 컴퓨터와 통신이 단절된 경우에는 지역 제어기는 자체 입력값에 의해 신호등의 신호 주기를 제어 할 수 있다. 지역 컴퓨터는 지역 제어기로부터 검지 데이터를 수신하여 전처리 가공한다. 구체적으로, 지역 컴퓨 터는 지역 제어기 제어 및 통신, 각종 이벤트 관리, 각종 DB 자료 초기화 및 계산, 기록, 갱신과 함 께, 지역 제어기를 통해 차량 검지부와 환경 검지부에서 전송된 검지 데이터를 초기 가공(전처 리 가공)하여 호스트 서버로 전송한다. 또한, 지역 컴퓨터는 호스트 서버와 지역 제어기 간의 명령과 자료 등을 가공하고 연결하는 역할을 한다. 본 발명에서 지역 컴퓨터는 지역 제어기로부터 전송 수신된 검지 데이터를 엣지 컴퓨팅(Edge computing) 기법으로 전처리 가공한다. 엣지 컴퓨팅 기법은 다양한 단말 기기에서 발생하는 데이터를 클라우드 와 같은 중앙 집중식 데이터센터로 보내지 않고 데이터가 발생한 현장 혹은 근거리에서 실시간 처리하는 방식으 로 데이터 흐름 가속화를 지원하는 컴퓨팅 방식이다. 엣지 컴퓨팅 기법은 처리 가능한 대용량 데이터를 발생지 (소스) 주변에서 효율적으로 처리함으로써 데이터 처리 시간이 큰 폭으로 단축되고 인터넷 대역폭 사용량이 감 소하는 장점이 있다. 여기서, 다양한 단말 기기는 차량 검지부, 환경 검지부, 지역 제어기가 될 수 있다. 호스트 서버는 지역 컴퓨터로부터 전처리 가공된 검지 데이터를 수신하고, 전처리 가공된 검지 데이 터를 이용하여 인공지능 딥러닝을 수행하여 교차로 주변의 교통상황을 예측하고 최적의 신호주기를 산출한다. 한편, 본 발명의 교통신호 제어 시스템은, 날씨, 기온, 미세먼지 농도, 이산화탄소 농도 중 적어도 어느 하나를 포함하는 환경 데이터를 제공하는 외부 서버를 더 포함할 수 있다. 외부 서버는 날씨, 기온, 미세먼 지 농도, 이산화탄소 농도 등을 포함하는 실시간 환경 데이터와 관련된 정보가 저장된 서버일 수 있다. 호스트 서버는 외부 서버로부터 환경 데이터를 직접 수신하고, 수신된 환경 데이터를 이용하여 인공지능 딥 러닝을 수행하여 교차로 주변의 교통상황을 예측하고 최적의 신호주기를 산출한다. 즉, 호스트 서버는 날 씨나 미세먼지 농도, 이산화탄소 농도 등의 환경 변화에 따른 교통량 변화와 그에 따른 차량의 지체에 대해 인 공지능 딥러닝을 수행하여, 최적의 신호주기를 산출한다. 호스트 서버는 외부 서버로부터 제공된 환 경 데이터를 이용함으로써, 교차로 주변에 설치된 환경 검지부가 외부 충격 등의 이유로 작동하지 못하는 경우에도 환경 변화에 따른 최적의 신호주기를 산출할 수 있게 된다. 또한, 호스트 서버는 산출된 최적의 신호주기를 3차원 BIM 객체 모델링으로 구현된 가상 시뮬레이션에 적 용하여 안정성 검증을 수행하고, 안정성 검증이 완료된 최적의 신호주기를 지역 컴퓨터로 전송한다. 호스 트 서버는 도로, 교차로 등에 설치된 복수개의 IoT 센서로부터 수신된 실시간 차량 정보, 교통 상황 정보 등을 이용하여 3차원 BIM 객체 모델링을 수행한다. 도 2는 본 발명의 일 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 제어 시스템의 호스트 서버 의 구조가 도시된 블록도이다. 도 2에 도시된 바와 같이, 호스트 서버는 통신모듈, 딥러닝모듈, BIM 검증모듈을 포함한다. 통신모듈은 지역 컴퓨터와 통신을 수행한다. 통신모듈은 지역 컴퓨터로부터 전처리 가공된 검지 데이터를 수신하여 딥러닝모듈로 전송하고, 딥러닝모듈에서 산출되고 BIM 검증모듈을 통해 안정성 검증이 완료된 최적의 신호주기를 지역 컴퓨터로 전송한다. 딥러닝모듈은 통신모듈을 통해 수신된 전처리 가공된 검지 데이터를 이용하여 교차로 주변의 교통상 황을 예측하고 최적의 신호주기를 산출한다. 딥러닝모듈은, 머신러닝의 한 분야인 강화학습(Reinforcement Learning : RL) 알고리즘을 이용하여 교통상 황 예측 및 최적 신호주기를 산출한다. 이에 대해서는 후술한다. BIM 검증모듈은 도로, 교차로 등에 설치된 복수개의 IoT 센서로부터 수신된 실시간 차량 정보, 교통 상황 정보 등을 이용하여 3차원 BIM 객체 모델링을 수행한다. BIM 검증모듈은 딥러닝모듈에서 산출된 최적 의 신호주기를 3차원 BIM 객체 모델링으로 구현된 실시간 가상 시뮬레이션에 적용하여 안정성 검증을 수행한다. 또한, BIM 검증모듈을 통해 현실 공간에서 생긴 문제를 가상의 공간에서 실시간으로 확인할 수 있으며, 가 상 공간의 신호 제어와 실제의 신호 제어를 동기화함으로써 현실의 문제도 즉각적으로 해결할 수 있게 된다. BIM 검증모듈은 실제의 도시 형태와 동일한 3차원 BIM 모델을 구축하고, GPS 모듈이 장착된 자율주행 자동 차로부터 실시간으로 위치 정보(GPS 정보)를 수신하여, 이를 3차원 BIM 모델에 적용함으로써 가상의 3차원 도시 에 실질적으로 실제 상황과 동일한 교통 환경을 구현한다. BIM 검증모듈은 교통 환경이 구현된 가상의 3차 원 도시 상에서 신호 주기를 제어하여 차량의 속도 및 정체도, 포화도 등을 가상으로 테스트하여 현실에서 발생 할 수 있는 문제점(정체발생 및 사고위험 등)을 미리 파악할 수 있게 된다. 한편, 가상의 3차원 도시 상에서의 차량의 움직임은 에이전트(AGENT) 기반의 룰-베이스드(Rule Based) 알고리즘을 활용하여 특정한 환경적 조건에 맞는 대응방식을 모사할 수 있다. 이와 같이, 딥러닝모듈에서 산출된 최적의 신호주기에 대해 BIM 검증모듈을 통해 미리 가상으로 구현 하여 산출된 신호주기가 실제 교통 상황에 적합한 지를 미리 검증하여 안정성에 대한 신뢰도를 높일 수 있다. 이하, 딥러닝모듈에서 수행되는 강화학습에 대해 설명한다. 1) 강화학습 강화학습은 기계학습의 한 분야로, 도 3에 도시된 바와 같이, 행위자(Agent)가 현재 환경(Environment)의 상태 (State)를 인식하여 특정한 행동(Action)을 취하고, 그 결과로 달라진 미래 상태(State) 및 행위자에게 주어지 는 보상(Reward)을 받는다. 행위자는 장기적으로 누적되는 보상을 최대화하는 방향으로 학습을 진행하며, 행위자의 행동뿐만 아니라 어떤 상태에서의 행동 전략을 나타내는 정책(Policy) 또한 최적화가 가능하다. 강화학습은 기계학습의 다른 분야인 지도학습(Supervised Learning) 및 비지도 학습(Unsupervised Learning)과 달리, 빅데이터를 요구하지 않고 변 화하는 상태에 대한 데이터를 통해 행동과 그에 상응하는 보상에 대한 데이터를 스스로 생성 및 학습하여 최적 행동 전략을 탐색하는 것이 가능하기 때문에 적절한 학습목표가 주어질 경우 목적에 부합하는 모형을 구축할 수 있으며 실시간으로 흘러가는 데이터를 통한 학습을 진행하기에 적절하다. 또한, 환경에 대한 정확한 모형이 요 구되지 않기 때문에 다양한 환경에 강화학습 모형을 적용하는 것이 가능하다. 따라서 다양한 기하구조가 존재하 는 도심부 신호 교차로에 적용될 경우, 교통류 변화에 반응하는 실시간 신호 제어 체계를 개발할 수 있다. 구체적으로, 어떤 환경 내에서 환경의 상태를 감지하는 행위자가 여러 가지 행동을 취해가면서 어떤 목표를 달 성하기 위한 최적 전략 또는 최적 행동을 탐색한다. 본 발명에서는 환경은 교차로 네트워크, 환경의 상태(St)는 이동류별 지체 시간, 행위자는 신호제어 체계, 행동(at)은 신호 현시로 설정하였다. 또한, 행위자의 행동결정 기 준이 되는 보상치(Rt+1)는 신호 현시 표출 후의 네트워크 상의 이동류별 지체 시간의 변화량으로 설정하여 이 보 상치를 최대화하는 최적 신호 현시를 표출할 수 있도록 하였다. 따라서, 신호 제어 체계는 신호 현시 표출을 통 해 지체 시간을 더욱 많이 감소시키려고 하며, 그 결과 교차로 전체의 지체 시간을 최소화하려고 한다. 2) Q-학습 강화학습은 마르코프 의사결정(MDP, Markov Decision Process)을 토대로 한다. 마르코프 의사결정은 행동이 즉 각적인 보상뿐만 아니라 후속적인 상황이나 미래의 보상에까지 영향을 미치는 연속적인 의사결정을 나타내는 방 법이다. 이러한 마르코프 의사결정을 기반으로 하는 Q-학습에서는 주어진 상황(s)에서 어떤 행동전략(π)에 속 하는 행동(a)을 취했을 때의 가치인 qπ(s,a)의 값을 추정하게 되며, 다음 식과 식 와 같이 나타낼 수 있 다.식 : qπ(s,a) = Eπ[Rt+1|st=s, at=a] 식 : qπ(s,a) ="}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "st : 시간 t에서의 상태 at : 시간 t에서 취한 행동 π : 행동 정책, 어떤 상태에서 선택가능한 모든 행동의 각 선택확률 qπ(s,a)\u0000: 정책 하에 있을 때, 특정 상태 s에서 행동 임의의 a를 취했을 때의 기대(예측) 보상치 Rt+1 : 할인율을 포함한 미래 기대 보상치 함수 γ: 보상치의 장기적/단기적 고려를 위한 할인율 변수 T: 시뮬레이션이 종료되는 최종 시간 : 시간 t에서의 상태 st에서 특정 행동 at를 취했을 때의 보상치 상태 s에서 어떤 행동 전략 π에 속하는 행동 a를 취했을 때 얻을 수 있는 보상치가 최대값이라면 이를 q*(s, a)라고 하며, 이 행동 a를 포함하는 정책 π는 최적 정책(Optimal policy)이 된다. 위 식에서 qπ(s,a)의 값은 주어진 상황 s에서 어떤 행동 전략 π에 속하는 행동 a를 취했을 때, 미래에 얻을 수 있는 보상치의 총합의 기 대값으로 표현된다. 이 때, 미래의 보상에 할인율인 γ를 적용함으로써, 행위자는 더 근시안적이거나 더 미래 지향적인 행동을 취할 수 있다. 환경에 대한 정보가 모두 알려져 있고 간단한 경우에는 모든 상태 s와 행동 a의 쌍에 따른 qπ(s,a)\u0000중 가장 큰 값이 q*(s,a)가 된다. 따라서 추정한 qπ(s,a)의 값과 최적값인 q*(s,a)과의 비교를 통해 항상 최고 보상치를 얻 게 하는 최적 정책을 알 수 있다. 하지만 대부분의 경우 환경의 역학(Dynamics)이 알려져 있지 않거나 상태-행 동 쌍(State-action pair) (s,a)가 무한히 많으므로, 시뮬레이션을 통한 표본 추출(Sampling)을 사용한다. 식 과 식 는 상태 s와 행동 a가 유한한 유한 마르코프 의사결정 과정이며, 이를 상태 및 행동이 무한할 때의 Q-학습으로 나타냈을 때의 Q-함수의 갱신 방법은 다음 식 과 같다. 식 :"}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "st : 시간 t에서의 상태 at : 시간 t에서 취한 행동 Rt+1 : 할인율을 포함한 미래 기대 보상치 함수 γ: 보상치의 장기적/단기적 고려를 위한 할인율 변수 α: Q-함수의 갱신에 사용되는 학습율(learning rate) 위 식에서 알 수 있듯이, Q-함수는 갱신 대상인 기존 Q-함수(Q(st,at))에, 시간 t에서의 상태(st)에서 취한 행동 (at)에 상응하는 보상치(Rt+1)와 시간 t+1에서 예측되는 미래의 보상치(Q(st+1,a))을 적용하여 갱신된다. 구체적 으로, Rt+1는 시간 t에서 어떤 행동(at)을 행했을 때 보상치의 미래 할인율을 적용한 기대값으로 시간 t를 포함한 이후 시간까지 고려한 보상치의 가치를 나타내며, 는 미래 상태(st+1)에서 최대 기대 보상치를 도출 하는 행동(a)을 취했을 때의 보상치의 기대값에 미래 할인율(γ)을 적용하여 도출된 기대 보상치로 시간 t+1 이 후에 얻을 수 있는 모든 보상치의 합, Q(st+1,a)는 현재 상태(st)에서 어떤 행동 at를 취했을 때의 기대 보상치이 다. 이러한 갱신 과정을 통해 Q-함수는 어떤 상황 st에서 미래까지의 보상치를 고려하여 최적의 행동 at를 도출 하게 된다. 한편, 시뮬레이션을 통한 표본 추출시 행위자가 경험한 상태-행동 쌍(s,a)와 이에 상응하는 보상치가 저장되며, 연속적인 상태 s에서의 qπ(s,a)는 지도학습을 통해 Q-함수에 대한 함수 추정의 형태로 행위자에게 학습된다. Q- 함수는 θ라는 새로운 변수에 의해 조정되며, 어떤 상태 s에 대한 정보가 Q-함수에 입력되면 θ에 의해 조정된 q값을 출력한다. 이 때, 학습은 Q-함수의 θ가 조정되면서 이루어지며, 다음 식 와 식 와 같다. 식 :"}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "식 :"}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "α : Q-함수의 갱신에 사용되는 학습율(learning rate) θt : Q-함수의 함수 추정시 이용되는 파라미터 위 식은 전통적 Q-함수의 파라미터 θ의 업데이트 과정으로, 어떤 환경의 정보가 입력되면 최적 행동이 도출되 며 도출된 행동에 의해 변화된 환경을 다시 관측하여 다시 최적 행동을 도출해낸다. 이 과정에서 하나의 식에 의해 모든 행동의 기대 보상치와 최적 행동 선택이 모두 이루어져 결국 기대 보상치의 편향 문제에서 자유로울 수 없다. 이 때, 예측 상의 편향을 최소화하기 위해, 모든 행동의 기대 보상치를 예측하는 평가 함수와 최적 행 동을 선택하는 조정 함수(선택 함수, Control function)를 분리하여 최적화를 실시하는 Double Q Learning 방 법론을 사용할 수 있다. 3) Double Q-학습 Dobule Q-학습은 전통적 Q-함수에서 기대 보상치 예측에서 발생할 수 있는 편향을 줄이기 위한 방법론으로, 모 든 행동의 기대 보상치를 예측하는 평가 함수와 최적 행동을 선택하는 조정 함수를 분리하여 최적화를 실시하며, Double Q-함수의 갱신은 다음 식 과 식 과 같이 나타낼 수 있다. 식 :"}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "식 :"}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "α : Q-함수의 갱신에 사용되는 학습율(learning rate) θt : Q-함수의 함수 추정시 이용되는 파라미터 위 식에서 나타나는 QA와 QB는 모두 평가 함수와 조정 함수를 포함하고 있으며 같은 문제에 대한 최적화를 진행 하지만, 두 함수에 저장되는 상태-행동 쌍과 이에 따른 보상치의 집합이 서로 다르기 때문에 하나의 Q-함수를 업데이트할 때 반대편 함수로부터 얻어진 값을 이용하여 이 과정에서 발생할 수 있는 과대 추정과 같은 편향을 줄일 수 있다. 4) Deep Q Network와 Double Deep Q Network Deep Q Network는 Q-함수의 학습시 딥러닝(Deep Learning)을 이용하는 방법으로 Q-함수에 대한 함수 추정에 심 층 인공 신경망을 사용하며, 이 때 딥러닝 기법을 적용하여 Q-함수의 함수 추정시 보다 빠르고 정확한 최적 행 동 결정을 가능케 한다. 기존의 Q-학습은 Q-함수 내의 파라미터인 θ를 조정해가면서 Q-함수를 갱신하여 최적값 에 수렴시켰으나, 이는 수렴 조건이 까다롭고 행위자(Agent)가 인지하는 환경(Environment)이 복잡할 경우, 특 히 지체 시간이나 오염물질 배출량과 같은 연속적 변수에서는 이에 따른 상태 표현과 이에 따른 상태-행동 쌍이 무한히 많아져 시뮬레이션을 이용한 샘플링 기법을 사용한다고 해도 특정 상황에서 모든 행동의 기대 보상치 예 측에 매우 복잡한 연산 과정을 거쳐야 하므로 계산 시간이 길어진다는 단점이 존재한다. 따라서, 이러한 최적화 과정에서의 단점을 극복할 수 있는 새로운 방법론이 요구된다. 딥러닝의 등장 이후로 이러한 복잡한 연산을 역전파 기법(Back Propagation), 드롭 아웃(Drop Out) 등으로 효율 적으로 처리할 수 있게 되었다. 또한, 딥러닝의 본질적인 단점인 심층 인공 신경망(Deep Neural Network) 구조 가 복잡해짐에 따른 학습효율의 저하는 인공 신경망 내 뉴런들의 활성 함수를 Sigmoid 함수 대신 ReLU(Rectified Linear Unit) 함수, 쌍곡탄젠트(Hyperbolic tangent) 함수 등을 사용하여 극복되었으며, Adam Optimizer 등의 새로운 최적화 함수를 사용하여 최적화의 효율을 높이고 있다. 이처럼 최근 딥러닝을 활용하여 실생활의 복잡하고 최적해를 찾기 힘든 여러 문제들이 해결되고 있다. 딥러닝을 적용한 Q-함수인 Deep Q Network의 최적화는 손실 함수(loss function)를 최소화하는 방향으로 이루어 진다. 손실 함수는 어떤 상태(st)에서 얻을 수 있는 보상치(Rt+1)가 최대인 특정 행동(at)을 취했을 때의 예측 보 상치와 실제 관측된 보상치의 차이를 나타내며, 앞서 설명한 Adam Optimizer를 통해 이 손실 함수의 수치를 최 소화하여 특정 상황에서 어떤 행동을 취해야 보상치를 최대로 얻을 수 있는 지 정확히 예측하는 방향으로 최적 화가 이루어진다. 단일 Q-함수와 딥러닝이 결합된 Deep Q Network의 손실 함수는 다음 식 과 같이 나타낼 수 있다. 식 :"}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "st : 시간 t에서의 상태 at : 시간 t에서 취한 행동 Rt+1 : 할인율을 포함한 미래 기대 보상치 함수 γ : 보상치의 장기적/단기적 고려를 위한 할인율 변수 θt : Q-함수의 함수 추정시 이용되는 파라미터 또한, Double Q-함수를 단일 Deep Q Network의 손실 함수에 적용하면 다음 식 와 같이 나타낼 수 있다. 식 :"}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "본 발명에서는 이러한 Double Deep Q Network 기법을 차량의 지체 시간을 최소화하는 최적의 신호 현시를 실시 간으로 표출하는 신호 제어 체계에 적용한다. 다음으로, Double Deep Q Network 기법을 이용하여 최적의 신호주기를 산출하는 과정을 설명한다. 아래의 설명에서, 최적의 신호주기는, 차량 검지부에서 수집된 개별 차량의 지체 시간 정보를 이용하여 산 출되는 것을 예시하며, 환경 검지부에서 수집된 환경 데이터에도 유사하게 적용될 수 있다. 1) 목적 함수 먼저, 개별 차량의 지체 시간 정보를 수집하여 지체 시간을 최소화하기 위한 목적 함수를 구축한다. 구축된 목 적 함수는 다음 식 , 식 과 같다. 식 : min st 식 :"}
{"patent_id": "10-2019-0091168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "st : 시간 t에서의 상태 i : 이동류j에서 이동중인 각각의 차량 j : 네트워크에서 각각의 이동류 dij,t : 시간 t에서 이동류j에 있는 각각의 차량i의 지체 시간 n : 이동류j의 총 차량수 위 식에서 나타나듯이, 시간 t에서 강화학습 모형에 입력되는 환경 상태 st는 모든 이동류 중 가장 큰 평균 지체시간을 보이는 이동류의 평균 지체시간으로 정의되며, 강화학습 모형은 식 에 의해 st를 최소화하는 방 향으로 학습을 진행하며, 전술한 Double Deep Q Network를 통해 학습이 이루어진다. 2) 강화학습 모형 강화학습에서 행위자의 학습 목표는 장기적으로 누적 보상치를 최대로 하는 것으로, 보상치를 어떻게 설정하느 냐에 따라 행위자의 학습 결과가 달라질 수 있다. 따라서 행위자의 행동으로 인해 변화하는 상황에 따른 보상치 를 적절하게 설정하여 행위자에게 부여하여야 한다. 개발된 알고리즘의 목적 함수에서 환경의 상태 표현을 지체 시간으로 하여 지체 시간을 최소화할 때에는 독립 신호교차로를 개선할 때의 주요 평가지표(MOE, Measure of Effectiveness)가 차량 지체시간이므로, 신호 표출 후 변화하는 차량 지체 시간을 보상치로 설정한다. 보상치 설정은 다음 식 와 같다.식 : Rt+1 = st+1 - st Rt+1 : 할인율을 포함한 미래 기대 보상치 함수 st : 시간 t에서의 상태 행위자에게 주어지는 신호 표출 이전 상태(st)와 표출한 신호 현시(at), 보상치(Rt+1), 신호 표출 이후 상태(st+ 1)는 누적되었다가 일정 시뮬레이션 시간 이후 무작위로 추출되어 학습에 사용된다. 행위자는 추출된 정보를 통 해 일정 횟수만큼 학습하며, 다시 일정 시뮬레이션 시간 동안 실시간으로 표출할 신호 현시를 결정한다. 행위자가 선택하는 신호 현시는, 도 4에 예시된 바와 같은, NB/SBTH, NB/SBLT, NBTH/LT, SBTH/LT, EB/WBTH, EB/WBLT, EBTH/LT, WBTH/LT이다. 행위자는 최종적으로 8개의 신호 현시 중 1개의 신호 현시를 선택하여 표출한 다. 물론, 8개의 신호 현시는 일 예일 뿐이며, 신호 체계가 더 고도화되는 경우, 신호 현시는 더 증가될 수도 있다. 학습 초반에는 임의의 신호 현시가 확률적으로 더 많이 표출되어 어떤 특정한 상태에서의 임의의 행동과 이에 따른 보상치 목록이 구성되며, 시뮬레이션이 진행됨에 따라 더 높은 확률로 행위자의 결정이 선택된다. 이를 통 해 행위자의 탐색과정(Exploitation & Exploration)을 가능하게 하며, 어떤 상태에서의 다양한 행동과 그에 따 른 보상치 목록을 활용하여 최적의 행동을 도출할 수 있기 때문에 지역해(Local optimum)에 빠지는 것을 방지할 수 있다. 또한, 인공 신경망 구조 내의 임의의 노드를 일정 비율에 따라 학습에서 배제(Drop out)하여 과적합(Over fitting) 문제를 방지할 수 있다. 마지막으로, 보상치에 할인율(Discount factor)을 적용하여 현재의 즉각적인 보상과 미래의 장기적인 보상 간에 적절한 선택이 가능하도록 할 수 있다. 도 5는, 행위자의 학습 과정 및 시뮬 레이션 수행에 사용하는 파라미터를 예시하고 있다. 본 발명을 통해 개발한 차량 지체 시간 최소화를 위한 실시간 신호 제어 체계 알고리즘의 전반적인 흐름도는 도 6과 같다. 다음으로, 도 7을 참조하여 본 발명의 일 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 제어 방법 을 설명한다. 도 7은 본 발명의 일 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 제어 방법이 도시 된 순서도이다. 차량 검지부가 교차로를 주행하는 차량의 시간대별 차량 교통량을 검지하고(S110), 환경 검지부가 교 차로 주변의 미세먼지 농도, 교차로 주변의 이산화탄소 농도를 포함하는 환경 데이터를 검지한다. (S120) 그 다음, 차량 검지부와 환경 검지부가 검지 데이터를 지역 제어기로 전송하고(S130), 이를 수 신한 지역 제어기는 검지 데이터를 지역 컴퓨터로 전송한다. (S140) 그 다음, 지역 컴퓨터는 수신된 검지 데이터를 전처리 가공한 후, 호스트 서버로 전송한다. (S150) 지역 컴퓨터는 지역 제어기로부터 전송 수신된 검지 데이터를 엣지 컴퓨팅(Edge computing) 기법으로 전처리 가공한다. 그 다음, 호스트 서버는 전처리 가공된 검지 데티터를 수신하고, 전처리 가공된 검지 데이터를 이용하여 인공지능 딥러닝을 수행하여 교차로 주변의 교통상황을 예측하고 최적의 신호주기를 산출한다. (S160) 호스트 서버의 일 구성인, 딥러닝모듈은 행위자(Agent)가 현재 환경(Environment)의 상태(State)를 인식하여 특정한 행동(Action)을 취하고, 그 결과로 달라진 미래 상태(State) 및 행위자에게 주어지는 보상 (Reward)을 받는, 강화학습 알고리즘을 이용하여 차량의 지체 시간을 최소화하는 신호주기를 산출한다. 여기서, 환경은 교차로 네트워크이고, 환경의 상태(St)는 교차로 네트워크에서의 이동류별 지체 시간이며, 행위 자는 신호제어 체계이고, 행동(at)은 신호등에 의해 표시되는 신호 현시이다. 행위자의 행동결정 기준이 되는 보상치(Rt+1)는 신호 현시 표출 후의 네트워크 상의 이동류별 지체 시간의 변화량이고, 강화학습 알고리즘은 보상 치를 최대로 하는 신호주기를 산출한다. 그 다음, 호스트 서버는 산출된 최적의 신호주기를 3차원 BIM 객체 모델링으로 구현된 가상 시뮬레이션에 적용하여 안정성 검증을 수행하고(S170), 안정성 검증이 완료된 최적의 신호주기를 지역 컴퓨터로 전송한 다. (S180) 그 다음, 지역 컴퓨터는 호스트 서버로부터 전송 수신된 신호주기를 지역 제어기로 전송하고, 지역 제어기는 전송 수신된 신호주기를 이용하여 신호등의 신호주기를 제어한다. (S190) 한편, 호스트 서버는 외부 서버로부터 환경 데이터를 직접 수신하고, 수신된 환경 데이터를 이용하여 인공지능 딥러닝을 수행하여 교차로 주변의 교통상황을 예측하고 최적의 신호주기를 산출할 수도 있다. 상기와 같은 본 발명의 일 실시예에 따르면, 인공지능 딥러닝인 강화학습 알고리즘을 통해 차량들의 지체시간을 최소화할 수 있는 최적의 신호주기를 산출할 수 있다. 또한, 산출된 최적의 신호주기를 3차원 BIM 객체 모델링 으로 구현된 가상 시뮬레이션에 적용하여 교통신호의 오류를 미연에 방지하고 안전사고를 예방할 수 있다. 또한, 도시의 신호등 시스템에 3차원 BIM 객체 모델링을 도입 적용함으로써, 스마트 도시로의 진화를 기대할 수 있다. 도 8은 본 발명의 실시예에 따른, 컴퓨팅 장치를 나타내는 도면이다. 도 8의 컴퓨팅 장치(TN100)는 본 명세서 에서 기술된 장치인, 차량 검지부, 환경 검지부, 지역 제어기, 지역 컴퓨터, 호스트 서버 , 외부 서버일 수 있다. 도 8의 실시예에서, 컴퓨팅 장치(TN100)는 적어도 하나의 프로세서(TN110), 송수신 장치(TN120), 및 메모리 (TN130)를 포함할 수 있다. 또한, 컴퓨팅 장치(TN100)는 저장 장치(TN140), 입력 인터페이스 장치(TN150), 출 력 인터페이스 장치(TN160) 등을 더 포함할 수 있다. 컴퓨팅 장치(TN100)에 포함된 구성 요소들은 버스 (bus)(TN170)에 의해 연결되어 서로 통신을 수행할 수 있다. 프로세서(TN110)는 메모리(TN130) 및 저장 장치(TN140) 중에서 적어도 하나에 저장된 프로그램 명령(program command)을 실행할 수 있다. 프로세서(TN110)는 중앙 처리 장치(CPU: central processing unit), 그래픽 처리 장치(GPU: graphics processing unit), 또는 본 발명의 실시예에 따른 방법들이 수행되는 전용의 프로세서를 의 미할 수 있다. 프로세서(TN110)는 본 발명의 실시예와 관련하여 기술된 절차, 기능, 및 방법 등을 구현하도록 구성될 수 있다. 프로세서(TN110)는 컴퓨팅 장치(TN100)의 각 구성 요소를 제어할 수 있다. 메모리(TN130) 및 저장 장치(TN140) 각각은 프로세서(TN110)의 동작과 관련된 다양한 정보를 저장할 수 있다. 메모리(TN130) 및 저장 장치(TN140) 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하나로 구 성될 수 있다. 예를 들어, 메모리(TN130)는 읽기 전용 메모리(ROM: read only memory) 및 랜덤 액세스 메모리 (RAM: random access memory) 중에서 적어도 하나로 구성될 수 있다. 송수신 장치(TN120)는 유선 신호 또는 무선 신호를 송신 또는 수신할 수 있다. 송수신 장치(TN120)는 네트워크 에 연결되어 통신을 수행할 수 있다. 한편, 본 발명의 실시예는 지금까지 설명한 장치 및/또는 방법을 통해서만 구현되는 것은 아니며, 본 발명의 실 시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있으며, 이러한 구현은 상술한 실시예의 기재로부터 본 발명이 속하는 기술 분야의 통상의 기술자라면 쉽게 구 현할 수 있는 것이다. 이상, 본 발명의 일 실시예에 대하여 설명하였으나, 해당 기술 분야에서 통상의 지식을 가진 자라면 특허청구범 위에 기재된 본 발명의 사상으로부터 벗어나지 않는 범위 내에서, 구성 요소의 부가, 변경, 삭제 또는 추가 등 에 의해 본 발명을 다양하게 수정 및 변경시킬 수 있을 것이며, 이 또한 본 발명의 권리범위 내에 포함된다고 할 것이다.부호의 설명 110 : 차량 검지부 120 : 환경 검지부 200 : 지역 제어기 300 : 지역 컴퓨터 400 : 호스트 서버 410 : 통신모듈 420 : 딥러닝모듈 430 : BIM 검증모듈 500 : 외부 서버"}
{"patent_id": "10-2019-0091168", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 제어 시스템이 도시된 개념도이 다. 도 2는 본 발명의 일 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 제어 시스템의 호스트 서버의 구조가 도시된 블록도이다.도 3은 강화학습에서의 행위자-환경 상호작용이 도시된 개념도이다. 도 4는 행위자(신호제어 체계)가 선택하는 신호 현시가 예시된 표이다. 도 5는 행위자(신호제어 체계)의 학습 과정 및 시뮬레이션 수행에 사용하는 파라미터가 예시된 표이다. 도 6은 본 발명을 통해 개발된 차량 지체 시간 최소화를 위한 실시간 신호 제어 체계 알고리즘의 전반적인 흐름 도이다. 도 7은 본 발명의 일 실시예에 따른 BIM 객체 모델을 이용한 인공지능 교통신호 제어 방법이 도시된 순서도이다. 도 8은 본 발명의 실시예에 따른, 컴퓨팅 장치를 나타내는 도면이다."}
