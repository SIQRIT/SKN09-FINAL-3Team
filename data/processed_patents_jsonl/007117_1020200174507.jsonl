{"patent_id": "10-2020-0174507", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0084738", "출원번호": "10-2020-0174507", "발명의 명칭": "인공 지능 신경망의 레이어에 다중 정밀도를 지원하는 방법 및 가속기", "출원인": "주식회사 사피온코리아", "발명자": "김원섭"}}
{"patent_id": "10-2020-0174507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능 신경망의 레이어에 다중 정밀도를 지원하는 방법으로서,입력 특징 맵(input feature map)의 채널들 중에서 같은 정밀도(precision)를 가지는 하나 이상의 채널들 및 이들 각각에 상응하는 커널(kernel)들을, 미리 설정된 비트 단위의 채널 그룹들로 구성하는 단계;상기 채널 그룹들 중에서 제1채널 그룹으로 구성된 제1채널들 및 제1커널들을 시스톨릭 어레이(systolic array)구조 내 처리 소자(processing element)에 입력하는 단계;상기 제1채널들의 정밀도에 따라, 상기 제1채널들 및 제1커널들을 기반으로 연산을 수행하는 단계; 및상기 연산된 결과를 누산기(accumulator)에 저장하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0174507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 연산을 수행하는 단계는,상기 제1채널들의 정밀도 및 상기 제1채널들의 정밀도에 의해 결정되는 상기 제1채널들의 개수 중에서 하나 이상에 기초하여, 상기 처리 소자(processing element)의 연산 유닛을 설정하는 단계; 및상기 연산 유닛이 설정된 처리 소자를 이용하여, 연산을 수행하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0174507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 연산 유닛을 설정하는 단계는,상기 제1채널들의 정밀도에 대응되도록, 상기 연산 유닛의 연산 단위를 설정하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0174507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 연산 유닛을 설정하는 단계는,상기 제1채널들의 개수에 대응되도록, 상기 연산 유닛의 개수를 설정하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0174507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 입력하는 단계는,상기 제1채널 그룹, 상기 연산된 결과 및 상기 누산기 각각에 대한 비트정보를 더 입력하고,상기 저장하는 단계는,상기 비트정보에 따라, 상기 연산된 결과의 소수부와 상기 누산기의 소수부를 정렬하여 상기 연산된 결과를 저장하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0174507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제1채널 그룹의 비트정보는,공개특허 10-2022-0084738-3-상기 제1채널 그룹의 정수부의 위치정보 및 소수부의 위치정보 중에서 하나 이상을 포함하고,상기 연산된 결과의 비트정보는,상기 연산된 결과의 정수부의 위치정보 및 소수부의 위치정보 중에서 하나 이상을 포함하며,상기 누산기의 비트정보는,상기 누산기의 정수부의 위치정보 및 소수부의 위치정보 중에서 하나 이상을 포함하는 것을 특징으로 하는방법."}
{"patent_id": "10-2020-0174507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "인공 지능 신경망의 레이어에 다중 정밀도를 지원하는 가속기로서,입력 특징 맵(input feature map)의 채널들 중에서 같은 정밀도(precision)를 가지는 하나 이상의 채널들 및 이들 각각에 상응하는 커널(kernel)들을, 미리 설정된 비트 단위의 채널 그룹들로 구성하는 제어기; 및누산기(accumulator)를 포함하는 처리 소자(processing element)들이 시스톨릭 어레이(systolic array) 구조로배열된 처리 소자 어레이를 포함하고,상기 처리 소자 어레이 내 처리 소자는,상기 채널 그룹들 중에서 제1채널 그룹으로 구성된 제1채널들의 정밀도에 따라, 상기 제1채널 그룹으로 구성된제1커널들 및 상기 제1채널들을 기반으로 연산을 수행하며, 상기 연산된 결과를 상기 누산기에 저장하는 것을특징으로 하는 가속기."}
{"patent_id": "10-2020-0174507", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 지능 신경망의 레이어에 다중 정밀도를 지원하는 방법 및 가속기를 개시한다. 본 발명의 일 실시예에 의하면, 인공 지능 신경망의 레이어에 다중 정밀도를 지원하는 방법으로서, 입력 특징 맵 (input feature map)의 채널들 중에서 같은 정밀도(precision)를 가지는 하나 이상의 채널들 및 이들 각각에 상 응하는 커널(kernel)들을, 미리 설정된 비트 단위의 채널 그룹들로 구성하는 단계; 상기 채널 그룹들 중에서 제1 채널 그룹으로 구성된 제1채널들 및 제1커널들을 시스톨릭 어레이(systolic array) 구조 내 처리 소자 (processing element)에 입력하는 단계; 상기 제1채널들의 정밀도에 따라, 상기 제1채널들 및 제1커널들을 기반 으로 연산을 수행하는 단계; 및 상기 연산된 결과를 누산기(accumulator)에 저장하는 단계를 포함하는 것을 특징 으로 하는 방법을 제공한다."}
{"patent_id": "10-2020-0174507", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 지능 신경망의 레이어에 대한 연산을 수행할 때 연산 처리 단위 별로 서로 다른 정밀도를 지원 하는 방법 및 가속기에 관한 것이다."}
{"patent_id": "10-2020-0174507", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 발명에 대한 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아니다. 인공 지능 신경망(artificial intelligence neural network) 또는 인공 신경망(artificial neural network)은 자연어 처리, 물체 인식, 자율 주행 등의 다양한 분야에서 활용되고 있으며, 하드웨어의 성능이 발전하고 인공 지능 신경망의 정확도가 향상됨에 따라 응용 분야가 확대되고 있다. 인공 지능 신경망의 정확도를 향상시키기 위해 인공 지능 신경망 모델의 크기를 증가시키는 연구가 계속되고 있 으며, 인공 지능 신경망의 정확도를 유지하면서도 처리 속도를 높이고 전력 소모를 최소화하는 기술에 대한 연 구도 뒤따르고 있다. 특히, 인공 지능 신경망의 정밀도를 낮추는 양자화(quantization) 기술은 처리 속도의 향 상과 전력 소모의 최소화라는 목적에 부합한다. 인공 지능 신경망 모델은 부동 소수점 방식(floating point format)의 하나인 단정도 부동 소수점 방식(single precision floating point format)을 바탕으로 설계된다. 부동 소수점 방식은 표현 범위가 넓을 뿐만 아니라 데 이터가 밀집된 영역의 정밀도를 높일 수 있으므로, 고정 소수점 방식에 비해 인공 지능 신경망 모델의 정확도를 높일 수 있다. 단정도 부동 소수점 방식은 위와 같이 인공 지능 신경망 모델의 정확도를 높일 수 있는 반면에, 전력 소모가 크 고 처리 속도가 느린 단점을 가진다. 따라서, 데이터의 정밀도가 낮아도 되는 상황에 한정하여, 양자화 기술이 적용된 부동 소수점 방식 또는 고정 소수점 방식이 사용된다. CNN(Convolutional Neural Network) 중심의 인공 지능 신경망에서 혼합 정밀도를 지원하는 기술이 비특허문헌 1 인 'Tianshu Chu et al., Mixed-Precision Quantized Neural Networks with Progressively Decreasing Bitwidth for Image Classification and Object Detection'에 소개된 바 있다. 비특허문헌 1은 레이어(계층) 별로 정밀도 요구가 다른 점을 이용하여 추론(inference) 과정에서 서로 다른 고정 소수점 숫자(1 비트 고정 소 수점 숫자로부터 최대 8 비트 고정 소수점 숫자)를 사용할 수 있도록 한다. 또한, 비특허문헌 1은 연산의 종류에 따라서도 입출력의 범위가 달라지는 점에 착안하여, 행렬 연산 이외에도 삼각함수, 지수함수, 로그함수 등의 초월함수에 따른 정밀도를 선택할 수 있도록 한다. 그러나, 비특허문헌 1은 레이어 별로 혼합 정밀도를 지원하는 방식이며 하나의 레이어에서는 동일한 정밀도를 지원한다. 이렇듯, 레이어 또는 연산의 종류에 따른 혼합 정밀도를 지원하는 방법은 소개된 바 있으나, 레이어 내에서 혼합 정밀도를 지원하는 방법은 아직 알려지지 않았다. 선행기술문헌 비특허문헌 (비특허문헌 0001) Tianshu Chu et al., Mixed-Precision Quantized Neural Networks with Progressively Decreasing Bitwidth for Image Classification and Object Detection, 2019.12."}
{"patent_id": "10-2020-0174507", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는, 하나의 레이어에 대해 혼합 정밀도를 지원함으로써 연산 처리 단위 별로 서로 다른 정 밀도를 지원할 수 있는 방법 및 가속기를 제공하는 데 주된 목적이 있다."}
{"patent_id": "10-2020-0174507", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 의하면, 인공 지능 신경망의 레이어에 다중 정밀도를 지원하는 방법으로서, 입력 특징 맵(input feature map)의 채널들 중에서 같은 정밀도(precision)를 가지는 하나 이상의 채널들 및 이들 각각에 상응하는 커널(kernel)들을, 미리 설정된 비트 단위의 채널 그룹들로 구성하는 단계; 상기 채널 그룹들 중에서 제1채널 그룹으로 구성된 제1채널들 및 제1커널들을 시스톨릭 어레이(systolic array) 구조 내 처리 소자 (processing element)에 입력하는 단계; 상기 제1채널들의 정밀도에 따라, 상기 제1채널들 및 제1커널들을 기반 으로 연산을 수행하는 단계; 및 상기 연산된 결과를 누산기(accumulator)에 저장하는 단계를 포함하는 것을 특 징으로 하는 방법을 제공한다 본 발명의 다른 일 실시예에 의하면, 인공 지능 신경망의 레이어에 다중 정밀도를 지원하는 가속기로서, 입력 특징 맵(input feature map)의 채널들 중에서 같은 정밀도(precision)를 가지는 하나 이상의 채널들 및 이들 각 각에 상응하는 커널(kernel)들을, 미리 설정된 비트 단위의 채널 그룹들로 구성하는 제어기; 및 누산기 (accumulator)를 포함하는 처리 소자(processing element)들이 시스톨릭 어레이(systolic array) 구조로 배열 된 처리 소자 어레이를 포함하고, 상기 처리 소자 어레이 내 처리 소자는, 상기 채널 그룹들 중에서 제1채널 그 룹으로 구성된 제1채널들의 정밀도에 따라, 상기 제1채널 그룹으로 구성된 제1커널들 및 상기 제1채널들을 기반 으로 연산을 수행하며, 상기 연산된 결과를 상기 누산기에 저장하는 것을 특징으로 하는 가속기를 제공한다."}
{"patent_id": "10-2020-0174507", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 인공 지능 신경망의 레이어 내 채널 그룹 단위 별로 정밀도를 다르게 적용하므로, 레이어 별로 동일 한 정밀도를 적용하는 종래 방식에 비하여 정확도를 유지시키면서도 단위 시간당 연산량을 향상시킬 수 있다. 또한, 본 발명은 채널 그룹 단위로 최적화된 정밀도를 적용함으로써 메모리 사용량을 감소시킬 수 있으므로, 대 용량 메모리를 요구하는 처리를 MEC(mobile edge computing) 수준의 하드웨어 장비에서 지원할 수 있게 된다. 나아가, 본 발명은 데이터 사용량을 감소시킬 수 있으므로, 인공 지능 처리를 위한 시스템과 외부 메모리 사이 의 에너지 당 대역폭(bandwidth/에너지)을 감소시킬 수 있다."}
{"patent_id": "10-2020-0174507", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구 체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 또한, 본 발명의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본 질이나 차례 또는 순서 등이 한정되지 않는다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 '포함', '구비' 한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 '…부', '모듈' 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현 될 수 있다. 본 발명은 레이어 내 연산 처리 단위로 다중 정밀도(또는, 혼합 정밀도)를 지원하는 방법 및 가속기에 관한 것 이다. 다중 정밀도를 지원하는 방법은 인공 지능 신경망 처리를 위한 비메모리 반도체 회로 구조 및 데이터 처 리 방식에 적용될 수 있다. 또한, 다중 정밀도를 지원하는 방법은 인공 지능, 신호처리, 그래픽스 등 많은 분야 에 적용될 수 있다. 특히, 다중 정밀도를 지원하는 방법은 그룹 단위의 입력 데이터가 특정 범위 내에 분포하여 그룹 단위의 연산 처리에 대한 최적화가 가능한 경우에 효과적일 수 있으며, 이 경우에 전력 소모를 감소시키고 성능을 높이기 위한 방법으로 활용될 수 있다. 다중 정밀도를 지원하는 가속기(이하에서는 '가속기'라 지칭하도록 한다)의 구조에 대한 일 예가 도 1에 나타나 있으며, 다중 정밀도를 지원하는 방법의 일 예가 도 2에 나타나 있다. 가속기는 인공 지능 신경망을 기반으로 데이터를 처리할 수 있다. 구체적으로, 가속기는 인공 지능 신경망의 컨벌루션 레이어(convolution layer)의 입력 특징 맵(input feature map)과 커널(kernel)(또는, 커널 데이터)을 기반으로 연산을 수행하고, 연산 결과로서 출력 특징 맵(output feature map)을 출력할 수 있다. 도 3을 참조하면, 3차원 형태의 입력 특징 맵은 너비 도메인(W), 높이 도메인(H) 및 깊이(depth) 방향의 채널 도메인(C)을 가질 수 있다. 입력 특징 맵은 복수 개의 채널들(C0 ~ Cm)을 포함할 수 있다. 복수 개의 채널들(또 는, 채널 성분들)은 서로 같거나 서로 다른 정밀도(precision)를 가질 수 있다. 여기서, 정밀도는 채널 내 성분 들을 수치로 표현한 비트 수를 의미한다. 서로 같은 정밀도를 가지는 연속하는 채널들은 하나의 채널 그룹(cg0, cg1, …)으로 설정 또는 구성될 수 있다. 커널은 입력 특징 맵을 필터링하기 위한 필터(또는, 가중치(weight))일 수 있다. 서로 같은 정밀도를 가지는 채 널들과 이 채널들 각각에 상응하는 커널들이 하나의 채널 그룹으로 구성될 수 있다. 도 1에 나타낸 바와 같이, 가속기는 메모리, 처리 소자 어레이 및 제어기를 포함할 수 있 다. 메모리는 입력 데이터를 저장하고, 저장된 입력 데이터를 처리 소자 어레이로 제공할 수 있다. 여기 서, 입력 데이터는 처리 소자 어레이를 통해 처리될 데이터로서, 입력 특징 맵 및 커널 중에서 적어도 하 나를 포함할 수 있다. 제어기는 메모리 및 처리 소자 어레이의 동작을 제어할 수 있다. 또한, 제어기는 입력 특 징 맵의 채널들 중에서 서로 같은 정밀도를 가지는 하나 이상의 채널들 및 이들 각각에 상응하는 커널들을 채널 그룹들로 구성할 수 있다(S202). 채널 그룹은 미리 설정된 비트 단위(예를 들어, 64bits)를 가질 수 있다. 채널 그룹에 미리 설정된 비트 단위가 64bits라고 가정하면, 8bits의 정밀도를 가지는 8개의 채널들이 하나의 채널 그룹으로 구성될 수 있고, 16bits 의 정밀도를 가지는 4개의 채널들이 하나의 채널 그룹으로 구성될 수 있으며, 4bits의 정밀도를 가지는 16개의 채널들이 하나의 채널 그룹으로 구성될 수 있다. 채널 그룹은 채널들의 정밀도 별로 구성되므로 채널 그룹은 복수 개일 수 있다. 이하에서는, 채널 그룹들 중에 서 첫 번째 채널 그룹을 '제1채널 그룹'이라 지칭하며, 제1채널 그룹으로 구성되는 채널들을 '제1채널들'이라 지칭하고, 제1채널 그룹으로 구성되는 커널들을 '제1커널들'이라 지칭하도록 한다. 제어기는 채널 그룹들을 처리 소자 어레이 내 처리 소자들로 입력할 수 있다(S204). 처리 소자들은 채널들의 정밀도(채널 그룹의 정밀도 또는 채널 그룹을 구성하는 채널들의 정밀도)에 따라, 입력 데이터를 기반 으로 연산을 수행할 수 있다(S206). 처리 소자 어레이는 복수 개의 처리 소자(processing element)들(P(0, 0), P(0, 1), P(1, 0), P(1, 1), …)을 포함할 수 있다. 처리 소자들은 메모리로부터 제공되는 입력 데이터를 기반으로 연산을 수행하고, 연산된 결과를 자체에 포함된 연산 유닛인 누산기(accumulator, 미도시)에 저장할 수 있다(S208). 또한, 처리 소자들은 입력 데이터를 주변의 다른 처리 소자들로 전달할 수 있다. 예를 들어, 처리 소자들은 입력 데이터를 기반으로 컨벌루션 연산을 수행할 수 있다. 즉, 처리 소자들은 덧셈 연산 또는 곱셈 연산 등을 수행할 수 있다. 이를 위해, 처리 소자들은 덧셈기(adder, 미도시) 및 곱셈기 (multiplier, 미도시)를 연산 유닛으로 더 포함할 수 있다. 입력 데이터가 벡터 형태(입력 특징 맵 벡터 X 및 커널 벡터 Y)인 경우, 처리 소자들은 입력 특징 맵 벡터 X와 커널 벡터 Y를 곱하고 더하는 수학식 1과 같은 벡터 내적 연산을 수행할 수 있다. 수학식 1"}
{"patent_id": "10-2020-0174507", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서, xi는 입력 특징 맵 벡터 X의 i-번째 성분을 나타내고, yi는 커널 벡터의 i-번째 성분을 나타내며, z는 벡터 내적 연산의 결과를 나타낸다. 처리 소자들은 수학식 2와 같이 정밀도에 따라 구분되는 채널 그룹 단위로 분할하여 입력 데이터에 대한 벡터 내적 연산을 수행할 수도 있다. 수학식 2"}
{"patent_id": "10-2020-0174507", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2에서, N은 채널 그룹들의 전체 개수에서 1을 뺀 값을 나타낸다. 3차원 형태의 입력 특징 맵 벡터 X의 성분을 로 하고, 3차원 형태의 커널 벡터 Y의 성분을 로 하면, 벡터 내적 연산은 아래 수학식 3과 같이 수행될 수 있다.수학식 3"}
{"patent_id": "10-2020-0174507", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "처리 소자 어레이는 복수 개의 처리 소자들이 시스톨릭 어레이(systolic array) 구조로 배열된 출력 고정 시스톨릭 어레이(output stationary systolic array, OSSA)로 구현될 수 있다. 4개의 행과 4개의 열로 구성된 OSSA에 대한 일 예가 도 4에 나타나 있다. 4개의 특징 맵 벡터들(X0,i,j,k, X1,i,j,k, X2,i,j,k, X3,i,j,k)은 클럭 사이클(cycle N)에 따라 순서대로 OSSA의 첫 번째 열에 위치하는 처리 소자들(P(0,0), P(1,0), P(2,0), P(3,0)) 각각에 입력된다. 구체적으로, 사이클 N에 X0,i,j,k 가 P(0,0)에 입력되며, 사이클 N+1에 X1,i,j,k가 P(1,0)에 입력되고, 사이클 N+2에 X2,i,j,k가 P(2,0)에 입력되며, 사이클 N+3에 X3,i,j,k가 P(3,0)에 입력된다. 4개의 커널 벡터들(Y0,i,j,k, Y1,i,j,k, Y2,i,j,k, Y3,i,j,k)은 클럭 사이클에 따라 순서대로 OSSA의 첫 번째 행에 위치하 는 처리 소자들(P(0,0), P(0,1), P(0,2), P(0,3)) 각각에 입력된다. 구체적으로, 사이클 N에 Y0,i,j,k가 P(0,0)에 입력되며, 사이클 N+1에 Y1,i,j,k가 P(0,1)에 입력되고, 사이클 N+2에 Y2,i,j,k가 P(0,2)에 입력되며, 사이클 N+3에 Y3,i,j,k가 P(0,3)에 입력된다. 특징 맵 벡터들과 커널 벡터들은 자신들이 입력된 처리 소자에서 연산 처리되며, 연산된 결과는 처리 소자 내 누산기에 (누적하여) 저장된다. 특징 맵 벡터들은 다음 사이클에 오른쪽에 위치한 다른 처리 소자에 입력(전달)된다. 구체적으로, 사이클 N에 P(0,0)에 입력된 X0,i,j,k는 사이클 N+1에 P(0,1)로 전달되며, 사이클 N+2에 P(0,2)로 전달되고, 사이클 N+2에 P(0,3)으로 전달된다. 커널 벡터들도 다음 사이클에 아래에 위치한 다른 처리 소자에 입력(전달)된다. 구체적으로, 사이클 N에 P(0, 0)에 입력된 Y0,i,j,k는 사이클 N+1에 P(1,0)으로 전달되며, 사이클 N+2에 P(2,0)으로 전달되고, 사이클 N+2에 P(3,0)으로 전달된다. 8bits의 정밀도를 가지는 채널들에 대해 OSSA 내 어느 처리 소자(P(0,0))에서 2x2 컨벌루션 연산(벡터 내적 연 산)을 처리하는 방법의 일 예가 도 5a 및 도 5b에 나타나 있다. 도 5a 및 도 5b에서는, 채널의 정밀도가 8bits이고, 연속한 8개의 채널들과 이들 각각에 상응하는 커널들이 64bits 크기의 채널 그룹들로 구성되어 총 4개의 채널 그룹들이 구성되는 것으로 가정한다. 도 5a의 (a)를 참조하면, 첫 번째 사이클(cycle 0)에서, 첫 번째 채널 그룹의 특징 맵 벡터 X(0,0,0)과 커널 벡 터 Y(0,0,0)이 P(0,0)에 입력된다. P(0,0)은 X(0,0,0)의 첫 번째 성분인 x(0,0,0,0) 및 두 번째 성분인 x(0,0,0,1)과, Y(0,0,0)의 첫 번째 성분인 y(0,0,0,0) 및 두 번째 성분인 y(0,0,0,1)에 대한 벡터 내적 연산을 수행한다. 연산된 결과인 Z0는 P(0,0) 내 누산기에 저장된다. 도 5a의 (b)를 참조하면, 두 번째 사이클(cycle 1)에서, 두 번째 채널 그룹의 특징 맵 벡터 X(0,0,1)과 커널 벡 터 Y(0,0,1)이 P(0,0)에 입력된다. P(0,0)은 X(0,0,1)의 첫 번째 성분인 x(0,0,1,0) 및 두 번째 성분인 x(0,0,1,1)과, Y(0,0,1)의 첫 번째 성분인 y(0,0,1,0) 및 두 번째 성분인 y(0,0,1,1)에 대한 벡터 내적 연산을 수행한다. 연산된 결과는 cycle 0에서 연산된 Z0와 합산되고, 합산된 결과인 Z1이 P(0,0) 내 누산기에 저장된다. 또한, X(0,0,0)은 오른쪽에 위치한 다른 처리 소자(P(0,1))로 전달되고, Y(0,0,0)은 아래쪽에 위치한 다른 처리 소자(P(1,0))로 전달된다. 도 5b 의 (a)를 참조하면, 세 번째 사이클(cycle 2)에서, 세 번째 채널 그룹의 특징 맵 벡터 X(0,1,0)과 커널 벡터 Y(0,1,0)이 P(0,0)에 입력된다. P(0,0)은 X(0,1,0)의 첫 번째 성분인 x(0,1,0,0) 및 두 번째 성분인 x(0,1,0,1)과, Y(0,1,0)의 첫 번째 성분인 y(0,1,0,0) 및 두 번째 성분인 y(0,1,0,1)에 대한 벡터 내적 연산을수행한다. 연산된 결과는 cycle 1에서 저장된 Z1과 합산되고, 합산된 결과인 Z2가 P(0,0) 내 누산기에 저장된다. 또한, X(0,0,1)은 오른쪽에 위치한 다른 처리 소자(P(0,1))로 전달되고, Y(0,0,1)은 아래쪽에 위치한 다른 처리 소자(P(1,0))로 전달된다. 도 5b 의 (b)를 참조하면, 네 번째 사이클(cycle 3)에서, 네 번째 채널 그룹의 특징 맵 벡터 X(0,1,1)과 커널 벡터 Y(0,1,1)이 P(0,0)에 입력된다. P(0,0)은 X(0,1,1)의 첫 번째 성분인 x(0,1,1,0) 및 두 번째 성분인 x(0,1,1,1)과, Y(0,1,1)의 첫 번째 성분인 y(0,1,1,0) 및 두 번째 성분인 y(0,1,1,1)에 대한 벡터 내적 연산을 수행한다. 연산된 결과는 cycle 2에서 저장된 Z2와 합산되고, 합산된 결과인 Z3가 P(0,0) 내 누산기에 저장된다. 또한, X(0,1,0)은 오른쪽에 위치한 다른 처리 소자(P(0,1))로 전달되고, Y(0,1,0)은 아래쪽에 위치한 다른 처리 소자(P(1,0))로 전달된다. 본 발명은 채널들의 정밀도에 따라 처리 소자 내 연산 유닛을 설정하거나 연산 유닛을 재구성할 수 있다. 연산 유닛을 설정하는 방법의 일 예가 도 6에 나타나 있다. 처리 소자는 하나의 채널 그룹에 포함된 채널들의 정밀도 및 개수 중에서 하나 이상에 기초하여 연산 유닛을 설 정할 수 있다(S602). 여기서, 채널들의 개수는 채널들의 정밀도에 의해 결정될 수 있다. 연산 유닛의 설정이 채널들의 정밀도에 기초하여 이루어지는 경우에, 처리 소자는 채널들의 정밀도에 대응되도 록 연산 유닛의 연산 단위를 설정할 수 있다(S604). 연산 유닛의 설정이 채널들의 개수에 기초하여 이루어지는 경우에, 처리 소자는 채널들의 개수에 대응되도록 연산 유닛의 개수를 설정할 수 있다(S604). 예를 들어, 도 7a의 (a) 및 도 7b의 (a)에 나타낸 바와 같이, 첫 번째 채널 그룹이 64bits의 미리 설정된 비트 크기를 가지고 채널들이 8bits의 정밀도를 가지면, 하나의 채널 그룹으로 구성되는 채널들의 개수는 8개이다 (X(0,0,0,0~7), Y(0,0,0,0~7)). 이 경우, 제어기는 8bits의 정밀도를 가지는 8개의 채널들을 처리하기 위 하여, 연산 유닛을 총 8개의 8bits 곱셈기를 가지는 연산 유닛으로 설정할 수 있다. 다른 예로, 도 7a의 (b)에 나타낸 바와 같이, 두 번째 채널 그룹이 64bits의 미리 설정된 비트 크기를 가지고 채널들이 4bits의 정밀도를 가지면, 하나의 채널 그룹으로 구성되는 채널들의 개수는 16개이다(X(0,0,0,8~23), Y(0,0,0,8~23)), 이 경우, 제어기는 4bits의 정밀도를 가지는 16개의 채널들을 처리하기 위하여, 연산 유 닛을 총 16개의 4bits 곱셈기를 가지는 연산 유닛으로 설정할 수 있다. 채널 그룹 내 채널들의 정밀도가 작은(감소하는) 경우에는 처리 소자가 동시에 처리할 수 있는 채널들의 개수가 증가하여 단위 시간 당 연산량이 증가하게 된다. 따라서, 총 8개의 채널들에 대한 연산을 수행하는 경우(도 7a 의 (a) 및 도 7b의 (a))에 비해, 총 16개의 채널들에 대한 연산을 수행하는 경우(도 7a의 (b))가 단위 시간 당 연산량이 2배로 증가될 수 있다. 또 다른 예로, 도 7b의 (b)에 나타낸 바와 같이, 세 번째 채널 그룹이 64bits의 미리 설정된 비트 크기를 가지 고 채널들이 16bits의 정밀도를 가지면, 하나의 채널 그룹으로 구성되는 채널들의 개수는 4개이다 (X(0,0,0,8~11), Y(0,0,0,8~11)). 이 경우, 제어기는 16bits의 정밀도를 가지는 4개의 채널들을 처리하기 위하여, 연산 유닛을 총 4개의 16bits 곱셈기를 가지는 연산 유닛으로 설정할 수 있다. 이와 같이, 본 발명은 채널들의 정밀도에 따라 연산 유닛을 설정하거나 연산 유닛의 설정을 재구성할 수 있다. 따라서, 본 발명은 모든 채널들(채널 그룹들)에 대해 동일한 설정의 연산 유닛을 이용하여 연산을 처리하는 방 법에 비해, 채널들의 다양한 정밀도 요구에 정확하게 대응함으로써, 인공 지능 신경망의 정확도를 향상시킬 수 있다. 한편, 채널 그룹들 간의 정밀도가 서로 다른 경우에, 각 채널들의 비트 위치에 따라 수치 해석이 달라질 수 있 다. 일반적으로, 고정 소수점 정밀도를 가지는 데이터를 처리하는 경우에는 정수부(integer parts)와 소수부 (fractional parts)를 미리 정해두고, 데이터를 처리하는 과정 중에 소수부의 자리 수를 일정하게 유지시킨다. 본 발명은 채널 그룹 별로 서로 다른 정밀도를 적용할 수 있으므로, 효과적인 정밀도 선택을 위해 채널 그룹, 연산된 결과 및 누산기 각각의 소수부의 자리 수를 선택하고, 각각의 소수부들을 정렬하는 방법이 요구된다. 소 수부를 정렬하는 방법의 일 예가 도 8에 나타나 있다.제어기는 비트정보가 처리 소자들에 입력되도록 제어할 수 있다(S802). 비트정보에는 채널 그룹, 연산된 결과 및 누산기 각각의 비트들에 대한 크기 정보, 정수부 정보 및 소수부 정보 중에서 둘 이상이 포함될 수 있다. 정수부 정보는 채널 그룹, 연산된 결과 및 누산기 각각의 비트들 중에서 정 수부(크기)를 나타내는 비트들의 위치정보에 해당한다. 소수부 정보는 채널 그룹, 연산된 결과 및 누산기 각각 의 비트들 중에서 소수부를 나타내는 비트들의 위치정보에 해당하거나, 소수점의 위치정보에 해당한다. 크기 정 보는 채널 그룹, 연산된 결과 및 누산기 각각의 비트들에 대한 크기를 나타낸다. 즉, 크기 정보는 정수부의 크 기와 소수부의 크기를 합산한 결과에 해당한다. 도 9a의 (a)를 참조하면, 채널 그룹의 비트들 중에서 가장 앞 자리(최좌측 자리)의 비트가 부호 비트(sign bi t)이며, 나머지 비트들이 정수부와 소수부(패턴으로 표현된 비트들)를 구성하고, 정수부와 소수부를 구분하는 위치가 소수점에 해당한다. 도 9a의 (b)를 참조하면, 연산된 결과의 비트들 중에서 가장 앞 자리의 비트가 부호 비트이며, 나머지 비트들이 정수부와 소수부(패턴으로 표현된 비트들)를 구성하고, 정수부와 소수부를 구분하는 위치가 소수점에 해당한다. 도 9a의 (c)를 참조하면, 누산기의 비트들 중에서 가장 앞 자리의 비트가 부호 비트이며, 나머지 비트들이 정수 부와 소수부(패턴으로 표현된 비트들)를 구성하고, 정수부와 소수부를 구분하는 위치가 소수점에 해당한다. 각 사이클마다 연산된 결과들이 누산기에 누적되어 저장되므로, 누산기의 정수부 위치, 소수부 위치 및 소수점 위 치는 이전 사이클에서 연산된 결과(누산기에 이미 저장된 결과)의 정수부 위치, 소수부 위치 및 소수점 위치와 동일하다. 비트정보가 정수부 정보 및 소수부 정보를 모두 포함하는 경우, 채널 그룹의 (정수부 정보, 소수부 정보)를 (k, l)이라 하고, 연산된 결과의 (정수부 정보, 소수부 정보)를 (m,n)이라 하며, 누산기의 (정수부 정보, 소수부 정 보)를 (o,p)라 하면, (k,l,m,n,o,p)가 처리 소자들에 입력될 수 있다. 도 9b에 예시된 바와 같이, 처리 소자들은 연산된 결과의 소수부(패턴으로 표현된 비트들)와 누산기의 소수부 (패턴으로 표현된 비트들)를 비트정보에 따라 정렬하고, 연산된 결과를 정렬된 상태로 누산기에 저장할 수 있다 (S804). 이전 사이클에서 연산된 결과가 누산기에 미리 저장되어 있는 경우, 처리 소자들은 현재 사이클에서 연 산된 결과의 소수부와 이전 사이클에서 연산된 결과(누산기에 미리 저장된 결과)의 소수부를 정렬하고, 정렬된 상태에서 두 결과들을 합산하여 누산기에 저장할 수 있다. 도 2, 도 6 및 도 8에서는 각 과정들이 순차적으로 실행되는 것으로 기재하고 있으나, 이는 본 발명의 일 실시 예의 기술 사상을 예시적으로 설명한 것에 불과한 것이다. 다시 말해, 본 발명의 일 실시예가 속하는 기술 분야 에서 통상의 지식을 가진 자라면 본 발명의 일 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 도 2, 도 6 및 도 8에 기재된 순서를 변경하여 실행하거나 각 과정들 중 하나 이상의 과정을 병렬적으로 실행하는 것으로 다양하게 수정 및 변형하여 적용 가능할 것이다. 따라서, 도 2, 도 6 및 도 8은 시계열적인 순서로 한정되는 것 은 아니다. 한편, 도 2, 도 6 및 도 8에 도시된 과정들은 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로 서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터 가 저장되는 모든 종류의 기록장치를 포함한다. 즉, 컴퓨터가 읽을 수 있는 기록매체는 ROM, RAM, CD-ROM, 자 기 테이프, 플로피디스크, 광 데이터 저장장치 등의 비일시적인(non-transitory) 매체일 수 있으며, 또한 캐리 어 웨이브(예를 들어, 인터넷을 통한 전송) 및 데이터 전송 매체(data transmission medium)와 같은 일시적인 (transitory) 매체를 더 포함할 수도 있다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다.부호의 설명"}
{"patent_id": "10-2020-0174507", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다중 정밀도를 지원하는 가속기를 개략적으로 나타낸 블록도이다. 도 2는 다중 정밀도를 지원하는 방법의 일 예를 설명하기 위한 순서도이다. 도 3은 3차원 형태의 특징 맵을 설명하기 위한 예시도이다.도 4, 도 5a 및 도 5b는 출력 고정 시스톨릭 어레이 구조의 처리 소자 어레이를 설명하기 위한 예시도이다. 도 6은 채널들의 정밀도에 따라 연산 유닛을 설정하는 방법의 일 예를 설명하기 위한 순서도이다. 도 7a 및 도 7b는 서로 다른 정밀도를 가지는 채널들에 대한 연산을 수행하는 방법의 일 예를 설명하기 위한 예 시도이다. 도 8은 소수부를 정렬하는 방법의 일 예를 설명하기 위한 순서도이다. 도 9a 및 도 9b는 소수부를 정렬하는 방법의 일 예를 설명하기 위한 예시도이다."}
