{"patent_id": "10-2017-0135244", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0043329", "출원번호": "10-2017-0135244", "발명의 명칭": "음성 신호 번역 방법 및 그에 따른 전자 장치", "출원인": "삼성전자주식회사", "발명자": "유지상"}}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번역하여 제2 사용자에게 제공하기 위한음성 신호 번역 방법에 있어서, 적어도 하나의 단어를 포함하는 상기 제1 음성 신호를 수신하는 단계; 상기 제2 사용자와 관련된 정보인 제1 정보에 근거하여 상기 제1 음성 신호의 번역에 적용되는 번역 레벨을 결정하고, 상기 결정된 번역 레벨에 따라서 상기 제1 음성 신호를 상기 제2 언어로 번역하는 단계; 및상기 제2 언어로 번역된 결과를 출력하는 단계를 포함하는 음성 신호 번역 방법."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 제1 정보는 상기 제1 언어로 형성된 상기 제1 음성 신호에 대한 상기 제2 사용자의 이해도를 나타내는 정보를 포함하는 것을 특징으로 음성 신호 번역 방법."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제1 정보는 상기 제2 사용자의 나이, 성별, 학렬, 직업, 국가 및 어학 점수 중 적어도 하나에 대한 정보를 포함하는 것을특징으로 하는 음성 신호 번역 방법."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 번역 레벨은상기 제1 음성 신호를 번역하는데 있어서, 상기 제1 음성 신호에 포함되는 적어도 하나의 단어에 대한 요약 또는 생략의 정도를 나타내는 정보를 포함하는 것을 특징으로 하는 음성 신호 번역 방법."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 제2 언어로 번역하는 단계는인공 신경망을 통한 연산을 수행하여, 상기 제1 음성 신호를 번역하는데 있어서 요약 또는 생략의 정도에 따라서 구별되는 복수개의 번역 레벨을 설정하는 단계; 상기 제1 정보에 근거하여 상기 복수개의 번역 레벨 중 제1 번역 레벨을 선택하는 단계; 및 상기 선택된 제1 번역 레벨에 따라서 상기 제1 음성 신호에 대한 번역을 수행하는 단계를 포함하는 것을 특징으로 하는 음성 신호 번역 방법."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 제1 정보는 이전에 번역이 수행되었던 이력, 상기 제2 사용자의 개인 정보, 번역이 수행되는 환경에 대한 정보, 및 상기 제1 음성 신호의 수신에 대응하여 상기 제2 사용자가 입력한 정보 중 적어도 하나를 포함하는 것을 특징으로 하는음성 신호 번역 방법."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 제2 언어로 번역하는 단계는 상기 제1 사용자의 발화 특성에 근거하여 상기 번역 레벨을 결정하고, 상기 결정된 번역 레벨에 따라서 상기 제공개특허 10-2019-0043329-3-1 음성 신호를 상기 제2 언어로 번역하는 단계를 포함하는 것을 특징으로 하는 음성 신호 번역 방법."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 제1 정보는 상기 제2 사용자와 관련된 번역 이력을 포함하며, 상기 음성 신호 번역 방법은 상기 제2 사용자와 관련된 번역 이력을 학습하여, 상기 제1 정보를 업데이트하는 단계를 더 포함하는 것을 특징으로 하는 음성 신호 번역 방법."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 제2 언어로 번역된 결과를 유무선의 통신 네트워크를 통하여 외부 전자 장치로 전송하는 단계를 더 포함하는 것을 특징으로 하는 음성 신호 번역 방법."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번역하여 제2 사용자에게 제공하기 위한전자 장치에 있어서, 적어도 하나의 단어를 포함하는 상기 제1 음성 신호를 수신하는 수신부; 상기 제2 사용자와 관련된 정보인 제1 정보에 근거하여 상기 제1 음성 신호의 번역에 적용되는 번역 레벨을 결정하고, 상기 결정된 번역 레벨에 따라서 상기 제1 음성 신호를 상기 제2 언어로 번역하는 프로세서; 및 상기 제2 언어로 번역된 결과를 출력하는 출력부를 포함하는 전자 장치."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 제1 정보는상기 제1 언어로 형성된 상기 제1 음성 신호에 대한 상기 제2 사용자의 이해도를 나타내는 정보를 포함하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 제1 정보는 상기 제2 사용자의 나이, 성별, 학렬, 직업, 국가 및 어학 점수 중 적어도 하나에 대한 정보를 포함하는 것을특징으로 하는 전자 장치."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 번역 레벨은상기 제1 음성 신호를 번역하는데 있어서, 상기 제1 음성 신호에 포함되는 적어도 하나의 단어에 대한 요약 또는 생략의 정도를 나타내는 정보를 포함하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서, 상기 프로세서는 인공 신경망을 통한 연산을 수행하여, 상기 제1 음성 신호를 번역하는데 있어서 요약 또는 생략의 정도에 따라서 구별되는 복수개의 번역 레벨을 설정하고, 상기 제1 정보에 근거하여 상기 복수개의 번역 레벨 중 제1 번역레벨을 선택하며, 상기 선택된 제1 번역 레벨에 따라서 상기 제1 음성 신호에 대한 번역을 수행하는 것을 특징으로 하는 전자 장치. 공개특허 10-2019-0043329-4-청구항 15 제10항에 있어서, 상기 제1 정보는 이전에 번역이 수행되었던 이력, 상기 제2 사용자의 개인 정보, 번역이 수행되는 환경에 대한 정보, 및 상기 제1 음성 신호의 수신에 대응하여 상기 제2 사용자가 입력한 정보 중 적어도 하나를 포함하는 것을 특징으로 하는전자 장치."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서, 상기 프로세서는 상기 제1 사용자의 발화 특성에 근거하여 상기 번역 레벨을 결정하고, 상기 결정된 번역 레벨에 따라서 상기 제1 음성 신호를 상기 제2 언어로 번역하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서, 상기 제1 정보는 상기 제2 사용자와 관련된 번역 이력을 포함하며, 상기 프로세서는 상기 제2 사용자와 관련된 번역 이력을 학습하여, 상기 제1 정보를 업데이트하는 것을 특징으로 하는 전자장치."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서, 상기 프로세서는 상기 제2 언어로 번역된 결과를 음성 합성 하여 음성 합성된 번역 결과를 생성하며, 상기 출력부는 상기 제2 언어로 번역된 텍스트 데이터를 포함하는 사용자 인터페이스 화면을 디스플레이 하는 디스플레이 및상기 음성 합성된 번역 결과를 출력하는 오디오 중 적어도 하나를 포함하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제10항에 있어서, 상기 프로세서의 제어에 따라서, 상기 전자 장치와 외부 전자 장치 사이의 데이터 송수신을 수행하는 통신부를더 포함하며, 상기 통신부는 상기 제2 언어로 번역된 결과를 상기 외부 전자 장치로 전송하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2017-0135244", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터에 의해서 실행 가능한 명령어들을 포함하는 프로그램을 기록한 기록 매체에 있어서, 상기 프로그램은 제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번역하여 제2 사용자에게 제공하기 위한음성 신호 번역 방법에 있어서, 적어도 하나의 단어를 포함하는 상기 제1 음성 신호를 수신하는 단계; 상기 제2 사용자와 관련된 정보인 제1 정보에 근거하여 상기 제1 음성 신호에 포함되는 적어도 하나의 단어 중적어도 하나의 번역을 생략할지 여부를 결정하고, 상기 결정에 따라서 상기 제1 음성 신호를 상기 제2 언어로번역하는 단계; 및공개특허 10-2019-0043329-5-상기 제2 언어로 번역된 결과를 출력하는 단계를 포함하는 방법을 실행하기 위한 명령어들을 포함하는 프로그램인 것을 특징으로 하는 기록 매체."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번역하여 제2 사용자에게 제공하기 위한 전 자 장치 및 그에 따른 방법이 개시된다. 개시된 전자 장치 및 그에 따른 방법은 음성 신호를 수신한 때부터 번역 결과를 출력하기까지 발생하는 지연 시 간을 최소화할 수 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 제1 사용자가 발화한 제1 음성 신호를 제2 언어로 번역하여 제2 사용자에게 제공하기 위한 방법 및 그에 따른 전자 장치에 대한 것이다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "서로 다른 언어를 사용하는 제1 사용자와 제2 사용자 간의 대화를 위하여 통역 또는 번역이 수행될 수 있다. 여 기서, 통역은 제1 언어로 형성된 음성 신호를 제2 언어로 형성된 음성 신호인 ‘말(speech)’로 변환하는 것이 고, 번역은 제1 언어로 형성된 음성 신호를 제2 언어로 형성된 ‘글(text)’로 변환하는 것이다. 이하에서는, 음성 신호를 인식하여 통역 또는 번역하는 것을 모두 ‘음성 번역(speech translation)’이라 지칭하겠다. 종래에는 서로 다른 언어를 사용하는 제1 사용자와 제2 사용자 간의 대화를 위하여, 제3의 사용자인 통역자가 수동으로 제1 사용자가 발화한 제1 음성 신호를 듣고, 이를 제2 언어로 변환하여 제2 사용자에게 말하였다. 그 에 따라서, 제2 사용자는 통역자가 말하는 통역 결과인 제2 언어로 변환된 제1 음성 신호를 듣고, 제1 사용자의 말을 이해할 수 있다. 최근에는 자동 음성 인식(automatic speech recognition) 기술 및 기계 번역(machine translation) 기술이 발 전함에 따라서, 음성 신호를 인식하고 이를 자동으로 번역하여 출력하는 음성 번역(speech translation) 기술이 탑재된 전자 장치가 생산되고 있다. 서로 다른 언어를 사용하는 제1 사용자와 제2 사용자 간의 통역을 자동으로 수행하기 위한 음성 번역 기술은 음 성 인식 단계, 번역 단계 및 음성 합성 단계로 구성될 수 있다. 음성 번역을 수행하는 전자 장치로 음성 신호가 입력되면, 입력된 음성 신호에 대하여 음성 인식이 수행되고, 음성 인식 결과로써 제1 언어 기반의 텍스트가 생성된다. 전자 장치는, 번역 단계에서 제1 언어 기반의 텍스트 를 제2 언어로 번역하여 제2 언어 기반의 텍스트를 생성한다. 계속하여 전자 장치는, 음성 합성 단계에서 제2 언어 기반의 텍스트를 제2 언어로 형성된 음성 신호로 변환한다. 그리고, 전자 장치는 스피커를 통해 제2 언어 로 형성된 음성 신호를 출력한다. 이러한 자동 음성 번역 기술에 있어서, 인공지능(Artificial Intelligence, AI) 시스템을 이용한 기계 번역이 이용될 수 있다. 전술한 자동 음성 번역 기술에 있어서, 음성 인식 단계, 번역 단계 및 음성 합성 단계를 각각 수행하는데 시간 이 소요되게 된다. 따라서, 음성 인식 단계, 번역 단계 및 음성 합성 단계 중 적어도 하나의 단계를 수행하는 데서 발생하는 시간들 중 불필요하게 소요되는 시간을 최소화하여 빠르고 실시간으로 번역 결과를 제공하는 것 이 무엇보다도 중요하다. 또한, 정확한 번역 결과를 제공하는 것이 중요하다. 여기서, 음성 인식 단계, 번역 단 계 및 음성 합성 단계 중 적어도 하나의 단계를 수행하는 데서 발생하는 시간들 중 불필요하게 발생하는 시간을 지연시간이라 할 수 있다. 따라서, 자동 음성 번역 방법 및 장치를 제공하는데 있어서, 번역의 대상이 되는 음성 신호를 수신한 때부터 번 역 결과가 출력되기까지의 시간 동안에 발생할 수 있는 지연 시간을 최소화할 필요가 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 번역의 대상이 되는 음성 신호를 수신한 때부터 번역 결과를 출력하기까지 발생하는 지연 시간을 최 소화할 수 있는 음성 신호 번역 방법 및 그에 따른 전자 장치를 제공의 목적으로 한다. 또한, 본 개시는 번역된 결과를 제공받는 사용자의 언어 능력에 맞춰 학습된 번역 레벨을 기반으로 최적화된 번 역 결과를 출력할 수 있는 음성 신호 번역 방법 및 그에 따른 전자 장치의 제공을 목적으로 한다. 또한, 학습된 번역 레벨을 기반으로, 통역자가 동시 통역을 수행할 때와 같이 사용자에 대한 정보 및 번역이 수"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "행되는 환경 정보 중 적어도 하나에 맞춰 최적화된 요약 서비스를 제공할 수 있는 음성 신호 번역 방법 및 그에따른 전자 장치의 제공을 목적으로 한다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시예에 따른 음성 신호 번역 방법은 제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번역하여 제2 사용자에게 제공하기 위한 음성 신호 번역 방법에 있어서, 적어도 하나의 단어를 포함하는 상기 제1 음성 신호를 수신하는 단계; 상기 제2 사용자와 관련된 정보인 제1 정보에 근거하여 상기 제1 음성 신 호의 번역에 적용되는 번역 레벨을 결정하고, 상기 결정된 번역 레벨에 따라서 상기 제1 음성 신호를 상기 제2 언어로 번역하는 단계; 및 상기 제2 언어로 번역된 결과를 출력하는 단계를 포함한다. 또한, 제1 정보는 상기 제1 언어로 형성된 상기 제1 음성 신호에 대한 상기 제2 사용자의 이해도를 나타내는 정 보를 포함할 수 있다. 또한, 상기 제1 정보는 상기 제2 사용자의 나이, 성별, 학렬, 직업, 국가 및 어학 점수 중 적어도 하나에 대한 정보를 포함할 수 있다. 또한, 상기 번역 레벨은 상기 제1 음성 신호를 번역하는데 있어서, 상기 제1 음성 신호에 포함되는 적어도 하나"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "의 단어에 대한 요약 또는 생략의 정도를 나타내는 정보를 포함할 수 있다. 또한, 상기 제2 언어로 번역하는 단계는 인공 신경망을 통한 연산을 수행하여, 상기 제1 음성 신호를 번역하는"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "데 있어서 요약 또는 생략의 정도에 따라서 구별되는 복수개의 번역 레벨을 설정하는 단계; 상기 제1 정보에 근 거하여 상기 복수개의 번역 레벨 중 제1 번역 레벨을 선택하는 단계; 및 상기 선택된 제1 번역 레벨에 따라서 상기 제1 음성 신호에 대한 번역을 수행하는 단계를 포함할 수 있다. 또한, 상기 제1 정보는 이전에 번역이 수행되었던 이력, 상기 제2 사용자의 개인 정보, 번역이 수행되는 환경에 대한 정보, 및 상기 제1 음성 신호의 수신에 대응하여 상기 제2 사용자가 입력한 정보 중 적어도 하나를 포함할 수 있다. 또한, 상기 제2 언어로 번역하는 단계는 상기 제1 사용자의 발화 특성에 근거하여 상기 번역 레벨을 결정하고, 상기 결정된 번역 레벨에 따라서 상기 제1 음성 신호를 상기 제2 언어로 번역하는 단계를 포함할 수 있다. 또한, 상기 제1 정보는 상기 제2 사용자와 관련된 번역 이력을 포함하며, 상기 음성 신호 번역 방법은 상기 제2 사용자와 관련된 번역 이력을 학습하여, 상기 제1 정보를 업데이트하는 단계를 더 포함할 수 있다. 또한, 본 개시의 실시예에 따른 음성 신호 번역 방법은 상기 제2 언어로 번역된 결과를 유무선의 통신 네트워크 를 통하여 외부 전자 장치로 전송하는 단계를 더 포함할 수 있다. 본 개시의 실시예에 따른 전자 장치는 제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번 역하여 제2 사용자에게 제공하기 위한 전자 장치에 있어서, 적어도 하나의 단어를 포함하는 상기 제1 음성 신호 를 수신하는 수신부; 상기 제2 사용자와 관련된 정보인 제1 정보에 근거하여 상기 제1 음성 신호의 번역에 적용 되는 번역 레벨을 결정하고, 상기 결정된 번역 레벨에 따라서 상기 제1 음성 신호를 상기 제2 언어로 번역하는 프로세서; 및 상기 제2 언어로 번역된 결과를 출력하는 출력부를 포함한다. 또한, 상기 제1 정보는 상기 제1 언어로 형성된 상기 제1 음성 신호에 대한 상기 제2 사용자의 이해도를 나타내 는 정보를 포함할 수 있다. 또한, 상기 제1 정보는 상기 제2 사용자의 나이, 성별, 학렬, 직업, 국가 및 어학 점수 중 적어도 하나에 대한 정보를 포함할 수 있다. 또한, 상기 번역 레벨은 상기 제1 음성 신호를 번역하는데 있어서, 상기 제1 음성 신호에 포함되는 적어도 하나"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "의 단어에 대한 요약 또는 생략의 정도를 나타내는 정보를 포함할 수 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 5, "content": "또한, 상기 프로세서는 인공 신경망을 통한 연산을 수행하여, 상기 제1 음성 신호를 번역하는데 있어서 요약 또 는 생략의 정도에 따라서 구별되는 복수개의 번역 레벨을 설정하고, 상기 제1 정보에 근거하여 상기 복수개의 번역 레벨 중 제1 번역 레벨을 선택하며, 상기 선택된 제1 번역 레벨에 따라서 상기 제1 음성 신호에 대한 번역 을 수행할 수 있다. 또한, 상기 제1 정보는 이전에 번역이 수행되었던 이력, 상기 제2 사용자의 개인 정보, 번역이 수행되는 환경에 대한 정보, 및 상기 제1 음성 신호의 수신에 대응하여 상기 제2 사용자가 입력한 정보 중 적어도 하나를 포함할수 있다. 또한, 상기 프로세서는 상기 제1 사용자의 발화 특성에 근거하여 상기 번역 레벨을 결정하고, 상기 결정된 번역 레벨에 따라서 상기 제1 음성 신호를 상기 제2 언어로 번역할 수 있다. 또한, 상기 제1 정보는 상기 제2 사용자와 관련된 번역 이력을 포함하며, 상기 프로세서는 상기 제2 사용자와 관련된 번역 이력을 학습하여, 상기 제1 정보를 업데이트할 수 있다. 또한, 상기 프로세서는 상기 제2 언어로 번역된 결과를 음성 합성 하여 음성 합성된 번역 결과를 생성하며, 상 기 출력부는 상기 제2 언어로 번역된 텍스트 데이터를 포함하는 사용자 인터페이스 화면을 디스플레이 하는 디 스플레이 및 상기 음성 합성된 번역 결과를 출력하는 오디오 중 적어도 하나를 포함할 수 있다. 또한, 본 개시의 실시예에 따른 전자 장치는 상기 프로세서의 제어에 따라서, 상기 전자 장치와 외부 전자 장치 사이의 데이터 송수신을 수행하는 통신부를 더 포함할 수 있다. 그리고, 상기 통신부는 상기 제2 언어로 번역된 결과를 상기 외부 전자 장치로 전송할 수 있다. 본 개시의 실시예에 따른 기록 매체는 컴퓨터에 의해서 실행 가능한 명령어들을 포함하는 프로그램을 기록한 기 록 매체이다. 여기서, 상기 프로그램은 제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번 역하여 제2 사용자에게 제공하기 위한 음성 신호 번역 방법에 있어서, 적어도 하나의 단어를 포함하는 상기 제1 음성 신호를 수신하는 단계; 상기 제2 사용자와 관련된 정보인 제1 정보에 근거하여 상기 제1 음성 신호에 포함 되는 적어도 하나의 단어 중 적어도 하나의 번역을 생략할지 여부를 결정하고, 상기 결정에 따라서 상기 제1 음 성 신호를 상기 제2 언어로 번역하는 단계; 및 상기 제2 언어로 번역된 결과를 출력하는 단계를 포함하는 방법 을 실행하기 위한 명령어들을 포함하는 프로그램 이다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예에 따른 음성 신호 번역 방법 및 그에 따른 전자 장치는 번역의 대상이 되는 음성 신호를 수신 한 때부터 번역 결과를 출력하기까지 발생하는 지연 시간을 최소화할 수 있다. 또한, 본 개시의 실시예에 따른 음성 신호 번역 방법 및 그에 따른 전자 장치는 번역된 결과를 제공받는 사용자 에 맞춰 최적화된 번역 결과를 출력할 수 있다. 구체적으로, 본 개시의 실시예에 따른 음성 신호 번역 방법 및 그에 따른 전자 장치는 번역된 결과를 제공받는 사용자의 언어 이해도, 언어 능력, 및 사용자가 존재하는 환경 중 적어도 하나에 맞춰 최적화된 번역 결과를 출력할 수 있다. 또한, 본 개시의 실시예에 따른 음성 신호 번역 방법 및 그에 따른 전자 장치는 통역자가 동시 통역을 수행할"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "때와 같이 사용자 및 번역 상황에 맞춰 최적화된 요약 서비스를 제공할 수 있다. 구체적으로, 본 개시의 실시예에 따른 음성 신호 번역 방법 및 그에 따른 전자 장치는 제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번역하여 제2 사용자에게 제공하는데 있어서, 제2 사용자와 관련된"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "정보인 제1 정보에 근거하여 번역의 생략 정도 또는 번역의 요약 정도를 결정함으로써, 제2 사용자에게 제공하 지 않아도 되는 부분에 대한 번역을 생략할 수 있다. 그에 따라서, 자동 음성 번역에 있어서 발생되는 지연 시 간을 최소화하여 보다 빠르게 번역 결과를 출력할 수 있다. 또한, 번역 결과를 제공받는 제2 사용자에게 최적화 된 간결하고 명확하게 번역 결과를 출력할 수 있다. 또한, 번역 결과를 제공받는 제2 사용자의 대화 패턴 또는 대화 이력을 인공 신경망을 이용하여 학습하여 사용 자의 언어 이해 수준에 최적화된 번역 결과를 출력할 수 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블록들 의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능 을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구 현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술 을 채용할 수 있다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 본 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미 하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. \"부\", \"모듈\"은 어드레싱될 수 있는 저장 매체에 저장되며 프로세서에 의해 실행될 수 있는 프로그램에 의해 구현될 수도 있다. 예를 들어, “부”, \"모듈\" 은 소프트웨어 구성 요소들, 객체 지향 소프트웨어 구성 요소들, 클래스 구성 요소 들 및 태스크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로 그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테 이블들, 어레이들 및 변수들에 의해 구현될 수 있다. 도 1은 본 개시에서 이용되는 자동 음성 번역 기술을 설명하기 위한 도면이다. 음성 번역(speech translation) 또는 음성 통역(speech interpretation) 기술은 입력된 제1 언어로 형성된 음 성 신호를 인식하고, 인식된 음성 신호를 제2 언어로 번역하는 기술에 관한 것이다. 음성 번역(speech translation)은 번역된 결과를 글(text)로 출력하는 것을 뜻하고, 음성 통역(speech interpretation)은 번역된 결과를 말(speech)로 출력하는 것을 뜻하므로, 음성 번역(speech translation)과 음성 통역(speech interpretation)은 번역의 결과를 출력하는 방식에 차이가 있을 뿐, 인식된 음성 신호를 다른 언어로 번역한다 는 점에서는 동일하다. 이하에서는, 설명의 편의상 음성 번역(speech translation) 또는 음성 통역(speech interpretation)을 모두 ‘ 음성 번역’이라 지칭하겠다. 또한, 전자 장치가 제공하는 음성 번역 기술을 ‘자동 음성 번역 서비스’라고 지 칭하겠다. 도 1을 참조하면, 제1 사용자는 제1 언어를 사용하는 사람이고, 제2 사용자는 제2 언어를 사용하는 사람이다. 또한, 제1 사용자 및 제2 사용자는 서로 다른 언어를 사용하여 상호 대화하는 화자들이다. 이하에서는, 제1 언어가 영어이며, 제2 언어가 한국어인 경우를 예로 들어 설명한다. 또한, 블록들(130, 140)은 음성 번역 기능을 제공하는 전자 장치의 동작들 나타낸다. 도 1에서는 전자 장치를 하나의 블록으로 도시하였으나, 자동 음성 번역 서비스를 제공하는 전자 장치 는 물리적으로 구별되는 복수개의 전자 장치들로 형성될 수 있다. 예를 들어, 제1 사용자의 전자 장 치(예를 들어, 제1 사용자 소유의 스마트 폰) 및 제2 사용자의 전자 장치(예를 들어, 제2 사용자 소유의 스마트 폰) 을 모두 이용하여, 자동 음성 번역 서비스를 수행할 수도 있을 것이다. 도 1을 참조하면, 제1 사용자는 제1 언어인 영어로 ‘Thank you’라고 발화한다. 전자 장치는 음성 신호인 ‘Thank you’를 수신하고, 수신된 음성 신호에 대한 음성 인식을 수행한다(131 블록 동작). 그리고, 음 성 인식된 ‘Thank you’를 제2 언어인 한국어로 번역한다(132 블록 동작). 여기서, 번역된 결과는 ‘감사 합니다’가 될 것이다. 계속하여, 전자 장치는 번역된 결과인 ‘감사합니다’를 음성 신호로 출력하기 위 해서 음성 합성 동작을 수행한다(133 블록 동작). 그에 따라서, 전자 장치는 ‘감사합니다’라는 음성 신 호를 제2 사용자에게 제공할 수 있다. 제2 사용자는 전자 장치가 출력하는 ‘감사합니다’라는 음성 신호를 듣고, 그에 대한 대답으로 ‘괜 찮아요’라고 발화할 수 있다. 그러면, 전자 장치는 제2 사용자가 발화한 ‘괜찮아요’를 음성 인식 하고(141 블록 동작), 이를 제1 언어인 영어로 번역한다(142 블록 동작). 여기서, 번역된 결과는 ‘You’re welcome’이 될 것이다. 계속하여, 전자 장치는 번역된 결과인 ‘You’re welcome’을 음성 신호로 출력하 기 위해서 음성 합성 동작을 수행한다(143 블록 동작). 그에 따라서, 전자 장치는 ‘You’re welcome’이 라는 음성 신호를 제1 사용자에게 제공할 수 있다. 일반적으로, 자동 음성 번역 기술은 자동적으로 입력되는 모든 음성 신호를 음성 인식하고 인식되는 모든 음성 신호에 대한 번역을 수행한다. 그러나, 경우에 따라서 음성 인식 단계, 번역 단계 및 음성 합성 단계 중 적어도 하나의 단계를 수행하는 데서 발생하는 시간들 중 쓸데없이 소요되는 시간이 존재할 수 있다. 예를 들어, 제2 사용자가 ‘Thank you’의 의미를 알고 있다면, ‘Thank you’를 ‘감사합니다’로 번역하여 제2 사용자에게 제공하는 동작은 불필요 한 동작이 되며, 이러한 번역 결과 출력을 위한 동작들(132, 133 동작)에 소요되는 시간은 쓸데없이 소요되는 시간이 될 수 있다. 도 1에서는 간단한 문장인 ‘Thank you’에 대한 번역을 예로 들어 설명하였지만, 이외에도 제1 사용자가 발화한 긴 문장 또는 복수개의 연속되는 문장에 대한 번역을 하는 경우, 제2 사용자가 긴 문장 또는 복수 개의 연속되는 문장 중 일부 또는 전부를 이해하는 경우, 이해한 부분에 대한 번역은 불필요할 수 있다. 또한, 제1 사용자가 발화한 적어도 하나의 문장 중 크게 의미가 없어서 번역을 생략하여도 무관한 부분도 번역이 불필요할 수 있다. 이하에서는 첨부된 도면을 참조하여, 전술한 예시에서와 같이 불필요한 부분에 대한 음성 번역을 수행하느라 쓸 데없이 소요되는 시간을 최소화하여, 보다 빠르게 번역 결과를 제공할 수 있도록 하는 본 개시의 실시예에 따른 음성 신호 번역 방법 및 그에 따른 전자 장치를 상세히 설명한다. 구체적으로, 본 개시의 실시예에 따른 음성 신호 번역 방법 및 그에 따른 전자 장치는 전술한 바와 같이 사용자가 이해한 표현 또는 사용자에게 불필요한"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "번역 부분에 대하여, 번역을 생략 또는 요약하여 제공함으로써, 불필요한 부분의 번역에 소요되는 시간을 줄일 수 있으며 보다 빠르게 실시간으로 번역 결과를 출력할 수 있다. 본 개시의 실시예에 따른 전자 장치는 제1 사용자가 발화한 제1 음성 신호를 제2 언어로 번역하여 제2 사용자에 게 제공한다. 구체적으로, 본 개시의 실시예에 따른 전자 장치는 자동 음성 번역 서비스를 제공할 수 있는 모든 전자 장치가 될 수 있다. 구체적으로, 전자 장치는 웨어러블 디바이스, 스마트 폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩탑 컴퓨터, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라 및 자동차의 전자 제어 장치, 중앙 정보 디스플레이(CID, Central Information Display) 등 모바일 컴퓨팅 장치 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 본 개시에 따른 음성 신호 번역 방법 및 그에 따른 전자 장치에서 제공하는 자동 음성 번역 서비스에 있어서, 인공지능(Artificial Intelligence, AI) 시스템이 이용될 수 있다. 인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 기계가 스스로 학습하고 판단하여 정확도를 높여나가는 시스템이다. 인공지능 시스템은 사용할수록 반복되는 학습에 의해서 산출되는 결과의 정확도가 향상되고 사용자의 의도를 보 다 정확하게 반영할 수 있게 되어, 기존의 규정 기반 스마트 시스템은 점차 딥러닝(Deep learning) 기반 인공지 능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습을 이용하는 기술이라 할 수 있으며, 딥러닝은 기계학습의 일 종류라 할 수 있다. 딥 러닝은 입력 데이터들의 특징을 스스로 분류 및 학습하는 알고리즘 기술이다. 그리고, 요소 기술은 딥러닝 등의 기계학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해 분야는 인간의 언어 및 문자를 인식하고 응 용 및 처리하는 기술 분야이며, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식 및/또는 합성 등을 포함한다. 시각적 이해 분야는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영 상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측 분야은 정보를 판단하여 논리 적으로 추론하고 예측하는 기술로서, 지식 및 확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한 다. 지식 표현 분야은 인간의 경험정보를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성 및 분류), 지식 관리(데이터 활용) 등을 포함한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술 로서, 움직임 제어(항법, 충돌, 주행), 조작 제어(행동 제어) 등을 포함한다. 이하에서는, 이러한 인공지능 시스템, 예를 들어, 신경망을 이용한 인공지능 시스템을 적용하여 지연 시간을 최 소화하고 사용자의 의도에 더욱 부합하는 번역 결과를 제공할 수 있는 음성 신호 번역 방법 및 그에 따른 전자 장치를 상세히 설명하도록 한다. 도 2는 본 개시의 일 실시예에 따른 전자 장치를 나타내는 블록도이다. 도 2를 참조하면, 전자 장치는 제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번역 하여 제2 사용자에게 제공하기 위한 전자 장치로, 수신부, 프로세서 및 출력부를 포함한다. 여 기서, 제1 사용자 및 제2 사용자 각각은 서로 다른 언어로 대화하는 복수의 사용자들 중 한 명이 될 수 있다. 이하에서는, 설명의 편의 상, 제1 언어를 사용하는 제1 사용자와 제2 언어를 사용하는 제2 사용자 간은 자동 음 성 번역 서비스를 제공하는 실시예를 예로 들어 설명한다. 즉, 제1 사용자는 번역의 대상이 되는 음성 신호를 발화한 사람이 되며, 제2 사용자는 번역된 결과를 제공받는 사람이 된다. 수신부는 적어도 하나의 단어를 포함하며 제1 언어로 형성된 제1 음성 신호를 수신한다. 구체적으로, 수신 부는 마이크를 포함하며, 마이크를 통하여 제1 음성 신호를 수신할 수 있다. 여기서, 수신부가 수신 하는 제1 음성 신호는 음성 인식 및 번역의 대상이 된다. 여기서, ‘단어’란 자립성과 분리성을 가지며, 일정한 뜻을 가지는, 말의 최소 단위를 뜻할 수 있다. 구체적으 로, ‘단어’는 번역을 통하여 그 뜻을 해석할 수 있는 말의 최소 단위가 된다. 따라서, 번역은 단어 단위로 수"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "행될 수 있으며, 번역의 생략 또는 번역의 요약은 단어 단위로 이뤄질 수 있을 것이다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "또한, 번역은 구문 단위, 또는 문장 단위로 수행될 수도 있다. 그에 따라서, 번역의 생략 또는 요약 또한 구문 단위 또는 문장 단위로 수행될 수 있을 것이다. 구문 또는 문장은 적어도 하나의 단어로 구성되므로, 번역은 적"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "어도 하나의 단어에 대하여 이루어진다 할 수 있으며, 번역의 생략 또는 요약 또한 적어도 하나의 단어 단위로 이뤄진다 할 수 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "그러므로, 번역, 번역의 생략, 및 번역의 요약 각각이 적어도 하나의 단어에 대하여 이뤄진다 할 것이다. 따라"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "서, 이하에서는 번역, 번역의 생략, 및 번역의 요약 각각이 적어도 하나의 단어에 대하여 이뤄지는 것으로 표현 하도록 하겠다. 즉, 이하에서는, 번역이 생략되는 단위 및 번역이 수행되는 단위로 ‘단어’를 예로 들어 설명할 것이나, 번역"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "및 번역의 생략 또는 요약은 적어도 하나의 단어로 이뤄지는 단어의 집합, 예를 들어, 구문, 또는 문장 등의 단 위로 이뤄질 수도 있을 것이다. 프로세서는 제2 사용자와 관련된 정보인 제1 정보에 근거하여, 상기 제1 음성 신호의 번역에 적용되는 번 역 레벨을 결정하고, 결정된 번역 레벨에 따라서 제1 음성 신호를 상기 제2 언어로 번역할 수 있다. 그리고, 프 로세서는 전술한 결정에 근거하여 제1 음성 신호를 제2 언어로 번역한다. 또한, 프로세서는 제2 사용자와 관련된 정보인 제1 정보에 근거하여, 제1 음성 신호에 포함되는 적어도 하 나의 단어 중 적어도 하나의 번역을 생략할지 여부를 결정할 수 있다. 그리고, 프로세서는 전술한 결정에근거하여 제1 음성 신호를 제2 언어로 번역할 수 있다. 구체적으로, 프로세서는 제1 음성 신호를 음성 인식하고, 제1 정보에 근거하여 음성 인식된 제1 음성 신호 를 제2 언어로 번역할 수 있다. 계속하여, 프로세서는 제2 언어로 번역된 결과를 음성 합성하여 출력할 수 있다. 여기서, 프로세서는 음성 인식된 제1 음성 신호인 음성 인식 데이터에 대하여 기계 번역(machine translation)을 수행한다. 또한, 프로세서는 음성 수신, 음성 인식, 음성 번역 및 음성 출력 중 적어도 하나의 동작을 포함하여 자동 음성 번역 서비스를 제공하기 위해서 필요한 동작들을 수행하기 위해서, 전자 장치에 포함되는 각 구성들 을 제어할 수 있다. 구체적으로, 프로세서에서 번역을 수행하는데 있어서, 인공지능(Artificial Intelligence) 분야에서 사용 되는 신경망(Neural Network)인 인공 신경망을 통해 번역을 수행할 수 있다. 인공 신경망은 인간의 신경망과 유 사한 구조로 가지는 네트워크로써, 입력된 신호를 복수의 계층(layer)을 통해 연산하고, 연산된 결과 값들에 기 초하여 학습(learning)을 수행하며 학습 결과에 따라 오차 범위를 줄임으로써, 정확도 높은 번역 결과를 출력할 수 있다. 여기서, 학습은 기계 학습을 포함할 수 있다. 구체적으로, 인공 신경망(Artificial Neural Network)을 이용한 기계학습인 딥 러닝(Deep learning)이 이용될 수 있다. 구체적으로, 인공 신경망은 복수개의 계층들을 포함할 수 있다. 각 계층에서는 입력된 신호인 제1 음성 신호에 가중치를 포함한 커널(Kernel)을 적용하여 제1 음성 신호에 대응되는 번역 결과를 출력한다. 여기서, 각 계층에 서 이용되는 가중치는 인공 신경망의 학습에 의해서 업데이트될 수 있다. 구체적으로, 프로세서는 입력 신호로 제1 정보 및 제1 음성 신호를 수신하고, 제1 정보 및 제1 음성 신호 를 학습하여 입력된 제1 음성 신호에 대한 제2 사용자의 언어 이해도를 분류할 수 있다. 프로세서는 복수 의 계층(layer)을 통한 연산을 제1 음성 신호에 포함되는 적어도 하나의 단어에 대한 제2 사용자의 언어 이해도 를 반복적으로 학습 및 분류하고, 학습된 결과에 따라서 제1 음성 신호에 포함되는 적어도 하나의 단어 중 적어 도 하나를 생략하여 번역을 수행할 수 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "또한, 프로세서는 생략 또는 요약된 번역의 결과가 자연스럽게 연결되는 문장 구조를 가지도록 학습하여,"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "제2 사용자의 언어 이해도에 맞춰 정확하게 요약된 번역 결과가 생성되도록 할 수 있다. 인공 신경망에 포함되는 복수개의 계층들에 의한 번역 동작 수행은 이하에서 도 11을 참조하여 상세히 설명한다. 출력부는 제2 언어로 번역된 결과를 출력한다. 출력부는 오디오 데이터를 출력하는 오디오 장치 및 영상 데이터를 출력하는 디스플레이 중 적어도 하나를 포함할 수 있다. 구체적으로, 출력부가 오디오 장치를 포함하는 경우, 오디오 장치는 프로세서에서 음성 합성된 번역 결과를 사용자가 청각적으로 인식할 수 있는 오디오 신호로 출력할 수 있다. 또는, 출력부가 디스플레이를 포함하는 경우, 디스플레이는 번역 결과인 텍스트 데이터를 포함하는 사용자 인터페이스 화면을 출력할 수 있다. 구체적으로, 수신부는 제1 음성 신호 또는 제1 음성 신호를 포함하는 오디오 신호를 입력받을 수 있다. 예를 들어, 오디오 신호는 제1 사용자가 발화하는 환경에서 발행하는 주변의 소음 등을 포함하는 주변음 및 제1 사용자가 발화하는 음성 신호를 포함하는 신호가 될 수 있다. 수신부가 제1 음성 신호를 수신하여 프로세서로 전달하면, 프로세서는 제1 음성 신호에 대한 음 성 인식을 수행할 수 있다. 구체적으로, 제1 음성 신호 이외의 다른 오디오 신호 성분이 제1 음성 신호와 함께 수신부로 수신될 경우, 프로세서는 수신된 오디오 신호 중 제1 음성 신호를 추출할 수 있다. 계속하 여, 프로세서는 추출된 제1 음성 신호에 대하여 음성 인식 및 번역을 수행할 수 있다. 음성 인식의 대상이 되는 제1 음성 신호를 추출하는 방법은 다양하게 존재할 수 있다. 예를 들어, 수신부는 수신된 오디오 신 호 중 사람 음성의 주파수 대역에 대응되는 신호 성분을 제1 음성 신호로 추출할 수 있다. 또한, 전술한 제1 음 성 신호의 추출 동작은 수신부에서 수행될 수도 있다. 이 경우, 수신부는 제1 음성 신호 이외의 다른 오디오 신호 성분이 제1 음성 신호와 함께 수신될 경우, 수신된 오디오 신호 중 제1 음성 신호를 추출할 수 있 다. 또한, 전자 장치는 외부 전자 장치에서 수신 및 음성 인식된 제1 음성 신호를 전송받을 수도 있을 것이다. 또한, 전자 장치는 외부 전자 장치(예를 들어, 무선 마이크, 유선 마이크, 다른 전자 장치 등)로부터 제1음성 신호를 전송받을 수도 있다. 이 경우, 전자 장치는 도 4를 참조하여 설명할 통신부를 통하여, 제1 음성 신호 또는 음성 인식된 제1 음성 신호를 전송받을 수 있다. 이 경우, 통신부는 전송된 제1 음성 신호 또는 음성 인식된 제1 음성 신호를 프로세서로 전달할 수 있다. 프로세서가 제1 음성 신호를 전 달받은 경우, 이를 음성 인식 및 번역할 수 있다. 또는, 프로세서가 음성 인식된 제1 음성 신호를 전달받 은 경우, 이를 번역할 수 있다. 전술한 바와 같이, 제1 사용자가 발화한 음성의 수신 동작은 외부의 음성 수신 장치(예를 들어, 무선 마이크, 유선 마이크, 웨어러블 디바이스 등), 외부의 음성 인식 장치(미도시) 등과 같은 외부 전자 장치, 및 수신부 중 적어도 하나에서 수행될 수 있다. 도 3a, 도 3b 및 도 3c는 전자 장치가 자동 음성 번역 서비스를 제공하는 동작을 설명하기 위한 도면이다. 도 3a, 도 3b, 도 3c 및 도 3d 각각에 도시된 제1 사용자는 도 1의 제1 사용자에 대응될 수 있다. 또 한, 도 3a, 도 3b, 도 3c 및 도 3d 각각에 도시된 전자 장치는 도 2의 전자 장치와 동일하다. 구체적으로, 음성 인식 동작은 자동 음성 인식(ASR: automatic speech recognition) 기술을 이용하여 수신되는 오디오 신호에서 사용자의 음성을 인식하는 동작을 뜻한다. 도 2에서 설명한 전자 장치는 음성 수신, 음성 인식 및 음성 번역 동작을 수행하는 장치가 되며, 전자 장 치가 수행하는 동작들 중 음성 수신 동작은 외부 전자 장치를 통하여 수행될 수도 있다. 또한, 전자 장치 가 수행하는 동작들 중 음성 수신 및 음성 인식 동작은 외부 전자 장치를 통하여 수행될 수도 있다. 구체적으로, 음성 수신 및 음성 인식 중 적어도 하나의 동작을 수행하고, 전자 장치와 연계되어 동작하는 외부 전자 장치(미도시)는 웨어러블 디바이스, 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라 및 자동차의 전자 제어 장치, 중앙 정보 디스플레이(CID, Central Information Display) 등 모바일 컴퓨팅 장치 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 외부 전자 장치는 전자 장치와 유선 또는 무선의 네트워크를 통하여 연결될 수 있다. 이하에서는, 전자 장치가 자동 음성 번역 서비스를 제공하기 위해서, 외부 전자 장치와 연계하여 동작하는 다양한 실시예들을 도 3b, 도 3c 및 도 3d를 참조하여 설명한다. 도 3a, 도 3b, 도 3c 및 도 3d에서는, 전자 장치가 스마트 폰인 경우를 예로 들어 도시하였다. 그리고, 음 성 수신, 음성 인식 및 번역 동작 중 적어도 하나의 동작을 수행하고, 전자 장치와 연계되어 동작하는 외 부 전자 장치(미도시)가 음성 인식 서버 및/또는 웨어러블 디바이스인 경우를 예로 들어 설명하였다. 도 3a는 전자 장치가 음성 신호를 직접 수신하여 자동 번역 서비스를 제공하는 경우를 예로 들어 도시한다. 전자 장치는 도 2에서 설명한 바와 같이, 화자가 발화한 제1 음성 신호를 수신하고, 수신된 제1 음성 신호 에 대하여 음성 인식을 수행한다. 예를 들어, 제1 사용자가 ‘Hello, nice to meet you.’라고 발화하면, 전자 장치는 제1 사용자가 발화한 제1 음성 신호인 ‘Hello, nice to meet you.’에 대응되는 오디오 신호를 수신한다. 그리고, 수신된 오디오 신 호를 음성 인식하여, ‘Hello, nice to meet you.’에 대응되는 데이터인 음성 인식 데이터를 획득할 수 있다. 그리고, 음성 인식 데이터에 대하여 번역을 수행하고, 번역된 결과를 출력한다. 도 3b는 전자 장치가 외부 전자 장치인 음성 인식 서버와 연계하여 자동 번역 서비스를 제공하는 경 우를 예로 들어 도시한다. 도 3b를 참조하면, 전자 장치는 제1 사용자가 발화한 음성 신호를 수신하고, 수신된 음성 신호를 음 성 인식 서버로 전송할 수 있다. 그러면, 음성 인식 서버는 도 1에서 설명한 음성 인식, 번역 및 음성 합성 동작을 수행하여, 번역 결과를 생성한다. 구체적으로, 전자 장치의 수신부는 제1 사용자가 발화한 음성 신호를 수신한다. 전자 장치(20 0)는 내부적으로 구비되는 통신부(미도시)를 통하여 음성 신호를 음성 인식 서버로 전송할 수 있다. 여기 서, 전자 장치는 음성 인식 서버와 소정 네트워크를 통하여 연결된다. 소정 네트워크는 유선 또는 무선의 네트워크로, 블루투스, WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), CDMA, WCDMA 등과 같은 통신 규격을 따르는 네트워크가 될 수 있다. 이하에서는, 전자 장치와 음성 인식 서버가 Wi-Fi 통신 규격을 따르는 네트워크를 통하여 소정 데이 터를 송수신하는 경우를 예로 들어 설명한다. 음성 인식 서버는 전자 장치로부터 Wi-Fi 통신 규격을 따르는 네트워크를 통하여 음성 신호를 수신하고, 수신된 음성 신호를 음성 인식 및 번역하여 번역 결과를 생성할 수 있다. 여기서, 번역 결과는 텍스 트 데이터가 될 수 있다. 또한, 번역 결과를 음성 합성하여 생성한 오디오 데이터가 될 수도 있을 것이다. 계속하여, 음성 인식 서버는 네트워크를 통하여 번역 결과를 전자 장치로 전송할 수 있다. 그러 면, 전자 장치의 출력부는 번역 결과 출력할 수 있다. 도 3c는 외부 전자 장치인 웨어러블 디바이스를 통하여 음성 신호를 수신하는 경우를 예로 들어 도시한다. 이 경우, 웨어러블 디바이스는 전자 장치와 유선 또는 무선의 네트워크를 통하여 연결될 수 있 다. 네트워크는 도 3b 에서 설명한 네트워크와 동일 대응될 수 있으므로, 상세 설명은 생략한다. 도 3c 에서는 네트워크가 블루투스 통신 규격에 따르는 네트워크인 경우를 예로 들어 설명한다. 외부 전자 장치인 웨어러블 디바이스는 제1 사용자가 발화한 음성 신호를 수신한다. 웨어러블 디바이 스는 수신된 음성 신호를 네트워크, 예를 들어, 블루투스 통신 규격에 따른 네트워크를 통하여 전자 장치로 전송한다. 그러면, 전자 장치는 전송된 음성 신호를 음성 인식 및 음성 번역하고, 번역된 결 과를 출력할 수 있다. 도 3d는 전자 장치가 외부 전자 장치인 웨어러블 디바이스를 통하여 음성 신호를 수신하고, 수신된 음성 신호를 음성 인식 서버로 전송하여 자동 음성 번역 서비스를 제공하는 경우를 예로 들어 도시한다. 도 3d 에 도시된 음성 인식 서버 및 네트워크는 도 3c 에 도시된 음성 인식 서버 및 네트워크 에 동일 대응되므로, 상세 설명은 생략한다. 도 3d를 참조하면, 외부 전자 장치인 웨어러블 디바이스는 제1 사용자가 발화한 음성 신호를 수신한 다. 웨어러블 디바이스는 수신된 음성 신호를 네트워크, 예를 들어, 블루투스 통신 규격에 따른 네트 워크를 통하여 전자 장치로 전송한다. 계속하여, 전자 장치는 전송된 음성 신호를 네트워크, 예 를 들어, Wi-Fi 통신 규격에 따른 네트워크를 통하여 음성 인식 서버로 전송한다. 그러면, 음성 인식 서버 는 음성 신호를 음성 인식 및 번역하여 번역 결과를 생성할 수 있다. 여기서, 번역 결과는 텍스트 데이터 가 될 수 있다. 또한, 번역 결과를 음성 합성하여 생성한 오디오 데이터가 될 수도 있을 것이다. 계속하여, 음성 인식 서버는 네트워크를 통하여 번역 결과를 전자 장치로 전송할 수 있다. 그러 면, 전자 장치의 출력부는 번역 결과 출력할 수 있다. 도 4는 본 개시의 다른 실시예에 따른 전자 장 치를 나타내는 블록도이다. 도 4를 참조하면, 본 개시의 다른 실시예에 따른 전자 장치는 수신부, 프로세서 및 출력부(43 0)를 포함한다. 그리고, 사용자 입력부, 통신부 및 메모리 중 적어도 하나를 더 포함할 수 있다. 도 4에 도시된 전자 장치에 있어서, 수신부, 프로세서 및 출력부는 각각 도 2에 도시된 전 자 장치의 수신부, 프로세서 및 출력부에 동일 대응된다. 따라서, 전자 장치를 설명 하는데 있어서 도 2의 전자 장치에서와 중복되는 설명은 생략한다. 수신부는 적어도 하나의 단어를 포함하며 제1 언어로 형성된 제1 음성 신호를 수신한다. 구체적으로, 수신 부는 제1 음성 신호를 수신하는 마이크를 포함할 수 있다. 구체적으로, 수신부가 제1 사용자가 발화한 제1 음성 신호를 입력받고, 이를 프로세서로 전달한다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "예를 들어, 제1 사용자가 ‘Hello, nice to meet you.’의 문장을 발화하고, 수신부는 제1 사용자가 발화 한 제1 음성 신호를 입력받는다. 그리고, 수신부는 입력된 제1 음성 신호를 프로세서로 전송한다. 그 러면, 프로세서는 제1 음성 신호를 음성 인식한다. 상기의 예에서, 음성 인식된 제1 음성 신호인 음성 인 식 데이터는 ‘Hello, nice to meet you.’에 대응되는 텍스트 데이터가 될 수 있다. 프로세서는 제2 사용자와 관련된 정보인 제1 정보에 근거하여 제1 음성 신호에 포함되는 적어도 하나의 단 어 중 적어도 하나의 번역을 생략할지 여부를 결정하고, 상기 결정에 근거하여 제1 음성 신호를 상기 제2 언어 로 번역한다. 여기서, 제1 정보는 제2 사용자의 언어 이해도, 언어 능력, 대화 환경 등을 나타내는 정보가 될 수 있다. 구체적으로, 프로세서는 기계 번역(MT: machine translation)을 통하여 음성 인식된 제1 음성 신호에 대응 되는 번역 결과를 생성할 수 있다. 여기서, 번역 결과는 텍스트 데이터로 생성될 수 있다. 계속하여, 프로세서 는 TTS(text to speech) 기술을 이용하여 번역 결과인 텍스트 데이터를 오디오 데이터로 변환할 수 있다. 즉, 프로세서는 음성 합성 동작을 수행하여, 번역 결과에 대응되는 오디오 데이터를 생성할 수 있다. 구체적으로, 프로세서는 인공 신경망을 이용하여 번역을 수행할 수 있다. 인공 신경망은 입력된 신호에 대 응되는 출력 신호를 생성하는데 있어서, 입력된 신호를 복수개의 계층(layer)를 통해서 자체적으로 학습함으로 써, 정확도 높은 출력 신호를 생성될 수 있도록 한다. 또한, 제1 정보는 제1 음성 신호에 포함되는 적어도 하나의 단어 중 적어도 하나에 대한 번역을 생략하여도, 제 2 사용자가 제1 음성 신호를 이해할 수 있는지 여부를 나타내는 정보가 될 수 있다. 또는, 제1 정보는 제1 음성 신호에 포함되는 적어도 하나의 단어 중 적어도 하나의 번역을 생략하는 것이, 제2 사용자의 의도에 맞는지 여 부를 나타내는 정보가 될 수 있다. 또한, 제1 정보는 제2 사용자의 요청 및/또는 번역을 수행하는 환경을 고려"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "하여 번역을 어느 정도로 요약하는지 판단할 수 있는 정보를 포함할 수 있다. 구체적으로, 제1 정보는 제1 언어로 형성된 제1 음성 신호에 대한 상기 제2 사용자의 이해도 또는 언어 능력을 나타내는 정보를 포함할 수 있다. 제1 정보는 메모리에 저장될 수도 있으며, 외부의 서버 장치(미도시)에 저장되어 있을 수도 있을 것이다. 제1 정보가 외부의 서버 장치에 저장된 경우, 프로세서는 통신부를 통하여 외부의 서버 장치로부터 제1 정보를 획득할 수 있을 것이다. 또한, 음성 인식 번역 서비스를 이용하는 복수의 사용자가 존재하는 경우, 제1 정보는 복수의 사용자 각각에 대 하여 획득될 수 있다. 또한, 제2 사용자에게 최적화된 번역 결과를 제공하기 위해서, 전자 장치는 제1 정보를 계속하여 업데이트 할 수 있다. 구체적으로, 전자 장치는 제1 정보를 인공 신경망을 통한 학습에 의하여 업데이트할 수 있다. 예를 들어, 제1 음성 신호는 Hello, nice, to, meet, 및 you의 5개의 단어를 포함할 수 있다. 프로세서는 제1 정보에 근거하여, 5개의 단어 중 적어도 하나의 번역을 생략할지 여부를 결정할 수 있다. 예를 들어, 제2 사용자가 ‘Hello’를 듣고, 국어 상의 의미인 ‘안녕’을 알고 있다면, ‘Hello’에 대한 번역은 생략하여도 무관하다. 이 경우, 프로세서는 ‘Hello’에 대한 번역은 생략하고, 나머지 부분인 ‘nice to meet you’ 만을 번역하여 ‘만나서 반가워’라는 번역 결과를 생성할 수 있다. 그러면, 전자 장치는 ‘안녕’을 번역 및 출력하는데 소요되는 시간을 감소시킬 수 있다. 또한, 제1 정보는 제2 사용자의 개인 정보, 번역이 수행되는 환경에 대한 정보, 및 제1 음성 신호의 수신에 대 응하여 제2 사용자가 입력한 정보 중 적어도 하나를 포함할 수 있다. 제1 정보는 이하에서 도 5 내지 도 8을 참 조하여 상세히 설명한다. 출력부는 제2 언어로 번역된 결과를 출력한다. 구체적으로, 프로세서는 음성 인식 및 번역을 수행하여, 제1 음성 신호에 대응되는 번역 결과를 포함하는 오디오 데이터 및 비디오 데이터 중 적어도 하나를 생성한다. 그리고, 프로세서는 오디오 데이터 및 비디 오 데이터 중 적어도 하나를 출력부로 전송한다. 그러면, 출력부는 프로세서에서 전송된 오디오 데이터 및 비디오 데이터 중 적어도 하나를 오디오 장치 및 디스플레이 중 적어도 하나를 통하여 출력한다. 출력부는 오디오 데이터 만을 출력할 수도 있고, 비디오 데이터 만을 출력할 수도 있을 것이다. 또한 출력 부는 오디오 데이터 및 비디오 데이터를 동시에 출력할 수도 있을 것이다. 예를 들어, 출력부는, 오디오 데이터 및 비디오 데이터를 각각 출력 할 수 있는 스피커 및 디스플레 이 중 적어도 하나를 포함할 수 있다. 구체적으로, 스피커는 번역된 결과를 제2 사용자가 청각적으로 인식할 수 있는 오디오 신호로 출력한다. 그리고, 디스플레이는 번역된 결과인 텍스트 데이터를 포함하는 사용자 인터페이스 화면을 출력한다. 또는, 디스플레이는 번역된 결과를 실시간으로 출력되는 자막 형태로 출력할 수 있을 것이다. 또한, 출력부는 번역된 결과를 외부 전자 장치(미도시)(예를 들어, 스마트 폰, 스마트 TV, 스마트 와치, 서버 등)로 전송할 수 있다. 이 경우, 외부 전자 장치(미도시)는 번역된 결과를 포함하는 오디오 데이터 및 비 디오 데이터 중 적어도 하나를 전송받고, 이를 제2 사용자에게 출력할 수 있을 것이다. 사용자 입력부는 전자 장치를 제어하기 위한 사용자 입력을 수신할 수 있다. 사용자 입력부는 사용자의 터치를 감지하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용자의 회전 조작을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch) 등을 포함하는 사용자 입력 디바이스를 포함할 수 있으나 이에 제한되지 않는다. 통신부는 유선 통신 또는 무선 통신을 통해 외부 전자 장치 또는 서버와 통신할 수 있다. 일 실시예에 따 른 통신부는, 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈, 방송 수신 모듈 등과 같은 적어도 하나 의 통신 모듈을 포함한다. 여기서, 적어도 하나의 통신 모듈은 블루투스, WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), CDMA, WCDMA 등과 같은 통신 규격을 따르는 네트워크를 통하여 데이터 송수신을 수행할 수 있는 통신 모듈을 뜻한다. 도 4에서는 통신부를 별도의 블록으로 도시하였으나, 통신부는 수신부를 포함하도록 형성될 수 도 있을 것이다. 또한, 전자 장치의 통신부는 도 3b, 도 3c, 및 도 3d 에서 설명한 바와 같이, 소정 네트워크(321, 335, 또는 351)을 통하여 외부 전자 장치 또는 서버와 통신할 수 있다. 도 3b, 도 3c, 및 도 3d 에서 설명한 바 와 같이, 전자 장치는 소정 네트워크를 통하여 연결되는 외부 전자 장치 또는 서버와 연계하여, 자동 음성 번역 서비스를 제공하기 위한 동작들을 수행할 수 있다. 본 개시의 실시예에 따른 통신부는 외부 전자 장치로부터 제1 음성 신호를 전송받을 수 있다. 이 경우, 통 신부는 전송된 제1 음성 신호를 프로세서으로 전송할 수 있다. 그러면, 프로세서는 수신된 제1 음성 신호를 음성 인식하여 번역할 수 있다. 메모리는 프로세서에서 번역된 결과를 저장할 수 있다. 메모리는, 수신부를 통해 수신되는 오디오 신호 또는 제1 음성 신호를 저장할 수 있다. 메모리는 문장 단위로, 일정한 시간 길이 단위로, 또 는 일정한 데이터 크기 단위로, 입력 오디오 신호를 수신하고 저장할 수 있다. 일 실시예에 따른 메모리는, 전자 장치를 제어하기 위해서 프로세서에서 실행되는 명령들을 저 장할 수 있다. 일 실시예에 따른 메모리는 제2 사용자와 관련된 정보인 제1 정보를 저장할 수 있다. 또한, 메모리는 번역을 수행하기 위해서 수신되는 음성 신호 및 음성 신호에 대한 음성 인식 결과를 저장할 수 있다. 또한, 메 모리는 제2 사용자가 제공받은 번역 결과에 대한 이력(이하, ‘발화 이력’)을 포함하는 데이터 베이스를 저장할 수 있다. 또한, 메모리는 복수개의 사용자들 각각에 대응되는 복수개의 제1 정보를 저장할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 제1 정보에 근거하여, 제1 음성 신호에 포함되는 적어 도 하나의 단어 중 적어도 하나의 번역을 생략할지 여부를 결정할 수 있다. 일 실시예에 따른 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모 리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 이하에서는, 본 개시의 실시예에 따른 전자 장치로 도 4에 도시된 전자 장치를 예로 들어, 본 개시의 실시 예에 따른 음성 신호 번역 방법 및 그에 따른 전자 장치의 상세 동작을 설명한다. 도 5는 본 개시의 일 실시예에 따른 제1 정보에 근거한 번역 동작을 상세히 설명하기 위한 도면이다. 도 5에 있 어서는, 번역 수행에 필요한 구체적인 동작을 설명하기 위해서, 도시된 바와 같이 블록으로 표시하였다. 도 5를 참조하면, 전자 장치는 제1 정보에 근거하여 제1 음성 신호에 포함되는 적어도 하나의 단어 중 적 어도 하나의 번역을 생략할지 여부를 결정할 수 있다(510 블록 동작). 여기서, 510 블록 동작은 프로세서 에서 수행될 수 있을 것이다. 505 블록은 제1 정보를 설명하기 위한 블록이다. 전술한 바와 같이, 제1 정보는 제2 사용자가 제1 음성 신호에 포함되는 적어도 하나의 단어 중 적어도 하나를 생략하여도, 제1 언어로 형성된 제1 음성 신호를 이해할 수 있 는지 여부를 나타내는 정보가 될 수 있다. 제1 정보는 제2 사용자의 개인 정보, 번역이 수행되는 환경에 대한 정보, 및 상기 제1 음성 신호의 수신에 대응 하여 상기 제2 사용자가 입력한 정보 중 적어도 하나를 포함할 수 있다. 제2 사용자의 개인 정보는 이하에서 도 6을 참조하여 상세히 설명한다. 도 6은 본 개시의 일 실시예에서 이용되는 제1 정보 중 제2 사용자의 개인 정보를 상세히 설명하기 위한 도면이 다. 제2 사용자의 개인 정보는 제2 사용자의 나이, 성별, 어학 점수, 학력, 직업, 및 국가 중 적어도 하나에 대한 정보를 포함할 수 있다. 도 6을 참조하면, 제2 사용자의 개인 정보는 사용자의 제1 언어로 형성된 제1 음성 신호에 포함된 적어도 하나 의 단어, 및/또는 적어도 하나의 문장에 대한 언어 이해도를 나타내는 정보들을 수집함으로써 획득될 수 있다. 도 6에서는, 제2 사용자의 제1 언어에 대한 이해도를 프로파일링 할 수 있는 정보로, 제2 사용자에 대한 개인 정보를 '사용자 프로파일링 정보'라 기재하였으며, 제2 사용자의 제1 언어에 대한 이해도를 복수개의 분류에 따 라서 프로파일링하는 실시예를 도시하였다. 전자 장치는 제2 사용자의 언어 이해도 또는 언어 능력을 판단하기 위하여, 사용자 프로파일링 정보를 획 득할 수 있다. 예를 들어, 전자 장치는 번역 결과를 제공받는 복수의 사용자들 각각 별로, 사용자 프로파 일링 정보를 획득하여 메모리에 저장할 수 있다. 구체적으로, 전자 장치는 사용자 입력부를 통 하여 사용자 별로 사용자 프로파일링 정보를 수신할 수 있다. 또는, 전자 장치는 자체적으로 사용자 프로 파일링 정보를 수집 및 획득할 수도 있다. 또한, 전자 장치는 외부의 서버 장치로부터 사용자 프로파일링 정보를 수신할 수도 있다. 사용자 프로파일링 정보는 사용자 어학 시험 성적 프로파일링, 사용자의 국가, 생활 지역 등을 나타내는 사용자 출신 정보 프로파일링, 사용자 학력 및 직종 프로파일링 등에 활용될 수 있다. 전자 장치는 내부 또는 외부적으로 구비되는 기억 장치, 예를 들어, 전자 장치와 유선 또는 무선 네 트워크를 통하여 연결되는 클라우드 서버를 참조한 사용자 프로파일링에 근거하여, 제1 음성 신호에 포함되는 단어 또는 문장을 제2 사용자가 제2 언어로 이해할 수 있는지 판단할 수 있다. 여기서, 사용자 프로파 일링 블록 동작은 프로세서에서 수행될 수 있다. 여기서, 클라우드 서버는 어학 시험 별 어학 능력 데이터 베이스, 국가 및 출신 별 및 어학 능력 데 이터 베이스, 및 학력 및 직종 별 어학 능력 데이터 베이스 등을 포함할 수 있다. 어학 시험 별 어학 능력 데이터 베이스는 소정 어학 시험의 시험 성적 구간 별로 사용자가 이해하고 있는 단어 및 문장을 분류하여 저장하고 있을 수 있다. 또한, 국가 및 출신 별 및 어학 능력 데이터 베이스는 국가 및 출신(어느 지역 출신인지 등) 별로 사용자 가 이해하고 있는 단어 및 문장을 분류하여 저장하고 있을 수 있다. 또한, 학력 및 직종 별 어학 능력 데이터 베이스는 학력 및 직종 중 적어도 하나에 따라서 사용자가 이해 하고 있는 단어 및 문장을 분류하여 저장하고 있을 수 있다. 예를 들어, 사용자 어학 시험 성적 프로파일링을 위하여 입력된 사용자 프로파일링 정보에 포함되는 제2 사용자의 공인 영어 시험의 시험 성적이 상위권에 해당한다고 가정하자. 그러면, 전자 장치는 어학 시험 별 어학 능력 데이터 베이스를 참조하여 제1 음성 신호에 포함되는 적어도 하나의 단어들, 또는 적어도 하 나의 문장들 중 적어도 하나를, 제2 사용자가 이해하고 있는 것으로 판단할 수 있다(634 블록 동작). 구체적으 로, 634 동작은 프로세서에서 수행될 수 있을 것이다. 이하에서는, 634 동작의 구체적인 실시예들을 상세히 설명한다. 예를 들어, 전자 장치는 제2 사용자의 나이에 대한 정보를 나이대별 신조어 및 주사용 언어를 고려하여 사 용자 이해 모델의 초기값으로 사용할 수 있다. 여기서, ‘사용자 이해 모델’은 번역 결과를 제공받는 제2 사용 자가 번역 결과의 제공이 없이도 뜻을 이해할 수 있는지 여부를 나타내는 모델을 뜻할 수 있다. 예를 들어, 전자 장치는 20대에서 공통적으로 관심 있는 가수 이름은 제2 사용자가 번역 없이도 이미 이해하는 것으로 판단할 수 있다. 그러면, 전자 장치는 해당 가수 이름에 대한 번역을 생략할 수 있다. 또한, 전자 장치는 제2 사용자의 성별에 대한 정보를 남녀에 따른 관심사를 구분 및 관련시켜 사용자 이해 모델의 초기값으로 사용 할 수 있다. 예를 들어, 20 대의 남자는 게임에 대한 관심사가 높고 20대의 여자는 화 장품에 대한 관심사가 높으므로, ‘game’이란 단어는 20대 남자인 제2 사용자가 이미 이해하고 있는 단어로 판 단할 수 있으며, ‘cosmetics’는 20대 여자인 제2 사용자가 이미 이해하고 있는 단어로 판단할 수 있을 것이다. 또한, 전자 장치는 제2 사용자의 어학 수준에 대한 정보를, 어학 수준에 따라 번역이 필요 없는 표현들을 구별하는 사용자 이해 모델의 초기값으로 사용할 수 있다. 또한, 전자 장치는 제2 사용자의 학력에 대한 정보를, 학력 수준에 따라 문장 난이도별로 이해하고 있는 정도를 나타내는 모델의 초기값으로 사용할 수 있다. 예를 들어, 대학생 사용자의 경우, 초등학생 수준의 문장 번역이 필요할 확률이 적을 것이다. 따라서, 전자 장치는 제2 사용자가 대학생인 경우, 초등학생 대상의 영어 교육에 이용되는 단어, 및/또는 문장에 대한 번역을 생략하기로 결정할 수 있다. 또한, 전자 장치는 제2 사용자의 직업에 대한 정보에 근거하여 직업별 전문 용어 어휘를 분류하고, 분류된 전문 용어 어휘를 저장하는 사용자 이해 모델의 초기값으로 사용할 수 있다. 예를 들어, 제2 사용자가 심장 전 문 의사인 경우, 제1 언어로 형성된 심장 관련 전문 용어는 이해하고 있는 것으로 판단하고, 이에 대한 번역을 생략할 수 있다. 또한, 전자 장치는 제2 사용자의 국가 또는 국적에 대한 정보에 근거하여, 해당 국가에서 빈번히 이용되는 어휘는 번역이 없이도 이해하고 있는 것으로 판단할 수 있다. 따라서, 이에 대한 번역을 생략하기로 결정할 수 있다. 예를 들어, 제2 사용자의 국적이 프랑스인 경우, 한국어로 발화된 ‘바게트’는 제2 사용자가 이해하고 있는 것으로 판단하고, 이에 대한 번역을 생략할 수 있다. 또한, 제1 정보에 포함되는, 번역이 수행되는 환경에 대한 정보(이하, ‘환경 정보’)는 번역이 수행될 때의 물 리적 및/또는 정신적 주변 상황을 나타내는 정보를 포함할 수 있다. 구체적으로, 환경 정보는 번역이 수행되는 일정, 제1 사용자 및/또는 제2 사용자가 위치한 장소, 제1 사용자와 제2 사용자 간의 대화 주제, 제1 사용자와 제2 사용자 간의 관계, 번역이 수행되는 환경에서의 잡음 상황 등에 대한 정보를 포함할 수 있다. 구체적으로, 전자 장치는 번역이 수행되는 일정의 중요도와 장소에 따라서 제1 음성 신호에 포함되는 적어 도 하나의 단어 중 적어도 하나의 번역을 생략할지 여부를 결정할 수 있다. 예를 들어, 번역이 수행되는 일정이 업무 미팅의 경우, 전자 장치는 상세한 부분까지 모두 구체적으로 정확히 번역되어야 할 필요가 있으므로, 번역의 생략을 최소화하여, 상세한 부분까지 모두 번역되도록 할 수 있다. 또 다른 예로, 전자 장치는 제1 사용자 및/또는 제2 사용자가 위치한 장소, 제1 사용자와 제2 사용자 간의"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "대화 주제, 제1 사용자와 제2 사용자 간의 관계 중 적어도 하나를 고려하여, 번역의 요약 또는 생략이 되는 정 도를 조정할 수 있다. 예를 들어, 전자 장치는 친구와 대화 시 수행되는 번역의 경우, 번역의 상세 정도를"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "낮게 설정하여, 번역의 요약 및 생략 정도를 높일 수 있다. 또한, 전자 장치는 번역이 수행되는 환경의 잡음 상황을 고려하여, 잡음이 큰 경우 제2 사용자가 제1 사용 자의 발화 내용을 정확하게 인식하지 못할 가능성이 더욱 커질 수 있다. 이 경우, 전자 장치는 번역의 상 세 정도를 높게 설정하거나, 번역 결과의 음량을 변화시키거나, 번역 결과에 대한 텍스트에서의 크기 및 색상의 하이라이트 표시 등을 할 수 있다. 또한, 전자 장치가 제2 사용자가 자주 이용하는 전자 장치인 경우, 예를 들어, 전자 장치가 제2 사용 자가 소유하는 휴대 전화인 경우, 제1 정보는 전자 장치에 저장된 정보를 포함할 수 있다. 여기서, 전자 장치에 저장된 정보는 제2 사용자가 입력한 메모, 제2 사용자가 송신한 문서, 전자 장치에 저장된 영화 및/또는 노래의 제목, 연락처에 저장된 이름 등이 될 수 있다. 예를 들어, 제2 사용자가 전자 장치를 통하여 메모를 입력하고 입력된 메모가 전자 장치의 개인 파 일에 저장된 경우, 상기 입력된 메모에 포함되는 제1 언어로 형성된 단어 또는 문장은 제2 사용자가 이해하고 있는 것으로 판단할 수 있다. 따라서, 전자 장치는 저장하고 있는 메모에 근거하여, 메모에 포함되는 소정 단어 또는 문장에 대한 번역을 생략할 수 있다. 도 5를 참조하면, 제2 사용자의 제1 언어에 대한 이해도를 나타내는 정보인 제1 정보는 언어 이해도 이력 (history)을 포함할 수 있다. 여기서, 언어 이해도 이력은 제2 사용자가 제1 언어에 대한 이해도를 알 수 있는 이력(history)을 나타내 는 정보이다. 언어 이해도 이력은 제2 사용자가 번역 결과를 제공받을 때, 제1 사용자와 제2 사용자 간의 대화가 이뤄질 때, 또는 제2 사용자가 제1 언어를 사용(청취(listening), 적기(writing) 또는 발화(speaking) 등)할 때에 계속하여 업데이트될 수 있다. 프로세서는 제2 사용자와 관련된 번역 이력을 학습하여, 제1 정보를 업데이트할 수 있다. 구체적으로, 프 로세서는 제2 사용자가 번역 결과를 제공받을 때, 제1 사용자와 제2 사용자 간의 대화가 이뤄질 때, 또는 제2 사용자가 제1 언어를 사용(청취(listening), 적기(writing) 또는 발화(speaking) 등)할 때에 발생하는 이 력을 학습하여, 언어 이해도 이력을 포함하는 제1 정보를 계속하여 업데이트할 수 있다. 또한, 언어 이해도 이력는 소정 기간 동안에 발생한 이력들을 포함할 수 있다. 예를 들어, 언어 이해도 이 력는 현재 시점을 기준으로 최근 3개월 동안의 제2 사용자의 제1 언어 사용 이력을 포함할 수 있다. 예를 들어, 언어 이해도 이력는 제2 사용자가 제1 언어로 발화하는 상대방(예를 들어, 제1 사용자)과의 대 화 이력, 제2 사용자가 사용한 제1 언어에 대한 이력 등을 포함할 수 있다. 예를 들어, 제1 언어가 영어인 경우, 제2 사용자가 ‘How can I go to city hall?’ 이라는 문장을 최근 일주일 동안 3회 이상 청취하고 그에 대한 번역 결과를 제공받았다면, 이러한 이력은 사용 빈도에 따른 학습을 통해 언 어 이해도 이력으로 저장될 수 있다. 전자 장치는 언어 이해도 이력을 참조하여, 제2 사용자가 ‘How can I go to city hall?’ 이라는 문장을 이해하고 있는 것으로 판단하고, ‘How can I go to city hall?’ 이라는 문장에 대한 번역을 생략할 수 있을 것이다. 또한, 제1 정보는 제1 음성 신호의 수신에 대응하여 제2 사용자가 대화 상대방인 제1 사용자의 발화 내용을 듣 고 그에 대응하여 입력한 정보를 포함할 수 있다. 이하에서는 제1 음성 신호의 수신에 대응하여 제2 사용 자가 입력한 정보를 ‘제2 사용자 입력 정보’라 칭하겠다. 전자 장치는 제2 사용자 입력 정보가 수 신되면, 제2 사용자가 제1 음성 신호를 이해한 것으로 판단하고, 번역을 수행하지 않거나, 제1 음성 신호에 포 함되는 적어도 하나의 단어, 적어도 하나의 구문, 또는 적어도 하나의 문장에 대한 번역을 생략할 수 있다. 구체적으로, 제2 사용자 입력 정보는, 음성, 터치 패턴, 제스쳐, 및 메모 형태로 수신될 수 있다. 구체적 으로, 제1 음성 신호가 수신될 때, 제2 사용자는 제1 음성 신호에 포함되는 적어도 하나의 단어의 의미를 이해 하였음을 나타내는 음성, 터치 패턴, 제스쳐, 및 메모 중 적어도 하나를 전자 장치로 입력할 수 있다. 예를 들어, 제2 사용자가 사용자 입력부에 포함되는 터치 스크린(미도시)을 연속하여 소정 횟수만큼 터치 하는 경우, 또는 터치 스크린(미도시)을 소정 패턴으로 드래그 하는 경우, 전자 장치는 해당 터치 패턴을 사용자 입력 정보로 수신할 수 있다. 또 다른 예로, 제1 음성 신호가 수신될 때, 즉, 제1 사용자가 발화할 때, 제2 사용자가 ‘오케이’, ‘응’ 등 으로 발화할 경우, 전자 장치는 사용자 입력부를 통하여 제2 사용자가 발화한 ‘오케이’, ‘응’ 등 을 수신하고, 그에 대응되는 적어도 하나의 단어를 제2 사용자가 이해하고 있어서 번역이 불필요한 것으로 판단 하고, 그에 대한 번역을 생략할 수 있다. 또는, 제2 사용자가 고개를 끄덕이는 제스쳐를 하는 경우, 전자 장치는 해당 제스쳐를 사용자 입력 정보로 인식할 수 있다. 여기서, 제2 사용자 입력 정보에 포함되는 음성, 터치 패턴, 제스쳐, 및 메모의 형태는 전자 장치의 사용자가 사용자 입력부를 통하여 설정할 수 있다. 여기서, 사용자는 제2 사용자를 포함하여, 전자 장치 의 소유자 등과 같은 전자 장치를 이용하는 사람이 포함될 수 있을 것이다. 또는, 제2 사용자 입력 정보는 전자 장치의 프로세서에서 자체적으로 설정될 수 있다. 구체적으 로, 전자 장치는 자동 음성 번역 서비스를 시작할 때, 설정된 제2 사용자 입력 정보의 형태를 제2 사 용자에게 알려줄 수 있다. 예를 들면, 전자 장치는 제1 사용자와 제2 사용자 간의 대화가 시작되어 자동 음성 번역 서비스를 개시할 때, '이해하는 단어(또는 문장)는 '네'로 답해주세요'와 같은 음성으로 출력되는 안 내 메시지를 출력할 수 있을 것이다. 또한, 안내 메시지는 음성 이외에도 사용자 인터페이스 화면 등을 통하여"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "출력될 수 있을 것이다. 또한, 제1 음성 신호가 수신되는 동안, 사용자 입력 정보가 수신되지 않으면, 전자 장치는 번역의 요약 또 는 생략 없이, 수신되는 제1 음성 신호 전체를 번역하여 출력할 수 있다. 또한, 제2 사용자는 제2 사용자 입력 정보를 단어 단위, 구문 단위, 또는 문장 단위로 입력할 수 있다. 또 한, 제2 사용자는 문장의 끊어 읽기 단위로 사용자 입력 정보를 입력할 수 있다. 사용자 입력 정보에 따른 번역"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "의 요약 또는 번역의 생략 동작은 이하에서 도 8을 참조하여 상세히 설명한다. 다시 도 5를 참조하면, 블록은 제1 음성 신호에 포함되는 적어도 하나의 단어에 대한 사용자의 이해 여부 를 판단하는 동작을 설명하기 위한 것이다. 그리고, 블록은 사용자의 이해 여부 판단 결과에 근거하여 제1 음성 신호에 포함되는 적어도 하나의 단어에 대한 번역을 생략할지 여부를 판단하는 동작을 설명하기 위한 것이다. 도 5의 사용자 프로파일링은 도 6에서 설명한 사용자 프로파일링에 동일 대응되므로, 중복되는 설명은 생략한다. 예를 들어, 전자 장치는 제2 사용자 입력 정보, 언어 이해도 이력, 제2 사용자의 언어 능력 및 사용자 프로파일링 중 적어도 하나를 포함하는 제1 정보에 근거하여, 제2 사용자가 제1 음성 신 호를 제2 언어로 이해하고 있는지 여부를 판단할 수 있다(521 블록 동작). 구체적으로, 전자 장치의 프로 세서는 제2 사용자가 제1 음성 신호를 제2 언어로 이해하고 있는지 여부를 판단할 수 있다. 그리고, 전자 장치는 제1 정보에 근거하여, 제1 음성 신호에 포함되는 적어도 하나의 단어 중 몇 개의 단 어를 생략할 것인지 결정할 수 있다(555 블록 동작). 여기서, 번역의 생략은 단어 단위, 적어도 하나의 단어를 포함하는 구문 단위, 또는 적어도 하나의 단어를 포함하는 문장 단위로 수행될 수 있다. 소정 단위, 예를 들어, 문장 또는 구문 등을 형성하는 제1 음성 신호 전체에 대한 번역을 생략하는 경우는 ‘번 역의 생략’이라 칭하고, 제1 음성 신호에 포함되는 적어도 하나의 단어에 대한 번역을 생략하여, 제1 음"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "성 신호에 대한 번역을 요약하여 제공하는 경우는 ‘번역의 요약’이라 칭할 수 있다. 또한, 번역의 생략"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "및 요약은 제1 음성 신호에 포함되는 단어, 문장 등에 대한 생략의 정도에 따라서 복수개의 레벨로 이뤄질 수"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "있다. 예를 들어, 생략의 정도를 높이면 번역의 요약 레벨은 높아질 것이며, 생략의 정도를 줄이면 번역의 요약 레벨은 낮아질 것이다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "전자 장치는 번역의 생략 또는 요약여부를 결정하고, 그 결과에 따라서 제1 음성 신호에 대한 번역을 수행 할 수 있다. 전자 장치는 제2 사용자와 관련된 정보인 제1 정보에 근거하여, 상기 제1 음성 신호의 번역에 적용되는 번 역 레벨을 결정하고, 결정된 번역 레벨에 따라서 제1 음성 신호를 상기 제2 언어로 번역할 수 있다. 그리고, 프 로세서는 전술한 결정에 근거하여 제1 음성 신호를 제2 언어로 번역한다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "구체적으로, 전자 장치는 제1 정보에 근거하여, 제1 음성 신호를 번역하는데 있어서 요약 또는 생략의 정 도를 나타내는 번역 레벨을 결정할 수 있다. 그리고, 결정된 번역 레벨에 따라서 제1 음성 신호를 제2 언어로 번역할 수 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 22, "content": "또한, 전자 장치는 제1 정보에 근거하여, 제1 음성 신호를 번역하는데 있어서 요약 또는 생략의 정도에 따 라서 구별되는 복수개의 번역 레벨을 설정할 수 있다. 즉, 전자 장치는 제1 정보에 근거하여, 제1 음성 신 호에 포함되는 적어도 하나의 단어 중 몇 개의 단어를 생략할 것인지에 따라서 복수개의 번역 레벨을 설정할 수 있다. 그리고, 전자 장치는 제1 정보에 근거하여 복수개의 번역 레벨 중 소정 번역 레벨, 예를 들어, 제1 번역 레벨을 선택하면, 선택된 번역 레벨에 따라서 제1 음성 신호에 대한 번역을 수행할 수 있다. 또한, 전자 장치는 인공 신경망을 통한 연산을 수행하여 상기 복수개의 번역 레벨을 설정할 수 있다. 또한, 전자 장치는 인공 신경망을 통한 연산을 수행하여, 설정된 복수개의 번역 레벨 중 제1 번역 레벨을 선택할 수 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 23, "content": "번역 레벨은 번역의 요약 정도에 따라서 복수개의 단계로 분류될 수 있다. 예를 들어, 번역 레벨이 0 이면 번역 을 하지 않는 것을 나타내며, 제1 음성 신호에 대한 번역 자체를 생략하는 것을 나타낸다. 그리고, 번역 레벨이"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 24, "content": "1 내지 N이면 제1 음성 신호의 일부분에 대하여 번역을 생략함으로써 요약된 번역을 제공하는 레벨을 나타낸다. 제1 음성 신호의 상세한 부분(details)까지 번역을 수행할수록 번역 레벨이 N에 가까워지고, 생략되는 부분이 증가할수록 번역 레벨이 1에 가까워질 수 있다. 예를 들어, 전자 장치는 제1 정보에 근거하여, 제2 사용자가 제1 음성 신호 전체의 의미를 이해한 것으로 판단하면, 번역을 수행하지 않는다. 즉, 번역 레벨을 레벨 0으로 판단하여, 제1 음성 신호 전체의 번역을 스킵(skip)할 수 있다. 전자 장치는 제1 정보에 근거하여, 제1 음성 신호에 포함되는 적어도 하나의 단어 중 이해가 되는 어휘가 존재하는 경우, 해당 어휘만 생략하고 번역을 수행할 수 있다. 또는, 제1 음성 신호에 제2 사용자가 이해하는 문형이 존재하는 경우, 해당 문형만 생략하고 번역을 수행할 수 있다. 복수개의 번역 레벨에 대한 상세한 설명은, 이하에서 도 10b 및 도 11을 참조하여 설명한다. 또 다른 예로, 전자 장치는 제1 음성 신호가 언어 이해도 이력에 근거하여 제2 사용자가 처음 접하는"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 25, "content": "언어인 것으로 판단한 경우, 번역의 생략 또는 요약을 최소화하여 상세한 부분까지 번역되도록 할 수 있다. 또한, 전자 장치는 제1 사용자가 입력하는 음성 신호의 발화 특성에 근거하여, 입력된 음성 신호에 포함되는 적어도 하나의 단어 중 적어도 하나를 생략할지 여부를 결정할 수 있다. 여기서, 도 5에 도시된 음성 신호은 번역의 대상이 되는 제1 음성 신호를 나타낸다. 구체적으로, 전자 장치의 프로세서는 제1 사용자의 발화 특성에 근거하여 제1 음성 신호에 포함되는 적어도 하나의 단어 중 적어도 하나를 생략할지 여부를 결정하고, 이러한 결정에 근거하여 제1 음성 신호를 제2 언어로 번역할 수 있다. 여기서, 제1 사용자의 발화 특성은, 제1 사용자가 제1 음성 신호를 발화함에 있어서 발화 속도, 발화 길이, 발 음, 억양 및 출신 국가 및 적어도 하나와 관련되는 정보를 포함할 수 있다. 전자 장치는 발화 속도, 발화 길이, 발음, 억양 및 출신 국가 및 적어도 하나에 따라서, 제2 사용자의 제1 음성 신호에 대한 이해 정도를 다르게 판단할 수 있다. 예를 들어, 네이티브 스피커가 아닌 제1 사용자가 특이 한 억양으로 발화할 경우, 전자 장치는 제2 사용자가 제1 사용자가 발화한 제1 음성 신호를 이해하지 못하 는 것으로 판단한다. 그에 따라서, 전자 장치는 번역의 생략 없이 제1 음성 신호 전체에 대한 번역을 수행 할 수 있을 것이다. 또한, 제1 사용자와 제2 사용자 간의 대화에 있어서, 대화의 속도가 느리거나, 발화 문장의 길이가 길어짐에 따 라서, 번역의 생략 정도를 증가시킬 수 있을 것이다. 또한, 전자 장치의 프로세서는 제1 사용자가 발화한 제1 음성 신호의 음성 정보 처리(553 블록 동 작)를 통하여, 발화 속도, 길이, 발음 및 언어 중 적어도 하나를 파악할 수 있다. 구체적으로, 프로세서는 제1 사용자가 발화한 제1 음성 신호를 학습하여, 제1 음성 신호의 특성에 따라서 제2 사용자의 이해 정도를 판 단할 수 있을 것이다. 예를 들어, 프로세서는 제1 사용자가 발화한 제1 음성 신호를 딥 러닝(Deep learning)하여, 제1 사용자가"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 26, "content": "발화한 제1 음성 신호의 특성에 따라서 허용되는 요약의 정도를 분류하고, 분류된 요약의 정도에 맞춰서 제1 음"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 27, "content": "성 신호를 요약 번역할 수 있을 것이다. 구체적으로, 프로세서는 제1 사용자가 발화한 제1 음성 신호를 수 신하고, 수신된 제1 음성 신호의 특성을 학습할 수 있다. 즉, 입력된 제1 음성 신호의 특성을 학습하여 제1 음"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 28, "content": "성 신호에 대한 번역을 어느 정도로 요약하여야 하는지에 대한 기준을 학습할 수 있다. 그리고, 학습된 기준에"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 29, "content": "맞춰서 제1 음성 신호에 대한 요약 번역을 수행할 수 있다. 또한, 전자 장치는 제1 정보에 근거하여, 번역 결과를 출력하는데 있어서, 주요 키워드 단어, 구문, 또는 문장을 주요 키워드가 아닌 단어, 구문 또는 문장과 구별되도록 출력할 수 있다. 예를 들어, 전자 장치의 출력부가 번역 결과를 디스플레이을 통하여 텍스트로 출력하는 경우, 주요 키워드 단어에 대하여는 문자 색상 또는 크기를 변경하거나 하이라이트 처리하여 출력할 수 있다. 또한, 전자 장치의 출력부 가 번역 결과를 스피커을 통하여 출력하는 경우, 주요 키워드 단어의 음량을 크게 하거나, 주요 키워드 단 어의 번역 결과를 소정 횟수만큼 반복하여 출력할 수 있다. 도 7은 본 개시의 실시예에 따른 번역 동작을 설명하기 위한 도면이다. 구체적으로, 도 7에서는 제1 사용자가 발화한 음성 신호를 번역하는 동작이 도시된다. 도 7을 참조하면, t1 시점에서 제1 사용자가 ‘how can I go to orthopedic surgery?’라고 발화하면, 전자 장 치는 제1 사용자가 발화한 ‘how can I go to orthopedic surgery?’ 에 대응되는 제1 음성 신호를 수신 하고, 수신된 제1 음성 신호를 음성 인식한다. 그리고, 전자 장치는 제2 사용자와 관련된 정보인 제1 정보 에 근거하여, 음성 인식된 제1 음성 신호에 포함되는 적어도 하나의 단어 중 적어도 하나를 생략할지 여부를 결 정한다. 구체적으로, 전자 장치는 제1 정보에 근거하여, 제2 사용자가 제1 음성 신호에 포함되는 적어도하나의 단어를 이해하고 있는지 여부를 판단한다. 구체적으로, 제1 정보는 도 5 및 도 6에서 설명한 언어 이해 도 이력을 나타내는 정보를 포함할 수 있으며, 도 7에서는 제1 정보가 표에 포함되는 정보를 포함하 는 경우를 예로 들어 설명한다. 도 7을 참조하면, 표는 상대방이 발화한 이력들로 제2 사용자가 번역 결과를 제공받은 음성 신호들에 대한 이력들을 나타낸다. 표을 참조하면, 도 6에서 설명한 사용자 프로파일링을 통하여, 사용자가 이미 이 해하고 있는 것으로 판단된 문장으로 ‘How can I go to city hall?’ 이 존재한다. 그리고, 이전에 제2 사용자 가 상대방이 발화하여 번역 결과를 제공받았거나, 제2 사용자가 이해하였음을 나타내는 제2 사용자 입력 정보 , 예를 들어, 제2 사용자가 제1 음성 신호를 듣고 이해하였음을 나타내며 입력한 음성 신호가 수신된 문장으로 ‘How can I go to the school?’ 이 존재한다. 그러면, 전자 장치는 제1 정보에 근거하여, 제2 사용자가 ‘How can I go to ~?’ 부분을 이해하고 있는 것으로 판단하고, ‘How can I go to ~?’ 부분에 대한 번역을 생략할 것으로 결정할 수 있다. 구체 적으로, 전자 장치는 표에 도시된 바와 같은 사용자 프로파일링에 대한 정보 및 음성 신호(72 1)를 포함하는 제2 사용자 입력 정보 등을 포함하는 제1 정보를 기반으로 학습된 결과에 근거하여, 제2 사 용자가 ‘How can I go to ~?’ 부분을 이해하고 있는 것으로 추정할 수 있다. 그에 따라서, 전자 장치는 제2 사용자가 이해하고 있지 못한 것으로 판단하는 ‘orthopedic surgery’ 부 분만을 번역한 결과인 ‘정형외과’을 출력할 수 있다. 전술한 바와 같이, 전자 장치는 제2 사용자에게 이해하고 있는 부분에 대한 번역을 생략함으로써, 보다 빠 르고 간결하게 번역 결과를 출력할 수 있다. 그에 따라서, 전자 장치는 자동 음성 번역을 수행하는데 있어 서 발생할 수 있는 지연을 최소화하여 빠르게 번역 결과를 제2 사용자에게 제공할 수 있다. 또한, 제2 사용자는 자신이 이해하지 못하는 부분에 대하여만 번역 결과를 제공받을 수 있다. 그에 따라서, 제2 사용자는 이미 이해 하고 있는 번역 결과를 읽거나 듣느라 소비하는 시간 및 노력을 줄일 수 있다. 도 8은 본 개시의 실시예에 따른 번역 동작을 설명하기 위한 다른 도면이다. 구체적으로, 도 8에서는 제1 정보 가 사용자 입력 정보를 포함하는 경우, 제1 정보에 근거한 번역 동작을 설명하는 도면이다. 또한, 도 8에서는, 사용자 입력 정보가 터치 스크린(미도시)를 1회 터치하는 터치 이벤트인 경우를 예로 들어 설명한다. 도 8을 참조하면, 제1 사용자가 t1 에서 t2 시점 동안에 ‘Excuse me’를 발화하고, 후속하여 t3 에서 t4 시점 동안에 ‘How can I go to hospital?’을 발화하였다. 그에 따라서, 전자 장치는 ‘Excuse me ’에 대응되는 음성 신호 및 ‘How can I go to hospital?’에 대응되는 음성 신호를 포함하는 제1 음성 신호를 수신한다. 제2 사용자는 제1 사용자가 발화한 ‘Excuse me’를 듣고, 이에 대한 의미를 알고 있다는 표현으로 터치 이벤트을 전자 장치로 입력할 수 있다. 여기서, 터치 이벤트는 제1 정보 에 포함되는 정보로, 도 5에서 설명한 제2 사용자 입력 정보에 동일 대응된다. 전자 장치는 입력된 터치 이벤트에 근거하여, ‘Excuse me’에 대한 번역을 생략하고, ‘How can I go to hospital?’ 부분만을 번역할 수 있다. 또한, 전자 장치는 터치 이벤트가 입력된 후, 발화 이력을 언어 이해도 이력에 업데이트할 수 있다. 그러면, 전자 장치는 후속되는 시점 에서 ‘Excuse me’ 에 대응되는 음성 신호가 수신되는 경우, 제2 사용자가 ‘Excuse me’를 이해하고 있는 것으로 판단하고, 이에 대한 번역을 생략할 수 있다. 도 9a 내지 도 9c는 본 개시의 실시예에 따른 번역 동작을 설명하기 위한 다른 도면이다. 구체적으로, 도 9a 내"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 30, "content": "지 도 9c는 제1 정보에 근거한 번역의 생략 또는 요약 동작이 도시된다. 도 9a 내지 도 9c에 있어서, t1 시점은 t0 에 후속하는 시점이며, t2 시점은 t1 시간에 후속하는 시점이다. 도 9a 를 참조하면, 제1 사용자가 ‘Thanks’를 발화하면, 전자 장치는 ‘Thanks’에 대응되는 음성 신호를 수신한다. 전자 장치는 제1 정보에 포함되는 언어 이해도 이력에 근거하여 ‘Thanks’에 대한 번역을 생략할지 여부를 판단한다. 예시에서, 언어 이해도 이력은 t0 시간 이전의 발화 이력을 포함한다. 발화 이력에는 ‘Thanks’에 대한 번역을 수행했던 이력이 없으며, 제2 사용자가 'Thanks’의 국어 상의 의미를 이해하고 있음을 나타내고 있는 이력이 없으므로, 전자 장치는 제2 사용자가 ‘Thanks’ 를 이해하고 있지 못하는 것으로 판단하고, 번역 결과인 ‘감사합니다’를 출력한다. 도 9b 를 참조하면, 전자 장치는 도 9a 에서 수행된 번역 이력을 반영하여 언어 이해도 이력에 포함 되는 발화 이력을 업데이트한다. 계속하여 도 9b를 참조하면, t1 시점에서 제1 사용자가 ‘Thanks’ 를 발화하면, 전자 장치는 ‘Thanks’ 에 대응되는 음성 신호를 수신한다. 제2 사용자가 ‘Thanks’에 대응되는 음성 신호를 듣고, 대응되는 대답으로 ‘You’re welcome’’을 발화할 수 있다. 이 경우, 전자 장치는 ‘Thanks’에 대응되는 음성 신호의 수신에 대응하여 제2 사용자가 입력한 정보인 ‘You’re welcome’’ 에 근거하여, ‘Thanks’에 대한 번 역의 생략을 결정할 수 있다. 그에 따라서, 전자 장치는 번역 결과를 출력하지 않을 수 있다. 전자 장치 는 수신되는 음성 신호에 대응되는 번역을 생략하는 경우, 이를 알리는 메시지를 출력할 수 있다. 예를 들 어, 전자 장치는 ‘Pass’, ‘skip’ 또는 소정 알람음에 대응되는 오디오 신호를 출력하거나 ‘번역 생략 ’을 포함한 메시지 화면을 출력할 수 있을 것이다. 또한, 전자 장치는 도 9b 에서 수행된 번역 이력을 반 영하여 언어 이해도 이력에 포함되는 발화 이력을 업데이트한다. 프로세서는 업데이트된 발화 이력을 학습하여, 제2 사용자가 ‘Thanks’에 대한 의미를 이해하고 있는 것으로 판단할 수 있다. 도 9c를 참조하면, t2 시점에서 제1 사용자가 ‘Thanks’를 발화하면, 전자 장치는 ‘Thanks’(95 0)에 대응되는 음성 신호를 수신한다. 전자 장치는 제1 정보에 포함되는 언어 이해도 이력에 근거하 여 ‘Thanks’에 대한 번역을 생략할지 여부를 판단한다. 예시에서, 언어 이해도 이력은 t2 시간 이전의 발화 이력을 포함한다. 발화 이력에는 ‘Thanks’에 제2 사용자가 이해하고 있음을 나타내는 이력이 있으므로, 전자 장치는 제2 사용자가 ‘Thanks’를 이해하고 있는 것으로 판단하고, 번역을 생략하기로 결 정할 수 있다. 도 10a는 본 개시의 실시예에 따른 번역 동작을 설명하기 위한 다른 도면이다. 도 10에 도시된 예를 참조하면, 전자 장치는 제1 사용자가 발화한 ‘Would you do me a favor?’ 및 ‘Could you bring me some souvenirs for me tomorrow?’에 대응되는 음성 신호를 수신한다. 전자 장치가 수신된 음성 신호에 포함되는 적어도 하나의 단어에 대하여 번역의 생략 없이 번역을 수행하 는 경우, ‘Would you do me a favor?’에 대응하는 번역 결과로 ‘부탁 좀 해도 될까?’을 출력 하고, ‘Could you bring me some souvenirs for me tomorrow?’에 대응하는 번역 결과로 ‘내일까지 날 위해서 네가 기념품을 좀 가져다 줄래?’을 출력한다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 31, "content": "도 10b는 본 개시의 실시예에 따른 번역의 요약 또는 생략을 설명하기 위한 일 도면이다. 도 10b를 참조하면, 도 10a 에서 설명한 음성 신호에 포함되는 적어도 하나의 단어를 생략하여 번역을 수행하는 예시가 도시된다. 도 10b을 참조하면, 전자 장치는 제1 정보에 근거하여, 음성 신호에 포함되는 적어도 하나의 단어를 생략 할지 여부를 결정하고, 그에 따라서 번역 결과를 출력할 수 있다. 구체적으로, 전자 장치가 제1 정보에 근거하여, 음성 신호에 포함되는 적어도 하나의 단어 중 몇 개를 생 략할지를 결정하고, 상기 결정에 근거하여 번역을 수행할 수 있다. 여기서는 ‘음성 신호에 포함되는 적어도 하나의 단어 중 몇 개를 생략할지를 결정’한다고 표현하였으나, 생략"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 32, "content": "되는 단어의 개수를 의미하기보다는, 제1 음성 신호에 포함되는 적어도 하나의 문장 들이 요약되어 번역되는 정"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 33, "content": "도를 나타내기 위한 것이다. 즉, 생략되는 단어의 개수가 증가하면 더욱 더 요약된 번역 결과가 출력될 것이고,"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 34, "content": "생략되는 단어의 개수가 감소하면 덜 요약된 번역 결과가 출력될 것이다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 35, "content": "도 10b에서는 음성 신호를 번역하는데 있어서 요약 또는 생략의 정도에 따라서 3개의 번역 레벨이 설정되는 경 우를 예로 들어 도시하였다. 예를 들어, 전자 장치는 3개의 번역 레벨은 입력된 음성 신호를 1011 및 1021 문장과 같이 번역하는 제1 번역 레벨, 입력된 음성 신호를 1050 문장과 같이 번역하는 제2 번역 레벨, 및 입력 된 음성 신호를 1060 문장과 같이 번역하는 제3 번역 레벨을 설정할 수 있다. 예를 들어, 전자 장치가 제 1 정보에 근거하여 음성 신호에 포함되는 적어도 하나의 단어에 대한 생략 없이 번역을 수행하기로 결정하면, ‘부탁 좀 해도 될까?’ 및 ‘내일까지 날 위해서 네가 기념품을 좀 가져다 줄래?’을 출력한다. 그리고, 전자 장치가 제1 정보에 근거하여, 음성 신호에 포함되는 ‘Would you do me a favor?’의 번역을 생략할 것을 결정하면, ‘Could you bring me some souvenirs for me tomorrow?’에 대응되는 번 역 결과인 ‘내일까지 날 위해서 네가 기념품을 좀 가져다 줄래?’ 만을 출력할 수 있다. 또한, 전자 장치가 제1 정보에 근거하여, 음성 신호에 포함되는 ‘Would you do me a favor?’의"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 36, "content": "번역을 생략하고, ‘Could you bring me some souvenirs for me tomorrow?’을 요약하여 번역하기로 결 정하면, 번역의 상세(detail) 정도를 낮춰서 ‘내일 기념품 좀 가져올래?’의 번역 결과를 출력할 수 있 다. 도 10b 을 참조하여 설명한 바와 같이, 전자 장치는 제1 정보에 근거하여 제2 사용자가 제1 언어로 형성된 제1 음성 신호의 제2 언어 상의 의미를 이해하는 정도를 판단하고, 그에 따라서 음성신호에 대한 번역의 생략"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 37, "content": "및/또는 번역의 요약을 수행할 수 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 38, "content": "도 11은 본 개시의 실시예에 따라 신경망을 통한 학습에 근거한 번역의 요약 또는 생략 동작을 설명하기 위한 다른 도면이다. 전자 장치는 복수개의 번역 레벨을 설정하고, 제1 정보에 근거하여 복수개의 번역 레벨 중 제1 번역 레벨 을 선택할 수 있다. 그리고, 선택된 제1 번역 레벨에 따라서 제1 음성 신호에 대한 번역을 수행할 수 있다. 구 체적으로, 전자 장치는 인공 신경망을 통한 연산을 통하여, 복수개의 사용자 별로 언어 이해도를 나타내는 정보에 근거하여, 언어 이해도에 대응되는 복수개의 번역 레벨을 설정할 수 있다. 그리고, 전자 장치는 특 정 사용자인 제2 사용자에 대한 번역 서비스 제공이 필요할 경우, 인공 신경망을 통한 연산을 수행하여, 제2 사 용자의 언어 이해도를 나타내는 제1 정보에 근거하여 복수개의 번역 레벨 중 소정 번역 레벨을 선택할 수 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 39, "content": "여기서, 복수개의 번역 레벨은 전술한 번역의 요약 또는 생략 정도에 따라서 구별될 수 있다. 예를 들어, 복수"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 40, "content": "개의 번역 레벨은 전체 번역 레벨(L-Max), 일부 요약 레벨(L-2) 및 최대 요약 레벨(L-1)을 포함할 수 있다. 그 리고, 전자 장치는 결정된 번역 레벨에 따라서 번역을 수행한다. 구체적으로, 전자 장치의 프로세서는 신경망을 통한 학습(learning)을 수행하고, 제1 정보 및 제1 음 성 신호를 입력 데이터로 한 학습 결과에 따라 출력 데이터인 번역 결과를 서로 다르게 출력할 수 있다. 구체적으로, 번역 레벨은 학습 데이터에 포함되어 번역 결과를 제공하기 위한 훈련(training)에 반영될 수"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 41, "content": "있다. 프로세서는 학습된 전술한 번역의 요약 또는 생략 정도에 따라서 번역의 결과를 구별되게 제공 할 수 있다. 예를 들어, 도 11을 참조하면, 프로세서는 학습 데이터에 번역 레벨을 포함하여 인공지능 신경망을 훈련 (training)한다. 도 11에서는 복수개의 계층 구조를 갖는 신경망을 개략적으로 도시하였다. 도 11을 참조하면, 인공 신경망은 입력층, 숨은층(Hidden layer) 및 출력층의 구조로 형성 될 수 있다. 또한, 인공 신경망을 통한 연산은 프로세서 내에서 수행될 수 있다. 또는, 프로세서와 별도의 인공 신경망을 통한 연산을 수행하기 위한 별도의 프로세서, 컨트롤러, 또는 칩을 통하여 수행될 수도 있을 것이다. 도 11에서 있어서, 입력층에서 입력된 데이터들은 제1 음성 신호들(1101, 1102, 1103) 및 번역 레벨을 나 타내는 정보가 될 수 있다. 즉, 신경망은 입력층, 숨은층(Hidden layer) 및 출력층의 구조로 형성될 수 있다. 여기서, 1101, 1102, 및 1103으로 표시된 음성 신호들 각각은 소정의 의미를 갖는 '의 미 단위'에 대응되며, 단어, 구, 절 또는 문장 단위로 형성될 수 있다. 여기서, 번역 레벨은 나타내는 정보는 학습에 의해서 분류된 번역 레벨을 나타내는 정보가 될 수 있으며, 또는 번역 레벨을 결정하는 근거가 되는 제1 정보가 될 수도 있을 것이다. 정보가 학습에 의해서 분류된 번역 레벨을 나타내는 정보 자체이면, 프로세서는 다음 계층인 숨은 층에서 입력된 정보인 제1 음성 신호들(1101, 1102, 1103) 및 정보를 학습하여 번역 결과를 생성할 수 있다. 그리고, 정보가 번역 레벨을 결정하는 근거가 되는 제1 정보이면, 프로세서는 제1 정보를 학습하여 수행되는 번역에 적용될 번 역 레벨을 결정할 수 있다. 그리고, 결정된 번역 레벨 및 제1 음성 신호들(1101, 1102, 1103)을 학습하여 번역 결과를 생성할 수 있다. 그리고, 도 11에 있어서, 숨은 층에서 수행된 학습 및 훈련을 통해 각 층(layer)과 노드(node) 사이의 가 중치가 학습이 된다. 예를 들어, 프로세서는 반복적인 학습을 통하여 입력 신호들인 제1 음성 신호들 (1101, 1102, 1103) 각각에 적용되는 가중치 W[1], W[...] 및 W[n]의 값을 획득할 수 있다. 그리고, 획득된 가 중치 W[1], W[...] 및 W[n]의 값을 입력 신호들인 제1 음성 신호들(1101, 1102, 1103) 각각에 적용하여, 훈련 된 신경망에서 번역 레벨에 따라 가변하는 문장 길이를 갖는 번역 결과를 생성할 수 있다. 따라서, 입력된 문장"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 42, "content": "이 동일하더라도, 번역 레벨에 따라 요약의 정도가 다르며 문장의 길이가 다른 번역 결과를 생성할 수 있다. 도 11을 참조하면, 출력층에서 출력되는 제1 음성 신호들(1101, 1102, 1103)에 대응되는 번역 결과들 중 일 부 의미 단위들(1141, 1142)은 번역 결과로 출력되고, 일부 의미 단위들(1143, 1144)는 생략되어 번역 결과로 출력되지 않는다. 예를 들어, 전자 장치는 언어 이해도 이력에 존재하지 않는 의미 단위에 대하여는 가중치 값 1을 부여하고, 언어 이해도 이력에서 사용 이력이 1회 존재할 때마다 -1의 가중치 값을 부여할 수 있을 것이다. 그 리고, 가중치 값에 근거하여, 번역 레벨에 따라서 의미 단위의 생략의 정도를 결정할 수 있다. 구체적으로, 전자 장치는 입력된 제1 음성 신호에 포함되는 단어, 구문, 또는 문장 단위로, 가중치를 부여 하고, 가중치 값에 근거하여 복수개의 번역 레벨 중 어느 하나를 적용하여 번역을 수행할 수 있다. 도 11을 참조하면, 전자 장치로 ‘Could you bring me some souvenirs for me tomorrow?’이 입력된다. 전자 장치는 구별된 의미 단위들인 제1 음성 신호들(1111, 1112, 1113) 각각에 대하여, 제2 사용자가 의미 를 이해하고 있는지 여부를 구별한다. 그리고, 언어 이해도 이력에 없는 적어도 하나의 의미단위로 가중치를 부 여하고, 가중치가 높은 부분에 대하여 우선적으로 번역을 수행하고, 가중치가 낮은 부분에 대한 번역을 생략할 수 있다. 예를 들어, 전자 장치는 언어 이해도 이력에 존재하지 않는 의미 단위에 대하여는 가중치 값 1을 부여하고, 언어 이해도 이력에서 사용 이력이 1회 존재할 때마다 -1의 가중치 값을 부여할 수 있을 것이다. 그 리고, 가중치 값에 근거하여, 번역 레벨에 따라서 단어 생략의 정도를 결정할 수 있다. 예를 들어, 전자 장치는 전체 번역 레벨(L-Max)에서는 1150 부분에서와 같이 ‘내일까지 날 위해서 네가 기념품을 좀 가져다 줄래?’를 출력할 수 있다. 전체 번역 레벨(L-Max)이기 때문에, 최대 길이의 번역 결 과를 제공하게 된다. 또한, 전자 장치는 번역 레벨(L-2)에서는 인공 신경망에서 의미 단위 별 가중치에 근거하여 해당 레벨에 적합한 번역 길이를 가지도록 할 수 있다. 따라서, 일부 의미 단위에 대한 번역을 생략하여 ‘내일 기념품 좀"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 43, "content": "가져다 줄래?’를 출력할 수 있다. 또한, 전자 장치는 최대 요약 레벨인 번역 레벨(L-1)에서는 더"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 44, "content": "요약된 번역 결과가 출력되도록, ‘기념품 좀?’을 출력할 수 있다. 또한, 전자 장치는 제1 정보에 근거하여 번역 레벨을 결정할 수도 있으나, 사용자의 입력에 따라서 번역 레벨을 결정할 수도 있을 것이다. 예를 들어, 사용자가 사용자 입력부를 통하여, 특정 번역 레벨에 따른"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 45, "content": "번역을 요청한 경우, 전자 장치는 그에 따라서 요청된 번역 레벨에 맞춰 번역의 요약 또는 생략 정도를 결 정할 수 있을 것이다. 전술한 바와 같이, 실시예에 따른 제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번역하 여 제2 사용자에게 제공하기 위한 전자 장치는 제2 사용자와 관련된 정보인 제1 정보에 근거하여 번역의 생략"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 46, "content": "정도 또는 번역의 요약 정도를 결정함으로써, 제2 사용자에게 제공하지 않아도 되는 부분에 대한 번역을 생략할 수 있다. 그에 따라서, 자동 음성 번역에 있어서 발생되는 지연 시간을 최소화하여 보다 빠르게 번역 결과를 출 력할 수 있다. 또한, 번역 결과를 제공받는 제2 사용자에게 최적화된 간결하고 명확하게 번역 결과를 출력할 수 있다. 도 12는 본 개시의 실시예에 따른 음성 신호 번역 방법을 나타내는 흐름도이다. 도 12에 도시된 음성 신호 번역 방법에 포함되는 각 단계에서 수행되는 동작은 도 1 내지 도 11을 참조하여 설명한 본 개시의 실시예에 따른 전자 장치(200 또는 400)에서의 동작 구성과 동일하다. 따라서, 본 개시의 실시예에 따른 음성 신호 번역 방법을 설명하는데 있어서, 도 1 내지 도 11에서와 중복되는 설명은 생략한다. 음성 신호 번역 방법은 제1 사용자가 발화한 제1 언어로 형성된 제1 음성 신호를 제2 언어로 번역하여 제 2 사용자에게 제공하기 위한 음성 신호 번역 방법이다. 음성 신호 번역 방법은 적어도 하나의 단어를 포함하는 제1 음성 신호를 수신한다(S1210). S1210의 동작 은 전자 장치의 수신부에서 수행될 수 있다. 음성 신호 번역 방법은 계속하여, 제2 사용자와 관련된 정보인 제1 정보에 근거하여 제1 음성 신호에 포 함되는 적어도 하나의 단어 중 적어도 하나의 번역을 생략할지 여부를 결정하고, 결정에 따라서 제1 음성 신호 를 제2 언어로 번역한다(S1220). S1220의 동작은 전자 장치의 프로세서에서 수행될 수 있다. 또한, 프로세서는 번역된 결과를 음성으로 출력하는 경우, 번역된 결과에 대한 음성 합성을 수행하고, 음성 합성 된 결과가 출력부를 통하여 출력되도록 제어할 수 있다. 음성 신호 번역 방법은 제2 언어로 번역된 결과를 출력한다(S1230). S1230의 동작은 전자 장치의 출 력부에서 수행될 수 있다. 도 13은 본 개시의 다른 실시예에 따른 음성 신호 번역 방법을 나타내는 흐름도이다. 도 13에 도시된 음성 신호 번역 방법에 포함되는 각 단계에서 수행되는 동작은 도 1 내지 도 11을 참조하여 설명한 본 개시의 실시 예에 따른 전자 장치(200 또는 400)에서의 동작 구성과 동일하다. 따라서, 본 개시의 실시예에 따른 음성 신호 번역 방법을 설명하는데 있어서, 도 1 내지 도 11에서와 중복되는 설명은 생략한다. 또한, 도 13의 S1310 단계는 도 2의 S1210와 동일 대응되고, 도 13의 S1320 및 S1325 단계는 도 2의 S1220와 동일 대응되며, 도 13 의 S1350 단계는 도 2의 S1240와 동일 대응된다. 따라서, 음성 신호 번역 방법을 설명하는데 있어서, 도 12에서와 중복되는 설명은 생략한다. 도 13을 참조하면, 음성 신호 번역 방법은 적어도 하나의 단어를 포함하는 제1 음성 신호를 수신한다 (S1310). S1310의 동작은 전자 장치의 수신부에서 수행될 수 있다. 음성 신호 번역 방법은 제2 사용자와 관련된 정보인 제1 정보를 획득한다(S1320). S1320의 동작은 전자 장치의 프로세서에서 수행될 수 있다. 그리고, 음성 신호 번역 방법은 제1 정보에 근거하여, 제1 음성 신호에 포함되는 적어도 하나의 단어 중 적어도 하나의 번역을 생략할지 여부를 결정하고, 결정에 따라서 제1 음성 신호를 제2 언어로 번역한다(S1325). S1325 의 동작은 전자 장치의 프로세서에서 수행될 수 있다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 47, "content": "구체적으로, 음성 신호 번역 방법은 제1 정보에 근거하여, 번역의 생략 또는 요약 정도를 결정할 수 있다. 구체적으로, 제1 정보에 근거하여, 제1 음성 신호에 대한 번역을 생략할지 여부를 결정할 수 있다 (S1330). S1330 단계의 판단 결과, 번역을 전체 생략하는 것이 아니면, 제1 음성 신호에 포함되는 적어도 하나의 단어 중"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 48, "content": "몇 개의 단어에 대한 번역을 생략할 지, 즉, 번역의 요약 정도,를 결정할 수 있다(S1340). S1330 단계 및 S1340 단계의 동작은 도 5에서 설명한 550 블록 동작에 대응하므로, 상세한 설명은 생략한다."}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 49, "content": "S1340 단계의 판단 결과, 요약의 정도 또는 요약의 정도에 대응되는 번역 레벨에 따라 요약 번역을 수행한다"}
{"patent_id": "10-2017-0135244", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 50, "content": "(S1341). 또한, S1340 단계의 판단 결과, 전체 생략 없이, 요약 없이 번역을 수행할 것으로 결정되면, 제1 음성 신호 전체에 대한 번역을 수행한다(S1345). S1341 단계 및 S1345 단계의 동작은 도 5에서 설명한 550 블록 동작 에 대응되며, 도 5, 도 6, 도 10 및 도 11을 참조하여 상세히 설명하였으므로, 상세한 설명은 생략한다. 음성 신호 번역 방법은 제2 언어로 번역된 결과를 출력한다(S1350). S1350의 동작은 전자 장치의 출 력부에서 수행될 수 있다. 상술한 실시예는, 일부 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령 어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있 는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판 독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기 술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전달 매체를 포함한다. 또한, 일부 실시예는 컴퓨터에 의해 실행 되는 컴퓨터 프로그램과 같은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 컴퓨터 프로그램 또는 컴퓨터 프로 그램 제품 (computer program product)으로도 구현될 수 있다. 본 개시에서 설명된 특정 실행들은 일 실시예 일 뿐이며, 어떠한 방법으로도 본 개시의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 및 상기 시스템들의 다 른 기능적인 측면들의 기재는 생략될 수 있다."}
{"patent_id": "10-2017-0135244", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시에서 이용되는 자동 음성 번역 기술을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치를 나타내는 블록도이다. 도 3a, 도 3b, 도 3c 및 도 3d는 전자 장치가 자동 음성 번역 서비스를 제공하는 동작을 설명하기 위한 도 면이다. 도 4는 본 개시의 다른 실시예에 따른 전자 장치를 나타내는 블록도이다. 도 5는 본 개시의 일 실시예에 따른 번역 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에서 이용되는 제1 정보를 설명하기 위한 도면이다. 도 7은 본 개시의 실시예에 따른 번역 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 실시예에 따른 번역 동작을 설명하기 위한 다른 도면이다. 도 9a 내지 도 9c는 본 개시의 실시예에 따른 번역 동작을 설명하기 위한 다른 도면이다. 도 10a는 본 개시의 실시예에 따른 번역 동작을 설명하기 위한 다른 도면이다."}
{"patent_id": "10-2017-0135244", "section": "도면", "subsection": "도면설명", "item": 2, "content": "도 10b는 본 개시의 실시예에 따른 번역의 요약 또는 생략을 설명하기 위한 일 도면이다."}
{"patent_id": "10-2017-0135244", "section": "도면", "subsection": "도면설명", "item": 3, "content": "도 11은 본 개시의 실시예에 따라 신경망을 통한 학습에 근거한 번역의 요약 또는 생략 동작을 설명하기 위한 다른 도면이다. 도 12는 본 개시의 실시예에 따른 음성 신호 번역 방법을 나타내는 흐름도이다. 도 13은 본 개시의 다른 실시예에 따른 음성 신호 번역 방법을 나타내는 흐름도이다."}
