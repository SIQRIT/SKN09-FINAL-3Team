{"patent_id": "10-2022-0186154", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0103723", "출원번호": "10-2022-0186154", "발명의 명칭": "모멘텀 모델을 이용하여 메타 모델을 학습시키는 방법 및 장치", "출원인": "한국과학기술원", "발명자": "신진우"}}
{"patent_id": "10-2022-0186154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "모멘텀 모델을 이용하여 메타 모델을 학습시키는 방법에 있어서,적응(adaptation)시키고자 하는 태스크에 대한 제1 데이터를 획득하는 단계;상기 모멘텀 모델을 이용하여, 상기 태스크에 적응하는 선생 모델을 생성하는 단계;상기 선생 모델의 지식을, 상기 메타 모델로부터 상기 태스크에 적응하도록 생성된 전수 모델에 전수(distillation)하는 단계; 및상기 전수 모델의 기울기를 역전파하여, 상기 메타 모델을 학습시키는 단계를 포함하는메타 모델을 학습시키는 방법."}
{"patent_id": "10-2022-0186154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 모멘텀 모델은 시계열 앙상블(temporal ensemble) 방법을 이용하여 상기 메타 모델로부터 업데이트되는 신경망인메타 모델을 학습시키는 방법."}
{"patent_id": "10-2022-0186154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 메타 모델을 이용하여, 상기 태스크에 적응하는 학생 모델을 생성하는 단계; 및상기 학생 모델을 드롭아웃하여, 상기 전수 모델을 생성하는 단계를 더 포함하는메타 모델을 학습시키는 방법."}
{"patent_id": "10-2022-0186154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 선생 모델의 지식을 전수 모델에 전수하는 단계는,상기 태스크에 대한 제2 데이터를 이용하여, 상기 선생 모델의 지식을 상기 전수 모델에 전수하는 단계를 포함하고,상기 제2 데이터는 상기 제1 데이터와 태스크는 동일하지만, 종류는 서로 다른 데이터인메타 모델을 학습시키는 방법."}
{"patent_id": "10-2022-0186154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "메타 모델 학습 프로그램이 저장된 메모리; 및상기 메모리를 제어하는 프로세서를 포함하고,상기 프로세서는, 상기 메타 모델 학습 프로그램을 실행하여,적응(adaptation)시키고자 하는 태스크에 대한 제1 데이터를 획득하고,모멘텀 모델을 이용하여, 상기 태스크에 적응하는 선생 모델을 생성하고,상기 선생 모델의 지식을, 메타 모델로부터 상기 태스크에 적응하도록 생성된 전수 모델에 전수(distillation)공개특허 10-2024-0103723-3-하고,상기 전수 모델의 기울기를 역전파하여, 상기 메타 모델을 학습시키는메타 모델 학습 장치."}
{"patent_id": "10-2022-0186154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 모멘텀 모델은 시계열 앙상블(temporal ensemble) 방법을 이용하여 상기 메타 모델로부터 업데이트되는 신경망인메타 모델 학습 장치."}
{"patent_id": "10-2022-0186154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5 항에 있어서,상기 프로세서는,상기 메타 모델을 이용하여, 상기 태스크에 적응하는 학생 모델을 생성하고,상기 학생 모델을 드롭아웃하여, 상기 전수 모델을 생성하는메타 모델 학습 장치."}
{"patent_id": "10-2022-0186154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5 항에 있어서,상기 프로세서는,상기 태스크에 대한 제2 데이터를 이용하여, 상기 선생 모델의 지식을 상기 전수 모델에 전수하고,상기 제2 데이터는 상기 제1 데이터와 태스크는 동일하지만, 종류는 서로 다른 데이터인메타 모델 학습 장치."}
{"patent_id": "10-2022-0186154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "컴퓨터 프로그램을 저장하고 있는 컴퓨터 판독 가능 기록매체로서,상기 컴퓨터 프로그램은,적응(adaptation)시키고자 하는 태스크에 대한 제1 데이터를 획득하는 단계;모멘텀 모델을 이용하여, 상기 태스크에 적응하는 선생 모델을 생성하는 단계;상기 선생 모델의 지식을, 메타 모델로부터 상기 태스크에 적응하도록 생성된 전수 모델에 전수(distillation)하는 단계; 및상기 전수 모델의 기울기를 역전파하여, 상기 메타 모델을 학습시키는 단계를 포함하는메타 모델을 학습시키는 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함하는컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2022-0186154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터 판독 가능한 기록매체에 저장되어 있는 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램은,적응(adaptation)시키고자 하는 태스크에 대한 제1 데이터를 획득하는 단계;모멘텀 모델을 이용하여, 상기 태스크에 적응하는 선생 모델을 생성하는 단계;공개특허 10-2024-0103723-4-상기 선생 모델의 지식을, 메타 모델로부터 상기 태스크에 적응하도록 생성된 전수 모델에 전수(distillation)하는 단계; 및상기 전수 모델의 기울기를 역전파하여, 상기 메타 모델을 학습시키는 단계를 포함하는메타 모델을 학습시키는 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함하는컴퓨터 프로그램."}
{"patent_id": "10-2022-0186154", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 메타 모델 학습 장치를 이용하여 메타 모델을 학습시키는 방법은, 적응(adaptatio n)시키고자 하는 태스크에 대한 제1 데이터를 획득하는 단계; 모멘텀 모델을 이용하여, 상기 태스크에 적응하는 선생 모델을 생성하는 단계; 상기 선생 모델의 지식을, 상기 메타 모델로부터 상기 태스크에 적응하도록 생성된 전수 모델에 전수(distillation)하는 단계; 및 상기 전수 모델의 기울기를 역전파하여, 상기 메타 모델을 학습시 키는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0186154", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 모멘텀 모델을 이용하여 메타 모델을 학습시키는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0186154", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "메타 학습(meta-learning)이란, 다양한 태스크(task)를 학습하여 배운 지식으로 새로운 태스크를 학습할 때 그 성능을 높이는 것을 의미한다. 예컨대, 물컵을 들어올리는 것과 공을 던지는 태스크를 학습하여, 공을 들어올리 는 새로운 태스크에 활용하는 것을 의미한다. 이를 위해, 메타 학습 모델(meta-learner)은 태스크에 적응 (adapt)하여 태스크 전문가가 될 수 있도록 학습이 된다. 다양한 인공지능 학습 분야에서 선생 모델(teacher model)(또는 타겟 모델(target model))의 지식을 활용하여 학생 모델(student model)을 학습하면 학생 모델이 높은 성능을 얻을 수 있는 것들이 밝혀졌으며(소위 선생-학 생 기법(teacher-student framework)), 메타 학습에서도 이런 선생-학생 기법이 최근 높은 성능을 보여주고 있 다. 다만, 메타 학습에 선생 모델을 활용하기 위해서는 태스크마다 선생 모델을 학습해야 하는데, 메타 학습에서 다 루는 태스크의 개수가 너무 방대하기 때문에 태스크마다 선생 모델을 학습하는 것은 매우 비효율적으로 실용적 이지 못하다는 문제가 있다."}
{"patent_id": "10-2022-0186154", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 모멘텀 모델을 이용하여 메타 모델을 학습시키는 방법을 제공하는 것이다. 다만, 본 발명이 해결하고자 하는 과제는 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 해 결하고자 하는 과제는 아래의 기재로부터 본 발명이 속하는 통상의 지식을 가진 자에게 명확하게 이해될 수 있 을 것이다."}
{"patent_id": "10-2022-0186154", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 메타 모델 학습 장치를 이용하여 메타 모델을 학습시키는 방법은, 적응 (adaptation)시키고자 하는 태스크에 대한 제1 데이터를 획득하는 단계; 모멘텀 모델을 이용하여, 상기 태스크 에 적응하는 선생 모델을 생성하는 단계; 상기 선생 모델의 지식을, 상기 메타 모델로부터 상기 태스크에 적응 하도록 생성된 전수 모델에 전수(distillation)하는 단계; 및 상기 전수 모델의 기울기를 역전파하여, 상기 메 타 모델을 학습시키는 단계를 포함할 수 있다. 상기 모멘텀 모델은 시계열 앙상블(temporal ensemble) 방법을 이용하여 상기 메타 모델로부터 업데이트되는 신 경망일 수 있다. 상기 방법은, 상기 메타 모델을 이용하여, 상기 태스크에 적응하는 학생 모델을 생성하는 단계; 및 상기 학생 모델을 드롭아웃하여, 상기 전수 모델을 생성하는 단계를 더 포함할 수 있다. 상기 선생 모델의 지식을 전수 모델에 전수하는 단계는, 상기 태스크에 대한 제2 데이터를 이용하여, 상기 선생 모델의 지식을 상기 전수 모델에 전수하는 단계를 포함하고, 상기 제2 데이터는 상기 제1 데이터와 태스크는 동 일하지만, 종류는 서로 다른 데이터일 수 있다. 본 발명의 다른 실시예에 따른 메타 모델 학습 장치는, 메타 모델 학습 프로그램이 저장된 메모리; 및 상기 메 모리를 제어하는 프로세서를 포함하고, 상기 프로세서는, 상기 메타 모델 학습 프로그램을 실행하여, 적응 (adaptation)시키고자 하는 태스크에 대한 제1 데이터를 획득하고, 모멘텀 모델을 이용하여, 상기 태스크에 적 응하는 선생 모델을 생성하고, 상기 선생 모델의 지식을, 메타 모델로부터 상기 태스크에 적응하도록 생성된 전 수 모델에 전수(distillation)하고, 상기 전수 모델의 기울기를 역전파하여, 상기 메타 모델을 학습시킬 수 있 다. 상기 프로세서는, 상기 메타 모델을 이용하여, 상기 태스크에 적응하는 학생 모델을 생성하고, 상기 학생 모델 을 드롭아웃하여, 상기 전수 모델을 생성할 수 있다. 상기 프로세서는, 상기 태스크에 대한 제2 데이터를 이용하여, 상기 선생 모델의 지식을 상기 전수 모델에 전수 하고, 상기 제2 데이터는 상기 제1 데이터와 태스크는 동일하지만, 종류는 서로 다른 데이터일 수 있다. 본 발명의 또 다른 실시예에 따른 컴퓨터 프로그램을 저장하고 있는 컴퓨터 판독 가능 기록매체로서, 상기 컴퓨 터 프로그램은, 적응(adaptation)시키고자 하는 태스크에 대한 제1 데이터를 획득하는 단계; 모멘텀 모델을 이 용하여, 상기 태스크에 적응하는 선생 모델을 생성하는 단계; 상기 선생 모델의 지식을, 메타 모델로부터 상기 태스크에 적응하도록 생성된 전수 모델에 전수(distillation)하는 단계; 및 상기 전수 모델의 기울기를 역전파 하여, 상기 메타 모델을 학습시키는 단계를 포함하는 메타 모델을 학습시키는 방법을 프로세서가 수행하도록 하 기 위한 명령어를 포함할 수 있다. 본 발명의 또 다른 실시예에 따른 컴퓨터 판독 가능한 기록매체에 저장되어 있는 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은, 적응(adaptation)시키고자 하는 태스크에 대한 제1 데이터를 획득하는 단계; 모멘텀 모델을 이용하여, 상기 태스크에 적응하는 선생 모델을 생성하는 단계; 상기 선생 모델의 지식을, 메타 모델로부터 상 기 태스크에 적응하도록 생성된 전수 모델에 전수(distillation)하는 단계; 및 상기 전수 모델의 기울기를 역전 파하여, 상기 메타 모델을 학습시키는 단계를 포함하는 메타 모델을 학습시키는 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함할 수 있다."}
{"patent_id": "10-2022-0186154", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 의하면, 선생 모델의 학습 과정을 별도로 거치지 않고, 메타 모델의 모멘텀 모델을 이용하 여 선생 모델을 생성하므로, 선생 모델의 학습에 필요한 시간적, 경제적 비용을 절감시킬 수 있다. 본 발명의 실시예에 의하면, 학생 모델을 드롭아웃한 변형모델에 지식을 전수함으로써, 학생 모델이 선생 모델 과 동일해지는 방향으로 학습되는 문제를 해결할 수 있다."}
{"patent_id": "10-2022-0186154", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하"}
{"patent_id": "10-2022-0186154", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 본 발명의 실시예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명의 실시예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도 1은 일 실시예에 따른 메타 모델 학습 장치를 나타내는 블록도이다. 도 1을 참조하면, 메타 모델 학습 장치는 프로세서, 입력기 및 메모리를 포함할 수 있다. 프로세서는 메타 모델 학습 장치의 동작을 전반적으로 제어할 수 있다. 프로세서는, 입력기를 이용하여, 적응(adapt)시키고자 하는 태스크(task)에 대한 데이터를 입력받을 수 있다. 본 명세서에서는, 메타 모델 학습 장치는 입력기를 이용하여 태스크에 대한 데이터를 입력받는 것으 로 설명하였지만, 이에 한정되지 않는다. 즉, 실시예에 따라, 메타 모델 학습 장치는 입력기 대신에, 또는 입력기에 더하여 송수신기(미도시)를 포함하고, 송수신기(미도시)를 이용하여 태스크에 대한 데이터 를 수신할 수도 있다. 또는, 실시예에 따라, 태스크에 대한 데이터는 메타 모델 학습 장치 내에서 생성될 수도 있다. 따라서, 본 명세서에서 입력기와 송수신기(미도시)는 획득부로 통칭될 수 있다. 메모리는 메타 모델 학습 프로그램 및 메타 모델 학습 프로그램의 실행에 필요한 정보를 저장할 수 있다. 본 명세서에서 메타 모델 학습 프로그램은 적응시키고자 하는 태스크에 대한 데이터를 입력받으면, 상기 태스크에 적응하도록 모멘텀 모델(momentum model)을 이용하여 메타 모델을 학습시키도록 프로그램된 명령어들 을 포함하는 소프트웨어를 의미할 수 있다. 프로세서는 메타 모델 학습 프로그램을 실행하기 위하여 메모리에서 메타 모델 학습 프로그램 및 메타 모델 학습 프로그램의 실행에 필요한 정보를 로드할 수 있다. 또한, 프로세서는, 메타 모델 학습 프로그램을 실행하여, 모멘텀 모델을 이용하여 메타 모델을 학습 시킬 수 있다. 메타 모델 학습 프로그램은 도 2에서 보다 자세하게 설명하기로 한다. 도 2는 일 실시예에 따른 메타 모델 학습 프로그램에 포함되는 신경망 모델을 나타내는 블록도이고, 도 3은 일 실시예에 따른 메타 모델 학습 프로그램을 이용하여 메타 모델을 학습시키는 과정을 나타내는 도면이다. 도 1, 도 2 및 도 3을 참조하면, 메타 모델 학습 프로그램은 메타 모델과 모멘텀 모델을 포함할 수 있다. 본 명세서에서 메타 모델은 메타 모델 학습 프로그램을 통해 소정의 태스크에 적응하도록(즉, 소정의 태스크를 잘 풀도록) 학습되는 신경망일 수 있다. 또한, 모멘텀 모델은 메타 모델과 구조가 동일하지만, 메타 모델보다 잘 학습된(즉, 적응 성능 이 더 뛰어난) 모델로서, 메타 모델을 학습시키는데 이용되는 선생 모델(teacher model)을 생성하는 데 이용될 수 있다. 실시예에 따라, 모멘텀 모델은 시계열 앙상블(temporal ensemble) 방법을 이용하여 메타 모델로부터 생성, 학습 또는 업데이트될 수 있다. 실시예에 따라, 모멘텀 모델은 아래의 수학식 1을 이용하여 생성, 학습 또는 업데이트될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0186154", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, θmoment는 모멘텀 모델을 나타내고, θ는 메타 모델을 나타내고, η은 모멘텀 모델이 과 거의 모멘텀 모델(즉, 업데이트 되기 전의 모멘텀 모델)을 얼마나 반영하는지를 결정하는데 이용되는 상수를 나 타낼 수 있다. 예컨대, η이 0.9인 경우, 모멘텀 모델은 현재의 메타 모델의 파라미터보다 과거의 모멘텀 모델의 파 라미터를 더 반영하여 생성될 수 있다. 또한, η이 1인 경우, 모멘텀 모델을 업데이트할 때, 현재의 메타 모델의 파라미터는 반영하지 않으며, η이 0인 경우, 현재의 메타 모델의 파라미터만을 반영하여 모 멘텀 모델을 업데이트할 수 있다. 적응시키고자 하는 태스크에 대한 제1 데이터(S)가 입력(또는 수신)된 경우, 메타 모델 학습 프로그램은, 모멘텀 모델로부터, 해당 태스크에 적응(즉, 해당 태스크를 잘 수행)하는 선생 모델을 생성할 수 있 다. 즉, 메타 모델 학습 프로그램은 선생 모델의 학습 과정을 별도로 거치지 않고, 메타 모델의 모멘텀 모델을 이용하여 선생 모델을 생성하므로, 선생 모델의 학습에 필요한 시간적, 경제적 비용을 절감시킬 수 있다. 또한, 메타 모델 학습 프로그램은, 메타 모델로부터, 입력된 태스크에 적응하는 학생 모델(student model)을 생성할 수 있다. 메타 모델 학습 프로그램은 학생 모델을 드롭아웃(dropout)하여 변형 모델을 생성할 수 있다. 여기서, 드롭 아웃은 학생 모델의 노드 중에서 적어도 일부를 제거하는 것을 의미할 수 있다. 즉, 학생 모델의 구조와 선생 모델의 구조가 동일할 때, 선생 모델의 지식(knowledge)을 학생 모델에 전수(distillation)할 경우, 학생 모델이 선생 모델과 동일해지는 문제가 발생할 수 있 다. 따라서, 메타 모델 학습 프로그램은 학생 모델을 드롭아웃함으로써, 학생 모델이 선생 모델 과 동일해지는 방향으로 학습되는 문제를 해결할 수 있다. 이후, 메타 모델 학습 프로그램은 선생 모델의 지식을 변형 모델에게 전수할 수 있다. 즉, 메타 모델 학습 프로그램은 선생 모델의 지식을 이용하여 변형 모델에게 태스크를 가르칠 수 있다. 선생 모델의 지식을 변형 모델에 전수할 때 사용하는 태스크에 대한 제2 데이터(Q)와 모멘텀 모델 로부터 선생 모델을 생성할 때 이용되는 태스크에 대한 제1 데이터(S)는 동일한 태스크에 대한 데이 터이지만, 종류는 서로 다를 수 있다. 예컨대, 적응시키고자 하는 태스크가 물컵을 들어올리는 태스크인 경우, 제1 데이터(S)는 사각형 컵을 들어올리는 태스크에 대한 데이터이지만, 제2 데이터(Q)는 원형 컵을 들어올리는 태스크에 대한 데이터일 수 있다. 메타 모델 학습 프로그램은 선생 모델의 지식이 전수된, 즉, 적응된 변형 모델의 기울기 (gradient)를 메타 모델에 역전파(backpropagation)함으로써, 메타 모델이 태스크에 적응하도록 메 타 모델을 학습시킬 수 있다. 도 4와 도 5는 일 실시예에 따른 메타 모델 학습 장치를 이용하여 메타 모델을 학습시키는 경우의 효과를 나타 낸다. 도 4를 참조하면, 기존의 메타 모델 학습 방법(MAML, ANIL, MetaSGD, ProtoNet)보다는, 기존의 메타 모델 학습 방법(MAML, ANIL, MetaSGD, ProtoNet)에 일 실시예에 따른 메타 모델 학습 방법(SiMT)을 적용할 때, 적응의 정 확도가 높아지는 것을 확인할 수 있다. 뿐만 아니라, 도 5를 참조하면, 퓨샷 학습(few-shot learning)의 경우에도, 샷의 양에 관계없이, 기존의 메타 모델 학습 방법(MAML, ANIL, MetaSGD, ProtoNet)보다, 기존의 메타 모델 학습 방법(MAML, ANIL, MetaSGD, ProtoNet)에 일 실시예에 따른 메타 모델 학습 방법(SiMT)을 적용할 때, 적응의 정확도가 높아지는 것을 확인할 수 있다. 도 6은 일 실시예에 따라 메타 모델 학습 장치가 메타 모델을 학습시키는 방법을 나타내는 흐름도이다. 도 1, 도 2, 도 3 및 도 6을 참조하면, 적응시키고자 하는 태스크에 대한 제1 데이터(S)가 입력(또는 수신)된 경우(S600), 메타 모델 학습 프로그램은, 모멘텀 모델로부터, 입력된 태스크에 적응하는 선생 모델 을 생성할 수 있다(S610). 또한, 메타 모델 학습 프로그램은, 메타 모델로부터, 입력된 태스크에 적응하는 학생 모델을 생 성할 수 있다(S620). 본 명세서에서는 설명의 편의를 위해, 메타 모델 학습 프로그램이 선생 모델을 생성한 이후에 학생 모델을 생성하는 것으로 기재하였지만, 이에 한정되지 않는다. 즉, 실시예에 따라, 메타 모델 학습 프로그 램은 학생 모델을 생성한 이후에 선생 모델을 생성할 수도 있고, 선생 모델의 생성과 학생 모델의 생성을 동시에 또는 병렬적으로 수행할 수도 있다.이후, 메타 모델 학습 프로그램은 학생 모델을 드롭아웃하여 변형 모델을 생성하고(S630), 선생 모델의 지식을 변형 모델에게 전수할 수 있다(S640). 메타 모델 학습 프로그램은 선생 모델의 지식이 전수된 변형 모델의 기울기를 메타 모델에 역전파함으로써, 메타 모델이 태스크에 적응하도록 메타 모델을 학습시킬 수 있다(S650). 본 발명의 실시예에 의하면, 선생 모델의 학습 과정을 별도로 거치지 않고, 메타 모델의 모멘텀 모델을 이용하 여 선생 모델을 생성하므로, 선생 모델의 학습에 필요한 시간적, 경제적 비용을 절감시킬 수 있다. 본 발명의 실시예에 의하면, 학생 모델을 드롭아웃한 변형모델에 지식을 전수함으로써, 학생 모델이 선생 모델 과 동일해지는 방향으로 학습되는 문제를 해결할 수 있다. 본 발명에 첨부된 블록도의 각 블록과 흐름도의 각 단계의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수행 될 수도 있다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 인코딩 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프 로세싱 장비의 인코딩 프로세서를 통해 수행되는 그 인스트럭션들이 블록도의 각 블록 또는 흐름도의 각 단계에 서 설명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방법으로 기능 을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리 에 저장된 인스트럭션들은 블록도의 각 블록 또는 흐름도 각 단계에서 설명된 기능을 수행하는 인스트럭션 수단 을 내포하는 제조 품목을 생산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로 세싱 장비 상에서 일련의 동작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프 로그램 가능한 데이터 프로세싱 장비를 수행하는 인스트럭션들은 블록도의 각 블록 및 흐름도의 각 단계에서 설 명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록 또는 각 단계는 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들 을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실시예들에서는 블록들 또 는 단계들에서 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시 되어 있는 두 개의 블록들 또는 단계들은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들 또는 단계들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 품질에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하 기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 균등한 범위 내에 있는 모든 기술사상은 본 발명의 권 리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0186154", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 메타 모델 학습 장치를 나타내는 블록도이다. 도 2는 일 실시예에 따른 메타 모델 학습 프로그램에 포함되는 신경망 모델을 나타내는 블록도이다. 도 3은 일 실시예에 따른 메타 모델 학습 프로그램을 이용하여 메타 모델을 학습시키는 과정을 나타내는 도면이 다. 도 4와 도 5는 일 실시예에 따른 메타 모델 학습 장치를 이용하여 메타 모델을 학습시키는 경우의 효과를 나타 낸다. 도 6은 일 실시예에 따라 메타 모델 학습 장치가 메타 모델을 학습시키는 방법을 나타내는 흐름도이다."}
