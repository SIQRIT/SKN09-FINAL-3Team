{"patent_id": "10-2021-0004590", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0102343", "출원번호": "10-2021-0004590", "발명의 명칭": "로봇 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "임지웅"}}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇에 있어서,통신 인터페이스;주행 공간에 포함된 제1 공간에 대응되는 제1 맵 데이터가 저장된 메모리;구동부; 및상기 통신 인터페이스를 통해 서버로부터 상기 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보가 수신되면,상기 제1 타겟 위치로 주행하도록 상기 구동부를 제어하고,상기 로봇이 상기 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 상기 제1 타겟 위치에 도달하였음을 나타내는 정보를 상기 서버로 전송하고,상기 서버로부터 상기 제1 타겟 위치를 포함하는 제2 공간에 대응되는 제2 맵 데이터 및 상기 제2 맵 데이터에포함된 제2 타겟 위치에 대한 정보가 수신되면, 상기 제2 타겟 위치로 주행하도록 상기 구동부를 제어하는 프로세서;를 포함하는, 로봇."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제2 공간은, 상기 제1 공간과 일부 공간이 오버랩되며,상기 제2 맵 데이터는,상기 제1 공간 중 상기 제1 타겟 위치를 포함하는 일부 공간에 대한 맵 정보를 포함하고,상기 제1 공간 중 상기 제1 타겟 위치를 포함하지 않는 일부 공간에 대한 맵 정보는 포함하지 않는, 로봇."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 서버로부터 상기 제2 맵 데이터가 수신되는 경우 또는 상기 로봇이 상기 제2 타겟 위치에 도달하는 경우중 적어도 하나의 경우에 상기 메모리에 저장된 상기 제1 맵 데이터를 삭제하는, 로봇."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,카메라;를 더 포함하며,상기 프로세서는,상기 로봇이 상기 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 상기 카메라를 통해 획득된 정보에 기초하여 상기 제1 타겟 위치의 환경 정보를 획득하고,상기 획득된 환경 정보에 기초하여 주행 환경이 변경된 것으로 식별되면, 상기 제1 타겟 위치의 환경 정보를 상기 서버로 전송하고,상기 서버로부터 상기 제1 타겟 위치의 환경 정보에 대응되는 인공 지능 모델에 대한 정보를 수신하여 상기 메모리에 저장하는, 로봇.공개특허 10-2022-0102343-3-청구항 5 제1항에 있어서,카메라;를 더 포함하며,상기 프로세서는,상기 로봇이 상기 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 상기 카메라를 통해 획득된 정보에 기초하여 상기 제1 타겟 위치의 환경 정보를 획득하고,상기 획득된 환경 정보에 기초하여 상기 로봇의 주행 상태를 변경하도록 상기 구동부를 제어하는, 로봇."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "서버에 있어서,통신 인터페이스;로봇의 주행 공간에 포함된 제1 공간에 대응되는 제1 맵 데이터 및 상기 제1 공간과 일부 공간이 오버랩되는 제2 공간에 대응되는 제2 맵 데이터가 저장된 메모리; 및상기 통신 인터페이스를 통해 상기 제1 맵 데이터 및 상기 제1 맵 데이터 상의 제1 타겟 위치에 대한 정보를 상기 로봇으로 전송하고,상기 로봇으로부터 상기 로봇이 상기 제1 타겟 위치에 도달하였음을 나타내는 정보가 수신되면, 상기 통신 인터페이스를 통해 상기 제2 맵 데이터를 상기 로봇으로 전송하는 프로세서;를 포함하며,상기 제2 맵 데이터는, 상기 제1 타겟 위치에 대한 맵 정보를 포함하는, 서버."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 메모리는, 상기 제1 공간과 일부 공간이 오버랩되는 제3 공간에 대응되는 제3 맵 데이터를 더 저장하며,상기 프로세서는,상기 로봇이 상기 제1 타겟 위치에 도달하였음을 나타내는 정보가 수신되면, 상기 제2 맵 데이터 및 상기 제3맵 데이터 중 상기 제1 타겟 위치 이후의 제2 타겟 위치에 대응되는 맵 정보를 포함하는 맵 데이터를 상기 로봇으로 전송하도록 상기 통신 인터페이스를 제어하는, 서버."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 프로세서는,상기 로봇의 주행 경로가 식별되면, 상기 로봇의 주행 경로에 기초하여 상기 제1 공간 및 상기 제2 공간이 오버랩되는 일부 공간에서 상기 제1 타겟 위치를 식별하는, 서버."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 프로세서는,상기 로봇의 주행 공간이 복수의 Z축 공간을 포함하는 경우, 상기 복수의 Z축 공간 중 각각을 상기 제1 공간 및상기 제2 공간으로 식별하고, 상기 제1 공간에서 상기 제2 공간으로 이동하기 위한 구조를 포함하는 일부 공간을 오버랩되는 공간으로 식별하는, 서버."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,공개특허 10-2022-0102343-4-상기 제1 공간에서 상기 제2 공간으로 이동하기 위한 구조는,엘리베이터, 에스컬레이터 또는 층계 중 적어도 하나를 포함하는, 서버."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제6항에 있어서,상기 프로세서는,상기 제1 맵 데이터의 크기가 임계 크기 이상인 경우, 상기 로봇의 현재 위치 및 상기 제1 타겟 위치 간 주행경로에 기초하여 상기 제1 맵 데이터 중 상기 주행 경로를 기준으로 식별된 일부 공간에 대응되는 일부 맵 데이터를 상기 로봇으로 전송하도록 상기 통신 인터페이스를 제어하는, 서버."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "로봇의 제어 방법에 있어서,서버로부터 상기 로봇의 주행 공간에 포함된 제1 공간에 대응되는 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보가 수신되면, 상기 제1 타겟 위치로 주행하는 단계;상기 로봇이 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 상기 제1 타겟 위치에 도달하였음을나타내는 정보를 상기 서버로 전송하는 단계; 및상기 서버로부터 상기 제1 타겟 위치를 포함하는 제2 공간에 대응되는 제2 맵 데이터 및 상기 제2 맵 데이터에포함된 제2 타겟 위치에 대한 정보가 수신되면, 상기 제2 타겟 위치로 주행하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 제2 공간은, 상기 제1 공간과 일부 공간이 오버랩되며,상기 제2 맵 데이터는,상기 제1 공간 중 상기 제1 타겟 위치를 포함하는 일부 공간에 대한 맵 정보를 포함하고,상기 제1 공간 중 제1 타겟 위치를 포함하지 않는 일부 공간에 대한 맵 정보는 포함하지 않는, 제어 방법."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 서버로부터 상기 제2 맵 데이터가 수신되는 경우 또는 상기 로봇이 상기 제2 타겟 위치에 도달하는 경우중 적어도 하나의 경우에 저장된 상기 제1 맵 데이터를 삭제하는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 로봇이 상기 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 카메라를 통해 획득된 정보에기초하여 상기 제1 타겟 위치의 환경 정보를 획득하는 단계; 상기 획득된 환경 정보에 기초하여 주행 환경이 변경된 것으로 식별되면, 상기 제1 타겟 위치의 환경 정보를 상기 서버로 전송하는 단계; 및 상기 서버로부터 상기 제1 타겟 위치의 환경 정보에 대응되는 인공 지능 모델에 대한 정보를 수신하여 저장하는단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 로봇이 상기 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 카메라를 통해 획득된 정보에공개특허 10-2022-0102343-5-기초하여 상기 제1 타겟 위치의 환경 정보를 획득하는 단계; 및 상기 획득된 환경 정보에 기초하여 상기 로봇의 주행 상태를 변경하는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 서버는, 상기 로봇이 제1 타겟 위치에 도달하였음을 나타내는 정보를 수신하고, 상기 제1 공간과 일부 공간이 오버랩되는 제3 공간에 대응되는 제3 타겟 위치에 대한 맵 정보를 포함하는 제3 맵 데이터 및 상기 제2 맵 데이터 중 상기 제1 타겟 위치 이후의 제2 타겟 위치에 대응되는 맵 정보를 포함하는 맵 데이터를 상기 로봇으로 전송하는,제어 방법."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 서버는, 상기 로봇의 주행 경로를 식별하고, 상기 로봇의 주행 경로에 기초하여 상기 제1 공간 및 제2 공간이 오버랩되는 일부 공간에서 상기 제1 타겟 위치를 식별하는, 제어 방법."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 서버는, 상기 로봇의 주행 공간이 복수의 Z축 공간을 포함하는 경우, 상기 복수의 Z축 공간 중 각각을 상기 제1 공간 및상기 제2 공간으로 식별하고, 상기 제1 공간에서 상기 제2 공간으로 이동하기 위한 구조를 포함하는 일부 영역을 오버랩되는 영역으로 식별하는, 제어 방법."}
{"patent_id": "10-2021-0004590", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항에 있어서,상기 서버는, 상기 제1 맵 데이터의 크기가 임계 크기 이상인 경우, 상기 로봇의 현재 위치 및 상기 제1 타겟 위치 간 주행경로에 기초하여 상기 제1 맵 데이터 중 상기 주행 경로를 기준으로 식별된 일부 공간에 대응되는 일부 맵 데이터를 상기 로봇으로 전송하는, 제어 방법."}
{"patent_id": "10-2021-0004590", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "로봇의 제어 방법이 개시된다. 제어 방법은 서버로부터 로봇의 주행 공간에 포함된 제1 공간에 대응되는 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보가 수신되면 제1 타겟 위치로 주행하는 단계, 로봇이 제1 타겟 위치 로부터 임계 거리 내에 도달한 것으로 식별되면 제1 타겟 위치에 도달하였음을 나타내는 정보를 서버로 전송하는 단계 및 서버로부터 제1 타겟 위치를 포함하는 제2 공간에 대응되는 제2 맵 데이터 및 제2 맵 데이터에 포함된 제2 타겟 위치에 대한 정보가 수신되면, 제2 타겟 위치로 주행하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0004590", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 맵 데이터에 기초하여 주행하는 로봇 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2021-0004590", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 가이드 봇 또는 리테일 봇과 같이 사용자에게 서비스를 제공하는 로봇에 대한 기술 개발이 활발해지고 있 다. 서비스를 제공하기 위해 구동부를 구비한 로봇은 일정 공간에 대한 맵 데이터에 기초하여 공간을 주행할 수 있다. 그러나, 로봇이 주행하는 공간이 넓은 경우 주행 공간에 대한 맵 데이터의 크기도 커지며, 이 경우 로봇은 주행 공간에 대한 전체 맵 데이터를 저장할 수 없는 문제점이 있다. 종래의 로봇은 전체 맵 데이터를 복수 개의 로컬 맵 데이터로 분할하여 저장하는 방식으로 이러한 문제점을 극복하려고 하였으나, 주행과정에서 새로운 로컬 맵 데이터가 적용될 때마다 로봇의 위치를 인식해야만 하는 불편이 있었다. 이에 따라 로봇의 주행 과정에서 추가 적인 위치 인식 동작을 요구하지 않으면서 메모리 용량 및 프로세서의 연산량에 관한 부담이 적은 주행 방법에"}
{"patent_id": "10-2021-0004590", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "대한 지속적인 요구가 있었다.발명의 내용"}
{"patent_id": "10-2021-0004590", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 따른 것으로, 본 발명의 목적은 로봇의 주행 경로 상에 식별된 적어도 하나 이상의 타겟 위치에 기초하여 서버로부터 순차적으로 맵 데이터를 수신하여 주행하는 로봇 및 그 제어 방법을 제공함에 있다."}
{"patent_id": "10-2021-0004590", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 본 발명의 일 실시 예에 따른 로봇은, 통신 인터페이스, 주행 공간에 포함된 제1 공간에 대응되는 제1 맵 데이터가 저장된 메모리, 구동부 및 상기 통신 인터페이스를 통해 서버로부터 상기 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보가 수신되면, 상기 제1 타겟 위치로 주행하도록 상기 구동부 를 제어하고, 상기 로봇이 상기 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 상기 제1 타겟 위치에 도달하였음을 나타내는 정보를 상기 서버로 전송하고, 상기 서버로부터 상기 제1 타겟 위치를 포함하는 제2 공간에 대응되는 제2 맵 데이터 및 상기 제2 맵 데이터에 포함된 제2 타겟 위치에 대한 정보가 수신되면, 상기 제2 타겟 위치로 주행하도록 상기 구동부를 제어하는 프로세서를 포함할 수 있다. 여기서, 상기 제2 공간은, 상기 제1 공간과 일부 공간이 오버랩되며, 상기 제2 맵 데이터는, 상기 제1 공간 중 상기 제1 타겟 위치를 포함하는 일부 공간에 대한 맵 정보를 포함하고, 상기 제1 공간 중 상기 제1 타겟 위치를 포함하지 않는 일부 공간에 대한 맵 정보는 포함하지 않을 수 있다. 한편, 상기 프로세서는, 상기 서버로부터 상기 제2 맵 데이터가 수신되는 경우 또는 상기 로봇이 상기 제2 타겟 위치에 도달하는 경우 중 적어도 하나의 경우에 상기 메모리에 저장된 상기 제1 맵 데이터를 삭제할 수 있다. 또한, 카메라를 더 포함하며, 상기 프로세서는, 상기 로봇이 상기 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 상기 카메라를 통해 획득된 정보에 기초하여 상기 제1 타겟 위치의 환경 정보를 획득하고, 상 기 획득된 환경 정보에 기초하여 주행 환경이 변경된 것으로 식별되면, 상기 제1 타겟 위치의 환경 정보를 상기 서버로 전송하고, 상기 서버로부터 상기 제1 타겟 위치의 환경 정보에 대응되는 인공 지능 모델에 대한 정보를 수신하여 상기 메모리에 저장할 수 있다. 또한, 카메라를 더 포함하며, 상기 프로세서는, 상기 로봇이 상기 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 상기 카메라를 통해 획득된 정보에 기초하여 상기 제1 타겟 위치의 환경 정보를 획득하고, 상 기 획득된 환경 정보에 기초하여 상기 로봇의 주행 상태를 변경하도록 상기 구동부를 제어할 수 있다. 한편, 본 발명의 일 실시 예에 따른 서버는, 통신 인터페이스, 로봇의 주행 공간에 포함된 제1 공간에 대응되는 제1 맵 데이터 및 상기 제1 공간과 일부 공간이 오버랩되는 제2 공간에 대응되는 제2 맵 데이터가 저장된 메모 리 및 상기 통신 인터페이스를 통해 상기 제1 맵 데이터 및 상기 제1 맵 데이터 상의 제1 타겟 위치에 대한 정 보를 상기 로봇으로 전송하고, 상기 로봇으로부터 상기 로봇이 상기 제1 타겟 위치에 도달하였음을 나타내는 정 보가 수신되면, 상기 통신 인터페이스를 통해 상기 제2 맵 데이터를 상기 로봇으로 전송하는 프로세서를 포함하 며, 상기 제2 맵 데이터는, 상기 제1 타겟 위치에 대한 맵 정보를 포함할 수 있다. 여기서, 상기 메모리는, 상기 제1 공간과 일부 공간이 오버랩되는 제3 공간에 대응되는 제3 맵 데이터를 더 저 장하며, 상기 프로세서는, 상기 로봇이 상기 제1 타겟 위치에 도달하였음을 나타내는 정보가 수신되면, 상기 제 2 맵 데이터 및 상기 제3 맵 데이터 중 상기 제1 타겟 위치 이후의 제2 타겟 위치에 대응되는 맵 정보를 포함하 는 맵 데이터를 상기 로봇으로 전송하도록 상기 통신 인터페이스를 제어할 수 있다. 또한, 상기 프로세서는, 상기 로봇의 주행 경로가 식별되면, 상기 로봇의 주행 경로에 기초하여 상기 제1 공간 및 상기 제2 공간이 오버랩되는 일부 공간에서 상기 제1 타겟 위치를 식별할 수 있다. 또한, 상기 프로세서는, 상기 로봇의 주행 공간이 복수의 Z축 공간을 포함하는 경우, 상기 복수의 Z축 공간 중 각각을 상기 제1 공간 및 상기 제2 공간으로 식별하고, 상기 제1 공간에서 상기 제2 공간으로 이동하기 위한 구 조를 포함하는 일부 공간을 오버랩되는 공간으로 식별할 수 있다. 여기서, 상기 제1 공간에서 상기 제2 공간으로 이동하기 위한 구조는, 엘리베이터, 에스컬레이터 또는 층계 중 적어도 하나를 포함할 수 있다. 한편, 상기 프로세서는, 상기 제1 맵 데이터의 크기가 임계 크기 이상인 경우, 상기 로봇의 현재 위치 및 상기 제1 타겟 위치 간 주행 경로에 기초하여 상기 제1 맵 데이터 중 상기 주행 경로를 기준으로 식별된 일부 공간에 대응되는 일부 맵 데이터를 상기 로봇으로 전송하도록 상기 통신 인터페이스를 제어할 수 있다. 한편, 본 발명의 일 실시 예에 따른 제어 방법은, 서버로부터 상기 로봇의 주행 공간에 포함된 제1 공간에 대응 되는 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보가 수신되면, 상기 제1 타겟 위치로 주행하는 단계, 상 기 로봇이 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 상기 제1 타겟 위치에 도달하였음을 나타내는 정보를 상기 서버로 전송하는 단계 및 상기 서버로부터 상기 제1 타겟 위치를 포함하는 제2 공간에 대 응되는 제2 맵 데이터 및 상기 제2 맵 데이터에 포함된 제2 타겟 위치에 대한 정보가 수신되면, 상기 제2 타겟 위치로 주행하는 단계를 포함할 수 있다. 여기서, 상기 제2 공간은, 상기 제1 공간과 일부 공간이 오버랩되며, 상기 제2 맵 데이터는, 상기 제1 공간 중 상기 제1 타겟 위치를 포함하는 일부 공간에 대한 맵 정보를 포함하고, 상기 제1 공간 중 제1 타겟 위치를 포함 하지 않는 일부 공간에 대한 맵 정보는 포함하지 않을 수 있다. 또한, 상기 서버로부터 상기 제2 맵 데이터가 수신되는 경우 또는 상기 로봇이 상기 제2 타겟 위치에 도달하는 경우 중 적어도 하나의 경우에 저장된 상기 제1 맵 데이터를 삭제하는 단계를 더 포함할 수 있다. 또한, 상기 로봇이 상기 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 카메라를 통해 획득된 정보에 기초하여 상기 제1 타겟 위치의 환경 정보를 획득하는 단계, 상기 획득된 환경 정보에 기초하여 주행 환 경이 변경된 것으로 식별되면, 상기 제1 타겟 위치의 환경 정보를 상기 서버로 전송하는 단계 및 상기 서버로부 터 상기 제1 타겟 위치의 환경 정보에 대응되는 인공 지능 모델에 대한 정보를 수신하여 저장하는 단계를 더 포 함할 수 있다. 또한, 상기 로봇이 상기 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면, 카메라를 통해 획득된 정보에 기초하여 상기 제1 타겟 위치의 환경 정보를 획득하는 단계 및 상기 획득된 환경 정보에 기초하여 상기 로봇의 주행 상태를 변경하는 단계를 더 포함할 수 있다. 또한, 상기 서버는, 상기 로봇이 제1 타겟 위치에 도달하였음을 나타내는 정보를 수신하고, 상기 제1 공간과 일 부 공간이 오버랩되는 제3 공간에 대응되는 제3 타겟 위치에 대한 맵 정보를 포함하는 제3 맵 데이터 및 상기 제2 맵 데이터 중 상기 제1 타겟 위치 이후의 제2 타겟 위치에 대응되는 맵 정보를 포함하는 맵 데이터를 상기 로봇으로 전송할 수 있다. 또한, 상기 서버는, 상기 로봇의 주행 경로를 식별하고, 상기 로봇의 주행 경로에 기초하여 상기 제1 공간 및 제2 공간이 오버랩되는 일부 공간에서 상기 제1 타겟 위치를 식별할 수 있다. 여기서, 상기 서버는, 상기 로봇의 주행 공간이 복수의 Z축 공간을 포함하는 경우, 상기 복수의 Z축 공간 중 각 각을 상기 제1 공간 및 상기 제2 공간으로 식별하고, 상기 제1 공간에서 상기 제2 공간으로 이동하기 위한 구조 를 포함하는 일부 영역을 오버랩되는 영역으로 식별할 수 있다. 한편, 상기 서버는, 상기 제1 맵 데이터의 크기가 임계 크기 이상인 경우, 상기 로봇의 현재 위치 및 상기 제1 타겟 위치 간 주행 경로에 기초하여 상기 제1 맵 데이터 중 상기 주행 경로를 기준으로 식별된 일부 공간에 대 응되는 일부 맵 데이터를 상기 로봇으로 전송할 수 있다."}
{"patent_id": "10-2021-0004590", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시 예에 따르면, 로봇은 전체 맵 데이터를 분할한 로컬 맵 데이터만을 저장하기 때문에 적 은 메모리 용량으로도 효율적인 주행이 가능하게 된다. 또한, 로봇은 새로운 로컬 맵 데이터가 적용될 때마다 위치 인식 동작을 수행할 필요가 없으므로 프로세서에 부담을 주지 않으면서 더욱 신속한 서비스 제공이 가능하 게 된다."}
{"patent_id": "10-2021-0004590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 개시에서 사용자라는 용어는 로봇을 사용하는 사람을 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개 시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 일정 공간을 주행하는 로봇이 복수의 로컬 맵 데이터에 기초하여 주행하는 동작을 설명하기 위한 도면이 다. 도 1을 참조하면, 로봇은 일정한 공간을 주행하며 사용자에게 서비스를 제공할 수 있다. 로봇은 주행 을 위해 공간에 대응되는 맵 데이터를 기 저장하고 있을 수도 있으나, 필요한 경우에 서버로부터 맵 데이 터를 다운로드 받을 수도 있다. 구체적으로, 로봇은 서버와 전기적으로 통신할 수 있으며, 로봇은 서버에 저장된 맵 데이 터를 수신할 수 있다. 본 명세서에서는 로봇이 서버로부터 특정 데이터를 수신하는 동작을 '다운로드'라는 용어를 통해 설명할 것이다. 공간에 대응되는 전체 맵 데이터는 전체 맵 데이터를 분할한 복수의 로컬 맵 데이터로 구성될 수 있다. 이 경우 로봇은 서버로부터 개별적인 로컬 맵 데이터를 다운로드 받고, 다운로드 받은 로컬 맵 데이터에 기초 하여 주행할 수 있다. 구체적으로, 로봇은 서버로부터 현재 로봇의 위치에 대한 정보를 포함하는 로컬 맵 데이터 및 로봇의 주행 경로에 포함된 또 다른 로컬 맵 데이터를 다운로드 받아 공간을 주행할 수 있다. 주행 과정에서 로봇의 주행에 기초가 되는 맵 데이터가 로봇의 초기 위치에 대한 정보를 포함하는 로 컬 맵 데이터에서 그 이후 주행 경로를 포함하는 로컬 맵 데이터로 전환되는 경우 로봇은 새로 운 로컬 맵 데이터에 기초하여 주행하기 위해 로봇의 위치를 식별할 필요가 있다. 이 경우 로봇이 위치를 식별하기 위해 Lidar와 같은 거리 센서를 이용한 위치 인식 동작을 수행하는 경우 연속적인 주행이 어려워지는 문제점이 생길 수 있다. 이에 따라, 이하에서는 로봇이 주행 과정에서 추가적인 위치 인식 동작을 수행하지 않고도 로봇의 위치를 식별 할 수 있는 다양한 실시 예에 대해 좀더 구체적으로 설명하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 로봇의 구성을 설명하기 위한 도면이다. 도 2를 참조하여, 본 개시의 일 실시 예에 따른 로봇은 통신 인터페이스, 메모리, 구동부 및 프로세서를 포함할 수 있다. 통신 인터페이스는 다양한 타입의 데이터를 입력 및 출력할 수 있다. 예를 들어 통신 인터페이스는 AP 기반의 Wi-Fi(와이파이, Wireless LAN 네트워크), 블루투스(Bluetooth), 지그비(Zigbee), 유/무선 LAN(Local Area Network), WAN(Wide Area Network), 이더넷(Ethernet), IEEE 1394, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), MHL(Mobile High-Definition Link), AES/EBU(Audio Engineering Society/ European Broadcasting Union), 옵티컬(Optical), 코액셜(Coaxial) 등과 같은 통신 방식 을 통해 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB 메모리), 외부 서버(예를 들어 웹 하드)와 다양한 타입의 데이터를 송수신할 수 있다. 일 예에 따르면, 로봇은 통신 인터페이스를 통해 서버에 저장된 맵 데이터를 다운로드할 수 있 다. 메모리는 본 개시의 다양한 실시 예를 위해 필요한 데이터를 저장할 수 있다. 메모리는 데이터 저장 용도에 따라 로봇에 임베디드된 메모리 형태로 구현되거나, 로봇에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 로봇의 구동을 위한 데이터의 경우 로봇에 임베디드된 메모리에 저장 되고, 로봇의 확장 기능을 위한 데이터의 경우 로봇에 탈부착이 가능한 메모리에 저장될 수 있다. 한 편, 로봇에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현될 수 있다. 또 한, 로봇에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital),MMC(multi-media card) 등), USB 포트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구 현될 수 있다. 일 예에 따르면, 메모리는 로봇의 주행 공간에 대응되는 맵 데이터를 저장할 수 있다. 구동부는 로봇을 주행시킬 수 있는 장치이며, 프로세서의 제어에 따라 구동부는 주행 방향 및 주행 속도를 조절할 수 있다. 이를 위해, 구동부는 로봇이 주행하기 위한 동력을 발생시키는 동력 발생장치(예: 사용 연료(또는 에너지원)에 따라 가솔린 엔진(engine), 디젤 엔진, LPG(liquefied petroleum gas) 엔진, 전기 모터 등), 주행 방향을 조절하기 위한 조향 장치(예: 기계식 스티어링(manual steering), 유압 식 스티어링(hydraulics steering), 전자식 스티어링(electronic control power steering; EPS) 등), 동력에 따라 로봇을 주행시키는 주행 장치(예: 바퀴, 프로펠러 등) 등을 포함할 수 있다. 여기서, 구동부는 로봇의 주행 타입(예: 휠 타입, 보행 타입, 비행 타입 등)에 따라 변형 실시될 수 있다. 프로세서는 로봇의 동작을 전반적으로 제어한다. 구체적으로, 프로세서는 로봇의 각 구성 과 연결되어 로봇의 동작을 전반적으로 제어할 수 있다. 예를 들어, 프로세서는 통신 인터페이스 , 메모리 및 구동부와 연결되어 로봇의 동작을 제어할 수 있다. 일 실시 예에 따라 프로세서는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세 서(microprocessor), 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), NPU(Neural Processing Unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)) 등 다양한 이름으로 명명될 수 있으나, 본 명세서에서는 프로세서로 기재한다. 프로세서는 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 또한, 프로세서는 SRAM 등의 휘발성 메모리를 포함 할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는 통신 인터페이스를 통해 서버로부터 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보를 수신할 수 있다. 여기서, 제1 맵 데이터는 로봇이 주행을 함에 있어 초기 위치에 대한 정보를 포함하는 맵 데이터일 수 있다. 또한, 제1 타겟 위치는 제1 맵 데이터에 대응되는 제1 공간 내에서 주행의 목표 지점과 인접한 위치일 수 있다. 일 예에 따르면, 프로세서는 제1 맵 데이터 및 제1 타겟 위치에 대한 정보가 수신된 후 로봇이 제1 타겟 위치로 주행하도록 구동부를 제어할 수 있다. 한편, 프로세서는 로봇이 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면 제1 타겟 위 치에 도달하였음을 나타내는 정보를 서버로 전송할 수 있다. 또한, 일 예에 따른 프로세서는 서버로부터 제1 타겟 위치를 포함하는 제2 공간에 대응되는 제2 맵 데이터 및 제2 맵 데이터에 포함된 제2 타겟 위치에 대한 정보를 수신할 수 있다. 여기서, 제2 공간은 제1 공간과 일부 공간이 오버랩 되는 동시에 제1 타겟 위치를 포함하는 공간으로서, 로봇 이 장차 주행할 주행 경로를 포함하는 공간일 수 있다. 또한, 제2 공간에 대응되는 제2 맵 데이터에는 제2 타겟 위치에 대한 정보가 포함될 수 있다. 여기서, 제2 타겟 위치는 제2 공간 내에서 주행의 목표 지점의 위치 일 수 있다. 여기서, 프로세서는 통신 인터페이스를 통해 서버로부터 데이터를 다운로드하는 속도를 고려하여 로 봇이 제1 타겟 위치에 근접하였음을 서버에 알리고, 서버로 맵 데이터 등의 데이터 전송을 요청할 수 있다. 예를 들어 제2 맵 데이터 및 제2 맵 데이터에 포함된 제2 타겟 위치에 대한 정보의 크기가 5mb(Mega byte)이고, 다운로드 속도가 1mb/s인 경우, 프로세서는 제1 타겟 위치에 도착할 것으로 예정되는 시점으로 부터 5초 전에 서버로 데이터 전송을 요청할 수 있다. 일 예에 따른 프로세서는 제2 맵 데이터 및 제2 맵 데이터에 포함된 제2 타겟 위치에 대한 정보가 수신되 면 로봇이 제2 타겟 위치로 주행하도록 구동부를 제어할 수 있다. 한편, 제2 맵 데이터는 제1 공간 중 제1 타겟 위치를 포함하는 일부 공간에 대한 맵 정보를 포함하고, 제1 공간 중 제1 타겟 위치를 포함하지 않는 일부 공간에 대한 맵 정보는 포함하지 않을 수 있다. 구체적으로, 제2 맵 데이터는 제1 공간 중에서 제2 공간과 오버랩되며 동시에 제1 타겟 위치를 포함하는 공간에 포함된 맵 정보만을 포함할 수 있다. 이에 따라 프로세서는 제2 공간에서 주행할 때 필요한 맵 정보만을포함하는 맵 데이터를 다운받을 수 있으므로, 서버와의 통신에서 발생하는 트래픽 증가를 방지할 수 있다. 여기서, 프로세서는 서버로부터 제2 맵 데이터가 수신되는 경우 또는 로봇이 제2 타겟 위치에 도달하는 경우 중 적어도 하나의 경우에 메모리에 저장된 제1 맵 데이터를 삭제할 수 있다. 구체적으로, 제2 공간을 주행하는 로봇은 제2 공간에 대응되는 제2 맵 데이터에 기초하여 주행하게 되므로, 주행에 필요가 없어진 제1 맵 데이터를 삭제하여 메모리의 용량을 확보할 수 있다. 한편, 로봇은 카메라를 더 포함할 수 있다. 여기서, 프로세서는 로봇이 제1 타겟 위치로부터 임 계 거리 내에 도달한 것으로 식별되면 카메라를 통해 획득된 정보에 기초하여 제1 타겟 위치의 환경 정보를 획 득할 수 있다. 여기서, 카메라를 통해 획득된 정보는 제1 타겟 위치와 인접한 공간을 촬영한 이미지를 포함할 수 있다. 구체적으로, 환경 정보는 공간에 위치하는 장애물 정보, 공간의 조도 정보 또는 공간에 분포하는 유동인구에 관 한 정보를 포함할 수 있다. 프로세서는 획득된 환경 정보에 기초하여 주행 환경이 변경된 것으로 식별되면 제1 타겟 위치의 환경 정보를 서버로 전송할 수 있다. 이어서, 서버로부터 제1 타겟 위치의 환경 정보에 기초하여 해당 공간을 주행할 때 활용하기 가장 적합한 인공 지능 모델이 수신되면 프로세서는 수신된 인공 지능 모델을 메모리에 저장할 수 있다. 한편, 프로세서는 획득된 환경 정보에 기초하여 로봇의 주행 상태를 변경하도록 구동부를 제어 할 수도 있다. 도 3은 본 개시의 일 실시 예에 따른 서버의 구성을 설명하기 위한 도면이다. 도 3을 참조하여, 본 개시의 일 실시 예에 따른 서버는 통신 인터페이스, 메모리 및 프로세서 를 포함할 수 있다. 통신 인터페이스는 다양한 타입의 데이터를 입력 및 출력할 수 있다. 예를 들어 통신 인터페이스는 AP 기반의 Wi-Fi(와이파이, Wireless LAN 네트워크), 블루투스(Bluetooth), 지그비(Zigbee), 유/무선 LAN(Local Area Network), WAN(Wide Area Network), 이더넷(Ethernet), IEEE 1394, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), MHL(Mobile High-Definition Link), AES/EBU(Audio Engineering Society/ European Broadcasting Union), 옵티컬(Optical), 코액셜(Coaxial) 등과 같은 통신 방식 을 통해 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB 메모리), 외부 서버(예를 들어 웹 하드)와 다양한 타입의 데이터를 송수신할 수 있다. 일 예에 따르면, 서버는 통신 인터페이스를 통해 로봇으로 맵 데이터를 전송할 수 있다. 메모리는 본 개시의 다양한 실시 예를 위해 필요한 데이터를 저장할 수 있다. 메모리는 데이터 저장 용도에 따라 서버에 임베디드된 메모리 형태로 구현되거나, 서버에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 서버의 구동을 위한 데이터의 경우 서버에 임베디드된 메모리에 저장 되고, 서버의 확장 기능을 위한 데이터의 경우 서버에 탈부착이 가능한 메모리에 저장될 수 있다. 한 편, 서버에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현될 수 있다. 또 한, 서버에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구 현될 수 있다. 일 예에 따르면, 메모리는 로봇의 주행 공간에 포함된 제1 공간에 대응되는 제1 맵 데이터 및 제1 공 간과 일부 공간이 오버랩되는 제2 공간에 대응되는 맵 데이터를 저장할 수 있다. 프로세서는 서버의 동작을 전반적으로 제어한다. 구체적으로, 프로세서는 서버의 각 구성 과 연결되어 서버의 동작을 전반적으로 제어할 수 있다. 예를 들어, 프로세서는 통신 인터페이스 및 메모리와 연결되어 서버의 동작을 제어할 수 있다.일 실시 예에 따라 프로세서는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세 서(microprocessor), 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), NPU(Neural Processing Unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)) 등 다양한 이름으로 명명될 수 있으나, 본 명세서에서는 프로세서로 기재한다. 프로세서는 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 또한, 프로세서는 SRAM 등의 휘발성 메모리를 포함 할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는 통신 인터페이스를 통해 제1 맵 데이터 및 제1 맵 데이터 상의 제1 타겟 위치에 대한 정보를 로봇으로 전송할 수 있다. 또한, 프로세서는 로봇으로부터 로봇이 제1 타겟 위치에 도달하였음을 나타내는 정보가 수신되 면 통신 인터페이스를 통해 제2 맵 데이터를 로봇으로 전송할 수 있다. 여기서, 제2 맵 데이터는 제1 타겟 위치에 대한 맵 정보를 포함할 수 있다. 여기서, 메모리는 제1 공간과 일부 공간이 오버랩되는 제3 공간에 대응되는 제3 맵 데이터를 더 저장할 수 있다. 일 예에 따르면, 제3 맵 데이터는 제1 공간 및 제1 공간과 일부 공간이 오버랩되는 제2 공간과 일부 공간 이 오버랩되는 공간일 수 있다. 일 예에 따른 프로세서는 로봇이 제1 타겟 위치에 도달하였음을 나타내는 정보가 수신되면 제2 맵 데 이터 및 제3 맵 데이터 중 제1 타겟 위치 이후의 제2 타겟 위치에 대응되는 맵 정보를 포함하는 맵 데이터를 로 봇으로 전송하도록 통신 인터페이스를 제어할 수 있다. 구체적으로, 제2 타겟 위치는 로봇이 주행과정에서 제1 타겟 위치 이후에 도달할 것으로 예상되는 위치일 수 있으며, 프로세서는 제2 타겟 위치를 포함하는 공간에 대응되는 맵 데이터를 로봇으로 전송할 수 있다. 예를 들어, 프로세서는 제2 타겟 위치가 제2 공간에 포함되어 있는 경우 제2 공간에 대응되는 제2 맵 데이터를 로봇으로 전송하며, 제2 타겟 위치가 제3 공간에 포함되어 있는 경우 제3 공간에 대응되는 제 3 맵 데이터를 로봇으로 전송할 수 있다. 또한, 프로세서는 로봇의 주행 경로가 식별되면 로봇의 주행 경로에 기초하여 제1 공간 및 제2 공간이 오버랩되는 일부 공간에서 제1 타겟 위치를 식별하고, 식별된 제1 타겟 위치에 대한 정보를 로봇으 로 전송하도록 통신 인터페이스를 제어할 수 있다. 구체적으로, 프로세서는 제1 공간 및 제2 공간이 오버랩되는 일부 공간에 포함된 로봇의 주행 경로 상의 임의의 위치를 제1 타겟 위치로 식별할 수 있다. 여기서, 식별된 제1 타겟 위치에 대한 정보는 제2 맵 데 이터 상에서 제1 타겟 위치에 대응되는 좌표를 포함할 수 있다. 또한, 프로세서는 로봇의 주행 공간이 복수의 Z축 공간을 포함하는 경우 복수의 Z축 공간 중 각각을 제1 공간 및 제2 공간으로 식별할 수 있다. 구체적으로, 로봇의 주행 공간은 복수의 층을 포함하는 건물의 내부 공간일 수 있으며, 프로세서는 로봇의 현재 위치를 포함하는 층을 제1 공간으로, 로봇의 목적지를 포함하는 층을 제2 공간으로 식별할 수 있다. 이어서, 프로세서는 제1 공간으로 식별된 층에서 제2 공간으로 식별된 층으로 이동하기 위한 구조를 포함 하는 일부 공간을 오버랩되는 공간으로 식별하고, 오버랩되는 공간 중 임의의 위치를 제1 타겟 위치로 식별할 수 있다. 여기서, 제1 공간에서 제2 공간으로 이동하기 위한 구조는 엘리베이터, 에스컬레이터 또는 층계 중 적어도 하나 를 포함할 수 있다. 한편, 프로세서는 제1 맵 데이터의 크기가 임계 크기 이상인 경우 로봇의 현재 위치 및 제1 타겟 위 치 간 주행 경로에 기초하여 제1 맵 데이터 중 주행 경로를 기준으로 식별된 일부 공간에 대응되는 일부 맵 데 이터를 로봇으로 전송하도록 통신 인터페이스를 제어할 수 있다. 도 4a 및 도 4b는 본 개시의 일 실시 예에 따른 로봇이 타겟 위치에 기초하여 주행하는 동작을 설명하기 위한 도면이다. 도 4a는 로봇이 주행하는 공간이 직사각형의 구조이며, 공간에 대응되는 맵 데이터가 정사각형 구조를 갖는 동일한 크기의 공간에 대응되는 8개의 맵 데이터(21-25 등)로 구성된 경우 로봇의 주행을 설명하기 위한 도면이다. 여기서, 8개의 맵 데이터(21-25 등)는 서로 일부 공간이 오버랩되도록 분할된 공간에 대응되는 맵 데이터이며, 본 개시의 일 실시 예에 따른 로봇은 최초의 위치에 대응되는 맵 데이터를 서버로부터 다운 로드하여 메모리에 저장할 수 있다. 일 예에 따른 서버는 서비스가 요구되는 최종 목적지까지 로봇의 주행 경로를 식별하고, 식 별된 경로 및 복수의 맵 데이터(21-25 등)에 대응되는 복수의 공간들이 오버랩되는 공간에 기초하여 복수의 타 겟 위치(11-14)를 식별할 수 있다. 먼저, 서버는 로봇이 최초 위치에 대응되는 제1 맵 데이터 및 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보를 로봇으로 전송할 수 있다. 일 예에 따른 로봇은 제1 맵 데이터 및 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보가 수신되면 제1 타겟 위치로 주행할 수 있다. 여기서, 로봇은 서버가 식별한 주행 경로에 기초 하여 주행할 수도 있으나, 주행 과정에서 발생하는 다양한 상황에 대처하기 위해 스스로 기 식별된 주행 경로 와는 다른 주행 경로에 기초하여 주행할 수도 있다. 이어서, 로봇이 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면 로봇은 제1 타겟 위치에 도달하였음을 나타내는 정보를 서버로 전송함과 동시에 이후의 주행 경로가 포함된 제2 공간에 대응되는 제2 맵 데이터를 요청할 수 있다. 이에 따라 서버는 제2 맵 데이터 및 제2 맵 데이터에 포함된 제2 타겟 위치에 대한 정보를 로봇 으로 전송할 수 있다. 이 경우 제2 맵 데이터는 제1 맵 데이터에 대응되는 공간 중 제1 타겟 위치(1 1)를 포함하지 않는 일부 공간에 대한 맵 정보는 포함하지 않을 수 있다. 일 예에 따른 로봇은 서버로부터 제2 맵 데이터가 수신되는 경우 메모리에 저장된 제1 맵 데이터를 삭제할 수 있다. 이와 동시에 로봇은 다운로드된 제2 맵 데이터에 기초하여 제2 타겟 위 치까지 주행할 수 있다. 이 경우 제2 맵 데이터에는 제2 맵 데이터 상의 제1 타겟 위치에 대응 되는 좌표가 포함되어 있으므로, 로봇는 추가적인 위치 인식 동작 없이도 로봇의 위치를 식별할 수 있다. 구체적으로, 로봇은 최초의 위치에서 위치 인식을 통해 최초의 위치에 대응되는 좌표 및 로봇의 지향 방향을 식별한 후 제1 맵 데이터 및 구동부의 구동 특성을 누적한 데이터에 기초하여 제1 타겟 위치까지 주행할 수 있으며, 그 후 로봇은 제2 맵 데이터에 포함된 제1 타겟 위치 및 제2 타 겟 위치에 대한 정보에 기초하여 제2 타겟 위치까지 주행할 수 있다. 보다 자세하게는, 제1 맵 데이터 상에서 제1 타겟 위치에 대응되는 좌표가 (70,35)이고 제2 맵 데이터 상에서 제1 타겟 위치에 대응되는 좌표가 (10,35)인 경우 로봇은 제1 맵 데이터 상에서 로봇 이 (70,35)의 좌표를 갖는 제1 타겟 위치에 근접한 것으로 식별되면 서버로부터 제2 맵 데이터 및 제2 맵 데이터에 포함된 제2 타겟 위치에 대한 정보를 다운로드 받고, 로봇이 제1 타겟 위치 에 도달하는 순간 제1 맵 데이터를 삭제하고 제2 맵 데이터에 기초하여 주행할 수 있다. 이 경우 제2 맵 데이터 상에서 로봇의 위치는 (10,35)의 좌표를 갖는 제1 타겟 위치로 식별되므로, 로봇은 추가적인 위치 인식 동작이 없이 신속하게 주행할 수 있게 된다. 마찬가지로, 로봇은 제2 타겟 위치에 근접한 경우 이후의 주행 경로를 포함하는 맵 데이터 및 해 당 맵 데이터에 포함된 다음 타겟 위치에 대한 정보를 서버로부터 다운로드하고, 이에 기초하여 다음 타겟 위치까지 주행할 수 있다. 로봇은 이와 동일한 방식으로 마지막 타겟 위치를 경유하여 최종 목적지까지 주행할 수 있다. 도 4b는 로봇이 주행하는 공간이 복잡한 다각형 구조이며, 공간에 대응되는 맵 데이터가 정사각 형 구조를 갖는 서로 상이한 크기의 공간에 대응되는 8개의 맵 데이터(26-29 등)로 구성된 경우 로봇의 주 행을 설명하기 위한 도면이다. 본 개시의 일 실시 예에 따른 로봇은 최초의 위치 여기서, 8개의 맵 데이터(26-29 등)는 서로 일부 공간이 오버랩되도록 분할된 공간에 대응되는 맵 데이터이며, 본 개시의 일 실시 예에 따른 로봇은 최초의 위치에 대응되는 맵 데이터를 서버로부터 다운로드하여 메모리에 저장할 수 있다. 일 예에 따른 서버는 서비스가 요구되는 최종 목적지까지 로봇의 주행 경로를 식별하고, 식 별된 경로 및 복수의 맵 데이터(26-29 등)에 대응되는 복수의 공간들이 오버랩되는 공간에 기초하여 복수의 타 겟 위치(15-17)를 식별할 수 있다. 먼저, 서버는 로봇이 최초 위치에 대응되는 제1 맵 데이터 및 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보를 로봇으로 전송할 수 있다. 일 예에 따른 로봇은 제1 맵 데이터 및 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보가 수신되면 제1 타겟 위치로 주행할 수 있다. 이어서, 로봇이 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면 로봇은 제1 타겟 위치에 도달하였음을 나타내는 정보를 서버로 전송함과 동시에 이후의 주행 경로가 포함된 제2 공간에 대응되는 제2 맵 데이터를 요청할 수 있다. 이에 따라 서버는 제2 맵 데이터 및 제2 맵 데이터에 포함된 제2 타겟 위치에 대한 정보를 로봇 으로 전송할 수 있다. 한편, 로봇은 서버로부터 제2 맵 데이터가 수신되는 경우 메모리 에 저장된 제1 맵 데이터를 삭제할 수 있다. 그 후 로봇은 제2 맵 데이터에 포함된 제1 타겟 위치 및 제2 타겟 위치에 대한 정보에 기초하여 제2 타겟 위치까지 주행할 수 있다. 마찬가지로, 로봇은 제2 타겟 위치에 근접한 경우 이후의 주행 경로를 포함하는 맵 데이터 및 해 당 맵 데이터에 포함된 다음 타겟 위치에 대한 정보를 서버로부터 다운로드하고, 이에 기초하여 다음 타겟 위치까지 주행할 수 있다. 이와 동일한 방식으로 로봇은 최종 목적지까지 주행할 수 있 다. 도 5는 본 개시의 일 실시 예에 따른 로봇이 타겟 위치에 도달한 경우 주행에 필요한 맵 데이터를 다운로드하는 동작을 설명하기 위한 도면이다. 본 개시의 일 실시 예에 따른 로봇은 현재 로봇의 위치를 포함하는 공간에 대응되는 맵 데이터 에 기초하여 맵 데이터에 포함된 타겟 위치까지 주행할 수 있다. 여기서, 해당 타겟 위치를 포함하는 공간에 대응되는 맵 데이터 중 로봇이 장차 주행을 함에 있어 필 요한 맵 데이터는 주행 경로 및 이후의 타겟 위치에 대한 정보를 포함하는 공간에 대응되는 맵 데이터 일 수 있다. 따라서 로봇은 타겟 위치에 대한 정보를 포함하는 복수의 맵 데이터(520, 530) 중에서 이후의 타겟 위치에 대한 정보를 포함하는 맵 데이터를 서버로 요청할 수 있으며, 서버는 로봇의 요청에 대응되는 맵 데이터를 로봇으로 전송할 수 있다. 이에 따라, 로봇은 타겟 위치에 도달한 경우 이후의 주행에 필요한 맵 데이터만을 서버로부터 다운로 드 받을 수 있으므로 메모리에 저장되는 맵 데이터들의 용량을 최소화할 수 있다. 도 6은 본 개시의 일 실시 예에 따른 로봇이 공간의 환경 정보에 기초하여 인공 지능 모델을 다운로드하는 동작 을 설명하기 위한 도면이다. 도 6을 참조하면, 서버는 복수의 인공 지능 모델(221, 222 등)를 메모리에 저장할 수 있다. 도 6에서 는 편의상 두 개의 인공 지능 모델(221, 222)이 서버에 저장되어 있는 것으로 도시하였으나, 두 개의 모델 (221, 222)이외에도 다양한 인공 지능 모델들이 서버에 저장되어 있을 수 있다. 일 예에 따른 로봇은 주행 과정에서 인공 지능 모델을 활용할 수 있다. 구체적으로 로봇은 카메라 를 더 구비할 수 있으며, 카메라를 통해 획득된 이미지를 인공 지능 모델에 입력하고, 인공 지능 모 델의 출력에 기초하여 주행할 수 있다. 로봇은 효율적인 주행을 위해 서버에 저장된 복수의 인공 지능 모델(221, 222 등) 중 로봇이 주 행하는 공간의 환경 정보에 기초하여 보다 정확한 출력을 제공할 수 있는 인공 지능 모델을 서버로부터 다 운로드 받을 수 있다. 본 개시에 따른 인공 지능과 관련된 기능은 로봇의 프로세서와 메모리를 통해 동작된다. 프로세 서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리 에 저장된 기 정의된 동작 규칙 또는 인공 지능 모델에 따라 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공 지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공 지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공 지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으 로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공 지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비 지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습 (reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공 지능 모델은, 복수의 인공 지능 레이어들로 구성될 수 있다. 복수의 인공 지능 레이어들 각각은 복수의 가 중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통 해 인공 지능 연산을 수행한다. 복수의 인공 지능 레이어들이 갖고 있는 복수의 가중치들은 인공 지능 모델의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공 지능 모델에서 획득한 로스(loss) 값 또 는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 인공 지능은 심층 인공 지능(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q- Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 일 예에 따르면, 로봇은 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면 카메라를 통 해 획득한 이미지에 기초하여 타겟 위치 및 장차 로봇이 주행할 주행 경로를 포함하는 공간(620, 이 하 장차 주행할 공간)의 환경 정보를 획득할 수 있다. 여기서, 환경 정보는 공간 내에 분포하는 장애물 (621, 622)에 관한 정보, 공간 내의 유동 인구에 관한 정보 또는 공간의 조도 정보 중 적어도 하나를 포함할 수 있다. 이어서, 로봇은 환경 정보에 기초하여 장차 주행할 공간의 환경이 이전의 공간의 환경과 임계 정도 이상 달라진 것으로 식별되면 획득된 환경 정보를 서버로 전송할 수 있다. 구체적으로, 장차 주행할 공간은 이전의 공간보다 조도가 낮은 공간일 수 있으며, 이전의 공간 에 비해 많은 장애물(621, 622) 및 유동 인구를 포함하는 공간일 수 있다. 서버는 로봇으로부터 수신된 환경 정보에 대응되는 인공지능 모델을 로봇으로 전송할 수 있다. 일 예에 따르면, 장차 주행할 공간의 환경 정보에 대응되는 인공 지능 모델은 저조도의 환경 하에서도 오 브젝트를 정확하게 식별할 수 있는 인공 지능 모델일 수 있다. 일 예에 따른 로봇은 서버로부터 수신된 인공 지능 모델을 메모리에 저장하고, 이에 기초 하여 주행함으로써 장차 주행할 공간에서 효율적으로 주행할 수 있게 된다. 도 6에서는 로봇이 환경 정보를 획득하고, 서버가 로봇으로부터 수신된 환경 정보에 기초하여 인공 지능 모델을 전송하는 실시 예에 대해서 설명하였으나, 다른 예에 따르면 서버가 장차 주행할 공간 의 맵 데이터 뿐만 아니라 공간의 환경 정보에 대응되는 인공 지능 모델을 타겟 위치에 접근하 는 로봇에게 동시에 전송할 수도 있다. 구체적으로, 다른 실시 예에 따른 서버는 복수의 맵 데이터, 각 맵 데이터에 대응되는 복수의 환경 정보 및 그 환경 정보에 대응되는 복수의 인공 지능 모델을 저장할 수 있으며, 로봇이 타겟 위치에 도달하였음 을 나타내는 정보가 수신되면 로봇이 장차 주행할 공간에 대응되는 맵 데이터와 그에 대응되는 인공 지능 모델을 함께 전송할 수도 있다. 도 7은 본 개시의 일 실시 예에 따른 로봇이 공간의 환경 정보에 기초하여 주행 상태를 변경하는 동작을 설명하 기 위한 도면이다. 일 예에 따르면, 로봇은 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면 카메라를 통 해 획득한 이미지에 기초하여 타겟 위치 및 장차 주행할 공간의 환경 정보를 획득할 수 있다. 이어서, 로봇은 환경 정보에 기초하여 장차 주행할 공간의 환경이 이전의 공간의 환경과 임계 정도 이상 달라진 것으로 식별되면 획득된 환경 정보에 기초하여 로봇의 주행 상태를 변경할 수 있다. 구체적으로, 장차 주행할 공간은 이전의 공간보다 조도가 낮은 공간일 수 있으며, 이전의 공간 에 비해 많은 장애물(721, 722) 및 유동 인구를 포함하는 공간일 수 있다. 일 예에 따른 로봇의 프로 세서는 장차 주행할 공간에서 장애물(721, 722) 및 사람과 충돌하는 것을 방지하기 위해 로봇의 속도를 감소시키도록 구동부를 제어할 수 있다. 도 7에서는 로봇의 이동 속도를 감소시키는 동작만을 설명하였으나, 이 외에도 로봇은 장차 주행할 공간의 환경 정보에 기초하여 로봇에 구비된 거리 센서의 센싱 주기 또는 카메라의 촬영 주기를 단축 시키는 동작을 수행할 수도 있다. 도 8은 본 개시의 일 실시 예에 따른 로봇이 건물의 여러 층을 이동하면서 서비스를 제공하는 동작을 설명하기 위한 도면이다. 도 8을 참조하면, 1층에 위치하는 로봇은 서비스 제공을 위해 같은 건물의 5층으로 주행할 수 있다. 일 예에 따른 서버는 1층을 제1 공간으로, 5층을 제2 공간으로 식별하고, 1층에서 5 층으로 이동하기 위한 엘리베이터 및 층계를 포함하는 일부 공간을 제1 공간과 제2 공간이 오버 랩되는 공간으로 식별할 수 잇다. 이어서, 서버는 1층에 대응되는 맵 데이터 및 1층에 위치한 엘리베이터와 인접한 위치 에 대한 정보를 로봇으로 전송할 수 있다. 일 예에 따른 로봇은 수신된 1층에 대응되는 맵 데이터에 기초하여 엘리베이터와 인접한 위치까지 주행할 수 있다. 또한, 서버는 로봇이 1층에 위치한 엘리베이터와 인접한 위치에 도달한 것으로 식별 되면 로봇이 장차 주행할 5층에 대응되는 맵 데이터 및 5층에 위치한 엘리베이터와 인접한 위치에 대한 정보를 로봇으로 전송할 수 있다. 일 예에 따르면, 로봇은 엘리베이터가 이동 하는 도중에 서버로부터 맵 데이터를 다운로드 받을 수 있다. 이어서, 5층에 도착한 로봇은 5층에 대응되는 맵 데이터에 기초하여 엘리베이터와 인접한 위치로 주행하고, 로봇이 해당 위치에 도달하는 경우 1층에 대응되는 맵 데이터를 삭제한 후 목적지까지 주행할 수 있다. 도 9는 본 개시의 일 실시 예에 따른 로봇이 로컬 맵 데이터 중 일부 맵 데이터를 다운로드하는 동작을 설명하 기 위한 도면이다. 일 예에 따르면, 맵 데이터에는 로봇에 구비될 수 있는 복수의 센서의 측정에 관련된 데이터 및 공간(91 0)의 환경 정보와 관련된 데이터 등을 포함될 수 있으므로, 로봇이 위치한 공간에 대응되는 맵 데이터 가 다른 공간에 대응되는 맵 데이터에 비해 데이터의 용량이 큰 경우가 있을 수 있다. 이러한 경우, 서버는 로봇의 현재 위치와 공간 내의 타겟 위치 사이의 주행 경로에 기초하여 공 간의 일부 공간에 대응되는 일부 맵 데이터를 로봇으로 전송할 수 있다. 구체적으로, 서버는 타 겟 위치까지 이르는 로봇의 주행 경로로부터 임계 거리 내의 공간에 대응되는 맵 데이터를 로봇 으로 전송할 수 있다. 이에 따라, 로봇과 서버간의 통신으로 인해 발생하는 트래픽이 최소화되며, 로봇의 메모리(12 0)의 저장용량이 부족한 문제도 방지할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 로봇의 기능적 구성을 구체적으로 설명하기 위한 블록도이다. 도 10에 따르면, 로봇은 통신 인터페이스, 메모리, 구동부, 프로세서, 카메라, 거리 센서 및 서비스 제공부를 포함한다. 도 10에 도시된 구성 중 도 2에 도시된 구성과 중복되는 구 성에 대해서는 자세한 설명을 생략하도록 한다. 카메라는 카메라의 화각(Field of View; FoV) 내에 영역에 대한 촬영을 수행하여 영상을 획득할 수 있다. 카메라는 오브젝트에 의해 반사되어 수신되는 가시광 기타 광학 신호를 이미지 센서로 포커싱하는 렌즈 및 가시광 기타 광학 신호를 감지할 수 있는 이미지 센서를 포함할 수 있다. 여기서, 이미지 센서는 복수의 픽셀로 구분되는 2D의 픽셀 어레이를 포함할 수 있다.거리 센서는 거리 정보를 획득할 수 있다. 구체적으로, 거리 센서는 로봇의 위치와 오브젝트의 위치 사이의 거리를 측정할 수 있다. 일 예에 따른 거리 센서는 라이다(LIDAR, Light Detection And Ranging) 또는 TOF(Time of flight) 센서로 구현될 수 있다. 서비스 제공부는 사용자의 명령을 수신하거나, 사용자 명령에 대응되는 서비스의 제공에 필요한 UI를 출력 할 수 있는 구성이다. 구체적으로, 서비스 제공부는 터치스크린을 포함하는 디스플레이, 스피커 또는 마이 크 중 적어도 하나를 포함할 수 있다. 일 예에 따른 로봇은 제공할 서비스의 종류 및 서비스의 제공 단계 에 기초하여 서비스 제공부를 통해 출력되는 UI를 변경할 수 있다. 도 11은 본 개시의 일 실시 예에 따른 제어 방법을 설명하기 위한 흐름도이다. 본 개시의 일 실시 예에 따른 로봇의 제어 방법은 서버로부터 로봇의 주행 공간에 포함된 제1 공간에 대응되는 제1 맵 데이터에 포함된 제1 타겟 위치에 대한 정보가 수신되면 제1 타겟 위치로 주행하는 단계(S1110), 로봇이 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면 제1 타겟 위치에 도달하였음을 나타내는 정보를 서버로 전송하는 단계(S1120) 및 서버로부터 제1 타겟 위치를 포함하는 제2 공간에 대응되는 제2 맵 데이터 및 제2 맵 데이터에 포함된 제2 타겟 위치에 대한 정보가 수신되면 제2 타겟 위치로 주행하는 단계(S1130)를 포함 할 수 있다. 여기서, 제2 공간은 제1 공간과 일부 공간이 오버랩되며, 제2 맵 데이터는 제1 공간 중 제1 타겟 위치를 포함하 는 일부 공간에 대한 맵 정보를 포함하고, 제1 공간 중 제1 타겟 위치를 포함하지 않는 일부 공간에 대한 맵 정 보는 포함하지 않을 수 있다. 또한, 서버로부터 제2 맵 데이터가 수신되는 경우 또는 로봇이 제2 타겟 위치에 도달하는 경우 중 적어도 하나 의 경우에 저장된 제1 맵 데이터를 삭제하는 단계를 더 포함할 수 있다. 또한, 로봇이 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면 카메라를 통해 획득된 정보에 기초 하여 제1 타겟 위치의 환경 정보를 획득하는 단계, 획득된 환경 정보에 기초하여 주행 환경이 변경된 것으로 식 별되면 제1 타겟 위치의 환경 정보를 서버로 전송하는 단계 및 서버로부터 제1 타겟 위치의 환경 정보에 대응되 는 인공 지능 모델에 대한 정보를 수신하여 저장하는 단계를 더 포함할 수 있다. 또한, 로봇이 제1 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면 카메라를 통해 획득된 정보에 기초 하여 제1 타겟 위치의 환경 정보를 획득하는 단계 및 획득된 환경 정보에 기초하여 로봇의 주행 상태를 변경하 는 단계를 더 포함할 수 있다. 한편, 서버는 로봇이 제1 타겟 위치에 도달하였음을 나타내는 정보를 수신하고 제1 공간과 일부 공간이 오버랩 되는 제3 공간에 대응되는 제3 타겟 위치에 대한 맵 정보를 포함하는 제3 맵 데이터 및 제2 맵 데이터 중 제1 타겟 위치 이후의 제2 타겟 위치에 대응되는 맵 정보를 포함하는 맵 데이터를 로봇으로 전송할 수 있다. 또한, 서버는 로봇의 주행 경로를 식별하고, 로봇의 주행 경로에 기초하여 제1 공간 및 제2 공간이 오버랩되는 일부 공간에서 제1 타겟 위치를 식별할 수 있다. 여기서, 서버는 로봇의 주행 공간이 복수의 Z축 공간을 포함하는 경우 복수의 Z축 공간 중 각각을 제1 공간 및 제2 공간으로 식별하고, 제1 공간에서 제2 공간으로 이동하기 위한 구조를 포함하는 일부 영역을 오버랩되는 영 역으로 식별할 수 있다. 한편, 서버는 제1 맵 데이터의 크기가 임계 크기 이상인 경우 로봇의 현재 위치 및 제1 타겟 위치 간 주행 경로 에 기초하여 제1 맵 데이터 중 주행 경로를 기준으로 식별된 일부 공간에 대응되는 일부 맵 데이터를 로봇으로 전송할 수 있다. 도 12는 본 개시의 일 실시 예에 따른 로봇의 주행 방법을 구체적으로 설명하기 위한 흐름도이다. 본 개시의 일 실시 예에 따른 로봇의 주행 방법에 따르면, 로봇은 서버로부터 타겟 위치에 대한 정보 수신 후 현재 맵 데이터에 기초하여 주행을 개시할 수 있다(S1210). 이어서, 로봇은 타겟 위치로부터 임계 거리 내에 도달한 것으로 식별되면 다음 맵 데이터를 서버로부터 다운로 드할 수 있다(S1220). 여기서, 다음 맵 데이터는 로봇이 장차 주행할 공간에 대응되는 맵 데이터일 수 있다. 이어서, 로봇이 타겟 위치에 도달하면(S1230) 로봇은 도달한 타겟 위치가 최종 목적지인지 식별할 수 있다 (S1240). 만일 현재 도달한 타겟 위치가 최종 목적지인 경우(S1240: Y) 로봇은 주행을 종료하고 사용자에게 서비스를 제공할 수 있다. 반대로, 현재 도달한 타겟 위치가 최종 목적지가 아닌 경우(S1250: N) 로봇은 다운로드된 다음 맵 데이터에 기 초하여 다음 타겟 위치로 주행할 수 있다(S1250). 로봇이 다음 타겟 위치로부터 임계 거리 내에 도달한 경우 로 봇은 그 다음 맵 데이터를 다운로드할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 로봇에 설치 가능한 어플리케이션 형태로 구 현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 로봇에 대한 소프트웨어 업그레이드, 또는 하 드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 로봇에 구비된 임베디드 서버 또는 적어도 하나의 외부 서버를 통 해 수행되는 것도 가능하다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합을 이 용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우 에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의 하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2021-0004590", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으로 이해 되어져서는 안될 것이다."}
{"patent_id": "10-2021-0004590", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일정 공간을 주행하는 로봇이 복수의 로컬 맵 데이터에 기초하여 주행하는 동작을 설명하기 위한 도면이 다. 도 2는 본 개시의 일 실시 예에 따른 로봇의 구성을 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시 예에 따른 서버의 구성을 설명하기 위한 도면이다.도 4a 및 도 4b는 본 개시의 일 실시 예에 따른 로봇이 타겟 위치에 기초하여 주행하는 동작을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 로봇이 타겟 위치에 도달한 경우 주행에 필요한 맵 데이터를 다운로드하는 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시 예에 따른 로봇이 공간의 환경 정보에 기초하여 인공 지능 모델을 다운로드하는 동작 을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시 예에 따른 로봇이 공간의 환경 정보에 기초하여 주행 상태를 변경하는 동작을 설명하 기 위한 도면이다. 도 8은 본 개시의 일 실시 예에 따른 로봇이 건물의 여러 층을 이동하면서 서비스를 제공하는 동작을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시 예에 따른 로봇이 로컬 맵 데이터 중 일부 맵 데이터를 다운로드하는 동작을 설명하 기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 로봇의 기능적 구성을 구체적으로 설명하기 위한 블록도이다. 도 11은 본 개시의 일 실시 예에 따른 제어 방법을 설명하기 위한 흐름도이다. 도 12는 본 개시의 일 실시 예에 따른 로봇의 주행 방법을 구체적으로 설명하기 위한 흐름도이다."}
