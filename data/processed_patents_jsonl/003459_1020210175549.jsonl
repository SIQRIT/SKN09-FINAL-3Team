{"patent_id": "10-2021-0175549", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0087656", "출원번호": "10-2021-0175549", "발명의 명칭": "스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치 및 처리방법", "출원인": "(주)케이아이오티", "발명자": "이재준"}}
{"patent_id": "10-2021-0175549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "스마트 폴에 설치된 카메라 모듈(Camera Module)이 미리 설정된 대상영역(Target Area)을 촬영하여 감시영상(Monitoring Image)을 생성하는 단계;상기 카메라 모듈이 상기 감시영상을 서버(Server)로 전송하는 단계;상기 서버가 상기 카메라 모듈로부터 수신한 상기 감시영상을 분석하여 위험상황을 검출하는 단계; 및상기 서버가 검출한 상기 위험상황에 관련된 관련영상 및 상기 위험상황에 관련된 위치정보를 연관시켜 저장하는 단계;를 포함하는 것을 특징으로 하는 스마트 폴과 인공지능을 이용한 위험상황 정보 처리방법."}
{"patent_id": "10-2021-0175549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 카메라 모듈은케이스부(Case Part);상기 케이스부 내부에 배치되는 프레임부(Frame Part);상기 케이스부 내에서 상기 프레임부에 배치되며 상기 대상영역을 촬영하는 카메라부(Camera Part); 및상기 케이스부 내에 배치되며, 상기 카메라부와 전기적으로 연결되는 카메라 구동부(Camera Driver);를 포함하고,상기 카메라부는제 1 촬영 영역에 대응되는 제 1 카메라부(First Camera Part); 및제 2 촬영 영역에 대응되는 제 2 카메라부(Second Camera Part);를 포함하고,상기 제 1 카메라부는제 1 렌즈부(First Lens Part); 및상기 제 1 렌즈부가 배치되는 제 1 렌즈 기판부(First Lens Substrate Part);를 포함하고,상기 제 2 카메라부는제 2 렌즈부(Second Lens Part); 및상기 제 2 렌즈부가 배치되는 제 2 렌즈 기판부(Second Lens Substrate Part);를 포함하고,상기 제 1 렌즈부가 향하는 방향은 상기 제 2 렌즈부가 향하는 방향과 다른 것을 특징으로 하는 스마트 폴과 인공지능을 이용한 위험상황 정보 처리방법."}
{"patent_id": "10-2021-0175549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,설정모드(Setting Mode)에서 상기 카메라 모듈이 상기 대상영역을 촬영하여 설정영상(Setting Image)을 생성하공개특허 10-2023-0087656-3-는 단계;상기 카메라 모듈이 상기 설정영상을 상기 서버로 전송하는 단계;상기 서버에서 상기 설정영상을 분석하여 상기 대상영역에서 배경을 검출하는 단계;상기 서버에서 상기 배경에서 관심영역 및 위험영역을 설정하는 단계; 및상기 서버가 상기 감시영상에서 객체(Object)가 상기 위험영역에 위치하는 경우에 상기 위험상황이 발생한 것으로 판단하는 단계;를 더 포함하는 것을 특징으로 하는 스마트 폴과 인공지능을 이용한 위험상황 정보 처리방법."}
{"patent_id": "10-2021-0175549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 서버가 미리 설정된 적어도 하나의 단말기로 상기 위험상황에 대한 정보를 전송하는 단계를 더 포함하는것을 특징으로 하는 스마트 폴과 인공지능을 이용한 위험상황 정보 처리방법."}
{"patent_id": "10-2021-0175549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "적어도 하나의 카메라 모듈(Camera Module); 및서버(Server);를 포함하고,상기 카메라 모듈은미리 설정된 대상영역(Target Area)을 촬영하여 감시영상(Monitoring Image)을 생성하고, 생성한 상기 감시영상을 상기 서버로 전송하고,상기 서버는상기 카메라 모듈로부터 수신한 상기 감시영상을 분석하여 위험상황을 검출하고, 검출한 상기 위험상황에 관련된 관련영상을 저장하는 것을 특징으로 하는 스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치."}
{"patent_id": "10-2021-0175549", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치 및 처리방법에 관한 것이다. 보다 자세하게는, 본 발명은 사람이 물에 빠지는 등의 위험한 상황을 인공지능을 이용하여 신속하고 정확하게 감 지할 수 있는 스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치 및 처리방법에 관한 것이다. 본 발명에 따른 스마트 폴과 인공지능을 이용한 위험상황 정보 처리방법은 카메라 모듈(Camera Module)이 미리 설정된 대상영역(Target Area)을 촬영하여 감시영상(Monitoring Image)을 생성하는 단계, 상기 카메라 모듈이 상기 감시영상을 서버(Server)로 전송하는 단계, 상기 서버가 상기 카메라 모듈로부터 수신한 상기 감시영상을 분석하여 위험상황을 검출하는 단계 및 상기 서버가 검출한 상기 위험상황에 관련된 관련영상 및 상기 위험상황 에 관련된 위치정보를 연관시켜 저장하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0175549", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치 및 처리방법에 관한 것이다. 보다 자세하게는, 본 발명은 사람이 물에 빠지는 등의 위험한 상황을 스마트폴과 인공지능을 이용하여 신속하고 정확하게 감지할 수 있는 인공지능을 이용한 위험상황 정보 처리장치 및 처리방법에 관한 것이다."}
{"patent_id": "10-2021-0175549", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보통신기술의 발달로 인해 CCTV 또는 블랙박스와 같은 영상 데이터를 수집하기 위한 장치가 널리 보급되고 있 다. 이러한 장치들은 사회 및 개인의 안전을 위한 무인 감시 체계의 일부로서 사용될 수 있다. 종래의 데이터 수집 장치는 녹화된 영상 데이터를 사후적으로 이용하여 문제를 확인하는 용도로 주로 사용되고 있다. 그러나 사후적으로 영상 데이터를 이용하는 경우에는 위험상황에 대해 신속하게 대응하기 어렵다는 문제점이 있 다. 위험상황에 신속하게 대응하기 위한 종래기술로서 대한민국 등록특허공보 제10-2126498호[문헌 1](발명의 명칭 : 영상 인식 기반의 위험상황 감지방법, 위험 관리 장치 및 위험상황 감지시스템)에서는 영상 인식에 대한 인공 지능 알고리즘을 이용한 학습을 통해 객체, 객체의 움직임 및 위험상황을 감지하고 위험 단계에 따른 감시 기능 을 수행하는 기술적 구성을 포함하고 있다.그러나 문헌 1에 따른 기술에서는 데이터 처리량이 과도하게 증가할 수 있다는 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) [문헌 1] 대한민국 등록특허공보 제10-2126498호"}
{"patent_id": "10-2021-0175549", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 인공지능을 이용하여 빠르고 정확하게 위험상황을 감지할 수 있는 스마트 폴과 인공지능을 이용한 위 험상황 정보 처리장치 및 처리방법을 제공하는데 그 목적이 있다. 본 발명은 상대적으로 적은 데이터 처리량으로 위험상황을 감지하기 위한 스마트 폴과 인공지능을 이용한 위험 상황 정보 처리장치 및 처리방법을 제공하는데 다른 목적이 있다. 본 발명은 위험상황을 효과적으로 관리할 수 있는 스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치 및 처리방법을 제공하는데 또 다른 목적이 있다."}
{"patent_id": "10-2021-0175549", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 스마트 폴과 인공지능을 이용한 위험상황 정보 처리방법은 카메라 모듈(Camera Module)이 미리 설정된 대상영역(Target Area)을 촬영하여 감시영상(Monitoring Image)을 생성하는 단계, 상기 카메라 모듈이 상기 감시영상을 서버(Server)로 전송하는 단계, 상기 서버가 상기 카메라 모듈로부터 수신한 상기 감시영상을 분석하여 위험상황을 검출하는 단계 및 상기 서버가 검출한 상기 위험상황에 관련된 관련영상 및 상기 위험상황 에 관련된 위치정보를 연관시켜 저장하는 단계를 포함할 수 있다. 또한, 서버는 안전영역을 더 설정할 수 있다. 또한, 상기 카메라 모듈은 케이스부(Case Part), 상기 케이스부 내부에 배치되는 프레임부(Frame Part), 상기 케이스부 내에서 상기 프레임부에 배치되며 상기 대상영역을 촬영하는 카메라부(Camera Part) 및 상기 케이스부 내에 배치되며, 상기 카메라부와 전기적으로 연결되는 카메라 구동부(Camera Driver)를 포함하고, 상기 카메라 부는 제 1 촬영 영역에 대응되는 제 1 카메라부(First Camera Part) 및 제 2 촬영 영역에 대응되는 제 2 카메라 부(Second Camera Part)를 포함하고, 상기 제 1 카메라부는 제 1 렌즈부(First Lens Part) 및 상기 제 1 렌즈 부가 배치되는 제 1 렌즈 기판부(First Lens Substrate Part)를 포함하고, 상기 제 2 카메라부는 제 2 렌즈부 (Second Lens Part) 및 상기 제 2 렌즈부가 배치되는 제 2 렌즈 기판부(Second Lens Substrate Part)를 포함하 고, 상기 제 1 렌즈부가 향하는 방향은 상기 제 2 렌즈부가 향하는 방향과 다를 수 있다. 또한, 설정모드(Setting Mode)에서 상기 카메라 모듈이 상기 대상영역을 촬영하여 설정영상(Setting Image)을 생성하는 단계, 상기 카메라 모듈이 상기 설정영상을 상기 서버로 전송하는 단계, 상기 서버에서 상기 설정영상 을 분석하여 상기 대상영역에서 배경을 검출하는 단계, 상기 서버에서 상기 배경에서 관심영역 및 위험영역을 설정하는 단계 및 상기 서버가 상기 감시영상에서 객체(Object)가 상기 위험영역에 위치하는 경우에 상기 위험 상황이 발생한 것으로 판단하는 단계를 더 포함할 수 있다. 또한, 상기 서버가 미리 설정된 적어도 하나의 단말기로 상기 위험상황에 대한 정보를 전송하는 단계를 더 포함 할 수 있다. 본 발명에 따른 인공지능을 이용한 위험상황 정보 처리장치는 적어도 하나의 카메라 모듈(Camera Module) 및 서 버(Server)를 포함하고, 상기 카메라 모듈은 미리 설정된 대상영역(Target Area)을 촬영하여 감시영상 (Monitoring Image)을 생성하고, 생성한 상기 감시영상을 상기 서버로 전송하고, 상기 서버는 상기 카메라 모듈 로부터 수신한 상기 감시영상을 분석하여 위험상황을 검출하고, 검출한 상기 위험상황에 관련된 관련영상을 저 장할 수 있다."}
{"patent_id": "10-2021-0175549", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치 및 처리방법은 위험상황을 충분히 빠르 고 정확하게 감지할 수 있는 효과가 있다. 본 발명에 따른 스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치 및 처리방법은 데이터 처리량을 줄임으 로써 위험상황을 보다 빠르게 감지할 수 있는 효과가 있다."}
{"patent_id": "10-2021-0175549", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명에 따른 인공지능을 이용한 위험상황 정보 처리장치 및 처리방법에 대해 상세히 설명한다. 본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해될 수 있다. 본 발명을 설명함에 있어서 제 1, 제 2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되지 않을 수 있다. 상기 용어들은 하나의 구성요소를 다른 구성요소로 부터 구별하는 목적으로만 사용될 수 있다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성요 소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목 을 포함할 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급되는 경우는, 그 다른 구성요소 에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해될 수 있다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해될 수 있다. 본 문서에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 본 문서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것으로서, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해될 수 있다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석될 수 있으며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않을 수 있다. 아울러, 본 문서에 개시된 실시예는 당 업계에서 평균적인 지식을 가진 자에게 보다 완전하게 설명하기 위해서 제공되는 것으로서, 도면에서의 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 본 문서에서 본 발명을 설명함에 있어서, 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지 를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 수 있다. 도 1 내지 도 3은 본 발명에 따른 스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치에 대해 설명하기 위 한 도면이다. 도 1을 살펴보면, 본 발명에 따른 스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치(1, 이하 '정보 처리 장치'라 칭할 수 있다)는 적어도 하나의 카메라 모듈(Camera Module, 10), 서버(Server, 20), 적어도 하나의 안전요원 단말기 및 적어도 하나의 감독관 단말기를 포함할 수 있다. 카메라 모듈은 주변의 영상을 촬영할 수 있다. 여기서, 주변은 카메라 모듈의 촬영이 가능한 영역, 즉 대상영역(Target Area)을 의미할 수 있다. 대상영역은 촬영영역이라고도 할 수 있다. 이러한 카메라 모듈은 기둥 형태를 갖는 기둥부(Pillar Part, 50)에 배치될 수 있다. 기둥부는 도로변 등에 설치되는 전신주, 가로등 등의 형태를 갖는 것이 가능하다. 이처럼, 기둥부에 카메라 모듈을 설치하는 것을 스마트 폴(Smart Pole, SP) 타입이라고 할 수 있다. 도시하지는 않았지만, 스마트 폴(SP)에는 전력을 공급하기 위한 전력 공급 수단, 통신을 수행하기 위한 통신 수 단 등의 다양한 전자부품이 배치될 수 있다. 도 2에 나타나 있는 바와 같이, 카메라 모듈을 포함하는 스마트 폴(SP)은 복수개가 강 등의 하천(RVR)의 고 수부지 등에 설치될 수 있다. 이하에서는 카메라 모듈의 관점에서 주로 설명을 진행하지만, 카메라 모듈은 스마트 폴(SP)로 치환되더 라도 무방할 수 있다. 안전요원 단말기는 미리 설정된 안전요원이 사용하는 무선 및/또는 유선 단말기라고 할 수 있다. 안전요원은 지역의 안정을 위해 활동하는 사람들로서 상인, 공무원, 경찰 등 다양한 사람들이 이에 참여할 수 있다. 예를 들면, 서울의 이촌동에서 활동하는 상인 A를 가정하여 보자. 상인 A는 자신의 단말기(안전요원 단말기)를 이용하여 서버에 서울 이촌동에 대응하는 안전요원으로 등 록하고, 서버로부터 안전요원에 대응하는 소정의 앱(App)을 다운로드하여 설치할 수 있다. 이러한 상인 A는 지역, 즉 서울 이촌동에서 위험상황이 발생하는 경우 서울 이촌동의 안전요원으로서 활동할 수 있다. 감독관 단말기는 미리 설정된 감독관(Supervisor)이 사용하는 무선 및/또는 유선 단말기라고 할 수 있다. 감독관은 위험상황에 대한 상황 파악을 하는 사람일 수 있다. 예를 들면, 감독관은 위험상황을 충분히 정확하게 파악할 수 있는 사람들로서 경찰관, 소방관 등 다양한 사람들 이 이에 참여할 수 있다. 서버는 적어도 하나의 카메라 모듈, 적어도 하나의 안전요원 단말기 및 적어도 하나의 감독관 단말 기와 유선 및/또는 무선 방식으로 통신을 수행할 수 있다. 카메라 모듈, 서버, 안전요원 단말기 및 감독관 단말기 사이의 통신의 흐름이 도 3에 대략적으 로 나타나 있다. 서버는 적어도 하나의 카메라 모듈로부터 카메라 모듈이 촬영한 영상(설정영상, 감시영상)을 전송 받고, 전송받은 영상을 인공지능을 이용하여 분석할 수 있다. 여기서, 설정영상 및/또는 감시영상은 동영상 및/또는 정지영상인 것이 가능하다. 서버는 인공지능을 이용하여 카메라 모듈이 촬영한 영상을 분석하여 위험상황을 감지할 수 있다. 서버는 포인팅 제어신호 및/또는 알람 제어신호를 카메라 모듈로 전송할 수 있다. 서버는 위험상황의 발생 시 위험상황에 대한 정보를 적어도 하나의 안전요원 단말기 및/또는 적어도 하 나의 감독관 단말기로 전송할 수 있다. 아울러, 서버는 위험상황에 대응하는 위치정보, 예컨대 위험상황이 발생한 위치에 대한 정보 및/또는 위험 상황이 감지된 감시영상을 촬영한 카메라 모듈의 위치에 대한 정보를 안전요원 단말기 및/또는 감독자단말기로 전송할 수 있다. 또는, 서버는 위험상황에 대응하는 위치 정보를 카메라 모듈로 전송하는 것도 가능할 수 있다. 적어도 하나의 안전요원 단말기는 서버로 위험상황에 대응하는 대응영상을 전송할 수 있다. 서버는 적어도 하나의 감독관 단말기로 위험상황의 판정을 요청하는 정보를 전송하고, 이에 대응하여 감독관 단말기는 서버로 위험상황을 판정한 판정정보를 전송하는 것이 가능하다. 아울러, 서버는 위험상황에 관련된 적어도 하나의 안전요원 단말기 및/또는 감독관 단말기로 소정 의 보상을 지급할 수 있다. 여기서, 보상은 금전적인 보상이 가능하고, 누적되는 포인트를 지급하는 방식도 가능할 수 있다. 아울러, 서버는 적어도 하나의 카메라 모듈, 적어도 하나의 안전요원 단말기 및/또는 적어도 하나 의 감독관 단말기를 관리할 수 있다. 카메라 모듈이 촬영한 영상은 설정영상(Setting Image) 및 감시영상(Monitoring Image)을 포함할 수 있다. 감시영상은 카메라 모듈이 촬영이 가능한 영역, 즉 대상영역에서 위험상황이 발생하는지를 감시 (Monitoring)하기 위해 촬영한 영상일 수 있다. 예를 들어, 20xx년 xx월 xx일 aa시~bb시 사이에 이촌동 한강변 에서 위험상황이 발생하는지를 감시하는 경우, 카메라 모듈이 20xx년 xx월 xx일 aa시~bb시 사이에 이촌동 한강변을 촬영한 영상이 감시영상이 될 수 있다. 설정영상은 카메라 모듈이 대상영역에서 배경(Background)을 검출하기 위해 촬영한 영상일 수 있다. 설정영상은 배경의 설정을 위한 영상으로서 샘플영상이라도 할 수 있다. 서버는 주기적 또는 비주기적으로 적어도 하나의 설정영상을 촬영하여 배경을 변경(업데이트)하는 것이 가 능하다. 도 4 내지 도 5는 설정모드에 대해 설명하기 위한 도면이다. 이하에서는 이상에서 상세히 설명한 부분에 대한 설명은 생략될 수 있다. 도 4를 살펴보면, 설정모드(Setting Mode)(S100)에서는 카메라 모듈이 대상영역을 촬영하여 설정영상을 생 성할 수 있다(S100). 설정모드는 카메라 모듈의 설정을 위한 모드라고 할 수 있다. 이후, 카메라 모듈은 생성한 설정영상을 서버로 전송할 수 있다(S120). 예를 들어, 카메라 모듈(혹은 스마트 폴(SP))이 최초로 설치되는 경우에는 카메라 모듈이 촬영할 수 있 는 영역이 아직 명확하게 규정되지 않을 수 있다. 이러한 경우, 카메라 모듈은 대상영역의 영상을 미리 설정된 기간동안 미리 설정된 주기로 촬영하고, 촬영 한 영상(설정영상)을 서버로 전송할 수 있다. 그러면, 서버에서는 인공지능을 이용하여 카메라 모듈로부터 전송받은 적어도 하나의 설정영상을 분석 하여 배경을 검출할 수 있다(S130). 예를 들어, 서버는 1분 간격으로 한달동안 촬영된 설정영상을 분석하여 한달동안의 데이터 변화량이 미리 설정된 임계 변화량보다 더 적은 부분을 검출할 수 있다. 이후, 서버는 데이터 변화량이 임계 변화량보다 적은 부분, 예컨대 데이터 변화량이 실질적으로 0이거나 충 분히 미미한 부분을 배경으로 판단하여 검출할 수 있다. 서버는 영상 분석을 거듭하면서 딥러닝(Deep Learning)을 통해 배경을 보다 효과적이고 정밀하게 검출할 수 있다. 아울러, 서버는 검출한 배경에서 관심영역(Region Of Interest, ROI) 및 위험영역(Dangerous Area, DA)을 구분하여 설정할 수 있다(S140). 또한, 서버는 대상영역에 대응하여 검출한 배경에서 관심영역(ROI) 및 위험영역(DA) 이외에 안전영역 (Safety Area, SA)을 더 설정할 수 있다.여기서, 위험영역(DA)은 사람이 들어가면 위험한 상황이 발생할 수 있는 영역이라고 할 수 있다. 예를 들면, 강 등의 하천, 바다, 다리의 난간 외부 등이 위험영역(DA)으로 설정될 수 있다. 관심영역(ROI)은 위험영역(DA)에 인접하여 사람이 위험영역(DA)으로 이동할 수 있는 가능성이 충분히 높은 영역 이라고 할 수 있다. 예를 들면, 강의 고수부지의 일부, 바다에서 테트라포드(Tetrapod)가 설치된 영역, 다리의 보행자 통로가 관심영역(ROI)으로 설정될 수 있다. 안심영역(SA)은 관심영역(ROI)과 인접하고, 위험영역(DA)으로부터 충분히 멀리 떨어진 영역일 수 있다. 예를 들어, 도 5의 (A)에 나타나 있는 바와 같이, 카메라 모듈이 설정영상으로서 소정의 강변에 대한 영상 을 촬영하는 경우를 가정하여 보자. 이러한 경우, 서버는 영상에서 물에 대응되는 영역을 위험영역(DA)으로 설정하고, 물에 접하는 고수부지 영 역을 관심영역(ROI)으로 설정하고, 물로부터 충분히 멀리 떨어진 부분을 안심영역(SA)으로 설정할 수 있다. 또는, 도 5의 (B)에 나타나 있는 바와 같이, 카메라 모듈이 설정영상으로서 소정의 방파제에 대한 영상을 촬영하는 경우를 가정하여 보자. 이러한 경우, 서버는 영상에서 물, 즉 바다에 대응되는 영역을 위험영역(DA)으로 설정하고, 테트라포드가 배치된 영역을 관심영역(ROI)으로 설정하고, 테트라포드가 설치되지 않고 물로부터 충분히 멀리 떨어진 부분을 안심영역(SA)으로 설정할 수 있다. 여기서는 강 및 바다(방파제)의 경우를 예로 들었지만 다리, 낚시터, 파도가 높은 갯바위, 저수지 등 위험상황 이 발생하는 장소라면 어떠한 곳이라도 본 발명에 따른 카메라 모듈(스마트 폴(SP))이 설치되는 것이 가능 할 수 있다. 아울러, 도 5에서는 대상영역에 대한 배경에서 위험영역(DA), 관심영역(ROI) 및 안전영역(SA)을 모두 설정하는 경우를 설명하고 있지만, 본 발명은 이에 한정되지 않을 수 있다. 예를 들면, 경우에 따라 배경에서 위험영역(DA) 및 관심영역(ROI)을 설정하면서도, 안전영역(SA)은 설정하지 않 을 수 있다. 폭이 좁은 방파제, 높이가 높은 출렁다리 등의 경우가 이에 대응될 수 있다. 이처럼, 배경을 안전영역(SA), 관심영역(ROI) 및 위험영역(DA)으로 구분하는 경우에는, 카메라 모듈이 촬영 한 영상, 즉 감시영상에서 관심영역(ROI) 및/또는 위험영역(DA)에 대응하는 부분만을 분석하여 위험상황을 감지 할 수 있다. 이에 따라, 데이터 처리량을 줄여 신속한 위험상황의 감지가 가능할 수 있다. 도 6 내지 도 17은 위험상황을 감지하는 방법 및 그에 관련된 내용을 설명하기 위한 도면이다. 이하에서는 이 상에서 상세히 설명한 부분에 대한 설명은 생략될 수 있다. 도 6을 살펴보면, 감시모드(Monitoring Mode)(S200)에서 카메라 모듈은 대상영역을 촬영하여 감시영상을 생 성할 수 있다(S210). 감시모드는 대상영역에서 위험상황이 발생하는지를 감시하는 모드라고 할 수 있다. 이후, 카메라 모듈은 생성한 감시영상을 서버로 전송할 수 있다(S220). 그러면 서버는 인공지능을 이용하여 감시영상을 분석(S230)하여, 감시영상에 위험상황이 포함되어 있는지, 즉 위험상황이 발생하는지의 여부를 판단할 수 있다(S240). 서버는 카메라 모듈로부터 전송받은 감시영상을 미리 설정된 기간 동안 저장할 수 있다. 서버는 수신한 감시영상을 분석하여 감시영상을 전송한 카메라 모듈에 대한 위치를 정보를 판별할 수 있다. 예를 들면, 서버는 미리 저장되어 있는 카메라 모듈에 대한 일련번호 등의 고유정보를 근거로 하여 감시영상을 전송한 카메라 모듈의 위치정보를 판별할 수 있다. 제 S240 단계에서 판단결과, 위험상황이 발생하지 않는 경우에는 미리 설정된 제 1 기능(Default 1)을 수행할 수 있다(S250). 제 1 기능으로는 위험상황이 발생하지 않았음을 알리는 기능, 계속해서 감시영상을 분석하는 기능 등을 예로 들 수 있다. 반면에, 제 S240 단계에서 판단결과, 위험상황이 발생한 경우에는 서버는 위험상황에 관련된 관련영상을 생 성(S2560)하고, 생성한 관련영상을 저장(S270)할 수 있다. 서버는 수신한 감시영상을 분석하여 감시영상 내에서 위험상황이 발생한 장소의 위치정보를 판별하는 것이 가능하다. 관련영상은 위험상황에 관련된 객체(Object)가 포함된 영상을 포함할 수 있다. 예를 들어, 20xx년 xx월 xx일 aa시~bb시 사이에 이촌동 한강변에서 촬영한 감시영상에서 객체 A(사람 A)에 대해 위험상황이 발생하는 경우를 가정하여 보자. 이러한 경우, 서버는 저장되어 있는 20xx년 xx월 xx일 aa시 이전의 감시영상을 다시 분석하여 20xx년 xx월 xx일 aa시 이전의 감시영상에서 객체 A를 역추적할 수 있다. 이후, 서버는 역추적한 객체 A가 포함되어 있는 영상을 추출하고, 추출한 영상을 관련영상으로 설정하여 저 장할 수 있다. 여기서, 객체를 사람으로 설정하였지만, 본 발명은 이에 한정되지 않을 수 있다. 예를 들면, 사람이 들고 있는 가방, 사람이 운전하는 자전거, 킥보드, 자동차 등의 탈것 등을 객체로 설정하는 것도 가능할 수 있다. 아울러, 서버는 관련영상을 저장하면서 위험상황에 대응하는 위치정보를 관련영상과 함께 저장하는 것이 가 능하다. 위험상황에 대응하는 위치정보는 위험상황이 발생한 위치에 대한 위치정보를 의미할 수 있다. 또는, 위험상황에 대응하는 위치정보는 위험상황이 검출된 감시영상을 촬영한 카메라 모듈(혹은 스마트 폴 (SP))의 위치정보를 의미하는 것도 가능할 수 있다. 서버에서 감시영상을 분석하여 위험상황이 발생하는지의 여부를 판단하는 방법에 대해 이하에서 보다 상세 히 설명하기로 한다. 도 7에 나타나 있는 바와 같이, 서버에서는 카메라 모듈로부터 전송받은 감시영상을 분석(S230)하여, 감시영상에서 객체(사람 등)를 검출할 수 있다(S300). 이후, 서버는 검출한 객체의 위치를 판별할 수 있다. 객체의 위치는 대상영역에서의 객체의 위치, 혹은 배경에서의 객체의 위치를 의미할 수 있다. 이후, 서버는 객체의 위치가 위험영역(DA)에 포함되어 있는지의 여부를 판단(S302)하고, 판단결과 객체가 위험영역(DA)에 위치하는 경우에는 위험상황이 발생한 것으로 판단할 수 있다(S303). 예를 들어, 객체가 물에 빠진 상황에서 객체는 위험영역(DA)에 위치할 수 있다. 서버는 이러한 경우를 위 험상황으로 판단할 수 있다. 반면에, 제 S302 단계에서의 판단결과, 객체의 위치가 위험영역(DA)에 포함되지 않는 경우에는 객체가 위험영역 (DA)에 인접한 관심영역(ROI)에 위치하는지의 여부를 판단할 수 있다(S304). 제 S304 단계에서의 판단결과, 객체의 위치가 위험영역(DA)에 포함되지 않는 경우에는 객체가 안정영역(SA)에 위치하는 경우에 해당되기 때문에 서버는 위험상황이 발생하지 않은 안전상황이라고 판단할 수 있다(S305). 반면에, 제 S304 단계에서의 판단결과, 객체의 위치가 위험영역(DA)에 포함되는 경우에는 객체가 관심영역(RO I)에서 위험영역(DA)으로 이동하는지의 여부를 판단할 수 있다(S306). 제 S306 단계에서의 판단결과, 객체가 관심영역(ROI)에서 위험영역(DA)으로 이동하는 경우에는 서버는 위험 상황이 발생한 것으로 판단할 수 있다(S303). 예를 들어, 객체가 고수부지에서 강쪽으로 이동하여 강물 들어가는 경우는 객체가 관심영역(ROI)에서 위험영역 (DA)으로 이동하는 경우에 해당될 수 있다. 서버는 이러한 경우를 위험상황으로 판단할 수 있다. 반면에, 제 S306 단계에서의 판단결과, 객체가 관심영역(ROI)에서 위험영역(DA)으로 이동하지 않는 경우에는 객 체가 관심영역(ROI)에서 안전영역(SA)으로 이동하는지의 여부를 판단할 수 있다(S307). 제 S307 단계에서의 판단결과, 객체가 관심영역(ROI)에서 안전영역(SA)으로 이동하는 경우에는 서버는 위험 상황이 발생하지 않은 안전상황이라고 판단할 수 있다(S305).반면에, 제 S307 단계에서의 판단결과, 객체가 관심영역(ROI)에서 안전영역(SA)으로 이동하지 않는 경우에는 서 버는 관심영역(ROI)에서 객체가 감지되는지의 여부를 판단할 수 있다(S308). 제 S308 단계에서의 판단결과, 객체가 관심영역(ROI)에서 감지되는 경우에는 제 S302 단계로 진행할 수 있다. 반면에, 제 S308 단계에서의 판단결과, 객체가 관심영역(ROI)에서 감지되지 않는 경우에는 서버는 위험상황 이 발생한 것으로 판단할 수 있다(S303). 이러한 경우는, 객체가 관심영역(ROI)에 위치하는 상황에서 안전영역(SA)으로 이동하지 않으면서도 갑자기 사라 지는 경우에 해당될 수 있다. 이러한 경우에는, 객체가 물에 빠지는 등의 위험상황이 발생했을 가능성이 높다. 또는, 객체가 테트라포드가 설치된 지역에 위치하다가 테트라포드의 사이로 빠지는 사고가 발생했을 가능성이 높다. 서버는 객체가 사라지는 것을 판단하기 위해 감시영상을 프레임(Frame) 별로 각각 분석하여 객체를 검출할 수 있다. 감시영상에서 객체가 관심영역(ROI)에 위치한 상태에서 객체가 안전영역(SA)으로 이동하지 않으면서 객체가 사 라지거나 혹은 개체가 관심영역(ROI)에서 위험영역(DA)으로 이동하는 과정에서 사라지는 경우에 서버는 위 험상황이 발생한 것으로 판단할 수 있다. 한편, 객체가 단순히 위험영역에 위치하는 것만으로는 위험상황이 발생한 것으로 판단하지 않는 것이 가능하다. 도 8에 나타나 있는 바와 같이, 서버는 객체가 위험영역(DA)에 위치하는 경우에는 객체가 위험영역(DA)에 위치하는 시간이 미리 설정된 기준시간을 초과하는지의 여부를 판단할 수 있다(S310). 제 S310 단계에서 판단결과, 객체가 기준시간보다 더 오래 위험영역(DA)에 위치하는 경우에는 서버는 위험 상황이 발생한 것으로 판단할 수 있다(S303). 예를 들어, 객체가 1시간 이상 계속 강물에 빠진 상태를 유지하는 경우 객체에 이상이 발생할 가능성이 높을 수 있다. 반면에, 제 S310 단계에서 판단결과, 객체가 위험영역(DA)에 위치하는 시간이 기준시간보다 더 짧은 경우에는 서버는 객체가 다른 영역, 예컨대 관심영역(ROI)으로 이동하는지의 여부를 판단할 수 있다(S311). 제 S311 단계에서 판단결과, 객체가 다른 영역으로 이동하는 경우에는 제 S304 단계로 진행할 수 있다. 반면에, 제 S311 단계에서 판단결과, 객체가 다른 영역으로 이동하지 않는 경우에는 감시영상에서 객체가 감지 되는지의 여부를 판단할 수 있다(S312). 제 S312 단계에서의 판단결과, 객체가 감지되는 경우에는 제 S310 단계로 진행할 수 있다. 반면에, 제 S312 단계에서의 판단결과, 객체가 감지되지 않는 경우에는 서버는 위험상황이 발생한 것으로 판단할 수 있다(S303). 이러한 경우는, 객체가 위험영역(DA)에 위치하는 상황에서 관심영역(ROI)으로 이동하지 않으면서도 갑자기 사라 지는 경우에 해당될 수 있다. 이러한 경우에는, 객체가 파도 또는 물살에 휩쓸리는 등의 위험상황이 발생했을 가능성이 높다. 또는, 객체가 깊은 물에 완전히 빠져 위험영역(DA)에서 사라지는 경우일 가능성이 높다. 한편, 객체의 포즈를 이용하여 위험상황의 발생을 감지하는 것이 가능하다. 도 9에 나타나 있는 바와 같이, 객체가 위험영역(DA)에 위치하거나 혹은 관심영역(ROI)에 위치하는 경우에 서버 는 감시영상을 분석하여 객체의 포즈를 판별할 수 있다(S321). 이후, 판별한 객체의 포즈가 미리 설정된 이상포즈에 매칭(Matching)되는지의 여부를 판단할 수 있다(S322). 제 S322 단계에서 판단결과, 객체의 포즈가 이상포즈에 매칭되지 않는 경우에는 미리 설정된 제 2 기능(Default 2)을 수행할 수 있다(S323). 여기서, 제 2 기능은 객체의 위치를 판별하는 단계(S301)로 진행하거나 현 상태를 안전상황이라고 판단하는 것 이 가능할 수 있다.반면에, 제 S322 단계에서 판단결과, 객체의 포즈가 이상포즈에 매칭되는 경우에는 서버는 위험상황이 발생 한 것으로 판단할 수 있다(S303). 예를 들면, 객체가 관심영역(ROI) 또는 위험영역(DA)에 위치하는 상태에서 넘어지는 포즈, 다이빙하는 포즈, 가 방 등의 또 다른 객체를 던지를 포즈, 다른 객체(사람)를 위험영역(DA)으로 밀어내는 포즈 등을 취하는 경우에, 서버는 위험상황이 발생한 것으로 판단하는 것이 가능하다. 이상에서 설명한 바와 같은 방법으로 위험상황을 판단하면서 서버는 다양한 데이터를 축적하고 딥러닝을 수 행할 수 있다. 이러한 과정을 거치면서 서버는 보다 빠르고 정확하게 위험상황의 발생을 판단할 수 있다. 한편, 서버는 위험상황 발생 시 관련영상 및 위치정보를 저장하면서, 위험상황에 대한 정보를 적어도 하나 의 다른 단말기로 전송하는 것이 가능하다. 이에 대해 첨부된 도면을 참조하여 살펴보면 아래와 같다. 도 10에 나타나 있는 바와 같이, 서버는 관련영상 및/또는 위치정보를 저장(S270)한 이후에 적어도 하나의 감독관 단말기로 위험상황의 판정을 요청하는 정보를 전송할 수 있다(S400). 위험상황의 판정을 위해서 서버는 감독관 단말기로 위험상황에 대응하는 관련정보 및 위치정보를 함께 전송할 수 있다. 감독관 단말기는 서버로부터의 판정 요청에 대응하여 관련영상 및 위치정보를 분석하여 위험상황에 대 한 위험도를 판정할 수 있다(S410). 이후, 감독관 단말기는 서버로 위험상황의 위험도를 판정한 정보, 즉 판정 정보를 전송할 수 있다 (S420). 예를 들어, 카메라 모듈이 20xx년 xx월 xx일 aa시~bb시 사이에 이촌동 한강변에서 촬영한 감시영상을 서버 에서 분석한 결과, 서버가 해당 감시영상에 객체 B(사람 B)에 대해 위험상황이 발생하는 경우를 가정하 여 보자. 이러한 경우, 객체 B에 대응하여 관련영상을 생성하고, 위험상황에 대응하는 위치 정보를 관련영상과 함께 저장 할 수 있다. 아울러, 서버는 객체 B에 대응하는 관련영상과 위치정보를 적어도 하나의 감독관 단말기로 전송하고, 위험상황을 판정해달라고 요청할 수 있다. 여기서, 감독관 단말기에서는 서버로부터 수신한 관련영상과 위치정보를 분석하여 위험정도를 판정할 수 있다. 감독관 단말기를 사용하는 감독관들은 위험상황을 신속하고 정확하게 판단할 수 있는 전문가 그룹으로부터 구성될 수 있다. 이처럼, 서버가 인공지능을 이용하여 감시영상을 분석하여 위험상황의 발생을 감지하면서도, 관련영상과 위 치정보를 감독관 단말기로 전송하여 감독관으로 하여금 위험상황을 판단하게 하는 경우에는 위험상황을 보 다 정밀하고 정확하게 분석할 수 있다. 이에 따라, 위험상황 발생 시 보다 신속하고 정확한 대처가 가능할 수 있다. 한편, 서버가 감독관 단말기로부터 수신한 판정정보를 분석하여, 해당 위험상황의 위험도가 미리 설정 된 기준 위험도를 초과하는지의 여부를 판단할 수 있다(S430). 제 S430 단계에서 판단결과, 해당 위험상황의 위험도가 기준 위험도를 초과하지 않는 경우에는 미리 설정된 제 3 기능(Default 3)을 수행할 수 있다(S440). 여기서, 제 3 기능은 해당 위험상황에 대한 위험도가 충분히 낮다는 것을 알리는 정보를 서버로 전송하는 기능, 위험 경보를 해제하는 기능 등을 예로 들 수 있다. 반면에, 제 S430 단계에서 판단결과, 해당 위험상황의 위험도가 기준 위험도를 초과하는 경우에는 서버는 해당 위험상황이 위험이 실제라고 판단하고, 이에 대한 정보를 적어도 하나의 안전요원 단말기로 전송하여 위험 상황을 알릴 수 있다(S450). 안전요원 단말기로 전송하는 정보는 위험상황에 대응하는 관련영상 및 위치정보를 포함할 수 있다. 예를 들면, 서버는 도 11에 나타나 있는 바와 같은 위험상황 알람 메시지를 적어도 하나의 안전요원 단말기 로 전송할 수 있다. 이후, 위험상황 알림 메시지를 수신한 적어도 하나의 안전요원은 관련영상 및 위치정보를 확인하여 해당 위험상 황이 발생한 위치로 이동할 수 있다. 이후, 안전요원 단말기에서는 위험상황에 대응하는 적어도 하나의 영상, 즉 대응영상을 촬영하여 서버 로 전송할 수 있다. 그러면, 서버는 안전요원 단말기로부터 대응영상이 입력되는지의 여부를 판단하고, 대응영상이 입력되 는 경우에 대응영상을 저장할 수 있다(S480). 이후, 서버는 대응영상을 입력한 적어도 하나의 안전요원 단말기로 소정의 보상을 지급할 수 있다 (S490). 반면에, 제 S460 단계에서 판단결과 대응영상이 입력되지 않는 경우에는 미리 설정된 제 4 기능(Default 4)을 수행할 수 있다(S470). 여기서, 제 4 기능은 대응영상을 입력하라는 요청을 적어도 하나의 안전요원 단말기로 전송하는 기능 등을 예로 들 수 있다. 예를 들어, 카메라 모듈이 20xx년 xx월 xx일 aa시~bb시 사이에 이촌동 한강변에서 촬영한 감시영상을 서버 에서 분석한 결과, 서버가 해당 감시영상에 객체 B(사람 B)에 대해 위험상황이 발생하는 경우를 가정하 여 보자. 여기서, 감독관 단말기에서 서버로 객체 B에 대한 위험상황의 위험도가 기준 위험도보다 저 높다고 판 정한 판정정보를 전송할 수 있다. 그러면, 서버는 감독관 단말기로부터 수신한 판정정보를 근거로 하여 적어도 하나의 안전요원 단말기 로 객체 B에 대해 위험상황이 발생했다는 정보를 전송할 수 있다. 여기서, 서버는 객체 B가 포함된 감시영상, 즉 관련영상 및 객체 B의 위험상황에 대응되는 위치정보를 적어 도 하나의 안전요원 단말기로 전송할 수 있다. 예를 들면, 이촌동 혹은 이촌동에 인접하는 지역에 거주하 거나 이촌동에 연관된 적어도 하나의 안전요원의 단말기로 객체 B의 위험상황에 대한 정보를 전송할 수 있 다. 이를 위해, 서버는 각각의 안전요원 단말기의 위치정보를 수집하여 저장할 수 있다. 객체 B의 위험상황에 대한 정보를 수신한 적어도 하나의 안전요원은 해당 위험상황에 대응되는 위치, 즉 이촌동 으로 이동할 수 있다. 이후, 이촌동으로 이동한 적어도 하나의 안전요원은 객체 B의 구조 등의 안전조치를 취할 수 있다. 이후, 안전조치를 취한 적어도 하나의 안전요원은 안전조치에 대한 영상, 즉 대응영상을 촬영하고, 촬영한 대응 영상을 서버로 전송할 수 있다. 그러면, 서버는 해당 안전요원 단말기로 금전적 보상, 누적 포인트의 지급 등의 방식으로 보상을 실시 할 수 있다. 이와 같이, 위험상황에 대한 정보를 적어도 하나의 안전요원 단말기로 전송하는 경우에는 안전요원으로 하 여금 위험상황에 자발적으로 개입하도록 하는 동기를 부여할 수 있다. 아울러, 위험상황 발생 시 경찰, 구급대 또는 구조대의 도착 이전에 인근에 위치한 안전요원으로부터 도움을 받 을 수 있어서 신속한 응급대응이 가능할 수 있다. 한편, 이상에서는 감독관 단말기와 안전요원 단말기를 별도로 설정하는 것으로 설명하였지만, 본 발명 은 이에 한정되지 않을 수 있다. 예를 들면, 서버에 등록된 사용자가 감독관 역할을 수행할지 혹은 안전요원 역할을 수행할지 스스로 선택하 는 것이 가능하다. 이에 대해 첨부된 도면을 참조하여 살펴보면 아래와 같다. 도 12를 살펴보면, 적어도 하나의 사용자 단말기(User Terminal, UT)가 서버에 접속할 수 있다(S500). 서버에 접속한 사용자 단말기(UT)는 서버로부터 안전관리를 위한 소정의 앱을 다운받아 설치할 수 있다 (S510). 아울러, 사용자 단말기(UT)는 서버에 소정의 사용자 정보를 전송하여 사용자 등록을 수행할 수 있다(S520). 사용자 등록을 완료한 사용자 단말기(UT)는 서버를 통해 설정모드를 선택할 수 있다(S530). 예를 들면, 도 13에 나타나 있는 바와 같이, 사용자 단말기(UT)에는 안전요원 모드를 선택할지 혹은 감독관 모 드를 설정할지는 선택하기 위한 메뉴가 표시될 수 있다. 여기서, 사용자가 사용자 단말기(UT)에서 안전요원 모드를 선택하면, 서버는 해당 사용자 단말기(UT)를 안 전요원 단말기로 설정할 수 있다. 반면에, 사용자가 사용자 단말기(UT)에서 감독관 모드를 선택하면, 서버는 해당 사용자 단말기(UT)를 감독 관 단말기로 설정할 수 있다. 이후, 사용자 단말기(UT)에서는 원하는 시간대를 선택할 수 있다(S540). 예를 들어, 사용자 C가 자신의 단말기를 이용하여 서버에 사용자 등록을 하고, 이후에 안전요원 모드에 대 응하여 안전요원으로서 원하는 시간대를 매주 토요일 22시~24시를 설정하고, 아울러, 감독관 모드에 대응하여 감독관으로서 원하는 시간대를 매주 금요일 22시~24시라를 설정하는 것을 가정하여 보자. 이러한 경우, 서버는 사용자 C의 단말기를 매주 금요일 22시~24시 동안에는 감독관 단말기로 설정하고, 매주 토요일 22시~24시 동안에는 안전요원 단말기로 설정하는 것이 가능하다. 이에 따라, 사용자 C는 자신의 단말기를 이용하여 매주 금요일 22시~24시 동안에는 감독관으로서 활동하고, 매 주 토요일 22시~24시 동안에는 안전요원으로서 활동할 수 있다. 이처럼, 서버에 등록된 사용자가 스스로 안전요원 또는 감독관 역할을 선택하도록 하는 경우에는 사용자의 자발적 참여를 촉진하는 것이 가능하다. 한편, 카메라 모듈을 포함하는 스마트 폴(SP)은 위험상황에 대응하는 위치, 즉 위험상황이 발생한 위치를 포인팅(Pointing)하기 위한 포인팅 수단을 포함할 수 있다. 이에 대해 첨부된 도면을 참조하여 살펴보면 아래 와 같다. 도 14를 살펴보면, 서버가 관련영상 및 위치정보를 저장(S270)한 이후에 포인팅 제어신호를 스마트 폴(SP) 로 전송할 수 있다(S600). 여기서, 포인팅 제어신호는 위험상황에 대응되는 위치를 포인팅하기 위한 제어신호일 수 있다. 그러면, 포인팅 제어신호를 수신한 스마트 폴(SP)은 포인팅부(Pointing Part)를 활성화시킬 수 있다(S610). 이후, 스마트 폴(SP)에서는 활성화된 포인팅부를 이용하여 위험상황에 대응되는 위치를 포인팅할 수 있다 (S620). 아울러, 서버는 알림 제어신호를 스마트 폴(SP)로 전송할 수 있다(S630). 알림 제어신호는 위험상황에 대응하는 감시영상을 촬영한 카메라 모듈을 포함하는 스마트 폴(SP)을 알리기 위한 제어신호일 수 있다. 그러면, 알림 제어신호를 수신한 스마트 폴(SP)은 알림부(Warning Part)를 활성화시키고, 활성화된 알림부는 알 림을 출력할 수 있다(S640). 이를 위해, 도 15에 나타나 있는 바와 같이, 스마트 폴(SP)은 기둥부에 배치되는 카메라 모듈, 알림부 및 포인팅부를 포함할 수 있다. 알림부는 소정의 광을 발산하기 위한 경광등(Warning Light)을 포함할 수 있다. 서버로부터 스마트 폴(SP)로 알림 제어신호가 전송되면, 스마트 폴(SP)은 알림부를 제어하여 소정의 광 을 발산하도록 할 수 있다. 그러면, 안전요원 등 위험상황을 처리하고자 하는 사람들에게 위험상황이 발생한 위치를 보다 용이하고 신속하 게 알릴 수 있다. 포인팅부는 레이저 등의 광을 이용하여 포인팅을 할 수 있는 레이저 포인터 등의 포인팅 수단을 포함할 수 있다. 서버로부터 스마트 폴(SP)로 포인팅 제어신호가 전송되면, 스마트 폴(SP)은 포인팅부를 제어하여 포인 팅부가 위험상황에 대응되는 위치(OP)를 소정의 광으로 포인팅하도록 할 수 있다. 이를 위해, 포인팅 제어신호는 위험상황에 대응되는 위치에 대한 정보를 포함할 수 있다. 다른 관점에서 보면, 서버는 포인팅부를 포함하는 스마트 폴(SP)로 위험상황에 대응하는 위치정보, 즉 위험상황이 발생한 장소에 대한 위치정보를 전송하는 것이 가능하다. 여기서, 서버는 감시영상을 분석하여 감시영상 내에서 위험상황이 발생한 장소의 위치를 판별하고, 판별한 위치정보를 포인팅부로 전송하는 것으로 볼 수 있다. 한편, 스마트 폴(SP)의 카메라 모듈은 복수의 카메라부(Camera Part)를 포함하고, 복수의 카메라부를 이용 하여 넓은 영역의 영상(설정영상, 감시영상 등)을 획득하는 것이 가능하다. 도 16 내지 도 17을 살펴보면, 기둥부는 수직방향(Vertical Direction, DRV)으로 길게 연장되는 형태를 갖 는 수직부 및 수직부로부터 수평방향(Horizontal Direction, DRH)으로 연장되는 수평부를 포함할 수 있다. 아울러, 수평부의 하부에 카메라 모듈이 설치될 수 있다. 여기서는, 알림부 및 포인팅부의 도시는 생략하기로 한다. 카메라 모듈은 제 1 대상영역의 영상을 촬영하기 위한 제 1 카메라부(First Camera Part, 11) 및 제 2 대상 영역의 영상을 촬영하기 위한 제 2 카메라부(Second Camera Part, 12)를 포함할 수 있다. 아울러, 포인팅부는 제 1 카메라부에 대응하는 제 1 포인팅부(81a) 및 제 2 카메라부에 대응하는 제 2 포인팅부(81b)를 포함할 수 있다. 카메라 모듈은 수평부의 하부의 하면에 배치되고, 제 1 포인팅부(81a)는 수평부의 제 1 카메라부 에 대응되는 측면에 배치될 수 있다. 예를 들면, 제 1 포인팅부(81a)는 수평부의 제 1 측면에 배치될 수 있다. 아울러, 제 2 포인팅부(81b)는 제 2 카메라부에 대응되는 수평부의 측면에 배치될 수 있다. 예를 들면, 제 2 포인팅부(81b)는 수평부의 제 2 측면에 배치될 수 있다. 이러한 경우, 제 1 포인팅부(81a)는 제 1 카메라부가 촬영한 감시영상으로부터 감지되는 위험상황에 대응하 는 위치를 포인팅할 수 있다. 아울러, 제 2 포인팅부(81b)는 제 2 카메라부가 촬영한 감시영상으로부터 감지되는 위험상황에 대응하는 위 치를 포인팅할 수 있다. 도 18 내지 도 35는 카메라 모듈에 대해 설명하기 위한 도면이다. 이하에서는 이상에서 상세히 설명한 부분에 대한 설명은 생략될 수 있다. 이하에서 제 1 방향(First Direction, DR1)은 제 2 방향(Second Direction, DR2) 및 제 3 방향(Third Direction, DR3)과 교차(수직)하고, 제 2 방향(DR2)은 제 3 방향(DR3)과 교차(수직)할 수 있다. 여기서, 제 1 방향(DR1), 제 2 방향(DR2) 및 제 3 방향(DR3)은 카메라 모듈의 설명을 용이하게 위해 임의로 설정한 것으로서, 본 발명이 이에 한정되는 것은 아닐 수 있다. 도 18을 살펴보면, 본 발명에 따른 카메라 모듈은 케이스부(Case Part, 30), 프레임부(Frame Part, 40) 및 카메라부(Camera Part, 11, 12)를 포함할 수 있다. 케이스부는 카메라 모듈의 외관을 이룰 수 있다. 프레임부는 케이스부의 내부에 배치될 수 있다. 이러한 프레임부는 카메라부(11, 12) 등의 다른 부품이 배치될 수 있는 지지기반을 마련할 수 있다. 카메라부(11, 12)는 케이스부 내에서 프레임부에 배치되며 주변 영상을 촬영할 수 있다. 이러한 카메라부(11, 12)는 제 1 카메라부 및 제 2 카메라부를 포함할 수 있다. 제 1 카메라부는 제 1 촬영영역, 즉 제 1 대상영역에 대응될 수 있다. 제 2 카메라부는 제 2 촬영영역 ,즉 제 2 대상영역에 대응될 수 있다. 예를 들어, 카메라부(11, 12)가 스마트 폴(SP)의 기둥부에 배치되는 경우, 제 1 카메라부는 기둥부(5 0)의 좌측 영역에 대응되고, 제 2 카메라부는 기둥부의 우측 영역에 대응될 수 있다. 다른 관점에서 보면, 제 1 카메라부는 기둥부의 좌측 영역을 촬영하고, 제 2 카메라부는 기둥부 의 우측 영역을 촬영할 수 있다. 아울러, 도시하지는 않았지만, 본 발명에 따른 카메라 모듈은 카메라 구동부(Camera Driver, 미도시)를 더 포함할 수 있다. 도 19를 살펴보면, 케이스부는 바닥부(Bottom Part, 300), 중간부(Middle Part, 310) 및 덮개부(Cover Part, 320)를 포함할 수 있다. 바닥부는 수평방향(제 1 방향(DR1) 또는 제 2 방향(DR2)으로 연장되는 부분을 포함하는 플레이트(Plate) 형태를 갖는 것이 가능하다. 중간부는 바닥부에 배치되며, 수직방향(제 3 방향(DR3))으로 연장되는 부분을 포함할 수 있다. 중간부는 도시하지는 않았지만 카메라 구동부(미도시) 등의 다른 부품이 배치될 수 있는 공간을 마련할 수 있다. 이러한 중간부는 양측이 개방된 관(Pipe) 형태를 갖는 것이 가능하다. 덮개부는 중간부의 상부에 연결될 수 있다. 덮개부와 바닥부의 사이에 마련된 공간에 프레임부, 카메라부(11, 12) 및 카메라 구동부(미도 시)가 배치될 수 있다. 아울러, 카메라부(11, 12)가 원활하게 촬영하기 위해 덮개부는 광투과성 재질을 포함하며 돔(Dome) 형태를 갖는 것이 가능하다. 덮개부는 어느 정도 투명할 수 있다. 도 20을 살펴보면, 제 1 카메라부는 제 1 렌즈부(First Lens Part, 11b) 및 제 1 렌즈 기판부(First Lens Substrate Part, 11a)를 포함할 수 있다. 제 1 렌즈부(11b)는 제 1 렌즈 기판부(11a)에 배치될 수 있다. 제 1 렌즈 기판부(11a)에는 제 1 커넥터부(First Connector Part, 11c)가 배치될 수 있다. 제 1 커넥터부(11c)는 제 1 렌즈부(11b)에 의해 촬영된 영상 데이터를 카메라 구동부(Camera Driver, 190)로 전 송하기 위한 제 1 케이블부(First Cable Part, 193)와 전기적으로 연결될 수 있다. 제 2 카메라부는 제 2 렌즈부(Second Lens Part, 12b) 및 제 2 렌즈 기판부(Second Lens Substrate Part, 12a)를 포함할 수 있다. 제 2 렌즈부(12b)는 제 2 렌즈 기판부(12a)에 배치될 수 있다. 제 2 렌즈 기판부(12a)에는 제 2 커넥터부(Second Connector Part, 12c)가 배치될 수 있다. 제 2 커넥터부(12c)는 제 2 렌즈부(12b)에 의해 촬영된 영상 데이터를 카메라 구동부로 전송하기 위한 제 2 케이블부(Second Cable Part, 194)와 전기적으로 연결될 수 있다. 카메라 구동부는 제 1 렌즈부(11b) 및/또는 제 2 렌즈부(12b)가 촬영한 영상 데이터를 수신할 수 있다. 이를 위해, 카메라 구동부는 제 3 커넥터부(Third Connector Part, 191) 및 제 4 커넥터부(Fourth Connector Part, 192)를 포함할 수 있다. 제 3 커넥터부은 제 1 케이블부와 전기적으로 연결되고, 제 4 커넥터부은 제 2 케이블부와 전기적으로 연결될 수 있다. 카메라 구동부는 제 1 렌즈부(11b) 및/또는 제 2 렌즈부(12b)로부터 수신한 영상 데이터를 처리하여 영상 이미지를 생성할 수 있다. 카메라 구동부는 생성한 영상 이미지를 서버로 전송하는 것이 가능하다. 이를 위해, 도시하지는 않았지만, 카메라 구동부는 제 1 통신부를 포함할 수 있다. 도 21 내지 도 22를 살펴보면, 프레임부는 베이스부(Base Part, 400), 제 1 지지부(First Supporting Part, 410) 및 제 2 지지부(Second Supporting Part, 420)를 포함할 수 있다. 베이스부는 제 1 지지부 및 제 2 지지부을 위한 지지기반을 마련할 수 있다. 제 1 지지부는 제 1 렌즈 기판부(11a)에 대응되며 베이스부에 배치될 수 있다. 제 2 지지부는 제 2 렌즈 기판부(12a)에 대응되며 베이스부에 배치될 수 있다. 도 22에 나타나 있는 바와 같이, 베이스부는 제 1 경사면부(First Slope Part, 404) 및 제 2 경사면부 (Second Slope Part, 405)를 포함할 수 있다. 제 1 경사면부는 제 1 지지부에 대응될 수 있다. 즉, 제 1 지지부는 제 1 경사면부에 배 치될 수 있다. 제 2 경사면부는 제 2 지지부에 대응될 수 있다. 즉, 제 2 지지부는 제 2 경사면부에 배 치될 수 있다. 베이스부에 대해 보다 상세히 살펴보면 아래와 같다. 베이스부는 수평부분(Horizontal Part, 401), 제 1 수직부분(First Vertical Part, 402), 제 2 수직부분 (Second Vertical Part, 403), 제 1 경사면부 및 제 2 경사면부를 포함할 수 있다. 수평부분은 수평방향(제 1 방향(DR1) 또는 제 2 방향(DR2))으로 연장되는 부분을 포함할 수 있다. 수평부분은 도시하지는 않았지만 케이스부에 연결될 수 있다. 예를 들면, 수평부분은 바닥부 및/또는 중간부에 연결될 수 있다. 제 1 수직부분은 수평부분의 일측 끝단에서 제 3 방향(DR3)으로 연장될 수 있다. 제 2 수직부분은 수평부분의 타측 끝단에서 제 3 방향(DR3)으로 연장될 수 있다. 제 1 경사면부는 제 1 수직부분의 끝단에서 사선방향으로 연장될 수 있다. 제 2 경사면부는 제 2 수직부분의 끝단에서 사선방향으로 연장될 수 있다. 제 1 경사면부와 제 2 경사면부의 끝단은 서로 연결될 수 있다. 제 1 경사면부에는 제 1 지지부가 배치될 수 있다. 제 2 경사면부에는 제 2 지지부가 배치될 수 있다. 이러한 구성의 프레임부는 케이스부의 바닥부 및 중간부 중 적어도 하나에 연결될 수 있다. 예를 들면, 프레임부의 베이스부의 수평부분은 케이스부의 바닥부 및 중간부 중 적어도 하나에 연결될 수 있다. 도 23을 살펴보면, 프레임부의 베이스부는 개구부(Opening, OP)를 포함할 수 있다. 개구부(OP)는 베이스부의 제 1 경사면부와 제 2 경사면부의 사이에 위치할 수 있다. 이러한 개구부(OP)는 제 1 케이블부 및/또는 제 2 케이블부가 지나는 통로가 될 수 있다. 도 24를 살펴보면, 프레임부의 베이스부는 제 1 베이스부(400a)와 제 2 베이스부(400b)로 분할될 수 있다. 제 1 베이스부(400a)와 제 2 베이스부(400b)는 형태가 동일하거나 충분히 유사할 수 있다. 제 1 베이스부(400a)는 제 1 수평부분(401a), 제 1-1 수직부분(402a), 제 2-1 수직부분(403a), 제 1-1 경사면 부(404a) 및 제 2-1 경사면부(405a)를 포함할 수 있다. 제 2 베이스부(400b)는 제 2 수평부분(401b), 제 1-2 수직부분(402b), 제 2-2 수직부분(403b), 제 1-2 경사면 부(404b) 및 제 2-2 경사면부(405b)를 포함할 수 있다. 도 24와 도 22를 비교하면, 각 부분의 사이즈는 다를 수 있으나, 단면의 형태는 동일하거나 충분히 유사할 수 있다. 도 25를 살펴보면, 제 1 베이스부(400a)의 제 1-1 경사면부(404a)와 제 2 베이스부(400b)의 제 2-1 경사면부 (404b)에 제 1 지지부가 배치될 수 있다. 아울러, 제 1 베이스부(400a)의 제 1-2 경사면부(405a)와 제 2 베이스부(400b)의 제 2-2 경사면부(405b)에 제 2 지지부가 배치될 수 있다. 이러한 경우에는, 도 26에 나타나 있는 바와 같이, 분할된 제 1 베이스부(400a)와 제 2 베이스부(400b)의 사이 에 개구부(OP)가 마련되고, 개구부(OP)를 통해 제 1 케이블부 및/또는 제 2 케이블부가 지날 수 있다. 도 26을 살펴보면, 제 1 경사면부(제 1-1 경사면부(404a) 및/또는 제 1-2 경사면부(404b))의 폭(W2)은 제 1 지지부의 폭(W1)보다 더 클 수 있다. 아울러, 제 2 경사면부(제 2-1 경사면부(405a) 및/또는 제 2-2 경사면부(405b))의 폭은 제 2 지지부(42 0)의 폭보다 더 클 수 있다. 이러한 경우, 제 1 케이블부 및/또는 제 2 케이블부가 개구부(OP)를 보다 용이하게 통과할 수 있다. 아울러, 제 1 케이블부 및/또는 제 2 케이블부의 연결 작업을 위한 공간을 충분히 확보할 수 있어서 작업이 용이할 수 있다. 도 27을 살펴보면, 제 1 경사면부(제 1-1 경사면부(404a) 및/또는 제 1-2 경사면부(404b)) 상에서 제 1 지지부는 제 2 지지부와 충분히 멀리 떨어지도록 배치될 수 있다. 자세하게는, 제 1 지지부는 제 1 경사면부(제 1-1 경사면부(404a) 및/또는 제 1-2 경사면부(404b)) 와 제 1 수직부분(제 1-1 수직부분(402a) 및/또는 제 1-2 수직부분(402b))의 연결 부분에 인접하게 위치할 수 있다. 이에 따라, 제 1 경사면부(제 1-1 경사면부(404a) 및/또는 제 1-2 경사면부(404b)) 상에서, 제 1 지지부 와 제 1 수직부분(제 1-1 수직부분(402a) 및/또는 제 1-2 수직부분(402b)) 사이의 간격(W3)은 제 1 지지부와 제 2 경사면부(제 2-1 경사면부(405a) 및/또는 제 2-2 경사면부(405b)) 사이의 간격(W4)보 다 더 작을 수 있다. 여기서, W3은 실질적으로 0이 되는 경우도 가능할 수 있다. 이러한 구성은 제 2 지지부에도 동일하거나 충분히 유사하게 적용될 수 있다. 이러한 경우, 제 1 지지부와 제 2 지지부 사이에 충분한 공간을 확보할 수 있다. 도 28을 살펴보면, 제 1 지지부에는 제 1 렌즈부(11b)는 제 1 렌즈 기판부(11a)를 포함하는 제 1 카메라부 가 배치될 수 있다. 아울러, 제 2 지지부에는 제 2 렌즈부(12b)는 제 2 렌즈 기판부(12a)를 포함하는 제 2 카메라부가 배 치될 수 있다. 이처럼, 제 1, 2 지지부(410, 420)에 제 1, 2 카메라부(11, 12)를 설치하는 경우에는 제 1, 2 카메라부(11, 12)를 보다 용이하게 설치할 수 있다. 도 29를 살펴보면, 제 1 지지부는 측면의 일부가 함몰되어 형성된 제 1 함몰부(HW1)를 포함할 수 있다. 제 1 지지부에서 제 1 함몰부(HW1)는 제 2 지지부에 인접한 측면에 형성될 수 있다. 아울러, 제 2 지지부는 측면의 일부가 함몰되어 형성된 제 2 함몰부(HW2)를 포함할 수 있다. 제 2 지지부에서 제 2 함몰부(HW2)는 제 1 지지부에 인접한 측면에 형성될 수 있다. 이에 따라, 제 1 함몰부(HW1)와 제 2 함몰부(HW2)는 서로 마주보는 것이 가능하다. 도 30을 살펴보면, 제 1 지지부는 전면(Front Surface, FS)의 일부가 함몰되어 형성된 제 1 안착부(DeP 1)를 포함할 수 있다. 이러한 제 1 안착부(DeP1)는 제 1 함몰부(HW1)와 연결될 수 있다. 제 2 지지부는 전면(FS)의 일부가 함몰되어 형성된 제 2 안착부(DeP2)를 포함할 수 있다. 이러한 제 2 안착부(DeP2)는 제 2 함몰부(HW2)와 연결될 수 있다. 도 31을 살펴보면, 제 1 카메라부는 제 1 지지부의 제 1 안착부(DeP1)에 배치될 수 있다. 예를 들면, 제 1 카메라부의 제 1 렌즈 기판부(11a)는 제 1 지지부의 제 1 안착부(DeP1)에 배치되고, 스크류 등의 소정의 체결수단(미도시)에 의해 고정되는 것이 가능하다. 제 2 카메라부는 제 2 지지부의 제 2 안착부(DeP2)에 배치될 수 있다. 예를 들면, 제 2 카메라부의 제 2 렌즈 기판부(12a)는 제 2 지지부의 제 2 안착부(DeP2)에 배치되고, 스크류 등의 소정의 체결수단(미도시)에 의해 고정되는 것이 가능하다. 도 32를 살펴보면, 제 1 지지부의 제 1 안착부(DeP1)에 제 1 카메라부가 배치된 상태에서, 제 1 렌즈 부(11b)는 제 1 지지부보다 W5만큼 더 돌출될 수 있다. 아울러, 제 2 지지부의 제 2 안착부(DeP2)에 제 2 카메라부가 배치된 상태에서, 제 2 렌즈부(12b)는 제 2 지지부보다 더 돌출될 수 있다. 이러한 경우에는, 제 1, 2 카메라부(11, 12)를 충분히 안정적으로 배치할 수 있을 뿐만 아니라, 제 1, 2 렌즈부 (11a, 11b)가 보다 용이하게 주변의 영상을 촬영할 수 있다. 도 33을 살펴보면, 베이스부는 제 1 베이스부(400a)와 제 2 베이스부(400b)를 포함하고, 베이스부의 제 1, 2 경사면부(404, 405)에 제 1, 2 지지부(410, 420)가 배치되는 경우의 일례가 나타나 있다. 여기서, 제 1, 2 지지부(410, 420)는 제 1, 2 함몰부(HW1, HW2)와 제 1, 2 안착부(DeP1, DeP2)를 포함할 수 있 다. 이러한 상태에서 제 1 케이블부와 제 2 케이블부가 연결되는 경우의 일례가 도 34에 나타나 있다. 도 34를 살펴보면, 제 1 케이블부는 카메라 구동부의 제 3 커넥터부와 제 1 카메라부를 전 기적으로 연결할 수 있다. 아울러, 제 2 케이블부는 카메라 구동부의 제 4 커넥터부와 제 2 카메라부를 전기적으로 연 결할 수 있다. 베이스부의 수평부분의 상부에 카메라 구동부가 배치될 수 있다. 또는, 프레임부의 베이스부가 제 1 수평부분(401a)과 제 2 수평부분(401b)으로 분할되는 경우에는, 카 메라 구동부는 제 1 수평부분(401a)과 제 2 수평부분(401b)에 걸쳐 배치될 수 있다. 제 1 경사면부와 제 2 경사면부의 사이 각도(θ1)는 제 1 카메라부와 제 2 카메라부의 촬영 영역의 중첩(Overlap)과 연관될 수 있다. 자세하게는, 제 1 경사면부와 제 2 경사면부의 사이 각도(θ1)에 따라 제 1 카메라부의 제 1 렌 즈부(11b)가 향하는 방향과 제 2 카메라부의 제 2 렌즈부(12b)가 향하는 방향은 서로 다를 수 있다. 여기서, 제 1 경사면부와 제 2 경사면부의 사이 각도(θ1)는 180°(도)보다 더 작을 수 있다. 예를 들면, 제 1 경사면부와 제 2 경사면부의 사이 각도(θ1)는 45°(도) 이상 135°(도)이하일 수 있다. 도 35에는 본 발명에 따른 카메라 모듈의 단면의 형태의 일례가 나타나 있다. 도 35를 살펴보면, 프레임부의 제 1 경사면부와 제 2 경사면부는 수직방향(제 3 방향(DR3))으로 중간부보다 더 돌출될 수 있다. 이를 위해, 프레임부의 제 1 수직부분 및 제 2 수직부분은 수직방향(제 3 방향(DR3))으로 중간부 보다 더 연장되는 부분을 포함할 수 있다. 이에 따라, 프레임부의 제 1 경사면부와 제 2 경사면부는 중간부에 의해 가려지지 않을 수 있다. 이로 인해, 제 1 카메라부 및 제 2 카메라부도 중간부보다 수직방향(제 3 방향(DR3))으로 더 돌출 될 수 있다. 이러한 경우, 제 1 카메라부 및 제 2 카메라부의 효과적인 영상 촬영이 가능할 수 있다. 이상에서 상세히 설명한 카메라 모듈을 스마트 폴(SP)에 적용하면 넓은 영역의 영상을 획득할 수 있다. 아울러, 하나의 스마트 폴(SP)에 다수의 카메라를 설치하지 않아도 되기 때문에 스마트 폴(SP)의 구조를 단순화 할 수 있다."}
{"patent_id": "10-2021-0175549", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이와 같이, 상술한 본 발명의 기술적 구성은 본 발명이 속하는 기술분야의 당업자가 본 발명의 그 기술적 사상 이나 필수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해되어야 하고, 본 발명의 범위는 전술한 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범 위의 의미 및 범위 그리고 그 등가개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함 되는 것으로 해석되어야 한다."}
{"patent_id": "10-2021-0175549", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 3은 본 발명에 따른 스마트 폴과 인공지능을 이용한 위험상황 정보 처리장치에 대해 설명하기 위 한 도면이다. 도 4 내지 도 5는 설정모드에 대해 설명하기 위한 도면이다. 도 6 내지 도 17은 위험상황을 감지하는 방법 및 그에 관련된 내용을 설명하기 위한 도면이다. 도 18 내지 도 35는 카메라 모듈에 대해 설명하기 위한 도면이다."}
