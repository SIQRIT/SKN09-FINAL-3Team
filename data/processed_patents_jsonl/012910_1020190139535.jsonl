{"patent_id": "10-2019-0139535", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0088204", "출원번호": "10-2019-0139535", "발명의 명칭": "안저영상 자동판독을 위한 딥러닝 아키텍처 시스템 및 딥러닝 아키텍쳐 시스템을 이용한 안저", "출원인": "주식회사 에이아이인사이트", "발명자": "박건형"}}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "안저이미지의 특징 추출(feature extraction)을 수행하는 다수 개의 콘볼루션레이어와 연산량을 줄이기 위해 서브샘플링을 수행하는 한 개의 풀링레이어로 구성되는 특징추출레이어 세트가 적어도 한 개 이상 직렬로 배치한다수개의 합성곱신경망(convolutional neural network, CNN) 아키텍처에서 공통 부분을 하나로 묶은 트렁크모듈(100);다수개로 마련되어 상기 트렁크모듈(100)에서 각각의 아키텍처를 생성하여 상기 트렁크모듈(100)의 아웃풋을 전달받아 상기 안저이미지에 대한 병변을 식별하여 해당하는 병명을 진단하는 브랜치모듈(200);다수개의 상기 브랜치모듈(200) 중 어느 하나의 브랜치모듈(200)과 상기 트렁크모듈(100)을 연결한 아키텍처인섹션(110);상기 트렁크모듈(100) 중 특정 레이어의 아웃풋을 상기 브랜치모듈(200)로 전달하여, 상기 트렁크모듈(100)과상기 브랜치모듈(200)을 연결시키는 루트레이어(120); 및다수개로 마련된 상기 브랜치모듈(200)로부터 진단된 데이터를 통합하여 최종 질환명을 결정하여 출력하는 최종확진부(300);를 포함하되,상기 브랜치모듈(200)은,의사의 차팅 과정에서 매칭된 질병명 또는 질병코드로 학습데이터를 생성하여 질병의 카테고리를 유추하는 질병유추부(210);상기 안저이미지에서 시각신경원반(Optic nerve head, ONH)를 찾고 이에 대한 맹점비율(vertical cup-to-discratio, VCDR)을 분류하고 시신경유두(disc) 및 황반(macula)의 위치를 탐색하는 위치탐색부(220);질병을 구성하는 요소가 되는 주요 병변(key lesion)을 찾는 주요병변검출부(230); 및상기 안저이미지에서 미세 병변을 검출하는 미세병변검출부(240);로 구성되는 것을 특징으로 하는 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 질병유추부(210)의 Dense2 레이어는 시그모이드 함수(sigmoid function)을 사용하여, 질병의 카테고리 별로 독립적으로 0~1 사이의 값으로 득점(scoring)하는 것을 특징으로 하는 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 질병유추부(210)의 결과값은,최종 자식노드의 수와 일치하는 것을 특징으로 하는 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,공개특허 10-2020-0088204-3-상기 질병유추부(210)와 상기 트렁크모듈(100)을 연결한 섹션(110)을 훈련할 때 발생된 제1손실(lossb1)은 [수학식 1]에 의해 수행되는 것을 특징으로 하는 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템 :[수학식 1](여기서, P1i는 훈련을 통해 i번째 카테고리에 질병이 속할 가능성을 0~1 사이의 값으로 출력, T1i는 사람 의사가 라벨링한 데이터값으로 i번째 카테고리의 질병에 속하면 1이고 그렇지 않으면 0)."}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 제1손실(lossb1)에서 사람 의사의 질병 라벨링이 마지막 자식 노드까지 분류되지 않고, 부모 노드에서 끝난경우 상기 Ti값은 같은 부모 노드에 소속된 자식 노드 수의 평균인 것을 특징으로 하는 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 질병유추부(210)의 학습데이터에 의한 라벨링은,한 사람이 여러 가지 질병을 동시에 가질 수 있는 중복성,질병의 카테고리는 계층적으로 분류되는 계층성, 및진단된 병변의 하위 분류는 상호배타적인 배타성에 의해 수행되는 것을 특징으로 하는 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서,상기 주요병변검출부(230)는,상기 안저이미지의 화질을 분류하여 화질분류결과값을 출력하고, 상기 안저이미지의 화질이 나빠 상기 주요 병변(key lesion)의 검출 신뢰도가 낮을 것으로 판단된 경우 상기 화질분류결과값을 출력하지 않는 것을 특징으로 하는 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항에 있어서,상기 주요병변검출부(230) 상기 트렁크모듈(100)을 연결한 섹션(110)을 훈련할 때 발생된 제2손실(lossb2)은 [수학식 2]에 의해 수행되는 것을 특징으로 하는 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템 :공개특허 10-2020-0088204-4-[수학식 2](여기서, qi는 훈련을 통해 출력한 각 화질을 5개로 분류하여 라벨링한 득점값(scoring), Qi는 사람 의사가 화질을 2개로 분류하여 라벨링한 득점값(scoring)으로 보통으로 라벨링된 경우 득점값은 1이고 나머지는 0, W는 화질별 가중치로 매우좋음/좋음/보통/나쁨/매우나쁨 = 1.0/0.75/0.5/0.25/0, P2i는 N개의 주요 병변(key lesion)별로 훈련을 통해 출력한 득점값(scoring),T2i는 사람 의사가 주요 병변(key lesion)별로 라벨링한 득점값(scoring)으로 병변이 존재하여 1이고 없으면0)."}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1항에 있어서,상기 미세병변검출부(240)는,상기 안저이미지에서 검출된 병변을 2개로 분류하여 라벨링하되,검출된 병변의 개수만큼 (라벨명, X좌표, Y좌표, 신뢰수준(Confidence level)) 형태로 출력하는 것을 특징으로하는 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1항에 있어서,상기 최종확진부(300)는,N개의 질병에 대해 질병의 존재 유무값을 출력하되,상기 N개의 질병에 대한 입력값은 상기 브랜치모듈(200)로부터 출력된 값으로,상기 질병유추부(210)는 N1개의 질병 카테고리 별 득점값(scoring)이고,상기 위치탐색부(220)는 상기 맹점비율(vertical cup-to-disc ratio, VCDR)값이고,상기 주요병변검출부(230)는 N2개의 상기 주요 병변(key lesion) 득점값(scoring)이고,상기 미세병변검출부(240)는 상기 검출된 병변의 라벨링값에 해당하는 신뢰 수준(confidence level)의 합(Csum)과 상기 신뢰 수준(confidence level)의 개수(N3)인 것을 특징으로 하는 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템."}
{"patent_id": "10-2019-0139535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서,상기 위치탐색부(220)에서 상기 시신경유두(disc)가 2개 이상 검출된 경우,아래 [수학식 3]에 의해 계산된 VCDRt값을 사용하는 것을 특징으로 하는 안저영상 자동판독을 위한 딥러닝 아키공개특허 10-2020-0088204-5-텍처 시스템 :[수학식 3](여기서, VCDRi는 검출된 각각의 VCDR값, Ci는 검출된 각각의 VCDR에 대한 신뢰 수준(confidence level) 값)."}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 안저영상 자동판독을 위한 알고리즘에 관한 것으로, 안과 의사가 의학지식을 습득하는 것과 유사한 방 식으로 인공지능을 훈련하고 판독하여 학습을 위한 데이터 요구량을 최소화할 수 있는 안저영상 자동판독을 위한 딥러닝 아키텍처에 관한 것이다. (뒷면에 계속)"}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 안저영상 자동판독을 위한 알고리즘에 관한 것으로, 안과 의사가 의학지식을 습득하는 것과 유사한 방식으로 인공지능을 훈련하고 판독하여 학습을 위한 데이터 요구량을 최소화할 수 있는 안저영상 자동판독을 위한 딥러닝 아키텍처에 관한 것이다."}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "구글이 최근 2016년도에 발표한 당뇨망막병증 자동판독에 관한 논문에 의하면 당뇨망막병증 1개를 판단하기 위 하여 의사 50여명이 작성한 10만여개의 학습데이터를 필요로 했다. 결과적으로는 좋은 성과를 보였지만, 단점은 질병 1개를 학습시키기 위하여 너무 많은 노력이 필요하다는 것이었다. 반면 사람의 경우 안과 전문의가 될 때 까지 학습하는 안저사진의 양은 그보다 훨씬 적다. 따라서 사람의사가 판독하는 방식과 유사하게 인공지능을 구 성하게 되면 필요한 학습데이터의 양을 크게 감축시킬 수 있다는데 착안하여 이와 같은 알고리즘을 고안하게 되 었다. 사람 의사의 경우 의료영상을 보고 판독할 때 이미지 전체를 직관적으로 대략 살펴보고 큰 질병 카테고리를 유 추한다. 이후 사진을 확대하여 자세히 살펴보며 의학교과서에 기술된 질병의 진단에 필수적인 병변들을 찾아내 어 확진을 하게 된다. 이러한 과정을 곰곰이 되짚어 보게 되면, 사람의사는 전체적인 윤곽을 직관적으로 인식하 는 하나의 지식을 가지고 있는 것으로 보이고, 여기에 개별 병변을 각각 인식하는 또 다른 지식 체계를 가지고 있는 것으로 생각된다. 즉 전체를 보는 지식 branch, 병변을 보는 branch 로 구성되어 있어 이를 응용하여 알고 리즘화 하여 인공지능에 적용한다면 학습데이터량을 줄일 수 있을 것으로 판단된다. 한편, 최근 영상인식 분야에 비약적인 발전을 가져온 딥러닝 신경망은 합성곱신경망 (convolutional neural network, CNN) 이다. 합성곱신경망은 맨 처음 입력 이미지 데이터에 계속해서 반복적으로 filter 를 합성곱 하 여 다음 단계의 레이어에 전달하는 것을 특징으로 한다. 합성곱신경망 아키텍처는 초기 AlexNet에서 시작하여 구글의 LeNet, Inception, Skip connection을 특징으로 하는 ResNet 등이 있다. 이들은 서로 다른 아키텍처이 지만, 공통적으로 합성곱(convolution)을 수직으로 쌓아가며 전역 특징(global feature)을 추출해내는 특징 추 출(feature extraction) 부분과 판단을 내리는 분류 층(classification layer)으로 구성되어 있다. 인공신경망 은 degradation problem이라 하여 레이어가 깊어질수록 앞쪽의 정보가 뒤쪽으로 잘 전달되지 않고 희석되는 문 제가 있다. 이는 학습과정에서 역전파가 일어날 때에도 마찬가지이며, 오차의 역전파 과정에서 앞쪽으로 되돌아 갈수록 오차가 거의 전달되지 않아 학습이 이루어 지지 않아 신경망의 가중치 값들이 거의 업데이트 되지 않는 다. 오차의 역전파 과정에서 앞쪽 레이어가 잘 학습되지 않는 문제를 vanishing gradient problem이라고도 한다. 따라서 본 발명은 이러한 문제점을 해결하고 오히려 이러한 인공신경망의 특징을 역으로 이용하여 신경망 전체 를 처음부터 학습시키지 않고 상대적으로 얼마 되지 않는 병목(bottleneck) 부분만 빠르게 학습시키는 방법을 통해 적은 양의 데이터로 학습이 가능하고, 의료 영상 중 안저 영상의 특징을 이용하여 안저 영상을 자동으로 판독할 수 있는 안저영상 자동판독을 위한 위한 딥러닝 아키텍처 시스템을 제공하고자 한다. 선행기술문헌 특허문헌 (특허문헌 0001) (비특허문헌 0001) Varun Gulshan, PhD; Lily Peng, MD, PhD; Marc Coram, PhD; et al. “ Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs”December 13, 2016, JAMA. 2016;316:2402-2410. doi:10.1001/jama.2016.17216"}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기의 문제점을 해결하기 위해서 안출된 것으로서, 본 발명의 목적은 안저 영상 학습을 위한 데이터 요구량을 최소화 하고 안과 의사가 의학지식을 습득하는 것과 비슷한 방식으로 인공지능을 훈련하여 안저 영상 을 자동판독할 수 있는 알고리즘을 제공하는 것이다. 발명이 해결하고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템은 안저이미지의 특징 추출(feature extraction)을 수행하는 다수 개의 콘볼루션레이어와 연산량을 줄이기 위해 서브샘플링을 수행하는 한 개의 풀 링레이어로 구성되는 특징추출레이어 세트가 적어도 한 개 이상 직렬로 배치한 다수개의 합성곱신경망 (convolutional neural network, CNN) 아키텍처에서 공통 부분을 하나로 묶은 트렁크모듈; 다수개로 마련되어 상기 트렁크모듈에서 각각의 아키텍처를 생성하여 상기 트렁크모듈의 아웃풋을 전 달받아 상기 안저이미지에 대한 병변을 식별하여 해당하는 병명을 진단하는 브랜치모듈; 다수개의 상기 브랜치모듈 중 어느 하나의 브랜치모듈과 상기 트렁크모듈을 연결한 아키텍처인 섹션; 상기 트렁크모듈 중 특정 레이어의 아웃풋을 상기 브랜치모듈로 전달하여, 상기 트렁크모듈과 상기 브랜치모듈을 연결시키는 루트레이어; 및 다수개로 마련된 상기 브랜치모듈로부터 진단된 데이터를 통합하여 최종 질환명을 결정하여 출력하는 최종 확진부;로 구성되는 것을 특징으로 한다."}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 과제의 해결 수단에 의해, 본 발명은 안저 영상 학습을 위한 데이터 요구량을 최소화하여 안저 영상을 효 과적으로 자동 판독할 수 있는 알고리즘을 제공할 수 있다. 또한, 본 발명은 계급에 따른 혼합 분류를 통해 의학용어의 분류체계를 반영할 수 있는 알고리즘을 제공할 수 있다. 또한, 본 발명은 작은 사이즈의 병변에 적합하게 미세 조정된 검출부를 마련하여 안저 영상에서 병변 확인을 용 이하게 할 수 있다. 또한, 본 발명은 브랜치모듈 별로 각각 개별적인 훈련 할 수 있으면서, 전체 시스템에 영향을 미치지 않고 필요 에 따라 일부분만 훈련 할 수 있는 효과가 있다.또한, 본 발명은 공통 부분이 축약되므로 컴퓨팅의 연산요구량과 저장요구량을 동시에 감소시킬 수 있다. 또한, 본 발명은 안저 이미지의 카테고리를 분류하는 분류(classifier)하는 브랜치(branch)와 안저 이미지 내에 특정 관심 병변을 찾는 객체 탐지(object detector) 브랜치(branch)와 같이 서로 다른 기능을 하는 아키텍쳐의 장점을 각각 살리면서 하나의 아키텍처처럼 사용할 수 있다. 또한, 본 발명은 어떤 변화가 생겨 신경망을 재학습 시켜야 할 필요가 있을 때, 전체를 다시 학습시키는 것이 아니라 필요한 부분(branch)만 학습시킬 수 있다. 또한, 본 발명은 신경망을 학습시키기 위해 [이미지+라벨]의 훈련 세트를 준비할 때, 필요한 만큼 진단명만 따 로 라벨링하고, 필요한 만큼 병변만 라벨링 하게 되어 각각의 브랜치 별로 따로 라벨을 구성할 수 있어 효율적 이다. 또한, 본 발명은 전체 신경망의 기능 중 개별 기능만 따로 필요한 경우 섹션(section)만 분리하여 그 기능만 따 로 사용할 수 있으므로 특정 기능을 이용하기 위해 아키텍처 전체를 사용하지 않으므로 효율적이다. 또한, 본 발명은 이미 신경망을 훈련 한 후 새로운 라벨 리스트와 라벨된 데이터가 준비되었을 경우 그것을 처 리하는 브랜치만을 하나 더 추가하여 신경망에 새로운 기능을 만들 수 있으므로, 새로운 기능을 추가하기 용이 하다. 또한, 본 발명은 개별의 아키텍처를 각각 실행한 것에 비해 속도가 빠른 효과가 있다."}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 발명의 전반 에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 “포함”한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다."}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명에 대한 해결하고자 하는 과제, 과제의 해결 수단, 발명의 효과를 포함한 구체적인 사항들은 다음에 기 재할 실시 예 및 도면들에 포함되어 있다. 본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 이하, 첨부된 도면을 참조하여 본 발명을 보다 상세히 설명하기로 한다. 본 발명은 학습을 위한 데이터 요구량을 최소화하고, 안과 의사가 의학지식을 습득하는 것과 최대한 비슷한 방 식으로 인공지능을 훈련하고, 판독하는 것을 특징으로 한다. 본 발명은 기존 특허를 제출한 HydraNet(출원번호 10-2018-0133415) 기법을 이용하여 안과 영상 판독에 최적화시켜 구조를 설계한 새로운 아키텍쳐이다. 안과의사가 안저 이미지를 판독할 때 대부분 3단계를 거처서 판독을 한다. 즉, 첫째로, 사진의 전체적인 모습 을 보고 질병의 대략적인 카테고리를 유추한다. 그 다음, 둘째로, 특정 망막 질환을 확진하기 위한 의학 교과서 의 특징적인 병변을 자세히 들여다보며 찾게 된다. 이 과정에서 병변을 찾게 되면 확진 및 질병의 중증도를 grading하게 된다. 세번째 과정은 녹내장성 변화를 유추하기 위해, 시신경 유두를 판독하여 녹내장의 특징적인 요소인 cup-to-disc ratio, disc hemorrhage, RNFL defect, LDS (lamina dot sign)등을 찾게 된다. 이러한 3단계의 질병 유추 과정은 실제 진료환경과도 밀접한 연관이 있다. 즉 안저 사진의 카테고리 유추과정 은 진료기록상 진단명 코드, 혹은 평가(assessment) 항목에 일반적으로 차팅이 되어 있다. 따라서 차트 데이터 베이스를 통해 대량의 학습데이터셋을 쉽게 구할 수 있다. 또한 망막질환과 녹내장 진단은 같은 안저 사진임에 도 불구하고, 중점적으로 관찰하는 위치가 다를 뿐 아니라, 의사의 전문영역이 분리되어 있기도 하다. 즉 망막 전문의사, 녹내장 전문의사 이렇게 물리적으로 분리되어 있기 때문에, 서로간의 차팅 방식도 다르고, 외래 환자 군도 다르며, 정밀 진단기기도 서로 다르다. 이는 망막과 녹내장 간에 학습을 위한 데이터가 서로 분리되어 있 을 가능성이 많고, 학습데이터의 양이나 분류 방식이 다를 수 있음을 뜻한다. 이 과정을 딥러닝으로 유사하게 구현하려면, 질병의 대략적인 분류를 위한 분류부(classifier), 망막병변용 및 시신경유두용의 병변을 찾는 두개의 검출부(detector)가 동시에 필요하다. 하나의 안저 사진 분석 및 훈련을 위 해 3가지 서로 다른 아키텍처의 공통부분을 융합하고, 다른 부분을 브랜치(branch)로 분리한 뒤, 안과의 현실세 계에 적합하게 설계되었다. 또한 본 발명은 상기 분류부(classifier)의 경우 중복성/계층성/배타성을 동시에 만 족해야만 하는 복잡한 의학용어 체계를 잘 반영할 수 있도록 새롭게 설계되었다. 본 발명의 핵심 특징은 1) 질 병 카테고리 유추부(classifier) 2) 시신경유두 및 황반을 검출하는 위치 탐색부(optic nerve head localizer), 3) 주요병변 검출부(key lesion finder), 4) 미세병변 검출부(small sized lesion finder)를 상기 HydraNet와 혼합된 것이라고 할 수 있다. 따라서 본 발명은, 도 2에 나타난 바와 같이, 크게 트렁크모듈, 브랜치모듈 및 최종확진부로 구 성되며 상기 브랜치모듈은 질병유추부, 위치탐색부, 주요병변검출부 및 미세병변검출부 로 구성된다. 이하 본 발명인 안저영상 자동판독을 위한 딥러닝 아키텍쳐 시스템을 Grem으로 명명한다. 1. 트렁크모듈(Trunk, 100) 트렁크모듈은 안저이미지의 특징 추출(feature extraction)을 수행하는 다수 개의 콘볼루션레이어와 연산 량을 줄이기 위해 서브샘플링을 수행하는 한 개의 풀링레이어로 구성되는 특징추출레이어 세트가 적어도 한 개 이상 직렬로 배치한 다수개의 합성곱신경망(convolutional neural network, CNN) 아키텍처에서 공통 부분을 하 나로 묶은 아키텍쳐이다. 상기 트렁크모듈은 합성곱신경망(convolutional neural network, CNN)을 이용하여 안저 영상의 특징 추출 (feature extraction)을 위한 공통 레이어(common layer)이다. 본 발명의 트렁크모듈 아키텍처는 작은 물 체 검출이 잘 되지 않는 문제를 해결하기 위해 입력 해상도를 높였다. 일반적으로 입력해상도와 콘볼루션 (convolution) 레이어의 수를 늘리게 되면 인공신경망의 정확도가 높아지는 것으로 알려져 있지만, 그렇다고 무 작정 늘리게 되면 메모리 한계를 초과하고 계산속도가 느려지기 때문에 어느 정도 최적화된 점이 필요하다. 따라서 본 발명에서 입력 해상도는 640x640을 택하는데, 그 이유는 첫째, 상기 브랜치모듈에서 검출하게 되는 최소 그리드(grid)의 크기(size)가 32x32의 크기가 되기 때문이며, 둘째 안저이미지에서 미세출혈과 같은 작은 병변도 대부분 이정도 그리드(grid)안에 1~2개 정도밖에 포함되지 않으므로 적절한 크기가 되기 때문이다. 또한 실험을 통하여 종래 사용하는 YOLO 아키텍처의 해상도가 높아짐에 따라 녹내장 검출 능력이 좋아지는 것을 확인하였으며, 그것이 640 해상도 이상에서는 크게 진전되지 않았기 때문에, 640 해상도가 녹내장을 검출하는데 도 최적이라고 판단해서이다. 표 1은 상기 트렁크모듈에서 합성곱신경망(convolutional neural network, CNN)을 이용하여 안저 영상의 특징 추출을 위한 일반적인 레이어(common layer)를 나타내었다. 표 1 Layer RepeatFiltersSizeStride Input Output Convolution0 1 323x3 1 640x640x3 640x640x32 Convolution1 643x3 2 640x640x32 320x320x64 Convolution2 321x1 1 320x320x64 320x320x32 Convolution3 643x3 1 320x320x32 320x320x64 Shortcut0 = add (conv2, conv3)320x320x64 320x320x64 Convolution4 x4 1283x3 2 320x320x64 160x160x128 Convolution5 641x1 1 160x160x128 160x160x64 Convolution6 1283x3 1 160x160x64 160x160x128 Shortcut1 = add (conv5, conv6)160x160x128 160x160x128 Convolution7 x8 2563x3 2 160x160x128 80x80x256 Convolution8 1281x1 1 80x80x256 80x80x128 Convolution9 2563x3 1 80x80x128 80x80x256 Shortcut2 = add (conv8, conv9)80x80x256 80x80x256 Convolution10 x8 5123x3 2 80x80x256 40x40x512 Convolution11 2561x1 1 40x40x512 40x40x256 Convolution12 5123x3 1 40x40x256 40x40x512 Shortcut3 = add (conv11, conv12)40x40x512 40x40x512 Convolution13 x4 10243x3 2 40x40x512 20x20x1024 Convolution14 5121x1 1 20x20x1024 20x20x512 Convolution15 10243x3 1 20x20x512 20x20x1024 Shortcut4 = add (conv14, conv15)20x20x1024 20x20x1024 또한, 섹션은 다수개의 상기 브랜치모듈 중 어느 하나의 브랜치모듈과 상기 트렁크모듈을 연결한 아키텍처이다. 한 개의 상기 브랜치모듈과 상기 트렁크모듈이 결합되어 각 질병마다 하나의 섹션을 이룰 수 있고, 새로운 기능을 이용하는 경우에, 다수 개의 섹션 중 해당하는 섹션만을 사용하여 연산할 수 있도록 구성되어 연산요구량과 저장요구량을 동시에 감소시킬 수 있는 것이다. 다음으로, 루트레이어은 상기 트렁크모듈 중 특정 레이어의 아웃풋을 상기 브랜치모듈로 전달하 여, 상기 트렁크모듈과 상기 브랜치모듈을 연결시킨다. 본 발명인 Grem 아키텍처는 콘볼루션레이어와 풀링레이어로 구성되는 피쳐추추레이어세트가 적어도 한 개 이상 직렬로 배치되는 상기 트렁크모듈와 상기 트렁크모듈의 아웃풋을 전달받아 병명을 진단하는 상기 브랜치모듈 및 상기 트렁크모듈과 브랜 치모듈을 연결하는 상기 루트레이어로 구성된다. 2. 브랜치모듈(Branch, 200) 상기 브랜치모듈은 다수개로 마련되어 상기 트렁크모듈에서 각각의 아키텍처를 생성하여 상기 트렁크 모듈의 아웃풋을 전달받아 상기 안저이미지에 대한 병변을 식별하여 해당하는 병명을 진단한다. 상기 브랜치모듈은, 도 2에 나타난 바와 같이, 질병유추부, 위치탐색부, 주요병변검출부 및 미세병변검출부로 구성된다. 상기 질병유추부는 의사의 차팅 과정에서 매칭된 질병명 또는 질병코드로 학습데이터를 생성하여 질병의 카테고리를 유추한다. 상기 위치탐색부는 상기 안저이미지에서 시각신경원반(Optic nerve head, ONH)를 찾고 이에 대한 맹점비율 (vertical cup-to-disc ratio, VCDR)을 분류하고 시신경유두(disc) 및 황반(macula)의 위치를 탐색한다. 상기 주요병변검출부는 질병을 구성하는 요소가 되는 주요 병변(key lesion)을 찾는다. 상기 미세병변검출부는 상기 안저이미지에서 10x10 pixels 사이즈 미만의 작은 크기의 미세병변을 검출한 다. 2-1. 질병유추부 상기 질병유추부는 사진의 전체를 보고 질병 카테고리를 유추하는 역할을 한다. 이것은 사람 의사가 사진 을 보고 첫 인상을 얻는 인상획득(impression) 과정과 유사하다. 상기 질병유추부는 안저이미지 전체를 보 고 분류하는 카테고리 분류부(classifier)에 해당하며, 특정 병변의 위치를 탐색하지는 않는다. 상기 질병유추부의 학습데이터는 의사의 차팅 과정에서 질병명 혹은 질병코드와 1:1로 매칭시킬 수 있기 때문에, 대량의 데이터를 이미 차팅 되어 있는 데이터로부터 손쉽게 획득 할 수 있다. 이것은 인공지능의 개발 과정에서 상당한 노력과 비용이 드는 학습데이터를 구축하는데 있어 상당한 절감효과가 있음을 의미한다. 상기 질병유추부의 아키텍처는 다음과 같으며, 앞서 기술한 상기 트렁크모듈에 연결되는 첫 번째 가지가 된다. 표 2 Layer FiltersSizeStride Input Output Convolution0 5121x11 Shortcut4 output 20x20x512 Convolution1 10243x31 20x20x512 20x20x1024 Convolution2 5121x11 20x20x1024 20x20x512 Convolution3 10243x31 20x20x512 20x20x1024 Convolution4 5121x11 20x20x1024 20x20x512 Global Average Pooling 20x20x512 204800 Dense1 256 204800 256 Dense2 N1 256 N1 (여기서, N1은 상기 질병유추부에서 질병의 개수 이다.) [표 2]에서 마지막 Dense2 레이어의 활성화 함수는 시그모이드 함수(Sigmoid function)을 사용하여서, 각각의 질병 카테고리별로 0~1사이의 값을 독립적으로 가질 수 있도록 한다. 즉 사람의 질병은 반드시 1개만 가지라는 보장이 없으므로, 각각 0~1 사이의 값으로 독립적으로 득점값(scoring)으로 수행 한다. 또한, [표 2]에 나타난 바와 같이 Dense2 레이어에서 아웃풋 값의 개수가 N1임을 나타낸다. 또한, 상기 질병유추부와 상기 트렁크모듈을 연결한 섹션을 훈련할 때 발생된 제1손실(lossb1)은 [수학식 1]에 의해 수행된다. 보다 구체적으로, 상기 질병유추부의 훈련을 위한 손실 함수는 일반적으로 널리 사용되는 sum of squared error를 따른다. 즉, [표 2]에 예시된 바와 같이 질병 카테고리가 N1개인 경우 아래와 같이 계산한다. 수학식 1"}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "(여기서, P1i는 훈련을 통해 i번째 카테고리에 질병이 속할 가능성을 0~1 사이의 값으로 출력. T1i는 사람 의사 가 라벨링한 데이터값으로 i번째 카테고리의 질병에 속하면 1이고 그렇지 않으면 0) 다만, 한 가지 특이사항은 의학용어의 계층적 특성을 반영하기 위하여 사람의사의 질병의 라벨링이 마지막 자식 노드까지 분류되지 않고, 부모 노드에서 끝난 경우 T1i 값은 같은 부모 노드에 소속된 자식들의 수의 평균이 된 다. 예를 들어 특정 부모 노드에 소속된 자식 노드가 5개 있다고 하면, T1i는 부모 노드의 값인 1을 5등분하여 1/5 = 0.2 가 된다. 즉, 상기 질병유추부의 훈련 시 계층적 라벨링을 반영하기 위한 방법으로 이를 도식화 하여 도 3에 나타내었고 아래에 좀 더 자세히 설명하였다. 상기 질병유추부의 훈련은 의학 용어의 계층적 특성을 반영한 새로운 방식의 결과 해석 방법을 사용한다. 안과 질환을 비롯하여 대부분의 질병은 계층구조가 있고, 하위 계층에서는 배타적이 된다. 즉 부모 노드에서는 중첩될 수 있는 특성이 있고, 자식 노드에서는 배타성을 가진다. 중복성이 있다는 것은, 한 사람이 여러가지 질 병을 동시에 가질 수 있다는 것이며, 질병의 분류는 계층적이고, 진단된 질병의 하위 분류는 배타성을 가진다. 즉, 상기 질병유추부의 학습데이터에 의한 라벨링은 한 사람이 여러 가지 질병을 동시에 가질 수 있는 중 복성, 질병의 카테고리는 계층적으로 분류되는 계층성, 및 진단된 병변의 하위 분류는 상호배타적인 배타성에 의해 수행된다. 예를 들면 안과 질환에서 당뇨망막병증과 정맥폐쇄는 한 사람에게 동시에 존재할 수 있도 있고 하나씩만 존재할 수도 있는 질환이다. 즉 상호배타적이지 못하고 중복성이 있다. 혈관폐쇄에는 세부적으로 부분혈관폐쇄(branch retinal vein obstruction)과 중심혈관폐쇄(central retinal vein obstruction)로 분류되며, 당뇨망막병증은 다시 증식성/비증식성으로 분류되며, 비증식성은 다시 초기/중기/말기 로 분류되는 계층성이 있다. 도 3에 나타난 바와 같이, 질병의 분류는 N2, N8 레벨에서는 중첩될 수 있으나, 그보다 하위 분류에서는 중첩될 수 없다. 즉, 상호 배타적이다. 이는 안과질환 뿐 아니라, 대부분의 질병 분류에서도 마찬가지다. 질병단위 (disease entity)끼리는 중첩될 수 있으나, 하나의 질병 내에서 세부 분류는 중첩되지 않는 것이다. 본 발명의 상기 질병유추부의 출력 수는 마지막 최종 자식노드의 수와 일치하지만, 그 훈련 시의 해석은 계층구조를 따른다. 즉, 도 3의 예에서는 상기 질병유추부의 마지막 Dense2 레이어의 출력 수는 녹색으로 도식화된 최종 자식 노드 (N3, N5, N6, N7. N9, N10) 의 6개가 된다. 의사의 차팅 (ground truth)에는 진단의 확신 정도에 따라 부모 노드 분류 (N2, N8) 만 되어있는 경우도 있고, 좀 더 확실한 경우 세부 분류까지 완료되 어 그 이하까지 진단되어 있는 경우도 있다. 앞서 설명한바와 같이, 상기 부모노드에서 더 이상 세분화되지 않고 의사의 라벨링이 종료되어 있는 경우, 훈 련 시의 T1i를 계산하기 위해서 그 부모노드에 소속된 모든 자식노드의 수만큼 상기 부모노드의 값인 1을 나눈 것을 T1i 로 사용한다. 예를 들어, 어떤 안저이미지의 최종 진단이 N2로 되어 있는 경우, 그 노드에 소속된 녹 색의 자식노드는 N3, N5, N6, N7 4개이므로 1/4 = 0.25 가 N3, N5, N6, N7 의 T1i 값에 해당하며 상기 제1손실 (lossb1) 함수의 계산에 사용되게 된다. 2-2. 위치탐색부 상기 위치탐색부는 안저 이미지에서 가장 뚜렷한 구조물인 시각신경원반(Optic nerve head, ONH)를 찾고 이에 대한 맹점비율(vertical cup-to-disc ratio, VCDR)을 분류하고 시신경유두(disc) 및 황반(macula)의 위치 를 탐색하는 계층이다. 이렇게 찾아진 시신경유두(disc)의 위치를 토대로 안저 이미지의 좌안/우안 분류, 녹내 장 가능성의 추론 등을 하게 된다. 상기 위치탐색부는 종래 기술인 YOLO V3의 디텍션 레이어(detection layer) 아키텍처를 이용한다. 표 3 Layer FiltersSizeStride Input Output Grid Convolution05121x1 1 Shortcut4 output 20x20x512 Convolution110243x3 1 20x20x512 20x20x1024 Convolution25121x1 1 20x20x1024 20x20x512 Convolution310243x3 1 20x20x512 20x20x1024 Convolution45121x1 1 20x20x1024 20x20x512 Convolution510243x3 1 20x20x512 20x20x1024 Convolution6N 1x1 1 20x20x1024 20x20xN 20x20 YOLO1 Convolution72561x1 1 Convolution4 20x20x256 Up sample 2x 20x20x256 40x40x256 Concat0 40x40x256,Shortcut3 40x40x768 Convolution82561x1 1 40x40x768 40x40x256 Convolution95123x3 1 40x40x256 40x40x512 Convolution102561x1 1 40x40x512 40x40x256 Convolution115123x3 1 40x40x256 40x40x512 Convolution122561x1 1 40x40x512 40x40x256 Convolution135123x3 1 40x40x256 40x40x512 Convolution14 N 1x1 1 40x40x512 40x40xN 40x40 YOLO2 Convolution151281x1 1 Convolution12 40x40x128 Up sample 2x 40x40x128 80x80x128 Concat1 80x80x128,Shortcut2 80x80x384 Convolution161281x1 1 80x80x384 80x80x128 Convolution172563x3 1 80x80x128 80x80x256 Convolution181281x1 1 80x80x256 80x80x128 Convolution192563x3 1 80x80x128 80x80x256 Convolution201281x1 1 80x80x256 80x80x128 Convolution212563x3 1 80x80x128 80x80x256 Convolution22 N 1x1 1 80x80x256 80x80xN 80x80 YOLO3 (여기서, N은 YOLO V3 레이어 직전의 콘볼루션 레이어(convolution layer)의 필터 수로, 디텍션 하고자 하는 라 벨의 수를 k개라고 하면, N = 3 x (5 + k)이다.) 2-3. 주요병변검출부 상기 주요병변검출부는 질병을 구성하는 요소가 되는 주요 병변(key lesion)을 찾는다. 또한 부가적으로 사진 화질을 평가하여 입력된 안저이미지가 판독 가능한 정도의 화질인지 불가능한지를 판단하여, 만약 화질이 너무 나빠 판독 신뢰도가 대단히 떨어질 것으로 판단되면 결과를 출력하지 않도록 한다. 즉, 상기 안저이미지의 화질을 분류하여 화질분류결과값을 출력하고, 상기 안저이미지의 화질이 나빠 상기 주요 병변(key lesion)의 검 출 신뢰도가 낮을 것으로 판단된 경우 상기 화질분류결과값을 출력하지 않는다. 상기 주요병변검출부의 아키텍처 구조는 다음과 같다. 표 4 Layer FiltersSizeStride Input Output Convolution0 5121x11 Shortcut4 output 20x20x512 Convolution1 10243x31 20x20x512 20x20x1024 Convolution2 5121x11 20x20x1024 20x20x512 Convolution3 10243x31 20x20x512 20x20x1024 Convolution4 5121x11 20x20x1024 20x20x512 Global Average Pooling 20x20x512 204800 Dense1 256 204800 256 Dense2 N2 256 N2 (여기서, N2은 병변(key lesion)의 수이다.) 상기 주요병변검출부는 안저이지미의 화질분류와 주요 병변(key lesion)의 유무를 디텍션하며, 라벨링은 아래와 같다. 표 5 라벨명 설명 매우 좋음 모든 판독이 가능하며, 화질이 매우 좋음. 좋음 모든 판독이 가능하며, 판독이 대체로 틀림 없음. 보통 모든 판독 가능하나, 보통의 화질로 판독이 틀릴 가능성도 있음. 나쁨 화질이 좋지 않아 판독이 부분적으로만 가능함. 매우 나쁨 화질이 너무 나빠 판독이 아예 불가능함. Lesion 1 Lesion 2 Lesion 3 … … 상기 주요병변검출부 상기 트렁크모듈을 연결한 상기 섹션을 훈련할 때 발생된 제2손실(lossb2) 은 [수학식 2]에 의해 수행된다. 상기 제2손실(lossb2) 함수는 화질 분류 부분과, 주요 병변(key lesion) 탐색 부분의 합으로 이루어진다. 이때 상기 주요 병변(key lesion) 부분의 손실 함수는 weighted sum of squared error를 사용한다. 즉, 사람이 라벨링한 화질의 수준에 따라 손실 계산 시 가중치를 둔다. 가중치는 매우좋음/ 좋음/보통/나쁨/매우나쁨 = 1.0 / 0.75 / 0.5 / 0.25 / 0 이 되며, 화질이 매우 나쁠 경우 가중치가 0이 되어 주요 병변(key lesion)의 손실 값이 0이 되어 전파(back propagation)되지 않는다. 수학식 2"}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "(여기서, qi는 훈련을 통해 출력한 각 화질을 5개로 분류하여 라벨링한 득점값(scoring), Qi는 사람 의사가 화질 을 2개로 분류하여 라벨링한 득점값(scoring)으로 보통으로 라벨링된 경우 득점값은 1이고 나머지는 0, W는 화 질별 가중치로 매우좋음/좋음/보통/나쁨/매우나쁨 = 1.0/0.75/0.5/0.25/0, P2i는 N개의 주요 병변(key lesion) 별로 훈련을 통해 출력한 득점값(scoring), T2i는 사람 의사가 주요 병변(key lesion)별로 라벨링한 득점값 (scoring)으로 병변이 존재하여 1이고 없으면 0). 2-4. 미세병변검출부 상기 미세병변검출부는 안저 이미지에서 크기가 매우 작으나 매우 중요한 병변을 따로 검출하기 위해 설계 된 브랜치이며, 크게 빨간점(R), 노란점(Y) 두개의 라벨만을 갖는다. 상기 미세병변검출부의 출력형식은 발견된 병변의 개수만큼 (라벨명, X좌표, Y좌표, 신뢰수준(Confidence level)) 형태로 출력된다. 3. 최종확진부 본 발명인 Glem 아키텍처는 4개의 브랜치모듈를 갖는 HydraNet을 바탕으로 하며, 상기 4개의 브랜치모듈 의 출력을 통합하여 최종 진단명을 결정하여 출력하는 계층이다. 이 계층은 각각의 질환명 별로 Random forest(RF) 알고리즘을 사용한다. 즉 N개의 질병 각각 그 질병이 있다, 없다 을 출력으로 가지는 RF가 하 나씩 존재하는 구조이다. 상기 N개의 RF에 대한 입력 (도4 참고)은 모두 동일하며 아래와 같이 구성된다. ① 상기 질병유추부는 N1개의 질병 카테고리 별 득점값(scoring)이다. ② 상기 위치탐색부는 상기 맹점비율(vertical cup-to-disc ratio, VCDR)값으로, 상기 시신경유두(disc) 가 2개 이상 검출되었다면 아래 [수학식 3]에 의해 계산된 VCDRt값을 사용한다. 수학식 3"}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "(여기서, VCDRi는 검출된 각각의 VCDR값이며, Ci는 검출된 각각의 VCDR에 대한 신뢰 수준(confidence level) 값 으로 상기 YoLo 인공신경망이 출력한 값). ③ 상기 주요병변검출부는 상기 주요 병변(key lesion)의 개수인 N2개만큼의 득점값(scoring)이다. ④ 상기 미세병변검출부는 상기 미세병변검출부에서 출력한 레이블 (N3개) 별로 각각 찾아진 모든 점 들의 신뢰 수준(confidence level)의 합(Csum)과 그 개수(Nc)이다. 예를 들어 빨간점(R) 이라는 레이블에 해당하는 점을 5개 찾았다고 하면, Csum=C1+C2+C3+C4+C5이며, Nc는 5가 된 다. 위 4가지로 구성된 입력벡터를 도식화 하면 도 4에 나타난 바와 같다."}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "상기 과제의 해결 수단에 의해, 본 발명은 안저 영상 학습을 위한 데이터 요구량을 최소화하여 안저 영상을 효 과적으로 자동 판독할 수 있는 알고리즘을 제공할 수 있다. 또한, 본 발명은 계급에 따른 혼합 분류를 통해 의학용어의 분류체계를 반영할 수 있는 알고리즘을 제공할 수 있다. 또한, 본 발명은 작은 사이즈의 병변에 적합하게 미세 조정된 검출부를 마련하여 안저 영상에서 병변 확인을 용 이하게 할 수 있다. 또한, 본 발명은 브랜치모듈 별로 각각 개별적인 훈련 할 수 있으면서, 전체 시스템에 영향을 미치지 않고 필요 에 따라 일부분만 훈련 할 수 있는 효과가 있다. 또한, 본 발명은 공통 부분이 축약되므로 컴퓨팅의 연산요구량과 저장요구량을 동시에 감소시킬 수 있다. 또한, 본 발명은 안저 이미지의 카테고리를 분류하는 분류(classifier)하는 브랜치(branch)와 안저 이미지 내에 특정 관심 병변을 찾는 객체 탐지(object detector) 브랜치(branch)와 같이 서로 다른 기능을 하는 아키텍쳐의 장점을 각각 살리면서 하나의 아키텍처처럼 사용할 수 있다. 또한, 본 발명은 어떤 변화가 생겨 신경망을 재학습 시켜야 할 필요가 있을 때, 전체를 다시 학습시키는 것이 아니라 필요한 부분(branch)만 학습시킬 수 있다. 또한, 본 발명은 신경망을 학습시키기 위해 [이미지+라벨]의 훈련 세트를 준비할 때, 필요한 만큼 진단명만 따 로 라벨링하고, 필요한 만큼 병변만 라벨링 하게 되어 각각의 브랜치 별로 따로 라벨을 구성할 수 있어 효율적 이다. 또한, 본 발명은 전체 신경망의 기능 중 개별 기능만 따로 필요한 경우 섹션(section)만 분리하여 그 기능만 따 로 사용할 수 있으므로 특정 기능을 이용하기 위해 아키텍처 전체를 사용하지 않으므로 효율적이다. 또한, 본 발명은 이미 신경망을 훈련 한 후 새로운 라벨 리스트와 라벨된 데이터가 준비되었을 경우 그것을 처 리하는 브랜치만을 하나 더 추가하여 신경망에 새로운 기능을 만들 수 있으므로, 새로운 기능을 추가하기 용이 하다. 또한, 본 발명은 개별의 아키텍처를 각각 실행한 것에 비해 속도가 빠른 효과가 있다."}
{"patent_id": "10-2019-0139535", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이와 같이, 상술한 본 발명의 기술적 구성은 본 발명이 속하는 기술분야의 당업자가 본 발명의 그 기술적 사상 이나 필수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해되어야 하고, 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타나며, 특허청구범위의 의 미 및 범위 그리고 그 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2019-0139535", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 기본 아키텍쳐인 HydraNet을 나타낸 의료영상 자동판독을 위한 딥러닝 아키텍쳐 시스템의 구 성도이다. 도 2는 본 발명인 안저영상 자동판독을 위한 딥러닝 아키텍처 시스템(Glem)의 구성도이다. 도 3은 질병유추부에서 의학 용어의 특성을 반영한 방식의 분류(classification)를 도식화하여 나타낸 도 면이다. 도 4는 본 발명에 의해 실시되는 일실시예로, 브랜치모듈에서 출력되는 출력값(최종확진부에 입력되 는 입력값)을 나타내어 도식화한 도면이다."}
