{"patent_id": "10-2020-0128003", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0045366", "출원번호": "10-2020-0128003", "발명의 명칭": "인공지능 기반의 의료 영상 합성 장치 및 방법", "출원인": "고려대학교 산학협력단", "발명자": "안경식"}}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반의 의료 영상 합성 방법에 있어서,대상자가 제1자세를 취한 상태에서 상기 대상자의 소정의 부위를 촬영한 제1학습 영상을 수집하는 단계;상기 제1학습 영상에 기초하여, 상기 제1자세에 기반하여 촬영된 대상 영상이 입력되면 상기 대상 영상에 기초하여 대상자가 상기 제1자세와 상이한 제2자세를 취한 상태에서 촬영된 것처럼 모사되는 가상의 합성 영상을 생성하는 인공지능 모델을 학습시키는 단계;상기 제1자세에 기반하여 촬영된 상기 대상 영상을 수신하는 단계; 및상기 인공지능 모델에 기초하여 상기 대상 영상에 대응하는 상기 합성 영상을 생성하는 단계,를 포함하는, 의료 영상 합성 방법."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공지능 모델을 학습시키는 단계는,생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 상기 인공지능 모델을 학습시키는것인, 의료 영상 합성 방법."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,대상자가 상기 제2자세를 취한 상태에서 상기 소정의 부위를 촬영한 제2학습 영상을 수집하는 단계,를 더 포함하고,상기 인공지능 모델을 학습시키는 단계는,상기 제1학습 영상 및 상기 제2학습 영상에 기초하여 상기 생성적 대립 신경망(Generative AdversarialNetwork) 알고리즘을 적용하는 것인, 의료 영상 합성 방법."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 인공지능 모델을 학습시키는 단계는,상기 제1학습 영상에 기초하여 상기 제2자세에 대응하는 상기 합성 영상을 생성하고, 상기 합성 영상의 진위 여부를 상기 제2학습 영상에 기초하여 판별하는 것인, 의료 영상 합성 방법."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 인공지능 모델을 학습시키는 단계는,상기 제2학습 영상에 기초하여 상기 제1자세에 대응하는 제1모사 영상을 생성하는 제1생성기 및 상기 제1모사영상의 진위 여부를 판단하는 제1판별기를 통한 순방향(Forward) 학습을 수행하는 단계; 및상기 제1학습 영상에 기초하여 상기 제2자세에 대응하는 제2모사 영상을 생성하는 제2생성기 및 상기 제2모사영상의 진위 여부를 판단하는 제2판별기를 통한 역방향(Backward) 학습을 수행하는 단계,공개특허 10-2022-0045366-3-를 포함하는 것인, 의료 영상 합성 방법."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 순방향(Forward) 학습을 수행하는 단계는,상기 제2학습 영상과 상기 제1모사 영상 사이의 변화 정보 및 상기 소정의 부위의 기하학적 정보를 고려하여 수행되고,상기 역방향(Backward) 학습을 수행하는 단계는,상기 제1학습 영상과 상기 제2모사 영상 사이의 변화 정보 및 상기 기하학적 정보를 고려하여 수행되는 것인,의료 영상 합성 방법."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 소정의 부위는 척추 영역을 포함하고,상기 기하학적 정보는, 전만 정도, 척추뼈의 높이, 척추뼈 사이의 각도 및 디스크 형상 중 적어도 하나를 포함하는 것인, 의료 영상 합성 방법."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항에 있어서,상기 제1학습 영상, 상기 제2학습 영상 및 상기 대상 영상은 자기공명영상인 것인, 의료 영상 합성 방법."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제1자세는 누운 자세를 포함하고, 상기 제2자세는 바로 선 자세를 포함하는 것인, 의료 영상 합성 방법."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 대상 영상 및 상기 합성 영상 중 적어도 하나를 사용자 단말을 통해 표시하는 단계,를 더 포함하는 것인, 의료 영상 합성 방법."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "인공지능 기반의 의료 영상 합성 장치에 있어서,대상자가 제1자세를 취한 상태에서 상기 대상자의 소정의 부위를 촬영한 제1학습 영상을 수집하는 수집부;상기 제1학습 영상에 기초하여, 상기 제1자세에 기반하여 촬영된 대상 영상이 입력되면 상기 대상 영상에 기초하여 대상자가 상기 제1자세와 상이한 제2자세를 취한 상태에서 촬영된 것처럼 모사되는 가상의 합성 영상을 생성하는 인공지능 모델을 생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 학습시키는학습부; 및상기 제1자세에 기반하여 촬영된 상기 대상 영상을 수신하고, 상기 인공지능 모델에 기초하여 상기 대상 영상에대응하는 상기 합성 영상을 생성하는 합성부,를 포함하는, 의료 영상 합성 장치."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,공개특허 10-2022-0045366-4-상기 수집부는,대상자가 상기 제2자세를 취한 상태에서 상기 소정의 부위를 촬영한 제2학습 영상을 더 수집하고,상기 학습부는,상기 제2학습 영상에 기초하여 상기 제1자세에 대응하는 제1모사 영상을 생성하는 제1생성기 및 상기 제1모사영상의 진위 여부를 판단하는 제1판별기를 통한 순방향(Forward) 학습을 수행하는 순방향 학습부; 및상기 제1학습 영상에 기초하여 상기 제2자세에 대응하는 제2모사 영상을 생성하는 제2생성기 및 상기 제2모사영상의 진위 여부를 판단하는 제2판별기를 통한 역방향(Backward) 학습을 수행하는 역방향 학습부,를 포함하는 것인, 의료 영상 합성 장치."}
{"patent_id": "10-2020-0128003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 소정의 부위는 척추 영역을 포함하고,상기 학습부는,전만 정도, 척추뼈의 높이, 척추뼈 사이의 각도 및 디스크 형상 중 적어도 하나를 포함하는 기하학적 정보를 고려하여 상기 순방향 학습 및 상기 역방향 학습을 수행하는 것인, 의료 영상 합성 장치."}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반의 의료 영상 합성 장치 및 방법이 개시되며, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 방법은, 대상자가 제1자세를 취한 상태에서 상기 대상자의 소정의 부위를 촬영한 제1학습 영상을 수집하는 단계, 상기 제1학습 영상에 기초하여, 상기 제1자세에 기반하여 촬영된 대상 영상이 입력되면 상기 대상 영상에 기초하여 대상자가 상기 제1자세와 상이한 제2자세를 취한 상태에서 촬영된 것처럼 모사되는 가상의 합성 영상을 생성하는 인공지능 모델을 학습시키는 단계, 상기 제1자세에 기반하여 촬영된 상기 대상 영상을 수신하는 단계 및 상기 인공지능 모델에 기초하여 상기 대상 영상에 대응하는 상기 합성 영상을 생성하는 단계를 포함할 수 있 다."}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 인공지능 기반의 의료 영상 합성 장치 및 방법에 관한 것이다. 예를 들면, 본원은 척추의 다양한 동적 자세들을 모사하기 위한 인공지능 기반의 자기공명영상(MRI) 합성 기법에 관한 것이다."}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 자기공명영상(MRI) 장치는 전자파에너지의 공급에 따른 공명현상을 이용하여 대상자의 특정 부위에 대한 단층 이미지를 획득하는 장치로서, X선이나 CT와 같은 촬영 기기에 비해 방사선 피폭이 없고 단층 이미지 를 비교적 용이하게 얻을 수 있다는 이점이 있다. 또한, MRI 기기는 몸 속의 해부학적 구조뿐만 아니라 다양한 기능적 정보 등을 원하는 각도에서 입체적으로 보여주기 때문에 정확한 질병 진단을 위해서 널리 이용되고 있다. 그러나, 일반적으로 척추 부위를 대상으로 촬영되는 자기공명영상(MRI)은 대상자가 누운 자세를 취한 상태에서 촬영되는 반면, 척추는 대상자의 실제 자세나 움직임에 따라 그 모양이 크게 변화하게 되기 때문에, 환자가 서 있거나 앉아있을 때와 누운 자세일 때의 척추 내부의 형태에는 큰 차이가 존재하게 된다. 이와 관련하여, 누운 자세로만 촬영되는 자기공명영상(MRI)이 대상자의 자세나 움직임에 따른 척추의 동적 특성 을 실질적으로 반영하지 못하는 한계로 인하여 척추 MRI 만으로 환자의 실제 증상을 설명하기 어려운 경우가 빈 번하게 발생하게 된다. 따라서, 임상의와 영상의학과 전문의 등의 진단과 치료 계획 수립을 보조할 수 있도록 서있는 자세 등 다양한 동적 자세에서의 자기공명영상(MRI)을 누운 자세에서 촬영된 자기공명영상(MRI)으로부터 획득할 수 있는 기법이 요구된다. 본원의 배경이 되는 기술은 한국등록특허공보 제10-1929127호에 개시되어 있다."}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 특정한 자세로 제한적으로 촬영되는 의료 영상을 대상자의 자세나 움직임을 고려하여 다양한 동적 자세에서 촬영된 것처럼 모사되는 가상의 합성 영상으로 변환 할 수 있는 인공지능 기반의 의료 영상 합성 장치 및 방법을 제공하려는 것을 목적으로 한다.다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 방법은, 대상자가 제1자세를 취한 상태에서 상기 대상자의 소정의 부위를 촬영한 제1학습 영상을 수집하는 단계, 상기 제1학습 영상에 기초하여, 상기 제1자세에 기반하여 촬영된 대상 영상이 입력되면 상기 대상 영상에 기초하여 대상자가 상기 제1자세와 상이한 제2자세를 취한 상태에서 촬영된 것처럼 모사되는 가상의 합성 영상 을 생성하는 인공지능 모델을 학습시키는 단계, 상기 제1자세에 기반하여 촬영된 상기 대상 영상을 수신하는 단 계 및 상기 인공지능 모델에 기초하여 상기 대상 영상에 대응하는 상기 합성 영상을 생성하는 단계를 포함할 수 있다. 또한, 상기 인공지능 모델을 학습시키는 단계는, 생성적 대립 신경망(Generative Adversarial Network) 알고리 즘에 기초하여 상기 인공지능 모델을 학습시킬 수 있다. 또한, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 방법은, 대상자가 상기 제2자세를 취한 상태에 서 상기 소정의 부위를 촬영한 제2학습 영상을 수집하는 단계를 포함할 수 있다. 또한, 상기 인공지능 모델을 학습시키는 단계는, 상기 제1학습 영상 및 상기 제2학습 영상에 기초하여 상기 생 성적 대립 신경망(Generative Adversarial Network) 알고리즘을 적용할 수 있다. 또한, 상기 인공지능 모델을 학습시키는 단계는, 상기 제1학습 영상에 기초하여 상기 제2자세에 대응하는 상기 합성 영상을 생성하고, 상기 합성 영상의 진위 여부를 상기 제2학습 영상에 기초하여 판별할 수 있다. 또한, 상기 인공지능 모델을 학습시키는 단계는, 상기 제2학습 영상에 기초하여 상기 제1자세에 대응하는 제1모 사 영상을 생성하는 제1생성기 및 상기 제1모사 영상의 진위 여부를 판단하는 제1판별기를 통한 순방향 (Forward) 학습을 수행하는 단계 및 상기 제1학습 영상에 기초하여 상기 제2자세에 대응하는 제2모사 영상을 생 성하는 제2생성기 및 상기 제2모사 영상의 진위 여부를 판단하는 제2판별기를 통한 역방향(Backward) 학습을 수 행하는 단계를 포함할 수 있다. 또한, 상기 순방향(Forward) 학습을 수행하는 단계는, 상기 제2학습 영상과 상기 제1모사 영상 사이의 변화 정 보 및 상기 소정의 부위의 기하학적 정보를 고려하여 수행될 수 있다. 또한, 상기 역방향(Backward) 학습을 수행하는 단계는, 상기 제1학습 영상과 상기 제2모사 영상 사이의 변화 정 보 및 상기 기하학적 정보를 고려하여 수행될 수 있다. 또한, 상기 소정의 부위는 척추 영역을 포함할 수 있다. 또한, 상기 기하학적 정보는, 전만 정도, 척추뼈의 높이, 척추뼈 사이의 각도 및 디스크 형상 중 적어도 하나를 포함할 수 있다. 또한, 상기 제1학습 영상, 상기 제2학습 영상 및 상기 대상 영상은 자기공명영상일 수 있다. 또한, 상기 제1자세는 누운 자세를 포함하고, 상기 제2자세는 바로 선 자세를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 방법은, 상기 대상 영상 및 상기 합성 영상 중 적어도 하나를 사용자 단말을 통해 표시하는 단계를 포함할 수 있다. 한편, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 장치는, 대상자가 제1자세를 취한 상태에서 상 기 대상자의 소정의 부위를 촬영한 제1학습 영상을 수집하는 수집부, 상기 제1학습 영상에 기초하여, 상기 제1 자세에 기반하여 촬영된 대상 영상이 입력되면 상기 대상 영상에 기초하여 대상자가 상기 제1자세와 상이한 제2 자세를 취한 상태에서 촬영된 것처럼 모사되는 가상의 합성 영상을 생성하는 인공지능 모델을 생성적 대립 신경 망(Generative Adversarial Network) 알고리즘에 기초하여 학습시키는 학습부 및 상기 제1자세에 기반하여 촬영 된 상기 대상 영상을 수신하고, 상기 인공지능 모델에 기초하여 상기 대상 영상에 대응하는 상기 합성 영상을 생성하는 합성부를 포함할 수 있다. 또한, 상기 수집부는, 대상자가 상기 제2자세를 취한 상태에서 상기 소정의 부위를 촬영한 제2학습 영상을 수집 할 수 있다.또한, 상기 학습부는, 상기 제2학습 영상에 기초하여 상기 제1자세에 대응하는 제1모사 영상을 생성하는 제1생 성기 및 상기 제1모사 영상의 진위 여부를 판단하는 제1판별기를 통한 순방향(Forward) 학습을 수행하는 순방향 학습부 및 상기 제1학습 영상에 기초하여 상기 제2자세에 대응하는 제2모사 영상을 생성하는 제2생성기 및 상기 제2모사 영상의 진위 여부를 판단하는 제2판별기를 통한 역방향(Backward) 학습을 수행하는 역방향 학습부를 포 함할 수 있다. 또한, 상기 소정의 부위는 척추 영역을 포함하고, 상기 학습부는, 전만 정도, 척추뼈의 높이, 척추뼈 사이의 각 도 및 디스크 형상 중 적어도 하나를 포함하는 기하학적 정보를 고려하여 상기 순방향 학습 및 상기 역방향 학 습을 수행할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 특정한 자세로 제한적으로 촬영되는 의료 영상을 대상자의 자세나 움 직임을 고려하여 다양한 동적 자세에서 촬영된 것처럼 모사되는 가상의 합성 영상으로 변환할 수 있는 인공지능 기반의 의료 영상 합성 장치 및 방법을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 다양한 동적 자세에 기반하여 촬영되는 의료 영상을 획득하기 위한 별 도의 특수 장비 없이도, 통상적인 자세로 촬영되는 의료 영상을 동적 자세에 대응되도록 변환한 가상의 합성 영 상을 제공함으로써 진단의 효율성과 정확성을 향상시킬 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 동적 자세 기반의 합성 영상을 임상의, 영상의학과 전문의 등의 의료 진에게 풍부하게 제공함으로써 진단 및 치료 계획 수립 과정을 보조할 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 인공지능 기반의 의료 영상 합성 장치 및 방법에 관한 것이다. 예를 들면, 본원은 척추의 다양한 동적 자세들을 모사하기 위한 인공지능 기반의 자기공명영상(MRI) 합성 기법에 관한 것이다. 도 1은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 장치를 포함하는 의료 영상 시스템의 개략적 인 구성도이다. 도 1을 참조하면, 본원의 일 실시예에 따른 의료 영상 시스템은, 본원의 일 실시예에 따른 인공지능 기반 의 의료 영상 합성 장치(이하, '의료 영상 합성 장치'라 한다.), 의료 영상 촬영 장치 및 사용 자 단말을 포함할 수 있다. 의료 영상 합성 장치, 의료 영상 촬영 장치 및 사용자 단말 상호간은 네트워크를 통해 통신 할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네 트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트 워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지 는 않는다. 사용자 단말은 예를 들면, 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 무선 통신 장치일 수 있다. 본원의 일 실시예에 따르면, 의료 영상 촬영 장치는 자기공명영상(Magnetic Resonance Imaging, MRI) 스 캐너일 수 있으나, 이에만 한정되는 것은 아니다. 다른 예로, 의료 영상 촬영 장치는 컴퓨터단층촬영 (Computerized Tomography, CT) 스캐너, X-선 촬영 장치, 초음파 영상 촬영 장치 등일 수 있다. 또한, 의료 영 상 촬영 장치의 유형에 따라 의료 영상 합성 장치로 제공되는 의료 영상(달리 말해, 후술하는 대상 영상 등)은 자기공명영상(MRI) 영상, CT 이미지, 초음파 영상, X-선 영상 등에 해당할 수 있다. 구체적으로, 본원의 일 실시예에 따르면, 의료 영상 촬영 장치에 의해 획득되는 대상 영상, 후술하는 인공지능 모델의 구축을 위한 학습 데이터 셋으로 활용되는 제1학습 영상 및 제2학습 영상은 자기공명 영상(MRI) 영상일 수 있다. 또한, 대상 영상, 제1학습 영상, 제2학습 영상 등은 DICOM(Digital Imaging and Communications in Medicine) 이미지일 수 있다. 또한, 의료 영상 시스템은 병원, 의료기관 등과 연계하여 구축되는 의료 영상 저장/전송 시스템(Picture Archiving and Communication System, PACS)을 지칭하는 것일 수 있으며, 의료 영상 합성 장치는 의료 영 상 시스템에 포함되는 의료 영상 촬영 장치에 의해 촬영된 의료 영상을 의료 영상 촬영 장치로 부터 대상 영상으로서 획득하여, 대상 영상에 대응하는 합성 영상을 출력하는 별도의 디바이스로 구현 되거나 의료 영상 촬영 장치에 탑재되는 형태(예를 들면, 의료 영상 촬영 장치에 설치되는 소프트웨 어, 프로그램 형태 등)로 구현되는 것일 수 있다. 한편, 도 1을 참조하면, 의료 영상 합성 장치는 수집부, 학습부, 합성부 및 출력부를 포함할 수 있다. 수집부는 대상자가 제1자세를 취한 상태에서 대상자의 소정의 부위를 촬영한 제1학습 영상을 수집할 수 있다. 또한, 수집부는 대상자가 제1자세와 상이한 제2자세를 취한 상태에서 소정의 부위를 촬영한 제2 학습 영상을 수집할 수 있다. 본원의 일 실시예에 따르면, 수집부는 복수의 대상자 각각에 대하여 제1 자세 기반의 제1학습 영상 및 제2자세 기반의 제2학습 영상을 함께 수집하여 후술하는 인공지능 모델의 학습을 위한 데이터 셋으로 활용할 수 있다. 또한, 수집부는 의료 영상 촬영 장치에 의해 촬영된 의료 영상을 학습 영상으로서 의료 영상 촬영 장치로부터 수집하는 것일 수 있으나, 이에만 한정되는 것은 아니 며, 의료 영상 시스템 내의 의료 영상 촬영 장치 외의 별도의 경로(예를 들면, 외부 저장 장치, 외부 서버 등)로 학습 영상을 수집하는 것일 수 있다. 본원의 실시예에 관한 설명에서, 제1자세는 누운 자세를 포함하고, 제2자세는 바로 선 자세를 포함할 수 있다. 또한, 본원의 구현예에 따라 제1자세 또는 제2자세는 누운 자세나 바로 선 자세 외에 앉은 자세, 비스듬히 선 자세, 앞으로 구부린 자세, 뒤로 구부린 자세 등을 포함할 수 있다. 예시적으로, 의료 영상 합성 장치를 통해 대상자가 누운 자세를 취한 상태에서 주로 촬영되는 자기공명영상(MRI) 타입의 의료 영상 촬영 장치 의 촬영 환경 특성을 고려하여 누운 자세 이외의 동적 자세를 기반으로 한 가상의 합성 영상을 생성할 수 있도 록 제2자세는 바로 선 자세, 앉은 자세, 비스듬히 서있는 자세, 엎드린 자세 등 누운 자세가 아닌 다양한 자세 를 포함하는 것일 수 있다. 다른 예로, 본원의 구현예에 따라 제1자세가 누운 자세(Supine) 또는 비스듬한 자세 (Prone)를 포함하고, 제2자세가 바로 선 자세(Stand)를 포함하도록 구분되는 것일 수 있다. 또한, 본원의 일 실시예에 따르면, 의료 영상이 촬영되는 영역인 소정의 부위는 대상자의 척추 영역을 포함할 수 있으나, 이에만 한정되는 것은 아니다. 또한, 본원의 일 실시예에 따르면, 대상자에 대한 제2학습 영상은 제1학습 영상의 촬영 대상인 대상자 가 제1자세 외의 자세인 제2자세를 취한 상태에서 의료 영상을 촬영할 수 있도록 마련되는 의료 영상 촬영 장치 외의 별도의 장치에 기반하여(예를 들면, 대상자가 전술한 별도의 장치를 착용한 상태에서) 촬영(획득)되 는 것일 수 있다. 도 2는 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 장치에 의해 수행되는 학습 영상에 대한 전처 리 과정을 설명하기 위한 개념도이다. 도 2를 참조하면, 수집부는 수집된 제1학습 영상 및 제2학습 영상에 대한 밝기 정보 기반의 전처 리(Pre-processing)를 수행할 수 있다. 구체적으로, 수집부는, 제1학습 영상 또는 제2학습 영상으로서 수집된 학습 영상 각각의 밝기 정 보 범위(Range)가 표준화(정규화)되지 않을 수 있으므로, 이를 통일적으로 처리하기 위하여, 수집된 학습 영상 각각의 DICOM 이미지 헤더 정보를 기초로, 최소 밝기 및 최대 밝기를 결정함으로써 학습 영상에 대한 밝기 정보 범위(Range)를 표준화(정규화)할 수 있다. 예시적으로, DICOM 이미지 헤더 정보에는 윈도우 넓이(Window Width) 정보 및 윈도우 중심(Window Center) 정보가 포함될 수 있으며, 예시적으로, 윈도우 넓이 정보는 (0028, 1051) 이고, 윈도우 중심 정보는 (0028, 1050) 등일 수 있다. 또한, 수집부는 하기 식 [1-1] 및 [1-2]에 기초하여 학습 영상 각각의 최소 픽셀값 및 최대 픽셀값을 연산 할 수 있다. [식 1-1]"}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[식 1-2]"}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, Pl은 최소 픽셀값이고, Ph는 최대 픽셀값이고, Pc는 입력 픽셀의 중심 밝기이고, Pw는 입력 픽셀의 너비 밝기일 수 있다. 또한, 수집부는 수집된 학습 영상 각각의 히스토그램의 분포를 고려하여 수집된 학습 영상들의 히스토그램 및 밝기 정보(픽셀값)에 기초하여 히스토그램 매칭을 위한 템플릿 이미지를 학습 영상 중에서 선택하거나 생성 할 수 있다. 구체적으로, 템플릿 이미지는 하기 식 2에 의해 선택될 수 있으며, 수집부는 선택된 템플릿 이미지에 기초하여 히스토그램 매칭을 수행할 수 있다.[식 2]"}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 4, "content": "도 3은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 장치에 의해 수행되는 인공지능 모델 학습 과 정을 설명하기 위한 개념도이다. 도 3을 참조하면, 학습부는 제1학습 영상(도 3을 참조하면, 'MRI-Supine/Prone', 11) 및 제2학습 영상(도 3을 참조하면, 'MRI-Stand', 12) 중 적어도 하나에 기초하여, 제1자세에 기반하여 촬영된 대상 영상이 입력 되면 대상 영상에 기초하여 대상자가 제1자세와 상이한 제2자세를 취한 상태에서 촬영된 것처럼 모사되는 가 상의 합성 영상을 생성하는 인공지능 모델을 학습시킬 수 있다. 구체적으로, 학습부는 생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 입력된 제1자세 기반의 대상 영상으로부터 제2자세 기반의 가상의 합성 영상을 생성하는 인공지능 모델을 학습시 킬 수 있다. 여기서, 생성적 대립 신경망(Generative Adversarial Network) 알고리즘은, 생성기(Generator)와 판별기 (Discriminator)가 경쟁하면서 학습이 이루어져 실제와 흡사한 결과물(예를 들면, 이미지, 동영상, 음성 등)을 자동으로 만들어 내도록 하는 기계학습(Machine Learning) 방식의 하나로, 본원의 일 실시예에 따르면, 학습부 는 수집된 학습 영상을 기초로 가상의 모사 영상(이미지)을 만드는 생성기(Generator)와 생성된 모사 영상 (이미지)의 진위를 가리는 판별기(Discriminator)를 포함하고, 이러한 생성기(Generator)와 판별기 (Discriminator)가 반복적으로 경쟁하도록 하여 학습이 진행된 후의 생성기(Generator)가 판별기 (Discriminator)에 의해 진위를 가리기 힘든 수준까지 잘 모사된 영상을 생성하도록 학습되는 것일 수 있다. 즉, 본원의 일 실시예에 따르면, 학습부는 생성적 대립 신경망(Generative Adversarial Network) 알고리 즘에 기초하여, 생성기(Generator)가 제1자세에 기반하여 촬영된 제1학습 영상에 기초하여 제2자세에 대응 하는 합성 영상을 생성하고, 판별기(Discriminator)가 제2자세에 대응하는 합성 영상의 진위 여부를 제2 학습 영상에 기초하여 판별하는 과정을 반복 수행하는 것일 수 있다. 또한, 본원의 일 실시예에 따르면, 학습부는 순방향(Forward) 사이클 및 역방향(Backward) 사이클을 포함 하는 생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 인공지능 모델을 학습시키는 것일 수 있다. 여기서, 순방향(Forward) 사이클 및 역방향(Backward) 사이클을 포함하는 생성적 대립 신경망 (Generative Adversarial Network) 알고리즘은 CycleGAN 등으로 달리 지칭될 수 있다. 도 4는 순방향(Forward) 학습 및 역방향(Backward) 학습을 포함하는 생성적 대립 신경망(Generative Adversarial Network) 알고리즘 기반의 인공지능 모델 학습 과정을 설명하기 위한 개념도이다. 도 4를 참조하면, 학습부는 제2학습 영상에 기초하여 제1자세에 대응하는 제1모사 영상을 생성하 는 제1생성기 및 생성된 제1모사 영상의 진위 여부를 판단하는 제1판별기를 통한 순방향 (Forward) 학습을 수행하는 순방향 학습부 및 제1학습 영상에 기초하여 제2자세에 대응하는 제2모사 영상을 생성하는 제2생성기 및 제2모사 영상의 진위 여부를 판단하는 제2판별기를 통한 역 방향(Backward) 학습을 수행하는 역방향 학습부를 포함할 수 있다. 구체적으로, 순방향 학습부의 제1판별기는 제1생성기에 의해 생성된 제1자세에 대응하는 제1 모사 영상의 진위 여부를 실제로 제1자세에 기반하여 촬영된 실제 영상(도 4를 참조하면, '실제 영상 (Supine/Prone)'에 대응된다.)에 기초하여 진위 여부의 판별을 수행하되, 여기서 진위 판별에 활용되는 실제 영 상은 미리 확보된 제1학습 영상 중 적어도 일부를 의미하는 것일 수 있다. 마찬가지로, 역방향 학습부의 제2판별기는 제2생성기에 의해 생성된 제2자세에 대응하는 제2 모사 영상의 진위 여부를 실제로 제2자세에 기반하여 촬영된 실제 영상(도 4를 참조하면, '실제 영상 (Stand)'에 대응된다.)에 기초하여 진위 여부의 판별을 수행하되, 여기서 진위 판별에 활용되는 실제 영상은 미 리 확보된 제2학습 영상 중 적어도 일부를 의미하는 것일 수 있다. 종합하면, 학습부는 입력된 제2자세 기반의 영상을 기초로 제1자세를 취한 상태에서 촬영된 것처럼 모사되 는 가상의 합성 영상을 반복하여 생성하는 과정과, 생성된 합성 영상의 진위 여부를 반복하여 판별하는 과정의 경쟁적인 반복 수행을 통해 제2자세 기반의 영상의 제1자세 기반의 영상으로의 가상 합성 프로세스를 보다 정밀 하게 수행하도록 하는 순방향 학습(Forward Cycle) 및 입력된 제1자세 기반의 영상을 기초로 제2자세를 취한 상태에서 촬영된 것처럼 모사되는 가상의 합성 영상을 반복하여 생성하는 과정과, 생성된 합성 영상의 진위 여부 를 반복하여 판별하는 과정의 경쟁적인 반복 수행을 통해 제1자세 기반의 영상의 제2자세 기반의 영상으로의 가 상 합성 프로세스를 보다 정밀하게 수행하도록 하는 역방향 학습(Backward Cycle)을 순환하여 수행할 수 있다. 상술한 바와 같이 각기 반대되는 방향으로의 영상 변환(합성)을 위한 두 가지의 구분되는 학습 사이클이 반복되 는 생성적 대립 신경망(예를 들면, CycleGAN) 기반의 인공지능 모델의 학습을 통해 학습이 완료된 본원에서의 인공지능 모델은 대상자가 제1자세를 취한 상태에서 촬영된 의료 영상을 해당 대상자가 제2자세를 취한 상태에 서 촬영된 것처럼 모사되는 가상의 합성 영상으로 변환하는 동작과 이와 반대되게 대상자가 제2자세를 취한 상 태에서 촬영된 의료 영상을 해당 대상자가 제1자세를 취한 상태에서 촬영된 것처럼 모사되는 가상의 합성 영상 으로 변환하는 동작을 모두 수행할 수 있다. 이렇듯, 학습부를 통해 구축되는 인공지능 모델은 대상자가 제1자세 또는 제2자세를 취함에 따라 소정의 부위와 연계된 형태학적(morphological) 특징의 변화를 반영하여 다양한 동적 자세에서의 가상의 합성 영상(모 사 영상)을 변환(생성)할 수 있게 된다. 이와 관련하여, 학습부가 제1자세 기반의 영상과 제2자세 기반의 영상 사이의 양방향 변환(예를 들면, 합성 및 복구)이 모두 가능한 인공지능 모델을 구축함으로써, 단방향(예를 들면, 제1자세 기반의 의료 영상을 제2자세 기반의 의료 영상으로 변환하는 단일 방향)으로의 변환만을 수행하 도록 하는 학습만을 진행하는 경우, 생성기(Generator)가 오직 판별기(Discriminator)를 속이기 위하여 소정의 부위의 대상자의 자세에 따른 형태학적 특징 변화를 고려하지 못하는 낮은 수준의 모사 영상을 출력하게 되는 문제를 방지할 수 있다. 또한, 본원의 일 실시예에 따르면, 학습부는 수집부에 의해 수집된 학습 영상과 생성기(Generator)에 의해 생성되는 모사 영상 사이의 변화 정보 및 촬영 대상 영역인 소정의 부위의 기하학적(Geometric) 정보를 고 려하여 전술한 인공지능 모델의 학습을 수행할 수 있다. 달리 말해, 순방향 학습부는 제2학습 영상과 제1모사 영상 사이의 변화 정보 및 소정의 부위의 기 하학적 정보를 고려하여 순방향 학습을 수행하고, 역방향 학습부는 제1학습 영상과 제2모사 영상 사이의 변화 정보 및 소정의 부위의 기하학적 정보를 고려하여 역방향 학습을 수행할 수 있다. 도 5는 입력된 학습 영상과 출력되는 모사 영상 사이의 변화 정보를 고려하여 인공지능 모델을 학습시키는 과정 을 설명하기 위한 개념도이다. 도 5를 참조하면, 학습부는 인코더(Encoder) 측의 다운 샘플링(Down Sampling) 결과에 기초하여 도출되는 복수의 유형의 활성화맵(Activation map)을 활용(또는 복수의 유형의 주의맵(Attention map)을 활용)하여 입력 된 학습 영상(Source)으로부터 출력된 가상의 모사 영상(Destination) 사이의 변화량을 파악하고(Multi-Class Activation Map), 이를 인공지능 모델 학습에서의 손실(Loss) 함수에 반영함으로써, 학습 영상과 모사 영상 사 이의 변화 정보를 고려한 학습을 수행할 수 있다. 본원의 일 실시예에 따르면, 복수의 유형의 활성화맵(Activation map)은 Grad-CAM(gradient-class activation map) 및 Score-CAM을 포함할 수 있고, 이러한 다중 클래스 활성화맵(Multi-Class Activation Map)과 연계된 다 중 주의맵(M-attentionMap)은 하기 식 3을 통해 도출될 수 있다. [식 3]"}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "또한, 이러한 다중 클래스 활성화맵(Multi-Class Activation Map)은 입력된 의료 영상에 기초하여 가상의 모사 영상을 생성하는 과정에서 주요하게 변환된 영역인 근거 영역을 도출하도록 활용되는 것일 수 있다. 이하에서는, 도 6 및 도 7을 참조하여, 학습부에 의한 인공지능 모델의 구축시 고려되는 소정의 부위의 기 하학적(Geometric) 정보를 구체적으로 설명하도록 한다. 도 6 및 도 7은 인공지능 모델의 학습에 고려되는 척추 영역의 기하학적 정보를 설명하기 위한 도면이다. 구체적으로, 도 6은 시상면에 대응하는 대상자 자세별 의료 영상을 통해 파악되는 대상자의 자세 등에 따른 소 정의 부위의 기하학적 정보의 변화를 나타내고, 도 7은 축상면에 대응하는 대상자 자세별 의료 영상을 통해 파 악되는 대상자의 자세 등에 따른 소정의 부위의 기하학적 정보의 변화를 나타낸 것이다. 본원의 일 실시예에 따르면, 의료 영상이 촬영되는 소정의 부위는 대상자의 척추 영역을 포함할 수 있다. 또한, 이에 따라, 소정의 부위인 척추 영역에 대한 기하학적 정보는 요추전만 정도, 분절전만 정도, 척추뼈(요추 등) 의 높이(도 6의 h1 및 h2), 척추뼈 사이의 각도(도 6의 α1및 α2) 및 디스크 형상 중 적어도 하나를 포함할 수 있다. 또한, 도 7을 참조하면, 소정의 부위인 척추 영역에 대한 기하학적 정보는 대상자의 자세 변화에 따른 레벨별 신경공(Neural foramen)의 넓이 변화, 디스크 탈출 정도의 변화 등을 포함할 수 있다. 또한, 인공지능 모델을 구축하기 위한 학습 과정에서 소정의 부위(예를 들면, 척추 영역)의 기하학적 정보가 고 려된다는 것은, 구체적으로, 인공지능 모델 학습에서의 손실(Loss) 함수에 소정의 부위의 특정 지역의 기하학적 정보의 부분적인 변화에 대응하는 텀(LGeometry)을 포함되는 것으로 이해될 수 있다. 또한, 본원의 일 실시예에 따 르면, 기하학적 정보의 부분적인 변화는 대상자의 성별, 체형 정보 (예를 들면, BMI 정보 등), 자세 별로 소정 의 부위에 가해지는 압력 정도 등에 기초하여 달리 측정(평가)되는 것일 수 있다. 합성부는 제1자세에 기반하여 촬영된 대상 영상을 수신할 수 있다. 예시적으로, 합성부는 의료 영 상 촬영 장치로부터 대상 영상을 수신하는 것일 수 있다. 또한, 합성부는 학습부에 의해 구축된 인공지능 모델에 기초하여 수신된 대상 영상에 대응하는 제 2자세 기반의 합성 영상을 생성할 수 있다. 또한, 합성부는 필요에 따라서는 수신된 대상 영상이 제 2자세에 기반한 의료 영상인 경우, 인공지능 모델에 기초하여 대상 영상을 제1자세에 기반한 가상의 합성 영 상으로 변환하도록 동작할 수 있다. 또한, 출력부는 대상 영상 및 합성부에 의해 생성된 합성 영상 중 적어도 하나를 출력할 수 있 다. 예를 들어, 출력부는 대상 영상 및 합성 영상 중 적어도 하나를 의료 영상 합성 장치에 자 체적으로 마련된 디스플레이를 통해 표시하거나 의료 영상 합성 장치와 네트워크를 통해 접속(연동)된 사용자 단말로 전송하여 사용자 단말을 통해 대상 영상 및 합성 영상 중 적어도 하나가 표출되 도록 할 수 있다. 또한, 본원의 일 실시예에 따르면, 출력부는 대상 영상 및 합성 영상에 반영된 소정의 부위의 영역 중 국부적인 진단 영역에 대응하는 부분 영상(Crop 영상)을 생성하고, 생성된 부분 영상(Crop 영상)을 출력할 수 있다. 이와 관련하여, 본원의 일 실시예에 따르면, 출력부는 인공지능 모델에 기초하여 도출되는 대상 영상 및 합성 영상에 대한 다중 클래스 활성화맵(Multi-Class Activation Map)의 형상, 위치 등에 기초하여 부분 영상(Crop 영상)을 출력할 영역을 선별하는 것일 수 있다. 달리 말해, 출력부는 전술한 다중 클래스 활성 화맵(Multi-Class Activation Map)에 기반하여 도출되는 근거 영역에 기초하여 부분 영상(Crop 영상)이 생성될 소정의 부위 내부의 진단 영역을 결정할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 8은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 방법에 대한 동작 흐름도이다. 도 8에 도시된 인공지능 기반의 의료 영상 합성 방법은 앞서 설명된 의료 영상 합성 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 의료 영상 합성 장치에 대하여 설명된 내용은 인공지 능 기반의 의료 영상 합성 방법에 대한 설명에도 동일하게 적용될 수 있다. 도 8을 참조하면, 단계 S11에서 수집부는, 대상자가 제1자세를 취한 상태에서 대상자의 소정의 부위를 촬 영한 제1학습 영상을 수집할 수 있다. 다음으로, 단계 S12에서 수집부는, 대상자가 제1자세와 상이한 제2자세를 취한 상태에서 소정의 부위를 촬 영한 제2학습 영상을 수집할 수 있다. 다음으로, 단계 S13에서 수집부는, 수집된 제1학습 영상 및 제2학습 영상에 대한 밝기 정보 기반 의 전처리(Pre-processing)를 수행할 수 있다. 다음으로, 단계 S14에서 학습부는, 제1학습 영상 및 제2학습 영상 중 적어도 하나에 기초하여, 제 1자세에 기반하여 촬영된 대상 영상이 입력되면 대상 영상에 기초하여 대상자가 제1자세와 상이한 제2자 세를 취한 상태에서 촬영된 것처럼 모사되는 가상의 합성 영상을 생성하는 인공지능 모델을 학습시킬 수 있 다.구체적으로, 단계 S14에서 학습부는, 생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 인공지능 모델을 학습시키되, 제1학습 영상에 기초하여 제2자세에 대응하는 합성 영상(모사 영 상)을 생성하고, 생성된 합성 영상(모사 영상)의 진위 여부를 제2학습 영상에 기초하여 판별하는 과정을 반 복적으로 수행함으로써 인공지능 모델을 학습시킬 수 있다. 또한, 단계 S14에서 학습부는, 제2학습 영상에 기초하여 제1자세에 대응하는 제1모사 영상을 생성 하는 제1생성기 및 제1모사 영상의 진위 여부를 판단하는 제1판별기를 통한 순방향(Forward) 학습과 제1학습 영상에 기초하여 제2자세에 대응하는 제2모사 영상을 생성하는 제2생성기 및 제2 모사 영상의 진위 여부를 판단하는 제2판별기를 통한 역방향(Backward) 학습을 순환하여 반복 수행함 으로써 인공지능 모델을 학습시킬 수 있다. 또한, 단계 S14에서 순방향 학습부는 제2학습 영상과 각각의 반복 시행마다 생성되는 제1모사 영상 사이의 변화 정보 및 소정의 부위의 기하학적 정보의 변화를 고려하여 순방향(Forward) 학습을 수행할 수 있다. 또한, 단계 S14에서 역방향 학습부는 제1학습 영상과 각각의 반복 시행마다 생성되는 제2모사 영상 사이의 변화 정보 및 소정의 부위의 기하학적 정보의 변화를 고려하여 역방향(Backward) 학습을 수행 할 수 있다. 다음으로, 단계 S15에서 합성부는, 제1자세에 기반하여 촬영된 대상 영상을 수신할 수 있다. 다음으로, 단계 S16에서 합성부는, 단계 S14를 통해 구축된 인공지능 모델에 기초하여 수신된 대상 영상 에 대응하는 합성 영상을 생성할 수 있다. 특히, 단계 S16을 통해 생성되는 합성 영상은 제2자세를 취 한 상태에서 촬영된 것처럼 대상 영상으로부터 모사되어 생성되는 가상의 영상일 수 있다. 다음으로, 단계 S17에서 출력부는, 대상 영상 및 생성된 합성 영상 중 적어도 하나에 기초하여 소정 의 부위의 영역 중 국부적인 진단 영역에 대응하는 부분 영상(Crop 영상)을 생성할 수 있다. 다음으로, 단계 S18에서 출력부는, 진단 영역에 대응하는 부분 영상(Crop 영상)이 식별 가능하도록 표시된 대상 영상 및 합성 영상 중 적어도 하나를 표시할 수 있다. 상술한 설명에서, 단계 S11 내지 S18은 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로 그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프 로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이 프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같 은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 또한, 전술한 인공지능 기반의 의료 영상 합성 방법은 기록 매체에 저장되는 컴퓨터에 의해 실행되는 컴퓨터 프 로그램 또는 애플리케이션의 형태로도 구현될 수 있다."}
{"patent_id": "10-2020-0128003", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다.부호의 설명 1000: 의료 영상 시스템 100: 인공지능 기반의 의료 영상 합성 장치 110: 수집부 120: 학습부 121: 순방향 학습부 1211: 제1생성기 1212: 제1판별기 122: 역방향 학습부 1221: 제2생성기 1222: 제2판별기 130: 합성부 140: 출력부 200: 의료 영상 촬영 장치 300: 사용자 단말 11: 제1학습 영상 12: 제2학습 영상 1: 대상 영상 2: 합성 영상 20: 네트워크도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2020-0128003", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 장치를 포함하는 의료 영상 시스템의 개략적 인 구성도이다. 도 2는 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 장치에 의해 수행되는 학습 영상에 대한 전처 리 과정을 설명하기 위한 개념도이다. 도 3은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 장치에 의해 수행되는 인공지능 모델 학습 과 정을 설명하기 위한 개념도이다. 도 4는 순방향(Forward) 학습 및 역방향(Backward) 학습을 포함하는 생성적 대립 신경망(Generative Adversarial Network) 알고리즘 기반의 인공지능 모델 학습 과정을 설명하기 위한 개념도이다. 도 5는 입력된 학습 영상과 출력되는 모사 영상 사이의 변화 정보를 고려하여 인공지능 모델을 학습시키는 과정 을 설명하기 위한 개념도이다. 도 6 및 도 7은 인공지능 모델의 학습에 고려되는 척추 영역의 기하학적 정보를 설명하기 위한 도면이다. 도 8은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 합성 방법에 대한 동작 흐름도이다."}
