{"patent_id": "10-2021-0182137", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0092604", "출원번호": "10-2021-0182137", "발명의 명칭": "지능형 운량 측정 장치 및 방법", "출원인": "한국원자력연구원", "발명자": "박승규"}}
{"patent_id": "10-2021-0182137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "구름이 포함된 컬러 영상을 획득하는 영상 획득 모듈;신경망 학습 모듈로부터 장착되는 신경망을 현 단계 신경망으로 인식하고 학습에 사용된 데이터를 현 단계 학습데이터로 인식하고, 상기 현 단계 신경망을 이용하여 획득한 상기 컬러 영상을 구름 영역과 구름 이외의 영역으로 판별하여 구름 판별 영상을 생성하는 구름 판별 신경망 모듈; 판별된 상기 구름 판별 영상을 참고하여 운량을 연산하는 운량 연산 모듈;상기 영상 획득 모듈로부터 획득한 영상에서 RGB(Red Green Blue) 색상을 분리하고, 분리된 색상값을 기설정된RGB(Red Green Blue) 경계값(θ)과 비교하여 RGB 색상을 이용한 대조군 구름 판별 영상을 생성하고, 상기 구름판별 신경망 모듈로부터 획득한 구름 판별 영상과 상기 대조군 구름 판별 영상의 절대차 평균값이 기설정된 임계값 이상일 경우, 상기 대조군 구름 판별 영상에 대응하는 컬러 영상을 다음 단계의 추가학습 데이터로 선별하는 학습영상 선별 모듈; 및상기 학습영상 선별 모듈로부터 얻은 다음 단계의 추가학습 데이터를 현 단계의 학습 데이터에 추가하여 다음단계 학습 데이터를 생성하고, 상기 다음 단계 학습 데이터를 이용하여 상기 현 단계 신경망을 추가 학습시켜다음 단계 신경망을 생성하고, 상기 다음 단계 신경망을 상기 구름 판별 신경망 모델의 신경망으로 교체 장착하는 신경망 학습 모듈;을 포함하는 지능형 운량 측정 장치."}
{"patent_id": "10-2021-0182137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 학습영상 선별 모듈은 하기 식을 통하여 상기 구름 판별 신경망 모듈로부터 획득한 구름 판별 영상과 상기대조군 구름 판별 영상의 절대차 평균값이 기설정된 임계값 이상인지 판단하며,여기서, 는 상기 영상 획득 모듈이 i번째 획득한 컬러 영상을 입력으로 사용한 상기 구름 판별 신경망모듈의 출력 영상인 구름 판별 영상의 (x, y) 위치에서의 영상 픽셀 값이고, 는 상기 영상 획득 모듈이 i번째 획득한 컬러 영상에 대해 RGB 경계값을 비교하여 판별한 구름 판별 영상에서 j번째 (θ2, θ3) 경계값그룹을 이용하여 얻은 구름판별 영상의 (x, y) 위치에서의 영상 픽셀 값이고, TH는 기설정된 임계값이며, NxN은영상 크기를 나타내는 픽셀이고, θ2와 θ3는 기설정된 RGB 경계값인, 지능형 운량 측정 장치."}
{"patent_id": "10-2021-0182137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 학습영상 선별 모듈에서 상기 영상은, 서로 다른 실수 값을 갖는 기설정된 (θ2, θ3) 경계값 풀로부터 생성된 j번째 (θ2, θ3) 경계값 그룹을 이용하여 생성된 j번째 대조군 구름 판별 영상이며, 상기 경계값 풀로부터 생성된 모든 대조군 구름 판별 영상이 상기 식을 만족하는 경우, 상기 대조군 구름 판별공개특허 10-2023-0092604-3-영상에 대응하는 컬러 영상을 추가 학습 데이터로 선별하는,지능형 운량 측정 장치."}
{"patent_id": "10-2021-0182137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 영상과 상기 영상 속에 태양이나 달을 포함하는 부분이 존재할 경우, 태양이나 달 부분은 제거하고 절대차 평균값을 비교하는 지능형 운량 측정 장치."}
{"patent_id": "10-2021-0182137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 신경망 학습 모듈은첫 학습용 초기 학습 데이터(T1)를 생성하는 초기학습 데이터 생성부;상기 현 단계(k) 신경망(Gk)을 추가학습 시키기 위한 다음 단계(k+1) 추가학습 데이터(Ak+1)를 생성하는 추가학습 데이터 생성부; 및현 단계 학습 데이터(Tk)와 상기 추가학습 데이터(Ak+1)를 더하여 다음 단계 학습 데이터(Tk+1)를 생성하고, 상기다음 단계 학습 데이터(Tk+1)를 상기 현 단계 신경망(Gk)에 대해 추가 학습시켜 다음 단계 신경망(Gk+1)을 생성하도록 신경망 학습을 수행하는 GAN 신경망 학습부;를 포함하며,상기 추가학습 데이터 생성부는,상기 학습영상 선별 모듈로부터 다음 단계(k+1) 추가 학습 데이터로 선별된 상기 컬러 영상에 대해 서로 다른실수 값을 갖는 기설정된 경계값 풀로부터 생성된 모든 (θ2, θ3) 경계값 그룹을 이용하여 대조군 구름 판별 영상을 생성하며,상기 모든 대조군 구름 판별 영상 중에서, 상기 현 단계 신경망(Gk)에 상기 컬러 영상을 입력하여 출력한 구름판별 영상과의 절대차 평균값이 가장 작은 대조군 구름 판별 영상을 추출하고, 추출된 대조군 구름 판별 영상과상기 추출된 대조군 구름 판별 영상에 대응하는 컬러 영상을 추가학습 데이터(Ak+1)에 포함시키는 지능형 운량 측정 장치."}
{"patent_id": "10-2021-0182137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "구름이 포함된 컬러 영상을 획득하는 단계;구름 판별 신경망 모듈에 장착된 신경망을 현 단계 신경망으로 인식하고 학습에 사용된 데이터를 현 단계 학습데이터로 인식하고, 상기 현 단계 신경망을 이용하여 획득한 상기 컬러 영상을 구름 영역과 구름 이외의 영역으로 판별하여 구름 판별 영상을 획득하는 단계; 판별된 구름 판별 영상을 참고하여 운량을 연산하는 단계; 획득한 상기 컬러 영상에서 RGB(Red Green Blue) 색상을 분리하고, 분리된 색상값을 기설정된 RGB(Red GreenBlue) 경계값(θ)과 비교하여 RGB 색상을 이용한 대조군 구름 판별 영상을 생성하고, 상기 구름 판별 영상과 상기 대조군 구름 판별 영상의 절대차 평균값이 기설정된 임계값 이상일 경우, 상기 대조군 구름 판별 영상에 대응하는 컬러 영상을 다음 단계 추가학습 데이터로 선별하는 단계; 및상기 선별된 추가학습 데이터를 상기 현 단계 학습 데이터에 추가하여 추가학습용 다음 단계 학습 데이터를 생성하고, 상기 현 단계 신경망에 상기 다음 단계 학습 데이터를 학습시켜 다음 단계 신경망을 생성하고 상기 다음 단계 신경망을 상기 구름 판별 신경망 모듈에 장착하는 단계;를 포함하는, 지능형 운량 측정 방법.공개특허 10-2023-0092604-4-청구항 7 제6 항에 있어서,상기 절대차 평균값이 기설정된 임계값 미만이 될 때까지 현 단계 신경망의 측정 결과로부터 추가학습 데이터를선별하는 단계 및 새로운 다음 단계 신경망을 생성하고, 상기 다음 단계 신경망을 상기 현 단계 신경망으로 교체하는 단계를 반복하는지능형 운량 측정 방법."}
{"patent_id": "10-2021-0182137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항 또는 제7 항에 따른 방법을 컴퓨터 상에서 실행하기 위한 프로그램을 기록한 컴퓨터로 독출 가능한 기록매체."}
{"patent_id": "10-2021-0182137", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 지능형 운량 측정 장치 및 방법에 관한 것으로, 구름이 포함된 컬러 영상을 획득하는 영상 획득 모듈; 현 단계 신경망을 이용하여 획득한 상기 컬러 영상을 구름 영역과 구름 이외의 영역으로 판별하여 구름 판별 영 상을 생성하는 구름 판별 신경망 모듈; 판별된 상기 구름 판별 영상을 참고하여 운량을 연산하는 운량 연산 (뒷면에 계속)"}
{"patent_id": "10-2021-0182137", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 운량 측정 분야에 관한 것으로, 특히 측정오차가 큰 데이터를 선별하여 신경망 추가 학습을 수행하는 지능형 운량 측정 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0182137", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "운량계(Cloud meter)는 구름 영상을 획득하고 전체 하늘의 면적중 구름이 차지하는 면적이 몇 % 인지를 측정하 는 장치이다. 기상분야에서 구름이 차지하는 비율을 측정하는 것은 아주 중요한 요소인데, 아직은 구름의 양(비 율)을 측정하는 운량계 신호처리 장치가 성능이 부족하여, 사람이 목측으로 측정하고 있다. 하늘의 구름 사진을 이용하여 운량을 측정하는 기존 방법은 R, G, B 색상을 이용한다. 이와 같은 방법의 원리는 빛의 레일리 산란(Rayleigh scattering)과 미 산란(Mie Scattering)을 이용한 것이다. 하늘의 공기 입자의 경 우, 빛의 파장보다 작기 때문에 레일리 산란이 크게 발생하며, 그 결과 하늘이 파랗게 나타난다. 그러나 구름의 수중기와 같이 입자가 큰 물질에 의하여 빛이 산란할 경우, 미 산란이 발생하여 모든 파장의 빛이 산란되어 하 얗게 나타난다. 따라서 기존 R, G, B 색상을 이용한 방법의 경우, 구름이 포함된 하늘 이미지에서 R, G, B 색상을 분리하여, 레 드(Red)와 블루(Blue) 파장의 비 또는 레드(Red)와 그린(Green) 파장의 비를 이용하여 구름을 분류하였다. 특히 기존 R, G, B 색상을 이용한 방법은 각각의 비의 특정 값을 임계값으로 사용하여 구름을 분류하였다. 즉, 도 1에 도시된 바와 같이, 이미지를 도출하고(SKY Image call), 왜곡을 보정한 후(Correction of radial distortion), RGB 컬러를 분리한다(RGB color separation). 이후 레드(Red)가 특정값 θ1 (예를 들어 60) 이하 인 영역의 경우 구름이 없는 것으로 판별한다. 또, 레드(Red)가 특정값 θ1 (예를 들어 60)을 초과하는 영역의 경우 R/G > 특정값 θ2 (예를 들어 0.95)이고 R/B > 특정값 θ3 (예를 들어 0.85)을 만족하지 않으면 구름이 없 는 영역이고, 이 조건을 만족하면 다시 판별하는데, R,G,B 각각의 값이 모두 특정값 θ4 (예를 들면 240) 이상이 면 구름이 없다고 보고, 이외의 영역은 구름으로 판별한다. 이런 작업을 거친 후 구름 영역의 면적과 전체 면적 (구름 영역과 구름이 없는 영역의 합)으로 운량을 연산한다(Calculate the amount of the cloud coverage). 여 기서 상기 특정값 θ1 내지 θ4 는 사용자가 미리 설정할 수 있는 경계값들이다. 그러나, 이러한 R, G, B 색상을 이용한 기존 방법은 낮의 태양과 밤의 달과 같은 밝은 물체에 의하여 카메라 센 서의 포화(Saturation) 현상(예를 들면, 역광)이 발생하면 측정할 수 없기 때문에 별도의 태양을 가리는 장치가 필요하며, 태양 또는 달에 의하여 구름에 의하여 빛이 반사되어 밝게 빛나는 부분, 또는 구름과 태양의 위치 또 는 구름의 두께에 의하여 발생하는 구름의 어두운 부분을 측정하지 못하는 경우가 발생한다. 따라서, 운량 측정에 영향을 주는 외부 환경 요소를 차단하는 별도의 장치를 구비하거나 정밀한 측정이 어려워 정밀도를 높이는 데에 한계가 있어 별도의 장치 없이도 정확하게 운량 측정을 수행하는 발명의 필요성이 대두되 었다. 선행기술문헌 특허문헌 (특허문헌 0001) (선행문헌 1) 한국등록특허 제1709860호(“전천 하늘 영상자료의 RGB 컬러를 이용한 전운량 산 출방법 및 시스템”, 등록일: 2017년02월17일)"}
{"patent_id": "10-2021-0182137", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 종래의 문제점을 해결하기 위하여, 신경망 기반의 고성능 인공지능을 도입하여 다양한 대기 환경 변 화 잡음이 포함된 스카이뷰 영상에서도 정밀한 구름 판별이 가능하도록 측정오차가 큰 데이터로 신경망 추가 학 습을 수행하여 정확도를 향상시킨 지능형 운량 측정 장치 및 방법을 제공한다."}
{"patent_id": "10-2021-0182137", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 지능형 운량 측정 장치는, 구름이 포함된 컬러 영상을 획득하는 영상 획득 모듈; 신경망 학습 모듈로부터 장착되는 신경망을 현 단계 신경망으로 인식하고 학습에 사용된 데이터를 현 단계 학습 데이터로 인식하고 상기 현 단계 신경망을 이용하여 획득한 상기 컬러 영상을 구름 영역과 구름 이외의 영역으 로 판별하여 구름 판별 영상을 생성하는 구름 판별 신경망 모듈; 판별된 상기 구름 판별 영상을 참고하여 운량 을 연산하는 운량 연산 모듈; 상기 영상 획득 모듈로부터 획득한 영상에서 RGB(Red Green Blue) 색상을 분리하 고, 분리된 색상값을 기설정된 RGB(Red Green Blue) 경계값(θ)과 비교하여 RGB 색상을 이용한 대조군 구름 판 별 영상을 생성하고, 상기 구름 판별 신경망 모듈로부터 획득한 구름 판별 영상과 상기 대조군 구름 판별 영상 의 절대차 평균값이 기설정된 임계값 이상일 경우, 상기 대조군 구름 판별 영상에 대응하는 컬러 영상을 다음 단계의 추가 학습 데이터로 선별하는 학습영상 선별 모듈; 및 상기 학습영상 선별 모듈로부터 얻은 다음 단계의 추가학습 데이터를 상기 현 단계의 학습 데이터에 추가하여 다음 단계 학습 데이터를 생성하고, 상기 다음 단계 학습 데이터를 이용하여 상기 현 단계 신경망을 추가 학습시켜 다음 단계 신경망을 생성하고, 상기 다음 단계 신경망을 상기 구름 판별 신경망 모델의 신경망으로 교체 장착하는 신경망 학습 모듈;을 포함할 수 있다. 본 발명의 다른 양태로서, 본 발명의 일 실시예에 따른 지능형 운량 측정 방법은, 구름이 포함된 컬러 영상을 획득하는 단계; 구름 판별 신경망 모듈에 장착된 신경망을 현 단계 신경망으로 인식하고 학습에 사용된 데이터 를 현 단계 학습 데이터로 인식하고, 상기 현 단계 신경망을 이용하여 획득한 상기 컬러 영상을 구름 영역과 구 름 이외의 영역으로 판별하여 구름 판별 영상을 획득하는 단계; 판별된 구름 판별 영상을 참고하여 운량을 연산 하는 단계; 획득한 상기 컬러 영상에서 RGB(Red Green Blue) 색상을 분리하고, 분리된 색상값을 기설정된 RGB(Red Green Blue) 경계값(θ)과 비교하여 RGB 색상을 이용한 대조군 구름 판별 영상을 생성하고, 상기 구름 판별 영상과 상기 대조군 구름 판별 영상의 절대차 평균값이 기설정된 임계값 이상일 경우, 상기 대조군 구름 판별 영상에 대응하는 컬러 영상을 다음 단계 추가학습 데이터로 선별하는 단계; 및 상기 선별된 추가학습 데이 터를 상기 현 단계 학습 데이터에 추가하여 추가학습용 다음 단계 학습 데이터를 생성하고, 상기 현 단계 신경 망에 상기 다음 단계 학습 데이터를 학습시켜 다음 단계 신경망을 생성하고 상기 다음 단계 신경망을 상기 구름 판별 신경망 모듈에 장착하는 단계;를 포함할 수 있다. 또한, 본 발명은 본 발명의 일 실시예에 따른 상기 방법을 컴퓨터 상에서 실행하기 위한 프로그램을 기록한 컴 퓨터로 독출 가능한 기록 매체를 제공할 수 있다."}
{"patent_id": "10-2021-0182137", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 측정 에러를 발생시키는 다양한 대기 환경 변화 잡음 영상들을 따로 수집하여 기존 학습 데이터에 추가하는 것으로 추가적인 신경망 학습을 진행함으로써, 목표로 하는 학습 방향을 유지하면 서 특정 잡음에 대한 강인성을 높여 구름판별 정확도를 향상시킬 수 있다."}
{"patent_id": "10-2021-0182137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 실시형태를 설명한다. 그러나 본 발명의 실시형태는 여러 가지의 다른 형태로 변형될 수 있으며, 본 발명의 범위가 이하 설명하는 실시형태로만 한정되는 것은 아니다. 도면에서의 요 소들의 형상 및 크기 등은 더욱 명확한 설명을 위해 과장될 수 있으며, 도면상의 동일한 부호로 표시되는 요소 는 동일한 요소이다. 도 2는 본 발명의 일 실시예에 따른 신경망 추가 학습을 수행하는 지능형 운량 측정 장치의 내부 블록도이며, 본 발명의 일 실시예에 따른 운량 측정 장치는 영상 획득 모듈, 구름 판별 신경망 모듈, 운량 연산 모듈, 신경망 학습 모듈, 학습영상 선별 모듈을 포함할 수 있다. 구체적으로, 영상 획득 모듈은 구름이 포함된 컬러 영상을 획득할 수 있다. 이러한 영상 획득 모듈은 어안 렌즈를 포함한 전천 카메라를 포함할 수 있다. 전천 카메라로 획득한 컬러 영상은 어안렌즈에 의한 왜곡이 있으므로, 영상 획득 모듈은 이러한 어안렌즈 에 의한 왜곡을 보정할 수 있다. 또한, 영상 획득 모듈은 획득된 컬러 영상 중 원형 이외의 부분은 검정색 으로 채울 수 있다. 또한, 본 발명의 일 실시예에 따른 구름 판별 신경망 모듈은 신경망을 포함할 수 있으며, 상기 신경망은 상기 영상 획득 모듈에서 획득한 컬러 영상을 입력으로 받아서 구름 판별 영상을 출력할 수 있다. 상기 구 름 판별 영상은 상기 컬러 영상에서 구름 부분과 구름 이외 부분을 구별할 수 있으며, 구름 부분은 1, 그 외 부 분은 0으로 구성되는 이진영상일 수 있다. 일 실시예로서, 상기 신경망 학습 모듈은 상기 컬러 영상을 학습 데이터로 하여 구름 판별을 할 수 있도록 신경망을 학습시킬 수 있으며, 상기 신경망은 구름 판별 신경망 모듈에 장착되어 운영될 수 있다. 즉, 학습 데이터는 심층 학습 모델인 구름 판별 신경망 모듈의 신경망 학습에 사용되며, 예를 들면 8000개 의 학습 데이터를 확보하여 학습 데이터의 70% 내지 80%는 심층 학습 모델인 영상 변환 모듈의 학습에, 나머지 는 성능을 검증하는데 사용될 수 있다. 학습 데이터의 구체적인 수 및 비율은 본 발명의 이해를 돕기 위한 것으 로, 그 수나 비율은 작업자나 통상의 기술자의 필요에 따라 변형되어 실시될 수 있음에 유의하여야 한다. 한편, 구름 판별 신경망 모듈은 별도의 영상 변환 모듈을 포함할 수 있다. 본 발명의 일 실시예에 따른 영 상 변환 모듈은 획득한 컬러 영상을 구름 영역과 구름 이외의 영역을 포함하는 이진 영상으로 변환할 수 있다. 이러한 영상 변환 모듈은 기 수집된 컬러 영상과 기 수집된 컬러 영상으로부터 생성된 이진 영상을 하나의 쌍으 로 한 학습 데이터를 이용하여 학습시킨 심층 학습 모델일 수 있다. 본 발명의 일 실시 형태에 의하면, 상술한 심층 학습 모델은 픽스투픽스(pix2pix) 모델일 수 있다. 일 실시예로서, 영상 획득 모듈에서 컬러 영상을 획득하면, 영상 변환 모듈이 컬러 영상을 이진 영상으로 변환할 수 있으며, 바이너리 값이 '0'인 검정색 영역은 구름이 아닌 영역이며, 바이너리 값이 '1'인 흰색 영역 은 구름 영역이다. 구름 판별 신경망 모듈 내의 영상 변환 모듈이 영상을 이진 영상으로 변환하는 것도 학습 데이터를 통해 학습할 수 있으며, 예를 들면 8000개의 학습 데이터를 확보하여 학습 데이터의 70% 내지 80%는 심층 학습 모델 인 영상 변환 모듈의 학습에, 나머지는 성능을 검증하는데 사용될 수 있다. 학습 데이터의 구체적인 수 및 비율 은 본 발명의 이해를 돕기 위한 것으로, 그 수나 비율은 작업자나 통상의 기술자의 필요에 따라 변형되어 실시 될 수 있음에 유의하여야 한다. 또한, 학습 데이터에 사용되는 컬러 영상은 적어도 역광이 있는 컬러 영상, 일출시의 컬러 영상 및 일몰시의 컬 러 영상 등 다양한 조건의 영상을 포함하도록 함으로써, 측정 오차를 보다 줄일 수 있는 이점이 있다. 본 발명의 일 실시예에 따른 운량 연산 모듈은 상기 구름 판별 영상의 구름 분포로부터 운량을 계산한다. 구체적으로, 운량 연산 모듈은 운량을 연산할 때, 구름 판별 신경망 모듈이 판별한 구름 판별 이진 영상에서 1인 영역을 구름 영역으로, 0인 영역을 구름 영역이 아닌 영역으로 하여 운량을 연산할 수 있다. 일 실시예로서, 연산된 운량을 운량 디스플레이부에 띄워 사용자가 실시간으로 운량을 파악하도록 사용자 편의를 도모할 수 있다. 또한, 도 2에 도시된 바와 같이, 본 발명의 일 실시예에 따르면, 상기 영상 획득 모듈로부터 획득한 컬러 영상을 초기학습 데이터로 이용하여 구름 판별 학습을 수행하고, 상기 학습영상 선별 모듈로부터 얻은 영 상을 상기 초기학습 데이터에 추가하여 추가적인 학습을 수행하는 신경망 학습 모듈을 포함할 수 있다. 구체적으로, 도 3에 도시된 바와 같이, 신경망 학습 모듈은 초기학습 데이터 생성부 및 추가학습 데 이터 생성부를 포함할 수 있으며, 상기 초기학습 데이터 생성부에 의해 생성된 초기학습 데이터와 추 가학습 데이터 생성부에서 생성된 추가학습 데이터를 이용하여 학습을 수행하는 GAN 신경망 학습부를 포함할 수 있다. 상기 GAN 신경망 학습부에서 구름 영역과 구름 영역이 아닌 영역을 학습 시켜, GAN 신경망 학습부가 학습 완료되면 학습 완료된 신경망을 구름 판별 신경망 모듈에 장착할 수 있다. 즉, 본 발명에서 신경망의 측정 정밀도를 높이기 위하여 신경망의 추가학습이 필요할 시에는 운량 측정과정에서 추가학습 데이터를 획득할 수 있다. 본 발명의 일 실시예에 따른 학습영상 선별 모듈은, 상기 영상 획득 모듈로부터 획득한 영상에서 RGB(Red Green Blue) 색상을 분리하고, 분리된 색상값을 기설정된 RGB(Red Green Blue) 경계값(θ)과 비교하여 RGB 색상을 이용한 대조군 구름 판별 영상을 생성하고, 상기 구름 판별 신경망 모듈로부터 획득한 구름 판 별 영상과 상기 대조군 구름 판별 영상의 절대차 평균값이 기설정된 임계값 이상일 경우, 상기 대조군 구름 판 별 영상에 대응하는 컬러 영상을 추가 학습 데이터로 선별할 수 있다. 일정 수 이상 추가학습 데이터 영상이 모이면, 신경망 학습 모듈은 상기 추가학습 데이터를 기존의 신경망 학습에 사용한 학습 데이터에 추가하여 새로운 학습 데이터를 생성하고 이를 이용하여 기존의 신경망을 더 학습 시켜서 새로운 신경망을 생성하고, 이 새로운 신경망을 상기 구름 판별 신경망 모듈에 장착할 수 있다. 신경망 학습은 상기 학습 데이터에 수집된 컬러 영상과 컬러 영상으로부터 생성된 구름판별 영상을 하나의 쌍으 로 한 학습 데이터를 이용하여 신경망 모델을 학습시킬 수 있다. 본 발명의 일 실시 형태에 의하면, 상술한 신 경망은 픽스투픽스(pix2pix) 모델일 수 있다. 상술한 바와 같이, 신경망 학습에 사용되는 학습 데이터의 80% 정도는 학습에 사용되고 20% 정도는 학습된 모델 의 성능 테스트에 사용될 수 있다. 예를 들어, 초기 신경망 학습에 10,000개의 학습 영상이 있다면 8,000개는 학습에 사용하고 2,000개는 테스트 데이터로 사용할 수 있다. 그 다음 추가 학습에서 10,000개가 더 추가 되면, 학습 데이터의 16,000개는 학습에 사용되고, 4,000개는 테스트에 사용될 수 있다. 학습 데이터의 구체적인 수 및 비율은 본 발명의 이해를 돕기 위한 것으로, 그 수나 비율은 작업자나 통상의 기술자의 필요에 따라 변형되 어 실시될 수 있음에 유의하여야 한다. 또한, 학습 데이터에 사용되는 컬러 영상은 적어도 역광이 있는 컬러 영상, 일출시의 컬러 영상 및 일몰시의 컬 러 영상 등 다양한 조건의 영상을 포함하도록 함으로써, 측정 오차를 보다 줄일 수 있는 이점이 있다. 구체적으로, 초기학습 데이터 생성부에 의해 생성된 초기학습 데이터를 이용하여 사용자가 원하는 에폭 (epoch)만큼 학습이 진행되어 학습이 완료되고 나면, 지금껏 학습에 사용되지 않았던 검증용 스카이뷰 영상들을 사용하여 초기 학습된 GAN 신경망 학습부를 테스트 할 수 있다. 테스트가 끝난 신경망은 상기 구름 판별 신경망 모듈에 장착되어 운영될 수 있다. 한편, 본 발명의 일 실시예에 따른 구름 판별 신경망 모듈에는 신경망 학습 모듈에서 학습 완료된 최 신의 신경망이 장착될 수 있으며, 장착된 신경망을 통해 구름 판별을 수행할 수 있다. 구름판별 신경망 모듈 은 장착되는 현재의 신경망을 현 단계(k) 신경망(Gk)으로 인식하고, 학습에 사용된 데이터를 현 단계 학습 데이터(Tk)로 인식한다. 여기서, k는 학습단계를 의미한다. 도 3에 도시된 바와 같이, 신경망 학습 모듈은 초기학습 데이터 생성부, 추가학습 데이터 생성부 , GAN 신경망 학습부을 포함할 수 있다. 상기 초기학습 데이터 생성부는 상기 신경망을 처음(k=1)으로 학습시키는 초기학습 데이터(T1)를 생성하고, 상기 추가학습 데이터 생성부는 상기 현 단계(k) 신경망을 추가로 더 학습시키기 위해 다음 단 계(k+1)에 추가할 추가학습 데이터(Ak+1)를 생성한다. 여기서 학습 데이터는 스카이뷰 컬러 영상과 목표영상을 한 쌍으로 묶은 데이터들의 집합이다. 여기서 목표영상은 상기 컬러 영상에 대한 구름 판별 영상을 의미한다. 목표영상인 구름 판별 영상은 다음과 같은 방법으로 구해질 수 있다. 상기 추가학습 데이터 생성부는 상기 학습영상 선별 모듈로부터 선별된 상기 컬러 영상에 대해 서로 다른 실수 값을 갖는 기설정된 경계값 풀로부터 생성된 모든 (θ2, θ3) 경계값 그룹 전부를 이용하여 대조군 구 름 판별 영상들을 생성하며, 상기 대조군 구름 판별 영상들 중에서, 현 단계(k) 신경망(Gk)에 상기 컬러 영상을 입력하여 출력한 구름 판별 영상과의 절대차 평균값이 가장 작은 대조군 구름 판별 영상을 추출하고, 추출된 대 조군 구름 판별 영상과 이에 대응하는 컬러 영상을 추가학습 데이터(Ak+1)를 생성하고, 이를 현 단계 학습 데이 터(Tk)에 추가하여 다음 단계 학습 데이터(Tk+1)를 생성할 수 있다. 즉, 영상 획득 모듈로부터 획득한 컬러 영상에 대해, R, G, B 색상을 이용한 구름 판별 방법으로 모든 (θ 2, θ3) 경계값 그룹을 이용하여 생성한 구름판별 영상들 중에서 현 단계(k번째) 신경망(Gk)의 출력으로 출력된 구름 판별 영상과의 절대차 비교에서 절대차 평균값이 가장 작은 구름 판별 영상을 목표영상으로 선정할 수 있 다. 구체적으로, R, G, B 색상을 이용한 구름 판별 방법에서 다른 실수 값을 갖는 여러 θ2값과 θ3값을 사전에 설정 하여 많은 (θ2, θ3) 그룹 값을 생성하고 기호 j를 이용하여 순차적으로 상기 각 j번째 (θ2, θ3)그룹 값을 인 식할 수 있다. j는 양의 실수일 수 있다. 예를 들어 모든 (θ2, θ3)그룹 수가 다섯 개(j=5)인 경우에, j=1의 (θ2, θ3) 경계값 그룹은 (0.95, 0.85), j=2의 (θ2, θ3) 경계값 그룹은 (0.95, 0.80), j=3의 (θ2, θ3) 경계값 그룹은 (0.95, 0.75), j=4의 (θ2, θ 3) 경계값 그룹은 (0.90, 0.85), j=5의 (θ2, θ3) 경계값 그룹은 (0.85, 0.85) 등으로 사전에 설정된 경계값 풀 로부터 무작위로 선택하거나, 또는 사전에 설정된 경계값 그룹대로 (θ2, θ3) 경계값 그룹이 설정될 수 있다. 추가학습 데이터 생성부는 j=1~5의 경계값을 이용하여 R, G, B 색상을 이용한 대조군 구름 판별 영상들을 생성할 수 있다. 또한, 구름판별 신경망 모듈에 장착되어 있는 현 단계 신경망(Gk)에 상기 대조군 구름 판별 영상을 생성하 는데 사용되었던 컬러 영상을 입력하여 구름 판별 영상을 출력할 수 있다. 따라서, 추가학습 데이터 생성부는 j=1~5를 이용하여 판별된 대조군 구름 판별 영상들과 상기 구름판별 신 경망 모듈로부터 출력된 구름 판별 영상 간의 절대차 평균값을 구하고, 상기 절대차 평균값이 가장 작은 j 번째 대조군 구름 판별 영상을 목표영상으로 추출할 수 있다. 더하여, 추가학습 데이터 생성부는 목표영상으로 상기 추출된 대조군 구름 판별 영상과 이에 사용되었던 컬러 영상을 쌍을 이루는 추가 학습 영상으로 선택하여 다음 단계 추가학습 데이터(Ak+1)에 추가하고 이를 현 단 계 학습 데이터(Tk)에 추가하여 다음 단계 학습 데이터(Tk+1)를 생성할 수 있다.또한, 예를 들면, 상기 추가학습 데이터 생성부는 상기 학습영상 선별 모듈이 다음 단계(k+1)로 학습 시킬 컬러 영상을 선별하면 선별된 컬러 영상에 대해 R, G, B 색상을 이용한 구름 판별 방법으로 대조군 구름 판별 영상들을 생성할 수 있다. 구체적으로, 선별된 컬러 영상에 대해 상기 순차적으로 j=1, 2, 3, 4,쪋번호에 해당하는 각 (θ2, θ3) 그룹 값 을 입력해서 R, G, B 색상을 이용한 구름 판별 방법을 통해 생성한 구름판별 영상들 중에서 상기 현 단계(k) 학 습된 신경망(Gk )을 장착한 구름판별 신경망(Gk) 모듈의 출력영상인 구름 판별 영상과 비교를 수행할 수 있다. 비교 결과, 가장 유사한(두 영상의 절대차 평균값이 가장 적은) 영상을 추가 학습할 구름판별 영상으로 선정할 수 있다. 선정된 추가학습 구름 판별 영상의 경우에, 필요 시에는 추가적으로 전문가의 전문 지식 기반의 데이 터베이스(DB)를 이용하여 눈에 띄는 오차가 있을 경우에는 이를 보정할 수도 있다. 여기서 선정된 추가학습 구 름 판별 영상을 신경망 학습의 목표영상으로도 칭한다. 신경망 학습 절차를 도시한 도 4에서는 이를 목표영상으 로 기술하였다. 한편, 도 4는 본 발명의 일 실시예에 따른 구름 판별 신경망 학습을 설명하는 모식도이다. 도 4에서 학습단계 k는 신경망의 학습 횟수를 의미한다. 여기서 k=1은 초기학습을 의미하고 첫 번째 추가 학습 시에는 k=2이고, 두 번째 추가 학습시에는 k=3이 된다. 그리고 k번째 학습이 되는 생성자 신경망은 Gk, 판별자 신경망은 Dk로 표시한다. Gk와 Dk는 k번째 학습 데이터(Tk)의 영상들을 이용하여 학습을 진행한다. k번째 학습 데이터(Tk)는 k-1번째 학습에 사용한 학습 데이터(Tk-1)와 학습영상 선별 모듈에서 k번째 학습을 위하여 추 가학습 데이터로 선별한 데이터(Ak)의 합으로 구성된다; Tk=Tk-1+Ak. 그리고 생성자 신경망(Gk)의 학습은 Gk-1를 시작점으로 하여 학습을 시작하며, 판별자 신경망(Dk)의 학습은 Dk-1를 시작점으로 하여 학습을 시작한다. 이때 Gk-1과 Dk-1는 K-1번째 학습에서 학습 완료된 신경망이다. k번째 학습을 함에 있어서, 신경망 학습 모듈은 GAN 신경망 학습부를 통해 GAN 신경망을 학습시키며, 학습된 GAN 신경망을 구름 판별 신경망 모듈에 장착함으로써 상기 구름 판별 신경망 모듈은 가장 최 근에 학습 완료한 GAN 신경망을 장착할 수 있다. 따라서, 상기 학습영상 선별 모듈은 하기 식을 통하여 상기 구름 판별 신경망 모듈로부터 획득한 구 름 판별 영상( )과 상기 대조군 구름 판별 영상( )의 절대차 평균값이 기설정된 임계값(TH) 이상인지 판단하며, 상기 절대차 평균값이 기설정된 임계값 이상일 경우, 상기 대조군 구름 판별 영상에 대응하 는 컬러 영상을 추가 학습 데이터로 선별하고, 상기 추가 학습 데이터를 이용하여 GAN 신경망을 학습시켜 가장 최근에 학습 완료된 GAN 신경망을 구름 판별 신경망 모듈에 장착할 수 있다."}
{"patent_id": "10-2021-0182137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 는 상기 영상 획득 모듈이 i번째 획득한 컬러 영상을 입력으로 사용한 상기 구름 판별 신 경망 모듈의 출력 영상인 구름 판별 영상의 (x, y) 위치에서의 영상 픽셀 값이고, 는 상기 영상 획득 모듈이 i번째 획득한 컬러 영상에 대해 RGB 경계값을 비교하여 판별한 구름 판별 영상에서 j번째 (θ 2, θ3) 경계값 그룹을 이용하여 얻은 구름판별 영상의 (x, y) 위치에서의 영상 픽셀 값이고, TH는 기설정된 임 계값이며, NxN은 영상 크기를 나타내는 픽셀이고, θ2와 θ3는 기설정된 RGB 경계값이다. 오차가 크다는 것은 데이터에 문제가 있다는 것인 바, 오차가 큰 데이터를 추출하여 학습시킴으로써 신경망의 정확도를 높일 수 있다. 또한, 상기 학습영상 선별 모듈에서 상기 영상은, 서로 다른 실수 값을 갖는 기설정된 경계값 풀 로부터 생성된 모든 (θ2, θ3) 경계값 그룹을 이용하여 생성된 대조군 구름 판별 영상들이며, 상기 모든 (θ2, θ3) 경계값 그룹을 이용하여 획득한 모든 대조군 구름 판별 영상이 상기 식을 만족하는 경우, 상기 대조군 구름판별 영상에 대응하는 컬러 영상을 추가 학습 데이터로 선별할 수 있다. 상술한 바와 같이, 기설정된 경계값 그룹들을 이용하여 RGB를 이용한 구름 판별 방법으로 대조군 구름 판별 영 상들을 생성할 수 있으며, 생성된 대조군 구름 판별 영상들이 모두 상기 임계값(TH) 이상이어야 대조군 구름 판 별 영상에 이용된 컬러 영상이 추가 학습 데이터로 선별될 수 있다. 더하여, 이때 상기 영상과 상기 영상 속에 태양이나 달을 포함하는 부분이 존재할 경우, 태 양이나 달 부분은 제거하고 절대차 평균값을 비교할 수 있다. 태양이나 달과 같이 빛을 내거나 건물 등과 같이 구름 판단과 상관 없는 고정 구조물의 잡음이 존재할 경우, 해당 부분을 제거하고 비교를 수행하여 비교 정확도 를 높일 수 있다. 도 4에 도시된 바와 같이, 학습단계 k번째인 신경망 학습에 있어서, GAN 신경망 학습부의 GAN 신경망은 생 성자 신경망(Gk, 410)과 판별자 신경망(Dk, 420)을 포함하는 조건부 GAN(Conditional Generative Adversial Networks) 모델이다. 상기 생성자 신경망은 초기학습시 G1, 추가학습으로 k번째 학습시 Gk이며, 판별자 신경망는 초기학습 시 D1, 추가학습으로 k번째 학습시 Dk이다. 도 4에 도시된 바와 같이, 학습 데이터에서 선택된 하나의 컬러 영상이 생성자 신경망(Gk, 410)에 입력된다. 이 입력 영상은 k번째 학습 데이터(Tk)에 등록되어 있는 컬러 영상이다. 즉, GAN 신경망의 생성자의 “입력” 부에 영상 획득 모듈에서 획득한 컬러 영상이 입력되고, 생성자는 \"출력\"부에서 출력영상(G)을 출력 한다. 판별자 신경망(Dk, 420)은 생성자의 출력영상인 출력(G)을 입력 받아 상기 출력(G)을 가짜(fake, 0) 영상으로 판별하도록 학습하고, 목표영상을 입력 받을 때는 진짜(real, 1)로 판별하도록 학습을 수행한다. 여기 서 목표영상은 학습 데이터(Tk)에 등록되어 있는 영상으로 생성자에 입력되는 컬러영상에 대응하는 절대차 평균 값이 가장 작은 대조군 구름판별 영상이다. 그리고 나서 생성자 신경망은 판별자 신경망이 진짜로 판별할 수 있는 출력(G) 영상을 출력하도록 생성자 신경망을 재학습 시킨다. 이와 같이 생성자 신경망과 판별자 신경망의 경쟁 학습을 통하여 생성자는 판별자가 진짜 로 판별할 정도로 목표영상에 근접한 구름판별 영상을 출력하도록 학습을 수행한다. 한편, 운량 연산 모듈은 구름 판별 신경망 모듈이 판별한 구름 영역으로부터 운량을 연산할 수 있다. 여기서, 운량은 컬러 영상의 전체 영역 대비 구름 영역의 비율일 수 있다. 구체적으로, 운량 연산 모듈은 운량을 연산할 때, 구름 판별 신경망 모듈이 판별한 구름 영역 또는 변환한 이진 영상에서 이진 영상의 바이너리 값인 1인 영역을 구름 영역으로, 0인 영역을 구름 영역이 아닌 영 역으로 하여 운량을 연산할 수 있다. 일 실시예로서, 연산된 운량을 운량 디스플레이부에 띄워 사용자가 실시간으로 운량을 파악하도록 사용자 편의 를 도모할 수 있다. 도 5는 본 발명의 일 실시예에 따라 신경망 추가 학습에서 배제되는 한 쌍의 학습 데이터, 도 6은 본 발명의 일 실시예에 따라 신경망 추가 학습에서 사용되는 한 쌍의 학습 데이터를 도시한 도면이다. 여기서 (a)는 영상획득 모듈에서 획득되는 영상이며, (b)는 구름판별 신경망모듈의 신경망이 판별하는 구름판별 영상이며, (c)는 신경망 학습의 최종 목표영상인 구름판별 영상이다. 본 발명의 일 실시예에 따르면, 구체적으로 도 5는 학습 완료된 GAN 신경망을 이용한 구름판별 검사에서 신경망 의 출력영상(b)이 목표하는 목표영상(c)과의 절대차 평균값 비교에서 임계값 TH 미만이 나온 것으로, 두 영상의 일치도가 매우 높아서 추가 학습 영상에 포함되지 않은 경우의 실험 결과이다. 도 6은 학습 완료된 GAN 신경망을 이용한 구름판별 검사에서 신경망의 출력영상(b)이 목표하는 목표영상(c)와의 절대차 평균값 비교에서 임계값 TH 이상이 나온 것으로, 출력 오차가 커서, 즉 두 영상의 일치도 매우 낮아서 추가학습 영상에 포함된 경우의 실험 결과이다. 도 6에 도시된 바와 같이, 출력영상의 점선 원형 부분은 눈에 띄는 오류 부분으로 영상의 이런 구역에 대해서는 신경망이 추가적인 학습을 통하여 오류를 보정할 필요가 있는 경우이다. 약 8,000개의 스카이뷰 영상을 이용하여 초기 학습을 수행한 신경망을 이용한 기초 실험에서, 스카이뷰 영상으 로부터 GAN 신경망의 평균 측정오차는 약 2%였고, 도 1과 같은 전통적인 기존의 R, G, B 색상을 이용한 구름 판 별 방법의 평균 측정오차는 약 10%였는 바, 스카이뷰 영상에는 측정 요소들의 변동성도 크고 강한 잡음도 섞여 있어서, 종래의 신호처리 알고리즘으로는 높은 정밀도의 운량을 측정하는 것은 어려운 일이었다. 반면, 본 발명 의 일 실시예에 따른 운량 측정 장치는 다양한 변동성에도 강인하면서도 높은 측정 정밀도를 갖는 특징이 있다. 오차가 큰 데이터를 따로 추출함과 동시에 기존 학습 데이터에 추가함으로써 초기 목표를 유지함과 동시에 오차 를 발생시키는 요소들을 보완하여 학습 효율을 극대화할 수 있다. 도 7은 본 발명의 일 실시예에 따라 신경망 추가 학습을 수행하는 운량 측정 방법을 설명하는 흐름도이다. 도 7에 도시된 바와 같이, 본 발명의 일 실시예에 따른 운량 측정 방법은 구름이 포함된 컬러 영상을 획득하는 단계(S710), 신경망 학습 모듈로부터 장착된 신경망을 이용하여 획득한 상기 컬러 영상을 구름 영역과 구름 이 외의 영역으로 판별하는 단계(S720), 판별된 구름 판별 영상을 참고하여 운량을 연산하는 단계(S730), 대조군 구름 판별 영상을 생성하고, 상기 구름 판별 영상과 대조군 구름 판별 영상의 절대차 평균값이 기설정된 임계값 이상일 경우, 상기 대조군 구름 판별 영상에 대응하는 컬러 영상을 다음 단계 추가학습 데이터로 선별하는 단계 (S740) 및 추가학습 데이터를 포함한 새로운 학습 데이터를 이용하여 추가학습된 신경망을 생성하고 이를 장착 하는 단계(S750)를 포함할 수 있다. 상기 절대차 평균값이 기설정된 임계값 이상인 오차가 큰 컬러 영상에 대해 추가학습 데이터로 선별하는 단계 (S740)는 다음과 같이 구현될 수 있다. 단계(S720)에서, 구름 판별 신경망 모듈에 장착된 신경망을 현 단계 신경망으로 인식하고 학습에 사용된 데이터를 현 단계 학습 데이터로 인식할 수 있으며, 신경망 학습 모듈로부터 장착된 신경망이 현 단계 신경망이 될 수 있다. 단계(S740)에서, 대조군 구름 판별 영상을 생성할 때, 획득한 상기 컬러 영상에서 RGB(Red Green Blue) 색상을 분리하고, 분리된 색상값을 기설정된 RGB(Red Green Blue) 경계값(θ)과 비교하여 RGB 색상을 이용한 대조군 구 름 판별 영상을 생성할 수 있다. 상술한 내용과 중복되는 내용은 생략한다. 또한, 단계(S740)에서, k번째로 추가 학습된 신경망(Gk)을 사용하여 판별한 구름판별 영상과 R, G, B 색상을 이 용한 구름 판별 방법에서 모든 (θ2, θ3)그룹 값을 이용하여 생성한 구름판별 영상들과의 절대차 평균값 비교에 서 모두 임계값 이상으로 큰 오차를 가지면, 상기 구름 판별 영상에 대응하는 컬러 영상을 다음 단계(k+1번째) 의 추가학습 데이터(Ak+1)로 선별한다. 이때 상기 컬러영상에 대한 구름판별 영상인 목표영상도 함께 구한다. 구체적으로, 상기 컬러 영상에 대해, R, G, B 색상을 이용한 구름 판별 방법으로 모든 (θ2, θ3) 경계값 그룹을 이용하여 생성한 구름판별 영상들 중에서 신경망 출력으로 판별한 구름 판별 영상과의 절대차 비교에서 절대차 평균값이 가장 작은 구름판별 영상이 목표영상인 구름판별 영상으로 구해질 수 있다. 상기 추가학습 데이터(Ak+1)를 기존 신경망(Gk) 학습에 사용한 기존 k번째 학습 데이터(Tk)에 추가한 후에 다음 단계의 새로운 학습 데이터(Tk+1)가 생성될 수 있다. 단계(S750)에서는 상기 새로운 학습 데이터(Tk+1)를 이용하 여 기존 신경망(Gk)을 추가 학습시켜 성능이 향상된 새로운 신경망(Gk+1)을 생성한 한 후에 이를 구름판별 신경망 모듈에 장착하여 성능이 개선된 신경망을 운영할 수 있다. 본 발명의 일 실시예에 따른 지능형 운량 측정 방법에서 신경망의 성능개선이 만족스러울 때까지 위의 단계를 반복하면서 구름판별 성능이 향상된 신경망을 획득할 수 있다. 즉, 상기 절대차 평균값이 기설정된 임계값 미만이 될 때까지 추가학습 데이터로 선별하는 단계 및 새로운 신경 망(Gk+1)을 생성하는 단계를 반복할 수 있다.상술한 내용과 중복되는 내용은 명세서의 중복을 피하기 위해 생략하기로 한다. 상술한 본 발명의 일 실시 형태에 따른 지능형 운량 측정 방법은 컴퓨터에서 실행되기 위한 프로그램으로 제작 되어 컴퓨터가 읽을 수 있는 기록 매체에 저장될 수 있다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등을 포함한다. 또한, 컴퓨터가 읽을 수 있는 기 록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 그리고 상기 방법을 구현하기 위한 기능적인(function) 프로그램, 코드 및 코드 세그먼트들은"}
{"patent_id": "10-2021-0182137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 발명이 속하는 기술분야의 프로그래머들에 의해 용이하게 추론될 수 있다. 또한, 본 발명을 설명함에 있어, '~ 모듈'은 다양한 방식, 예를 들면 프로세서, 프로세서에 의해 수행되는 프로 그램 명령들, 소프트웨어 모듈, 마이크로 코드, 컴퓨터 프로그램 생성물, 로직 회로, 애플리케이션 전용 집적 회로, 펌웨어 등에 의해 구현될 수 있다. 본 발명은 상술한 실시형태 및 첨부된 도면에 의해 한정되지 아니한다. 첨부된 청구범위에 의해 권리범위를 한 정하고자 하며, 청구범위에 기재된 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 다양한 형태의 치환,"}
{"patent_id": "10-2021-0182137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "변형 및 변경할 수 있다는 것은 당 기술분야의 통상의 지식을 가진 자에게 자명할 것이다."}
{"patent_id": "10-2021-0182137", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 R, G, B 색상 비율을 이용한 운량 측정 방법을 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 신경망 추가 학습을 수행하는 지능형 운량 측정 장치의 내부 블록도이다. 도 3은 본 발명의 일 실시예에 따른 신경망학습모듈의 간단한 내부 블록도이다. 도 4는 본 발명의 일 실시예에 따른 구름 판별 신경망 학습을 설명하는 모식도이다. 도 5는 본 발명의 일 실시예에 따라 신경망 추가 학습에서 배제된 한 쌍의 학습 데이터를 도시한 도면이다. 도 6은 본 발명의 일 실시예에 따라 신경망 추가 학습에서 사용된 한 쌍의 학습 데이터를 도시한 도면이다. 도 7은 본 발명의 일 실시예에 따라 신경망 추가 학습을 수행하는 지능형 운량 측정 방법을 설명하는 흐름도이 다."}
