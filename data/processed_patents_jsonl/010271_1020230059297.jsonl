{"patent_id": "10-2023-0059297", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0162346", "출원번호": "10-2023-0059297", "발명의 명칭": "3D 포즈 추정을 위한 학습데이터 증강 장치 및 방법", "출원인": "서울대학교산학협력단", "발명자": "박성찬"}}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "3D 포즈 추정을 위한 학습데이터 증강 방법에 있어서,2차원 이미지에 등장하는 사람들 각각의 발 좌표를 수집하는 단계;수집된 상기 발 좌표들에 기초하여 3차원 공간의 바닥면(Ground plane)을 추정하는 단계;상기 바닥면의 법선 벡터에 수직인 두 기저 벡터(b1, b2)를 기준으로 적어도 한 사람을 이동 또는회전시키거나, 상기 바닥면을 이동 또는 회전시켜 3차원 자세 데이터를 생성하는 단계;상기 3차원 자세 데이터를 상기 2차원 이미지를 촬영한 카메라의 초점 거리 및 상기 2차원 이미지 좌표의 주점(principle point)에 기초하여 2차원 자세 데이터와 매핑하는 단계; 및상기 3차원 자세 데이터와 상기 2차원 자세 데이터 쌍을 학습데이터로 획득하는 단계를 포함하는,3D 포즈 추정을 위한 학습데이터 증강 방법."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 3차원 자세 데이터를 생성하는 단계는, 각 대상 사람을 3차원 공간상 상기 바닥면을 표현하는 2가지 상기 기저벡터를 따라 이동시키는 단계(PT:PersonTranslation); 및상기 PT에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하는 단계를 포함하고,상기 이동의 이동량은 상기 각 대상 사람의 중심 관절 위치가 상기 카메라 앞에 위치하고, 이미지 평면 상에 투사되게 하는 범위 내에서 랜덤하게 정해지는, 3D 포즈 추정을 위한 학습데이터 증강 방법."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 3차원 자세 데이터를 생성하는 단계는, 각 대상 사람을 상기 바닥면의 법선 벡터(Nornal vector)에 대해 회전시키는 단계(PR:Person Rotaion); 및상기 PR에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하는 단계를 포함하고,회전각도는 -45도 내지 45도 사이에서 랜덤하게 정해지는,3D 포즈 추정을 위한 학습데이터 증강 방법."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 3차원 자세 데이터를 생성하는 단계는, 상기 카메라의 주축(Principal Axis)을 따라 상기 바닥면을 이동시키는 단계(GPT:Ground Plane Translation);및상기 GPT에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하는 단계를 포함하고,이동량은 상기 복수 사람의 상기 카메라로부터의 상대위치를 고려하여 결정되는,공개특허 10-2024-0162346-3-3D 포즈 추정을 위한 학습데이터 증강 방법."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 3차원 자세 데이터를 생성하는 단계는, 상기 바닥면을 상기 카메라로부터 가까워지거나 멀어지는 방향으로 회전시키는 단계(GPR:Ground PlaneRotation); 및상기 GPR에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하는 단계를 포함하고,상기 회전량은 -30도 내지 30도 사이에서 랜덤하게 정해지는,3D 포즈 추정을 위한 학습데이터 증강 방법."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항 내지 제5항 중 어느 한 항에 있어서,상기 학습데이터의 증강의 순서는 PR, GPT, GPR, PT 순을 따르고, 상기 PT에서 각 대상사람의 중심좌표가 상기카메라 앞에 위치하고 이미지 평면 상에 투사되게 하는 값을 가지게 하는 범위 안에서 랜덤하게 정해지는,3D 포즈 추정을 위한 학습데이터 증강 방법."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,각 대상사람의 부피를 각 관절(각 키포인트)을 중심으로 3차원 구들의 집합으로 표현하는 단계를 더 포함하고,상기 구는 한명의 대상사람의 각 관절에 동일한 사이즈로 표현되고,상기 구들은 2차원 이미지 평면 상에 원으로 투사되며, 상기 원의 반경은 상기 3차원 구의 상기 카메라로부터의거리에 반비례하는,3D 포즈 추정을 위한 학습데이터 증강 방법."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,제1 사람에 대응하는 제1원과 제2 사람에 대응하는 제2원 간의 중심간의 거리를 측정하는 단계; 및상기 카메라로부터 더 가까운 상기 제1 사람의 상기 제1원의 반경과 상기 제1원과 상기 제2원 간의 중심간의 거리 간의 비교에 따라 상기 제1 사람이 상기 제2 사람을 가렸는지 여부를 판단하는 단계를 포함하는,3D 포즈 추정을 위한 학습데이터 증강 방법."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 제1 사람이 상기 제2 사람을 가렸는지 여부를 판단하는 단계는,상기 카메라로부터 더 가까운 상기 제1 사람의 상기 제1원의 반경보다 상기 제1원과 상기 제2원 간의 중심간의거리가 작은 경우, 상기 제1 사람이 상기 제2 사람을 가린 것으로 판단하는,3D 포즈 추정을 위한 학습데이터 증강 방법."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "프로세서; 및상기 프로세서와 연결되고, 상기 프로세서에서 수행되는 적어도 하나의 코드가 저장되는 메모리를 포함하고,공개특허 10-2024-0162346-4-상기 프로세서는,2차원 이미지에 등장하는 사람들 각각의 발 좌표를 수집하는 동작, 수집된 상기 발 좌표들에 기초하여 3차원 공간의 바닥면(Ground plane)을 추정하는 동작, 상기 바닥면의 법선 벡터에 수직인 두 기저 벡터(b1, b2)를 기준으로 적어도 한 사람을 이동 또는 회전시키거나, 상기 바닥면을 이동 또는 회전시켜 3차원 자세 데이터를 생성하는 동작, 상기 3차원 자세 데이터를 상기 2차원 이미지를 촬영한 카메라의 초점 거리 및 상기 2차원 이미지좌표의 주점(principle point)에 기초하여 2차원 자세 데이터와 매핑하는 동작, 및 상기 3차원 자세 데이터와상기 2차원 자세 데이터 쌍을 학습데이터로 획득하는 동작을 실행하는,3D 포즈 추정을 위한 학습데이터 증강 장치."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 프로세서는,상기 3차원 자세 데이터를 생성하는 동작으로서,각 대상 사람을 3차원 공간상 상기 바닥면을 표현하는 2가지 상기 기저벡터를 따라 이동시키는 동작(PT:PersonTranslation), 및 상기 PT에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하는 동작을 포함하고,상기 이동의 이동량은 상기 각 대상 사람의 중심 관절 위치가 상기 카메라 앞에 위치하고, 이미지 평면 상에 투사되게 하는 범위 내에서 랜덤하게 정해지는, 3D 포즈 추정을 위한 학습데이터 증강 장치."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서,상기 프로세서는,상기 3차원 자세 데이터를 생성하는 동작으로서,각 대상 사람을 상기 바닥면의 법선 벡터(Nornal vector)에 대해 회전시키는 동작(PR:Person Rotaion), 및 상기 PR에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하는 동작을 포함하고, 회전각도는 -45도 내지 45도 사이에서 랜덤하게 정해지는,3D 포즈 추정을 위한 학습데이터 증강 장치."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,상기 프로세서는,상기 3차원 자세 데이터를 생성하는 동작으로서,상기 카메라의 주축(Principal Axis)을 따라 상기 바닥면을 이동시키는 동작(GPT:Ground Plane Translation),및 상기 GPT에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하는 동작을 포함하고, 이동량은 상기 복수사람의 상기 카메라로부터의 상대위치를 고려하여 결정되는,3D 포즈 추정을 위한 학습데이터 증강 장치."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10 항에 있어서,상기 프로세서는,상기 3차원 자세 데이터를 생성하는 동작으로서,상기 바닥면을 상기 카메라로부터 가까워지거나 멀어지는 방향으로 회전시키는 동작(GPR:Ground PlaneRotation), 및 상기 GPR에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하는 동작을 포함하고, 상기 회공개특허 10-2024-0162346-5-전량은 -30도 내지 30도 사이에서 랜덤하게 정해지는,3D 포즈 추정을 위한 학습데이터 증강 장치."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 10 항 내지 제14항 중 어느 한 항에 있어서,상기 학습데이터의 증강의 순서는 PR, GPT, GPR, PT 순을 따르고, 상기 PT에서 각 대상사람의 중심좌표가 상기카메라 앞에 위치하고 이미지 평면 상에 투사되게 하는 값을 가지게 하는 범위 안에서 랜덤하게 정해지는,3D 포즈 추정을 위한 학습데이터 증강 장치."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 10 항에 있어서,각 대상사람의 부피를 각 관절(각 키포인트)을 중심으로 3차원 구들의 집합으로 표현하는 동작을 더 실행하고,상기 구는 한명의 대상사람의 각 관절에 동일한 사이즈로 표현되고,상기 구들은 2차원 이미지 평면 상에 원으로 투사되며, 상기 원의 반경은 상기 3차원 구의 상기 카메라로부터의거리에 반비례하는,3D 포즈 추정을 위한 학습데이터 증강 장치."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,제1 사람에 대응하는 제1원과 제2 사람에 대응하는 제2원 간의 중심간의 거리를 측정하는 동작, 및 상기 카메라로부터 더 가까운 상기 제1 사람의 상기 제1원의 반경과 상기 제1원과 상기 제2원 간의 중심간의 거리 간의 비교에 따라 상기 제1 사람이 상기 제2 사람을 가렸는지 여부를 판단하는 동작을 실행하는,3D 포즈 추정을 위한 학습데이터 증강 장치."}
{"patent_id": "10-2023-0059297", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 제1 사람이 상기 제2 사람을 가렸는지 여부를 판단하는 동작은,상기 카메라로부터 더 가까운 상기 제1 사람의 상기 제1원의 반경보다 상기 제1원과 상기 제2원 간의 중심간의거리가 작은 경우, 상기 제1 사람이 상기 제2 사람을 가린 것으로 판단하는,3D 포즈 추정을 위한 학습데이터 증강 장치."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 3D 포즈 추정을 위한 학습데이터 증강 장치 및 방법에 관한 것으로, 더욱 상세하게는 2차원 입력 데이 터로부터 3차원 자세를 추정하는 인공지능 모델 학습에 필요한 학습데이터를 증강하는 3D 포즈 추정을 위한 학습 데이터 증강 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 3D 포즈 추정을 위한 학습데이터 증강 장치 및 방법에 관한 것으로, 더욱 상세하게는 2차원 입력 데 이터로부터 3차원 자세를 추정하는 인공지능 모델 학습에 필요한 학습데이터를 증강하는 3D 포즈 추정을 위한 학습데이터 증강 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "3D 포즈 추정은 대상자의 수에 따라 3DSPPE(3D Single-Person Pose Estimation)와 3DMPPE(3D Multi-Person Pose Estimation)로 분류된다. 3DSPPE는 이미 광범위하게 연구되고 많은 응용 프로그램에 사용되고 있는 반면에, 3DMPPE는 아직 와일드 시나리 오에 거의 적용할 수 없는 모델을 가진 미지의 영역이다. 또한, 포즈를 추정하기 위해 개발된 종래 모델들에는 해결되지 않은 세가지 문제가 있다. 첫째는, 기존 모델은 보이지 않는 뷰(예를 들어, 비정상적인 카메라 각도 또는 거리)에는 적용되지 못한다는 것 이다. 제한된 양의 데이터로 훈련된 대부분의 기존 모델은 유사한 보기에서 캡처된 테스트 예제에서만 잘 수행 되며 보이지 않는 보기에 적용될 때 성능이 크게 저하된다. 둘째는, 폐색(occlusion)은 대부분의 기존 모델이 여전히 겪고 있는 또 다른 오랜 과제이다. 눈에 보이는 가려 진 키 포인트로 인해 그럴듯한 답변이 여러 개 있기 때문에 모호성을 피할 수 없다. 사람이 카메라에서 다른 사 람을 완전히 차단하면 폐색(oclusion)이 훨씬 더 심각해져 모델 출력이 프레임 전체에서 일관되지 않은 추정을 하게 된다. 셋째는, 기존 모델은 종종 심한 흔들림이 있는 일련의 3D 포즈를 생성한다는 것이다. 특히, 2차원 입력 데이터로부터 3차원 자세를 추정하는 AI 모델 학습에 필요한 학습데이터 쌍을 생성하기 위해 전통적으로는 모션 캡쳐 시스템(Motion capture system)이 활용되었으나, 이 방법은 시공간적 제약과 비용적 제 약이 매우 크기 때문에, 연구에 활용할 수 있는 데이터의 범위 또한 매우 제한적이라는 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-2462799호"}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 2차원 입력 데이터로부터 3차원 자세를 추정하되 와일드 비디오에서 야기되는 폐색 현상을 방지하는 인공지능 모델을 제안하고, 기존의 1인 데이터를 결합하고 조정하여 인공지능 모델 학습에 필요한 데 이터 수집을 수행함으로써 비용적 효율성을 높이고 시공간적 제약에 구애받지 않는 3D 포즈 추정을 위한 학습데 이터 증강 장치 및 방법을 제공하는데 목적이 있다. 본 발명의 목적은 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로부 터 본 발명이 속하는 기술 분야의 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명의 실시예에 따른 3D 포즈 추정을 위한 학습데이터 증강 방법은, 2차 원 이미지에 등장하는 사람들 각각의 발 좌표를 수집하는 단계; 수집된 상기 발 좌표들에 기초하여 3차원 공간 의 바닥면(Ground plane)을 추정하는 단계; 상기 바닥면의 법선 벡터에 수직인 두 기저 벡터(b1, b2)를 기준으 로 적어도 한 사람을 이동 또는 회전시키거나, 상기 바닥면을 이동 또는 회전시켜 3차원 자세 데이터를 생성하 는 단계; 상기 3차원 자세 데이터를 상기 2차원 이미지를 촬영한 카메라의 초점 거리 및 상기 2차원 이미지 좌 표의 주점(principle point)에 기초하여 2차원 자세 데이터와 매핑하는 단계; 및 상기 3차원 자세 데이터와 상 기 2차원 자세 데이터 쌍을 학습데이터로 획득하는 단계를 포함할 수 있다. 본 발명의 다른 실시 예에 따른 3D 포즈 추정을 위한 학습데이터 증강 장치는, 프로세서; 및 상기 프로세서와 연결되고, 상기 프로세서에서 수행되는 적어도 하나의 코드가 저장되는 메모리를 포함하고, 상기 프로세서는, 2 차원 이미지에 등장하는 사람들 각각의 발 좌표를 수집하는 동작, 수집된 상기 발 좌표들에 기초하여 3차원 공 간의 바닥면(Ground plane)을 추정하는 동작, 상기 바닥면의 법선 벡터에 수직인 두 기저 벡터(b1, b2)를 기준 으로 적어도 한 사람을 이동 또는 회전시키거나, 상기 바닥면을 이동 또는 회전시켜 3차원 자세 데이터를 생성 하는 동작, 상기 3차원 자세 데이터를 상기 2차원 이미지를 촬영한 카메라의 초점 거리 및 상기 2차원 이미지 좌표의 주점(principle point)에 기초하여 2차원 자세 데이터와 매핑하는 동작, 및 상기 3차원 자세 데이터와 상기 2차원 자세 데이터 쌍을 학습데이터로 획득하는 동작을 실행할 수 있다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따른 3D 포즈 추정을 위한 학습데이터 증강 장치 및 방법은, 2차원 입력 데이터로부터 3차 원 자세를 추정하되 와일드 비디오에서 야기되는 폐색 현상을 방지할 수 있다. 또한, 3D 포즈 추정을 위한 학습데이터 증강 장치 및 방법은,에 따르면, 기존의 1인 데이터를 가공하여 인공지 능 모델 학습에 필요한 학습데이터 증강을 수행함으로써 비용적 효율성을 높이고 시공간적 제약에 구애받지 않 을 수 있다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로부 터 본 발명이 속하는 기술 분야의 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적 및 효과, 그리고 그것들을 달성하기 위한 기술적 구성들은 첨부되는 도면과 함께 상세하게 뒤에 설명이 되는 실시 예들을 참조하면 명확해질 것이다. 본 발명을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것 이다. 그리고 뒤에 설명되는 용어들은 본 발명에서의 구조, 역할 및 기능 등을 고려하여 정의된 용어들로서 이 는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있"}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다. 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 오로지 특허청구범위에 기재된 청구항의 범주에 의하여 정의될 뿐이다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하에서는 첨부한 도면을 참조하며, 본 발명의 바람직한 실시예들을 보다 상세하게 설명하기로 한다. 도 1은 실시예에 따른 3차원 포즈 추정을 개략적으로 설명하기 위한 도면이고, 도 2는 실시예에 따른 3차원 포 즈 추정 장치의 구성을 개략적으로 도시한 블록도이다. 실시예에 따른 3차원 포즈 추정 장치는 와이들 비디오의 몇 가지 예에서 3차원 포즈 추정 모델의 성능을 보여준다. 도 1을 보면, 사람들간 폐색(occlusion)이 있음에도 불구하고 3차원 추정 모델이 여러 사람의 3차원 포즈를 정확하게 추정하는 것을 볼 수 있다. 이러한 3차원 추정 모델을 학습시키기 위해 2차원 입력 데이터로부터 3차원 자세를 추정하는 AI 모델 학습에 필 요한 학습데이터 쌍을 증강시키는 것이 핵심이다. 종래에는 학습데이터 쌍을 생성하기 위해 모션 캡쳐 시스템이 활용되었으며, 이의 시공간적 제약과 비용적 제약 이 매우 컸고, 자세를 뒤집는 방법 정도에 국한되어 학습데이터 증강에 소극적이었다. 본 발명에서는 학습데이터 증강의 다양성과 범위를 대폭 향상시킴으로써, 3차원 포즈 추정 모델 성능 향상에 크 게 기여할 수 있다. 3차원 포즈 추정은 대상자의 수에 따라 3DSPPE(3D Single-Person Pose Estimation)와 3DMPPE(3D Multi-Person Pose Estimation)로 분류된다.본 발명에서는 영상에 등장하는 모든 사람의 신체 키포인트의 3차원 좌표를 재현하는 3DMMPE(3D Multi-Person Pose Estimation) 모델(이하, 3차원 포즈 추정 모델로 지칭할 수 있음)을 다루기로 한다. 본 발명의 3차원 포즈 추정 모델은 고비용이 필요한 실제 데이터 수집을 피하기 위해, 기존의 1인 자세 데이터 를 가공하여 학습데이터를 생성하는 새로운 데이터증강 전략을 개시한다. 본 발명에서는 영상에 등장하는 모든 사람의 신체 키 포인트의 3차원 좌표를 재현하는 3DMPPE를 주로 다룬다. 또한, 본 발명에서는 폐색 문제를 완화하기 위해 다음과 같은 해결책을 개시한다. 기존 모델에서 폐색이 발생하 는 주된 이유는 한 번에 하나의 프레임(frame2frame)을 처리하기 때문에다. 본 발명은 3DSPPE를 위해 한 번에 여러 프레임(seq2seq)을 효과적으로 처리하는 전처리 실행에 이어 3차원 포즈 추정 모델은 유사한 트랜스포머 기반 2D-to-3D 구조를 채택하여 자연스럽게 다중 사용자로 확장할 수 있다. 3차원 포즈 추정 모델은 영상 속에 등장하는 여러 사람에 대한 셀프 어텐션을 추가로 탑재함으로써, 여러 사람 을 동시에 추적할 수 있다. 이하에서는 3차원 포즈 추정에 대해 설명하기로 한다. 도 2에 도시된 바와 같이, 3차원 포즈 추정 장치는 프로세서를 포함한다. 프로세서는 일종의 중앙처리장치로서, 메모리에 저장된 하나 이상의 명령어를 실행하여 실시예에 따 른 3차원 포즈 추정을 위한 학습데이터 증강 방법을 실행할 수 있다. 프로세서는 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있다. 프로세서는 예를 들어 프로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로서, 마이크로프로세서(microprocessor), 중앙처리장치(central processing unit; CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 및 그래픽 처리 유닛(Graphics Processing Unit; GPU) 등의 처리 장치를 망라할 수 있으나, 이에 한정되는 것은 아니다. 프로세서는 하나 이상의 프로세서를 포함할 수 있다. 프로세서는 적어도 하나의 코어를 포함할 수 있다. 실시예에 따른 3차원 포즈 추정 장치는 메모리를 더 포함할 수 있다. 메모리는 실시예에 따른 3차원 포즈 추정 장치가 3차원 포즈 추정을 위한 학습데이터 증강 방법을 실 행하기 위한 명령 등을 저장할 수 있다. 메모리는 실시예에 따른 3차원 포즈 추정을 위한 학습데이터 증강 기법을 구현한 하나 이상의 명령을 생성 및 실행하는 실행가능한(executable) 프로그램을 저장할 수 있다. 프로세서는 메모리에 저장된 프로그램 및 명령어들에 기반하여 실시예에 따른 메모리 관리 방법을 실 행할 수 있다. 메모리는 내장 메모리 및/또는 외장 메모리를 포함할 수 있으며, DRAM, SRAM, 또는 SDRAM 등과 같은 휘발 성 메모리, OTPROM(one time programmable ROM), PROM, EPROM, EEPROM, mask ROM, flash ROM, NAND 플래시 메 모리, 또는 NOR 플래시 메모리 등과 같은 비휘발성 메모리, SSD, CF(compact flash) 카드, SD 카드, Micro-SD 카드, Mini-SD 카드, Xd 카드, 또는 메모리 스틱(memory stick) 등과 같은 플래시 드라이브, 또는 HDD와 같은 저장 장치를 포함할 수 있다. 메모리는 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체 (flash storage media)를 포함할 수 있으나, 이에 한정되는 것은 아니다. 3DMPPE(3D Multi-person pose estimation) 문제에서 입력은 T 프레임의 비디오 로 구성되고, 여기서 각 프레임은 이고, 비디오에는 N명의 사람이 등장할 수 있다. 프로세서의 작업은 비디오의 모든 프레임에서 나타나는 모든 사람에 대해 3D 공간에서 미리 정의된 K 신체 키포인트 세트(예로, 목, 발목 또는 무릎 등)를 찾는 것이다. 2D 이미지 공간의 신체 키포인트는 로 표시되며, 출력 은 N명의 모든 사람에 대한 각 신체 키포인트의 3D 좌표를 지정한다.Notations. 설명의 편의상, 2D 및 3D 포인트에 대한 공통 표기법을 정의할 수 있다. 2D 포인트 를 로 나타내고, 여기서 u ∈{0, ... , H1} 및 v ∈ {0, ..., W 1}은 각각 이미지 의 수직 및 수평 좌표이다. 유사하게, 3D 포인트 를 로 나타내고, 여기서 x와 y 는 투영된 2D 이미지에 평행한 두 방향을 통한 좌표이고, z는 카메라로부터의 깊이이다. Data Preprocessing. 프로세서는 일반적인 관행에 따라 두 가지 방법으로 입력을 조정할 수 있다. 첫째로, 프로세서는 프레임 t에서 사람 i에 대해 루트 조인트(root joint, 일반적으로 골반, 신체 중심: )라는 키포인트를 특별히 처리할 수 있다. 이 루트 조인트의 포인트에 대한 실측값은 (u, v, z)로 제공되고, 여기서 (u, v)는 루트 조인트의 2D 좌표이고, z는 깊이이다. 루트 조인트의 경우, 3차원 포즈 추정 모델은 의 절대값인 을 추정한다. ( u 및 v이지만 여전히 기성품 모델에 의한 불완전한 2D 포즈 추정을 보상하는 것으로 추정함) 기타 일반 관절 ( )은 해당 루트 조인트 와 상대적 차이로 표시 될 수 있다. 둘째로, 프로세서는 카메라 초점 거리로 루트 조인트의 실측 깊이를 정규화할 수 있다. 이를 위해, 2D 포 즈가 3D 공간에 매핑되면 투영 방향을 향한 각 2D 키포인트의 깊이를 추정해야 한다. 추정된 깊이는 훈련에 사용된 카메라 초점 거리에 비례하기 때문에 공지의 기술에 따라 초점 거리로 실측 깊이 z를 정규화할 수 있다. 즉, 를 쓸 수 있고, 여기서 f는 카메라 초점 거리이다. 이러한 방식으로 3 차원 포즈 추정 모델은 카메라 초점 거리와 독립적으로 작동할 수 있다. 도 3은 본 발명의 실시예에 따른 3차원 포즈 추정 모델을 설명하기 위한 개념도로서, 전체 워크플로우를 도시한 다. 먼저, 입력 프레임 V가 기성품 모델(제1 신경망 모델)에 의해 일련의 2D 키포인트로 변환될 수 있다. 그런 다음, 3D 공간으로 들어올려질 수 있다. 아래에서 이에 대해 상세히 설명하기로 한다. < 2D 포즈 추출 및 매칭 > 프로세서는 입력 비디오 가 주어지면, 먼저 비디오에 등장하는 전원 N명의 사람의 2D 좌표 를 추출한다. 여기서, T는 프레임, K는 데이터 세트에 의해 미리 결정된 신체 키포인트의 수이다. 비디오에서 여러 사람을 다 루기 때문에 각 개인은 모든 프레임에서 재정의되어야 한다. 즉, X와 Y의 두번째 인덱스는 모든 프레임에서 각 개인에 대해 일관성이 있어야 한다. 프로세서는 이같이 사람의 2D 좌표를 구하기 위해 공지의 2D 다인용 포즈 추정기 및 추적 모델을 각각 채 택할 수 있으며, 이의 종류에 대해 한정하지 않을 수 있다. 프로세서는 2D 좌표가 실측 3D 포즈 및 카메라 매개변수에서 계산될 수 있는 증강 비디오에서 모델을 훈련 하기 때문에 이러한 단계는 테스트 시에만 수행해야 한다. < 2D-3D 리프팅 모듈 > 프로세서는 이 2D-3D 리프팅 모듈을 통해 입력 X를 3D 좌표 로 들어 올린다. 시공간 기하학적 맥락을 위해 인코더를 적용할 수 있다. 2D-3D 리프팅 모듈에 의해 특정 사람 과 신체 키포인트 에 대 한 특정 프레임 에서 2D 좌표 는 D차원(D-dimensional) 토큰 임베딩에 선형 매핑될 수 있다. 따라서, 입력은 이제 의 토큰 시퀀스로 변환되며, 이러한 토큰을 로 표시할 수 있다. 여기서, 루트 조인트와 일반 조인트를 분리하여 처리하는 대부분의 기존 방법과 달리 단일 통합 모델로 처리한 다. 이러한 통합 모델은 더 간단할 뿐만 아니라 깊이와 자세에 대해 주의를 허용함으로써 보다 포괄적인 추정을 가능하게 한다. 도 4는 2D-to-3D 리프팅 트랜스포머에 관한 예시도이다. 도 4를 참조하면, 3가지 유형의 트랜스포머가 개시되는데, 각 트랜스포머는 서로 다른 신체 키포인트 사이의 특 정 관계를 모델링하도록 설계되었다. 3가지 유형의 트랜스포머는 두 트랜스포머인 공간 모델링을 위한 SPST, 시 간 관계를 위한 SJTT, 및 모든 신체 키포인트중 사람 간 관계를 학습하도록 설계된 IPST를 포함한다. 각 레이어 l에서 입력 은 SPST, IPST, 및 SJTT를 거쳐 시퀀스 내에서 맥락 화되고, 동일한 크기의 텐서 를 출력한다. Single Person Spatial Transformer (SPST) 각 레이어l의 첫 번째 단계에 위치한 SPST는 각 프레임에서 각 사람 관절의 공간적 상관관계를 학습한다. 입력 에서 SPST는 에 대응하는 각 ,"}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "에 대해 해당하는 크기 D의 K토큰을 한 번에 각각 가져온다. 즉, SPST는 특정 프레임 t에서 동일한 사람 i에 속하는 K개의 다른 신체 키포인트를 취한다. 출력 은 동일한 모양을 가지며, 여기서 각 토큰 은 같은 사람에게 속한 다른 토큰을 맥락화하여 변환된 것이다. Inter-Person Spatial Transformer (IPST) SPST 후 IPST는 동일한 프레임에서 여러 개인 간의 상관 관계를 학습한다. 이를 통해 모델은 장면에서 공간적 대인 관계를 학습한다. IPST는 모델을 3DMPPE로 확장하기 위해 새롭게 설계 되었다. 보다 공식적으로 IPST는 한 번에 입력으로 D 크기의 N Х K 토큰을 사용한다. 즉, 입력 가 주어지면 프레임의 모든 N Х K 토큰 는 IPST에 공 급되고, 서로 컨텍스트화되며 출력 토큰 Yt로 변환된다. 이 프로세스는 t = 1, ..., T에서 각 프레임에 대해 개별적으로 수행된다. IPST 후 각 토큰은 동일한 장면에 있 는 다른 사람에 대해 알 수 있다. Single Joint Temporal Transformer (SJTT). 입력 에서 i = 1, ..., N 및 k= 1, 쪋 , K에 대해 에 해 당하는 길이 T의 N Х K 입력 시퀀스를 생성한다. 각 시퀀스는 SJTT에 공급되어 시퀀스의 각 토큰을 시간적으로 컨텍스트화하고 변환된 출력 토큰 가 반환된다. NХK 시퀀스를 모두 완성하면, 2D-to-3D 리프팅 모듈 Z(*?*의 *?*번째 레이어의 변환된 시퀀스 가 다음의 결과로 출력된다. 이 3개의 블록은 2D-to 3D 리프팅 모듈의 단일 레이어를 구성하며 이러한 레이어가 여러 개 쌓인다. 학습 가능한 위치 인코딩은 SPST 및 SJTT의 첫 번째 레이어(ℓ=1)에서 각 토큰에 추가된다. 비디오의 여러 개인 간에 자연스러운 순서가 없기 때문에 IPST에 위치 인코딩이 추가되지 않는다. Regression Head 프로세서는 {SPST, IPST, SJTT}의 L 레이어를 반복한 후 모든 신체 키 포인트 에 대한 출력 토큰을 얻는다. 이것은 다층 퍼셉트론(MLP)으로 구성된 회귀 헤 드에 입력된다. 에 포함된 각 신체 키포인트를 해당 3D 좌표 에 매핑한다. Training objectives 프로세서는 예측된 결과 와 실제값 이 주어지면, 다 음의 두 손실을 최소화시킨다. MPJPE(Joint Position Error) 손실은 예측과 목표 사이의 평균 거리 이다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "MPJVE(Mean per Joint Velocity Error) 손실은 예측의 1차 도함수와 시간에 대한 대상 사이의 평균 거리 로, 예측된 시퀀스의 평활도를 측정한다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "전체 손실 L은 두 손실의 가중 합이다. 즉, L = LMPJPE + λ·LMPJVE이며, 여기서 λ는 이들 사이의 상대적 중 요도를 제어한다. 선택적으로 루트 관절 등에 다른 가중치를 적용할 수 있다. <Geometry-Aware Data Augmentation> 도 5는 본 발명의 학습데이터 증강 방법을 나타내기 위한 예시도이다. 이하, 도 5를 참조하여 학습데이터를 증강하는 방법을 설명한다. 구체적으로, 프로세서는 3차원 자세 데이터인 1인 데이터 세트에서 고정 카메라로 캡처한 N개의 샘플 을 취할 수 있다.(i=1, ..., N) 이어, N개의 샘플을 싱글 비디오 에 오버레이하고, 원근 카메라 모델을 적 용하여 2D 공간에 투영하여 를 생성할 수 있다. 3D 공간의 포인트(x, y, z)는 아래 관계식에 의해 (u, v)에 매핑될 수 있다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 여기서 fu, fv는 초점 거리이고 Cu, Cv는 2D 이미지 좌표의 주요한 포인트이다. 이(X, Y)는 증강된 3DMPPE 교육 샘플이고, 다른 샘플로 이것을 반복하면 새로운 샘플이 무한히 생성될 수 있다. 또한, 추가 임의성을 도입하고 기존 데이터를 완전히 활용하기 위해 궤적을 무작위로 변환하거나 회전시키는 것 과 같이 궤적에 대한 추가 증강을 고려할 수 있다. 그러나, 바닥면(Ground plane)과 잠재적 폐색(Potential occlusion)과 같이 고려해야 할 기하학적 요소가 있다. Ground-plane-aware Augmentations 기하학적으로 비디오의 사람들은 수영하는 상황과 같은 몇 가지 예외를 제외하고 발이 지면에 닿기 때문에, 공 통 접지면을 공유한다. 이러한 상황을 고려하여 프로세서는 2차원 이미지에 등장하는 복수 사람 각각의 발 좌표를 수집한다. 고정 카메라로 캡처한 모든 프레임에서 발 좌표를 수집하고, 이를 선형 회귀로 피팅하여 3D 공간 내에서 2D 선 형 다양체 바닥면을 생성함으로써 바닥면을 추정할 수 있다. 그리고, 바닥면(G)의 법선 벡터에 수직인 두 기저 벡터{b1, b2}가 설정될 수 있다. 이어, 프로세서는 도 5에 도시된 바와 같이 4가지 증강 방법을 결합하여, 다양한 다중 사람 및 카메라 움 직임을 모방하는 풍부한 시퀀스를 생성할 수 있다. 즉, 바닥면의 법선 벡터에 수직인 두 기저 벡터{b1, b2}를 기준으로 적어도 한 사람을 이동 또는 회전시키거나, 상기 바닥면을 이동 또는 회전시키며 상기 학습데이터를 추가 생성할 수 있다. 학습데이터를 추가 생성하는 기법은 PR(Person Rotaion), GPT(Ground Plane Translation), GPR(GPR:Ground Plane Rotation), PT(PT:Person Translation) 중 적어도 하나를 이용할 수 있다. 일 예로, 학습데이터를 증강시키기 위해 PR, GPT, GPR, PT 순으로 수행될 수 있다. 이때, 상기 PT에서 각 대상 사람의 중심좌표가 상기 카메라 앞에 위치하고 이미지 평면 상에 투사되게 하는 값을 가지게 하는 범위 안에서 랜덤하게 정해질 수 있다. 이에 대해 상세히 설명하면, 상기 학습데이터를 추가 생성하는 단계는, 각 대상 사람을 3차원 공간상 상기 바닥 면을 표현하는 2가지 상기 기저벡터를 따라 이동시키는 단계(PT:Person Translation)를 포함하고, 상기 이동의 이동량은 상기 각 대상 사람의 중심 관절 위치가 상기 카메라 앞에 위치하고, 이미지 평면 상에 투사되게 하는 범위 내에서 랜덤하게 정해질 수 있다. 또는, 상기 학습데이터를 추가 생성하는 단계는, 각 대상 사람을 상기 바닥면의 법선 벡터(Nornal vector)에 대 해 회전시키는 단계(PR:Person Rotaion)를 포함하고, 회전각도는 -45도 내지 45도 사이에서 랜덤하게 정해질 수 있다. 또는, 상기 학습데이터를 추가 생성하는 단계는, 상기 카메라의 주축(Principal Axis)을 따라 상기 바닥면을 이 동시키는 단계(GPT:Ground Plane Translation)를 포함하고, 이동량은 상기 복수 사람의 상기 카메라로부터의 상대위치를 고려하여 결정될 수 있다. 또는, 상기 학습데이터를 추가 생성하는 단계는, 상기 바닥면을 상기 카메라로부터 가까워지거나 멀어지는 방향 으로 회전시키는 단계(GPR:Ground Plane Rotation)를 포함하고, 상기 회전량은 -30도 내지 30도 사이에서 랜덤하게 정해질 수 있다. 여기서, 상기 학습데이터의 증강의 순서는 PR, GPT, GPR, PT 순을 따르고, 상기 PT에서 각 대상사람의 중심좌표 가 상기 카메라 앞에 위치하고 이미지 평면 상에 투사되게 하는 값을 가지게 하는 범위 안에서 랜덤하게 정해질 수 있다. Reflecting Occlusions 이하, 폐색 문제를 해결하기 위한 본 발명의 방안을 설명하기로 한다. 폐색(occlusion)은 대부분의 기존 모델이 여전히 겪고 있는 또 다른 오랜 과제이다. 신체는 어느 정도의 부피를 가지고 있기 때문에 두 신체 부위(같은 사람이든 다른 사람이든)가 정확히 일치하지 않더라도 두 개의 키포인트를 충분히 가깝게 투영하면 가려질 수 있다. 이와 같은 문제를 해결하기 위해, 본 발명은 도 6에 도시된 바와 같이, 프로세서가 각 대상사람의 부피를 각 관절(각 키포인트)을 중심으로 3차원 구들의 집합으로 표현하는 단계를 수행한다. 즉, 사람의 간단한 체적 표현을 제안하고, 각 신체 부위의 체적은 해당 키포인트를 중심으로 동일한 크기의 3D 구(ball)로 모델링된다. 상기 구는 한명의 대상사람의 각 관절에 동일한 사이즈로 표현되고, 상기 구들은 2차원 이미지 평면 상에 원으 로 투사되며, 상기 원의 반경은 상기 3차원 구의 상기 카메라로부터의 거리에 반비례하도록 설정될 수 있다. 이를 위해, 제1 사람에 대응하는 제1원과 제2 사람에 대응하는 제2원 간의 중심간의 거리를 측정하고, 상기 카 메라로부터 더 가까운 상기 제1 사람의 상기 제1원의 반경과 상기 제1원과 상기 제2원 간의 중심간의 거리 간의 비교에 따라 상기 제1 사람이 상기 제2 사람을 가렸는지 여부를 판단할 수 있다. 다시 말해서, 두 원의 중심 사이의 거리가 큰 원의 반지름보다 짧으면 원이 겹치는 것으로 간주될 수 있다. 그 러면 반지름이 더 작은 쪽이 더 멀리 가려진 것으로 간주된다. 키포인트가 가려지면 약간의 노이즈로 방해하거 나 드롭아웃하여 낮은 신뢰도로 기성품 모델에서 예측한 키포인트가 추론에서 드롭되는 경우를 시뮬레이션 한다. 도 7은 본 발명의 일 실시예에 따른 3D 포즈 추정을 위한 학습데이터 증강 방법을 설명하기 위한 순서도이다. 도 7의 각 단계는 프로세서에 의해 수행되며, 전술한 내용과 중복되는 내용은 일부 생략하기로 한다. 먼저, 프로세서는 2차원 이미지에 등장하는 사람들 각각의 발 좌표를 수집할 수 있다(S110). 다음으로, 수집된 상기 발 좌표들에 기초하여 3차원 공간의 바닥면(Ground plane)을 추정할 수 있다(S120). 다음으로, 상기 바닥면의 법선 벡터에 수직인 두 기저 벡터(b1, b2)를 기준으로 적어도 한 사람을 이동 또는 회 전시키거나, 상기 바닥면을 이동 또는 회전시켜 3차원 자세 데이터를 생성할 수 있다(S130). 여기서, 학습데이터를 증강시키기 위해 3차원 자세 데이터를 추가 생성할 수 있는데, 이를 위해 3차원 자세 데 이터를 추가 생성하는 기법은 PR(Person Rotaion), GPT(Ground Plane Translation), GPR(GPR:Ground Plane Rotation), PT(PT:Person Translation) 중 적어도 하나를 이용할 수 있다. 일 예로, 3차원 자세 데이터를 새롭게 생성하기 위해 PR, GPT, GPR, PT 순으로 변환을 수행할 수 있다. 이때, 상기 PT에서 각 대상사람의 중심좌표가 상기 카메라 앞에 위치하고 이미지 평면 상에 투사되게 하는 값을 가지 게 하는 범위 안에서 랜덤하게 정해질 수 있다. 구체적으로, 도 5에 도시된 바와 같이 3차원 자세 데이터를 추가 생성하기 위해, 각 대상 사람을 3차원 공간상 상기 바닥면을 표현하는 2가지 상기 기저벡터를 따라 이동시키는 동작(PT:Person Translation), 및 상기 PT에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하는 동작을 실행할 수 있다. 여기서, 이동의 이동량은 상 기 각 대상 사람의 중심 관절 위치가 상기 카메라 앞에 위치하고, 이미지 평면 상에 투사되게 하는 범위 내에서 랜덤하게 정해질 수 있다. 또한, 3차원 자세 데이터를 추가 생성하기 위해, 각 대상 사람을 상기 바닥면의 법선 벡터(Nornal vector)에 대 해 회전시키는 동작(PR:Person Rotaion), 및 상기 PR에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하 는 동작을 실행하고, 여기서 회전각도는 -45도 내지 45도 사이에서 랜덤하게 정해질 수 있다. 또한, 3차원 자세 데이터를 추가 생성하기 위해, 상기 카메라의 주축(Principal Axis)을 따라 상기 바닥면을 이 동시키는 동작(GPT:Ground Plane Translation), 및 상기 GPT에 의한 상기 각 대상 사람의 3차원 자세 데이터를 생성하는 동작을 실행하고, 여기서 이동량은 상기 복수 사람의 상기 카메라로부터의 상대위치를 고려하여 결정될 수 있다. 또한, 3차원 자세 데이터를 추가 생성하기 위해, 상기 바닥면을 상기 카메라로부터 가까워지거나 멀어지는 방향 으로 회전시키는 동작(GPR:Ground Plane Rotation), 및 상기 GPR에 의한 상기 각 대상 사람의 3차원 자세 데이 터를 생성하는 동작을 실행하고, 여기서 상기 회전량은 -30도 내지 30도 사이에서 랜덤하게 정해질 수 있다. 다음으로, 상기 3차원 자세 데이터를 상기 2차원 이미지를 촬영한 카메라의 초점 거리 및 상기 2차원 이미지 좌 표의 주점(principle point)에 기초하여 2차원 자세 데이터와 매핑할 수 있다(S140). 이를 위해, 프로세서는 1인 데이터 세트(3차원 자세 데이터)에서 고정 카메라로 캡처한 N개의 샘플 을 취할 수 있다.(i=1, ..., N) 이어, N개의 샘플을 싱글 비디오 에 오버레이하고, 원근 카메라 모델을 적 용하여 2D 공간에 투영하여 를 생성할 수 있다. 3D 공간의 포인트(x, y, z)는 아래 관계식에 의해 (u, v)에 매핑될 수 있다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, 여기서 fu, fv는 초점 거리이고 Cu, Cv는 2D 이미지 좌표의 주요한 포인트이다. 다음으로, 상기 3차원 자세 데이터와 상기 2차원 자세 데이터 쌍을 학습데이터로 획득할 수 있다(S150). 즉, PR(Person Rotaion), GPT(Ground Plane Translation), GPR(GPR:Ground Plane Rotation), PT(PT:Person Translation) 중 적어도 하나를 통해 3차원 자세 데이터를 추가 생성하고, 이에 상응하는 2차원 자세 데이터를 매핑함으로써, 3차원 자세 데이터와 2차원 자세 데이터를 쌍으로 하는 학습데이터를 증강시킬 수 있다. 한편, 폐색 문제를 해결하기 위해, 프로세서는 각 대상사람의 부피를 각 관절(각 키포인트)을 중심으로 3 차원 구들의 집합으로 표현하는 단계를 수행한다. 즉, 사람의 간단한 체적 표현을 제안하고, 각 신체 부위의 체 적은 해당 키포인트를 중심으로 동일한 크기의 3D 구(ball)로 모델링된다. 상기 구는 한명의 대상사람의 각 관절에 동일한 사이즈로 표현되고, 상기 구들은 2차원 이미지 평면 상에 원으 로 투사되며, 상기 원의 반경은 상기 3차원 구의 상기 카메라로부터의 거리에 반비례하도록 설정될 수 있다. 이를 위해, 제1 사람에 대응하는 제1원과 제2 사람에 대응하는 제2원 간의 중심간의 거리를 측정하고, 상기 카 메라로부터 더 가까운 상기 제1 사람의 상기 제1원의 반경과 상기 제1원과 상기 제2원 간의 중심간의 거리 간의 비교에 따라 상기 제1 사람이 상기 제2 사람을 가렸는지 여부를 판단할 수 있다. 다시 말해서, 두 원의 중심 사이의 거리가 큰 원의 반지름보다 짧으면 원이 겹치는 것으로 간주될 수 있다. 그 러면 반지름이 더 작은 쪽이 더 멀리 가려진 것으로 간주된다. 키포인트가 가려지면 약간의 노이즈로 방해하거 나 드롭아웃하여 낮은 신뢰도로 기성품 모델에서 예측한 키포인트가 추론에서 드롭되는 경우를 시뮬레이션 한다. 전술한 본 발명의 일 실시예에 따른 방법은 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하 는 것이 가능하다. 컴퓨터가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다."}
{"patent_id": "10-2023-0059297", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이상 설명된 본 발명의 실시예에 대한 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가 능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 청구범위에 의하여 나타내어지며, 청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석 되어야 한다."}
{"patent_id": "10-2023-0059297", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 3차원 포즈 추정을 개략적으로 설명하기 위한 도면이다. 도 2는 실시예에 따른 3차원 포즈 추정 장치의 구성을 개략적으로 도시한 블록도이다. 도 3은 본 발명의 실시예에 따른 3차원 포즈 추정 모델을 설명하기 위한 개념도로서, 전체 워크플로우를 도시한 다. 도 4는 2D-to-3D 리프팅 트랜스포머에 관한 예시도이다. 도 5는 본 발명의 학습데이터 증강 방법을 나타내기 위한 예시도이다. 도 6은 사람의 단순 체적을 표현한 예시도이다."}
