{"patent_id": "10-2023-0061476", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0164088", "출원번호": "10-2023-0061476", "발명의 명칭": "인공지능 기반의 가상객체를 이용한 채팅 시스템 및 방법", "출원인": "최옥순", "발명자": "최옥순"}}
{"patent_id": "10-2023-0061476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반의 가상객체를 이용한 채팅 시스템에 있어서,사용자가 원하는 대상의 이미지, 영상, 목소리를 포함하는 가상 객체 생성 정보를 수집하여, 3차원 가상 객체를컴퓨터 그래픽으로 설계하고, 상기 3차원 가상 객체에 상기 가상 객체 생성 정보로부터 생성한 동적 캐릭터를연동하여 지능형 가상 객체를 제공하는 서버; 및상기 지능형 가상 객체로 음성 정보를 입력하여 상기 지능형 가상 객체와 상호작용하는 사용자 단말; 을 포함하는 인공지능 기반의 가상객체를 이용한 채팅 시스템."}
{"patent_id": "10-2023-0061476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 서버; 는가상객체 생성을 위한 대상의 이미지, 음성, 영상, 대화기록을 포함하는 가상객체 생성 정보를 수집하는수집부;상기 가상객체 생성 정보에서 대화패턴, 모션패턴을 추출하여 학습 데이터 셋을 생성하고, 상기 생성된 학습 데이터 셋을 학습한 동적 캐릭터 생성 모델을 구현하는 딥러닝부;상기 가상객체 생성 정보에서 대상의 윤곽선 및 특징점을 포함하는 외형표현정보를 추출하고, 추출된 외형표현정보를 통해 대상의 외형을 3차원 그래픽으로 설계하여 가상객체를 생성하는 가상객체 생성부;대상의 외형에 행동 및 대화패턴을 나타내기 위해, 상기 생성된 가상객체에 동적 캐릭터를 로딩하는 통합부; 를포함하는 인공지능 기반의 가상객체를 이용한 채팅 시스템."}
{"patent_id": "10-2023-0061476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 딥러닝부; 는가상 객체 생성 정보로부터 대상의 고유한 모션, 목소리, 사용언어, 행동 패턴, 언어사용 패턴을 포함하는 동적특징 정보를 추출하여 추출된 동적 특징 정보를 사용자가 원하는 대상의 동적 캐릭터를 생성을 위한 학습데이터셋으로 이용하는 것을 특징으로 하는 인공지능 기반의 가상객체를 이용한 채팅 시스템."}
{"patent_id": "10-2023-0061476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 딥러닝부; 는DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하는 딥러닝 뉴럴 네트워크를 대상객체의 모션 및 대화 패턴을 표현하는 동적 캐릭터의 트레이닝 데이터 셋으로 학습시켜 동적 캐릭터 생성 모델을 구현하는 것을 특징으로 하는 인공지능 기반의 가상객체를 이용한 채팅 시스템."}
{"patent_id": "10-2023-0061476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 가상 객체 생성부; 는가상 객체 생성 후 시간의 흐름에 따라 주름, 흰머리, 자세 변화를 포함하는 노화 징후(sign)를 가상 객체에 부공개특허 10-2024-0164088-3-가하여, 생성된 가상 객체를 변화시키는 것을 특징으로 하는 인공지능 기반의 가상객체를 이용한 채팅 시스템."}
{"patent_id": "10-2023-0061476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 통합부; 는사용자 단말로부터 전달된 음성 정보를 동적 캐릭터 생성 모델에 입력하고, 상기 동적 캐릭터 생성 모델의 출력을 사용자 단말로 전송하여 사용자와 가상 객체가 상호작용하도록 하는 것을 특징으로 하는 인공지능 기반의 가상객체를 이용한 채팅 시스템."}
{"patent_id": "10-2023-0061476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "인공지능 기반의 가상객체를 이용한 채팅 방법에 있어서, (A) 수집부에서 가상객체 생성을 위한 대상의 이미지, 음성, 영상, 대화기록을 포함하는 가상객체 생성 정보를수집하는 단계;(B) 딥러닝부에서 상기 가상객체 생성 정보에서 대화패턴, 모션패턴을 추출하여 학습 데이터 셋을 생성하고, 상기 생성된 학습 데이터 셋을 학습한 동적 캐릭터 생성 모델을 구현하는 단계;(C)가상객체 생성부에서 상기 가상객체 생성 정보에서 대상의 윤곽선 및 특징점을 포함하는 외형표현정보를 추출하고, 추출된 외형표현정보를 통해 대상의 외형을 3차원 그래픽으로 설계하여 가상객체를 생성하는 단계; 및(D) 통합부에서 대상의 외형에 행동 및 대화패턴을 나타내기 위해, 상기 생성된 가상객체에 동적 캐릭터를 로딩하는 단계; 를 포함하는 인공지능 기반의 가상객체를 이용한 채팅 방법."}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예에 따른 인공지능 기반의 가상 객체를 이용한 채팅 시스템 및 방법은 고인, 연예인 등 사용자가 원하는 대 상을 가상 객체와 동적 캐릭터로 표현하고, 사용자와 가상 객체가 실감나게 상호작용할 수 있도록 한다. 실시예 를 통해, 고인이 가상 객체로 표현된 경우, 고인에 대한 그리움을 해소시킬 수 있고, 연예인이 가상 객체로 표현 된 경우 스토킹 범죄를 예방할 수 있다. 또한, 실시예에서는 가상객체를 시간 흐름에 따라 변화시키고 대상의 아 이템을 가상객체에 적용하여, 가상 객체를 더욱 현실적으로 표현할 수 있다."}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능 기반의 가상객체를 이용한 채팅 시스템 및 방법에 관한 것으로, 인공지능 딥러닝 모델을 통 해, 사용자가 원하는 가상객체와 가상객체의 동적 캐릭터를 생성하여 생성된 가상객체와 대화하는 채팅 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 명세서에서 달리 표시되지 않는 한, 이 섹션에 설명되는 내용들은 이 출원의 청구항들에 대한 종래 기술이 아니며, 이 섹션에 포함된다고 하여 종래 기술이라고 인정되는 것은 아니다. 인공지능(AI, artificial intelligence)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술이다. 인공지능은 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현하려는 컴퓨터 과학의 세부분야 중 하나이다. 정보공학 분야에 있어 하나의 인프라 기술이기도 하다. 인간을 포함한 동물이 갖고 있는 지능 즉, 자연 지능(natural intelligence)과는 다른 개념이다. 인공지능은 지능을 갖고 있는 기능을 갖춘 컴퓨터 시스템이며, 인간의 지능을 기계 등에 인공적으로 구현한 것 이다. 일반적으로 범용 컴퓨터에 적용한다고 가정한다. 이 용어는 또한 그와 같은 지능을 만들 수 있는 방법론 이나 실현 가능성 등을 연구하는 과학 기술 분야를 지칭하기도 한다. 일반적으로 인공지능은 약인공지능과 강인공지능으로 구분된다. 약인공지능(weak AI)은 사진에서 물체를 찾거나 소리를 듣고 상황을 파악하는 것과 같이 기존에 인간은 쉽게 해결할 수 있으나 컴퓨터로 처리하기에는 어려웠던 각종 문제를 컴퓨터로 수행하게 만드는데 중점을 두고 있다. 한참 막연한 인간 지능을 목표로 하기보다는 더 현 실적으로 실용적인 목표를 가지고 개발되고 있는 인공지능이고, 특정한 문제를 해결하는 도구로써 활용된다. 한편, 강인공지능(strong AI) 또는 인공 일반 지능(Artificial general intelligence, AGI)은 인간처럼 실제로 사고하여 문제를 해결할 수 있는 일반 지능을 인공적으로 구현하려는 시도이다. 강인공지능 구현을 위해, 학습 대상의 다양한 정보를 학습하여 모델을 생성하고, 생성된 학습 모델을 통해 일반 지능을 구현한다. 예컨대, 인 공지능을 이용한 스피커, 대화 서비스, 채팅 서비스 등이 있고, 인공지능이 발전함에 따라 그 적용 범위가 확대 되고 있다."}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국 특허등록 제10-1014852호 (2011.02.08) (특허문헌 0002) 2. 한국 특허공개 제10-2023-0016366호 (2023.02.02)"}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예에 따른 인공지능 기반의 가상 객체를 이용한 채팅 시스템 및 방법은 고인, 연예인 등 사용자가 원하는 가상 객체와 가상 객체의 대화와 행동을 제어하여 대상을 표현하는 동적 캐릭터를 생성한다. 실시예에서는 가상 객체에 사용자가 원하는 대상의 말투, 대화패턴, 동작패턴을 표현한 동적 캐릭터를 로딩 한다. 실시예에서는 딥러닝 뉴럴 네트워크를 트레이닝 데이터 셋으로 학습시켜 사용자가 원하는 대상을 표현하는 동적 캐릭터 생성 모델을 구현한다. 또한, 실시예에서는 인공 지능 기반의 동적 캐릭터 생성 모델을 통해 가상 객체의 동적 캐릭터를 생성하고, 생 성된 가상 객체와 동적 캐릭터를 시간 흐름에 따라 업데이트 하여, 가상 객체를 시간에 따라 변화시킨다. 또한, 실시예에서는 헤어, 의복, 장신구 등 가상 객체에 적용하는 아이템을 생성하고, 사용자 단말에서 구매한 아이템을 가상 객체에 적용할 수 있도록 한다."}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 따른 인공지능 기반의 가상객체를 이용한 채팅 시스템은 사용자가 원하는 대상의 이미지, 영상, 목소 리를 포함하는 가상 객체 생성 정보를 수집하여, 3차원 가상 객체를 컴퓨터 그래픽으로 설계하고, 상기 3차원 가상 객체에 상기 가상 객체 생성 정보로부터 생성한 동적 캐릭터를 연동하여 지능형 가상 객체를 제공하는 서 버; 및 지능형 가상 객체로 음성 정보를 입력하여 상기 지능형 가상 객체와 상호작용하는 사용자 단말; 을 포함 한다."}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같은 인공지능 기반의 가상 객체를 이용한 채팅 시스템 및 방법은 고인, 연예인 등 사용자가 원하는 대상을 가상 객체와 동적 캐릭터로 실감나게 표현하고, 사용자와 가상 객체가 상호작용할 수 있도록 한다. 실시예를 통해, 고인이 가상 객체로 표현된 경우, 고인에 대한 그리움을 해소시킬 수 있고, 연예인이 가상 객체 로 표현된 경우 스토킹 범죄를 예방할 수 있다. 또한, 실시예에서는 가상객체를 시간 흐름에 따라 변화시키고 대상의 아이템을 가상객체에 적용하여, 가상 객체 를 더욱 현실적으로 표현할 수 있도록 한다."}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이"}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 도면부호는 동일 구성 요소를 지칭한다. 본 발명의 실시 예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명의 실시 예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도 1은 실시예에 따른 인공지능 기반의 가상 객체를 이용한 채팅 시스템 구성을 나타낸 도면이다. 도 1을 참조하면, 실시예에 따른 인공지능 기반의 가상 객체를 이용한 채팅 시스템은 사용자 단말 및 서버 를 포함하여 구성될 수 있다. 서버는 사용자가 원하는 대상을 표현한 지능형 가상 객체를 생성한다. 실시예에서 사용자가 원하는 대상은 고인, 연예인 등을 포함할 수 있다. 실시예에서 서버는 가상 객체 생성 정보를 수집하여 3차원 가상 객체 를 컴퓨터 그래픽으로 설계하고, 3차원 가상 객체에 가상 객체 생성 정보로부터 생성한 동적 캐릭터를 연동하여 지능형 가상 객체를 생성한다. 실시예에서 가상 객체 생성 정보는 사용자가 원하는 대상을 가상의 객체로 표현 하기 위해 필요한 정보로서, 대상이 포함된 이미지, 영상, 대상의 목소리, SNS 대화기록 등을 포함할 수 있다. 실시예에서 동적 캐릭터는 가상 객체의 대화, 움직임 등을 제어하는 프로그램이다. 실시예에서 동적 캐릭터는 대상 객체를 제어하여 사용자가 원하는 대상의 고유한 대화패턴과 모션패턴을 대상 객체를 통해 나타낸다. 사용자 단말은 지능형 가상 객체로 음성 정보를 입력하여 지능형 가상 객체와 상호작용한다. 실시예에서 적어도 하나의 사용자 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터로 구현 될 수 있다. 여기서, 컴퓨터는 예를 들어, 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱 (Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 사용자 단말은, 네트워크를 통해 원 격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 사용자 단말은, 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(smartphone), 스마트 패드(smartpad), 태블릿 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 실시예에 따른 인공지능 기반의 가상 객체를 이용한 채팅 시스템 및 방법은 고인, 연예인 등 사용자가 원하는 가상 객체와 가상 객체를 표현하는 동적 캐릭터를 생성한다. 실시예에서는 가상 객체에 사용자가 원하는 대상의 말투, 대화패턴, 동작패턴을 표현한 동적 캐릭터를 로딩 한다. 또한, 실시예에서는 딥러닝 뉴럴 네트워크를 트 레이닝 데이터 셋으로 학습시켜 사용자가 원하는 대상을 표현하는 동적 캐릭터 생성 모델을 구현한다. 또한, 실 시예에서는 인공 지능 기반의 동적 캐릭터 생성 모델을 통해 가상 객체의 동적 캐릭터를 생성하고, 생성된 가상 객체와 동적 캐릭터를 시간 흐름에 따라 업데이트 하여, 가상 객체를 시간에 따라 변화시킨다. 또한, 실시예에 서는 헤어, 의복, 장신구 등 가상 객체에 적용하는 아이템을 생성하고, 사용자 단말에서 구매한 아이템을 가상 객체에 적용할 수 있도록 한다.도 2는 실시예에 따른 서버의 데이터 처리 구성을 나타낸 도면이다. 도 2를 참조하면, 실시예에 따른 서버는 수집부, 딥러닝부, 가상객체 생성부, 통합부 , 아이템 생성부 및 아이템 적용부를 포함하여 구성될 수 있다. 본 명세서에서 사용되는 '부' 라는 용어는 용어가 사용된 문맥에 따라서, 소프트웨어, 하드웨어 또는 그 조합을 포함할 수 있는 것으로 해석 되어야 한다. 예를 들어, 소프트웨어는 기계어, 펌웨어(firmware), 임베디드코드(embedded code), 및 애플리케 이션 소프트웨어일 수 있다. 또 다른 예로, 하드웨어는 회로, 프로세서, 컴퓨터, 집적 회로, 집적 회로 코어, 센서, 멤스(MEMS; Micro-Electro-Mechanical System), 수동 디바이스, 또는 그 조합일 수 있다. 수집부는 가상객체 생성을 위한 가상객체 생성정보를 수집한다. 실시예에서 가상객체 생성정보는 고인, 연 예인 등 사용자가 원하는 대상의 외형과 대화패턴, 행동패턴 정보를 제공하는 정보이다. 실시예에서 가상객체 생성정보는 대상을 포함하는 대상의 이미지, 음성, 영상, 대화기록을 포함할 수 있다. 실시예에서 수집부 는 가상객체의 대상이 고인인 경우, 고인의 스마트 단말이나 사용자 단말을 통해 가상객체 생성정보를 수집할 수 있고, 대상이 연예인인 경우, 웹에서 대상에 관한 정보를 크롤링하여 가상객체 생성정보를 수집할 수 있다. 딥러닝부는 딥러닝 뉴럴 네트워크를 트레이닝 데이터 셋으로 학습시켜 동적 캐릭터 생성 모델을 구현한다. 실시예에서 동적 캐릭터 생성 모델은 가상 객체의 행동, 대화를 제어하기 위한 인공지능 프로그램으로 트레이닝 데이터 셋을 학습하여 생성될 수 있다. 실시예에서 트레이닝 데이터 셋은 가상객체 생성 정보로부터 추출된 대 상의 대화패턴과 모션패턴으로 생성될 수 있다. 실시예에서 딥러닝부는 언어 인식 모델, 음성 인식 모델, 행동 패턴 분석 모델 등의 딥러닝 기반 인공지능 모델을 통해, 가상객체 생성 정보로부터 대상의 대화패턴, 모 션 패턴 정보를 추출하고, 추출된 패턴정보를 트레이닝 데이터셋으로 설정하여, 설정된 트레이닝 데이터 셋으로 동적 캐릭터 생성모델을 학습시킨다. 실시예에서 딥러닝부는 가상 객체 생성 정보로부터 대상의 고유한 모션, 목소리, 사용언어, 행동 패턴, 언 어사용 패턴을 포함하는 동적 특징 정보를 추출하여 추출된 동적 특징 정보를 사용자가 원하는 대상의 동적 캐 릭터를 생성을 위한 학습데이터 셋으로 이용한다. 실시예에서 딥러닝 뉴럴 네트워크는 DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하고, 이에 한정하지 않는다. 실시예에서 딥러닝부는 인공지능 머신러닝을 통한 이미지 인식(image recognition)과정을 통해 가상객체 생성 정보의 이미지와 영상에서 대상을 인식할 수 있다. 인공지능 이미지 인식은 기계가 마치 사람처럼 사진으 로부터 사물을 인식하고 장면을 이해하는 것으로, 컴퓨터 비전 기술 중 하나에 해당한다. 실시예에서는 이미지 인식을 위해, 이미지와 영상에 포함된 대상을 분류(classification), 검출(detection) 및 픽셀 단위로 식별하여 분할(segmentation)하는 데이터 처리 과정을 수행한다. 실시예에서 딥러닝부는 노이즈 대응 외 학습하지 못한 패턴 처리를 위해 학습 외 분포 데이터 탐지(out of distribution detection)과정을 수행한다. 학습 외 분 포 데이터 탐지는 인공지능에 입력된 이미지가 학습된 확률분포 데이터 인지 아닌지 식별하는 것이다. 실시예에 서는 학습 외 분포 데이터 탐지를 통해 인공 신경망이 판단하기 어려운 이미지를 걸러내거나 예외 처리하여 안 정성과 신뢰성을 높일 수 있도록 한다. 실시예에서는 학습 외 분포 데이터 탐지를 위해서 딥러닝 판정에 대해 얼마나 확신(confidence)하는지를 나타내는 확률 값을 보정(calibration)하거나 학습 외 분포 데이터를 생성적 대립 신경망(GAN, Generative Adversarial Network)으로 생성하고 학습하여 탐지 정확도를 향상시킬 수 있도록 한다. 또한, 실시예에서는 이미지 인식 정확도를 유지하면서 모델의 크기를 줄이기 위해, 연산을 간소화하는 경량 딥 러닝 기술을 이용하여 대상 인식을 최종 확정할 수 있도록 한다. 실시예에서는 이미지 인식을 위해 콘볼루션 신 경망(CNN, Convolution Neural Network)에서 콘볼루션 필터를 변형하여 연산 차원을 축소(Reduction)하거나 큰 영향이 없는 신경망의 가중치(weight)를 삭제하는 가지치기, 가중치 값의 부동 소수점을 줄여 연산을 간소화하 는 양자화 과정을 수행하여 데이터 경량화를 가능하도록 한다. 또한, 실시예에서는 미리 학습시킨 큰 신경망의 출력을 작은 신경망에서 모방 학습하도록 하여 연산을 간소화하며 정확도를 유지할 수 있도록 한다. 가상객체 생성부는 가상객체 생성 정보를 이용하여 대상의 외형을 3차원 그래픽으로 설계하여 가상객체를 생성한다. 실시예에서 가상객체 생성부는 대상이 포함된 이미지에서 대상을 인식하고, 대상의 윤곽선 및 특징추출을 통해 대상의 외형을 3차원 그래픽으로 설계할 수 있다. 실시예에서 가상객체 생성부는 가상 객체 생성 후 시간의 흐름에 따라 노화징후를 가상객체에 부가하여 가 상객체를 변화시킨다. 노화징후는 가상객체 생성 후 시간의 흐름에 따라 나타나는 노화상태정보로서, 주름, 흰 머리, 자세 변화, 목소리 변화 등을 포함할 수 있다. 실시예에서 가상객체 생성부는 가상객체가 최초 생성 된 시점의 나이를 기준으로 시간의 흐름에 따라 노화징후를 부가할 수 있다. 실시예에서 가상객체 생성부 는 노화징후를 부가하기 위해, 나이대에 따른 일반적인 노화정보를 미리 수집하고, 나이대에 따라 부가되어야 할 노화 징후를 설정한다. 이후, 가상객체 생성부는 가상객체의 나이대에 따라 설정된 노화징후를 기존 가 상객체의 외형에 부가하여, 가상객체를 변화시킬 수 있다. 또한, 실시예에서 가상객체 생성부는 나이대에 따라 노화징후의 강도를 다르게 설정하여 부가할 수 있다. 예컨대, 가상객체 생성부는 40대 가상객체의 주름강도 제1값으로 설정하고, 50대 가상객체의 주름 강도를 제1값을 초과하는 제2값으로 설정하고, 60대 가상객체의 주름강도를 제2값을 초과하는 제3값으로 설정한다. 이 후, 시간의 흐름에 따른 가상객체의 나이대에 따라 설정된 주름 강도를 노화징후로 부가하여 가상객체를 변화시 킬 수 있다. 또한, 실시예에서 가상객체 생성부는 가상객체가 생성된 시점의 가상객체 나이가 일정 값(예컨대, 19세) 미만인 경우, 가상객체의 성장을 반영하여 가상객체를 변화시킬 수 있다. 예컨대, 가상객체 생성부는 가상 객체 생성 시점에 생성된 가상객체가 어린이인 경우, 시간의 흐름에 따른 성장징후를 가상객체의 외형에 부가하 여 가상객체를 변화시킬 수 있다. 실시예에서 성장징후는 나이대에 따른 일반적인 성장정보로서, 평균키, 평균 몸무게, 인지능력, 얼굴크기 등을 포함할 수 있다. 구체적으로, 가상객체 생성부는 가상객체의 나이대에 대응하는 평균키, 평균 몸무게, 얼굴크기 등을 고려하여 가상객체의 외형을 시간의 흐름에 따라 변화시킬 수 있 다. 통합부는 대상을 나타낸 가상객체와 동적 캐릭터를 통합한다. 실시예에서 통합부는 대상의 외형을 나 타낸 가상객체에 동적 캐릭터를 로딩하여 가상객체와 동적 캐릭터를 통합할 수 있다. 실시예에서 동적 캐릭터는 가상객체를 실제 대상의 행동패턴과 대화패턴에 따라 제어하기위한 프로그램이다. 실시예에서 통합부는 사용자 단말로부터 전달된 음성 정보를 동적 캐릭터 생성 모델에 입력하고, 동적 캐 릭터 생성 모델의 출력을 사용자 단말로 전송하여 사용자와 가상 객체가 상호작용하도록 한다. 실시예에서 통합부는 동적 캐릭터 생성 모델의 출력에 따른 사용자 반응 정보를 모니터링하고, 사용자 반 응 정보를 수집하여, 수집된 사용자 반응정보를 동적 캐릭터 생성 모델의 트레이닝 데이터 셋으로 이용할 수 있 다. 실시예에서 사용자 반응정보는 동적 캐릭터 생성모델의 출력정보에 대한 사용자의 반응을 나타낸 정보이다. 사 용자 반응정보는 사용자의 모션, 표정, 발화 텍스트 등을 포함할 수 있다. 예컨대, 통합부는 사용자 단말로의 음성입력, 동적 캐릭터 생성모델의 출력 및 동적 캐릭터 생성모델의 출 력에 대한 사용자 반응 정보를 포함하는 시퀀셜(sequential) 정보를 수집하여, 수집된 시퀀셜 정보의 컨텍스트 를 파악한다. 컨텍스트는 문맥과 상황정보로서, 실시예에서 통합부는 사용자 반응 정보를 통해, 동적 캐릭 터 생성모델의 출력이 컨텍스트에 부합하는지 판단할 수 있다. 또한, 실시예에서 통합부는 동적 캐릭터 생성모델의 출력과 대상의 모션, 대화 패턴을 비교하고, 일치율이 일정 수준 이상인 동적 캐릭터 생성모델의 출력만을 수집하여, 트레이닝 데이터 셋으로 이용할 수 있도록 한다. 아이템 생성부는 가상객체에 적용할 아이템을 생성한다. 실시예에서 아이템은 의류, 신발, 장신구, 가방 등을 포함할 수 있다. 실시예에서 아이템 생성부는 대상이 포함된 영상 및 이미지 분석을 통해, 가상객체 로 표현된 대상이 주로 착용하는 아이템을 인식하고, 인식된 아이템을 동일하게 생성할 수 있다. 또한, 실시예 에서 아이템 생성부는 가상객체로 표현된 대상이 주로 착용하는 아이템과 유사한 아이템을 생성할 수 있다. 예컨대, 아이템 생성부는 인공지능 이미지 분석 모델을 통해, 가상객체 생성 정보를 분석하여 대상 의 선호 스타일을 파악하고, 선호 스타일에 대응하는 아이템을 생성할 수 있다. 구체적으로 아이템 생성부(25 0)는 대상이 포함된 이미지와 영상의 옷, 신발, 장신구 등의 사용 아이템을 추출하여, 추출된 사용 아이템과 일 정수준 이상 유사한 아이템을 생성할 수 있다. 실시예에서 인공지능 이미지 분석 모델은, 예로, 신경망 (Neural Network)을 기반으로 하는 모델일 수 있다. 인 공지능 학습모델은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며 인간의 신경망의 뉴런 (neuron)을 모의하는, 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은"}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "뉴런이 시냅스(synapse)를 통하여 신호를 주고받는 뉴런의 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계를 형성할 수 있다. 또한, 문서 요약 모델은, 일 예로, 신경망 모델, 또는 신경망 모델에서 발전한 딥 러닝 모 델을 포함할 수 있다. 딥러닝 모델에서 복수의 네트워크 노드들 은 서로 다른 깊이(또는, 레이어)에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고받을 수 있다. 이미지 분석 모델의 예에는 DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 등 이 있을 수 있으나 이에 한정되지 않는다. 아이템 적용부는 생성된 아이템 중 사용자 단말에서 구매한 아이템을 가상객체에 적용한다. 실시예에서 아 이템 적용부는 사용자 단말의 아이템 제어에 따라 가상객체에 사용자 단말에서 구매한 아이템을 적용하거 나 구매한 아이템을 자동 적용할 수 있다. 실시예에서는 아이템을 통해, 가상객체를 실제 대상과 더욱 유사하게 나타낼 수 있다. 이하에서는 인공지능 기반의 가상객체를 이용한 채팅 방법에 대해서 차례로 설명한다. 실시예에 따른 인공지능 기반의 가상객체를 이용한 채팅 방법의 작용(기능)은 위조품 탐지 시스템의 기능과 본질적으로 같은 것이므로 도 1 및 도 2와 중복되는 설명은 생략하도록 한다. 도 3은 실시예에 따른 인공지능 기반의 가상객체를 이용한 채팅 시스템의 신호흐름을 나타낸 도면이다. 도 3을 참조하면, S100단계에서는 서버에서 사용자가 원하는 대상의 이미지, 영상, 목소리를 포함하는 가상 객 체 생성 정보를 수집하여, 3차원 가상 객체를 컴퓨터 그래픽으로 설계하고, 3차원 가상 객체에 가상 객체 생성 정보로부터 생성한 동적 캐릭터를 연동하여 지능형 가상 객체를 생성한다. 실시예에서 가상객체 생성정보는 고인, 연예인 등 사용자가 원하는 대상의 외형과 대화패턴, 행동패턴 정보를 제공하는 정보이다. 실시예에서 가상객체 생성정보는 대상을 포함하는 대상의 이미지, 음성, 영상, 대화기록을 포함할 수 있다. 실시예에서 S100단계에서는 대상이 고인인 경우, 고인의 스마트 단말이나 사용자 단말을 통해 가상객체 생성정보를 수집할 수 있고, 대상이 연예인인 경우, 웹에서 대상에 관한 정보를 크롤링하여 가상객체 생성정보를 수집할 수 있다. S200 단계에서는 사용자 단말에서 서버로부터 지능형 가상객체를 수신하여, 지능형 가상객체를 출력한다. S300 단계에서는 지능형가상객체로 사용자의 음성정보를 입력하고 S400 단계에서는 사용자의 음성 입력에 따라 지능 형 가상 객체와 상호작용한다. 도 4는 실시예에 따른 지능형 가상객체 생성과정을 나타낸 도면이다. S110 단계에서는 수집부에서 가상객체 생성을 위한 대상의 이미지, 음성, 영상, 대화기록을 포함하는 가상객체 생성 정보를 수집한다. S120 단계에서는 딥러닝부에서 가상객체 생성 정보에서 대화패턴, 모션패턴을 추출하여 학습 데이터 셋을 생성 하고, 생성된 학습 데이터 셋을 학습한 동적 캐릭터 생성 모델을 구현한다. S130 단계에서는 가상객체 생성부에서 가상객체 생성 정보에서 대상의 윤곽선 및 특징점을 포함하는 외형표현정 보를 추출하고, 추출된 외형표현정보를 통해 대상의 외형을 3차원 그래픽으로 설계하여 가상객체를 생성한다. S130 단계에서는 가상객체 생성부에서 가상객체 생성 정보를 이용하여 대상의 외형을 3차원 그래픽으로 설계하 여 가상객체를 생성한다. 실시예에서 S130 단계에서는 가상객체 생성부에서 대상이 포함된 이미지에서 대상을 인식하고, 대상의 윤곽선 및 특징추출을 통해 대상의 외형을 3차원 그래픽으로 설계할 수 있다. S130 단계에서는 가상객체 생성부에서 가상 객체 생성 후 시간의 흐름에 따라 노화징후를 가상객체에 부가하여 가상객체를 변화시킨다. 노화징후는 가상객체 생성 후 시간의 흐름에 따라 나타나는 노화상태정보로서, 주름, 흰머리, 자세 변화 등을 포함할 수 있다. S130 단계에서는 가상객체 생성부에서 가상객체가 최초 생성된 시점 의 나이를 기준으로 시간의 흐름에 따라 노화징후를 부가할 수 있다. 실시예에서 S300 단계에서는 가상객체 생 성부에서 노화징후를 부가하기 위해, 나이대에 따른 일반적인 노화정보를 미리 수집하고, 나이대에 따라 부가되 어야 할 노화 징후를 설정한다. 또한, 실시예에서 S300 단계에서는 가상객체 생성부에서 나이대에 따라 노화징 후의 강도를 다르게 설정하여 부가할 수 있다. 예컨대, S130 단계에서는 가상객체 생성부에서 40대 가상객체의 주름강도 제1값으로 설정하고, 50대 가상객체의 주름 강도를 제1값을 초과하는 제2값으로 설정하고, 60대 가상 객체의 주름강도를 제2값을 초과하는 제3값으로 설정한다. 이후, 시간의 흐름에 따른 가상객체의 나이대에 따라 설정된 주름 강도를 노화징후로 부가하여 가상객체를 변화시킬 수 있다. 또한, 실시예에서 S130 단계에서는 가상객체 생성부에서 가상객체가 생성된 시점의 가상객체 나이가 일정 값(예 컨대, 19세) 미만인 경우, 가상객체의 성장을 반영하여 가상객체를 변화시킬 수 있다. 예컨대, 가상객체 생성부 는 가상객체가 어린이인 경우, 시간의 흐름에 따른 성장징후를 가상객체에 부가하여 가상객체를 변화시킬 수 있다. 실시예에서 성장징후는 나이대에 따른 일반적인 성장정보로서, 평균키, 평균 몸무게, 인지능력, 얼굴 크기 등을 포함할 수 있다. 구체적으로, S130 단계에서는 가상객체 생성부에서 가상객체의 나이대에 대응하는 평균키, 평균 몸무게, 얼굴크기 등을 고려하여 가상객체의 외형을 시간의 흐름에 따라 변화시킬 수 있다. S140 단계에서는 통합부에서 대상의 외형에 행동 및 대화패턴을 나타내기 위해, 생성된 가상객체에 동적 캐릭터 를 로딩(loading)한다. 실시예에서 S140 단계에서는 통합부에서 사용자 단말로부터 전달된 음성 정보를 동적 캐릭터 생성 모델에 입력 하고, 동적 캐릭터 생성 모델의 출력을 사용자 단말로 전송하여 사용자와 가상 객체가 상호작용하도록 한다. 실시예에서 S140 단계에서는 통합부에서 동적 캐릭터 생성 모델의 출력에 따른 사용자 반응 정보를 모니터링하 고, 사용자 반응 정보를 수집하여, 수집된 사용자 반응정보를 동적 캐릭터 생성 모델의 트레이닝 데이터 셋으로 이용할 수 있다. 실시예에서 사용자 반응정보는 동적 캐릭터 생성모델의 출력정보에 대한 사용자의 반응을 나타낸 정보이다. 사 용자 반응정보는 사용자의 모션, 표정, 발화 텍스트 등을 포함할 수 있다. 예컨대, S140 단계에서는 통합부에서 사용자 단말로의 음성입력, 동적 캐릭터 생성모델의 출력 및 동적 캐릭터 생성모델의 출력에 대한 사용자 반응 정보를 포함하는 시퀀셜(sequential) 정보를 수집하여, 수집된 시퀀셜 정 보의 컨텍스트를 파악한다. 컨텍스트는 문맥과 상황정보로서, 실시예에서 통합부는 사용자 반응 정보를 통 해, 동적 캐릭터 생성모델의 출력이 컨텍스트에 부합하는지 판단할 수 있다. 또한, 실시예에서 S140 단계에서는 통합부에서 동적 캐릭터 생성모델의 출력과 대상의 모션, 대화 패턴을 비교 하고, 일치율이 일정 수준 이상인 동적 캐릭터 생성모델의 출력만을 수집하여, 트레이닝 데이터 셋으로 이용할 수 있도록 한다. S150 단계에서는 아이템 생성부에서 가상객체에 적용할 아이템을 생성한다. 실시예에서 아이템은 의류, 신발, 장신구, 가방 등을 포함할 수 있다. 실시예에서 S150 단계에서는 아이템 생성부에서 대상이 포함된 영상 및 이 미지 분석을 통해, 가상객체로 표현된 대상이 주로 착용하는 아이템을 인식하고, 인식된 아이템을 동일하게 생 성할 수 있다. 또한, 실시예에서 S150 단계에서는 아이템 생성부에서 가상객체로 표현된 대상이 주로 착용하는 아이템과 유사한 아이템을 생성할 수 있다. 예컨대, S150 단계에서는 아이템 생성부에서 인공지능 이미지 분석 모델을 통해, 가상객체 생성 정보를 분석하여 대상의 선호 스타일을 파악하고, 선호 스타일에 대응하는 아이템 을 생성할 수 있다. 실시예에서 인공지능 이미지 분석 모델은, 예로, 신경망 (Neural Network)을 기반으로 하는 모델일 수 있다. 인 공지능 학습모델은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며 인간의 신경망의 뉴런 (neuron)을 모의하는, 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 뉴런이 시냅스(synapse)를 통하여 신호를 주고받는 뉴런의 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계"}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "를 형성할 수 있다. 또한, 문서 요약 모델은, 일 예로, 신경망 모델, 또는 신경망 모델에서 발전한 딥 러닝 모 델을 포함할 수 있다. 딥러닝 모델에서 복수의 네트워크 노드들 은 서로 다른 깊이(또는, 레이어)에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고받을 수 있다. 이미지 분석 모델의 예에는 DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 등 이 있을 수 있으나 이에 한정되지 않는다. S160 단계에서는 아이템 적용부에서 생성된 아이템 중 사용자 단말에서 구매한 아이템을 가상객체에 적용한다. 실시예에서 아이템 적용부는 사용자 단말의 아이템 제어에 따라 가상객체에 사용자 단말에서 구매한 아이 템을 적용할 수 있다. 실시예에서는 아이템을 통해, 가상객체를 실제 대상과 더욱 유사하게 나타낼 수 있다. 이상에서와 같은 인공지능 기반의 가상 객체를 이용한 채팅 시스템 및 방법은 고인, 연예인 등 사용자가 원하는 대상을 가상 객체와 동적 캐릭터로 실감나게 표현하고, 사용자와 가상 객체가 상호작용할 수 있도록 한다. 실시예를 통해, 고인이 가상 객체로 표현된 경우, 고인에 대한 그리움을 해소시킬 수 있고, 연예인이 가상 객체 로 표현된 경우 스토킹 범죄를 예방할 수 있다. 또한, 실시예에서는 가상객체를 시간 흐름에 따라 변화시키고 대상의 아이템을 가상객체에 적용하여, 가상 객체를 더욱 현실적으로 표현할 수 있다."}
{"patent_id": "10-2023-0061476", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "개시된 내용은 예시에 불과하며, 특허청구범위에서 청구하는 청구의 요지를 벗어나지 않고 당해 기술분야에서 통상의 지식을 가진 자에 의하여 다양하게 변경 실시될 수 있으므로, 개시된 내용의 보호범위는 상술한 특정의 실시예에 한정되지 않는다."}
{"patent_id": "10-2023-0061476", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 인공지능 기반의 가상 객체를 이용한 채팅 시스템 구성을 나타낸 도면 도 2는 실시예에 따른 서버의 데이터 처리 구성을 나타낸 도면 도 3은 실시예에 따른 인공지능 기반의 가상객체를 이용한 채팅 시스템의 신호흐름을 나타낸 도면 도 4는 실시예에 따른 지능형 가상객체 생성과정을 나타낸 도면"}
