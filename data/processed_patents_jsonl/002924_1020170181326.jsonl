{"patent_id": "10-2017-0181326", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0079253", "출원번호": "10-2017-0181326", "발명의 명칭": "대화형 인공지능을 위한 다중 에이전트 시스템", "출원인": "한국항공대학교산학협력단", "발명자": "김현근"}}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "대화형 인공지능을 위한 다중 에이전트 시스템으로서,대화 중인 대상으로부터 수신한 대상 언어를 분석하여 상기 대상 언어에 대응하는 의미 분석 정보 및 감정 분석정보를 생성하는 대상 언어 분석 에이전트;상기 대상 언어에 대하여 상기 대화의 흐름을 고려하여 상기 대화형 인공지능 스스로의 자기감정 상태를 모델링하는 자기감정 파악 에이전트;상기 의미 분석 정보, 상기 감정 분석 정보 및 상기 자기감정 상태에 기반하여 상기 대화의 상황을 인식하는 대화 상황 인식 에이전트;상기 대화의 상황을 고려하여 초기에 설정된 목표의 유지 또는 변경 여부를 결정하는 의사 결정 에이전트; 및상기 대화의 상황, 및 유지 또는 변경된 상기 목표를 기초로 의미적 응답을 생성하는 응답 생성 에이전트를 포함하는 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 의미적 응답을 문법에 맞는 문장으로 표현하는 문장 표현 에이전트를 더 포함하는 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상언어를 포함하고,상기 대상 언어 분석 에이전트는, 상기 현재 대상 언어에 대응하여 상기 대상의 일시적 감정과 일시적 기분을분석하고, 상기 과거 대상 언어에 대응하여 상기 대상의 성격을 파악함으로써, 상기 감정 분석 정보를 생성하는것인, 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 대상 언어 분석 에이전트는, 상기 의미 분석 정보를 대화 기록 DB에 기록하고, 상기 감정 분석 정보를 상기 현재 대상 언어에 대응하는 분석 정보와 상기 과거 대상 언어에 대응하는 분석 정보로 분리하여 수집 및 관리하는 것인, 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 대상 언어 분석 에이전트는, 상기 대화에 참여하는 대상이 복수인 경우, 상기 복수의 대상 각각에 대하여독립적으로 대응하도록 제공되는 것인, 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상언어를 포함하고,공개특허 10-2019-0079253-3-상기 자기감정 파악 에이전트는, 상기 현재 대상 언어에 대응하여 상기 대화형 인공지능 스스로의 일시적 감정과 일시적 기분을 모델링하고, 상기 과거 대상 언어에 대응하여 상기 대화형 인공지능 스스로의 성격을 모델링하여, 상기 자기감정 상태를 모델링하는 것인, 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 자기감정 파악 에이전트는, 상기 자기감정 상태를 상기 현재 대상 언어에 대응하는 분석 정보와 상기 과거대상 언어에 대응하는 분석 정보로 분리하여 수집 및 관리하는 것인, 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 대화 상황 인식 에이전트는, 상기 대상 언어 분석 에이전트로부터 전달받은 상기 의미 분석 정보를 바탕으로 상기 대화의 상황을 의미적 상황으로 분석하고, 상기 대상 언어 분석 에이전트로부터 전달받은 상기 감정 분석 정보 및 상기 자기감정 파악 에이전트로부터 전달받은 상기 자기감정 상태를 바탕으로 상기 대화의 상황을감정적 상황으로 분석함으로써, 상기 대화의 상태를 인식하는 것인, 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 의사 결정 에이전트는, 상기 대화 상황 인식 에이전트를 통해 전달받은 의미적 상황과 감정적 상황을 기초로, 상기 목표의 유지 또는 변경 여부를 결정하는 것인, 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 응답 생성 에이전트는, Fact Base와 외부 연동부를 이용하여 상기 의미적 응답을 생성하는 것인, 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 외부 연동부는, 상기 의미적 응답을 생성하기 위해 필요한 정보를 찾기 위한 검색 엔진 및 외부 시스템 중적어도 하나와 연동되는 것인, 다중 에이전트 시스템."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "대화형 인공지능을 위한 다중 에이전트 시스템의 동작 방법으로서,대상 언어 분석 에이전트가, 대화 중인 대상으로부터 수신한 대상 언어를 분석하여 상기 대상 언어에 대응하는의미 분석 정보 및 감정 분석 정보를 생성하는 대상 언어 분석 단계;자기감정 파악 에이전트가, 상기 대상 언어에 대하여 상기 대화의 흐름을 고려하여 상기 대화형 인공지능 스스로의 자기감정 상태를 모델링하는 자기감정 파악 단계;대화 상황 인식 에이전트가, 상기 의미 분석 정보, 상기 감정 분석 정보 및 상기 자기감정 상태에 기반하여 상기 대화의 상황을 인식하는 대화 상황 인식 단계;의사결정 에이전트가, 상기 대화의 상황을 고려하여 초기에 설정된 목표의 유지 또는 변경 여부를 결정하는 의사결정 단계; 및응답 생성 에이전트가, 상기 대화의 상황, 및 유지 또는 변경된 상기 목표를 기초로 의미적 응답을 생성하는 응답 생성 단계를 포함하는 다중 에이전트 시스템의 동작 방법."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2019-0079253-4-제12항에 있어서,문장 표현 에이전트가, 상기 의미적 응답을 문법에 맞는 문장으로 표현하는 문장 표현 단계를 더 포함하는 다중에이전트 시스템의 동작 방법."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상언어를 포함하고,상기 대상 언어 분석 단계는, 상기 현재 대상 언어에 대응하여 상기 대상의 일시적 감정과 일시적 기분을 분석하고, 상기 과거 대상 언어에 대응하여 상기 대상의 성격을 파악함으로써, 상기 감정 분석 정보를 생성하는 것인, 다중 에이전트 시스템의 동작 방법."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상언어를 포함하고,상기 자기감정 파악 단계는, 상기 현재 대상 언어에 대응하여 상기 대화형 인공지능 스스로의 일시적 감정과 일시적 기분을 모델링하고, 상기 과거 대상 언어에 대응하여 상기 대화형 인공지능 스스로의 성격을 모델링하여,상기 자기감정 상태를 모델링하는 것인, 다중 에이전트 시스템의 동작 방법."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 대화 상황 인식 단계는, 상기 대상 언어 분석 에이전트로부터 전달받은 상기 의미 분석 정보를 바탕으로상기 대화의 상황을 의미적 상황으로 분석하고, 상기 대상 언어 분석 에이전트로부터 전달받은 상기 감정 분석정보 및 상기 자기감정 파악 에이전트로부터 전달받은 상기 자기감정 상태를 바탕으로 상기 대화의 상황을 감정적 상황으로 분석함으로써, 상기 대화의 상태를 인식하는 것인, 다중 에이전트 시스템의 동작 방법."}
{"patent_id": "10-2017-0181326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 의사 결정 단계는, 상기 대화 상황 인식 에이전트를 통해 전달받은 의미적 상황과 감정적 상황을 기초로,상기 목표의 유지 또는 변경 여부를 결정하는 것인, 다중 에이전트 시스템의 동작 방법."}
{"patent_id": "10-2017-0181326", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본원의 일 실시예에 따른 대화형 인공지능을 위한 다중 에이전트 시스템은, 대화 중인 대상으로부터 수신한 대상 언어를 분석하여 상기 대상 언어에 대응하는 의미 분석 정보 및 감정 분석 정보를 생성하는 대상 언어 분석 에이 전트; 상기 대상 언어에 대하여 상기 대화의 흐름을 고려하여 상기 대화형 인공지능 스스로의 자기감정 상태를 모델링하는 자기감정 파악 에이전트; 상기 의미 분석 정보, 상기 감정 분석 정보 및 상기 자기감정 상태에 기반 하여 상기 대화의 상황을 인식하는 대화 상황 인식 에이전트; 상기 대화의 상황을 고려하여 초기에 설정된 목표 의 유지 또는 변경 여부를 결정하는 의사 결정 에이전트; 및 상기 대화의 상황, 및 유지 또는 변경된 상기 목표 를 기초로 의미적 응답을 생성하는 응답 생성 에이전트를 포함하는 다중 에이전트 시스템을 제공할 수 있다."}
{"patent_id": "10-2017-0181326", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 대화형 인공지능을 위한 다중 에이전트 시스템(구조)에 관한 것이다."}
{"patent_id": "10-2017-0181326", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "비서형 인공지능은 대화형 인공지능의 일종으로 최근 스마트폰에 기본 사양으로 탑재되는 경우가 많다. 현재의 비서형 인공지능은 제조사에서 정한 캐릭터를 기반으로 하는바, 다음과 같은 문제점을 갖고 있다. 첫째, 연속대 화를 처리할 수 없다. 하나의 문장을 기본으로 학습하고 처리하는 방식을 취하기 때문이다. 둘째, 대화 상황에 대한 이해보다는 정의된 기능 수행을 중점으로 진행된다. 따라서 사전에 정의되지 않은 질문에는 답변이 불가능 하다. 셋째, 인공지능 스스로의 감정을 생성하고 표현할 수 없다. 사람과의 깊은 의사소통을 위해서는 대화의 상황을 이해하고, 이를 토대로 자신의 감정 상태를 변화시킬 줄 알며, 주관적인 감정과 의견을 드러낼 줄 알아 야 한다. 위와 같은 문제를 극복하기 위한 시도들로 다음과 같은 접근방식의 연구들이 진행되었다. 대화의 상황을 완벽하 게 인식하고 인공지능 스스로의 감정을 표현하기 위해 거대한 Decision Tree를 사용한 \"Character-basedinteractive storytelling\", 기계학습 환경에서의 문장대 문장 학습방법인 \"Sequence to Sequence\", 이 Sequence to Sequence를 활용하여 대화의 상황에 맞는 답변을 만들어내는 방법인 \"Generative Hierarchical Neural Network Models\" 등이 대표적이다. 이들 시스템은 Decision Tree와 기계 학습을 도입하였지만, Decision Tree를 이용한 기술은 Decision Tree를 벗어난 대화를 처리할 수 없으며, 기계 학습을 이용한 기술은 대화의 상황을 이해하는 능력이 떨어지는 수준이 다. 또한, 인공지능 스스로 상황을 판단하여 행동을 결정하는 것이 아니라 주어진 입력에 대한 단순한 반응 수 준에 머물고 있다."}
{"patent_id": "10-2017-0181326", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 대화 상황에 대한 의미적 상황과 감정적 상황을 이해하고, 인공지능 스스로의 주관적인 감정 변화와 개성을 지닌 수준의 의도형 답변을 제공할 수 있는 대화형 인공지능을 위한 다중 에이전트 시스템 및 방법을 제공하고자 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2017-0181326", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 대화형 인공지능을 위한 다 중 에이전트 시스템은, 대화 중인 대상으로부터 수신한 대상 언어를 분석하여 상기 대상 언어에 대응하는 의미 분석 정보 및 감정 분석 정보를 생성하는 대상 언어 분석 에이전트; 상기 대상 언어에 대하여 상기 대화의 흐름 을 고려하여 상기 대화형 인공지능 스스로의 자기감정 상태를 모델링하는 자기감정 파악 에이전트; 상기 의미 분석 정보, 상기 감정 분석 정보 및 상기 자기감정 상태에 기반하여 상기 대화의 상황을 인식하는 대화 상황 인 식 에이전트; 상기 대화의 상황을 고려하여 초기에 설정된 목표의 유지 또는 변경 여부를 결정하는 의사 결정 에이전트; 및 상기 대화의 상황, 및 유지 또는 변경된 상기 목표를 기초로 의미적 응답을 생성하는 응답 생성 에이전트를 포함하는 다중 에이전트 시스템을 제공할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 의미적 응답을 문법에 맞는 문장으로 표현하는 문장 표현 에이전트를 더 포함하는 다중 에이전트 시스템이 제공될 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상 언어를 포함하고, 상기 대상 언어 분석 에이전트는, 상기 현재 대상 언어에 대응하여 상기 대상의 일시적 감정과 일시적 기분을 분석하고, 상기 과거 대상 언어에 대응하여 상기 대상의 성 격을 파악함으로써, 상기 감정 분석 정보를 생성할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 대상 언어 분석 에이전트는, 상기 의미 분석 정보를 대화 기록 DB에 기 록하고, 상기 감정 분석 정보를 상기 현재 대상 언어에 대응하는 분석 정보와 상기 과거 대상 언어에 대응하는 분석 정보로 분리하여 수집 및 관리할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 대상 언어 분석 에이전트는, 상기 대화에 참여하는 대상이 복수인 경우, 상기 복수의 대상 각각에 대하여 독립적으로 대응하도록 제공될 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상 언어를 포함하고, 상기 자기감정 파악 에이전트는, 상기 현재 대상 언어에 대응하여 상기 대화형 인공지능 스스로의 일시적 감정과 일시적 기분을 모델링하고, 상기 과거 대상 언어에 대 응하여 상기 대화형 인공지능 스스로의 성격을 모델링하여, 상기 자기감정 상태를 모델링할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 자기감정 파악 에이전트는, 상기 자기감정 상태를 상기 현재 대상 언어 에 대응하는 분석 정보와 상기 과거 대상 언어에 대응하는 분석 정보로 분리하여 수집 및 관리할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 대화 상황 인식 에이전트는, 상기 대상 언어 분석 에이전트로부터 전달 받은 상기 의미 분석 정보를 바탕으로 상기 대화의 상황을 의미적 상황으로 분석하고, 상기 대상 언어 분석 에 이전트로부터 전달받은 상기 감정 분석 정보 및 상기 자기감정 파악 에이전트로부터 전달받은 상기 자기감정 상 태를 바탕으로 상기 대화의 상황을 감정적 상황으로 분석함으로써, 상기 대화의 상태를 인식할 수 있다.또한, 본원의 일 실시예에 따르면, 상기 의사 결정 에이전트는, 상기 대화 상황 인식 에이전트를 통해 전달받은 의미적 상황과 감정적 상황을 기초로, 상기 목표의 유지 또는 변경 여부를 결정할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 응답 생성 에이전트는, Fact Base와 외부 연동부를 이용하여 상기 의미 적 응답을 생성할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 외부 연동부는, 상기 의미적 응답을 생성하기 위해 필요한 정보를 찾기 위한 검색 엔진 및 외부 시스템 중 적어도 하나와 연동될 수 있다. 또한, 본원의 일 실시예에 따른 대화형 인공지능을 위한 다중 에이전트 시스템의 동작 방법은, 대상 언어 분석 에이전트가, 대화 중인 대상으로부터 수신한 대상 언어를 분석하여 상기 대상 언어에 대응하는 의미 분석 정보 및 감정 분석 정보를 생성하는 대상 언어 분석 단계; 자기감정 파악 에이전트가, 상기 대상 언어에 대하여 상기 대화의 흐름을 고려하여 상기 대화형 인공지능 스스로의 자기감정 상태를 모델링하는 자기감정 파악 단계; 대화 상황 인식 에이전트가, 상기 의미 분석 정보, 상기 감정 분석 정보 및 상기 자기감정 상태에 기반하여 상기 대 화의 상황을 인식하는 대화 상황 인식 단계; 의사결정 에이전트가, 상기 대화의 상황을 고려하여 초기에 설정된 목표의 유지 또는 변경 여부를 결정하는 의사결정 단계; 및 응답 생성 에이전트가, 상기 대화의 상황, 및 유지 또는 변경된 상기 목표를 기초로 의미적 응답을 생성하는 응답 생성 단계를 포함하는 다중 에이전트 시스템의 동작 방법을 제공할 수 있다. 또한, 본원의 일 실시예에 따르면, 문장 표현 에이전트가, 상기 의미적 응답을 문법에 맞는 문장으로 표현하는 문장 표현 단계를 더 포함하는 다중 에이전트 시스템의 동작 방법이 제공될 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상 언어를 포함하고, 상기 대상 언어 분석 단계는, 상기 현재 대상 언어에 대응 하여 상기 대상의 일시적 감정과 일시적 기분을 분석하고, 상기 과거 대상 언어에 대응하여 상기 대상의 성격을 파악함으로써, 상기 감정 분석 정보를 생성할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 대상 언어 분석 단계는, 상기 의미 분석 정보를 대화 기록 DB에 기록하 고, 상기 감정 분석 정보를 상기 현재 대상 언어에 대응하는 분석 정보와 상기 과거 대상 언어에 대응하는 분석 정보로 분리하여 수집 및 관리할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 대상 언어 분석 단계는, 상기 대화에 참여하는 대상이 복수인 경우, 상 기 복수의 대상 각각에 대하여 독립적으로 대응하도록 제공될 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상 언어를 포함하고, 상기 자기감정 파악 단계는, 상기 현재 대상 언어에 대응 하여 상기 대화형 인공지능 스스로의 일시적 감정과 일시적 기분을 모델링하고, 상기 과거 대상 언어에 대응하 여 상기 대화형 인공지능 스스로의 성격을 모델링하여, 상기 자기감정 상태를 모델링할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 자기감정 파악 단계는, 상기 자기감정 상태를 상기 현재 대상 언어에 대응하는 분석 정보와 상기 과거 대상 언어에 대응하는 분석 정보로 분리하여 수집 및 관리할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 대화 상황 인식 단계는, 상기 대상 언어 분석 에이전트로부터 전달받은 상기 의미 분석 정보를 바탕으로 상기 대화의 상황을 의미적 상황으로 분석하고, 상기 대상 언어 분석 에이전트 로부터 전달받은 상기 감정 분석 정보 및 상기 자기감정 파악 에이전트로부터 전달받은 상기 자기감정 상태를 바탕으로 상기 대화의 상황을 감정적 상황으로 분석함으로써, 상기 대화의 상태를 인식할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 의사 결정 단계는, 상기 대화 상황 인식 에이전트를 통해 전달받은 의 미적 상황과 감정적 상황을 기초로, 상기 목표의 유지 또는 변경 여부를 결정할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 응답 생성 단계는, Fact Base와 외부 연동부를 이용하여 상기 의미적 응답을 생성할 수 있다. 또한, 본원의 일 실시예에 따르면, 상기 외부 연동부는, 상기 의미적 응답을 생성하기 위해 필요한 정보를 찾기 위한 검색 엔진 및 외부 시스템 중 적어도 하나와 연동될 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2017-0181326", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단 중 어느 하나에 의하면, 대상이 전달하고자 하는 의미뿐만 아니라 감정 또한 분 석하고, 이를 통해 대화의 상황 판단 능력의 향상을 확보할 수 있다. 또한, 자기감정 파악 기능과 의사 결정 기 능을 포함하기 때문에, 인공지능 스스로의 감정 상태와 목표에 따라 대화의 주제를 변경하여 대화의 상황을 주 도할 수 있는 능력을 확보할 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2017-0181326", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 도 1은 본원의 일 실시예에 따른 다중 에이전트 시스템(구조)의 블록도이다. 이하에서 설명되는 에이전트는 동 적 환경 내에 위치하여 주어진 목적 달성을 위해 자율적이고 유연하게 환경 변화를 지각하고 학습하고 의사결정 하고 또한 행동할 수 있는 컴퓨터 프로그램이나 시스템(모듈) 또는 그러한 시스템을 분석하고 설계하기 위한 도 구를 총칭할 수 있다. 또한, 본원의 일 실시예에 따른 다중 에이전트 시스템은 대화형 인공지능 시스템이라 칭 할 수 있다. 도 1을 참조하면, 다중 에이전트 시스템은 대상 언어 분석 에이전트, 자기감정 파악 에이전트, 대화 상황 인식 에이전트, 의사 결정 에이전트 및 응답 생성 에이전트를 포함할 수 있으나, 이에 한정되 는 것은 아니다. 또한, 다중 에이전트 시스템은 문장 표현 에이전트를 포함할 수 있다. 도 2는 본원의 일 실시예에 따른 다중 에이전트 시스템의 대상 언어 분석 에이전트의 블록도이다. 대상 언어 분석 에이전트(Target Language Analysis Agent)는, 대화 중인 대상(상대방)으로부터 수신한 대 상 언어를 분석하여 상기 대상 언어에 대응하는 의미 분석 정보 및 감정 분석 정보를 생성할 수 있다. 도 2를 참조하면, 대상 언어 분석 에이전트는 대상의 언어를 의미적, 감정적으로 분석하며 이를 축적한다. 이 때, 대상의 언어는 언어 분석부에 의해 의미적 분석 및 감정적 분석 중 적어도 하나로 분석된다. 대상의 언어의 의미는 대화 기록 DB에 기록되고, 대상의 감정은 현재 진행되는 대화와 과거에 진행된 대화에 따 라 분리되어 수집, 관리된다. 현재 진행되는 대화의 감정 정보를 수집하는 현재 감정 DB는 대상의 일시적 감정과 일시적 기분을 파악하는데 사용될 수 있다. 과거에 진행된 대화의 감정 정보를 수집하는 과거 감정 DB는 대상의 성격을 파악하는데 사용될 수 있다. 또한, 대상 언어 분석 에이전트가 분석하는 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상 언어를 포함할 수 있다. 대상 언어 분석 에이전트는, 상기 현 재 대상 언어에 대응하여 상기 대상의 일시적 감정과 일시적 기분을 분석하고, 상기 과거 대상 언어에 대응하여 상기 대상의 성격을 파악함으로써, 상기 감정 분석 정보를 생성할 수 있다. 도 2를 참조하면, 대상 언어 분석 에이전트는, 대상 언어에 대응하는 의미 분석 정보를 대화 기록 DB에 기록하고, 대상 언어에 대응하는 감정 분석 정보를 상기 현재 대상 언어에 대응하는 분석 정보와 상기 과거 대상 언어에 대응하는 분석 정보로 분리하여 수집 및 관리할 수 있다. 또한, 대상 언어 분석 에이전트는, 대화에 참여하는 대상이 복수인 경우, 복수의 대상 각각에 대하여 독립 적으로 대응하도록 제공될 수 있다. 대상 언어 분석 에이전트는 후술할 의사 결정 에이전트의 피드백 및 대화의 대상(상대방)의 발언(말)에 대한 단편 분석과 심층 분석을 통하여 상대방이 전하고자 하는 의미와 감정을 파악하여 이를 대화 상황 인식 에 이전트에 전달할 수 있다. 여기서, 단편 분석은 현재 상대방으로부터 전달받은 문장(대화 언어)에 대한 의 미적·분석 및 감정적인 분석을 의미한다. 한편, 심층 분석은 대화 상황 인지 에이전트로부터 받은 피드백 을 통해 업데이트 받은 상대방(대상)의 의도와 감정을 누적시킴으로써 상대의 실제 의도와 감정을 유추하기 위 한 분석을 의미한다. 심층 분석은 대화의 초기에는 단편 분석의 값만으로 구성되기 때문에 대상에 대한 선입견 이 반영될 수 있지만, 이러한 심층 분석은 대화가 진행됨에 따라 실제 대상의 의도와 감정에 맞게 업데이트될 수 있다. 심층적 반응을 통한 모델링은 상대방과의 대화가 진행되어가는 상황으로부터 발생하여 누적되는 감정 적 변화를 모델링할 수 있다. 도 3은 본원의 일 실시예에 따른 다중 에이전트 시스템의 자기감정 파악 에이전트의 블록도이다. 자기감정 파악 에이전트(Self Emotion Awareness Agent)는, 상기 대상 언어에 대하여 상기 대화의 흐름을 고려하여 상기 대화형 인공지능 스스로의 자기감정 상태를 모델링할 수 있다. 자기감정 파악 에이전트는 대화의 흐름에 따라 대화하는 대상(상대방)의 말(대화 언어)에 대하여 대화형 인공지능 스스로의 감정을 모델링 하는 구성이다. 자기감정 파악 에이전트에 의해 고려되는 상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언 어 및 과거 진행된 대화에 대응하는 과거 대상 언어를 포함할 수 있다. 자기감정 파악 에이전트는, 상기 현재 대상 언어에 대응하여 상기 대화형 인공지능 스스로의 일시적 감정과 일시적 기분을 모델링하고, 상기 과 거 대상 언어에 대응하여 상기 대화형 인공지능 스스로의 성격을 모델링하여, 상기 자기감정 상태를 모델링할 수 있다. 자기감정 파악 에이전트는, 상기 자기감정 상태를 상기 현재 대상 언어에 대응하는 분석 정보와 상기 과거 대상 언어에 대응하는 분석 정보로 분리하여 수집 및 관리할 수 있다. 도 3을 참조하면, 대화형 인공지능의 감 정은 감정 모델링부에 의해 분석될 수 있다. 또한, 인공지능의 대화 기록은 대화 기록 DB에 기록될 수 있다. 감정 모델링부에 의해 분석된 인공지능의 감정은 현재 진행되는 대화와 과거에 진행된 대화에 따라 분리되어 수집, 관리될 수 있다. 예시적으로 도 3을 참조하면, 현재 진행되는 대화와 관련된 현재 감정 정보는 현재 감정 DB에 수집될 수 있다. 또한, 과거에 진행된 대화와 관련된 과거 감정 정보는 과거 감정 DB 에 수집될 수 있다. 현재 감정 DB에 수집된 현재 감정 정보는 대화형 인공지능의 일시적 감정과 기분을 파 악하는데 사용되고, 과거 감정 DB에 수집된 과거 감정 정보는 대화형 인공지능의 성격을 파악하는데 사용될 수 있다. 자기감정 파악 에이전트는 상대방으로부터 전달받은 문장을 통해 대화형 인공지능 스스로의 감정의 변화를 모델링하기 위한 에이전트로서, 대상 언어 분석 에이전트와 마찬가지로 단편 분석과 심층 분석을 통해 상대 방의 발언(문장)으로부터 대화형 인공지능 스스로의 감정을 파악하여 이를 대화 상황 인식 에이전트에 전달 할 수 있다. 단편적 반응을 통한 모델링은 상대방의 일정 수준이상의 강한 반응을 통해 일어나는 순간적인 감 정적 변화에 대한 것이다. 이는 강한 자극으로 인한 갑작스런 감정의 변화 혹은 순간적인 감정의 표출에 영향을 미친다.이처럼, 자기감정 파악 에이전트는 대화형 인공지능 스스로의 감정적 변화를 모델링할 수 있다. 예시적으 로, 자기감정 파악 에이전트의 대화형 인공지능 스스로의 자기감정 상태 모델링에는, 이인근, 서석태, 정혜 천, 권순학. . 인공 감정 모델의 설계. 한국지능시스템학회 학술발표 논문집, 17, 58-62.에 의해 제안 된 인공 감정 모델링 기술이 이용될 수 있다. 또한, 자기감정 파악 에이전트는 대화형 인공지능 스스로의 감정을 대화에 참여하는 대상의 수와 무관하게 모델링하도록 구비될 수 있다. 한편, 대화 상황 인식 에이전트(Dialogue Situation Recognition Agent)는 상기 의미 분석 정보, 상기 감 정 분석 정보 및 상기 자기감정 상태에 기반하여 상기 대화의 상황을 인식할 수 있다. 대화 상황 인식 에이전트는 대상 언어 분석 에이전트를 통해 상대방의 언어의 의미와 감정을 전달받고, 자기감정 파악 에이전트를 통해 대화형 인공지능 스스로의 감정을 전달받을 수 있다. 대화 상황 인식 에이 전트는 대상 언어 분석 에이전트로부터 전달받은 의미 분석 정보를 바탕으로 상기 대화의 상황을 의미 적 상황으로 분석할 수 있다. 또한, 대화 상황 인식 에이전트는 대상 언어 분석 에이전트로부터 전달 받은 감정 분석 정보 및 자기감정 파악 에이전트로부터 전달받은 자기감정 상태를 바탕으로 대화의 상황을 감정적 상황으로 분석할 수 있다. 이러한 분석을 통해, 대화 상황 인식 에이전트는 대화의 상태를 인식할 수 있다. 즉, 대화 상황 인식 에이전트는 대상 언어 분석 에이전트와 자기감정 파악 에이전트를 통해 전달받은 대상의 언어의 의미와 대상과 자신의 현재 감정적 상태를 바탕으로 대화의 상황을 의미적, 감정 적으로 인식하고 판단할 수 있다. 또한, 대화 상황 인식 에이전트는 파악한 대화의 상황을 의사 결정 에이 전트에 전달할 수 있다. 또한, 대상 상황 인식 에이전트는 상기와 같이 파악된 대화 상황에 대하여 대상 언어 분석 에이전트와 자기감정 파악 에이전트에게 피드백을 해주어 대상 언어 분석 에이전트와 자기감정 파악 에이전트 각각이 심층 분석을 위한 심층 분석 모듈을 업데이트하도록 할 수 있다. 의사 결정 에이전트(Decision Making Agent)는 상기 대화의 상황을 고려하여 초기에 설정된 목표의 유지 또 는 변경 여부를 결정할 수 있다. 의사 결정 에이전트는, 대화 상황 인식 에이전트를 통해 전달받은 의 미적 상황과 감정적 상황을 기초로, 초기에 설정된 목표 또는 재설정된 목표의 유지 또는 변경(재설정) 여부를 결정할 수 있다. 즉, 의사 결정 에이전트 는 대화형 인공지능이 설정 또는 재설정한 목표를 대화 상황에 따라 계속적으로 유지하거나, 혹은 다시 변경(재설정)할 수 있다. 의사 결정 에이전트는 대화 상황 인식 에이전트를 통해 파악한 대화의 상황에 대하여 대화형 인공지능 의 발화 목적을 포함하여 다음 발언의 의도를 결정하는 에이전트라 할 수 있다. 또한, 의사 결정 에이전트(4 0)는 상기와 같이 결정된 다음 발언의 의도를 대상 언어 분석 에이전트의 추론 엔진 및 대화 상황 인식 에 이전트의 추론 엔진 각각에게 피드백을 주어, 주어진 대화의 상황에 대해 각 에이전트마다 주관적인 해석 (분석)을 수행하도록 할 수 있다. 의사 결정 에이전트는 대화형 인공지능 스스로의 목적을 이루기 위해 대상 언어 분석 에이전트와 자기 감정 파악 에이전트를 통해 만들어진 감정 모델을 통한 시뮬레이션을 통해 의사를 결정할 수 있다. 도 4는 본원의 일 실시예에 따른 다중 에이전트 시스템의 응답 생성 에이전트의 블록도이다. 응답 생성 에이전트(Response Generating Agent)는 상기 대화의 상황, 및 유지 또는 변경된 상기 목표를 기 초로 의미적 응답(의미적 답변)을 생성할 수 있다. 즉, 응답 생성 에이전트는 의사 결정 에이전트를 통해 설정 또는 재설정된 목표와 대화 상황 인식 에이전트를 통해 파악된 대화 상황을 바탕으로 의미적 응 답(의미적 답변)을 생성할 수 있다. 도 4를 참조하면, 응답 생성 에이전트(Response Generating Agent)는, Fact Base와 외부 연동부를 이용하여 상기 의미적 응답을 생성할 수 있다. 이때, 상기 의미적 응답은 문장 생성부에 의해 생성될 수 있다. 예시적으로 도 4를 참조하면, 문장 생성부는 Fact Base의 데이터를 기반으로 답변 문장(의미적 응답)을 생성할 수 있다. 또한, 외부 연동부는, 상기 의미적 응답을 생성하기 위해 필요한 정보를 찾기 위 한 검색 엔진 및 외부 시스템 중 적어도 하나와 연동되도록 구비되는 구성일 수 있다. 여기서, 외부 시스템이 라 함은 정보를 찾기 위해 이용될 수 있는 외부의 다양한 프로그램, 어플리케이션, 수단, 기능, 유닛, 모듈, 알 고리즘 등을 포괄하는 넓은 개념으로 이해함이 바람직하다. 응답 생성 에이전트는 의사 결정 에이전트를 통해 결정된 다음 발언의 의도를 문장의 수준으로 생성해 주는 에이전트라 할 수 있다. 또한 예시적으로, 응답 생성 에이전트의 의미적 응답(의미적 문장) 생성에는, Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \"Sequence to sequence learning with neural networks.\" Advances in neural information processing systems. 2014.에 의해 제안된 기계학습을 이용한 문장 생성 기술이 이용될 수 있다. 한편, 문장 표현 에이전트(Sentence Expressing Agent)는 응답 생성 에이전트를 통해 생성된 의미적 응답(의미적 답변)을 문법에 맞는 문장으로 표현할 수 있다. 예시적으로, 문장 표현 에이전트는 응답 생성 에이전트에 생성된 결과 문장(의미적 응답에 대응하는 문장)을 문법과 특정 어투(사투리)에 맞도록 변형해 주는 에이전트일 수 있다. 예시적으로, 문장 표현 에이전트의 문법적 문장(문법에 맞는 문장) 생성에는, Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \"Sequence to sequence learning with neural networks.\" Advances in neural information processing systems. 2014.에 의해 제안된 기계학습을 이용한 문장 생성 기술이 이용될 수 있다. 이처럼, 본원은 상술한 에이전트들을 통해 대화형 인공지능과 대화하는 상대방인 대상의 언어를 의미적, 감정적 으로 분석하고 이를 기초로 인공지능의 감정 상태를 모델링하고, 이를 통해 대화의 상황을 의미적, 감정적으로 정의하며, 설정된 목표를 유지 또는 재계획하여 의미적 응답을 생성함으로써 대화의 상황을 유지 또는 재계획된 목표대로 이끌 수 있는 다중 에이전트 시스템(구조) 또는 대화형 인공지능 시스템을 제공할 수 있다. 또한, 본원에 의하면, 대상 언어 분석 에이전트와 대화 상황 인식 에이전트를 통해 대화의 상황을 판단 하고 이를 바탕으로 의사 결정 에이전트를 통해 인공지능이 목표로 하는 대화방향을 이끎으로써 연속대화를 처리할 수 있다. 감정 처리 또한 이와 마찬가지로, 대상 언어 분석 에이전트와 자기감정 파악 에이전트(2 0)를 통해 상대의 언어를 분석하여 상대와 자신의 단편적인 감정과 심층적인 감정을 모델링하고, 대화 상황 인 식 에이전트를 통해 감정적인 상황을 고려한 상황판단이 가능하다. 이렇게 판단된 감정을 의사 결정 에이전 트의 목표와 맞물려 자신의 감정을 드러낼지 말지를 결정하고 응답 생성 에이전트를 통해 자신의 감정 을 포함한 답변을 생성할 수 있다. 한편, 이하에서는 본원의 일 실시예에 따른 다중 에이전트 시스템 동작 방법에 관하여 설명한다. 다만, 본원의 일 실시예에 따른 다중 에이전트 시스템 동작 방법은 전술한 본원의 일 실시예에 따른 다중 에이전트 시스템과 동일하거나 상응하는 기술적 특징을 공유한다고 할 것이므로, 동일 또는 유사한 구성에 대해서는 동일한 도면 부호를 부여하고, 중복되는 설명은 간략히 하거나 생략하기로 한다. 도 5는 본원의 일 실시예에 따른 다중 에이전트 시스템 동작 방법의 동작 흐름도이다. 도 5를 참조하면, 본원의 일 실시예에 따른 대화형 인공지능을 위한 다중 에이전트 시스템의 동작 방법은, 대상 언어 분석 에이전트가 대화 중인 대상으로부터 수신한 대상 언어를 분석하여 상기 대상 언어에 대응하는 의 미 분석 정보 및 감정 분석 정보를 생성하는 대상 언어 분석 단계(S110), 자기감정 파악 에이전트가 상기 대상 언어에 대하여 상기 대화의 흐름을 고려하여 상기 대화형 인공지능 스스로의 자기감정 상태를 모델링하는 자기감정 파악 단계(S120), 대화 상황 인식 에이전트가 상기 의미 분석 정보, 상기 감정 분석 정보 및 상기 자기감정 상태에 기반하여 상기 대화의 상황을 인식하는 대화 상황 인식 단계(S130), 의사결정 에이전트가 상기 대화의 상황을 고려하여 초기에 설정된 목표의 유지 또는 변경 여부를 결정하는 의사결정 단계(S140), 및 응답 생성 에이전트가 상기 대화의 상황, 및 유지 또는 변경된 상기 목표를 기초로 의미적 응답을 생성하는 응답 생성 단계(S150)를 포함할 수 있다. 또한 도 5를 참조하면, 본원의 일 실시예에 따른 대화형 인공지능을 위한 다중 에이전트 시스템의 동작 방법은, 문장 표현 에이전트가 상기 의미적 응답을 문법에 맞는 문장으로 표현하는 문장 표현 단계(S160)를 포함할 수 있다. 이처럼, 본원의 일 실시예에 따른 대화형 인공지능을 위한 다중 에이전트 시스템의 동작 방법은 대화를 하는 상 대방이 전달하고자 하는 의미와 상대방의 감정을 파악하는 대상 언어 분석(Target Language Analysis), 상대방 의 말에 대해 인공지능 스스로의 감정적 변화를 모델링하는 자기감정 파악(Self Emotion Awareness), 상대방의 언어를 통해 분석된 의미와 상대방의 감정, 자신의 감정을 통해 대화의 상황을 의미적, 감정적으로 인식하는 대 화 상황 인식(Dialogue Situation Recognition), 대화의 상황에 따라 초기에 설정된 목표를 유지할지 혹은 설정 된 목표를 변경할지 여부를 결정하는 의사 결정(Decision Making), 대화의 상황과 의사 결정을 통해 설정된 대 화의 목표에 따라 의미적 응답을 생성하는 응답 생성(Response Generating), 생성된 의미적 응답을 문법에 맞는문장으로써 표현하는 문장 표현(Sentence Expressing)의 단계로 세분화, 계층화될 수 있다. 또한, 상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상 언어를 포함하고, 상기 대상 언어 분석 단계는, 상기 현재 대상 언어에 대응하여 상기 대상의 일시적 감정 과 일시적 기분을 분석하고, 상기 과거 대상 언어에 대응하여 상기 대상의 성격을 파악함으로써, 상기 감정 분 석 정보를 생성할 수 있다. 또한, 상기 대상 언어 분석 단계(S110)는, 상기 의미 분석 정보를 대화 기록 DB에 기록하고, 상기 감정 분 석 정보를 상기 현재 대상 언어에 대응하는 분석 정보와 상기 과거 대상 언어에 대응하는 분석 정보로 분리하여 수집 및 관리할 수 있다. 또한, 상기 대상 언어 분석 단계(S110)는, 상기 대화에 참여하는 대상이 복수인 경우, 상기 복수의 대상 각각에 대하여 독립적으로 대응하도록 제공될 수 있다. 또한, 상기 대상 언어는, 현재 진행되는 대화에 대응하는 현재 대상 언어 및 과거 진행된 대화에 대응하는 과거 대상 언어를 포함하고, 상기 자기감정 파악 단계(S120)는, 상기 현재 대상 언어에 대응하여 상기 대화형 인공지 능 스스로의 일시적 감정과 일시적 기분을 모델링하고, 상기 과거 대상 언어에 대응하여 상기 대화형 인공지능 스스로의 성격을 모델링하여, 상기 자기감정 상태를 모델링할 수 있다. 또한, 상기 자기감정 파악 단계(S120)는, 상기 자기감정 상태를 상기 현재 대상 언어에 대응하는 분석 정보와 상기 과거 대상 언어에 대응하는 분석 정보로 분리하여 수집 및 관리할 수 있다. 또한, 상기 대화 상황 인식 단계(S130)는, 상기 대상 언어 분석 에이전트로부터 전달받은 상기 의미 분석 정보를 바탕으로 상기 대화의 상황을 의미적 상황으로 분석하고, 상기 대상 언어 분석 에이전트로부터 전달 받은 상기 감정 분석 정보 및 상기 자기감정 파악 에이전트로부터 전달받은 상기 자기감정 상태를 바탕으로 상기 대화의 상황을 감정적 상황으로 분석함으로써, 상기 대화의 상태를 인식할 수 있다. 또한, 상기 의사 결정 단계(S140)는, 상기 대화 상황 인식 에이전트를 통해 전달받은 의미적 상황과 감정적 상황을 기초로, 상기 목표의 유지 또는 변경 여부를 결정할 수 있다. 또한, 상기 응답 생성 단계(S150)는, Fact Base와 외부 연동부를 이용하여 상기 의미적 응답을 생성할 수 있다. 상기 외부 연동부는, 상기 의미적 응답을 생성하기 위해 필요한 정보를 찾기 위한 검색 엔진 및 외부 시스템 중 적어도 하나와 연동될 수 있다. 한편, 도 6은 본원의 일 실시예에 따른 다중 에이전트 시스템(구조)의 일부에 의해 구현되는 CCAI 시스템 (Character based Conversational Artificial Intelligence System)과 기존 비서형 인공지능인 Apple의 Siri 및 Google의 Google Assistant를 예시적으로 비교한 표이다. 본원과 관련된 CCAI는 세 가지 에이전트(대상 언어 분석 에이전트, 응답 생성 에이전트, 문장 표현 에이전트)로 구성하였다. 대상 언어 분석 에이전트에서는 NLTK를 사용하여 기본적인 언어 분석을 하였다. 응답 생성 에이전 트는 ‘2001 A Space Odyssey’[9]의 HAL, ‘Prometheus’[10]의 David, ‘Alien Covenant’[11]의 David와 Walter의 대사를 훈련시켰다. 문장 표현 에이전트는 위의 대사들과 ‘Cornell Movie-Dialogs Corpus’를 훈련 시켰다. 도 6의 표는 Siri와 Google Assistant, 제안하는 CCAI 시스템에게 동일한 질문을 하여 답변을 얻은 것이다. 해 당 질문과 답변들은 모두 제안하는 CCAI에서 훈련시키지 않은 내용들이다. 도 6의 표에 따르면, Siri는 질문 , 를 통해, Google Assistant는 질문, , 를 통해 미리 지정된 답변을 하는 것을 알 수 있다. Siri의 질문, 와 Google Assistant의 질문 에서는 검색엔진 혹은 어플리케이션과 연동하여 해당 기능 을 수행하는 모습을 볼 수 있다. 또한, Siri의 질문, 과 Google Assistant의 , 의 경우 해당 질 문에 대한 답변이 존재하지 않아 해당 질문을 되묻고 회피하는 모습을 볼 수 있다. 반면, 본원의 일 실시예에 따른 다중 에이전트 시스템(구조)의 일부에 의해 구현되는 CCAI의 경우 질문∼ 에 대한 답변에서 훈련되지 않은 질문에 대해 답변을 할 수 있음을 확인할 수 있었다. 또 한, 훈련 데이터로 사용된 ‘2001 A Space Odyssey’의 HAL과 ‘Prometheus’의 David, ‘Alien Covenant’의 David와 Walter의 성격이 드러나는 것을 확인할 수 있다. 한편, 본원의 일 실시예에 따른 다중 에이전트 시스템 동작 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있 는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이 프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같 은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2017-0181326", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다."}
{"patent_id": "10-2017-0181326", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 다중 에이전트 시스템(구조)의 블록도이다. 도 2는 본원의 일 실시예에 따른 다중 에이전트 시스템의 대상 언어 분석 에이전트의 블록도이다. 도 3은 본원의 일 실시예에 따른 다중 에이전트 시스템의 자기감정 파악 에이전트의 블록도이다. 도 4는 본원의 일 실시예에 따른 다중 에이전트 시스템의 응답 생성 에이전트의 블록도이다. 도 5는 본원의 일 실시예에 따른 다중 에이전트 시스템 동작 방법의 동작 흐름도이다. 도 6은 본원의 일 실시예에 따른 다중 에이전트 시스템(구조)에 의해 구현되는 CCAI 시스템(Character based Conversational Artificial Intelligence System)과 기존 비서형 인공지능인 Apple의 Siri 및 Google의 Google Assistant를 예시적으로 비교한 표이다."}
