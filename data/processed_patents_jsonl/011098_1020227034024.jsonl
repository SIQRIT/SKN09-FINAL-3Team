{"patent_id": "10-2022-7034024", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0140639", "출원번호": "10-2022-7034024", "발명의 명칭": "보안, 복원, 및 제어가 강화된 분산된 데이터 스토리지를 위한 방법 및 시스템", "출원인": "묘타, 인크.", "발명자": "정, 재윤"}}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "보안 스토리지(secure storage)로부터 키 암호화 및 인코딩된 파일 및 관련 메타데이터를 안전하고 신뢰성있게재구성하기 위한 프로세서 기반 서버에 있어서,파일을 청크화(chunking) 및 암호화(encrypting)하기 위한 데이터 프로세싱 엔진 - 상기 데이터 프로세싱 엔진은 파일 암호화 엔진 및 메타데이터 암호화 엔진을 포함함 -샤드 버퍼(shard buffer);수정 및 샤드화된(sharded) 메타데이터를 적어도 일시적으로 저장하기 위한 스토리지;스케줄러 모듈 및 스토리지 선택기 모듈을 포함하는 동기화 프로세싱 유닛;데이터를 저장하기 위해 상기 스토리지와 인터페이싱하기 위한 네트워크 인터페이스; 및 재구성을 위한 파일들의 사용자 선택을 위한 적어도 하나의 사용자 인터페이스;를 포함하는, 서버."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,디스플레이(display)를 위한 사용자 선택 옵션(user selection option)들을 생성하기 위한 지식 베이스(knowledge base);를 더 포함하는,서버."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,인공 지능(Artificial Intelligence, AI) 모듈 - 상기 AI 모듈은 이벤트 로그 수집기(event log collector),알고리즘을 생성하기 위한 데이터 분석기(data analyzer), 파라미터 튜너(parameter tuner), 및 실행기(executor) 중 적어도 하나를 포함함 -;을 더 포함하는,서버."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 스토리지 선택기 모듈은 상기 데이터 프로세싱 엔진 내에 구성되는 최적화 알고리즘(optimizationalgorithm)을 구현하는, 공개특허 10-2022-0140639-3-서버."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 데이터 프로세싱 엔진은 상기 스토리지로 하여금 임의의 데이터 중복제거(data deduplication) 없이 저장하도록 구성되는, 서버"}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 데이터 프로세싱 엔진은 n 개의 시나리오 중에서 t 개(t out of n scenario)에 근거하여 파일을 재구성하기 위해 사용되는, 서버."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 사용자 인터페이스는 파일 시스템 인터페이스(file system interface), 어플리케이션 프로그래밍 인터페이스(application programming interface), 커맨드 라인 인터페이스(command line interface), 및 도식적 유저인터페이스(graphical user interface)를 포함하고, 상기 사용자 인터페이스는 원격 사용자 디바이스상에 적어도 부분적으로 상주하는,서버."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 사용자 인터페이스는 사용자 원격 제어 가능(remotely user controllable)한 것인,서버."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 서버는 암호화 및 파싱된 파일을 재구성하도록 구성되고, 상기 파일은:적어도 하나의 암호화 키를 생성하는 단계;암호화를 위한 적어도 하나의 파일을 선택하는 단계;컴퓨터연산적 및 이론적 암호화방식(computational and theoretical cryptography)의 조합에 기초한 알고리즘을 구현하는 단계 - 상기 알고리즘은:상기 파일의 상기 콘텐츠 데이터 부분을 n개의 콘텐츠 청크(content chunk)들의 체인(chain)으로 파싱(parsing)하는 단계 - 각각의 상기 청크에는 청크 ID가 할당됨 -; 청크 당 상기 적어도 하나의 암호화 키를 사용하여, 상기 콘텐츠 청크들 각각을 암호화하는 단계;공개특허 10-2022-0140639-4-각각의 상기 콘텐츠 청크를 복수의 콘텐츠 샤드(content shard)들로 인코딩(encoding) 및 파싱(parsing)하는 단계;상기 청크 ID들을 암호화하는 단계; 및상기 증강된 메타데이터를 복수의 메타데이터 샤드들로 파싱하여 상기 메타데이터를 수정하는 단계;상기 복수의 콘텐츠 샤드들을 저장(storage)을 위해 적어도 하나의 위치로 전달하는 단계; 및상기 복수의 메타데이터 샤드들을 저장을 위해 적어도 하나의 위치로 전달하는 단계;상기 암호화된 청크 ID들로 상기 메타데이터를 증강시키는 단계;상기 적어도 하나의 키를 복수의 키 샤드(key shard)들로 파싱하는 단계;상기 복수의 키 샤드들을 암호화하는 단계; 및상기 암호화된 복수의 키 샤드들을 상기 증강된 메타데이터에 추가하는 단계;를 포함함 -;에 의해 키-암호화(key-encrypted)되고 인코딩되는,서버."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "스토리지로부터 적어도 하나의 암호화된 컴퓨터 파일을 안전하고 신뢰 가능하게 재구성하기 위한 프로세서-기반서버를 위한 방법에 있어서, 상기 컴퓨터 파일은 데이터 및 관련 메타데이터를 포함하고, 상기 암호화는 n1개의청크들로 파싱된 상기 적어도 하나의 암호화된 파일의 데이터 콘텐츠를 이용하는 컴퓨터 연산적 및 이론적 암호화 방식 둘 다를 포함하고, 각각의 상기 청크는 각각의 샤드가 복수의 스토리지 디바이스들에 걸쳐 개별적으로저장되는 n2개의 샤드들로 파싱되고, 그리고 상기 적어도 하나의 암호화된 컴퓨터 파일의 메타데이터는 하나 이상의 암호화 키들을 포함하고 후속적으로 n3개의 부분들로 파싱되고, 상기 n3개의 부분들 각각은 별도로 저장되고, 상기 방법은:인증된 사용에 의해 재구성을 위한 선택을 위해 암호화된 파일들의 리스트(list)를 전달하는 단계 - 상기 리스트는 암호화 시간(encryption time)을 포함함 -;재구성을 위한 적어도 하나의 파일을 선택하는 경우, 상기 프로세서가 적어도 t3개의 메타데이터 부분들을 식별하는 단계 - t3은 n3보다 작음 -;스토리지 내의 상기 파일에 대한 메타데이터의 모든 파싱된 부분들을 식별함으로써 상기 메타데이터를 재구성하는 단계;상기 프로세서가 청크 당 적어도 t2개의 콘텐츠 샤드들을 식별하는 단계 - t2는 청크별로 상이할 수 있고, 각각의 t2는 관련된 n2보다 작음 -;각각의 청크를 재구성하고 상기 콘텐츠 데이터 파일을 재조립하는 단계; 및상기 재구성된 데이터 파일을 상기 사용자에게 전달하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,공개특허 10-2022-0140639-5-콘텐츠 샤드들의 수는 암호화시 사용자 구성가능하고 t=2 및 n=3인 t, n 각각으로 한정되지 않는 것인, 방법."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 프로세서-기반 서버는 사용자 인터페이스를 이용하여 입력되는 데이터를 제어하고 그리고 암호화된 파일들의 상기 리스트는 상기 사용자 인터페이스로 선택을 위해 전달되는,방법."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "스토리지 디바이스 상에 상주하는 암호화된 파일을 안전하고 신뢰 가능하게 재-저장(re-store)하기 위한 프로세서를 위한 방법에 있어서, 사전-암호화된 형태의 상기 파일은 컨텐츠 데이터 및 관련 메타데이터를 포함하고,상기 암호화 및 인코딩된 컨텐츠 데이터를 저장하기 위한 적어도 하나의 위치는 상기 암호화 및 인코딩된 메타데이터를 저장하기 위한 적어도 하나의 위치와 상이하고, 상기 암호화 방법은:상기 파일의 상기 콘텐츠 데이터 부분을 n개의 콘텐츠 청크(content chunk)들의 체인(chain)으로 파싱(parsing)하는 단계 - 각각의 상기 청크에는 청크 ID가 할당됨 -;청크 당 상기 적어도 하나의 암호화 키를 사용하여, 상기 콘텐츠 청크들 각각을 암호화하는 단계;각각의 상기 콘텐츠 청크를 복수의 콘텐츠 샤드(content shard)들로 인코딩(encoding) 및 파싱하는 단계;상기 청크 ID들을 암호화하는 단계; 및상기 증강된 메타데이터를 암호화를 위한 복수의 메타데이터 샤드들로 파싱하여 상기 메타데이터를 수정하는 단계;를 포함하고,상기 방법은 컴퓨터연산적 및 이론적 암호화방식(computational and theoretical cryptography)의 조합에 기초하여 상기 구현된 알고리즘의 단계들을 리버싱(reversing)하는 단계를 포함하고, 상기 파일의 상기 콘텐츠 데이터 부분은 n개의 콘텐츠 청크(content chunk)들의 체인(chain)으로 파싱되고 - 각각의 상기 청크에는 청크 ID가 할당됨 -; 각각의 상기 콘텐츠 청크들은 청크 당 적어도 하나의 암호화 키를 이용하여 암호화되고; 각각의 상기 청크는 복수의 콘텐츠 샤드들로 인코딩(encoding) 및 파싱되고; 그리고 상기청크 ID들은 암호화되는,방법."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,리버싱을 위한 상기 알고리즘은:상기 암호화된 청크 ID들로 상기 메타데이터를 증강하는 단계:상기 적어도 하나의 키를 복수의 키 샤드들로 파싱하는 단계;상기 복수의 키 샤드들을 암호화하는 단계; 및상기 암호화된 복수의 키 샤드들을 상기 증강된 메타데이터에 추가하는 단계;를 포함하는,공개특허 10-2022-0140639-6-방법."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 암호화된 키 샤드들 및 상기 청크 ID들은 별도로 저장되는,방법."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 암호화하는 단계는 샤미르의 비밀 공유 방식(Shamir's Secret Sharing Scheme, SSSS)의 사용을 포함하는,방법."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 암호화 방법은 컴퓨터연산적 암호화방식(computational cryptography) 및 리드-솔로몬 코딩(Reed-Solomoncoding)의 사용을 포함하는, 방법."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 콘텐츠 데이터 암호화 기법은 AES-256의 사용을 포함하는,방법."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항에 있어서,데이터 스토리지들, 키 스토리지들, 및 메타데이터 스토리지들의 수는 각각 구성가능하고, 각각은 3으로 한정되지 않는,방법."}
{"patent_id": "10-2022-7034024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제13항에 있어서,데이터 샤드들, 키 샤드들, 및 메타데이터의 파라미터들의 t 및 n은 독립적으로 구성가능하고, t=2 및 n=3으로한정되지 않으며, 여기서 t는 재구성할 요구된 콘텐츠 샤드들의 수이고, n은 저장할 콘텐츠 샤드들의 수인것인, 방법.공개특허 10-2022-0140639-7-"}
{"patent_id": "10-2022-7034024", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "관련된 메타데이터를 포함하는 데이터 파일들을 암호화 및 재구성하기 위한 방법 및 시스템이 개시된다. 이러한 방법은 데이터 및 메타데이터를 체인화 프로세스들로서 별도로 암호화하는 것, 그리고 복수의 암호화/인코딩 기 법들을 전략적인 스토리지 분산 기법들 및 파싱 기법들과 함께 통합하는 것을 포함하고, 이것은 결과적으로 기법 (뒷면에 계속)"}
{"patent_id": "10-2022-7034024", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 보안화된 스토리지 기술 분야에 관한 것이다."}
{"patent_id": "10-2022-7034024", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "데이터를 보호하는 것은 보안 및 복원의 측면에서 스토리지(storage) 기술 분야에서 잘 알려진 문제이다. 공지 의 솔루션들이 존재하는데, 예컨대, 이전의 솔루션들보다 에러 정정의 능력을 향상시키기 위해 CD들, DVD들, QR 코드들, 등에 대해 널리 사용되는 이레이저 코드(Erasure Code)가 있고, 다항식 보간 기법(polynomial interpolation technique)으로 비밀을 보호하는 샤미르의 비밀 공유 방식(Shamir's Secret Sharing Scheme, SSSS)이 있다. 이들의 (t, n) 임계 속성은 원본 데이터를 재구성하기 위해 n 중에서 쉐어(share)들(또는 샤드 (shard)들)로 지칭되는 적어도 t개의 데이터 조각(data piece)들을 요구한다. n개의 복제된 카피(copy)들과 유 사하지만 추가적인 제약 t를 도입하는 이러한 속성은 원본을 재구성할 때 데이터 복원을 향상시키는데, 왜냐하 면 이것은 서비스 중단 없이 n-t 스토리지 노드 실패들을 허용하기 때문이다. 데이터 보호의 관점에서, (t, n) 임계 속성은 또한, 적어도 t개의 쉐어들이 액세스가능하고 유효한 경우에만 원본 데이터를 들어낸다. 이레이저 코드는 전송 또는 스토리지 효율을 최대화하면서 데이터 내의 비트 에러들을 정정하는 목표를 갖는다. 따라서, 대부분의 애플리케이션(application)들은 리드-솔로몬(Reed-Solomon, RS) 코드와 같은 이레이저 코드에 만 기반을 두고 있다. 컴퓨터 스토리지에서, 이레이저 코드는 독립 디스크들의 리던던트 어레이(Redundant Array of Independent Disks, RAID)를 구현하기 위해 사용되었는데(특히 레벨 5 및 레벨 6), 이는 실패들의 상 이한 레벨들 하에서 신뢰가능한 스토리지 컴포넌트(storage component)를 위해 설계된 것이다. 대규모 데이터 스토리지 시스템은 새로운 기술적 도전 과제를 야기한다(즉, 메타데이터(metadata)를 관리 및 보 호하는 것). 유연성(flexibility) 및 확장성(scalability)을 달성하기 위해, 데이터는 분산된 스토리지들에 자 신의 메타데이터와 함께 저장되는데, 여기서 메타데이터는 요구된 데이터 조각들이 어디에 위치하는지에 관한 정보를 포함한다. 따라서, 메타데이터를 신뢰가능하게 그리고 보안화되게 저장하기 위해, 데이터 보호의 또 하 나의 다른 계층이 대체로 필요하다. 예를 들어, 샤미르의 비밀 공유 방식(SSSS) 및 RS는, SSSS 및 RS 코드가 원본 데이터를 재구성하기 위해 n 중에 서 적어도 t개의 데이터 쉐어들을 요구하는 (t, n) 임계 속성을 가짐에도 불구하고, 데이터의 보안 및 에러 정 정을 각각 보호하기 위해 사용되었다. 이들은 암호화 및 에러 정정을 각각 목표로 한다. SSSS는 암호화 키(encryption key)의 사용 없이 비밀을 다수의 쉐어들 n에 저장하는 암호화 기법으로서 설계된 다. SSSS는 이론적인 암호화를 보장하는 다항식 보간을 활용하고, 이에 따라 t보다 적은 쉐어들로 SSSS를 깨는 (break) 방법은 알려져 있지 않다. RS 코드도 또한 동일한 (t, n) 임계 속성을 가지고 있지만, 에러 정정 및 스토리지 효율을 위해 설계된다. SSSS 와는 달리, RS 코드는 C(x) = x·A가 성립되도록 선형 맵핑(linear mapping)을 사용하는데, 여기서 코드 워드 벡터(code word vector) x = (x1,...,xt)∈Ft이고, A는 일반적으로 방데르몽드 행렬(Vandermonde matrix)의 전 치행렬(transpose)인 (t×n)-행렬이다. 따라서, C: Ft → Fn이다. RS 코드의 수 개의 변형들이 존재하지만, 원 본 RS 코드는 체계적 코드(systematic code) 및 비-쳬계적 코드(non-systematic code)로 범주화될 수 있다. 체 계적 코드는 원본 데이터와 추가 패리티(parity)들을 합하여 유지시키도록 행렬 A를 설계하는데, 이는 디코딩 비용(decoding cost)을 감소시킨다. 비-체계적 코드는 원본 데이터를 포함하지 않지만 여전히 SSSS의 레벨까지 데이터 보안을 보장하지 않는다. RS 코드는 데이터 스토리지에 대해 혜택을 갖는다. 예를 들어, SSSS는 B*n의 스토리지 공간을 요구하지만, RS 코드는 B*n/t를 요구하며, 여기서 B는 원본 데이터의 크기이다. 분산된 데이터 스토리지는 그 확장성 및 비용 효율로 인해 출현했다. 공지의 분산된 데이터 스토리지 시스템들 중 하나는 하둡 파일 시스템(HaDoop File System, HDFS)인데, 이것은 초대형 데이터 센터 스토리지 시스템이 예 컨대 맵리듀스(MapReduce)를 위한 병렬 데이터 작업부하(parallel data workload)를 실행하도록 설계된다. HDFS는 데이터의 3-중복 카피들을 제안했는데, 두 개는 동일한 랙(rack) 내에서 두 개의 상이한 노드(node)들에 저장되고, 또 하나의 다른 하나는 상이한 랙(위치) 내에서 상이한 노드에 저장된다. 이러한 전략은 실패 로컬화 (failure locality)를 활용함으로써 데이터 액세스가능성을 간단히 향상시킨다. 더 최근에는, 오브젝트 스토리지 솔루션(object storage solution)들이 키와 값의 쌍(key and value pair)들을 사용하여 I/O 쿼리(query)를 단순화하기 위해 사용되었다. 분산된 스토리지 시스템들에 대한 당면한 도전 과제들이 존재한다. 첫 번째 도전 과제는 메타데이터 관리와 관 련된다. 데이터 콘텐츠(data content)들이 다수의 스토리지 노들에 분산되기 때문에, 분산된 콘텐츠들의 어드레 스(address)들은 보안화된 그리고 신뢰가능한 장소에서 유지돼야만 하는데, 이것은 단일 실패 지점이 되게 되고 성능 병목현상을 일으키게 된다. 메타데이터를 저장하는 것은 시스템 성능에 상당한 영향을 미치는데, 왜냐하면 이러한 메타데이터의 저장은 성능 병목현상이 존재하는 디렉토리 서비스(directory service) 및 메타데이터 조 회(metadata lookup) 동작들과 대부분 관련되어 있기 때문이다. 예를 들어, 리스트(List) 및 스탯(Stat)은 판독 (Read) 및 기입(Write)보다 더 빈번하게 호출된다. 세프(Ceph)[S. A. Weil, S. A. Brandt, E. L. Miller, D. D. E. Long, and C. Maltzahn, \"Ceph: A Scalable, High-performance Distributed File System\", 7th Symposium on Operating systems design and implementation (OSDI). Nov, 2006.]는 서버들 간에 메타데이터 요청 쿼리들을 더 효율적으로 분산시키기 위해서 메타데이터 서버 팜(metadata server farm)을 구축하는 방법 및 메타데이터의 위치를 제안했다. 세프(Ceph)의 해시 함수(hash function)는 서버 팜 내에서 메타데이터 쿼리 들의 공유된 경로들을 최소화하도록 설계되었다. 성능이 쟁점일 뿐만 아니라, 메타데이터 분리(metadata decoupling)의 결과로서 보안 및 복원도 또한 도전 과제 적 주제들이다. 데이터 암호화 기법들로 메타데이터를 보호하는 것은 추가적인 컴퓨터연산적 비용들 및 성능 저 하들을 초래한다. 중요한 것으로, 이전의 솔루션들에서, 스토리지 및 검색은 동기식 프로토콜(synchronous protocol) 하에서 일어 나는 반면, 본 발명에서는 스토리지 및 검색이 아래에서 상세히 설명되는 바와 같이 비동기식으로 일어난다. 또 하나의 다른 도전 과제는 엔드-투-엔드 솔루션(end-to-end solution)을 위한 아키텍처적 유연성 (architectural flexibility)의 제한이다. 대부분의 분산된 스토리지 시스템들은 동일한 데이터 센터 내의 클라 이언트(client)들을 위해 설계되는데(이들의 네트워크 레이턴시(network latency)는 대략 1 ms보다 작음), 이것 은 다수-데이터 센터 솔루션들에 부정적인 영향을 미친다. 예를 들어, 만약 클라이언트-중심적 아키텍처 (client-centric architecture)를 고려하면, 클라이언트 디바이스들이 이동가능한 경우, 클라이언트 디바이스는 인터넷을 통해 스토리지 노드들 및 메타데이터 서버 노드들에 연결될 수 있다. 클라이언트가 이동가능하기 때문 에 또는 데이터 센터의 외부에 위치하기 때문에, 시스템 성능은 데이터 센터 내부의 스토리지 서비스들과 비교 가능하지 않다. 본 출원은 2019년 5월 22일자로 출원되어 현재 계류중인 미국 가특허 출원 번호 제62/851,146호에 대한 우선권 을 주장하며, 그 전체 내용은 참조로서 본원에 포함된다. 본 출원은 보안화된 스토리지를 위해 네트워크 구비 디바이스(network equipped device) 및 네트워크 구비 스토 리지 노드(network equipped storage node)들을 사용하여 데이터 및 메타데이터를 체인화 프로세스(chaining process)들로서 별도로 암호화하기 위한 방법 및 시스템에 관한 것이고, 여기서 프로세스 및 시스템은 모두, 현 재 이용가능한 레벨들을 뛰어넘어 신뢰가능하고 복원가능하다. 본 발명의 방법 및 시스템은 다양한 암호화 (encryption)/인코딩(encoding) 기법들을 전략적인 스토리지 기법들 및 파싱(parsing) 기법들과 함께 통합하고, 이것은 결과적으로 기법들의 집합의 통합된 혜택들을 제공한다. 본 발명은 콘텐츠 데이터를 콘텐츠 데이터의 메 타데이터로부터 분리시키고, 그리고 콘텐츠 데이터 암호화 체인화 프로세스에서, 본 방법은 콘텐츠 데이터를 청 크화(chunk)하고, 암호화(encrypt)하고, 샤드화(shard)하고, 그리고 저장(store)하고, 메타데이터를 별도로 샤 드화하고 저장하며, 여기서 메타데이터는 콘텐츠 데이터 암호화 체인화 프로세스와 관련된 정보로 증강 (augment)된다. 본 발명의 방법은 컴퓨터연산적(computational) 및 이론적(theoretical) 암호화방식 (cryptography)을 모두 사용한다. 추가적으로, 프로세스들은 바람직하게는 로컬로(locally) 구현되는데, 여기에 는 프록시 서버(proxy server) 또는 콘텐츠 데이터의 사이트(site)에서 구현되는 것이 포함된다. 바람직한 실시예에서, 콘텐츠 데이터는 청크화되고, 그 다음에 각각의 청크는 무작위로 생성되는 키-기반 AES- 256(또는 동등한 것)으로 암호화되고, 그 다음에 RS 인코딩(또는 동등한 것)이 수행되고, 그 다음에 샤드들로 분해되고 또는 \"샤드화\"되는데, 여기서 샤드들은 암호화 및 인코딩에 후속하여 파일을 파싱함으로써 형성되는 파일 부분들이다. 메타데이터는 SSSS 암호화되는 청크 ID들을 도입함으로써 수정되고, 그 다음에 키 샤드(key shard)들과 결합되어 샤드화되고, 그 다음에 SSSS 암호화된 키 샤드들이 메타데이터 암호화 프로세스 동안 도입된다. 적어도 두 개의 암호화 방법들: 데이터 샤드들을 만들기 위한 AES + RS 및 메타데이터 샤드들 내 에 저장되는 청크 ID들 및 AES 키들에 대한 SSSS가 사용되고 있음에 유의하는 것이 중요하다. 간단히 말하면, 본 발명은 암호화에 인코딩이 합해진, 그리고 암호화된(그리고 일부 데이터에 대해서는 또한 인 코딩된) 파일들의 분산된 스토리지가 합해진 다수의 형태들을 포함한다. 본 방법은 이전의 솔루션들보다 향상된 보안 및 복원을 가능하게 하고, 더 빠른 복구를 가능하게 하며, 그리고 또한 데이터 액세스 제어를 위한 스토리지 관리 및 구성에 대한 사용자의 선호도에 근거하여 제어가능하다."}
{"patent_id": "10-2022-7034024", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은, 데이터 암호화/인코딩을 위해 컴퓨터연산적 암호화방식에 적어도 부분적으로 근거하는 데이터 암호 화 체인 모듈(data encryption chain module)과 이론적 암호화방식으로 데이터 암호화 체인 모듈에 후속하는 상 이한 메타데이터/키 암호화 체인 모듈(metadata/key encryption chain module)의 조합을 사용함으로써, 앞서언 급된 암호화/스토리지 도전 과제를 해결한다. 다른 것들도 또한 메타데이터를 콘텐츠 데이터로부터 분리시켜 저 장하고 구성하지만, 이들은 단지 콘텐츠와 메타데이터를 별도로 저장하는 것에만 초점을 맞추고 있고, 본 명세 서에서 설명되는 바와 같은 많은 중요한 그리고 유익한 속성들 및 접근법들을 포함하지 않는다. 신뢰가능성 및 보안은 콘텐츠 저장들/스토리지들의 전통적인 우선사항들이다. 신뢰가능성 및 부하 균형(load balancing)도 또 한 메타데이터/키 저장들/스토리지들의 중요한 우선사항들이다. 본 발명은, 콘텐츠 데이터 및 메타데이터/키 암 호화의 실제 구현을 콘텐츠에 대해서는 적어도 컴퓨터연산적 암호화방식을 사용하고 메타데이터/키에 대해서는 적어도 이론적 암호화방식을 사용하여 별도로(하지만 상호관련되게) 체인화 프로세스들로 구현함으로써, 이에 따라 보안화된 스토리지를 위해 이전에 사용되지 않은 아키텍처를 구현하게 됨으로써, 기술을 진보시킨다. 이러 한 솔루션은, 다른 혜택들 중에서도, \"그룹(group)\" 사용자(예컨대, 공통 스토리지를 갖는 사업체)에 대해서, 그리고 다수-데이터 센터 사용자(예컨대, 서비스의 백엔드(backend)에서 다수의 데이터 센터들을 갖는 사용자) 에 대해서, 개별 사용자에 대한 속도, 복원 및 복구, 그리고 보안에서의 상당한 향상을 제공하고, 그럼으로써 복수의 사용자 타입들을 동시에 서빙(serving)하게 된다. 컴퓨터연산적 암호화방식과 비교하여, 일부 암호화 알 고리즘들은 공격자들에 의해 수학적으로 깨질 수 없는 이론적 암호화방식 알고리즘들로서 입증된다. 사용되는 컴퓨터연산적 암호화방식 알고리즘들은 사용중인 접근법에 대해 실제로 충분히 긴 원본 데이터를 리버스 (reverse)하기 위한 시간의 양에 근거하여 결정가능하다. 반면, 이론적 암호화방식 알고리즘들은 요구된 조건들 을 충족시킴 없이 암호화된 데이터를 깨는 것이 수학적으로 불가능하게 하는 솔루션들을 제공한다. 정의에 있어, RS 코드(또는 동등한 것)를 사용하여 각각의 암호화된 청크로부터 데이터 샤드들을 생성시키는 상 황들에 대해서는 용어 \"인코딩(encoding)\"이 사용되고, SSSS(또는 동등한 것) 및/또는 청크 암호화에 대해서는 \"암호화(encrypting)\"가 사용된다. 용어 \"청크화(chunking)\"는 임의의 조작(manipulation)들 없이 파일을 다수 의 조각들로 분할하는 맥락에서 사용된다. 용어 \"샤드화(sharding)\"는 출력이 (t, n) 임계 속성을 가질 때 사용 된다. 암호화된 청크를 데이터 샤드들로 인코딩하는 것은 출력에서 암호화를 유지시킨다. \"메타데이터 샤드(metadata shard)\"는 암호화된 청크 ID들 및 파일 속성들을 포함하는 데이터로서 정의된다. \"키 샤드(key shard)\"는 SSSS 또는 동등한 것을 사용하는 각각의 청크 암호화 키의 암호화된 데이터로서 정의된다. 본 출원은 클라이언트를 데스크탑, 랩탑, 핸드헬드 디바이스, 등과 같은 사용자-대면 디바이스(user-facing device)로서 정의한다. 클라이언트의 확장된 정의는 사용자 도메인(user domain) 내에 위치하는 서버 머신(server machine) 들을 포함한다. 본 발명에서, 데이터는 먼저 청크화되고, 암호화되고, 그 다음에, 샤드화된다. 메타데이터 및 콘텐츠 데이터는 별도로 암호화 및 인코딩되고, 그리고 별도로 저장된다. 본 발명의 암호화/인코딩 방식은, 적어도 암호화 방식, 인코딩 방식, 및 스토리지 방식, 그리고 어떻게 메타데이터가 인가된 사용자에게 액세스가능한 상태로 유지되는 지에 근거하여 스토리지 효율, 데이터 복원 및 보안을 크게 향상시킨다. 본 발명의 방법은 시스템 신뢰가능성 (이것은 예컨대 물리적 또는 사이버-공격을 막는 것을 의미함), 및 복원(이것은 파일 손상에 후속하여 파일들을 복구할 수 있는 능력을 의미함)을 유지시키거나 향상시킨다. 본 발명의 접근법은 암호화 및 스토리지를 위한 신규한 시스템 아키텍처와, 그리고 콘텐츠 및 메타데이터 양쪽 모두에 대한 신규한 암호화 및 인코딩 접근법을 포함한다. 이러한 접근법들에 의해 제공되는 향상들은, 다른 것 들 중에서도, 원격 스토리지에서의 레이턴시를 극복하는 것, AI(Artificial Intelligence; 인공 지능)를 사용하 는 스토리지 분산 기법들에서의 진보들, 구조화되지 않은 데이터의 모니터링, 제어 및 관리와 관련된 이점들을 포함하지만, 이러한 것으로만 한정되는 것은 아니다. 본 솔루션은 두 개의 별도의 암호화 체인들을 생성하는데, 파일 콘텐츠 및 이것의 메타데이터/키 각각은 별도로 암호화되고, 각각은 상이한 접근법들을 사용하며 파일 콘텐츠는 또한 인코딩을 포함한다. 파일 콘텐츠 인코딩 알고리즘은, 콘텐츠가 알고리즘들, 예를 들어, AES-256과 같은 공지의 알고리즘들을 사용하여 이미 암호화된 이 후에만 수행되는 RS 코딩과 같은(하지만, 이러한 것으로만 한정되는 것은 아닌) 성능-집중적 정보 분산 알고리 즘들(이것은 컴퓨터연산적 암호화방식 알고리즘으로서 알려짐)을 포함한다. 파일 콘텐츠 인코딩의 프로세스에서, 하나 이상의 무작위로 생성되는 암호화 키들은 잠재적으로는 논스(nonce)들(이것은 초기화 벡터 (initialization vector)들을 포함함, 본 발명에서는 전형적으로 무작위로 선택됨)을 포함하여, 파일을 암호화 하기 위해 사용된다. 암호화 키를 보안화되게 저장하기 위해, 키는, 일반적으로 수행되는 방식(데이터 샤드들과 함께 저장되는 것) 대신에 메타데이터 파일 내에 저장되거나 별도로 저장된다. 암호화 키를 콘텐츠 데이터로부 터 이렇게 분리시키는 것은, 공격자가 데이터 스토리지 액세스 허가를 이미 확보한 경우 및/또는 여하간 키를 획득한 경우에도, 공격자로부터 콘텐츠 데이터를 보호한다. 본 발명에서는, 메타데이터가 추가적인 중요한 정보 를 포함하도록 수정되기 때문에, 본 발명은 보안-집중적 정보 분산 알고리즘(이것은 이론적 암호화방식 알고리 즘으로서 알려짐)을 메타데이터에 적용한다. 본 발명은 청크들의 각각의 참조(reference)(청크 ID들)를 암호화 하고 SSSS 또는 동등한 것을 사용하는 암호화 키만을 사용한다. SSSS의 이론은 충분한 수(본 예에서는 >= 2인 수)의 샤드들이 재구성을 위해 이용가능할 때만 메타데이터 재구성이 이용가능하도록 보장한다. 이전의 접근법들과 비교하여, 본 솔루션은 기존의 도전 과제들을 해결하고, 시스템 성능을 향상시키며, 동시에 종래의 스토리지 필요들을 감소시킨다. 스토리지 시스템이 달성할 필요가 있는 가장 중요한 목표는 데이터 이용 가능성, 복원, 및 신뢰가능성이다. 데이터 이용가능성 및 복원을 향상시키기 위한 가장 일반적인 솔루션은 리던 던트 데이터(redundant data)를 저장하기 위해서 대체로 적어도 두 배의 데이터 스토리지 공간을 요구하는 데이 터 백업(data backup)이다. 본 발명은 더 적게 요구하는데, 전형적으로 n/t배의 스토리지 공간이 필요하고, 여 기서 t는 샤드들의 요구된 수이고, n은 저장된 샤드들의 전체 수이다. n 중에서 n 대신에 n 중에서 t만을 필요 로 함으로써, 복원이 크게 향상된다. 이전의 솔루션들에서, RAID(Redundant Array of Independent Disks; 독립 디스크들의 리던던트 어레이)는 데이터에 에러 정정 코드를 추가함으로써 데이터 백업과 거의 동일한 복원을 보 장하면서 스토리지 효율을 향상시킨다. (본 발명에 선행하는) 이러한 예전의 최신 스토리지 솔루션들은, 이용가 능성 및 복구 양쪽 모두를 달성하기 위해, 분산된 스토리지 노드들을 사용한다. 이들은 이레이저 코드와 같은 에러 정정 코드를 활용하고 데이터 조각들을 분산된 스토리지 노드들에 저장하는데, 이것은 인코딩 파라미터들 에 근거하여 특정 수의 스토리지 노드 실패들을 허용한다. 하지만, 이러한 솔루션들은 단지 메타데이터 및 콘텐 츠 데이터의 독립적인 스토리지에 관한 것이다. 본 발명은 메타데이터/키 스토리지를 콘텐츠 데이터 스토리지로부터 분리시키지만 둘 간의 관련성을 유지시킨다. 추가적으로, 본 솔루션은, 사용자들이 상이한 공급자들로부터의 클라우드 스토리지 서비스(cloud storage service)들 및 사용자 자신의 스토리지 노드들과 같은 백엔드 스토리지들의 상이한 타입들을 부가하기 위한 다양한 스토리지 백엔드들에 대한 최적의 그리고 시간 경과에 따라 향상되는 구성을 제공한다. 즉, 본 발 명은 스토리지 타입(및 위치)에 관해 불가지론(agnostic)적인데, 단일 컴퓨터의 스토리지/사용자의 스토리지에서도 그러하며, 다수의 스토리지 타입들의 동시 사용을 가능하게 한다. 이러한 접근법은 추가되는 혜택을 제공 하는데, 왜냐하면 이전의 솔루션들은 다양한 백엔드 스토리지들의 편성(orchestration)을 위해 설계되지 않았거 나 그러한 편성을 성공적으로 달성하지 못했기 때문이다. 백엔드 스토리지들의 다양성 때문에, 시스템 성능 및 효율을 향상시키기 위한 구성은 대체로 전문가에 의해 행해져야만 하는 정교한 작업이고, 이로 인해 이전의 솔 루션들에는 비보안호된 계층들 및 위험이 추가되게 된다. 본 솔루션에서의 편성 계층은, 선택에 따라서는 AI-보 조적 최적화 모듈로, 구성 작업들의 추상화(abstraction)를 제공한다. 최적의 구성은, 비용 최적화, 스토리지 효율, 보안 향상, 정책 구성(policy configuration)을 단순화하는 것, 진보된 모니터링 계측(monitoring metric)들, 및 경고 관리를 포함하지만, 이러한 것으로만 한정되는 것은 아니다. 본 솔루션은 또한, 적어도 부분적으로 메타데이터가 스토리지를 위해 구성되는 방식 및 스토리지가 선택되는 방 식에 의해, 레이턴시가 긴 네트워크들에서 메타데이터 동작들의 레이턴시를 감소시킨다. 이전의 솔루션들에서는, 일반적으로, 사용된 스토리지 접근법들 때문에, 복구 레이턴시가 중요한 쟁점이다. 파일 시스 템 무결성(file system integrity)을 유지하기 위해, 뿐만 아니라 현행 파일 데이터 동작들을 유지하기 위해, 파일 디렉토리(file directory) 및 파일 스탯(file stat) 정보의 빈번한 조회들이 필요하다. 즉, 원격 백업은 단 한 번이 아니라 정기적으로 그리고 자동적으로 수행되고, 저장된 콘텐츠 및 메타데이터는 업데이트(update) 된다. 따라서, 메타데이터 동작들의 성능은 전체 시스템 성능 및 사용자 경험과 직접적으로 관련된다. 분산된 스토리지 솔루션들은 메타데이터를 조회하기 위한 동작들을 요구하기 때문에, 레이턴시가 긴 네트워크들을 넘어 배치되는 메타데이터 서버들은 시스템 성능과 관련된 병목현상을 일으키게 된다. 이전의 발명들과 비교하여, 본 솔루션은 성능 저하 없이 인터넷과 같은 레이턴시가 긴 네트워크들에서 백엔드 스토리지들을 사용하도록 의도된 다. 본 솔루션은, 로컬 머신(local machine) 내의 잠재적 스토리지를 포함하는 분산된 메타데이터 스토리지들 내에 저장되는 동작 속성들 및 콘텐츠 참조들을 분리시킴으로써 메타데이터 동작들의 레이턴시를 감소시킨다. 본 솔루션은 또한, 비동기식 접근법을 구현함으로써 레이턴시가 긴 네트워크들에서 판독(Read) 및 기입(Write) 과 같은 파일 콘텐츠 동작들과 관련된 사용자 경험을 향상시킨다. 대체로, 레이턴시가 긴 네트워크들은 파일 콘 텐츠 동작들의 성능에 부정적인 영향을 미친다. 성능은 종종 사용자 디바이스와 백엔드 스토리지들 사이의 네트 워크 내에 있는 병목 링크(bottleneck link)에 의존한다. 본 발명의 맥락에서, 사용자 디바이스는, 서버, 핸드- 헬드 디바이스, 또는 사용자의 데이터의 스토리지에 대한 네트워킹 인터페이스(networking interface)를 구비한 독립형 컴퓨터일 수 있고, 여기서 사용자는 개인 또는 그룹(예컨대, 기업)일 수 있다. 전형적인 동기식 접근법 은 직접적으로 사용자 경험에 부정적인 영향을 미치는데, 왜냐하면 사용자들은 레이턴시가 긴 네트워크에서 백 엔드 스토리지들로부터 응답들을 기다려야만 하기 때문이다. 본 솔루션은 레이턴시가 긴 네트워크들에서 사용자 디바이스와 백엔드 스토리지들 간의 지연을 흡수하기 위해 비동기식 접근법을 사용한다. 백엔드 스토리지들로부 터 응답들을 기다리는 대신, 이러한 접근법은 응답들을 일찍 리턴(return)하는데, 특히, 요청이 중간 상태로서 로컬로 스테이지화(stage)되고 일괄 프로세스(batch process)로서 동기화가 행해져 결과들이 이후에 비동기식으 로 업데이트되도록 스케줄링(schedule)되어 있는 경우에 그러하다. 다음의 설명은 데이터를 저장하는 방식의 제한들을 극복하면서 앞서언급된 도전 과제들을 해결하기 위한 본 발 명의 추가적인 고유한 그리고 신규한 솔루션들이다. 인공 지능(AI)-보조적 최적화 구성. 본 발명은 다양한 백엔드 스토리지들 및 구성들에 대한 추상화된 레벨의 제 어를 제공하기 위해 AI를 사용하여 백엔드 구성을 최적화한다. 본 솔루션은 상세한 스토리지 구성을 도출하기 위해 추론 모듈(inference module)로서 그리고 해석기(interpreter)로서 동작하는 인간-친화적 인터페이스들(여 기에는 도식적 사용자 인터페이스(Graphical User Interface, GUI), 및/또는 파일 시스템 인터페이스가 포함됨) 및 언어들을 제공한다. 도 1 참조. AI의 적용들은, (ⅰ) 최적의 데이터 할당으로 스토리지 비용을 최적화하는 것, (ⅱ) 사용자 데이터 액세스 패턴 및 사용자와 스토리지의 위치 정보에 근거하여 데이터 액세스 레이턴시를 최적화하는 것, 그리고 (ⅲ) 데이터 재구성을 위한 샤드들의 수를 동적으로 변경시킴으로써 보안의 레벨을 강화 시키는 것을 포함하지만, 이러한 것으로만 한정되는 것은 아니다. AI 알고리즘들을 사용함에 있어, 본 솔루션은 사용자들의 파일 동작 이벤트(file operation event)들로부터 익명화된 로그(log)들을 수집한다. 도 2 참조. 파 일 동작 이벤트 로그들은 AI 알고리즘들을 훈련시키기 위해서 패턴 분석기에 의한 분석을 위해 저장될 수 있다. 알고리즘들이 훈련되면, 알고리즘들이 실제로 실행되는 AI-보조적 모듈들에 모델들 및 파라미터들이 배치된다. AI-보조적 모듈들은 최적의 구성, 비정상 검출, 등을 수행하기 위해 사용자 디바이스들로부터 이벤트들을 수신 한다. 데이터 위치들은 저장된 그리고 암호화된 메타데이터 내에 유지되고, AI-기반 조정들에 근거하여 업데이 트된다.본 발명의 맥락에서 추가적인 견본적 AI 적용들은 아래와 같은 것을 포함한다. 최적의 스토리지 선택 - 성능 시스템은 각각의 백엔드 스토리지에 대한 실증적 속도를 측정하기 위해 스토리지(및 잠재적으로는 더 일반적인 액세스)에 대한 업로드(upload) 및 다운로드(download) 이벤트들을 수집한다. 샤드들을 저장할 때, 그리고 저장 할 샤드들의 수보다 더 큰 수의 스토리지들을 가정하면, 시스템은 데이터 저장 레이턴시를 최소화하기 위해 더 많은 샤드들을 더 빠른 백엔드 스토리지들에 저장한다. 가장 느린 스토리지에서의 병목현상에 의해 레이턴시가 결정되기 때문에, 각각의 스토리지에 대한 샤드 저장 레이턴시의 최대 값을 최소화시키는 민-맥스 알고리즘 (min-max algorithm)은 전체 데이터 업로드 레이턴시를 감소시킨다. 파일을 재구성하기 위해 샤드들을 페칭 (fetching)할 때, 민-맥스 알고리즘은 또한 각각의 스토리지에서 최대 레이턴시를 감소시키기 위해 샤드들이 저 장된 총 n개의 스토리지들 중에서 빠른 t개의 스토리지들을 선택한다. 최적의 스토리지 선택 - 비용 시스템은 가장 적게 액세스된 파일들을 콜드 스토리지(cold storage)들로 마이그레이션(migrate)시키기 위해 파 일 액세스 빈도를 수집한다. 논의 목적으로, 2-계층 스토리지들, 즉, 빠르지만 비싼 핫 스토리지(hot storage) 들, 그리고 느리지만 비용 효율적인 콜드 스토리지들이 존재한다고 가정한다. 기존의 서비스들은 콜드 스토리지 들로 마이그레이션시킬 데이터를 결정하기 위해 저장을 위한 시간 또는 마지막 액세스에 근거하는 스토리지 위 치(storage locale)들에 대한 간단한 정책을 제공한다. 본 발명은 n개의 샤드들을 저장하고, 그리고 원본 데이 터를 재구성하기 위해 n 중에서 t를 요구하기 때문에, 결정은 이원적 선택, 콜드 또는 핫이 아니라, 얼마나 많 은 샤드들, 혹은 샤드들의 부분들 중 얼마나 많은 부분들, 혹은 어떤 샤드들이 콜드 및 핫 스토리지들로 지시 (direct)되는지이다. 본 발명의 시스템은 콜드 스토리지 마이그레이션 비용들을 포함하는 스토리지의 추정된 비 용을 계산하기 위해 샤드 액세스 이벤트들 및 빈도를 정기적으로 수집한다. 본 발명의 시스템은 상이한 타입의 스토리지들로부터 다수의 파라미터들을 고려할 때 구성 복잡성(configuration complexity)을 감소시킨다. 성능 계측들을 함께 고려하여, 알고리즘은 샤드 액세스 패턴에 근거하여 콜드로부터 핫 스토리지들로 데이터를 후속 적으로 마이그레이션할 수 있다. 비정상적인 파일 액세스 검출 자기상관(autocorrelation)은 본 발명에서 적용될 수 있는 네트워크화된 시스템들의 작업부하에서의 하나의 특 징이다. 예를 들어, 네트워크 트래픽 연구들(network traffic studies)은 트래픽 발원지 및 목적지의 시간적 및 공간적 유사성에 근거하여 정기적인(예컨대, 일간) 패턴들을 보여준다. 본 발명의 일 실시예에서, 시스템은 주 로 일간 및 주간 유사성을 보여주는 파일 액세스 패턴들에 근거하는 자기상관을 사용한다. 이러한 특징은 심층 학습 및 회귀 방법들을 사용하여 예측 알고리즘을 개발할 수 있게 한다. 따라서, 시스템은 패턴들로부터 불규칙 성(irregularity)들 또는 편차(deviation)들, 예컨대, 통계적 유의성(statistical significance)을 갖는 불규 칙성들 또는 편차들을 결정할 수 있고, 이에 따라 악의적 사용자들 또는 맬웨어(malware)들에 의한 비정상적인 파일 액세스를 시스템 관리자에게 경고할 수 있다. 레이턴시가 긴 네트워크들에서 메타데이터 동작들의 감소된 레이턴시. 본 솔루션은 파일들의 조각난 조각들을 다수의 백엔드 스토리지들에 저장하기 때문에, 메타데이터는 원본 파일들을 재구성하기 위해 필요한 정보로 강 화된이다. 메타데이터는 또한, 대체로 파일 크기, 수정 시간, 액세스 시간, 등과 같은 파일 속성들을 저장하게 된다. 파일 동작 호출들의 빈도를 관찰한 것에 근거하면, 파일 콘텐츠 동작들이 호출되는 것보다 더 빈번하게 메타데이터 동작들이 호출되는 것이 관찰되었다. 결과적으로 그리고 추가적으로, 파일 시스템들은 메타데이터 동작들의 레이턴시가 짧다고 가정하여 설계된다. 따라서, 이전의 솔루션들은 로컬 영역 네트워크들 내에 메타데 이터 스토리지들(혹은 서버들)을 요구했는데, 이것은 결과적으로 실패로 인한 손실의 불필요한 위험을 초래한다. 하지만, 본 솔루션은 분산된 데이터 암호화의 속성들을 유지하면서 레이턴시가 긴 네트워크들에 적용 될 수 있도록 메타데이터를 설계한다. 본 솔루션의 메타데이터는 \"복제된\" 데이터 및 \"암호화된\" 데이터로 구성 된다(도 10 참조). 복제된 데이터는 파일의 콘텐츠와 관련되지 않은 정보를 포함한다. 파일 이름, 크기, 수정된 시간, 및 다른 파일 속성들은 복제된 데이터 내에 저장된다. 이것은 시스템으로 하여금 다수의 메타데이터 샤드 들을 수집하고 데이터를 암호해독함이 없이 데이터를 획득할 수 있게 한다. 반면, 파일 콘텐츠, 청크 ID들, 및 청크 암호화 키들과 관련된 정보는 암호화된 데이터로서 저장된다. 암호화 키들 및 메타데이터에 대한 분산된 암호화의 속성을 유지하기 위해, 본 솔루션은 파일 콘텐츠에 대해 본 발명에서 필요한 것보다 더 강한 보안 레 벨의 메타데이터를 달성하는 SSSS 또는 동등한 것을 사용한다. SSSS는 암호화 키를 요구하지 않기 때문에, 암호 해독은 다수의 데이터 샤드들의 수집만을 요구한다. 따라서, 본 발명은, 신뢰의 근원으로서, 스토리지 솔루션에의해 제공되는 다양한 인증 및 보안 솔루션들과 함께, 분산된 스토리지들을 활용한다. 복제된 데이터와 암호화된 데이터의 분리를 사용하여 메타데이터 쉐어들을 분산시키는 것은 또한, 인코딩된 메 타데이터 샤드들 중 하나를 LAN 내의 메타데이터 서버 또는 사용자 디바이스와 같은 로컬 디바이스(local device)에 저장함으로써 메타데이터 동작들의 성능을 향상시킨다. 추가적으로, 이것은 본 솔루션으로 하여금 메 타데이터 쉐어들을 리던던트 카피(redundant copy)들로서 뿐만 아니라 암호화된 데이터 쉐어들로서 상이한 위치 들에 저장할 수 있게 한다. 오픈디렉토리(OpenDir) 및 스탯(Stat) - 메타데이터 동작 예. 사용자가 디렉토리를 오픈시킬 때, 파일 시스템은 해당 디렉토리의 차일드들(children)의 정보(즉, 파일들 및 디렉토리들)의 리스트를 리턴해야 한다. 타겟 디렉 토리(target directory)의 각각의 차일드의 정보를 리스트화하기 위해, 메타데이터 스토리지는 오브젝트 이름 또는 프리픽스(prefix)에 근거하는 메타데이터 선택 기능을 제공할 필요가 있다. 본 발명은 본래의 디렉토리 구 조(native directory structure), 키-값 스토리지(key-value storage), 및/또는 데이터베이스 시스템(database system)을 사용하여 디렉토리 시스템을 구현할 수 있다. 메타데이터 쉐어들의 일 세트가 로컬로 저장되기 때문 에, 차일드들의 디렉토리들 및 파일들을 식별하는 것은 원격 메타데이터 파일들 없이 수행된다. 즉, 현재 사용 자는 로컬 디바이스 상에 저장된 메타데이터를 \"잠금해제(unlock)\"할 수 있고 복구하기를 원하는 그러한 파일들 만을 식별할 수 있다. 다음의 동작과 관련하여, 스탯(Stat) 동작은 복제된 데이터로서 메타데이터 쉐어들의 세트 내에 저장되는 파일 속성들을 리턴해야 한다. 따라서, 스탯(Stat) 동작은 가벼운 방식으로, 즉, 로컬 디바이스 내에 저장된 대응하 는 메타데이터 쉐어의 조회로 구현된다. 판독(Read) - 파일 콘텐츠 동작 예. 본 발명에서, 청크 ID들은 SSSS와 같은(하지만, 이러한 것으로만 한정되는 것은 아닌) 기법을 사용하여 암호화되기 때문에, 청크 ID들을 디코딩하는 것은 메타데이터 쉐어들 중 둘 이상의 사용을 요구한다. 이것은 적어도 하나의 메타데이터 쉐어가 원격 메타데이터 서버(들)로부터 획득돼야함을 의미 하는데, 이는 간단한 메타데이터 조회 동작들보다 더 긴 시간을 소요한다. 하지만, 원격 스토리지들로부터 메타 데이터 쉐어들을 다운로드하기 위한 시간은 파일 콘텐츠를 다운로드하는 것보다 상당히 더 짧다. 추가적으로, 메타데이터 동작과는 달리, 파일 콘텐츠 동작들은 메타데이터 동작들만큼 빈번하게 요청되지 않는다. 따라서, 원격 서버들로부터의 메타데이터 다운로드의 추가 지연은 다운로드 완료 시간의 측면에서 파일 판독 동작들의 실질적인 인자가 아니다. 원격 스토리지들로의 비동기식 콘텐츠 전달. 본 솔루션은 사용자 디바이스 내의 인코딩된 콘텐츠를 원격 스토리 지들에 보내기 전에 스테이지함으로써 사용자 경험을 향상시킨다. 따라서, 본 솔루션은 결과를 사용자에게 일찍 리턴하고, 백엔드 스토리지들에 데이터를 비동기식으로 보냄으로써 지연을 흡수한다. 예를 들어, 현재 파일 시 스템 인터페이스가 예컨대, 파일을 기입하기 위한 파일 콘텐츠 동작의 요청을 수신할 때, 동작은 인코딩된 콘텐 츠를 스테이지화된 상태로서 로컬 버퍼(local buffer)에 저장한 이후 결과를 사용자 인터페이스에 리턴한다. 스 테이지화된 상태는 백그라운드(background)에서 비동기식으로 완료되도록 일괄 스케줄링(batch schedule)된다. 이러한 설계는 파일을 기입할 때 사용자 경험을 상당히 향상시키는데, 왜냐하면 사용자 디바이스와 원격 스토리 지들 간의 레이턴시를 사용자-대면 상호작용(user-facing interaction)들로부터 분리시키기 때문이다. 원격 스토리지들로부터의 파일 콘텐츠의 프리-페칭(pre-fetching) 및 캐싱(caching). 원격 스토리지들과 로컬 스토리지 간의 레이턴시에서의 큰 간극 때문에, 프리-페칭 및 캐싱은 판독 동작의 완료 시간 및 사용자 경험을 향상시킨다. 파일 기입 동작들과는 달리, 파일 판독 동작들은 전형적으로 사용자가 파일 판독을 원한 이후 즉시 데이터 콘텐츠가 전달될 것을 요구하는 요구형 동작(on-demand operation)들이다. 요구된 데이터 조각들을 원격 스토리지들로부터 다운로드하기 위한 지연을 감소시키기 위해, 본 솔루션은 사용자의 파일 액세스 패턴(이것의 모델은 본 발명의 AI 모듈에 의해 계산됨)에 근거하여 그 요구된 데이터 조각들을 프리-페칭한다. 모듈은 캐싱 된 데이터의 수명 및 교체, 데이터 프리-페칭, 등을 결정하기 위해 시간적 자기상관, 사용자 ID, 애플리케이션 의 타입, 캐시 스토리지(cache storage)의 용량, 등을 활용한다. 이전의 솔루션들은 분산된 스토리지 시스템들이 다수의 백엔드 스토리지들을 사용하고 이레이저 코드 혹은 SSSS(또는 이들의 변형들)를 사용함으로써 통합 계층(integration layer)을 제공하는 것에 관한 것이었다. 일부 가 WAN 및 LAN 내에 다양한 백엔드 스토리지들을 도입했지만, 관리가능성 및 효율을 향상시키는 것은 미해결 쟁 점들로 남아있다. 본 솔루션은 WAN 및 LAN 내에 배치된 분산된 스토리지 시스템들에서 이들의 구성가능성 및 성 능(즉, 지연)을 향상시키기 위해 이러한 쟁점들 및 다른 쟁점들에 대처한다. 비용, 성능, 및 보안의 측면에서 다양한 백엔드 스토리지 구성의 복잡성을 극복하기 위해, 본 발명은, 이벤트 로그 수집기(인터페이스), 데이터분석기(알고리즘 생성), 알고리즘 훈련기(파라미터 튜너(parameter tuner)), 모델 배치기(Model deployer)(일 괄 프로세스), 및 실행기(프로세서)를 포함하는 AI 모듈들을 이용한다. (도 1 및 도 2 참조). 본 솔루션은 또한, 분산된 스토리지 솔루션들에서의 출현하는 도전 과제들에 대처하는데, 즉, 백엔드 스토리지 들 및 메타데이터 서버들이 레이턴시가 긴 네트워크들(예컨대, 인터넷) 내에 배치될 때 메타데이터 동작 및 파 일 콘텐츠 동작들의 긴 레이턴시에 대처한다. 본 솔루션은 로컬 스토리지 내에 복제되는 메타데이터의 일부를 한 번에 저장/검색할 수 있게 하여 콘텐츠 동작들보다 더 빈번하게 호출되는 메타데이터 동작들의 레이턴시를 감소시킴으로써 사용자 경험을 향상시킨다. 이 경우, 본 솔루션은 메타데이터의 보안을 분산된 방식으로 유지시 키기 위해 SSSS(또는 동등한 것)를 사용하여 콘텐츠-관련 메타데이터(예컨대, 청크 ID)를 암호화한다. 파일들을 기입하는 경우 원격 스토리지들로의 비동기식 파일 콘텐츠 전달은 데이터 저장 절차들을 사용자-대면 절차들로 부터 분리시키고, 이는 원격 스토리지들로의 콘텐츠 업로드 작업들을 완료하기 전에 일찍부터 사용자 인터페이 스에 대한 응답을 향상시킨다. 파일들을 판독하는 경우 AI-보조적 프리-페칭 및 캐싱은, 사용자의 파일 액세스 패턴, 애플리케이션의 타입, 등에 근거하여 로컬 디바이스 내에 요구된 데이터 콘텐츠를 배치하기 위한 더 좋은 예측을 제공한다. 본 솔루션은 또한, RS 코딩(또는 동등한 것)을 사용하여 콘텐츠를 직접적으로 인코딩하는 것에 추가하여, 콘텐 츠를 암호화하고, 그리고 RS 코딩은 암호화된 청크들을 인코딩하기 위해 사용되는데, 왜냐하면 이러한 코딩은 효율적인 스토리지를 조직화(formulating)하는데 적어도 유용하기 때문이다. 따라서, 더 강한 암호화를 제공하 지만 더 많은 오버헤드(overhead)를 제공하는 SSSS와 같은 또 하나의 다른 알고리즘을 사용하는 대신에, 본 솔 루션은 AES-256(또는 동등한 것)을 사용하여 청크 콘텐츠들을 암호화하고 이것의 암호화 키를 메타데이터 내에 별도로 저장한다. RS 코딩은 SSSS와 같은 다른 접근법들과 비교되는 바와 같이 스토리지 및 컴퓨팅(computing) 오버헤드의 측면에 서 효율적이다. 본 솔루션이 콘텐츠를 인코딩 전에 암호화함으로써 RS 코드의 보안 취약성을 이미 극복하기 때 문에, 효율 및 성능에 초점을 맞춘 다른 유사한 알고리즘들이 사용될 수 있다. SSSS(또는 동등한 것)가 메타데이터를 암호화하기 위해 사용된다. 메타데이터는 콘텐츠 암호화의 루트 키(root key)이다. 비록 본 발명이 다른 알고리즘들을, 이들이 동일한 (t, n) 또는 유사한 임계 속성들을 제공한다면, 사용할 수 있어도, 본 발명은 콘텐츠 데이터로부터 분리되어 다르게 암호화되고 저장되는 메타데이터를 보호하 기 위한 강한 암호화 알고리즘을 사용하고 요구한다. SSSS는 그 안정성을 이론적으로 보장하고, 이에 따라 공격 자가 충분한 샤드들을 갖지 않는다면 무차별 대입 공격(brute-force attack)이 가능하지 않다. 메타데이터의 전 체 크기가 파일 콘텐츠보다 훨씬 더 작기 때문에, 암호화 오버헤드는 무시가능하다. 콘텐츠 암호화에 대해, SSSS는 n배의 스토리지 오버헤드를 보여주지만, RS는 단지 n/t배의 스토리지 오버헤드만 을 보여준다. 하지만, RS는 암호화를 위해 설계되지 않았고, 이에 따라 알고리즘에서 제한된 무작위성 (randomness)을 갖는다(정적이며 리버스하기에 비교적 쉬움). RS 코드 외에 콘텐츠 청크들에 대해 AES-256(또는 다른 암호화)을 또한 사용함으로써, 본 솔루션은 n/t배의 스토리지 오버헤드를 여전히 달성하면서 무작위성을 향상시킨다. AES-256(또는 동등한 것) 암호화의 암호화 키를 보호하기 위해, 이차 체인이 SSSS를 사용하여 키를 암호화하고 키 샤드들을 메타데이터 샤드들 내에 저장한다. 파일 콘텐츠는 여러 가지 이유들 때문에 청크화된다. 첫째, 청크화는 중복된 콘텐츠를 식별할 수 있는 능력을 제공하고, 이에 따라 콘텐츠의 단 하나의 카피만을 그 카피의 참조들과 함께 저장함으로써 스토리지 효율이 향 상될 수 있다. 둘째, 청크화는 보안을 향상시킨다. 공격자는, 파일 콘텐츠를 획득하기 위해서, 요구된 청크들의 참조들을 알 필요가 있게 된다. 셋째, 청크화는 데이터 저장 및 그 위치의 유연성을 향상시킨다. 본 발명의 시스템은 또한, 스토리지 아키텍처 및 환경과 무관하게 엔드-투-엔드 보안을 구현하는 것에 관한 것 이다. 파일 암호화/암호해독 동작들은 메타데이터 및 데이터 판독/기입 동작들에 통합되는데, 이것은 중간자 공 격(man-in-the-middle attack)들 및 성능 저하들의 취약성을 최소화한다. 본 발명의 시스템 아키텍처는 또한 제 어 경로를 데이터 경로로부터 분리시킴으로써 엔드-투-엔드 보안을 강화시킨다. 도 3 참조. 암호화 체인으로 지칭되는 본 발명의 파일 인코딩 알고리즘은 데이터/메타데이터 암호화를 데이터 저장 전략과 통합하는 것을 목표로 한다. 이것은, 적대자(adversary)가 무한한 컴퓨팅 파워(computing power)를 가졌음에도 깨질 수 없는 정보-이론적 암호화방식(Information-Theoretic Cryptography)과 실현가능할 만큼 충 분히 짧은 기간 내에 현재 컴퓨팅 기술로는 깨질 수 없는 컴퓨터연산적 암호화방식(Computational Cryptography)의 조합이다.이전의 솔루션들과는 달리, 본 발명의 아키텍처에서는, 클라이언트와 데이터/메타데이터/키 스토리지들 사이에 데이터가 집합되는 단일 지점이 존재하지 않고, 이것은 \"중간자\" 공격에 대한 취약성을 제거함에 유의해야 한다 (예를 들어, 프록시 서버를 지칭할 때 때때로 용어 \"클라이언트\"가 사용되며, 용어 \"사용자 디바이스\"는 독립형 서버 또는 컴퓨터 또는 어떤 다른 컴퓨팅 디바이스일 수 있고, 여기서는 클라이언트들의 다양한 타입들을 포함 하는 것으로 가정됨). 암호화 체인들은 프록시 서버 없이 사용자 디바이스 상에서 개시된다. 암호화 체인은 또 한, 기존의 시스템들의 수정을 최소화하기 위해, 뿐만 아니라 사용자 경험의 변화를 감소시키기 위해, 메타데이 터 및 파일 I/O 동작들에 매끄럽게(seamlessly) 통합된다. 암호화 체인은, 스토리지 노드들로부터 데이터를 수 집하는 것을 제외하고, 메타데이터 및 파일 동작들의 수정들을 요구하지 않는다. 본 발명의 암호화 체인은 두 개의 부분들, 파일 암호화 체인과 메타데이터/키 암호화 체인으로 구성된다. 파일 암호화 체인은 콘텐츠 파일의 청크들을 포함한다. 본 발명의 방법은 각각의 청크를 암호화하고, 그 다음에 암호 화된 청크들을 샤드화한다. 각각의 청크는 중복된 조각들을 식별하기 위해 대체로 사용될 수 있는 콘텐츠 파일 의 슬라이스(slice)이다(문헌[KyoungSoo Park, Sunghwan Ihm, Mic Bowman, and Vivek S. Pai, \"Supporting practical content-addressable caching with CZIP compression\" Proceedings of the 2007 USENIX Annual Technical Conference, Santa Clara, CA, USA, June 17-22, 2007] 참조). 본 방법에서는, 스토리지 공간을 절 약하기 위해서 중복 조각들 중 단 하나의 카피만이 저장되며(이러한 기법은 데이터 중복제거(Data Deduplication)로 지칭됨), 위치는 메타데이터 내에 표시된다. 각각의 청크는 RS 코딩을 사용하여 다수의 샤드 들로서 인코딩된다. RS 코드는 일반적으로 암호화를 위해 사용되지 않기 때문에, 청크들은 적어도 하나의 암호 화 키로 암호화되며, 여기서 키는 청크가 샤드들로서 인코딩되기 전에 한번 사용을 위해 무작위로 생성된다. 암 호화 키는 메타데이터/키 암호화 체인 내에 보안화되게 저장된다. 키들 및 청크 식별자들(청크 ID들)은 SSSS에 의해 암호화된다. 청크 ID 샤드들의 각각의 세트 및 암호화 키 샤드들의 각각의 세트는 메타데이터 및 키 샤드 파일들의 형태로 메타데이터 스토리지 노드들 및 키 스토리지 노드들에 각각 분산된다. 이러한 프로세스는 중앙 집중화된 컴포넌트가 다수의 스토리지 노드들 간의 메타데이터, 키, 및 데이터 샤드들의 할당을 계산하도록 요 구하지 않는다. 다음의 섹션(section)들은 도 4를 참조하여 파일 및 메타데이터/키 암호화 체인들의 세부사항들 을 설명한다. 도 10은 추가 예를 제공한다. 파일 암호화 체인. 파일 및 파일의 메타데이터가, 제안된 암호화 체인 알고리즘의 입력들이다. 알고리즘은 데이 터 샤드들(암호화된 파일) 및 암호화된 메타데이터를 생성시킨다. 파일 암호화 체인의 절차를 탐구하기 전에, 평범한 메타데이터 M = (I,A)가 정의되는데, 여기서 I는 청크 ID들의 정렬된 리스트이고, A는 파일 속성들의 세 트이다. 청크화는 파일 f를 (청크들로 지칭되는) 더 작은 조각들로 쪼개어 C = {cid|id ∈ M의 I} = 청크화(f)가 성립되 도록 하는데, 여기서 cid는 청크의 콘텐츠이다(단계 3). 청크화는 전송 효율을 향상시키고 데이터 중복 제거의 유효성을 증가시킨다. 청크화는 또한 스토리지 백엔드에 의해 특정될 수 있는 파일의 최대 크기의 쟁점을 해결 한다. 청크들의 콘텐츠는 업데이트된 콘텐츠 및 메타데이터가 저장될 때마다 무작위로 생성되는 암호화 키 k로 암호화된다. i번째 암호화된 청크는 c'id = 암호화(cid,k)로서 나타내어진다. 암호화 알고리즘은 AES-256, 등과 같은 레거시 암호화 알고리즘(legacy encryption algorithm)들 중 하나일 수 있다. 암호화 알고리즘은 특정 알 고리즘으로만 한정되지 않는다. 암호화된 청크들은 RS 코딩을 사용하여 다수의 데이터 샤드들로 인코딩된다. RS 코드는 데이터 암호화를 위해서가 아니라 에러 정정을 위해 설계되기 때문에, 청크들을 암호화한 이후 RS 코딩 을 적용하는 것은 RS 코드의 보안 취약성을 보완한다. 데이터 샤드(또는 샤드)는 Sid = {si id|1≤i≤n} = RS(cid,t,n)이 성립하도록 나타내어지며, 여기서 t 및 n은 RS 코드의 파라미터들이다. 데이터 샤드는 이러한 시 스템 내에서 데이터 저장의 단위이며, 데이터 복원을 위해서 레거시 암호화 알고리즘으로 암호화되고 데이터 복 원을 위해서 RS 코딩에 의해 인코딩된다. 최종적으로, 데이터 샤드들은 다수의 스토리지들에 저장된다. 메타데이터/키 암호화 체인. 메타데이터는 바람직하게는 다수의 스토리지들에 걸쳐 저장된다. 메타데이터를 저 장할 때, 요구된 청크들의 참조들(청크 ID들)이 보안화되게 바람직하게는 SSSS로 암호화되는데, 이것은 메타데 이터/키 암호화 체인의 이론적 보안을 보장한다. 암호화된 청크 ID들은 {id'i|1≤i≤n} = SS(id,t,n)에 의해 나 타내어지는데, 여기서 t 및 n은 SSSS의 파라미터들이다. 파일 속성들과 같은 메타데이터 정보의 나머지는 메타 데이터 조회 성능을 향상시키기 위해서 암호화되지 않는다. 청크 ID들처럼, 암호화 키 k는 SSSS에 의해 암호화 되어 {k'i|1≤i≤n} = SS(k,t,n)이 성립되게 되는데, 여기서 t 및 n은 SSSS의 파라미터들이다. 그 다음에, 각각의 id'i는 암호화된 메타데이터 M'i = (I'i,A)에 저장된다. 최종적으로, 각각의 M'i 및 k'i는 메타데이터 스토리 지 및 키 스토리지에 각각 저장되게 된다. 따라서, 콘텐츠 및 메타데이터의 전체 암호화 솔루션으로서, 제안되는 암호화 체인은 (C,I) → (C'i,I'i),...,(C'n,I'n)의 함수이다. 콘텐츠 및 참조들은 컴퓨터연산적 및 이론적 암호화 기법들이 각각 적용된 후에 저장되기 때문에, 각각의 데이터 샤드 및 암호화된 메타데이터/키에서 데이터는 재구성을 위한 의미있는 정보를 포함하지 않는다. 암호해독 체인들. 데이터 디코딩은 암호화 체인의 리버스 절차이다. 정기적인 파일 동작에 대한 요구된 절차인 암호화된 메타데이터/키를 상이한 메타데이터/키 스토리지들로부터 수집함으로써, 요구된 키 샤드들이 암호화 키 및 청크 ID들을 디코딩하기 위해 수집된다. 그 다음에, 요구된 데이터 샤드들이 암호화된 청크들을 재생성시 키기 위해 수집된다. 최종적으로, 청크들을 암호해독하고 이들을 순서대로 연쇄(concatenating)시킨 후에 원본 파일이 재구성된다. 도 4는 시스템 컴포넌트들, 상호작용들, 및 프로세스 단계들을 포함하는 시스템 아키텍처의 예를 나타낸다. 사 용자 디바이스는 콘텐츠 및 메타데이터를 암호화(및 암호해독)하고 사용자 디바이스와 스토리지들 간에 데이터 를 동기화한다. 논리적 I/O 모듈은 사용자들과 통신하는 인터페이스이다. 만약 논리적 I/O 모듈이 오픈(Open), 판독(Read), 기입(Write), 등과 같은 파일 I/O 요청을 수신한다면, 이벤트 핸들러(event handler)는 파일 프로 세싱을 위한 부가 암호화 체인(add-on encryption chain)들을 수행하기 위해서 요청의 본래 파일 동작 이벤트를 하이잭킹(hijacking)함으로써 해당 요청을 핸들링(handling)한다. 엔드-투-엔드 보안을 보장하기 위해, 본 발명 은 바람직하게는 데이터 콘텐츠를 스토리지에 저장하기 전에 파일 암호화를 수행하는 장소로서 플러시(Flush), 에프싱크(Fsync), 및 클로즈(Close) 핸들러들을 구현한다. 수 개의 사용가능한 접근법들이 존재하며, 여기에는 라운드-로빈(round-robin), 무작위화(random), 및 민-맥스 알고리즘들과 같은 알고리즘들이 포함되지만, 이러한 것으로만 한정되는 것은 아니다. 본 발명의 일 실시예에서, 민-맥스 알고리즘은 스토리지들로의 전달을 위한 실증적 데이터 전송 속도를 사용하여 각각의 스토 리지에서 최대 전송 시간을 최소화시킨다. 업드로드할 때, 여기서 구현되는 바와 같은 민-맥스 알고리즘은, 만 약 인코딩 파라미터 n(각각의 청크에 대해 저장할 샤드들의 수)보다 더 많은 스토리지들이 이용가능하다면, 더 빠른 스토리지에 더 많은 샤드들을 저장한다. 다운로드할 때, 본 민-맥스 알고리즘은, 빠른 t개의 스토리지들 (여기서 t는 청크를 재구성하기 위한 요구된 샤드들의 수)을 대응하는 샤드들이 저장된 n개의 스토리지들로부터 선택함으로써 더 유용하다. 즉, n개의 샤드들에 분산된 파일을 재구성할 때, t개의 청크들이 필요하다. 파일 암호화 체인의 링크된 체인으로서, 메타데이터/키 암호화 체인은, SSSS에 의한 암호화된 키들 및 메타데이 터 샤드들 내의 하나 이상의 암호화된 청크 ID들과 같은 암호화된 정보를 포함하는, 다수의 메타데이터 및 키 샤드들을 생성시킨다. 암호화된 메타데이터 파일들 중 하나는 사용자 디바이스 내의 메타데이터 스토리지에 저 장된다. 구체적으로, 메타데이터 동작들의 레이턴시를 감소시키기 위해 로컬 디바이스 내에 메타데이터 샤드 파 일들의 카피가 저장된다. 다른 메타데이터 및 키 샤드 파일들은, 사용자의 선호도에 따라 단일 스토리지 노드 또는 논리적으로/물리적으로 독립된 스토리지 노드들에서 구성될 수 있는 메타데이터/키 스토리지들에 저장된다. 동기화 프로세싱 유닛은 자신의 지식 베이스(knowledge base)에 근거하여 사용자 디바이스와 스토리지들 간의 데이터 전송의 타이밍(timing)을 계산한다. 동기화 프로세싱 유닛은 또한 자신의 지식 베이스를 사용하여 샤드들 및 암호화된 메타데이터 파일들의 위치를 선택/식별한다. 이러한 작업은 비용 최적화, 성능 최적화, 보 안 최적화, 등을 목표로 한다. 데이터 전송 요청들이 요청 큐(request queue)로 푸시(push)되고, 커넥터(connector)들이 네트워크를 통한 실제 데이터 스토리지를 수행하기 위해 대응하는 요청들을 페칭한다. 스토리지들로부터의 응답 메시지들이 응답 큐 (response queue)로 푸시되는데, 응답 큐는 데이터 저장 요청들의 비동기식 응답들을 직렬화(serialize)한다. 응답들은 샤드들 및 암호화된 메타데이터 저장 상태를 업데이트하기 위해 페칭된다. 만약 I/O 요청이 데이터 전 송 동기화를 요구한다면, I/O 이벤트 핸들러는 대응하는 응답들이 수집될 때까지 대기한다. 시스템은, 암호화 체인을 통합하고 정보 분산 이론(information dispersion theory)을 적용함으로써, 저장된 데 이터의 엔드-투-엔드 보안을 제공한다. 엔드-투-엔드 데이터 보안은 도전 과제적 주제인데, 왜냐하면 최종- 사용자 디바이스 대 스토리지 백엔드 위치 간의 지연이 데이터 센터(data center) 내의 머신들 간의 지연보다 훨씬 더 높다는 점, 시스템의 성능이 가장 제한된 컴포넌트에 의해 제한된다는 점, 그리고 환경 설정(environment setup) 및 리소스(resource)들의 제어가 제한된다는 점 때문이다. 클라이언트들과 메타데이터 서 버들 간의 높은 네트워크 레이턴시는 메타데이터 동작들의 성능에 영향을 미친다. 메타데이터는 파일 콘텐츠를 조립(assemble)하기 위해 필요한 중요한 정보를 포함하기 때문에, 메타데이터를 최 종-사용자 디바이스 상에 온전히 그대로 저장하는 것은 매우 위험할 수 있다. 만약 메타데이터가 델리게이트 서 버(delegate server)(또는 서버들)에 저장된다면, 데이터 조회 동작들보다 더 빈번하게 호출되는 메타데이터 조 회 동작들은 시스템 성능에 있어 병목현상을 일으키게 된다. 예로서, 세프(Ceph)의 방법은 콘텐츠 스토리지와는 논리적으로 상이한 분산된 서버들에 메타데이터를 저장하되, 메타데이터 서버들 간의 오버헤드들을 균형잡으면 서 저장하는 것을 포함한다. 엔드-투-엔드 솔루션들에서의 도전 과제는, (거의) 최적의 또는 근사화된 성능을 보장하는 시스템을 설계하기 위해 클라이언트들과 서버들 간의 지연이 충분히 예측가능하지 않다는 것이다. 인 코딩/디코딩, (데이터 중복제거로서 주로 지칭되는) 중복된 콘텐츠를 식별하는 것, 그리고 데이터/제어 채널을 설계하는 것과 같은 기능들의 분해는 기능들을 결정하고 시스템의 성능은 하드웨어의 컴퓨팅 용량, 네트워크들 의 예상된 레이턴시, 및 동작들의 빈도를 주의깊게 고려하여 설계돼야 한다. 본 발명에서의 \"n 중에서 t\" 접근법과 관련하여, 이러한 접근법은 다수의 시간들에서 여러 가지로 중요하다. 먼 저, 본 발명에서는 아이템(item)이 n개의 단위(unit)들로 파싱되는 많은 시간들이 존재한다. 하지만, 이러한 경 우에, n은 상이한 값일 수 있다. 유사하게, 각각의 상이한 t도 또한 상이한 값일 수 있다(하지만, 둘 이상의 이 러한 t의 값 및/또는 둘 이상의 이러한 n의 값은 또한 동일한 값일 수 있음). 본 n 중에서 t 접근법은 바람직하 게는 파싱된 데이터 콘텐츠 조각들의 수와 관련되며, 이와는 별도로, 파싱된 메타데이터 조각들의 수와 관련되 고, 그리고 이와는 별도로 콘텐츠 데이터의 각각의 암호화된 청크의 데이터 샤드 조각들의 조각들의 수와 관련 된다. 재구성에 관해서, n 중에서 t 접근법은 다수의 시간들에서 중요하게 된다. 파일 암호화 체인 및 메타데이터/키 암호화 체인을 조직화하는 것은 전형적으로 데이터 프로세싱 유닛에서 수행 되는 컴퓨터연산적 작업들이다. 이전에 설명된 바와 같이, 파일 암호화 체인은 데이터 샤드들을 인코딩/디코딩 하고, 후속하여 메타데이터/키 암호화 체인이 유사한 기능을 서빙한다. 데이터 샤드들은 샤드들이 데이터 스토 리지들에 동기화되도록 스케줄링될 때까지 샤드 버퍼(shard buffer)에 일시적으로 저장된다. 다시, 도 4는 시스템 개관을 예시한다. 가능한 배치 방식들 중 하나의 예인 이러한 클라이언트-중심적 아키텍처 는 파일 및 메타데이터/키 암호화 체인들을 생성하는, 뿐만 아니라 암호화된 데이터를 스토리지 백엔드들로 확 산(spread)시키는 최종-사용자 디바이스에 배치되는 컴포넌트들을 나타낸다. 클라이언트는 PC, 랩탑, 또는 핸드 헬드 디바이스와 같은 최종-사용자 디바이스로만 한정되는 것이 아니라, 예로서 기업 서버(enterprise server) 일 수도 있다. 도 4는 본 발명의 맥락에서 사용자 디바이스와 스토리지 풀(storage pool)(들) 간의 관계를 도시한다. 사용자 디바이스는 보여지는 기능들을 적어도 수행하도록 프로그래밍된 프로세서 또는 프로세서 들의 그룹일 수 있다. 보여지는 바와 같이, 사용자 디바이스는 암호화 및 체인화를 담당하고, 그리고 암호 해독을 또한 담당한다. 사용자 디바이스는 입력/출력 수단을 포함하고, 여기서 입력/출력 수단은 (프로세 스 단계 1에서) I/O 요청 엔진(request engine)을 포함하고, 파일 콘텐츠를 전달하기 위한 입력/출력 이벤트 핸들러(들)를 포함하며, 여기에는 적어도 하나의 입력/출력 논리적 모듈이 포함되고(하지만, 이러한 것으로만 한정되는 것은 아님), 사용자 디바이스는 또한, 적어도 하나의 데이터 프로세싱 엔진/유 닛을 포함하고, 이러한 적어도 하나의 데이터 프로세싱 엔진/유닛은 파일 조각화(shredding), 청크들 및 데이터 샤드들을 인코딩, 디코딩, 암호화, 그리고 암호해독하는 것을 포함하는 기능들을 수행하는 파일 암호화 모듈을 포함하고, 메타데이터 파일 및 키 조각화, 샤드들을 인코딩, 디코딩, 암호화, 그리고 암호 해독하는 것을 포함하는 기능들을 포함하는 메타데이터/키 암호화 모듈을 포함하고, 사용자 디바이스 는 또한, 스토리지 엔진 및 관련된 스토리지를 포함하고, 이러한 관련된 스토리지는 업로드 및 다운 로드를 위한 데이터 샤드들 및 메타데이터/키 샤드들을 식별하기 위한 샤드 버퍼 및 메타데이터/키 스 토리지를 포함하고, 사용자 디바이스는 또한, 동기화 프로세싱 유닛 또는 엔진을 포함하고, 이 러한 동기화 프로세싱 유닛 또는 엔진에는 집합적으로 큐잉(queueing)을 요청하는 스케줄러 및 스 토리지 선택기가 포함되고, 사용자 디바이스는 또한, 요청들을 할당하기 위한 요청 큐잉 엔진 을 포함하고, 사용자 디바이스는 또한, 네트워크 인터페이스 엔진을 포함하고, 이러한 네트워크 인터페이스 엔진에는 네트워크를 통해 데이터 요청들을 전달하기 위한 데이터 및 메타데이터/키 스토리지를 위한 커넥터들이 포함되고, 그리고 사용자 디바이스는 또한, 데이터 결과들을 전송하기 위한 그리고 샤드들 및 암호화된 메타데이터/키 상태를 업데이트하기 위한 응답 큐잉 엔진을 포함 한다. 사용자 디바이스는 분산될 수 있는 다양한 원격 외부 스토리지 풀들과 통신하고, 여기서 원격 외부 스토리지 풀들은 데이터 및 메타데이터/키 스토리지, 뿐만 아니라 백업 스토리지(들)(42 1)를 포함한다. 재구성 프로세스는 청크화, 암호화, 샤드화, 및 분산 프로세스의 리버스 절차이고, 이것은 도식적 사용자 인터 페이스(GUI)를 갖는 사용자 애플리케이션으로서 구현될 수 있고 그리고/또는 범용 파일 시스템 인터페이스(예컨 대, 포직스(POSIX))를 사용하여 구현될 수 있다(하지만, 이러한 것으로만 한정되는 것은 아님). 본 발명에서, GUI 또는 파일 시스템 인터페이스는 바람직하게는 파일 이름 및 수정 시간에 의해 파일들을 리스트화한다. 다른 더 일반적인 파일 시스템 인터페이스들이 또한 지원된다(파일 수정 시간은 바람직하게는 메타데이터 내에 파일 속성으로서 저장됨). 이러한 인터페이스들은 파일 이름, 수정 시간, 액세스 시간, 크기, 등과 같은 필수 파일 속성들을 요구한다. 따라서, 인터페이스 내에서 보여지는 모든 파일들은 사용자 및 시스템 인터페이스 각각이 파일을 식별할 수 있도록 속성들을 갖는다. 파일을 재구성할 때, 메타데이터를 먼저 재구성하는 것이 필요하다. 메타데이터의 t개의 부분들이 메타데이터를 재구성하기 위해 식별될 필요가 있다. 메타데이터는 청크별로 콘텐츠 데이터의 청크 데이터를 포함하고, 이에 따라 t개의 샤드들이 각각의 청크를 재구성하기 위해 각각의 청크에 대해 식별될 필요가 있다(다시 말하지만, 청크별로 각각의 t 및 각각의 n은 서로 상이할 수 있지만 그럴 필요는 없으며 메타데이터에 대한 n 중에서 t와 상이할 수 있지만 그럴 필요는 없음). 각각의 청크는 메타데이터 내에 이전에 저장 및 암호화된 관련된 키를 적 어도 사용하여 재구성된다. 각각의 청크가 재구성된 후에, 청크들은 이들이 초기에 존재했던 대로 정렬되어 전 체 파일을 재구성하게 되고 다시 한번 사용가능하게 된다. 전에 언급된 바와 같이, 본 발명에서 사용가능한 많은 스토리지 시설들이 존재하며, 바람직한 실시예에서, 재구 성을 위해 더 필요한 아이템들은 더 액세스가능한(그리고 잠재적으로는 더 값비싼) 영역들에 저장된다. 더욱이, 이러한 아이템들은 언급된 예들에서와 같이 비용 고려들에 근거하여 하나의 위치로부터 또 하나의 다른 곳으로 이동될 수 있다. 결과로서, 파싱된 데이터 콘텐츠 및 메타데이터 요소들의 지속적인 스토리지 재배치를 위한 구 현된 알고리즘이 존재할 수 있다. 그럼에도 불구하고, 다수의 n 중에서 t 접근법들을 포함하는 재구성 프로세스 는 바람직한 실시예로 존속한다. 파일 재구성 예. 암호화된 파일 F가 존재하는데 이 파일의 콘텐츠가 하나의 청크 C1로 구성되고, C'1로서 암호화 되고, 그리고 샤드들 S1,1, S1,2 ... S1,n으로서 저장된다고 가정한다. 파일 F에 대한 메타데이터 M은, C1의 청크 ID로서의 저장된 I1, 암호화 키 K1, 그리고 (이름, 크기, 및 수정 시간(modification time)(m시간)을 포함하는) 파일 속성들을 포함하도록 수정되었고, 이들은 메타데이터 샤드들 M1, ... M3이다. 저장되는 바와 같은 메타데이 터 샤드 Mi는 파일 속성들(이름, 크기 및 m시간), 암호화된 청크 ID I'1,i 및 암호화 키 K'1,i를 포함한다. 사용자가 파일을 재구성하려고 시도하는 경우, 사용자 인터페이스는 사용자 디바이스 내에서 메타데이터 샤드들 의 세트에 액세스함으로써, 저장된 파일들을 디스플레이한다. 디스플레이는 전형적으로 파일 이름 및 암호화의 시간을 보여준다. 사용자는 이름에 의해 파일을 선택함으로써 파일 F의 재구성을 시작할 수 있다. 시스템은 동 일한 파일 속성들을 찾음으로써 메타데이터 백엔드 스토리지들 내에서 대응하는 메타데이터 샤드들을 식별한다. 시스템은 두 개의 대응하는 메타데이터 샤드들 Mi 및 Mj 내에서 I'1,i 및 I'1,j로부터 I1을 암호해독하고 K'1,i 및 K'1,j로부터 K1을 암호해독한다. I1을 사용하여, 시스템은 대응하는 샤드들 S1,1, S1,2 ... S1,n으로부터 t개의 샤드 들을 다운로드하여, 암호화된 청크 C'1을 재구성하게 되고, 이것은 K1을 사용하여 C1로 암호해독되게 된다. 최종 적으로, 재구성된 청크(들)에 의해 파일 F가 재구성된다. 파일 이름 및 수정 시간의 쌍은 파일을 재구성하기 위해 필요한 초기 조합이다. 도 4를 참조하면, 엔드-투-엔드 보안을 보장하기 위해, 재구성은 파일 이름 및 수정 시간을 특정하는 파일 오픈 동작과 통합된다. 메타데이터/ 키 암호화 모듈은 동기화 프로세싱 유닛에게 메타데이터 및 키 샤드들의 수집을 요청한다. 스토리지 선택기 모듈은 레이턴시 및 비용을 포함하는(하지만, 이러한 것으로만 한정되는 것은 아닌) 최적화 파라미 터들에 근거하여 t개의 타겟 메타데이터/키 스토리지들을 선택한다. 만약 바람직한 파라미터가 구성되지 않는다 면, 스토리지들은 무작위로 선택된다. 메타데이터/키 암호화 모듈은 청크 ID들 및 암호화 키들을 대응하는 청크들로 암호해독한다. 파일 암호화 모듈은 청크 ID들에 의해 특정된 데이터 샤드들의 수집을 요청한다. 데이터 샤드들에 대한 스토리지 선택은 암호화에서와 동일하다. 파일 암호화 모듈은 암호화된 청크들을 데이터 샤드들을 사용하여 재구성한다. 그 다음에, 암호화된 청크들은 암호화 키들을 사용하여 파일의 평범한 청 크들로 암호해독된다. 제어 서버는 클라이언트들의 상태를 제어 및 모니터링하기 위해 클라이언트들을 감독(oversee)한다. 제어 서버 는 또한 데이터 스토리지, 메타데이터/키 스토리지, 및 메타데이터/키 백엔드 스토리지를 구성하지만, 제어 서 버는 스토리지 백엔드들의 프록시를 서빙하지 않는다. 제어 서버는 또한, 데이터 스토리지 설정, 메타데이터 스 토리지 설정, 키 스토리지 설정, 상태 모니터링, 정책 구성, 액세스 제어, 등과 같은 전체 구성을 제어하기 위 해 관리자 포털(administrator portal)을 제공한다. 제어 서버는 또한 사용자 및 디바이스의 초기 인증을 담당 한다. 제어 서버는 인증 절차를 LDAP 또는 유사한 것과 같은 기존의 컴포넌트들과 통합할 수 있다. 데이터 스토리지는 사용자 데이터가 실제로 저장되는 위치이다. 데이터 스토리지 상에서 코드 실행은 없다. 따 라서, 데이터 스토리지는 클라우드 서비스들로만으로 한정되는 것이 아니라 네트워크를 갖는 레거시 스토리지 노드들 중 임의의 것을 포함할 수 있다. 메타데이터 스토리지 및 키 스토리지들은 파일 메타데이터 및 암호화 키들이 저장되는 위치이다. 데이터 스토리지, 메타데이터 스토리지, 및 키 스토리지는 독립적인 (t, n) 파라미 터들로 구성될 수 있다. 메타데이터 및 키 스토리지들은 데이터 스토리지의 요건과 유사한 요건들을 갖고, 이에 따라 데이터 스토리지 노드는 메타데이터 및 키 스토리지들에 대해 대안적으로 사용될 수 있다. 성능 및 신뢰가 능성 요건들, 뿐만 아니라 데이터 관리 정책에 따라 스토리지들이 구성될 수 있다. 메타데이터/키 백업 스토리 지는 클라이언트 디바이스 상의 메타데이터/키 샤드들과 동일한 메타데이터/키 샤드들의 중복 카피들을 저장한 다. 메타데이터 및 키 샤드들이 SSSS에 의해 암호화되기 때문에, 동일한 세트의 샤드들을 복제하는 것이 데이터 침해(data breach)의 위험을 증가시키지 않는다. 비록 이러한 데이터 스토리지, 메타데이터/키 스토리지, 및 메 타데이터/키 백업 스토리지가 LAN을 통해, 인터넷을 통해, 또는 하이브리드(hybrid) 형태로 배치될 수 있지만, 최적의 배치를 위한 지침들이 존재하는데, 제어 서버는 클라우드 또는 LAN 내에 있을 수 있고, 메타데이터/키 백업 스토리지는 LAN 내에 있을 수 있고, 또는 데이터 스토리지 및 메타데이터/키 스토리지는 클라우드 내에 혹 은 클라우드와 LAN 간의 하이브리드 형태로 있을 수 있다. 데이터 경로 및 제어 경로 분리. 도 5는 본 시스템에서 데이터 및 제어 경로들이 어떻게 분리되는지의 개관을 나타낸다. 메타데이터를 분리시키는 것에 추가하여, 제어 서버와 클라이언트 간의 제어 경로(긴 점선들)는 클라 이언트 대 데이터 스토리지 간의 데이터 경로(실선들)로부터 논리적으로 또는 물리적으로 분리된다. 데이터 경로와 제어 경로의 분리는 제어 서버의 가장 높은 권한을 가진 관리자라도 사용자 데이터에 액세스하는 것을 막는다. 클라이언트와 각각의 데이터 스토리지 간의 각각의 데이터 경로는 각각의 데이터 스토리지 노드에 의해 제공되는 다양한 보안 메커니즘들을 활용함으로써 독립적으로 보호된다. 데이터 경로로부터의 제어 경로의 독립성으로 인해, 제어 서버를 배치하는 것은 보안 및 성능 구성에 영향을 미침이 없는 유연한 프로세스이다. 데이터 샤드들의 저장. 엔드-투-엔드 보안을 보장하기 위해서, I/O 이벤트 핸들러는 데이터 콘텐츠를 스토리지 노드들에 저장하기 전에 파일 암호화를 구현하기 위해 플러시(Flush) 및 에프싱크(Fsync) 파일 시스템 호출 이 벤트들을 인터셉트(intercept)한다[플러시(Flush) 및 에프싱크(Fsync)는 메인 메모리 내의 데이터를 물리적 스 토리지 디바이스에 동기화시키는 파일시스템 호출들임. 에프싱크(Fsync)는 플러시(Flush)의 하위-레벨 시스템 호출임. www.man7.org/linux/man-pages/man2/fdatasync.2.html]. 암호화된 청크들로부터의 데이터 샤드들은 데 이터 스토리지로의 전송이 스케줄링될 때까지 샤드 버퍼 내에 버퍼링된다. 따라서, 본 발명은 플러시(Flush)가 호출된 후에 중간 데이터 암호화를 보장한다. 스케줄러는 비용 최적, 성능 최적, 및 보안 최적과 같은 구성에 근거하여 데이터 샤드들의 위치 및 전송의 타이밍을 결정한다. 예를 들어, 일관된-해시 알고리즘(consistent- hash algorithm)은 데이터 스토리지를 부가/분리할 때 샤드 재배치 비용들을 최소화한다. 더 진보된 알고리즘들 이 개발 및 배치될 수 있다. 암호화된 메타데이터/키의 저장. 메타데이터/키 암호화 체인은 파일 암호화 체인을 완료한 이후에 트리거 (trigger)된다. 암호화 키들은 키 스토리지로의 전송이 스케줄링될 때까지 로컬 메타데이터/키 스토리지 내에서 샤드화된다. 데이터 및 키 샤드들을 데이터 및 키 스토리지 노드들에 저장하는 것과는 달리, 메타데이터를 저장 하는 것은 플러시(Flush), 에프싱크(Fsync), 또는 클로즈(Close) 호출들과 함께 동기화된 프로세스이다. 따라서, 만약 암호화된 메타데이터를 저장하는 것이 실패한다면, 플러시(Flush), 에프싱크(Fsync), 또는 클로즈 (Close)는 실패 코드를 리턴하게 된다. 데이터의 스테이지화. 샤드들을 스토리지 백엔드들에 업로드하기 전에 최종-사용자 디바이스 내에서 데이터를 스테이지화하는 것은, 업로드 지연들을 흡수함으로써, 뿐만 아니라 데이터 저장을 스케줄링하기 위해 사용자들 에게 더 많은 자유를 제공함으로써, 사용자 경험들을 향상시킨다. 본 발명의 스토리지 내에는 스테이지화된 데이터의 6가지 상태들이 존재한다. 메타데이터는 프로세스를 계속 진행시키기 위해 저장돼야만 하기 때문에 상태 4가 상태 3과 동기화돼야만 함에 유의해야 한다. 상태 0: 시작할 준비가 됨 상태 1: 청크 콘텐츠를 무작위로 생성된 암호화 키로 암호화함; 데이터 샤드들을 인코딩함(프로세스에서 블록 1) 상태 2: 청크 ID를 암호화함(블록 2 완료) 상태 3: 메타데이터 및 키 샤드들을 저장함(블록 3 완료) 상태 4: 데이터 샤드들을 저장함(블록 1 재방문 및 완료) 상태 5: 끝남 메타데이터 동작들. 암호화된 메타데이터의 샤드들은 다수의 위치들 내에 저장되기 때문에, 메타데이터 조회 동 작들은 로컬 암호화된 메타데이터 샤드들로부터 직접적으로 파일 속성들을 판독할 수 있다. 디렉토리 동작들 및 파일 속성 동작들은 메타데이터/키 스토리지 및 데이터 스토리지의 레이턴시와 무관하게 성능 저하를 초래하지 않는다. 메타데이터 파일을 기입하는 것은 데이터 동작들과 대부분 관련되어 있기 때문에, 메타데이터를 기입하 는 지연은 다른 데이터 스토리지 및 복구 동작들과 비교해 무시할만큼 충분히 작다. 메타데이터 스토리지 선택. 데이터 샤드들을 확산시킬 때와는 달리, 메타데이터 샤드들은 미리-구성된 메타데이 터 스토리지들에 저장된다. 메타데이터 인코딩의 지침은 (t, n) = (2, 3)으로 설정하는 것이다. 메타데이터 정 의는 다음과 같다. M = {M'1,M'2,M'3}, 여기서 M'i는 암호화된 메타데이터 샤드임(M'1). 적어도 일부 메타데이터는 로컬 디바이스 내의 메타데이터 볼트(metadata vault)에 항상 저장되는데, 이것은 메 타데이터 조회 동작의 레이턴시를 감소시킨다. 메타데이터 샤드들의 나머지, M'2 및 M'3은 원격 메타데이터 스토 리지들에 저장된다. 본 발명의 시스템은 메타데이터 샤드들을 다수의 메타데이터 스토리지 노드들에 분산시키도 록 구성된다. 선택적인 프로세스로서, 메타데이터 샤드 M'1의 카피가 메타데이터 백업 스토리지에 저장된다. M'1 의 카피를 저장하는 것은 메타데이터 샤드들의 복원을 증가시키면서 파라미터 n을 변경시키지 않는다. 비록 지 침이 (t, n) = (2, 3) 구성을 제안하지만, 본 발명의 시스템은 고객 요건들에 따라 유연하고 구성가능할 수 있 다. 메타데이터 및 데이터 콘텐츠의 동기화. 모든 파일들의 메타데이터 및 데이터 콘텐츠는 주기적으로 동기화된다. 이러한 프로세스는 청크들의 상태들, 즉, 로컬 전용, 원격 전용, 로컬 및 원격, 중간 상태에 따라 청크들의 참 조 카운터(reference counter)들을 계산한다. 참조 카운터들은 청크 인코딩 및 샤드들의 확산을 스케줄링하기 위해 사용된다. 이러한 프로세스는 또한 완전히 삭제될 수 있는 비-참조된(un-referred) 청크들을 식별한다. 데이터 삭제. 메타데이터 업데이트들은 히스토리(history)를 추적하기 위해서 저장되기 때문에, 삭제는 메타데 이터 또는 콘텐츠 데이터를 삭제하지 않는다. 파일이 업데이트될 때, 시스템은 이전의 버전(version)들의 수가 미리-정의된 수를 초과할 때까지 이전의 버전을 삭제함이 없이, 업데이트된 메타데이터를 저장한다. 만약 메타 데이터 파일이 삭제돼야 한다면, 시스템은 최종적으로 메타데이터와 청크 간의 참조를 언링크(unlink)시킨다. 만약 시스템이 참조 카운트가 제로(zero)인 청크들을 식별한다면, 시스템은 최종적으로 백엔드 스토리지들로부 터 청크들을 삭제한다. 정상 모드 동작들. 도 6은 본 발명의 파일 저장 프로세스의 단계별 절차를 나타낸다. 보여지는 바와 같이, 8개 의 관련 단계들이 존재한다. 601. 에프싱크(Fsync) - 클라이언트에서 수행됨 602. 인코딩 - 클라이언트에서 수행됨 603. 스테이지화 - 클라이언트에서 수행됨 604. 메타데이터 샤드를 저장함 - 클라이언트에서 수행됨 605. 메타데이터/키 샤드들을 저장함 - 인터넷으로부터 메타데이터/키 스토리지로 606. 메타데이터/키 샤드의 백업을 저장함 - LAN으로부터 메타데이터/키 백업 스토리지로 607. 스케줄링된 것을 푸시함 - 클라이언트에서 수행됨 608. 파일 샤드들을 저장함 - 인터넷으로부터 데이터 스토리지로 에프싱크(Fsync) 및 플러시(Flush)와 같은 특정 시스템 호출 이벤트가 수신될 때마다, 클라이언트는 대응하는 파일을 암호화 체인으로 인코딩하기 시작한다. 파일 암호화 체인 프로세스가 완료된 경우, 데이터 샤드들이 스 테이지화된다(데이터 스토리지로 푸시할 준비가 됨). 그 다음에, 메타데이터 샤드들이 클라이언트, 메타데이터 스토리지, 및 메타데이터 백업 스토리지에 저장된다. 키 샤드들이 또한 키 스토리지, 및 키 백업 스토리지에 저 장된다. 최종적으로, 스테이지화된 데이터는 스케줄러가 실행을 트리거할 때 데이터 스토리지들을 저장하도록 스케줄링된다. 파일 페칭은 파일 저장의 리버스 절차이다. 비록 특정 레벨의 스토리지 실패들이 존재할지라도(n개의 스토리지 들 중에서 적어도 t개가 이용가능할지라도, 여기서 t는 RS 코드 및 SSSS 코드의 파라미터임), 파일 페칭 동작들 은 정상 모드로서 실행된다(실패들은 로그화됨). 만약 에러들의 수가 구성가능한 임계치를 초과한다면(t개보다 작은 스토리지들이 이용가능하다면), 파일 페칭은 페칭 에러를 사용자에게 리턴한다. 때때로, 소실된 클라이언트와 같은(하지만, 이러한 것으로만 한정되는 것은 아닌) 클라이언트를 블랙리스트화는 것은 중요할 수 있다. 도 7은 오래된 디바이스를 블랙리스트에 추가하고 새로운 클라이언트를 등록하는 절차를 나타낸다. 만약 사용자가 클라이언트를 소실한다면, 사용자 및/또는 관리자는 이것을 제어 서버에 보고한다. 보 여지는 바와 같은 절차에서의 단계들은 다음과 같은 것을 포함한다. 701. 소실된 클라이언트를 블랙리스트화함 - 제어 서버에 의해 수행됨 702. 인증 세션(authentication session)들을 만료함 - 제어 서버에 의해 수행됨 703 - 705. 액세스가 거부됨 706. 클라이언트를 등록함 - 제어 서버에 의해 수행됨 707. 메타데이터를 복구하도록 커맨드(command)함 - 제어 서버에 의해 수행됨 708. 백업 스토리지로부터 메타데이터를 페칭함 - 새로운 클라이언트에 의해 수행됨 709. 인증 세션들을 재구성함 - 제어 서버에 의해 수행됨 710 - 712. 액세스가 허가됨 제어 서버는 클라이언트 정보를 블랙리스트에 배치하고 데이터 스토리지들, 메타데이터/키 스토리지들 및 메타 데이터/키 백업 스토리지와의 인증을 위해 사용된 모든 세션들을 만료한다. 만약 사용자가 파일들을 복구하기 위해 클라이언트 디바이스를 복구 또는 교체한다면, 새로운 클라이언트는 제어 서버에 의해 인증돼야만 한다. 그 다음에, 제어 서버는 메타데이터/키 백업 스토리지를 사용하여 메타데이터를 복구하기 위해 커맨드 메시지 (command message)를 보낸다. 최종적으로, 제어 서버는 새로운 클라이언트 액세스 정보를 데이터 스토리지들, 메타데이터/키 스토리지들, 및 메타데이터/키 백업 스토리지들에 제공한다. 실패 모드 동작들. 실패 모드 동작들은 스토리지 실패들의 수가 임계치를 초과하지 않는 경우 사용자들로 하여 금 시스템을 계속 사용할 수 있게 한다. 실패 모드를 요구하지 않는 파일 페칭과는 달리, 파일 저장은 제어되는 그리고 실행가능한 상태들 하에서 시스템을 유지하기 위해 백엔드-측 업로드 실패 에러들을 핸들링하기 위한 메 커니즘을 요구한다. 도 8은 데이터 스토리지 실패가 있는 파일 저장의 절차를 나타낸다. 이러한 프로세스의 단계들은 다음과 같은 것을 포함한다. 801. 에프싱크(Fsync) 802. 인코딩 803. 스테이지화 804. 메타데이터 샤드를 저장함 805. 메타데이터/키 샤드들을 저장함 806. 메타데이터/키 샤드의 백업을 저장함 807. 스케줄링된 것을 푸시함 808. 파일 샤드들을 저장함 809. 에러를 검출함 810. 비성공적으로 저장된 샤드들을 로컬로 유지시킴 811. 다음 스케줄에서 푸시를 재시도함 이러한 절차는 데이터 샤드들이 데이터 스토리지들로 푸시될 때까지 정상 모드 파일 저장 동작에서와 동일하다. 만약 클라이언트가 샤드들을 저장하기 위한 업로드 에러들을 검출한다면, 클라이언트는 샤드들을 로컬로 유지하 고, 이것은 스테이지화된 샤드들에서와 동일한 방식으로서 관리된다. 그 다음에, (클라이언트 내의) 스케줄러는 다음 푸시 싸이클에서 다른 새로운 스테이지화된 샤드들과 함께 샤드들을 재-스케줄링한다. 도 9는 데이터 스토리지 실패보다 훨씬 더 중요한 메타데이터/키 스토리지 실패가 있는 파일 저장의 절차를 나 타낸다. 이러한 프로세스의 단계들은 다음과 같은 것을 포함한다. 901. 에프싱크(Fsync) 902. 인코딩 903. 스테이지화 904. 메타데이터 샤드를 저장함 905. 메타데이터/키 샤드의 백업을 저장함 906. 메타데이터/키 샤드들을 저장함 907. 에러를 검출함 908. 롤백(Rollback) 데이터 스토리지 실패의 실패 모드와는 달리, 메타데이터/키 스토리지 실패는 시스템으로 하여금 파일 저장 동 작을 계속하도록 허용하지 않는다. 대신에, 진행 중인 데이터 저장 동작들은 롤백된다. 이전에 저장된 모든 파 일들은 메타데이터/키 스토리지가 복구될 때까지 판독-전용 모드에서 여전히 액세스가능하다. 도 3은 본 발명의 암호화 체인 생성 실시예를 도시한다. 본 명세서에서 암호화 체인으로서 지칭되는 파일 인코 딩 접근법은 데이터/메타데이터/키 암호화를 데이터/메타데이터/키 스토리지 전략과 통합하는 것을 목표로 한다. 방법 단계들은 다음과 같은 것을 포함한다. 1. 파일 암호화 체인들의 생성 o 각각의 데이터 파일은 암호화 체인을 형성하기 위해 청크들로 파싱된다. o 암호화 체인들이 바람직하게는, 중앙집중화된 디바이스가 아니라 사용자 디바이스 상에서 개시된다. o 두 개의 별도의 암호화 체인들이 생성됨 - 데이터 파일 암호화 체인 및 전형적으로 이후에 생성되는 메타데이 터 파일 암호화 체인. 이러한 메타데이터 파일은, 데이터 파일 암호화 체인이 어떻게 암호화되는지에 관한 정보, 그리고 메타데이터 파일 암호화의 분산 및/또는 암호화에 관한 다른 정보, 그리고 분산되는 것을 포함하 지만, 이러한 것으로만 한정되는 것은 아니다. o 이러한 실시예에서, 데이터 파일은 먼저 청크화되고 그 다음에, 암호화된다. o 청크화될 때, 각각의 청크에는 ID가 할당되고, 할당된 ID들은 메타데이터 내에 포함된다. o 그 다음에, 각각의 암호화된 청크는 샤드들로 분해된다. o 샤드들은 궁극적으로 스토리지로 보내지며, 각각의 샤드는 잠재적으로 상이한 위치들 내의 상이한 스토리지 매체로 잠재적으로 이동한다. o 바람직하게는 데이터 샤드들 내에서 암호화되는 어떠한 메타데이터도 없다(하지만 청크 식별자들이 메타데이 터 샤드들 내에 임베드(embed)됨). 2. 데이터 파일 암호화는 종래의 파일 암호화를 사용하고 여기에 더하여 샤드화를 위한 후속하는 리드-솔로몬 (RS, 또는 동등한 것) 코딩을 사용한다. o 각각의 데이터 파일은 암호화 체인으로 파싱되고, 여기서 파일은 청크들로 확산되고 그 다음에, 각각의 청크 는 샤드들로 확산된다. o 각각의 청크는 계산에 의해 결정될 수 있는 특정된 ID를 갖는다. o 메타데이터는 할당된 ID들에 의해 증강되고, 이에 따라 메타데이터는 다양한 파일 속성들(예컨대, 이름, 크기, 수정 시간, 및 액세스 시간과 같은 것, 하지만, 이러한 것으로만 한정되는 것은 아님), 및 ID들을 포함하 게 되며, 여기서 각각의 ID는 특정 데이터 파일 청크와 관련된다. o 청크 ID들은 관련된 메타데이터에 삽입된다. o 데이터 파일 청크들은 암호화되고, 그 다음에, RS 또는 동등한 것을 사용하여 인코딩된다. o 그 다음에, 암호화된 청크들은 샤드화된다. o RS 코드는 암호화를 위해 설계되지 않기 때문에, 청크들은 본 발명의 프로세서에 의해 결정되는 암호화 키로 암호화되고, 여기서 암호화 키는 청크가 샤드들로서 인코딩되기 전에 한번 사용을 위해 무작위로 생성될 수 있 다. o 하나의 키가 전체 데이터 파일 청크화, 암호화, 및 저장 프로세스에 대해 사용될 수 있고, 상이한 키가 각각 의 청크에 대해 사용될 수 있고, 또는 그 중간 정도의 것이 사용될 수 있다. 키들의 분량(quantity)의 결정은 본 발명의 프로세서에 의해 수행될 수 있고, 결과는 청크화, 등을 위해 메타데이터 내에 저장될 수 있다. 3. 요구된 콘텐츠의 참조들을 저장하는 메타데이터에 대해, SSSS 또는 동등한 것을 사용하여 청크 식별자(청크 ID들)가 암호화된다. o 메타데이터 샤드 파일은 청크 ID 샤드들을 저장한다. o 각각의 암호화 키 자체가 샤드화된다. o SSSS 또는 동등한 것을 사용하여 (청크 암호화를 위해) 각각의 암호화 키가 또한 암호화된다. o SSSS 암호화 방식들과는 다른 것이 대안적으로 사용될 수 있다. o 사용자는 파일을 재구성하기 위해 필요한 샤드들의 최소 수를 특정할 수 있다. 4. 청크 ID 샤드들의 세트가 크기, 수정 시간, 등을 포함하는 복제된 파일 속성들과 함께 메타데이터 샤드 파일 에 저장된다. 암호화 키 샤드들은 대응하는 청크 ID들과 관련된다. 5. 청크화된 데이터, 메타데이터, 및 암호화 키의 샤드들이 물리적으로 또는 논리적으로 분산된 스토리지/매체 에 저장된다. 6. 이러한 프로세스는 중앙집중화된 컴포넌트가 다수의 스토리지 유닛들 간의 데이터, 메타데이터, 및 키 샤드 들의 할당을 계산하도록 요구하지 않는다. 7. 샤드들을 저장/페칭하기 위해 스토리지들을 선택하기 위해서 스토리지 효율 및 성능을 향상시키기 위해 다양 한 알고리즘들이 적용가능하다. 도 11은 파일 암호화 및 메타데이터/키 암호화의 예를 나타낸다. 구성가능한 파라미터 t 및 n은 파일 및 메타데 이터/키 암호화를 위해 2 및 3으로 각각 설정된다. 본 예는 파일의 콘텐츠가 \"abcdefgh\"인 파일을 저장하고 세 개의 스토리지들 중에서 하나의 스토리지 실패를 허용한다. 파일은 두 개의 조각들 \"abcd\" 및 \"efgh\"로 청크화 된다. 청크들의 참조들(청크 ID로 지칭됨)을 만들기 위해, 청크 콘텐츠의 SHA 256 해시가 계산된다. 이러한 예 에서, 8c3f = Sha-256(\"abcd\") 및 a3dc = Sha-256(\"efgh\")은 청크 ID들이다. 이러한 청크 ID들은 메타데이터에 저장된다(제이슨 포맷(JSON format)). 청크 콘텐츠 \"abcd\" 및 \"efgh\"는 무작위로 생성된 키들 \"y2gt\" 및 \"5xkn\"을 사용하여 각각 암호화된다. 따라서, 청크 콘텐츠는 \"X?2#\" 및 \"&$cK\"로서 암호화된다. 그 다음에, 암 호화된 청크 콘텐츠는 리드-솔로몬(RS) 코딩을 사용하여 인코딩된다. 암호화된 청크 콘텐츠 \"X?2#\"는 3개의 샤 드들 \"kg\", \"dh\", 및 \"%f\"로 인코딩된다. \"X?2#\"를 재구성하기 위해서는, 3개의 샤드들 중에서 임의의 2개의 샤드들이 요구된다. 암호화된 청크 \"&$cK\"도 또한 동일한 방식으로 인코딩된다. 최종적으로, 데이터 샤드들은 데 이터 스토리지 노드들에 저장된다. 청크 콘텐츠를 암호화하기 위해 사용된 키들은 대응하는 청크와 관련된다. 청크 참조 정보(청크 ID들)를 보호하 기 위해, 이들은 SSSS를 사용하여 암호화되는데, 이것도 또한 암호해독을 위해서는 세 개의 샤드들 중 임의의 2 개를 요구한다. 청크 ID \"8c3f\"는 \"ct1d\", \"jfy2\", 및 \"7g72\"로 암호화된다. 다른 청크는 동일한 방식으로 인코 딩된다. 청크 ID 샤드들이 메타데이터 샤드 파일들에 각각 저장된다. 암호화 키 \"y2gt\"가 또한 SSSS를 사용하여 \"3cd2\", \"ziaj\", 및 \"pzc8\"로 암호화된다. 다른 암호화 키 \"5xkn\"도 또한 동일한 방식으로 인코딩된다. 최종적 으로, 메타데이터 및 키들은 세 개의 상이한 메타데이터 샤드 파일들 키 샤드 파일들을 상이한 위치에서 저장함 으로써 보호된다. 세 개의 메타데이터 파일들 중 두 개가 액세스가능한 경우에만, 청크 ID들 \"8c3f\" 및 \"a3dc\"가 획득될 수 있다. 이러한 청크 ID들을 사용하여, 데이터/키 샤드들을 찾을 수 있고, 암호화된 청크 콘텐츠 \"X?2#\" 및 \"&$cK\"가 재 구성될 수 있다. 최종적으로, 암호화된 청크 콘텐츠가 암호화 키들을 사용하여 암호해독되고, 암호해독된 청크 들을 연쇄시킴으로써 원본 콘텐츠 \"abcdefgh\"가 획득된다. 데이터 무결성 확인(Data Integrity Validation). 특정 레벨의 실패들을 허용하면서 다수의 샤드들을 저장하는 것은 프로세스가 데이터 저장 상태를 계산하도록 요구하고, 이것은 대개 I/O 집중적 작업이다. 데이터 무결성 확인의 효율을 향상시키기 위해, 본 발명의 시스템은 데이터 저장 상태를 계산하기 위해서만 전형적인 스토리지 및 오퍼레이팅 시스템(operating system)들 상에서 이용가능한 전형적인 리스트 오브젝트(list object)(또는 파 일) 동작을 사용한다. 파일 경로, 수정 시간, 및 파일 상태를 포함하는 메타데이터 스토리지들로부터 메타 데이터 샤드 오브젝트들의 리스트들을 페칭함. 청크 ID를 포함하는 데이터 스토리지들로부터 데이터 샤드 오브젝트들의 리스트들을 페칭함. 관련된 청크 ID를 포함하는 키 스토리지들로부터 키 샤드 오브젝트들의 리스트들을 페칭함. 파일 경로 및 수정 시간이 동일한 메타데이터 파일 세트에 근거하여 리스트 내에 나타 나는 메타데이터 파일들을 카운트(count)함. 만약 세트 내의 메타데이터 파일들의 수가 n이라면, 메타데이터 파 일들은 스토리지 실패들로부터 완전한 복원을 보장한다. 만약 메타데이터 파일들의 수가 n보다 작고 t보다 크거 나 같다면, 대응하는 메타데이터는 암호해독가능하고, 그리고 또한 메타데이터 세트는 스토리지 실패들로부터 완전한 복원을 갖도록 복구가능하다. 만약 메타데이터 파일들의 수가 t보다 작다면, 메타데이터 파일은 훼손된 다. 청크 ID에 근거하여 리스트 내에 나타나는 데이터/키 샤드들을 카운트함. 만약 세트 내의 샤드들의 수 가 n이라면, 각각의 청크, 메타데이터, 및 암호화 키는 n-t 스토리지 실패들을 허용하는데, 이것은 주어진 파라 미터 t 및 n의 최대 허용오차(tolerance)이다. 만약 샤드들의 수가 n보다 작고 t보다 크거나 같다면, 청크는 디 코딩가능하고, 그리고 또한 세트는 스토리지 실패들로부터 완전한 복원을 갖도록 복구가능하다. 만약 샤드들의 수가 t보다 작다면, 청크는 훼손된다. 비록 이러한 프로세가 파일들과 청크들 간의 맵(map)을 찾기 위해 메타데 이터 파일 콘텐츠를 판독하지 않기 때문에 어떤 파일이 훼손되는지를 식별할 수는 없어도, 전체 무결성 및 데이 터 저장 상태가 스토리지들에 대한 더 적은 리스트 오브젝트들 동작들로 계산된다. 이러한 프로세스는 각각의 클라이언트 디바이스에서 실행될 수 있고, 그리고 또한 제어 서버와 같은 다른 중앙집중화된 엔티티(entity)들 로부터 실행될 수 있다."}
{"patent_id": "10-2022-7034024", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "요약하면, 본 발명은 신규성 및 고유성의 많은 영역들을 포함한다. 이들 중 일부는 다음과 같은 것을 포함한다. 파일 및 메타데이터/키 암호화 체인들; 파일 인코딩과 메타데이터/키 인코딩의 통합을 제공하기 위해서 RS 코드 및 SSSS를 파일의 암호화된 청크들 및 청크 식별자/키 콘텐츠들에 적용함. 엔드-투-엔드 보안; 파일 시스템 인터페이스와 스토리지 백 엔드들 간의 보안 허점(security hole)들을 막 기 위해 파일 및 메타데이터/키 암호화 체인들을 파일 시스템 동작들에 통합시킴. 시스템 구현; 레이턴시가 긴 네트워크들(예컨대, 인터넷 및 WAN) 및 사용자 경험들을 고려하면서 시스템 컴 포넌트들을 설계 및 구현함. - 클라이언트-중심적 아키텍처는 엔드-투-엔드 데이터 보호 솔루션의 설계 및 구현을 보장함 - 암호화 체인; (t, n) 임계 보유 속성(threshold hold property)을 사용하는 콘텐츠 암호화 및 메타데이터 암 호화 o 스토리지 효율 및 최소 크기의 에러 정정 코드가 콘텐츠 암호화를 위해 바람직함. o 무작위성 및 이론적 암호화방식이 메타데이터 암호화를 위해 요구됨. - AI-보조적 구성 및 비정상 모니터링 및 검출 클라이언트-중심적 아키텍처. 클라이언트의 정의에 근거하여, 본 솔루션의 아키텍처는 클라이언트와 데이터/메 타데이터/키 스토리지들 간의 직접적인 통신을 보장하는 클라이언트-중심적 구현들을 실현하도록 설계된다. 클 라이언트에서의 엔드로부터 스토리지에서의 엔드까지, 클라이언트는 스토리지들의 상이한 타입들에 의해 제공되 는 프로토콜 및 채널들을 사용한다. 다양한 프로토콜들 및 채널들이 코드의 최소 실행 또는 백엔드들 상에서의 제로 수정(zero modification)으로 클라이언트에서 구현된다. 분산된 스토리지 솔루션을 위해 클라이언트-중심적 아키텍처를 구현하는 것은 이것을 서버-측 상에 구현하는 것 보다 더 도전적인 과제인데, 왜냐하면 클라이언트는 서버와 같은 공유된 컴포넌트가 아니기 때문이다. 따라서, 클라이언트는 소실한 샤드 컴포넌트의 제한을 극복하기 위해 효율적으로 동기화를 행하기 위한 프로세스들을 구 현한다. 본 솔루션은 공유된 그리고 중앙집중화된 리소스들에 대해 설계되지 않은 분산된 스토리지들에서 메타 데이터에 직접적으로 액세스하여, 메타데이터를 부분적으로 인코딩하고 하나의 버전을 클라이언트 내에 저장함 으로써 메타데이터 액세스 레이턴시를 포함하는 성능 제한들을 극복하게 된다. 클라이언트를 구현하기 위해서, 네트워크 구비 클라이언트 디바이스는 사용자 데이터 I/O 인터페이스, 데이터 프로세싱 유닛, 하드웨어 스토리지, 동기화 프로세싱 유닛, 및 네트워크 인터페이스를 요구한다. 이러한 예에서, 데이터 I/O 인터페이스는 판독(Read), 기입(Write), 리스트(List), 등과 같은 데이터 I/O 요청들을 수 신한다. 본 솔루션은 데이터 I/O 인터페이스로서 포직스(POSIX) 파일 인터페이스를 구현한다(하지만, 이러한 것으로만 한정되는 것은 아님). 데이터 I/O 인터페이스는 키-값 스토리지, CRUD(Create - Read - Update - Delete; 생성 - 판독 - 업데이트 - 삭제) 인터페이스, 등의 구현일 수 있다. 데이터 프로세싱 유닛은 파일 및 메타데이터/키 암호화 체인을 구현함으로써 데이터를 샤드들로 암호화 및 인코딩한다. 하드웨어 스토리지는 중 간 상태 및 프로세스 중인 데이터를 저장하는데 이들을 스토리지들로 보내기 전에 저장한다. 하드웨어 스토리지 는 액세스 제어로 하여금 비인가된 엔티티가 중간 상태 및 데이터에 액세스하는 것을 막도록 요구한다. 동기화 프로세싱 유닛은 샤드들을 보내고 수신하는 것을 담당한다. 동기화 프로세싱 유닛은 클라이언트 및 스토리지들 의 실증적 성능 및 구성들을 저장하는 지식 베이스에 근거하여 송신/수신 작업들을 스케줄링한다. 동기화 프로 세싱 유닛은 또한 이용가능한 스토리지 노드들 중에서 샤드들의 위치를 결정하는데, 이것은 또한 지식 베이스에 근거하여 결정된다. 동기화 프로세싱 유닛은 사용자로부터의 구성에 근거하여 파라미터들을 최적화하기 위해 AI 엔진들을 실행한다. 동기화 프로세싱 유닛 내에서의 이러한 비동기적 송신 및 수신 작업들은, 데이터를 스토리 지들로 보내기 전에 사용자에게 응답함으로써, 뿐만 아니라 장래에 스케줄링 알고리즘들을 확장시키기 위한 유 연성을 제공함으로써, 지연을 흡수한다. 이러한 솔루션은 데이터 스토리지들의 세 가지 타입들을 정의하는데, 데이터 스토리지, 메타데이터/키 스토리지, 및 메타데이터/키 백업 스토리지를 정의한다. 스토리지들은 클라이언트에게 인증 및 데이터 I/O 인터 페이스들을 제공한다. 데이터 스토리지들은 비용 효율적이고 확장가능한 솔루션을 요구하는 반면, 메타데이터 및 키 스토리지들은 빠른 액세스 시간을 요구한다. 메타데이터/키 백업 스토리지의 요건들은 메타데이터/키 스 토리지와 동일하지만 사용자 도메인(user domain) 내에 위치한다. 제어 서버는 백엔드 스토리지들을 구성하고, 사용자들/디바이스들/정책들을 관리하고, 그리고 클라이언트들에게 커맨드들을 보내기 위한 포털이다. 제어 서버는 중간에 사용자 데이터를 인터셉트하는 것을 막기 위해 데이터 전송 채널들로부터 완전히 분리된다. 제어 서버는 클라이언트들이 요구된 파라미터들, 요청들의 리디렉션 (redirection)들, 등을 획득함으로써 프로세스를 개시시킬 수 있도록 클라이언트들에게 구성들을 배치한다. 구성을 위한 인공 지능. 백엔드 인터페이스들의 복잡성 및 서비스들의 다양성으로 인해, 만족을 최대화하면서 예산(budget)에 근거하여 최적의 설정을 구성하는 것은 도전적인 과제이다. 본 발명은 백엔드 구성을 위한 시간 및 노력을 감소시키기 위해 구성 계층의 추상화를 제공한다. 본 발명은, 백엔드 스토리지들의 비용 및 성능에 대한 실증적 데이터, 그리고 사용자의 행동 프로파일(behavioral profile)에 근거하여, 동작 비용을 최적화하는 것, 성능을 최적화하는 것, 그리고 비정상을 모니터링 및 검출하는 것을 목표로 한다. 클라이언트는 이벤트 데 이터를 수집하고 익명화(anonymization), 리포맷팅(reformatting), 등과 같은 프리-프로세싱(pre- processing)을 수행한다. 이벤트 데이터를 수집한 후에, 클라이언트는 이벤트 데이터를 데이터 수집 서버로 보 낸다. 동작 비용을 감소시키기 위해 구성을 최적화하는 것은, 데이터 저장/액세스 비용, 실증적 스토리지 성능, 피어 그룹(peer group)의 사용 프로파일(usage profile), 미리-정의된 정적 모델, 등에 근거하여, 샤드들을 최적의 백엔드 스토리지들에 분산시킴으로써, 백엔드 스토리지 구성의 복잡성을 극복하고 동작들의 비용을 감소시킨다. 본 솔루션은 또한 응답을 향상시키기 위해, 구현된 아키텍처의 혜택들을 활용한다. 본 솔루션은 데이터 액세스 및 저장의 레이턴시를 감소시키면서 백엔드 스토리지의 복잡성을 극복한다. 동작 비용을 최적화하는 것과는 달 리, 더 많은 샤드들을 빠른 스토리지들에 분산시키는 것이 스토리지 비용보다 더 높은 우선권을 가져야 한다. 이러한 두 가지 경우들에 추가하여, 시스템은 예를 들어, 간단한 가중합 방정식(weighted sum equation)을 사용 함으로써 비용 최적조건과 성능 최적조건 간의 균형잡힌 설정을 달성하도록 구성될 수 있다. 본 발명에서, 행동 분석을 위한 AI 알고리즘들은 시스템 내에서 비정상을 검출하기 위해 사용자 데이터를 조사 하지 않는다. 알고리즘들은 알려지지 않은 공격들을 검출하기 위해 널리 사용되지만, 허위-양성 에러(false- positive error)들을 감소시키기 위해 정상 상태를 올바르게 정의할 필요가 있다. 비정상들을 찾기 위해 행동 분석 알고리즘이 사용된다. 엄격하게 맞춰진 모델(tightly-fitted model)은 낮은 정밀도 비율(precision rat e)을 보여주지만 느슨하게 맞춰진 모델(loosely fitted model)은 낮은 재현 비율(recall rate)을 보여준다. 클 라이언트들로부터의 수집된 데이터에 근거하여, 시스템은 정상과 비정상 상태들 간의 분류기(classifier)를 적 응적으로 업데이트한다. 본 발명은 개개의 사용자들 및 사용자 그룹들로부터의 데이터 액세스 패턴들의 특징들 을 활용한다. 다음의 것들은 본 발명이 최적화하는 파라미터들이다. - 최적화 1: 데이터 저장 비용 및 데이터 액세스 비용을 최소화하는 샤드 저장의 표시자 변수(indicator variable) - 최적화 2: 데이터 업로드/다운로드 완료 시간을 최소화하는 샤드 저장의 표시자 변수 - 최적화 3: 최적화 1 또는 최적화 2를 배치할 때 샤드 재할당을 최소화하는 비용 - 최적화 4: 시간 경과에 따른 정상 및 비정상 데이터 액세스를 결정하는 분류기 - 최적화 5: 시간 경과에 따른 정상 및 비정상 스토리지 액세스를 결정하는 분류기 - 최적화 6: 클라이언트로부터 정상 및 비정상 에러들을 결정하는 분류기 이러한 최적화들을 달성하기 위해, 본 발명은 다음과 같은 것들을 수집할 것이다. - 백엔드 스토리지들의 비용 및 (정량적) 서비스 레벨 협약(Service Level Agreement, SLA) - 각각의 클라이언트에서 백엔드 스토리지의 실증적 처리량(throughput) - 파일 콘텐츠 동작들의 타임스탬프(timestamp) - 동작 이름 - 샤드 액세스 카운트 - 익명화된 파일 식별자 - 익명화된 클라이언트 식별자 비록 본 발명의 일부 공통적인 애플리케이션들이 위에서 설명되지만, 본 발명이 보안, 고장 허용범위(fault tolerance), 익명성(anonymity), 또는 앞서 말한 것의 임의의 적절한 조합, 또는 다른 관련된 속성들을 증가시 키기 위해서 임의의 네트워크 애플리케이션과 통합될 수 있음이 명확히 이해돼야 한다. 추가적으로, 다른 조합 들, 추가들, 대체들, 및 수정들은 본 명세서에서의 개시내용에 비취어 숙련된 기술자에게는 명백할 것이다. 따 라서, 본 발명은 바람직한 실시예들의 반응에 의해 제한되도록 의도된 것이 아니다. 비록 앞서의 발명이 명확성의 목적들로 일부 상세히 설명되었지만, 특정 변경들 및 수정들이 본 발명의 원리들 로부터 벗어남이 없이 행해질 수 있음은 명백할 것이다. 본 발명의 프로세스들 및 장치들 모두를 구현하는 많은 대안적 방식들이 존재함에 유의해야 한다. 따라서, 본 실시예들은 예시적인 것으로서 고려돼야 하고 제한적인 것으로서 고려돼서는 안 되며, 본 발명은 본 명세서에서 주어지는 특정 세부사항들로만 한정되는 것이 아니다. 본 명세서에서 설명되는 실시형태들은 시스템, 방법, 또는 컴퓨터 판독가능 매체로서 구현될 수 있다. 일부 실 시예들에서, 설명되는 실시형태들은 하드웨어, (펌웨어 등을 포함하는) 소프트웨어, 또는 이들의 조합들로 구현될 수 있다. 일부 실시형태들은 프로세서에 의한 실행을 위한 컴퓨터 판독가능 명령들을 포함하는 컴퓨터 판독 가능 매체로 구현될 수 있다. 하나 이상의 컴퓨터 판독가능 매체(들)의 임의의 조합이 사용될 수 있다. 컴퓨터 판독가능 매체는 컴퓨터 판독가능 신호 매체 및/또는 컴퓨터 판독가능 스토리지 매체를 포함할 수 있다. 컴퓨터 판독가능 스토리지 매체는, 입력 데이터에 관해 동작함으로써 그리고 출력을 생성시킴으로써 본 명세서에서 설 명되는 기능들을 수행하기 위해 프로그래밍가능 프로세서에 의한 사용을 위한 컴퓨터 프로그램을 저장할 수 있 는 임의의 유형의 매체를 포함할 수 있다. 컴퓨터 프로그램은 특정 기능을 수행하기 위해 또는 특정 결과를 결 정하기 위해 컴퓨터 시스템 내에서 직접적으로 또는 간접적으로 사용될 수 있는 명령들의 세트이다. 일부 실시예들은 클라우드-컴퓨팅 기반구조를 통해 최종-사용자에게 제공될 수 있다. 클라우드 컴퓨팅은 일반적 으로, 확장가능한 컴퓨팅 리소스들을 네트워크(예를 들어, 인터넷 등)를 통해 서비스로서 제공하는 것을 포함한 다. 비록 본 명세서에서 많은 방법들 및 시스템들이 설명되지만, 단일의 시스템 또는 방법이 위에서 논의된 주 된 내용 중 하나보다 많은 것을 포함할 수 있음이 고려된다. 따라서, 앞서의 시스템들 및 방법들 중 다수는 단 일 시스템 또는 방법에서 함께 사용될 수 있다. 본 출원에서 개시되는 예들은 모든 측면들에 있어 예시적인 것이며, 이에 제한되어서는 안 된다는 것을 고려해 야 한다. 본 발명의 범위는 앞서의 설명에 의해서가 아니라 첨부되는 청구항들에 의해 나타내어지며, 청구항들 의 등가의 의미 및 범위 내에 있는 모든 변경들이 여기에 포함되도록 의도된다. 도면들에서의 흐름도들 및/또는 블록도들은, 본 발명적 개념의 다양한 예시적 실시예들에 따른 시스템들, 방법 들, 및 컴퓨터 프로그램 제품들의 가능한 구현들의 아키텍처, 기능 및 동작을 예시한다. 이와 관련하여, 흐름도 또는 블록도들 내의 각각의 블록은, 특정된 논리적 기능(들)을 구현하기 위한 하나 이상의 실행가능한 명령들을 포함하는 명령들의 모듈, 세그먼트, 또는 부분을 나타낼 수 있다. 대안적 구현예들에서, 블록 내에 표시된 기능 들은 도면들에서 표시된 순서를 벗어나 일어날 수 있다. 예를 들어, 연속으로 보여지는 두 개의 블록들은, 관련 된 기능에 따라, 실제로는 실질적으로 동시에 실행될 수 있고, 또는 블록들은 때때로 역순으로 실행될 수 있다. 블록도들 및/또는 흐름도 예시의 각각의 블록, 그리고 블록도들 및/또는 흐름도 예시 내의 블록들의 조합들은, 특정된 기능들을 수행하는 또는 특수 목적 하드웨어와 컴퓨터 명령들의 조합들을 수행하거나 실행하는 특수 목 적 하드웨어-기반 시스템들에 의해 구현될 수 있음에 또한 유의해야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2022-7034024", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 추론 및 이벤트 검출을 나타낸다(특히 추론 및 이벤트 검출을 보여줌). 도 2는 본 발명의 이벤트 로그 수집 및 훈련을 나타낸다. 도 3은 본 발명의 파일 및 메타데이터/키 암호화 체인들을 나타낸다. 도 4는 시스템 컴포넌트들, 상호작용들, 및 프로세스 단계들을 나타낸다. 도 5는 본 발명에서 데이터 경로 제어 경로들이 어떻게 분리되는지를 나타낸다. 도 6은 본 발명의 파일 저장의 단계별 절차를 나타낸다. 도 7은 소실된 클라이언트를 블랙리스트화(blacklist)하는 것 및 새로운 클라이언트를 구성하는 것을 나타낸다. 도 8은 데이터 스토리지 실패가 있는 파일 저장의 절차를 나타낸다. 도 9는 메타데이터/키 스토리지 실패가 있는 파일 저장의 절차를 나타낸다. 도 10은 본 발명의 \"복제된\" 데이터 및 \"암호화된\" 데이터의 메타데이터 인코딩을 나타낸다. 도 11은 파일 암호화 및 메타데이터 암호화의 예를 나타낸다."}
