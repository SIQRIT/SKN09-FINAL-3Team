{"patent_id": "10-2021-0105681", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0023505", "출원번호": "10-2021-0105681", "발명의 명칭": "음성 언어 이해 모델 생성 방법 및 장치", "출원인": "주식회사 케이티", "발명자": "성우경"}}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서에 의해 동작하는 인공지능 보이스봇의 음성 언어 이해 모델 생성 방법으로서,기 생성된 음성 언어 이해 모델을 이용하여 복수의 음성 데이터로부터 도출된 복수의 의도 추론 결과를 상기 복수의 음성 데이터와 매칭하여 저장하는 단계,사용자 입력에 의해 복수개의 클래스 중 하나의 클래스로 라벨링된 상기 복수의 의도 추론 결과를 학습 데이터로 사용하여, 입력받은 의도 추론 결과를 복수의 클래스 단위로 분류하는 음성 데이터 분류 모델을 생성하는 단계,상기 저장한 복수의 음성 데이터에 매칭된 복수의 의도 추론 결과를 상기 음성 데이터 분류 모델에 입력하여 복수의 클래스로 분류하는 단계, 분류된 복수의 클래스 중에서 타겟 클래스에 해당하는 의도 추론 결과에 매칭되는 타겟 음성 데이터들을 상기저장한 복수의 음성 데이터로부터 선별하는 단계, 그리고상기 선별한 타겟 음성 데이터들을 이용하여 상기 타겟 클래스의 의도 추론 성능이 갱신된 음성 언어 모델을 생성하는 단계를 포함하는, 음성 언어 이해 모델 생성 방법."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 갱신된 음성 언어 모델을 생성하는 단계는,상기 저장한 복수의 음성 데이터를 학습 데이터로 사용한 비지도 학습을 수행하고, 비지도 학습시 상기 타겟 음성 데이터들에 대해서는 상기 기 생성된 음성 언어 이해 모델을 이용한 디스턴스(Distance) 기반 비지도 학습을수행하는 음성 언어 이해 모델 생성 방법."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에서,상기 갱신된 음성 언어 모델을 생성하는 단계는,거리 함수를 이용하여, 상기 갱신된 음성 언어 이해 모델의 위치 인코딩 계층(positional encoding layer)이 출력하는 상기 타겟 음성 데이터들의 제1 언어 표현 데이터와 상기 기 생성된 음성 언어 이해 모델의 위치 인코딩계층이 출력하는 상기 타겟 음성 데이터의 제2 언어 표현 데이터 간의 거리를 계산하는 단계, 상기 계산된 거리가 임계값을 초과하는 상기 제1 언어 표현 데이터를 상기 제2 언어 표현 데이터를 이용하여 마스킹하는 단계, 그리고마스킹한 언어 표현 데이터로 상기 갱신된 음성 언어 이해 모델의 추출(Extraction) 계층을 비지도 학습 방식으로 학습시키는 단계를 포함하고,상기 추출 계층은,언어 표현 데이터로부터 의도를 추론하는 계층인 음성 언어 이해 모델 생성 방법."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에서, 상기 저장하는 단계와 상기 음성 데이터 분류 모델을 생성하는 단계 사이에,공개특허 10-2023-0023505-3-상기 복수의 의도 추론 결과를 정형화한 데이터인 복수의 문맥 불확실성 맵(Contextual Uncertainty Map, CUM)을 생성하는 단계를 더 포함하고,상기 음성 데이터 분류 모델은,상기 복수의 문맥 불확실성 맵을 학습 데이터로 사용하며, 상기 복수의 문맥 불확실성 맵은, 상기 복수의 음성 데이터로부터 상기 기 생성한 음성 언어 이해 모델의 불확실한 정도를 나타내는 정보인, 음성언어 이해 모델 생성 방법."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에서, 상기 문맥 불확실성 맵을 생성하는 단계 이후,음성 데이터의 파일명과 상기 문맥 불확실성 맵을 매칭하여 저장하고, 상기 저장한 문맥 불확실성 맵으로부터,상기 복수의 음성 데이터 중에서 특정 클래스로 라벨링된 음성 데이터들에 대응하는 문맥 불확실성 맵들을 추출하는 단계를 더 포함하는 음성 언어 이해 모델 생성 방법."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에서, 상기 문맥 불확실성 맵을 생성하는 단계는,멜-필터 뱅크(mel-filterbank)를 이용하여 상기 복수의 음성 데이터의 특징 벡터를 추출하는 단계,기 생성한 음성 언어 이해 모델을 이용하여 상기 추출한 특징 벡터에 대응하는 확실한 언어 표현(certainlanguage representation)을 추출하는 단계,모델의 불확실성 확률 변수를 나타내는 베르누이 분포 파라미터를 이용하여 마스킹한 음성 언어 이해 모델을 이용하여, 상기 추출한 특징 벡터에 대응하는 불확실한 언어 표현(Uncertain language representation)을 추출하는 단계,상기 확실한 언어 표현과 상기 불확실한 언어 표현으로부터 공통의 문맥 정보를 포함하는 컨텍스트 가중치를 생성하는 단계, 그리고상기 컨텍스트 가중치와 상기 불확실한 언어 표현을 이용하여 상기 문맥 불확실성 맵을 생성하는 단계를 포함하는 음성 언어 이해 모델 생성 방법."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에서,상기 음성 데이터 분류 모델을 생성하는 단계 이전에,복수개의 클래스로 분류된 복수의 음성 데이터에 대응하는 문맥 불확실성 맵들을 훈련 셋과 평가 셋으로 구분하고, 상기 훈련 셋과 상기 평가 셋에 대한 각각의 특징 벡터들 간의 거리를 연산하여, 가장 작은 거리를 가지는클래스로 분류하도록 사전 학습된 기본 음성 데이터 분류 모델을 생성하는 단계를 더 포함하고,상기 음성 데이터 분류 모델을 생성하는 단계는,상기 사전 학습된 기본 음성 모델을 베이스 모델로 사용하는 음성 언어 이해 모델 생성 방법."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에서,상기 저장하는 단계 이전에,공개특허 10-2023-0023505-4-복수의 계층 구조로 이루어지고, 음성 데이터로부터 의도를 추론하는 기본 음성 언어 이해 모델을 생성하는 단계를 더 포함하고,상기 복수의 계층 구조는,입력 음성 데이터의 특징 벡터로부터 음성 표현 데이터를 추출하기 위한 선형 레이어 및 컨포머 레이어, 상기 음성 표현 데이터를 복수개의 언어 토큰들의 분포값을 갖는 벡터로 출력하는 프로젝션 레이어,상기 분포값이 가장 큰 값을 가지는 언어 토큰들에 대한 위치 정보가 포함된 임베딩 벡터로 출력하는 임베딩 레이어 및 위치 인코딩 레이어,상기 임베딩 벡터로부터 언어 표현 데이터를 추출하기 위한 트랜스포머 레이어, 그리고상기 언어 표현 데이터로부터 의도를 추론하는 추출 레이어를 포함하고,상기 기본 음성 언어 이해 모델을 생성하는 단계는,상기 추출 레이어가 추론한 결과와 사전에 입력된 상기 언어 표현 데이터의 정답 추론 결과 간의 손실을 학습하는 음성 언어 이해 모델 생성 방법."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "음성 데이터로부터 의도를 추론하는 기본 음성 언어 이해 모델을 생성하는 음성 언어 이해 모델 생성부,상기 기본 음성 언어 이해 모델을 이용하여 복수의 음성 데이터로부터 도출된 복수의 의도 추론 결과를 상기 복수의 음성 데이터와 매칭하여 저장하는 서비스 데이터 DB, 그리고사용자 입력에 의해 복수개의 클래스 중 하나의 클래스로 라벨링된 상기 복수의 의도 추론 결과를 학습 데이터로 사용하여, 입력받은 의도 추론 결과를 복수의 클래스 단위로 분류하는 음성 데이터 분류 모델을 생성하고,상기 저장한 복수의 음성 데이터에 매칭된 복수의 의도 추론 결과를 상기 음성 데이터 분류 모델에 입력하여 복수의 클래스로 분류하며, 분류된 복수의 클래스 중에서 타겟 클래스에 해당하는 의도 추론 결과에 매칭되는 타겟 음성 데이터들을 상기 저장한 복수의 음성 데이터로부터 선별하고, 상기 선별한 타겟 음성 데이터들을 이용하여 상기 타겟 클래스의 의도 추론 성능이 업데이트된 갱신된 음성 언어 모델을 생성하는 음성 언어 이해 모델갱신부를 포함하는 음성 언어 이해 모델 생성 장치."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에서,상기 음성 언어 이해 모델 갱신부는,퓨샷 러닝(few shot learning) 기술을 이용하여, 상기 서비스 데이터 DB에 저장된 의도 추론 결과의 정형화된데이터인 문맥 불확실성 맵(Contextual Uncertainty Map, CUM)을 학습시켜 상기 음성 데이터 분류 모델을 생성하는 음성 언어 이해 모델 생성 장치."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에서,상기 음성 언어 이해 모델 갱신부는,상기 기본 음성 언어 이해 모델을 이용하여 상기 복수의 음성 데이터의 특징 벡터에 대응하는 확실한 언어 표현(certain language representation)을 추출하고, 베르누이 분포 파라미터를 이용하여 마스킹한 상기 기본 음성언어 이해 모델을 이용하여, 상기 특징 벡터에 대응하는 불확실한 언어 표현(Uncertain languagerepresentation)을 추출하고, 상기 확실한 언어 표현과 상기 불확실한 언어 표현으로부터 공통의 문맥 정보를 포함하는 상기 문맥 불확실성맵을 생성하는, 음성 언어 이해 모델 생성 장치."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2023-0023505-5-제9항에서,상기 음성 언어 이해 모델 갱신부는,상기 복수의 음성 데이터를 학습 데이터로 사용하여 비지도 학습을 수행하고, 외부에서 입력된 의도 추론 결과가 라벨링된 음성 데이터와 비지도 학습 결과를 이용한 지도 학습을 통해 상기 갱신된 음성 언어 이해 모델을생성하는 음성 언어 이해 모델 생성 장치."}
{"patent_id": "10-2021-0105681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에서,상기 음성 언어 이해 모델 갱신부는,상기 비지도 학습을 수행할 때, 상기 타겟 음성 데이터들을 상기 기본 음성 언어 이해 모델에 입력하여 추출된언어 표현 데이터를 마스킹 데이터로 사용하여 거리 함수 기반의 비지도 학습을 수행하는 음성 언어 이해 모델생성 장치."}
{"patent_id": "10-2021-0105681", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "음성 언어 이해 모델 생성 방법 및 장치가 개시된다. 그 방법은 적어도 하나의 프로세서에 의해 동작하는 인공지 능 보이스봇의 음성 언어 이해 모델 생성 방법으로서, 기 생성된 음성 언어 이해 모델을 이용하여 복수의 음성 데이터로부터 도출된 복수의 의도 추론 결과 데이터를 상기 복수의 음성 데이터와 매칭하여 저장하는 단계, 입력 (뒷면에 계속)"}
{"patent_id": "10-2021-0105681", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성 언어 이해 모델 생성 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2021-0105681", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(Artificial Intelligence, AI) 보이스봇(Voicebot)은 음성을 사용하여 인간과 상호 작용하는 로봇으 로서, 인간의 음성을 인식하여 의도를 파악하고 의도에 적합한 서비스를 구현하거나 음성으로 서비스를 제공한 다. 종래에 AI 보이스봇은 크게 음성 인식 모듈, QA(Question Answering) 기능 및 TA(Text Analysis) 기능이 포함 된 자연어 처리 모듈 및 음성 합성 모듈로 구성된다. 사용자가 음성 기반으로 문의를 하면, 음성 인식 모듈은 사용자의 음성을 텍스트로 변환하고, 자연어 처리 모듈은 변환된 질의 문장 텍스트를 의도 분석을 통해 의도와 개체를 추출하여 알맞은 응답 문장을 생성하며, 음성 합성 모듈은 생성된 응답 문장을 음성 합성을 통해 다시 음성으로 출력한다. 그런데, AI 보이스봇을 이용하는 고객의 컴플레인 대부분은 문의한 내용에 대해 제대로 된 답변을 못 듣는 것이다. 즉, 응답 문장에 대해 만족하지 못하는 경우가 많다. 따라서, 시스템 관리자는 주기적으로 음성 인식 모듈 이 사용하는 STT(Speech-to-Text) 모델과 자연어 처리 모듈이 사용하는 NLU(Natural Language Understanding) 모델을 업데이트하여 사용자의 만족도를 개선하고자 한다. STT 모델 및 NLU 모델을 업데이트하는 방법은 비지도 재학습 방법과 지도 재학습 방법이 있다. 비지도 재학습의 경우는 성능 향상에 한계가 있기 때문에, 주로 지도 재학습을 수행한다. 그러나, 지도 재학습의 경우 정답지를 사람이 직접 만들어야 주어야 하기 때문에, 많은 인력과 비용, 시간이 필 요하다. 이러한 비용과 시간을 줄이기 위해 특정 기준에 맞게 선별한 데이터를 재학습에 이용하는데, 이를 위해 서 인력을 투입하게 된다. 예를 들어, NLU 모델의 경우, 1) 부정적 피드백을 받은 질의, 2) 재질의를 통해 사용 자가 최종적으로 선택한 답변, 3) 모델 확률 임계치 이상인 질의를 발췌하기 위해 인력을 투입한다. STT 모델의 경우, 1) 의도분석 실패한 음성, 2) 모델 확률 임계치 이상인 음성을 수집하기 위해 인력을 투입한다. 이와 같이, 기존 시스템에서는 NLU 모델과 STT 모델을 독립적으로 재학습 해야 되기 때문에, 재학습에 필요한 데이터 선별 비용이 2배 이상 발생한다."}
{"patent_id": "10-2021-0105681", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "해결하고자 하는 과제는 사용자의 음성 데이터를 텍스트로 변환하는 STT 모델과 텍스트로부터 의도를 추론하기 위한 NLU 모델을 하나로 통합하여 음성 데이터로부터 의도를 추론하기 위한 언어 대화(Spoken LanguageUnderstanding, 이하, 'SLU'라 통칭함) 모델을 생성하는 방법 및 그 장치를 제공하는 것이다. 해결하고자 하는 과제는 특정 의도 클래스에 해당하는 음성 데이터들을 학습 데이터로 사용하여 비지도 (unsupervised) 학습과 지도(supervised) 학습을 결합한 학습 과정을 통해 특정 의도 클래스의 추론에 최적화된 SLU 모델을 생성하는 방법 및 그 장치를 제공하는 것이다."}
{"patent_id": "10-2021-0105681", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "한 특징에 따르면, 적어도 하나의 프로세서에 의해 동작하는 인공지능 보이스봇의 음성 언어 이해 모델 생성 방 법으로서, 기 생성된 음성 언어 이해 모델을 이용하여 복수의 음성 데이터로부터 도출된 복수의 의도 추론 결과 를 상기 복수의 음성 데이터와 매칭하여 저장하는 단계, 사용자 입력에 의해 복수개의 클래스 중 하나의 클래스 로 라벨링된 상기 복수의 의도 추론 결과를 학습 데이터로 사용하여, 입력받은 의도 추론 결과를 복수의 클래스 단위로 분류하는 음성 데이터 분류 모델을 생성하는 단계, 상기 저장한 복수의 음성 데이터에 매칭된 복수의 의 도 추론 결과를 상기 음성 데이터 분류 모델에 입력하여 복수의 클래스로 분류하는 단계, 분류된 복수의 클래스 중에서 타겟 클래스에 해당하는 의도 추론 결과에 매칭되는 타겟 음성 데이터들을 상기 저장한 복수의 음성 데 이터로부터 선별하는 단계, 그리고 상기 선별한 타겟 음성 데이터들을 이용하여 상기 타겟 클래스의 의도 추론 성능이 갱신된 음성 언어 모델을 생 성하는 단계를 포함한다. 상기 갱신된 음성 언어 모델을 생성하는 단계는, 상기 저장한 복수의 음성 데이터를 학습 데이터로 사용한 비지 도 학습을 수행하고, 비지도 학습시 상기 타겟 음성 데이터들에 대해서는 상기 기 생성된 음성 언어 이해 모델 을 이용한 디스턴스(Distance) 기반 비지도 학습을 수행할 수 있다. 상기 갱신된 음성 언어 모델을 생성하는 단계는, 거리 함수를 이용하여, 상기 갱신된 음성 언어 이해 모델의 위 치 인코딩 계층(positional encoding layer)이 출력하는 상기 타겟 음성 데이터들의 제1 언어 표현 데이터와 상 기 기 생성된 음성 언어 이해 모델의 위치 인코딩 계층이 출력하는 상기 타겟 음성 데이터의 제2 언어 표현 데 이터 간의 거리를 계산하는 단계, 상기 계산된 거리가 임계값을 초과하는 상기 제1 언어 표현 데이터를 상기 제 2 언어 표현 데이터를 이용하여 마스킹하는 단계, 그리고 마스킹한 언어 표현 데이터로 상기 갱신된 음성 언어 이해 모델의 추출(Extraction) 계층을 비지도 학습 방식으로 학습시키는 단계를 포함하고, 상기 추출 계층은, 언어 표현 데이터로부터 의도를 추론하는 계층일 수 있다. 상기 저장하는 단계와 상기 음성 데이터 분류 모델을 생성하는 단계 사이에,상기 복수의 의도 추론 결과를 정형 화한 데이터인 복수의 문맥 불확실성 맵(Contextual Uncertainty Map, CUM)을 생성하는 단계를 더 포함하고, 상 기 음성 데이터 분류 모델은, 상기 복수의 문맥 불확실성 맵을 학습 데이터로 사용하며, 상기 복수의 문맥 불확 실성 맵은, 상기 복수의 음성 데이터로부터 상기 기 생성한 음성 언어 이해 모델의 불확실한 정도를 나타내는 정보일 수 있다. 상기 문맥 불확실성 맵을 생성하는 단계 이후, 음성 데이터의 파일명과 상기 문맥 불확실성 맵을 매칭하여 저장 하고, 상기 저장한 문맥 불확실성 맵으로부터, 상기 복수의 음성 데이터 중에서 특정 클래스로 라벨링된 음성 데이터들에 대응하는 문맥 불확실성 맵들을 추출하는 단계를 더 포함할 수 있다. 상기 문맥 불확실성 맵을 생성하는 단계는, 멜-필터 뱅크(mel-filterbank)를 이용하여 상기 복수의 음성 데이터 의 특징 벡터를 추출하는 단계, 기 생성한 음성 언어 이해 모델을 이용하여 상기 추출한 특징 벡터에 대응하는 확실한 언어 표현(certain language representation)을 추출하는 단계, 모델의 불확실성 확률 변수를 나타내는 베르누이 분포 파라미터를 이용하여 마스킹한 음성 언어 이해 모델을 이용하여, 상기 추출한 특징 벡터에 대응 하는 불확실한 언어 표현(Uncertain language representation)을 추출하는 단계, 상기 확실한 언어 표현과 상 기 불확실한 언어 표현으로부터 공통의 문맥 정보를 포함하는 컨텍스트 가중치를 생성하는 단계, 그리고 상기 컨텍스트 가중치와 상기 불확실한 언어 표현을 이용하여 상기 문맥 불확실성 맵을 생성하는 단계를 포함할 수 있다. 상기 음성 데이터 분류 모델을 생성하는 단계 이전에, 복수개의 클래스로 분류된 복수의 음성 데이터에 대응하 는 문맥 불확실성 맵들을 훈련 셋과 평가 셋으로 구분하고, 상기 훈련 셋과 상기 평가 셋에 대한 각각의 특징 벡터들 간의 거리를 연산하여, 가장 작은 거리를 가지는 클래스로 분류하도록 사전 학습된 기본 음성 데이터 분 류 모델을 생성하는 단계를 더 포함하고, 상기 음성 데이터 분류 모델을 생성하는 단계는, 상기 사전 학습된 기 본 음성 모델을 베이스 모델로 사용할 수 있다.상기 저장하는 단계 이전에, 복수의 계층 구조로 이루어지고, 음성 데이터로부터 의도를 추론하는 기본 음성 언 어 이해 모델을 생성하는 단계를 더 포함하고, 상기 복수의 계층 구조는, 입력 음성 데이터의 특징 벡터로부터 음성 표현 데이터를 추출하기 위한 선형 레이어 및 컨포머 레이어, 상기 음성 표현 데이터를 복수개의 언어 토 큰들의 분포값을 갖는 벡터로 출력하는 프로젝션 레이어, 상기 분포값이 가장 큰 값을 가지는 언어 토큰들에 대 한 위치 정보가 포함된 임베딩 벡터로 출력하는 임베딩 레이어 및 위치 인코딩 레이어, 상기 임베딩 벡터로부터 언어 표현 데이터를 추출하기 위한 트랜스포머 레이어, 그리고 상기 언어 표현 데이터로부터 의도를 추론하는 추출 레이어를 포함하고, 상기 기본 음성 언어 이해 모델을 생성하는 단계는, 상기 추출 레이어가 추론한 결과 와 사전에 입력된 상기 언어 표현 데이터의 정답 추론 결과 간의 손실을 학습할 수 있다. 다른 특징에 따르면, 음성 언어 이해 모델 생성 장치는 음성 데이터로부터 의도를 추론하는 기본 음성 언어 이 해 모델을 생성하는 음성 언어 이해 모델 생성부, 상기 기본 음성 언어 이해 모델을 이용하여 복수의 음성 데이 터로부터 도출된 복수의 의도 추론 결과를 상기 복수의 음성 데이터와 매칭하여 저장하는 서비스 데이터 DB, 그 리고 사용자 입력에 의해 복수개의 클래스 중 하나의 클래스로 라벨링된 상기 복수의 의도 추론 결과를 학습 데 이터로 사용하여, 입력받은 의도 추론 결과를 복수의 클래스 단위로 분류하는 음성 데이터 분류 모델을 생성하 고, 상기 저장한 복수의 음성 데이터에 매칭된 복수의 의도 추론 결과를 상기 음성 데이터 분류 모델에 입력하 여 복수의 클래스로 분류하며, 분류된 복수의 클래스 중에서 타겟 클래스에 해당하는 의도 추론 결과에 매칭되 는 타겟 음성 데이터들을 상기 저장한 복수의 음성 데이터로부터 선별하고, 상기 선별한 타겟 음성 데이터들을 이용하여 상기 타겟 클래스의 의도 추론 성능이 갱신된 음성 언어 모델을 생성하는 음성 언어 이해 모델 갱신부 를 포함한다. 상기 음성 언어 이해 모델 갱신부는, 퓨샷 러닝(few shot learning) 기술을 이용하여, 상기 서비스 데이터 DB에 저장된 의도 추론 결과의 정형화된 데이터인 문맥 불확실성 맵(Contextual Uncertainty Map, CUM)을 학습시켜 상기 음성 데이터 분류 모델을 생성할 수 있다. 상기 음성 언어 이해 모델 갱신부는, 상기 기본 음성 언어 이해 모델을 이용하여 상기 복수의 음성 데이터의 특 징 벡터에 대응하는 확실한 언어 표현(certain language representation)을 추출하고, 베르누이 분포 파라미터 를 이용하여 마스킹한 상기 기본 음성 언어 이해 모델을 이용하여, 상기 특징 벡터에 대응하는 불확실한 언어 표현(Uncertain language representation)을 추출하고, 상기 확실한 언어 표현과 상기 불확실한 언어 표현으로 부터 공통의 문맥 정보를 포함하는 상기 문맥 불확실성 맵을 생성할 수 있다. 상기 음성 언어 이해 모델 갱신부는, 상기 복수의 음성 데이터를 학습 데이터로 사용하여 비지도 학습을 수행하 고, 외부에서 입력된 의도 추론 결과가 라벨링된 음성 데이터와 비지도 학습 결과를 이용한 지도 학습을 통해 상기 갱신된 음성 언어 이해 모델을 생성할 수 있다. 상기 음성 언어 이해 모델 갱신부는, 상기 비지도 학습을 수행할 때, 상기 타겟 음성 데이터들을 상기 기본 음 성 언어 이해 모델에 입력하여 추출된 언어 표현 데이터를 마스킹 데이터로 사용하여 거리 함수 기반의 비지도 학습을 수행할 수 있다."}
{"patent_id": "10-2021-0105681", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예에 따르면, 데이터 전사량을 최소화하여 갱신이 필요한 학습 데이터에 대한 SLU 모델 성능을 최대화할 수 있다."}
{"patent_id": "10-2021-0105681", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였 다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 \"…부\", \"…기\", \"…모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 본 발명에서 설명하는 장치들은 적어도 하나의 프로세서, 메모리 장치, 통신 장치 등을 포함하는 하드웨어로 구 성되고, 지정된 장소에 하드웨어와 결합되어 실행되는 프로그램이 저장된다. 하드웨어는 본 발명의 방법을 실행 할 수 있는 구성과 성능을 가진다. 프로그램은 도면들을 참고로 설명한 본 발명의 동작 방법을 구현한 명령어 (instructions)를 포함하고, 프로세서와 메모리 장치 등의 하드웨어와 결합하여 본 발명을 실행한다. 본 명세서에서 \"전송 또는 제공\"은 직접적인 전송 또는 제공하는 것 뿐만 아니라 다른 장치를 통해 또는 우회 경로를 이용하여 간접적으로 전송 또는 제공도 포함할 수 있다. 본 명세서에서 단수로 기재된 표현은 \"하나\" 또는 \"단일\" 등의 명시적인 표현을 사용하지 않은 이상, 단수 또는 복수로 해석될 수 있다. 본 명세서에서 도면에 관계없이 동일한 도면번호는 동일한 구성요소를 지칭하며, \"및/또는\" 은 언급된 구성 요 소들의 각각 및 하나 이상의 모든 조합을 포함한다. 본 명세서에서, 제1, 제2 등과 같이 서수를 포함하는 용어들은 다양한 구성요소들을 설명하는데 사용될 수 있지 만, 상기 구성요소들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요 소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 개시의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 본 명세서에서 도면을 참고하여 설명한 흐름도에서, 동작 순서는 변경될 수 있고, 여러 동작들이 병합되거나, 어느 동작이 분할될 수 있고, 특정 동작은 수행되지 않을 수 있다. 도 1은 실시예에 따른 AI(Artificial Intelligence) 보이스봇(Voicebot)의 구성을 도시한다. 도 1을 참조하면, AI 보이스봇은 음성 의도 분석부, 응답 문장 생성부, 음성 합성부, TTS(Text to Speech) 모델 DB, 음성 언어 이해(Spoken Language Understanding, 이하, 'SLU'로 통칭함) 모델 생성부, 서비스 데이터 DB 및 SLU 모델 갱신부를 포함한다. 음성 의도 분석부는 SLU 모델 생성부가 제공하는 기본 SLU 모델을 이용하여, 입력 발화 음성(Tx)으로 부터 의도 결과 및 개체 변수(Text)를 추출한다. 예를 들어, 입력 발화 음성이 '내일 서울 날씨 알려줘'라는 질 의 음성이라면, 음성 의도 분석부는 '일기예보 요청'이라는 의도 결과와, '내일'/'서울'이라는 개체 변수(Text)를 출력한다. 이러한 의도 결과 및 개체 변수(Text)는 응답 문장 생성부로 입력된다. 응답 문장 생성부는 의도 결과 및 개체 변수(Text)에 대응하는 응답 문장을 생성한다. 음성 합성부는 TTS 모델 DB에 저장된 TTS 모델을 이용하여, 응답 문장을 응답 음성(Rx)으로 합성하여 출력한다. SLU 모델은 음성 데이터를 텍스트로 변환하는 STT(Speech-to-Text) 모델과 텍스트로부터 의도를 추론하기 위한 NLU(Natural Language Understanding) 모델이 하나로 통합된 모델이다. SLU 모델 생성부는 입력 및 출력을 고려하여 최적화하는 E2E(End to End) 방식으로 SLU 모델을 생성한다. 이때, SLU 모델은 기본 SLU 모델로 호칭한다. E2E 방식의 SLU 모델은 질의 음성으로부터 의도와 개체를 직접 추론한다. SLU 모델 생성부는 복수의 계층 구조로 이루어진 딥러닝 모델을 음성 데이터로부터 의도를 추론하는 SLU 모델로 학습시킨다. AI 보이스봇이 서비스를 하는 동안, 음성 의도 분석부는 입력 음성에 대한 음성 의도 분석 결과인 서 비스 데이터를 서비스 데이터 DB에 저장한다. 음성 의도 분석부는 기본 SLU 모델을 이용하여 복수의 음성 데이터로부터 도출된 복수의 의도 추론 결과 데이터를 복수의 음성 데이터와 매칭하여 서비스 데이터 DB에 저장할 수 있다. 서비스 데이터 DB는 관계형 데이터베이스로서, 서비스 데이터를 튜플(tuple)로 저장한다. 서비스 데이터는 입력 음성 파일명/음성 데이터, 날짜, 의도 결과, 개체 변수, 모델 신뢰도(confidence score) 값을 포함한다. 여기서, 모델 신뢰도 값은 SLU 모델의 출력값으로서, 출력값은 입력 음성 데이터 별로 그 음성 데이터에 대해 SLU 모델이 추론한 의도/개체 변수의 확률값과 같다. 예컨대, 음성 X가 입력되었을 때 SLU 모델의 출력값 Y는 \"Y= arg maxy SLU(Y|X)\"로 정의할 수 있고, 이 중에 가장 높은 확률값을 갖는 출력 Y가 모델 추론 결과가 되며, 그 확률값을 해당 추론의 모델 신뢰도 값으로 정의할 수 있다. 이와 같이, 음성 의도 분석부가 기본 SLU 모델을 토대로 입력 음성에 대한 의도/개체 변수를 추론한 결과 는 서비스 데이터 DB에 저장된다. VOC(Voice of Customer) 발생 등으로 관리자가 SLU 모델 갱신이 필요하다고 판단한 경우, SLU 모델 갱신부 는 SLU 모델을 갱신하는 동작을 수행한다. 즉, SLU 모델 갱신부는 특정 의도 클래스의 추론 성능이 개선되어야 하는 경우, 특정 의도 클래스에 해당하는 음성 데이터를 학습 데이터로 사용하여 특정 의도 클래스 추론에 최적화된 SLU 모델을 생성한다. 이때, SLU 모델 갱신부는 From Scratch 방식, 즉, 처음부터 다시 SLU 모델을 생성하는 과정을 통해 SLU 모 델을 갱신한다. 즉, 특정 의도 클래스에 해당하는 음성 데이터 뿐만 아니라, 특정 의도 크래스가 아닌 음성 데 이터도 SLU 모델 갱신시 학습 데이터로 사용된다. 즉, SLU 모델 갱신에서 비지도 학습을 할때에는 특정 의도 클 래스에 해당하는 음성 데이터 뿐만 아니라, 특정 의도 클래스가 아닌 음성 데이터를 학습 데이터로 사용하고, 지도 학습을 할때에는 특정 의도 클래스에 해당하는 음성 데이터를 학습 데이터로 사용한다. 따라서, 갱신된 SLU 모델은 기본 SLU 모델과 비교할때, 특정 의도 클래스에 해당하는 음성 데이터의 추론 성능이 개선된 모델이 라 할 수 있다. 음성 의도 분석부는 SLU 모델 갱신부가 제공하는 특정 의도 클래스 추론에 최적화된 SLU 모델을 이용 하여 입력 음성 데이터로부터 의도 결과 및 개체 변수를 추출한다. SLU 모델 갱신부는 서비스 데이터 DB를 참조하여 SLU 모델을 갱신한다. SLU 모델 갱신부는 관리자가 세팅한 업데이트 전략이 반영된 특정 의도 클래스에 최적화된 음성 데이터 분 류 모델을 기반으로 업데이트하고자 하는 음성 데이터를 추출한 후, 이러한 추출 음성 데이터를 이용하여 갱신 된 SLU 모델을 생성한다. SLU 모델 갱신은 크게 비지도 학습과 지도 학습이 결합된 형태로 이루어진다. SLU 모델 갱신부는 서비스 데이터 DB에 저장된 서비스 데이터 중에서 SLU 모델 갱신을 위한 학습 데 이터로 사용할 서비스 데이터를 선별한다. SLU 모델 갱신부는 선별한 학습 데이터를 토대로 비지도 (unsupervised) 학습과 지도(supervised) 학습을 통해 특정 의도 클래스 추론에 최적화된 SLU 모델을 생성한다. 여기서, 비지도 학습을 수행할때, SLU 모델 갱신부는 기 생성된 SLU 모델과 차이가 많이 나는 부분을 중점적으로 학습하는 방식, 즉, 디스턴스(distance) 기반 비지도 학습을 수행한다. 음성 의도 분석부는 SLU 모델 생성부에 의해 기 생성된 기본 SLU 모델을 이용하여 복수의 음성 데이 터로부터 도출된 복수의 의도 추론 결과를 복수의 음성 데이터와 매칭한 서비스 데이터를 서비스 데이터 DB에 저장한다. 사용자 입력에 의해 서비스 데이터 DB에 저장된 복수의 의도 추론 결과는 복수개의 클래스 중 하나의 클래 스로 라벨링이 이루어진다. SLU 모델 갱신부는 이처럼 사용자 입력에 의해 복수개의 클래스 중 하나의 클 래스로 라벨링된 복수의 의도 추론 결과를 학습 데이터로 사용하여 입력받은 의도 추론 결과를 복수의 클래스 단위로 분류하는 음성 데이터 분류 모델을 생성한다. SLU 모델 갱신부는 서비스 데이터 DB에 저장한 복수의 음성 데이터에 매칭된 복수의 의도 추론 결과 를 상기 음성 데이터 분류 모델에 입력하여 복수의 클래스로 분류한다. SLU 모델 갱신부는 분류된 복수의 클래스 중에서 타겟 클래스에 해당하는 의도 추론 결과에 매칭되는 타겟 음성 데이터들을 선별한다. SLU 모델 갱신부는 서비스 데이터 DB에 저장한 복수의 음성 데이터를 학습 데이터로 사용하여 비지도 학습을 수행하는데, 이때, 선별한 타겟 음성 데이터들을 비지도 학습할때에는 기본 SLU 모델을 이용하여 디스턴 스 기반, 즉, 거리 함수를 이용한 비지도 학습을 수행한다. SLU 모델 갱신부는 비지도 학습 결과와 타겟 클래스에 해당하는 의도 추론 결과가 라벨링된 음성 데이터를 학습 데이터로 사용하여 지도 학습을 수행한다. 이러한 지도 학습을 통해 최종적으로 타겟 클래스의 의도 추론 성능이 갱신된 음성 언어 모델이 생성된다. 이하, SLU 모델 생성부 및 SLU 모델 갱신부의 세부적인 동작에 대해 설명하기로 한다. 도 2는 실시예에 따른 개략적인 SLU 모델 구조를 도시한다. 도 2를 참조하면, SLU 모델 구조는 특징 추출부, 음성 표현(Speech Representation) 추출부, 언어 표현(Language Representation) 추출부, 의도 추론부를 포함한다. 이러한 SLU 모델 구조는 SLU 모델 생성부가 생성하는 기본 SLU 모델 구조 및 SLU 모델 갱신부가 생성하는 특정 의도 클래스 추론 에 최적화된 SLU 모델 구조에 공통적으로 해당한다. 특징 추출부는 입력 음성 데이터로부터 특징 벡터를 추출한다. 특징 추출부는 특징 벡터를 추출하는 컨볼루셔널 서브샘플링 레이어(Convolutional Subsampling Layer), 추출한 특징 벡터를 임의로 섞는 랜덤 (Random) 마스킹(Masking) 및 셔플링(Shuffling) 레이어를 포함한다. 음성 표현 추출부는 특징 벡터를 학습하여 음성 표현 데이터를 추출한다. 음성 표현 추출부는 특징 벡터의 패턴을 학습하는 선형 레이어(linear layer), 특징 벡터의 학습된 패턴으로부터 음성 표현을 추출하는 컨포머 레이어(Conformer layer)를 포함한다. 언어 표현 추출부는 음성 표현 데이터를 학습하여 언어 표현 데이터를 추출한다. 언어 표현 추출부는 프로젝션 레이어(Projection layer), 임베딩 레이어(Embedding layer), 위치 인코딩 레이어(positional encoding layer), 트랜스포머 레이어(Transformer layer)를 포함한다. 의도 추론부는 언어 표현 데이터로부터 의도 클래스를 분류한다. 의도 추론부는 언어 표현 데이터로 부터 특정 클래스의 의도 및 개체 변수를 추출하는 추출 레이어(Extraction Layer), 입력 음성 데이터에 라벨링 된 Ground truth 의도 및 개체 변수와, 추출 레이어가 추출한 의도 맻 개체 변수 간의 손실을 학습하는 교차 엔 트로피 손실 레이어(Cross Entropy Loss Layer)를 포함한다. 도 3은 실시예에 따른 기본 SLU 모델의 구조를 도시하고, 도 4는 실시예에 따른 기본 SLU 모델 생성 과정을 설 명하는 순서도이다. 도 3을 참조하면, 기본 SLU 모델은 복수의 계층 구조로 이루어진다. 도 2에서 설명한 바와 같이, 기본 SLU 모델은 컨볼루셔널 서브샘플링 레이어, 2개의 랜덤 마스킹 및 셔플링 레이어(2, 8), 선형 레이어, 컨포머 레이어, 프로젝션 레이어, 임베딩 레이어, 위치 인코딩 레이어, 트랜스포머 레이어, 추출 레이어, 교차 엔트로피 손실 레이어를 포함한다. 이때, 도 3에서 블록은 벡터의 원소를 의미하고, 블록의 열이 다르면 벡터의 원소의 값이 다름을 의미한다. 또 한, 동일한 열에서 블록의 색상이 다름은 원소의 값이 다름을 의미한다. 이러한 복수의 레이어 구조를 가진 기본 SLU 모델을 학습시키는 과정에 대해 설명하면, 다음과 같다. 도 3 및 도 4를 참조하면, SLU 모델 생성부는 입력된 음성에 대해 컨볼루셔널 서브샘플링 레이어로 하여금 특징 벡터를 추출하고 추출한 특징 벡터를 시간축으로 1/4로 줄어들게 한다(S101). 이때, 컨볼루셔널 서브샘플링 레이어는 멜 필터 뱅크(Mel filter bank) 필터를 포함한다. 따라서, SLU 모델 생 성부는 입력 음성 데이터로부터 25ms 프레임, 즉, 10ms씩 이동시킨 프레임을 생성하고 생성한 프레임 마다 멜 필터 뱅크를 통해 특징 벡터를 추출한다(S101). 추출한 특징 벡터는 이동시킨 프레임을 열로 하고 그 프레임에서 추출된 벡터 원소들이 나열되어 있다. 이때, 도면에서 벡터 원소들은 블록으로 표현되어 있다. 구체적으로, S101에서 SLU 모델 생성부는 추출한 특징 벡터에 대하여 2D-convolution layer, Batch Normalization, ReLU(Rectified Linear Unit), Max Pooling Layer를 적용한 후, 2 block convolutional subsampling을 적용({2d-convolution layer + Batch Normalization + ReLU(Rectified Linear Unit) + maxpooling layer} × 2 block convolutional subsampling)함으로써, 특징 벡터를 시간축으로 1/4 줄어들도록 한다. SLU 모델 생성부는 SLU 모델의 오버피팅(overfitting)을 방지하기 위한 데이터 증강(data augmentation) 기법으로서, 마스킹 및 셔플링 레이어로 하여금 랜덤 샘플링한 프레임에 대해 0값으로 마스킹 및 셔플링을 적용(S102)하도록 한다. SLU 모델 생성부는 선형 레이어와 컨포머 레이어로 하여금 랜덤 마스킹 및 셔플링이 적용된 특징 벡 터를 학습하여 음성 표현을 추출(S103)한다. 이때, 컨포머 레이어를 통과한 특징 벡터를 음성 표현 벡터라 정의한다. 음성 표현 벡터는 음성 데이터에 대한 함축적인 정보 표현 방법을 나타낸다. SLU 모델 생성부는 프로젝션 레이어로 하여금 음성 표현 벡터를 N개의 언어 토큰(language token)들의 분포값을 갖는 벡터로 출력하게 한다(S104). SLU 모델 생성부는 임베딩 레이어로 하여금 출력한 각 벡터의 원소 중에서 분포값이 가장 큰 값을 가지 는 원소를 찾고, 사전에 저장된 룩업 테이블(look-up table)을 이용하여, 분포값이 가장 큰 값을 가지는 원소에 해당하는 임베딩 벡터값으로 변환하게 한다(S105). SLU 모델 생성부는 위치 인코딩 레이어로 하여금 임베딩 벡터열들의 위치에 따라 위치 정보가 추가된 임베딩 벡터를 생성하게 한다(S106). SLU 모델 생성부는 랜덤 마스킹 셔플링 레이어로 하여금 임베딩 벡터열에 대해 랜덤 샘플링한 프레임에 해당하는 임베딩 벡터를 0값으로 마스킹 및 셔플링을 하게 함(S107)으로써 데이터 증강을 수행한다. SLU 모델 생성부는 데이터 증강이 적용된 임베딩 벡터를 트랜스포머 레이어를 통과시켜 언어 표현 (language representation)을 학습한다(S107). SLU 모델 생성부는 트랜스포머 레이어로 하여금 데이터 증강이 적용된 임베딩 벡터를 언어 표현 벡터로 학습시킨다. SLU 모델 생성부는 추출 레이어로 하여금 언어 표현 벡터로부터 의도와 개체를 추론하게 한다(S109). SLU 모델 생성부는 교차 엔트로피 손실 레이어로 하여금 추론한 의도/개체와 정답(ground truth) 의도 /개체 사이의 교차 엔트로피 손실을 계산하게 한다(S110). 이처럼, SLU 모델 생성부는 추론된 의도/개체 변수와 Ground truth 의도/개체 변수 사이의 손실을 학습시킨다. 여기서, Ground truth 의도/개체 변수는 입력 음성 데이터에 대해 라벨링된 의도 클래스로 분류될 수 있다. 이러한 일련의 과정을 수행함으로써, 기본 SLU 모델이 생성된다. 도 5는 실시예에 따른 SLU 모델 갱신부의 세부 구성을 도시한다. 도 5를 참조하면, SLU 모델 갱신부는 문맥 불확실 맵(Contextual Uncertainty Map, 이하, 'CUM'으로 통칭 함) 생성부, CUM DB, 인덱싱 모듈, 음성 데이터 분류 모델 생성부, 비지도 학습부 및 지도 학습부를 포함한다. 메타 러닝(Meta learning)에는 N-way, K-shot형태의 데이터 준비(data preparation)가 필요하다. 즉, N개의 분 류하고자 하는 클래스와 각 클래스 별 K개의 샘플(example)을 준비해야 한다. 뿐만 아니라, 샘플(example)은 이 미지 분류 태스크(task)에서처럼 로 데이터 대표(raw data representation), 즉, '0~255'값을 갖는 N×N 이미 지 파일로 구성할 수도 있지만, 음성 인식 태스크(task)처럼 로 음성 데이터(raw speech data)를 사용하는 것이 아니라 윈도우 오프 필터 뱅크(window of filter bank) 값처럼 잠재 데이터 대표(latent data representatio n)를 사용하는 경우도 있다. 본 발명의 관리자가 세운 선별 전략에 따른 데이터 분류 태스크(task)는 분류하고자 하는 타겟이 음성 데이터가 아니라 음성 데이터로부터 추론된 결과인 의도/개체 정보, 즉, 의도 클래스이다. 따라서, 음성 데이터의 잠재 데이터 표현(latent data representation)을 적절히 정의해야 할 필요가 있다. 즉, 음성 데이터로부터 추론된 의도 클래스에 대한 정형화된 데이터가 필요하며, 실시예에 따르면, 이러한 정형화된 데이터를 언어 표현 불확 실성 정보인 CUM으로 정의하였다. 또한, 언어 표현 불확실성을 의도 클래스의 특징으로 사용하는 이유는 메타 러닝(meta learning)시 기본 SLU 모 델의 확률값을 기반으로 분류하므로, 이러한 확률값은 결국 모델의 불확실성을 나타낸다고 볼 수 있으며, 이를 CUM으로 정의하였다. CUM 생성부는 기본 SLU 모델과 서비스 데이터 DB에 저장된 서비스 데이터, 즉, 전사 음성 데이터를 이용하여 CUM을 생성한다. 앞서 기재한 바와 같이, CUM은 서비스 데이터 DB에 음성 데이터와 매칭하여 저 장된 의도/추론 결과 데이터를 정형화한 데이터이다. 이러한 CUM이 음성 데이터 분류 모델에 입력 데이터로 사 용되고, 음성 데이터 분류 모델에 의해 N개의 의도 클래스 중 하나의 의도 클래스로 분류된다. CUM의 행은 언어 표현 벡터(language representation vector)의 차원수, 열은 마스킹 레벨 수로 정의한다. CUM 생성부는 CUM 생성에 사용된 전사 음성 데이터의 음성 파일명, 날짜, CUM을 매칭한 CUM DB 테이블을 생성하고, 이를 CUM DB에 저장한다. CUM은 행렬값으로 저장될 수 있다. CUM DB와 서비스 데이터 DB는 음성 파일명으로 상호 참조된다. 한편, 관리자는 VOC(Voice Of Customer)를 모니터링하면서 SLU 모델의 업데이트가 필요한 부분을 결정할 수 있 다. 예를 들어, '일기예보요청' 이라는 특정 의도 클래스와 관련한 SLU 모델 성능을 개선시키고자 하면, '일기 예보요청'에 해당하는 음성 데이터를 확보하기 위한 전략을 수립한다. 전략 수립은 음성 데이터 분류 모델의 분 류 태스크(Task) 또는 의도 클래스를 '일기예보요청'과 'others'로 세팅하는 것을 말한다. 관리자는 특정 의도 클래스인 '일기예보요청'과 특정 의도 클래스를 제외한 나머지 의도 클래스를 의미하는 'others'에 해당하는 각 각의 퓨-샷(Few-shot) 데이터를 선정한다. 이때, 퓨-샷 데이터는 CUM을 사용한다. 따라서, 관리자는 전사 인력 을 투입하여 서비스 데이터 DB에 저장된 음성 데이터 중에서 '일기예보요청'으로 의도가 분류된 음성 데이 터에 해당 의도 클래스를 라벨링한다. 이처럼, 특정 의도 클래스가 라벨링된 음성 데이터를 퓨-샷 데이터로 호 칭한다. 퓨-샷 데이터는 '일기예보요청', 'others'로 라벨링된 3~9개 정도의 음성 데이터로 구성될 수 있다. 이 처럼 전사 이력에 의해 선별한 특정 의도 클래스가 라벨링된 음성 데이터 또는 퓨-샷 데이터는 인덱싱 모듈 에 입력된다. 인덱싱 모듈은 관리자 모니터링에 기초한 업데이트 전략의 특정 클래스에 해당하는 퓨-샷 데이터를 외부에 서 입력받는다. 인덱싱 모듈은 외부로부터 입력받은 퓨-샷 데이터로부터 확인한 음성 파일명을 이용해서 CUM DB로부터 음성 파일명에 대응하는 CUM을 추출하며, 이러한 추출 과정을 인덱싱이라 호칭한다. 인덱싱 모듈은 입력받은 퓨-샷 데이터, 즉, 업데이트 전략 대상의 음성 데이터에 대응하는 CUM을 CUM DB로부터 추출한다. 음성 데이터 분류 모델 생성부는 기본 음성 데이터 분류 모델과 특정 의도 클래스를 잘 분류하도록 갱신된 음성 데이터 분류 모델을 생성한다. 기본 음성 데이터 분류 모델은 입력받은 음성 데이터로부터 관리자가 정한 N개의 의도 클래스 중 하나로 분류하도록 학습된다. 갱신된 음성 데이터 분류 모델은 입력받은 음성 데이터로부 터 특정 의도 클래스와 나머지 의도 클래스 중 하나로 분류하도록 학습된다. 음성 데이터 분류 모델 생성부는 서비스 데이터 DB에 저장된 음성 데이터와 CUM DB에 저장된 CUM을 이용하여 기본 음성 데이터 분류 모델을 생성한다. 기본 음성 데이터 분류 모델은 관리자가 정하는 업데이트 전략, 즉, 분류하고자 하는 의도 클래스에 해당하는 음성 데이터를 분류하도록 모델링한 것이다. 기본 음성 데이터 분류 모델은 사전 지식 전략 모델이라 호칭할 수도 있다. 이러한 기본 음성 데이터 분류 모델 은 임의의 CUM이 입력되면 N개의 클래스 중 하나의 클래스를 출력한다. \"일기 예보\"라는 특정 클래스를 잘 분류하도록 기본 음성 데이터 분류 모델을 갱신하고자 하면, 갱신된 음성 데 이터 분류 모델은 입력된 CUM을 N개의 클래스 중에서 \"일기 예보\"에 해당하는 특정 클래스 또는 \"일기 예보\"가 아닌 임의의 더미 클래스(dummy class)로 분류한다. 이를 위하여, 음성 데이터 분류 모델 생성부는 기본 음성 데이터 분류 모델에 \"일기 예보\"라는 특정 클래스에 해당하는 음성 데이터들과 \"일기 예보\"에 해당하지 않는 음성 데이터들 각각의 CUM을 학습 데이터로 사용하여 재학습시킨다. 음성 데이터 분류 모델 생성부는 모델 신뢰도 값을 기준으로 선별한 음성 데이터에 대한 CUM을 학습 데이 터로 사용하여 기본 음성 데이터 분류 모델을 생성한다. 음성 데이터 분류 모델 생성부는 서비스 DB로부터 모델 신뢰도 값에 따라 음성 데이터를 선별하고, 선별한 음성 데이터를 훈련 데이터로 사용하여 기본 음성 데이터 분류 모델을 생성한다. 여기서, 모델 신뢰도 값은 운용자가 임의로 선정할 수 있다. 이러한 기본 음성 데이터 분류 모델은 관리자가 설정한 특정 의도 클래 스를 잘 분류하도록 최적화된 갱신된 음성 데이터 분류 모델을 생성하기 위한 베이스 모델로 사용된다. 음성 데이터 분류 모델 생성부는 퓨-삿 러닝 기술을 이용하여, 기본 음성 데이터 분류 모델을 인덱싱 모듈 이 추출한 CUM으로 학습시켜 특정 의도 클래스, 예컨대, '일기예보요청'에 해당하는 음성 데이터를 분류하 기 위한 갱신된 음성 데이터 분류 모델을 생성한다. 즉, 특정 의도 클래스에 최적화된 음성 분류 모델은 입력된 음성 데이터가 SLU 모델 업데이트에 사용할 데이터인지 구분하는 분류기(classifier)이다. 여기서, 퓨-샷 러닝 기술은 공지된 다양한 기술이 사용될 수 있으므로, 특정 기술로 제한하지 않는다. 비지도 학습부는 입력으로 일기예보에 해당하는 음성을 입력으로 받아 음성 표현과 언어 표현을 학습한다. 음성 표현을 학습하는 과정에서 Base SLU 모델의 중간 스코어(score)값이 사용된다. 비지도 학습부는 특정 의도 클래스에 최적화된 음성 데이터 분류 모델을 이용하여, 서비스 데이터 DB(16 0)에 저장된 전사 음성 데이터들을 특정 의도 클래스인 타겟 클래스와, 더미 클래스로 분류한다. 여기서, 더미 클래스는 타겟 클래스가 아닌 클래스들이다. 비지도 학습부는 서비스 데이터 DB에 저장된 음성 데이터들을 갱신된 음성 분류 데이터 모델에 입력 하여 입력된 음성 데이터를 갱신 대상인 타겟 클래스와 더미 클래스로 분류한다. 예컨대, 비지도 학습부는 갱신된 음성 분류 데이터 모델을 사용하여 '일기 예보 요청', '실시간 요금제 요청'에 대한 음성 데이터들을 분 류할 수 있다. 비지도 학습부는 서비스 데이터 DB에 저장된 음성 데이터들을 학습 데이터로 사용하여, 비지도 학습 을 통해 SLU 모델을 다시 생성한다. 이때, 비지도 학습부는 음성 데이터 중에서 타겟 클래스에 속하는 음성 데이터에 한해, 비지도 학습시 기 본 SLU 모델을 이용하여 디스턴스(distance) 기반 마스킹을 통해 비지도 학습을 수행한다. 즉, 타겟 클래스에 속하는 음성 데이터를 새로 학습중인 SLU 모델의 위치 인코딩 계층에 입력하여 출력된 제1 언어 표현 데이터와, 타겟 클래스에 속하는 음성 데이터를 기본 SLU 모델의 위치 인코딩 계층에 입력하여 출력된 제2 언어 표현 데이 터 간의 거리를 비교한다. 그리고 거리가 임계값을 초과하는 제1 언어 표현 데이터를 제2 언어 표현 데이터를 이용하여 마스킹하고, 마스킹한 언어 표현 데이터로 SLU 모델의 추출 계층을 학습시킨다. 비지도 학습부는 대량의 음성 데이터를 학습 데이터로 사용하여 기 생성된 SLU 모델을 비지도 학습 방식으 로 재학습시키면서, 음성 표현(speech representation)과 언어 표현(language representation)에 대한 손실 (loss)값을 재학습한다. 지도 학습부는 비지도 학습된 모델의 출력을 입력으로 받아, 일기예보에 해당하는 음성과 태깅된 특정 의 도 클래스, 예를들어, 일기예보요청이라는 추론된 의도와 개체 변수(entity)인 서울, 오후, 등을 학습 데이터로 사용하여 지도 학습을 수행함으로써, 최종적으로 갱신된 SLU 모델을 생성한다. 지도 학습부는 분류하고자 하는 특정 의도 클래스의 음성 데이터와 그에 대한 정답값, 즉, 의도와 개체 변 수인 퓨-샷 데이터를 외부에서 입력받아, 이를 통해 기본 SLU 모델을 파인-튜닝(Fine-tuning)한 갱신된 SLU 모 델을 생성할 수 있다. 이때, 입력되는 음성 데이터는 특정 틀래스의 음성 데이터이고, 특정 클래스의 음성 데이터에 대해 전사 작업을 통해 의도/개체 변수가 라벨링된다. 이와 같이, 비지도 학습 및 지도 학습 방식으로 새로운 SLU 모델을 학습하는 과정을 통해 특정 클래스의 성능을 개선시킨 최종적인 SLU 모델, 즉, 특정 클래스에 최적화된 SLU 모델이 생성된다. 도 6은 실시예에 따른 언어 표현 불확실성 정보(CUM) 생성 과정을 도시하고, 도 7은 도 6의 CUM 생성 과정을 설 명한 예시도이다. CUM 생성부는 SLU 모델 생성부가 생성한 기본 SLU 모델을 이용하여 음성 데이터(Speech Data)로부터 CUM을 추출한다. 이러한 CUM 추출 과정에 대해 설명하면 다음과 같다. 도 6 및 도 7을 참조하면, CUM 생성부는 기본 SLU 모델을 이용하여 발화 데이터로부터 특정 언어 표현 (certain language representation), 즉, R1~T를 추출한다(S201). 여기서, T는 언어 표현의 전체 길이를 의미한 다. 이때, CUM 생성부는 음성 데이터 X에 대해 25ms 프레임, 즉, 10ms씩 이동한 프레임마다 80차원의 멜 필터 뱅크를 통하여 특징 벡터, 즉, X1~T를 추출하고, 이러한 특징 벡터(X1~T)를 기본 SLU 모델에 입력한다. 기본 SLU 모델에 입력된 특징 벡터(X1~T)는 도 3의 복수의 레이어, 즉, 컨볼루셔널 서브샘플링 레이어, 랜덤 마 스킹 및 셔플링 레이어, 선형 레이어, 컨포머 레이어, 프로젝션 레이어, 임베딩 레이어, 위치 인코딩 레이어, 랜덤 마스킹 및 셔플링 레이어, 트랜스포머 레이어를 순차적으로 거쳐 언어 표현(language representation), 즉, R1~T로 생성된다. 기본 SLU 모델이 이상적(ideal)이라는 전제하에 R1~T를 확실한 언어 표현(certain language representation)이라고 호칭한다. 또한, CUM 생성부는 베르누이 분포(Bernoulli distribution)의 모델 파라미터 'P'값을 세팅한다(S202). CUM 생성부는 'P'값을 0.0부터 1.0까지 0.1의 간격으로 세팅한다. P값이 0.0이면 SLU 모델의 불확실성 (uncertainty)을 최대화하고, 1.0이면 불확실성을 최소화한다고 해석할 수 있다. CUM 생성부는 'P'값을 가지는 베르누이 분산 모델 파라미터를 기본 SLU 모델의 음성 표현(speech representation)의 입력단, 즉, 도 3의 프로젝션 레이어와, 언어 표현(language representation)의 입력단, 즉, 추출 레이어에 적용하여 기본 SLU 모델에 불확실성을 부여한다. SIn t 는 음성 표현 레이어인 프로젝션 레이어의 t번째 입력 유닛이고, 'P' 값이 0.0이면, SIn t는 항상 마스킹된 다. 마찬가지로 LIn t는 언어 표현 레이어인 추출 레이어의 t번째 입력 유닛이며, 'P'값이 0.0이면 LIn t 는 항상 마스킹 된다. 'P' 레벨로 마스킹(S203)된 기본 SLU 모델의 언어 표현, U1~T,P를 추출(S204)하며, U1~T,P를 를 P 레벨 불확실한 언어 표현(uncertain language representation)이라고 호칭한다. 즉, 입력 벡터열에 대해 임의의 벡터가 확률 값 'P'에 의해 제거되었기 때문에 불확실성 언어 표현이 된다. 확률값 'P'에 따라 음성 표현, 언어 표의 입력 벡터열에 대해 임의의 벡터를 제거할지 즉, 0값으로 치환할지 말지가 확률적으로 결정되므로, 불확실성 부여라 고 한다. 또한, 확률값 'P'에 따라 불확실성 정도가 달라지기 때문에, p-level 불확실성이라고 호칭한다. CUM 생성부는 기본 SLU 모델을 이용하여 음성 데이터로부터 추출(S201)한 특정 언어 표현(R1~T)과 확률값 'P'에 따라 추출(S204)한 P 레벨 불확실성 언어 표현(U1~T,P) 간의 유사도인 P-level 컨텍스트 가중치(Context Weight)(Cpij)를 생성한다(S205). 구체적으로, CUM 생성부는 R1~T과 U1~T,P으로부터 공통의 문맥 정보(contextual information)를 포함할 수 있도록 컨텍스트 가중치를 생성하며, 아래 수학식 1 및 수학식 2를 이용하여 생성할 수 있다. [수학식 1] Eij= Uj,P * Ri / |Uj,P| ×|Ri| Eij는 i번째 확실한 언어 표현(certain language representation)과 j번째 불확실성 언어 표현(uncertain language reprensentation) 간의 유사도값을 의미한다. [수학식 2] Cij= exp(Eij) / SUMj(exp(Eij)) Cij는 i번째 확실한 언어 표현(certain language representation)과 j번째 불확실한 언어 표현(uncertain language reprensentation) 간의 컨텍스트 가중치(context weight) 값을 의미한다. Uj,p는 p-level 불확실한 언어 표현(uncertain language reprensentation)의 j번째 벡터값을 의미한다. Ri는 확 실한 언어 표현(certain language representation)의 i번째 벡터값을 의미한다. |.|는 벡터의 크기값을 나타낸 다. Exp()는 지수 함수(exponential function)를 의미한다. SUMj는 모든 j에 대해 유한합(summation)을 의미한 다. CUM 생성부는 아래 수학식 3을 이용하여 P 레벨 컨텍스트 가중치(context weight)로부터 P-level 문맥 불 확실성(Contextual Uncertainty)(CUP)을 추출한다(S206). [수학식 3] CUP,i = Cij × Uj,P and CUP = SUMi(Ui,P) / T T는 언어 표현(language representation)의 총 길이를 나타낸다. CUP 는 N차원 벡터다. 여기서, N은 언어 표현 벡터(language representation vector)(Rt)의 사이즈와 동일하다. 즉, CUP는 P 레벨의 불확실성(uncertainty)의 모든 컨텍스트(context) 정보가 반영된 모델 출력값이라 할 수 있다. 'p'의 확률로 불확실성을 주었을 때의 문맥 불확실성(contextual uncertainty), 즉, i번째 특정 언어 표현 (certain language representation)을 기준으로 p-level 불특정 언어 표현(uncertain language representation)으로부터 산출한 p-level 불확실성(uncertainty)을 CUP,i로 정의하고, 모든 특정 언어 표현 (certain language representation)에 대해 p-level 불확실성(uncertainty)을 평균하면 전체 컨텍스트 (context)가 반영됐기 때문에, p-level 문맥 불확실성(contextual uncertainty)(CUP)이라고 한다. CUM 생성부는 CONCAT 함수를 이용하여 P개의 P 레벨 CUP를 토대로 CUM을 생성한다(S207). CUP는 1차원 벡 터값 이므로, P개의 불특정(uncertain) 확률에 의해 구해진 각 CUP 벡터들을 연결해서 [CUp1, CUp2, … , CUpN] 처럼 2차원 행렬로 생성하고 이를 CUM으로 생성한다. 이와 같이, CUM은 언어 표현의 불확실성 정보를 나타낸다. 도 8은 한 실시예에 따른 음성 데이터 분류 모델 생성 과정을 도시한다. 도 8을 참조하면, 음성 데이터 분류 모델 생성부는는 서비스 데이터 DB에 저장된 복수의 음성 데이터 중에서 모델 신뢰도 값을 기초로 선별(S401)한 음성 데이터들에 대응하는 CUM을 CUM DB로부터 추출하고, 추출한 CUM을 학습 데이터로 선정한다(S402). 음성 데이터 분류 모델 생성부는 S402에서 선정한 CUM을 학습 데이터로 사용하여 N개의 의도 클래스 중 하 나로 분류하는 기본 음성 데이터 분류 모델을 생성한다(S403). 음성 데이터 분류 모델 생성부는 인덱싱 모듈에 의해 추출된 특정 의도 클래스와 그에 해당하는 음성 데이터들의 CUM을 학습 데이터로 선정(S404)한다. 음성 데이터 분류 모델 생성부는 S404에서 선정한 학습 데이터를 이용하여 기본 음성 데이터 분류 모델을 학습시켜 특정 의도 클래스와 특정 의도 클래스가 아닌 더미 클래스를 분류하는 갱신된 음성 데이터 분류 모델 을 생성한다(S405). 도 9는 실시예에 따른 음성 데이터 분류 모델의 구조를 나타내고, 도 10은 다른 실시예에 따른 음성 데이터 분 류 모델 모델 생성 과정을 도시한다. 도 9를 참조하면, 음성 데이터 분류 모델은 임베딩 레이어(Embedding Layer), 거리 함수(Distance Metric), 분 류기(Classifier)로 구성된다. 기본 음성 데이터 분류 모델 생성 과정에서, 기본 SLU 모델의 신뢰도 값 기반으로 데이터를 분류하여 모델링하 는데, 모델 신뢰도값은 언어 표현의 불확실성과 유사 관계가 있다고 볼 수 있으므로, CUM을 특징(feature) 값으 로 사용하여 훈련한다. 관리자가 정하는 업데이트 전략, 즉, 특정 클래스에 해당하는 음성 데이터를 분류하기 위한 기본 음성 데이터 분류 모델은 비지도 학습 방식으로 생성된다. 기본 음성 데이터 분류 모델은 학습하는 법을 학습하는 모델로 볼 수 있다. 관리자가 정하는 업데이트 전략은 discrete한 형태로 되며, 분류하고자 하는 N개의 의도 클래스에 해당한다. 최 대 분류 클래스 N, 각 분류 클래스 별 샘플 개수를 K라 정의한다. 음성 데이터 분류 모델 생성부는 외부 입력에 따라 분류 클래스 및 샘플 개수를 결정한다(S401). 음성 데이터 분류 모델 생성부는 서비스 데이터 DB에 저장된 음성 데이터를 로그 데이터 정보를 활용 해서 N 개의 클래스로 분류(S402)하는데, 분류하는 기준은 모델 출력 확률, 즉, 모델 신뢰도값이 어느 범위에 있는지에 따라 분류한다. 각 범위는 uniform 하게 설정될 수도 있고, Gaussian 분포 형태로 설정될 수 있다. 음성 데이터 분류 모델 생성부는 N개의 의도 클래스 중 하나의 의도 클래스로 분류된 음성 데이터에 대해 서 생성된 CUM을 학습 셋(set)으로 생성한다(S403). 학습 셋은 훈련 셋(Support set)과 평가 셋(Query set)으 로 구성된다. 훈련 셋은 각 의도 클래스 별로 K개의 CUM으로 구성되고, 평가 셋은 각 의도 클래스 별로 1개의 CUM으로 구성된다. 음성 데이터 분류 모델 생성부는 컨볼루셔널 레이어(convolutional layer) 모듈로 이루어진 임베딩 (Embedding layer)로 하여금 훈련 셋 및 평가 셋에 대한 각각의 특징 벡터(Yn,k)를 추출하도록 한다(S404). Yn,k=Fully-Connected(Conv(Xn, k))로 정의되고, n 클래스의 k번째 CUM에 대한 특징 벡터를 의미한다. 음성 데이터 분류 모델 생성부는 디스턴스 메트릭(Distance Metric)으로 하여금 훈련 셋 및 평가 셋 각각 의 특징 벡터 간의 거리를 연산(S405)하고, 가장 작은 거리를 가지는 n 클래스로 분류(arg minn distance(Ysup n,k, Yquery n))하도록 분류기를 학습시킨다(S406). 이러한 과정을 통해 도 8의 임베딩 레이어 (Embedding Layer), 디스턴스 메트릭(Distance Metric), 분류기(Classifier)는 음성 데이터 분류 모델로 학습 된다. 관리자가 업데이트 전략 수립, 예를 들어, 의도(Intent)가 일기예보요청 또는 실시간 요금 요청하는 내용에 대 하여 선별적으로 업데이트하겠다는 전략을 수립할 수 있다. 관리자는 클래스 개수 N, 각 클래스 별 샘플 개수 K 에 맞게 전사 인력을 투입하여 음성 데이터를 선정한다. 관리자가 선정한 각 클래스에 해당하는 음성 데이터들, 즉, 일기 예보 요청에 대한 음성 데이터들과 실시간 요 금 요청에 대한 음성 데이터들이 음성 데이터 분류 모델 생성부로 입력된다. 음성 데이터 분류 모델 생성부는 입력된 음성 데이터의 파일명을 기초로 CUM DB로부터 업데이트 대상 인 CUM 들을 추출하여 이들을 기초로 훈련 셋과 평가 셋을 생성한다(S407). 이때, 음성 데이터 분류 모델 생성부는 관리자가 입력한 업데이트 전략 클래스는 '일기예보요청', '실시간 요금요청' 2개의 클래스 밖에 없으므로, 나머지 클래스는 랜덤 데이터로 채운다. 즉, N개의 클래스에 해당하는 훈련 셋과 평가 셋인 C1, C2, C3, … CN에서, C1은 '일기예보요청' 클래스의 음성 데이터에 대응하는 CUM, C2는 '실시간요금요청' 클래스의 음성 데이터에 대응하는 CUM, C3, … CN는 랜덤 클래스의 음성 데이터에 대응하는 CUM으로 설정될 수 있다. 이때, 클래스 N과 샘플 개수 K를 10, 5로 세팅할 경우, 관리자의 전사 작업이 필요한 음성 데이터, 즉, 업데이 트 하고자 N개의 클래스에 해당하는 음성 데이터가 10×5=50개로 전사 비용이 대폭 줄어든다. 음성 데이터 분류 모델 생성부는 S407에서 생성한 훈련 셋과 평가 셋으로 S406에서 생성한 음성 데이터 분 류 모델을 재학습 시켜 특정 클래스의 음성 데이터를 분류하도록 최적화된, 즉, 갱신된 음성 데이터 분류 모델 을 생성한다(S408).도 11은 실시예에 따른 특정 의도 클래스 추론에 최적화된 SLU 모델을 생성하는 과정을 도시한다. 도 11을 참조하면, 비지도 학습부는 특정 의도 클래스에 최적화된 음성 데이터 분류 모델을 이용하여 서비 스 DB로부터 외부에서 입력된 분류 태스크, 즉, 특정 클래스에 해당하는 음성 데이터를 추출한다(S501). 비지도 학습부는 S501에서 추출한 음성 데이터를 기본 SLU 모델에 입력하여 위치 인코딩된 음성 표현 벡터 를 추출한다(S502). 비지도 학습부는 S501에서 추출한 음성 데이터를 학습 데이터로 사용하고, S502에서 추출한 음성 표현 벡 터를 이용하여 디스턴스(distance) 기반 비지도 학습을 수행하여 갱신된 SLU 모델을 생성한다(S503). 이때, 비지도 학습부는 S501에서 추출한 특정 의도 클래스에 해당하는 음성 데이터 뿐만 아니라 서비스 DB에 저장된 다른 의도 클래스에 해당하는 음성 데이터도 비지도 학습한다. 지도 학습부는 외부에서 입력된 의도 추론 결과가 라벨링된 음성 데이터로 S504에서 생성한 갱신 SLU 모델 에 대한 지도 학습(S504)을 수행하여 파인 튜닝한다. 지도 학습부는 파인 튜닝된 SLU 모델을 특정 의도 클래스의 추론 성능이 갱신된 SLU 모델로 출력한다 (S505). 도 12는 실시예에 따른 특정 의도 클래스 추론에 최적화된 SLU 모델의 구조를 나타내고, 도 13은 실시예에 따른 특정 의도 클래스 추론에 최적화된 SLU 모델을 생성하기 위한 비지도 학습 및 지도 학습 과정을 설명한다. 도 12를 참조하면, 특정 의도 클래스 추론에 최적화된, 즉, 갱신된 SLU 모델 구조는 도 3에서 설명한 기본 SLU 모델과 유사한 계층 구조의 딥러닝 모델 구조를 가진다. 즉, 갱신된 SLU 모델은 복수의 계층 구조인 딥러닝 모 델을 사용하며, 컨볼루셔널 서브샘플링 레이어(Convolutional Subsampling Layer), 랜덤(Random) 마스킹 (Masking) 및 셔플링(Shuffling) 레이어, 선형 레이어(linear layer), 컨포머 레이어(Conformer layer), 프로젝션 레이어(Projection layer), 임베딩 레이어(Embedding layer), 위치 인코딩 레이 어(positional encoding layer), 거리 기반 마스킹/강화 레이어(Distance based Masking/Forcing Layer), 트랜스포머 레이어(Transformer layer), 추출 레이어(Extraction Layer), 교차 엔트로피 손실 레이어(Cross Entropy Loss Layer)를 포함한다. 도 12를 참조하면, 비지도 학습부는 대량의 음성 데이터들에 대해 음성 표현 및 언어 표현의 모델 파라미 터를 랜덤하게 설정한다(S601). 음성 표현의 랜덤 마스킹/셔플 레이어 모델 파라미터는 Wspeech_representation로 정의 하고, 언어 표현의 랜덤 마스킹/셔플 레이어 모델 파라미터는 Wlanguage_representation로 정의한다. 비지도 학습부는 임의의 입력 음성에 대해 음성 표현 손실(Speech representation loss)과 언어 표현 손실 (language representation loss)을 계산한다(S602). 비지도 학습부는 입력 음성에 대해 도 12의 컨볼루션 서브샘플링 레이어를 통과한 Ct(t=1~T)에 대해 랜덤 마스킹/셔플링 레이어로 하여금 랜덤 샘플링한 프레임에 대해 0값으로 마스킹 및 셔플링을 적용한 Mt(t=1~T)를 추출하게 한다. 비지도 학습부는 Mt(t=1~T)를 선형 레이어 및 컨포머 레이어를 통과시켜 음성 표현 Yt(t=1~T)를 추출한다. 비지도 학습부는 랜덤 마스킹/셔플 레이어 모델(Wspeech_representation)을 통과한 Yt(t=1~T)에 대해 음성 표현 손 실(Speech Loss)을 구하며, 이는 아래 수학식 4와 같다. [수학식 4] 손실(Loss)=-log{exp(sim(Yt , Mt(t=masked time step)))/sum(exp(sim(Yt, Mt (t=other time step))))} 비지도 학습부는 음성 표현 Yt(t=1~T)에 대해 프로젝션 레이어를 통과한 Pt를 추출한다. Pt는 N 차원의 벡터값이며, Pt,i는 SPM token index 'i'에 해당하는 확률값이다. 여기서, N은 SPM token 사이즈이다. 비지도 학습부는 Pt를 argmaxi(Pt,i)에 해당하는 i값을 임베딩 레이어를 통과시켜 Et를 추출하며, Sinusoidal Function을 통해 t 값에 따라 위치값을 더해주는 위치 인코딩이 적용된 벡터값 Ut을 추출한다 (S603). 이때, 비지도 학습부는 입력 음성 중에서 타겟 클래스에 해당하는 음성에 대한 음성 표현 Yt(t=1~T)를 기 본 SLU 모델의 오리지널 프로젝션 레이어를 통과시켜 출력된 Pref t를 추출한다. 비지도 학습부는 Pref t를 기본 SLU 모델의 임베딩 레이어 및 위치 인코딩 레이어를 통과시켜 위치 인 코딩이 적용된 벡터값 Rt을 출력한다(S604). 비지도 학습부는 거리 함수를 이용하여 Ut와 Rt의 거리를 연산(S605)하고, 연산된 거리값이 임계값(예, 0.7)을 초과하는 Ut에 대해 Rt로 마스킹한 Ft를 추출한다(S606). 여기서, 거리 함수는 타겟 클래스로 분류된 음 성에 대해 적용된다. 비지도 학습부는 추출한 Ft를 트랜스포머 레이어를 통과시켜 최종적인 언어 표현(Tt)을 추출한다 (S607). 비지도 학습부는 Tt에 대해 언어 표현 손실(NLP Loss)을 구하며, 이는 아래 수학식 5와 같다. [수학식 5] 손실(Loss)=-log{exp(sim(Ut, Ft(t=other time step)))/sum(exp(sim(Ut, Ft (t=masked time step))))} 이처럼, 비지도 학습부는 기본 SLU 모델을 이용하여 디스턴스 기반으로 비지도 학습을 수행한다. 이때, 비 지도 학습부는 갱신된 음성 데이터 분류 모델을 통해 타겟 클래스로 분류된 음성 데이터를 비지도 학습할 때에는 앞서 설명한 바와 같이, 기본 SLU 모델을 이용하여 디스턴스 기반으로 비지도 학습을 수행한다. 그리고 타겟 클래스가 아닌 다른 클래스에 속하는 음성 데이터를 비지도 학습할때에는 기본 SLU 모델을 학습할때와 마 찬가지로, 거리 함수를 적용함없이 비지도 학습을 수행한다. 다음, 지도 학습부는 비지도 학습된 SLU 모델에 대해 지도 학습을 하기 위해 업데이트 대상 클래스에 해당 하는 음성 데이터를 소규모로 추출한다. 소규모 음성 데이터는 예컨대, 100~1000개와 같이 일정 개수로 추출한 데이터를 의미하며, 개수는 관리자에 의해 설정될 수 있다. 이때, 추출 개수는 전사 인력에 의해 라벨링이 이루 어져야 함을 고려하여 설정될 수 있다. 전사 인력을 투입하여 특정 클래스, 즉, 타겟 클래스에 속하는 소규모 음성 데이터에 대하여, 타겟 클래스로 분 류되는 의도(intent)와 개체 변수(entity)를 태깅한다. 이러한 태깅 작업으로 수작업으로 이루어지고, 타겟 클 래스에 속하는 의도와 개체 변수가 라벨링된 소규모 음성 데이터는 학습 데이터로 사용되어, 비지도 학습된다. 의도와 개체 변수는 Ground truth 값으로 크로스-엔트로피 로스 레이어(Cross-Entropy Loss Layer)로 입력된다. 여기서, 사전 비지도 학습된 모델은 S601~S607를 통해 학습된 컨볼루셔널 서브샘플링 레이어, 랜덤 마스킹 및 셔플링 레이어, 선형 레이어, 컨포머 레이어, 프로젝션 레이어, 임베딩 레이어, 위치 인코딩 레이어, 디스턴스 기반 마스킹/강화 레이어 및 트랜스포머 레이어를 의미한다. 지도 학습부는 사전 비지도 학습된 모델을 통하여 소규모 음성 데이터에 대응하는 언어 표현을 추출하고, 이러한 언어 표현을 추출 레이어를 통과시켜 의도/개체 변수를 추론한다(S608). 추출 레이어는 태스크에 따 라 미리 설계된 딥러닝 모델이라 할 수 있다. 지도 학습부는 크로스-엔트로피 손실 레이어로 하여금 추론한 의도/개체 변수와 라벨링된 타겟 클래스 인 Ground truth 의도/개체 변수 간의 크로스-엔트로피 손실을 계산하고, 이를 지도 학습을 통해 학습(S609)시 켜 갱신된 SLU 모델을 생성한다. 한편, 도 14는 실시예에 따른 컴퓨팅 장치의 하드웨어 구성도이다. 도 14를 참고하면, 도 1 ~ 도 13에서 설명한 인공지능 보이스봇은 적어도 하나의 컴퓨팅 장치로 구현 될 수 있고, 본 개시의 동작을 실행하도록 기술된 명령들(instructions)이 포함된 컴퓨터 프로그램을 실행할 수 있다. 컴퓨팅 장치의 하드웨어는 적어도 하나의 프로세서, 메모리, 스토리지, 통신 장치를 포함할 수 있고, 버스를 통해 연결될 수 있다. 이외에도 입력 장치 및 출력 장치 등의 하드웨어가 포함될 수 있 다. 컴퓨팅 장치는 컴퓨터 프로그램을 구동할 수 있는 운영 체제를 비롯한 각종 소프트웨어가 탑재될 수 있다. 프로세서는 컴퓨팅 장치의 동작을 제어하는 장치로서, 컴퓨터 프로그램에 포함된 명령들을 처리하는 다양한 형태의 프로세서일 수 있고, 예를 들면, CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 등 일 수 있다. 또한, 프로세서는 도 1 ~ 도 13에서 설명한 방법을 실행하기 위한 프로그램에 대한 연산을 수행할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 개시의 동작을 실행하도록 기술 된 명령들이 프로세서에 의해 처리되도록 해당 컴퓨터 프로그램을 스토리지로부터 로드 할 수 있다. 메모리는 예를 들면, ROM(read only memory), RAM(random access memory) 등 일 수 있다. 스토리지 는 본 개시의 동작을 실행하는데 요구되는 각종 데이터, 컴퓨터 프로그램 등을 저장할 수 있다. 스토리지 는 컴퓨터 프로그램을 비임시적으로 저장할 수 있다. 스토리지는 비휘발성 메모리로 구현될 수 있다. 통신 장치는 유/무선 통신 모듈일 수 있다. 프로세서는 도 1 ~ 도 13에서 설명한 음성 의도 분석부, 응답 문장 생성부, 음성 합성부, SLU 모델 생성부, SLU 모델 갱신부, CUM 생성부, 인덱싱 모듈, 음성 데이터 분류 모델 생 성부, 비지도 학습부 및 지도 학습부를 메모리에 로딩하여 해당 동작을 실행할 수 있다. 이상에서 설명한 본 발명의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 발명의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14"}
{"patent_id": "10-2021-0105681", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 AI(Artificial Intelligence) 보이스봇(Voicebot)의 구성을 도시한다. 도 2는 실시예에 따른 개략적인 SLU 모델 구조를 도시한다. 도 3은 실시예에 따른 기본 SLU 모델의 구조를 도시한다. 도 4는 실시예에 따른 기본 SLU 모델 생성 과정을 도시한다. 도 5는 실시예에 따른 SLU 모델 갱신부의 세부 구성을 도시한다. 도 6은 실시예에 따른 언어 표현 불확실성 정보(CUM) 생성 과정을 도시한다. 도 7은 도 6의 CUM 생성 과정을 설명한 예시도이다.도 8은 한 실시예에 따른 음성 데이터 분류 모델 생성 과정을 도시한다. 도 9는 실시예에 따른 음성 데이터 분류 모델의 구조를 나타낸다. 도 10은 다른 실시예에 따른 음성 데이터 분류 모델 모델 생성 과정을 도시한다. 도 11은 실시예에 따른 특정 의도 클래스 추론에 최적화된 SLU 모델을 생성하는 과정을 도시한다. 도 12는 실시예에 따른 특정 의도 클래스 추론에 최적화된 SLU 모델의 구조를 나타낸다. 도 13은 실시예에 따른 특정 의도 클래스 추론에 최적화된 SLU 모델을 생성하기 위한 비지도 학습 및 지도 학습 과정을 설명한다. 도 14는 실시예에 따른 컴퓨팅 장치의 하드웨어 구성도이다."}
