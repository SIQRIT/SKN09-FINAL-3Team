{"patent_id": "10-2022-0131110", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0051444", "출원번호": "10-2022-0131110", "발명의 명칭": "임계치 설정에 따른 추론성능 가속화방법", "출원인": "주식회사 소이넷", "발명자": "김용호"}}
{"patent_id": "10-2022-0131110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 추론 모델이 수행될 엣지 디바이스와 네트워크를 통해 통신하는 서버를 포함하는 추론성능 가속화시스템에서 수행하는 추론성능 가속화방법에 있어서,(A) 엣지 디바이스별 연산 단위 및/또는 연산 속도에 따라 추론모델에 포함된 파라미터 값의 임계치를 설정하는단계;(B) 상기 임계치 이내의 파라미터 값 및 상기 임계치를 초과하는 파라미터 값 각각을 설정된 단위의 추론 코드로 압축 및/또는 변환하는 단계; 및(C) 상기 추론 모델에 상기 추론 코드를 적용하여 추론을 실행하는 단계;를 포함하는, 추론성능 가속화방법."}
{"patent_id": "10-2022-0131110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 (A) 단계에서는,상기 임계치 이내의 파라미터 값을 가수부로 설정하고, 상기 임계치를 초과하는 파라미터 값을 진수부로 설정하는 것을 특징으로 하는, 추론성능 가속화방법."}
{"patent_id": "10-2022-0131110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 (B) 단계에서는,상기 가수부 및 상기 진수부 각각을 설정된 단위의 추론 코드로 압축 및/또는 변환하는 것을 특징으로 하는, 추론성능 가속화방법."}
{"patent_id": "10-2022-0131110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 추론 코드는 학습이 완료된 인공지능 추론 모델에 따라 디바이스, 정확도(accuracy), 모델 크기, 지연 시간(latency), 압축 시간 및 에너지 소모량 중 적어도 하나의 항목에 대한 임계값을 반영하는 코드를 포함하는것을 특징으로 하는, 추론성능 가속화방법."}
{"patent_id": "10-2022-0131110", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 (C) 단계에서는,상기 가수부 및 상기 진수부 각각에 대한 추론 코드가 적용된 인공지능 추론 모델의 성능을 측정하는 것을 특징으로 하는, 추론성능 가속화방법.공개특허 10-2024-0051444-2-"}
{"patent_id": "10-2022-0131110", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 임계치 설정에 따른 추론성능 가속화방법에 관한 것으로, 본 발명의 일 실시예는 인공지능 추론 모델 이 수행될 엣지 디바이스와 네트워크를 통해 통신하는 서버를 포함하는 추론성능 가속화시스템에서 수행하는 추 론성능 가속화방법에 있어서, (A) 엣지 디바이스별 연산 단위 및/또는 연산 속도에 따라 추론모델에 포함된 파라 미터 값의 임계치를 설정하는 단계; (B) 상기 임계치 이내의 파라미터 값 및 상기 임계치를 초과하는 파라미터 값 각각을 설정된 단위의 추론 코드로 압축 및/또는 변환하는 단계; 및 (C) 상기 추론 모델에 상기 추론 코드를 적용하여 추론을 실행하는 단계를 포함하는, 추론성능 가속화방법을 제공한다."}
{"patent_id": "10-2022-0131110", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 임계치 설정에 따른 추론성능 가속화방법에 관한 것이다."}
{"patent_id": "10-2022-0131110", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술이 발전하면서 다양한 산업 분야에서 활용되는 임베디드 시스템이 내장된 임베디드 디바이스에 인 공지능 기술이 접목되고 있다. 특히, 미리 학습이 완료된 인공지능 모델을 임베디드 장치에 최대한 효율적으로 실행시키도록 개발된 소프트웨어인 추론 모델(Inference Model)을 통하여 임베디드 디바이스에 인공지능 기술이 접목되게 되었다. 이에 따라, 저성능, 저사양인 임베디드 디바이스들에 인공지능 기술이 접목될 수 있도록 경량화 기술들이 개발 되었고, 인공지능 추론 모델의 경량화는 대상 인공지능 모델을 구성하는 가중치(weights/bias)의 수를 줄이거나, 용량을 줄이거나, 추론 속도를 빠르게 하는 방법으로 개발되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록특허공보 제10-2086815호"}
{"patent_id": "10-2022-0131110", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는 디바이스별 성능과 파라미터 값의 연계에 따른 효율화를 추구하는 임 계치 설정에 따른 추론성능 가속화방법을 제공하는 것이다. 또한, 본 발명이 해결하고자 하는 기술적 과제는 디바이스별 성능에 따른 추론 성능을 효율적으로 활용하여 추 론성능 가속화를 제공하는 임계치 설정에 따른 추론성능 가속화방법을 제공하는 것이다. 본 발명이 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다 른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0131110", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 달성하기 위하여, 본 발명의 일 실시예는 인공지능 추론 모델이 수행될 엣지 디바이스와 네 트워크를 통해 통신하는 서버를 포함하는 추론성능 가속화시스템에서 수행하는 추론성능 가속화방법에 있어서, (A) 엣지 디바이스별 연산 단위 및/또는 연산 속도에 따라 추론모델에 포함된 파라미터 값의 임계치를 설정하는 단계; (B) 상기 임계치 이내의 파라미터 값 및 상기 임계치를 초과하는 파라미터 값 각각을 설정된 단위의 추론 코드로 압축 및/또는 변환하는 단계; 및 (C) 상기 추론 모델에 상기 추론 코드를 적용하여 추론을 실행하는 단 계를 포함하는, 추론성능 가속화방법을 제공한다. 본 발명의 실시예에 있어서, 상기 (A) 단계에서는, 상기 임계치 이내의 파라미터 값을 가수부로 설정하고, 상기 임계치를 초과하는 파라미터 값을 진수부로 설정할 수 있다. 본 발명의 실시예에 있어서, 상기 (B) 단계에서는, 상기 가수부 및 상기 진수부 각각을 설정된 단위의 추론 코 드로 압축 및/또는 변환할 수 있다.본 발명의 실시예에 있어서, 상기 추론 코드는 학습이 완료된 인공지능 추론 모델에 따라 디바이스, 정확도 (accuracy), 모델 크기, 지연 시간(latency), 압축 시간 및 에너지 소모량 중 적어도 하나의 항목에 대한 임계 값을 반영하는 코드를 포함할 수 있다. 본 발명의 실시예에 있어서, 상기 (C) 단계에서는, 상기 가수부 및 상기 진수부 각각에 대한 추론 코드가 적용 된 인공지능 추론 모델의 성능을 측정할 수 있다."}
{"patent_id": "10-2022-0131110", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따르면, 디바이스별 성능과 파라미터 값의 연계에 따른 효율화를 추구할 수 있다. 또한, 본 발명의 실시 예에 따르면, 디바이스별 성능에 따른 추론 성능을 효율적으로 활용하여 추론성능 가속화 를 제공할 수 있다."}
{"patent_id": "10-2022-0131110", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2022-0131110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여 본 발명을 설명하기로 한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며, 따라서 여기에서 설명하는 실시예로 한정되는 것은 아니다. 그리고 도면에서 본 발명을 명확 하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유 사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결(접속, 접촉, 결합)\"되어 있다고 할 때, 이는 \"직접적으로 연 결\"되어 있는 경우뿐 아니라, 그 중간에 다른 부재를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 구비할 수 있다는 것을 의미한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하 첨부된 도면을 참고하여 본 발명의 실시예를 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 추론성능 가속화시스템을 나타내는 도면이고, 도 2는 본 발명의 일 실시예 에 따른 엣지 디바이스의 구성을 나타내는 도면이며, 도 3은 본 발명의 일 실시예에 따른 서버의 구성을 나타내 는 도면이다. 도 1 내지 도 3을 참조하면, 본 발명의 일 실시예에 따른 추론모델 가속성능 향상시스템은 엣지 디바이스 및 서버를 포함할 수 있다. 상기 서버는 네트워크를 통해 엣지 디바이스와 통신할 수 있다. 여기서, 상기 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네 트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트 워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지 는 않는다. 상기 엣지 디바이스는 본 발명의 일 실시예에 따라 인공지능 추론 모델을 디바이스 상에 구현하려는 대상 장치를 의미할 수 있다. 예를 들면, 상기 엣지 디바이스는 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 무선 통신 장치일 수 있다. 또한, 상 기 엣지 디바이스는 임베디드 환경에서 구동하는 IoT 단말, 엣지 디바이스, 임베디드 보드 등을 의미하는 것일 수 있다. 본 발명의 일 실시예에서 상기 엣지 디바이스는 프로세서, 메모리, 메모리 컨트롤러 및 가 속기를 포함할 수 있다. 여기서, 프로세서, 메모리, 메모리 컨트롤러 및 가속기는 버 스(bus)를 통하여 서로 통신할 수 있다. 구체적으로, 상기 프로세서는 상기 엣지 디바이스에 포함된 컴포넌트들의 동작을 제어하는 장치로, 예를 들어, 중앙처리 장치(CPU; Central Processing Unit)를 포함할 수 있다. 이러한, 상기 프로세서는 뉴럴 네트워크에 기반한 추론 작업을 상기 가속기에서 처리하기 위한 요청을 수신하고, 해당 요청에 응답 하여 명령어를 상기 가속기로 전달할 수 있다. 요청은 뉴럴 네트워크에 기반한 데이터 추론을 위한 것으로, 예를 들어, 음성 인식, 기계번역, 기계 통역, 객체 인식, 패턴 인식, 컴퓨터 비전 등을 위해 상기 가속 기로 하여금 뉴럴 네트워크를 실행하게 하여 데이터 추론 결과를 얻기 위한 것일 수 있다. 상기 메모리는 상기 가속기의 외부에 배치된 메모리로서, 예를 들어, 메인 메모리로 활용되는 DRAM(Dynamic Random Access Memory)일 수 있다. 상기 메모리는 메모리 컨트롤러를 통해 액세스될 수 있다. 상기 메모리는 상기 가속기에서 실행할 명령어, 뉴럴 네트워크의 파라미터들, 추론하고자 하는 입력 데이터 중 적어도 하나를 저장할 수 있고, 상기 가속기에서 뉴럴 네트워크를 실행하는데 상기 가속기 내부의 온-칩 메모리(on-chip memory)가 충분하지 않은 경우에 활용될 수도 있다. 이를 위하여, 상 기 메모리는 상기 가속기 내부의 온-칩 메모리보다 큰 메모리 용량을 가지고 있으나, 뉴럴 네트워크 실행 시 상기 가속기가 상기 메모리로 액세스하는 비용이 내부의 온-칩 메모리로 액세스하는 비용보 다 상대적으로 크게 설정될 수 있다. 이때, 메모리 액세스 비용은 해당 메모리에 액세스하여 데이터를 읽거나 쓸 때 요구되는 전력 및/또는 처리시간을 나타낼 수 있다. 상기 가속기는 상기 프로세서의 명령어에 따른 뉴럴 네트워크를 실행하여 입력되는 데이터를 추론하 는 AI 가속기(Artificial Intelligence accelerator)로서, 상기 프로세서와 구별되는 별도의 전용 프로세 서일 수 있다. 예를 들어, 상기 가속기은 NPU(Neural Processing Unit), GPU, TPU(Tensor Processing Unit), CPU등으로 구현될 수 있다. 이러한 상기 가속기는 뉴럴 네트워크에 따른 연산들의 특성 상 범용의 상기 프로세서 보다 효율적으로 뉴럴 네트워크에서 추론 작업들을 처리할 수 있다. 뉴럴 네트워크는 복수의 레이어들을 포함할 수 있다. 예를 들면, 뉴럴 네트워크는 입력 레이어, 복수의 히든 레 이어들 및 출력 레이어를 포함할 수 있다. 이때, 각각의 레이어들은 인공 뉴런이라고도 불리는 복수의 노드들을 포함할 수 있다. 각 노드는 하나 이상의 입력 및 출력을 가지는 계산 단위를 나타내고, 노드들은 상호 연결될 수 있다. 노드들 간의 연결에는 가중치가 설정될 수 있으며, 이러한 가중치는 조정 또는 변경될 수 있다. 여기서, 가중치는 연관 된 데이터 값을 증폭, 감소 또는 유지시킴으로써 해당 데이터 값이 최종 결과에 미치는 영향도를 결정하는 파라 미터일 수 있다. 출력 레이어에 포함된 각각의 노드에는 이전 레이어에 포함된 노드들의 가중된 입력들이 입력 될 수 있다. 가중된 데이터가 임의의 레이어로부터 다음 레이어로 입력되는 과정을 전파(propagation)로 정의할수 있다. 뉴럴 네트워크의 추론 작업은 입력 데이터와 뉴럴 네트워크의 파라미터를 이용하여 뉴럴 네트워크에 따른 연산 들을 실행함으로써, 입력 데이터의 특성을 분석하는 작업일 수 있다. 뉴럴 네트워크의 추론 작업은 대용량의 데 이터를 분석하는 데 사용되며, 이 경우 변화하는 입력 데이터와 고정된 파라미터 값에 기반하여 많은 연산들이 수행될 수 있다. 상기 서버는 학습이 완료된 인공지능 추론 모델에 대한 데이터와, 인공지능 추론 모델이 실제로 수행될 상 기 엣지 디바이스의 컴퓨팅 환경 정보에 기초하여 인공지능 추론 모델(대상 추론 모델)에 대한 최적화 및/ 또는 경량화를 수행하여 대상 추론 모델과 연계된 인공지능 기능이 엣지 디바이스 상에서 구현되도록 지원 할 수 있다. 본 발명에서 추론성능 가속화 대상으로 하는 인공지능 추론(Inference) 모델은 미리 학습된 인공지능 모델을 상 기 엣지 디바이스에 최대한 효율적으로 실행시키기 위한 소프트웨어로서, 인공지능 실사용에 목적을 둔 기 술이며 탑재되는 장치의 환경에 효율성을 높이는 기능을 수행할 수 있다. 예컨대, 상기 엣지 디바이스가 모바일 기기의 경우, 모바일 기기의 컴퓨팅 환경인 느린 연산속도 및 저전력 사양에 맞춰 추론 모델이 구현될 수 있고, 상기 엣지 디바이스가 컴퓨팅 성능이 상대적으로 높은 PC 서버의 경우에는 고성능 병렬처리 능력 을 극대화시키도록 추론 모델이 구현될 수 있다. 이와 관련하여, 상기 서버는 인공지능 추론 모델을 이용하여 입력 데이터를 변환하는 데이터 변환부, 상기 엣지 디바이스별 연산 단위 및/또는 연산 속도에 맞춰 추론모델에 포함된 파라미터 값의 임계치를 설 정하는 파라미터 설정부, 설정된 임계치 이내의 파라미터 값을 설정된 단위의 추론 코드로 압축 및/또는 변환하는 추론코드 압축부, 및 추론 모델을 이용하여 추론을 실행하는 추론 실행부를 포함할 수 있다. 상기 데이터 변환부는 상기 엣지 디바이스에서 사용될 수 있는 형식으로 입력 데이터를 변환할 수 있 다. 예를 들면, 상기 데이터 변환부는 텐서플로우(TensorFlow), 파이토치(PyTorch), 케라스(Keras) 중 어 느 하나의 프레임워크에서 파일 포맷 변환(파이썬(Python), NNEF(Neural Network Exchange Format), ONNX(Open Neural Network eXchange format) 등), 정확도 변경 중 적어도 하나를 통해 상기 엣지 디바이스에서 사용 될 수 있는 형식으로 입력 데이터를 변환할 수 있다. 상기 파라미터 설정부는 상기 엣지 디바이스별 연산 단위 및/또는 연산 속도에 맞춰 추론모델에 포함 된 파라미터 값의 임계치를 설정할 수 있다. 이때, 파라미터 값은 추론모델에 포함된 파라미터들 중 어느 하나 의 값에 해당할 수 있다. 또한, 파라미터 값은 설정된 비트(자리수)의 디지털 코드로 이루어질 수 있다. 예를 들면, 파라미터 값은 128비트의 디지털 코드로 이루어지며, 상기 파라미터 설정부는 파라미터 값의 임계치 를 32비트의 디지털 코드로 설정할 수 있다. 또한, 상기 파라미터 설정부는 상기 임계치 이내의 파라미터 값을 가수부로 설정하고, 상기 임계치를 초과 하는 파라미터 값을 진수부로 설정할 수 있다. 상기 추론코드 압축부는 상기 파라미터 설정부에서 설정된 임계치 이내의 파라미터 값 및 임계치를 초과하는 파라미터 값 각각을 설정된 단위의 추론 코드로 압축 및/또는 변환할 수 있다. 예를 들면, 상기 추론 코드 압축부는 총 128비트의 디지털 코드 중 임계치 32비트 이내의 디지털 코드(가수부)와 임계치를 초과 하는 디지털 코드(진수부) 각각을 4비트 또는 8비트의 추론 코드로 압축 및/또는 변환할 수 있다. 상기 추론 코드는 학습이 완료된 인공지능 추론 모델에 따라 설정될 수 있으며, 상기 엣지 디바이스의 환 경 정보에 따라 분류된 템플릿에 맞춰 압축 및/또는 변환될 수 있다. 여기서, 템플릿은 인공지능 추론 모델별로 미리 설정된 추론 코드를 제공하는 기능을 의미할 수 있다. 예를 들면, 상기 추론 코드는 디바이스, 정확도 (accuracy), 모델 크기, 지연 시간(latency), 압축 시간 및 에너지 소모량 중 적어도 하나의 항목에 대한 임계 값을 반영하는 코드를 포함할 수 있다. 또한, 상기 추론코드 압축부는 가수부 및 진수부 각각에 대한 추론 코드를 상기 추론 실행부에 전달 할 수 있다. 상기 추론 실행부는 가수부 및 진수부 각각에 대한 추론 코드를 인공지능 추론 모델에 적용하여 추론을 실 행할 수 있다. 여기서, 상기 추론 실행부는 가수부 및 진수부 각각에 대한 추론 코드가 적용된 인공지능 추론 모델의 성능(예컨대 지연시간, 정확도 등)을 측정할 수 있다. 이러한 상기 추론 실행부는 측정된 성능을 사용자에게 제공할 수 있다. 이하에서는, 본 발명의 일 실시예에 따른 추론성능 가속화시스템의 서버에 의해 수행되는 추론성능 가속화방법 을 설명한다. 도 3은 본 발명의 일 실시예에 따른 추론성능 가속화방법을 나타내는 도면이다. 도 3을 참조하면, 본 발명의 일 실시예에 따른 추론성능 가속화방법은 엣지 디바이스별 연산 단위 및/또는 연산 속도에 따라 추론모델에 포함된 파라미터 값의 임계치를 설정하는 단계(S100), 상기 임계치 이내의 파라미터 값 및 상기 임계치를 초과하는 파라미터 값 각각을 설정된 단위의 추론 코드로 압축 및/또는 변환하는 단계(S200), 및 상기 추론 모델에 상기 추론 코드를 적용하여 추론을 실행하는 단계(S300)를 포함할 수 있다. 우선, 단계 S100에서는, 파라미터 설정부가 엣지 디바이스별 연산 단위 및/또는 연산 속도에 맞춰 추론모델에 포함된 파라미터 값의 임계치를 설정할 수 있다. 여기서, 파라미터 설정부는 임계치 이내의 파라미터 값을 가수 부로 설정하고, 임계치를 초과하는 파라미터 값을 진수부로 설정할 수 있다. 다음, 단계 S200에서는, 추론코드 압축부가 파라미터 설정부에서 설정된 임계치 이내의 파라미터 값 및 임계치 를 초과하는 파라미터 값 각각을 설정된 단위의 추론 코드로 압축 및/또는 변환할 수 있다. 또한, 추론모델 압 축부는 가수부 및 진수부 각각에 대한 추론 코드를 추론 실행부에 전달할 수 있다. 여기서, 상기 추론 코드는 학습이 완료된 인공지능 추론 모델에 따라 디바이스, 정확도(accuracy), 모델 크기, 지연 시간(latency), 압축 시간 및 에너지 소모량 중 적어도 하나의 항목에 대한 임계값을 반영하는 코드를 포 함하여 설정될 수 있다. 다음, 단계 S300에서는, 추론 실행부가 가수부 및 진수부 각각에 대한 추론 코드를 인공지능 추론 모델에 적용 하여 추론을 실행할 수 있다. 여기서, 추론 실행부는 가수부 및 진수부 각각에 대한 추론 코드가 적용된 인공지 능 추론 모델의 성능(예컨대 지연시간, 정확도 등)을 측정하고, 측정된 성능을 사용자에게 제공할 수 있다. 본 발명의 실시 예에 따르면, 디바이스별 성능과 파라미터 값의 연계에 따른 효율화를 추구할 수 있다. 또한, 본 발명의 실시 예에 따르면, 디바이스별 성능에 따른 추론 성능을 효율적으로 활용하여 추론성능 가속화 를 제공할 수 있다. 본 발명의 실시예들에 따른 추론성능 가속화방법은 적어도 하나의 컴퓨터 장치에 의해 구현될 수 있다. 이때, 컴퓨터 장치에는 본 발명의 일실시예에 따른 컴퓨터 프로그램이 설치 및 구동될 수 있고, 컴퓨터 장치는 구동된 컴퓨터 프로그램의 제어에 따라 본 발명의 실시예들에 따른 추론성능 가속화방법을 수행할 수 있다. 상술한 컴 퓨터 프로그램은 컴퓨터 장치와 결합되어 추론성능 가속화방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장될 수 있다."}
{"patent_id": "10-2022-0131110", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2022-0131110", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 추론성능 가속화시스템을 나타내는 도면이다. 도 2는 본 발명의 일 실시예에 따른 엣지 디바이스의 구성을 나타내는 도면이다. 도 3은 본 발명의 일 실시예에 따른 서버의 구성을 나타내는 도면이다. 도 4는 본 발명의 일 실시예에 따른 추론성능 가속화방법을 나타내는 도면이다."}
