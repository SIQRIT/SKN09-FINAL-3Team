{"patent_id": "10-2022-0046677", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0054754", "출원번호": "10-2022-0046677", "발명의 명칭": "시선 추적 방법, 장치, 모델 트레이닝 방법 및 장치, 단말 기기, 컴퓨터 판독 가능한 저장 매", "출원인": "아폴로 인텔리전트 커넥티비티", "발명자": "덩, 수난"}}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 이미지를 획득하는 단계 - 상기 제1 이미지는 운전자의 안구 상태 이미지를 포함함 -; 및사전 트레이닝한 시선 캘리브레이션 모델을 기반으로, 월드 좌표계 중 상기 제1 이미지에 대응되는 주시 영역을결정하는 단계를 포함하는 시선 추적 방법."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 주시 영역을 결정하는 단계는,상기 제1 이미지를 사전 트레이닝한 시선 캘리브레이션 모델에 입력하여, 상기 제1 이미지에 대응되는 시선 방향을 획득하는 단계; 및월드 좌표계 중 상기 시선 방향에 대응되는 주시 영역을 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서,제2 이미지를 획득하는 단계 - 상기 제2 이미지는 상기 운전자 탑승 차량의 주변 환경 이미지를 포함함 -; 및월드 좌표계와 상기 제2 이미지에 대응되는 이미지 좌표계 사이의 대응 관계를 기반으로, 상기 제2 이미지 중상기 제1 타깃 영역에 대응되는 제2 타깃 영역을 결정하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제2 타깃 영역 중의 관심 지점(POI) 객체를 결정하는 단계; 및상기 이미지 좌표계와 헤드업 디스플레이 화면에 대응되는 디스플레이 좌표계 사이의 대응 관계를 기반으로, 상기 헤드업 디스플레이 화면에서 상기 POI 객체의 타깃 표시 위치를 결정하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제2 타깃 영역 중의 관심 지점(POI) 객체를 결정하는 단계 이후에, 상기 차량의 현재 위치 정보를 획득하는 단계;상기 현재 위치 정보를 기반으로 상기 POI 객체의 속성 정보를 획득하는 단계; 및상기 속성 정보를 상기 헤드업 디스플레이 화면 중의 상기 POI 객체에 중첩되게 표시하는 단계를 더 포함하는방법."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "트레이닝 샘플 세트를 획득하는 단계 - 상기 트레이닝 샘플 세트 중의 트레이닝 샘플은 운전자가 마크업 포인트를 주시하는 경우의 안구 이미지와 상기 마크업 포인트의 위치 정보를 포함함 -; 및상기 안구 이미지를 입력으로 하고, 상기 위치 정보를 출력으로 하여, 트레이닝을 통해 시선 캘리브레이션 모델을 획득하는 단계를 포함하는 모델 트레이닝 방법."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2022-0054754-3-제1 이미지를 획득하는 제 1 획득 모듈 - 상기 제1 이미지는 운전자의 안구 상태 이미지를 포함함 -; 및사전 트레이닝한 시선 캘리브레이션 모델을 기반으로, 월드 좌표계 중 상기 제1 이미지에 대응되는 주시 영역을결정하는 제1 결정 모듈을 포함하는 시선 추적 장치."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제1 결정 모듈은,상기 제1 이미지를 사전 트레이닝한 시선 캘리브레이션 모델에 입력하여 상기 제1 이미지에 대응되는 시선 방향을 획득하는 입력 서브 모듈; 및월드 좌표계 중 상기 시선 방향에 대응되는 주시 영역을 결정하는 결정 서브 모듈을 포함하는 장치."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항 또는 제8항에 있어서,제2 이미지를 획득하는 제 2 획득 모듈 - 상기 제2 이미지는 상기 운전자 탑승 차량의 주변 환경 이미지를 포함함 -; 및상기 월드 좌표계와 상기 제2 이미지에 대응되는 이미지 좌표계 사이의 대응 관계를 기반으로, 상기 제2 이미지중 상기 제1 타깃 영역에 대응되는 제2 타깃 영역을 결정하는 제2 결정 모듈을 더 포함하는 장치."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제2 타깃 영역 중의 관심 지점(POI) 객체를 결정하는 제3 결정 모듈; 및상기 이미지 좌표계와 헤드업 디스플레이 화면에 대응되는 디스플레이 좌표계 사이의 대응 관계를 기반으로, 상기 POI 객체가 상기 헤드업 디스플레이 화면 중의 타깃 표시 위치를 결정하는 제4 결정 모듈을 더 포함하는 장치."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 차량의 현재 위치 정보를 획득하는 제3 획득 모듈;상기 현재 위치 정보를 기반으로, 상기 POI 객체의 속성 정보를 획득하는 제4 획득 모듈; 및상기 속성 정보를 상기 헤드업 디스플레이 화면 중의 상기 POI 객체에 중첩되게 표시하는 표시 모듈을 더 포함하는 장치."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "트레이닝 샘플 세트를 획득하는 제 5 획득 모듈 - 상기 트레이닝 샘플 세트 중의 트레이닝 샘플은 운전자가 마크업 포인트를 주시하는 경우의 안구 이미지와 상기 마크업 포인트의 위치 정보를 포함함 -; 및상기 안구 이미지를 입력으로 하고, 상기 위치 정보를 출력으로 하고, 트레이닝을 통해 시선 캘리브레이션 모델을 획득하는 트레이닝 모듈을 포함하는 모델 트레이닝 장치."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "단말 기기로서,적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하고,상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령은 상기 적어도하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제5항 중 어느 한 항에 따른 방공개특허 10-2022-0054754-4-법을 구현하는 전자 기기."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨터 명령이 저장된 비 일시적 컴퓨터 판독 가능 저장 매체로서,상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제5항 중 어느 한 항에 따른 방법을 구현하는 비 일시적 컴퓨터판독 가능 저장 매체."}
{"patent_id": "10-2022-0046677", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우 제1항 내지 제5항 중 어느 한 항에 따른 방법을 구현하는컴퓨터 프로그램."}
{"patent_id": "10-2022-0046677", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공 지능"}
{"patent_id": "10-2022-0046677", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것으로, 구체적으로 스마트 교통과 딥러닝 기술 분야에 관한 것이며, 시 선 추적 방법, 장치, 모델 트레이닝 방법 및 장치, 단말 기기, 컴퓨터 판독 가능한 저장 매체 및 컴퓨터 프로그 램을 제공한다. 상기 방법의 일 구체적인 실시형태는, 제1 이미지를 획득하되, 제1 이미지는 운전자의 안구 상태 이미지인 단계; 및 사전 트레이닝한 시선 캘리브레이션 모델을 기반으로, 월드 좌표계 중 제1 이미지에 대응되는 주시 영역을 결정하는 단계를 포함한다. 상기 실시형태는 운전자의 안구 상태 이미지를 기반으로, 월드 좌표계 중의 대응 영역을 결정함으로써, 운전자의 시선에 대해 캘리브레이션이 가능하다. 대 표 도 - 도2"}
{"patent_id": "10-2022-0046677", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2022-0054754 CPC특허분류 G02B 27/0101 (2013.01) G02B 27/0179 (2013.01) G06F 3/005 (2013.01) G06F 3/04812 (2022.01) G06K 9/6256 (2022.01) G02B 2027/0187 (2013.01)명 세 서 청구범위 청구항 1 제1 이미지를 획득하는 단계 - 상기 제1 이미지는 운전자의 안구 상태 이미지를 포함함 -; 및 사전 트레이닝한 시선 캘리브레이션 모델을 기반으로, 월드 좌표계 중 상기 제1 이미지에 대응되는 주시 영역을 결정하는 단계를 포함하는 시선 추적 방법. 청구항 2 제1항에 있어서, 상기 주시 영역을 결정하는 단계는, 상기 제1 이미지를 사전 트레이닝한 시선 캘리브레이션 모델에 입력하여, 상기 제1 이미지에 대응되는 시선 방 향을 획득하는 단계; 및 월드 좌표계 중 상기 시선 방향에 대응되는 주시 영역을 결정하는 단계를 포함하는 방법. 청구항 3 제1항 또는 제2항에 있어서, 제2 이미지를 획득하는 단계 - 상기 제2 이미지는 상기 운전자 탑승 차량의 주변 환경 이미지를 포함함 -; 및 월드 좌표계와 상기 제2 이미지에 대응되는 이미지 좌표계 사이의 대응 관계를 기반으로, 상기 제2 이미지 중 상기 제1 타깃 영역에 대응되는 제2 타깃 영역을 결정하는 단계를 더 포함하는 방법. 청구항 4 제3항에 있어서, 상기 제2 타깃 영역 중의 관심 지점(POI) 객체를 결정하는 단계; 및 상기 이미지 좌표계와 헤드업 디스플레이 화면에 대응되는 디스플레이 좌표계 사이의 대응 관계를 기반으로, 상 기 헤드업 디스플레이 화면에서 상기 POI 객체의 타깃 표시 위치를 결정하는 단계를 더 포함하는 방법. 청구항 5 제4항에 있어서, 상기 제2 타깃 영역 중의 관심 지점(POI) 객체를 결정하는 단계 이후에, 상기 차량의 현재 위치 정보를 획득하는 단계; 상기 현재 위치 정보를 기반으로 상기 POI 객체의 속성 정보를 획득하는 단계; 및 상기 속성 정보를 상기 헤드업 디스플레이 화면 중의 상기 POI 객체에 중첩되게 표시하는 단계를 더 포함하는 방법. 청구항 6 트레이닝 샘플 세트를 획득하는 단계 - 상기 트레이닝 샘플 세트 중의 트레이닝 샘플은 운전자가 마크업 포인트 를 주시하는 경우의 안구 이미지와 상기 마크업 포인트의 위치 정보를 포함함 -; 및 상기 안구 이미지를 입력으로 하고, 상기 위치 정보를 출력으로 하여, 트레이닝을 통해 시선 캘리브레이션 모델 을 획득하는 단계를 포함하는 모델 트레이닝 방법. 청구항 7 제1 이미지를 획득하는 제 1 획득 모듈 - 상기 제1 이미지는 운전자의 안구 상태 이미지를 포함함 -; 및 사전 트레이닝한 시선 캘리브레이션 모델을 기반으로, 월드 좌표계 중 상기 제1 이미지에 대응되는 주시 영역을 결정하는 제1 결정 모듈을 포함하는 시선 추적 장치. 청구항 8 제7항에 있어서, 상기 제1 결정 모듈은, 상기 제1 이미지를 사전 트레이닝한 시선 캘리브레이션 모델에 입력하여 상기 제1 이미지에 대응되는 시선 방향 을 획득하는 입력 서브 모듈; 및 월드 좌표계 중 상기 시선 방향에 대응되는 주시 영역을 결정하는 결정 서브 모듈을 포함하는 장치. 청구항 9 제7항 또는 제8항에 있어서, 제2 이미지를 획득하는 제 2 획득 모듈 - 상기 제2 이미지는 상기 운전자 탑승 차량의 주변 환경 이미지를 포함 함 -; 및 상기 월드 좌표계와 상기 제2 이미지에 대응되는 이미지 좌표계 사이의 대응 관계를 기반으로, 상기 제2 이미지 중 상기 제1 타깃 영역에 대응되는 제2 타깃 영역을 결정하는 제2 결정 모듈을 더 포함하는 장치. 청구항 10 제9항에 있어서, 상기 제2 타깃 영역 중의 관심 지점(POI) 객체를 결정하는 제3 결정 모듈; 및 상기 이미지 좌표계와 헤드업 디스플레이 화면에 대응되는 디스플레이 좌표계 사이의 대응 관계를 기반으로, 상 기 POI 객체가 상기 헤드업 디스플레이 화면 중의 타깃 표시 위치를 결정하는 제4 결정 모듈을 더 포함하는 장 치. 청구항 11 제10항에 있어서, 상기 차량의 현재 위치 정보를 획득하는 제3 획득 모듈; 상기 현재 위치 정보를 기반으로, 상기 POI 객체의 속성 정보를 획득하는 제4 획득 모듈; 및 상기 속성 정보를 상기 헤드업 디스플레이 화면 중의 상기 POI 객체에 중첩되게 표시하는 표시 모듈을 더 포함 하는 장치. 청구항 12 트레이닝 샘플 세트를 획득하는 제 5 획득 모듈 - 상기 트레이닝 샘플 세트 중의 트레이닝 샘플은 운전자가 마 크업 포인트를 주시하는 경우의 안구 이미지와 상기 마크업 포인트의 위치 정보를 포함함 -; 및 상기 안구 이미지를 입력으로 하고, 상기 위치 정보를 출력으로 하고, 트레이닝을 통해 시선 캘리브레이션 모델 을 획득하는 트레이닝 모듈을 포함하는 모델 트레이닝 장치. 청구항 13 단말 기기로서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제5항 중 어느 한 항에 따른 방법을 구현하는 전자 기기. 청구항 14 컴퓨터 명령이 저장된 비 일시적 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제5항 중 어느 한 항에 따른 방법을 구현하는 비 일시적 컴퓨터 판독 가능 저장 매체. 청구항 15 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우 제1항 내지 제5항 중 어느 한 항에 따른 방법을 구현하는 컴퓨터 프로그램. 발명의 설명 기 술 분 야 본 발명은 컴퓨터 분야에 관한 것으로, 구체적으로 스마트 교통, 딥러닝과 같은 인공 지능 분야에 관한 것이며, 특히 시선 추적 방법, 장치, 모델 트레이닝 방법 및 장치, 단말 기기, 컴퓨터 판독 가능한 저장 매체 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2022-0046677", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "시선 추적은 컴퓨터 비전과 컴퓨터 그래픽 분야에서 중요하고 기초적인 문제로, 인간-컴퓨터 인터랙션, 가상 현 실 및 증강 현실 등의 분야에서도 매우 널리 사용된다. 예를 들어, 컴퓨터 비전에서 안구가 스크린을 주시하는 위치는 다양한 인간-컴퓨터 인터랙션 기능을 완성하는데 사용될 수 있고, 증강 현실에서, 시선 방향은 디스플레 이되는 콘텐츠를 보다 사실감 있게 조정하는데 사용 가능하다. 눈은 인간의 풍부한 감정을 표현 가능하기 때문 에, 안구 시선을 추적하는 연구는 매우 높은 연구와 응용 가치가 있다. 컴퓨터 그래픽과 컴퓨터 비전 분야에서, 높은 정밀도의 시선 방향 추적은 항상 중요하고 어려운 문제이다."}
{"patent_id": "10-2022-0046677", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 시선 추적 방법, 장치, 모델 트레이닝 방법 및 장치, 단말 기기, 컴퓨터 판독 가능한 저장 매체 및 컴퓨터 프로그램을 제공한다."}
{"patent_id": "10-2022-0046677", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 제1 양태에 따르면, 제1 이미지를 획득하되, 제1 이미지는 운전자의 안구 상태 이미지인 단계; 및 사 전 트레이닝한 시선 캘리브레이션 모델을 기반으로, 월드 좌표계 중 제1 이미지에 대응되는 주시 영역을 결정하 는 단계를 포함하는 시선 추적 방법을 제공한다. 본 발명의 제2 양태에 따르면, 트레이닝 샘플 세트를 획득하되, 트레이닝 샘플 세트 중의 트레이닝 샘플은 운전 자가 마크업 포인트를 주시하는 경우의 안구 이미지와 마크업 포인트의 위치 정보를 포함하는 단계; 및 안구 이 미지를 입력으로 하고, 위치 정보를 출력으로 하여, 트레이닝을 통해 시선 캘리브레이션 모델을 획득하는 단계 를 포함하는 모델 트레이닝 방법을 제공한다. 본 발명의 제3 양태에 따르면, 제1 이미지를 획득하도록 구성되되, 제1 이미지는 운전자의 안구 상태 이미지인 제1 획득 모듈; 및 사전 트레이닝한 시선 캘리브레이션 모델을 기반으로, 월드 좌표계 중 제1 이미지에 대응되 는 주시 영역을 결정하도록 구성되는 제1 결정 모듈을 포함하는 시선 추적 장치를 제공한다. 본 발명의 제4 양태에 따르면, 트레이닝 샘플 세트를 획득되되, 트레이닝 샘플 세트 중의 트레이닝 샘플은 운전 자가 마크업 포인트를 주시하는 경우의 안구 이미지와 마크업 포인트의 위치 정보를 포함하도록 구성되는 제5 획득 모듈; 및 안구 이미지를 입력으로 하고, 위치 정보를 출력으로 하여, 트레이닝을 통해 시선 캘리브레이션 모델을 획득하도록 구성되는 트레이닝 모듈을 포함하는 모델 트레이닝 장치를 제공한다.본 발명의 제5 양태에 따르면, 적어도 하나의 프로세서; 및 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하되; 메모리에는 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 명령은 적어도 하나의 프 로세서에 의해 실행되어, 적어도 하나의 프로세서가 제1 양태 중 어느 하나의 실시형태에 설명된 바와 같은 방 법을 구현할 수 있도록 하는 전자 기기를 제공한다. 본 발명의 제6 양태에 따르면, 컴퓨터 명령이 저장된 비 일시적 컴퓨터 판독 가능 저장 매체를 제공하되, 컴퓨 터 명령은 컴퓨터가 제1 양태 또는 제2 양태 중 어느 하나의 실시형태에 설명된 바와 같은 방법을 구현할 수 있 도록 하는데 사용된다. 본 발명의 제7 양태에 따르면, 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램을 제공하되, 컴퓨터 프로그램이 프 로세서에 의해 실행될 경우 제1 양태 또는 제2 양태 중 어느 하나의 실시형태에 설명된 바와 같은 방법을 구현 할 수 있다. 본 부분에서 설명된 내용은 본 발명의 실시예의 핵심 또는 중요한 특징을 식별하기 위한 것이 아니며, 본 발명 의 범위를 한정하려는 의도도 아님을 이해해야 할 것이다. 본 발명의 다른 특징은 아래 명세서에 의해 쉽게 이 해될 것이다."}
{"patent_id": "10-2022-0046677", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래 첨부된 도면을 참조하여 본 발명의 예시적 실시예를 설명하되, 여기에는 이해를 돕기 위한 본 발명의 실시"}
{"patent_id": "10-2022-0046677", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예의 다양한 세부 사항이 포함되며, 이들은 단지 예시적인 것으로 간주되어야 한다. 따라서, 본 기술분야의 통 상의 기술자는 본 발명의 범위와 사상을 벗어나지 않으면서, 여기서 설명되는 실시예에 대해 다양한 변경과 수 정이 이루어질 수 있음을 이해해야 한다. 마찬가지로, 명확성 및 간결성을 위해, 아래의 설명에서 공지된 기능 과 구조에 대한 설명을 생략한다. 모순되지 않는 한, 본 발명의 실시예 및 실시예의 특징은 서로 결합될 수 있음에 유의해야 한다. 아래 첨부 도 면과 실시예를 참조하여 본 발명을 상세히 설명하기로 한다. 도 1은 본 발명의 시선 추적 방법, 또는 시선 추적 장치의 실시예가 적용될 수 있는 예시적 시스템 아키텍처 를 도시한다. 도 1에 도시된 바와 같이, 시스템 아키텍처는 단말 기기(101, 102, 103), 네트워크 및 서버를 포함할 수 있다. 네트워크는 단말 기기(101, 102, 103)와 서버 사이에서 통신 링크를 제공하는 매체 로 사용된다. 네트워크는 유선, 무선 통신 링크 또는 광섬유 케이블 등과 같은 다양한 연결 타입을 포함할 수 있다. 사용자는 단말 기기(101, 102, 103)를 사용하여 네트워크를 통해 서버와 인터랙션함으로써 정보 등을 수신 또는 송신할 수 있다. 단말 기기(101, 102, 103)에는 다양한 클라이언트 애플리케이션이 설치될 수 있다. 단말 기기(101, 102, 103)는 하드웨어일 수 있고 소프트웨어일 수도 있다. 단말 기기(101, 102, 103)가 하드웨 어인 경우 다양한 전자 기기일 수 있으며, 스마트폰, 태블릿PC, 휴대형 랩톱 및 데스크톱 등을 포함하지만 이에한정되는 것은 아니다. 단말 기기(101, 102, 103)가 소프트웨어인 경우, 상기 열거된 전자 기기에 설치될 수 있 다. 이는 복수개의 소프트웨어 또는 소프트웨어 모듈로 구현되거나, 하나의 소프트웨어 또는 소프트웨어 모듈로 구현될 수 있다. 여기서는 구체적으로 한정하지 않는다. 서버는 다양한 서비스를 제공할 수 있다. 예를 들면 서버는 단말 기기(101, 102, 103)로부터 획득한 제1 이미지를 분석 및 처리하고, 처리 결과(예를 들면 주시 영역)를 생성할 수 있다. 서버는 하드웨어 또는 소프트웨어일 수 있다. 서버가 하드웨어인 경우 복수개의 서버로 구성된 분산 형 서버 클러스터로 구현될 수 있고, 하나의 서버로 구현될 수도 있다. 서버가 소프트웨어인 경우 복수개 의 소프트웨어 또는 소프트웨어 모듈(예를 들면 분산형 서비스를 제공함)로 구현되거나, 하나의 소프트웨어 또 는 소프트웨어 모듈로 구현될 수 있다. 여기서는 구체적으로 한정하지 않는다. 본 발명의 실시예가 제공하는 시선 추적 방법은 일반적으로 서버에 의해 수행되고, 상응하게, 시선 추적 장치는 일반적으로 서버에 설치된다. 도 1 중의 단말 기기, 네트워크 및 서버의 개수는 단지 예시적인 것이며, 실제 필요에 따라 임의의 개수의 단말 기기, 네트워크 및 서버를 구비할 수 있다. 계속해서 도 2를 참조하면, 도 2는 본 발명에 따른 시선 추적 방법의 일 실시예의 프로세스를 도시한다. 상기 시선 추적 방법은 하기와 같은 단계를 포함한다. 단계에서, 제1 이미지를 획득한다. 본 실시예에서, 시선 추적 방법의 수행 주체(예를 들어 도 1에 도시된 서버)에 의해 제1 이미지를 획득할 수 있고, 상기 제1 이미지는 운전자의 안구 상태 이미지이다. 제1 이미지는 운전자가 탑승한 차량 내의 이미지 센서에 의해 수집되어 획득된 것으로서, 본 실시예의 이미지 센서는 카메라 센서(이하 카메라라고 함)일 수 있고, 실제 상황에 따라 기타 이미지 센서를 사용할 수도 있으며, 본 발명은 이에 대해 한정하지 않는다. 상기 카메라는 운전자의 안구 상태 이미지를 실시간으로 촬영할 수 있다. 단계에서, 사전 트레이닝한 시선 캘리브레이션 모델을 기반으로, 월드 좌표계 중 상기 제1 이미지에 대응 되는 주시 영역을 결정한다. 본 실시예에서, 상기 수행 주체는 사전 트레이닝한 시선 캘리브레이션 모델을 기반으로 월드 좌표계 중 제1 이 미지에 대응되는 주시 영역을 결정할 수 있다. 시선 캘리브레이션 모델은 사전 트레이닝한 모델일 수 있고, 운 전자의 안구 상태를 나타내는 제1 이미지를 상기 사전 트레이닝한 시선 캘리브레이션 모델에 입력하여 상기 제1 이미지에 대응되는 운전자의 주시 방향을 결정할 수 있으며, 결정된 주시 방향을 기반으로 월드 좌표계 중 제1 이미지에 대응되는 주시 영역을 결정하고, 상기 주시 영역이 바로 최종 결정할 운전자가 관심을 가지는 영역이 므로 운전자의 시선에 대한 추적을 구현한다. 월드 좌표계는 시스템의 절대 좌표계로 사용자 좌표계가 구축되기 전까지는 화면에 있는 모든 픽셀의 좌표가 상 기 좌표계의 원점에 의해 각각의 위치를 결정한다. 본 발명의 실시예예서 제공하는 시선 추적 방법은 운전자의 안구 상태를 나타내는 제1 이미지를 획득한 다음, 사전 트레이닝한 시선 캘리브레이션 모델을 기반으로 월드 좌표계 중 제1 이미지에 대응되는 주시 영역을 결정 한다. 본 발명은 시선 추적 방법을 제공하고, 상기 방법은 사전 트레이닝한 시선 캘리브레이션 모델을 기반으로 운전자의 시선에 대해 캘리브레이션 가능하므로, 운전자 시선 중의 물체 또는 객체에 대한 추적을 구현하여 시 선 추적의 정확성을 향상시킨다. 계속해서 도 3을 참조하면, 도 3은 본 발명에 따른 시선 추적 방법의 다른 실시예의 프로세스를 도시한다. 상기 시선 추적 방법은 하기와 같은 단계를 포함한다. 단계에서, 제1 이미지를 획득한다. 단계는 전술한 실시예의 단계와 기본적으로 동일하므로 구체적인 실시형태는 전술한 단계에 대 한 설명을 참조할 수 있으며 여기서 더이상 반복 설명하지 않는다. 단계에서, 제1 이미지를 사전 트레이닝한 시선 캘리브레이션 모델에 입력하여, 제1 이미지에 대응되는 시 선 방향을 획득한다.본 실시예에서, 시선 추적 방법의 수행 주체(예를 들어 도 1에 도시된 서버)는 제1 이미지를 사전 트레이 닝한 시선 캘리브레이션 모델에 입력하여, 제1 이미지에 대응되는 시선 방향을 획득할 수 있다. 운전자가 주행도로 양쪽에 있는 상이한 건물들을 바라볼 때 그 시선 방향은 상이하며, 그 대응되는 안구의 방향 정보도 상이하므로, 본 실시예에서, 운전자의 안구 상태를 나타내는 제1 이미지를 사전 트레이닝한 시선 캘리브 레이션 모델에 입력하여, 제1 이미지에 대응되는 시선 방향을 획득함으로써, 이때 운전자의 시선 방향을 결정한 다. 단계에서, 월드 좌표계 중 시선 방향에 대응되는 주시 영역을 결정한다. 본 실시예에서, 상기 수행 주체는 월드 좌표계 중 시선 방향에 대응되는 주시 영역을 결정할 수 있다. 월드 좌 표계는 현실 세계의 좌표계로서, 운전자의 시선 방향을 결정한 후에 시선 방향을 기반으로 현실 좌표계 중의 주 시 영역을 결정할 수 있으며, 상기 주시 영역은 시선 방향에 대응된다. 예를 들어 운전자의 시선 방향이 좌측 전방으로 결정된 후 월드 좌표계 중 좌측 전방에 대응되는 영역을 그 주시 영역으로 결정할 수 있다. 도 3에 도시된 바와 같이, 도 2에 대응되는 실시예와 비교했을 때, 본 실시예의 시선 추적 방법은 시선 캘리브 레이션 모델의 트레이닝 단계를 강조하였고, 상기 시선 캘리브레이션 모델을 기반으로 제1 이미지에 대응되는 시선 방향을 결정한 이후에, 월드 좌표계 중 시선 방향에 대응되는 주시 영역을 결정하고, 상기 방법은 시선 캘 리브레이션의 정확성을 향상하였고, 적용 범위가 더 넓다. 계속해서 도 4를 참조하면, 도 4는 본 발명에 따른 시선 추적 방법의 또 다른 실시예의 프로세스를 도시한 다. 상기 시선 추적 방법은 하기와 같은 단계를 포함한다. 단계에서, 제1 이미지를 획득한다. 단계에서, 제1 이미지를 사전 트레이닝한 시선 캘리브레이션 모델에 입력하여 제1 이미지에 대응되는 시선 방향을 획득한다. 단계에서, 월드 좌표계 중 시선 방향에 대응되는 주시 영역을 결정한다. 단계 내지 단계는 전술한 실시예의 단계 내지 단계와 기본적으로 동일하므로 구체적인 실 시형태는 전술한 단계 내지 단계에 대한 설명을 참조할 수 있으며, 여기서 더이상 반복 설명하지 않 는다. 단계에서, 제2 이미지를 획득한다. 본 실시예에서, 시선 추적 방법의 수행 주체(예를 들어 도 1에 도시된 서버)는 제2 이미지를 획득하되, 제 2 이미지는 운전자 탑승 차량의 주변 환경 이미지이다. 제2 이미지는 운전자가 탑승한 차량 내의 다른 카메라에 의해 수집하여 획득된 것으로서, 운전자가 탑승한 차량 내에 2개의 카메라를 설치할 수도 있으며, 하나는 내측을 향해 운전자의 안구 상태 이미지를 수집할 수 있고, 다른 하나는 외측을 향해 운전자가 탑승한 차량의 주변 환경 이미지를 수집할 수 있으며, 실제 상황에 따라 다 른 개수의 카메라를 설치할 수 있음은 물론이고, 본 발명은 이에 대해 구체적으로 한정하지 않는다. 제2 이미지는 상기 차량의 주행도로 양쪽에 있는 다양한 건물들을 포함할 수 있고, 장애물 등을 더 포함할 수 있다. 단계에서, 월드 좌표계와 제2 이미지에 대응되는 이미지 좌표계 사이의 대응 관계를 기반으로, 제2 이미지 중 제1 타깃 영역에 대응되는 제2 타깃 영역을 결정한다. 본 실시예에서, 상기 수행 주체는 월드 좌표계와 제2 이미지에 대응되는 이미지 좌표계 사이의 대응 관계를 기 반으로， 제2 이미지 중 제1 타깃 영역에 대응되는 제2 타깃 영역을 결정할 수 있다. 제2 이미지가 현실 환경에서 물체의 이미지를 촬영하였기 때문에 제2 이미지와 월드 좌표계는 대응되고, 제2 이 미지에도 하나의 이미지 좌표계가 있으므로, 월드 좌표계와 제2 이미지에 대응되는 이미지 좌표계 사이의 대응 관계를 기반으로, 제2 이미지 중 제1 타깃 영역에 대응되는 제2 타깃 영역을 결정할 수 있다. 제2 타깃 영역은 제2 이미지 중 운전자의 시선 방향에 대응되는 영역이다. 카메라가 수집한 데이터 이미지는 컴퓨터에 어레이 형태로 저장될 수 있고, 어레이 중 각 요소(픽셀, pixel)의 값이 바로 이미지 포인트의 휘도(그레이 스케일)이다. 이미지에서 직교 좌표계 u-v를 정의하고, 각 픽셀의 좌표(u, v)는 각각 어레이에서 상기 픽셀의 열수 및 행수이다. 따라서 (u, v)는 픽셀 단위의 이미지 좌표계의 좌표 이다. 단계에서, 제2 타깃 영역 중의 POI 객체를 결정한다. 본 실시예에서, 상기 수행 주체는 제2 타깃 영역 중의 POI(Point of Interest, 관심 지점) 객체를 결정할 수 있 다. 제2 타깃 영역은 제2 이미지 중 운전자의 시선 방향에 대응되는 영역이기 때문에, 제2 타깃 영역이 바로 운 전자의 주시 영역이므로, 제2 영역 중의 타깃 객체가 바로 본 실시예 중의 POI 객체이고, 즉 운전자가 주시하는 객체이다. 따라서 상기 수행 주체는 제2 타깃 영역 중의 POI 객체를 결정할 수 있다. 본 실시예의 일부 선택 가능한 실시형태에서, 상기 시선 추적 방법은 차량의 현재 위치 정보를 획득하는 단계; 및 현재 위치 정보를 기반으로 POI 객체의 속성 정보를 획득하는 단계를 더 포함한다. 본 실시형태에서, 상기 수행 주체는 차량의 현재 위치 정보를 획득할 수 있다. 현재 위치 정보는 차량의 GPS(Global Positioning System, 글로벌 포지셔닝 시스템)에 의해 획득할 수 있고, 차량의 IMU(Inertial Measurement Unit, 관성 측정 유닛) 센서에 의해 획득할 수도 있으며, 본 발명은 이에 대해 구체적으로 한정하 지 않는다. 현재 지리적 위치 정보는 월드 좌표계에서 현재 위치의 좌표이다. 차량의 현재 위치 정보를 획득한 후, 획득한 현재 위치 정보를 기반으로 POI 객체의 속성 정보를 획득할 수 있 다. 예를 들면, 현재 위치의 좌표를 기반으로 지도에서 상기 POI 객체의 속성 정보를 획득할 수 있다. 속성 정 보는 POI 객체의 명칭, 카테고리 정보 등 일 수 있다. 예를 들면, POI 객체가 쇼핑몰인 경우, 그 속성 정보는 상기 쇼핑몰의 이름, 쇼핑몰 내 매장의 프로모션 추천 및 프로모션 세일 정보 등 정보를 포함할 수 있다. POI 객체는 운전자가 관심을 가지는 객체이기 때문에, 본 실시예에서는 또한 POI 객체의 속성 정보를 획득하여, 운 전자한테 더 전면적인 정보를 피드백한다. 단계에서, 이미지 좌표계와 헤드업 디스플레이 화면에 대응되는 디스플레이 좌표계 사이의 대응 관계를 기 반으로, 헤드업 디스플레이 화면에서 POI 객체의 타깃 표시 위치를 결정한다. 본 실시예에서, 상기 수행 주체는 이미지 좌표계와 헤드업 디스플레이 화면에 대응되는 디스플레이 좌표계 사이 의 대응 관계를 기반으로, 헤드업 디스플레이 화면에서 POI 객체의 타깃 표시 위치를 결정할 수 있다. 본 실시예에서, 헤드업 디스플레이 화면은 헤드업 디스플레이 장치로 투사하여 획득하고, 헤드업 디스플레이 화 면에도 대응되는 디스플레이 좌표계가 있으며, POI 객체는 제2 이미지 중의 객체이고, 상기 디스플레이 좌표계 와 제2 이미지가 대응되는 이미지 좌표계 사이에도 하나의 대응 관계가 있으므로, 상기 수행 주체는 디스플레이 좌표계와 이미지 좌표계 사이의 대응 관계를 기반으로, 헤드업 디스플레이 화면에서 POI 객체의 타깃 표시 위치 를 결정하고, 상기 타깃 표시 위치에서 상기 POI 객체를 표시한다. 단계에서, 헤드업 디스플레이 화면 중의 타깃 표시 위치에 POI 객체를 표시한다. 본 실시예에서, 상기 수행 주체는 헤드업 디스플레이 화면 중의 타깃 표시 위치에 상기 POI 객체를 표시할 수 있고, 상기 속성 정보를 헤드업 디스플레이 화면 중의 POI 객체에 중첩되게 표시한다. 타깃 표시 위치는 현실에 서의 POI 객체의 위치 정보(즉 제2 이미지 중의 위치 정보)와 대응되므로, POI 객체의 타깃 표시 위치를 결정한 후, 헤드업 디스플레이 장치는 POI를 타깃 표시 위치에 투사함으로써, POI 객체를 더 직관적이고 정확하게 운전 자한테 보여준다. 단계에서, 속성 정보를 헤드업 디스플레이 화면 중의 POI 객체에 중첩되게 표시한다. 본 실시예에서, 상기 수행 주체는 POI 객체의 속성 정보를 POI 객체에 중첩되게 표시할 수 있어서, 속성 정보들 이 실제 환경 중의 건물과 융합되게 하여 증강 현실의 효과를 달성할 수 있다. 예로, POI 객체가 하나의 쇼핑몰 인 경우, 상기 수행 주체는 상기 쇼핑몰을 타깃 표시 위치에 렌더링하고, 상기 쇼핑몰의 이름, 쇼핑몰 내의 프 로모션 정보 등을 상기 POI 객체에 중첩되게 표시한다. 도 4에 도시된 바와 같이, 도 3에 대응되는 실시예와 비교하면, 본 실시예의 시선 추적 방법은 제2 이미지를 더 획득하였고, 월드 좌표계와 제2 이미지에 대응되는 이미지 좌표계 사이의 대응 관계를 기반으로, 제2 이미지 중 제1 타깃 영역에 대응되는 제2 타깃 영역을 결정하며, 제2 타깃 영역 중의 POI 객체를 결정한 다음; 차량의 현 재 위치 정보를 획득하고 현재 위치 정보를 기반으로 POI 객체의 속성 정보를 획득하며; 마지막으로, 이미지 좌 표계와 헤드업 디스플레이 화면에 대응되는 디스플레이 좌표계 사이의 대응 관계를 기반으로, 헤드업 디스플레 이 화면에서 POI 객체의 타깃 표시 위치를 결정하고, 헤드업 디스플레이 화면 중의 타깃 표시 위치에 POI 객체를 표시하여, 속성 정보를 헤드업 디스플레이 화면 중의 POI 객체에 중첩되게 표시하므로, 운전자의 시선을 기 반으로 객체를 타겟팅, 추적하고 객체의 속성 정보가 실제 환경 중의 건물과 융합되게 함으로써, 증강 현실의 효과를 달성하게 된다. 본 발명의 기술적 해결수단에서, 관련된 사용자 개인 정보의 획득, 저장 및 적용은 모두 관련 법규의 규정을 준 수하고, 공서양속을 위배하지 않는다. 계속해서 도 5를 참조하면, 도 5는 본 발명에 따른 모델 트레이닝 방법의 일 실시예의 프로세스를 도시한 다. 상기 모델 트레이닝 방법은 하기와 같은 단계를 포함한다. 단계에서, 트레이닝 샘플 세트를 획득한다. 본 실시예에서, 모델 트레이닝 방법의 수행 주체(예를 들어 도 1에 도시된 서버)는 트레이닝 샘플 세트를 획득할 수 있고, 상기 트레이닝 샘플 세트 중의 트레이닝 샘플은 운전자가 마크업 포인트를 주시하는 경우의 안 구 이미지와 마크업 포인트의 위치 정보를 포함한다. 본 실시예에서, 트레이닝 샘플 세트를 획득하는 경우, 하나의 캘리브레이션 보드판을 배치할 수 있는데, 상기 캘리브레이션 보드판이 헤드업 디스플레이 장치에 의해 투사되어 형성된 헤드업 디스플레이 화면에서 나타나도 록 하며, 상기 캘리브레이션 보드판은 사전에 상이한 영역으로 구획할 수 있고, 각 영역은 대응되는 자체 위치 정보가 있으며, 캘리브레이션 보드판의 해상도는 헤드업 디스플레이 장치의 해상도와 동일하여야 하고, 예를 들 어 해상도 모두 854 * 480이다. 이 밖에, 캘리브레이션 보드판은 체커보드 형태도 가능하고, 본 실시예는 이에 대해 구체적으로 한정하지 않는다. 다음으로, 테스트 대상자를 운전자의 위치에 앉게하고(운전자가 직접 테스트를 진행할 수도 있음), 눈으로 캘리 브레이션 보드판의 상이한 데이터를 바라보도록 하며, 즉 캘리브레이션 보드판의 상이한 영역을 바라보도록 하 여, 테스트 대상자가 상이한 영역을 바라보는 경우의 안구 상태 이미지를 수집함으로써, 트레이닝 시선 캘리브 레이션 모델의 트레이닝 샘플 세트를 획득한다. 트레이닝 샘플 세트 중 운전자가 마크업 포인트를 주시하는 경 우의 안구 이미지와 마크업 포인트의 위치 정보를 포함하고, 상기 마크업 포인트의 위치 정보는 수동으로 마크 업할 수 있고, 예를 들어 위치 정보 5행3열 등으로 표기할 수 있다. 단계에서, 안구 이미지를 입력으로 하고, 위치 정보를 출력으로 하여, 트레이닝을 통해 시선 캘리브레이션 모델을 획득한다. 본 실시예에서, 상기 수행 주체는 안구 이미지를 입력으로 하고, 위치 정보를 출력으로 하여, 트레이닝을 통해 시선 캘리브레이션 모델을 획득할 수 있다. 트레이닝 샘플 세트를 획득한 후, 상기 트레이닝 샘플 세트를 딥러닝 모델에 넣고, 딥러닝 모델에 대해 트레이 닝함으로써, 트레이닝이 완료된 시선 캘리브레이션 모델을 획득하고, 상기 시선 캘리브레이션 모델의 입력은 운 전자의 안구 이미지이고, 출력은 안구 이미지에 대응되는 위치 정보이다. 여기서, 딥러닝 모델은 종래의 모델을 이용할 수 있으므, 본 발명은 이에 대해 구체적으로 한정하지 않는다. 본 발명의 실시예예서 제공하는 모델 트레이닝 방법은, 트레이닝 샘플 세트를 획득한 다음, 안구 이미지를 입력 으로 하고, 위치 정보를 출력으로 하여, 트레이닝을 통해 시선 캘리브레이션 모델을 획득한다. 본 발명은 모델 트레이닝 방법을 제공하고, 상기 방법은 트레이닝을 통해 시선 캘리브레이션 모델을 획득할 수 있으므로, 시선 캘리브레이션 결과를 더 정확하게 한다. 추가로 도 6을 참조하면, 상기 각 도면에 도시된 방법의 구현으로서, 본 발명은 시선 추적 장치의 일 실시예를 제공하며, 상기 장치 실시예는 도 2에 도시된 방법 실시예에 대응되고, 상기 장치는 구체적으로 다양한 전자 기 기에 적용될 수 있다. 도 6에 도시된 바와 같이, 본 실시예의 시선 추적 장치는 제1 획득 모듈 및 제1 결정 모듈을 포 함할 수 있다. 여기서 제1 획득 모듈은 제1 이미지를 획득하도록 구성되되, 제1 이미지는 운전자의 안구 상태 이미지이고; 제1 결정 모듈은 사전 트레이닝한 시선 캘리브레이션 모델을 기반으로, 월드 좌표계 중 제1 이미지에 대응되는 주시 영역을 결정하도록 구성된다. 본 실시예에서, 시선 추적 장치 중 제1 획득 모듈 및 제1 결정 모듈의 구체적인 처리 및 이에 따른 기술적 효과는 각각 도 2에 대응되는 실시예 중의 단계 및 단계의 관련 설명을 참조할 수 있으 며, 여기서 더이상 반복 설명하지 않는다.본 실시예의 일부 선택 가능한 실시형태에서, 제1 결정 모듈은 제1 이미지를 사전 트레이닝한 시선 캘리브레이 션 모델에 입력하여 제1 이미지에 대응되는 시선 방향을 획득하도록 구성되는 입력 서브 모듈; 및 월드 좌표계 중 시선 방향에 대응되는 주시 영역을 결정하도록 구성되는 결정 서브 모듈을 포함한다. 본 실시예의 일부 선택 가능한 실시형태에서, 상기 시선 추적장치는 제2 이미지를 획득하도록 구성되되, 제2 이 미지는 운전자 탑승 차량의 주변 환경 이미지인 제2 획득 모듈; 및 월드 좌표계와 제2 이미지에 대응되는 이미 지 좌표계 사이의 대응 관계를 기반으로, 제2 이미지 중 제1 타깃 영역에 대응되는 제2 타깃 영역을 결정하도록 구성되는 제2 결정 모듈을 더 포함한다. 본 실시예의 일부 선택 가능한 실시형태에서, 상기 시선 추적 장치는 제2 타깃 영역 중의 관심 지점(POI) 객체 를 결정하도록 구성되는 제3 결정 모듈; 및 이미지 좌표계와 헤드업 디스플레이 화면에 대응되는 디스플레이 좌 표계 사이의 대응 관계를 기반으로, POI 객체가 헤드업 디스플레이 화면 중의 타깃 표시 위치를 결정하도록 구 성되는 제4 결정 모듈을 더 포함한다. 본 실시예의 일부 선택 가능한 실시형태에서, 상기 시선 추적 장치는 차량의 현재 위치 정보를 획득하도록 구성 되는 제3 획득 모듈; 현재 위치 정보를 기반으로 POI 객체의 속성 정보를 획득하도록 구성되는 제4 획득 모듈; 및 속성 정보를 헤드업 디스플레이 화면 중의 POI 객체에 중첩되게 표시하도록 구성되는 표시 모듈을 더 포함한 다. 추가로 도 7을 참조하면, 상기 각 도면에 도시된 방법의 구현으로서, 본 발명은 모델 트레이닝 장치의 일 실시 예를 제공하며, 상기 장치 실시예는 도 5에 도시된 방법 실시예에 대응되고, 상기 장치는 구체적으로 다양한 전 자 기기에 적용될 수 있다. 도 7에 도시된 바와 같이, 본 실시예의 모델 트레이닝 장치는 제5 획득 모듈 및 트레이닝 모듈 을 포함할 수 있다. 여기서 제5 획득 모듈은 트레이닝 샘플 세트를 획득되되, 트레이닝 샘플 세트 중의 트 레이닝 샘플은 운전자가 마크업 포인트를 주시하는 경우의 안구 이미지와 마크업 포인트의 위치 정보를 포함하 도록 구성되고; 트레이닝 모듈은 안구 이미지를 입력으로 하고, 위치 정보를 출력으로 하고, 트레이닝을 통해 시선 캘리브레이션 모델을 획득하도록 구성된다. 본 실시예에서, 모델 트레이닝 장치 중 제5 획득 모듈 및 트레이닝 모듈의 구체적인 처리 및 이 에 따른 기술적 효과는 각각 도 5에 대응되는 실시예 중의 단계 및 단계의 관련 설명을 참조할 수 있 으며 여기서 더이상 반복 설명하지 않는다. 본 발명의 실시예에 따르면, 본 발명은 전자기기, 판독 가능 기록 매체 및 컴퓨터 프로그램을 더 제공한다. 도 8은 본 발명의 실시예를 구현하기 위한 예시적 전자 기기의 예시적 블록도이다. 전자 기기는 랩톱 컴퓨 터, 데스크톱 컴퓨터, 워크벤치, 개인 정보 단말기, 서버, 블레이드 서버, 메인 프레임 컴퓨터, 및 다른 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 의미한다. 전자 기기는 개인 디지털 처리, 셀룰러폰, 스마트폰, 웨어러블 기기 및 다른 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장치를 나타낼 수도 있다. 본 명세서 에 개시된 부재, 이들의 연결과 관계, 및 그 기능은 단지 예시적인 것으로, 본 명세서에 기술되거나 및/또는 청 구된 본 발명의 실시형태를 한정하도록 의도되지 않는다. 도 8에 도시된 바와 같이, 기기는 판독 전용 메모리(ROM, 802)에 저장된 컴퓨터 프로그램 또는 저장 유닛 으로부터 랜덤 액세스 메모리(RAM, 803)에 로딩된 컴퓨터 프로그램에 따라 다양한 적절한 동작 및 처리를 수행할 수 있는 산출 유닛을 포함한다. RAM에는 또한 기기의 동작에 필요한 다양한 프로그램과 데이터가 저장될 수 있다. 산출 유닛, ROM 및 RAM은 버스를 통해 서로 연결된다. 입력/출 력(I/O) 인터페이스 역시 버스에 연결된다. 키보드, 마우스 등과 같은 입력 유닛; 다양한 유형의 시선 추적기, 스피커 등과 같은 출력 유닛; 자 기 디스크, 광 디스크 등과 같은 저장 유닛; 및 네트워크 카드, 모뎀, 무선 통신 트랜시버 등과 같은 통신 유닛을 포함하는 기기의 복수 개의 부재는 I/O 인터페이스에 연결된다. 통신 유닛은 기기 가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신 네트워크를 통해 다른 기기와 정보/데이터를 교환 할 수 있도록 허용한다. 산출 유닛은 처리 및 컴퓨팅 기능을 갖는 다양한 범용 및/또는 전용 처리 컴포넌트일 수 있다. 산출 유닛 의 일부 예에는 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공지능(AI) 컴퓨팅 칩, 기계 학습 모델 알고리즘을 실행하는 다양한 산출 유닛, 디지털 신호 프로세서(DSP), 및 임의의 적절한 프로세서, 컨트롤러, 마이크로 컨트롤러 등이 포함되나 이에 한정되는 것은 아니다. 산출 유닛은 시선 추적 방법과 같 이 상술한 다양한 방법 및 처리를 수행한다. 예를 들어, 일부 실시예에서, 시선 추적 방법은 저장 유닛과 같은 기계 판독 가능 매체에 유형적으로 포함되는 컴퓨터 소프트웨어 프로그램으로 구현될 수 있다. 일부 실시 예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛을 통해 기기에 로딩 및/또 는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되어 산출 유닛에 의해 실행될 경우, 상술한 시선 추적 방법의 하나 이상의 단계를 수행할 수 있다. 대안적으로, 다른 실시예에서, 산출 유닛은 다른 임의의 적절한 방식(예를 들어, 펌웨어에 의함)을 통해 시선 추적 방법을 구현하도록 구성될 수 있다. 본 명세서에서 기술된 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로그래머블 어레이(FPGA), 전용 집적 회로(ASIC), 전용 표준 제품(ASSP), 시스텝 온 칩(SOC), 복합 프로그램 가능 논리 소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합에서 구현될 수 있다. 이러 한 다양한 실시형태는 하나 이상의 컴퓨터 프로그램에서 구현되는 것을 포함할 수 있고, 상기 하나 이상의 컴퓨 터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해석 될 수 있으며, 상기 프로그램 가능 프로세서는 전용 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력 장치, 및 적어도 하나의 출력 장치로부터 데이터와 명령을 수신하며, 데이터와 명 령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치, 및 상기 적어도 하나의 출력 장치에 전송할 수 있다. 본 발명의 방법을 구현하는 프로그램 코드는 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 다른 프로그램 가능 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공되어, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 경우 흐름도 및/또는 블록도에 지정된 기능/동작이 구현될 수 있도록 한다. 프로그램 코드는 전부 기계에서 실행되거나, 부분적으로 기계에서 실행되거나, 독립형 소프트웨어 패키지로서 부분적으로 기계에서 실행되고 부분적으로 원격 기계에서 실행되거 나, 전부 원격 기계 또는 서버에서 실행될 수 있다. 본 발명의 컨텍스트에서, 기계 판독 가능 매체는 명령 실행 시스템, 장치 또는 기기에 의해 사용되거나 명령 실 행 시스템, 장치 또는 기기와 결합하여 사용하기 위한 프로그램을 포함하거나 저장할 수 있는 유형 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적절한 조합을 포함할 수 있지만 이에 한정되지 않는다. 기계 판독 가능 저장 매체의 보다 구체적인 예는 하나 이상의 와이어에 기반한 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 판독 전용 메모리(ROM), 소거 가능 프로그램 가능 판독 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, 휴대용 컴팩트 디스크 판독 전용 메모리(CD-ROM), 광학 저장 기기, 자기 저장 기기 또는 상기 내용의 임의의 적절한 조합을 포 함한다. 사용자와의 인터랙션을 제공하기 위하여, 컴퓨터에서 여기에 설명된 시스템 및 기술을 실시할 수 있고, 상기 컴 퓨터는 사용자에게 정보를 시선 추적하기 위한 시선 추적 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 시선 추적기) 모니터); 및 키보드 및 포인팅 장치(예를 들어, 마우스 또는 트랙볼)를 구비하고, 사용자는 상기 키보 드 및 상기 포인팅 장치를 통해 컴퓨터에 입력을 제공할 수 있다. 다른 타입의 장치를 사용하여 사용자와의 인 터랙션을 제공할 수 있는데; 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 감지 피드백(예를 들어, 시각적 피드백, 청각적 피드백 또는 촉각적 피드백)일 수 있고; 임의의 형태(사운드 입력, 음성 입력, 또는 촉 각 입력)로 사용자로부터의 입력을 수신할 수 있다. 여기서 설명된 시스템 및 기술은 백엔드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버), 또는 미들엔 드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 애플리케이션 서버), 또는 프론트 엔드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 그래픽 사용자 인터페이스 또는 웹 브라우저를 구비하는 사용자 컴퓨터이며, 사용자는 상기 그래픽 사용자 인터페이스 또는 상기 웹 브라우저를 통해 여기서 설명된 시스템 및 기술의 실시형태와 인터랙션 할 수 있음), 또는 이러한 백엔드 부재, 미들엔드 부재, 또는 프론트 엔드 부재의 임의의 조합을 포함하는 컴퓨 팅 시스템에서 구현될 수 있다. 시스템의 부재는 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 서로 연결될 수 있다. 통신 네트워크의 예로는, 근거리 통신망(LAN), 광역 통신망(WAN), 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고, 통상적으로 통신 네트워크를 통해 인터랙션한다. 클라이언트와 서버 간의 관계는, 해당 컴퓨터에서 실행되 고 서로 클라이언트-서버 관계를 갖는 컴퓨터 프로그램에 의해 생성된다. 서버는 클라우드 컴퓨팅 서버 또는 분산형 시스템의 서버일 수 있으며, 또는 블록체인과 결합한 서버일 수 있다. 위에서 설명된 다양한 형태의 프로세스를 통해 단계를 재배열, 추가 또는 삭제할 수 있음을 이해해야 한다. 예 를 들어, 본 발명에 설명된 각 단계들은 동시에, 순차적으로 또는 상이한 순서로 수행될 수 있으며, 본 발명에 개시된 기술적 해결수단이 이루고자 하는 결과를 달성할 수만 있으면, 본 명세서는 여기서 한정하지 않는다."}
{"patent_id": "10-2022-0046677", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 구체적인 실시형태는 본 발명의 보호 범위를 한정하지 않는다. 본 기술분야의 통상의 기술자라면 설계 요 구 및 다른 요인에 따라 다양한 수정, 조합, 서브 조합 및 대체가 이루어질 수 있음을 이해할 것이다. 본 발명 의 사상 및 원칙 내에서 이루어진 모든 수정, 등가적 대체 및 개선은 모두 본 발명의 보호 범위 내에 포함되어 야 한다."}
{"patent_id": "10-2022-0046677", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 본 해결수단을 더 잘 이해하기 위한 것으로, 본 발명에 대해 한정하지 않는다. 여기서, 도 1은 본 발명이 적용될 수 있는 예시적 시스템 아키텍처이다. 도 2는 본 발명에 따른 시선 추적 방법의 일 실시예의 흐름도이다. 도 3은 본 발명에 따른 시선 추적 방법의 다른 실시예의 흐름도이다. 도 4는 본 발명에 따른 시선 추적 방법의 또 다른 실시예의 흐름도이다. 도 5는 본 발명에 따른 모델 트레이닝 방법의 일 실시예의 흐름도이다. 도 6은 본 발명에 따른 시선 추적 장치의 일 실시예의 구조 모식도이다. 도 7은 본 발명에 따른 모델 트레이닝 장치의 일 실시예의 흐름도이다. 도 8은 본 발명의 실시예의 시선 추적 방법을 구현하기 위한 전자 기기의 블록도이다."}
