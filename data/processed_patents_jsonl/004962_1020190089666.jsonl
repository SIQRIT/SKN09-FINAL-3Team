{"patent_id": "10-2019-0089666", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0094303", "출원번호": "10-2019-0089666", "발명의 명칭": "인공지능을 이용하여 로봇의 위치를 재정의하는 방법 및 로봇", "출원인": "엘지전자 주식회사", "발명자": "박중태"}}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "정보를 출력하고 외부로부터 정보를 입력받는 인터페이스부; 외부에 배치된 장애물을 센싱하는 장애물 센서;상기 로봇이 이동하는 공간에서 진입 가능한 영역과 진입 불가능한 영역을 구분하여 맵으로 저장하며, 상기 로봇이 위치를 복구하는데 필요한 로케이팅 포스트를 저장하는 맵저장부;상기 로봇을 이동시키는 이동부; 및상기 장애물 센서 및 상기 이동부를 제어하여 상기 로봇의 위치를 상기 맵 상에서 식별하는 제어부를 포함하며, 상기 제어부가 상기 로봇의 위치를 상기 맵저장부에서 확인할 수 없을 경우 상기 인터페이스부가 상기 로케이팅포스트를 하나 이상 출력한 후, 상기 인터페이스부는 상기 출력된 로케이팅 포스트 중에서 어느 하나를 선택하는 정보를 입력받는, 인공지능을이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제어부는 상기 로봇에 가해지는 외력에 순응하여 상기 로봇이 이동하도록 상기 이동부를 제어하는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 로케이팅 포스트가 선택된 후, 상기 제어부는 상기 로봇에 가해지는 외력이 발생한 후 상기 장애물 센서가반복하여 센싱하는 장애물에 대해서는 회피 동작을 수행하지 않도록 상기 로봇을 제어하는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 로케이팅 포스트가 선택된 후, 상기 제어부는 상기 로봇이 회피동작을 수행하도록 설정된 장애물과의 기준거리를 감소시키는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 로봇은 영상을 촬영하는 카메라부를 더 포함하며, 상기 제어부는 상기 외력에 순응하여 상기 로봇을 이동시키며, 상기 제어부는 상기 카메라부를 제어하여 상기로봇의 진행 방향에 배치된 영상을 촬영시키며, 상기 제어부는 상기 카메라부가 촬영한 영상과 상기 선택된 로케이팅 포스트의 이미지를 비교하여 상기 선택된공개특허 10-2019-0094303-3-로케이팅 포스트에 도착했는지를 판단하는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 제어부는 상기 선택한 로케이팅 포스트에 도착하면 상기 로봇의 위치를 복구하는 프로세스를 수행하는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 제어부는 상기 로케이팅 포스트를 하나 이상 출력한 위치 또는 하나의 로케이팅 포스트가 선택된 위치를출발점으로 하여 상기 선택한 로케이팅 포스트까지 이동하는 경로를 저장한 후, 상기 선택한 로케이팅 포스트에도착하면 상기 선택한 로케이팅 포스트의 상기 맵 상에서의 위치와 상기 경로에 기반하여 상기 출발점을 상기맵 상에서 확인하는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 인터페이스부는 상기 선택된 로케이션 포스트에서 상기 로봇의 배치 방향 또는 세부 위치에 대한 정보를출력하는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "정보를 출력하고 외부로부터 정보를 입력받는 인터페이스부; 외부에 배치된 장애물을 센싱하는 장애물 센서;상기 로봇이 이동하는 공간에서 진입 가능한 영역과 진입 불가능한 영역을 구분하여 맵으로 저장하며, 상기 로봇이 위치를 복구하는데 필요한 로케이팅 포스트를 저장하는 맵저장부;상기 로봇을 이동시키는 이동부; 로봇의 주변을 촬영하는 카메라부; 및상기 장애물 센서 및 상기 이동부를 제어하여 상기 로봇의 위치를 상기 맵 상에서 식별하는 제어부를 포함하며, 상기 제어부가 상기 로봇의 위치를 상기 맵저장부에서 확인할 수 없을 경우 상기 제어부는 상기 맵저장부에 저장된 로케이팅 포스트의 이미지와 상기 카메라부가 촬영한 영상을 비교하여 하나의 로케이팅 포스트를선택하고, 상기 제어부는 상기 선택한 로케이팅 포스트까지 상기 로봇을 이동시키는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 제어부는 상기 로봇을 이동시키며, 상기 제어부는 상기 카메라부를 제어하여 상기 로봇의 진행 방향에 배치된 영상을 촬영시키며, 상기 제어부는 상기 카메라부가 촬영한 영상과 상기 선택된 로케이팅 포스트의 이미지를 비교하여 상기 선택된공개특허 10-2019-0094303-4-로케이팅 포스트에 도착하는데 필요한 경로를 생성하는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 제어부는 상기 선택한 로케이팅 포스트에 도착하면 상기 로봇의 위치를 복구하는 프로세스를 수행하는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 제어부는 상기 로케이팅 포스트를 선택한 위치를 출발점으로 하여 상기 선택한 로케이팅 포스트까지 이동하는 경로를 저장한 후, 상기 선택한 로케이팅 포스트에 도착하면 상기 선택한 로케이팅 포스트의 상기 맵 상에서의 위치와 상기 경로에 기반하여 상기 출발점을 상기 맵 상에서 확인하는, 인공지능을 이용하여 위치를 재정의하는 로봇."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "로봇의 제어부가 상기 로봇의 위치를 상기 로봇의 맵저장부에서 확인할 수 없음을 판단하는 단계; 상기 로봇의 인터페이스부가 상기 맵 저장부에 저장된 로케이팅 포스트를 하나 이상 출력하는 단계; 및인터페이스부는 상기 출력된 로케이팅 포스트 중에서 어느 하나를 선택하는 정보를 입력받는 단계를 포함하는,인공지능을 이용하여 로봇의 위치를 재정의하는 방법."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 제어부는 상기 로봇에 가해지는 외력에 순응하여 상기 로봇이 이동하도록 상기 이동부를 제어하는 단계를더 포함하는, 인공지능을 이용하여 로봇의 위치를 재정의하는 방법."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 입력받는 단계 이후에, 상기 제어부가 상기 로봇에 가해지는 외력이 발생한 후 상기 장애물 센서가 반복하여 센싱하는 장애물에 대해서는 회피 동작을 수행하지 않도록 상기 로봇을 제어하는 단계를 더 포함하는, 인공지능을 이용하여 로봇의 위치를 재정의하는 방법."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 입력받는 단계 이후에, 상기 제어부가 상기 로봇이 회피동작을 수행하도록 설정된 장애물과의 기준 거리를감소시키는 단계를 더 포함하는, 인공지능을 이용하여 로봇의 위치를 재정의하는 방법."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2019-0094303-5-제14항에 있어서, 상기 제어부가 상기 외력에 순응하여 상기 로봇을 이동시키는 과정에서, 상기 로봇의 카메라부가 상기 로봇의진행 방향에 배치된 영상을 촬영하는 단계; 및상기 제어부가 상기 촬영한 영상과 상기 선택된 로케이팅 포스트의 이미지를 비교하여 상기 선택된 로케이팅 포스트에 도착했는지를 판단하는 단계를 더 포함하는, 인공지능을 이용하여 로봇의 위치를 재정의하는 방법."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서, 상기 제어부는 상기 선택한 로케이팅 포스트에 도착하면 상기 로봇의 위치를 복구하는 프로세스를 수행하는 단계를 더 포함하는, 인공지능을 이용하여 로봇의 위치를 재정의하는 방법."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항에 있어서, 상기 제어부는 상기 로케이팅 포스트를 하나 이상 출력한 위치 또는 하나의 로케이팅 포스트가 선택된 위치를출발점으로 하여 상기 선택한 로케이팅 포스트까지 이동하는 경로를 저장하는 단계; 상기 로봇이 상기 선택한 로케이팅 포스트에 도착하면 상기 제어부는 상기 선택한 로케이팅 포스트의 상기 맵상에서의 위치와 상기 경로에 기반하여 상기 출발점을 상기 맵 상에서 확인하는 단계를 더 포함하는, 인공지능을 이용하여 로봇의 위치를 재정의하는 방법."}
{"patent_id": "10-2019-0089666", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제13항에 있어서, 상기 인터페이스부는 상기 선택된 로케이션 포스트에서 상기 로봇의 배치 방향 또는 세부 위치에 대한 정보를출력하는 단계를 더 포함하는, 인공지능을 이용하여 로봇의 위치를 재정의하는 방법."}
{"patent_id": "10-2019-0089666", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 이용하여 로봇의 위치를 재정의하는 방법 및 로봇에 관한 것으로, 발명의 일 실시예에 의 한 인공지능을 이용하여 위치를 재정의하는 로봇은 로봇이 이동하는 공간에서 진입 가능한 영역과 진입 불가능한 영역을 구분하여 맵으로 저장하며, 상기 로봇이 위치를 복구하는데 필요한 로케이팅 포스트를 저장한다."}
{"patent_id": "10-2019-0089666", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용하여 로봇의 위치를 재정의하는 방법 및 로봇에 관한 기술이다."}
{"patent_id": "10-2019-0089666", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "대형 마트, 백화점, 공항, 골프장 등 인적, 물적 교류가 활발하게 발생하는 공간에는 사람들에게 정보를 제공하 기 위해, 또는 사람들에게 편의를 제공하기 위해 로봇이 배치될 수 있다. 전술한 로봇의 종류로는 안내로봇, 보안로봇, 청소로봇 등이 있으며, 이들 다양한 로봇들은 공간 내에서 자신의 위치를 확인하며 이동한다. 한편, 로봇들이 자신의 위치를 확인하고 장애물을 회피하며 이동하기 위해서는 공간에 대한 정보와 로봇의 현재 위치 또는 이전에 로봇이 이동한 경로 등에 대한 정보를 로봇이 유지해야 한다 그러나, 로봇들이 복잡한 공간 내에서 이동하는 과정에서 자신의 위치를 확인하지 못하거나, 일시적으로 경로에 대한 정보를 업데이트하지 못하는 상황이 발생하면 로봇의 위치를 정의해야 한다. 그러나, 로봇이 다수이거나 로봇을 원격에서 제어해야 하거나, 공간이 넓어서 개별 로봇 하나하나를 제어하는 것이 불가능한 경우 로봇을"}
{"patent_id": "10-2019-0089666", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "정확하게 제어하는데 있어 많은 노력을 필요로 하는 문제점이 있다. 발명의 내용"}
{"patent_id": "10-2019-0089666", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서에서는 전술한 문제점을 해결하기 위한 것으로, 로봇이 공간 내에서 위치를 확인할 수 없는 상황에서 이를 복구할 수 있는 인터페이스를 제공하고자 한다. 또한, 본 명세서에서는 로봇의 위치 복구 과정을 인터페이스를 통해 쉽게 구현할 수 있도록 위치에 대한 이미지 정보를 제공하여 사용자가 로봇의 위치 복구를 원활하게 수행할 수 있도록 정보를 제공하고자 한다. 또한, 본 명세서에서는 로봇이 사용자의 제어에 따라 위치 복구 장소로 쉽게 이동하되 로봇이 별도의 모드로 이 동할 수 있도록 한다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발 명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것 이다."}
{"patent_id": "10-2019-0089666", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "발명의 일 실시예에 의한 인공지능을 이용하여 위치를 재정의하는 로봇은 로봇이 이동하는 공간에서 진입 가능 한 영역과 진입 불가능한 영역을 구분하여 맵으로 저장하며, 로봇이 위치를 복구하는데 필요한 로케이팅 포스트 를 저장한다. 발명의 일 실시예에 의한 인공지능을 이용하여 위치를 재정의하는 로봇은 로봇의 위치를 맵저장부에서 확인할 수 없을 경우 인터페이스부가 로케이팅 포스트를 하나 이상 출력한 후, 인터페이스부는 출력된 로케이팅 포스트 중에서 어느 하나를 선택하는 정보를 입력받는다. 발명의 일 실시예에 의한 인공지능을 이용하여 위치를 재정의하는 로봇은 로봇에 가해지는 외력에 순응하여 로 봇이 이동하도록 이동부를 제어한다. 발명의 일 실시예에 의한 인공지능을 이용하여 위치를 재정의하는 로봇은 선택한 로케이팅 포스트에 도착하면 로봇의 위치를 복구하는 프로세스를 수행하는, 인공지능을 이용하여 위치를 재정의한다. 발명의 일 실시예에 의한 인공지능을 이용하여 위치를 재정의하는 로봇은 제어부가 로봇의 위치를 맵저장부에서 확인할 수 없을 경우 제어부는 맵저장부에 저장된 로케이팅 포스트의 이미지와 카메라부가 촬영한 영상을 비교 하여 하나의 로케이팅 포스트를 선택한 후 선택한 로케이팅 포스트까지 로봇을 이동시킨다. 발명의 일 실시예에 의한 인공지능을 이용하여 로봇의 위치를 재정의하는 방법은 로봇의 제어부가 로봇의 위치 를 로봇의 맵저장부에서 확인할 수 없음을 판단하는 단계, 로봇의 인터페이스부가 맵 저장부에 저장된 로케이팅 포스트를 하나 이상 출력하는 단계, 그리고 인터페이스부는 출력된 로케이팅 포스트 중에서 어느 하나를 선택하 는 정보를 입력받는 단계를 포함한다. 발명의 일 실시예에 의한 인공지능을 이용하여 로봇의 위치를 재정의하는 방법은 제어부가 로케이팅 포스트를 하나 이상 출력한 위치 또는 하나의 로케이팅 포스트가 선택된 위치를 출발점으로 하여 선택한 로케이팅 포스트 까지 이동하는 경로를 저장하는 단계와 로봇이 선택한 로케이팅 포스트에 도착하면 제어부는 선택한 로케이팅 포스트의 맵 상에서의 위치와 경로에 기반하여 출발점을 맵 상에서 확인하는 단계를 더 포함한다."}
{"patent_id": "10-2019-0089666", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들을 적용할 경우, 로봇이 공간 내에서 위치를 확인할 수 없는 상황에서 이를 복구할 수 있는 인터페이스를 제공하여 로봇이 복잡한 절차 없이 위치를 복구할 수 있다. 또한, 본 발명의 실시예들을 적용할 경우, 로봇의 위치 복구 과정을 인터페이스를 통해 쉽게 구현할 수 있도록 위치에 대한 이미지 정보를 제공하여 사용자가 로봇의 위치 복구를 원활하게 수행할 수 있도록 정보를 제공할 수 있다. 또한, 본 발명의 실시예들을 적용할 경우, 로봇이 사용자의 제어에 따라 위치 복구 장소로 쉽게 이동할 수 있도"}
{"patent_id": "10-2019-0089666", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "록 로봇의 이동부와 센서가 별도의 모드로 동작할 수 있도록 한다. 본 발명의 효과는 전술한 효과에 한정되지 않으며, 본 발명의 당업자들은 본 발명의 구성에서 본 발명의 다양한 효과를 쉽게 도출할 수 있다."}
{"patent_id": "10-2019-0089666", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조 부호를 붙이도록 한다. 또한, 본 발명의 일부 실시예들을 예시적인 도 면을 참조하여 상세하게 설명한다. 각 도면의 구성요소들에 참조부호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가질 수 있다. 또한, 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에 는 그 상세한 설명은 생략할 수 있다. 본 발명의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질, 차례, 순서 또는 개수 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성 요소 사이에 다른 구성 요소가 \"개재\"되거나, 각 구성 요소가 다른 구성 요소를 통해 \"연결\", \"결합\" 또는 \"접 속\"될 수도 있다고 이해되어야 할 것이다. 또한, 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요 소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘 어져서 구현될 수도 있다. 이하, 본 명세서에서 로봇은 특정한 목적(청소, 보안, 모니터링, 안내 등)을 가지거나 혹은 로봇이 이동하는 공 간의 특성에 따른 기능을 제공하며 이동하는 장치를 포함한다. 따라서, 본 명세서에서의 로봇은 소정의 정보와 센서를 이용하여 이동할 수 있는 이동수단을 보유하며 소정의 기능을 제공하는 장치를 통칭한다. 본 명세서에서 로봇은 맵을 보유하면서 이동할 수 있다. 맵은 공간에서 이동하지 않는 것으로 확인된 고정된 벽, 계단 등 고정 객체에 대한 정보를 의미한다. 또한, 주기적으로 배치되는 이동 장애물, 즉 동적인 객체들에 대한 정보도 맵 상에 저장될 수 있다. 일 실시예로 로봇의 진행 방향을 기준으로 일정한 범위 내에 배치된 장애물들에 대한 정보도 맵 상에 저장될 수 있다. 이 경우, 전술한 고정 객체가 저장되는 맵과 달리 임시적으로 장애물들의 정보가 맵에 등록되고 이후 로 봇이 이동한 후 맵에서 제거될 수 있다. 또한, 본 명세서에서 로봇은 다양한 센서들을 이용하여 외부의 동적 객체를 확인할 수 있다. 외부의 동적 객체 를 확인하면, 보행자로 붐비는 환경에서 로봇이 목적지까지 주행할 때, 목적지까지 거쳐가야 하는 경유 지점 (Waypoint)의 장애물에 의한 점유 상황을 확인할 수 있다. 또한 로봇은 경유 지점의 방향 변경 정도에 따라 유연하게 경유 지점을 도착한 것으로 판단하고 다음 경유 지점 으로 넘어 가도록 하여 목적지까지 성공적으로 주행할 수 있다. 도 1은 본 발명의 일 실시예에 의한 로봇의 외관을 보여준다. 도 1은 예시적인 외관에 해당하며, 도 1의 외관 외에도 다양한 외관으로 본 발명의 로봇을 구현할 수 있다. 특히, 각각의 구성요소는 로봇의 형상에 따라 상하 좌우 전후 등에서 다른 위치에 배치될 수 있다. 본체는 상하 방향으로 길이가 길게 형성되며, 전체적으로 하부에서 상부 방향으로 올라갈수록 슬림해지는 오뚝이 형상을 가질 수 있다. 본체는 로봇의 외관을 형성하는 케이스를 포함할 수 있다. 케이스는 상측에 배치되는 탑 커버 , 탑 커버의 하측에 배치되는 제1 미들 커버, 제1 미들 커버의 하측에 배치되는 제2 미들 커버 및 제2 미들 커버의 하측에 배치되는 바텀 커버를 포함할 수 있다. 여기서 제1 미들 커버와 제2 미들 커버는 하나의 미들 커버로 이루어질 수 있다. 탑 커버는 로봇의 최상단에 위치되며, 반구 또는 돔 형상을 가질 수 있다. 탑 커버는 사용자로부터 명령을 용이하게 입력 받기 위하여 성인의 키보다 낮은 높이에 위치될 수 있다. 그리고 탑 커버는 소정각도 회전 가능하도록 구성될 수 있다. 한편, 로봇은 그 내부에 제어모듈을 더 포함할 수 있다. 제어모듈은 일종의 컴퓨터 또는 프로세서 와 같이 로봇을 제어한다. 따라서 제어모듈은 로봇내에 배치되어 메인 프로세서와 유사한 기능을 수 행하며, 사용자와의 인터랙션(interaction)을 담당할 수 있다. 탑 커버는 전면 일측에 사용자로부터 명령을 입력받거나 정보를 출력하는 디스플레이부(31a)과 카메라 (31b), 마이크(31c)를 일 실시예로 하는 센서가 배치될 수 있다. 또한, 탑 커버의 디스플레이부(31a) 외에도 미들 커버의 일측에도 디스플레이부가 배치된다. 로봇의 기능에 따라 두 개의 디스플레이부(31a, 20) 모두 정보를 출력하거나 혹은 어느 한쪽에서만 정보가 출력 될 수 있다. 한편, 로봇의 일측면 또는 하단부 전체에는 35a, 35b와 같이 다양한 장애물 센서(도 2의 220)들이 배치된다. 장애물 센서들은 TOF(Time of Flight) 센서, 초음파 센서, 적외선 센서, 뎁스 센서, 레이저 센서, 라이다 센서 등을 일 실시예로 한다. 센서들은 다양한 방식으로 로봇 외부의 장애물을 감지한다. 또한, 도 1의 로봇은 하단부에 로봇을 이동시키는 구성요소인 이동부를 더 포함한다. 이동부는 일종의 바퀴와 같이 로봇을 이동시키는 구성요소이다. 도 1의 로봇의 형상은 예시적이며, 본 발명이 이에 한정되는 것은 아니다. 또한, 로봇의 다양한 카메라들과 센 서들 역시 로봇의 다양한 위치에 배치될 수 있다. 도 1의 로봇은 사용자에게 정보를 안내하고 특정 지점까지 이동하여 사용자를 안내하는 안내 로봇을 일 실시예로 한다. 이외에도 청소, 보안 또는 기능을 제공하는 로봇 역시 도 1의 로봇의 범위에 포함된다. 다양한 기능을 제공할 수 있으나, 본 명세서에서는 설명의 편의를 위해 안내 로봇을 중심으로 설명한다. 도 1를 일 실시예로 하는 로봇이 서비스 공간 내에 다수 배치된 상태에서 로봇이 특정한 기능(안내, 청소, 보안 등)을 수행한다. 이 과정에서 로봇은 자신의 위치를 항상 저장하며, 로봇은 전체 공간에서 자신의 현재 위치를 확인하고, 목표 지점으로 이동하는데 필요한 경로를 생성할 수 있다.도 2는 본 발명의 일 실시예에 의한 로봇의 제어모듈의 구성 요소를 보여준다. 로봇의 제어모듈의 구성요소는 다음과 같다. 인터페이스부는 정보를 출력하고 외부로부터 정보를 입력받는다. 터치스크린을 일 실시예로 한다. 장애물 센서는 외부에 배치된 장애물을 센싱한다. 장애물 센 서는 도 1에 도시된 바와 같이 로봇의 상하좌우 다양한 영역에 배치된다. 맵저장부는 로봇이 이동하는 공간에서 진입 가능한 영역과 진입 불가능한 영역을 구분하여 맵으로 저장한 다. 또한, 맵저장부는 로봇이 위치를 복구하는데 필요한 로케이팅 포스트를 저장한다. 맵은 도 3에, 로케 이팅 포스트는 도 4에 도시되었다. 카메라부는 로봇의 주변을 촬영한다. 제어부는 장애물 센서 및 이동부를 제어하여 로봇의 위치를 맵 상에서 식별한다. 그러나 이동 과정에 서 제어부가 로봇의 위치를 맵저장부에서 확인할 수 없을 경우 위치 복구를 위한 프로세스를 진행한다. 일 실시예로, 제어부는 인터페이스부를 제어하여 로케이팅 포스트를 하나 이상 출력한다. 그리고 사 용자가 인터페이스부에 출력된 로케이팅 포스트 중에서 어느 하나를 선택하고 인터페이스부는 선택한 정보를 입력받는다. 이때, 제어부는 사용자에 의해 로봇이 로케이팅 포스트로 이동하면 위치 복구 프로세스를 수행할 수 있다. 다른 실시예로, 제어부는 로봇의 위치를 맵 저장부에서 확인할 수 없을 경우, 맵저장부에 저장 된 로케이팅 포스트의 이미지와 카메라부가 촬영한 영상을 비교하여 하나의 로케이팅 포스트를 선택한다. 이때 제어부는 두 이미지를 비교하여 유사도가 높은 이미지를 선택할 수 있다. 또는 제어부는 최근까 지 확인된 지점에서 가장 가까운 순서로 로케이팅 포스트를 정렬하여 가장 가까운 로케이팅 포스트의 이미지와 주변의 이미지를 비교할 수 있다. 그리고 제어부는 선택한 로케이팅 포스트까지 로봇을 이동시킨다. 이동 과정에서 제어부는 카메라 부를 이용하여 주변을 촬영하여 로케이팅 포스트까지 로봇이 이동할 수 있도록 제어한다. 로봇은 이동하며 측정한 로봇의 이동 경로에 대한 정보와 맵 저장부의 맵 정보를 이용하여 로봇의 현재 위 치를 확인할 수 있다. 이 과정에서 로봇이 위치 추정을 실패할 경우, 로봇은 특정하게 약속된 위치로 이동하여 로봇의 위치를 재정의 할 수 있다. 이하 전술한 약속된 위치를 로케이팅 포스트(locating post)라고 한다. 맵 저장부는 공간 내의 로케이팅 포스트에 대한 좌표 정보와 해당 위치에 대한 사진 정보를 위치복구 정보 로 저장한다. 좌표 정보는 (x, y, deg) 등과 같이 맵 내에서 로봇의 x, y 좌표 및 사진을 확인할 수 있거나 로 봇이 로케이팅 포스트에 위치해야 하는 각도 정보를 포함한다. 이들 위치복구 정보는 다수를 포함하므로 하나의 집합(set)을 구성할 수 있다. 로봇이 이동하여 동작하는 공간의 크기에 맞게 유동적으로 로케이팅 포스트의 수나 위치가 결정된다. 또한, 로 케이팅 포스트는 사진상으로 식별이 가능한 위치 또는 눈에 쉽게 띄거나 로봇이 이미지 비교를 통해 쉽게 확인 할 수 있는 위치 등으로 선정될 수 있다. 로봇이 위치추정을 실패할 경우 운영자가 다수의 위치복구정보 집합에서 현재 로봇에서 가장 가까운 위치로 로 봇을 이동시킨다. 그리고 위치복구정보에 표시된 사진처럼 로봇을 위치시킨 후, 위치복구 기능을 수행할 수 있 다. 로봇에는 위치복구정보 집합에 기록된 좌표 정보(x, y, deg)정보가 현재 로봇의 위치정보로 입력된다. 이 경우, 자율주행 로봇의 위치추정 실패 시, 비전문가도 로봇의 위치를 100% 복구할 수 있다. 또한, 자율주행 로봇이 내장된 이미지들과 현재 촬영된 외부 이미지를 비교하여 로케이팅 포스트를 식별할 수도 있다. 도 3은 본 발명의 일 실시예에 의한 맵의 구성을 보여준다. 맵 저장부는 로봇이 이동하는 공간을 2차원으로 저장한다. 도 2의 맵(210a)은 20x20의 비트맵 공간 중에서 각 공간에서 로봇이 진입 가능한 영역(흰색), 진입 불가능한 영역(검은색), 로케이팅 포스트를 구분하여 표시한 다. 맵으로 저장될 경우 전술한 색상이나 무늬 대신 값이 입력될 수 있다. 도 3과 같이 맵을 구성할 경우, 로봇 은 자신의 위치와 맵을 비교하여 위치를 추정한다. 그리고 로봇은 에서 진입할 수 없는 영역도 확인할 수 있다.예를 들어 20x20 행렬에 빈 공간을 지시하기 위해 0 이라는 값이 저장된다. 또는 진입 불가 영역을 지시하기 위 해 검은 색에 해당하는 영역은 99라는 값이 저장된다. 또한, 로케이팅 포스트는 각도와 이미지 정보가 저장될 수 있다. 도 3에서 로봇이 진입하지 못하는 진입불가영역과 로케이팅 포스트가 표시되어 있다. 로케이팅 포스트는 맵 내 의 특정 위치이며, 여기서 로봇이 위치를 복구하기 위해 향해야 할 각도 정보(deg)도 포함된다. 그리고 로케이 팅 포스트는 별도의 사진 정보도 함께 저장될 수 있다. 이는 사용자가 해당 사진을 보고 로봇을 이동시키는데 필요하다. 또는 로봇이 주변을 이미지 서치하여 해당 사진과 비교하여 이동할 수 있도록 한다. 도 4는 본 발명의 일 실시예에 의한 로케이팅 포스트 및 이미지 저장을 보여준다. 맵 저장부가 저장하는 로케이션 포스트의 일 실시예로, 각 로케이션 포스트의 명칭(LocationName), 위치 좌표(x, y, deg), 해당 위치 의 이미지 등을 포함한다. 좌표에서 각도는 로봇이 해당 위치에서 배치되어야 하는 각도 정보이다. 예를 들어 로봇이 해당 위치의 벽을 좌 측에 둔 후 회전해야 하는 각도가 될 수 있다. 각도 정보는 생략될 수 있다. 이미지 정보는 하나 이상 저장될 수 있다. 예를 들어, 로봇이 자동으로 로케이션 포스트를 식별하기 위해 맵 저 장부는 다양한 각도에서 촬영된 이미지 정보를 저장할 수 있다. 도 5는 본 발명의 일 실시예에 의한 로봇을 로케이션 포스트로 이동시키는 과정을 보여준다. 로봇의 제어부는 위치 추정에 실패하였음을 확인한다(S51). 로봇이 이동 과정에서 외부의 힘으로 인해 경 로 정보를 누적하지 못하고 이동되거나, 로봇이 보유한 맵과 달리 공간이 구성된 경우 등의 상황에서 로봇은 위 치 추정에 실패할 수 있다. 인터페이스부는 최근까지 확인된 위치를 기준으로 로케이션 포스트의 이미지를 출력한다(S52). 예를 들어 도 1의 31a, 20 등과 같은 디스플레이부에 이미지가 출력될 수 있다. 사용자는 출력된 이미지와 주변의 이미지를 비교하여 주변에 배치된 장소 중 로케이션 포스트의 이미지와 동일 한 곳이 있는지 확인한다. 그리고 사용자는 인터페이스부에서 동일한 로케이션 포스트를 터치한다. 이후, 로봇은 자동 또는 수동으로 로케이션 포스트로 이동한다(S53). 자동으로 이동한다는 것은 로봇이 외부 제어 없이 로케이션 포스트로 이동하는 것을 의미한다. 로봇은 카메라부를 이용하여 주변을 촬영한다. 그리고 제어부는 선택된 로케이션 포스트의 이미지와 촬영된 이미지를 비교하여 로케이션 포스트를 향해 이동한다. 수동으로 이동한다는 것은 사용자가 로봇을 제어하여 로봇이 로케이션 포스트로 이동하는 것을 의미한다. 로봇이 로케이션 포스트에 도착하면 사용자는 위치 복구를 인터페이스부에서 선택하고 제어부는 위치 복구를 수행한다(S54). 또는 로봇은 자동으로 로케이션 포스트의 도착 여부를 확인하여 위치 복구를 수 행할 수 있다. 도 5의 프로세스를 적용할 경우, 자율주행 로봇이 위치추정을 실패할 경우에도, 비 전문가인 사용자도 로봇의 위치를 로케이션 포스트로 이동시켜 위치를 복구할 수 있다. 즉, 별도의 외부 인력의 투입 없이도 로봇은 신속 하게 100% 위치를 복구 시킬 수 있으므로, 로봇의 운영정지 시간을 최소화시킬 수 있다. 도 6 내지 도 8은 본 발명의 일 실시예에 의한 로봇이 수동으로 로케이션 포스트로 이동하는 과정을 보여준다. 로봇은 자신의 위치를 추정하는데 실패한 상태이다. 따라서 로봇은 자신의 위치를 도 4의 맵 상에서 확인할 수 없는 상태이다. 도 7과 같이 로봇은 도 5에 설명된 바와 같이 4개의 로케이션 포스트의 이미지를 인터페이스부에 출력한다. 인터페이스부는 다수의 로케이션 포스트의 이미지를 출력한다. 만약, 로봇이 자신이 위치한 공간에 대한 대략적인 정보는 유지한 상태인 경우에 인터페이스부는 해당 공간에 포함된 로케이션 포스트의 이미지만을 출력할 수 있다. 예를 들어서 도 3에서 로봇이 자신의 위치가 (0, 0)~(8, 16) 내에 포함된 것으로 확인한 경우에는 인터페이스부 는 두 개의 로케이션 포스트(Bestshop, Starbucks)만을 출력할 수 있다. 인터페이스부는 로케이션 포스트의 이미지와 명칭을 출력할 수 있다. 인터페이스부는 로케이션 포스 트를 선택할 수 있는 선택 버튼도 출력한다. 사용자는 인터페이스부에 표시된 4 개의 이미지 중에서 로봇 근처에서 확인되는 이미지를 선택한다. 예를 들어 가장 최상단의 이미지(Bestshop)를 선택할 수 있다. 그리고, 사용자는 로봇을 선택한 로케이션 포스트 쪽으로 이동시킨다. 도 7은 사용자가 로봇을 첫번째 로케이션 포스트로 이동시킨 상태에서 인터페이스부가 출력하는 정보이다. 첫번 째 로케이션 포스트로 이동한 후, 로봇의 인터페이스부는 도 7과 같이 로케이션 포스트에서 로봇을 배 치한 후, 로봇의 정면 방향을 설명에 표시된 바와 같이 배치한다. 그리고 배치 완료 버튼을 사용자가 선택하면 로봇의 제어부는 로케이션 포스트의 위치(도 4의 (1, 14))를 이 용하여 로봇의 위치를 복구한다. 도 7의 하단에 맵(210a) 상에 로봇의 위치가 동그라미 위치로 복구되었음이 인 터페이스부에 추가로 표시될 수 있다. 도 8은 사용자가 로봇을 첫번째 로케이션 포스트로 이동시킨 상태에서 인터페이스부가 출력하는 정보이다. 도 7 과 달리, 로봇이 로케이션 포스트에 배치되는 가이드가 출력된다. 로봇이 로케이션 포스트에서 전면을 보도록 배치된 형태이다. 도 7 및 도 8에 도시된 바와 같이, 인터페이스부는 로봇이 선택된 로케이션 포스트에 도달하면 로케이 션 포스트에서 로봇이 배치되어야 하는 세부 정보를 출력한다. 예를 들어, 인터페이스부는 로봇의 배치 방 향 또는 로케이션 포스트에서의 세부적인 위치에 대한 정보를 출력한다. 사용자는 이를 확인하고 로봇을 정 확하게 배치시킬 수 있다. 도 9는 본 발명의 일 실시예에 의한 로봇이 자동으로 로케이션 포스트를 선택하는 과정을 보여준다. 제어부 가 위치 추정 실패를 확인한다(S61). 카메라부는 주변 이미지를 촬영한다(S62). 이때, 제어부는 촬영한 주변 이미지와 로봇의 현재 위치와의 상대적인 거리나 방향을 이미지 별로 저장할 수 있다. 이후 제어부는 촬영한 주변 이미지와 로케이션 포스트의 이미지를 비교하여 하나의 로케이션 포스트를 선 택한다(S63). 그리고 제어부는 선택한 로케이션 포스트와 유사도가 높은 이미지가 촬영된 방향으로 로봇을 이동시킨다(S64). 이 과정에서 로봇은 장애물 센서를 이용하여 장애물을 회피하여 이동할 수 있다. 로봇이 이동하는 중에 제어부는 이동하고자 하는 위치의 이미지를 촬영하여 저장된 로케이션 포스트와 비교하여 로케이션 포스트의 선택의 정확도를 높일 수 있다. 로봇이 선택한 로케이션 포스트로 실제로 이동하면 제어부는 위치 복구를 시작한다(S65). 전술한 실시예를 적용할 경우, 로봇의 자율주행 과정에서 맵상의 로봇 위치를 확인할 수 없는 위치추정 실패의 상황에서 로봇이 로케이션 포스트로 이동하여 위치를 복구할 수 있다. 위치추정 실패 시, 복구를 위해 로봇이 이동해야 하는 로케이션 포스트는 위치 정보와 하나 이상의 이미지 정보를 하나의 집합으로 포함할 수 있다. 또한, 로봇의 인터페이스부는 사용자가 로케이션 포스트를 선택할 수 있도록 로케이션 포스트의 이미지를 출력한다. 그리고 사용자는 해당 사진과 주변을 비교하여 특정 로케이션 포스트를 선택하고 로봇을 선택한 로케 이션 포스트로 이동시킨다. 그 결과 로봇을 제어할 줄 모르는 사용자도 사진을 통해서 로봇의 위치를 복구할 수 있다. 도 10은 본 발명의 일 실시예에 의한 로봇이 수동으로 이동하는 과정에서 이동부와 장애물 센서를 제어하는 과 정을 보여준다. 70a는 도 1의 로봇를 위에서 도시한 도면이다. 70b는 로봇의 하방 측면을 도시한 도면이다. 사용자는 손 으로 로봇을 72a방향으로 밀 수 있다. 제어부는 로케이팅 포스트가 선택된 후에 로봇에게 외력이 가해지면, 이동부(190a, 190b)의 모터에 전기 에너지를 공급한다. 따라서 70b와 같이 로봇이 72b 방향으로 쉽게 이동할 수 있도록 한다. 만약 로케이팅 포스트가 선택되기 전이라면, 제어부는 사용자가 로봇을 밀 경우에도 로봇이 이동하 지 않도록 이동부(190a, 190b)의 회전을 중지시킨다. 그러나, 로케이팅 포스트가 선택된 후라면, 제어부는 사용자가 로봇을 밀 경우, 로봇이 쉽게 이동하 도록 이동부(190a, 190b)를 회전시켜 로봇이 72b 방향으로 이동하도록 한다. 물론, 이 과정에서 제어부는 지속적으로 로봇에 가해지는 외력을 센싱하여 외력이 사라진 경우 이동부(190a, 190b)의 회전을 중지시 킨다. 외력의 센싱은 로봇이 정지했을 경우에는 로봇의 이동부(190a, 190b)가 힘을 받는 경우를 일 실시예로 한다. 또한 외력의 센싱은 로봇이 이동중일 경우 로봇의 이동부(190a, 190b)가 더 빨리 혹은 더 느리게 움직이도록 힘을 받는 경우를 일 실시예로 한다. 도 11은 본 발명의 일 실시예에 의한 제어부가 외력을 센싱하는 과정을 보여준다. 제어부는 로케이션 포스트가 선택되면(S75) 로봇이 수동으로 제어되어 이동하는 상태로 확인한다. 그리 고 로봇의 정지 상태에서 제어부는 이동부(190a, 190b)의 회전을 감지한다(S76). 이는 로봇을 사용 자가 밀 경우에 이동부(190a, 190b)가 회전하는 상황이다. 이때, 제어부는 로봇이 쉽게 이동할 수 있도록 이동부(190a, 190b)의 회전을 증가시키는 전기에너지를 이동부(190a, 190b)에 제공한다(S77). 일 실시예로 제어부가 이동부(190a, 190b)를 구성하는 바퀴의 시간 당 회전횟수를 증가시키거나, 이동부(190a, 190b)의 모터에 인가되는 전기에너지를 증가시킬 수 있다. 이후 제어부는 로봇이 이동하는 과정에서 이동부(190a, 190b)의 역회전을 감지한다(S78). 이는 사용자 가 로봇을 다른 방향으로 이동시키거나 로봇의 이동을 멈추고자 하는 상황이다. 따라서, 제어부는 로봇 이 정지할 수 있도록 이동부(190a, 190b)의 회전을 중지시킨다(S79). 이후 S76단계와 같이 다시 로봇을 사용자가 밀 경우에는 제어부는 전술한 과정을 반복한다. 도 10 및 도 11을 적용할 경우, 사용자가 로케이션 포스트를 선택하면, 제어부는 로봇에 가해지는 외력 에 순응하여 로봇이 이동하도록 이동부(190a, 190b)를 제어한다. 도 12는 본 발명의 일 실시예 의한 로봇이 수동 이동하는 경우의 장애물 회피 과정을 보여준다. 설명의 편의를 위해 디스플레이부는 도시하지 않았다. 로봇의 외부면에는 다양한 장애물 센서들이 배치되며, 이들은 주변에 배치된 장애물을 센싱하여 로봇의 회피 이동을 가능하게 한다. 그런데 로봇이 사용자의 제어에 따라 로케이션 포스트로 이동할 경우 사용자를 장애물로 인식하면 로봇의 이동이 사용자의 제어를 벗어날 수 있다. 따라서, 제어부는 로봇이 사용자를 장애물로 인식하지 않도록 장애물 센서를 제어하는 것이 필요하다. 또한, 사용자가 로봇을 밀어서 이동시킬 경우 로봇 주변의 장애물은 사용자도 확인할 수 있으므로, 로봇 의 장애물 회피 동작 역시 자율 주행시와 달리 이루어져야 한다. 81에서 사용자가 손으로 로봇을 미는 상황에서는 장애물 센서가 동작하지 않는 방향을 X로 표시하고 장애물 센서가 동작하는 방향을 O로 표시하였다. 사람이 미는 방향에 근접한 장애물 센서(X로 표시)들은 로케이션 포스 트로 이동하는 과정에서는 장애물을 센싱하지 않도록 제어된다. 또는 제어부는 X로 표시된 위치의 장애물 센서들이 센싱한 장애물에 대해서는 로봇이 회피 동작을 수행하지 않도록 제어한다. 또한, 로봇이 자율주행을 할 경우의 로봇이 장애물을 회피하기 위해 유지하는 기준 거리(d1)는 로케이션 포스트로 이동할 경우 줄어들 수 있다. 82에서 로봇이 장애물을 센싱하여 회피 동작을 수행하는 영역은 82a와 같다. 따라서 로봇은 d1 이내에 장 애물이 센싱된 경우 회피 동작을 한다. 반면 로케이션 포스트로 수동 이동할 경우 사용자가 로봇을 제어하므로 로봇은 아예 장애물 회피 동작을 하지 않을 수 있다. 또는 로봇은 83과 같이 장애물을 센싱하여 회피 동작을 수행하는 영역을 83a와 매우 작 은 범위로 설정한다. 그 결과 로봇은 d2 이내에 장애물이 센싱된 경우 회피 동작을 한다. 로봇의 회피 동 작은 장애물을 회피하여 방향을 바꾸거나 정지하는 동작을 모두 포함한다. 도 12를 정리하면 다음과 같다. 81에 도시한 바와 같이, 로케이팅 포스트가 선택된 후, 제어부는 로봇에 가해지는 외력이 발생한 후에 장 애물 센서가 반복하여 센싱하는 장애물에 대해서는 사람으로 판단하고, 회피 동작을 수행하지 않도록 로봇을 제 어한다. 제어부는 외력이 가해진 방향, 또는 외력이 가해진 방향과 인접한 방향의 장애물을 사람으로 판단하여, 로봇이 회피하지 않도록 제어한다. 83에 도시된 바와 같이, 로케이팅 포스트가 선택된 후, 제어부는 로봇이 회피동작을 수행하도록 설정된 장애물 과의 기준 거리(d2)를 감소시킨다. 그 결과 사용자는 로봇을 용이하게 이동시킬 수 있다. 도 13은 본 발명의 일 실시예에 의한 로봇이 주변의 영상을 촬영하여 로케이션 포스트의 이미지와 비교하는 과 정을 보여준다. 로봇이 사용자의 제어에 따라 수동 이동할 경우 로봇이 로케이션 포스트에 도착하였는지를 판단할 수 있 다. 또한, 로봇이 로케이션 포스트를 향해 자동으로 이동할 경우에도 로봇이 로케이션 포스트에 도착하였 는지를 판단할 수 있다. 이를 위해 로봇은 이동 과정에서 주변을 촬영하여 촬영한 이미지와 로케이션 포스트 의 이미지를 비교한다. 즉, 제어부의 제어에 의해, 카메라부가 로봇의 진행 방향에 배치된 영상을 촬영한다. 그리고 제어부 는 촬영한 영상을 이미지로 생성한다(S91). 제어부는 선택된 로케이션 포스트의 이미지와 카메라부 에 의해 촬영된 이미지를 비교하여 로봇이 선택된 로케이션 포스트로 도착했는지를 확인한다(S92). 로봇이 로케이션 포스트에 도착한 경우에 도 7 또는 도 8에 도시된 바와 같이 인터페이스부는 로봇의 세부 배치를 위한 정보를 출력한다(S93). 이후 사용자가 위치 복구 버튼을 선택하거나, 자동으로 로봇의 위 치 복구 프로세스가 진행된다(S94). 로봇이 로케이션 포스트에 도착하면, 로봇은 위치를 복구하는 프로세스를 수행한다. 제어부는 로케이션 포스트의 위치를 로봇의 현재 위치로 저장한다. 예를 들어, 도 4에 제시된 바와 같이 로봇이 \"Bestshop\"이라 는 로케이션 포스트로 이동한 경우, 제어부는 (1, 14)를 로봇의 위치 정보로 설정한다. 도 14 및 도 15는 본 발명의 일 실시예에 의한 로봇이 위치를 복구할 경우, 이전의 위치를 확인하는 과정을 보 여준다. 사용자의 제어에 따라 로케이션 포스트를 선택하는 모드에서, 로봇은 위치를 확인할 수 없는 경우, 로케이션 포스트를 하나 이상 출력한다. 그리고 사용자는 출력된 로케이션 포스트 중에서 하나를 선택한다. 이때, 제어부 는 로케이션 포스트를 출력한 위치 또는 로케이션 포스트가 선택된 위치를 출발점으로 한다. 사용자의 제어 없이 자동으로 로케이션 포스트를 선택하는 모드에서, 제어부는 로케이팅 포스트를 선택한 위치를 출발점으로 한다. 그리고 제어부는 사용자의 제어 또는 자율주행으로 로케이션 포스트까지 이동하며 이동부(190a, 190b)의 회전이나 방향 전환 등을 기록한다. 제어부는 출발점에서 로케이션 포스트까지 이동하는 경로를 저장한다. 뿐만 아니라 로케이션 포스트와 로봇이 이루는 각도도 저장한다. 그리고 로봇이 로케이팅 포스트에 도착하면, 제어부는 앞서 저장한 경로의 도착점을 로케이션 포스트의 좌표로 설정한다. 그리고 제어부는 이전의 경로를 도착점에서 역으로 계산하여 출발점을 맵 상에서 확인할 수 있다. 도 14 및 도 15는 도 3의 맵 중 일부만을 표시하였다. 도 14에서 R은 로봇이 위치 정보를 확인할 수 없어 로케이션 포스트(L1)로 이동을 결정하기 시작한 출발지점을 표시한다. 사용자의 제어 또는 자율주행으로 로봇은 화살표와 같이 로케이션 포스트(L1)를 향해 이동한다. 이 과정에서 직진 이동한 경우에 로봇은 로케이션 포스트(L1)에 도착할 때까지의 거리 정보(dist1)과 로케이션 포스트에 도착했을 때 로봇과 로케이션 포스트가 이루는 측면 각도(30°)를 저장한다. 그리고 로케이션 포스 트(L1)에 도착한 로봇의 제어부는 측면 각도(30°)와 거리(dist1), 그리고 L1의 위치 정보(1, 14)를 이용 하여 출발점의 위치를 (4, 8)로 산출한다. 도 15에서 R은 로봇이 위치 정보를 확인할 수 없어 로케이션 포스트(L1)로 이동을 결정하기 시작한 출발지점을 표시한다. 사용자의 제어 또는 자율주행으로 로봇은 화살표와 같이 로케이션 포스트(L1)를 향해 이동한다. 이 과정에서 평행-직각 이동한 경우에 로봇은 로케이션 포스트(L1)에 도착할 때까지의 거리 정보(dist2, dist 3)과 dist2-dist3의 직각 이동, 그리고 로케이션 포스트에 도착했을 때 로봇과의 측면 각도(90도)를 저장한 다. 그리고 로케이션 포스트(L1)에 도착한 로봇의 제어부는 측면 각도(90도)와 두 번의 이동 거리(dist2, dist3) 및 직각 이동, 그리고 L1의 위치 정보(1, 14)를 이용하여 출발점의 위치를 (4, 8)로 산출한다. 전술한 제어부는 인공지능모듈을 추가로 탑재할 수 있다. 카메라부가 촬영한 이미지를 제어부에 게 제공하면, 제어부 내의 인공지능모듈이 센싱된 값을 입력받아 이미지의 유사도를 판단할 수 있다. 인공 지능모듈은 기계학습(machine learning) 또는 딥러닝 네트워크(Deep Learning Network)를 일 실시예로 한다. 또한, 제어부는 인공지능 모듈을 이용하여 상황인식(Context Awareness)을 수행할 수 있다. 마찬가지로, 센싱된 값들, 사용자의 제어, 또는 다른 로봇들이나 서버로부터 수신된 정보 등을 인공지능 모듈의 입력값으로 하여 제어부는 로봇의 상황을 인식할 수 있다. 또한, 제어부는 인공지능 모듈을 이용하여 카메라부가 촬영한 이미지를 입력받아 이미지를 판독할 수 있다. 즉, 제어부는 이미지 프로세싱(image processing)을 수행할 수 있다. 전술한 인공지능모듈은 추론 엔진(inference engine), 뉴럴 네트워크(neural network), 확률모델(probability model)을 포함할 수 있다. 그리고 인공지능 모듈은 다양한 데이터에 기반한 지도학습(supervised learning) 또 는 비지도학습(unsupervised learning)을 수행할 수 있다. 또한, 인공지능모듈은 사용자의 음성을 인식하여 이로부터 정보를 추출하기 위해 자연어 처리(natural language processing)을 수행할 수 있다. 따라서, 본 발명의 실시예를 적용할 경우, 로케이팅 포스트를 선택하거나, 로케이션 포스트로 이동하는 과정에 서 제어부 내의 인공지능 모듈이 이미지들을 비교하고 판단하는 과정을 수행할 수 있다. 본 발명의 실시예를 구성하는 모든 구성 요소들이 하나로 결합되거나 결합되어 동작하는 것으로 설명되었다고 해서, 본 발명이 반드시 이러한 실시예에 한정되는 것은 아니며, 본 발명의 목적 범위 내에서 모든 구성 요소들 이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 또한, 그 모든 구성 요소들이 각각 하나의 독립적인 하드웨어로 구현될 수 있지만, 각 구성 요소들의 그 일부 또는 전부가 선택적으로 조합되어 하나 또는 복수 개 의 하드웨어에서 조합된 일부 또는 전부의 기능을 수행하는 프로그램 모듈을 갖는 컴퓨터 프로그램으로서 구현 될 수도 있다. 그 컴퓨터 프로그램을 구성하는 코드들 및 코드 세그먼트들은 본 발명의 기술 분야의 당업자에 의해 용이하게 추론될 수 있을 것이다. 이러한 컴퓨터 프로그램은 컴퓨터가 읽을 수 있는 저장매체(Computer Readable Media)에 저장되어 컴퓨터에 의하여 읽혀지고 실행됨으로써, 본 발명의 실시예를 구현할 수 있다. 컴 퓨터 프로그램의 저장매체로서는 자기 기록매체, 광 기록매체, 반도체 기록소자를 포함하는 저장매체를 포함한 다. 또한 본 발명의 실시예를 구현하는 컴퓨터 프로그램은 외부의 장치를 통하여 실시간으로 전송되는 프로그램 모듈을 포함한다. 이상에서는 본 발명의 실시예를 중심으로 설명하였지만, 통상의 기술자의 수준에서 다양한 변경이나 변형을 가 할 수 있다. 따라서, 이러한 변경과 변형이 본 발명의 범위를 벗어나지 않는 한 본 발명의 범주 내에 포함되는 것으로 이해할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15"}
{"patent_id": "10-2019-0089666", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 의한 로봇의 외관을 보여준다. 도 2는 본 발명의 일 실시예에 의한 로봇의 제어모듈의 구성 요소를 보여준다. 도 3은 본 발명의 일 실시예에 의한 맵의 구성을 보여준다. 도 4는 본 발명의 일 실시예에 의한 로케이팅 포스트 및 이미지 저장을 보여준다. 도 5는 본 발명의 일 실시예에 의한 로봇을 로케이션 포스트로 이동시키는 과정을 보여준다. 도 6 내지 도 8은 본 발명의 일 실시예에 의한 로봇이 수동으로 로케이션 포스트로 이동하는 과정을 보여준다. 도 9는 본 발명의 일 실시예에 의한 로봇이 자동으로 로케이션 포스트를 선택하는 과정을 보여준다. 도 10은 본 발명의 일 실시예에 의한 로봇이 수동으로 이동하는 과정에서 이동부와 장애물 센서를 제어하는 과 정을 보여준다. 도 11은 본 발명의 일 실시예에 의한 제어부가 외력을 센싱하는 과정을 보여준다. 도 12는 본 발명의 일 실시예 의한 로봇이 수동 이동하는 경우의 장애물 회피 과정을 보여준다. 도 13은 본 발명의 일 실시예에 의한 로봇이 주변의 영상을 촬영하여 로케이션 포스트의 이미지와 비교하는 과 정을 보여준다. 도 14 및 도 15는 본 발명의 일 실시예에 의한 로봇이 위치를 복구할 경우, 이전의 위치를 확인하는 과정을 보 여준다."}
