{"patent_id": "10-2021-0063620", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0155840", "출원번호": "10-2021-0063620", "발명의 명칭": "관심 영역의 심도 정보를 생성하는 전자 장치 및 이의 동작 방법", "출원인": "삼성전자주식회사", "발명자": "조순용"}}
{"patent_id": "10-2021-0063620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 광전 변환 소자들을 이용하여 객체를 센싱하고, 상기 복수의 광전 변환 소자들 중 적어도 두 개는 하나의 마이크로 렌즈를 공유함으로써 디스패리티(disparity)를 가지는 스테레오 이미지 데이터를 생성하도록 구성된 카메라 모듈;적어도 하나의 인스트럭션, 및 상기 스테레오 이미지 데이터를 저장하는 메모리; 및상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 스테레오 이미지 데이터에 기초해 관심 객체를 검출하고,상기 카메라 모듈이 상기 관심 객체를 포함하는 관심 영역을 센싱하도록 지시하는 크롭 신호를 생성하고, 상기스테레오 이미지 데이터에 기초해 심도(depth) 정보를 생성하도록 구성된 처리 회로를 포함하는 전자 장치."}
{"patent_id": "10-2021-0063620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 스테레오 이미지 데이터는 한 쌍의 제1 이미지 데이터, 및 제2 이미지 데이터를 포함하고,상기 처리 회로는,상기 제1 이미지 데이터에 기초하여 상기 관심 객체를 검출하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2021-0063620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 카메라 모듈은 상기 제1 이미지 데이터의 크기를 감소시킴으로써 제3 이미지 데이터를 생성하고,상기 처리 회로는 상기 제3 이미지 데이터로부터 상기 관심 객체를 검출하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2021-0063620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 처리 회로는,상기 제1 이미지 데이터 및 상기 제2 이미지 데이터에 기초하여 심도를 추정함으로써 상기 심도 정보를 생성하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2021-0063620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 카메라 모듈은상기 크롭 신호에 기초해 상기 관심 영역을 센싱함으로써 상기 관심 객체에 대해 디스패리티를 가지는 부분 스테레오 이미지 데이터를 더 생성하도록 구성된 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2021-0063620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 처리 회로는,상기 스테레오 이미지 데이터에 포함된 휘도 데이터에 기초하여 상기 심도 정보를 생성하는 것을 특징으로 하는전자 장치."}
{"patent_id": "10-2021-0063620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2022-0155840-3-제1항에 있어서,상기 카메라 모듈은,동작 모드로서, 상기 스테레오 이미지 데이터를 생성하는 제1 모드, 상기 디스패리티를 가지지 않는 일반 이미지 데이터를 생성하는 제2 모드, 및 상기 스테레오 이미지 데이터 및 상기 일반 이미지 데이터를 모두 생성하는제3 모드를 지원하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2021-0063620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "동일한 객체에 대해 디스패리티(disparity)를 가지는 제1 이미지 데이터 및 제2 이미지 데이터를 포함하는 스테레오 이미지 데이터를 생성하도록 구성된 카메라 모듈;적어도 하나의 인스트럭션, 및 상기 스테레오 이미지 데이터를 저장하는 메모리; 및상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 이미지 데이터로부터 관심 객체를 검출하고, 상기 관심 객체를 포함하는 관심 영역을 센싱하도록 지시하는 크롭 신호를 생성하도록 구성된 처리 회로를 포함하고,상기 카메라 모듈은,상기 크롭 신호에 기초하여, 상기 관심 객체에 대해 디스패리티를 가지는 제1 부분 이미지 데이터 및 제2 부분이미지 데이터를 포함하는 부분 스테레오 이미지 데이터를 생성하도록 더 구성되고,상기 처리 회로는,상기 부분 스테레오 이미지에 기초하여 심도(depth) 정보를 생성하도록 더 구성된 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2021-0063620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "카메라 모듈 및 처리 회로를 포함하는 전자 장치의 동작 방법에 있어서,하나의 마이크로 렌즈를 공유하는 두 개의 광전 변환 소자들에 의해 디스패리티(disparity)를 가지는 스테레오이미지 데이터를 생성하는 단계;상기 스테레오 이미지 데이터로부터 관심 객체를 검출하는 단계;상기 관심 객체를 포함하는 관심 영역에 대한 부분 스테레오 이미지 데이터를 생성하는 단계; 및상기 부분 스테레오 이미지 데이터에 기초해 심도를 추정함으로써 심도 정보를 생성하는 단계를 포함하는 전자장치의 동작 방법."}
{"patent_id": "10-2021-0063620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 스테레오 이미지 데이터로부터 상기 관심 객체를 검출하는 단계는,상기 스테레오 이미지 데이터를 구성하는 한 쌍의 제1 이미지 데이터 및 제2 이미지 데이터 중, 상기 제1 이미지 데이터에 기초해 상기 관심 객체를 탐색하는 단계를 포함하는 것을 특징으로 하는 전자 장치의 동작 방법."}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 본 개시의 기술적 사상의 예시적 실시 예에 따른 전자 장치는, 복수의 광전 변환 소자들 을 이용하여 객체를 센싱하고, 상기 복수의 광전 변환 소자들 중 적어도 두 개는 하나의 마이크로 렌즈를 공유함 으로써 디스패리티(disparity)를 가지는 스테레오 이미지 데이터를 생성하도록 구성된 카메라 모듈, 적어도 하나 의 인스트럭션, 및 상기 스테레오 이미지 데이터를 저장하는 메모리, 및 상기 적어도 하나의 인스트럭션을 실행 함으로써, 상기 스테레오 이미지 데이터에 기초해 관심 객체를 검출하고, 상기 카메라 모듈이 상기 관심 객체를 포함하는 관심 영역을 센싱하도록 지시하는 크롭 신호를 생성하고, 상기 스테레오 이미지 데이터에 기초해 심도 (depth) 정보를 생성하도록 구성된 처리 회로를 포함할 수 있다."}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 기술적 사상은 관심 영역의 심도 정보를 생성하는 전자 장치 및 이의 동작 방법에 관한 것으로서, 상 세하게는 듀얼 픽셀을 이용해 객체를 센싱해 관심 영역을 결정하고, 관심 영역에 대한 심도 정보를 생성하는 전 자 장치 및 이의 동작 방법에 관한 것이다."}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "CMOS(complementary metal-oxide semiconductor) 이미지 센서가 휴대용 전자 기기에 널리 탑재되면서, 다양한 촬상 환경에서도 선명한 이미지가 요구된다. 저조도 환경에서 선명한 이미지가 촬상되기 위해서는 피사체의 심도(Depth) 정보가 보다 정확히 요구된다. 심도 정보를 획득하기 위해 일반적으로 TOF(Time Of Flight) 센서가 이용되나 공간을 많이 차지하며 비용과 소비 전력이 증가하는 단점이 있고, 일반적인 RGB 기반의 CMOS 이미지 센서는 저조도에 취약하다. 자동 초점 검출 및 심도 정보를 획득하기 위해, 하나의 마이크로 렌즈를 공유하는 두개의 광전 변환 소자들 쌍 인 듀얼 픽셀이 이용된다. 서로 다른 이미지 센서로 구성된 듀얼 카메라에 비해, 동일한 이미지 센서 내에 포함 된 듀얼 픽셀은 광전 변환 소자 간의 거리인 베이스라인이 짧으므로 디스패리티가 작아 심도 정보를 정확히 추 정하기 어렵다."}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 사상이 해결하려는 과제는, 관심 영역만을 센싱함으로써 심도 추정에 필요한 데이터 처리량을 감축하는 전자 장치 및 이의 동작 방법을 제공하는 데 있다."}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위하여, 본 개시의 예시적 실시 예에 따른 전자 장치는, 복수의 광전 변환 소자들 을 이용하여 객체를 센싱하고, 상기 복수의 광전 변환 소자들 중 적어도 두 개는 하나의 마이크로 렌즈를 공유 함으로써 디스패리티(disparity)를 가지는 스테레오 이미지 데이터를 생성하도록 구성된 카메라 모듈, 적어도 하나의 인스트럭션, 및 상기 스테레오 이미지 데이터를 저장하는 메모리, 및 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 스테레오 이미지 데이터에 기초해 관심 객체를 검출하고, 상기 카메라 모듈이 상기 관심 객 체를 포함하는 관심 영역을 센싱하도록 지시하는 크롭 신호를 생성하고, 상기 스테레오 이미지 데이터에 기초해 심도(depth) 정보를 생성하도록 구성된 처리 회로를 포함할 수 있다. 본 개시의 예시적 실시 예에 따른 전자 장치는, 동일한 객체에 대해 디스패리티(disparity)를 가지는 제1 이미 지 데이터 및 제2 이미지 데이터를 포함하는 스테레오 이미지 데이터를 생성하도록 구성된 카메라 모듈, 적어도 하나의 인스트럭션, 및 상기 스테레오 이미지 데이터를 저장하는 메모리, 및 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 이미지 데이터로부터 관심 객체를 검출하고, 상기 관심 객체를 포함하는 관심 영역을 센싱하도록 지시하는 크롭 신호를 생성하도록 구성된 처리 회로를 포함하고, 상기 카메라 모듈은, 상기 크롭 신 호에 기초하여, 상기 관심 객체에 대해 디스패리티를 가지는 제1 부분 이미지 데이터 및 제2 부분 이미지 데이 터를 포함하는 부분 스테레오 이미지 데이터를 생성하도록 더 구성되고, 상기 처리 회로는, 상기 부분 스테레오 이미지에 기초하여 심도(depth) 정보를 생성하도록 더 구성된 것을 특징으로 할 수 있다. 본 개시의 예시적 실시 예에 따른 카메라 모듈 및 처리 회로를 포함하는 전자 장치의 동작 방법은, 하나의 마이 크로 렌즈를 공유하는 두 개의 광전 변환 소자들에 의해 디스패리티(disparity)를 가지는 스테레오 이미지 데이 터를 생성하는 단계, 상기 스테레오 이미지 데이터로부터 관심 객체를 검출하는 단계, 상기 관심 객체를 포함하 는 관심 영역에 대한 부분 스테레오 이미지 데이터를 생성하는 단계, 및 상기 부분 스테레오 이미지 데이터에 기초해 심도를 추정함으로써 심도 정보를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 예시적 실시 예에 따른 전자 장치 및 이의 동작 방법은 관심 영역만을 센싱함으로써 심도 추정에 필 요한 데이터 처리량을 감축시킬 수 있다. 그에 따라, 전자 장치의 전력 소모는 절감될 수 있고, 데이터 처리 속 도는 향상될 수 있다. 또한, 본 개시의 예시적 실시 예에 따른 전자 장치 및 이의 동작 방법은 YUV 데이터 중 휘도 데이터만을 인공 신경망에 학습시킴으로써 메모리 사용량 및 전력 소비량을 감축시킬 수 있고, 저조도 환경에서도 심도 추정 정 확도를 향상시킬 수 있다."}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참조하여 본 개시의 실시 예에 대해 상세히 설명한다. 도 1은 본 개시의 예시적인 실시 예에 따른 전자 장치를 나타내는 블록도이다. 도 1을 참조하면, 전자 장치는 듀얼 픽셀을 포함하는 이미지 센서, 이미지 신호 처리기(Image Signal Processor; 이하, ISP), 처리 회로, 및 메모리를 포함할 수 있고, 제1 버스(BUS1)를 통 해 각 구성과 통신하거나, 제어 신호, 데이터, 및/또는 전력을 각 구성에 제공할 수 있다. 이미지 센서 및 이미지 신호 처리기는 카메라 모듈로 지칭될 수 있다. 전자 장치는 하드웨어와 소프트웨어의 상호 작용을 통해 데이터를 처리하고 처리 결과를 사용자에게 제공할 수 있다. 전자 장치는 소프트웨어가 실행될 수 있는 물리적 기반을 제공하고, 하드웨어의 자원을 이용해 사 용자가 의도하는 결과를 도출할 수 있다. 예시적인 실시 예에서, 전자 장치는 운영체제(Operating System; OS)를 통해 응용 소프트웨어를 실행할 수 있고, 실행에 따른 연산 결과를 메모리에 저장할 수 있으며, 이 경우 전자 장치는 컴퓨팅 시스템으로 지칭될 수 있다. 예를 들어, 전자 장치는 디지털 카메라, 스마트폰, 웨어러블 기기, 사물 인터넷(Internet of Things(IoT)), 태블릿 PC(Personal Computer), PDA(Personal Digital Assistant), PMP(portable Multimedia Player), 네비게 이션(navigation) 장치를 포함할 수 있다. 또한 전자 장치는 차량, 가구, 제조 설비, 도어, 각종 계측 기기 등에 부품으로서 구비될 수 있다. 이미지 센서는 이미지 또는 광 센싱 기능을 갖는 전자 장치에 탑재될 수 있다. 이미지 센서는 광 학 렌즈를 통하여 입사된 피사체(Object)의 광학적 신호를 전기적 신호로 변환하고, 전기적 신호들을 기초로 이 미지 데이터를 생성하고 외부에 출력할 수 있다. 이미지 센서는 예를 들어, 2차원적으로 배열된 복수의 픽 셀들을 포함하는 픽셀 어레이 및 리드아웃 회로를 포함할 수 있으며, 픽셀 어레이는 수신되는 광 신호들을 전기 적 신호들로 변환할 수 있다. 예시적인 실시 예에서, 픽셀 어레이는 CCD(Charge Coupled Devices) 또는 CMOS(Complementary Metal Oxide Semiconductor) 등의 광전 변환 소자들로 구현될 수 있으며 이외에도 다양한 종류의 광전 변환 소자로 구현될 수 있다. 광전 변환 소자는 입사되는 광의 세기에 따라 가변되는 광전하를 생성할 수 있다. 예를 들어, 광전 변 환 소자는 포토(photo) 다이오드, 포토 트랜지스터, 포트 게이트 또는 핀드 포토 다이오드(pinned photodiode) 등을 포함할 수 있다. 예를 들어, 포토 다이오드(PD)는 P-N 접합 다이오드로서, 입사된 광량에 비례하여 전하, 즉, 음의 전하인 전자와 양의 전하인 정공을 생성할 수 있다. 복수의 픽셀들 각각의 상부에는 마이크로 렌즈 및 컬러 필터가 적층될 수 있다. 예시적인 실시 예에서, 복수의 픽셀들 각각은 적어도 두 개의 광전 변환 소자를 이용하여 객체를 센싱할 수 있다. 본 개시에서, 하나의 마이크 로 렌즈를 공유하는 두 개의 광전 변환 소자를 포함하는 픽셀은 듀얼 픽셀(dual pixel)이라고 지칭될 것이다. 듀얼 픽셀은 좌우 또는 상하로 배치된 한 쌍의 광전 변환 소자들을 포함할 수 있다. 예시적인 실시 예에서, 듀얼 픽셀은 마이크로 렌즈의 광축을 중심으로 왼쪽 방향(또는 위쪽 방향)에 배치된 적어도 하나 의 제1 광전 변환 소자(L) 및 렌즈의 광축을 중심으로 오른쪽 방향(또는 아래쪽 방향)에 배치된 적어도 하나의 제2 광전 변환 소자(R)를 포함할 수 있다. 듀얼 픽셀은 제1 광전 변환 소자로부터 생성되는 제1 이미지 신호 또는 제2 광전 변환 소자로부터 생성되 는 제2 이미지 신호를 출력할 수 있다. 한 쌍의 광전 변환 소자들이 센싱한 동일한 피사체에 대한 제1 이미지 신호 및 제2 이미지 신호의 위상 차이인 디스패리티(Disparity)가 카메라 모듈의 출력인 이미지 데이터에 포함될 수 있다. 듀얼 픽셀을 포함하는 이미지 센서, 또는 이미지 센서를 포함하는 카메라 모듈 은 디스패리티를 이용해 객체와 듀얼 픽셀 간의 거리인 심도(depth)를 추정하거나, 제1 및 제2 이미지 신호들의 위상 차이로부터 자동적으로 초점을 검출할 수 있다. 듀얼 픽셀의 구조에 대하여는 도 3a 내지 도 3c를 참조하여 보다 상세히 설명될 것이다. 리드아웃 회로는 픽셀 어레이로부터 제공되는 전기적 신호를 기초로 배드 픽셀 제거 등의 전처리가 수행된 데이 터를 출력 데이터로서 출력할 수 있다. 이미지 센서는 픽셀 어레이 및 리드아웃 회로를 포함하는 반도체 칩 또는 패키지로서 구현될 수 있다. 이미지 신호 처리기는 이미지 센서으로부터 제공되는 출력 데이터에 대하여 이미지 처리(image processing) 및 보정을 수행할 수 있고, 그 결과를 이미지 데이터(IDAT)로 출력할 수 있다. 예를 들어, 이미지 신호 처리기는 출력 데이터에 대하여 데이터 형식을 변경하는 이미지 처리(예컨대 베이어 패턴의 이미지 데이터를 YUV 또는 RGB 형식으로 변경), 노이즈 제거, 밝기 조정, 선명도(sharpness) 조정 등의 화질 향상을 위 한 이미지 처리 등을 포함할 수 있다. 이미지 신호 처리기의 구조에 관하여는 도 5를 참조하여 보다 상세 히 설명될 것이다. 이미지 신호 처리기는 출력 데이터에 대한 처리 결과로서, 이미지 데이터(IDAT)를 생성할 수 있다. 이미지 데이터(IDAT)는 장면의 광량, 또는 밝기를 나타내는 휘도 데이터(YDAT), 및 장면을 표현할 수 있는 색 공간의 두 점 간의 기하학적 거리인 색차를 나타내는 색차 데이터들(UDAT, VDAT)를 포함할 수 있다. 이미지 데이터 (IDAT)는 메모리에 저장될 수 있다. 본 개시의 예시적 실시 예에 따르면, 이미지 신호 처리기는 듀얼 픽셀로부터 센싱된 출력 데이터들을 처리 및 보정함으로써 제1 이미지 데이터(IDATL) 및 제2 이미지 데이터(IDATR)를 포함하는 스테레오 이미지 데이 터(SIDAT)를 생성할 수 있다. 예를 들어, 이미지 신호 처리기는 제1 광전 변환 소자(L)로부터 센싱된 제1 이미지 신호를 처리 및 보정해 제1 이미지 데이터(IDATL)를 생성할 수 있고, 제2 광전 변환 소자(R)로부터 센싱 된 제2 이미지 신호를 처리 및 보정해 제2 이미지 데이터(IDATR)를 생성할 수 있다. 카메라 모듈은 이미지 센서 및 이미지 신호 처리기를 포함할 수 있다. 카메라 모듈은 이미지 센서에서 생성한 이미지 신호를 처리 및 보정해 스마트폰을 포함하는 모바일 전자 기기에서 처리되기 적합 하도록 이미지 데이터(IDAT)로 변환하는 일체화된 부품일 수 있다. 카메라 모듈은 서로 다른 제조사에서 생 산한 처리 회로를 포함하는 전자 장치에서도 원활히 작동되도록 표준화, 또는 규격화될 수 있다. 처리 회로는 전자 장치의 전반적인 동작, 보다 구체적으로는 전자 장치를 이루는 다른 구성 요소 들(예를 들어, 이미지 센서, 이미지 신호 처리기, 메모리)의 요청을 처리하고, 다른 구성 요소 들을 제어할 수 있다. 예시적인 실시 예에서, 처리 회로는 특정한 태스크(task), 인스트럭션(instruction) 또는 오퍼레이션(operation) 등을 수행할 수 있다. 예시적인 실시 예에서, 인스트럭션은 메모리로부터 로드된 것일 수 있다. 예시적인 실시 예에서, 처리 회로는 범용 프로세서, 전용 프로세서 또는 애플리케이션 프로세서 (Application Processor; AP) 등으로 구현될 수 있다. 예시적인 실시 예에서, 처리 회로는 전용 논리 회 로(예컨대, FPGA(Field Programmable Gate Array), ASICs(Application Specific Integrated Circuits) 등)를 포함하는 연산 프로세서(예를 들어, CPU(Central Processing Unit), GPU(Graphic Processing Unit), NPU(Neural Processing Unit), AP(Application Processor) 등)로 구현될 수 있으나 이에 제한되지 않는다. 처리 회로는 AI(artificial intelligence) 데이터 연산 등 고속 데이터 연산을 위한 전용 회로인 가속기를 더 포함할 수 있고, 가속기는 GPU(Graphics Processing Unit), NPU(Neural Processing Unit) 및/또는 DSP(Digital Signal Processor) 등을 포함할 수 있다. 예시적인 실시 예에 따르면, 가속기는 처리 회로의 다른 구성 요소와는 물리적으로 독립된 별개의 칩(chip)으로 구현될 수도 있다. 예시적 실시 예에 따르면, 처리 회로는 하나 이상의 인공 신경망(Neural Network)을 이용해 데이터를 처리할 수 있다. 또한, 처리 회로 는 하나 이상의 인공 신경망(Neural Network)을 통해 데이터를 학습시킴으로써 인공 신경망을 강화시킬 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 적어도 하나의 처리 회로와 메모리를 통해 동작될 수 있다. 처리 회로는 CPU, AP, DSP 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그 래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 처리 회로는 메모리에 저장 된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어할 수 있다. 처리 회로 가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드 웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데 이터들을 이용하여 학습됨으로써, 원하는 특징(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인 공지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어 질 수도 있고, 별도의 서버 및/또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습 (supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또 는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공 신경망(Neural Network)은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 인공 신경망은 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망에 대하여는 도 10a 내지 도 10c 를 참조하여 보다 상세히 설명될 것이다. 본 개시의 예시적 실시 예에 따르면, 처리 회로는 객체 검출기, 관심 영역 선택기, 및 심도 추 정기를 포함할 수 있다. 객체 검출기는 대상 객체를 포함하는 장면(Scene)을 전체적으로 센싱하고, 장면에 포함된 적어도 하나의 객체를 각각 검출할 수 있다. 객체 검출기는 컴퓨터 비전 분야의 객체 검출(Object Detection) 방식들을 활용할 수 있다. 예를 들어, 객체 검출기는 경계 박스(bounding box)를 이용해 장면에서 객체들을 구분할 수 있고, 각 객체에 대한 참값(groundtruth) 정보를 레이블의 형태로 개별적으로 분류시킨 핸드크래프트 기반 객체 검출, 또는 객체 검출을 위해 설계된 인공신경망을 이용한 AI(Artificial Intelligence) 기반 객체 검출의 방식으로 객체를 검출할 수 있다. 객체 검출기는 적어도 하나의 객체에서 관심 객체(Object Of Interest; OOI)를 탐지할 수 있다. 관심 영역 선택기는 관심 객체를 포함하는 관심 영역(Region Of Interest; ROI)을 결정할 수 있다. 예시적 인 실시 예에 따르면, 관심 영역 선택기는 장면에서 탐지된 관심 객체에 상응하는 영역을 확인하고, 관심 객체를 포함하는 관심 영역을 선택할 수 있다. 예를 들어, 관심 영역은 관심 객체를 검출한 경계 박스보다 클수 있다. 심도 추정기는 절대 심도(absolute depth), 또는 상대 심도(relative depth)를 추정할 수 있다. 예시적인 실시 예에서, 심도 추정기는 인공 신경망을 이용하여 입력 이미지로부터 테두리, 선, 색, 엣지(edge, 객체 의 경계), 밀도(빽빽함(dense), 성김(Sparse)을 포함한다), 심도(depth) 등과 같은 특징들(features)을 추출할 수 있다. 본 개시에서, 밀도가 빽빽한 이미지는 텍스쳐드(textured) 이미지로, 밀도가 성긴 이미지는 언텍스쳐 드(untextured) 이미지로 지칭될 것이다. 텍스쳐드 이미지는 고-주파수에, 언텍스쳐드 이미지는 저-주파수에 각 각 상응할 수 있다. 심도 추정기는 입력 이미지에 대해 특징들을 추출함으로써 절대 심도를 추정할 수 있 다. 예시적인 실시 예에서, 심도 추정기는 장면(Scene)의 전체적인 특징을 학습하도록 구성된 인공 신경망을 이용해 입력 이미지를 가공할 수 있다. 장면의 전체적인 특징을 학습하는 인공 신경망인 장면 네트워크(S.NET) 는 피라미드(pyramid) 구조로 구현될 수 있다. 예시적인 실시 예에 따르면, 장면 네트워크 모듈은 이미지 데이터에 상응하는 장면에 대해 순차적으로 해상도를 낮추어가면서 인코딩을 수행하고, 다시 원래의 해상도로 돌아올 때까지 순차적으로 해상도를 높여가면서 디코딩을 수행할 수 있다. 본 개시의 예시적인 실시 예에 따르 면, 심도 추정기는 장면 네트워크(S.NET)를 이용하여 입력 이미지의 상대 심도를 추정할 수 있다. 메모리는 이미지 센서, 이미지 신호 처리기, 및/또는 처리 회로에서 생성되거나 처리된 데 이터를 저장할 수 있고, 저장된 데이터를 이미지 신호 처리기 및/또는 처리 회로에게 제공할 수 있다. 메모리는 전자 장치의 운영 체제(OS), 애플리케이션, 처리 동작을 위한 인스트럭션을 저장할 수 있 다. 예시적인 실시 예에 따르면, 메모리는 처리 회로와 실시간으로 데이터를 통신하는 워킹 메모리일 수 있다. 예를 들어, 메모리는 휘발성 메모리로서, DRAM(Dynamic Random Access Memory), SRAM(Static Random Access Memory), 모바일 DRAM, DDR SDRAM(Double Data Rate Synchronous Dynamic Random Access Memory), LPDDR(Low Power DDR) SDRAM, GDDR(Graphic DDR) SDRAM, RDRAM(Rambus Dynamic Random Access Memory) 등을 포함할 수 있다. 그러나, 이는 예시적인 실시 예일 뿐, 본 개시의 기술적 사상은 메모리가 비휘발성 메모리를 포함하는 것을 배제하지 않는다. 예를 들어 메모리는 이미지 센서, 이미지 신호 처리기, 및/또는 처리 회로에서 생성되거나 처리된 데이터를 비휘발적으로 저장하는 스토리지 장치일 수 있다. 예시적인 실시 예에서, 메모리는 비휘 발성 메모리로서, EEPROM(Electrically Erasable Programmable Read-Only Memory), 플래시 메모리(flash memory), PRAM(Phase Change Random Access Memory), RRAM(Resistance Random Access Memory), NFGM(Nano Floating Gate Memory), PoRAM(Polymer Random Access Memory), MRAM(Magnetic Random Access Memory), FRAM(Ferroelectric Random Access Memory) 등을 포함할 수 있다. 본 개시의 예시적인 실시 예에 따르면, 메모리는 스테레오 이미지 데이터(SIDAT)를 저장할 수 있다. 스테 레오 이미지 데이터(SIDAT)는 듀얼 픽셀로부터 생성된, 디스패리티를 가지는 한 쌍의 이미지 데이터일 수 있다. 예시적인 실시 예에서, 스테레오 이미지 데이터(SIDAT)는 한 쌍의 포토다이오드들을 포함하는 듀얼 픽셀 중, 좌측 포토다이오드로부터 센싱된 좌측 이미지 데이터(IDATL), 및 우측 포토다이오드로부터 센싱된 우 측 이미지 데이터(IDATR)를 포함할 수 있다. 스테레오 이미지 데이터(SIDAT)는 베이어 패턴으로 센싱된 객체에 대한 원본(raw) 데이터, 또는, 이미지 센서 나 이미지 신호 처리기로부터 일부 보정 및 후처리된 데이터를 포함할 수 있다. 예를 들어, 스테레오 이미지 데이터(SIDAT)는 YUV 색 공간을 따르는 YUV 형식의 데이터들을 포함할 수 있다. YUV 형식의 데이터는 휘 도 데이터(YDAT), 및 색차 데이터(UDAT, VDAT)를 포함할 수 있다. 휘도 데이터(YDAT) 및 색차 데이터들(UDAT, VDAT)은 YUV 형식을 따르는 이미지 데이터의 일부로서 이미지 신호 처리기에 의해 생성된 것일 수 있다. 휘도 데이터(YDAT), 및 색차 데이터들(UDAT, VDAT)은 메모리에 논리적, 또는 물리적으로 분리된 공간에 별 도로 저장될 수 있다. 예시적인 실시 예에 따라, 처리 회로는 YUV 형식의 이미지 데이터 중, 휘도 데이터 (YDAT)만을 이용할 수 있다. 제1 버스(BUS1)는 이미지 센서, 이미지 신호 처리기, 처리 회로, 및 메모리 와의 데이터 통신을 중계할 수 있다. 예시적인 실시 예에서, 제1 버스(BUS1)는 어드레스 버스(address bus), 제어 버스 (control bus) 및 데이터 버스(data bus) 등과 같은 버스 타입을 이용하여 처리 회로, 메모리, 및 메모리와의 제어 신호, 데이터, 및 어드레스의 송수신을 중계할 수 있다.도 1에 도시된 이미지 센서, 이미지 신호 처리기, 처리 회로, 메모리, 및 제1 버스(BUS 1)를 포함하는 전자 장치 시스템-온-칩(System On Chip, SoC)으로 구현될 수 있다. 시스템-온-칩은 하나의 칩으로 전자 장치를 구동시키는 데에 필요한 하드웨어 모듈을 포함하는 반도체 칩이다. 예시적인 실시 예 에서, 시스템-온-칩은 복수의 하드웨어 모듈 각각의 기능이 수행되는 데에 필요한 애플리케이션(Application)과 내장 소프트웨어를 결합하여 탑재할 수 있다. 애플리케이션(또는 프로그램)은 특정 목적을 수행하는 응용 소 프트웨어일 수 있다. 예시적인 실시 예에 따르면, 애플리케이션은 적어도 하나의 함수(function)를 이용하여 실 행될 수 있다. 애플리케이션은 소스 코드(source code)를 실행함으로써 빌드(build)될 수 있다. 시스템-온-칩을 이용함으로써, 기판에 각 소자들을 탑재하는 공간이 줄어들어 제품 소형화가 가능하고, 여러 기능 소자들을 별 도로 생산하는 것에 비해 제조 비용이 절감될 수 있다. 본 개시의 예시적인 실시 예에 따르면, 전자 장치는 제1 광전 변환 소자(L) 및 제2 광전 변환 소자(R) 중 어느 하나에서 출력된 이미지 신호에 기초해 관심 객체를 검출할 수 있다. 예시적인 실시 예에 따르면, 카메라 모듈은 듀얼 픽셀을 이용해 대상 객체를 포함하는 장면(Scene)을 전체적으로 센싱할 수 있고, 메모리 는 제1 광전 변환 소자(L)로부터 센싱되고 이미지 신호 처리기에 의해 보정된 제1 이미지 데이터 (IDATL), 및 제2 광전 변환 소자(R)로부터 센싱되고 이미지 신호 처리기에 의해 보정된 제2 이미지 데이터 (IDATR)를 저장할 수 있다. 처리 회로는 메모리에 저장된 스테레오 이미지 데이터(SIDAT) 중 어느 하 나(예를 들어, 제1 이미지 데이터(IDATL))를 이용하여 장면에 포함된 관심 객체를 검출할 수 있다. 이로써, 본 개시의 예시적 실시 예에 따른 전자 장치는 장면 전체에 대한 스테레오 이미지가 아닌, 어느 하나의 이미지 데이터만을 이용할 수 있고, 데이터 처리량을 감축시킬 수 있다. 본 개시의 예시적인 실시 예에 따르면, 전자 장치는 관심 영역만을 센싱함으로써 심도 추정에 필요한 데이 터 처리량을 감축시킬 수 있다. 그에 따라, 전자 장치의 전력 소모는 절감될 수 있고, 데이터 처리 속도는 향상 될 수 있다. 또한, 본 개시의 예시적인 실시 예에 따르면, 전자 장치는 YUV 데이터 중 휘도 데이터만을 인공 신경망에 학습시킴으로써 메모리 사용량 및 전력 소비량을 감축시킬 수 있고, 저조도 환경에서도 심도 추정 정확도를 향 상시킬 수 있다. 도 2는 이미지 센서를 상세히 나타내는 블록도이다. 이미지 센서는 이미지 또는 광 센싱 기능을 갖는 전자 기기에 탑재될 수 있다. 예를 들어, 이미지 센서 는 카메라, 스마트폰, 웨어러블 기기, 사물 인터넷(Internet of Things(IoT)) 기기, 가전 기기, 태블릿 PC(Personal Computer), PDA(Personal Digital Assistant), PMP(portable Multimedia Player), 네비게이션 (navigation), 드론(drone), 첨단 운전자 보조 시스템(Advanced Drivers Assistance System; ADAS) 등과 같은 전자 기기에 탑재될 수 있다. 또한 이미지 센서는 차량, 가구, 제조 설비, 도어, 각종 계측 기기 등에 부 품으로서 구비되는 전자 기기에 탑재될 수 있다. 도 2를 참조하면, 이미지 센서는 렌즈(LS), 픽셀 어레이, 로우 디코더, 제어 로직, 램프 생성기, 및 리드아웃 회로를 포함할 수 있다. 도 1에 도시되지는 않았으나, 이미지 센서는 클럭 신호 생성기, 신호 처리기, 컬럼 디코더, 및/또는 메모리를 더 포함할 수 있음이 이해되어야 한다. 이미지 센서는 광학 장치를 통하여 입사된 객체(OBJECT)의 광학적 신호를 전기적 신호로 변환하고, 전기적 신호들을 기초로 이미지 데이터(IDAT)를 생성할 수 있다. 광학 장치는 거울 및 렌즈(LS)를 포함하는 광학적 집 광 장치일 수 있다. 예를 들어, 이미지 센서는 빛의 분산이나 굴절 등 광학적 특성을 이용하여 객체 (OBJECT)에 의해 반사된 빛의 다양한 경로를 집광하거나, 빛의 이동 경로를 변경할 수 있는 광학 장치를 이용할 수 있다. 본 개시에서는 설명의 편의를 위해, 렌즈(LS)가 이용되는 것으로 가정되나 전술한 바와 같이 다양한 광학 장치를 이용해 본 개시의 기술적 사상이 구현될 수 있음이 이해될 수 있다. 픽셀 어레이는 광학 신호를 전기적 신호로 변환하는 CIS(Complementary Metal Oxide Semiconductor Image Sensor)일 수 있다. 렌즈(LS)를 투과한 광학 신호는 픽셀 어레이의 수광면에 도달하여 피사체의 상을 결상 할 수 있다. 이와 같은 픽셀 어레이는 제어 로직의 제어에 의해 광학 신호의 감도 등을 조절할 수 있 다. 픽셀 어레이는 매트릭스 형태로 배열된 수의 픽셀들에 신호를 전달하는 복수의 로우 라인들(RLs) 및 복수 의 컬럼 라인들(CLs)과 연결될 수 있다. 예를 들어, 복수의 로우 라인들(RLs) 각각은 픽셀에 포함된 트랜지스터들 각각에 로우 디코더로부터 출력되는 제어 신호들을 전송할 수 있으며, 복수의 컬럼 라인들(CLs) 각각은 픽셀 어레이의 열 단위로 픽셀들의 픽셀 신호를 리드아웃 회로에 전송할 수 있다. 복수의 컬럼 라인 들(CLs) 각각은 컬럼 방향으로 연장되며, 동일한 컬럼에 배치된 픽셀과 리드아웃 회로를 서로 연결할 수 있다. 픽셀 어레이의 복수의 픽셀들 각각은 적어도 하나의 광전 변환 소자 및 트랜지스터를 포함할 수 있다. 예 를 들면, 픽셀 어레이는 CCD(Charge Coupled Devices) 또는 CMOS(Complementary Metal Oxide Semiconductor) 등의 광전 변환 소자(또는 광 감지 소자)로 구현될 수 있으며 이외에도 다양한 종류의 광전 변 환 소자로 구현될 수 있다. 예시적인 실시 예에 따르면, 광전 변환 소자는 빛을 감지하고, 감지된 빛을 광전하 로 변환할 수 있다. 예를 들어, 광전 변환 소자는 무기 포토(photo) 다이오드, 유기 포토다이오드, 페로브 스카 이트 포토다이오드, 포토 트랜지스터, 포토 게이트 또는 핀드 포토다이오드(pinned photodiode) 등과 같이, 유 기 물질 또는 무기 물질로 구성되는 광 감지 소자일 수 있다. 예시적 실시 예에 있어서, 트랜지스터는 광전 변 환 소자에 저장된 전하를 전송시키거나, 전원 전압으로 리셋시키거나, 전하를 전기적 신호로 변환할 수 있다. 복수의 픽셀 각각의 상부에는 마이크로 렌즈 및 컬러 필터가 적층될 수 있으며, 복수의 픽셀의 복수의 컬러 필 터가 컬러 필터 어레이를 구성할 수 있다. 컬러 필터는 마이크로 렌즈를 통해 입사되는 빛 중 특정 색상의 빛, 다시 말해서 특정 색상 영역의 파장을 투과시킬 수 있다. 픽셀에 구비되는 컬러 필터에 따라 픽셀이 감지할 수 있는 색상이 결정될 수 있다. 그러나, 이에 제한되는 것은 아니며, 실시 예에 있어서, 픽셀에 구비되는 광전 변 환 소자는 인가되는 전기 신호의 레벨, 예컨대 전압 레벨에 따라서, 색상 영역의 파장에 해당하는 빛을 전기적 신호로 변환할 수 있으며, 이에 따라서, 광전 변환 소자에 인가되는 전기 신호의 레벨에 따라서 픽셀이 감지할 수 있는 색상이 결정될 수도 있다. 예시적인 실시 예에서, 픽셀 어레이의 복수의 픽셀들 각각은 마이크로 렌즈 및 마이크로 렌즈 아래에 나란 하게 배치된 적어도 하나 이상의 광전 변환 소자를 포함할 수 있다. 복수의 픽셀들 각각은 적어도 하나의 듀얼 픽셀을 이용하여 객체를 센싱할 수 있다. 예시적인 실시 예에서, 듀얼 픽셀은 마이크로 렌즈의 광축 을 중심으로 왼쪽 방향(또는 위쪽 방향)에 배치된 적어도 하나의 제1 광전 변환 소자(L) 및 렌즈의 광축을 중심 으로 오른쪽 방향(또는 아래쪽 방향)에 배치된 적어도 하나의 제2 광전 변환 소자(R)를 포함할 수 있다. 이 외 에도, 픽셀은 제1 광전 변환 소자 및 제2 광전 변환 소자로부터 생성되는 이미지 신호가 합산되는 합산 이미지 신호를 출력할 수 있다. 복수의 픽셀들은 컬러 픽셀, 예를 들어 레드(red) 픽셀, 그린(green) 픽셀, 및 블루(blue) 픽셀을 포함할 수 있 다. 컬러 픽셀은 서로 다른 컬러 필터를 통과한 빛에 기초하여 해당 컬러 정보를 포함하는 이미지 신호를 생성 할 수 있다. 본 개시에서는 서로 다른 컬러 정보를 생성하는 컬러 필터, 또는 서로 다른 컬러 정보를 포함하는 이미지 신호를 생성하는 컬러 픽셀 각각, 또는 컬러 픽셀들의 집합을 컬러 채널이라고 지칭한다. 예를 들어, 레 드 채널은 레드 필터 그 자체, 또는 레드 필터를 통과한 빛을 처리하는 픽셀인 레드 픽셀을 지칭할 수 있고, 블 루 채널은 블루 필터 그 자체, 또는 블루 필터를 통과한 빛을 처리하는 픽셀인 블루 픽셀을 지칭할 수 있으며, 그린 채널은 그린 필터 그 자체, 또는 그린 필터를 통과한 빛을 처리하는 픽셀인 그린 픽셀을 지칭할 수 있다. 본 개시에서는 레드, 그린, 블루의 컬러가 예시되었으나, 복수의 픽셀은 다른 색 구성으로 조합된 픽셀들, 예컨 대 옐로우(Yellow) 픽셀, 사이언(Cyan) 픽셀 및 화이트 픽셀을 포함할 수 있다. 레드 픽셀은, 가시광 영역 중에서 레드 영역의 파장들에 응답하여, 레드 컬러 신호에 상응하는 이미지 신호(또 는 전하들)를 생성할 수 있다. 그린 픽셀은, 가시광 영역 중에서 그린 영역의 파장들에 응답하여, 그린 컬러 신 호에 상응하는 이미지 신호(또는 전하들)를 생성할 수 있다. 블루 픽셀은, 가시광 영역 중에서 블루 영역의 파 장들에 응답하여, 블루 컬러 신호에 상응하는 이미지 신호(또는 전하들)를 생성할 수 있다. 그러나, 이에 한정 되는 것은 아니며, 복수의 픽셀은 화이트 픽셀을 더 포함할 수 있다. 다른 예로서, 복수의 픽셀은 시안(cyan) 픽셀, 옐로우(yellow) 픽셀, 마젠타(magenta) 픽셀, 또는 화이트 픽셀을 포함할 수도 있다. 로우 디코더는 제어 로직의 제어(예를 들어, 행 제어 신호(CTR_X)) 하에, 픽셀 어레이를 구동하 기 위한 제어 신호들을 생성할 수 있고, 복수의 로우 라인들(RLs)을 통해 픽셀 어레이의 복수의 픽셀을 행 마다 구동시킬 수 있다. 복수의 로우 라인들(RLs) 각각은 행 방향으로 연장되며, 동일한 로우에 배치된 픽셀에 연결될 수 있다. 예시적인 실시 예에서, 로우 디코더는 픽셀 어레이의 복수의 픽셀들이 동시에 또는 행(row) 단위로 입사되는 광을 감지하도록 픽셀들을 제어할 수 있다. 또한 로우 디코더는 복수의 픽셀들을 행 단위로 픽셀 들을 선택하고, 선택된 픽셀들(예컨대 한 행의 픽셀들)에 리셋 신호를 제공하여 픽셀을 리셋시킬 수 있으며, 선택된 픽셀들이 생성하는 센싱 전압이 복수의 컬럼 라인들(CLs)을 통해 출력되도록 제어할 수 있다. 제어 로직은 로우 디코더, 램프 생성기 및 리드아웃 회로의 타이밍을 제어하는 제어 신호 들을 제공할 수 있다. 예를 들어, 제어 로직은 로우 디코더에 행 제어 신호(CTR_X)를 제공할 수 있고, 로우 디코더 는 행 제어 신호(CTR_X)에 기초하여 로우 라인들(RLs)을 통해 픽셀 어레이를 행마 다 센싱시킬 수 있다. 예를 들어, 제어 로직은 램프 생성기에 램프 신호를 제어하는 램프 제어 신호 (CTR_R)를 제공할 수 있고, 램프 생성기는 램프 제어 신호(CTR_R)에 기초하여 리드아웃 회로의 동작 을 위한 램프 신호(RMP)를 생성할 수 있다. 예를 들어, 제어 로직은 리드아웃 회로에 열 제어 신호 (CTR_Y)를 제공할 수 있고, 리드아웃 회로는 열 제어 신호(CTR_Y)에 기초하여 컬럼 라인들(CLs)을 통해 픽 셀 어레이로부터의 픽셀 신호를 수신하고 처리할 수 있다. 본 개시의 예시적인 실시 예에 따르면, 제어 로직은 모드 신호(MODE)에 기초하여 이미지 센서를 전반 적으로 제어할 수 있다. 예시적인 실시 예에 따르면, 전자 장치는 복수의 동작 모드에 따라 객체를 센싱하 고 처리할 수 있다. 예를 들어, 전자 장치는 동작 모드로서, 듀얼 픽셀(도 1, 101)을 이용해 스테레오 이미지 데이터(도 1, SIDAT)를 생성하는 제1 모드를 지원할 수 있다. 또한, 전자 장치는 듀얼 픽셀을 이용하는 대신 하나의 픽셀에 마련된 하나의 광전 변환 소자로부터의 이미지 신호에 기초한 단일 이미지 데이터를 생성하거나, 듀얼 픽셀을 이용하되 듀얼 픽셀에 포함된 복수의 광전 변환 소자들 각각의 이미지 신호를 합산해 이미지 데이터를 생성하는 제2 모드를 지원할 수 있다. 제2 모드는 디스패리티를 가지지 않으며, 플로팅 디퓨전 노드(Floating Diffusion Node)가 공유되는 FD 공유 모 드로도 지칭될 수 있다. 또한, 전자 장치는 하나의 광전 변환 소자로부터의 이미지 신호에 기초한 단일 이미지 데이터에 더하여, 듀 얼 픽셀로부터 센싱된 스테레오 휘도 데이터를 추가적으로 생성하는 제3 모드를 지원할 수 있다. 여기에서, 스테레오 휘도 데이터는, 듀얼 픽셀 중 제1 광전 변환 소자에 의해 생성된 제1 휘도 데이터 및, 제2 광전 변환 소자에 의해 생성된 제2 휘도 데이터를 포함할 수 있다. 이미지 센서는 제어 로직의 제어에 따라 제1 모드 내지 제3 모드에 상응하도록 듀얼 픽셀을 선 택적으로 이용해 객체를 센싱하거나, 적어도 두개의 광전 변환 소자로부터 센싱된 이미지 신호를 합산하거나, 센싱된 데이터를 가공해 휘도 데이터를 센싱하거나, 휘도 데이터 및 합산 이미지 신호를 생성할 수 있다. 예시적인 실시 예에서, 제어 로직은 애플리케이션 프로세서로부터 모드 신호(MODE)를 수신하고, 픽셀 어레 이의 복수의 픽셀들 각각이 독립적인 픽셀 신호를 출력하도록 행 제어 신호(CTR_X), 열 제어 신호(CTR_Y), 및 램프 제어 신호(CTR_R)를 제어할 수 있고, 픽셀 어레이는 행 제어 신호(CTR_X) 및 열 제어 신호(CTR_ Y)에 기초하여 복수의 픽셀들 각각을 출력할 수 있으며, 리드아웃 회로는 램프 신호(RMP)에 기초하여 픽셀 신호들을 샘플링하고 처리할 수 있다. 예를 들어, 애플리케이션 프로세서는 촬상 환경의 조도, 사용자의 해상도 설정, 센싱되거나 학습된 상태 등 다양한 시나리오에 따라 이미지 센서의 촬상 모드를 결정한 결과를 모드 신호(MODE)로 제공할 수 있다. 제어 로직은 크롭 신호(CROP)를 제공받고, 관심 객체에 상응하는 영역, 또는 관심 객체를 포함하는 영역을 센싱하도록 이미지 센서를 제공할 수 있다. 예를 들어, 이미지 센서는 장면 중 관심 영역에 대응되는 영역만을 센싱하도록 렌즈(LS)의 초점 거리를 조절하거나, 행 제어 신호(CTR_X) 및 열 제어 신호(CTR_Y)를 조절 할 수 있다. 본 개시의 예시적인 실시예에서, 이미지 센서는 크롭 신호(CROP)에 기초해 관심 영역만을 센 싱함으로써 종전의 높은 해상도를 유지하되, 상대적으로 적은 데이터 처리량에 따른 처리 속도의 향상 및 전력 소모의 감축을 도모할 수 있다. 제어 로직은 로직 회로를 포함하는 하드웨어와 같은 처리 회로로서 구현될 수 있거나, 압축 동작을 수행하 는 소프트 웨어를 실행하는 프로세서와 같이 하드웨어와 소프트웨어의 조합으로 구현 될 수 있다. 특히, 제어 로직은 이미지 센서에 포함된 중앙 처리 장치(Central Procesing Unit; CPU), 산술 및 논리 연산, 비트 쉬프트 등을 수행하는 ALU(Arithmetic Logic Unit), DSP(Digital Signal Processor), 마이크로프로세서 (microprocessor), ASIC(Application Specific Integrated Circuit), 컨트롤 로직(control logic) 등으로 구 현될 수 있으나, 이에 제한되지 않고, 인공 신경망 등의 보조, 또는 인공 신경망 그 자체를 이용한 가속기 (Accelerator), NPU(Neural Processing Unit) 등을 더 이용할 수도 있다. 램프 생성기는 소정의 기울기를 가지며 점진적으로 증가 또는 감소하는 램프 신호(RMP)를 생성하고, 램프 신호(RMP)를 리드아웃 회로에 제공할 수 있다. 리드아웃 회로는 픽셀 어레이로부터 출력된 픽셀 신호를 컬럼 라인들(CLs)을 통해 수신하고, 픽셀 신 호를 처리하여 이미지 데이터(IDAT)로 출력할 수 있다. 리드아웃 회로는 상관 이중 샘플링(CDS) 회로 , 아날로그-디지털 컨버팅(ADC) 회로 및 버퍼를 포함할 수 있다. 상관 이중 샘플링 회로는 복수의 비교기들을 포함할 수 있고, 복수의 컬럼 라인들(CLs)을 통해 픽셀 어레 이로부터 수신되는 픽셀 신호를 램프 생성기로부터의 램프 신호(RMP)와 비교할 수 있다. 비교기는 수 신되는 픽셀 신호를 버퍼링된 램프 신호(RMP)와 비교하고, 비교 결과를 로직 로우, 또는 로직 하이로 출력할 수 있다. 예를 들어, 비교기는 램프 신호(RMP)의 레벨과 픽셀 신호의 레벨이 동일할 때, 제1 레벨(예컨대 로직-하 이)에서 제2 레벨(예컨대 로직-로우)로 천이하는 비교 신호를 출력할 수 있으며, 비교 신호의 레벨이 천이되는 시점은 픽셀 신호의 레벨에 따라 결정될 수 있다. 복수의 픽셀들로부터 출력되는 복수의 픽셀 신호는 각 픽셀마다 가지는 고유의 특성(예컨대, FPN(Fixed Pattern Noise) 등)에 의한 편차 및/또는 픽셀로부터 픽셀 신호를 출력하기 위한 로직(예컨대, 픽셀 내에서 광전 변환 소자에 저장된 전하를 출력하기 위한 트랜지스터들)의 특성 차이에 기인한 편차를 가질 수 있다. 이와 같이, 복 수의 컬럼 라인들(CLs)을 통해 출력되는 복수의 픽셀 신호간의 편차를 보상하기 위하여, 픽셀 신호에 대하여 리 셋 전압(또는 리셋 성분) 및 센싱 전압(또는 센싱 성분)를 구하고 그 차이(예컨대 전압 차이)를 유효한 신호 성 분으로 추출하는 것을 상관 이중 샘플링(Correlated Double Sampling)이라고 한다. 비교기는 상관 이중 샘플링 기법이 적용된 비교 결과(예컨대 비교 출력)를 출력할 수 있다. 결과적으로, 상관 이중 샘플링 회로는 상 관 이중 샘플링(Correlated Double Sampling; CDS) 기법이 적용되는 비교 결과를 생성할 수 있다. 아날로그 디지털 컨버팅 회로는 상관 이중 샘플링 회로의 비교 결과를 디지털 데이터로 변환함으로써, 복수의 픽셀에 대응하는 픽셀값들을 행(row) 단위로 생성 및 출력할 수 있다. 아날로그 디지털 컨버팅 회로는 복수의 카운터들을 포함할 수 있다. 복수의 카운터들은 복수의 비교기들 각각의 출력에 연 결되며, 비교기로부터 출력되는 비교 결과를 카운팅할 수 있다. 카운터는 리셋 신호를 센싱하는 리셋 변환 구간 및 센싱 신호를 센싱하는 이미지 변환 구간에 카운팅 클럭을 기초로 비교기로부터 출력되는 로직 하이 또는 로 직 로우의 비교 결과를 카운팅할 수 있고, 카운팅 결과에 따른 디지털 데이터(예를 들어, 픽셀값)를 출력할 수 있다. 카운터는 래치 회로 및 연산 회로를 포함할 수 있다. 래치 회로는 비교기로부터 수신되는 비교 신호의 레 벨이 천이되는 시점에 카운팅 클럭 신호로서 수신되는 코드 값을 래치할 수 있다. 래치 회로는 리셋 신호에 대 응하는 코드 값, 예컨대 리셋 값 및 이미지 신호에 대응하는 코드 값, 예컨대 이미지 신호 값 각각을 래치할 수 있다. 연산 회로는 리셋 값과 이미지 신호 값을 연산하여, 픽셀의 리셋 레벨이 제거된 이미지 신호 값을 생성할 수 있다. 카운터는 리셋 레벨이 제거된 이미지 신호 값을 픽셀값으로서 출력할 수 있다. 그러나, 이에 제한되는 것은 아니며, 카운터는, 카운팅 클럭 신호를 기초로 카운트 값이 순차적으로 증가하는 업-카운터와 연산 회로, 또는 업/다운 카운터, 또는 비트-와이즈 인버젼 카운터(bit-wise inversion counter)로 구현될 수도 있다. 버퍼는 아날로그 디지털 컨버팅 회로로부터 출력되는 픽셀값을 각각 저장할 수 있다. 버퍼는 각 행(row)마다의 디지털 데이터(예를 들어 픽셀값)을 저장할 수 있다. 예시적인 실시 예에서, 버퍼는 카운터 로부터 출력되는 복수의 디지털 데이터들을 임시 저장한 후, 증폭하여 출력할 수 있다. 즉, 버퍼는 출력 버퍼일 수 있다. 버퍼는 복수의 카운터 각각으로부터 출력되는 디지털 데이터를 임시 저장한 후 차례로 또 는 선택적으로 센스 앰프(미도시)로 출력할 수 있으며, 센스 앰프는 수신되는 디지털 데이터를 증폭하여 출력할 수 있다. 버퍼는 제어 로직의 제어에 따라 컬럼을 선택하는 컬럼 디코더(미도시)의 열 제어 신호 (CTR_Y)에 기초하여 증폭된 이미지 데이터(IDAT)를 외부로 출력할 수 있다. 버퍼는 SRAM (static random access memory), 래치(latch), 플립-플롭(flipflop), 또는 이들의 결합으로 구현될 수 있으나 이에 한정되는 것은 아니다. 예시적인 실시 예에 있어서, 버퍼는 메모리로서 아날로그 디지털 컨버팅 회로 내부에 포함될 수도 있다. 예시적인 실시 예에서, 이미지 센서는 자동 초점 검출(auto focusing; 이하 AF) 기능을 지원할 수 있으며, 자동 초점 검출을 위해, 위상차 AF 기술이 이용될 수 있다. 위상차 AF는 이미지 센서에 맺힌 상의 위상의 디스패리티(disparity)를 감지하여, 포커스를 조정하는 방식이다. 위상차 AF는 전핀과 후핀의 경우 모두 위상차 가 커지는 특성이 있다. 위상차 AF는 감지된 위상차를 통해 위상차값 뿐 아니라, 핀의 방향 정보를 알 수 있으 므로, 포커스 렌즈를 한번만 움직여서 포커싱이 가능한 장점이 있다. 예를 들어, 이미지 센서는 위상차와 핀의 방향 정보에 따른 렌즈의 이동값을 미리 계산해 놓고, 이를 참조하여, 포커스 렌즈를 한번 구동하여 포커 싱을 할 수 있다. 따라서, 위상차 AF를 이용한 이미지 센서는 전자 뷰 파인더의 디스플레이 울렁임이 없이신속한 포커싱이 가능하다. 도 3a는 픽셀의 구조를, 도 3b 및 도 3c는 본 개시의 예시적인 실시 예에 따른 픽셀의 구조를 각각 나타내는 도 면이다. 도 3a 내지 도 3c 중 서로 중복되는 설명은 생략될 것이다. 도 3a를 참조하면, 픽셀(101a)은 마이크로 렌즈, 광전 변환 소자 및 컬러 필터를 포함할 수 있다. 예를 들어, 복수의 픽셀들(PX1, PX2) 각각은 광전 변환 소자 중 일 구현예로서 포토다이오드(PD1, PD2), 컬러 필터(CF1, CF2)를 포함하고, 컬러 필터(CF1, CF2) 상부에는 마이크로 렌즈(ML1, ML2)가 구비될 수 있다. 예시적인 실시 예 에 따라 마이크로 렌즈(ML)의 수직 단면 형상은 원의 곡률을 가지는 호이거나, 타원의 일부일 수 있다. 도 3a에 예시된 실시 예에 따르면, 하나의 포토다이오드(PD1 또는 PD2) 상에 하나의 컬러 필터(CF1 또는 CF2) 및 하나의 마이크로 렌즈(ML1 또는 ML2)가 각각 구비될 수 있다. 예를 들어, 마이크로 렌즈(ML1)의 중심으로 입 사한 빛은 컬러 필터(CF1)를 통과함으로써 특정 파장 대역의 빛(예를 들어, 그린 컬러에 상응하는 500~600nm(nano-meter))만 투과되고, 투과된 특정 파장 대역의 빛은 포토다이오드(PD1)에 결상(imagery)될 수 있다. 유사하게, 마이크로 렌즈(ML2)의 중심으로 입사한 빛은 컬러 필터(CF2)를 통과함으로써 특정 파장의 빛만 투과되고, 투과된 특정 파장의 빛은 포토다이오드(PD2)에 결상될 수 있다. 도 3a에 예시된 바와 같이, 하나의 마이크로 렌즈(ML1 또는 ML2)에 입사된 빛이 하나의 포토다이오드(PD1 또는 PD2)에 결상되는 경우는 싱글-포토 다이오드(Single-PD)라고 지칭될 수 있다. 이미지 센서(도 1, 100)는 픽셀(101a)을 이용해 포토다이오드들(PD1 및 PHD2) 간의 위상 차에 따른 디스패리티를 산출함으로써 객체와의 거리를 판단할 수 있다. 도 3b를 참조하면, 듀얼 픽셀(101b)은 마이크로 렌즈, 광전 변환 소자 및 컬러 필터를 포함할 수 있다. 예를 들 어 픽셀(PXx)은 두 개의 컬러 필터들(CFa 및 CFb) 및, 컬러 필터들 (CFa 및 CFb) 각각에 대응되는 제1 및 제2 포토다이오드(PDa 및 PDb)를 포함할 수 있으며, 유사하게 픽셀(PXy)은 두 개의 컬러 필터들 (CFc 및 CFd) 및, 컬러 필터들(CFc 및 CFd) 각각에 대응되는 제3 및 제4 포토다이오드들(PDc 및 PDd)를 포함할 수 있다. 도 3b에 예시된 실시 예에 따르면, 하나의 마이크로 렌즈(MLx) 하에 두 개의 컬러 필터들(CF1 및 CF2) 및 두 개 의 제1 및 제2 포토다이오드들(PDa, PDb)이 각각 구비될 수 있다. 예를 들어, 마이크로 렌즈(MLx)의 중심으로 입사한 빛 중 일부인 제1 광속(LFx)은 컬러 필터(CFa)를 통과하여 포토다이오드(PDa)에 결상될 수 있고, 마이크 로 렌즈(MLx)의 중심으로 입사한 빛 중 나머지 일부인 제2 광속(LXy)은 컬러 필터(CFb)를 통과하여 포토다이오 드(PDb)에 결상될 수 있다. 픽셀(PXy)에도 픽셀(PXx)과 유사한 현상이 발생할 수 있다. 도 3b에 예시된 바와 같 이, 하나의 마이크로 렌즈(MLx 또는 MLy)에 입사된 빛이 두 개의 제1 및 제2 포토다이오드(PDa 및 PDb)(또는, 제3 및 제4 포토 다이오드들(PDc 및 PDd))에 결상되는 경우는 듀얼-포토다이오드(Dual-PD), 또는 듀얼 픽셀(도 1, 101)이라고 지칭될 수 있다. 도 3c는 도 3b의 듀얼 픽셀의 평면도이다. 도 3c를 참조하면, 픽셀(PXx)은 마이크로 렌즈(MLx) 및 두 개의 서브 픽셀, 예컨대 제1 서브 픽셀(SPXa) 및 제2 서브 픽셀(SPXb)을 포함할 수 있다. 제1 서브 픽셀(SPXa) 및 제2 서 브 픽셀(SPXb)은 컬럼 방향, 예컨대 Y 축 방향(제2 방향)으로 나란하게 배치될 수 있다. 예를 들어, 제1 서브 픽셀(SPXa)은 픽셀(PXx) 내에서 왼쪽에 배치되고 제2 서브 픽셀(SPXb)은 픽셀(PXx) 내에서 오른쪽에 배치될 수 있다. 제1 서브 픽셀(SPXa) 및 제2 서브 픽셀(SPXb)은 제1 포토다이오드(PDa) 및 제2 포토다이오드(PDb)를 각각 포함할 수 있다. 예시적인 실시 예에 따르면, 제1 포토다이오드(PDa) 및 제2 포토다이오드(PDb)에서 센싱 신호가 생성될 수 있다. 예를 들어, 제1 서브 픽셀(SPXa)에서는 제1 이미지 신호들이, 제2 서브 픽셀(SPXb)에서는 제2 이미지 신 호들이 각각 출력되고, 제1 및 제2 이미지 신호들에 기초하여 위상차 연산에 따른 디스패리티가 산출될 수 있다. 본 개시의 예시적인 실시 예에 따르면, 듀얼 픽셀에 포함된 복수의 광전 변환 소자(예를 들어, 한 쌍의 제 1 포토다이오드(PDa), 및 제2 포토다이오드(PDb), 또는, 한 쌍의 제3 포토다이오드(PDc) 및 제4 포토다이오드 (PDd)) 중 어느 하나(예를 들어, 제1 포토다이오드(PDa) 및 제2 포토다이오드(PDb) 중 어느 하나, 또는 제3 포 토다이오드(PDc) 및 제4 포토다이오드(PDd) 중 어느 하나)를 이용해 관심 객체가 검출될 수 있다. 본 개시의 예 시적 실시 예에 따른 처리 회로(도 1, 300)는 관심 객체를 포함하는 관심 영역을 센싱하도록 지시하는 크롭 신 호(도 1, CROP)를 생성해 이미지 센서(도 1, 100)에 제공할 수 있고, 이미지 센서는 크롭 신호(CROP)에 기 초해 관심 영역만을 센싱함으로써 종전의 높은 해상도를 유지하되, 상대적으로 적은 데이터 처리량에 따른 처리 속도의 향상 및 전력 소모의 감축을 도모할 수 있다. 도 4a는 및 도 4b는 본 개시의 예시적인 실시 예에 따른 장면에 대한 카메라 종류 별 디스패리티 차이를 나타내 는 도면이다. 도 4a를 참조하면, 서로 다른 이미지 센서에 포함된 서로 다른 광전 변환 소자들(121, 및 123)이 센싱하는 장면 (SCENE)이 도시된다. 예시적인 실시 예에 따르면, 제5 광전 변환 소자, 및 제6 광전 변환 소자는 장면에 포함된 복수의 객 체 중 관심 객체인 토끼에 대해 센싱할 수 있다. 제5 광전 변환 소자는 토끼의 오른쪽 귀 및 왼쪽 귀를 포 함하는 영역까지 센싱할 수 있다. 한편, 제6 광전 변환 소자는 토끼의 귀를 포함하지 않고 토끼의 몸통만 을 포함하는 영역만을 센싱할 수 있다. 이와 같이, 서로 다른 이미지 센서에 포함된 광전 변환 소자들(121, 및 123)은 광전 변환 소자들 간의 거리인 베이스라인이 제1 거리(distance1)만큼 길기 때문에, 상대적으로 디스패 리티가 클 수 있다. 도 4b를 참조하면, 동일한 이미지 센서에 포함된 듀얼 픽셀이 센싱하는 장면(SCENE)이 도시된다. 듀얼 픽 셀은 장면에 포함된 복수의 객체 중 관심 객체인 토끼에 대해 센싱할 수 있는데, 듀얼 픽셀은 장면에 서 토끼의 몸통 및 귀를 포함한 관심 객체 전체에 대해 실질적으로 근접하거나 유사한 영역을 센싱할 수 있다. 이와 같이, 동일한 이미지 센서에 포함된 듀얼 픽셀은 광전 변환 소자들 간의 거리인 베이스라인이 제1 거 리(distance1)보다 짧은 제2 거리(distance2)기 때문에, 상대적으로 디스패리티가 작을 수 있다. 따라서, 듀얼 픽셀을 이용하는 이미지 센서, 또는 이미지 센서를 포함하는 전자 장치는 심도 정보를 정확 히 추정하기 어려울 수 있다. 본 개시는 이를 극복하기 위해 관심 영역만을 센싱함으로써 종전의 높은 해상도를 유지하되, 상대적으로 적은 데이터 처리량에 따른 처리 속도의 향상 및 전력 소모의 감축을 도모하는 전자 장치 및 전자 장치의 동작 방법을 제안한다. 도 5는 본 개시의 예시적인 실시 예에 따른 이미지 신호 처리기를 상세히 나타내는 블록도이다. 도 5을 참조하면, 이미지 신호 처리기는 DPHY, ISP 인터페이스(ISP I/F), 이미지 프론트-엔드 엔진(IFE), 및 이미지 처리 엔진을 포함할 수 있다. DPHY는 이미지 센서와 디스플레이 간 인터페이스를 위한 물리 계층으로서, MIPI(Mobile Industry Processor Interface) 연합에 의해 수립된 표준화된 인터페이스이다. DPHY는 출력 데이터(ODAT)를 이미지 신호 처리기 내로 전달할 수 있다. 출력 데이터(ODAT)는 듀얼 픽셀(도 1, 101)에 생성된 스테레오 출력 데 이터(SODAT)를 포함할 수 있다. 출력 데이터(ODAT)는 이미지 센서로부터 이미지 신호 처리기로 제공 될 수 있다. 이 경우, 이미지 신호 처리기는 카메라 서브 시스템으로 지칭될 수 있으며, 특히 MIPI 연합에 의해 정의된 카메라 직렬 인터페이스-2(Camenra Serial Interface-2; MIPI-CSI-2)를 따를 수 있다. ISP 인터페이스는 복수의 카메라 직렬 인터페이스(Camera Serial Interface; CSI) 디코더로부터의 데이터 스트림을 라우팅할 수 있다. ISP 인터페이스는 DPHY를 통해 제공된 로우 데이터(RDAT)를 이미지 프론 트-엔드 엔진으로 라우팅할 수 있다. 이미지 프론트-엔드 엔진은 로우 데이터(RDAT)를 수신하고, 프리-YUV 데이터(pYUV)를 출력할 수 있다. 예 시적 실시 예에 따르면, 이미지 프론트-엔드 엔진은 자동 노출(Auto Exposure(AE)) 노이즈, 자동 초점 (Auto Focus(AF)) 노이즈, 자동 화이트 밸런스(Auto White Balance(AWB)) 노이즈의 통계 수집 등의 이미지 처 리 동작을 수행할 수 있다. 이외에도, 이미지 프론트-엔드 엔진은 결함 픽셀 보정, 오프셋 보정, 렌즈 왜 곡 보정, 컬러 게인(color gain) 보정, 녹색 불균형 보정 등 다양한 이미지 처리 동작들을 수행할 수 있다. 이미지 처리 엔진은 중앙 처리 장치(CPU), 마이크로프로세서(Microprocessor), 또는 MCU(Micro Controller Unit)를 포함할 수 있다. 이미지 처리 엔진은 입력 데이터에 대한 이미지 후처리(image post- processing)를 수행할 수 있다. 후처리는 센싱된 이미지 데이터에 기초하여 에러와 왜곡을 줄이기 위한 일련의 후속적인 처리 작업을 의미할 수 있다. 이미지 처리 엔진이 수행하는 후처리는, 이미지 아티팩트들 (artifacts)에 대한 이미지 향상 알고리즘(Image Enhancement Algorithm)의 적용을 의미할 수 있다. 예시적인 실시 예에서, 이미지 처리 엔진에서 처리된 데이터는 이미지 데이터(IDAT)로서 메모리에 저 장될 수 있다. 예를 들어, 프리-YUV 데이터(pYUV)에 대하여 데이터 형식이 변경된 휘도 데이터(YDAT), 및 색차 데이터들(UDAT, VDAT)은 메모리에 저장될 수 있다. 이 외에도, 이미지 처리된 프레임(이하, 변환된 이미지 데이터) 및/또는 이미지 처리에 따라 생성되는 결과 데이터(통계 데이터, 히스토그램 등)는 메모리에 더 저장될 수 있다. 듀얼 픽셀에 의해 스테레오 출력 데이터(SODAT)가 생성된 경우, 이미지 처리 엔진은 스테레오 이미지 데이터(SIDAT)를 메모리에 저장할 수 있다.도 6a는 베이어 패턴을 가지는 출력 데이터가 YUV 형식으로 변환됨을 설명하는 도면이고, 도 6b 내지 도 6e는 YUV 형식을 따르는 이미지 데이터(IDAT)의 데이터 구조를 나타내는 도면이다. 도 6a를 참조하면, 컬러 픽셀(CP)은 레드(R), 그린(G), 및 블루(B) 채널들(RGB 3CH)을 포함할 수 있다. 예시적 인 실시예에서, 컬러 픽셀(CP)은 베이어(BAYER) 패턴을 가지는 컬러 필터를 통해 객체에 대한 센싱을 수행할 수 있다. 이미지 신호 처리기는 R, G, B 채널들(RGB 3CH)은 색 공간(color space) 변환을 통해, Y, U, V 채 널들(YUV 3CH)로 변환할 수 있다. 이때, 휘도 데이터(YDAT)는 휘도(Luminance) 신호를 나타내는 채널에 상응하 는 데이터이다. U데이터(UDAT)는 휘도 신호와 청색 성분의 차를 나타내는 채널이며 청색 색차(Cb) 채널로도 지 칭된다. V데이터(VDAT)는 휘도 신호와 적색 성분의 차를 나타내는 채널이며 적색 색차(Cr) 채널로도 지칭된다. 전자 장치는 변환된 Y, U, V 채널들(YUV 3CH) 중 Y 채널에 대한 데이터인 휘도 데이터(YDAT)를 인공 신경망 에 입력시킬 수 있다. 도 6b 내지 도 6e는 YUV 형식을 따르는 이미지 데이터(IDAT)의 데이터 구조를 나타내는 도면이다. YUV 형식의 이미지 데이터는 컬러 영상을 표시하기 위해 각 픽셀마다 휘도 성분(LUMA)과 색차 성분(CHROMA)을 구분하여 저 장할 수 있다. YUV 형식은 YCbCr 형식으로도 지칭된다. 도 6b 내지 도 6e 에서는 설명의 편의를 위해 YCbCr 형 식을 예시하여 데이터 구조를 설명한다. 도 6b을 참조하면, YCbCr의 샘플링 비율이 4:4:4인 데이터 구조가 도시된다. YCbCr 4:4:4는 Y에 대한 Cr 또는 Cb의 비율이 동일하게 4:4:4인 것을 의미할 수 있다. 데이터 구조를 수직한 방향으로 휘도 성분(LUMA)부터 읽으 면, 휘도 성분(LUMA)에 대해 한 행에 4개의 데이터 공간이 마련될 때, 색차 성분(CHROMA)은 청색 색차(Cb)에 대 해 4개의 데이터 공간이, 적색 색차(Cr)에 대해 4개의 데이터 공간이 마련된다. 도 6c를 참조하면, YCbCr의 샘플링 비율이 4:2:2인 데이터 구조가 도시된다. 데이터 구조를 수직한 방향으로 휘 도 성분(LUMA)부터 읽으면, 휘도 성분(LUMA)에 대해 한 행에 4개의 데이터 공간이 마련될 때, 색차 성분 (CHROMA)은 청색 색차(Cb)에 대해 2개의 데이터 공간이, 적색 색차(Cr)에 대해 2개의 데이터 공간이 마련된다. 즉, YCbCr 4:2:2는 Y에 대한 Cr 또는 Cb의 비율이 4:2:2인 것을 의미할 수 있다. 도 6d를 참조하면, YCbCr의 샘플링 비율이 4:1:1인 데이터 구조가 도시된다. 데이터 구조를 수직한 방향으로 휘 도 성분(LUMA)부터 읽으면, 휘도 성분(LUMA)에 대해 한 행에 4개의 데이터 공간이 마련될 때, 색차 성분 (CHROMA)은 청색 색차(Cb)에 대해 1개의 데이터 공간이, 적색 색차(Cr)에 대해 1개의 데이터 공간이 마련된다. 즉, YCbCr 4:1:1는 Y에 대한 Cr 또는 Cb의 비율이 4:1:1인 것을 의미할 수 있다. 도 6e를 참조하면, YCbCr의 샘플링 비율이 4:2:0인 데이터 구조가 도시된다. 데이터 구조를 수직한 방향으로 휘 도 성분(LUMA)부터 읽으면, 휘도 성분(LUMA)에 대해 한 행에 4개의 데이터 공간이 마련될 때, 색차 성분 (CHROMA)은 청색 색차(Cb)(또는 적색 색차(Cr))에 대해 1개의 데이터 공간만이 마련된다. 즉, YCbCr 4:2:0은 Y 에 대한 Cr(또는 Cb), Cb(또는 Cr)의 비율이 4:2:0인 것을 의미할 수 있다. 본 개시의 예시적 실시 예에 따르면, 이미지 신호 처리기(도 3, 300)은 이미지 데이터(IDAT)에 대해 YCbCr 4:2:0 의 형식에 따른 YUV 데이터를 생성할 수 있다. YCbCr 4:2:0은 휴대용 전자 장치의 데이터 처리, 저장, 및 /또는 표시에 효율적일 수 있다. 그러나, 이미지 데이터(IDAT)는 이에 제한되지 않고, 전술된 바와 같이 다양한 YCbCr 데이터 구조를 가질 수 있다. 도 7은 본 개시의 예시적인 실시 예에 따른 처리 회로를 도시하는 블록도이다. 도 1이 함께 참조되며, 도 1과 중복되는 설명되는 생략된다. 도 7을 참조하면, 처리 회로는 리사이저, 객체 검출기, 관심 영역 선택기, 심도 추정기 , 및 RGB 변환기를 포함하고, 심도 추정기는 디스패리티 특징 추출기, 및 디스패리티 네트 워크 모듈을 포함하며, 장면 네트워크 모듈을 선택적으로 더 포함할 수 있다. 리사이저는 이미지 데이터(IDAT)의 크기 또는 해상도를 조정할 수 있다. 예시적인 실시예에서, 리사이저 는 이미지 데이터(IDAT)의 크기를 축소시킬 수 있다. 예시적인 실시예에서, 리사이저는 이미지 데이 터(IDAT)의 해상도를 축소시킬 수 있다. 리사이저가 이미지 데이터(IDAT)의 크기 또는 해상도를 조정한 결 과, 객체 검출을 위해 필요한 데이터 처리량은 감축될 수 있다. 따라서, 데이터 처리 속도는 향상될 수 있으며, 데이터 처리에 필요한 전력은 절약될 수 있다. 객체 검출기는 대상 객체를 포함하는 장면을 전체적으로 센싱하고, 장면에 포함된 적어도 하나의 객체를 각각 검출할 수 있다. 객체 검출기는 컴퓨터 비전 분야의 객체 검출(Object Detection) 방식들을 이용할수 있다. 예를 들어 객체 검출기는 경계 박스(bounding box)를 이용해 장면에서 객체들을 구분할 수 있고, 각 객체에 대한 참값(groundtruth) 정보를 레이블의 형태로 개별적으로 분류시킨 핸드크래프트 기반 객체 검출, 또는 객체 검출을 위해 설계된 인공신경망을 이용한 AI 기반 객체 검출의 방식으로 객체를 검출할 수 있다. 객 체 검출기는 적어도 하나의 객체에서 관심 객체(OOI)를 탐지할 수 있다. 관심 영역 선택기는 관심 객체를 포함하는 관심 영역(ROI)을 결정할 수 있다. 예시적인 실시 예에 따르면, 관심 영역 선택기는 장면에서 탐지된 관심 객체에 상응하는 영역을 확인하고, 관심 객체를 포함하는 관심 영역을 선택할 수 있다. 예를 들어, 관심 영역은 관심 객체를 검출한 경계 박스보다 클 수 있다. 심도 추정기는 디스패리티 특징 추출기(Disparity Feature Extractor; DFE), 장면 네트워크(Scene Network; S.NET) 모듈, 디스패리티 네트워크(Disparity Network; D.NET) 모듈을 포함할 수 있다. 디스패리티 특징 추출기에는 한 쌍의 이미지 데이터가 입력될 수 있고, 그 결과로써 특징을 포함하는 하나 의 출력 데이터가 생성될 수 있다. 예시적인 실시 예에서, 디스패리티 특징 추출기는 인공 신경망을 이용 하여 입력 이미지로부터 테두리, 선, 색, 엣지(edge, 객체의 경계), 밀도(빽빽함(dense), 성김(Sparse)을 포함 한다), 심도(depth) 등과 같은 특징들(features)을 추출할 수 있다. 본 개시에서, 밀도가 빽빽한 이미지는 텍스 쳐드(textured) 이미지로, 밀도가 성긴 이미지는 언텍스쳐드(untextured) 이미지로 지칭될 것이다. 텍스쳐드 이 미지는 고-주파수에, 언텍스쳐드 이미지는 저-주파수에 각각 상응할 수 있다. 디스패리티 특징 추출기는 인공 신경망을 이용하여 이미지의 밀도에 대해 미리 학습할 수 있다. 예를 들어, 디스패리티 특징 추출기는 고밀도 이미지(즉, 텍스쳐드 이미지)를 인공 신경망을 이용하여 미리 학 습할 수 있고, 학습 결과에 따라 입력 데이터에 대한 엣지 검출 등의 성능이 향상될 수 있다. 예시적인 실시 예에 따르면, 디스패리티 특징 추출기는 디스패리티를 가지는 입력 데이터 쌍에 대하여 절 대 심도를 추정할 수 있다. 예를 들어, 디스패리티 특징 추출기는 입력 데이터 쌍의 특징을 추출한 결과로 서, 절대 심도 데이터를 생성할 수 있다. 본 개시의 예시적인 실시 예에 따르면, 디스패리티 특징 추출기에 휘도 데이터(YDAT)가 입력됨으로써, 휘 도 데이터(YDAT)에 대한 절대 심도가 추정될 수 있다. 디스패리티 네트워크 모듈에는 하나의 데이터가 입력될 수 있고, 그 결과로써 특징을 포함하는 하나의 출 력 데이터가 생성될 수 있다. 디스패리티 네트워크 모듈은 인공 신경망을 이용해 상대 심도 데이터 및 절 대 심도 데이터를 결합시킬 수 있다. 상대 심도 데이터 및 절대 심도 데이터를 결합함으로써 최종 심도 데이터 를 생성하는 인공 신경망인 디스패리티 네트워크(D.NET)는 적어도 하나의 ReLU(Rectified Linear Unit) 함수를 포함하는 활성 레이어 및 복수의 컨볼루션(Convolution) 레이어를 포함할 수 있다. 예를 들어, 디스패리티 네트 워크(D.NET)는 각 스테이지마다 하나의 컨볼루션 레이어 및 하나의 액티베이션 레이어를 가지는 5개의 스테이지 로 구성될 수 있다. 본 개시의 예시적인 실시 예에 따르면, 디스패리티 네트워크 모듈은 디스패리티 네트워크(D.NET)를 이용하 여 상대 심도 데이터 및 절대 심도 데이터를 결합(fusing)할 수 있다. 예를 들어, 디스패리티 네트워크 모듈 은 디스패리티 특징 추출기에서 출력된 절대 심도 데이터, 및 장면 네트워크 모듈에서 출력된 상대 심도 데이터를 각각 제공받을 수 있고, 디스패리티 네트워크(D.NET)의 처리 결과로서 최종 심도 데이터를 생성할 수 있다. 최종 심도 데이터는 후 처리 레이어(미도시)의 가공을 통해 심도 정보로 변환될 수 있다. 장면 네트워크 모듈에는 하나의 데이터가 입력될 수 있고, 그 결과로써 특징을 포함하는 하나의 출력 데이 터가 생성될 수 있다. 장면 네트워크 모듈은 장면(Scene)의 전체적인 특징을 학습하도록 구성된 인공 신경 망을 이용해 입력 이미지를 가공할 수 있다. 장면의 전체적인 특징을 학습하는 인공 신경망인 장면 네트워크 (S.NET)는 피라미드(pyramid) 구조로 구현될 수 있다. 예시적인 실시 예에 따르면, 장면 네트워크 모듈은 이미지 데이터에 상응하는 장면에 대해 순차적으로 해상도를 낮추어가면서 인코딩을 수행하고, 다시 원래의 해 상도로 돌아올 때까지 순차적으로 해상도를 높여가면서 디코딩을 수행할 수 있다. 예를 들어, 장면 네트워크 (S.NET)는 5개 내지는 6개의 인코딩 및 디코딩 스테이지를 가질 수 있다. 순차적으로 해상도를 낮추면서 인코딩 을 수행한 결과, 장면 네트워크(S.NET)는 장면을 표현하는 모든 해상도에 대해 특징을 학습할 수 있다. 예를 들 어, 장면 네트워크 모듈이 이용하는 인공 신경망 모델은 PyDNet일 수 있으나, 본 개시의 기술적 사상은 특 정한 모델, 또는 특정한 구현 예에 국한되지 않는다. 본 개시의 예시적인 실시 예에 따르면, 장면 네트워크 모듈은 장면 네트워크(S.NET)를 이용하여 입력 이미 지의 상대 심도를 추정할 수 있다. 예를 들어, 장면 네트워크 모듈은 디스패리티 특징 추출기에서 출력된 절대 심도 데이터를 제공받을 수 있고, 절대 심도 데이터에 대한 장면 네트워크(S.NET)의 처리 결과로서 상대 심도 데이터를 생성할 수 있다. 장면 네트워크 모듈은 저밀도 이미지(즉, 언텍스쳐드 이미지)에 대한 상대 심도를 추정함으로써, 상대적으로 작은 디스패리티를 이미지 데이터에 대하여도 비교적 정확한 심도를 획 득할 수 있다. 본 개시에서, 디스패리티 특징 추출기, 장면 네트워크 모듈, 및 디스패리티 네트워크 모듈은 하 드웨어, 펌웨어, 및/또는 소프트웨어의 조합으로 구현될 수 있다. 예를 들어, 디스패리티 특징 추출기, 장 면 네트워크 모듈, 및 디스패리티 네트워크 모듈은 로직 회로를 포함하는 하드웨어와 같은 처리 회로 로서 각각 구현될 수도 있고, 인공 신경망의 처리 동작을 수행하는 소프트웨어를 실행하는 프로세서와 같이 하 드웨어와 소프트웨어의 조합으로 구현 될 수도 있다. 본 개시의 예시적인 실시 예에 따르면, 휘도 데이터(YDAT)는 RGB 형식의 이미지 데이터에 비해 인공 신경망의 처리를 거친 후에도 저조도 환경에 강건할 수 있다. 본 개시의 예시적인 실시 예에 따라, 처리 회로는 입 력으로서 휘도 데이터(YDAT)를 이용할 수 있고, 처리 회로에서 이용되는 적어도 하나의 인공 신경망의 처 리 결과인 심도 추정 결과는 RGB 형식의 이미지 데이터를 이용할 때 보다 향상될 수 있다. 객체 검출기, 관심 영역 선택기, 및 심도 추정기 각각은 로직 회로를 포함하는 하드웨어와 같은 처리 회로로서 구현될 수 있거나, 객체 검출, 관심 영역 선택, 심도 추정 등을 수행하는 소프트웨어를 실행하는 프로세서와 같이 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 특히, 객체 검출기, 관심 영역 선택 기, 및 심도 추정기 각각은 중앙 처리 장치(Central Procesing Unit; CPU), 산술 및 논리 연산, 비 트 쉬프트 등을 수행하는 ALU(Arithmetic Logic Unit), DSP(Digital Signal Processor), 마이크로프로세서 (microprocessor), 인공신경망을 구동하는 뉴럴-네트워크 처리 유닛(NPU), ASIC(Application Specific Integrated Circuit) 등으로 구현될 수 있으나, 이에 제한되지 않는다. RGB 변환기는 YUV 형식을 따르는 이미지 데이터(IDAT)를 RGB 형식으로 변환할 수 있다. 디스플레이 장치에 표시되기 위해 요구되는 YUV 형식과 달리, RGB 형식은 사용자에게 시각적으로 제공되기 위해 요구될 수 있다. 예시적인 실시예에서, RGB 변환기를 통해 이미지 데이터(IDAT)가 사용자가 접근 가능한 시각 정보로 변환 될 수 있고, 시각 정보는 심도 정보를 더 포함함으로써 객체에 대한 보다 다양한 정보를 제공할 수 있다. 도 8은 본 개시의 예시적인 실시 예에 따른 처리 회로를 도시하는 블록도이다. 도 8을 참조하면, 처리 회로는 메모리에 저장된 이미지 데이터(IDAT)에 기초하여 크롭 신호(CROP)를 생성하고, 크롭 신호(CROP)를 이미지 센서에 제공할 수 있다. 보다 구체적으로, 리사이저는 이미지 데이터(IDAT)의 크기 또는 해상도를 축소시킨 결과로서 크기 조정 이미지 데이터(rIDAT)를 생성할 수 있다. 객체 검출기는 크기 조정 이미지 데이터(rIDAT)에서 적어도 하나의 객체를 각각 검출할 수 있으며, 예를 들어 핸드크래프트 기반 객체 검출, 또는 AI 기반 객체 검출의 방식으로 객체를 검출한 결과로서 관심 객체 (OOI)를 탐지하고, 관심 객체에 대한 객체 정보(iOBJ)를 생성할 수 있다. 관심 영역 선택기는 객체 정보(iOBJ)에 기초해 관심 객체를 포함하는 관심 영역(ROI)을 결정할 수 있다. 예시적인 실시 예에 따르면, 관심 영역 선택기는 장면에서 탐지된 관심 객체를 포함하는 관심 영역을 선택 하고, 관심 영역에 상응하는 크롭 신호(CROP)를 생성할 수 있다. 본 개시의 예시적인 실시예에 따르면, 듀얼 픽셀을 포함하는 전자 장치는 상대적으로 적은 베이스라인 거리를 가짐에도 불구하고, 크롭 신호(CROP)에 기초하여 상대적으로 작은 크기의 고해상도를 유지한 채로 객체 를 촬상할 수 있다. 따라서, 작은 디스패리티를 가지는 이미지 데이터에 대한 심도 추정에 수반되는 고해상도의 요구를 충족할 수 있다. 도 9a 및 도 9b는 본 개시의 예시적인 실시 예에 따른 처리 회로를 도시하는 블록도이다. 도 9a를 참조하면, 처리 회로(303a)는 크롭 이미지 데이터(cIDAT)를 처리함으로써 심도 정보(iDEPTHa)를 생성할 수 있고, 처리 결과에 따라 전자 장치의 동작 모드를 변경하는 모드 신호(MODE)를 더 생성할 수 있다. 예시 적인 실시 예에 따르면, 크롭 이미지 데이터(cIDAT)는 크롭 신호(도 2, CROP)에 응답한 이미지 센서(도 1, 10 0)에 의해 직접 생성되거나, 출력 데이터(도 2, ODAT)를 가공하고 처리하며 보정하는 이미지 신호 처리기(도 1, 200)에서 직접 제공되거나, 또는 메모리로부터 로딩될 수 있다. 처리 회로(303a)는 디스패리티 특징 추출 기, 디스패리티 네트워크 모듈, 및 후 처리 레이어를 포함할 수 있다. 디스패리티 특징 추출기에 크롭 이미지 데이터(cIDAT)가 입력됨으로써 절대 심도 데이터(ADa)가 생성될 수 있다. 디스패리티 네트워크 모듈(350a)이 지원하는 디스패리티 네트워크(D.NET)는 적어도 하나의 ReLU(Rectified Linear Unit) 함수를 포함하는 활성 레이어 및 복수의 컨볼루션(Convolution) 레이어를 포함할 수 있으며, 절대 심도 데이터(ADa)를 처리함으로써 최종 심도 데이터(FDa)를 생성할 수 있다. 후 처리 레이어 (370a)는 최종 심도 데이터(FDa)를 심도 정보(iDEPTHa)로 가공할 수 있다. 본 개시의 예시적 실시 예에 따르면, 처리 회로(303a)는 크롭 이미지 데이터(cIDAT) 중 휘도 데이터(YDATa)만을 이용함으로써 RGB 형식을 따르는 이미지 데이터에 비해 저조도 환경에 보다 강건한 심도 정보를 생성할 수 있다. 또한, 본 개시의 예시적 실시 예에 따르면, 처리 회로(303a)는 YUV 데이터(예를 들어, 휘도 데이터(YDAT), 및 색차 데이터(도 6a, UDAT, VDAT) 중 휘도 데이터(YDATa)만을 인공 신경망에 학습시킴으로써 메모리 사용량 및 전력 소비량을 감축시킬 수 있다. 도 9b을 참조하면, 처리 회로(303b)는 크롭 이미지 데이터(cIDAT)를 처리함으로써 심도 정보(iDEPTHb)를 생성할 수 있다. 예시적인 실시 예에 따르면, 처리 회로(303b)는 디스패리티 특징 추출기, 장면 네트워크 모듈 , 디스패리티 네트워크 모듈, 및 후 처리 레이어를 포함할 수 있다. 디스패리티 특징 추출기에 크롭 이미지 데이터(cIDAT)가 입력됨으로써 크롭 이미지 데이터(cIDAT)에 대한 절대 심도가 추정된 결과, 절대 심도 데이터(ADb)가 생성될 수 있다. 장면 네트워크 모듈은 장면 네트워크 (S.NET)를 이용하여 절대 심도 데이터(ADb)의 상대 심도를 추정할 수 있다. 절대 심도 데이터(ADb)에 대한 상대 심도 추정 결과는 상대 심도 데이터(CDb)로 출력될 수 있다. 디스패리티 네트워크 모듈이 지원하는 디스패 리티 네트워크(D.NET)는 절대 심도 데이터(ADb) 및 상대 심도 데이터(CDb)를 결합함으로써 최종 심도 데이터 (FDb)를 생성할 수 있다. 후 처리 레이어는 최종 심도 데이터(FDb)를 심도 정보(iDEPTHb)로 가공할 수 있 다. 본 개시의 예시적 실시 예에 따른 처리 회로(303b)는 장면 네트워크(S.NET)를 추가적으로 이용함으로써 심도 추 정의 정확도를 향상시킬 수 있다. 또한, 본 개시의 예시적 실시 예에 따른 처리 회로(303b)는 디스패리티가 작 은 데이터(예를 들어, 듀얼 픽셀(도 1, 101)로부터 생성된 스테레오 이미지 데이터(도 1, SIDAT))에 대하여도 장면 전체가 아닌 관심 영역에 상응하는 크롭 이미지 데이터(cIDAT)를 처리할 수 있다. 따라서, 본 개시의 예시 적 실시 예에 따른 전자 장치는 심도 추정에 필요한 데이터 처리량을 감축시킴에 따라 전력 소모를 절감시 킬 수 있고, 데이터 처리 속도를 향상시킬 수 있다. 도 9a 내지 도 9b에 도시되지는 않았으나, 본 개시의 예시적 실시 예에 따른 처리 회로는 인공 신경망 중 어느 일부를 다른 처리 회로에서 처리시킴으로써 데이터 분산 처리를 도모하고, 데이터 크기가 크거나 데이터 처리 시간이 오래 소요되는 작업에 대한 분산 및/또는 병렬 처리를 성취할 수 있다. 도 10a 내지 도 10c는 인공 신경망(NN1, NN2, NN3)의 구조 및 동작을 설명하는 도면이다. 도 10a을 참조하면, 인공 신경망(NN1)은 컨볼루션 뉴럴 네트워크(Convolution Neural Network: CNN)일 수 있으 나, 이에 제한되지는 않는다. 도 10a에서, 설명의 편의를 위해 인공 신경망(NN1)이 2개의 히든 레이어들(hidden layers)을 포함하는 것으로 도시되어 있으나 인공 신경망(NN1)은 그에 한정되지 않고 다양한 개수의 히든 레이 어들을 포함할 수 있다. 또한, 도 10a에서, 인공 신경망(NN1)은 입력 데이터를 수신하기 위한 별도의 입력 레이 어(input layer)를 포함하는 것으로 도시되고 있으나, 실시 예에 따라 입력 데이터는 히든 레이어에 직접 입력 될 수도 있다. 인공 신경망(NN1)에서 출력 레이어(output layer)를 제외한 레이어들의 노드들은 출력 신호를 전송하기 위한 링 크들을 통해 다음 레이어의 노드들과 연결될 수 있다. 이들 링크를 통해 하나의 노드에는 이전 레이어에 포함된 노드들의 노드 값과 각 링크에 할당된 웨이트가 곱해진 값들이 입력될 수 있다. 이전 레이어의 노드 값들은 액 손 값들에 해당하고, 웨이트는 시냅틱 웨이트에 해당할 수 있다. 웨이트는 인공 신경망(NN1)의 파라미터로 지칭 될 수 있다. 활성 함수는 특징 맵들의 값들을, 특징의 존재 여부에 대한 비선형적 정보로 변환하기 위해 적용될 수 있다. 예 를 들어, 활성 함수는 시그모이드(Sigmoid) 함수, 하이퍼볼릭 탄젠트(tanh: Hyperbolic Tangent) 함수, 렐루 (ReLU) 함수 등을 포함할 수 있고, 활성 함수에 의해 인공 신경망(NN1)에 비선형성이 구현될 수 있다. 인공 신경망(NN1)에 포함된 임의의 한 노드의 출력은 이하의 [수학식 4]와 같이 나타낼 수 있다. [수학식 4]"}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[수학식 4]는 임의의 레이어에서 m개의 입력 값에 대한 i번째 노드의 출력 값 yi를 나타낼 수 있다. xj는 이전 레이어의 j번째 노드의 출력 값을 나타낼 수 있고, wj,i는 이전 레이어의 j번째 노드와 현재 레이어의 i번째 노 드의 연결부에 적용되는 웨이트를 나타낼 수 있다. f()는 활성 함수를 나타낼 수 있다. [수학식 4]에 나타난 바 와 같이, 활성 함수에는, 입력 값 xj과 웨이트 wj,i의 곱셈의 누적 결과가 사용될 수 있다. 다시 말해, 각 노드 에서 입력 값 xj과 웨이트 wj,i를 곱하고 그 결과들을 합하는 연산, 즉 MAC(Multiply Accumulate) 연산 (operation)이 수행될 수 있다. 이러한 용도 외에도, MAC 연산을 필요로 하는 다양한 응용 분야가 있을 수 있고, 이를 위해 아날로그 회로 영역에서 MAC 연산을 처리할 수 있는 프로세싱 장치가 사용될 수 있다. 도 10b를 참조하면, 뉴럴 네트워크(NN2)는 복수의 레이어들(L1 내지 Ln)을 포함할 수 있다. 복수의 레이어들(L1 내지 Ln) 각각은 선형 레이어 또는 비선형 레이어일 수 있으며, 일 실시 예에 있어서, 적어도 하나의 선형 레이 어 및 적어도 하나의 비선형 레이어가 결합되어 하나의 레이어로 지칭될 수도 있다. 예시적으로, 선형 레이어는 컨볼루션 레이어(convolution layer) 및 풀리 커넥티드 레이어(fully connected layer)를 포함할 수 있으며, 비선형 레이어는 풀링(pooling layer) 및 활성 레이어(activation layer)를 포함할 수 있다. 예시적으로, 제1 레이어(L1)는 컨볼루션 레이어이고, 제2 레이어(L2)는 풀링 레이어이고, 제n 레이어(Ln)는 출 력 레이어로서 풀리 커넥티드 레이어일 수 있다. 뉴럴 네트워크(NN)는 활성 레이어를 더 포함할 수 있으며, 다 른 종류의 연산을 수행하는 레이어를 더 포함할 수 있다. 복수의 레이어들(L1 내지 Ln) 각각은 입력되는 데이터(예컨대, 이미지 프레임) 또는 이전 레이어에서 생성된 피 처맵을 입력 피처맵으로서 수신하고, 입력 피처맵을 연산함으로써 출력 피처맵 또는 인식 신호(REC)를 생성할 수 있다. 이 때, 피처맵은 입력 데이터의 다양한 특징이 표현된 데이터를 의미한다. 피처맵들(FM1, FM2, FMn)은 예컨대 2차원 매트릭스 또는 3차원 매트릭스(또는 텐서(tensor)) 형태를 가질 수 있다. 피처맵들(FM1, FM2, FMn)은 너비(W)(또는 칼럼), 높이(H)(또는 로우) 및 깊이(D)를 가지며, 이는 좌표상의 x축, y축 및 z축에 각각 대응될 수 있다. 이 때, 깊이(D)는 채널 수로 지칭될 수 있다. 제1 레이어(L1)는 제1 피처맵(FM1)을 웨이트 맵(WM)과 컨볼루션함으로써 제2 피처맵(FM2)을 생성할 수 있다. 웨 이트 맵(WM)은 제1 피처맵(FM1)을 필터링할 수 있으며, 필터 또는 커널로도 지칭될 수 있다. 웨이트 맵(WM)의 깊이, 즉 채널 개수는 제1 피처맵(FM1)의 깊이, 즉 채널 개수와 동일하며, 웨이트 맵(WM)과 제1 피처맵(FM1)의 동일한 채널끼리 컨볼루션 될 수 있다. 웨이트 맵(WM)이 제1 피처맵(FM1)을 슬라이딩 윈도우로 하여 횡단하는 방식으로 시프트 될 수 있다. 시프트되는 양은 \"스트라이드(stride) 길이\" 또는 \"스트라이드\"로 지칭될 수 있다. 각 시프트 동안, 웨이트 맵(WM)에 포함되는 웨이트 값들 각각이 제1 피처맵(FM1)과 중첩되는 영역에서의 모든 셀 데이터들과 곱해지고 더해질 수 있다. 웨이트 맵(WM)에 포함되는 웨이트 값들 각각이 제1 피처맵(FM1) 과 중첩되는 영역에서의 제1 피처맵(FM1)의 데이터들을 추출 데이터라 칭할 수 있다. 제1 피처맵(FM1)과 웨이트 맵(WM)이 컨볼루션 됨에 따라, 제2 피처맵(FM2)의 하나의 채널이 생성될 수 있다. 도 3에는 하나의 웨이트 맵 (WM)이 표시되었으나, 실질적으로는 복수의 웨이트 맵들이 제1 피처맵(FM1)과 컨볼루션 되어, 제2 피처맵(FM2) 의 복수의 채널들이 생성될 수 있다. 다시 말해, 제2 피처맵(FM2)의 채널의 수는 웨이트 맵의 개수에 대응될 수 있다. 제2 레이어(L2)는 풀링을 통해 제2 피처맵(FM2)의 공간적 크기(spatial size)를 변경함으로써, 제3 피처맵(FM 3)을 생성할 수 있다. 풀링은 샘플링 또는 다운-샘플링으로 지칭될 수 있다. 2차원의 풀링 윈도우(PW)가 풀링 윈도우(PW)의 사이즈 단위로 제2 피처맵(FM2) 상에서 시프트 되고, 풀링 윈도우(PW)와 중첩되는 영역의 셀 데이 터들 중 최대값(또는 셀 데이터들의 평균값)이 선택될 수 있다. 이에 따라, 제2 피처맵(FM2)으로부터 공간적 사 이즈가 변경된 제3 피처맵(FM3)이 생성될 수 있다. 제3 피처맵(FM3)의 채널과 제2 피처맵(FM2)의 채널 개수는 동일하다. 제n 레이어(Ln)는 제n 피처맵(FMn)의 피처들을 조합함으로써 입력 데이터의 클래스(class)(CL)를 분류할 수 있 다. 또한, 제n 레이어(Ln)는 클래스에 대응되는 인식 신호(REC)를 생성할 수 있다. 실시 예에 있어서, 입력 데 이터는 비디오 스트림(video stream)에 포함되는 프레임 데이터에 대응될 수 있으며, 제n 레이어(Ln)는 이전 레이어로부터 제공되는 제n 피처맵(FMn)을 기초로 프레임 데이터가 나타내는 이미지에 포함되는 사물에 해당하는 클래스를 추출함으로써, 사물을 인식하고, 인식된 사물에 상응하는 인식 신호(REC)를 생성할 수 있다. 도 10c를 참조하면, 입력 피처맵들은 D개의 채널들을 포함하고, 각 채널의 입력 피처맵은 H행 W열의 크기를 가 질 수 있다(D, H, W는 자연수). 커널들 각각은 R행 S열의 크기를 갖고, 커널들은 입력 피처맵들의 채널 수 (또는 깊이)(D) 에 대응되는 개수의 채널들을 포함할 수 있다(R, S는 자연수). 출력 피처맵들은 입력 피처맵들 과 커널들 간의 3차원 컨볼루션 연산을 통해 생성될 수 있고, 컨볼루션 연산에 따라 Y개의 채널들을 포함할 수 있다. 도 11a 내지 도 11d는 본 개시의 예시적인 실시 예에 따른 네트워크의 구조를 나타내는 블록도이다. 도 11a 내 지 도 11d 중 서로 중복되는 설명은 생략될 것이다. 도 11a는 본 개시의 예시적인 실시 예에 따른 디스패리티 특징 추출기의 구조를 나타내는 블록도이다. 도 11a를 참조하면, 디스패리티 특징 추출기는 복수의 스테이지를 포함하며, 하나의 스테이지는 한 쌍의 컨볼 루션 레이어(CONV) 및 활성 레이어(ACTV)로 구성될 수 있다. 활성 레이어(ACTV)는 특징(feature)의 존재 여부를 비선형적 정보로 변환하기 위해 시그모이드(Sigmoid) 함수, 하이퍼볼릭 탄젠트(tanh) 함수, 렐루(ReLU) 함수가 적용되는 비선형적 층위이다. 본 개시의 예시적 실시 예에 따르면, 디스패리티 특징 추출기는 메모리로부터 휘도 데이터(YDAT)를 수신하고, 휘도 데이터(YDAT)를 제1 스테이지의 컨볼루션 레이어(CONV)에 입력시킴으로써 데이터를 가공 및 처 리할 수 있다. 디스패리티 특징 추출기는 결과로서 절대 심도 데이터(AD)를 생성할 수 있다. 절대 심도 데 이터(AD)는 장면 네트워크 모듈, 또는 디스패리티 네트워크 모듈로 제공될 수 있다. 도 11b는 본 개시의 예시적인 실시 예에 따른 디스패리티 네트워크 모듈의 구조를 나타내는 블록도이다. 도 11b를 참조하면, 디스패리티 네트워크 모듈은 복수의 스테이지를 포함하며, 하나의 스테이지는 한 쌍의 컨볼루션 레이어(CONV) 및 활성 레이어(ACTV)로 구성될 수 있다. 본 개시의 예시적 실시 예에 따르면, 디스패리티 네트워크 모듈은 디스패리티 특징 추출기로부터 절 대 심도 데이터(AD)를 수신하거나, 및/또는, 장면 네트워크 모듈로부터 상대 심도 데이터(CD)를 수신할 수 있다. 절대 심도 데이터(AD), 또는 절대 심도 데이터(AD)와 결합된 상대 심도 데이터(CD)는 제1 스테이지의 컨볼루션 레이어(CONV)에 입력될 수 있다. 디스패리티 네트워크 모듈은 결과로서 최종 심도 데이터(FD)를 생성할 수 있다. 최종 심도 데이터(FD)는 후 처리 레이어로 전송될 수 있다. 도 11c를 참조하면, 본 개시의 예시적인 실시 예에 따른 장면 네트워크 모듈의 구조를 나타내는 블록도이 다. 도 11c를 참조하면, 장면 네트워크 모듈에 이용되는 장면 네트워크(S.NET)는 입력 레이어(IL), 출력 레이어(OL), 인코딩 레이어 유닛(LUa) 및 디코딩 레이어 유닛(LUb)을 포함할 수 있다. 장면 네트워크(S.NET)는 절대 심도 데이터(AD)를 수신하고, 입력 레이어(IL), 인코딩 레이어 유닛(LUa), 디코딩 레이어 유닛(LUb) 및 출 력 레이어(OL)에 의해 절대 심도 데이터(AD)의 특징 값을 연산할 수 있다. 장면 네트워크(S.NET)는 복수의 인코더(인코딩 레이어 유닛)들 및 복수의 디코더(디코딩 레이어 유닛)들을 포함 할 수 있고, 상기 복수의 인코더들 및 상기 복수의 디코더들은 서로 대칭적인 피라미드 구조로 구현될 수 있다. 예를 들어, 복수의 인코더들은 점진적으로 인코딩 데이터의 해상도를 낮추도록 직렬 연결될 수 있고, 복수의 디 코더들은 점진적으로 디코딩 데이터의 해상도를 높이도록 직렬 연결될 수 있다. 인코딩 레이어 유닛(LUa)은 이전의 인코딩 레이어 유닛에서 출력된 특징맵을 수신하고, 각각의 인코딩 레이어 유닛(예컨대, LUa1)에 할당된 연산을 수행할 수 있다. 예를 들어, 제1 인코딩 레이어 유닛(LUa1)은 특징맵 (FMa0)을 수신하고, 제1 인코딩 레이어 유닛(LUa1)에 포함된 다양한 레이어들에 의한 연산을 수행할 수 있다. 예를 들어, 인코딩 레이어 유닛(LUa)은 컨볼루션 레이어, 샘플링 레이어 및 활성 레이어를 포함할 수 있다. 컨 볼루션 레이어는 컨볼루션 연산을 수행할 수 있다. 샘플링 레이어는 다운-샘플링, 업-샘플링, 평균 풀링 또는 최대 풀링 연산을 수행할 수 있다. 활성 레이어는 ReLU(Rectified Linear Unit) 함수 또는 시그모이드 (sigmoid) 함수에 의한 연산을 수행할 수 있다. 제1 인코딩 레이어 유닛(LUa1)은 연산 결과에 기초하여 특징맵 (FMa1)을 출력할 수 있다. 제1 인코딩 레이어 유닛(LUa1)에서 출력된 특징맵(FMa1)은, 입력된 특징맵(FMa0) 보다 너비 및 높이가 작을 수 있으며, 깊이가 클 수 있다. 즉, 제1 인코딩 레이어(LUa1)는 특징맵(FMa1)의 너비, 높이 및 깊이를 제어할 수있으며, 예컨대, 깊이가 과도하게 커지지 않도록 제어할 수 있다. 제1 인코딩 레이어(LUa1)는 특징맵(FMa1)의 깊이를 설정하는 파라미터를 가질 수 있다. 한편, 제1 인코딩 레이어 유닛(LUa1)은 다운 샘플링 레이어(DS)를 포함할 수 있다. 다운 샘플링 레이어(DS)는 입력된 특징맵(FMa0)에 포함된 특징 값들 중 소정의 특징 값들을 선 택하고, 특징맵(FMa1)의 특징 값으로 출력할 수 있다. 다시 말해, 다운 샘플링 레이어(DS)는 특징맵(FMa1)의 너 비 및 높이를 제어할 수 있다. 제2 인코딩 레이어 유닛(LUa2) 및 제3 인코딩 레이어 유닛(LUa3)도 제1 인코딩 레이어 유닛(LUa1)과 유사하게 연산을 처리할 수 있다. 즉, 이전의 인코딩 레이어 유닛으로부터 특징맵을 수신 하고, 현재의 레이어 유닛에 포함된 복수의 레이어들에 의해 연산을 처리하며, 다음의 인코딩 레이어 유닛으로 연산 결과를 포함하는 특징맵을 출력할 수 있다. 인코딩 레이어 유닛(LUa)은 다음의 인코딩 레이어 유닛(LUa) 또는 동일한 레벨의 디코딩 레이어 유닛(LUb)에 출 력할 수 있다. 각각의 인코딩 레이어 유닛(LUa1)은 다음의 인코딩 레이어 유닛(LUa)과 고정적으로 연결되어 있 을 수 있으며, 동일한 레벨의 디코딩 레이어 유닛(LUb)과 스킵 커넥션들(SK0~SK3)에 의해 연결되어 있을 수 있 다. 동일한 레벨은, 예컨대 입력 레이어(IL)로부터의 순서와 출력 레이어(OL)로부터의 순서가 각각 동일한 경우 를 의미할 수 있으며, 동일한 레벨의 레이어 유닛들은, 예컨대 제1 인코딩 레이어 유닛(LUa1) 및 제1 디코딩 레 이어 유닛(LUb1)일 수 있다. 예시적 실시 예에 따르면, 처리 회로 또는 전자 장치에 의해 복수의 스킵 커넥션들(SK0~SK3) 중 적어 도 일부가 선택될 수 있다. 예컨대, 처리 회로는 스킵 레벨에 관한 정보를 수신할 수 있다. 인공 신경망 모델의 스킵 레벨이 설정된 경우, 기설정된 스킵 레벨에 해당하는 스킵 커넥션들(SK0~SK3)은 활성화될 수 있다. 예컨대, 인공 신경망 모델의 스킵 레벨이 2 인 경우, 제1 스킵 커넥션(SK0) 및 제2 스킵 커넥션(SK1)이 활성될 수 있다. 활성된 스킵 커넥션에 의해 인코딩 레이어 유닛(LUa)은 디코딩 레이어 유닛(LUb)으로 특징맵을 출력할 수 있다. 비활성된 스킵 커넥션(예컨대, SK2, SK3)은 특징맵을 전파할 수 없다. 예시적 실시 예에 따르면, 동일한 레벨의 레이어 유닛(예컨대, LUa1, LUb1)은 실질적으로 동일한 사이즈의 특징 맵을 처리할 수 있다. 예컨대, 제1 인코딩 레이어 유닛(LUa1)이 수신하는 특징맵(FMa0)과 제1 디코딩 레이어 유 닛(LUb1)이 출력하는 특징맵(FMb0)의 사이즈는 실질적으로 동일할 수 있다. 예컨대, 특징맵의 사이즈는, 너비, 높이 및 깊이 중 적어도 하나를 포함할 수 있다. 또한, 제1 인코딩 레이어 유닛(LUa1)이 출력하는 특징맵(FMa 1)과 제1 디코딩 레이어 유닛(LUb1)이 수신하는 특징맵(FMb1)의 사이즈는 실질적으로 동일할 수 있다. 예시적 실시 예에 따르면, 동일한 레벨의 인코딩 레이어 유닛(LUa)과 디코딩 레이어 유닛(LUb)은, 실질적으로 동일한 샘플링 사이즈를 가질 수 있다. 예컨대, 제1 인코딩 레이어 유닛(LUa)이 다운 샘플링 사이즈는 제1 디코 딩 레이어 유닛(LUb)이 업 샘플링 사이즈와 실질적으로 동일할 수 있다. 디코딩 레이어 유닛(LUb)은 이전의 디코딩 레이어 유닛(LUb)으로부터 특징맵을 수신하거나, 동일한 레벨의 인코 딩 레이어 유닛(LUa)으로부터 특징맵을 수신할 수 있다. 디코딩 레이어 유닛(LUb)은 수신한 특징맵을 이용하여 연산을 처리할 수 있다. 예를 들어, 디코딩 레이어 유닛(LUb)은 컨볼루션 레이어, 샘플링 레이어 및 활성 레이 어를 포함할 수 있다. 제1 인코딩 레이어 유닛(LUa1)에서 출력된 특징맵(FMa1)은, 입력된 특징맵(FMa0) 보다 너비 및 높이가 작을 수 있으며, 깊이가 클 수 있다. 즉, 제1 인코딩 레이어(LUa1)는 특징맵(FMa1)의 너비, 높이 및 깊이를 제어할 수 있으며, 예컨대, 깊이가 과도하게 커지지 않도록 제어할 수 있다. 제1 인코딩 레이어(LUa1)는 특징맵(FMa1)의 깊이를 설정하는 파라미터를 가질 수 있다. 업 샘플링 레이어(US)는 입력된 특징맵의 사이즈를 조절할 수 있다. 예컨대, 업 샘플링 레이어(US)는 특징맵의 너비와 높이를 조절할 수 있다. 업 샘플링 레이어(US)는 입력된 특징맵의 각 특징값들과, 상기 각 특징값들에 인접한 특징값들을 이용하여 업 샘플링 동작을 수행할 수 있다. 일 예로, 업 샘플링 레이어(US)는 니어리스트 네이버(Nearest Neighbor) 방식을 이용하여 동일한 특징 값들을 출력 특징맵에 기입하는 레이어 일 수 있다. 다 른 예로, 업 샘플링 레이어(US)는 트랜스포즈(transpose) 컨볼루션 레이어일 수 있으며, 소정의 웨이트맵을 이 용하여 이미지를 업샘플링할 수 있다. 업샘플링됨으로써 종전의 해상도로 돌아온 데이터는 컨볼루션 레이어(CONV), 배치 정규화 레이어(BN), 및 활성 레이어(ACTV)를 통해 상대 심도 데이터(CD)로 변환될 수 있다. 도 11d는 본 개시의 예시적인 실시 예에 따른 후 처리 레이어의 구조를 나타내는 블록도이다. 예시적인 실시 예에 따르면, 후 처리 레이어는 컨볼루션 레이어(CONV), 배치 정규화 레이어(BN), 및 활성 레이어(ACTV)를 포함할 수 있다. 후 처리 레이어는 최종 심도 데이터(FD)를 심도 정보(iDEPTH)로 변환할수 있다. 도 12는 본 개시의 예시적인 실시 예에 따른 처리 회로를 도시하는 블록도이다. 도 12를 참조하면, 처리 회로는 이미지 센서, 또는 이미지 신호 처리기에서 생성되거나, 또는 메모리에서 로딩된 이미지 데이터(IDAT)에 기초해 색상 및 심도 정보(iRGBD)를 생성할 수 있다. 처리 회로 는 색상 및 심도 생성기를 더 포함할 수 있다. 예시적인 실시예에서, 심도 추정기는 이미지 데이터(IDAT)에 대해 심도를 추정함으로써 심도 정보(iDEPT H)를 생성할 수 있다. 예시적인 실시예에서, 심도 추정기는 이미지 데이터(IDAT)에 포함된 휘도 데이터 (YDAT) 대해 심도를 추정함으로써 심도 정보(iDEPTH)를 생성할 수 있다. 심도 추정기가 휘도 데이터(YDA T)에 대해 심도를 추정함으로써 심도 추정에 요구되는 데이터의 처리량, 및 데이터 처리에 수반되는 전력 소모 는 저감될 수 있고, 데이터 처리 속도는 향상될 수 있다. 심도 정보(iDEPTH)는 색상 및 심도 생성기에 제 공될 수 있다. 예시적인 실시예에서, RGB 변환기는 YUV 형식을 따르는 데이터를 포함하는 이미지 데이터(IDAT)에 대해 RGB 변환을 수행할 수 있다. RGB 변환기는 RGB 변환 결과로서 색상 정보(iRGB)를 생성할 수 있다. 색상 정 보(iRGB)는 색상 및 심도 생성기에 제공될 수 있다. RGB 변환에 관하여는 도 13을 참조하여 보다 상세히 설명될 것이다. 색상 및 심도 생성기는 심도 정보(iDEPTH) 및 색상 정보(iRGB)를 결합할 수 있고, 색상 및 심도 정보 (iRGBD)를 생성할 수 있다. 도 13은 이미지 데이터의 RGB 형식과 YUV 형식의 변환 관계를 나타내는 도면이다. 도 13은 도 7와 함께 참조되 며, RGB 변환기(도 7, 390)에서 수행되는 동작의 결과를 설명한다. 도 13을 참조하면, RPG 색 공간과 YUV 색 공간의 변환 관계가 설명된다. 예시적인 실시 예에 따르면, RGB 변환 기는 RPG 색 공간과 YUV 색 공간의 변환을 수행할 수 있다. 예시적인 실시 예에 따르면, RGB 변환기 는 YUV 색 공간의 데이터를, RGB 색 공간의 데이터로 변환할 수 있다. 그러나, 이에 제한되지 않고 RGB 변환기 는 RGB 색 공간의 데이터를, YUV 색 공간의 데이터로 변환할 수도 있다. 예시적인 실시 예에서, RGB 변환 기는 색채 정보(iRGB)를 생성할 수 있다. 본 개시에서는 설명의 편의를 위해, YUV 색 공간의 데이터가 RGB 색 공간의 데이터로 변홤됨을 예시하나, RGB 색 공간에서 YUV 색 공간으로의 변환은 YUV 색 공간에서 RGB 색 공 간의 변환의 역 연산으로부터 쉽게 산출될 수 있음이 이해될 것이다. RGB 색 공간으로서, 적색(레드, R), 청색(블루, B), 및 녹색(그린, G)이 차원을 구성하고, 그 원점은 흑색(Bk) 이다. 데이터가 8비트로 표현되는 경우, 적색은 (255, 0, 0)을, 청색은 (0, 0, 255)를, 녹색은 (0, 255, 0)을 각각 나타낼 수 있다. 이 경우, 옐로우는 (255, 255, 0)으로, 마젠타는 (255, 0, 255)로, 싸이언은 (0, 255, 255)로, 및 백색은 (255, 255, 255)로 표현될 수 있다. RGB 색 공간은 다음과 같은 식을 통해 YUV 색 공간으로 변환될 수 있다. [수학식 1]"}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[수학식 2]"}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[수학식 3]"}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "상기 [수학식 1] 내지 [수학식 3]을 통해 RGB 색 공간이 YUV 색 공간으로 변환된 경우, RGB 색 공간에서의 적색, 청색, 녹색, 옐로우, 마젠타, 싸이언, 백색의 위치 관계는 변화한다. YUV 색 공간으로서, 휘도(Y), 청색 색차(Cb)(즉, U채널), 및 적색 색차(Cr)(즉, V 채널)이 차원을 구성한다. 데 이터가 8비트로 표현되는 경우, RGV 색 공간의 적색, 청색, 녹색, 옐로우, 마젠타, 싸이언, 백색, 및 흑색은 팔 면체의 모서리로서 표현될 수 있으나, 특정한 위치로 정형화할 수는 없다. 예를 들어, 백색은 휘도(Y)가 255이며, 청색 색차(Cb) 및 적색 색차(Cr)는 모두 128인 색상이다. 도 14a 및 도 14b는 본 개시의 예시적인 실시 예에 따른 전자 장치의 동작 방법을 설명하는 흐름도이다. 도 1이 함께 참조된다. 도 14a를 참조하면, 단계 S10에서 스테레오 이미지 데이터(도 1, SIDAT)가 생성될 수 있다. 예시적인 실시 예에 서, 전자 장치는 듀얼 픽셀(도 1, 101)을 이용하여 스테레오 이미지 데이터(SIDAT)를 생성할 수 있다. 스테 레오 이미지 데이터(SIDAT)는 한 쌍의 이미지 데이터(IDATL, IDATR)를 포함할 수 있다. 단계 S20에서, 스테레오 이미지 데이터(SIDAT)에서 관심 객체가 검출될 수 있다. 예시적인 실시 예에서, 처리 회로(도 1, 300)는 장면에서 복수의 객체를 추출할 수 있고, 복수의 객체에서 관심 객체(OOI)를 검출할 수 있다. 처리 회로는 관심 객체를 포함하는 관심 영역을 센싱하도록 크롭 신호(도 1, CROP)를 생성할 수 있 다. 단계 S30에서, 관심 객체를 포함하는 관심 영역에 대한 부분 스테레오 이미지 데이터가 생성될 수 있다. 예시적 인 실시 예에서, 처리 회로는 크롭 신호(CROP)에 기초해 장면에 대한 부분적 이미지를 센싱하는 부분 스테 레오 이미지 데이터를 생성할 수 있다. 센싱하는 부분 스테레오 이미지 데이터는 도 9a 또는 도 9b의 크롭 이미 지 데이터(cIDAT)와 대응될 수 있다. 단계 S40에서, 부분 스테레오 이미지 데이터에 기초해 심도가 추정될 수 있다. 예시적인 실시 예에서, 이미지 센서는 장면에 비해 상대적으로 작은 영역인 관심 영역에 대한 센싱을 수행할 수 있고, 처리 회로는 부분 스테레오 이미지 데이터에 기초해 심도 추정을 위한 인공신경망을 이용해 심도를 추정할 수 있다. 단계 S50에서, 추정된 심도를 이용해 심도 정보가 생성될 수 있다. 도 14b를 참조하면, 단계 S30 후 단계 S41에서 부분 스테레오 이미지 데이터에 기초해 심도가 추정될 수 있고, 단계 S51에서 추정된 심도를 이용해 심도 정보가 생성될 수 있다. 한편, 단계 S30 후 단계 S43에서 부분 스테레오 이미지 데이터에 기초해 RGB가 변환될 수 있고, 단계 S53에서 변환된 RGB를 이용해 심도 정보가 생성될 수 있다. 단계 S51 또는 단계 S53 후인 단계 S60에서, 처리 회로는 색상 및 심도 정보(iRGBD)를 생성할 수 있다. 도 15a 및 도 15b는 본 개시의 예시적인 실시 예에 따른 전자 장치의 동작 방법을 설명하는 흐름도이다. 단계 S105에서, 디스패리티를 가지는 제1 출력 데이터가 생성될 수 있다. 예시적인 실시 예에서, 제1 출력 데이 터는 이미지 센서에서 출력되며, 이미지 센서가 듀얼 픽셀(도 1, 101)을 포함함으로 인해 생성되는 데이터 쌍일 수 있다. 단계 S110에서, 제1 출력 데이터가 이미지 신호 처리기에 제공될 수 있다. 단계 S115에서, 제1 출력 데이터를 보정함으로써 제1 이미지 데이터가 생성될 수 있다. 예시적인 실시 예에서, 이미지 신호 처리기는 한 쌍의 출력 데이터를 보정함으로써 한 쌍의 제1 이미지 데이터를 생성할 수 있다. 단계 S120에서, 제1 이미지 데이터가 제공될 수 있다. 단계 S125에서, 제1 이미지 데이터가 리사이징될 수 있다. 예시적인 실시 예에서, 리사이저(도 7, 310)는 이미 지 데이터(IDAT)의 크기 또는 해상도를 조정할 수 있으며, 리사이저는 이미지 데이터(IDAT)의 크기를 축소 시킬 수 있거나, 리사이저는 이미지 데이터(IDAT)의 해상도를 축소시킬 수 있다. 리사이저가 이미지 데이터(IDAT)의 크기 또는 해상도를 조정한 결과, 객체 검출을 위해 필요한 데이터 처리량은 감축될 수 있다. 단계 S130에서, 관심 객체가 검출될 수 있다. 관심 객체는 장면을 구성하는 복수의 객체들 중 사용자가 검출하 고자 하는 대상 객체를 의미할 수 있다. 단계 S135 에서, 관심 영역이 결정될 수 있다. 예시적인 실시 예에서, 관심 영역은 관심 객체를 포함하며, 관심 객체를 둘러쌓은 경계 박스와 같거나 큰 영역일 수 있다. 단계 S140에서, 처리 회로는 크롭 신호(CROP)를 이미지 센서에 전송할 수 있다. S145에서, 크롭 영역에 대한 디스패리티를 가지는 제2 출력 데이터가 생성될 수 있다. 예시적인 실시 예에서, 제2 출력 데이터는 이미지 센서에서 출력되며, 이미지 센서가 크롭 신호(CROP)에 의해 생성하는 장면 에 대한 부분적 데이터 쌍일 수 있다. 단계 S150에서, 제2 출력 데이터가 이미지 신호 처리기에 제공될 수 있다. S155에서, 이미지 신호 처리기가 제2 출력 데이터를 보정함으로써 제2 이미지 데이터를 생성할 수 있다. 단계 S165에서, 제2 이미지 데이터에 대한 심도가 추정될 수 있고, 단계 S170에서, 제2 이미지 데이터에 대해 추정된 심도에 기반하여 심도 정보가 생성될 수 있다. 도 15b는 도 15a와 함께 참조된다. 단계 S205에서 처리 회로가 심도 정보를 생성하는 것은 도 15a에서 전 술된 바와 같이 제2 이미지 데이터에 대해 추정된 심도에 기반하여 심도 정보가 생성되는 것에 대응될 수 있다. 단계 S210에서, 모드 변경 신호는 이미지 센서에 전송될 수 있다. 예를 들어, 이미지 센서는 동작 모 드로서, 듀얼 픽셀(도 1, 101)을 이용해 스테레오 이미지 데이터(도 1, SIDAT)를 생성하는 제1 모드, 하나의 픽 셀에 마련된 하나의 광전 변환 소자로부터의 이미지 신호에 기초한 단일 이미지 데이터를 생성하거나, 듀얼 픽 셀을 이용하되 듀얼 픽셀에 포함된 복수의 광전 변환 소자들 각각의 이미지 신호를 합산해 이미지 데 이터를 생성하는 제2 모드, 및/또는 단일 이미지 데이터에 더하여, 듀얼 픽셀로부터 센싱된 스테레오 휘도 데이터를 추가적으로 생성하는 제3 모드를 지원할 수 있다. 모드 변경 신호는 제1 내지 제3 모드 중 어느 하나 의 모드에서 다른 어느 하나의 모드로 변경하도록 지시할 수 있다. 예를 들어, 이미지 센서는 제3 모드로 변경될 수 있다. 이하에서, 본 도 15b에 대한 설명은 편의를 위해 제3 모드로 변경된 경우의 동작 방법을 설명 한다. 단계 S215에서, 이미지 센서는 디스패리티를 가지는 제3 출력 데이터, 및 베이어 패턴의 제4 출력 데이터 를 생성할 수 있다. 제4 출력 데이터는 듀얼 픽셀에 포함된 복수의 광전 변환 소자들 각각의 이미지 신호 를 합산해 생성될 수 있다. 단계 S220에서, 제3 및 제4 출력 데이터는 이미지 신호 처리기로 제공될 수 있 다. 단계 S225에서, 제3 출력 데이터를 보정해 제3 이미지 데이터가 생성될 수 있다. 예를 들어, 이미지 신호 처리 기는 디스패리티를 가지는 제3 출력 데이터에 대해 자동 초점 보정, 자동 화이트 노이즈 보정 등을 수행함 으로써 제3 이미지 데이터를 생성할 수 있다. 제3 이미지 데이터는 심도 정보와 관련될 수 있다. 단계 S230에서, 제4 출력 데이터를 변환 및 보정해 제4 이미지 데이터가 생성될 수 있다. 예를 들어, 이미지 신 호 처리기는 베이어 패턴의 제4 출력 데이터를 YUV 변환함으로써 휘도 및 색차 정보를 포함시킬 수 있으며, 자동 초점 보정, 자동 화이트 노이즈 보정 등을 수행함으로써 제4 이미지 데이터를 생성할 수 있다. 제 4 이미지 데이터는 색상 정보와 관련될 수 있다. S235에서, 제3 및 제4 이미지 데이터가 처리 회로에 제공 될 수 있다. 단계 S240에서, 제3 이미지 데이터에 기초해 심도가 추정될 수 있다. 예를들어, 처리 회로는 제3 이미지 데이터에 기초해 심도를 추정할 수 있다. 처리 회로는 심도 추정기를 이용해 제3 이미지 데이터에 대 한 상대 심도 및 절대 심도를 포함하는 심도 정보를 추정할 수 있다. 단계 S245에서, 제4 이미지 데이터가 RGB 변환될 수 있다. 예를들어, 처리 회로는 제4 이미지 데이터에 기 초해 색채 정보를 획득할 수 있다. 단계 S250에서, RGBD 정보가 생성될 수 있다. 예를 들어, 처리 회로는 심도 정보 및 색채 정보에 기초해, 심도 및 색채 정보(RGBD)를 생성할 수 있다. 도 16a 내지 도 16c는 본 개시의 예시적인 실시 예에 따른 이미지 데이터(IDAT)의 심도 추정 결과를 도시하는 도면이다. 도 16a를 참조하면, 제1 이미지(IMG1)는 객체(토끼)와 배경을 포함할 수 있다. 제1 이미지(IMG1)는 이미지 데이 터(IDAT)에 상응할 수 있다. 제1 이미지(IMG1)의 배경으로서 언덕은 이미지의 밀도가 성기며 경계가 급격하게 변화하거나 엣지의 발생이 적은, 언텍스쳐드 영역이라고 이해될 수 있다. 도 16b를 참조하면, 제2 이미지(IMG2)는 객체(토끼)와 배경을 포함하며 심도 정보(iDEPTHa)에 상응하는 뎁스 맵 (depth map)을 나타낸다. 뎁스 맵은 이미지 센서로부터 또는 관찰 지점으로부터 물체 표면과의 거리 및 거리와 관련된 정보가 담긴 영상 또는 영상의 한 채널이며, 사용자의 시각(또는, 이미지 센서)으로부터 화면에 담긴 물 체들의 표면까지의 거리가 심도(depth) 정보로 정의될 수 있다. 제2 이미지(IMG2)는 심도 정보를 명암으로 표시하는데, 밝을수록 (또는, 백색에 가까울수록) 깊이가 적은 값을 갖는 부분으로, 어두울수록 (또는, 흑색에 가까울수록) 깊이가 큰 값을 갖는 부분인 것으로 각각 정의될 수 있 다. 심도 정보(iDEPTHa)는 도 9a의 디스패리티 특징 추출기, 디스패리티 네트워크 모듈, 및 후 처리 레이 어로부터 생성된다. 본 개시의 예시적 실시 예에 따르면, 처리 회로는 저조도에 강건한 휘도 데이터 (YDAT)만을 절대 심도를 추정하는 인공 신경망에 적용함으로써, 객체(토끼)와 배경의 구분을 달성할 수 있다. 도 16c를 참조하면, 제3 이미지(IMG3)는 객체(토끼)와 배경을 포함하며 심도 정보(iDEPTHb)에 상응하는 뎁스 맵 (depth map)을 나타낸다. 심도 정보(iDEPTHb)는 도 9b의 디스패리티 특징 추출기, 장면 네트워크 모듈, 디스패리티 네트워크 모듈, 및 후 처리 레이어로부터 생성된다. 본 개시의 예시적 실시 예에 따르면, 처리 회로는 장면 네트워크 모듈을 이용해 상대 심도 데이터를 추가적으로 결합함으로써, 상대적으로 작은 디스패리티를 가지는 데이터에 대하여도 객체(토끼)와 배경의 구분 을 보다 명확히 달성할 수 있다. 예를 들어, 제3 이미지(IMG3)의 언텍스쳐드 영역은 제2 이미지(IMG2)에서는 관 측될 수 없었던 영역으로써, 뎁스 맵이 개선됨을 증명할 수 있다. 도 17은 본 개시의 예시적인 실시 예에 따른 전자 시스템을 나타내는 블록도이다. 도 17을 참조하면, 도 17의 시스템-온-칩(SOC)은 도 1의 전자 장치가 적용된 것일 수 있다. 즉, 도 17의 시스템-온-칩은 도 1의 전자 장치를 지원하도록 설계될 수 있다. 도 17에 도시된 시스템-온-칩 은 도 3에 도시된 전자 장치와 대응될 수 있다. 시스템-온-칩은 구성 요소들 중 적어도 하나의 동작을 제어할 수 있다. 전자 시스템은 PC(personal computer), 데이터 서버, 또는 휴대용 전자 장치로 구현될 수 있다. 상기 휴대용 전자 장치는 랩탑(laptop) 컴퓨터, 이동 전화기, 스마트 폰 (smart phone), 태블릿 (tablet) PC, PDA(personal digital assistant), EDA(enterprise digital assistant), 디지털 스틸 카메라(digital still camera), 디지털 비디오 카메라(digital video camera), PMP(portable multimedia player), PND(personal navigation device 또는 portable navigation device), 휴대용 게임 콘솔(handheld game console), 또는 e-북(e-book)으로 구현될 수 있다. 전자 시스템은 시스템-온-칩, 카메라 모듈, 디스플레이, 파워 소스, 입출력 포트 , 메모리, 스토리지, 외부 메모리, 및 네트워크 장치를 포함할 수 있다. 카메라 모듈은 광학 이미지를 전기적인 이미지로 변환할 수 있는 모듈을 의미한다. 따라서, 카메라 모듈 로부터 출력된 전기적인 이미지는 스토리지, 메모리, 또는 외부 메모리에 저장될 수 있다. 또한, 카메라 모듈로부터 출력된 전기적인 이미지는 디스플레이를 통하여 표시될 수 있다. 카메라 모듈은 도 1의 이미지 센서, 또는 이미지 센서 및 이미지 신호 처리기를 포함할 수 있다. 디스플레이는 스토리지, 메모리, 입출력 포트, 외부 메모리, 또는 네트워크 장 치로부터 출력된 데이터를 디스플레이할 수 있다. 파워 소스는 구성 요소들 중 적어도 하나 로 동작 전압을 공급할 수 있다. 입출력 포트는 전자 시스템으로 데이터를 전송하거나 또는 전자 시스 템로부터 출력된 데이터를 외부 장치로 전송할 수 있는 포트들을 의미한다. 예컨대, 입출력 포트는 컴 퓨터 마우스와 같은 포인팅 장치(pointing device)를 접속하기 위한 포트, 프린터를 접속하기 위한 포트, 또는 USB 드라이브를 접속하기 위한 포트일 수 있다. 메모리는 휘발성 또는 불휘발성 메모리로 구현될 수 있다. 실시 예에 따라, 메모리에 대한 데이터 액세스 동작, 예컨대, 리드 동작, 라이트 동작(또는 프로그램 동작), 또는 이레이즈 동작을 제어할 수 있는 메 모리 컨트롤러는 시스템-온-칩에 집적 또는 내장될 수 있다. 다른 실시 예에 따라, 상기 메모리 컨트롤러 는 시스템-온-칩과 메모리 사이에 구현될 수 있다. 스토리지는 하드디스크 드라이브(hard disk drive) 또는 SSD(solid state drive)로 구현될 수 있다. 외부 메모리는 SD(secure digital) 카드 또는 MMC(multimedia card)로 구현될 수 있다. 실시 예에 따라, 외부 메모리는 SIM(subscriber identification module) 카드 또는 USIM(universal subscriber identity module) 카드일 수 있다. 네트워크 장치는 전자 시스템을 유선 네트워크 또는 무선 네트워크에 접속시킬 수 있는 장치를 의미할 수 있다.도 18은 도 17의 시스템-온-칩의 예시적 실시 예를 나타내는 블록도이다. 도 18을 참조하면, 시스템-온-칩은 메인 프로세서, ROM(Read Only Memory)/RAM, 모뎀(103 0)이미지 신호 처리기, NPU, GPU, DSP를 포함하는 가속기 모듈, 비휘발성 메모 리 인터페이스, 카메라 인터페이스, 메모리 인터페이스 및 디스플레이 인터페이스를 포함할 수 있다. 시스템-온-칩의 구성들, 즉 메인 프로세서, ROM/RAM, 모뎀, 이미지 신호 처리기, 비휘발성 메모리 인터페이스, 카메라 인터페이스, 메모리 인터페이스 및 디스플레이 인터페이스는 제2 버스(BUS2)를 통해 데이터를 송수신할 수 있다. 메인 프로세서는 시스템-온-칩의 전반적인 동작을 제어할 수 있다. 메인 프로세서는 예컨대 CPU, 마이크로 프로세서, ARM 프로세서, X86 프로세서, MIPS 프로세서 등으로 구현될 수 있으며, 실시 예에 따 라서는 2개 이상의 독립적인 프로세서들(또는 코어들)을 갖는 하나의 컴퓨팅 컴포넌트(computing component), 즉 멀티-코어 프로세서(multi-core processor)로 구현될 수 있다. 메인 프로세서는 ROM/RAM에 저 장된 명령어 코드(예를 들어, 인스트럭션) 및/또는 데이터를 처리 또는 실행시킬 수 있다. RAM/ROM은 프로그램들, 데이터, 및/또는 명령들(instructions)을 일시적으로 저장할 수 있다. 실시 예에 따라, RAM은 DRAM 또는 SRAM으로 구현될 수 있다. RAM은 인터페이스들(1060, 1070, 1080, 1090)을 통해 입출력되거나, 이미지 신호 처리기에서 이미지 처리된 데이터를 일시적으로 저장할 수 있다. 비휘발성 메모리 인터페이스는 비휘발성 메모리 장치로부터 입력되는 데이터 또는 비휘발성 메모리 로 출력되는 데이터를 인터페이싱할 수 있다. 비휘발성 메모리 장치는 예컨대, 메모리 카드(MMC, eMMC, SD, micro SD 등)로 구현될 수 있다. 카메라 인터페이스는 시스템-온-칩의 외부에 위치한 카메라로부터 입력되는 이미지 데이터 (예컨대, 원시 이미지 데이터)를 인터페이싱할 수 있다. 카메라는 복수의 광전 변환 소자들을 이용해 촬 영한 이미지에 대한 데이터를 생성할 수 있다. 카메라 인터페이스를 통해 수신되는 이미지 데이터 이미지 신호 처리기에 제공되거나 또는 메모리 인터페이스를 통해 메모리에 저장될 수 있다. 메모리 인터페이스는 메모리로부터 입력되는 데이터 또는 메모리로 출력되는 데이터를 인터 페이싱할 수 있다. 실시 예에 따라, 메모리는 DRAM이나 SRAM 등의 휘발성 메모리 또는 ReRAM, PRAM 또는 NAND flash 등의 비휘발성 메모리로 구현될 수 있다. 디스플레이 인터페이스는 디스플레이 장치로 출력되는 데이터(예컨대, 이미지 데이터)를 인터페이 싱할 수 있다. 디스플레이 장치는 이미지 데이터에 따른 영상 신호를 LCD(Liquid-crystal display), AMOLED(active matrix organic light emitting diodes) 등의 디스플레이를 통해 출력할 수 있다. 이미지 신호 처리기는 카메라로부터 제공되는 이미지 데이터에대하여 이미지 처리를 수행함으로써, 변환된 이미지 데이터를 생성하고, 변환된 이미지 데이터를 메모리에 저장하거나, 변환된 이미지 데이터 를 스케일링하여 스케일링된 이미지를 디스플레이 장치에 제공할 수 있다. 이 외에도, 시스템-온-칩 은 보안 방법, 프로토콜, 암호화 및 복호화 키를 포함하는 보안기를 더 포함할 수 있다. 이상에서와 같이 도면과 명세서에서 예시적인 실시 예들이 개시되었다. 본 명세서에서 특정한 용어를 사용하여 실시 예들을 설명되었으나, 이는 단지 본 개시의 기술적 사상을 설명하기 위한 목적에서 사용된 것이지 의미 한"}
{"patent_id": "10-2021-0063620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "정이나 청구범위에 기재된 본 개시의 범위를 제한하기 위하여 사용된 것은 아니다. 그러므로 본 기술분야의 통 상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라 서, 본 개시의 진정한 기술적 보호범위는 첨부된 청구범위의 기술적 사상에 의해 정해져야 할 것이다.도면 도면1 도면2 도면3a 도면3b 도면3c 도면4a 도면4b 도면5 도면6a 도면6b 도면6c 도면6d 도면6e 도면7 도면8 도면9a 도면9b 도면10a 도면10b 도면10c 도면11a 도면11b 도면11c 도면11d 도면12 도면13 도면14a 도면14b 도면15a 도면15b 도면16a 도면16b 도면16c 도면17 도면18"}
{"patent_id": "10-2021-0063620", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 예시적인 실시 예에 따른 전자 장치를 나타내는 블록도이다. 도 2는 이미지 센서를 상세히 나타내는 블록도이다. 도 3a는 픽셀의 구조를, 도 3b 및 도 3c는 본 개시의 예시적인 실시 예에 따른 픽셀의 구조를 각각 나타내는 도면이다. 도 4a는 및 도 4b는 본 개시의 예시적인 실시 예에 따른 장면에 대한 카메라 종류 별 디스패리티 차이를 나타내 는 도면이다. 도 5는 본 개시의 예시적인 실시 예에 따른 이미지 신호 처리기를 상세히 나타내는 블록도이다. 도 6a는 베이어 패턴을 가지는 출력 데이터가 YUV 형식으로 변환됨을 설명하는 도면이고, 도 6b 내지 도 6e는 YUV 형식을 따르는 이미지 데이터의 데이터 구조를 나타내는 도면이다. 도 7은 본 개시의 예시적인 실시 예에 따른 처리 회로를 도시하는 블록도이다. 도 8은 본 개시의 예시적인 실시 예에 따른 처리 회로를 도시하는 블록도이다. 도 9a 및 도 9b는 본 개시의 예시적인 실시 예에 따른 처리 회로를 도시하는 블록도이다. 도 10a 내지 도 10c는 인공 신경망의 구조 및 동작을 설명하는 도면이다. 도 11a 내지 도 11d는 본 개시의 예시적인 실시 예에 따른 네트워크의 구조를 나타내는 블록도이다. 도 12는 본 개시의 예시적인 실시 예에 따른 처리 회로를 도시하는 블록도이다. 도 13은 이미지 데이터의 RGB 형식과 YUV 형식의 변환 관계를 나타내는 도면이다. 도 14a 및 도 14b는 본 개시의 예시적인 실시 예에 따른 전자 장치의 동작 방법을 설명하는 흐름도이다. 도 15a 및 도 15b는 본 개시의 예시적인 실시 예에 따른 전자 장치의 동작 방법을 설명하는 흐름도이다. 도 16a 내지 도 16c는 본 개시의 예시적인 실시 예에 따른 이미지 데이터의 심도 추정 결과를 도시하는 도면이 다. 도 17은 본 개시의 예시적인 실시 예에 따른 전자 시스템을 나타내는 블록도이다. 도 18은 도 17의 시스템-온-칩의 예시적 실시 예를 나타내는 블록도이다."}
