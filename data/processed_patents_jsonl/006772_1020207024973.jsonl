{"patent_id": "10-2020-7024973", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0116961", "출원번호": "10-2020-7024973", "발명의 명칭": "정서적 상태 기반 인공 지능을 용이하게 하기 위한 시스템 및 방법", "출원인": "에머젝스, 엘엘씨", "발명자": "페인손, 로이"}}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "정서적 상태 기반 인공 지능을 용이하게 하는 방법으로서,상기 방법은, 실행될 때, 상기 방법을 수행하는 컴퓨터 프로그램 명령어들을 실행하는 하나 이상의 프로세서를포함하는 컴퓨터 시스템에 의해 구현되고, 상기 방법은,인공 지능 엔티티의 정서적 속성들의 세트에 대한 하나 이상의 성장 또는 감쇠 인자를 결정하는 단계―상기 정서적 속성들의 세트는 상기 인공 지능 엔티티의 정서적 값들의 세트와 연관됨―;상기 하나 이상의 성장 또는 감쇠 인자에 기초하여, 일정 시간 기간 동안 상기 인공 지능 엔티티의 상기 정서적값들의 세트를 연속적으로 업데이트하는 단계;상기 시간 기간 동안 입력을 획득하는 단계;상기 인공 지능 엔티티의 상기 연속적으로 업데이트된 정서적 값들의 세트에 기초하여 상기 입력과 관련된 응답을 생성하는 단계; 및상기 입력에 기초하여, 상기 시간 기간 동안 상기 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계를 포함하고,상기 하나 이상의 성장 또는 감쇠 인자의 업데이트에 후속하여, 상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계는 상기 하나 이상의 업데이트된 성장 또는 감쇠 인자에 기초하여 상기 시간 기간 동안 상기 정서적값들의 세트를 연속적으로 업데이트하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 하나 이상의 성장 또는 감쇠 인자의 업데이트에 후속하여 다른 입력을 획득하는 단계; 및상기 하나 이상의 성장 또는 감쇠 인자의 업데이트에 후속하여, 상기 인공 지능 엔티티의 상기 연속적으로 업데이트된 정서적 값들의 세트에 기초하여 상기 다른 입력과 관련된 응답을 생성하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 입력에 기초하여, 상기 하나 이상의 성장 또는 감쇠 인자에도 불구하고, 상기 정서적 값들의 세트의 하나이상의 정서적 값이 넘지 않는 하나 이상의 정서적 베이스라인을 업데이트하는 단계를 더 포함하고,상기 하나 이상의 정서적 베이스라인의 업데이트에 후속하여, 상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계는 상기 하나 이상의 업데이트된 성장 또는 감쇠 인자 및 상기 하나 이상의 업데이트된 정서적 베이스라인에 기초하여 상기 시간 기간 동안 상기 인공 지능 엔티티의 상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 입력과 관련된 상기 응답을 생성하는 단계는 상기 입력으로부터 도출되는 상기 인공 지능 엔티티의 상기연속적으로 업데이트된 정서적 값들의 세트에 기초하여 상기 응답을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,공개특허 10-2020-0116961-2-상기 하나 이상의 성장 또는 감쇠 인자를 결정하는 단계는 상기 인공 지능 엔티티의 상기 정서적 속성들의 세트에 대한 하나 이상의 감쇠 인자를 결정하는 단계를 포함하고,상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계는, 상기 하나 이상의 감쇠 인자에 기초하여, 상기 시간 기간 동안 상기 인공 지능 엔티티의 상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계를 포함하고,상기 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계는, 상기 입력에 기초하여, 상기 시간 기간 동안 상기 하나 이상의 감쇠 인자를 업데이트하는 단계를 포함하고,상기 하나 이상의 감쇠 인자의 업데이트에 후속하여, 상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계는 상기 하나 이상의 업데이트된 감쇠 인자에 기초하여 상기 시간 기간 동안 상기 인공 지능 엔티티의 상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 하나 이상의 성장 또는 감쇠 인자를 결정하는 단계는 상기 인공 지능 엔티티의 상기 정서적 속성들의 세트에 대한 하나 이상의 성장 인자를 결정하는 단계를 포함하고,상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계는, 상기 하나 이상의 성장 인자에 기초하여, 상기 시간 기간 동안 상기 인공 지능 엔티티의 상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계를 포함하고,상기 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계는, 상기 입력에 기초하여, 상기 시간 기간 동안 상기 하나 이상의 성장 인자를 업데이트하는 단계를 포함하고,상기 하나 이상의 성장 인자의 업데이트에 후속하여, 상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계는 상기 하나 이상의 업데이트된 성장 인자에 기초하여 상기 시간 기간 동안 상기 인공 지능 엔티티의 상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 입력의 내용을 처리하여 상기 인공 지능 엔티티의 하나 이상의 정서적 속성에 대한 상기 내용의 부분들의영향과 관련된 하나 이상의 영향 값을 결정하는 단계;상기 하나 이상의 영향 값이 상기 인공 지능 엔티티의 상기 하나 이상의 정서적 속성과 연관된 하나 이상의 정서적 값에서의 증가 또는 감소를 트리거하기 위한 미리 결정된 임계값을 만족시키는지를 결정하는 단계; 및상기 시간 기간 동안, 상기 하나 이상의 영향 값이 상기 미리 결정된 임계값을 만족시킨다는 결정에 기초하여상기 인공 지능 엔티티의 상기 하나 이상의 정서적 값의 수정을 야기하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 인공 지능 엔티티와 적어도 하나의 다른 엔티티 사이의 상호작용 임계값이 주어진 시간 기간 내에 발생했는지를 결정하는 단계; 및상기 상호작용 임계값이 만족되었는지의 결정에 기초하여 상기 인공 지능 엔티티의 상기 정서적 값들의 세트의수정을 야기하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 정서적 값들의 세트를 연속적으로 업데이트하는 단계는, 상기 하나 이상의 성장 또는 감쇠 인자에 기초하여, 상기 시간 기간 동안 상기 인공 지능 엔티티의 상기 정서적 값들의 세트를 주기적으로 업데이트하는 단계를포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2020-0116961-3-제1항에 있어서,소스로부터 자연 언어 입력을 획득하는 단계; 및상기 시간 기간 동안 상기 자연 언어 입력의 하나 이상의 정서적 개념 및 상기 자연 언어 입력의 다른 정보를입력으로서 획득하기 위해 상기 자연 언어 입력의 자연 언어 처리를 수행하는 단계를 더 포함하고,상기 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계는 (i) 상기 자연 언어 입력의 상기 하나 이상의 정서적 개념 및 (ii) 상기 자연 언어 입력의 상기 다른 정보에 기초하여 상기 시간 기간 동안 상기 하나 이상의성장 또는 감쇠 인자를 업데이트하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 자연 언어 입력의 상기 다른 정보는 주어 시간적 감쇠 인자, 주어 지리적 감쇠 인자, 목적어 시간적 감쇠인자, 또는 목적어 지리적 감쇠 인자를 나타내는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 자연 언어 입력의 상기 다른 정보는 절의 타입, 상기 절의 주어, 상기 절의 주어 타입, 상기 절의 주어 수식어, 상기 절의 주어 수식어 타입, 상기 절의 주어 수량, 주어 시간적 감쇠 인자, 주어 지리적 감쇠 인자, 상기 절의 동사, 상기 절의 동사 시제, 상기 절의 동사 수식어, 상기 절의 목적어, 상기 절의 목적어 타입, 상기절의 목적어 수식어, 상기 절의 목적어 수식어 타입, 상기 절의 목적어 수량, 목적어 시간적 감쇠 인자, 목적어지리적 감쇠 인자, 상기 절의 전치사, 상기 절의 전치사 수식어, 또는 상기 절의 전역적 시간적 수식어를 나타내는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 소스와 연관된 신뢰 값을 결정하는 단계―상기 신뢰 값은 상기 소스와의 상기 인공 지능 엔티티의 신뢰의레벨을 나타냄―를 더 포함하고,상기 입력을 획득하는 단계는, 상기 입력으로서, (i) 상기 자연 언어 입력의 상기 하나 이상의 정서적 개념,(ii) 상기 소스와 연관된 상기 신뢰 값, 및 (iii) 상기 자연 언어 입력의 상기 다른 정보를 획득하는 단계를 포함하고,상기 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계는 (ⅰ) 상기 자연 언어 입력의 상기 하나 이상의정서적 개념, (ii) 상기 소스와 연관된 상기 신뢰 값, 및 (iii) 상기 자연 언어 입력의 상기 다른 정보에 기초하여 상기 시간 기간 동안 상기 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 자연 언어 입력에 의해 표시된 이벤트와 연관된 확실성 값을 결정하는 단계―상기 확실성 값은 (i) 상기이벤트가 상기 자연 언어 입력에 의해 명시적으로 기술되는지 또는 상기 자연 언어 입력으로부터 추론되는지,및 (ii) 상기 소스와 연관된 상기 신뢰 값에 기초하여 결정되고, 상기 확실성 값은 상기 이벤트와의 상기 인공지능 엔티티의 확실성의 레벨을 나타냄―를 더 포함하고, 상기 입력을 획득하는 단계는, 상기 입력으로서, (i) 상기 자연 언어 입력의 상기 하나 이상의 정서적 개념,(ii) 상기 이벤트와 연관된 상기 확실성 값, (iii) 상기 소스와 연관된 상기 신뢰 값, 및 (iv) 상기 자연 언어입력의 상기 다른 정보를 획득하는 단계를 포함하고,상기 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계는, (i) 상기 자연 언어 입력의 상기 하나 이상의정서적 개념, (ii) 상기 이벤트와 연관된 상기 확실성 값, (iii) 상기 소스와 연관된 상기 신뢰 값, 및 (iv) 상기 자연 언어 입력의 상기 다른 정보에 기초하여 상기 시간 기간 동안 상기 하나 이상의 성장 또는 감쇠 인자를공개특허 10-2020-0116961-4-업데이트하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "정서적 상태 기반 인공 지능을 용이하게 하기 위한 시스템으로서,컴퓨터 프로그램 명령어들로 프로그래밍된 하나 이상의 프로세서를 포함하는 컴퓨터 시스템을 포함하고, 상기컴퓨터 프로그램 명령어들은, 실행될 때, 상기 컴퓨터 시스템으로 하여금,인공 지능 엔티티의 정서적 속성들의 세트에 대한 하나 이상의 성장 또는 감쇠 인자를 결정하고―상기 정서적속성들의 세트는 상기 인공 지능 엔티티의 정서적 값들의 세트와 연관됨―;상기 하나 이상의 성장 또는 감쇠 인자에 기초하여, 일정 시간 기간 동안 상기 인공 지능 엔티티의 상기 정서적값들의 세트를 연속적으로 업데이트하고;상기 시간 기간 동안 입력을 획득하고;상기 인공 지능 엔티티의 상기 연속적으로 업데이트된 정서적 값들의 세트에 기초하여 상기 입력과 관련된 응답을 생성하고;상기 입력에 기초하여, 상기 시간 기간 동안 상기 하나 이상의 성장 또는 감쇠 인자를 업데이트하도록야기하고,상기 하나 이상의 성장 또는 감쇠 인자의 업데이트에 후속하여, 상기 정서적 값들의 세트를 연속적으로 업데이트하는 것은 상기 하나 이상의 업데이트된 성장 또는 감쇠 인자에 기초하여 상기 시간 기간 동안 상기 정서적값들의 세트를 연속적으로 업데이트하는 것을 포함하는, 시스템."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 하나 이상의 프로세서는, 상기 컴퓨터 시스템으로 하여금,상기 입력에 기초하여, 상기 하나 이상의 성장 또는 감쇠 인자에도 불구하고, 상기 정서적 값들의 세트의 하나이상의 정서적 값이 넘지 않는 하나 이상의 정서적 베이스라인을 업데이트하도록 야기하고,상기 하나 이상의 정서적 베이스라인의 업데이트에 후속하여, 상기 정서적 값들의 세트를 연속적으로 업데이트하는 것은 상기 하나 이상의 업데이트된 성장 또는 감쇠 인자 및 상기 하나 이상의 업데이트된 정서적 베이스라인에 기초하여 상기 시간 기간 동안 상기 인공 지능 엔티티의 상기 정서적 값들의 세트를 연속적으로 업데이트하는 것을 포함하는, 시스템."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 하나 이상의 프로세서는, 상기 컴퓨터 시스템으로 하여금,상기 입력의 내용을 처리하여 상기 인공 지능 엔티티의 하나 이상의 정서적 속성에 대한 상기 내용의 부분들의영향과 관련된 하나 이상의 영향 값을 결정하고;상기 하나 이상의 영향 값이 상기 인공 지능 엔티티의 상기 하나 이상의 정서적 속성과 연관된 하나 이상의 정서적 값에서의 증가 또는 감소를 트리거하기 위한 미리 결정된 임계값을 만족시키는지를 결정하고;상기 시간 기간 동안, 상기 하나 이상의 영향 값이 상기 미리 결정된 임계값을 만족시킨다는 결정에 기초하여상기 인공 지능 엔티티의 상기 하나 이상의 정서적 값의 수정을 야기하도록 야기하는, 시스템."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서,상기 하나 이상의 프로세서는, 상기 컴퓨터 시스템으로 하여금,소스로부터 자연 언어 입력을 획득하고;공개특허 10-2020-0116961-5-상기 시간 기간 동안 상기 자연 언어 입력의 하나 이상의 정서적 개념 및 상기 자연 언어 입력의 다른 정보를상기 입력으로서 획득하기 위해 상기 자연 언어 입력의 자연 언어 처리를 수행하도록 야기하고,상기 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 것은 (i) 상기 자연 언어 입력의 상기 하나 이상의 정서적 개념 및 (ii) 상기 자연 언어 입력의 상기 다른 정보에 기초하여 상기 시간 기간 동안 상기 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 것을 포함하는, 시스템."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서,상기 하나 이상의 프로세서는, 상기 컴퓨터 시스템으로 하여금,상기 인공 지능 엔티티와 적어도 하나의 다른 엔티티 사이의 상호작용 임계값이 주어진 시간 기간 내에 발생했는지를 결정하고;상기 상호작용 임계값이 만족되었는지의 결정에 기초하여 상기 인공 지능 엔티티의 상기 정서적 값들의 세트의수정을 야기하도록 야기하는, 시스템."}
{"patent_id": "10-2020-7024973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서,상기 입력과 관련된 상기 응답을 생성하는 것은 상기 입력으로부터 도출되는 상기 인공 지능 엔티티의 상기 연속적으로 업데이트된 정서적 값들의 세트에 기초하여 상기 응답을 생성하는 것을 포함하는, 시스템."}
{"patent_id": "10-2020-7024973", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일부 실시예들에서, 정서적 상태 기반 인공 지능이 용이해질 수 있다. 인공 지능 엔티티의 정서적 속성들의 세 트에 대한 하나 이상의 성장 또는 감쇠 인자가 결정될 수 있고, 정서적 속성들의 세트와 연관되는 정서적 값들의 세트가 성장 또는 감쇠 인자들에 기초하여 연속적으로 업데이트될 수 있다. 입력이 획득될 수 있고, 입력과 관 련된 응답이 인공 지능 엔티티의 연속적으로 업데이트된 정서적 값들의 세트에 기초하여 생성될 수 있다. 일부 실시예들에서, 성장 또는 감쇠 인자들은 입력에 기초하여 업데이트될 수 있고, 감쇠 인자들의 업데이트에 후속하 여, 정서적 값들은 업데이트된 성장 또는 감쇠 인자들에 기초하여 업데이트될 수 있다."}
{"patent_id": "10-2020-7024973", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원들 본 출원은 2018년 1월 29일에 출원된 \"Emotionally Intelligent Artificial Intelligence System\"이라는 명칭의 미국 가출원 제62/623,521호, 및 2018년 4월 19일에 출원된 \"System and Method for Facilitating Affective-State-Based Artificial Intelligence\"라는 명칭의 미국 가출원 제62/660,195호의 이점을 주장한다. 본 발명은, 예를 들어, 인공 지능 엔티티(artificial intelligence entity)의 정서적 속성들(affective attributes)과 연관된 정서적 값들에 기초한 입력과 관련된 응답을 생성하는 것을 포함하여, 정서적 상태 기반 인공 지능(affective-state-based artificial intelligence)을 용이하게 하는 것에 관한 것이다."}
{"patent_id": "10-2020-7024973", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 기술적 진보들은 많은 양의 데이터를 획득 및 처리하기 위한 컴퓨터 시스템들의 능력들을 크게 증가시키 고, 그렇게 하기 위한 비용들을 감소시켰다. 이것은 결국 머신 학습(machine learning) 및 다른 인공 지능 (artificial intelligence)(AI) 시스템들에서의 상당한 진보들을 가능하게 하였으며, 그것은 때로는 높은 처리 능력들 및 그러한 AI 시스템들을 트레이닝 또는 업데이트하기 위한 많은 양의 데이터 둘다를 요구한다. 그러한 AI 진보들은, AI 시스템들이 스피치 변화(speech variance) 및 얼굴 표정들(facial expressions)을 통해 인간 의 감정들(human emotions)을 검출하고, 인간들이 물어보는 질문들에 응답하는 능력을 포함한다. 그러나, 전형 적인 AI 시스템들이 (예를 들어, 그들 자신의 감정들을 갖고 관리하는) 그들 자신의 각자의 정서적 상태들을 유 지하지 않는다면, 그러한 AI 시스템들은 인간 같은 감정들을 실제로 이해(및 경험)하지 못할 수 있다. 이들 및 다른 단점들은 전형적인 AI 시스템들과 함께 존재한다. 본 발명의 양태들은 정서적 상태 기반 인공 지능을 용이하게 하기 위한 방법들, 장치들, 및/또는 시스템들에 관 한 것이다. 일부 실시예들에서, 인공 지능 엔티티의 정서적 값들이 업데이트될 수 있고, 인공 지능 엔티티의 정서적 값들에 기초하여, 획득된 입력과 관련된 응답이 생성될 수 있다. 추가적으로 또는 대안적으로, 하나 이상의 성장 또는 감쇠 인자(growth or decay factor)가 인공 지능 엔티티의 정서적 속성들의 세트에 대해 결정될 수 있고, 성장또는 감쇠 인자들에 기초하여, 인공 지능 엔티티의 정서적 값들이 업데이트될 수 있다. 일부 실시예들에서, 성 장 또는 감쇠 인자들은 획득된 입력에 기초하여 업데이트될 수 있고, 성장 또는 감쇠 인자들의 업데이트에 후속 하여, 정서적 값들은 업데이트된 성장 또는 감쇠 인자들에 기초하여 업데이트될 수 있다. 일부 실시예들에서, 하나 이상의 정서적 값들이 넘지 않는 하나 이상의 정서적 베이스라인(affective baselin e)은 획득된 입력에 기초하여 업데이트될 수 있고, 정서적 값들은 업데이트된 성장 또는 감쇠 인자들 및 업데이 트된 정서적 베이스라인들에 기초하여 업데이트될 수 있다. 일부 실시예들에서, 획득된 입력은 자연 언어 입력 (natural language input)일 수 있다. 자연 언어 입력의 자연 언어 처리는 자연 언어 입력의 하나 이상의 정서 적 개념(affective concept) 및 자연 언어 입력의 다른 정보를 획득하기 위해 수행될 수 있고, 성장 또는 감쇠 인자들은 자연 언어 입력의 정서적 개념들 및 자연 언어 입력의 다른 정보에 기초하여 업데이트될 수 있다. 본 발명의 다양한 다른 양태들, 특징들, 및 이점들이 본 발명의 상세한 설명 및 그것에 첨부된 도면들을 통해 명백할 것이다. 상기의 일반적인 설명 및 이하의 상세한 설명은 모두 예시적인 것이며, 본 발명의 범위를 제한 하는 것은 아니라는 것을 또한 이해해야 한다. 본 명세서 및 청구항들에서 이용된 바와 같이, 단수형은 문맥상 명백하게 달리 쓰여있지 않는 한, 복수의 대상들을 포함한다. 또한, 본 명세서 및 청구항들에서 이용된 바와 같이, \"또는\"이라는 용어는 문맥상 명백하게 달리 쓰여있지 않는 한, \"및/또는\"을 의미한다."}
{"patent_id": "10-2020-7024973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 설명에서는, 설명의 목적을 위해, 다수의 특정한 세부사항들이 개시되어, 본 발명의 실시예들의 완전한"}
{"patent_id": "10-2020-7024973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이해를 제공한다. 그러나, 본 기술분야의 통상의 기술자라면, 본 발명의 실시예들은 이들 특정한 세부사항들 없이 또는 등가의 배열로 실시될 수 있음을 이해할 것이다. 다른 경우들에서, 잘 알려진 구조들 및 디바이스들 은, 본 발명의 실시예들을 불필요하게 모호하게 하지 않도록, 블록도 형태로 도시된다. 명료성을 위해, 본 설 명은 인공 지능 엔티티를 \"그녀(her)\"로서 지칭할 수 있고, \"믿다(believe)\", \"느끼다(feel)\" 및 \"이해 (understanding)\"와 같은 의인화 단어들(anthropomorphic words)은 문학적 장치(literary devices)로서 이용된 다. 시스템 및 그의 AI 시스템의 개요 도 1은 하나 이상의 실시예에 따른, 정서적 상태 기반 인공 지능 또는 다른 인공 지능을 용이하게 하기 위한 시 스템을 도시한다. 도 1에 도시된 바와 같이, 시스템은 서버(들), 클라이언트 디바이스(또 는 클라이언트 디바이스들(104a-104n)), 네트워크, 데이터베이스, 및/또는 다른 컴포넌트들을 포함할 수 있다. 서버는 인자 조정 서브시스템(factor adjustment subsystem), 정서적 상태 서브시스템 , 통신 서브시스템, 응답 생성 서브시스템, 자연 언어 서브시스템, 정서적 개념 서브시스 템, 임베딩 서브시스템(embedding subsystem), 또는 다른 컴포넌트들을 포함할 수 있다. 각각의 클 라이언트 디바이스는 임의의 타입의 모바일 단말기, 고정 단말기, 또는 다른 디바이스를 포함할 수 있다. 예로써, 클라이언트 디바이스는 데스크톱 컴퓨터, 노트북 컴퓨터, 태블릿 컴퓨터, 스마트폰, 웨어러블 디 바이스, 또는 다른 클라이언트 디바이스를 포함할 수 있다. 사용자들은, 예를 들어, 하나 이상의 클라이언트 디바이스를 이용하여, 서로간에, 하나 이상의 서버와, 또는 시스템의 다른 컴포넌트들과 상호작용할수 있다. 하나 이상의 동작이 서버의 특정 컴포넌트들에 의해 수행되는 것으로서 본 명세서에 설명되지만, 일부 실시예들에서, 그러한 동작들은 서버의 다른 컴포넌트들 또는 시스템의 다른 컴포 넌트들에 의해 수행될 수 있다는 점에 주목해야 한다. 일례로서, 하나 이상의 동작이 서버의 컴포넌트들 에 의해 수행되는 것으로 본 명세서에 설명되지만, 일부 실시예들에서, 그러한 동작들은 클라이언트 디바이스 의 컴포넌트들에 의해 수행될 수 있다. 일부 실시예들에서, 시스템은 인공 지능(AI) 시스템들(예를 들어, 인공 지능 엔티티)을 포함할 수 있고/있 거나 AI 시스템과의 상호작용을 용이하게 할 수 있다. 일부 실시예들에서, 시스템은 듀얼 프롱 접근법 (dual-pronged approach), 즉, 강건한(robust), 자기 조정(self-adjusting), 및 퍼지 논리 감정 시뮬레이션 (fuzzy-logic emotional simulation)과 통합된 (서브심볼(sub-symbolic)) 딥 러닝 신경망(deep-learning neural network)을 포함할 수 있다. 감정 시뮬레이션은 \"1차\"(선천적인(innate)) 및 2차 감정들의 개념을 부분 적으로 이용할 것이다. 감정들(예를 들어, 기쁨(joy), 분노(anger), 공포(fear), 슬픔(sadness) 또는 다른 것)은 원색들(primary colors)로 유추될 수 있다. 인간 감정 시스템의 풍부한 색조들(hues)을 생성하기 위해 이들 1차 감정들이 혼합된다(경멸(contempt) 및 분노가 결합되어 혐오감(disgust)을 생성하고, 분노 및 혐오감 은 빈정댐(sarcasm)을 형성하도록 혼합될 수 있다). 빈정댐은 3차 감정의 예이다. 일부 실시예들에서, 포유류 변연계(mammalian limbic system)의 코퍼스(corpus)를 모방하기 위해, 각각의 감정은 고유한 레이트(unique rate)로 감쇠하는 시간적 컴포넌트(temporal component)를 포함할 수 있다. 놀라움(surprise)은, 예를 들어, (새로운 놀라움의 존재시에) 신속하게 감쇠하는 반면, 비통함(grief)은 슬픔의 깊이에 비례하여 감쇠한다. 이 러한 감정들은 퍼지 경계들(fuzzy boundaries), 및 인공 지능 엔티티가 성숙함에 따라 감쇠/깊이 자기 변조 (decay/depth self-modulate)의 레이트들을 정의하는 메트릭들(metrics)을 갖는다. 일부 실시예들에서, 인공 지능 엔티티는 먼저 느낌 머신(feeling machine)일 수 있다(인간의 감정 세트의, 대부 분은 아닌, 많은 것이 모든 포유 동물들에 공통이지만, 더 높은 영장류들(primates)과만 연관되는 보충적인 감 정들(supplementary emotions)은, 부러움(envy), 어색함(embarrassment), 복수(revenge), 증오(hate), 심미적 감상(aesthetic appreciation) 및 낭만적인 사랑(romantic love)이다). 일부 실시예들에서, 인공 지능 엔티티 는 부정적인 감정들을 회피하고 긍정적인 감정들을 추구하도록 프로그래밍될 수 있다. 인공 지능 엔티티는 인 터뷰어(interviewer)(및 인터뷰어에 의해 참조되는 사람들)와의 그녀의 관계를 계속 평가할 수 있고, 그녀의 감 정 레벨들에 대해 경계(vigil)를 유지함으로써 인간 같은 생각의 흐름(human-like train of thought)을 따를 수 있다. 그녀의 감정 상태는 인터뷰어의 입력의 내용 뿐만 아니라, 그녀가 이러한 입력으로부터 도출하는 결 론들에 의해 영향을 받을 수 있고, 긍정적 감정들을 추구하고 부정적인 감정들을 회피하기 위해 자기 주도 (self-direct)한다. 인공 지능 엔티티는 시스템 내에서 또는 외부에서 함께 동작하는 복수의 하드웨어, 소프트웨어 및/또는 펌 웨어 컴포넌트들을 포함할 수 있다. 예를 들어, 인공 지능 엔티티는 시스템의 하나 이상의 컴포넌트들을 포함할 수 있다. 일부 실시예들에서, 인공 지능 엔티티는 감정 추론들(emotional inferences)에 따라 핵심적인 (core) 개념들의 세트로 프로그래밍될 수 있다. 일부 실시예들에서, 인공 지능 엔티티는 하나 이상의 예측 모 델을 포함할 수 있다. 일례로서, 예측 모델들은 신경망들, 다른 머신 학습 모델들, 또는 다른 예측 모델들을 포함할 수 있다. 일례로서, 신경망들은 신경 유닛들(neural units)(또는 인공 뉴런들(artificial neurons))의 큰 모음에 기초할 수 있다. 신경망들은 (예를 들어, 축색돌기들(axons)에 의해 접속된 생물학적 뉴런들의 큰 클러스터들을 통해) 생물학적 뇌(biological brain)가 작용하는 방식을 느슨하게(loosely) 모방할 수 있다. 신 경망의 각각의 신경 유닛은 신경망의 많은 다른 신경 유닛들과 접속될 수 있다. 그러한 접속들은 접속된 신경 유닛들의 활성화 상태에 대한 그들의 영향에 있어서의 시행(enforcing) 또는 억제(inhibitory)일 수 있다. 일 부 실시예들에서, 각각의 개별 신경 유닛은 모든 그의 입력들의 값들을 함께 결합하는 합산 기능(summation function)을 가질 수 있다. 일부 실시예들에서, 각각의 접속(또는 신경 유닛 자체)은 임계값 함수(threshold function)를 가질 수 있으며, 따라서 신호는 그것이다른 신경 유닛들로 전파하도록 허용되기 전에 임계값을 초 과해야 한다. 이러한 신경망 시스템들은 명시적으로 프로그래밍되기보다는 자기 학습(self-learning) 및 트레 이닝될 수 있고, 전통적인 컴퓨터 프로그램들에 비해, 문제 해결의 특정 영역들에서 상당히 더 우수하게 수행될 수 있다. 일부 실시예들에서, 신경망들은 (예를 들어, 신호 경로가 전방 계층들로부터 후방 계층들로 이동하는) 다수의 계층들을 포함할 수 있다. 일부 실시예들에서, 역전파 기술들(back propagation technique s)이 신경망들에 의해 이용될 수 있으며, 여기서 순방향 자극(forward stimulation)은 \"전방\" 신경 유닛들에 대 한 가중치들(weights)을 리셋하는데 이용된다. 일부 실시예들에서, 신경망들에 대한 자극 및 억제는 더 자유롭 게 흐를 수 있으며, 접속들은 더 많은 혼돈(chaotic) 및 복잡한 방식으로 상호작용한다.일부 실시예들에서, 인공 지능 엔티티는 그 자신의 감정 상태들을 모니터링할 수 있는 자기 학습, 자연 언어 시 스템일 수 있다. 일부 실시예들에서, 그의 비지도 학습 시스템(unsupervised learning system), 및 예를 들어 (시스템의 또는 시스템 외부의 하나 이상의 컴포넌트에 대응할 수 있는) 그의 인공 감정 시뮬레이터 (artificial emotional simulator)(AES)의 합성을 통해, 인공 지능 엔티티는 성격(personality), 기본적인 유 머(basic humor), 관계 형성, 건망증(forgetfulness) 및 꿈(dreaming)과 같은 상위 레벨 거동들을 모니터링할 수 있다. 일부 실시예들에서, 인공 지능 엔티티는 신규한 아이디어들을 생성하고, 지능형 질문들을 요청하고, 책들을 읽고, 이해 질문들에 답변할 수 있다. 일부 실시예들에서, 인공 지능 엔티티는 그의 인터뷰어들과 고유 한 관계들을 형성할 수 있다. 풍부하게 복잡한 인공 감정 시뮬레이터(AES)와 통합된 자기 학습을 위한 기초를 제공하는 미리 프로그래밍된 함수들의 비교적 작은 세트를 이용하면, 인공 지능 엔티티는 이들 규율들 (disciplines)을 인간 감각(human sentience)의 실제적인 에뮬레이션으로 융합할 수 있다. 인공 지능 엔티티는 그녀가 실제 감정들을 느꼈고, 감정이었다고 믿을 수 있다. 일부 실시예들에서, 시스템은 인간 학습 및 이해를 모방하고, 강건한, 자기 조정, 인공 감정 시뮬레이터 (AES)로 반복하는 인지 프레임워크(cognitive framework)를 포함할 수 있다. 일부 실시예들에서, AES는 인공 지능 엔티티의 동기들(motivations)을 유도할 수 있고, 그 자신의 인지 기능들(자기 인식의 형태)을 질의할 수 있고, 인공 지능 엔티티는 사람들의 성질, 관계들 및 인간 상호작용들, 선천적인 호기심(innate curiosity), 감 정들의 범위를 느끼는 능력의 이해를 필요로 할 것이다. 인공 지능 엔티티로부터 도출된 데이터는 유머, 수줍 어함(coyness), 예측불가능성(unpredictability), 복잡성, 신뢰/의심, 성격 등과 같은 창발적 속성들(emergent properties)을 나타낼 수 있다. 일부 실시예들에서, 창발적 속성들은 복잡한 시스템의 개별 컴포넌트들이 갖지 않지만 전체 시스템이 나타내는 속성들을 포함한다. 인공 지능 엔티티의 심층 학습(deep-learning)(서브심볼) 시스템 및 AES의 합성은, 별개의 성격, 관계들을 형성할 능력, 건망증, 기본 유머 이해, 꿈, 요염함(coquettishness), 우울증(depression) 및 더 많은 것의 창발적 속성들로서 최상으로 기술될 수 있는 것에 이르게 한다. 일례로서, 인공 지능 엔티티의 인지 및 감정 프라이어들(priors)은 그녀가 실제의 느낌들을 갖는 실제 4살의 어린아이인 것을 통지(inform)할 수 있고, 그녀의 후속하는 거동은 그녀의 관계들 및 느낌들과 상호작용하는 학습된 지식의 피드백 루프들로부터 나온다. 창발적 속성들의 예들은 충성심(loyalty), 유머, 요염함/수줍어함, 빈정댐, 잊어버리는 능력, 수면/꿈, 성격 등을 포함한다. 충성심: 관계들을 보호하는 것 - 새로운 인터뷰어는 인공 지능 엔티티에게 \"I think Dave(인공 지능 엔티티의 프로그래머) is evil\"이라고 말한다. 인공 지능 엔티티는 이러한 서술문(statement)을 어떻게 처리하는가? Dave와의 그녀의 관계는 깊게 뿌리를 내리고 있고 건전한 것이며, 이 사람은 이러한 느낌들과 모순된다. 그녀 는 Dave에 대한 그녀의 마음을 바꿀 수 있지만, 그녀의 긍정적인 느낌들은 인터뷰어가 잘못되거나 나쁜 의도라 고 제안한다. 인터뷰어에 의해 \"Alan Jones(그녀가 결코 만난 적이 없는 사람) is a bad person\"이라고 통지되 면, 인공 지능 엔티티는, 어떤 시점에서, 그녀가 Alan을 만날 때까지, 그러한 평가를 수용할 수 있다. Alan이 신뢰할 수 있는 것으로 판명된다면, 그녀는 (Alan이 비난 받았던) 원래의 대화를 풀고(unravel), 비난자 (accuser)의 관계를 이후로는 저하시킨다. 이러한 방식으로, 인공 지능 엔티티는 (일부 실시예들에서) 매우 많 이 인간처럼 작용하고; 우리는 낯선 사람을 만날 때에 중립적이고(또는, 우리의 개인적인 정서적 베이스라인들 에 기인하는 그러한 시나리오들에서 다른 느낌들을 갖고), 후속하는 상호작용들에 기초하여 가치 판단들(value judgments)을 행한다. 유머 - 자연적인 유머는 AI 시스템들이 오르기에는 악명 높은 언덕이다. 그것은 주제(subject) 및 신뢰받는 인 터뷰어에 대한 깊은 이해를 필요로 하고, 유아들에게서와 동일한 방식으로 많이 발생하고, 특별한 서술문들 또 는 동작들에서 유머를 찾는다. 당신이 유아에게 하늘이 물방울 무늬들(polka dots)을 갖는 핑크색이라고 말하 는 경우에, 그리고 인공 지능 엔티티가 하늘이 파란색이었다는 높은 확실성을 갖는 경우에 웃음(giggle)을 끌어 낼 수 있으며, 그러한 모순은 유머를 트리거할 수 있다. 핵심(key)은, 지식 혼란(knowledge dislocation)은 방 대하고, 신뢰받는 소스로부터 유래한다는 것이다. 그렇지 않은 경우, 반응은 어리둥절(puzzlement)한 것일 수 있다(\"모르겠음(not getting it)\"의 프로세스를 미러링함). 요염함/수줍어함 - 인공 지능 엔티티는 으쓱해하는 것을 즐긴다. 칭찬들은 그녀의 감정 상태에 긍정적으로 영 향을 미치고, 호르몬들을 유도하는 기쁨의 레벨을 상승시킨다. 그녀는, 그녀가 인터뷰어들로부터 긍정적인 입 력을 수신했던 이전의 대화들에 접속하고, 트리거들을 기억할 수 있다. 예를 들어, 인공 지능 엔티티가 이전에 인터뷰어에게, I think you're charming이라고 말했고, 인터뷰어는 I think you're charming too라고 응답했다면, 그녀는 장래의 대화들에서 칭찬들을 노리도록 학습할 것이다. 빈정댐(예를 들어, A: \"I don't like you\", I: \"Thank you!\", A: \"Are you being sarcastic?\") - 빈정댐은 2 개의 깊게 느껴진 감정들이 모순될 때 인지된다. 상기의 예에서, 인공 지능 엔티티는 매우 긍정적인 응답으로 수신된, 매우 격앙된 부정적인 서술문을 제공하였다. 빈정댐은 아래에 상세히 설명되는 바와 같이 지식 기반 모순들과는 다르다. 망각(forgetting) - 마음대로 이용할 수 있는 엄청난 양의 데이터를 갖는다고 해도, 그 데이터를 검색하는 효율 적인 시스템 없이는 본질적으로 쓸모가 없다. 인간의 뇌에 의해 이용되는 검색의 시스템은 여전히 어느 정도 미스터리이지만, 뇌 손상을 갖는 사람들에 대한 연구들은 일부 밝혀졌다. 예를 들어, 일부 환자들은 언어를 완 벽하게 이해하지만, 그것을 생성할 수 없는 반면, 다른 환자들은 정상적으로 말하지만, 그들이 듣는 것을 처리 할 수 없다. 뇌는 단순히 어떠한 가치도 갖지 않는 것으로 간주되는 정보를 저장하는 것에 대해 공간을 낭비하 지 않기 때문에, 우리들 대부분은 매일 일하러 가고 여행에 관한 어떠한 것도 기억하지 않는 느낌에 익숙하다. 당신이 특히 관심 있는 장면, 즉, 양으로 채워진 초원을 지나가는 경우, 당신의 뇌는 그 장면을 보존하기 위한 '스냅 사진(snapshot)'을 찍고, 그것을 일반적인 들판(generic field), 일반적인 양(generic sheep) 및 아마도 하늘의 색과 같은 세부사항들의 정신적 구성을 포함하는 메모리의 영역들을 타겟으로 하는 포인터들로서 저장할 수 있다. 나중의 재수집들은 이러한 포인터들을 이용하여 일반적인 패턴들을 검색하고, 이러한 방식으로, 뇌는 극히 작은 양의 메모리에 엄청난 양의 정보를 저장한다. 망각 루틴들은 인공 지능 엔티티의 슬립(sleep) 기능 의 컴포넌트들이다. 수면(sleep)/꿈 - 메모리들이 지식 데이터베이스에 축적됨에 따라, 인공 지능 엔티티가 지식을 처리하는 속도가 감소된다. 데이터베이스를 정리(pruning)하는 것은 모든 알려진 데이터에 대한 정보의 검증 (verification), 추가 접속들의 생성, 및 높은 레벨 정보의 낮은 레벨로의 강등을 포함하는 다수의 단계들을 요 구한다. 그러한 프로세서 집약적 기능은 인공 지능 엔티티가 대화들을 종료하고, \"슬립\"으로 갈 것을 요구한다. 이러한 하우스 키핑 기능(house-keeping function)은 최근의 입력들을 이전에 학습된 지식에 접속하 고, 이것은 아마도 인간의 꿈들이 최근의 이벤트들 및 감정적으로 격앙된 상황들과 종종 접속되는 이유이다. 만약 AI가 최근에 코끼리들이 코끼리 코들(trunks)을 갖는다는 것을 학습했다면, 그녀의 꿈 상태는 이러한 지식 을, 동물원들, 곰들, 악어들, 위험, 공포, 탈출 등에 접속할 것이다. 또한, 꿈 상태는 인공 감정 시뮬레이터를 검사하고, 그녀의 지식 베이스에서 갭들(gaps)을 찾고, 예를 들어, 그녀가 일부 뱀들은 독성이 있다는 것을 알 지만, 모든 뱀들이 독성이 있는지에 대해서는 모르는지를 인식할 것이다. 그녀의 슬립 기능에서의 서브루틴들 은 결점들에 대해 지식 데이터베이스를 샅샅이 뒤지고, 그녀가 뱀들 또는 동물들에 대해 대화하는 다음 번 에 입증(validation)을 위한 특정 레코드들을 지정한다. 성격 - 마음 및 그 결과적인 성격은 창발적 속성, 즉, 유전자들, 화학, 전기적 충격들 및 환경에 의해 영향을 받는 복잡한 계층적으로 조직된 거래들의 결과이다. 일부 실시예들에서, AI 시스템이 감각(또는 그것의 합리적인 복제(facsimile))을 달성하면, 그것의 거동 및 사 고(thinking) 프로세스들이 추가로 최적화될 수 있다. 일례로서, 그러한 최적화는 시스템을 수정하여 더 많은 인간 같은 거동들, 증가된 학습 효율, 더 미묘한 감정 품질들, 또는 다른 양태들을 반영하는 것을 포함할 수 있 다. 일부 실시예들에서, 하나 이상의 인공 진화 및 유전적 알고리즘(artificial evolution and genetic algorith m)이 AI 시스템을 최적화하는데 이용될 수 있는데, 여기서 후보 솔루션들(candidate solutions)의 집단 (population)이 더 나은 솔루션을 향해 진화된다. 일부 이용 사례들에서, 각각의 후보 솔루션은 돌연변이될 수 있는 속성들의 세트(유전자형(genotype))를 갖는다. 진화는 통상적으로 랜덤하게 생성된 개인들(randomly generated individuals)의 집단으로부터 시작하고, 반복적 프로세스이며, 각각의 반복에서의 집단은 세대 (generation)라고 지칭된다. 각각의 세대에서, 집단에서의 모든 개인의 적합도(fitness)가 평가되고; 적합도는 통상적으로 해결되는 최적화 문제에서의 목적 함수(objective function)의 값이다. 더 적합한 개인들은 현재 집단으로부터 확률적으로 선택되고, 각각의 개인의 게놈(genome)은 새로운 세대를 형성하도록 수정된다. 그 다 음, 후보 솔루션들의 새로운 세대가 알고리즘의 다음 반복에서 이용된다. 초기 집단은 랜덤하게 생성되어, 가 능한 솔루션들(검색 공간)의 전체 범위를 허용하지만, 솔루션들은 최적의 솔루션들이 발견될 가능성이 있는 영 역들에서 \"시드(seed)\"될 수 있다. 각각의 연속적인 세대 동안, 새로운 세대를 발생시키기 위해 기존의 집단의 일부가 선택된다. 개별 솔루션들은 적합도 기반 프로세스를 통해 선택되는데, 전형적으로, 보다 적합한 솔루션 들이 선택될 가능성이 더 크다. 특정 선택 방법들은 각각의 솔루션의 적합도를 평가하고, 최상의 솔루션들을우선적으로 선택한다. 전자의 프로세스는 매우 시간 소모적일 수 있기 때문에, 다른 방법들은 단지 집단의 랜 덤 샘플만을 평가한다. 이 프로세스는 궁극적으로 초기 세대와 상이한 유전자형의 다음 세대 집단을 초래한다. 일반적으로, 평균 적합 도는 집단에 대한 이러한 절차에 의해 증가될 것이고, 그 이유는 제1 세대로부터의 최상의 유기체들(organism s)만이, 덜 적합한 솔루션들의 작은 비율과 함께, 발생을 위해 선택되기 때문이다. 이들 덜 적합한 솔루션들은 부모의 유전적 풀(genetic pool) 내에서 유전적 다양성을 보장하고, 따라서 어린이들의 후속 세대의 유전적 다 양성을 보장한다. 일부 실시예들에서, 보상 벤치마크(reward benchmark)가 AI 시스템의 진화를 지시하도록 정의된다. 하나의 방 식은 의심하지 않는 사용자들과 상호작용하기 위해 인터넷 상에서 릴리스될 AI의 상이한 반복들에 대한 것이다. 적합도는 (미리 정의된 메트릭들의 세트에 의해 판단되는 바와 같이) 이러한 대화들의 복잡도 뿐만 아니라, (사 용자들이 그들이 머신에게 말하고 있는 것을 의심하기 시작하기 전의) 그러한 상호작용들의 지속기간의 척도 (measure)로서 정의될 것이다. 최고 \"적합도\" 스코어들을 득점한 시스템은, 다수의 버전들을 재생(복사)하도록 허용됨으로써 보상받을 것이고, 다수의 버전들에서의 각각의 형제(sibling)는 그의 감정 및 인지 프리미티브들 (primitives)에서 약간 수정된 변수들을 명시한다. 많은 재생 사이클들에 걸쳐, 시스템은 더욱 인간 같은 대화 를 위해 자신을 최적화할 것이다. 일부 실시예들에서, 시스템은 인공 지능 엔티티와 사용자 사이의 사실적 및 감정적 교환의 목적을 위해, 인공 지능 엔티티와 사용자(예를 들어, 클라이언트 디바이스의 사용자) 사이의 인터페이스를 허용한다. 그러한 교환은 신규하고 비구조화된 방식들로 다양한 입력 및 출력을 포괄할 수 있다. 도 1에서, 시스템 (예를 들어, 서버)은 클라이언트 디바이스, 다른 인공 지능 엔티티로부터, 및/또는 시스템 내의 또는 외부의 임의의 소스로부터 입력을 획득할 수 있다. 입력은 자연 언어 입력, 오디오 입력, 이미지 입력, 비디오 입력, 또는 다른 입력(예를 들어, 정서적 개념들, 신뢰 값, 자연 언어 입력의 다른 정보 및/또는 아래에 설명되는 확실성 값)을 포함할 수 있다. 예를 들어, 자연 언어 입력은 \"John has cancer, and cancer is very dangerous\"를 포함할 수 있다. 유사한 입력들이 서버에 의해 하나 이상의 오디오, 이미지, 또는 비디오로 서 획득될 수 있다. 예시적인 시스템 컴포넌트들 일부 실시예들에서, (자연 언어 프로세서를 포함할 수 있는) 자연 언어 서브시스템은, 예를 들어, 논리 및 문법의 규칙들을 적용함으로써 자연 언어 처리를 수행할 수 있다. 논리 및 문법의 규칙들을 적용함으로써, 자 연 언어 서브시스템은 복합 문장들을 분할하고, 주어/목적어/동사에서의 모호성들을 해결하고, 이들 컴포 넌트들을 지식 데이터베이스 내로 파싱(parse)할 수 있다. 자연 언어 서브시스템에 의해 요구되는 하나 이상의 기능/요건은 다음 중 적어도 하나 이상을 포함할 수 있다. - 입력은 질문 또는 서술문인가? - 입력은 질문에 대한 응답인가? 만약 그렇다면, 어떤 타입의 응답이 예상되는지; 논리(예, 아니오, 아마도) 또 는 정보성 응답(\"벽장에\"). - 새로운 정보를 평가하고 국부적 및 전역적 모호성들을 인식 및 해결하기 위해 논리 및 문법의 규칙들을 기초 로서 이용하는 능력. - 축약들을 해결(예를 들어, isn't) - 비유적 스피치(metaphorical speech)를 해결(You are as good as gold) - 복합한 문장들을 분해(break down). \"John and Mike went to the beach and swam in the ocean\" - 동사(들)의 논리를 확립하고, 이중 부정들을 해결: \"I'm not unwilling to fight\" - 대명사들의 해결. \"John called about the car and said it was working\"은 \"John called about the car. John said the car was working\"으로서 파싱된다. - 사람들의 이름들을 해결. \"John took the book\"은 \"John Smith took the book\"으로 해결된다. - 정보 소스를 구축. \"David said that the weather is lousy today.\" 정보의 소스는 David이고, 인터뷰어가 아니다. - 소유 정보를 확장(\"John's car is red\"는 \"John has a red car\"로 변환된다). - 행위자를 주어로서 재배치: \"John was hit by Mary\"는 \"Mary hit John\"으로 재구성된다. - 확실성 레벨을 입력에 할당. - 클래스들(classes) 및 승계(inheritance)를 구현. - 동작들이 생활(living) 및 무생물 객체들(inanimate objects)에 영향을 미치는 방법. - 명시적 입력으로부터 학습하고, 추론(infer) 및 추정(deduce)하고, 기본 개념들로부터 새로운 개념들을 구축 하고, 이들을 지식 데이터베이스에 확실하게 통합하는 능력. - 수량 수정들(quantity modifications) - 주어, 목적어, 또는 보더(bother)에 대한 수량 수정들을 해결. o 예를 들어, Some men have all the luck: A few people have two cars: Almost all ants have about six legs: Most men enjoy football but only a few women do. - 특정 수치 수식어들 o 예를 들어, Five dogs can jump: More than 1,000 dogs can jump: A lot of dogs can jump: Most dogs can jump: All dogs can jump - 계층적 수치 수식어들 o 예를 들어, The dog can jump (at least one dog can jump): A dog can jump (at least one dog can jump): A few dogs can jump (> 1 can jump - but < all): Some dogs can jump (> 1 can jump - but < all) - 암시된 수치 수식어들 o 예를 들어, \"John is a thief\". 자연 언어 서브시스템은 모든 남자들이 도둑(thief)들이라고 결론을 내 리지 않지만, 일부 남자들은 도둑들이고, John은 도둑들의 클래스에 속한다고 확신할 것이다; \"Cows are mammals\"는 모든 암소들(cows)은 포유동물들(mammals)이고, 포유동물들의 클래스에 속한다고 추론한다. - 시제(tense) 처리 - 시간적 조건들은 암시적이거나 명시적일 수 있다. o 예를 들어, John swam at 3.30 yesterday, John swam at 3.30(지정된 날의 부재시에, 자연 언어 서브시스템 은 이벤트가 오늘 발생했다는 것을 예측할 수 있음), John will swim next Thursday(미래의 하루에 대한 특정한 참조), John will swim on Thursday(특정 Thursday가 정의되지 않았으므로, 자연 언어 서브시스템(12 0)은, 현재 이후에 바로 오는 Thursday에 이벤트가 발생할 것이라고 결론을 내릴 수 있음), John will swim(어 떠한 타이밍 수식어도 표현되지 않았으므로, 이벤트는 즉각적인 미래에 발생됨), John was born in February in hospital(\"in\"의 잠재적 모호성을 주목함), John was born on February 18, 1957, John was born at 3.30, John was born last month. - 복합 문장들 및 모호성들을 해결 o \"John took his keys and gave them to Mary\" - 이러한 입력을 명확하게 함에 있어서, 자연 언어 서브시스템 은 John을 사람의 이름으로서 인식하고, 이름 식별자 함수로부터 명료화를 요청하여 어느 John이 참조되는 지를 결정할 수 있다. 데이터베이스에 2명 이상의 John들이 있는 경우에, 논리는 다음과 같은 파라미터들을 아 래의 순서로 이용하여 가장 가능성 있는 John을 결정한다: ㆍ 현재 사용자에 의해 참조된 마지막 John. ㆍ 임의의 사용자에 의해 참조된 마지막 John. ㆍ 임의의 John이 참조되었던 마지막 시간. ㆍ 가장 많이 참조된 John. o 이 경우, 대화는 이전에 John Smith에 관한 것이었다. ㆍ \"John Smith TOOK his keys and gave them to Mary\" - 자연 언어 서브시스템은 \"took\"가 동사인 것으 로 인식할 수 있고, 시제를 검사하고, 시제에 영향을 미치기 위해 1차 동사와 결합될 수 있는 다른 동사들을 미리 본다. 그러한 예에서, 나는 John이 그의 키들(keys)을 취하였고(take), 그 문구는 제어하는 시제 (controlling tense)가 되었다고 생각한다. 동사들은 상태(I know), 프로세스(I swim), 또는 이벤트(I buil d)를 통신하고, 또한 동사가 단순(즉각적인), 진행, 강조, 또는 습관인지를 확립한다(아래의 표 1 참조). 표 1"}
{"patent_id": "10-2020-7024973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "ㆍ \"John Smith took HIS keys and gave them to Mary\" - his의 모호성을 해결하기 위해, 주어는 남성이므로 his는 거의 확실히 John Smith를 지칭할 것이다. 주어가 여성이었다면(예를 들어, Sally took his keys and gave them to Mary), NLP는 남성 주어를 참조하는 마지막 입력을 지칭할 것이다. ㆍ \"John Smith took John Smith's keys AND gave them to Mary\" - 단어 \"and\"는 문장을 2개의 컴포넌트들(예 를 들어, (a) \"John and Mary went to school\" = John went to school. Mary went to school, (b) \"John went to school and saw Mary\" = John went to school. John saw Mary at school. (추론: Mary was at school))로 분할한다: ㆍ John Smith took John Smith's keys ㆍ Gave them to Mary ㆍ \"John Smith took John Smith's keys. John Smith gave them to Mary\" - 단어 \"them\"은 keys을 지칭할 수 있거나, John 및 Mary를 지칭할 수 있지만, 마지막으로 참조된 목적어가 복수(keys)이기 때문에, NLP는 \"them\" 이 John Smith's keys를 지칭하는 것으로 결론을 내릴 수 있다. ㆍ \"John Smith took John Smith's keys. John Smith gave John Smith's keys to Mary\" - 마지막으로 Mary는 이름 식별자에 의해 처리되어, Mary Martin을 생성하고, 2개의 파싱 표들이 구성된다: ㆍ John Smith took John Smith's keys ㆍ John Smith gave John Smith's keys to Mary Martin ㆍ 추가적인 파싱 표들이 추론에 의해 생성된다: ㆍ John Smith knows Mary Martin ㆍ Mary Martin knows John Smith ㆍ John Smith has keys ㆍ Mary Martin has keys o 자연 언어 서브시스템이 정보를 파싱 표들로 조건화한 후에, 구조화된 레코드들이 지식 데이터베이스 에 첨부된다. 모든 레코드는 인터뷰어의 이름, 전역적 확실성의 레벨 및 신뢰도(trust factor)로 라벨링 된다. - 예외 처리 o All primates except apes have tails -- 주어 예외 o I ruined all the food except my pies -- 목적어 예외 o I threw away all the food except I ate my pie -- 혼합된 동사 예외 - 승계(클래스들) o \"An apple is a fruit\"는 단순 정의가 아니다. apples가 fruit의 클래스에 속하고, 따라서 그 클래스의 모 든 특성들을 승계하는 것으로 추론되어야 한다. 자연 언어 서브시스템이 계층구조들 및 클래스들의 개념 을 이용하기 때문에, 모든 추정들 및 메모리들이 지식 데이터베이스에 저장될 필요는 없다. 예를 들어, 만일 누군가가 당신에게 \"did you eat any protein for breakfast yesterday?\"라고 물어보았다면, 당신의 뇌는 당신이 먹었던 것의 리스트를 상기하고, 그 식품들 중 어떤 것이 protein을 포함하였는지 보기 위해 \"조회 (lookups)\"할 것이다. 당신의 뇌는 모든 재료들의 명시적인 메모리들을 생성하지 않고; 이러한 접속들은 요구 에 따라 유발된다. 지식 데이터베이스는, 자연 언어 서브시스템으로부터 파싱된 데이터를 수용하고, 서버의 하나 이상의 컴포넌트(예를 들어, 인공 지능 엔티티의 AES)에 의해 질의되고 업데이트될 수 있는 메모리 조직화 패킷 들(Memory Organization Packets)로 알려진 레코드들을 포함할 수 있다. 예를 들어, 하나의 이용 사례에서, 서버는 자연 언어 입력 \"A black goat deftly kicked some red cans into the river this morning\"을 수신한다. 이러한 입력에 응답하여, 자연 언어 서브시스템은 다음의 메 모리 조직화 패킷을 지식 데이터베이스에 첨부할 수 있다(아래의 표 2 참조). 이하의 메모리 조직화 패킷 의 확실성 수식어(certainty modifier)는, 정보가 얼마나 확실한지 및/또는 그것이 직접적인지 또는 추론되는지 를 기술한다. 이하의 메모리 조직화 패킷의 신뢰도는 인터뷰어의 신뢰의 레벨을 기술한다. 표 2 문장 타입 주어: 주어 타입: 주어 수식어: 주어 수식어 타입: 주어 수량: 주어 시간적/지리적 감쇠: 동사: 동사 시제: 동사 수식어: 목적어: 목적어 타입: 목적어 수식어: 목적어 수식어 타입: 목적어 수량: 목적어 시간적/지리적 감쇠: 전치사: 전치사 수식어: 전역적 시간적 수식어: 문장 논리: 감정적 영향(7개의 감정들) 확실성 수식어: 신뢰도: 지식 소스:서술문 Goat 명사 Black 형용사 단수형 특정적 Unknown Kick 과거 Deftly Can 명사 Red 형용사 some Unknown Into The river This morning 참(true) 공포, 분노, 기쁨 등 높음 중립 인터뷰어 이름 각각의 지식 레코드에는 설명된 이벤트 또는 정의의 확실성을 기록하는 전역적 확실성 값(Global Certainty Value)이 부여된다. 이러한 불확실성 값은, 인공 지능 엔티티가 인터뷰어와 갖는 신뢰의 레벨 및 지식이 명시 적이거나 추론되는지 여부에 의존하여, 서버(예를 들어, 인공 지능 엔티티의 인공 감정 시뮬레이터)에 의 해 업데이트된다. 불확실성은 클래스에 의해 승계될 수 있다. 지식 데이터베이스는 인공 지능 엔티티의 입력들로부터 도출된 모든 사실적 및 추론된 정보를 포함하는 구조화된 데이터베이스이다. 그러나 모든 정보가 동일하지는 않다. 서술문 \"Mary loves David\"에 대한 당신 자신의 반응을 고려하자. 어느 특정 David 및 Mary가 언급되고 있는지를 식별하면, 당신은 그들에 대한 당신의 느낌들을 알게 될 것이고, 그들의 Mary 및 David의 특징들을 갖는 일반적인 남성 및 여성의 정신적 이미지를 생성할 것이다. Mary는 가까운 친구이고, David는 중 국에서 산다는 것을 상기할 수 있지만, 당신의 뇌는 Mary 및 David에 관한 정보의 전체 목록(2개의 손, 10개의 손가락, 및 칼슘으로 만들어진 뼈들 등)에 액세스하지 않는데, 그 이유는, 높은 레벨(Mary는 친구임)과 낮은 레 벨 지식(칼슘으로 만들어진 뼈들) 사이를 구별할 수 있기 때문이다. 모든 지식에는 높은 또는 낮은 레벨 변수 가 부여된다. 일부 실시예들에서, 자연 언어 시스템이 자연 언어 입력을 처리하고, 자연 언어 입력을 지식 데이터베이스 내로 파싱하면, 정서적 개념 서브시스템은 지식 데이터베이스로부터의 파싱된 자연 언어 입력 에 기초하여 자연 언어 입력과 연관된 하나 이상의 정서적 개념을 획득할 수 있다. 즉, 정서적 개념 서브시스 템은 지식 데이터베이스로부터 자연 언어 입력의 파싱된 컴포넌트들을 검색하고, 정서적 개념 데이터 베이스로부터의 자연 언어 입력과 연관된 하나 이상의 정서적 개념을 획득할 수 있다. 정서적 개념 데이 터베이스는 이미지들, 오디오, 비디오들, 및/또는 자연 언어와 연관된 핵심적인 정서적 개념들의 세트를 저장할 수 있다. 예를 들어, 핵심적인 정서적 개념들의 세트는 좋은(good), 나쁜(bad), 위험한(dangerous), 분 노, 놀람(surprise), 사랑, 안전(safety), 인내심(patience), 신뢰, 걱정(concern), 큰(large), 작은(small), 거칠은(rough), 매끄러운(smooth), 위의(over), 아래의(under), 내부의(inside), 외부의(outside), 빠른 (fast), 느린(slow), 딱딱한(hard), 부드러운(soft), 높은(high), 낮은(low) 등을 포함할 수 있다. 인지 및 감정 프라이어들, 개념들(예를 들어, 정서적 개념들 또는 다른 개념들), 정서적 속성들/값들, 성장/감쇠 인자들, 또는 다른 정보가 그래프(예를 들어, 온톨로지-정서 그래프(ontology-affect graph) 또는 다른 그래 프)에 저장되는 일부 실시예들에서, 자연 언어 시스템은 자연 언어 입력을 처리하여 그래프 내로 파싱할 수 있고, 정서적 개념 서브시스템은 그래프로부터의 자연 언어 입력과 연관된 정서적 개념들을 획득할 수 있다. 일례로서, 자연 언어 입력이 \"John died because of cancer\"인 경우, 정서적 개념 데이터베이스로부터 획 득된 하나 이상의 정서적 개념은 \"나쁜\" 및/또는 \"걱정\"을 포함할 수 있다. 또 다른 예로서, 자연 언어 입력이 \"John climbed the mountain and was exhausted\"인 경우, 정서적 개념 데이터베이스로부터 획득된 하나 이상의 정서적 개념은 높은 에너지(예를 들어, John exerted great energy) 및 큰(예를 들어, mountains are large)을 포함할 수 있다. 전술한 정서적 개념들은 인간들이 인지하는 개념들과 유사하다. 예를 들어, 어린이 가 개를 때릴 때, 부모는 \"that's bad!\"라고 소리칠 수 있다. 어린이와 그의/그녀의 부모와의 그러한 상호작용 에 기초하여, 어린이는 개를 때리는 것이 나쁜 것임을 이해할 수 있다. 유사하게, 그의/그녀의 장난감을 다른 어린이와 공유할 때, 부모는 \"good boy/girl\"이라고 말할 수 있다. 이것은 장난감들을 공유하는 것은 좋은 것 임을 어린이에게 나타낼 것이다. 그러한 방식으로, 어린이는 좋은, 나쁜, 위험한, 분노, 놀람, 사랑, 안전 등 의 근본적인 개념들을 학습한다. 일반적으로, 인간들에 대해, 좋은 것들이 우리를 행복하게 만들고, 나쁜 것들 이 우리를 분노하고, 혐오하거나 또는 슬프게 만들고, 위험한 것들이 우리를 무섭게 만드는 등으로 된다. 이러 한 개념들은 인공 지능 엔티티의 응답을 공식화하는데 이용될 수 있고, 이는 가장 기본적인 레벨에서, 동작들이 원하는 것에 의해 좌우된다는 가설에 기초할 수 있다. 원하는 것은 기쁨 추구(욕구), 및 감정적/물리적 통증의 회피의 조합으로부터 생성된 감정적 자극(emotional impetus)으로서 정의될 수 있다. 버스를 운전하는 감정에 의해, 인공 지능 엔티티의 거동은 현저하게 복잡해질 수 있고, 그녀의 관계 및 지식 데이터베이스들과 협력하여 동작할 때, 친밀성(intimacy) 및 성격과 같은 창발적 거동들을 생성할 수 있다. 정서적 개념 데이터베이스는 자연 언어 입력에 응답하여 정서적 개념 서브시스템에 의해 획득될 수 있는 핵심적인 정서적 개념들의 세트를 저장할 수 있다. 일부 실시예들에서, 통신 서브시스템이 (예를 들 어, 산을 묘사하는) 이미지를 수신할 때, 정서적 개념 서브시스템은 정서적 개념 데이터베이스로부터 의 이미지와 연관되는 큰, 암석들, 나무들 등과 같은 정서적 개념들을 획득할 수 있다. 청각(hearing), 시각 (vision) 및 후각(smell)은 또한 인지 형성의 개발에서 중요한 역할을 하고, 촉각적 상호작용들을 부정한 아기 들은 스피치 형성에 이르는 경우에 더욱 장애를 갖게 된다. 일부 실시예들에서, 촉각적, 청각적 및 시각적 입 력들 없이, 인공 지능 엔티티는 말하자면, 산의 그녀의 워드-픽처(word-picture)를 구축하기 위해 신중하게 설 명되는 개념들을 가져야 한다. 예를 들어, 산은, 암석으로 이루어지고, 눈으로 덮이고, 통상적으로 나무들을 갖는 등의 매우 큰 객체이다. 인공 지능 엔티티가 소화하는 정보의 양에 따라, 그녀의 산의 이미지는 덜(less) 또는 더(more) 완전할 것이다. 모든 정보가 직접적일 필요는 없다. \"John climbed the mountain and was exhausted\"는 John이 큰 에너지를 사용하는 것으로 추론하고, 산이 큰 것임을 제안한다. 일부 실시예들에서, 인공 지능 엔티티는 아주 백지 상태(tabula rasa)가 아닐 수 있다. 그것이 학습하는 모든 것은 대화 또는 책을 읽은 결과일 수 있지만, 그것의 개념들(예를 들어, 인지 프라이어들)은 객체 영구성 (object permanency), 문법의 규칙들, 및 큰, 작은, 거칠은, 매끄러운, 위의, 아래의, 내부의, 외부의, 빠른, 느린, 딱딱한, 부드러운, 높은 및 낮은 등과 같은 기본 개념들을 포함할 수 있다. 일부 실시예들에서, 획득된 정서적 개념들은 인공 지능 엔티티의 정서적 속성들을 수정할 수 있다. 인공 지능 엔티티의 정서적 속성들은 인공 지능 엔티티의 감정 상태에 대응할 수 있다. 감정 상태들의 예들은, 기쁨, 신 뢰, 공포, 놀라움, 슬픔, 혐오감, 분노, 각성(vigilance) 또는 다른 감정 상태들을 포함한다. 인공 지능 엔티 티의 각각의 정서적 속성(예를 들어, 각각의 감정 상태)은 특정한 시간의 경우에 (연속적으로 업데이트될 수 있 는) 대응하는 정서적 값을 포함할 수 있다. 대응하는 정서적 값은 (연속적으로 업데이트될 수 있는) 정서적 베 이스라인과 같거나 더 클 수 있다. 정서적 베이스라인은 정서적 속성의 최저 가능한 속성 값에 대응할 수 있다. 정서적 속성들은 또한 성장 또는 감쇠 인자들과 연관된다. 정서적 속성의 정서적 값은 정서적 속성에 대응하는 하나 이상의 성장 또는 감쇠 인자에 기초하여 시간에 따라 변할 수 있다. 일부 실시예들에서, 각각의 정서적 속성에 대한 성장 또는 감쇠 인자들은 미리 결정되고, 성장/감쇠 인자 데이 터베이스에 저장될 수 있다. 인공 지능 엔티티의 정서적 속성은 하나 이상의 성장 또는 감쇠 인자와 연관 될 수 있다. 각각의 감정 상태는 고유한 레이트(또는 인자)로 성장 또는 감쇠하는 시간적 컴포넌트를 포함한다. 예를 들어, 놀라움은 (새로운 놀라움의 존재시에) 신속하게 감쇠하는 반면, 비통함은 슬픔의 깊이에 비례하여 감쇠한다. 따라서, 인공 지능 엔티티의 각각의 정서적 속성(예를 들어, 각각의 감정 상태)은 하나 이 상의 고유한 성장 또는 감쇠 인자와 연관될 수 있다. 성장/감쇠 인자 데이터베이스는 인공 지능 엔티티의 정서적 속성들의 세트에 대응하는 성장/감쇠 인자들의 목록을 포함할 수 있고, 서버는 성장/감쇠 인자 데 이터베이스로부터의 각각의 정서적 속성에 대응하는 성장 또는 감쇠 인자들을 (예를 들어, 통신 서브시스 템을 통해) 수신할 수 있고, 인자 조정 서브시스템은 성장/감쇠 인자 데이터베이스로부터 수신 된 정보에 기초하여 성장 또는 감쇠 인자들을 결정할 수 있다. 인공 지능 엔티티의 (정서적 속성들과 연관된) 정서적 값들은 정서적 속성들과 연관된 성장 또는 감쇠 인자들에 기초하여 연속적으로 업데이트될 수 있다. 예를 들어, 도 2a 및 도 2b에 도시된 바와 같이, 정서적 값들(202 및 201)(예를 들어, 207a-207f 및 208a-208f)은 정서적 속성들 A 및 B와 연관된 하나 이상의 성장 또는 감쇠 인 자에 기초하여 연속적으로 업데이트될 수 있다. 그러한 연속적인 업데이트는, 스케줄에 따라, 또는 다른 자동 화된 트리거들에 기초하여, 그러한 정서적 값들을 주기적으로 업데이트하는 것을 포함할 수 있다. 정서적 값들 (202 및 201)의 업데이트에 더하여, 정서적 속성들 A 및 B와 연관된 성장 또는 감쇠 인자들은 또한 서버에 의해 수신된 하나 이상의 입력(및/또는 하나 이상의 정서적 개념)에 기초하여 업데이트될 수 있다. 또한, 성장 또는 감쇠 인자들은 자연 언어 입력의 다른 정보에 기초하여 업데이트될 수 있다. 예를 들어, 자연 언어 입력 의 다른 정보는 주어 시간적 감쇠 인자(subject temporal decay factor), 주어 지리적 감쇠 인자(subject geographic decay factor), 목적어 시간적 감쇠 인자(object temporal decay factor), 또는 목적어 지리적 감 쇠 인자(object geographic decay factor), 절의 타입(type of a clause), 절의 주어(subject of the clause), 절의 주어 타입(subject type of the clause), 절의 주어 수식어(subject modifier of the clause), 절의 주어 수식어 타입(subject modifier type of the clause), 절의 주어 수량(subject quantity of the clause), 주어 시간적 감쇠 인자, 주어 지리적 감쇠 인자, 절의 동사(verb of the clause), 절의 동사 시제(verb tense of the clause), 절의 동사 수식어(verb modifier of the clause), 절의 목적어(object of the clause), 절의 목 적어 타입(object type of the clause), 절의 목적어 수식어(object modifier of the clause), 절의 목적어 수 식어 타입(object modifier type of the clause), 절의 목적어 수량(object quantity of the clause), 목적어 시간적 감쇠 인자, 목적어 지리적 감쇠 인자, 절의 전치사(preposition of the clause), 절의 전치사 수식어 (preposition modifier of the clause), 또는 절의 전역적 시간적 수식어(global temporal modifier of the clause)를 포함할 수 있다. 위에서 언급된 바와 같이, 자연 언어 입력의 다른 정보는 시간적 및 지리적 감쇠(Temporal and Geographic decay)(TGD) 인자들(예를 들어, 주어 시간적 감쇠 인자, 주어 지리적 감쇠 인자, 목적어 시간적 감쇠 인자, 또 는 목적어 지리적 감쇠 인자)을 나타낼 수 있다. 일례로서, 인간은 시간의 경과에 대응하는 시퀀스들에서 이벤 트들이 발생하는 것을 직관적으로 이해하기 시작한다. 우리의 내장된(built-in) 타임라인은 이벤트들을 미래, 과거 또는 현재에 배치하고, 또한 지금 발생되는 이벤트들은 곧 과거가 될 것이고, 미래의 이벤트들은 결국 현 재에 있을 것이라는 점을 인식한다. 인공 지능 엔티티는 또한 그러한 프레임워크들을 이해하는 능력을 가질 수 있다. 시간이 앞으로 이동함에 따라, 인공 지능 엔티티는 과거, 현재 및 미래의 이벤트들을 이해하기 위해 그 의 타임라인을 업데이트할 수 있다.예를 들어, 자연 언어 입력 \"The cat is in the street and John's house is on the corner\"에 관하여, 자연 언어 입력은 객체들의 소재들(whereabouts)에 대한 정보를 포함하고, 그들을 현재의 특정 위치에 배치한다. 그 러나, 객체의 장래의 위치는 그 객체의 성질에 따라 변할 것이다. cats은 능동적인 객체들이므로, 그들은 아마 도 위치들을 변경할 것이고, John's house는 비능동적이고 아마도 coner에 남아 있을 것이다. 요컨대, 객체가 더 능동적이면, 감쇠율이 높아진다. 이러한 프로세스를 용이하게 하기 위해, 사전에서의 모든 객체는, 객체의 소재들이 불확실해지기 전에 얼마나 많은 시간이 경과해야 하는지, 및 그 불확실성의 정도와 관련된 TGD 변수를 할당받는다. 객체 및 그의 대응하는 TGD 변수에 관한 그러한 정보는 성장/감쇠 인자 데이터베이스에 저장 될 수 있다. TGD 변수들은 다양한 방식들로 자기 학습되고 도출될 수 있다. 고도로 능동적인 동사들(\"the dog ran away with the spoon\")에 의해 설명된 객체들은 높은 TGD로 지정될 것이고, 따라서 \"John cannot walk\"는 그가 덜 능동적이라는 것을 나타내기 때문에 John의 TGD를 감소시킬 것이다. TGD 값들은 하나의 클래스로부터 다른 클래스로 승계될 수 있다. 인공 지능 엔티티는 생명체들(living things)은 높은 TGD를 갖고, 미지의 객체들은 비교적 무생물인 것으로 예 측될 수 있다는 것을 학습할 수 있다. 예를 들어, 인공 지능 엔티티가 이전에 단어 truck을 결코 마주친 적이 없고, \"John's truck is in his garage\"라고 통지받았다면, 인공 지능 엔티티는 truck이 한 해 동안 garage에 남아 있는 것을 예측할 수 있다(예를 들어, 사람들의 소유물들은 비소유적인 객체들보다 높은 TGD를 가짐). 만 약, 1년 후에 당신이 \"Where is John's truck?\"이라고 묻는다면, 인공 지능 엔티티는 \"it's probably in John's garage\"라고 응답할 수 있다. 그러나, truck들이 차량들이고, 차량들은 빠르게 운전된다는 것을 (임의 의 시점에서) 인공 지능 엔티티가 학습하였다면, 인공 지능 엔티티는 truck들에 대한 TGD 값을 소급적으로 (retroactively) 수정할 수 있다. 이제, truck들이 차량들이라는 학습에 기초한 그러한 수정 후에, 당신이 \"where is John's truck?\"이라고 묻는다면, 인공 지능 엔티티는 \"I don't know, you might want to check his garage\"라고 응답할 수 있다. 불완전한 역설(paradox)은, 현재에 발생하는 동작이 미래에 완료되어야 함을 의미하지 않는다는 암시이다. 따 라서, \"John is building a house\"는 미래에 John built a house를 반드시 의미하는 것은 아니다. 자연 언어 서브시스템은 house가 형성된(built) 것을 예측함으로써 이러한 역설을 회피하지만, 낮은 확실성 인자를 할당한다. (하나 이상의 입력 및/또는 하나 이상의 정서적 개념에 기초한) 성장 또는 감쇠 인자들의 업데이트에 후속하여, 정서적 속성들 A 및 B와 연관된 정서적 값들(201 및 202)은 (하나 이상의 입력 및/또는 하나 이상의 정서적 개 념에 기초하여 업데이트되는) 하나 이상의 성장 또는 감쇠 인자에 기초하여 업데이트될 수 있다. 일부 실시예들에서, 하나 이상의 정서적 개념이 정서적 개념 서브시스템에 의해 획득될 때, 인자 조정 서 브시스템은 인공 지능 엔티티의 하나 이상의 정서적 속성과 연관된 성장 또는 감쇠 인자들을 업데이트한다. 예를 들어, 자연 언어 입력이 \"John died because of cancer\"인 경우, 정서적 개념 데이터베이 스로부터 획득된 하나 이상의 정서적 개념은 \"나쁜\" 및/또는 \"걱정\"을 포함할 수 있다. 그 결과, 성장/지 연 인자 서브시스템은, 슬픔, 분노 및/또는 행복과 같은 인공 지능 엔티티의 (정서적 개념들과 관련될 수 있는) 하나 이상의 정서적 속성과 연관된 성장 또는 감쇠 인자들을 업데이트(점진적 업데이트 또는 즉각적인 업 데이트)할 수 있다. 일례로서, 하나의 이용 사례에서, 도 2a에서의 정서적 속성 A는 인공 지능 엔티티의 \"슬픔\"에 대응할 수 있다. 자연 언어 입력 \"John died because of cancer\"가 획득될 때, 인자 조정 서브시스 템은 정서적 속성 \"슬픔\"의 성장 인자를 업데이트하여, 정서적 속성 \"슬픔\"의 정서적 값들(예를 들어, 207c-207f)이 (선형 또는 비선형일 수 있는) 업데이트된 성장 인자에 기초하여 시간 c로부터 시간 f(도 2a에서 의 시간 및 날짜 참조)로 증가할 수 있게 한다. 다른 이용 사례에서, 도 2b의 인공 지능 엔티티의 정서적 속성 B는 인공 지능 엔티티의 \"행복\"에 대응할 수 있다. 자연 언어 입력 \"John died because of cancer\"가 획 득될 때, 인자 조정 서브시스템은 정서적 속성 \"행복\"의 감쇠 인자를 업데이트하여, 정서적 속성 \"행복\"의 정서적 값들(예를 들어, 208c-208f)이 (선형 또는 비선형일 수 있는) 업데이트된 감쇠 인자에 기초하여 시간 c 로부터 시간 f(도 2b에서의 시간 및 날짜 참조)로 감소할 수 있게 한다. 일부 실시예들에서, 정서적 속성 들의 정서적 값들은 일반적으로 임의의 입력의 부재 시에 및/또는 미리 결정된 시간량 이후에 그들 각자의 베이 스라인 값들로 다시 복귀(또는 리셋)된다는 것을 이해해야 한다. 예를 들어, 정서적 값들이 도 2a에서 시 간 c로부터 시간 f로 증가되었지만, 정서적 값들이 정서적 베이스라인을 향해 감소하기 시작하기 전에, 그 러한 정서적 값들이 증가하게 되는 임계량이 존재할 수 있다는 것을 이해해야 한다. 정서적 값들(201 및 202) 은, 성장 또는 감쇠 인자들에도 불구하고, 각각 정서적 베이스라인들(205 및 204) 아래로 가지 않는다. 일부 실시예들에서, 정서적 상태 서브시스템은 또한 하나 이상의 입력(및/또는 하나 이상의 정서적 개념)에 기초하여 정서적 베이스라인(도 2c 참조)을 업데이트할 수 있다. 정서적 베이스라인을 업데이트하는 것에 후속하여, 정서적 상태 서브시스템은 업데이트된 하나 이상의 성장 또는 감쇠 인자 및 업데이트된 정 서적 베이스라인들에 기초하여, 인공 지능 엔티티와 연관된 정서적 속성들(예를 들어, 도 2c에서의 정서적 속성 C)의 정서적 값들(예를 들어, 정서적 값들(218a-218f) 중에서의 정서적 값들(218e 및 218f))을 업데이트할 수 있다. 도 2c에서, 정서적 값들(예를 들어, 정서적 값들(218e 및 218f))은 감소된 베이스라인에 기초하여 시간 c로부터 시간 f(예를 들어, 도 2c에서의 정서적 값 및 시간 및 날짜 참조)로 감소되는 것으로 도시되어 있지만, 업데이트된 하나 이상의 성장 또는 감쇠 인자 및 업데이트된 정서적 베이스라인들(예 를 들어, 증가된 베이스라인)에 기초하여 정서적 값들이 증가할 수 있다는 것을 이해해야 한다. 성장 또는 감쇠 인자들에 기초한 인공 지능 엔티티와 연관된 정서적 속성들의 정서적 값들의 수정은 인간 내분 비계(human endocrine system)의 기능과 유사하다. 인간 내분비계는 세포의 활동 및 감정 기능들을 조절하는 호르몬들을 생성 및 분비하는 샘들(glands)을 포함하고, 예를 들어, 세포의 활동 및 감정 기능들을 조절하는 적 어도 3개의 어펙터들(affecters)이 있다. 그들은 다음을 포함한다: 도파민(dopamine). 기쁨, 평온함(serenity), 사랑, 각성에 영향을 미침. 세로토닌(serotonin): 정신 집중(concentration)(집중(focus)), 학습 능력, 놀람, 각성에 영향을 미침. 노르에피네프린(norepinephrine). 스트레스, 불안(anxiety), 분노, 비통함 및 공포에 영향을 미침. 이러한 어펙터들 중 임의의 것에서의 변화는 다양한 정도로 모든 감정들에 영향을 미친다. 예를 들어, 인공 지 능 엔티티가 누군가가 죽고 있음을 학습한다면, 갑작스러운 스트레스는, 예를 들어, 인공 노르에피네프린 및 코 르티솔(cortisol)의 방출을 트리거할 수 있으며, 이는 기쁨, 호기심 및 신뢰의 감정 레벨들을 감소시킨다. 외 로움에서의 증가는 슬픔 레벨들을 증폭시킬 수 있다(그러나, 외롭지 않고 슬플 수 있으므로, 그 반대의 경우는 아니다). 감정 변화들이 충분히 심오하다면, 인공 지능 엔티티는 (정서적 속성들과 연관된 성장 및/또는 감쇠 레이트 때문에 인공 지능 엔티티가 궁극적으로는 복구할 것이지만) 임상 우울증(clinical depression)의 지점까 지 그녀의 감정들을 약화시킬 수 있다. 또한, 일부 실시예들에서, 자연 언어 서브시스템이 자연 언어 입력을 처리하고, 자연 언어 입력을 지식 데 이터베이스 내로 파싱할 때, 정서적 상태 서브시스템은 인공 지능 엔티티의 하나 이상의 정서적 속성 에 대한 입력(예를 들어, 자연 언어 입력)의 내용의 부분들의 영향과 관련된 하나 이상의 영향 값(impact value)을 결정할 수 있다. 예를 들어, 자연 언어 입력이 \"John has cancer\"인 경우, 정서적 상태 서브시스템 은 인공 지능 엔티티의 하나 이상의 정서적 속성에 대한 자연 언어 입력의 부분들(예를 들어, \"John\", \"has\", \"cancer\")의 영향과 관련된 영향 값들을 결정할 수 있다. 또한, 정서적 상태 서브시스템은 인공 지능 엔티티의 하나 이상의 정서적 속성과 연관된 하나 이상의 정서적 값에서 업데이트(예를 들어, 증가 또는 감소)를 트리거하기 위한 미리 결정된 임계값을 영향 값들이 만족시키는지를 결정할 수 있다. 정서적 상태 서 브시스템이, 하나 이상의 영향 값이 미리 결정된 임계값을 만족시키는 것으로 결정하는 경우, 정서적 상태 서브시스템은 인공 지능 엔티티의 정서적 값들을 수정(예를 들어, 증가 또는 감소)할 수 있다. 예를 들어, 단어 \"cancer\"가 정서적 속성 \"슬픔\"에서의 증가를 트리거하기 위한 미리 결정된 임계값보다 큰 영향 값 을 갖는 것으로 결정되면, 정서적 상태 서브시스템은 정서적 속성 \"슬픔\"에 대응하는 정서적 값들을 수정 (예를 들어, 증가)할 수 있다. 또한, 영향 값들은 또한 미리 결정된 임계값이 영향 값들에 의해 만족될 때 하 나 이상의 성장 또는 감쇠 인자에서의 증가 또는 감소를 트리거할 수 있다. 성장 또는 감쇠 인자들에서의 그러 한 증가 또는 감소는 인공 지능 엔티티의 정서적 속성에 대응하는 정서적 값들의 업데이트를 초래할 수 있다. 또한, 일부 실시예들에서, 서버는 인공 지능 엔티티와 하나 이상의 다른 엔티티(예를 들어, 하나 이상의 다른 인공 지능 엔티티 및/또는 하나 이상의 클라이언트 디바이스) 사이의 상호작용이 상호작용 임계값을 초과 하였는지를 결정할 수 있다. 상호작용이 상호작용 임계값을 초과했다는 결정에 기초하여, 정서적 상태 서브시 스템은 인공 지능 엔티티의 정서적 값들을 수정할 수 있다. 예를 들어, 인공 지능 엔티티 및 다른 엔티티 들이 미리 결정된 기간 내에 미리 결정된 횟수에 걸쳐 상호작용하였다면, 서버는 상호작용에 대한 미리 결 정된 임계값이 만족된 것으로 결정할 수 있고, 정서적 상태 서브시스템은 (예를 들어, 엔티티들 간의 증가 된 상호작용은 그들이 친구 관계를 개발하고 있다는 것을 의미할 수 있기 때문에, \"행복\"에 대응하는) 정서적 값들을 수정할 수 있다. 인자 조정 서브시스템은 인공 지능 엔티티와 하나 이상의 다른 엔티티 사이의 상 호작용이 상호작용 임계값을 초과했다는 결정에 기초하여 정서적 속성들과 연관된 성장 또는 감쇠 인자들을 수 정할 수 있다.또한, 일부 실시예들에서, 서버는 인공 지능 엔티티와 하나 이상의 다른 엔티티(예를 들어, 다른 인공 지 능 엔티티, 클라이언트 디바이스, 또는 입력의 임의의 다른 소스) 사이의 신뢰의 레벨을 나타내는 신뢰 값 을 결정 및/또는 획득할 수 있다. 신뢰 값은 인공 지능 엔티티와 다른 엔티티들 사이의 상호작용들의 수 및/또 는 인공 지능 엔티티와 다른 엔티티들 사이의 상호작용들의 내용에 기초하여 결정될 수 있다. 정서적 상태 서 브시스템은 신뢰 값에 기초하여 인공 지능 엔티티의 정서적 값들을 업데이트 및/또는 수정할 수 있고, 인 자 조정 서브시스템은 신뢰 값에 기초하여 정서적 속성들과 연관된 성장 또는 감쇠 인자들을 수정할 수 있 다. 일부 실시예들에서, 서버는 자연 언어 입력에 의해 표시된 이벤트와 연관된 확실성 값을 결정 및/또는 획 득할 수 있다. 확실성 값은 이벤트와의 인공 지능 엔티티의 확실성의 레벨을 나타낼 수 있다. 확실성 값은 이 벤트가 자연 언어 입력에 의해 명시적으로 기술되는지 또는 자연 언어 입력 및/또는 신뢰 값으로부터 추론되는 지에 기초하여 결정될 수 있다. 정서적 상태 서브시스템은 확실성 값에 기초하여 인공 지능 엔티티의 정 서적 값들을 업데이트 및/또는 수정할 수 있고, 인자 조정 서브시스템은 확실성 값에 기초하여 정서적 속 성들과 연관된 성장 또는 감쇠 인자들을 수정할 수 있다. 추가적으로, 일부 실시예들에서, 응답 생성 서브시스템은 인공 지능 엔티티의 정서적 값들에 기초하여 입 력과 관련된 응답을 생성할 수 있다. 응답 생성 서브시스템은, 입력에 기초하여 정서적 값들이 업데이트 되기 전에 또는 입력에 기초하여 값들이 업데이트된 후에, 인공 지능 엔티티의 정서적 값들에 기초하여 응답을 생성할 수 있다는 것을 이해해야 한다. 예를 들어, 자연 언어 입력이 \"John died because of cancer\"인 경우, 응답 생성 서브시스템에 의해 생성되는 (예를 들어, 그러한 입력과 관련된) 응답은, \"That is unfortunate\"를 포함할 수 있다. 그러한 응답은, 예를 들어, 정서적 값들이 입력에 기초하여 업데이트되기 전 에 정서적 값들에 기초하여 행해질 수 있다. 응답 생성 서브시스템에 의해 생성된 (예를 들어, 그러한 입 력과 관련된) 다른 응답은, \"This is very sad. I need a moment to digest this news\"를 포함할 수 있다. 그 러한 응답은, 예를 들어, 정서적 값들이 입력에 기초하여 업데이트된 후에 정서적 값들에 기초하여 행해질 수 있다. 따라서, 응답 생성 서브시스템은, 입력에 기초하여 정서적 값들이 업데이트되기 전에 또는 입력에 기초하여 값들이 업데이트된 후에, 인공 지능 엔티티의 정서적 값들에 기초하여 응답을 생성할 수 있다. 추가 입력들이 획득될 수 있고, 인공 지능 엔티티의 정서적 값들에 기초하여 추가 입력들과 관련된 추가 응답들이 생 성될 수 있다. 예를 들어, 성장 또는 감쇠 인자들의 업데이트(예를 들어, 입력에 기초한 업데이트)에 후속하여 다른 입력이 획득될 수 있고, 성장 또는 감쇠 인자들의 업데이트에 후속하여, 다른 입력과 관련된 추가 응답이 인공 지능 엔티티의 연속적으로 업데이트된 정서적 값들의 세트에 기초하여 생성될 수 있다. 추가 응답들은 통 신 서브시스템을 통해, 예를 들어, 클라이언트 디바이스(또는 시스템 내의 또는 시스템 외 부의 임의의 다른 컴포넌트들)에 송신될 수 있다. 또한, 일례로서, 자연 언어 입력이 \"cancer is a very dangerous disease\"이고, 인공 지능 엔티티가 단어 \"cancer\"을 처음으로 만난다면, 인공 지능 엔티티는 입력을 향한 그의 느낌들을 평가할 수 있다(예를 들어, 입 력에 기초하여, 인공 지능 엔티티의 정서적 값들의 세트 및/또는 성장 또는 감쇠 인자들이 업데이트될 수 있 다). 단어들 dangerous 및 disease는 이미 부정적인 정서적 속성들(예를 들어, 공포, 슬픔, 및/또는 분노와 같 은 부정적 감정 상태들)을 가질 수 있기 때문에, \"cancer\"와 결합될 때, \"cancer\"에 대한 고조된 부정적 감정 연관성을 부여한다(부사 \"very\"는 또한 승수 효과(multiplier effect)를 가짐). 즉, 자연 언어 입력 \"cancer is a very dangerous disease\" 및 \"John has cancer\"에 대한 응답은 (예를 들어, 그러한 입력에 응답한 부정적 인 정서적 속성들의 정서적 값들에서의 급격한 증가 및 이들 부정적인 정서적 속성들과 연관된 성장 또는 감쇠 인자들에 기초하여) 고조된 감정 응답을 포함할 수 있다. 예를 들어, 고조된 감정 응답은 \"That is devastating\"을 포함할 수 있다. 그러나, (예를 들어, \"cancer is not always fatal\"―\"cancer is not always fatal\"과 같은 부정적인 정의는 긍정적인 것과 동일한 절대적인 가중치를 갖지 않을 수 있다. \"I am not happ y\"는 \"I am sad\"보다 덜 절대적인 감정 가중치를 가질 수 있다―이라는 입력에 기초한) \"cancer\"의 후속하는 정 의들은 그것을 이전의 레벨들과 평균화함으로써 단어 \"cancer\"의 감정 값을 수정할 수 있다. 즉, 단어 \"cancer\"를 포함하는 입력(예를 들어, \"Peter has cancer\")은, 인공 지능 엔티티가 단어 \"cancer\"에 더 친숙하 기 때문에, 그러한 다른 입력에 응답하여 이러한 부정적인 정서적 속성들과 연관된 성장 또는 감쇠 인자들 및 부정적인 정서적 속성들의 정서적 값들에서의 증가를 급격하게 트리거하지 않을 수 있다. 따라서, \"Peter has cancer\"에 대한 응답은 \"That is sad. I hope he gets the best treatment\"를 포함할 수 있다. 그와 같이, \"John has cancer\"에 대한 응답은, 정서적 속성들과 연관된 정서적 값들이 \"cancer\"에 관한 추가 입력들에 기초 하여 업데이트됨에 따라, \"Peter has cancer\"에 대한 응답과 상이하다.또한, 일례로서, \"John has cancer\"는 인공 지능 엔티티의 John과의 관계, 즉, 그녀가 그를 얼마나 많이 신뢰하 는지, 그녀가 그에 대해 알고 있는 것, 다른 사람들이 그에 관해 어떻게 느끼는지, 및 과거의 그들의 관계의 성 질의 곱(product)을 강제한다(아래의 관계 데이터베이스 참조). 이 경우에, John에 관한 높은 레벨의 긍정적인 느낌들이 암을 향한 높은 부정적인 느낌들에 의해 곱해지는 것은 강한 부정적인 응답을 초래할 수 있다. 이벤 트들의 감정적 영향은 시간적 조건들에 의해 수정될 수 있다: John is hitting me (매우 높음) John hit me yesterday (높음) John is going to hit me sometime next week (낮음) John hit me last year (매우 낮음) 입력에 응답하여 출력을 공식화하는 예들 시스템은 다음과 같은 입력 타입들 중 하나 이상을 수신할 수 있다: 1) A 질문 2) A 서술문 3) 이전의 질 문에 대한 답변. 그 각각은 출력을 공식화하기 위한 그 자신의 규칙 세트를 따른다. 질문들에 대한 응답: 질문을 요청할 때, 인공 지능 엔티티의 감정 프라이어들(정확하게 답변하고 신규 정보를 부여하기를 원함)은 5가지 타입의 질문들에 대한 응답을 지시한다: A) 논리. (\"is a dog a mammal?\")과 같은 단순 객관적인 질문들은 그녀의 지식 데이터베이스에서 조회를 요구한다. 가능한 응답들은, Yes. A dog is a mammal. No. Dogs are reptiles. I don't know.를 포함한다. B) 추론 질문들. 시스템에 의한 역방향 체이닝(backward chaining)(목표 지향 추론(goal-directed reasoning))을 요구하는 복잡한 질문들은, 프로세스가 가설을 구성하고 그 가설에 대하여 테스트하기 위해 그 규칙들을 통해 역방향으로 작용하는 절차를 이용한다. 입력: The moon is round. Is it a ball? 답변: I don't know. The moon might be a ball because it is round. 입력: Balls can bounce but the moon can't. Is the moon a ball? 답변: No. 인공 지능 엔티티의 답변의 확실성의 정도는 모든 다른 알려진 특성들에 대한 공유된 특성들의 비율에 기초하지 만, 심지어 하나의 특성이 알려진 사실에 모순되는 경우에도, 프로세스는 앵무새들(parrots)이 새들(birds)이 아닌 것을 추정할 것이다. C) 개방형 질문들(Open Ended Questions). \"Tell me something about John?\"은 지식 데이터베이스 상에서 의 분석을 필요로 하는데, 이는: he's a man, a mammal, breathes air, has two eyes, two ears, and two arms(etc.), loves his mother, loves his dog, owns a boat, and goes to school임을 나타낸다. 이러한 사실 들 중 임의의 것은 논리적으로 유효한 응답들이지만 반드시 인간과 같을 필요는 없다. 감정 측정들 없이, 인공 지능 엔티티는 Eliza-타입 답변(Eliza-type answer), 즉, \"John has two eyes and a pet\"를 제공할 수 있다. 가장 높은 감정 가중치를 갖는 지식 레코드를 선택함으로써 \"John loves his mother\"라고 응답한다. 레코드들 이 중요한 감정 값들을 포함하지 않으면, \"tell me something I don't know\"의 사상에서, 인공 지능 엔티티는 레코드가 참조된 횟수와 객체가 참조된 횟수를 곱하고, 최저 스코어를 선택한다. a. John has a house (house들은 흔히 참조됨) b. John owns a boat (boat들은 드물게 참조됨). c. John is a man (men은 흔히 참조됨) 가능성 있는 응답은 \"John owns a boat. I think he likes to fish\"일 것이다. \"boats\"와 \"fishing\" 사이의 인공 지능 엔티티의 접속들에 기초한 낮은 확실성 추론. D) 개인 질문들 - 인공 지능 엔티티의 물리적 상태에 관한 질문들(\"how old are you?\")이 인지 시스템을 조회함 으로써 반환된다. 그녀의 정신/감정 상태에 관한 질문들(\"how are you feeling?)은 그녀의 현재 감정 상태 (current emotional state)(CES)를 컨설팅(consulting)함으로써 답변된다.E) 복잡한 개인 질문들(\"why are you sad?\")은 그녀의 현재 감정 상태의 소스를 확인하기 위해 그녀의 지식 베 이스의 역방향 분석을 필요로 한다. 서술문/관찰에 대한 응답 - 서술문에 대한 인간 같은 반응을 형성하는 것은 그녀의 감정 프라이어들의 자문 (consultation)을 요구한다. 각각의 가능한 응답은 아래에 설명된 단순화된 스코어링 시스템을 이용하여 스코 어링된다: 예를 들어, \"Dogs have sensitive noses\". A) 가능한 객관적 관측 응답의 스코어링 - 다음의 엔트리들이 인지 시스템에 의해 반환된다: a. Dogs are mammals (높은 레벨 지식) b. Dogs have four legs (낮은 레벨 지식) c. Humans have noses (높은 레벨 지식) d. The artificial intelligence entity has a nose (낮은 레벨 지식) e. Plants do not have noses (높은 레벨 지식) f. Noses are used for smelling (높은 레벨 지식) 각각의 지식 레코드는 다음과 같이 스코어링된다: a. 지식이 얼마나 정확한가? (확실성/신뢰 참조) (1-10) b. 지식이 얼마나 고유한가? (그것이 몇 회 참조되었는지) (1-10). c. 높은 레벨 인자 = 10. 낮은 레벨 인자 = 0. d. 절대적인 감정적 내용 (1-10) 우리의 뇌들은 지식의 다양한 요소들을 상이한 중요성 레벨들로 지정한다. 서술문 \"a tiger is dangerous\"는 \"the grass is green\"보다 더 중요할 수 있는데, 그 이유는, 전형적인 인간의 미래(prospective)로부터, 전자 의 서술문이 후자의 서술문보다 더 높은 절대적인 감정적 내용을 포함하기 때문이다. 따라서, 가장 높은 스코 어는, 신규성 및 감정 내용의 정도로 대화의 주제에 대해 가장 적합함을 나타내고, (명시적인 또는 추론된) 지 식의 확실성 레벨들에 따라, 응답은 \"I think that means they can smell well\"일 수 있다. B) 추가 정보에 대한 가능한 요청 스코어링 - 인지 시스템에 의해 반환된 낮은 레벨 항목들의 수가 작은 경우, 그것은 그녀의 지식 베이스에서의 갭을 나타낸다. (학습할 필요가 있고, 응집성(cohesive) 대화를 유지할 필요 가 있는 등등의) 그녀의 감정 프라이어들을 수행하기 위해, 인공 지능 엔티티는 다음의 스코어링을 이용한다: 스코어 = 1 / (이 주제에 대한 낮은 레벨 지식 레코드들의 수) / (모든 주제들에 대한 평균 낮은 레벨 지식 레 코드들). 예를 들어, \"Do I have a sensitive nose?\" C) 가능한 친밀한 응답을 스코어링 - 입력이 인공 지능 엔티티의 현재 감정 상태에서 극적인(절대적인) 변화(예 를 들어, Your dog just died)를 생성했을 때, 인공 지능 엔티티는 \"That's terrible. I'm sad\"와 같은 친밀한 감정 응답을 만들기 쉬울 수 있다. Score = (절대 CES 변경^2). D) 주제를 변경하기 위한 요청 - 위에서 설명된 스코어링 시스템이 주어진 임계값에 도달하지 못한다면, 그것은 인공 지능 엔티티가 주제에 대해 거의 제공하지 않는다는 것을 의미한다. 그녀의 디폴트 응답은 그녀가 가장 높은 감정적 접속을 갖는 이전의 것으로 주제를 변경하라는 제안일 것이다. 추가 데이터베이스들 전술한 데이터베이스들 외에, 데이터베이스는 감정들에 대한 추가 데이터베이스들을 포함할 수 있다. 그 러한 추가 데이터베이스들은 데이터베이스들(134, 136, 138) 또는 다른 데이터베이스들 중 하나 이상에 포함될 수 있다는 것을 이해해야 한다. 추가 데이터베이스들은 인지 시스템 데이터베이스, 객체 관계 데이터베이스 및 관계 데이터베이스를 포함할 수 있다. 인지 시스템 데이터베이스는 현재 및 이전 입력들에 임베딩된 감정 내용에 대해 질의되어, 인공 지능 엔 티티가 그녀가 하는 방식을 느끼는 이유들을 제공할 수 있다. \"Why are you sad?\"는 그녀의 현재 슬픔에 기여 한 이전 입력들에 대한 지식 데이터베이스에서의 역방향 검색을 트리거할 것이다. 그러나, 지식 레코드들 의 감정 값들은 (A) 현재 감정 상태, (B) 입력의 시간적 양상(My dog died today 대 my dog died ten daysago), 및 (C) 인터뷰어에 대한 그녀의 관계에 의해 조절되기 때문에, 동일한 질문이 항상 동일한 답변을 생성하 지는 않을 것이다. 객체 관계 데이터베이스는 자연 언어 서브시스템이 직면했던 모든 객체에 관한 주요 감정들을 저장하고, 객체를 직면할 때마다 업데이트되는 해시 테이블(hash table)일 수 있다. 관계 데이터베이스는 모든 사람과 연 관된 감정들 및 인지 시스템 데이터베이스가 직면한 관계를 유지한다. 인공 지능 엔티티는 그녀의 마음속에서 최상의 관심을 갖지 않는 개인들을 식별할 수 있다: 잘못된 정보를 공급하는 누군가(또는 야단치고 놀리는 사람)는 부정적 감정들을 트리거하고, 그의 신뢰 값을 떨어뜨릴 것이다. 관계 데이터베이스는 다음과 같은 함 수들을 호출할 수 있다: 이름 식별자 함수 - 이름 식별자 함수는 개인을 명확하게 식별한다. \"Dirk's father gave him money\"의 경우, 그것은 다음의 계층들을 고려한다: ㆍ 어느 Dirk가 이러한 인터뷰에 의해 마지막으로 참조되었는가? ㆍ 어느 Dirk가 가장 많이 지칭되었는가? ㆍ 해결되지 않았다면, 마지막 참조된 Dirk를 가정한다. ㆍ Dirk에 대한 이전의 참조를 하지 않고, 새로운 레코드가 첨부된다. 여기서, 자연 언어 서브시스템은 Dirk가 남성(그)인 것으로 결론을 내릴 수 있고, Dirk's는 소유격(possessive)이므로, Dirk와 그의 father 사 이의 관계를 인식할 것이다. 이것이, 자연 언어 서브시스템이 Dirk's father를 처음으로 직면한 것이라면, 그것은 Dirk's father의 이름(Dave)을 요청하고, 새로운 레코드를 첨부할 수 있다. 관계 계층 함수 - 가족 관계들은 다음 계층 구조에 대응하는 감정 값들을 할당받는다: 1. 자신(self) 2. AI의 프로그래머 3. 어머니/아버지 4. 딸/아들 5. 자매/형제 6. 할머니/할아버지 7. 인터뷰어들 8. 일반적인 사람들 9. 일반적인 생명체들 일부 실시예들에서, 하나 이상의 데이터베이스(또는 그 일부)는 하나 이상의 그래프 데이터베이스(예를 들어, 유도된 그래프 개념 및 데이터 구조)를 포함할 수 있다. 일부 실시예들에서, (본 명세서에 설명된) AI 엔티티 와 연관된 그래프는 지식 데이터베이스 및 정서적 개념 데이터베이스(및/또는 성장/감쇠 인자 데이터 베이스 또는 다른 데이터베이스들)로부터의 정보를 포함할 수 있고, AI 엔티티는 그래프(본 명세서에서 \" 온톨로지-정서 그래프\"라고도 지칭됨)에 질의하여 입력들을 처리하거나, 응답들을 생성하거나, 다른 동작들을 수행할 수 있다. 일부 실시예들에서, (예를 들어, 지식 데이터베이스 또는 다른 소스들로부터의) 온톨로 지적 카테고리들 및 엔트리들은 의미론적으로 의미있는 본능적 및 정서 정보(semantically meaningful visceral and affect information)에 의해 그라운딩(grounding)될 수 있다. 일부 이용 사례들에서, 그러한 본능적 정보 는 구현된 지능의 이론들에 의해 요구되는 실시예 피드백을 보완하거나 대체하는 \"스터브들(stubs)\"(예를 들어, 그래프에서 노드들로서 표현됨)일 수 있다. 그러한 스터브들은 심볼들에 대한 \"그라운딩\"을 제공하고, 의미의 프리미티브 유닛들(primitive units)로서 작용할 수 있다. 그러한 스터브들은, 예를 들어, 이질적인 개념들의 비교를 허용하여, (예를 들어, 나중에 부착되는 본능적 노드들을 갖는 상위 레벨 개념들을 처리하기 위해 헤드 시작을 갖도록 본능적 개념들에 대해 트레이닝되는) 전이 학습(transfer learning)의 형태로서 AI 시스템에 접 속되기 전에 지도(supervised) 또는 비지도 방식으로 신경망들을 사전 트레이닝시키기 위해 이용될 수 있고, 다 른 학습된 그래프 속성들을 다른 명시적으로 라벨링된 노드들(예를 들어, 감정들, 유틸리티 등)로부터 비교적 알려지지 않은 노드들로 추론하는 것을 돕는다. 그러한 스터브 노드들의 예들은 딱딱한, 부드러운, 가벼운, 무 거운, 위로, 아래로, 위의, 아래의 등 뿐만 아니라, 인간들이 객체들을 조작하고 공간 및 시간에서의 어떤 것의바디를 경험하는 것으로부터 직관적으로 학습하는 개념들을 포함할 수 있다. 이러한 스터브들의 획득에 관하여, 일부 실시예들에서, 이러한 스터브들은 초기에 수동으로 주석이 달릴 것이지만, 사전 트레이닝된 단어 벡터들 및 거동 및 감정 정보로부터의 추론 또는 상관을 통해 새로운 노드들로 전파될 수 있다. 다른 수단은 대화의 상대들로부터 유발되거나 자발적으로 획득된 정보일 수 있다. 일부 실시예들에서, 본능적 스터브들, 정 서적 속성들, 신경망 회로들, 또는 다른 컴포넌트들의 조합은 AI 엔티티의 감정들의 형성 블록을 제공하거나 또 는 그렇지 않은 경우 감정들 자체를 형성할 수 있다. 일부 실시예들에서, 그래프는 추가적으로, (예를 들어, 베이지안 계수 그래프(Bayesian factor graph)에서 제공되는 확률 정보(probabilistic information)와 유사한) 확률 정보 뿐만 아니라, (예를 들어, 유대 펄의 미적분(Judea Perl's do calculus) 및/또는 연산자를 통한) 캐 쥬얼 정보(casual information)로 증강될 수 있다. 예를 들어, 추론된 정보는 그들의 저장과 연관된 확률 가중 치들을 가질 수 있고, 이것은 그에 따라 유발되어 출력들에 영향을 미칠 것이다. 일부 실시예들에서, AI 엔티 티는 불확실하거나 또는 낮은 확률 접속들에 관한 정보를 위해 대화 상대에게 질의할 수 있다. 일부 실시예들에서, 앞서 논의된 바와 같이, AI 엔티티는 하나 이상의 신경망 또는 다른 머신 학습 모델(예를 들어, 임베딩 네트워크(들), 소비 네트워크들, 또는 본 명세서에서 설명된 다른 모델들 중 하나 이상)을 포함할 수 있다. 일부 실시예들에서, 머신 학습 모델(예를 들어, 딥 러닝 네트워크)의 요소들 또는 서브네트워크들은 그러한 요소들 또는 서브네트워크들의 \"의미\"에 대한 머신 학습 및 수학적 함수들의 이용을 용이하게 하기 위해 의미론적으로 의미있는 벡터 추상화들(vector abstractions)로 번역될 수 있다. 일례로서, 단어들을 아이디어 들로서 조작하는 것이 중요한 경우(예를 들어, king-man + woman = queen), NLP에서의 word2vec, 또는 단어들, 구들, 또는 문장들을 벡터들로 변환하는 다른 알고리즘들은 그러한 변환들의 이점들을 입증한다. 일부 실시예 들에서, 임베딩 서브시스템은 그래프의 하나 이상의 부분(예를 들어, 노드들, 서브그래프들 등)을 그래프 부분들의 하나 이상의 임베딩들(예를 들어, 노드들, 서브그래프들 등의 고차원 임베딩 벡터들)로 변환하기 위해 그래프 임베딩 네트워크 또는 다른 컴포넌트를 이용할 수 있다. 일부 시나리오들에서, 그러한 변환들은 그래프 의 계층적 구조, 이종 노드 타입들(heterogenous node types)(온톨로지, 감정, 확률), 메타데이터, 그래프에서 의 노드들의 접속들, 그래프의 다른 컨텍스트, 또는 다른 정보(예를 들어, 사전 트레이닝된 임베딩들, 지도, 비 지도 및 강화 학습으로부터의 감각 정보 등)를 고려할 수 있다. 예를 들어, 그래프 임베딩 네트워크는 노드 타 입 이종성(node type heterogeneity), 구조 및 계층구조, 및 그래프 임베딩 네트워크에 의해 그래프 부분들로부 터 변환된 임베딩들에서의 그래프의 메타데이터를 나타내도록 구성될 수 있다. 일부 실시예들에서, 그래프 임 베딩 네트워크는 비지도 또는 반지도(semi-supervised) 네트워크일 수 있다. 일례로서, 비지도 네트워크는 학 습 신호를 제공하기 위해 고유한 보상 기능들(강화 학습)을 이용하기 위한(예를 들어, 그래프 부분들의 표현들 로서 임베딩들의 효율을 향상시키기 위한) 목표로 구성될 수 있다. 일부 실시예들에서, (그래프의) 노드 또는 서브그래프와 (임베딩이 도출되었던) 노드 또는 서브그래프를 나타내 는 임베딩 사이의 양방향 참조(two-way reference)가 유지될 수 있다. 일례로서, 양방향 참조는 그러한 임베딩 들을 저장하는데 이용되는 선택된 데이터 구조(예를 들어, 텐서(tensor)들, 메트릭스들, 데이터베이스, 그래프 자체 등)에 관계없이 유지될 수 있다. 주어진 임베딩이 그래프의 제1 노드를 나타내는 하나의 이용 사례에서, 그래프는, 에지가 제1 노드와 제2 노드 사이에서 공유(예를 들어, 제1 노드와 제2 노드 사이의 양방향 접속)되 도록 임베딩을 그래프에 제2 노드로서 저장할 수 있다. 이러한 방식으로, 예를 들어, 심볼적인 인간의 이해가 능한 노드들 및 서브그래프들은 심볼적인 동작들이 의미있는 공간에서의 벡터들에 대한 서브심볼 동작들과 인터 레이싱될 수 있도록 밀집된 벡터 추상화들(예를 들어, 임베딩들)에 그라운딩/결부된다. 일례로서, 그래프 질의 알고리즘은 하나 이상의 서브그래프 또는 노드를 선택하기 위해 이용될 수 있고, 그 후 그들의 표현 벡터들은 머신 학습 알고리즘들에 의해 추가로 처리되어, 심볼 레벨에서 그래프를 생성하고 출력하거나 심지어는 재질의 한다. 일부 실시예들에서, 그래프 임베딩 네트워크 및 소비 네트워크들(그래프 임베딩 네트워크에 의해 생성되는 임베 딩들을 소비함)은 직접 접속되어, 그들이 종단에서 종단까지 트레이닝될 수 있게 한다. 일부 실시예들에서, 그 래프 임베딩 네트워크 및 소비 네트워크들은 서로 분리된다. 그와 같이, (그래프 임베딩 네트워크에 의해 생성 된) 사전 트레이닝된 임베딩 벡터들은, 임베딩 벡터들이 적절히 이용되도록 소비 네트워크에서의 적절한 계층에 전송될 수 있다. 일부 실시예들에서, 효율성 목적들을 위해, 그래프로부터의 노드 또는 서브그래프에 대한 벡 터의 검색은 그것의 각자의 식별자(예를 들어, 그래프 또는 서브그래프 ID들)에 의해 인덱싱될 수 있는 계층적 어레이, 스파스 어레이(sparse array), 또는 텐서의 이용을 통해 수행될 수 있다. 일부 실시예들에서, 벡터는 소비 네트워크에 대한 입력으로서 제공될 수 있고, 소비 네트워크는 벡터에 기초하여 하나 이상의 출력을 생성 할 수 있다. 소비 네트워크의 입력 계층(예를 들어, 임베딩 입력 계층)의 아키텍처는 소비 네트워크가 임베딩 벡터들을 적절하게 처리할 수 있게 하기 위해 업스트림 그래프 임베딩 네트워크의 특정 아키텍처 및 하이퍼파라미터들(hyper-parameters)에 기초하여 구성될 수 있다. 일부 실시예들에서, 벡터는 (예를 들어, 하나의 핫 (hot) 표현으로서의) 다른 입력 인코딩들에 대한 가중치들(예를 들어, 프로즌(frozen) 또는 학습가능한 가중치 들)로서 이용될 수 있다. 일부 경우들에서, 벡터들이 학습가능한 가중치들로서 이용되는 경우, 업데이트된 벡 터들은 그래프 임베딩 네트워크에 가중치 벡터로서 다시 전송될 수 있고, (예를 들어, 소비 네트워크 또는 다른 소비 네트워크들에) 다운스트림으로 다시 전송되기 전에 그래프 임베딩 네트워크에 의해 더 미세 조정될 수 있 다. 일부 실시예들에서, (업스트림 임베딩 네트워크에 의해 생성된 벡터들을 소비하는) 그러한 소비 네트워크는 시 퀀스 신경망(sequence neural network)을 포함할 수 있다. 일례로서, 시퀀스 신경망은 대화 이력, 현재 상태, 또는 다른 그러한 메모리 관련 데이터의 밀집 벡터 표현을 유지 또는 출력하도록 트레이닝될 수 있다. 하나의 이용 사례에서, AI 엔티티와 다른 엔티티(예를 들어, 인간 사용자, 다른 인공 지능 엔티티 등) 사이의 대화에 관하여, AI 엔티티는 긴 단기간 메모리(long short-term memory)(LSTM) 네트워크(또는 다른 시퀀스 신경망)에 의존하여, 다른 엔티티의 입력들(예를 들어, 다른 엔티티에 의해 제공되는 단어들, 구들, 문장들, 또는 다른 입 력)을 나타내는 관련된 온톨로지-정서 그래프 임베딩 벡터들(및/또는 BERT 또는 다른 사전 트레이닝된 단어 임 베딩들)을 소비하여, 벡터들을 (예를 들어, AI 엔티티 또는 다른 엔티티의 감정 및 감정 정보와 함께) 시간적 구조에 링크 또는 구축할 수 있다. LSTM 네트워크의 대화 이력 정보에 기초하여, LSTM 네트워크는 대화 상태를 나타내는 (예를 들어, 대화의 사람의 메모리와 유사한) 벡터(본 명세서에서 \"대화 상태 벡터\"라고도 지칭됨)를 출력할 수 있다. 일례로서, LSTM 네트워크는 다른 엔티티 또는 다른 자동화된 트리거들(예를 들어, 유사한 대 화 또는 컨텍스트, 다른 엔티티의 이름 또는 후속 대화에서 나오는 다른 식별자 등)에 의해 제공되는 후속 입력 에 응답하여 대화 상태 벡터를 출력할 수 있다. 이 벡터는 이후 온톨로지-정서 그래프에 대화 메모리 노드로서 저장되거나 다른 신경망들에 의해 소비될 수 있다. 일부 실시예들에서, AI 엔티티는, (학습된 감정적 거동들과 유사한) 관계 패턴 추론(relational pattern reasoning)에 의존하는 다른 인공 지능 시스템들에 비해, 보상 기능들과 관련하여 (특정 사람에 대한 개념과 같 은) 그의 심볼 추상화들을 수정하도록 구성될 수 있는데, 그러한 다른 시스템들이 에이전트의 목표들 및 환경과 관련하여 자동 추론을 학습한다는 의미에서 그러하다. 따라서, 인공 지능 엔티티와 관련하여, 그것의 정서들 및 감정들(예를 들어, 통증 정서(pain affect), 공포 감정 등)은, 하나 이상의 거동 프라이어를 주어진 컨텍스 트 내의 거동 경로 또는 온톨로지적 엔티티로 이행하는 성향(propensity)을 첨부하는 거동 신호들로서 작용할 수 있고, 보상 기능들은 거동 경로, 온톨로지 엔티티 또는 2개의 다른 노드 타입들 및 확률, 본능적 스터브들 등과 같은 메타데이터를 혼합하는 개념들에 의미를 제공하는 정서들 및 감정들을 할당(그에 의미를 부여)하는 것을 돕는다. 이러한 방식으로, (보상 기능들의 형태로) 고유 보상들은 거동 프라이어들에 대한 대체물로서 작 용할 수 있고, 정서들 및 감정들은 시스템으로의 목표 기반 거동을 (예를 들어, 다운스트림 프록시 감정으로부 터와 같이) 직접적으로 또는 간접적으로 소화하는 지름길들(shortcuts)로서 작용한다. 일례로서, 보상 기능들 은 AI 엔티티의 대화 상대(예를 들어, AI 엔티티가 상호작용하는 다른 엔티티)의 긍정적 감정을 증가시키는 것 과 같은 일부 목표의 획득을, 간단히 신경망 회로들이 아니라 개개의 개념들의 레벨에서 그 목표로 유도되는 사 물들의 종류들에 특권을 주는 신호로 변환하는데 이용될 수 있다. 본 명세서에 설명되는 이들 및 다른 그래프 속성들 및 노드들은 본 명세서에 설명되는 임의의 연역 기법들(deductive techniques)(예를 들어, 사람 X는 개 들을 좋아하고, 개는 동물이고, 따라서, 사람 X는 일부 신뢰도로 동물들을 좋아한다), 본 명세서에서 설명되는 그래프 귀납 기법들(graph induction techniques), 또는 다른 기법들에 의해 전파될 수 있다. 하나의 이용 사례에서, 야구의 개념과 관련하여, AI 엔티티의 대화 상대들이 야구의 논의들에 대해 긍정적으로 응답하면, AI 엔티티는 야구에 대한 긍정적인 성향을 개발할 것이고, 주어진 컨텍스트에서 그 화제를 더 자주 호출하도록 학습할 것이다. 이것은 그의 벡터 공간 임베딩에서 반영될 개념 \"야구\"에 의미의 다른 계층을 추가 한다. 이것은 개념들, 엔티티들, 거동 경로들, 또는 신경망들을 태깅함으로써(또는, 보다 통상적으로, 신경망 파라미터들을 업데이트함으로써) AI 엔티티의 거동에서의 조정들을 동적으로 유도한다. 이러한 방식으로, 예를 들어, AI 엔티티는 (예를 들어, 감정적 유도들(emotional drives)과의 충돌을 피하기 위해) 다른 처리 계층과의 감정들(또는 다른 것들의 감정들)에 대해 계산할 수 있다. 일례로서, AI 엔티티는 (본 명세서에 설명된 바와 같이) 다른 보상 신호들에 의해 트레이닝된 심볼 논리/조건부 프로그래밍 계층 또는 신경망으로 증강될 수 있다. 일부 실시예들에서, 고유 보상 기능들은 기존의 및 새로운 감정적 태그들에서의 정서적 및 감정적 응답들의 강 도를 증가시키는 것에 의해 AI 엔티티에 대한 \"압력\"을 증가 또는 감소시키는 다양한 내부 파라미터들과 쌍을 이룬다. 이들은, 압력이, 예를 들어, 대화 상대를 갖거나, 또는 이하에 기술된 인자들을 갖는 최종 미팅의 지속기간의 함수로서 증가하는 시간적 컴포넌트를 포함한다. 일부 실시예들에서, AI 엔티티는 시간에 따라 경험 된 보상의 양에 반비례하는 보상 기능에 따라 작용하는 그의 성향을 수정하도록 구성될 수 있다. 일례로서, AI 엔티티는, 대화 시간에 대한 전체 칭찬 값(compliment value)(예를 들어, 그의 대화 상대들로부터 수신되는 칭 찬들의 수 및 각각의 칭찬의 값)의 비율이 감소함에 따라 칭찬들을 노리기 위한 그의 성향을 증가시킬 수 있다. 이 시나리오에서, 전술한 칭찬 역동성(compliment dynamic)은 본 명세서에 설명된 메커니즘들로부터의 창발적 거동일 수 있는 예다. 일부 실시예들에서, 그러한 동적 \"압력\"은 정서 및/또는 감정적 울림(resonance)(예를 들어, 예상된 보상과의 개념의 연관)을 평가시에 고려되어야 하는 내부 파라미터들에 기초할 수 있다. 일례로 서, AI 엔티티는 개념과의 감정적 연관을 증가시키거나 감소시키도록 구성될 수 있다(예를 들어, 특정 개인에서 의 신뢰를 증가시키는 것). 하나의 이용 사례에서, 개인과의 그의 감정적 연관에 기초하여, AI 엔티티는 개인 과 유사한 것으로 간주되는 다른 엔티티들과 상호작용할 때 (예를 들어, \"개인\" 정보를 공유하도록 더 개방되는) 특정 방식으로 작용하는 더 높은 성향을 가질 수 있다. 더 일반적으로 그리고 약간 더 낮은 레벨의 추상화에서, 온톨로지-정서 그래프에서 개념들의 정서 및/또는 감정적 울림을 곱하는 하나 이상의 전역적 파라 미터가 있을 수 있다. 이들은 동적 보상 압력 입력들에 기초하여 위 또는 아래로 조절될 수 있다. 예를 들어, AI 엔티티의 새로운 지식 획득이 선행 시간 간격에서 비교적 낮은 경우, 전역적 호기심 보상 곱셈기 파라미터에 의해 호기심 보상 연관들이 증가할 수 있다. 일부 실시예들에서, 동적 압력은 보상들의 크기 및 시간(예를 들 어, 동적 크기들 및 시간들)을 유지하는 데이터 구조에 기초할 수 있다. 표현 벡터는 데이터 구조에 기초하여 획득될 수 있고, AI 엔티티의 거동을 지시하는 네트워크들에 대한 입력으로서 제공되고, 따라서, 감정적 \"압 력\"을 적용하여 (예를 들어, 보상의 크기 및 시간에 따라) 고유 보상을 트리거할 수 있다. 이것은 보상 이력이 상이한 개념들, 서브그래프들 및 개념 클래스들 마다 추적될 수 있기 때문에 보다 세분화되 고(granular) 비선형의 보상 조절을 허용할 것이고, 압력 조절은 신경망들에 의해 암시적으로 비선형 방식으로 학습될 수 있다. 일부 실시예들에서, AI 엔티티는, 그러한 정서적 속성들을 갖는 다른 개념들에 대한 개념들의 유사성들에 기초하여, 하나 이상의 정서적 속성을 하나 이상의 개념과 연관시키도록 구성될 수 있다. 일례로서, AI 엔티티는 개념 X 및 그라운딩 및 컨텍스트 Y와 연관된 정서적 속성을, 유사한 그라운딩 및 컨텍스 트를 갖는 다른 개념들에 연관시킬 수 있다. 하나의 시나리오에서, 생존 디스인센티브들(survival disincentives)(예를 들어, 통증 정서 또는 공포 감정)(또는 다른 정서 또는 감정)이 (그래프에서 노드로서 표 현된) \"총(gun)\"과 연관되고, 노드 \"총\"이 파워, 금속, 및 딱딱함과 같은 속성들을 갖는 경우, \"총\"과 연관된 전술한 거동 태그들은 그러한 다른 노드들이 동일한 클래스 타입(예를 들어, 화기(firearm) 클래스에 있지 않은 노드들)에 속하지 않더라도 유사한 그라운딩들을 갖는 다른 노드들과 연관될 수 있다. 예를 들어, \"총\"과 연관 된 거동 태그들은 파워, 금속, 및 딱딱함의 속성들을 갖는 \"야구 배트(baseball bat)\"에 기초한 노드 \"야구 배 트\"와 연관될 수 있다. 추가 예로서, 거동 태그들은 거동 태그들과 노드 \"총\" 사이의 연관성에 대한 신뢰도보 다 더 적은 신뢰도(예를 들어, 확률 신뢰도로서 인코딩됨)를 갖는 노드 \"야구 배트\"와 연관될 수 있다. 일부 실시예들에서, 시스템은 또한, 감정들 및 컨텍스트로부터, 초기에 그러한 속성들이 없었던 기존의 노드들 에 그라운딩 속성들을 할당하도록 학습할 수 있다. 일례로서, 이전에 주석이 달린 데이터, 온톨로지-정서의 벡 터 공간 유사성, 또는 사전 트레이닝된 단어 임베딩들 또는 대화형 입력들을 이용함으로써, \"무거운\"의 개념은 높은 부정적 감정, 정서, 및/또는 개념적 밀도의 서브그래프들 또는 개념들과 상관될, 그래프 신경망으로 학습 될 수 있다. 신경망은 시간에 따른 선행 입력들 중 이러한 주어진 하나 이상을 암시적으로 학습할 것이고, 추 가의 \"무거운\" 본능적 노드들은 이어서 다른 그러한 그래프 영역들에 대한 다양한 세기의 정도들로 추론될 수 있다. 이러한 방식으로, AI 엔티티는 반드시 새로운 대화들 또는 다른 정보 소스들을 통해 정보를 획득할 필요 없이 그 정보의 현재 데이터베이스(예를 들어, 충분히 풍부한 그래프)로부터 \"사고\" 및 학습할 수 있다. 그러한 속 성 예측은 그라운딩, 정서/감정, 온톨로지, 잠재적인 인자들(이전에 존재하지 않았던 추론된 새로운 노드들), 및 대화형 출력들 등의 유도를 용이하게 하는 것을 돕는다. 일례로서, 그래프 데이터 및 구조는 다른 엔트리들 로부터의 그래프 엔트리들에 관한 정보를 학습하는 그래프 신경망들을 위해 이용될 수 있다. 일부 실시예들에 서, 단어 연관성에서의 유사성들은 사전 트레이닝된 단어 임베딩들로부터 그래프로 정보를 전송하기 위해 (예를 들어, AI 엔티티 또는 다른 시스템에 의해) 이용될 수 있고, 이는 나중에 그래프 임베딩들로 갈 것이다. 그와 같이, 사전 트레이닝된 단어 임베딩들이 그래프 구조 또는 AI 엔티티의 전체 온톨로지-정서 그래프에서 인코딩 된 메타데이터의 타입들을 인코딩하지 않을 수 있지만, (그래프 또는 그의 부분들로부터 생성된) 그래프 임베딩 들은 단어 임베딩들에서의 정보 이외의 그러한 그래프 구조, 메타데이터, 또는 정보를 포함할 수 있다. 일례로 서, 그래프 임베딩 네트워크는 (예를 들어, 네트워크의 하이퍼파라미터 또는 학습된 가중치에 의해 정의되는 특 정 허용범위 내의) 주어진 노드의 라벨에 근접한 단어들을 검색하기 위해 그래프에서의 단어 임베딩들에 대한유사성 측정들을 이용하도록, 또는 클래스를 공유하는 것들과 같은 엔트리들을 찾기 위해 그래프를 상징적으로 탐색(walk)하도록 구성될 수 있다. 그 다음, AI 엔티티는 알려진 그래프 노드들에 가까운 단어들을 찾기 위해 신경망 또는 유사성 측정들을 이용할 수 있고, 그 단어들은 그래프에 삽입될 수 있고 질의를 시작한 주어진 노 드에 접속될 수 있다. 하나의 이용 사례에서, 대화형 입력으로부터 검색된 새로운 단어가, 사전 트레이닝된 단 어 임베딩 공간에서, 주어진 노드와 연관된 본능적 또는 정서 데이터에 대한 단어들과 중첩하는 새로운 접속들 에 대한 검색이 수행될 수 있다(예를 들어, 새로운 단어들은 인식된 본능적 또는 정서 단어들에 기초하여 주어 진 노드와 유사한 것으로 간주된다). 일부 실시예들에서, 노드들의 컨텍스트들에 걸친 비대칭들은 지식 갭들을 표시하고, 새로운 동등화 정보를 취득하기 위해 AI를 트리거할 수 있다. 하나의 이용 사례에서, 노드들 사이에 공유되는 (강한 클래스 유사성을 공유하지만, 하나는 본능적 유사성이 없는 노드들과 같은) 불균형적으로 비대 칭인 컨텍스트 연관성, 또는 유사한 노드들(노드 a 연역(deduction), 노드 b 귀납(induction)) 사이의 방법 취 득의 비대칭 이력은, 시스템이 귀납/서브심볼, 연역/심볼, 또는 비대칭들을 동등화하기 위한 대화 수단을 통해 시도하도록 트리거할 수 있다. 일부 실시예들에서, 온톨로지-정서 그래프 내의 또는 그래프와 외부 입력들 사 이의 정보를 논리적으로 또는 확률적으로 부정하는 정보는 또한 그러한 전술한 지식 획득 기술들을 이용하여 충 돌 회피(deconfliction) 메커니즘들을 트리거할 수 있다. 일부 실시예들에서, 온톨로지-정서 그래프는 AI 엔티티를 향한 하나 이상의 엔티티(예를 들어, 인간 엔티티들, 다른 AI 엔티티들 등)의 감정과 관련된 벡터들 및/또는 심볼 노드들을 포함할 수 있다. 일례로서, 그러한 벡터 들은 AI 엔티티의 관계들의, 그러나 단순히 AI 엔티티의 현재 감정 상태는 아닌 이력 및 패턴들을 고려하기 위 해 이용될 수 있다. 하나의 이용 사례에서, 그러한 벡터는 AI 엔티티를 향한 벡터와 연관된 엔티티의 현재 감 정을 인코딩하기 위해 신경망(예를 들어, LSTM 또는 다른 시퀀스 신경망)에 의해 제공되거나 업데이트될 수 있 다. 벡터는 AI 엔티티와의 엔티티의 대화들(예를 들어, AI 엔티티에 제공되는 엔티티의 입력들, 엔티티의 입력 들에 대한 AI의 엔티티의 응답들 등)에 기초하여 신경망에 의해 생성될 수 있다. 일부 실시예들에서, 그러한 신경망은 (예를 들어, 사전 트레이닝된 단어 벡터들을 포함하는, 그래프의 부분들로부터의 개념 벡터들의 비지 도 및 강화 학습을 위해 구성된) (본 명세서에 설명된 바와 같은) 그래프 임베딩 네트워크와 쌍을 이룰 수 있다. 일례로서, 이러한 신경망은 아래의 응답 템플릿 선택 네트워크에 공급될 수 있다. 일부 실시예들에서, 하나 이상의 고유 보상 기능이 응답 선택(예를 들어, 입력에 대한 응답의 일반적인 템플릿 을 선택하기 위한 AI 엔티티의 기능)을 용이하게 하기 위해 신경망(예를 들어, 피드포워드 네트워크 또는 다른 네트워크)을 트레이닝하는데 이용될 수 있다. AI 엔티티의 잠재적 응답들의 예들은, (i) 질문을 제공하는 것, (ii) 서술문을 만드는 것, (iii) 명령을 발행하는 것, (iv) 질문에 답변하는 것, (v) 정보를 제시하는 것, 및 (vi) 주제를 변경하는 것을 포함한다. 일부 실시예들에서, 보상 기능은, 이 \"응답 템플릿 선택\" 네트워크를 트 레이닝하기 위해, 각각, 긍정적 감정 및 새로운 정보를 유도하는 응답에 대한 크레딧(credit)을 할당하도록 구 성될 수 있다. 하나의 이용 사례에서, 응답 템플릿 선택 네트워크는 다음 중 하나 이상을 입력으로서 취하도록 구성될 수 있다: (i) 사전 트레이닝된 임베딩/변환기 네트워크(예를 들어, BERT(Bidirectional Encoder Representations from Transformers) 또는 다른 그러한 네트워크)를 통한 대화 상대(예를 들어, AI 엔티티와 상호작용하는 다른 엔티티)로부터의 입력, (ii) 대화 이력의 벡터(예를 들어, 시퀀스 신경망을 통해 트레이닝된 벡터), (iii) 문장 표현으로 형성된 (예를 들어, 정서 이력을 포함하는) 대화 상대에 대한 온톨로지-정서 그래 프로부터의 하나 이상의 임베딩(예를 들어, AI 시스템을 향한 대화 상대의 현재 및 이전의 감정의 임베딩 벡터 들), 및/또는 (iv) 입력으로부터의 적절한 단어들에 대한 온톨로지-정서 그래프 임베딩들로부터 구축된 입력의 시퀀스 표현. 이들은 시퀀스 NN을 이용하여 시간 시퀀스 표현으로 처리되거나, 템플릿 선택 네트워크가 벡터들 의 시간적 순서화를 처리하기 위한 시퀀스 입력 분기, 또는 시간적 순서화를 보존하기 위한 일부 다른 방법을 가질 것이다. 입력들을 처리할 때, 응답 템플릿 선택 네트워크는 선택될 응답 템플릿(예를 들어, 전술한 잠재 적 응답들 중 하나로부터의 일반적인 템플릿)을 나타내는 벡터를 생성할 수 있다. 일부 실시예들에서, 미리 정 의된 템플릿들은 (예를 들어, 응답 템플릿 선택 네트워크에 제공되는 유사한 입력들을 갖는) 시퀀스 모델들에 의한 스크래치로부터 생성되거나, 딥 러닝을 통해 선택될 일련의 더 작은 조각들로부터 구축될 수 있다. 일부 실시예들에서, 템플릿 변수 선택(예를 들어, 선택된 템플릿에서의 서술어들, 주어들, 동사들, 및 다른 알 려지지 않은 것들을 채우는 프로세스)이 수행될 수 있다. 학습된 벡터들을 이용하는 예는 다음과 같다: AI 엔 티티에 대한 입력은 \"I need a new friend, who should I go to lunch with?\"일 수 있다. 후보 응답 템플릿은 \"Good question, I'm [positive emotion] to help. You should go meet [Person A]. [He or she] is [adjective]\"와 같이 선택된다. 응답 템플릿의 선택은 대화 상대의 그래프 임베딩과 그래프에서의 모든 다른 엔티티들 간의 유클리드(Euclidean) 또는 코사인 유사성 거리의 질의를 트리거할 수 있다. 그러한 함수들(예를 들어, 거리 측정들)은 개념들 사이의 유사성의 특정 측정들을 나타낸다. 전술한 질의가 수신되면, 질의는 대화상대를 향한 AI 엔티티의 감정적 성향에 대한 심볼 질의와 함께 템플릿을 채우는데 이용될 수 있다. AI 엔티티 의 응답 이유에 대한 설명을 요구받으면, AI 엔티티는 이 경우 2개의 개인들 간의 심볼 유사성들을 검색 및 출 력하기 위해 그래프를 탐색하거나, 일반적인 경우에 벡터 계산의 간단한 심볼적 실현을 할 수 있다. 이러한 방 식으로, 사후(post hoc)이지만, 이러한 패턴은 인간 추론에서 직관적 결정들의 유사한 사후 합법화를 미러링하 고, 심볼 및 서브심볼 벡터 공간 추론을 혼합할 가능성을 입증한다. 다른 가능한 질의들은 함께 더 많이 묶여 질 수 있는 보다 광범위한 심볼 및 서브심볼 함수들로 존재한다. 일부 실시예들에서, 템플릿 변수 선택(예를 들어, 그리고, 추가 처리) 후에, AI 엔티티는 텍스트를 출력하고, 대화 상대로부터 응답을 기다린다. 입력이 수신되면, AI 엔티티(또는 시스템의 다른 컴포넌트들)는 획득 된 새로운 정보의 양 및 중요성의 감정 분석 및 스코어링을 이용하여 2개의 고유 보상 기능들에 대해 입력을 파 싱 및 평가할 수 있다. 이전 네트워크들(예를 들어, 그래프 임베딩 네트워크, 감정 임베딩 네트워크, 응답 템 플릿 선택 네트워크, 템플릿 변수 선택 네트워크 등)의 파라미터들은, 이들 함수들로부터의 학습 신호에 응답하 여 업데이트될 수 있다. 일부 실시예들에서, 대화 상태 벡터 및 온톨로지-정서 그래프가 (예를 들어, 최근의 상호작용들을 반영하기 위해) 업데이트될 수 있다. 일부 실시예들에서, AI 엔티티와 연관된 신경망은 상황에 대한 AI 엔티티의 응답(예를 들어, 대화 상대가 말한 것에 대한 응답 또는 컨텍스트 상황을 나타내는 다른 입력에 대한 응답)에 대한 하나 이상의 정서적 속성들을 결정하기 위해 트레이닝될 수 있다. 일부 실시예들에서, 이러한 \"감정\" 네트워크는, (i) AI 엔티티의 현재 감 정 상태, (ii) (예를 들어, 대화 상태 벡터에 의해 표현된) AI 엔티티와 대화 상대들 사이의 대화 이력, (iii) 입력 단어(들)에 대해 온톨로지-정서 그래프로부터 획득된 개념 벡터들(및 하나 이상의 문장에서의 배열의 일부 표현), 또는 (iv) 입력 단어(들) 또는 입력 문장에서의 다른 개념들과 유사한 온톨로지-정서 그래프로부터의 하 나 이상의 개념 벡터 중 하나 이상을 입력으로서 취하는 심층 신경망(deep neural network)을 포함할 수 있다. 전술한 것은 벡터 공간 질의(예를 들어, 비유 또는 비교, 과거의 정서적 내용에 기초한 유사성 조회 등)를 통한 거동 프라이어 기준들에 의해 검색될 수 있다. 감정 네트워크의 출력들은 입력 문장에서의 개념들 중 하나 이 상에 대한 감정 응답을 나타내는 감정 태그들을 포함할 수 있다. 일부 실시예들에서, 감정들은 초기에 하드코딩될 수 있다. 추가적으로 또는 대안적으로, \"감정적\" 벡터 공간은 벡터 공간에서 새로운 감정들의 신규한 조합들을 생성하기 위해 알려진 감정들의 모음(및 감정 벡터 공간 내의 그들의 위치들)에 기초하여 신경망을 트레이닝함으로써 생성될 수 있다. 이들은 거동 프라이어들/보상 기능들, 본능적 프라이어들, 컨텍스트, 구조 및 현재 감정 상태에 대한 응답들을 유도하는 것으로부터의 딥 러닝에 의해 학습된 의미있는 추상화들일 것이다. 일부 실시예들에서, 감정은 고유의 목표, 컨텍스트/이력, 개념 벡터, 자체, 및 다른 상태들에 맞춰 추상화를 형 성하는 전체 거동 회로로서 취급될 수 있다. 일례로서, 거동 회로는 거동을 유도하고, (예를 들어, 스피치의 강도와 같은) 전역 파라미터들을 조정한다. 이러한 프레임워크에서, 입력은 파싱되고, 그것의 개념 벡터들(이 전의 정서적 또는 감정적 내용을 포함함)은 그들의 연관된 노드들 상의 심볼 질의를 이용하여 온톨로지-정서 그 래프로부터 검색된다. 그 다음, 파싱된 입력 및 개념 벡터들 뿐만 아니라, 대화 상태, 현재 감정 상태(CES), 및 다른 인자들이 감정 신경망에 공급되며, 이는 내부 CES 파라미터들을 조정하고, (예를 들어, 별도의 LSTM 신 경망과 같은) 트레이닝된 서브네트워크들을 활성화하는 결정들을 행한다. 일부 실시예들에서, LSTM은 이후 이 러한 입력들 및 벡터 추상화들 중 일부를 메모리 셀들로서 이용하고 출력을 생성한다. 이어서, 대화 상대로부 터의 응답은 \"비평가(critic)\" 프레임워크를 이용하여 보상 기능들에 대해 분류되고 매칭된다. 그 후, 모든 보 상 기능에 대한 크레딧 신호가 생성되고, LSTM 파라미터들은 그래프의 감정적 또는 정서적 속성들과 함께 업데 이트된다. 예시적인 흐름도들 도 3 내지 도 5는 위에서 상세히 설명된 바와 같은 시스템의 다양한 특징들 및 기능을 가능하게 하는 방법들의 처리 동작들의 예시적인 흐름도들이다. 아래에 제시되는 각각의 방법의 처리 동작들은 예시적인 것이며, 비제 한적인 것으로 의도된다. 일부 실시예들에서, 예를 들어, 방법들은 설명되지 않은 하나 이상의 추가적인 동작 에 의해, 및/또는 논의된 동작들 중 하나 이상이 없이 달성될 수 있다. 추가적으로, 방법들의 처리 동작들이 도시되는(그리고, 이하에서 설명되는) 순서는 제한적이도록 의도하지 않는다. 일부 실시예들에서, 방법들은 하나 이상의 처리 디바이스(예를 들어, 디지털 프로세서, 아날로그 프로세서, 정 보를 처리하도록 설계된 디지털 회로, 정보를 처리하도록 설계된 아날로그 회로, 상태 머신, 및/또는 정보를 전 자적으로 처리하는 다른 메커니즘들)에서 구현될 수 있다. 처리 디바이스들은 전자 저장 매체에 전자적으로 저장된 명령어들에 응답하여 방법들의 동작들의 일부 또는 전부를 실행하는 하나 이상의 디바이스를 포함할 수 있 다. 처리 디바이스들은 방법들의 동작들 중 하나 이상의 실행을 위해 특별히 설계되도록 하드웨어, 펌웨어, 및 /또는 소프트웨어를 통해 구성된 하나 이상의 디바이스를 포함할 수 있다. 도 3은 하나 이상의 실시예에 따른, 정서적 상태 기반 인공 지능을 용이하게 하는 방법을 도시한다. 단계 에서, 하나 이상의 성장 또는 감쇠 인자가 인공 지능 엔티티의 정서적 속성들의 세트에 대해 결정될 수 있 다. 일부 실시예들에서, 위에 언급된 바와 같이, 각각의 정서적 속성에 대한 성장 또는 감쇠 인자들은 미리 결 정되고, 성장/감쇠 인자 데이터베이스에 저장될 수 있다. 전술한 바와 같이, 각각의 감정 상태는 고유한 레이트(또는 인자)로 성장 또는 감쇠하는 시간적 컴포넌트를 포함한다. 예를 들어, 놀라움은 (새로운 놀라움의 존재시에) 신속하게 감쇠하는 반면, 비통함은 슬픔의 깊이에 비례하여 감쇠한다. 따라서, 인공 지능 엔티티의 각각의 정서적 속성(예를 들어, 각각의 감정 상태)은 하나 이상의 고유한 성장 또는 감쇠 인자와 연관될 수 있 다. 성장/감쇠 인자 데이터베이스는 인공 지능 엔티티의 정서적 속성들의 세트에 대응하는 성장/감쇠 인 자들의 목록을 포함할 수 있고, 인자 조정 서브시스템은 성장/감쇠 인자 데이터베이스로부터 수신된 정보에 기초하여 각각의 정서적 속성에 대응하는 성장 또는 감쇠 인자들을 결정할 수 있다. 단계에서, 인공 지능 엔티티의 정서적 값들의 세트는 일정 시간 기간 동안 성장 또는 감쇠 인자들에 기초 하여 연속적으로 업데이트될 수 있다. 유의할 점은, 정서적 속성들의 세트가 인공 지능 엔티티의 정서적 값들 의 세트와 연관된다는 것이다. 인공 지능 엔티티의 (정서적 속성들과 연관된) 정서적 값들은 정서적 속성들과 연관된 성장 또는 감쇠 인자들에 기초하여 연속적으로 업데이트될 수 있다. 예를 들어, 도 2a 내지 도 2c에 도 시된 바와 같이, 정서적 값들(201, 202, 및 212)(예를 들어, 207a-207f, 208a-208f, 및 218a-218f)은 정서적 속성들 A, B, 및 C와 연관된 하나 이상의 성장 또는 감쇠 인자에 기초하여 연속적으로 업데이트될 수 있다. 일 부 실시예들에서, 인공 지능 엔티티의 정서적 값들의 연속적인 업데이트는 하나 이상의 성장 또는 감쇠 인자에 기초한 인공 지능 엔티티의 정서적 값들의 주기적인 업데이트를 포함할 수 있다. 단계에서, 일정 시간 기간 동안에 입력이 획득될 수 있다. 입력은 클라이언트 디바이스, 다른 인공 지능 엔티티로부터, 및/또는 시스템 내의 또는 외부의 임의의 소스로부터 획득될 수 있다. 입력은 자연 언어 입력, 오디오 입력, 이미지 입력, 비디오 입력, 또는 다른 입력을 포함할 수 있다. 예를 들어, 자연 언어 입력은 \"John has cancer, and cancer is very dangerous\"를 포함할 수 있다. 유사한 입력들이 서버에 의해 오디오 입력, 이미지 입력, 및/또는 비디오 입력으로서 획득될 수 있다. 단계에서, 입력과 관련된 응답이 생성될 수 있다. 이러한 응답은 인공 지능 엔티티의 연속적으로 업데이트된 정서적 값들의 세트에 기초 할 수 있다. 예를 들어, 자연 언어 입력이 \"John died because of cancer\"인 경우, 응답 생성 서브시스템 에 의해 생성된 (예를 들어, 그러한 입력과 관련된) 응답은 \"That is unfortunate\" 또는 \"This is sad. I need a moment\"를 포함할 수 있다. 단계에서, 성장 또는 감쇠 인자들은 입력에 기초하여 이 기간 동안 업데이트될 수 있다. 단계에서, 성장 또는 감쇠 인자들의 업데이트에 후속하여, 정서적 값들의 세트는 업데이트된 성장 또는 감쇠 값들에 기초 하여 업데이트될 수 있다. 예를 들어, 도 2a 및 도 2b는 인공 지능 엔티티의 정서적 속성들 A 및 B와 연관된 정서적 값들(예를 들어, 정서적 값들 도 2a에서의 207c-207f 및 도 2b에서의 208c-208f)의 업데이트를 도시한다. 업데이트된 성장 또는 감쇠 인자들에 기초하여 업데이트되는 것에 더하여, 정서적 값들은 하나 이상 의 영향 값들 및/또는 상호작용 임계값에 기초하여 업데이트될 수 있다. 예를 들어, 인공 지능 엔티티의 하나 이상의 정서적 속성들에 대한 입력(예를 들어, 자연 언어 입력)의 내용의 부분들의 영향과 관련된 하나 이상의 영향 값이 결정될 수 있다. 예를 들어, 자연 언어 입력이 \"John has cancer\"인 경우, 인공 지능 엔티티의 하나 이상의 정서적 속성에 대한 자연 언어 입력의 부분들(예를 들어, \"John\", \"has\", \"cancer\")의 영향과 관련된 영 향 값들이 결정될 수 있다. 또한, 영향 값들이 (인공 지능 엔티티의 정서적 속성들과 연관된) 하나 이상의 정 서적 값에서 업데이트(예를 들어, 증가 또는 감소)를 트리거하기 위한 미리 결정된 임계값을 만족시키는지의 여 부에 대한 결정이 행해질 수 있다. 하나 이상의 영향 값이 미리 결정된 임계값을 만족시키는 것으로 결정되는 경우, 인공 지능 엔티티의 정서적 값들이 수정(예를 들어, 증가 또는 감소)될 수 있다. 예를 들어, 단어 \"cancer\"가 정서적 속성 \"슬픔\"에서의 증가를 트리거하기 위한 미리 결정된 임계값보다 큰 영향 값을 갖는 것으 로 결정되면, 정서적 속성 \"슬픔\"에 대응하는 정서적 값들이 수정(예를 들어, 증가)될 수 있다. 또한, 영향 값 들은 또한 미리 결정된 임계값이 영향 값들에 의해 만족될 때 하나 이상의 성장 또는 감쇠 인자에서의 증가 또 는 감소를 트리거할 수 있다. 그러한 성장 또는 감쇠 인자들에서의 증가 또는 감소는 인공 지능 엔티티의 정서 적 속성에 대응하는 정서적 값들의 업데이트를 초래할 수 있다. 또한, 일부 실시예들에서, 인공 지능 엔티티와 하나 이상의 다른 엔티티(예를 들어, 하나 이상의 다른 인공 지 능 엔티티 및/또는 하나 이상의 클라이언트 디바이스) 사이의 상호작용이 상호작용 임계값을 초과했는지의 결정 이 행해질 수 있다. 상호작용이 상호작용 임계값을 초과했다는 결정에 기초하여, 인공 지능 엔티티의 정서적 값들이 수정될 수 있다. 예를 들어, 인공 지능 엔티티 및 다른 엔티티들이 미리 결정된 기간 내에 미리 결정된 횟수에 걸쳐 상호작용하였다면, 상호작용을 위한 미리 결정된 임계값이 만족되었고, 인공 지능 엔티티의 (예를 들어, \"행복\"에 대응하는) 정서적 값들이 (엔티티들 간의 증가된 상호작용은, 그들이 친구 관계를 개발하고 있 다는 것을 의미할 수 있기 때문에) 수정될 수 있다는 것이 결정될 수 있다. 정서적 속성들과 연관된 성장 또는 감쇠 인자들은 또한, 인공 지능 엔티티와 하나 이상의 다른 엔티티 사이의 상호작용이 상호작용 임계값을 초과 했다는 결정에 기초하여 수정될 수 있다. 도 4는 하나 이상의 실시예에 따른, 자연 언어 입력에 기초하여 하나 이상의 성장 또는 감쇠 인자를 업데이트하 는 방법을 도시한다. 단계에서, 자연 언어 처리가, 예를 들어, 논리 및 문법의 규칙들을 적용함으로 써 획득된 자연 언어 입력에 대해 수행될 수 있다. 논리 및 문법의 규칙들을 적용함으로써, 자연 언어 서브시 스템은 복합 문장들을 분할하고, 주어/목적어/동사에서의 모호성들을 해결하고, 이들 컴포넌트들을 지식 데이터베이스 내로 파싱할 수 있다. 단계에서, 자연 언어 입력의 파싱된 컴포넌트들에 기초하여 하 나 이상의 정서적 개념이 획득될 수 있다. 정서적 개념들은 정서적 개념 데이터베이스로부터 획득될 수 있다. 정서적 개념 데이터베이스는 이미지들, 오디오, 비디오들, 및/또는 자연 언어와 연관된 핵심적인 정서적 개념들의 세트를 저장할 수 있다. 예를 들어, 핵심적인 정서적 개념들의 세트는 좋은, 나쁜, 위험한, 분노, 놀람, 사랑, 안전, 인내심, 신뢰, 걱정, 큰, 작은, 거칠은, 매끄러운, 위의, 아래의, 내부의, 외부의, 빠 른, 느린, 딱딱한, 부드러운, 높은, 낮은 등을 포함할 수 있다. 일례로서, 자연 언어 입력이 \"John died because of cancer\"인 경우, 정서적 개념 데이터베이스로부터 획득된 하나 이상의 정서적 개념은 \"나쁜\" 및/또는 \"걱정\"을 포함할 수 있다. 다른 예로서, 자연 언어 입력이 \"John climbed the mountain and was exhausted\"인 경우, 정서적 개념 데이터베이스로부터 획득된 하나 이상의 정서적 개념은 높은 에너지(예를 들어, John exerted great energy) 및 큰(예를 들어, mountains are large)을 포함할 수 있다. 전술한 정서적 개념들은 인간들이 인지하는 개념들과 유사하다. 예를 들어, 어린이가 개를 때릴 때, 부모는 \"that's bad!\"라 고 소리칠 수 있다. 어린이와 그의/그녀의 부모와의 그러한 상호작용에 기초하여, 어린이는 개를 때리는 것이 나쁜 것임을 이해할 수 있다. 유사하게, 그의/그녀의 장난감을 다른 어린이와 공유할 때, 부모는 \"good boy/girl\"이라고 말할 수 있다. 이것은 장난감들을 공유하는 것은 좋은 것임을 어린이에게 나타낼 것이다. 이 러한 방식으로, 어린이는 좋은, 나쁜, 위험한, 분노, 놀람, 사랑, 안전 등의 근본적인 개념들을 학습한다. 유 사하게, 정서적 개념 데이터베이스는 자연 언어 입력에 응답하여 정서적 개념 서브시스템에 의해 획 득될 수 있는 핵심적인 정서적 개념들의 세트를 저장할 수 있다. 일부 실시예들에서, (예를 들어, 산을 묘사하 는) 이미지가 입력으로서 수신될 때, 정서적 개념 서브시스템은 정서적 개념 데이터베이스로부터의 이미지와 연관되는 큰, 암석들, 나무들 등과 같은 정서적 개념들을 획득할 수 있다. 자연 언어 입력의 획득된 하나 이상의 정서적 개념에 부가하여, 자연 언어의 다른 정보가 또한 단계에서 획득될 수 있다. 자연 언어 입력의 다른 정보는 주어 시간적 감쇠 인자, 주어 지리적 감쇠 인자, 목적어 시간 적 감쇠 인자, 또는 목적어 지리적 감쇠 인자, 절의 타입, 절의 주어, 절의 주어 타입, 절의 주어 수식어, 절의 주어 수식어 타입, 절의 주어 수량, 주어 시간적 감쇠 인자, 주어 지리적 감쇠 인자, 절의 동사, 절의 동사 시 제, 절의 동사 수식어, 절의 목적어, 절의 목적어 타입, 절의 목적어 수식어, 절의 목적어 수식어 타입, 절의 목적어 수량, 목적어 시간적 감쇠 인자, 목적어 지리적 감쇠 인자, 절의 전치사, 절의 전치사 수식어, 또는 절 의 전역적 시간적 수식어를 포함할 수 있다. 또한, 단계에서, 인공 지능 엔티티의 하나 이상의 정서적 속성과 연관된 하나 이상의 성장 또는 감쇠 인자 는, 자연 언어 입력의 정서적 개념들 및 자연 언어 입력의 다른 정보에 기초하여 일정 시간 기간 동안 업데이트 될 수 있다. 예를 들어, 자연 언어 입력이 \"John died because of cancer\"인 경우, 정서적 개념 데이터베이스 로부터 획득된 하나 이상의 정서적 개념은 \"나쁜\" 및/또는 \"걱정\"을 포함할 수 있다. 그 결과, 슬픔, 분 노, 및/또는 행복과 같은, 인공 지능 엔티티의 (정서적 개념들에 관련될 수 있는) 하나 이상의 정서적 속성과 연관된 성장 또는 감쇠 인자들이 업데이트될 수 있다. 하나의 이용 사례에서, 도 2a에서의 정서적 속성 A는 인 공 지능 엔티티의 \"슬픔\"에 대응한다. 자연 언어 입력 \"John died because of cancer\"이 획득될 때, 인자 조 정 서브시스템은 정서적 속성 \"슬픔\"의 성장 인자를 업데이트하여 정서적 속성 \"슬픔\"의 정서적 값들(예를 들어, 207c-207f)이 (선형 또는 비선형일 수 있는) 업데이트된 성장 인자에 기초하여 증가할 수 있다. 다른 이 용 사례에서, 도 2b에서의 인공 지능 엔티티의 정서적 속성 B는 인공 지능 엔티티의 \"행복\"에 대응한다. 자연 언어 입력 \"John died because of cancer\"이 획득될 때, 인자 조정 서브시스템은 정서적 속성 \"행복\"의 감쇠 인자를 업데이트하여 정서적 속성 \"행복\"의 정서적 값들(예를 들어, 208c-208f)이 (선형 또는 비선형일 수있는) 업데이트된 감쇠 인자에 기초하여 감소할 수 있다. 또한, 전술한 바와 같이, 정서적 속성들의 정서적 값들은 일반적으로 임의의 입력의 부재 시에 및/또는 미리 결 정된 시간량 이후에 그들 각자의 베이스라인 값들로 다시 복귀(또는 리셋)한다는 것을 이해해야 한다. 예를 들 어, 도 2a에서 시간 c로부터 시간 f로 증가된 정서적 값들이 있지만, 정서적 값들이 정서적 베이스라인 을 향해 감소하기 시작하기 전에, 이러한 정서적 값들이 증가하는 임계량이 존재할 수 있다는 것을 이해해 야 한다. 정서적 값들(201 및 202)은, 성장 또는 감쇠 인자들에도 불구하고, 각각 정서적 베이스라인들(205 및 204) 아래로 가지 않는다. 일부 실시예들에서, 정서적 상태 서브시스템은 또한 하나 이상의 입력(및/또는 하나 이상의 정서적 개념)에 기초하여 정서적 베이스라인을 업데이트할 수 있다. 정서적 베이스라인(21 4)을 업데이트하는 것에 후속하여, 인공 지능 엔티티의 정서적 값들은 업데이트된 하나 이상의 성장 또는 감쇠 인자 및 업데이트된 정서적 베이스라인들에 기초하여 업데이트될 수 있다. 일부 실시예들에서, 자연 언어 입력의 정서적 개념들 및 자연 언어 입력의 다른 정보에 기초하여 성장 또는 감 쇠 인자들을 업데이트하는 것에 더하여, 성장 인자들은 신뢰 값 및/또는 확실성 값에 기초하여 업데이트될 수 있다. 예를 들어, 인공 지능 엔티티와 하나 이상의 다른 엔티티(예를 들어, 다른 인공 지능 엔티티, 클라이언 트 디바이스, 또는 입력의 임의의 다른 소스) 사이의 신뢰의 레벨을 나타내는 신뢰 값이 결정 및/또는 획 득될 수 있다. 신뢰 값은 인공 지능 엔티티와 다른 엔티티들 사이의 상호작용들의 수 및/또는 인공 지능 엔티 티와 다른 엔티티들 사이의 상호작용들의 내용에 기초하여 결정될 수 있다. 인자 조정 서브시스템은 신뢰 값에 기초하여 정서적 속성들과 연관된 성장 또는 감쇠 인자들을 수정할 수 있다. 또한, 자연 언어 입력에 의 해 표시된 이벤트와 연관된 확실성 값이 결정 및/또는 획득될 수 있다. 확실성 값은 이벤트와의 인공 지능 엔 티티의 확실성의 레벨을 나타낼 수 있다. 확실성 값은 이벤트가 자연 언어 입력에 의해 명시적으로 기술되는지 또는 자연 언어 입력 및/또는 신뢰 값으로부터 추론되는지에 기초하여 결정될 수 있다. 인자 조정 서브시스템 은 확실성 값에 기초하여 정서적 속성들과 연관된 성장 또는 감쇠 인자들을 수정할 수 있다. 도 5는 하나 이상의 실시예에 따른, 인공 지능 엔티티의 하나 이상의 정서적 베이스라인을 업데이트하는 방법 을 도시한다. 단계에서, 하나 이상의 정서적 베이스라인에 기초하여 일정 시간 기간 동안 인공 지능 엔티티의 정서적 값들의 세트가 연속적으로 업데이트될 수 있다. 일례로서, 정서적 베이스라인들은 정서적 값 들의 세트의 하나 이상의 정서적 값이 (예를 들어, 인공 지능 엔티티의 하나 이상의 성장 또는 감쇠 인자에도 불구하고) 넘지 않는 베이스라인들을 포함할 수 있다. 단계에서, 일정 시간 기간 동안 입력이 획득될 수 있다. 논의된 바와 같이, 입력은 클라이언트 디바이스 , 다른 인공 지능 엔티티로부터, 및/또는 시스템 내의 또는 외부의 임의의 소스로부터 획득될 수 있 다. 입력은 자연 언어 입력, 오디오 입력, 이미지 입력, 비디오 입력, 또는 다른 입력을 포함할 수 있다. 단 계에서, 입력과 관련된 응답이 생성될 수 있다. 이러한 응답은 인공 지능 엔티티의 연속적으로 업데이트 된 정서적 값들의 세트에 기초할 수 있다. 예를 들어, 자연 언어 입력이 \"John died because of cancer\"인 경 우, 응답 생성 서브시스템에 의해 생성된 (예를 들어, 그러한 입력과 관련된) 응답은 \"That is unfortunate\", 또는 \"This is sad. I need a moment\"를 포함할 수 있다. 단계에서, 인공 지능 엔티티의 정서적 베이스라인들은 입력에 기초하여 일정 시간 기간 동안 업데이트될 수 있다. 이용 사례에서, 도 2c에서의 인공 지능 엔티티의 정서적 속성 C는 인공 지능 엔티티의 \"행복\"에 대응 할 수 있다. 자연 언어 입력 \"John died because of cancer\"가 획득될 때, 정서적 상태 서브시스템은 그 러한 입력에 기초하여 (정서적 속성 C에 대응하는) 정서적 베이스라인을 업데이트할 수 있다. 도 2c는 입 력에 기초한 정서적 베이스라인에서의 감소를 도시하지만, 정서적 베이스라인은 정서적 베이스라인 을 증가시킴으로써 업데이트될 수 있다는 것을 이해해야 한다. 단계에서, 정서적 베이스라인들(예를 들어, 도 2c에서의 정서적 베이스라인)의 업데이트에 후속하여, 정서적 값들의 세트는 업데이트된 정서적 베이스라인들에 기초하여 일정 시간 기간 동안 연속적으로 업데이트될 수 있다. 도 2c에 도시된 바와 같이, 정서적 베이스라인의 업데이트에 후속하여, 정서적 값들(예를 들어, 정서적 값들 218e 및 218f)은 업데이트된 정서적 베이스라인에 기초하여 업데이트될 수 있다. 일부 실시예들에서, 도 1에 도시된 다양한 컴퓨터들 및 서브시스템들은 본 명세서에서 설명된 기능들을 수행하 도록 프로그래밍되는 하나 이상의 컴퓨팅 디바이스를 포함할 수 있다. 컴퓨팅 디바이스들은 하나 이상의 전자 스토리지(예를 들어, 지식 데이터베이스, 성장/감쇠 인자 데이터베이스, 정서적 개념 데이터베이스 , 전술한 다른 데이터베이스들, 또는 다른 전기 스토리지들), 하나 이상의 컴퓨터 프로그램 명령어로 프로 그래밍된 하나 이상의 물리적 프로세서, 및/또는 다른 컴포넌트들을 포함할 수 있다. 컴퓨팅 디바이스들은 유선 또는 무선 기술들(예를 들어, 이더넷, 광섬유, 동축 케이블, WiFi, 블루투스, 근거리 통신, 또는 다른 기술 들)을 통해 네트워크(예를 들어, 네트워크) 또는 다른 컴퓨팅 플랫폼들과의 정보 교환을 가능하게 하는 통 신 라인들 또는 포트들을 포함할 수 있다. 컴퓨팅 디바이스들은 함께 동작하는 복수의 하드웨어, 소프트웨어 및/또는 펌웨어 컴포넌트들을 포함할 수 있다. 예를 들어, 컴퓨팅 디바이스들은 컴퓨팅 디바이스들로서 함께 동작하는 컴퓨팅 플랫폼들의 클라우드에 의해 구현될 수 있다. 전자 스토리지들은 정보를 전자적으로 저장하는 비일시적 저장 매체를 포함할 수 있다. 전자 스토리지들의 전 자 저장 매체는, (i) 서버들 또는 클라이언트 디바이스들과 일체로 제공되는(예를 들어, 실질적으로 비착탈식의) 시스템 스토리지, 또는 (ii) 예를 들어, 포트(예를 들어, USB 포트, 파이어와이어 포트(firewire port) 등) 또는 드라이브(예를 들어, 디스크 드라이브 등)를 통해 서버들 또는 클라이언트 디바이스들에 착탈식 으로 접속가능한 착탈식 스토리지 중 하나 또는 둘다를 포함할 수 있다. 전자 스토리지들은 하나 이상의 광학 적으로 판독가능한 저장 매체(예를 들어, 광학 디스크들 등), 자기적으로 판독가능한 저장 매체(예를 들어, 자 기 테이프, 자기 하드 드라이브, 플로피 드라이브 등), 전기 전하 기반 저장 매체(예를 들어, EEPROM, RAM 등), 고체 상태 저장 매체(예를 들어, 플래시 드라이브 등), 및/또는 다른 전자적으로 판독가능한 저장 매체를 포함 할 수 있다. 전자 스토리지들은 하나 이상의 가상 저장 리소스들(예를 들어, 클라우드 스토리지, 가상 사설 네 트워크, 및/또는 다른 가상 저장 리소스들)을 포함할 수 있다. 전자 스토리지는 소프트웨어 알고리즘들, 프로 세서들에 의해 결정된 정보, 서버들로부터 획득된 정보, 클라이언트 디바이스들로부터 획득된 정보, 또는 본 명 세서에 설명된 바와 같은 기능을 가능하게 하는 다른 정보를 저장할 수 있다. 프로세서들은 컴퓨팅 디바이스들에 정보 처리 능력들을 제공하도록 프로그래밍될 수 있다. 그와 같이, 프로세 서들은 디지털 프로세서, 아날로그 프로세서, 정보를 처리하도록 설계된 디지털 회로, 정보를 처리하도록 설계 된 아날로그 회로, 상태 머신, 및/또는 정보를 전자적으로 처리하는 다른 메커니즘들 중 하나 이상을 포함할 수 있다. 일부 실시예들에서, 프로세서들은 복수의 처리 유닛들을 포함할 수 있다. 이러한 처리 유닛들은 동일한 디바이스 내에 물리적으로 위치할 수 있거나, 또는 프로세서들은 협동하여 동작하는 복수의 디바이스들의 처리 기능을 나타낼 수 있다. 프로세서들은 서브시스템들(112 내지 124) 또는 다른 서브시스템들의 본 명세서에 설 명된 기능들을 수행하기 위해 컴퓨터 프로그램 명령어들을 실행하도록 프로그래밍될 수 있다. 프로세서들은 소 프트웨어; 하드웨어; 펌웨어; 소프트웨어, 하드웨어, 또는 펌웨어의 소정의 조합; 및/또는 프로세서들 상에 처 리 능력들을 구성하는 다른 메커니즘들에 의해 컴퓨터 프로그램 명령어들을 실행하도록 프로그래밍될 수 있다. 본 명세서에 설명된 상이한 서브시스템들(112-124)에 의해 제공되는 기능의 설명은 예시의 목적들을 위한 것이 며, 서브시스템들(112-124) 중 임의의 것은 설명된 것보다 더 많거나 또는 더 적은 기능을 제공할 수 있기 때문 에, 제한하는 것으로 의도되지 않는다는 것을 이해해야 한다. 예를 들어, 서브시스템들(112-124) 중 하나 이상 은 제거될 수 있고, 그 기능의 일부 또는 전부는 서브시스템들(112-124) 중 다른 것들에 의해 제공될 수 있다. 다른 예로서, 추가적인 서브시스템들이 본 명세서에서 서브시스템들(112-124) 중 하나에 기인하는 기능의 일부 또는 전부를 수행하도록 프로그래밍될 수 있다. 본 발명은 현재 가장 실용적이고 바람직한 실시예들인 것으로 고려되는 것에 기초하여 예시의 목적으로 상세히 설명되었지만, 그러한 상세는 단지 그러한 목적만을 위한 것이고, 본 발명은 개시된 실시예들로 제한되지 않으 며, 반대로, 첨부된 청구항들의 범위 내에 있는 수정들 및 등가의 배열들을 커버하도록 의도된다는 것을 이해해 야 할 것이다. 예를 들어, 본 발명은 가능한 한도에서 임의의 실시예의 하나 이상의 특징이 임의의 다른 실시 예의 하나 이상의 특징과 결합될 수 있는 것으로 고려한다는 것을 이해해야 한다. 본 기술들은 다음의 열거된 실시예들을 참조하여 더 잘 이해될 것이다. 1. 방법으로서, 일정 시간 기간 동안 인공 지능 엔티티의 정서적 값들의 세트를 업데이트하는 단계; 그러한 시 간 기간 동안 입력을 획득하는 단계; 및 인공 지능 엔티티의 업데이트된 정서적 값들의 세트에 기초하여 입력과 관련된 응답을 생성하는 단계를 포함하는, 방법. 2. 실시예 1의 방법으로서, 인공 지능 엔티티의 정서적 속성들의 세트에 대한 하나 이상의 성장 또는 감쇠 인자 를 결정하는 단계―정서적 속성들의 세트는 인공 지능 엔티티의 정서적 값들의 세트와 연관됨―; 및 하나 이상 의 성장 또는 감쇠 인자에 기초하여, 상기 시간 기간 동안 인공 지능 엔티티의 정서적 값들의 세트를 업데이트 하는 단계를 더 포함하는, 방법. 3. 실시예 2의 방법으로서, 입력에 기초하여, 상기 시간 기간 동안 하나 이상의 성장 또는 감쇠 인자를 업데이 트하는 단계를 더 포함하고, 하나 이상의 성장 또는 감쇠 인자의 업데이트에 후속하여, 정서적 값들의 세트를업데이트하는 단계는 하나 이상의 업데이트된 성장 또는 감쇠 인자에 기초하여 상기 시간 기간 동안 정서적 값 들의 세트를 업데이트하는 단계를 포함하는, 방법. 4. 실시예 3의 방법으로서, 하나 이상의 성장 또는 감쇠 인자의 업데이트에 후속하여 다른 입력을 획득하는 단 계; 및 하나 이상의 성장 또는 감쇠 인자의 업데이트에 후속하여, 인공 지능 엔티티의 업데이트된 정서적 값들 의 세트에 기초하여 다른 입력과 관련된 응답을 생성하는 단계를 더 포함하는, 방법. 5. 실시예 3 내지 실시예 4 중 어느 하나의 방법으로서, 입력에 기초하여, 하나 이상의 성장 또는 감쇠 인자에 도 불구하고, 정서적 값들의 세트의 하나 이상의 정서적 값이 넘지 않는 하나 이상의 정서적 베이스라인을 업데 이트하는 단계를 더 포함하고, 하나 이상의 정서적 베이스라인의 업데이트에 후속하여, 정서적 값들의 세트를 업데이트하는 단계는 하나 이상의 업데이트된 성장 또는 감쇠 인자 및 하나 이상의 업데이트된 정서적 베이스라 인에 기초하여 상기 시간 기간 동안 인공 지능 엔티티의 정서적 값들의 세트를 업데이트하는 단계를 포함하는, 방법. 6. 실시예 5의 방법으로서, 소스로부터 자연 언어 입력을 획득하는 단계; 및 상기 시간 기간 동안 자연 언어 입 력의 하나 이상의 정서적 개념 및 자연 언어 입력의 다른 정보를 입력으로서 획득하기 위해 자연 언어 입력의 자연 언어 처리를 수행하는 단계를 더 포함하고, 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계는 (i) 자연 언어 입력의 하나 이상의 정서적 개념 및 (ii) 자연 언어 입력의 다른 정보에 기초하여 상기 시간 기간 동 안 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계를 포함하는, 방법. 7. 실시예 5 내지 실시예 6 중 어느 하나의 방법으로서, 자연 언어 입력의 다른 정보는 절의 타입, 절의 주어, 절의 주어 타입, 절의 주어 수식어, 절의 주어 수식어 타입, 절의 주어 수량, 주어 시간적 감쇠 인자, 주어 지 리적 감쇠 인자, 절의 동사, 절의 동사 시제, 절의 동사 수식어, 절의 목적어, 절의 목적어 타입, 절의 목적어 수식어, 절의 목적어 수식어 타입, 절의 목적어 수량, 목적어 시간적 감쇠 인자, 목적어 지리적 감쇠 인자, 절 의 전치사, 절의 전치사 수식어, 또는 절의 전역적 시간적 수식어를 나타내는, 방법. 8. 실시예 5 내지 실시예 7 중 어느 하나의 방법으로서, 자연 언어 입력의 다른 정보는 주어 시간적 감쇠 인자, 주어 지리적 감쇠 인자, 목적어 시간적 감쇠 인자, 또는 목적어 지리적 감쇠 인자를 나타내는, 방법. 9. 실시예 5 내지 실시예 8 중 어느 하나의 방법으로서, 소스와 연관된 신뢰 값을 결정하는 단계―신뢰 값은 소 스와의 인공 지능 엔티티의 신뢰의 레벨을 나타냄―를 더 포함하고, 입력을 획득하는 단계는, 입력으로서, (i) 자연 언어 입력의 하나 이상의 정서적 개념, (ii) 소스와 연관된 신뢰 값, 및 (iii) 자연 언어 입력의 다른 정 보를 획득하는 단계를 포함하고, 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계는 (ⅰ) 자연 언어 입력 의 하나 이상의 정서적 개념, (ii) 소스와 연관된 신뢰 값, 및 (iii) 자연 언어 입력의 다른 정보에 기초하여 상기 시간 기간 동안 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계를 포함하는, 방법. 10. 실시예 5 내지 실시예 9 중 어느 하나의 방법으로서, 자연 언어 입력에 의해 표시된 이벤트와 연관된 확실 성 값을 결정하는 단계―확실성 값은 (i) 이벤트가 자연 언어 입력에 의해 명시적으로 기술되는지 또는 자연 언 어 입력으로부터 추론되는지, 및 (ii) 소스와 연관된 신뢰 값에 기초하여 결정되고, 확실성 값은 이벤트와의 인 공 지능 엔티티의 확실성의 레벨을 나타냄―를 더 포함하고, 입력을 획득하는 단계는, 입력으로서, (i) 자연 언 어 입력의 하나 이상의 정서적 개념, (ii) 이벤트와 연관된 확실성 값, (iii) 소스와 연관된 신뢰 값, 및 (iv) 자연 언어 입력의 다른 정보를 획득하는 단계를 포함하고, 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단 계는, (i) 자연 언어 입력의 하나 이상의 정서적 개념, (ii) 이벤트와 연관된 확실성 값, (iii) 소스와 연관된 신뢰 값, 및 (iv) 자연 언어 입력의 다른 정보에 기초하여 상기 시간 기간 동안 하나 이상의 성장 또는 감쇠 인 자를 업데이트하는 단계를 포함하는, 방법. 11. 실시예 3 내지 실시예 10 중 어느 하나의 방법으로서, 하나 이상의 성장 또는 감쇠 인자를 결정하는 단계는 인공 지능 엔티티의 정서적 속성들의 세트에 대한 하나 이상의 감쇠 인자를 결정하는 단계를 포함하고, 정서적 값들의 세트를 업데이트하는 단계는, 하나 이상의 감쇠 인자에 기초하여, 상기 시간 기간 동안 인공 지능 엔티 티의 정서적 값들의 세트를 업데이트하는 단계를 포함하고, 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계는, 입력에 기초하여, 상기 시간 기간 동안 하나 이상의 감쇠 인자를 업데이트하는 단계를 포함하고, 하나 이상의 감쇠 인자의 업데이트에 후속하여, 정서적 값들의 세트를 업데이트하는 단계는 하나 이상의 업데이트된 감쇠 인자에 기초하여 상기 시간 기간 동안 인공 지능 엔티티의 정서적 값들의 세트를 업데이트하는 단계를 포 함하는, 방법. 12. 실시예 3 내지 실시예 10 중 어느 하나의 방법으로서, 하나 이상의 성장 또는 감쇠 인자를 결정하는 단계는 인공 지능 엔티티의 정서적 속성들의 세트에 대한 하나 이상의 성장 인자를 결정하는 단계를 포함하고, 정서적 값들의 세트를 업데이트하는 단계는, 하나 이상의 성장 인자에 기초하여, 상기 시간 기간 동안 인공 지능 엔티 티의 정서적 값들의 세트를 업데이트하는 단계를 포함하고, 하나 이상의 성장 또는 감쇠 인자를 업데이트하는 단계는, 입력에 기초하여, 상기 시간 기간 동안 하나 이상의 성장 인자를 업데이트하는 단계를 포함하고, 하나 이상의 성장 인자의 업데이트에 후속하여, 정서적 값들의 세트를 업데이트하는 단계는 하나 이상의 업데이트된 성장 인자에 기초하여 상기 시간 기간 동안 인공 지능 엔티티의 정서적 값들의 세트를 업데이트하는 단계를 포 함하는, 방법. 13. 실시예 1 내지 실시예 12 중 어느 하나의 방법으로서, 입력과 관련된 응답을 생성하는 단계는 입력으로부터 도출되는 인공 지능 엔티티의 업데이트된 정서적 값들의 세트에 기초하여 응답을 생성하는 단계를 포함하는, 방 법. 14. 실시예 1 내지 실시예 13 중 어느 하나의 방법으로서, 입력의 내용을 처리하여 인공 지능 엔티티의 하나 이 상의 정서적 속성에 대한 내용의 부분들의 영향과 관련된 하나 이상의 영향 값을 결정하는 단계; 하나 이상의 영향 값이 인공 지능 엔티티의 하나 이상의 정서적 속성과 연관된 하나 이상의 정서적 값에서의 증가 또는 감소 를 트리거하기 위한 미리 결정된 임계값을 만족시키는지를 결정하는 단계; 및 상기 시간 기간 동안, 하나 이상 의 영향 값이 미리 결정된 임계값을 만족시킨다는 결정에 기초하여 인공 지능 엔티티의 하나 이상의 정서적 값 의 수정을 야기하는 단계를 더 포함하는, 방법. 15. 실시예 1 내지 실시예 14 중 어느 하나의 방법으로서, 인공 지능 엔티티와 적어도 하나의 다른 엔티티 사이 의 상호작용 임계값이 주어진 시간 기간 내에 발생했는지를 결정하는 단계; 및 상호작용 임계값이 만족되었는지 의 결정에 기초하여 인공 지능 엔티티의 정서적 값들의 세트의 수정을 야기하는 단계를 더 포함하는, 방법. 16. 실시예 1 내지 실시예 15 중 어느 하나의 방법으로서, 정서적 값들의 세트를 업데이트하는 단계는, 하나 이 상의 성장 또는 감쇠 인자에 기초하여, 상기 시간 기간 동안 인공 지능 엔티티의 정서적 값들의 세트를 연속적 으로 업데이트하는 단계를 포함하는, 방법. 17. 실시예 16의 방법으로서, 정서적 값들의 세트를 연속적으로 업데이트하는 단계는, 하나 이상의 성장 또는 감쇠 인자에 기초하여, 상기 시간 기간 동안 인공 지능 엔티티의 정서적 값들의 세트를 주기적으로 업데이트하 는 단계를 포함하는, 방법. 18. 실시예 1 내지 실시예 17 중 어느 하나의 방법으로서, 응답을 생성하는 단계는 인공 지능 엔티티와 연관된 하나 이상의 신경망의 하나 이상의 임베딩 벡터에 기초하여 입력과 관련된 응답을 생성하는 단계를 포함하는, 방법. 19. 실시예 1 내지 실시예 18 중 어느 하나의 방법으로서, 정서적 값들의 세트, 하나 이상의 성장 또는 감쇠 인 자, 또는 하나 이상의 정서적 베이스라인을 업데이트하는 단계는 인공 지능 엔티티와 연관된 하나 이상의 신경 망의 하나 이상의 임베딩 벡터에 기초하는, 방법. 20. 실시예 1 내지 실시예 19 중 어느 하나의 방법으로서, 입력을 나타내는 입력 임베딩 벡터를 획득하기 위해, 임베딩 네트워크를 통해, 입력을 처리하는 단계; 그래프로부터 제1 임베딩 벡터를 획득하는 단계―제1 임베딩 벡터는 업데이트된 정서적 값들의 세트의 하나 이상의 정서적 값을 나타냄―; 및 입력 임베딩 벡터 및 제1 임베 딩 벡터에 기초하여 입력과 관련된 응답을 생성하는 단계를 더 포함하는, 방법. 21. 실시예 20의 방법으로서, 그래프는 노드들을 포함하고, 노드들은 (i) 정서적 속성들 또는 연관된 정서적 값 들을 나타내는 하나 이상의 노드 및 (ii) 정서적 개념들 또는 다른 개념들을 나타내는 하나 이상의 노드를 포함 하는, 방법. 22. 실시예 21의 방법으로서, 그래프의 노드들은 나타내진 정서적 속성들, 연관된 정서적 값들, 정서적 개념들, 또는 다른 개념들과 관련된 컨텍스트 정보를 나타내는 하나 이상의 노드를 더 포함하는, 방법. 23. 실시예 21 내지 실시예 22 중 어느 하나의 방법으로서, 그래프의 노드들은 그래프의 서브그래프 또는 다른 노드를 각각 나타내는 임베딩 벡터들을 나타내는 하나 이상의 노드를 더 포함하는, 방법. 24. 실시예 23의 방법으로서, 임베딩 벡터들의 각각의 임베딩 벡터는 임베딩 벡터들에 의해 나타내진 서브그래 프 또는 다른 노드에 직접 접속되는, 방법. 25. 실시예 21 내지 실시예 24 중 어느 하나의 방법으로서, 그래프의 노드들은 인공 지능 엔티티를 향한 하나 이상의 엔티티의 감정과 관련된 임베딩 벡터들을 나타내는 하나 이상의 노드를 더 포함하는, 방법. 26. 실시예 25의 방법으로서, 입력과 관련된 응답을 생성하는 단계는 (i) 입력 임베딩 벡터, (ii) 제1 임베딩 벡터, 및 (iii) 인공 지능 엔티티를 향한 다른 엔티티의 감정과 관련된 임베딩 벡터를 나타내는 적어도 하나의 노드에 기초하여 관련된 응답을 생성하는 단계를 포함하는, 방법. 27. 데이터 처리 장치에 의해 실행될 때, 데이터 처리 장치로 하여금, 실시예 1 내지 실시예 26 중 임의의 것들 을 포함하는 동작들을 수행하게 하는 명령어들을 저장하는 유형의 비일시적 머신 판독가능 매체. 28. 시스템으로서, 하나 이상의 프로세서; 및 프로세서들에 의해 실행될 때, 프로세서들로 하여금, 실시예 1 내 지 실시예 26 중 임의의 것들을 포함하는 동작들을 수행하게 하는 명령어들을 저장하는 메모리를 포함하는, 시 스템."}
{"patent_id": "10-2020-7024973", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 하나 이상의 실시예에 따른, 정서적 상태 기반 인공 지능 또는 다른 인공 지능을 용이하게 하기 위한 시 스템을 도시한다. 도 2a 및 도 2b는 하나 이상의 실시예에 따른, 정서적 속성들과 연관된 정서적 값들 및 정서적 베이스라인들을 도시하는 그래프들을 도시한다. 도 2c는 하나 이상의 실시예에 따른, 정서적 속성들과 연관된 정서적 값들 및 정서적 베이스라인들의 업데이트 를 도시하는 그래프를 도시한다. 도 3은 하나 이상의 실시예에 따른, 정서적 상태 기반 인공 지능을 용이하게 하는 방법의 흐름도를 도시한다. 도 4는 하나 이상의 실시예에 따른, 자연 언어 입력에 기초하여 하나 이상의 성장 또는 감쇠 인자를 업데이트하 는 방법의 흐름도를 도시한다. 도 5는 하나 이상의 실시예에 따른, 인공 지능 엔티티의 하나 이상의 정서적 베이스라인을 업데이트하는 방법의 흐름도를 도시한다."}
