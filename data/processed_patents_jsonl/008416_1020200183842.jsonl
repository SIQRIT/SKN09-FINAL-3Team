{"patent_id": "10-2020-0183842", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0092247", "출원번호": "10-2020-0183842", "발명의 명칭": "전자 장치 및 이의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "진보라"}}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 제어 방법에 있어서,서로 다른 시점(view point)의 제1 LF 영상을 획득하는 단계;제1 인공지능 모델에 상기 제1 LF 영상을 입력하여 상기 제1 LF 영상 내 픽셀들을 변환하기 위한 픽셀 이동 값을 획득하는 단계;상기 제1 LF 영상 내의 픽셀들을 상기 픽셀 이동 값에 따라 변환하여 제2 LF 영상을 획득하는 단계;LF 영상을 레이어 영상으로 변환하기 위한 제2 인공지능 모델에 상기 제1 LF 영상 및 상기 제2 LF 영상을 입력하여 레이어 영상을 획득하는 단계;상기 LF 영상을 복원하기 위한 시뮬레이션 모델에 상기 획득한 레이어 영상을 입력하여 제3 LF 영상을 획득하는단계; 및상기 제2 LF 영상과 상기 제3 LF 영상을 바탕으로 상기 제1 인공지능 모델 및 제2 인공지능 모델을 학습시키는단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제2 LF 영상을 획득하는 단계는,상기 제1 LF 영상에 포함된 복수의 뷰 영상 각각에 대응되는 픽셀 이동 값에 따라 상기 복수의 뷰 영상 각각의픽셀을 이동시켜 상기 제2 LF 영상을 획득하는 단계인 제어 방법."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제2 LF 영상을 획득하는 단계는,상기 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀들을 상기 제1 뷰 영상에 대응되는 제1 픽셀 이동 값에 따라 이동시켜, 상기 제2 LF 영상의 제1 뷰 영상을 획득하는 단계를 포함하는 제어 방법."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 픽셀 이동 값은 픽셀 각각에 대응되는 서브 픽셀 이동 값들을 포함하며, 상기 제2 LF 영상의 제1 뷰 영상을 획득하는 단계는,상기 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀 각각을 상기 제1 픽셀 이동 값에 포함된 서브 픽셀 이동 값에따라 이동시켜, 상기 제2 LF 영상의 제1 뷰 영상을 획득하는 단계인 제어 방법."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2022-0092247-3-제1항에 있어서,상기 레이어 영상을 획득하는 단계는,제2 인공지능 모델에 상기 제1 LF 영상, 상기 제2 LF 영상 및 상기 픽셀 이동 값을 입력하여 상기 레이어 영상을 획득하는 단계인 제어 방법."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 레이어 영상은 제1 레이어 영상, 제2 레이어 영상 및 제3 레이어 영상을 포함하고,상기 제3 LF 영상을 획득하는 단계는,상기 제1 레이어 영상 및 상기 제3 레이어 영상 각각을 시점 별로 시프팅하는 단계;상기 시프팅된 제1 레이어 영상 및 상기 시프팅된 제3 레이어 영상을 상기 제2 레이어 영상과 함께 크롭하여 상기 제3 LF 영상을 획득하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 학습시키는 단계는상기 제2 LF 영상과 상기 제3 LF 영상을 비교하여 손실 함수를 획득하는 단계; 및상기 손실 함수를 바탕으로 상기 제1 인공지능 모델 및 제2 인공지능 모델을 학습시키는 단계를 포함하는 제어방법."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 제1 LF 영상을 상기 학습된 제1 인공지능 모델에 입력하여, 픽셀 이동 값을 획득하는 단계;상기 제1 LF 영상 내의 픽셀들을 상기 픽셀 이동 값에 따라 변환하여 제2 LF 영상을 획득하는 단계; 및상기 제1 LF 영상 및 상기 제2 LF 영상을 상기 학습된 제2 인공지능 모델에 입력하여 레이어 영상을 획득하는단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 제1 LF 영상을 상기 학습된 제1 인공지능 모델에 입력하여, 픽셀 이동 값을 획득하는 단계;상기 제1 LF 영상 및 상기 픽셀 이동 값을 상기 학습된 제2 인공지능 모델에 입력하여 레이어 영상을 획득하는단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,공개특허 10-2022-0092247-4-상기 레이어 영상을 적층형 디스플레이에 제공하는 단계를 더 포함하는 제어 방법."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치에 있어서,적어도 하나의 인스트럭션을 저장하는 메모리;상기 메모리에 저장된 적어도 하나의 인스트럭션을 실행하여 상기 전자 장치를 제어하는 프로세서를 포함하고,상기 프로세서는,서로 다른 시점(view point)의 제1 LF 영상을 획득하고,제1 인공지능 모델에 상기 제1 LF 영상을 입력하여 상기 제1 LF 영상 내 픽셀들을 변환하기 위한 픽셀 이동 값을 획득하고,상기 제1 LF 영상 내의 픽셀들을 상기 픽셀 이동 값에 따라 변환하여 제2 LF 영상을 획득하고,LF 영상을 레이어 영상으로 변환하기 위한 제2 인공지능 모델에 상기 제1 LF 영상 및 상기 제2 LF 영상을 입력하여 레이어 영상을 획득하고,상기 LF 영상을 복원하기 위한 시뮬레이션 모델에 상기 획득한 레이어 영상을 입력하여 제3 LF 영상을획득하고,상기 제2 LF 영상과 상기 제3 LF 영상을 바탕으로 상기 제1 인공지능 모델 및 제2 인공지능 모델을 학습시키는전자 장치."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는,상기 제1 LF 영상에 포함된 복수의 뷰 영상 각각에 대응되는 픽셀 이동 값에 따라 상기 복수의 뷰 영상 각각의픽셀을 이동시켜 상기 제2 LF 영상을 획득하는 전자 장치."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는,상기 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀들을 상기 제1 뷰 영상에 대응되는 제1 픽셀 이동 값에 따라 이동시켜, 상기 제2 LF 영상의 제1 뷰 영상을 획득하는 전자 장치."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 픽셀 이동 값은 픽셀 각각에 대응되는 서브 픽셀 이동 값들을 포함하며, 상기 프로세서는,상기 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀 각각을 상기 제1 픽셀 이동 값에 포함된 서브 픽셀 이동 값에따라 이동시켜, 상기 제2 LF 영상의 제1 뷰 영상을 획득하는 전자 장치.공개특허 10-2022-0092247-5-청구항 15 제11항에 있어서,상기 프로세서는,상기 제2 인공지능 모델에 상기 제1 LF 영상, 상기 제2 LF 영상 및 상기 픽셀 이동 값을 입력하여 상기 레이어영상을 획득하는 전자 장치."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 레이어 영상은 제1 레이어 영상, 제2 레이어 영상 및 제3 레이어 영상을 포함하고,상기 프로세서는,상기 제1 레이어 영상 및 상기 제3 레이어 영상 각각을 시점 별로 시프팅하고,상기 시프팅된 제1 레이어 영상 및 상기 시프팅된 제3 레이어 영상을 상기 제2 레이어 영상과 함께 크롭하여 상기 제3 LF 영상을 획득하는 전자 장치."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 프로세서는,상기 제2 LF 영상과 상기 제3 LF 영상을 비교하여 손실 함수를 획득하고,상기 손실 함수를 바탕으로 상기 제1 인공지능 모델 및 제2 인공지능 모델을 학습시키는 전자 장치."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 프로세서는,상기 제1 LF 영상을 상기 학습된 제1 인공지능 모델에 입력하여, 픽셀 이동 값을 획득하고,상기 제1 LF 영상 내의 픽셀들을 상기 픽셀 이동 값에 따라 변환하여 제2 LF 영상을 획득하고,상기 제1 LF 영상 및 상기 제2 LF 영상을 상기 학습된 제2 인공지능 모델에 입력하여 레이어 영상을 획득하는전자 장치."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 프로세서는,상기 제1 LF 영상을 상기 학습된 제1 인공지능 모델에 입력하여, 픽셀 이동 값을 획득하고,상기 제1 LF 영상 및 상기 픽셀 이동 값을 상기 학습된 제2 인공지능 모델에 입력하여 레이어 영상을 획득하는전자 장치."}
{"patent_id": "10-2020-0183842", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2022-0092247-6-제18항에 있어서,상기 프로세서는,상기 레이어 영상을 적층형 디스플레이에 제공하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2020-0183842", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치 및 이의 제어 방법이 개시된다. 본 개시에 따른 전자 장치의 제어 방법은 서로 다른 시점(view poin t)의 제1 LF 영상을 획득하는 단계; 제1 인공지능 모델에 제1 LF 영상을 입력하여 제1 LF 영상 내 픽셀들을 변환 하기 위한 픽셀 이동 값을 획득하는 단계; 제1 LF 영상 내의 픽셀들을 픽셀 이동 값에 따라 변환하여 제2 LF 영 상을 획득하는 단계; LF 영상을 레이어 영상으로 변환하기 위한 제2 인공지능 모델에 제1 LF 영상 및 제2 LF 영 상을 입력하여 레이어 영상을 획득하는 단계; LF 영상을 복원하기 위한 시뮬레이션 모델에 획득한 레이어 영상을 입력하여 제3 LF 영상을 획득하는 단계; 제2 LF 영상과 제3 LF 영상을 바탕으로 제1 인공지능 모델 및 제2 인공 지능 모델을 학습시키는 단계;를 포함한다."}
{"patent_id": "10-2020-0183842", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 이의 제어 방법에 관한 것으로, 보다 상세하게는 적층형 디스플레이 장치에 제공되는 영상을 획득하기 위한 전자 장치 및 이의 제어 방법을 제공한다."}
{"patent_id": "10-2020-0183842", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래에는 영상의 입체감을 표현하기 위해 적층형 디스플레이(Stacked display) 장치를 이용하여 영상을 표시하 는 방법이 제안되었다. 적층형 디스플레이 장치는 2개 이상의 디스플레이 패널이 적층되어 구현될 수 있으며, 2 개 이상의 디스플레이 패널 각각에 영상이 표시되어 3차원 뎁스가 반영된 영상을 제공할 수 있다. 다만, 종래의 적층형 디스플레이 장치의 경우, 표현할 수 있는 뎁스 범위에 한계가 있었으며, 뎁스 범위를 벗어 나는 LF 영상을 통해 영상이 제공되는 경우, LF 영상 내 뎁스 범위를 벗어나는 영역의 화질, 해상도 또는 시야 각의 표현 품질이 저하되는 문제점이 발생될 수 있었다. 여기서 뎁스 범위란 3차원 영상에서 표현할 수 있는 영 상 내 오브젝트 간의 실제 거리 범위이며, 뎁스란 3차원 영상 내 오브젝트가 가까운 정도를 의미한다. 적층형 디스플레이의 패널의 개수만큼 대응되는 레이어 영상으로만 3차원 뎁스를 표현하려는 경우, 영상 내 모든 오브 젝트들을 표현할 수 없는 문제점이 생길 수 있다. 즉, 영상 내 상대적으로 가까이에 있는 오브젝트의 표현 품질 을 향상 시키기 위해서는 영상 내 상대적으로 멀리 있는 오브젝트의 표현 품질이 감소될 수 밖에 없다. 따라서, 종래에는 하나의 레이어 영상에서 표현할 수 있는 영상 내 오브젝트 간의 거리 범위가 한정적일 수 밖에 없게 된다."}
{"patent_id": "10-2020-0183842", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에, 본 개시는 LF 영상을 적층형 디스플레이 장치에 적합하도록 변환시킨 LF 영상을 이용하여 적층형 디스플 레이 장치에 제공되는 영상을 획득하는 전자 장치 및 이의 제어 방법을 제공한다."}
{"patent_id": "10-2020-0183842", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 상술한 목적을 달성하기 위한 일 실시 예에 따른, 전자 장치의 제어 방법은 서로 다른 시점(view point)의 제1 LF 영상을 획득하는 단계; 제1 인공지능 모델에 상기 제1 LF 영상을 입력하여 상기 제1 LF 영상 내 픽셀들을 변환하기 위한 픽셀 이동 값을 획득하는 단계; 상기 제1 LF 영상 내의 픽셀들을 상기 픽셀 이동 값 에 따라 변환하여 제2 LF 영상을 획득하는 단계; LF 영상을 레이어 영상으로 변환하기 위한 제2 인공지능 모델 에 상기 제1 LF 영상 및 상기 제2 LF 영상을 입력하여 레이어 영상을 획득하는 단계; 상기 LF 영상을 복원하기 위한 시뮬레이션 모델에 상기 획득한 레이어 영상을 입력하여 제3 LF 영상을 획득하는 단계; 상기 제2 LF 영상 과 상기 제3 LF 영상을 바탕으로 상기 제1 인공지능 모델 및 제2 인공지능 모델을 학습시키는 단계;를 포함한다. 그리고, 상기 제2 LF 영상을 획득하는 단계는, 상기 제1 LF 영상에 포함된 복수의 뷰 영상 각각에 대응되는 픽 셀 이동 값에 따라 상기 복수의 뷰 영상 각각의 픽셀을 이동시켜 상기 제2 LF 영상을 획득하는 단계일 수 있다. 그리고, 상기 제2 LF 영상을 획득하는 단계는, 상기 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀들을 상기 제1 뷰 영상에 대응되는 제1 픽셀 이동 값에 따라 이동시켜, 상기 제2 LF 영상의 제1 뷰 영상을 획득하는 단계를 포 함할 수 있다. 그리고, 상기 픽셀 이동 값은 픽셀 각각에 대응되는 서브 픽셀 이동 값들을 포함하며, 상기 제2 LF 영상의 제1 뷰 영상을 획득하는 단계는, 상기 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀 각각을 상기 제1 픽셀 이동 값에 포함된 서브 픽셀 이동 값에 따라 이동시켜, 상기 제2 LF 영상의 제1 뷰 영상을 획득하는 단계일 수 있다.그리고, 상기 레이어 영상을 획득하는 단계는, 제2 인공지능 모델에 상기 제1 LF 영상, 상기 제2 LF 영상 및 상 기 픽셀 이동 값을 입력하여 상기 레이어 영상을 획득하는 단계일 수 있다. 그리고, 상기 레이어 영상은 제1 레이어 영상, 제2 레이어 영상 및 제3 레이어 영상을 포함하고, 상기 제3 LF 영상을 획득하는 단계는, 상기 제1 레이어 영상 및 상기 제3 레이어 영상 각각을 시점 별로 시프팅하는 단계; 상기 시프팅된 제1 레이어 영상 및 상기 시프팅된 제3 레이어 영상을 상기 제2 레이어 영상과 함께 크롭하여 상 기 제3 LF 영상을 획득하는 단계;를 포함할 수 있다. 그리고, 상기 학습시키는 단계는 상기 제2 LF 영상과 상기 제3 LF 영상을 비교하여 손실 함수를 획득하는 단계; 및 상기 손실 함수를 바탕으로 상기 제1 인공지능 모델 및 제2 인공지능 모델을 학습시키는 단계를 포함할 수 있다. 그리고, 상기 제어 방법은 상기 제1 LF 영상을 상기 학습된 제1 인공지능 모델에 입력하여, 픽셀 이동 값을 획 득하는 단계; 상기 제1 LF 영상 내의 픽셀들을 상기 픽셀 이동 값에 따라 변환하여 제2 LF 영상을 획득하는 단 계; 및 상기 제1 LF 영상 및 상기 제2 LF 영상을 상기 학습된 제2 인공지능 모델에 입력하여 레이어 영상을 획 득하는 단계;를 더 포함할 수 있다. 그리고, 상기 제어 방법은, 상기 제1 LF 영상을 상기 학습된 제1 인공지능 모델에 입력하여, 픽셀 이동 값을 획 득하는 단계; 상기 제1 LF 영상 및 상기 픽셀 이동 값을 상기 학습된 제2 인공지능 모델에 입력하여 레이어 영 상을 획득하는 단계;를 더 포함할 수 있다. 그리고, 상기 레이어 영상을 적층형 디스플레이에 제공하는 단계를 더 포함할 수 있다. 한편, 본 개시의 상술한 목적을 달성하기 위한 일 실시 예에 따른 전자 장치는 적어도 하나의 인스트럭션을 저 장하는 메모리; 상기 메모리에 저장된 적어도 하나의 인스트럭션을 실행하여 상기 전자 장치를 제어하는 프로세 서를 포함하고, 상기 프로세서는, 서로 다른 시점(view point)의 제1 LF 영상을 획득하고, 제1 인공지능 모델에 상기 제1 LF 영상을 입력하여 상기 제1 LF 영상 내 픽셀들을 변환하기 위한 픽셀 이동 값을 획득하고, 상기 제1 LF 영상 내의 픽셀들을 상기 픽셀 이동 값에 따라 변환하여 제2 LF 영상을 획득하고, LF 영상을 레이어 영상으 로 변환하기 위한 제2 인공지능 모델에 상기 제1 LF 영상 및 상기 제2 LF 영상을 입력하여 레이어 영상을 획득 하고, 상기 LF 영상을 복원하기 위한 시뮬레이션 모델에 상기 획득한 레이어 영상을 입력하여 제3 LF 영상을 획 득하고, 상기 제2 LF 영상과 상기 제3 LF 영상을 바탕으로 상기 제1 인공지능 모델 및 제2 인공지능 모델을 학 습시킬 수 있다. 그리고, 상기 프로세서는, 상기 제1 LF 영상에 포함된 복수의 뷰 영상 각각에 대응되는 픽셀 이동 값에 따라 상 기 복수의 뷰 영상 각각의 픽셀을 이동시켜 상기 제2 LF 영상을 획득할 수 있다. 그리고, 상기 프로세서는, 상기 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀들을 상기 제1 뷰 영상에 대응되는 제1 픽셀 이동 값에 따라 이동시켜, 상기 제2 LF 영상의 제1 뷰 영상을 획득할 수 있다. 그리고, 상기 픽셀 이동 값은 픽셀 각각에 대응되는 서브 픽셀 이동 값들을 포함하며, 상기 프로세서는, 상기 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀 각각을 상기 제1 픽셀 이동 값에 포함된 서브 픽셀 이동 값에 따라 이동시켜, 상기 제2 LF 영상의 제1 뷰 영상을 획득할 수 있다. 그리고, 상기 프로세서는, 상기 제2 인공지능 모델에 상기 제1 LF 영상, 상기 제2 LF 영상 및 상기 픽셀 이동 값을 입력하여 상기 레이어 영상을 획득할 수 있다. 그리고, 상기 레이어 영상은 제1 레이어 영상, 제2 레이어 영상 및 제3 레이어 영상을 포함하고, 상기 프로세서 는, 상기 제1 레이어 영상 및 상기 제3 레이어 영상 각각을 시점 별로 시프팅하고, 상기 시프팅된 제1 레이어 영상 및 상기 시프팅된 제3 레이어 영상을 상기 제2 레이어 영상과 함께 크롭하여 상기 제3 LF 영상을 획득할 수 있다. 그리고, 상기 프로세서는, 상기 제2 LF 영상과 상기 제3 LF 영상을 비교하여 손실 함수를 획득하고, 상기 손실 함수를 바탕으로 상기 제1 인공지능 모델 및 제2 인공지능 모델을 학습시킬 수 있다. 그리고, 상기 프로세서는, 상기 제1 LF 영상을 상기 학습된 제1 인공지능 모델에 입력하여, 픽셀 이동 값을 획 득하고, 상기 제1 LF 영상 내의 픽셀들을 상기 픽셀 이동 값에 따라 변환하여 제2 LF 영상을 획득하고, 상기 제 1 LF 영상 및 상기 제2 LF 영상을 상기 학습된 제2 인공지능 모델에 입력하여 레이어 영상을 획득할 수 있다. 그리고, 상기 프로세서는, 상기 제1 LF 영상을 상기 학습된 제1 인공지능 모델에 입력하여, 픽셀 이동 값을 획 득하고, 상기 제1 LF 영상 및 상기 픽셀 이동 값을 상기 학습된 제2 인공지능 모델에 입력하여 레이어 영상을 획득할 수 있다. 그리고, 상기 프로세서는, 상기 레이어 영상을 적층형 디스플레이에 제공하는 것을 특징으로 할 수 있다."}
{"patent_id": "10-2020-0183842", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 실시 예들을 통해, 전자 장치는 LF 영상을 적층형 디스플레이가 표현할 수 있는 뎁스 범위에 적합하게 변환하고, 변환된 LF 영상을 통해 레이어 영상을 획득함으로, 표현 품질이 향상된 레이어 영상을 획득할 수 있 다."}
{"patent_id": "10-2020-0183842", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는, 첨부된 도면을 통해 본 개시를 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따른, 레이어 영상 획득을 위한 제1 및 제2 인공지능 모델의 학습 과정을 도시 한 도면이다. 도 1을 참조하면, 전자 장치는 제1 인공지능 모델 및 제2 인공지능 모델을 학습 시킴으로, 적층형 디스플레이 장치가 표현할 수 있는 뎁스 범위를 벗어나는 영역이 보정된 레이어 영상을 획득할 수 있다. 본 개 시에 따른 전자 장치는 레이어 영상을 획득하기 위한 제1 인공지능 모델 및 제2 인공지능 모델 을 학습시키기 위한 전자 장치로, 획득한 레이어 영상을 외부의 적층형 디스플레이 장치에 제공할수 있다. 다만, 이에 한정되지 않고, 전자 장치가 적층형 디스플레이를 포함할 수 도 있다. 본 개시에 따른 레이어 영상은 적층형 디스플레이에 표시하기 위한 영상으로 사용자의 시점(또는 사용자의 위치)에 따라 영상 내 오브젝트의 다른 면이 사용자에게 보이도록 하는 영상을 의미한다. 예를 들어, 적층형 디 스플레이 장치를 바라보는 사용자가 왼쪽으로 위치를 이동할 경우 레이어 영상에서 오브젝트의 좌측 부분 이 사용자에게 더 많이 보이게 될 수 있다. 일 예로, 레이어 영상은 레이어 스택(stack)으로 명칭 될 수 있다. 도 1에 따른 제1 인공지능 모델 및 제2 인공지능 모델을 학습 시키기 위해 우선, 전자 장치는 서로 다른 시점의 제1 LF 영상을 획득할 수 있다. LF(Light Field) 영상은 LF 카메라를 통해 적어도 하나의 오브젝트가 서로 다른 시점(view)으로 촬영된 복수의 영상의 집합을 의미한다. 즉, LF 영상은 특정한 오브젝트에서 반사되어 나오는 빛을 서로 다른 복수의 시점 (view point)에서 촬영한 복수의 뷰 영상의 집합을 의미한다. 그리고, 본 개시에 따르면, 팩토리제이션 기법을 통해 제1 LF 영상을 적층형 디스플레이에 표시하기 위한 레이어 영상으로 변환할 수 있다. 일 예로, 전자 장치가 LF 카메라를 포함하는 경우, 전자 장치는 LF 카메라로부터 제1 LF 영상을 획득할 수 있다. 또 다른 예로, 전자 장치는 외부 서버 또는 외부 LF 카메라로부터 제1 LF 영상을 수신하여 획득할 수 있다. 그리고, 전자 장치는 제1 인공지능 모델에 제1 LF 영상을 입력하여 제1 LF 영상 각각의 픽셀들을 변환하기 위한 픽셀 이동 값(f)을 획득할 수 있다. 본 개시에 따른 제1 인공지능 모델은 제1 LF 영상에 대응되는 픽셀 이동 값을 획득하기 위한 인공지 능 모델로, 일 예로, DNN(Deep Neural Network) 기반의 인공지능 모델일 수 있다. 본 개시에 따른, 픽셀 이동 값은 영상 내 적층형 디스플레이 장치에서 표현할 수 있는 뎁스 범위를 벗어나는 영 역의 화질, 해상도 또는 시야 각의 표현 품질이 저하되지 않도록 영상 내 뎁스 범위를 벗어나는 영역의 뎁스를 변경하기 위한 픽셀의 이동 값이다. 즉, 픽셀 이동 값은 영상에서 일 영역의 픽셀을 이동 시키기 위한 값이다. 픽셀 이동 값은 일 예로, 플로우(flow) 값 = ( , )으로 지칭될 수 있다. 또는 픽셀 이동 값은 Flow field 값으로 지칭될 수 있다. 그리고, 전자 장치는 제1 LF 영상에 포함된 뷰 영상들에 대한 픽셀들을 픽셀 이동 값을 바탕으로 변환하여 제2 LF 영상을 획득할 수 있다. 즉, 전자 장치는 LF 영상 변환 모델을 통해, 제1 LF 영상에 포함된 뷰 영상들의 픽셀들을 픽셀 이동 값에 따라 이동시키는 와핑 기법을 수행하여 제2 LF 영상을 획득할 수 있다. 제2 LF 영상은 제1 LF 영 상이 픽셀 이동 값에 따라 와핑된 LF 영상이다. 와핑 기법이란, 영상 내 픽셀 각각에 대응되는 픽셀 이동 값에 따라 픽셀 각각을 이동시키는 기법이다. 그리고, LF 영상 변환 모델은 제1 LF 영상에 포함된 뷰 영상 각각에 대응되는 픽셀 이동 값에 따라 뷰 영상 각각을 와핑하기 위한 모델이다. 와핑 기법에 대한 자세한 내용은 도 3 및 도 4를 통해 후술하도록 한다. 즉, 제1 인공지능 모델을 통해 제1 LF 영상에 대한 픽셀 이동 값이 획득되면, LF 영상 변환 모델 은 픽셀 이동 값을 바탕으로, 제1 LF 영상에 포함된 뷰 영상 각각의 픽셀들을 이동시킬 수 있다. 즉, LF 영상 변환 모델은 픽셀 이동 값을 통해 제1 LF 영상 내 각각의 뷰 영상을 와핑하여 제2 LF 영상 을 획득할 수 있다. 구체적으로, 뷰 개수만큼의 뷰 영상을 포함하는 제1 LF 영상의 경우, LF 영상 변환 모델 은 센터 뷰 에 해당되는 뷰 영상에는 픽셀 이동 값이 적용되지 않을 수 있다 ( . 그 리고, 에 해당되는 뷰 영상에는 픽셀 이동 값 = ( , ) 이 적용되어 픽셀들을 이동 될 수 있다. 즉, 뷰에 해당되는 뷰 영상에는 뷰에 대응되는 픽셀 이동 값 을 이용하여 픽셀들을 이동 시킬 수 있으며, 뷰 영상에 대응되는 픽셀 이동 값 는 ( ) 일 수 있다. 이에 대한 자세한 내용은 도 3 및 도 4를 통해 후술하도록 한다.그리고, 픽셀 이동 값 ( , )은 영상 내 픽셀마다 각각 상이할 수 있다. 즉, 영상 내 픽셀의 위치에 따라 픽셀 이동 값이 각각 상이하며, 이러한, 서브 픽셀 이동 값이 영상 내 픽셀 마다 상이한 것은 제1 인공지능 모델 을 통해 학습될 수 있다. 상술한 서브 픽셀 이동 값에 대한 예시는 개념상 설명을 위한 예일 뿐이며 본 개시는, 이에 한정되지 않는다. 즉, backward warping이 적용될 수 있다. 또한, 전자 장치는 bilinear sampling을 적용하여, 뷰 영상내 일 픽셀의 주변 픽셀들의 weighted summation으로 일 픽셀에 대한 서브 픽셀 이동 값이 계산될 수도 있다. 예로, 뷰 영상에서 적층형 디스플레이 장치에서 표현할 수 있는 뎁스 범위를 벗어나는 (1,1) 픽 셀에 대응되는 서브 픽셀 이동 값은 뎁스 범위를 벗어나지 않는 (8,8) 픽셀 에 대응되는 서브 픽셀 이동 값보다 작을 수 있다. 즉, 은 하나의 영상 내 일 픽셀을 x 축으로 이동시키기 위한 이동 값이며, 은 하나의 영상 내 일 픽셀을 y축으로 이동시키기 위한 이동 값이며, 영상 내 픽셀 마다 픽셀 이동 값 ( , )이 상이할 수 있 다. LF 영상 변환 모델을 통해 제2 LF 영상이 획득되면, 전자 장치는 제1 LF 영상 및 제2 LF 영상을 제2 인공지능 모델에 입력하여, 레이어 영상을 획득할 수 있다. 제2 인공지능 모델은 팩토리제이션 기법을 통해 LF 영상을 레이어 영상으로 변환하기 위한 인공지능 모델 로, 일 예로, DNN(Deep Neural Network) 기반의 인공지능 모델일 수 있다. 레이어 영상은 적층형 디스플레이 장치에 제공되는 영상으로, 적층형 디스플레이 장치의 패널의 개수에 대 응되는 개수로 구성될 수 있다. 즉, 적층형 디스플레이 장치 각각의 패널에 레이어 영상이 각각 표시되어 입체 영상이 제공될 수 있다. 일 예로, 3개의 패널로 구성된 적층형 디스플레이 장치에 제공하기 위한 레이어 영상은 제1 레이어 영상, 제2 레이어 영상 및 제3 레이어 영상으로 구성될 수 있다. 그리고, 적층형 디스 플레이 장치의 제1 패널에는 제1 레이어 영상이 표시되며, 제2 패널에는 제2 레이어 영상이 표시되며, 제3 패널 에는 제3 레이어 영상이 표시되어, 입체 영상이 제공될 수 있다. 이러한, 레이어 영상은 제2 인공지능 모델을 통해 LF 영상을 펙토리제이션하여 획득될 수 있으며, 본 개시에 따른 제2 인공지능 모델은 제1 LF 영상 및 제1 LF 영상이 와핑된 제2 LF 영상을 이용하여 레이 어 영상을 획득할 수 있다. 상술한 실시 예에서는 제2 인공지능 모델에 제1 LF 영상 및 제2 LF 영상이 입력되어, 레이어 영 상이 획득되는 것으로 설명하였지만, 본 개시는 이에 한정되지 않는다. 즉, 제2 인공지능 모델에 제 1 LF 영상 및 제1 인공지능 모델에서 획득된 픽셀 이동 값이 입력되어, 레이어 영상이 획득될 수도 있다. 레이어 영상이 획득되면, 제1 인공지능 모델 및 제2 인공지능 모델을 학습 시키기 위해, 전자 장치는 시뮬레이션 모델을 통해 레이어 영상을 LF 영상 형식으로 복원할 수 있다. 즉, 전자 장치는 시뮬레이션 모델을 통해 레이어 영상을 제3 LF 영상으로 복원할 수 있다. 제3 LF 영상은 레이어 영상이 LF 영상 형식으로 복원된 영상으로, 기존 LF 영상과 비교하여 인공지능 모델 을 학습시키기 위한 LF 영상이다. 시뮬레이션 모델은 복수 개의 레이어 영상을 뷰 별로 시프팅하여, 복수의 뷰 영상을 포함하는 제3 LF 영상을 획득할 수 있다. 레이어 영상을 제3 LF 영상으로 복원하는 구체적인 방법에 대해서는 도 8a, 8b 및 8c를 통해 후술하도록 한다. 제3 LF 영상이 획득되면, 전자 장치는 제2 LF 영상과 제3 LF 영상을 비교하여 제1 인공지능 모델 및 제2 인공지능 모델을 학습시킬 수 있다. 구체적으로, 전자 장치는 제2 LF 영상과 제3 LF 영상을 비교하여 손실(loss)함수를 획득하고, 손실 함수를 바탕으로 손실(loss)을 계산하여, 제1 인공지능 모델 및 제2 인공지능 모델을 학습시킬 수 있다. 즉, 본 개시에 따르면, 제1 인공지능 모델 및 제2 인공지능 모델은 공통된 손실 함수를 사용하여 학습될 수 있다. 손실 함수(loss function)란 인공지능 모델의 현재 학습 상태를 나타내는 지표를 나타낸다. 구 체적으로, 손실 함수는 인공지능 모델에 대한 현재 성능의 나쁨을 나타내는 지표로, 인공지능 모델은 손실 함수 가 감소하는 방향으로 학습될 수 있다.일 예로, 수학식 1과 같이 손실 함수를 계산할 수 있다. [수학식 1]"}
{"patent_id": "10-2020-0183842", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서, 은 L1 norm으로 제2 LF 영상과 제3 LF 영상간 오차(차이)의 절대값의 합이며, 는 mean square error 개념으로 오차의 제곱의 합 L2 norm 을 의미한다. 그리고, 과 는 loss간의 비율 조정을 하기 위해 주는 가중치이며, 하이퍼 파라미터로 실험적으로 사용자에 의해 설정될 수 있다. SSIM은 Structural Similarity Index 로 MSE, PSNR 같은 image quality metric의 일종 으로 구조적 유사도를 측정하기위해 L1 loss와 함께 조합하여 사용될 수 있다. 그리고, 는 제1 인공지능 모델 을 통해 획득하는 픽셀 이동 값을 나타낸다. 손실 함수가 획득되면, 전자 장치는 손실 함수가 감소되는 방향으로, 제1 인공지능 모델 및 제2 인공지능 모델을 학습시킬 수 있다. 그리고, 전자 장치는 상술한 학습과정을 반복하여, 제1 인공지능 모델 및 제2 인공지능 모델을 계 속하여 학습시킬 수 있다. 그리고, 전자 장치는 학습이 완료된 제1 인공지능 모델 및 제2 인공지능 모델을 이용하여 적층형 디스플레이 장치가 표현할 수 있는 뎁스 범위를 벗어나는 영역이 보정된 레이어 영상을 획득할 수 있다. 그리고, 전자 장치는 적층형 디스플레이 장치에 레이어 영상을 제공할 수 있다. 도 2는 본 개시에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 2를 참조하면, 전자 장치는 메모리 및 프로세서를 포함할 수 있다. 메모리는 전자 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 구체적으로, 메모 리에는 적어도 하나의 인스트럭션이 저장될 수 있다. 프로세서는 메모리에 저장된 인스트럭션을 실행함으로써 전자 장치의 동작을 수행할 수 있다. 구체적으로, 메모리는 전자 장치의 적어도 하나의 다른 구성요소에 관계된 명령(instruction) 또는 데이터를 저장할 수 있다. 특히, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모리는 프로세 서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 본 개시에서 메모리라는 용어는 메모리, 프로세서 내 롬(미도시), 램(미도시) 또는 전자 장치에 장착되는 메모리 카드(미도시)(예를 들어, micro SD 카드, 메모리 스틱)를 포함할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU(Central Processing Unit), AP(application processor) 등과 같은 범용 프로세서, GPU(Graphics Processing Unit). VPU(Visual Processing Unit) 등과 같은 그래픽 전용 프로세서 또는 NPU(Neural Processing Unit) 와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터 를 처리하도록 제어한다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 다수의 학습 데이터들에 학습 알고리즘을 적용함으로써, 원하는 특성의 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지 능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 각 레이어는 복수의 가중치(weight values)을 갖 고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치의 연산을 통해 레이어의 연산을 수행한다. 신 경망의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional RecurrentDeep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks)이 있으며, 본 개시에서의 신경망은 명시한 경우 를 제외하고 전술한 예에 한정되지 않는다. 프로세서는 메모리와 전기적으로 연결되어 전자 장치의 전반적인 동작 및 기능을 제어할 수 있 다. 구체적으로, 프로세서는 메모리에 저장된 적어도 하나의 명령어를 실행함으로써, 서로 다른 시점의 제1 LF 영상을 획득할 수 있다. 일 실시 예로, 프로세서는 외부 서버 또는 외부 장치로부터 제1 LF 영 상을 수신하거나, 전자 장치가 LF 카메라를 포함하는 경우, LF 카메라로부터 제1 LF 영상을 수신 할 수 있다. 그리고, 본 개시에 따른 제1 LF 영상은 뷰 개수만큼의 뷰 영상을 포함할 수 있으며, 일 예로, 제1 LF 영상은 도 3과 같이 3 X 3 뷰 개수만큼의 뷰 영상을 포함할 수 있다. 그리고, 프로세서는 제1 인공지능 모델에 제1 LF 영상을 입력하여 제1 LF 영상 내 뷰 영상의 픽셀들을 변환하기 위한 픽셀 이동 값을 획득할 수 있다. 즉, 도 1에서 상술한 바와 같이, 프로세서는 제1 인공지능 모델에 뷰의 제1 LF 영상을 입력하여, 뷰 영상에 대응되는 픽셀 이동 값 을 획득할 수 있다. 그리고, 프로세서는 제1 LF 영상 내 뷰 영상들의 픽셀들을 픽셀 이동 값에 따라 변환하여 제2 LF 영상을 획득할 수 있다. 일 실시 예로, 프로세서는 제1 LF 영상에 포함된 복수의 뷰 영상 각각에 대응되는 픽셀 이동 값에 따라 복수의 뷰 영상 각각의 픽셀을 이동시켜 제2 LF 영상을 획득할 수 있다. 구체적으로, 프로세서 는 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀들을 제1 뷰 영상에 대응되는 제1 픽셀 이동 값에 따라 이동 시켜 제2 LF 영상의 제1 뷰 영상을 획득할 수 있다. 즉, 프로세서는 제1 LF 영상의 뷰 영상 내 픽셀을 뷰 영상에 대응되는 픽셀 이동 값 = ( )에 따라 이동시켜, 제2 LF 영상의 뷰 영상을 획득할 수 있다. 도 3은 본 개시에 따른 3 x 3 뷰의 제1 LF 영상을 도시한 도면이며, 도 4는 도 3의 제1 LF 영상이 픽셀 이동 값 에 따라 변환되어 획득되는 제2 LF 영상을 도시한 도면이다. 예로, 도 3과 같이 u=1, v=1인 3 x 3 뷰를 가지는 제1 LF 영상의 경우, 프로세서는 (0,0) 뷰인 제1 뷰 영상 내 픽셀을 제1 뷰 영상에 대응되는 제1 픽셀 이동 값 = (- ) 에 따라 변환하여, 도 4의 제1 뷰 영상을 획득할 수 있다. 그리고, 프로세서는 (1,1) 뷰인 제2 뷰 영상을 제2 뷰 영 상에 대응되는 제2 픽셀 이동 값 = (0,0)에 따라 제2 뷰 영상 내 픽셀들을 이동시키지 않고 도 4의 제2 뷰 영상을 획득할 수 있다. 그리고, 프로세서는 (2,2) 뷰인 제3 뷰 영상 내 픽셀을 제3 뷰 영상에 대응되는 제3 픽셀 이동 값 = ( ) 에 따라 변환하여, 도 4의 제3 뷰 영상을 획득할 수 있다. 프로세서는 도 3의 제1 LF 영상 전부에 대해 상술한 과정을 수행하여, 도 4의 제2 LF 영상을 획득할 수 있다. 일 예로, (1,1) 뷰인 제2 뷰 영상은 제1 LF 영상내 오브젝트를 정면에서 관측한 영상일 수 있으며, (0,0) 뷰인 제1 뷰 영상은 제1 LF 영상내 오브젝트를 (1,1) 뷰 기준 상대적으로, 왼쪽 위(정면 기준 (- 1, -1) 뷰)에서 관측한 영상일 수 있다. 그리고, (2,2) 뷰인 제3 뷰 영상은 제1 LF 영상내 오브젝트를 (1,1) 뷰 기준 상대적으로, 오른쪽 아래(정면 기준 (1, 1) 뷰)에서 관측한 영상일 수 있다. 일 예로, 도 3의 LF 영상 각각의 시점은 사용자의 단안 기준 시점일 수 있다. 즉, 사용자가 양안으로 관측하는 경우, 제1 LF 영상 에서 복수의 뷰 영상이 사용자에게 관측될 수 있다. 그리고, 본 개시의 일 실시 예로, 픽셀 이동 값은 픽셀 각각에 대응되는 서브 픽셀 이동 값들을 포함할 수 있다. 즉, 픽셀을 이동시키기 위한 픽셀 이동 값은 하나의 뷰 영상 내 픽셀에 따라 상이할 수 있다. 그리고, 프로세서는 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀 각각을 제1 픽셀 이동 값에 포함 된 서브 픽셀 이동 값에 따라 이동시켜, 제2 LF 영상의 제1 뷰 영상을 획득할 수 있다. 일 예 로, 뷰의 제1 LF 영상 중 에 해당되는 뷰 영상에서 (1,1) 픽셀 위치에 해당되는 서브 픽셀 이동 값이 ( , )=(1,1)이라면, 전자 장치는 에 해당되는 뷰 영상에 서 (1,1) 픽셀을 (1,1) 픽셀만큼 이동시켜 와핑을 수행할 수 있다. 그리고, 뷰 영상에서 (2, 2) 픽셀 위치에 해 당되는 서브 픽셀 이동 값이 ( , )= (0.5, 0.5)이라면, 전자 장치는 (2, 2) 픽셀을 (0.5, 0.5) 픽셀 만큼 이동시켜 와핑을 수행할 수 있다. 그리고, 프로세서는 LF 영상을 레이어 영상으로 변환하기 위한 제2 인공지능 모델에 제1 LF 영상 및 제2 LF 영상을 입력하여 레이어 영상을 획득할 수 있다. 다만, 이에 한정되지 않고, 일 실시 예로, 프로세서는 제2 인공지능 모델에 제1 LF 영상 및 제2 LF 영 상과 함께 제1 인공지능 모델에서 획득한 픽셀 이동 값을 입력하여 레이어 영상을 획득할 수 있다. 또한, 일 실시 예로, 프로세서는 제2 인공지능 모델에 제1 LF 영상 및 1 인공지능 모델에서 획득한 픽 셀 이동 값을 입력하여 레이어 영상을 획득할 수 있다. 또한, 일 실시 예로, 프로세서는 제2 인공지능 모델에 제1 LF 영상 만을 입력하여 레이어 영상을 획득 할 수 있다. 일 실시 예로, 레이어 영상은 도 5a와 같이 3장의 레이어 영상으로 구현될 수 있다. 즉, 레이어 영상(10 0)을 표시하기 위한 적층형 디스플레이의 패널의 개수가 3개인 경우, 제2 인공지능 모델은 제1 LF 영상 을 입력 받아 3개의 레이어 영상을 출력할 수 있다. 이 경우, 레이어 영상은 제1 레이어 영상, 제2 레이어 영상 및 제3 레이어 영상을 포함할 수 있다. 레이어 영상이 획득되면, 프로세서는 LF 영상을 복원하기 위한 시뮬레이션 모델에 레이어 영상(10 0)을 입력하여 제3 LF 영상을 획득할 수 있다. 구체적으로, 시뮬레이션 모델은 제1 레이어 영상 및 제3 레이어 영상 각각을 시점 별로 시프팅할 수 있다. 그리고, 시뮬레이션 모델은 시프팅된 제1 레이어 영상 및 시프팅된 제3 레이어 영상을 제2 레이어 영상과 함께 크롭하여 제3 LF 영상을 획득할 수 있다. 구체적으로, 시뮬레이션 모델은 도 5c와 같이 제1 레이어 영상 및 제3 레이어 영상을 시프팅 하는 과정을 거쳐 제3 LF 영상을 획득할 수 있다. 도 5a는 본 개시의 일 실시 예에 따른, 세 장의 레이어 영상을 나타낸 도면이다. 도 5b는 본 개시의 일 실시 예 에 따른, (3 X 3) 뷰의 제3 LF 영상을 도시한 도면이다. 도 5c 는 본 개시의 일 실시 예에 따른, 레이어 영상을 제3 LF 영상으로 복원하는 과정을 설명하기 위한 도면이다. 시뮬레이션 모델은 도 5a의 레이어 영상을 통해, 도 5b의 제3 LF 영상을 복원할 수 있다. 구체 적으로 도 5a의 레이어 영상은 후면 레이어 영상, 중간 레이어 영상 및 전면 레이어 영상 으로 구성될 수 있다. 그리고, 도 5c와 같이, 후면 레이어 영상 및 전면 레이어 영상이 시점 별로 각 각 상이하게 시프팅되고, 시프팅된 후면 레이어 영상 및 전면 레이어 영상을 중간 레이어 영상 기준 크롭하여 제3 LF 영상을 획득할 수 있다. 도 5c를 참조하면, 제3 LF 영상 내의 (0,0) 뷰 영상은 후면 레이어 영상이 중간 레이어 영상 기준 (-Sny, -Snx)만큼 시프팅되고, 전면 레이어 영상이 중간 레이어 영상 기준 (Sny, Snx)만큼 시프 팅된 후, 3장의 레이어 영상을 중간 레이어 영상 기준 크롭하여 생성될 수 있다. 여기서, Sny 및 Snx는 전면 레이어 영상 및 후면 레이어 영상을 시프팅 시키기 위한 시프팅 파라미터 로, 제1 LF 영상의 뎁스에 대한 정보를 바탕으로 획득하거나 사용자로부터 입력을 받아서 정할 수 있다. 또 한 Sny는 영상 기준 y축 방향으로의 시프팅 파라미터이고 Snx는 x축 방향으로의 시프팅 파라미터로 정할 수 있 다. 일 예로, 복수의 레이어 영상을 고속 재생하는 타임 멀티플렉싱 기법을 사용하기 위해, 제2 인공지능 모델 은 도 10a 및 도 10b와 같이 복수의 레이어 영상(100-1, 100-2, 100-3)을 출력할 수 있으며, 복수의 레 이어 영상(100-1, 100-2, 100-3) 각각에 상이한 시프팅 파라미터(S1, S2, S3)들이 적용되어, 복수의 레이어 영 상(100-1, 100-2, 100-3) 각각을 LF 영상으로 복원할 수 있다. 이에 대한 자세한 내용은 도 10a 및 도 10b를 통해 후술하도록 한다. 일 예로, 후면 레이어 영상 및 전면 레이어 영상이 시프팅 된 후, 세 장의 레이어 영상들의 겹치는 영역의 픽셀 값의 평균 값을 해당 영역의 픽셀 값으로 설정하는 크롭 방식에 의해 (0,0) 뷰 영상이 복원될수 있다. 다만 이에 한정되지 않고, 세 장의 레이어 영상의 겹치는 영역의 픽셀 값을 모두 곱한 값을 해당 영역 의 픽셀 값으로 설정하거나, 세 장의 레이어 영상의 겹치는 영역의 픽셀 값을 모두 더한 값을 해당 영역의 픽셀 값으로 설정하는 크롭 방식에 의해 (0,0) 뷰 영상이 복원될 수 있다. 그리고, 제3 LF 영상 내의 (0,2) 뷰 영상은 후면 레이어 영상이 중간 레이어 영상 기준 (- Sny, Snx)만큼 시프팅되고, 전면 레이어 영상이 중간 레이어 영상 기준 (Sny, -Snx)만큼 시프팅된 후, 3장의 레이어 영상을 중간 레이어 영상 기준 크롭하여 생성될 수 있다. 그리고, 제3 LF 영상 내의 (1,0) 뷰 영상은 후면 레이어 영상이 중간 레이어 영상 기준 (0, -Snx)만큼 시프팅되고, 전면 레이어 영상이 중간 레이어 영상 기준 (0, Snx)만큼 시프팅된 후, 3장의 레이어 영상을 중간 레이어 영상 기준 크롭하여 생성될 수 있다. 그리고, 제3 LF 영상 내의 (2,1) 뷰 영상은 후면 레이어 영상이 중간 레이어 영상 기준 (Sny, 0)만큼 시프팅되고, 전면 레이어 영상이 중간 레이어 영상 기준 (-Sny, 0)만큼 시프팅된 후, 3 장의 레이어 영상을 중간 레이어 영상 기준 크롭하여 생성될 수 있다. 상술한 과정이 제3 LF 영상 내의 모든 뷰 영상 각각에 대해 수행되어, 시뮬레이션 모델을 통해 레이 어 영상이 제3 LF 영상으로 복원될 수 있다. 그리고, 제3 LF 영상이 획득되면, 프로세서는 제2 LF 영상과 제3 LF 영상을 바탕으로 제1 인 공지능 모델 및 제2 인공지능 모델을 학습시킬 수 있다. 구체적으로, 프로세서는 제2 LF 영상 과 제3 LF 영상을 비교하여 수학식 1과 같은 손실 함수를 획득하고, 손실 함수를 바탕으로 제1 인공지 능 모델 및 제2 인공지능 모델을 학습시킬 수 있다. 프로세서는 상술한 과정을 반복하여, 제1 인공지능 모델 및 제2 인공지능 모델을 계속하여 학 습시킬 수 있다. 그리고, 프로세서는 학습된 제1 인공지능 모델 및 학습된 제2 인공지능 모델을 이용하여, 적층형 디스플레이에 제공하기 위한 레이어 영상을 획득할 수 있다. 도 6a 는 본 개시의 일 실시 예에 따른, 적층형 디스플레이에 제공하기 위한 레이어 영상을 획득하는 과정을 도 시한 도면이다. 프로세서는 상술한 과정을 통해, 학습이 완료된 제1 인공지능 모델 및 제2 인공지능 모델을 획득할 수 있다. 그리고, 프로세서는 제1 LF 영상을 학습이 완료된 제1 인공지능 모델에 입력하 여 픽셀 이동 값을 획득할 수 있다. 그리고, 프로세서는 제1 LF 영상 및 픽셀 이동 값을 학습이 완료 된 제2 인공지능 모델에 입력하여 적층형 디스플레이에 제공하기 위한 레이어 영상을 획득할 수 있 다. 그리고, 프로세서는 획득한 레이어 영상을 적층형 디스플레이에 제공할 수 있다. 도 6b 는 본 개시의 또 다른 실시 예에 따른, 적층형 디스플레이에 제공하기 위한 레이어 영상을 획득하는 과정 을 도시한 도면이다. 프로세서는 상술한 과정을 통해, 학습이 완료된 제1 인공지능 모델 및 제2 인공지능 모델을 획득할 수 있다. 그리고, 프로세서는 제1 LF 영상을 학습이 완료된 제1 인공지능 모델에 입력하 여 픽셀 이동 값을 획득할 수 있다. 그리고, 프로세서는 픽셀 이동 값 및 제1 LF 영상을 LF 영상 변환 모델에 입력하여, 제1 LF 영상이 와핑된 제2 LF 영상을 획득할 수 있다. 그리고, 프로세서는 제 1 LF 영상 및 제2 LF 영상을 학습이 완료된 제2 인공지능 모델에 입력하여 적층형 디스플레이에 제공하기 위한 레이어 영상을 획득할 수 있다. 그리고, 프로세서는 획득한 레이어 영상을 적층형 디스플레이에 제공할 수 있다. 일 실시 예로, 전자 장치는 적층형 디스플레이를 더 포함할 수 있다. 여기서, 적층형 디스플레이는 TV, 모 니터, 스마트폰, 휴대용 멀티미디어 장치, 휴대용 통신장치, 스마트 글래스, 스마트 윈도우, 스마트 워치, HMD(Head Mount Display), 웨어러블 장치(Wearable device), 포터블 장치(Portable device), 핸즈헬드 장치 (Handheld device), 사이니지(Signage), 전광판, 광고판, 시네마 스크린, 비디오 월 등 다양한 형태로 구현될 수 있으며, 그 형태가 한정되지 않는다. 그리고, 적층형 디스플레이는 복수개의 패널을 포함할 수 있으며, 복수개의 패널 각각에 레이어 영상이 표시될 수 있다. 즉, 프로세서는 적층형 디스플레이 상에 레이어 영상을 표시하여 입체 영상을 제공할 수 있다. 일 실시 예로, 전자 장치는 통신부를 더 포함할 수 있다. 통신부는 외부 장치와 통신을 수행하여 외부 장 치와 데이터를 주거나 받을 수 있다. 예를 들어, 통신부는, LTE, LTE-A(LTE Advance), CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), 또는 GSM(Global System for Mobile Communications) 등 중 적어도 하나를 사용하 는 셀룰러 통신, WiFi(wireless fidelity), 블루투스, 블루투스 저전력(BLE), 지그비(Zigbee), NFC(near field communication) 등의 다양한 방식 중 적어도 하나의 무선 통신을 수행할 수 있다. 또한, 통신부는 USB(universal serial bus), HDMI(high definition multimedia interface), DVI(Digital Visual Interface), 썬더볼트, 이더넷, USB 포트, 라이트닝 등의 다양한 방식 중 적어도 하나의 유선 통신을 수행할 수 있다. 전자 장치가 통신부를 포함하는 경우, 프로세서는 외부의 LF 카메라 또는 외부 장치(서버)로부터 제1 LF 영상을 수신하도록 통신부를 제어할 수 있다. 또한, 전자 장치가 통신부를 포함하는 경우, 프로세서 는 레이어 영상을 외부의 적층형 디스플레이 장치로 전송하도록 통신부를 제어할 수 있다. 일 실시 예로, 전자 장치는 입력 인터페이스를 더 포함할 수 있다. 입력 인터페이스는 사용자로부터 다양 한 방식의 사용자 명령(command)을 수신할 수 있다. 입력 인터페이스는 수신된 사용자 명령을 프로세서로 전달할 수 있다. 이를 위해, 입력 인터페이스는 예를 들면, 터치 패널 또는 키를 포함할 수 있다. 터치 패널은, 예를 들면, 정전식, 감압식, 적외선 방식, 또는 초음파 방식 중 적어도 하나의 방식을 사용할 수 있으며, 이를 위한 제어 회로를 포함할 수 있다. 터치 패널은 택타일 레이어(tactile layer)를 더 포함하여, 사용자에게 촉각 반응을 제공할 수 있다. 키는 예를 들면, 물리적인 버튼 방식, 광학 방식 또는 터치 패널과 결합된 가상의 키패 드 방식을 통해 구현될 수 있다. 도 7은 본 개시의 일 실시 예에 따른, 제1 LF 영상 및 픽셀 이동 값을 제2 인공지능 모델의 입력 데이터로 설정 하여 제1 인공지능 모델 및 제2 인공지능 모델의 학습이 수행되는 과정을 도시한 도면이다. 본 개시에 따른 제1 인공지능 모델 및 제2 인공지능 모델의 학습 방법은 도 1에 개시된 실시 예에 한정되지 않 는다. 즉, 도 7을 참조하면, 전자 장치는 제1 LF 영상을 제1 인공지능 모델에 입력하여 픽셀 이 동 값(f)을 획득하고, 픽셀 이동 값 및 제1 LF 영상을 LF 영상 변환 모델에 입력하여, 제1 LF 영상 에 픽셀 이동 값이 반영된 제2 LF 영상을 획득할 수 있다. 그리고, 전자 장치는 제1 LF 영상을 픽셀 이동 값과 함께 제2 인공지능 모델에 입력하여 레이어 영상을 획득할 수 있다. 본 개시에 따른 제2 인공지능 모델은 도 8에 도시된 바와 같은 형태일 수 있다. 그리고, 도 7의 제2 인공지능 모델은 제1 LF 영상 및 픽셀 이동 값을 입력으로 하여 레이어 영 상을 출력하는 인공지능 모델일 수 있다. 그리고, 전자 장치는 레이어 영상을 시뮬레이션 모델을 통해 제3 LF 영상으로 복원할 수 있다. 그리고, 전자 장치는 제2 LF 영상 및 제3 LF 영상을 바탕으로, 제1 인공지능 모델 및 제2 인공지능 모델을 학습 시킬 수 있다. 구체적으로, 전자 장치는 제2 LF 영상 및 제3 LF 영상(3 0)을 비교하여 손실 함수를 획득하고, 손실 함수가 감소하는 방향으로 제1 인공지능 모델 및 제2 인공지 능 모델을 학습 시킬 수 있다. 여기서 손실 함수는 일 예로, 수학식 1과 같은 형태일 수 있다. 도 8은 본 개시의 일 실시 예에 따른, 제1 LF 영상 및 제2 LF 영상을 제2 인공지능 모델의 입력 데이터로 설정 하여 제1 인공지능 모델 및 제2 인공지능 모델의 학습이 수행되는 과정을 도시한 도면이다. 도 8을 참조하면, 전자 장치는 제1 LF 영상을 제1 인공지능 모델에 입력하여 픽셀 이동 값(f)을 획득하고, 픽셀 이동 값 및 제1 LF 영상을 LF 영상 변환 모델에 입력하여, 제1 LF 영상에 픽셀 이동 값이 반영된 제2 LF 영상을 획득할 수 있다. 그리고, 전자 장치는 제1 LF 영상을 제2 LF 영상과 함께 제2 인공지능 모델에 입력하여 레 이어 영상을 획득할 수 있다. 도 8의 제2 인공지능 모델은 제1 LF 영상 및 제2 LF 영상을 입력으로 하여 레이어 영상을 출력하는 인공지능 모델일 수 있다. 그리고, 전자 장치는 레이어 영상을 시뮬레이션 모델을 통해 제3 LF 영상으로 복원할 수 있다. 그리고, 전자 장치는 제2 LF 영상 및 제3 LF 영상을 바탕으로, 제1 인공지능 모델 및 제2 인공지능 모델을 학습 시킬 수 있다. 구체적으로, 전자 장치는 제2 LF 영상 및 제3 LF 영상(3 0)을 비교하여 손실 함수를 획득하고, 손실 함수가 감소하는 방향으로 제1 인공지능 모델 및 제2 인공지 능 모델을 학습 시킬 수 있다. 여기서 손실 함수는 일 예로, 수학식 1과 같은 형태일 수 있다. 도 9은 본 개시의 일 실시 예에 따른, 제1 LF 영상을 제2 인공지능 모델의 입력 데이터로 설정하여 제1 인공지 능 모델 및 제2 인공지능 모델의 학습이 수행되는 과정을 도시한 도면이다. 도 9를 참조하면, 전자 장치는 제1 LF 영상을 제1 인공지능 모델에 입력하여 픽셀 이동 값(f)을 획득하고, 픽셀 이동 값 및 제1 LF 영상을 LF 영상 변환 모델에 입력하여, 제1 LF 영상에 픽셀 이동 값이 반영된 제2 LF 영상을 획득할 수 있다. 그리고, 전자 장치는 제1 LF 영상만을 제2 인공지능 모델에 입력하여 레이어 영상을 획득 할 수 있다. 즉, 도 9의 제2 인공지능 모델은 제1 LF 영상을 입력으로 하여 레이어 영상을 출력 하는 인공지능 모델일 수 있다. 그리고, 전자 장치는 레이어 영상을 시뮬레이션 모델을 통해 제3 LF 영상으로 복원할 수 있다. 그리고, 전자 장치는 제2 LF 영상 및 제3 LF 영상을 바탕으로, 제1 인공지능 모델 및 제2 인공지능 모델을 학습 시킬 수 있다. 구체적으로, 전자 장치는 제2 LF 영상 및 제3 LF 영상(3 0)을 비교하여 손실 함수를 획득하고, 손실 함수가 감소하는 방향으로 제1 인공지능 모델 및 제2 인공지 능 모델을 학습 시킬 수 있다. 여기서 손실 함수는 일 예로, 수학식 1과 같은 형태일 수 있다. 상술한 바와 같이, 전자 장치는 제2 인공지능 모델의 입력 데이터를 다양하게 변형하여, 제1 인공지 능 모델 및 제2 인공지능 모델을 학습시킬 수 있다. 도 10a는 본 개시의 일 실시 예에 따른, 타임 멀티플렉싱 기법을 이용하기 위해 복수의 레이어 영상을 획득하기 위한 제2 인공지능 모델의 학습 방법을 도시한 도면이다. 본 개시에 따른 제1 인공지능 모델 및 제2 인공지능 모델의 학습 방법은 타임 멀티플렉싱 (time multiplexing) 기법을 적용하기 위해 복수의 레이어 영상을 획득할 때에도 구현될 수 있다. 본 개시에 따른 타임 멀티플렉싱 기법이란, 복수의 레이어 영상(100-1, 100-2, ..., 100-N)을 적층형 디스플레 이의 패널 각각에 순서대로 표시하는 기법으로, 복수의 레이어 영상(100-1, 100-2, ..., 100-N)을 고속 재생함 으로, 표현 가능한 뎁스 범위가 증가될 수 있다. 구체적으로, 제1 레이어 영상(100-1)이 적층형 디스플레이 상 에 t1 시간에 표시될 수 있다. 즉, 적층형 디스플레이 3개의 패널 각각에 제1 레이어 영상(100-1)에 포함된 3개 의 영상 각각이 t1 시간에 표시될 수 있다. 그리고, 제2 레이어 영상(100-2)이 적층형 디스플레이 상에 t2 시간 에 표시될 수 있다. 여기서 t1과 t2사이의 시간 간격은 짧은 시간 간격(예로, 0.01초)일 수 있다. 또한, t1과 t2사이의 시간 간격은 적층형 디스플레이의 주사율에 따라 변경될 수 있다. 이러한 과정이 반복되어, 제N 레이 어 영상(100-N)이 적층형 디스플레이 상에 tn 시간에 표시될 수 있다. 그리고, tn+1 시간에 제1 레이어 영상 (100-1)이 적층형 디스플레이 상에 다시 표시될 수 있다. 즉, 학습된 제2 인공지능 모델을 통해 획득된 복수의 레이어 영상(100-1, 100-2, ..., 100-N)을 반복하여 고속 재생하는 타임 멀티플렉싱 기법을 통해 복수의 레이어 영상이 적층형 디스플레이 상에 표시됨으로, 적층형 디스플레이 장치에서 표현 가능한 뎁스의 범위가 증 가될 수 있다. 이러한, 제1 LF 영상의 뎁스에 대한 정보가 반영된 복수의 레이어 영상을 생성하여 타임 멀 티플렉싱 기법을 이용함으로 인해, 적층형 디스플레이의 표현 가능한 뎁스 범위의 제한이 없어지고, 레이어 영 상에 대한 이미지 렌더링에서 발생될 수 있는 아티팩트가 제거될 수 있으며, PSNR(Peak to Noise Ratio)이 향상 된 렌더링 영상이 획득될 수 있다. 이러한 타임 멀티플렉싱 기법을 위해, 제2 인공지능 모델에서는 복수의 레이어 영상을 출력할 수 있으며, 복수의 레이어 영상은 제2 인공지능 모델의 학습에 따라 서로 상이한 시프팅 파라미터가 각각 반영될 수 있다. 시프팅 파라미터(shifting parameter)란 제1 LF 영상 내 포함된 대표 뎁스 정보 값을 나타내며, 뎁스 정보 는 LF 영상에 포함된 적어도 하나의 오브젝트간의 거리 정보를 나타내는 정보일 수 있다. 구체적으로, 시프팅 파라미터를 바탕으로 제1 LF 영상에 포함된 적어도 하나의 오브젝트간의 뎁스의 차이가 식별될 수 있다. 예로, 제1 LF 영상 내 영역 중 시프팅 파라미터의 크기가 0인 기준 영역이 설정될 수있다. 그리고, 복수의 시프팅 파라미터 중 제1 시프팅 파라미터(S1)의 크기가 제2 시프팅 파라미터(S2)의 크기 보다 큰 경우, 제1 LF 영상에 포함된 영역 중 제2 시프팅 파라미터(S2)에 대응되는 영역은 제1 시프팅 파라 미터(S1)에 대응되는 영역보다 상대적으로 기준 영역과 더 가까울 수 있다. 일 실시 예로, 전자 장치는 스테레오 정합(stereo matching) 기법을 이용하여 제1 LF 영상에 대한 뎁 스 정보를 획득할 수 있다. 스테레오 정합(stereo matching) 기법이란, 적어도 하나의 오브젝트를 서로 다른 시 점(view point)으로 촬영한 복수의 영상을 바탕으로, 복수의 영상에 포함된 적어도 하나의 오브젝트간의 거리를 계산하기 위한 기법이다. 구체적으로, 스테레오 정합 기법은 적어도 하나의 오브젝트에 대해 서로 다른 시점 (view point)으로 촬영된 복수의 영상 중 하나의 기준 영상을 설정하고, 기준 영상에서의 한 영역에 대응되는 동일한 영역을 다른 복수의 영상에서 찾아 영상에 포함된 깊이 정보를 획득하는 기법이다. 즉, 스테레오 정합 기법을 통해 적어도 하나의 오브젝트에 대해 서로 다른 시점(view point)으로 촬영된 복수의 영상의 시차 (disparity) 정보를 획득할 수 있다. 특히, 스테레오 정합 기법은 2차원으로 촬영된 복수의 영상을 바탕으로, 복수의 영상의 3차원 깊이 정보를 획득하기 위해 사용될 수 있다. 일 실시 예로, 전자 장치는 스테레오 정합 기법을 이용해 제1 LF 영상의 각 영역 별 뎁스 맵을 획득할 수 있다. 뎁스 맵(Depth map)이란 영상의 각 영역 별 뎁스 정보를 포함하고 있는 테이블을 의미한다. 구체적으 로, 전자 장치는 스테레오 정합 기법을 이용하여 제1 LF 영상 중 하나의 LF 영상을 기준 영상으로 설 정하고, 하나의 기준 영상에서의 한 영역과, 다른 복수의 영상에서 기준 영상의 한 영역에 대응되는 부분의 위 치 차이를 나타내는 시차(disparity) 정보를 포함하는 뎁스 맵을 획득할 수 있다. 그리고, 전자 장치는 획득된 뎁스 맵을 바탕으로 통해 복수의 시프팅 파라미터를 획득할 수 있다. 즉, 전 자 장치는 획득된 뎁스 맵에서의 대표적인 시차(disparity) 정보를 복수의 레이어 영상의 개수에 대응되는 수만큼 추출하여 복수의 시프팅 파라미터를 획득하거나, 뎁스 맵에서 추출된 시차(disparity) 정보를 보간 (scaling)한 값을 시프팅 파라미터로 획득할 수 있다. 본 개시에 따른, 시프팅 파라미터 값은 정수(integer) 또 는 실수(real number)일 수 있다. 즉, 시프팅 파라미터는 본 개시에 따른 복수의 레이어 영상(100-1, 100-2, ..., 100-N)에 대응되는 개수만큼 획 득될 수 있다. 즉, 도 10a를 참조하면, 제1 레이어 영상(100-1)은 제1 시프팅 파라미터(S1)에 대응되는 영역의 표현 품질이 향상된 레이어 영상이며, 제2 레이어 영상은 제2 시프팅 파라미터(S2)에 대응되는 영역의 표현 품 질이 향상된 레이어 영상일 수 있다. 도 10a를 참조하면, 전자 장치는 제1 LF 영상을 제1 인공지능 모델에 입력하여 픽셀 이동 값 (f)을 획득할 수 있다. 그리고, 전자 장치는 LF 영상 변환 모델에 제1 LF 영상 및 픽셀 이동 값 을 입력하여, 제2 LF 영상을 획득할 수 있다. 그리고, 전자 장치는 제1 LF 영상과 픽셀 이동 값을 제2 인공지능 모델에 입력하여, 복수의 레이어 영상(100-1, 100-2, ..., 100-N)을 획득할 수 있다. 그리고, 전자 장치는 시뮬레이션 모델을 통해 복수의 레이어 영상(100-1, 100-2, ..., 100-N) 각각 에 대응되는 시프팅 파라미터에 따라 복수의 레이어 영상(100-1, 100-2, ..., 100-N)을 LF 영상 형식으로 복원 할 수 있다. 즉, 도 5c와 같은 방법을 통해, 전자 장치는 복수의 레이어 영상(100-1, 100-2, ..., 100- N)을 LF 영상 형식으로 복원할 수 있다. 그리고, 전자 장치는 복원된 복수의 LF 영상을 바탕으로 제3 LF 영상을 획득할 수 있다. 일 예로, 전 자 장치는 시뮬레이션 모델을 통해 복원된 복수의 LF 영상들의 평균 값을 바탕으로 제3 LF 영상(3 0)을 획득할 수 있다. 즉, 제3 LF 영상내 제1 뷰 영상은 복수의 LF 영상들의 복수의 제1 뷰 영상에 포함된 픽셀 값들을 각각 평균 내어 합친 영상일 수 있다. 그리고, 전자 장치는 제2 LF 영상 및 제3 LF 영상을 바탕으로 제1 인공지능 모델 및 제2 인 공지능 모델을 학습시킬 수 있다. 일 예로, 전자 장치는 제2 LF 영상 및 제3 LF 영상을 비 교하여 손실 함수를 획득하고, 손실 함수가 감소되는 방향으로 제1 인공지능 모델 및 제2 인공지능 모델 을 학습시킬 수 있다. 여기서, 손실 함수는 수학식1과 같은 형태일 수 있으나, 이에 한정되지 않는다. 즉, 평균 제곱의 오차를 이용하 여 손실함수를 계산하는 Mean squared error 방법, 영상에 대한 화질을 측정하여 손실함수를 계산하는 SSIM(structural similarity index) 방법, 최소절대편차(least absolute deviations) 또는 최소절대오차(least absolute errors)를 이용하여 손실함수를 계산하는 L1 norm 방법 및 최소제곱오차(least squares errors)를 이 용하여 손실함수를 계산하는 L2 norm 방법 등을 다양하게 조합하여 손실 함수를 획득할 수 있다. 상술한 과정을 통해, 팩토리제이션을 수행하기 위한 제2 인공지능 모델이 학습되고, 학습된 제2 인공지능 모델에 제1 LF 영상 및 픽셀 이동 값이 입력되는 경우, 복수의 시프팅 파라미터가 반영된 복수의 레이어 영상(100-1, 100-2, ..., 100-N)이 획득될 수 있다. 그리고, 타임 멀티플렉싱 (time multiplexing) 기법을 적용하기 위한 제1 인공지능 모델 및 제2 인공지능 모델의 학습 방법은 도 10a의 학습 방법에 한정되지 않는다. 즉, 도 10b와 같은 방법으로 제1 인공지능 모델 및 제2 인공지능 모델이 학습될 수 있다. 도 10b는 본 개시의 또 다른 실시 예에 따른, 타임 멀티플렉싱 기법을 이용하기 위해 복수의 레이어 영상을 획 득하기 위한 제2 인공지능 모델의 학습 방법을 도시한 도면이다. 도 10b를 참조하면, 전자 장치는 제1 LF 영상을 제1 인공지능 모델에 입력하여 픽셀 이동 값 (f)을 획득할 수 있다. 그리고, 전자 장치는 LF 영상 변환 모델에 제1 LF 영상 및 픽셀 이동 값 을 입력하여, 제2 LF 영상을 획득할 수 있다. 그리고, 전자 장치는 제1 LF 영상을 제2 인공지능 모델에 입력하여, 복수의 레이어 영상(100-1, 100-2, ..., 100-N)을 획득할 수 있다. 그리고, 전자 장치는 시뮬레이션 모델을 통해 복수의 레이어 영상(100-1, 100-2, ..., 100-N) 각각 에 대응되는 시프팅 파라미터에 따라 복수의 레이어 영상(100-1, 100-2, ..., 100-N)을 LF 영상 형식으로 복원 하고, 복원된 복수의 LF 영상을 바탕으로 제3 LF 영상을 획득할 수 있다. 일 예로, 전자 장치는 시뮬 레이션 모델을 통해 복원된 복수의 LF 영상들의 평균 값을 바탕으로 제3 LF 영상을 획득할 수 있다. 즉, 제3 LF 영상내 제1 뷰 영상은 복수의 LF 영상들의 복수의 제1 뷰 영상에 포함된 픽셀 값들을 각각 평균 내어 합친 영상일 수 있다. 그리고, 전자 장치는 제2 LF 영상 및 제3 LF 영상을 바탕으로 제1 인공지능 모델 및 제2 인 공지능 모델을 학습시킬 수 있다. 일 예로, 전자 장치는 제2 LF 영상 및 제3 LF 영상을 비 교하여 손실 함수를 획득하고, 손실 함수가 감소되는 방향으로 제1 인공지능 모델 및 제2 인공지능 모델 을 학습시킬 수 있다. 상술한 과정을 통해, 팩토리제이션을 수행하기 위한 제2 인공지능 모델이 학습되고, 학습된 제2 인공지능 모델에 제1 LF 영상 및 픽셀 이동 값이 입력되는 경우, 복수의 시프팅 파라미터가 반영된 복수의 레이어 영상(100-1, 100-2, ..., 100-N)이 획득될 수 있다. 도 11은 본 개시의 일 실시 예에 따른, 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 우선, 전자 장치는 서로 다른 시점의 제1 LF 영상을 획득할 수 있다(S1110). 그리고, 전자 장치 는 제1 인공지능 모델에 제1 LF 영상을 입력하여 제1 LF 영상 내 픽셀들을 변환하기 위한 픽셀 이동 값을 획득할 수 있다(S1120). 그리고, 전자 장치는 제1 LF 영상 내의 픽셀들을 픽셀 이동 값에 따라 변환하여 제2 LF 영상을 획 득할 수 있다(S1130). 구체적으로, 전자 장치는 제1 LF 영상에 포함된 복수의 뷰 영상 각각에 대응되 는 픽셀 이동 값에 따라 복수의 뷰 영상 각각의 픽셀을 이동시켜 제2 LF 영상을 획득할 수 있다. 즉, 전자 장치는 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀들을 제1 뷰 영상에 대응되는 제1 픽셀 이동 값에 따라 이동시켜, 제2 LF 영상의 제1 뷰 영상을 획득할 수 있으며, 전자 장치는 이러한 과정을 제1 LF 영상에 포함된 모든 뷰 영상에 적용하여 제2 LF 영상을 획득할 수 있다. 그리고, 일 예로, 픽셀 이동 값은 픽셀 각각에 대응되는 서브 픽셀 이동 값들을 포함할 수 있다. 즉, 전자 장치 는 제1 LF 영상에 포함된 제1 뷰 영상 내 픽셀 각각을 제1 픽셀 이동 값에 포함된 서브 픽셀 이동 값 에 따라 이동시켜, 제2 LF 영상의 제1 뷰 영상을 획득할 수 있다. 그리고, 전자 장치는 LF 영상을 레이어 영상으로 변환하기 위한 제2 인공지능 모델에 제1 LF 영상 및 제2 LF 영상을 입력하여 레이어 영상을 획득할 수 있다(S1140). 다만, 이에 한정되지 않고, 전자 장치는 제2 인공지능 모델에 제1 LF 영상, 제2 LF 영상 및 픽셀 이동 값을 입력하여, 레이어 영상을 획득할 수 있다. 또한, 전자 장치는 제2 인공지능 모델에 제1 LF 영상을 입 력하여, 레이어 영상을 획득할 수 있다. 그리고, 전자 장치는 LF 영상을 복원하기 위한 시뮬레이션 모델에 획득한 레이어 영상을 입력 하여 제3 LF 영상을 획득할 수 있다(S1150). 일 예로, 레이어 영상은 제1 레이어 영상, 제2 레이어 영상 및 제3 레이어 영상을 포함할 수 있다. 이 경 우, 전자 장치는 제1 레이어 영상 및 상기 제3 레이어 영상 각각을 시점 별로 시프팅하고, 시프팅된 제1 레이어 영상 및 시프팅된 제3 레이어 영상을 제2 레이어 영상과 함께 크롭하여 제3 LF 영상을 획득할 수 있다. 그리고, 전자 장치는 제2 LF 영상과 제3 LF 영상을 바탕으로, 제1 인공지능 모델 및 제2 인공지능 모델을 학습시킬 수 있다(S1160). 구체적으로, 전자 장치(20 0)는 제2 LF 영상과 상기 제3 LF 영상을 비교하여 손실 함수를 획득하고, 손실 함수를 바탕으로 제1 인 공지능 모델 및 제2 인공지능 모델을 학습시킬 수 있다. 그리고, 전자 장치는 상술한 과정들을 반복하여, 학습된 제1 인공지능 모델 및 제2 인공지능 모델을 획득 할 수 있다. 그리고, 전자 장치는 제1 LF 영상을 학습된 제1 인공지능 모델에 입력하여, 픽셀 이동 값 을 획득하고, 제1 LF 영상 내의 픽셀들을 상기 픽셀 이동 값에 따라 변환하여 제2 LF 영상을 획득할 수 있 다. 그리고, 전자 장치는 제1 LF 영상 제2 LF 영상을 학습된 제2 인공지능 모델에 입력하여 레이어 영 상을 획득할 수 있다. 다만, 이에 한정되지 않고, 전자 장치는 제1 LF 영상을 학습된 제1 인공지능 모델에 입력하여, 픽셀 이동 값을 획득하고, 제1 LF 영상 및 상기 픽셀 이동 값을 학습된 제2 인공지능 모델에 입력하여 레이어 영 상을 획득할 수 있다. 학습된 제1 인공지능 모델로부터 레이어 영상이 획득되면, 전자 장치는 획득된 레이어 영상을 적층형 디스 플레이에 제공할 수 있다. 본 문서의 실시 예의 다양한 변경(modifications), 균등물(equivalents), 및/또는 대체물(alternatives)을 포 함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사 용될 수 있다. 본 문서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 문서에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 문서에서 사용된 \" 제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식 할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 문서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 부프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 한편, 본 개시에서 사용된 용어 \"부\" 또는 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구성된 유닛을 포함하 며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. \"부\" 또는 \"모듈\"은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수 있다. 예를 들면, 모듈은 ASIC(application-specific integrated circuit)으로 구성될 수 있다. 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명 령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 적층형 디스플레이 장치를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세서의 제 어하에 다른 구성요소들을 이용하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터 프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않 으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 일 실시 예에 따르면, 본 문서에 개시된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행 할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다."}
{"patent_id": "10-2020-0183842", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른, 레이어 영상 획득을 위한 제1 및 제2 인공지능 모델의 학습 과정을 도시 한 도면이다. 도 2는 본 개시에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 3은 본 개시에 따른 3 x 3 뷰의 제1 LF 영상을 도시한 도면이다. 도 4는 도 3의 제1 LF 영상이 픽셀 이동 값에 따라 변환되어 획득되는 제2 LF 영상을 도시한 도면이다. 도 5a는 본 개시의 일 실시 예에 따른, 세 장의 레이어 영상을 나타낸 도면이다. 도 5b는 본 개시의 일 실시 예에 따른, (3 X 3) 뷰의 제3 LF 영상을 도시한 도면이다. 도 5c 는 본 개시의 일 실시 예에 따른, 레이어 영상을 제3 LF 영상으로 복원하는 과정을 설명하기 위한 도면이 다. 도 6a 는 본 개시의 일 실시 예에 따른, 적층형 디스플레이에 제공하기 위한 레이어 영상을 획득하는 과정을 도 시한 도면이다. 도 6b 는 본 개시의 또 다른 실시 예에 따른, 적층형 디스플레이에 제공하기 위한 레이어 영상을 획득하는 과정 을 도시한 도면이다. 도 7은 본 개시의 일 실시 예에 따른, 제1 LF 영상 및 픽셀 이동 값을 제2 인공지능 모델의 입력 데이터로 설정 하여 제1 인공지능 모델 및 제2 인공지능 모델의 학습이 수행되는 과정을 도시한 도면이다. 도 8은 본 개시의 일 실시 예에 따른, 제1 LF 영상 및 제2 LF 영상을 제2 인공지능 모델의 입력 데이터로 설정 하여 제1 인공지능 모델 및 제2 인공지능 모델의 학습이 수행되는 과정을 도시한 도면이다. 도 9은 본 개시의 일 실시 예에 따른, 제1 LF 영상을 제2 인공지능 모델의 입력 데이터로 설정하여 제1 인공지 능 모델 및 제2 인공지능 모델의 학습이 수행되는 과정을 도시한 도면이다. 도 10a는 본 개시의 일 실시 예에 따른, 타임 멀티플렉싱 기법을 이용하기 위해 복수의 레이어 영상을 획득하기 위한 제2 인공지능 모델의 학습 방법을 도시한 도면이다. 도 10b는 본 개시의 또 다른 실시 예에 따른, 타임 멀티플렉싱 기법을 이용하기 위해 복수의 레이어 영상을 획 득하기 위한 제2 인공지능 모델의 학습 방법을 도시한 도면이다. 도 11은 본 개시의 일 실시 예에 따른, 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
