{"patent_id": "10-2023-0101797", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0081313", "출원번호": "10-2023-0101797", "발명의 명칭": "가상 공간에서의 디지털 휴먼 제공 방법 및 시스템", "출원인": "주식회사 엘젠", "발명자": "김남현"}}
{"patent_id": "10-2023-0101797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "가상 공간에서의 디지털 휴먼 제공 방법에 있어서,복수의 공간을 포함하는 상기 가상 공간에서 관심 공간을 특정하는 단계;상기 관심 공간과 관련된 인물의 인물 정보를 획득하는 단계;인공 신경망이, 상기 획득한 인물 정보에 기반하여, 상기 인물과 대응되는 상기 디지털 휴먼을 생성하는 단계;및사용자가 상기 가상 공간에 접속하는 것에 응답하여, 상기 생성된 디지털 휴먼을 상기 가상 공간 중 상기 관심공간에 제공하는 단계를 포함하고,상기 인공 신경망은, 특정 공간과 관련된 인물의 인물 정보를 입력 받고, 입력 받은 인물 정보로부터 인물 특성을 추출함으로써, 추출된 인물 특성을 갖는 상기 디지털 휴먼을 생성하는 방법을 학습하고, 상기 인물 정보를 획득하는 단계에서는, 상기 인물을 촬영한 영상 정보로부터, 상기 인물의 복수의 동작 중 상기 관심 공간에 대응되는 유효 동작을 식별하여 상기 인물 정보를 획득하고,상기 인공 신경망은, 상기 유효 동작으로부터 추출된 제스처에 따라 동작하는 상기 디지털 휴먼을 생성하는 방법을 학습하며, 상기 유효 동작은, 상기 가상 공간 별로 미리 정의되어 존재하는 것을 특징으로 하는, 디지털 휴먼 제공 방법."}
{"patent_id": "10-2023-0101797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인물 정보는 상기 인물에 대한 이미지 정보 및 음성 정보를 포함하고,상기 인공 신경망은, 상기 이미지 정보로부터 추출된 외형 및 상기 음성 정보로부터 추출된 음성 중 적어도 일부를 갖도록 상기 디지털 휴먼을 생성하는 방법을 학습하는 것을 특징으로 하는, 디지털 휴먼 제공 방법."}
{"patent_id": "10-2023-0101797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 인물 정보 중 적어도 일부는, 상기 관심 공간과 대응되는 실제 공간 내의 상기 인물에 대하여 상기 실제공간에 배치되는 정보 획득부를 통해 획득되는 것을 특징으로 하는, 디지털 휴먼 제공 방법."}
{"patent_id": "10-2023-0101797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 영상 정보는, 상기 실제 공간에 매치된 카메라를 통해 수신되는 것을 특징으로 하는, 디지털 휴먼 제공 방법."}
{"patent_id": "10-2023-0101797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 인물 정보는 상기 인물의 업무 정보를 포함하고,상기 인물 정보를 획득하는 단계에서는, 상기 영상 정보에 포함된 상기 인물의 복수의 동작 중, 상기 인물의 업무 정보와 대응되는 상기 유효 동작을 식별하는 것을 특징으로 하는, 디지털 휴먼 제공 방법.공개특허 10-2024-0081313-3-청구항 6 제4항에 있어서,상기 인물 정보를 획득하는 단계에서는,상기 관심 공간에 배치되는 객체의 객체 정보를 획득하고, 상기 객체 정보를 이용하여 상기 영상 정보에서 상기 객체를 인식하고,상기 영상 정보에 포함된 상기 인물의 복수의 동작 중, 상기 인식된 객체의 위치와 상기 인물의 위치가 미리 설정된 범위 이내인 경우에 행해진 동작만을 상기 유효 동작으로 식별하는 것을 특징으로 하는, 디지털 휴먼 제공방법."}
{"patent_id": "10-2023-0101797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 관심 공간에 상기 디지털 휴먼을 제공하는 단계는:상기 가상 공간 내에서의 상기 사용자의 요청을 수신하는 단계, 및상기 인물 특성을 가지고 상기 요청에 대한 대응을 수행하는 상기 디지털 휴먼을 상기 관심 공간에 제공하는 단계를 더 포함하는 것을 특징으로 하는, 디지털 휴먼 제공 방법."}
{"patent_id": "10-2023-0101797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 인공 신경망은, 상기 이미지 정보 및 상기 음성 정보 중 적어도 하나로부터 상기 인물의 성격 유형을 추출하고, 상기 추출된 성격 유형에 대응되는 상기 외형 및 상기 음성 중 적어도 일부를 갖는 상기 디지털 휴먼을생성하는 방법을 학습하는 것을 특징으로 하는, 디지털 휴먼 제공 방법."}
{"patent_id": "10-2023-0101797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "가상 공간에서의 디지털 휴먼 제공 시스템에 있어서,상기 디지털 휴먼 제공 시스템의 제어부는,사용자 입력에 근거하여, 복수의 공간을 포함하는 상기 가상 공간에서 관심 공간을 특정하고,상기 관심 공간과 관련된 인물을 촬영한 영상 정보로부터, 상기 인물의 복수의 동작 중 상기 관심 공간에 대응되는 유효 동작을 식별하여, 상기 관심 공간과 관련된 상기 인물의 인물 정보를 획득하고,인공 신경망이, 상기 획득한 인물 정보에 기반하여, 상기 인물과 대응되는 상기 디지털 휴먼을 생성하고,상기 사용자가 상기 가상 공간에 접속하는 것에 응답하여, 상기 생성된 디지털 휴먼을 상기 가상 공간 중 상기관심 공간에 제공하며,상기 인공 신경망은, 특정 공간과 관련된 인물의 인물 정보를 입력 받고, 입력 받은 인물 정보로부터 인물 특성을 추출함으로써, 추출된 인물 특성을 갖는 상기 디지털 휴먼을 생성하는 방법을 학습하고, 상기 유효 동작은, 상기 가상 공간 별로 미리 정의되어 존재하는 것을 특징으로 하는, 디지털 휴먼 제공 시스템."}
{"patent_id": "10-2023-0101797", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "전자기기에서 하나 이상의 프로세스에 의하여 실행되며, 컴퓨터로 판독될 수 있는 매체에 저장 가능한 프로그램으로서,상기 프로그램은,복수의 공간을 포함하는 상기 가상 공간에서 관심 공간을 특정하는 단계;상기 관심 공간과 관련된 인물의 인물 정보를 획득하는 단계;공개특허 10-2024-0081313-4-인공 신경망이, 상기 획득한 인물 정보에 기반하여, 상기 인물과 대응되는 상기 디지털 휴먼을 생성하는 단계;및사용자가 상기 가상 공간에 접속하는 것에 응답하여, 상기 생성된 디지털 휴먼을 상기 가상 공간 중 상기 관심공간에 제공하는 단계를 수행하는 명령어들을 포함하고,상기 인공 신경망은, 특정 공간과 관련된 인물의 인물 정보를 입력 받고, 입력 받은 인물 정보로부터 인물 특성을 추출함으로써, 추출된 인물 특성을 갖는 상기 디지털 휴먼을 생성하는 방법을 학습하고, 상기 인물 정보를 획득하는 단계에서는, 상기 인물을 촬영한 영상 정보로부터, 상기 인물의 복수의 동작 중 상기 관심 공간에 대응되는 유효 동작을 식별하여 상기 인물 정보를 획득하고,상기 인공 신경망은, 상기 유효 동작으로부터 추출된 제스처에 따라 동작하는 상기 디지털 휴먼을 생성하는 방법을 학습하며, 상기 유효 동작은, 상기 가상 공간 별로 미리 정의되어 존재하는 것을 특징으로 하는 컴퓨터로 판독될 수 있는기록매체에 저장된 프로그램."}
{"patent_id": "10-2023-0101797", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "위에서 살펴본 과제를 해결하기 위하여, 본 발명에 따른 디지털 휴먼 제공 방법은, 복수의 공간을 포함하는 상기 가상 공간에서 관심 공간을 특정하는 단계, 상기 관심 공간과 관련된 인물의 인물 정보를 획득하는 단계, 인공 신경망이, 상기 획득한 인물 정보에 기반하여, 상기 인물과 대응되는 상기 디지털 휴먼을 생성하는 단계 및 사용 자가 상기 가상 공간에 접속하는 것에 응답하여, 상기 생성된 디지털 휴먼을 상기 가상 공간 중 상기 관심 공간 에 제공하는 단계를 포함하고, 상기 인공 신경망은, 특정 공간과 관련된 인물의 인물 정보를 입력 받고, 입력 받 은 인물 정보로부터 인물 특성을 추출함으로써, 추출된 인물 특성을 갖는 상기 디지털 휴먼을 생성하는 방법을 학습하는 것을 특징으로 할 수 있다."}
{"patent_id": "10-2023-0101797", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 가상 공간에서의 디지털 휴먼 제공 방법 및 시스템에 관한 것이다. 보다 구체적으로, 본 발명은 인공 신경망을 이용하여 특정 인물에 대한 정보로부터 인물 특성을 추출함으로써, 추출된 인물 특성을 갖는 디지털 휴먼을 가상 공간을 통해 제공하는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0101797", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기술이 발전함에 따라, 전자기기(예를 들어, 스마트폰, 태블릿 PC, 자동화 기기 등)의 보급이 대중화되었으며, 이에 따라 일상생활의 많은 부분에서 전자기기에 대한 의존도가 점차적으로 높아지고 있다. 특히, 디스플레이 기술의 발전으로 사용자는 평면 이미지 뿐만 아니라, 다양한 수단을 통해 3차원적 이미지 및 3차원적 공간을 볼 수 있다. 이에 따라, 사용자에게 3차원적인 시각적 사용자 경험을 제공하기 위해 가상 현실 (virtual reality) 및 증강 현실(augmented reality) 서비스가 제공되고 있다. 이처럼 현재 3차원적 공간을 경 험하는 것은 사용자 경험의 새로운 트렌드가 되었으며, 사용자는 가상 공간에서 시뮬레이션하고, 시각적 및 기 타 감각적 경험을 제공받고, 가상 이미지와 상호 작용할 수 있다. 더 나아가, 위의 개념들을 모두 포괄하며 혼합 현실 환경을 제공하는 대표적인 서비스로서, 메타버스 (metaverse)가 있다. 이 메타버스는 가공, 추상을 의미하는 '메타(meta)'와 현실세계를 의미하는 '유니버스 (universe)'의 합성어로 3차원 가상 공간과 현실 공간의 연결을 의미한다. 메타버스는 기존의 가상 현실 환경 (virtual reality environment)이라는 용어보다 진보된 개념으로서, 웹과 인터넷 등의 가상세계가 현실세계에 흡수된 상술한 혼합 현실 환경(mixed reality environment)을 제공한다. 메타버스(metaverse)는 사용자의 참여에 따라 무한한 확장이 가능하며, 캐릭터, 환경 및 공간 등을 자유자재로 선택할 수 있다. 예를 들어, 사용자는 지형을 생성하고, 지형에 원하는 자연물 및 시설물 등을 배치할 수 있다. 한편, 디지털 휴먼은 가상 공간의 다른 사용자가 보고 상호 작용할 수 있는 사용자의 그래픽 표현의 하나의 방 법이며, 현실 공간의 사용자는 디지털 휴먼을 사용하여 가상 공간의 다른 사용자의 디지털 휴먼들과 상호 작용 하거나, 해당 가상 공간에서의 각종 경제 활동, 문화 활동, 교육 활동 등을 수행할 수 있다."}
{"patent_id": "10-2023-0101797", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 가상 공간 중 특정 관심 공간과 관련된 실제 인물의 인물 정보를 획득하고, 인경 신경망이 인물 정보 를 이용하여 실제 인물과 대응되는 디지털 휴먼을 생성함으로써, 생성된 디지털 휴먼을 가상 공간을 통해 제공 하는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0101797", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "위에서 살펴본 과제를 해결하기 위하여, 본 발명에 따른 디지털 휴먼 제공 방법은, 복수의 공간을 포함하는 상 기 가상 공간에서 관심 공간을 특정하는 단계, 상기 관심 공간과 관련된 인물의 인물 정보를 획득하는 단계, 인 공 신경망이, 상기 획득한 인물 정보에 기반하여, 상기 인물과 대응되는 상기 디지털 휴먼을 생성하는 단계 및 사용자가 상기 가상 공간에 접속하는 것에 응답하여, 상기 생성된 디지털 휴먼을 상기 가상 공간 중 상기 관심 공간에 제공하는 단계를 포함하고, 상기 인공 신경망은, 특정 공간과 관련된 인물의 인물 정보를 입력 받고, 입 력 받은 인물 정보로부터 인물 특성을 추출함으로써, 추출된 인물 특성을 갖는 상기 디지털 휴먼을 생성하는 방 법을 학습하는 것을 특징으로 할 수 있다. 나아가, 상기 인물 정보는 상기 인물에 대한 이미지 정보 및 음성 정보를 포함하고, 상기 인공 신경망은, 상기 이미지 정보로부터 추출된 외형 및 상기 음성 정보로부터 추출된 음성 중 적어도 일부를 갖도록 상기 디지털 휴 먼을 생성하는 방법을 학습하는 것을 특징으로 할 수 있다. 나아가, 상기 인물 정보 중 적어도 일부는, 상기 관심 공간과 대응되는 실제 공간 내의 상기 인물에 대하여 상 기 실제 공간에 배치되는 정보 획득부를 통해 획득될 수 있다. 나아가, 상기 인물 정보는, 상기 실제 공간 내에서의 상기 인물의 동작을 포함하는 영상 정보를 더 포함하고, 상기 인공 신경망은, 상기 영상 정보로부터 추출된 제스처(gesture)에 따라 동작하는 상기 디지털 휴먼을 생성 하는 방법을 학습하는 것을 특징으로 할 수 있다. 나아가, 상기 인물 정보는 상기 인물의 업무 정보를 포함하고, 상기 영상 정보를 포함하는 상기 인물 정보를 획 득하는 단계는, 상기 영상 정보에 포함된 상기 인물의 복수의 동작 중, 기 설정된 기준에 근거하여, 상기 인물 의 업무 정보와 대응되는 유효 동작을 식별하는 단계, 및 상기 유효 동작을 포함하는 영상 정보를 상기 인물 정 보로써 획득하는 단계를 더 포함하고, 상기 인공 신경망은, 상기 유효 동작으로부터 추출된 제스처에 따라 동작 하는 상기 디지털 휴먼을 생성하는 방법을 학습하는 것을 특징으로 할 수 있다. 나아가, 상기 디지털 휴먼 제공 방법은, 상기 음성 정보로부터 상기 인물의 발화 내용을 식별하는 단계를 더 포 함하고, 상기 인공 신경망은 상기 발화 내용으로부터 상기 인물의 발화 양식을 추출함으로써, 상기 가상 공간 내에서 상기 발화 양식에 따라 발화하는 상기 디지털 휴먼을 생성하는 방법을 학습하는 것을 특징으로 할 수 있 다. 나아가, 상기 관심 공간에 상기 디지털 휴먼을 제공하는 단계는, 상기 가상 공간 내에서의 상기 사용자의 요청 을 수신하는 단계, 및 상기 인물 특성을 가지고 상기 요청에 대한 대응을 수행하는 상기 디지털 휴먼을 상기 관 심 공간에 제공하는 단계를 더 포함할 수 있다. 나아가, 상기 인공 신경망은, 상기 이미지 정보 및 상기 음성 정보 중 적어도 하나로부터 상기 인물의 성격 유 형을 추출하고, 상기 추출된 성격 유형에 대응되는 상기 외형 및 상기 음성 중 적어도 일부를 갖는 상기 디지털 휴먼을 생성하는 방법을 학습하는 것을 특징으로 할 수 있다. 한편, 본 발명에 따른 가상 공간에서의 디지털 휴먼 제공 시스템은, 제어부를 포함하고, 제어부는, 사용자 입력 에 근거하여, 복수의 공간을 포함하는 상기 가상 공간에서 관심 공간을 특정하고, 상기 관심 공간과 관련된 인 물의 인물 정보를 획득하고, 인공 신경망이, 상기 획득한 인물 정보에 기반하여, 상기 인물과 대응되는 상기 디 지털 휴먼을 생성하고, 상기 사용자가 상기 가상 공간에 접속하는 것에 응답하여, 상기 생성된 디지털 휴먼을 상기 가상 공간 중 상기 관심 공간에 제공하고, 상기 인공 신경망은, 특정 공간과 관련된 인물의 인물 정보를 입력 받고, 입력 받은 인물 정보로부터 인물 특성을 추출함으로써, 추출된 인물 특성을 갖는 상기 디지털 휴먼 을 생성하는 방법을 학습하는 것을 특징으로 할 수 있다. 한편, 전자기기에서 하나 이상의 프로세스에 의하여 실행되며, 컴퓨터로 판독될 수 있는 매체에 저장 가능한 프 로그램으로서, 상기 프로그램은, 복수의 공간을 포함하는 상기 가상 공간에서 관심 공간을 특정하는 단계, 상기 관심 공간과 관련된 인물의 인물 정보를 획득하는 단계, 인공 신경망이, 상기 획득한 인물 정보에 기반하여, 상 기 인물과 대응되는 상기 디지털 휴먼을 생성하는 단계 및 사용자가 상기 가상 공간에 접속하는 것에 응답하여, 상기 생성된 디지털 휴먼을 상기 가상 공간 중 상기 관심 공간에 제공하는 단계를 수행하는 명령어들을 포함하 고, 상기 인공 신경망은, 특정 공간과 관련된 인물의 인물 정보를 입력 받고, 입력 받은 인물 정보로부터 인물 특성을 추출함으로써, 추출된 인물 특성을 갖는 상기 디지털 휴먼을 생성하는 방법을 학습하는 것을 특징으로 할 수 있다."}
{"patent_id": "10-2023-0101797", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 다양한 실시 예에 따르면, 디지털 휴먼 제공 방법 및 시스템은 복수의 공간을 포함하는 가상 공간 중 특정 관심 공간과 관련된 인물과 대응되는 디지털 휴먼을 생성하여 제공함으로써, 공간 특성에 적합한 디지 털 휴먼을 통해 가상 공간과 관련된 서비스를 제공할 수 있다. 또한, 본 발명의 다양한 실시 예에 따른 디지털 휴먼 제공 방법 및 시스템은, 관심 공간과 관련된 인물의 인물 정보를 활용하여 인물 특성을 추출하고, 추출된 인물 특성을 갖도록 디지털 휴먼을 생성 및 제공함으로써, 실존 인물과의 이질감을 최소화하고, 사용자에게 보다 실제 공간과 유사한 사용자 경험을 제공할 수 있다. 나아가, 본 발명의 다양한 실시 예에 따르면, 디지털 휴먼 제공 방법 및 시스템은, 실제 공간에서 인물이 수행 하는 복수의 제스처 중 가상 공간 내 특정 공간에서의 업무와 관련된 제스처만을 식별하여 인공 신경망을 학습 시킴으로써, 공간 특성 및 인물 특성을 모두 반영한 디지털 휴먼을 제공하고, 이를 통해 보다 실제 경험과 유사 한 사용자 경험을 제공할 수 있다."}
{"patent_id": "10-2023-0101797", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소에는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설 명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼 용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실 시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 발명에 따른 디지털 휴먼 제공 시스템을 도시한다. 도 1을 참조할 때, 일 실시 예에 따른 디지털 휴먼 제공 시스템은, 가상 공간 중 특정 공간과 관련된 인물 정보를 획득하고, 인공 신경망이 획득한 인물 정보를 이용하여 생성한 디지털 휴먼을 가상 공간을 통해 사용자 단말로 제공하도록 구성될 수 있다. 이때, 사용자 단말은 다양한 형태의 전자 장치로 참조될 수 있다. 예를 들어, 사용자 단말은 스마트 폰, 태블릿 PC, 전자책 리더기, 데스크탑 PC, 랩탑 PC, 가전 장치, 또는 웨어러블(wearable) 장치 중 적어도 하 나로 참조될 수 있으나, 이에 한정되는 것은 아니다. 단, 설명의 편의를 위해서 아래에서 사용자 단말은 웨어러블 장치 중 가상 현실(virtual reality) 환경을 제공하는 헤드 마운티드 디스플레이(HMD, head mounted display)로 참조하여 설명한다. 또한, 디지털 휴먼은 가상 공간 중 특정 관심 공간에 제공되는 가상의 캐릭터(또는, 아바타)로 이 해될 수 있다. 즉, 디지털 휴먼은 캐릭터 또는 아바타로 명명될 수 있음은 물론이다. 보다 구체적으로, 디지털 휴먼은 가상 공간 중 관심 공간에 제공됨으로써, 사용자 요청에 대 한 응답을 제공하는 가상의 객체로 참조될 수 있다. 예를 들어, 디지털 휴먼 제공 시스템은 가상 공간 중 특정 관심 공간에 디지털 휴먼을 제공 함으로써, 디지털 휴먼이 가상 공간 내에서의 사용자 요청에 대응하는 안내 또는 가이드를 제공하 도록 할 수 있다. 따라서, 본 발명에 따른 디지털 휴먼 제공 시스템은, 디지털 휴먼을 생성하고, 생성된 디지털 휴먼을 포함 하는 가상 공간을 사용자 단말을 통해 사용자에게 제공할 수 있다. 이를 위해, 일 실시 예에 따른 디지털 휴먼 제공 시스템은, 통신부, 저장부, 정보 획득부, 제어부 및 인공 신경망 중 적어도 하나를 포함할 수 있다. 한편, 본 발명에 따른 디지털 휴먼 제공 시스템은 애플리케이션 또는 소프트웨어로 구현될 수 있다. 이와 같이 애플리케이션으로 구현되는 디지털 휴먼 제공 시스템은 전자 기기 상에 애플리케이션을 다운받을 수 있는 프로그램(예: 플레이스토어, 앱스토어)을 통해 다운로드 되거나, 전자 기기 상에 초기 설치 프로그램을 통 해 구현될 수 있다. 이 경우, 본 발명에 따른 통신부, 저장부, 정보 획득부 및 제어부는 전자 기기의 구성 요소로 활용될 수 있다. 또한, 본 발명에 따른 디지털 휴먼 제공 시스템은 사용자 단말을 통해 접근되는 웹페이지를 통하여 제공될 수 있다. 본 발명에 따른 통신부는 사용자 단말 및 외부 서버(미도시) 중 적어도 하나와 유선 또는 무선으로 통신하도록 이루어질 수 있다. 통신부는 유선 또는 무선 통신을 이용하여 사용자 단말로 디지털 휴먼 을 포함하는 가상 공간(또는, 메타버스) 서비스를 전송하거나, 외부 서버로부터 특정 인물에 관한 인물 정 보를 수신할 수 있다. 이 때, 통신부는 통신하는 사용자 단말 및 외부 서버 중 적어도 하나의 통신 규격에 따라 다양한 통 신 방식을 지원할 수 있다. 예를 들어, 통신부는, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G(5th Generation Mobile Telecommunication ), 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(InfraredData Association; IrDA), UWB(Ultra-Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 사용자 단말 및 외부 서 버 중 적어도 하나와 통신하도록 구성될 수 있다. 또한, 본 발명에 따른 저장부는 정보 획득부 또는 외부 서버(미도시)로부터 획득한 인물 정보를 저장 하도록 구성될 수 있다. 일 실시 예에 따른 저장부는 디지털 휴먼 제공 시스템 자체에 구비될 수 있 다. 다른 실시 예에 따르면, 저장부의 적어도 일부는, 외부 서버의 클라우드 서버 및 데이터베이스 중 적 어도 하나로 참조될 수 있다. 즉, 저장부는 일 실시 예에 따른 특정 인물에 대한 인물 정보가 저장되는 공 간으로 참조되며, 물리적인 공간에 대한 제약은 없는 것으로 이해될 수 있다. 이 때, 인물 정보는, 특정 인물의 i) 이미지 정보, ii) 음성 정보, iii) 해당 인물의 동작을 포함하는 영상 정 보 및 iv) 해당 인물과 디지털 휴먼 간의 대화 정보 중 적어도 하나를 포함할 수 있다. 한편, 본 발명에 따른 정보 획득부는 특정 인물에 대한 인물 정보를 획득하기 위한 수단으로 이해될 수 있 다. 보다 구체적으로, 제어부는 정보 획득부를 이용하여 가상 공간 중 관심 공간과 관련된 인물의 인물 정보를 획득할 수 있다. 일 실시 예에 따른 정보 획득부는 관심 공간과 대응되는 실제 공간에서, 특정 인물의 인물 정보를 획 득하기 위한 수단으로 이해될 수 있다. 예를 들어, 정보 획득부는 실제 공간에서 인물의 이미지 또는 영상 정보를 획득하기 위한, 카메라, 캠코더 또는 CCTV(closed-circuit television)로 이해될 수 있으나, 이에 한정 되는 것은 아니며, 이미지 또는 영상 정보를 획득할 수 있는 다양한 수단으로 이해될 수 있다. 다른 예를 들어, 정보 획득부는, 관심 공간과 대응되는 실제 공간에서 인물의 음성 정보를 획득하기 위한, 녹음기(recorder)로 이해될 수 있으나, 이에 한정되는 것은 아니며, 음성 정보를 획득하기 위한 다양한 수단으로 이해될 수 있다. 다른 실시 예에 따른 정보 획득부는, 관리자로부터 입력되는 인물 정보를 획득하기 위한 것으로서, 관리자 와 디지털 휴먼 제공 시스템 사이의 매개체가 될 수 있다. 보다 구체적으로, 정보 획득부는 관리자로 부터, 특정 인물에 대한 인물 정보를 수신하는 입력 수단을 의미할 수 있다. 이때, 정보 획득부는 다양한 종류의 입력 부재로 참조될 수 있다. 일 실시 예에 따른 정보 획득부는 기계식 (mechanical) 입력수단(또는, 메커니컬 키, 예를 들어, 마우스(mouse), 조이스틱(joy stick), 물리적인 버튼, 돔 스위치 (dome switch), 조그 휠, 조그 스위치 등) 및 터치식 입력수단 중 적어도 하나로 참조될 수 있 다. 다른 실시 예에 따른, 터치식 입력수단은, 소프트웨어적인 처리를 통해 터치스크린에 표시되는 가상 키 (virtual key), 소프트 키(soft key) 또는 비주얼 키(visual key)로 참조되거나, 상기 터치스크린 이외의 부분 에 배치되는 터치 키(touch key)로 참조될 수 있다. 한편, 상기 가상키 또는 비주얼 키는, 다양한 형태를 가지 면서 터치스크린 상에 표시되는 것이 가능하며, 예를 들어, 그래픽(graphic), 텍스트(text), 아이콘(icon), 비 디오(video) 또는 이들의 조합으로 이루어질 수 있다. 다음으로, 제어부는 디지털 휴먼 제공 시스템의 전반적인 동작을 제어할 수 있다. 일 실시 예에 따르 면, 제어부는, 정보 획득부를 통해 입력되거나 통신부를 통해 외부 서버로부터 수신된, 인물 정 보와 관련된 데이터를 처리할 수 있다. 또한, 획득한 인물 정보를 인공 신경망에 입력함으로써, 인공 신경 망이 디지털 휴먼을 생성하거나 디지털 휴먼을 생성하는 방법을 학습하도록 제어할 수 있다. 또한, 제어부는 획득한 인물 정보 및/또는 사용자 단말로부터 수신한 데이터를 저장부로 저장할 수 있다. 또한, 제어부는, 디지털 휴먼 및 가상 공간과 관련된 데이터를 사용자 단말로 전송함으로써, 사용자 단말에 구비된 디스플레이를 통해 디지털 휴먼을 포함하는 가상 공간이 출력되도록 제어를 수 행할 수 있다. 이 때, 사용자 단말에 구비된 디스플레이의 종류에는 제한이 없다. 또한, 본 발명에 따른 인공 신경망은, 연결선에 의해 연결된 복수의 인공 뉴런들을 이용하여 생물학적인 시스템의 계산 능력을 모방하는 인식 모델로 이해될 수 있다. 인공 신경망은 생물학적인 뉴런의 기능을 단 순화시킨 인공 뉴런들을 이용하고, 인공 뉴런들은 연결 가중치(connection weight)를 가지는 연결선을 통해 상 호 연결될 수 있다. 인공 신경망의 파라미터인 연결 가중치는 연결선이 가지는 값으로써, 연결 강도를 나 타낼 수 있다. 인공 신경망은 인공 뉴런들을 통해 인간의 인지 작용 또는 학습 과정을 수행할 수 있다. 이 때, 인공 신경망의 인공 뉴런은 노드(node)로 지칭될 수 있다.인공 신경망은 복수의 레이어를 포함할 수 있다. 예를 들어, 인공 신경망은 입력 레이어, 하나 이상 의 히든 레이어 및 출력 레이어를 포함할 수 있다. 입력 레이어는 인공 신경망의 학습을 위한 입력 데이터 를 수신하여 히든 레이어로 전달할 수 있고, 출력 레이어는 히든 레이어의 노드들로부터 수신된 신호에 기초하 여 인공 신경망의 출력 데이터를 생성할 수 있다. 하나 이상의 히든 레이어가 입력 레이어 및 출력 레이어 사이에 위치할 수 있고, 입력 레이어를 통해 전달된 입력 데이터를 예측하기 쉬운 값으로 변환할 수 있다. 입력 레이어 및 하나 이상의 히든 레이어에 포함된 노드들은 연결 가중치를 가지는 연결선을 통해 서로 연결될 수 있 고, 히든 레이어 및 출력 레이어에 포함된 노드들도 연결 가중치를 가지는 연결선을 통해 서로 연결될 수 있다. 히든 레이어는 CNN(convolution neural networ)에서의 콘볼루션 필터(convolution filter) 또는 완전 연결 레 이어(fully connected layer)이거나, 특별한 기능이나 특징을 기준으로 묶인 다양한 종류의 필터 또는 레이어를 나타낼 수 있다. 인공 신경망 중에서 복수의 히든 레이어를 포함하는 인공 신경망을 딥 신경망(deep neural network)라 하고, 딥 신경망을 학습시키는 것을 딥러닝(deep learning)이라고 한다. 본 발명에 따른, 인공 신경망은 이러한 딥러닝을 통해 인물 정보로부터 인물 특성(또는, 페르소나)을 추출 하고, 추출된 인물 특성을 갖는 디지털 휴먼을 생성하도록 학습된 모델로 이해될 수 있다. 예를 들어, 인공 신경망은 DNN(deep neural network), RNN(recurrent neural network), BRDNN(bidirectional recurrent deep neural network)와 같은 기계 학습 모델로 이해될 수 있다. 나아가, 인공 신경망은 기계 학습 모델 (machine learning model) 또는 딥러닝 모델(deep learning model)로 지칭될 수 있다. 보다 구체적으로, 인공 신경망은 가상 공간 중 특정 관심 공간과 관련된 인물의 인물 정보를 입 력 받고, 입력된 인물 정보로부터 인물 특성을 추출하고, 추출된 인물 특성 중 적어도 일부를 갖는 디지털 휴먼 을 생성하는 방법을 학습하도록 설계될 수 있다. 이 때, 인공 신경망는 디지털 휴먼 제공 시스템 내부에 구현되거나, 통신부를 통해 디지털 휴먼 제공 시스템과 연결된 외부 장치(또는, 서버)에 구현될 수 있다. 즉, 인공 신경망이 구현되는 공간은, 물리적인 공간에 대한 제약은 없는 것으로 이해될 수 있다. 이상에서 살펴본 디지털 휴먼 제공 시스템의 구성에 근거하여, 아래에서는 학습된 인공 신경망이 인물 정 보를 이용하여 디지털 휴먼을 생성하고, 생성된 디지털 휴먼을 포함하는 가상 공간 서비스를 사용자 단말 을 통해 사용자에게 제공하는 방법에 대해 보다 구체적으로 설명하도록 한다. 도 2는 본 발명에 따른 디지털 휴먼 제공 방법을 나타내는 흐름도다. 도 3은 일 실시 예에 따라 복수의 공간을 포함하는 가상 공간 중 관심 공간을 특정하는 구성을 도시한다. 도 4는 본 발명에 따른 정보 획득부를 이용하여 실제 공간에서 특정 인물의 인물 정보를 획득하는 구성을 도시한다. 도 5는, 본 발명에 따른 정보 획득부를 통 해 획득한 인물 정보를 이용하여 디지털 휴먼을 생성하도록 학습하는 인공 신경망을 도시한다. 도 6은, 본 발명 에 따른 인물 정보 중 이미지 정보를 이용하여, 이미지 정보로부터 추출된 외형을 갖는 디지털 휴먼을 생성하는 구성을 도시한다. 도 7은, 본 발명에 따른 인물 정보 중 음성 정보를 이용하여, 음성 정보로부터 추출된 음성을 갖는 디지털 휴먼을 생성하는 구성을 도시한다. 도 8a 및 도 8b는, 본 발명에 따른 인물 정보 중 영상 정보를 이용하여, 영상 정보로부터 추출된 제스처 중 적어도 일부에 따라 동작하는 디지털 휴먼을 생성하는 구성을 도 시한다. 도 9는, 본 발명에 따른 인물 정보로부터 발화 양식 및 성격 유형을 추출함으로써, 추출된 발화 양식 및 성격 유형에 따라 동작하는 디지털 휴먼을 생성하는 구성을 도시한다. 본 발명에 따른 디지털 휴먼 제공 시스템은 가상 공간 중 특정 공간과 관련된 인물 정보를 획득하고, 인공 신경망이 인물 정보를 이용하여 생성한 디지털 휴먼을 사용자 단말에 표시되는 가상 공간을 통해 사용자에 게 제공할 수 있다. 단, 아래에서는 설명의 편의를 위하여, 디지털 휴먼을 제공하기 위한 동작들이 디지털 휴먼 제공 시스템의 제어부에 의해 수행되는 것으로 설명한다. 본 발명에 따른 제어부는, 복수의 공간을 갖는 가상 공간에서, 관심 공간을 특정할 수 있다 (S201). 보다 구체적으로, 제어부는 가상 공간에 포함된 복수의 공간(301 내지 304) 중 하나에 대한 사용자 입 력에 근거하여, 선택된 공간을 관심 공간으로 특정할 수 있다. 도 3에 도시된 것과 같이, 본 발명에 따른 제어부는 사용자 단말을 통해 사용자에게 표시된 복수의 가상 공간(301 내지 304) 중 적어도 하나에 대한 입력(예: 터치 입력 또는 음성 발화)에 근거하여, 관심 공간을특정할 수 있다. 다른 실시 예에 따르면, 제어부는 복수의 가상 공간(301 내지 304) 중 적어도 하나에 대한, 사용자의 사용 자 단말의 디스플레이를 통한 물리적 입력에 근거하여, 관심 공간을 특정할 수 있다. 예를 들어, 제어부는 복수의 가상 공간(301 내지 304) 중 “시청”을 포함하는 제1 가상 공간에 대한 사용자의 입력에 응답하여, “시청”을 관심 공간으로 특정할 수 있다. 또 다른 실시 예에 따르면, 제어부는 저장부에 사용자 단말에 관한 정보와 연동되어 저장된 정 보 중 적어도 일부에 근거하여, 사용자가 사용자 단말을 통해 가상 공간에 접속하는 것에 응답하여, 복수의 가상 공간(301 내지 304) 중 하나를 관심 공간으로 특정할 수 있다. 나아가, 제어부는 특정된 관심 공간과 관련된 인물을 특정할 수 있다. 보다 구체적으로, 제어부는 관 심 공간이 특정되는 경우, 관심 공간과 연계하여 저장된 정보에 근거하여 관심 공간과 관련된 인물을 특정할 수 있다. 예를 들어, 제어부는 “시청(City hall)”이 관심 공간으로 특정되는 것에 응답하여, “시청” 공간과 연 계되어 저장부에 저장된 정보에 근거하여, “시장(mayor)”을 관심 공간과 관련된 인물로 특정할 수 있다. 저장부에는 가상 공간에 포함된 복수의 가상 공간 각각에 대응되는 인물 정보가 저장될 수 있다. 즉, 복수 의 가상 공간과, 복수의 가상 공간 각각에 대응되는 인물에 대한 정보는 서로 매칭되어 매칭 정보로서 저장부 에 존재할 수 있다. 이때, 복수의 가상 공간 각각에 대응되는 인물에 대한 정보는, 복수의 가상 공간에 대 응되는 실제 공간에서 생활(ex: 근무 또는 거주)하는 인물에 해당할 수 있다. 한편, 실제 공간에서 생활하는 인 물이 변경되는 경우, 예를 들어, 제1 인물이, 특정 실제 공간에서 퇴사하는 경우, 또는 임기가 만료된 경우, 실 제 공간에는 제1 인물이 아닌 제2 인물이 생활할 수 있다. 이러한 인물에 대한 정보가 업데이트 되는 경우, 저 장부의 매칭 정보도 연동되어 업데이트될 수 있다. 한편, 인물에 대한 정보의 업데이트는, 다양한 경로를 통해 이루어질 수 있으므로, 이에 대한 구체적인 설명은 생략한다. 한편, 관심 공간이 특정되는 것에 응답하여 관심 공간과 관련된 인물이 복수인 경우, 복수의 인물 정보(예를 들 면, 복수의 인물 각각에 대한 사진 정보, 이름 정보, 직책, 직함 정보 등)를 사용자 단말을 통해 표시할 수 있다. 이때, 제어부는 표시된 복수의 인물 정보 중 어느 하나, 또는, 적어도 하나에 대한 사용자 입력 에 근거하여, 관심 공간과 관련된 인물을 특정할 수 있다. 예를 들어, 제어부는 “시청”이 관심 공간으로 특정되는 것에 응답하여 “시청”과 관련된 인물, 예를 들 면, “시장”, “행정부시장”, 및 “민원담당관”에 대한 정보를 사용자 단말을 통해 표시하고, 표시된 정보 중 “시장(mayor)”에 대한 사용자 입력에 근거하여, “시장”을 관심 공간과 관련된 인물로 특정할 수 있 다. 다만, 관심 공간 및 관심 공간과 관련된 인물을 특정하는 방법은 상술한 예시들에 한정되는 것은 아니며, 복수 의 가상 공간 중 하나의 공간 및 특정된 공간과 관련된 인물을 특정하기 위한 다양한 수단으로 이해될 수 있다. 나아가, 본 발명에 따른 제어부는 특정된 관심 공간과 관련된 인물의 인물 정보를 획득할 수 있다(S203). 보다 구체적으로, 제어부는 정보 획득부를 제어함으로써, 관심 공간과 관련된 인물로 특정된 인 물의 인물 정보를 획득할 수 있다. 도 4에 도시된 것과 같이, 제어부는 가상 공간 중 관심 공간과 대응되는 실제 공간에 배치 된 정보 획득부를 이용하여, 실제 공간에 존재하는 인물에 대한 인물 정보를 획득할 수 있 다. 예를 들어, 제어부는 실제 공간에 배치된 정보 획득부(예: 카메라)를 통해 촬영한 인물의 이미지 정보 또는 영상 정보를, 인물에 대한 인물 정보로써 획득할 수 있다. 다른 예를 들어, 제어부 는 실제 공간에 배치된 정보 획득부(예: 녹음기)를 통해 녹음한 인물의 음성 정보를, 인물 에 대한 인물 정보로써 획득할 수 있다. 나아가, 제어부는 실제 공간과 다른 공간에 배치되거나, 또는 다른 수단을 이용하여 인물에 대한 인물 정보를 획득할 수 있음은 물론이다. 예를 들어, 제어부는 통신부를 통해 외부 서버로부터 인물 정보를 수신함으로써, 관심 공간과 관련된 인물의 인물 정보를 획득할 수 있다. 제어부는 통신부를 통해 외부 서버로부터 특정 인물에 대한 이미지 파일 또는 음성 파일을 수신할 수 있다.나아가, 제어부는 관심 공간 및 관심 공간과 관련된 인물이 특정되는 것에 응답하여, 관심 공간 및 인물과 연계하여 저장부에 저장된 인물 정보를 호출 또는 로드(load)함으로써 획득 할 수 있다. 이러한 경우에, 인물 정보는 저장부에 인물과 매칭되어 기 존재할 수 있다. 나아가, 본 발명에 따른 제어부는, 인공 신경망이 인물 정보을 이용하여 인물과 대응되는 디지털 휴먼을 생성하도록 제어할 수 있다(S205). 도 5에 도시된 것과 같이, 제어부는 획득한 인물 정보를 인공 신경망에 입력함으로써, 인공 신 경망이 인물 정보를 이용하여 인물과 대응되는 디지털 휴먼을 생성하도록 할 수 있다. 보다 구체적으로, 제어부는 획득한 인물 정보를 인공 신경망에 입력함으로써, 인공 신경망(15 0)이 인물 정보로부터 인물 특성(또는, 페르소나)을 추출하고, 추출된 인물 특성(또는, 페르소나 (Persona)(예를 들면, 외형, 음성, 제스처(Gesture))을 가짐으로써 실제 공간에 실존하는 인물과 대응되는 디지털 휴먼을 생성하도록 할 수 있다. 이 때, 인공 신경망은 인물 정보을 입력 받아, 인물 정보에 기반하여 디지털 휴먼을 생성하 는 방법을 학습하도록 설계될 수 있다. 보다 구체적으로, 인공 신경망은 인물 정보를 입력 받고, 입 력 받은 인물 정보로부터 인물 특성(또는, 페르소나)을 추출하고, 추출된 인물 특성을 갖는 디지털 휴먼 을 생성하는 방법을 학습하도록 설계될 수 있다. 예를 들어, 인공 신경망은 획득한 인물 정보 중 이미지 정보로부터 추출된 외형 및/또는 음성 정보로 부터 추출된 음성을 갖는 디지털 휴먼을 생성하는 방법을 학습하도록 설계될 수 있다. 본 발명에 따른 제어부는 인공 신경망이 실제 공간에 실존하는 인물의 외형과 대응되는 외 형을 갖는 디지털 휴먼을 생성하도록 제어할 수 있다. 보다 구체적으로, 도 6에 도시된 바와 같이, 제어부는 인물 정보 중 이미지 정보를 인공 신경망 에 입력함으로써, 인공 신경망이 이미지 정보로부터 추출된 외형을 갖는 디지털 휴먼 을 생성하도록 할 수 있다. 제어부는 인공 신경망을 통해, 이미지 정보에 기반한 2차원 또는 3차원의 이미지에 해당하는 디 지털 휴먼을 생성할 수 있다. 이때, 이미지 정보는 인물의 얼굴 이미지, 체형 이미지, 서로 다른 의미를 갖는 복수의 제스처(예를 들면, 인사 제스처, 거절 제스처 등)에 해당하는 제스처 이미지 중 적어도 하나를 포함할 수 있다. 인공 신경망 은, 이러한 다양한 이미지 정보에 기반하여, 관심 공간에서 디지털 휴먼이 다양한 표정 및 행동을 취 하도록, 디지털 휴먼을 생성할 수 있다. 한편, 인공 신경망은 인물의 얼굴 이미지와 기 확보된 다 양한 표정 이미지를 합성하여, 인물에 대한 다양한 표정을 갖는 디지털 휴먼을 생성할 수 있다. 나아가, 인공 신경망은 인물의 체형 이미지 및 복수의 제스처 이미지와, 기 확보된 다양한 제스처 이 미지를 합성하여, 다양한 상황에서의 다양한 제스처를 취하는 디지털 휴먼을 생성할 수 있다. 이 때, 인공 신경망은 이미지 정보를 처리하는 다양한 종류의 인공지능 모델로 이해될 수 있다. 예를 들어, 인공 신경망은 FACS(facial action coding system), SER(speech emotion recognition), FER(facial expression recognition), Gaze tracking, Lucas-Kanade Fitting Algorithm, Face Reenactment 및 Face Synthesis 중 적어도 하나의 기술을 활용하는 인공지능 모델로서, 상술한 기술들 중 적어도 하나를 이용하 여 이미지 정보로부터 외형을 추출하고, 추출된 외형을 갖는 디지털 휴먼을 생성하는 방법 을 학습할 수 있다. 단, 인공 신경망이 이미지 정보로부터 외형을 추출하는 기술 또는 방식은 상술한 예시에 한정되 는 것은 아니며, 생물학적인 뉴런 시스템을 이용하여 이미지 정보로부터 외형을 추출하는 다양한 모 델로 이해될 수 있다. 또한, 본 발명에 따른 제어부는 인공 신경망이 실제 공간에 실존하는 인물의 음성과 대응되 는 음성을 갖는 디지털 휴먼을 생성하도록 제어할 수 있다. 도 7에 도시된 바와 같이, 제어부는 인물 정보 중 음성 정보를 인공 신경망에 입력함으로 써, 인공 신경망이 음성 정보로부터 추출한 음성을 갖는 디지털 휴먼을 생성하도록 할 수 있다. 보다 구체적으로, 제어부는 인물의 발화에 따라 획득된 음성 정보를 인공 신경망에 입력함 으로써, 인공 신경망이 음성 정보로부터 추출한 음성으로 발화하는 디지털 휴먼을 생성하도 록 할 수 있다. 이 때, 인공 신경망은 음성 정보를 처리하는 다양한 종류의 인공지능 모델로 이해될 수 있다. 예를 들어, 인공 신경망은 Wavenet 기반의 TTS(text to speech) 합성 기술, Multi-Speaker TTS, Multi- Language TTS, Voice conversion 및 Self-Attention 기술 중 적어도 하나를 활용하는 인공지능 모델로서, 상술 한 기술들 중 적어도 하나를 이용하여 음성 정보로부터 음성을 추출하고, 추출된 음성을 갖는 디지털 휴먼을 생성하는 방법을 학습할 수 있다. 단, 인공 신경망이 음성 정보로부터 음성을 추출하는 기술 또는 방식은 상술한 예시에 한정되는 것은 아니며, 생물학적인 뉴런 시스템을 이용하여 음성 정보로부터 음성을 추출하는 다양한 모델로 이해될 수 있다. 상술한 구성을 통해, 디지털 휴먼 제공 시스템은 관심 공간과 관련된 인물의 외형 및/또는 음성을 갖는 디 지털 휴먼을 생성하여 제공함으로써, 보다 실제 경험과 유사한 사용자 경험(UX, user experience)을 가상 공간 (또는, 메타버스 공간)을 통해 제공할 수 있다. 나아가, 본 발명에 따른 제어부는 인공 신경망이 실제 공간에 실존하는 인물의 동작과 대응 되는 제스처에 따라 동작하는 디지털 휴먼을 생성하도록 제어할 수 있다. 이를 위해, 도 8a 및 도 8b에 도시된 것과 같이, 제어부는 관심 공간과 관련된 인물의 동작을 포 함하는 영상 정보를 인공 신경망에 입력함으로써, 인공 신경망이 영상 정보로부터 추출한 제스처에 따라 동작하는 디지털 휴먼을 생성하도록 할 수 있다. 도 8a를 참조하면, 제어부는 관심 공간과 대응되는 실제 공간에 배치되는 정보 획득부(예: 카메라)를 제어함으로써, 실제 공간에서의 인물의 동작을 포함하는 영상 정보를 획득할 수 있다. 보다 구체적으로, 제어부는 실제 공간에 배치된 복수의 정보 획득부(131 내지 134)를 통해 획득한 정 보에 기반하여, 인물의 동작을 포함하는 영상 정보를 획득할 수 있다. 다만, 다른 실시 예에 따르면, 실제 공간에 배치된 복수의 정보 획득부(131 내지 134)는, 단일한 정보 획 득부(예: 카메라)가 위치를 변경하며 이동하는 구성으로 이해될 수 있다. 예를 들어, 제어부는 SfM(structure from motion)을 이용함으로써, 실제 공간에 배치된 복수의 정보 획득부(131 내지 134)를 통해 획득한 복수의 이미지(image i 내지 image i+3)로부터 인물의 동작을 포함하 는 영상 정보를 획득할 수 있다. 보다 구체적으로, 제어부는 인물에 포함된 복수의 특징점들을 기준으로, 복수의 정보 획득부(131 내지 134)가 획득한 복수의 이미지 및 복수의 이미지 간 시야각에 근거하여, 인물의 동작과 관련된 정보를 획득 할 수 있다. 나아가, 도 8b에 도시된 것과 같이, 제어부는 인물 정보 중 영상 정보를 인공 신경망에 입 력함으로써, 인공 신경망이 영상 정보로부터 추출한 제스처에 따라 동작하는 디지털 휴먼을 생성하도록 할 수 있다. 이 때, 인공 신경망은 영상 정보를 처리하는 다양한 종류의 인공지능 모델로 이해될 수 있다. 예를 들어, 인공 신경망은 ASM(active shape model), Lipsync animation, DCGAN(deep convolutional generative adversarial network) 구조, 3D reconstruction 기술 중 적어도 하나를 활용하는 인공지능 모델로 서, 상술한 기술들 중 적어도 하나를 이용하여 영상 정보로부터 제스처을 추출하고, 추출된 제스처 에 따라 동작하는 디지털 휴먼을 생성하는 방법을 학습할 수 있다. 단, 인공 신경망이 영상 정보로부터 제스처을 추출하는 기술 또는 방식은 상술한 예시에 한정되 는 것은 아니며, 생물학적인 뉴런 시스템을 이용하여 영상 정보로부터 제스처을 추출하는 다양한 모 델로 이해될 수 있다. 또한, 제어부는 영상 정보에 포함된 인물의 복수의 동작 중 유효 동작을 식별하고, 유효 동작을 포함하는 영상을 인공 신경망에 입력함으로써, 인공 신경망이 유효 동작에 기반하여 추출한 제스처에따라 동작하는 디지털 휴먼을 생성하도록 할 수 있다. 여기에서, 유효 동작은 가상 공간에서 디지털 휴먼의 제스처로서 생성해야 할 의미있는 동작으로서, 가상 공간의 목적, 성질 또는 종류에 따라, 서로 다를 수 있다. 또한, 유효 동작은 가상 공간 별로 복수의 유효 동작 이 정의되어 존재할 수 있으며, 이는 저장부에 저장될 수 있다. 즉, 저장부에는, 가상 공간 별로 매 칭된 적어도 하나의 유효 동작 정보가 존재할 수 있다. 예를 들어, \"병원”에 해당하는 가상 공간의 경우, i) 접수 동작, ii) 휠체어를 미는 동작, iii) 인사하는 동작 등이 유효 동작으로 정의되어 존재할 수 있다. 나아가, “시청”에 해당하는 가상 공간의 경우, i) 인사하는 동작, ii) 서류 작성을 안내하는 동작 등이 유효 동작으로 정의되어 존재할 수 있다. 한편, 이러한 유효 동작의 정의는 다양한 방식으로 이루어질 수 있으며, 실제 공간에서 획득된 영상 정보 로부터 인물의 업무를 정의하는 것을 통해 이루어질 수 있다. 예를 들어, 제어부는 인물 정보 로써, 관심 공간 또는 관심 공간과 대응되는 실제 공간에서 인물의 업무 정보를 획득 할 수 있다. 보다 구체적으로, 제어부는 실제 공간에서 인물의 영상 정보로부터 실제 공간에서의 인물의 업무 정보를 추출할 수 있다. 예를 들어, 제어부는 실제 시청 공간에서의 시장(mayor)의 영상 정보에 기반하여, 시장의 안내 업무에 관한 정보를 추출할 수 있다. 그리고, 제어부는 추출된 업무 정보 및 업무 정보에 해당하는 업무를 수행할 때의 인물의 동작 정보를 유효 동작으로서 추출(또는 정의)할 수 있다. 그리고, 제어부는 추출된 유효 동작을 영상 정보부터 획득함으로써 저장부에 저장하고, 디지털 휴먼을 생성하는데 활용할 수 있다. 이와 다르게, 제어부는 관심 공간이 특정되는 것에 응답하여, 관심 공간에 대한 정보와 연계되 어 저장부에 저장된 업무 정보를 획득할 수 있다. 예를 들어, 제어부는 가상 공간 내 시청 공간 이 관심 공간으로 특정되는 것에 응답하여, 시청 공간과 연계되어 저장된 안내 업무에 관한 정보를 획득할 수 있다. 이러한 업무 정보는 다양한 경로로 입수되는 업무 관련 매뉴얼, 업무 지침, 업무 리스트 등으로부터 획득 될 수 있다. 그리고, 제어부는 영상에서, 상기 업무 정보에 따른 업무를 수행할 때, 인물이 어떠한 동 작을 취했는지 추출하고, 추출된 동작 정보를 상기 업무 정보에 대한 유효 동작으로서 정의할 수 있다. 이에 따 라, 가상 공간(관심 가상 공간)에서, 정의된 유효 동작을 수행하는 디지털 휴먼을 생성할 수 있다. 나아가, 제어부는 영상 정보에 포함된 인물의 복수의 동작 중 기 설정된 기준에 근거하여, 인물 의 업무 정보와 대응되는 적어도 하나의 동작을 유효 동작으로 식별할 수 있다. 예를 들어, 제어부는 영상 정보에 포함된 인물의 복수의 동작 중, 관심 공간 내에서 인물 의 업무 정보와 연계되어 저장된 동작들과 대응되는 동작을 유효 동작으로 식별할 수 있다. 다른 예를 들어, 제어부는 영상 정보에 포함된 인물의 복수의 동작 중, 관리자(예를 들면, 디지 털 휴먼 생성 관련 업무 수행자)로부터 수신한 입력을 통해 선택된 적어도 하나의 동작을 유효 동작으로 식별할 수 있다. 또 다른 예를 들어, 제어부는 영상 정보에 포함된 인물의 복수의 동작으로부터, 업무 정보에 해 당하는 업무와 무관하게 수행되는 동작으로 저장된 일반 동작에 해당하는 동작을 제외한 적어도 하나의 동작을 유효 동작으로 식별할 수 있다. 한편, 제어부는 인물 정보를 획득하는 과정에서, 관심 공간 또는 관심 공간과 대응되는 실 제 공간에서 배치되는 객체의 객체 정보를 획득할 수 있다. 이러한 경우에, 가상 공간(또는, 관심 공간)에 는 획득된 객체 정보에 대응하는 가상 객체가 상호작용이 가능하도록 배치될 수도 있다. 이때, 가상 객체에는 객체 정보의 일부 또는 전체가 매칭될 수 있으며, 이를 통해, 사용자는 가상 공간에서 디지털 휴먼을 통해, 실 제 객체에 대응되는 가상 객체와의 상호작용을 수행할 수 있다. 이와 관련하여, 제어부는 실제 공간에서 인물의 영상 정보로부터 실제 공간에서의 인 물이 이용하거나, 또는 인물에 인접한 객체의 객체 정보를 추출할 수 있다. 예를 들어, 제어부는 실제 시청 공간에서의 시장(mayor)의 영상 정보에 기반하여, 시장의 안내 업무에 따라 안내하는 자동화 기기에 관한 정보를 추출할 수 있다. 다른 실시 예에 따르면, 제어부는 관심 공간이 특정되는 것에 응답하여, 관심 공간에 대한 정보 와 연계되어 저장부에 저장된 객체 정보를 획득할 수 있다. 예를 들어, 제어부는 가상 공간 내시청 공간이 관심 공간으로 특정되는 것에 응답하여, 시청 공간과 연계되어 저장된 자동화 기기에 관한 정보를 획득할 수 있다. 나아가, 제어부는 영상 정보에서 객체 정보를 이용하여 객체의 위치를 인식하고, 영상 정보에 포함된 인물의 복수의 동작 중, 인식된 객체의 위치와 인물의 위치가 미리 설정된 범위 이내인 경우에 행해진 동작만을 유효 동작으로 식별할 수 있다. 이때, 제어부는 식별된 유효 동작과, 인식된 객체의 객체 정보를 매칭시킬 수 있다. 여기에서, 유효 동작 에 매칭될 객체 정보는 가상 객체에 매칭된 객체 정보와 동일할 수 있다. 이를 통해, 제어부는 가상 공간 (또는, 관심 공간)에서 디지털 휴먼이 가상 객체와 상호작용하는 경우에, 가상 객체에 매칭된 유효 동작을 수행 하도록 디지털 휴먼을 생성할 수 있다. 이와 관련하여, 제어부는 영상 정보에 대해, 특징점 추출 및 경계 결정 등의 과정을 적용하여 특징들 의 패턴을 획득하고, 획득된 패턴을 미리 마련된 객체 정보와 비교하여 객체를 인식할 수 있다. 예를 들어, 제 어부는 SVM(Support Vector Machine)와 같은 종래의 기법을 이용하여 영상 정보로부터 객체를 인식 할 수 있다. 또한, 제어부는 별도의 딥러닝 알고리즘을 통해 학습된 객체 인식 모델을 이용하여 영상 정보 에서 객체를 인식할 수도 있다. 한편, 유효 동작을 식별하는 과정에 대해 예를 들면, 제어부는 영상 정보에 포함된 인물의 복수 의 동작 중, 관심 공간 내에서 관심 공간과 연계되어 저장된 객체들과 인접한 인물의 동작을 유 효 동작으로 식별할 수 있다. 다른 예를 들어, 제어부는 영상 정보에 포함된 복수의 객체 중, 관리자로부터 수신한 입력을 통해 선 택된 적어도 하나의 객체에 인접한 인물의 동작을 유효 동작으로 식별할 수 있다. 또 다른 예를 들어, 제어부는 영상 정보에 포함된 복수의 객체 중, 관심 공간과 무관하게 배치 된 객체로 저장된 일반 객체에 해당하는 객체를 제외한 적어도 하나의 객체에 인접한 인물의 동작을 유효 동작으로 식별할 수 있다. 이와 관련하여, 제어부는 영상 정보에서 객체 정보를 이용하여 객체의 위치를 인식하고, 영상 정보 에 포함된 인물의 복수의 동작 중, 인식된 객체의 위치와 인물의 위치가 미리 설정된 범위 이내인 경우에 행해진 적어도 하나의 동작을 추출하고, 추출된 적어도 하나의 동작 중, 기 설정된 기준에 근거하여, 인 물의 업무 정보와 대응되는 적어도 하나의 동작을 유효 동작으로 식별할 수도 있다. 나아가, 본 발명에 따른 제어부는 유효 동작만을 포함하는 영상 정보를 인물 정보로써 획득할 수 있 다. 보다 구체적으로, 제어부는 영상 정보에 포함된 인물의 복수의 동작 중 유효 동작을 포함하 는 영상 부분을 인물 정보로써 획득하고, 인공 신경망에 입력할 수 있다. 즉, 본 발명에 따른 제어부는 인물의 복수의 동작 중 유효 동작만을 포함하는 영상 정보를 인공 신경 망에 입력함으로써, 인공 신경망이 유효 동작으로부터 제스처를 추출하고 추출된 제스처에 따라 동작 하는 디지털 휴먼을 생성(또는 생성하는 방법을 학습)하도록 할 수 있다. 또한, 제어부는 실제 공간에서 인물에 대한 영상 정보를 인공 신경망에 입력함으로써, 인공 신경망이 인물의 상황별 행동 양식을 추출하고, 추출된 행동 양식에 따른 제스처를 수행하는 디 지털 휴먼을 생성하도록 할 수 있다. 보다 구체적으로, 제어부는 실제 공간에서 인물에 대한 영상 정보를 인공 신경망에 입력함으로써, 인공 신경망이 실제 공간에서 발생하는 상황 및 각 상황에 대응되는 인물의 행동 양식을 추출하고, 관심 공간에서의 상황에 응답하여 추출된 행동 양 식에 따른 제스처를 수행하는 디지털 휴먼을 생성하도록 할 수 있다. 이를 통해, 본 발명에 따른 디지털 휴먼 제공 시스템은 실제 공간에서 인물의 동작 중 업무와 관련된 유효 동작을 통해 학습한 인공 신경망이 유효 동작으로부터 추출된 제스처에 따라 동작하는 디지털 휴먼을 생성하여 제공함으로써, 보다 정확하고 실제 경험과 유사한 가상 공간에서의 사용자 경험을 제공할 수 있다. 나아가, 도 9에 도시된 것과 같이, 본 발명에 따른 제어부는 인물 정보로부터 식별된 인물의 발화 내용 을 인공 신경망에 입력함으로써, 인공 신경망이 발화 내용으로부터 발화 양식을 추출하고, 추출된 발화 양식에 따라 발화하는 디지털 휴먼을 생성하도록 할 수 있다. 이 때, 발화 내용은 실제 공간 내의 인물의 음성 정보로부터 획득될 수 있다. 실시 예에 따르면, 발화 내용는 영상 정보에서 유효 동작이 식별된 시점과 동일한 시점에 작성된 음 성 정보로부터 획득될 수 있다. 이러한 경우에, 제어부는 유효 동작과 발화 내용을 매칭시킬 수 있다. 이때, 제어부는 서로 다른 영상 정보에서 추출된 어느 한 종류의 유효 동작(예를 들면, 인사 동작)에 다수의 음성 정보(예를 들면, \"안녕하세요.\", \"반갑습니다.\")가 매칭되면, 매칭된 다수의 음성 정보 중 기 설정된 기준을 만족하는 음성 정보만을 이용할 수 있다. 예를 들어, 제어부는 서로 다른 영상 정보에서 추출된 어느 한 종류의 유효 동작에 다수의 음성 정보가 매칭되면, 다수의 음성 정보 중 가장 높은 빈도로 나타나는 음성 정보를 이용할 수 있다. 이를 통해, 제어부는 유효 동작을 취하는 시점에, 상기의 유효 동작에 매칭된 발화 내용을 발화하도 록 디지털 휴먼을 생성할 수 있다. 다른 실시 예에 따르면, 발화 내용은 가상 공간 내에서 사용자와 디지털 휴먼이 대화한 대화 이력 으로부터 획득될 수 있다. 또한, 발화 내용은 가상 공간 중 관심 공간 내에서 현재 사용자를 제 외한 다른 사용자들이 디지털 휴먼와 대화한 대화 이력으로부터 획득될 수 있다. 또한, 인공 신경망은 발화 내용을 처리하는 다양한 종류의 인공지능 모델로 이해될 수 있다. 예를 들 어, 인공 신경망은 STT(speech to text), DM(dialog management), Self-Attention, NLP(natural language processing) 및 Deep QA(question answering) 중 적어도 하나를 활용하는 인공지능 모델로서, 상술한 기술들 중 적어도 하나를 이용하여 발화 내용로부터 발화 양식을 추출하고, 추출된 발화 양식에 따라 발화 하는 디지털 휴먼을 생성하는 방법을 학습할 수 있다. 단, 인공 신경망이 발화 내용으로부터 발화 양식을 추출하는 기술 또는 방식은 상술한 예시에 한정되 는 것은 아니며, 생물학적인 뉴런 시스템을 이용하여 발화 내용으로부터 발화 양식을 추출하는 다양한 모 델로 이해될 수 있다. 또한, 제어부는 인물 정보로부터 인물의 성격 유형(“Persona”)을 식별할 수 있다. 보다 구체적으로, 제어부는 이미지 정보 및 음성 정보 중 적어도 하나를 인공 신경망에 입 력함으로써, 인공 신경망이 이미지 정보 및 음성 정보 중 적어도 하나에 기반하여 인물의 성격 유형을 추출하고, 추출된 성격 유형에 따라 동작하는 디지털 휴먼을 생성하도록 할 수 있다. 한편, 제어부는 인물 정보로부터 식별된 발화 내용 및 인물의 성격 유형을 포함하는 지식 베이스(“knowledge Base”)를 생성할 수 있다. 본 발명에 따른 제어부는, 인공 신경망이 발화 내용 및/또는 성격 유형을 이용하여, 사용 자 요청에 따른 응답을 제공하는 디지털 휴먼을 생성하도록 할 수 있다. 보다 구체적으로, 제어부는 발화 내용 및 성격 유형을 포함하는 지식 베이스를 생성함으로 써, 인공 신경망이 사용자 요청에 응답하여 지식 베이스를 로드(load)하고, 지식 베이스에 포함된 발화 내용 및/또는 성격 유형에 기반한 응답을 제공하는 디지털 휴먼을 생성하도록 할 수 있다. 이를 통해, 본 발명에 따른 디지털 휴먼 제공 시스템은, 실제 공간에서의 인물의 발화 양식 및 성격 유형에 대응되는 발화 양식 및 성격 유형을 갖는 디지털 휴먼을 통해 사용자 요청에 대한 응답을 제공할 수 있다. 예를 들어, 제어부는 사용자 요청에 응답하여, 공적(official) 발화 양 식 및 상냥한 성격을 가지고 응답을 제공하는 디지털 휴먼을 생성하여 제공할 수 있다. 나아가, 본 발명에 따른 제어부는 사용자가 가상 공간(또는 관심 공간)에 접속하는 것에 응답하 여, 관심 공간을 통해 디지털 휴먼을 제공할 수 있다(S207). 보다 구체적으로, 제어부는 사용자 가 가상 공간에 접속하거나, 가상 공간을 통해 사용자 요청을 제공하는 것에 응답하여, 관심 공간 에 실제 인물의 외형, 음성 및 제스처 중 적어도 하나를 갖는 디지털 휴먼을 제공할 수 있다. 즉, 제어부는 사용자가 가상 공간에 접속하거나, 가상 공간을 통해 사용자 요청을 제공하는 것에 응답하여, 관심 공간에 실제 인물의 외형, 음성 및 제스처 중 적어도 하나를 갖는 디지털 휴먼을 제공함으로써, 디지털 휴먼이 사용자 요청에 대한 응답을 제공(또는, 수행)하도록 할 수 있다.예를 들어, 제어부는 사용자가 가상 공간에 접속하는 것에 응답하여, 가상 시청 민원실 내에, “시장 ”의 외형, 음성 및 제스처를 가지고 동작하는 디지털 휴먼을 제공함으로써, 디지털 휴먼이 가상 공간 (또는 관심 공간)에서 민원에 대한 사용자 요청에 대한 응답을 제공하도록 할 수 있다. 상술한 바에 따라, 본 발명의 다양한 실시 예에 따른 디지털 휴먼 제공 시스템은, 관심 공간과 관련 된 인물의 인물 정보로부터 추출된 인물 특성을 갖도록 디지털 휴먼을 생성 및 제공함으로써, 실존 인물과 의 이질감을 최소화하고, 사용자에게 보다 실제 공간과 유사한 사용자 경험을 제공할 수 있다. 한편, 컴퓨터가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽힐 수 있는 데이터가 저장되는 모든 종류의 기 록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 나아가, 컴퓨터가 읽을 수 있는 매체는, 저장소를 포함하며 전자기기가 통신을 통하여 접근할 수 있는 서버 또 는 클라우드 저장소일 수 있다. 이 경우, 컴퓨터는 유선 또는 무선 통신을 통하여, 서버 또는 클라우드 저장소 로부터 본 발명에 따른 프로그램을 다운로드 받을 수 있다. 나아가, 본 발명에서는 위에서 설명한 컴퓨터는 프로세서, 즉 CPU(Central Processing Unit, 중앙처리장치)가 탑재된 전자기기로서, 그 종류에 대하여 특별한 한정을 두지 않는다. 한편, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8a 도면8b 도면9"}
{"patent_id": "10-2023-0101797", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 디지털 휴먼 제공 시스템을 도시한다. 도 2는 본 발명에 따른 디지털 휴먼 제공 방법을 나타내는 흐름도다. 도 3은 일 실시 예에 따라 복수의 공간을 포함하는 가상 공간 중 관심 공간을 특정하는 구성을 도시한다. 도 4는 본 발명에 따른 정보 획득부를 이용하여 실제 공간에서 특정 인물의 인물 정보를 획득하는 구성을 도시 한다. 도 5는, 본 발명에 따른 정보 획득부를 통해 획득한 인물 정보를 이용하여 디지털 휴먼을 생성하도록 학습하는 인공 신경망을 도시한다. 도 6은, 본 발명에 따른 인물 정보 중 이미지 정보를 이용하여, 이미지 정보로부터 추출된 외형을 갖는 디지털 휴먼을 생성하는 구성을 도시한다. 도 7은, 본 발명에 따른 인물 정보 중 음성 정보를 이용하여, 음성 정보로부터 추출된 음성을 갖는 디지털 휴먼 을 생성하는 구성을 도시한다. 도 8a 및 도 8b는, 본 발명에 따른 인물 정보 중 영상 정보를 이용하여, 영상 정보로부터 추출된 제스처 중 적 어도 일부에 따라 동작하는 디지털 휴먼을 생성하는 구성을 도시한다. 도 9는, 본 발명에 따른 인물 정보로부터 발화 양식 및 성격 유형을 추출함으로써, 추출된 발화 양식 및 성격 유형에 따라 동작하는 디지털 휴먼을 생성하는 구성을 도시한다."}
