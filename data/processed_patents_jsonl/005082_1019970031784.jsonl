{"patent_id": "unknown_patent", "section": "특허_기본정보", "subsection": "특허정보", "content": {"출원인": "한국전기통신공사    이계철", "발명자": "원용관"}}
{"patent_id": "unknown_patent", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라를 통해 입력된 영상을 소 영상단위로 분할하는 영상분할 과정과; 상기 분할된 영상에 대해 각각 특징지도처리 과정과, 형태인식처리 과정을 거쳐 얼굴의 위치를 추적하는 과정을 포함하는 얼굴 위치 추적 방법에 있어서,얼굴 위치 추적의 고속 처리를 위해;상기 카메라를 통해 입력된 영상의 전체에 대해 특징지도처리를 수행하는 과정과;상기 과정을 통한 다수의 특징지도에 대해 형태인식처리를 수행하는 과정을 포함하여 얼굴 위치 정보를 추출하는 것을 특징으로 하는 비선형 코릴레이션 신경망을 이용한 얼굴 위치 추적 방법."}
{"patent_id": "unknown_patent", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 특징지도처리 수행 과정에서 하나의 특징 지도에 속하는 신경소들은 동일한 바이어스 값을 가지도록 하여, 얼굴의 위치 이동에 무관하게 처리하는 것을 특징으로 하는 비선형 코릴레이션 신경망을 이용한 얼굴 위치 추적 방법.도면 도면112-91019970031784 도면2 도면312-101019970031784 도면4 도면512-111019970031784 도면6 도면712-121019970031784"}
{"patent_id": "unknown_patent", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 화자의 이동에 따라 카메라가 화자의 얼굴을 추적하는 영상 전화기나 영상 회의 시스템을 구현 할 때 요구되는 얼굴 위치 추적을 위한 비선형 코릴레이션 신경망을 이용한 얼굴 위치 추적 방법에 관한 것으로, 기존의 가중치 공유신경망을 확장한 새로운 구조를 제안하여 계산량을 현저하게 적게하므로써, 고속 처리가 가능해 얼굴의 위치 추적이 매우 빠르다는 장점이 있으며, 또한 동일한 층에 속한 특징 지도 들의 계산은 상호 독립적이고, 적절한 제어를 할 경우 각 층간에도 상호 독립성을 유지할 수 있으므로, 병렬 처리 시스템으로 구현할 경우 역시 고속처리를 가능케 하며, 시스템을 구성하고 있는 특징 지도들의 계산에 있어 코릴레이션 필터의 변수의 갯수와 그 값들이 다를 뿐 계산하는 방법이 동일하므로 시스템 구 현이 간단해지는 장점이 있는 기술이다."}
{"patent_id": "unknown_patent", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "및 그 분야의 종래기술 본 발명은 영상 전화기나 영상 회의 시스템등에 활용되는 비선형 코릴레이션 신경망을 이용한 얼굴 위치 추적 방법에 관한 것으로, 특히 움직이는 화자에 따라 카메라의 방향을 조절할 수 있도록 입력영상으로부 터 얼굴의 위치를 추출하는 방법에 관한 것이다. 일반적으로 인공지능 신경망은 얼굴 인식을 포함한 다양한 형태 인식의 문제에 적용되어 왔다. 특히 영상 이 입력 정보일 경우 전처리 과정 및 특징 추출의 과정이 형태 인식에 선형되는 것이 일반적이다. 따라서, 인식의 결과는 인식 시스템 자체의 성능도 중요하지만 인식 시스템의 입력 정보의 특성에 매우 밀접하게 관련되므로 전처리 방법 및 특징 추출의 방법이 매우 중요하다. 현재까지 신경망의 활용은 주료 얼굴의 인식, 즉 신분의 파악에 활용되어 왔다. 이는 이미 얼굴의 위치를 파악하여 얼굴만을 추출하는 별도의 전처리 과정을 거친 후에 이루어진다. 얼굴 영역의 추출을 위한 별도의 전처리를 수행하지 않는 방법으로는 얼굴인식을 목적으로 구현된 시스템 으로 전체 입력 영상을 작은 영역으로 분할하여 검색을 하는 스캐닝(Scanning) 방법이 있다(Carnegie Mellon University의 Face detector - 도 3 참조). 이와 같은 얼굴 위치 추적기의 일반적인 개략 블럭도를 보면, 도 1과 같이 나타낼 수 있는 바, 움직이는 화상을 촬영하는 카메라와; 상기 카메라에서 출력되는 아날로그 화상을 디지탈 영상화시키는 프레임 그레버(Frame grabber)와 ; 상기 프레임 그레버에서 출력된 화상에 대해 잡음 제거를 용이하게 하도록 하는 영상 조작등을 행하는 전처리부와; 상기 전처리기에서 출력된 영상에서 찾고자하는 얼굴의 위치를 탐지하는 얼굴위치 탐지부와;상기 얼굴위치 탐지부에서 생성된 얼굴 위치 정보를 추출하는 얼굴위치 정보 추출부와; 상기 얼굴위치정보 추출부에서 추출된 정보를 이용하여 상기 카메라의 방향을 제어하는 카메라 방 향 제어부; 및 상기 카메라 방향 제어부에서 출력된 제어신호에 따라 카메라의 방향을 전환시키는 카메라 방향 전 환 구동부를 포함하여 구성된다. 상기와 같이 구성된 얼굴 위치 추적기는 추적하고자 하는 대상이 존재하는 부분을 촬영한 다음, 이 촬영 된 영상 내에 표적이 존재하는지의 여부와 존재하면 어느 위치에 있는지를 판별하여 그 위치에 맞게 카메 라 방향을 전환시킨다. 여기서 상기 얼굴 인식 및 위치를 탐지하는 방식으로 종래 사용되고 있는 가중치 공유 인공지능 신경망의 구성 및 연산을 살펴보고, 이를 확장하여 비선형 코릴레이션 필터링을 수행하는 동작을 도 2를 참조하여 살펴보면 다음과 같다. 도 2는 본 발명의 기본이 되는 가중치 공유 신경망(Shared-weight neural network: Y.le Cun, L. D. Jackel, B. Boser, J. S. Denker, H. P. Graf, I. Guyon, D. Hender son, R. E. Howard, and W. Hubbard, Handwritten Digit Recognition: Application of Neural Network Ch ips and Automatic Learning, IEEE Communications Magazine, November, pp.41-64, 1989)의 일례에 대한 개념적 구도를 나타낸 도면으로, 특 징 추출 부분과 형태 인식 부분이 캐스케이드(Cascade)로 구성되어 있다. 12-31019970031784얼굴 추적 시스템은 2차원 정보를 처리하는 다수의 내부 연산기들로 구성되고, 이들 연산기들은 입력에 대하여 코릴레이션 및 비선형 함수에 의한 전환(mapping)을 수행한다. 이때 요구되는 연산기의 코릴레이션 필터의 변수 값들은 인공지능 신견망의 학습 이론을 이용하여 얻는 바, 도 1에 도시된 카메라를 거쳐 프레임 그레버에서 얻어진 디지탈 영상을 M×N 행렬로 나타내면 다음과 같다. [수식 1] 특징 추출 부분의 l 번째 단계의 i번째 비선형 코릴레이션 필터의 출력인 특징지도(Feature map)(210, 211, 230, 231)를 [수식 2] 라 하고, 이의 계산에 이용되는 코릴레이션 필터(202, 203, 221, 222, 223, 224, 242, 2 43, 252)를 [수식 3] 라 하자. 이 코릴레이션 필터의 변수값은 이하에서 설명되는 가중치 공유 신경망(Shared-weight neural netw ork)의 ‘공유된 가중치(Shared-weight)이다. 이때 m은 ( l - 1)번째 단계의 특징 지도의 숫자를 나타내고 ( , i=1,2… ,m), 12-41019970031784[수식 4] 이며, 여기에서 pM이며 qN이고, p와 q 모두 홀수이다. 도 2에 나타난 가중치 공유 신경망은 두개의 특징 추출 단계를 가지고, 첫 단계는 m개의 특징 지도를 갖 고 두번째 단계는 n개의 특징 지도를 가지며, 첫 단계에 대한 입력은 식로 표현되는 영상이고, 두번째 단계에 대한 입력은 첫 단계의 코릴레이션 출력인 특징 지도(210, 211)들이며, P1으로 표시되어 있 다. 상기 식에 타나낸 특징 지도 의 각 요소들은 신경소(neuron)(212, 232)에 의하여 다음 식으로 계산된다. [수식 5] 만약 l =1이면 T34 = U 로, 식로 표현된 입력 영상이다. 이 식에서 T35 (x,y)는 T36 (x,y)이 신경소가 갖는 바이어스(Bias)이며, 일반적으로 신경망에서는 각 (x,y)마다의 신경소들이 독립적인 바이어스를 갖는다. 그러나 이 경우 위치 독립적으로 얼굴을 추적하기 위한 시스템의 구현이 대단히 복잡해지는 단점이 있다. 상기 식의 함수 f 는 신경소의 동작함수(activation function)라 하며, 일반적으로 인공 지능 신경망 에서 흔히 사용되는 f함수의 예로는 [수식 6] 또는 [수식 7] 12-51019970031784 등이 있다. 이때 식의 계산시 입력이 정의되지 않는 경우(예 : x=y=s=t=1, p=q=7)에는 적절한 처리 방법이 요구되 는 바, 예를 들면, 영역 밖의 값을 모두 0으로 또는 영역내의 정의된 값의 평균값으로 정의할 수 있다. 특징 추출에 이어 수행되는 형태 인식 부분은 일반적인 다층 구조 신경망(Multi-layer neural netw ork; D. E. Rumelhart and J. L. McClelland, Parallel Distributed Proc essing : Explortions in the Microstructure of Cognition : Foundation, Vol. 1, MIT Press, Ca mbridege, MA, 1986)이다. 이 신경망은 하나 또는 그 이상의 은닉층(Hidden layer)과 하나의 출력층을 가지며, 각 은닉층과 출력층 은 하나 또는 그 이상의 신경소(240, 250)를 갖는다. 따라서, 각 층의 출력은 하나의 벡터로 나타낼 수 있으며, l 번째 은닉층의 출력을 다음 식과 같이 나타낸다. [수식 8] 그리고, 출력층의 출력 벡터는 다음 식과 같이 나타낸다.[수식 9] 여기서, l 이 1인 첫번째 은닉층에 대한 입력은 특징 추출부의 최종 단계의 특징 지도(230, 231)들이며, 이 층에 속한 j번째의 신경소는 다음과 같은 연산을 수행한다. [수식 10] 상기 식에서n : 특징 추출부 최종 단계에 속한 특징 지도의 수,C : 입력 영상 및 특징 지도의 열의 수,R : 입력 영상 및 특징 지도의 행의 수,F : 특징 추출부의 최종 단계층,b 1j : j번째 신경소의 바이어스 값을 나타낸다. l 이 1보다 큰 경우의 은닉층에 대한 입력은 바로 앞단계의 출력 벡터이며, 이층에 속한 j번째 신경소 는 다음과 같은 계산을 한다. [수식 11] 상기 식에서 c는 ( l -1)번째 은닉층이 갖는 신경소의 수를 나타낸다. 12-61019970031784출력층의 입력은 최종 은닉층의 출력 벡터이며, 이 층에 속한 j번째 신경소는 다음과 같은 계산을 한다. [수식 12] 상기 식에서 L은 최종 은닉층을 나타내고, c는 최종 은닉층이 갖는 신경소의 숫자를 나타낸다. 이상에서 설명한 도 2는 특징 추출부의 , 첫번째 은닉층의 , 이하 은닉층의 및 출력층의 W j와 같은 다수의 시스템 변수를 가지고 있다. 이러한 변수들은 다층 구조 신경망의 학습 방법인 오류 역전파 학습법(Error Back-propagation Le arning Rule; D.E. Rumelhart and J.L. McClelland, Parallel Distributed Processing : Explorations in the Microstructure of Cognition : Foundations, Vol. 1, MIT Press, C ambridge, MA, 1986)에 의하여 구할 수 있다. 이때, 특징 추출부가 가중치를 공유하는 제약 조건을 오류 역전파 학습 과정에 포함시켜야 한다(Y. le Cun, L.D. Jackel, B. Boser, J.S. Denker, H.P. Graf, I. Guyon, D . Henderson, R. E. Howard, and W. Hubbard, “Handwritten Digit Recognition : Application of Neural Network Chips and Automatic Learning.” IEEE Communications Magazine, November, pp.41-64, 19 89). 또한 도 2의 시스템은 R×C의 입력 영상이 어떠한 부류에 속하는가를 판정하는 형태 인식의 문제에 의 적용에 적합하다. 예를 들어, 출력층의 신경소가 2개라 할 때 두 신경소의 출력이(High Low)이면 R×C 의 입력 영상이 얼굴을 포함하고 있고, (Low High)면 얼굴을 포함하고 있지 않다고 판정하며, 이러한 판단 기준은 학습 과정에서 결정된다. 따라서 R×C보다 큰 M×N 크기의 영상에 대하여 어느 위치에 얼굴이 존재하는가를 알아내기 위해서는 전체의 입력 영상을 다수의 R×C로 분할하여 각 분할 영역에 얼굴이 존 재하는가를 검사하여야 한다. 도 3은 상기와 같은 다수 분할 영역에 의한 얼굴 추적을 나타낸 도면으로, 중심이 (a, b)인 하나의 분할 영역에 대한 얼굴의 존재 여부를 출력 어레이의 (a, b) 위치에 나타내는 것이다. M×N 크기의 입력 영상 전체 (a=1 부터 M, b=1부터 N)에 대하여 이러한 과정이 반복 수행된다. 이 도 면 에서 예시한 두개의 분할 영역의 공통 부분(A)에 대해서는 공유된 필터의 변수에 의한 코릴레이션 연산을 수행하므로 도 2의 시스템 특징 추출부에서는 동일한 계산 결과를 얻게 된다. 따라서, 도 2를 이용한 도 3과 같은 방법은 결과적으로 지나치게 많은 중복된 계산을 수행하게 된다. 따라서 이는 움직이는 화상을 쫓아 카메라의 방향이 빠르게 전환되어야 하는 움직임 추정기에서의 속도를 현저히 저하시키게 되고, 심하면 추적하고자 하는 얼굴을 놓치게 되는 문제점도 발생하게 된다. 발명이 이루고자 하는 기술적 과제 본 발명은 상기에 기술한 바와 같은 종래 문제점을 감안하여, 인공 지능 신경망의 이론에 근거한 코릴레 이션 연산기를 제안하고, 이를 이용하여 카메라가 고속으로 얼굴의 위치를 추적하도록 입력 영상내의 얼 굴의 위치를 탐지하는 방법을 제공하는 것을 목적으로 한다. 발명의 구성 및 작용 상기와 같은 목적을 달성하기 위해 본 발명에서는 카메라를 통해 입력된 영상을 소 영상단위로 분할하는 영상 분할 과정과; 상기 분할된 영상에 대해 각각 특징지도처리 과정과, 형태인식처리 과정을 거쳐 얼굴 의 위치를 추적하는 과정을 포함하는 얼굴 위치 추적 방법에 있어서, 얼굴 위치 추적의 고속 처리를 위해;상기 카메라를 통해 입력된 영상의 전체에 대해 특징지도처리를 수행하는 과정과; 상기 과정을 통한 다수의 특징지도에 대해 형태인시기처리를 수행하는 과정을 포함하여 얼굴 위치 정보를 추출하는 것을 특징으로 한다. 상술한 목적 및 특징들, 장점은 첨부된 도면과 관련한 다음의 상세한 설명을 통하여 보다 분명해질 것이다. 이하 첨부된 도면을 참조하여 본 발명의 실시예를 상세히 설명하면 다음과 같다. 본 발명은 가중치 공유 신경망을 확장하여 얼굴 추적 시스템의 구조를 정의하고, 코릴레이션 연산기의 동 작을 정의하는 바, 본 얼굴 추적 시스템은 크게 특징추출과 형태 인식의 두 부분으로 구분되고 이 두 부 분은 캐스케이드(Cascade)로 구성되며, 특징 추출 부분은 다단계의 2차원 비선형 코릴레이션 필터링 연산 을 수행하는데 각 단계는 하나 또는 그 이상의 비선형 코릴레이션 필터로 구성되며, 비선형 코릴레이션 필터의 출력은 특징지도(Feature map)라 하며 다음 단계의 입력이 된다. 12-71019970031784형태 인식 부분은 특징 추출 부분과 동일한 연산을 수행하는데, 최초의 단계는 R×C의 코릴레이션 필터를 가지며, 출력층을 포함한 나머지 단계는 1×1 코릴레이션 필터를 갖는점이 다르다. 이때 최초 단계의 R×C 코릴레이션 필터는 도 2의 ‘242’와 ‘243’에 해당한다. 이러한 시스템은 각 단계들이 동일한 시간에 연산을 수행하는 병렬 처리가 가능하며, 또한 각 단계의 비 선형 코릴레이션 필터링들 역시 동시에 병렬로 수행될 수 있어 고속 처리가 가능하고, 전체 입력 영상을 분할(Segmentation)하여 각 분할영역에 얼굴이 존재하는가를 검사하는 복잡한 과정을 거치지 않는 점이 특징들이다. 도 4는 본 발명에 의해 제안된 시스템인 비선형 코릴레이션 신경망 시스템을 나타낸 도면으로 도 3의 방 법에 의한 단점을 보완하기 위한 새로운 구조이다. 본 발명의 특징은 특징 추출부에서 특징 지도의 크기만 M×N으로 확장되었을 뿐 도 2의 특징 추출부와 동 일하다. 도 2의 은닉층 및 출력층의 신경소(240, 250)들은 도 3에서는 하나의 2차원 출력 평면(340, 350)이 된다. 이는 R×C 크기의 영상의 중심 위치가 a=[1 M] 및 b=[1 N]에 대하여 도 3의 방법이 수행될 때 은닉층 및 출력층의 신경소들의 출력은 이러한 2차원 평면으로 나타난다. 즉, 첫번째 은닉층의 각 신경소는 R×C의 공유된 가중치(식 의 iWj(s, t))(242, 243)에 의한 코릴레이 션 출력이 되고, 다른 은닉층 및 출력층의 각 신경소는 1×1의 공유된 가중치에 의한 코릴레이션 출 력이 되는 것이다. 이때의 1×1의 공유 가중치는 식 및 식의 w ji이다. 그리고 본 발명에서는 상기 종래 방식에서 잠시 언급된 바와 같이 식에 나타나는 일반적인 신경소인 b 값을 종래에는 위치에 따라 값을 다르게 계산하였으나, 이러한 방식을 이용하려면 하드웨어가 너무 복잡 해지는 문제가 있기 때문에 위치에 상관없이 동일한 값으로 계산한다. 즉, 다음 식과 같이 계산한다.[수식 13] 그리고 상기 계산에 이어 행해지는 형태인식 부분에서 사용되는 계산 식들은 종래 사용했던 식을 그대로 사용하므로 설명을 생략한다. 이러한 구조를 갖는 도 4의 시스템은 도 2의 시스템이 도 3처럼 수행될 때 발생되는 특징 추출부에서의 중복된 계산을 피할 수 있어 고속 처리가 가능하며, 모든 계산이 특징 지도를 계산하는 방법으로 단일화 되므로 시스템의 구현이 간단해진다. 즉, 하드웨어적인 구성에 있어서 필터의 사이즈만 달라지는 것이지 계산 방법 및 기본적인 구성이 각 층 마다 동일한 것이다. 도 5는 입력 영상에 대한 최종 출력층의 특징 지도를 하나의 영상으로 표현한 예이다. 얼굴이 탐지될 경 우 최종 출력층의 신경소들이 [High]값을 내도록 학습되었다면 최종 출력층의 특징 지도로부터 얻어진 영상의 밝은 부분에 얼굴이 위치함을 나타낸다. 따라서 카메라는 이 위치를 향하도록 조절되어 화자를 추적 할 수 있다. 도 6은 입력이 하나인 경우에 대한 비선형 코릴레이션 출력의 계산 블럭도로, 입력이 하나일 경우 얼 굴 위치를 추적하는 방식을 나타낸다. 도 4에서의 예를 들면 특징 추출부의 첫번째 층의 특징 지도(310, 311)들이 이 경우에 속하는 대표적인 예가 된다. 즉, 입력영상을 하나의 입력으로 하고, 이 입력을 코릴레이션 필터링을 통해 입력되는 파라미터 값을 이용하여 연산하는 선형 연산기를 거쳐 특징 추출을 행한다. 이때 상기 선형 연산기 내에 내장되는 연산 식은 상기에 설명된 식의 선형 계산 부분이 내장된다. 이어 선형 연산기에서 출력된 값은 비선형 함수부에 의하여 매핑(mapping)된다. 여기서 상기 비선형 함수부 내에 내장되는 연산 식은 상기에 설명된 식 또는 경우에 따라 식이 내장된다. 도 7은 도 6과 계산 방식은 동일한데 단지 입력이 하나 이상(입력 10∼10n)인 경우에 대한 비선형 코릴레 이션 출력의 계산을 나타내는 블럭도로, 여기서의 선형 연산기와 합산기 및 비선형 함수부의 세 블럭은 상기 식을 수행한다."}
