{"patent_id": "10-2023-0114708", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0032201", "출원번호": "10-2023-0114708", "발명의 명칭": "데이터 증강 방법 및 장치", "출원인": "사회복지법인 삼성생명공익재단", "발명자": "오하영"}}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "라벨 정보를 포함하는 한국어 텍스트 데이터를 수신하는 단계;상기 라벨 정보 및 상기 한국어 텍스트 데이터를 인공 신경망 모델에 입력하여, 상기 한국어 텍스트 데이터에대응하는 제1 증강 데이터를 생성하는 단계; 및노이즈 추가 알고리즘에 기초하여, 상기 한국어 텍스트 데이터에 대응하는 제2 증강 데이터를 생성하는 단계를 포함하는, 데이터 증강 방법."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 한국어 텍스트 데이터는사람의 발화 데이터와 상기 사람의 발화 데이터에 대응하는 챗봇의 발화 데이터 세트로 구성된 상담 데이터 세트 문장을 포함하고,상기 라벨 정보는정신 증상의 종류를 나타내는 의도(intent) 정보를 포함하는, 데이터 증강 방법."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 인공 신경망 모델은서로 다른 종류의 복수의 뉴럴 네트워크들을 포함하고,상기 제1 증강 데이터를 생성하는 단계는상기 라벨 정보 및 상기 한국어 텍스트 데이터를 상기 복수의 뉴럴 네트워크들 각각에 입력하여, 상기 복수의뉴럴 네트워크들 별 증강 데이터들을 생성하는 단계;상기 복수의 뉴럴 네트워크들 별 증강 데이터들 사이의 유사도 판단을 수행하는 단계; 및상기 유사도 판단에 기초하여, 상기 제1 증강 데이터를 결정하는 단계를 포함하는, 데이터 증강 방법."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 복수의 뉴럴 네트워크들은BERT 모델, GPT 모델 및 T5 모델 중 적어도 하나를 포함하는, 데이터 증강 방법."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0032201-4-제1항에 있어서,상기 노이즈 추가 알고리즘은자모 분리 알고리즘, 모음 변형 알고리즘 및 온점 추가 알고리즘 중 적어도 하나를 포함하는, 데이터 증강방법."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 한국어 텍스트 데이터, 상기 제1 증강 데이터 및 상기 제2 증강 데이터 중 적어도 하나에 기초하여, 언어모델을 학습하는 단계를 더 포함하는, 데이터 증강 방법."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 언어 모델은 선행 학습된 모델(pre-trained model)이고,상기 언어 모델을 학습하는 단계는상기 한국어 텍스트 데이터, 상기 제1 증강 데이터 및 상기 제2 증강 데이터 중 적어도 하나에 기초하여 상기선행 학습된 모델을 파인 튜닝(fine-tuning)하는 단계를 포함하는, 데이터 증강 방법."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "하드웨어와 결합되어 제1항 내지 제7항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "라벨 정보를 포함하는 한국어 텍스트 데이터를 수신하고, 상기 라벨 정보 및 상기 한국어 텍스트 데이터를 입력으로 하여 상기 한국어 텍스트 데이터에 대응하는 제1 증강 데이터를 생성하는 인공 신경망 모델; 및노이즈 추가 알고리즘에 기초하여, 상기 한국어 텍스트 데이터에 대응하는 제2 증강 데이터를 생성하는 노이즈추가 모델을 포함하는, 데이터 증강 장치."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 한국어 텍스트 데이터는 사람의 발화 데이터와 상기 사람의 발화 데이터에 대응하는 챗봇의 발화 데이터세트로 구성된 상담 데이터 세트 문장을 포함하고,상기 라벨 정보는 정신 증상의 종류를 나타내는 의도(intent) 정보를 포함하는, 데이터 증강 장치."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2025-0032201-5-제9항에 있어서,상기 인공 신경망 모델은,서로 다른 종류의 복수의 뉴럴 네트워크들을 포함하고,상기 라벨 정보 및 상기 한국어 텍스트 데이터를 상기 복수의 뉴럴 네트워크들 각각에 입력하여, 상기 복수의뉴럴 네트워크들 별 증강 데이터들을 생성하고, 상기 복수의 뉴럴 네트워크들 별 증강 데이터들 사이의 유사도 판단을 수행하고,상기 유사도 판단에 기초하여 상기 제1 증강 데이터를 결정 및 생성하는데이터 증강 장치."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 있어서,상기 복수의 뉴럴 네트워크들은BERT 모델, GPT 모델 및 T5 모델 중 적어도 하나를 포함하는, 데이터 증강 장치."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 노이즈 추가 알고리즘은자모 분리 알고리즘, 모음 변형 알고리즘 및 온점 추가 알고리즘 중 적어도 하나를 포함하는, 데이터 증강장치."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 한국어 텍스트 데이터, 상기 제1 증강 데이터 및 상기 제2 증강 데이터 중 적어도 하나에 기초하여 학습을수행하는 언어 모델을 더 포함하는, 데이터 증강 장치."}
{"patent_id": "10-2023-0114708", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 언어 모델은 선행 학습된 모델(pre-trained model)이고,상기 언어 모델은,상기 한국어 텍스트 데이터, 상기 제1 증강 데이터 및 상기 제2 증강 데이터 중 적어도 하나에 기초하여 상기선행 학습된 모델을 파인 튜닝(fine-tuning)하여 학습하는, 데이터 증강 장치."}
{"patent_id": "10-2023-0114708", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "데이터 증강 방법 및 이에 기초한 학습 방법이 개시된다. 일 실시예에 따른 학습 방법은 라벨 정보를 포함하는 한국어 텍스트 데이터를 수신하는 단계, 라벨 정보 및 한국어 텍스트 데이터를 인공 신경망 모델에 입력하여, 한 국어 텍스트 데이터에 대응하는 제1 증강 데이터를 생성하는 단계, 노이즈 추가 알고리즘에 기초하여, 한국어 텍 스트 데이터에 대응하는 제2 증강 데이터를 생성하는 단계 및 한국어 텍스트 데이터, 제1 증강 데이터 및 제2 증 강 데이터 중 적어도 하나에 기초하여, 언어 모델을 학습하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0114708", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 실시예들은 데이터 증강 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0114708", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 자연어 처리 모델(Natural Language Processing Model)은 컴퓨터가 인간이 이해할 수 있는 구문적 및 의미적 표상을 구현하는 모델이다. 이러한 자연어 처리 모델은 신경망(Neutral Network)에 기반한 언어 모델을 이용하여 유사한 단어들을 벡터 공 간상에 가깝게 배치하여 어휘 의미를 표현하는 단어 임베딩(Embeding) 기술을 이용한다. 상기 언어 모델(Language Model)은 주어진 문장에서 앞선 단어들을 기초로 다음 단어가 나올 확률을 계산해주는 모델인데, 어떤 문장이 실제로 존재할 확률을 계산해주기 때문에 주어진 문장이 문법적으로 또는 의미적으로 얼 마나 적합한지를 결정할 수 있다. 상술한 바와 같은 자연어 처리 모델은 크롤링(crawling) 기법(웹페이지상에 존재하는 텍스트를 대량으로 수집하 는 기법)을 이용하여 수집된 대량의 데이터를 이용하여 선행 학습을 수행하게 된다. 그리고, 자연어 처리 모델의 선행 학습 이후에는, 해당 자연어 처리 모델의 목적에 맞도록 특정시킨 텍스트를 학습시켜 모델이 해당 목적에 부합되도록 미세 조정을 수행하게 된다. 이때, 상기 목적에 맞도록 특정시킨 텍스트의 수집은 별도의 인력에 의하여 직접적으로 수집되며, 인력에 의하 여 텍스트의 수집이 직접적으로 이루어지므로 비용이 추가적으로 소요되며 나아가 이러한 인력으로서 해당 분야 전문가를 동반하기도 하므로 인력에 관한 비용이 높게 책정되는 단점이 있다."}
{"patent_id": "10-2023-0114708", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 데이터 증강 방법은 라벨 정보를 포함하는 한국어 텍스트 데이터를 수신하는 단계; 상기 라벨 정보 및 상기 한국어 텍스트 데이터를 인공 신경망 모델에 입력하여, 상기 한국어 텍스트 데이터에 대응하는 제 1 증강 데이터를 생성하는 단계; 및 노이즈 추가 알고리즘에 기초하여, 상기 한국어 텍스트 데이터에 대응하는 제2 증강 데이터를 생성하는 단계를 포함할 수 있다. 상기 한국어 텍스트 데이터는 사람의 발화 데이터와 상기 사람의 발화 데이터에 대응하는 챗봇의 발화 데이터 세트로 구성된 상담 데이터 세트 문장을 포함하고, 상기 라벨 정보는 정신 증상의 종류를 나타내는 의도 (intent) 정보를 포함할 수 있다. 상기 제1 증강 데이터를 생성하는 단계는 상기 상담 데이터 세트 문장과 상기 의도 정보를 상기 인공 신경망 모 델에 입력하는 단계; 상기 사람의 발화 데이터에 대응하는 제1 출력 데이터를 획득하는 단계; 상기 챗봇의 발화 데이터에 대응하는 제2 출력 데이터를 획득하는 단계; 상기 의도 정보에 대응하는 제3 출력 데이터를 획득하는 단계; 상기 제3 출력 데이터에 기초하여, 상기 제1 출력 데이터의 제1 적합성 판단을 수행하는 단계; 상기 제3 출력 데이터에 기초하여, 상기 제2 출력 데이터의 제2 적합성 판단을 수행하는 단계; 상기 제1 출력 데이터와 상기 제2 출력 데이터 사이의 제3 적합성 판단을 수행하는 단계; 및 상기 제1 적합성 판단, 상기 제2 적합성 판 단 및 상기 제3 적합성 판단 수행 결과에 기초하여, 상기 제1 증강 데이터를 생성하는 단계를 포함할 수 있다. 상기 인공 신경망 모델은 서로 다른 종류의 복수의 뉴럴 네트워크들을 포함하고, 상기 제1 증강 데이터를 생성 하는 단계는 상기 라벨 정보 및 상기 한국어 텍스트 데이터를 상기 복수의 뉴럴 네트워크들 각각에 입력하여, 상기 복수의 뉴럴 네트워크들 별 증강 데이터들을 생성하는 단계; 상기 복수의 뉴럴 네트워크들 별 증강 데이터 들 사이의 유사도 판단을 수행하는 단계; 및 상기 유사도 판단에 기초하여, 상기 제1 증강 데이터를 결정하는 단계를 포함할 수 있다. 상기 복수의 뉴럴 네트워크들은 BERT 모델, GPT 모델 및 T5 모델 중 적어도 하나를 포함할 수 있다. 상기 노이즈 추가 알고리즘은 자모 분리 알고리즘, 모음 변형 알고리즘 및 온점 추가 알고리즘 중 적어도 하나 를 포함할 수 있다. 일 실시예에 따른 데이터 증강 방법은 상기 한국어 텍스트 데이터, 상기 제1 증강 데이터 및 상기 제2 증강 데 이터 중 적어도 하나에 기초하여, 언어 모델을 학습하는 단계를 더 포함할 수 있다.상기 언어 모델은 선행 학습된 모델(pre-trained model)일 수 있고, 상기 언어 모델을 학습하는 단계는 상기 한 국어 텍스트 데이터, 상기 제1 증강 데이터 및 상기 제2 증강 데이터 중 적어도 하나에 기초하여 상기 선행 학 습된 모델을 파인 튜닝(fine-tuning)하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0114708", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 개시되어 있는 특정한 구조적 또는 기능적 설명들은 단지 기술적 개념에 따른 실시예들을 설명하 기 위한 목적으로 예시된 것으로서, 실제로 구현된 형태는 다양한 다른 모습을 가질 수 있으며 본 명세서에 설 명된 실시예로만 한정되지 않는다. 제1 또는 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 이해되어야 한다. 예를 들어 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 표현들, 예를 들어 \"~간의\"와 \"바로~간의\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 실시예들은 퍼스널 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 스마트 폰, 텔레비전, 스마트 가전 기기, 지능형 자동 차, 키오스크, 웨어러블 장치 등 다양한 형태의 제품으로 구현될 수 있다. 이하, 실시예들을 첨부된 도면을 참 조하여 상세하게 설명한다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 최근 딥러닝 모델을 활용한 자연어 처리 분야의 발전에 따라 텍스트 데이터의 증강의 중요성이 높아지고 있다. 더 강건한 딥러닝 모델을 만들고 모델의 성능을 향상시키기 위해서는 많은 데이터가 필요한데, 한정적인 데이터 가 있는 현실 세계에서 데이터 증강은 딥러닝 모델의 정확도를 높일 수 있는 효율적인 방법이기 때문이다. 데이터 증강이란 인위적인 변화를 통해 데이터의 수를 증가시켜 학습에 필요한 충분한 수의 데이터를 확보하는 기법이다. 데이터 증강은 특히 이미지 데이터의 수를 늘리기 위해 널리 사용될 수 있다. 구체적으로 이미지 데 이터에 대한 Flipping, Color Space, Cropping, Rotation, Translation 등의 간단한 변형을 통해 이미지 데이터의 수를 늘리는 전통적인 방법뿐 아니라, 학습된 Feature Space에서의 변환, Neural Transfer 혹은 GAN을 활 용한 새로운 데이터 생성 등 딥 러닝 기술을 적용한 데이터 증강 알고리즘들도 새롭게 제안되고 있다. 하지만 단순하게 이미지를 회전하거나 크롭하는 등 간단한 방법으로 데이터의 양을 증강시킬 수 있는 이미지 데 이터와 달리, 텍스트 데이터의 경우 증강 과정에서 원래 문장의 의미를 손상하면 안되므로 데이터 증강 과정에 서 각별히 유의해야 한다. 또한, 구어체로 이루어진 데이터의 경우, 문법에 맞지 않는 데이터가 많기 때문에 학습이 끝난 후 모델이 표준어가 아닌 문장을 입력으로 받았을 때 문장을 이해하지 못하는 경우가 있다. 아래에서 상세히 설명하겠지만, 일 실시예에 따른 데이터 증강 시스템은 문장 데이터의 라벨을 보존하며 데이터 를 증강하고, 문법에 맞지 않는 문장을 원본 데이터에 추가하는 증강 방법을 통해 상술한 문제점을 해결할 수 있다. 도 1은 일 실시예에 따른 데이터 증강 시스템을 설명하는 도면이다. 도 1을 참조하면, 데이터 증강 시스템은 사용자 단말, 데이터 증강 장치 및 데이터베이스 를 주체로 포함할 수 있다. 사용자 단말은 데이터 증강 장치와 연결되어 텍스트 데이터를 제공하고 데이터 증강에 따른 증강 데 이터를 수신하는 컴퓨팅 장치에 해당할 수 있다. 사용자 단말은 스마트폰, 노트북 또는 컴퓨터로 구현될 수 있으며, 반드시 이에 한정되지 않고, 태블릿 PC 등 다양한 디바이스로도 구현될 수 있다. 사용자 단말 은 데이터 증강 장치와 네트워크를 통해 연결될 수 있고, 복수의 사용자 단말들이 데이터 증강 장치 와 동시에 연결될 수도 있다. 데이터 증강 장치는 일 실시예에 따른 텍스트 데이터 증강 방법을 수행하는 컴퓨터 또는 프로그램에 해당 하는 서버로 구현될 수 있다. 데이터 증강 장치는 사용자 단말과 유선 또는 무선 네트워크를 통해 연결될 수 있고 상호 간에 데이터를 주고받을 수 있다. 일 실시예에서, 데이터 증강 장치는 텍스트 데이터 증강 방법을 수행하는 과정에서 다양한 외부 시스템(또 는 서버)과 연동하여 동작할 수 있다. 예를 들어, 데이터 증강 장치는 SNS 서비스, 포털 사이트, 블로그 등을 통해 텍스트로 이루어진 다양한 문서들에 접근할 수 있으며, 데이터 증강에 필요한 학습 모델의 구축 과정 에서 필요한 데이터를 수집할 수 있다. 데이터베이스는 데이터 증강 장치의 동작 과정에서 필요한 다양한 정보들을 저장하는 저장장치에 해 당할 수 있다. 예를 들어, 데이터베이스는 학습 모델 구축을 위한 학습 알고리즘 및 모델 정보를 저장할 수 있으며, 반드시 이에 한정되지 않고, 데이터 증강 장치가 텍스트 데이터 증강 방법을 수행하는 과정에 서 다양한 형태로 수집 또는 가공된 정보들을 저장할 수 있다. 도 2a는 인공 신경망을 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 딥러닝(Deep Learning) 등을 포함하는 인공지능(AI) 알고리즘은 인공 신경망(Artificial Neural Network, AN N)에 입력 데이터를 입력시키고, 컨볼루션 등의 연산을 통해 출력 데이터를 학습하고, 학습된 인공 신경망을 이 용하여 특징을 추출할 수 있다. 인공 신경망은 생물학적 뇌를 모델링한 컴퓨터 과학적 아키텍쳐(Computational Architecture)를 의미할 수 있다. 인공 신경망 내에서, 뇌의 뉴런들에 해당되는 노드들은 서로 연결되어 있고, 입력 데이터를 처리하기 위하여 집합적으로 동작한다. 다양한 종류의 뉴럴 네트워크들을 예로 들면, 컨볼루션 뉴럴 네트워크(Convolutional Neural Network, CNN), 회귀 뉴럴 네트워크(Recurrent Neural Network, RNN), 딥 빌리프 네트워크(Deep Belief Network, DBN), 제한된 볼츠만 기계(Restricted Boltzman Machine, RBM) 방식 등이 있으나, 이에 제한되지 않는다. 피드-포워드 (feed-forward) 뉴럴 네트워크에서, 뉴럴 네트워크의 뉴런들은 다른 뉴런들과의 연결들(links)을 갖는다. 이와 같은 연결들은 뉴럴 네트워크를 통해, 한 방향으로, 예를 들어 순방향(forward direction)으로 확장될 수 있다. 도 2a는 입력 데이터를 입력 받아 출력 데이터를 출력하는 인공 신경망(예를 들어, 컨볼루션 뉴럴 네트워크 (Convolution Neural Network, CNN))의 구조를 도시한다. 인공 신경망은 2개 이상의 레이어(layer)를 보유한 딥 뉴럴 네트워크(deep neural network)일 수 있다. 도 2b는 일 실시예에 따른 인공 신경망 모델의 학습 및 추론 방법을 설명하기 위한 도면이다. 도 2b를 참조하면, 일 실시예에 따른 자연어 처리 시스템은 학습 장치 및 추론 장치를 포함할 수 있 다. 일 실시예에 따른 학습 장치는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train)(또는 학습(learn))하거나, 뉴럴 네트워크를 재훈련(retrain)하는 기능들과 같은 다양한 프로세싱 기능들을 갖는 컴퓨팅 디바이스에 해당된다. 예를 들어, 학습 장치는 PC(personal computer), 서버 디바이스, 모바일 디바이스 등의 다양한 종류의 디바이스들로 구현될 수 있다. 일 실시예에 따른 학습 장치는 데이터 증강 장치(예를 들어, 도 1의 데이터 증강 장치)로부터 수신한 학습 데이터에 기초하여, 초기 뉴럴 네트워크를 학습할 수 있다. 학습 장치는 데이터 증강 장치를 포함할 수 있다. 또는, 데이터 증강 장치와 학습 장치는 별도로 존재할 수도 있다. 일 실시예에 따른 학습 장치는 주어진 초기 뉴럴 네트워크를 반복적으로 훈련(학습)시킴으로써, 하나 이상 의 훈련된 뉴럴 네트워크를 생성할 수 있다. 하나 이상의 훈련된 뉴럴 네트워크를 생성하는 것은 뉴 럴 네트워크 파라미터를 결정하는 것을 의미할 수 있다. 여기서, 파라미터들은 예를 들어 뉴럴 네트워크의 입/ 출력 액티베이션들, 웨이트들, 바이어스들 등 뉴럴 네트워크에 입/출력되는 다양한 종류의 데이터를 포함할 수 있다. 뉴럴 네트워크의 반복적인 훈련이 진행됨에 따라, 뉴럴 네트워크의 파라미터들은 주어진 입력에 대해 보 다 정확한 출력을 연산하기 위해 조정될(tuned) 수 있다. 일 실시예에 따른 학습 장치는 훈련된 하나 이상의 뉴럴 네트워크를 추론 장치에 전달할 수 있 다. 추론 장치는 모바일 디바이스, 임베디드(embedded) 디바이스 등에 포함될 수 있다. 일 실시예에 따 른 추론 장치는 뉴럴 네트워크의 구동을 위한 전용 하드웨어로 프로세서, 메모리, 입출력(I/O) 인터페이스, 디스플레이, 통신 인터페이스, 또는 센서 중 적어도 하나를 포함하는 전자 장치일 수 있다. 일 실시예에 따른 추론 장치는 태블릿 PC, 스마트폰, 개인용 컴퓨터(예를 들어, 노트북 컴퓨터 등), 인공 지능 스피커, 스마트 TV, 이동 전화기, 내비게이션, 웹 패드, PDA, 워크스테이션 등과 같이 메모리 수단을 구비 하고 마이크로 프로세서를 탑재하여 연산 능력을 갖춘 디지털 기기를 모두 포함하는 개념일 수 있다. 도 1을 참조하여 설명한 일 실시예에 따른 게이트웨이는 일 실시예에 따른 추론 장치를 포함할 수 있다. 일 실시예에 따른 추론 장치는 하나 이상의 훈련된 뉴럴 네트워크를 그대로 구동하거나, 하나 이상의 훈련된 뉴럴 네트워크가 가공(예를 들어, 양자화)된 뉴럴 네트워크를 구동할 수 있다. 가공된 뉴럴 네트워크를 구동하는 추론 장치는, 학습 장치와는 별도의 독립적인 디바이스에서 구현될 수 있 다. 하지만, 이에 제한되지 않고, 추론 장치는 학습 장치와 동일한 디바이스 내에도 구현될 수 있다. 도 3은 일 실시예에 따른 데이터 증강 방법 및 데이터 증강 방법에 의해 생성된 데이터를 이용하여 언어 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 1 내지 도 2b를 참조하여 설명한 내용은 도 3에도 동일하게 적용될 수 있다. 도 3을 참조하면, 일 실시예에 따른 데이터 증강 장치는 라벨 정보를 포함하는 한국어 텍스트 데이터를 수신할 수 있다. 아래에서, 데이터 증강 처리를 통해 생성된 증강 데이터와 구분하기 위하여, 데이터 증강 처리의 대 상이 되는 한국어 텍스트 데이터를 원본 데이터라 지칭할 수 있다. 일 실시예에 따른 원본 데이터는 라벨링이 완료된 데이터를 포함할 수 있다. 일 실시예에 따른 데이터 증강 장 치는 원본 데이터의 라벨 을 보존하면서 데이터를 증강하여, 데이터 증강 처리 과정에서 문장의 의미가 손상(변 경)되는 것을 방지할 수 있다. 나아가, 한국어 텍스트 데이터는 사람의 발화 데이터와 사람의 발화 데이터에 대응하는 챗봇의 발화 데이터 세 트로 구성된 상담 데이터 세트 문장을 포함할 수 있다. 또한, 상담 데이터 세트 문장에는 정신 증상의 종류를 나타내는 의도(intent) 정보가 라벨링될 수 있다. 예를 들어, 한국어 텍스트 데이터는 웰니스 데이터 세트일 수 있다. 웰니스 데이터 세트는 병원에서 전달받은 상담 데이터에서 추출되었고, 각 의도에 따른 사용자의 발화와 발화에 해당하는 챗봇의 스크립트로 구성될 수 있다. 정신증상의 종류를 나타내는 의도는 총 19가지이고, 총 23994개의 사람 발화 데이터로 구성될 수 있다. 일 실시예에 따른 데이터 증강 장치는 라벨 정보 및 한국어 텍스트 데이터를 인공 신경망 모델에 입력하여, 한국어 텍스트 데이터에 대응하는 제1 증강 데이터를 생성할 수 있다. 데이터 증강 장치는 텍스트 데이터 뿐만 아니라, 라벨 정보를 인공 신경망 모델에 함께 입력할 수 있다. 나아가, 상담 데이터 세트 문장의 경우, 사람의 발화 데이터, 챗봇의 발화 데이터 및 정신 증상의 종류를 나타 내는 의도가 인공 신경망 모델에 함께 입력될 수 있다.인공 신경망 모델은 서로 다른 종류의 복수의 뉴럴 네트워크들을 포함할 수 있다. 예를 들어, 인공 신경 망 모델은 BERT 모델, GPT-2 모델 및 T5 모델을 포함할 수 있다. BERT 모델은 오토 인코더(AutoEncoder) 기반의 딥러닝 모델로, 사전 학습(pretrain) 방법 중에서 특정 토큰을 마스킹(masking)한 후 해당 토큰을 맞추 는 방식의 학습 방법인 마스크드 언어 모델링(MLM; Masked Language Modeling)을 사용할 수 있다. 일 실시예에 따른 데이터 증강 장치는 MLM 방법을 이용하여 사전학습을 마친 BERT 모델에 MLM 태스크를 적용하여 원본 데이 터에 마스킹을 적용하고, 해당 부분에 새로운 단어를 넣어 데이터를 생성시킬 수 있다. GPT-2 모델은 오토 리그레시브(auto-regressive) 기반의 딥러닝 모델로, 라벨 정보를 프롬프트(prompt)로 제공 하여, 새로운 데이터를 생성하는 방법으로 데이터를 증강할 수 있다. 일 실시예에서는, 모든 텍스트 데이터와 라벨 데이터를 하나로 모았고, 라벨 데이터와 텍스트 데이터 사이에는 SEP 토큰을, 시퀀스와 시퀀스 사이에는 EOS 토큰을 두어서 구분을 하였다. 때문에 프롬프트로는 labelSEP를 제공할 수 있다. T5 모델은 입력과 출력의 형태가 모두 텍스트인 텍스트 투 텍스트(text-to-text) 모델로, 모델에 따라 적용 가 능한 다운스트림 태스크(downstream task)가 한정적인 기존의 트랜스포머(Transformer) 기반 모델들과 다르게, 하나의 모델로 다양한 다운스트림 태스크를 적용할 수 있다. T5 모델의 경우 기존의 구문과 유사한 문장을 생 성하는 패러프레이즈 태스크(paraphrase task)를 데이터에 적용하여 데이터 증강에 적용할 수 있다. 데이터 증강 장치는 라벨 정보 및 한국어 텍스트 데이터를 복수의 뉴럴 네트워크들 각각에 입력하여, 복수의 뉴 럴 네트워크들 별 증강 데이터들을 생성할 수 있다. 나아가, 데이터 증강 장치는 복수의 뉴럴 네트워크들 별 증강 데이터들 사이의 유사도 판단을 수행하고, 유사도 판단에 기초하여, 제1 증강 데이터를 결정할 수 있다. 예를 들어, BERT 모델, GPT-2 모델, T5 모델 각각에서 증강 데이터들을 생성할 수 있고, 데이터 증강 장치는 BERT 모델, GPT-2 모델, T5 모델 각각에서 생성된 증강 데이터들 사이의 유사도 판단을 수행하여, 유사도가 미 리 정해진 임계값 이하인 데이터들을 증강 데이터에서 제외할 수 있다. 이를 통해, 원래 문장의 의미가 손상될 확률이 높은 데이터들을 제거할 수 있다. 전술한 상담 데이터 세트 문장과 의도 정보가 인공 신경망 모델에 입력되는 경우, 데이터 증강 장치는 사람의 발화 데이터에 대응하는 제1 출력 데이터를 획득하고, 챗봇의 발화 데이터에 대응하는 제2 출력 데이터를 획득 하고, 의도 정보에 대응하는 제3 출력 데이터를 획득할 수 있다. 데이터 증강 장치는 제3 출력 데이터에 기초하여, 제1 출력 데이터의 제1 적합성 판단을 수행하고, 제3 출력 데 이터에 기초하여, 제2 출력 데이터의 제2 적합성 판단을 수행할 수 있다. 제1 출력 데이터, 제2 출력 데이터 및 제3 출력 데이터는 동일한 벡터 공간에 생성될 수 있기 때문에, 유사도 판단(예를 들어, 코싸인 유사도 판단)에 기초한 데이터의 적합성 판단을 수행할 수 있다. 다시 말해, 데이터 증강 장치는 의도 정보에 대응하는 제3 출력 데이터와 상담 데이터 세트 문장에 대응하는 제 1 출력 데이터 및 제2 출력 데이터를 동일한 벡터 공간에 생성하여, 제1 출력 데이터와 제2 출력 데이터가 원래 문장의 의미에서 벗어나는지 여부를 판단할 수 있다. 상담 데이터 세트 문장은 서로 상관 관계가 있는 문장이기 때문에, 그 출력인 제1 출력 데이터와 제2 출력 데이 터 역시 상관 관계를 갖어야 할 수 있다. 이에, 데이터 증강 장치는 제1 출력 데이터와 제2 출력 데이터 사이 의 제3 적합성 판단을 수행할 수 있다, 제3 적합성 판단은 제1 출력 데이터와 제2 출력 데이터 사이의 유사도 판단에 기초하여 수행될 수 있다. 데이터 증강 장치는 제1 적합성 판단, 제2 적합성 판단 및 제3 적합성 판단 수행 결과에 기초하여, 제1 증강 데 이터를 생성할 수 있다. 일례로, 데이터 증강 장치는 제1 적합성 판단, 제2 적합성 판단 및 제3 적합성 판단 수행 결과를 모두 통과한 출력 데이터만 제1 증강 데이터로 결정할 수 있다. 또 다른 예로, 데이터 증강 장치 는 1 적합성 판단, 제2 적합성 판단 및 제3 적합성 판단 수행 결과 중 어느 하나라도 통과한 데이터면 해당 데 이터를 제1 증강 데이터로 결정할 수도 있다. 적합성 판단 결과에 기초하여 제1 증강 데이터를 결정하는 방법 은 전술한 예시에 한정되지 않는다. 데이터 증강 장치는 노이즈 추가 알고리즘에 기초하여, 한국어 텍스트 데이터에 대응하는 제2 증강 데이터를 생 성할 수 있다. 데이터 증강 장치는 일반적인 텍스트 데이터 증강 기법들 뿐만 아니라, 챗봇 개발이라는 특수한 상황에서도 사용될 수 있는 데이터 증강 기법으로 노이즈 추가 기법을 사용할 수 있다. 노이즈 추가 알고리즘 은 자모를 분리하는 방식의 jamo_split 알고리즘, 모음을 변형시키는 vowel_change 알고리즘, 텍스트 사이에 온 점을 추가하는 add_noise 알고리즘, 중성 중 일부를 영어로 변환하는 kor2eng 알고리즘, 그리고 야민정음으로일부 글자를 변환하는 yamin 알고리즘을 포함할 수 있으나, 전술한 예시로 한정되는 것은 아니다. 학습 장치는 한국어 텍스트 데이터, 제1 증강 데이터 및 제2 증강 데이터 중 적어도 하나에 기초하여, 언어 모 델을 학습할 수 있다. 언어 모델은 선행 학습된 모델(pre-trained model)일 수 있고, 학습 장치는 한국어 텍스트 데이터, 제1 증강 데이터 및 제2 증강 데이터 중 적어도 하나에 기초하여 선행 학습된 모델을 어 플리케이션에 맞게 파인 튜닝(fine-tuning)할 수 있다. 도 4는 일 실시예에 따른 데이터 증강 방법 및 언어 모델을 학습 방법의 예시를 도시한 도면이다. 도 4를 참조하면, 학습 데이터는 Utterance 2차 데이터로 설정했고, 검증 데이터는 Utterance 1차 데이터로 설 정할 수 있다. 인공 신경망 모델과 노이즈 추가 알고리짐 모델은 9가지 증강 방법들을 적용하여 각각 증강 데 이터들을 생성할 수 있다. 증강된 데이터들은 원본 데이터들과 합쳐지고, 해당 데이터에 기초하여 분류 (classification) 모델에 학습시킨 후, 해당 모델에 검증 데이터를 적용하여 정확도를 측정할 수 있다. 도 5는 일 실시예에 따른 데이터 증강 방법을 설명하기 위한 순서도이다. 도 5을 참조하면, 단계들(510 내지 530)은 도 1을 참조하여 설명한 데이터 증강 장치에 의해 수행되는 것으로 기술된다. 그러나 이 단계들(510 내지 530)은 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스템 내에서도 사용될 수 있을 것이다. 나아가, 도 5의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 5에 도시된 다수의 동작은 병렬로 또는 동시에 수행될 수 있다. 단계에서, 일 실시예에 따른 데이터 증강 장치는 라벨 정보를 포함하는 한국어 텍스트 데이터를 수신할 수 있다. 단계에서, 일 실시예에 따른 데이터 증강 장치는 라벨 정보 및 한국어 텍스트 데이터를 인공 신경망 모델 에 입력하여, 한국어 텍스트 데이터에 대응하는 제1 증강 데이터를 생성할 수 있다. 데이터 증강 장치는 라벨 정보 및 한국어 텍스트 데이터를 복수의 뉴럴 네트워크들 각각에 입력하여, 복수의 뉴럴 네트워크들 별 증강 데 이터들을 생성하고, 복수의 뉴럴 네트워크들 별 증강 데이터들 사이의 유사도 판단을 수행하고, 유사도 판단에 기초하여, 제1 증강 데이터를 결정할 수 있다. 단계에서, 일 실시예에 따른 데이터 증강 장치는 노이즈 추가 알고리즘에 기초하여, 한국어 텍스트 데이터 에 대응하는 제2 증강 데이터를 생성할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2023-0114708", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들의 조합을 포함 할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처 리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2023-0114708", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2023-0114708", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 데이터 증강 시스템을 설명하는 도면이다. 도 2a는 인공 신경망을 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 도 2b는 일 실시예에 따른 인공 신경망 모델의 학습 및 추론 방법을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 데이터 증강 방법 및 데이터 증강 방법에 의해 생성된 데이터를 이용하여 언어 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 데이터 증강 방법 및 언어 모델을 학습 방법의 예시를 도시한 도면이다."}
