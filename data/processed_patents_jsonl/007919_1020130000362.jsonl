{"patent_id": "10-2013-0000362", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2014-0088462", "출원번호": "10-2013-0000362", "발명의 명칭": "실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템 및 그의 실시간 렌더링 3D 오브젝트", "출원인": "주식회사 오렌지큐브", "발명자": "백훈"}}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "멀티비전용 디스플레이 유닛에 있어서,하나의 전체 화면 중 일부에 해당하는 분할 영상데이터를 처리하는 영상처리부; 입력된 UX이벤트를 처리하는 UX이벤트 처리부;실시간 렌더링 오브젝트 데이터를 만드는 오브젝트 처리부;상기 실시간 렌더링 오브젝트 데이터와 분할 영상데이터를 겹쳐진 화면으로 표현하는 마스킹 영상 인코딩부;다른 디스플레이 유닛 또는 서버와 통신데이터를 송수신하는 통신부;상기 다른 디스플레이 유닛과의 동기화를 위한 타이머; 및상기 영상처리부, UX이벤트 처리부, 오브젝트 처리부, 마스킹 영상 인코딩부, 및 통신부 중 적어도 하나를 제어하기 위한 제어부를 포함하는 것을 특징으로 하는 멀티비전용 디스플레이 유닛."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 하나의 전체 화면 중 일부에 해당하는 분할 영상데이터 또는 상기 실시간 렌더링 오브젝트 데이터를 사전에 저장하는 저장부를 더 포함하는 멀티비전용 디스플레이 유닛."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 UX이벤트를 입력하는 UX이벤트 입력부를 더 포함하는 멀티비전용 디스플레이 유닛."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,오브젝트들의 용도, 크기 및 특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만드는 오브젝트 인공지능 시뮬레이터를 더 포함하는 것을 특징으로 하는 멀티비전용 디스플레이 유닛."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 제어부는,영상처리부를 제어하는 영상제어부;상기 그래픽처리부를 제어하는 그래픽제어부;실시간 렌더링 3D 오브젝트 화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현 방법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나를 제어하는 오브젝트 제어부;복수의 디스플레이 유닛에서 다양한 인터페이스를 통해 입력받은 데이터 값을 다른 각각의 디스플레이 유닛에동기화시킬 데이터로 만들고 제어하는 UX이벤트 제어부;및 외부의 시스템 또는 다른 플랫폼 장치와 통신하여 수신한 오브젝트 상태값을 제어하는 통신제어부 중 적어도 하나를 포함하는 것을 특징으로 하는 멀티비전용 디스플레이 유닛."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,공개특허 10-2014-0088462-2-상기 통신데이터는 동기신호 데이터, 오브젝트 데이터, 영상 데이터, 그래픽 데이터, 및 UX이벤트 데이터 중 적어도 하나를 포함하는 것을 특징으로 하는 멀티비전용 디스플레이 유닛."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항 또는 제6항에 있어서,상기 통신데이터는 네트워크에 연결된 다른 플랫폼과 송수신되는 것을 특징으로 하는 멀티비전용 디스플레이 유닛."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항 내지 제7항 중 어느 한 항에 기재된 디스플레이 유닛들 다수를 서로 통신 가능하도록 결합하여 이루어지는 것을 특징으로 하는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 다수의 디스플레이 유닛들은 동기화 서버를 통하여 결합되는 것을 특징으로 하는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 동기화 서버는,연결된 각 디스플레이 유닛 또는 외부 플랫폼 디바이스와 통신데이터를 송수신하는 서버통신부;디스플레이 유닛들의 동기화를 위한 서버 타이머; 및 디스플레이 유닛들의 동기 정보를 생성하는 서버 동기정보 생성부를 포함하는 것을 특징으로 하는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서,상기 동기화 서버는,실시간 렌더링 3D 오브젝트 화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현 방법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나를 제어하는 오브젝트 제어부; 복수의 디스플레이 유닛에서 다양한 인터페이스를 통해 입력받은 데이터 값을 다른 각각의 디스플레이 유닛에동기화시킬 데이터로 만들고 제어하는 UX이벤트 제어부; 및연결된 각 디스플레이 유닛 또는 외부 플랫폼 디바이스와 통신하여 주고 받은 오브젝트 상태값을 제어하는 통신제어부 중 적어도 하나를 포함하는 것을 특징으로 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 동기화 서버는 오브젝트들의 용도, 크기와 특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만드는 오브젝트의 인공지능 시뮬레이터를 더 포함하는 것을 특징으로 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "하나의 전체 화면을 분할한 분할 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 복수의 디스플레이 유닛마다 사전에 할당하여 저장하는 단계;상기 복수의 디스플레이 유닛들이 상기 저장된 분할 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 동기화공개특허 10-2014-0088462-3-하여 표시하는 단계;상기 복수의 디스플레이 유닛들 중 적어도 하나에서 사용자로부터 UX이벤트를 입력받는 단계; 및상기 입력된 UX이벤트에 따라 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 표시하는 단계를 포함하는 것을 특징으로 하는 멀티비전 시스템의 실시간 렌더링 3D 오브젝트 처리방법."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 입력받은 UX이벤트가 다른 디스플레이 유닛과 관계되어 있는지를 판단하는 단계를 더 포함하는 것을 특징으로 하는 멀티비전 시스템의 실시간 렌더링 3D 오브젝트 처리방법."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14항에 있어서,상기 UX이벤트가 입력된 디스플레이 유닛으로부터 UX이벤트와 관련된 디스플레이 유닛에 동기화 정보 데이터,영상데이터, 실시간 렌더링 오브젝트 데이터, 및 UX이벤트 데이터 중 적어도 하나를 전송하는 단계를 더 포함하는 것을 특징으로 하는 멀티비전 시스템의 실시간 렌더링 3D 오브젝트 처리방법."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 13항에 있어서,네트워크에 연결된 다른 플랫폼 또는 다른 디스플레이 유닛으로부터 동기화 정보 데이터, 영상데이터, 실시간렌더링 오브젝트 데이터, 및 UX이벤트 데이터 중 적어도 하나를 수신하는 단계를 더 포함하는 것을 특징으로 하는 멀티비전 시스템의 실시간 렌더링 3D 오브젝트 처리방법."}
{"patent_id": "10-2013-0000362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 15항 또는 제16항에 있어서,상기 동기화 정보 데이터, 영상데이터, 실시간 렌더링 오브젝트 데이터, 및 UX이벤트 데이터 중 적어도 하나는동기 서버를 경유하여 전송 또는 수신하는 것을 특징으로하는 멀티비전 시스템의 실시간 렌더링 3D 오브젝트 처리방법.명 세 서기 술 분 야본 발명은 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템 및 그의 실시간 렌더링 3D 오브젝트 처리방 [0001]법에 관한 것으로, 복수의 상호 독립적인 디스플레이 유닛에서 표시되는 실시간 렌더링 3D 화면을 디스플레이유닛들 간의 화면을 동기화(Synchronization)하여 표현할 수 있는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템에 관한 것이다.배 경 기 술멀티비전(Multivision)이란 복수의 디스플레이 유닛 상에서 하나의 전체 화면 또는 각기 다른 화면을 표시해 주 [0002]는 장치이다. 멀티비전은 기술적 제약이나 비용의 한계를 넘는 크기의 영상을 표현하기 위해서, 작은 크기의 영상 표시유닛들을 모아서 배치하고 전체 영상의 각 부분들을 분할한 뒤 각각의 장치를 통해서 표시하는 방법을사용한다.멀티비전을 구현하기 위해서는 단일 영상 신호 발생장치에서 나오는 전기적인 영상 신호를 하드웨어적으로 분배 [0003]하여 여러 개의 개별 디스플레이 유닛을 위한 전기적인 영상 신호를 만드는 방법을 사용하거나, 개별 디스플레이 유닛마다 상호 독립적인 영상 신호 발생 장치를 직접 연결하고, 각각의 영상 신호 발생 장치의 제어를 담당하는 시스템끼리 네트워크로 연결하여 연동하는 방법을 사용할 수 있다.개별 디스플레이 유닛 혹은 소수의 디스플레이 유닛마다 독립적인 영상 신호 발생기를 사용하고, 그 제어 시스 [0004]템끼리 네트워크로 연동하는 경우에는 전체 영상 크기의 영상 신호를 만들거나 이 신호를 개별 표시장치를 위한공개특허 10-2014-0088462-4-신호로 분배하는 하드웨어 장치를 만들 필요가 없기 때문에 백여 개 이상의 표시장치를 모아서 거대한 디스플레이를 구성하는 것이 가능해 진다.이러한 종래의 멀티비전은 제작된 영상물의 전체 영상을 개별 또는 분할해 각 디스플레이 유닛에 스케쥴에 따라 [0005]단순 재생하는 하는 것에 불과하고 하였다. 발명의 내용해결하려는 과제본 발명의 목적은 3D 오브젝트들을 실시간으로 렌더링하여 멀티비전 형태로 표현할 수 있는 실시간 렌더링 3D [0006]오브젝트 인터렉티브 멀티비전 시스템 및 그의 실시간 렌더링 3D 오브젝트 처리방법을 제공하는 것이다.본 발명의 다른 목적은 실시간 렌더링 3D 오브젝트 프로그램과 사용자 입력에 따라 실시간으로 변화하는 화면을 [0007]화상의 불일치가 발생하지 않고 정확하게 동기화되어 표현할 수 있는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템 및 그의 실시간 렌더링 3D 오브젝트 처리방법을 제공하는 것이다.본 발명의 또 다른 목적은 독립적인 다양한 플랫폼 디바이스들과 통신하고 상호작용하여 플랫폼 디바이스와 멀 [0008]티비전으로 표현하는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템 및 그의 실시간 렌더링 3D 오브젝트 처리방법을 제공하는 것이다.본 발명의 또 다른 목적은 멀티비전을 구성하는 디스플레이 유닛의 수를 충분히 확장하더라도 높은 수준의 해상 [0009]도를 유지할 수 있는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템 및 그의 실시간 렌더링 3D 오브젝트 처리방법을 제공하는 것이다.과제의 해결 수단본 발명의 과제를 해결하기 위한 멀티비전용 디스플레이 유닛은, 하나의 전체 화면 중 일부에 해당하는 분할 영 [0010]상데이터를 처리하는 영상처리부; 입력된 UX이벤트를 처리하는 UX이벤트 처리부; 실시간 렌더링 오브젝트 데이터를 만드는 오브젝트 처리부; 상기 실시간 렌더링 오브젝트 데이터와 분할 영상데이터를 겹쳐진 화면으로 표현하는 마스킹 영상 인코딩부; 다른 디스플레이 유닛 또는 서버와 통신데이터를 송수신하는 통신부; 상기 다른 디스플레이 유닛과의 동기화를 위한 타이머; 및 상기 영상처리부, UX이벤트 처리부, 오브젝트 처리부, 마스킹 영상 인코딩부, 및 통신부 중 적어도 하나를 제어하기 위한 제어부를 포함하여 구성할 수 있다.상기 멀티비전용 디스플레이 유닛은 하나의 전체 화면 중 일부에 해당하는 분할 영상데이터 또는 상기 실시간 [0011]렌더링 오브젝트 데이터를 사전에 저장하는 저장부를 더 포함할 수 있다.상기 멀티비전용 디스플레이 유닛은, 상기 UX이벤트를 입력하는 UX이벤트 입력부를 더 포함할 수 있다. [0012]상기 멀티비전용 디스플레이 유닛은, 오브젝트들의 용도, 크기 및 특징에 따라 상태값을 시뮬레이션하여 정형화 [0013]되지 않은 연속 상태값을 만드는 오브젝트 인공지능 시뮬레이터를 더 포함할 수 있다.상기 멀티비전용 디스플레이 유닛의 제어부는, 영상처리부를 제어하는 영상제어부; 상기 그래픽처리부를 제어하 [0014]는 그래픽제어부; 실시간 렌더링 3D 오브젝트 화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현 방법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나를 제어하는오브젝트 제어부; 복수의 디스플레이 유닛에서 다양한 인터페이스를 통해 입력받은 데이터 값을 다른 각각의 디스플레이 유닛에 동기화시킬 데이터로 만들고 제어하는 UX이벤트 제어부; 및 외부의 시스템 또는 다른 플랫폼장치와 통신하여 수신한 오브젝트 상태값을 제어하는 통신제어부 중 적어도 하나를 포함할 수 있다.상기 멀티비전용 디스플레이 유닛에서, 상기 통신데이터는 동기신호 데이터, 오브젝트 데이터, 영상 데이터, 그 [0015]래픽 데이터, 및 UX이벤트 데이터 중 적어도 하나를 포함할 수 있다.상기 멀티비전용 디스플레이 유닛에서, 상기 통신데이터는 네트워크에 연결된 다른 플랫폼과 송수신되는 것이 [0016]바람직하다.본 발명의 일실시예에 따른 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템은 청구항 제 1항 내지 제7 [0017]항 중 어느 한 항에 기재된 디스플레이 유닛들 다수를 서로 통신 가능하도록 결합하여 이루어지는 것을 특징으로 한다.상기 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템에서, 다수의 디스플레이 유닛들은 동기화 서버를 [0018]공개특허 10-2014-0088462-5-통하여 결합되는 것이 바람직하다.상기 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템의 동기화 서버는, 각 디스플레이 유닛과 통신데이 [0019]터를 송수신하는 서버통신부; 각 디스플레이 유닛과 동기화를 위한 서버 타이머; 및 각 디스플레이 유닛의 동기정보를 생성하는 서버 동기정보 생성부를 포함할 수 있다.상기 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템은, 실시간 렌더링 3D 오브젝트 화면을 구성하는 [0020]오브젝트들의 생성, 삭제, 위치, 이동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현 방법, 재생 속도,및 프레임 넘버 정보 중 적어도 하나를 제어하는 오브젝트 제어부; 복수의 디스플레이 유닛에서 다양한 인터페이스를 통해 입력받은 데이터 값을 다른 각각의 디스플레이 유닛에 동기화시킬 데이터로 만들고 제어하는 UX이벤트 제어부; 및 연결된 각 디스플레이 유닛 또는 외부 플랫폼 디바이스와 통신하여 주고 받은 오브젝트 상태값을 제어하는 통신제어부 중 적어도 하나를 포함할 수 있다.상기 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템의 동기화 서버는 오브젝트들의 용도, 크기와 특징 [0021]에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만드는 오브젝트의 인공지능 시뮬레이터를 더포함할 수 있다.본 발명의 일실시예에 따른 멀티비전의 실시간 렌더링 3D 오브젝트 처리방법은, 하나의 전체 화면을 분할한 분 [0022]할 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 복수의 디스플레이 유닛마다 사전에 할당하여 저장하는단계; 상기 복수의 디스플레이 유닛들이 상기 저장된 분할 영상데이터 또는 실시간 렌더링 오브젝트 데이터를동기화하여 표시하는 단계; 상기 복수의 디스플레이 유닛들 중 적어도 하나에서 사용자로부터 UX이벤트를 입력받는 단계; 및 상기 입력된 UX이벤트에 따라 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 표시하는 단계를 포함할 수 있다.상기 멀티비전의 실시간 렌더링 3D 오브젝트 처리방법은, 상기 입력받은 UX이벤트가 다른 디스플레이 유닛과 관 [0023]계되어 있는지를 판단하는 단계를 더 포함할 수 있다.상기 멀티비전의 실시간 렌더링 3D 오브젝트 처리방법은, 상기 UX이벤트가 입력된 디스플레이 유닛으로부터 UX [0024]이벤트와 관련된 디스플레이 유닛에 동기화 정보 데이터, 영상데이터, 실시간 렌더링 오브젝트 데이터, 및 UX이벤트 데이터 중 적어도 하나를 전송하는 단계를 더 포함할 수 있다.상기 멀티비전의 실시간 렌더링 3D 오브젝트 처리방법은, 네트워크에 연결된 다른 플랫폼 또는 다른 디스플레이 [0025]유닛으로부터 동기화 정보 데이터, 영상데이터, 실시간 렌더링 오브젝트 데이터, 및 UX이벤트 데이터 중 적어도하나를 수신하는 단계를 더 포함할 수 있다.상기 멀티비전의 실시간 렌더링 3D 오브젝트 처리방법에서, 동기화 정보 데이터, 영상데이터, 실시간 렌더링 오 [0026]브젝트 데이터, 및 UX이벤트 데이터 중 적어도 하나는 동기 서버를 경유하여 전송 또는 수신할 수 있다. 발명의 효과본 발명에 따른 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템에 의하면, 복수의 디스플레이 유닛에서 [0027]표현되는 실시간 렌더링 3D 화면을 복수의 디스플레이 유닛들 간에 표시되는 화면의 재생빈도마다 밀리 초 단위의 정밀도를 가지고 동기를 맞추어 표시할 수 있어, 멀티 디스플레이 환경에서 전체적인 화면의 어긋남이 없이정확하게 표시할 수 있다. 또한, 전체 표시 화면의 어긋남이 없이 정확한 화면 표시가 유지되면서 수십, 수백 개 이상의 디스플레이 장치 [0028]에서 화면 표시가 구동되도록 용이하게 확장할 수 있다.또한, 본 발명의 멀티비전 시스템은 구성되는 각 디스플레이 유닛마다 사전에 표시할 영상 데이터(오브젝트)를 [0029]사전에 할당하여 저장한 후에 이를 표시하기 때문에, 멀티비전 시스템을 수십, 수백 개 이상의 디스플레이 유닛으로 구성하더라도 최고 수준의 해상도로 표현하는 것이 가능하다.또한, 사용자는 제한된 디스플레이 영역에서 조작하는 한계에서 벗어나 복수의 다중 디스플레이 유닛들을 단일 [0030]디스플레이 장치처럼 조작이 가능해 진다.또한, 개별 혹은 다수의 독립적인 디스플레이 유닛 장치마다 다양한 인터페이스를 배치하여 복수의 다중 디스플 [0031]레이 유닛에서 동시에 다중 사용자가 다양한 인터페이스와 상호작용하는 시스템을 구성할 수 있다.또한, 다양한 플랫폼의 디바이스들과 연동되어 그 디바이스를 사용하는 사용자와 상호작용하는 시스템을 구성할 [0032]공개특허 10-2014-0088462-6-수 있다.도면의 간단한 설명도 1은 본 발명에 따른 멀티비전용 디스플레이 유닛의 구성을 나타내는 블록도, [0033]도 2는 본 발명에 따른 동기화 서버의 구성을 나타내는 블록도,도 3은 본 발명의 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템에서 복수의 디스플레이 유닛과 동기화 서버 간의 데이터 흐름을 나타내는 흐름도,도 4는 본 발명의 일실시예에 따른 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템의 구성을 나타내는블록도,도 5는 본 발명의 다른 실시예에 따른 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템의 구성을 나타내는 블록도, 및도 6 및 도 7은 본 발명의 실시예에 따른 멀티비전 시스템의 실시간 렌더링 3D 오브젝트 처리방법을 나타내는순서도이다. 발명을 실시하기 위한 구체적인 내용이하, 첨부한 도면을 참조하여 본 발명의 실시예들에 대하여 상세히 설명한다. 설명의 편의상 본 발명과 직접 [0034]적으로 관련이 없는 부분은 생략하였고, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한참조부호를 부여하였다.본 발명에 따른 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템은 예를 들면 다양한 인터페이스 및 다 [0035]양한 플랫폼을 통한 사용자의 이벤트에 따라 오브젝트들이 반응하도록 구성한 스마트 아쿠아리움에 적용할 수있다.실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템은 각각 디스플레이 유닛(1)으로 구성된 복수의 클라이 [0036]언트(#1-#n)들을 서로 통신가능하게 결합하여 구성할 수 있다. 복수의 클라이언트(#1-#n)들을 서로 통신가능하게 결합하는 방법은 도 4에 나타낸 바와 같이 클라이언트끼리 서 [0037]로 연결하는 것과 도 5에 나타낸 바와 같이 동기화 서버(300)를 경유하여 클라이언트들을 결합하는 것이 가능하다.복수의 클라이언트(#1-#n)들은 각각 표시할 영상 데이터와 오브젝트 데이터를 사전에 저장한 후 모든 클라이언 [0038]트(#1-#n)들을 동기화시켜 표시할 수 있다. 복수의 클라이언트(#1-#n)는 각각 하나의 전체 화면 중 일부에 해당하는 분할 화면을 할당하여 표시하는 복수의 [0039]디스플레이 유닛(1)을 포함할 수 있다.도 1에 나타낸 바와 같이, 본 발명의 멀티비전용 디스플레이 유닛(1)은 다른 디스플레이 유닛(클라이언트#1-#n) [0040]또는 서버(300)와 통신데이터를 송수신하는 통신부(110), 실시간 렌더링 오브젝트 데이터와 분할 영상데이터를겹쳐진 화면으로 표현하는 마스킹 영상 인코딩부(120), 다른 디스플레이 유닛과의 동기화를 위한 타이머(130),사용자로부터 UX이벤트(user experience event)를 입력받는 UX이벤트 입력부(140), UX이벤트 입력부(140)로부터 입력된 UX이벤트를 처리하는 UX이벤트 처리부(150), 실시간 렌더링 오브젝트 데이터를 만드는 오브젝트 처리부(160), 오브젝트들의 용도, 크기 및 특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만드는 오브젝트 인공지능 시뮬레이터(220), 입력되는 그래픽 데이터를 처리하는 그래픽 처리부(170), 하나의 전체 화면 중 일부에 해당하는 분할 영상데이터를 처리하는 영상처리부(180), 상기 하나의 전체 화면 중 일부에해당하는 분할 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 사전에 저장하는 저장부(190), 영상처리부(180), UX이벤트 처리부(150), 오브젝트 처리부(160), 마스킹 영상 인코딩부(120), 및 통신부(110) 중 적어도하나를 제어하기 위한 제어부(200), 처리된 실시간 렌더링 오브젝트 데이터와 분할 영상데이터를 화면으로 출력하는 출력부(210)를 포함하여 구성할 수 있다.통신부(110)는 다른 디스플레이 유닛(클라이언트 #2-#n), 동기화 서버(300), 예를 들면 스마트폰과 같은 다양한 [0041]플랫폼(미도시), 인터넷으로 연결된 사용자 컴퓨터 등과 통신데이터를 송수신할 수 있다.통신데이터는 동기신호 데이터, 오브젝트 데이터, 영상 데이터, 그래픽 데이터, 및 UX이벤트 데이터 중 적어도 [0042]공개특허 10-2014-0088462-7-하나를 포함할 수 있다.통신부(110)는 무선 인터넷 기술로서 WLAN (Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World [0043]Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access) 등이 이용될 수 있다.통신부(110)는 근거리 통신기술로서 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통 [0044]신(IrDA, infrared Data Association), UWB(Ultra Wideband), ZigBee 등이 적용될 수 있다.통신부(110)는 HDMI(high definition multimedia interface), USB, 컴포넌트(component), LVDS 등의 규격에 따 [0045]라 송수신할 수 있는 인터페이스가 적용될 수 있다.마스킹 영상 인코딩부(120)는 저장부(190)에 저장된 분할 영상데이터와 실시간 렌더링 오브젝트 데이터를 중첩 [0046]시켜 하나의 분할 화면으로 출력할 수 있도록 처리할 수 있다.또한, 마스킹 영상 인코딩부(120)는 통신부(110)를 통해 수신한 영상데이터와 실시간 렌더링 오브젝트 데이터를 [0047]중첩시켜 하나의 화면으로 출력할 수 있도록 처리할 수 있다.타이머(130)는 모든 클라이언트(#1-#n)들 및 동기화 서버를 동기화하기 위해 현재 디스플레이 유닛(1)의 시각 [0048]정보를 유지 관리할 수 있다. 타이머(130)는 네트워크를 통해 다른 클라이언트 또는 서버와 시각을 주고 교환하며, 네트워크 통신 중 지연요소 및 클라이언트 상태 지연요소를 측정하고 보상하여 시각을 다른 클라이언트 및서버와 일치시킬 수 있다. UX이벤트 입력부(140)는 사용자의 명령을 입력하는 터치패널, 마우스, 키보드, 리모컨 등을 포함할 수 있다. [0049]UX이벤트 입력부(140)는 또한 와이파이(Wi-Fi), 블루투스 등과 같은 무선통신기술을 이용하여 연결된 스마트폰 [0050]과 같은 모바일 장치를 포함할 수도 있다.UX이벤트 처리부(150)는 UX이벤트 입력부(140)에서 입력된 정해지지 않은 일정의 입출력 데이터 처리와 사용자 [0051]상호작용 처리를 위한 각종 인터페이스 입출력 데이터 처리를 수행한다. 즉, 사용자의 명령에 따라 UX이벤트를처리하여 UX이벤트에 따른 오브젝트, 영상, 그래픽 등을 처리할 수 있다.물론, UX이벤트 처리부(150)는 통신부(110)를 통하여 입력된 UX이벤트를 처리하여 오브젝트, 영상, 그래픽 등을 [0052]처리할 수도 있다. 오브젝트 처리부(160)는 저장부(190)에 저장된 또는 통신부(110)를 통해 입력된 오브젝트 데이터를 처리하여 출 [0053]력부(210)를 통해 오브젝트가 출력될 수 있도록 한다.오브젝트 처리부(160)는 UX이벤트 처리부(150)에서 처리된 또는 통신부(110)를 통해 입력된 UX이벤트에 따라 오 [0054]브젝트들을 처리할 수 있다.오브젝트 처리부(160)는 오브젝트 종류에 따라 정적(statics) 오브제트 처리부 및 동적(dynamic) 오브젝트 처리 [0055]부를 포함할 수 있다. 인공지능 시뮬레이터(220)는 UX이벤트 처리부(150)에서 처리된 UX이벤트에 따라 오브젝트들의 용도, 크기 및 [0056]특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만들어 오브젝트 처리부(160)에 제공할수 있다.또한, 인공지능 시뮬레이터(220)는 저장부(190)에 저장되거나 통신부(110)를 통하여 입력된 UX이벤트에 따라 오 [0057]브젝트들의 용도, 크기 및 특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만들어 오브젝트 처리부(160)에 제공할 수 있다.그래픽 처리부(170)는 UX이벤트 입력부(140) 또는 통신부(110)를 통해 입력되거나, 저장부(190)에 저장된 그래 [0058]픽 데이터를 처리하여 출력부(210)에 제공할 수 있다.영상처리부(180)는 기본적으로 저장부(190)에 저장된 분할 영상데이터에 대해 기 설정된 다양한 영상처리과정을 [0059]수행한다. 상기 저장부(190)에 저장된 영상 데이터는 멀티비전에서 처리하는 하나의 전체 화면 중 할당된 일부에 해당하는 분할 영상 데이터로서 사전에 저장되어 다른 디스플레이 유닛들과 동기화하여 처리될 수 있다.영상처리부(180)는 이러한 프로세스가 수행된 영상 데이터를 출력부(210)에 출력함으로써, 출력부(210)에 해당 [0060]영상신호에 기초하는 영상이 표시되게 한다. 물론 영상처리부(180)는 연결된 디스플레이 유닛, 동기화 서버, 및다른 플랫폼 디바이스로부터 입력되어 수신된 영상 데이터를 소정 프로세스로 처리할 수 있다. 공개특허 10-2014-0088462-8-영상처리부(180)가 수행하는 신호처리의 종류는 한정되지 않는 바, 예를 들면 소정 신호를 각 특성별 신호로 분 [0061]배하는 디멀티플렉싱(de-multiplexing), 영상데이터의 영상 포맷에 대응하는 디코딩(decoding), 인터레이스(interlace) 방식의 영상 데이터를 프로그레시브(progressive) 방식으로 변환하는 디인터레이싱(de-interlacing), 영상 데이터를 기 설정된 해상도로 조정하는 스케일링(scaling), 영상 화질 개선을 위한 노이즈감소(noise reduction), 디테일 강화(detail enhancement), 프레임 리프레시 레이트(frame refresh rate) 변환등을 포함할 수 있다.영상처리부(180)는 상기 프로세스를 수행하기 위한 다양한 칩셋(미도시), 메모리(미도시), 전자부품(미도시), [0062]배선(미도시) 등의 회로 구성이 인쇄회로기판(미도시) 상에 실장된 영상처리보드(미도시)로 구현된다.저장부(190)는 하나의 전체 화면 중 할당된 일부에 해당하는 분할 영상 데이터, 실시간 렌더링 3D 오브젝트 데 [0063]이터, 그래픽 데이터, 디스플레이 유닛(1)을 구동하기 위한 각종 프로그램 등을 저장할 수 있다. 저장부(190)는 한정되지 않은 데이터가 저장된다. 저장부(250)는 플래시메모리(flash-memory), 하드디스크 드 [0064]라이브(hard-disc drive)와 같은 비휘발성 메모리로 구현된다. 저장부(190)는 제어부(200)에 의해 액세스되며,이들에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행된다.제어부(200)는 CPU로 구성할 수 있고, 디스플레이 유닛(1)의 다양한 구성에 대한 제어동작을 수행한다. 예를 들 [0065]면, 제어부(200)는 영상처리부(180)가 처리하는 영상 데이터 처리과정의 진행, 통신부(110)를 통한 신호/정보/데이터의 송수신 동작, 저장부(190)에 액세스하여 데이터의 독취/기록/수정/삭제/갱신 작업을 수행, UX이벤트처리부(150)의 이벤트 처리과정, 오브젝트 처리부(1600의 오브젝트 처리과정, 그래픽 처리부(170)의 그래픽 처리과정 및 처리된 각종 데이터를 출력부(210)를 통해 출력하는 과정을 제어한다.도 1에는 편의상 하나의 제어부(200)로 각 구성 요소를 제어하는 것으로 표현하였지만, 각 구성 요소의 효율적 [0066]인 제어를 위해 별도의 제어부를 개별적으로 구성할 수 있다. 제어부(200)는 예를 들면 영상처리부(180)를 제어하는 영상제어부(미도시), 상기 그래픽처리부(170)를 제어하는 그래픽제어부(미도시), 실시간 렌더링 3D 오브젝트 화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현방법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나를 제어하는 오브젝트 제어부(미도시), 복수의 디스플레이 유닛(10)에서 다양한 인터페이스를 통해 입력받은 데이터 값을 다른 각각의 디스플레이 유닛에 동기화시킬데이터로 만들고 제어하는 UX이벤트 제어부(미도시) 및 외부의 시스템 또는 다른 플랫폼 디바이스와 통신하여수신한 오브젝트 상태값을 제어하는 통신제어부(미도시) 중 적어도 하나를 포함할 수 있다.출력부(210)는 상기 영상 처리부(180)로부터 처리되어 수신된 영상 데이터에 기초하여 영상을 표시한다. 출력부 [0067](210)의 구현 방식은 한정되지 않는 바, 액정(liquid crystal), 플라즈마(plasma), 발광 다이오드(light-emitting diode), 유기발광 다이오드(organic light-emitting diode), 면전도 전자총(surface-conductionelectron-emitter), 탄소 나노 튜브(carbon nano-tube), 나노 크리스탈(nano-crystal) 등의 다양한 디스플레이패널로 구현될 수 있다.출력부(210)는 구현 방식에 따라서 부가적인 구성을 추가적으로 포함할 수 있다. 예를 들면, 출력부(210)는 액 [0068]정 방식인 경우, 광을 공급하는 백라이트유닛(미도시)과, 표시패널(미도시)을 구동시키는 패널구동기판(미도시)을 포함할 수 있다.도 4에 나타낸 바와 같이 지금까지 설명한 디스플레이 유닛(1)들 다수를 상호 직접 연결하여 본 발명에 따른 실 [0069]시간 랜터링 3D 오브젝트 인터렉티브 멀티비전 시스템을 구성할 수 있다.본 발명의 다른 실시예로서, 도 5에 나타낸 바와 같이 네트워크 허브(#1-#N)를 통하여 다수의 클라이언트(#1- [0070]#N+1…)를 서버에 연결할 수 있다.도 2는 도 5에 나타낸 동기화 서버(300)의 구성을 나타내는 블록도이다. [0071]동기화 서버(300)는 연결된 각 디스플레이 유닛(1) 또는 외부 플랫폼 디바이스(미도시)와 통신데이터를 송수신 [0072]하는 서버통신부(320), 디스플레이 유닛들(1)의 동기화를 위해 서버 시각 정보를 유지 관리하는 서버 타이머(310), 디스플레이 유닛들(1)의 동기 정보를 생성하는 서버 동기정보 생성부(330), 실시간 렌더링 3D 오브젝트화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현 방법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나를 제어하는 서버 오브젝트 제어부(340), 복수의 디스플레이 유닛(1)에서 다양한 인터페이스를 통해 입력받은 데이터 값을 다른 각각의 디스플레이 유닛(1)에 동기화시킬데이터로 만들고 제어하는 서버 UX이벤트 제어부(350), 연결된 각 디스플레이 유닛(1) 또는 외부 플랫폼 디바이공개특허 10-2014-0088462-9-스와 통신하여 주고 받은 오브젝트 상태값을 제어하는 서버 통신제어부(360), 및 오브젝트들의 용도, 크기와 특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만드는 서버 오브젝트의 인공지능 시뮬레이터(370)를 포함하여 구성할 수 있다.서버 타이머(310)는 모든 클라이언트(#1-#n)들 및 동기화 서버를 동기화하기 위해 현재 동기화 서버(300)의 시 [0073]각 정보를 유지 관리할 수 있다. 서버 타이머(310)는 네트워크를 통해 다른 클라이언트(#1-#N)와 시각을 주고교환하며, 네트워크 통신 중 지연요소 및 동기화 서버(300)의 상태 지연요소를 측정하고 보상하여 시각을 모든클라이언트와 일치시킬 수 있다.서버통신부(320)는 모든 디스플레이 유닛(클라이언트 #1-#n), 예를 들면 스마트폰과 같은 다양한 [0074]플랫폼(미도시), 인터넷으로 연결된 사용자 컴퓨터 등과 통신데이터를 송수신할 수 있다.통신데이터는 동기신호 데이터, 오브젝트 데이터, 영상 데이터, 그래픽 데이터, 및 UX이벤트 데이터 중 적어도 [0075]하나를 포함할 수 있다.서버통신부(320)는 HDMI(high definition multimedia interface), USB, 컴포넌트(component), LVDS 등의 규격 [0076]에 따라 송수신할 수 있는 인터페이스가 적용될 수 있다.서버통신부(320)는 무선 인터넷 기술로서 WLAN (Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), [0077]Wimax(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access) 등이 이용될 수도 있다.서버통신부(320)는 근거리 통신기술로서 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 [0078]통신(IrDA, infrared Data Association), UWB(Ultra Wideband), ZigBee 등이 적용될 수도 있다.서버 동기정보 생성부(330)는 모든 클라이언트들(#1-#N)이 동기화하여 동영상 데이터, 그래픽 데이터, 오브젝트 [0079]데이터 등을 표현할 수 있도록 동기화 정보를 생성할 수 있다. 동기화 정보는 서버통신부(320)를 통하여 동기신호로서 통신데이터와 함께 각 클라이언트로 송수신될 수 있다. [0080]서버 UX이벤트 제어부(350)는 외부의 플랫폼 디바이스 또는 각 클라이어언트(#1-#N)의 인터페이스 장치 [0081](A,B,C,D,E…)를 통하여 입력된 데이터를 각 클라이언트에 동기화시킬 데이터로 만들고 제어할 수 있다. 서버 오브젝트 제어부(340)는 실시간 렌더링 3D 오브젝트 화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이 [0082]동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현 방법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나를 제어할 수 있다.서버 통신제어부(360)는 서버통신부(320)를 제어하여 연결된 각 디스플레이 유닛(1) 또는 외부 플랫폼 디바이스 [0083]와 통신하여 주고 받은 오브젝트 상태값을 제어할 수 있다.서버 인공지능 시뮬레이터(370)는 서버 UX이벤트 제어부(350)에서 제공된 UX이벤트에 따라 오브젝트들의 용도, [0084]크기 및 특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만들어 오브젝트 제어부(340)에제공할 수 있다.이하 동기 서버(300)와 디스플레이 유닛(1)(클라이언트) 사이의 데이터 흐름을 도 3을 참조하여 설명하면 다음 [0085]과 같다.디스플레이 유닛(1)과 동기 서버(300)는 서버 연결신호를 주고 받아 서로 연결될 수 있다. 이때, 연결된 디스플 [0086]레이 유닛(1)과 동기 서버(300)는 밀리초(ms)당 오브젝트 동기화 정보를 주고 받는다.연결된 디스플레이 유닛(1)과 동기 서버(300)는 영상 동기 정보, 영상 준비 상태 정보, 및 영상 재생신호, 프레 [0087]임 정보를 순차적으로 주고받는다.이후, 연결된 디스플레이 유닛(1)과 동기 서버(300)는 외부의 플랫폼 디바이스 또는 각 디스플레이 유닛의 인터 [0088]페이스 장치에서 입력된 UX이벤트 입력데이터와 UX이벤트 동기화 정보를 송수신할 수 있다.마지막으로 연결된 디스플레이 유닛(1)과 동기 서버(300)는 통신 동기화 정보 및 통신 준비상태 정보를 주고 받 [0089]은 후, 통신 데이터를 출력 시작 명령, 통신 상태 정보를 주고 받는다.이와 같이 동기 서버(300)는 연결된 모든 디스플레이 유닛(1)과 실시간으로 3D 오브젝트를 동기화하여 처리하여 [0090]모든 디스플레이 유닛들이 전체적으로 일체화된 화면을 표현할 수 있을 뿐만 아니라 다양한 사용자 이벤트를 실공개특허 10-2014-0088462-10-시간으로 반영하여 표현할 수 있다.이하 본 발명의 실시예에 따른 멀티비전 시스템의 실시간 렌더링 3D 오브젝트 처리방법을 도 6 및 도 7을 참조 [0091]하여 설명하면 다음과 같다.도 6은 모든 디스플레이 유닛(1)이 각각 저장부(190)에 저장된 데이터를 기준으로 동기화하여 표시하면서, 각 [0092]디스플레이 유닛의 UX이벤트 입력부(140)를 통하여 UX이벤트가 입력되었을 때의 실시간 렌더링 3D 오브젝트 처리방법을 나타낸 것이다.먼저, 각 디스플레이 유닛(1)들의 저장부(190)에는 영상 데이터(오브젝트 포함)가 할당되어 저장된다(S410). [0093]각 디스플레이 유닛(1)은 저장부(190)에 저장된 할당 영상 데이터(오브젝트 포함)를 표시한다(S411). [0094]이후, 각 디스플레이 유닛(1)의 UX이벤트 입력부(140)로부터 UX이벤트가 입력되었는지를 판단한다(S412). 만일 [0095]UX이벤트가 입력되지 않았으면 저장부(190)에 저장된 일정으로 사전 할당된 영상 데이터(오브젝트 포함)를 표시한다. 만일 만일 UX이벤트가 입력되었으면, 입력된 UX이벤트가 다른 디스플레이 유닛들과 관계되었는지를 판단한다(S413).만일, 입력된 UX이벤트가 다른 디스플레이 유닛들과 관계되지 않았으면, 입력된 UX이벤트를 자신에게만 반영하 [0096]여 영상 데이터(오브젝트 포함)를 동기화하여 표시한다.만일 입력된 UX이벤트가 다른 디스플레이 유닛들과 관계되어 있으면, UX이벤트를 관계된 디스플레이 유닛 또는 [0097]동기 서버(300)에 전송한다(S414).이후 입력 또는 수신된 UX이벤트를 반영하여 각 디스플레이 유닛(1)은 영상 데이터(오브젝트 포함)를 동기화하 [0098]여 표시한다(S415).도 7은 디스플레이 유닛(1)이 각각 저장부(190)에 저장된 데이터를 기준으로 동기화하여 표시하면서, 외부 플랫 [0099]폼 디바이스 또는 다른 디스플레이 유닛을 통하여 UX이벤트가 입력되었을 때의 실시간 렌더링 3D 오브젝트 처리방법을 나타낸 것이다.먼저, 각 디스플레이 유닛(1)들의 저장부(190)에는 영상 데이터(오브젝트 포함)가 할당되어 저장된다(S510). [0100]각 디스플레이 유닛(1)은 저장부(190)에 저장된 할당 영상 데이터(오브젝트 포함)를 표시한다(S511). [0101]이후, 외부 플랫폼 디바이스 또는 다른 디스플레이 유닛으로부터 UX이벤트가 입력되었는지를 판단한다(S512). [0102]만일 UX이벤트가 입력되지 않았으면 저장부(190)에 저장된 일정으로 사전 할당된 영상 데이터(오브젝트 포함)를표시한다. 만일 만일 UX이벤트가 입력되었으면, 입력 또는 수신된 UX이벤트를 반영하여 각 디스플레이 유닛(1)은 영상 데이터(오브젝트 포함)를 동기화하여 표시한다(S512).외부 플랫폼 디바이스 또는 다른 디스플레이 유닛으로부터 입력되는 통신데이터는 동기화 정보 데이터, 영상데 [0103]이터, 실시간 렌더링 오브젝트 데이터, 및 UX이벤트 데이터 중 적어도 하나를 포함할 수 있다.지금까지 본 발명의 실시예가 도시되고 설명되었지만, 본 발명이 속하는 기술분야의 통상의 지식을 가진 당업자 [0104]라면 본 발명의 원칙이나 정신에서 벗어나지 않으면서 실시예를 변형할 수 있을 것이다. 따라서, 발명의 범위는지금까지 설명된 실시예로 정해지는 것이 아니라 첨부된 청구항과 그 균등물에 의해 정해질 것이다.부호의 설명1: 디스플레이 유닛(클라이언트) 110: 통신부 [0105]120: 영상 마스킹 인코딩부 130: 타이머140: UX이벤트 입력부 150: UX이벤트 처리부160: 오브젝트 처리부 170: 그래픽 처리부180: 영상 처리부 190: 저장부200: 제어부 210: 출력부(디스플레이 패널)220: 인공지능 시뮬레이터 300: 동기 서버공개특허 10-2014-0088462-11-310: 서버 타이머 320: 서버통신부330: 서버동기 정보 생성부 340: 서버 오브젝트 제어부350: 서버 UX이벤트 제어부 360: 서버 통신제어부370: 서버 인공지능 시뮬레이터도면도면1공개특허 10-2014-0088462-12-도면2공개특허 10-2014-0088462-13-도면3공개특허 10-2014-0088462-14-도면4공개특허 10-2014-0088462-15-도면5공개특허 10-2014-0088462-16-도면6공개특허 10-2014-0088462-17-도면7공개특허 10-2014-0088462-18-"}
{"patent_id": "10-2013-0000362", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템 및 멀티비전 시스템의 실시간 렌더링 3D 오브 젝트 처리방법에 관한 것이다. 본 발명의 멀티비전 시스템의 실시간 렌더링 3D 오브젝트 처리방법, 하나의 전체 화면을 분할한 분할 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 복수의 디스플레이 유닛마다 사전에 할당하여 저장하는 단계; 상기 복수 의 디스플레이 유닛들이 상기 저장된 분할 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 동기화하여 표시하 는 단계; 상기 복수의 디스플레이 유닛들 중 적어도 하나에서 사용자로부터 UX이벤트를 입력받는 단계; 및 상기 입력된 UX이벤트에 따라 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 표시하는 단계를 포함하는 것을 특징 으로 한다. 본 발명에 의하면, 복수의 디스플레이 유닛에서 표현되는 실시간 렌더링 3D 화면을 복수의 디스플레이 유닛들 간 에 표시되는 화면의 재생빈도마다 밀리초 단위의 정밀도를 가지고 동기를 맞추어 표시할 수 있고, 멀티 디스플레 이 환경에서 전체적인 화면의 어긋남이 없이 정확하게 표시할 수 있다. 나아가, 전체 표시 화면의 어긋남이 없이 정확한 화면 표시가 유지되면서 수십, 수백 개 이상의 디스플레이 유닛에서 최고 수준의 해상도로 화면 표시가 가능하도록 용이하게 확장할 수 있다."}
{"patent_id": "10-2013-0000362", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템 및 그의 실시간 렌더링 3D 오브젝트 처리방 법에 관한 것으로, 복수의 상호 독립적인 디스플레이 유닛에서 표시되는 실시간 렌더링 3D 화면을 디스플레이 유닛들 간의 화면을 동기화(Synchronization)하여 표현할 수 있는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티 비전 시스템에 관한 것이다."}
{"patent_id": "10-2013-0000362", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "멀티비전(Multivision)이란 복수의 디스플레이 유닛 상에서 하나의 전체 화면 또는 각기 다른 화면을 표시해 주 는 장치이다. 멀티비전은 기술적 제약이나 비용의 한계를 넘는 크기의 영상을 표현하기 위해서, 작은 크기의 영 상 표시유닛들을 모아서 배치하고 전체 영상의 각 부분들을 분할한 뒤 각각의 장치를 통해서 표시하는 방법을 사용한다. 멀티비전을 구현하기 위해서는 단일 영상 신호 발생장치에서 나오는 전기적인 영상 신호를 하드웨어적으로 분배 하여 여러 개의 개별 디스플레이 유닛을 위한 전기적인 영상 신호를 만드는 방법을 사용하거나, 개별 디스플레 이 유닛마다 상호 독립적인 영상 신호 발생 장치를 직접 연결하고, 각각의 영상 신호 발생 장치의 제어를 담당 하는 시스템끼리 네트워크로 연결하여 연동하는 방법을 사용할 수 있다. 개별 디스플레이 유닛 혹은 소수의 디스플레이 유닛마다 독립적인 영상 신호 발생기를 사용하고, 그 제어 시스 템끼리 네트워크로 연동하는 경우에는 전체 영상 크기의 영상 신호를 만들거나 이 신호를 개별 표시장치를 위한신호로 분배하는 하드웨어 장치를 만들 필요가 없기 때문에 백여 개 이상의 표시장치를 모아서 거대한 디스플레 이를 구성하는 것이 가능해 진다. 이러한 종래의 멀티비전은 제작된 영상물의 전체 영상을 개별 또는 분할해 각 디스플레이 유닛에 스케쥴에 따라 단순 재생하는 하는 것에 불과하고 하였다."}
{"patent_id": "10-2013-0000362", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 3D 오브젝트들을 실시간으로 렌더링하여 멀티비전 형태로 표현할 수 있는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템 및 그의 실시간 렌더링 3D 오브젝트 처리방법을 제공하는 것이다. 본 발명의 다른 목적은 실시간 렌더링 3D 오브젝트 프로그램과 사용자 입력에 따라 실시간으로 변화하는 화면을 화상의 불일치가 발생하지 않고 정확하게 동기화되어 표현할 수 있는 실시간 렌더링 3D 오브젝트 인터렉티브 멀 티비전 시스템 및 그의 실시간 렌더링 3D 오브젝트 처리방법을 제공하는 것이다. 본 발명의 또 다른 목적은 독립적인 다양한 플랫폼 디바이스들과 통신하고 상호작용하여 플랫폼 디바이스와 멀 티비전으로 표현하는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템 및 그의 실시간 렌더링 3D 오브젝 트 처리방법을 제공하는 것이다. 본 발명의 또 다른 목적은 멀티비전을 구성하는 디스플레이 유닛의 수를 충분히 확장하더라도 높은 수준의 해상 도를 유지할 수 있는 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템 및 그의 실시간 렌더링 3D 오브젝 트 처리방법을 제공하는 것이다."}
{"patent_id": "10-2013-0000362", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 과제를 해결하기 위한 멀티비전용 디스플레이 유닛은, 하나의 전체 화면 중 일부에 해당하는 분할 영 상데이터를 처리하는 영상처리부; 입력된 UX이벤트를 처리하는 UX이벤트 처리부; 실시간 렌더링 오브젝트 데이 터를 만드는 오브젝트 처리부; 상기 실시간 렌더링 오브젝트 데이터와 분할 영상데이터를 겹쳐진 화면으로 표현 하는 마스킹 영상 인코딩부; 다른 디스플레이 유닛 또는 서버와 통신데이터를 송수신하는 통신부; 상기 다른 디 스플레이 유닛과의 동기화를 위한 타이머; 및 상기 영상처리부, UX이벤트 처리부, 오브젝트 처리부, 마스킹 영 상 인코딩부, 및 통신부 중 적어도 하나를 제어하기 위한 제어부를 포함하여 구성할 수 있다. 상기 멀티비전용 디스플레이 유닛은 하나의 전체 화면 중 일부에 해당하는 분할 영상데이터 또는 상기 실시간 렌더링 오브젝트 데이터를 사전에 저장하는 저장부를 더 포함할 수 있다. 상기 멀티비전용 디스플레이 유닛은, 상기 UX이벤트를 입력하는 UX이벤트 입력부를 더 포함할 수 있다. 상기 멀티비전용 디스플레이 유닛은, 오브젝트들의 용도, 크기 및 특징에 따라 상태값을 시뮬레이션하여 정형화 되지 않은 연속 상태값을 만드는 오브젝트 인공지능 시뮬레이터를 더 포함할 수 있다. 상기 멀티비전용 디스플레이 유닛의 제어부는, 영상처리부를 제어하는 영상제어부; 상기 그래픽처리부를 제어하 는 그래픽제어부; 실시간 렌더링 3D 오브젝트 화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이동, 오브젝트 간 간섭, 시작 시각, 지속 시간, 영상 표현 방법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나를 제어하는 오브젝트 제어부; 복수의 디스플레이 유닛에서 다양한 인터페이스를 통해 입력받은 데이터 값을 다른 각각의 디 스플레이 유닛에 동기화시킬 데이터로 만들고 제어하는 UX이벤트 제어부; 및 외부의 시스템 또는 다른 플랫폼 장치와 통신하여 수신한 오브젝트 상태값을 제어하는 통신제어부 중 적어도 하나를 포함할 수 있다. 상기 멀티비전용 디스플레이 유닛에서, 상기 통신데이터는 동기신호 데이터, 오브젝트 데이터, 영상 데이터, 그 래픽 데이터, 및 UX이벤트 데이터 중 적어도 하나를 포함할 수 있다. 상기 멀티비전용 디스플레이 유닛에서, 상기 통신데이터는 네트워크에 연결된 다른 플랫폼과 송수신되는 것이 바람직하다. 본 발명의 일실시예에 따른 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템은 청구항 제 1항 내지 제7 항 중 어느 한 항에 기재된 디스플레이 유닛들 다수를 서로 통신 가능하도록 결합하여 이루어지는 것을 특징으 로 한다. 상기 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템에서, 다수의 디스플레이 유닛들은 동기화 서버를 통하여 결합되는 것이 바람직하다. 상기 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템의 동기화 서버는, 각 디스플레이 유닛과 통신데이 터를 송수신하는 서버통신부; 각 디스플레이 유닛과 동기화를 위한 서버 타이머; 및 각 디스플레이 유닛의 동기 정보를 생성하는 서버 동기정보 생성부를 포함할 수 있다. 상기 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템은, 실시간 렌더링 3D 오브젝트 화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현 방법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나를 제어하는 오브젝트 제어부; 복수의 디스플레이 유닛에서 다양한 인터페 이스를 통해 입력받은 데이터 값을 다른 각각의 디스플레이 유닛에 동기화시킬 데이터로 만들고 제어하는 UX이 벤트 제어부; 및 연결된 각 디스플레이 유닛 또는 외부 플랫폼 디바이스와 통신하여 주고 받은 오브젝트 상태값 을 제어하는 통신제어부 중 적어도 하나를 포함할 수 있다. 상기 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템의 동기화 서버는 오브젝트들의 용도, 크기와 특징 에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만드는 오브젝트의 인공지능 시뮬레이터를 더 포함할 수 있다. 본 발명의 일실시예에 따른 멀티비전의 실시간 렌더링 3D 오브젝트 처리방법은, 하나의 전체 화면을 분할한 분 할 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 복수의 디스플레이 유닛마다 사전에 할당하여 저장하는 단계; 상기 복수의 디스플레이 유닛들이 상기 저장된 분할 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 동기화하여 표시하는 단계; 상기 복수의 디스플레이 유닛들 중 적어도 하나에서 사용자로부터 UX이벤트를 입력 받는 단계; 및 상기 입력된 UX이벤트에 따라 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 표시하는 단계 를 포함할 수 있다. 상기 멀티비전의 실시간 렌더링 3D 오브젝트 처리방법은, 상기 입력받은 UX이벤트가 다른 디스플레이 유닛과 관 계되어 있는지를 판단하는 단계를 더 포함할 수 있다. 상기 멀티비전의 실시간 렌더링 3D 오브젝트 처리방법은, 상기 UX이벤트가 입력된 디스플레이 유닛으로부터 UX 이벤트와 관련된 디스플레이 유닛에 동기화 정보 데이터, 영상데이터, 실시간 렌더링 오브젝트 데이터, 및 UX이 벤트 데이터 중 적어도 하나를 전송하는 단계를 더 포함할 수 있다. 상기 멀티비전의 실시간 렌더링 3D 오브젝트 처리방법은, 네트워크에 연결된 다른 플랫폼 또는 다른 디스플레이 유닛으로부터 동기화 정보 데이터, 영상데이터, 실시간 렌더링 오브젝트 데이터, 및 UX이벤트 데이터 중 적어도 하나를 수신하는 단계를 더 포함할 수 있다. 상기 멀티비전의 실시간 렌더링 3D 오브젝트 처리방법에서, 동기화 정보 데이터, 영상데이터, 실시간 렌더링 오 브젝트 데이터, 및 UX이벤트 데이터 중 적어도 하나는 동기 서버를 경유하여 전송 또는 수신할 수 있다."}
{"patent_id": "10-2013-0000362", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템에 의하면, 복수의 디스플레이 유닛에서 표현되는 실시간 렌더링 3D 화면을 복수의 디스플레이 유닛들 간에 표시되는 화면의 재생빈도마다 밀리 초 단위 의 정밀도를 가지고 동기를 맞추어 표시할 수 있어, 멀티 디스플레이 환경에서 전체적인 화면의 어긋남이 없이 정확하게 표시할 수 있다. 또한, 전체 표시 화면의 어긋남이 없이 정확한 화면 표시가 유지되면서 수십, 수백 개 이상의 디스플레이 장치 에서 화면 표시가 구동되도록 용이하게 확장할 수 있다. 또한, 본 발명의 멀티비전 시스템은 구성되는 각 디스플레이 유닛마다 사전에 표시할 영상 데이터(오브젝트)를 사전에 할당하여 저장한 후에 이를 표시하기 때문에, 멀티비전 시스템을 수십, 수백 개 이상의 디스플레이 유닛 으로 구성하더라도 최고 수준의 해상도로 표현하는 것이 가능하다. 또한, 사용자는 제한된 디스플레이 영역에서 조작하는 한계에서 벗어나 복수의 다중 디스플레이 유닛들을 단일 디스플레이 장치처럼 조작이 가능해 진다. 또한, 개별 혹은 다수의 독립적인 디스플레이 유닛 장치마다 다양한 인터페이스를 배치하여 복수의 다중 디스플 레이 유닛에서 동시에 다중 사용자가 다양한 인터페이스와 상호작용하는 시스템을 구성할 수 있다. 또한, 다양한 플랫폼의 디바이스들과 연동되어 그 디바이스를 사용하는 사용자와 상호작용하는 시스템을 구성할 수 있다."}
{"patent_id": "10-2013-0000362", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참조하여 본 발명의 실시예들에 대하여 상세히 설명한다. 설명의 편의상 본 발명과 직접 적으로 관련이 없는 부분은 생략하였고, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조부호를 부여하였다. 본 발명에 따른 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템은 예를 들면 다양한 인터페이스 및 다 양한 플랫폼을 통한 사용자의 이벤트에 따라 오브젝트들이 반응하도록 구성한 스마트 아쿠아리움에 적용할 수 있다. 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템은 각각 디스플레이 유닛으로 구성된 복수의 클라이 언트(#1-#n)들을 서로 통신가능하게 결합하여 구성할 수 있다. 복수의 클라이언트(#1-#n)들을 서로 통신가능하게 결합하는 방법은 도 4에 나타낸 바와 같이 클라이언트끼리 서 로 연결하는 것과 도 5에 나타낸 바와 같이 동기화 서버를 경유하여 클라이언트들을 결합하는 것이 가능하 다. 복수의 클라이언트(#1-#n)들은 각각 표시할 영상 데이터와 오브젝트 데이터를 사전에 저장한 후 모든 클라이언 트(#1-#n)들을 동기화시켜 표시할 수 있다. 복수의 클라이언트(#1-#n)는 각각 하나의 전체 화면 중 일부에 해당하는 분할 화면을 할당하여 표시하는 복수의 디스플레이 유닛을 포함할 수 있다. 도 1에 나타낸 바와 같이, 본 발명의 멀티비전용 디스플레이 유닛은 다른 디스플레이 유닛(클라이언트#1-#n) 또는 서버와 통신데이터를 송수신하는 통신부, 실시간 렌더링 오브젝트 데이터와 분할 영상데이터를 겹쳐진 화면으로 표현하는 마스킹 영상 인코딩부, 다른 디스플레이 유닛과의 동기화를 위한 타이머, 사용자로부터 UX이벤트(user experience event)를 입력받는 UX이벤트 입력부, UX이벤트 입력부로부 터 입력된 UX이벤트를 처리하는 UX이벤트 처리부, 실시간 렌더링 오브젝트 데이터를 만드는 오브젝트 처리 부, 오브젝트들의 용도, 크기 및 특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만 드는 오브젝트 인공지능 시뮬레이터, 입력되는 그래픽 데이터를 처리하는 그래픽 처리부, 하나의 전 체 화면 중 일부에 해당하는 분할 영상데이터를 처리하는 영상처리부, 상기 하나의 전체 화면 중 일부에 해당하는 분할 영상데이터 또는 실시간 렌더링 오브젝트 데이터를 사전에 저장하는 저장부, 영상처리부 , UX이벤트 처리부, 오브젝트 처리부, 마스킹 영상 인코딩부, 및 통신부 중 적어도 하나를 제어하기 위한 제어부, 처리된 실시간 렌더링 오브젝트 데이터와 분할 영상데이터를 화면으로 출력 하는 출력부를 포함하여 구성할 수 있다. 통신부는 다른 디스플레이 유닛(클라이언트 #2-#n), 동기화 서버, 예를 들면 스마트폰과 같은 다양한 플랫폼(미도시), 인터넷으로 연결된 사용자 컴퓨터 등과 통신데이터를 송수신할 수 있다. 통신데이터는 동기신호 데이터, 오브젝트 데이터, 영상 데이터, 그래픽 데이터, 및 UX이벤트 데이터 중 적어도 하나를 포함할 수 있다. 통신부는 무선 인터넷 기술로서 WLAN (Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access) 등이 이용될 수 있다. 통신부는 근거리 통신기술로서 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통 신(IrDA, infrared Data Association), UWB(Ultra Wideband), ZigBee 등이 적용될 수 있다. 통신부는 HDMI(high definition multimedia interface), USB, 컴포넌트(component), LVDS 등의 규격에 따 라 송수신할 수 있는 인터페이스가 적용될 수 있다. 마스킹 영상 인코딩부는 저장부에 저장된 분할 영상데이터와 실시간 렌더링 오브젝트 데이터를 중첩 시켜 하나의 분할 화면으로 출력할 수 있도록 처리할 수 있다. 또한, 마스킹 영상 인코딩부는 통신부를 통해 수신한 영상데이터와 실시간 렌더링 오브젝트 데이터를 중첩시켜 하나의 화면으로 출력할 수 있도록 처리할 수 있다. 타이머는 모든 클라이언트(#1-#n)들 및 동기화 서버를 동기화하기 위해 현재 디스플레이 유닛의 시각 정보를 유지 관리할 수 있다. 타이머는 네트워크를 통해 다른 클라이언트 또는 서버와 시각을 주고 교환하 며, 네트워크 통신 중 지연요소 및 클라이언트 상태 지연요소를 측정하고 보상하여 시각을 다른 클라이언트 및 서버와 일치시킬 수 있다. UX이벤트 입력부는 사용자의 명령을 입력하는 터치패널, 마우스, 키보드, 리모컨 등을 포함할 수 있다. UX이벤트 입력부는 또한 와이파이(Wi-Fi), 블루투스 등과 같은 무선통신기술을 이용하여 연결된 스마트폰 과 같은 모바일 장치를 포함할 수도 있다. UX이벤트 처리부는 UX이벤트 입력부에서 입력된 정해지지 않은 일정의 입출력 데이터 처리와 사용자 상호작용 처리를 위한 각종 인터페이스 입출력 데이터 처리를 수행한다. 즉, 사용자의 명령에 따라 UX이벤트를 처리하여 UX이벤트에 따른 오브젝트, 영상, 그래픽 등을 처리할 수 있다. 물론, UX이벤트 처리부는 통신부를 통하여 입력된 UX이벤트를 처리하여 오브젝트, 영상, 그래픽 등을 처리할 수도 있다. 오브젝트 처리부는 저장부에 저장된 또는 통신부를 통해 입력된 오브젝트 데이터를 처리하여 출 력부를 통해 오브젝트가 출력될 수 있도록 한다. 오브젝트 처리부는 UX이벤트 처리부에서 처리된 또는 통신부를 통해 입력된 UX이벤트에 따라 오 브젝트들을 처리할 수 있다. 오브젝트 처리부는 오브젝트 종류에 따라 정적(statics) 오브제트 처리부 및 동적(dynamic) 오브젝트 처리 부를 포함할 수 있다. 인공지능 시뮬레이터는 UX이벤트 처리부에서 처리된 UX이벤트에 따라 오브젝트들의 용도, 크기 및 특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만들어 오브젝트 처리부에 제공할 수 있다. 또한, 인공지능 시뮬레이터는 저장부에 저장되거나 통신부를 통하여 입력된 UX이벤트에 따라 오 브젝트들의 용도, 크기 및 특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만들어 오브젝 트 처리부에 제공할 수 있다. 그래픽 처리부는 UX이벤트 입력부 또는 통신부를 통해 입력되거나, 저장부에 저장된 그래 픽 데이터를 처리하여 출력부에 제공할 수 있다. 영상처리부는 기본적으로 저장부에 저장된 분할 영상데이터에 대해 기 설정된 다양한 영상처리과정을 수행한다. 상기 저장부에 저장된 영상 데이터는 멀티비전에서 처리하는 하나의 전체 화면 중 할당된 일부 에 해당하는 분할 영상 데이터로서 사전에 저장되어 다른 디스플레이 유닛들과 동기화하여 처리될 수 있다. 영상처리부는 이러한 프로세스가 수행된 영상 데이터를 출력부에 출력함으로써, 출력부에 해당 영상신호에 기초하는 영상이 표시되게 한다. 물론 영상처리부는 연결된 디스플레이 유닛, 동기화 서버, 및 다른 플랫폼 디바이스로부터 입력되어 수신된 영상 데이터를 소정 프로세스로 처리할 수 있다. 영상처리부가 수행하는 신호처리의 종류는 한정되지 않는 바, 예를 들면 소정 신호를 각 특성별 신호로 분 배하는 디멀티플렉싱(de-multiplexing), 영상데이터의 영상 포맷에 대응하는 디코딩(decoding), 인터레이스 (interlace) 방식의 영상 데이터를 프로그레시브(progressive) 방식으로 변환하는 디인터레이싱(de- interlacing), 영상 데이터를 기 설정된 해상도로 조정하는 스케일링(scaling), 영상 화질 개선을 위한 노이즈 감소(noise reduction), 디테일 강화(detail enhancement), 프레임 리프레시 레이트(frame refresh rate) 변환 등을 포함할 수 있다. 영상처리부는 상기 프로세스를 수행하기 위한 다양한 칩셋(미도시), 메모리(미도시), 전자부품(미도시), 배선(미도시) 등의 회로 구성이 인쇄회로기판(미도시) 상에 실장된 영상처리보드(미도시)로 구현된다. 저장부는 하나의 전체 화면 중 할당된 일부에 해당하는 분할 영상 데이터, 실시간 렌더링 3D 오브젝트 데 이터, 그래픽 데이터, 디스플레이 유닛을 구동하기 위한 각종 프로그램 등을 저장할 수 있다. 저장부는 한정되지 않은 데이터가 저장된다. 저장부는 플래시메모리(flash-memory), 하드디스크 드 라이브(hard-disc drive)와 같은 비휘발성 메모리로 구현된다. 저장부는 제어부에 의해 액세스되며, 이들에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행된다. 제어부는 CPU로 구성할 수 있고, 디스플레이 유닛의 다양한 구성에 대한 제어동작을 수행한다. 예를 들 면, 제어부는 영상처리부가 처리하는 영상 데이터 처리과정의 진행, 통신부를 통한 신호/정보/ 데이터의 송수신 동작, 저장부에 액세스하여 데이터의 독취/기록/수정/삭제/갱신 작업을 수행, UX이벤트 처리부의 이벤트 처리과정, 오브젝트 처리부(1600의 오브젝트 처리과정, 그래픽 처리부의 그래픽 처 리과정 및 처리된 각종 데이터를 출력부를 통해 출력하는 과정을 제어한다. 도 1에는 편의상 하나의 제어부로 각 구성 요소를 제어하는 것으로 표현하였지만, 각 구성 요소의 효율적 인 제어를 위해 별도의 제어부를 개별적으로 구성할 수 있다. 제어부는 예를 들면 영상처리부를 제어 하는 영상제어부(미도시), 상기 그래픽처리부를 제어하는 그래픽제어부(미도시), 실시간 렌더링 3D 오브젝 트 화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현 방법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나를 제어하는 오브젝트 제어부(미도시), 복수의 디스플레 이 유닛에서 다양한 인터페이스를 통해 입력받은 데이터 값을 다른 각각의 디스플레이 유닛에 동기화시킬 데이터로 만들고 제어하는 UX이벤트 제어부(미도시) 및 외부의 시스템 또는 다른 플랫폼 디바이스와 통신하여 수신한 오브젝트 상태값을 제어하는 통신제어부(미도시) 중 적어도 하나를 포함할 수 있다. 출력부는 상기 영상 처리부로부터 처리되어 수신된 영상 데이터에 기초하여 영상을 표시한다. 출력부 의 구현 방식은 한정되지 않는 바, 액정(liquid crystal), 플라즈마(plasma), 발광 다이오드(light- emitting diode), 유기발광 다이오드(organic light-emitting diode), 면전도 전자총(surface-conduction electron-emitter), 탄소 나노 튜브(carbon nano-tube), 나노 크리스탈(nano-crystal) 등의 다양한 디스플레이 패널로 구현될 수 있다. 출력부는 구현 방식에 따라서 부가적인 구성을 추가적으로 포함할 수 있다. 예를 들면, 출력부는 액 정 방식인 경우, 광을 공급하는 백라이트유닛(미도시)과, 표시패널(미도시)을 구동시키는 패널구동기판(미도 시)을 포함할 수 있다. 도 4에 나타낸 바와 같이 지금까지 설명한 디스플레이 유닛들 다수를 상호 직접 연결하여 본 발명에 따른 실 시간 랜터링 3D 오브젝트 인터렉티브 멀티비전 시스템을 구성할 수 있다. 본 발명의 다른 실시예로서, 도 5에 나타낸 바와 같이 네트워크 허브(#1-#N)를 통하여 다수의 클라이언트(#1- #N+1…)를 서버에 연결할 수 있다. 도 2는 도 5에 나타낸 동기화 서버의 구성을 나타내는 블록도이다. 동기화 서버는 연결된 각 디스플레이 유닛 또는 외부 플랫폼 디바이스(미도시)와 통신데이터를 송수신 하는 서버통신부, 디스플레이 유닛들의 동기화를 위해 서버 시각 정보를 유지 관리하는 서버 타이머 , 디스플레이 유닛들의 동기 정보를 생성하는 서버 동기정보 생성부, 실시간 렌더링 3D 오브젝트 화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현 방 법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나를 제어하는 서버 오브젝트 제어부, 복수의 디스플레 이 유닛에서 다양한 인터페이스를 통해 입력받은 데이터 값을 다른 각각의 디스플레이 유닛에 동기화시킬 데이터로 만들고 제어하는 서버 UX이벤트 제어부, 연결된 각 디스플레이 유닛 또는 외부 플랫폼 디바이스와 통신하여 주고 받은 오브젝트 상태값을 제어하는 서버 통신제어부, 및 오브젝트들의 용도, 크기와 특 징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만드는 서버 오브젝트의 인공지능 시뮬레이 터를 포함하여 구성할 수 있다. 서버 타이머는 모든 클라이언트(#1-#n)들 및 동기화 서버를 동기화하기 위해 현재 동기화 서버의 시 각 정보를 유지 관리할 수 있다. 서버 타이머는 네트워크를 통해 다른 클라이언트(#1-#N)와 시각을 주고 교환하며, 네트워크 통신 중 지연요소 및 동기화 서버의 상태 지연요소를 측정하고 보상하여 시각을 모든 클라이언트와 일치시킬 수 있다. 서버통신부는 모든 디스플레이 유닛(클라이언트 #1-#n), 예를 들면 스마트폰과 같은 다양한 플랫폼(미도시), 인터넷으로 연결된 사용자 컴퓨터 등과 통신데이터를 송수신할 수 있다. 통신데이터는 동기신호 데이터, 오브젝트 데이터, 영상 데이터, 그래픽 데이터, 및 UX이벤트 데이터 중 적어도 하나를 포함할 수 있다. 서버통신부는 HDMI(high definition multimedia interface), USB, 컴포넌트(component), LVDS 등의 규격 에 따라 송수신할 수 있는 인터페이스가 적용될 수 있다. 서버통신부는 무선 인터넷 기술로서 WLAN (Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access) 등이 이용 될 수도 있다. 서버통신부는 근거리 통신기술로서 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(IrDA, infrared Data Association), UWB(Ultra Wideband), ZigBee 등이 적용될 수도 있다. 서버 동기정보 생성부는 모든 클라이언트들(#1-#N)이 동기화하여 동영상 데이터, 그래픽 데이터, 오브젝트 데이터 등을 표현할 수 있도록 동기화 정보를 생성할 수 있다. 동기화 정보는 서버통신부를 통하여 동기신호로서 통신데이터와 함께 각 클라이언트로 송수신될 수 있다. 서버 UX이벤트 제어부는 외부의 플랫폼 디바이스 또는 각 클라이어언트(#1-#N)의 인터페이스 장치 (A,B,C,D,E…)를 통하여 입력된 데이터를 각 클라이언트에 동기화시킬 데이터로 만들고 제어할 수 있다. 서버 오브젝트 제어부는 실시간 렌더링 3D 오브젝트 화면을 구성하는 오브젝트들의 생성, 삭제, 위치, 이 동, 오브젝트간 간섭, 시작 시각, 지속 시간, 영상 표현 방법, 재생 속도, 및 프레임 넘버 정보 중 적어도 하나 를 제어할 수 있다. 서버 통신제어부는 서버통신부를 제어하여 연결된 각 디스플레이 유닛 또는 외부 플랫폼 디바이스 와 통신하여 주고 받은 오브젝트 상태값을 제어할 수 있다. 서버 인공지능 시뮬레이터는 서버 UX이벤트 제어부에서 제공된 UX이벤트에 따라 오브젝트들의 용도, 크기 및 특징에 따라 상태값을 시뮬레이션하여 정형화되지 않은 연속 상태값을 만들어 오브젝트 제어부에 제공할 수 있다. 이하 동기 서버와 디스플레이 유닛(클라이언트) 사이의 데이터 흐름을 도 3을 참조하여 설명하면 다음 과 같다. 디스플레이 유닛과 동기 서버는 서버 연결신호를 주고 받아 서로 연결될 수 있다. 이때, 연결된 디스플 레이 유닛과 동기 서버는 밀리초(ms)당 오브젝트 동기화 정보를 주고 받는다. 연결된 디스플레이 유닛과 동기 서버는 영상 동기 정보, 영상 준비 상태 정보, 및 영상 재생신호, 프레 임 정보를 순차적으로 주고받는다. 이후, 연결된 디스플레이 유닛과 동기 서버는 외부의 플랫폼 디바이스 또는 각 디스플레이 유닛의 인터 페이스 장치에서 입력된 UX이벤트 입력데이터와 UX이벤트 동기화 정보를 송수신할 수 있다. 마지막으로 연결된 디스플레이 유닛과 동기 서버는 통신 동기화 정보 및 통신 준비상태 정보를 주고 받 은 후, 통신 데이터를 출력 시작 명령, 통신 상태 정보를 주고 받는다. 이와 같이 동기 서버는 연결된 모든 디스플레이 유닛과 실시간으로 3D 오브젝트를 동기화하여 처리하여 모든 디스플레이 유닛들이 전체적으로 일체화된 화면을 표현할 수 있을 뿐만 아니라 다양한 사용자 이벤트를 실시간으로 반영하여 표현할 수 있다. 이하 본 발명의 실시예에 따른 멀티비전 시스템의 실시간 렌더링 3D 오브젝트 처리방법을 도 6 및 도 7을 참조 하여 설명하면 다음과 같다. 도 6은 모든 디스플레이 유닛이 각각 저장부에 저장된 데이터를 기준으로 동기화하여 표시하면서, 각 디스플레이 유닛의 UX이벤트 입력부를 통하여 UX이벤트가 입력되었을 때의 실시간 렌더링 3D 오브젝트 처 리방법을 나타낸 것이다. 먼저, 각 디스플레이 유닛들의 저장부에는 영상 데이터(오브젝트 포함)가 할당되어 저장된다(S410). 각 디스플레이 유닛은 저장부에 저장된 할당 영상 데이터(오브젝트 포함)를 표시한다(S411). 이후, 각 디스플레이 유닛의 UX이벤트 입력부로부터 UX이벤트가 입력되었는지를 판단한다(S412). 만일 UX이벤트가 입력되지 않았으면 저장부에 저장된 일정으로 사전 할당된 영상 데이터(오브젝트 포함)를 표시 한다. 만일 만일 UX이벤트가 입력되었으면, 입력된 UX이벤트가 다른 디스플레이 유닛들과 관계되었는지를 판단 한다(S413). 만일, 입력된 UX이벤트가 다른 디스플레이 유닛들과 관계되지 않았으면, 입력된 UX이벤트를 자신에게만 반영하 여 영상 데이터(오브젝트 포함)를 동기화하여 표시한다. 만일 입력된 UX이벤트가 다른 디스플레이 유닛들과 관계되어 있으면, UX이벤트를 관계된 디스플레이 유닛 또는 동기 서버에 전송한다(S414). 이후 입력 또는 수신된 UX이벤트를 반영하여 각 디스플레이 유닛은 영상 데이터(오브젝트 포함)를 동기화하 여 표시한다(S415). 도 7은 디스플레이 유닛이 각각 저장부에 저장된 데이터를 기준으로 동기화하여 표시하면서, 외부 플랫 폼 디바이스 또는 다른 디스플레이 유닛을 통하여 UX이벤트가 입력되었을 때의 실시간 렌더링 3D 오브젝트 처리 방법을 나타낸 것이다. 먼저, 각 디스플레이 유닛들의 저장부에는 영상 데이터(오브젝트 포함)가 할당되어 저장된다(S510). 각 디스플레이 유닛은 저장부에 저장된 할당 영상 데이터(오브젝트 포함)를 표시한다(S511). 이후, 외부 플랫폼 디바이스 또는 다른 디스플레이 유닛으로부터 UX이벤트가 입력되었는지를 판단한다(S512). 만일 UX이벤트가 입력되지 않았으면 저장부에 저장된 일정으로 사전 할당된 영상 데이터(오브젝트 포함)를 표시한다. 만일 만일 UX이벤트가 입력되었으면, 입력 또는 수신된 UX이벤트를 반영하여 각 디스플레이 유닛 은 영상 데이터(오브젝트 포함)를 동기화하여 표시한다(S512). 외부 플랫폼 디바이스 또는 다른 디스플레이 유닛으로부터 입력되는 통신데이터는 동기화 정보 데이터, 영상데 이터, 실시간 렌더링 오브젝트 데이터, 및 UX이벤트 데이터 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2013-0000362", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "지금까지 본 발명의 실시예가 도시되고 설명되었지만, 본 발명이 속하는 기술분야의 통상의 지식을 가진 당업자 라면 본 발명의 원칙이나 정신에서 벗어나지 않으면서 실시예를 변형할 수 있을 것이다. 따라서, 발명의 범위는 지금까지 설명된 실시예로 정해지는 것이 아니라 첨부된 청구항과 그 균등물에 의해 정해질 것이다."}
{"patent_id": "10-2013-0000362", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 멀티비전용 디스플레이 유닛의 구성을 나타내는 블록도, 도 2는 본 발명에 따른 동기화 서버의 구성을 나타내는 블록도, 도 3은 본 발명의 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템에서 복수의 디스플레이 유닛과 동기 화 서버 간의 데이터 흐름을 나타내는 흐름도, 도 4는 본 발명의 일실시예에 따른 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템의 구성을 나타내는 블록도, 도 5는 본 발명의 다른 실시예에 따른 실시간 렌더링 3D 오브젝트 인터렉티브 멀티비전 시스템의 구성을 나타내 는 블록도, 및 도 6 및 도 7은 본 발명의 실시예에 따른 멀티비전 시스템의 실시간 렌더링 3D 오브젝트 처리방법을 나타내는 순서도이다."}
