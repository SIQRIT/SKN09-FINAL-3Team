{"patent_id": "10-2022-0165879", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0082014", "출원번호": "10-2022-0165879", "발명의 명칭": "안무 영상을 생성하는 장치, 방법 및 컴퓨터 프로그램", "출원인": "주식회사 케이티", "발명자": "임호성"}}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "안무 영상을 생성하는 장치에 있어서,음원 데이터 및 캐릭터의 템플릿 정보를 입력받는 입력부;상기 음원 데이터에 대한 음악적 특징값을 추출하는 추출부;상기 추출된 음악적 특징값에 기초하여 상기 음원 데이터로부터 대표 구간을 선정하는 대표 구간 선정부;기학습된 모델에 기초하여 상기 추출된 음악적 특징값 및 상기 선정된 대표 구간으로부터 자세 정보 시퀀스를도출하는 자세 정보 시퀀스 도출부; 및상기 캐릭터의 템플릿 정보 및 상기 자세 정보 시퀀스에 기초하여 상기 캐릭터에 대한 안무 영상을 생성하는 안무 영상 생성부를 포함하는 것인, 안무 영상 생성 장치."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 입력부는 장르 정보를 더 입력받고,상기 자세 정보 시퀀스 도출부는 상기 기학습된 모델에 기초하여 상기 추출된 음악적 특징값, 상기 선정된 대표구간 및 상기 장르 정보로부터 상기 자세 정보 시퀀스를 도출하는 것인, 안무 영상 생성 장치."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 음악적 특징값은 MFCC(Mel-Frequency Cepstral Coefficient), 음계(Chroma) 정보 및 템포(Tempo) 정보 중적어도 하나인 것인, 안무 영상 생성 장치."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 대표 구간 선정부는,상기 음원 데이터 중 반복되는 음악적 특징값이 나타나는 구간을 상기 음원 데이터의 대표 구간으로 선정하는것인, 안무 영상 생성 장치."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,안무 영상 데이터를 수집하는 데이터 수집부;상기 안무 영상 데이터로부터 자세 정보를 추출하는 자세 정보 추출부; 및상기 안무 영상 데이터에 대한 음악적 특징값, 상기 자세 정보, 장르 정보 및 상기 안무 영상에 대한 대표 구간공개특허 10-2024-0082014-3-중 적어도 하나에 기초하여 상기 모델을 학습시키는 학습부를 더 포함하는 것인, 안무 영상 생성 장치."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 학습부는,상기 안무 영상 데이터 내의 안무 패턴에 대한 손실함수, 상기 안무 영상 데이터 내에서 인접하는 안무 간의 움직임 패턴에 대한 손실함수 및 상기 안무 영상 데이터 내의 반복 안무 패턴에 대한 손실함수 중 적어도 하나에기초하여 상기 자세 정보 시퀀스를 생성하도록 상기 모델을 학습시키는 것인, 안무 영상 생성 장치."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "안무 영상을 생성하는 방법에 있어서,음원 데이터 및 캐릭터의 템플릿 정보를 입력받는 단계;상기 음원 데이터에 대한 음악적 특징값을 추출하는 단계;상기 추출된 음악적 특징값에 기초하여 상기 음원 데이터로부터 대표 구간을 선정하는 단계;기학습된 모델에 기초하여 상기 추출된 음악적 특징값, 상기 선정된 대표 구간으로부터 자세 정보 시퀀스를 도출하는 단계; 및상기 캐릭터의 템플릿 정보 및 상기 자세 정보 시퀀스에 기초하여 상기 캐릭터에 대한 안무 영상을 생성하는 단계를 포함하는 것인, 안무 영상 생성 방법."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 음원 데이터 및 캐릭터의 템플릿 정보를 입력받는 단계는,장르 정보을 더 입력받고,상기 자세 정보 시퀀스를 도출하는 단계는,상기 기학습된 모델에 기초하여 상기 추출된 음악적 특징값, 상기 선정된 대표 구간 및 상기 장르 정보로부터상기 자세 정보 시퀀스를 도출하는 것인, 안무 영상 생성 방법."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서,상기 음악적 특징값은 MFCC(Mel-Frequency Cepstral Coefficient), 음계(Chroma) 정보 및 템포(Tempo) 정보 중적어도 하나인 것인, 안무 영상 생성 방법."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7 항에 있어서,공개특허 10-2024-0082014-4-상기 대표 구간을 선정하는 단계는,상기 음원 데이터 중 반복되는 음악적 특징값이 나타나는 구간을 상기 음원 데이터의 대표 구간으로 선정하는것인, 안무 영상 생성 방법."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 7 항에 있어서,안무 영상 데이터를 수집하는 단계;상기 안무 영상 데이터로부터 자세 정보를 추출하는 단계; 및상기 안무 영상 데이터에 대한 음악적 특징값, 상기 자세 정보, 장르 정보 및 상기 안무 영상에 대한 대표 구간중 적어도 하나에 기초하여 상기 모델을 학습시키는 단계를 더 포함하는 것인, 안무 영상 생성 방법."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 모델을 학습시키는 단계는,상기 안무 영상 데이터 내의 안무 패턴에 대한 손실함수, 상기 안무 영상 데이터 내에서 인접하는 안무 간의 움직임 패턴에 대한 손실함수 및 상기 안무 영상 데이터 내의 반복 안무 패턴에 대한 손실함수 중 적어도 하나에기초하여 상기 자세 정보 시퀀스를 생성하도록 상기 모델을 학습시키는 것인, 안무 영상 생성 방법."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "안무 영상을 생성하는 명령어들의 시퀀스를 포함하는 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램에 있어서,상기 컴퓨터 프로그램은 컴퓨팅 장치에 의해 실행될 경우,음원 데이터 및 캐릭터의 템플릿 정보를 입력받고,상기 음원 데이터에 대한 음악적 특징값을 추출하고,상기 추출된 음악적 특징값에 기초하여 상기 음원 데이터로부터 대표 구간을 선정하고,기학습된 모델에 기초하여 상기 추출된 음악적 특징값 및 상기 선정된 대표 구간으로부터 자세 정보 시퀀스를도출하고,상기 캐릭터의 템플릿 정보 및 상기 자세 정보 시퀀스에 기초하여 상기 캐릭터에 대한 안무 영상을 생성하도록하는 명령어들의 시퀀스를 포함하는, 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 음원 데이터 및 캐릭터의 템플릿 정보를 입력받는 것은,장르 정보을 더 입력받고,상기 자세 정보 시퀀스를 도출하는 것은,상기 기학습된 모델에 기초하여 상기 추출된 음악적 특징값, 상기 선정된 대표 구간 및 상기 장르 정보로부터공개특허 10-2024-0082014-5-상기 자세 정보 시퀀스를 도출하는 것인, 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 13 항에 있어서,상기 음악적 특징값은 MFCC(Mel-Frequency Cepstral Coefficient), 음계(Chroma) 정보 및 템포(Tempo) 정보 중적어도 하나인 것인, 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 13 항에 있어서,상기 대표 구간을 선정하는 것은,상기 음원 데이터 중 반복되는 음악적 특징값이 나타나는 구간을 상기 음원 데이터의 대표 구간으로 선정하는것인, 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 13 항에 있어서,안무 영상 데이터를 수집하고,상기 안무 영상 데이터로부터 자세 정보를 추출하고,상기 안무 영상 데이터에 대한 음악적 특징값, 상기 자세 정보, 장르 정보 및 상기 안무 영상에 대한 대표 구간중 적어도 하나에 기초하여 상기 모델을 학습시키는 것을 더 포함하는 것인, 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0165879", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 모델을 학습시키는 것은,상기 안무 영상 데이터 내의 안무 패턴에 대한 손실함수, 상기 안무 영상 데이터 내에서 인접하는 안무 간의 움직임 패턴에 대한 손실함수 및 상기 안무 영상 데이터 내의 반복 안무 패턴에 대한 손실함수 중 적어도 하나에기초하여 상기 자세 정보 시퀀스를 생성하도록 상기 모델을 학습시키는 것인, 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "안무 영상 생성 장치는 음원 데이터 및 캐릭터의 템플릿 정보를 입력받는 입력부, 상기 음원 데이터에 대한 음악 적 특징값을 추출하는 추출부, 상기 추출된 음악적 특징값에 기초하여 상기 음원 데이터로부터 대표 구간을 선정 하는 대표 구간 선정부, 기학습된 모델에 기초하여 상기 추출된 음악적 특징값 및 상기 선정된 대표 구간으로부 터 자세 정보 시퀀스를 도출하는 자세 정보 시퀀스 도출부, 및 상기 캐릭터의 템플릿 정보 및 상기 자세 정보 시 퀀스에 기초하여 상기 캐릭터에 대한 안무 영상을 생성하는 안무 영상 생성부를 포함한다."}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 안무 영상을 생성하는 장치, 방법 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 SNS를 잇는 차세대 플랫폼으로 메타버스가 주목 받고 있다. 메타버스는 가상과 초월을 의미하는 '메타 (meta)'와 세계ㆍ우주를 뜻하는 '유니버스(universe)'의 합성어로서, 1992년 SF소설 '스노우 크래쉬'에 처음 등 장했다. 현재는 물리적 실재(현실 세계)와 가상의 공간이 실감형 기술로 결합한 3차원 세계를 뜻하는 용어로 쓰 이며, 개인, 창작자 그리고 기업 등 다양한 주체들이 가상 세계에서 서로 상호작용하며, 경제활동을 통해 자체적인 산업 생태계가 만들어지고 있다. 이에 따라, 가상의 사이버 공간에서 자신을 표현할 수단이 필요하게 되었으며, 이러한 필요성에 따라 등장한 것이 바로 아바타이다. 이와 더불어, 컴퓨터 하드웨어와 그래픽 엔진이 발전함에 따라 작금의 아바타는 실제와 같은 움직임 표현을 극대화할 수 있도록 3차원 형태의 캐릭터(이하, 3D 캐릭터)로 제작이 되고 있다. 특히, 엔 터테인먼트 산업 분야에 있어 이러한 3D 캐릭터의 활용은 가상공간에 소속 연예인을 닮은 캐릭터를 배치하여 온 라인으로 진행할 수 있는 팬 사인회, 공연 등의 다양한 이벤트 개최를 가능케 하였다. 그러나, 종래의 3D 캐릭터의 애니메이션 제어를 통한 콘텐츠 제작 방식은 사용자의 많은 시간적, 재정적 투자를 요구하는 방식으로 일반 사용자가 쉽게 접근하기 어려운 방식이다. 뿐만 아니라, 기존의 방식은 만화처럼, 정형 화된 3D 캐릭터의 움직임을 매 프레임마다 일일이 수작업으로 저장해 놓았다가, 적당한 시점에 불러와서 표현하 는 것이 일반적이지만, 기 정립된 항목 중에서 특정된 하나를 선택하는 방식을 취하고 있어서, 음악적 요소와 춤 스타일 등 여러 측면을 동시에 고려한 자연스럽고 독창적인 안무를 표현하기에는 힘들다는 문제점이 있다. 또한, 전술한 문제를 해결하기 위한 하나의 방안으로서 상기 서술한 모션캡처 방식을 고려할 수 있는데, 이와 같은 경우 별도의 고가 촬영장비가 필요하며, 매 프레임에 해당하는 각 관절 및 포인트를 3D 캐릭터에 정합하는 과정에서 매우 높은 음악적, 예술적, 프로그래밍적 전문성이 요구된다. 따라서, 전문적인 장비와 기술이 부족한 일반인들에게는 3D 캐릭터 애니메이션을 통한 뮤직비디오를 제작하기엔 많은 난관이 존재하며, 적극적인 콘텐츠 제작 참여를 유도하기 어렵다는 문제가 존재한다."}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "안무 영상을 생성하는 장치, 방법 및 컴퓨터 프로그램을 제공하고자 한다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 수단으로서, 본 발명의 일 실시예는, 음원 데이터 및 캐릭터의 템플릿 정 보를 입력받는 입력부, 상기 음원 데이터에 대한 음악적 특징값을 추출하는 추출부, 상기 추출된 음악적 특징값 에 기초하여 상기 음원 데이터로부터 대표 구간을 선정하는 대표 구간 선정부, 기학습된 모델에 기초하여 상기 추출된 음악적 특징값, 상기 선정된 대표 구간으로부터 자세 정보 시퀀스를 도출하는 자세 정보 시퀀스 도출부, 및 상기 캐릭터의 템플릿 정보 및 상기 자세 정보 시퀀스에 기초하여 상기 캐릭터에 대한 안무 영상을 생성하는 안무 영상 생성부를 포함하는 것인 안무 영상 생성 장치를 제공할 수 있다. 본 발명의 다른 실시예는, 음원 데이터 및 캐릭터의 템플릿 정보를 입력받는 단계, 상기 음원 데이터에 대한 음 악적 특징값을 추출하는 단계, 상기 추출된 음악적 특징값에 기초하여 상기 음원 데이터로부터 대표 구간을 선 정하는 단계, 기학습된 모델에 기초하여 상기 추출된 음악적 특징값, 상기 선정된 대표 구간으로부터 자세 정보 시퀀스를 도출하는 단계, 및 상기 캐릭터의 템플릿 정보 및 상기 자세 정보 시퀀스에 기초하여 상기 캐릭터에 대한 안무 영상을 생성하는 단계를 포함하는 것인 안무 영상 생성 방법을 제공할 수 있다. 본 발명의 또 다른 실시예는, 컴퓨터 프로그램은 컴퓨팅 장치에 의해 실행될 경우, 음원 데이터 및 캐릭터의 템 플릿 정보를 입력받고, 상기 음원 데이터에 대한 음악적 특징값을 추출하고, 상기 추출된 음악적 특징값에 기초 하여 상기 음원 데이터로부터 대표 구간을 선정하고, 기학습된 모델에 기초하여 상기 추출된 음악적 특징값, 상 기 선정된 대표 구간으로부터 자세 정보 시퀀스를 도출하고, 상기 캐릭터의 템플릿 정보 및 상기 자세 정보 시 퀀스에 기초하여 상기 캐릭터에 대한 안무 영상을 생성하도록 하는 명령어들의 시퀀스를 포함하는, 컴퓨터 판독 가능 기록매체에 저장된 컴퓨터 프로그램을 제공할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본 발명을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 기재된 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 개인화되어가는 생산과 소비 문화가 확산됨에 따라, 메타버스 내 아바타를 중심으로 3D 캐릭터 기반의 뮤직비디오 컨텐츠를 개인이 쉽게 생산할 수 있다. 또한, 음악과 춤 동작의 상호 밀접한 연관성을 토대로 인공지능 기법을 활용하여, 음악이 어울리고, 보다 움직 임이 자연스럽고, 포인트 안무를 포함한 애니메이션을 생성할 수 있다."}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미하며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 본 명세서에 있어서 단말 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말 또는 디 바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기술된 동작이나 기능 중 일부도 해당 서버와 연결된 단말 또는 디바이스에서 수행될 수도 있다. 이하 첨부된 도면을 참고하여 본 발명의 일 실시예를 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 안무 영상 생성 시스템을 개략적으로 나타내는 도면이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 안무 영상 생성 시스템은 사용자 단말 및 안무 영상 생 성 장치를 포함할 수 있다. 도 1에 도시된 사용자 단말 및 안무 영상 생성 장치는 안무 영상 생 성 시스템에 의하여 제어될 수 있는 구성요소들을 예시적으로 도시한 것이다. 도 1의 안무 영상 생성 시스템의 각 구성요소들은 일반적으로 네트워크를 통해 연결될 수 있다. 예를 들어, 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷 (WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 블루투스 통신, 적외선 통신, 초음파 통신, 가시 광 통신(VLC: Visible Light Communication), 라이파이(LiFi) 등이 포함되나 이에 한정되지는 않는다. 사용자 단말은 PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W- Code Division Multiple Access), Wibro(Wireless Broadband Internet), 3G, 4G, 5G 단말, 스마트폰(smart phone)과 같은 무선 통신 장치 및 스마트 패드와 같은 태블릿 PC 등을 포함할 수 있다. 또한, 사용자 단말(10 0)은 데스크톱(desktop), 노트북(notebook), 넷북(Netbook), 울트라북(UltraBook), 서브노트북(SubNotebook), 데스크노트(DeskNote), UMPC(Ultra-Mobile PC) 등과 같은 모든 종류의 PC를 포함할 수 있다. 안무 영상 생성 장치는 안무 영상을 생성하는 장치일 수 있다. 안무 영상 생성 장치는 사용자 단말로부터 음원 데이터 및 캐릭터의 템플릿 정보를 입력받을 수 있다. 안무 영상 생성 장치는 음원 데이터에 대한 음악적 특징값을 추출할 수 있다. 안무 영상 생성 장치는 추출된 음악적 특징값에 기초하여 음원 데이터로부터 대표 구간을 선정할 수 있다. 안무 영상 생성 장치는 기학습된 모델에 기초하여 추출된 음악적 특징값, 선정된 대표 구간으로부터 자세 정보 시퀀스를 도출할 수 있다. 안무 영상 생성 장치는 캐릭터의 템플릿 정보 및 자세 정보 시퀀스에 기초하여 캐릭터에 대한 안무 영상을 생성할 수 있다. 안무 영상 생성 장치는 생성된 안무 영상을 사용자 단말로 전송할 수 있다. 본 발명의 일 실시예에 따른 안무 영상 생성 시스템에 따르면, 개인화되어가는 생산과 소비 문화가 확산됨에 따라, 메타버스 내 아바타를 중심으로 3D 캐릭터 기반의 뮤직비디오 컨텐츠를 개인이 쉽게 생산할 수 있다. 또한, 종래의 3D 캐릭터 애니메이션 제작 방식의 경우, 애니메이터의 역량에 크게 의존하고 있으며, 고가의 촬 영 장비나 촬영 공간 확보 등에 많은 시간과 비용이 소요된다는 단점이 있는 반면, 본 발명의 일 실시예에 따르 면 별다른 장비나 제작자의 큰 개입 없이도 그 과정과 비용을 간소화할 수 있다. 도 2는 본 발명의 일 실시예에 따른 안무 영상 생성 장치의 구성도이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 안무 영상 생성 장치는 입력부, 추출부, 대표 구 간 선정부, 자세 정보 시퀀스 도출부, 안무 영상 생성부, 데이터 수집부, 자세 정보 추출 부 및 학습부를 포함할 수 있다. 다만, 도 2에 도시된 안무 영상 생성 장치는 본 발명의 하나의 구현 예에 불과하며, 도 2에 도시된 구성요소들을 기초로 하여 여러 가지 변형이 가능하다. 이하에서는 도 3 내지 도 6을 함께 참조하여 도 2를 설명하기로 한다. 입력부는 음원 데이터 및 캐릭터의 템플릿 정보를 입력받을 수 있다. 여기서 음원 데이터는 음악에 해당하는 오디오 신호(Audio Signal)을 포함할 수 있다. 또한, 캐릭터의 템플릿 정보는 안무 애니메이션의 적용 대상이 되는 3D 캐릭터 템플릿에 대한 정보를 포함할 수 있으며, 3D 캐릭터 템 플릿은 메쉬(Mesh), 본(Bone), 그리고 텍스처(Texture)로 이루어져 있으며, 메쉬는 모양 및 형태를 나타내는 3D 모델의 기하학적인 정보이고, 본을 내부에 추가함으로써 본의 움직임에 따른 3D 캐릭터의 전체 움직임을 제어할 수 있다. 추출부는 음원 데이터에 대한 음악적 특징값을 추출할 수 있다. 여기서, 음악적 특징값은 MFCC(Mel- Frequency Cepstral Coefficient), 음계(Chroma) 정보 및 템포(Tempo) 정보 중 적어도 하나일 수 있다. 대표 구간 선정부는 추출된 음악적 특징값에 기초하여 음원 데이터로부터 대표 구간을 선정할 수 있다. 구 체적으로, 대표 구간 선정부는 음원 데이터 중 반복되는 음악적 특징값이 나타나는 구간을 음원 데이터의 대표 구간으로 선정할 수 있다. 자세 정보 시퀀스 도출부는 기학습된 모델에 기초하여 추출된 음악적 특징값 및 선정된 대표 구간으로부터 자세 정보 시퀀스를 도출할 수 있다. 예를 들면, 자세 정보 시퀀스 도출부는 기학습된 모델에 추출된 음악적 특징값 및 선정된 대표 구간에 대 한 값을 입력하여 초당 60 프레임 단위의 자세 정보 시퀀스를 도출할 수 있다. 여기서, 자세 정보 시퀀스는 음 원의 각 프레임 별로 추정된 3차원 형태의 포즈 랜드마크의 위치정보 값일 수 있다. 일 실시예에서, 입력부는 장르 정보을 더 입력받고, 자세 정보 시퀀스 도출부는 기학습된 모델에 기 초하여 추출된 음악적 특징값, 선정된 대표 구간 및 장르 정보로부터 자세 정보 시퀀스를 도출할 수 있다. 여기서, 자세 정보 시퀀스 도출부는 매 프레임에 해당하는 음악적 특징값과 장르 정보를 결합한 벡터 값, 및 대표 구간을 추출하여 반환할 수 있다. 예를 들면, 자세 정보 시퀀스 도출부는 음원의 길이가 T초인 경 우, 초 당 60프레임을 기준으로 윈도우 사이즈 W, 음악적 특징값 D, 춤 장르의 원-핫 벡터 값 8개로 이루어진 60TХWХ(D+8) 차원의 배열과 후렴 구간 즉, 대표 구간에 해당하는 프레임 인덱스 배열을 반환할 수 있다. 안무 영상 생성부는 캐릭터의 템플릿 정보 및 자세 정보 시퀀스에 기초하여 캐릭터에 대한 안무 영상을 생 성할 수 있다. 예를 들면, 안무 영상 생성부는 자세 정보 시퀀스에 기초하여 대상 3D 캐릭터 템플릿에 포함된 본의 관절 부분에 대응시켜, 매 프레임에 해당하는 관절의 위치 변화에 따른 본의 움직임으로 3D 캐릭터의 안무 동작을 표 현할 수 있다. 도 3은 본 발명의 일 실시예에 따라 안무 영상을 생성하는 방법을 개략적으로 설명하기 위한 도면이다. 도 3의 (a)는 음원 데이터로부터 추출된 프레임별 음악적 특징값을 시간순으로 나열한 것을 도시하는 것이고, 대표 구간 선정부는 이러한 음악적 특징값에 기초하여 대표 구간(301, 302)을 선정할 수 있다. 또한, 도 3의 (b)는 기학습된 모델에 기초하여 추출된 음악적 특징값 및 선정된 대표 구간으로부터 도출된 자세 정보 시퀀스들을 시간순으로 나타낸 것이고, 도 3의 (b)에 도시된 바와 같이, 선정된 대표 구간(303, 304)이 포 함되어 자세 정보 시퀀스가 도출될 수 있다. 도 3의 (c)는 캐릭터의 템플릿 정보 및 자세 정보 시퀀스에 기초하여 생성된 캐릭터에 대한 안무 영상을 나타내는 것으로, 도 3의 (c)에 도시된 바와 같이, 선정된 대표 구간(306, 307)에 포인트 안무가 포함되어 안무 영상이 생성될 수 있다. 이하에서는 음악적 특징값 및 대표 구간으로부터 자세 정보 시퀀스를 도출하는 모델을 학습하는 방법에 대하여 설명하도록 한다. 데이터 수집부는 안무 영상 데이터를 수집할 수 있다. 예를 들면, 데이터 수집부는 온라인 상에 존재 하는 안무 영상 데이터를 수집할 수 있다. 추출부는 안무 영상 데이터에 대한 음악적 특징값을 추출할 수 있다. 구체적으로, 추출부는 안무 영 상 데이터로부터 음원 데이터를 분리하고, 분리된 음원 데이터에 대한 음악적 특징값을 추출할 수 있다. 여기서, 추출부는 음원 데이터에 대한 음악적 특징값을 음원 벡터로 임베딩할 수 있다. 음악적 특징값은 MFCC(Mel-Frequency Cepstral Coefficient), 음계(Chroma) 정보 및 템포(Tempo) 정보 중 적어 도 하나일 수 있다. 예를 들면, 음악적 특징값은 39차원의 MFCC 벡터, 12차원의 음계 벡터, 그리고 템포 스칼라 를 모두 이어서 하나의 곡을 D=42차원의 벡터값으로 임베딩될 수 있다. 또한, 추출부는 음악적 특징값을 추출하는 주기는 자연스럽고 매끄러운 안무 동작을 표현하기에 적합한 매 초당 60프레임을 추출할 수 있으며, 이보다 낮은 경우 선형 보간을 통해 예측된 값을 사용할 수 있다. 예를 들 어, 입력받은 음원 데이터의 길이가 T초인 경우, 60T에 해당하는 프레임이 생성되며, D개의 음악적 특징값을 활 용한다고 했을 때, 60TХD 차원의 배열값으로 변환될 수 있다. 추가적으로, 추출부는 음악적 특징값에 시간적 요소를 포함시키기 위하여, 특정 사이즈 W를 갖는 윈도우를 1-Step 간격으로 오버래핑 슬라이딩하여 60TХWХD 차원의 배열값으로 변환할 수 있다. 일 실시예에서, 데이터 수집부는 해당 안무 영상 데이터에 대한 장르 정보를 더 수집할 수 있다. 이러한 장르 정보는 동일한 음악에 대해에서도 춤 스타일에 따라 안무 동작이 달라질 수 있기 때문에, 이를 일반화할 수 있는 추가 정보로서 활용될 수 있다. 예를 들면, 장르 정보는 디스코, 스트릿, 아크로밧, 재즈, 스윙, 무용, 발레, 왈츠을 포함할 수 있으며, 학습부 는 해당 정보를 벡터화하기 위해 다음의 [수학식 1]의 원-핫 인코딩(One-Hot Encoding)을 적용할 수 있다.수학식 1"}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상술한 음악적 특징값과 장르에 대한 원-핫 벡터를 결합하여, 차원의 배열이 학습부 의 입력 계층에 해당하는 입력값으로 사용할 수 있다. 또한, 대표 구간 선정부는 전체 안무 중 불연속적이지만 반복적으로 나타나는 포인트 안무를 포함하도록 인공신경망을 구성하기 위하여, 음원 데이터 중 반복되는 음악적 특징값이 나타나는 구간을 탐색하고, 이를 음 원 데이터의 대표 구간으로 선정할 수 있다. 예를 들면, 일반적으로 대중 음악의 각 부분들은 소악절로 이루어져있고, 이러한 소악절들 사이에는 반복적인 멜로디를 담고 있는 특징이 있다. 도 4는 대중 음악에서 흔히 사용하는 곡 형식의 일 예를 도시화하여 나타낸다. 도 4를 참조하면, 대다수 음악들의 주요 내용이 곡 전체 중 중앙 부분에 위치하는 경향이 있으며, 1절 과 2절로 이분화된 대중 음악의 특성상, 음악의 중앙 부분을 기준으로 유사 반복되는 음악적 특 징값이 나타나는 구간을 포인트 안무가 반영되는 후렴 부분(402, 405) 즉 대표 구간으로 보고, 학습부의 입력 계층에 이를 추가하여 학습에 이용할 수 있다. 자세 정보 추출부는 안무 영상 데이터로부터 자세 정보를 추출할 수 있다. 여기서, 자세 정보는 수집된 안 무 영상 데이터로부터 추출한 포즈 랜드마크(Pose Landmark)에 해당하는 3차원 형태의 위치 정보일 수 있다. 도 5는 본 발명의 일 실시예에 따른 자세 정보에 포함된 포즈 랜드마크 항목을 나타내는 도면이다. 도 5를 참조하면, 포즈 랜드마크는 얼굴과 더불어 인간의 골격 구조에 맞춰 코, 왼쪽 눈 안쪽, 왼쪽 눈 , 왼쪽 눈 바깥쪽, 오른쪽 눈 안쪽, 오른쪽 눈, 오른쪽 눈 바깥쪽, 왼쪽 귀, 오른쪽 귀, 왼쪽 입, 오른쪽 입, 왼쪽 어깨, 오른쪽 어깨, 왼쪽 팔꿈치, 오른쪽 팔꿈치, 왼쪽 손목 , 오른쪽 손목, 왼쪽 새끼손가락, 오른쪽 새끼손가락, 왼쪽 검지, 오른쪽 검지, 왼쪽 엄지, 오른쪽 엄지, 왼쪽 골반, 오른쪽 골반, 왼쪽 무릎, 오른쪽 무릎, 왼쪽 발목 , 오른쪽 발목, 왼쪽 뒤꿈치, 오른쪽 뒤꿈치, 왼쪽 발끝, 오른쪽 발끝 총 N=33개의 항목을 기준으로 구성되며, 이들의 위치에 따라서 안무 자세가 나타날 수 있다. 도 6은 사전 학습된 포즈 검출 모델(Pose Detect Model)을 이용하여 안무 영상 데이터로부터 추출된 자세 정보 의 한 예를 도시화한 도면이다. 도 6의 (a)는 안무 영상 데이터 중 한 프레임의 예시이고, 도 6의 (b)는 도 6의 (a)의 안무 영상 데이터로부터 추출된 자세 정보에 대한 그래프이다. 도 6의 (b)를 참조하면, 자세 정보는 안무 자세에 따른 포즈 랜드마크 별 위치 정보로 x, y, z의 3차원 좌표값 으로 표현될 수 있으며, 학습 과정에서 학습부의 출력 계층으로부터 도출된 결과값의 비교군인 실제값으로 서 활용될 수 있다. 학습부는 안무 영상 데이터에 대한 음악적 특징값, 자세 정보, 장르 정보 및 안무 영상에 대한 대표 구간 중 적어도 하나에 기초하여 모델을 학습시킬 수 있다. 구체적으로, 학습부는 학습을 통해 최적의 인공신경망을 찾는 작업을 수행할 수 있다. 이러한 인공신경망 에는 입력 계층, 은닉 계층, 출력 계층을 포함하고 있으며, 주어진 학습 데이터를 바탕으로 손실함수의 결과값 이 최소화 되도록 가중치와 편향을 갱신하는 과정을 포함할 수 있다. 학습부의 학습 데이터는 안무 영상 데이터에 대한 음악적 특징값, 자세 정보, 장르 정보 및 안무 영상에 대한 대표 구간을 이용할 수 있다. 즉, 학습 데이터는 매 프레임에 해당하는 음악적 특징값 및 장르 정보를 결합한 벡터 값과 자세 정보의 대응 쌍 으로 구성되어 있으며, 이하, [수학식 2]로 표현될 수 있다. 수학식 2"}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 는 수집된 안무 영상 데이터에 포함된 총 프레임 수를 나타내며, 만약, 안무 영상의 길이가 T초인 경 우, 60T개의 프레임으로 구성될 수 있다. 또한, 는 음악적 특징값, 는 예측된 자세 정보, 는 실제 자 세 정보를 나타낼 수 있다. 이하에서는 학습부가 예측값과 실제값의 오차를 최소화하도록 신경망의 가중치와 편향을 갱신하는 과정을 구체적으로 설명하도록 한다. 일 실시예에서, 학습부는 안무 영상 데이터 내의 안무 패턴에 대한 손실함수, 안무 영상 데이터 내에서 인 접하는 안무 간의 움직임 패턴에 대한 손실함수 및 안무 영상 데이터 내의 반복 안무 패턴에 대한 손실함수 중 적어도 하나에 기초하여 자세 정보 시퀀스를 생성하도록 모델을 학습시킬 수 있다. 구체적으로, 학습부에서는 실제값과 결과값의 오차를 구하기 위하여, 총 3가지 지표의 손실함수를 사용할 수 있으며, 이는 안무 자세에 따른 포즈 랜드마크의 위치 정보와 연속된 안무 동작에 따른 인접한 포즈 랜드마 크 위치 정보의 변화량, 불연속적이지만 반복적으로 나타나는 음악의 대표 구간에 해당하는 포즈 랜드마크 위치 정보의 구속 조건과 관련된 지표로서 포함될 수 있다. 먼저, 안무 영상 데이터 내의 안무 패턴에 대한 손실함수에 대해 설명하도록 한다. 이 때, 전술한 안무 자세에 따른 포즈 랜드마크의 위치정보는 음악적 특징에 따라 취하는 안무 자세의 패턴을 학습하기 위해 포함되는 항목 이며, 해당 손실함수는 평균 제곱 오차(Mean Squared Error, 이하, MSE)를 사용하여 이하, [수학식 3]으로 표현 될 수 있다. 수학식 3"}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 안무 자세에 따른 포즈 랜드마크 위치 정보의 예측값과 실제값의 MSE를 나타내며, 는 수집된 안 무영상에 포함된 총 프레임 수, 는 예측된 자세 정보 는 실제 자세 정보를 나타낸다. 또한, 안무 영상 데이터 내에서 인접하는 안무 간의 움직임 패턴에 대한 손실함수에 대해 설명하도록 한다. 이 때, 전술한 연속된 안무 동작에 따른 포즈 랜드마크 위치 정보의 변화량은 연이어 이어지는 안무 동작의 관성을 고려하여, 연이은 동작 간 자연스러운 움직임 패턴을 학습하기 위해 포함되는 항목이며, 인접한 프레임 간 포즈 랜드마크 위치 정보를 비교하여, 예측된 결과와 실제가 서로 유사하도록 오차를 조정하는 역할을 수행할 수 있 다. 해당 손실함수는 MSE를 사용하여 이하, [수학식 4]로 표현될 수 있다. 수학식 4"}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 는 연이은 안무 동작에 따른 포즈 랜드마크 위치정보 변화량의 오차를 나타내며, 는 수집된 안무 영상에 포함된 총 프레임 수, 는 예측된 자세 정보 는 실제 자세 정보를 나타낼 수 있다. 또한, 안무 영상 데이터 내의 반복 안무 패턴에 대한 손실함수에 대해 설명하도록 한다. 이 때, 전술한 불연속 적이지만 반복적으로 나타나는 음악의 대표 구간에 해당하는 포즈 랜드마크 위치정보의 구속 조건은 음악의 후 렴구 부분에 핵심이 되는 포인트 안무를 반드시 포함시키 위하여, 해당 구간에 있어서 만큼은 안무 동작의 자유 도를 일부 제약하여 반복된 안무 동작을 수행할 수 있도록 학습하기 위해 포함되는 항목이며, 반복되는 구간의 포즈 랜드마크 위치 정보의 평균 변화율이 최소화되도록 오차를 조정하는 역할을 수행한다. 해당 손실함수는 MSE를 사용하여 이하, [수학식 5]로 표현될 수 있다. 수학식 5"}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 는 반복된 후렴 구간에 해당하는 포즈 랜드마크 위치정보 간 평균 변화율의 오차를 나타내며, 는 대표 구간에 해당하는 프레임 구간을 의미하며 1절과 2절에 포함된 각각의 후렴 구간인 와 를 포함한다. 는 후렴 구간에 해당하는 예측된 자세 정보의 평균 변화율, 는 후렴 구간에 해당하는 실제 자세 정보 의 평균 변화율을 나타낼 수 있다. 따라서, 학습부에서는 상술한 안무 자세에 따른 포즈 랜드마크의 위치정보, 연속된 안무 동작에 따른 포즈 랜드마크 위치정보의 변화량, 그리고 불연속적이지만 반복적으로 나타나는 음악의 후렴 구간에 해당하는 포즈 랜드마크 위치정보의 평균 변화율의 차이, 이 세 가지 지표를 기준으로 최적의 인공신경망을 구성할 수 있으며, 본 발명의 일 실시예에 따른 음악에 해당하는 오디오 신호(Audio Signal)와 춤 장르에 따른 자세 정보 시퀀스를 생성하는 장치로서 활용할 수 있다. 본 발명의 일 실시예에 따르면, 음악과 춤 동작의 상호 밀접한 연관성을 토대로 인공지능 기법을 활용하여, 음 악이 어울리고, 보다 움직임이 자연스럽고, 포인트 안무를 포함한 애니메이션을 생성할 수 있다. 또한, 춤 장르에 대한 조건부 입력을 통해 음악에 독립적이면서 다양한 춤 장르에 따른 안무 스타일을 표현할 수 있다. 즉, 동일한 음악에 대해서도 춤의 장르에 따라 취할 수 있는 안무 자세 및 동작이 상이하기 때문에, 춤의 장르에 따른 안무 스타일을 일반화할 수 있다. 도 7은 본 발명의 일 실시예에 따른 안무 영상 생성 장치에서 안무 영상을 생성하는 방법의 순서도이다. 도 7에 도시된 안무 영상 생성 장치에서 안무 영상을 생성하는 방법은 도 1 내지 도 6에 도시된 실시예에 따라 시 계열적으로 처리되는 단계들을 포함한다. 따라서, 이하 생략된 내용이라고 하더라도 도 1 내지 도 6에 도시된 실시예에 따라 안무 영상 생성 장치에서 안무 영상을 생성하는 방법에도 적용된다. 단계 S710에서 안무 영상 생성 장치는 음원 데이터 및 캐릭터의 템플릿 정보를 입력받을 수 있다. 단계 S720에서 안무 영상 생성 장치는 음원 데이터에 대한 음악적 특징값을 추출할 수 있다. 단계 S730에서 안무 영상 생성 장치는 추출된 음악적 특징값에 기초하여 음원 데이터로부터 대표 구간을 선정할 수 있다. 단계 S740에서 안무 영상 생성 장치는 기학습된 모델에 기초하여 추출된 음악적 특징값, 선정된 대표 구간 으로부터 자세 정보 시퀀스를 도출할 수 있다. 단계 S750에서 안무 영상 생성 장치는 캐릭터의 템플릿 정보 및 자세 정보 시퀀스에 기초하여 캐릭터에 대 한 안무 영상을 생성할 수 있다. 상술한 설명에서, 단계 S710 내지 S750은 본 발명의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적 은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 전환될 수도 있다. 도 1 내지 도 7을 통해 설명된 안무 영상 생성 장치에서 안무 영상을 생성하는 방법은 컴퓨터에 의해 실행 되는 매체에 저장된 컴퓨터 프로그램 또는 컴퓨터에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 또한, 도 1 내지 도 7을 통해 설명된 안무 영상 생성 장치에서 안무 영상을 생성하는 방 법은 컴퓨터에 의해 실행되는 매체에 저장된 컴퓨터 프로그램의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매 체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보 의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한 다."}
{"patent_id": "10-2022-0165879", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2022-0165879", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 안무 영상 생성 시스템을 개략적으로 나타내는 도면이다. 도 2는 본 발명의 일 실시예에 따른 안무 영상 생성 장치의 구성도이다. 도 3은 본 발명의 일 실시예에 따라 안무 영상을 생성하는 방법을 개략적으로 설명하기 위한 도면이다. 도 4는 대중 음악에서 흔히 사용하는 곡 형식의 일 예를 도시화하여 나타낸 도면이다. 도 5는 본 발명의 일 실시예에 따른 자세 정보에 포함된 포즈 랜드마크 항목을 나타내는 도면이다. 도 6은 사전 학습된 포즈 검출 모델(Pose Detect Model)을 이용하여 안무 영상 데이터로부터 추출된 자세 정보 의 한 예를 도시화한 도면이다. 도 7은 본 발명의 일 실시예에 따른 안무 영상 생성 장치에서 안무 영상을 생성하는 방법의 순서도이다."}
