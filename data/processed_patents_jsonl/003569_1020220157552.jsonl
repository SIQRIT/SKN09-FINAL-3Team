{"patent_id": "10-2022-0157552", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0094133", "출원번호": "10-2022-0157552", "발명의 명칭": "인공지능 모델 간의 앙상블 기법을 바탕으로 고장을 검출하는 비전 검사 시스템", "출원인": "주식회사 아이코어", "발명자": "이용주"}}
{"patent_id": "10-2022-0157552", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비전 검사 시스템에 있어서,검사 대상을 촬영하는 카메라;고장과 관련된 semantic 정보를 추출하여 고장을 검출하는 제1 인공지능 모델 및 특징 정보(featureinformation)를 추출하여 고장을 검출하는 제2 인공지능 모델을 포함하는 메모리; 및상기 카메라 및 상기 메모리와 연결된 프로세서;를 포함하고,상기 프로세서는,상기 카메라를 통해 획득된 이미지를 상기 제1 인공지능 모델에 입력하여 제1 출력 정보를 획득하고,상기 이미지를 상기 제2 인공지능 모델에 입력하여 제2 출력 정보를 획득하고,상기 제1 출력 정보 및 상기 제2 출력 정보를 기반으로 상기 이미지에 포함된 객체의 고장을 검출하고,상기 제1 출력 정보는,상기 이미지에 포함된 객체의 고장 영역을 나타내는 제1 마스크를 포함하고,상기 제2 출력 정보는,상기 이미지에 포함된 객체의 고장 영역을 나타내는 제2 마스크를 포함하고,상기 제1 인공지능 모델은,상기 이미지에 포함된 객체의 고장과 관련된 semantic 정보를 획득하고,상기 획득된 semantic 정보에 따라 상기 제1 마스크를 출력하고,상기 제2 인공지능 모델은,상기 이미지에 포함된 객체의 특징 정보를 추출하고,상기 추출된 특징 정보를 기반으로 상기 이미지에 포함된 객체의 분류를 식별하고,상기 분류에 매칭되는 정상 객체의 특징 정보를 상기 추출된 특징 정보와 비교하여 고장 정보를 획득하고,상기 획득된 고장 정보에 따라 상기 제2 마스크를 출력하고,상기 프로세서는,상기 제1 출력 정보에 제1 가중치를 적용하여 제1 값을 획득하고,상기 제2 출력 정보에 제2 가중치를 적용하여 제2 값을 획득하고,상기 제1 값 및 상기 제2 값을 합산한 값을 바탕으로 상기 이미지에 포함된 객체의 고장 영역을 식별하고,상기 프로세서는,상기 이미지가 촬영된 환경에 대한 정보를 기반으로, 상기 제1 가중치 및 상기 제2 가중치를 각각 설정하고,상기 프로세서는,상기 제1 인공지능 모델 및 상기 제2 인공지능 모델 각각의 입력과 매칭되지 않는 사이즈의 이미지가 입력된 경우, 상기 입력된 이미지를 객체 인식을 위한 적어도 하나의 인공지능 모델에 입력하여 객체를 식별하고,상기 입력된 이미지 내에서 상기 식별된 객체를 포함하는 영역을 상기 제1 인공지능 모델 및 상기 제2 인공지능모델 각각의 입력 사이즈에 맞도록 추출하고,공개특허 10-2023-0094133-3-상기 추출된 영역을 상기 제1 인공지능 모델 및 상기 제2 인공지능 모델 각각에 입력하고,상기 프로세서는,정상 객체의 이미지를 활용하여 고장 객체의 이미지를 생성하거나 또는 고장 객체의 이미지를 활용하여 정상 객체의 이미지를 생성하도록 훈련된, GAN(Generative Adversarial Networks) 모델을 통해, 훈련 데이터를 획득하고,상기 획득된 훈련 데이터를 바탕으로, 상기 제1 인공지능 모델 및 상기 제2 인공지능 모델 중 적어도 하나를 훈련시키는, 비전 검사 시스템."}
{"patent_id": "10-2022-0157552", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "비전 검사 시스템이 개시된다. 본 비전 검사 시스템은, 검사 대상을 촬영하는 카메라, 고장과 관련된 semantic 정보를 추출하여 고장을 검출하는 제1 인공지능 모델 및 특징 정보(feature information)를 추출하여 고장을 검 출하는 제2 인공지능 모델을 포함하는 메모리, 프로세서를 포함한다. 프로세서는, 카메라를 통해 획득된 이미지 를 제1 인공지능 모델에 입력하여 제1 출력 정보를 획득하고, 이미지를 제2 인공지능 모델에 입력하여 제2 출력 정보를 획득하고, 제1 출력 정보 및 제2 출력 정보를 기반으로 이미지에 포함된 객체의 고장을 검출한다."}
{"patent_id": "10-2022-0157552", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 비전 검사 시스템에 관한 것으로, 보다 상세하게는, 복수의 인공지능 모델로부터 독립적으로 획득된 출력들을 조합하여 고장을 검출하는 비전 검사 시스템에 관한 것이다."}
{"patent_id": "10-2022-0157552", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "고장 검출을 위한 비전 검사 기술에 있어, 고장 검출의 자동화 및 판단의 정밀성을 위해 인공지능 모델이 이용 되기 시작했다. 다만, 인공지능 모델의 판단 정확도를 담보하기 위해서는 다양한 상황에 대한 방대한 훈련 데이터가 필요하기 때문에, 다양한 출처의 이미지 데이터를 분류하고 전처리하는 과정이 필요하다. 또한, 인공지능 모델의 구체적인 네트워크 구성 내지는 훈련 기법에 따라 장단점이 명확하기 때문에, 인공지능 모델의 판단 정확도에 백퍼센트 의존할 정도의 기술수준에는 이르지 못하고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2020-0046137호"}
{"patent_id": "10-2022-0157552", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 독립적으로 훈련 및 운영되는 두 개의 인공지능 모델의 출력을 조합하는 앙상블 기법을 바탕으로 고 장 검출을 수행하는 비전 검사 시스템을 제공한다. *본 개시는 입출력 포맷이 동일한 서로 다른 인공지능 모델들을 활용하고, 훈련을 최소화하여, 효율적인 고장 검출 환경을 제공하는 비전 검사 시스템을 제공한다. 본 개시의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 개시의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 개시의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 개시의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2022-0157552", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 비전 검사 시스템은, 검사 대상을 촬영하는 카메라, 고장과 관련된 semantic 정보 를 추출하여 고장을 검출하는 제1 인공지능 모델 및 특징 정보(feature information)를 추출하여 고장을 검출하 는 제2 인공지능 모델을 포함하는 메모리, 상기 카메라 및 상기 메모리와 연결된 프로세서를 포함한다. 상기 프 로세서는, 상기 카메라를 통해 획득된 이미지를 상기 제1 인공지능 모델에 입력하여 제1 출력 정보를 획득하고,상기 이미지를 상기 제2 인공지능 모델에 입력하여 제2 출력 정보를 획득하고, 상기 제1 출력 정보 및 상기 제2 출력 정보를 기반으로 상기 이미지에 포함된 객체의 고장을 검출한다. 상기 제1 인공지능 모델은, 정상에 해당하는 객체를 포함하는 제1 이미지 및 고장에 해당하는 객체를 포함하는 제2 이미지를 기반으로 훈련된 모델일 수 있다. 그리고, 상기 제2 인공지능 모델은, 상기 제1 이미지로부터 정 상 객체의 특징 정보를 추출할 수 있다. 상기 제1 출력 정보는, 상기 이미지에 포함된 객체의 고장 영역을 나타내는 제1 마스크를 포함하고, 상기 제2 출력 정보는, 상기 이미지에 포함된 객체의 고장 영역을 나타내는 제2 마스크를 포함할 수 있다. 이 경우, 상기 제1 인공지능 모델은, 상기 이미지에 포함된 객체의 고장과 관련된 semantic 정보를 획득하고, 상기 획득된 semantic 정보에 따라 상기 제1 마스크를 출력할 수 있다. 또한, 상기 제2 인공지능 모델은, 상기 이미지에 포함된 객체의 특징 정보를 추출하고, 상기 추출된 특징 정보를 기반으로 상기 이미지에 포함된 객체 의 분류를 식별하고, 상기 분류에 매칭되는 정상 객체의 특징 정보를 상기 추출된 특징 정보와 비교하여 고장 정보를 획득하고, 상기 획득된 고장 정보에 따라 상기 제2 마스크를 출력할 수 있다. 한편, 상기 프로세서는, 상기 제1 출력 정보에 제1 가중치를 적용하여 제1 값을 획득하고, 상기 제2 출력 정보 에 제2 가중치를 적용하여 제2 값을 획득하고, 상기 제1 값 및 상기 제2 값을 기반으로 상기 이미지에 포함된 객체의 고장 영역을 식별할 수 있다. 이 경우, 상기 프로세서는, 상기 이미지가 촬영된 환경에 대한 정보를 기반으로, 상기 제1 가중치 및 상기 제2 가중치를 각각 설정할 수 있다. 상기 프로세서는, 상기 제1 인공지능 모델 및 상기 제2 인공지능 모델 각각의 입력과 매칭되지 않는 사이즈의 이미지가 입력된 경우, 상기 입력된 이미지를 객체 인식을 위한 적어도 하나의 인공지능 모델에 입력하여 객체 를 식별하고, 상기 입력된 이미지 내에서 상기 식별된 객체를 포함하는 영역을 추출하고, 상기 추출된 영역을 상기 제1 인공지능 모델 및 상기 제2 인공지능 모델 각각에 입력할 수도 있다. 본 개시의 일 실시 예에 따른 비전 검사 시스템은, 고장과 관련된 semantic 정보를 추출하여 고장을 검출하는 제1 인공지능 모델 및 특징 정보(feature information)를 추출하여 고장을 검출하는 제2 인공지능 모델을 포함 하는 메모리, 상기 메모리와 연결된 프로세서를 포함한다. 상기 프로세서는, 객체를 포함하는 이미지를 상기 제 1 인공지능 모델에 입력하여 제1 출력 정보를 획득하고, 상기 이미지를 상기 제2 인공지능 모델에 입력하여 제2 출력 정보를 획득하고, 상기 제1 출력 정보 및 상기 제2 출력 정보를 기반으로 상기 이미지에 포함된 객체의 고 장을 검출한다. 이때, 이미지는 메모리에 기저장된 것이거나 또는 적어도 하나의 외부 전자 장치로부터 수신된 것일 수 있 다."}
{"patent_id": "10-2022-0157552", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따른 비전 검사 시스템은, 서로 다른 두 개의 인공지능 모델의 출력을 활용함으로써 다양한 클래스의 객체에 대한 정밀한 고장 검출이 가능하다는 효과가 있다. 본 개시에 따른 비전 검사 시스템은, 두 개의 인공지능 모델의 훈련/구축에 공통된 훈련 데이터(이미지)를 활용 할 수 있고, 하나의 인공지능 모델에 대해서만 노드 간 가중치를 업데이트하는 훈련이 수행되면 충분하므로, 정 밀한 고장 검출 환경을 구축하는 데에 소요되는 로드가 비교적 적다는 장점이 있다."}
{"patent_id": "10-2022-0157552", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에 대하여 구체적으로 설명하기에 앞서, 본 명세서 및 도면의 기재 방법에 대하여 설명한다. 먼저, 본 명세서 및 청구범위에서 사용되는 용어는 본 개시의 다양한 실시 예들에서의 기능을 고려하여 일반적 인 용어들을 선택하였다. 하지만, 이러한 용어들은 당해 기술 분야에 종사하는 기술자의 의도나 법률적 또는 기 술적 해석 및 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 일부 용어는 출원인이 임의로 선정한 용어 도 있다. 이러한 용어에 대해서는 본 명세서에서 정의된 의미로 해석될 수 있으며, 구체적인 용어 정의가 없으 면 본 명세서의 전반적인 내용 및 당해 기술 분야의 통상적인 기술 상식을 토대로 해석될 수도 있다. 또한, 본 명세서에 첨부된 각 도면에 기재된 동일한 참조번호 또는 부호는 실질적으로 동일한 기능을 수행하는 부품 또는 구성요소를 나타낸다. 설명 및 이해의 편의를 위해서 서로 다른 실시 예들에서도 동일한 참조번호 또 는 부호를 사용하여 설명한다. 즉, 복수의 도면에서 동일한 참조 번호를 가지는 구성요소를 모두 도시되어 있다 고 하더라도, 복수의 도면들이 하나의 실시 예를 의미하는 것은 아니다. 또한, 본 명세서 및 청구범위에서는 구성요소들 간의 구별을 위하여 \"제1\", \"제2\" 등과 같이 서수를 포함하는 용어가 사용될 수 있다. 이러한 서수는 동일 또는 유사한 구성요소들을 서로 구별하기 위하여 사용하는 것이며 이러한 서수 사용으로 인하여 용어의 의미가 한정 해석되어서는 안 된다. 일 예로, 이러한 서수와 결합된 구성 요소는 그 숫자에 의해 사용 순서나 배치 순서 등이 제한되어서는 안 된다. 필요에 따라서는, 각 서수들은 서로 교체되어 사용될 수도 있다. 본 명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 실시 예에서 \"모듈\", \"유닛\", \"부(part)\" 등과 같은 용어는 적어도 하나의 기능이나 동작을 수행하는 구성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\", \"유닛\", \"부(part)\" 등은 각각이 개별적인 특정 한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나 의 프로세서로 구현될 수 있다. 또한, 본 개시의 실시 예에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적인 연결뿐 아니라, 다른 매체를 통한 간접적인 연결의 경우도 포함한다. 또한, 어떤 부분이 어떤 구성요소를 포함한다는 의미는, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것 을 의미한다. 도 1은 본 개시의 일 실시 예에 따른 비전 검사 시스템의 구성을 설명하기 위한 블록도이다. 도 1을 참조하면, 비전 검사 시스템은 카메라, 메모리, 프로세서 등을 포함할 수 있다. 비전 검사 시스템은 다양한 부품/제품 등의 고장을 검출하기 위한 시스템/장치에 해당할 수 있다. 비전 검 사 시스템 내 상술한 구성들은 모두 하나의 장치 내에 포함될 수도 있고, 서로 유무선 통신 가능한 복수의 장치/모듈 내에 구비될 수도 있다. 카메라는 검사 대상을 촬영하여 적어도 하나의 이미지를 생성하기 위한 구성이다. 카메라는 RGB 카메 라, TOF(Time of Flight) 카메라 등으로 구현될 수 있으나, 이에 한정되지 않는다. 카메라는 적어도 하나의 광 센서, 특정 지점 또는 특정 범위를 촬영하기 위하여 빛의 경로를 조절하는 렌 즈 등을 포함할 수 있다. 카메라는 고정되어 있거나 또는 움직이는 검사 대상을 촬영할 수 있다. 이 경우, 검사 대상은 카메라(11 0)의 촬영 범위를 지나가는 경로에 따라 이동하도록 배치될 수 있다. 또한, 카메라가 적어도 하나의 이동 수단(ex. 바퀴, 롤러 등)에 부착되어 이동하면서 촬영이 수행될 수도 있다. 구체적으로, 검사 대상에 대한 에어 리어 스캔 방식, 라인 스캔 방식 등이 이용될 수 있으나, 이에 한정되지 않는다. 메모리는 비전 검사 시스템에 포함되는 적어도 하나의 전자 장치의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 전자 장치의 구성요소와 관련된 적어도 하나의 인스트럭션 또는 데이터를 저장하기 위한 구성이다. 메모리는 ROM, 플래시 메모리 등의 비휘발성 메모리를 포함할 수 있으며, DRAM 등으로 구성된 휘발성 메모 리를 포함할 수 있다. 또한, 메모리는 하드 디스크, SSD(Solid state drive) 등을 포함할 수도 있다. 도 1을 참조하면, 메모리는 독립적으로 고장 검출을 수행하는 제1 인공지능 모델 및 제2 인공지능 모 델을 각각 포함할 수 있다. 본 인공지능 모델들 각각은, 신경망(Neural Network)을 기반으로 하는 네트워크 모델(신경망 모델)에 해당할 수 있다. 네트워크 모델은 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 서로 다른 레이어의 노드 간 가중치를 기반으로 연결 관계를 형성할 수 있다. 일 실시 예로, 제1 인공지능 모델은 객체의 고장과 관련된 semantic 정보를 추출하는 Semantic Segmentation 모델에 해당할 수 있다. Semantic 정보는, 객체의 분류(ex. 부품 종류, 제품 종류 등), 고장 여부, 고장 정도, 고장 영역 등에 대한 정 보를 포함할 수 있다. 제1 인공지능 모델에 이미지가 입력되면, 제1 인공지능 모델은 이미지 내 객체를 인식하고, 객체의 고장 여부를 판단할 수 있으며, 이미지 내에서 객체의 고장 영역을 나타내는 마스크를 출력할 수 있다. 일 실시 예로, 제2 인공지능 모델은 정상 객체와의 비교를 통해 이상치를 검출하는 Anomaly Detection 모 델에 해당할 수 있다. 제2 인공지능 모델은 적어도 하나의 레이어를 통해 이미지의 특징 정보(feature information)를 추출할 수 있다. 여기서, 제2 인공지능 모델은 특징 정보를 활용하여 객체의 분류를 식별할 수 있다. 또한, 제2 인공지능 모델은 식별된 분류에 매칭되는 정상 객체(: 고장이 없는 객체)의 특징 정보를 상술한 특징 정보와 비교하여 고장 여부, 고장 영역 등을 판단할 수 있다. 그 결과, 이미지 내에서 객체의 고장 영역을 나타내는 마스크가 출력될 수 있다. 프로세서는 비전 검사 시스템을 전반적으로 제어하기 위한 구성이다. 구체적으로, 프로세서는 메모리와 연결되는 한편 메모리에 저장된 적어도 하나의 인스트럭션을 실행함으로써 본 개시의 다양 한 실시 예들에 따른 동작을 수행할 수 있다. 프로세서는 하나 이상의 프로세서로 구성될 수 있다. 이때, 하나 이상의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit) 등과 같은 그래픽 전용 프로 세서 또는 NPU와 같은 인공지능 전용 프로세서 등을 포함할 수 있다. 프로세서는 메모리에 저장된 상술한 인공지능 모델들(121, 122)을 각각 구동할 수 있으며, 각 모델의 훈련도 수행할 수 있다. 도 2는 본 개시의 일 실시 예에 따른 비전 검사 시스템의 동작을 설명하기 위한 흐름도이다. 도 2를 참조하면, 프로세서는 카메라를 통해 획득된 이미지를 제1 인공지능 모델에 입력하여 제 1 출력 정보를 획득할 수 있다(S210). 이때, 제1 인공지능 모델은 상술한 Semantic Segmentation 모델일 수 있다. 여기서, 제1 출력 정보는 이미지 내 객체의 고장 영역을 나타내는 마스크에 해당할 수 있다. 또한, 프로세서는 카메라를 통해 획득된 이미지를 제2 인공지능 모델에도 입력하여 제2 출력 정 보를 획득할 수 있다(S220). 이때, 제2 인공지능 모델은 상술한 Anomaly Detection 모델일 수 있다.여기서, 제2 출력 정보 역시 이미지 내 객체의 고장 영역을 나타내는 마스크에 해당할 수 있다. 그리고, 프로세서는 제1 출력 정보 및 제2 출력 정보를 기반으로 이미지에 포함된 객체의 고장을 검출할 수 있다(S230). 예를 들어, 프로세서는 제1 출력 정보에 제1 가중치를 적용하여 제1 값을 획득하고, 제2 출력 정보에 제2 가중치를 적용하여 제2 값을 획득할 수 있다. 그리고, 프로세서는 제1 값 및 제2 값을 기반으로 이미지에 포함된 객체의 고장 영역을 식별할 수 있다. 구체적으로, 제1 값 및 제2 값이 단순히 더해질 수 있으나, 이에 한정되지 않는다. 여기서, 제1 출력 정보에 매칭되는 제1 마스크의 픽셀 각각에 제1 가중치가 적용되고, 제2 출력 정보에 매칭되 는 제2 마스크의 픽셀 각각에 제2 가중치가 적용된 결과, 객체의 고장 영역을 나타내는 (최종) 마스크가 획득될 수 있다. 이때, 최종 마스크 내에서 픽셀 값이 일정 값 이상인 영역이 고장 영역으로 식별될 수 있다. *관련하여, 도 3은 본 개시의 일 실시 예에 따른 비전 검사 시스템이 서로 다른 두 개의 인공지능 모델에 이미 지를 각각 입력하는 동작을 설명하기 위한 도면이다. 도 3을 참조하면, 프로세서는 검사 대상 객체가 촬영된 이미지를 각 인공지능 모델(121, 122)로 입력 할 수 있다. 이때, 제1 인공지능 모델 및 제2 인공지능 모델은 각각 고장 영역을 나타내는 마스크(320, 330)를 출 력할 수 있다. 그리고, 프로세서는 마스크들(320, 330) 각각에 가중치(제1 가중치, 제2 가중치)를 부여하여 합산함에 따 라 최종 마스크를 획득할 수 있다. 구체적인 예로, 제1 가중치와 제2 가중치가 동일한 경우, 제1 출력 정보(마스크)와 제2 출력 정보(마스크 )의 평균치가 획득될 수 있다. 이 경우, 프로세서는 각 인공지능 모델(121, 122)로부터 출력된 마스크들(320, 330)의 픽셀 위치마다 평균 을 산출함으로써 마스크를 획득할 수 있다. 마스크 내에서 특정 값 이상의 R/G/B 값을 가지는 영역이 고장 영역으로 식별될 수 있다. 한편, 제1 가중치 및 제2 가중치는, 각 모델(121, 122)로부터 출력된 마스크(320, 330)의 픽셀 위치 별로 다르 게 설정될 수도 있다. 즉, 마스크의 일부 영역에 대해서는 마스크에 대한 제1 가중치가 마스크에 대한 제2 가중치보다 더 크게 적용되고, 마스크의 다른 영역에 대해서는 마스크에 대한 제2 가중치가 마스크에 대한 제1 가중치보다 더 크게 적용될 수 있다. 또한, 일 실시 예로, 프로세서는 이미지가 촬영된 환경에 대한 정보를 기반으로 제1 가중치 및 제2 가중치 를 각각 설정할 수도 있다. 환경에 대한 정보는, 촬영이 수행된 장소의 밝기, 습도, 공기 오염도, 카메라와 객체 간의 거리 등에 대한 정보 를 포함할 수 있으나, 이에 한정되지 않는다. 이 경우, 메모리에는 환경에 따른 각 인공지능 모델(121, 122)의 정확도에 대한 정보가 픽셀 위치 별로 저 장될 수 있다. 예를 들어, 특정 픽셀 위치에 대하여, 임계치 이상의 밝기에서 촬영된 이미지들에 대해서는 제1 인공지능 모델 이 출력하는 마스크의 정확도가 제2 인공지능 모델이 출력하는 마스크보다 높은 반면, 임계치 미만의 밝기에서 촬영된 이미지들에 대해서는 제2 인공지능 모델이 출력하는 마스크의 정확도가 제1 인공지능 모 델이 출력하는 마스크의 정확도보다 높을 수 있다. 관련하여, 프로세서는 조도 센서를 통해 카메라의 주변 밝기를 식별할 수 있으며, 카메라를 통 해 촬영을 수행하여 이미지를 획득할 수 있다. 여기서, 프로세서는, 마스크 내 적어도 하나의 픽셀 위치에 대하여, 주변 밝기가 임계치 이상이면 제1 가 중치를 제2 가중치보다 더 높게 설정하고, 주변 밝기가 임계치 미만이면 제1 가중치보다 제2 가중치를 더 높게설정할 수 있다. 한편, 메모리에는 상술한 제1 가중치 및 제2 가중치를 마스크 내 픽셀 별로 판단하도록 훈련된 인공지능 모델이 저장될 수 있다. 본 인공지능 모델은, 신경망 모델일 수 있으며, 예를 들어, 다양한 환경에 대한 정보(ex. 밝기, 습도, 공기 오 염도, 카메라의 거리 등)를 입력으로 하고, 상술한 제1 가중치 및 제2 가중치를 출력으로 하는 인공지능 모델 (가중치 판단 모델)일 수 있다. 구체적으로, 프로세서는 카메라를 통해 촬영된 이미지, 이미지가 촬영된 환경에 대한 정보, 이미지가 입력된 결과 각 모델(121, 122)로부터 출력된 마스크들에 대한 (픽셀 위치 별) 다양한 가중치 조합(제1 가중치, 제2 가중치)에 따라 도출된 최종 마스크의 정확도(: 이미지 내 실제 고장 영역과 비교) 등을 활용하여 상술한 인공지능 모델(가중치 판단 모델)을 훈련시킬 수 있다. 여기서, 가중치 판단 모델을 구성하는 노드 간의 가중치 는, 최종 마스크의 픽셀 위치 별 정확도가 향상되는 방향으로 업데이트될 수 있다. 이후, 프로세서는 카메라의 촬영과 관련된 환경에 대한 정보를 가중치 판단 모델에 입력한 결과에 따 라 제1 가중치 및 제2 가중치를 유동적으로 설정할 수 있다. 그리고, 프로세서는 카메라를 통해 촬영 된 이미지를 각 모델(121, 122)에 입력한 결과 획득되는 마스크들에 제1 가중치 및 제2 가중치를 반영하여 최종 마스크(고장 검출 결과)를 획득할 수 있다. 한편, 도 4는 본 개시의 일 실시 예에 따른 비전 검사 시스템의 제1 인공지능 모델이 훈련되는 과정을 설명하기 위한 흐름도이다. 제1 인공지능 모델의 훈련은 프로세서에 의해 수행되거나 또는 적어도 하나의 외부 전자 장치에 의해 수행될 수 있다. 도 4를 통해서는, 제1 인공지능 모델의 훈련이 프로세서를 통해 수행되는 상황을 가 정하여 설명한다. 도 4를 참조하면, 프로세서는 정상 객체가 촬영된 이미지 및 고장 객체가 촬영된 이미지를 각각 하나 이상 획득할 수 있다(S410). 각 이미지는 다양한 클래스(: 객체의 분류)의 객체에 대한 이미지일 수 있으며, 카메라 를 통해 촬영된 것일 수도 있고, 외부 전자 장치로부터 수신된 이미지일 수 있다. 이때, 각 이미지에는 고장 영역과 관련된 라벨이 매칭되어 등록될 수 있다. 예를 들어, 라벨은, 정상/고장 여부, 고장 영역, 고장 정도 등에 대한 정보를 포함할 수 있으나, 이에 한정되지 않는다. 프로세서는 획득된 이미지에 대한 전처리를 수행할 수 있다(S420). 일 실시 예로, 프로세서는 제1 인공지능 모델의 입력 사이즈에 맞도록 각 이미지를 축소/확대할 수 있다. 또는, 제1 인공지능 모델의 입력과 매칭되지 않는 사이즈의 이미지가 입력된 경우, 프로세서는 객체 인식을 위한 적어도 하나의 인공지능 모델에 해당 이미지를 입력하여 객체를 포함하는 영역만을 입력 사이즈에 맞도록 추출할 수 있다. 또한, 훈련 데이터의 확보를 위해, 프로세서는 정상 객체의 이미지 및 고장 객체의 이미지 각각을 활용하 여 하나 이상의 이미지를 추가로 생성할 수 있다. 예를 들어, 프로세서는 획득된 이미지에 대하여 밝기, 대조 등을 변경하거나 또는 이미지의 회전, 와핑, 크롭 등의 동작을 수행하여 새로운 이미지를 생성할 수 있다. 다른 예로, 프로세서는 이미지를 생성하기 위한 적어도 하나의 GAN(Generative Adversarial Networks)을 활용할 수도 있다. 구체적으로, GAN은 적어도 하나의 정상 객체의 이미지 및 적어도 하나의 고장 객체의 이미지를 통해 훈련된 결 과, 정상 객체의 이미지를 활용하여 고장 객체의 이미지를 생성하거나 또는 고장 객체의 이미지를 활용하여 정 상 객체의 이미지를 생성할 수 있다. 이 경우, GAN은 검사 대상인 객체의 분류 별로 훈련될 수 있다. 또한, GAN은 적어도 하나의 정상 객체의 이미지 및 고장 객체의 고장 영역을 나타내는 마스크 이미지를 통해 훈 련될 수도 있다. 이렇듯 전처리 과정이 수행되면, 프로세서는 훈련을 위한 이미지들을 제1 인공지능 모델에 입력하고 (S430), 제1 인공지능 모델의 출력을 상술한 라벨과 비교(S440)할 수 있다. 그리고, 프로세서는 비교결과에 따라 제1 인공지능 모델 내 노드 간 가중치를 업데이트할 수 있다(S450). 한편, 도 5는 본 개시의 일 실시 예에 따른 비전 검사 시스템의 제2 인공지능 모델이 구축되는 과정을 설명하기 위한 흐름도이다. 제2 인공지능 모델의 구축은 프로세서에 의해 수행되거나 또는 적어도 하나의 외부 전자 장치에 의해 수행될 수 있다. 도 5를 통해서는, 제2 인공지능 모델의 구축이 프로세서를 통해 수행되는 상황을 가 정하여 설명한다. 도 5를 참조하면, 프로세서는 정상 객체가 촬영된 이미지를 하나 이상 획득할 수 있다(S510). 각 이미지는, 다양한 클래스(: 객체의 분류)에 해당하는 객체의 이미지일 수 있으며, 카메라를 통해 촬영된 것일 수도 있고, 외부 전자 장치로부터 수신된 이미지일 수 있다. 제2 인공지능 모델은 Anomaly Detection 모델로서 정상 객체의 이미지로부터 특징 정보를 추출한 이후 고 장 객체의 검출에 활용할 수 있다. 도 5를 참조하면, 프로세서는 획득된 정상 객체의 이미지에 대한 전처리를 수행할 수 있다(S520). 상술한 S420과 마찬가지로 다양한 실시 예에 따른 전처리 과정이 정상 객체의 이미지에 대해 수행될 수 있다. 그리고, 프로세서는 (정상 객체의) 이미지들을 제2 인공지능 모델에 입력할 수 있다(S530). 이 경우, 특징 정보가 다수 레이어를 통해 출력될 수 있는 바, 일부 레이어들의 특징 정보만이 랜덤으로 선별될 수 있다(S540). 그리고, 클래스(: 객체의 분류) 별로, 프로세서는 레이어 단위의 특징 정보의 평균 및 공분산을 추출하여 저장할 수 있다(S550). 이후, 고장 객체의 이미지가 제2 인공지능 모델에 입력되는 경우, 제2 인공지능 모델은 정상 객체에 대하여 저장된 평균/공분산 등을 활용하여 고장을 검출할 수 있다. 관련하여, 도 6은 본 개시의 일 실시 예에 따른 비전 검사 시스템이 제2 인공지능 모델을 활용하여 고장을 검출 하는 과정을 설명하기 위한 흐름도이다. 도 6을 참조하면, 프로세서는 검사 대상인 객체가 촬영된 이미지를 획득할 수 있다(S610). 이때, 프로세서 는 카메라를 통해 이미지를 촬영하거나 또는 외부 전자 장치로부터 이미지를 수신할 수 있다. 그리고, 프로세서는 제2 인공지능 모델에 이미지를 입력할 수 있다(S620). 제2 인공지능 모델에 이미지가 입력되는 동안, 제1 인공지능 모델에도 이미지가 입력됨은 물론이다. 이때, 프로세서는 제2 인공지능 모델의 레이어들을 통해 레이어 단위의 특징 정보를 다수 획득할 수 있다. 여기서, 프로세서는 특징 정보를 활용하여 이미지 내 객체의 클래스를 분류할 수 있다(S640). 또한, 프로세서는 특징 정보를 출력하는 레이어들 중 일부 레이어들을 선별하여 특징 정보를 추출할 수 있 다(S630). 일 예로, Encoder 형태로 일정 수에 해당하는 레이어의 특징 정보(ex. Feature Map)가 추출될 수 있 으나, 이에 한정되지 않는다. 이때, 프로세서는 분류된 클래스에 해당하는 정상 객체의 특징 정보의 평균과 공분산을, 추출된 특징 정보 와 비교할 수 있다(S650). 예를 들어, 마할라노비스(Mahalanobis) 거리에 따라 편차가 계산될 수 있으나, 이 밖 에 pooled feature map의 KNN 거리가 비교되어 outlier가 추출되는 PatchCore 기법, Semi-orthogonal 기법 등 도 활용될 수 있다. 그리고, 프로세서는 비교 결과에 따라 고장 정보(ex. 고장 여부, 고장 정도, 고장 영역 등)를 획득함으로 써 고장 검출을 수행할 수 있다(S660). 구체적으로, 비교 결과 정상 객체와의 차이가 큰 이미지 내 영역에 대해 픽셀 값이 차별적으로 설정된 결과 마스크(ex. 330)가 출력될 수 있다. 도 7은 본 개시의 다양한 실시 예에 따른 비전 검사 시스템의 상세한 구성을 설명하기 위한 블록도이다. 도 7을 참조하면, 비전 검사 시스템은 카메라, 메모리, 프로세서 외에 사용자 입력부 , 통신부, 출력부 등을 포함할 수 있다.사용자 입력부는 사용자로부터 다양한 명령 내지는 정보를 입력 받기 위한 구성이다. 예를 들어, 사용자 입력부는 비전 검사 시스템에 포함되는 장치의 터치 센서, 버튼, 카메라, 마이크, 키보드 등으로 구성될 수 있으나, 이에 한정되지 않는다. 일 실시 예로, 비전 검사 시스템은 사용자 입력부를 통해 수신되는 사용자 입력에 따라 카메라 의 촬영을 제어하거나 및/또는 고장 검출(ex. 제1 인공지능 모델 및 제2 인공지능 모델 구동)을 수행할 수 있다. 통신부는 비전 검사 시스템이 다양한 외부 장치와 데이터를 송수신하기 위한 구성으로, 통신을 위한 적어도 하나의 회로를 포함할 수 있다. 통신부는 TCP/IP(Transmission Control Protocol/Internet Protocol), UDP(User Datagram Protocol), HTTP(Hyper Text Transfer Protocol), HTTPS(Secure Hyper Text Transfer Protocol), FTP(File Transfer Protocol), SFTP(Secure File Transfer Protocol), MQTT(Message Queuing Telemetry Transport) 등의 통신 규 약(프로토콜)을 이용하여 하나 이상의 외부 전자 장치와 다양한 정보를 송수신할 수 있다. 이를 위해, 통신부는 유선 통신 및/또는 무선 통신을 통해 구현된 네트워크를 기반으로, 외부 장치와 연결 될 수 있다. 이때, 통신부는 외부 장치와 직접적으로 연결될 수도 있지만, 네트워크를 제공하는 하나 이상 의 외부 서버(ex. ISP(Internet Service Provider))를 통해서 외부 전자 장치와 연결될 수도 있다. 네트워크는 영역 또는 규모에 따라 개인 통신망(PAN; Personal Area Network), 근거리 통신망(LAN; Local Area Network), 광역 통신망(WAN; Wide Area Network) 등일 수 있으며, 네트워크의 개방성에 따라 인트라넷 (Intranet), 엑스트라넷(Extranet), 또는 인터넷(Internet) 등일 수 있다. 무선 통신은 LTE(long-term evolution), LTE-A(LTE Advance), 5G(5th Generation) 이동통신, CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), GSM(Global System for Mobile Communications), DMA(Time Division Multiple Access), WiFi(Wi-Fi), WiFi Direct, Bluetooth, NFC(near field communication), Zigbee 등의 통신 방식 중 적어도 하나를 포함할 수 있다. 유선 통신은 이더넷(Ethernet), 광 네트워크(optical network), USB(Universal Serial Bus), 선더볼트 (ThunderBolt) 등의 통신 방식 중 적어도 하나를 포함할 수 있다. 여기서, 통신부는 상술한 유무선 통신 방식에 따른 네트워크 인터페이스(Network Interface) 또는 네트워 크 칩을 포함할 수 있다. 한편, 통신 방식은 상술한 예에 한정되지 아니하고, 기술의 발전에 따라 새롭게 등장 하는 통신 방식을 포함할 수 있다. 일 실시 예로, 비전 검사 시스템은 통신부를 통해 외부 전자 장치로부터 이미지를 수신할 수 있다. 여기서, 이미지는 정상 객체 또는 고장 객체가 촬영된 이미지일 수 있다. 이렇듯 통신부가 구비된 경우, 비전 검사 시스템이 카메라를 구비하지 않는 실시 예도 가능하다. 출력부는 다양한 정보를 출력하여 사용자에게 제공하기 위한 구성이다. 출력부는 스피커, 디스플레이, 이어폰/헤드셋 단자 등으로 구현될 수 있으나, 이에 한정되지 않는다. 일 실시 예로, 비전 검사 시스템은 검사 대상인 객체의 고장이 검출된 경우, 출력부의 디스플레이를 통해 이미지 내 고장 영역을 표시할 수 있다. 여기서, 고장 영역은 각 모델(121, 122)로부터 출력된 마스크들이 가중치에 따라 조합된 최종 마스크에 따라 선택될 수 있다. 한편, 카메라는, 단순히 이미지 센서만을 포함할 수도 있으나, 이미지 센서에 대하여 적어도 하나의 프로 세싱 모듈을 포함할 수도 있다. 관련하여, 도 8은 본 개시의 일 실시 예에 따른 비전 검사 시스템 내 FPGA(field programmable gate arrays)를 포함하는 카메라의 구성을 설명하기 위한 도면이다. 일반적인 스마트 카메라는 64bit RISC Processor Module에 CMOS 이미지 센서가 MIPI Interface 나 LVDS Interface를 통해 직접 연결되는 구조로 되어있다. 즉, 사용되는 이미지 센서 해상도 및 종류에 따라 이미지 처 리가 달라지게 된다. 이 경우, 이미지 센서가 변경되면 검사 알고리즘을 처리하는 모듈의 프로그램도 변경이 필요하다. 사용자는 각 검사 유형에 맞는 해상도의 카메라를 별도로 구매해야 하기 때문에 비용적인 측면에서 부 담이 될 수 있다. 반면, 도 8을 참조하면, 본 개시의 일 실시 예에 따른 카메라는 이미지 센서에서 이미지를 받고 이미지 처 리하는 별도의 모듈(FPGA)을 포함하고 검사 알고리즘 처리를 위한 프로세서로 이미지 데이터를 빠르게 전 달할 수 있다(ex. USB 3.0). 이 경우, 프로세서는 연결된 해상도에 맞는 Buffer 설정만으로 쉽게 다양한 해상도의 이미지를 적용할 수 있다. 사용자는 하나의 프로세서에 필요한 해상도의 이미지 센서를 다양하게 연결하여 사용 가능 하기 때 문에 비용적인 측면에서도 많은 이점이 생기고 각 검사 유형에 맞게 쉽고 빠르게 대응할 수 있다. 특히, CMOS 이미지센서에서 받은 데이터는 노이즈 등으로 인해 검사에 바로 사용되기 힘든 반면, 도 8의 카메라 의 FPGA 모듈에서는 노이즈 저감 및 defect 보정을 위한 ISP(Image Signal Processing) 처리 후 사용자가 원하는 이미지 사이즈를 설정하고 프로세서로 보정된 이미지 데이터를 전송할 수 있다. 이후, 프로세서는 미리 학습된 데이터셋을 활용하여 보정된 이미지에 대한 고장 검출을 시행할 수 있다 (ex. 도 2). 여기서, 룰 기반의 검사와 딥러닝 검사가 함께 활용될 수 있다. 이렇듯, 모든 검사가 별도 컴퓨팅 유닛 없이(별도 서버 등) 비전 검사 시스템 내에서 수행될 수 있기 때문에 시스템을 구성하는데 소모되는 비용이 획기적으로 절감될 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 서로 저촉되지 않는 한 둘 이상이 서로 결합되어 구현될 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합된 것 을 이용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 본 개시에서 설명되는 실시 예들은 ASICs(Application Specific Integrated Circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기 (controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행 을 위한 전기적인 유닛(unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 상술한 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 비전 검사 시스템에서의 처리동작을 수행하기 위한 컴퓨 터 명령어(computer instructions) 또는 컴퓨터 프로그램은 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어 또는 컴퓨터 프로그램은 특정 기기의 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 비전 검사 시스템에서의 처리 동작을 상술한 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2022-0157552", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2022-0157552", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 비전 검사 시스템의 구성을 설명하기 위한 블록도, 도 2는 본 개시의 일 실시 예에 따른 비전 검사 시스템의 동작을 설명하기 위한 흐름도, 도 3은 본 개시의 일 실시 예에 따른 비전 검사 시스템이 서로 다른 두 개의 인공지능 모델에 이미지를 각각 입 력하는 동작을 설명하기 위한 도면, 도 4는 본 개시의 일 실시 예에 따른 비전 검사 시스템의 제1 인공지능 모델이 훈련되는 과정을 설명하기 위한 흐름도, 도 5는 본 개시의 일 실시 예에 따른 비전 검사 시스템의 제2 인공지능 모델을 구축하는 과정을 설명하기 위한흐름도, 도 6은 본 개시의 일 실시 예에 따른 비전 검사 시스템이 제2 인공지능 모델을 활용하여 고장을 검출하는 과정 을 설명하기 위한 흐름도, 도 7은 본 개시의 다양한 실시 예에 따른 비전 검사 시스템의 상세한 구성을 설명하기 위한 블록도, 그리고 도 8은 본 개시의 일 실시 예에 따른 비전 검사 시스템 내 FPGA를 포함하는 카메라의 구성을 설명하기 위한 도 면이다."}
