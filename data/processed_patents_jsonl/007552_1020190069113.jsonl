{"patent_id": "10-2019-0069113", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0142200", "출원번호": "10-2019-0069113", "발명의 명칭": "신경망 연산 효율 증대를 위한 신경망 가속기 및 그의 동작 방법", "출원인": "에스케이텔레콤 주식회사", "발명자": "한정호"}}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "신경망 가속기(neural network accelerator)에 있어서,신경망 연산을 수행하는 프로세서(processor);멀티 레인(multi-lane) 구조의 메모리부; 및상기 프로세서의 신경망 연산 전 특징 데이터를 전처리하는 전처리부를 포함하고,상기 전처리부는 상기 메모리부로부터 병렬적으로 읽어들인 상기 특징 데이터 중 일부에 대해 시프팅(shifting)및 마스킹(masking) 중 적어도 어느 하나를 수행하여 상기 프로세서에게 병렬로 전송하며,상기 프로세서는 상기 특징 데이터에 대해 신경망 연산을 수행하는 것인 신경망 가속기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 시프팅은 상기 전처리부가 병렬적으로 읽어들인 상기 특징 데이터 중 일부의 순서를 바꾸어 상기 프로세서에게 전송하는 것인 신경망 가속기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 마스킹은, 상기 전처리부가 병렬적으로 읽어들인 상기 특징 데이터 중 일부에 대해 상기 특징 데이터 대신 영(zero) 값을상기 프로세서에게 전송하는 것인 신경망 가속기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 전처리부는,상기 메모리부에 저장된 상기 특징 데이터에 접근하기 위한 메모리 어드레스를 생성하는 어드레스 시퀀스 생성기를 포함하고,상기 어드레스 시퀀스 생성기는 커널 정보 및 특징 데이터 레이아웃 정보를 이용하여 상기 메모리 어드레스를생성하는 신경망 가속기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 전처리부는,현재 커널 연산에 사용한 특징 데이터 중 다음 커널 연산에도 사용되는 특징 데이터를 저장하기 위한 캐시를 포함하고, 상기 다음 커널 연산에 사용되는 특징 데이터 중 상기 캐시에 저장된 특징 데이터와 동일한 특징 데이터가 상기메모리부에 존재하는 경우, 상기 다음 커널 연산 시 상기 메모리부가 아닌 상기 캐시에 저장된 특징 데이터를사용하는 신경망 가속기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2020-0142200-2-제5항에 있어서,상기 전처리부는 상기 캐시에 특징 데이터를 저장할 때, 상기 현재 커널 연산에 사용한 특징 데이터 중 다음 커널 연산에도 사용되는 특징 데이터가 저장되지 않은 위치에 저장하는 신경망 가속기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "신경망 연산 효율을 위한 전처리기(pre-processing device)에 있어서,외부의 메모리부에 저장된 특징 데이터에 접근하기 위한 메모리 어드레스를 생성하는 어드레스 시퀀스 생성기;상기 어드레스를 이용하여 상기 메모리부로부터 병렬적으로 읽어들인 상기 특징 데이터 중 일부에 대해 시프팅및 마스킹 중 적어도 어느 하나를 수행하여 외부의 프로세서에게 병렬로 전송하는 읽기 데이터 정렬부; 및상기 읽기 데이터 정렬부에게 상기 시프팅 및 마스킹을 제어하기 위한 멀티플렉서(multiplexer: mux) 제어 신호를 전송하는 멀티플렉서 제어 시퀀스 생성기를 포함하는 전처리기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 시프팅은 상기 읽기 데이터 정렬부가 병렬적으로 읽어들인 상기 특징 데이터 중 일부의 순서를 바꾸어 상기 프로세서에게 전송하는 것인 전처리기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 마스킹은, 상기 읽기 데이터 정렬부가 병렬적으로 읽어들인 상기 특징 데이터 중 일부에 대해 상기 특징 데이터 대신 영(zero) 값을 상기 프로세서에게 전송하는 것인 전처리기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,현재 커널 연산에 사용한 특징 데이터 중 다음 커널 연산에도 사용되는 특징 데이터를 저장하기 위한 캐시를 포함하고, 상기 다음 커널 연산에 사용되는 특징 데이터 중 상기 캐시에 저장된 특징 데이터와 동일한 특징 데이터가 상기메모리부에 존재하는 경우, 상기 다음 커널 연산 시 상기 메모리부가 아닌 상기 캐시에 저장된 특징 데이터를사용하는 전처리기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 캐시에 특징 데이터를 저장할 때, 상기 현재 커널 연산에 사용한 특징 데이터 중 다음 커널 연산에도 사용되는 특징 데이터가 저장되지 않은 위치에 저장하는 전처리기."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "신경망 가속 방법에 있어서,프로세서로부터 특징 데이터를 요청받는 단계;메모리부로부터 멀티 레인을 통하여 상기 특징 데이터를 병렬적으로 전달받는 단계; 및상기 특징 데이터 중 일부에 대해 시프팅 및 마스킹 중 적어도 어느 하나를 수행하여 상기 프로세서에게 병렬로전송하는 단계공개특허 10-2020-0142200-3-를 포함하는 신경망 가속 방법."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 요청받는 단계 이후, 상기 특징 데이터가 저장된 메모리부에 접근하기 위한 메모리 어드레스 시퀀스를 생성하는 단계를 더 포함하되,상기 전달받는 단계는 상기 메모리 어드레스 시퀀스를 이용하여 상기 특징 데이터를 전달받는 단계인 신경망 가속 방법."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 요청받는 단계 전에, 상기 프로세서로부터 커널 정보 및 특징 데이터 레이아웃 정보를 전달받는 단계를 포함하고,상기 생성하는 단계는 상기 커널 정보 및 특징 데이터 레이아웃 정보를 이용하여 상기 메모리 어드레스 시퀀스를 생성하는 단계인 신경망 가속 방법."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,현재 커널 연산에 사용한 특징 데이터 중 다음 커널 연산에도 사용되는 특징 데이터를 캐시에 저장하는 단계를더 포함하고,상기 다음 커널 연산에 사용되는 특징 데이터 중 상기 캐시에 저장된 특징 데이터와 동일한 특징 데이터가 상기메모리부에 존재하는 경우, 상기 다음 커널 연산 시 상기 메모리부가 아닌 상기 캐시에 저장된 특징 데이터를사용하는 신경망 가속 방법."}
{"patent_id": "10-2019-0069113", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 저장하는 단계는 상기 현재 커널 연산에 사용한 특징 데이터 중 다음 커널 연산에도 사용되는 특징 데이터가 저장되지 않은 위치에 저장하는 단계인 신경망 가속 방법."}
{"patent_id": "10-2019-0069113", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "신경망 연산 효율 증대를 위한 신경망 가속기 및 그의 동작 방법을 개시한다. 본 실시예의 일 측면에 의하면, 신경망 가속기(neural network accelerator)에 있어서, 신경망 연산을 수행하는 프로세서(processor); 멀티 레인(multi-lane) 구조의 메모리부; 및 상기 프로세서의 신경망 연산 전 특징 데이터 를 전처리하는 전처리부를 포함하고, 상기 전처리부는 상기 메모리부로부터 병렬적으로 읽어들인 상기 특징 데이 터 중 일부에 대해 시프팅(shifting) 및 마스킹(masking) 중 적어도 어느 하나를 수행하여 상기 프로세서에게 병 렬로 전송하며, 상기 프로세서는 상기 특징 데이터에 대해 신경망 연산을 수행하는 것인 신경망 가속기를 포함한 다."}
{"patent_id": "10-2019-0069113", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 신경망을 이용하여 인공지능을 구현하기 위해 신경망 연산 효율을 위한 신경망 가속기(neural network accelerator) 및 그의 동작 방법에 관한 것이다."}
{"patent_id": "10-2019-0069113", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 발명에 대한 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아니다. 최근 딥러닝(deep learning)을 이용한 신경망의 인식 성능이 발전함에 따라, 영상인식 및 음성인식 등 다양한 분야에서 인공지능 기술을 구현하는 데 심층 신경망(deep neural network)이 활용되고 있다. 심층 신경망은 대표적으로 합성곱 신경망(convolution neural network, CNN) 계열과 순환 신경망(recurrent neural network, RNN) 계열로 나뉜다. 합성곱 신경망에서는 많은 입력 레이어(input layer)에 대해 컨볼루션 (convolution) 연산이 사용된다. 순환 신경망에서는 행렬 곱셈(matrix multiplication) 연산이 일반적으로 사 용된다. 심층 신경망을 이용하여 추론(inference) 결과를 얻기 위해서는 매우 많은 양의 연산이 필요하기 때문에, 심층 신경망을 이용한 추론 결과를 실시간으로 얻어야 할 필요가 있는 분야에서는 일반적으로 심층 신경망에 특화된 전용 가속기가 사용된다. 대부분의 신경망 전용 가속기는 연산을 가속화하기 위한 전용 하드웨어 로직, 메모리및 프로그래밍이 가능한 프로세서를 포함한다. 일반적으로 특정한 목적의 가속기를 개발하는 데 많은 비용과 시간이 필요하기 때문에, 특정 어플리케이션 (application)을 위한 가속기를 개발할 때, 특정 어플리케이션의 알고리즘들을 분석하고, 알고리즘들에 공통적 으로 사용되는 기능들을 구현하는 전용 가속기를 추가하는 방식이 이용된다. 한편, 여러 알고리즘들 중 특정 알고리즘에서만 사용되거나, 자주 변경되는 기능들은 프로그래밍이 가능한 프로 세서를 이용하여 구현함으로써 연산을 가속화할 수 있다. 이는, 심층 신경망을 이용하여 추론(inference) 결과 를 얻기 위해서는 매우 많은 양의 연산이 필요하기 때문에, 범용 프로세서(general processor)를 이용하여 실시 간으로 추론 결과를 얻는 데는 한계가 있기 때문이다. 프로그래밍이 가능한 프로세서는 다양한 신경망 알고리즘을 수행하기 위하여 깊이 별 컨볼루션(depth-wise convolution), 최대/평균 풀링(max/average pooling), 엘리먼트 별 곱셈/덧셈(elenment-wise multiplication/addition) 등을 연산할 수 있어야 한다. 특히, 이 중 커널을 이용하는 깊이 별 컨볼루션 및 최 대/평균 풀링의 경우, 처리해야 하는 연산량이 많기 때문에 프로그래밍이 가능한 프로세서로써, SIMD(sigle instruction multiple data), VLIW(very long instruction word)와 같은 벡터 프로세서(vector processor)를 이용할 수 있다. 벡터 프로세서는 복수의 커널들에 대해 병렬 연산을 진행함으로써 연산 속도를 높일 수 있다. 그러나 깊이 별 컨볼루션 및 풀링 등에서는 연산에 필요한 데이터를 준비하기 위한 오버헤드(overhead) 작업이 필요하다. 여기서, 오버헤드 작업은 벡터 프로세서를 이용하여 병렬 연산을 위해 데이터 정렬, 마스킹 등의 작 업을 의미한다. 벡터 프로세서를 사용하더라도 많은 데이터 처리 및 오버헤드 작업으로 인해 연산 처리 시간을 줄이는 데 한계가 있다. 또한, 벡터 프로세서를 이용하여 병렬 연산을 하기 위해서는 여러 데이터에 동시에 접근할 수 있도록 동일한 메 모리 어드레스 시퀀스 및 동일한 데이터 연산이 필요하다. 이는, 입력 특징 맵(input feature map)의 메모리 레 이아웃, 커널의 위치, 패딩 유무 등의 조건에 따라 커널 별로 필요한 메모리 어드레스 시퀀스 생성 및 데이터 연산이 다르기 때문이다. 벡터 프로세서를 이용하더라도, 커널 별로 어드레스 시퀀스 생성 및 오버헤드 작업으 로 인해, 벡터 프로세서의 신경망 연산에 있어서 범용 프로세서보다 성능 향상이 미미하다는 문제점이 있다."}
{"patent_id": "10-2019-0069113", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들은, 병렬 연산을 위한 개별 커널들의 위치 및 제로 패딩 등의 조건에 따른 데이터 시프팅 및 마스킹을 수행하는 전처리부를 포함하여 벡터 프로세서가 오버헤드 작업을 제외한 병렬 연산만을 할 수 있도록 함으로써, 벡터 프로세서의 신경망 연산 효율을 증대시킬 수 있는 신경망 가속기 및 그의 동작 방법을 제공하는 데 주된 목적이 있다. 본 발명의 일부 실시예들은, 전처리부 내에 캐시를 포함하며, 캐시는 현재 커널 연산에 사용된 특징 데이터 중 다음 커널 연산에 사용될 특징 데이터들을 저장한 뒤, 다음 커널 연산에서 별도의 메모리 접근없이 캐시로부터 특징 데이터를 연산에 사용할 수 있도록 함으로써, 메모리에 접근하는 데 필요한 대역폭을 줄일 수 있는 신경망 가속기 및 그의 동작 방법을 제공하는 데 일 목적이 있다."}
{"patent_id": "10-2019-0069113", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 의하면, 신경망 가속기에 있어서, 신경망 연산을 수행하는 프로세서; 멀티 레인 구조의 메 모리부; 및 상기 프로세서의 신경망 연산 전 특징 데이터를 전처리하는 전처리부를 포함하고, 상기 전처리부는 상기 메모리부로부터 병렬적으로 읽어들인 상기 특징 데이터 중 일부에 대해 시프팅 및 마스킹 중 적어도 어느 하나를 수행하여 상기 프로세서에게 병렬로 전송하며, 상기 프로세서는 상기 특징 데이터에 대해 신경망 연산을 수행하는 것인 신경망 가속기를 제공한다. 본 실시예의 다른 측면에 의하면, 신경망 연산 효율을 위한 전처리기에 있어서, 외부의 메모리부에 저장된 특징 데이터에 접근하기 위한 메모리 어드레스를 생성하는 어드레스 시퀀스 생성기; 상기 어드레스를 이용하여 상기 메모리부로부터 병렬적으로 읽어들인 상기 특징 데이터 중 일부에 대해 시프팅 및 마스킹 중 적어도 어느 하나 를 수행하여 외부의 프로세서에게 병렬로 전송하는 읽기 데이터 정렬부; 및 상기 읽기 데이터 정렬부에게 상기 시프팅 및 마스킹을 제어하기 위한 멀티플렉서 제어 신호를 전송하는 멀티플렉서 제어 시퀀스 생성기를 제공한다. 본 실시예의 다른 측면에 의하면, 신경망 가속 방법에 있어서, 프로세서로부터 특징 데이터를 요청받는 단계; 메모리부로부터 멀티 레인을 통하여 상기 특징 데이터를 병렬적으로 전달받는 단계; 및 상기 특징 데이터 중 일 부에 대해 시프팅 및 마스킹 중 적어도 어느 하나를 수행하여 상기 프로세서에게 병렬로 전송하는 단계를 포함 하는 신경망 가속 방법을 제공한다."}
{"patent_id": "10-2019-0069113", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이 본 실시예에 의하면, 프로세서의 병렬 연산 전에, 전처리부가 멀티 레인 구조의 메 모리부로부터 데이터를 병렬로 전달받아 데이터 시프팅 및 마스킹 작업을 수행한 뒤 프로세서에게 전달하고, 프 로세서는 전처리 된 데이터를 이용하여 병렬 연산만을 수행함으로써, 프로세서의 여러 커널에 대한 병렬 연산 효율을 높일 수 있다. 또한, 전처리부 내에 포함된 캐시가 현재 커널 연산에 사용된 특징 데이터 중 다음 커널 연산에 사용될 특징 데 이터들을 저장한 뒤, 다음 커널 연산에서 별도의 메모리 접근없이 캐시로에 저장된 특징 데이터를 연산에 사용 함으로써, 메모리에 접근하는 데 필요한 대역폭을 줄이고, 데이터 병목 현상을 줄일 수 있는 신경망 가속기 및 그의 동작 방법을 제공하는 데 일 목적이 있다."}
{"patent_id": "10-2019-0069113", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구 체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다.또한, 본 발명의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본 질이나 차례 또는 순서 등이 한정되지 않는다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 '포함', '구비' 한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 '~부', '모듈' 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현 될 수 있다. 도 1은 본 발명의 일 실시예에 따른 신경망 가속기를 포함한 전체 시스템을 도시한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 신경망 가속기(neural network accelerator, 10)는 메모리부, 전처리부(pre-processing unit, 110), 프로세서, 가속기 제어부, 연산부(computing unit, 140), 프 로그램 메모리를 포함한다. 전체 시스템은 신경망 가속기, 외부 메모리, 외부 프로세서를 포 함한다. 우선, 외부 메모리는 신경망 연산에 필요한 입출력 데이터를 저장한다. 메모리부는 전처리부 및 연산부와 데이터를 빠르게 주고 받기 위해 멀티 레인(multi-lane) 구조 의 고대역폭 메모리이다. 메모리부는 전처리부로부터 특징 데이터(feature data) 요청을 받으면, 외 부 메모리로부터 특징 데이터를 전달 받아 N 개의 데이터 레인을 통해 전처리부에게 특징 데이터를 전 달한다. 또한, 메모리부는 연산부와 연결되어 N 개의 데이터 레인을 통해 데이터를 주고 받을 수 있 다. 메모리부의 구조에 대해서는 도 3을 참조하여 자세히 후술한다. 전처리부는 메모리부로부터 전달받은 특징 데이터를 전처리(pre-processing)하여 프로세서에게 전달한다. 전처리부는 프로세서로부터 커널 정보(커널 위치, 커널 크기 등) 및 특징 데이터 레이아웃 (feature data layout) 정보를 전달받은 뒤 특징 데이터 요청을 받으면, 멀티 레인 구조의 메모리부에게 특징 데이터를 요청한다. 여기서, 특징 데이터 레이아웃은 메모리부의 메모리 모듈 개수 및 각 메모리 모 듈 당 이미지 타일 개수를 포함한다. 메모리부로부터 특징 데이터를 병렬로 전달받아 전처리한 후 프로세 서에게 전달한다. 여기서, 전처리 작업은 데이터 시프팅(shifting) 및 마스킹(masking) 작업을 포함하며, 전처리부는 메모리부로부터 특징 데이터를 병렬적으로 읽어들이고, 특징 데이터 중 일부에 대해 시프 팅 및 마스킹 중 적어도 어느 하나를 수행하여 프로세서에게 병렬로 전송하거나, 시프팅 및 마스킹을 수행 하지 않고 그대로 프로세서에게 병렬로 전송할 수 있다. 여기서, 특징 데이터 중 일부란, 메모리부로부터 병렬적으로 읽어들인 특징 데이터 중 일부를 의미할 수 있다, 예컨대, 프로세서의 클럭(clock)에 따라 메모리부로부터 병렬적으로 읽어들인 특징 데이터 중 한 클럭에 해당하는 특징 데이터를 의미할 수 있다. 구체적으로, 한 클럭에 해당하는 특징 데이터 중 전부 또는 일부를 의미할 수 있다. 시프팅은 전처리부가 병렬적으로 읽어들인 특징 데이터 중 일부의 순서를 바꾸어 프로세서에게 전송 하는 것이다. 시프팅은 왼쪽 시프팅 및 오른쪽 시프팅(left-shifting and right-shfting)을 포함한다. 왼쪽 시 프팅 및 오른쪽 시프팅에 관해서는 후술한다. 한편, 마스킹은 전처리부가 병렬적으로 읽어들인 특징 데이터 중 일부에 대해 특징 데이터 대신 영(zero) 값을 프로세서에게 전송하는 것이다. 시프팅 및 마스킹은 특징맵(feature map)에서의 커널 크기, 커널 위치, 제로 패딩(zero-padding)의 유무 및 크 기, 특징 데이터 레이아웃 등의 조건에 따라 각 커널 마다 다르게 수행될 수 있다. 전처리부는 왼쪽 시프팅 및 오른쪽 시프팅을 포함하는 데이터 시프팅 및 마스킹 등의 오버헤드(overhead) 작업을 프로세서 대신 수행함으로써, 프로세서가 오버헤드 작업 없이 복수의 커널에 대한 병렬 연산 처리만 수행할 수 있도록 하여 신경망 연산 속도 및 효율을 높일 수 있다. 프로세서는 전처리부에게 신경망 연산에 필요한 커널 정보 및 특징 데이터 레이아웃 정보를 전달한 뒤 특징 데이터를 요청하며, 전처리부로부터 전달받은 특징 데이터를 이용하여 신경망 연산을 수행할 수 있다. 본 발명의 실시예에 따른 프로세서는 범용 프로세서(general processor), 벡터 프로세서(vector processor), 어레이 프로세서(array processor), 또는 행렬 프로세서(matrix processor) 등을 포함한다. 다만, 이에 한정되는 것은 아니다. 또한, 신경망 연산은 깊이 별 컨볼루션 연산 및 풀링 등 CNN계열의 연산 및 RNN계 열 연산을 포함한다.또한, 프로세서는 다양한 신경망 연산을 지원할 수 있도록 프로그래밍이 가능하다. 즉, 프로세서는 다양한 신경망을 지원할 수 있도록 전체 신경망 연산 중에서 연산량 비중은 적지만, 알고리즘의 변화가 필요한 연산을 별도의 프로세서 프로그래밍을 통하여 처리할 수 있다. 프로세서는 프로그램 메모리에 저장된 여러 코드들을 이용하여, CNN 연산 및 RNN 연산을 수행할 수 있다. 또한, 프로세서는 데이터 연산량이 많은 신경망을 실시간으로 처리하기 위하여, 특징 데이터를 복수의 커 널 데이터와 레지스터 번호 별로 병렬 연산할 수 있다. 여기서, 연산은 누적곱(multiply and accumulate, MAC) 연산을 포함한다. 연산량이 많은 작업은 깊이 별 합성곱(depth-wise convolution) 또는 비선형 활성화 함수 (non-linear activation function)를 이용한 활성화(activation), 풀링(pooling), 데이터 합병(data merge) 및 데이터 변형(data reshaping) 등을 포함한다. 또한, 프로세서는 벡터 프로세서 중 SIMD(single instruction multiple data) 또는 VLIW(very long instruction word)를 포함한다. 가속기 제어부는 신경망 가속기가 외부 메모리 및 외부 프로세서와 동작할 수 있도록 하며, 특히 외부 메모리의 특징 데이터가 메모리부로 전달되도록 제어할 수 있다. 연산부는 신경망에서 자주 사용되는 연산들을 빠르게 처리하여 추론(inference) 결과를 도출해내기 위한 주요 연산 전용 하드웨어이다. 연산부는 심층 신경망에서 주로 이용되는 CNN계열과 RNN계열에서 공통적으 로 사용되는 연산을 전용으로 빠르게 처리할 수 있다. 프로그램 메모리는 프로세서의 부팅 및 동작 등에 관한 코드가 저장되는 메모리이다. 프로그램 메모 리는 프로세서의 깊이 별 컨볼루션 연산 및 풀링 등의 동작에 관한 코드를 저장한다. 프로세서 가 특징 데이터를 요청하거나 레지스터 내의 특징 데이터를 커널 데이터와 연산 처리하기 위해 프로그램 메모리 에 저장된 코드를 이용할 수 있다. 이하에서는, 신경망 연산 중 CNN 계열의 깊이 별 컨볼루션 연산 과정을 중심으로 설명하지만, 본 발명의 실시예 에 따른 신경망 연산은 이에 한정되지 않고 최대/평균 풀링 및 엘리먼트 별 곱셈/덧셈 등을 포함할 수 있다. 또 한, 특징맵 상에서 커널 4개의 위치를 굵은 선으로 표시된 박스로 나타내며, 각 커널은 고정된 것이 아니며 스 트라이드 크기에 따라 움직일 수 있다. 특징 데이터는 각 메모리 모듈에 열 방향을 우선(column-major order)하 여 배치된 것으로 설명한다. 도 2a 및 도 2b는 제로 패딩 유무에 따른 깊이 별 컨볼루션 연산 과정을 설명하기 위한 도면이다. 도 2a는 제로 패딩의 크기가 0이고, 즉 제로 패딩이 적용되지 않는 경우 스트라이드(stride)의 크기가 1인 3Х3 깊이 별 컨볼루션 연산 과정 및 결과를 나타낸다. 여기서, 스트라이드는 특징맵 상에서 커널이 움직이는 간격이다. 예를 들면, 스트라이드 크기가 1인 경우 커널 이 특징맵 상에서 한 칸씩 움직이며 MAC 연산이 수행된다. 도 2a를 참조하면, 출력(output)의 9개 데이터는 특징 데이터에서 굵은 선으로 표시된 박스에 해당하는 9개의 데이터를 컨볼루션 커널(convolution kernel, 이하 '커널')의 9개 가중치 데이터와 각각 곱한 후, 모두 더한 데 이터이다. 예를 들면, 출력의 첫 번째 데이터인 107은 (1Х1 + 3Х7 + 7Х1 + 6Х4 + 2Х3 +8Х5 + 4Х2 + 5Х 0 + 0Х1)의 결과이다. 제로 패딩의 크기가 0인 경우, 출력 데이터 레이아웃 크기가 입력되는 특징 데이터의 레 이아웃 크기보다 작아지게 된다. 도 2b는 제로 패딩의 크기가 1이고, 스트라이드의 크기가 1인 3Х3 깊이 별 컨볼루션 연산 과정 및 결과를 나타 낸다. 출력(output)에서 16개의 데이터는 특징 데이터에서 굵은 선으로 표시된 박스에 해당하는 9개의 데이터를 커널의 9개 가중치 데이터와 각각 곱한 후, 모두 더한 데이터이다. 이때, 입력되는 특징맵의 외곽에 44개의 0이 있다고 가정(제로 패딩)하여 연산한다. 예를 들면, 출력의 첫 번째 데이터인 20은 (0Х1 + 0Х7 + 0Х1 + 0Х4 + 1Х3 + 3Х5 + 0Х2 + 6Х0 + 2Х1)의 결과이다. 제로 패딩을 적용한 경우, 출력 데이터 레이아웃 크기가 입 력되는 특징 데이터의 레이아웃 크기와 같아지게 된다. 도 3a, 도 3b, 도 3c, 도 3d 및 도 3e는 본 발명의 일 실시예에 따른 멀티 레인 구조의 메모리부 및 메모리부의 특징 데이터 레이아웃을 나타내는 메모리 모듈을 설명하기 위한 도면이다. 도 3a를 참조하면, 메모리부는 N 개의 데이터 레인을 가지며, 데이터 레인은 메모리부 내의 N개의 메 모리 모듈에 연결되어 있다. 각 메모리 모듈은 데이터 레인을 통하여 데이터를 송수신할 수 있다. 각 메모리 모 듈이 일 사이클 당 W개의 비트(bits)를 읽고 쓸 수 있을 때, 메모리부는 일 사이클 당 NХW 개의 비트를 읽고 쓸 수 있다. 즉, 메모리부는 NХW bits/cycle의 대역폭을 가지며, 하나의 레인을 가지는 일반적인 메모리에 비해 고-대역폭(high-bandwidth)을 가질 수 있다. 도 3b를 참조하면, 4개의 입력 특징맵은 각각 16개의 타일로 타일링(tiling)되며, 각 타일 마다 인덱스(index) 를 가진다. 각 타일 내에는 특징 데이터들이 저장된다. 특징 데이터의 저장 방식과 관련하여, 하나의 특징맵에 서 서로 다른 행에 위치한 특징 데이터들이 각 메모리 모듈에 저장될 수도 있고, 서로 다른 특징맵에서 같은 행 에 위치한 특징 데이터들이 각 메모리 모듈에 저장될 수도 있다. 도 3c는 하나의 입력 이미지(1 batch) A를 16개 타일로 타일링한 뒤 4개의 메모리 모듈(N=4)에 저장하는 메모리 레이아웃과 두 입력 이미지(2 batch) A 및 B를 타일링한 뒤 각 2개, 총 4개의 메모리 모듈(N=4)에 저장하는 메 모리 레이아웃을 나타낸다. 각 메모리 모듈은 데이터 레인을 통해 전처리부 또는 프로세서와 연결된다. 이하에서는, 입력 특징맵은 4개의 메모리 모듈에 저장된 타일 중 4개의 타일을 예시하며, 타일 내 총 64개의 특 징 데이터가 들어있으며, 각 특징 데이터 값은 임의로 설정한 것으로 설명한다. 4개의 타일은 이미지 A의 타일 4개일 수 있고, 이미지 A 타일 2개 및 B 타일 2개일 수 있다. 도 3d 및 도 3e를 참조하면, 하나의 입력 이미지를 타일링한 뒤 4개의 메모리 모듈에 저장하는 경우, 각 메모리 모듈의 데이터 배치 형태를 예시하고 있다. A 이미지가 도 3b와 같이 타일링되는 경우, A 이미지에 대한 특징맵 의 16개 타일 중 4개의 타일(A00, A10, A20, A30)은 서로 다른 메모리 모듈에 배치된다. 각 타일은 16개의 특징 데이터를 가지며 특징 데이터는 열(column) 방향을 우선으로 배치된다(column major order). 예를 들면, A00의 타일의 경우, Mem_0 메모리 모듈에 특징 데이터를 배치하며, 첫 번째 열에 있는 특징 데이터 1, 6, 4, 1이 각각 Mem_0의 0번, 1번, 2번, 3번 어드레스에 저장된다. 두 번째 열에 있는 특징 데이터 3, 2, 5, 7은 각각 Mem_1의 4번, 5번, 6번, 7번 어드레스에 저장된다. 나머지 타일인 A10, A20 및 A30의 경우에도 마찬가지로 특징 데이터 가 저장된다. 도 4a 내지 도 6b는 한 장의 입력 이미지 A를 타일링하고, 서로 다른 4개의 메모리 모듈에 배치한 후, 그 중 타 일 4개의 특징 데이터가 메모리 모듈에서 프로세서의 레지스터로 저장한 뒤 오버헤드 작업 과정을 설명하기 위 한 도면이다. 도 4a 및 도 4b는 커널 크기가 3Х3이고 제로 패딩 크기가 0일 때, 특징 데이터가 메모리 모듈에서 프로세서의 레지스터로 저장되는 과정을 설명하기 위한 도면이다. 도 4a 및 도 4b를 참조하면, 메모리 어드레스(memory address)는 각 메모리 모듈의 특징 데이터에 열 방향을 우 선으로 접근하기 위한 어드레스이다. 메모리 어드레스는 특징맵 상에서 커널이 위치한 굵은 선으로 표시된 박스 의 좌측 상단부터 열 방향으로 0부터 15까지 나타낼 수 있다. 예를 들면, Kernel_pos_0의 경우, 1, 6, 및 4는 각각 0번째, 1번째, 2번째이며, 3, 2, 및 5는 각각 4번째, 5번째, 6번째이고, 7, 8, 및 0은 각각 8번째, 9번째, 10번째이므로 메모리 어드레스 시퀀스는 0, 1, 2, 4, 5, 6, 8, 9, 10이다. 메모리 아웃풋(memory output)은 어드레스 시퀀스에 따라 각 메모리 모듈로부터 출력되는 특징 데이터의 순서를 나타낸 것이다. 각 메모리 모듈로부터 가장 왼쪽 상단에 있는 숫자가 가장 먼저 전달되며 총 9번의 사이클 (cycle)에 걸쳐서 전달된다. 벡터 레지스터(vector register)는 프로세서 내에 위치한 메모리로써, 메모리 모듈로부터 전달받은 특징 데이터 들을 저장한다. 각 커널의 첫 번째 열의 특징 데이터는 0번, 1번, 및 2번 레지스터에 저장되며, 두 번째 열의 특징 데이터는 3번, 4번, 및 5번 레지스터에 저장되며, 세 번째 열의 특징 데이터는 6번, 7번, 및 8번 레지스터 에 저장된다. 가장 상단에 있는 메모리 모듈의 데이터가 레지스터의 가장 오른쪽에 저장된다. 예를 들면, lane_0의 특징 데이터를 가장 오른쪽에 저장하고, lane_3의 특징 데이터를 가장 왼쪽에 저장할 수 있다. 프로세서가 신경망 연산 중 깊이 별 컨볼루션 연산을 하는 경우, 9개의 레지스터에 저장된 특징 데이터들은 커 널 데이터와 함께 MAC 연산이 수행된다. 프로세서는 총 9번의 MAC 연산을 수행하여, 결과적으로 4개의 커널을 연산한 결과를 도출해낼 수 있다. 이하에서는, 전처리부가 없는 경우, 특징 데이터가 메모리 모듈에서 프로세서의 레지스터로 저장되고, 시 프팅 또는 마스킹되는 과정을 설명한다. 도 5a 및 도 5b는 커널 크기가 3Х3이고 제로 패딩 크기가 1일 때, 특징 데이터가 메모리 모듈에서 프로세서의 레지스터로 저장되고, 왼쪽 시프팅 또는 마스킹되는 과정을 설명하기 위한 도면이다. 도 5a를 참조하면, 입력 특징맵 외곽에 값이 0인 총 14개의 엘리먼트(element)가 있다고 가정할 수 있다. 예를 들면, kernel_pos_0의 경우 4개의 특징 데이터가 사용되고, 5개의 엘리먼트들에 대해서는 가상의 0이 있는 것으 로 가정한다. 한편, kernel_pos_1, kernel_pos_2, kernel_pos_3의 경우, 5개의 특징 데이터가 사용되고, 커널 의 첫 번째 열에 해당하는 3개의 엘리먼트들에 대해서 가상의 0이 있는 것으로 가정하고 연산한다. 이때, kernel_pos_1, kernel_pos_2, kernel_pos_3의 경우, 각 커널의 첫 번째 행에 위치한 특징 데이터를 연산하기 위해서는 각 메모리 모듈의 위쪽에 인접한 메모리 모듈의 특징 데이터가 필요하기 때문에 데이터 시프팅이 필요 하다. 도 5a 및 도 5b를 참조하면, 각 커널의 첫 번째 열의 특징 데이터는 0번, 1번, 및 2번 레지스터에 저장된다. 제 로 패딩을 위해, 0번, 1번, 및 2번 레지스터는 데이터 값이 0으로 마스킹되어야 한다. 또한, 각 메모리 모듈의 위쪽에 인접한 메모리 모듈의 특징 데이터 값을 이용하기 위해, 3번 및 6번 레지스터는 왼쪽 시프팅되어야 한다. 또한, 시프팅 후 kernel_pos_0의 1행 2열 및 1행 3열 데이터를 제로 패딩하기 위해, 3번 및 6번 레지스터 의 가장 오른쪽 값을 0으로 마스킹하여야 한다. 따라서, 2번의 데이터 시프팅, 5번의 마스킹을 포함하여 총 7번 의 오버헤드 작업이 필요하다. 프로세서가 신경망 연산 중 깊이 별 컨볼루션 연산을 하는 경우, 4개의 커널에 대해 9번의 MAC 연산을 처리한다. 도 6a 및 도 6b는 커널 크기가 3Х3이고 제로 패딩 크기가 1일 때, 특징 데이터가 메모리 모듈에서 프로세서의 레지스터로 저장되고, 오른쪽 시프팅 또는 마스킹되는 과정을 설명하기 위한 도면이다. 도 6a 및 도 6b를 참조하면, kernel_pos_3의 경우 제로 패딩을 위해, 2번, 5번, 및 8번 레지스터의 가장 왼쪽은 데이터 값이 0으로 마스킹(masking)되어야 한다. kernel_pos_0, kernel_pos_1, kernel_pos_2의 경우, 각 커널 의 세 번째 행에 위치한 특징 데이터를 연산하기 위해서는 각 메모리 모듈의 아래쪽에 인접한 메모리 모듈의 특 징 데이터가 필요하기 때문에 데이터 시프팅이 필요하다. 구체적으로, 각 메모리 모듈의 아래쪽에 인접한 메모리 모듈의 특징 데이터 값을 이용하기 위해, 2번, 5번 및 8 번 레지스터는 오른쪽 시프팅되어야 한다. 또한, kernel_pos_3의 3행 2열 및 3행 3열에 제로 패딩하기 위해, 2 번, 5번 및 8번 레지스터의 가장 왼쪽 값을 0으로 마스킹하여야 한다. 따라서, 3번의 데이터 시프팅, 3번의 마 스킹을 포함하여 총 6번의 오버헤드 작업이 필요하다. 프로세서가 신경망 연산 중 깊이 별 컨볼루션 연산을 하 는 경우, 4개의 커널에 대해 9번의 MAC 연산을 처리한다. 도 7a 내지 도 8b는 두 장의 입력 이미지 A, B를 타일링하고, 서로 다른 4개의 메모리 모듈에 배치한 후, A 타 일 2개 및 B 타일 2개의 특징 데이터를 메모리 모듈에서 프로세서의 레지스터로 저장한 뒤 오버헤드 작업 과정 을 설명하기 위한 도면이다. kernel_pos_0 및 kernel_pos_1은 타일 A00 및 A10에 대한 커널을 나타내고, kernel_pos_2 및 kernel_pos_3은 타일 B00 및 B10에 대한 커널을 나타낸다. 도 7a 및 도 7b는 커널 크기가 3Х3이고, A 타일 및 B 타일의 제로 패딩 크기가 1일 때, 특징 데이터가 메모리 모듈에서 프로세서의 레지스터로 저장되고, 왼쪽 시프팅 또는 마스킹되는 과정을 설명하기 위한 도면이다. 도 7a 및 도 7b를 참조하면, 우선 4개 커널에 있어서, 공통적으로 첫 번째 열에 해당하는 특징 데이터를 0으로 설정해야한다. 개별적으로, Kernel_pos_0 및 kernel_pos_2는 제로 패딩에 의해 커널 일부가 이미지 타일의 바깥 쪽을 포함한다. 따라서, kernel_pos_0 및 kernel_pos_2의 경우, 커널 내의 (row, col) = (0, 1), 및 (0, 2)의 위치에 해당되는 특징 데이터를 0으로 설정해야한다. 한편, kernel_pos_1 및 kernel_pos_3의 경우 위쪽에 인접한 메모리 모듈에 포함되어 있는 특징 데이터를 신경망 연산에 필요로 한다. 즉, kernel_pos_1의 경우, 연산을 위해 A00 및 A10 타일에 있는 특징 데이터를 필요로 하 고, kernel_pos_3의 경우, B00 및 B10 타일에 들어 있는 데이터를 필요로 한다. 따라서, kernel_pos_1 및 kernel_pos_3의 경우, (row, col) = (0, 1), 및 (0, 2)의 위치에 해당되는 특징 데이터를 위쪽에 인접한 메모 리 모듈에 저장된 특징 데이터로 설정해야 한다. 구체적으로, 커널의 1열의 특징 데이터가 저장된 0번, 1번 및 2번 레지스터는 0으로 마스킹하고, 커널의 1행2열 및 1행3열의 특징 데이터가 저장된 3번 및 6번 레지스터에 대해서는 왼쪽 시프팅 및 마스킹 작업이 필요하다(도 5와 달리, 도 7에서는 두 장의 이미지를 동시에 처리하므로, 3번 및 6번 레지스터의 가장 오른쪽에서부터 첫 번 째 및 세 번째 위치에 0으로 마스킹한다). 프로세서가 신경망 연산 중 깊이 별 컨볼루션 연산을 하는 경우, 4개 의 커널에 대해 9번의 MAC 연산을 처리한다. 도 8a 및 도 8b는 커널 크기가 3Х3이고, A 타일 및 B 타일의 제로 패딩 크기가 1일 때, 특징 데이터가 메모리 모듈에서 프로세서의 레지스터로 저장되고, 오른쪽 시프팅 또는 마스킹되는 과정을 설명하기 위한 도면이다.도 8a 및 도 8b를 참조하면, Kernel_pos_1 및 kernel_pos_3은 제로 패딩에 의해 커널 일부가 이미지 타일의 바 깥쪽을 포함한다. 따라서, kernel_pos_1 및 kernel_pos_3의 경우, 커널 내의 (row, col) = (2, 0), (2, 1), 및 (2, 2)의 위치에 해당되는 특징 데이터를 0으로 설정해야한다. 한편, kernel_pos_0 및 kernel_pos_2의 경우 아래쪽에 인접한 메모리 모듈에 포함되어 있는 특징 데이터를 필요 로 한다. 즉, kernel_pos_0의 경우, 연산을 위해 A00 및 A10 타일에 있는 특징 데이터를 필요로 하고, kernel_pos_2의 경우, B00 및 B10 타일에 들어 있는 데이터를 필요로 한다. 따라서, kernel_pos_0 및 kernel_pos_2의 경우, (row, col) = (2, 0), (2, 1), 및 (2, 2)의 위치에 해당되는 특징 데이터를 아래쪽에 인 접한 메모리 모듈에 저장된 특징 데이터로 설정해야 한다. 구체적으로, Kernel_pos_0 및 Kernel_pos_2를 참조하면, 2번, 5번 및 8번 레지스터를 오른쪽 시프팅하고, Kernel_pos_1 및 Kernel_pos_3을 참조하면, 2번, 5번 및 8번 레지스터의 두 번째 및 네 번째 데이터를 0으로 마스킹해야한다. 따라서 데이터 시프팅 및 마스킹 작업을 하기 위해 총 6번의 동작이 필요하다. 그 후, 프로세 서가 신경망 연산 중 깊이 별 컨볼루션 연산을 하는 경우, 4개의 커널에 대해 9번의 MAC 연산을 처리한다. 도 9a 내지 도 9c는 본 발명의 일 실시예에 따른 전처리부의 구성 및 전처리부에 포함된 읽기 데이터 정렬부의 구성을 예시하는 도면이다. 도 9a를 참조하면, 전처리부는 제어부, 어드레스 시퀀스 생성기(address sequence generator, 910), 멀티플렉서 제어 시퀀스 생성기(multiplexer control sequence generator, 920), 및 읽기 데이터 정렬부(read data alignment module, 930)을 포함한다. 제어부는 프로세서로부터 커널 정보 및 특징 데이터 레이아웃 정보를 전달받을 수 있으며, 프로세서 로부터 특징 데이터 요청을 받으면, 어드레스 시퀀스 생성기에게 어드레스 시퀀스 생성을 명령하며, 멀티플렉서 제어 시퀀스 생성기를 통하여 프로세서에게 특징 데이터를 전달하도록 명령할 수 있다. 어드레스 시퀀스 생성기는 커널의 크기, 제로 패딩, 스트라이드 크기 및 특징 데이터 레이아웃 등을 고려 하여, 특징 데이터가 저장된 메모리에 접근하기 위한 어드레스 시퀀스를 생성한다. 어드레스 시퀀스는 각 커널 의 위치에 대응되는 특징 데이터에 순서대로 접근하기 위한 어드레스 배열이다. 전처리부가 프로세서(12 0)로부터 커널 정보 및 특징 데이터 레이아웃 정보를 전달 받으면, 제어부의 명령에 의해 어드레스 시퀀스 생성기는 어드레스 레지스터와 카운터를 초기화한다. 여기서, 어드레스 레지스터와 카운터는 어드레스 시 퀀스 생성기에 포함된 구성요소이다. 전처리부가 프로세서로부터 특징 데이터 요청을 받으면, 어드레스 시퀀스 생성기는 특징 데이터가 저장된 메모리부에 접근하기 위한 메모리 어드레스 시퀀스를 생 성하고, 전처리부는 어드레스 시퀀스를 이용하여 메모리부로부터 특징 데이터를 시퀀스 순서에 따라 전달받는다. 멀티플렉서 제어 시퀀스 생성기는 읽기 데이터 정렬부가 메모리부의 각 메모리 모듈로부터 전달 받은 특징 데이터를 선택적으로 프로세서에게 전달하도록 제어 신호를 생성하는 구성요소이다. 멀티플렉서 제어 시퀀스 생성기는 각 메모리 모듈의 레인에 연결된 mux를 제어하는 신호를 생성한다. 이 신호가 읽기 데이터 정렬부로 전달되어 데이터 시프팅 및 마스킹 작업이 수행된다. 읽기 데이터 정렬부는 메모리부로부터 전달받은 특징 데이터를 커널의 위치, 커널의 크기, 제로 패딩, 스트라이드 크기 및 특징 데이터 레이아웃 등을 고려하여, 데이터 시프팅 또는 마스킹 중 어느 하나 이상 을 수행하는 구성요소이다. 도 9b를 참조하면, 읽기 데이터 정렬부가 멀티플렉서(multiplxer: mux)를 이용하여 각 메모리 모듈의 특징 데이터를 선택적으로 전달하기 위한 mux 구조를 나타낸다. Mux는 제로 패딩을 위해 0을 출력하거나, 특징 데이 터를 그대로 출력하거나, 인접한 메모리 모듈의 특징 데이터를 출력하기 위해 사용된다. mux_sel의 값이 0일 때 해당 레인으로 전달된 그대로 데이터를 출력하고, mux_sel의 값이 1일 때 0을 출력하고, mux_sel의 값이 2일 때 위쪽 레인으로 전달된 데이터를 출력하며, mux_sel의 값이 3일 때 아래쪽 레인으로 전달된 데이터를 출력한다. 도 9c를 참조하면, 읽기 데이터 정렬부의 내부 구조가 도시되어 있다. 읽기 데이터 정렬부는 특징 데 이터 시프팅 또는 마스킹을 위해 각 메모리 모듈로부터 병렬적으로 전달받은 특징 데이터를 선택하여 프로세서 에게 전송할 수 있다. 예를 들면, 4개의 메모리 모듈 및 레인을 이용하여 특징 데이터를 전처리하기 위하 여 4-입력의 멀티플렉서(mux)가 사용한다. 첫 번째 mux의 경우, 첫 번째 메모리 모듈의 레인인 rdata_lane_0 및 인접한 메모리 모듈의 레인인 rdata_lane_1이 입력으로 사용되고, 나머지 두 입력은 제로 패딩을 위해 0을 입력으로 설정한다. rdout_lane_0로 출력하기 위해서는, 데이터 시프팅이 필요하지 않으므로, mux_sel_0의 값을 0으 로 설정하면 rdata_lane_0이 출력된다. 반면, 첫 번째 메모리 모듈의 아래쪽 메모리 모듈의 특징 데이터가 필요 한 경우 mux_sel_0의 값을 3으로 설정하면 rdata_lane_1이 출력된다. 제로 패딩을 위해 마스킹이 필요한 경우, mux_sel_0의 값을 1로 설정하면 0(zero)이 rdout_lane_1으로 출력되어 프로세서에 저장된다. 이하에서는, 전처리부의 왼쪽 시프팅 및 오른쪽 시프팅을 설명한다. 왼쪽 시프팅은 전처리부가 각 메모리 모듈로부터 병렬적으로 전달받은 특징 데이터를 각 메모리 모듈의 위 쪽에 위치한 메모리 모듈로부터 전달받은 특징 데이터로 바꾸어 프로세서에게 전송하는 것으로써, 결과적 으로 프로세서 내 레지스터에 특징 데이터를 저장한 뒤 왼쪽 시프팅한 것과 같은 결과를 저장할 수 있다. 오른쪽 시프팅은 전처리부가 각 메모리 모듈로부터 병렬적으로 전달받은 특징 데이터를 각 메모리 모듈의 아래쪽에 위치한 메모리 모듈로부터 전달받은 특징 데이터로 바꾸어 프로세서에게 전송하는 것으로써, 결 과적으로 프로세서 내 레지스터에 특징 데이터를 저장한 뒤 오른쪽 시프팅한 것과 같은 결과를 저장할 수 있다. 도 10a 내지 도 13b는 본 발명의 실시예에 따른 전처리부가 있는 경우, 전처리부가 메모리 모듈로부 터 전달받은 특징 데이터를 시프팅 또는 마스킹한 후 프로세서의 레지스터에 저장하는 과정을 설명한다. 도 9c 내지 10b를 참조하면, 도 5a와 같은 조건에서, 전처리부의 특징 데이터 왼쪽 시프팅 및 마스킹 과정을 나 타낸다. 우선 제로 패딩을 위해, 공통적으로 4개 커널의 첫 번째 열에 해당하는 데이터들을 0으로 마스킹한다. 그리고 각 커널의 (row, col) = (0, 1) 및 (0, 2) 위치에 해당하는 데이터에 있어서는, Kernel_pos_0의 경우 0으로 마 스킹하고, Kernel_pos_1, Kernel_pos_2 및 Kernel_pos_3의 경우 각 메모리 모듈의 위쪽에 인접한 메모리 모듈 의 특징 데이터를 이용하기 위해 왼쪽 시프팅이 필요하다. 구체적으로, 커널의 첫 번째 열에 해당하는 0번, 1번 및 2번 레지스터를 0으로 마스킹하기 위해, mux_sel_{0, 1, 2, 3}의 값을 1로 함으로써 rdout_lane_0, rdout_lane_1, rdout_lane_2 및 rdout_lane_3에 모두 0이 출력된 다. 한편, 3번 및 6번 레지스터는 위쪽 메모리 모듈의 특징 데이터를 이용하기 위해, mux_sel_{0, 1, 2, 3}의 값을 2로 함으로써, rdout_lane_0, rdout_lane_1, rdout_lane_2 및 rdout_lane_3에는 각각 0, rdata_lane_0, rdata_lane_1 및 rdata_lane_2가 출력된다. 나머지 레지스터는 특징 데이터를 그대로 보내기 위해, mux_sel_{0, 1, 2, 3}의 값을 0으로 한다. 예를 들면, 3번 레지스터에 저장될 0-8-5-1 값들이 전처리부에 의해 8-5-1-0으로 저장된다. 레지스터에 0-8-5-1 값들을 저장한 후 왼쪽 시프팅 및 마스킹한 것과 같은 결과이 다. 도 9c, 도 11a 및 도 11b를 참조하면, 도 6a와 같은 조건에서, 전처리부의 특징 데이터 오른쪽 시프팅 및 마스 킹 과정을 나타낸다. 2번, 5번 및 8번 레지스터는 아래쪽 메모리 모듈의 특징 데이터를 이용하기 위해, mux_sel_{0, 1, 2, 3}의 값을 3으로 함으로써, rdout_lane_0, rdout_lane_1, rdout_lane_2 및 rdout_lane_3에 는 각각 rdata_lane_1, rdata_lane_2, rdata_lane_3 및 0이 출력된다(mux_sel_3의 경우 마스킹을 위해 값을 1 로 설정할 수도 있다). 나머지 레지스터는 특징 데이터를 그대로 보내기 위해, mux_sel_{0, 1, 2, 3}의 값을 0 으로 한다. 도 9c, 도 12a 및 도 12b를 참조하면, 도 7a와 같은 조건에서, 전처리부의 특징 데이터 왼쪽 시프팅 및 마스킹 과정을 나타낸다. lane_0 및 lane_1에는 이미지 A의 타일이 배치되고, lane_2 및 lane_3에는 이미지 B의 타일이 배치된다. 우선 제로 패딩을 위해, 공통적으로 4개 커널의 첫 번째 열에 해당하는 데이터들을 0으로 마스킹한다. 그리고 각 커널의 (row, col) = (0, 1) 및 (0, 2) 위치에 해당하는 데이터에 있어서, Kernel_pos_0 및 Kernel_pos_2의 경우 0으로 마스킹하고, Kernel_pos_1 및 Kernel_pos_3의 경우 아래쪽에 인접한 메모리 모듈의 특징 데이터를 이용하기 위해 오른쪽 시프팅이 필요하다. 구체적으로, 0번, 1번 및 2번 레지스터를 0으로 마스킹하기 위해, mux_sel_{0, 1, 2, 3}의 값을 1로 함으로써 rdout_lane_0, rdout_lane_1, rdout_lane_2 및 rdout_lane_3에 0이 출력된다. 한편, 3번 및 6번 레지스터는 제 로 패딩 및 위쪽 메모리 모듈의 특징 데이터 이용을 위해, mux_sel_{0, 1, 2, 3}의 값을 {2, 2, 1, 2}로 설정 함으로써, rdout_lane_0, rdout_lane_1, rdout_lane_2 및 rdout_lane_3에는 각각 0, rdata_lane_0, 0 및 rdata_lane_2가 출력된다(mux_sel_0의 값을 1로 해도 마스킹이 수행된다). 나머지 레지스터는 특징 데이터를 그대로 보내기 위해, mux_sel_{0, 1, 2, 3}의 값을 0으로 한다. 예를 들면, 3번 레지스터에 저장될 0-8-5-1 값들 이 전처리부에 의해 8-0-1-0으로 저장된다. 레지스터에 0-8-5-1 값들을 저장한 후 왼쪽 시프팅 및 마스킹 한 것과 같은 결과이다. 도 9c, 도 13a 및 도 13b를 참조하면, 도 8a와 같은 조건에서, 전처리부의 특징 데이터 오른쪽 시프팅 및 마스 킹 과정을 나타낸다. 2번, 5번 및 8번 레지스터는 제로 패딩 및 아래쪽 메모리 모듈의 특징 데이터를 이용하기 위해, mux_sel_{0, 1, 2, 3}의 값을 {3, 1, 3, 1}로 설정함으로써, rdout_lane_0, rdout_lane_1, rdout_lane_2 및 rdout_lane_3에는 각각 rdata_lane_1, 0, rdata_lane_3 및 0이 출력된다(mux_sel_3의 경우 마스킹을 위해 값을 3으로 설정할 수도 있다). 나머지 레지스터는 특징 데이터를 그대로 보내기 위해, mux_sel_{0, 1, 2, 3}의 값을 0으로 한다. 표 1 w/o data transfer unit w/ data transfer unit Single batch, tiled image Multi batch 도 4도 5 도 6 도 7 도 8 도 10 내지 도 13 Computation# of MAC 9 9 9 9 9 9 # of overhead operations(shift, mask)0 7 (=3+2×2)6 (=3Х2)7 (=3+2×2)6 (=2Х3)0 Comp_total 9 16 15 16 15 9 Address # of Initialize operations for start address1 2 2 2 2 0 # of operations for column start address update3 6 (=3Х2)6 (=3Х2)6 (=3Х2)6 (=3Х2)0 # of overhead operations0 0 0 0 0 1 Addr_total 4 8 8 8 8 1 MAC UtilizationMAC/ Comp_total1 0.56 0.6 0.56 0.6 1 MAC /(Comp_total + Addr_total)0.690.38 0.39 0.38 0.39 0.90 표 1은 3Х3 깊이 별 컨볼루션 연산 과정에서 전처리부의 유무에 따른 컨볼루션 연산 효율을 비교하여 설명하기 위한 표이다. 표 1을 참조하면, Computation 항목은 멀티 레인 구조의 메모리부로부터 프로세서의 레지스터에 특징 데이터를 저장하고, 3Х3 깊이 별 컨볼루션 연산에 필요한 총 연산의 수를 나타낸다. '# of MAC'항목은 프로세서가 9개의 레지스터에 저장된 특징 데이터를 커널 데이터와 MAC 연산하는 횟수를 나타 낸다. 도 4 내지 도 11을 참조하면, 3Х3 깊이 별 컨볼루션 연산 과정에서, 프로세서가 9개의 레지스터에 저장 된 데이터에 대해 MAC 연산을 실시하므로 횟수가 9이다. '# of overhead operation'은 레지스터 번호 별로 데이터 시프팅 및 마스킹 작업 횟수를 나타낸다. 도 4 내지 도 9를 참조하면, 커널 위치, 커널 크기 및 특징 데이터 레이아웃을 고려하여 시프팅 및 마스킹 횟수가 정해진 다. 도 10 및 도 11을 참조하면, 특징 데이터가 레지스터에 저장되기 전 전처리부에 의해 데이터 시프팅 및 마 스킹되므로 횟수가 0이다. Address 항목은 멀티 레인 구조의 메모리부에 접근하는 데 필요한 메모리 어드레스를 생성 및 갱신하는데 필요한 연산의 수를 나타낸다. Address 항목에서는, 복수의 기준 레지스터(base register)를 갱신하는 것으로 가정하고, 이 갱신에 대해서는 오버헤드 연산 수로 카운트하지 않는다. 또한, 어드레스 레지스터 초기값 설정 및 열(column)의 변경에 따라 스트라이드 값을 추가하는 것으로 가정한다. 또한, 둘 이상의 메모리 모듈로부터 특징 데이터를 전달받는 경우, 둘 이상의 메모리 모듈에 대한 메모리 어드레스를 관리하기 위해 둘 이상의 어드 레스 레지스터를 이용한다고 가정한다. '# of Initialize operations for start address'항목은 메모리 어드레스 시퀀스 생성 전 초기화 작업 횟수를 나타낸다. 도 4, 도7, 도 8 및 도 9를 참조하면, 하나의 메모리 모듈에 접근하기 위한 메모리 어드레스 초기화 가 1번 필요하며, 도 5 및 도 6을 참조하면 두 메모리 모듈에 접근하기 위해 메모리 어드레스 초기화 과정이 2 번 필요하다. '# of operations for column start address update'항목은 각 열(column) 방향마다 어드레스를 갱신하는 횟수 를 나타낸다. 3Х3 깊이 별 컨볼루션 연산과정에서, 도 4, 도7, 도 8, 및 도 9를 참조하면, 3개의 열을 이용하 므로 어드레스를 3회 갱신하며, 도 5 및 도 6을 참조하면 2개의 메모리 모듈 및 3개의 열을 이용하므로 총 6회 갱신한다. '# of overhead operations'항목은 본 발명의 실시예에 따라, 전처리부가 현재 커널 위치의 위치에서 다음 커널 위치로 어드레스를 갱신하는 횟수를 나타낸다. 도 4 내지 도 9를 참조하면 전처리부가 없으므로 횟수가 0 이며, 도 10 및 도 11을 참조하면 전처리부를 이용하며 인접한 메모리 모듈에 접근하도록 어드레스를 1회 갱신 한다. 따라서, MAC utilization 항목을 참조하면, 전처리부를 이용하지 않는 경우, Computation 항목에서 필요한 작업과 Address 항목에서 필요한 작업이 동시에 수행 가능한 경우에는 프로세서의 MAC utilization(MAC 연산 이 용률)은 56%, 동시에 수행이 가능하지 않은 경우에는 38%로 제한된다. 반면, 전처리부를 이용하는 경우, 프로세서의 MAC utilization은 90% 이상으로 향상되는 효과가 있다. 도 14는 본 발명의 일 실시예에 따른 캐시를 포함하는 전처리부의 구성, 메모리부 및 프로세서를 예시한 도면이 다. 도 14를 참조하면, 캐시(cache, 1400)을 제외한 구성은 도 9a에서 자세히 설명하였으니 생략한다. 이하에서, 커 널 연산은 커널 위치에 해당하는 특징 데이터에 대해 신경망 연산을 수행하는 것이며, 깊이 별 컨볼루션 연산을 포함하나 이에 한정되는 것은 아니다. 캐시는 전처리부 내에 위치하고, 커널 크기, 커널 위치 및 스트라이드 크기에 따라서, 현재 커널 연 산에 사용한 특징 데이터 중 다음 커널 연산에도 사용되는 특징 데이터를 저장하고, 다음 커널 연산에 사용되는 특징 데이터 중 상기 캐시에 저장된 특징 데이터와 동일한 특징 데이터가 상기 메모리부에 존재하는 경우, 다음 커널 연산 시 메모리부가 아닌 상기 캐시에 저장된 특징 데이터를 사용한다. 이는, 전처리부가 특징 데이터를 메모리부로부터 전달받는 것이 아니라 캐시로부터 읽어 사용 함으로써, 메모리부에 접근하는데 필요한 대역폭을 줄이기 위함이다. 또한, 캐시는 커널 크기, 커널 위치 및 스트라이드 크기 등의 정보를 활용하면, 캐시에 저장된 특 징 데이터 중 다음 커널 연산에 사용되지 않는 데이터의 위치를 알 수 있다. 따라서, 캐시는 특징 데이터 를 저장할 때, 현재 커널 연산에 사용한 특징 데이터 중 다음 커널 연산에 사용되는 특징 데이터가 저장되지 않 은 위치에 저장하여 캐시의 적중률(hit ratio)을 높일 수 있다. 따라서, 다음 커널 연산에 사용되는 데이터가 저장된 위치가 아닌 다른 위치를 우선적으로 선택하여 새로운 데 이터를 저장한다면, LRU(least recently used)와 같은 캐시 교체 정책보다 캐시의 hit ratio를 높일 수 있다. 도 15는 본 발명의 일 실시예에 따른 프로세서가 컨볼루션 연산 과정에서 수행하는 동작들을 설명하기 위한 도 면이다. 프로세서는 커널 크기, 커널 위치 등 커널에 대한 정보 및 특징 데이터 레이아웃에 대한 정보를 전처리부 에게 전달한다(S1502). 프로세서는 전처리부에게 특징 데이터를 요청한다(S1504). 이는, 프로세서가 컨볼루션 연산을 수행하기 위함이다. 프로세서는 전처리부로부터 데이터 시프팅 및 마스킹된 특징 데이터를 전달받는다(S1506). 특징 데이 터의 데이터 시프팅 및 마스킹 작업은 각 커널들의 위치 및 제로 패딩 등의 조건에 따라 전처리부에 의해 수행된다. 프로세서가 전처리부에게 요청한 특징 데이터를 전부 전달 받았는지 여부를 판단한다(S1508). 프로세 서가 전처리부로부터 요청한 모든 특징 데이터를 전달받지 못하였다면, 다시 전처리부로부터 특 징 데이터를 전달받는다.반면, 프로세서가 전처리부로부터 특징 데이터를 모두 전달받는다면, 프로세서는 전처리부(11 0)로부터 받은 특징 데이터를 복수의 커널 데이터와 병렬적으로 MAC 연산을 수행한다(S1510). 프로세서는 특징 데이터를 커널 데이터와 MAC 연산 처리한 결과를 프로세서 내에 위치한 레지스터에 저장한다(S1512). 도 16은 본 발명의 일 실시예에 따른 전처리부가 메모리부터 읽어들인 특징 데이터를 전처리하여 프로세서에게 전달하는 동작들을 설명하기 위한 도면이다. 전처리부는 프로세서로부터 커널 위치, 커널 크기 및 특징 데이터 레이아웃 정보를 전달받는다 (S1602). 전처리부가 여러 정보를 전달 받으면, 전처리부 내에 위치한 어드레스 시퀀스 생성기가 어드레 스 생성에 사용되는 어드레스 레지스터와 카운터를 초기화한다(S1604). 이는, 어드레스 시퀀스 생성기가 메모리 어드레스 시퀀스를 생성하기 위한 과정이다. 전처리부는 프로세서로부터 특징 데이터 요청을 받았는지 여부를 판단한다(S1606). 전처리부가 프로세서로부터 특징 데이터 요청을 받지 못했다면, 전처리부는 프로세서로부 터 특징 데이터 요청을 받았는지 여부를 다시 판단하는 과정을 반복한다. 전처리부가 프로세서로부터 특징 데이터 요청을 받았다면, 전처리부 내의 어드레스 시퀀스 생성 기는 특징 데이터가 위치한 메모리 모듈에 접근하기 위한 메모리 어드레스 시퀀스를 생성한다(S1608). 어드레스 시퀀스 생성기가 생성한 메모리 어드레스 시퀀스를 메모리부로 전달함으로써, 전처리부 가 메모리부에게 특징 데이터를 어드레스 시퀀스에 따라 순서대로 요청한다(S1610). 전처리부가 메모리부로부터 요청한 특징 데이터를 전달받고, 전처리부는 메모리부로부터 전달받은 특징 데이터에 대해 데이터 시프팅 및 마스킹 작업을 수행한다(S1612). 데이터 시프팅 및 마스킹 작업 은 각 커널들의 위치 및 제로 패딩 등의 조건에 따라 다르게 수행된다. 그 후, 전처리부는 프로세서가 MAC 병렬 연산을 처리할 수 있도록 데이터 시프팅 및 마스킹 작업이 수행된 특징 데이터를 프로세서에게 전달한다(S1614). 도 17은 본 발명의 실시예에 따른, 프로세서, 전처리부 및 메모리부의 동작 및 전달되는 정보를 순서대로 나타 낸다. 우선, 프로세서는 전처리부에게 커널 위치 및 커널 크기를 포함하는 커널 정보 및 메모리 모듈에 저 장된 이미지의 특징 데이터 레이아웃 정보를 전달한다(S1702). 여기서, 레이아웃 정보는 이미지 내에 위치한 특 징맵의 위치, 특징맵의 크기 및 multi-batching 여부를 포함한다. 전처리부는 어드레스 시퀀스 생성기를 이용하여, 메모리 모듈에 저장된 특징 데이터 중 연산에 필요 한 특징 데이터의 위치의 어드레스 시퀀스를 생성한다. 전처리부는 메모리부에게 메모리 어드레스 및 특징 데이터 요청을 전달한다(S1704). 메모리부는 메모리 어드레스에 저장된 특징 데이터들을 읽기 유효 신호(read_valid signal)과 함께 전처리 부에게 전달한다(S1706). 전처리부 내의 멀티플렉서 제어 시퀀스 생성기는 커널 정보 및 특징 데이터 레이아웃 등을 고려하여, 메모리부로부터 전달받은 특징 데이터를 시프팅 및 마스킹 중 어느 하나 이상의 작업을 수행할 것을 결정 하고, 읽기 데이터 정렬부에 연결된 mux를 제어하도록 신호를 생성한다. 전처리부는 데이터 시프팅 및 마스킹 작업을 거친 특징 데이터들을 프로세서로 전달한다(S1708). 프 로세서에 전달된 특징 데이터들은 프로세서 내의 레지스터에 저장된다. 도 15 및 도 17에서는 과정 S1502 내지 과정 S1708을 순차적으로 실행하는 것으로 기재하고 있으나, 이는 본 발 명의 일 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것이다. 다시 말해, 본 발명의 일 실시예가 속하 는 기술 분야에서 통상의 지식을 가진 자라면 본 발명의 일 실시예의 본질적인 특성에서 벗어나지 않는 범위에 서 도 15 및 도 17에 기재된 순서를 변경하여 실행하거나 과정 S1502 내지 과정 S1708 중 하나 이상의 과정을 병렬적으로 실행하는 것으로 다양하게 수정 및 변형하여 적용 가능할 것이므로, 도 6은 시계열적인 순서로 한정되는 것은 아니다. 한편, 도 15 및 도 17에 도시된 과정들은 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 즉, 컴퓨터가 읽을 수 있는 기록매체는 마그네틱 저장매체(예를 들 면, 롬, 플로피 디스크, 하드디스크 등) 및 광학적 판독 매체(예를 들면, 시디롬, 디브이디 등)와 같은 저장매 체를 포함한다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어 분산방식 으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2019-0069113", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 신경망 가속기를 포함한 전체 시스템을 도시한 도면이다. 도 2a 및 도 2b는 제로 패딩 유무에 따른 깊이 별 컨볼루션 연산 과정을 설명하기 위한 도면이다. 도 3a 내지 도 3e는 본 발명의 일 실시예에 따른 멀티 레인 구조의 메모리부 및 메모리부의 특징 데이터 레이아 웃을 나타내는 메모리 모듈을 설명하기 위한 도면이다. 도 4a 내지 도 6b는 한 장의 입력 이미지 A를 타일링(tiling)하고, 서로 다른 4개의 메모리 모듈에 배치한 후, 그 중 타일 4개의 특징 데이터를 메모리 모듈에서 프로세서의 레지스터로 저장한 뒤 오버헤드 작업 과정을 설명 하기 위한 도면이다. 도 7a 내지 도 8b는 두 장의 입력 이미지 A, B를 타일링하고, 서로 다른 4개의 메모리 모듈에 배치한 후, A 타 일 2개 및 B 타일 2개의 특징 데이터를 메모리 모듈에서 프로세서의 레지스터로 저장한 뒤 오버헤드 작업 과정 을 설명하기 위한 도면이다. 도 9a 내지 도 9c는 본 발명의 일 실시예에 따른 전처리부의 구성 및 전처리부에 포함된 읽기 데이터 정렬부의 구성을 예시하는 도면이다. 도 10a 내지 도 13b는 본 발명의 실시예에 따른 전처리부가 있는 경우, 전처리부가 메모리 모듈로부터 전달받은 특징 데이터를 시프팅 또는 마스킹한 후 프로세서의 레지스터에 저장하는 과정을 설명한다. 도 14는 본 발명의 일 실시예에 따른 캐시를 포함하는 전처리부의 구성, 메모리부 및 프로세서를 예시한 도면이 다. 도 15는 본 발명의 일 실시예에 따른 프로세서가 컨볼루션 연산 과정에서 수행하는 동작들을 설명하기 위한 도 면이다. 도 16은 본 발명의 일 실시예에 따른 전처리부가 메모리부터 읽어들인 특징 데이터를 전처리하여 프로세서에게 전달하는 동작들을 설명하기 위한 도면이다. 도 17은 본 발명의 실시예에 따른, 프로세서, 전처리부 및 메모리부의 동작 및 전달되는 정보를 순서대로 나타 낸다."}
