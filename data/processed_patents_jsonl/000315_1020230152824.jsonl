{"patent_id": "10-2023-0152824", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0056739", "출원번호": "10-2023-0152824", "발명의 명칭": "캐리커처 생성 방법 및 장치", "출원인": "경북대학교 산학협력단", "발명자": "정순기"}}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 처리 장치가 얼굴 영상을 획득 받는 단계; 상기 영상 처리 장치가 상기 얼굴 영상을 캐리커처 생성 모델에 입력하는 단계; 상기 영상 처리 장치가 상기 캐리커처 생성 모델의 출력값을 기반으로 상기 얼굴 영상에 대한 캐리커처 영상을출력하는 단계;를 포함하되,상기 캐리커려 생성 모델은 상기 얼굴 영상에서 눈과 입의 크기가 변형된 영상을 생성하는 모델인, 캐리커처 생성 방법."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 캐리커처 생성 모델은 학습 데이터 구축 모듈이 구축한 학습 데이터를 기반으로 학습된 모델이고, 상기 학습 데이터 구축 모듈은 학습 데이터 얼굴 영상에서 안경 마스크를 생성 한 뒤, 상기 안경 마스크를 기반으로 상기 학습 데이터 얼굴 영상에서 안경을 제거하고, 상기 안경이 제거된 학습 데이터 얼굴 영상의 눈과 입을 변형 시킨 뒤, 상기 안경 마스크를 기반으로 상기 눈과 입이 변형된 학습 데이터 얼굴 영상에 안경을 다시부여하는, 캐리커처 생성 방법."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 얼굴 영상의 눈과 입을 변형시키는 것은 상기 얼굴 영상에서 눈과 입을 구성하는 랜드마크 포인트를 찾은뒤, 상기 랜드마크 포인트를 기반으로 상기 눈과 입의 크기를 미리 설정 된 비율만큼 스케일링하는 것을 포함하는, 캐리커처 생성 방법. 캐리커처 생성 방법."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 캐리커처 생성 모델은 상기 생성된 눈과 입의 크기가 변형된 영상에 상기 입력 받은 얼굴 영상의 배경(Background)을 블랜딩(Blending)하여 상기 캐리커처 영상을 생성하는, 캐리커처 생성 방법."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 캐리커처 생성 모델은 매핑 네트워크(Mapping Network, f) 및 합성 네트워크(Synthesis network, g)를 포함하고, 상기 매핑 네트워크는 잠재 코드로부터 disentanglement 한 style 특징을 추출하고, 상기 합성 네트워크는 상기 disentanglement 한 style 특징 및 노이즈를 기반으로 캐리커처 영상을 생성하는,캐리커처 생성 방법."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 캐리커처 생성 모델은 피라미드 네트워크(Pyramid Network)형태를 가지며, 상기 캐리커처 생성 모델은 각 해상도의 단계에서 매핑 네트워크(Mapping Network)을 통해 스타일 특징을 추출공개특허 10-2025-0056739-3-하고, 상기 캐리커처 생성 모델은 상기 추출한 스타일 특징을 기반으로 캐리커처 영상을 생성하는, 캐리커처 생성 방법."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "얼굴 영상을 입력 받은 입력 장치; 상기 얼굴 영상을 캐리커처 생성 모델에 입력하고, 상기 캐리커처 생성 모델의 출력값을 기반으로 상기 얼굴 영상에 대한 캐리커처 영상을 출력하는 연산장치 및 상기 얼굴 영상 및 상기 캐리커처 생성 모델을 저장하는 저장장치; 를 포함하되, 상기 캐리커려 생성 모델은 상기 얼굴 영상에서 눈과 입의 크기가 변형된 영상을 생성하는 모델인, 캐리커처 생성 장치."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 캐리커처 생성 모델은 학습 데이터 구축 모듈이 구축한 학습 데이터를 기반으로 학습된 모델이고, 상기 학습 데이터 구축 모듈은 학습 데이터 얼굴 영상에서 안경 마스크를 생성 한 뒤, 상기 안경 마스크를 기반으로 상기 학습 데이터 얼굴 영상에서 안경을 제거하고, 상기 안경이 제거된 학습 데이터 얼굴 영상의 눈과 입을 변형 시킨 뒤, 상기 안경 마스크를 기반으로 상기 눈과 입이 변형된 학습 데이터 얼굴 영상에 안경을 다시부여하는, 캐리커처 생성 장치."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 얼굴 영상의 눈과 입을 변형시키는 것은 상기 얼굴 영상에서 눈과 입을 구성하는 랜드마크 포인트를 찾은뒤, 상기 랜드마크 포인트를 기반으로 상기 눈과 입의 크기를 미리 설정된 비율만큼 스케일링하는 것을 포함하는, 캐리커처 생성 장치. 캐리커처 생성 장치."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 캐리커처 생성 모델은 상기 생성된 눈과 입의 크기가 변형된 영상에 상기 입력 받은 얼굴 영상의 배경(Background)을 블랜딩(Blending)하여 상기 캐리커처 영상을 생성하는, 캐리커처 생성 장치."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 캐리커처 생성 모델은 매핑 네트워크(Mapping Network, f) 및 합성 네트워크(Synthesis network, g)를 포함하고, 상기 매핑 네트워크는 잠재 코드로부터 disentanglement 한 style 특징을 추출하고, 상기 합성 네트워크는 상기 disentanglement 한 style 특징 및 노이즈를 기반으로 캐리커처 영상을 생성하는,캐리커처 생성 장치."}
{"patent_id": "10-2023-0152824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 캐리커처 생성 모델은 피라미드 네트워크(Pyramid Network)형태를 가지며, 상기 캐리커처 생성 모델은 각 해상도의 단계에서 매핑 네트워크(Mapping Network)을 통해 스타일 특징을 추출하고, 공개특허 10-2025-0056739-4-상기 캐리커처 생성 모델은 상기 추출한 스타일 특징을 기반으로 캐리커처 영상을 생성하는, 캐리커처 생성 장치."}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "캐리커처 생성 방법은 영상 처리 장치가 얼굴 영상을 획득 받는 단계; 상기 영상 처리 장치가 상기 얼굴 영상을 캐리커처 생성 모델에 입력하는 단계; 및 상기 영상 처리 장치가 상기 캐리커처 생성 모델의 출력값을 기반으로 상기 얼굴 영상에 대한 캐리커처 영상을 출력하는 단계;를 포함한다."}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하 설명하는 기술은 캐리커처 생성 방법 및 장치에 대한 것이다."}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "예술적인 초상화는 만화, 애니메이션, 포스터등 다양한 분야에서 볼 수 있다. 캐리커처는 개인의 신원을 그대로 유지하면서 얼굴의 특징을 과장한 그림을 의미한다. 캐리커처는 스케치나 예술적 그림을 통해 인물의 특징을 단 순화하거나 과장하여 표현한 그림을 의미한다. 캐리커처는 풍자나 유머를 전달하기 위해 사용되는 예술의 한 형 태이며 엔터네인먼트에서 흔히 사용된다. 최근 개인 사진등이 소셜 네트워킹 플랫폼에 개시되는 경우가 많다. 누구나 개인 사진에 쉽게 접근할 수 있기에 개인 사진은 남용될 수도 있다. 이를 위하여 개인의 민감하고 식별가능한 특징을 숨겨야 할 필요가 있다. 즉 얼 굴 영역을 비식별화 할 필요가 있다. 이를 위하여 캐리커처를 활용할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허 10-2023-0093120"}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전통적인 캐리커처 생성 방법은 얼굴의 랜드마크를 명시적으로 식별하고 왜곡하여 평균 편차를 확대 하는 방식 으로 진행하였다. 하지만 종래 캐리커처 생성 방법은 공간적 변화가 큰 기술에는 적합하지 않기 때문에 성능이 낮았다. 이하 설명하는 기술은 인공신경망에 기반한 캐리커처 생성 모델을 이용함으로써 얼굴 영상에서 캐리커처를 생성 하는 방법을 개시한다. 특히 눈과 입이 변형된 캐리커처를 생성하는 방법을 제공하고자 한다."}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "캐리커처 생성 방법은 영상 처리 장치가 얼굴 영상을 획득 받는 단계; 상기 영상 처리 장치가 상기 얼굴 영상을 캐리커처 생성 모델에 입력하는 단계; 및 상기 영상 처리 장치가 상기 캐리커처 생성 모델의 출력값을 기반으로 상기 얼굴 영상에 대한 캐리커처 영상을 출력하는 단계;를 포함한다."}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이하 설명하는 기술을 이용하면 얼굴 영상으로부터 캐리커처 영상을 생성할 수 있다. 캐리커처 영상은 원본 얼 굴 영상에서 눈과 입만이 변형된 얼굴일 수 있다. 이하 설명하는 기술을 이용하면 캐리커처 생성 모델을 구축하기 위한 학습 데이터를 구축할 수 있다. 특히 원본 얼굴 영상에 안경등이 있는 경우에도 캐리커처 생성 모델을 구축할 수 있다. 이에 눈과 입을 변형하는 캐리커처 생성 모델을 구축할 수 있다. 이하 설명하는 기술을 이용하면 눈과 입만이 변형된 캐리커처 영상을 생성할 수 있다. 이에 개인 사전에서 얼굴 영역을 비 식별화 할 수 있다. 이에 개인의 민감하고 식별가능한 특징을 숨길 수 있다."}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있다. 명세서의 도면에 이하 설 명하는 기술의 특정 실시 형태가 기재될 수 있다. 그러나, 이는 이하 설명하는 기술의 설명을 위한 것이며 이하 설명하는 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니다. 따라서 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변경 물, 균등 물 내지 대체 물이 이하 설명하는 기술에 포함하는 것으로 이해되어야 한 다. 이하 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함하는 것으 로 이해되어야 하고, \"포함한다\" 등의 용어는 기재된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요소, 부분 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성 부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의 해 전담되어 수행될 수도 있음은 물론이다. 또, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기 재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 이하 영상 처리 장치가 캐리커처 생성 방법을 수행하는 전체적인 과정을 설명한다. 도1은 영상 처리 장치가 캐리커처 생성하는 전체적인 과정을 보여준다. 영상 처리 장치는 얼굴 영상을 획득할 수 있다. 영상 처리 장치는 얼굴 영상을 캐리커처 생성 모델에 입력할 수 있다. 영상 처리 장치는 캐리커처 생성 모델의 출력값을 기반으로 얼굴 영상에 대한 캐리커처 영상을 출력할 수 있다. 캐리커처 생성 모델은 얼굴 영상에서 눈과 입의 크기가 변형된 영상을 생성할 수 있다. 이하 캐리커처 생성 방법에 대해 구체적으로 설명한다. 도2는 캐리커처 생성 방법의 실시예 중 하나이다. 영상 처리 장치는 얼굴 영상을 획득할 수 있다. 얼굴 영상은 사람의 얼굴을 촬영한 영상을 포함할 수 있다. 얼굴 영상은 사람의 얼굴을 정면으로 촬영한 영상을 포함할 수 있다. 얼굴 영상은 디지털 카메라, 핸드폰 카메라와 같이 촬영 장치로 촬영한 영상을 포함할 수 있다. 영상 처리 장치는 얼굴 영상을 캐리커처 생성 모델에 입력할 수 있다. 캐리커처 생성 모델은 얼굴 영상에서 눈과 입의 크기가 변형된 영상을 생성하는 모델일 수 있다. 캐리커처 생성 모델은 인공지능 모델일 수 있다. 인공지능 모델은 기계 학습(Machine Learning, ML) 기반의 모 델일 수 있다. 기계학습은 인공지능 기술의 한 분야로서 컴퓨팅 장치가 데이터를 통해 학습하여 특정 대상 혹은 조건을 이해할 수 있게 하거나 데이터의 패턴을 찾아내 분류하는 기술적 방식으로써 컴퓨터가 데이터를 분석할 수 있게 하는 알고리즘일 수 있다. 캐리커처 생성 모델은 StyleGAN기반의 학습 모델일 수 있다. 캐리커처 생성 모델은 2가지 형태의 모델을 가질 수 있다. 캐리커처 생성 모델은 학습 데이터 구축 모듈이 구축한 학습 데이터를 기반으로 학습된 모델일 수 있 다. 캐리커처 생성 모델의 구체적인 설명은 이하에서 기재한다. 영상 처리 장치는 캐리커처 생성 모델의 출력값을 기반으로 얼굴 영상에 대한 캐리커처 영상을 출력할 수 있다 . 캐리커처 영상은 입력 받은 얼굴 영상에서 눈과 입이 크게 변형된 영상일 수 있다. 일 실시예로 캐리커처 영상 은 원본 얼굴 영상과 비교할 때 눈과 입이 크게 강조된 영상일 수 있다. 또는 캐리커처 영상은 원본 얼굴 영상 과 비교할 때 스타일(Style) 변경된 영상일 수도 있다. 예를 들어 캐리커려 영상은 배경이 변경된 영상일 수 있 다. 이하 첫번째 캐리커처 생성 모델과 그 성능을 평가한 실험결과를 살펴 본다. 도3은 첫번째 캐리커처 생성 모델의 구조를 보여준다. 캐리커처 생성 모델은 StyleGAN기반의 모델일 수 있다. 캐리커처 생성 모델은 매핑 네트워크(Mapping Network, ) 및 합성 네트워크(Synthesis network, )를 포함할 수 있다. 매핑 네트워크는 8개의 레이어 MLP(Multi-Layers Perceptron)을 포함할 수 있다. 매핑 네트워크는 잠재 코드 (Latent code) 를 기반으로 을 생성할 수 있다. 구체적으로 매핑 네트워크는 잠재 코드로 부터 disentanglement 한 style 특징을 추출할 수 있다. 합성 네트워크는 18개의CNN(Convolution Neural Network) 레이어를 포함할 수 있다. 합성 네트워크는 적응적 인 스턴트 정규화(Adaptive instance normalization, AdaIn)로 제어될 수 있다. 각 레이어는 잠재 코드의 학습된 아핀 변환(Affine transformation)를 가질 수 있다. 가우시안 노이즈(Gaussian noise)는 합성 네트워크 각 레 이어에 입력될 수 있다. 캐리커처 생성 모델의 구조는 하나의 컨볼루션 레이어에서 하나의 스타일만을 조절할 수 있다. 임의의 잠재 코 드는 생성된 이미지의 스타일을 조절하는데 사용된다. 새로운 캐리커처 이미지를 학습한 뒤, 생성자는 서로 다 른 스타일을 가진 캐리커처 이미지를 생성할 수 있다. 즉 캐리커처 이미지는 피부톤, 헤어 컬러, 모습등이 서로 다를 수 있다. 도4는 첫번째 생성 모델이 생성한 캐리커처 영상이다. 하나의 행(Row)은 하나의 아이덴디티(Identity)를 보여준다. 하나의 행은 다양한 스타일 기법이 적용된 캐리커 처 영상을 보여준다. 이는 캐리커처 생성 모델의 disentanglement 특성 때문에 가능하다. 도5는 첫번째 캐리커처 생성 모델의 성능을 대조군과 비교한 실험결과를 보여준다. 대조군은 종래 캐리커처 생 성 모델이다. 종래 캐리커처 생섬 모델은 AutoTOON 및 WrapGAN이 이용되었다. WrapGAN의 스타일의 경우 워핑(Warping)과 밀접하게 연간되어 있으며, 이에 얼굴 특징이 불규칙하거나 (Irregularities) 변형(Deformation)되어 있어 캐리커처 품질이 상당히 떨어지는 것을 확인할 수 있다.AutoTOON은 일반적인 품질 및 지속성을 유지하면서 얼굴 특성을 과장할 수 있다. 하지만 이를 위하여 AutoTOON 은 페어링 학습이 필요한다. 반면에 전술한 캐리커처 생성 방법(Our Method)을 이용하면 얼굴의 윤곽을 변경하지 않으면서 얼굴의 특정 영역 만을 과장할 수 있다. 이에 신원 정보와 표정도 보존될 수 있다. 따라서 다른 기법에 비해 더 사실적으로 보이 면서 얼굴 변형이 나타날 수 있다. 이하 두번째 캐리커처 생성 모델과 그 성능을 평가한 실험결과에 대해 살펴 본다. 도6은 두번째 캐리커처 생성 모델의 구조를 보여준다. 캐리커처 생성 모델은 피라미드 네트워크(Pyramid Network)형태를 가질 수 있다. 캐리커처 생성 모델은 입력 받 은 실제 얼굴 영상( )에서 캐리커처 이미지( )를 생성한다. 캐리커처 생성 모델은 얼굴 영상에서 특징을 추출할 수 있다. 캐리커처 생성 모델은 작은 각 해상도의 단계에서 스타일 특징(Style feature)을 추출할 수 있다. 스타일 특징을 추출하기 위하여 매핑 네트워크(Mapping Network)인 map2sytle를 이용할 수 있다. map2sytle은 스타일을 추출하도록 학습된 네트워크일 수 있다. Map2sytle은 Fully Convolution Layer일 수 있다. 이는 특징 맵(Feature)을 다운 샘플 한 뒤 512차원의 스타일 입력값을 획득할 수 있다. 캐리커처 생성 모델은 추출한 스타일 특징을 기반으로 캐리커처 영상을 생성할 수 있 다. 작은 특징 맵은 W0 내지 W2의 스타일을 생성한다. 중간 특징 맵은 W3 내지 W6의 스타일을 생성한다. 큰 특징맵 은 W7 내지 W17의 특징맵을 생성한다. 단일 훈련 방법(Single Training Iteration)을 이미지 배치에 대해 수행되는 N단계의 집합으로 설정할 수 있다. 모델은 배치단 N=2인 단계를 사용하여 학습되었다. 그 반복된 결과는 이다. 더 나아가 원본 얼굴 영상의 배 경(Background)와 결과 값을 블랜딩(Blending)하여 원본 얼굴 영상의 배경을 반영할 수 있다. 수학식1은 두번째 캐리커처 생성 모델을 학습시키는데 이용되는 손실함수이다. 손실함수는 4개의 손실항(L2, L , LID, L )으로 구성되어 있다. 수학식 1"}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식1에서 λ1, λ2, λ3 및 λ4는 손실함수 각 손실항의 가중치를 의미한다. L2는 픽셀 별(Pixel-wise) 차이이다. 수학식2는 L2를 계산하는데 이용되는 식이다. 수학식 2"}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "L 는 인지 유사성(perceptual similarity)에 대한 항이다. L 는 인지 유사성을 보존하기 위하여 이용된다. 수학식3은 인지 유사성을 계산할 때 이용되는 식이다. 수학식 3 는 정규화(Regularization)에 대한 항이다. 정규화 항은 인코더가 잠재 스타일 벡터를 평균 잠재 벡터와 가까워지게 하도록 한다. 수학식4는 정규화 항을 계산할 때 이용하는 식이다. 수학식 4"}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식4에서 w'는 사전에 학습된 생성자의 평균 스타일 벡터 값을 의미한다. 아이덴티디 손실(Identity loss)항은 비슷한 얼굴 특징을 가진 캐리커처 얼굴을 생성하기 위하여 이용된다. 아 이덴티디 손실항은 출력되는 이미지와 그 소스간의 코사인 유사성을 측정하는 방식으로 계산된다. 수학식5는 아 이덴티디 유사성을 계산하는데 이용되는 식이다. 수학식 5"}
{"patent_id": "10-2023-0152824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 5, "content": "도7은 두번째 캐리커처 생성 모델을 이용해서 캐리커처 영상을 생성한 결과를 보여준다. 얼굴의 전체적인 특징 이 보존되면서 눈 또는 입의 크기가 변형된 캐리커처 영상을 잘 생성하는 것을 보여준다. 이하 캐리커처 생성 모델을 구축할 때 이용한 학습 데이터를 구축하는 과정을 살펴본다. 학습 데이터를 구축하 는 것은 학습 데이터 구축 모듈이 수행할 수 있다. 도8은 학습 데이터를 구축하는 첫번째 실시예를 보여준다. 먼저 얼굴 영상( )에서 랜드마크 포인트( )를 찾는다. 얼굴 영상은 FFHQ 데이터 셋일 수 있다. FFQH데이 터 셋은 다양한 성별, 인종, 연령, 표정 및 포즈를 포함할 수 있다. 랜드마크 포인트를 찾기 위하여 Dlib가 이 용될 수 있다. Dlib는 일반적으로 사용되는 옾느 소스 라이브러리 중 하나이다. Dlib는 얼굴 이미지의 구조 68 개의 좌표를 인식할 수 있다. 이 68개의 랜드마크는 눈, 눈썹, 코 입, 얼굴 윤곽과 같은 얼굴 부분에 대해 할당 된다. 눈의 랜드마크 인덱스(Index)는 왼쪽 눈과 오른쪽 눈의 그룹으로 분류될 수 있다. 왼쪽눈은 37번 내지 42번으로 표시되며, 오른쪽은 43번 내지 48번으로 표시될 수 있다. 입 영역은 윗 입술의 랜드마크의 인덱스와 아랫 입술의 랜드마크 인덱스만 사용되었다. 인덱스 49 내지 60번은 입 영역을 나타낸다. 눈과 입의 랜드마크 인덱스를 사용하여 두개의 눈 영역과 입 영역의 패치를 세분화할 수 있다( ).이후 패치 를 1.5배일로 스케일링 하고 블랜딩(Blending)할 수 있다( ). 스케일링된 패치 영역은 푸아송 이미지 편집 기법을 사용하여 원본이미지에 다시 적용하여 블랜딩 할 수 있다. 도9는 학습 데이터를 구축하는 두번째 실시예 중 하나이다. 실제 얼굴 영상( )로 부터 안경이 제거된 얼굴 영상( )을 생성할 수 있다. 이를 위하여 안경 마스크 네트 워크(Glass Mask network,) 및 그림자 마스크 네트워크(Shadow Mask Network)를 이용할 수 있다. 안경 마스크 네트워크는 얼굴 영상으로부터 안경 마스크 ( )를 생성할 수 있다. 그림자 마스크 네트워크는 얼굴 영상에 서 그림자 마스크를 ( ) 생성할 수 있다. 안경 및 그림자가 제거된 얼굴 영상에서 눈과 입이 변형된 얼굴 영상( )을 생성할 수 있다. 이를 위하여 도8 등에서 개시한 캐리커처 생성 방법을 이용할 수도 있다. 눈과 입이 변형된 얼굴 영상에 안경을 다시 부여할 수 있다( ). 이때 기존에 생성된 안경 마스크를 이용할 수 있다. 즉 안경 마스크와 눈과 입이 변형된 얼굴 영상 을 블랜딩(Blending)하여 눈과 입이 변형된 얼굴 영상에 안경을 부여할 수 있다. 이후 최초 영상으로부터 생성 한 라이트닝 마스크(Light mask)를 이용해서 조명을 보정할 수 있다. 이하 도10을 통해 영상 처리 장치에 대해 설명한다. 도10은 영상 처리 장치의 실시예 중 하나의 구성이다. 영상 처리 장치는 도1에서 설명한 영상 처리 장치에 해당할 수 있다. 즉 영상 처리 장치는 전술 한 캐리커처 생성 방법을 수행하는 장치일 수 있다. 영상 처리 장치는 물리적으로 다양한 형태로 구현될 수 있다. 예를 들어 영상 처리 장치는 PC, 노트 북, 스마트기기, 서버 또는 데이터처리 전용 칩셋 등의 형태를 가질 수 있다. 영상 처리 장치는 입력장치, 저장장치, 연산장치, 출력장치, 인터페이스 장치 및 통신장치를 포함할 수 있다. 입력장치는 일정한 명령 또는 데이터를 입력 받는 인터페이스 장치(키보드, 마우스, 터치스크린 등)를 포 함할 수도 있다. 입력장치는 별도의 저장장치(USB, CD, 하드디스크 등)를 통하여 정보를 입력 받는 구성을 포함할 수도 있다. 입력장치는 입력 받는 데이터를 별도의 측정장치를 통하여 입력 받거나, 별도의 DB를 통하여 입력 받을 수도 있다. 입력장치는 통신장치을 통해 데이터를 유선 또는 무선 통신으로 입력 받을 수도 있다. 입력장치는 전술한 캐리커처 생성 방법을 수행하는데 필요한 정보를 입력 받을 수 있다. 입력장치는 전술한 캐리커처 생성 방법을 수행하는데 필요한 모델을 입력 받을 수 있다. 입력장치는 얼굴 영상을 입력 받을 수 있다. 입력 장치는 캐리커처 생성 모델을 입력 받을 수 있다. 저장장치는 일정한 정보를 저장하는 장치가 될 수도있다. 저장장치는 입력장치를 통해 입력 받 은 정보를 저장할 수 있다. 저장장치는 연산장치가 연산하는 과정에서 생성되는 정보를 저장할 수 있 다. 즉 저장장치는 메모리를 포함할 수 있다. 저장장치는 전술한 캐리커처 생성 방법을 수행하는데 필요한 정보를 저장할 수 있다. 저장장치는 전 술한 캐리커처 생성 방법을 수행하는데 필요한 모델을 저장할 수 있다. 저장장치는 얼굴 영상을 저장할 수 있다. 저장장치는 캐리커처 생성 모델을 저장할 수 있다. 연산장치는 데이터를 처리하고, 일정한 연산을 처리하는 프로세서, AP, 프로그램이 임베디드된 칩과 같은 장치일 수 있다. 연산장치는 영상 처리 장치를 제어하는 제어신호를 생성할 수 있다. 연산장치(33 0)는 영상 처리 장치에 포함된 입력장치, 저장장치, 출력장치, 인터페이스 장치 및 통신장치을 제어하는 제어신호를 생성할 수 있다. 연산장치는 전술한 캐리커처 생성 방법을 수행하는데 필요한 연산을 할 수 있다. 연산장치는 상기 얼 굴 영상을 캐리커처 생성 모델에 입력할 수 있다. 연산장치는 캐리커처 생성 모델의 출력값을 기반으로 상 기 얼굴 영상에 대한 캐리커처 영상을 출력할 수 있다. 출력장치는 일정한 정보를 출력하는 장치가 될 수도 있다. 출력장치는 데이터 과정에 필요한 인터페 이스, 입력된 데이터, 분석결과 등을 출력할 수도 있다. 출력장치는 디스플레이, 문서를 출력하는 장치, 스피커등과 같이 물리적으로 다양한 형태로 구현될 수도 있다. 출력장치는 저장장치에 저장된 정보를 출력할 수 있다. 출력장치는 연산장치가 연산하는 과정에서 생성된 정보를 출력할 수 있다. 출력장치 는 연산장치가 연산한 결과를 출력할 수 있다. 인터페이스 장치는 외부로부터 일정한 명령 및 데이터를 입력 받는 장치일 수 있다. 인터페이스 장치(35 0)는 영상 처리 장치를 제어하기 위한 제어신호를 입력 받을 수 있다. 인터페이스 장치는 영상 처리장치가 분석한 결과를 출력할 수 있다. 인터페이스 장치는 물리적으로 연결된 입력 장치 또는 외부 저장장치로부터 전술한 캐리커처 생성 방법을 수행하는데 필요한 정보를 입력 받을 수 있다. 통신장치는 유선 또는 무선 네트워크를 통해 일정한 정보를 수신하고 전송하는 구성을 의미할 수 있다. 통 신장치는 Wi-Fi(Wireless Fidelity), Wi-Fi Direct, 블루투스(Bluetooth), UWB(Ultra Wide Band) 또는 NFC(Near Field Communication), USB(Universal Serial Bus), 혹은 HDMI(High Definition Multimedia Interface), LAN(Local Area Network) 등과 같은 네트워크 통신을 수행할 수 있다. 통신장치는 영상 처리 장치를 제어하는데 필요한 제어 신호를 수신할 수 있다. 통신장치는 영상 처리 장치가 분석한 결과를 전송할 수 있다. 통신장치는 전술한 캐리커처 생성 방법을 수행하는데 필 요한 정보를 수신받을 수 있다. 통신장치는 전술한 캐리커처 생성 방법을 수행하는데 필요한 모델을 수신 받을 수 있다. 전술한 캐리커처 생성 방법은 컴퓨터에서 실행될 수 있는 실행가능한 알고리즘을 포함하는 프로그램(또는 어플 리케이션)으로 구현될 수 있다. 상기 프로그램은 일시적 또는 비일시적 판독 가능 매체(non-transitory computer readable medium)에 저장되어 제공될 수 있다. 상기 일시적 판독 가능 매체는 스태틱 램(Static RAM，SRAM), 다이내믹 램(Dynamic RAM，DRAM), 싱크로너스 디 램 (Synchronous DRAM，SDRAM), 2배속 SDRAM(Double Data Rate SDRAM，DDR SDRAM), 증강형 SDRAM(Enhanced SDRAM，ESDRAM), 동기화 DRAM(Synclink DRAM，SLDRAM) 및 직접 램버스 램(Direct Rambus RAM，DRRAM) 과 같은 다양한 RAM을 의미한다. 상기 비일시적 판독 가능 매체는 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM (read-only memory), PROM (programmable read only memory), EPROM(Erasable PROM, EPROM) 또는 EEPROM(Electrically EPROM) 또는 플래시 메모리 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있 다. 본 실시예 및 본 명세서에 첨부된 도면은 전술한 기술에 포함되는 기술적 사상의 일부를 명확하게 나타내고 있 는 것에 불과하며, 전술한 기술의 명세서 및 도면에 포함된 기술적 사상의 범위 내에서 당업자가 용이하게 유추 할 수 있는 변형 예와 구체적인 실시예는 모두 전술한 기술의 권리범위에 포함되는 것이 자명하다고 할 것이다."}
{"patent_id": "10-2023-0152824", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 영상 처리 장치가 캐리커처 생성하는 전체적인 과정을 보여준다. 도2는 캐리커처 생성 방법의 실시예 중 하나이다. 도3은 첫번째 캐리커처 생성 모델의 구조를 보여준다. 도4는 첫번째 생성 모델이 생성한 캐리커처 영상이다. 도5는 첫번째 캐리커처 생성 모델의 성능을 대조군과 비교한 실험결과를 보여준다. 도6은 두번째 캐리커처 생성 모델의 구조를 보여준다. 도7은 두번째 캐리커처 생성 모델을 이용해서 캐리커처 영상을 생성한 결과를 보여준다. 도8은 학습 데이터를 구축하는 첫번째 실시예를 보여준다. 도9는 학습 데이터를 구축하는 두번째 실시예 중 하나이다. 도10은 영상 처리 장치의 실시예 중 하나의 구성이다."}
