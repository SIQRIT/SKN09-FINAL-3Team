{"patent_id": "10-2022-0170767", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0153910", "출원번호": "10-2022-0170767", "발명의 명칭": "사용자 목적 달성을 위한 최적 경로를 제공하는 방법, 컴퓨터 장치, 및 컴퓨터 프로그램", "출원인": "네이버 주식회사", "발명자": "김용범"}}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 장치에서 실행되는 방법에 있어서,상기 컴퓨터 장치는 메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를포함하고,상기 방법은,상기 적어도 하나의 프로세서에 의해, 세션(session) 단위로 사용자 행동 궤적을 포함하는 사용자 기록 세션 데이터(user historical session data)를 수집하는 단계; 및상기 적어도 하나의 프로세서에 의해, 상기 사용자 기록 세션 데이터를 그래프 형태의 패스(path)로 표현하여상기 패스를 학습함으로써 최적 경로 예측을 위한 모델을 생성하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 수집하는 단계는,각 세션 별로 해당 세션 내에서 이루어진 일련의 사용자 경험을 한 묶음의 샘플 데이터로 수집하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 수집하는 단계는,네트워크로 연결된 복수 개의 서비스 중 사용자가 이용하는 서비스에 대한 사용자 로그로 상기 세션 단위의 상기 사용자 기록 세션 데이터를 수집하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 생성하는 단계는,상기 세션 단위로 상기 사용자 기록 세션 데이터를 적어도 하나의 패스로 표현하는 단계를 포함하고,상기 패스는 각 시간 단계에서의 상태(state)와 상기 상태에서의 액션(action), 및 상기 액션에 대한 리워드(reward)로 구성되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 상태는 사용자가 소비하는 서비스 화면에 대한 내용으로 정의되고, 서비스 유형, 사용자와 관련된 환경 정보, 사용자 개인 정보, 세션 카테고리 중 적어도 하나를 더 포함하고,공개특허 10-2023-0153910-3-상기 액션은 상기 상태에서의 사용자 활동(user activity)으로 정의되고,상기 리워드는 상기 액션에 대한 사용자 만족도(user satisfaction)로 정의되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 리워드는 상기 액션에 대해 사용자로부터 직접 받은 피드백을 기초로 결정되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 리워드는 상기 액션에 따른 상태에 대한 체류 시간(dwell time)과 추가 액션 중 적어도 하나를 기초로 결정되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제4항에 있어서,상기 생성하는 단계는,상기 상태와 상기 액션 및 상기 리워드에 대한 강화 학습(reinforcement learning), 언어 모델링 학습, 및 신경망(neural network) 학습 중 적어도 하나를 기초로 최적 경로 예측 모델을 생성하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 방법은,상기 적어도 하나의 프로세서에 의해, 타겟 사용자를 대상으로 상기 최적 경로 예측을 위한 모델을 통해 다음액션을 예측하여 예측된 액션의 패스를 최적 경로로 추천하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 추천하는 단계는,상기 타겟 사용자의 현재 세션에서 이전 행동 궤적을 포함하는 사용자 기록 세션 데이터를 이용하여 상기 다음액션을 예측하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독가능한 기록 매체에 저장되는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "컴퓨터 장치에 있어서,메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서공개특허 10-2023-0153910-4-를 포함하고,상기 적어도 하나의 프로세서는,세션 단위로 사용자 행동 궤적을 포함하는 사용자 기록 세션 데이터를 수집하는 과정; 및상기 사용자 기록 세션 데이터를 그래프 형태의 패스로 표현하여 상기 패스를 학습함으로써 최적 경로 예측을위한 모델을 생성하는 과정을 처리하는 컴퓨터 장치."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,각 세션 별로 해당 세션 내에서 이루어진 일련의 사용자 경험을 한 묶음의 샘플 데이터로 수집하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,네트워크로 연결된 복수 개의 서비스 중 사용자가 이용하는 서비스에 대한 사용자 로그로 상기 세션 단위의 상기 사용자 기록 세션 데이터를 수집하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,상기 세션 단위로 상기 사용자 기록 세션 데이터를 적어도 하나의 패스로 표현하는 과정을 처리하고,상기 패스는 각 시간 단계에서의 상태와 상기 상태에서의 액션, 및 상기 액션에 대한 리워드로 구성되는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 상태는 사용자가 소비하는 서비스 화면에 대한 내용으로 정의되고, 서비스 유형, 사용자와 관련된 환경 정보, 사용자 개인 정보, 세션 카테고리 중 적어도 하나를 더 포함하고,상기 액션은 상기 상태에서의 사용자 활동으로 정의되고,상기 리워드는 상기 액션에 대한 사용자 만족도로 정의되는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 리워드는 상기 액션에 대한 사용자 피드백, 상기 액션에 따른 상태에 대한 체류 시간과 추가 액션 중 적어도 하나를 기초로 결정되는 것을 특징으로 하는 컴퓨터 장치.공개특허 10-2023-0153910-5-청구항 18 제15항에 있어서,상기 적어도 하나의 프로세서는,상기 상태와 상기 액션 및 상기 리워드에 대한 강화 학습, 언어 모델링 학습, 및 신경망 학습 중 적어도 하나를기초로 최적 경로 예측 모델을 생성하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,타겟 사용자를 대상으로 상기 최적 경로 예측을 위한 모델을 통해 다음 액션을 예측하여 예측된 액션의 패스를최적 경로로 추천하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2022-0170767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 적어도 하나의 프로세서는,상기 타겟 사용자의 현재 세션에서 이전 행동 궤적을 포함하는 사용자 기록 세션 데이터를 이용하여 상기 다음액션을 예측하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자 목적 달성을 위한 최적 경로를 제공하는 방법, 컴퓨터 장치, 및 컴퓨터 프로그램이 개시된다. 세션 (session) 단위로 사용자 행동 궤적을 포함하는 사용자 기록 세션 데이터(user historical session data)를 수 집한 후 상기 사용자 기록 세션 데이터를 그래프 형태의 패스(path)로 표현하여 상기 패스를 학습함으로써 최적 경로 예측을 위한 모델을 생성할 수 있다."}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 사용자 행동에서 패턴을 찾아 최적 경로를 제공하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "방대한 양과 종류의 컨텐츠들이 서비스되고 있는 현 상황에서는 사용자에게 다양한 기준으로 컨텐츠를 추천해주 는 서비스들이 등장하고 있으며, 가장 대표적으로는 개인화 추천 서비스가 있다. 개인화 추천 서비스는 사용자의 활동(예컨대, 컨텐츠 이용 패턴, 컨텐츠 구매 패턴 등)을 기준으로 사용자에게 적합한 컨텐츠, 즉 개인화된 컨텐츠를 추천해 주는 서비스이다. 이러한 개인화 추천 서비스의 기존 방식은, 사용자의 과거 활동을 기초로 활동 패턴을 분석하고 사용자와 유사 한 활동 패턴을 가진 다른 사용자를 검색하여 검색된 다른 사용자가 이용하거나 구매한 컨텐츠를 사용자에게 추 천해 주는 방식이다. 한국 등록특허공보 제10-1647364호(등록일 2016년 08월 04일)에는 복수의 사용자 그룹을 대상으로 하여 복수개 의 컨텐츠 중 적합한 것을 복수 사용자들의 각 컨텐츠에 대한 상호작용에 기반한 사용자 그룹별 스코어와 해당 사용 자가 속하는 사용자 그룹에 기초한 우선 순위를 기초로 하여 제공함으로써 해당 사용자에게 보다 적합도가 높은 컨텐츠를 추천할 수 있는 기술이 개시되어 있다."}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인공지능 모델을 이용하여 사용자 행동에서 패턴을 찾아 최적 경로를 추천할 수 있는 방법과 장치를 제공한다. 사용자 경험(user experience)을 모델링하여 개인화된 모델을 통해 목적 달성을 위한 최적 경로를 추천할 수 있 는 방법과 장치를 제공한다."}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "컴퓨터 장치에서 실행되는 방법에 있어서, 상기 컴퓨터 장치는 메모리에 포함된 컴퓨터 판독가능한 명령들을 실 행하도록 구성된 적어도 하나의 프로세서를 포함하고, 상기 방법은, 상기 적어도 하나의 프로세서에 의해, 세션 (session) 단위로 사용자 행동 궤적을 포함하는 사용자 기록 세션 데이터(user historical session data)를 수 집하는 단계; 및 상기 적어도 하나의 프로세서에 의해, 상기 사용자 기록 세션 데이터를 그래프 형태의 패스 (path)로 표현하여 상기 패스를 학습함으로써 최적 경로 예측을 위한 모델을 생성하는 단계를 포함하는 방법을 제공한다. 일 측면에 따르면, 상기 수집하는 단계는, 각 세션 별로 해당 세션 내에서 이루어진 일련의 사용자 경험을 한 묶음의 샘플 데이터로 수집하는 단계를 포함할 수 있다. 다른 측면에 따르면, 상기 수집하는 단계는, 네트워크로 연결된 복수 개의 서비스 중 사용자가 이용하는 서비스 에 대한 사용자 로그로 상기 세션 단위의 상기 사용자 기록 세션 데이터를 수집하는 단계를 포함할 수 있다. 또 다른 측면에 따르면, 상기 생성하는 단계는, 상기 세션 단위로 상기 사용자 기록 세션 데이터를 적어도 하나 의 패스로 표현하는 단계를 포함하고, 상기 패스는 각 시간 단계에서의 상태(state)와 상기 상태에서의 액션 (action), 및 상기 액션에 대한 리워드(reward)로 구성될 수 있다. 또 다른 측면에 따르면, 상기 상태는 사용자가 소비하는 서비스 화면에 대한 내용으로 정의되고, 서비스 유형, 사용자와 관련된 환경 정보, 사용자 개인 정보, 세션 카테고리 중 적어도 하나를 더 포함하고, 상기 액션은 상 기 상태에서의 사용자 활동(user activity)으로 정의되고, 상기 리워드는 상기 액션에 대한 사용자 만족도(user satisfaction)로 정의될 수 있다. 또 다른 측면에 따르면, 상기 리워드는 상기 액션에 대해 사용자로부터 직접 받은 피드백을 기초로 결정될 수 있다. 또 다른 측면에 따르면, 상기 리워드는 상기 액션에 따른 상태에 대한 체류 시간(dwell time)과 추가 액션 중 적어도 하나를 기초로 결정될 수 있다. 또 다른 측면에 따르면, 상기 생성하는 단계는, 상기 상태와 상기 액션 및 상기 리워드에 대한 강화 학습 (reinforcement learning), 언어 모델링 학습, 및 신경망(neural network) 학습 중 적어도 하나를 기초로 최적 경로 예측 모델을 생성하는 단계를 더 포함할 수 있다. 또 다른 측면에 따르면, 상기 방법은, 상기 적어도 하나의 프로세서에 의해, 타겟 사용자를 대상으로 상기 최적 경로 예측을 위한 모델을 통해 다음 액션을 예측하여 예측된 액션의 패스를 최적 경로로 추천하는 단계를 더 포 함할 수 있다. 또 다른 측면에 따르면, 상기 추천하는 단계는, 상기 타겟 사용자의 현재 세션에서 이전 행동 궤적을 포함하는 사용자 기록 세션 데이터를 이용하여 상기 다음 액션을 예측하는 단계를 포함할 수 있다. 상기 방법을 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독가능한 기록 매체에 저장되는 컴퓨터 프로그램을 제공 한다. 컴퓨터 장치에 있어서, 메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세 서를 포함하고, 상기 적어도 하나의 프로세서는, 세션 단위로 사용자 행동 궤적을 포함하는 사용자 기록 세션 데이터를 수집하는 과정; 및 상기 사용자 기록 세션 데이터를 그래프 형태의 패스로 표현하여 상기 패스를 학습 함으로써 최적 경로 예측을 위한 모델을 생성하는 과정을 처리하는 컴퓨터 장치를 제공한다."}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면, 인공지능 모델을 이용하여 사용자 행동에서 패턴을 찾아 불필요한 단계들을 건너 뛸 수 있는 사용자 목적까지의 최적 경로를 추천할 수 있다. 본 발명의 실시예들에 따르면, 사용자 경험을 패스(path)로 표현하여 모델링함으로써 최적 경로 예측을 위한 초 개인화된 모델을 구축할 수 있고 특정 도메인이나 서비스에 의존하지 않는 플랫폼을 구축할 수 있다."}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 본 발명의 실시예들은 사용자 행동에서 패턴을 찾아 최적 경로를 제공하는 기술에 관한 것이다. 본 명세서에서 구체적으로 개시되는 것들을 포함하는 실시예들은 여러 서비스가 연계 가능한 플랫폼 상에서의 경로로써 사용자 목적 달성을 위한 최적 경로를 추천할 수 있다. 본 발명의 실시예들에 따른 최적 경로 추천 시스템은 적어도 하나의 컴퓨터 장치에 의해 구현될 수 있으며, 본 발명의 실시예들에 따른 최적 경로 추천 방법은 최적 경로 추천 시스템에 포함되는 적어도 하나의 컴퓨터 장치 를 통해 수행될 수 있다. 이때, 컴퓨터 장치에는 본 발명의 일실시예에 따른 컴퓨터 프로그램이 설치 및 구동 될 수 있고, 컴퓨터 장치는 구동된 컴퓨터 프로그램의 제어에 따라 본 발명의 실시예들에 따른 최적 경로 추천 방법을 수행할 수 있다. 상술한 컴퓨터 프로그램은 컴퓨터 장치와 결합되어 최적 경로 추천 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장될 수 있다. 도 1은 본 발명의 일실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 1의 네트워크 환경은 복수의 전 자 기기들(110, 120, 130, 140), 복수의 서버들(150, 160) 및 네트워크를 포함하는 예를 나타내고 있다. 이러한 도 1은 발명의 설명을 위한 일례로 전자 기기의 수나 서버의 수가 도 1과 같이 한정되는 것은 아니다. 또한, 도 1의 네트워크 환경은 본 실시예들에 적용 가능한 환경들 중 하나의 예를 설명하는 것일 뿐, 본 실시예 들에 적용 가능한 환경이 도 1의 네트워크 환경으로 한정되는 것은 아니다. 복수의 전자 기기들(110, 120, 130, 140)은 컴퓨터 장치로 구현되는 고정형 단말이거나 이동형 단말일 수 있다. 복수의 전자 기기들(110, 120, 130, 140)의 예를 들면, 스마트폰(smart phone), 휴대폰, 내비게이션, 컴퓨터, 노트북, 디지털방송용 단말, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 태블릿 PC 등이 있다. 일례로 도 1에서는 전자 기기의 예로 스마트폰의 형상을 나타내고 있으나, 본 발명의 실시예 들에서 전자 기기는 실질적으로 무선 또는 유선 통신 방식을 이용하여 네트워크를 통해 다른 전자 기 기들(120, 130, 140) 및/또는 서버(150, 160)와 통신할 수 있는 다양한 물리적인 컴퓨터 장치들 중 하나를 의미 할 수 있다. 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용하는 통신 방식뿐만 아니라 기기들 간의 근거리 무선 통신 역시 포함될 수 있다. 예를 들어, 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network),MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포함하는 네트 워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 서버(150, 160) 각각은 복수의 전자 기기들(110, 120, 130, 140)과 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 예를 들어, 서버는 네트워크를 통해 접속한 복수의 전자 기기들(110, 120, 130, 140)로 서비스(일례로, 개 인화 추천 서비스 등)를 제공하는 시스템일 수 있다. 도 2는 본 발명의 일실시예에 따른 컴퓨터 장치의 예를 도시한 블록도이다. 앞서 설명한 복수의 전자 기기들 (110, 120, 130, 140) 각각이나 서버들(150, 160) 각각은 도 2를 통해 도시된 컴퓨터 장치에 의해 구현될 수 있다. 이러한 컴퓨터 장치는 도 2에 도시된 바와 같이, 메모리, 프로세서, 통신 인터페이스 그리 고 입출력 인터페이스를 포함할 수 있다. 메모리는 컴퓨터에서 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치 (permanent mass storage device)를 포함할 수 있다. 여기서 ROM과 디스크 드라이브와 같은 비소멸성 대용량 기록장치는 메모리와는 구분되는 별도의 영구 저장 장치로서 컴퓨터 장치에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드가 저장될 수 있다. 이러한 소프트웨어 구성요 소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 메모리로 로딩될 수 있다. 이러 한 별도의 컴퓨터에서 판독 가능한 기록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴 퓨터에서 판독 가능한 기록매체가 아닌 통신 인터페이스를 통해 메모리에 로딩될 수도 있다. 예를 들어, 소프트웨어 구성요소들은 네트워크를 통해 수신되는 파일들에 의해 설치되는 컴퓨터 프로그램에 기 반하여 컴퓨터 장치의 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 인터페이스에 의해 프로세서로 제공될 수 있다. 예 를 들어 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행 하도록 구성될 수 있다. 통신 인터페이스는 네트워크를 통해 컴퓨터 장치가 다른 장치(일례로, 앞서 설명한 저장 장치들)와 서로 통신하기 위한 기능을 제공할 수 있다. 일례로, 컴퓨터 장치의 프로세서가 메모리 와 같은 기록 장치에 저장된 프로그램 코드에 따라 생성한 요청이나 명령, 데이터, 파일 등이 통신 인터페 이스의 제어에 따라 네트워크를 통해 다른 장치들로 전달될 수 있다. 역으로, 다른 장치로부터의 신 호나 명령, 데이터, 파일 등이 네트워크를 거쳐 컴퓨터 장치의 통신 인터페이스를 통해 컴퓨터 장치로 수신될 수 있다. 통신 인터페이스를 통해 수신된 신호나 명령, 데이터 등은 프로세서나 메모리로 전달될 수 있고, 파일 등은 컴퓨터 장치가 더 포함할 수 있는 저장 매체(상술한 영구 저장 장치)로 저장될 수 있다. 입출력 인터페이스는 입출력 장치와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 마이크, 키보드 또는 마우스 등의 장치를, 그리고 출력 장치는 디스플레이, 스피커와 같은 장치를 포함할 수 있 다. 다른 예로 입출력 인터페이스는 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와 의 인터페이스를 위한 수단일 수도 있다. 입출력 장치는 컴퓨터 장치와 하나의 장치로 구성될 수도 있다. 또한, 다른 실시예들에서 컴퓨터 장치는 도 2의 구성요소들보다 더 적은 혹은 더 많은 구성요소들을 포함 할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 컴퓨 터 장치는 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버 (transceiver), 데이터베이스 등과 같은 다른 구성요소들을 더 포함할 수도 있다. 이하에서는 사용자 목적 달성을 위한 최적 경로를 제공하는 방법 및 장치의 구체적인 실시예를 설명하기로 한다. 본 명세서에서 경로는 사용자 목적을 달성하기 위해 거치는 인터넷 상의 모든 사용자 경험을 의미하는 것으로, 인터넷 상에서의 모든 탐색 활동(search, exploration, navigation 등)을 포괄하여 의미할 수 있다. 다시 말 해, 경로는 단순히 검색 활동만을 의미하는 것이 아니라, 상호 연동 가능한 다양한 서비스(검색 서비스(search service), 지도 서비스(map service), 쇼핑 서비스(shopping service), 간편 결제 서비스(pay service), 블로 그 서비스(blog service), 광고 서비스(AD service) 등)에서 이루어지는 모든 사용자 경험을 포함할 수 있다. 본 실시예들은 사용자의 행동 패턴을 바탕으로 인공지능 모델을 학습하여 사용자에게 최적의 경험을 제공하고, 서비스 간에 사용자 경험을 쉽게 만들거나 확장해줄 수 있는 모델(Optimal Composable Experience Action Network, 이하 'OCEAN 모델'이라 칭하기로 함)을 제공할 수 있다. 본 실시예들은 OCEAN 모델을 통해 특정 도메인이나 서비스에 의존하지 않는 플랫폼을 구축할 수 있다. 본 명세 서에서 플랫폼은 수많은 서비스가 연계된 네트워크 상의 경로를 제공하기 위해 멀티 도메인(multi-domain), 크 로스 플랫폼(cross platform) 등을 포함하는 통합 플랫폼을 의미할 수 있다. 본 실시예에 따른 컴퓨터 장치는 클라이언트(client)를 대상으로 클라이언트 상에 설치된 전용 어플리케이 션이나 컴퓨터 장치와 관련된 웹/모바일 사이트 접속을 통해 개인화 추천 서비스를 제공할 수 있다. 컴퓨 터 장치에는 컴퓨터로 구현된 최적 경로 추천 시스템이 구성될 수 있다. 일례로, 최적 경로 추천 시스템 은 독립적으로 동작하는 프로그램 형태로 구현되거나, 혹은 특정 어플리케이션의 인-앱(in-app) 형태로 구성되 어 상기 특정 어플리케이션 상에서 동작이 가능하도록 구현될 수 있다. 컴퓨터 장치의 프로세서는 이하의 최적 경로 추천 방법을 수행하기 위한 구성요소로 구현될 수 있다. 실시예에 따라 프로세서의 구성요소들은 선택적으로 프로세서에 포함되거나 제외될 수도 있다. 또한, 실시예에 따라 프로세서의 구성요소들은 프로세서의 기능의 표현을 위해 분리 또는 병합될 수 도 있다. 이러한 프로세서 및 프로세서의 구성요소들은 이하의 최적 경로 추천 방법이 포함하는 단계들을 수행 하도록 컴퓨터 장치를 제어할 수 있다. 예를 들어, 프로세서 및 프로세서의 구성요소들은 메모 리가 포함하는 운영체제의 코드와 적어도 하나의 프로그램의 코드에 따른 명령(instruction)을 실행하도록 구현될 수 있다. 여기서, 프로세서의 구성요소들은 컴퓨터 장치에 저장된 프로그램 코드가 제공하는 명령에 따라 프로 세서에 의해 수행되는 서로 다른 기능들(different functions)의 표현들일 수 있다. 프로세서는 컴퓨터 장치의 제어와 관련된 명령이 로딩된 메모리로부터 필요한 명령을 읽어들일 수 있다. 이 경우, 상기 읽어들인 명령은 프로세서가 이후 설명될 단계들을 실행하도록 제어하기 위한 명 령을 포함할 수 있다. 이후 설명될 최적 경로 추천 방법이 포함하는 단계들은 도시된 순서와 다른 순서로 수행될 수 있으며, 단계들 중 일부가 생략되거나 추가의 과정이 더 포함될 수 있다. 도 3은 본 발명의 일실시예에 따른 컴퓨터 장치가 수행할 수 있는 방법의 일례를 도시한 흐름도이다. 도 3을 참조하면, 단계(S310)에서 프로세서는 사용자 각각에 대해 세션(session) 단위로 해당 세션에서의 모든 행동 궤적(trajectory)을 포함하는 사용자 기록 세션 데이터(user historical session data)를 수집할 수 있다. 프로세서는 각 세션 별로 사용자 행동을 추적하여 해당 세션 내에서 이루어진 일련의 모든 경험을 한 묶음의 샘플 데이터로 수집함으로써 모델 학습을 위한 학습 데이터로 사용할 수 있다. 단계(S320)에서 프로세서는 세션 별 사용자 기록 세션 데이터를 그래프 패스(graph path)로 표현할 수 있 다. 프로세서는 세션 단위의 사용자 기록 세션 데이터 각각을 적어도 하나 이상의 패스로 표현할 수 있고, 이때 각 패스는 상태(state)와 액션(action) 및 리워드(reward)로 구성될 수 있다. 상태는 각 시간 단계 에서의 사용자의 현재 상태(서비스에서 제공하는 화면으로 사용자가 소비하고 있는 내용)를 의미하고, 액션은 클릭, 스크롤, 뒤로 가기, 재검색 등 현재 상태에서의 사용자 활동(user activity)을 의미하고, 리워드는 액션 으로 획득한 상태, 즉 상태-액션 쌍에 대한 사용자의 만족도(satisfaction)를 의미할 수 있다. 단계(S330)에서 프로세서는 그래프 패스로 표현된 사용자 경험을 학습함으로써 최적 경로 예측을 위한 모 델인 OCEAN 모델을 생성할 수 있다. 프로세서는 멀티 도메인이나 크로스 플랫폼을 기초로 상호 연동 가능 한 서비스를 네트워크 형태로 연결할 수 있다. 서비스에 대한 사용자 로그로 수집된 사용자 경험은 네트워크의 그래프 패스로 표현될 수 있고, 이때 프로세서는 패스 히스토리와 각 상태에 대한 액션, 그리고 각 패스에대한 리워드를 이용하여 모델을 학습할 수 있다. 단계(S340)에서 프로세서는 타겟 사용자의 현재 세션에서 수집된 사용자 기록 세션 데이터에 대해 OCEAN 모델을 통해 사용자의 다음 행동을 예측하여 네트워크 상의 최적 경로를 추천할 수 있다. 프로세서는 네 트워크로 연결된 서비스 중 적어도 하나를 이용 중인 타겟 사용자를 대상으로 현재 세션에서의 사용자 로그에 따른 이전 패스 히스토리를 이용하여 다음 액션을 예측하고 예측된 행동의 패스를 최적 경로로 추천할 수 있다. 본 실시예에 따른 OCEAN 모델은 사용자 경험을 직접 모델링한 것으로, 적어도 하나 이상의 서비스에 대한 사용 자 경험을 포함할 수 있다. OCEAN 모델은 조합 가능한(composable) 그래프 패스 구조로 구축되어 확정성이 좋 으며, 전문가의 지식 또한 네트워크 상의 패스로 표현 가능하다. 또한, OCEAN 모델은 초개인화된 모델로서 사 용자가 최적의 목적을 달성할 수 있도록 연속적인 경험을 가이드할 수 있다. 본 실시예들은 사용자에 의해 이미 목적이 정의된 세션 단위의 사용자 기록 세션 데이터를 학습함에 따라 학습 된 여러 목적 중에서 타겟 사용자의 현재 세션 내에서의 행동을 기반으로 타겟 사용자의 목적을 스스로 찾아낼 수 있다. 도 4와 도 5는 본 발명의 일실시예에 있어서 사용자 경험 시나리오 예시를 도시한 것이다. 도 4는 '식탁 구매'라는 특정 목적을 달성하기 위해 검색창에서 식탁을 검색하고, 검색결과 화면에서 블로그 게 시글을 클릭하고, 블로그 게시글에서 확인한 제품명을 검색하고, 검색한 제품의 상품페이지로 이동하여 제품을 주문하는 일련의 시나리오를 나타내고 있다. 한편, 도 5는 도 4와 동일한 목적을 달성하기 위해 보다 많은 과정을 거치는 시나리오 예시를 나타내고 있다. 사용자는 목적을 달성하기 위해 상태와 액션을 반복한다. 이때, 상태는 서비스 화면의 내용을 나타내는 현재 사용자 상태로 정의될 수 있고, 액션은 클릭, 스크롤, 뒤로 가기, 재검색 등과 같은 사용자 활동으로 정의될 수 있다. 본 실시예에서는 상호 연동 가능한 서비스를 네트워크 형태로 연결 가능하다. 네트워크에서 사용자 경험은 네 트워크 상의 패스로 표현되고, 패스 히스토리와 각 상태에 대한 액션, 그리고 각 패스에 대한 리워드를 이용하 여 모델을 학습시킬 수 있다. 이렇게 학습된 모델은 사용자의 다음 액션을 예측하고 예측된 액션을 연결하여 최적 경로로 목적을 달성할 수 있도록 가이드할 수 있다. 예를 들어, 도 6을 참조하면, 검색 서비스(search service), 지도 서비스(map service), 쇼핑 서비스(shopping service), 간편 결제 서비스(pay service), 블로그 서비스(blog service), 광고 서비스(AD service) 등 다양한 서비스들이 상호 연동 가능한 서비스로 하나의 네트워크로 연결될 수 있다. 다양한 서비스에서 사용자 경험에 대한 패스가 만들어 질 수 있으며, 네트워크 형태로 연결된 서비스들의 패스 를 모두 포괄한 학습을 통해 최적 경로 예측을 위한 OCEAN 모델을 구축할 수 있다. 도 7은 본 발명의 일실시예에 있어서 사용자 기록 세션 데이터를 표현한 그래프 패스의 예시를 도시한 것이다. 동일한 상품을 구매하고 싶은 사용자 A, 사용자 B, 사용자 C는 달성하고자 하는 목적은 같으나 해당 목적에 이 르는 과정(사용자 경험 시나리오)이 각자 다를 수 있다. 목적 달성을 위한 세 사람의 사용자 경험을 네트워크 로 표현한 결과가 도 7과 같다고 할 때, 사용자마다 다른 과정을 거침에 따라 다양한 패스가 그려질 수 있다. 사용자 A는 결국 원하는 상품을 구매하지 못하였고, 상품을 가장 구체적으로 알고 있는 사용자 C는 세 사람 중 가장 최단 경로로 상품 구매에 성공한 것을 알 수 있다. 본 실시예에서는 그래프 패스로 구성된 사용자 경험을 학습하여 여러 경로 중 최적 경로를 예측할 수 있는 OCEAN 모델을 만들 수 있고, 이를 통해 다른 사용자에게도 사용자 C와 같은 경로를 추천하여 목적 달성을 위한 가이드를 제공할 수 있다. 도 8은 본 발명의 일실시예에 있어서 사용자 경험을 표현한 패스 구성 예시를 도시한 것이다. 도 8을 참조하면, OCEAN 모델의 네트워크는 하나 이상의 패스로 구성될 수 있고, 각 패스는 각 시간 단계에서의 상태와, 상태에 대한 액션, 액션에 대한 리워드로 구성될 수 있다. 연계 가능한 모든 서비스에서 사용자에게 제공되는 모든 화면을 대상으로 상태를 정의할 수 있고, 각 서비 스 별로 사용자들이 취할 수 있는 가능한 모든 활동(예를 들어, 클릭, 검색, 브라우즈 등)을 액션으로 정 의할 수 있고, 액션에 대한 만족도를 바탕으로 리워드를 설계할 수 있다.상태는 사용자 상태를 판단할 수 있는 모든 요소를 포함하여 정의될 수 있다. 현재 시간 단계에서 사용자 가 보고 있는 화면은 물론이고, 서비스 유형(예를 들어, 검색, 쇼핑, 지도, 블로그 등), 환경 정보(예를 들어, 시간, 위치, 날씨, 계절 등), 사용자 개인 정보(예를 들어, 연령, 성별, 취향 등), 세션 카테고리(예를 들어, 인테리어, 패션, 자동차 등) 등을 포함할 수 있다. 이를 통해 개인화된 최적 경로를 추천하는 서비스가 가능하 다. 상태는 요소에 따라 서비스 상태, 환경 상태, 사용자 상태, 세션 상태 등으로 구분될 수 있으며, 예를 들 어, 현재 쿼리, 연령, 현재 화면, 위치, 시간 등 현재 상태를 나타내는 다양한 변수들로 이루어질 수 있다. 액션은 사용자 행동을 의미하는 것으로, 쿼리(예를 들어, 텍스트, 이미지, 음성 등), 제스처(예를 들어, 뷰(view), 클릭, 스크롤, 뒤로 가기, 즐겨찾기 등) 등을 포함할 수 있다. 리워드는 액션에 대한 사용자 만족도를 의미한다. 일례로, 사용자에게 직접 피드백을 받아 액션 에 대한 만족도를 측정하는 직접 방식을 통해 리워드를 결정할 수 있다. 다른 예로, 페이지 체류 시 간(dwell time)이나 상품 구매, 페이지 클릭 등 추가 액션을 기반으로 액션에 대한 만족도를 예측하는 간 접 방식을 통해 리워드를 결정할 수 있다. 한 세션에서의 사용자 로그를 모두 그래프로 만들면 사용자 경험이 다양한 패스로 표현될 수 있다. 특정 서비스에 종속되지 않고 연계 가능한 모든 서비스에서의 사용자 경험을 상태, 액션, 리워드로 구성된 패스로 표현할 수 있다. 이와 같이 사용자 경험 자체를 모델링하여 특정 도메인이나 서비스에 의 존하지 않는 플랫폼을 구축할 수 있다. 목적을 달성하기 위한 시행착오들의 모든 집합(즉, 성공 경험과 실패 경험을 모두 포함)을 학습 데이터로 활용 할 수 있다. 예를 들어, 정답형 지식 패널 서비스로 연결되는 사용자 경험 예시는 표 1과 같다. 이때, 정답형 지식 패널 서 비스는, 예를 들어 지역이나 명소에 대해 사용자들이 원하는 기본적인 상세 정보를 바로 볼 수 있도록 제공하는 서비스이다. 다시 말해, 정답형 검색은 각 질의 별로 해당 질의에 대한 검색 결과 화면에 노출될 문서가 사전 매칭되는 검색 유형을 의미하는 것이고, 정답형 지식 패널 서비스는 정답형 검색 결과가 포함된 서비스 화면을 의미할 수 있다. 이러한 검색과 관련된 사용자 경험은, 오타를 수정하거나, 좀 더 원하는 정보에 적합한 쿼리 를 입력하는 내용을 포함한다. 표 1 est 국가코드의 정답을 찾 아가는 사용자 경험est 구가 -> est 국가 -> est 나라 -> 에스토니아 -> success est 국가 코드 -> est 나라 -> 에스토니아 -> success est -> 에스파냐 -> est 나라 -> 에스토니아 -> success est -> 에스파냐 -> fail ... 연예인 2명의 최근 출연작을 찾아가는 사용자 경험정우성 황정민 -> 정우성 황정민 영화 -> 아수라 -> success 정우성이 황정민이랑 나온 영화 -> 아수라-> success 황정민 정우성 같이 나온 영화 -> 황정민 정우성 영화 -> 아수라 -> success 황정민 정우성 영화 -> 베테랑 -> fail ... 어떤 가사의 정답 노래를 찾 고자 하는 사용자 경험갈수록 짙어져 간 -> 해품달 ost -> 시간을 거슬러 -> success 갈수록 짙어져 간 -> 해품달 ost -> 달빛이 지고 -> fail ... ... ... 상기한 사용자 경험 예시를 수집하여 모델이 학습할 수 있도록 상태, 액션, 리워드로 정의할 수 있다.표 2 상태-사용자 행동 결과 화면 액션-사용자 행동 통합 검색 결과특정 컬렉션 검색 결과 지도 화면 결과 쇼핑 화면 결과 ...검색 또는 재검색 스크롤 문서 클릭 구매 버튼 클릭 뒤로 가기 버튼 클릭 ... 리워드는 액션에 대한 사용자 만족도로 정의될 수 있다.일례로, 리워드는 노출 대비 클릭율 (CTR)을 기초로 결정될 수 있으며, 상태에서의 노출 대비 사용자 클릭이 많은 경우 포지티브 지표로 적용될 수 있다. 다른 예로, 리워드는 특정 컬렉션이나 문서, 포인트 등을 클릭하는 확률을 기초로 결정될 수 있으며, 사용 자들이 비슷한 위치를 많이 클릭한 경우 포지티브 지표로 적용되고 사용자들의 클릭 위치가 분산되어 있다면 네 거티브 지표로 적용될 수 있다. 또 다른 예로, 리워드는 체류 시간을 기초로 결정될 수 있으며, 상태에서 일정 시간 이상 오래 체류하는 경우 포지티브 지표로 적용되고 체류 시간이 일정 시간 미만으로 짧은 경우 네거티브 지표로 적용될 수 있다. 또 다른 예로, 리워드는 체류 시간 차이를 기초로 결정될 수 있으며, 현재 상태의 체류 시간이 이전 상태 의 체류 시간 보다 길면 포지티브 지표로 적용되고 현재 상태의 체류 시간이 이전 상태의 체류 시간 보다 짧으 면 네거티브 지표로 적용될 수 있다. 또 다른 예로, 리워드는 스크롤을 기초로 결정될 수 있으며, 스크롤이 적고 한 부분에 오래 머문다면 포지 티브 지표로 적용되고 의미 없는 스크롤이 많은 경우 네거티브 지표로 적용될 수 있다. 또 다른 예로, 리워드는 액션 쌍 개수(action pair count)를 기초로 결정될 수 있으며, 이전 액션과 현재 액션이 동시 출현한 경우가 일정 레벨 이상 많은 경우 포지티브 지표로 적용되고 이전 액션과 현재 액션이 동시 출현한 경우가 일정 레벨 미만인 경우 네거티브 지표로 적용될 수 있다. 또 다른 예로, 리워드는 액션 전환 확률(action transition probability)을 기초로 결정될 수 있으며, 이 전 액션에서 현재 액션으로의 전환 확률이 일정 레벨 이상 높은 경우 포지티브 지표로 적용되고 이전 액션에서 현재 액션으로의 전환 확률이 일정 레벨 미만인 경우 네거티브 지표로 적용될 수 있다. 또 다른 예로, 리워드는 현재 액션이 세션의 마지막 액션일 확률을 기초로 결정될 수 있으며, 많은 사용자 가 현재 상태에서 세션을 종료한 경우 포지티브 지표로 적용되고 많은 사용자가 현재 상태에서 다른 액션을 취 한 경우 네거티브 지표로 적용될 수 있다. 표 3 질의 시퀀스 est 구가 -> est 국가 -> est 나라 -> 에스토니아 -> success 상세 시퀀스 - action 0: 검색 (est 구가) -> state 0: 검색 결과- reward 0: ctr, dwell, ... - action 1: 재검색 (est 국가) -> state 1: 검색 결과 - reward 1: ctr, dwell, ... - action 2: 재검색 (est 나라) -> state 2: 검색 결과 - reward 2: ctr, dwell, ... - action 3: 문서 클릭 -> state 3: 클릭된 문서 내용 - reward 3: dwell time, ... - action 3: 재검색 (에스토니아) -> state 3: 검색 결과 - reward 3: ctr, dwell, ... 세션의 마지막 상태에 대한 리워드가 일정 레벨 이상으로 높은 경우 성공 경험으로 활용될 수 있고, 세션의 마 지막 상태에 대한 리워드가 일정 레벨 미만인 경우 실패 경험으로 활용될 수 있다.다시 말해, OCEAN 모델 의 학습을 위해 세션 단위로 해당 세션에서의 모든 행동 궤적을 포함하는 사용자 기록 세션 데이터를 학습 데이터로 사용할 수 있고, 학습 데이터는 서비스 상황이나 모델 학습 방법 등에 따라 적절하게 가공하여 사용할 수 있다. 예를 들어, 검색 서비스의 경우 쿼리가 액션으로 정의될 수 있고, 쇼핑 서비스의 경우 클릭이 액션 으로 정의될 수 있다. 언어 모델링 학습을 적용하는 경우 상태와 액션을 모두 언어로 표현하여 활용할 수 있다. 프로세서는 세션 내 각 시간 단계에서의 사용자 현재 상태를 상태, 사용자의 활동을 액션, 사용 자의 만족도를 리워드로 표현한 패스를 학습하여 OCEAN 모델을 구축할 수 있다. 일례로, 프로세서는 상태와 액션 및 리워드를 기반으로 하는 강화 학습(reinforcement learning)을 통해 OCEAN 모델을 생성할 수 있다. 다른 예로, 프로세서는 상태와 액션 및 리워드 자체를 언어로 이해하는 언어 모델링 학습을 통해 OCEAN 모델을 생성할 수 있다. 또 다른 예 로, 프로세서는 상태와 액션 및 리워드로 구성된 그래프 구조의 패스에 대한 신경망 (neural network) 학습을 통해 OCEAN 모델을 생성할 수 있다. 실시예에 따라서는 둘 이상의 모델을 이용 한 앙상블 학습(Ensemble learning)을 통해 OCEAN 모델을 생성하는 것 또한 가능하다. 강화 학습 기반의 모델 학습 과정을 설명하면 다음과 같다. 강화 학습을 위한 정의 중 하나로 MDP(Markov decision process)는 튜플 (S,A,τ,r,γ,μ로 정의될 수 있다. 이때, S와 A는 상태와 액션의 집합이다. τ는 모든 s,a∈S×A를 상태(S)에 대한 조건부 분포 τ(·|s,a)에 매 핑하고, r은 임의의 s,a∈S×A를 r(s,a)∈[0,1]에 매핑한다. γ∈[0,1)은 할인 인자(discount factor)이고, μ는 상태(S)에 대한 분포이다. 그리고, θ∈Rd로 매개변수화된 정책(policy) πθ는 액션(A)에 대한 조건부 분포 πθ(·|s,h)를 정의한다. 여 기서, s∈S는 현재 상태를 의미하고, h는 조건에 대한 추가 정보(예를 들어, 과거 상태-액션-리워드 이력(past state-action-reward history))를 의미한다. 또한, MDP(S,A,τ,r,γ,μ) 및 정책 πθ과 관련된 가치 함수(value function, )는 수학식 1과 같 다. [수학식 1]"}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "강화 학습의 목적은 가치 함수 V(θ)를 최대화하는 정책을 찾는 것이다. 프로세서는 최적의 정책을 추출할 수 있는 각 상태-액션 쌍에서 최대 리워드(Q 함수)를 예측하여 정책 학 습을 간접적으로 수행할 수 있다. 이때, 학습 알고리즘은 TD(temporal difference) 학습을 기반으로 하며 값 반복(value iteration)과 같은 model-based(즉, 리워드 함수와 상태 전이 분포에 대한 지식이 필요함) 방법 또 는 Q-학습과 같은 model-free(해당 지식이 필요하지 않음) 방법을 활용할 수 있다. 정책이 미분 가능한 경우 기울기(gradient) 기반 방법을 사용하여 가치 함수 V(θ)를 최적화할 수 있다. 본 실 시예에서는 주로 상승 방향(자연 기울기, TRPO 및 PPO)을 사전 조정/정규화하여 희소 신호(sparse signals)로 인해 발생하는 평평한 기울기(flat gradient) 문제를 해결할 수 있다. 프로세서는 시퀀스 모델링으로 오프라인 강화 학습을 고려하여 상태, 액션, 리워드의 시퀀스를 직접 모델 링할 수 있다. 세션 내 사용자 행동 궤적을 시퀀스 모델을 학습할 수 있는 정적 데이터 셋으로 구성할 수 있으 며, 시퀀스 모델링을 위한 의사결정 트랜스포머(decision transformer)는 수학식 2와 같다. [수학식 2]"}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, Rt는 테스트 시간에 규정할 수 있는 returns-to-go(미래 리워드의 합계)를 의미한다. 한편, 궤적 트랜스포머(trajectory transformer)는 수학식 3과 같다. [수학식 3]"}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 상태, 액션, 리워드, Rt가 이산화된 경우 테스트 시간에 수정된 빔 검색(beam search)을 사용하여 리워 드를 최대화하는 궤적을 근사화할 수 있다. OCEAN 모델은 달성 목적을 포함하는 사용자 경험으로 학습됨에 따라 모델에 대한 추가 파인튜닝 (finetuning)이 없이도 서비스와 관련된 모든 태스크에 유용한 리소스가 내포되어 있어 사용자 경험을 기반으로 모든 서비스를 개인화할 수 있다. 다만, 필요 시 파인튜닝과 같은 모델 튜닝을 통해 모델 서비스에 최적화하는 방법도 가능하다. 도 9를 참조하면, 프로세서는 동일한 목적을 달성하는 사용자 경험 각각을 상태와 액션 및 리워 드로 구성된 패스로 표현하여 패스에 대한 강화 학습을 통해 OCEAN 모델을 구축할 수 있다. 목적을 달성하기까지 다양한 패스가 존재하며, 프로세서는 OCEAN 모델을 이용하여 다음 액션을 예측 하면서 최적 경로를 찾을 수 있다. 도 10을 참조하면, 프로세서는 OCEAN 모델을 이용하여 목적 달성 에 이르는 최적 경로를 찾아 추천할 수 있다. 한 세션 내에서 현재의 상태까지 도달하게 된 사용자의 지난 액션과 상태 히스토리 시퀀스(state[0], state[1], ..., state[n-1], action[0], action[1], ..., action[n-1])는 OCEAN 모델의 입력이 되고, 마지막 상태- 액션 쌍(state[n] based on action[n])이 OCEAN 모델의 출력이 된다. action[n]에서 n은 사용자가 하나 의 목적을 달성하기 위해 시도한 액션의 개수를 의미한다. OCEAN 모델은 바로 이전 로그 하나만이 아니라, 동일 세션 내 모든 사용자 행동 궤적, 즉 이전 이력의 모 든 패스(상태, 액션, 리워드)가 다음 액션을 예측하는데 영향을 끼치게 된다. 예를 들어, state[1], action"}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[1], reward[1]을 이용하여 action [2]를 예측할 수 있고, state[1], state[2], action [1], action [2], reward[1], reward[2]를 이용하여 action [3]을 예측할 수 있고, state[1], state[2], state[3], action [1], action [2], action [3], reward[1], reward[2], reward[3]을 이용하여 action [4]을 예측할 수 있다. 이하에서는 전문가 지식을 이용한 최적 경로를 제공하는 실시예를 구체적으로 설명하기로 한다. 본 실시예에서는 OCEAN 모델을 이용하여 구현할 수 있는 서비스 중 하나로서 유니버설 어드바이저 (universal advisor)(이하, 'UA'라 칭함) 서비스를 제공할 수 있다. UA 서비스는 상향식(bottom up) 접근 방식으로 구현될 수 있다. 즉, 패스가 모여 하나의 경험이 되고, 경험이 모여 하나의 어드바이저가 되며, 어드바이저가 모여 유니버설 어드바이저가 완성될 수 있다. UA 서비스는 개인화된 정보를 기반으로 검색 흐름 전반에 걸쳐 필요한 순간에 등장하여 목적 달성을 위한 가이 드를 제공할 수 있다. 도 11은 본 발명의 일실시예에 있어서 전문가 지식을 이용한 최적 경로를 제공하는 과정의 일례를 도시한 흐름 도이다. 도 11을 참조하면, 단계(S1110)에서 프로세서는 전문가 지식 기반의 패스를 중심으로 한 학습으로 전문가 AI 모델(expert-embedded AI model)을 생성할 수 있다. 프로세서는 전문가 카테고리(예를 들어, 인테리 어, 패션, 음식, 법률 등) 각각에 대하여 해당 카테고리의 전문가 지식을 기반으로 목적을 달성한 사용자 경험 을 수집할 수 있다. 일례로, 프로세서는 전문가에 의한 사용자 경험으로 전문가의 세션에서의 모든 행동 궤적을 추적하여 해당 세션 내에서 이루어지는 일련의 모든 경험을 한 묶음의 샘플 데이터로 수집함으로써 모델 학습을 위한 학습 데이터로 사용할 수 있다. 예를 들어, 테이블을 구매하는 목적에 대해 인테리어 전문가에 해 당되는 사용자가 어떤 경로로 테이블을 구매하는지 사용자 기록 세션 데이터를 추출하여 전문가 지식 기반의 패 스를 모을 수 있다. 다른 예로, 프로세서는 전문가 지식으로 정의된 법칙을 고려하여 정답 데이터로 정해 진 패스를 수집할 수 있다. 예를 들어, 인테리어 전문가에 대하여 전문가의 지식을 개발하기 위해 인테리어 요 소(소재, 질감, 색상, 형태), 공간 스타일(내츄럴, 모던, 빈티지, 스칸디나비안 등), 공간 종류(거실, 주방, 침 실, 욕실, 현관 등) 등 인테리어 항목을 정의할 수 있고, 각 항목을 고려하여 전문가가 공간을 바꿀 때 어떤 기준으로 바꾸는지 좋은 인테리어의 판단 기준이 되는 법칙을 정의할 수 있다. 인테리어 전문가의 법칙에 맞게 좋은 인테리어로 판단되는 이미지 셋을 기초로 전문가 지식 기반의 패스를 수집할 수 있다. 프로세서는 전문가 카테고리 각각에 대해 패스를 수집하여 수집된 패스를 해당 카테고리로 분류한 후 분류된 패스들을 학습 함으로써 전문가 카테고리 별 전문가 AI 모델을 생성할 수 있다. 따라서, 프로세서는 전문가 지식이 반영 된 사용자 경험을 모델링하여 UA 서비스를 위한 전문가 AI 모델을 만들 수 있다. 프로세서는 서비스에 대 한 사용자 로그로 수집된 사용자 경험을 그래프 형태의 패스로 표현함에 있어 전문가 경험을 포함하여 전문가 경험 또한 같은 네트워크 상의 패스로 표현할 수 있다. 단계(S1120)에서 프로세서는 타겟 사용자의 현재 세션에서 수집된 사용자 기록 세션 데이터를 기초로 해당 사용자의 검색 의도를 파악할 수 있다. 세션 내 사용자 로그 데이터에서 추출된 상태와 액션 중 해당 세션의 마지막 상태를 사용자의 잠재 목적으로 정의할 수 있다. 목적 달성에 성공한 세션의 행동 궤적(state&action trajectory)을 학습한 모델을 이용하여 타겟 사용자의 다음 행동을 예측할 수 있고, 이러한 예측 결과를 바탕으 로 과거 다른 사용자들의 행동 패턴에서 타겟 사용자의 잠재 목적을 파악할 수 있다. 프로세서는 타겟 사 용자의 검색 의도에 따라 UA 서비스가 필요한 순간을 판단할 수 있다. 프로세서는 타겟 사용자의 잠재 목 적이 파악되면 해당 목적을 달성하는 여러 패스 중에서 전문가 패스가 포함되어 있는지 여부를 확인할 수 있다. 단계(S1130)에서 프로세서는 타겟 사용자의 검색 의도에 따라 UA 서비스가 필요한 순간으로 파악되면 검색 의도에 부합하는 전문가 AI 모델을 호출할 수 있다. 예를 들어, 프로세서는 사용자의 검색 의도로 파악된 잠재 목적에 대해 해당 목적을 달성했던 과거 여러 패스 중에서 인테리어 전문가 패스가 발견되면 UA 서비스가 필요한 순간으로 판단하여 인테리어 전문가 패스로 학습된 인테리어 전문가 AI 모델을 호출할 수 있다. 단계(S1140)에서 프로세서는 전문가 AI 모델을 통한 패스를 타겟 사용자에 대한 최적 경로 중 하나로 추천 할 수 있다. 프로세서는 타겟 사용자의 검색 의도에 따라 UA 서비스를 제공하는 것으로, 이때 UA 서비스 는 전문가 AI 모델을 통해 사용자의 현재 상태에 해당되는 전문가 패스를 가이드해줄 수 있다. 프로세서는 타겟 사용자에 대해 현재 세션에서 거쳐온 히스토리를 바탕으로 해당 사용자의 다음 행동을 예 측한 후 이를 통해 사용자의 검색 의도를 나타내는 잠재 목적을 파악할 수 있다. 사용자의 잠재 목적을 달성하 는 패스를 바탕으로 다음 상태를 제공하기 위해 필요한 정보를 사용자에게 요청하고 이러한 요청에 대한 사용자 입력에 따라 그에 맞는 최적 경로로 다음 상태를 제공할 수 있다. 도 12는 본 발명의 일실시예에 있어서 전문가 경험을 포함한 패스 구성 예시를 도시한 것이다. UA 서비스를 제공하기 위해서는 일반 사용자 경험은 물론이고 전문가 경험을 그래프 구조의 패스로 표현하여 모 델링할 수 있다. 도 12를 참조하면, 프로세서는 전등을 구매하는 공통된 목적을 달성하는 사용자 경험으로써 일반적인 제품 탐색 경로를 거쳐 전등을 구매하는 일반 사용자 경험과 함께, 전문가 지식으로 정의된 경로를 거쳐 전등 을 구매하는 전문가 경험을 함께 모델링할 수 있다. 프로세서는 동일한 전등 구매가 타겟 사용자의 잠재 목적으로 파악되는 경우 타겟 사용자를 대상으로 일반 사용자 경험에 의한 패스를 추천할 수도 있고, UA 서비스를 통해 전문가 경험에 의한 패스를 추천 할 수 있다. 프로세서는 UA 서비스를 위해 전문가 경험을 모델링하여 전문가 AI 모델을 구축할 수 있다. 도 13 을 참조하면, 전문가 AI 모델은 인테리어(공간), 패션, 음식, 법률 등 다양한 분야의 AI 모델을 포함할 수 있고, 프로세서는 타겟 사용자의 잠재 목적을 파악하여 그에 맞는 AI 모델을 이용하여 UA 서비스를 제 공할 수 있다. 일반 사용자 경험에서 만들어 낼 수 없는 새로운 패스를 전문가 AI 모델을 통해 만들어 낼 수 있으 며, 이때 전문가 경험은 모델링 과정에서 일반 사용자 경험에 비해 높은 리워드를 적용하는 형태로 OCEAN 모델에 반영할 수 있다. 전문가 AI 모델은 카테고리 별로 독립적인 모델로 구축될 수 있으며, 사용자의 검색 의도에 맞는 전문가 AI 모델을 선택하여 호출하는 방식으로 동작할 수 있다. 도 14 내지 도 17은 본 발명의 일실시예에 있어서 UA 서비스 시나리오 예시를 도시한 것이다. 도 14는 인테리어와 관련된 UA 서비스 시나리오 예시를 나타내고 있다. 프로세서는 사용자가 검색어 '북유럽 인테리어'를 이용한 검색 서비스를 이용하는 경우 사용자의 현재 상 태(검색어, 그리고 현재 세션에서 거쳐온 히스토리 등)를 기초로 사용자가 자신의 공간을 북유럽풍 인테리어로 바꾸고 싶다는 의도를 파악할 수 있다. 프로세서는 사용자의 검색 의도가 전문가 카테고리에 속하는 경우 해당 카테고리의 UA 서비스를 제공할 수 있다. 일례로, 프로세서는 사용자의 현재 상태가 전문가 카테고 리인 경우 UA 서비스가 필요한 순간으로 판단할 수 있다. 인테리어 전문가 AI 모델의 경우 인테리어 전문가 지식 기반의 경험을 모델링한 것으로, 인테리어 전문가 AI 모 델을 이용한 UA 서비스는 사용자에게 인테리어 공간에 대한 이미지를 요청하여 입력 이미지로부터 인테리어 공 간 정보를 추출하고 공간 내 객체를 검출하는 과정(understanding), 입력 이미지의 인테리어 공간 정보와 객체 검출 결과에 대해 인테리어 전문가 지식으로 정의된 법칙을 적용하여 분석하는 과정(reasoning), 분석 결과에 맞는 추천 솔루션을 결정하는 과정(decision making)을 거쳐 전문가 지식 기반의 추천을 제공할 수 있다. 도 14를 참조하면, 프로세서는 사용자의 검색 의도로부터 인테리어 전문가에 의한 UA 서비스가 필요한 시 점으로 판단되는 경우 검색어 '북유럽 인테리어'에 대응되는 검색 결과 화면 상에 UA 인터페이스를 노출할 수 있다. 프로세서는 OCEAN 모델을 통해 사용자의 검색 의도에 최적화된 패스를 발견하여 이를 수행하기 위해 사용자로부터 인테리어 공간에 대한 이미지 입력을 요청할 수 있다. 프로세서는 검색 결과 화면에 서 UA 인터페이스가 선택되는 경우 이미지 입력 인터페이스를 제공하여 이미지 입력을 요청할 수 있다. 프로세서는 이미지 입력 인터페이스를 통해 입력된 이미지를 사용자의 현재 상태로 추가하여 사용자 상태에 대응되는 패스로서 입력 이미지 상의 공간에 맞는 인테리어 결과를 검색 결과 화면 을 통해 추천할 수 있다. 도 15는 쇼핑과 관련된 UA 서비스 시나리오 예시를 나타내고 있다. 사용자가 특정 제품을 구매하고자 하는 목적이 있지만 제품에 대한 구체적인 정보를 알지 못하는 상태에서 '버 섯모양 조명'이라는 검색어를 입력하는 경우 검색어나 현재 세션에서 거쳐온 히스토리를 기초로 사용자가 조명 을 구매하고자 하는 의도를 파악할 수 있다. 도 15를 참조하면, 프로세서는 사용자의 검색 의도로부터 쇼핑 전문가에 의한 UA 서비스가 필요한 시점으 로 판단되는 경우 검색어 '버섯모양 조명'에 대응되는 검색 결과 화면 상에 UA 인터페이스를 노출 할 수 있다. 조명 구매를 달성하는 사용자 경험은 일반 사용자 경험은 물론이고 전문가 경험이 포함되어 모델링될 수 있다. 프로세서는 OCEAN 모델을 통해 전문가 패스를 발견하여 이를 수행하기 위해 구매하고자 하는 제품에 대한 이미지 입력을 요청할 수 있다. 프로세서는 검색 결과 화면에서 UA 인터페이스가 선택 되는 경우 이미지 입력 인터페이스를 제공하여 이미지 입력을 요청할 수 있다. 프로세서는 이미지 입력 인터페이스를 통해 입력된 이미지를 사용자의 현재 상태로 추가하여 사용자 상태에 대응되는 패스로 서 입력 이미지 상의 제품에 대한 쇼핑 정보(예를 들어, 제품 상세 정보, 제품 홈페이지, 제품 구매 페이지, 업 체 정보 등)를 검색 결과 화면을 통해 추천할 수 있다. 프로세서는 사용자가 제품 정보를 찾아 여러 단계의 탐색 과정을 거치지 않더라도 UA 서비스를 통해 불필 요한 단계를 건너 뛰어 목적을 쉽고 빠르게 달성할 수 있는 최적의 경로를 제안할 수 있다. 프로세서는 검색어나 세션에서 거쳐온 히스토리 등 사용자의 현재 상태를 기초로 사용자 의도를 이해하여 사용자 의도에 따라 플랫폼을 넘어서는 결과를 제안할 수 있다. 예를 들어, 사용자가 커피를 옷에 쏟았을 때의 상황에서 검색어로 '커피 얼룩 지우는 법'을 검색하는 경우 커피 얼룩을 제거하고자 하는 사용자의 잠재 목적을 파악하여 커피 얼룩 제거 노하우가 담긴 문서를 포함하는 검색 결과를 제공하는 검색 서비스, 커피 얼룩을 지울 때 사용하는 세제를 구매할 수 있는 쇼핑 서비스, 사용자의 현재 위치를 기반으로 주변 세탁소 목록을 제공하는 위치 기반 서비스 등을 연결해 줄 수 있다. 다시 말해, UA 서비스는 검색 서비스, 쇼핑 서비스, 위치 기반 서 비스 등 여러 플랫폼을 넘나들며 사용자가 목적을 달성할 수 있도록 적극적으로 가이드할 수 있다. 프로세서는 UA 서비스로서 상식 추론(common sense reasoning)도 가능하다. 검색어를 대신하여 사용자가 커피 얼룩이 묻은 셔츠 이미지를 업로드하면 이미지 분석을 통한 상식 추론으로 얼룩 제거라는 잠재 목적을 파 악하여 해당 목적을 달성하는 패스를 제안할 수 있다. OCEAN 모델에는 사용자 경험이 그래프 형태의 패스로 모델링되어 있다. 예를 들어, 검색어 '머리가 아플 때'에 대해 사용자가 어떤 최종 결과에 도달했는지가 검색 히스토리 데이터로 학습 가능하고 많은 사용자들이 선택한 최종 결과가 결국 상식이 된다. 이러한 사용자 경험을 학습하기 때문에 검색어 '머리가 아플 때'가 입 력되면 사용자들의 상식을 바탕으로 최종 결과를 예측할 수 있다. '머리가 아프면 두통 약을 먹는다', '배가 고프면 밥을 먹는다', '비가 오면 우산을 쓴다'와 같은 수많은 상식들이 OCEAN 모델에 반영될 수 있고, OCEAN 모델을 이용한 UA 서비스는 상식 추론을 통해 최적화된 경험을 제공할 수 있다. 그리고, 프로세서는 멀티 도메인이나 크로스 플랫폼에서 사용자가 과거 세션에서 달성하지 못한 목적에 대 해 적극적으로 알림을 제공할 수 있다. 예를 들어, UA 서비스는 사용자가 쇼핑 서비스에서 품절로 인해 목적하 는 상품을 구매하지 못한 경우 상품에 대한 상태를 모니터링하고 있다가 해당 상품이 입고되면 사용자에게 알려 줄 수 있다. 사용자의 목적 달성을 판단하는 기준으로 여러가지 있을 수 있으며, 예를 들어 검색 이후 제품을 구매한 경우, 검색 이후 페이지를 이동하여 일정 시간 이상 체류한 경우 등을 목적을 달성한 것으로 판단할 수 있다. OCEAN 모델을 구축하는 과정에서 사용자의 행동 히스토리 데이터 속에서의 마지막 상태(많은 사람들이 제 품 검색 페이지에서 세션을 종료했는지, 제품 구매 이후 세션을 종료했는지 등)를 확률적으로 학습할 수 있다. 다시 말해, 각 상태에 대해 목적을 달성한 마지막 상태일 확률을 학습할 수 있다. 사용자가 마지막 상태일 확률이 높지 않은 상태에서 세션을 종료한 경우 목적을 달성하지 못한 것으로 간주할 수 있다. 사용자의 행동 시퀀스와 현재 상태가 마지막 상태인지를 계속 모니터링하여 사용자가 목적을 달성했 는지 여부를 확인할 수 있다. 사용자가 목적을 달성하도록 최적 경로를 가이드하기 위해 중요한 요소 중 하나는 개인화이다. 사용자 상태를 얼마나 잘 파악하는지가 추천을 결정하는데 중요한 요소로 작용될 수 있다. 도 16 내지 도 17은 사용자 상태를 고려한 UA 서비스 시나리오 예시를 나타내고 있다. 프로세서는 UA 서비스를 통해 사용자의 현재 상태를 인식하여 추가 정보를 제공할 수 있다. 도 16은 상품 상세 화면을 나타내고 있다. 현재 한국에 거주하는 한국 국적의 사용자가 신발 사이즈가 미국 규격으로 표기된 상품을 탐색하고 있는 경우 UA 서비스가 필요한 시점으로 판단하여 상품 상세 화면 상에 UA 인터 페이스를 노출할 수 있다. 사용자가 미국에 거주하고 있거나 미국 국적의 사용자라면 상품 상세 화면에서 UA 인터페이스의 노 출이 생략된다. 프로세서는 상품 상세 화면에서 UA 인터페이스가 선택되는 경우 상품 상세 화면 상에 사용자의 현재 상태에 대응되는 추가 정보로서 한국 사이즈 규격을 제공하거나 사용자의 개인 정보에 맞 는 사이즈를 추천할 수 있다. 프로세서는 OCEAN 모델에 사용자 상태로 사용자의 신발 사이즈, 선호 색상, 선호 브랜드 등과 같은 개인 정보가 누적될수록 더욱 최적화된 패스로 UA 서비스를 제공할 수 있다. 도 17은 쇼핑 서비스 화면을 나타내고 있다. 사용자가 최근 소파를 구매한 이력이 있고, 인테리어, 조명, 러그와 같은 인테리어 관련 키워드 검색이 증가한 경우, 이러한 히스토리를 기반으로 사용자 상태를 정의 할 수 있다. 사용자가 쇼핑 서비스 화면을 소비하는 과정에서 인테리어 전문가 AI 모델을 이용하여 쇼핑 서비스 화면 상에 사용자 상태와 관련된 추가 정보를 포함하는 UA 인터페이스를 제공할 수 있다. 한편, 최근 다이어트가 필요해 운동을 목적으로 트레이닝복을 검색하는 사용자를 대상으로 최근 검색어와 선호 브랜드, 계절 정보 등을 토대로 사용자 상태를 정의할 수 있고, 해당 사용자를 위해 패션 전문가 AI 모델과 음 식 전문가 AI 모델 중 적어도 하나를 이용하여 관련 정보를 추천할 수 있다. 다시 말해, 프로세서는 현재 세션 또는 최근 일정 기간 동안의 사용자 행동 히스토리나 사용자 환경 정보 (예를 들어, 시간, 위치, 날씨, 계절 등), 사용자 개인 정보(예를 들어, 연령, 성별, 취향 등) 등을 사용자의 현재 상태로 정의할 수 있고 이를 통해 개인화된 패스를 가이드할 수 있다. 따라서, 프로세서는 여러 도메인의 전문가 AI 모델을 이용하여 더욱 정확하고 유용한 추천을 제공할 수 있 으며, 사용자 상태를 파악하여 현재 상태에 필요한 정보를 제공함으로써 사용자마다 다른 패스를 추천할 수 있 다.기존에는 서비스 제공자(service provider)가 정의한 규칙에 따라 추천 정보가 제공되는 반면에, 본 실시예에 따른 OCEAN 모델을 이용한 UA 서비스는 AI 모델을 통해 사용자 히스토리를 기반으로 정의된 사용자 상태에 따라 개인화된 추천 정보를 제공할 수 있다. 다시 말해, OCEAN 모델을 이용한 UA 서비스는 사용자 경험을 통해 목적을 예측하여 최적 경로를 가이드할 수 있고 더욱 다양한 변수들에 따른 결과를 제공할 수 있다. 일반 사용자 경험은 물론이고 전문가 지식 기반의 경험을 직접 모델링함으로써 모든 상황에 대해 대응이 가능하며 패스의 확장으로 새로운 서비스와의 연결도 얼 마든지 가능하다. 이처럼 본 발명의 실시예들에 따르면, 인공지능 모델을 이용하여 사용자 행동에서 패턴을 찾아 불필요한 단계들 을 건너 뛸 수 있는 사용자 목적까지의 최적 경로를 추천할 수 있다. 특히, 본 발명의 실시예들에 따르면, 사 용자 경험을 그래프 패스로 표현하여 모델링함으로써 최적 경로 예측을 위한 초개인화된 모델을 구축할 수 있고 특정 도메인이나 서비스에 의존하지 않는 플랫폼을 구축할 수 있다. 그리고, 본 발명의 실시예들에 따르면, 플 랫폼을 통해 연동 가능한 모든 서비스를 쉽게 연결 가능하고 전문가의 지식 또한 패스로 표현하여 추천 대상으 로 적용할 수 있다. 또한, 본 발명의 실시예들에 따르면, 사용자 의도에 적합한 경로로 전문가 지식으로 표현 된 경로를 추천함으로써 사용자 목적에 더욱 빠르게 도달할 수 있는 최적의 사용자 경험을 가이드할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 프로세서, 콘트롤 러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 컴퓨 터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분 산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 이때, 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수 개의 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트 워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같 은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 어플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어 를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다."}
{"patent_id": "10-2022-0170767", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2022-0170767", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 2는 본 발명의 일실시예에 따른 컴퓨터 장치의 예를 도시한 블록도이다. 도 3은 본 발명의 일실시예에 따른 컴퓨터 장치가 수행할 수 있는 방법의 예를 도시한 순서도이다. 도 4와 도 5는 본 발명의 일실시예에 있어서 사용자 경험 시나리오 예시를 도시한 것이다. 도 6은 본 발명의 일실시예에 있어서 네트워크 형태로 연결된 서비스 예시를 도시한 것이다. 도 7은 본 발명의 일실시예에 있어서 사용자 기록 세션 데이터를 표현한 그래프 패스의 예시를 도시한 것이다. 도 8은 본 발명의 일실시예에 있어서 사용자 경험을 표현한 패스 구성 예시를 도시한 것이다. 도 9 내지 도 10은 본 발명의 일실시예에 있어서 사용자 경험을 패스로 표현하여 학습한 모델을 통해 최적 경로 를 찾는 과정을 설명하기 위한 예시 도면이다. 도 11은 본 발명의 일실시예에 있어서 전문가 지식을 이용한 최적 경로를 제공하는 과정의 일례를 도시한 흐름 도이다. 도 12는 본 발명의 일실시예에 있어서 전문가 경험을 포함한 패스 구성 예시를 도시한 것이다. 도 13은 본 발명의 일실시예에 있어서 전문가 AI 모델(expert-embedded AI model) 예시를 도시한 것이다. 도 14 내지 도 17은 본 발명의 일실시예에 있어서 UA 서비스 시나리오 예시를 도시한 것이다."}
