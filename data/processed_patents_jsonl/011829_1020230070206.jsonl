{"patent_id": "10-2023-0070206", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0047900", "출원번호": "10-2023-0070206", "발명의 명칭": "캡슐내시경 영상을 이용한 위장관 분류 및 전환 영역 식별을 수행하는 전자장치 및 방법", "출원인": "동국대학교 산학협력단", "발명자": "임윤정"}}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 의해 수행되는 캡슐내시경 영상을 이용한 위장관 분류 및 전환 영역 식별 방법에 있어서,노이즈 영상을 식별하도록 학습된 제1인공지능 모델을 이용하여 상기 캡슐내시경 영상을 이루는 복수의 영상 프레임들을 노이즈 영상 및 정상 영상으로 분류하는 단계; 캡슐내시경 영상을 식도, 위, 소장 및 대장을 포함하는 위장관 별로 분류하도록 학습된 제2인공지능 모델을 이용하여 상기 정상 영상을 식도, 위, 소장 및 대장에 대응하는 영상으로 분류하는 단계;상기 분류된 영상의 예측 정확도에 기초하여 식도, 위, 소장 및 대장 간의 전환 영역을 식별하는 단계;를 포함하는 방법."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 전환 영역을 식별하는 단계는, 상기 분류된 영상을 시간 순으로 나열하여 식도, 위, 소장 및 대장에 대응하는 구간들로 시각화하는 단계; 상기 구간들에 기초하여 상기 전환 영역을 식별하는 단계;를 포함하는 방법."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 시각화하는 단계는, 상기 분류된 영상 중 예측 정확도가 임계값 이상인 영상을 추출하는 단계;를 포함하는 방법."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 시각화하는 단계는, 상기 임계값을 점진적으로 증가시키며 상기 임계값 이상인 영상을 추출하는 단계;를 포함하는 방법."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,식도, 위, 소장 및 대장에 대응하는 영상을 비병변 영상 및 병변 영상으로 분류하는 단계; 상기 병변 영상은 출혈 영상, 염증성 영상, 혈관성 영상 및 용종성 영상 중 어느 하나의 영상으로 분류하는 단계;를 더 포함하는 방법."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 분류하는 단계는, 식도, 위, 소장 및 대장에 대응하는 영상을 비병변 영상 및 병변 영상으로 분류하도록 학습된 제3인공지능 모델에 기초하여 분류하는 단계;를 포함하는 방법."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2024-0047900-3-제1항에 있어서,상기 제1인공지능 모델 및 상기 제2인공지능 모델은 노코트 플랫폼(no-code platform)을 이용하여 학습되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "캡슐내시경 영상을 이용한 위장관 분류 및 전환 영역 식별을 수행하는 전자장치에 있어서,노이즈 영상을 식별하도록 학습된 제1인공지능 모델을 이용하여 상기 캡슐내시경 영상을 이루는 복수의 영상 프레임들을 노이즈 영상 및 정상 영상으로 분류하고, 캡슐내시경 영상을 식도, 위, 소장 및 대장을 포함하는 위장관 별로 분류하도록 학습된 제2인공지능 모델을 이용하여 상기 정상 영상을 식도, 위, 소장 및 대장에 대응하는 영상으로 분류하고,상기 분류된 영상의 예측 정확도에 기초하여 식도, 위, 소장 및 대장 간의 전환 영역을 식별하는 프로세서;를포함하는 전자장치."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 프로세서는, 상기 분류된 영상을 시간 순으로 나열하여 식도, 위, 소장 및 대장에 대응하는 구간들로 표시하고,상기 구간들에 기초하여 상기 전환 영역을 식별하는 전자장치."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 프로세서는, 상기 분류된 영상 중 예측 정확도가 임계값 이상인 영상을 추출하는 전자장치."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 프로세서는, 상기 임계값을 점진적으로 증가시키며 상기 임계값 이상인 영상을 추출하는 전자장치."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서,상기 프로세서는, 식도, 위, 소장 및 대장에 대응하는 영상을 비병변 영상 및 병변 영상으로 분류하고, 상기 병변 영상은 출혈 영상, 염증성 영상, 혈관성 영상 및 용종성 영상 중 어느 하나의 영상으로 분류하는 전자장치."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는, 식도, 위, 소장 및 대장에 대응하는 영상을 비병변 영상 및 병변 영상으로 분류하도록 학습된 제3인공지능 모델에 기초하여 분류하는 전자장치."}
{"patent_id": "10-2023-0070206", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2024-0047900-4-제8항에 있어서,상기 제1인공지능 모델 및 상기 제2인공지능 모델은 노코트 플랫폼(no-code platform)을 이용하여 학습되는 것을 특징으로 하는 전자장치."}
{"patent_id": "10-2023-0070206", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 전자장치에 의해 수행되는 캡슐내시경 영상을 이용한 위장관 분류 및 전환 영역 식 별 방법에 있어서, 노이즈 영상을 식별하도록 학습된 제1인공지능 모델을 이용하여 상기 캡슐내시경 영상을 이루 는 복수의 영상 프레임들을 노이즈 영상 및 정상 영상으로 분류하는 단계; 캡슐내시경 영상을 식도, 위, 소장 및 대장을 포함하는 위장관 별로 분류하도록 학습된 제2인공지능 모델을 이용하여 상기 정상 영상을 식도, 위, 소장 및 대장에 대응하는 영상으로 분류하는 단계; 상기 분류된 영상의 예측 정확도에 기초하여 식도, 위, 소장 및 대 장 간의 전환 영역을 식별하는 단계;를 포함한다."}
{"patent_id": "10-2023-0070206", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 캡슐내시경 영상을 이용한 위장관 분류 및 전환 영역 식별을 수행하는 전자장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0070206", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "캡슐내시경(Capsule endoscopy, CE)은 위내시경(esophagogastroduodenoscopy)이나 대장내시경(colonoscopy)으 로 접근할 수 없는 소장을 탐색할 수 있는 혁신적인 진단 방법이다. 그러나 소장에서 4~10시간에 걸쳐 기록된 수십만 장의 영상 중 병변을 포함하는 단 몇 개의 영상을 찾아내려면 상당한 노력이 필요하다. 특히, 소장에서 촬영되는 영상들은 담즙, 음식물, 대변, 거품 등 이물질이 포함된 영상이 상당 부분 존재하는 바, 진단에 적합하지 않은 영상들이 많이 포함될 수 있다. 따라서 컴퓨터를 이용한 진단적 접근은 캡슐내시경 영상 판독에 도움이 되며 많은 연구에서 소장질환을 발견하는데 긍정적인 결과를 보고하고 있다. 이전 연구에서는 흐릿하고 더러운 영상, 부분적으로 보이는 병리학적 병변이 있는 영상과 같은 저품질 영상보다 정확하게 촬영된 점막을 의도적으로 선택하였다. 그 결과 영상 전체를 표현할 수 없는 캡슐내시경 사례당 대략 14~930개의 이미지만을 사용하여 인공지능 모델을 개발하였다. 이렇듯 선택된 일부 영상만으로 학습된 인공지능 모델은 한정된 영상에서만 높은 성능을 보인다. 하지만, 실제 캡슐내시경 영상은 정제되지 않은 영상이 너무 많 기 때문에, 현재까지 개발된 수많은 인공지능 모델들이 실제 데이터에 유용하게 사용되지 못하고 있다. 또한, 캡슐내시경의 인공지능 기술 적용에 대한 대부분의 연구가 병변 검출에 집중되어 있어 일부 선택된 이미지에만 적용이 가능한 실정이다. 따라서 임상의의 판독 시간을 줄이고, 영상 품질에 관계없이 전체 캡슐내시경 영상에 걸쳐 사용할 수 있는 인공 지능 모델이 필요한 실정이다."}
{"patent_id": "10-2023-0070206", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 보다 정확하고 빠르게 위장관을 분류하고, 위장관 간 전환 영역 식별하는 전자장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2023-0070206", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 전자장치에 의해 수행되는 캡슐내시경 영상을 이용한 위장관 분류 및 전환 영역 식 별 방법에 있어서, 노이즈 영상을 식별하도록 학습된 제1인공지능 모델을 이용하여 상기 캡슐내시경 영상을 이 루는 복수의 영상 프레임들을 노이즈 영상 및 정상 영상으로 분류하는 단계; 캡슐내시경 영상을 식도, 위, 소장 및 대장을 포함하는 위장관 별로 분류하도록 학습된 제2인공지능 모델을 이용하여 상기 정상 영상을 식도, 위, 소장 및 대장에 대응하는 영상으로 분류하는 단계; 상기 분류된 영상의 예측 정확도에 기초하여 식도, 위, 소장 및 대장 간의 전환 영역을 식별하는 단계;를 포함한다. 상기 전환 영역을 식별하는 단계는, 상기 분류된 영상을 시간 순으로 나열하여 식도, 위, 소장 및 대장에 대응 하는 구간들로 시각화하는 단계; 상기 구간들에 기초하여 상기 전환 영역들을 식별하는 단계;를 포함할 수 있다. 상기 시각화하는 단계는, 상기 분류된 영상 중 예측 정확도가 임계값 이상인 영상을 추출하는 단계;를 포함할 수 있다. 상기 시각화하는 단계는, 상기 임계값을 점진적으로 증가시키며 상기 임계값 이상인 영상을 추출하는 단계;를 포함할 수 있다. 상기 방법은, 식도, 위, 소장 및 대장에 대응하는 영상을 비병변 영상 및 병변 영상으로 분류하는 단계; 상기 병변 영상은 출혈 영상, 염증성 영상, 혈관성 영상 및 용종성 영상 중 어느 하나의 영상으로 분류하는 단계;를 더 포함할 수 있다. 상기 분류하는 단계는, 식도, 위, 소장 및 대장에 대응하는 영상을 비병변 영상 및 병변 영상으로 분류하도록 학습된 제3인공지능 모델에 기초하여 분류하는 단계;를 포함할 수 있다. 상기 제1인공지능 모델 및 상기 제2인공지능 모델은 노코트 플랫폼(no-code platform)을 이용하여 학습되는 것 을 특징으로 한다. 본 발명의 일 실시예에 따른 캡슐내시경 영상을 이용한 위장관 분류 및 전환 영역 식별을 수행하는 전자장치에 있어서, 노이즈 영상을 식별하도록 학습된 제1인공지능 모델을 이용하여 상기 캡슐내시경 영상을 이루는 복수의 영상 프레임들을 노이즈 영상 및 정상 영상으로 분류하고, 캡슐내시경 영상을 식도, 위, 소장 및 대장을 포함하 는 위장관 별로 분류하도록 학습된 제2인공지능 모델을 이용하여 상기 정상 영상을 식도, 위, 소장 및 대장에 대응하는 영상으로 분류하고, 상기 분류된 영상의 예측 정확도에 기초하여 식도, 위, 소장 및 대장 간의 전환 영역을 식별하는 프로세서;를 포함할 수 있다. 상기 프로세서는, 상기 분류된 영상을 시간 순으로 나열하여 식도, 위, 소장 및 대장에 대응하는 구간들로 표시 하고, 상기 구간들에 기초하여 상기 전환 영역들을 식별할 수 있다. 상기 프로세서는, 상기 분류된 영상 중 예측 정확도가 임계값 이상인 영상을 추출할 수 있다. 상기 프로세서는, 상기 임계값을 점진적으로 증가시키며 상기 임계값 이상인 영상을 추출할 수 있다. 상기 프로세서는, 식도, 위, 소장 및 대장에 대응하는 영상을 비병변 영상 및 병변 영상으로 분류하고, 상기 병 변 영상은 출혈 영상, 염증성 영상, 혈관성 영상 및 용종성 영상 중 어느 하나의 영상으로 분류할 수 있다. 상기 프로세서는, 식도, 위, 소장 및 대장에 대응하는 영상을 비병변 영상 및 병변 영상으로 분류하도록 학습된 제3인공지능 모델에 기초하여 분류할 수 있다."}
{"patent_id": "10-2023-0070206", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 위장관을 높은 정확도로 구별하여 전체 판독 시간을 줄일 수 있다. 본 발명의 일 실시예에 따르면, 예측 정확도의 임계값과 시간 경과에 따른 분류 결과의 시각화를 통해 전환 영 역을 보다 명확하고, 직관적으로 식별할 수 있다. 본 발명의 일 실시예에 따르면, 자동적인 장기 구분은 판독의 시간을 직접적으로 줄여줄 뿐만 아니라 대장 통과 시간(bowel transit time) 계산, 병변의 위치 파악에도 도움이 될 수 있다."}
{"patent_id": "10-2023-0070206", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 바람직한 실시 형태를 첨부된 도면을 참조하여 상세하게 설명한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 발명의 예시적인 실시형태를 설명하고자 하는 것이며, 본 발명이 실시될 수 있 는 유일한 실시형태를 나타내고자 하는 것이 아니다. 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략할 수 있고, 명세서 전체를 통하여 동일 또는 유사한 구성 요소에 대해서는 동일한 참조 부호를 사용할 수 있다. 도 1은 본 발명의 일 실시예에 따른 위장관 분석 시스템을 도시한 개략도이다. 도 1의 위장관 분류 및 전환 영역 식별을 수행하는 위장관 분석 시스템(이하, 시스템이라고도 한다.)은 전자장치 및 캡슐내시경을 포함한다. 본 발명의 일 실시예에 따르면, 전자장치는 캡슐내시경 영상을 이용하여 식도, 위, 소장, 대장으로 이루어지는 위장관(gastrointestinal tract, GI)을 분류하고, 식도에서 위로, 위에서 소장으로, 소장에서 대장으로의 전환 영역을 식별하는 장치이다. 본 발명의 일 실시예에 따르면, 전자장치는 컴퓨터, 서버, 스마트 폰, 태블릿 PC, 스마트 패드, 노트북 등으로 구현될 수 있다. 본 발명의 일 실시예에 따른 캡슐내시경 영상은 입에서 항문까지 전위장관 점막을 촬영한 영상이다. 캡슐내 시경 영상은 소형 카메라가 내장된 알약 크기의 캡슐내시경을 환자가 삼키면, 캡슐내시경이 환자 의 입에서 항문까지 위장관을 따라 이동하면서 위장관 내부를 촬영하여 획득될 수 있다. 이때, 전자장치는 캡슐내시경에 내장된 무선 통신 모듈을 통해 캡슐내시경 영상을 바로 수신할 수 있으며, 다만 이에 한정되지 않고 캡슐내시경과 무선 통신하여 영상을 획득하는 서버 등 외부 장치를 통해 수신할 수 있다. 본 발명의 일 실시예에 따르면, 전자장치는 먼저 캡슐내시경 영상에서 노이즈 영상을 식별하여 제 거할 수 있다. 전자장치는 노이즈 영상을 제거한 후, 정상 영상을 식도 영상, 위 영상, 소장 영상, 대장 영상으로 구별할 수 있다. 한편, 앞서 서술한 바와 같이, 캡슐내시경 영상은 수십만 개의 영상 프레임으로 이루어지는 바, 영상 전체 를 판독하는 경우 많은 시간이 소요된다. 본 발명에서는 방대한 양의 캡슐내시경 영상을 처리하기 위해 노이즈 영상을 추출하도록 학습된 인공지능 모델(이하, 제1인공지능 모델이라 한다.)을 이용하여 1차적으로 영상을 필터링하고, 2차적으로 위장관을 분류하 도록 학습된 인공지능 모델(이하, 제2인공지능 모델이라 한다.)을 이용하여 위장관을 분류하는 방안에 대해 제 안한다. 또한, 분류된 영상들을 이용하여 위장관을 구간별로 시각화하는 방안을 제안한다. 본 발명의 일 실시예에 따르면, 자동 위장관 분류는 판독 속도를 높이고, 병리학적 병변을 찾는데 도움을 줄 수 있으며, 전환 영역에 대한 직관적인 판단을 가능하게 한다. 이하, 도면들을 참조하여 본 발명의 일 실시예에 따른 전자장치의 구성 및 동작에 대해 구체적으로 설명한다. 도 2는 본 발명의 일 실시예에 따른 전자장치의 구성을 도시한 블럭도이다. 본 발명의 일 실시예에 따른 전자장치는 입력부, 통신부, 표시부, 메모리, 및 프로세 서를 포함한다. 입력부는 전자장치의 사용자 입력에 대응하여 입력데이터를 발생시킨다. 예를 들어, 사용자 입력은 전자장치의 동작을 시작하게 하는 사용자 입력, 예측 정확도를 조정하는 사용자 입력, 학습데이터를 선별 하는 사용자 입력 등일 수 있으며, 이 외에도 위장관 분류 및 전환 영역 식별에 필요한 사용자 입력인 경우 제 한하지 않고 적용 가능하다. 입력부는 적어도 하나의 입력수단을 포함한다. 입력부는 키보드(key board), 키패드(key pad), 돔 스 위치(dome switch), 터치패널(touch panel), 터치 키(touch key), 마우스(mouse), 메뉴 버튼(menu button) 등 을 포함할 수 있다. 통신부는 캡슐내시경 영상, 노이즈 영상 분류, 위장관 분류, 병변 분류를 위해 생성된 인공지능 모델 등을 수신하기 위해 캡슐내시경, 서버 등 외부장치와의 통신을 수행한다. 이를 위해, 통신부는 5G(5th generation communication), LTE-A(long term evolution-advanced), LTE(long term evolution), Wi- Fi(wireless fidelity), 블루투스(Bluetooth) 등의 무선 통신 혹은 LAN(local area network), WAN(Wide Area Network), 전력선 통신 등의 유선 통신을 수행할 수 있다. 표시부는 전자장치의 동작에 따른 표시 데이터를 표시한다. 표시부는 캡슐내시경 영상을 표시하 는 화면, 분류된 정상 영상을 표시하는 화면, 위장관 별로 분류된 영상을 표시하는 화면, 위장관에 대응하는 구 간들 및 전환 영역을 표시하는 화면, 사용자 입력을 수신하기 위한 화면 등을 표시할 수 있다. 표시부는 액정 디스플레이(LCD; liquid crystal display), 발광 다이오드(LED; light emitting diode) 디 스플레이, 유기 발광 다이오드(OLED; organic LED) 디스플레이, 마이크로 전자기계 시스템(MEMS; micro electro mechanical systems) 디스플레이 및 전자 종이(electronic paper) 디스플레이를 포함한다. 표시부 는 입력부와 결합되어 터치 스크린(touch screen)으로 구현될 수 있다. 메모리는 전자장치의 동작 프로그램들을 저장한다. 메모리는 전원의 제공 유무와 무관하게 데이 터(정보)를 보존할 수 있는 비휘발성 속성의 스토리지(storage)와, 프로세서에 의해 처리되기 위한 데이터 가 로딩되며 전원이 제공되지 않으면 데이터를 보존할 수 없는 휘발성 속성의 메모리(memory)를 포함한다. 스토 리지에는 플래시메모리(flash-memory), HDD(hard-disc drive), SSD(solid-state drive) ROM(Read Only Memory) 등이 있으며, 메모리에는 버퍼(buffer), 램(RAM; Random Access Memory) 등이 있다. 메모리는 외부장치로부터 수신한 캡슐내시경 영상, 분류된 노이즈 영상, 정상 영상, 정상 영상들에서 분류된 식도 영상, 위 영상, 소장 영상, 대장 영상, 전환 영역에 관한 정보, 제1인공지능 모델, 제2인공지능 모 델 등을 저장할 수 있다. 메모리는 캡슐내시경 영상을 복수의 영상 프레임들로 분할, 복수의 영상 프레임들을 노이즈 영상/정상 영 상으로 분류, 정상 영상을 식도/위/소장/대장 영상으로 분류, 예측 정확도에 따라 영상을 필터링, 전환 영역을 식별 등을 수행하는 과정에서 필요한 연산 프로그램 등을 저장할 수 있다. 프로세서는 프로그램 등 소프트웨어를 실행하여 전자장치의 적어도 하나의 다른 구성요소(예: 하드웨 어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 일 실시예 에 따르면, 프로세서는 중앙 처리 장치(CPU) 또는 어플리케이션 프로세서 역할을 수행하는 메인 프로세서 와 이와는 독립적으로 또는 함께 운영 가능한 그래픽 처리 장치(GPU)를 포함할 수 있다. 프로세서는 노이즈 영상을 식별하도록 학습된 제1인공지능 모델을 이용하여 상기 캡슐내시경 영상을 이루 는 복수의 영상 프레임들을 노이즈 영상 및 정상 영상으로 분류하고, 캡슐내시경 영상을 식도, 위, 소장 및 대 장을 포함하는 위장관 별로 분류하도록 학습된 제2인공지능 모델을 이용하여 상기 정상 영상을 식도, 위, 소장 및 대장에 대응하는 영상으로 분류하고, 상기 분류된 영상의 예측 정확도에 기초하여 식도, 위, 소장 및 대장 간의 전환 영역을 식별한다. 이때, 프로세서는 노이즈 영상을 식별하는 제1인공지능 모델, 캡슐내시경 영상을 식도, 위, 소장 및 대장 을 포함하는 위장관 별로 분류하는 제2인공지능 모델, 영상을 비병변 영상, 병변 영상으로 분류하는 제3인공지 능 모델을 학습하거나, 기 학습되어 생성된 제1인공지능 모델, 제2인공지능 모델 및 제3인공지능 모델을 외부로 부터 수신 및 저장하여 이용할 수 있으며 어느 하나에 한정되는 것은 아니다. 한편, 프로세서는 상기 동작들을 수행하기 위한 데이터 분석, 처리, 및 결과 정보 생성 중 적어도 일부를 규칙 기반 또는 인공지능(Artificial Intelligence) 알고리즘으로서 기계학습, 신경망 네트워크(neural network), 또는 딥러닝 알고리즘 중 적어도 하나를 이용하여 수행할 수 있다. 신경망 네트워크의 예로는, DCNN(Deep Convolutional Neural Network), CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), GAN(Generative Adversarial Networks)과 같은 모델을 포괄적으로 포함할 수 있다. 도 3은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 본 발명의 일 실시예에 따르면, 프로세서는 노이즈 영상을 식별하도록 학습된 제1인공지능 모델을 이 용하여 캡슐내시경 영상을 이루는 복수의 영상 프레임들을 노이즈 영상 및 정상 영상으로 분류할 수 있다 (S10). 노이즈 영상은 담즙, 음식물, 대변, 거품 등 이물질을 포함하는 영상으로, 프로세서는 제1인공지능 모 델을 이용하여 캡슐내시경 영상으로부터 노이즈 영상을 식별할 수 있다. 제1인공지능 모델은 이물질을 포함하는 노이즈의 특징들을 학습하여 캡슐내시경 영상의 복수의 영상 프레임들 중 노이즈 영상을 식별하도 록 학습될 수 있다. 본 발명의 일 실시예에 따르면, 프로세서는 캡슐내시경 영상을 식도, 위, 소장 및 대장을 포함하는 위장관 별로 분류하도록 학습된 제2인공지능 모델을 이용하여 정상 영상을 식도, 위, 소장 및 대장에 대응하는 영상으 로 분류할 수 있다(S20). 본 발명의 일 실시예에 따른 제1인공지능 모델 및 제2인공지능 모델을 위한 데이터 수집 및 학습 과정은 도 4 및 도 5를 참조하여 설명한다. 본 발명의 일 실시예에 따르면, 프로세서는 분류된 영상의 예측 정확도(AI score or prediction probability)에 기초하여 식도, 위, 소장 및 대장 간의 전환 영역을 식별할 수 있다(S30). 본 발명의 일 실시예에 따르면, 프로세서는 위장관 별로 분류된 영상을 시간 순으로 나열하면, 식도, 위, 소장 및 대장에 대응하는 구간들을 식별할 수 있다. 따라서, 각 구간들의 종료 시점에 배치되는 영상 프레임과 시작 시점에 배치되는 영상 프레임을 이용하여 식도-위, 위-소장, 소장-대장 간의 전환 영역을 식별할 수 있다. 식도, 위, 소장 및 대장에 대응하는 구간들을 시각화한 일 예는 도 6에서 도시한다. 그러나, 높은 예측 정확도에도 불구하고, 정상 영상 프레임 전체를 제2인공지능 모델에 적용하는 경우 위장관을 분류하는 과정에서 다른 장기로 잘못 예측되는 경우가 존재할 수 있다. 예를 들어, 위장관 별로 분류된 영상을 시간 순으로 나열하였음에도, 소장과 대장으로 예측된 영상이 반복적으로 섞여서 나타나는 경우, 실제 소장에서 대장으로의 전환 영역을 판단하기 어렵다. 본 발명에서는 제2인공지능 모델의 결과에서 개별 영상 프레임의 예측 정확도(%)의 임계값(threshold)을 조절하 여 불필요한 영상을 소거하는 방법을 이용한다. 구체적으로, 프로세서는 위장관 별로 분류된 영상 중 예측 정확도가 임계값 이상인 영상을 추출할 수 있다. 예를 들어 제2인공지능 모델에 따른 분석 결과, 예측 정확도가 99% 이상인 영상을 발췌하게 되면 전체 영상보다 결과의 이질성 (heterogeneity)이 감소할 수 있다. 나아가, 예측 정확도를 99%에서 99.95%까지 조정함에 따라 불필요한 영상들을 소거하여, 전환 영역들을 더 명확하게 판단할 수 있다. 이때, 프로세서는 입력부를 통해 예측 정확도의 임계값을 설정하는 사용자 입력을 수신할 수 있다. 이 외에도, 프로세서가 예측 정확도의 적절한 조정을 통해 최적의 결과를 내도록 예측 정확도를 식별하는 등 임계값을 설정/조정하는 방안에 대해서는 제한 없이 적용 가능하다. 추가로, 본 발명의 일 실시예에 따른 프로세서는 식도, 위, 소장 및 대장에 대응하는 영상을 비병변 영상 및 병변 영상으로 분류하고, 병변 영상은 출혈 영상, 염증성 영상, 혈관성 영상 및 용종성 영상 중 어느 하나의 영상으로 분류할 수 있다. 이때, 프로세서는 식도, 위, 소장 및 대장에 대응하는 영상을 비병변 영상 및 병변 영상으로 분류하도록 학습된 인공지능 모델(이하, 제3인공지능 모델이라 한다.)에 기초하여 분류할 수 있 다. 본 발명의 일 실시예에 따르면, 위장관을 높은 정확도로 구별하여 전체 판독 시간을 줄일 수 있다. 본 발명의 일 실시예에 따르면, 예측 정확도의 임계값과 시간 경과에 따른 분류 결과의 시각화를 통해 전환 영 역을 보다 명확하고, 직관적으로 식별할 수 있다. 도 4는 본 발명의 일 실시예에 따른 데이터 수집 모습을 도시한 도면이다. 본 발명의 일 실시예에 따르면, 전자장치는 제1인공지능 모델 및 제2인공지능 모델을 구축할 수 있으며, 이하 그 과정에 대해 설명한다. 제1인공지능 모델 및 제2인공지능 모델을 구축하기 위해 데이터 수집 및 라벨링 과정을 거칠 수 있다. 먼저, 정상적으로 수행된 복수의 캡슐내시경 사례들(cases)에 따른 복수의 캡슐내시경 영상들을 식도, 위, 소장 및 대장에 대한 영상으로 분류하고, 복수의 캡슐내시경 영상들을 훈련 데이터세트(train dataset), 테스트 데이 터세트(test dataset), 검증 데이터세트(validation dataset)로 나눌 수 있다. 데이터세트의 경우, 전문가의 수동 선택으로 인한 편향을 줄이고 영상 녹화 정보의 손실을 최소화하기 위해 영 상 프레임들이 임의적으로 선택될 수 있다. 예를 들어, 프로세서는 각 캡슐내시경 영상에서 식도 영상은 5 영상 프레임당 1장(의 영상프레임), 위·대장 영상은 1초당 1장을 추출할 수 있다. 소장 영상은 가장 광범위하 고 반복되는 영상이 많기 때문에 실제 모델 테스트를 위해 무작위로 영상을 선택할 수 있다. 훈련 데이터세트는 여기에 추가로 이물질을 포함하는 노이즈 영상을 포함할 수 있다. 본 발명의 일 실시예에 따 르면, 프로세서는 이물질을 포함하는 노이즈 영상을 선택하여 훈련데이터 세트를 선정할 수 있다. 검증 데이터세트(validation dataset)를 선정하기 위해, 먼저 복수의 캡슐내시경 사례들(cases)에 따른 복수의 캡슐내시경 영상들을 비병변 영상(정상) 및 병변 영상(출혈, 염증, 혈관, 폴립)으로 분류할 수 있다. 비병변 영상 및 병변 영상들로 분류 후, 앞서 서술한 방법(n개의 영상 프레임 당 1장, m초당 1장 등)으로 영상 프레임들 을 임의적으로 선택할 수 있다. 도 4의 일 실시예를 참조하면, 154개의 레이블이 지정된 캡슐내시경 영상들(154개 사례)을 훈련 데이터세 트(24개 사례), 테스트 데이터세트(30개 사례), 검증 데이터세트(100개 사례) 선정을 위해 무작 위로 나눌 수 있다. 본 발명의 일 실시예에 따른 프로세서는 훈련 데이터 세트의 24개 캡슐내시경 영상들에서 무작위로 선택할 수 있다. 본 실시예에서는, 훈련 데이터세트는 식도 영상 1,000개, 위 영상 10,000개, 소장 영상 15,049개, 대장 영상 10,000개 및 노이즈 영상 1,258개를 포함한다. 테스트 데이터 세트의 30개의 캡슐내시경 영상들은 식도, 위, 소장 및 대장에 대한 각각 30, 30, 30 및 28개의 비디오로 구성된다. 본 발명의 일 실시예에 따른 프로세서는 식도는 5 영상 프레임 당 1장, 위·대장은 1 초당 1장의 영상을 추출하여 테스트 데이터세트를 선정할 수 있다. 본 발명의 일 실시예에 따른 프로세서 는 소장 영상은 가장 광범위하고 반복되는 영상이 많기 때문에 실제 모델 테스트를 위해 무작위로 10,000개의 영상을 선택할 수 있다. 그 결과, 테스트 데이터세트에는 식도 영상 600개, 위 영상 10,548개, 소장 영상 10,000개, 대장 영상 18,633개 영상이 포함되었다. 본 발명의 일 실시예에 따르면, 프로세서는 테스트 데이터세트와 마찬가지로 식도는 5 영상 프레임 당 1장, 위·소장·대장은 1초당 1장의 영상 프레임을 추출하여 검증 데이터세트를 선정할 수 있다. 이하, 선정된 데이터세트를 이용하여 인공지능 모델을 학습하는 과정에 대해 설명한다. 도 5는 본 발명의 일 실시예에 따른 인공지능 모델의 학습 과정을 도시한 도면이다. 본 발명의 일 실시예에 따른 프로세서는 학습 방식을 다양하게 선정할 수 있으며, 학습 방식은 예를 들어, 노코드 플랫폼(no-code platform)을 이용하여 인공지능 모델을 학습시킬 수 있다. 노코드 플랫폼은 자동 모델 선택 및 최상의 하이퍼 파라미터(hyper prarameter)를 신속하게 식별하고 계산 지식 없이 우수한 분류 성능을 달성하는 데 특화된 도구이다. 노코드 플랫폼은 예를 들어 Neuro-T (버전 2.3.3)을 포함할 수 있다. 프로세서는 전체 길이 캡슐내시경 영상을 표현하기 위해 캡슐내시경 영상 전체에 걸쳐 영상을 고르게 추출 하고, 캡슐내시경 영상에서 노이즈 영상들을 제거하는 전처리 단계를 추가할 수 있다. 앞서 도 4와 관련하여 선정된 데이터세트에는 이물질이 포함된 부적절한 영상이 포함될 수 있으므로, 프로세서 는 이를 필터링하기 위해 제1인공지능 모델을 학습시킬 수 있다. 본 발명의 일 실시예에 따른 프로세서는 노이즈 영상으로 라벨링된 영상과, 노이즈에 대한 설명이 없는 훈 련 데이터세트의 영상을 이용하여 제1인공지능 모델을 학습시킬 수 있다. 본 발명의 일 실시예에 따른 프로세서는 크기 조정 및 정규화로 데이터 전처리 옵션을 선택적으로 수행할 수 있고, 훈련 데이터세트에 포함된 영상 프레임들을 지정된 자체 학습 방식(예를 들어, 배치 크기 20, 16 에포 크, 6 레이어 및 전역 학습률(global learning rate) 0.00146)으로 학습시킬 수 있다. 본 발명의 일 실시예에 따른 프로세서는 각 영상 프레임의 크기(픽셀)를 조정할 수 있고, 사용 가능한 그래픽 처리 장치를 기반으 로 훈련 시간 수준을 선택하고, 배치 크기를 기반으로 한 추론 속도 범위를 선택할 수 있다. 그 다음 프로세서는 제1인공지능 모델에서 필터링된 정상 영상을 이용하여 위장관을 분류하도록 제2인공지능 모델을 학습시킬 수 있다. 프로세서는 제1인공지능 모델과 동일한 방식으로 노코드 플랫폼을 사용하여 제2인공지능 모델을 학습시킬 수 있다(예를 들어, 배치 크기 36, 33 에포크, 6 레이어, 전역 학습률 0.00146). 프로세서는 제1인공지능 모델 및 제2인공지능 모델의 학습 후, 테스트 데이터세트에 적용하여 테스트하고 검증 데이터 세트에 적용하여 검증할 수 있다. 이하, 인공지능 모델들의 성능에 대한 결과값을 표 1 내지 표 4에 나타내었다. 표 1은 노코드 플랫폼을 사용한"}
{"patent_id": "10-2023-0070206", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "제2인공지능 모델의 성능 요약을 나타내고, 표 2는 영상에 적용한 제2인공지능 모델의 성능을 나타낸다. 표 3은 제3인공지능 모델에서 소장 질환별 위장관 분류 성능을 나타낸다.표 1 위장관 정확도 재현율 특이도 정밀도 NPVF1 scoreAUROC95% CI 식도 0.99 0.97 0.99 0.66 1.0 0.78 0.9980.996-1.00 0 위 0.97 0.94 0.99 0.97 0.98 0.96 0.9950.994-0.99 6 소장 0.99 1.0 0.99 0.97 1.0 0.98 1.0001.000-1.00 0 대장 0.98 0.96 0.99 0.98 0.97 0.97 0.9950.995-0.99 6 Total 0.98 0.97 0.99 0.89 0.99 0.92 0.9410.935-0.94 7 NPV, negative predictive value; AUROC, area under the receiver operating characteristic curve; 표 2 예측 정확도 임계값위장관 정확도 재현율 특이도 정밀도 NPV F1 score 0 식도 (n=5,340)0.98 (0.97-0.99)0.96 (0.93-0.98)0.98 (0.97-0.99)0.26 (0.19-0.32)1.0 (1.0-1.0)0.33 (0.26-0.40) 위 (n=217,974)0.96 (0.95-0.97)0.89 (0.86-0.92)0.98 (0.96-0.99)0.85 (0.81-0.90)0.97 (0.96-0.98)0.85 (0.81-0.88) 소장 (n=987,613)0.87 (0.85-0.89)0.83 (0.80-0.85)0.98 (0.97-0.99)0.98 (0.97-0.99)0.68 (0.63-0.72)0.89 (0.88-0.91) 대장 (n=193,276)0.87 (0.85-0.89)0.91 (0.86-0.96)0.88 (0.86-0.89)0.54 (0.48-0.61)0.97 (0.95-0.99)0.64 (0.58-0.70) 전체 (n=1,404,20 3)0.92 (0.91-0.93)0.89 (0.88-0.91)0.96 (0.95-0.96)0.67 (0.63-0.71)0.90 (0.88-0.92)0.69 (0.65-0.72) ₃99.9% 식도 (n=4,135)0.99 (0.98-1.0)0.98 (0.95-1.0) 0.99 (0.98-1.0)0.71 (0.63-0.79)1.0 (1.0-1.0)0.76 (0.69-0.84) 위 (n=128,737)0.98 (0.96-1.0)0.95 (0.92-0.98)0.98 (0.96-1.0)0.95 (0.92-0.98)0.99 (0.99-1.0)0.94 (0.91-0.97) 소장 (n=638,053)0.94 (0.93-0.96)0.92 (0.90-0.94)0.99 (0.99-1.0)1.0 (0.99-1.0)0.83 (0.80-0.87)0.95 (0.94-0.97) 대장 (n=133,981)0.94 (0.92-0.96)0.94 (0.89-0.99)0.94 (0.93-0.96)0.73 (0.66-0.79)0.99 (0.97-1.0)0.82 (0.77-0.87) 전체 (n=904,906)0.96 (0.96-0.97)0.94 (0.93-0.96)0.98 (0.97-0.99)0.85 (0.82-0.88)0.95 (0.94-0.96)0.87 (0.85-0.90) 100개의 캡슐 내시경 영상들 영상 추출로 1,715,852개의 영상(식도 5,400개, 위 229,618개, 소장 1,206,033개, 대장 274,801개)을 생성했다. 노이즈 영상 제거 과정에서 311,525개(18.2%)의 영상이 제거되었다(식도 60개, 위 11,644개, 소장 218,420개, 대장 81,525개). 표 2를 살펴보면, 1,404,203개의 영상에 위장관 분류 제2인공지능 모델을 적용하여 위장관 식별 시, 예측 정확 도 임계값이 0인 경우, 전체 정확도 0.92, 재현율 0.89, 특이도 0.96, 정밀도 0.67, NPV 0.90을 보였다. 식도와 위는 각각 0.98과 0.96의 높은 정확도를 보였으나 식도와 대장은 0.26과 0.54로 정확도가 떨어져 F1 점 수가 각각 0.33과 0.64로 낮은 결과를 보였다. 소장은 정확도 0.87, 특이도 0.98, 정밀도 0.98, F1 점수 0.89 를 보였다. 각 영상 프레임의 예측 정확도 임계값을 99.9% 이상으로 제한한 경우, 전체 영상의 약 43.7%가 제거되었다. 나 머지 904,906개의 영상에 대한 결과는 모든 위장관의 모든 성능 메트릭이 증가한 것으로 나타났다. 전체 정확도 0.96, 재현율 0.94, 특이도 0.98, 정밀도 0.85 및 NPV 0.95. 표 2는 99.9% 임계값 적용이 각 위장관에서 대부분의 성능을 크게 개선했음을 보여준다. 표 3 예측 정확도 임계값위장관 정확도 재현율 특이도 정밀도 NPV F1 score 0 Normal (n=390,410)0.93 (0.91-0.95)0.90 (0.88-0.93)0.96 (0.94-0.97)0.67 (0.60-0.74)0.91 (0.87-0.94)0.70 (0.64-0.75) Blood (n=336,656)0.89 (0.86-0.91)0.83 (0.77-0.88)0.93 (0.91-0.95)0.58 (0.48-0.67)0.89 (0.84-0.93)0.57 (0.48-0.66) Inflamed(n= 250,158)0.93 (0.91-0.95)0.91 (0.89-0.94)0.97 (0.95-0.98)0.72 (0.64-0.80)0.90 (0.85-0.94)0.73 (0.66-0.80) Vascular(n= 239,632)0.93 (0.91-0.95)0.90 (0.86-0.93)0.96 (0.94-0.98)0.69 (0.59-0.78)0.89 (0.83-0.94)0.70 (0.62-0.78) Polypoid (n=187,347)0.94 (0.92-0.96)0.94 (0.92-0.97)0.96 (0.95-0.98)0.72 (0.62-0.81)0.92 (0.88-0.96)0.74 (0.66-0.82) ₃99.9% Normal (n=261,234)0.96 (0.95-0.98)0.96 (0.94-0.98)0.97 (0.96-0.99)0.85 (0.81-0.90)0.96 (0.94-0.98)0.88 (0.85-0.92) Blood (n=196,127)0.95 (0.92-0.97)0.88 (0.83-0.94)0.97 (0.95-0.99)0.74 (0.65-0.83)0.94 (0.92-0.97)0.76 (0.68-0.85) Inflamed (n=168,331)0.97 (0.96-0.98)0.96 (0.94-0.98)0.98 (0.97-1.0)0.92 (0.88-0.96)0.94 (0.90-0.97)0.93 (0.89-0.96) Vascular (n=153,850)0.98 (0.97-0.99)0.96 (0.93-0.98)0.99 (0.98-1.0)0.86 (0.78-0.93)0.95 (0.91-0.98)0.88 (0.83-0.94) Polypoid (n=125,364)0.97 (0.96-0.99)0.98 (0.96-1.0)0.98 (0.97-1.0)0.91 (0.86-0.96)0.97 (0.94-0.99)0.93 (0.89-0.97) 도 6은 본 발명의 일 실시예에 따른 위장관 간의 전환 영역을 구별하는 모습을 도시한 도면이다. 본 발명에서는 전환 영역을 찾기 위해 분류 결과를 시간 경과에 따라 시각화했으며, 예측 정확도의 임계값을 조 정하여 기준선보다 더 직관적인 표현이 가능하게 하는 방안을 제안한다. 앞서 도 3의 S30과 관련하여 서명한 바와 같이, 도 6은 예측 정확도에 따라 식도, 위, 소장 및 대장에 대응하는 영상을 시간 순으로 나열하여 시각화한 것이다. 이때, 시각화한 모습은 도 6에 한정되지 않고, 다양한 방식으로 시각화할 수 있다. 예를 들어, 각 장기의 영상 프레임 수에 대응하는 구간의 길이를 가지고, 장기 간 전환 영역 이 구별가능 하도록 시각화 되면 충분하다. 앞서 설명한 제1인공지능 모델 및 제2인공지능 모델은 높은 성능에도 불구하고 분류된 영상들은 결과가 순차적 이지 않고 분산될 수 있다. 따라서, 분류된 영상들을 이용하여 전환 영역을 한 번에 감지하는 데는 한계가 있다. 본 발명의 일 실시예에 따른 프로세서는 예측 정확도에 대한 임계값을 점진적으로 증가시키며 예측 정확도 가 임계값 이상인 영상을 추출할 수 있다. 즉, 임계값을 점진적으로 높여 영상을 압축하여 과도기적 영역을 제 시할 수 있다. 도 6은 앞서 식도, 위, 소장 및 대장에 대응하는 영상을 시간 순으로 나열하고, 이들 중 위 영상 및 소장 영상 을 분류 결과에 따라 구간화한 것이다. 이때, 도 6의 (a)를 살펴보면, 실제 위 구간, 실제 소장 구간 및 이들 간의 실제 전환 영역으로 이루어진다고 가정한다. 위 구간의 앞부분과, 소장 구간의 뒷 부분은 중략되어 있을 수 있다. 그러나, 도 6의 (a)에서는 실제 소장 구간에 소장 영상(영상 프레임)과 대장 영상(영상 프레임)이 섞여있 음을 알 수 있다. 도 6의 (a)에서부터 순차적으로 (e)를 살펴보면, 예측 정확도(AI score)의 임계값이 99%에서 99.95%로 증가함에 따라 실제 소장 구간에 섞인 대장 영상이 점차 줄어듦을 알 수 있다. 또한, 위 구간에 서 소장 구간으로 넘어가는 과도 영역이 정보 손실 없이 더 명확하게 시각화 됨을 알 수 있다. 본 발명의 일 실시예에 따르면, 자동적인 장기 구분은 판독의 시간을 직접적으로 줄여줄 뿐만 아니라 대장 통과 시간(bowel transit time) 계산, 병변의 위치 파악에도 도움이 될 수 있다.부호의 설명 100: 전자장치 110: 입력부 120: 통신부 130: 표시부 140: 저장부 150: 프로세서 200: 캡슐내시경"}
{"patent_id": "10-2023-0070206", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 위장관 분석 시스템을 도시한 개략도이다. 도 2는 본 발명의 일 실시예에 따른 전자장치의 구성을 도시한 블럭도이다. 도 3은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 도 4는 본 발명의 일 실시예에 따른 데이터 수집 모습을 도시한 도면이다. 도 5는 본 발명의 일 실시예에 따른 인공지능 모델의 학습 과정을 도시한 도면이다. 도 6은 본 발명의 일 실시예에 따른 위장관 간의 전환 영역을 구별하는 모습을 도시한 도면이다."}
