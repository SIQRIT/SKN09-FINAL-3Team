{"patent_id": "10-2021-0152915", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0036945", "출원번호": "10-2021-0152915", "발명의 명칭": "엣지 컴퓨팅 환경의 자원 관리 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "강성주"}}
{"patent_id": "10-2021-0152915", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "워커 노드 및 마스터 노드로 구성된 엣지 서버 클러스터에 수행되는 자원 관리 방법에 있어서,영상 획득 단말로부터 추론 요청을 수신하는 단계;상태 분석 모듈로부터 가속기 정보 및 노드 정보를 수신하는 단계; 및상기 노드 정보 및 가속기 정보에 기반하여 상기 추론 요청을 수행할 노드 및 가속기를 선택하는 단계;를 포함하는 것을 특징으로 하는 엣지 컴퓨팅 환경의 자원 관리 방법."}
{"patent_id": "10-2021-0152915", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 워커 노드 및 마스터 노드로 구성된 엣지 서버 클러스 터에 수행되는 자원 관리 방법은 영상 획득 단말로부터 추론 요청을 수신하는 단계, 상태 분석 모듈로부터 가속 기 정보 및 노드 정보를 수신하는 단계, 및 상기 노드 정보 및 가속기 정보에 기반하여 상기 추론 요청을 수행할 노드 및 가속기를 선택하는 단계를 포함한다."}
{"patent_id": "10-2021-0152915", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 기술에 엣지 컴퓨팅 환경에서 가속기 등의 자원을 효율적으로 관리하기 위한 방법에 관한 것이다. 구체적으로, 본 발명은 이종의 연산/가속기가 존재하는 엣지 컴퓨팅 환경에서 가장 적합한 자원을 선택하고, 선 택한 자원을 활용하여 대기 없이 추론 서비스를 제공하기 위한 기술에 관한 것이다."}
{"patent_id": "10-2021-0152915", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "초저지연 서비스의 기반이 되는 5G 이동통신과 엣지 컴퓨팅 기술의 발전으로 실세계의 사물과 근접한 곳에서 다 양한 인공지능 서비스가 가능해지고 있다. 하지만 복잡한 연산 처리와 데이터 저장을 위한 대규모 자원이 필요 한 인공지능 서비스의 특성상 이를 효과적으로 운영하는 방법이 필요하며, 최근에는 학습은 데이터센터의 클라 우드에서, 그리고 추론은 실세계 현장의 엣지 서버를 연계해서 인공지능 서비스를 수행하는 방법들이 시도되고 있다. 인공지능 서비스를 이루는 주요 기능 중 영상 기반의 추론은 실세계에서 일어나는 다양한 상황에 대한 영상을 획득하고, 이를 기존에 학습된 데이터와 비교해 확률적으로 근접한 결과를 도출하는 기술로서 엣지 컴퓨팅 기술 이 점차 고도화됨에 따라 예전의 산업현장에서는 할 수 없었던 다양한 현장 상황 추론이 시도되고 있다. 예를 들어 공항, 항만, 철도 등 주요 시설에서의 위험물 자동 판별, 열악한 현장 작업자의 보행 동작을 분석한 낙상사고 검출, 방문객에 대한 얼굴 인식이나 번호판 인식 등이 대표적이다. 실세계와 근접한 엣지 컴퓨팅 환경은 클라우드 컴퓨팅 환경에 비해 연산자원이 제한적이다. 실제로 엣지 컴퓨팅 환경에 배치되는 엣지 서버 클러스터의 규격은 단일 서버나 4U 수준의 클러스터 시스템이며, 특히 빠른 추론 기 능에 필수적인 GPU, FPGA 등 가속기 자원은 여러 응용에 의해 공유되기 어려우므로 더욱더 제한적이다. 따라서 다수의 영상 획득 장치(ex. CCTV)들로부터 유입되는 대규모의 영상 기반 추론 요청을 제한된 연산·가속 기 자원으로 처리하기 위해서는 엣지 서버 클러스터의 컴퓨팅 자원에 대한 효율적 관리 방법이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내 공개특허공보 제 10-2021-0064033호(발명의 명칭: 공존 에지 컴퓨팅에서 분산 게임 이론 을 기반으로 무선 및 컴퓨팅 리소스를 관리하는 장치 및 방법)"}
{"patent_id": "10-2021-0152915", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 이종의 연산/가속기가 존재하는 엣지 서버 환경에서 효율적으로 연산/가속 자원을 관리하는 것이다. 또한, 본 발명의 목적은 다양한 추론 요청에 대해 유휴 노드에서 비할당된 가속기를 선별하여 원하는 서비스를 대기 없이 수행하는 것이다."}
{"patent_id": "10-2021-0152915", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 워커 노드 및 마스터 노드로 구성된 엣지 서버 클러 스터에 수행되는 자원 관리 방법은 영상 획득 단말로부터 추론 요청을 수신하는 단계, 상태 분석 모듈로부터 가 속기 정보 및 노드 정보를 수신하는 단계, 및 상기 노드 정보 및 가속기 정보에 기반하여 상기 추론 요청을 수 행할 노드 및 가속기를 선택하는 단계를 포함한다. 이때, 상기 추론 요청을 수행할 노드 및 가속기를 선택하는 단계는 가상화된 추론 서비스 저장소의 추론 응용 컨테이너를 선택할 수 있다. 이때, 상기 추론 응용 컨테이너는 특정 가속기 정보가 서비스 정의 파일에 명시되어 있을 수 있다. 이때, 상기 추론 요청을 수행할 노드 및 가속기를 선택하는 단계는 상기 수신한 추론 요청에 상응하는 추론 종 류와 매칭되는 컨테이너 중 노드 및 가속기를 선택하는 시점의 가용 노드와 가속기 정보에 기반하여 노드 및 가 속기를 선택할 수 있다. 이때, 본 발명의 일 실시예에 따른 워커 노드 및 마스터 노드로 구성된 엣지 서버 클러스터에 수행되는 자원 관 리 방법은 상기 선택된 컨테이너 정보를 클러스터 스케줄러에 전달하는 단계, 및 클러스터 스케줄러가 선택된 워커 노드에 추론 서비스를 요청하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2021-0152915", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 이종의 연산/가속기가 존재하는 엣지 서버 환경에서 효율적으로 연산/가속 자원을 관리할 수 있다. 또한, 본 발명은 다양한 추론 요청에 대해 유휴 노드에서 비할당된 가속기를 선별하여 원하는 서비스를 대기 없 이 수행할 수 있다."}
{"patent_id": "10-2021-0152915", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2021-0152915", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 비록 \"제1\" 또는 \"제2\" 등이 다양한 구성요소를 서술하기 위해서 사용되나, 이러한 구성요소는 상기와 같은 용 어에 의해 제한되지 않는다. 상기와 같은 용어는 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용될 수 있다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있다. 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세 서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다(comprises)\" 또는 \"포함하는(comprising)\"은 언급된 구성요소 또는 단계가 하나 이상의 다른 구성요소 또는 단 계의 존재 또는 추가를 배제하지 않는다는 의미를 내포한다."}
{"patent_id": "10-2021-0152915", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 해석될 수 있다. 또한, 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 컨테이너 오케스트레이션 플랫폼인 쿠버네티스 상에서 추론 서비스를 용이하게 하기 위한 솔루션이 제안되고 있 다. KFServing은 쿠버네티스에서 Tensorflow, XGBoost, ScikitLearn, PyTorch 및 ONNX와 같은 일반적인 머신러 닝 프레임워크에 대한 고성능의 높은 추상화 인터페이스를 제공한다. KFServing을 통해 다양한 머신 러닝 프레 임워크를 제공하기 위한, 쿠버네티스 사용자 리소스의 추상화가 잘 되어 있다. 그래서 쉽고 간편하게 추론 서비 스를 생성할 수 있다. 셀던 코어(Seldon core)도 머신러닝 모델을 쿠버네티스에 대규모로 배포하기 위한 오픈 소스 플랫폼이다. 셀던 코어는 머신러닝 모델(Tensorflow, Pytorch, H2o 등)을 REST 기반 서버 프로그램으로 변환한다. 셀던 코어는 수 천 개의 프로덕션 머신러닝 모델로 확장 처리하고 고급 메트릭, 요청 로깅, 설명자, 이상값 감지기, A/B 테스트, 카나리아 등을 포함한 고급 머신 러닝 기능을 서비스로 제공한다. 인텔의 오픈비노(OpenVINO)는 딥러닝 응용을 신속한 개발을 지원하는 오픈소스 툴킷이다. 오픈비노는 CNN을 기 반으로 하여 인텔 하드웨어 가속기에 대한 딥러닝과 Xeon CPU, Iris GPU, Arria FPGA 및 Movidius NPU 등의 연 산·가속기에서의 추론 기능 실행을 가능하게 한다. 오픈비노 모델 서버(Model Server)는 오픈비노 툴킷을 통해 최적화된 모델을 이용해 추론 기능을 서비스 형태로 제공할 수 있도록 한다. 임의의 머신러닝 추론 모델을 가진 개발자 또는 운영자는 상기 솔루션들을 활용해 특정 모델을 입력으로 하여 추론 서비스(서버) 프로그램을 출력물로 변환할 수 있다. 하지만 실제 프로그램 실행 환경에서 CPU, GPU, FPGA, NPU 등 연산·가속기는 서비스(프로세스) 간 경쟁을 통해 획득하는 자원이다. 따라서 실제 추론 서비스를 제공하는 환경에서 임의의 추론 요청을 처리하기 위한 추론 응용(서버)이 다른 응용 에 의해 선점된 가속기 자원을 장시간 대기하거나, 동일한 추론이 가능한 다른 연산·가속기가 가용한 상태임에 도 불구하고 추론 서비스가 유휴 가속기를 사용할 수 없기 때문에 추론 기능이 개시되지 않는 문제가 있다. 왜 냐하면 상기 솔루션-KFServing, Seldon core, OpenVINO 등의 솔루션은 추론 서비스 변환 시점에 추론에 사용하 는 가속기가 결정되어 있기 때문이다. 위와 같은 문제를 해결하기 위해서 본 발명에서는 이종의 연산·가속기가 존재하는 엣지 서버 환경에서 실제 영 상 획득 장치에서 추론 요청 시 현재 엣지 서버 클러스터 상의 이종 연산·가속기 자원 중 가장 적합한 자원을 선택하고, 선택된 종류의 연산·가속기 자원을 활용해 추론 기능을 수행하는 응용을 컨테이너 저장소로부터 추 출해 클러스터 내의 노드에 활성화하여 원하는 추론 서비스를 대기 없이 수행할 수 있게 한다. 도 1은 본 발명의 일실시예에 따른 엣지 컴퓨팅 환경의 자원 관리 방법을 개념적으로 나타낸 흐름도이다. 이때, 본 발명의 일실시예에 따른 엣지 컴퓨팅 환경의 자원 관리 방법은 워커 노드 및 마스터 노드로 구성된 엣 지 서버 클러스터에 수행될 수 있다. 이때, 상기 워커 노드는 상기 엣지 서버 클러스터 내에 복수개 존재할 수 있다. 이때, 상기 마스터 노드는 상기 엣지 서버 클러스터 내에 일반적으로 하나의 노드가 존재할 수 있으나, 본 발명 의 범위가 이에 한정되는 것은 아니다. 도 1을 참조하면, 실시예에 따른 자원 관리 방법은 영상 획득 단말로부터 추론 요청을 수신한다(S110). 이때, 상기 추론 요청은 위험물 자동 판별, 열악한 현장 작업자의 보행 동작을 분석한 낙상사고 검출, 방문객에 대한 얼굴 인식, 차량 번호판 인식 등을 포함할 수 있다. 이때, 상기 추론 요청을 수신하는 단계(S110)는 워커 노드의 추론 요청 분석 모듈(추론 요청 분석기)에서 수행 될 수 있다. 다음으로, 상태 분석 모듈(상태 추출기)로부터 가속기 정보 및 노드 정보를 수신한다(S120). 이때, 상기 가속기 정보는 가속기의 종류 및 가속기가 유휴 상태인지 여부를 포함할 수 있다. 이때 가속기의 종류는 CPU(Central Processing Unit), GPU(Graphic Processing Unit), FPGA(Field- Programmable Gate Array), 및 NPU(Neural Processing Unit)를 포함할 수 있다. 다만, 본 발명의 범위가 이에 한정되는 것은 아니며 연산/가속기의 종류는 다양하게 차용될 수 있다. 다음으로, 상기 노드 정보 및 가속기 정보에 기반하여 상기 추론 요청을 수행할 노드 및 가속기를 선택한다 (S130). 이때, 상기 추론 요청을 수행할 노드 및 가속기를 선택하는 단계(S130)는 가속기 결정 모듈(가속기 결정기)에서 수행될 수 있다. 이때, 도 1에는 도시되지 않았지만, 상기 추론 요청을 수행할 노드 및 가속기를 선택하는 단계(S130)의 수행을 위해 추론 요청 분석 모듈 및 상태 분석 모듈의 정보를 가속기 결정 모듈로 전달할 수 있다. 이때, 상기 추론 요청을 수행할 노드 및 가속기를 선택하는 단계는 가상화된 추론 서비스 저장소의 추론 응용 컨테이너를 선택할 수 있다. 이때, 상기 추론 응용 컨테이너는 특정 가속기 정보가 서비스 정의 파일에 명시되어 있을 수 있다. 이때, 상기 추론 요청을 수행할 노드 및 가속기를 선택하는 단계는 상기 수신한 추론 요청에 상응하는 추론 종 류와 매칭되는 컨테이너 중 노드 및 가속기를 선택하는 시점의 가용 노드와 가속기 정보에 기반하여 노드 및 가 속기를 선택할 수 있다. 이때, 가상화된 추론 서비스 저장소는 엣지 서버 내 가속기로 구동되는 추론 응용 전용 컨테이너와 서비스 정의 파일이 저장된 공간에 상응할 수 있다. 이때, 도 1에는 도시되지 않았지만 본 발명의 실시예에 따른 자원 관리 방법은 상기 선택된 컨테이너 정보를 클 러스터 스케줄러에 전달하는 단계, 및 클러스터 스케줄러가 선택된 워커 노드에 추론 서비스를 요청하는 단계를 더 포함할 수 있다. 도 2는 본 발명의 일실시예에 따른 자원 관리 시스템의 구성을 나타낸 연결도이다. 도 2를 참조하면, 본 발명의 일실시예에 따른 자원 관리 시스템은 영상획득장치, 마스터 노드, 워커 노드(300-1, 300-2)로 구성될 수 있다. 이때, 상기 영상획득장치, 마스터 노드, 및 워커 노드(300-1, 300-2)는 네트워크를 통해 연결될 수 있다. 이때, 상기 영상획득장치는 추론 요청을 수행하는 스마트 폰, PC(Personal computer), 태블릿 PC, CCTV 등을 포함하는 개념일 수 있다. 도 3은 본 발명의 실시예에 따른 시스템의 구성을 상세히 나타낸 도면이다. 도 3을 참조하면, 다수의 엣지 서버 노드가 엣지 서버 클러스터를 구성하는 것을 알 수 있다. 쿠버네티스에서 시스템 구성을 실시할 경우 클러스터에는 마스터 노드와 워커 노드가 존재하며, 각각의 노드에 일반 컴포넌트 외에 본 발명의 컴포넌트가 추가된다. 본 발명의 컴포넌트는 추론 요청 분석기, 상태 추출기, 연산·가속기 결정기, 클러스터 상태 모 니터, 가상화된 추론 서비스 저장소로 구성된다. 추론 요청 분석기는 쿠버네티스 워커 노드에 파드 형태(쿠버네티스 내에서 응용의 최소 단위로서 컨테이너 의 집합)로 배포가 된다. 추론 분석 요청기의 역할은 일정한 시간 간격마다 또는 외부의 영상 획득 장치에 서 추론 요청이 들어왔을 때 자신이 배치된 워커 노드의 가속기 정보를 모니터링하는 것이다. 이어서 클러스터 상태 모니터에서 수집 중인 워커 노드들의 상태 정보를 바탕으로 해당 워커 노드에 어떠 한 연산·가속기(CPU, GPU, FPGA, NPU)가 유휴한 상태인지를 판단한다. 파악된 상태 정보는 최종적으로 연산· 가속기 결정기에 전달된다. 상태 추출기는 자신이 배포된 노드의 연산·가속기 정보를 수집한다. 상태 추출기가 저장하는 정보는 해당 노드의 연산·가속기 종류, 가속기 ID, 가속기 상태를 포함할 수 있다. 연산·가속기 결정기는 클러스터 내 모든 워커 노드의 추론 요청 분석기로부터 가속기 정보를 전달받 고, 클러스터 상태 모니터로부터 유휴 노드 정보를 전달받아 <유휴 가속기 종류, 가속기 ID, 노드 이름> 정보를 갱신한다. 또한, 사용자가 요청한 <추론 종류>와 매칭되는 추론 컨테이너를 가상화된 추론 서비스 저장소로부터 확인 한다. 끝으로 선택된 추론 응용 파드를 선택된 노드에 배포하도록 클러스터의 스케줄러에 스케줄링을 요청한다. 클러스터 상태 모니터는 각 워커 노드에 배포된 상태 추출기가 수집하는 정보를 스크랩하는 서버이다. 이를 통해 워커 노드별 <유휴 가속기 종류, 가속기 ID> 정보를 수집한다 가상화된 추론 서비스 저장소는 엣지 서버 내 연산·가속기(CPU, FPGA, GPU, NPU)로 구동되는 추론 응용 전용 컨테이너와 서비스 정의 파일의 저장소이다. 각각의 추론 응용 컨테이너들은 하나의 특정 가속기 정보가 서비스 정의 파일에 명시되어 있고, 연산·가속기 결정기에 의해서 스케줄러에 요청되어 실행될 수 있다. 도 3의 가상화된 추론 서비스 저장소 내의 추론 응용 컨테이너의 표현은 다음과 같은 의미를 가진다. A, B, C, D는 얼굴 인식, 객체 인식 등 각기 다른 추론 응용의 종류를 나타낸다. - IAHC= CPU로 A 종류의 추론하는 응용 프로그램 - IBHG = GPU로 B 종류의 추론하는 응용 프로그램 - ICHF = FPGA로 C 종류의 추론하는 응용 프로그램 - IDHN = NPU로 D 종류의 추론하는 응용 프로그램 도 4는 본 발명의 일실시예에 따른 자원 관리 방법을 상세하게 나타낸 흐름도이다. 도 4를 참조하면, 본 발명의 일실시예에 따른 자원 관리 방법은 추론 요청 분석 단계, 유휴 연산·가속기 결정 단계, 추론 서비스 추출 단계, 추론 서비스 실행 단계를 포함한다. 이하, 도 4를 참조하여 실제 엣지 컴퓨팅 환경에서 영상 획득 장치로부터 임의의 추론 요청이 서버에 도착해서, 해당 요청을 처리하기 위한 가상화된 추론 서비스 응용이 임의의 워커 노드에 배치되기까지의 순서를 상세히 설 명한다. 먼저, 영상 획득 장치은 획득한 영상에 기반하여 추론 요청 분석기에 임의의 추론 서비스를 요청한다 (S202). 영상 획득 장치로부터 추론 서비스 요청을 수신한(S204) 추론 요청 분석기는 클러스터 상태 모니터 에 상기 수신한 추론 요청을 전달한다(S206). 클러스터 상태 모니터는 클러스터 모든 워커 노드의 상태 추출기로부터 현재 보유 중인 연산/가속기 정보와 가용 정보를 획득한다. 보다 상세하게, 클러스터 상태 모니터는 워커 노드 각각의 상태 추출기에 가속기 정보 요청을 전달한 다(S208). 가속기 정보 요청을 수신한 상태 추출기는 가속기 정보를 모니터링하고(S210), 가속기 정보 및 노드 정보 를 반환한다(S212). 가속기 정보 및 노드 정보를 반환 받은 클러스터 상태 모니터는 유휴 가속기 및 노드 정보를 추론 요청 분 석기에 전달한다(S214). 추론 요청 분석기는 파악된 유휴 연산·가속기 정보와 노드 정보를 연산·가속기 결정기에 전달한다 (S216).연산·가속기 결정기는 가상화된 추론 서비스 저장소 내에서 현재 유휴 노드와 가속기 정보에 기반하 여 영상 획득 장치가 요청한 추론의 종류와 매칭되는 컨테이너를 선택한다(S218). 가상화된 추론 서비스 저장소는 선택된 추론 서비스 응용 정보를 반환(S220)한다. 연산·가속기 결정기는 선택된 추론 컨테이너 정보를 클러스터 스케줄러에 전달하고, 추론 서비스 응 용의 실행을 요청한다(S222). 클러스터 스케줄러는 선택된 워커 노드에 추론 서비스를 실행한다. 실행된 추론 서버의 주소가 영상 획득 장치에 전달되고, 추론 서비스가 시작된다. 기존의 기술에 의하면 서비스 정의 파일에 응용 실행을 위해 요구되는 자원을 기입하고, 이를 바탕으로 쿠버네 티스 스케줄러에 의해 파드가 배포되는 현재의 방식에서 서비스 운영자는 다양한 유휴 가속기를 사용하기 위해 파드 정의 파일을 수정하는 작업을 반복하고 배치를 요청하는 작업도 반복해야 하는 번거로움이 있다. 본 발명의 구성에 따라 시스템을 구현함으로써 다양한 추론 요청에 대해 유휴 노드에서 비할당된 가속기를 검색 해서 원하는 추론 서비스를 대기 없이 수행할 수 있게 해준다. 이는 관련 서비스 개발 및 운영 효율을 높이는데 기여할 수 있고, 결과적으로 쿠버네티스 기반의 엣지 컴퓨팅 환경에서의 전체 추론 성능을 향상시킬 수 있다. 도 5은 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다. 실시예에 따른 엣지 컴퓨팅 환경의 자원 관리 장치는 컴퓨터로 읽을 수 있는 기록매체와 같은 컴퓨터 시스템 에서 구현될 수 있다. 컴퓨터 시스템은 버스를 통하여 서로 통신하는 하나 이상의 프로세서, 메모리, 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치 및 스토리지를 포함할 수 있다. 또한, 컴퓨터 시스템은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있다. 프로세서 는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로그램 또는 프로세싱 인스트럭션들 을 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 휘발성 매체, 비휘발성 매체, 분리형 매체, 비분리형 매체, 통신 매체, 또는 정보 전달 매체 중에서 적어도 하나 이상을 포함하는 저장 매체일 수 있 다. 예를 들어, 메모리는 ROM이나 RAM을 포함할 수 있다. 본 발명에서 설명하는 특정 실행들은 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어시스템들, 소프트웨어, 상기 시스템들의 다른 기능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재 들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “ 필수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요 소가 아닐 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐만 아 니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한다 고 할 것이다."}
{"patent_id": "10-2021-0152915", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 엣지 컴퓨팅 환경의 자원 관리 방법을 개념적으로 나타낸 흐름도이다. 도 2는 본 발명의 일실시예에 따른 자원 관리 시스템의 구성을 나타낸 연결도이다. 도 3은 본 발명의 실시예에 따른 시스템의 구성을 상세히 나타낸 도면이다. 도 4는 본 발명의 일실시예에 따른 자원 관리 방법을 상세하게 나타낸 흐름도이다. 도 5는 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다."}
