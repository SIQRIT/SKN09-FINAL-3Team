{"patent_id": "10-2022-0146927", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0065772", "출원번호": "10-2022-0146927", "발명의 명칭": "객체의 3차원 위치 실시간 추정 장치 및 방법", "출원인": "한국생산기술연구원", "발명자": "유수정"}}
{"patent_id": "10-2022-0146927", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "RGB 영상과 깊이 영상을 입력 받는 입력부;인공 신경망을 이용하여 상기 RGB 영상에서 객체를 포함하는 2차원 경계 상자를 추출하는 객체 검출부;상기 2차원 경계 상자에 대해 설명 가능한 인공 지능을 적용하여 상기 2차원 경계 상자에서 상기 객체 영역에해당하는 분할 마스크를 추출하는 객체영역 분할부; 및 상기 깊이 영상 및 상기 분할 마스크를 이용하여 상기 객체의 3차원 위치를 추정하는 객체 위치 추정부를 포함하는 객체의 3차원 위치 실시간 추정 장치."}
{"patent_id": "10-2022-0146927", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 객체 영역 분할부는상기 인공 신경망이 상기 2차원 경계 상자를 추출하는데 있어 상기 RGB 영상의 각 픽셀에 대해 참조한 정도를기초로 상기 분할 마스크를 추출하는객체의 3차원 위치 실시간 추정 장치."}
{"patent_id": "10-2022-0146927", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 객체 영역 분할부는상기 인공 신경망이 상기 2차원 경계 상자를 추출하는데 있어 상기 RGB 영상의 각 픽셀에 대해 참조한 정도를히트 맵으로 표현하고, 상기 히트 맵을 기초로 상기 분할 마스크를 추출하는객체의 3차원 위치 실시간 추정 장치."}
{"patent_id": "10-2022-0146927", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 객체 영역 분할부는상기 인공 신경망이 상기 2차원 경계 상자를 추출하는데 있어 상기 RGB 영상의 각 픽셀에 대해 참조한 정도를점수화하여 히트 맵 점수를 산출하고, 상기 히트 맵 점수를 임계치와 비교하여 상기 분할 마스크를 추출하는객체의 3차원 위치 실시간 추정 장치."}
{"patent_id": "10-2022-0146927", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 객체 영역 분할부는공개특허 10-2024-0065772-3-상기 히트 맵 점수가 임계치 이상인 픽셀들을 선택하여 상기 분할 마스크를 추출하는객체의 3차원 위치 실시간 추정 장치."}
{"patent_id": "10-2022-0146927", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서,상기 객체 영역 분할부는상기 히트 맵 점수가 임계치 미만인 픽셀들을 필터링하여 상기 분할 마스크를 추출하는객체의 3차원 위치 실시간 추정 장치."}
{"patent_id": "10-2022-0146927", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 객체 위치 추정부는상기 분할 마스크 내 각 픽셀에 대응되는 깊이 영상 값을 추출하는객체의 3차원 위치 실시간 추정 장치."}
{"patent_id": "10-2022-0146927", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 객체 위치 추정부는상기 분할 마스크 내 각 픽셀의 이미지 좌표와 카메라 투영 행렬을 이용하여 각 픽셀의 3차원 위치 좌표를 추출하는객체의 3차원 위치 실시간 추정 장치."}
{"patent_id": "10-2022-0146927", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "RGB 영상과 깊이 영상을 입력 받는 단계;인공 신경망을 이용하여 상기 RGB 영상에서 객체를 포함하는 2차원 경계 상자를 추출하는 단계;상기 2차원 경계 상자에 대해 설명 가능한 인공 지능을 적용하여 상기 2차원 경계 상자에서 상기 객체 영역에해당하는 분할 마스크를 추출하는 단계; 및 상기 깊이 영상 및 상기 분할 마스크를 이용하여 상기 객체의 3차원 위치를 추정하는 단계를 포함하는 객체의 3차원 위치 실시간 추정 방법."}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, RGB 영상과 깊이 영상을 입력 받는 입력부와, 인공 신경망을 이용하여 상기 RGB 영상에서 객체를 포 함하는 2차원 경계 상자를 추출하는 객체 검출부와, 상기 2차원 경계 상자에 대해 설명 가능한 인공 지능을 적용 하여 상기 2차원 경계 상자에서 상기 객체 영역에 해당하는 분할 마스크를 추출하는 객체영역 분할부와, 상기 깊 이 영상 및 상기 분할 마스크를 이용하여 상기 객체의 3차원 위치를 추정하는 객체 위치 추정부를 포함하는 객체 의 3차원 위치 실시간 추정 장치를 제공한다."}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 객체의 3차원 위치 실시간 추정 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "3차원 객체 검출(3d object detection) 기술은 시야 내에 보이는 각 객체의 종류를 판별하고, 해당 객체의 3차 원 위치를 가늠하는 인간의 인지 능력을 센서와 연산 장치로 구현하는 인공지능 기술이다. 인간이 작업할 때 주 변 물체의 종류를 판별하고, 위치를 가늠하는 능력은 인공지능 시스템이 고등작업을 수행하는 데에 필수적인 능 력이다. 예를 들어, 3차원 객체 검출 기술은 자율 주행 로봇이 주행 정책을 결정하기 위해 주변의 정적/동적 장 애물을 판단하는 데에 사용될 수 있다. 또한, 로봇 팔이 집어야 하는 물체를 판별하고, 해당 물체까지 팔의 이 동 궤적을 연산하는 데에 사용될 수 있다. 이와 같이 인공 지능 시스템이 3차원 객체 검출 능력을 갖추도록 만들기 위한 연구는 컴퓨터 비전 분야에서 30 년 넘게 지속적으로 수행되어 왔다. 근래에 들어, 2012년 ILSVRC(ImageNet Large Scale Visual Recognition Challenge)의 이미지 판별 문제에서 AlexNet이 뛰어난 성능을 선보인 이래로 심층학습(deep learning) 이론이 컴퓨터 비전 분야의 여러 문제들에 대한 효과적인 해결책으로 떠올랐으며, 이후 발표된 3차원 객체 검출 연구는 심층 학습을 활용한 방법이 주를 이룬다. 3차원 객체 검출 기술 연구에서 주로 사용되는 접근법 중 하나는 RGB-D 영상과 심층 학습 이론을 활용하는 방법 이다. 구체적으로 해당 방법은 RGB 영상으로부터 인근 객체의 시각적 특징 정보를 획득하고, 깊이(depth) 영상 으로부터 영상 내 각 픽셀에 대한 3차원 위치 정보를 획득하여 심층 학습 이론을 통해 인근 객체의 종류를 판별 하고, 3차원 위치를 추정한다. RGB-D 영상을 이용한 3차원 객체 검출 접근법은 크게 3가지로 분류할 수 있으며, 첫번째는 RGB 영상에 대한 2 차원 객체 검출 결과와 깊이 영상을 융합하는 방법이고, 두번째는 RGB 영상에 대한 2차원 인스턴스 분할 (instance segmentation) 결과와 깊이 영상을 융합하는 방법이며, 세번째는 RGB 영상과 깊이 영상을 인공신경망 에 함께 입력하여 3차원 객체 검출 결과를 획득하는 종단 간(end-to-end) 학습 방법이다. 먼저, RGB 영상에 대한 2차원 객체 검출 결과와 깊이 영상을 융합하는 방법은 두 단계로 구성된다. 첫번째 단계 는 2차원 객체 검출 결과를 얻는 단계로, 심층 인공 신경망(deep neural network)에 RGB 영상을 입력하여 영상 내 각 객체의 종류를 판별하고, 각 객체의 위치 및 크기를 표현하는 2차원 경계 상자(bounding box)획득한다. 두번째 단계는 각 객체의 3차원 위치를 추정하는 단계로, 각 객체에 대해 획득한 2차원 경계상자 내 깊이 영상 값을 추출하고 카메라 투영 행렬(projection matrix)을 이용하여 2차원 경계 상자 내 픽셀들의 3차원 실세계 좌 표(world coordinate)를 획득한다. 이렇게 획득한 픽셀들의 3차원 위치 좌표들을 필터링하여 객체의 3차원 위치 를 추정한다. 이 방법을 적용하기 위해서는 RGB 영상을 입력 받아 2차원 객체 검출 결과를 출력하는 심층 인공 신경망을 학습시켜야 하며, 이를 위한 학습 데이터셋의 레이블링 작업에 소요되는 시간은 이미지 당 약 38.1초 이다. 이와 같은 2차원 객체 검출 방법은 후술할 다른 접근법에 비해 평균적으로 제일 적은 연산량을 필요로 한다. 하 지만 3차원 위치 추정을 할 때 2차원 경계 상자 내 객체를 가리고 있는 물체 또는 배경 물체들로 인해서, 그리 고 객체 자세의 다양성으로 인해서 추정 잡음이 발생한다. 다음으로, RGB 영상에 대한 2차원 인스턴스 분할 결과와 깊이 영상을 융합하는 방법은 두 단계로 구성된다. 첫 번째 단계는 2차원 인스턴스 분할 결과를 얻는 단계로, 심층 인공신경망에 RGB 영상을 입력하여 영상 내 각 객 체의 종류를 판별하고, 각 객체가 영상 내에서 차지하고 있는 픽셀 영역을 나타내는 2차원 인스턴스 마스크를 획득한다. 두번째 단계는 각 객체의 3차원 위치를 추정하는 단계로, 각 객체에 대해 획득한 2차원 인스턴스 마 스크 내 깊이 영상 값을 추출하고 카메라 투영 행렬을 이용하여 2차원 인스턴스 마스크 내 픽셀들의 3차원 실세 계 좌표를 획득한다. 이렇게 획득한 픽셀들의 3차원 위치 좌표들을 필터링하여 객체의 3차원 위치를 추정한다. 이 방법을 적용하기 위해서는 RGB 영상을 입력 받아 2차원 인스턴스 분할 결과를 출력하는 심층 인공신경망을 학습시켜야 하며, 이를 위한 학습 데이터셋의 레이블링 작업에 소요되는 시간은 이미지 당 약 239.7초이다. 이 러한 2차원 인스턴스 분할 방법은 2차원 객체 검출 방법과 달리 잡음 필터링 절차를 필요로 하지 않는다. 하지 만 평균적으로 2차원 객체 검출 방법보다 많은 연산량을 필요로 한다. 마지막으로, RGB 영상과 깊이 영상을 인공 신경망에 함께 입력하는 종단 간 학습 방법은 한 단계로 구성되며, RGB 영상과 깊이 영상을 함께 심층 인공 신경망에 입력하여 영상 내 각 객체의 종류를 판별하고 3차원 위치를 획득한다. 이 방법을 적용하기 위해서는 RGB 영상과 깊이 영상을 입력 받아 3차원 객체 검출 결과를 출력하는 인공신경망을 학습시켜야 하며, 이를 위한 학습 데이터셋의 레이블링 작업에 소요되는 시간은 이미지 당 약 714.4초이다. 이와 같은 종단 간 학습 방법은 2차원 객체 검출 방법 또는 2차원 인스턴스 분할 방법과 달리 잡음 필터링 절차 를 필요로 하지 않으며, 실세계 좌표를 따로 계산할 필요도 없다. 하지만 평균적으로 2차원 객체 검출 방법과 2 차원 인스턴스 분할 방법보다 많은 연산량을 필요로 한다."}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해결하기 위해 안출된 것으로서, 본 발명은, 객체의 3차원 위치를 추정하는 과정에 설명 가능한 인공 지능 기법을 적용하여 적은 데이터셋 구축 비용으로 정확하게 객체의 3차원 위치를 추정할 수 있는 객체의 3차원 위치 실시간 추정 장치 및 방법을 제공하는 것을 목적으로 한다 본 발명에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이를 위해, 본 발명은, RGB 영상과 깊이 영상을 입력 받는 입력부와, 인공 신경망을 이용하여 상기 RGB 영상에 서 객체를 포함하는 2차원 경계 상자를 추출하는 객체 검출부와, 상기 2차원 경계 상자에 대해 설명 가능한 인 공 지능을 적용하여 상기 2차원 경계 상자에서 상기 객체 영역에 해당하는 분할 마스크를 추출하는 객체영역 분 할부와, 상기 깊이 영상 및 상기 분할 마스크를 이용하여 상기 객체의 3차원 위치를 추정하는 객체 위치 추정부 를 포함하는 객체의 3차원 위치 실시간 추정 장치를 제공한다. 여기서, 상기 객체 영역 분할부는, 상기 인공 신경망이 상기 2차원 경계 상자를 추출하는데 있어 상기 RGB 영상 의 각 픽셀에 대해 참조한 정도를 기초로 상기 분할 마스크를 추출할 수 있다. 또한, 상기 객체 영역 분할부는, 상기 인공 신경망이 상기 2차원 경계 상자를 추출하는데 있어 상기 RGB 영상의 각 픽셀에 대해 참조한 정도를 히트 맵으로 표현하고, 상기 히트 맵을 기초로 상기 분할 마스크를 추출할 수 있 다. 또한, 상기 객체 영역 분할부는, 상기 인공 신경망이 상기 2차원 경계 상자를 추출하는데 있어 상기 RGB 영상의 각 픽셀에 대해 참조한 정도를 점수화하여 히트 맵 점수를 산출하고, 상기 히트 맵 점수를 임계치와 비교하여 상기 분할 마스크를 추출할 수 있다. 또한, 상기 객체 영역 분할부는, 상기 히트 맵 점수가 임계치 이상인 픽셀들을 선택하여 상기 분할 마스크를 추 출할 수 있다. 또한, 상기 객체 영역 분할부는, 상기 히트 맵 점수가 임계치 미만인 픽셀들을 필터링하여 상기 분할 마스크를 추출할 수 있다. 또한, 상기 객체 위치 추정부는, 상기 분할 마스크 내 각 픽셀에 대응되는 깊이 영상 값을 추출할 수 있다. 또한, 상기 객체 위치 추정부는, 상기 분할 마스크 내 각 픽셀의 이미지 좌표와 카메라 투영 행렬을 이용하여 각 픽셀의 3차원 위치 좌표를 추출할 수 있다. 또한, 본 발명은, RGB 영상과 깊이 영상을 입력 받는 단계와, 인공 신경망을 이용하여 상기 RGB 영상에서 객체 를 포함하는 2차원 경계 상자를 추출하는 단계와, 상기 2차원 경계 상자에 대해 설명 가능한 인공 지능을 적용 하여 상기 2차원 경계 상자에서 상기 객체 영역에 해당하는 분할 마스크를 추출하는 단계와, 상기 깊이 영상 및 상기 분할 마스크를 이용하여 상기 객체의 3차원 위치를 추정하는 단계를 포함하는 객체의 3차원 위치 실시간 추정 방법을 제공한다."}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, RGB 영상 2차원 객체 검출 결과에 설명 가능한 인공 지능 기법을 적용하여 각 객체마다 객체 영역 분할 마스크를 획득함으로써 깊이 영상 값을 활용한 객체 3차원 위치 추정 기술의 정확도를 향상시킬 수 있다. 또한, 본 발명과 같이 학습 데이터셋이 구축되지 않은 새로운 환경을 위한 3차원 객체 검출 알고리즘을 개발할 때, 기존의 2차원 객체 검출 기술과 깊이 영상을 융합하여 사용하는 방법에서 적용된 인스턴스 분할 방법이나 종단 간 학습 방법에 비해 데이터셋 구축에 적은 비용을 소모된다. 즉, 본 발명은 기존 방법보다 더 적은 데이 터셋 구축 비용으로 더 정확하게 객체의 3차원 위치를 추정할 수 있다. 또한, 본 발명의 2차원 객체 검출 알고리즘은 필요 연산량이 비교적 적기 때문에 AR 기기, 드론, 모바일 로봇과 같이 저전력 연산 장치를 탑재한 인공 지능 시스템에서도 더 정확한 실시간 RGB-D 영상 객체 3차원 위치 추정 기술을 사용할 수 있게 된다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정해서 해석되어서는 아니 되 며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념을 적절하게 정의할 수 있다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시 예와 도면에 도시된 구성은 본 발명의 가장 바람직한 실시 예에 불과할 뿐이고 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원 시점에서 이들을 대체할 수 있는 다양한 균등 물과 변형 예들이 있을 수 있음을 이해하여야 한다. 도 1은 종래의 2차원 객체 검출 결과와 깊이 영상을 융합하여 3차원 객체의 위치를 추정하는 방법의 순서도이다. 도 1을 참조하면, 종래의 3차원 객체의 위치 추정 방법은, 먼저, RGB 영상에서 객체를 포함하는 2차원 경계 상 자를 검출한다(S10). 다음, 깊이 영상에 대해 2차원 경계 상자를 적용하여 2차원 경계 상자 내 깊이 영상 값을 추출한다(S20). 다음, 2차원 경계 상자 내 픽셀들의 실세계 좌표를 획득하고(S30), 획득한 실세계 좌표를 기초 로 객체의 3차원 위치를 추정한다(S40). 구체적으로, 2차원 객체 검출(2D object detection) 기술은, 인공 신경망을 이용하여 입력 영상 내에 존재하는 객체들의 종류(class)를 판별하고, 각 객체에 대해 중심 픽셀 과 너비 , 높이 를 가진 2차원 경계 상 자(2D bounding box)를 추정하여 해당 객체의 위치 및 크기를 표현한다. 여기서, 2D 객체 검출 인공 신경망은, 영상 을 입력 받아 영상 내 존재하는 개의 객체(object) 각각에 대해 경계 상자 회귀(bounding box regression) 결과인 , , ,와 해당 객체가 개의 객체 종류(class) 각각에 속할 확률의 추정값 , 그리고 해당 객체의 객 체 종류(class) 추정값 를 출력한다. 여기서 는 객체의 순서를 나타내는 정수이고, 는 클래스 순서를 나타내는 정수이다. 그리고 활성화 함수(activation function) 는 소 프트맥스(softmax)함수이며, 는 번째 객체가 개 클래스 각각에 속할 확률의 logit 값이다. 상기 2차원 객체 검출 결과와 깊이 영상을 융합하여 각 객체의 3차원 위치를 추정하는 과정은 카메라 역투영 (camera inverse projection)을 통해 이루어진다. 구체적으로, RGB 영상 , 깊이 영상 , 그리고 카메라 투영 행렬 가 주어졌을 때, 영상 내 번째 객체의 2차원 경계 상자에 포함된 임의의 픽셀 좌표 의 실세계 좌표(world coordinate) 는 하기 수학식 1을 통해 계산된다. [수학식 1]"}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 실수 는 깊이 영상 의 픽셀 좌표 에 측정된 깊이 값이며, 행렬 은 카메라 투 영 행렬 의 역행렬이다. 상기 수학식 1을 번째 객체의 2차원 경계 상자에 포함된 모든 픽셀 좌표 에 적용함으로써, 도 1과 같이 실세계 좌표의 집합인 점구름(point cloud) 를 획득한다. 이렇게 획득한 점구 름으로부터 평균값, 가중 평균값, 또는 중간값 등의 추정량(estimator)를 계산함으로써 번째 객체의 실세계 3 차원 위치 추정값 를 획득한다. 상기 연산 과정을 영상 의 2차원 객체 검출 결과인 모든 경계 상자에 대해 수행함으로써 개 객체의 실세계 3 차원 위치 추정값 , 를 획득한다. 전술한 종래의 2차원 객체 검출과 깊이 영상을 융합하여 객체의 3차원 위치를 추정하는 방법의 한계점은, 2차원 경계 상자 내에 객체 외 성분이 포함될 수 있다는 점이다. 도 1과 같이 2차원 경계 상자에 포함된 모든 픽셀에 대해 계산된 점구름은 객체뿐만 아니라 객체를 가리는 물체(occlusion), 배경 물체(background) 등 객체 외 성 분을 포함한다. 따라서, 객체의 3차원 위치를 획득하기 위해 추정량을 계산하는 과정에서 점구름에 포함된 객체 외 성분은 위치 추정 값에 잡음을 발생시키는 문제점이 있다. 도 2는 본 발명의 실시예에 따른 설명 가능한 인공지능 기법을 이용한 RGB-D 영상 내 검출된 객체의 3차원 위치 실시간 추정 장치를 나타내는 블록도이고, 도 3은 본 발명의 실시예에 따른 설명 가능한 인공지능 기법을 이용 한 RGB-D 영상 내 검출된 객체의 3차원 위치 실시간 추정 방법의 순서도이고, 도 4는 도 3에서 분할 마스크를 추출하는 방법의 순서도이다. 도 2 를 참조하면, 설명 가능한 인공지능 기법을 이용한 RGB-D 영상 내 검출된 객체의 3차원 위치 실시간 추정 시스템은 입력부, 메모리, 객체 검출부, 객체영역 분할부, 객체 위치 추정부를 포함할 수 있다. 도 2 및 도 3을 참조하면, 입력부는 객체를 검출하고자 하는 대상에 대한 센서 측정값을 입력 받을 수 있 다(S110). 예를 들어, RGB-D 카메라가 촬영한 RGB 영상과 깊이(depth) 영상을 실시간으로 입력 받도록 구성될수 있다. 하지만 입력부는 RGB-D 카메라에 국한되지 않으며, 본 발명은 RGB 영상과 3차원 라이다(LiDAR) 영상 입력, 또는 RGB 영상과 RGB 영상에 심층 인공 신경망을 적용하여 획득한 추정 깊이 영상을 입력 받아서 동 작할 수도 있다. 메모리는 객체 검출부, 객체영역 분할부, 객체 위치 추정부를 구동하기 위해 필요한 파라 미터를 저장하도록 구성될 수 있다. 구체적으로는, 메모리는 객체 검출부에서 사용되는 파라미터인 경계 상자 신뢰도 임계치, 클래스 추 정 확률 임계치를 저장할 수 있고, 객체영역 분할부에서 사용하는 파라미터인 히트 맵 점수 임계치, 히트 맵 구성 시 사용하는 활성화 층 수를 저장할 수 있고, 객체 3차원 위치 추정부에서 사용하는 깊이 영상 값 의 최솟값과 최댓값, 카메라 투영 행렬 등을 저장할 수 있다. 객체 검출부는 인공 신경망을 이용하여 RGB 영상에서 객체를 포함하는 2차원 경계 상자를 추출할 수 있다 (S120). 구체적으로, 객체 검출부는 입력부로부터 전달받은 RGB 영상에 사전 학습된 2차원 객체 검출 인공 신 경망을 적용하여 영상 내 각 객체에 대한 2차원 경계 상자와 객체 종류 판별 결과를 획득할 수 있다. 이 때, 2 차원 객체 검출 인공 신경망은 2차원 객체 검출 결과와 함께 영상 내 각 객체에 대한 클래스 추정 확률의 logit 값을 출력할 수 있다. 객체영역 분할부는 2차원 경계 상자에 대해 설명 가능한 인공 지능(XAI, Explainable AI)을 적용하여 2차 원 경계 상자에서 객체 영역에 해당하는 분할 마스크를 추출할 수 있다(S130). 여기서, 설명 가능한 인공지능(XAI, Explainable AI)은 판단 과정을 해석하기 어려운 블랙박스 구조인 인공 신 경망의 판단 근거를 인간이 이해할 수 있는 방식으로 표현하는 방법이다. 설명 가능한 인공지능 기술 중 주로 연구되는 방법인 히트 맵(heat map) 표현 방법은 인공 신경망이 결과값을 연산하기 위해 입력 자료에서 주로 참조한 부분을 입력 자료와 같은 차원을 가진 히트 맵으로 표현하는 방법이 다. 여기서, 히트 맵 표현 방법은 크게 3가지로 분류할 수 있는데, 첫번째는 섭동 기반 방법(perturbation based method)이고 두번째는 기울기 기반 방법(gradient based method)이며 세번째는 클래스 활성화 맵(class activation map)이다. 먼저, 섭동 기반 방법은 여러 방식으로 입력 자료에 부분적으로 변화를 주어 출력 값이 가장 많이 변화하는 입 력 자료 변화 양상을 찾는 방법이다. 후술할 다른 접근법에 비해 명확하게 해석 가능한 히트 맵을 획득할 수 있 으나, 히트 맵을 획득하기 위해 동일한 입력 자료에 대해 인공신경망 연산을 여러 차례 수행해야 하며 입력 자 료의 차원과 해상도가 증가함에 따라 많은 연산량을 필요로 한다. 다음으로, 기울기 기반 방법은 입력 자료에 대한 출력 값의 기울기(gradient)를 계산하여 인공 신경망의 클래스 추정 점수가 가장 빠르게 증가하기 위한 입력 값의 변화 양상을 획득하는 방법이다. 기울기는 인공 신경망 연산 을 한번 수행한 후 역전파(backpropagation)를 이용하여 계산할 수 있기 때문에 섭동 기반 방법보다 필요한 연 산량이 적지만 기울기 깨짐(gradient shattering) 현상으로 인해 히트 맵에 잡음이 많다. 마지막으로, 클래스 활성화 맵은 인공신경망 각 계층의 출력 값인 활성화 맵(activation map)에서 인공 신경망 최종 출력 값인 클래스 추정 점수에 기여하는 부분을 히트 맵으로 표현하는 방법이다. 이 방법은 기울기 기반 방법보다 잡음이 적으며, 섭동 기반 방법보다 연산량이 적지만 일반적으로 히트 맵의 해상도가 낮다. 히트 맵을 표현하는 설명 가능한 인공지능 기술들은 인공 지능 설명이 아닌 다른 문제를 해결하기 위해 활용되 기도 한다. 예를 들어, 섭동 기반 방법은 이미 학습된 2차원 객체 검출 인공 신경망을 이용하여 2차원 인스턴스 분할 학습 데이터셋을 구축하기 위한 자동 라벨링 시스템을 개발하는 연구에 적용되기도 하며, 클래스 활성화 맵은 입력 영상 내 특정 대상의 존재 여부를 판별하는 인공 신경망(ex: 도로 균열 유무 판별, 제품 손상 유무 판별)을 사용할 때 입력 영상에서 해당 대상의 위치를 찾기 위한 분할(segmentation) 기법으로써 적용되기도 한 다. 객체 영역 분할부는 인공 신경망이 2차원 경계 상자를 추출하는데 있어 RGB 영상의 각 픽셀에 대해 참조한 정도를 기초로 분할 마스크를 추출할 수 있다. 구체적으로, 객체 영역 분할부는 인공 신경망이 2차원 경계 상자를 추출하는데 있어 RGB 영상의 각 픽셀에 대해 참조한 정도를 히트 맵으로 표현하고, 히트 맵을 기초로 분할 마스크를 추출할 수 있다. 여기서, 객체 영역 분할부는 RGB 영상의 각 픽셀에 대해 참조한 정도를 점수화하여 히트 맵 점수를 산출하 고, 히트 맵 점수를 임계치와 비교하여 분할 마스크를 추출할 수 있다. 구체적으로, 객체 영역 분할부는, 히트 맵 점수가 임계치 이상인 픽셀들을 선택하여 분할 마스크를 추출하 거나, 히트 맵 점수가 임계치 미만인 픽셀들을 필터링하여 분할 마스크를 추출할 수 있다. 예를 들어, 도 4를 참조하면, 객체영역 분할부는 객체 검출부에서 획득한 영상 내 각 객체에 대한 2 차원 경계 상자 출력값 및 클래스 판별 점수 출력값과 입력부로부터 전달받은 RGB 영상을 이용하여 설명 가능한 인공지능 기법 중 하나인 유도된 기울기(guided gradient)를 계산함으로써 RGB 입력 영상과 2차원 객체 검출 결과 간 상관 관계를 나타내는 히트 맵을 획득할 수 있다(S131). 그리고, 객체영역 분할부는 획득한 상관관계 히트 맵을 메모리에 저장된 임계치를 기준으로 걸러내어 객체영역 분할 마스크를 획득할 수 있다(S132). 본 발명의 실시예에서는 기울기 기반 방법 중 하나인 유도된 기 울기를 명시하였지만, 실시간으로 결과를 획득할 수 없는 섭동 기반 방법을 제외한 설명 가능한 인공지능 히트 맵 표현 기법 중 SmoothGrad와 같은 기울기 기반 방법 또는 Grad-CAM, LayerCAM과 같은 클래스 활성화 맵을 적 용할 수 있다. 히트 맵을 표현하는 설명 가능한 인공지능 기법(XAI, Explainable AI)은 인공 신경망이 특정 클래스의 판별 점 수를 연산하기 위해 입력 자료에서 참조한 부분을 히트 맵으로 표현한다. 구체적으로, 히트 맵을 표현하는 XAI 기법은 클래스 판별 문제를 해결하기 위한 심층 인공 신경망이 개의 은닉 층(hidden layer)로 구성되어 있으며, 임의의 영상 를 입력 받아 해당 영상이 개의 각 클래스에 속할 확률 추정 값 을 출력한다고 가정하고, 특정 클래스 에 대한 인공 신경망의 확률 추정값 을 연산하기 위해 인공 신경망이 입력 영상에서 참조한 부분을 히트 맵 를 계산하여 나타낸다. 여러 히트 맵 표현 기법 중에서 기울기 기반 방법(gradient based method)은 출력 값의 입력에 대한 기울기 (gradient)를 이용하여 인공지능 설명을 위한 히트 맵을 표현한다. 구체적으로, 특정 클래스 에 대한 인공 신 경망 추정 확률의 logit 값인 의 입력 영상 에 대한 기울기인 를 연산하여, 클래스 에 대 한 확률의 logit 값 가 가장 빠르게 증가하기 위한 입력 영상 의 변화 양상 히트 맵 를 획득한다. 하지만 이렇게 획득한 기울기 기반 히트 맵 는 기울기를 계산하기 위한 역전파(backpropagation) 과정에서 음의 기 울기와 양의 기울기를 모두 고려하기 때문에 사람이 해석하기 어려운 잡음 성분을 많이 보유하고 있다. 이를 보 완하기 위해 제안된 유도된 역전파(guided backpropagation)는 역전파 과정에서 양의 기울기만을 고려하여 사람 이 해석 가능한 히트 맵을 표현한다. 이때, 유도된 역전파를 통해 계산된 유도된 기울기(guided gradient) 히트 맵 은 하기 수학식 2를 이용하여 계산된다. [수학식 2]"}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 , 은 인공 신경망 내 번째 은닉층의 출력값이며, 활성화 함수 는 ReLU(Rectified Linear Unit) 함수이다. 정리하면, 상기 수학식 2를 통해 유도된 기울기를 계산함으로써 클래스 판별 인공 신경망이 번째 클래스에 대한 추정 확률을 계산할 때 입력 영상 내에서 어떤 시각적 특징을 참조하는지를 표현하는 히트 맵 을 획득할 수 있다. 앞서 설명한 바와 같이 2차원 객체 검출 결과와 깊이 영상을 융합하여 객체의 3차원 위치를 추정하는 기존 방법 은, 객체의 경계 상자 내에 객체 외 성분이 포함된다는 한계점을 보유하고 있다. 기존에는 이러한 문제점을 회 피하기 위해 3차원 위치 추정 문제를 해결할 때 객체 검출을 적용하기 보다 2차원 인스턴스 분할(instance segmentation)을 적용하거나, 종단 간 학습(end-to-end learning) 방법을 적용하였다. 하지만 2차원 인스턴스 분할과 종단 간 학습 방법은 데이터셋 구축 비용과 알고리즘 자체의 연산량 측면에서 2차원 객체 검출 기술보다 많은 비용을 요구한다. 그렇기 때문에 2차원 객체 검출만으로 객체의 3차원 위치를 더 정확하게 추정하는 방법 의 연구가 필요한데, 이를 위해 앞서 설명한 유도된 기울기 XAI 기법을 적용할 수 있다. 구체적으로, 입력 영상 에 대한 2차원 객체 검출 결과로 개의 객체에 대한 2차원 경계 상자 추정 값 과 총 개의 객체 종류 각각에 대한 확률 추정값 , 그리고 객체 종류 추정값 , , 이 주어졌을 때 객체의 추정 클래스 에 대한 번째 객체의 유도된 기 울기 히트 맵 은 하기 수학식3과 같이 계산할 수 있다. [수학식 3]"}
{"patent_id": "10-2022-0146927", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 집합 은 번째 객체의 2차원 경계 상자 에 포함된 픽셀 좌표의 집합이 며, 는 2차원 경계 상자 내 픽셀 좌표에 해당하는 영상 의 픽셀 값이다. 그리고 는 인공 신경망 이 추정한 번째 객체가 번째 클래스에 속할 확률의 logit 값이다. 상기 연산 과정을 영상 의 2차원 객체 검출 결과인 모든 경계 상자에 대해 수행함으로써 개 객체에 대한 유 도된 기울기 히트 맵 , 를 획득한다. 마지막으로, 각 객체의 유도된 기울기 히트 맵 에서 임계치 보다 높은 값을 선택하여 해당 객체의 픽셀 영 역을 표시하는 객체영역 분할 마스크를 획득한다. 객체 위치 추정부는 깊이 영상 및 분할 마스크를 이용하여 객체의 3차원 위치를 추정할 수 있다. 구체적으로, 객체 위치 추정부는 객체영역 분할부에서 획득한 각 객체에 대한 객체영역 분할 마스크 내 각 픽셀에 대응되는 깊이 영상 값을 추출하고, 해당 픽셀의 이미지 좌표와 카메라 투영 행렬을 이용하여 각 픽셀의 3차원 실세계 좌표를 획득할 수 있다. 그리고, 객체 위치 추정부는 획득한 실세계 점 구름(point cloud)의 평균값을 계산하여 최종적으로 해당 객체의 3차원 위치 좌표를 획득할 수 있다. 본 발명의 실시예에서는 객체의 최종 3차원 위치를 추정하기 위해 점 구름의 평균값을 계산하였지만, 가중 평균 값, 중간값과 같이 다른 종류의 추정량(estimator)를 적용할 수도 있다. 이와 같이, 본 발명은, RGB 영상 2차원 객체 검출 결과에 설명 가능한 인공 지능 기법을 적용하여 각 객체마다 객체영역 분할 마스크를 획득함으로써 깊이 영상 값을 활용한 객체 3차원 위치 추정 기술의 정확도를 향상시킬 수 있다. 또한, 본 발명과 같이 학습 데이터셋이 구축되지 않은 새로운 환경을 위한 3차원 객체 검출 알고리즘을 개발할 때, 기존의 2차원 객체 검출 기술과 깊이 영상을 융합하여 사용하는 방법에서 적용된 인스턴스 분할 방법이나 종단 간 학습 방법에 비해 데이터셋 구축에 적은 비용을 소모된다. 즉, 본 발명은 기존 방법보다 더 적은 데이 터셋 구축 비용으로 더 정확하게 객체의 3차원 위치를 추정할 수 있다. 또한, 본 발명의 2차원 객체 검출 알고리즘은 필요 연산량이 비교적 적기 때문에 AR 기기, 드론, 모바일 로봇과 같이 저전력 연산 장치를 탑재한 인공 지능 시스템에서도 더 정확한 실시간 RGB-D 영상 객체 3차원 위치 추정 기술을 사용할 수 있게 된다.이상의 상세한 설명은 본 발명을 예시하는 것이다. 또한, 전술한 내용은 본 발명의 바람직한 실시 형태를 나타 내고 설명하는 것에 불과하며, 본 발명은 다양한 다른 조합, 변경 및 환경에서 사용할 수 있다. 즉, 본 명세서 에 개시된 발명의 개념의 범위, 저술한 개시 내용과 균등한 범위 및/또는 당 업계의 기술 또는 지식의 범위 내 에서 변경 또는 수정할 수 있다. 전술한 실시 예들은 본 발명을 실시함에 있어 최선의 상태를 설명하기 위한 것이며, 본 발명과 같은 다른 발명 을 이용하는데 당 업계에 알려진 다른 상태로의 실시, 그리고 발명의 구체적인 적용 분야 및 용도에서 요구되는 다양한 변경도 가능하다. 따라서 이상의 발명의 상세한 설명은 개시된 실시 상태로 본 발명을 제한하려는 의도 가 아니다. 또한, 첨부된 청구범위는 다른 실시 상태도 포함하는 것으로 해석되어야 한다."}
{"patent_id": "10-2022-0146927", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 2차원 객체 검출 결과와 깊이 영상을 융합하여 3차원 객체의 위치를 추정하는 방법의 순서도이다. 도 2는 본 발명의 실시예에 따른 설명 가능한 인공지능 기법을 이용한 RGB-D 영상 내 검출된 객체의 3차원 위치 실시간 추정 장치를 나타내는 블록도이다. 도 3은 본 발명의 실시예에 따른 설명 가능한 인공지능 기법을 이용한 RGB-D 영상 내 검출된 객체의 3차원 위치 실시간 추정 방법의 순서도이다. 도 4는 도 3에서 분할 마스크를 추출하는 방법의 순서도이다."}
