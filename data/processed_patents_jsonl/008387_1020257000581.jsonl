{"patent_id": "10-2025-7000581", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0024805", "출원번호": "10-2025-7000581", "발명의 명칭": "안내 로봇 및 안내 로봇의 동작방법", "출원인": "엘지전자 주식회사", "발명자": "박미현"}}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "안내 로봇으로서,주변의 관람객 정보를 획득하기 위한 센서;상기 관람객 정보에 근거하여 대상 전시물과 관련된 도착 위치를 결정하는 프로세서; 및상기 결정된 도착 위치로 로봇을 이동시키기 위한 주행부를 포함하고,상기 프로세서는,상기 결정된 도착 위치에서 상기 관람객 정보에 포함된 관람객의 얼굴 방향에 대응하도록 로봇의 자세 또는 시선방향을 조절하고, 대상 전시물에 대한 발화 동안 업데이트되는 관람객 정보에 기초하여 다음 동작을결정하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 결정된 도착 위치에서 상기 대상 전시물에 대한 주변 혼잡도에 근거하여 로봇의 세부 위치의 조정 필요 여부를 결정하고, 상기 결정에 따라 세부 위치의 이동 또는 확인 후, 상기 자세 또는 시선방향을 조절하는안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,대상 전시물 주변의 혼잡도가 정해진 범위 이상인 것에 응답하여, 상기 주행부를 제어하여 상기 대상 전시물 주변의 관람객과 일정거리 이격된 지점에 위치하도록 로봇의 세부 위치를 조정하고, 상기 로봇이 상기 대상 전시물를 향하도록 각도를 조절하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,안내 로봇이 미리입력된 POI에 대응되는 제1 그룹의 후보 지점들로 이동할 수 없는 것으로 판단되면, 상기 관람객 정보에 기반하여 결정된 로봇의 도착 위치에 대응하는 제2 그룹의 후보 지점들 중 하나를 로봇의 세부 위치로 결정하고,상기 제2 그룹의 후보 지점들 간의 관계는 상기 제1 그룹의 후보 지점들 간의 관계에 대응되는안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,공개특허 10-2025-0024805-3-로봇의 전면 바디에 장착되어, 상기 대상 전시물과 관련된 시각정보를 표시하는 디스플레이를 더 포함하고,상기 프로세서는,대상 전시물 주변의 혼잡도가 정해진 범위 이상인 것에 응답하여, 상기 디스플레이가 상기 혼잡도가 평균 이하인 방향을 향하도록 로봇의 전면 바디를 회전시키는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 관람객 정보를 획득하기 위한 센서는 카메라와 3D 뎁쓰 카메라, 라이다, 근접 센서 중 적어도 하나 이상을포함하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 안내 로봇은,상부에 위치하여 로봇의 얼굴 표정변화를 표시하는 제1 디스플레이를 포함하는 헤드부와, 상기 헤드부 및 상기주행부 사이에 위치하여 상기 대상 전시물에 대한 설명과 관련된 시각정보를 표시하는 제2디스플레이를 포함하는 바디부로 구분되며,상기 프로세서는,상기 제2디스플레이가 상기 관람객 정보에 포함된 관람객의 얼굴 방향과 마주하도록 상기 바디부의 중심을 정렬하고,발화 동안 모니터링되는 관람객 정보에 포함된 얼굴 밀집 분포에 기초하여, 로봇의 주시방향이 변화하도록 상기제1 디스플레이의 표시를 제어하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는,상기 제1 디스플레이를 제어하여, 상기 관람객의 얼굴 밀집 분포가 평균 이상인 지점 또는 영역을 더 오래 주시하도록 로봇의 주시방향을 조절하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는,상기 결정된 도착 위치로 로봇의 이동시, 로봇과 관람객이 일정거리를 유지하도록 상기 주행부를 통해 주행속도를 조절하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 안내 로봇에 장착되어, 대상 전시물에 대한 발화를 출력하는 스피커를 더 포함하고,공개특허 10-2025-0024805-4-상기 프로세서는,상기 대상 전시물에 대한 발화 개시전, 관람객 정보에 대응되는 관람객 특징을 분석하고, 상기 분석에 따라 상기 스피커를 통해 발화의 음성 타입, 발화음량, 및 발화속도 중 하나 이상을 조절하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 프로세서는,상기 관람객 정보에 포함된 관람객의 표정 또는 행동 변화를 분석하고,상기 분석에 따른 관람 집중 정도에 기초하여 상기 대상 전시물에 대한 발화 컨텐츠의 변경 여부 또는 발화 시간의 조절 여부를 결정하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,정해진 공간 내에서, 로봇이 안내할 관람 경로 및 설명할 대상 전시물에 관한 정보가 저장되는 메모리를 포함하고,상기 프로세서는,상기 관람객 정보에 포함된 혼잡 정도에 근거하여 상기 저장된 관람 경로의 수정 여부를 결정하고, 상기 설명할대상 전시물의 주변 혼잡도에 근거하여 다음 대상 전시물의 변경 여부를 결정하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는,상기 관람객 정보에 포함된 관람객의 특징에 기초하여 상기 저장된 관람 경로 또는 규정 제한 안내 방식의 변경여부를 결정하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,대상 전시물에 대한 발화 동안 상기 관람객 정보에 포함된 남은 관람객 수에 기초하여 다음 대상 전시물로의 안내 여부를 결정하는,안내 로봇."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 프로세서는,상기 센서를 통해 상기 관람객 정보에 포함된 남은 관람객 수가 없는 것으로 결정되면, 로봇이 안내할 관람 경로를 모두 마친 것으로 인지하고, 다음 대상 전시물로 안내 없이 관람 안내를 종료하는,안내 로봇.공개특허 10-2025-0024805-5-청구항 16 안내 로봇의 동작방법으로서,주변의 관람객 정보를 획득하는 단계;상기 관람객 정보에 근거하여 대상 전시물과 관련된 도착 위치를 결정하고, 결정된 도착 위치로 로봇을 이동시키기 단계;이동 후, 상기 관람객 정보에 포함된 관람객의 얼굴 방향에 대응하도록 로봇의 자세 또는 시선방향을 조절하는단계; 및상기 대상 전시물에 대한 발화 동안 업데이트되는 관람객 정보에 기초하여 다음 동작을 결정하는 단계를 포함하는,안내 로봇의 동작방법."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 결정된 도착 위치로 로봇을 이동시키기 단계는,상기 관람객 정보에 포함된 혼잡도에 따라, 대상 전시물과 관련된 도착 위치의 수정 여부를 결정하는 단계;관람객과 일정 거리를 유지하면서 다음 도착 위치로 로봇을 이동시키는 단계; 및대상 전시물 주변의 혼잡도에 기초하여 도착 위치 또는 로봇 자세를 수정하는 단계를 포함하는,안내 로봇의 동작방법."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서,상기 관람객의 얼굴 방향에 대응하도록 로봇의 자세 또는 시선방향을 조절하는 단계는,상기 도착 위치에서, 센서를 통해 관람객의 얼굴을 모니터링하는 단계;모니터링 결과에 기초하여, 상기 도착 위치를 수정하거나 또는 현재 위치에서 정해진 모션을 수행하는 단계;모니터링 결과에 기초하여, 대상 전시물에 대한 발화의 음성 타입, 발화음량, 발화속도를 조절하는 단계; 및로봇이 관람객이 많은 위치 또는 영역을 오래 주시하도록 로봇의 헤드 또는 눈동자 시선방향을 좌우로 이동하면서 발화를 개시하는 단계를 포함하는,안내 로봇의 동작방법."}
{"patent_id": "10-2025-7000581", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서,상기 업데이트되는 관람객 정보에 기초하여 다음 동작을 결정하는 단계는,업데이트되는 관람객 정보에 포함된 관람객의 표정 또는 행동 변화를 분석하고, 상기 분석에 따른 관람 집중 정도에 기초하여 발화 컨텐츠 또는 발화시간의 수정 여부를 결정하는 단계;업데이트되는 관람객 정보에 포함된 혼잡도에 기초하여, 안내 관람 경로 또는 다음 대상 전시물의 변경 여부를결정하는 단계; 및업데이트되는 관람객 정보에 포함된 관람객 수에 근거하여, 관람 안내 종료 여부를 결정하는 단계를 포함하는,안내 로봇의 동작방법.공개특허 10-2025-0024805-6-"}
{"patent_id": "10-2025-7000581", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "안내 로봇 및 그것의 동작방법이 개시된다. 본 개시에 따른 안내 로봇은, 도슨트 기능을 수행하기 위해 미리 저 장된 지정 위치를 인지하고 있더라도, 주변의 관람객 정보에 근거하여 지정 위치에 대한 수정 여부를 결정할 수 있고, 결정된 지정 위치로 이동한 후에도 관람객 정보에 따라 세부 위치, 자세, 각도, 시선을 조절할 수 있다. 또한, 대상 전시물에 대한 발화 동안 업데이트되는 관람객 정보에 기초하여 다음 동작을 결정할 수 있다. 그에 따라, 관람객에게 보다 스마트한 도슨트 서비스를 제공할 수 있다."}
{"patent_id": "10-2025-7000581", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 안내 로봇 및 안내 로봇의 동작방법으로서, 보다 구체적으로는 소정 공간 내 대상 전시물을 설명하고 안내하는 기능을 수행할 수 있는 안내 로봇 및 안내 로봇의 동작방법에 관한 것이다."}
{"patent_id": "10-2025-7000581", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 사용자에게 다양한 안내 서비스를 제공하는 안내 로봇에 대한 관심이 꾸준히 증가하고 있다. 안내 로봇은 사용자의 조작 없이도 자율적으로 주행하면서 예를 들어 음성 대화 기능 또는 터치 스크린을 통한 인터랙션 기 능을 통해 사용자에게 다양한 안내 서비스를 제공한다. 한편, 안내 로봇의 기능 중 하나로, 특정 대상물과 관련된 설명 또는 안내를 제공하는 도슨트(docent) 기능이 있다. 이러한 도슨트(docent) 기능을 수행하기 위해, 안내 로봇은 관람 안내 경로와 안내 로봇의 지정 위치를 미리 저장한다 그리고, 도슨트 기능이 시작되면, 저장된 관란 안내 경로를 따라 지정 위치로 이동하여 특정 대 상물과 관련된 설명 또는 안내를 수행한다. 도슨트 기능을 수행하기 위한 안내 로봇의 지정 위치는, 일반적으로 특정 대상물의 중심 위치 또는 그 중심 위 치 주변의 일정 범위(즉, 마진 범위) 내의 임의 위치로 정해진다. 이때, 안내 로봇의 지정 위치에 이미 관람객이 존재하거나 또는 주변이 혼잡한 경우, 안내 로봇은 지정 위치에 도착하지 못하여 해설이 지체되거나 또는 관람객을 장애물로 인식하여 비켜달라고 요청하는 경우가 종종 발생하 여, 사용자 불편을 초래하였다. 또한, 사람이 도슨트를 수행하는 경우와 같이 모여있는 관람객의 수, 성별, 연령대 등을 고려하여 유연하게 해 설 수준을 변경하지 못함에 따라, 친근감이나 해설 이해도가 떨어지는 문제가 있었다. 또한, 안내 로봇의 경우, 도슨트를 사람이 수행하는 경우와 달리 관람객이 쉽게 집중하지 못하거나 또는 설명을 끝까지 듣지 않고 지나가 버리는 경우가 있다. 그럼에도 불구하고, 안내 로봇이 저장된 대로 관람 안내를 계속 수행함에 따라 관람객의 흥미와 집중이 감소되는 문제가 있었다."}
{"patent_id": "10-2025-7000581", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에, 본 개시의 일부 실시 예에 따르면, 서비스 제공을 위한 안내 로봇의 지정 위치에 이미 관람객이 존재하거 나 주변이 혼잡한 경우에도, 안내 로봇이 지정 위치에 도착하지 못하는 상황이 발생하지 않도록, 지정 위치를 보다 유연하고 적합하게 가변하여 안내 로봇을 이동시킴으로서, 전시물에 대한 해설 기능을 지체없이 이어나갈 수 있는 안내 로봇 및 안내 로봇의 동작방법을 제공하는데 그 목적이 있다. 또한, 본 개시의 일부 실시 예에 따르면, 관람객의 외형적 특징이나, 혼잡 도, 해설에 대한 집중도를 감시하여, 컨텐츠나 관람 경로를 유연하게 수정하여 안내할 수 있는 안내 로봇 및 안내 로봇의 동작방법을 제공하는데 그 목적이 있다. 또한, 본 개시의 일부 실시 예에 따르면, 해설이 수행되는 동안이나 해설을 위해 다음 전시물로 이동하는 동안 에도 관람객의 집중을 최대한 유지할 수 있도록 상황 대처가 가능한 안내 로봇 및 안내 로봇의 동작방법을 제공 하는데 그 목적이 있다. 또한, 본 개시의 일부 실시 예에 따르면, 추가 입력 없이, 전시물에 대한 해설 기능을 수행하는 동안 관람객의 행동변화나 관람객 수 변화에 따른 적절한 동작을 스스로 판단하고 수행할 수 있는 안내 로봇 및 안내 로봇의 동작방법을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2025-7000581", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시에 따른 안내 로봇은, 도슨트 기능을 수행하기 위해 미리 저장된 지정 위치를 인지하고 있더라도, 주변 의 관람객 정보에 근거하여 지정 위치에 대한 수정 여부를 결정할 수 있고, 결정된 지정 위치로 이동한 후에도 관람객 정보에 따라 세부 위치, 자세, 각도, 시선을 조절할 수 있다.또한, 본 개시에 따른 안내 로봇은, 주변의 관람객 특징, 관람객의 행동변화, 관람객의 혼잡도에 따라, 발화 컨 텐츠를 변경하거나, 관람 안내 경로 수정, 안내할 다음 전시물 변경과 같이 관람 안내 관련 동작을 변경할 수 있다. 보다 구체적으로, 본 개시에 따른 안내 로봇은, 로봇의 현재 위치를 기준으로 주변의 관람객 정보를 획득하기 위한 센서와, 상기 관람객 정보에 근거하여 대상 전시물과 관련된 도착 위치를 결정하는 프로세서와, 상기 결정 된 도착 위치로 로봇을 이동시키기 위한 주행부를 포함할 수 있다. 여기에서, 상기 프로세서는, 상기 결정된 도 착 위치에서 상기 관람객 정보에 포함된 관람객의 얼굴 방향에 대응하도록 로봇의 자세 또는 시선방향을 조절하 고, 대상 전시물에 대한 발화 동안 업데이트되는 관람객 정보에 기초하여 다음 동작을 결정할 수 있다. 또한, 실시 예에서, 상기 프로세서는, 상기 결정된 도착 위치에서 상기 대상 전시물에 대한 주변 혼잡도에 근거 하여 로봇의 세부 위치의 조정 필요 여부를 결정하고, 상기 결정에 따라 세부 위치의 이동 또는 확인 후, 상기 자세 또는 시선방향을 조절할 수 있다 또한, 실시 예에서, 상기 프로세서는, 대상 전시물 주변의 혼잡도가 정해진 범위 이상인 것에 응답하여, 상기 주행부를 제어하여 상기 대상 전시물 주변의 관람객과 일정거리 이격된 지점에 위치하도록 로봇의 세부 위치를 조정하고, 상기 로봇이 상기 대상 전시물를 향하도록 각도를 조절할 수 있다. 또한, 실시 예에서, 상기 프로세서는, 안내 로봇이 미리입력된 POI에 대응되는 제1 그룹의 후보 지점들로 이동 할 수 없는 것으로 판단되면, 상기 관람객 정보에 기반하여 결정된 로봇의 도착 위치에 대응하는 제2 그룹의 후 보 지점들 중 하나를 로봇의 세부 위치로 결정하고, 상기 제2 그룹의 후보 지점들 간의 관계는 상기 제1 그룹의 후보 지점들 간의 관계에 대응될 수 있다. 또한, 실시 예에서, 상기 안내 로봇은, 전면 바디에 장착되어, 상기 대상 전시물과 관련된 시각정보를 표시하는 디스플레이를 더 포함하고, 상기 프로세서는, 대상 전시물 주변의 혼잡도가 정해진 범위 이상인 것에 응답하여, 상기 디스플레이가 상기 혼잡도가 평균 이하인 방향을 향하도록 로봇의 전면 바디를 회전시킬 수 있다. 또한, 실시 예에서, 상기 관람객 정보를 획득하기 위한 센서는 카메라와 3D 뎁쓰 카메라, 라이다, 근접 센서 중 하나 이상을 포함할 수 있다. 또한, 실시 예에서, 상기 안내 로봇은, 상부에 위치하여 로봇의 얼굴 표정변화를 표시하는 제1 디스플레이를 포 함하는 헤드부와, 상기 헤드부 및 상기 주행부 사이에 위치하여 상기 대상 전시물에 대한 설명과 관련된 시각정 보를 표시하는 제2디스플레이를 포함하는 바디부로 구분될 수 있고, 상기 프로세서는, 상기 제2디스플레이가 상 기 관람객 정보에 포함된 관람객의 얼굴 방향과 마주하도록 상기 바디부의 중심을 정렬하고, 상기 발화 동안 모 니터링되는 관람객 정보에 포함된 얼굴 밀집 분포에 기초하여, 로봇의 주시방향이 변화하도록 상기 제1 디스플 레이의 표시를 제어할 수 있다. 또한, 실시 예에서, 상기 프로세서는, 상기 제1 디스플레이를 제어하여, 상기 관람객의 얼굴 밀집 분포가 평균 이상인 지점 또는 영역을 더 오래 주시하도록 로봇의 주시방향을 조절할 수 있다. 또한, 실시 예에서, 상기 프로세서는, 상기 결정된 도착 위치로 로봇의 이동시, 로봇과 관람객이 일정거리를 유 지하도록 상기 주행부를 통해 주행속도를 조절할 수 있다. 또한, 실시 예에서, 상기 안내 로봇은, 상기 안내 로봇에 장착되어, 대상 전시물에 대한 발화를 출력하는 스피 커를 더 포함하고, 상기 프로세서는, 상기 대상 전시물에 대한 발화 개시전, 관람객 정보에 대응되는 관람객 특 징을 분석하고, 상기 분석에 따라 상기 스피커를 통해 발화의 음성 타입, 발화음량, 및 발화속도 중 하나 이상 을 조절할 수 있다. 또한, 실시 예에서, 상기 프로세서는, 상기 관람객 정보에 포함된 관람객의 표정 또는 행동 변화를 분석하고, 상기 분석에 따른 관람 집중 정도에 기초하여 상기 대상 전시물에 대한 발화 컨텐츠의 변경 여부 또는 발화 시 간의 조절 여부를 결정할 수 있다 . 또한, 실시 예에서, 상기 안내 로봇은, 정해진 공간 내에서, 로봇이 안내할 관람 경로 및 설명할 대상 전시물에 관한 정보가 저장되는 메모리를 포함할 수 있고, 상기 프로세서는, 상기 관람객 정보에 포함된 혼잡 정도에 근 거하여 상기 저장된 관람 경로의 수정 여부를 결정하고, 상기 설명할 대상 전시물 주변 혼잡 정도에 근거하여 다음 대상 전시물의 변경 여부를 결정할 수 있다. 또한, 실시 예에서, 상기 프로세서는, 상기 관람객 정보에 포함된 관람객의 특징에 기초하여 상기 저장된 관람 경로 또는 규정 제한 안내 방식의 변경 여부를 결정할 수 있다. 또한, 실시 예에서, 상기 프로세서는, 상기 대상 전시물에 대한 발화 동안 상기 관람객 정보에 포함된 남은 관 람객 수에 기초하여 다음 대상 전시물로의 안내 여부를 결정할 수 있다. 또한, 실시 예에서, 상기 프로세서는, 상기 센서를 통해 상기 관람객 정보에 포함된 남은 관람객 수가 없는 것으로 결정되면, 로봇이 안내할 관람 경로를 모두 마친 것으로 인지하고, 다음 대상 전시물로 안내 없이 관람 안 내를 종료할 수 있다 . 또한, 본 개시에 따른 안내 로봇의 동작방법은 다음과 같은 단계를 포함하여 구현될 수 있다. 상기 동작방법은, 주변의 관람객 정보를 획득하는 단계; 상기 관람객 정보에 근거하여 대상 전시물과 관련된 도착 위치를 결정하 고, 결정된 도착 위치로 로봇을 이동시키기 단계; 상기 이동 후, 상기 관람객 정보에 포함된 관람객의 얼굴 방 향에 대응하도록 로봇의 자세 또는 시선방향을 조절하는 단계; 및 상기 대상 전시물에 대한 발화 동안 업데이트 되는 관람객 정보에 기초하여 다음 동작을 결정하는 단계를 포함할 수 있다. 실시 예에 따라, 상기 결정된 도착 위치로 로봇을 이동시키기 단계는, 상기 관람객 정보에 포함된 혼잡도에 따 라, 대상 전시물과 관련된 도착 위치의 수정 여부를 결정하는 단계; 관람객과 일정 거리를 유지하면서 다음 도 착 위치로 로봇을 이동시키는 단계; 및 대상 전시물 주변의 혼잡도에 기초하여 도착 위치 또는 로봇 자세를 수 정하는 단계를 포함할 수 있다. 실시 예에 따라, 상기 관람객의 얼굴 방향에 대응하도록 로봇의 자세 또는 시선방향을 조절하는 단계는, 상기 도착 위치에서, 센서를 통해 관람객의 얼굴을 모니터링하는 단계; 모니터링 결과에 기초하여, 상기 도착 위치를 수정하거나 또는 현재 위치에서 정해진 모션을 수행하는 단계; 모니터링 결과에 기초하여, 대상 전시물에 대한 발화의 음성 타입, 발화음량, 발화속도를 조절하는 단계; 및 로봇이 관람객이 많은 위치 또는 영역을 오래 주시 하도록 로봇의 헤드 또는 눈동자 시선방향을 좌우로 이동하면서 발화를 개시하는 단계를 포함할 수 있다. 실시 예에 따라, 상기 업데이트되는 관람객 정보에 기초하여 다음 동작을 결정하는 단계는, 업데이트되는 관람 객 정보에 포함된 관람객의 표정 또는 행동 변화를 분석하고, 상기 분석에 따른 관람 집중 정도에 기초하여 발 화 컨텐츠 또는 발화시간의 수정 여부를 결정하는 단계; 업데이트되는 관람객 정보에 포함된 혼잡도에 기초하여, 안내 관람 경로 또는 다음 대상 전시물의 변경 여부를 결정하는 단계; 및 업데이트되는 관람객 정보 에 포함된 관람객 수에 근거하여, 관람 안내 종료 여부를 결정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2025-7000581", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일부 실시 예에 따른 안내 로봇 및 그것의 동작방법에 의하면, 주변의 관람객 정보에 포함된 관람객 수, 대상 전시물 주변의 혼잡도에 따라 미리저장된 지정 위치를 수정할 수 있고, 해당 위치로 안내 로봇이 이동 한 후에도 관람객이 바라보는 방향, 혼잡도, 대상 전시물의 위치에 따라 세부 위치를 조정하거나 안내 로봇의 자세, 각도, 시선처리를 적절하게 조절할 수 있다. 그에 따라, 서비스를 제공받는 관람객은 사람이 도슨트를 수 행하는 경우와 유사한 친근감을 느낄 수 있고, 관람에 집중할 수 있다. 또한, 본 발명의 일부 실시 예에 따른 안내 로봇 및 그것의 동작방법에 의하면, 대상 전시물 주변에 모인 관람 객의 특징을 모니터링하여 그에 적절한 음성타입, 음량, 속도로 발화하고, 관람객의 집중도를 모니터링하여 컨 텐츠나 발화 시간을 조절함으로써, 관람객의 관람 집중도와 내용 이해도를 보다 증진시킬 수 있다. 또한, 본 발명의 일부 실시 예에 따른 안내 로봇 및 그것의 동작방법에 의하면, 관람 혼잡도에 따라 저장된 관 람 안내 경로나 설명할 다음 대상 전시물을 유연하게 수정함으로써, 도슨트 효과를 높일 수 있다. 또한, 본 발명의 일부 실시 예에 따른 안내 로봇 및 그것의 동작방법에 의하면, 다음 대상 전시물로 이동시 관 람객의 이동속도에 맞추어 주행함으로써, 다음 해설을 지체없이 이어나갈 수 있어서, 도슨트 서비스를 제공받는 관람객의 집중을 최대한 유지할 수 있다. 또한, 본 발명의 일부 실시 예에 따른 안내 로봇 및 그것의 동작방법에 의하면, 관람 안내가 진행되는 동안에도 관람객이 모두 떠난 경우와 같이 더 이상 도슨트 서비스를 제공할 필요가 없는 것으로 판단되면, 관리자의 추가 입력 없이, 안내 로봇 스스로 서비스를 종료하고, 대기 위치로 이동할 수 있다. 그에 따라, 불필요한 자원 낭비 가 없게 되며, 관람객이 없음에도 도슨트를 계속 진행하는 어색한 상황이 제거된다."}
{"patent_id": "10-2025-7000581", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 한편, 본 명세서에 개시된 \"안내 로봇\"은 공항, 백화점 등의 쇼핑몰, 호텔 등의 숙박시설, 미술관, 도서관 등의 문화 공간 등의 다양한 공공장소에서 사용자에게 웰컴 인사, 길 안내, 상품안내, 상품검색, 주차 안내, 공항 정 보, 도슨트 정보, 도서관 안내 등의 다양한 정보를 제공할 수 있는 로봇을 의미한다. 또한, 본 명세서에 개시된 \"안내 로봇\"은, 길, 특정 장소 등을 사용자에게 안내하기 위하여, 스스로 자율주행을 수행할 수 있다.특히, 본 명세서에 개시된 \"안내 로봇\"은 정해진 공간 내에서 미리설정된 안내 경로에 따라 대상 전시물과 관련 된 설명을 수행하는 기능, 관람객에게 관람 경로 등을 안내하는 기능, 관람객의 질의를 듣고 답변하는 기능 등 (이와 같은 기능을 포함하여, 이하 '도슨트 기능'으로 명명할 수 있음)을 수행할 수 있다. 또한, 일부 실시예에 서, 상기 안내 로봇은 도슨트 기능을 수행하는 로봇을 의미하는 것으로 사용될 수 있다. 또한, 본 명세서에 개시된 \"안내 로봇\"은, 사용자에게 정보나 안내를 다양한 방식(시각적, 청각적, 촉각적)으로 제공하기 위해, 터치 스크린, 음향 출력부, LED, 촉각센서 등과 관련된 다양한 출력수단을 포함할 수 있다. 또한, 본 명세서에 개시된 \"대상 전시물\"은 안내 로봇이 안내, 해설, 설명하려는 대상이 되는 다양한 종류의 전 시된 물품을 포함할 수 있다. 예를 들어, 대상 전시물은, 박물관, 미술관, 갤러리, 기념관, 쇼룸, 플래그쉽스토 어 등 일정 공간에 전시된 미술품, 작품, 전시품, 예술품, 신제품, 브랜드제품 등을 의미할 수 있다. 도 1은 본 발명과 관련된 안내 로봇의 예시를 보여주는 도면이다. 도 1을 참조하면, 본 발명에 따른 안내 로봇은, 헤드, 카메라, 스피커, 음성인식부(미도시), 터치스크린, 및 주행부를 포함하여 이루어질 수 있다. 다만, 경우에 따라서는 여기에 개시된 수단 중 일부를 제거하거나 또는 다른 수단을 더 포함하여, 본 발명에 따른 안내 로봇이 구 현될 수도 있다. 본 발명에 따른 안내 로봇의 외관은 크게, 헤드와 터치스크린를 포함하는 상부모듈과 주행부 를 포함하는 하부모듈을 포함하여 이루어질 수 있다. 상부모듈과 하부모듈은 상호간에 탈착 가능하도록 구 비될 수 있다. 상기 상부모듈은, 서비스 환경에 따라 변경 가능한 사용자 인터페이스(User Interface)를 제공한다. 상기 하부 모듈은 안내 로봇 본체의 이동을 위한 주행기능을 제공한다. 상기 상부모듈은, 다시 몸체를 형성하며, 터치스크린이 구비된 바디부와, 카메라 등이 구비된 헤드부 로 구분될 수 있다. 그러나, 경우에 따라서는 바디부에 카메라가 구비되거나 헤드부에 터치스크린이 배치되는 형태로 구현될 수도 있다. 카메라는 헤드부의 케이스 일측 또는 바디부의 케이스 일측에 구비될 수 있다. 또, 상기 카메라(12 1)는 복수 개 구비될 수 있다. 이러한 경우, 하나는 본체의 전면에 구비되어 전방을 향하도록 설치되고, 다른 하나는 측면 또는 후면에 구비되어 측방/후방을 향하도록 설치될 수 있다. 그에 따라, 360 범위의 화각을 형성 할 수 있다. 카메라가 복수 개 구비되는 경우, 제1카메라는 예를 들어 3D 스테레오 카메라를 포함할 수 있다. 상기 3D 스테레오 카메라는 장애물 감지, 사용자 얼굴인식, 입체영상 획득 등의 기능을 수행할 수 있다. 안내 로봇(10 0)은 제1카메라를 이용하여 자신의 이동방향에 존재하는 장애물을 감지하여 회피할 수 있고, 사용자를 인식하여 각종 제어동작을 수행할 수 있다. 또, 제2카메라는 예를 들어 슬램(Simultaneous Localization And Mapping) 카메라를 포함할 수 있다. 상기 슬램카메라는 특징점 매칭을 통하여 카메라의 현 위치를 추적하고 이를 기초로 3차원 지도를 작성하는 기능을 수행한다. 안내 로봇은 제2카메라를 이용하여 자신의 현재 위치를 파악할 수 있다. 또한, 카메라는 화각범위 내의 오브젝트를 인식할 수 있고, 사진 및 동영상 촬영의 기능을 수행할 수 있다. 이와 관련하여, 카메라는 카메라 센서(예를 들어, CCD, CMOS 등), 포토 센서(또는 이미지 센서) 및 레이저 센서 중 적어도 하나를 포함할 수 있다. 카메라와 레이저 센서는 서로 조합되어, 3차원 입체영상에 대한 감지대상의 터치를 감지할 수 있다. 포토 센서는 디스플레이 소자에 적층될 수 있는데, 이러한 포토 센서 는 터치 스크린에 근접한 감지대상의 움직임을 스캐닝하도록 이루어진다. 보다 구체적으로, 포토 센서는 행/열 에 Photo Diode와 TR(Transistor)를 실장하여 Photo Diode에 인가되는 빛의 양에 따라 변화되는 전기적 신호를 이용하여 포토 센서 위에 올려지는 내용물을 스캔한다. 즉, 포토 센서는 빛의 변화량에 따른 감지대상의 좌표 계산을 수행하며, 이를 통하여 감지대상의 위치정보가 획득될 수 있다. 음향 출력부는 사용자에게 제공될 정보를 음성으로 알려주는 기능을 수행하며, 예를 들어 스피커 형태일 수 있다. 구체적으로, 안내 로봇에 구비된 음향 수신부와 음성 인식부(미도시)를 통해 수신된 사용자 의 음성에 대응되는 응답이나 검색 결과를 음향 출력부를 통해 음성으로 출력된다. 이러한 음향 출력부 는 헤드부나 터치스크린이 구비된 바디부의 외주면에 마련될 수 있다. 또한, 음향 출력부 는 터치스크린에 디스플레이된 화면(예, 메뉴화면, 광고화면 등)과 관련된 음성 정보를 출력할 수 있다.음향 수신부는 사용자의 음성 등을 수신하는 기능을 수행하며, 예를 들어 마이크로폰 형태일 수 있다. 음 향 수신부는 외부의 음향 신호를 전기적인 음성 데이터로 처리하며, 외부의 음향 신호를 입력 받는 과정에 서 발생되는 잡음(noise)을 제거하기 위한 다양한 잡음 제거 알고리즘이 구현될 수 있다. 터치스크린은 바디부의 일 방향에 길이방향으로 위치할 수 있고, 시각적인 정보, 예를 들어 안내 정보를 제공하기 위하여 화면을 표시할 수 있다. 또, 상기 터치스크린은 디스플레이모듈, 터치센서, 압력센서를 포함하여 이루어질 수 있다. 상기 터치스크린은 예를 들어 이동가이드수단과 결합하여 바디부의 내부를 개폐하도록 구현될 수 있다. 또, 상기 터치스크린은 예를 들어 고정부재를 사용하여 바디부에 결속되어 고정되도록 구현될 수도 있다. 또, 비록 자세히 도시되지는 않았지만, 안내 로봇이 사용자에게 길을 안내하기 위하여 설정된 경로로 선 이동하는 경우를 고려하여, 상기 터치스크린은 헤드를 기준으로 후방에 구비되거나, 또는 전방 외에 후방에도 추가로 구비될 수 있다. 또는, 설정된 경로로 선 이동하기에 앞서 헤드가 180도 회전하여, 터치 스크린이 후방에 위치한 것처럼 외관을 변형시킬 수도 있다. 이러한 경우 터치스크린에는 현재 제공되는 서비스와 관련된 시각정보(예, 길 안내 정보, 질의 정보)를 표 시하는 기능을 수행한다. 사용자는 안내 로봇을 따라 이동하면서, 안내 로봇의 후방에 설치된 터치스 크린를 볼 수 있다. 또한, 상기 터치스크린은 본체의 전면 및 후면 양측에 각각 구비될 수 있다. 이러한 경우, 본체의 전면에 구비된 제1 터치스크린와 본체의 후면에 구비된 제2 터치스크린에 서로 다른 화면(예, 제1 터치스크린에는 사용 자와 인터랙션하는 화면, 제2 터치스크린에는 광고 화면 등)이 디스플레이될 수 있다. 또한, 헤드부의 전 면에는 안내 로봇의 다양한 표정변화가 출력하기 위한 디스플레이부가 구비될 수 있다. 주행부는 안내 로봇 본체의 이동, 회전을 수행한다. 이를 위해, 주행부는 복수의 휠 및 구동 모 터를 포함하여 이루어질 수 있다. 주행부의 구동은 프로세서에 의해 수신된 제어명령에 따라 제어되며, 구 동 전 후에 LED 등의 출력수단을 통한 알림이 제공될 수 있다. 도 2 본 발명과 관련된 안내 로봇의 예시적 세부구성을 보인 블록도이다. 본 발명에 따른 안내 로봇은 통신부, 입력부, 주행부, 센싱부, 출력부, 메모리 , 프로세서 및 전원부 등을 포함할 수 있다. 도 2에 도시된 구성요소들은 안내 로봇을 구현하는 데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 안내 로봇은 위에서 열거된 구성요소들 보다 많 거나, 또는 적은 구성요소들을 가질 수 있다. 통신부는, 안내 로봇과 외부서버, 예를 들어 인공 지능 서버, 또는 외부단말 사이의 무선 통신을 가 능하게 하는 하나 이상의 모듈을 포함할 수 있다. 또, 상기 통신부는, 안내 로봇을 하나 이상의 네트 워크에 연결하는 하나 이상의 모듈을 포함할 수 있다. 상기 통신부는, 예를 들어 WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced) 등의 무선 인터넷 통신 기술을 사 용하여 인공지능 서버 등과 통신을 수행할 수 있다. 또, 상기 통신부는 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication) 등의 근거리 통신 기술을 사용하여 외부 단말 등과 통신을 수행할 수 있다. 입력부는, 영상 신호 입력을 위한 카메라 또는 영상 입력부, 오디오 신호 입력을 위한 음향 수신부 , 예를 들어 마이크로폰(microphone), 사용자로부터 정보를 입력받기 위한 사용자 입력부(미도시, 예를 들 어, 터치키(touch key), 푸시키(mechanical key) 등)를 포함할 수 있다. 입력부에서 수집한 신호데이터, 음성 데이터, 이미지 데이터는 분석되어 제어명령으로 처리될 수 있다. 주행부는 안내 로봇 본체의 이동, 회전을 수행한다. 이를 위해, 주행부는 복수의 휠 및 구동 모 터를 포함하여 이루어질 수 있다. 주행부의 구동은 프로세서에 의해 수신된 제어명령에 따라 제어되 며, 구동 전 후 LED 등의 광출력부를 통한 알림이 제공될 수 있다.센싱부는 안내 로봇 내 정보, 안내 로봇을 둘러싼 주변 환경 정보 및 사용자 정보 중 적어도 하나를 센싱 하기 위한 하나 이상의 센서를 포함할 수 있다. 예를 들어, 센싱부는 근접센서(141, proximity sensor), 조도 센서(illumination sensor), 터치 센서(touch sensor), 가속도 센서(acceleration sensor), 자기 센서 (magnetic sensor), 중력 센서(G-sensor), 자이로스코프 센서(gyroscope sensor), 모션 센서(motion sensor), RGB 센서, 적외선 센서(IR 센서: infrared sensor), 지문인식 센서(finger scan sensor), 초음파 센서 (ultrasonic sensor), 광 센서(optical sensor, 예를 들어, 카메라(121 참조)), 마이크로폰(microphone), 배터 리 게이지(battery gauge), 환경 센서(예를 들어, 기압계, 습도계, 온도계, 방사능 감지 센서, 열 감지 센서, 가스 감지 센서 등), 화학 센서(예를 들어, 전자 코, 헬스케어 센서, 생체 인식 센서 등) 중 적어도 하나를 포 함할 수 있다. 한편, 본 명세서에 개시된 안내 로봇은, 이러한 센서들 중 적어도 둘 이상의 센서에서 센싱되는 정보들을 조합하여 활용할 수 있다. 또한, 상기 센싱부는 장애물, 바닥 상태 등을 감지하는 주행 관련 센 서를 포함할 수 있다. 근접 센서의 예로는 투과형 광전 센서, 직접 반사형 광전 센서, 미러 반사형 광전 센서, 고주파 발진형 근 접 센서, 정전 용량형 근접 센서, 자기형 근접 센서, 적외선 근접 센서 등이 있다. 또, 근접 센서는 네비 카메라, 초음파 센서, 라이다(lidar), ToF 센서 중 적어도 하나를 포함할 수 있고, 이를 통해 감지대상(예, 사 용자)의 접근 및 위치를 인식할 수 있다. 또한, 상기 센싱부는 관람객 정보 수집 센서를 포함할 수 있다. 관람객 정보 수집 센서는 둘 이 상의 센서를 포함하는 것을 의미할 수 있다. 상기 관람객 정보 수집 센서의 예로, 카메라, 3D 뎁쓰 카메라, 라이다, 근접 센서 중 하나 또는 둘 이상의 센서가 포함될 수 있다. 상기 관람객 정보 수집 센서는 하나 또는 둘 이상의 센서를 이용하여, 관 람객 정보를 수집할 수 있다. 여기서, 수집되는 관람객 정보로, 예를 들어 공간 내 관람객 혼잡도, 관람객의 얼 굴방향, 관람객의 외형적 특징, 대상 전시물 주변의 관람객 밀도, 관람객의 집중 정도, 관람객의 구성, 성별, 나이 등의 정보를 포함할 수 있다. 또한, 관람객 정보 수집 센서는 대상 전시물에 대한 설명을 청취하는 관람객의 변화, 예를 들어 관람객이 많아지거나, 변경되거나, 다른 곳으로 이동하는 것을 감지할 수 있다. 상기 관람객 정보 수집 센서에 의해 수집된 관람객 정보는 프로세서에 제공되거나 메모리에 저 장될 수 있다. 프로세서는 수신된 또는 저장된 관람객 정보에 근거하여 또는 이를 분석하여, 안내 로봇의 도착 위치 를 수정하거나, 이동 속도를 변경하거나, 도착 위치에서의 자세, 각도, 시선을 조절할 수 있고, 대상 관람객의 특징에 대응되는 컨텐츠 내용, 발화의 음성타입, 음량, 속도 등을 선택하여, 도슨트 발화를 수행할 수 있다. 프로세서는 도슨트 기능을 수행하는 동안에도 지속적으로 그리고 실시간으로 획득된 관람객 정보에 근거하 여, 발화 컨텐츠나 발화 시간을 조절할 수 있고, 관람 안내 경로나 다음 대상 전시물을 선택적으로 변경할 수 있다. 프로세서는 관람객 정보에 근거하여 관람 혼잡도 및/또는 관람 집중도를 판단할 수 있고, 판단에 따라 관 람 안내 지속 여부를 결정할 수 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 터치스크린, 음향출력 부, 광 출력부 중 적어도 하나를 포함할 수 있다. 터치스크린은 터치 센서와 상호 레이어 구조 를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이러한 터치 스크린은, 안내 로봇 과 사용자 사이의 입력 인터페이스를 제공하는 사용자 입력부로써 기능함과 동시에, 출력 인터페이스를 제공할 수 있다. 일 예로, 음향출력부를 통해 도슨트 발화 음성이 출력되고, 터치스크린을 통해 안내하는 대상 전시물 과 관련된 시각정보 또는 도슨트 발호 음성에 대응되는 프롬프트가 디스플레이될 수 있다. 광 출력부는 광원의 빛을 이용하여 안내 로봇의 이벤트 발생을 알리기 위한 신호를 출력한다. 예를 들어, 안내 로봇의 주행부에 이동명령이 전달된 경우, 이동을 알리기 위한 신호가 광 출력부를 통해 출력된다. 프로세서는 안내 로봇의 인공 지능 기술와 관련된 동작을 수행하기 위하여 AI 학습부(미도시)를 포함 할 수 있다. AI 학습부는 데이터 마이닝(data mining), 데이터 분석, 지능형 의사결정 및 머신 러닝 알고 리즘 및 기술을 위해 이용될 정보를 수신, 분류, 저장 및 출력하도록 구성될 수 있다. AI 학습부는 안내로봇을 통해 수신, 검출, 감지, 생성, 사전 정의된 정보 또는 상기 안내 로봇을 통해 다른 방식으로 출력된 정 보를 저장하거나, 다른 구성, 장치 및 단말기에 의하여 수신, 검출, 감지, 생성, 사전 정의 또는 출력된 데이터 를 저장하도록 구성된 하나 이상의 메모리 유닛을 포함할 수 있다. 일 실시 예에서, AI 학습부는 안내 로봇에 통합되거나, 메모리를 포함할 수 있다. 일 실시 예에서, AI 학 습부는 메모리를 통해 구현될 수 있다. 다만 이에 한정되지 않고, AI 학습부는 안내 로봇 과 관련된 외부 메모리에 구현되거나, 안내 로봇과 통신 가능한 서버에 포함된 메모리를 통해 구현될 수 있다. 다른 일 실시 예에서, AI 학습부는 클라우드 컴퓨팅 환경에서 유지되는 메모리, 또는 네트워크와 같 은 통신 방식을 통해 안내 로봇에 의해 액세스 가능한 다른 원격 메모리를 통해 구현될 수 있다. AI 학습부는 일반적으로 감독 또는 감독되지 않은 학습, 데이터 마이닝, 예측 분석 또는 다른 머신 러닝 기술에서 사용하기 위한 데이터를 식별, 색인화, 분류, 조작, 저장, 검색 및 출력하기 위해, 상기 데이터를 하 나 이상의 데이터베이스에 저장하도록 이루어진다. AI 학습부에 저장된 정보는 서로 다른 유형의 데이터 분석, 기계 학습 알고리즘 및 기계 학습 기술 중 적어도 하나를 사용하는 프로세서 또는 안내 로봇에 포함 된 복수의 프로세서들(프로세서들)에 의하여 이용될 수 있다. 이러한 알고리즘 및 기법의 예로는 K 최근접 이웃 시스템(k-Nearest neighbor system), 퍼지 논리(fuzzy logic)(예를 들어, 가능성 이론(possibility theory)), 신경 회로망(neural networks), 볼츠만 머신(Boltzmann machines), 벡터 양자화, 펄스 신경망(pulsed neural nets), 서포트 벡터 머신(support vector machines), 최대-마진 분류기(maximum margin classifiers), 힐 클라 이밍(hill-climbing), 유도 논리 시스템(inductive logic systems), 베이지안 네트워크(baysian networks), 페 트리 네트(petri nets) (예를 들어, 유한 상태 기계(finite state machines), 밀리 머신(mealy machines), 무 어 유한 상태 머신(moore finite state machines)), 분류 트리(classifier trees)(예를 들어, 퍼셉트론 트리 (perceptron trees), 서포트 벡터 트리(support vector trees), 마코브 트리(markov trees), 트리-숲 결정 (decision tree forests), 랜덤 숲(random forests)), 목마전 모형 및 시스템(pandemonium models and systems), 클러스터링(clustering), 인공 지능 플래닝(artificially intelligent planning), 인공 지능 예측 (artificially intelligent forecasting), 데이터 퓨전(data fusion), 센서 퓨전(sensor fusion), 이미지 퓨전 (image fusion), 강화 학습(reinforcement learning), 증강 현실(augmented reality), 패턴 인식(pattern recognition), 자동 플래닝(automated planning) 등이 있다. 프로세서는 데이터 분석, 머신 러닝 알고리즘 및 머신 러닝 기술을 사용하여 결정 또는 생성된 정보에 기 초하여, 안내 로봇의 실행 가능한 동작을 결정 또는 예측할 수 있다. 이를 위하여, 프로세서는 AI 학습부 의 데이터를 요청, 검색, 수신 또는 활용할 수 있다. 프로세서는 지식 기반 시스템, 추론 시스템 및 지식 획득 시스템 등을 구현하는 다양한 기능을 수행할 수 있으며, 불확실한 추론을 위한 시스템(예를 들어, 퍼 지 논리 시스템), 적응 시스템, 기계 학습 시스템, 인공 신경망 등을 포함하는 다양한 기능을 수행할 수 있다. 또한, 프로세서는 I/O 처리 모듈, 환경 조건 모듈, 음성-텍스트(STT) 처리 모듈, 자연 언어 처리 모듈, 작 업 흐름 처리 모듈 및 서비스 처리 모듈 등과 같은 음성 및 자연 언어 처리를 가능하게 하는 서브 모듈들을 포 함할 수 있다. 서브 모듈들 각각은 안내 로봇에서 하나 이상의 시스템 또는 데이터 및 모델, 또는 이들의 서브 셋 또는 수퍼셋에 대한 접근권한을 가질 수 있다. 여기서, 서브 모듈들 각각이 접근권한을 가지는 대상은 스케 줄링, 어휘 인덱스, 사용자 데이터, 태스크 플로우 모델, 서비스 모델 및 자동 음성 인식(ASR) 시스템을 포함할 수 있다. 일부 실시 예에서, 프로세서는 AI 학습부에서의 데이터에 기초하여 사용자 입력 또는 자연 언어 입력 으로 표현된 문맥 조건 또는 사용자의 의도에 기초하여 사용자가 요구하는 것을 검출하고 감지하도록 구성될 수 도 있다. AI 학습부에 의해 수행된 데이터 분석, 머신 러닝 알고리즘 및 머신 러닝기술을 바탕으로, 안내 로봇의 동작이 결정되면, 프로세서는 이러한 결정된 동작을 실행하기 위하여, 안내 로봇의 구성 요소들을 제어할 수 있다. 프로세서는 제어 명령에 근거하여, 안내 로봇을 제어함으로써, 결정된 동작을 실행할 수 있다. 메모리는 안내 로봇의 다양한 기능을 지원하는 데이터를 저장한다. 메모리는 안내 로봇에 서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application))과, 안내 로봇 의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 또한, 메모리는 사용자와 음성 대화 기능을 수행하 기 위한 가변가능한 호출어를 저장할 수 있다. 메모리는 안내 로봇의 도슨트 기능과 관련된 정보, 데이터, 및 프로그램을 저장할 수 있다. 도슨트 기능과 관련된 정보 또는 데이터는, 예를 들어 관람 안내 경로, 대상 전시물, 각 대상 전시물에 대한 지정 위치에 관한 정보 똔든 데이터를 포함할 수 있다. 메모리는, 예를 들어 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타 입(Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스 크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 프로세서는 상기 응용 프로그램과 관련된 동작 외에, 통상적으로 안내 로봇의 전반적인 동작을 제어 한다. 프로세서는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하 거나 메모리에 저장된 응용 프로그램을 구동하거나, 주행부를 제어함으로써, 사용자에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 전원부는 프로세서의 제어 하에서, 외부의 전원, 내부의 전원을 인가 받아 안내 로봇에 포함된 각 구성요소들에 전원을 공급한다. 이러한 전원부는 배터리를 포함할 수 있고, 상기 배터리는 내장형 배터 리 또는 교체가능한 형태의 배터리가 될 수 있다. 상기 각 구성요소들 중 적어도 일부는, 이하에서 설명되는 다양한 실시 예들에 따른 안내 로봇의 동작, 제어, 또는 제어방법을 구현하기 위하여 서로 협력하여 동작할 수 있다. 또한, 상기 안내 로봇의 동작, 제어, 또는 제 어방법은 상기 메모리에 저장된 적어도 하나의 응용 프로그램의 구동에 의하여 안내 로봇상에서 구현될 수 있다. 또한, 이하에 개시된 다양한 실시 예는 예를 들어, 소프트웨어, 하드웨어 또는 이들의 조합된 것을 이용하여 컴 퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록매체 내에서 구현될 수 있다. 도 3은 본 발명과 관련된 안내 로봇이, 관람객 정보에 기초하여 대상 전시물에 대한 안내 또는 설명을 위 해 발화하는 모습을 보여주는 예시 도면이다. 안내 로봇은, 도슨트 기능이 개시되면, 관람객 정보에 기초하여 도착 위치를 결정하고, 결정된 도착 위치 로 이동하고, 이후 세부 위치의 수정 및 이동을 반복할 수 있다. 구체적으로, 안내 로봇은 센서, 예를 들어 카메라, 근접 센서 등을 포함한 관람객 정보 수집 센서를 통해, 주변의 관람객 정보를 획득할 수 있다. 예를 들어, 관람객 정보 수집 센서의 카메라를 통해, 주변의 관람객의 얼굴 인식, 얼굴방향, 얼굴 표정(기 분), 성별, 연령대, 특정 모션/제스처를 감지할 수 있다. 또, 예를 들어 관람객 정보 수집 센서의 라이다, 근접 센서, 또는 3D 카메라, 일반 카메라 중 하나를 통해 주변의 관람객 수, 관람객과 안내 로봇 간의 거 리정보를 획득할 수 있다. 이때, 상기 관람객 정보는, 이미지 분석 등을 통한 관람객 수, 관람 혼잡도, (대상 전시물에 대한) 관람객 분포 도, 관람객의 외형적 특징(예, 성별, 연령대, 마스크 착용여부, 유모차 소지여부, 아이 동반 여부, 보조기구(휠 체어, 목발 등) 사용여부), 얼굴 인식 알고리즘을 이용한 행동 및 표정변화, 시선방향 등을 포함할 수 있다. 또 한, 상기 관람객 정보는, 안내 로봇의 위치로부터 이격된 정도, 즉 거리정보와 안내 로봇이 주시방향 에 대응되는 얼굴방향, 즉 각도정보를 포함할 수 있다. 안내 로봇의 프로세서(180, 도 2)는 이와 같이 다양한 관람객 정보에 근거하여, 저장된 지정 위치를 고려 한 안내 로봇의 도착 위치를 결정할 수 있다. 예를 들어, 저장된 지정 위치 주변이 혼잡하지 않고 관람객이 존재하지 않는 경우, 안내 로봇은 저장된 지 정 위치를 도착 위치로 결정할 수 있다. 반면, 예를 들어 저장된 지정 위치 주변이 혼잡하거나 지정 위치에 관 람객 또는 장애물이 존재하는 경우, 관람 혼잡도가 낮으면서 대상 전시물을 향하는 다른 위치나 영역을 도착 위 치로 결정할 수 있다. 또, 예를 들어, 공간에 대한 관람 혼잡도에 따라 도착 위치가 수정될 수 있다. 상기 관람 혼잡도는, 전술한 관람객 정보의 분석에 따라 결정될 수도 있다. 구체적으로, 상기 관람 혼잡도는, 관람객 정보 수집 센서(143, 도 2)를 통해 획득된 이미지에 포함된 관람객 수를 분석하거나, 또는 통신부를 통해 수신된 현재 관람객 입장 수에 기초하여 판단될 수 있다.안내 로봇이 주행부(130, 도 2)를 사용하여 상기 결정된 도착 위치(P)로 이동하면, 프로세서는 결정 된 도착 위치에서, 대상 전시물 주변에 존재하는 관람객의 관람객 정보에 근거하여, 안내 로봇 의 세부 위치 수정 여부를 결정하고, 관람객의 얼굴 방향에 대응하도록 로봇의 자세 또는 시선방향을 조절 할 수 있다. 이를 위해, 안내 로봇은 도착 위치(P) 또는 수정된 세부 위치에서, 카메라의 화각범위에 있는 관람객 의 얼굴 방향을 모니터링한다. 모니터링 결과, 관람객과 일정 거리를 유지하면서, 대상 전시물을 관람할 수 있는 각도로 자세를 수 정하고, 그리고 관람객의 얼굴 방향과 시선이 마주하도록 안내 로봇의 시선방향을 처리한다. 이를 위 해, 안내 로봇의 프로세서를 통해, 터치 스크린이 구비된 바디부를 회전하거나 그리고/또는 안 내 로봇의 표정 또는 시선이 표현되는 헤드부를 회전하도록 제어할 수 있다. 안내 로봇은 모니터링되는 관람객의 설명 이해도를 높이기 위해, 관람객의 외형적 특징을 분석 하고, 분석에 따라 발화의 음성타입(어린이 음성타입, 어른 음성타입 등), 발화음량(발화크기), 발화속도를 가 변할 수 있다. 또한, 안내 로봇은 대상 전시물에 대한 발화 동안, 지속적으로 업데이트되는 관람객 정보에 기초하여 다음 동작을 결정할 수 있다. 예를 들어, 안내 로봇은 업데이트되는 관람객 정보에 기초하여, 설명 위치를 추가 변경하거나(예, 관람객 이 더 모여든 경우) 또는 주시방향(예, 관람객 밀도 변화 감지된 경우)을 변경할 수 있을 뿐만 아니라, 발화 컨 텐츠를 변경하거나 발화 시간을 조절할 수도 있다. 또, 예를 들어, 안내 로봇은 업데이트되는 관람객 정보에 기초하여,다음 안내할 대상물을 변경하거나 관람 안내 경로(또는, 관람 안내 순서)를 수정하거나, 관람객에 대한 이동 또는 제한에 대한 안내를 선택하거나, 관 람 안내 종료 여부를 결정할 수 있다. 도 4는 본 발명과 관련된 안내 로봇의 동작방법의 대표 흐름도이다. 먼저, 도 4에 도시된 흐름도의 각 과정은 다른 설명이 없다면, 안내 로봇의 프로세서에 의해 수행됨 을 전제로 한다. 또한, 도슨트 서비스의 진행 특성에 따라, 도 4에 도시된 단계들(410 내지 440)은 도슨트 서비 스가 종료될 때까지 수차례, 예를 들어 대상 전시물의 수만큼 반복적으로 수행될 수 있다. 도 4를 참조하면, 도슨트 기능이 개시되면, 본 개시에 따른 안내 로봇은 현재 위치를 기준으로, 메모리 등 에 미리저장된 관람 경로, 대상 전시물, 및 로봇의 이동 위치를 인지한다. 그리고, 안내 로봇은, 센서(예, 관람객 정보 수집 센서)를 통해 획득된 관람객 정보에 근거하여 대상 전시물과 관련된 도착 위치를 결정하고, 주행부를 통해 결정된 도착 위치로 안내 로봇을 이동시킬 수 있다 . 구체적으로, 안내 로봇은 현재 위치를 기준으로 저장된 대상 전시물 및 그에 대한 지정 위치를 인지한 상 태에서, 관람객 정보에 근거하여 지정 위치의 수정 여부를 결정하고, 그 결정에 따라 대상 전시물과 관련된 도 착 위치를 결정한다. 도착 위치가 결정되면, 안내 로봇은 주행부를 제어하여, 관람객과 일정거리를 유지하도록 주행속도를 조절하면서 결정된 도착 위치로 이동한다. 예를 들어, 안내 로봇은 관람객의 이동속도를 모니터링하면서, 전체 평균 이동속도에 근접하도록 (즉, 전체 평균 이동속보다 너무 느리지도 너무 빠르지 않게) 주행속도를 조 절하면서 도착 위치로 이동한다. 이와 같이 안내 로봇의 주행속도를 관람객의 이동속도에 맞추어 조절함으 로써, 도슨트 효과를 높일 수 있다. 또한, 실시 예에 따라, 상기 결정된 도착 위치는, 안내 로봇이 관람객과 일정 거리를 두고 이동하는 동안 에도 실시간 수집되는 관람객 정보에 근거하여 수정될 수 있다. 예를 들어, 도착 위치에 관람객이 먼저 도착한 경우, 이동 중에 관람객이 이탈하거나 많아진경우, 도착 위치가 다시 수정될 수 있다. 안내 로봇이 상기 도착 위치(또는, 이동하면서 수정된 위치)에 도착하면, 프로세서는 상기 도착 위치 에서 관람객 정보에 포함된 관람객의 얼굴방향에 대응하도록 안내 로봇의 자세 또는 시선방향을 조절한다 .이를 위해, 프로세서는 상기 결정된 도착 위치로 이동한 후, 대상 전시물 주변에 모인 관람객의 얼굴을 인 식하고 인식된 얼굴 및 얼굴방향을 모니터링할 수 있다. 안내 로봇은 얼굴 및 얼굴방향의 모니터링 결과, 대상 전시물에 대한 발화를 시작하기 전, 관람객에 적합 한 발화 음성타입, 발화음량, 발화속도를 선택하여, 발화 개시를 준비할 수 있다. 구체적으로, 안내 로봇은 얼굴 및 얼굴방향의 모니터링 결과에 기초하여, 관람객의 구성(예, 가족 여부, 어린이 대상 여부 등), 성별, 연령대를 관람객 정보로 획득할 수 있다. 또한, 안내 로봇의 프로세서는 대상 전시물에 대한 발화를 개시하기 전, 관람객 정보에 대응되는 관 람객 특징을 분석하고, 그 분석에 따라 안내 로봇의 스피커를 통해 출력되는 발화의 음성타입, 발화음량, 및 발화속도 중 하나 이상을 조절할 수 있다. 구체적으로, 안내 로봇은 획득된 관람객의 구성, 성별, 연령대에 맞는 음성타입을 선택하도록 연동된 TTS 엔진을 변경/제어할 수 있고, 획득된 관람객의 구성, 성별, 연령대에 맞는 발화음량 및 발화속도로 음성을 출력 하도록 안내 로봇의 음향출력부를 제어할 수 있다. 예를 들어, 관람객의 구성이 주로 어린이인 경우라면, 어린이 음성의 TTS 로 도스튼 발화를 수행할 수 있다. 또, 예를 들어, 관람객의 연령대가 높은 경우라면, 발화속도를 낮추고 발화음량을 높여서 도슨트 발화를 수행할 수 있을 것이다. 그에 따라, 커스터마이징 도슨트가 가능해짐에 따라, 도슨트 효과를 높이고 관람객의 관람 집 중도를 향상시킬 수 있다. 다음, 안내 로봇은 대상 전시물에 대한 발화 동안, 지속적으로 업데이트되는 관람객 정보에 기초하여, 수 행할 다음 동작을 적응적으로 결정할 수 있다. 실시 예에 따라, 상기 대상 전시물에 대한 발화 동안은, 안내 로봇이 대상 전시물에 대한 설명을 시작하기 전, 즉 설명을 준비하는 단계를 포함할 수 있다. 또한, 실시 예에 따라, 상기 대상 전시물에 대한 발화 동안은, 안내 로봇이 현재 대상 전시물에 대한 설명을 마친 후 다음 대상 전시물로 이동하기 전 일정시간 동안을 포함할 수 있다. 따라서, 상기 다음 동작은, 특정 대상 전시물에 대한 발화 준비 동안, 발화 동안, 발화 후 일정시간 동안, 수집 되는 관람객 정보에 근거하여 상황에 적합하다고 판단되는 특정 동작 또는 로봇의 현재 동작의 변경동작을 포함 할 수 있다. 구체적으로, 실시 예로, 안내 로봇의 프로세서는, 업데이트된 관람객 정보에 포함된 관람객의 표정 및 행동을 분석하고, 분석에 따른 관람객의 관람 집중도를 판단하여 발화 컨텐츠 또는 발화시간의 수정 여부를 결정할 수 있다. 예를 들어, 관람객이 표정이 지루함을 느끼는 것으로 판단되면, 흥미를 유발하는 컨텐츠로 변 경하여 도슨트 발화를 지속할 수 있다. 또한, 실시 예로서, 안내 로봇의 프로세서는, 업데이트된 관람객 정보에 포함된 관람객의 외형적 특 징을 분석하여, 발화할 컨텐츠 정보를 변경할 수 있다. 예를 들어 관람객의 외형적 특징을 분석한 결과, 관람객 이 이동하기 편안한 경로로 관람 안내 경로를 가변하여 안내하거나, 또는 제한 규정 위반(예, 동물 출입 금지, 노키즈 존)에 따른 규정 안내를 설명할 수 있다 또한, 실시 예로서, 안내 로봇의 프로세서는, 업데이트된 관람객 정보에 포함된 혼잡도에 따라 관람 안내 경로 또는 다음 대상 전시물의 변경 여부를 결정할 수 있다. 예를 들어, 엘리베이터가 혼잡한 경우, 다른 수단(예, 계단)을 통해 다음 대상 전시물로 이동하도록 안내할 수 있다. 또는, 예를 들어, 다음 순서의 대상 전 시물 주변이 매우 혼잡한 경우, 이에 대한 해설을 건너뛰거나 나중순서로 변경하여 관람 이동 경로를 안내할 수 있다. 또한, 실시 예로서, 안내 로봇의 프로세서는, 업데이트된 관람객 정보에 관람객 수에 근거하여 관람 안내 종료 여부를 결정할 수 있다. 예를 들어, 관람객이 한명도 남지 않은 경우, 안내 로봇은 현재 위치에 서 관람 안내를 종료한 후, 지정된 대기 위치(또는, 초기 위치)로 이동할 수 있다. 그에 따라, 불필요한 자원 낭비가 없고, 도슨트 서비스를 이용하는 관람객이 없음에도 도슨트 서비스를 계속 진행하는 어색한 상황이 제거 된다. 도 5a, 도 5b, 도 5c는 본 발명과 관련된 안내 로봇이, 안내할 대상 전시물 주변의 혼잡도에 근거하여 도착 위 치를 세부 수정하는 것을 설명하기 위한 개념도들이다.구체적으로, 도 5a는 도슨트 기능을 수행할 수 있는 안내 로봇에 미리입력된 지정 위치를 나타낸 것으로, 특정 POI 지점 및 그 주변 일정범위내 영역을 나타낸 것이다. 그리고, 도 5b 및 도 5c는 본 개시에 따른 안내 로봇이 관람객 정보, 특히 관람 혼잡도에 따라 수정된 도착 위치, 각도, 자세를 나타낸 것이다. 안내 로봇의 프로세서는 안내 로봇에 미리입력된 POI에 대응되는 제1 그룹의 후보 지점들로 이동할 수 있는지를 판단하고, 이동할 수 없는 경우(예, 관람객 존재, 관람객 혼잡도 높음)라면, 관람객 정보에 기반하 여 결정된 로봇의 도착 위치에 대응하는 제2 그룹의 후보 지점들 중 하나를 로봇의 세부 위치로 결정할 수 있다. 이때, 제2 그룹의 후보 지점들 간의 관계는 상기 제1 그룹의 후보 지점들 간의 관계에 대응된다고 말할 수 있다. 예를 들어, 제2 그룹의 후보 지점들은 도 5b와 도 5c에 도시된 결정된 후보 도착 위치(502, 503, 504)이며, 제1 그룹의 후보 지점들은 도 5a에 도시된 미리입력된(미리저장된) 지정 위치이다. 이때, 결정된 후보 도착 위 치(502, 503, 504) 내의 다수의 후보 지점들의 개수, 간격 등은 지정 위치에 대응되는 다수의 후보 지점들 의 개수, 간격 등과 일치할 수 있다. 관람 혼잡도가 낮은 경우, 즉 대상 전시물 주변에 관람객이 많지 않은 경우, 안내 로봇은, 도 5a에 도시된 바와 같이, 대상 전시물에 대해 미리입력된 POI 지점 또는 그 POI 지점 주변 영역, 즉 미리저장된 지정 위 치를 도착 위치로 결정한다. 지정 위치에서 관람 혼잡도가 일정값 이상이면, 안내 로봇(100은 관람객 정보에 포함된 관람객의 위치, 혼잡도, 혼잡 형태에 따라, 관람 혼잡도가 낮은 위치 또는 영역으로 도착 위치를 결정한다. 예를 들어, 도 5b와 같이, 관람객의 혼잡도가 일정 값 이상이고, 우측 및 중앙이 더 혼잡한 형태인 경우, 안내 로봇은 대상 전 시물의 좌측 영역 중 대상 전시물을 감상할 수 있는 후보 위치를 도착 위치로 결정할 수 있다. 이때, 후보 위치는 도시된 바와 같이, 관람객과 일정거리(마진거리)를 유지하는 위치(들)로 결정될 수 있다. 또한, 안내 로봇은 대상 전시물을 바라보는 방향으로 자세 또는 각도를 정렬할 수 있다. 이때, 대상 전시물 주변의 관람객 혼잡 형태에 따라, 안내 로봇의 자세 또는 각도가 수정될 수 있다. 예를 들어, 도 5c에 도시된 바와 같이, 관람객의 혼잡 형태에 따라, 안내 로봇의 도착 위치가 대상 전시물을 기준으로, (a)좌측 후보 위치로 결정되면 안내 로봇의 바디부 또는 터치 스크린이 우측방향 을 향하도록 자세 또는 각도(R1)를 조절하고, (b) 우측 후보 위치로 결정되면 안내 로봇의 바디부 또는 터 치 스크린이 좌측방향을 향하도록 자세 또는 각도(R2)를 조절한다. 한편, 비록 도시되지는 않았지만, 관람객의 혼잡 형태에 따라, 안내 로봇의 바디부 또는 터치 스크린 이 혼잡하지 않는 위치나 영역을 향하도록 주행부를 회전함으로써, 세부 위치나 자세/각도를 수정할 수 있다. 이는, 관람객이 혼잡하지 않는 위치나 영역으로 이동하도록 유도함으로써, 보다 질서 있는 도슨트가 수행 될 수 있게끔 한다. 또한, 안내 로봇의 프로세서는 대상 전시물에 대한 주변 혼잡도에 근거하여 로봇의 세부 위치의 조정이 필요한지를 결정하고, 그 결정에 따라 세부 위치로 이동하거나 또는 확인 후, 안내 로봇의 자세 또 는 시선방향을 조절할 수 있다. 구체적으로, 대상 전시물 주변의 혼잡도가 정해진 범위 이상인 것에 응답하여, 안내 로봇은 주행부 를 제어하여, 대상 전시물 주변의 관람객과 일정거리 이격된 지점에 위치하도록 로봇의 세부 위 치를 조정한 다음, 로봇이 대상 전시물를 향하도록 자세 또는 각도를 조절할 수 있다. 도 6은 본 발명과 관련된 안내 로봇이, 도착 위치로 이동 후 관람객이 더 많은 위치 또는 영역을 보다 오래 주 시하는 것을 설명하기 위한 예시 개념도이다. 도 6을 참조하면, 본 개시에 따른 안내 로봇은, 헤드부와 바디부로 구분될 수 있고, 헤드부 는 로봇의 상부에 위치하여 시선, 얼굴 표정변화를 나타낼 수 있는 제1 디스플레이(151a)를 포함할 수 있 다. 또한, 바디부는 헤드부와 주행부 사이에 위치하여, 대상 전시물에 대한 설명과 관련된 시각정보를 표시하는 제2디스플레이(151b)를 포함할 수 있다. 한편, 실시 예에 따라, 바디부는 전면에 구비된 제2디스플레이와 후면에 구비된 제3디스플레이를 포함하도 록 구현될 수 있다. 이러한 경우, 관람객은 안내 로봇의 전방과 후방 어느에도 위치할 수 있으므로, 관람객이 많거나 관람 혼잡도가 높은 경우에도 도슨트 효과가 향상될 수 있다. 안내 로봇은 결정된 도착 위치로 이동 후, 대상 전시물 주변에 모인 관람객을 모니터링하기 위해, 카메라 를 회전하거나 또는 카메라가 장착된 바디부 또는 헤드부를 좌우방향으로 회전시킬 수 있다. 이어서, 안내 로봇은 관람객의 얼굴을 인식하고 인식된 얼굴의 얼굴방향의 모니터링에 따라, 안내 로봇의 세 부 위치를 조정하거나 자세 또는 각도를 조절하도록, 주행부를 제어할 수 있다. 안내 로봇의 프로세서는, 바디부의 제2디스플레이(151b)가 관람객 정보에 포함된 관람객의 얼굴 방향과 마주하도록, 바디부의 중심을 정렬할 수 있다. 이를 위해, 프로세서는 주행부의 구동휠을 회전시켜서, 바디부의 중심이 관람객을 향하도 록 자세를 수정할 수 있다. 또한, 안내 로봇은 대상 전시물과 관련된 발화를 수행하는 동안, 모니터링되는 관람객 정보에 포함된 얼굴 밀집 분포에 기초하여, 안내 로봇의 주시방향이 변화하도록, 제1 디스플레이(151a)의 표시를 제어할 수 있다. 실시 예에 따라, 안내 로봇의 프로세서는 헤드부의 제1 디스플레이(151a)의 표시를 제어하여, 안내 로봇이 관람객의 얼굴 밀집 분포가 평균 이상인 지점 또는 영역을 더 오래 주시하도록 로봇의 주시방향을 조절할 수 있다. 예를 들어, 안내 로봇은 관람객의 모니터링 후, 관람객의 얼굴 밀집 분포도가 높은 위치 또는 영역을 더 오래 주시하도록, 제1 디스플레이(151a)에 시선방향을 표시할 수 있다. 이와 같이, 관람객이 많이 모 인 곳에 안내 로봇의 시선이 오래 향하도록 처리함으로써, 관람객과 눈을 맞추고 설명하는 것처럼 자연스 럽고 스마트한 도슨트 효과를 제공할 수 있다. 또한, 실시 예에 따라, 안내 로봇은 대상 전시물에 대한 도슨트 발화를 시작한 후에도, 지속적으로 관람객을 모니터링하고, 모니터링 결과 관람객의 얼굴 밀집 분포도의 변화가 감지되면, 감지된 변화에 기 초하여 제1 디스플레이(151a)에 시선방향 및 시선방향의 분배를 재조절할 수 있다. 또한, 실시 예에 따라, 안내 로봇은 관람객의 모니터링 후, 관람객의 표정변화를 분석하여, 관 람 집중도가 높은 관람객에게 더 오래 또는 자주 시선이 향하도록 헤드부를 회전하거나 또는 제1 디스플레 이(151a)에 주시방향을 표시할 수 있다. 이를 위해, 안내 로봇의 메모리에는 관람객의 다양한 표정변 화에 대응되는 집중도와 관련된 값/레벨 데이터가 미리 저장될 수 있다. 도 7a, 도 7b, 도 7c는 본 발명과 관련된 안내 로봇이, 도착 위치에서 관람객의 얼굴방향에 대응하도록 시선방 향을 이동하는 예시를 설명하기 위한 개념도들이다. 안내 로봇의 제1 디스플레이(151a)에 표시되는 시선방향 또는 주시방향은 도 7a 내지 도 7c에 도시된 바와 같이, 안내 로봇이 현재 위치에서 관람객(P1, P2, P3)의 얼굴방향을 바라보는 것처럼, 제1 디스플레이 (151a)에 표시되는 안내 로봇의 눈동자의 움직임 변화를 표시한다. 예를 들어, 도 7a 와 같이, 안내 로봇의 위치를 기준으로 우측에 위치한 제1 관람객(P1)을 주시하기 위해, 우측의 제1 관람객(P1)을 향하는(주시하는) 눈동자 이미지를 제1 디스플레이(151a)에 디스플레이할 수 있다. 또, 예를 들어, 도 7b 와 같이, 안내 로봇의 위치를 기준으로 가운데 =위치한 제2 관람객(P2)을 주시하기 위해, 중앙의 제2 관람객(P2)을 향하는(주시하는) 눈동자 이미지를 제1 디스플레이(151a)에 디스플레이할 수 있 다. 또, 예를 들어, 도 7c 와 같이, 안내 로봇의 위치를 기준으로 좌측에 위치한 제3 관람객(P3)을 주시하기 위해, 좌측의 제3 관람객(P3)을 향하는(주시하는) 눈동자 이미지를 제1 디스플레이(151a)에 디스플레이할 수 있 다. 한편, 주시방향에 위치한 관람객이 이동하거나 또는 얼굴 방향이 변경된 것이 감지되면, 안내 로봇은 시선 을 다시 좌우로 이동하면서 관람객의 얼굴 및 얼굴방향을 모니터링하고, 도슨트 발화를 수행하는 동안 전술한 과정을 반복한다. 또는, 안내 로봇의 시선이 이동하는 관람객을 향하도록 일정시간 동안 관람객의 얼굴 트 래킹을 수행할 수 있다.이에 의하여, 로봇이 주시하던 관람객이 도슨트를 더 이상 듣지 않거나 이동하더라도, 안내 로봇이 빈 곳을 주 시하지 않고 자연스러운 시선처리를 수행할 수 있다. 이하에서는, 도 8, 도 9, 도 10을 참조하여, 전술한 도 4의 흐름도에 포함된 각 단계에 대한 세부 동작을 구체 적으로 설명하겠다. 도 8, 도 9, 도 10에 도시된 각각의 세부 동작은 일련의 세부 동작으로 수행될 수도 있고, 각 세부 동작이 별개로 실시 예로서 독립적으로 수행될 수도 있고, 일부 세부 동작이 생략되거나 또는 다른 세 부 동작을 포함하여 수행될 수도 있다. 특히, 도 10에 도시된 도면의 세부 동작은 특정 순서를 따르도록 도시한 것이 아니며, 도시된 순서와 다른 순서로 세부 동작이 수행될 수 있다. 도 8은 본 발명과 관련된 안내 로봇이, 대상 전시물과 관련된 도착 위치를 결정하고, 결정된 위치로 이동하는 것과 관련된 세부 동작을 포함하는 도면이다. 다시 말해, 도 4의 흐름도의 단계와 관련된 세부 동작을 도 시한 것이다. 실시 예에서, 안내 로봇은 관람객 정보에 포함된 관람 혼잡도에 따라, 안내할 대상 전시물과 관련된 로봇 의 도착 위치에 대한 수정 여부를 결정할 수 있다. 안내 로봇은, 관람객 정보에 근거하여 도착 위치의 세부 위치를 수정하거나, 그리고/또는 대상 전시물 주 변의 관람 혼합도에 기초하여 도착 위치의 세부 위치를 수정하도록 동작할 수 있다. 여기서, 상기 관람객 정보에 근거하여 도착 위치의 세부 위치를 수정하는 것은, 로봇의 도착 위치가 관람객과 일정거리르 유지하도록 세부 위치를 수정하는 것과, 도착 위치에서 모니터링되는 관람객의 얼굴방향에 기초하여 안내 로봇의 자세 또는 각도를 수정하는 것을 포함할 수 있다. 또한, 상기 대상 전시물 주변의 관람 혼합도에 기초하여 도착 위치의 세부 위치를 수정하는 것은, 도착 위치에 서 모니터링되는 관람 혼잡도 및 혼잡도 형태에 따라 현재 안내 로봇의 세부 위치와 각도(자세))를 수정하는 것 을 포함할 수 있다. 또한, 안내 로봇의 프로세서는, 업데이트된 관람객 정보에 포함된 관람 혼잡도에 따라 관람 안내 경 로 또는 다음 대상 전시물의 변경 여부를 결정할 수 있다. 예를 들어, 안내 로봇은 관람객의 입장 수에 따른 공간 혼잡도, 층간 이동을 위한 엘리베이터와 통신하여 수집되는 이동수단 혼잡도, 안내 로봇의 진행방향을 기준으로 한 관람객 혼잡도 등에 따라, 원할하고 스마트한 도슨트가 수행될 수 있도록, 관람 순서, 경로, 설명할 대상 전시물을 적응적으로 변경할 수 있다. 실시 예에서, 안내 로봇은 도착 위치가 결정되면, 관람객과 일정 거리를 유지하도록 주행하면서 결정된 도 착 위치로 이동한다. 이는, 안내 로봇이 관람객 보다 너무 느리게 이동할 경우 관람객이 지루함을 느끼게 되어 이탈하거나 가이드 효 용이 낮아지며, 안내 로봇이 관람객 보다 너무 빠르게 이동할 경우 무리하여 좇아가는 도중에 사고로 이어질 수 있기 때문이다. 이와 같이 관람객의 이동 속도에 맞추어 안내 로봇이 다음 대상 전시물 위치로 이동하게 함으로 써, 도슨트 서비스를 이용하는 관람객이 이탈하지 않고 도슨트를 계속 사용하게끔 하며, 도슨트 효과도 더욱 향 상된다. 또한, 안내 로봇은 앞서가는 관람객을 향해 다음 대상 전시물의 위치를 미리 안내할 수도 있다. 또한, 안내 로봇은 관람객과 로봇의 현재 위치 간의 거리 정보에 근거하여 주행속도를 조절할 수 있고, 상 기 거리 정보를 이용하여 안내 로봇의 세부 위치를 수정하거나 발화음량을 설정 또는 변경할 수 있다. 예를 들어, 상기 거리 정보에 기초하여 관람객과 로봇이 일정한 이격거리범이를 유지하도록 안내 로봇을 전후로 이동하여 안내 로봇의 위치를 조절할 수 있다. 또, 예를 들어, 상기 거리 정보나 따라오는 관람객 수 정보에 기 초하여, 안내하는 발화음량을 증가시킬 수 있다. 실시 예에서, 안내 로봇은 대상 전시물 주변의 혼잡도에 기초하여 도착 위치 또는 로봇 자세를 수정할 수 있다. 예를 들어, 대상 전시물 주변이 혼잡한 경우, 혼잡 형태에 기초하여 혼잡이 덜한 위치 또는 영역으로 도착 위치 를 수정할 수 있다. 또, 예를 들어 혼잡의 해소를 유도하기 위해, 안내 로봇이 혼잡이 덜한 위치 또는 영역을 주시하여, 관람객 스스로 혼잡하지 않는 위치로 이동하게끔 할 수 있다. 또, 예를 들어, 안내 로봇의 자세는 관 람객의 얼굴 밀집 분포도가 높거나 혼잡한 방향과 대상 전시물을 감상할 수 있는 방향 내에 오도록 자세를 수정할 수 있다. 도 9는 본 발명과 관련된 안내 로봇이, 도착 위치로 이동 후 관람객의 얼굴방향에 따라 자세 또는 시선방향을 조절하는 것과 관련된 세부 동작을 포함하는 도면이다. 다시 말해, 도 9는 도 4의 흐름도의 단계와 관련된 세부 동작을 도시한 것이다. 실시 예에서, 안내 로봇이 결정된 도착 위치로 이동한 후, 안내 로봇은 해당 도착 지점에서 주변 관람객의 얼굴을 모니터링한다. 예를 들어, 안내 로봇은 헤드부 또는 헤드부의 시선방향을 좌우로 이동하면서, 카메라 등의 비전센서를 통 해, 대상 전시물 주변에 모여든 관람객의 얼굴 및 얼굴방향을 모니터링한다. 실시 예에서, 상기 모니터링에 기초하여, 안내 로봇은 도착 위치를 수정하거나 또는 현재 위치에서 정해진 모션 을 수행할 수 있다. 여기서, 정해진 모션은 미리정해진 특정 동작(예, 헤드를 좌우로 움직임), 표정변화 (예, 눈 깜빡임)를 수행하는 것으로, 이는 도착 위치가 확정되었음을 인지한 것에 대한 표시일 수 있다. 실시 예에서, 안내 로봇은 상기 모니터링에 기초하여, 대상 전시물에 대한 발화의 음성타입, 발화음량, 발 화속도를 선택적으로 조절할 수 있다. 이를 위해, 상기 안내 로봇은 상기 모니터링에 기초하여, 대상 전시물 주변의 관람객 정보, 예를 들어, 관 람객의 주요 구성(예, 가족 여부, 어린이 포함 여부 등), 성별, 연령대를 확인할 수 있다. 발화의 음성타입은 관람객의 성별, 연령대에 맞는 음성이 자동 선택되도록, 안내 로봇과 연동된 TTS 엔진을 선 택할 수 있다. 그에 따라, 관람객에 보다 친화적인 도슨트 서비스를 제공할 수 있다. 발화음량은, 관람객이 많을수록 로봇과의 이격거리가 클수록, 관람객의 연령대가 높을수록 증가할 수 있다. 또 한, 발화속도는, 관람객의 연령대가 평균보다 낮거나 높은 경우, 관람객의 주요 구성이 가족인 경우, 기준치보 다 감소될 수 있다. 실시 예에서, 안내 로봇은 관람객이 많은 위치 또는 영역을 오래 주시하도록 로봇의 헤드 또는 눈동자 시 선방향을 좌우로 이동하면서 발화를 개시할 수 있다. 이와 같은 발화 개시 전 동작을 통해, 관람객의 집중 이 보다 향상될 수 있다. 도 10은 본 발명과 관련된 안내 로봇이, 대상 전시물에 대한 발화 전후 또는 발화 동안 업데이트되는 관람객 정 보에 기초하여 다음 동작을 결정하는 것과 관련된 세부 동작을 포함하는 도면이다. 다시 말해, 도 10은 도 4의 흐름도의 단계와 관련된 세부 동작을 도시한 것이다. 도슨트 서비스가 개시되면, 안내 로봇은 카메라 등의 비전센서를 통해 지속적이고 실시간으로 관람객 정보 를 획득 및 업데이트할 수 있다. 실시 예에서, 안내 로봇은, 업데이트되는 관람객 정보에 포함된 관람객의 표정 또는 행동 변화를 분석하고, 상기 분석에 따른 관람 집중 정도에 기초하여 발화 컨텐츠나 발화시간의 수정 여부를 결정할 수 있다 . 여기에서, 초기의 발화 컨텐츠는 관람객의 모니터링에 따른 관람객의 주요 구성, 연령대 등과 같은 관람객의 특 징에 따라 선택될 수 있다. 예를 들어, 관람객의 연령대가 기준보다 낮거나 높은 경우 컨텐츠 난이도를 낮추어 서 발화를 개시할 수 있다. 이와 같은 초기 발화 컨텐츠에 따라 도슨트 발화를 수행하는 동안, 모니터링되는 관람객의 표정 및/또는 행동변 화에서 지루함 또는 이해 못함이 감지되면, 안내 로봇은 컨텐츠 발화를 중단하지 않고, 재미요소를 포함하 는 발화 컨텐츠(예, 대상 전시물과 관련된 퀴즈, 일화 등)로 수정하여 발화를 이어나갈 수 있다. 또는, 안내 로"}
{"patent_id": "10-2025-7000581", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "봇은 컨텐츠의 길이를 조절하여, 예를 들어 요약 형태로 발화 컨텐츠를 변경할 수 있다. 또한, 발화 도중이라도 관람 조건에 맞지 않는 상황 발생이 감지되면, 안내 로봇은 규정 안내(예, '동물을 데리고 입장할 수 없어요')를 발화하도록, 발화 컨텐츠의 종류를 변경할 수 있다. 실시 예에서, 안내 로봇은 업데이트되는 관람객 정보에 포함된 혼잡도에 기초하여, 안내 관람 경로 또는 다음 대상 전시물의 변경 여부를 결정할 수 있다. 예를 들어, 공간의 혼잡도에 따라 안내 로봇이 지정된 관람 안내 경로로 주행하기 곤란하거나 또는 관람객 의 특징에 따라 다음 대상 전시물로의 이동경로 또는 이동수단의 변경이 필요하다고 판단되는 경우, 관람 순서,관람 안내 경로, 안내할 다음 전시물을 상황에 적합하게 수정하여 안내할 수 있다. 예를 들어, 층간 이동시 엘리베이터 공간이 혼잡한 경우 계단을 이용하도록 안내하거나, 관람객이 보조기구(예, 휠체어 등)를 사용하는 경우 이동하기 편한 경로를 추가로 안내할 수 있다. 또는, 예를 들어 관람 순서를 변경하여 관람 혼잡도가 낮은 전시물부터 설명하거나, 대상 전시물의 주변 혼잡도 가 높은 경우에는 발화 컨텐츠의 길이/시간을 감소시켜서 도슨트 발화를 제공할 수 있다. 또한, 실시 예에서, 안내 로봇은 업데이트되는 관람객 정보에 포함된 관람객 수에 근거하여, 관람 안내 종 료 여부를 결정할 수 있다. 구체적으로, 안내 로봇의 프로세서는 카메라 등의 비전 센서를 통해 남은 관람객 수가 없는 것으로 결정되면, 안내할 관람 경로를 모두 마친 것으로 인지하고, 다음 대상 전시물로 안내 없이 관람 안내를 종료할 수 있다. 이후, 안내 로봇은 지정된 대기 위치로 이동하거나, 설정 조건(예, 혼잡도가 적은 위치 또는 영 역)에 부합하는 위치로 스스로 이동할 수 있다. 그에 따라, 기존에는 미리 지정된 안내 경로를 완료하거나 또는 사용자나 관리자가 취소 버튼(또는, 다른 명령 입력)을 눌러야 관람 안내가 비로소 종료되었던 문제가 해소되었다. 본 발명의 일부 실시 예에 따른 안내 로봇 및 그것의 동작방법에 의하면, 주변의 관람객 정보에 포함된 관람객 수, 대상 전시물 주변의 혼잡도에 따라 미리저장된 지정 위치를 수정할 수 있고, 해당 위치로 안내 로봇이 이동 한 후에도 관람객이 바라보는 방향, 혼잡도, 대상 전시물의 위치에 따라 세부 위치를 조정하거나 안내 로봇의 자세, 각도, 시선처리를 적절하게 조절할 수 있다. 그에 따라, 서비스를 제공받는 관람객은 사람이 도슨트를 수 행하는 경우와 유사한 친근감을 느낄 수 있고, 관람에 집중할 수 있다. 이상에서 설명한 바와 같이, 본 발명의 일부 실시 예에 따른 안내 로봇 및 그것의 동작방법에 의하면, 대상 전 시물 주변에 모인 관람객의 특징을 모니터링하여 그에 적절한 음성타입, 음량, 속도로 발화하고, 관람객의 집중 도를 모니터링하여 컨텐츠나 발화 시간을 조절함으로써, 관람객의 관람 집중도와 내용 이해도를 보다 증진시킬 수 있다. 또한, 관람 혼잡도에 따라 저장된 관람 안내 경로나 설명할 다음 대상 전시물을 유연하게 수정함으로 써, 도슨트 효과를 높일 수 있다. 또한, 다음 대상 전시물로 이동시 관람객의 이동속도에 맞추어 주행함으로써, 다음 해설을 지체없이 이어나갈 수 있어서, 도슨트 서비스를 제공받는 관람객의 집중을 최대한 유지할 수 있다. 또한, 관람 안내가 진행되는 동안에도 관람객이 모두 떠난 경우와 같이 더 이상 도슨트 서비스를 제공할 필요가 없는 것으로 판단되면, 관리자의 추가 입력 없이, 안내 로봇 스스로 서비스를 종료하고, 대기 위치로 이동할 수 있다. 그에 따라, 불필요한 자원 낭비가 없게 되며, 관람객이 없음에도 도슨트를 계속 진행하는 어색한 상황이 제거된다. 본 발명의 적용 가능성의 추가적인 범위는 이하의 상세한 설명으로부터 명백해질 것이다. 그러나 본 발명의 사 상 및 범위 내에서 다양한 변경 및 수정은 당업자에게 명확하게 이해될 수 있으므로, 상세한 설명 및 본 발명의 바람직한 실시 예와 같은 특정 실시 예는 단지 예시로 주어진 것으로 이해되어야 한다. 이상에서 실시예들에 설명된 특징, 구조, 효과 등은 본 발명의 적어도 하나의 실시예에 포함되며, 반드시 하나 의 실시예에만 한정되는 것은 아니다. 나아가, 각 실시예에서 예시된 특징, 구조, 효과 등은 실시예들이 속하는 분야의 통상의 지식을 가지는 자에 의해 다른 실시예들에 대해서도 조합 또는 변형되어 실시 가능하다. 따라서 이러한 조합과 변형에 관계된 내용들은 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다. 또한, 이상에서 실시예를 중심으로 설명하였으나 이는 단지 예시일 뿐 본 발명을 한정하는 것이 아니며, 본 발 명이 속하는 분야의 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성을 벗어나지 않는 범위에서 이상에 예시되지 않은 여러 가지의 변형과 응용이 가능함을 알 수 있을 것이다. 예를 들어, 실시예에 구체적으로 나타 난 각 구성 요소는 변형하여 실시할 수 있는 것이다. 그리고 이러한 변형과 응용에 관계된 차이점들은 첨부된 청구 범위에서 규정하는 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5a 도면5b 도면5c 도면6 도면7a 도면7b 도면7c 도면8 도면9 도면10"}
{"patent_id": "10-2025-7000581", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명과 관련된 안내 로봇의 예시를 보여주는 도면이다. 도 2 본 발명과 관련된 안내 로봇의 예시 구성을 보인 블록도이다. 도 3은 본 발명과 관련된 안내 로봇이, 관람객 정보에 기초하여 대상 전시물에 대한 안내 또는 설명을 위해 발 화하는 모습을 보여주는 예시 도면이다. 도 4는 본 발명과 관련된 안내 로봇의 동작방법의 대표 흐름도이다. 도 5a, 도 5b, 도 5c는 본 발명과 관련된 안내 로봇이, 안내할 대상 전시물 주변의 혼잡도에 근거하여 도착 위 치를 세부 수정하는 것을 설명하기 위한 개념도들이다. 도 6은 본 발명과 관련된 안내 로봇이, 도착 위치로 이동 후 관람객이 더 많은 위치 또는 영역을 보다 오래 주 시하는 것을 설명하기 위한 예시 개념도이다. 도 7a, 도 7b, 도 7c는 본 발명과 관련된 안내 로봇이, 도착 위치에서 관람객의 얼굴방향에 대응하도록 시선방 향을 이동하는 예시를 설명하기 위한 개념도들이다. 도 8은 본 발명과 관련된 안내 로봇이, 대상 전시물과 관련된 도착 위치를 결정하고, 결정된 위치로 이동하는 것과 관련된 세부 동작을 포함하는 도면이다. 도 9는 본 발명과 관련된 안내 로봇이, 도착 위치로 이동 후 관람객의 얼굴방향에 따라 자세 또는 시선방향을 조절하는 것과 관련된 세부 동작을 포함하는 도면이다. 도 10은 본 발명과 관련된 안내 로봇이, 대상 전시물에 대한 발화 전후 또는 발화 동안 업데이트되는 관람객 정 보에 기초하여 다음 동작을 결정하는 것과 관련된 세부 동작을 포함하는 도면이다."}
