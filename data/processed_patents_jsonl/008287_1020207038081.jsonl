{"patent_id": "10-2020-7038081", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0018352", "출원번호": "10-2020-7038081", "발명의 명칭": "신경망의 양자화 파라미터 확정방법 및 관련제품", "출원인": "상하이 캠브리콘 인포메이션 테크놀로지 컴퍼니", "발명자": "리우 샤올리"}}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "데이터 비트폭을 조정하기 위한 방법에 있어서, 양자화 대상 데이터에 대해 양자화 처리를 수행하기 위한 상기 양자화 대상 데이터의 상기 양자화 처리 후 양자화 된 데이터의 비트폭을 나타내는 데이터 비트폭을 회득하는 것; 상기 데이터 비트폭에 기초하여 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 수행하여 상기 1그룹의 양자화 대상 데이터를 상기 데이터 비트폭을 갖는 1그룹의 양자화 된 데이터로 변환하는 것; 상기 1그룹의 양자화 대상 데이터와 상기 1그룹의 양자화 된 데이터를 비교하여 상기 데이터 비트폭과 관련된양자화 오차를 확정하는 것; 및 확정된 상기 양자화 오차에 근거하여 상기 데이터 비트폭을 조정하는 것을 포함하는 것을 특징으로 하는 데이터비트폭을 조정하기 위한 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 1그룹의 양자화 대상 데이터와 상기 1그룹의 양자화 된 데이터를 비교하여 상기 데이터 비트폭과 관련된양자화 오차를 확정하는 것은, 상기 데이터 비트폭에 근거하여 양자화 간격을 확정하는 것; 및 상기 양자화 간격, 상기 1그룹의 양자화 된 데이터 및 상기 1그룹의 양자화 대상 데이터에 근거하여 상기 양자화 오차를 확정하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 양자화 간격, 상기 1그룹의 양자화 된 데이터 및 상기 1그룹의 양자화 대상 데이터에 근거하여 상기 양자화 오차를 확정하는 것은, 상기 양자화 간격에 근거하여, 상기 1그룹의 양자화 된 데이터를 역 양자화하여 1그룹의 역 양자화 데이터를 획득하며, 여기에서 상기 1그룹의 역 양자화 데이터의 데이터 형식은 상기 1그룹의 양자화 대상 데이터의 데이터형식과 같은 것; 및 상기 1그룹의 역 양자화 데이터와 상기 1그룹의 양자화 대상 데이터에 근거하여 양자화 오차를 확정하는 것을포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 확정된 상기 양자화 오차에 근거하여 상기 데이터 비트폭을 조정하는 것은, 제1 한계 값과 제2 한계 값 중의 적어도 하나를 포함하는 미리 설정된 한계 값과 상기 양자화 오차를 비교하는것; 및 상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 공개특허 10-2021-0018352-3-상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하는 것은, 상기 양자화 오차가 제1 한계 값 이상임을 확정하는 것에 응답하여 상기 데이터 비트폭을 증가하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 데이터 비트폭을 증가하는 것은, 제1 미리 설정된 비트폭 스텝에 근거하여 상기 데이터 비트폭을 증가하여 조정 후 데이터 비트폭을 확정하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하여 상기 1그룹의 양자화 대상 데이터를 상기 조정 후 데이터 비트폭을 갖는 다른 그룹의 양자화 된 데이터로 변환하는 것; 및 상기 1그룹의 양자화 대상 데이터와 상기 다른 그룹의 양자화 된 데이터를 비교하여 상기 다른 하나의 양자화오차가 상기 제1 미리 설정된 한계 값보다 작을 때까지 상기 조정 후 데이터 비트폭과 관련되는 다른 하나의 양자화 오차를 확정하는 것을 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 방법은 반복적으로 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제4항에 있어서, 상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하는 것은, 상기 양자화 오차 상기 제2 한계 값 이하임을 확정하는 것에 응답하여 상기 데이터 비트폭을 감소하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 데이터 비트폭을 감소하는 것은, 제2 미리 설정된 비트폭 스텝에 근거하여 상기 데이터 비트폭을 감소하여 조정 후 데이터 비트폭을 확정하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하여 상기 1그룹의 양자화 대상 데이터를 상기 조정 후 데이터 비트폭을 갖는 다른 그룹의 양자화 된 데이터로 변환하는 것; 및 상기 1그룹의 양자화 대상 데이터와 상기 다른 그룹의 양자화 된 데이터에 근거하여, 상기 다른 하나의 양자화오차가 상기 제2 미리 설정된 한계 값보다 클 때까지 상기 조정 후 데이터 비트폭과 관련된 다른 하나의 양자화오차를 확정하는 것을 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2021-0018352-4-제11항에 있어서, 상기 방법은 반복적으로 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제4항에 있어서, 상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하는 것은, 상기 양자화 오차가 상기 제1 한계 값과 상기 제2 한계 값 사이에 있음을 확정한 것에 응답하여 상기 데이터 비트폭을 유지하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항 내지 제13항 중 어느 한 항에 있어서, 상기 1그룹의 양자화 대상 데이터와 상기 조정 후 데이터 비트폭에 근거하여 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하기 위한 양자화 파라미터를 업데이트하는 것; 및 업데이트된 상기 양자화 파라미터에 근거하여 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하는것을 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서, 양자화 대상 데이터의 데이터 변동폭을 획득하는 것; 및상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거하여 상기 데이터 비트폭을 조정하는 것을 더 포함하며, 상기 목표반복간격은 적어도 1회 반복을 포함하는 것을특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭을 획득하는 것은, 점 위치의 변동폭을 획득하는 것을 포함하며, 여기에서 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭을 특성화하는 데 사용되고, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭과정의 상관이 있는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 점 위치의 변동폭을 획득하는 것은, 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복에 대응하는점 위치에 근거하여 제1 균치를 확정하며, 여기에서, 상기 전회 검사 반복은 상기 목표반복간격 전의 전회 반복간격에 대응하는 검사 반복인 것; 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균치를 확정하며; 여기에서, 상기 현재 검사 반복에 대응하는 점 위치는 상기 현재 검사 반복에 대응하는 목표데이터 비트폭과 양자화 대상 데이터에 의해 확정된 것; 및상기 제1 균치와 상기 제2 균치에 근거하여 상기 점 위치의 변동폭을 특성화하기 위한 제1 오차를 확정하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 공개특허 10-2021-0018352-5-상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정하는 것은, 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하는 것을 포함하며, 상기 목표반복간격은 상기 제1 오차와부의 상관이 있을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭을 획득하는 것은 진일보로, 상기 데이터 비트폭의 변화추세를 획득하는 것; 상기 점 위치의 변동폭과 상기 데이터 비트폭의 변화추세에 근거하여 상기 양자화 대상 데이터의 데이터 변동폭을 확정하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정하는 것은 진일보로, 획득한 점 위치의 변동폭을 특성화하기 위한 제1 오차와 데이터 비트폭의 변화추세를 특성화하기 위한제2 오차에 근거하여 상기 목표반복간격을 확정하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 획득한 상기 제1 오차와 상기 제2 오차에 근거하여 상기 목표반복간격을 확정하는 것은, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 하는 것; 및 상기 목표오차에 근거하여 상기 목표반복간격을 확정하는 것을 포함하며, 여기에서, 상기 목표오차는 상기 목표반복간격과 부의 상관이 있는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항 또는 제21항에 있어서, 상기 제2 오차는 양자화 오차에 의해 확정되고; 여기에서, 상기 양자화 오차는 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 의해 확정되며, 상기 제2 오차는 상기 양자화 오차와 정의 상관이 있는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제15항 내지 제22항 중 어느 한 항에 있어서, 상기 방법은 신경망의 훈련 또는 미조정에 적용되며, 상기 방법은 진일보로, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정하며, 상기 목표반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 포함하는 것을특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 제1 미리 설정된 반복간격을 상기 목표반복간격으로하고, 상기 제1 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "공개특허 10-2021-0018352-6-제23항 또는 제24항에 있어서, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 제2 미리 설정된 반복간격을 상기 목표반복간격으로하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 더 포함하며; 여기에서, 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간격이 상기 제1 미리 설정된 반복간격보다도 큰 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제25항에 있어서, 상기 신경망의 수렴정도가 미리 설정된 조건을 충족시키면, 상기 현재 검사 반복이 제2 미리 설정된 반복 이상임을 확정하는 것을 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제25항에 있어서, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 또 제2 오차가 미리 설정된 오차 값보다 큰 경우, 상기양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확정하며, 상기 반복간격에 근거하여 상기 데이터비트폭을 다시 확정하도록 하는 것을 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "데이터 비트폭을 조정하는 장치에 있어서, 양자화 대상 데이터에 대해 양자화 처리를 수행하기 위한 상기 양자화 대상 데이터의 상기 양자화 처리 후 양자화 된 데이터의 비트폭을 나타내는 데이터 비트폭을 회득하기 위한 획득모듈; 상기 데이터 비트폭에 기초하여 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 수행하여 상기 1그룹의 양자화 대상 데이터를 상기 데이터 비트폭을 갖는 1그룹의 양자화 된 데이터로 변환하기 위한 양자화 모듈; 상기 1그룹의 양자화 대상 데이터와 상기 1그룹의 양자화 된 데이터를 비교하여 상기 데이터 비트폭과 관련된양자화 오차를 확정하기 위한 확정모듈; 및 확정된 상기 양자화 오차에 근거하여 상기 데이터 비트폭을 조정하기 위한 조정모듈을 포함하는 것을 특징으로하는 데이터 비트폭을 조정하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제28항에 있어서, 상기 비교모듈은, 상기 데이터 비트폭에 근거하여 양자화 간격을 확정하기 위한 간격확정모듈, 및 상기 양자화 간격, 상기 1그룹의 양자화 된 데이터 및 상기 1그룹의 양자화 대상 데이터에 근거하여 상기 양자화 오차를 확정하기 위한 오차 확정모듈을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제29항에 있어서, 상기 오차 확정모듈은, 상기 양자화 간격에 근거하여 상기 1그룹의 양자화 된 데이터에 대해 역 양자화를 수행하여 1그룹의 역 양자화데이터를 획득하는 데 사용되고, 상기 1그룹의 역 양자화 데이터의 데이터 형식이 상기 1그룹의 양자화 대상 데이터의 데이터 형식과 같은 역 양자화 모듈, 및 상기 1그룹의 역 양자화 데이터와 상기 1그룹의 양자화 대상 데이터에 근거하여 양자화 오차를 확정하기 위한양자화 오차 확정모듈을 포함하는 것을 특징으로 하는 장치. 공개특허 10-2021-0018352-7-청구항 31 제28항 내지 제30항 중 어느 한 항에 있어서, 상기 조정모듈은, 제1 한계 값과 제2 한계 값 중의 적어도 하나를 포함하는 미리 설정된 한계 값과 상기 양자화 오차를 비교하기위한 비교모듈, 및 상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하기 위한 비트폭 조정모듈을 포함하는 것을 특징으로하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제31항에 있어서, 상기 비트폭 조정모듈은, 상기 양자화 오차가 제1 한계 값 이상임의 확정에 응답하여 상기 데이터 비트폭을 증가하기 위한 증가모듈을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제32항에 있어서, 상기 증가모듈은, 제1 미리 설정된 비트폭 스텝에 근거하여 상기 데이터 비트폭을 증가시켜 조정 후 데이터 비트폭을 확정하기 위한 스텝 증가모듈을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제33항에 있어서, 상기 양자화 모듈은 진일보로 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하여 상기 1그룹의 양자화 대상 데이터를 다른 1그룹의 양자화 된 데이터로 변환하는 데사용되며, 상기 다른 1그룹의 양자화 된 데이터는 상기 조정 후 데이터 비트폭을 가지며; 및 상기 확정모듈은 진일보로 상기 1그룹의 양자화 대상 데이터와 상기 다른 1그룹의 양자화 된 데이터를비교하여, 다른 하나의 양자화 오차가 상기 제1 미리 설정된 한계 값보다 작을 때까지 상기 조정 후 데이터 비트폭과 관련되는 다른 하나의 양자화 오차를 확정하는 데 사용되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제34항에 있어서, 상기 장치는 반복적으로 호출되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제31항에 있어서, 상기 조정모듈은, 상기 양자화 오차가 상기 제2 한계 값 이하임을 확정하는 것에 응답하여 상기 데이터 비트폭을 감소시키기 위한감소모듈을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "제36항에 있어서, 상기 감소모듈은, 제2 미리 설정된 비트폭 스텝에 근거하여 상기 데이터 비트폭을 감소하여 조정 후 데이터 비트폭을 확정하기 위공개특허 10-2021-0018352-8-한 스텝 감소모듈을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "제37항에 있어서, 상기 양자화 모듈은 진일보로 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하여 상기 1그룹의 양자화 대상 데이터를 다른 1그룹의 양자화 된 데이터로 변환하는 데사용되며, 상기 다른 1그룹의 양자화 된 데이터는 상기 조정 후 데이터 비트폭을 가지며; 및 상기 확정모듈은 진일보로 상기 1그룹의 양자화 대상 데이터와 상기 다른 1그룹의 양자화 된 데이터에근거하여, 다른 하나의 양자화 오차가 상기 제2 미리 설정된 한계 값보다 클 때까지 상기 조정 후 데이터 비트폭과 관련되는 다른 하나의 양자화 오차를 확정하는 데 사용되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "제38항에 있어서, 상기 장치는 반복적으로 호출되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제31항에 있어서, 상기 조정모듈은, 상기 양자화 오차가 상기 제1 한계 값과 상기 제2 한계 값 사이에 있음을 확정하는 것에 응답하여 상기 데이터비트폭을 유지하기 위한 유지모듈을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제28항 내지 제40항 중 어느 한 항에 있어서, 상기 1그룹의 양자화 대상 데이터와 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하기 위한 양자화 파라미터를 업데이트하기 위한 업데이트모듈, 및 진일보로 업데이트한 상기 양자화 파라미터에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하기 위한 상기 양자화 모듈을 더 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "제28항에 있어서, 양자화 대상 데이터의 데이터 변동폭을 획득하기 위한 변동폭 모듈; 및 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거하여 상기 데이터 비트폭을 조정하기 위한 간격모듈을 더 포함하며, 상기 목표반복간격은 적어도 1회 반복을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "제42항에 있어서, 상기 변동폭 모듈은, 점 위치의 변동폭을 획득하기 위한 점 위치 모듈을 포함하며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭을 특성화하는 데 사용되고, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭과 정의 상관이 있는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "제43항에 있어서, 상기 점 위치모듈은, 공개특허 10-2021-0018352-9-현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복에 대응하는점 위치에 근거하여 제1 균치를 확정하는 데 사용되며, 상기 전회 검사 반복이 상기 목표반복간격 전의 이전 반복간격에 대응하는 검사 반복인 제1 균치모듈; 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균치를 확정하는 데 사용되며; 상기 현재 검사 반복에 대응하는 점 위치가 상기 현재 검사 반복에 대응하는 목표데이터 비트폭과 양자화 대상 데이터에 의해 확정되는 제2 균치모듈; 및 상기 제1 균치와 상기 제2 균치에 근거하여 상기 점 위치의 변동폭을 특성화하기 위한 제1 오차를 확정하기 위한 제1 오차모듈을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "제42항에 있어서, 상기 간격모듈은, 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하기 위한 제1 간격모듈을 포함하며, 상기 목표반복간격은상기 제1 오차와 부의 상관이 있는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "제42항에 있어서, 상기 변동폭 모듈은 진일보로, 상기 데이터 비트폭의 변화추세를 획득하기 위한 추세모듈; 및 상기 점 위치의 변동폭과 상기 데이터 비트폭의 변화추세에 근거하여 상기 양자화 대상 데이터의 데이터 변동폭을 확정하기 위한 데이터 변동폭 모듈을 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_47", "content": "제46항에 있어서, 상기 간격모듈은 진일보로, 획득한 제1 오차와 제2 오차에 근거하여 상기 목표반복간격을 확정하기 위한 반복간격모듈을 포함하며; 상기 제1 오차는 점 위치의 변동폭을 특성화하는 데 사용되고, 상기 제2 오차는 데이터 비트폭의 변화추세를 특성화하는 데 사용되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_48", "content": "제47항에 있어서, 상기 반복간격모듈은, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 하기 위한 목표오차모듈; 상기 목표오차에 근거하여 상기 목표반복간격을 확정하기 위한 목표반복간격모듈을 포함하며, 상기 목표오차는상기 목표반복간격과 부의 상관이 있는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_49", "content": "제37항 또는 제48항에 있어서, 상기 제2 오차는 양자화 오차에 의해 확정되고; 여기에서, 상기 양자화 오차는 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 의해 확정되며, 상기 제2 오차는 상기 양자화 오차와 정의 상관이 있는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_50", "content": "제42항 내지 제49항 중 어느 한 항에 있어서, 공개특허 10-2021-0018352-10-상기 장치는 신경망의 훈련 또는 미조정에 사용되며, 상기 장치는 진일보로, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정하고, 상기 목표반복간격에 근거하여 상기 양자화 파라미터를 조정하기 위한 제1 반복모듈을포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_51", "content": "제50항에 있어서, 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 제1 미리 설정된 반복간격을 상기 목표반복간격으로하고, 상기 제1 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하기 위한 제2 반복모듈을 더 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_52", "content": "제50항 또는 제51항에 있어서, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 제2 미리 설정된 반복간격을 상기 목표반복간격으로하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하기 위한 제3 반복모듈을 더 포함하며; 여기에서, 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간격이 상기 제1 미리 설정된 반복간격보다도 큰 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_53", "content": "제52항에 있어서, 상기 신경망의 수렴정도가 미리 설정된 조건을 충족시키면 상기 현재 검사 반복이 제2 미리 설정된 반복 이상임을 확정하기 위한 수렴모듈을 더 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_54", "content": "제52항에 있어서, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 또 제2 오차가 미리 설정된 오차 값보다 큰 경우, 상기양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확정하며, 상기 반복간격에 근거하여 상기 데이터비트폭을 다시 확정하도록 하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_55", "content": "컴퓨터 프로그램이 저장된 컴퓨터 판독 가능한 저장매체에 있어서, 상기 프로그램은 실행시에 제1항 내지 제27항 중의 어느 한 항에 따른 방법을 실현하는 것을 특징으로 하는 컴퓨터 판독 가능한 저장매체."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_56", "content": "제28항 내지 제54항 중의 어느 한 항에 따른 데이터를 처리하기 위한 장치를 포함하는 것을 특징으로 하는 인공지능 칩."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_57", "content": "제56항에 따른 인공지능 칩을 포함하는 것을 특징으로 하는 전자기기."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_58", "content": "메모리 디바이스, 인터페이스 장치와 제어 디바이스 및 제56항에 따른 인공지능 칩을 포함하며; 그 중, 상기 인공지능 칩은 상기 메모리 디바이스, 상기 제어 디바이스 및 상기 인터페이스 장치와 연결되고; 상기 메모리 디바이스는 데이터를 저장하는 데 사용되고; 상기 인터페이스 장치는 상기 인공지능 칩과 외부기기 사이의 데이터 전송을 실현하는 데 사용되며 공개특허 10-2021-0018352-11-상기 제어 디바이스는 상기 인공지능 칩의 상태를 감시하는 데 사용되는 것을 특징으로 하는 보드 카드."}
{"patent_id": "10-2020-7038081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_59", "content": "제58항에 있어서, 상기 메모리 디바이스는 복수 그룹의 저장유닛을 포함하며, 각 그룹의 저장유닛은 버스를 통해 상기 인공지능칩과 연결되고, 상기 저장유닛은 DDR SDRAM이며; 상기 칩은 각 상기 저장유닛의 데이터 전송과 데이터 저장을 제어하기 위한 DDR 컨트롤러를 포함하며; 상기 인터페이스 장치는 표준 PCIE 인터페이스인 것을 특징으로 하는 보드 카드."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 기술방안은 보드 카드에 관한 것이며, 상기 보드 카드는 메모리 디바이스, 인터페이스 장치와 제어 디바이스 및 인공지능 칩을 포함하며; 상기 인공지능 칩은 상기 메모리 디바이스, 상기 제어 디바이스 및 상기 인터페이스 장치와 각각 연결되고; 상기 메모리 디바이스는 데이터를 저장하는 데 사용되고; 상기 인터페이스 장치는 상기 인공지능 칩과 외부기기 사이의 데이터 전송을 실현하는 데 사용되며; 상기 제어 디바이스는 상기 인공지능 칩의 상태를 감시하는 데 사용된다. 상기 보드 카드는 인공지능 연산을 실행하는 사용될 수 있다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 신경망의 양자화 파라미터 확정방법 및 관련제품에 관한 것이다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "신경망（neural network, NN）은 생물학적 신경망의 구조와 기능을 모방한 수학적 모델 또는 계산모델이다. 신 경망은 샘플 데이터의 훈련을 통해 네트워크 가중치와 한계 값을 지속적으로 수정하여 오차함수를 음의 기울기 방향으로 강하시켜 소망의 출력에 근사한다. 이것은 널리 응용되고 있는 식별분류모델이며, 함수근사, 모델식별 분류, 데이터 압축 및 시간열 예측 등에 많이 채용된다. 실제 운용에서 신경망의 데이터는 32Bit가 일반적이며, 종래의 신경망에서 데이터는 더 많은 비트를 차지하여 정밀도는 확보되지만 큰 저장공간 및 처리대역폭이 필요하고, 비용이 상승하고 있다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상술한 기술적 문제를 해결하기 위해 본 발명은 데이터 비트폭을 조정하기 위한 방법 및 관련제품을 제안한다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위해, 본 발명은 데이터 비트폭을 조정하기 위한 방법을 제공하며, 상기 방법은, 양자화 대상 데이터에 대해 양자화 처리를 수행하기 위한 상기 양자화 대상 데이터의 상기 양자화 처리 후 양자 화 된 데이터의 비트폭을 나타내는 데이터 비트폭을 회득하는 단계; 상기 데이터 비트폭에 기초하여 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 수행하여 상기 1그룹의 양자 화 대상 데이터를 상기 데이터 비트폭을 갖는 1그룹의 양자화 된 데이터로 변환하는 단계; 상기 1그룹의 양자화 대상 데이터와 상기 1그룹의 양자화 된 데이터를 비교하여 상기 데이터 비트폭과 관련된 양자화 오차를 확정하는 단계; 및 확정된 상기 양자화 오차에 근거하여 상기 데이터 비트폭을 조정하는 단계를 포함하는 것을 특징으로 한다. 상기 목적을 달성하기 위해, 본 발명은 데이터 비트폭을 조정하는 장치를 제공하는 바, 메모리 및 프로세서를 포함하며, 상기 메모리에는 프로세서에 의해 실행가능한 컴퓨터 프로그램이 저장되어 있고, 상기 프로세서가 상 기 컴퓨터 프로그램을 실행하면 전술한 방법의 단계를 구현한다. 상기 목적을 달성하기 위해, 본 발명은 컴퓨터 판독 가능한 저장매체를 제공하는 바, 프로세서에 의해 실행되면 저술한 방법의 단계를 구현하는 컴퓨터 프로그램이 저장되어 있다. 상기 목적을 달성하기 위해, 본 발명은 데이터 비트폭을 조정하는 기기를 제공하는 바, 상기 기기는, 양자화 대상 데이터에 대해 양자화 처리를 수행하기 위한 상기 양자화 대상 데이터의 상기 양자화 처리 후 양자 화 된 데이터의 비트폭을 나타내는 데이터 비트폭을 회득하기 위한 획득유닛; 상기 데이터 비트폭에 기초하여 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 수행하여 상기 1그룹의 양자 화 대상 데이터를 상기 데이터 비트폭을 갖는 1그룹의 양자화 된 데이터로 변환하기 위한 양자화 유닛; 상기 1그룹의 양자화 대상 데이터와 상기 1그룹의 양자화 된 데이터를 비교하여 상기 데이터 비트폭과 관련된 양자화 오차를 확정하기 위한 확정유닛; 및 확정된 상기 양자화 오차에 근거하여 상기 데이터 비트폭을 조정하기 위한 조정유닛을 포함한다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "신경망 연산과정에서 양자화하는 경우 본 발명의 기술방안을 이용하여, 인공지능 프로세서가 신경망 연산과정에 서 데이터를 양자화하는 데 사용되는 데이터 비트폭을 확정하고 고정밀도 데이터를 저정밀도 고정 소수점 수로 변환하면 신경망 연산과정에 관련된 모든 데이터 저장공간의 크기를 줄일 수 있다. 예를 들어: float32를 fix8 로 변환하면 모델 파라미터를 4배 줄일 수 있다. 데이터 저장공간이 작아지므로 신경망의 배치시에 보다 작은 공간을 사용하게 되며, 인공지능 프로세서 칩상의 온 칩 메모리에 보다 많은 데이터를 수용할 수 있고, 인공지 능 프로세서 칩의 액세스 데이터를 감소시키고, 계산성능을 향상시킨다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시예에 따른 도면을 참조하여 본 발명의 실시예에 따른 기술방안을 명확하고 완전하게 설명 한다. 다음 설명되는 실시예는 단지 본 발명의 일부 실시예에 불과하며, 모든 실시예가 아니다는 점이 분명하다. 당업자가 창조적인 노력 없이 본 발명의 실시예에 기초하여 획득한 모든 다른 실시예는 모두 본 발명 의 보호범위에 속한다. 본 발명의 명세서, 청구범위 및 첨부된 도면에 있어서의 \"제1\", \"제2\", \"제3\", \"제4\" 등 용어는 서로 다른 대상 을 구분하는 데에 사용되며, 특정 순서를 설명하는 데에 사용되는 것은 아니다. 또한, 본 발명의 명세서, 청구 범위 및 첨부된 도면에 있어서 사용되는 \"포함한다\"와 \"가진다\"는 용어는 설명된 특징, 전체, 단계, 동작, 요소 및/또는 구성요소의 존재를 나타내는 데 사용되지만 하나 이상의 다른 특징, 전체, 단계, 동작, 요소, 구성요소 및/또는 이들 컬렉션의 존재 또는 추가를 배제하는 것이 아니다. 또한, 본 발명 명세서에서 사용된 용어는 특정 실시예를 설명하기 위한 것이며 본 발명 명세서를 제한하려는 의 도가 아님을 이해해야 한다. 본 발명 명세서 및 청구범위에서 사용된 바와 같이, 문맥이 다른 상황을 명확하게 나타내지 않는 한, \"a\", \"an\" 및 \"the\"의 단수형태는 복수형태를 포함하는 것으로 의도된다. 본 발명 명세서 및 청구범위에서 사용된 용어 \"및/또는\"은 관련하여 나열된 하나 이상의 항목 및 모든 가능한 조합의 임의의 조합 을 지칭하고 이러한 조합을 포함한다는 것을 추가로 이해해야 한다. 본 명세서 및 청구범위에서 사용되는 바와 같이, 용어 \"만약\"은 문맥에 따라 \"... 때\" 또는 \"... 면\" 또는 \"확 정에 대한 응답으로\" 또는 \"검출에 대한 응답으로\" 로 해석 될 수 있다. 유사하게, \"확정된 경우\" 또는 \"검출된 경우 [설명된 조건 또는 이벤트]\" 라는 문구는 문맥에 따라 \"일단 확정되면\" 또는 \"확정에 대한 응답으로\" 또는 \"일단 검출되면 [설명된 조건 또는 이벤트]\" 또는 \"검출에 대한 응답 [설명된 조건 또는 이벤트]\" 의 의미로 해 석될 수 있다. 기술용어정의: 부동 소수점 수: IEEE 부동 소수점 표준은 의 형식으로 하나의 숫자를 나타낸 다. 여기에서, sign은 부호 비트이고, 0은 정의 수를 나타내며, 1은 부의 수를 나타내며, E는 지수를 나타내고, 부동 소수점 수에 가중치를 부여하며, 가중치는 2의 E제곱（부의 수 제곱일 수 있음）이고; 는 가수를 나타내며, 는 바이너리 소수이고, 그 범위는 또는 이다. 컴퓨터에서의 부동 소수점 수의 표현은 3개의 필드로 나뉘며, 이들 필드를 각각 인코딩한다. 단일 부호 비트s는 부호s를 직접 인코딩한다. k비트의 지수 필드는 지수를 인코딩하며, 이다. n비트의 소수 필드mantissa는 가수를 인코딩한다. 그러나 인코딩 결과는 지수 단계가 모두 0인지 여부에 의 존한다. 고정 소수점 수: 공유지수（exponent）, 부호 비트（sign）, 가수（mantissa）의 세 부분으로 구성된다. 그 중 공유지수는 지수가 양자화를 필요로 하는 실수집합 내에서 공유되는 것을 의미하고, 부호 비트는 고정 소수점 수의 정부를 나타낸다. 가수는 고정 소수점 수의 유효자리수, 즉 정밀도를 결정한다. 8bit 고정 소수점 수 유형 을 예로 들어 수치계산방법은 다음과 같다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "바이너리 소수: 임의의 십진수는 모두 수학식 으로 표현할 수 있다. 예를 들어 십진수 12.34를 수학식1 로 표현하면 이며, 소수점의 왼쪽은 10의 양의 제곱으로 계산하고, 소수점의 오른쪽은 10의 음의 제곱으로 계산한다. 마찬가지로 바이너리 소수도 이런 방식으로 표현할 수 있다. 즉 소수점 왼쪽은 2의 양의 제곱으로, 소수점의 오른쪽은 2의 음의 제곱으로 계산하며, 십진소수 575는 바이너리 소수 10111로 표현할 수 있다. 당해 바이너리 소수는 로 표현된다. 오버플로(overflow): 고정 소수점 연산기에서는 수의 표현에 일정한 범위가 있다. 연산과정에서 수의 크기가 고 정 소수점 수가 표현할 수 있는 범위를 초과하는 경우 \"오버플로\"라고 한다. KL（Kullback-Leibler divergence） 분산도: 상대 엔트로피（relative entropy）, 정보분산도（information divergence）, 정보이득（information gain）이라고도 한다. KL분산도는 두 확율분포 P와 Q 사이의 차이 비대칭 성의 척도이다. KL분산도는 Q 기반 코드를 사용하여 P로부터의 샘플을 인코딩하기 위해 평균적으로 필요로 되는 추가 비트 수를 측정하기 윈한 것이다. 전형적으로는, P는 데이터의 실제분포를 나타내고, Q는 데이터의 이론분 포, 모델분포, 또는 P의 근사분포를 나타낸다. 데이터 비트폭: 데이터를 나타내는 데 사용되는 비트수이다. 양자화: 종래 32bit또는 64bit로 표현된 고정밀도 수를 메모리 공간을 덜 차지하는 고정 소수점 수로 변환한는 과정이다. 고정밀도 수를 고정 소수점 수로 변환하는 과정에서는 정밀도에 일정한 손실이 생긴다. 이하, 본 발명 실시예에서 제공하는 신경망의 양자화 파라미터 확정방법 및 관련제품의 구체적인 실시예에 대하여 첨부도면을 참조하면서 상세히 설명한다. 신경망（neural network, NN）은 다수의 뉴런이 연결되어 계산되는 생물학적 신경망의 구조와 기능을 모방한 수 학적 모델이다. 따라서, 신경망은 계산모델로서 다수의 노드（또는 \"뉴런\"이라고 함）가 서로 연결되어 구성된 다. 각 노드는 활성화 함수（activation function）라고 불리는 특정한 출력함수이다. 두 뉴런 사이의 각 연결 은 모두 당해 연결을 통과하는 신호에 곱해지는 값을 나타내며 가중치라고 한다. 이는 신경망의 기억에 상당하 다. 신경망의 출력은 뉴런 사이의 연결방식 및 가중치와 활성화 함수에 따라 다르다. 신경망에서 뉴런은 신경망 의 기본단위이다. 이는 특정 수의 입력과 바이어스를 취득하고, 신호（값）가 도착하면 가중치를 곱한다. 연결 은 하나의 뉴런을 다른 층 또는 동일한 층의 다른 뉴런에 연결하는 것이며, 연결에는 관련된 가중치가 수반된다. 또한, 바이어스는 뉴런의 추가 입력이며, 항상 1이고, 자체의 연결 가중치를 가진다. 이것에 의해 모 든 입력이NULL（모두 0）이여도 뉴런이 활성화된다. 응용에서 비선형 함수가 신경망 내의 뉴런에 적용되지 않으면 신경망은 선형 함수일 뿐이며 단일 뉴런보다 강력 하지 않다. 하나의 신경망의 출력결과를 0으로부터 1 사이로 하면, 예를 들어, 고양이와 개의 판별 예에서 0에 가까운 출력을 고양이로 간주하고, 1에 가까운 출력을 개로 간주할 수 있다. 이 목표를 달성하기 위해 신경망에 서 활성화 함수, 예를 들어 시그모이드(sigmoid) 활성화 함수를 도입한다. 이 활성화 함수와 관련하여 반환 값 이 0과 1 사이의 숫자임을 알면 된다. 따라서, 활성화 함수는 비선형성을 신경망에 도입하기 위해 사용되며, 신 경망 연산결과를 작은 범위로 줄인다. 실제로는 활성화 함수가 어떻게 표현되는지는 중요하지 않으며, 일부 가 중치를 통해 비선형 함수를 파라미터화하는 것이 중요하다. 이들 가중치를 변경함으로써 비선형 함수를 변경할 수 있다. 도1에 도시된 바와 같이, 신경망 구조모식도이다. 도1에 도시된 신경망에는 입력층, 은닉층 및 출력층의 3층이 포함되어 있으며, 도1에 도시된 은닉층은 5층이다. 그 중에서 신경망의 가장 왼쪽층을 입력층이라고 하며, 입력 층의 뉴런을 입력뉴런이라고 한다. 입력층은 신경망의 제1 층으로서 필요한 입력신호（값）를 수신하고 다음 층 으로 전달한다. 일반적으로 입력신호（값）에 대하여 작업하지 않으며, 관련된 가중치와 바이어스가 없다. 도1 에 도시된 신경망에는 4개의 입력신호x1, x2, x3, x4가 있다. 은닉층은 입력 데이터에 다른 변환을 적용하기 위한 뉴런（노드）을 포함한다. 도1에 도시된 신경망에는 5개의 은닉층이 있다. 제1 은닉층에 4개의 뉴런（노드）, 제2 층에 5개의 뉴런, 제3 층에 6개의 뉴런, 제4 층에 4개의 뉴런, 제5 층에 3개의 뉴런이 있다. 마지막으로 은닉층은 뉴런의 연산 값을 출력층에 전달한다. 도1에 도시된 신경망은 5개의 은닉층 중 각 뉴런 사이를 완전히 연결한다. 즉 각 은닉층의 각 뉴런은 모두 다음 층의 각 뉴런 에 연결된다. 설명할 필요가 있는 것은 각 신경망의 은닉층이 완전히 연결되는 것이 아니다는 점이다. 도1 신경망의 맨 오른쪽 층을 출력층이라고 하며, 출력층의 뉴런을 출력뉴런이라고 한다. 출력층은 마지막 은닉 층으로부터 출력을 받는다. 도1에 도시된 신경망에서 출력층은 3개의 뉴런이 있어 3개의 출력신호y1, y2, y3이 있다. 실제 응용에서는 미리 대량의 샘플 데이터(입력 및 출력을 포함)를 주어 초기 신경망을 훈련하고, 훈련이 완료 된 후에 훈련된 신경망을 얻는다. 당해 신경망은 실제환경의 향후 입력에 대해 올바른 출력을 줄 수 있다. 신경망의 훈련에 대해 논의하기 전에 손실함수를 정의할 필요가 있다. 손실함수는 신경망이 어느 특정 태스크를 실행할 때 성능을 가늠하는 표현함수이다. 일부 실시예에서 손실함수는 다음과 같이 얻을 수 있다. 어느 신경망 을 훈련하는 과정에서 각 샘플 데이터에 대하여 모두 신경망에 따라 전달되어 출력 값을 얻게 되며, 이 출력 값 과 기대 값의 차이를 제곱하여 산출한 손실함수가 예측 값과 실제 값 사이의 거리로 되고, 신경망을 훈련하는 목적이 이 거리 또는 손실함수의 값을 작게 하는 것이다. 일부 실시예에서 손실함수는 다음과 같이 표현될 수 있다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 수학식에서 는 기대 값을 나타내고, 는 샘플 데이터 집합 중 각 샘플 데이터가 신경망을 통해 얻은 실 제결과를 가리키며, 는 샘플 데이터 집합 중 각 샘플 데이터의 인덱스이다. 은 기대 값 와 실제결과 사이의 오차 값을 나타낸다. 은 샘플 데이터 집합 중 샘플 데이터의 개수이다. 역시 고양이와 개의 판별을 예로 한다. 고양이와 개의 픽쳐로 구성된 한 데이터 세트에 있어서, 픽쳐가 개인 경우 대응하는 라벨은 1이고, 픽쳐가 고양이인 경우 대응하는 라벨은 0이다. 이 라벨이 상술한 수학식 중 기대 값 에 대응되고, 신경망에 매개 샘플픽쳐를 전달할 때 실제로는 신경망을 통해 식별결과를 획득하려고 한 것이다. 손실함수를 계산하기 위 해서는 샘플 데이터 세트 중 매개 샘플픽쳐를 거쳐 각 샘플픽쳐에 대응하는 실제결과 를 획득한 다음에 위의 정의에 따라 손실함수를 계산할 필요가 있다. 손실함수가 상대적으로 크면 신경망이 아직 제대로 훈련되지 않았 으며 가중치를 추가로 조정해야 함을 의미한다. 신경망의 훈련을 시작할 때 가중치를 랜덤으로 초기화해야 한다. 초기화된 신경망은 분명히 좋은 결과를 제공하 지 않는다. 훈련과정에서 아주 엉망인 신경망으로 시작한다고 가정하고, 훈련에 의해 정밀도가 높은 네트워크를 얻을 수 있다. 신경망의 훈련과정은 다음과 같은 2개의 단계로 나눌 수 있다. 첫 단계는 입력층으로부터 은닉층을 경유하여 최 종적으로 출력층에 이르는 신호의 순방향 처리이다. 다음 단계는 역방향 전파 그래디언트인 바, 출력층에서 은 닉층으로, 마지막으로 입력층에 도달하며, 그래디언트에 따라 신경망 중 각 층의 가중치와 바이어스를 순차조정 한다. 순방향 처리과정에서 입력 값을 신경망의 입력층에 입력하며, 신경망의 출력층으로부터 소위 예측 값의 출력을 얻는다. 입력 값이 신경망의 입력층에 제공되는 경우 아무 작업도 수행하지 않는다. 은닉층에서 두 번째 은닉층 은 첫 번째 은닉층으로부터 예측 중간결과 값을 획득하고 계산작업 및 활성화 작업을 수행한 다음 얻은 예측 중 간결과 값을 다음의 은닉층에 전달한다. 후속 층에서 동일한 작업을 수행하여 최종적으로 신경망의 출력층에서 출력 값을 얻게 된다. 순방향 처리 후 예측 값이라고 불리는 출력 값을 얻는다. 오차를 계산하기 위해 예측 값을 실제출력 값과 비교 하여 대응하는 오차 값을 획득한다. 역방향 전파는 미분학의 연쇄법칙을 사용하며, 연쇄법칙에서 먼저 신경망의 최종층의 가중치에 해당하는 오차 값의 도함수를 계산한다. 이들 도함수를 그래디언트라고 부르며, 이들 그래디 언트를 이용하여 신경망의 최후부터 두 번째 층의 그래디언트를 계산한다. 신경망 중 각 가중치에 대응하는 그 래디언트가 얻어질 때까지 이 과정을 반복한다. 마지막으로, 오차 값을 줄이는 목적을 달성하기 위해 신경망 중 각 가중치에서 대응하는 그래디언트를 감산하여 가중치를 한 번 업데이트한다. 신경망인 경우 미조정은 훈련된 신경망에 로드하는 것이며, 미조정과정은 훈련과정과 동일하게 두 단계로 나눌 수 있다. 첫 번째 단계는 신호의 순방향 처리이고, 두 번째 단계는 역방향 전파 그래디언트로서 훈련된 신경망 의 가중치를 업데이트한다. 훈련과 미조정의 차이점은 훈련은 랜덤으로 초기화된 신경망을 처리하여 신경망을 처음부터 훈련시키는 반면 미조정은 그렇지 않다는 것이다. 신경망의 훈련 또는 미조정과정에서 신경망이 신호의 1회 순방향 처리 및 대응하는 1회 오차의 역방향 전파과정 을 경과할 때마다 신경망 중 가중치가 그래디언트를 이용하여 1회 업데이트되며, 이를 1회 반복（iteration）이 라고 한다. 정밀도가 기대에 해당한 신경망을 얻기 위해서는 훈련과정에서 거대한 샘플 데이터 세트가 필요하다. 이 경우 샘플 데이터 세트을 컴퓨터에 한 번에 입력할 수 없다. 따라서 이 문제를 해결하기 위해 샘 플 데이터 세트를 복수의 블록으로 나누고 각 블록을 컴퓨터에 전달하며, 각 블록의 데이터 세트를 순방향 처리한 후 대응하여 신경망의 가중치를 1회 업데이트한다. 하나의 완전한 샘플 데이터 세트가 신경망의 1회 순방향 처리를 통과하고 대응하여 1회 업데이트한 가중치를 반환하는 과정을 1주기（epoch）라고 한다. 실제로는 신경 망에서 완전한 데이터 세트를 1회 전달하는 것만으로는 불충분하여 완전한 데이터 세트를 동일한 신경망에서 여 러 번 전달할 필요가 있다. 즉 최종적으로 정밀도가 기대에 해당한 신경망을 획득하려면 복수의 주기가 필요하 다. 신경망의 훈련 또는 미조정과정에서 일반적으로 속도가 빠를수록 더 좋고 정밀도가 높을수록 더 좋다. 신경망의 데이터는 부동 소수점 수와 같은 고정밀도 데이터 형식으로 표현되므로 훈련 또는 미조정과정에서 관련되는 데 이터는 모두 고정밀도 데이터 형식이며, 훈련된 신경망을 양자화한다. 양자화 대상이 신경망 전체인 가중치, 및 양자화 후의 가중치가 모두 8bit인 고정 소수점 수를 예로 들면 하나의 신경망에 항상 수백만 개의 연결이 있기 때문에 거의 모든 공간이 뉴런연결의 가중치에 의해 차지되어 있다. 또한 이들 가중치는 모두 서로 다른 부동 소수점 수이다. 각 층 가중치는 (-3.0, 3.0)과 같이 어느 특정구간의 정규분포 경향이 있다. 신경망 중 각 층의 가중치에 대응하는 최대 값과 최소 값을 보존하고, 각 부동 소수점 값을 8bit의 고정 소수점 수로 표현한다. 그 중, 최대 값과 최소 값 범위 내의 구간을 256개의 양자화 간격으로 선형적으로 나누고, 하나의 8bit 고정 소수 점 수로 각 양자화 간격을 표현한다. 예를 들어, (-3.0, 3.0) 구간 내에서 바이트 0이 -3.0을 나타내고, 바이트 255가 3.0을 나타낸다. 이하 유사하게 바이트 128이 0을 나타낸다. 고정밀도 데이터 형식으로 표현된 데이터는, 부동 소수점 수를 예로 들면, 컴퓨터 아키텍처에 의해 부동 소수점 수의 연산표현법칙 및 고정 소수점 수의 연산표현법칙에 근거하여 같은 길이의 고정 소수점 연산 및 부동 소수 점 연산을 하는 경우 부동 소수점 연산의 계산모드가 더 복잡하고, 보다 많은 논리 디바이스로 부동 소수점 연 산기를 구성할 필요가 있다는 것을 알 수 있다. 이렇게 부피적으로는, 부동 소수점 연산기의 부피는 고정 소수 점 연산기의 부피보다도 크다. 또한, 부동 소수점 연산기는 처리하는 데 보다 많은 리소스를 소비할 필요가 있 으므로 고정 소수점 연산과 부동 소수점 연산 사이의 소비전력 격차는 일반적으로 수십 배이다. 간단히 말하면, 부동 소수점 연산기가 점유하는 칩 면적과 소비전력은 고정 소수점 연산기에 비교하면 몇 배도 크다. 그러나 부동 소수점 연산은 대체할 수 없다. 우선, 고정 소수점 연산은 직관적이지만 고정된 소수점위치가 고정 자리수의 정수부와 소수부를 결정하며, 특히 큰 수 또는 특히 작은 수를 동시에 표현하는 데 도움이 되지 않아 오버플로가 발생할 가능성이 있다. 또한, 구체적으로 인공지능 프로세서 칩을 사용하여 훈련 또는 미조정하는 경우에는 부동 소수점 연산기가 일반 적으로 선호된다. 주로 감독학습의 신경망에서는 부동 소수점 연산만 훈련시의 얼마 안되는 증가 분을 기록하고 캡처할 수 있기 때문이다. 따라서 인공지능 프로세서 칩 면적과 소비전력을 증가시키지 않는 전제 아래에서 훈 련용 칩의 연산능력을 대폭으로 향상시킬 수 있는 방법은 현재 시급히 해결해야 할 문제이다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면, 낮은 비트폭으로 표현되는 고정 소수점 수를 이용 하여 훈련하는 경우, 8bit보다도 높은 고정 소수점 수를 사용하여 역방향 전파 그래디언트를 처리할 필요가 있 는 것이 실천적인 피드백으로부터 명확하지만 낮은 비트폭으로 표현되는 고정 소수점 수를 사용하여 훈련을 실 현하는 과정을 매우 복잡하게 한다. 어떻게 고정 소수점 연산기를 부동 소수점 연산기로 교체하여 고정 소수점 연산의 고속화를 달성하고 인공지능 프로세서 칩의 피크 연산력을 향상시킴과 동시에 연산에 필요한 부동 소수 점 연산의 정밀도를 충족시키는 것이 본 명세서에서 해결할 기술적 문제이다. 상술한 기술적 문제의 설명에 근거하면 신경망의 하나의 특성은 입력 노이즈에 대한 내성이 높은 것이다. 사진 속의 물체를 식별하는 것을 고려하면, 신경망은 주요한 노이즈를 무시하고, 중요한 유사성에 주목할 수 있다. 당해 기능은 신경망이 저정밀도 계산을 노이즈 소스로 사용하고, 보다 적은 정보를 수용하는 수치 형식이라도 정확한 예측결과를 생성할 수 있음을 의미한다. 저정밀도의 훈련 또는 미조정을 수행하려면 데이터의 오버플로 를 개선할 뿐만 아니라 목표구간범위 내 0부근의 데이터를 보다 좋게 표현할 수 있는 하나의 범용성이 있는 데 이터 표현을 찾아야 한다. 따라서 이 데이터 표현은 훈련 또는 미조정의 과정에 따라 조정할 수 있는 자기 적응 성이 필요하다. 상술한 설명에 따라 도2에 도시된 바와 같이, 본 발명에 따른 신경망의 양자화 파라미터 확정방법의 흐름도를 도시한다. 도2에 도시된 기술방안을 이용하여 확정하는 양자화 파라미터는 양자화 대상 데이터를 데이터 표현하 는 데 사용되며, 양자화 후의 고정 소수점 수를 확인한다. 상기 양자화 후의 고정 소수점 수는 신경망의 훈련, 미조정 또는 추론에 사용된다. 상기 방법은 다음과 같은 단계를 포함한다. 단계201）: 양자화 대상 데이터를 통계하여 각 종류의 양자화 대상 데이터의 통계결과를 확정한다. 여기에서 상 기 양자화 대상 데이터는 상기 신경망의 뉴런, 가중치 그래디언트, 바이어스 중 적어도 한 가지 데이터를 포함 한다. 전술한 바와 같이, 신경망을 훈련 또는 미조정하는 과정에서 신경망의 각 층은 뉴런, 가중치 그래디언트 및 바 이어스 이 네 가지 데이터를 포함한다. 추론과정에서 신경망의 각 층은 뉴런, 가중치 및 바이어스 이 세 가지데 이터를 포함한다. 이들 데이터는 모두 고정밀도 데이터 형식으로 표현되며, 본 명세서는 부동 소수점 수를 고정 밀도 데이터의 예로 하고 있다. 명확해야 할 것은 부동 소수점 수는 예로서 모든 상황이 아니라 일부 상황만 열"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "거할 뿐이며, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 기술방안의 본질을 이해한 뒤에 본 발명의 기술방안을 기반으로 다른 변형 또는 변환을 이룰 수 있다. 예를 들어, 고정밀도 데이터는 표현범위가 크고 표현하는 최소정밀도가 작은 높은 데이터 비트폭을 갖는 고정 소수점 수일 수 있으며, 본 기술방안을 사용 하여 모두 낮은 데이터 비트폭을 갖는 고정 소수점 수로 변환할 수 있다. 그러나, 그 실현된 기능 및 달성한 기 술적 효과가 본 발명과 유사하면 모두 본 발명의 보호범위에 속하는 것이다. 어떤 신경망구조이여도 신경망을 훈련 또는 미조정하는 과정에서 양자화 대상 데이터는 신경망의 뉴런, 가중치 그래디언트, 바이어스 중 적어도 한 가지 데이터를 포함하며, 추론과정에서 양자화 대상 데이터는 신경망의 뉴 런, 가중치, 바이어스 중 적어도 한 가지 데이터를 포함한다. 양자화 대상 데이터가 가중치인 경우를 예로 들면, 양자화 대상 데이터는 신경망 중 어느 한 층의 모든 가중치일 수도 있고, 신경망 중 어느 한 층의 부분 가중치일 수도 있다. 당해 층이 컨벌루션 층인 경우, 양자화 대상 데이터는 당해 컨벌루션 층에서 채널을 단위 로 하는 모든 가중치 또는 부분 가중치이고, 당해 채널은 당해 컨벌루션 층의 모든 채널 또는 부분 채널일 수도 있다. 여기에서, 컨벌루션 층만이 채널의 개념을 가지고, 컨벌루션 층에서 가중치만 층을 나누고 채널의 방식으 로 양자화된다는 점을 이해해야할 필요가 있다. 이하에서 양자화 대상 데이터가 신경망 중 목표층의 뉴런과 가중치 이 두 가지 데이터인 경우를 예로 들어, 본 기술방안을 자세히 설명한다. 본 단계에서 목표층에 있어서의 각 층의 뉴런과 가중치를 각각 통계하여 각 종류 의 양자화 대상 데이터의 최대 값 및 최소 값을 획득한다. 또한 각 종류의 양자화 대상 데이터의 절대치 최대 값을 획득할 수도 있다. 여기에서 목표층은 신경망에서 양자화해야 하는 층으로서 한 층일 수도 있고, 여러 층 일 수도 있다. 한 층을 단위로하여 각 종류의 양자화 대상 데이터의 절대치 최대 값은 각 종류의 양자화 대상 데이터 중 최대 값과 최소 값 방식을 통해 확인할 수 있다. 또한, 먼저 각 종류의 양자화 대상 데이터의 절대치 를 구하고, 모든 절대치를 구한 결과에 따라 각 종류의 양자화 대상 데이터의 절대치 최대 값을 획득할 수도 있 다. 실제 응용에서 각 종류의 양자화 대상 데이터 중 최대 값과 최소 값 방식에 따라 각 종류의 양자화 대상 데이터 의 절대치 최대 값을 획득하는 이유는 양자화할 때 정상적인 상황에서 목표층 중 각 층의 양자화 대상 데이터에 대응하는 최대 값과 최소 값을 보존하고 있었으므로 더 많은 리소스를 소비하여 양자화 대상 데이터에 대해 절 대치를 구할 필요가 없고, 보존한 양자화 대상 데이터에 대응하는 최대 값과 최소 값을 기반으로 절대치 최대 값을 직접 획득하면 되기 때문이다. 단계202）: 각 종류의 양자화 대상 데이터의 통계결과 및 데이터 비트폭을 이용하여 대응하는 양자화 파라미터 를 확정한다. 여기에서 상기 양자화 파라미터는 인공지능 프로세서가 신경망 연산과정 중의 데이터를 대응하는 양자화하기 위해 사용된다. 본 단계에서 양자화 파라미터는 다음과 같은 6 가지 상황으로 나눌 수 있다. 첫 번째 경우는 양자화 파라미터가 점 위치 파라미터 s인 것이다. 이 경우 다음과 같은 수학식 （1）을 이용하여 양자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. （1） 여기에서 s는 점 위치 파라미터이고, 는 데이터 가 양자화된 후의 n비트 바이너리 표현 값이며, 는 데이터 를 양자화하기 전의 부동 소수점 값이고, 는 반올림에 따른 정수연산이다. 설명할 필요가 있는 것은, 여기에서 와 같은 정수연산에만 국한되지 않고, 다른 정수연산방법을 사용할 수도 있다. 예를 들어, 정수 로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 사용하여 수학식 （1） 중의 를 바꾸어정수연산할 수 있다. 이 때, n비트 고정 소수점 수가 표현할 수 있는 부동 소수점 수의 최대 값 는 이면, n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최대 값은 이고, n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최소 값은 이다. 수 학식 （1）로부터 알 수 있는 바와 같이, 첫 번째 경우에 대응하는 양자화 파라미터를 사용하여 양자화 대상 데 이터를 양자화할 때 양자화 간격은 이며, 양자화 간격을 C로 표시한다. 를 양자화 대상 데이터의 수체 중 모든 부동 소수점 수의 절대치 최대 값이라고 가정하면, 는 Z를 포함해야 하며, Z는 보다 커야하므로 다음과 같은 수학식 （2）의 제약이 있다. （2） 따라서, 로 되며, , 를 얻게 된다. 수학식 （3）에 의해 데이터 가 양자화된 후의 n비트 바이너리 표현 값 를 역 양자화하여 역 양자화 데이터 를 획득한다. 여기에서, 상기 역 양자화 데이터 의 데이터 형식은 대응하는 양자화 전의 데이터 의 데이터 형식과 같으며 모두 부동 소수점 값이다. （3） 두 번째 경우는 양자화 파라미터가 제1 스케일 팩터 인 것이다. 이 경우 다음과 같은 수학식 （4）을 이용하여 양자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. （4） 여기에서, 는 제1 스케일 팩터이고, 는 데이터 가 양자화된 후의 n비트 바이너리 표현 값이며, 는 데이터 를 양자화하기 전의 부동 소수점 값이며, 는 반올림에 따른 정수연산이다. 설명할 필요가 있는 것은, 여기에서 와 같은 정수연산에만 국한되지 않고, 다른 정수연산방법을 사용할 수도 있다. 예를 들어, 정수 로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 사용하여 수학식 （4） 중의 를 바꾸어 정수연산할 수 있다. 수학식 （4）로부터 알 수 있는 바와 같이, 두 번째 경우에 대응하는 양자화 파라미터를 사용하여 양자화 대상 데이터를 양자화할 때 양자화 간격은 이며, 양자화 간격을 C로 표시한다. 제1 스케일 팩터 인 경우 다음과 같은 한 가지 상황이 있다. 즉 점 위치 파라미터 s가 고정의 기지 값이고 더 이상 변경되지 않는다. 라 하고, 가 고정 값이면, n비트 고정 소수점 수로 표현할 수 있는 부동 소수점 수의 최대 값 는 이다. 이 경우 최대 값 는 데이터 비트폭 n에 의해 확정된다. Z가 양자화 대상 데이터의 수체 중 모든 수의 절대치 최대 값이라고 가정하면, 이고, 이 때이다. n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최대 값은 이고, n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최소 값은 이다. 또 한 가지 상황은 엔지니어링 어플리케이션에서, 를 하나의 전체로 하여 제1 스케 일 팩터 로 볼 수 있다. 이 때, 독립적인 점 위치 파라미터 s가 없다고 볼 수 있다. 여기에서 는 제2 스케일 팩터이다. Z가 양자화 대상 데이터의 수체 중 모든 수의 절대치 최대 값이라고 가정하면, 이고, 이 때 이다. n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최대 값은 이고, n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최소 값은 이다. 수학식 （5）에 따라 데이터 가 양자화된 후의 n비트 바이너리 표현 값 에 대해 역 양자화를 수행하여 역 양자화 데이터 를 획득한다. 여기에서 상기 역 양자화 데이터 의 데이터 형식은 대응하는 양자화하기 전의 데 이터 의 데이터 형식과 같으며, 모두 부동 소수점 값이다. （5） 세 번째 경우는 양자화 파라미터가 점 위치 파라미터 s와 제2 스케일 팩터 인 것이다. 이 경우 다음과 같은 수 학식（6）을 이용하여 양자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. （6） 여기에서, s는 점 위치 파라미터이고, 는 제2 스케일 팩터이며, 이다. 는 데이터 를 양자화한 후의 n비트 바이너리 표현 값이고, 는 데이터 를 양자화하기 전의 부동 소수점 값이며, 는 반올림에 따른 정수연산이다. 설명할 필요가 있는 것은, 여기에서 와 같은 정수연산에만 국한되지 않고, 다른 정수 연산방법을 사용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 사용하여 수학식 （6） 중의 를 바꾸어 정수연산할 수 있다. n비트 고정 소수점 수로 표현할 수 있 는 양자화 대상 데이터의 수체 중 최대 값 는 이다. 수학식 （6）으로부터 알 수 있는 바와 같이, 세 번째 경우에 대응하는 양자화 파라미터를 사용하여 양자화 대상 데이터를 양자화할 때 양자화 간격은 이며, 양자화 간격을 C로 표시한다. Z를 양자화 대상 데이터의 수체 중 모든 수의 절대치 최대 값이라고 가정하면, 이 때 수학식 （2）에 따라 다음 과 같이 얻을 수 있다. , 즉 ,"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "인 경우, 수학식 （2）에 따라 Z는 손실없이 정확하게 표현할 수 있다. 일 때 수학식 （6） 은 수학식 （1）과 같으며 이다. n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최대 값은 이고, n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이 터의 수체 중 최소 값은 이다. 수학식 （7）에 의해 데이터 가 양자화된 후의 n비트 바이너리 표현 값 를 역 양자화하여 역 양자화 데이터 를 획득한다. 여기에서, 상기 역 양자화 데이터 의 데이터 형식은 대응하는 양자화하기 전의 데이터 의 데이 터 형식과 같으며 모두 부동 소수점 값이다. （7） 도3에 도시된 바와 같이, 대칭되는 고정 소수점 수 표현모식도이다. 도3에 도시된 양자화 대상 데이터의 수체는 \"0\"을 대칭중심으로 분포되어 있다. 는 양자화 대상 데이터의 수체 중 모든 부동 소수점 수의 절대치 최대 값 이고, 도3에서 는 n비트 고정 소수점 수가 표현할 수 있는 부동 소수점 수의 최대 값이며, 부동 소수점 수 를 고정 소수점 수로 전환하면 이다. 오버플로를 방지하려면 는 를 포함할 필요가 있다. 실제 로는 신경망 연산과정 중의 부동 소수점 데이터는 어느 특정구간의 정규분포 경향이 있으나 반드시 \"0\"을 대칭 중심으로 하는 분포를 만족시키는 것이 아니고, 이 때 고정 소수점 수로 표현하면 오버플로가 발생하기 쉽다. 이러한 상황을 개선하기 위해 도4에 도시된 바와 같이 양자화 파라미터에 오프셋이 도입되어 있다. 도4에서 양 자화 대상 데이터의 수체는 \"0\"을 대칭중심으로 하는 분포가 아니며, 는 양자화 대상 데이터의 수체 중 모 든 부동 소수점 수의 최소 값이고, 는 양자화 대상 데이터의 수체 중 모든 부동 소수점 수의 최대 값이다. P는 ~ 사이의 중심점이고, 양자화 대상 데이터의 수체를 전체적으로 오프셋시켜 평행이동 후의 양자화 대상 데이터의 수체가 \"0\"을 대칭중심으로 하는 분포로 되게 한다. 평행이동 후의 양자화 대상 데이터의 수체 중 절대치 최대 값은 이다. 도4에서 알 수 있는 바와 같이, 오프셋은 \"0\"점으로부터 \"P\"까지 사이의 수평거리 이고, 당해 거리를 오프셋 라고 부른다. 여기에서 , 이다. 상술한 오프셋 에 관한 설명에 따라, 네 번째로 되는 양자화 파라미터의 상황이 나타난다. 네 번째 경우는 양 자화 파라미터가 점 위치 파라미터와 오프셋을 포함하는 것이다. 이 경우 다음과 같은 수학식 （8）을 이용하여 양자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. （8） 여기에서, s는 점 위치 파라미터이고, 는 오프셋이며, 이고, 는 데이터 가 양자화된 후 의 n비트 바이너리 표현 값이며, 는 데이터 를 양자화하기 전의 부동 소수점 값이고,"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "는 반올림 에 따른 정수연산이다. 설명할 필요가 있는 것은, 여기에서 와 같은 정수연산에만 국한되지 않고, 다른 정수연산방법을 사용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연 산을 사용하여 수학식 （8） 중의 를 바꾸어 정수연산할 수 있다. 이 때, n비트 고정 소수점 수로 표현할 수 있는 부동 소수점 수의 최대 값 가 이면, n비트 고정 소수점 수가 표현할 수 있는 양자 화 대상 데이터의 수체 중 최대 값은 이고, n비트 고정 소수점 수가 표현할 수 있는 양자화 대 상 데이터의 수체 중 최소 값은 이다. 수학식 （8）로부터 알 수 있는 바와 같이, 네 번째 경우에 대응하는 양자화 파라미터를 사용하여 양자화 대상 데이터를 양자화할 때 양자화 간격은 이며, 양자화 간 격을 C로 표시한다. 를 양자화 대상 데이터의 수체 중 모든 부동 소수점 수의 절대치 최대 값이라고 가정하고, 이 면, 는 Z를 포함해야 하며, Z는 보다 커야 한다. 수학식 （2）에 따라 를 획득하며, 진일보로 , 를 얻는다. 수학식 （9）에 의해 데이터 가 양자화된 후의 n비트 바이너리 표현 값 를 역 양자화하여 역 양자화 데이터 를 획득한다. 여기에서, 상기 역 양자화 데이터 의 데이터 형식은 대응하는 양자화하기 전의 데이터 의 데 이터 형식과 같으며 모두 부동 소수점 값이다. （9） 상술한 오프셋 에 관한 설명에 따라, 다섯 버째로 되는 양자화 파라미터의 상황이 나타난다. 다섯 번째 경우 는 양자화 파라미터가 제1 스케일 팩터 와 오프셋 를 포함하는 것이다. 이 경우 다음과 같은 수학식 （10） 을 이용하여 양자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. （10） 여기에서, 는 제1 스케일 팩터이고, 는 오프셋이며, 는 데이터 가 양자화된 후의 n비트 바이너리 표현 값이며, 는 데이터 를 양자화하기 전의 부동 소수점 값이고,"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "는 반올림에 따른 정수연산이다. 설명할 필요가 있는 것은, 여기에서 와 같은 정수연산에만 국한되지 않고, 다른 정수연산방법을 사용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 사용하여 수학식 （ 10） 중의 를 바꾸어 정수연산할 수 있다. 이 때 다음과 같은 한 가지 상황이 있다. 즉 점 위치 파라미터 s가 고정의 기지 값이고 더 이상 변경되지 않으며, 라 하고, 가 고정 값이다. 따라서, n비트 고정 소 수점 수로 표현할 수 있는 부동 소수점 수의 최대 값 는 이다. 이 경우, 최대 값 는 데이터 비트폭 n에 의해 확정된다. 가 양자화 대상 데이터의 수체 중 모든 수의 절대치 최대 값이라고 가정하 면, 이고, 이 때 이다. n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터 의 수체 중 최대 값은 이고, n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최소 값은 이다. 또 한 가지 상황은 엔지니어링 어플리케이션에서, 를 하나의 전체로 하여 제1 스케일 팩터 로 본다. 이 때, 독립적인 점 위치 파라미터 s가 없다고 볼 수 있다. 여기에서 는 제2 스케일 팩터이다. Z가 양자화 대상 데이터의 수체 중 모든 수의 절대치 최대 값이라고 가정하면, 이고, 이 때 이다. n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최대 값은 이고, n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수 체 중 최소 값은 이다. 수학식 （10）으로부터 알 수 있는 바와 같이, 다섯 번째 경우에 대응하는 양자화 파라미터를 사용하여 양자화 대상 데이터를 양자화할 때 양자화 간격은 이며, 양자화 간격을 C로 표시한다. 수학식 （11）에 따라 데이터 가 양자화된 후의 n비트 바이너리 표현 값 를 역 양자화하여 역 양자화 데이 터 를 획득한다. 여기에서 상기 역 양자화 데이터 의 데이터 형식은 대응하는 양자화하기 전의 데이터 의 데이터 형식과 같으며, 모두 부동 소수점 값이다. （11） 상술한 오프셋 에 관한 설명에 따라, 여섯 번째로 되는 양자화 파라미터의 상황이 나타난다. 여섯 번째 경우 는 양자화 파라미터가 점 위치 파라미터, 제2 스케일 팩터 및 오프셋 를 포함하는 것이다. 이 경우 다음과 같은 수학식 （12）를 이용하여 양자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. （12） 여기에서, s는 점 위치 파라미터이고, 오프셋은 이며, 가 제2 스케일 팩터이고, ;"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이다. 는 데이터 가 양자화된 후의 n비트 바이너리 표현 값이고, 는 데이터 를 양자화하기 전의 부동 소 수점 값이며, 는 반올림에 따른 정수연산이다. 설명할 필요가 있는 것은, 여기에서 와 같은 정수연 산에만 국한되지 않고, 다른 정수연산방법을 사용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내림, 0을 향 해 버림 또는 올림 등 정수연산을 사용하여 수학식 （12） 중의 를 바꾸어 정수연산할 수 있다. n비트 고 정 소수점 수로 표현할 수 있는 양자화 대상 데이터의 수체 중 최대 값 는 이다. 수학식 （ 12）로부터 알 수 있는 바와 같이, 여섯 번째 경우에 대응하는 양자화 파라미터를 사용하여 양자화 대상 데이터 를 양자화할 때 양자화 간격은 이며, 양자화 간격을 C로 표시한다. Z를 양자화 대상 데이터의 수체 중 모든 수의 절대치 최대 값이라고 가정한다. 이 때 수학식 （2）에 따라 다음 과 같이 얻을 수 있다. , 즉 ,"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "인 경우, 수학식 （2）에 따라 Z는 손실없이 정확하게 표현할 수 있다. 일 때 이다. n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최대 값은 이고, n비트 고정 소수점 수가 표현할 수 있는 양자화 대상 데이터의 수체 중 최소 값은 이다. 수학식 （13）에 의해 데이터 가 양자화된 후의 n비트 바이너리 표현 값 를 역 양자화하여 역 양자화 데이 터 를 획득한다. 여기에서, 상기 역 양자화 데이터 의 데이터 형식은 대응하는 양자화 전의 데이터 의 데이 터 형식과 같으며, 모두 부동 소수점 값이다. （13） 이상에서 6 가지 양자화 파라미터의 확정과정을 상세히 설하였으나 실시예의 설명일 뿐이다. 양자화 파라미터의 종류는 상이한 실시예에서 상기 설명과 다를 수 있다. 수학식 （1）~ 수학식 （13）으로부터 알 수 있는 바와 같이, 점 위치 파라미터와 스케일 팩터는 모두 데이터 비트폭과 관련된다. 상이한 데이터 비트폭에 의해 점 위 치 파라미터와 스케일 팩터가 다르게 되고, 따라서 양자화 정밀도에 영향을 준다. 훈련 또는 미조정과정에서, 특정 반복（iterations） 회수범위 내에서 동일한 데이터 비트폭을 사용하여 양자화하면 신경망 연산의 전체 정 밀도에 별로 영향을 주지 않는다. 특정 반복회수를 넘고, 역시 동일한 데이터 비트폭을 사용하여 양자화하면 훈련 또는 미조정의 정밀도 요건을 충족시킬 수 없다. 이를 위해서는 훈련 또는 미조정의 과정에 따라 데이터 비 트폭 n을 조정할 필요가 있다. 간단히 말하면, 인위적으로 데이터 비트폭 n을 설정할 수 있다. 서로 다른 반복 회수범위 내에서 미리 설정한 대응하는 데이터 비트폭 n을 호출하여 사용한다. 그러나, 위에서 언급한 것과 같 이, 낮은 비트폭으로 표현된 고정 소수점 수를 사용하여 훈련을 실현하는 과정은 대단히 복잡하다. 이러한 인위 적으로 데이터 비트폭을 미리 설정하는 조정방식은 기본적으로 실제 응용의 요구사항을 충족하지 않는다. 본 기술방안에서는, 양자화 오차 에 근거하여 데이터 비트폭 n을 조정한다. 더 자세하게는, 양자화 오차 를 한계 값과 비교하여 비교결과를 획득한다. 여기에서, 한계 값은 제1 한계 값과 제2 한계 값을 포함하며, 제1 한계 값은 제2 한계 값보다도 크고, 비교결과에는 다음과 같은 세 가지 상황이 있다. 첫 번째 경 우는 양자화 오차 가 상기 제1 한계 값 이상이다. 이 경우 상기 데이터 비트폭을 증가한다. 두 번째 경우 는 양자화 오차 가 상기 제2 한계 값 이하이다. 이 경우 상기 데이터 비트폭을 감소한다. 세 번째 경우는 양자화 오차 가 상기 제1 한계 값과 상기 제2 한계 값 사이에 있다. 이 경우 상기 데이터 비트폭은 변경되 지 않는다. 실제 응용에서 제1 한계 값과 제2 한계 값은 경험 값일 수도 있고, 가변 하이퍼 파라미터일 수도 있 다. 통상의 하이퍼 파라미터의 최적화방법은 모두 제1 한계 값과 제2 한계 값에 적합하며, 여기에서는 하이퍼 파라미터의 최적화방안에 대해 다시 언급하지 않는다. 또한, 데이터 비트폭을 고정된 비트 스텝에 따라 조정할 수 있으며, 양자화 오차와 오차 한계 값과의 차이의 다 른 점에 근거하여 가변 조정 스텝에 따라 데이터 비트폭을 조정할 수도 있으며, 최종적으로는 신경망 연산과정 의 실제 필요에 따라 데이터 비트폭을 보다 길게 또는 보다 짧게 조정하는 점을 강조할 필요가 있다. 예를 들어, 현재 컨벌루션 층의 데이터 비트폭 n가 16이며, 양자화 오차 에 따라 데이터 비트폭 n을 12로 조정 한다. 즉 실제 응용에서 데이터 비트폭 n은 16의 값이 아니라 12의 값을 취하는 것으로 신경망 연산과정에서의 정밀도 요구사항을 충족시킬 수 있으며, 이를 통해 정밀도 허용범위 내에서 고정 소수점 연산속도를 크게 향상 할 수 있으며, 따라서 인공지능 프로세서 칩의 리소스 활용율이 향상할 수 있다. 양자화 오차 인 경우, 양자화 후의 데이터와 대응하는 양자화 전의 데이터에 근거하여 양자화 오차를 확정 한다. 실제 응용에는 세 가지 양자화 오차 확정방식이 있으며, 모두 본 기술방안에 적용할 수 있다. 첫 번째 방 식은 양자화 간격, 양자화 후 데이터의 개수 및 대응하는 양자화 전의 데이터에 근거하여 수학식 （14）에 따라 양자화 오차를 확정한다. （14） 여기에서, 는 양자화할 때 대응하는 양자화 간격이고, 은 양자화한 후 획득한 양자화 데이터의 개수이며, 는 양자화하려는 대응하는 부동 소수점 값이다. 여기에서, 는 양자화 대상 데이터 집합 중 데이터의 아래첨 자이다. 두 번째 방식은 양자화한 후의 데이터 및 대응하는 역 양자화 데이터에 근거하여 수학식 （15）에 따라 양자화 오차 를 확정한다. （15） 여기에서, 는 양자화하려는 대응하는 부동 소수점 값이다. 여기에서, 는 양자화 대상 데이터 집합 중 데이터 의 아래첨자이다. 는 부동 소수점 값에 대응하는 역 양자화 데이터이다. 세 번째 방식은 양자화한 후의 데이터 및 대응하는 역 양자화 데이터에 근거하여 수학식 （16）에 따라 양자화 오차 를 확정한다. （16） 여기에서, 는 양자화하려는 대응하는 부동 소수점 값이다. 여기에서, 는 양자화 대상 데이터 집합 중 데이터 의 아래첨자이다. 는 부동 소수점 값에 대응하는 역 양자화 데이터이다. 또한, 상술한 양자화 오차 를 획득하는 방식은 예로서 모든 상황이 아니라 일부 상황만 열거할 뿐이며, 본"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 발명 기술방안의 본질을 이해한 뒤에 본 발명의 기술 방안을 기반으로 다른 변형 또는 변환을 이룰 수 있으며, 양자화한 후의 데이터와 대응하는 양자화하기 전의 데 이터에 근거하여 양자화 오차를 확정하는 것을 지원하는 모든 변형 수학식은, 그 실현하는 기능 및 달성하는 기 술적 효과가 본 발명과 유사하면 모두 본 발명의 보호범위에 속하는 것이다. 데이터 비트폭에 대하여, 도5a는 훈련과정에서 신경망의 가중치 데이터 변동폭의 제1 그래프를 도시한다. 도5b 는 훈련과정에서 신경망의 가중치 데이터 변동폭의 제2 그래프를 도시한다. 도5a 및 도5b에서 횡축은 반복회수 를 나타내고, 세로축은 가중치 로그의 최대 값을 나타낸다. 도5a에 도시된 가중치 데이터의 변동폭 곡선은 신경 망의 임의의 컨벌루션 층의 동일한 주기(epoch) 내 상이한 반복에 대응하는 가중치 데이터의 변동상황을 나타내 고 있다. 도5b에서 conv0층은 가중치 데이터 변동폭 곡선 A에 대응하고, conv1층은 가중치 데이터 변동폭 곡선 B에 대응하며, conv2층은 가중치 데이터 변동폭 곡선 C에 대응하고, conv3층은 가중치 데이터 변동폭 곡선 D에 대응하며, conv4층은 가중치 데이터 변동폭 곡선 e에 대응한다. 도5a 및 도5b로부터 알 수 있는 바와 같이, 동 일한 주기(epoch) 내에서 훈련 초기 반복마다 가중치가 크게 변화한다. 훈련의 중, 후기에서 반복마다 가중치의 변화 폭은 별로 크지 않다. 이 경우 훈련의 중, 후기에서 가중치 데이터는 각 반복의 전후에서 변화 폭이 크지 않으므로 각 반복에서 대응하는 층의 가중치 데이터 사이는 특정 반복간격 내에서 유사성을 갖는다. 신경망 훈 련과정에서 각 층에 관련된 데이터를 양자화하는 경우 전회 반복할 때 대응하는 층을 양자화할 때 사용한 데이 터 비트폭을 채용할 수 있다. 그러나, 훈련 초기에 가중치 데이터는 각 반복의 전후에 변화 폭이 비교적 크다. 양자화에 필요한 부동 소수점 연산의 정밀도를 충족시키기 위해 훈련 초기의 매회 반복에서는 전회 반복에서 대 응하는 층을 양자화할 때 사용한 데이터 비트폭을 이용하여 현재 반복에서 대응하는 층의 가중치 데이터를 양자 화하거나 현재 층에 미리 설정된 데이터 비트폭 n을 기반으로 현재 층의 가중치 데이터를 양자화하여 양자화된 후의 고정 소수점 수를 획득한다. 양자화한 후의 가중치 데이터와 대응하는 양자화하기 전의 가중치 데이터에 근거하여 양자화 오차 를 확정하며, 양자화 오차 와 한계 값의 비교결과에 따라 전회 반복에서 대응 하는 층을 양자화할 때 사용한 데이터 비트폭 n 또는 현재 층에 미리 설정한 데이터 비트폭 n을 조정하고, 조정 한 후의 데이터 비트폭을 이번 반복에서 대응하는 층의 가중치 데이터의 양자화에 적용한다. 또한, 훈련 또는 미조정과정에서 신경망의 각 층 사이의 가중치 데이터는 서로 독립적이고 유사성이 없다. 가중치 데이터가 유사 성을 가지지 않기 때문에 각 층 사이의 뉴런 데이터도 서로 독립적이며 유사성이 없다. 따라서, 신경망의 훈련 또는 미조정과정에서 신경망의 매회 반복에서 각 층의 데이터 비트폭은 대응하는 신경망 층에만 적용된다. 이상은 가중치 데이터를 예로 하며, 신경망 훈련 또는 미조정과정에서 뉴런 데이터와 그래디언트 데이터가 각각 대응하는 데이터 비트폭에 대해서도 같으므로 여기에서는 다시 언급하지 않는다. 신경망 추론과정에서 신경망의 각 층 사이의 가중치 데이터는 서로 독립적이며 유사성이 업다. 가중치 데이터가 유사성을 가지지 않아 각 층 사이의 뉴런 데이터도 서로 독립적으로 되며 유사성이 없다. 따라서, 신경망 추론 과정에서 신경망 각 층의 데이터 비트폭을 대응하는 층에 적용한다. 실제 응용에서, 추론과정에서 매번의 입력 뉴런 데이터가 다르거나 유사하지 않을 가능성이 매우 높다. 또한, 신경망의 각 층 사이의 가중치 데이터가 서 로 독립적이기 때문에 신경망 은닉층에서의 각 층의 입력 뉴런 데이터가 유사하지 않다. 양자화하는 경우, 위 층의 입력 뉴런 데이터가 사용하는 데이터 비트폭은 현재 층의 입력 뉴런 데이터에 적합하지 않다. 이를 바탕으 로 양자화에 필요한 부동 소수점 연산의 정밀도를 충족시키기 위해 추론시에 위 층의 입력 뉴런 데이터를 양자 화할 때 채용한 데이터 비트폭을 이용하여 현재 층의 입력 뉴런 데이터를 양자화하거나 현재 층에 미리 설정한 데이터 비트폭 n에 근거하여 현재 층의 입력 뉴런 데이터를 양자화하여 양자화된 후의 고정 소수점 수를 획득한 다. 양자화하기 전의 입력 뉴런 데이터와 대응하는 양자화된 후의 입력 뉴런 데이터에 따라 양자화 오차 를 확정하며, 양자화 오차 와 한계 값의 비교결과에 따라 위 층의 입력 뉴런 데이터를 양자화할 때 채용한 데이터 비트폭 n 또는 현재 층에 미리 설정한 데이터 비트폭 n을 조정하고, 조정 후의 데이터 비트폭을 현재 층의 입력 뉴런 데이터의 양자화에 적용한다. 가중치 데이터에 대응하는 데이터 비트폭도 마찬가지기 때문에 여기 에서 다시 언급하지 않는다. 양자화 파라미터에 대해서는, 도5a로부터 알 수 있는 바와 같이, 동일한 주기(epoch) 내에서 훈련 초기 매번 반 복의 가중치 변화 폭이 비교적 크다. 훈련의 중, 후기에서 매회 반복 전후의 가중치 데이터 변화 폭이 별로 크 지 않아 매번 반복의 대응하는 층의 가중치 데이터 사이는 일정한 반복간격 내에서 유사성을 가지므로 양자화할 때 현재 반복의 각 층의 데이터는 전회 반복의 대응하는 층의 대응 데이터의 양자화 파라미터를 계속 사용할 수 있으며, 훈련의 중, 후기에서 번 마다 다시 양자화 파라미터를 확인할 필요가 없으며, 훈련 초기의 각 반복의 각 층에서 양자화 파라미터를 확인하는 것만으로 신경망 연산에 필요한 부동 소수점 연산의 정밀도를 충족할 수 있으며, 양자화할 때의 효율을 대폭으로 향상시킬 수 있다. 또한, 훈련 또는 미조정과정에서, 신경망의 각 층 사이의 가중치 데이터는 서로 독립적이고 유사성을 가지지 않는다. 가중치 데이터가 유사성을 가지지 않으므로 각 층 사이의 뉴런 데이터도 서로 독립적이며, 유사성을 가지지 않는다. 따라서, 신경망 훈련 또는 미조정과정 에서, 신경망의 매회 반복 내 각 층의 양자화 파라미터는 대응하는 층의 대응 양자화 대상 데이터에 적용된다. 이상은 가중치 데이터를 예로 하며, 신경망 훈련 또는 미조정과정에서 뉴런 데이터와 그래디언트 데이터가 각각 대응하는 양자화 파라미터에 대해서도 마찬가지기 때문에 여기에서 다시 언급하지 않는다. 신경망 추론과정에서 신경망의 각 층 사이의 가중치 데이터는 서로 독립적이고 유사성을 가지지 않는다. 가중치 데이터가 유사성을 가지지 않으므로 각 층 사이의 뉴런 데이터도 서로 독립적이고 유사성을 가지지 않는다. 따 라서, 신경망 추론과정에서 신경망의 각 층의 양자화 파라미터는 대응하는 층의 양자화 대상 데이터에 적용된다. 예를 들어, 신경망의 현재 층이 컨벌루션 층인 경우, 컨벌루션 층의 양자화 대상 데이터에 근거하여 도2에 도시된 기술방안에 따라 현재 컨벌루션 층의 양자화 대상 데이터의 양자화 파라미터를 획득하며, 당해 양 자화 파라미터는 현재의 컨벌루션 층에만 적용되며, 당해 신경망의 다른 층에 적용할 수 없다. 다른 층이 컨벌 루션 층인 경우에도 적용할 수 없다. 이상과 같이, 데이터 비트폭과 양자화 파라미터의 연장사용대책은 데이터 사이의 유사성에 근거하여 확정되며, 데이터 사이에 유사성이 있으면 데이터 비트폭과 양자화 파라미터는 연장하여 사용할 수 있고, 데이터 사이에 유사성이 없으면 데이터 비트폭 또는 양자화 파라미터를 조정할 필요가 있다. 데이터 사이 유사성의 척도는 일 반적으로 KL 분산도로 가늠하며, 이하 수학식 （17）로 가늠할 수도 있다. 또한 （17） 일부 실시예에서, 데이터 A와 데이터 B가 수학식 （17）을 충족하면 데이터 A와 데이터 B 사이에 유사성이 있다 고 판정된다. 설명할 필요가 있는 것은, 상술한 양자화 오차의 확인방법, 데이터 비트폭의 조정방법, 데이터 비트폭 및 양자 화 파라미터의 연장사용대책에 관하여, 모두 예로서 모든 상황이 아니라 일부 상황만 열거할 뿐이며, 예를 들어, 상술한 양자화 오차의 확인방법, 데이터 비트폭의 조정방법, 데이터 비트폭 및 양자화 파라미터의 연장사 용대책은 모두 신경망의 미조정과정에 적용된다. 그리고, 데이터 사이의 유사성의 척도에 관하여, 상기에서는 KL 분산도 및 수학식 （17）과 같은 유사성의 척도방법을 열거하였지만, 예로서 모든 상황이 아니라 일부 상황 만 열거할 뿐이다. 예를 들어, 히스토그램 매칭법, 행렬 분해법, 특징점에 근거하는 이미지유사도 계산법, 근접"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "도 척도표준법 등이 있다. 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 발명 기술방안의 본질을 이해한 뒤에 본 발명의 기술방안을 기반으로 다른 변형 또는 변환을 이룰 수 있으며, 그러나, 그 실현된 기능 및 달성한 기술적 효과가 본 발명과 유사하면 모두 본 발명의 보호범위에 속하는 것이다. 이상과 같이, 훈련의 중, 후기에서, 매번 반복의 전후에서 가중치 데이터 변화 폭이 별로 크지 않으므로, 매번 반복의 대응하는 층의 가중치 데이터 사이는 일정한 반복간격 내에서 유사성을 가지지 않으며, 훈련 또는 미조 정에서 본 기술방안이 보다 좋은 범용성을 가지고, 인공지능 프로세서 칩의 리소스의 합리적인 어플리케이션을 달성하기 위해서는, 당해 반복간격 범위 내에서 매회 반복의 대응하는 층의 데이터 비트폭 n을 변하지 않도록 유지하고, 당해 반복간격을 넘으면 데이터 비트폭 n을 변화시켜 번 마다 데이터 비트폭 n을 조정할 것인가 아닌 가를 확정할 필요가 없는 반복간격을 확정하기 위한 대책이 필요하다. 마찬가지로, 양자화 파라미터도 같아서 인공지능 프로세서 칩의 피크 연산력을 향상시킴과 동시에 양자화에 필요한 부동 소수점 연산의 정밀도를 충족 시킬 수 있다. 도6에 도시된 바와 같이, 목표반복간격을 확정하는 방법의 제1 흐름도이다. 도6에 도시된 기술방안에서, 목표반 복간격은 적어도 1회의 가중치 업데이트 반복을 포함하며, 동일한 목표반복간격 내 양자화 과정에서 동일한 상 기 데이터 비트폭을 채용한다. 상기 목표반복간격의 확정단계는 다음과 같은 단계를 포함한다. 단계601）: 사전판정시점에서, 가중치 반복과정에서 상기 양자화 대상 데이터에 대응하는 점 위치 파라미터의 변화추세 값을 확정한다. 여기에서, 상기 사전판정시점은 상기 데이터 비트폭을 조정할 필요가 있는지 여부를 판정하기 위한 시점이며, 상기 사전판정시점은 가중치 업데이트 반복이 완료될 때의 시점에 대응한다. 본 단계에서, 수학식 （18）에 따라 상기 점 위치 파라미터의 변화추세 값은 현재 사전판정시점에 대응하는 가 중치 반복과정에서의 점 위치 파라미터의 이동평균 값, 전회 사전판정시점에 대응하는 가중치 반복과정에서의 점 위치 파라미터의 이동평균 값에 근거하여 확정되거나, 현재 사전판정시점에 대응하는 가중치 반복과정에서의 점 위치 파라미터, 전회 사전판정시점에 대응하는 가중치 반복과정에서의 점 위치 파라미터의 이동평균 값에 근 거하여 확정된다. 수학식 18의 표달식은 다음과 같다. （18） 수학식 18에서, 은 점 위치 파라미터 가 훈련 및 반복에 따라 증가되는 이동평균 값이다. 여기에서, 는 t 번째의 사전판정시점에 대응하는 점 위치 파라미터 가 훈련 및 반복에 따라 증가되는 이동평균 값이고, 수학 식 （19）에 따라 를 획득한다. 는 t 번째의 사전판정시점에 대응하는 점 위치 파라미터 이다. 은 t-1 번째의 사전판정시점에 대응하는 점 위치 파라미터 의 이동평균 값이고, 는 하이퍼 파라미터이다. 는 점 위치 파라미터 의 변화추세를 가늠하며, 점 위치 파라미터 의 변화도 현재 양자화 대상 데이 터 중 데이터 최대 값 의 변화상황에 다르게 구현된다. 가 크면 클수록 수치범위가 크게 변화된다 는 것을 설명하며, 간격이 보다 짧은 업데이트 빈도가 필요하다. 즉 목표반복간격이 더 작을 필요가 있다. （19） 단계602）: 상기 점 위치 파라미터의 변화추세 값에 근거하여 대응하는 상기 목표반복간격을 확정한다. 본 기술방안에서, 수학식 （20）에 따라 목표반복간격을 확정한다. 목표반복간격에 대해서는, 동일한 목표반복 간격 내 양자화 과정에서 동일한 상기 데이터 비트폭을 채용하며, 상이한 목표반복간격 내 양자화 과정에서 채 용한 데이터 비트폭은 같을 수도 다를 수도 있다. （20） 수학식 （20）에서 는 목표반복간격이다. 는 점 위치 파라미터의 변화추세 값이다. , 는 경험 값 이고, 가변 하이퍼 파라미터일 수도 있다. 통상의 하이퍼 파라미터의 최적화방법은 , 에도 적용되며, 여기에 서는 하이퍼 파라미터의 최적화방안에 대하여 다시 언급하지 않는다. 본 기술방안인 경우, 사전판정시점은 목표반복간격에 따라 확정되는 제1 사전판정시점을 포함한다. 구체적으로 는, 훈련 또는 미조정과정에서의 t 번째의 사전판정시점에서, 전회 반복에서 대응하는 층을 양자화할 때 채용한 데이터 비트폭을 이용하여 현재 반복의 대응하는 층의 가중치 데이터를 양자화하여, 양자화한 후의 고정 소수점 수를 획득하며, 양자화하기 전의 가중치 데이터와 대응하는 양자화하기 전의 가중치 데이터에 근거하여, 양자화 오차 를 확정한다. 양자화 오차 를 제1 한계 값 및 제2 한계 값과 각각 비교하며, 비교결과를 이용 하여 전회 반복에서 대응하는 층을 양자화할 때 채용한 데이터 비트폭를 조정할지 여부를 확정한다. t 번째의 제1 사전판정시점이 제100회 반복에 대응되고, 제99회 반복에서 사용하는 데이터 비트폭이 n1이라고 가정한다. 제100회 반복에서, 데이터 비트폭 n1에 근거하여 양자화 오차 를 확인하고, 양자화 오차 를 제1 한 계 값, 제2 한계 값과 비교하여 비교결과를 획득한다. 비교결과에 따라 데이터 비트폭 n1을 변경할 필요가 없다 는 것을 확인하고, 수학식 （20）을 이용하여 목표반복간격이 8회 반복임을 확인하였으며, 제100회 반복이 현재 목표반복간격 내의 처음 반복이면, 제100회 반복~제107회 반복을 현재 목표반복간격으로 하고, 제100회 반복이이전 목표반복간격의 최후의 반복인 경우, 제101회 반복~제108회 반복을 현재 목표반복간격으로 한다. 현재 목 표반복간격 내에서 양자화할 때 번 마다 여전히 이전 목표반복간격에서 사용된 데이터 비트폭 n1을 계속 사용한 다. 이 경우, 상이한 목표반복간격 사이 양자화할 때 사용한 데이터 비트폭은 동일할 수 있다. 제100회 반복~제 107회 반복을 현재의 목표반복간격으로 하면, 다음 목표반복간격 내의 제108회 반복을 t+1 번째의 제1 사전판정 시점으로 하며, 제101회 반복~제108회 반복을 현재의 목표반복간격으로 하면, 현재의 목표반복간격 내의 제108 회 반복을 t+1 번째의 제1 사전판정시점으로 한다. t+1 번째의 제1 사전판정시점에서, 데이터 비트폭 n1에 근거 하여 양자화 오차 를 확인하고, 양자화 오차 를 제1 한계 값, 제2 한계 값과 비교하여 비교결과를 획득한다. 비교결과에 따라 데이터 비트폭 n1을 n2에 변경할 필요가 있다는 것을 확정하고 수학식 （20）을 이용 하여 목표반복간격이 55회 반복임을 확인하였다. 따라서 제108회 반복~제163회 반복 또는 제109회 반복~제163회 반복을 목표반복간격으로 하며, 당해 목표반복간격 내에서 양자화할 때 각 반복에서 데이터 비트폭 n2을 사용한 다. 이 경우 상이한 목표반복간격 사이 양자화할 때 사용한 데이터 비트폭은 다를 수 있다. 본 기술방안인 경우, 제1 사전판정시점이 목표반복간격 내의 처음 반복이든 최후 반복이든 관계없이, 모두 수학 식 （18）을 통해 점 위치 파라미터의 변화추세 값을 획득하는 데 적합하다. 현재 순간의 제1 사전판정시점이 현재 목표반복간격의 처음 반복이면, 수학식 （18）에서, 은 현재 목표반복간격의 처음 반복대응시점에 대응 하는 점 위치 파라미터 가 훈련 및 반복에 따라 증가되는 이동평균 값이고, 는 현재 목표반복간격의 처음 반복대응시점에 대응하는 점 위치 파라미터 이며, 은 이전 목표반복간격의 처음 반복대응시점에 대응하 는 점 위치 파라미터 가 훈련 및 반복에 따라 증가되는 이동평균 값이다. 현재 순간의 제1 사전판정시점이 현 재 목표반복간격의 최후 반복이면, 수학식 （18）에서 은 현재 목표반복간격의 최후 반복대응시점에 대응하 는 점 위치 파라미터 가 훈련 및 반복에 따라 증가되는 이동평균 값이고, 는 현재 목표반복간격의 최후 반 복대응시점에 대응하는 점 위치 파라미터 이며, 은 이전 목표반복간격의 최후 반복대응시점에 대응하는 점 위치 파라미터 가 훈련 및 반복에 따라 증가되는 이동평균 값이다. 본 기술방안인 경우, 제1 사전판정시점을 포함하는 것에 기초하여, 사전판정시점은 제2 사전판정시점을 포함할 수도 있다. 제2 사전판정시점은 데이터 변동폭 곡선에 의해 확정된다. 신경망 훈련과정에서 빅 데이터의 데이터 변동폭 상화에 근거하여 도5a에 도시된 바와 같은 상기 데이터 변동폭 곡선을 획득한다. 가중치 데이터를 예로 들면, 도5a에 도시된 데이터 변동폭 곡선으로부터 알 수 있는 바와 같이, 훈련 시작으로 부터 T 번째 반복까지의 반복간격 주기 내에서, 가중치를 업데이트할 때 마다 데이터 변동폭이 매우 크다. 현재 사전판정시점에서, 양자화하는 경우, 현재 반복에서 우선 전회 반복의 데이터 비트폭 n1을 이용하여 양자화하며, 획득한 양자화 결과와 대응하는 양자화 전의 데이터에 따라 대응하는 양자화 오차를 확정하며, 양자화 오차를 제1 한계 값, 제2 한계 값과 각각 비교하고, 비교결과에 따라 데이터 비트폭 n1을 조정하여 데이터 비트폭 n2를 획득한다. 데이터 비트폭 n2를 이용하여 현재 반복에 관련된 양자화 대상 가중치 데이터를 양자화한다. 그 다음 에 수학식 （20）에 따라 목표반복간격을 확정하여 제1 사전판정시점을 확정하며, 제1 사전판정시점에서 데이터 비트폭을 조정할지 여부와 조정방법을 다시 판정하고, 수학식 （20）에 따라 다음 목표반복간격을 확정하여 다 음의 제1 사전판정시점을 획득한다. 훈련 시작으로부터 T 번째 반복까지의 반복간격 주기 내에서, 매회 반복 전 후의 가중치 데이터 변화 폭이 매우 크기 때문에 매번 반복의 대응하는 층의 가중치 데이터 사이에 유사성이 없 으며, 정밀도 문제를 충조시키기 위해, 양자화할 때 현재 반복의 각 층의 데이터는 전회 반복의 대응하는 층의 대응 양자화 파라미터를 계속 사용할 수 없으며, 이전 T회 반복에서는 반복 마다 데이터 비트폭을 조정할 수 있 다. 이 때, 양자화할 때 이전 T회 반복에서 반복 마다 사용하는 데이터 비트폭이 모두 다르며, 목표반복간격은 1회 반복이다. 인공지능 프로세서 칩의 리소스를 최적으로 이용하기 위해, 이전 T회 반복의 목표반복간격은 도 5a에 도시된 데이터 변동폭 곡선에 의해 개시되는 규칙에 따라 사전에 미리 설정할 수 있다. 즉, 데이터 변동폭 곡선의 이전 T회 반복의 목표반복간격에 근거하여 직접 미리 설정하며, 수학식 （20）을 통해 이전 T회 반복의 매번 반복에 대응하는 가중치 업데이트 반복이 완료될 때의 시점을 확인하여 제2 사전판정시점으로 할 필요가 없다. 따라서 인공지능 프로세서 칩의 리소스를 보다 합리적으로 이용되게 한다. 도5a에 도시된 데이터 변동폭곡선은 T 번째 반복부터 변동폭이 크지 않으며, 훈련의 중, 후기에서는 번 마다 양자화 파라미터를 다시 확인할 필요가 없으며, T 번째 반복 또는 T+1 번째 반복에서 현재 반복에 대응하는 양자화하기 전의 데이터 및 양자화 한 후의 데이터를 이용하여 양자화 오차를 확정하고, 양자화 오차에 따라 데이터 비트폭을 조정할지 여부 및 조 정방법을 확정하며, 또 수학식 （20）에 따라 목표반복간격을 확정해야 한다. 확인한 목표반복간격이 55회 반복 이면, T 번째 반복 또는 T+1 번째 반복 후 55회 반복을 사이로 대응하는 시점을 제1 사전판정시점으로 하고 데 이터 비트폭을 조정할지 여부 및 조정방법을 다시 판정하며, 수학식 （20）에 따라 다음 목표반복간격을 확정하 고, 동일한 주기(epoch) 내에서 모든 반복 연산이 완료될 때까지 다음의 제1 사전판정시점을 확정한다. 이를 바 탕으로, 각 주기(epoch) 후에, 데이터 비트폭 또는 양자화 파라미터에 대하여 적응성을 다시 조정하며, 최종적 으로 양자화된 후의 데이터를 사용하여 정밀도가 기대에 해당한 신경망을 획득한다. 특히, 도5a에 도시된 가중치 데이터 변동폭 곡선도에 근거하여 T의 값을 130으로 확정하면（이 수치는 도5a와 대응되지 않으며, 설명의 편의를 위해, 단지 T의 값이 130이라고 가정할 뿐이며, 가정 값에 한정되지 않는다. ）, 훈련과정 중 제130회 반복이 제2 사전판정시점으로 되고, 현재의 제1 사전판정시점이 훈련과정 중 제100회 반복이며, 제100회 반복에서, 수학식 （20）에 따라 확정한 목표반복간격이 35회 반복이다. 당해 목표반복간격 내에서 제130회 반복까지 훈련하여 제2 사전판정시점에 도달하며, 이 때에는 제130회 반복에 대응하는 시점에서 데이터 비트폭을 조정할지 여부 및 조정방법을 확정하고, 수학식 （20）에 근거하여 목표반복간격도 확정해야 한다. 이 경우 확정한 목표반복간격이 42회 반복이면, 제130회 반복부터 제172회 반복까지를 목표반복간격으로 하며, 목표반복간격이 35회 반복일 때 확정한 제1 사전판정시점에 대응하는 제135회 반복이 목표반복간격인 42 회 반복 내에 있고, 제135회 반복에서는 수학식 （20）에 따라 데이터 비트폭을 조정할지 여부 및 조정방법을 다시 판정할 수 있다. 또한 제135회 반복에서 평가 및 사전판정을 하지 않고, 직접 제172회 반복으로 이동하고"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "데이터 비트폭을 조정할지 여부의 평가 및 조정방법을 다시 실행할 수도 있다. 요약하면, 제135회 반복에서 평 가 및 사전판정할지 여부는 모두 본 기술방안에 적합하다. 이상과 같이, 데이터 변동폭 곡선에 따라 사전에 제2 사전판정시점을 미리 설정하며, 훈련 또는 미조정의 초기 에서는 인공지능 프로세서 칩의 리소스를 소비햐여 목표반복간격을 확정할 필요가 없으며, 미리 설정된 제2 사 전판정시점에서 직접 양자화 오차에 근거하여 데이터 비트폭을 조정하고, 조정된 데이터 비트폭을 이용하여 현 재 반복에 관련된 양자화 대상 데이터를 양자화한다. 훈련 또는 미조정의 중, 후기에서는 수학식 （20）에 따라 목표반복간격을 획득하고, 따라서 대응하는 제1 사전판정시점을 확정하며, 각 제1 사전판정시점에서 데이터 비 트폭을 조정할지 여부 및 조정방법 확정한다. 이러한 방식으로 신경망 연산에 필요한 부동 소수점 연산의 정밀 도를 충족시킴과 동시에 합리적으로 인공지능 프로세서 칩의 리소스를 이용할 수 있으며, 양자화할 때의 효율을 대폭으로 향상시킬 수 있다. 실제로는 보다 정확한 데이터 비트폭의 목표반복간격을 획득하기 위해, 점 위치 파라미터의 변화추세 값 뿐만 아니라, 점 위치 파라미터의 변화추세 값 및 데이터 비트폭의 변화추세 값 를 동시에 고려할 수 있다. 도7에 도시된 바와 같이, 목표반복간격을 확정하는 방법의 제2 흐름도이다. 상기 목표반복간격의 확정단계는 다음과 같은 단계를 포함한다. 단계701）: 사전판정시점에서, 가중치 반복과정에서 상기 양자화 대상 데이터에 대응하는 점 위치 파라미터의 변화추세 값, 데이터 비트폭의 변화추세 값을 확정한다. 여기에서, 상기 사전판정시점은 상기 데이터 비트폭을 조정할 필요가 있는지 여부를 판정하기 위한 시점이며, 상기 사전판정시점은 가중치 업데이트 반복이 완료될 때 의 시점에 대응한다. 한편, 도6에 도시된 점 위치 파라미터의 변화추세 값에 근거하여 데이터 비트폭의 목표반복간격을 확정하는 기 술방안의 내용은 도7에 도시된 기술방안에 적용되어, 여기에서 다시 언급하지 않는다. 본 단계에서 수학식 （21）에 따라 대응하는 상기 양자화 오차를 이용하여 상기 데이터 비트폭의 변화추세 값을 확정한다. （21） 수학식 （21）에서 는 하이퍼 파라미터이고, 는 양자화 오차이며, 는 데이터 비트폭의 변화추 세 값이다. 는 양자화할 때 채용하는 데이터 비트폭 n의 변화추세를 가늠하며, 가 크면 클 수록 고정 소수점의 비트폭을 업데이트해야 할 가능성이 높아지고 간격이 보다 짧은 업데이트 빈도가 필요하게된다. 도7에 관련된 점 위치 파라미터의 변화추세 값은 여전히 수학식 （18）에 따라 획득할 수 있으며, 수학식 （18 ） 중 는 수학식 （19）에 따라 획득한다. 는 점 위치 파라미터 의 변화추세를 가늠하며, 점 위 치 파라미터 의 변화가 현재 양자화 대상 데이터 중 데이터 최대 값 의 변화상황도 다르게 구현하기 때문 에 가 크면 클 수록 수치범위변화가 급히 변함을 의미하며, 간격이 보다 짧은 업데이트 빈도가 필요하 게 된다. 즉 목표반복간격이 보다 작아진다. 단계702）: 상기 점 위치 파라미터의 변화추세 값과 상기 데이터 비트폭의 변화추세 값에 근거하여 대응하는 상 기 목표반복간격을 확정한다. 본 기술방안에서는 수학식 （22）에 따라 목표반복간격을 확정한다. 목표반복간격에 대해서는, 동일한 목표반복 간격 내 양자화 과정에서 동일한 상기 데이터 비트폭을 채용하며, 상이한 목표반복간격 내 양자화 과정에서 채 용한 데이터 비트폭은 같을 수도 다를 수도 있다. （22） 수학식 （22）에서 는 목표반복간격이다. , 는 하이퍼 파라미터이다. 는 점 위치 파라미터의 변 화추세 값이다. 는 데이터 비트폭의 변화추세 값이다. , 는 경험 값이며, 가변 하이퍼 파라미터일 수도 있다. 통상의 하이퍼 파라미터의 최적화방법은 모두 , 에도 적합하며, 여기에서는 하이퍼 파라미터의 최적화방안에 대하여 다시 언급하지 않는다. 본 기술방안인 경우, 는 점 위치 파라미터 의 변화상황을 가늠하는 데 사용되나 데이터 비트폭 n의 변화에 의해 초래되는 점 위치 파라미터 의 변화는 무시해야 한다. 이것은 에서 데이터 비트폭 n의 변화가 이미 반영되었기 때문이다. 에서 이 무시 작업을 수행하지 않으면 수학식 （22）에 따라 확정 하는 목표반복간격 가 부정확하여 제1 사전판정시점을 너무 많게하며, 훈련 또는 미조정과정에서 데이터 비트 폭 n의 업데이트 여부 및 업데이트 방법에 대한 작업을 빈번하게 수행히기 쉬워 인공지능 프로세서 칩의 리소스 가 합리적으로 이용되지 않게 한다. 상술한 설명에 따라 는 에 의해 확정된다. t-1 번째의 사전판정시점에 대응하는 데이터 비트폭이 n1이고, 대응하는 점 위치 파라미터가 이며, 점 위치 파라미터가 훈련 및 반복에 따라 증가되는 이동평균 값이 이라고 가정한다. 데이터 비트폭 n1을 이용하여 양자화 대상 데이터를 양자화하며, 양자화된 후의 고정 소수 점 수를 획득한다. 양자화하기 전의 데이터와 대응하는 양자화된 후의 데이터에 근거하여 양자화 오차 를 확정하며, 양자화 오차 와 한계 값의 비교결과게 근거하여 데이터 비트폭 을 에 조정하며, 데이터 비트 폭은 비트 조정되고, t 번째의 사전판정시점에서 양자화할 때 사용하는 데이터 비트폭이 이다. 데이 터 비트폭의 변화에 의해 초래되는 점 위치 파라미터의 변화를 무시하기 위해, 을 확정할 때 다음 두 가지 최적화방식 중 한 가지를 선택하면 된다. 첫 번째 방식은 데이터 비트폭이 비트 증가되면, 의 값 은 로 되고, 의 값은 로 되며, , 을 수학식 （19）에 대입하여 을 획득한다. 즉 t 번째의 사전판정시점에 대응하는 점 위치 파라미터가 훈련 및 반복에 따라 증가되는 이동평 균 값이다. 데이터 비트폭이 비트 감소되면, 의 값은 로 되고, 의 값은 로 되며, , 을 수학식 （19）에 대입하여 을 획득한다. 즉 t 번째의 사전판정시점에 대응하는 점 위치 파라미터가 훈련 및 반복에 따라 증가되는 이동평균 값이다. 두 번째 방식은 데이터 비트폭이 비트 증가되든 비트 감소되든, 의 값은 이고, 의 값은 이며, , 을 수학식 （19）에 대입하여 을 획득한다. 데이터 비트폭이 비트 증가할 때, 에서 을 감 산하며, 데이터 비트폭이 비트 감소할 때, 에 을 가산하며, 결과를 t 번째의 사전판정시점 에 대응하는 점 위치 파라미터가 훈련 및 반복에 따라 증가되는 이동평균 값으로 한다. 이 두 가지 방식은 등가 적이며, 모두 데이터 비트폭의 변화에 의해 초래되는 점 위치 파라미터의 변화를 무시할 수 있고, 보다 정확한 목표반복간격을 획득하여 인공지능 프로세서 칩의 리소스 활용율을 향상시킬 수 있다. 실제 응용에서, 데이터 비트폭 n과 점 위치 파라미터 는 양자화 정밀도에 큰 영향을 주며, 양자화 파라미터 중 제2 스케일 팩터 및 오프셋 는 양자화 정밀도에 큰 영향을 주지 않는다. 제1 스케일 팩터 인 경우, 위에 서 이미 언급하였는 바, 두 번째 경우에 속하면 를 전체적으로 제1 스케일 팩터 로 간주하며, 점 위치 파라미터 가 양자화 정밀도에 큰 영향을 주기 때문에, 이 경우 제1 스케일 팩터 은 양자화에 큰 영향을 준다. 따라서, 본 기술방안에서, 데이터 비트폭 n의 변화 여부와 점 위치 파라미터 의 가변 여부에 관계없이 점 위치 파라미터 의 목표반복간격을 확정하는 것도 매우 의미있는 것이며, 도6에 도시된 기술방안의 사상은 점 위치 파라미터 의 목표반복간격을 확정하는 데 적용할 수 있다. 따라서, 점 위치 파라미터 의 목표반복간 격을 확정하는 방법은 도8A에 도시된 바와 같이 다음과 같은 단계를 포함한다. 단계801）: 사전판정시점에서, 가중치 반복과정에 관련된 양자화 대상 데이터에 대응하는 점 위치 파라미터의 변화추세 값을 확정한다. 여기에서, 상기 사전판정시점은 상기 양자화 파라미터에 대해 조정할 필요가 있는지 여부를 판정하기 위한 시점이고, 상기 사전판정시점은 가중치 업데이트 반복이 완료될 때의 시점에 대응한다. 단계802）: 상기 점 위치 파라미터의 변화추세 값에 근거하여 대응하는 상기 목표반복간격을 확정한다. 또한, 도6에 도시된 점 위치 파라미터의 변화추세 값에 근거하여 양자화 파라미터의 목표반복간격을 확정하는 기술방안의 내용은 도8A에 도시된 기술방안에 적용되어, 여기에서 다시 언급하지 않는다. 도8A에 도시된 기술방 안인 경우, 양자화 파라미터는 점 위치 파라미터인 것이 바람직하다. 설명할 필요가 있는 것은, 상술한 데이터 비트폭의 목표반복간격과 양자화 파라미터의 목표반복간격을 확정하는"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "것은 모두 예로서 모든 상황이 아니라 일부 상황만 열거할 뿐이며, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명 기술방안의 본질을 이해한 뒤에 본 발명의 기술방안을 기반으로 다른 변형 또는 변환을 이룰 수 있다. 예를 들어, 데이터 비트폭의 목표반복간격을 확정하는 동안에 양자화 파라미터의 목표반복간격을 확정하는 것도 도6, 도7 및 도8A에 도시된 기술방안에 적용된다. 그러나, 그 실현된 기능 및 달성한 기술적 효 과가 본 발명과 유사하면, 모두 본 발명의 보호범위에 속하는 것이다. 본 기술방안을 이용하여 양자화 파라미터를 확정하고, 양자화 오차에 근거하여 데이터 비트폭 또는 양자화 파라 미터를 조정하며, 데이터 비트폭 또는 양자화 파라미터에 대해 조정할지 여부의 목표반복간격을 확정하였고, 신 경망 연산과정에서 적절한 시점에서 데이터 비트폭 또는 양자화 파라미터에 대한 조정을 달성하여 적절한 반복 시점에서 적절한 양자화 파라미터를 사용하게 하며, 인공지능 프로세서 칩이 신경망 연산을 실행하는 속도를 고 정 소수점 연산의 속도에 달하게 하고 , 인공지능 프로세서 칩의 피크 연산력을 향상시킴과 동시에 연산에 필요 한 부동 소수점 연산의 정밀도를 충족시킨다. 설명할 필요가 있는 것은, 상술한 각 방법 실시예에 대하여, 간단히 설명하기 위해 이들을 동작의 일련 조합으"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "로서 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 본 발명은 설명된 동작의 순서 에 의해 한정되지 않는다는 것을 인식해야 한다. 본 발명에 따르면, 특정 단계는 다른 순서를 채용하거나 동시"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "에 수행할 수 있기 때문이다. 따라서, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 명세서에서 설명된 실시예는 모두 선택할 수 있는 실시예에 속하며, 관련되는 동작과 모듈은 반드시 본 발명에 필수적인 것 이 아니라는 것도 인식해야 한다. 또한, 여기서 양자화 파라미터는 미리 설정한 양자화 파라미터（즉, 오프라인 양자화 파라미터）일 수도 있고, 양자화 대상 데이터를 처리하여 획득한 양자화 파라미터（즉, 온라인 양자화 파라미터）일 수도 있다는 것이 이 해될 것이다. 신경망의 추론, 훈련 및 미조정과정에서, 목표데이터를 오프라인 양자화 또는 온라인 양자화할 수있다. 여기에서, 오프라인 양자화는 양자화 파라미터를 이용하여 양자화 대상 데이터를 오프라인 처리하는 것일 수 있다. 온라인 양자화는 양자화 파라미터를 이용하여 양자화 대상 데이터를 온라인 처리하는 것일 수 있다. 예를 들어, 신경망이 인공지능 칩상에서 가동하며, 양자화 대상 데이터와 양자화 파라미터를 인공지능 칩 외의 연산장치에 송신하여 오프라인 양자화를 수행하거나, 인공지능 칩 외의 연산장치를 이용하여 미리 획득한 양자 화 대상 데이터와 양자화 파라미터를 오프라인 양자화하거나 할 수 있다. 한편, 인공지능 칩이 신경망을 가동하 는 과정에서, 인공지능 칩은 양자화 대상 데이터에 대하여 양자화 파라미터를 이용하여 온라인 양자화할 수 있 다. 신경망에 복수의 양자화 대상 층이 포함되는 경우, 각 양자화 대상 층은 각각 온라인 양자화와 오프라인 양 자화를 수행할 수 있다. 본 발명에서는 각 양자화 대상 층의 양자화 과정이 온라인일지 오프라인일지에 대하여 한정하지 않는다. 본 발명의 실시예에 따르면, 데이터 비트폭을 조정하기 위한 방법을 제공하고 있다. 이하, 도8B 내지 도8V를 참 조하여 설명한다. 도8B는 본 발명의 일 실시예에 있어서 데이터 비트폭 조정방법(800B)의 흐름도를 도시한다. 당해 방법은 다음과 같은 단계를 포함할 수 있다. S114, 상기 현재 검사 반복의 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여 양자화 오차를 확정한다. 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 현재 검사 반복의 양자화 대상 데이 터에 대해 양자화하는 것을 통해 획득한다. 바람직하게는, 상술한 프로세서는 초기 데이터 비트폭을 채용하여 양자화 대상 데이터를 양자화하며, 상술한 양 자화 데이터를 획득할 수 있다. 당해 현재 검사 반복의 초기 데이터 비트폭은 하이퍼 파라미터일 수도 있고, 당 해 현재 검사 반복의 초기 데이터 비트폭은 당해 현재 검사 반복하기 전의 이전 검사 반복의 양자화 대상 데이 터에 근거하여 확정될 수도 있다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이터와 현재 검사 반복의 양자화 데이터에 근거하여 중간표현 데이터를 확정할 수 있다. 바람직하게는, 상기 중간표현 데이터는 상술한 양자화 대상 데이터의 표현 형식과 일치하다. 예를 들어, 프로세서는 상술한 양자화 데이터에 대해 역 양자화를 수행하여 양자화 대상 데이 터의 표현형식과 이치한 중간표현 데이터를 획득할 수 있다. 여기에서, 역 양자화는 양자화의 반대과정을 의미 한다. 예를 들어, 당해 양자화 데이터는 수학식 23을 채용하여 획득할 수 있으며, 프로세서는 수 학식 24에 따라 양자화 데이터에 대해 역 양자화를 수행하고, 대응하는 중간표현 데이터를 획득하며, 양자화 대상 데이터와 중간표현 데이터에 근거하여 양자화 오차를 확정할 수 있다. （23） （24） 또한, 프로세서는 양자화 대상 데이터 및 그에 대응하는 중간표현 데이터에 근거하여 계산을 통해 양자화 오차 를 획득할 수 있다. 현재 검사 반복의 양자화 대상 데이터를 =[ ]로 가정하고, 당해 양자화 대상 데 이터에 대응하는 중간표현 데이터를 =[ ]로 가정한다. 프로세서는 당해 양자화 대상 데이터 및 그에 대응하는 중간표현 데이터 에 근거하여 오차항을 확정하며, 당해 오차항에 근거하여 양자화 오차 를 확정할 수 있다. 바람직하게는, 프로세서는 중간표현 데이터 중 각 요소들의 합, 및 양자화 대상 데이터 중 각 요소들의 합에 근거하여 상술한 오차항을 확정할 수 있으며, 당해 오차항은 중간표현 데이터 중 각 요소들의 합과 양 자화 대상 데이터 중 각 요소들의 합의 차이 값일 수 있다. 그리고, 프로세서는 당해 오차항에 근거하여 양자화 오차를 확정할 수 있다. 구체적인 양자화 오차는 다음과 같은 수학식에 따라 확정할 수 있다. 수학식（25） 여기에서, 는 양자화 대상 데이터 중의 요소이고, 은 중간표현 데이터 의 요소이다. 바람직하게는, 프로세서는 양자화 대상 데이터 중 각 요소와 중간표현 데이터 중 대응하는 요소의 차이 값을 각각 계산하여, m 개의 차이 값을 획득하며, 당해 m 개의 차이 값의 합을 오차항으로 할 수 있다. 그리고, 프로 세서는 당해 오차항에 근거하여 양자화 오차를 확정할 수 있다. 구체적인 양자화 오차는 다음과 같은 수학식에 따라 확정할 수 있다. 수학식（26） 여기에서, 는 양자화 대상 데이터 중의 요소이고, 은 중간표현 데이터 의 요소이다. 바람직하게는, 상술한 양자화 대상 데이터 중 각 요소와 중간표현 데이터 중 대응하는 요소의 차이 값은 대 략 과 같을 수 있기 때문에 상술한 양자화 오차는 다음과 같은 수학식에 따라 확정할 수도 있다. 수학식（27） 여기에서, m은 목표데이터에 대응하는 중간표현 데이터 의 수이며, s는 점 위치이고, 는 양자화 대상 데이 터 중의 요소이다. 바람직하게는, 상기 중간표현 데이터는 상술한 양자화 데이터의 데이터 표현형식과 일치하고, 당해 중간표현 데 이터와 양자화 데이터에 근거하여 양자화 오차를 확정할 수도 있다. 예를 들어, 양자화 대상 데이터는 로 표달할 수 있으며, 중간표현 데이터 를 확정할 수 있고, 당해 중간표현 데이터 는 상술 한 양자화 데이터와 동일한 데이터 표현형식을 가질 수 있다. 이 때 프로세서는 중간표현 데이터 과 상술한 수학식 （23）에 따라 계산하여 획득한 에 근거하여 양자화 오차를 확정할 수 있다. 구체적인 양 자화 오차확정방식은 상술한 수학식 （25） ~ 수학식 （27）을 참조할 수 있다. S115, 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정한다. 구체적으로는, 프로세서는 당해 양자화 오차에 근거하여, 자기 적응적으로 현재 검사 반복에 대응하는 데이터 비트폭을 조정하여 당해 현재 검사 반복이 조정된 후의 목표데이터 비트폭을 확정할 수 있다. 당해 양자화 오차 가 미리 설정된 조건을 충족하는 경우, 현재 검사 반복에 대응하는 데이터 비트폭을 변하지 않도록 유지할 수 있다. 즉 당해 현재 검사 반복의 목표데이터 비트폭은 초기 데이터 비트폭과 같을 수 있다. 양자화 오차가 미리 설정된 조건을 충족하지 않는 경우, 프로세서는 현재 검사 반복의 양자화 대상 데이터에 대응하는 데이터 비트 폭을 조정하여 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득할 수 있다. 프로세서가 당해 목표데이터 비트폭을 채용하여 현재 검사 반복의 양자화 대상 데이터를 양자화할 때 양자화 오차가 상술한 미리 설정된 조 건을 충족한다. 바람직하게는, 상술한 미리 설정된 조건은 사용자가 설정한 미리 설정한 한계 값이여도 좋다. 바람직하게는, 도8C는 본 발명의 다른 실시예에 있어서 데이터 비트폭 조정방법(800C)의 흐름도를 도시한다. 도 8C에 도시된 바와 같이, 상술한 작업(S115)은 다음과 같은 단계를 포함할 수 있다. S1150, 프로세서는 상술한 양자화 오차가 제1 미리 설정된 한계 값 이상인지 판정할 수 있다. 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 작업(S1151)을 수행하여 상기 현재 검사 반복에 대응하 는 데이터 비트폭을 증가시켜 현재 검사 반복의 목표데이터 비트폭을 획득할 수 있다. 양자화 오차가 제1 미리 설정된 한계 값보다도 작으면, 현재 검사 반복의 데이터 비트폭을 변하지 않도록 유지할 수 있다. 더 바람직하게는, 프로세서는 1회 조정을 경유하여 상술한 목표데이터 비트폭을 획득할 수 있다. 예를 들어, 현 재 검사 반복의 초기 데이터 비트폭이 n1인 경우, 프로세서는 1회 조정을 경유하여 당해 목표데이터 비트폭 n2=n1+t를 확정할 수 있다, 여기에서, t는 데이터 비트폭의 조정 값이다. 여기에서, 당해 목표데이터 비트폭 n2 를 채용하여 현재 검사 반복의 양자화 대상 데이터를 양자화할 때, 획득한 양자화 오차는 상기 제1 미리 설정된 한계 값보다도 작을 수 있다. 더 바람직하게는, 프로세서는 양자화 오차가 제1 미리 설정된 한계 값 미만이 될 때까지 여러 번의 조정을 경유 하여 목표데이터 비트폭을 획득하고, 당해 양자화 오차가 제1 미리 설정된 한계 값 미만인 경우 데이터 비트폭 을 목표데이터 비트폭으로 할 수 있다. 구체적으로는, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 제1 미리 설정된 비트폭 스텝에 근거하여 제1 중간 데이터 비트폭을 확정하며, 그 다음에 프로세서는 당해 제1 중간 데이터 비트폭에 근거하여 현재 검사 반복의 양자화 대상 데이터를 양자화하여 양자화 데이터를 획득하고, 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제1 미리 설정된 한계 값 미만이 될 때까지 양자화 오차를 확정할 수 있다. 프로세서는 당해 양자 화 오차가 제1 미리 설정된 한계 값 미만인 경우에 대응하는 데이터 비트폭을 당해 목표데이터 비트폭으로 할 수 있다. 예를 들어, 현재 검사 반복의 초기 데이터 비트폭이 n1인 경우, 프로세서는 당해 초기 데이터 비트폭 n1을 채용 하여 현재 검사 반복의 양자화 대상 데이터 A를 양자화하여 양자화 데이터 B1을 획득하고, 당해 양자화 대상 데 이터 A와 양자화 데이터 B1에 근거하여 계산을 통해 양자화 오차 C1을 획득할 수 있다. 양자화 오차 C1이 제1 미리 설정된 한계 값 이상인 경우, 프로세서는 제1 중간 데이터 비트폭 n2=n1+t1을 확정한다. 여기에서, t1은 제1 미리 설정된 비트폭 스텝이다. 그 다음에는, 프로세서는 당해 제1 중간 데이터 비트폭 n2에 근거하여 현재 검사 반복의 양자화 대상 데이터를 양자화하여 현재 검사 반복의 양자화 데이터 B2를 획득하고, 당해 양자화 대 상 데이터 A와 양자화 데이터 B2에 근거하여 계산을 통해 양자화 오차 C2를 획득할 수 있다. 당해 양자화 오차 C2가 제1 미리 설정된 한계 값 이상인 경우, 프로세서는 제1 중간 데이터 비트폭 n2=n1+t1+t1을 확정하며, 그 다음에는 당해 새로운 제1 중간 데이터 비트폭에 근거하여 현재 검사 반복의 양자화 대상 데이터 A를 양자화하 고, 양자화 오차가 제1 미리 설정된 한계 값 미만이 될 때까지 대응하는 양자화 오차를 계산한다. 양자화 오차 C1이 제1 미리 설정된 한계 값 미만이면, 당해 초기 데이터 비트폭 n1을 변하지 않도록 유지할 수 있다. 또한, 상술한 제1 미리 설정된 비트폭 스텝은 일정한 값일 수 있다. 예를 들어, 양자화 오차가 제1 미리 설정된 한계 값보다도 클 때 마다 프로세서는 현재 검사 반복에 대응하는 데이터 비트폭을 같은 비트폭 값 만큼 증가시 킬 수 있다. 바람직하게는, 상술한 제1 미리 설정된 비트폭 스텝은 가변 값일 수도 있다. 예를 들어, 프로세서 는 양자화 오차와 제1 미리 설정된 한계 값의 차이 값을 계산할 수 있다. 당해 양자화 오차와 제1 미리 설정된 한계 값의 차이 값이 작으면 작을 수록 제1 미리 설정된 비트폭 스텝의 값이 작아진다. 바람직하게는, 도8D는 본 발명의 또 다른 실시예에 있어서 데이터 비트폭 조정방법(800D)의 흐름도를 도시한다. 도8D에 도시된 바와 같이, 상술한 작업(S115)은 다음과 같은 단계를 더 포함할 수 있다. S1152, 프로세서는 상술한 양자화 오차가 제2 미리 설정된 한계 값 이하인지 여부를 판정할 수 있다. 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 작업(S1153)을 수행하여 상기 현재 검사 반복에 대응하 는 데이터 비트폭을 감소시키고 현재 검사 반복의 목표데이터 비트폭을 획득할 수 있다. 양자화 오차가 제2 미 리 설정된 한계 값보다도 클 경우, 현재 검사 반복의 데이터 비트폭을 변하지 않도록 유지할 수 있다. 더 바람직하게는, 프로세서는 1회 조정을 경유하여 상술한 목표데이터 비트폭을 획득할 수 있다. 예를 들어, 현 재 검사 반복의 초기 데이터 비트폭이 n1인 경우, 프로세서는 1회 조정을 경유하여 당해 목표데이터 비트폭 n2=n1-t를 확정할 수 있다. 여기에서, t는 데이터 비트폭의 조정 값이다. 여기에서, 당해 목표데이터 비트폭 n2 를 채용하여 현재 검사 반복의 양자화 대상 데이터를 양자화할 때, 획득한 양자화 오차가 상기 제2 미리 설정된 한계 값보다도 클 수 있다. 더 바람직하게는, 프로세서는 양자화 오차가 제2 미리 설정된 한계 값보다 클 때까지 여러 번 조정을 통해 목표 데이터 비트폭을 획득하고, 당해 양자화 오차가 제2 미리 설정된 한계 값보다 클 때의 데이터 비트폭을 목표데 이터 비트폭으로 할 수 있다. 구체적으로는, 상기 양자화 오차가 제1 미리 설정된 한계 값 이하이면, 제2 미리 설정된 비트폭 스텝에 의해 제2 중간 데이터 비트폭을 확정한다. 그 다음에는 프로세서는 당해 제2 중간 데이터 비트폭에 근거하여 현재 검사 반복의 양자화 대상 데이터를 양자화하여 양자화 데이터를 획득하고, 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상 기 제2 미리 설정된 한계 값보다 클 때까지 양자화 오차를 확정할 수 있다. 프로세서는 당해 양자화 오차가 제2 미리 설정된 한계 값보다 큰 경우에 대응하는 데이터 비트폭을 당해 목표데이터 비트폭으로 할 수 있다. 예를 들어, 현재 검사 반복의 초기 데이터 비트폭이 n1인 경우, 프로세서는 당해 초기 데이터 비트폭 n1을 채용 하여 현재 검사 반복의 양자화 대상 데이터 A를 양자화하여 양자화 데이터 B1을 획득하고, 당해 양자화 대상 데 이터 A와 양자화 데이터 B1에 근거하여 계산을 통해 양자화 오차 C1을 획득할 수 있다. 양자화 오차 C1이 제2 미리 설정된 한계 값 이하인 겨우, 프로세서는 제2 중간 데이터 비트폭 n2=n1-t2를 확정한다. 여기에서, t2는 제2 미리 설정된 비트폭 스텝이다. 그 다음에는, 프로세서는 당해 제2 중간 데이터 비트폭 n2에 근거하여 현재 검사 반복의 양자화 대상 데이터를 양자화하여 현재 검사 반복의 양자화 데이터 B2를 획득하고, 당해 양자화 대 상 데이터 A와 양자화 데이터 B2에 근거하여 계산을 통해 양자화 오차 C2를 획득할 수 있다. 당해 양자화 오차 C2가 제2 미리 설정된 한계 값 이하인 경우, 프로세서는 제2 중간 데이터 비트폭 n2=n1-t2-t2를 확정한다. 그 다음에는 당해 새로운 제2 중간 데이터 비트폭에 근거하여 현재 검사 반복의 양자화 대상 데이터 A를 양자화하 며, 양자화 오차가 제2 미리 설정된 한계 값보다 클 때까지 대응하는 양자화 오차를 계산한다. 양자화 오차 C1 이 제2 미리 설정된 한계 값보다 크면, 당해 초기 데이터 비트폭 n1을 변하지 않도록 유지할 수 있다. 또한, 상술한 제2 미리 설정된 비트폭 스텝은 일정한 값일 수 있다. 예를 들어, 양자화 오차가 제2 미리 설정된 한계 값 미만인 경우, 프로세서는 현재 검사 반복에 대응하는 데이터 비트폭을 동일한 비트폭 값으로 감소시킬 수 있다. 바람직하게는, 상술한 제2 미리 설정된 비트폭 스텝은 가변 값일 수도 있다. 예를 들어, 프로세서는 양자화 오차와 제2 미리 설정된 한계 값의 차이 값을 계산할 수 있다. 당해 양자화 오차와 제2 미리 설정된 한 계 값의 차이 값이 작으면 작을 수록 제2 미리 설정된 비트폭 스텝의 값은 작아진다. 바람직하게는, 도8E는 본 발명의 또 하나의 실시예에 있어서 데이터 비트폭 조정방법(800E)의 흐름도를 도시한 다. 도8E에 도시된 바와 같이, 프로세서는 양자화 오차가 제1 미리 설정된 한계 값보다 작고, 또 양자화 오차가 제2 미리 설정된 한계 값보다 큼을 확정한 경우, 현재 검사 반복의 데이터 비트폭이 변하지 않도록 유지할 수 있다. 여기에서, 제1 미리 설정된 한계 값은 제2 미리 설정된 한계 값보다 크다. 즉 현재 검사 반복의 목표데이 터 비트폭은 초기 데이터 비트폭과 같을 수 있다. 여기에서, 도8E에서는 열거의 방식으로 본 발명의 일 실시예 의 데이터 비트폭 확정방식을 설명하였지만, 도8E 중 각 작업의 순서는 적응적으로 조정할 수 있으며, 여기에서 는 구체적으로 한정하지 않는다. 도8F는 본 발명 실시예에 따른 신경망의 양자화방법(800F)의 흐름도를 도시한다. 도8F에 도시된 바와 같이, 상 기 신경망의 양자화방법은 다음과 같은 단계를 포함한다. 단계(S10), 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터와 대응하는 양자화 파라미터를 확정하며, 상 기 양자화 대상 데이터는 뉴런, 가중치, 바이어스, 그래디언트 중 적어도 한 가지를 포함한다. 단계(S20), 대응하는 양자화 파라미터에 근거하여 양자화 대상 데이터를 양자화하여 양자화 데이터를 얻으며, 상기 신경망이 상기 양자화 데이터에 근거하여 연산을 수행하도록 한다. 단계(S30), 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 상기 목표데이터의 양자화 오 차를 확정하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 목표데이터에 대응하는 양자화 데이터와 목표데이터 사이의 오차에 근거하여 목표데이터의 양자화 오차를 확정 할 수 있다. 설정한 오차 계산방법, 예를 들어 표준차 계산방법, 평균제곱근 오차 계산방법 등을 이용하여 목표 데이터의 양자화 오차를 계산할 수 있다. 양자화 파라미터에 근거하여 목표데이터에 대응하는 양자화 데이터를 역 양자화한 후에 역 양자화 데이터를 얻 으며, 역 양자화 데이터와 목표데이터 사이의 오차에 근거하여, 목표데이터의 양자화 오차를 확정할 수도 있다. 양자화 파라미터가 점 위치를 포함하는 경우, 수학식 （28）에 따라 목표데이터의 양자화 데이터를 역 양자화하 여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（28） 여기에서, round는 반올림에 따른 정수연산이고, 는 목표데이터의 역 양자화 데이터이며, s는 목표데이터에 대응하는 점 위치이다. 양자화 파라미터가 스케일 팩터를 포함하는 경우, 수학식 （29）에 따라 목표데이터의 양자화 데이터를 역 양자 화하여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（29） 여기에서, 는 반올림에 따른 정수연산이다. 는 목표데이터의 역 양자화 데이터이고, 는 스케일 팩터이 다. 양자화 파라미터가 오프셋을 포함하는 경우, 수학식 （30）에 따라 목표데이터의 양자화 데이터를 역 양자화하 여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（30） 여기에서, 는 반올림에 따른 정수연산이다. 는 목표데이터의 역 양자화 데이터이고, 는 스케일 팩터이 다. 양자화 파라미터가 점 위치와 스케일 팩터를 포함하는 경우, 수학식 （31）에 따라 목표데이터의 양자화 데이터 를 역 양자화하여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（31） 양자화 파라미터가 점 위치와 오프셋을 포함하는 경우, 수학식 （32）에 따라 목표데이터의 양자화 데이터를 역 양자화하여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（32） 양자화 파라미터가 스케일 팩터와 오프셋을 포함하는 경우, 수학식 （33）에 따라 목표데이터의 양자화 데이터 를 역 양자화하여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（33） 양자화 파라미터가 점 위치, 스케일 팩터, 및 오프셋을 포함하는 경우, 수학식 （34）에 따라 목표데이터의 양 자화 데이터를 역 양자화하여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（34） 양자화 간격의 계산에 관한 방법을 통해, 예를 들어 수학식 （35）를 통해 계산하여 목표데이터와 목표데이터에 대응하는 역 양자화 데이터 사이의 오차 diffbit를 얻을 수 있다. 수학식（35） 여기에서, p는 목표데이터 중 각 요소의 수이고, s는 목표데이터의 점 위치이다. A의 값은 양자화 파라미터에 근거하여 확정할 수 있다. 양자화 파라미터가 점 위치 s를 포함하는 경우, A= 이고, 양자화 파라미터가 점 위치 s와 스케일 팩터 f를 포함하는 경우, 이다. 2개 데이터의 균치 사이의 차이를 계산하는 방법을 통해, 예를 들어 수학식 （36）을 통해 계산하여 목표데이터 와 목표데이터에 대응하는 역 양자화 데이터 사이의 오차 diffbit를 얻을 수도 있다. 수학식（36） 2개 데이터의 차이 사이의 균치를 계산하는 방법을 통해, 예를 들어 수학식 （37）을 통해 계산하여 목표데이터 와 목표데이터에 대응하는 역 양자화 데이터 사이의 오차 diffbit를 얻을 수도 있다. 수학식（37） 단계(S40), 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조정하 며, 상기 목표데이터에 대응하는 조정 비트폭을 얻는다. 경험 값에 근거하여 오차 한계 값을 확정할 수 있다. 오차 한계 값은 양자화 오차에 대한 기대 값을 표현하는 데 사용할 수 있다. 양자화 오차가 오차 한계 값 이상인 경우, 목표수에 대응하는 데이터 비트폭을 조정하여 목 표데이터에 대응하는 조정 비트폭을 얻을 수 있다. 양자화 정밀도를 향상 또는 저하되게 하기 위해 데이터 비트 폭을 더 긴 비트폭 또는 더 짧은 비트폭으로 조정할 수 있다. 허용 가능한 최대 오차에 근거하여 오차 한계 값을 확정할 수 있다. 양자화 오차가 오차 한계 값보다 클 경우, 양자화 정밀도가 기대에 달하지 않은 것을 설명하며, 데이터 비트폭을 더 긴 비트폭으로 조정할 필요가 있다. 비교적 높은 양자화 정밀도에 근거하여 하나의 비교적 작은 오차 한계 값을 확정할 수도 있다. 양자화 오차가 오차 한계 값보다 작은 경우, 양자화 정밀도가 비교적 높은 것을 설명하며, 신경망의 가동효율이 영향을 받으며, 데이터 비트폭을 더 짧은 비트폭으로 적당히 조정하여 양자화 정밀도를 적당히 저하시키고 신경망의 가 동효율을 향상시킬 수 있다. 데이터 비트폭을 고정의 비트 스텝에 따라 조정할 수 있고, 양자화 오차와 오차 한계 값 사이의 차이 값의 다름 에 따라 가변 조정 스텝에 의해 데이터 비트폭을 조정할 수도 있다. 본 발명은 이에 대해 한정하지 않는다. 단계(S50), 상기 목표데이터에 대응하는 데이터 비트폭을 상기 조정 비트폭으로 업데이트하고, 상기 목표데이터 와 상기 조정 비트폭에 근거하여 계산을 통해 대응하는 조정 양자화 파라미터를 얻으며, 상기 신경망이 상기 조 정 양자화 파라미터에 근거하여 양자화하도록 한다. 조정 비트폭을 확정한 후, 목표데이터에 대응하는 데이터 비트폭을 조정 비트폭으로 업데이트할 수 있다. 예를 들어, 목표데이터의 업데이트 전의 데이터 비트폭이 8비트이고, 조정 비트폭이 12비트이면, 업데이트한 후 목표 데이터에 대응하는 데이터 비트폭은 12비트이다. 조정 비트폭과 목표데이터에 근거하여 계산을 통해 목표데이터 에 대응하는 조정 양자화 파라미터를 얻을 수 있다. 양자화 정밀도가 보다 높거나 보다 낮은 양자화 데이터을 얻기 위해, 목표데이터에 대응하는 조정 양자화 파라미터에 근거하여 목표데이터를 다시 양자화하여 양자화 대 상 층으로 하여금 양자화 정밀도와 처리효율 사이에서 균형을 이루게 할 수 있다. 신경망의 추론, 훈련 및 미조정과정에서, 각 층 사이의 양자화 대상 데이터는 일정한 관련성을 가진다고 간주할 수 있다. 예를 들어, 각 층의 양자화 대상 데이터 사이의 균치 사이의 차이가 설정된 균치 한계 값보다 작고, 각 층의 양자화 대상 데이터 사이의 최대 값 사이의 차이 값도 설정된 차이 값 한계 값보다 작은 경우, 양자화 대상 층의 조정 양자화 파라미터를 후속의 하나 또는 복수의 층의 조정 양자화 파라미터로 하여 양자화 대상 층 의 후속의 하나 또는 복수의 층의 양자화 대상 데이터를 양자화하는 데 사용할 수 있다. 신경망의 훈련 및 미조 정과정에서, 양자화 대상 층에서 현재 반복에 의해 얻은 조정 양자화 파라미터를 후속의 반복에서 양자화 대상층에 대한 양자화에 사용할 수도 있다. 가능한 실현방식에서, 상기 방법은 다음과 같은 단계를 더 포함한다. 상기 양자화 대상 층 다음의 한 층 또는 여러 층에서 상기 양자화 대상 층의 양자화 파라미터를 채용한다. 신경망은 조정 양자화 파라미터에 근거하여 양자화하며, 양자화 대상 층에서만 조정 양자화 파라미터를 이용하 여 양자화 대상 데이터를 다시 양자화하는 것을 포함하고, 새로 얻은 양자화 데이터를 양자화 대상 층의 연산에 사용할 수 있다. 양자화 대상 층에서 조정 양자화 파라미터를 사용하여 양자화 대상 데이터를 다시 양자화하는 것이 아니라, 양자화 대상 층의 후속의 하나 또는 복수의 층에서 조정 양자화 파라미터를 사용하여 양자화하는 것, 및/또는 후속의 반복에서 양자화 대상 층에서 조정 양자화 파라미터를 사용하여 양자화하는 것을 포함할 수 도 있다. 양자화 대상 층에서 조정 양자화 파라미터를 사용하여 다시 양자화하며, 새로 얻은 양자화 데이터를 양자화 대상 층의 연산에 사용하고, 양자화 대상 층의 후속의 하나 또는 복수의 층에서 조정 양자화 파라미터를 사용하여 양자화하는 것, 및/또는 후속의 반복에서 양자화 대상 층에서 조정 양자화 파라미터를 사용하여 양자 화하는 것을 더 포함할 수 있다. 본 발명은 이에 대해 한정하지 않는다. 본 실시예에서, 목표데이터와 목표데이터에 대응하는 양자화 데이터에 근거하여 목표데이터의 양자화 오차를 확 정하며, 목표데이터는 임의의 한 가지 양자화 대상 데이터이고; 상기 양자화 오차와 오차 한계 값에 대하여, 목 표데이터에 대응하는 데이터 비트폭을 조정하여 목표데이터에 대응하는 조정 비트폭을 얻으며; 목표데이터에 대 응하는 데이터 비트폭을 조정 비트폭으로 업데이트하고, 목표데이터와 조정 비트폭에 근거하여 계산을 통해 대 응하는 조정 양자화 파라미터를 얻으며, 신경망으로 하여금 조정 양자화 파라미터에 근거하여 양자화하게 한다. 목표데이터와 양자화 데이터 사이의 오차에 근거하여 데이터 비트폭을 조정하며, 조정 후의 데이터 비트폭에 근 거하여 계산을 통해 조정 양자화 파라미터를 얻는다. 서로 다른 오차 한계 값을 설정하는 것을 통해 서로 다른 조정 양자화 파라미터를 얻을 수 있으며, 양자화 정밀도의 향상이나 가동효율의 향상 등 다양한 양자화 요구사 항을 달성할 수 있다. 목표데이터와 목표데이터의 양자화 데이터에 근거하여 계산을 통해 얻은 조정 양자화 파 라미터는, 목표데이터 자체의 데이터 특징에 보다 적합하고, 목표데이터 자체의 요구에 보다 적합한 양자화 결 과를 달성하며, 양자화 정밀도와 처리효율 사이가 보다 좋은 균형을 달성하도록 할 수도 있다. 도8G는 본 발명 실시예에 따른 신경망의 양자화방법(800G)의 흐름도를 도시한다. 도8G에 도시된 바와 같이, 상 기 신경망의 양자화방법에서 단계(S40)는 다음과 같은 단계를 포함한다. 단계(S41), 상기 양자화 오차가 상기 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트 폭을 증가하여 상기 목표데이터에 대응하는 조정 비트폭을 얻는다. 허용 가능한 최대 양자화 오차에 근거하여 제1 오차 한계 값을 확정할 수 있다. 양자화 오차를 제1 오차 한계 값과 비교할 수 있다. 양자화 오차가 제1 오차 한계 값보다 클 경우, 양자화 오차가 허용되지 않는 것으로 간주 할 수 있다. 양자화 정밀도를 향상할 필요가 있는 경우, 목표데이터에 대응하는 데이터 비트폭을 증가하는 방식 으로 목표데이터의 양자화 정밀도를 향상할 수 있다. 목표데이터에 대응하는 데이터 비트폭을 고정된 조정 스텝에 따라 증가하여 조정 비트폭을 얻을 수 있다. 고정 된 조정 스텝은 N비트일 수 있으며 , N은 정의 정수이다. 데이터 비트폭을 조정할 때마다 N비트 증가시킬 수 있 다. 매번 증가한 후의 데이터 비트폭=원래 데이터 비트폭+N비트이다. 목표데이터에 대응하는 데이터 비트폭을 가변의 조정 스텝에 따라 증가하여 조정 비트폭을 얻을 수 있다. 예를 들어, 양자화 오차와 오차 한계 값 사이의 차이 값이 제1 한계 값보다 클 경우, 조정 스텝 M1에 따라 데이터 비 트폭을 조정할 수 있으며, 양자화 오차와 오차 한계 값 사이의 차이 값이 제1 한계 값보다 작은 경우, 조정 스 텝 M2에 따라 데이터 비트폭을 조정할 수 있고, 여기에서, 제1 한계 값은 제2 한계 값보다 크며, M1>M2이다. 필 요에 따라 각 가변의 조정 스텝을 확정할 수 있다. 본 발명은 데이터 비트폭의 조정 스텝 및 조정 스텝이 가변 인지 여부에 대해 한정하지 않는다. 목표데이터를 조정 비트폭에 따라 계산을 통해 조정 후의 양자화 파라미터를 얻을 수 있다. 조정 후의 양자화 파라미터를 이용하여 목표데이터를 다시 양자화한 다음에 얻은 양자화 데이터는, 조정하기 전의 양자화 파라미 터를 이용하여 양자화하여 얻은 양자화 데이터보다도 양자화 정밀도가 높다. 도8H는 본 발명 실시예에 따른 신경망의 양자화방법(800H)의 흐름도를 도시한다. 도8H에 도시된 바와 같이, 상 기 신경망의 양자화방법은 다음과 같은 단계를 더 포함한다. 단계(S42), 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산 한다. 단계(S43), 상기 조정 후의 양자화 오차와 상기 제1 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터 에 따라 계산하여 얻은 조정 후의 양자화 오차가 상기 제1 오차 한계 값 이하로 될 때까지 상기 조정 비트폭을 계속 증가한다. 양자화 오차에 근거하여 목표데이터에 대응하는 데이터 비트폭을 증가할 때, 비트폭을 1회 조정한 후 조정 비트 폭을 얻으며, 조정 비트폭에 근거하여 계산을 통해 조정 후의 양자화 파라미터를 얻고, 조정 후의 양자화 파라 미터에 근거하여 목표데이터를 양자화하여 조정 후의 양자화 데이터를 얻으며, 또 조정 후의 양자화 데이터와 목표데이터에 근거하여 계산을 통해 목표데이터 조정 후의 양자화 오차를 얻고, 조정 후의 양자화 오차는 여전 히 제1 오차 한계 값보다 클 가능성이 있다. 즉 1회 조정된 데이터 비트폭에 따라서는 조정목적을 충족할 수 없 는 가능성이 있다. 조정 후의 양자화 오차가 여전히 제1 오차 한계 값보다 클 때, 조정 후의 데이터 비트폭을 계속 조정할 수 있다. 즉 최종적으로 얻는 조정 비트폭과 목표데이터에 근거하여 얻은 조정 후의 양자화 오차가 제1 오차 한계 값보다 작을 때까지 목표데이터에 대응하는 데이터 비트폭을 여러번 증가한다. 여러번 증가되는 조정 스텝은 고정된 조정 스텝일 수 있고, 가변의 조정 스텝일 수도 있다. 예를 들어, 최종적 인 데이터 비트폭=원래 데이터 비트폭+A*N비트이다. 여기에서 N은 매번 증가하는 고정된 조정 스텝이고, A는 데 이터 비트폭의 증가회수이다. 최종적인 데이터 비트폭=원래 데이터 비트폭+M1+M2+…+Mm이다. 여기에서, M1, M2...Mm은 매번 증가되는 가변의 조정 스텝이다. 본 실시예에서, 양자화 오차가 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 증 가하여 상기 목표데이터에 대응하는 조정 비트폭을 얻는다. 제1 오차 한계 값과 조정 스텝을 설정하여 데이터 비트폭을 증가함으로써, 조정 후의 데이터 비트폭이 양자화의 요구사항을 충족시킬 수 있도록 할 수 있다. 1회 조정이 조정의 요구사항을 충족시킬 수 없는 경우, 데이터 비트폭에 대하여 여러번 조정할 수도 있다. 제1 오차 한계 값과 조정 스텝의 설정은 양자화 파라미터를 양자화 요구사항에 따라 유연히 조정할 수 있도록 하며, 다양 한 양자화 요구사항을 충족시켜 양자화 정밀도를 자체의 데이터 특징에 따라 자기 적응적으로 조정할 수 있도록 한다. 도8I는 본 발명 실시예에 따른 신경망의 양자화방법(800I)의 흐름도를 도시한다. 도8I에 도시된 바와 같이, 상 기 신경망의 양자화방법 중 단계(S40)는 다음과 같은 단계를 포함한다. 단계(S44), 상기 양자화 오차가 상기 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비 트폭을 감소하며, 상기 제2 오차 한계 값은 상기 제1 오차 한계 값보다 작다. 허용 가능한 양자화 오차와 소망의 신경망의 가동효율에 따라 제2 오차 한계 값을 확정할 수 있다. 양자화 오차 를 제2 오차 한계 값과 비교할 수 있다. 양자화 오차가 제2 오차 한계 값보다 작은 경우, 양자화 오차가 기대를 초과한다고 간주할 수 있으나 가동효율이 너무 낮아 이미 허용할 수 없다. 양자화 정밀도를 저하시켜 신경망의 가동효율을 향상시킬 수 있고, 목표데이터에 대응하는 데이터 비트폭을 감소하는 방식을 통해 목표데이터의 양 자화 정밀도를 저하시킬 수 있다. 목표데이터에 대응하는 데이터 비트폭을 고정된 조정 스텝에 따라 감소시켜 조정 비트폭을 얻을 수 있다. 고정 된 조정 스텝은 N비트일 수 있으며, N은 정의 정수이다. 매번 조정에서 데이터 비트폭은 N비트 감소할 수 있다. 증가 후의 데이터 비트폭=원래 데이터 비트폭-N비트이다. 목표데이터에 대응하는 데이터 비트폭을 가변의 조정 스텝에 따라 감소시켜 조정 비트폭을 얻을 수 있다. 예를 들어, 양자화 오차와 오차 한계 값 사이의 차이 값이 제1 한계 값보다 클 경우, 조정 스텝 M1에 따라 데이터 비 트폭을 조정할 수 있으며, 양자화 오차와 오차 한계 값 사이의 차이 값이 제1 한계 값보다 작은 경우, 조정 스 텝 M2에 따라 데이터 비트폭을 조정할 수 있고, 여기에서, 제1 한계 값은 제2 한계 값보다 크며, M1>M2이다. 필 요에 따라 각 가변의 조정 스텝을 확정할 수 있다. 본 발명은 데이터 비트폭의 조정 스텝 및 조정 스텝이 가변 인지 여부에 대해 한정하지 않는다. 목표데이터를 조정 비트폭에 따라 계산을 통해 조정 후의 양자화 파라미터를 얻을 수 있다. 조정 후의 양자화 파라미터를 이용하여 목표데이터를 다시 양자화한 다음에 얻은 양자화 데이터는, 조정하기 전의 양자화 파라미 터를 이용하여 양자화하여 얻은 양자화 데이터보다도 양자화 정밀도가 낮다. 도8J는 본 발명 실시예에 따른 신경망의 양자화방법(800J)의 흐름도를 도시한다. 도8J에 도시된 바와 같이, 상 기 신경망의 양자화방법은 다음과 같은 단계를 더 포함한다. 단계(S45), 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산 한다. 단계(S46), 상기 조정 후의 양자화 오차와 상기 제2 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터 에 따라 계산을 통해 얻은 조정 후의 양자화 오차가 상기 제2 오차 한계 값 이상이 될 때까지 상기 조정 비트폭 을 계속 감소한다. 양자화 오차에 근거하여 목표데이터에 대응하는 데이터 비트폭을 증가할 때, 비트폭을 1회 조정한 후 조정 비트 폭을 얻으며, 조정 비트폭에 근거하여 계산을 통해 조정 후의 양자화 파라미터를 얻고, 조정 후의 양자화 파라 미터에 근거하여 목표데이터를 양자화하여 조정 후의 양자화 데이터를 얻으며, 또 조정 후의 양자화 데이터와 목표데이터에 근거하여 계산을 통해 목표데이터 조정 후의 양자화 오차를 얻고, 조정 후의 양자화 오차는 여전 히 제2 오차 한계 값보다 작을 가능성이 있다. 즉 1회 조정된 데이터 비트폭에 따라서는 조정목적을 충족할 수 없는 가능성이 있다. 조정 후의 양자화 오차가 여전히 제2 오차 한계 값보다 작은 경우, 조정 후의 데이터 비트 폭을 계속 조정할 수 있다. 즉 최종적으로 얻은 조정 비트폭과 목표데이터에 근거하여 얻은 조정 후의 양자화 오차가 제2 오차 한계 값보다 클 때까지 목표데이터에 대응하는 데이터 비트폭를 여러번 감소한다. 여러번 감소하는 조정 스텝은 고정된 조정 스텝일 수 있고, 가변의 조정 스텝일 수도 있다. 예를 들어, 최종적 인 데이터 비트폭=원래 데이터 비트폭-A*N비트이다. 여기에서 N은 매번 증가하는 고정된 조정 스텝이고, A는 데 이터 비트폭의 증가회수이다. 최종적인 데이터 비트폭=원래 데이터 비트폭-M1-M2-...-Mm이다. 여기에서, M1, M2 ...Mm은 매번 감소하는 가변의 조정 스텝이다. 본 실시예에서, 양자화 오차가 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 감소하여 상기 목표데이터에 대응하는 조정 비트폭을 얻는다. 제2 오차 한계 값과 조정 스텝을 설정하여 데이터 비트폭을 감소하는 것을 통해 조정 후의 데이터 비트폭이 양자화의 요구사항을 충족시킬 수 있도록 할 수 있다. 1회 조정이 조정의 요구사항을 충족시킬 수 없는 경우, 데이터 비트폭에 대하여 여러번 조정할 수도 있다. 제2 오차 한계 값과 조정 스텝의 설정은 양자화 파라미터를 양자화 요구사항에 따라 유연히 자기 적응적으로 조정할 수 있도록 하며, 다양한 양자화 요구사항을 충족시켜 양자화 정밀도를 조정 가능하게 하며, 양자화 정밀도와 신 경망의 가동효율 사이의 균형을 잡을 수 있도록 한다. 가능한 실현방식에서, 상기 방법은 다음과 같은 단계를 더 포함한다. 상기 양자화 오차가 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 증가하며, 상 기 양자화 오차가 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 감소하여 상 기 목표데이터에 대응하는 조정 비트폭을 얻는다. 2개의 오차 한계 값을 동시에 설정할 수도 있다. 여기에서, 제1 오차 한계 값은 양자화 정밀도가 지나치게 낮음 을 나타내기 위한 것이고, 데이터 비트폭의 비트 수를 증가할 수 있으며, 제2 오차 한계 값은 양자화 정밀도가 지나치게 높음을 나타내기 위한 것이고, 데이터 비트폭의 비트 수를 감소할 수 있다. 제1 오차 한계 값은 제2 오차 한계 값보다도 크며, 목표데이터의 양자화 오차를 2개의 오차 한계 값과 동시에 비교하여, 양자화 오차가 제1 오차 한계 값보다 클 경우, 데이터 비트폭의 비트 수를 증가하고, 양자화 오차가 제2 오차 한계 값보다 작 은 경우, 데이터 비트폭의 비트 수를 감소할 수 있다. 양자화 오차가 제1 오차 한계 값과 제2 오차 한계 값 사 이에 위치할 때, 데이터 비트폭은 변하지 않도록 유지될 수 있다. 본 실시예에서, 양자화 오차를 제1 오차 한계 값 및 제2 오차 한계 값과 동시에 비교함으로써, 비교결과에 따라 데이터 비트폭을 증가 또는 감소할 수 있고, 제1 오차 한계 값과 제2 오차 한계 값을 이용하여 보다 유연하게 데이터 비트폭을 조정할 수 있다. 따라서 데이터 비트폭의 조정결과를 양자화 수요사하에 보다 적합하게 한다. 또한, 신경망의 훈련（Training）은 신경망（당해 신경망의 가중치는 난수일 수 있다）에 대해 여러번 반복연산 （iteration）을 수행하여 신경망의 가중치가 미리 설정된 조건을 충족할 수 있게 하는 과정이라는 것이 분명해 야 한다. 여기에서, 1회 반복연산은 일반적으로 1회 순방향 연산, 1회 역방향 연산 및 1회 가중치 업데이트 연 산을 포함한다. 순방향 연산은 신경망의 입력 데이터에 근거하여 순방향 추론을 수행하여 순방향 연산결과를 획 득하는 과정을 의미한다. 역방향 연산은 순방향 연산결과와 미리 설정된 기준 값에 근거하여 손실 값을 확정하 고, 당해 손실 값에 근거하여 가중치 그래디언트 값 및/또는 입력 데이터 그래디언트 값을 확정하는 과정을 의 미한다. 가중치 업데이트 연산은 가중치 그래디언트 값에 근거하여 신경망의 가중치를 조정하는 과정을 의미한 다. 구체적으로는, 신경망의 훈련과정은 다음과 같다. 프로세서는 가중치가 난수인 신경망을 채용하여 입력 데 이터에 대해 순방향 연산을 수행하여 순방향 연산결과를 획득할 수 있다. 그 다음에는 프로세서는 당해 순방향연산결과와 미리 설정된 기준 값에 근거하여 손실 값을 확정하고, 당해 손실 값에 근거하여 가중치 그래디언트 값 및/또는 입력 데이터 그래디언트 값을 확정한다. 마지막으로, 프로세서는 가중치 그래디언트 값에 근거하여 신경망의 그래디언트 값을 업데이트하여 새로운 가중치를 획득하여 1회 반복연산을 완료할 수 있다. 프로세서는 신경망의 순방향 연산결과가 미리 설정된 조건을 충족할 때까지 반복연산을 여러번 루프 실행한다. 예를 들어, 신경망의 순방향 연산결과가 미리 설정된 기준 값에 수렴되면 훈련이 종료된다. 또는, 신경망의 순방향 연산결 과와 미리 설정된 기준 값이 확정한 손실 값이 미리 설정된 정밀도 이하인 경우 훈련이 종료된다. 미조정은 신경망（당해 신경망의 가중치는 이미 수렴상태에 있으며 난수가 아니다）에 대해 여러번 반복연산을 수행하여 신경망의 정밀도가 미리 설정된 요구사항을 충족시킬 수 있도록 하는 과정을 의미한다. 당해 미조정과 정과 상술한 훈련과정은 기본적으로 일치하며, 수렴상태에 있는 신경망을 다시 훈련하는 과정이라고 간주할 수 있다. 추론（Inference）은 가중치가 미리 설정된 조건을 충족하는 신경망을 채용하여 순방향 연산을 수행하여 식별 또는 분류 등 기능을 실현하는 과정을 의미한다. 예를 들어 신경망을 채용하여 화상식별 등을 수행한다. 본 발명 실시예에서는, 상술한 신경망의 훈련 또는 미조정과정에서, 신경망 연산의 상이한 단계에서 상이한 양 자화 파라미터를 채용하여 신경망의 연산 데이터를 양자화하며, 양자화 후의 데이터에 근거하여 반복연산을 수 행할 수 있다. 따라서 신경망 연산과정에서의 데이터 저장공간을 감소시키고, 데이터 액세스 효율 및 연산효율 을 향상시킬 수 있다. 도8K에 도시된 바와 같이, 본 발명의 일 실시예의 양자화 파라미터 조정방법(800K)의 흐 름도를 나타내며, 상술한 방법은 다음과 같은 단계를 포함할 수 있다. S100, 양자화 대상 데이터의 데이터 변동폭을 획득한다. 바람직하게는, 프로세서는 당해 양자화 대상 데이터의 데이터 변동폭을 직접 읽어 낼 수 있으며, 당해 양자화 대상 데이터의 데이터 변동폭은 사용자가 입력할 수 있다 . 바람직하게는, 프로세서는 현재 반복의 양자화 대상 데이터와 이력 반복의 양자화 대상 데이터에 근거하여 계산 을 통해 상술한 양자화 대상 데이터의 데이터 변동폭을 획득할 수도 있다. 여기에서 현재 반복은 현재 실행하는 반복연산을 의미하고, 이력 반복은 현재 반복 전에 실행한 반복연산을 의미한다. 예를 들어, 프로세서는 현재 반복의 양자화 대상 데이터 중 요소의 최대 값과 요소의 평균 값, 및 각 이력 반복의 양자화 대상 데이터 중 요 소의 최대 값과 요소의 평균 값을 획득하고, 매번 반복 중 요소의 최대 값과 요소의 평균 값에 근거하여 양자화 대상 데이터의 변동폭을 확정할 수 있다. 현재 반복의 양자화 대상 데이터 중 요소의 최대 값이 미리 설정된 수 의 이력 반복의 양자화 대상 데이터 중 요소의 최대 값에 가까울 경우, 또 현재 반복의 양자화 대상 데이터 중 요소의 평균 값이 미리 설정된 수의 이력 반복의 양자화 대상 데이터 중 요소의 평균 값에 가까울 경우, 상술한 양자화 대상 데이터의 데이터 변동폭이 작다고 확정할 수 있다. 그렇지 않을 경우, 양자화 대상 데이터의 데이 터 변동폭이 크다고 확정할 수 있다. 한편, 당해 양자화 대상 데이터의 데이터 변동폭은 양자화 대상 데이터의 이동평균 값 또는 분산 등을 채용하여 표현할 수 있으며, 여기에서는 구체적으로 한정하지 않는다. 본 발명 실시예에서, 당해 양자화 대상 데이터의 데이터 변동폭은 양자화 대상 데이터의 양자화 파라미터를 조 정할 필요가 있는지 여부를 확정하는 데 사용할 수 있다. 예를 들어, 양자화 대상 데이터의 데이터 변동폭이 비 교적 크면 양자화 정밀도를 보장하기 위해 양자화 파라미터를 제때에 조정할 필요가 있는 것을 설명할 수 있다. 양자화 대상 데이터의 데이터 변동폭이 비교적 작으면 현재 검사 반복 및 그 다음의 일정 수의 반복에서 이력 반복의 양자화 파라미터를 계속하여 사용할 수 있으며, 양자화 파라미터의 빈번한 조정을 회피할 수 있고 양자 화 효율을 향상시킬 수 있다. 여기에서, 매번 반복은 적어도 하나의 양자화 대상 데이터에 관련되며, 당해 양자화 대상 데이터는 부동 소수점 으로 표현하는 연산 데이터일 수 있고, 고정 소수점으로 표현하는 연산 데이터일 수도 있다. 바람직하게는, 매 번 반복의 양자화 대상 데이터는 뉴런데이터, 가중치 데이터 또는 그래디언트 데이터 중 적어도 한 가지일 수 있으며, 그래디언트 데이터는 뉴런 그래디언트 데이터와 가중치 그래디언트 데이터 등을 포함할 수도 있다. S200, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써 당해 목표반복간격에 근거하여 신경망 연산 중의 양자화 파라미터를 조정한다. 여기에서, 상기 목표반복간격은 적어도 1회 반복을 포 함하며, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. 여기에서, 양자화 파라미터는 데이터 폭을 포함할 수 있다. 따라서, 여기에서는 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써 당해 목표반복간격에 근거하여 신경망 연산 중의 데이터 폭을 조정할 수 있고, 상기 목표반복간격은 적어도 1회 반복을 포함한다. 바람직하게는, 당해 양자화 파라미터는 상술한 점 위치 및/또는 스케일 팩터를 포함할 수 있다. 여기에서, 스케 일 팩터는 제1 스케일 팩터와 제2 스케일 팩터를 포함할 수 있다. 구체적인 점 위치 계산방법, 스케일 팩터의 계산방법은 위에서 설명한 수학식을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 바람직하게는, 당해 양 자화 파라미터는 오프셋을 포함할 수 있으며, 당해 오프셋의 계산방법은 위에서 설명한 수학식을 참조할 수 있 다. 또한, 프로세서는 위에서 설명한 다른 수학식에 따라 점 위치나 스케일 팩터를 확정할 수도 있다. 본 발명 실시예에서, 프로세서는 확정한 목표반복간격에 근거하여 상술한 점 위치, 스케일 팩터 또는 오프셋 중의 적어 도 한 가지를 업데이트하여 당해 신경망 연산 중의 양자화 파라미터를 조정할 수 있다. 즉, 당해 신경망 연산 중의 양자화 파라미터는 신경망 연산 중 양자화 대상 데이터의 데이터 변동폭에 근거하여 업데이트함으로써 양 자화 정밀도를 보장할 수 있다. 또한, 신경망의 훈련 또는 미조정과정에서 연산 데이터의 변화추세를 통계 및 분석하는 것을 통해 양자화 대상 데이터의 데이터 변동곡선을 얻을 수 있음을 이해할 수 있다. 도8L에 도시된 바와 같이, 당해 데이터 변동곡선 (800L)에 따라 신경망의 훈련 또는 미조정 초기에서, 상이한 반복의 양자화 대상 데이터의 데이터 변동이 격렬 하며, 훈련 또는 미조정 연산이 진행함에 따라 상이한 반복의 양자화 대상 데이터의 데이터 변동이 점차 평탄해 지는 경향이 있음을 알 수 있다. 따라서, 신경망 훈련 또는 미조정의 초기에서, 양자화 파라미터를 비교적 빈번 하게 조정할 수 있다. 신경망 훈련 또는 미조정의 중기 및 후기에서, 여러번 반복 또는 훈련주기 간격으로 양자 화 파라미터를 다시 조정할 수 있다. 본 발명의 방법은 적절한 반복간격을 확정함으로써 양자화 정밀도와 양자 화 효율의 균형을 달성하는 것이다. 구체적으로는, 프로세서는 양자화 대상 데이터의 데이터 변동폭을 통해 목표반복간격을 확정하여, 당해 목표반 복간격에 근거하여 신경망 연산 중의 양자화 파라미터를 조정할 수 있다. 바람직하게는, 당해 목표반복간격은 양자화 대상 데이터의 데이터 변동폭의 감소에 따라 증가할 수 있다. 즉, 당해 양자화 대상 데이터의 데이터 변 동폭이 크면 클 수록 당해 목표반복간격이 작아지며, 양자화 파라미터의 조정이 빈번해 진다는 것을 나타낸다. 당해 양자화 대상 데이터의 데이터 변동폭이 작으면 작을 수록 당해 목표반복간격이 커지며, 양자화 파라미터의 조정이 빈번하지 않은 것을 나타낸다. 물론, 다른 실시예에서, 상술한 목표반복간격은 하이퍼 파라미터일 수도 있다. 예를 들어, 당해 목표반복간격은 사용자 자신의 이해에 따라 설정될 수 있다. 바람직하게는, 상술한 가중치 데이터, 뉴런 데이터 및 그래디언트 데이터 등 각종 양자화 대상 데이터는 서로 다른 반복간격을 가질 수 있다. 이에 대응하여, 프로세서는 각종 양자화 대상 데이터에 대응하는 데이터 변동폭 을 각각 획득하여 각 종류의 양자화 대상 데이터의 데이터 변동폭에 근거하여 대응 종류의 양자화 대상 데이터 에 대응하는 목표반복간격을 각각 확정할 수 있다. 즉, 각종 양자화 대상 데이터의 양자화 과정은 비동기적으로 수행할 수 있다. 본 발명 실시예에서, 서로 다른 종류의 양자화 대상 데이터 사이에는 차이가 있어서 서로 다른 양자화 대상 데이터의 데이터 변동폭을 채용하여 대응하는 목표반복간격을 확정하고, 대응하는 목표반복간격에 근거하여 대응하는 양자화 파라미터를 각각 확정할 수 있다. 따라서 양자화 대상 데이터의 양자화 정밀도를 보 장하고, 신경망의 연산결과의 정확성도 보장할 수 있다. 물론, 다른 실시예에서, 서로 다른 종류의 양자화 대상 데이터에 대하여, 동일한 목표반복간격을 확정하여 당해 목표반복간격에 근거하여 대응하는 양자화 대상 데이터에 대응하는 양자화 파라미터를 조정할 수도 있다. 예를 들어, 프로세서는 각종 양자화 대상 데이터의 데이터 변동폭을 각각 획득하고, 최대의 양자화 대상 데이터의 데 이터 변동폭에 근거하여 목표반복간격을 확정하며, 당해 목표반복간격에 근거하여 각종 양자화 대상 데이터의 양자화 파라미터를 각각 확정할 수 있다. 또한, 서로 다른 종류의 양자화 대상 데이터는 동일한 양자화 파라미 터를 채용할 수도 있다. 더 바람직하게는, 상술한 신경망은 적어도 하나의 연산층을 포함할 수 있으며, 당해 양자화 대상 데이터는 각 연산층에 관련된 뉴런 데이터, 가중치 데이터 또는 그래디언트 데이터 중의 적어도 한 가지일 수 있다. 이 때, 프로세서는 현재 연산층에 관련된 양자화 대상 데이터를 획득하고, 상술한 방법에 따라 현재 연산층 중 각종 양 자화 대상 데이터의 데이터 변동폭 및 대응하는 목표반복간격을 확정할 수 있다. 바람직하게는, 프로세서는 매번 반복연산과정에서 모두 상술한 양자화 대상 데이터의 데이터 변동폭을 한번 확 정하고, 대응하는 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 한번 확정할 수 있다. 즉, 프로세서는 매번 반복할 때마다 목표반복간격을 한번 계산할 수 있다. 구체적인 목표반복간격의 계산방식은 다 음의 설명을 참조할 수 있다. 또한, 프로세서는 미리 설정된 조건에 따라 각 반복에서 검사 반복을 선정하고, 각 검사 반복에서 양자화 대상 데이터의 변동폭을 확정하며, 검사 반복에 대응하는 목표반복간격에 근거하여 양 자화 파라미터 등의 업데이트를 조정할 수 있다. 이 때, 당해 반복이 선정된 검사 반복이 아닌 경우, 프로세서 는 당해 반복에 대응하는 목표반복간격을 무시할 수 있다. 바람직하게는, 각 목표반복간격은 하나의 검사 반복에 대응할 수 있고, 당해 검사 반복은 당해 목표반복간격의 처음 반복일 수 있으며, 당해 목표반복간격의 종료 반복일 수도 있다. 프로세서는 각 목표반복간격의 검사 반복 에서 신경망의 양자화 파라미터를 조정하여 목표반복간격에 따른 신경망 연산의 양자화 파라미터의 조정을 실현 할 수 있다. 여기에서, 검사 반복은 현재 양자화 파라미터가 양자화 대상 데이터의 요구사항을 충족하는지 여부 를 검증하기 위한 시점일 수 있다. 당해 조정하기 전의 양자화 파라미터는 조정 후의 양자화 파라미터와 같을 수 있고, 조정 후의 양자화 파라미터와 다를 수도 있다. 바람직하게는, 인접하는 검사 반복 사이의 간격은 하나 의 목표반복간격 이상일 수 있다. 예를 들어, 당해 목표반복간격은 현재 검사 반복으로부터 반복회수를 계산할 수 있으며, 당해 현재 검사 반복은 당해 목표반복간격의 처음 반복일 수 있다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복간격이 3이면, 프로세서는 당해 목표반복 간격이 제100회 반복, 제101회 반복 및 제102회 반복의 3회 반복을 포함하는 것을 확정할 수 있다. 프로세서는 당해 제100회 반복에서 신경망 연산 중의 양자화 파라미터를 조정할 수 있다. 여기에서, 현재 검사 반복은 프로 세서가 현재 양자화 파라미터 업데이트의 조정을 실행하는 경우에 대응하는 반복연산이다. 바람직하게는, 목표반복간격은 현재 검사 반복의 다음의 반복으로부터 계산하는 반복회수일 수도 있고, 당해 현 재 검사 반복은 현재 검사 반복 이전의 이전 반복간격의 종료 반복일 수 있다. 예를 들어, 현재 검사 반복이 제 100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복간격 이 3이면, 프로세서는 당해 목표반복간격이 제101회 반복, 제102회 반복 및 제103회 반복의 3회 반복을 포함하 는 것을 확정할 수 있다. 프로세서는 당해 제100회 반복과 제103회 반복에서 신경망 연산 중의 양자화 파라미터 를 조정할 수 있다. 본 발명은 목표반복간격의 확정방식에 대하여 특히 한정하지 않는다. 일 실시예에서, 상술한 점 위치, 스케일 팩터 및 오프셋의 계산 수학식으로부터 알 수 있는 바와 같이, 양자화 파라미터는 종종 양자화 대상 데이터와 관련되며, 따라서, 상술한 작업(S100)에서, 양자화 대상 데이터의 데이 터 변동폭은 양자화 파라미터의 변동폭을 통해 간접적으로 확정할 수도 있고, 당해 양자화 대상 데이터의 데이 터 변동폭은 양자화 파라미터의 변동폭을 통해 특성화할 수 있다. 구체적으로는, 도8M에 도시된 바와 같이, 본 발명의 일 실시예의 파라미터 조정방법에서 목표반복간격의 확정방법(800M)의 흐름도를 도시한다. 상술한 작업 (S100)은 다음과 같은 단계를 포함할 수 있다. S110, 점 위치의 변동폭을 획득한다. 여기에서, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변 동폭을 특성화하는 데 사용할 수 있으며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭과 정의 상관이 있다. 바람직하게는, 점 위치의 변동폭은 간접적으로 양자화 대상 데이터의 변동폭을 반영할 수 있다. 당해 점 위치의 변동폭은 현재 검사 반복의 점 위치와 적어도 1회의 이력 반복의 점 위치에 의해 확정될 수 있다. 여기에서, 현 재 검사 반복의 점 위치 및 각 이력 반복의 점 위치는 위에서 설명한 수학식에 따라 확정할 수 있다. 예를 들어, 프로세서는 현재 검사 반복의 점 위치와 이력 반복의 점 위치의 분산 등을 계산하고, 당해 분산에 근거하여 점 위치의 변동폭을 확정할 수도 있다. 또한, 프로세서는 현재 검사 반복의 점 위치와 이력 반복의 점 위치의 평균 값에 근거하여 점 위치의 변동폭을 확정할 수 있다. 구체적으로는, 도8N에 도시된 바와 같이, 도8N 은 본 발명의 일 실시예에 있어서 점 위치의 변동폭의 확정방법(800N)의 흐름도를 도시한다. 상술한 작업(S11 0)은 다음과 같은 단계를 포함한다. S111, 상기 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복 에 대응하는 점 위치에 근거하여 제1 균치를 확정한다. 여기에서, 전회 검사 반복은 전회에서 상기 양자화 파라 미터를 조정하는 경우에 대응하는 반복이며, 전회 검사 반복과 상기 현재 검사 반복 사이에 적어도 하나의 반복 간격을 둔다. 바람직하게는, 적어도 1회 이력 반복은 적어도 하나의 반복간격에 각각 속할 수 있으며, 각 반복간격은 대응하 여 하나의 검사 반복이 있을 수 있고, 인접한 2개의 검사 반복은 하나의 반복간격을 가질 수 있다. 상술한 작업 (S111) 중 전회 검사 반복은 목표반복간격 전의 전회 반복간격에 대응하는 검사 반복일 수 있다. 바람직하게는, 당해 제1 균치는 다음과 같은 수학식에 따라 계산할 수 있다. 수학식（38） 여기에서, a1~am은 각 반복의 점 위치에 대응하는 계산 가중치이고, 는 전회 검사 반복에 대응하는 점 위치 이며, ... 는 전회 검사 반복 전의 이력 반복에 대응하는 점 위치이고, M1은 상술한 제1 균치이다. 또 한, 데이터의 분포특성에 따라, 이력 반복이 당해 전회 검사 반복에서 멀리 떨어질 수록 당해 전회 검사 반복의 근방의 반복의 점 위치의 분포 및 변동폭에 대한 영향이 작으며, 따라서, 상술한 계산 가중치는 a1~am의 순서에 따라 점차 작아질 수 있다. 예를 들어, 전회 검사 반복이 신경망 연산의 제100회 반복이고, 이력 반복이 제1회 반복부터 제99회 반복일 수 있으며, 프로세서는 당해 제100회 반복의 점 위치를 획득할 수 있고（즉 ）, 당해 제100회 반복 전의 이력 반복의 점 위치를 획득한다. 즉 는 신경망의 제1회 반복에 대응하는 점 위치일 수 있고......, 는 신경망 의 제98회 반복에 대응하는 점 위치일 수 있으며, 는 신경망의 제99회 반복에 대응하는 점 위치일 수 있다. 또한, 프로세서는 상술한 수학식에 따라 계산을 통해 제1 균치를 획득할 수 있다. 또한, 당해 제1 균치는 각 반복간격에 대응하는 검사 반복의 점 위치에 근거하여 계산할 수 있다. 예를 들어, 당해 제1 균치는 다음과 같은 수학식에 따라 계산할 수 있다. ; 여기에서, a1~am은 각 검사 반복의 점 위치에 대응하는 계산 가중치이고, 는 전회 검사 반복에 대응하는 점 위치이며, ... 는 전회 검사 반복 전의 미리 설정된 수의 반복간격의 검사 반복에 대응하는 점 위치이 고, M1은 상술한 제1 균치이다. 예를 들어, 전회 검사 반복이 신경망 연산의 제100회 반복이고, 이력 반복이 제1회 반복부터 제99회 반복일 수 있으며, 당해 99회의 이력 반복은 11개의 반복간격에 각각 속할 수 있다. 예를 들어, 제1회 반복 내지 제9회 반 복은 첫 번째 반복간격에 속하고, 제10회 반복 내지 제18회 반복은 두 번째 반복간격에 속하며, ......, 제90회 반복 내지 제99회 반복은 열한 번째 반복간격에 속한다. 프로세서는 당해 제100회 반복의 점 위치를 획득할 수 있고（즉 ）, 당해 제100회 반복 전의 반복간격 중 검사 반복의 점 위치를 획득한다. 즉 는 신경망의 첫 번째 반복간격의 검사 반복에 대응하는 점 위치일 수 있고（예를 들어 는 신경망의 제1회 반복에 대응하는 점 위치일 수 있다）, ......, 는 신경망의 열 번째 반복간격의 검사 반복에 대응하는 점 위치일 수 있으며（예 를 들어 는 신경망의 제81회 반복에 대응하는 점 위치일 수 있다）, 는 신경망의 열한 번째 반복간격의 검사 반복에 대응하는 점 위치일 수 있다（예를 들어, 는 신경망의 제90회 반복에 대응하는 점 위치일 수 있 다）. 또한, 프로세서는 상술한 수학식에 따라 계산을 통해 제1 균치 M1을 획득할 수 있다. 본 발명 실시예에서, 쉽게 예를 들어 설명하기 위해, 당해 반복간격에 포함된 반복회수가 같다고 가정한다. 그 러나 실제의 사용과정에서 당해 반복간격에 포함된 반복회수는 다를 수 있다. 바람직하게는, 당해 반복간격에 포함된 반복회수는 반복의 증가에 따라 증가된다. 즉 신경망 훈련 또는 미조정이 진행됨에 따라 반복간격은 갈 수록 커질 수 있다. 또한, 계산을 보다 단순화하고, 데이터가 점유하는 저장공간을 저감하기 위해, 상술한 제1 균치 M1은 다음과 같 은 수학식을 채용하여 계산할 수 있다. 수학식（39） 여기에서, 는 전회 검사 반복에 대응하는 점 위치의 계산 가중치이며, 는 전회 검사 반복에 대응하는 점 위 치이며, M0은 당해 전회 검사 반복 전의 검사 반복에 대응하는 이동평균 값이고, 당해 M0의 구체적 계산방식은 상술한 M1의 계산방식을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. S112, 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균치를 확정한다. 여기에서, 현재 검사 반복에 대응하는 점 위치는 현재 검사 반복의 목표데이터 비트폭과 양자 화 대상 데이터에 근거하여 확정할 수 있다. 바람직하게는, 당해 제2 균치M2는 다음과 같은 수학식에 따라 계산할 수 있다. 수학식（40） 여기에서, b1~bm은 각 반복의 점 위치에 대응하는 계산 가중치이고, 는 현재 검사 반복에 대응하는 점 위치이 며, ... 는 현재 검사 반복 전의 이력 반복에 대응하는 점 위치이고, M2는 상술한 제2 균치이다. 또한, 데이터의 분포특성에 따라 이력 반복이 당해 현재 검사 반복거리에서 멀리 떨어질 수록 당해 현재 검사 반복의 근방의 반복의 점 위치의 분포 및 변동폭에 대한 영향이 작아진다. 따라서, 상술한 계산 가중치는 b1~bm 의 순서에 따라 점차 작아질 수 있다. 예를 들어, 현재 검사 반복이 신경망 연산의 제101회 반복이면, 당해 현재 검사 반복 전의 이력 반복은 제1회 반복 내지 제100회 반복이다. 프로세서는 당해 제101회 반복의 점 위치를 획득할 수 있고（즉 ）, 또 당해 제 101회 반복 전의 이력 반복의 점 위치를 획득한다. 즉 는 신경망의 제1회 반복에 대응하는 점 위치일 수 있 고......, 는 신경망의 제99회 반복에 대응하는 점 위치일 수 있으며, 는 신경망의 제100회 반복에 대응 하는 점 위치일 수 있다. 또한, 프로세서는 상술한 수학식에 따라 계산을 통해 제2 균치 M2를 획득할 수 있다. 바람직하게는, 당해 제2 균치는 각 반복간격에 대응하는 검사 반복의 점 위치에 근거하여 계산할 수 있다. 구체 적으로는, 도8O에 도시된 바와 같이, 본 발명의 일 실시예에 있어서 제2 균치의 확정방법(800O)의 흐름도를 도 시 한다. 상술한 작업(S112)은 다음과 같은 작업을 포함할 수 있다. S1121, 미리 설정된 수의 중간 이동평균 값을 획득한다. 여기에서, 각 상기 중간 이동평균 값은 상기 현재 검사 반복하기 전 상기 미리 설정된 수의 검사 반복에 근거하여 확정되며, 상기 검사 반복은 상기 신경망 양자화 과 정에서의 파라미터를 조정하는 경우에 대응하는 반복이다. S1122, 상기 현재 검사 반복의 점 위치 및 상기 미리 설정된 수의 중간 이동평균 값에 근거하여 상기 제2 균치 를 확정한다. 예를 들어, 당해 제2 균치는 다음과 같은 수학식에 따라 계산할 수 있다. ; 여기에서, b1~bm은 각 반복의 점 위치에 대응하는 계산 가중치이고, 는 현재 검사 반복에 대응하는 점 위치이 며, ... 는 현재 검사 반복 전의 검사 반복에 대응하는 점 위치이고, M2는 상술한 제2 균치이다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 이력 반복이 제1회 반복부터 제99회 반복일 수 있으며, 당해 99회의 이력 반복은 11개의 반복간격에 각각 속할 수 있다. 예를 들어, 제1회 반복 내지 제9회 반복은 첫 번째 반복간격에 속하고, 제10회 반복 내지 제18회 반복은 두 번째 반복간격에 속하며, ......, 제90회 반복 내지 제 99회 반복은 열한 번째 반복간격에 속한다. 프로세서는 당해 제100회 반복의 점 위치를 획득할 수 있고（즉 ）, 당해 제100회 반복 전의 반복간격 중 검사 반복의 점 위치를 획득한다. 즉 는 신경망의 첫 번째 반복간 격의 검사 반복에 대응하는 점 위치일 수 있고（예를 들어 는 신경망의 제1회 반복에 대응하는 점 위치일 수 있다）, ......, 는 신경망의 열 번째 반복간격의 검사 반복에 대응하는 점 위치일 수 있으며（예를 들어 는 신경망의 제81회 반복에 대응하는 점 위치일 수 있다）, 는 신경망의 열한 번째 반복간격의 검사 반 복에 대응하는 점 위치일 수 있다（예를 들어, 는 신경망의 제90회 반복에 대응하는 점 위치일 수 있다）. 또한, 프로세서는 상술한 수학식에 따라 계산을 통해 제2 균치 M2를 획득할 수 있다. 본 발명 실시예에서, 쉽게 예를 들어 설명하기 위해, 당해 반복간격에 포함된 반복회수가 같다고 가정한다. 그 러나 실제의 사용과정에서 당해 반복간격에 포함된 반복회수는 다를 수 있다. 바람직하게는, 당해 반복간격에 포함된 반복회수는 반복의 증가에 따라 증가된다. 즉 신경망 훈련 또는 미조정이 진행됨에 따라 반복간격은 갈 수록 커질 수 있다. 또한, 계산을 단순화하고, 데이터가 점유하는 저장공간을 저감하기 위해, 프로세서는 상기 현재 검사 반복에 대 응하는 점 위치 및 상기 제1 균치에 근거하여 상기 제2 균치를 확정할 수 있다. 즉 상술한 제2 균치는 다음과 같은 수학식에 따라 계산할 수 있다. 수학식（41） 여기에서, 는 현재 검사 반복에 대응하는 점 위치의 계산 가중치이며, M1은 상술한 제1 균치이다. S113, 상기 제1 균치와 상기 제2 균치에 근거하여 제1 오차를 확정한다. 상기 제1 오차는 상기 현재 검사 반복 및 상기 이력 반복의 점 위치의 변동폭을 특성화하는 데 사용된다. 바람직하게는, 제1 오차는 제2 균치와 상술한 제1 균치 간의 차이 값의 절대치일 수 있다. 구체적으로는, 상술 한 제1 오차는 다음과 같은 수학식에 따라 계산할 수 있다. 수학식（42） 바람직하게는, 상술한 현재 검사 반복의 점 위치는 현재 검사 반복의 양자화 대상 데이터와 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여 확정할 수 있으며, 구체적인 점 위치 계산방식은 위의 수학식을 참조할 수 있다. 여기에서, 상술한 현재 검사 반복에 대응하는 목표데이터 비트폭은 하이퍼 파라미터일 수도 있다. 더 바람직하게는, 당해 현재 검사 반복에 대응하는 목표데이터 비트폭은 사용자가 자신의 이해에 따라 입력한 것일 수 있다. 바람직하게는, 신경망 훈련 또는 미조정과정에서 양자화 대상 데이터에 대응하는 데이터 비트폭은 일 정할 수 있다. 즉 동일한 신경망의 같은 종류의 양자화 대상 데이터는 동일한 데이터 비트폭을 채용하여 양자화 된다. 예를 들어, 당해 신경망에 대하여 각 반복 중의 뉴런 데이터는 모두 8비트의 데이터 비트폭을 채용하여 양자화된다. 바람직하게는, 신경망 훈련 또는 미조정과정에서의 양자화 대상 데이터에 대응하는 데이터 비트폭은, 데이터 비 트폭이 양자화 대상 데이터의 양자화 요구사항을 충족시킬 수 있게 보장하기 위해 가변적이다. 즉, 프로세서는 양자화 대상 데이터에 근거하여 자기 적응적으로 당해 양자화 대상 데이터에 대응하는 데이터 비트폭을 조정하 여 당해 양자화 대상 데이터에 대응하는 목표데이터 비트폭을 획득할 수 있다. 구체적으로는, 프로세서는 먼저 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정할 수 있다. 그 다음, 프로세서는 당해 현재 검사 반복에 대응하는 목표데이터 비트폭 및 당해 현재 검사 반복에 대응하는 양자화 대상 데이터에 근거하여 현재 검사 반 복에 대응하는 점 위치를 확정할 수 있다. 본 발명 실시예에서, 현재 검사 반복의 데이터 비트폭이 변화될 때, 점 위치는 그에 따라 변화된다. 이 때 점 위치의 변화는 양자화 대상 데이터의 데이터 변동에 의해 초래된 것이 아니며, 상술한 수학식 （42）이 확정한 제1 오차에 근거하여 계산을 통해 획득한 목표반복간격은 정확하지 않은 경우가 있어 양자화의 정밀도에 영향을 줄 가능성이 있다. 따라서, 현재 검사 반복의 데이터 비트폭이 변화될 때, 상술한 제2 균치를 그것에 따라 조정 하여 제1 오차가 점 위치의 변동폭을 정확하게 반영할 수 있게 보장할 수 있으며, 진일보로 목표반복간격의 정 확성과 신뢰성을 보장하게 할 수 있다. 구체적으로는, 도8P에 도시된 바와 같이, 본 발명의 다른 실시예에 있어 서 제2 균치의 확정방법(800P)의 흐름도를 도시한다. 상술한 방법은 다음과 같은 단계를 포함할 수 있다. S116, 상기 목표데이터 비트폭에 근거하여 상기 현재 검사 반복의 데이터 비트폭 조정 값을 확정한다. 구체적으로는, 프로세서는 현재 검사 반복의 목표데이터 비트폭과 초기 데이터 비트폭에 근거하여 현재 검사 반 복의 데이터 비트폭 조정 값을 확정한다. 여기에서, 당해 데이터 비트폭 조정 값=목표데이터 비트폭-초기 데이 터 비트폭이다. 물론, 프로세서는 현재 검사 반복의 데이터 비트폭 조정 값을 직접 획득할 수 있다. S117, 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상술한 제2 균치를 업데이트한다. 구체적으로는, 데이터 비트폭 조정 값이 미리 설정된 파라미터（예를 들어, 당해 미리 설정된 파라미터는 령일 수 있다）보다 클 경우, 즉 현재 검사 반복의 데이터 비트폭이 증가될 때, 프로세서는 이에 대응하여 제2 균치 를 감소할 수 있다. 데이터 비트폭 조정 값이 미리 설정된 파라미터（예를 들어, 당해 미리 설정된 파라미터는 령일 수 있다）보다 작은 경우, 즉 현재 검사 반복의 데이터 비트폭이 감소될 때, 프로세서는 이에 대응하여 제 2 균치를 증가시킬 수 있다. 데이터 비트폭 조정 값이 미리 설정된 파라미터와 같은 경우, 즉 데이터 비트폭 조 정 값이 0인 경우, 이 때 현재 반복에 대응하는 양자화 대상 데이터에 변경이 없으면, 업데이트 후의 제2 균치 는 업데이트하기 전의 제2 균치와 같으며, 당해 업데이트 전의 제2 균치는 상술한 수학식 （41）에 따라 계산하 여 획득할 수 있다. 바람직하게는, 데이터 비트폭 조정 값이 미리 설정된 파라미터와 같은 경우, 즉 데이터 비 트폭 조정 값이 0인 경우, 프로세서는 제2 균치를 업데이트하지 않는다. 즉 프로세서는 상술한 작업(S117)을 실 행하지 않을 수 있다. 예를 들어, 업데이트하기 전의 제2 균치 이다. 현재 검사 반복에 대응하는 목표데이터 비트폭은 n2=초기 데이터 비트폭 n1+ 이다, 여기에서, 은 데이터 비트폭 조정 값을 나타낸다. 이 때, 업데 이트 후의 제2 균치 이다. 현재 검사 반복에 대응하는 목표데이터 가 비트폭 n2=초기 데이터 비트폭n1- 인 경우, 여기에서, 은 데이터 비트폭 조정 값을 나타낼 수 있다. 이 때, 업데이트 후의 제2 균치 이다. 여기에서, 는 현재 검사 반복 이 목표데이터 비트폭에 근거하여 확정한 점 위치이다. 또한, 업데이트하기 전의 제2 균치 이다. 현재 검사 반복에 대응하는 목표데이터 비트 폭 n2=초기 데이터 비트폭 n1+ 인 경우, 여기에서, 은 데이터 비트폭 조정 값이다. 이 때, 업데이트 후의 제2 균치 이다. 또한, 현재 검사 반복에 대응하는 목표데이터 비트폭 n2=초기 데 이터 비트폭 n1- 인 경우, 여기에서, 은 데이터 비트폭 조정 값을 표현하며, 이 때, 업데이트 후의 제2 균 치 이다. 여기에서, 는 현재 검사 반복이 목표데이터 비트폭에 근거하여 확정한 점 위치이다. 또한, 상술한 작업(S200)은 다음과 같은 단계를 포함할 수 있다. 점 위치의 변동폭에 근거하여 목표반복간격을 확정할 수 있다, 여기에서, 당해 목표반복간격과 상술한 점 위치 의 변동폭은 부의 상관이고. 즉 상술한 점 위치의 변동폭이 클수록 당해 목표반복간격이작아진다. 상술한 점 위 치의 변동폭이 작으면 작을 수록 당해 목표반복간격이크다. 상술한 바와 같이, 상술한 제1 오차는 점 위치의 변동폭을 특성화할 수 있다. 상술한 작업은 다음과 같은 것을 포함한다. 프로세서는 상기 제1 오차에 근거하여 상기 목표반복간격을 확정할 수 있으며, 여기에서, 목표반복간격은 상기 제1 오차와 부의 상관이 있다. 즉 제1 오차가 클 수록 점 위치의 변화 폭이 크며, 진일보로 양자화 대상 데이터 의 데이터 변동폭이 크다는 것을 설명하며, 이 때, 목표반복간격이 작아진다. 구체적으로는, 프로세서는 이하의 수학식에 따라 계산을 통해 목표반복간격 을 얻는다 수학식（43） 여기에서, I는 목표반복간격이고, 는 상술한 제1 오차를 표현하며, 은 하이퍼 파라미터일 수 있다. 또한, 제1 오차는 점 위치의 변동폭을 가늠하는 데 사용되며, 제1 오차가 클 수록 점 위치의 변동폭이 크고, 진 일보로 양자화 대상 데이터의 데이터 변동폭이 큰 것을 나타내며, 목표반복간격을 작게 설정할 필요가 있는 것 을 이해해야 한다. 즉, 제1 오차가 클 수록 빈번하게 양자화 파라미터를 조정한다. 본 실시예에서, 점 위치의 변동폭（제1 오차）을 계산함으로써, 점 위치의 변동폭에 근거하여 목표반복간격을 확정한다. 양자화 파라미터는 목표반복간격에 근거하여 확정되기 때문에, 양자화 파라미터에 근거하여 양자화하 여 얻은 양자화 데이터를 목표데이터의 점 위치의 변동추세에 보다 부합되도록 할 수 있고, 양자화 정밀도를 보 장함과 동시에 신경망의 가동효율을 향상시킬 수 있다. 바람직하게는, 프로세서는 현재 검사 반복에서 목표반복간격을 확정한 후, 현재 검사 반복에서 목표반복간격에 대응하는 양자화 파라미터와 데이터 비트폭등 파라미터를 더 확정하여 목표반복간격에 근거하여 양자화 파라미 터를 업데이트할 수 있다. 여기에서, 양자화 파라미터는 점 위치 및/또는 스케일 팩터를 포함할 수 있다. 또한, 당해 양자화 파라미터는 오프셋을 포함할 수 있다. 당해 양자화 파라미터의 구체적 계산방식은 위의 설명을 참 조할 수 있다. 도8Q에 도시된 바와 같이, 본 발명 다른 실시예의 양자화 파라미터 조정방법(800Q)의 흐름도를 나타내며, 상술한 방법은 다음과 같은 단계를 포함할 수 있다. S300, 프로세서는 목표반복간격에 근거하여 신경망 연산 중의 양자화 파라미터를 조정한다. 구체적으로는, 프로세서는 목표반복간격에 근거하여 검사 반복을 확정하고, 각 검사 반복에서 목표반복간격을 업데이트할 수 있으며, 각 검사 반복에서 양자화 파라미터를 업데이트할 수도 있다. 예를 들어, 신경망 연산에 서 데이터 비트폭을 변하지 않게 유지하며, 이 때, 프로세서는 각 검사 반복에서 직접 검사 반복의 양자화 대상 데이터에 근거하여 점 위치 등 양자화 파라미터를 조정할 수 있다. 또한, 신경망 연산에서 데이터 비트폭은 가 변적이며, 이 때, 프로세서는 각 검사 반복에서 데이터 비트폭을 업데이트하고, 업데이트 후의 데이터 비트폭과 당해 검사 반복의 양자화 대상 데이터에 근거하여 점 위치 등 양자화 파라미터를 조정할 수 있다. 본 발명 실시예에서, 프로세서는 각 검사 반복에서 양자화 파라미터를 업데이트하여 현재 양자화 파라미터가 양 자화 대상 데이터의 양자화 요구사항을 충족하도록 보장한다. 여기에서, 업데이트하기 전의 목표반복간격과 업 데이트 후의 목표반복간격은 같을 수도 다를 수도 있다. 업데이트하기 전의 데이터 비트폭과 업데이트 후의 데 이터 비트폭은 같을 수도 다를 수도 있다. 즉 상이한 반복간격의 데이터 비트폭은 같을 수도 다를 수도 있다. 업데이트하기 전의 양자화 파라미터와 업데이트 후의 양자화 파라미터는 같을 수도 다를 수도 있다. 즉 상이한 반복간격의 양자화 파라미터는 같을 수도 다를 수도 있다. 바람직하게는, 상술한 작업(S300)에서, 프로세서는 검사 반복에서 목표반복간격 중의 양자화 파라미터를 확정하 여 신경망 연산에서의 양자화 파라미터를 조정할 수 있다. 한 가지 상황에서, 당해 신경망 연산에서 각 반복에 대응하는 데이터 비트폭은 모두 변화하지 않는다. 즉 당해 신경망 연산에서 각 반복에 대응하는 데이터 비트폭은 모두 같으며, 이 때, 프로세서는 목표반복간격에서의 점위치 등 양자화 파라미터를 확정하여 목표반복간격에 근거한 신경망 연산에서의 양자화 파라미터의 조정 목적을 실현할 수 있다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 양자화 파라미터는 일치할 수 있다. 즉, 목 표반복간격 중의 각 반복은 모두 동일한 점 위치를 채용하며, 각 검사 반복에서만 점 위치 등 양자화 파라미터 를 업데이트 및 확정한다. 따라서 매번 반복에서 모두 양자화 파라미터를 업데이트하여 조정하는 것을 회피하고, 양자화 과정에서의 계산량을 삭감하며, 양자화 작업의 효율을 향상시킬 수 있다. 바람직하게는, 상술한 데이터 비트폭이 변하지 않는 경우에 대하여, 목표반복간격 중 반복에 대응하는 점 위치 는 일치하게 유지할 수 있다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이터와 당해 현재 검 사 반복에 대응하는 목표데이터 비트폭에 근거하여, 현재 검사 반복에 대응하는 점 위치를 확정하고, 당해 현재 검사 반복에 대응하는 점 위치를 당해 목표반복간격에 대응하는 점 위치로 할 수 있으며, 당해 목표반복간격 중 반복은 모두 현재 검사 반복에 대응하는 점 위치를 계속 사용한다. 바람직하게는, 당해 현재 검사 반복에 대응 하는 목표데이터 비트폭은 하이퍼 파라미터일 수도 있다. 예를 들어, 당해 현재 검사 반복에 대응하는 목표데이 터 비트폭은 사용자가 이해에 의해 입력한 것이다. 당해 현재 검사 반복에 대응하는 점 위치는 위의 수학식 계 산을 참조할 수 있다. 한 가지 상황에서, 당해 신경망 연산에서의 각 반복에 대응하는 데이터 비트폭은 변화할 수 있다. 즉 상이한 목 표반복간격에 대응하는 데이터 비트폭은 일치하지 않아도 되지만, 목표반복간격 중 각 반복의 데이터 비트폭은 변하지 않도록 유지된다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 데이터 비트폭은 하이퍼 파라미터일 수도 있다. 예를 들어, 당해 목표반복간격 중 반복에 대응하는 데이터 비트폭은 사용자가 자신의 이해에 따라 입력한 것일 수 있다. 한 가지 상황에서, 당해 목표반복간격 중 반복에 대응하는 데이터 비트폭은 프로세서가 계산하여 획득한 것일 수도 있다. 예를 들어, 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 현 재 검사 반복에 대응하는 목표데이터 비트폭을 확정하고, 당해 현재 검사 반복에 대응하는 목표데이터 비트폭을 목표반복간격에 대응하는 데이터 비트폭으로 할 수 있다. 이 때, 양자화 과정에서의 계산량을 단순화하기 위해, 당해 목표반복간격에서 대응하는 점 위치 등 양자화 파라 미터는 변하지 않도록 유지할 수도 있다. 즉, 목표반복간격 중의 각 반복은 모두 동일한 점 위치를 채용하며, 각 검사 반복에서만 점 위치 등 양자화 파라미터 및 데이터 비트폭을 업데이트 및 확정한다. 따라서 매번 반복 에서 모두 양자화 파라미터를 업데이트하여 조정하는 것을 회피하고, 양자화 과정에서의 계산량을 삭감하며, 양 자화 작업의 효율을 향상시킬 수 있다. 바람직하게는, 상술한 목표반복간격에 대응하는 데이터 비트폭이 변하지 않는 경우에 대하여, 목표반복간격 중 반복에 대응하는 점 위치는 일치하게 유지할 수 있다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이터와 당해 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여, 현재 검사 반복에 대응하는 점 위치 를 확정하고, 당해 현재 검사 반복에 대응하는 점 위치를 당해 목표반복간격에 대응하는 점 위치로 할 수 있으 며, 당해 목표반복간격 중 반복은 모두 현재 검사 반복에 대응하는 점 위치를 계속 사용한다. 바람직하게는, 당 해 현재 검사 반복에 대응하는 목표데이터 비트폭은 하이퍼 파라미터일 수도 있다. 예를 들어, 당해 현재 검사 반복에 대응하는 목표데이터 비트폭은 사용자가 이해에 의해 입력한 것이다. 당해 현재 검사 반복에 대응하는 점 위치는 위의 수학식 계산을 참조할 수 있다. 바람직하게는, 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치할 수 있다. 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 현재 검사 반복에 대응하는 스케일 팩터를 확정하고, 당해 현재 검사 반복에 대 응하는 스케일 팩터을 목표반복간격 중 각 반복의 스케일 팩터로 할 수 있다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치하다. 바람직하게는, 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 현재 검사 반복에 대응하는 오프셋을 확정하며, 당해 현재 검사 반복에 대응하는 오프셋을 목표반복간격 중 각 반복의 오프셋으로 할 수 있다. 또한, 프로세서는 양자화 대상 데이터의 모든 요소 중 최소 값과 최대 값을 확정하고, 진일보로 점 위치와 스케일 팩터 등 양자화 파라미터를 확정할 수 있으며, 상세에 대 해서는 위의 설명을 참조할 수 있다. 당해 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 예를 들어, 당해 목표반복간격은 현재 검사 반복부터 반복회수를 계산할 수 있다. 즉 목표반복간격에 대응하는 검사 반복은 목표반복간격의 처음 반복일 수 있다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복간격이 3이면, 프로세서는 당해 목 표반복간격이 제100회 반복, 제101회 반복 및 제102회 반복의 3회 반복을 포함하는 것을 확정할 수 있다. 또한 프로세서는 제100회 반복에 대응하는 양자화 대상 데이터와 목표데이터 비트폭에 근거하여, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 확정할 수 있고, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 채용하여 제100회 반복, 제101회 반복 및 제102회 반복을 양자화할 수 있다. 이러한 방식으로, 프로 세서는 제101회 반복과 제102회 반복에서 점 위치 등 양자화 파라미터을 계산할 필요가 없으며, 양자화 과정에 서의 계산량을 삭감하여 양자화 작업의 효율을 향상시킨다. 바람직하게는, 목표반복간격은 현재 검사 반복의 다음의 반복으로부터 계산하는 반복회수일 수도 있다. 즉 당해 목표반복간격에 대응하는 검사 반복은 당해 목표반복간격의 종료 반복일 수도 있다. 예를 들어, 현재 검사 반복 이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복 간격이 3이다. 프로세서는 당해 목표반복간격이 제101회 반복, 제102회 반복 및 제103회 반복의 3회 반복을 포 함하는 것을 확정할 수 있다. 따라서 프로세서는 제100회 반복에 대응하는 양자화 대상 데이터와 목표데이터 비 트폭에 근거하여, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 확정할 수 있고, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 채용하여 제101회 반복, 제102회 반복 및 제103회 반복을 양자 화할 수 있다. 이러한 방식으로, 프로세서는 제102회 반복과 제103회 반복에서 점 위치 등 양자화 파라미터를 계산할 필요가 없으며, 양자화 과정에서의 계산량을 삭감하여 양자화 작업의 효율을 향상시킨다. 본 발명 실시예에서, 동일한 목표반복간격 중 각 반복에 대응하는 데이터 비트폭 및 양자화 파라미터 모두 일치 하다. 즉 동일한 목표반복간격 중 각 반복에 대응하는 데이터 비트폭, 점 위치, 스케일 팩터 및 오프셋은 모두 변하지 않도록 유지되며, 신경망의 훈련 또는 미조정과정에서 양자화 대상 데이터의 양자화 파라미터를 빈번하 게 조정하는 것을 회피할 있고, 양자화 과정에서의 계산량을 삭감하여 양자화 효율을 향상시킬 수 있다. 또한, 훈련 또는 미조정의 상이한 단계에서 데이터 변동폭에 근거하여 동적으로 양자화 파라미터를 조정함으로써 양자 화 정밀도를 보장할 수 있다. 다른 상황에서, 당해 신경망 연산에서의 각 반복에 대응하는 데이터 비트폭은 변화할 수 있으나 목표반복간격 중 각 반복의 데이터 비트폭은 변하지 않게 유지된다. 이 때, 목표반복간격 중 반복에 대응하는 점 위치 등 양 자화 파라미터는 일치하지 않을 수도 있다. 프로세서는 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하 여 목표반복간격에 대응하는 데이터 비트폭을 확정할 수도 있다. 여기에서, 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치하다. 그 다음, 프로세서는 당해 목표반복간격에 대응하는 데이터 비트폭과 점 위치 반복 간격에 근거하여 신경망 연산과정에서의 점 위치 등 양자화 파라미터를 조정할 수 있다. 바람직하게는, 도8R에 도시된 바와 같이, 본 발명의 일 실시예의 양자화 파라미터 조정방법에서 양자화 파라미터를 조정하는 방법 (800R)의 흐름도를 나타낸다. 상술한 작업(S300)은 다음과 같은 단계를 포함할 수 있다. S310, 현재 검사 반복의 양자화 대상 데이터에 근거하여 목표반복간격에 대응하는 데이터 비트폭을 확정한다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치하다. 즉, 신경망 연산과정에서의 데이 터 비트폭은 하나의 목표반복간격을 사이로 1회 업데이트한다. 바람직하게는, 당해 목표반복간격에 대응하는 데 이터 비트폭은 현재 검사 반복의 목표데이터 비트폭일 수 있다. 당해 현재 검사 반복의 목표데이터 비트폭은 위 의 작업(S114)과 (S115)을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 예를 들어, 당해 목표반복간격은 현재 검사 반복부터 반복회수를 계산할 수 있다, 즉 목표반복간격에 대응하는 검사 반복은 목표반복간격의 처음 반복일 수 있다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정한 반복간격이 6이면, 프로세서는 당해 목 표반복간격이 제100회 반복 내지 제105회 반복의 6회 반복을 포함한다는 것을 확정할 수 있다. 이 때, 프로세서 는 제100회 반복의 목표데이터 비트폭을 확정하고, 제101회 반복 내지 제105회 반복에서 당해 제100회 반복의 목표데이터 비트폭을 계속 사용할 수 있어 제101회 반복 내지 제105회 반복에서 목표데이터 비트폭을 계산할 필 요가 없다. 따라서 계산량을 삭감하고, 양자화 효율 및 연산효율을 향상시킬 수 있다. 그 다음에, 제106회 반복 은 현재 검사 반복으로 될 수 있고, 상술한 목표반복간격의 확정 및 데이터 비트폭의 업데이트 작업을 되풀이 할 수 있다. 바람직하게는, 목표반복간격은 현재 검사 반복의 다음의 반복으로부터 계산하는 반복회수일 수도 있다. 즉 당해 목표반복간격에 대응하는 검사 반복은 당해 목표반복간격의 종료 반복일 수도 있다. 예를 들어, 현재 검사 반복 이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정한 반복 간격이 6이다. 따라서 프로세서는 당해 목표반복간격이 제101회 반복 내지 제106회 반복의 6회 반복을 포함한다 는 것을 확정할 수 있다. 이 때, 프로세서는 제100회 반복의 목표데이터 비트폭을 확정하고, 제101회 반복 내지 제106회 반복에서 당해 제100회 반복의 목표데이터 비트폭을 계속 사용할 수 있으며, 제101회 반복 내지 제106 회 반복에서 목표데이터 비트폭을 계산할 필요가 없다. 따라서 계산량을 삭감하고, 양자화 효율 및 연산효율을향상시킬 수 있다. 그 다음에, 제106회 반복은 현재 검사 반복으로 될 수 있고, 상술한 목표반복간격의 확정 및 데이터 비트폭의 업데이트 작업을 되풀이 할 수 있다. S320, 프로세서는 획득한 점 위치 반복간격과 상기 목표반복간격에 대응하는 데이터 비트폭에 근거하여 상기 목 표반복간격 중 반복에 대응하는 점 위치를 조정함으로써, 상기 신경망 연산에서의 점 위치 등 양자화 파라미터 를 조정한다. 여기에서, 상기 점 위치 반복간격은 적어도 1회 반복을 포함하며, 상기 점 위치 반복간격 중 반복되는 점 위치 가 일치하다. 바람직하게는, 당해 점 위치 반복간격은 하이퍼 파라미터일 수 있다. 예를 들어, 당해 점 위치 반 복간격은 사용자가 자체의 이해에 따라 입력한 것일 수 있다. 바람직하게는, 상기 점 위치 반복간격은 상기 목표반복간격 이하이다. 당해 점 위치 반복간격와 상술한 목표반 복간격이 같은 경우, 프로세서는 현재 검사 반복에서 데이터 비트폭과 점 위치 등 양자화 파라미터를 동기적으 로 업데이트할 수 있다. 더 바람직하게는, 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치할 수 있다. 또 한, 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 이 때, 당해 목표반복간격에서의 반복에 대응하는 데 이터 비트폭과 점 위치 등 양자화 파라미터가 모두 같으므로 계산량을 삭감할 수 있어 양자화 효율과 연산효율 을 향상시킬 수 있다. 구체적인 실현과정과 상술한 실시예는 기본적으로 일치하며, 위의 설명을 참조할 수 있어 여기에서 다시 언급하지 않는다. 점 위치 반복간격이 상술한 목표반복간격 미만인 경우, 프로세서는 목표반복간격에 대응하는 검사 반복에서 데 이터 비트폭과 점 위치 등 양자화 파라미터를 업데이트하고, 당해 점 위치 반복간격이 확정된 서브 검사 반복에 서 점 위치 등 양자화 파라미터를 업데이트할 수 있다. 데이터 비트폭이 변하지 않는 경우, 점 위치 등 양자화 파라미터는 양자화 대상 데이터에 근거하여 미조정할 수 있다. 따라서, 동일한 목표반복간격 내에서 점 위치 등 양자화 파라미터를 조정하여 진일보로 양자화 정밀도를 향상시킬 수 있다. 구체적으로는, 프로세서는 현재 검사 반복과 점 위치 반복간격에 근거하여 서브 검사 반복을 확정할 수 있으며, 당해 서브 검사 반복은 점 위치을 조정하는 데 사용되고, 당해 서브 검사 반복은 목표반복간격 중의 반복일 수 있다. 또한, 프로세서는 서브 검사 반복의 양자화 대상 데이터와 목표반복간격에 대응하는 데이터 비트폭에 근 거하여 목표반복간격 중 반복에 대응하는 점 위치를 조정할 수 있다. 여기에서, 점 위치의 확정방식은 상술한 수학식을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 당해 목표반복간격이 6이며, 당해 목표반복간격에 포함된 반복 이 제100회 반복 내지 제105회 반복이다. 프로세서가 획득한 점 위치 반복간격이 =3인 경우, 현재 검사 반복 부터 3회 반복을 간격으로 점 위치를 1회 조정할 수 있다. 구체적으로는, 프로세서는 제100회 반복을 상술한 서 브 검사 반복으로 하고, 당해 제100회 반복에 대응하는 점 위치 s1을 계산하여 획득하며, 제100회 반복, 제101 회 반복 및 제102회 반복에서 점 위치 s1을 공통으로 사용하여 양자화할 수 있다. 그 다음, 프로세서은 점 위치 반복간격 에 근거하여 제103회 반복을 상술한 서브 검사 반복으로 할 수 있으며, 동시에 프로세서는 제103회 반복에 대응하는 양자화 대상 데이터와 목표반복간격에 대응하는 데이터 비트폭 n에 근거하여 두 번째 점 위치 반복간격에 대응하는 점 위치 s2를 확정할 수 있으며, 제103회 반복 내지 제105회 반복에서 상술한 점 위치 s2 를 공통으로 사용하여 양자화할 수 있다. 본 발명 실시예에서, 상술한 업데이트하기 전의 점 위치 s1과 업데이 트 후의 점 위치 s2의 값은 같을 수도 다를 수도 있다. 또한, 프로세서는 제106회 반복에서 다시 양자화 대상 데이터의 데이터 변동폭에 근거하여 다음 목표반복간격 및 당해 다음 목표반복간격에 대응하는 데이터 비트폭 및 점 위치 등 양자화 파라미터를 확정할 수 있다. 또한, 현재 검사 반복이 제100회 반복이고, 당해 목표반복간격이 6이며, 당해 목표반복간격에 포함된 반복이 제 101회 반복 내지 제106회 반복이다. 프로세서가 획득한 점 위치 반복간격이 =3인 경우, 현재 검사 반복부터 3회 반복을 간격으로 점 위치를 1회 조정할 수 있다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이터와 현재 검사 반복에 대응하는 목표데이터 비트폭 n1에 근거하여 첫 번째 점 위치 반복간격에 대응하는 점 위치가 s1임을 확정하면, 제101회 반복, 제102회 반복 및 제103회 반복에서 상술한 점 위치 s1을 공통으로 사용하여 양자화할 수 있다. 그 다음, 프로세서는 점 위치 반복간격 에 근거하여 제104회 반복을 상술한 서브검사 반복으로 할 수 있고, 동시에 프로세서는 제104회 반복에 대응하는 양자화 대상 데이터와 목표반복간격에 대응하는 데이터 비트폭 n1에 근거하여 두 번째 점 위치 반복간격에 대응하는 점 위치 s2를 확정할 수 있으며, 제104회 반복 내지 제106회 반복에서 상술한 점 위치 s2를 공통으로 사용하여 양자화할 수 있다. 본 발명 실시 예에서, 상술한 업데이트하기 전의 점 위치 s1과 업데이트 후의 점 위치 s2의 값은 같을 수도 다를 수도 있다. 또한, 프로세서는 제106회 반복에서 다시 양자화 대상 데이터의 데이터 변동폭에 근거하여 다음 목표반복간격 및 당해 다음 목표반복간격에 대응하는 데이터 비트폭 및 점 위치 등 양자화 파라미터를 확정할 수 있다. 바람직하게는, 당해 점 위치 반복간격은 1과 같을 수 있다. 즉 매번 반복에서 모두 점 위치를 1회 업데이트한다. 바람직하게는, 당해 점 위치 반복간격은 같을 수도 다를 수도 있다. 예를 들어, 당해 목표반복간 격에 포함된 적어도 하나의 점 위치 반복간격은 순차적으로 증가될 수 있다. 여기에서는 예시적으로 본 실시예 의 실현방식을 설명할 뿐이며, 본 발명을 한정하기 위한 것이 아니다. 바람직하게는, 당해 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치하지 않을 수도 있다. 더 바람직하게 는, 당해 스케일 팩터는 상술한 점 위치와 동기적으로 업데이트될 수 있다. 즉, 당해 스케일 팩터에 대응하는 반복간격은 상술한 점 위치 반복간격과 같을 수 있다. 즉 프로세서가 점 위치를 업데이트하고 확정할 때마다, 이에 대응하여 스케일 팩터를 업데이트하고 확정한다. 바람직하게는, 당해 목표반복간격 중 반복에 대응하는 오프셋은 일치하지 않을 수도 있다. 또한, 당해 오프셋은 상술한 점 위치와 동기적으로 업데이트될 수 있다. 즉, 당해 오프셋에 대응하는 반복간격은 상술한 점 위치 반 복간격과 같을 수 있다. 즉 프로세서가 점 위치를 업데이트하고 확정할 때마다, 이에 대응하여 오프셋을 업데이 트하고 확정한다. 물론, 당해 오프셋은 상술한 점 위치 또는 데이터 비트폭과 비동기적으로 업데이트될 수도 있 으며, 여기에서는 구체적으로 한정하지 않는다. 또한, 프로세서는 양자화 대상 데이터의 모든 요소 중 최소 값 과 최대 값을 확정하고, 진일보로 점 위치와 스케일 팩터 등 양자화 파라미터를 확정할 수 있으며, 상세에 대해 서는 위의 설명을 참조할 수 있다. 다른 실시예에 있어서, 프로세서는 점 위치의 변동폭과 양자화 대상 데이터의 데이터 비트폭의 변화에 근거하여 양자화 대상 데이터의 데이터 변동폭을 통합적으로 확정하고, 당해 양자화 대상 데이터의 데이터 변동폭에 근거 하여 목표반복간격을 확정할 수 있다. 여기에서, 당해 목표반복간격은 데이터 비트폭을 업데이트하고 확정하는 데 사용할 수 있다. 즉 프로세서는 각 목표반복간격의 검사 반복에서 데이터 비트폭을 업데이트하고 확정할 수 있다. 점 위치가 고정 소수점 데이터의 정밀도를 반영할 수 있고, 데이터 비트폭이 고정 소수점 데이터의 데이 터 표현범위을 반영할 수 있으므로, 점 위치의 변동폭과 양자화 대상 데이터의 데이터 비트폭 변화를 통합함으 로써 양자화 후의 데이터가 정밀도를 충족할 수 있을 뿐만 아니라 데이터 표현범위도 충족시킬 수 있도록 보장 할 수 있다. 바람직하게는, 점 위치의 변화 폭은 상술한 제1 오차를 채용하여 특성화할 수 있고, 데이터 비트폭 의 변화는 상술한 양자화 오차에 근거하여 확정할 수 있다. 구체적으로는, 도8S에 도시된 바와 같이, 본 발명 다른 실시예의 파라미터 조정방법에서 목표반복간격의 확정방법(800S)의 흐름도를 도시하며, 상술한 방법은 다 음과 같은 단계를 포함할 수 있다. S400, 양자화 대상 데이터의 데이터 변동폭을 표현할 수 있는 점 위치의 변동폭을 특성화할 수 있는 제1 오차를 획득한다. 구체적으로는, 상술한 제1 오차의 계산방식은 위 작업(S110)에서의 설명을 참조할 수 있으며, 여기에 서 다시 언급하지 않는다. S500, 상기 데이터 비트폭의 변화를 특성화하는 데 사용되는 제2 오차를 획득한다. 바람직하게는, 상술한 제2 오차는 양자화 오차에 근거하여 확정할 수 있으며, 당해 제2 오차는 상술한 양자화 오차와 정의 상관이 있다. 구체적으로는, 도8T에 도시된 바와 같이, 본 발명의 또 다른 실시예의 파라미터 조정 방법에서 목표반복간격의 확정방법(800T)의 흐름도를 도시하며, 상술한 작업(S500)은 다음과 같은 단계를 포함 할 수 있다. S510, 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여 양자화 오차를 확정한다. 여기에서, 상기 현재 검사 반복의 양자화 데이터는 초기 데이터 비트폭에 근거하여 상기 현재 검사 반복의 양자화 대상 데이터에 대해 양자화하여 획득한다. 여기에서, 구체적인 양자화 오차 확정방식은 위 작업(S114)에서의 설명을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. S520, 상기 양자화 오차에 근거하여 상기 제2 오차를 확정하며, 상기 제2 오차는 상기 양자화 오차와 정의 상관 이 있다. 구체적으로는, 제2 오차는 다음과 같은 수학식에 따라 계산할 수 있다. 수학식（44） 여기에서, 는 상술한 제2 오차를표현하고, 는 상술한 양자화 오차를 표현하며, 는 하이퍼 파라 미터일 수 있다. 도8S에 되돌와서, S600에서는, 상기 제2 오차와 상기 제1 오차에 근거하여 상기 목표반복간격을 확정한다. 구체적으로는, 프로세서는 제1 오차와 제2 오차에 근거하여 계산을 통해 목표오차를 획득하고, 목표오차에 근거 하여 목표반복간격을 확정할 수 있다. 바람직하게는, 목표오차는 제1 오차와 제2 오차에 가중치를 부여하고 평 균을 계산하여 획득한 것일 수 있다. 예를 들어, 목표오차=K*제1 오차+（1-K）*제2 오차. 여기에서, K는 하이퍼 파라미터이다. 그 다음에는, 프로세서는 당해 목표오차에 근거하여 목표반복간격을 확정할 수 있으며, 목표반복 간격은 당해 목표오차와 부의 상관이 있다. 즉 목표오차가 크면 클 수록, 목표반복간격이 작아진다. 바람직하게는, 당해 목표오차는 제1 오차와 제2 오차 중의 최대 또는 최소 값에 근거하여 확정할 수도 있으며, 이 때 제1 오차 또는 제2 오차의 가중치는 0이다. 구체적으로는, 도8T에 도시된 바와 같이, 상술한 작업(S600) 은 다음과 같은 단계를 포함할 수 있다. S610, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 한다. 구체적으로는, 프로세서는 제1 오차 와 제2 오차 의 크기를 비교하며, 제1 오차 가 제2 오차 보다 클 경우, 당해 목표오차는 제1 오차 와 같다. 제1 오차 가 제2 오차 미만이 면 당해 목표오차는 제2 오차 와 같다. 제1 오차 가 제2 오차와 같은 경우, 당해 목표오차는 제 1 오차 또는 제2 오차 일 수 있다. 즉 목표오차 는 다음과 같은 수학식으로 확정할 수 있다. 수학식（45） 여기에서, 는 목표오차이고, 는 제1 오차이며, 는 제2 오차이다. S620, 상기 목표오차에 근거하여 상기 목표반복간격을 확정한다, 여기에서, 상기 목표오차는 상기 목표반복간격 과 부의 상관이 있다. 구체적으로는, 목표반복간격은 다음과 같은 방식으로 확정할 수 있다. 이하의 수학식에 따라 목표반복간격을 얻을 수 있다. 수학식（46） 여기에서, I는 목표반복간격을 표현하고, 는 상술한 목표오차를 표현하며, 와 는 하이퍼 파라미터일 수 있다. 바람직하게는, 상술한 실시예에서, 신경망 연산 중 데이터 비트폭은 가변적이며, 제2 오차를 통해 데이터 비트 폭의 변화추세를 가늠할 수 있다. 이런 경우에서, 도8T에 도시된 바와 같이, 프로세서는 목표반복간격을 확정한 후, 작업(S630)을 실행하여 목표반복간격 중 반복에 대응하는 데이터 비트폭을 확정할 수 있다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치하다. 구체적으로는, 프로세서는 현재 검사 반복의 양자 화 대상 데이터에 근거하여 목표반복간격에 대응하는 데이터 비트폭을 확정할 수 있다. 즉, 신경망 연산과정에 서의 데이터 비트폭은 하나의 목표반복간격을 사이로 1회 업데이트한다. 바람직하게는, 당해 목표반복간격에 대 응하는 데이터 비트폭은 현재 검사 반복의 목표데이터 비트폭일 수 있다. 당해 현재 검사 반복의 목표데이터 비트폭은 위의 작업(S114)과 (S115)을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 예를 들어, 당해 목표반복간격은 현재 검사 반복부터 반복회수를 계산할 수 있다. 즉 목표반복간격에 대응하는 검사 반복은 목표반복간격의 처음 반복일 수 있다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정한 반복간격이 6이면, 프로세서는 당해 목 표반복간격이 제100회 반복 내지 제105회 반복의 6회 반복을 포함한다는 것을 확정할 수 있다. 이 때, 프로세서 는 제100회 반복의 목표데이터 비트폭을 확정하고, 제101회 반복 내지 제105회 반복에서 당해 제100회 반복의 목표데이터 비트폭을 계속 사용할 수 있어 제101회 반복 내지 제105회 반복에서 목표데이터 비트폭을 계산할 필 요가 없다. 따라서 계산량을 삭감하고, 양자화 효율 및 연산효율을 향상시킬 수 있다. 그 다음에는, 제106회 반 복은 현재 검사 반복으로 될 수 있고, 상술한 목표반복간격의 확정 및 데이터 비트폭의 업데이트 작업을 되풀이 할 수 있다. 바람직하게는, 목표반복간격은 현재 검사 반복의 다음의 반복으로부터 계산하는 반복회수일 수도 있다. 즉 당해 목표반복간격에 대응하는 검사 반복은 당해 목표반복간격의 종료 반복일 수도 있다. 예를 들어, 현재 검사 반복 이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정한 반복 간격이 6이다. 따라서 프로세서는 당해 목표반복간격이 제101회 반복 내지 제106회 반복의 6회 반복을 포함한다 는 것을 확정할 수 있다. 이 때, 프로세서는 제100회 반복의 목표데이터 비트폭을 확정하고, 제101회 반복 내지 제106회 반복에서 당해 제100회 반복의 목표데이터 비트폭을 계속 사용할 수 있으며, 제101회 반복 내지 제106 회 반복에서 목표데이터 비트폭을 계산할 필요가 없다. 따라서 계산량을 삭감하고, 양자화 효율 및 연산효율을 향상시킬 수 있다. 그 다음에는, 제106회 반복은 현재 검사 반복으로 될 수 있고, 상술한 목표반복간격의 확정 및 데이터 비트폭의 업데이트 작업을 되풀이 할 수 있다. 또한, 프로세서는 검사 반복에서 목표반복간격 주의 양자화 파라미터를 확정하여 목표반복간격에 근거하여 신경 망 연산 중의 양자화 파라미터를 조정하도록 할 수 있다. 즉 당해 신경망 연산에서의 점 위치 등 양자화 파라미 터는 데이터 비트폭과 동기적으로 업데이트될 수 있다. 한 가지 상황에서, 당해 목표반복간격 중 반복에 대응하는 양자화 파라미터는 일치할 수 있다. 바람직하게는, 프로세서는 현재 검사 반복의 양자화 대상 데이터와 당해 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거 하여 현재 검사 반복에 대응하는 점 위치를 확정하고, 당해 현재 검사 반복에 대응하는 점 위치를 당해 목표반 복간격에 대응하는 점 위치로 할 수 있다. 여기에서 당해 목표반복간격 중 반복에 대응하는 점 위치는 일치하다. 즉, 목표반복간격 중의 각 반복은 모두 현재 검사 반복의 점 위치 등 양자화 파라미터를 계속하여 사 용하며, 매번 반복에서 모두 양자화 파라미터를 업데이트하여 조정하는 것을 회피함으로써, 양자화 과정에서의 계산량을 삭감하고, 양자화 작업의 효율을 향상시킨다. 바람직하게는, 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치할 수 있다. 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 현재 검사 반복에 대응하는 스케일 팩터를 확정하고, 당해 현재 검사 반복에 대 응하는 스케일 팩터을 목표반복간격 중 각 반복의 스케일 팩터로 할 수 있다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치하다. 바람직하게는, 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 현재 검사 반복에 대응하는 오프셋을 확정하며, 당해 현재 검사 반복에 대응하는 오프셋을 목표반복간격 중 각 반복의 오프셋으로 할 수 있다. 또한, 프로세서는 양자화 대상 데이터의 모든 요소 중 최소 값과 최대 값을 확정하고, 진일보로 점 위치와 스케일 팩터 등 양자화 파라미터를 확정할 수 있으며, 상세에 대 해서는 위의 설명을 참조할 수 있다. 당해 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 예를 들어, 당해 목표반복간격은 현재 검사 반복부터 반복회수를 계산할 수 있다. 즉 목표반복간격에 대응하는 검사 반복은 목표반복간격의 처음 반복일 수 있다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복간격이 3이면, 프로세서는 당해 목 표반복간격이 제100회 반복, 제101회 반복 및 제102회 반복의 3회 반복을 포함하는 것을 확정할 수 있다. 또한 프로세서는 제100회 반복에 대응하는 양자화 대상 데이터와 목표데이터 비트폭에 근거하여, 당해 제100회 반복 에 대응하는 점 위치 등 양자화 파라미터를 확정할 수 있고, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 채용하여 제100회 반복, 제101회 반복 및 제102회 반복을 양자화할 수 있다. 이러한 방식으로, 프로 세서는 제101회 반복과 제102회 반복에서 점 위치 등 양자화 파라미터을 계산할 필요가 없으며, 양자화 과정에 서의 계산량을 삭감하여 양자화 작업의 효율을 향상시킨다. 바람직하게는, 목표반복간격은 현재 검사 반복의 다음의 반복으로부터 계산하는 반복회수일 수도 있다. 즉 당해 목표반복간격에 대응하는 검사 반복은 당해 목표반복간격의 종료 반복일 수도 있다. 예를 들어, 현재 검사 반복 이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복 간격이 3이면. 프로세서는 당해 목표반복간격이 제101회 반복, 제102회 반복 및 제103회 반복의 3회 반복을 포 함하는 것을 확정할 수 있다. 따라서 프로세서는 제100회 반복에 대응하는 양자화 대상 데이터와 목표데이터 비 트폭에 근거하여, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 확정할 수 있고, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 채용하여 제101회 반복, 제102회 반복 및 제103회 반복을 양자 화할 수 있다. 이러한 방식으로, 프로세서는 제102회 반복과 제103회 반복에서 점 위치 등 양자화 파라미터를 계산할 필요가 없으며, 양자화 과정에서의 계산량을 삭감하여 양자화 작업의 효율을 향상시킨다. 본 발명 실시예에서, 동일한 목표반복간격 중 각 반복에 대응하는 데이터 비트폭 및 양자화 파라미터 모두 일치 하다. 즉 동일한 목표반복간격 중 각 반복에 대응하는 데이터 비트폭, 점 위치, 스케일 팩터 및 오프셋은 모두 변하지 않도록 유지되며, 신경망의 훈련 또는 미조정과정에서 양자화 대상 데이터의 양자화 파라미터를 빈번하 게 조정하는 것을 회피할 있고, 양자화 과정에서의 계산량을 삭감하여 양자화 효율을 향상시킬 수 있다. 또한, 훈련 또는 미조정의 상이한 단계에서 데이터 변동폭에 근거하여 동적으로 양자화 파라미터를 조정함으로써 양자 화 정밀도를 보장할 수 있다. 다른 상황에서, 프로세서는 점 위치 등 양자화 파라미터에 대응하는 점 위치 반복간격에 근거하여 목표반복간격 중의 양자화 파라미터를 확정하여 신경망 연산에서의 양자화 파라미터를 조정하도록 할 수 있다. 즉 당해 신경 망 연산에서의 점 위치 등 양자화 파라미터는 데이터 비트폭과 비동기적으로 업데이트될 수 있고, 프로세서는 목표반복간격의 검사 반복에서 데이터 비트폭과 점 위치 등 양자화 파라미터를 업데이트할 수 있으며, 프로세서 는 점 위치 반복간격에 근거하여 목표반복간격 중 반복에 대응하는 점 위치를 개별적으로 업데이트할 수도 있다. 구체적으로는, 프로세서는 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여 목표반복간격에 대응하는 데이터 비트폭을 확정할 수도 있다. 여기에서, 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치하다. 그 다음에는, 프로세서는 당해 목표반복간격에 대응하는 데이터 비트폭과 점 위치 반복간격에 근거하여 신경망 연 산과정에서의 점 위치 등 양자화 파라미터를 조정할 수 있다. 즉 도8T에 도시된 바와 같이, 목표반복간격에 대 응하는 데이터 비트폭을 확정한 다음에, 프로세서는 작업(S640)을 실행할 수도 있으며, 획득한 점 위치 반복간 격과 상기 목표반복간격에 대응하는 데이터 비트폭에 근거하여 상기 목표반복간격 중 반복에 대응하는 점 위치 를 조정하여 상기 신경망 연산에서의 점 위치를 조정하도록 한다. 여기에서, 상기 점 위치 반복간격은 적어도 1 회 반복을 포함하며, 상기 점 위치 반복간격 중 반복되는 점 위치가 일치하다. 바람직하게는, 당해 점 위치 반 복간격은 하이퍼 파라미터일 수 있다. 예를 들어, 당해 점 위치 반복간격은 사용자가 자체의 이해에 따라 입력 한 것일 수 있다 . 바람직하게는, 상기 점 위치 반복간격은 상기 목표반복간격 이하이다. 당해 점 위치 반복간격와 상술한 목표반 복간격이 같은 경우, 프로세서는 현재 검사 반복에서 데이터 비트폭과 점 위치 등 양자화 파라미터를 동기적으 로 업데이트할 수 있다. 더 바람직하게는, 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치할 수 있다. 또 한, 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 이 때, 당해 목표반복간격에서의 반복에 대응하는 데 이터 비트폭과 점 위치 등 양자화 파라미터가 모두 같으므로 계산량을 삭감할 수 있어 양자화 효율과 연산효율 을 향상시킬 수 있다. 구체적인 실현과정과 상술한 실시예는 기본적으로 일치하며, 위의 설명을 참조할 수 있어 여기에서 다시 언급하지 않는다. 점 위치 반복간격이 상술한 목표반복간격 미만인 경우, 프로세서는 목표반복간격에 대응하는 검사 반복에서 데 이터 비트폭과 점 위치 등 양자화 파라미터를 업데이트하고, 당해 점 위치 반복간격이 확정된 서브 검사 반복에 서 점 위치 등 양자화 파라미터를 업데이트할 수 있다. 데이터 비트폭이 변하지 않는 경우, 점 위치 등 양자화 파라미터는 양자화 대상 데이터에 근거하여 미조정할 수 있다. 따라서, 동일한 목표반복간격 내에서 점 위치 등 양자화 파라미터를 조정하여 진일보로 양자화 정밀도를 향상시킬 수 있다. 구체적으로는, 프로세서는 현재 검사 반복과 점 위치 반복간격에 근거하여 서브 검사 반복을 확정할 수 있으며, 당해 서브 검사 반복은 점 위치을 조정하는 데 사용되고, 당해 서브 검사 반복은 목표반복간격 중의 반복일 수 있다. 또한, 프로세서는 서브 검사 반복의 양자화 대상 데이터와 목표반복간격에 대응하는 데이터 비트폭에 근 거하여 목표반복간격 중 반복에 대응하는 점 위치를 조정할 수 있다. 여기에서, 점 위치의 확정방식은 상술한 수학식을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 당해 목표반복간격이 6이며, 당해 목표반복간격에 포함된 반복 이 제100회 반복 내지 제105회 반복이다. 프로세서가 획득한 점 위치 반복간격이 =3인 경우, 현재 검사 반복 부터 3회 반복을 간격으로 점 위치를 1회 조정할 수 있다. 구체적으로는, 프로세서는 제100회 반복을 상술한 서 브 검사 반복으로 하고, 당해 제100회 반복에 대응하는 점 위치 s1을 계산하여 획득하며, 제100회 반복, 제101 회 반복 및 제102회 반복에서 점 위치 s1을 공통으로 사용하여 양자화할 수 있다. 그 다음에는, 프로세서는 점 위치 반복간격 에 근거하여 제103회 반복을 상술한 서브 검사 반복으로 할 수 있고, 동시에 프로세서는 제103 회 반복에 대응하는 양자화 대상 데이터와 목표반복간격에 대응하는 데이터 비트폭 n에 근거하여 두 번째 점 위 치 반복간격에 대응하는 점 위치 s2를 확정할 수 있으며, 제103회 반복 내지 제105회 반복에서 상술한 점 위치 s2를 공통으로 사용하여 양자화할 수 있다. 본 발명 실시예에서, 상술한 업데이트하기 전의 점 위치 s1과 업데 이트 후의 점 위치 s2의 값은 같을 수도 다를 수도 있다. 또한, 프로세서는 제106회 반복에서 다시 양자화 대상 데이터의 데이터 변동폭에 근거하여 다음 목표반복간격 및 당해 다음 목표반복간격에 대응하는 데이터 비트폭 및 점 위치 등 양자화 파라미터를 확정할 수 있다 . 또한, 현재 검사 반복이 제100회 반복이고, 당해 목표반복간격이 6이며, 당해 목표반복간격에 포함된 반복이 제 101회 반복 내지 제106회 반복이다. 프로세서가 획득한 점 위치 반복간격이 =3인 경우, 현재 검사 반복부터 3회 반복을 간격으로 점 위치를 1회 조정할 수 있다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이터와 현재 검사 반복에 대응하는 목표데이터 비트폭 n1에 근거하여 첫 번째 점 위치 반복간격에 대응하는 점 위치가 s1임을 확정하면, 제101회 반복, 제102회 반복 및 제103회 반복에서 상술한 점 위치 s1을 공통으로 사용하여 양자화할 수 있다. 그 다음에는, 프로세서는 점 위치 반복간격 에 근거하여 제104회 반복을 상술한 서브 검사 반복으로 할 수 있고, 동시에 프로세서는 제104회 반복에 대응하는 양자화 대상 데이터와 목표반복간 격에 대응하는 데이터 비트폭 n1에 근거하여 두 번째 점 위치 반복간격에 대응하는 점 위치 s2를 확정할 수 있 으며, 제104회 반복 내지 제106회 반복에서 상술한 점 위치 s2를 공통으로 사용하여 양자화할 수 있다. 본 발명 실시예에서, 상술한 업데이트하기 전의 점 위치 s1과 업데이트 후의 점 위치 s2의 값은 같을 수도 다를 수도 있 다. 또한, 프로세서는 제106회 반복에서 다시 양자화 대상 데이터의 데이터 변동폭에 근거하여 다음 목표반복간 격 및 당해 다음 목표반복간격에 대응하는 데이터 비트폭 및 점 위치 등 양자화 파라미터를 확정할 수 있다 . 바람직하게는, 당해 점 위치 반복간격은 1과 같을 수 있다. 즉 매번 반복에서 모두 점 위치를 1회 업데이트한다. 바람직하게는, 당해 점 위치 반복간격은 같을 수도 다를 수도 있다. 예를 들어, 당해 목표반복간 격에 포함된 적어도 하나의 점 위치 반복간격은 순차적으로 증가될 수 있다. 여기에서는 예시적으로 본 실시예 의 실현방식을 설명할 뿐이며, 본 발명을 한정하기 위한 것이 아니다. 바람직하게는, 당해 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치하지 않을 수도 있다. 더 바람직하게 는, 당해 스케일 팩터는 상술한 점 위치와 동기적으로 업데이트될 수 있다. 즉, 당해 스케일 팩터에 대응하는 반복간격은 상술한 점 위치 반복간격과 같을 수 있다. 즉 프로세서가 점 위치를 업데이트하고 확정할 때마다, 대응적으로 스케일 팩터를 업데이트하고 확정한다. 바람직하게는, 당해 목표반복간격 중 반복에 대응하는 오프셋은 일치하지 않을 수도 있다. 또한, 당해 오프셋은 상술한 점 위치와 동기적으로 업데이트될 수 있다. 즉, 당해 오프셋에 대응하는 반복간격은 상술한 점 위치 반 복간격과 같을 수 있다. 즉 프로세서가 점 위치를 업데이트하고 확정할 때마다, 이에 대응하여 오프셋을 업데이 트하고 확정한다. 물론, 당해 오프셋은 상술한 점 위치 또는 데이터 비트폭과 비동기적으로 업데이트될 수도 있 으며, 여기에서는 구체적으로 한정하지 않는다. 또한, 프로세서는 양자화 대상 데이터의 모든 요소 중 최소 값 과 최대 값을 확정하고, 진일보로 점 위치와 스케일 팩터 등 양자화 파라미터를 확정할 수 있으며, 상세에 대해 서는 위의 설명을 참조할 수 있다. 다른 바람직한 실시예에서, 점 위치, 스케일 팩터 및 오프셋 3개의 양자화 파라미터 사이는 비동기적일 수도 있 다. 즉 점 위치 반복간격, 스케일 팩터 반복간격 및 오프셋 반복간격 중의 하나 또는 3개 모두가 다르다. 여기 에서, 점 위치 반복간격과 스케일 팩터 반복간격은 모두 목표반복간격 이하이다. 오프셋 반복간격은 목표반복간 격보다 작을 수 있다. 오프셋이 양자화 대상 데이터의 분포에만 관련되기 때문에, 하나의 가능한 실시예에서, 당해 오프셋은 목표반복간격과 완전히 비동기적일 수도 있다. 즉 오프셋 반복간격은 목표반복간격보다 클 수도있다. 하나의 바람직한 실시예에서, 상술한 방법은 신경망의 훈련 또는 미조정과정에 적용함으로써, 신경망의 미조정 또는 훈련과정에 관련된 연산 데이터의 양자화 파라미터에 대한 조정을 실현하고, 신경망 연산과정에 관련된 연 산 데이터의 양자화 정밀도 및 효율을 향상시키도록 한다. 당해 연산 데이터는 뉴런 데이터, 가중치 데이터 또 는 그래디언트 데이터 중의 적어도 한 가지이다. 도8L에 도시된 바와 같이, 양자화 대상 데이터의 데이터 변동 곡선에 따라, 훈련 또는 미조정의 초기 단계에서, 각 반복의 양자화 대상 데이터 사이의 차이점이 비교적 크고, 양자화 대상 데이터의 데이터 변동폭이 비교적 심하므로, 이 때 목표반복간격의 값을 작게 할 수 있고, 수시로 목표반복간격 중의 양자화 파라미터를 업데이트하여 양자화 정밀도를 보장할 수 있음을 알 수 있다. 훈련 또는 미조정의 중기 단계에서, 양자화 대상 데이터의 데이터 변동폭은 점차 완만해 지는 경향이 있고, 이 때에는 목 표반복간격의 값을 증가하여 양자화 파라미터를 빈번하게 업데이트하는 것을 회피하며, 양자화 효율 및 연산효 율을 향상하도록 한다. 훈련 또는 미조정의 후기 단계에서, 이 때에는 신경망의 훈련 또는 미조정이 안정해 지 는 경향이 있다（즉 신경망의 순방향 연산결과가 미리 설정된 기준 값에 근접하면 당해 신경망의 훈련 또는 미 조정이 안정되는 경향이 있다）. 이 때에는 목표반복간격의 값을 계속 증가하여 진일보로 양자화 효율 및 연산 효율을 향상시킬 수 있다. 상술한 데이터 변동추세에 따라, 신경망의 훈련 또는 미조정의 서로 다른 단계에서 서로 다른 방식을 채용하여 목표반복간격을 확정함으로써, 양자화 정밀도의 보장을 기반으로 양자화 효율 및 연 산효율을 향상시킬 수 있다. 구체적으로는, 도8U에 도시된 바와 같이, 본 발명의 또 다른 실시예의 양자화 파라미터 조정방법(800U)의 흐름 도를 도시한다. 당해 방법은 신경망의 훈련 또는 미조정과정에 적용되는 경우, 당해 방법은 다음과 같은 단계를 포함할 수 있다. S710, 프로세서는 현재 반복이 제1 미리 설정된 반복보다 클지 여부를 확정한다. 여기에서, 현재 반복은 프로세서가 현재 실행하고 있는 반복연산을 의미한다. 바람직하게는, 당해 제1 미리 설 정된 반복은 하이퍼 파라미터일 수 있고, 당해 제1 미리 설정된 반복은 양자화 대상 데이터의 데이터 변동곡선 에 의해 확정할 수 있으며, 당해 제1 미리 설정된 반복은 사용자가 자신의 이해에 따라 설정한 것일 수도 있다. 바람직하게는, 당해 제1 미리 설정된 반복은 한 훈련주기（epoch）에 포함된 총반복회수보다 작을 수 있다. 여 기에서, 한 훈련주기는 데이터 세트 중의 모든 양자화 대상 데이터가 모두 1회 순방향 연산과 1회 역방향 연산 을 완료한 것을 의미한다. 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 프로세서는 작업(S711)을 실행할 수 있으며, 제1 미 리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제1 미리 설정된 반복간격에 근거하여 양자화 파라미 터를 조정한다. 바람직하게는, 프로세서는 사용자가 입력한 제1 미리 설정된 반복을 판도하고, 당해 제1 미리 설정된 반복과 제 1 미리 설정된 반복간격의 대응관계에 근거하여, 제1 미리 설정된 반복간격을 확정할 수 있다. 바람직하게는, 당해 제1 미리 설정된 반복간격은 하이퍼 파라미터일 수 있고, 당해 제1 미리 설정된 반복간격은 사용자가 자신 의 이해에 따라 설정한 것일 수도 있다. 이 때, 프로세서는 사용자가 입력한 제1 미리 설정된 반복과 제1 미리 설정된 반복간격을 직접 판독하고, 당해 제1 미리 설정된 반복간격에 근거하여 신경망 연산에서의 양자화 파라 미터를 업데이트할 수 있다. 본 발명 실시예에서, 프로세서는 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정할 필요가 없다. 예를 들어, 사용자가 입력한 제1 미리 설정된 반복이 제100회 반복이고, 제1 미리 설정된 반복간격이 5이면, 현 재 반복이 제100회 반복 이하인 경우, 제1 미리 설정된 반복간격에 근거하여 양자화 파라미터를 업데이트할 수 있다. 즉 프로세서는 신경망의 훈련 또는 미조정의 제1회 반복 내지 제100회 반복을 확정할 수 있고, 매번 5회 반복을 간격으로 양자화 파라미터를 1회 업데이트할 수 있다. 구체적으로는, 프로세서는 제1회 반복에 대응하는 데이터 비트폭 n1 및 점 위치 s1 등 양자화 파라미터를 확정하고, 당해 데이터 비트폭 n1과 점 위치 s1 등 양자 화 파라미터를 채용하여 제1회 반복 내지 제5회 반복의 양자화 대상 데이터를 양자화할 수 있다. 즉 제1회 반복 내지 제5회 반복에서 동일한 양자화 파라미터를 채용할 수 있다. 그 다음에는, 프로세서는 제6회 반복에 대응하 는 데이터 비트폭 n2 및 점 위치 s2 등 양자화 파라미터를 확정하고, 당해 데이터 비트폭 n2와 점 위치 s2 등 양자화 파라미터를 채용하여 제6회 반복 내지 제10회 반복의 양자화 대상 데이터를 양자화할 수 있다. 즉 제6회 반복 내지 제10회 반복은 동일한 양자화 파라미터를 채용할 수 있다. 마찬가지로, 프로세서는 제100회 반복이 완료될 때까지 상술한 양자화 방식에 따를 수 있다. 여기에서, 각 반복간격 중 데이터 비트폭 및 점 위치 등 양 자화 파라미터의 확정방식은 위의 설명을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 또한, 사용자가 입력한 제1 미리 설정된 반복이 제100회 반복이고, 제1 미리 설정된 반복간격이 1이며, 현재 반 복이 제100회 반복 이하인 경우, 제1 미리 설정된 반복간격에 근거하여 양자화 파라미터를 업데이트할 수 있다. 즉 프로세서는 신경망의 훈련 또는 미조정의 제1회 반복 내지 제100회 반복을 확정할 수 있고, 매번 반복에서 모두 양자화 파라미터를 업데이트한다. 구체적으로는, 프로세서는 제1회 반복에 대응하는 데이터 비트폭 n1 및 점 위치 s1 등 양자화 파라미터를 확정하고, 당해 데이터 비트폭 n1과 점 위치 s1 등 양자화 파라미터를 채용하 여 제1회 반복의 양자화 대상 데이터를 양자화할 수 있다. 그 다음에는, 프로세서는 제2회 반복에 대응하는 데 이터 비트폭 n2 및 점 위치 s2 등 양자화 파라미터를 확정하고, 당해 데이터 비트폭 n2와 점 위치 s2 등 양자화 파라미터를 채용하여 제2회 반복의 양자화 대상 데이터를 양자화, ……할 수 있다. 마찬가지로, 프로세서는 제 100회 반복의 데이터 비트폭 n100 및 점 위치 s100 등 양자화 파라미터를 확정하고, 당해 데이터 비트폭 n100과 점 위치 s100 등 양자화 파라미터를 채용하여 제100회 반복의 양자화 대상 데이터를 양자화할 수 있다. 여기에 서, 각 반복간격 중 데이터 비트폭 및 점 위치 등 양자화 파라미터의 확정방식은 위의 설명을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 상기에서는 데이터 비트폭과 양자화 파라미터가 동기적으로 업데이트되는 방식을 예로 설명하였지만, 다른 바람 직한 실시예에서는, 각 목표반복간격에서, 프로세서는 점 위치의 변동폭에 근거하여 점 위치의 반복간격을 확정 하고, 당해 점 위치 반복간격에 근거하여 점 위치 등 양자화 파라미터를 업데이트할 수 있다. 바람직하게는, 현재 반복이 제1 미리 설정된 반복보다 큰 경우, 신경망의 훈련 또는 미조정이 중기 단계인 것을 나타낸다. 이 때 이력 반복의 양자화 대상 데이터의 데이터 변동폭을 획득하고, 당해 양자화 대상 데이터의 데 이터 변동폭에 근거하여 목표반복간격을 확정할 수 있으며, 당해 목표반복간격은 상술한 제1 미리 설정된 반복 간격보다 클 수 있으므로 양자화 파라미터의 업데이트 회수를 감소하고, 양자화 효율 및 연산효율을 향상시킬 수 있다. 구체적으로는, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 프로세서는 작업(S713)을 실행할 수 있으며, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정하고 상기 목표반복간격 에 근거하여 양자화 파라미터를 조정한다. 위의 예에 계속하여, 사용자가 입력한 제1 미리 설정된 반복이 제100회 반복이고, 제1 미리 설정된 반복간격이 1이며, 현재 반복이 제100회 반복 이하인 경우, 제1 미리 설정된 반복간격에 근거하여 양자화 파라미터를 업데 이트할 수 있다. 즉 프로세서는 신경망의 훈련 또는 미조정의 제1회 반복 내지 제100회 반복을 확정할 수 있고, 매번 반복에서 모두 양자화 파라미터를 업데이트하며, 구체적 실현방식은 위의 설명을 참조할 수 있다. 현재 반 복이 제100회 반복보다 큰 경우, 프로세서는 현재 반복의 양자화 대상 데이터 및 그 전의 이력 반복의 양자화 대상 데이터에 근거하여 양자화 대상 데이터의 데이터 변동폭을 확정하고, 당해 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정할 수 있다. 구체적으로는, 현재 반복이 제100회 반복보다 큰 경우, 프 로세서는 현재 반복에 대응하는 데이터 비트폭을 자기 적응적으로 조정하여 당해 현재 반복에 대응하는 목표데 이터 비트폭을 획득하고, 당해 현재 반복에 대응하는 목표데이터 비트폭을 목표반복간격의 데이터 비트폭으로 할 수 있다. 여기에서, 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치하다. 동시에, 프로세서는 현재 반복에 대응하는 목표데이터 비트폭과 양자화 대상 데이터에 근거하여 현재 반복에 대응하는 점 위치를 확정하 고, 현재 반복에 대응하는 점 위치에 근거하여 제1 오차를 확정할 수 있다. 프로세서는 현재 반복에 대응하는 양자화 대상 데이터에 근거하여 양자화 오차를 확정하고, 양자화 오차에 근거하여 제2 오차를 확정할 수 있다. 그 다음에는, 프로세서는 제1 오차와 제2 오차에 근거하여 목표반복간격을 확정할 수 있고, 당해 목표반복간격 은 상술한 제1 미리 설정된 반복간격보다 클 수 있다. 또한, 프로세서는 목표반복간격 중의 점 위치 또는 스케 일 팩터 등 양자화 파라미터를 확정할 수 있으며, 구체적 확정방식은 위의 설명을 참조할 수 있다. 예를 들어, 현재 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복간격이 3이면, 프로세서는 당해 목표반복간격이 제100회 반복, 제101회 반복 및 제102회 반 복의 3회 반복을 포함하는 것을 확정할 수 있다. 프로세서는 제100회 반복의 양자화 대상 데이터에 근거하여 양 자화 오차를 확정하고, 양자화 오차에 근거하여 제2 오차와 제100회 반복에 대응하는 목표데이터 비트폭을 확정 하며, 당해 목표데이터 비트폭을 목표반복간격에 대응하는 데이터 비트폭으로 할 수 있다. 여기에서, 제100회 반복, 제101회 반복 및 제102회 반복에 대응하는 데이터 비트폭은 모두 당해 제100회 반복에 대응하는 목표데이 터 비트폭이다. 프로세서는 당해 제100회 반복의 양자화 대상 데이터와 당해 제100회 반복에 대응하는 목표데이 터 비트폭에 근거하여 당해 제100회 반복에 대응하는 점 위치와 스케일 팩터 등 양자화 파라미터를 확정할 수도 있다. 그 다음에는, 당해 제100회 반복에 대응하는 양자화 파라미터를 채용하여 제100회 반복, 제101회 반복 및 제102회 반복을 양자화한다. 또한, 도8V에 도시된 바와 같이, 본 발명의 또 하나의 실시예의 양자화 파라미터 조정방법(800V)의 흐름도를 도 시한다. 상술한 방법은 다음과 같은 단계를 포함할 수 있다. 현재 반복이 제1 미리 설정된 반복보다 큰 경우, 프로세서는 작업(S712)을 실행할 수도 있다. 즉 프로세서는 현 재 반복이 제2 미리 설정된 반복보다 큰지 여부를 더 확정할 수 있다. 여기에서, 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간격이 상기 제1 미리 설정된 반복간격보다 도 크다. 바람직하게는, 상술한 제2 미리 설정된 반복은 하이퍼 파라미터일 수 있고, 제2 미리 설정된 반복은 적어도 하나의 훈련주기의 총반복수보다도 클 수 있다. 바람직하게는, 제2 미리 설정된 반복은 양자화 대상 데 이터의 데이터 변동곡선에 따라 확정할 수 있다. 바람직하게는, 제2 미리 설정된 반복은 사용자가 자신의 이해 에 따라 설정한 것일 수도 있다. 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 프로세서는 작업(S714)을 실행할 수 있으며, 제2 미리 설 정된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 신경망양자화 과정 중의 파라미터를 조정한다. 현재 반복이 제1 미리 설정된 반복보다 크고, 또 현재 반복이 제2 미리 설정된 반복보다 작은 경우, 프로세서는 상술한 작업(S713)을 실행할 수 있으며, 상기 양자화 대상 데이터의 데이터 변 동폭에 근거하여 목표반복간격을 확정하고 상기 목표반복간격에 근거하여 양자화 파라미터를 조정한다. 바람직하게는, 프로세서는 사용자가 설정한 제2 미리 설정된 반복을 판독하고, 제2 미리 설정된 반복과 제2 미 리 설정된 반복간격의 대응관계에 근거하여 제2 미리 설정된 반복간격을 확정할 수 있으며, 당해 제2 미리 설정 된 반복간격은 제1 미리 설정된 반복간격보다 크다. 바람직하게는, 상기 신경망의 수렴정도가 미리 설정된 조건 을 충족시키면, 상기 현재 반복이 제2 미리 설정된 반복 이상이라고 확정한다. 예를 들어, 현재 반복의 순방향 연산결과가 미리 설정된 기준 값에 근접했을 경우, 당해 신경망의 수렴정도가 미리 설정된 조건을 충족시킨다고 확정할 수 있다. 이 때 현재 반복이 제2 미리 설정된 반복 이상이라고 확정할 수 있다. 또는, 현재 반복에 대응 하는 손실 값이 미리 설정된 한계 값 이하인 경우, 당해 신경망의 수렴정도가 미리 설정된 조건을 충족시킨다고 확정할 수 있다. 바람직하게는, 상술한 제2 미리 설정된 반복간격은 하이퍼 파라미터일 수 있고, 당해 제2 미리 설정된 반복간격 은 적어도 한 훈련주기의 총반복수 이상일 수 있다. 바람직하게는, 당해 제2 미리 설정된 반복간격은 사용자가 자신의 이해에 따라 설정한 것일 수 있다. 프로세서는 사용자가 입력한 제2 미리 설정된 반복과 제2 미리 설정 된 반복간격을 직접 판독하고, 당해 제2 미리 설정된 반복간격에 근거하여 신경망 연산 중의 양자화 파라미터를 업데이트할 수 있다. 예를 들어, 당해 제2 미리 설정된 반복간격은 한 훈련주기의 총반복수와 같을 수 있다. 즉 각 훈련주기（epoch）에서 양자화 파라미터를 1회 업데이트한다. 또한, 상술한 방법은 다음과 같은 단계를 더 포함한다. 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 프로세서는 매번 검사 반복에서 현재 데이터 비트폭을 조 정할 필요가 있는지 여부를 확정할 수도 있다. 현재 데이터 비트폭을 조정할 필요가 있으면, 프로세서는 상술한 작업(S714)에서 작업(S713)으로 전환하여 데이터 비트폭을 다시 확정하며, 데이터 비트폭이 양자화 대상 데이터 의 요구사항을 충족시키도록 할 수 있다. 구체적으로는, 프로세서는 상술한 제2 오차에 근거하여 데이터 비트폭을 조정할 필요가 있는지 여부를 확정할 수 있다. 프로세서는 상술한 작업(S715)을 실행할 수 있으며, 제2 오차가 미리 설정된 오차 값보다 큰지 여부를 확정한다. 상기 현재 반복이 제2 미리 설정된 반복 이상이고, 또 상기 제2 오차가 미리 설정된 오차 값보다 큰 경우, 작업(S713)으로 전환하여 실행하며, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확 정하며, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 한다. 현재 반복이 제2 미리 설정된 반복 이상이고, 또 제2 오차가 미리 설정된 오차 값 이하이면, 작업(S714)을 계속하여 실행하며, 제2 미리 설정 된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 신경망양자화 과 정 중의 파라미터를 조정한다. 여기에서, 미리 설정된 오차 값은 양자화 오차에 대응하는 미리 설정된 한계 값 에 근거하여 확정될 수 있다. 제2 오차가 미리 설정된 오차 값보다 클 경우, 이 때 데이터 비트폭은 진일보로 조정할 필요가 있으며, 프로세서는 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확정하고, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 할 수 있다. 예를 들어, 제2 미리 설정된 반복간격은 한 훈련주기의 총반복수이다. 현재 반복이 제2 미리 설정된 반복 이상 인 경우, 프로세서는 제2 미리 설정된 반복간격에 근거하여 양자화 파라미터를 업데이트할 수 있다. 즉 각 훈련 주기（epoch）에서 양자화 파라미터를 1회 업데이트한다. 이 때, 각 훈련주기의 처음 반복은 하나의 검사 반복 으로서, 각 훈련주기의 처음 반복에서, 프로세서는 당해 검사 반복의 양자화 대상 데이터에 근거하여 양자화 오차를 확정할 수 있으며, 양자화 오차에 근거하여 제2 오차를 확정하고, 다음과 같은 수학식에 따라 제2 오차가 미리 설정된 오차 값보다 큰지 여부를 확정한다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "여기에서, 는 제2 오차이고, 는 양자화 오차이며, 는 하이퍼 파라미터이고, 는 미리 설정된 오 차 값이다. 바람직하게는, 당해 미리 설정된 오차 값은 제1 미리 설정된 한계 값을 하이퍼 파라미터로 나눈 것 과 같다. 물론, 당해 미리 설정된 오차 값은 하이퍼 파라미터일 수도 있다. 예를 들어, 당해 미리 설정된 오차 값은 다음과 같은 수학식 =th/10 따라 계산하여 획득할 수 있다. 여기에서, th는 제1 미리 설정된 한계 값이고, 하이퍼 파라미터의 값은 10이다. 제2 오차 가 미리 설정된 오차 값 보다 크면, 데이터 비트폭이 가능하게 미리 설정된 요구사항을 충 족시킬 수 없다는 것을 설명한다. 이 때, 제2 미리 설정된 반복간격을 채용하여 양자화 파라미터를 업데이트하 지 않아도 되며, 프로세서는 양자화 대상 데이터의 데이터 변동폭에 따라 목표반복간격을 확정하여 데이터 비트 폭이 미리 설정되 요구사항을 충족시키도록 보장할 수 있다. 즉 제2 오차 가 미리 설정된 오차 값 보 다 큰 경우, 프로세서는 상술한 작업(S714)에서 상술한 작업(S713)으로 전환한다. 물론, 다른 실시예에서, 프로세서는 상술한 양자화 오차에 근거하여 데이터 비트폭을 조정할 필요가 있는지 여 부를 확정할 수 있다. 예를 들어, 제2 미리 설정된 반복간격은 한 훈련주기의 총반복수이다. 현재 반복이 제2 미리 설정된 반복 이상인 경우, 프로세서는 제2 미리 설정된 반복간격에 근거하여 양자화 파라미터를 업데이트 할 수 있다. 즉 각 훈련주기（epoch）에서 양자화 파라미터를 1회 업데이트한다. 여기에서, 각 훈련주기의 처음 반복은 하나의 검사 반복으로서, 각 훈련주기의 처음 반복에서, 프로세서는 당해 검사 반복의 양자화 대상 데이 터에 근거하여 양자화 오차를 확정할 수 있으며, 당해 양자화 오차가 제1 미리 설정된 한계 값 이상인 경우, 데 이터 비트폭이 가능하게 미리 설정된 요구사항을 충족시킬 수 없다는 것을 설명한다. 즉 프로세서는 상술한 작 업(S714)에서 상술한 작업(S713)으로 전환한다. 하나의 바람직한 실시예에서, 상술한 점 위치, 스케일 팩터 및 오프셋 등 양자화 파라미터는 표시장치를 통해 표시될 수 있다. 이 때, 사용자는 표시장치를 통해 신경망 연산과정에서의 양자화 파라미터를 알 수 있으며, 사 용자는 지기 적응적으로 프로세서가 확정한 양자화 파라미터를 수정할 수도 있다. 마찬가지로, 상술한 데이터 비트폭과 목표반복간격 등도 표시장치를 통해 표시될 수 있다. 이 때, 사용자는 표시장치를 통해 신경망 연산과 정에서의 목표반복간격과 데이터 비트폭 등 파라미터를 알 수 있고, 또한 사용자는 자기 적응적으로 프로세서가 확정한 목표반복간격과 데이터 비트폭 등 파라미터를 수정할 수도 있다. 설명할 필요가 있는 것은, 상술한 데이터 비트폭의 목표반복간격과 양자화 파라미터의 목표반복간격을 확정하는"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "것은 모두 예로서 모든 상황이 아니라 일부 상황만 열거할 뿐이며, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명 기술방안의 본질을 이해한 뒤에 본 발명의 기술방안을 기반으로 다른 변형 또는 변환을 이룰 수 있다. 예를 들어, 데이터 비트폭의 목표반복간격을 확정하는 동안에 또 양자화 파라미터의 목표반복간 격을 확정하는 것도 도6, 도7 및 도8A에 도시된 기술방안에 적용된ㄷ. 그러나, 그 실현된 기능 및 달성한 기술 적 효과가 본 발명과 유사하면, 모두 본 발명의 보호범위에 속하는 것이다. 본 기술방안을 이용하여 양자화 파라미터를 확정하고, 양자화 오차에 근거하여 데이터 비트폭 또는 양자화 파라 미터를 조정하며, 데이터 비트폭 또는 양자화 파라미터에 대해 조정할지 여부의 목표반복간격을 확정하였고, 신 경망 연산과정에서 적절한 시점에서 데이터 비트폭 또는 양자화 파라미터에 대한 조정을 달성하여, 적절한 반복 시점에서 적절한 양자화 파라미터를 사용하게 하며, 인공지능 프로세서 칩이 신경망 연산을 실행하는 속도를 고 정 소수점 연산의 속도에 달하게 하고, 인공지능 프로세서 칩의 피크 연산력을 향상시킴과 동시에 연산에 필요 한 부동 소수점 연산의 정밀도를 충족시킨다. 설명할 필요가 있는 것은, 상술한 각 방법 실시예에 대하여, 설명의 편의를 위해, 이들을 동작의 일련 조합으로"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "서 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 본 발명은 설명된 동작의 순서에"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "의해 한정되지 않는다는 것을 인식해야 한다. 본 발명에 따르면, 특정 단계는 다른 순서를 채용하거나 동시에수행할 수 있기 때문이다. 따라서, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 명세서에서 설명 된 실시예는 모두 선택할 수 있는 실시예에 속하며, 관련되는 동작과 모듈은 반드시 본 발명에 필수적인 것이 아니라는 것도 인식해야 한다 . 진일보로 설명할 필요가 있는 것은, 도2, 도6, 도7, 도8A 내지 도8V의 흐름도 중의 각 단계는 화살표의 지시에 따라 순서대로 표시하고 있지만, 이들 단계는 반드시 화살표로 지시한 순서대로 순차적으로 실행되는 것이 아니 다. 이 명세서에서 명시적으로 기재되지 않는 한, 이들 단계의 실행에는 엄밀한 순서제한이 없고, 이들 단계는 다른 순서로 실행될 수 있다. 그리고, 도2, 도6, 도7, 도8A 내지 도8V중의 적어도 일부 단계는 복수의 서브 단 계 또는복수의 공정을 포함하며, 이들 서브 단계 또는공정은 반드시 동일한 시점으로 실행완료하는 것이 아니라, 다른 시점으로 실행되어도 좋다. 또한 이들 서브 단계 또는 공정의 실행순서도 반드시 순서대로 진행하 는 것이 아니라, 다른 단계 또는 다른 단계의 서브 단계 또는 공정의 적어도 일부와 번갈아 또는 교대로 실행할 수 있다. 도9에 도시된 바와 같이, 본 발명에 제안된 신경망의 양자화 파라미터 확정장치의 하드웨어 구성의 블록도이다. 도9에서, 신경망의 양자화 파라미터 확정장치는 프로세서와 메모리를 포함한다. 도9의 신경망의 양자화 파라미터 확정장치에는 본 실시예와 관련된 구성요소만 도시되어 있다. 따라서, 신경망의 양자화 파 라미터 확정장치가 도10에 도시된 구성요소와 다른 공통의 구성요소를 더 포함할 수 있다는 것은 본 발명이"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "속하는 기술분야에서 통상의 지식을 가진 자라에게 자명할 것이다. 예를 들어, 고정 소수점 연산기 등. 신경망의 양자화 파라미터 확정장치는 각종 처리기능을 갖는 계산기기, 예를 들어, 신경망의 생성, 신경망 의 훈련 또는 학습, 부동 소수점형 신경망의 고정 소수점형 신경망에의 양자화, 또는 신경망의 재훈련 등 기능 에 대응될 수 있다. 예를 들어, 신경망의 양자화 파라미터 확정장치는 각종 유형의 기기, 예를 들어 개인용 컴퓨터(PC), 서버 기기, 모바일 기기 등으로서 실현될 수 있다. 프로세서는 신경망의 양자화 파라미터 확정장치의 모든 기능을 제어한다. 예를 들어, 프로세서는 신경망의 양자화 파라미터 확정장치의 메모리에 저장된 프로그램을 실행함으로써, 신경망의 양자화 파 라미터 확정장치의 모든 기능을 제어한다. 프로세서는 신경망의 양자화 파라미터 확정장치에서 제 공되는 중앙처리장치(CPU), 그래픽 처리장치(GPU), 애플리케이션 프로세서(AP), 인공지능 프로세서 칩（IPU）등 에 의해 실현될 수 있다. 그러나, 본 발명은 이에 한정되지 않는다. 메모리는 신경망의 양자화 파라미터 확정장치에서 처리되는 각종 데이터를 저장하기 위한 하드웨어이 다. 예를 들어, 메모리는 신경망의 양자화 파라미터 확정장치에서 처리된 데이터 및 처리될 데이터을 저장할 수 있다. 메모리는 프로세서가 이미 처리한 또는 처리하려는 신경망 연산과정에 관련된 데이 터 세트, 예를 들어, 미훈련된 초기 신경망의 데이터, 훈련과정에서 생성된 신경망의 중간 데이터, 모든 훈련이 완료된 신경망의 데이터, 양자화된 신경망의 데이터 등을 저장할 수 있다. 또한, 메모리는 신경망의 양자 화 파라미터 확정장치에 의해 구동될 애플리케이션, 드라이버 프로그램 등을 저장할 수 있다. 예를 들어, 메모리는 프로세서에 의해 실행될 신경망의 훈련 알고리즘, 양자화 알고리즘 등에 관련된 각종 프로 그램을 저장할 수 있다. 메모리는 DRAM일 수 있지만, 본 발명은 이에 한정되지 않는다. 메모리는 휘 발성 메모리 또는 비 휘발성 메모리 중의 적어도 한 가지이다. 비 휘발성 메모리는 읽기 전용 메모리(ROM), 프 로그래밍 가능 ROM(PROM), 전기적 프로그래밍 가능 ROM(EPROM), 전기적 소거 가능 프로그래밍 가능 ROM(EEPROM), 플래시 메모리, 상 변화 RAM(PRAM), 자기 RAM(MRAM), 저항 RAM(RRAM), 강유전성 RAM (FRAM) 등을 포함할 수 있다. 휘발성 메모리는 다이나믹 RAM(DRAM), 스태틱 RAM(SRAM), 동기식 DRAM(SDRAM), PRAM, MRAM, RRAM, 강유전성 RAM(FeRAM) 등을 포함할 수 있다. 실시예에서는, 메모리는 하드 디스크 드라이브(HDD), 솔 리드 스테이트 드라이브 (SSD), 고밀도 플래시 메모리 (CF), 보안 디지털 (SD) 카드, 마이크로 보안 디지털 (Micro-SD) 카드, 미니 보안 디지털 (Mini -SD) 카드, 제한 디지털 (xD) 카드, 캐쉬(caches) 또는 메모리 스틱 중 적어도 하나를 포함할 수 있다. 프로세서는 주어진 초기 신경망을 반복적으로 훈련(학습)하여 훈련된 신경망을 생성할 수 있다. 이 상태에 서, 신경망의 처리 정확도를 보장한다는 의미에서 초기 신경망의 파라미터는 고정밀도 데이터 표현형식, 예를 들어 32비트 부동 소수점 정밀도를 가진 데이터 표현형식이다. 파라미터는 신경망에(부터) 입력(출력)하는 각종 유형의 데이터, 예를 들어, 신경망의 입력/출력뉴런, 가중치, 바이어스 등을 포함할 수 있다. 고정 소수점 연산 과 비교하면, 부동 소수점 연산과정에서는 상대적으로 대량의 연산과 상대적으로 빈번한 메모리 액세스가 필요 하다. 구체적으로는, 신경망 처리에 필요한 대부분 연산은 다양한 컨볼루션 연산인 것이 알려져 있다. 따라서, 처리성능이 상대적으로 낮은 모바일 기기(스마트 폰, 태블릿, 웨어러블 디바이스 등, 임베디드 디바이스 등 )에서, 신경망의 고정밀도 데이터 연산은 모바일 기기의 리소스가 충분히 활용되지 않게 한다. 결과적으로, 허용되 는 정밀도 손실범위 내에서 신경망 연산을 구동하고, 상술한 기기에서의 연산량을 충분히 감소하기 위해, 신경 망 연산과정에 관련된 고정밀도 데이터를 양자화하여 저정밀도의 고정 소수점 수로 변환할 수 있다. 신경망을 전개하는 예를 들어 모바일 기기, 임베디드 디바이스 등 기기의 처리성능을 고려하면, 신경망의 양자 화 파라미터 확정장치는 훈련된 신경망의 파라미터를 특정 비트수를 가진 고정 소수점형으로 변환하는 양자 화를 실행하며, 또한 신경망의 양자화 파라미터 확정장치는 신경망을 전개하는 기기에 대응하는 양자화 파 라미터를 송신하여, 인공지능 프로세서 칩이 훈련, 미조정 등 연산작업을 실행할 때에 고정 소수점 수 연산 작 업을 실행하도록 한다. 신경망을 전개하는 기기는 신경망을 사용하여 음성식별, 화상식별 등을 실행하는 자율 차량, 로봇, 스마트 폰, 태블릿 기기, 증강현실(AR) 기기, 사물 인터넷(IoT) 기기 등일 수 있지만, 본 발명은 이에 한정되지 않는다. 프로세서는 메모리부터 신경망 연산과정에서의 데이터를 획득한다. 당해 데이터는 뉴런, 가중치, 바 이어스 및 그래디언트 중의 적어도 한 가지 데이터를 포함하며, 도2에 도시된 기술방안을 이용하여 대응하는 양 자화 파라미터를 확정하고, 양자화 파라미터를 이용하여 신경망 연산과정에서의 목표데이터를 양자화한다. 양자 화 후의 데이터로 신경망 연산작업을 실행한다. 당해 연산작업은 훈련, 미조정, 추론을 포함하지만, 이에 한정 되지 않는다. 프로세서는 양자화 오차 에 근거하여 데이터 비트폭 n을 조정하며, 또 프로세서는 도6, 도7 및 도8에 도시된 목표반복간격의 방법의 프로그램을 실행하여 데이터 비트폭의 목표반복간격 또는 양자화 파라미터 의 목표반복간격을 확정할 수 있다. 이상과 같이, 본 명세서 실시예에 의해 제공되는 신경망의 양자화 파라미터 확정장치에서, 메모리와 프로 세서에 의해 실현되는 구체적 기능은, 본 명세서의 전술한 실시예와 비교하여 설명될 수 있으며, 전술항 실시예의 기술적 효과를 달성할 수 있으므로, 여기에서는 다시 언급하지 않는다. 본 실시예에서, 상기 프로세서는 임의의 적절한 방식으로 실현될 수 있다. 예를 들어, 상기 프로세서(11 0)는, 예를 들어, 마이크로 프로세서 또는 프로세서 및 당해 （마이크로）프로세서에 의해 실행 가능한 컴퓨터 판독 가능 프로그램 코드（예를 들어 소프트웨어 또는 펌웨어）가 저장된 컴퓨터 판독 가능 매체, 로직 게이트, 스위치, 특정용도용 직접회로（Application Specific Integrated Circuit, ASIC）, 프로그램 가능 로직 제어기 및 임베디드 마이크로 컨트롤러 등 형식을 채용할 수 있다. 도10에 도시된 바와 같이, 본 발명에 제안된 신경망의 양자화 파라미터 확정장치를 인공지능 프로세서 칩에 적 용한 응용 모식도이다. 도10을 참조하면, 상술한 바와 같이, PC, 서버 등 신경망의 양자화 파라미터 확정장치 에서, 프로세서가 양자화 작업을 실행하여 신경망 연산과정에서에 관련된 부동 소수점 데이터를 고정 소수점 수로 양자화하고, 인공지능 프로세서 칩의 고정 소수점 연산기가 양자화하여 획득한 고정 소수점 수를 채용하여 훈련, 미조정 또는 추론을 실행한다. 인공지능 프로세서 칩은 신경망을 구동하기 위한 전용 하드웨어 이다. 인공지능 프로세서 칩은 상대적으로 낮은 전력 또는 성능으로 실현되므로, 본 기술방안을 이용하여 저정 밀도의 고정 소수점 수로 신경망 연산을 실현하는 것은, 고정밀도 데이터에 비해, 저정밀도의 고정 소수점 수를 판독하는 데 필요한 메모리 대역폭이 더 작으며, 인공지능 프로세서 칩의 캐쉬(caches)를 더 잘 사용할 수 있고, 액세스 병목현상을 회피할 수 있다. 동시에, 인공지능 프로세서 칩에서 SIMD 명령을 실행할 때, 한 클록 주기에서 더 많은 계산을 실현하여, 더 빠르게 신경망 연산작업을 실행할 수 있다. 또한, 같은 길이의 고정 소수점 연산과 고정밀도 데이터 연산, 특히 고정 소수점 연산과 부동 소수점 연산 간의 비교에서 알 수 있는 바와 같이, 부동 소수점 연산의 계산모드가 더 복잡하고, 더 많은 논리 디바이스로 부동 소수점 연산기를 구성한다. 이러한 방식으로 부피적으로는, 부동 소수점 연산기의 부피는 고정 소수점 연산기의 부피보다 크다. 또한, 부동 소수점 연산기는 처리를 위해 보다 많은 리소스를 소비해야 하며, 고정 소수점 연산 과 부동 소수점 연산 사이의 소비전력 격차가 일반적으로 수십 배가 된다. 이상과 같이, 본 기술방안은 인공지능 프로세서 칩 상의 부동 소수점 연산기를 고정 소수점 연산기에 교환할 수 있으므로, 인공지능 프로세서 칩의 소비전력을 낮게 할 수 있다. 이것은 모바일 기기에 있어서 특히 중요하다. 즉, 본 기술방안은 부동 소수점 계산 코드를 효율적으로 실행할 수 없는 수많은 임베디드 시스템에 대한 문을 열어 사물 인터넷 세계의 광범위한 응용을 가능하게 한다. 본 기술방안에서, 인공지능 프로세서 칩은, 예를 들어, 신경처리유닛(NPU), 덴소루 처리유닛(TPU), 뉴라루 엔진 등에 대응할 수 있으며, 이들은 신경망을 구동하기 위한 전용 칩이지만, 본 발명은 이에 한정되지 않는다. 본 기술방안에서, 인공지능 프로세서 칩은 신경망의 양자화 파라미터 확정장치와 독립적인 별도의 기기에서 실현될 수 있고, 신경망의 양자화 파라미터 확정장치는 인공지능 프로세서 칩의 일부 기능모듈로 실현할 수 있다. 그러나 본 발명은 이에 한정되지 않는다. 본 기술방안에서, 범용 프로세서（예를 들어 CPU）의 운영체제은 본 기술방안을 기반으로 명령을 생성하고, 생 성된 명령을 인공지능 프로세서 칩（예를 들어 GPU）에 송신하며, 인공지능 프로세서 칩이 명령을 실행하여 신 경망의 양자화 파라미터의 확정 및 양자화 과정을 실현한다. 다른 한 응용에서, 범용 프로세서는 본 기술방안을 기반으로 대응하는 양자화 파라미터를 직접 확정하고, 범용 프로세서가 직접 양자화 파라미터에 근거하여 대응 하는 목표데이터를 양자화하며, 인공지능 프로세서 칩이 양자화 후의 데이터를 이용하여 고정 소수점 연산 작업 을 실행한다. 또한, 범용 프로세서（예를 들어 CPU）와 인공지능 프로세서 칩（예를 들어 GPU）이 유선형 작업 을 하며, 범용 프로세서（예를 들어CPU）의 운영체제가 본 기술방안을 기반으로 명령을 생성하고, 또 목표데이 터를 복사함과 동시에 인공지능 프로세서 칩（예를 들어GPU）이 신경망 연산작업을 수행한다. 이러한 방식으로 일정한 시간소비를 은폐할 수 있다. 그러나 본 발명은 이에 한정되지 않는다. 본 실시예에서, 본 발명 실시예는 컴퓨터 프로그램이 저장된 판독 가능한 저장매체도 제공하며, 상기 컴퓨터 프 로그램은 실행될 때 상술한 신경망의 양자화 파라미터 확정방법을 실현한다. 이상에서 불 수 있듯이, 신경망 연산과정에서, 양자화할 때 본 발명의 기술방안을 이용하여 양자화 파라미터를 확정하고, 당해 양자화 파라미터는 인공지능 프로세서가 신경망 연산과정에서 데이터를 양자화하는 데 사용되며, 고정밀도 데이터를 저정밀도 고정 소수점 수로 변환하면, 신경망 연산과정에 관련된 데이터의 모든 저장공간의 크기를 감소할 수 있다. 예를 들어, float32를 fix8로 변환하면 모델 파라미터를 4배 감소할 수 있 다. 데이터 저장공간이 작아지므로, 신경망 전개시에 보다 작은 공간을 사용하게 되며, 인공지능 프로세서 칩 상의 온 칩 메모리가 보다 많은 데이터를 수용할 수 있고, 인공지능 프로세서 칩의 데이터 액세스를 감소하였으 며, 계산성능을 향상시킨다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 22, "content": "본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면, 순수한 컴퓨터 판독 가능 프로그램 코드방식으로 클라이언트 및 서버를 실현하는 것 외에도, 완전히 방법단계를 논리적으로 프로그램함느로써 클라이언트 및 서 버가 로직 게이트, 스위치, 특정용도용 직접회로, 프로그램 가능 로직 제어기 및 임베디드 마이크로 컨트롤러 등의 형식으로 동일한 기능을 실현할 수 있다는 것을 알 수 있다. 따라서 이러한 클라이언트 및 서버는 하드웨 어 부품으로 간주할 수 있으며, 그 내부에 포함된 각종 기능을 실현하기 위한 장치도 하드웨어 부품 내의 구조 로 간주할 수 있다. 혹은, 각종 기능을 실현하기 위한 장치를 방법을 실현하는 소프트웨어 모듈로 간주할 수도 있고, 하드웨어 부품 내의 구조로 간주할 수도 있다. 도11에 도시된 바와 같이, 본 발명에 제안된 신경망의 양자화 파라미터 확정기기의 기능 블록도이다. 상기 기기 는 통계유닛(a)과 양자화 파라미터 확정유닛(b)을 포함한다. 통계유닛(a)은 양자화 대상 데이터를 통계하여 각 종류의 양자화 대상 데이터의 통계결과를 확정는 데 사용된다. 여기에서, 상기 양자화 대상 데이터는 상기 신경망의 뉴런, 가중치 그래디언트, 바이어스 중의 적어 도 한 가지 데이터를 포함한다. 양자화 파라미터 확정유닛(b)은 각 종류의 양자화 대상 데이터의 통계결과 및 데이터 비트폭을 이용하여 대응하 는 양자화 파라미터를 확정하는 데 사용된다. 여기에서, 상기 양자화 파라미터는 인공지능 프로세서가 신경망 연산과정에서 데이터에 대해 대응하는 양자화를 수행하는 데 사용된다. 본 실시예에서, 바람직하게는, 상기 신경망의 양자화 파라미터 확정기기는 제1 양자화 유닛을 더 포함한다. 제1 양자화 유닛은 대응하는 양자화 파라미터를 이용하여 상기 양자화 대상 데이터를 양자화하는 데 사용된다. 본 실시예에서, 바람직하게는, 상기 신경망의 양자화 파라미터 확정기기는 제2 양자화 유닛을 더 포함한다. 제2 양자화 유닛은 대응하는 양자화 파라미터를 이용하여 목표데이터를 양자화하는 데 사용된다. 여기에서, 상 기 목표데이터의 특징은 상기 양자화 대상 데이터의 특징과 유사성이 있다. 본 실시예에서, 상기 신경망 연산과정은 신경망 훈련, 신경망 추론, 신경망 미조정 중의 적어도 한 가지 연산을 포함한다. 본 실시예에서, 상기 통계유닛이 획득한 통계결과는 각 종류의 양자화 대상 데이터 중의 최대 값과 최소 값이다. 본 실시예에서, 상기 통계유닛이 획득한 통계결과는 각 종류의 양자화 대상 데이터 중의 절대치 최대 값이다. 본 실시예에서, 상기 통계유닛은 각 종류의 양자화 대상 데이터 중의 최대 값과 최소 값에 근거하여 상기 절대 치 최대 값을 확정한다. 본 실시예에서, 상기 양자화 파라미터 확정유닛은 각 종류의 양자화 대상 데이터 중의 최대 값, 최소 값 및 상 기 데이터 비트폭에 근거하여 양자화 파라미터를 확정한다. 본 실시예에서, 상기 양자화 파라미터 확정유닛은 각 종류의 양자화 대상 데이터 중의 절대치 최대 값, 상기 데 이터 비트폭에 근거하여 양자화 파라미터를 확정한다. 본 실시예에서, 상기 양자화 파라미터 확정유닛이 확정한 상기 양자화 파라미터는 점 위치 파라미터 또는 제1 스케일 팩터이다. 본 실시예에서, 상기 양자화 파라미터 확정유닛은 점 위치 파라미터와 제2 스케일 팩터에 근거하여 상기 제1 스 케일 팩터를 확정한다. 여기에서, 제1 스케일 팩터를 확정할 때 사용한 점 위치 파라미터는 기지의 고정 값, 또 는 상기 점 위치 파라미터와 대응하는 상기 제2 스케일 팩터를 곱셈한 결과 전체가 제1 스케일 팩터로서 신경망 연산과정의 데이터 양자화에 응용된다. 본 실시예에서, 상기 양자화 파라미터 확정유닛이 확정한 상기 양자화 파라미터는 점 위치 파라미터와 제2 스케 일 팩터를 포함한다. 본 실시예에서, 상기 양자화 파라미터 확정유닛은 상기 점 위치 파라미터, 상기 통계결과, 상기 데이터 비트폭 에 근거하여 상기 제2 스케일 팩터를 확정한다. 본 실시예에서, 상기 양자화 파라미터 확정유닛이 확정한 상기 양자화 파라미터는 오프셋도 포함한다. 본 실시예에서, 상기 양자화 파라미터 확정유닛은 각 종류의 양자화 대상 데이터의 통계결과에 근거하여 상기 오프셋을 확정한다. 본 실시예에서, 상기 양자화 파라미터 확정유닛이 사용한 데이터 비트폭을 미리 설정된 값이다. 본 실시예에서, 상기 양자화 파라미터 확정유닛은 조정모듈과 양자화 오차 확정모듈을 포함하며, 여기에서, 상기 조정모듈은 대응하는 양자화 오차에 근거하여 데이터 비트폭을 조정하는 데 사용되고; 상기 양자화 오차 확정모듈은 양자화 후의 데이터와 대응하는 양자화 전의 데이터에 근거하여 상기 양자화 오차 를 확정하는 데 사용되다. 본 실시예에서, 상기 조정모듈은 구체적으로, 상기 양자화 오차와 한계 값을 비교하고, 비교결과에 근거하여 상 기 데이터 비트폭을 조정한다. 여기에서, 상기 한계 값은 제1 한계 값과 제2 한계 값 중의 적어도 하나를 포함 한다. 본 실시예에서, 상기 조정모듈은 제1 조정 서브 모듈을 포함한다. 여기에서, 상기 제1 조정 서브 모듈은 상기 양자화 오차가 상기 제1 한계 값 이상인 경우 상기 데이터 비트폭을 증가하는 데 사용된다. 본 실시예에서, 상기 조정모듈은 제2 조정 서브 모듈을 포함한다. 여기에서, 상기 제2 조정 서브 모듈은 상기 양자화 오차가 상기 제2 한계 값 이하인 경우 상기 데이터 비트폭을 감소하는 데 사용된다. 본 실시예에서, 상기 조정모듈은 제3 조정 서브 모듈을 포함한다. 여기에서, 상기 제3 조정 서브 모듈은 상기 양자화 오차가 상기 제1 한계 값과 상기 제2 한계 값 사이에 있을 때 상기 데이터 비트폭을 변하지 않게 유지하 는 데 사용된다. 본 실시예에서, 상기 양자화 오차 확정모듈은 상기 데이터 비트폭에 근거하여 양자화 간격을 확정하기 위한 양 자화 간격확정 서브 모듈, 및 상기 양자화 간격, 상기 양자화 후의 데이터의 개수와 대응하는 양자화 전의 데이 터에 근거하여 양자화 오차를 확정하기 위한 제1 양자화 오차확정 서브 모듈을 포함한다. 본 실시예에서, 상기 양자화 오차 확정모듈은 양자화 후의 데이터를 역 양자화하여 역 양자화 데이터를 획득하 기 위한 역 양자화 데이터 확정 서브 모듈, 및 상기 양자화 후의 데이터 및 대응하는 역 양자화 데이터에 근거 하여 양자화 오차를 확정하기 위한 제2 양자화 오차확정 서브 모듈을 포함하며, 여기에서, 상기 역 양자화 데이터의 데이터 형식은 대응하는 양자화 전의 데이터의 데이터 형식과 같다. 본 실시예에서, 상기 양자화 오차 확정모듈이 사용하는 상기 양자화 전의 데이터는 상기 양자화 대상 데이터이 다. 본 실시예에서, 상기 양자화 오차 확정모듈이 사용하는 상기 양자화 전의 데이터는 목표반복간격 내의 가중치 업데이트 반복과정에 관련된 양자화 대상 데이터이다. 여기에서, 상기 목표반복간격은 적어도 1회 가중치 업데 이트 반복을 포함하며, 또 동일한 목표반복간격 내 양자화 과정에서 동일한 상기 데이터 비트폭을 채용한다. 본 실시예에서, 상기 신경망의 양자화 파라미터 확정기기는 제1 목표반복간격 확정유닛을 더 포함하며; 여기에 서, 상기 제1 목표반복간격 확정유닛은, 사전판정시점에서, 가중치 업데이트 반복과정에 관련된 양자화 대상 데이터의 점 위치 파라미터의 변화추세 값 을 확정하기 위한 제1 변화추세 값 확정모듈, 및 상기 점 위치 파라미터의 변화추세 값에 근거하여 대응하는 상 기 목표반복간격을 확정하기 위한 제1 목표반복간격모듈을 포함하며, 여기에서, 상기 사전판정시점은 상기 데이 터 비트폭을 조정할 필요가 있는지 여부를 판정하기 위한 시점이며, 상기 사전판정시점은 가중치 업데이트 반복 이 완료될 때의 시점에 대응한다. 본 실시예에서, 상기 제1 목표반복간격 확정유닛은: 사전판정시점에서, 가중치 업데이트 반복과정에 관련된 양자화 대상 데이터의 점 위치 파라미터의 변화추세 값, 데이터 비트폭의 변화추세 값을 확정하기 위한 제2 변화추세 값 확정모듈, 및 상기 점 위치 파라미터의 변화추 세 값과 상기 데이터 비트폭의 변화추세 값에 근거하여 대응하는 상기 목표반복간격을 확정하기 위한 제2 목표 반복간격모듈을 포함하며, 여기에서, 상기 사전판정시점은 상기 데이터 비트폭을 조정할 필요가 있는지 여부를 판정하기 위한 시점이고, 상기 사전판정시점은 가중치 업데이트 반복이 완료될 때의 시점에 대응한다. 본 실시예에서, 상기 제1 목표반복간격 확정유닛은 제1 사전판정시점 확정유닛을 더 포함하며; 여기에서, 상기 제1 사전판정시점 확정유닛은 상기 목표반복간격에 근거하여 상기 제1 사전판정시점을 확정하는 데 사용된다. 본 실시예에서, 상기 제1 목표반복간격 확정유닛은 포함제2 사전판정시점 확정유닛을 더 포함하며; 여기에서, 상기 제2 사전판정시점 확정유닛은 데이터 변동폭 곡선에 근거하여 제2 사전판정시점을 확정하는 데 사용되고; 여기에서, 상기 데이터 변동폭 곡선은 가중치 업데이트 반복과정 중 데이터 변동폭 상황을 통계하여 획득한 것 이다. 본 실시예에서, 상기 제1 변화추세 값 확정모듈과 상기 제2 변화추세 값 확정모듈은 모두 현재 사전판정시점에 대응하는 점 위치 파라미터의 이동평균 값, 이전 사전판정시점에 대응하는 점 위치 파라미터의 이동평균 값에 근거하여 상기 점 위치 파라미터의 변화추세 값을 확정한다. 본 실시예에서, 상기 제1 변화추세 값 확정모듈과 상기 제2 변화추세 값 확정모듈은 모두 현재 사전판정시점에 대응하는 점 위치 파라미터, 이전 사전판정시점에 대응하는 점 위치 파라미터의 이동평균 값에 근거하여 상기 점 위치 파라미터의 변화추세 값을 확정한다. 본 실시예에서, 상기 제1 변화추세 값 확정모듈과 상기 제2 변화추세 값 확정모듈은 모두 이전 사전판정시점에 대응하는 점 위치 파라미터와 상기 데이터 비트폭의 조정 값에 근거하여 상기 현재 사전판 정시점에 대응하는 점 위치 파라미터를 확정하기 위한 현재 사전판정시점에 대응하는 점 위치 파라미터 확정 서 브 모듈, 상기 데이터 비트폭의 조정 값에 근거하여 상기 이전 사전판정시점에 대응하는 점 위치 파라미터의 이동평균 값 을 조정하여 조정결과를 획득하기 위한 조정결과 확정 서브 모듈, 및 상기 현재 사전판정시점에 대응하는 점 위치 파라미터, 상기 조정결과에 근거하여 현재 사전판정시점에 대응하 는 점 위치 파라미터의 이동평균 값을 확정하기 위한 제1 이동평균 값 확정 서브 모듈을 포함한다. 본 실시예에서, 상기 제1 변화추세 값 확정모듈과 상기 제2 변화추세 값 확정모듈은 모두 이전 사전판정시점에 대응하는 점 위치 파라미터와 이전 사전판정시점에 대응하는 점 위치 파라미터의 이동평균 값에 근거하여 현재 사전판정시점에 대응하는 점 위치 파라미터의 이동평균 값의 중간결과를 확정하기 위한 중간결과 확정 서브 모듈, 및 현재 사전판정시점에 대응하는 점 위치 파라미터의 이동평균 값의 중간결과와 상기 데이터 비트폭의 조정 값에 근거하여 상기 현재 사전판정시점에 대응하는 점 위치 파라미터의 이동평균 값을 확정하기 위한 제2 이동평균 값 확정 서브 모듈을 포함한다. 본 실시예에서, 상기 제2 변화추세 값 확정모듈은 대응하는 상기 양자화 오차에 근거하여 데이터 비트폭의 변화 추세 값을 확정한다. 본 실시예에서, 상기 제1 목표반복간격 확정유닛은, 대응하는 양자화 오차를 확정하기 위한 양자화 오차 확정모듈, 및 대응하는 양자화 오차에 근거하여 상기 목표반복간격 내 양자화 과정에서 채용하는 데이터 비트폭을 확정하기 위한 데이터 비트폭 확정모듈을 포함하며, 여기에서, 상기 양자화 오차에 대응하는 양자화 전의 데이터는 상기 사전판정시점에 대응하는 가중치 업데이트 반복과정에 관련된 양자화 대상 데이터이다. 본 실시예에서, 상기 데이터 비트폭 확정모듈은 구체적으로, 상기 양자화 오차와 한계 값을 비교하고, 비교결과에 근거하여 이전 목표반복간격 내 양자화 과정에서 채용하는 데이터 비트폭을 조정하며, 조정결과를 현재 목표반복간격 내 양자화 과정에서 채용하는 데이터 비트폭으로 하 는 데 사용된다. 본 실시예에서, 상기 양자화 오차 확정모듈이 사용하는 상기 양자화 전의 데이터는 목표반복간격 내의 가중치 업데이트 반복의 경우에 관련된 양자화 대상 데이터이고; 여기에서, 상기 목표반복간격은 적어도 1회 가중치 업 데이트 반복을 포함하며, 동일한 목표반복간격 내 양자화 과정에서 동일한 상기 양자화 파라미터를 채용한다. 본 실시예에서, 상기 신경망의 양자화 파라미터 확정기기는 제2 목표반복간격 확정유닛을 더 포함하며; 여기에 서, 상기 제2 목표반복간격 확정유닛은, 사전판정시점에서, 가중치 업데이트 반복과정에 관련된 양자화 대상 데이터의 점 위치 파라미터의 변화추세 값 을 확정하기 위한 제3 변화추세 값 확정모듈, 및 상기 점 위치 파라미터의 변화추세 값에 근거하여 대응하는 상기 목표반복간격을 확정하기 위한 제3 목표반복 간격모듈을 포함하며, 여기에서, 상기 사전판정시점은 상기 양자화 파라미터에 대해 조정할 필요가 있는지 여부를 판정하기 위한 시점 이고, 상기 사전판정시점은 가중치 업데이트 반복이 완료될 때의 시점에 대응한다. 본 실시예에서, 상기 양자화 파라미터 확정유닛은 통계결과와, 상기 데이터 비트폭에 근거하여 상기 점 위치 파 라미터를 확정한다. 일 실시예에서, 데이터 비트폭을 조정하는 장치를 제공하는 바, 그 특징은: 양자화 대상 데이터에 대해 양자화 처리를 수행하기 위한 상기 양자화 대상 데이터의 상기 양자화 처리 후 양자 화 된 데이터의 비트폭을 나타내는 데이터 비트폭을 회득하기 위한 획득모듈, 상기 데이터 비트폭에 기초하여 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 수행하여 상기 1그룹의 양자 화 대상 데이터를 상기 데이터 비트폭을 갖는 1그룹의 양자화 된 데이터로 변환하기 위한 양자화 모듈, 상기 1그룹의 양자화 대상 데이터와 상기 1그룹의 양자화 된 데이터를 비교하여 상기 데이터 비트폭과 관련된 양자화 오차를 확정하기 위한 확정모듈, 및 확정된 상기 양자화 오차에 근거하여 상기 데이터 비트폭을 조정하기 위한 조정모듈을 포함한다. 본 실시예에서, 상기 비교모듈은, 상기 데이터 비트폭에 근거하여 양자화 간격을 확정하기 위한 간격확정모듈, 및 상기 양자화 간격, 상기 1그룹의 양자화 된 데이터 및 상기 1그룹의 양자화 대상 데이터에 근거하여 상기 양자 화 오차를 확정하기 위한 오차 확정모듈을 포함한다. 본 실시예에서, 상기 오차 확정모듈은, 상기 양자화 간격에 근거하여 상기 1그룹의 양자화 된 데이터에 대해 역 양자화를 수행하여 1그룹의 역 양자화 데이터를 획득하는 데 사용되고, 상기 1그룹의 역 양자화 데이터의 데이터 형식이 상기 1그룹의 양자화 대상 데 이터의 데이터 형식과 같은 양자화 모듈, 및 상기 1그룹의 역 양자화 데이터와 상기 1그룹의 양자화 대상 데이터에 근거하여 양자화 오차를 확정하기 위한 양자화 오차 확정모듈을 포함한다. 본 실시예에서, 상기 조정모듈은, 제1 한계 값과 제2 한계 값 중의 적어도 하나를 포함하는 미리 설정된 한계 값과 상기 양자화 오차를 비교하기 위한 비교모듈, 및 상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하기 위한 비트폭 조정모듈을 포함한다. 본 실시예에서, 상기 비트폭 조정모듈은, 상기 양자화 오차가 제1 한계 값 이상임의 확정에 응답하여 상기 데이터 비트폭을 증가하기 위한 증가모듈을 포 함한다. 본 실시예에서, 상기 증가모듈은, 제1 미리 설정된 비트폭 스텝에 근거하여 상기 데이터 비트폭을 증가시켜 조정 후 데이터 비트폭을 확정하기 위 한 스텝 증가모듈을 포함한다. 본 실시예에서, 상기 양자화 모듈은 진일보로 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대 상 데이터에 대해 양자화 처리를 실행하여 상기 1그룹의 양자화 대상 데이터를 다른 1그룹의 양자화 된 데이터 로 변환하는 데 사용되며, 상기 다른 1그룹의 양자화 된 데이터는 상기 조정 후 데이터 비트폭을 가지며; 및 상기 확정모듈은 진일보로 상기 1그룹의 양자화 대상 데이터와 상기 다른 1그룹의 양자화 된 데이터를 비교하여, 다른 하나의 양자화 오차가 상기 제1 미리 설정된 한계 값보다 작을 때까지 상기 조정 후 데이터 비 트폭과 관련되는 다른 하나의 양자화 오차를 확정하는 데 사용된다. 본 실시예에서, 상기 장치는 반복적으로 호출된다. 본 실시예에서, 상기 조정모듈은, 상기 양자화 오차가 상기 제2 한계 값 이하임을 확정하는 것에 응답하여 상기 데이터 비트폭을 감소시키기 위한 감소모듈을 포함한다. 본 실시예에서, 상기 감소모듈은, 제2 미리 설정된 비트폭 스텝에 근거하여 상기 데이터 비트폭을 감소하여 조정 후 데이터 비트폭을 확정하기 위 한 스텝 감소모듈을 포함한다. 본 실시예에서, 상기 양자화 모듈은 진일보로 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대 상 데이터에 대해 양자화 처리를 실행하여 상기 1그룹의 양자화 대상 데이터를 다른 1그룹의 양자화 된 데이터 로 변환하는 데 사용되며, 상기 다른 1그룹의 양자화 된 데이터는 상기 조정 후 데이터 비트폭을 가지며; 및 상기 확정모듈은 진일보로 상기 1그룹의 양자화 대상 데이터와 상기 다른 1그룹의 양자화 된 데이터에 근거하여, 다른 하나의 양자화 오차가 상기 제2 미리 설정된 한계 값보다 클 때까지 상기 조정 후 데이터 비트 폭과 관련되는 다른 하나의 양자화 오차를 확정하는 데 사용된다. 본 실시예에서, 상기 장치는 반복적으로 호출된다. 본 실시예에서, 상기 조정모듈은, 상기 양자화 오차가 상기 제1 한계 값과 상기 제2 한계 값 사이에 있음을 확정하는 것에 응답하여 상기 데이터 비트폭을 유지하기 위한 유지모듈을 포함한다. 본 실시예에서, 진일보로, 상기 1그룹의 양자화 대상 데이터와 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터 에 대해 양자화 처리를 실행하기 위한 양자화 파라미터를 업데이트하기 위한 업데이트모듈, 및 진일보로 업데이트한 상기 양자화 파라미터에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리 를 실행하기 위한 상기 양자화 모듈을 포함한다. 본 실시예에서, 변동폭 모듈은 양자화 대상 데이터의 데이터 변동폭을 획득하는 데 사용되며; 간격모듈은 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복 간격에 근거하여 상기 데이터 비트폭을 조정하는 데 사용되며, 상기 목표반복간격은 적어도 1회 반복을 포함한 다. 본 실시예에서, 상기 변동폭 모듈은, 점 위치의 변동폭을 획득하기 위한 점 위치 모듈을 포함하며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이 터의 데이터 변동폭을 특성화하는 데 사용되며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변 동폭과 정의 상관이 있다. 본 실시예에서, 상기 점 위치모듈은, 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복에 대응하는 점 위치에 근거하여 제1 균치를 확정하는 데 사용되며, 상기 전회 검사 반복이 상기 목표반복간격 전의 이전 반 복간격에 대응하는 검사 반복인 제1 균치모듈; 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균 치를 확정하는 데 사용되며; 상기 현재 검사 반복에 대응하는 점 위치가 상기 현재 검사 반복에 대응하는 목표 데이터 비트폭과 양자화 대상 데이터에 의해 확정되는 제2 균치모듈; 및 상기 제1 균치와 상기 제2 균치에 근거하여 상기 점 위치의 변동폭을 특성화하기 위한 제1 오차를 확정하기 위 한 제1 오차모듈을 포함한다. 본 실시예에서, 상기 간격모듈은, 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하기 위한 제1 간격모듈을 포함하며, 상기 목표반복간격은 상기 제1 오차와 부의 상관이 있다. 본 실시예에서, 상기 변동폭 모듈은 진일보로, 상기 데이터 비트폭의 변화추세를 획득하기 위한 추세모듈; 및 상기 점 위치의 변동폭과 상기 데이터 비트폭의 변화추세에 근거하여 상기 양자화 대상 데이터의 데이터 변동폭 을 확정하기 위한 데이터 변동폭 모듈을 포함한다. 본 실시예에서, 상기 간격모듈은 진일보로, 획득한 제1 오차와 제2 오차에 근거하여 상기 목표반복간격을 확정하기 위한 반복간격모듈을 포함하며; 상기 제 1 오차는 점 위치의 변동폭을 특성화하는 데 사용되고, 상기 제2 오차는 데이터 비트폭의 변화추세를 특성화하 는 데 사용된다. 본 실시예에서, 상기 반복간격모듈은, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 하기 위한 목표오차모듈; 및 상기 목표오차에 근거하여 상기 목표반복간격을 확정하기 위한 목표반복간격모듈을 포함하며, 상기 목표오차는 상기 목표반복간격과 부의 상관이 있다. 본 실시예에서, 상기 제2 오차는 양자화 오차에 의해 확정되고; 여기에서, 상기 양자화 오차는 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데 이터에 의해 확정되며, 상기 제2 오차는 상기 양자화 오차와 정의 상관이 있다. 본 실시예에서, 상기 장치는 신경망의 훈련 또는 미조정에 사용되며, 상기 장치는 진일보로, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목 표반복간격을 확정하고, 상기 목표반복간격에 근거하여 상기 양자화 파라미터를 조정하기 위한 제1 반복모듈을 포함한다. 본 실시예에서, 상기 장치는 진일보로, 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 제1 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제1 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하기 위한 제2 반복모듈을 포함 한다. 본 실시예에서, 상기 장치는 진일보로, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 제2 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하기 위한 제3 반복모듈을 포함 하며; 여기에서, 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간 격이 상기 제1 미리 설정된 반복간격보다도 크다. 본 실시예에서, 상기 장치는 진일보로, 상기 신경망의 수렴정도가 미리 설정된 조건을 충족시키면 상기 현재 검사 반복이 제2 미리 설정된 반복 이상임 을 확정하기 위한 수렴모듈을 포함한다. 본 실시예에서, 상기 장치는 진일보로, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 또 제2 오차가 미리 설정된 오차 값보다 큰 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확정하며, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 한다. 일 실시예에서, 실행시에 위의 임의의 하나의 기술된 방법을 실현하는 컴퓨터 프로그램이 저장된 것을 특지으로 하는 컴퓨터 판독 가능한 저장매체를 제공한다. 일 실시예에서, 위의 임의의 하나의 데이터를 처리하기 위한 장치를 포함하는 것을 특징으로 하는 인공지능 칩 을 제공한다. 일 실시예에서, 위의 인공지능 칩을 포함하는 것을 특징으로 하는 전자기기를 제공한다. 일 실시예에서는, 메모리 디바이스, 인터페이스 장치와 제어 디바이스 및 위에 기재된 인공지능 칩을 포함하며, 그 중, 상기 인공지능 칩은 상기 메모리 디바이스, 상기 제어 디바이스 및 상기 인터페이스 장치와 연결되고; 상기 메모리 디바이스는 데이터를 저장하는 데 사용되고; 상기 인터페이스 장치는 상기 인공지능 칩과 외부기기 사이의 데이터 전송을 실현하는 데 사용되며, 상기 제어 디바이스는 상기 인공지능 칩의 상태를 감시하는 데 사용된다 특징으로 하는 보드 카드를 제공한다. 일 실시예에서, 상기 메모리 디바이스는 복수 그룹의 저장유닛을 포함하며, 각 그룹의 저장유닛은 버스를 통해 상기 인공지능 칩과 연결되고, 상기 저장유닛은 DDR SDRAM이며; 상기 칩은 각 상기 저장유닛의 데이터 전송과 데이터 저장을 제어하기 위한 DDR 컨트롤러를 포함하며; 상기 인터페이스 장치는 표준 PCIE 인터페이스이다. 일 실시예에서, 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터를 확정하는 것은, 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻는 것을 포함한다. 일 실시예에서, 상기 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하 는 양자화 파라미터를 얻는 것은, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터 중의 절대치 최대 값과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여 상기 목표데이터의 점 위치를 얻는 것을 포함하며, 상기 목표데이터는 임의 의 한 가지 양자화 대상 데이터이다. 일 실시예에서, 상기 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하 는 양자화 파라미터를 얻는 것은, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트 폭에 근거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻으며, 상기 목표데이터는 임의의 한 가지 양자 화 대상 데이터인 것; 및 목표데이터 중의 절대치 최대 값과 상기 목표데이터 양자화 된 데이터의 최대 값에 근거하여 상기 목표데이터의 스케일 팩터를 얻는 것을 포함한다. 일 실시예에서, 상기 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하 는 양자화 파라미터를 얻는 것은, 상기 양자화 파라미터에 오프셋이 포함된 경우, 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값 과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여, 상기 목표데이터의 점 위치를 얻는 것을 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 일 실시예에서, 상기 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하 는 양자화 파라미터를 얻는 것은, 상기 양자화 파라미터에 오프셋이 포함된 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트폭에 근 거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻으며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터인 것; 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값과 상기 목표데이터 양자화 된 데이터의 최대 값 에 근거하여 상기 목표데이터의 스케일 팩터를 얻는 것을 포함한다. 일 실시예에서, 상기 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하 는 양자화 파라미터를 얻는 것은, 목표데이터 중의 최대 값과 최소 값에 근거하여 상기 목표데이터의 오프셋을 얻는 것을 포함하며, 상기 목표데 이터는 임의의 한 가지 양자화 대상 데이터이다. 일 실시예에서, 상기 방법은, 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 상기 목표데이터의 양자화 오차를 확정하 며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터인 것; 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조정하며, 상기 목 표데이터에 대응하는 조정 비트폭을 얻는 것; 및 상기 목표데이터에 대응하는 데이터 비트폭을 상기 조정 비트폭으로 업데이트하고, 상기 목표데이터와 상기 조 정 비트폭에 근거하여 계산을 통해 대응하는 조정 양자화 파라미터를 얻으며, 상기 신경망이 상기 조정 양자화 파라미터에 근거하여 양자화하도록 하는 것을 더 포함한다. 일 실시예에서, 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조 정하며, 상기 목표데이터에 대응하는 조정 비트폭을 얻는 것은, 상기 양자화 오차가 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 증가하여 상 기 목표데이터에 대응하는 조정 비트폭을 얻는 것을 포함한다. 일 실시예에서, 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산하고; 상기 조정 후의 양자화 오차와 상기 제1 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터에 따라 계산 하여 얻은 조정 후의 양자화 오차가 상기 제1 오차 한계 값 이하로 될 때까지 상기 조정 비트폭을 계속 증가한 다. 일 실시예에서, 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조 정하는 것은, 상기 양자화 오차가 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 감소하는 것을 포함하며, 상기 제2 오차 한계 값은 상기 제1 오차 한계 값보다 작다. 일 실시예에서, 상기 방법은, 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산하는 것; 및 상기 조정 후의 양자화 오차와 상기 제2 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터에 따라 계산 을 통해 얻은 조정 후의 양자화 오차가 상기 제2 오차 한계 값 이상이 될 때까지 상기 조정 비트폭을 계속 감소 하는 것을 더 포함한다. 일 실시예에서, 상기 신경망 연산의 미조정단계 및/또는 훈련단계에서, 상기 방법은, 현재 반복 및 상기 현재 반복 전의 반복인 이력 반복 중 목표데이터의 데이터 변동폭을 획득하는 것; 및 상기 목표데이터의 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하는 것을 포함 하며, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이 터이다. 일 실시예에서, 상기 방법은, 상기 목표데이터의 상기 현재 반복에서의 데이터 비트폭에 근거하여 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 데이터 비트폭을 확정함으로써, 상기 신경망이 상기 목표데이터의 상기 목표반복간격 내의 반 복에 대응하는 데이터 비트폭에 근거하여 양자화 파라미터를 확정하도록 하는 것을 더 포함한다. 일 실시예에서, 상기 양자화 파라미터 확정모듈은, 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻기 위한 제2 양자화 파라미터 확정 서브 모듈을 포함한다. 일 실시예에서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터 중의 절대치 최대 값과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여 상기 목표데이터의 점 위치를 얻기 위한 제1 점 위치 계산유닛을 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 일 실시예에서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트 폭에 근거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻기 위한 제1 스케일 팩터 계산유닛를 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이고; 목표데이터 중의 절대치 최대 값과 상기 목표데이터 양자화 된 데이터의 최대 값에 근거하여 상기 목표데이터의 스케일 팩터를 얻는다. 일 실시예에서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함된 경우, 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값 과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여, 상기 목표데이터의 점 위치를 얻기 위한 제2 점 위 치 계산유닛을 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 일 실시예에서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함된 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트폭에 근 거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻기 위한 제2 스케일 팩터 계산유닛을 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이고; 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값과 상기 목표데이터 양자화 된 데이터의 최대 값에 근거하여 상기 목표데이터의 스케일 팩터를 얻는다. 일 실시예에서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 목표데이터 중의 최대 값과 최소 값에 근거하여 상기 목표데이터의 오프셋을 얻기 위한 오프셋 계산유닛을 포함 하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 일 실시예에서, 상기 장치는, 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 상기 목표데이터의 양자화 오차를 확정하 는 데 사용되며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터인 양자화 오차 확정모듈; 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조정하며, 상기 목 표데이터에 대응하는 조정 비트폭을 얻기 위한 조정 비트폭 확정모듈; 및 상기 목표데이터에 대응하는 데이터 비트폭을 상기 조정 비트폭으로 업데이트하고, 상기 목표데이터와 상기 조 정 비트폭에 근거하여 계산을 통해 대응하는 조정 양자화 파라미터를 얻으며, 상기 신경망이 상기 조정 양자화 파라미터에 근거하여 양자화하도록 하기 위한 조정 양자화 파라미터 확정모듈을 포함한다. 일 실시예에서, 상기 조정 비트폭 확정모듈은, 상기 양자화 오차가 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 증가하여 상 기 목표데이터에 대응하는 조정 비트폭을 얻기 위한 제1 조정 비트폭 확정 서브 모듈을 포함한다. 일 실시예에서, 상기 조정 비트폭 확정모듈은, 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산하기 위한 제 1 조정 양자화 오차 확정 서브 모듈; 및 상기 조정 후의 양자화 오차와 상기 제1 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터에 따라 계산 하여 얻은 조정 후의 양자화 오차가 상기 제1 오차 한계 값 이하로 될 때까지 상기 조정 비트폭을 계속 증가하 기 위한 제1 조정 비트폭 순환 확정 서브 모듈을 더 포함한다. 일 실시예에서, 상기 조정 비트폭 확정모듈은, 상기 양자화 오차가 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 감소하기 위한 제2 조정 비트폭 확정 서브 모듈을 포함하며, 상기 제2 오차 한계 값은 상기 제1 오차 한계 값보다 작다. 일 실시예에서, 상기 조정 비트폭 확정모듈은, 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산하기 위한 제 2 조정 양자화 오차 확정 서브 모듈; 및 상기 조정 후의 양자화 오차와 상기 제2 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터에 따라 계산 을 통해 얻은 조정 후의 양자화 오차가 상기 제2 오차 한계 값 이상이 될 때까지 상기 조정 비트폭을 계속 감소 하기 위한 제2 조정 비트폭 순환 확정 서브 모듈을 더 포함한다. 일 실시예에서, 상기 신경망 연산의 미조정단계 및/또는 훈련단계에서, 상기 장치는, 현재 반복 및 상기 현재 반복 전의 반복인 이력 반복 중 목표데이터의 데이터 변동폭을 획득하기 위한 데이터 변동폭 확정모듈; 및 상기 목표데이터의 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하기 위한 목표 반복간격 확정모듈을 더 포함하며, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 목표데이터는 임의 의 한 가지 양자화 대상 데이터이다. 일 실시예에서, 상기 장치는, 상기 목표데이터의 상기 현재 반복에서의 데이터 비트폭에 근거하여 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 데이터 비트폭을 확정함으로써, 상기 신경망이 상기 목표데이터의 상기 목표반복간격 내의 반 복에 대응하는 데이터 비트폭에 근거하여 양자화 파라미터를 확정하도록 하기 위한 제1 목표반복간격 응용모듈 을 더 포함한다. 일 실시예에서, 신경망의 양자화 파라미터 조정방법을 제공하는 바, 그 특징은 상기 방법은, 양자화 대상 데이터의 데이터 변동폭을 획득하는 것; 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 신경망 연산에서의 양자화 파라미터를 조정하도록 하는 것을 포함하며, 여기에서, 상기 목표반복간격 은 적어도 1회 반복을 포함하고, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. 일 실시예에서, 상기 양자화 파라미터는 상기 양자화 대상 데이터에 대응하는 양자화 데이터 중 소수점의 위치 인 점 위치를 포함하며; 상기 방법은, 현재 검사 반복에 대응하는 목표데이터 비트폭과 상기 현재 검사 반복의 양자화 대상 데이터에 근거하여 상기 목표반복간격 중 반복에 대응하는 점 위치를 확정함으로써, 상기 신경망 연산에서의 점 위치를 조정하도록 하는 것을 더 포함하며; 여기에서, 상기 목표반복간격 중 반복에 대응하는 점 위치가 일치하다. 일 실시예에서, 상기 양자화 파라미터는 상기 양자화 대상 데이터에 대응하는 양자화 데이터 중 소수점의 위치 인 점 위치를 포함하며; 상기 방법은, 상기 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여 상기 목표반복간격에 대응하는 데이터 비트폭을 확정하며, 여기에서, 상기 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치한 것; 및 획득한 점 위치 반복간격과 상기 목표반복간격에 대응하는 데이터 비트폭에 근거하여 상기 목표반복간격 중 반 복에 대응하는 점 위치를 조정하여 상기 신경망 연산에서의 점 위치를 조정하도록 하는 것을 더 포함하며; 여기에서, 상기 점 위치 반복간격은 적어도 1회 반복을 포함하며, 상기 점 위치 반복간격 중 반복되는 점 위치 가 일치하다. 일 실시예에서, 상기 점 위치 반복간격은 상기 목표반복간격 이하이다. 일 실시예에서, 상기 양자화 파라미터는 상기 점 위치와 동기적으로 업데이트되는 스케일 팩터를 더 포함한다. 일 실시예에서, 상기 양자화 파라미터는 상기 점 위치와 동기적으로 업데이트되는 오프셋을 더 포함한다. 일 실시예에서, 상기 방법은, 상기 현재 검사 반복의 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여 양자화 오차를 확정하며, 여기에서, 상기 현재 검사 반복의 양자화 데이터가 상기 현재 검사 반복의 양자화 대상 데이터의 양 자화에 의해 획득되는 것; 및 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정하는 것을 더 포함한다. 일 실시예에서, 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정하는 것은, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 증가 하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 것; 또는, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 감소 하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 것을 포함한다. 일 실시예에서, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 상기 현재 검사 반복에 대응하는 데이 터 비트폭을 증가하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 것은, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 제1 미리 설정된 비트폭 스텝에 근거하여 제1 중간 데 이터 비트폭을 확정하는 것; 및 상기 현재 검사 반복에서 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제1 미리 설정된 한계 값 미만이 될 때까지 리턴 실행하여 양자화 오차를 확정하는 것을 포함하며; 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 제1 중간 데이터 비트폭에 근거하여 상기 현재 검사 반 복의 양자화 대상 데이터를 양자화하여 획득된다. 일 실시예에서, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 상기 현재 검사 반복에 대응하는 데이 터 비트폭을 감소하는 것은, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 제2 미리 설정된 비트폭 스텝에 의해 제2 중간 데이터 비트폭을 확정하는 것; 및 상기 현재 검사 반복에서 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제2 미리 설정된 한계 값보다 클 때까지 리턴 실행하여 양자화 오차를 확정하는 것을 포함하며; 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 제2 중간 데이터 비트폭에 근거하여 상기 현재 검사 반복 의 양자화 대상 데이터를 양자화하여 획득된다. 일 실시예에서, 상기 양자화 대상 데이터의 데이터 변동폭을 획득하는 것은, 점 위치의 변동폭을 획득하는 것을 포함하며; 여기에서, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭을 특성화하는 데 사용할 수 있으며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭과 정의 상관이 있다. 일 실시예에서, 상기 점 위치의 변동폭을 획득하는 것은, 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복에 대응하는 점 위치에 근거하여 제1 균치를 확정하며, 여기에서, 상기 전회 검사 반복은 상기 목표반복간격 전의 전회 반복 간격에 대응하는 검사 반복인 것; 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균 치를 확정하며; 여기에서, 상기 현재 검사 반복에 대응하는 점 위치는 상기 현재 검사 반복에 대응하는 목표데 이터 비트폭과 양자화 대상 데이터에 의해 확정된 것; 및 상기 제1 균치와 상기 제2 균치에 근거하여 상기 점 위치의 변동폭을 특성화하기 위한 제1 오차를 확정하는 것 을 포함한다. 일 실시예에서, 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균치를 확정하는 것은, 미리 설정된 수의 중간 이동평균 값을 획득하며, 여기에서, 각 상기 중간 이동평균 값은 상기 현재 검사 반복하 기 전 상기 미리 설정된 수의 검사 반복에 근거하여 확정된 것; 및 상기 현재 검사 반복의 점 위치 및 상기 미리 설정된 수의 중간 이동평균 값에 근거하여 상기 제2 균치를 확정 하는 것을 포함한다. 일 실시예에서, 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균치를 확정하는 것은, 상기 현재 검사 반복에 대응하는 점 위치 및 상기 제1 균치에 근거하여 상기 제2 균치를 확정하는 것을 포함한 다. 일 실시예에서, 상기 방법은, 획득한 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제2 균치를 업데이트하는 것을 더 포함 하며; 여기에서, 상기 현재 검사 반복의 데이터 비트폭 조정 값은 상기 현재 검사 반복의 목표데이터 비트폭과 초기 데이터 비트폭에 의해 확정된다. 일 실시예에서, 획득한 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제2 균치를 업데이트하 는 것은, 상기 현재 검사 반복의 데이터 비트폭 조정 값이 미리 설정된 파라미터보다 클 경우, 상기 현재 검사 반복의 데 이터 비트폭 조정 값에 근거하여 상기 제2 균치를 감소하는 것; 및 상기 현재 검사 반복의 데이터 비트폭 조정 값이 미리 설정된 파라미터보다 작은 경우, 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제2 균치를 증가하는 것을 포함한다. 일 실시예에서, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정하는 것은, 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하는 것을 포함하며, 상기 목표반복간격은 상기 제1 오차와 부의 상관이 있다. 일 실시예에서, 상기 양자화 대상 데이터의 데이터 변동폭을 획득하는 것은, 데이터 비트폭의 변화추세를 획득하는 것; 및 상기 점 위치의 변동폭과 상기 데이터 비트폭의 변화추세에 근거하여 상기 양자화 대상 데이터의 데이터 변동폭 을 확정하는 것을 더 포함한다. 일 실시예에서, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정하는 것은, 획득한 점 위치의 변동폭을 특성화하기 위한 제1 오차와 데이터 비트폭의 변화추세를 특성화하기 위한제2 오차 에 근거하여 상기 목표반복간격을 확정하는 것을 더 포함한다. 일 실시예에서, 획득한 상기 제2 오차와 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하는 것은, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 하는 것; 및 상기 목표오차에 근거하여 상기 목표반복간격을 확정하는 것을 포함하며, 여기에서, 상기 목표오차는 상기 목표 반복간격과 부의 상관이 있다. 일 실시예에서, 상기 제2 오차는 양자화 오차에 의해 확정되고; 여기에서, 상기 양자화 오차는 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데 이터에 의해 확정되며, 상기 제2 오차는 상기 양자화 오차와 정의 상관이 있다. 일 실시예에서, 상기 방법은 신경망의 훈련 또는 미조정에 적용되며, 상기 방법은, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목 표반복간격을 확정하며, 상기 목표반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 더 포함한다. 일 실시예에서, 상기 방법은, 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 제1 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제1 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 더 포함한다. 일 실시예에서, 상기 방법은, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 제2 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 더 포함하며; 여기에서, 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간 격이 상기 제1 미리 설정된 반복간격보다도 크다. 일 실시예에서, 상기 방법은, 상기 신경망의 수렴정도가 미리 설정된 조건을 충족시키면, 상기 현재 검사 반복이 제2 미리 설정된 반복 이상 임을 확정하는 것을 더 포함한다. 일 실시예에서, 상기 방법은, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 또 제2 오차가 미리 설정된 오차 값보다 큰 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확정하며, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 하는 것을 더 포함한다. 일 실시예에서, 상기 양자화 대상 데이터는 뉴런 데이터, 가중치 데이터 또는 그래디언트 데이터 중의 적어도 한 가지이다. 일 실시예에서, 컴퓨터 프로그램이 저장된 메모리, 및 상기 컴퓨터 프로그램을 실행할 때 위의 임의의 한 가지 방법의 단계를 실행하는 프로세서를 포함하는 것을 특징으로 하는 신경망의 양자화 파라미터 조정장치를 제공한 다. 일 실시예에서, 상기 컴퓨터 판독 가능한 저장매체에는 컴퓨터 프로그램이 저장되어 있고, 상기 컴퓨터 프로그 램은 실행될 때 위의 임의의 한 가지 방법의 단계를 실현한다. 일 실시예에서, 신경망의 양자화 파라미터 조정장치를 제공하며, 그 특징은, 상기 장치는, 양자화 대상 데이터의 데이터 변동폭을 획득하기 위한 획득모듈; 및 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 신경망 연산에서의 양자화 파라미터를 조정하도록 하기 위한 반복간격 확정모듈을 포함하며, 여기에 서, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. 일 실시예에서, 상기 양자화 파라미터는 상기 양자화 대상 데이터에 대응하는 양자화 데이터 중 소수점의 위치 인 점 위치를 포함하며; 상기 장치는, 현재 검사 반복에 대응하는 목표데이터 비트폭과 상기 현재 검사 반복의 양자화 대상 데이터에 근거하여 상기 목표반복간격 중 반복에 대응하는 점 위치를 확정함으로써, 상기 신경망 연산에서의 점 위치를 조정하도록 하기 위한 양자화 파라미터 확정모듈을 더 포함하며; 여기에서, 상기 목표반복간격 중 반복에 대응하는 점 위치가 일치하다. 일 실시예에서, 상기 양자화 파라미터는 상기 양자화 대상 데이터에 대응하는 양자화 데이터 중 소수점의 위치 인 점 위치를 포함하며; 상기 장치는, 상기 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여 상기 목표반복간격에 대응하는 데이터 비트폭을 확정하는 데 사용되며, 여기에서, 상기 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치한 데이터 비트 폭 확정모듈; 및 획득한 점 위치 반복간격과 상기 목표반복간격에 대응하는 데이터 비트폭에 근거하여 상기 목표반복간격 중 반 복에 대응하는 점 위치를 조정하여 상기 신경망 연산에서의 점 위치를 조정하도록 하기 위한 양자화 파라미터 확정모듈을 더 포함하며; 여기에서, 상기 점 위치 반복간격은 적어도 1회 반복을 포함하고, 상기 점 위치 반복간격 중 반복되는 점 위치 가 일치하다. 일 실시예에서, 상기 점 위치 반복간격은 상기 목표반복간격 이하이다. 일 실시예에서, 상기 양자화 파라미터는 상기 점 위치와 동기적으로 업데이트되는 스케일 팩터를 더 포함한다. 일 실시예에서, 상기 양자화 파라미터는 상기 점 위치와 동기적으로 업데이트되는 오프셋을 더 포함한다. 일 실시예에서, 상기 데이터 비트폭 확정모듈은, 상기 현재 검사 반복의 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여 양자화 오차를 확정하는 데 사용되며, 여기에서, 상기 현재 검사 반복의 양자화 데이터가 상기 현재 검사 반복의 양자화 대상 데이터의 양자화에 의해 획득되는 양자화 오차 확정유닛; 및 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정하기 위한 데이터 비트 폭 확정유닛을 포함한다. 일 실시예에서, 상기 데이터 비트폭 확정유닛은 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정할 때 구체적으로, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 증가 하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 데; 또는, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 감소 하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 데 사용된다. 일 실시예에서, 상기 데이터 비트폭 확정유닛은 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 증가하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획 득할 때 구체적으로, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 제1 미리 설정된 비트폭 스텝에 근거하여 제1 중간 데 이터 비트폭을 확정하며; 상기 현재 검사 반복에서 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제1 미리 설정된 한계 값 미만이 될 때까지 리턴 실행하여 양자화 오차를 확정하는 데 사용되며; 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 제1 중간 데이터 비트폭에 근거하여 상기 현재 검사 반 복의 양자화 대상 데이터를 양자화하여 획득된다. 일 실시예에서, 상기 데이터 비트폭 확정유닛은 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 감소하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득할 때 구체적으로, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 제2 미리 설정된 비트폭 스텝에 의해 제2 중간 데이터 비트폭을 확정하며; 상기 현재 검사 반복에서 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제2 미리 설정된 한계 값보다 클 때까지 리턴 실행하여 양자화 오차를 확정하는 데 사용되며; 여기 에서, 상기 현재 검사 반복의 양자화 데이터는 상기 제2 중간 데이터 비트폭에 근거하여 상기 현재 검사 반복의 양자화 대상 데이터를 양자화하여 획득된다. 일 실시예에서, 상기 획득모듈은, 점 위치의 변동폭을 획득하기 위한 제1 획득모듈을 포함하며; 여기에서, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭을 특성화하는 데 사용할 수 있으며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭과 정의 상관이 있다. 일 실시예에서, 상기 제1 획득모듈은, 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복에 대응하는 점 위치에 근거하여 제1 균치를 확정하는 데 사용되며, 여기에서, 상기 전회 검사 반복은 상기 목표반복간격 전 의 전회 반복간격에 대응하는 검사 반복인 제1 균치 확정유닛; 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균 치를 확정하는 데 사용되며; 여기에서, 상기 현재 검사 반복에 대응하는 점 위치는 상기 현재 검사 반복에 대응 하는 목표데이터 비트폭과 양자화 대상 데이터에 의해 확정되는 제2 균치 확정유닛; 및 상기 제1 균치와 상기 제2 균치에 근거하여 상기 점 위치의 변동폭을 특성화하기 위한 제1 오차를 확정하기 위 한 제1 오차 확정유닛을 포함한다. 일 실시예에서, 상기 제2 균치 확정유닛은 구체적으로, 미리 설정된 수의 중간 이동평균 값을 획득하며, 여기에서, 각 상기 중간 이동평균 값은 상기 현재 검사 반복하 기 전 상기 미리 설정된 수의 검사 반복에 근거하여 확정되고; 상기 현재 검사 반복의 점 위치 및 상기 미리 설정된 수의 중간 이동평균 값에 근거하여 상기 제2 균치를 확정 하는 데 사용된다. 일 실시예에서, 상기 제2 균치 확정유닛은 구체적으로 상기 현재 검사 반복에 대응하는 점 위치 및 상기 제1 균 치에 근거하여 상기 제2 균치를 확정하는 데 사용된다. 일 실시예에서, 상기 제2 균치 확정유닛은 획득한 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상 기 제2 균치를 업데이트하는 데 사용되며; 여기에서, 상기 현재 검사 반복의 데이터 비트폭 조정 값은 상기 현재 검사 반복의 목표데이터 비트폭과 초기 데이터 비트폭에 의해 확정된다. 일 실시예에서, 상기 제2 균치 확정유닛은 획득한 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상 기 제2 균치를 업데이트하는 데 사용될 때 구체적으로, 상기 현재 검사 반복의 데이터 비트폭 조정 값이 미리 설정된 파라미터보다 클 경우, 상기 현재 검사 반복의 데 이터 비트폭 조정 값에 근거하여 상기 제2 균치를 감소하며; 상기 현재 검사 반복의 데이터 비트폭 조정 값이 미리 설정된 파라미터보다 작은 경우, 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제2 균치를 증가하는 데 사용된다. 일 실시예에서, 상기 반복간격 확정모듈은 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하는 데 사용되 며, 상기 목표반복간격은 상기 제1 오차와 부의 상관이 있다. 일 실시예에서, 상기 획득모듈은, 데이터 비트폭의 변화추세를 획득하고; 상기 점 위치의 변동폭과 상기 데이터 비트폭의 변화추세에 근거하여 상 기 양자화 대상 데이터의 데이터 변동폭을 확정하기 위한 제2 획득모듈을 더 포함한다. 일 실시예에서, 획득한 점 위치의 변동폭을 특성화하기 위한 제1 오차와 데이터 비트폭의 변화추세를 특성화하 기 위한제2 오차에 근거하여 상기 목표반복간격을 확정하기 위한 상기 반복간격 확정모듈을 더 포함한다. 일 실시예에서, 상기 반복간격 확정모듈은 획득한 제1 오차와 제2 오차에 근거하여 상기 목표반복간격을 확정하 는 데 사용될 때 구체적으로, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 하고; 상기 목표오차에 근거하여 상기 목표반복간격을 확정하는 데 사용되며, 여기에서, 상기 목표오차는 상기 목표반 복간격과 부의 상관이 있다. 일 실시예에서, 상기 제2 오차는 양자화 오차에 의해 확정되고; 여기에서, 상기 양자화 오차는 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데 이터에 의해 확정되며, 상기 제2 오차는 상기 양자화 오차와 정의 상관이 있다. 일 실시예에서, 상기 장치는 신경망의 훈련 또는 미조정을 실현하는 데 적용되며; 상기 반복간격 확정모듈은, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목 표반복간격을 확정하며, 상기 목표반복간격에 근거하여 상기 양자화 파라미터를 조정하는 데도 사용된다 . 일 실시예에서, 상기 반복간격 확정모듈은 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 제1 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제1 미리 설정된 반복간격에 근거하여 상기 양자화 파라 미터를 조정하는 데도 사용된다. 일 실시예에서, 상기 반복간격 확정모듈은, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 제2 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 데도 사용되며; 여기에서, 상기 신경망의 수렴정도가 미리 설정된 조건을 충족시키면, 상기 현재 검사 반복이 제2 미리 설정된 반복 이상임이 확정되고; 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간격이 상기 제1 미리 설정된 반복간격보다도 크다. 일 실시예에서, 상기 반복간격 확정모듈은, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 또 제2 오차 가 미리 설정된 오차 값보다 큰 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확정하 며, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 하는 데도 사용된다. 또한, 상술한 장치 실시예는 단지 예시일 뿌이며, 본 발명의 기기는 다른 방식으로 실현될 수 있다는 것을 이해 해야 한다. 예를 들어, 상술한 실시예에서 상기 유닛/모듈의 구분은 단지 논리적 기능 구분일 뿐이며, 실제로 실현될 경우에는 다른 구분방식이 있을 수 있다. 예를 들어, 복수의 유닛, 모듈 또는 컴포넌트가 결합될 수 있 거나 다른 시스템에 통합되거나 일부 특징을 무시 또는 실행하지 않을 수 있다. 상기 분리부품으로서 설명한 유닛 또는 모듈은 물리적으로 분리될 수도 있고, 물리적으로 분리되지 않을 수도 있다. 유닛 또는 모듈로서 설명한 부품은 물리적 유닛일 수도 있고, 물리적 유닛이 아닐 수도 있다. 즉 하나의 장치에 위치할 수도 있고, 복수의 장치에 분산될 수도 있다. 본 발명에서 실시예의 방안은 실제의 필요에 따라 유닛의 일부 또는 전부를 선택하여 실현할 수 있다. 또한, 특히 명기되지 않는 한, 본 발명 각 실시예의 각 기능 유닛/모듈은 하나의 유닛/모듈에 통합될 수 있고, 각 유닛/모듈이 물리적으로 단독으로 존재할 수도 있으며, 2개 또는 2개 이상의 유닛/모듈이 하나로 통합될 수 도 있다. 상술한 통합된 유닛/모듈은 하드웨어의 형식을 채용하여 실현할 수도 있고, 소프트웨어 프로그램 모듈 의 형식을 채용하여 실현할 수도 있다. 또한, 상술한 장치 실시예는 단지 예시일 뿐이며, 본 발명의 장치는 다른 방식으로 실현할 수 있다는 것을 이해 해야 한다. 예를 들어, 상술한 실시예에서 상기 유닛/모듈의 구분은 단지 논리적 기능 구분일 뿐이며, 실제로 실현될 경우에는 다른 구분방식이 있을 수 있다. 예를 들어, 복수의 유닛, 모듈 또는 컴포넌트가 결합될 수 있 거나 다른 시스템에 통합되거나 일부 특징을 무시 또는 실행하지 않을 수 있다. 상기 분리부품으로서 설명한 유닛 또는 모듈은 물리적으로 분리될 수도 있고, 물리적으로 분리되지 않을 수도 있다. 유닛 또는 모듈로서 설명한 부품은 물리적 유닛일 수도 있고, 물리적 유닛이 아닐 수도 있다, 즉 하나의 장치에 위치할 수도 있고, 복수의 장치에 분산될 수도 있다. 본 발명에서 실시예의 방안은 실제의 필요에 따라 유닛의 일부 또는 전부를 선택하여 실현할 수 있다. 또한, 특히 명기되지 않는 한, 본 발명 각 실시예의 각 기능 유닛/모듈은 하나의 유닛/모듈에 통합될 수 있고, 각 유닛/모듈이 물리적으로 단독으로 존재할 수도 있으며, 2개 또는 2개 이상의 유닛/모듈이 하나로 통합될 수 도 있다. 상술한 통합된 유닛/모듈은 하드웨어의 형식을 채용하여 실현할 수도 있고, 소프트웨어 프로그램 모듈 의 형식을 채용하여 실현할 수도 있다. 상기 통합된 유닛/모듈은 하드웨어의 형식으로 실현하는 경우, 당해 하드웨어는 디지털 회로, 아날로그 회로 등 일 수 있다. 하드웨어 구조의 물리적 실현은 트랜지스터, 멤 리스터 등을 포함하지만, 이들에 한정되지 않는다. 특히 명기되지 않는 한, 상기 인공지능 프로세서는 임의의 적절한 하드웨어 프로세서, 예를 들어, CPU, GPU, FPGA, DSP 및 ASIC 등일 수 있다. 특히 명기되지 않는 한, 상기 저장유닛은 임의의 적절한 자기 저장 매체 또는 광 자기 저장 매체, 예를 들어, 저항변화 메모리 RRAM（Resistive Random Access Memory）, 다이나믹 랜덤 액 세스 메모리 DRAM（Dynamic Random Access Memory）, 스태틱 랜덤 액세스 메모리 SRAM（Static Random-Access Memory）, 임베디드 다이나믹 랜덤 액세스 메모리 EDRAM（Enhanced Dynamic Random Access Memory）, 고대역 폭 메모리HBM（High-Bandwidth Memory）, 하이브리드 메모리 큐브 HMC（Hybrid Memory Cube） 등일 수 있다. 상기 통합된 유닛/모듈은 소프트웨어 프로그램 모듈의 형식으로 실현되고 독립적인 제품으로 판매되거나 사용될 때 하나의 컴퓨터 판독 가능한 메모리에 저장될 수 있다. 이러한 이해에 따라, 본 발명의 기술방안은 본질적으 로 또는 종래기술에 공헌하는 부분 또는 당해 기술방안의 전부 또는 일부는 소프트웨어 제품의 형식으로 구현할 수 있으며, 당해 컴퓨터 소프트웨어 제품은 하나의 메모리에 저장되며, 컴퓨터기기（개인용 컴퓨터, 서버 또는 네트워크 기기 등일 수 있다）가 본 발명각 실시예에서 설명한 방법의 전부 또는 일부단계를 실행 하기 위한 복 수의 명령을 포함한다. 한편 전술한 메모리는 U 디스크, 읽기 전용 메모리（ROM, Read-Only Memory）, 랜덤 액 세스 메모리（RAM, Random Access Memory）, 모바일 하드 디스크, 자기 디스크 또는 광 디스크 등 각종 프로그 램 코드를 저장할 수있는 매체를 포함한다. 본 기술방안에서, 본 발명은 상술한 신경망의 양자화 파라미터 확정기기를 포함하는 인공지능 칩을 포함한다. 본 기술방안에서, 본 발명은 메모리 디바이스, 인터페이스 장치와 제어 디바이스 및 상술한 인공지능 칩을 포함 하는 보드 카드도 개시하는 바; 여기에서, 상기 인공지능 칩은 상기 메모리 디바이스, 상기 제어 디바이스 및 상기 인터페이스 장치와 각각 연결되고; 상기 메모리 디바이스는 데이터를 저장하는 데 사용되고; 상기 인터페 이스 장치는 상기 인공지능 칩과 외부기기 사이의 데이터 전송을 실현하는 데 사용되며; 상기 제어 디바이스는 상기 인공지능 칩의 상태를 감시하는 데 사용된다. 도12은 본 발명 실시예에 따른 보드 카드를 나타내는 구조 블록도이다. 도12를 참조하면, 상술한 보드 카드는 상술한 칩을 포함하는 외에도 다른 부대부품을 포함할 수 있다. 당해 부대부품은 메모리 디바이스, 인터페이스 장치 및 제어 디바이스를 포함할 수 있지만, 이들에 한정되지 않는다. 상기 메모리 디바이스는 데이터를 저장하기 위해 베스를 통해 상기 인공지능 칩과 연결된다. 상기 메모리 디바이스는 복수 그룹의 저장유닛을 포함할 수 있다. 각 그룹의 상기 저장유닛은 버스를 통해 상기 인공지 능 칩과 연결된다. 또한, 각 그룹의 상기 저장유닛이 DDR SDRAM（영문: Double Data Rate SDRAM, 2배 속도 동 기적 다이나믹 랜덤메모리）일 수 있다는 것을 이해할 수 있다. DDR은 클록 주파수를 높이지 않고도 SDRAM의 속도를 2배로 할 수 있다. DDR은 클록 펄스의 상승 및 하강 에지에 서 데이터를 읽어 내는 것을 허용한다. DDR의 속도는 표준 SDRAM의 2배이다. 일 실시예에서, 상기 저장장치는 4 그룹의 상기 저장유닛을 포함할 수 있다. 각 그룹의 상기 저장유닛은 복수의 DDR4 입자（칩）를 포함할 수 있다. 일 실시예에서, 상기 인공지능 칩 내부는 4개의 72비트 DDR4 컨트롤러를 포함할 수 있으며, 상술한 72비 트 DDR4 컨트롤러 중 64bit는 데이터 전송에 사용되고, 8bit는 ECC검증에 사용된다. 또한, 각 그룹의 상기 저장 유닛에서 DDR4-3200 입자를 채용하는 경우, 데이터 전송의 이론 대역폭은 25600MB/s에 도달할 수 있다고 이해할 수 있다. 일 실시예에서, 각 그룹의 상기 저장유닛은 복수의 병렬로 배치한 2배 속도 동기적 다이나믹 랜덤 메모리를 포 함한다. DDR은 한 클록 주기 내에 데이터를 2회 전송할 수 있다. 상기 칩에 DDR을 제어하는 컨트롤러를 배치하 여 각 상기 저장유닛의 데이터 전송과 데이터 저장의 제어한다. 상기 인터페이스 장치는 상기 인공지능 칩과 전기적으로 연결된다. 상기 인터페이스 장치는 상기 인공지능 칩과 외부기기（예를 들어 서버 또는 컴퓨터） 사이의 데이터 전송을 실현하는 데 사용된다. 예를 들어 일 실시예에 서, 상기 인터페이스 장치는 표준 PCIE 인터페이스일 수 있다. 예를 들어, 처리될 데이터는 서버에서 표준 PCIE 인터페이스를 통해 상기 칩에 전달되어 데이터 이전을 실현한다. 바람직하게, PCIE 3.0 X 16 인터페이스를 채용 하여 전송하는 경우, 이론 대역폭은 16000MB/s에 달할 수도 있다. 다른 하나의 실시예에서, 상기 인터페이스 장 치는 다른 인터페이스일 수도 있고, 본 발명은 상술한 다른 인터페이스의 구체적인 표현형식을 한정하지 않으며, 상기 인터페이스 유닛은 이전기능을 실현하면 된다. 또한, 상기 인공지능 칩의 계산결과는 여전히 상기 인터페이스 장치에 의해 외부기기（예를 들어 서버）로 다시 전송된다. 상기 제어 디바이스는 상기 인공지능 칩과 전기적으로 연결된다. 상기 제어 디바이스는 상기 인공지능 칩의 상 태를 감시하는 데 사용된다. 구체적으로, 상기 인공지능 칩은 SPI 인터페이스를 통해 상기 제어 디바이스와 전 기적으로 연결될 수 있다. 상기 제어 디바이스는 단일 칩 마이크로 컴퓨터（Micro Controller Unit, MCU）를 포 함할 수 있다. 상기와 같이 인공지능 칩은 복수의 처리 칩, 복수의 처리 코아 또는 복수의 처리회로를 포함하여 복수의 부하를 구동할 수 있다. 따라서, 상기 인공지능 칩은 다부하와 경부하 등 상이한 동작상태에 있을 수 있 다. 상기 제어장치를 통해 상기 인공지능 칩 중 복수의 처리 칩, 복수의 처리 코아 또는 복수의 처리회로의 동 작상태의 조정 및 제어를 실현할 수 있다. 가능한 실현방식에서, 상술한 인공지능 칩을 포함한 전자기기를 개시한다. 전자기기는 데이터 처리장치, 로봇, 컴퓨터, 프린터, 스캐너, 태블릿, 스마트 단말, 휴대전화, 드라이브 레코더, 네비게이션 장치, 센서, 카메라, 서버, 클라우드 서버, 카메라, 비디오 카메라, 프로젝터, 손목 시계, 헤드폰, 모바일 스토리지, 웨어러블 디바 이스, 교통수단, 가전제품, 및/또는 의료기기를 포함한다. 상기 교통수단은 항공기, 선박 및/또는 차량을 포함하며; 상기 가전제품은 텔레비전, 에어컨, 전자렌지, 냉장고, 전기밥솥, 가습기, 세탁기, 전등, 가스 버너, 레인지 푸드를 포함하고; 상기 의료기기는 핵자기 공명 장치, B-초음파진단 장치 및/또는 심전계를 포함한다. 전술한 내용은 다음 조항에 따라 더 잘 이해할 수 있다. A1．데이터 비트폭을 조정하기 위한 방법에 있어서, 양자화 대상 데이터에 대해 양자화 처리를 수행하기 위한 상기 양자화 대상 데이터의 상기 양자화 처리 후 양자 화 된 데이터의 비트폭을 나타내는 데이터 비트폭을 회득하는 것; 상기 데이터 비트폭에 기초하여 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 수행하여 상기 1그룹의 양자 화 대상 데이터를 상기 데이터 비트폭을 갖는 1그룹의 양자화 된 데이터로 변환하는 것; 상기 1그룹의 양자화 대상 데이터와 상기 1그룹의 양자화 된 데이터를 비교하여 상기 데이터 비트폭과 관련된 양자화 오차를 확정하는 것; 및 확정된 상기 양자화 오차에 근거하여 상기 데이터 비트폭을 조정하는 것을 포함하는 것을 특징으로 한다. A2．조항A1에 따른 방법에 있어서, 상기 1그룹의 양자화 대상 데이터와 상기 1그룹의 양자화 된 데이터를 비교 하여 상기 데이터 비트폭과 관련된 양자화 오차를 확정하는 것은, 상기 데이터 비트폭에 근거하여 양자화 간격을 확정하는 것; 및 상기 양자화 간격, 상기 1그룹의 양자화 된 데이터 및 상기 1그룹의 양자화 대상 데이터에 근거하여 상기 양자 화 오차를 확정하는 것을 포함하는 것을 특징으로 한다. A3．조항A2에 따른 방법에 있어서, 상기 양자화 간격, 상기 1그룹의 양자화 된 데이터 및 상기 1그룹의 양자화 대상 데이터에 근거하여 상기 양자화 오차를 확정하는 것은, 상기 양자화 간격에 근거하여, 상기 1그룹의 양자화 된 데이터를 역 양자화하여 1그룹의 역 양자화 데이터를 획 득하며, 여기에서 상기 1그룹의 역 양자화 데이터의 데이터 형식은 상기 1그룹의 양자화 대상 데이터의 데이터 형식과 같은 것; 및 상기 1그룹의 역 양자화 데이터와 상기 1그룹의 양자화 대상 데이터에 근거하여 양자화 오차를 확정하는 것을 포함하는 것을 특징으로 한다. A4．조항A1 내지 A3중의 어느 한 항에 따른 방법에 있어서, 확정된 상기 양자화 오차에 근거하여 상기 데이터 비트폭을 조정하는 것은, 제1 한계 값과 제2 한계 값 중의 적어도 하나를 포함하는 미리 설정된 한계 값과 상기 양자화 오차를 비교하는 것; 및 상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하는 것을 포함하는 것을 특징으로 한다. A5．조항A4에 따른 방법에 있어서, 상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하는 것은, 상기 양자화 오차가 제1 한계 값 이상임을 확정하는 것에 응답하여 상기 데이터 비트폭을 증가하는 것을 포함하 는 것을 특징으로 한다. A6．조항A5에 따른 방법에 있어서, 상기 데이터 비트폭을 증가하는 것은, 제1 미리 설정된 비트폭 스텝에 근거하여 상기 데이터 비트폭을 증가하여 조정 후 데이터 비트폭을 확정하는 것 을 포함하는 것을 특징으로 한다. A7．조항A6에 따른 방법에 있어서, 진일보로, 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하여 상 기 1그룹의 양자화 대상 데이터를 상기 조정 후 데이터 비트폭을 갖는 다른 그룹의 양자화 된 데이터로 변환하 는 것; 및 상기 1그룹의 양자화 대상 데이터와 상기 다른 그룹의 양자화 된 데이터를 비교하여 상기 다른 하나의 양자화 오차가 상기 제1 미리 설정된 한계 값보다 작을 때까지 상기 조정 후 데이터 비트폭과 관련되는 다른 하나의 양 자화 오차를 확정하는 것을 포함하는 것을 특징으로 한다. A8．조항A7에 따른 방법에 있어서, 상기 방법은 반복적으로 실행되는 것을 특징으로 한다. A9．조항A4에 따른 방법에 있어서, 상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하는 것은: 상기 양자화 오차 상기 제2 한계 값 이하임을 확정하는 것에 응답하여 상기 데이터 비트폭을 감소하는 것을 포 함하는 것을 특징으로 한다. A10．조항A9에 따른 방법에 있어서, 상기 데이터 비트폭을 감소하는 것은, 제2 미리 설정된 비트폭 스텝에 근거하여 상기 데이터 비트폭을 감소하여 조정 후 데이터 비트폭을 확정하는 것 을 포함하는 것을 특징으로 한다. A11．조항A10에 따른 방법에 있어서, 진일보로, 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하여 상 기 1그룹의 양자화 대상 데이터를 상기 조정 후 데이터 비트폭을 갖는 다른 그룹의 양자화 된 데이터로 변환하 는 것; 및 상기 1그룹의 양자화 대상 데이터와 상기 다른 그룹의 양자화 된 데이터에 근거하여, 상기 다른 하나의 양자화 오차가 상기 제2 미리 설정된 한계 값보다 클 때까지 상기 조정 후 데이터 비트폭과 관련된 다른 하나의 양자화 오차를 확정하는 것을 포함하는 것을 특징으로 한다. A12．조항A11에 따른 방법에 있어서, 상기 방법은 반복적으로 실행되는 것을 특징으로 한다. A13．조항A4에 따른 방법에 있어서, 상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하는 것은, 상기 양자화 오차가 상기 제1 한계 값과 상기 제2 한계 값 사이에 있음을 확정한 것에 응답하여 상기 데이터 비 트폭을 유지하는 것을 포함하는 것을 특징으로 한다. A14．조항A1 내지 A13중의 어느 한 항에 따른 방법에 있어서, 진일보로, 상기 1그룹의 양자화 대상 데이터와 상기 조정 후 데이터 비트폭에 근거하여 상기 1그룹의 양자화 대상 데이터 에 대해 양자화 처리를 실행하기 위한 양자화 파라미터를 업데이트하는 것; 및 업데이트된 상기 양자화 파라미터에 근거하여 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 실행하는 것을 포함하는 것을 특징으로 한다. A15．조항A1에 따른 방법에 있어서, 진일보로, 양자화 대상 데이터의 데이터 변동폭을 획득하는 것; 및 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 데이터 비트폭을 조정하는 것을 포함하며, 상기 목표반복간격은 적어도 1회 반복을 포함하는 것을 특 징으로 한다. A16．조항A15에 따른 방법에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭을 획득하는 것은, 점 위치의 변동폭을 획득하는 것을 포함하며, 여기에서 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데 이터 변동폭을 특성화하는 데 사용되고, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭과 정의 상관이 있는 것을 특징으로 한다. A17．조항A16에 따른 방법에 있어서, 상기 점 위치의 변동폭을 획득하는 것은, 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복에 대응하는 점 위치에 근거하여 제1 균치를 확정하며, 여기에서, 상기 전회 검사 반복은 상기 목표반복간격 전의 전회 반복 간격에 대응하는 검사 반복인 것; 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균 치를 확정하며; 여기에서, 상기 현재 검사 반복에 대응하는 점 위치는 상기 현재 검사 반복에 대응하는 목표데 이터 비트폭과 양자화 대상 데이터에 의해 확정된 것; 및 상기 제1 균치와 상기 제2 균치에 근거하여 상기 점 위치의 변동폭을 특성화하기 위한 제1 오차를 확정하는 것 을 포함하는 것을 특징으로 한다. A18．조항A15에 따른 방법에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확 정하는 것은, 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하는 것을 포함하며, 상기 목표반복간격은 상기 제1 오차와 부의 상관이 있는 것을 특징으로 한다. A19．조항A15에 따른 방법에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭을 획득하는 것은 진일보로, 상기 데이터 비트폭의 변화추세를 획득하는 것; 및 상기 점 위치의 변동폭과 상기 데이터 비트폭의 변화추세에 근거하여 상기 양자화 대상 데이터의 데이터 변동폭 을 확정하는 것을 포함하는 것을 특징으로 한다. A20．조항A19에 따른 방법에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확 정하는 것은 진일보로, 획득한 점 위치의 변동폭을 특성화하기 위한 제1 오차와 데이터 비트폭의 변화추세를 특성화하기 위한제2 오차 에 근거하여 상기 목표반복간격을 확정하는 것을 포함하는 것을 특징으로 한다. A21．조항A20에 따른 방법에 있어서, 획득한 상기 제1 오차와 상기 제2 오차에 근거하여 상기 목표반복간격을 확정하는 것은, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 하는 것; 및 상기 목표오차에 근거하여 상기 목표반복간격을 확정하는 것을 포함하며, 여기에서, 상기 목표오차는 상기 목표 반복간격과 부의 상관이 있는 것을 특징으로 한다. A22．조항A20또는 A21에 따른 방법에 있어서, 상기 제2 오차는 양자화 오차에 의해 확정되고; 여기에서, 상기 양자화 오차는 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데 이터에 의해 확정되며, 상기 제2 오차는 상기 양자화 오차와 정의 상관이 있는 것을 특징으로 한다. A23．조항A15 내지 A22 중의 어느 한 항에 따른 방법에 있어서, 상기 방법은 신경망의 훈련 또는 미조정에 적용 되며, 상기 방법은 진일보로, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목 표반복간격을 확정하며, 상기 목표반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 더 포함을 포함 하는 것을 특징으로 한다. A24．조항A23에 따른 방법에 있어서, 상기 방법은 진일보로, 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 제1 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제1 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 포함하는 것을 특징으 로 한다. A25．조항A23또는 A24에 따른 방법에 있어서, 상기 방법은 진일보로, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 제2 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 포함하며 ; 여기에서, 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간 격이 상기 제1 미리 설정된 반복간격보다도 큰 것을 특징으로 한다. A26．조항A25에 따른 방법에 있어서, 상기 방법은 진일보로, 상기 신경망의 수렴정도가 미리 설정된 조건을 충족시키면, 상기 현재 검사 반복이 제2 미리 설정된 반복 이상 임을 확정하는 것을 포함하는 것을 특징으로 한다. A27, 조항A25에 따른 방법에 있어서, 상기 방법은 진일보로, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 또 제2 오차가 미리 설정된 오차 값보다 큰 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확정하며, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 하는 것을 포함하는 것을 특징으로 한다. A28．데이터 비트폭을 조정하는 장치에 있어서, 양자화 대상 데이터에 대해 양자화 처리를 수행하기 위한 상기 양자화 대상 데이터의 상기 양자화 처리 후 양자 화 된 데이터의 비트폭을 나타내는 데이터 비트폭을 회득하기 위한 획득모듈; 상기 데이터 비트폭에 기초하여 1그룹의 양자화 대상 데이터에 대해 양자화 처리를 수행하여 상기 1그룹의 양자 화 대상 데이터를 상기 데이터 비트폭을 갖는 1그룹의 양자화 된 데이터로 변환하기 위한 양자화 모듈; 상기 1그룹의 양자화 대상 데이터와 상기 1그룹의 양자화 된 데이터를 비교하여 상기 데이터 비트폭과 관련된 양자화 오차를 확정하기 위한 확정모듈; 및 확정된 상기 양자화 오차에 근거하여 상기 데이터 비트폭을 조정하기 위한 조정모듈을 포함하는 것을 특징으로 한다. A29．조항A28에 따른 장치에 있어서, 상기 비교모듈은, 상기 데이터 비트폭에 근거하여 양자화 간격을 확정하기 위한 간격확정모듈, 및 상기 양자화 간격, 상기 1그룹의 양자화 된 데이터 및 상기 1그룹의 양자화 대상 데이터에 근거하여 상기 양자 화 오차를 확정하기 위한 오차 확정모듈을 포함하는 것을 특징으로 한다. A30．조항A29에 따른 장치에 있어서, 상기 오차 확정모듈은, 상기 양자화 간격에 근거하여 상기 1그룹의 양자화 된 데이터에 대해 역 양자화를 수행하여 1그룹의 역 양자화 데이터를 획득하는 데 사용되고, 상기 1그룹의 역 양자화 데이터의 데이터 형식이 상기 1그룹의 양자화 대상 데 이터의 데이터 형식과 같은 양자화 모듈, 및 상기 1그룹의 역 양자화 데이터와 상기 1그룹의 양자화 대상 데이터에 근거하여 양자화 오차를 확정하기 위한 양자화 오차 확정모듈을 포함하는 것을 특징으로 한다. A31．조항A28 내지 A30 중의 어느 한 항에 따른 장치에 있어서, 상기 조정모듈은, 제1 한계 값과 제2 한계 값 중의 적어도 하나를 포함하는 미리 설정된 한계 값과 상기 양자화 오차를 비교하기 위한 비교모듈, 및 상기 비교의 결과에 근거하여 상기 데이터 비트폭을 조정하기 위한 비트폭 조정모듈을 포함하는 것을 특징으로 한다. A32．조항A31에 따른 장치에 있어서, 상기 비트폭 조정모듈은, 상기 양자화 오차가 제1 한계 값 이상임의 확정에 응답하여 상기 데이터 비트폭을 증가하기 위한 증가모듈을 포 함하는 것을 특징으로 한다. A33．조항A32에 따른 장치에 있어서, 상기 증가모듈은, 제1 미리 설정된 비트폭 스텝에 근거하여 상기 데이터 비트폭을 증가시켜 조정 후 데이터 비트폭을 확정하기 위 한 스텝 증가모듈을 포함하는 것을 특징으로 한다. A34．조항A33에 따른 장치에 있어서, 상기 양자화 모듈은 진일보로 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대 해 양자화 처리를 실행하여 상기 1그룹의 양자화 대상 데이터를 다른 1그룹의 양자화 된 데이터로 변환하는 데 사용되며, 상기 다른 1그룹의 양자화 된 데이터는 상기 조정 후 데이터 비트폭을 가지며; 및 상기 확정모듈은 진일보로 상기 1그룹의 양자화 대상 데이터와 상기 다른 1그룹의 양자화 된 데이터를 비교하여, 다른 하나의 양자화 오차가 상기 제1 미리 설정된 한계 값보다 작을 때까지 상기 조정 후 데이터 비 트폭과 관련되는 다른 하나의 양자화 오차를 확정하는 데 사용되는 것을 특징으로 한다. A35．조항A34에 따른 장치에 있어서, 상기 장치는 반복적으로 호출되는 것을 특징으로 한다. A36．조항A31에 따른 장치에 있어서, 상기 조정모듈은, 상기 양자화 오차가 상기 제2 한계 값 이하임을 확정하는 것에 응답하여 상기 데이터 비트폭을 감소시키기 위한 감소모듈을 포함하는 것을 특징으로 한다. A37．조항A36에 따른 장치에 있어서, 상기 감소모듈은, 제2 미리 설정된 비트폭 스텝에 근거하여 상기 데이터 비트폭을 감소하여 조정 후 데이터 비트폭을 확정하기 위 한 스텝 감소모듈을 포함하는 것을 특징으로 한다. A38．조항A37에 따른 장치에 있어서, 상기 양자화 모듈은 진일보로 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대 해 양자화 처리를 실행하여 상기 1그룹의 양자화 대상 데이터를 다른 1그룹의 양자화 된 데이터로 변환하는 데 사용되며, 상기 다른 1그룹의 양자화 된 데이터는 상기 조정 후 데이터 비트폭을 가지며; 및 상기 확정모듈은 진일보로 상기 1그룹의 양자화 대상 데이터와 상기 다른 1그룹의 양자화 된 데이터에 근거하여, 다른 하나의 양자화 오차가 상기 제2 미리 설정된 한계 값보다 클 때까지 상기 조정 후 데이터 비트 폭과 관련되는 다른 하나의 양자화 오차를 확정하는 데 사용되는 것을 특징으로 한다. A39．조항A38에 따른 장치에 있어서, 상기 장치는 반복적으로 호출되는 것을 특징으로 한다. A40．조항A31에 따른 장치에 있어서, 상기 조정모듈은, 상기 양자화 오차가 상기 제1 한계 값과 상기 제2 한계 값 사이에 있음을 확정하는 것에 응답하여 상기 데이터 비트폭을 유지하기 위한 유지모듈을 포함하는 것을 특징으로 한다. A41．조항A28 내지 A40 중의 어느 한 항에 따른 장치에 있어서, 진일보로, 상기 1그룹의 양자화 대상 데이터와 상기 조정 후 데이터 비트폭에 근거하여, 상기 1그룹의 양자화 대상 데이터 에 대해 양자화 처리를 실행하기 위한 양자화 파라미터를 업데이트하기 위한 업데이트모듈, 및 진일보로 업데이트한 상기 양자화 파라미터에 근거하여, 상기 1그룹의 양자화 대상 데이터에 대해 양자화 처리 를 실행하기 위한 상기 양자화 모듈을 포함하는 것을 특징으로 한다. A42．조항A28에 따른 장치에 있어서, 진일보로, 양자화 대상 데이터의 데이터 변동폭을 획득하기 위한 변동폭 모듈; 및 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 데이터 비트폭을 조정하기 위한 간격모듈을 포함하며, 상기 목표반복간격은 적어도 1회 반복을 포함 하는 것을 특징으로 한다. A43．조항A42에 따른 장치에 있어서, 상기 변동폭 모듈은, 점 위치의 변동폭을 획득하기 위한 점 위치 모듈을 포함하며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이 터의 데이터 변동폭을 특성화하는 데 사용되며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변 동폭과 정의 상관이 있는 것을 특징으로 한다. A44．조항A43에 따른 장치에 있어서, 상기 점 위치모듈은, 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복에 대응하는 점 위치에 근거하여 제1 균치를 확정하는 데 사용되며, 상기 전회 검사 반복이 상기 목표반복간격 전의 이전 반 복간격에 대응하는 검사 반복인 제1 균치모듈; 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균 치를 확정하는 데 사용되며; 상기 현재 검사 반복에 대응하는 점 위치가 상기 현재 검사 반복에 대응하는 목표 데이터 비트폭과 양자화 대상 데이터에 의해 확정되는 제2 균치모듈; 상기 제1 균치와 상기 제2 균치에 근거하여 상기 점 위치의 변동폭을 특성화하기 위한 제1 오차를 확정하기 위 한 제1 오차모듈을 포함하는 것을 특징으로 한다. A45．조항A42에 따른 장치에 있어서, 상기 간격모듈은, 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하기 위한 제1 간격모듈을 포함하며, 상기 목표반복간격은 상기 제1 오차와 부의 상관이 있는 것을 특징으로 한다. A46．조항A42에 따른 장치에 있어서, 상기 변동폭 모듈은 진일보로, 상기 데이터 비트폭의 변화추세를 획득하기 위한 추세모듈; 및 상기 점 위치의 변동폭과 상기 데이터 비트폭의 변화추세에 근거하여 상기 양자화 대상 데이터의 데이터 변동폭 을 확정하기 위한 데이터 변동폭 모듈을 포함하는 것을 특징으로 한다. A47．조항A46에 따른 장치에 있어서, 상기 간격모듈은 진일보로, 획득한 제1 오차와 제2 오차에 근거하여 상기 목표반복간격을 확정하기 위한 반복간격모듈을 포함하며; 상기 제 1 오차는 점 위치의 변동폭을 특성화하는 데 사용되고, 상기 제2 오차는 데이터 비트폭의 변화추세를 특성화하 는 데 사용되는 것을 특징으로 한다. A48．조항A47에 따른 장치에 있어서, 상기 반복간격모듈은, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 하기 위한 목표오차모듈; 상기 목표오차에 근거하여 상기 목표반복간격을 확정하기 위한 목표반복간격모듈을 포함하며, 상기 목표오차는 상기 목표반복간격과 부의 상관이 있는 것을 특징으로 한다. A49．조항A47 또는 A48에 따른 장치에 있어서, 상기 제2 오차는 양자화 오차에 의해 확정되고; 여기에서, 상기 양자화 오차는 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데 이터에 의해 확정되며, 상기 제2 오차는 상기 양자화 오차와 정의 상관이 있는 것을 특징으로 한다. A50．조항A42 내지 A49 중의 어느 한 항에 따른 장치에 있어서, 상기 장치는 신경망의 훈련 또는 미조정에 사용 되며, 상기 장치는 진일보로, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목 표반복간격을 확정하고, 상기 목표반복간격에 근거하여 상기 양자화 파라미터를 조정하기 위한 제1 반복모듈을 포함하는 것을 특징으로 한다. A51．조항A50에 따른 장치에 있어서, 상기 장치는 진일보로, 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 제1 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제1 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하기 위한 제2 반복모듈을 포함 하는 것을 특징으로 한다. A52．조항A50 또는 A51에 따른 장치에 있어서, 상기 장치는 진일보로, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 제2 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하기 위한 제3 반복모듈을 포함 하며 ; 여기에서, 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간 격이 상기 제1 미리 설정된 반복간격보다도 큰 것을 특징으로 한다. A53．조항A52에 따른 장치에 있어서, 상기 장치는 진일보로, 상기 신경망의 수렴정도가 미리 설정된 조건을 충족시키면 상기 현재 검사 반복이 제2 미리 설정된 반복 이상임 을 확정하기 위한 수렴모듈을 포함하는 것을 특징으로 한다. A54, 조항A52에 따른 장치에 있어서, 상기 장치는 진일보로, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 또 제2 오차가 미리 설정된 오차 값보다 큰 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확정하며, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 하는 것을 특징으로 한다. A55．컴퓨터 프로그램이 저장된 컴퓨터 판독 가능한 저장매체에 있어서, 상기 프로그램은 실행시에 조항A1-A27 중의 어느 한 항에 따른 방법을 실현하는 것을 특징으로 한다. A56．조항A28 내지 A54 중의 어느 한 항에 따른 데이터를 처리하기 위한 장치를 포함하는 것을 특징으로 하는 인공지능 칩. A57．조항56에 따른 인공지능 칩을 포함하는 것을 특징으로 하는 전자기기. A58．메모리 디바이스, 인터페이스 장치와 제어 디바이스 및 조항56에 따른 인공지능 칩을 포함하는 것을 특징 으로 하는 보드 카드에 있어서; 그 중, 상기 인공지능 칩은 상기 메모리 디바이스, 상기 제어 디바이스 및 상기 인터페이스 장치와 연결되고; 상기 메모리 디바이스는 데이터를 저장하는 데 사용되고; 상기 인터페이스 장치는 상기 인공지능 칩과 외부기기 사이의 데이터 전송을 실현하는 데 사용되며, 상기 제어 디바이스는 상기 인공지능 칩의 상태를 감시하는 데 사용되는 것을 특징으로 한다. A59．조항A58에 따른 보드 카드에 있어서, 상기 메모리 디바이스는 복수 그룹의 저장유닛을 포함하며, 각 그룹의 저장유닛은 버스를 통해 상기 인공지능 칩과 연결되고, 상기 저장유닛은 DDR SDRAM이며; 상기 칩은 각 상기 저장유닛의 데이터 전송과 데이터 저장을 제어하기 위한 DDR 컨트롤러를 포함하며; 상기 인터페이스 장치는 표준 PCIE 인터페이스인 것을 특징으로 한다. 신경망의 양자화 문제를 해결하기 위해, 다음과 같은 방안（201910505239.7）을 제안 하였다. 구체적으로는, 신 경망의 양자화방법과 장치 및 관련제품을 제공하였다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 23, "content": "본 발명은 인공지능 기술분야에 관한 것이며, 특히 신경망의 양자화방법과 장치 및 관련제품에 관한 것이다. 인공지능 기술의 지속적인 발전에 따라 그 응용분야는 점점 넓어져, 화상식별, 음성식별, 자연언어 처리 등 분 야에서 잘 응용되고 있다. 그러나, 인공지능 알고리즘의 복잡성이 증가함에 따라 처리 해야할 데이터 량과 데 이터 차원이 지속적으로 증가하고 있으며, 인공지능 분야에서 연산효율과 연산결과의 정확도 간의 균형을 맞추 는 방법이 시급히 해결해야할 문제이다. 이를 고려하여, 본 발명은 신경망 양자화 기술방안을 제안한다. 본 발명의 일 측면에 따르면, 신경망의 양자화방법을 제공하는 바, 상기 신경망에서 임의의 한 층의 양자화 대 상 층에 대하여, 상기 방법은, 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터와 대응하는 양자화 파라미터를 확정하며, 상기 양자화 대상 데이터는 뉴런, 가중치, 바이어스, 그래디언트 중 적어도 한 가지를 포함하는 것; 및 대응하는 양자화 파라미터에 근거하여 양자화 대상 데이터를 양자화하여 양자화 데이터를 얻으며, 상기 신경망 이 상기 양자화 데이터에 근거하여 연산을 수행하도록 하는 것을 포함한다. 본 발명의 다른 측면에 따르면, 신경망 양자화장치를 제공하는 바, 상기 장치는 상기 신경망에서 임의의 한 층 의 양자화 대상 층을 양자화하는 데 적용되며, 상기 장치는, 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터와 대응하는 양자화 파라미터를 확정하는 데 사용되고, 상기 양자화 대상 데이터는 뉴런, 가중치, 바이어스, 그래디언트 중 적어도 한 가지를 포함하는 양자화 파라미 터 확정모듈; 및 대응하는 양자화 파라미터에 근거하여 양자화 대상 데이터를 양자화하여 양자화 데이터를 얻으며, 상기 신경망 이 상기 양자화 데이터에 근거하여 연산을 수행하도록 하기 위한 양자화 모듈을 포함한다. 본 발명의 다른 측면에 따르면, 인공지능 칩을 제공하는 바, 상기 칩은 상술한 신경망 양자화장치를 포함한다. 본 발명의 다른 측면에 따르면, 전자기기를 제공하는 바, 상기 전자기기는 상술한 바와 같은 인공지능 칩을 포 함한다. 본 발명의 다른 측면에 따르면, 보드 카드를 제공하는 바, 상기 보드 카드는 메모리 디바이스, 인터페이스 장치 와 제어 디바이스 및 상술한 바와 같은 인공지능 칩을 포함하며; 여기에서, 상기 인공지능 칩은 상기 메모리 디 바이스, 상기 제어 디바이스 및 상기 인터페이스 장치와 각각 연결되고; 상기 메모리 디바이스는 데이터를 저장 하는 데 사용되고; 상기 인터페이스 장치는 상기 인공지능 칩과 외부기기 사이의 데이터 전송을 실현하는 데 사 용되며; 상기 제어 디바이스는 상기 인공지능 칩의 상태를 감시하는 데 사용된다. 본 발명 실시예에서, 상기 신경망에서 임의의 한 층의 양자화 대상 층에 대하여, 상기 양자화 대상 층 중 각 종 류의 양자화 대상 데이터와 대응하는 양자화 파라미터를 확정하며, 상기 양자화 대상 데이터는 뉴런, 가중치, 바이어스, 그래디언트 중 적어도 한 가지를 포함하고; 대응하는 양자화 파라미터에 근거하여 양자화 대상 데이 터를 양자화하여 양자화 데이터를 얻으며, 상기 신경망이 상기 양자화 데이터에 근거하여 연산을 수행하도록 한다. 각 층양자화 대상 데이터에 적합한 양자화 파라미터를 채용하여 각 양자화 대상 층을 양자화하는 것에 의 해, 각 층의 연산결과의 정밀도를 보장한다는 전제하에서 각 층의 연산효율을 향상시킬 수 있다. 또한 신경망 전체의 연산결과의 정밀도를 보장한다는 전제하에서 신경망 전체의 연산효율을 향상시킬 수 있다. 첨부된 도면을 참조하여 예시적인 실시예에 대한 다음의 상세한 설명에 따르면, 본 발명의 다른 특징 및 측면이 명확해 질 것이다. 명세서에 포함되고 명세서의 일부를 구성하는 도면은 명세서와 함께 본 발명의 예시적인 실시예, 특징 및 측면 을 예시하며, 본 발명의 원리를 설명하기 위해 사용된다. 도13은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도14는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도15은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도16는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도17는 본 발명 실시예에 따른 신경망의 양자화방법 중 양자화 파라미터가 오프셋을 포함하지 않을 때 양자화 전후의 데이터를 나타내는 대응 모식도이다. 도18은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도19은 본 발명 실시예에 따른 신경망의 양자화방법 중 양자화 파라미터가 오프셋을 포함할 때 양자화 전후의 데이터를 나타내는 대응 모식도이다. 도20은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도21는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도22은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도23은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도24는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도25은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도26는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도27는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도28은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도29은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도30은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도31는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도32은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도33은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도34는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도35은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도36는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도37는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도38은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도39은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도40은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도41은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도42은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도43은 본 발명 실시예에 따른 보드 카드를 나타내는 구조 블록도이다. 신경망의 양자화 문제를 해결하기 위해, 다음과 같은 방안（201910505239.7）을 제안하였다. 이하, 본 발명 실 시예에 따른 도면을 참조하여 본 발명 실시예에 따른 기술방안을 명확하고 완전하게 설명한다. 물론, 설명되는 실시예는 본 발명의 일부 실시예이고, 모든 실시예가 아니다. 본 발명의 실시예를 기반으로, 본 발명이 속하는"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 24, "content": "기술분야에서 통상의 지식을 가진 자가 창조적인 노력 없이 획득한 모든 다른 실시예는 모두 본 발명의 보호범 위에 속한다. 또한, 본 발명의 청구항, 명세서 및 도면 중의 \"제1\", \"제2\", \"제3 \" 및 \"제4\" 등 용어는 특정 순서를 설명하기 보다는 다를 대상을 구별하는 데 사용된다는 것을 이해해야 한다. 본 발명의 명세서와 청구범위에서 사용한 “ 포함한다” 및 “가진다” 등 용어는 설명하는 특징, 전체, 단계, 작업, 요소 및/또는 컴포넌트의 존재를 나타 내지만, 하나 또는 복수의 다른 특징, 전체, 단계, 작업, 요소, 컴포넌트 및/또는 이들 컬렉션의 존재 또는 추 가를 배제하지 않는다. 여기에서 본 발명 명세서에서 사용한 용어는 특정 실시예를 설명할 목적 뿐이며, 본 발명을 한정하는 것을 의도 하지 않는 것도 이해해야 한다. 본 발명 명세서 및 청구범위에서 사용된 바와 같이, 문매이 다른 상황을 명확히 명시하지 않는 한, 단수 형식의 “하나”, “한 개” 및 “당해”는 복수 형식을 포함하도록 의도된다. 또한, 본 발명 명세서 및 청구범위에서 사용한 “및/또는 ” 용어는 관련하여 열거한 항목 중의 하나 또는 복수의 의 임의의 조합 및 모든 가능한 조합을 의미하며, 또한 이들 조합을 포함하는 것이 이해되어야 한다. 여기에서 \"예시적\"이라는 전용 단어는 \"예, 실시예 또는 설명성\"으로서 사용되는 것을 의미한다. 여기에서 \"예 시적\"으로 설명한 임의의 실시예는 다른 실시예보다 우수하거나 더 나은 것으로 해석될 필요는 없다. 또한, 본 발명을 더 잘 설명하기 위해, 이하 구체적인 실시예에서 많은 구체적인 세부사항이 제공된다. 본 발명"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 25, "content": "이 속하는 기술분야에서 통상의 지식을 가진 자라면, 특정한 세부사항 없이도 본 발명는 동일하게 실시 가능한"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 26, "content": "것을 이해해야 한다. 일부 예에서, 본 발명의 요지를 강조하기 위해 본 발명이 속하는 기술분야에서 통상의 지 식을 가진 자가 숙지하고 있는 방법, 수단, 소자 및 회로에 대하여 상세하게 설명되지 않고 있다. 신경망에서 연산되는 데이터는 일반적으로 부동 소수점 데이터 형식 또는 정밀도가 높은 고정 소수점 데이터 형 식이며, 신경망을 탑재한 칩에서 신경망을 실행하면, 부동 소수점 데이터 형식 또는 정밀도가 높은 고정 소수점 데이터 형식의 각종 연산되는 데이터는, 신경망 운영의 연산량과 액세스 오버 헤드가 상대거으로 크다. 연산효 율을 높이기 위해, 신경망의 연산 대상 데이터를 양자화할 수 있으며, 양자화 후의 데이터 형식은 일반적으로 비트폭이 짧고, 정밀도가 낮은 고정 소수점 데이터 형식이다. 정밀도가 낮은 양자화 된 데이터를 이용하여 신경 망의 연산을 실행하면, 연산량과 액세스 얄을 저감할 수 있다. 양자화 후의 데이터 형식은 비트폭이 비교적 짧 은 고정 소수점 데이터 형식일 수 있다. 부동 소수점 데이터 형식의 연산 대상 데이터를 고정 소수점 데이터 형 식의 연산 대상 데이터로 양자화할 수 있고, 정밀도가 높은 고정 소수점 형식의 연산 대상 데이터를 정밀도가 낮은 고정 소수점 형식의 연산 대상 데이터로 양자화할 수도 있다. 또한, 양자화 정밀도 즉 양자화 된 데이터는 양자화 전 데이터와의 오차 크기를 의미함을 이해할 수 있다. 양자 화 정밀도는 신경망 연산결과의 정확도에 영향을 줄 수 있다. 양자화 정밀도가 높을 수록 연산결과의 정밀도가 높게 되지만, 연산량이 더 커지고, 액세스 오버 헤드도 더 커진다. 비트폭이 짧은 양자화 된 데이터에 비해 비 트폭이 긴 양자화 된 데이터의 양자화 정밀도가 보다 높으며, 신경망을 실행하기 위한 연산시의 정밀도도 보다 높아진다. 그러나 신경망의 연산에 이용할 때, 비트폭이 긴 양자화 된 데이터 연산량이 더 크고, 액세스 오버 헤드도 크며, 연산효율이 비교적 낮다. 마찬가지로, 동일한 양자화 대상 데이터에 대하여, 상이한 양자화 파라 미터를 채용하여 얻은 양자화 된 데이터는 상이한 양자화 정밀도를 가지며, 상이한 양자화 결과가 생성되어, 연 산효율과 연산결과의 정밀도에도 다른 영향을 준다. 신경망을 양자화하여 연산효율과 연산결과의 정밀도 간의 균형을 맞추기 위해 연산 대상 데이터의 데이터 특징에 더 적합한 양자화 된 데이터 비트폭과 양자화 파라미터 를 채용할 수 있다. 신경망에서의 연산 대상 데이터는 가중치, 뉴런, 바이어스, 그래디언트를 포함할 수 있다. 종래의 신경망에서의 연산 대상 데이터에 대해 양자화를 수행할 때, 일반적으로 신경망 전체에 대하여 동일한 양자화 파라미터를 설 정한다. 예를 들어, 신경망에는 4개의 컨벌루션 층과 2개의 완전연결층이 포함되고, 연산 대상 데이터가 뉴런（ 일반적으로 입력 뉴런）이면, 신경망의 양자화를 위해 일련의 양자화 파라미터 A를 설정할 수 있으며, 양자화 파라미터 A를 이용하여 4개의 컨벌루션 층과 2개의 완전연결층의 뉴런에 대해 양자화를 수행할 수 있다. 신경망 각 층의 뉴런이 다르기 때문에 각 층에서 사용되는 알고리즘도 다르며, 동일한 양자화 파라미터를 이용하여 각 층에 대해 양자화를 수행하는 경우, 양자화 파라미터는 각 층의 뉴런의 특징에 적을할 수 없으므로 신경망의 전 체 양자화 정밀도가 낮게 되어, 연산결과의 정밀도가 낮다. 또한, 신경망에 대해 일련의 양자화 파라미터를 설 정할 때, 연산결과의 정밀도를 고려하여 양자화 정밀도를 높이기 위해 일련의 비트폭이 긴 양자화 후 비트폭을 설정하면, 신경망의 연산효율이 저하된다. 따라서, 종래의 신경망의 양자화방법은 양자화 정밀도의 향상과 연산 효율 향상 사이의 효과적인 균형을 잡을 수 없었다. 도13은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 당해 신경망의 양자화방법은 범용 프로세서（예를 들어 중앙처리장치 CPU, 그래픽처리장치 GPU）와 전용 프로세서（예를 들어 인공지능 프로세서, 과학적 계산 프로세서 또는 디지털 신호 프로세서 등 ）에 응용할 수 있으며, 본 발명에서는 신경망의 양자화방 법에서 응용하는 프로세서의 유형을 제한하지 않는다. 도13에 도시된 바와 같이, 상기 신경망에서 임의의 한 층의 양자화 대상 층에 대하여, 상기 신경망의 양자화방 법은 다음과 같은 단계를 포함한다. 단계(S10), 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터와 대응하는 양자화 파라미터를 확정하며, 상 기 양자화 대상 데이터는 뉴런, 가중치, 바이어스, 그래디언트 중 적어도 한 가지를 포함한다. 신경망에서 양자화 대상 층은 신경망 중 임의의 한 층일 수 있다. 요구사항에 근거하여 신경망 중의 일부 층 또 는 전체 층을 양자화 대상 층으로 확정할 수 있다. 신경망에 복수의 양자화 대상 층이 포함될 때, 각 양자화 대 상 층은 연속적일 수도 있고, 불연속적일 수도 있다. 신경망의 다름에 따라 양자화 대상 층의 종류도 다를 수 있다. 예를 들어 양자화 대상 층은 컨벌루션 층, 완전연결층 등일 수 있으며, 본 발명은 양자화 대상 층의 수 및 유형에 대하여 한정하지 않는다. 가능한 실현방식에서, 상기 양자화 대상 데이터는 뉴런, 가중치, 바이어스, 그래디언트 중의 적어도 한 가지를 포함한다. 양자화 대상 층의 연산을 실행하기 위한 연산 데이터는 뉴런, 가중치, 바이어스 및 그래디언트를 포함할 수 있 다. 요구사항에 따라 양자화 대상 층의 뉴런, 가중치, 바이어스, 그래디언트 중의 적어도 한 가지를 양자화 대 상 데이터로 할 수 있다. 양자화 대상 층에 여러 가지 양자화 대상 데이터가 있을 때, 각 종류의 양자화 대상데이터에 대하여 본 발명에서의 양자화방법을 채용하여 양자화한 후, 각 종류의 양자화 대상 데이터에 대응하는 양자화 데이터을 얻으며, 각종 양자화 데이터와 양자화할 필요가 없는 연산 데이터를 이용하여 양자화 대상 층 의 연산을 실행할 수 있다. 진일보로, 요구사항에 따라 양자화 대상 층 중 각종 연산 데이터 중의 전부 데이터 또는 부분 데이터를 양자화 대상 데이터로 확정할 수 있으며, 본 발명은 이에 대해 한정하지 않는다. 신경망 연산의 추론단계는 태스크 설정을 완료하기 위해 훈련된 신경망을 전방 연산하는 단계를 포함할 수 있다. 신경망의 추론단계에서, 뉴런, 가중치, 바이어스 및 그래디언트 중의 적어도 한 가지를 양자화 대상 데이 터로 하고, 본 발명 실시예에서의 방법에 따라 양자화한 후, 양자화 후의 데이터를 이용하여 양자화 대상 층의 연산을 완료할 수 있다. 신경망 연산의 미조정단계는 훈련된 신경망을 미리 설정된 수반복의 전방 연산과 역방향 연산하여 파라미터의 미조정을 하며 설정 태스크에 적응하게 하는 단계를 포함할 수 있다. 신경망 연산의 미조정 단계에서, 뉴런, 가 중치, 바이어스, 그래디언트 중의 적어도 한 가지를 본 발명 실시예에서의 방법에 따라 양자화한 후, 양자화 후 의 데이터를 이용하여 양자화 대상 층의 전방 연산 또는 역방향 연산을 완료할 수 있다. 신경망 연산의 훈련단계는 초기화의 신경망을 반복훈련하여 훈련된 신경망을 얻는 단계를 포함할 수 있으며, 훈 련된 신경망은 특정 태스크를 실행할 수 있다. 신경망의 훈련단계에서, 뉴런, 가중치, 바이어스, 그래디언트 중 의 적어도 한 가지를 본 발명 실시예에서의 방법에 따라 양자화한 후, 양자화 후의 데이터를 이용하여 양자화 대상 층의 전방 연산 또는 역방향 연산을 완료할 수 있다. 양자화 대상 층에 대응하는 양자화 파라미터는 하나의 양자화 파라미터일 수 있고, 복수의 양자화 파라미터일 수도 있다. 양자화 파라미터는 점 위치 등 양자화 대상 데이터에 대해 양자화를 수행하기 위한 파라미터을 포함할 수 있다. 점 위치는 양자화 된 데이터에서 소수점의 위치를 확정하는 데 사용될 수 있다. 양자화 파라미터는 스케일 팩터, 오프셋 등을 포함할 수 있다. 신경망에 복수의 양자화 대상 층이 포함될 때, 각 양자화 대상 층은 모두 대응하는 양자화 파라미터를 가질 수 있고, 각 양자화 대상 층에 대응하는 양자화 파라미터는 다를 수도 같을 수도 있으며, 본 발명은 이에 대해 한정하지 않는다. 양자화 대상 층 중 상이한 양자화 대상 데이터에 대하여, 상이한 양자화 파라미터가 대응할 수 있다. 예를 들어, 양자화 대상 층1의 뉴런이 양자화 파라미터1에 대응하고, 양자화 대상 층1의 가중치는 양자화 파라미터2 에 대응할 수 있다. 양자화 대상 층 중 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터를 확정하는 방식은, 미리 설정한 양자화 파라미터를 검색하여 직접 양자화 파라미터를 확정하는 방식, 대응관계를 검색하여 양자화 파라미터를 확정하는 방식, 또는 양자화 대상 데이터에 근거하여 계산하여 양자화 파라미터를 얻는 방식 을 포함할 수있다. 예를 들어, 신경망에서의 양자화 대상 층에 양자화 대상 층 중 각 종류의 양자화 대상 데이터와 대응하는 양자화 파라미터 를 설정할 수 있다. 설정된 양자화 파라미터를 설정한 저장공간에 저장할 수 있다. 설정한 저장공간은 온칩 또 는 오프 칩의 저장공간일 수 있다. 예를 들어, 설정된 양자화 파라미터를 층 식별로 구별하여 설정한 저장공간 에 저장할 수 있다. 각 양자화 대상 층은 양자화할 때 설정한 저장공간에서 대응하는 양자화 파라미터를 추출한 후 양자화를 수행할 수 있다. 경험 값에 의해 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터를 설 정할 수 있다. 요구사항에 근거하여 설정된 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터를 업데 이트할 수도 있다. 예를 들어 이전 층의 양자화 파라미터에 근거하여 다음 층의 양자화 파라미터를 업데이트할 수 있다. 각 양자화 대상 층 중의 양자화 대상 데이터의 데이터 특징 또는 양자화 대상 층의 층 특징에 근거하여, 데이터 특징과 양자화 파라미터의 대응관계를 검색, 또는 층 특징과 양자화 파라미터의 대응관계를 검색함으로써 양자 화 파라미터를 확정할 수 있다. 예를 들어, 양자화 대상 데이터의 데이터 분포가 희박하고 조밀할 때 각각 다른 양자화 파라미터에 대응할 수 있다. 대응관계를 검색함으로써 양자화 대상 데이터의 데이터 분포에 대응하는 양 자화 파라미터를 확정할 수 있다. 또한, 양자화 대상 층이 컨벌루션 층 또는 완전연결층일 때 각각 다른 양자화 파라미터에 대응하게 할 수 있으며, 양자화 대상 층이 컨벌루션 층인 경우 컨벌루션 층에 대응하는 양자화 파라 미터를 검색할 수 있다. 각 양자화 대상 층 중의 양자화 대상 데이터에 근거하여 설정한 양자화 파라미터 계산방법에 따라, 각 양자화 대상 층에 대응하는 양자화 파라미터를 계산하여 얻을 수도 있다. 예를 들어, 양자화 대상 데이터의 절대치 최 대 값과 미리 설정한 데이터 비트폭에 근거하여, 정수 올림 알고리즘을 이용하여 계산을 통해 양자화 파라미터중의 점 위치를 얻을 수 있다. 단계(S20), 대응하는 양자화 파라미터에 근거하여 양자화 대상 데이터를 양자화하여 양자화 데이터를 얻으며, 상기 신경망이 상기 양자화 데이터에 근거하여 연산을 수행하도록 한다. 설정한 양자화 알고리즘을 이용하여, 양자화 파라미터에 근거하여 양자화 대상 데이터을 양자화하여 양자화 데 이터을 얻을 수 있다. 예를 들어, 정수 올림 알고리즘을 양자화 알고리즘으로 이용할 수있고, 데이터 비트폭과 점 위치에 근거하여 양자화 대상 데이터에 대해 정수 올림 양자화하여 양자화 데이터를 얻을 수 있다. 여기에서, 정수 올림 알고리즘은 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 및 반올림 정수 올림 등 을 포함할 수 있다. 본 발명은 양자화 알고리즘의 구체적 실현방식에 대해 한정하지 않는다. 신경망에 복수의 양자화 대상 층이 있는 경우, 각 양자화 대상 층 중의 각 종류의 양자화 대상 데이터는 각각 대응하는 양자화 파라미터를 채용하여 양자화할 수 있다. 각 양자화 대상 데이터에 대응하는 양자화 파라미터가 각 양자화 대상 데이터 자체 특징에 더 적합하기 때문에, 각 양자화 대상 층의 각 종류의 양자화 데이터의 양자 화 정밀도는 본 층의 연산 요구사항에 더 부합된다. 본 층 연산결과 정밀도를 보장한다는 전제하에서, 본 층의 연산효율을 향상시킬 수 있으며, 본 층의 연산효율과 연산결과 정밀도 사이의 균형을 이룰 수 있다. 전체 신경 망에 대해, 각 양자화 대상 층의 연산결과의 정밀도와 연산효율 사이의 균형을 실현하면, 신경망 전체의 연산결 과의 정밀도와 연산효율 사이의 균형도 실현하게 된다. 신경망의 추론, 훈련 및 미조정과정에서, 목표데이터에 대해 오프라인 양자화 또는 온라인 양자화를 수행할 수 있다. 여기에서, 오프라인 양자화는 양자화 파라미터를 이용하여 양자화 대상 데이터를 오프라인 처리하는 것일 수 있다. 온라인 양자화는 양자화 파라미터를 이용하여 양자화 대상 데이터를 온라인 처리하는 것일 수 있다. 예를 들어, 신경망이 인공지능 칩에서 가동되고, 양자화 대상 데이터와 양자화 파라미터를 인공지능 칩 외의 연 산장치에 송신하여 오프라인 양자화하거나, 또는 인공지능 칩 외의 연산장치를 이용하여 미리 획득한 양자화 대 상 데이터와 양자화 파라미터를 오프라인 양자화할 수 있다. 한편, 인공지능 칩이 신경망을 가동하는 과정에서, 인공지능 칩은 양자화 파라미터를 이용하여 양자화 대상 데이터에 대해 온라인 양자화할 수 있다. 신경망에 복 수의 양자화 대상 층이 포함되는 경우, 각 양자화 대상 층은 각각 온라인 양자화와 오프라인 양자화를 수행할 수 있다. 본 발명에서는 각 양자화 대상 층의 양자화 과정이 온라인일지 오프라인일지에 대하여 한정하지 않는 다. 본 실시예에서, 상기 신경망에서 임의의 한 층의 양자화 대상 층에 대하여, 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터와 대응하는 양자화 파라미터를 확정하며, 상기 양자화 대상 데이터는 뉴런, 가중치, 바이어 스, 그래디언트 중 적어도 한 가지를 포함한다. 대응하는 양자화 파라미터에 근거하여 양자화 대상 데이터를 양 자화하여 양자화 데이터를 얻으며, 상기 신경망이 상기 양자화 데이터에 근거하여 연산을 수행하도록 한다. 각 층 양자화 대상 데이터에 적합한 양자화 파라미터를 채용하여 각 양자화 대상 층을 양자화하는 것에 의해, 각 층의 연산결과 정밀도를 보장한다는 전제하에서 각 층의 연산효율을 향상시킬 수 있다. 신경망 전체의 연산결과 정밀도를 보장한다는 전제하에서 신경망 전체의 연산효율을 향상시킬 수도 있다. 가능한 실현방식에서, 상기 양자화 파라미터는 점 위치, 스케일 팩터 및 오프셋 중의 적어도 한 가지를 포함한 다. 여기에서, 상기 점 위치는 양자화 후 소수점의 위치이고, 상기 스케일 팩터는 양자화 된 데이터의 최대 값 과 양자화 대상 데이터의 최대 절대치 사이의 비율이며, 상기 오프셋은 양자화 대상 데이터의 중간 값이다. 가능한 실현방식에서, 양자화 파라미터는 점 위치를 포함할 수 있다. 다음과 같은 수학식 （1）을 이용하여 양 자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. 수학식（1） 여기에서, s는 점 위치이고, 는 양자화 데이터이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정수 연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（1）중의 반올림의 정수연산을 바꿀 수 있다. 이해할 수 있은 것은, 데이터 비트폭이 일정한 경우, 점 위치에 근거하여 양자화하여 얻은 양자화 데이터에서, 소수점 뒤의 비트 수가 많으면 많을 수록 양자화 데이터의 양자화 정밀도가 높아진다. 가능한 실현방식에서, 양자화 파라미터는 스케일 팩터를 포함할 수 있다. 다음과 같은 수학식 （2）을 이용하여 양자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. 수학식（2） 여기에서, 는 스케일 팩터이고, 는 양자화 데이터이며, 는 양자화 대상 데이터이고, 는 반올림에 따 른 정수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정수 로 내림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（2） 중의 반올림의 정수연산을 바꿀 수 있 다. 이해할 수 있은 것은, 데이터 비트폭이 일정한 경우, 상이한 스케일 팩터를 채용하면 양자화 된 데이터의 수치범위를 조정할 수 있다. 가능한 실현방식에서, 양자화 파라미터는 오프셋을 포함할 수 있다. 다음과 같은 수학식 （3）을 이용하여 양자 화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. 수학식（3） 여기에서, 는 오프셋이소, 는 양자화 데이터이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정 수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내 림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（3） 중의 반올림의 정수연산을 바꿀 수 있다. 이해할 수 있은 것은, 데이터 비트폭이 일정한 경우, 서로 다른 오프셋을 채용하여 양자화 된 데이터의 수치와 양자화 전의 데이터 사이의 오프셋을 조정할 수 있다. 가능한 실현방식에서, 양자화 파라미터는 점 위치와 스케일 팩터를 포함할 수 있다. 다음과 같은 수학식 （4） 을 이용하여 양자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. 수학식（4） 여기에서, s는 점 위치이고, 는 스케일 팩터이며, 는 양자화 데이터이고, 는 양자화 대상 데이터이며, 는 반올림에 따른 정수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（4） 중의 반올림 의 정수연산을 바꿀 수 있다. 가능한 실현방식에서, 양자화 파라미터는 점 위치와 오프셋을 포함할 수 있다. 다음과 같은 수학식 （5）을 이 용하여 양자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. 수학식（5） 여기에서, s는 점 위치이고, 는 양자화 데이터이고, 는 양자화 대상 데이터이며, 는 반 올림에 따른 정수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（5） 중의 반올림의 정수연산을 바꿀 수 있다. 가능한 실현방식에서, 양자화 파라미터는 점 위치, 스케일 팩터 및 오프셋을 포함할 수 있다. 다음과 같은 수학 식 （6）을 이용하여 양자화 대상 데이터를 양자화하여 양자화 데이터 를 얻을 수 있다. 수학식（6） 여기에서, s는 점 위치이고, 는 스케일 팩터이며, 는 양자화 데이터이며, 는 양자화 대상 데 이터이고, 는 반올림에 따른 정수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（6）중의 반올림의 정수연산을 바꿀 수 있다. 본 실시예에서, 양자화 파라미터는 점 위치, 스케일 팩터 및 오프셋 중의 적어도 한 가지를 포함한다. 상이한 양자화 파라미터의 조합을 채용하여 양자화 대상 데이터를 양자화하면 상이한 정밀도의 양자화결과를 생성할 수 있다. 요구사항에 따라 양자화 파라미터를 유연히 조합한 후 수요에 따라 사용할 수 있다. 도14는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도14에 도시된 바와 같이, 상기 신 경망의 양자화방법 중의 단계(S10)는 다음과 같은 단계를 포함한다. 단계(S11), 양자화 대상 데이터와 양자화 파라미터의 대응관계를 검색하여 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터를 확정한다. 가능한 실현방식에서, 각 양자화 대상 층 중 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터는, 보 존한 미리 설정된 값일 수 있다. 신경망을 위해 하나의 양자화 대상 데이터와 양자화 파라미터 사이의 대응관계 를 확립할 수 있으며, 당해 대응관계는 각 양자화 대상 층의 각 종류의 양자화 대상 데이터와 양자화 파라미터 의 대응관계일 수 있고, 대응관계를 각 층에서 공유 액세스 가능한 저장공간에 보존할 수 있다. 신경망을 위해 복수의 양자화 대상 데이터와 양자화 파라미터 사이의 대응관계를 확립하고, 각 양자화 대상 층은 각각 그 중의 하나의 대응관계에 대응할 수 있다. 각 층의 대응관계를 본 층에서 독점하는 저장공간에 보존할 수 있으며, 각 층의 대응관계를 각 층에서 공유 액세스가 가능한 저장공간에 보존할 수도 있다. 양자화 대상 데이터와 양자화 파라미터 대응관계에서, 복수의 양자화 대상 데이터와 그에 대응하는 복수의 양자 화 파라미터 사이의 대응관계를 포함할 수 있다. 예를 들어, 양자화 대상 데이터와 양자화 파라미터 대응관계A 에서, 양자화 대상 층1의 뉴런과 가중치 둘의 양자화 대상 데이터를 포함할 수 있으며, 뉴런은 점 위치1, 스케 일 팩터1 및 오프셋1의 3개의 양자화 파라미터에 대응되며, 가중치는 점 위치2와 오프셋2의 2개의 양자화 파라 미터에 대응된다. 본 발명은 양자화 대상 데이터와 양자화 파라미터의 대응관계의 구체적 형식에 대해 한정하지 않는다. 본 실시예에서, 양자화 대상 데이터와 양자화 파라미터의 대응관계를 검색하여 상기 양자화 대상 층 중 각 종류 의 양자화 대상 데이터에 대응하는 양자화 파라미터를 확정할 수 있다 . 각 양자화 대상 층에 대응하는 양자화 파라미터를 미리 설정하고, 대응관계를 통해 저장한 후, 양자화 대상 층이 검색 후에 사용하도록 할 수 있다. 본 실시예에서 양자화 파라미터의 획득방식은 간단하고 편리하다. 도15은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도15에 도시된 바와 같이, 상기 신 경망의 양자화방법 중의 단계(S10)는 다음과 같은 단계를 포함한다. 단계(S12), 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻는다. 각 양자화 대상 데이터에 대응하는 데이터 비트폭 n을 미리 설정할 수 있다. 데이터 비트폭 n과 각 양자화 대상 데이터에 근거하여 계산을 통해 각 양자화 대상 데이터에 대응하는 양자화 파라미터를 얻을 수 있다. 양자화 대 상 데이터 자체에 근거하여 계산을 통해 얻은 양자화 파라미터는, 양자화 대상 데이터 자체의 특징에 더욱 부합 된다. 신경망의 추론, 훈련 및 미조정과정에서, 양자화 대상 데이터는 뉴런, 가중치, 바이어스 중의 적어도 한 가지일 수 있다. 훈련 및 미조정과정에 대하여, 양자화 대상 데이터는 그래디언트를 포함할 수 있다. 신경망의 추론, 훈련 및 미조정과정에서, 온라인으로 획득한 각 양자화 대상 데이터와 이에 대응하는 데이터 비트폭에 근거하여, 각 양자화 대상 데이터에 대응하는 양자화 파라미터를 계산할 수 있다. 본 실시예에서, 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양 자화 파라미터를 얻는다 . 온라인 양자화 대상 데이터에 근거하여 계산을 통해 얻은 양자화 파라미터는, 신경망 양자화 대상 층 중 각종 양자화 대상 데이터 자체의 양자화 요구사항에 더 적합할 수 있다. 도16는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도16에 도시된 바와 같이, 상기 신 경망의 양자화방법에서 단계(S12)는 다음과 같은 단계를 포함한다. 단계(S121), 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터 중의 절대치 최대 값과 상기 목 표데이터에 대응하는 데이터 비트폭에 근거하여 상기 목표데이터의 점 위치를 얻으며, 상기 목표데이터는 임의 의 한 가지 양자화 대상 데이터이다. 가능한 실현방식에서, 양자화 파라미터는 복수의 파라미터를 포함할 수 있으며, 양자화 파라미터가 오프셋을 포 함하지 않는 경우, 양자화 파라미터는 점 위치와 스케일 팩터 중의 적어도 한 가지를 포함할 수 있다. 양자화 파라미터가 오프셋을 포함하지 않는 경우, 임의의 양자화 대상 데이터를 목표 데이터로 할 수 있다. 목표데이터 는 뉴런, 가중치, 바이어스 및 그래디언트 중 임의의 한 가지일 수 있다. 목표데이터는 복수의 요소로 구성된 데이터를 포함할 수 있다. 목표데이터의 각 요소에서 최대 값과 최소 값을 확정하고, 최대 값의 절대치와 최소 값의 절대치에 근거하여 목표데이터 중의 절대치 최대 값을 얻을 수 있다. 목표데이터 중 각 요소의 절대치를 확정하고, 각 요소의 절대치에 근거하여 목표데이터 중의 절대치 최대 값을 얻을 수도 있다. 도17는 본 발명 실시예에 따른 신경망의 양자화방법 중 양자화 파라미터가 오프셋을 포함하지 않을 때 양자화 전후의 데이터를 나타내는 대응 모식도이다. 도17에 도시된 바와 같이, Z1은 목표데이터 중의 절대치 최대 값이 고, 목표데이터에 대응하는 데이터 비트폭 n은 8이며, A는 데이터 비트폭 n로 목표데이터를 양자화한 후 표현할 수 있는 최대 값, 즉 이다. A는 Z1를 포함할 필요가 있고, 또 Z1은 보다 커야 하며, 수학식 （ 7）로 제약할 수 있다. 수학식（7） 목표데이터 중의 절대치 최대 값과 데이터 비트폭에 근거하여 계산을 통해 목표데이터의 점 위치를 얻을 수 있 다. 예를 들어, 다음과 같은 수학식（8）을 이용하여 계산을 통해 양자화 파라미터가 오프셋을 포함하지 않는 경우, 목표데이터의 점 위치s는 다음과 같다. 수학식（8） 여기에서, ceil은 정수로 올림이고, Z1은 목표데이터 중의 절대치 최대 값이며, s는 점 위치이고, n은 목표데 이터에 대응하는 데이터 비트폭이다. 본 실시예에서, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터 중의 절대치 최대 값과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여 상기 목표데이터의 점 위치를 얻는다. 목표데이터에 근거하여 계산을 통해 이에 대응하는 점 위치를 얻으면, 목표데이터 자체의 특징에 보다 부합되게 할 수 있어 목표데이터 의 양자화 정밀도를 보다 높게 할 수 있다. 도18은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도18에 도시된 바와 같이, 상기 신 경망의 양자화방법 중 단계(S12)는 다음과 같은 단계를 포함한다. 단계(S122), 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻으며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 단계(S123), 목표데이터 중의 절대치 최대 값과 상기 목표데이터 양자화 된 데이터의 최대 값에 근거하여 상기 목표데이터의 스케일 팩터를 얻는다. 목표데이터 중의 절대치 최대 값은 상술한 실시예에서의 관련설명을 참조하면 된다. 수학식（9）를 이용하여 계산을 통해 얻은 양자화 파라미터가 오프셋을 포함하지 않는 겨우, 목표데이터의 스케 일 팩터 는 다음과 같다. = 수학식（9） 여기에서, A는 양자화 파라미터가 오프셋을 포함하지 않는 경우, 목표데이터가 양자화된 후의 데이터의 최대 값 은, 수학식（10）을 이용하여 A를 계산할 수 있다. 수학식（10） 본 실시예에서, 양자화 파라미터가 오프셋을 포함하지 않는 경우, 목표데이터 중의 절대치 최대 값과 목표데이 터에 대응하는 데이터 비트폭에 근거하여 계산을 통해 목표데이터에 대응하는 스케일 팩터를 얻을 수 있다. 목표데이터에 근거하여 계산을 통해 이에 대응하는 스케일 팩터를 얻으며, 목표데이터 자체의 특징에 보다 부합되 게 할 수 있어 목표데이터의 양자화 정밀도를 보다 높게 할 수 있다. 도19은 본 발명 실시예에 따른 신경망의 양자화방법 중 양자화 파라미터가 오프셋을 포함할 때 양자화 전후의 데이터를 나타내는 대응 모식도이다. 도19에 도시된 바와 같이, A1과 A2는 n로 목표데이터를 양자화한 후 표현 할 수 있는 최대 값과 최소 값이고, 은 목표데이터 중 모든 요소의 최소 값이며, 는 목표데이터 중 모 든 요소의 최대 값, 즉 이고, 목표데이터를 오프셋 에 따라 평행이동한 후, 또 양자화를 수행할 수 있다. 도20은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도20에 도시된 바와 같이, 상기 신 경망의 양자화방법에서 단계(S12)는 다음과 같은 단계를 포함한다. 단계(S124), 상기 양자화 파라미터에 오프셋이 포함된 경우, 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여, 상기 목표데이터의 점 위치를 얻으며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 가능한 실현방식에서, 양자화 파라미터가 오프셋을 포함하는 경우, 양자화 파라미터는 점 위치, 스케일 팩터 중 의 적어도 한 가지를 포함할 수 있다. 도19에 도시된 바와 같이, 수학식（11）에 따라 계산을 통해 양자화 파라 미터가 오프셋을 포함할 때 목표데이터의 점 위치 를 얻을 수 있다. 수학식（11） 여기에서, ceil은 정수로 올림이고, s는 점 위치이고, n은 목표데이터에 대응하는 데이터 비트폭이다. 본 실시예에서, 양자화 파라미터가 오프셋을 포함하는 경우, 목표데이터 중의 최대 값, 최소 값 및 목표데이터 에 대응하는 데이터 비트폭에 근거하여 계산을 통해 목표데이터에 대응하는 점 위치를 얻을 수 있다. 목표데이 터에 근거하여 계산을 통해 이에 대응하는 점 위치를 얻으면, 목표데이터 자체의 특징에 보다 부합되게 할 수 있어 목표데이터의 양자화 정밀도를 보다 높게 할 수 있다. 도21는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도21에 도시된 바와 같이, 상기 신 경망의 양자화방법에서 단계(S12)는 다음과 같은 단계를 포함한다. 단계(S125), 상기 양자화 파라미터에 오프셋이 포함된 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻으며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 단계(S126), 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값과 상기 목표데이터 양자화 된 데이 터의 최대 값에 근거하여 상기 목표데이터의 스케일 팩터를 얻는다. 가능한 실현방식에서, 양자화 파라미터가 오프셋을 포함하는 경우, 양자화 파라미터는 점 위치, 스케일 팩터 중 의 적어도 한 가지를 포함할 수 있다. 도19에 도시된 바와 같이, 수학식（12）에 따라 계산을 통해 양자화 파라 미터가 오프셋을 포함할 때 목표데이터의 스케일 팩터 를 얻을 수 있다. = 수학식（12） 본 실시예에서, 양자화 파라미터가 오프셋을 포함하는 경우, 목표데이터 중의 최대 값, 최소 값 및 목표데이터 에 대응하는 데이터 비트폭에 근거하여, 계산을 통해 목표데이터에 대응하는 스케일 팩터를 얻을 수 있다. 목표 데이터에 근거하여 계산을 통해 이에 대응하는 스케일 팩터를 얻으며, 목표데이터 자체의 특징에 보다 부합되게 할 수 있어 목표데이터의 양자화 정밀도를 보다 높게 할 수 있다. 도22은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도22에 도시된 바와 같이, 상기 신 경망의 양자화방법에서 단계(S12)는 다음과 같은 단계를 포함한다. 단계(S127), 목표데이터 중의 최대 값과 최소 값에 근거하여 상기 목표데이터의 오프셋을 얻으며, 상기 목표데 이터는 임의의 한 가지 양자화 대상 데이터이다. 가능한 실현방식에서, 도19에 도시된 바와 같이, 수학식（13）을 이용하여 양자화 파라미터가 오프셋을 포함할 때 목표데이터의 오프셋 를 얻을 수 있다 수학식（13） 본 실시예에서, 양자화 파라미터가 오프셋을 포함하는 경우, 목표데이터 중의 최대 값, 최소 값과 목표데이터에 대응하는 데이터 비트폭에 근거하여 계산을 통해 목표데이터에 대응하는 오프셋을 얻을 수 있다. 목표데이터에 근거하여 계산을 통해 이에 대응하는 오프셋을 얻으면, 목표데이터 자체의 특징에 보다 부합되게 할 수 있어 목 표데이터의 양자화 정밀도를 보다 높게 할 수 있다. 도23은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도23에 도시된 바와 같이, 상기 신 경망의 양자화방법은 다음과 같은 단계를 더 포함한다. 단계(S30), 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 상기 목표데이터의 양자화 오 차를 확정하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 목표데이터에 대응하는 양자화 데이터와 목표데이터 사이의 오차에 근거하여 목표데이터의 양자화 오차를 확정 할 수 있다. 설정한 오차 계산방법, 예를 들어 표준차 계산방법, 평균제곱근 오차 계산방법 등을 이용하여 목표 데이터의 양자화 오차를 계산할 수 있다. 양자화 파라미터에 근거하여 목표데이터에 대응하는 양자화 데이터를 역 양자화한 후에 역 양자화 데이터를 얻 으며, 역 양자화 데이터와 목표데이터 사이의 오차에 근거하여, 목표데이터의 양자화 오차를 확정할 수도 있다. 양자화 파라미터가 점 위치를 포함하는 경우, 수학식（14）에 따라 목표데이터의 양자화 데이터를 역 양자화하 여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（14） 여기에서: round는 반올림에 따른 정수연산이고, 는 목표데이터의 역 양자화 데이터이고, s는 목표데이터에 대응하는 점 위치이다. 양자화 파라미터가 스케일 팩터를 포함하는 경우, 수학식（15）에 따라 목표데이터의 양자화 데이터를 역 양자 화하여 목표데이터의 역 양자화 데이터 : 를 얻을 수 있다. 수학식（15） 여기에서: 는 반올림에 따른 정수연산이며, 는 목표데이터의 역 양자화 데이터이고, 는 스케일 팩터이 다. 양자화 파라미터가 오프셋을 포함하는 경우, 수학식（16）에 따라 목표데이터의 양자화 데이터를 역 양자화하여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（16） 여기에서: 는 반올림에 따른 정수연산이다. 는 목표데이터의 역 양자화 데이터이고, 는 스케일 팩터이 다. 양자화 파라미터가 점 위치와 스케일 팩터를 포함하는 경우, 수학식（17）에 따라 목표데이터의 양자화 데이터 를 역 양자화하여 목표데이터의 역 양자화 데이터 : 를 얻을 수 있다. 수학식（17） 양자화 파라미터가 점 위치와 오프셋을 포함하는 경우, 수학식（18）에 따라 목표데이터의 양자화 데이터를 역 양자화하여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（18） 양자화 파라미터가 스케일 팩터와 오프셋을 포함하는 경우, 수학식（19）에 따라 목표데이터의 양자화 데이터를 역 양자화하여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（19） 양자화 파라미터가 점 위치, 스케일 팩터, 및 오프셋을 포함하는 경우, 수학식（20）따라 목표데이터의 양자화 데이터를 역 양자화하여 목표데이터의 역 양자화 데이터 를 얻을 수 있다. 수학식（20） 양자화 간격의 계산에 관한 방법을 통해, 예를 들어, 수학식（21）에 따라 계산하여 목표데이터와 목표데이터에 대응하는 역 양자화 데이터 사이의 오차 diffbit를 얻을 수도 있다. 수학식（21） 여기에서, p는 목표데이터 중 각 요소의 수이고, s는 목표데이터의 점 위치이다. A의 값은 양자화 파라미터에 근거하여 확정할 수 있다. 양자화 파라미터가 점 위치 s를 포함하는 경우, A= ; 양자화 파라미터가 점 위치 s와 스케일 팩터 f를 포함하는 경우, 2개 데이터의 균치 사이의 차이를 계산하는 방법을 통해, 예를 들어 수학식（22）을 통해 계산하여 목표데이 터와 목표데이터에 대응하는 역 양자화 데이터 사이의 오차diffbit 를 얻을 수도 있다. 수학식（22） 2개 데이터의 차이 사이의 균치를 계산하는 방법을 통해, 예를 들어 수학식（23）을 통해 계산하여 목표데이터 와 목표데이터에 대응하는 역 양자화 데이터 사이의 오차를 얻을diffbit: 수도 있다. 수학식（23） 단계(S40), 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조정하 며, 상기 목표데이터에 대응하는 조정 비트폭을 얻는다. 경험 값에 근거하여 오차 한계 값을 확정할 수 있다. 오차 한계 값은 양자화 오차에 대한 기대 값을 표현하는 데 사용할 수 있다. 양자화 오차가 오차 한계 값 이상인 경우, 목표수에 대응하는 데이터 비트폭을 조정하여 목 표데이터에 대응하는 조정 비트폭을 얻을 수 있다. 양자화 정밀도를 향상 또는 저하되게 하기 위해 데이터 비트 폭을 더 긴 비트폭 또는 더 짧은 비트폭으로 조정할 수 있다. 허용 가능한 최대 오차에 근거하여 오차 한계 값을 확정할 수 있다, 양자화 오차가 오차 한계 값보다 클 경우, 양자화 정밀도가 기대에 달하지 않은 것을 설명하며, 데이터 비트폭을 더 긴 비트폭으로 조정할 필요가 있다. 비교적 높은 양자화 정밀도에 근거하여 하나의 비교적 작은 오차 한계 값을 확정할 수도 있다, 양자화 오차가 오차 한계 값보다 작은 경우, 양자화 정밀도가 비교적 높은 것을 설명하며, 신경망의 가동효율이 영향을 받으며, 데이터 비트폭을 더 짧은 비트폭으로 적당히 조정하여 양자화 정밀도를 적당히 저하시키고 신경망의 가 동효율을 향상시킬 수 있다. 데이터 비트폭을 고정의 비트 스텝에 따라 조정할 수 있고, 양자화 오차와 오차 한계 값 사이의 차이 값의 다 름에 따라 가변 조정 스텝에 의해 데이터 비트폭을 조정할 수도 있다. 본 발명은 이에 대해 한정하지 않는다. 단계(S50), 상기 목표데이터에 대응하는 데이터 비트폭을 상기 조정 비트폭으로 업데이트하고, 상기 목표데이터 와 상기 조정 비트폭에 근거하여 계산을 통해 대응하는 조정 양자화 파라미터를 얻으며, 상기 신경망이 상기 조 정 양자화 파라미터에 근거하여 양자화하도록 한다. 조정 비트폭을 확정한 후, 목표데이터에 대응하는 데이터 비트폭을 조정 비트폭으로 업데이트할 수 있다. 예를 들어, 목표데이터의 업데이트 전의 데이터 비트폭이 8비트이고, 조정 비트폭이 12비트이면, 업데이트한 후 목표 데이터에 대응하는 데이터 비트폭은 12비트이다. 조정 비트폭과 목표데이터에 근거하여 계산을 통해 목표데이터 에 대응하는 조정 양자화 파라미터를 얻을 수 있다 . 양자화 정밀도가 보다 높거나 보다 낮은 양자화 데이터을 얻기 위해, 목표데이터에 대응하는 조정 양자화 파라미터에 근거하여 목표데이터를 다시 양자화하여 양자화 대 상 층으로 하여금 양자화 정밀도와 처리효율 사이에서 균형을 이루게 할 수 있다. 신경망의 추론, 훈련 및 미조정과정에서, 각 층 사이의 양자화 대상 데이터는 일정한 관련성을 가진다고 간주할 수 있다. 예를 들어, 각 층의 양자화 대상 데이터 사이의 평균치 사이의 차이가 설정된 균치 한계 값보다 작고, 각 층의 양자화 대상 데이터 사이의 최대 값 사이의 차이 값도 설정된 차이 값 한계 값보다 작은 경우, 양자화 대상 층의 조정 양자화 파라미터를 후속의 하나 또는 복수의 층의 조정 양자화 파라미터로 하여 , 양자화 대상 층의 후속의 하나 또는 복수의 층의 양자화 대상 데이터를 양자화하는 데 사용할 수 있다. 신경망의 훈련 및 미 조정과정에서, 양자화 대상 층에서 현재 반복에 의해 얻은 조정 양자화 파라미터를 후속의 반복에서 양자화 대 상 층에 대한 양자화에 사용할 수도 있다. 가능한 실현방식에서, 상기 방법은 다음과 같은 단계를 더 포함한다. 상기 양자화 대상 층 다음의 한 층 또는 여러 층에서 상기 양자화 대상 층의 양자화 파라미터를 채용한다. 신경망은 조정 양자화 파라미터에 근거하여 양자화하며, 양자화 대상 층에서만 조정 양자화 파라미터를 이용하 여 양자화 대상 데이터를 다시 양자화하는 것을 포함하고, 새로 얻은 양자화 데이터를 양자화 대상 층의 연산에 사용할 수 있다. 양자화 대상 층에서 조정 양자화 파라미터를 사용하여 양자화 대상 데이터를 다시 양자화하는 것이 아니라, 양자화 대상 층의 후속의 하나 또는 복수의 층에서 조정 양자화 파라미터를 사용하여 양자화하는 것, 및/또는 후속의 반복에서 양자화 대상 층에서 조정 양자화 파라미터를 사용하여 양자화하는 것을 포함할 수 도 있다. 양자화 대상 층에서 조정 양자화 파라미터를 사용하여 다시 양자화하며, 새로 얻은 양자화 데이터를 양자화 대상 층의 연산에 사용하고, 양자화 대상 층의 후속의 하나 또는 복수의 층에서 조정 양자화 파라미터를 사용하여 양자화하는 것, 및/또는 후속의 반복에서 양자화 대상 층에서 조정 양자화 파라미터를 사용하여 양자 화하는 것을 더 포함할 수 있다. 본 발명은 이에 대해 한정하지 않는다. 본 실시예에서, 목표데이터와 목표데이터에 대응하는 양자화 데이터에 근거하여 목표데이터의 양자화 오차를 확 정하며, 목표데이터는 임의의 한 가지 양자화 대상 데이터이고; 상기 양자화 오차와 오차 한계 값에 대하여, 목 표데이터에 대응하는 데이터 비트폭을 조정하여 목표데이터에 대응하는 조정 비트폭을 얻으며; 목표데이터에 대 응하는 데이터 비트폭을 조정 비트폭으로 업데이트하고, 목표데이터와 조정 비트폭에 근거하여 계산을 통해 대 응하는 조정 양자화 파라미터를 얻으며, 신경망으로 하여금 조정 양자화 파라미터에 근거하여 양자화하게 한다. 목표데이터와 양자화 데이터 사이의 오차에 근거하여 데이터 비트폭을 조정하며, 조정 후의 데이터 비트폭에 근 거하여 계산을 통해 조정 양자화 파라미터를 얻는다. 서로 다른 오차 한계 값을 설정하는 것을 통해 서로 다른 조정 양자화 파라미터를 얻을 수 있으며, 양자화 정밀도의 향상이나 가동효율의 향상 등 다양한 양자화 요구사 항을 달성할 수 있다. 목표데이터와 목표데이터의 양자화 데이터에 근거하여 계산을 통해 얻은 조정 양자화 파 라미터는 , 목표데이터 자체의 데이터 특징에 보다 적합하고, 목표데이터 자체의 요구에 보다 적합한 양자화 결 과를 달성하며, 양자화 정밀도와 처리효율 사이가 보다 좋은 균형을 달성하도록 할 수도 있다. 도24는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도24에 도시된 바와 같이, 상기 신 경망의 양자화방법에서 단계(S40)는 다음과 같은 단계를 포함한다. 단계(S41), 상기 양자화 오차가 상기 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트 폭을 증가하여 상기 목표데이터에 대응하는 조정 비트폭을 얻는다. 허용 가능한 최대 양자화 오차에 근거하여 제1 오차 한계 값을 확정할 수 있다. 양자화 오차를 제1 오차 한계 값과 비교할 수 있다. 양자화 오차가 제1 오차 한계 값보다 클 경우, 양자화 오차가 허용되지 않는 것으로 간주 할 수 있다. 양자화 정밀도를 향상할 필요가 있는 경우, 목표데이터에 대응하는 데이터 비트폭을 증가하는 방식 으로 목표데이터의 양자화 정밀도를 향상할 수 있다. 목표데이터에 대응하는 데이터 비트폭을 고정된 조정 스텝에 따라 증가하여 조정 비트폭을 얻을 수 있다. 고정 된 조정 스텝은 N비트일 수 있으며, N은 정의 정수이다. 데이터 비트폭을 조정할 때마다 N비트 증가시킬 수 있 다 . 매번 증가한 후의 데이터 비트폭=원래 데이터 비트폭+N비트이다. 목표데이터에 대응하는 데이터 비트폭을 가변의 조정 스텝에 따라 증가하여 조정 비트폭을 얻을 수 있다. 예를 들어, 양자화 오차와 오차 한계 값 사이의 차이 값이 제1 한계 값보다 클 경우, 조정 스텝 M1에 따라 데이터 비트폭을 조정할 수 있으며, 양자화 오차와 오차 한계 값 사이의 차이 값이 제1 한계 값보다 작은 경우, 조정 스 텝 M2에 따라 데이터 비트폭을 조정할 수 있고, 여기에서, 제1 한계 값은 제2 한계 값보다 크며, M1>M2이다. 필 요에 따라 각 가변의 조정 스텝을 확정할 수 있다. 본 발명은 데이터 비트폭의 조정 스텝 및 조정 스텝이 가변 인지 여부에 대해 한정하지 않는다. 목표데이터를 조정 비트폭에 따라 계산을 통해 조정 후의 양자화 파라미터를 얻을 수 있다. 조정 후의 양자화 파라미터를 이용하여 목표데이터를 다시 양자화한 다음에 얻은 양자화 데이터는, 조정하기 전의 양자화 파라미 터를 이용하여 양자화하여 얻은 양자화 데이터보다도 양자화 정밀도가 높다. 도25은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도25에 도시된 바와 같이, 상기 신 경망의 양자화방법은 다음과 같은 단계를 더 포함한다. 단계(S42), 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산 한다. 단계(S43), 상기 조정 후의 양자화 오차와 상기 제1 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터 에 따라 계산하여 얻은 조정 후의 양자화 오차가 상기 제1 오차 한계 값 이하로 될 때까지 상기 조정 비트폭을 계속 증가한다. 양자화 오차에 근거하여 목표데이터에 대응하는 데이터 비트폭을 증가할 때, 비트폭을 1회 조정한 후 조정 비트 폭을 얻으며, 조정 비트폭에 근거하여 계산을 통해 조정 후의 양자화 파라미터를 얻고 , 조정 후의 양자화 파라 미터에 근거하여 목표데이터를 양자화하여 조정 후의 양자화 데이터를 얻으며, 또 조정 후의 양자화 데이터와 목표데이터에 근거하여 계산을 통해 목표데이터 조정 후의 양자화 오차를 얻고, 조정 후의 양자화 오차는 여전 히 제1 오차 한계 값보다 클 가능성이 있다, 즉 1회 조정된 데이터 비트폭에 따라서는 조정목적을 충족할 수 없 는 가능성이 있다 . 조정 후의 양자화 오차가 여전히 제1 오차 한계 값보다 클 때, 조정 후의 데이터 비트폭을 계속 조정할 수 있다, 즉 최종적으로 얻는 조정 비트폭과 목표데이터에 근거하여 얻은 조정 후의 양자화 오차가 제1 오차 한계 값보다 작을 때까지 목표데이터에 대응하는 데이터 비트폭을 여러번 증가한다. 여러번 증가되는 조정 스텝은 고정된 조정 스텝일 수 있고, 가변의 조정 스텝일 수도 있다. 예를 들어, 최종적 인 데이터 비트폭=원래 데이터 비트폭+A*N비트이다. 여기에서N은 매번 증가하는 고정된 조정 스텝이고, A는 데 이터 비트폭의 증가회수이다. 최종적인 데이터 비트폭=원래 데이터 비트폭+M1+M2+…+Mm이다, 여기에서, M1, M2...Mm은 매번 증가되는 가변의 조정 스텝이다. 본 실시예에서, 양자화 오차가 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 증 가하여 상기 목표데이터에 대응하는 조정 비트폭을 얻는다. 제1 오차 한계 값과 조정 스텝을 설정하여 데이터 비트폭을 증가함으로써, 조정 후의 데이터 비트폭이 양자화의 요구사항을 충족시킬 수 있도록 할 수 있다. 1회 조정이 조정의 요구사항을 충족시킬 수 없는 경우, 데이터 비트폭에 대하여 여러번 조정할 수도 있다. 제1 오차 한계 값과 조정 스텝의 설정은 양자화 파라미터를 양자화 요구사항에 따라 유연히 조정할 수 있도록 하며, 다양 한 양자화 요구사항을 충족시켜 양자화 정밀도를 자체의 데이터 특징에 따라 자기 적응적으로 조정할 수 있도록 한다. 도26는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도26에 도시된 바와 같이, 상기 신 경망의 양자화방법에서 단계(S40)는 다음과 같은 단계를 포함한다. 단계(S44), 상기 양자화 오차가 상기 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비 트폭을 감소하며, 상기 제2 오차 한계 값은 상기 제1 오차 한계 값보다 작다. 허용 가능한 양자화 오차와 소망의 신경망의 가동효율에 따라 제2 오차 한계 값을 확정할 수 있다. 양자화 오차 를 제2 오차 한계 값과 비교할 수 있다. 양자화 오차가 제2 오차 한계 값보다 작은 경우, 양자화 오차가 기대를 초과한다고 간주할 수 있으나 가동효율이 너무 낮아 이미 허용할 수 없다. 양자화 정밀도를 저하시켜 신경망의 가동효율을 향상시킬 수 있고, 목표데이터에 대응하는 데이터 비트폭을 감소하는 방식을 통해 목표데이터의 양 자화 정밀도를 저하시킬 수 있다. 목표데이터에 대응하는 데이터 비트폭을 고정된 조정 스텝에 따라 감소시켜 조정 비트폭을 얻을 수 있다. 고정 된 조정 스텝은 N비트일 수 있으며, N은 정의 정수이다. 매번 조정에서 데이터 비트폭은 N비트 감소할 수 있다. 증가 후의 데이터 비트폭=원래 데이터 비트폭-N비트이다. 목표데이터에 대응하는 데이터 비트폭을 가변의 조정 스텝에 따라 감소시켜 조정 비트폭을 얻을 수 있다. 예를 들어, 양자화 오차와 오차 한계 값 사이의 차이 값이 제1 한계 값보다 클 경우, 조정 스텝 M1에 따라 데이터 비 트폭을 조정할 수 있으며, 양자화 오차와 오차 한계 값 사이의 차이 값이 제1 한계 값보다 작은 경우, 조정 스 텝 M2에 따라 데이터 비트폭을 조정할 수 있고, 여기에서, 제1 한계 값은 제2 한계 값보다 크며, M1>M2이다. 필 요에 따라 각 가변의 조정 스텝을 확정할 수 있다. 본 발명은 데이터 비트폭의 조정 스텝 및 조정 스텝이 가변 인지 여부에 대해 한정하지 않는다. 목표데이터를 조정 비트폭에 따라 계산을 통해 조정 후의 양자화 파라미터를 얻을 수 있다 , 조정 후의 양자화 파라미터를 이용하여 목표데이터를 다시 양자화한 다음에 얻은 양자화 데이터는, 조정하기 전의 양자화 파라미 터를 이용하여 양자화하여 얻은 양자화 데이터보다도 양자화 정밀도가 낮다. 도27는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도27에 도시된 바와 같이, 상기 신 경망의 양자화방법은 다음과 같은 단계를 더 포함한다. 단계(S45), 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산 한다. 단계(S46), 상기 조정 후의 양자화 오차와 상기 제2 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터 에 따라 계산을 통해 얻은 조정 후의 양자화 오차가 상기 제2 오차 한계 값 이상이 될 때까지 상기 조정 비트폭 을 계속 감소한다. 양자화 오차에 근거하여 목표데이터에 대응하는 데이터 비트폭을 증가할 때, 비트폭을 1회 조정한 후 조정 비트 폭을 얻으며, 조정 비트폭에 근거하여 계산을 통해 조정 후의 양자화 파라미터를 얻고, 조정 후의 양자화 파라 미터에 근거하여 목표데이터를 양자화하여 조정 후의 양자화 데이터를 얻으며, 또 조정 후의 양자화 데이터와 목표데이터에 근거하여 계산을 통해 목표데이터 조정 후의 양자화 오차를 얻고, 조정 후의 양자화 오차는 여전 히 제2 오차 한계 값보다 작을 가능성이 있다, 즉 1회 조정된 데이터 비트폭에 따라서는 조정목적을 충족할 수 없는 가능성이 있다. 조정 후의 양자화 오차가 여전히 제2 오차 한계 값보다 작은 경우, 조정 후의 데이터 비트 폭을 계속 조정할 수 있다, 즉 최종적으로 얻은 조정 비트폭과 목표데이터에 근거하여 얻은 조정 후의 양자화 오차가 제2 오차 한계 값보다 클 때까지 목표데이터에 대응하는 데이터 비트폭를 여러번 감소한다. 여러번 감소하는 조정 스텝은 고정된 조정 스텝일 수 있고, 가변의 조정 스텝일 수도 있다. 예를 들어, 최종적 인 데이터 비트폭=원래 데이터 비트폭-A*N비트 , 여기에서N은 매번 증가하는 고정된 조정 스텝이고, A는 데이터 비트폭의 증가회수이다. 최종적인 데이터 비트폭=원래 데이터 비트폭-M1-M2-...-Mm, 여기에서, M1, M2...Mm은 매번 감소하는 가변의 조정 스텝이다. 본 실시예에서, 양자화 오차가 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 감소하여 상기 목표데이터에 대응하는 조정 비트폭을 얻는다. 제2 오차 한계 값과 조정 스텝을 설정하여 데이터 비트폭을 감소하는 것을 통해 조정 후의 데이터 비트폭이 양자화의 요구사항을 충족시킬 수 있도록 할 수 있다. 1회 조정이 조정의 요구사항을 충족시킬 수 없는 경우, 데이터 비트폭에 대하여 여러번 조정할 수도 있다. 제2 오차 한계 값과 조정 스텝의 설정은 양자화 파라미터를 양자화 요구사항에 따라 유연히 자기 적응적으로 조정할 수 있도록 하며, 다양한 양자화 요구사항을 충족시켜 양자화 정밀도를 조정 가능하게 하며, 양자화 정밀도와 신 경망의 가동효율 사이의 균형을 잡을 수 있도록 한다. 가능한 실현방식에서, 상기 방법은 다음과 같은 단계를 더 포함한다. 상기 양자화 오차가 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 증가하며, 상 기 양자화 오차가 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 감소하여 상 기 목표데이터에 대응하는 조정 비트폭을 얻는다. 2개의 오차 한계 값을 동시에 설정할 수도 있다. 여기에서, 제1 오차 한계 값은 양자화 정밀도가 지나치게 낮음 을 나타내기 위한 것이고, 데이터 비트폭의 비트 수를 증가할 수 있으며, 제2 오차 한계 값은 양자화 정밀도가 지나치게 높음을 나타내기 위한 것이고, 데이터 비트폭의 비트 수를 감소할 수 있다. 제1 오차 한계 값은 제2 오차 한계 값보다도 크며, 목표데이터의 양자화 오차를 2개의 오차 한계 값과 동시에 비교하여, 양자화 오차가 제1 오차 한계 값보다 클 경우, 데이터 비트폭의 비트 수를 증가하고, 양자화 오차가 제2 오차 한계 값보다 작 은 경우, 데이터 비트폭의 비트 수를 감소할 수 있다. 양자화 오차가 제1 오차 한계 값과 제2 오차 한계 값 사 이에 위치할 때, 데이터 비트폭은 변하지 않도록 유지될 수 있다. 본 실시예에서, 양자화 오차를 제1 오차 한계 값 및 제2 오차 한계 값과 동시에 비교함으로써, 비교결과에 따라 데이터 비트폭을 증가 또는 감소할 수 있고, 제1 오차 한계 값과 제2 오차 한계 값을 이용하여 보다 유연하게 데이터 비트폭을 조정할 수 있다. 따라서 데이터 비트폭의 조정결과를 양자화 수요사하에 보다 적합하게 한다. 도28은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도28에 도시된 바와 같이, 상기 신 경망 연산의 미조정단계 및/또는 훈련단계에서, 상기 방법은 다음과 같은 단계를 포함한다. 단계(S60), 현재 반복 및 상기 현재 반복 전의 반복인 이력 반복 중 목표데이터의 데이터 변동폭을 획득한다. 신경망 연산의 미조정단계 및/또는 훈련단계에는 복수의 반복이 포함된다. 신경망 중의 각 양자화 대상 층은, 1 회 순방향 연산 및 1회 역방향 연산을 수행하고, 양자화 대상 층의 가중치를 업데이트한 후, 1회 반복을 완료 한다. 여러번 반복에서, 양자화 대상 층 중의 목표데이터 및/또는 목표데이터에 대응하는 양자화 데이터의 데이 터 변동폭은, 상이한 반복에서 목표데이터 및/또는 양자화 데이터가 동일한 양자화 파라미터를 채용하여 양자화 를 수행할 수 있는지 가늠할 수 있다. 현재 반복 및 이력 반복에서 목표데이터의 데이터 변동폭이 작으면, 예를 들어 설정된 변동폭 변동 한계 값보다 작으면, 데이터 변동폭이 상대적으로 작은 복수의 반복에서 동일한 양자 화 파라미터를 채용할 수 있다. 미리 저장된 양자화 파라미터를 추출하는 방식을 통해 목표데이터에 대응하는 양자화 파라미터를 확정할 수 있 다. 상이한 반복에서 목표데이터를 양자화할 때, 각 반복에서 목표데이터에 대응하는 양자화 파라미터를 추출할 필요가 있다. 복수의 반복의 목표데이터 및/또는 목표데이터에 대응하는 양자화 데이터의 데이터 변동폭이 작으 면, 데이터 변동폭 상대적으로 작은 복수의 반복에서 채용한 동일한 양자화 파라미터를 일시적으로 저장할 수 있고, 각 반복은 양자화할 때 일시적으로 저장한 양자화 파라미터를 이용하여 양자화 연산을 수행할 수 있으며, 반복마다 양자화 파라미터를 추출할 필요가 없다. 목표데이터와 데이터 비트폭에 근거하여 계산을 통해 양자화 파라미터을 얻을 수 있다. 상이한 반복에서 목표데 이터를 양자화할 때, 각 반복에서 각각 양자화 파라미터를 계산할 필요가 있다. 복수의 반복의 목표데이터 및/ 또는 목표데이터에 대응하는 양자화 데이터의 데이터 변동폭이 작으면, 데이터 변동폭 작은 복수의 반복에서 채 용한 동일한 양자화 파라미터는, 매번 반복마다 양자화 파라미터를 계산하는 것이 아니라, 각 반복에서 모두 첫 번째 반복에서 계산하여 얻은 양자화 파라미터를 직접 사용할 수 있다. 이해할 수 있은 것은, 목표데이터가 가중치인 경우, 각 반복 사이의 가중치는 지속적으로 업데이트되며, 복수의 반복의 가중치의 데이터 변동폭이 작거나, 또는 복수의 반복의 가중치에 대응하는 양자화 데이터의 데이터 변동 폭이 작으면, 복수의 반복에서 동일한 양자화 파라미터를 이용하여 가중치를 양자화할 수 있다. 단계(S70), 상기 목표데이터의 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정함으 로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하며, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이 터이다. 목표데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정할 수 있다. 목표반복간격은 적어도 1회 반복을 포 함하며, 목표반복간격 내의 각 반복에서 동일한 양자화 파라미터를 사용할 수 있다. 즉 목표반복간격 내의 각 반복에서 목표데이터의 양자화 파라미터를 다시 업데이트하지 않는다. 신경망은 목표반복간격에 근거하여 목표 데이터의 양자화 파라미터를 업데이트하며, 목표반복간격 내에 포함된 반복은, 미리 설정한 양자화 파라미터를 획득하지 않거나 양자화 파라미터를 계산하지 않는다. 즉 목표반복간격 내의 반복양자화 파라미터를 업데이트하 지 않는다. 한편, 목표반복간격 외의 반복은, 미리 설정한 양자화 파라미터를 다시 획득하거나 양자화 파라미터 를 다시 계산한다. 즉 목표반복간격 외의 반복은 양자화 파라미터를 업데이트한다. 이해할 수 있은 것은, 복수의 반복 사이의 목표데이터 또는 목표데이터의 양자화 데이터의 데이터 변동폭 작을 수록, 확정한 목표반복간격에 포함된 반복회수가 많다. 계산하여 얻은 데이터 변동폭에 근거하여, 미리 설정한 데이터 변동폭과 반복간격의 대응관계를 검색하며, 계산하여 얻은 데이터 변동폭에 대응하는 목표반복간격을 확 정할 수 있다. 요구사항에 근거하여 데이터 변동폭과 반복간격의 대응관계를 미리 설정할 수 있다. 계산하여 얻 은 데이터 변동폭에 근거하여, 설정한 계산방법을 이용하여 계산을 통해 목표반복간격을 얻을 수 있다. 본 발명 은 데이터 변동폭의 계산방식, 및 목표반복간격의 획득방식에 대해서는 한정하지 않는다. 본 실시예에서, 신경망 연산의 미조정단계 및/또는 훈련단계에서, 현재 반복 및 이력 반복에서 목표데이터의 데이터 변동폭을 획득하며, 상기 목표데이터의 데이터 변동폭에 근거하여, 목표데이터에 대응하는 목표반복간격 을 확정하며, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도 록 한다. 복수의 반복에서 목표데이터 또는 목표데이터에 대응하는 양자화 데이터의 데이터 변동폭에 근거하여,목표반복간격을 확정할 수 있다. 신경망은 목표반복간격에 근거하여 양자화 파라미터를 업데이트할지 여부를 확 정할 수 있다. 목표반복간격에 포함된 복수의 반복의 데이터 변동폭이 작기 때문에, 목표반복간격 내의 반복은 양자화 파라미터를 업데이트하지 않아도 양자화 정밀도를 보장할 수 있다. 한편, 목표반복간격 내의 복수의 반 복양자화 파라미터를 업데이트하지 않으면, 양자화 파라미터의 추출회수 또는 계산회수를 감소하여, 신경망의 연산효율을 향상시킬 수 있다. 도29은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도29에 도시된 바와 같이, 상기 신 경망의 양자화방법은 다음과 같은 단계를 더 포함한다. 단계(S80), 상기 목표데이터의 상기 현재 반복에서의 데이터 비트폭에 근거하여 상기 목표데이터의 상기 목표반 복간격 내의 반복에 대응하는 데이터 비트폭을 확정함으로써, 상기 신경망이 상기 목표데이터의 상기 목표반복 간격 내의 반복에 대응하는 데이터 비트폭에 근거하여 양자화 파라미터를 확정하도록 한다. 본 발명의 상술한 실시예에서 설명한 바와 같이, 목표데이터의 양자화 파라미터는 미리 설정할 수도 있고, 목표 데이터에 대응하는 데이터 비트폭에 따라 계산하여 얻을 수도 있다. 상이한 양자화 대상 층에서 목표데이터에 대응하는 데이터 비트폭, 또는 동일한 양자화 대상 층에서 목표데이터의 상이한 반복에서 대응하는 데이터 비트 폭은, 본 발명 상술한 실시예에서의 방식에 근거하여 자기 적응적으로 조정할 수 있다. 목표데이터의 데이터 비트폭이 자기 적응적으로 조정할 수 없고, 미리 설정한 데이터 비트폭인 경우, 목표데이 터의 현재 반복에서 미리 설정된 데이터 비트폭에 근거하여, 목표데이터의 목표반복간격 내 반복에 대응하는 데 이터 비트폭을 확정한다. 목표반복간격 내의 각 반복은 자체의 미리 설정된 값을 사용하지 않을 수 있다. 목표데이터의 데이터 비트폭이 자기 적응적으로 조정될 수 있는 경우, 목표데이터의 현재 반복에 대응하는 데이 터 비트폭에 근거하여, 목표데이터의 목표반복간격 내 반복에 대응하는 데이터 비트폭을 확정할 수 있다. 데이 터 비트폭이 자기 적응적으로 조정할 수 있는 경우, 데이터 비트폭은 1회 조정 또는 여러번 조정을 할 수 있다. 목표데이터의 현재 반복에서 자기 적응적으로 조정한 후의 데이터 비트폭을, 목표반복간격 내의 각 반복에 대응 하는 데이터 비트폭으로 하고, 목표반복간격 내의 각 반복에서 다시 데이터 비트폭에 대하여 자기 적응적으로 조정（업데이트）하지 않을 수 있다. 목표데이터는 현재 반복에서 자기 적응적으로 조정한 후의 데이터 비트폭 을 사용할 수도 있고, 자기 적응적으로 조정하기 전의 데이터 비트폭을 사용할 수도 있다. 본 발명은 이에 대해 한정하지 않는다. 목표반복간격 이외의 다른 반복에서, 목표데이터의 데이터 변동폭이 설정조건을 충족시키지 않으므로, 본 발명 의 상술한 방법에 따라 데이터 비트폭을 자기 적응적으로 조정하여, 현재 반복의 목표데이터에 더 적합한 데이 터 비트폭을 얻을 수 있으며, 본 발명에서의 목표반복간격의 계산방법을 사용하여, 계산을 통해 새로운 목표반 복간격을 얻어 사용할 수도 있으며, 목표반복간격 이외의 반복의 양자화 정밀도를 보장함과 동시에, 신경망의 가동효율을 향상시킨다. 목표반복간격 내의 각 반복의 데이터 비트폭은 같으며, 각 반복은 동일한 데이터 비트폭에 근거하여 각기 계산 하여 대응하는 양자화 파라미터를 얻을 수 있다. 양자화 파라미터는 점 위치, 스케일 팩터 및 오프셋 중의 적어 도 한 가지를 포함할 수 있다. 목표반복간격 내의 각 반복에서, 동일한 데이터 비트폭에 근거하여 계산을 통해 양자화 파라미터를 각각 얻을 수 있다. 양자화 파라미터가 점 위치, 스케일 팩터 및 오프셋을 포함할 때, 목표 반복간격 내의 각 반복은, 동일한 데이터 비트폭을 이용하여 각기 대응하는 점 위치, 스케일 팩터 및 오프셋을 각각 계산할 수 있다. 현재 반복의 데이터 비트폭에 근거하여, 목표반복간격 내 각 반복의 데이터 비트폭을 확정함과 동시에, 현재 반 복의 양자화 파라미터에 근거하여 목표반복간격 내 각 반복의 대응하는 양자화 파라미터를 확정할 수 있다. 목 표반복간격 내 각 반복의 양자화 파라미터도 다시 동일한 데이터 비트폭에 근거하여 계산을 통해 얻지 않으며, 진일보로 신경망의 연산효율을 향상시킬 수 있다. 현재 반복의 전부 양자화 파라미터 또는 일부 양자화 파라미 터에 근거하여, 목표반복간격 내 각 반복의 대응하는 양자화 파라미터를 확정할 수 있다. 현재 반복의 일부 양 자화 파라미터에 근거하여 목표반복간격 내 각 반복의 대응하는 양자화 파라미터를 확정할 때, 나머지 부분의 양자화 파라미터는 목표반복간격 내 각 반복에서 계산되어야 한다. 예를 들어, 양자화 파라미터는 점 위치, 스케일 팩터 및 오프셋을 포함한다. 현재 반복의 데이터 비트폭과 점 위치에 근거하여 목표반복간격 내 각 반복의 데이터 비트폭과 점 위치를 확정할 수 있다. 목표반복간격 내 각 반복의 스케일 팩터와 오프셋은 동일한 데이터 비트폭에 근거하여 계산을 통해 얻는다. 현재 반복의 데이터 비 트폭, 점 위치, 스케일 팩터 및 오프셋에 근거하여, 목표반복간격 내 각 반복의 데이터 비트폭, 점 위치, 스케일 팩터 및 오프셋을 확정할 수도 있으며, 목표반복간격 내 각 반복의 각 양자화 파라미터 모두 계산하여 얻을 필요가 없다. 본 실시예에서, 목표데이터의 현재 반복에 대응하는 데이터 비트폭에 근거하여, 목표데이터의 목표반복간격 내 반복에 대응하는 데이터 비트폭을 확정하며, 신경망으로 하며금 목표데이터의 목표반복간격 내의 반복에 대응하 는 데이터 비트폭에 근거하여 양자화 파라미터를 확정하도록 한다. 목표반복간격 내의 각 반복의 데이터 비트폭 은, 현재 반복의 데이터 비트폭에 의해 확정되며, 목표반복간격 내 각 반복의 목표데이터의 데이터 변화폭이 설 정조건을 충족하므로 동일한 데이터 비트폭을 이용하여 계산하여 얻은 양자화 파라미터는 목표반복간격 내의 각 반복의 양자화 정밀도를 보장할 수 있다. 목표반복간격 내 각 반복이 동일한 데이터 비트폭을 사용하면, 신경망 의 연산효율을 향상시킬 수도 있다. 신경망을 양자화한 후 연산결과의 정밀도와 신경망의 연산효율 사이에 균형 을 이룬다. 도30은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도30에 도시된 바와 같이, 상기 신 경망의 양자화방법은 다음과 같은 단계를 더 포함한다. 단계(S90), 상기 목표데이터의 상기 현재 반복에 대응하는 점 위치에 근거하여 상기 목표데이터의 상기 목표반 복간격 내의 반복에 대응하는 점 위치를 확정한다. 양자화 파라미터에서, 스케일 팩터와 오프셋에 대하여, 상이한 점 위치가 동일한 목표데이터에 대한 양자화결과 에 주는 영향이 크다. 목표데이터의 현재 반복에 대응하는 점 위치에 근거하여 목표반복간격 내의 반복에 대응 하는 점 위치를 확정할 수 있다. 데이터 비트폭이 자기 적응적으로 조정할 수 없을 경우, 목표데이터의 현재 반 복에서 미리 설정된 점 위치를, 목표데이터의 목표반복간격 내 각 반복에 대응하는 점 위치로 할 수 있다. 또한, 목표데이터의 현재 반복에서 미리 설정한 데이터 비트폭에 근거하여 계산하여 얻은 점 위치를, 목표데이 터의 목표반복간격 내 각 반복에 대응하는 점 위치로 할 수 있다. 데이터 비트폭이 자기 적응적으로 조정될 수 있는 경우, 목표데이터의 현재 반복에서 조정된 후의 점 위치를, 목표데이터의 목표반복간격 내 각 반복에 대응 하는 점 위치로 할 수 있다. 상기 목표데이터의 상기 현재 반복에 대응하는 점 위치에 근거하여 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 점 위치를 확정함과 동시에, 목표데이터의 현재 반복에 대응하는 스케일 팩터에 근거하여, 상 기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 스케일 팩터를 확정, 및/또는 목표데이터의 현재 반 복에 대응하는 오프셋에 근거하여, 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 오프셋을 확정 할 수도 있다. 상기 목표데이터의 상기 현재 반복에 대응하는 점 위치에 근거하여 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 점 위치를 확정함과 동시에, 목표데이터의 현재 반복에 대응하는 데이터 비트폭에 근거하여, 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 데이터 비트폭을 확정할 수도 있다. 여기에서, 목 표데이터의 현재 반복에 대응하는 데이터 비트폭은 현재 반복에서 미리 설정된 데이터 비트폭 또는 자기 적응적 으로 조정한 후의 데이터 비트폭일 수 있다. 본 실시예에서, 목표데이터의 현재 반복에 대응하는 점 위치에 근거하여 목표데이터의 목표반복간격 내의 반복 에 대응하는 점 위치를 확정한다. 목표반복간격 내의 각 반복의 점 위치는 현재 반복의 점 위치에 의해 확정되 며, 목표반복간격 내 각 반복의 목표데이터의 데이터 변화폭이 설정조건을 충족시키므로, 동일한 점 위치를 이 용하여, 목표반복간격 내의 각 반복의 양자화 정밀도를 보장할 수 있다. 목표반복간격 내 각 반복이 동일한 점 위치를 사용하면 신경망의 연산효율을 향상시킬 수도 있다. 신경망을 양자화한 후 연산결과의 정밀도와 신경망 의 연산효율 사이에 균형을 이룬다. 도31는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도31에 도시된 바와 같이, 상기 신 경망의 양자화방법에서 단계(S60)는 다음과 같은 단계를 포함한다. 단계(S61), 목표데이터의 현재 반복의 점 위치, 및 이력 반복간격에 근거하여 확정한 상기 현재 반복에 대응하 는 이력 반복의 점 위치에 근거하여, 목표데이터의 각 반복간격에 대응하는 점 위치의 이동평균 값을 계산한다. 단계(S62), 상기 목표데이터의 현재 반복의 점 위치의 제1 이동평균 값 및 전회 반복간격에서 대응하는 반복의 점 위치의 제2 이동평균 값에 근거하여 제1 데이터 변동폭을 얻는다. 상기 단계(S70)는 다음과 같은 단계를 포함한다. 단계(S71), 상기 제1 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정하여 상기 신 경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 한다. 가능한 실현방식에서, 이력 반복간격에 근거하여 확정한 상기 현재 반복에 대응하는 이력 반복은 목표반복간격 을 계산하는 이력 반복일 수 있다. 현재 반복과 대응하는 목표반복간격 사이의 대응관계는 다음과 같은 것을 포 함할 수 있다. 현재 반복부터 시작하여 목표반복간격을 카운트하며, 현재 반복에 대응하는 목표반복간격이 종료한 후 다음 반 복부터 다시 목표반복간격을 계산할 수 있다. 예를 들어, 현재 반복이 제100세대이고, 목표반복간격이 3이며, 목표반복간격내의 반복에 제100세대, 제101세대 및 제102세대가 포함되면, 제103세대에서 제103세대와 대응하는 목표반복간격을 계산하고, 103세대를 새로 계산하여 얻은 당해 목표반복간격 내의 첫 번째 반복으로 할 수 있다. 이 때, 현재 반복이 103세대인 경우, 이력 반복간격에 근거하여 확정한 상기 현재 반복에 대응하는 이력 반복은 100세대이다. 현재 반복의 다음 반복부터 시작하여 목표반복간격을 카운트하고, 목표반복간격 내의 마지막 반복부터 시작하여 다시 목표반복간격을 계산할 수 있다. 예를 들어, 현재 반복이 제100세대이고, 목표반복간격이 3이며, 목표반복 간격내의 반복에 제101세대, 제102세대 및 제103세대가 포함되면, 제103세대에서 제103세대와 대응하는 목표반 복간격을 계산하고, 104세대를 새로 계산하여 얻은 당해 목표반복간격 내의 첫 번째 반복으로 할 수 있다. 이 때, 현재 반복이 103세대인 경우, 이력 반복간격에 근거하여 확정한 상기 현재 반복에 대응하는 이력 반복은 100세대이다. 현재 반복의 다음 반복부터 시작하여 목표반복간격을 카운트하고, 목표반복간격이 종료된 후의 다음 반복부터 시작하여 다시 목표반복간격을 계산한다. 예를 들어, 현재 반복이 제100세대이고, 목표반복간격이 3이며, 목표 반복간격내의 반복에 제101세대, 제102세대 및 제103세대가 포함되면, 제104세대에서 제104세대에 대응하는 목 표반복간격을 계산하고, 105세대를 새로 계산하여 얻은 당해 목표반복간격 내의 첫 번째 반복으로 할 수 있다. 이 때, 현재 반복이 104세대인 경우, 이력 반복간격에 근거하여 확정한 상기 현재 반복에 대응하는 이력 반복은 100세대이다. 요구사항에 근거하여 현재 반복 및 목표반복간격 사이의 다른 대응관계를 확정할 수 있다. 예를 들어 현재 반복 다음의 N 번째 반복부터 시작하여 목표반복간격을 카운트할 수 있다. N은 1보다 크며, 본 발명은 이에 대해 한 정하지 않는다. 이해할 수 있은 것은, 계산하여 얻은 목표데이터는 각 반복간격의 점 위치의 이동평균 값에 대응하며, 목표데이 터의 현재 반복의 점 위치의 제1 이동평균 값, 및 목표데이터의 전회 반복간격에서 대응한는 반복의 점 위치의 제2 이동평균 값을 포함한다. 수학식（24）을 이용하여 현재 반복에서 대응하는 점 위치의 제1 이동평균 값 를 계산한다. 수학식（24） 여기에서, t는 현재 반복이고, t-1은 전회 반복간격에 따라 확정한 이력 반복이며, 은 전회 반복간격에 따 라 확정한 이력 반복의 제2 이동평균 값이고, 는 현재 반복의 점 위치이며, 는 제1 파라미터이다. 제1 파라 미터는 하이퍼 파라미터일 수 있다. 본 실시예에서, 목표데이터의 현재 반복의 점 위치, 및 이력 반복간격에 근거하여 확정한 상기 현재 반복에 대 응하는 이력 반복의 점 위치에 근거하여, 목표데이터의 각 반복간격에 대응하는 점 위치의 이동평균 값을 계산 한다. 목표데이터의 현재 반복의 점 위치의 제1 이동평균 값 및 전회 반복간격에 대응하는 반복의 점 위치의 제 2 이동평균 값에 근거하여 제1 데이터 변동폭을 얻는다. 제1 데이터 변동폭에 근거하여 상기 목표데이터에 대응 하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파 라미터를 업데이트하도록 한다. 제1 데이터 변동폭은 점 위치의 변화추세를 가늠하는 데 사용되며, 목표반복간 격을 목표데이터의 점 위치의 변화추세에 따라 변화되게 할 수 있으며, 계산하여 얻은 각 목표반복간격의 크기 도 목표데이터의 점 위치의 변화추세에 따라 변화되게 할 수 있다. 양자화 파라미터는 목표반복간격에 근거하여 확정되기 때문에, 양자화 파라미터에 근거하여 양자화하여 얻은 양자화 데이터를 목표데이터의 점 위치의 변동 추세에 보다 부합되도록 할 수 있고, 양자화 정밀도를 보장함과 동시에 신경망의 가동효율을 향상시킬 수 있다. 도32은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도32에 도시된 바와 같이, 도시한 신경망의 양자화방법에서 단계(S62)는 다음과 같은 단계를 포함한다. 단계(S621), 상기 제1 이동평균 값과 상기 제2 이동평균 값의 차이 값을 계산한다. 단계(S622), 상기 차이 값의 절대치를 제1 데이터 변동폭으로 확정한다. 수학식（25）를 이용하여 제1 데이터 변동폭 을 계산할 수 있다. 수학식（25） 제1 데이터 변동폭에 근거하여 목표데이터에 대응하는 목표반복간격을 확정함으로써, 신경망으로 하여금 목표반 복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 할 수 있다. 수학식（26）에 따라 계 산을 통해 목표반복간격 을 얻을 수 있다. 수학식（26） 여기에서, 는 제2 파라미터이고, 은 제3 파라미터이다. 제2 파라미터와 제3 파라미터는 하이퍼 파라미터일 수 있다. 이해할 수 있은 것은, 제1 데이터 변동폭은 점 위치의 변화추세를 가늠하는 데 사용될 수 있고, 제1 데이터 변 동폭이 클 수록 양자화 데이터의 수치범위변화가 급격함을 의미하며, 양자화 파라미터를 업데이트할 때 간격이 보다 짧은 목표반복간격 이 필요하다. 본 실시예에서, 상기 제1 이동평균 값과 상기 제2 이동평균 값의 차이 값을 계산하고; 차이 값의 절대치를 제1 데이터 변동폭으로 확정한다. 이동평균 값 사이의 차이 값에 근거하여 정확한 제1 데이터 변동폭을 얻을 수 있 다. 도33은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도33에 도시된 바와 같이, 상기 신 경망의 양자화방법은 다음과 같은 단계를 더 포함한다: 단계(S63), 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 제2 데이 터 변동폭을 얻는다. 상기 단계(S70)는 다음과 같은 단계를 포함한다. 단계(S72), 상기 목표데이터의 제1 데이터 변동폭과 상기 제2 데이터 변동폭에 근거하여 상기 목표데이터에 대 응하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 한다. 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 제2 데이터 변동폭을 얻을 수 있다. 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 역 양자화 데이터에 근거하여 제2 데이터 변동폭을 얻을 수 있다. 동일하게, 수학식（23）에 따라 계산하여 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 역 양 자화 데이터 사이의 제2 데이터 변동폭 을 얻을 수 있다. 또한 다른 오차의 계산방법을 이용하여 목표데이 터와 역 양자화 데이터 사이의 제2 데이터 변동폭 을 계산할 수도 있다. 본 발명은 이에 대해 한정하지 않 는다. 수학식（23） 여기에서, 는 목표데이터이고, 은 목표데이터에 대응하는 역 양자화 데이터이다. 이해할 수 있은 것은, 제 2 데이터 변동폭은 목표데이터에 대응하는 데이터 비트폭의 변화추세를 가늠하는 데 사용될 수 있다. 제2 데이 터 변동폭이 크면 클 수록, 목표데이터는 대응하는 데이터 비트폭을 업데이트해야 할 가능성이 있으며, 간격이 보다 짧은 반복으로 업데이트할 필요가 있고, 제2 데이터 변동폭이 크면 클 수록, 목표반복간격이 보다 작을 것 이 필요하다. 본 실시예에서, 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 제2 데이터 변동폭을 얻는다. 상기 목표데이터의 제1 데이터 변동폭과 상기 제2 데이터 변동폭에 근거하여 상기 목 표데이터에 대응하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데 이터의 양자화 파라미터를 업데이트하도록 한다. 제2 데이터 변동폭은 데이터 비트폭의 변동 요구사항을 가늠하 는 데 사용될 수 있으며, 제1 데이터 변동폭과 제2 데이터 변동폭에 근거하여 계산하여 얻은 목표반복간격은, 동시에 점 위치와 데이터 비트폭의 변동을 추적할 수 있으며, 목표반복간격은 목표데이터 자체의 데이터 양자화 요구사항에 더 잘 부합될 수도 있다. 도34는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도34에 도시된 바와 같이, 상기 신 경망의 양자화방법에서 단계(S63)는 다음과 같은 단계를 포함한다. 단계(S631), 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터사이의 오차를 계산한 다. 단계(S632), 상기 오차의 제곱을 상기 제2 데이터 변동폭으로 확정한다. 수학식（27）을 이용하여 계산을 통해 제2 데이터 변동폭 을 얻을 수 있다. 수학식（27） 여기에서, 는 제4 파라미터이고, 제4 파라미터는 하이퍼 파라미터일 수 있다. 이해할 수 있은 것은, 상이한 데이터 비트폭을 이용하여 상이한 양자화 파라미터를 얻을 수 있으며, 진일보로 상이한 양자화 데이터를 얻을 수 있고, 상이한 제2 데이터 변동폭을 생성할 수 있다. 제2 데이터 변동폭은 데이 터 비트폭의 변화추세를 가늠하는 데 사용될 수 있고, 제2 데이터 변동폭이 크면 클 수록, 보다 짧은 목표반복 간격으로 보다 빈번하게 데이터 비트폭을 업데이트해야함을 의미한다. 즉 목표반복간격은 보다 작을 필요가 있 다. 도35은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도35에 도시된 바와 같이, 상기 단 계(S72)는 다음과 같은 단계를 포함한다. 단계(S721), 상기 제1 데이터 변동폭과 상기 제2 데이터 변동폭 중의 최대 값에 근거하여 상기 목표데이터에 대 응하는 목표반복간격을 확정한다. 수학식（28）에 따라 계산하여 목표반복간격을 얻을 수 있다. 수학식（28） 여기에서, 는 제2 파라미터이고, 는 제3 파라미터이다. 제2 파라미터와 제3 파라미터는 하이퍼 파라미터일 수 있다. 이해할 수 있은 것은, 제1 데이터 변동폭과 제2 데이터 변동폭을 이용하여 얻은 목표반복간격은, 데이터 비트폭 과 점 위치의 변화추세를 동시에 가늠할 수 있다. 둘 중 하나의 변화추세가 상대적으로 크면, 목표반복간격에 대응하는 변화를 발생시킬 수 있다. 목표반복간격은 데이터 비트폭과 점 위치의 변화를 동시에 추적하고 대응하 는 조정을 할 수 있다. 따라서 목표반복간격에 근거하여 업데이트한 양자화 파라미터를 목표데이터의 변동추세 에 보다 적합하게 할 수 있고, 최종적으로 양자화 파라미터에 근거하여 얻은 양자화 데이터를 양자화 요구사항 에 보다 적합하게 할 수 있다. 도36는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도36에 도시된 바와 같이, 상기 신 경망의 양자화방법에서 단계(S60)는 다음과 같은 단계를 포함한다. 단계(S64), 현재 반복이 업데이트 주기 이외에 위치할 때, 현재 반복 및 이력 반복 중 목표데이터의 데이터 변 동폭을 획득하며, 상기 업데이트 주기에는 적어도 1회 반복이 포함된다. 신경망 연산의 훈련과정 및/또는 미조정과정에서, 훈련 시작 또는 미조정 시작의 복수의 반복에서, 목표데이터 의 변화 폭이 비교적 크다. 훈련 시작 또는 미조정 시작의 복수의 반복에서 목표반복간격을 계산하면, 계산하여 얻은 목표반복간격은 사용의 의미를 잃을 가능성이 있다. 미리 설정한 업데이트 주기에 따라, 업데이트 주기 내의 각 반복에서 목표반복간격을 계산하지 않고, 목표반복간격도 적용하지 않아 복수의 반복에서 동일한 데이터 비트폭 또는 점 위치를 사용하게 할 수 있다. 반복이 업데이트 주기 이외까지 수행되는 경우, 즉 현재 반복이 업데이트 주기 이외에 위치할 때, 현재 반복 및 이력 반복 중 목표데이터의 데이터 변동폭을 획득하고, 상기 목표데이터의 데이터 변동폭에 근거하여, 상기 목 표데이터에 대응하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데 이터의 양자화 파라미터를 업데이트하도록 한다. 예를 들어, 미리 설정한 업데이트 주기가 100세대이면, 제1세 대부터 시작하여 제100세대까지의 반복에서, 목표반복간격을 계산하지 않는다. 101세대까지 반복하면, 즉 현재 반복이 101세대일 때, 현재 반복은 업데이트 주기 이외에 위치한다. 이 때, 제101세대 및 제1세대 내지 제100세 대의 반복에서 목표데이터의 데이터 변동폭에 근거하여, 제101세대의 목표데이터에 대응하는 목표반복간격을 확 정하고, 제101세대 또는 제101세대와 미리 설정한 세대수를 사이한 반복에서, 계산하여 얻은 목표반복간격을 사 용할 수 있다. 미리 설정한 세대 수부터 시작하여 업데이트 주기를 카운트할 수 있다. 예를 들어, 제1 세대부터 시작하여 업데 이트 주기 중 복수의 반복을 카운트할 수 있고, 제N세대부터 시작하여 업데이트 주기 중의 복수의 반복을 카운 트할 수 있으며, 본 발명은 이에 대해 한정하지 않는다. 본 실시예에서, 반복이 업데이트 주기 이외까지 수행되는 경우 목표반복간격을 계산하여 사용한다. 신경망 연산 의 훈련과정 또는 미조정과정의 초기에서, 목표데이터의 변동폭이 비교적 큰 것에 의해 목표반복간격에 사용해 도 의미가 크지 않다는 문제를 회피할 수 있고, 목표반복간격을 사용하는 경우에 진일보로 신경망의 가동효율을 향상시킬 수 있다. 도37는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도37에 도시된 바와 같이, 상기 신 경망의 양자화방법은 다음과 같은 단계를 더 포함한다. 단계(S100), 현재 반복이 미리 설정된 주기 내에 위치할 때, 현재 반복의 상기 미리 설정된 주기의 다음 주기에 서 상기 현재 반복에 대응하는 반복 및 현재 반복에 대응하는 반복간격에 근거하여 주기간격을 확정한다. 단계(S110), 상기 목표데이터의 현재 반복에 대응하는 데이터 비트폭에 근거하여 상기 주기간격 내의 반복에서 상기 목표데이터의 데이터 비트폭을 확정한다. 또는 상기 목표데이터의 현재 반복에 대응하는 점 위치에 근거하여 상기 주기간격 내의 반복에서 상기 목표데이터의 점 위치를 확정한다. 신경망 연산의 훈련과정 또는 미조정과정에서, 복수의 주기를 포함할 수 있다. 각 주기에는 복수의 반복이 포함 될 수 있다. 신경망 연산에 사용되는 데이터가 한 번의 완전한 연산을 1주기로 한다. 훈련과정에서, 반복의 진 행에 따라, 신경망의 가중치 변화는 안정화되고, 훈련이 안정된 후, 뉴런, 가중치, 바이어스 및 그래디언트 등 양자화 대상 데이터들도 모두 안정화되며. 목표데이터가 안정화된 후, 목표데이터의 데이터 비트폭과 양자화 파 라미터도 안정화되고. 마찬가지로, 미조정과정에서, 미조정이 안정된 후, 목표데이터의 데이터 비트폭과 양자화 파라미터도 안정화된다. 따라서, 훈련이 안정된 또는 미조정이 안정된 주기에 근거하여 미리 설정된 주기를 확정할 수 있다. 훈련이 안 정된 또는 미조정이 안정된 주기가 있는 주기 뒤의 주기를 미리 설정된 주기로 확정할 수 있다. 예를 들어, 훈 련이 안정된 주기가 M 번째 주기인 경우, M 번째 주기 뒤의 주기를 미리 설정된 주기로 할 수 있다. 미리 설정 된 주기 내에서, 1주기 간격으로 하나의 목표반복간격을 계산하며, 계산하여 얻은 목표반복간격에 근거하여 데 이터 비트폭 또는 양자화 파라미터를 1회 조정할 수 있으므로, 데이터 비트폭 또는 양자화 파라미터의 업데이트 회수를 감소하고, 신경망의 가동효율을 향상시킨다. 예를 들어, 미리 설정된 주기가 M 번째 주기 이후의 주기이다. M+1 번째 주기에서, M 번째 주기 중의 P 번째 반 복계산하여 얻은 목표반복간격은 M+1 번째 주기 중의 Q 번째 반복까지이다. M+1 번째 주기 중 Qm+1 번째 반복계 산에 의해 이에 대응하는 목표반복간격Im+1을 얻는다. M+2 번째 주기 중, M+1 번째 주기 중의 Qm+1 번째 반복에 대응하는 반복이 Q m+2 번째 반복이다. M+1 번째 주기 중의 Qm+1 번째 반복부터 시작하여 M+2 번째 주기 내 Q m+2+ Im+1 번째 반복까지는 주기간격이다. 주기간격 내의 각 반복은, 모두 M+1 번째 주기 중의 Qm+1 번째 반복에서 확정 한 데이터 비트폭 또는 점 위치 등 양자화 파라미터를 채용한다. 본 실시예에서, 주기간격을 설정하고, 신경망 연산의 훈련 또는 미조정이 안정에 도달한 후, 주기간격에 근거하 여 주기마다 데이터 비트폭 또는 점 위치 등 양자화 파라미터를 1회 업데이트할 수 있다. 주기간격은 훈련이 안 정된 후 또는 미조정이 안정된 후, 데이터 비트폭 또는 점 위치의 업데이트 회수를 감소하여, 양자화 정밀도를 보장하는 동시에, 신경망의 가동효율을 향상시킬 수 있다. 설명할 필요가 있는 것은, 상술한 각 방법 실시예에 대하여, 설명의 편의를 위해, 이들을 동작의 일련 조합으로"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 27, "content": "서 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 본 발명은 설명된 동작의 순서에 의해 한정되지 않는다는 것을 인식해야 한다. 본 발명에 따르면, 특정 단계는 다른 순서를 채용하거나 동시에"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 28, "content": "수행할 수 있기 때문이다. 따라서, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 명세서에서 설명 된 실시예는 모두 선택할 수 있는 실시예에 속하며, 관련되는 동작과 모듈은 반드시 본 발명에 필수적인 것이 아니라는 것도 인식해야 한다 . 진일보로 설명할 필요가 있는 것은, 도13 내지 도18의 흐름도 중의 각 단계는 화살표의 지시에 따라 순서대로 표시하고 있지만, 이들 단계는 반드시 화살표로 지시한 순서대로 순차적으로 실행되는 것이 아니다. 이 명세서 에서 명시적으로 기재되지 않는 한, 이들 단계의 실행에는 엄밀한 순서제한이 없고, 이들 단계는 다른 순서로 실행될 수 있다. 그리고, 도13 내지 도18중의 적어도 일부 단계는 복수의 서브 단계 또는복수의 공정을 포함하 며, 이들 서브 단계 또는공정은 반드시 동일한 시점으로 실행완료하는 것이 아니라, 다른 시점으로 실행되어도 좋다, 또한 이들 서브 단계 또는 공정의 실행순서도 반드시 순서대로 진행하는 것이 아니라, 다른 단계 또는 다 른 단계의 서브 단계 또는 공정의 적어도 일부와 번갈아 또는 교대로 실행할 수 있다. 도38은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도38에 도시된 바와 같이, 본 발명은 신경망 양자화장치를 제공하는 바, 상기 장치는 상기 신경망에서 임의의 한 층의 양자화 대상 층을 양자화하는 데 적용되며, 상기 장치는, 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터와 대응하는 양자화 파라미터를 확정하는 데 사용되고, 상기 양자화 대상 데이터는 뉴런, 가중치, 바이어스, 그래디언트 중 적어도 한 가지를 포함하는 양자화 파라미 터 확정모듈; 및 대응하는 양자화 파라미터에 근거하여 양자화 대상 데이터를 양자화하여 양자화 데이터를 얻으며, 상기 신경망 이 상기 양자화 데이터에 근거하여 연산을 수행하도록 하기 위한 양자화 모듈을 포함한다. 가능한 실현방식에서, 상기 양자화 파라미터는 점 위치, 스케일 팩터 및 오프셋 중의 적어도 한 가지를 포함하 며, 여기에서, 상기 점 위치는 양자화 후 소수점의 위치이고, 상기 스케일 팩터는 양자화 된 데이터의 최대 값과 양자화 대상 데이터의 최대 절대치 사이의 비율이며, 상기 오프셋은 양자화 대상 데이터의 중간 값이다. 도39은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도39에 도시된 바와 같이, 상기 양자 화 파라미터 확정모듈은, 양자화 대상 데이터와 양자화 파라미터의 대응관계를 검색하여 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터를 확정하기 위한 제1 양자화 파라미터 확정 서브 모듈을 포함한다. 가능한 실현방식에서, 상기 양자화 파라미터 확정모듈은, 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻기 위한 제2 양자화 파라미터 확정 서브 모듈을 포함한다. 가능한 실현방식에서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터 중의 절대치 최대 값과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여 상기 목표데이터의 점 위치를 얻기 위한 제1 점 위치 계산유닛을 포함 하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 가능한 실현방식에서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트 폭에 근거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻으며, 상기 목표데이터는 임의의 한 가지 양자 화 대상 데이터이고; 목표데이터 중의 절대치 최대 값과 상기 목표데이터 양자화 된 데이터의 최대 값에 근거하여 상기 목표데이터의 스케일 팩터를 얻기 위한 제1 스케일 팩터 계산유닛을 포함한다. 가능한 실현방식에서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함된 경우, 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값 과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여, 상기 목표데이터의 점 위치를 얻기 위한 제2 점 위 치 계산유닛을 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 가능한 실현방식에서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함된 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트폭에 근 거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻으며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이고; 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값과 상기 목표데이터 양자화 된 데이 터의 최대 값에 근거하여 상기 목표데이터의 스케일 팩터를 얻기 위한 제2 스케일 팩터 계산유닛을 포함한 다. 가능한 실현방식에서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 목표데이터 중의 최대 값과 최소 값에 근거하여 상기 목표데이터의 오프셋을 얻기 위한 오프셋 계산유닛을 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 도40은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도40에 도시된 바와 같이, 가능한 실 현방식에서, 상기 장치는: 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 상기 목표데이터의 양자화 오차를 확정하 는 데 사용되고, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터인 양자화 오차 확정모듈; 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조정하며, 상기 목 표데이터에 대응하는 조정 비트폭을 얻기 위한 조정 비트폭 확정모듈; 및 상기 목표데이터에 대응하는 데이터 비트폭을 상기 조정 비트폭으로 업데이트하고, 상기 목표데이터와 상기 조 정 비트폭에 근거하여 계산을 통해 대응하는 조정 양자화 파라미터를 얻으며, 상기 신경망이 상기 조정 양자화 파라미터에 근거하여 양자화하도록 하기 위한 조정 양자화 파라미터 확정모듈을 포함한다. 가능한 실현방식에서, 상기 조정 비트폭 확정모듈은, 상기 양자화 오차가 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 증가하여 상 기 목표데이터에 대응하는 조정 비트폭을 얻기 위한 제1 조정 비트폭 확정 서브 모듈을 포함한다. 가능한 실현방식에서, 상기 조정 비트폭 확정모듈은, 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산하기 위한 제 1 조정 양자화 오차 확정 서브 모듈; 및 상기 조정 후의 양자화 오차와 상기 제1 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터에 따라 계산 하여 얻은 조정 후의 양자화 오차가 상기 제1 오차 한계 값 이하로 될 때까지 상기 조정 비트폭을 계속 증가하 기 위한 제1 조정 비트폭 순환 확정 서브 모듈을 더 포함한다. 가능한 실현방식에서, 상기 조정 비트폭 확정모듈은, 상기 양자화 오차가 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 감소하기 위한 제2 조정 비트폭 확정 서브 모듈을 포함하며, 상기 제2 오차 한계 값은 상기 제1 오차 한계 값보다 작 다. 가능한 실현방식에서, 상기 조정 비트폭 확정모듈은, 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산하기 위한 제 2 조정 양자화 오차 확정 서브 모듈; 및 상기 조정 후의 양자화 오차와 상기 제2 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터에 따라 계산 을 통해 얻은 조정 후의 양자화 오차가 상기 제2 오차 한계 값 이상이 될 때까지 상기 조정 비트폭을 계속 감소 하기 위한 제2 조정 비트폭 순환 확정 서브 모듈을 더 포함한다. 도41은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도41에 도시된 바와 같이, 가능한 실 현방식에서, 상기 신경망 연산의 미조정단계 및/또는 훈련단계에서, 상기 장치는, 현재 반복 및 상기 현재 반복 전의 반복인 이력 반복 중 목표데이터의 데이터 변동폭을 획득하기 위한 데이터 변동폭 확정모듈; 및 상기 목표데이터의 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하기 위한 목표 반복간격 확정모듈을 더 포함하며, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. 가능한 실현방식에서, 상기 장치는, 상기 목표데이터의 상기 현재 반복에서의 데이터 비트폭에 근거하여 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 데이터 비트폭을 확정함으로써, 상기 신경망이 상기 목표데이터의 상기 목표반복간격 내의 반 복에 대응하는 데이터 비트폭에 근거하여 양자화 파라미터를 확정하도록 하기 위한 제1 목표반복간격 응용모듈 을 더 포함한다. 가능한 실현방식에서, 상기 장치는, 상기 목표데이터의 상기 현재 반복에 대응하는 점 위치에 근거하여 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 점 위치를 확정하기 위한 제2 목표반복간격 응용모듈을 더 포함한다. 가능한 실현방식에서, 상기 데이터 변동폭 확정모듈은, 목표데이터의 현재 반복의 점 위치, 및 이력 반복간격에 근거하여 확정한 상기 현재 반복에 대응하는 이력 반복 의 점 위치에 근거하여, 목표데이터의 각 반복간격에 대응하는 점 위치의 이동평균 값을 계산하기 위한 이동평 균 값 계산 서븐 모듈; 및 상기 목표데이터의 현재 반복의 점 위치의 제1 이동평균 값 및 전회 반복간격에서 대응하는 반복의 점 위치의 제2 이동평균 값에 근거하여 제1 데이터 변동폭을 얻기 위한 제1 데이터 변동폭 확정 서브 모듈을 포함하며; 상기 목표반복간격 확정모듈은, 상기 제1 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정하여 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하기 위한 제1 목표반복간격 확 정 서브 모듈를 포함한다. 가능한 실현방식에서, 상기 제1 데이터 변동폭 확정 서브 모듈은, 상기 제1 이동평균 값과 상기 제2 이동평균 값의 차이 값을 계산하기 위한 제1 데이터 변동폭 확정유닛을 포함하며; 상기 차이 값의 절대치를 제1 데이터 변동폭으로 확정한다. 가능한 실현방식에서, 상기 데이터 변동폭 확정모듈은, 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 제2 데이터 변동폭을 얻기 위한 제2 데이터 변동폭 확정 서브 모듈을 더 포함하며; 상기 목표반복간격 확정모듈은, 상기 목표데이터의 제1 데이터 변동폭과 상기 제2 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표 반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하기 위한 제2 목표반복간격 확정 서브 모듈을 포함한다. 가능한 실현방식에서, 상기 제2 데이터 변동폭 확정모듈은, 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터사이의 오차를 계산하기 위한 제2 데이터 변동폭 확정유닛을 포함하며; 상기 오차의 제곱을 상기 제2 데이터 변동폭으로 확정한다. 가능한 실현방식에서, 상기 제2 목표반복간격 확정 서브 모듈은 상기 제1 데이터 변동폭과 상기 제2 데이터 변동폭 중의 최대 값에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정하는 데 사용된다. 가능한 실현방식에서, 상기 데이터 변동폭 확정모듈은, 현재 반복이 업데이트 주기 이외에 위치할 때, 현재 반복 및 이력 반복 중 목표데이터의 데이터 변동폭을 획득 하기 위한 제3 데이터 변동폭 확정 서브 모듈을 포함하며, 상기 업데이트 주기에는 적어도 1회 반복이 포 함된다. 도42은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도42에 도시된 바와 같이, 가능한 실 현방식에서, 상기 장치는, 현재 반복이 미리 설정된 주기 내에 위치할 때, 현재 반복의 상기 미리 설정된 주기의 다음 주기에서 상기 현재 반복에 대응하는 반복 및 현재 반복에 대응하는 반복간격에 근거하여 주기간격을 확정하기 위한 주기간격 확정 모듈; 상기 목표데이터의 현재 반복에 대응하는 데이터 비트폭에 근거하여 상기 주기간격 내의 반복에서 상기 목표데 이터의 데이터 비트폭을 확정하기 위한 제1 주기간격 응용모듈; 또는 상기 목표데이터의 현재 반복에 대응하는 점 위치에 근거하여 상기 주기간격 내의 반복에서 상기 목표데이터의 점 위치를 확정하기 위한 제2 주기간격 응용모듈을 더 포함한다. 가능한 실현방식에서, 상기 장치는, 상기 양자화 대상 층 다음의 한 층 또는 여러 층에서 상기 양자화 대상 층의 양자화 파라미터를 채용하기 위한 양자화 파라미터 계속 사용모듈을 더 포함한다. 또한, 상술한 장치 실시예는 단지 예시일 뿐이며, 본 발명의 장치는 다른 방식으로 실현할 수 있다는 것을 이해 해야 한다. 예를 들어, 상술한 실시예에서 상기 유닛/모듈의 구분은 단지 논리적 기능 구분일 뿐이며, 실제로 실현될 경우에는 다른 구분방식이 있을 수 있다. 예를 들어, 복수의 유닛, 모듈 또는 컴포넌트가 결합될 수 있 거나 다른 시스템에 통합되거나 일부 특징을 무시 또는 실행하지 않을 수 있다. 상기 분리부품으로서 설명한 유닛 또는 모듈은 물리적으로 분리될 수도 있고, 물리적으로 분리되지 않을 수도 있다 . 유닛 또는 모듈로서 설명한 부품은 물리적 유닛일 수도 있고, 물리적 유닛이 아닐 수도 있다. 즉 하나의 장치에 위치할 수도 있고, 복수의 장치에 분산될 수도 있다. 본 발명에서 실시예의 방안은 실제의 필요에 따라 유닛의 일부 또는 전부를 선택하여 실현할 수 있다. 또한, 특히 명기되지 않는 한, 본 발명 각 실시예의 각 기능 유닛/모듈은 하나의 유닛/모듈에 통합될 수 있고, 각 유닛/모듈이 물리적으로 단독으로 존재할 수도 있으며, 2개 또는 2개 이상의 유닛/모듈이 하나로 통합될 수 도 있다. 상술한 통합된 유닛/모듈은 하드웨어의 형식을 채용하여 실현할 수도 있고, 소프트웨어 프로그램 모듈 의 형식을 채용하여 실현할 수도 있다. 상기 통합된 유닛/모듈은 하드웨어의 형식으로 실현하는 경우, 당해 하드웨어는 디지털 회로, 아날로그 회로 등 일 수 있다. 하드웨어 구조의 물리적 실현은 트랜지스터, 멤 리스터 등을 포함하지만, 이들에 한정되지 않는다. 특히 명기되지 않는 한, 상기 인공지능 프로세서는 임의의 적절한 하드웨어 프로세서, 예를 들어, CPU, GPU, FPGA, DSP 및 ASIC 등일 수 있다. 특히 명기되지 않는 한, 상기 저장유닛은 임의의 적절한 자기 저장 매체 또는 광 자기 저장 매체, 예를 들어, 저항변화 메모리RRAM（Resistive Random Access Memory）, 다이나믹 랜덤 액세 스 메모리 DRAM（Dynamic Random Access Memory）, 스태틱 랜덤 액세스 메모리 SRAM（Static Random-Access Memory）, 임베디드 다이나믹 랜덤 액세스 메모리 EDRAM（Enhanced Dynamic Random Access Memory）, 고대역 폭 메모리 HBM（High-Bandwidth Memory）, 하이브리드 메모리 큐브 HMC （Hybrid Memory Cube）등일 수 있다. 상기 통합된 유닛/모듈은 소프트웨어 프로그램 모듈의 형식으로 실현되고 독립적인 제품으로 판매되거나 사용될 때 하나의 컴퓨터 판독 가능한 메모리에 저장될 수 있다. 이러한 이해에 따라, 본 발명의 기술방안은 본질적으 로 또는 종래기술에 공헌하는 부분 또는 당해 기술방안의 전부 또는 일부는 소프트웨어 제품의 형식으로 구현할 수 있으며, 당해 컴퓨터 소프트웨어 제품은 하나의 메모리에 저장되며, 컴퓨터기기（개인용 컴퓨터, 서버 또는 네트워크 기기 등일 수 있다）가 본 발명 각 실시예에서 설명한 방법의 전부 또는 일부단계를 실행 하기 위한 복수의 명령을 포함한다. 한편 전술한 메모리는: U 디스크, 읽기 전용 메모리（ROM, Read-Only Memory）, 랜덤 액세스 메모리（RAM, Random Access Memory）, 모바일 하드 디스크, 자기 디스크 또는 광 디스크 등 각종 프로 그램 코드를 저장할 수있는 매체를 포함한다. 가능한 실현방식에서, 본 발명은 인공지능 칩도 개시하는 바, 상술한 데이터 동기적 장치를 포함하고 있다. 가능한 실현방식에서, 본 발명은 메모리 디바이스, 인터페이스 장치와 제어 디바이스 및 상술한 인공지능 칩을 포함하는 보드 카드도 개시하는 바; 여기에서, 상기 인공지능 칩은 상기 메모리 디바이스, 상기 제어 디바이스 및 상기 인터페이스 장치와 각각 연결되고; 상기 메모리 디바이스는 데이터를 저장하는 데 사용되고; 상기 인터 페이스 장치는 상기 인공지능 칩과 외부기기 사이의 데이터 전송을 실현하는 데 사용되며; 상기 제어 디바이스 는 상기 인공지능 칩의 상태를 감시하는 데 사용된다. 도43은 본 발명 실시예에 따른 보드 카드를 나타내는 구조 블록도이다. 도43을 참조하면, 상술한 보드 카드는 상술한 칩을 포함하는 외에도 다른 부대부품을 포함할 수 있다. 당해 부대부품은 메모리 디바이스, 인터페이스 장치 및 제어 디바이스를 포함할 수 있지만, 이들에 한정되지 않는다. 상기 메모리 디바이스는 데이터를 저장하기 위해 베스를 통해 상기 인공지능 칩과 연결된다. 상기 메모리 디바이스는 복수 그룹의 저장유닛을 포함할 수 있다. 각 그룹의 상기 저장유닛은 버스를 통해 상기 인공지 능 칩과 연결된다. 또한, 각 그룹의 상기 저장유닛이 DDR SDRAM（영문: Double Data Rate SDRAM, 2배 속도 동 기적 다이나믹 랜덤메모리）일 수 있다는 것을 이해할 수 있다. DDR은 클록 주파수를 높이지 않고도 SDRAM의 속도를 2배로 할 수 있다. DDR은 클록 펄스의 상승 및 하강 에지에 서 데이터를 읽어 내는 것을 허용한다. DDR의 속도는 표준 SDRAM의 2배이다. 일 실시예에서, 상기 저장장치는 4 그룹의 상기 저장유닛을 포함할 수 있다. 각 그룹의 상기 저장유닛은 복수의 DDR4 입자（칩）를 포함할 수 있다. 일 실시예에서, 상기 인공지능 칩 내부는 4개의 72비트 DDR4 컨트롤러를 포함할 수 있으며, 상술한 72비 트 DDR4 컨트롤러 중 64bit는 데이터 전송에 사용되고, 8bit는 ECC검증에 사용된다. 또한, 각 그룹의 상기 저장 유닛에서 DDR4-3200 입자를 채용하는 경우, 데이터 전송의 이론 대역폭은 25600MB/s에 도달할 수 있다고 이해할 수 있다 . 일 실시예에서, 각 그룹의 상기 저장유닛은 복수의 병렬로 배치한 2배 속도 동기적 다이나믹 랜덤 메모리를 포 함한다. DDR은 한 클록 주기 내에 데이터를 2회 전송할 수 있다. 상기 칩에 DDR을 제어하는 컨트롤러를 배치하 여 각 상기 저장유닛의 데이터 전송과 데이터 저장의 제어한다. 상기 인터페이스 장치는 상기 인공지능 칩과 전기적으로 연결된다. 상기 인터페이스 장치는 상기 인공지능 칩과 외부기기（예를 들어 서버 또는 컴퓨터） 사이의 데이터 전송을 실현하는 데 사용된다. 예를 들어 일 실시예에 서, 상기 인터페이스 장치는 표준 PCIE 인터페이스일 수 있다. 예를 들어, 처리될 데이터는 서버에서 표준 PCIE 인터페이스를 통해 상기 칩에 전달되어 데이터 이전을 실현한다. 바람직하게, PCIE 3.0 X 16 인터페이스를 채용 하여 전송하는 경우, 이론 대역폭은 16000MB/s에 달할 수도 있다. 다른 하나의 실시예에서, 상기 인터페이스 장 치는 다른 인터페이스일 수도 있고, 본 발명은 상술한 다른 인터페이스의 구체적인 표현형식을 한정하지 않으며, 상기 인터페이스 유닛은 이전기능을 실현하면 된다. 또한, 상기 인공지능 칩의 계산결과는 여전히 상기 인터페이스 장치에 의해 외부기기（예를 들어 서버）로 다시 전송된다. 상기 제어 디바이스는 상기 인공지능 칩과 전기적으로 연결된다. 상기 제어 디바이스는 상기 인공지능 칩의 상 태를 감시하는 데 사용된다. 구체적으로, 상기 인공지능 칩은 SPI 인터페이스를 통해 상기 제어 디바이스와 전 기적으로 연결될 수 있다. 상기 제어 디바이스는 단일 칩 마이크로 컴퓨터（Micro Controller Unit, MCU）를 포 함할 수 있다. 상기와 같이 인공지능 칩은 복수의 처리 칩, 복수의 처리 코아 또는 복수의 처리회로를 포함하여 복수의 부하를 구동할 수 있다. 따라서, 상기 인공지능 칩은 다부하와 경부하 등 상이한 동작상태에 있을 수 있 다. 상기 제어장치를 통해 상기 인공지능 칩 중 복수의 처리 칩, 복수의 처리 코아 또는 복수의 처리회로의 동 작상태의 조정 및 제어를 실현할 수 있다. 가능한 실현방식에서, 상술한 인공지능 칩을 포함한 전자기기를 개시한다. 전자기기포함데이터 처리장치, 로봇, 컴퓨터, 프린터, 스캐너, 태블릿, 스마트 단말, 휴대전화, 드라이브 레코더, 네비게이션 장치, 센서, 카메라, 서버, 클라우드 서버, 카메라, 비디오 카메라, 프로젝터, 손목 시계, 헤드폰, 모바일 스토리지, 웨어러블 디바 이스, 교통수단, 가전제품, 및/또는 의료기기를 포함한다. 상기 교통수단은 항공기, 선박 및/또는 차량을 포함하며; 가전제품은 텔레비전, 에어컨, 전자렌지, 냉장고, 전 기밥솥, 가습기, 세탁기, 전등, 가스 버너, 레인지 푸드를 포함하고; 상기 의료기기는 핵자기 공명 장치, B-초 음파진단 장치 및/또는 심전계를 포함한다. 전술한 내용은 다음 조항에 따라 더 잘 이해할 수 있다. B1, 신경망의 양자화방법에 있어서, 상기 신경망에서 임의의 한 층의 양자화 대상 층에 대하여, 상기 방법은, 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터와 대응하는 양자화 파라미터를 확정하며, 상기 양자화 대상 데이터는 뉴런, 가중치, 바이어스, 그래디언트 중 적어도 한 가지를 포함하는 것; 및 대응하는 양자화 파라미터에 근거하여 양자화 대상 데이터를 양자화하여 양자화 데이터를 얻으며, 상기 신경망 이 상기 양자화 데이터에 근거하여 연산을 수행하도록 하는 것을 포함한다. B2, 조항B1에 따른 방법에 있어서, 상기 양자화 파라미터는 점 위치, 스케일 팩터 및 오프셋 중의 적어도 한 가 지를 포함하며, 여기에서, 상기 점 위치는 양자화 후 소수점의 위치이고, 상기 스케일 팩터는 양자화 된 데이터의 최대 값과 양자화 대상 데이터의 최대 절대치 사이의 비율이며, 상기 오프셋은 양자화 대상 데이터의 중간 값이다. B3, 조항B1 또는 B2에 따른 방법에 있어서, 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터를 확정하는 것은, 양자화 대상 데이터와 양자화 파라미터의 대응관계를 검색하여 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터를 확정하는 것을 포함한다 . B4, 조항B1 또는 B2에 따른 방법에 있어서, 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터를 확정하는 것은, 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻는 것을 포함한다. B5, 조항B4에 따른 방법에 있어서, 상기 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻는 것은, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터 중의 절대치 최대 값과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여 상기 목표데이터의 점 위치를 얻는 것을 포함하며, 상기 목표데이터는 임의 의 한 가지 양자화 대상 데이터이다. B6, 조항B4에 따른 방법에 있어서, 상기 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻는 것은, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트 폭에 근거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻으며, 상기 목표데이터는 임의의 한 가지 양자 화 대상 데이터인 것; 목표데이터 중의 절대치 최대 값과 상기 목표데이터 양자화 된 데이터의 최대 값에 근거하여 상기 목표데이터의 스케일 팩터를 얻는 것을 포함한다. B7, 조항B4에 따른 방법에 있어서, 상기 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻는 것은, 상기 양자화 파라미터에 오프셋이 포함된 경우, 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값 과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여, 상기 목표데이터의 점 위치를 얻는 것을 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. B8, 조항B4에 따른 방법에 있어서, 상기 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻는 것은, 상기 양자화 파라미터에 오프셋이 포함된 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트폭에 근 거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻으며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터인 것; 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값과 상기 목표데이터 양자화 된 데이터의 최대 값 에 근거하여 상기 목표데이터의 스케일 팩터를 얻는 것을 포함한다. B9, 조항B4에 따른 방법에 있어서, 상기 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻는 것은, 목표데이터 중의 최대 값과 최소 값에 근거하여 상기 목표데이터의 오프셋을 얻는 것을 포함하며, 상기 목표데 이터는 임의의 한 가지 양자화 대상 데이터이다. B10, 조항B1 내지 B9 중 어느 한 항에 따른 방법에 있어서, 상기 방법은, 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 상기 목표데이터의 양자화 오차를 확정하 며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터인 것; 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조정하며, 상기 목 표데이터에 대응하는 조정 비트폭을 얻는 것; 상기 목표데이터에 대응하는 데이터 비트폭을 상기 조정 비트폭으로 업데이트하고, 상기 목표데이터와 상기 조 정 비트폭에 근거하여 계산을 통해 대응하는 조정 양자화 파라미터를 얻으며, 상기 신경망이 상기 조정 양자화 파라미터에 근거하여 양자화하도록 하는 것을 더 포함한다. B11, 조항B10에 따른 방법에 있어서, 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조정하며, 상기 목표데이터에 대응하는 조정 비트폭을 얻는 것은, 상기 양자화 오차가 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 증가하여 상 기 목표데이터에 대응하는 조정 비트폭을 얻는 것을 포함한다. B12, 조항B11에 따른 방법에 있어서, 상기 방법은, 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산하는 것; 및 상기 조정 후의 양자화 오차와 상기 제1 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터에 따라 계산 하여 얻은 조정 후의 양자화 오차가 상기 제1 오차 한계 값 이하로 될 때까지 상기 조정 비트폭을 계속 증가하 는 것을 포함한다. B13, 조항B10 또는 B11에 따른 방법에 있어서, 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조정하는 것은, 상기 양자화 오차가 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 감소하는 것을 포함하며, 상기 제2 오차 한계 값은 상기 제1 오차 한계 값보다 작다. B14, 조항B13에 따른 방법에 있어서, 상기 방법은, 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산하는 것; 및 상기 조정 후의 양자화 오차와 상기 제2 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터에 따라 계산 을 통해 얻은 조정 후의 양자화 오차가 상기 제2 오차 한계 값 이상이 될 때까지 상기 조정 비트폭을 계속 감소 하는 것을 더 포함한다. B15, 조항B1 내지 B14 중 어느 한 항에 따른 방법에 있어서, 상기 신경망 연산의 미조정단계 및/또는 훈련단계 에서, 상기 방법은, 현재 반복 및 상기 현재 반복 전의 반복인 이력 반복 중 목표데이터의 데이터 변동폭을 획득하는 것; 및 상기 목표데이터의 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하는 것을 더 포 함하며, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 목표데이터는 임의의 한 가지 양자화 대상 데 이터이다. B16, 조항B15에 따른 방법에 있어서, 상기 방법은, 상기 목표데이터의 상기 현재 반복에서의 데이터 비트폭에 근거하여 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 데이터 비트폭을 확정함으로써, 상기 신경망이 상기 목표데이터의 상기 목표반복간격 내의 반 복에 대응하는 데이터 비트폭에 근거하여 양자화 파라미터를 확정하도록 하는 것을 더 포함한다. B17, 조항B15에 따른 방법에 있어서, 상기 방법은, 상기 목표데이터의 상기 현재 반복에 대응하는 점 위치에 근거하여 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 점 위치를 확정하는 것을 더 포함한다. B18, 조항B15에 따른 방법에 있어서, 상기 현재 반복 및 이력 반복 중 목표데이터의 데이터 변동폭을 획득하는 것은, 목표데이터의 현재 반복의 점 위치, 및 이력 반복간격에 근거하여 확정한 상기 현재 반복에 대응하는 이력 반복 의 점 위치에 근거하여, 목표데이터의 각 반복간격에 대응하는 점 위치의 이동평균 값을 계산하는 것; 상기 목표데이터의 현재 반복의 점 위치의 제1 이동평균 값 및 전회 반복간격에서 대응하는 반복의 점 위치의 제2 이동평균 값에 근거하여 제1 데이터 변동폭을 얻는 것을 포함하며; 상기 목표데이터의 데이터 변동폭에 근거하여, 상기 목표데이터에 대응하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하는 것은, 상기 제1 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정하여 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하는 것을 포함한다. B19, 조항B18에 따른 방법에 있어서, 상기 목표데이터의 현재 반복의 점 위치의 제1 이동평균 값 및 전회 반복 간격에서 대응하는 반복의 점 위치의 제2 이동평균 값에 근거하여 제1 데이터 변동폭을 얻는 것은, 상기 제1 이동평균 값과 상기 제2 이동평균 값의 차이 값을 계산하는 것; 및 상기 차이 값의 절대치를 제1 데이터 변동폭으로 확정하는 것을 포함한다. B20, 조항B18에 따른 방법에 있어서, 상기 방법은, 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 제2 데이터 변동폭을 얻는 것을 더 포함하며; 상기 목표데이터의 데이터 변동폭에 근거하여, 상기 목표데이터에 대응하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하는 것은, 상기 목표데이터의 제1 데이터 변동폭과 상기 제2 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표 반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하는 것을 포함한다. B21, 조항B20에 따른 방법에 있어서, 상기 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자 화 데이터에 근거하여 제2 데이터 변동폭을 얻는 것은, 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터사이의 오차를 계산하는 걸; 및 상기 오차의 제곱을 상기 제2 데이터 변동폭으로 확정하는 것을 포함한다. B22, 조항B20에 따른 방법에 있어서, 상기 목표데이터의 제1 데이터 변동폭과 상기 제2 데이터 변동폭에 근거하 여 상기 목표데이터에 대응하는 목표반복간격을 확정하는 것은, 상기 제1 데이터 변동폭과 상기 제2 데이터 변동폭 중의 최대 값에 근거하여 상기 목표데이터에 대응하는 목표 반복간격을 확정하는 것을 포함한다. B23, 조항B15 내지 B22 중 어느 한 항에 따른 방법에 있어서, 상기 현재 반복 및 이력 반복 중 목표데이터의 데 이터 변동폭을 획득하는 것은, 현재 반복이 업데이트 주기 이외에 위치할 때, 현재 반복 및 이력 반복 중 목표데이터의 데이터 변동폭을 획득 하는 것을 포함하며, 상기 업데이트 주기에는 적어도 1회 반복이 포함된다. B24, 조항B15 내지 B23 중 어느 한 항에 따른 방법에 있어서, 상기 방법, 현재 반복이 미리 설정된 주기 내에 위치할 때, 현재 반복의 상기 미리 설정된 주기의 다음 주기에서 상기 현재 반복에 대응하는 반복 및 현재 반복에 대응하는 반복간격에 근거하여 주기간격을 확정하는 것; 상기 목표데이터의 현재 반복에 대응하는 데이터 비트폭에 근거하여 상기 주기간격 내의 반복에서 상기 목표데 이터의 데이터 비트폭을 확정하는 것; 또는 상기 목표데이터의 현재 반복에 대응하는 점 위치에 근거하여 상기 주기간격 내의 반복에서 상기 목표데이터의 점 위치를 확정하는 것을 더 포함한다. B25, 조항B1 내지 B24 중 어느 한 항에 따른 방법에 있어서, 상기 방법은, 상기 양자화 대상 층 다음의 한 층 또는 여러 층에서 상기 양자화 대상 층의 양자화 파라미터를 채용하는 것을 더 포함한다 . B26, 신경망 양자화장치에 있어서, 상기 장치는 상기 신경망에서 임의의 한 층의 양자화 대상 층을 양자화하는 데 적용되며, 상기 장치는, 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터와 대응하는 양자화 파라미터를 확정하는 데 사용되고, 상기 양자화 대상 데이터는 뉴런, 가중치, 바이어스, 그래디언트 중 적어도 한 가지를 포함하는 양자화 파라미 터 확정모듈; 및 대응하는 양자화 파라미터에 근거하여 양자화 대상 데이터를 양자화하여 양자화 데이터를 얻으며, 상기 신경망 이 상기 양자화 데이터에 근거하여 연산을 수행하도록 하기 위한 양자화 모듈을 포함한다. B27, 조항B26에 따른 장치에 있어서, 상기 양자화 파라미터는 점 위치, 스케일 팩터 및 오프셋 중의 적어도 한 가지를 포함하며, 여기에서, 상기 점 위치는 양자화 후 소수점의 위치이고, 상기 스케일 팩터는 양자화 된 데이터의 최대 값과 양자화 대상 데이터의 최대 절대치 사이의 비율이며, 상기 오프셋은 양자화 대상 데이터의 중간 값이다. B28, 조항B25 또는 B27에 따른 장치에 있어서, 상기 양자화 파라미터 확정모듈은, 양자화 대상 데이터와 양자화 파라미터의 대응관계를 검색하여 상기 양자화 대상 층 중 각 종류의 양자화 대상 데이터에 대응하는 양자화 파라미터를 확정하기 위한 제1 양자화 파라미터 확정 서브 모듈을 포함한다. B29, 조항B26또는 B27에 따른 장치에 있어서, 상기 양자화 파라미터 확정모듈은, 각 종류의 양자화 대상 데이터와 대응하는 데이터 비트폭에 근거하여 계산을 통해 대응하는 양자화 파라미터를 얻기 위한 제2 양자화 파라미터 확정 서브 모듈을 포함한다 . B30, 조항B29에 따른 장치에 있어서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터 중의 절대치 최대 값과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여 상기 목표데이터의 점 위치를 얻기 위한 제1 점 위치 계산유닛을 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. B31, 조항B29에 따른 장치에 있어서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함되지 않은 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트 폭에 근거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻기 위한 제1 스케일 팩터 계산유닛를 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이고; 목표데이터 중의 절대치 최대 값과 상기 목표데이터 양자화 된 데이터의 최대 값에 근거하여 상기 목표데이터의 스케일 팩터를 얻는 것을 포함한다. B32, 조항B29에 따른 장치에 있어서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함된 경우, 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값 과 상기 목표데이터에 대응하는 데이터 비트폭에 근거하여, 상기 목표데이터의 점 위치를 얻기 위한 제2 점 위 치 계산유닛을 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. B33, 조항B29에 따른 장치에 있어서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 상기 양자화 파라미터에 오프셋이 포함된 경우, 목표데이터와 상기 목표데이터에 대응하는 데이터 비트폭에 근 거하여 상기 목표데이터 양자화 된 데이터의 최대 값을 얻기 위한 제2 스케일 팩터 계산유닛을 포함하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이고; 상기 목표데이터 중의 최대 값, 상기 목표데이터 중의 최소 값과 상기 목표데이터 양자화 된 데이터의 최대 값에 근거하여 상기 목표데이터의 스케일 팩터를 얻는 것 을 포함한다. B34, 조항B29에 따른 장치에 있어서, 상기 제2 양자화 파라미터 확정 서브 모듈은, 목표데이터 중의 최대 값과 최소 값에 근거하여 상기 목표데이터의 오프셋을 얻기 위한 오프셋 계산유닛을 포함 하며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터이다. B35, 조항B26 내지 B34 중 어느 한 항에 따른 장치에 있어서, 상기 장치는, 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 상기 목표데이터의 양자화 오차를 확정하 는 데 사용되며, 상기 목표데이터는 임의의 한 가지 양자화 대상 데이터인 양자화 오차 확정모듈; 상기 양자화 오차와 오차 한계 값에 근거하여 상기 목표데이터에 대응하는 데이터 비트폭을 조정하며, 상기 목 표데이터에 대응하는 조정 비트폭을 얻기 위한 조정 비트폭 확정모듈; 및 상기 목표데이터에 대응하는 데이터 비트폭을 상기 조정 비트폭으로 업데이트하고, 상기 목표데이터와 상기 조 정 비트폭에 근거하여 계산을 통해 대응하는 조정 양자화 파라미터를 얻으며, 상기 신경망이 상기 조정 양자화 파라미터에 근거하여 양자화하도록 하기 위한 조정 양자화 파라미터 확정모듈을 포함한다. B36, 조항B35에 따른 장치에 있어서, 상기 조정 비트폭 확정모듈은, 상기 양자화 오차가 제1 오차 한계 값보다 클 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 증가하여 상 기 목표데이터에 대응하는 조정 비트폭을 얻기 위한 제1 조정 비트폭 확정 서브 모듈을 포함한다. B37, 조항B36에 따른 장치에 있어서, 상기 조정 비트폭 확정모듈은, 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산하기 위한 제 1 조정 양자화 오차 확정 서브 모듈; 및 상기 조정 후의 양자화 오차와 상기 제1 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터에 따라 계산 하여 얻은 조정 후의 양자화 오차가 상기 제1 오차 한계 값 이하로 될 때까지 상기 조정 비트폭을 계속 증가하 기 위한 제1 조정 비트폭 순환 확정 서브 모듈을 포함한다. B38, 조항B35 또는 B36에 따른 장치에 있어서, 상기 조정 비트폭 확정모듈은, 상기 양자화 오차가 제2 오차 한계 값보다 작은 경우, 상기 목표데이터에 대응하는 데이터 비트폭을 감소하기 위한 제2 조정 비트폭 확정 서브 모듈을 포함하며, 상기 제2 오차 한계 값은 상기 제1 오차 한계 값보다 작다. B39, 조항B38에 따른 장치에 있어서, 상기 조정 비트폭 확정모듈은, 상기 조정 비트폭과 상기 목표데이터에 근거하여 상기 목표데이터의 조정 후의 양자화 오차를 계산하기 위한 제 2 조정 양자화 오차 확정 서브 모듈; 및 상기 조정 후의 양자화 오차와 상기 제2 오차 한계 값에 근거하여, 조정 비트폭과 상기 목표데이터에 따라 계산 을 통해 얻은 조정 후의 양자화 오차가 상기 제2 오차 한계 값 이상이 될 때까지 상기 조정 비트폭을 계속 감소 하기 위한 제2 조정 비트폭 순환 확정 서브 모듈을 더 포함한다. B40, 조항B26 내지 B39 중 어느 한 항에 따른 장치에 있어서, 상기 신경망 연산의 미조정단계 및/또는 훈련단계 에서, 상기 장치는, 현재 반복 및 상기 현재 반복 전의 반복인 이력 반복 중 목표데이터의 데이터 변동폭을 획득하기 위한 데이터 변동폭 확정모듈; 및 상기 목표데이터의 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하기 위한 목표 반복간격 확정모듈을 더 포함하며, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 목표데이터는 임의 의 한 가지 양자화 대상 데이터이다. B41, 조항B40에 따른 장치에 있어서, 상기 장치는, 상기 목표데이터의 상기 현재 반복에서의 데이터 비트폭에 근거하여 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 데이터 비트폭을 확정함으로써, 상기 신경망이 상기 목표데이터의 상기 목표반복간격 내의 반 복에 대응하는 데이터 비트폭에 근거하여 양자화 파라미터를 확정하도록 하기 위한 제1 목표반복간격 응용모듈 을 더 포함한다. B42, 조항B40에 따른 장치에 있어서, 상기 장치는, 상기 목표데이터의 상기 현재 반복에 대응하는 점 위치에 근거하여 상기 목표데이터의 상기 목표반복간격 내의 반복에 대응하는 점 위치를 확정하기 위한 제2 목표반복간격 응용모듈을 더 포함한다. B43, 조항B40에 따른 장치에 있어서, 상기 데이터 변동폭 확정모듈은, 목표데이터의 현재 반복의 점 위치, 및 이력 반복간격에 근거하여 확정한 상기 현재 반복에 대응하는 이력 반복 의 점 위치에 근거하여, 목표데이터의 각 반복간격에 대응하는 점 위치의 이동평균 값을 계산하기 위한 이동평 균 값 계산 서븐 모듈; 및 상기 목표데이터의 현재 반복의 점 위치의 제1 이동평균 값 및 전회 반복간격에서 대응하는 반복의 점 위치의 제2 이동평균 값에 근거하여 제1 데이터 변동폭을 얻기 위한 제1 데이터 변동폭 확정 서브 모듈을 포함하며; 상기 목표반복간격 확정모듈은, 상기 제1 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정하여 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하기 위한제1 목표반복간격 확 정 서브 모듈을 포함한다. B44, 조항B43에 따른 장치에 있어서, 상기 제1 데이터 변동폭 확정 서브 모듈은, 상기 제1 이동평균 값과 상기 제2 이동평균 값의 차이 값을 계산한다; 상기 차이 값의 절대치를 제1 데이터 변 동폭으로 확정하기 위한 제1 데이터 변동폭 확정유닛을 포함한다. B45, 조항B43에 따른 장치에 있어서, 상기 데이터 변동폭 확정모듈은, 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터에 근거하여 제2 데이터 변동폭을 얻기 위한 제2 데이터 변동폭 확정 서브 모듈을 포함하며; 상기 목표반복간격 확정모듈은, 상기 목표데이터의 제1 데이터 변동폭과 상기 제2 데이터 변동폭에 근거하여 상기 목표데이터에 대응하는 목표 반복간격을 확정함으로써, 상기 신경망이 상기 목표반복간격에 근거하여 상기 목표데이터의 양자화 파라미터를 업데이트하도록 하기 위한 제2 목표반복간격 확정 서브 모듈을 포함한다. B46, 조항B45에 따른 장치에 있어서, 상기 제2 데이터 변동폭 확정 서브 모듈은, 현재 반복에서 상기 목표데이터와 상기 목표데이터에 대응하는 양자화 데이터사이의 오차를 계산하기 위한 제2 데이터 변동폭 확정유닛을 포함하며; 상기 오차의 제곱을 상기 제2 데이터 변동폭으로 확정한다. B47, 조항B45에 따른 장치에 있어서, 상기 제2 목표반복간격 확정 서브 모듈은 상기 제1 데이터 변동폭과 상기 제2 데이터 변동폭 중의 최대 값에 근거하여 상기 목표데이터에 대응하는 목표반복간격을 확정하는 데 사용된다. B48, 조항B40 내지 B47 중 어느 한 항에 따른 장치에 있어서, 상기 데이터 변동폭 확정모듈은, 현재 반복이 업데이트 주기 이외에 위치할 때, 현재 반복 및 이력 반복 중 목표데이터의 데이터 변동폭을 획득 하기 위한 제3 데이터 변동폭 확정 서브 모듈을 포함하며, 상기 업데이트 주기에는 적어도 1회 반복이 포함된 다. B49, 조항B40 내지 B48 중 어느 한 항에 따른 장치에 있어서, 상기 장치는, 현재 반복이 미리 설정된 주기 내에 위치할 때, 현재 반복의 상기 미리 설정된 주기의 다음 주기에서 상기 현재 반복에 대응하는 반복 및 현재 반복에 대응하는 반복간격에 근거하여 주기간격을 확정하기 위한 주기간격 확정 모듈; 상기 목표데이터의 현재 반복에 대응하는 데이터 비트폭에 근거하여 상기 주기간격 내의 반복에서 상기 목표데 이터의 데이터 비트폭을 확정하기 위한 제1 주기간격 응용모듈; 또는 상기 목표데이터의 현재 반복에 대응하는 점 위치에 근거하여 상기 주기간격 내의 반복에서 상기 목표데이터의 점 위치를 확정하기 위한 제2 주기간격 응용모듈을 포함한다. B50, 조항B26 내지 B49 중 어느 한 항에 따른 장치에 있어서, 상기 장치는, 상기 양자화 대상 층 다음의 한 층또는 여러 층에서 상기 양자화 대상 층의 양자화 파라미터를 채용하기 위한 양자화 파라미터 계속 사용모듈을 포함한다. B51, 인공지능 칩에 있어서, 상기 칩에는 조항B26 내지 B50 중 어느 한 항에 따른 신경망 양자화장치가 포함된 다. B52, 전자기기에 있어서, 상기 전자기기에는 조항B51에 따른 인공지능 칩이 포함된다. B53, 보드 카드에 있어서, 상기 보드 카드는 메모리 디바이스, 인터페이스 장치와 제어 디바이스 및 조항B51에 따른 인공지능 칩을 포함하며; 여기에서, 상기 인공지능 칩은 상기 메모리 디바이스, 상기 제어 디바이스 및 상기 인터페이스 장치와 각각 연 결되고; 상기 메모리 디바이스는 데이터를 저장하는 데 사용되고; 상기 인터페이스 장치는 상기 인공지능 칩과 외부기기 사이의 데이터 전송을 실현하는 데 사용되며; 상기 제어 디바이스는 상기 인공지능 칩의 상태를 감시하는 데 사용된다. B54, 청구항B53에 따른 보드 카드에 있어서, 상기 메모리 디바이스는 복수 그룹의 저장유닛을 포함하며, 각 그 룹의 상기 저장유닛은 버스를 통해 상기 인공지능 칩과 연결되고, 상기 저장유닛은 DDR SDRAM이며; 상기 칩은 각 상기 저장유닛의 데이터 전송과 데이터 저장을 제어하기 위한 DDR 컨트롤러를 포함하고; 상기 인터페이스 장치는 표준 PCIE 인터페이스이다. 이상, 본 발명의 각 실시예를 설명하였으며, 상술한 설명은 예시적인 것일 뿐이고, 전체적인 것이 아니며, 또한 개시된 각 실시예에 한정되는 것이 아니다. 설명된 실시예의 범위 및 정신을 일탈할 일 없고, 당업자에 있어서 수정 및 변경의 대부분은 자명하다. 본명세서로 사용되는 용어의 선택은, 본명세서로 공개된 실시예의 원리, 실"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 29, "content": "제의 적용, 또는 시장에 있어서의 기술의 개량을 가장 잘 설명하는 것, 또는 본 기술분야의 다른 당업자가 본 명세서로 공개된 실시예를 이해가 가도록 하는 것을 목적으로 한다. 위에서 신경망 양자화의 문제를 해결하기 위해 제안한 방안（201910505239.7）을 설명하였다. 양자화 파라미터의 조정문제를 해결하기 위해, 다음과 같은 방안（201910528537.8）을 제안하였다. 구체적으로 는, 양자화 파라미터 조정방법, 장치 및 관련제품을 제안하였다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 30, "content": "본 발명은 컴퓨터 기술분야에 관한 것이며, 특히, 신경망의 양자화 파라미터 조정방법, 장치 및 관련제품에 관 한 것이다. 인공지능 기술의 지속적인 발전에 따라 그 응용분야는 점점 넓어져, 화상식별, 음성식별, 자연언어 처리 등 분 야에서 잘 응용되고 있다. 그러나, 인공지능 알고리즘의 복잡성이 증가함에 따라, 처리될 데이터의 데이터 량 과 데이터 차원이 끊임 없이 증가되고 있으며, 끊임 없이 증가되는 데이터 량 등은 연산장치의 데이터 처리효율, 저장장치의 저장용량 및 액세스 효율 등에 대하여 비교적 큰 도전을 제기하고 있다. 상술한 기술적 문제를 해결하기 위해, 종래기술에서는 고정 비트폭을 채용하여 신경망의 연산 데이터를 양자화 한다. 즉 부동 소수점형의 연산 데이터를 고정 소수점형의 연산 데이터로 변환하여 신경망의 연산 데이터의 압 축을 실현한다. 그러나, 신경망의 다양한 연산 데이터 사이에 비교적 큰 차이가 존재할 가능성이 있으며, 종래 의 양자화방법은 신경망 전체에 대하여 동일한 양자화 파라미터（점 위치 등）를 채용하여 양자화하며, 종종 정 밀도가 낮아지고, 데이터 연산결과에 영향을 준다. 이를 고려하여, 본 발명은 신경망의 양자화 정밀도를 향상시키고 연산결과의 정확성과 신뢰성을 보장할 수 있는 신경망의 양자화 파라미터 조정방법, 장치 및 관련제품을 제공한다. 본 발명은 신경망의 양자화 파라미터 조정방법을 제공하는 바, 상기 방법은, 양자화 대상 데이터의 데이터 변동폭을 획득하는 것; 및 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 신경망 연산에서의 양자화 파라미터를 조정하도록 하는 것을 포함하며, 여기에서, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. 본 발명은 신경망의 양자화 파라미터 조정장치도 제공하는 바, 메모리와 프로세서를 포함하며, 상기 메모리에는 컴퓨터 프로그램이 저장되어 있고, 상기 프로세서가 상기 컴퓨터 프로그램을 실행할 때, 상술한 임의의 한 항에 따른 방법의 단계를 실현한다. 구체적으로는, 프로세서는 상술한 컴퓨터 프로그램을 실행할 때, 다음과 같은 작 업을 실현한다. 양자화 대상 데이터의 데이터 변동폭을 획득하는 것; 및 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 신경망 연산에서의 양자화 파라미터를 조정하도록 하는 것을 포함하며, 여기에서, 상기 목표반복간격 은 적어도 1회 반복을 포함하고, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. 본 발명은 컴퓨터 판독 가능한 저장매체도 제공하는 바, 상기 컴퓨터 판독 가능한 저장매체에는 컴퓨터 프로그 램이 저장되어 있고, 상기 컴퓨터 프로그램은 실행될 때, 상술한 임의의 한 항에 따른 방법의 단계를 실현한다. 구체적으로는, 상술한 컴퓨터 프로그램은 실행할 때, 다음과 같은 작업을 실현한다. 양자화 대상 데이터의 데이터 변동폭을 획득하는 것; 및 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 신경망 연산에서의 양자화 파라미터를 조정하도록 하는 것을 포함하며, 여기에서, 상기 목표반복간격 은 적어도 1회 반복을 포함하고, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. 본 발명은 신경망의 양자화 파라미터 조정장치도 제공하는 바, 상기 장치는, 양자화 대상 데이터의 데이터 변동폭을 획득하기 위한 획득모듈; 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 신경망 연산에서의 양자화 파라미터를 조정하도록 하기 위한 반복간격 확정모듈을 포함하며, 여기에 서, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. 본 발명의 신경망의 양자화 파라미터 조정방법, 장치 및 관련제품은, 양자화 대상 데이터의 데이터 변동폭을 획 득하고, 당해 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써 당해 목표반복간격 에 근거하여 신경망의 양자화 파라미터를 조정할 수 있으며, 이러한 방식으로 양자화 대상 데이터를 확정하는 데이터 분포특성에 근거하여 신경망이 상이한 연산단계의 양자화 파라미터를 확정할 수 있다. 동일한 신경망의 각종 연산 데이터는 모두 동일한 양자화 파라미터를 채용하는 방식인 종래기술에 비해, 본 발명의 방법 및 장치 는 신경망 양자화 과정 중의 정밀도를 향상시킬 수 있으며, 진일보로 연산결과의 정확성과 신뢰성을 확보할 수 있다. 또한, 목표반복간격을 확정함으로써 양자화 효율도 향상시킬 수 있다. 본 발명에 관련되는 첨부 도면은, 명세서에 포함되고, 명세서의 일부를 구성하는 첨부 도면은, 명세서와 함께 본 발명의 예시적인 실시예, 특징, 및 태양을 가리키고, 본 발명의 원리를 설명하기 위해서 사용된다.. 도44은 본 발명의 일 실시예의 양자화 파라미터 조정방법의 적용환경을 나타내는 모식도이고; 도45는 본 발명의 일 실시예의 양자화 대상 데이터와 양자화 데이터의 대응관계를 나타내는 모식도이고; 도46은 본 발명의 일 실시예의 양자화 대상 데이터를 나타내는 변환 모식도이고; 도47는 본 발명의 일 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도48는 본 발명의 일 실시예의 양자화 대상 데이터의 연산과정 중 변동추세를 나타내는 도이고; 도49은 본 발명의 일 실시예의 파라미터 조정방법 중 목표반복간격의 확정방법을 나타내는 흐름도이고; 도50은 본 발명의 일 실시예에 있어서 포인트 위치 변동폭의 확정방법을 나타내는 흐름도이고; 도51은 본 발명의 일 실시예에 있어서 제2 균치의 확정방법을 나타내는 흐름도이고; 도52는 본 발명의 일 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도53은 본 발명의 다른 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도54은 본 발명의 또 다른 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도55는 본 발명의 또 하나의 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도56은 본 발명의 다른 실시예에 있어서 제2 균치의 확정방법을 나타내는 흐름도이고; 도57는 본 발명의 다른 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도58은 본 발명의 일 실시예의 양자화 파라미터 조정방법 중 양자화 파라미터의 조정을 나타내는 흐름도이고; 도59은 본 발명의 다른 실시예의 파라미터 조정방법 중 목표반복간격의 확정방법을 나타내는 흐름도이고; 도60은 본 발명의 또 다른 실시예의 파라미터 조정방법 중 목표반복간격의 확정방법을 나타내는 흐름도이고; 도61은 본 발명의 또 다른 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도62는 본 발명의 또 하나의 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도63은 본 발명의 일 실시예의 양자화 파라미터 조정장치를 나타내는 구조 블록도이고; 도64은 본 발명의 일 실시예의 양자화 파라미터 조정장치를 나타내는 구조 블록도이고; 도65은 본 발명의 일 실시예의 양자화 파라미터 조정장치를 나타내는 구조 블록도이고; 도66은 본 발명의 일 실시예의 양자화 파라미터 조정장치를 나타내는 구조 블록도이고; 도67은 본 발명의 일 실시예의 양자화 파라미터 조정장치를 나타내는 구조 블록도이고; 도68은 본 발명 실시예에 따른 보드 카드를 나타내는 구조 블록도이다. 양자화 파라미터의 조정문제를 해결하기 위해, 다음과 같은 방안（201910528537.8）을 제안하였다. 이하, 본 발 명 실시예에 따른 도면을 참조하여 본 발명 실시예에 따른 기술방안을 명확하고 완전하게 설명한다, 물론, 所설 명의 실시예是본 발명일부실시예, 而不是전부의 실시예. 본 발명의 실시예를 기반으로, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 창조적인 노력 없이 획득한 모든 다른 실시예는 모두 본 발명의 보호범위에 속한다. 또한, 본 발명의 청구항, 명세서 및 도면 중의 \"제1 \", \"제2 \"등 용어는 특정 순서를 설명하기보다는 다를 대상 을 구별하는 데 사용된다는 것을 이해해야 한다. 본 발명의 명세서와 청구범위에서 사용한 \"포함한다\" 및 \"가진 다\" 등 용어는 설명하는 특징, 전체, 단계, 작업, 요소 및/또는 컴포넌트의 존재를 나타내지만, 하나 또는 복수 의 다른 특징, 전체, 단계, 작업, 요소, 컴포넌트 및/또는 이들 컬렉션의 존재 또는 추가를 배제하지 않는다. 여기에서 본 발명 명세서에서 사용한 용어는 특정 실시예를 설명할 목적 뿐이며, 본 발명을 한정하는 것을 의도 하지 않는 것도 이해해야 한다. 본 발명 명세서 및 청구범위에서 사용된 바와 같이, 문매이 다른 상황을 명확히 명시하지 않는 한, 단수 형식의 “하나”, “한 개” 및 “당해”는 복수 형식을 포함하도록 의도된다. 또한, 본 발명 명세서 및 청구범위에서 사용한 “및/또는 ” 용어는 관련하여 열거한 항목 중의 하나 또는 복수의 의 임의의 조합 및 모든 가능한 조합을 의미하며, 또한 이들 조합을 포함하는 것이 이해되어야 한다. 인공지능 알고리즘의 복잡성이 증가함에 따라, 처리될 데이터의 데이터 량과 데이터 차원도 끊임 없이 증가되 고 있으며, 종래의 신경망 알고리즘은 일반적으로 부동 소수점 데이터 형식을 채용하여 신경망 연산을 실행하였 다. 끊임 없이 증가되는 데이터 량 등은 연산장치의 데이터 처리효율, 저장장치의 저장용량 및 액세스 효율 등 에 대하여 비교적 큰 도전을 제기하고 있다. 상술한 문제를 해결하기 위해, 신경망 연산과정에 관련된 연산 데 이터를 양자화할 수 있다. 즉 부동 소수점 표현의 연산 데이터를 고정 소수점 표현의 연산 데이터로 전환하여, 저장장치의 저장용량 및 액세스 효율을 감소시키며, 연산장치의 연산효율을 향상시킬 수 있다. 그러나 종래의 양자화방법은 신경망의 전체 훈련과정에서 모두 동일한 데이터 비트폭과 양자화 파라미터（소수점의 위치 등） 를 채용하여 신경망의 상이한 연산 데이터를 양자화한다. 상이한 연산 데이터 사이의 차이, 또는, 훈련과정의 여러 단계의 연산 데이터의 차이로 인해, 상술한 양자화방법을 채용하여 양자화할 때, 종종 정밀도가 불충분하 여 연산결과에 영향을 주게 된다. 이를 바탕으로, 본 발명은 신경망의 양자화 파라미터 조정방법을 제공하는 바, 당해 방법은 메모리와 프로 세서를 포함한 양자화 파라미터 조정장치에 적용된다. 도44은 당해 양자화 파라미터 조정장치의 구조 블록도이고, 여기에서, 당해 양자화 파라미터 조정장치의 프로세서는 범용 프로세서일 수 있으며, 당 해 양자화 파라미터 조정장치의 프로세서도 인공지능 프로세서일 수도 있으며, 당해 양자화 파라미터 조정장치의 프로세서는 범용 프로세서와 인공지능 프로세서를 포함할 수도 있다. 여기에서는 구체적으로 한정하지 않는다. 당해 메모리는 신경망 연산과정중의 연산 데이터를 저장하는 데 사용되며, 당해 연산 데 이터는 뉴런 데이터, 가중치 데이터 또는 그래디언트 데이터 중의 한 가지 또는 여러 가지일 수 있다. 당해 메 모리는 컴퓨터 프로그램을 저장하는 데도 사용되며, 당해 컴퓨터 프로그램은 상술한 프로세서에 의해 실행될 때, 본 발명 실시예에서의 양자화 파라미터 조정방법을 실현할 수 있다. 당해 방법은 신경망의 훈련 또 는 미조정과정에 응용할 수 있으며, 신경망의 훈련 또는 미조정과정의 상이한 단계의 연산 데이터의 분포특성에 근거하여, 연산 데이터의 양자화 파라미터를 동적으로 조정할 수 있으며, 따라서 신경망의 양자화 과정의 정밀 도를 향상하고, 연산결과의 정확성 및 신뢰성을 보장할 수 있다. 특히 명기되지 않는 한, 상기 인공지능 프로세서는 임의의 적절한 하드웨어 프로세서, 예를 들어, CPU, GPU, FPGA, DSP 및 ASIC 등일 수 있다 . 특히 명기되지 않는 한, 상기 메모리는 임의의 적절한 자기 저장 매체 또는 광 자기 저장 매체, 예를 들어, 저항변화 메모리RRAM（Resistive Random Access Memory）, 다이나믹 랜덤 액세 스 메모리DRAM（Dynamic Random Access Memory）, 스태틱 랜덤 액세스 메모리SRAM（Static Random-Access Memory）, 임베디드 다이나믹 랜덤 액세스 메모리EDRAM（Enhanced Dynamic Random Access Memory）, 고대역폭 메모리HBM（High-Bandwidth Memory）또는 하이브리드 메모리 큐브 HMC（Hybrid Memory Cube）등일 수 있다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 31, "content": "본 발명의 내용을 보다 쉽게 이해하기 위해, 이하에서는, 먼저 본 발명 실시예에 있어서의 양자화 과정 및 양자 화 과정에 관련된 양자화 파라미터에 대하여 설명한다. 본 발명 실시예에서, 양자화는 제1 데이터 형식의 연산 데이터를 제2 데이터 형식의 연산 데이터로 변환하는 것 을 의미한다. 여기에서, 당해 제1 데이터 형식의 연산 데이터는 부동 소수점 표현의 연산 데이터일 수 있고, 당 해 제2 데이터 형식의 연산 데이터는 고정 소수점 표현의 연산 데이터일 수 있다. 부동 소수점 표현의 연산 데 이터는 일반적으로 비교적 큰 저장공간을 점유하며, 따라서 부동 소수점 표현의 연산 데이터를 고정 소수점 표 현의 연산 데이터로 변환함으로써, 저장공간을 절약하고, 연산 데이터의 액세스 효율 및 연산효율 등을 향상시 킬 수 있다. 바람직하게는, 양자화 과정중의 양자화 파라미터는 점 위치 및/또는 스케일 팩터를 포함할 수 있다. 여기에서, 점 위치는 양자화 후의 연산 데이터에서의 소수점의 위치를 의미한다. 스케일 팩터는 양자화 데이터의 최대 값 과 양자화 대상 데이터의 최대 절대치 사이의 비율을 의미한다. 또한, 양자화 파라미터는 오프셋을 포함할 수 있다. 오프셋은, 비대칭의 양자화 대상 데이터에 대하여, 당해 양자화 대상 데이터 중의 복수의 요소의 중간 값 을 의미하며, 구체적으로는, 오프셋은 양자화 대상 데이터 중 복수의 요소의 중앙 값일 수 있다. 당해 양자화 대상 데이터가 대칭적인 양자화 대상 데이터인 경우, 양자화 파라미터는 오프셋을 포함하지 않아도 된다. 이 때 당해 양자화 대상 데이터에 근거하여 점 위치 및/또는 스케일 팩터 등 양자화 파라미터를 확정할 수 있다. 도67에 도시된 바와 같이, 양자화 대상 데이터는 원점에 대하여 대칭되는 데이터이며, Z1가 양자화 대상 데이터 중 요소의 절대치의 최대 값이고, 양자화 대상 데이터에 대응하는 데이터 비트폭이 n이며, A가 데이터 비트폭 n 으로 양자화 대상 데이터를 양자화한 후의 양자화 데이터로서 표현할 수 있는 최대 값이라고 가정하면, 이다. A는 Z1을 포함하며 Z1> 인 필요가 있다. 따라서 수학식（1）의 제약이 있다. 수학식（1） 프로세서는 양자화 대상 데이터 중의 절대치 최대 값Z1과 데이터 비트폭n에 근거하여, 점 위치s를 계산할 수 있 다. 예를 들어, 다음과 같은 수학식（2）을 이용하여 양자화 대상 데이터에 대응하는 점 위치s를 계산하여 얻을 수 있다. 수학식（2） 여기에서, ceil은 정수로 올림이고, Z1은 양자화 대상 데이터 중의 절대치 최대 값이며, s는 점 위치이고, n은 데이터 비트폭이다. 이 때, 점 위치s를 채용하여 양자화 대상 데이터를 양자화할 때, 부동 소수점 표현의 양자화 대상 데이터 는 로 표현할 수 있다. 여기에서, 는 양자화 후의 n비트 바이너리 표현 값이고, s는 점 위치를 표현한 다. 여기에서, 당해 양자화 대상 데이터에 대응하는 양자화 데이터는 다음과 같다. 수학식（3） 여기에서, s는 점 위치이고, 는 양자화 데이터이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정 수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다, 예를 들어, 정수로 올림, 정수로 내 림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（3）중의 반올림의 정수연산을 대체할 수 있다. 이해할 수 있은 것은, 데이터 비트폭이 일정한 경우, 점 위치에 근거하여 양자화하여 얻은 양자화 데이터에서, 소수점 뒤의 비트 수가 많으면 많을수록 양자화 데이터의 양자화 정밀도가 높아진다. 또한, 당해 양자화 대상 데이터에 대응하는 중간표현 데이터 은 다음과 같을 수 있다. 수학식（4） 여기에서, s는 상술한 수학식（2）에 따라 확정한 점 위치이고, 는 양자화 대상 데이터이며, 는 반올림 에 따른 정수연산이다. 은 상술한 양자화 데이터 에 대해 역 양자화하여 획득한 데이터이고, 당해 중간표현 데이터 의 데이터 표현형식은 상술한 양자화 대상 데이터 의 데이터 표현형식과 일치하며, 당해 중간표현 데 이터 는 양자화 오차를 계산는 사용된다(상세에 대해 후술함). 여기에서, 역 양자화는 양자화의 반대과정을 의미한다. 바람직하게는, 스케일 팩터는 제1 스케일 팩터를 포함할 수 있다. 당해 제1 스케일 팩터는 다음과 같은 방식으 로 계산할 수 있다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 32, "content": "= 수학식（5） 여기에서, Z1은 양자화 대상 데이터 중의 절대치 최대 값이고, A는 데이터 비트폭 n으로 양자화 대상 데이터를 양자화한 후 데이터의 양자화 데이터가 표현할 수 있는 최대 값이며, 이다. 이 때, 프로세서는 점 위치와 제1 스케일 팩터를 결합한 방식을 채용하여 양자화 대상 데이터 를 양자화하여 양자화 데이터를 획득할 수 있다. 수학식（6） 여기에서, s는 상술한 수학식（2）따라 확정한 점 위치이고, 은 제1 스케일 팩터이고, 는 양자화 데이터이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연 산을 채용하여, 수학식（6）중의 반올림의 정수연산을 대체할 수 있다. 또한, 당해 양자화 대상 데이터에 대응하는 중간표현 데이터 는 다음과 같을 수 있다. 수학식（7） 여기에서, s는 상술한 수학식（2）에 따라 확정한 점 위치이고, 은 스케일 팩터이며, 는 양자화 대상 데이터 이고, 는 반올림에 따른 정수연산이다. 은 상술한 양자화 데이터 에 대하여 역 양자화하여 획득한 데 이터이고, 당해 중간표현 데이터 의 데이터 표현형식은 상술한 양자화 대상 데이터 의 데이터 표현형식과 일 치하며, 당해 중간표현 데이터 은 양자화 오차의 계산에 사용될 수 있다(상세에 대해 후술함). 여기에서, 역양자화는 양자화의 반대과정을 의미한다. 바람직하게는, 당해 스케일 팩터는 제2 스케일 팩터를 포함할 수 있다. 당해 제2 스케일 팩터는 다음과 같은 방 식으로 계산될 수 있다. = 수학식（8） 프로세서는 제2 스케일 팩터를 별도로 사용하여 양자화 대상 데이터 를 양자화하여 양자화 데이터를 획득할 수 있다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 33, "content": "수학식（9） 여기에서, 는 제2 스케일 팩터이고, 는 양자화 데이터이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정 수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（9）중의 반올림의 정수연산을 대체할 수 있다. 이해할 수 있은 것은, 데이터 비트폭이 일정한 경우, 상이한 스케일 팩터를 채용하면 양자화 된 데이터의 수치범위를 조정할 수 있다. 또한, 당해 양자화 대상 데이터에 대응하는 중간표현 데이터 은 다음과 같을 수 있다. 수학식（10） 여기에서, 는 제2 스케일 팩터이고, 는 양자화 대상 데이터이고, 는 반올림에 따른 정수연산이다. 은 상술한 양자화 데이터 에 대해 역 양자화하여 획득한 데이터일 수 있으며, 당해 중간표현 데이터 의 데이터 표현형식은 상술한 양자화 대상 데이터 의 데이터 표현형식과 일치하고, 당해 중간표현 데이터 은 양 자화 오차를 계산하는 데 사용될 수 있다 (상세에 대해 후술함). 여기에서, 역 양자화는 양자화의 반대과정을 의미한다. 또한, 상술한 제2 스케일 팩터는 점 위치와 제1 스케일 팩터 에 근거하여 확정한 것일 수 있다. 즉 제2 스케일 팩터는 다음과 같은 수학식에 따라 계산할 수 있다. = 수학식（11） 여기에서, s는 상술한 수학식（2）에 따라 확정한 점 위치이고, 은 상술한 수학식（5）에 따라 계산하여 획득 한 제1 스케일 팩터이다. 바람직하게는, 본 발명 실시예의 양자화방법은 대칭적 데이터의 양자화를 실현할 뿐만 아니라, 비대칭적 데이터 의 양자화도 실현할 수 있다. 이 때, 프로세서는 비대칭적인 데이터를 대칭적 데이터로 변환하여 데이터의 \"오 버플로\"를 회피할 수 있다. 구체적으로는, 양자화 파라미터는 오프셋을 포함할 수 있다. 당해 오프셋은 양자화 대상 데이터의 중앙 값일 수 있고, 당해 오프셋은 양자화 대상 데이터의 중앙 값이 원점에 대한 오프셋을 표현 할 수 있다. 도3-3에 도시된 바와 같이, 프로세서는 양자화 대상 데이터의 데이터분포에 대해 통계하여, 양자화 대상 데이터 중 모든 요소 중의 최소 값 , 및 당해 양자화 대상 데이터 중 모든 요소 중의 최대 값 을 획득할 수 있으며, 그 다음에는, 프로세서는 당해 최소 값 과 최대 값 에 근거하여 상술한 오프셋을 계산 하여 획득할 수 있다. 구체적인 오프셋 계산방식은 다음과 같다. 수학식（12） 여기에서, o는 오프셋을 나타내고, 은 양자화 대상 데이터 모든 요소 중의 최소 값을 나타내고, 은 양 자화 대상 데이터 모든 요소 중의 최대 값을 나타낸다. 또한, 프로세서는 당해 양자화 대상 데이터 모든 요소 중의 최소 값 과 최대 값 에 근거하여 당해 양자화 대상 데이터 중의 절대치 최대 값 를 확정할 수 있다. 수학식（13） 이러한 방식으로, 도3-3에 도시된 바와 같이, 프로세서는 오프셋o에 근거하여 양자화 대상 데이터를 평행이동시 켜, 비대칭인 양자화 대상 데이터를 대칭적인 양자화 대상 데이터로 변환할 수 있다. 프로세서는 당해 양자화 대상 데이터 중의 절대치 최대 값 에 근거하여 진일보로 점 위치s를 확정할 수 있다. 여기에서, 점 위치는 다음 과 같은 수학식에 따라 계산할 수 있다. 수학식（14） 여기에서, ceil은 정수로 올림이고, s는 점 위치이고, n은 데이터 비트폭이다. 그 다음에는, 프로세서는 당해 오프셋 및 그에 대응하는 점 위치에 근거하여 양자화 대상 데이터를 양자화하며, 양자화 데이터를 획득할 수 있다. 수학식（15） 여기에서, s는 상술한 수학식（14）에 따라 확정한 점 위치이고, 는 양자화 데이터이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채 용할 수도 있다, 예를 들어, 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수 학식（15）중의 반올림의 정수연산을 대체할 수 있다. 또한, 당해 양자화 대상 데이터에 대응하는 중간표현 데이터 은 다음과 같을 수 있다. 수학식（16） 여기에서, s는 상술한 수학식（14）에 따라 확정한 점 위치이고, 는 오프셋이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정수연산이다. 은 상술한 양자화 데이터 에 대해 역 양자화하여 획득한 데이터일 수 있고, 당해 중간표현 데이터 의 데이터 표현형식은 상술한 양자화 대상 데이터 의 데이터 표현형 식과 일치하며, 당해 중간표현 데이터 은 양자화 오차를 계산하는 데 사용될 수 있다 (상세에 대해 후술함). 여기에서, 역 양자화는 양자화의 반대과정을 의미한다. 더 바람직하게는, 프로세서는 당해 양자화 대상 데이터 중의 절대치 최대 값 에 근거하여 진일보로 점 위치s와 제1 스케일 팩터 을 확정할 수 있다. 여기에서, 점 위치s의 구체적 계산방식은 상술한 수학식（14）를 참조하면 된다. 제1 스케일 팩터 는 다음과 같은 수학식에 따라 계산할 수 있다. = 수학식（17） 프로세서는 오프셋 및 그에 대응하는 제1 스케일 팩터 과 점 위치s에 근거하여, 양자화 대상 데이터를 양자화하 며, 양자화 데이터를 획득할 수 있다. 수학식（18） 여기에서, 은 제1 스케일 팩터이고, s는 상술한 수학식（14）에 따라 확정한 점 위치이고,"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 34, "content": "는 양자화 데이터이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（18）중의 반올림의 정수연산을 대체할 수 있다. 또한, 당해 양자화 대상 데이터에 대응하는 중간표현 데이터 는 다음과 같을 수 있다. 수학식（19） 여기에서, 은 제1 스케일 팩터이고, s는 상술한 수학식（14）에 따라 확정한 점 위치이고, o는 오프셋이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정수연산이다. 은 상술한 양자화 데이터 에 대하여 역 양자화하여 획득한 데이터일 수 있으며, 당해 중간표현 데이터 의 데이터 표현형식은 상술한 양자화 대상 데 이터 의 데이터 표현형식과 일치하며, 당해 중간표현 데이터 은 양자화 오차를 계산하는 데 사용될 수 있다, (상세에 대해 후술함). 여기에서, 역 양자화는 양자화의 반대과정을 의미한다. 바람직하게는, 당해 스케일 팩터는 제2 스케일 팩터를 포함할 수 있고, 당해 제2 스케일 팩터는 다음과 같은 방 식으로 계산될 수 있다. = 수학식（20） 프로세서는 제2 스케일 팩터를 별도로 사용하여 양자화 대상 데이터 를 양자화함으로써, 양자화 데이터를 획득 할 수 있다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 35, "content": "수학식（21） 여기에서, 는 제2 스케일 팩터이고, 는 양자화 데이터이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정 수로 내림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（21）중의 반올림의 정수연산을 대체할 수 있다. 이해할 수 있은 것은, 데이터 비트폭이 일정한 경우, 상이한 스케일 팩터를 채용하면 양자화 된 데이 터의 수치범위를 조정할 수 있다. 또한, 당해 양자화 대상 데이터에 대응하는 중간표현 데이터 은 다음과 같을 수 있다. 수학식（22） 여기에서, 는 제2 스케일 팩터이고, 는 양자화 대상 데이터이며, 는 반올림에 따른 정수연산이다. 은 상술한 양자화 데이터 에 대해 역 양자화하여 획득한 데이터일 수 있고, 당해 중간표현 데이터 의 데 이터 표현형식은 상술한 양자화 대상 데이터 의 데이터 표현형식과 일치하며, 당해 중간표현 데이터 은 양자 화 오차를 계산하는 데 사용될 수 있다 (상세에 대해 후술함). 여기에서, 역 양자화는 양자화의 반대과정을 의 미한다. 또한, 상술한 제2 스케일 팩터는 점 위치와 제1 스케일 팩터 에 근거하여 확정할 수 있다. 즉 제2 스케일 팩터 는 다음과 같은 수학식에 따라 계산할 수 있다. = 수학식（23） 여기에서, s는 상술한 수학식（14）에 따라 확정한 점 위치이고, 은 상술한 수학식（17）에 따라 계산하여 획득한 제1 스케일 팩터이다. 바람직하게는, 프로세서는 오프셋o에 근거하여 양자화 대상 데이터를 양자화할 수 있다. 이 때 점 위치s 및/또 는 스케일 팩터는 미리 설정된 값일 수 있다. 이 때, 프로세서는 오프셋에 근거하여 양자화 대상 데이터를 양자 화하며, 양자화 데이터를 획득한다. 수학식（24） 여기에서, 는 오프셋이고, 는 양자화 데이터이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정 수연산이다. 이해할 수 있은 것은, 다른 정수연산방법을 채용할 수도 있다. 예를 들어, 정수로 올림, 정수로 내 림, 0을 향해 버림 또는 올림 등 정수연산을 채용하여, 수학식（24）중의 반올림의 정수연산을 대체할 수 있다. 이해할 수 있은 것은, 데이터 비트폭이 일정한 경우, 서로 다른 오프셋을 채용하여 양자화 된 데이터의 수치와 양자화 전의 데이터 사이의 오프셋을 조정할 수 있다. 또한, 당해 양자화 대상 데이터에 대응하는 중간표현 데이터 은 다음과 같을 수 있다. 수학식（25） 여기에서, o는 오프셋이며, 는 양자화 대상 데이터이고, 는 반올림에 따른 정수연산이다. 은 상술한 양자화 데이터 에 대해 역 양자화하여 획득한 데이터일 수 있고, 당해 중간표현 데이터 의 데이터 표현형식은 상술한 양자화 대상 데이터 의 데이터 표현형식과 일치하며, 당해 중간표현 데이터 은 양자화 오차를 계산하 는 데 사용될 수 있다 (상세에 대해 후술함). 여기에서, 역 양자화는 양자화의 반대과정을 의미한다. 본 발명의 양자화작업은 상술한 부동 소수점 데이터의 양자화에 사용될 수 있을 뿐만 아니라, 고정 소수점 데이 터의 양자화를 실현하는 데도 사용될 수 있다. 바람직하게는, 당해 제1 데이터 형식의 연산 데이터는 고정 소수 점 표현의 연산 데이터일 수 있고, 당해 제2 데이터 형식의 연산 데이터는 고정 소수점 표현의 연산 데이터일 수 있으며, 제2 데이터 형식의 연산 데이터의 데이터 표현범위는 제1 데이터 형식의 데이터 표현범위보다 작고, 제2 데이터 형식의 소수점 비트 수는 제1 데이터 형식의 소수점 비트 수보다 크다. 즉 제2 데이터 형식의 연산 데이터는 제1 데이터 형식의 연산 데이터에 비해 보다 높은 정밀도를 가진다. 예를 들어, 당해 제1 데이터 형식 의 연산 데이터는 16비트를 점유한 고정 소수점 데이터이며, 당해 제2 데이터 형식은 8비트를 점유한 고정 소수 점 데이터일 수 있다. 본 발명 실시예에서, 고정 소수점이 나타내는 연산 데이터를 양자화 처리함으로써 연산 데이터가 점유의 저장공간을 진일보로 삭감하고, 연산 데이터의 액세스 효율 및 연산효율을 향상시킬 수 있다. 본 발명의 일 실시예의 양자화 파라미터 조정방법은, 신경망의 훈련 또는 미조정과정에 응용할 수 있으며, 신경 망의 훈련 또는 미조정과정에서, 신경망 연산과정의 연산 데이터의 양자화 파라미터를 동적으로 조정하여 당해 신경망의 양자화 정밀도를 향상시킬 수 있다. 여기에서, 신경망은 심층 신경망 또는 컨볼루션 신경망 등일 수 있으며, 여기에서는 구체적으로 한정하지 않는다. 또한, 신경망의 훈련（Training）은 신경망（당해 신경망의 가중치는 난수일 수 있다）에 대해 여러번 반복연산 （iteration）을 수행하여 신경망의 가중치가 미리 설정된 조건을 충족할 수 있게 하는 과정이라는 것이 분명해 야 한다. 여기에서, 1회 반복연산은 일반적으로 1회 순방향 연산, 1회 역방향 연산 및 1회 가중치 업데이트 연 산을 포함한다. 순방향 연산은 신경망의 입력 데이터에 근거하여 순방향 추론을 수행하여 순방향 연산결과를 획 득하는 과정을 의미한다. 역방향 연산은 순방향 연산결과와 미리 설정된 기준 값에 근거하여 손실 값을 확정하 고, 당해 손실 값에 근거하여 가중치 그래디언트 값 및/또는 입력 데이터 그래디언트 값을 확정하는 과정을 의 미한다. 가중치 업데이트 연산은 가중치 그래디언트 값에 근거하여 신경망의 가중치를 조정하는 과정을 의미한 다. 구체적으로는, 신경망의 훈련과정은 다음과 같다. 프로세서는 가중치가 난수인 신경망을 채용하여 입력 데 이터에 대해 순방향 연산을 수행하여 순방향 연산결과를 획득할 수 있다. 그 다음에는 프로세서는 당해 순방향 연산결과와 미리 설정된 기준 값에 근거하여 손실 값을 확정하고, 당해 손실 값에 근거하여 가중치 그래디언트 값 및/또는 입력 데이터 그래디언트 값을 확정한다. 마지막, 프로세서는 가중치 그래디언트 값에 근거하여 신경 망의 그래디언트 값을 업데이트하여 새로운 가중치를 획득하여 1회 반복연산을 완료할 수 있다. 프로세서는 신 경망의 순방향 연산결과가 미리 설정된 조건을 충족할 때까지 반복연산을 여러번 루프 실행한다. 예를 들어, 신 경망의 순방향 연산결과가 미리 설정된 기준 값에 수렴되면 훈련이 종료된다. 또는, 신경망의 순방향 연산결과 와 미리 설정된 기준 값이 확정한 손실 값이 미리 설정된 정밀도 이하인 경우 훈련이 종료된다. 미조정은 신경망（당해 신경망의 가중치는 이미 수렴상태에 있으며 난수가 아니다）에 대해 여러번 반복연산을 수행하여 신경망의 정밀도가 미리 설정된 요구사항을 충족시킬 수 있도록 하는 과정을 의미한다. 당해 미조정과 정과 상술한 훈련과정은 기본적으로 일치하며, 수렴상태에 있는 신경망을 다시 훈련하는 과정이라고 간주할 수 있다. 추론（Inference）은 가중치가 미리 설정된 조건을 충족하는 신경망을 채용하여 순방향 연산을 수행하여 식별 또는 분류 등 기능을 실현하는 과정을 의미한다. 예를 들어 신경망을 채용하여 화상식별 등을 수행한다 . 본 발명 실시예에서, 상술한 신경망의 훈련 또는 미조정과정에서, 신경망 연산의 상이한 단계에서 상이한 양자 화 파라미터를 채용하여 신경망의 연산 데이터를 양자화하며, 양자화 후의 데이터에 근거하여 반복연산을 수행 할 수 있다. 따라서 신경망 연산과정에서의 데이터 저장공간을 감소시키고, 데이터 액세스 효율 및 연산효율을 향상시킬 수 있다. 도3-4에 도시된 바와 같이, 상술한 방법은 다음과 같은 단계를 포함할 수 있다. S100, 양자화 대상 데이터의 데이터 변동폭을 획득한다. 바람직하게는, 프로세서는 당해 양자화 대상 데이터의 데이터 변동폭을 직접 읽어 낼 수 있으며, 당해 양자화 대상 데이터의 데이터 변동폭은 사용자가 입력할 수 있다. 바람직하게는, 프로세서는 현재 반복의 양자화 대상 데이터와 이력 반복의 양자화 대상 데이터에 근거하여 계산 을 통해 상술한 양자화 대상 데이터의 데이터 변동폭을 획득할 수도 있다, 여기에서 현재 반복은 현재 실행하는 반복연산을 의미하고, 이력 반복은 현재 반복 전에 실행한 반복연산을 의미한다. 예를 들어, 프로세서는 현재 반복의 양자화 대상 데이터 중 요소의 최대 값과 요소의 평균 값, 및 각 이력 반복의 양자화 대상 데이터 중 요 소의 최대 값과 요소의 평균 값를 획득하고, 매번 반복 중 요소의 최대 값과 요소의 평균 값에 근거하여 양자화 대상 데이터의 변동폭을 확정할 수 있다. 현재 반복의 양자화 대상 데이터 중 요소의 최대 값이 미리 설정된 수 의 이력 반복의 양자화 대상 데이터 중 요소의 최대 값에 가까울 경우, 또 현재 반복의 양자화 대상 데이터 중 요소의 평균 값가 미리 설정된 수의 이력 반복의 양자화 대상 데이터 중 요소의 평균 값에 가까울 경우, 상술한 양자화 대상 데이터의 데이터 변동폭이 작다고 확정할 수 있다. 그렇지 않을 경우, 양자화 대상 데이터의 데이 터 변동폭이 크다고 확정할 수 있다. 한편, 당해 양자화 대상 데이터의 데이터 변동폭은 양자화 대상 데이터의 이동평균 값 또는 분산 등을 채용하여 표현할 수 있으며, 여기에서는 구체적으로 한정하지 않는다. 본 발명 실시예에서, 당해 양자화 대상 데이터의 데이터 변동폭은 양자화 대상 데이터의 양자화 파라미터를 조 정할 필요가 있는지 여부를 확정하는 데 사용할 수 있다. 예를 들어, 양자화 대상 데이터의 데이터 변동폭이 비 교적 크면 양자화 정밀도를 보장하기 위해 양자화 파라미터를 제때에 조정할 필요가 있는 것을 설명할 수 있다. 양자화 대상 데이터의 데이터 변동폭이 비교적 작으면 현재 검사 반복 및 그 다음의 일정 수의 반복에서 이력 반복의 양자화 파라미터를 계속하여 사용할 수 있으며, 양자화 파라미터의 빈번한 조정을 회피할 수 있고 양자 화 효율을 향상시킬 수 있다. 여기에서, 매번 반복은 적어도 하나의 양자화 대상 데이터에 관련되며, 당해 양자화 대상 데이터는 부동 소수점 으로 표현하는 연산 데이터일 수 있고, 고정 소수점으로 표현하는 연산 데이터일 수도 있다. 바람직하게는, 매 번 반복의 양자화 대상 데이터는 뉴런데이터, 가중치 데이터 또는 그래디언트 데이터 중 적어도 한 가지일 수 있으며, 그래디언트 데이터는 뉴런 그래디언트 데이터와 가중치 그래디언트 데이터 등을 포함할 수도 있다. S200, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 당해 목표반복간격 에 근거하여 신경망 연산 중의 양자화 파라미터를 조정한다. 여기에서, 상기 목표반복간격은 적어도 1회 반복을 포함하며, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하 는 데 사용된다. 바람직하게는, 당해 양자화 파라미터는 상술한 점 위치 및/또는 스케일 팩터를 포함할 수 있다. 여기에서, 스케 일 팩터는 제1 스케일 팩터와 제2 스케일 팩터를 포함할 수 있다. 구체적인 점 위치 계산방법은 상술한 수학식 （2）를 참조할 수 있다. 스케일 팩터의 계산방법은 상술한 수학식（5） 또는 （8）을 참조할 수 있으며, 여기 에서 다시 언급하지 않는다. 바람직하게는, 당해 양자화 파라미터는 오프셋을 포함할 수 있으며, 당해 오프셋의 계산방법은 상술한 수학식（12）을 참조할 수 있다. 또한, 프로세서는 수학식（14）에 따라 점 위치를 확정하고, 상술한 수학식（17） 또는 （20）에 따라 스케일 팩터를 확정할 수 있다. 본 발명 실시예에서, 프로 세서는 확정한 목표반복간격에 근거하여, 상술한 점 위치, 스케일 팩터 또는 오프셋 중 적어도 한 가지를 업데 이트하여 당해 신경망 연산 중의 양자화 파라미터를 조정할 수 있다. 즉, 당해 신경망 연산 중의 양자화 파라미 터는 신경망 연산 중 양자화 대상 데이터의 데이터 변동폭에 근거하여 업데이트함으로써 양자화 정밀도를 보장 할 수 있다. 또한, 신경망의 훈련 또는 미조정과정에서 연산 데이터의 변화추세를 통계 및 분석하는 것을 통해 양자화 대상 데이터의 데이터 변동곡선을 얻을 수 있음을 이해할 수 있다. 도3-5에 도시된 바와 같이, 당해 데이터 변동곡선 으로부터, 신경망의 훈련 또는 미조정 초기에서, 상이한 반복의 양자화 대상 데이터의 데이터 변동이 격렬하며, 훈련 또는 미조정 연산이 진행함에 따라 상이한 반복의 양자화 대상 데이터의 데이터 변동이 점차 평탄해지는 경향이 있음을 알 수 있다. 따라서, 신경망 훈련 또는 미조정의 초기에서, 양자화 파라미터를 비교적 빈번하게 조정할 수 있다. 신경망 훈련 또는 미조정의 중기 및 후기에서, 여러번 반복 또는 훈련주기 간격으로 양자화 파 라미터를 다시 조정할 수 있다. 본 발명의 방법은 적절한 반복간격을 확정함으로써 양자화 정밀도와 양자화 효 율의 균형을 달성하는 것이다. 구체적으로는, 프로세서는 양자화 대상 데이터의 데이터 변동폭을 통해 목표반복간격을 확정하여, 당해 목표반 복간격에 근거하여 신경망 연산 중의 양자화 파라미터를 조정한다. 바람직하게는, 당해 목표반복간격은 양자화 대상 데이터의 데이터 변동폭의 감소에 따라 증가할 수 있다. 즉, 당해 양자화 대상 데이터의 데이터 변동폭이 크면 클 수록 당해 목표반복간격이 작아지며, 양자화 파라미터의 조정이 빈번해 진다는 것을 나타낸다. 당해 양 자화 대상 데이터의 데이터 변동폭이 작으면 작을 수록 당해 목표반복간격이 커지며, 양자화 파라미터의 조정이 빈번하지 않은 것을 나타낸다. 물론, 다른 실시예에서, 상술한 목표반복간격은 하이퍼 파라미터일 수도 있다. 예를 들어, 당해 목표반복간격은 사용자 자신의 이해에 따라 설정될 수 있다. 바람직하게는, 상술한 가중치 데이터, 뉴런 데이터 및 그래디언트 데이터 등 각종 양자화 대상 데이터는 서로 다른 반복간격을 가질 수 있다. 이에 대응하여, 프로세서는 각종 양자화 대상 데이터에 대응하는 데이터 변동폭 을 각각 획득하여 각 종류의 양자화 대상 데이터의 데이터 변동폭에 근거하여 대응 종류의 양자화 대상 데이터 에 대응하는 목표반복간격을 각각 확정할 수 있다. 즉, 각종 양자화 대상 데이터의 양자화 과정은 비동기적으로 수행할 수 있다. 본 발명 실시예에서, 서로 다른 종류의 양자화 대상 데이터 사이에는 차이가 있어서, 서로 다 른 양자화 대상 데이터의 데이터 변동폭을 채용하여 대응하는 목표반복간격을 확정하고, 대응하는 목표반복간격 에 근거하여 대응하는 양자화 파라미터를 각각 확정할 수 있다. 따라서 양자화 대상 데이터의 양자화 정밀도를 보장하고, 신경망의 연산결과의 정확성도 보장할 수 있다. 물론, 다른 실시예에서, 서로 다른 종류의 양자화 대상 데이터에 대하여, 동일한 목표반복간격을 확정하여 당해 목표반복간격에 근거하여 대응하는 양자화 대상 데이터에 대응하는 양자화 파라미터를 조정할 수도 있다. 예를 들어, 프로세서는 각종 양자화 대상 데이터의 데이터 변동폭을 각각 획득하고, 최대의 양자화 대상 데이터의 데 이터 변동폭에 근거하여 목표반복간격을 확정하며, 당해 목표반복간격에 근거하여 각종 양자화 대상 데이터의 양자화 파라미터를 각각 확정할 수 있다. 또한, 서로 다른 종류의 양자화 대상 데이터는 동일한 양자화 파라미 터를 채용할 수도 있다. 더 바람직하게는, 상술한 신경망은 적어도 하나의 연산층을 포함할 수 있으며, 당해 양자화 대상 데이터는 각 연산층에 관련된 뉴런 데이터, 가중치 데이터 또는 그래디언트 데이터 중의 적어도 한 가지일 수 있다. 이 때, 프로세서는 현재 연산층에 관련된 양자화 대상 데이터를 획득하고, 상술한 방법에 따라 현재 연산층 중 각종 양 자화 대상 데이터의 데이터 변동폭 및 대응하는 목표반복간격을 확정할 수 있다. 바람직하게는, 프로세서는 매번 반복연산과정에서 모두 상술한 양자화 대상 데이터의 데이터 변동폭을 한번 확 정하고, 대응하는 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 한번 확정할 수 있다. 즉, 프로세서는 매번 반복할 때마다 목표반복간격을 한번 계산할 수 있다. 구체적인 목표반복간격의 계산방식은 다 음의 설명을 참조할 수 있다. 또한, 프로세서는 미리 설정된 조건에 따라 각 반복에서 검사 반복을 선정하고, 각 검사 반복에서 양자화 대상 데이터의 변동폭을 확정하며, 검사 반복에 대응하는 목표반복간격에 근거하여 양 자화 파라미터 등의 업데이트를 조정할 수 있다. 이 때, 당해 반복이 선정된 검사 반복이 아닌 경우, 프로세서 는 당해 반복에 대응하는 목표반복간격을 무시할 수 있다. 바람직하게는, 각 목표반복간격은 하나의 검사 반복에 대응할 수 있고, 당해 검사 반복은 당해 목표반복간격의 처음 반복일 수 있으며, 당해 목표반복간격의 종료 반복일 수도 있다. 프로세서는 각 목표반복간격의 검사 반복 에서 신경망의 양자화 파라미터를 조정하여 목표반복간격에 따른 신경망 연산의 양자화 파라미터의 조정을 실현 할 수 있다. 여기에서, 검사 반복은 현재 양자화 파라미터가 양자화 대상 데이터의 요구사항을 충족하는지 여부 를 검증하기 위한 시점일 수 있다. 당해 조정하기 전의 양자화 파라미터는 조정 후의 양자화 파라미터와 같을 수 있고, 조정 후의 양자화 파라미터와 다를 수도 있다. 바람직하게는, 인접하는 검사 반복 사이의 간격은 하나 의 목표반복간격 이상일 수 있다. 예를 들어, 당해 목표반복간격은 현재 검사 반복으로부터 반복회수를 계산할 수 있으며, 당해 현재 검사 반복은 당해 목표반복간격의 처음 반복일 수 있다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 프로세서가 양자화대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복간격이 3이면, 프로세서는 당해 목표반복 간격이 제100회 반복, 제101회 반복 및 제102회 반복의 3회 반복을 포함하는 것을 확정할 수 있다. 프로세서는 당해 제100회 반복에서 신경망 연산 중의 양자화 파라미터를 조정할 수 있다 . 여기에서, 현재 검사 반복은 프 로세서가 현재 양자화 파라미터 업데이트의 조정을 실행하는 경우에 대응하는 반복연산이다. 바람직하게는, 목표반복간격은 현재 검사 반복의 다음의 반복으로부터 계산하는 반복회수일 수도 있고, 당해 현 재 검사 반복은 현재 검사 반복 이전의 이전 반복간격의 종료 반복일 수 있다. 예를 들어, 현재 검사 반복이 제 100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복간격 이 3이면, 프로세서는 당해 목표반복간격이 제101회 반복, 제102회 반복 및 제103회 반복의 3회 반복을 포함하 는 것을 확정할 수 있다. 프로세서는 당해 제100회 반복과 제103회 반복에서 신경망 연산 중의 양자화 파라미터 를 조정할 수 있다 . 본 발명은 목표반복간격의 확정방식에 대하여 특히 한정하지 않는다. 일 실시예에서, 상술한 점 위치, 스케일 팩터 및 오프셋의 계산 수학식으로부터 알 수 있는 바와 같이, 양자화 파라미터는 종종 양자화 대상 데이터와 관련되며, 따라서, 상술한 작업(S100)에서, 양자화 대상 데이터의 데이 터 변동폭은 양자화 파라미터의 변동폭을 통해 간접적으로 확정할 수도 있고, 당해 양자화 대상 데이터의 데이 터 변동폭은 양자화 파라미터의 변동폭을 통해 특성화할 수 있다. 구체적으로는, 도3-6에 도시된 바와 같이, 상 술한 작업(S100)은 다음과 같은 단계를 포함할 수 있다. S110, 점 위치의 변동폭을 획득한다. 여기에서, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변 동폭을 특성화하는 데 사용할 수 있으며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭과 정의 상관이 있다. 바람직하게는, 점 위치의 변동폭은 간접적으로 양자화 대상 데이터의 변동폭을 반영할 수 있다. 당해 점 위치의 변동폭은 현재 검사 반복의 점 위치와 적어도 1회의 이력 반복의 점 위치에 의해 확정될 수 있다 . 여기에서, 현재 검사 반복의 점 위치 및 각회 이력 반복의 점 위치는 수학식（2）에 의해 확정할 수 있다. 물론, 현재 검 사 반복의 점 위치및 각회 이력 반복의 점 위치는 수학식（14）에 의해 확정할 수 있다. 예를 들어, 프로세서는 현재 검사 반복의 점 위치와 이력 반복의 점 위치의 분산 등을 계산하고, 당해 분산에 근거하여 점 위치의 변동폭을 확정할 수도 있다. 또한, 프로세서는 현재 검사 반복의 점 위치와 이력 반복의 점 위치의 평균치에 근거하여 점 위치의 변동폭을 확정할 수 있다. 구체적으로는, 도3-7에 도시된 바와 같이, 상술 한 작업(S110)은 다음과 같은 단계를 포함할 수 있다. S111, 상기 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복 에 대응하는 점 위치에 근거하여 제1 균치를 확정한다. 여기에서, 전회 검사 반복은 전회에서 상기 양자화 파라 미터를 조정하는 경우에 대응하는 반복이며, 전회 검사 반복과 상기 현재 검사 반복 사이에 적어도 하나의 반복 간격을 둔다. 바람직하게는, 적어도 1회 이력 반복은 적어도 하나의 반복간격에 각각 속할 수 있으며, 각 반복간격은 대응하 여 하나의 검사 반복이 있을 수 있고, 인접한 2개의 검사 반복은 하나의 반복간격을 가질 수 있다. 상술한 작업 (S111)중의 전회 검사 반복은 목표반복간격 전의 전회 반복간격에 대응하는 검사 반복일 수 있다. 바람직하게는, 당해 제1 균치는 다음과 같은 수학식에 따라 계산할 수 있다. 수학식（26） 여기에서, a1~am은 각 반복의 점 위치에 대응하는 계산 가중치이고, 는 전회 검사 반복에 대응하는 점 위치 이며, ... 는 전회 검사 반복 전의 이력 반복에 대응하는 점 위치이고, M1은 상술한 제1 균치이다. 또 한, 데이터의 분포특성에 따라, 이력 반복이 당해 전회 검사 반복에서 멀리 떨어질 수록 당해 전회 검사 반복의 근방의 반복의 점 위치의 분포 및 변동폭에 대한 영향이 작으며, 따라서, 상술한 계산 가중치는 a1~am의 순서에 따라 점차 작아질 수 있다. 예를 들어, 전회 검사 반복이 신경망 연산의 제100회 반복이고, 이력 반복이 제1회 반복부터 제99회 반복일 수 있으며, 프로세서는 당해 제100회 반복의 점 위치를 획득할 수 있고（즉 ）, 당해 제100회 반복 전의 이력 반복의 점 위치를 획득한다, 즉 는 신경망의 제1회 반복에 대응하는 점 위치일 수 있고......, 는 신경망의 제98회 반복에 대응하는 점 위치일 수 있으며, 는 신경망의 제99회 반복에 대응하는 점 위치일 수 있다. 또한, 프로세서는 상술한 수학식에 따라 계산을 통해 제1 균치를 획득할 수 있다. 또한, 당해 제1 균치는 각 반복간격에 대응하는 검사 반복의 점 위치에 근거하여 계산할 수 있다. 예를 들어, 당해 제1 균치는 다음과 같은 수학식에 따라 계산할 수 있다. ; 여기에서, a1~am은 각 검사 반복의 점 위치에 대응하는 계산 가중치이고, 는 전회 검사 반복에 대응하는 점 위치이며, ... 는 전회 검사 반복 전의 미리 설정된 수의 반복간격의 검사 반복에 대응하는 점 위치이 고, M1은 상술한 제1 균치이다. 예를 들어, 전회 검사 반복이 신경망 연산의 제100회 반복이고, 이력 반복이 제1회 반복부터 제99회 반복일 수 있으며, 당해 99회의 이력 반복은 11개의 반복간격에 각각 속할 수 있다. 예를 들어, 제1회 반복 내지 제9회 반 복은 첫 번째 반복간격에 속하고, 제10회 반복 내지 제18회 반복은 두 번째 반복간격에 속하며, ......, 제90회 반복 내지 제99회 반복은 열한 번째 반복간격에 속한다. 프로세서는 당해 제100회 반복의 점 위치를 획득할 수 있고（즉 ）, 당해 제100회 반복 전의 반복간격 중 검사 반복의 점 위치를 획득한다. 즉 는 신경망의 첫 번째 반복간격의 검사 반복에 대응하는 점 위치일 수 있고（예를 들어 는 신경망의 제1회 반복에 대응하는 점 위치일 수 있다）, ......, 는 신경망의 열 번째 반복간격의 검사 반복에 대응하는 점 위치일 수 있으며（예 를 들어 는 신경망의 제81회 반복에 대응하는 점 위치일 수 있다）, 는 신경망의 열한 번째 반복간격의 검사 반복에 대응하는 점 위치일 수 있다（예를 들어, 는 신경망의 제90회 반복에 대응하는 점 위치일 수 있 다）. 또한, 프로세서는 상술한 수학식에 따라 계산을 통해 제1 균치M1를 획득할 수 있다. 본 발명 실시예에서, 쉽게 예를 들어 설명하기 위해, 당해 반복간격에 포함된 반복회수가 같다고 가정한다. 그 러나 실제의 사용과정에서 당해 반복간격에 포함된 반복회수는 다를 수 있다. 바람직하게는, 당해 반복간격에 포함된 반복회수는 반복의 증가에 따라 증가된다, 즉 신경망 훈련 또는 미조정이 진행됨에 따라 반복간격은 갈 수록 커질 수 있다. 또한, 계산을 보다 단순화하고, 데이터가 점유하는 저장공간을 저감하기 위해, 상술한 제1 균치 M1은 다음과 같 은 수학식을 채용하여 계산할 수 있다: 수학식（27） 여기에서, 는 전회 검사 반복에 대응하는 점 위치의 계산 가중치이며, 는 전회 검사 반복에 대응하는 점 위 치이며, M0은 당해 전회 검사 반복 전의 검사 반복에 대응하는 이동평균 값이고, 당해 M0의 구체적 계산방식은 상술한 M1의 계산방식을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. S112, 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균치를 확정한다. 여기에서, 현재 검사 반복에 대응하는 점 위치는 현재 검사 반복의 목표데이터 비트폭과 양자 화 대상 데이터에 근거하여 확정할 수 있다. 바람직하게는, 당해 제2 균치M2는 다음과 같은 수학식에 따라 계산할 수 있다. 수학식（28） 여기에서, b1~bm은 각 반복의 점 위치에 대응하는 계산 가중치이고, 는 현재 검사 반복에 대응하는 점 위치이 며, ... 는 현재 검사 반복 전의 이력 반복에 대응하는 점 위치이고, M2는 상술한 제2 균치이다. 또한, 데이터의 분포특성에 따라 이력 반복이 당해 현재 검사 반복거리에서 멀리 떨어질 수록 당해 현재 검사 반복의 근방의 반복의 점 위치의 분포 및 변동폭에 대한 영향이 작아진다, 따라서, 상술한 계산 가중치는 b1~bm 의 순서에 따라 점차 작아질 수 있다. 예를 들어, 현재 검사 반복이 신경망 연산의 제101회 반복이면, 당해 현재 검사 반복 전의 이력 반복은 제1회 반복 내지 제100회 반복이다. 프로세서는 당해 제101회 반복의 점 위치를 획득할 수 있고（즉 ）, 또 당해 제 101회 반복 전의 이력 반복의 점 위치를 획득한다. 즉 는 신경망의 제1회 반복에 대응하는 점 위치일 수 있 고......, 는 신경망의 제99회 반복에 대응하는 점 위치일 수 있다, 는 신경망의 제100회 반복에 대응하 는 점 위치일 수 있다. 또한, 프로세서는 상술한 수학식에 따라 계산을 통해 제2 균치 M2를 획득할 수 있다. 바람직하게는, 당해 제2 균치는 각 반복간격에 대응하는 검사 반복의 점 위치에 근거하여 계산할 수 있다. 구체 적으로는, 도3-8에 도시된 바와 같이, 상술한 작업(S112)은 다음과 같은 작업을 포함할 수 있다: S1121, 미리 설정된 수의 중간 이동평균 값을 획득한다. 여기에서, 각 상기 중간 이동평균 값은 상기 현재 검사 반복하기 전 상기 미리 설정된 수의 검사 반복에 근거하여 확정되며, 상기 검사 반복은 상기 신경망 양자화 과 정에서의 파라미터를 조정하는 경우에 대응하는 반복이다. S1122, 상기 현재 검사 반복의 점 위치 및 상기 미리 설정된 수의 중간 이동평균 값에 근거하여 상기 제2 균치 를 확정한다. 예를 들어, 당해 제2 균치는 다음과 같은 수학식에 따라 계산할 수 있다: ; 여기에서, b1~bm은 각 반복의 점 위치에 대응하는 계산 가중치이고, 는 현재 검사 반복에 대응하는 점 위치이 며, ... 는 현재 검사 반복 전의 검사 반복에 대응하는 점 위치이고, M2는 상술한 제2 균치이다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 이력 반복이 제1회 반복부터 제99회 반복일 수 있으며, 당해 99회의 이력 반복은 11개의 반복간격에 각각 속할 수 있다. 예를 들어, 제1회 반복 내지 제9회 반복은 첫 번째 반복간격에 속하고, 제10회 반복 내지 제18회 반복은 두 번째 반복간격에 속하며, ......, 제90회 반복 내지 제 99회 반복은 열한 번째 반복간격에 속한다. 프로세서는 당해 제100회 반복의 점 위치를 획득할 수 있고（즉 ）, 당해 제100회 반복 전의 반복간격 중 검사 반복의 점 위치를 획득한다. 즉 는 신경망의 첫 번째 반복간 격의 검사 반복에 대응하는 점 위치일 수 있고（예를 들어 는 신경망의 제1회 반복에 대응하는 점 위치일 수 있 다）, ......, 는 신경망의 열 번째 반복간격의 검사 반복에 대응하는 점 위치일 수 있으며（예를 들어 는 신경망의 제81회 반복에 대응하는 점 위치일 수 있다）, 는 신경망의 열한 번째 반복간격의 검사 반복에 대응하는 점 위치일 수 있다（예를 들어, 는 신경망의 제90회 반복에 대응하는 점 위치일 수 있다）. 또한, 프로세서는 상술한 수학식에 따라 계산을 통해 제2 균치 M2를 획득할 수 있다. 본 발명 실시예에서, 쉽게 예를 들어 설명하기 위해, 당해 반복간격에 포함된 반복회수가 같다고 가정한다. 그 러나 실제의 사용과정에서 당해 반복간격에 포함된 반복회수는 다를 수 있다. 바람직하게는, 당해 반복간격에 포함된 반복회수는 반복의 증가에 따라 증가된다. 즉 신경망 훈련 또는 미조정이 진행됨에 따라 반복간격은 갈 수록 커질 수 있다. 또한, 계산을 단순화하고, 데이터가 점유하는 저장공간을 저감하기 위해, 프로세서는 상기 현재 검사 반복에 대 응하는 점 위치 및 상기 제1 균치에 근거하여 상기 제2 균치를 확정할 수 있다, 즉 상술한 제2 균치는 다음과 같은 수학식에 따라 계산할 수 있다. 수학식（29） 여기에서, 는 현재 검사 반복에 대응하는 점 위치의 계산 가중치이며, M1은 상술한 제1 균치이다. S113, 상기 제1 균치와 상기 제2 균치에 근거하여 제1 오차를 확정한다. 상기 제1 오차는 상기 현재 검사 반복 및 상기 이력 반복의 점 위치의 변동폭을 특성화하는 데 사용된다. 바람직하게는, 제1 오차는 제2 균치와 상술한 제1 균치 간의 차이 값의 절대치일 수 있다. 구체적으로는, 상술 한 제1 오차는 다음과 같은 수학식에 따라 계산할 수 있다. 수학식（30） 바람직하게는, 상술한 현재 검사 반복의 점 위치는 현재 검사 반복의 양자화 대상 데이터와 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여 확정할 수 있으며, 구체적인 점 위치 계산방식은 위의 수학식（2）또는 수학식（14）을 참조할 수 있다. 여기에서, 상술한 현재 검사 반복에 대응하는 목표데이터 비트폭은 하이퍼 파 라미터일 수도 있다. 더 바람직하게는, 당해 현재 검사 반복에 대응하는 목표데이터 비트폭은 사용자가 자신의 이해에 따라 입력한 것일 수 있다. 바람직하게는, 신경망 훈련 또는 미조정과정에서 양자화 대상 데이터에 대응 하는 데이터 비트폭은 일정할 수 있다. 즉 동일한 신경망의 같은 종류의 양자화 대상 데이터는 동일한 데이터 비트폭을 채용하여 양자화된다. 예를 들어, 당해 신경망에 대하여 각 반복 중의 뉴런 데이터는 모두 8비트의 데 이터 비트폭을 채용하여 양자화된다. 바람직하게는, 신경망 훈련 또는 미조정과정에서의 양자화 대상 데이터에 대응하는 데이터 비트폭은, 데이터 비 트폭이 양자화 대상 데이터의 양자화 요구사항을 충족시킬 수 있게 보장하기 위해 가변적이다. 즉, 프로세서는 양자화 대상 데이터에 근거하여 자기 적응적으로 당해 양자화 대상 데이터에 대응하는 데이터 비트폭을 조정하 여 당해 양자화 대상 데이터에 대응하는 목표데이터 비트폭을 획득할 수 있다. 구체적으로는, 프로세서는 먼저 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정할 수 있다. 그 다음에는, 프로세서는 당해 현재 검사 반 복에 대응하는 목표데이터 비트폭 및 당해 현재 검사 반복에 대응하는 양자화 대상 데이터에 근거하여 현재 검 사 반복에 대응하는 점 위치를 확정할 수 있다. 구체적으로는, 도3-9에 도시된 바와 같이, 상술한 작업(S110)은 다음과 같은작업을 포함할 수 있다. S114, 상기 현재 검사 반복의 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여 양자화 오차를 확정한다. 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 현재 검사 반복의 양자화 대상 데이 터에 대해 양자화하는 것을 통해 획득한다. 바람직하게는, 상술한 프로세서는 초기 데이터 비트폭을 채용하여 양자화 대상 데이터를 양자화하며, 상술한 양 자화 데이터를 획득할 수 있다. 당해 현재 검사 반복의 초기 데이터 비트폭은 하이퍼 파라미터일 수도 있고, 당 해 현재 검사 반복의 초기 데이터 비트폭은 당해 현재 검사 반복하기 전의 이전 검사 반복의 양자화 대상 데이 터에 근거하여 확정될 수도 있다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이터와 현재 검사 반복의 양자화 데이터에 근거하여 중간표현 데이터를 확정할 수 있다. 바람직하게는, 상기 중간표현 데이터는 상술한 양자화 대상 데이터의 표현 형식과 일치하다. 예를 들어, 프로세서는 상술한 양자화 데이터에 대해 역 양자화를 수행하여 양자화 대상 데이 터의 표현형식과 이치한 중간표현 데이터를 획득할 수 있다, 여기에서, 역 양자화는 양자화의 반대과정을 의미 한다. 예를 들어, 당해 양자화 데이터는 상술한 수학식（3）을 채용하여 획득할 수 있고, 프로세서는 상술한 수 학식（4）에 따라 양자화 데이터를 역 양자화하여 대응하는의 중간표현 데이터를 획득할 수 있으며, 양자화 대 상 데이터와 중간표현 데이터에 근거하여 양자화 오차를 확정할 수 있다. 또한, 프로세서는 양자화 대상 데이터 및 그에 대응하는 중간표현 데이터에 근거하여 계산을 통해 양자화 오차 를 획득할 수 있다. 현재 검사 반복의 양자화 대상 데이터가 =[ ]이면, 당해 양자화 대상 데이터에 대응하는 중간표현 데이터는 =[ ]이다. 프로세서는 당해 양자화 대상 데이터 및 그에 대응 하는 중간표현 데이터 에 근거하여 오차항을 확정하고, 당해 오차항에 근거하여 양자화 오차를 확정할 수 있다. 바람직하게는, 프로세서는 중간표현 데이터 중 각 요소의 합, 및 양자화 대상 데이터 중 각 요소의 합에 근 거하여 상술한 오차항을 확정할 수 있으며, 당해 오차항은 중간표현 데이터 중 각 요소의 합과 양자화 대상 데이터 중 각 요소의 합의 차이 값일 수 있다. 그 다음에는, 프로세서는 당해 오차항에 근거하여 양자화 오차 를 확정할 수 있다. 구체적인 양자화 오차는 다음과 같은 수학식에 따라 확정할 수 있다. 수학식（31） 여기에서, 는 양자화 대상 데이터 중의 요소이고, 는 중간표현 데이터 의 요소이다. 바람직하게는, 프로세서는 양자화 대상 데이터 중 각 요소와 중간표현 데이터 중 대응하는 요소의 차이 값을 각각 계산하여, m 개의 차이 값을 얻고, 당해 m 개의 차이 값의 합을 오차항으로 할 수 있다. 그 다음에는, 프 로세서는 당해 오차항에 근거하여 양자화 오차를 확정할 수 있다. 구체적인 양자화 오차는 다음과 같은 수학식 에 따라 확정할 수 있다. 수학식（32） 여기에서, 는 양자화 대상 데이터 중의 요소이고, 는 중간표현 데이터 의 요소이다. 바람직하게는, 상술한 양자화 대상 데이터 중 각 요소와 중간표현 데이터 중 대응하는 요소의 차이 값은 대략 과 같을 수 있다. 따라서, 상술한 양자화 오차는 다음과 같은 수학식에 따라 확정할 수도 있다. 수학식（33） 여기에서, m는 목표데이터에 대응하는 중간표현 데이터 의 수이고, s는 점 위치이며, 는 양자화 대상 데이터 중의 요소이다. 바람직하게는, 상기 중간표현 데이터는 상술한 양자화 데이터의 데이터 표현형식과 일치하고, 당해 중간표현 데 이터와 양자화 데이터에 근거하여 양자화 오차를 확정할 수도 있다. 예를 들어, 양자화 대상 데이터는 로 표현할 수 있고, 중간표현 데이터 임을 확정할 수 있으며, 당해 중간표현 데이터 은 상술 한 양자화 데이터와 동일한 데이터 표현형식일 수 있다. 이 때 프로세서는 중간표현 데이터 과 상술한 수학식 （3）에 의해 계산하여 획득한 에 근거하여 양자화 오차를 확정할 수 있다. 구체적인 양자화 오 차의 확정방식은 상술한 수학식（31）~수학식（33）을 참조할 수 있다. S115, 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정한다. 구체적으로는, 프로세서는 당해 양자화 오차에 근거하여, 자기 적응적으로 현재 검사 반복에 대응하는 데이터 비트폭을 조정하여 당해 현재 검사 반복이 조정된 후의 목표데이터 비트폭을 확정할 수 있다. 당해 양자화 오차 가 미리 설정된 조건을 충족하는 경우, 현재 검사 반복에 대응하는 데이터 비트폭을 변하지 않도록 유지할 수 있다. 즉 당해 현재 검사 반복의 목표데이터 비트폭은 초기 데이터 비트폭과 같을 수 있다. 양자화 오차가 미리 설정된 조건을 충족하지 않는 경우, 프로세서는 현재 검사 반복의 양자화 대상 데이터에 대응하는 데이터 비트 폭을 조정하여 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득할 수 있다. 프로세서가 당해 목표데이터 비트폭을 채용하여 현재 검사 반복의 양자화 대상 데이터를 양자화할 때 양자화 오차가 상술한 미리 설정된 조 건을 충족한다. 바람직하게는, 상술한 미리 설정된 조건은 사용자가 설정한 미리 설정한 한계 값이여도 좋다. 바람직하게는, 도3-10에 도시된 바와 같이, 상술한 작업(S115)은 다음과 같은 단계를 포함할 수 있다. S1150, 프로세서는 상술한 양자화 오차가 제1 미리 설정된 한계 값 이상인지 판정할 수 있다. 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 작업(S1151)을 수행하여 상기 현재 검사 반복에 대응하 는 데이터 비트폭을 증가시켜 현재 검사 반복의 목표데이터 비트폭을 획득할 수 있다. 양자화 오차가 제1 미리 설정된 한계 값보다도 작으면, 현재 검사 반복의 데이터 비트폭을 변하지 않도록 유지할 수 있다. 더 바람직하게는, 프로세서는 1회 조정을 경유하여 상술한 목표데이터 비트폭을 획득할 수 있다. 예를 들어, 현 재 검사 반복의 초기 데이터 비트폭이 n1인 경우, 프로세서는 1회 조정을 경유하여 당해 목표데이터 비트폭 n2=n1+t를 확정할 수 있다. 여기에서, t는 데이터 비트폭의 조정 값이다. 여기에서, 당해 목표데이터 비트폭 n2 를 채용하여 현재 검사 반복의 양자화 대상 데이터를 양자화할 때, 획득한 양자화 오차는 상기 제1 미리 설정된 한계 값보다도 작을 수 있다. 더 바람직하게는, 프로세서는 양자화 오차가 제1 미리 설정된 한계 값 미만이 될 때까지 여러 번의 조정을 경유 하여 목표데이터 비트폭을 획득하고, 당해 양자화 오차가 제1 미리 설정된 한계 값 미만인 경우 데이터 비트폭 을 목표데이터 비트폭으로 할 수 있다. 구체적으로는, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 제1 미리 설정된 비트폭 스텝에 근거하여 제1 중간 데이터 비트폭을 확정하며; 그 다음에 프로세서는 당해 제1 중간 데이터 비트폭에 근거하여 현재 검사 반복의 양자화 대상 데이터를 양자화하여 양자화 데이터를 획득하고, 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제1 미리 설정된 한계 값 미만이 될 때까지 양자화 오차를 확정할 수 있다. 프로세서는 당해 양자 화 오차가 제1 미리 설정된 한계 값 미만인 경우에 대응하는 데이터 비트폭을 당해 목표데이터 비트폭으로 할 수 있다. 예를 들어, 현재 검사 반복의 초기 데이터 비트폭이 n1인 경우, 프로세서는 당해 초기 데이터 비트폭 n1을 채용 하여 현재 검사 반복의 양자화 대상 데이터 A를 양자화하여 양자화 데이터 B1을 획득하고, 당해 양자화 대상 데 이터 A와 양자화 데이터 B1에 근거하여 계산을 통해 양자화 오차 C1을 획득할 수 있다. 양자화 오차 C1이 제1 미리 설정된 한계 값 이상인 경우, 프로세서확정제1 중간 데이터 비트폭n2=n1+t1, 여기에서, t1은 제1 미리 설 정된 비트폭 스텝이다. 그 다음에는, 프로세서는 당해 제1 중간 데이터 비트폭 n2에 근거하여 현재 검사 반복의 양자화 대상 데이터를 양자화하여 현재 검사 반복의 양자화 데이터 B2를 획득하고, 당해 양자화 대상 데이터 A 와 양자화 데이터 B2에 근거하여 계산을 통해 양자화 오차 C2를 획득할 수 있다. 당해 양자화 오차 C2가 제1 미 리 설정된 한계 값 이상인 경우, 프로세서확정제1 중간 데이터 비트폭n2=n1+t1+t1, 그 다음에는 당해 새로운 제 1 중간 데이터 비트폭에 근거하여 현재 검사 반복의 양자화 대상 데이터 A를 양자화하고, 양자화 오차가 제1 미 리 설정된 한계 값 미만이 될 때까지 대응하는 양자화 오차를 계산한다. 양자화 오차 C1이 제1 미리 설정된 한 계 값 미만이면, 당해 초기 데이터 비트폭 n1을 변하지 않도록 유지할 수 있다. 또한, 상술한 제1 미리 설정된 비트폭 스텝은 일정한 값일 수 있다. 예를 들어, 양자화 오차가 제1 미리 설정된 한계 값보다도 클 때 마다, 프로세서는 현재 검사 반복에 대응하는 데이터 비트폭을 같은 비트폭 값 만큼 증가 시킬 수 있다. 바람직하게는, 상술한 제1 미리 설정된 비트폭 스텝은 가변 값일 수도 있다. 예를 들어, 프로세 서는 양자화 오차와 제1 미리 설정된 한계 값의 차이 값을 계산할 수 있다. 당해 양자화 오차와 제1 미리 설정 된 한계 값의 차이 값이 작으면 작을 수록 제1 미리 설정된 비트폭 스텝의 값이 작아진다. 바람직하게는, 도3-11에 도시된 바와 같이, 상술한 작업(S115)은 다음과 같은 단계를 포함할 수 있다. S1152, 프로세서는 상술한 양자화 오차가 제1 미리 설정된 한계 값 이하인지 여부를 판정할 수 있다. 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 작업(S1153)을 실행할 수 있으며, 상기 현재 검사 반복 에 대응하는 데이터 비트폭을 감소하여 현재 검사 반복의 목표데이터 비트폭을 획득한다. 양자화 오차가 제2 미 리 설정된 한계 값보다도 클 경우, 현재 검사 반복의 데이터 비트폭을 변하지 않도록 유지할 수 있다. 더 바람직하게는, 프로세서는 1회 조정을 경유하여 상술한 목표데이터 비트폭을 획득할 수 있다. 예를 들어, 현 재 검사 반복의 초기 데이터 비트폭이 n1인 경우, 프로세서는 1회 조정을 경유하여 당해 목표데이터 비트폭 n2=n1-t를 확정할 수 있다, 여기에서, t는 데이터 비트폭의 조정 값이다. 여기에서, 당해 목표데이터 비트폭 n2 를 채용하여 현재 검사 반복의 양자화 대상 데이터를 양자화할 때, 획득한 양자화 오차가 상기 제2 미리 설정된 한계 값보다도 클 수 있다. 더 바람직하게는, 프로세서는 양자화 오차가 제2 미리 설정된 한계 값보다 클 때까지 여러 번 조정을 통해 목표 데이터 비트폭을 획득하고 , 당해 양자화 오차가 제2 미리 설정된 한계 값보다 클 때의 데이터 비트폭을 목표데 이터 비트폭으로 할 수 있다. 구체적으로는, 상기 양자화 오차가 제1 미리 설정된 한계 값 이하이면, 제2 미리 설정된 비트폭 스텝에 의해 제2 중간 데이터 비트폭을 확정한다. 그 다음에는 프로세서는 당해 제2 중간 데이터 비트폭에 근거하여 현재 검사 반복의 양자화 대상 데이터를 양자화하여 양자화 데이터를 획득하고, 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상 기 제2 미리 설정된 한계 값보다 클 때까지 양자화 오차를 확정할 수 있다. 프로세서는 당해 양자화 오차가 제2 미리 설정된 한계 값보다 큰 경우에 대응하는 데이터 비트폭을 당해 목표데이터 비트폭으로 할 수 있다. 예를 들어, 현재 검사 반복의 초기 데이터 비트폭이 n1인 경우, 프로세서는 당해 초기 데이터 비트폭 n1을 채용 하여 현재 검사 반복의 양자화 대상 데이터 A를 양자화하여 양자화 데이터 B1을 획득하고, 당해 양자화 대상 데 이터 A와 양자화 데이터 B1에 근거하여 계산을 통해 양자화 오차 C1을 획득할 수 있다. 양자화 오차 C1이 제2 미리 설정된 한계 값 이하인 겨우, 프로세서는 제2 중간 데이터 비트폭 n2=n1-t2를 확정한다. 여기에서, t2는 제2 미리 설정된 비트폭 스텝이다. 그 다음에는, 프로세서는 당해 제2 중간 데이터 비트폭 n2에 근거하여 현재검사 반복의 양자화 대상 데이터를 양자화하여 현재 검사 반복의 양자화 데이터 B2를 획득하고, 당해 양자화 대 상 데이터 A와 양자화 데이터 B2에 근거하여 계산을 통해 양자화 오차 C2를 획득할 수 있다. 당해 양자화 오차 C2가 제2 미리 설정된 한계 값 이하인 경우, 프로세서는 제2 중간 데이터 비트폭 n2=n1-t2-t2를 확정한다, 그 다음에는 당해 새로운 제2 중간 데이터 비트폭에 근거하여 현재 검사 반복의 양자화 대상 데이터 A를 양자화하 며, 양자화 오차가 제2 미리 설정된 한계 값보다 클 때까지 대응하는 양자화 오차를 계산한다. 양자화 오차 C1 이 제2 미리 설정된 한계 값보다 크면, 당해 초기 데이터 비트폭 n1을 변하지 않도록 유지할 수 있다. 또한, 상술한 제2 미리 설정된 비트폭 스텝은 일정한 값일 수 있다. 예를 들어, 양자화 오차가 제2 미리 설정된 한계 값 미만인 경우, 프로세서는 현재 검사 반복에 대응하는 데이터 비트폭을 동일한 비트폭 값으로 감소시킬 수 있다. 바람직하게는, 상술한 제2 미리 설정된 비트폭 스텝은 가변 값일 수도 있다. 예를 들어, 프로세서는 양자화 오차와 제2 미리 설정된 한계 값의 차이 값을 계산할 수 있다. 당해 양자화 오차와 제2 미리 설정된 한 계 값의 차이 값이 작으면 작을 수록 제2 미리 설정된 비트폭 스텝의 값은 작아진다. 바람직하게는, 도3-12에 도시된 바와 같이, 프로세서는 양자화 오차가 제1 미리 설정된 한계 값보다 작고, 또 양자화 오차가 제2 미리 설정된 한계 값보다 큼을 확정한 경우, 현재 검사 반복의 데이터 비트폭이 변하지 않도 록 유지할 수 있다. 여기에서, 제1 미리 설정된 한계 값은 제2 미리 설정된 한계 값보다 크다. 즉 현재 검사 반 복의 목표데이터 비트폭은 초기 데이터 비트폭과 같을 수 있다. 여기에서, 도3-12에서는 예시적인 방식으로만 본 발명의 일 실시예의 데이터 비트폭 확정방식을 설명하며, 도3-12에서의 각 작업의 순서는 적응성에 따라 조 정할 수 있으므로 여기에서는 구체적으로 한정하지 않는다. 본 발명 실시예에서, 현재 검사 반복의 데이터 비트폭이 변화될 때, 점 위치는 그에 따라 변화된다. 이 때 점 위치의 변화는 양자화 대상 데이터의 데이터 변동에 의해 초래된 것이 아니며, 상술한 수학식（30）에 의해 확 정된 제1 오차에 근거하여 계산을 통해 획득한 목표반복간격은 정확하지 않을 가능성이 있으며, 따라서 양자화 의 정밀도에 영향을 줄 수 있다. 따라서, 현재 검사 반복의 데이터 비트폭이 변화될 때, 상술한 제2 균치를 그 것에 따라 조정하여 제1 오차가 점 위치의 변동폭을 정확하게 반영할 수 있게 보장할 수 있으며, 진일보로 목표 반복간격의 정확성과 신뢰성을 보장하게 할 수 있다. 구체적으로는, 도3-13에 도시된 바와 같이, 상술한 방법은 다음과 같은 단계를 포함할 수 있다. S116, 상기 목표데이터 비트폭에 근거하여 상기 현재 검사 반복의 데이터 비트폭 조정 값을 확정한다. 구체적으로는, 프로세서는 현재 검사 반복의 목표데이터 비트폭과 초기 데이터 비트폭에 근거하여 현재 검사 반 복의 데이터 비트폭 조정 값을 확정한다. 여기에서, 당해 데이터 비트폭 조정 값=목표데이터 비트폭-초기 데이 터 비트폭이다. 물론, 프로세서는 현재 검사 반복의 데이터 비트폭 조정 값을 직접 획득할 수 있다. S117, 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상술한 제2 균치를 업데이트한다. 구체적으로는, 데이터 비트폭 조정 값이 미리 설정된 파라미터（예를 들어, 당해 미리 설정된 파라미터는 령일 수 있다）보다 클 경우, 즉 현재 검사 반복의 데이터 비트폭이 증가될 때, 프로세서는 이에 대응하여 제2 균치 를 감소할 수 있다. 데이터 비트폭 조정 값이 미리 설정된 파라미터（예를 들어, 당해 미리 설정된 파라미터는 령일 수 있다）보다 작은 경우, 즉 현재 검사 반복의 데이터 비트폭이 감소될 때, 프로세서는 이에 대응하여 제 2 균치를 증가시킬 수 있다. 데이터 비트폭 조정 값이 미리 설정된 파라미터와 같은 경우, 즉 데이터 비트폭 조 정 값이 0인 경우, 이 때 현재 반복에 대응하는 양자화 대상 데이터에 변경이 없으면, 업데이트 후의 제2 균치 는 업데이트하기 전의 제2 균치와 같으며, 당해 업데이트하기 전의 제2 균치는 상술한 수학식（29）에 의해 계 산하여 획득한다. 바람직하게는, 데이터 비트폭 조정 값이 미리 설정된 파라미터와 같은 경우, 즉 데이터 비트 폭 조정 값이 0인 경우, 프로세서는 제2 균치를 업데이트하지 않는다. 즉 프로세서는 상술한 작업(S117)을 실행 하지 않을 수 있다. 예를 들어, 업데이트하기 전의 제2 균치 이고; 현재 검사 반복에 대응하는 목표데이터 비트폭n2=초기 데이터 비트폭n1+ 인 경우, 여기에서, 은 데이터 비트폭 조정 값을 표현한다. 이 때, 업데이 트 후의 제2 균치 이다. 현재 검사 반복에 대응하는 목표데이터 비 트폭n2=초기 데이터 비트폭n1- 인 경우, 여기에서, 은 데이터 비트폭 조정 값을 표현하며, 이 때, 업데이트 후의 제2 균치 이고, 여기에서, 는 현재 검사 반복이 목표데이터비트폭에 근거하여 확정한 점 위치이다. 또한, 업데이트하기 전의 제2 균치 이고; 현재 검사 반복에 대응하는 목표데이터 비트 폭n2=초기 데이터 비트폭n1+ 인 경우, 여기에서, 은 데이터 비트폭 조정 값을 표현한다. 이 때, 업데이트 후의 제2 균치 이다. 또한, 현재 검사 반복에 대응하는 목표데이터 비트폭n2=초기 데이터 비트폭n1- 인 경우, 여기에서, 은 데이터 비트폭 조정 값을 표현하며, 이 때, 업데이트 후의 제2 균 치 이고, 여기에서, 는 현재 검사 반복이 목표데이터 비트폭에 근거하여 확정한 점 위치이다. 또한, 도3-6에 도시된 바와 같이, 상술한 작업(S200)은 다음과 같은 단계를 포함할 수 있다. S210, 점 위치의 변동폭에 근거하여 목표반복간격을 확정할 수 있다. 여기에서, 당해 목표반복간격은 상술한 점 위치의 변동폭과 부의 상관이 있다. 즉 상술한 점 위치의 변동폭이 크면 클 수록, 당해 목표반복간격이 작아 진 다. 상술한 점 위치의 변동폭이 작으면 작을 수록 당해 목표반복간격이 크다. 상술한 바와 같이, 상술한 제1 오차는 점 위치의 변동폭을 특성화할 수 있다. 따라서, 도3-7에 도시된 바와 같 이, 상술한 작업(S210)은 다음과 같은 단계를 포함할 수 있다. S211, 프로세서는 상기 제1 오차에 근거하여 상기 목표반복간격을 확정할 수 있으며, 여기에서, 목표반복간격은 상기 제1 오차와 부의 상관이 있다. 즉 제1 오차가 클 수록 점 위치의 변화 폭이 크며, 진일보로 양자화 대상 데이터의 데이터 변동폭이 크다는 것을 설명하며, 이 때, 목표반복간격이 작아진다. 구체적으로는, 프로세서는 이하의 수학식에 따라 계산을 통해 목표반복간격 을 얻는다. 수학식（31） 여기에서, I는 목표반복간격이고, 는 상술한 제1 오차를 나타내며, 는 하이퍼 파라미터일 수 있다. 또한, 제1 오차는 점 위치의 변동폭을 가늠하는 데 사용되며, 제1 오차가 클 수록 점 위치의 변동폭이 크고, 진 일보로 양자화 대상 데이터의 데이터 변동폭이 큰 것을 나타내며, 목표반복간격을 작게 설정할 필요가 있는 것 을 이해해야 한다. 즉, 제1 오차가 클 수록 빈번하게 양자화 파라미터를 조정한다. 본 실시예에서, 점 위치의 변동폭（제1 오차）을 계산함으로써, 점 위치의 변동폭에 근거하여 목표반복간격을 확정한다. 양자화 파라미터는 목표반복간격에 근거하여 확정되기 때문에, 양자화 파라미터에 근거하여 양자화하 여 얻은 양자화 데이터를 목표데이터의 점 위치의 변동추세에 보다 부합되도록 할 수 있고, 양자화 정밀도를 보 장함과 동시에 신경망의 가동효율을 향상시킬 수 있다. 바람직하게는, 프로세서는 현재 검사 반복에서 목표반복간격을 확정한 후, 현재 검사 반복에서 목표반복간격에 대응하는 양자화 파라미터와 데이터 비트폭등 파라미터를 더 확정하여 목표반복간격에 근거하여 양자화 파라미 터를 업데이트할 수 있다. 여기에서, 양자화 파라미터는 점 위치 및/또는 스케일 팩터를 포함할 수 있다. 또한, 당해 양자화 파라미터는 오프셋을 포함할 수 있다. 당해 양자화 파라미터의 구체적 계산방식은 위의 설명을 참 조할 수 있다. 도3-14에 도시된 바와 같이, 상술한 방법은 다음과 같은 단계를 포함할 수 있다. S300, 프로세서는 목표반복간격에 근거하여 신경망 연산 중의 양자화 파라미터를 조정한다 . 구체적으로는, 프로세서는 목표반복간격에 근거하여 검사 반복을 확정하고, 각 검사 반복에서 목표반복간격을 업데이트할 수 있으며, 각 검사 반복에서 양자화 파라미터를 업데이트할 수도 있다. 예를 들어, 신경망 연산에 서 데이터 비트폭을 변하지 않게 유지하며, 이 때, 프로세서는 각 검사 반복에서 직접 검사 반복의 양자화 대상 데이터에 근거하여 점 위치 등 양자화 파라미터를 조정할 수 있다. 또한, 신경망 연산에서 데이터 비트폭은 가 변적이며, 이 때, 프로세서는 각 검사 반복에서 데이터 비트폭을 업데이트하고, 업데이트 후의 데이터 비트폭과 당해 검사 반복의 양자화 대상 데이터에 근거하여 점 위치 등 양자화 파라미터를 조정할 수 있다. 본 발명 실시예에서, 프로세서는 각 검사 반복에서 양자화 파라미터를 업데이트하여 현재 양자화 파라미터가 양 자화 대상 데이터의 양자화 요구사항을 충족하도록 보장한다. 여기에서, 업데이트하기 전의 목표반복간격과 업 데이트 후의 목표반복간격은 같을 수도 다를 수도 있다. 업데이트하기 전의 데이터 비트폭과 업데이트 후의 데 이터 비트폭은 같을 수도 다를 수도 있다. 즉 상이한 반복간격의 데이터 비트폭은 같을 수도 다를 수도 있다. 업데이트하기 전의 양자화 파라미터와 업데이트 후의 양자화 파라미터는 같을 수도 다를 수도 있다. 즉 상이한 반복간격의 양자화 파라미터는 같을 수도 다를 수도 있다. 바람직하게는, 상술한 작업(S300)에서, 프로세서는 검사 반복에서 목표반복간격 중의 양자화 파라미터를 확정하 여 신경망 연산에서의 양자화 파라미터를 조정할 수 있다. 한 가지 상황에서, 당해 신경망 연산에서 각 반복에 대응하는 데이터 비트폭은 모두 변화하지 않는다. 즉 당해 신경망 연산에서 각 반복에 대응하는 데이터 비트폭은 모두 같으며, 이 때, 프로세서는 목표반복간격에서의 점 위치 등 양자화 파라미터를 확정하여 목표반복간격에 근거한 신경망 연산에서의 양자화 파라미터의 조정 목적을 실현할 수 있다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 양자화 파라미터는 일치할 수 있다. 즉, 목 표반복간격 중의 각 반복은 모두 동일한 점 위치를 채용하며, 각 검사 반복에서만 점 위치 등 양자화 파라미터 를 업데이트 및 확정한다. 따라서 매번 반복에서 모두 양자화 파라미터를 업데이트하여 조정하는 것을 회피하고, 양자화 과정에서의 계산량을 삭감하며, 양자화 작업의 효율을 향상시킬 수 있다. 바람직하게는, 상술한 데이터 비트폭이 변하지 않는 경우에 대하여, 목표반복간격 중 반복에 대응하는 점 위치 는 일치하게 유지할 수 있다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이터와 당해 현재 검 사 반복에 대응하는 목표데이터 비트폭에 근거하여, 현재 검사 반복에 대응하는 점 위치를 확정하고, 당해 현재 검사 반복에 대응하는 점 위치를 당해 목표반복간격에 대응하는 점 위치로 할 수 있으며, 당해 목표반복간격 중 반복은 모두 현재 검사 반복에 대응하는 점 위치를 계속 사용한다. 바람직하게는, 당해 현재 검사 반복에 대응 하는 목표데이터 비트폭은 하이퍼 파라미터일 수도 있다. 예를 들어, 당해 현재 검사 반복에 대응하는 목표데이 터 비트폭은 사용자가 이해에 의해 입력한 것이다. 당해 현재 검사 반복에 대응하는 점 위치는 위의 수학식（2 ） 또는 수학식（14）를 참조하여 계산할 수 있다. 한 가지 상황에서, 당해 신경망 연산에서의 각 반복에 대응하는 데이터 비트폭은 변화할 수 있다. 즉 상이한 목 표반복간격에 대응하는 데이터 비트폭은 일치하지 않아도 되지만, 목표반복간격 중 각 반복의 데이터 비트폭은 변하지 않도록 유지된다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 데이터 비트폭은 하이퍼 파라미터일 수도 있다. 예를 들어, 당해 목표반복간격 중 반복에 대응하는 데이터 비트폭은 사용자가 자신의 이해에 따라 입력한 것일 수 있다. 한 가지 상황에서, 당해 목표반복간격 중 반복에 대응하는 데이터 비트폭은 프로세서가 계산하여 획득한 것일 수도 있다. 예를 들어, 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 현 재 검사 반복에 대응하는 목표데이터 비트폭을 확정하고, 당해 현재 검사 반복에 대응하는 목표데이터 비트폭을 목표반복간격에 대응하는 데이터 비트폭으로 할 수 있다. 이 때, 양자화 과정에서의 계산량을 단순화하기 위해, 당해 목표반복간격에서 대응하는 점 위치 등 양자화 파라 미터는 변하지 않도록 유지할 수도 있다. 즉, 목표반복간격 중의 각 반복은 모두 동일한 점 위치를 채용하며, 각 검사 반복에서만 점 위치 등 양자화 파라미터 및 데이터 비트폭을 업데이트 및 확정한다. 따라서 매번 반복 에서 모두 양자화 파라미터를 업데이트하여 조정하는 것을 회피하고, 양자화 과정에서의 계산량을 삭감하며, 양 자화 작업의 효율을 향상시킬 수 있다. 바람직하게는, 상술한 목표반복간격에 대응하는 데이터 비트폭이 변하지 않는 경우에 대하여, 목표반복간격 중 반복에 대응하는 점 위치는 일치하게 유지할 수 있다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이터와 당해 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여, 현재 검사 반복에 대응하는 점 위치 를 확정하고, 당해 현재 검사 반복에 대응하는 점 위치를 당해 목표반복간격에 대응하는 점 위치로 할 수 있으 며, 당해 목표반복간격 중 반복은 모두 현재 검사 반복에 대응하는 점 위치를 계속 사용한다. 바람직하게는, 당 해 현재 검사 반복에 대응하는 목표데이터 비트폭은 하이퍼 파라미터일 수도 있다. 예를 들어, 당해 현재 검사 반복에 대응하는 목표데이터 비트폭은 사용자가 이해에 의해 입력한 것이다. 당해 현재 검사 반복에 대응하는 점 위치는 위의 수학식（2） 또는 수학식（14）을 참조하여 계산할 수 있다. 바람직하게는, 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치할 수 있다. 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 현재 검사 반복에 대응하는 스케일 팩터를 확정하고, 당해 현재 검사 반복에 대 응하는 스케일 팩터을 목표반복간격 중 각 반복의 스케일 팩터로 할 수 있다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치하다. 바람직하게는, 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 현재 검사 반복에 대응하는 오프셋을 확정하며, 당해 현재 검사 반복에 대응하는 오프셋을 목표반복간격 중 각 반복의 오프셋으로 할 수 있다. 또한, 프로세서는 양자화 대상 데이터의 모든 요소 중 최소 값과 최대 값을 확정하고, 진일보로 점 위치와 스케일 팩터 등 양자화 파라미터를 확정할 수 있으며, 상세에 대 해서는 위의 설명을 참조할 수 있다. 당해 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 예를 들어, 당해 목표반복간격은 현재 검사 반복부터 반복회수를 계산할 수 있다, 즉 목표반복간격에 대응하는 검사 반복은 목표반복간격의 처음 반복일 수 있다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복간격이 3이면, 프로세서는 당해 목 표반복간격이 제100회 반복, 제101회 반복 및 제102회 반복의 3회 반복을 포함하는 것을 확정할 수 있다. 또한 프로세서는 제100회 반복에 대응하는 양자화 대상 데이터와 목표데이터 비트폭에 근거하여, 당해 제100회 반복 에 대응하는 점 위치 등 양자화 파라미터를 확정할 수 있고, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 채용하여 제100회 반복, 제101회 반복 및 제102회 반복을 양자화할 수 있다. 이러한 방식으로, 프로 세서는 제101회 반복과 제102회 반복에서 점 위치 등 양자화 파라미터을 계산할 필요가 없으며, 양자화 과정에 서의 계산량을 삭감하여 양자화 작업의 효율을 향상시킨다. 바람직하게는, 목표반복간격은 현재 검사 반복의 다음의 반복으로부터 계산하는 반복회수일 수도 있고, 즉 당해 목표반복간격에 대응하는 검사 반복은 당해 목표반복간격의 종료 반복일 수도 있다. 예를 들어, 현재 검사 반복 이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복 간격이 3이면. 프로세서는 당해 목표반복간격이 제101회 반복, 제102회 반복 및 제103회 반복의 3회 반복을 포 함하는 것을 확정할 수 있다. 따라서 프로세서는 제100회 반복에 대응하는 양자화 대상 데이터와 목표데이터 비 트폭에 근거하여, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 확정할 수 있고, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 채용하여 제101회 반복, 제102회 반복 및 제103회 반복을 양자 화할 수 있다. 이러한 방식으로, 프로세서는 제102회 반복과 제103회 반복에서 점 위치 등 양자화 파라미터를 계산할 필요가 없으며, 양자화 과정에서의 계산량을 삭감하여 양자화 작업의 효율을 향상시킨다. 본 발명 실시예에서, 동일한 목표반복간격 중 각 반복에 대응하는 데이터 비트폭 및 양자화 파라미터 모두 일치 하다. 즉 동일한 목표반복간격 중 각 반복에 대응하는 데이터 비트폭, 점 위치, 스케일 팩터 및 오프셋은 모두 변하지 않도록 유지되며, 신경망의 훈련 또는 미조정과정에서 양자화 대상 데이터의 양자화 파라미터를 빈번하 게 조정하는 것을 회피할 있고 , 양자화 과정에서의 계산량을 삭감하여 양자화 효율을 향상시킬 수 있다. 또한, 훈련 또는 미조정의 상이한 단계에서 데이터 변동폭에 근거하여 동적으로 양자화 파라미터를 조정함으로써 양자 화 정밀도를 보장할 수 있다. 다른 상황에서, 당해 신경망 연산에서의 각 반복에 대응하는 데이터 비트폭은 변화할 수 있으나 목표반복간격 중 각 반복의 데이터 비트폭은 변하지 않게 유지된다. 이 때, 목표반복간격 중 반복에 대응하는 점 위치 등 양 자화 파라미터는 일치하지 않을 수도 있다. 프로세서는 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하 여 목표반복간격에 대응하는 데이터 비트폭을 확정할 수도 있다. 여기에서, 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치하다. 그 다음에는, 프로세서는 당해 목표반복간격에 대응하는 데이터 비트폭과 점 위치 반복간격에 근거하여 신경망 연산과정에서의 점 위치 등 양자화 파라미터를 조정할 수 있다. 바람직하게는, 도 3-15에 도시된 바와 같이, 상술한 작업(S300)은 다음과 같은 단계를 포함할 수 있다. S310, 현재 검사 반복의 양자화 대상 데이터에 근거하여 목표반복간격에 대응하는 데이터 비트폭을 확정한다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치하다. 즉, 신경망 연산과정에서의 데이 터 비트폭은 하나의 목표반복간격을 사이로 1회 업데이트한다. 바람직하게는, 당해 목표반복간격에 대응하는 데 이터 비트폭은 현재 검사 반복의 목표데이터 비트폭일 수 있다. 당해 현재 검사 반복의 목표데이터 비트폭은 위 의 작업(S114)과 (S115)을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 예를 들어, 당해 목표반복간격은 현재 검사 반복부터 반복회수를 계산할 수 있다, 즉 목표반복간격에 대응하는 검사 반복은 목표반복간격의 처음 반복일 수 있다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정한 반복간격이 6이면, 프로세서는 당해 목 표반복간격이 제100회 반복 내지 제105회 반복의 6회 반복을 포함한다는 것을 확정할 수 있다. 이 때, 프로세서 는 제100회 반복의 목표데이터 비트폭을 확정하고, 제101회 반복 내지 제105회 반복에서 당해 제100회 반복의 목표데이터 비트폭을 계속 사용할 수 있어 제101회 반복 내지 제105회 반복에서 목표데이터 비트폭을 계산할 필 요가 없다. 따라서 계산량을 삭감하고, 양자화 효율 및 연산효율을 향상시킬 수 있다. 그 다음에는, 제106회 반복은 현재 검사 반복으로 될 수 있고, 상술한 목표반복간격의 확정 및 데이터 비트폭의 업데이트 작업을 되풀이 할 수 있다. 바람직하게는, 목표반복간격은 현재 검사 반복의 다음의 반복으로부터 계산하는 반복회수일 수도 있고, 즉 당해 목표반복간격에 대응하는 검사 반복은 당해 목표반복간격의 종료 반복일 수도 있다. 예를 들어, 현재 검사 반복 이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정한 반복 간격이 6이면. 따라서 프로세서는 당해 목표반복간격이 제101회 반복 내지 제106회 반복의 6회 반복을 포함한다 는 것을 확정할 수 있다. 이 때, 프로세서는 제100회 반복의 목표데이터 비트폭을 확정하고, 제101회 반복 내지 제106회 반복에서 당해 제100회 반복의 목표데이터 비트폭을 계속 사용할 수 있으며, 제101회 반복 내지 제106 회 반복에서 목표데이터 비트폭을 계산할 필요가 없다. 따라서 계산량을 삭감하고, 양자화 효율 및 연산효율을 향상시킬 수 있다. 그 다음에는, 제106회 반복은 현재 검사 반복으로 될 수 있고, 상술한 목표반복간격의 확정 및 데이터 비트폭의 업데이트 작업을 되풀이 할 수 있다. S320, 프로세서는 획득한 점 위치 반복간격과 상기 목표반복간격에 대응하는 데이터 비트폭에 근거하여 상기 목 표반복간격 중 반복에 대응하는 점 위치를 조정함으로써, 상기 신경망 연산에서의 점 위치 등 양자화 파라미터 를 조정한다. 여기에서, 상기 점 위치 반복간격은 적어도 1회 반복을 포함하며, 상기 점 위치 반복간격 중 반복되는 점 위치 가 일치하다. 바람직하게는, 당해 점 위치 반복간격은 하이퍼 파라미터일 수 있다. 예를 들어, 당해 점 위치 반 복간격은 사용자가 자체의 이해에 따라 입력한 것일 수 있다 . 바람직하게는, 상기 점 위치 반복간격은 상기 목표반복간격 이하이다. 당해 점 위치 반복간격와 상술한 목표반 복간격이 같은 경우, 프로세서는 현재 검사 반복에서 데이터 비트폭과 점 위치 등 양자화 파라미터를 동기적으 로 업데이트할 수 있다 . 더 바람직하게는, 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치할 수 있다. 또한, 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 이 때, 당해 목표반복간격에서의 반복에 대응하는 데이터 비트폭과 점 위치 등 양자화 파라미터가 모두 같으므로 계산량을 삭감할 수 있어 양자화 효율과 연산효 율을 향상시킬 수 있다. 구체적인 실현과정과 상술한 실시예는 기본적으로 일치하며, 위의 설명을 참조할 수 있 어 여기에서 다시 언급하지 않는다. 점 위치 반복간격이 상술한 목표반복간격 미만인 경우, 프로세서는 목표반복간격에 대응하는 검사 반복에서 데 이터 비트폭과 점 위치 등 양자화 파라미터를 업데이트하고, 당해 점 위치 반복간격이 확정된 서브 검사 반복에 서 점 위치 등 양자화 파라미터를 업데이트할 수 있다. 데이터 비트폭이 변하지 않는 경우, 점 위치 등 양자화 파라미터는 양자화 대상 데이터에 근거하여 미조정할 수 있다. 따라서, 동일한 목표반복간격 내에서 점 위치 등 양자화 파라미터를 조정하여 진일보로 양자화 정밀도를 향상시킬 수 있다. 구체적으로는, 프로세서는 현재 검사 반복과 점 위치 반복간격에 근거하여 서브 검사 반복을 확정할 수 있으며, 당해 서브 검사 반복은 점 위치을 조정하는 데 사용되고, 당해 서브 검사 반복은 목표반복간격 중의 반복일 수 있다. 또한, 프로세서는 서브 검사 반복의 양자화 대상 데이터와 목표반복간격에 대응하는 데이터 비트폭에 근 거하여 목표반복간격 중 반복에 대응하는 점 위치를 조정할 수 있다. 여기에서, 점 위치의 확정방식은 상술한 수학식（2）또는 수학식（14）을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 당해 목표반복간격이 6이며, 당해 목표반복간격에 포함된 반복 이 제100회 반복 내지 제105회 반복이다. 프로세서가 획득한 점 위치 반복간격이 =3, 현재 검사 반복부터 3 회 반복을 간격으로 점 위치를 1회 조정할 수 있다. 구체적으로는, 프로세서는 제100회 반복을 상술한 서브 검 사 반복으로 하고, 당해 제100회 반복에 대응하는 점 위치 s1을 계산하여 획득하며, 제100회 반복, 제101회 반 복 및 제102회 반복에서 점 위치 s1을 공통으로 사용하여 양자화할 수 있다. 그 다음에는, 프로세서는 점 위치 반복간격 에 근거하여 제103회 반복을 상술한 서브 검사 반복으로 하고, 동시에 프로세서는 제103회 반복에 대 응하는 양자화 대상 데이터와 목표반복간격에 대응하는 데이터 비트폭 n에 근거하여 두 번째 점 위치 반복간격 에 대응하는 점 위치 s2를 확정할 수 있으며, 제103회 반복 내지 제105회 반복에서 상술한 점 위치 s2를 공통으 로 사용하여 양자화할 수 있다. 본 발명 실시예에서, 상술한 업데이트하기 전의 점 위치 s1과 업데이트 후의 점 위치 s2의 값은 같을 수도 다를 수도 있다. 또한, 프로세서는 제106회 반복에서 다시 양자화 대상 데이터의 데 이터 변동폭에 근거하여 다음 목표반복간격 및 당해 다음 목표반복간격에 대응하는 데이터 비트폭 및 점 위치 등 양자화 파라미터를 확정할 수 있다. 또한, 현재 검사 반복이 제100회 반복이고, 당해 목표반복간격이 6이며, 당해 목표반복간격에 포함된 반복이 제 101회 반복 내지 제106회 반복이다. 프로세서가 획득한 점 위치 반복간격이 =3이면, 현재 검사 반복부터 3회 반복을 간격으로 점 위치를 1회 조정할 수 있다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이 터와 현재 검사 반복에 대응하는 목표데이터 비트폭 n1에 근거하여 첫 번째 점 위치 반복간격에 대응하는 점 위 치가 s1임을 확정하면, 제101회 반복, 제102회 반복 및 제103회 반복에서 상술한 점 위치 s1을 공통으로 사용하 여 양자화할 수 있다. 그 다음에는, 프로세서는 점 위치 반복간격 에 근거하여 제104회 반복을 상술한 서브 검 사 반복으로 할 수 있고, 동시에 프로세서는 제104회 반복에 대응하는 양자화 대상 데이터와 목표반복간격에 대 응하는 데이터 비트폭 n1에 근거하여 두 번째 점 위치 반복간격에 대응하는 점 위치 s2를 확정할 수 있으며, 제 104회 반복 내지 제106회 반복에서 상술한 점 위치 s2를 공통으로 사용하여 양자화할 수 있다. 본 발명 실시예 에서, 상술한 업데이트하기 전의 점 위치 s1과 업데이트 후의 점 위치 s2의 값은 같을 수도 다를 수도 있다. 또 한, 프로세서는 제106회 반복에서 다시 양자화 대상 데이터의 데이터 변동폭에 근거하여 다음 목표반복간격 및 당해 다음 목표반복간격에 대응하는 데이터 비트폭 및 점 위치 등 양자화 파라미터를 확정할 수 있다. 바람직하게는, 당해 점 위치 반복간격은 1과 같을 수 있다. 즉 매번 반복에서 모두 점 위치를 1회 업데이트한다. 바람직하게는, 당해 점 위치 반복간격은 같을 수도 다를 수도 있다. 예를 들어, 당해 목표반복간 격에 포함된 적어도 하나의 점 위치 반복간격은 순차적으로 증가될 수 있다. 여기에서는 예시적으로 본 실시예 의 실현방식을 설명할 뿐이며, 본 발명을 한정하기 위한 것이 아니다. 바람직하게는, 당해 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치하지 않을 수도 있다. 더 바람직하게 는, 당해 스케일 팩터는 상술한 점 위치와 동기적으로 업데이트될 수 있다. 즉, 당해 스케일 팩터에 대응하는 반복간격은 상술한 점 위치 반복간격과 같을 수 있다. 즉 프로세서가 점 위치를 업데이트하고 확정할 때마다, 이에 대응하여 스케일 팩터를 업데이트하고 확정한다. 바람직하게는, 당해 목표반복간격 중 반복에 대응하는 오프셋은 일치하지 않을 수도 있다. 또한, 당해 오프셋은 상술한 점 위치와 동기적으로 업데이트될 수 있다. 즉, 당해 오프셋에 대응하는 반복간격은 상술한 점 위치 반 복간격과 같을 수 있다. 즉 프로세서가 점 위치를 업데이트하고 확정할 때마다, 이에 대응하여 오프셋을 업데이 트하고 확정한다. 물론, 당해 오프셋은 상술한 점 위치 또는 데이터 비트폭과 비동기적으로 업데이트될 수도 있 으며, 여기에서는 구체적으로 한정하지 않는다. 또한, 프로세서는 양자화 대상 데이터의 모든 요소 중 최소 값 과 최대 값을 확정하고, 진일보로 점 위치와 스케일 팩터 등 양자화 파라미터를 확정할 수 있으며, 상세에 대해 서는 위의 설명을 참조할 수 있다. 다른 실시예에 있어서, 프로세서는 점 위치의 변동폭과 양자화 대상 데이터의 데이터 비트폭의 변화에 근거하여 양자화 대상 데이터의 데이터 변동폭을 통합적으로 확정하고, 당해 양자화 대상 데이터의 데이터 변동폭에 근거 하여 목표반복간격을 확정할 수 있다. 여기에서, 당해 목표반복간격은 데이터 비트폭을 업데이트하고 확정하는 데 사용할 수 있다. 즉 프로세서는 각 목표반복간격의 검사 반복에서 데이터 비트폭을 업데이트하고 확정할 수 있다. 점 위치가 고정 소수점 데이터의 정밀도를 반영할 수 있고, 데이터 비트폭이 고정 소수점 데이터의 데이 터 표현범위을 반영할 수 있으므로, 점 위치의 변동폭과 양자화 대상 데이터의 데이터 비트폭 변화를 통합함으 로써 양자화 후의 데이터가 정밀도를 충족할 수 있을 뿐만 아니라 데이터 표현범위도 충족시킬 수 있도록 보장 할 수 있다. 바람직하게는, 점 위치의 변화 폭은 상술한 제1 오차를 채용하여 특성화할 수 있고, 데이터 비트폭 의 변화는 상술한 양자화 오차에 근거하여 확정할 수 있다. 구체적으로는, 도3-16에 도시된 바와 같이, 상술한 방법은 다음과 같은 단계를 포함할 수 있다. S400, 양자화 대상 데이터의 데이터 변동폭을 표현할 수 있는 점 위치의 변동폭을 특성화할 수 있는 제1 오차를 획득한다. 구체적으로는, 상술한 제1 오차의 계산방식은 위 작업(S110)에서의 설명을 참조할 수 있으며, 여기에 서 다시 언급하지 않는다. S500, 상기 데이터 비트폭의 변화를 특성화하는 데 사용되는 제2 오차를 획득한다. 바람직하게는, 상술한 제2 오차는 양자화 오차에 근거하여 확정할 수 있으며, 당해 제2 오차는 상술한 양자화 오차와 정의 상관이 있다. 구체적으로는, 도3-16에 도시된 바와 같이, 상술한 작업(S500)은 다음과 같은 단계를 포함할 수 있다. S510, 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여 양자화 오차를 확정한다. 여기에서, 상기 현재 검사 반복의 양자화 데이터는 초기 데이터 비트폭에 근거하여 상기 현재검사 반복의 양자화 대상 데이터에 대해 양자화하여 획득한다. 여기에서, 구체적인 양자화 오차 확정방식은 위 작업(S114)에서의 설명을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. S520, 상기 양자화 오차에 근거하여 상기 제2 오차를 확정하며, 상기 제2 오차는 상기 양자화 오차와 정의 상관 이 있다. 구체적으로는, 제2 오차는 다음과 같은 수학식에 따라 계산할 수 있다. 수학식（34） 여기에서, 는 하이퍼 파라미터 일 수 있다. S600, 상기 제2 오차와 상기 제1 오차에 근거하여 상기 목표반복간격을 확정한다. 구체적으로는, 프로세서는 제1 오차와 제2 오차에 근거하여 계산을 통해 목표오차를 획득하고, 목표오차에 근거 하여 목표반복간격을 확정할 수 있다. 바람직하게는, 목표오차는 제1 오차와 제2 오차에 가중치를 부여하고 평 균을 계산하여 획득한 것일 수 있다. 예를 들어, 목표오차=K*제1 오차+（1-K）*제2 오차, 여기에서, K는 하이퍼 파라미터이다. 그 다음에는, 프로세서는 당해 목표오차에 근거하여 목표반복간격을 확정할 수 있으며, 목표반복 간격은 당해 목표오차와 부의 상관이 있다. 즉 목표오차가 크면 클 수록, 목표반복간격이 작아진다. 바람직하게는, 당해 목표오차는 제1 오차와 제2 오차 중의 최대 또는 최소 값에 근거하여 확정할 수도 있으며, 이 때 제1 오차 또는 제2 오차의 가중치는 0이다. 구체적으로는, 도3-17에 도시된 바와 같이, 상술한 작업 (S600)은 다음과 같은 단계를 포함할 수 있다. S610, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 한다. 구체적으로는, 프로세서는 제1 오차 와 제2 오차 의 크기를 비교하며, 제1 오차 가 제2 오차 보다 큰 경우, 당해 목표오차는 제1 오차 와 같다. 제1 오차 가 제2 오차보다 작 은 경우, 당해 목표오차는 제2 오차 와 같다. 제1 오차 가 제2 오차와 같은 경우, 당해 목표오 차는 제1 오차 또는 제2 오차 일 수 있다. 즉 목표오차 는 다음과 같은 수학식으로 확 정할 수 있다. 수학식（35） 여기에서, 는 목표오차이고, 는 제1 오차이며, 는 제2 오차이다. S620, 상기 목표오차에 근거하여 상기 목표반복간격을 확정한다. 여기에서, 상기 목표오차는 상기 목표반복간격 과 부의 상관이 있다. 구체적으로는, 목표반복간격은 다음과 같은 방식으로 확정할 수 있다. 이하의 수학식에 따라 목표반복간격을 얻을 수 있다. 수학식（36） 여기에서, I는 목표반복간격을 표현하고, 는 상술한 목표오차를 표현하며, 와 는 하이퍼 파라미터일 수 있다. 바람직하게는, 상술한 실시예에서, 신경망 연산 중 데이터 비트폭은 가변적이며, 제2 오차를 통해 데이터 비트 폭의 변화추세를 가늠할 수 있다. 이런 경우에서, 도3-17에 도시된 바와 같이, 프로세서는 목표반복간격을 확정 한 후, 작업(S630)을 실행하여 목표반복간격 중 반복에 대응하는 데이터 비트폭을 확정할 수 있다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치하다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 목표반복간격에 대응하는 데이터 비트폭을 확정할 수 있다. 즉, 신경망 연산과 정에서의 데이터 비트폭은 하나의 목표반복간격을 사이로 1회 업데이트한다 . 바람직하게는, 당해 목표반복간격 에 대응하는 데이터 비트폭은 현재 검사 반복의 목표데이터 비트폭일 수 있다. 당해 현재 검사 반복의 목표데이터 비트폭은 위의 작업(S114)과 (S115)을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 예를 들어, 당해 목표반복간격은 현재 검사 반복부터 반복회수를 계산할 수 있다. 즉 목표반복간격에 대응하는 검사 반복은 목표반복간격의 처음 반복일 수 있다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정한 반복간격이 6이면, 프로세서는 당해 목 표반복간격이 제100회 반복 내지 제105회 반복의 6회 반복을 포함한다는 것을 확정할 수 있다. 이 때, 프로세서 는 제100회 반복의 목표데이터 비트폭을 확정하고, 제101회 반복 내지 제105회 반복에서 당해 제100회 반복의 목표데이터 비트폭을 계속 사용할 수 있어 제101회 반복 내지 제105회 반복에서 목표데이터 비트폭을 계산할 필 요가 없다. 따라서 계산량을 삭감하고, 양자화 효율 및 연산효율을 향상시킬 수 있다. 그 다음에는, 제106회 반 복은 현재 검사 반복으로 될 수 있고, 상술한 목표반복간격의 확정 및 데이터 비트폭의 업데이트 작업을 되풀이 할 수 있다. 바람직하게는, 목표반복간격은 현재 검사 반복의 다음의 반복으로부터 계산하는 반복회수일 수도 있고, 즉 당해 목표반복간격에 대응하는 검사 반복은 당해 목표반복간격의 종료 반복일 수도 있다. 예를 들어, 현재 검사 반복 이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정한 반복 간격이 6이다. 따라서 프로세서는 당해 목표반복간격이 제101회 반복 내지 제106회 반복의 6회 반복을 포함한다 는 것을 확정할 수 있다. 이 때, 프로세서는 제100회 반복의 목표데이터 비트폭을 확정하고, 제101회 반복 내지 제106회 반복에서 당해 제100회 반복의 목표데이터 비트폭을 계속 사용할 수 있으며, 제101회 반복 내지 제106 회 반복에서 목표데이터 비트폭을 계산할 필요가 없다. 따라서 계산량을 삭감하고, 양자화 효율 및 연산효율을 향상시킬 수 있다. 그 다음에는, 제106회 반복은 현재 검사 반복으로 될 수 있고, 상술한 목표반복간격의 확정 및 데이터 비트폭의 업데이트 작업을 되풀이 할 수 있다. 또한, 프로세서는 검사 반복에서 목표반복간격 주의 양자화 파라미터를 확정하여 목표반복간격에 근거하여 신경 망 연산 중의 양자화 파라미터를 조정하도록 할 수 있다. 즉 당해 신경망 연산에서의 점 위치 등 양자화 파라미 터는 데이터 비트폭과 동기적으로 업데이트될 수 있다. 한 가지 상황에서, 당해 목표반복간격 중 반복에 대응하는 양자화 파라미터는 일치할 수 있다. 바람직하게는, 프로세서는 현재 검사 반복의 양자화 대상 데이터와 당해 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거 하여 현재 검사 반복에 대응하는 점 위치를 확정하고, 당해 현재 검사 반복에 대응하는 점 위치를 당해 목표반 복간격에 대응하는 점 위치로 할 수 있다. 여기에서 당해 목표반복간격 중 반복에 대응하는 점 위치는 일치하다. 즉, 목표반복간격 중의 각 반복은 모두 현재 검사 반복의 점 위치 등 양자화 파라미터를 계속하여 사 용하며, 매번 반복에서 모두 양자화 파라미터를 업데이트하여 조정하는 것을 회피함으로써, 양자화 과정에서의 계산량을 삭감하고, 양자화 작업의 효율을 향상시킨다. 바람직하게는, 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치할 수 있다. 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 현재 검사 반복에 대응하는 스케일 팩터를 확정하고, 당해 현재 검사 반복에 대 응하는 스케일 팩터을 목표반복간격 중 각 반복의 스케일 팩터로 할 수 있다. 여기에서, 당해 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치하다. 바람직하게는, 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 프로세서는 현재 검사 반복의 양자화 대상 데이터에 근거하여 현재 검사 반복에 대응하는 오프셋을 확정하며, 당해 현재 검사 반복에 대응하는 오프셋을 목표반복간격 중 각 반복의 오프셋으로 할 수 있다. 또한, 프로세서는 양자화 대상 데이터의 모든 요소 중 최소 값과 최대 값을 확정하고, 진일보로 점 위치와 스케일 팩터 등 양자화 파라미터를 확정할 수 있으며, 상세에 대 해서는 위의 설명을 참조할 수 있다. 당해 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 예를 들어, 당해 목표반복간격은 현재 검사 반복부터 반복회수를 계산할 수 있다, 즉 목표반복간격에 대응하는 검사 반복은 목표반복간격의 처음 반복일 수 있다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복간격이 3이면, 프로세서는 당해 목 표반복간격이 제100회 반복, 제101회 반복 및 제102회 반복의 3회 반복을 포함하는 것을 확정할 수 있다. 또한 프로세서는 제100회 반복에 대응하는 양자화 대상 데이터와 목표데이터 비트폭에 근거하여, 당해 제100회 반복 에 대응하는 점 위치 등 양자화 파라미터를 확정할 수 있고, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 채용하여 제100회 반복, 제101회 반복 및 제102회 반복을 양자화할 수 있다. 이러한 방식으로, 프로 세서는 제101회 반복과 제102회 반복에서 점 위치 등 양자화 파라미터을 계산할 필요가 없으며, 양자화 과정에 서의 계산량을 삭감하여 양자화 작업의 효율을 향상시킨다. 바람직하게는, 목표반복간격은 현재 검사 반복의 다음의 반복으로부터 계산하는 반복회수일 수도 있고, 즉 당해 목표반복간격에 대응하는 검사 반복은 당해 목표반복간격의 종료 반복일 수도 있다. 예를 들어, 현재 검사 반복 이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복 간격이 3이다. 프로세서는 당해 목표반복간격이 제101회 반복, 제102회 반복 및 제103회 반복의 3회 반복을 포 함하는 것을 확정할 수 있다. 따라서 프로세서는 제100회 반복에 대응하는 양자화 대상 데이터와 목표데이터 비 트폭에 근거하여, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 확정할 수 있고, 당해 제100회 반복에 대응하는 점 위치 등 양자화 파라미터를 채용하여 제101회 반복, 제102회 반복 및 제103회 반복을 양자 화할 수 있다. 이러한 방식으로, 프로세서는 제102회 반복과 제103회 반복에서 점 위치 등 양자화 파라미터를 계산할 필요가 없으며, 양자화 과정에서의 계산량을 삭감하여 양자화 작업의 효율을 향상시킨다. 본 발명 실시예에서, 동일한 목표반복간격 중 각 반복에 대응하는 데이터 비트폭 및 양자화 파라미터 모두 일치 하다, 즉 동일한 목표반복간격 중 각 반복에 대응하는 데이터 비트폭, 점 위치, 스케일 팩터 및 오프셋은 모두 변하지 않도록 유지되며, 신경망의 훈련 또는 미조정과정에서 양자화 대상 데이터의 양자화 파라미터를 빈번하 게 조정하는 것을 회피할 있고, 양자화 과정에서의 계산량을 삭감하여 양자화 효율을 향상시킬 수 있다. 또한, 훈련 또는 미조정의 상이한 단계에서 데이터 변동폭에 근거하여 동적으로 양자화 파라미터를 조정함으로써 양자 화 정밀도를 보장할 수 있다. 다른 상황에서, 프로세서는 점 위치 등 양자화 파라미터에 대응하는 점 위치 반복간격에 근거하여 목표반복간격 중의 양자화 파라미터를 확정하여 신경망 연산에서의 양자화 파라미터를 조정하도록 할 수 있다. 즉 당해 신경 망 연산에서의 점 위치 등 양자화 파라미터는 데이터 비트폭과 비동기적으로 업데이트될 수 있고, 프로세서는 목표반복간격의 검사 반복에서 데이터 비트폭과 점 위치 등 양자화 파라미터를 업데이트할 수 있으며, 프로세서 는 점 위치 반복간격에 근거하여 목표반복간격 중 반복에 대응하는 점 위치를 개별적으로 업데이트할 수도 있다. 구체적으로는, 프로세서는 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여 목표반복간격에 대응하는 데이터 비트폭을 확정할 수도 있다. 여기에서, 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치하다. 그 다음에는, 프로세서는 당해 목표반복간격에 대응하는 데이터 비트폭과 점 위치 반복간격에 근거하여 신경망 연 산과정에서의 점 위치 등 양자화 파라미터를 조정할 수 있다. 즉 도3-17에 도시된 바와 같이, 목표반복간격에 대응하는 데이터 비트폭을 확정한 다음에, 프로세서는 작업(S640)을 실행할 수도 있으며, 획득한 점 위치 반복 간격과 상기 목표반복간격에 대응하는 데이터 비트폭에 근거하여 상기 목표반복간격 중 반복에 대응하는 점 위 치를 조정하여 상기 신경망 연산에서의 점 위치를 조정하도록 한다. 여기에서, 상기 점 위치 반복간격은 적어도 1회 반복을 포함하며, 상기 점 위치 반복간격 중 반복되는 점 위치가 일치하다. 바람직하게는, 당해 점 위치 반 복간격은 하이퍼 파라미터일 수 있다. 예를 들어, 당해 점 위치 반복간격은 사용자가 자체의 이해에 따라 입력 한 것일 수 있다 . 바람직하게는, 상기 점 위치 반복간격은 상기 목표반복간격 이하이다. 당해 점 위치 반복간격와 상술한 목표반 복간격이 같은 경우, 프로세서는 현재 검사 반복에서 데이터 비트폭과 점 위치 등 양자화 파라미터를 동기적으 로 업데이트할 수 있다. 더 바람직하게는, 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치할 수 있다. 또 한, 목표반복간격 중 반복에 대응하는 오프셋은 일치하다. 이 때, 당해 목표반복간격에서의 반복에 대응하는 데 이터 비트폭과 점 위치 등 양자화 파라미터가 모두 같으므로 계산량을 삭감할 수 있어 양자화 효율과 연산효율 을 향상시킬 수 있다. 구체적인 실현과정과 상술한 실시예는 기본적으로 일치하며, 위의 설명을 참조할 수 있어 여기에서 다시 언급하지 않는다. 점 위치 반복간격이 상술한 목표반복간격 미만인 경우, 프로세서는 목표반복간격에 대응하는 검사 반복에서 데 이터 비트폭과 점 위치 등 양자화 파라미터를 업데이트하고, 당해 점 위치 반복간격이 확정된 서브 검사 반복에 서 점 위치 등 양자화 파라미터를 업데이트할 수 있다. 데이터 비트폭이 변하지 않는 경우, 점 위치 등 양자화 파라미터는 양자화 대상 데이터에 근거하여 미조정할 수 있다. 따라서, 동일한 목표반복간격 내에서 점 위치 등 양자화 파라미터를 조정하여 진일보로 양자화 정밀도를 향상시킬 수 있다. 구체적으로는, 프로세서는 현재 검사 반복과 점 위치 반복간격에 근거하여 서브 검사 반복을 확정할 수 있으며, 당해 서브 검사 반복은 점 위치을 조정하는 데 사용되고, 당해 서브 검사 반복은 목표반복간격 중의 반복일 수 있다. 또한, 프로세서는 서브 검사 반복의 양자화 대상 데이터와 목표반복간격에 대응하는 데이터 비트폭에 근 거하여 목표반복간격 중 반복에 대응하는 점 위치를 조정할 수 있다. 여기에서, 점 위치의 확정방식은 상술한 수학식（2）또는 수학식（14）을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 예를 들어, 현재 검사 반복이 제100회 반복이고, 당해 목표반복간격이 6이며, 당해 목표반복간격에 포함된 반복 이 제100회 반복 내지 제105회 반복이다. 프로세서가 획득한 점 위치 반복간격이 =3이면, 현재 검사 반복부터 3회 반복을 간격으로 점 위치를 1회 조정할 수 있다. 구체적으로는, 프로세서는 제100회 반복을 상술한 서브 검 사 반복으로 하고, 당해 제100회 반복에 대응하는 점 위치 s1을 계산하여 획득하며, 제100회 반복, 제101회 반 복 및 제102회 반복에서 점 위치 s1을 공통으로 사용하여 양자화할 수 있다. 그 다음에는, 프로세서는 점 위치 반복간격 에 근거하여 제103회 반복을 상술한 서브 검사 반복으로 하고, 동시에 프로세서는 제103회 반복에 대 응하는 양자화 대상 데이터와 목표반복간격에 대응하는 데이터 비트폭 n에 근거하여 두 번째 점 위치 반복간격 에 대응하는 점 위치 s2를 확정할 수 있으며, 제103회 반복 내지 제105회 반복에서 상술한 점 위치 s2를 공통으 로 사용하여 양자화할 수 있다. 본 발명 실시예에서, 상술한 업데이트하기 전의 점 위치 s1과 업데이트 후의 점 위치 s2의 값은 같을 수도 다를 수도 있다. 또한, 프로세서는 제106회 반복에서 다시 양자화 대상 데이터의 데 이터 변동폭에 근거하여 다음 목표반복간격 및 당해 다음 목표반복간격에 대응하는 데이터 비트폭 및 점 위치 등 양자화 파라미터를 확정할 수 있다. 또한, 현재 검사 반복이 제100회 반복이고, 당해 목표반복간격이 6이며, 당해 목표반복간격에 포함된 반복이 제 101회 반복 내지 제106회 반복이다. 프로세서가 획득한 점 위치 반복간격이 =3이면, 현재 검사 반복부터 3회 반복을 간격으로 점 위치를 1회 조정할 수 있다. 구체적으로는, 프로세서는 현재 검사 반복의 양자화 대상 데이 터와 현재 검사 반복에 대응하는 목표데이터 비트폭 n1에 근거하여 첫 번째 점 위치 반복간격에 대응하는 점 위 치가 s1임을 확정하면, 제101회 반복, 제102회 반복 및 제103회 반복에서 상술한 점 위치 s1을 공통으로 사용하 여 양자화할 수 있다. 그 다음에는, 프로세서는 점 위치 반복간격 에 근거하여 제104회 반복을 상술한 서브 검 사 반복으로 할 수 있고, 동시에 프로세서는 제104회 반복에 대응하는 양자화 대상 데이터와 목표반복간격에 대 응하는 데이터 비트폭 n1에 근거하여 두 번째 점 위치 반복간격에 대응하는 점 위치 s2를 확정할 수 있으며, 제 104회 반복 내지 제106회 반복에서 상술한 점 위치 s2를 공통으로 사용하여 양자화할 수 있다. 본 발명 실시예 에서, 상술한 업데이트하기 전의 점 위치 s1과 업데이트 후의 점 위치 s2의 값은 같을 수도 다를 수도 있다. 또 한, 프로세서는 제106회 반복에서 다시 양자화 대상 데이터의 데이터 변동폭에 근거하여 다음 목표반복간격 및 당해 다음 목표반복간격에 대응하는 데이터 비트폭 및 점 위치 등 양자화 파라미터를 확정할 수 있다 . 바람직하게는, 당해 점 위치 반복간격은 1과 같을 수 있다. 즉 매번 반복에서 모두 점 위치를 1회 업데이트한다. 바람직하게는, 당해 점 위치 반복간격은 같을 수도 다를 수도 있다. 예를 들어, 당해 목표반복간 격에 포함된 적어도 하나의 점 위치 반복간격은 순차적으로 증가될 수 있다. 여기에서는 예시적으로 본 실시예 의 실현방식을 설명할 뿐이며, 본 발명을 한정하기 위한 것이 아니다. 바람직하게는, 당해 목표반복간격 중 반복에 대응하는 스케일 팩터는 일치하지 않을 수도 있다. 더 바람직하게 는, 당해 스케일 팩터는 상술한 점 위치와 동기적으로 업데이트될 수 있다. 즉, 당해 스케일 팩터에 대응하는 반복간격은 상술한 점 위치 반복간격과 같을 수 있다. 즉 프로세서가 점 위치를 업데이트하고 확정할 때마다, 대응적으로 스케일 팩터를 업데이트하고 확정한다. 바람직하게는, 당해 목표반복간격 중 반복에 대응하는 오프셋은 일치하지 않을 수도 있다. 또한, 당해 오프셋은 상술한 점 위치와 동기적으로 업데이트될 수 있다, 즉, 당해 오프셋에 대응하는 반복간격은 상술한 점 위치 반 복간격과 같을 수 있다. 즉 프로세서가 점 위치를 업데이트하고 확정할 때마다, 이에 대응하여 오프셋을 업데이 트하고 확정한다. 물론, 당해 오프셋은 상술한 점 위치 또는 데이터 비트폭과 비동기적으로 업데이트될 수도 있 으며, 여기에서는 구체적으로 한정하지 않는다. 또한, 프로세서는 양자화 대상 데이터의 모든 요소 중 최소 값 과 최대 값을 확정하고, 진일보로 점 위치와 스케일 팩터 등 양자화 파라미터를 확정할 수 있으며, 상세에 대해 서는 위의 설명을 참조할 수 있다. 다른 바람직한 실시예에서, 점 위치, 스케일 팩터 및 오프셋 3개의 양자화 파라미터 사이는 비동기적일 수도 있 다 , 즉 점 위치 반복간격, 스케일 팩터 반복간격 및 오프셋 반복간격 중의 하나 또는 3개 모두가 다르다. 여기 에서, 점 위치 반복간격과 스케일 팩터 반복간격은 모두 목표반복간격 이하이다. 오프셋 반복간격은 목표반복간 격보다 작을 수 있다. 오프셋이 양자화 대상 데이터의 분포에만 관련되기 때문에, 하나의 가능한 실시예에서, 당해 오프셋은 목표반복간격과 완전히 비동기적일 수도 있다. 즉 오프셋 반복간격은 목표반복간격보다 클 수도 있다. 하나의 바람직한 실시예에서, 상술한 방법은 신경망의 훈련 또는 미조정과정에 적용함으로써, 신경망의 미조정 또는 훈련과정에 관련된 연산 데이터의 양자화 파라미터에 대한 조정을 실현하고, 신경망 연산과정에 관련된 연 산 데이터의 양자화 정밀도 및 효율을 향상시키도록 한다. 당해 연산 데이터는 뉴런 데이터, 가중치 데이터 또 는 그래디언트 데이터 중의 적어도 한 가지이다. 도3-5에 도시된 바와 같이, 양자화 대상 데이터의 데이터 변동 곡선에 따라, 훈련 또는 미조정의 초기 단계에서, 각 반복의 양자화 대상 데이터 사이의 차이점이 비교적 크고, 양자화 대상 데이터의 데이터 변동폭이 비교적 심하므로, 이 때 목표반복간격의 값을 작게 할 수 있고, 수시로 목표반복간격 중의 양자화 파라미터를 업데이트하여 양자화 정밀도를 보장할 수 있음을 알 수 있다. 훈련 또는 미조정의 중기 단계에서, 양자화 대상 데이터의 데이터 변동폭은 점차 완만해 지는 경향이 있고, 이 때에는 목 표반복간격의 값을 증가하여 양자화 파라미터를 빈번하게 업데이트하는 것을 회피하며, 양자화 효율 및 연산효 율을 향상하도록 한다. 훈련 또는 미조정의 후기 단계에서, 이 때에는 신경망의 훈련 또는 미조정이 안정해 지 는 경향이 있다（즉 신경망의 순방향 연산결과가 미리 설정된 기준 값에 근접하면 당해 신경망의 훈련 또는 미 조정이 안정되는 경향이 있다）, 이 때에는 목표반복간격의 값을 계속 증가하여 진일보로 양자화 효율 및 연산 효율을 향상시킬 수 있다. 상술한 데이터 변동추세에 따라, 신경망의 훈련 또는 미조정의 서로 다른 단계에서 서로 다른 방식을 채용하여 목표반복간격을 확정함으로써, 양자화 정밀도의 보장을 기반으로 양자화 효율 및 연 산효율을 향상시킬 수 있다. 구체적으로는, 도3-18에 도시된 바와 같이, 당해 방법은 신경망의 훈련 또는 미조정과정에 적용되는 경우, 당해 방법은 다음과 같은 단계를 포함할 수 있다. S710, 프로세서는 현재 반복이 제1 미리 설정된 반복보다 클지 여부를 확정한다. 여기에서, 현재 반복은 프로세서가 현재 실행하고 있는 반복연산을 의미한다. 바람직하게는, 당해 제1 미리 설 정된 반복은 하이퍼 파라미터일 수 있고, 당해 제1 미리 설정된 반복은 양자화 대상 데이터의 데이터 변동곡선 에 의해 확정할 수 있으며, 당해 제1 미리 설정된 반복은 사용자가 자신의 이해에 따라 설정한 것일 수도 있다. 바람직하게는, 당해 제1 미리 설정된 반복은 한 훈련주기（epoch）에 포함된 총반복회수보다 작을 수 있다, 여 기에서, 한 훈련주기는 데이터 세트 중의 모든 양자화 대상 데이터가 모두 1회 순방향 연산과 1회 역방향 연산 을 완료한 것을 의미한다. 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 프로세서는 작업(S711)을 실행할 수 있으며, 제1 미 리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제1 미리 설정된 반복간격에 근거하여 양자화 파라미 터를 조정한다. 바람직하게는, 프로세서는 사용자가 입력한 제1 미리 설정된 반복을 판도하고, 당해 제1 미리 설정된 반복과 제 1 미리 설정된 반복간격의 대응관계에 근거하여, 제1 미리 설정된 반복간격을 확정할 수 있다. 바람직하게는, 당해 제1 미리 설정된 반복간격은 하이퍼 파라미터일 수 있고, 당해 제1 미리 설정된 반복간격은 사용자가 자신 의 이해에 따라 설정한 것일 수도 있다. 이 때, 프로세서는 사용자가 입력한 제1 미리 설정된 반복과 제1 미리 설정된 반복간격을 직접 판독하고, 당해 제1 미리 설정된 반복간격에 근거하여 신경망 연산에서의 양자화 파라 미터를 업데이트할 수 있다. 본 발명 실시예에서, 프로세서는 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정할 필요가 없다. 예를 들어, 사용자가 입력한 제1 미리 설정된 반복이 제100회 반복이고, 제1 미리 설정된 반복간격이 5이면, 현 재 반복이 제100회 반복 이하인 경우, 제1 미리 설정된 반복간격에 근거하여 양자화 파라미터를 업데이트할 수 있다. 즉 프로세서는 신경망의 훈련 또는 미조정의 제1회 반복 내지 제100회 반복을 확정할 수 있고, 매번 5회 반복을 간격으로 양자화 파라미터를 1회 업데이트할 수 있다. 구체적으로는, 프로세서는 제1회 반복에 대응하는 데이터 비트폭 n1 및 점 위치 s1 등 양자화 파라미터를 확정하고, 당해 데이터 비트폭 n1과 점 위치 s1 등 양자 화 파라미터를 채용하여 제1회 반복 내지 제5회 반복의 양자화 대상 데이터를 양자화할 수 있다. 즉 제1회 반복 내지 제5회 반복에서 동일한 양자화 파라미터를 채용할 수 있다. 그 다음에는, 프로세서는 제6회 반복에 대응하 는 데이터 비트폭 n2 및 점 위치 s2 등 양자화 파라미터를 확정하고, 당해 데이터 비트폭 n2와 점 위치 s2 등 양자화 파라미터를 채용하여 제6회 반복 내지 제10회 반복의 양자화 대상 데이터를 양자화할 수 있다. 즉 제6회 반복 내지 제10회 반복은 동일한 양자화 파라미터를 채용할 수 있다. 마찬가지로, 프로세서는 제100회 반복이 완료될 때까지 상술한 양자화 방식에 따를 수 있다. 여기에서, 각 반복간격 중 데이터 비트폭 및 점 위치 등 양 자화 파라미터의 확정방식은 위의 설명을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 또한, 사용자가 입력한 제1 미리 설정된 반복이 제100회 반복이고, 제1 미리 설정된 반복간격이 1이며, 현재 반 복이 제100회 반복 이하인 경우, 제1 미리 설정된 반복간격에 근거하여 양자화 파라미터를 업데이트할 수 있다. 즉 프로세서는 신경망의 훈련 또는 미조정의 제1회 반복 내지 제100회 반복을 확정할 수 있고, 매번 반복에서모두 양자화 파라미터를 업데이트한다. 구체적으로는, 프로세서는 제1회 반복에 대응하는 데이터 비트폭 n1 및 점 위치 s1 등 양자화 파라미터를 확정하고, 당해 데이터 비트폭 n1과 점 위치 s1 등 양자화 파라미터를 채용하 여 제1회 반복의 양자화 대상 데이터를 양자화할 수 있다. 그 다음에는, 프로세서는 제2회 반복에 대응하는 데 이터 비트폭 n2 및 점 위치 s2 등 양자화 파라미터를 확정하고, 당해 데이터 비트폭 n2와 점 위치 s2 등 양자화 파라미터를 채용하여 제2회 반복의 양자화 대상 데이터를 양자화, ……할 수 있다. 마찬가지로, 프로세서는 제 100회 반복의 데이터 비트폭 n100 및 점 위치 s100 등 양자화 파라미터를 확정하고, 당해 데이터 비트폭 n100과 점 위치 s100 등 양자화 파라미터를 채용하여 제100회 반복의 양자화 대상 데이터를 양자화할 수 있다. 여기에 서, 각 반복간격 중 데이터 비트폭 및 점 위치 등 양자화 파라미터의 확정방식은 위의 설명을 참조할 수 있으며, 여기에서 다시 언급하지 않는다. 상기에서는 데이터 비트폭과 양자화 파라미터가 동기적으로 업데이트되는 방식을 예로 설명하였지만, 다른 바람 직한 실시예에서, 각 목표반복간격에서, 프로세서는 점 위치의 변동폭에 근거하여 점 위치의 반복간격을 확정하 고, 당해 점 위치 반복간격에 근거하여 점 위치 등 양자화 파라미터를 업데이트할 수 있다 . 바람직하게는, 현재 반복이 제1 미리 설정된 반복보다 큰 경우, 신경망의 훈련 또는 미조정이 중기 단계인 것을 나타낸다. 이 때 이력 반복의 양자화 대상 데이터의 데이터 변동폭을 획득하고, 당해 양자화 대상 데이터의 데 이터 변동폭에 근거하여 목표반복간격을 확정할 수 있으며, 당해 목표반복간격은 상술한 제1 미리 설정된 반복 간격보다 클 수 있으므로 양자화 파라미터의 업데이트 회수를 감소하고, 양자화 효율 및 연산효율을 향상시킬 수 있다. 구체적으로는, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 프로세서는 작업(S713)을 실행할 수 있으며, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정하고 상기 목표반복간격 에 근거하여 양자화 파라미터를 조정한다. 위의 예에 계속하여, 사용자가 입력한 제1 미리 설정된 반복이 제100회 반복이고, 제1 미리 설정된 반복간격이 1이며, 현재 반복이 제100회 반복 이하인 경우, 제1 미리 설정된 반복간격에 근거하여 양자화 파라미터를 업데 이트할 수 있다. 즉 프로세서는 신경망의 훈련 또는 미조정의 제1회 반복 내지 제100회 반복을 확정할 수 있고, 매번 반복에서 모두 양자화 파라미터를 업데이트한다. 구체적 실현방식은 위의 설명을 참조할 수 있다. 현재 반 복이 제100회 반복보다 큰 경우, 프로세서는 현재 반복의 양자화 대상 데이터 및 그 전의 이력 반복의 양자화 대상 데이터에 근거하여 양자화 대상 데이터의 데이터 변동폭을 확정하고, 당해 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정할 수 있다. 구체적으로는, 현재 반복이 제100회 반복보다 큰 경우, 프 로세서는 현재 반복에 대응하는 데이터 비트폭을 자기 적응적으로 조정하여 당해 현재 반복에 대응하는 목표데 이터 비트폭을 획득하고, 당해 현재 반복에 대응하는 목표데이터 비트폭을 목표반복간격의 데이터 비트폭으로 할 수 있다. 여기에서, 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치하다. 동시에, 프로세서는 현재 반복에 대응하는 목표데이터 비트폭과 양자화 대상 데이터에 근거하여 현재 반복에 대응하는 점 위치를 확정하 고, 현재 반복에 대응하는 점 위치에 근거하여 제1 오차를 확정할 수 있다. 프로세서는 현재 반복에 대응하는 양자화 대상 데이터에 근거하여 양자화 오차를 확정하고, 양자화 오차에 근거하여 제2 오차를 확정할 수 있다. 그 다음에는, 프로세서는 제1 오차와 제2 오차에 근거하여 목표반복간격을 확정할 수 있고, 당해 목표반복간격 은 상술한 제1 미리 설정된 반복간격보다 클 수 있다. 또한, 프로세서는 목표반복간격 중의 점 위치 또는 스케 일 팩터 등 양자화 파라미터를 확정할 수 있으며, 구체적 확정방식은 위의 설명을 참조할 수 있다. 예를 들어, 현재 반복이 제100회 반복이고, 프로세서가 양자화 대상 데이터의 데이터 변동폭에 근거하여 확정한 목표반복간격의 반복간격이 3이면, 프로세서는 당해 목표반복간격이 제100회 반복, 제101회 반복 및 제102회 반 복의 3회 반복을 포함하는 것을 확정할 수 있다. 프로세서는 제100회 반복의 양자화 대상 데이터에 근거하여 양 자화 오차를 확정하고, 양자화 오차에 근거하여 제2 오차와 제100회 반복에 대응하는 목표데이터 비트폭을 확정 하며, 당해 목표데이터 비트폭을 목표반복간격에 대응하는 데이터 비트폭으로 할 수 있다. 여기에서, 제100회 반복, 제101회 반복 및 제102회 반복에 대응하는 데이터 비트폭은 모두 당해 제100회 반복에 대응하는 목표데이 터 비트폭이다. 프로세서는 당해 제100회 반복의 양자화 대상 데이터와 당해 제100회 반복에 대응하는 목표데이 터 비트폭에 근거하여 당해 제100회 반복에 대응하는 점 위치와 스케일 팩터 등 양자화 파라미터를 확정할 수도 있다. 그 다음에는, 당해 제100회 반복에 대응하는 양자화 파라미터를 채용하여 제100회 반복, 제101회 반복 및 제102회 반복을 양자화한다. 또한, 도3-19에 도시된 바와 같이, 상술한 방법은 다음과 같은 단계를 포함할 수 있다. 현재 반복이 제1 미리 설정된 반복보다 큰 경우, 프로세서는 작업(S712)을 실행할 수도 있다, 즉 프로세서는 현 재 반복이 제2 미리 설정된 반복보다 큰지 여부를 더 확정할 수 있다. 여기에서, 상기 제2 미리 설정된 반복이상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간격이 상기 제1 미리 설정된 반복간격보다 도 크다. 바람직하게는, 상술한 제2 미리 설정된 반복은 하이퍼 파라미터일 수 있고, 제2 미리 설정된 반복은 적어도 하나의 훈련주기의 총반복수보다도 클 수 있다. 바람직하게는, 제2 미리 설정된 반복은 양자화 대상 데 이터의 데이터 변동곡선에 따라 확정할 수 있다. 바람직하게는, 제2 미리 설정된 반복은 사용자가 자신의 이해 에 따라 설정한 것일 수도 있다. 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 프로세서는 작업(S714)을 실행할 수 있으며, 제2 미리 설 정된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 신경망양자화 과정 중의 파라미터를 조정한다. 현재 반복이 제1 미리 설정된 반복보다 크고, 또 현재 반복이 제2 미리 설정된 반복보다 작은 경우, 프로세서는 상술한 작업(S713)을 실행할 수 있으며, 상기 양자화 대상 데이터의 데이터 변 동폭에 근거하여 목표반복간격을 확정하고 상기 목표반복간격에 근거하여 양자화 파라미터를 조정한다. 바람직하게는, 프로세서는 사용자가 설정한 제2 미리 설정된 반복을 판독하고, 제2 미리 설정된 반복과 제2 미 리 설정된 반복간격의 대응관계에 근거하여 제2 미리 설정된 반복간격을 확정할 수 있으며, 당해 제2 미리 설정 된 반복간격은 제1 미리 설정된 반복간격보다 크다. 바람직하게는, 상기 신경망의 수렴정도가 미리 설정된 조건 을 충족시키면, 상기 현재 반복이 제2 미리 설정된 반복 이상이라고 확정한다. 예를 들어, 현재 반복의 순방향 연산결과가 미리 설정된 기준 값에 근접했을 경우, 당해 신경망의 수렴정도가 미리 설정된 조건을 충족시킨다고 확정할 수 있다, 이 때 현재 반복이 제2 미리 설정된 반복 이상이라고 확정할 수 있다. 또는, 현재 반복에 대응 하는 손실 값이 미리 설정된 한계 값 이하인 경우, 당해 신경망의 수렴정도가 미리 설정된 조건을 충족시킨다고 확정할 수 있다. 바람직하게는, 상술한 제2 미리 설정된 반복간격은 하이퍼 파라미터일 수 있고, 당해 제2 미리 설정된 반복간격 은 적어도 한 훈련주기의 총반복수 이상일 수 있다. 바람직하게는, 당해 제2 미리 설정된 반복간격은 사용자가 자신의 이해에 따라 설정한 것일 수 있다. 프로세서는 사용자가 입력한 제2 미리 설정된 반복과 제2 미리 설정 된 반복간격을 직접 판독하고, 당해 제2 미리 설정된 반복간격에 근거하여 신경망 연산 중의 양자화 파라미터를 업데이트할 수 있다. 예를 들어, 당해 제2 미리 설정된 반복간격은 한 훈련주기의 총반복수와 같을 수 있다. 즉 각 훈련주기（epoch）에서 양자화 파라미터를 1회 업데이트한다. 또한, 상술한 방법은 다음과 같은 단계를 더 포함한다. 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 프로세서는 매번 검사 반복에서 현재 데이터 비트폭을 조 정할 필요가 있는지 여부를 확정할 수도 있다. 현재 데이터 비트폭을 조정할 필요가 있으면, 프로세서는 상술한 작업(S714)에서 작업(S713)으로 전환하여 데이터 비트폭을 다시 확정하며, 데이터 비트폭이 양자화 대상 데이터 의 요구사항을 충족시키도록 할 수 있다. 구체적으로는, 프로세서는 상술한 제2 오차에 근거하여 데이터 비트폭을 조정할 필요가 있는지 여부를 확정할 수 있다. 프로세서는 상술한 작업(S715)을 실행할 수 있으며, 제2 오차가 미리 설정된 오차 값보다 큰지 여부를 확정한다. 상기 현재 반복이 제2 미리 설정된 반복 이상이고, 또 상기 제2 오차가 미리 설정된 오차 값보다 큰 경우, 작업(S713)으로 전환하여 실행하며, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확 정하며, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 한다. 현재 반복이 제2 미리 설정된 반복 이상이고, 또 제2 오차가 미리 설정된 오차 값 이하이면, 작업(S714)을 계속하여 실행하며, 제2 미리 설정 된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 신경망양자화 과 정 중의 파라미터를 조정한다. 여기에서, 미리 설정된 오차 값은 양자화 오차에 대응하는 미리 설정된 한계 값 에 근거하여 확정될 수 있다. 제2 오차가 미리 설정된 오차 값보다 클 경우, 이 때 데이터 비트폭은 진일보로 조정할 필요가 있으며, 프로세서는 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확정하고, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 할 수 있다. 예를 들어, 제2 미리 설정된 반복간격은 한 훈련주기의 총반복수이다. 현재 반복이 제2 미리 설정된 반복 이상 인 경우, 프로세서는 제2 미리 설정된 반복간격에 근거하여 양자화 파라미터를 업데이트할 수 있다. 즉 각 훈련 주기（epoch）에서 양자화 파라미터를 1회 업데이트한다. 이 때, 각 훈련주기의 처음 반복은 하나의 검사 반복 으로서, 각 훈련주기의 처음 반복에서, 프로세서는 당해 검사 반복의 양자화 대상 데이터에 근거하여 양자화 오 차를 확정할 수 있으며, 양자화 오차에 근거하여 제2 오차를 확정하고, 다음과 같은 수학식에 따라 제2 오차가 미리 설정된 오차 값보다 큰지 여부를 확정한다. 여기에서, 는 제2 오차를 나타내고, 는 양자화 오차를 나타내며, 는 하이퍼 파라미터를 나타내 고, 는 미리 설정된 오차 값을 나타낸다. 바람직하게는, 당해 미리 설정된 오차 값은 제1 미리 설정된 한계 값 을 하이퍼 파라미터로 나눈 것과 같다. 물론, 당해 미리 설정된 오차 값은 하이퍼 파라미터일 수도 있다. 예를 들어, 당해 미리 설정된 오차 값은 다음과 같은 수학식에 따라 계산하여 획득할 수 있으며: =th/10, 여기에서, th는 제1 미리 설정된 한계 값을 나타내고, 하이퍼 파라미터의 값은 10이다. 제2 오차 가 미리 설정된 오차 값 보다 크면, 데이터 비트폭이 가능하게 미리 설정된 요구사항을 충족시 킬 수 없다는 것을 설명한다. 이 때, 제2 미리 설정된 반복간격을 채용하여 양자화 파라미터를 업데이트하지 않 아도 되며, 프로세서는 양자화 대상 데이터의 데이터 변동폭에 따라 목표반복간격을 확정하여 데이터 비트폭이 미리 설정되 요구사항을 충족시키도록 보장할 수 있다. 즉 제2 오차 가 미리 설정된 오차 값 보다 크면, 프로세서는 상술한 작업(S714)에서 상술한 작업(S713)으로 전환한다. 물론, 다른 실시예에서, 프로세서는 상술한 양자화 오차에 근거하여 데이터 비트폭을 조정할 필요가 있는지 여 부를 확정할 수 있다. 예를 들어, 제2 미리 설정된 반복간격은 한 훈련주기의 총반복수이다. 현재 반복이 제2 미리 설정된 반복 이상인 경우, 프로세서는 제2 미리 설정된 반복간격에 근거하여 양자화 파라미터를 업데이트 할 수 있다. 즉 각 훈련주기（epoch）에서 양자화 파라미터를 1회 업데이트한다 . 여기에서, 각 훈련주기의 처 음 반복은 하나의 검사 반복으로서, 각 훈련주기의 처음 반복에서, 프로세서는 당해 검사 반복의 양자화 대상 데이터에 근거하여 양자화 오차를 확정할 수 있으며, 당해 양자화 오차가 제1 미리 설정된 한계 값 이상인 경우, 데이터 비트폭이 가능하게 미리 설정된 요구사항을 충족시킬 수 없다는 것을 설명한다. 즉 프로세서는 상 술한 작업(S714)에서 상술한 작업(S713)으로 전환한다. 하나의 바람직한 실시예에서, 상술한 점 위치, 스케일 팩터 및 오프셋 등 양자화 파라미터는 표시장치를 통해 표시될 수 있다. 이 때, 사용자는 표시장치를 통해 신경망 연산과정에서의 양자화 파라미터를 알 수 있으며, 사 용자는 지기 적응적으로 프로세서가 확정한 양자화 파라미터를 수정할 수도 있다. 마찬가지로, 상술한 데이터 비트폭과 목표반복간격 등도 표시장치를 통해 표시될 수 있다. 이 때, 사용자는 표시장치를 통해 신경망 연산과 정에서의 목표반복간격과 데이터 비트폭 등 파라미터를 알 수 있고, 또한 사용자는 자기 적응적으로 프로세서가 확정한 목표반복간격과 데이터 비트폭 등 파라미터를 수정할 수도 있다. 설명할 필요가 있는 것은, 상술한 각 방법 실시예에 대하여, 설명의 편의를 위해, 이들을 동작의 일련 조합으로"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 36, "content": "서 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 본 발명은 설명된 동작의 순서에 의해 한정되지 않는다는 것을 인식해야 한다. 본 발명에 따르면, 특정 단계는 다른 순서를 채용하거나 동시에"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 37, "content": "수행할 수 있기 때문이다. 따라서, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 명세서에서 설명 된 실시예는 모두 선택할 수 있는 실시예에 속하며, 관련되는 동작과 모듈은 반드시 본 발명에 필수적인 것이 아니라는 것도 인식해야 한다. 본 발명의 일 실시예는 신경망의 양자화 파라미터 조정장치도 제공하는 바, 당해 양자화 파라미터 조정장 치는 프로세서에 배치될 수 있다. 예를 들어, 당해 양자화 파라미터 조정장치는 범용 프로세서에 배 치할 수도 있고, 또한, 당해 양자화 파라미터 조정장치는 인공지능 프로세서에 배치될 수도 있다. 도3-20에 도 시된 바와 같이, 상기 장치는, 양자화 대상 데이터의 데이터 변동폭을 획득하기 위한 획득모듈; 및 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 신경망 연산에서의 양자화 파라미터를 조정하도록 하기 위한 반복간격 확정모듈을 포함하며, 여 기에서, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. 바람직하게는, 상기 양자화 파라미터는 상기 양자화 대상 데이터에 대응하는 양자화 데이터 중 소수점의 위치인 점 위치를 포함한다. 도3-21에 도시된 바와 같이, 상기 장치는, 현재 검사 반복에 대응하는 목표데이터 비트폭과 상기 현재 검사 반복의 양자화 대상 데이터에 근거하여 상기 목표반복간격 중 반복에 대응하는 점 위치를 확정함으로써, 상기 신경망 연산에서의 점 위치를 조정하도록 하기 위한 양자화 파라미터 확정모듈을 더 포함하며; 여기에서, 상기 목표반복간격 중 반복에 대응하는 점 위치가 일치하다. 바람직하게는, 상기 양자화 파라미터는 상기 양자화 대상 데이터에 대응하는 양자화 데이터 중 소수점의 위치인 점 위치를 포함하며; 도3-23 또는 도3-24에 도시된 바와 같이, 상기 장치는, 상기 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여 상기 목표반복간격에 대응하는 데이터 비트폭을 확정하는 데 사용되고, 여기에서, 상기 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치한 데이터 비트 폭 확정모듈; 및 획득한 점 위치 반복간격과 상기 목표반복간격에 대응하는 데이터 비트폭에 근거하여 상기 목표반복간격 중 반 복에 대응하는 점 위치를 조정하여 상기 신경망 연산에서의 점 위치를 조정하도록 하기 위한 양자화 파라미터 확정모듈을 포함하며; 여기에서, 상기 점 위치 반복간격은 적어도 1회 반복을 포함하며, 상기 점 위치 반복간격 중 반복되는 점 위치 가 일치하다. 바람직하게는, 상기 점 위치 반복간격은 상기 목표반복간격 이하이다. 바람직하게는, 상기 양자화 파라미터는 상기 점 위치와 동기적으로 업데이트되는 스케일 팩터를 더 포함한다. 바람직하게는, 상기 양자화 파라미터는 상기 점 위치와 동기적으로 업데이트되는 오프셋을 더 포함한다. 바람직하게는, 도3-24에 도시된 바와 같이, 상기 데이터 비트폭 확정모듈은, 상기 현재 검사 반복의 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여 양자화 오차를 확정하는 데 사용되고, 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 현재 검사 반복의 양자화 대상 데이터를 양자화하여 획득하는 양자화 오차 확정유닛 ; 및 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정하기 위한 데이터 비트 폭 확정유닛을 포함한다. 바람직하게는, 상기 데이터 비트폭 확정유닛은 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응 하는 목표데이터 비트폭을 확정하기 위해 사용될 때, 구체적으로, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 증가 하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하고; 또는, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 감소 하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 데 사용된다. 바람직하게는, 상기 데이터 비트폭 확정유닛은 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 상 기 현재 검사 반복에 대응하는 데이터 비트폭을 증가하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 데 사용될 때, 구체적으로, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 제1 미리 설정된 비트폭 스텝에 근거하여 제1 중간 데 이터 비트폭을 확정하며; 상기 현재 검사 반복에서 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제1 미리 설정된 한계 값 미만이 될 때까지 양자화 오차를 확정하는 데로 되돌아 가는 데에 사용되 며; 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 제1 중간 데이터 비트폭에 근거하여 상기 현재 검 사 반복의 양자화 대상 데이터를 양자화하여 획득한다. 바람직하게는, 상기 데이터 비트폭 확정유닛은, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 감소하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭 을 획득하는 데 사용될 때, 구체적으로, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 제2 미리 설정된 비트폭 스텝에 의해 제2 중간 데이터 비트폭을 확정하고; 상기 현재 검사 반복에서 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제2 미리 설정된 한계 값보다 클 때까지 양자화 오차를 확정하는 데로 되돌아 가는 데에 사용되며; 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 제2 중간 데이터 비트폭에 근거하여 상기 현재 검사 반복의 양자화 대상 데이터를 양자화하여 획득한다. 바람직하게는, 상기 획득모듈은, 점 위치의 변동폭을 획득하기 위한 제1 획득모듈을 포함하며; 여기에서, 상기 점 위치의 변동폭은 상기 양 자화 대상 데이터의 데이터 변동폭을 특성화하는 데 사용할 수 있으며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭과 정의 상관이 있다. 바람직하게는, 도3-23 또는 도3-24에 도시된 바와 같이, 상기 제1 획득모듈은, 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복에 대응하는 점 위치에 근거하여 제1 균치를 확정하는 데 사용되며, 여기에서, 상기 전회 검사 반복은 상기 목표반복간격 전 의 전회 반복간격에 대응하는 검사 반복인 제1 균치 확정유닛; 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균 치를 확정하는 데 사용되며; 여기에서, 상기 현재 검사 반복에 대응하는 점 위치는 상기 현재 검사 반복에 대응 하는 목표데이터 비트폭과 양자화 대상 데이터에 의해 확정되는 제2 균치 확정유닛; 및 상기 제1 균치와 상기 제2 균치에 근거하여 상기 점 위치의 변동폭을 특성화하기 위한 제1 오차를 확정하기 위 한 제1 오차확정유닛을 포함한다. 바람직하게는, 상기 제2 균치 확정유닛은 구체적으로, 미리 설정된 수의 중간 이동평균 값을 획득하며, 여기에서, 각 상기 중간 이동평균 값은 상기 현재 검사 반복하 기 전 상기 미리 설정된 수의 검사 반복에 근거하여 확정되고; 상기 현재 검사 반복의 점 위치 및 상기 미리 설정된 수의 중간 이동평균 값에 근거하여 상기 제2 균치를 확정 하는 데 사용된다. 바람직하게는, 상기 제2 균치 확정유닛은 구체적으로 상기 현재 검사 반복에 대응하는 점 위치 및 상기 제1 균치에 근거하여 상기 제2 균치를 확정하는 데 사용된다. 바람직하게는, 상기 제2 균치 확정유닛은 획득한 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하 여 상기 제2 균치를 업데이트하는 데 사용되며; 여기에서, 상기 현재 검사 반복의 데이터 비트폭 조정 값은 상기 현재 검사 반복의 목표데이터 비트폭과 초기 데이터 비트폭에 의해 확정된다. 바람직하게는, 상기 제2 균치 확정유닛은 획득한 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하 여 상기 제2 균치를 업데이트하는 데 사용될 때, 구체적으로, 상기 현재 검사 반복의 데이터 비트폭 조정 값이 미리 설정된 파라미터보다 클 경우, 상기 현재 검사 반복의 데 이터 비트폭 조정 값에 근거하여 상기 제2 균치를 감소하며; 상기 현재 검사 반복의 데이터 비트폭 조정 값이 미리 설정된 파라미터보다 작은 경우, 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제2 균치를 증가하는 데 사용된다. 바람직하게는, 상기 반복간격 확정모듈은 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하는 데 사 용되며, 상기 목표반복간격은 상기 제1 오차와 부의 상관이 있다. 바람직하게는, 상기 획득모듈은, 데이터 비트폭의 변화추세를 획득하기 위한 제2 획득모듈을 더 포함하며; 상기 점 위치의 변동폭과 상기 데이터 비트폭의 변화추세에 근거하여 상기 양자화 대상 데이터의 데이터 변동폭을 확정한다. 바람직하게는, 상기 반복간격 확정모듈은 획득한 점 위치의 변동폭을 특성화하기 위한 제1 오차와 데이터 비트폭의 변화추세를 특성화하기 위한제2 오차에 근거하여 상기 목표반복간격을 확정하는 데 사용된다. 바람직하게는, 상기 반복간격 확정모듈은 획득한 제1 오차와 제2 오차에 근거하여 상기 목표반복간격을 확 정하는 데 사용될 때, 구체적으로, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 하고; 상기 목표오차에 근거하여 상기 목표반복간격을 확정하는 데 사용되며, 여기에서, 상기 목표오차는 상기 목표반 복간격과 부의 상관이 있다. 바람직하게는, 상기 제2 오차는 양자화 오차에 의해 확정되고; 여기에서, 상기 양자화 오차는 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 의해 확정되며, 상기 제2 오차는 상기 양자화 오차와 정의 상관이 있다. 바람직하게는, 상기 장치는 신경망의 훈련 또는 미조정을 실현하는 데 적용되며; 상기 반복간격 확정모듈 은, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목 표반복간격을 확정하는 데 사용되며, 상기 목표반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 더 포함한다. 바람직하게는, 상기 반복간격 확정모듈은, 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 제1 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제1 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 데 사용된다. 바람직하게는, 상기 반복간격 확정모듈은, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 제2 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 데 사용되며; 여기에서, 상기 신경망의 수렴정도가 미리 설정된 조건을 충족시키면, 상기 현재 검사 반복이 제2 미리 설정된 반복 이상임을 확정하고; 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간격이 상기 제1 미리 설정된 반복간격보다도 크다. 바람직하게는, 상기 반복간격 확정모듈은, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 또 제2 오차가 미리 설정된 오차 값보다 큰 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확 정하며, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 하는 데 사용된다. 또한, 본 발명 실시예의 각 모듈 또는 유닛의 동작원리는 상술한 방법에서 각 작업의 실현과정과 실질적으로 일 치하며, 구체적인 것은 위의 설명을 참조하면 되고, 여기에서 다시 언급하지 않는다. 또한, 상술한 장치 실시예 는 단지 예시일 뿐이며, 본 발명의 장치는 다른 방식으로 실현할 수 있다는 것을 이해해야 한다. 예를 들어, 상 술한 실시예에서 상기 유닛/모듈의 구분은 단지 논리적 기능 구분일 뿐이며, 실제로 실현될 경우에는 다른 구분 방식이 있을 수 있다. 예를 들어, 복수의 유닛, 모듈 또는 컴포넌트가 결합될 수 있거나 다른 시스템에 통합되 거나 일부 특징을 무시 또는 실행하지 않을 수 있다. 상술한 통합된 유닛/모듈은 하드웨어의 형식을 채용하여 실현할 수도 있고, 소프트웨어 프로그램 모듈의 형식을 채용하여 실현할 수도 있다. 상기 통합된 유닛/모듈은 하드웨어의 형식으로 실현하는 경우, 당해 하드웨어는 디지털 회로, 아날로그 회로 등일 수 있다. 하드웨어 구 조의 물리적 실현은 트랜지스터, 멤 리스터 등을 포함하지만, 이들에 한정되지 않는다 . 상기 통합된 유닛/모듈은 소프트웨어 프로그램 모듈의 형식으로 실현되고 독립적인 제품으로 판매되거나 사용될 때 하나의 컴퓨터 판독 가능한 메모리에 저장될 수 있다. 이러한 이해에 따라, 본 발명의 기술방안은 본질적으 로 또는 종래기술에 공헌하는 부분 또는 당해 기술방안의 전부 또는 일부는 소프트웨어 제품의 형식으로 구현할 수 있으며, 당해 컴퓨터 소프트웨어 제품은 하나의 메모리에 저장되며, 컴퓨터기기（개인용 컴퓨터, 서버 또는 네트워크 기기 등일 수 있다）가 본 발명각 실시예에서 설명한 방법의 전부 또는 일부단계를 실행 하기 위한 복 수의 명령을 포함한다. 한편 전술한 메모리는 U 디스크, 읽기 전용 메모리（ROM, Read-Only Memory）, 랜덤 액 세스 메모리（RAM, Random Access Memory）, 모바일 하드 디스크, 자기 디스크 또는 광 디스크 등 각종 프로그 램 코드를 저장할 수있는 매체를 포함한다. 일 실시예에서, 본 발명은 컴퓨터 판독 가능한 저장매체도 제공하는 바, 당해 저장메체에는 컴퓨터 프로그램이 저장되어 있고, 당해 컴퓨터 프로그램이 프로세서 또는 장치에 의해 실행될 때, 상술한 바와 같은 임의의 실시 예 중의 방법을 실현한다. 구체적으로는, 당해 컴퓨터 프로그램은 프로세서 또는 장치에 의해 실행될 때, 다음 과 같은 방법을 실현한다. 양자화 대상 데이터의 데이터 변동폭을 획득한다. 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 신경망 연산에서의 양자화 파라미터를 조정하도록 하며, 여기에서, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. 또한, 본 발명 실시예의 각 작업의 실현은 상술한 방법에서 각 작업의 실현과정과 실질적으로 일치하며, 구체적 인 것은 위의 설명을 참조하면 되고, 여기에서 다시 언급하지 않는다. 상술한 실시예에서, 각 실시예의 설명은 모두 각자의 중점이 있으며, 특정 실시예에서 상세하게 설명되지 않고 있는 부분은, 다른 실시예의 관련된 설명을 참조하면 된다. 상술한 실시예의 각 기술특징은 임의로 조합할 수 있으며, 설명을 간결하게 하기 위해서, 상술한 실시예에서의 각 기술특징이 가능한 모든 조합에 대해서 설명하 지 않고 있지만, 이들 기술특징의 조합에 모순이 없는 한, 모두 본 명세서에 기재된 범위로 간주된다. 가능한 실현방식에서, 인공지능 칩도 개시하는 바, 이는 상술한 양자화 파라미터 조정장치를 포함하고 있다. 가능한 실현방식에서, 보드 카드도 개시하는 바, 이는 메모리 디바이스, 인터페이스 장치와 제어 디바이스 및 상술한 인공지능 칩을 포함하며; 여기에서, 상기 인공지능 칩은 상기 메모리 디바이스, 상기 제어 디바이스 및 상기 인터페이스 장치와 각각 연결되고; 상기 메모리 디바이스는 데이터를 저장하는 데 사용되고; 상기 인터페 이스 장치는 상기 인공지능 칩과 외부기기 사이의 데이터 전송을 실현하는 데 사용되며; 상기 제어 디바이스는 상기 인공지능 칩의 상태를 감시하는 데 사용된다. 도3-25은 본 발명 실시예에 따른 보드 카드를 나타내는 구조 블록도이다. 도3-25를 참조하면, 상술한 보드 카드 는 상술한 칩을 포함하는 외에도 다른 부대부품을 포함할 수 있다. 당해 부대부품은 메모리 디바이스 , 인터페이스 장치 및 제어 디바이스를 포함할 수 있지만, 이들에 한정되지 않는다. 상기 메모리 디바이스는 데이터를 저장하기 위해 베스를 통해 상기 인공지능 칩과 연결된다. 상기 메모리 디바이스는 복수 그룹의 저장유닛을 포함할 수 있다. 각 그룹의 상기 저장유닛은 버스를 통해 상기 인공지 능 칩과 연결된다. 또한, 각 그룹의 상기 저장유닛이 DDR SDRAM（영문: Double Data Rate SDRAM, 2배 속도 동 기적 다이나믹 랜덤메모리）일 수 있다는 것을 이해할 수 있다. DDR은 클록 주파수를 높이지 않고도 SDRAM의 속도를 2배로 할 수 있다. DDR은 클록 펄스의 상승 및 하강 에지에 서 데이터를 읽어 내는 것을 허용한다. DDR의 속도는 표준 SDRAM의 2배이다. 일 실시예에서, 상기 저장장치는 4 그룹의 상기 저장유닛을 포함할 수 있다. 각 그룹의 상기 저장유닛은 복수의 DDR4 입자（칩）를 포함할 수 있다. 일 실시예에서, 상기 인공지능 칩 내부는 4개의 72비트 DDR4 컨트롤러를 포함할 수 있으며, 상술한 72비 트 DDR4 컨트롤러 중 64bit는 데이터 전송에 사용되고, 8bit는 ECC검증에 사용된다. 또한, 각 그룹의 상기 저장 유닛에서 DDR4-3200 입자를 채용하는 경우, 데이터 전송의 이론 대역폭은 25600MB/s에 도달할 수 있다고 이해할 수 있다. 일 실시예에서, 각 그룹의 상기 저장유닛은 복수의 병렬로 배치한 2배 속도 동기적 다이나믹 랜덤 메모리를 포 함한다. DDR은 한 클록 주기 내에 데이터를 2회 전송할 수 있다. 상기 칩에 DDR을 제어하는 컨트롤러를 배치하 여 각 상기 저장유닛의 데이터 전송과 데이터 저장의 제어한다. 상기 인터페이스 장치는 상기 인공지능 칩과 전기적으로 연결된다. 상기 인터페이스 장치는 상기 인공지능 칩과 외부기기（예를 들어 서버 또는 컴퓨터） 사이의 데이터 전송을 실현하는 데 사용된다. 예를 들어 일 실시예에 서, 상기 인터페이스 장치는 표준 PCIE 인터페이스일 수 있다. 예를 들어, 처리될 데이터는 서버에서 표준 PCIE 인터페이스를 통해 상기 칩에 전달되어 데이터 이전을 실현한다. 바람직하게, PCIE 3.0 X 16 인터페이스를 채용 하여 전송하는 경우, 이론 대역폭은 16000MB/s에 달할 수도 있다. 다른 하나의 실시예에서, 상기 인터페이스 장 치는 다른 인터페이스일 수도 있고, 본 발명은 상술한 다른 인터페이스의 구체적인 표현형식을 한정하지 않으며, 상기 인터페이스 유닛은 이전기능을 실현하면 된다. 또한, 상기 인공지능 칩의 계산결과는 여전히 상기 인터페이스 장치에 의해 외부기기（예를 들어 서버）로 다시 전송된다. 상기 제어 디바이스는 상기 인공지능 칩과 전기적으로 연결된다. 상기 제어 디바이스는 상기 인공지능 칩의 상 태를 감시하는 데 사용된다. 구체적으로, 상기 인공지능 칩은 SPI 인터페이스를 통해 상기 제어 디바이스와 전 기적으로 연결될 수 있다. 상기 제어 디바이스는 단일 칩 마이크로 컴퓨터（Micro Controller Unit, MCU）를 포 함할 수 있다. 상기와 같이 인공지능 칩은 복수의 처리 칩, 복수의 처리 코아 또는 복수의 처리회로를 포함하여 복수의 부하를 구동할 수 있다. 따라서, 상기 인공지능 칩은 다부하와 경부하 등 상이한 동작상태에 있을 수 있 다. 상기 제어장치를 통해 상기 인공지능 칩 중 복수의 처리 칩, 복수의 처리 코아 또는 복수의 처리회로의 동작상태의 조정 및 제어를 실현할 수 있다. 가능한 실현방식에서, 상술한 인공지능 칩을 포함한 전자기기를 개시한다. 전자기기는 데이터 처리장치, 로봇, 컴퓨터, 프린터, 스캐너, 태블릿, 스마트 단말, 휴대전화, 드라이브 레코더, 네비게이션 장치, 센서, 카메라, 서버, 클라우드 서버, 카메라, 비디오 카메라, 프로젝터, 손목 시계, 헤드폰, 모바일 스토리지, 웨어러블 디바 이스, 교통수단, 가전제품, 및/또는 의료기기를 포함한다. 상기 교통수단은 항공기, 선박 및/또는 차량을 포함하며; 가전제품은 텔레비전, 에어컨, 전자렌지, 냉장고, 전 기밥솥, 가습기, 세탁기, 전등, 가스 버너, 레인지 푸드를 포함하고; 상기 의료기기는 핵자기 공명 장치, B-초 음파진단 장치 및/또는 심전계를 포함한다."}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 38, "content": "본 발명의 내용은 다음 조항에 따라 더 잘 이해될 것이다. C1, 신경망의 양자화 파라미터 조정방법에 있어서, 상기 방법은, 양자화 대상 데이터의 데이터 변동폭을 획득하는 것; 및 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 신경망 연산에서의 양자화 파라미터를 조정하도록 하는 것을 포함하며, 여기에서, 상기 목표반복간격 은 적어도 1회 반복을 포함하고, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. C2, 조항C1에 따른 방법에 있어서, 상기 양자화 파라미터는 상기 양자화 대상 데이터에 대응하는 양자화 데이터 중 소수점의 위치인 점 위치를 포함하며; 상기 방법은, 현재 검사 반복에 대응하는 목표데이터 비트폭과 상기 현재 검사 반복의 양자화 대상 데이터에 근거하여 상기 목표반복간격 중 반복에 대응하는 점 위치를 확정함으로써, 상기 신경망 연산에서의 점 위치를 조정하도록 하는 것을 더 포함하며; 여기에서, 상기 목표반복간격 중 반복에 대응하는 점 위치가 일치하다. C3, 조항C1에 따른 방법에 있어서, 상기 양자화 파라미터는 상기 양자화 대상 데이터에 대응하는 양자화 데이터 중 소수점의 위치인 점 위치를 포함하며; 상기 방법은, 상기 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여 상기 목표반복간격에 대응하는 데이터 비트폭을 확정하며, 여기에서, 상기 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치한 것; 및 획득한 점 위치 반복간격과 상기 목표반복간격에 대응하는 데이터 비트폭에 근거하여 상기 목표반복간격 중 반 복에 대응하는 점 위치를 조정하여 상기 신경망 연산에서의 점 위치를 조정하도록 하는 것을 포함하며; 여기에서, 상기 점 위치 반복간격은 적어도 1회 반복을 포함하며, 상기 점 위치 반복간격 중 반복되는 점 위치 가 일치한 것을 특징으로 한다. C4, 조항C2 또는 C3에 따른 방법에 있어서, 상기 점 위치 반복간격은 상기 목표반복간격 이하이다. C5, 조항C1-C4 중 어느 한 항에 따른 방법에 있어서, 상기 양자화 파라미터는 상기 점 위치와 동기적으로 업데 이트되는 스케일 팩터를 더 포함한다. C6, 조항C1-C5 중 어느 한 항에 따른 방법에 있어서, 상기 양자화 파라미터는 상기 점 위치와 동기적으로 업데 이트되는 오프셋을 더 포함한다. C7, 조항C1-C6 중 어느 한 항에 따른 방법에 있어서, 상기 방법은, 상기 현재 검사 반복의 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여 양자화 오차를 확정하며, 여기에서, 상기 현재 검사 반복의 양자화 데이터가 상기 현재 검사 반복의 양자화 대상 데이터의 양 자화에 의해 획득되는 것; 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정하는 것을 포함한다. C8, 조항C1-C7에 따른 방법에 있어서, 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이 터 비트폭을 확정하는 것은, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 증가 하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 것; 또는, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 감소 하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 것을 포함한다. C9, 조항C8에 따른 방법에 있어서, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 상기 현재 검사 반 복에 대응하는 데이터 비트폭을 증가하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 것은, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 제1 미리 설정된 비트폭 스텝에 근거하여 제1 중간 데 이터 비트폭을 확정하고; 상기 현재 검사 반복에서 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제1 미리 설정된 한계 값 미만이 될 때까지 양자화 오차를 확정하는 데로 되돌아 가는 것을 포함하 며, 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 제1 중간 데이터 비트폭에 근거하여 상기 현재 검 사 반복의 양자화 대상 데이터를 양자화하여 획득한 것이다. C10, 조항C8에 따른 방법에 있어서, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 상기 현재 검사 반 복에 대응하는 데이터 비트폭을 감소하는 것은, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 제2 미리 설정된 비트폭 스텝에 의해 제2 중간 데이터 비트폭을 확정하고; 상기 현재 검사 반복에서 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제2 미리 설정된 한계 값보다 클 때까지 양자화 오차를 확정하는 데로 되돌아 가는 것을 포함하며; 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 제2 중간 데이터 비트폭에 근거하여 상기 현재 검사 반 복의 양자화 대상 데이터를 양자화하여 획득한 것이다. C11, 조항C1-C10 중 어느 한 항에 따른 방법에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭을 획득하는 것은, 점 위치의 변동폭을 획득하는 것을 포함하며; 여기에서, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭을 특성화하는 데 사용할 수 있고, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭과 정의 상관이 있다. C12, 조항C1-C11에 따른 방법에 있어서, 상기 점 위치의 변동폭을 획득하는 것은, 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복에 대응하는 점 위치에 근거하여 제1 균치를 확정하며, 여기에서, 상기 전회 검사 반복은 상기 목표반복간격 전의 전회 반복 간격에 대응하는 검사 반복인 것; 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균 치를 확정하며; 여기에서, 상기 현재 검사 반복에 대응하는 점 위치는 상기 현재 검사 반복에 대응하는 목표데 이터 비트폭과 양자화 대상 데이터에 의해 확정된 것; 상기 제1 균치와 상기 제2 균치에 근거하여 상기 점 위치의 변동폭을 특성화하기 위한 제1 오차를 확정하는 것 을 포함한다. C13, 조항C12에 따른 방법에 있어서, 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이 력 반복의 점 위치에 근거하여 제2 균치를 확정하는 것은, 미리 설정된 수의 중간 이동평균 값을 획득하며, 여기에서, 각 상기 중간 이동평균 값은 상기 현재 검사 반복하 기 전 상기 미리 설정된 수의 검사 반복에 근거하여 확정된 것; 상기 현재 검사 반복의 점 위치 및 상기 미리 설정된 수의 중간 이동평균 값에 근거하여 상기 제2 균치를 확정 하는 것을 포함한다. C14, 조항C12에 따른 방법에 있어서, 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이 력 반복의 점 위치에 근거하여 제2 균치를 확정하는 것은, 상기 현재 검사 반복에 대응하는 점 위치 및 상기 제1 균치에 근거하여 상기 제2 균치를 확정하는 것을 포함한 다. C15, 조항C12에 따른 방법에 있어서, 상기 방법은 다음과 같은 단계를 더 포함한다: 획득한 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제2 균치를 업데이트하는 것을 더 포함 하며; 여기에서, 상기 현재 검사 반복의 데이터 비트폭 조정 값은 상기 현재 검사 반복의 목표데이터 비트폭과 초기 데이터 비트폭에 의해 확정된다. C16, 조항C15에 따른 방법에 있어서, 획득한 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제 2 균치를 업데이트하는 것은, 상기 현재 검사 반복의 데이터 비트폭 조정 값이 미리 설정된 파라미터보다 클 경우, 상기 현재 검사 반복의 데 이터 비트폭 조정 값에 근거하여 상기 제2 균치를 감소하는 것; 상기 현재 검사 반복의 데이터 비트폭 조정 값이 미리 설정된 파라미터보다 작은 경우, 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제2 균치를 증가하는 것을 포함한다. C17, 조항C12에 따른 방법에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확 정하는 것은, 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하는 것을 포함하며, 상기 목표반복간격은 상기 제1 오차와 부의 상관이 있다. C18, 조항C11-C17 중 어느 한 항에 따른 방법에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭을 획득하는 것은, 데이터 비트폭의 변화추세를 획득하는 것; 상기 점 위치의 변동폭과 상기 데이터 비트폭의 변화추세에 근거하여 상기 양자화 대상 데이터의 데이터 변동폭 을 확정하는 것을 더 포함한다. C19, 조항C18에 따른 방법에 있어서, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확 정하는 것은, 획득한 점 위치의 변동폭을 특성화하기 위한 제1 오차와 데이터 비트폭의 변화추세를 특성화하기 위한제2 오차 에 근거하여 상기 목표반복간격을 확정하는 것을 더 포함한다. C20, 조항C19에 따른 방법에 있어서, 획득한 상기 제2 오차와 상기 제1 오차에 근거하여 상기 목표반복간격을 확정하는 것은, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 하는 것; 상기 목표오차에 근거하여 상기 목표반복간격을 확정하는 것을 포함하며, 여기에서, 상기 목표오차는 상기 목표 반복간격과 부의 상관이 있다. C21, 조항C19 또는 C20에 따른 방법에 있어서, 상기 제2 오차는 양자화 오차에 의해 확정되고; 여기에서, 상기 양자화 오차는 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데 이터에 의해 확정되며, 상기 제2 오차는 상기 양자화 오차와 정의 상관이 있다. C22, 조항C1-C21 중 어느 한 항에 따른 방법에 있어서, 상기 방법은 신경망의 훈련 또는 미조정에 적용되며, 상 기 방법은, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목 표반복간격을 확정하며, 상기 목표반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 더 포함한다 . C23, 조항C22에 따른 방법에 있어서, 상기 방법은, 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 제1 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제1 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 더 포함한다. C24, 조항C22 또는 C23에 따른 방법에 있어서, 상기 방법은, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 제2 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 것을 더 포함하며 ; 여기에서, 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간 격이 상기 제1 미리 설정된 반복간격보다도 크다. C25, 조항C24에 따른 방법에 있어서, 상기 방법은, 상기 신경망의 수렴정도가 미리 설정된 조건을 충족시키면, 상기 현재 검사 반복이 제2 미리 설정된 반복 이상 임을 확정하는 것을 더 포함한다. C26, 조항C24에 따른 방법에 있어서, 상기 방법은, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 또 제2 오차가 미리 설정된 오차 값보다 큰 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 반복간격을 확정하며, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 하는 것을 더 포함한다. C27, 조항C1-C26 중 어느 한 항에 따른 방법에 있어서, 상기 양자화 대상 데이터는 뉴런 데이터, 가중치 데이터 또는 그래디언트 데이터 중의 적어도 한 가지이다. C28,메모리와 프로세서를 포함한 신경망의 양자화 파라미터 조정장치에 있어서, 상기 메모리에는 컴퓨터 프로그 램이 저장되어 있고, 상기 프로세서가 상기 컴퓨터 프로그램을 실행할 때, 조항C1-C27 중 어느 한 항에 따른 방 법의 단계를 실현한다. C29, 컴퓨터 판독 가능한 저장매체에 있어서, 상기 컴퓨터 판독 가능한 저장매체에는 컴퓨터 프로그램이 저장되 어 있고, 상기 컴퓨터 프로그램은 실행될 때, 조항C1-C27 중 어느 한 항에 따른 방법의 단계를 실현한다. C30, 신경망의 양자화 파라미터 조정장치에 있어서, 상기 장치, 양자화 대상 데이터의 데이터 변동폭을 획득하기 위한 획득모듈; 및 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목표반복간격을 확정함으로써, 상기 목표반복간격에 근거 하여 상기 신경망 연산에서의 양자화 파라미터를 조정하도록 하기 위한 반복간격 확정모듈을 포함하며, 여기에 서, 상기 목표반복간격은 적어도 1회 반복을 포함하고, 상기 신경망의 양자화 파라미터는 상기 신경망 연산 중 양자화 대상 데이터의 양자화 작업을 실현하는 데 사용된다. C31, 조항C30에 따른 장치에 있어서, 상기 양자화 파라미터는 상기 양자화 대상 데이터에 대응하는 양자화 데이 터 중 소수점의 위치인 점 위치를 포함하며; 상기 장치는, 현재 검사 반복에 대응하는 목표데이터 비트폭과 상기 현재 검사 반복의 양자화 대상 데이터에 근거하여 상기 목표반복간격 중 반복에 대응하는 점 위치를 확정함으로써, 상기 신경망 연산에서의 점 위치를 조정하도록 하기 위한 양자화 파라미터 확정모듈을 더 포함하며; 여기에서, 상기 목표반복간격 중 반복에 대응하는 점 위치가 일치하다. C32, 조항C30에 따른 장치에 있어서, 상기 양자화 파라미터는 상기 양자화 대상 데이터에 대응하는 양자화 데이 터 중 소수점의 위치인 점 위치를 포함하며; 상기 장치는, 상기 현재 검사 반복에 대응하는 목표데이터 비트폭에 근거하여 상기 목표반복간격에 대응하는 데이터 비트폭을 확정하는 데 사용되며, 여기에서, 상기 목표반복간격 중 반복에 대응하는 데이터 비트폭은 일치한 데이터 비트 폭 확정모듈; 및 획득한 점 위치 반복간격과 상기 목표반복간격에 대응하는 데이터 비트폭에 근거하여 상기 목표반복간격 중 반 복에 대응하는 점 위치를 조정하여 상기 신경망 연산에서의 점 위치를 조정하도록 하기 위한 양자화 파라미터 확정모듈을 더 포함하며; 여기에서, 상기 점 위치 반복간격은 적어도 1회 반복을 포함하며, 상기 점 위치 반복간격 중 반복되는 점 위치 가 일치하다. C33, 조항C 32에 따른 장치에 있어서, 상기 점 위치 반복간격은 상기 목표반복간격 이하이다. C 34, 조항C 31- C 33 중 어느 한 항에 따른 장치에 있어서, 상기 양자화 파라미터는 상기 점 위치와 동기적으 로 업데이트되는 스케일 팩터를 더 포함한다. C 35, 조항C 31- C 33 중 어느 한 항에 따른 장치에 있어서, 상기 양자화 파라미터는 상기 점 위치와 동기적으 로 업데이트되는 오프셋을 더 포함한다. C 36, 조항C 31- C 33 중 어느 한 항에 따른 장치에 있어서, 상기 데이터 비트폭 확정모듈은, 상기 현재 검사 반복의 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여 양자화 오차를 확정하는 데 사용되며, 여기에서, 상기 현재 검사 반복의 양자화 데이터가 상기 현재 검사 반복의 양자화 대상 데이터의 양자화에 의해 획득되는 양자화 오차 확정유닛; 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정하기 위한 데이터 비트 폭 확정유닛을 포함한다. C 37, 조항C36에 따른 장치에 있어서, 상기 데이터 비트폭 확정유닛은 상기 양자화 오차에 근거하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 확정할 때 구체적으로, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 증가 하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하고; 또는, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 감소 하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득하는 데 사용된다. C 38, 조항C 37에 따른 장치에 있어서, 상기 데이터 비트폭 확정유닛은 상기 양자화 오차가 제1 미리 설정된 한 계 값 이상이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 증가하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득할 때 구체적으로, 상기 양자화 오차가 제1 미리 설정된 한계 값 이상이면, 제1 미리 설정된 비트폭 스텝에 근거하여 제1 중간 데 이터 비트폭을 확정하고; 상기 현재 검사 반복에서 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제1 미리 설정된 한계 값 미만이 될 때까지 양자화 오차를 확정하는 데로 되돌아 가는 것을 포함하 며, 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 제1 중간 데이터 비트폭에 근거하여 상기 현재 검 사 반복의 양자화 대상 데이터를 양자화하여 획득된다. C 39, 조항C 37에 따른 장치에 있어서, 상기 데이터 비트폭 확정유닛은 상기 양자화 오차가 제2 미리 설정된 한 계 값 이하이면, 상기 현재 검사 반복에 대응하는 데이터 비트폭을 감소하여 상기 현재 검사 반복에 대응하는 목표데이터 비트폭을 획득할 때 구체적으로, 상기 양자화 오차가 제2 미리 설정된 한계 값 이하이면, 제2 미리 설정된 비트폭 스텝에 의해 제2 중간 데이터 비트폭을 확정하고; 상기 현재 검사 반복에서 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데이터에 근거하여, 상기 양자화 오차가 상기 제2 미리 설정된 한계 값보다 클 때까지 양자화 오차를 확정하는 데로 되돌아 가는 것을 포함하며; 여기에서, 상기 현재 검사 반복의 양자화 데이터는 상기 제2 중간 데이터 비트폭에 근거하여 상기 현재 검사 반 복의 양자화 대상 데이터를 양자화하여 획득된다. C 40, 조항C 30- C 39 중 어느 한 항에 따른 장치에 있어서, 상기 획득모듈은, 점 위치의 변동폭을 획득하기 위한 제1 획득모듈을 포함하며; 여기에서, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭을 특성화하는 데 사용할 수 있으며, 상기 점 위치의 변동폭은 상기 양자화 대상 데이터의 데이터 변동폭과 정의 상관이 있다. C 41, 조항C 40에 따른 방법에 있어서, 상기 제1 획득모듈은, 현재 검사 반복 전의 전회 검사 반복에 대응하는 점 위치, 및 상기 전회 검사 반복 전의 이력 반복에 대응하는 점 위치에 근거하여 제1 균치를 확정하는 데 사용되며, 여기에서, 상기 전회 검사 반복은 상기 목표반복간격 전 의 전회 반복간격에 대응하는 검사 반복인 제1 균치 확정유닛; 상기 현재 검사 반복에 대응하는 점 위치 및 상기 현재 검사 반복 전의 이력 반복의 점 위치에 근거하여 제2 균 치를 확정하는 데 사용되며; 여기에서, 상기 현재 검사 반복에 대응하는 점 위치는 상기 현재 검사 반복에 대응 하는 목표데이터 비트폭과 양자화 대상 데이터에 의해 확정되는 제2 균치 확정유닛; 및 상기 제1 균치와 상기 제2 균치에 근거하여 상기 점 위치의 변동폭을 특성화하기 위한 제1 오차를 확정하기 위 한 제1 오차 확정유닛을 포함한다. C 42, 조항C 41에 따른 장치에 있어서, 상기 제2 균치 확정유닛은 구체적으로, 미리 설정된 수의 중간 이동평균 값을 획득하며, 여기에서, 각 상기 중간 이동평균 값은 상기 현재 검사 반복하 기 전 상기 미리 설정된 수의 검사 반복에 근거하여 확정되고; 상기 현재 검사 반복의 점 위치 및 상기 미리 설정된 수의 중간 이동평균 값에 근거하여 상기 제2 균치를 확정 하는 데 사용된다. C 43, 조항C 41에 따른 장치에 있어서, 상기 제2 균치 확정유닛은 구체적으로 상기 현재 검사 반복에 대응하는 점 위치 및 상기 제1 균치에 근거하여 상기 제2 균치를 확정하는 데 사용된다. C 44, 조항C 41에 따른 장치에 있어서, 상기 제2 균치 확정유닛은 획득한 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제2 균치를 업데이트하는 데도 사용되며; 여기에서, 상기 현재 검사 반복의 데이터 비트폭 조정 값은 상기 현재 검사 반복의 목표데이터 비트폭과 초기 데이터 비트폭에 의해 확정된다. C 45, 조항C 44에 따른 장치에 있어서, 상기 제2 균치 확정유닛은 획득한 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제2 균치를 업데이트하는 데 사용되될 때, 구체적으로, 상기 현재 검사 반복의 데이터 비트폭 조정 값이 미리 설정된 파라미터보다 클 경우, 상기 현재 검사 반복의 데 이터 비트폭 조정 값에 근거하여 상기 제2 균치를 감소하고 상기 현재 검사 반복의 데이터 비트폭 조정 값이 미리 설정된 파라미터보다 작은 경우, 상기 현재 검사 반복의 데이터 비트폭 조정 값에 근거하여 상기 제2 균치를 증가하는 데 사용된다. C 46, 조항C 41에 따른 장치에 있어서, 상기 반복간격 확정모듈은 상기 제1 오차에 근거하여 상기 목표반복간격 을 확정하는 데 사용되며, 상기 목표반복간격은 상기 제1 오차와 부의 상관이 있다. C 47, 조항C 40에 따른 장치에 있어서, 상기 획득모듈은, 데이터 비트폭의 변화추세를 획득하고; 상기 점 위치의 변동폭과 상기 데이터 비트폭의 변화추세에 근거하여 상 기 양자화 대상 데이터의 데이터 변동폭을 확정하기 위한 제2 획득모듈을 더 포함한다. C 48, 조항C 47에 따른 장치에 있어서, 획득한 점 위치의 변동폭을 특성화하기 위한 제1 오차와 데이터 비트폭 의 변화추세를 특성화하기 위한제2 오차에 근거하여 상기 목표반복간격을 확정하기 위한 상기 반복간격 확정모 듈을 더 포함한다. C 49, 조항C 48에 따른 장치에 있어서, 상기 반복간격 확정모듈은 획득한 제1 오차와 제2 오차에 근거하여 상기 목표반복간격을 확정하는 데 사용될 때 구체적으로, 상기 제1 오차와 상기 제2 오차 중 최대 값을 목표오차로 하고; 상기 목표오차에 근거하여 상기 목표반복간격을 확정하는 데 사용되며, 여기에서, 상기 목표오차는 상기 목표반 복간격과 부의 상관이 있다. C 50, 조항C 48 또는 C 49에 따른 장치에 있어서, 상기 제2 오차는 양자화 오차에 의해 확정되고; 여기에서, 상기 양자화 오차는 상기 현재 검사 반복 중 양자화 대상 데이터와 상기 현재 검사 반복의 양자화 데 이터에 의해 확정되며, 상기 제2 오차는 상기 양자화 오차와 정의 상관이 있다. C 51, 조항C 30- C 50 중 어느 한 항에 따른 장치에 있어서, 상기 장치는 신경망의 훈련 또는 미조정을 실현하 는 데 적용되며; 상기 반복간격 확정모듈은, 상기 현재 반복이 제1 미리 설정된 반복보다 클 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거하여 목 표반복간격을 확정하며, 상기 목표반복간격에 근거하여 상기 양자화 파라미터를 조정하는 데 사용된다. C 52, 조항C 51에 따른 장치에 있어서, 상기 반복간격 확정모듈은 상기 현재 반복이 상기 제1 미리 설정된 반복 이하인 경우, 제1 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제1 미리 설정된 반복간격에 근거 하여 상기 양자화 파라미터를 조정하는 데도 사용된다 . C 53, 조항C 51또는 C 52에 따른 장치에 있어서, 상기 반복간격 확정모듈은, 상기 현재 반복이 제2 미리 설정된 반복 이상인 경우, 제2 미리 설정된 반복간격을 상기 목표반복간격으로 하고, 상기 제2 미리 설정된 반복간격에 근거하여 상기 양자화 파라미터를 조정하는 데 사용되고; 여기에서, 상기 신경망의 수렴정도가 미리 설정된 조건을 충족시키면, 상기 현재 검사 반복이 제2 미리 설정된 반복 이상임을 확정하며; 상기 제2 미리 설정된 반복이 상기 제1 미리 설정된 반복보다도 크고, 상기 제2 미리 설정된 반복간격이 상기 제1 미리 설정된 반복간격보다도 크다. C 54, 조항C 53에 따른 장치에 있어서, 상기 반복간격 확정모듈은, 상기 현재 반복이 제2 미리 설정된 반복 이 상인 경우, 또 제2 오차가 미리 설정된 오차 값보다 큰 경우, 상기 양자화 대상 데이터의 데이터 변동폭에 근거 하여 반복간격을 확정하며, 상기 반복간격에 근거하여 상기 데이터 비트폭을 다시 확정하도록 하는데 사용된다. 이상, 본 발명의 각 실시예를 설명하였으며, 상술한 설명은 예시적인 것일 뿐이고, 전체적인 것이 아니며, 또한 개시된 각 실시예에 한정되는 것이 아니다. 설명된 실시예의 범위 및 정신을 일탈할 일 없고, 당업자에 있어서 수정 및 변경의 대부분은 자명하다. 본명세서로 사용되는 용어의 선택은, 본명세서로 공개된 실시예의 원리, 실"}
{"patent_id": "10-2020-7038081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 39, "content": "제의 적용, 또는 시장에 있어서의 기술의 개량을 가장 잘 설명하는 것, 또는 본 기술분야의 다른 당업자가 본 명세서로 공개된 실시예를 이해가 가도록 하는 것을 목적으로 한다. 위에서 양자화 파라미터 조정의 문제를 해결하기 위해 제안한 방안（201910528537.8）을 설명하였다."}
{"patent_id": "10-2020-7038081", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하, 본 발명 실시예의 기술방안을 보다 명확하게 설명하기 위해 실시예의 도면에 대해 간단히 설명하지만, 다 음에 설명되는 도면이 본 발명의 일부 실시예에 불과하며 본 발명에 대한 제한이 아닌 것은 분명할 것이다. 도1은 신경망구조의 모식도이고; 도2는 본 발명에 따른 신경망의 양자화 파라미터 확정방법의 흐름도이고; 도3은 대칭되는 고정 소수점 수를 나타내는 모식도이고; 도4는 오프셋이 도입된 고정 소수점 수를 나타내는 모식도이고; 도5A는 훈련과정에 있어서 신경망의 가중치 데이터 변동폭의 제1 그래프이고; 도5B는 훈련과정에 있어서 신경망의 가중치 데이터 변동폭의 제2 그래프이고; 도6은 목표반복간격을 확정하는 방법의 제1 흐름도이고; 도7은 목표반복간격을 확정하는 방법의 제2 흐름도이고; 도8A는 목표반복간격을 확정하는 방법의 제3 흐름도이고; 도8B는 본 발명의 일 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도8C는 본 발명의 다른 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도8D는 본 발명의 또 다른 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도8E는 본 발명의 또 하나의 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도8F는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이고; 도8G는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이고; 도8H는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이고; 도8I는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이고; 도8J는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이고; 도8K는 본 발명의 일 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도8L은 본 발명의 일 실시예의 양자화 대상 데이터의 연산과정 중 변동추세를 나타내는 도이고; 도8M은 본 발명의 일 실시예의 파라미터 조정방법 중 목표반복간격의 확정방법을 나타내는 흐름도이고; 도8N은 본 발명의 일 실시예에 있어서 포인트 위치 변동폭의 확정방법을 나타내는 흐름도이고; 도8O는 본 발명의 일 실시예에 있어서 제2 균치의 확정방법을 나타내는 흐름도이고; 도8P는 본 발명의 다른 실시예에 있어서 제2 균치의 확정방법을 나타내는 흐름도이고; 도8Q는 본 발명의 다른 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도8R은 본 발명의 일 실시예의 양자화 파라미터 조정방법 중 양자화 파라미터의 조정을 나타내는 흐름도이고; 도8S는 본 발명의 다른 실시예의 파라미터 조정방법 중 목표반복간격의 확정방법을 나타내는 흐름도이고; 도8T는 본 발명의 또 다른 실시예의 파라미터 조정방법 중 목표반복간격의 확정방법을 나타내는 흐름도이고; 도8U는 본 발명의 또 다른 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도8V는 본 발명의 또 하나의 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도9는 본 발명에 제안된 신경망의 양자화 파라미터 확정장치의 하드웨어 구성의 블록도이고; 도10은 본 발명에 제안된 신경망의 양자화 파라미터 확정장치를 인공지능 프로세서 칩에 적용한 응용 모식도이 고; 도11은 본 발명에 제안된 신경망의 양자화 파라미터 확정기기의 기능 블록도이고; 도12는 본 발명 실시예의 보드 카드의 구조 블록도이다. 신경망의 양자화 문제를 해결하기 위해, 다음과 같은 방안（중국특허출원 제201910505239.7호）에 포함된 도13 내지 도43을 제공한다. 도13은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도14는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도15은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도16는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도17는 본 발명 실시예에 따른 신경망의 양자화방법 중 양자화 파라미터가 오프셋을 포함하지 않을 때 양자화 전후의 데이터를 나타내는 대응 모식도이다. 도18은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도19은 본 발명 실시예에 따른 신경망의 양자화방법 중 양자화 파라미터가 오프셋을 포함할 때 양자화 전후의 데이터를 나타내는 대응 모식도이다. 도20은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도21는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도22은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도23은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도24는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도25은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도26는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도27는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도28은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도29은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도30은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도31는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도32은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도33은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도34는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도35은 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도36는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도37는 본 발명 실시예에 따른 신경망의 양자화방법을 나타내는 흐름도이다. 도38은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도39은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도40은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도41는 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도42은 본 발명 실시예에 따른 신경망 양자화장치를 나타내는 모식도이다. 도43은 본 발명 실시예에 따른 보드 카드를 나타내는 구조 블록도이다. 양자화 파라미터의 조정문제를 해결하기 위해, 다음과 같은 방안（중국특허출원 제201910528537.8호）에 포함된 도44 내지 도675을 제공한다. 도44은 본 발명의 일 실시예의 양자화 파라미터 조정방법의 적용환경을 나타내는 모식도이고; 도45는 본 발명의 일 실시예의 양자화 대상 데이터와 양자화 데이터의 대응관계를 나타내는 모식도이고; 도46은 본 발명의 일 실시예의 양자화 대상 데이터를 나타내는 변환 모식도이고; 도47는 본 발명의 일 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도48는 본 발명의 일 실시예의 양자화 대상 데이터의 연산과정 중 변동추세를 나타내는 도이고; 도49은 본 발명의 일 실시예의 파라미터 조정방법 중 목표반복간격의 확정방법을 나타내는 흐름도이고; 도50은 본 발명의 일 실시예에 있어서 포인트 위치 변동폭의 확정방법을 나타내는 흐름도이고; 도51은 본 발명의 일 실시예에 있어서 제2 균치의 확정방법을 나타내는 흐름도이고; 도52는 본 발명의 일 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도53은 본 발명의 다른 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도54은 본 발명의 또 다른 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도55는 본 발명의 또 하나의 실시예에 있어서 데이터 비트폭 조정방법을 나타내는 흐름도이고; 도56은 본 발명의 다른 실시예에 있어서 제2 균치의 확정방법을 나타내는 흐름도이고; 도57는 본 발명의 다른 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도58는 본 발명의 일 실시예의 양자화 파라미터 조정방법 중 양자화 파라미터의 조정을 나타내는 흐름도이고; 도59은 본 발명의 다른 실시예의 파라미터 조정방법 중 목표반복간격의 확정방법을 나타내는 흐름도이고; 도60은 본 발명의 또 다른 실시예의 파라미터 조정방법 중 목표반복간격의 확정방법을 나타내는 흐름도이고; 도61은 본 발명의 또 다른 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도62는 본 발명의 또 하나의 실시예의 양자화 파라미터 조정방법을 나타내는 흐름도이고; 도63은 본 발명의 일 실시예의 양자화 파라미터 조정장치를 나타내는 구조 블록도이고; 도64은 본 발명의 일 실시예의 양자화 파라미터 조정장치를 나타내는 구조 블록도이고; 도65는 본 발명의 일 실시예의 양자화 파라미터 조정장치를 나타내는 구조 블록도이고; 도66은 본 발명의 일 실시예의 양자화 파라미터 조정장치를 나타내는 구조 블록도이고; 도67는 본 발명의 일 실시예의 양자화 파라미터 조정장치를 나타내는 구조 블록도이고; 도68는 본 발명 실시예에 따른 보드 카드를 나타내는 구조 블록도이다."}
