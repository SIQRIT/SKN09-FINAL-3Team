{"patent_id": "10-2023-0101837", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0093317", "출원번호": "10-2023-0101837", "발명의 명칭": "인공 지능 자세 추정 모델 및 동작 분석 모델을 이용한 운동 치료 제공 방법, 그리고 시스템", "출원인": "에버엑스 주식회사", "발명자": "김병훈"}}
{"patent_id": "10-2023-0101837", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "의사(doctor) 단말기로부터, 환자(patient)에 대한 운동과 관련된 처방 정보를 수신하는 단계;상기 처방 정보에 근거하여, 상기 환자의 계정에, 적어도 하나의 처방 운동을 포함하는 운동 플랜을 할당하는단계;환자 단말기로부터, 상기 처방 운동에 따른 운동을 촬영한 운동 영상을 수신하는 단계;인공 지능 자세 추정 모델을 이용하여, 상기 운동 영상으로부터, 기 설정된 복수의 관절 포인트에 각각 대응되는 키포인트를 추출하는 단계;인공 지능 동작 분석 모델을 통해, 상기 키포인트 간의 상대적인 위치 관계를 분석하고, 상기 위치 관계에 대한분석에 기초하여, 상기 처방 운동에 대한 상기 환자의 운동 동작을 분석하는 단계; 및상기 환자의 운동 동작에 대한 분석 결과를, 상기 환자 단말기에 전송하는 단계를 포함하는 인공 지능 동작 분석 모델을 이용한 운동 치료 제공 방법."}
{"patent_id": "10-2023-0101837", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 환자의 운동 동작을 분석하는 방법 및 시스템에 관한 것이다. 본 발명에 따른 운동 치료 제공 방법은, 본 발명에 따른 인공 지능 동작 분석 모델을 이용한 운동 치료 제공 추정 방법은, 의사(doctor) 단말기로부터, 환자(patient)에 대한 운동과 관련된 처방 정보를 수신하는 단계, 상기 처방 정보에 근거하여, 상기 환자의 계정 (뒷면에 계속)"}
{"patent_id": "10-2023-0101837", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 근골격계 질환에 특화된 인공 지능 자세 추정 모델 및 인공 지능 동작 분석 모델을 이용하여, 환자에 게 운동 치료를 제공할 수 있는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0101837", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근골격계 질환이란, 근육, 신경, 건, 인대, 뼈와 주변조직 등 근골격계에 발생하는 통증 또는 손상을 말한다. 근골격계 질환은 목과 허리, 팔과 다리 등 우리 몸의 다양한 곳에 나타난다. 세계보건기구 (WHO-World Health Organization)의 보고에 따르면, 근골격계 질환으로 인한 경제적 손실은 전체 질환 중 네번째로 높은 것으로 나타났으며, 근골격계 질환은 일상 생활 뿐만 아니라 경제 활동에도 영향을 미치 는 만성적인 통증이다. 한편, 근골격계 질환의 치료는, 침습적인 정도가 적은 치료부터 시행되는 것이 원칙으로, 비약물 보존적 치료 (ex: 운동 치료 및 교육, 인지 치료 또는 이완 요법 등)가 먼저 시행되고, 이후 약물치료, 수술적 치료가 순차 적으로 고려되어야 한다. 치료 지침에서는, 근골격계 질환의 비약물 보존적 치료를 적극적으로 권장하고 있으며, 미국 및 유럽을 중심으 로, 근골격계 질환의 비약물 보존적 치료를 수행하는 방법에 대한 연구가 활발하게 진행되고 있다. 한편, 기술이 발전함에 따라, 전자기기(예를 들어, 스마트폰, 태블릿 PC 등)의 보급이 대중화되었으며, 이에 따 라 일상생활의 많은 부분에서 인터넷에 대한 의존도가 점차적으로 높아지고 있다. 이와 같이, 인터넷을 비롯한 다양한 기술의 발전에 힘입어, 종래 오프라인에 대한 의존도가 높았던 소비패턴은, 점차적으로 온라인(on-line)으로 옮겨갔으며, 현재에는, 온라인을 중심으로 한 소비가 기하급수적으로 늘어가고 있다. 이러한 트렌드의 변화에 맞추어, 의료 산업과 같은 서비스의 특성상 오프라인(off-line)에 기반을 둔 산업 분야 역시, 온라인을 통하여 의료 서비스를 제공하는 것이 보편화 되고 있다. 이에, 최근에는, 온라인을 통한 다양한 의료 서비스가 제공되고 있으며, 환자, 즉 사용자는 인터넷이 연결된 전 자기기를 통해, 몇번의 클릭 만으로, 의료진과 질병에 대한 의료 상담을 할 수 있게 되었다. 이러한 기술로서, 대한민국 등록특허 제10-2195512호는 온라인 의료 플랫폼을 제공하는 서버 및 시스템과 관련 된 기술을 개시하고 있으며, 온라인을 통한 의료 서비스 제공 지점에 대한 정보를 환자에게 제공하고 있다. 이러한 트렌드에 맞추어, 근골격계 질환의 비약물 보존적 치료를 온라인으로 제공하는 방법에 니즈가 존재한다."}
{"patent_id": "10-2023-0101837", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은, 온라인을 기반으로 근골격계 질환에 대한 운동 치료를 제공할 수 있는 운동 치료 제공 방법 및 시스 템에 관한 것이다. 특히, 본 발명은, 운동 영상을 기반으로, 처방된 운동을 수행하는 환자의 운동 동작을 분석할 수 있는 운동 치 료 제공 방법 및 시스템에 관한 것이다. 특히, 본 발명은 근골격계 질환에 특화된 인공 지능 모델에 기반하여, 운동 영상으로부터 환자의 운동 동작을 분석할 수 있는 운동 치료 제공 방법 및 시스템에 관한 것이다. 나아가, 본 발명은, 환자가 근골격계 질환의 치료에 용이하게 접근 가능한 사용자 환경을 제공할 수 있는 운동 치료 제공 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0101837", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "위에서 살펴본 과제를 해결하기 위하여, 본 발명에 따른 운동 치료 제공 방법은, 의사(doctor) 단말기로부터, 환자(patient)에 대한 운동과 관련된 처방 정보를 수신하는 단계, 상기 처방 정보에 근거하여, 상기 환자의 계 정에, 적어도 하나의 처방 운동을 포함하는 운동 플랜을 할당하는 단계, 환자 단말기로부터, 상기 처방 운동에 따른 운동을 촬영한 운동 영상을 수신하는 단계, 인공 지능 자세 추정 모델을 이용하여, 상기 운동 영상으로부 터, 기 설정된 복수의 관절 포인트에 각각 대응되는 키포인트를 추출하는 단계, 인공 지능 동작 분석 모델을 통 해, 상기 키포인트 간의 상대적인 위치 관계를 분석하고, 상기 위치 관계에 대한 분석에 기초하여, 상기 처방 운동에 대한 상기 환자의 운동 동작을 분석하는 단계 및 상기 환자의 운동 동작에 대한 분석 결과를, 상기 환자 단말기에 전송하는 단계를 포함할 수 있다. 나아가, 본 발명에 따른 운동 치료 제공 추정 방법은, 상기 환자 단말기에서 상기 운동 영상이 촬영되는 것에 연동하여, 상기 환자 단말기에 상기 운동 영상을 실시간으로 출력하는 단계 및 상기 환자가, 상기 환자의 운동 동작에 대해 분석이 이루어지는 관절 포인트를 인지가능 하도록, 상기 운동 영상 중 상기 환자에 대응되는 피사 체가 위치한 영역에, 추출된 상기 키포인트에 해당하는 그래픽 객체를 오버랩하여 제공하는 단계를 더 포함할 수 있다. 일 예에 있어서, 상기 키포인트를 추출하는 단계에서는, 상기 기 설정된 복수의 관절 포인트 중, 상기 운동 영 상에서 가시(visible) 가능한 상기 피사체의 가시 관절 포인트를 특정하고, 특정된 상기 가시 관절 포인트를 상 기 키포인트로서 추출할 수 있다. 일 예에 있어서, 상기 동작 분석 모델은, 상기 학습 데이터에 기반하여, 상기 기 설정된 복수의 관절 포인트 중 상기 운동 영상에서 가시(visible) 불가능한 상기 피사체의 비가시(invisible) 관절 포인트를 예측하고, 상기 가시 관절 포인트와 상기 비가시 관절 포인트에 기반하여, 상기 환자의 운동 동작을 분석할 수 있다. 이 경우, 상기 키포인트는, 상기 가시 관절 포인트 및 상기 비가시 관절 포인트에 해당하는 키포인트를 포함할 수 있다. 일 예에 있어서, 상기 학습 데이터는, 학습 대상 영상에 포함된 피사체의 학습 대상 가시 관절 포인트 및 상기 가시 관절 포인트에 기반하여 추정되는 학습 대상 비가시 관절 포인트에 대한 위치 정보가 순차적으로 나열된 제1 데이터 그룹 및 상기 학습 대상 가시 관절 포인트 및 상기 학습 대상 비가시 관절 포인트 각각의 가시 여부 를 나타내는 데이터 값을 포함하는 제2 데이터 그룹을 포함할 수 있다. 이 경우, 상기 제2 데이터 그룹에 포함된 데이터 값의 나열 순서는, 상기 학습 대상 가시 관절 포인트 및 상기 학습 대상 비가시 관절 포인트가 나열된 순서와 동일한 순서를 갖을 수 있다. 일 예에 있어서, 기 환자의 운동 동작을 분석하는 단계에서는, 상기 처방 운동과 관련된 규칙 정보를 기준으로, 상기 키포인트 간의 상대 위치 관계를 분석하고, 상기 키 포인트 간의 상대 위치 관계가 상기 규칙 정보를 만족 하는지 판단하는 것을 통해 상기 환자의 운동 동작을 분석할 수 있다.일 예에 있어서, 상기 운동 영상에 오버랩되는 그래픽 객체의 시각적 외관은, 추출된 상기 키포인트 간의 상대 위치 관계가 상기 규칙 정보를 만족하는지 여부에 따라 서로 다르게 이루어질 수 있다. 일 예에 있어서, 상기 환자의 운동 동작에 대한 분석 결과는, 상기 운동 영상이 상기 환자 단말기에서 촬영되고 있는 상태에서, 상기 키포인트에 해당하는 상기 그래픽 객체를 상기 규칙 정보에 근거한 서로 다른 시각적 외관 으로, 상기 운동 영상에 실시간으로 오버랩하여 제공하는 제1 분석 결과 및 상기 운동 영상을 구성하는 복수의 프레임들 각각으로부터 추출된 키포인트에 기초하여 상기 처방 운동에 대한 상기 환자의 평가 점수를 포함하는 제2 분석 결과를 포함할 수 있다. 이 경우, 상기 제1 분석 결과는 상기 환자 단말기에 설치된 애플리케이션의 동작 분석 모델에 의해서 생성되고, 상기 제2 분석 결과는, 상기 애플리케이션과 연동하는 클라우드 서버에서 이루어지며, 상기 제1 분석 결과 및 상기 제2 분석 결과 모두는, 상기 의사 단말기로 전송될 수 있다. 나아가, 본 발명에 따른 운동 치료 운동 치료 제공 시스템은, 의사(doctor) 단말기로부터, 환자(patient)에 대 한 운동과 관련된 처방 정보를 수신하는 통신부 및 상기 처방 정보에 근거하여, 상기 환자의 계정에, 적어도 하 나의 처방 운동을 포함하는 운동 플랜을 할당하는 제어부를 포함하고, 상기 제어부는, 환자 단말기로부터, 상기 처방 운동에 따른 운동을 촬영한 운동 영상을 수신하고, 상기 운동 영상으로부터, 기 설정된 복수의 관절 포인 트에 각각 대응되는 키포인트를 추출하고, 인공 지능 동작 분석 모델을 통해, 상기 키포인트 간의 상대적인 위 치 관계를 분석하고, 상기 위치 관계에 대한 분석에 기초하여, 상기 처방 운동에 대한 상기 환자의 운동 동작을 분석하고, 상기 환자의 운동 동작에 대한 분석 결과를, 상기 환자 단말기에 전송할 수 있다. 나아가, 본 발명에 따른 운동 치료 제공 시스템은, 의사(doctor) 단말기로부터, 환자(patient)에 대한 운동과 관련된 처방 정보를 수신하는 통신부 및 상기 처방 정보에 근거하여, 상기 환자의 계정에, 적어도 하나의 처방 운동을 포함하는 운동 플랜을 할당하는 제어부를 포함하고, 상기 제어부는, 환자 단말기로부터, 상기 처방 운동 에 따른 운동을 촬영한 운동 영상을 수신하고, 인공 지능 동작 분석 모델을 이용하여, 상기 운동 영상으로부터, 상기 처방 운동에 대한 상기 환자의 운동 동작을 분석하고, 상기 환자의 운동 동작에 대한 분석 결과를, 상기 환자 단말기에 전송하는 것을 특징으로 한다. 나아가, 전자기기에서 하나 이상의 프로세스에 의하여 실행되며, 컴퓨터로 판독될 수 있는 기록매체에 저장된 프로그램은, 의사(doctor) 단말기로부터, 환자(patient)에 대한 운동과 관련된 처방 정보를 수신하는 단계, 상 기 처방 정보에 근거하여, 상기 환자의 계정에, 적어도 하나의 처방 운동을 포함하는 운동 플랜을 할당하는 단 계, 환자 단말기로부터, 상기 처방 운동에 따른 운동을 촬영한 운동 영상을 수신하는 단계, 상기 운동 영상으로 부터, 기 설정된 복수의 관절 포인트에 각각 대응되는 키포인트를 추출하는 단계, 인공 지능 동작 분석 모델을 통해, 상기 키포인트 간의 상대적인 위치 관계를 분석하고, 상기 위치 관계에 대한 분석에 기초하여, 상기 처 방 운동에 대한 상기 환자의 운동 동작을 분석하는 단계 및 상기 환자의 운동 동작에 대한 분석 결과를, 상기 환자 단말기에 전송하는 단계를 수행하는 명령어들을 포함할 수 있다."}
{"patent_id": "10-2023-0101837", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "위에서 살펴본 것과 같이, 본 발명에 따른 운동 치료 제공 시스템 및 방법은, 의사(doctor) 단말기로부터, 환자 (patient)에 대한 운동과 관련된 처방 정보를 수신하고, 상기 처방 정보에 근거하여, 상기 환자의 계정에, 적어 도 하나의 처방 운동을 포함하는 운동 플랜을 할당할 수 있다. 이를 통해, 근골격계 질환에 대한 운동 치료를 위해 의사와 환자의 대면이 없더라도, 의사는 환자에게 처방이 가능하고, 환자는 의사의 처방에 따른 운동 플랜 을 제공받음으로써, 운동 치료에 대한 장소적, 시간적, 경제적 제약을 해결하고, 운동 치료에 대한 접근성을 높 일 수 있다. 나아가, 본 발명에 따른 운동 치료 제공 시스템 및 방법은, 운동 영상으로부터, 기 설정된 복수의 관절 포인트 에 각각 대응되는 키포인트를 추출함으로써, 근골격계 질환의 운동 치료에 필요한 관절에 포커스(Focus)를 맞추 어 사용자의 운동 동작을 분석할 수 있다. 나아가, 본 발명에 따른 운동 치료 제공 시스템 및 방법은, 관절 포인트에 대한 위치 정보를 포함하는 학습 데 이터 세트(data set)를 이용하여 학습된 자세 추정 모델에 기반하여, 운동 영상에 포함된 사용자의 특정 운동 동작과 관련된 운동 동작을 분석할 수 있다. 이를 통해, 본 발명에서는 운동 영상으로부터 환자의 자세에 대한 정확한 분석이 가능하며, 특히, 환자의 관절 가동 범위, 정렬 상태 및 이탈 상태 등에 대한 정보를 획득하여 의 료 서비스의 퀄리티(quality)를 향상시킬 수 있다.나아가, 본 발명에 따른 운동 치료 제공 시스템 및 방법은, 환자의 운동 동작에 대한 분석 결과를, 상기 환자 단말기에 전송함으로써, 환자는 먼 거리에 위치하는 병원에 직접 방문하지 않더라도 운동 영상에 대한 피드백 (feedback)을 제공받아 운동 치료 효과를 제고할 수 있으며, 운동에 대한 환자의 순응도를 향상시킬 수 있다."}
{"patent_id": "10-2023-0101837", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소에는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설 명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼 용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실 시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 발명은 환자(Patient)의 단말기로부터 수신되는 운동 영상에 기반하여, 운동 영상에 포함된 환자의 운동 동 작을 분석하고, 분석 결과를 제공하기 위한 것이다. 특히, 본 발명은, 근골격계 질환에 특화된 인공 지능 모델 을 이용하여, 환자의 관절 포인트를 기반으로 운동 동작을 분석하는 방법에 대한 것이다. 본 발명에서는, 근골격계 질환에 대한 재활 운동의 운동 동작 분석을 중심으로 설명하나, 반드시 이에 한정되는 것은 아니다. 즉, 본 발명에서 동작 분석은, 운동 동작 뿐만 아니라, 일상 생활에서의 동작, 스트레칭(Stretc h)시 동작 등 다양한 동작에 대한 분석을 모두 포함할 수 있다. 한편, 본 발명에서 설명되는 “운동 동작”은 운동을 수행하는 과정에서 이루어지는 몸짓(동작)으로, 몸의 “움 직임”, “액션(action)”, “무브먼트(movement)”, “제스처(gesture)”등의 용어와 혼용하여 사용될 수 있다. 그리고, “운동 영상”은, 도 6에 도시된 것과 같이, 환자가 운동 동작을 수행하는 과정이 촬영(포함)된 영상 (이미지 또는 동영상)으로, 환자(U)의 신체 중 적어도 일부가 포함될 수 있다. 본 발명에서는, 운동 영상에 포함된 환자 객체를, “피사체(U)”로 명명하여 설명할 수 있다. 본 발명에서 “피 사체(U)”는 운동 영상에서 운동하는 환자 또는 환자의 신체 일부를 의미할 수 있다. 본 발명에서는, “피사체 ”와 “환자”를 혼용하여 사용할 수 있으며, 동일한 도면부호 “U”를 부여하여 설명할 수 있다. 이하에서는 첨부된 도면과 함께, 본 발명에 따른 인공 지능 자세 추정 모델 및 동작 분석 모델을 이용한 운동 치료 제공 방법 및 시스템에 대해 구체적으로 설명하도록 한다. 도 1은 본 발명에 따른 운동 치료 제공 시스템 을 설명하기 위한 개념도이다. 도 2 및 도 3은 본 따른 운동 치료 제공 방법을 설명하기 위한 흐름도들이고, 도 4a 및 도 4b는 의사의 처방을 설명하기 위한 개념도들이고, 도 5 및 도 6은 운동 영상으로부터 환자의 운동 동 작을 분석하는 방법을 설명하기 위한 개념도들이고, 도7, 도 8a 도 8b, 도 8c, 도 8d, 도 8e 및 도 8f은 인공 지능 자세 추정 모델을 설명하기 위한 개념도들이며, 도 9a, 도 9b 및 도9c는 환자의 운동 동작 분석 결과가 제 공되는 사용자 환경을 설명하기 위한 개념도들이다. 도 1에 도시된 것과 같이, 본 발명에 따른 운동 치료 제공 시스템은, 인공 지능 자세 추정 및 동작 분석 모델을 이용하여, 환자 단말기로부터 수신된 운동 영상에서 환자의 운동 동작을 분석하는 것으로, 환자 단 말기에 설치되는 애플리케이션(Application, 100) 및 인공지능 서버(또는 클라우드 서버, 200) 중 적어도 하나를 포함하여 구성될 수 있다. 그리고, 본 발명에 따른 운동 치료 제공 시스템은, 학습 데이터를 이용 하여 학습된 자세 추정 모델 및 동작 분석 모델을 포함할 수 있다. 본 발명에서의 애플리케이션은, 환자 단말기에 설치되어 근골격계 질환을 갖고 있는 환자(U)의 운동 동작을 분석하고, 분석 결과에 기반한 피드백(Feedback) 정보를 제공하는 기능을 수행할 수 있다. 이에 본 발명 에 따른 애플리케이션은, “디지털 운동 치료 솔루션”, “디지털 재활 치료 솔루션”, “디지털 운동 평 가 솔루션”, “비대면 운동 치료 솔루션”, “비대면 재활 치료 솔루션”, “비대면 운동 평가 솔루션”, “모 바일 운동 치료 프로그램”, “모바일 재활 치료 프로그램”, “모바일 운동 평가 프로그램” 및 “모바일 정형 외과 재활 보조원(Mobile Orthopedic Rehabilitation Assistant, MORA) 등으로 명명될 수 있다. 본 발명에 따른 애플리케이션은, 환자 단말기에 설치되어, 근골격계 질환의 환자(U)와 정형외과 의사 (D)를 연결하여, 환자(U)의 재활을 도와주는 역할을 수행할 수 있다. 이하에서는 설명의 편의를 위하여 환자 단 말기에 설치되는 애플리케이션을, “운동 치료 애플리케이션”으로 명명하여 설명하도록 한다. 한편, 본 발명에 따른 운동 치료 애플리케이션은, 환자 단말기에 설치될 수 있다. 본 발명에서 설명되 는 환자 단말기는, 환자(U)의 사용자 계정으로 로그인된 전자기기를 의미하는 것으로서, 예를 들어, 전자기 기는 스마트폰(smart phone), 휴대폰, 태블릿 PC, 키오스크(KIOSK), 컴퓨터, 노트북, 디지털방송용 단말, PDA(Personal Digital Assistants), 및 PMP(Portable Multimedia Player) 중 적어도 하나를 포함할 수 있다. 여기에서, 환자(U)의 사용자 계정은, 본 발명에 따른 운동 치료 제공 시스템에 기 등록된 환자(U)의 계정 을 의미할 수 있다. 이러한 환자(U)의 사용자 계정은, “환자 계정” 또는 “환자 ID(identification, identification number)”로 이해되어질 수 있다. 본 발명에서, “환자”, “환자 계정(또는 환자의 사용자 계 정)”, “환자 단말기”를 혼용하여 사용할 수 있다. 한편, 의사(Doctor)는, 의사 단말기를 통해 환자(U)에게 운동과 관련된 처방을 내릴 수 있다. 본 발명에서 의사 단말기는, 의사(D)의 사용자 계정으로 로그인된 전자기기를 의미할 수 있다. 의사(D)의 사용자 계정은, 본 발명에 따른 운동 치료 제공 시스템에 기 등록된 의사(D)의 계정으로, “의사 계정” 또는 “ 의사 ID(identification, identification number)”로 이해되어질 수 있다. 본 발명에서, “의사”, “의사 계 정(또는 의사의 사용자 계정)”, “의사 단말기”를 혼용하여 사용할 수 있다. 의사(D)는, 환자(U)의 사용자 정보가 포함된 사용자 DB를 참조하여, 환자(U)에 대한 처방을 내릴 수 있다. 사용자 DB에는, 환자 계정 각각에 매칭된 환자(U)의 사용자 정보(또는 환자 정보)가 존재할 수 있다. 환자 (U)의 사용자 정보는, 운동 치료 제공에 필요한 다양한 정보를 포함할 수 있다. 예를 들어, 환자(U)의 사용자 정보는, 환자(U)의 질병 정보, 나이 정보, 성별 정보, 수술 이력 정보, 운동 플랜 정보, 운동 수행 정보, 신장 정보, 체중 정보 중 적어도 하나를 포함할 수 있다. 다만, 상술한 환자의 사용자 정보는 일 예시에 불과하며, 환자의 사용자 정보에는, 환자의 운동 치료 제공을 위하여 필요한 다양한 정보가 포함될 수 있음은 당연하다. 한편, 본 발명에서 설명되는 운동 치료 애플리케이션은, 환자 단말기에 설치되며, 의사(D) 처방에 따 라 운동을 수행한 환자의 운동 동작을, 인공 지능 자세 추정 모델 및 인공지능 동작 분석 모델을 통해 분석하여환자 단말기 상에 제공할 수 있다. 그리고, 운동 치료 애플리케이션은, 인공지능 서버와 통신을 수행하도록 이루어질 수 있으며, 인공지 능 서버에 의해 분석된 환자의 운동 동작 분석 결과를, 환자 단말기 상에 제공할 수 있다. 인공지능 서버에 의해 분석된 환자의 운동 동작 분석 결과는, 동작 분석부에 포함된 인공 지능 동작 분석부 및 규칙기반 동작 분석부 중 적어도 하나에 의하여 생성될 수 있다. 운동 치료 애플리케이션은, 인공지능 서버와 무선 통신을 통하여, 상호 데이터를 송수신하도록 이루 어지며, 무선 통신방식에는 제한이 없다. 본 발명에 따른 운동 치료 애플리케이션은 환자 단말기에 구 비된 통신 모듈을 이용하여, 인공지능 서버와의 통신을 수행할 수 있다. 환자 단말기에 구비된 통신 모듈을 다양할 수 있다. 예를 들어, 환자 단말기에 구비된 통신 모듈은, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi- Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G(5th Generation Mobile Telecommunication ), 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra-Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 인공지능 서버와 통신을 수행하도록 이루어질 수 있다. 한편, 본 발명에서 설명되는 인공지능 서버는, 운동 영상으로부터 환자(U)의 운동 동작 분석을 수행하는 클라우드 서버(Cloud Server)일 수 있다. 이러한 인공지능 서버는 운동 치료 애플리케이션으로부터 수신된 운동 영상을 이용하여, 환자(U)의 운동 동작에 대한 분석을 수행할 수 있다. 본 발명에서 설명되는 “인 공지능 서버”는, “인공지능 운동 치료 서버”, “인공지능 재활 치료 서버”, “디지털 치료 서버” 등으로 명명될 수 있다. 이하에서는 설명의 편의를 위하여, “인공지능 서버”로 명명하여 설명하도록 한다. 한편, 본 발명에 따른 운동 치료 애플리케이션 및 인공지능 서버 중 적어도 하나는, 도 7에 도시된 것과 같이, 관절 포인트와 관련된 학습 데이터를 이용하여 학습된 자세 추정 모델(52, 도 1의 인공 지능 자세 추정부(121a)에 대응)을 통해 운동 영상으로부터, 추출된 환자(U)의 복수의 관절 포인트에 대응되는 키포 인트(P1, P2) 간의 상대적인 위치 관계를 분석할 수 있다. 키포인트 간의 상대적인 위치 분석은, 동작 분석부 (120, 210)에 의하여 이루어질 수 있다. 특히, 동작 분석부의 인공지능 동작 분석부(122, 212) 및 규칙기반 동 작 분석부(123, 213) 중 하나에 의하여, 운동 동작 분석이 이루어질 수 있다. 인공지능 동작 분석부(122, 212) 또는 규칙기반 동작분석부(123, 213) 중 하나는 인공 지능 동작 분석 모델이라고 명명될 수 있다. 여기에서, “관절 포인트”는, 환자(U)의 복수의 관절(또는 관절을 포함하는 환자(U) 신체의 일부)를 의미할 수 있다. 그리고, “키포인트”는, 운동 영상에서 피사체(U)의 복수의 관절 포인트 각각에 대응되는 영역을 의미할 수 있다. 이에, 본 발명에서는, “관절 포인트”와 “키포인트”를 혼용하여 사용할 수 있으며, 관절 포인트와 키포인트 각각에, 동일한 도면부호 “P1, P2”를 부여하여 설명할 수 있다. 운동 치료 제공 시스템은, 상기 자세 추정 모델을 이용하여, 환자의 운동 영상으로부터 관절 포인트 에 대응하는 키포인트(P1, P2)를 추출하고, 추출된 키포인트(P1, P2) 간의 위치 관계에 대한 분석에 기반하여, 환자(U)의 운동 동작을 분석할 수 있다. 본 발명에서는, 인공 지능 자세 추정 모델을 통해 추출된 키포인트 를 이용하여, 운동 영상으로부터 환자의 운동 동작을 분석하는 일련의 프로세스를, “운동 동작 분석 프로세스 ”로 명명할 수 있다. 이러한 운동 동작 분석 프로세스는, 운동 치료 애플리케이션 및 인공지능 서버 중 적어도 하나에 의 해 수행될 수 있다. 구체적으로, 운동 동작 분석 프로세스는, i) 운동 치료 애플리케이션에 의해 이루어지 는 제1 데이터 처리 방법, ii) 인공지능 서버에 의해 이루어지는 제2 데이터 처리 방법, iii) 운동 치료 애플리케이션 및 인공지능 서버 모두에 의해 이루어지는 제3 데이터 처리 방법 중 적어도 하나를 포 함할 수 있다. 여기에서, 제3 데이터 처리 방법은, 운동 치료 애플리케이션과 인공지능 서버 각각에서, 데이터 처리 가 순차적으로 이루어지거나 동시에 이루어질 수 있다. 이에, 본 발명에서는, 운동 동작 분석 프로세스가 이루어지는 물리적인 공간 및 주체를 별도로 구분하지 않고, 운동 치료 제공 시스템에서 이루어지는 것으로 설명할 수 있다. 한편, 도 7에 도시된 것과 같이, 운동 동작 분석 프로세스는, 인공 지능 자세 추정 모델에서 추출된 키포인 트를 이용하여 이루어질 수 있다. 인공 지능 자세 추정 모델은, 관절 포인트에 특화된 학습 데이터에 대한 학습을 통해 운동 영상으로부터 환자의 관절 포인트를 특정 또는 추정하고, 이에 대응되는 키포인트를 추출할 수 있다. 본 발명에서, 인공 지능 자세 추정 모델이 학습을 수행하는 학습 데이터는, 데이터베이스에 저장되어 존재할 수 있으며, 이러한 데이터베이스는, “학습 데이터 DB”로도 명명될 수 있다. 학습 데이터에 대한 자세한 내용은 후술하도록 한다. 도 7에 도시된 것과 같이, 자세 추정 서버는, 학습부 및 자세 추정 모델 중 적어도 하나를 포함할 수 있다. 자세 추정 서버는, 본 발명에 따른 운동 치료 제공 시스템 내부에 구비되거나, 외부 서버로 이루어질 수 있다. 즉, 본 발명에 따른 자세 추정 서버는, 자세 추정에 대한 학습을 수행하는 기능을 수행 하는 것으로, 물리적인 공간에 대한 제약은 없는 것으로 이해될 수 있다. 자세 추정 서버에 대한 자세한 내 용은, 학습 데이터와 함께 후술하도록 한다. 한편, 도 1에 도시된 것과 같이, 본 발명에 따른 운동 치료 애플리케이션은, 영상 수신부, 동작 분석 부, 영상 처리부 및 제어부 중 적어도 하나의 구성을 포함할 수 있다. 운동 치료 애플리케이션의 영상 수신부는, 애플리케이션이 설치된 환자 단말기로부터 환자 의 운동 모습이 포함된 운동 영상을 수신하도록 이루어질 수 있다. 이러한 운동 영상은 환자 단말기에 설치 된 카메라에 의해 촬영될 수 있다. 본 발명에서, “환자 단말기로부터 운동 영상을 수신한다”는 것은, 운 동 치료 애플리케이션의 영상 수신부가 환자 단말기의 메모리(Memory)에 기록되는 운동 영상에 접근(access)하는 것으로 이해될 수 있다. 운동 치료 애플리케이션의 동작 분석부는, 환자 단말기로부터 수신된 운동 영상에 근거하여, 환 자의 운동 동작(또는 운동 자세) 분석을 수행할 수 있다. 이를 위해, 운동 치료 애플리케이션의 동작 분석 부는, 키포인트 추출부, 인공지능 동작분석부 및 규칙기반 동작분석부 중 적어도 하나의 구성을 포함하여 이루어질 수 있다. 인공지능 동작분석부 또는 규칙기반 동작분석부는 “인공 지능 동작 분석 모델”로 명명될 수 있다. 키포인트 추출부는, 운동 영상으로부터, x축, y축 좌표 정보가 쌍을 이룬 형태로 이루어지는 키포인트(P1, P2)를 추출할 수 있다. 이 경우, 키포인트 추출부는, 인공지능 모델을 이용하여, 영상으로부터 키포인트를 추출할 수 있다. 본 발명에서, 인공지능 모델을 이용한 키포인트 추출은, 키포인트 추출부에 포함된 인공지능 자세 추정부 (121a)에 의해 이루어지는 것으로 설명할 수 있다. 인공지능 자세 추정부(121a)는, “인공 지능 자세 추정 모델”으로 명명될 수 있으며, 영상으로부터 객체 탐지 (Object Detection)를 위하여 학습된 인공지능 모델을 이용하여, 운동 영상으로부터 환자의 관절 포인트에 대응 되는 키포인트를 추출할 수 있다. 인공 지능 자세 추정 모델은, 객체 탐지를 기반으로하는 모델일 수 있다. 예 를 들어, 인공지능 자세 추정부(121a)는 복수의 바운딩 박스(Bounding Box)를 앙상블(ensemble)하는 객체 탐지 인공지능 모델을 이용하여 운동 영상으로부터 키포인트를 추출할 수 있다. 한편, 인공지능 자세 추정부(121a)는, 다양한 객체 탐지 인공지능 모델을 이용할 수 있으며, 상술한 객체 탐지 인공지능 모델은 일 예시에 해당한다. 나아가, 본 발명에서, 인공지능 동작분석부 및 규칙기반 동작 분석부는, 환자 단말기로부터 수신된 운동 영상 및 키포인트 추출부에서 추출된 키포인트 중 적어도 하나를 이용하여, 환자의 운동 동작(또는 운동 자세)에 대한 분석을 수행할 수 있다. 보다 구체적으로, 인공지능 동작분석부 및 규칙기반 동작분석부는, i) 운동 영상에 기반하여 환자의 운동 동작에 대한 분석을 수행하거나, ii) 키포인트에 기반하여 환자의 운동 동작에 대한 분석을 수행하거나, iii) 운동 영상 및 키포인트를 모두 이용하여 환자의 운동 동작에 대한 분석을 수행할 수 있다. 이하에서는, 설명의 편의를 위하여, 키포인트에 기반하여 환자의 운동 동작 분석을 수행하는 방법을 중점적으로 설명하도록 한다. 다만, 인공지능 동작분석부 및 규칙기반 동작분석부는, 키포인트가 아닌 운동 영상 을 입력 데이터(Input data)로 입력 받아, 운동 영상으로부터 바로 환자의 운동 동작 분석을 수행할 수 있음은 당연하다. 한편, 인공지능 동작 분석부 또는 규칙기반 동작 분석부는 앞서 언급된 “인공 지능 동작 분석 모델”로도 표현될 수 있다. 한편, 인공지능 동작분석부는, 키포인트로부터 환자의 운동 동작(또는 운동 자세) 분석을 위해 학습된 인 공 지능 모델(또는 자세 추정 모델, 도7에서 도면부호 “52” 참조)에 기반하여, 환자가 수행하는 운동의 운동 종류 분류(또는 운동 종류 특정), 운동 동작의 정확도 판단을 수행할 수 있다. 그리고, 규칙 기반 동작분석부는, 환자의 운동 동작 분석을 위하여 정의된 규칙 정보에 기반하여, 환자가 수행하는 운동의 운동 종류 분류(또는 운동 종류 특정), 운동 동작의 정확도 판단을 수행할 수 있다. 여기에서, “규칙 정보”는, 운동 동작 분석에 이용되는 다양한 규칙을 포함하는 정보로, 예를 들어, 운동 동작 (또는 운동 종류)별 기준 관절 가동 범위 정보를 포함할 수 있다. 이러한 규칙 정보는, “참조(Reference) 정보 ”, “기준 정보” 등의 용어와 혼용되어 사용될 수 있다. 나아가, 규칙 정보는, 관절의 가동 범위 외에도, 관절의 가동 거리, 관절의 움직임 속도(또는 가속도), 분석 대 상 운동 영상에 포함된 피사체(환자에 대응)의 신체 밸런스, 신체 균형, 신체 정렬 상태(EX: 다리의 축 정렬 상 태, 척추 정렬상태 등) 중 적어도 하나에 대한 분석을 수행하기 위한 다양한 규칙 정보를 포함할 수 있다. 규칙 기반 동작분석부는 이러한 규칙 정보에 기반하여, 환자의 분석 대상 운동 영상으로부터 다양한 분석 결과 를 도출할 수 있다. 본 발명에서는, 인공지능 동작분석부 및 규칙 기반 동작분석부 중 적어도 하나에 의해, 운동 영상으 로부터 환자의 운동 동작에 대한 분석을 수행할 수 있다. 구체적으로, 본 발명에서는, i) 인공지능 동작분석부에 의해 환자의 운동 동작에 대한 분석 수행이 이루어 지거나(“제1 분석 수행 방식”), ii) 규칙 기반 동작분석부에 의해 환자의 운동 동작에 대한 분석 수행이 이루어지거나(“제2 분석 수행 방식”), iii) 인공지능 동작분석부 및 규칙 기반 동작분석부 모두에 의해 환자의 운동 동작에 대한 분석이 이루어질 수 있다(“제3 분석 수행 방식”). 여기에서, 제3 분석 수행 방식은, 인공지능 동작분석부 및 규칙 기반 동작분석부 각각에서, 데이터 처리가 순차적으로 이루어지거나 동시에 이루어질 수 있다. 한편, 운동 치료 애플리케이션의 영상 처리부는, 운동 영상에 포함된 환자의 피사체(U)에, 추출 된 키포인트(P1, P2)에 해당하는 그래픽 객체를 오버랩(overlap) 또는 렌더링(rendering)하도록 이루어질 수 있 다. 이를 통해, 환자는, 자신의 운동 동작에 대해 분석이 이루어지는 관절 포인트를 직관적으로 인지할 수 있다. 운동 치료 애플리케이션의 제어부는, 운동 치료 애플리케이션에 포함된 구성들에 대한 전반적인 제어를 수행하도록 이루어질 수 있다. 운동 치료 애플리케이션의 제어부는, 환자 단말기의 CPU(Central Processing Unit)를 이용하여 운동 치료 애플리케이션의 구성들을 제어할 수 있으며, 나아가, 환자 단말기에 구비된 구성(ex: 통신 모듈, 카메라 모듈, 센싱 모듈, 출력 모듈(ex: 디스플레이, 스피커), 입력 모듈(ex: 터치 스크린, 마이크)에 대한 제어를 수행할 수 있다. 한편, 도 1에 도시된 것과 같이, 인공지능 서버는, 인공 지능 자세 추정 모델을 이용하여 환자의 운동 자 세를 수행하도록 이루어진 클라우드 서버로, 동작 분석부 및 제어부 중 적어도 하나의 구성을 포함하 여 이루어질 수 있다. 인공지능 서버의 동작 분석부는, 환자 단말기로부터 수신된 운동 영상에 근거하여, 환자의 운동 동작(또는 운동 자세) 분석을 수행할 수 있다. 인공지능 서버의 동작 분석부는, 운동 치료 애플리케이션으로부터 환자의 운동 영상을 수신할 수 있으며, 운동 영상 수신은 인공지능 서버의 통신부(또는 통신 모듈)에 의해 이루어 질 수 있다. 인공지능 서버의 동작 분석부는, 키포인트 추출부, 인공지능 동작분석부 및 규칙기반 동작 분석부 중 적어도 하나의 구성을 포함하여 이루어질 수 있다. 인공지능 동작분석부 또는 규칙기반 동 작분석부는 “인공 지능 동작 분석 모델”로 명명될 수 있다.인공지능 서버에 포함된 키포인트 추출부, 인공지능 동작분석부 및 규칙기반 동작분석부 각각은, 앞서 설명된 운동 치료 애플리케이션의 키포인트 추출부, 인공지능 동작분석부 및 규칙 기반 동작분석부와 동일한 기능을 수행할 수 있다. 이에, 구체적인 설명은 생략하도록 한다. 인공지능 서버의 제어부는, 인공지능 서버에 포함된 구성들에 대한 전반적인 제어를 수행하도록 이루어질 수 있다. 이하에서는, 본 발명에 따른 운동 치료 제공 시스템의 상기 구성을 이용하여, 운동 영상으로부터 환자 (U)의 운동 동작을 분석하여 운동 동작 분석 결과를 제공하는 운동 동작 분석 프로세스에 대해 설명하도록 한다. 도 2에 도시된 것과 같이, 의사 단말기에서는 환자(U)에 대한 운동 처방이 이루어질 수 있다(S210), 운동 치료 제공 시스템은, 의사 단말기에서 환자에 대한 운동 처방이 이루어진 것에 근거하여, 의사 단말 기로부터 상기 운동 처방에 대한 처방 정보를 수신할 수 있다. 운동 치료 제공 시스템은, 의사 단말기로부터 처방 정보가 수신되는 것에 근거하여, 환자 계정에, 처 방 정보에 따른 적어도 하나의 처방 운동을 포함하는 운동 플랜을 할당할 수 있다. 할당된 운동 플랜은 환자 단 말기로 전송할 수 있다(S220). 운동 치료 제공 시스템은, 환자 단말기, 의사 단말기, 사용자 DB, 데이터베이스 중 적어 도 하나와 통신을 수행하는 통신부를 포함할 수 있다. 예를 들어, 통신부는 WLAN(Wireless LAN), Wi- Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G(5th Generation Mobile Telecommunication ), 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra- Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 통신을 수행할 수 있다. 한편, 환자 단말기에서는, 운동 플랜에 포함된 처방 운동을 수행하는 환자의 운동 영상을 촬영할 수 있다 (S230). 운동 치료 애플리케이션은, 환자 단말기에 구비된 카메라를 활성화시켜, 운동 영상이 촬영되 도록 제어할 수 있다. 환자 단말기에서 촬영된 운동 영상은, 운동 치료 제공 시스템에 의해, 환자의 운동 동작 분석의 분석 대상 데이터(또는 분석 대상 운동 영상)으로 이용될 수 있다. 앞서 설명한 것과 같이, 운동 동작 분석 프로세스는, 환자 단말기에 설치된 운동 치료 애플리케이션 및 인공지능 서버 중 적어도 일부에서 이루어질 수 있으며, 본 발명에서는 운동 동작 분석 프로세스가 이 루어지는 물리적인 공간 및 주체를 별도로 구분하지 않고, 운동 치료 제공 시스템에서 이루어지는 것으로 설명할 수 있다. 한편, 운동 치료 제공 시스템은, 운동 영상에서, 복수의 관절 포인트에 대응하는 키포인트(P1, P2)를 추 출할 수 있다. 키포인트(P1, P2) 추출은, 운동 치료 애플리케이션에 포함된 키포인트 추출부 및 인공 지능 서버에 포함된 키포인트 추출부 중 적어도 일부에 의해 수행될 수 있다. 운동 치료 제공 시스템은, 추출된 키포인트(P1, P2)들 간의 상대적인 위치 관계에 대한 분석을 수할 수 있다(S250). 그리고, 운동 치료 제공 시스템은, 키포인트(P1, P2)간의 위치 관계에 대한 분석에 기초하여, 환자(U)의 운동 동작을 분석할 수 있다(S260). 이러한 운동 동작 분석은, 애플리케이션의 동작 분석부 및 인공지능 서버의 동작 분석부 중 적어도 일부에 의해 이루어질 수 있다. 나아가, 운동 치료 제공 시스템은, 환자(U)의 운동 동작 분석 결과를, 환자 단말기에는 피드백 (Feedback) 정보로서 제공하고, 의사 단말기에는 모니터링 정보로서 제공할 수 있다(S270). 이와 같이, 운동 치료 제공 시스템은, 운동 동작 분석 프로세스에 대한 전반적인 제어를 수행할 수 있으 며, 이를, 본 발명에서는 운동 치료 제공 시스템의 제어부에 의해 이루어지는 것으로 이해할 수 있다. 즉, 운동 치료 제공 시스템의 제어부는, 운동 치료 애플리케이션의 제어부 및 인공지능 서버 의 제어부를 포함하는 개념으로, 운동 치료 제공 시스템에 대한 전반적인 제어를 수행할 수 있다. 이하에서는, 운동 치료 제공 시스템에 의해 이루어지는 운동 동작 분석 프로세스에 대해 보다 구체적으로 설명하도록 한다. 본 발명에서는, 의사(doctor) 단말기로부터, 환자(patient)에 대한 운동과 관련된 처방 정보를 수신하는 과정이 진행될 수 있다(S310, 도3 참조). 도 4a 및 도 4b에 도시된 것과 같이, 운동 치료 제공 시스템은, 의사 계정으로 로그인된 의사 단말기 상에, 환자의 운동과 관련된 처방 기능을 포함하는 운동 처방 페이지(또는 운동 배정 페이지)를 제공할 수 있다. 본 발명에서, “운동 처방”은, “운동 배정”과 혼용하여 사용될 수 있다. 운동 치료 제공 시스템은, 의사 계정에 매칭된 환자 계정 중 특정 환자(U) 계정에 대한 처방이 이루어질 수 있도록, 환자 계정 각각의 운동 처방 페이지를, 의사 단말기 상에 제공할 수 있다. 예를 들어, 본 발명에서, 특정 의사(D) 계정에 제1 환자 계정(ex: “김우영” 환자 계정) 및 제2 환자 계정(ex: “김소희” 환자 계정)이 매칭되어 있다고 가정하자. 운동 치료 제공 시스템은, 의사 단말기로부터 제1 환자 계정(ex: “김우영” 환자 계정)의 운동 처방 요청을 수신하는 것에 근거하여, 의사 단말기 상에, 제1 환자 계정에 대응하는 운동 처방 페이지를 제공할 수 있다. 운동 치료 제공 시스템은, 특정 환자에 대응하는 운동 처방 페이지에서 이루어지는 사용자 선택(또는 사 용자 입력)에 기반하여, 의사 단말기로부터, 특정 환자에 대한 처방 정보를 수신할 수 있다. 처방 정보에는, 환자에게 운동을 처방하기 위한 다양한 정보가 포함될 수 있다. 예를 들어, 처방 정보에는, i) 운동 플랜에 포함되어야 하는 적어도 하나의 운동 동작(ex: “벽집고 종아리 스트레칭”, “앉아서 공굴려 발바닥 마 사지”)에 대한 정보, ii) 운동 동작의 난이도 정보, iii) 운동 동작 유지 시간 정보, iv) 운동 동작 수행 횟수 정보, v) 운동 동작 수행 일정 정보, vi) 운동 동작에 매칭된 신체 정보(ex: “발목”, “무릎”), vii) 주의 사항 정보(ex: “운동이 끝나면 얼음찜질을 해주세요”) 중 적어도 하나를 포함할 수 있다(도 4a 및 도 4b의 (a) 참조). 운동 치료 제공 시스템은, 특정 환자에 대응하는 운동 처방 페이지에서, 특정 환자에 대한 처방 정보가 입력(또는 선택)되는 것에 근거하여, 의사 단말기로부터 특정 환자(U)에 대한 처방 정보를 수신할 수 있다. 이 경우, 의사 단말기 상에는, 특정 환자에 대한 처방이 이루어졌음을 안내하는 안내 정보가 출력될 수 있 다(도 4의 (b) 참조). 한편, 본 발명에서는 상기 처방 정보에 근거하여, 환자의 계정에, 적어도 하나의 처방 운동을 포함하는 운동 플 랜을 할당하는 과정이 진행될 수 있다(S320, 도 3 참조). 도 5의 (a)에 도시된 것과 같이, 운동 치료 제공 시스템은, 특정 환자(U)에 대한 처방 정보에 근거하여, 특정 환자 계정에 적어도 하나의 처방 운동을 포함하는 운동 플랜(E)을 할당하고, 할당된 운동 플랜(ex:”대퇴 슬개골 관절염 디지털 치료제”, E)을 특정 환자 계정으로 로그인된 환자 단말기 상에 제공할 수 있다. 여기에서, “처방 운동”은, 운동 치료 제공 시스템에 포함된 복수의 운동 동작(또는 운동 종류) 중 처방 정보에 근거하여 특정되어 환자 계정에 할당되는 운동 동작으로 이해될 수 있다. 이에, 본 발명에서, “처방 운 동”은, “운동 동작”과 혼용하여 사용될 수 있다. 그리고, 본 발명에서, “운동 플랜”은, “디지털 치료제” 와 혼용되어 사용될 수 있다. 운동 치료 제공 시스템은, 특정 환자 계정으로 로그인된 환자 단말기로부터, 특정 환자 계정에 할당 된 운동 플랜 제공 요청을 수신하는 것에 근거하여, 환자가 운동 플랜에 포함된 처방 운동을 수행할 수 있도록, 운동 가이드 영상 제공 기능에 연계된 운동 페이지를, 환자 단말기 상에 제공할 수 있다. 도 5의 (b)에 도시된 것과 같이, 운동 페이지는 운동 리스트(L)를 포함할 수 있으며, 운동 리스트(L)는, 특정 계정에 할당된 운동 플랜에 포함된 복수의 처방 운동(ex “하지 직거상”, “서서 무릎 굽힙”) 각각의 운동 가 이드 영상에 대응하는 항목(V1 내지 V6)을 포함할 수 있다. 운동 치료 제공 시스템은, 운동 플랜에, 운동 세트(Set)가 복수인 특정 처방 운동(ex: “하지 직거상”) 이 포함되어 있는 경우, 상기 세트수(ex: “3”) 만큼, 특정 처방 운동의 운동 가이드 영상에 대응하는 항목(V1 내지 V3)이, 운동 리스트(L)에 포함되도록 제어할 수 있다. 한편, 운동 치료 제공 시스템은, 환자 단말기로부터, 운동 시작 요청을 수신하는 것에 근거하여, 운 동 리스트(L)에 포함된 항목(V1 내지 V6)의 순서에 근거하여, 복수의 운동 가이드 영상이, 환자 단말기 상 에서 순차적으로 재생되도록 제어할 수 있다. 한편, 본 발명에서는 환자 단말기로부터, 처방 운동에 따른 운동을 촬영한 운동 영상을 수신하는 과정이 진행될 수 있다(S330, 도 3 참조). 도 6에 도시된 것과 같이, 운동 치료 제공 운동 치료 제공 시스템은, 환자 단말기상에서, 운동 가이 드 영상이 재생되는 것에 근거하여, 환자 단말기에 구비된 카메라가 환자(U)의 운동 영상을 촬영하도록 제 어할 수 있다. 환자 단말기에 설치된 운동 치료 애플리케이션은, 환자 단말기에 구비된 카메라의 활성화 상태를, 비활성화 상태에서 활성화 상태로 제어하여, 카메라가 운동 가이드 영상에 따른 운동 동작을 수행하는 환자(U) 의 운동 영상을 촬영하도록 제어할 수 있다. 도 6의 (a)에 도시된 것과 같이, 운동 치료 애플리케이션은, 카메라를 통해 촬영되는 운동 영상으로부터 환자에 대응하는 피사체(U)를 탐지하기 위하여, 환자의 신체 전체가 운동 영상(또는 환자 단말기의 디스플레 이)의 특정 영역에 내에 모두 포함되도록, 안내 멘트(ex: “화면 안에 서주세요”)를 환자 단말기상에 출력 할 수 있다. 운동 치료 애플리케이션은, 특정 영역 내에 환자 신체 전체에 대응하는 피사체(U)가 포함되는 것에 근거하 여, 객체 탐지(Object Detection) 알고리즘을 이용하여 영상으로부터 피사체(U)를 탐지할 수 있다. 운동 치료 애플리케이션은, 다양한 객체 탐지 알고리즘을 이용할 수 있다. 예를 들어, 운동 치료 애플리케 이션은, 복수의 바운딩 박스(Bounding Box)를 앙상블(ensemble)하는 알고리즘(Weighted Box Fusion, WB F)을 이용할 수 있다. 다만, 운동 치료 애플리케이션은 상술한 객체 탐지 알고리즘에 한정되지 않고, 학습 대상 운동 영상으로부터 피사체(U)에 대응하는 객체를 탐지할 수 있는 다양한 객체 탐지 알고리즘을 이용 할 수 있음은 당연하다. 나아가, 운동 치료 애플리케이션은, 특정 영역 내에서, 환자 신체 전체에 대응하는 피사체(U)가 탐지되는 것에 근거하여, 카메라를 통해, 처방 운동에 따라 운동 동작을 취하는 환자의 운동 영상을 촬영할 수 있다. 이 경우, 운동 치료 애플리케이션은, 환자에게 할당된 처방 운동에 대응되는 운동 가이드 영상이 재생되는 상태에서, 처방 운동을 수행하는 환자를 촬영할 수 있다. 그리고, 운동 치료 애플리케이션은, 환자 단말기의 카메라에 의해 촬영된 운동 영상을, 운동 플랜(또 는 운동 플랜에 포함된 복수의 처방 운동 각각)에 매칭하여, 환자 단말기의 메모리에 기록되도록 제어할 수 있다. 한편, 본 발명에서는 운동 영상으로부터, 기 설정된 복수의 관절 포인트에 각각 대응되는 키포인트를 추출하는 과정이 진행될 수 있다(S340, 도 3 참조). 본 발명에서는, 운동 치료 애플리케이션 및 인공지능 서버 중 적어도 일부에 의해, 운동 영상으로부 터 기 설정된 관절 포인트(P1, P2)에 대응하는 키포인트(P1, P2)를 추출할 수 있다. 앞서 설명한 것과 같이, 키 포인트(P1, P2) 추출은, i) 운동 치료 애플리케이션에 의해 이루어지거나, ii) 인공지능 서버에 의해 이루어 지거나, iii) 운동 치료 애플리케이션 및 인공지능 서버 모두에 의해 이루어질 수 있다. 이하 에서는 키포인트(P1, P2) 추출을 수행하는 주체를 별도로 구분하지 않고, 운동 치료 제공 시스템에 의해 이루어지는 것으로 설명하도록 한다. 운동 치료 제공 시스템은, 운동 영상에서, 환자의 복수의 관절 포인트 중, 기 정의(또는 기 설정된) 관절 포인트에 대응하는 영역을, 키포인트(P1, P2)로 추출할 수 있다. 여기에서, “관절 포인트”는, 환자(U)의 복수의 관절(또는 관절을 포함하는 환자(U) 신체의 일부)를 의미할 수 있다. 그리고, “키포인트”는, 운동 영상에서 피사체(U)의 복수의 관절 포인트 각각에 대응되는 영역을 의미할 수 있다. 본 발명에서는, “관절 포인트”와 “키포인트”를 혼용하여 사용할 수 있으며, 관절 포인트와 키포인트 각각에, 동일한 도면부호 “P1, P2”를 부여하여 설명할 수 있다. 한편, 인체는 200여개의 뼈로 이루어져 있으며, 관절은, 뼈와 뼈가 연결되는 부분으로, 인체는 복수의 관절로 구성될 수 있다. 본 발명에서는, 인체를 이루는 복수의 관절 포인트 중 키포인트 대상이 되는 관절 포인트가 미리 지정되어, 관 절 포인트 정의 정보로서 존재할 수 있다. 예를 들어, 관절 포인트 정의 정보에는, 머리 중심에 대응되는 제1 관절 포인트(P1), 목 중심에 대응되는 제2 관절 포인트(P2)가 미리 정의되어 존재할 수 있다 (도 8d 참조). 운동 치료 제공 시스템은, 기 설정된 관절 포인트의 위치 정보를 포함하는 학습 데이터 세트(Set)를 이용 하여 학습된 자세 추정 모델에 기반하여, 운동 영상으로부터, 관절 포인트에 대응하는 키포인트(P1, P2)를 추출할 수 있다. 이 경우, 운동 치료 제공 시스템은, 자세 추정 모델에 의해 기 설정된 관절 포인트 각각의 위치 정보가, x축, y축 좌표 정보가 쌍을 이룬 형태로 추출되는 것에 근거하여, 운동 영상에서 키포인트(P1, P2)의 위치 를 특정할 수 있다. 한편, 운동 치료 제공 시스템은, 운동 영상에서의 관절 포인트의 가시(visible) 여부에 근거하여, 관절 포인트에 대응하는 키포인트(P1, P2)를 제1 키포인트 추출 프로세스 및 제2 키포인트 추출 프로세스 중 어 느 하나의 프로세스에 따라 추출(또는 특정)할 수 있다. 본 발명에서, 관절 포인트의 가시 여부는, 운동 영상에서 관절 포인트가 보이는지 여부를 의미하는 것으로 이해될 수 있다. 운동 치료 제공 시스템은, 운동 영상에, 관절 포인트에 대응하는 피사체(U)의 신체 일부가 포함되어 있으면, 운동 영상 관절 포인트가 보이는 것으로 판단할 수 있다. 운동 치료 제공 시스템은, 운동 영상에서 특정 관절 포인트가 보이는 경우, 제1 키포인트 추출 프로 세스에 따라, 특정 관절 포인트에 대응하는 키포인트를 추출할 수 있다. 구체적으로, 운동 치료 제공 시스템은, 기 설정된 복수의 관절 포인트 중, 운동 영상에서 가시 (visible) 가능한 피사체(U)의 가시 관절 포인트를 특정할 수 있다. 예를 들어, 운동 치료 제공 시스템은, 기 설정된 복수의 관절 포인트 중, 제1 관절 포인트 및 제2 관절 포인트가 운동 영상에서 가시 가능한 경우, 운동 치료 제공 시스템은, 제1 관절 포인트 및 제2 관절 포인트를, 가시 관절 포인트로 특 정할 수 있다. 그리고, 운동 치료 제공 시스템은, 특정된 가시 관절 포인트를 키포인트로서 추출할 수 있다. 이 경우, 운동 치료 제공 시스템은, 운동 영상 내에서 가시 관절 포인트에 대응하는 영역(또는 픽셀, pixel)의 위치 정보를 추출하여, 가시 관절 포인트에 대응하는 키포인트를 추출할 수 있다. 예를 들어, 운동 치 료 제공 시스템은, 객체 탐지 알고리즘을 이용하여, 가시 관절 포인트의 위치 정보를 추출하여, 가시 관 절 포인트에 대응하는 키포인트를 추출할 수 있다. 본 발명에서는 제1 키포인트 추출 프로세스에 따라 추출된 가시 관절 포인트의 위치 정보를, “제1 타입의 정보 (제1 타입의 위치 정보)” 또는 “실체 위치 정보”로 명명하여 설명할 수 있다. 반면에, 운동 치료 제공 시스템은 운동 영상에 관절 포인트에 대응하는 피사체(U)의 신체 일부가 포 함되어 있지 않으면, 운동 영상에서 관절 포인트가 보이지 않는 것으로 판단할 수 있다. 운동 치료 제공 시스템은, 운동 영상에서 특정 관절 포인트가 보이지 않는 경우, 제2 키포인트 추출 프로세스에 따라, 자세 추정 모델을 이용하여 상기 특정 관절 포인트에 대응하는 키포인트를 예측하여 추출 할 수 있다. 운동 치료 제공 시스템은, 자세 추정 모델에 기반하여, 기 설정된 복수의 관절 포인트 중, 운동 영상 에서 가시(visible) 불가능한 피사체(U)의 비가시(invisible) 관절 포인트의 위치 정보를, 예측할 수 있다. 이 경우, 자세 추정 모델은, 가시 관절 포인트의 위치 정보에 근거하여, 비가시 관절 포인트의 위치 정보를 예측할 수 있다. 본 발명에서는 제2 키포인트 특정 프로세스에 따라 추출된 관절 포인트의 위치 정보를, “제2 타입의 정보(제2 타입의 위치 정보)” 또는 “예측 위치 정보”로 명명하여 설명할 수 있다. 운동 치료 제공 시스템은, 비가시 관절 포인트의 예측 위치 정보를, 비가시 관절 포인트에 대응하는 키포 인트에 매칭함으로써, 비가시 관절 포인트에 대응하는 키포인트를 추출(또는 특정)할 수 있다. 이와 같이, 본 발명에서는, 운동 영상에서, 기 정의된 관절 포인트의 가시(visible) 여부에 따라, 관절 포 인트의 위치 정보에 대한 학습을 수행한 자세 추정 모델에 기반하여, 서로 다른 프로세스에 따라 관절 포인트에 대응하는 키포인트(P1, P2)를 추출(또는 특정)할 수 있다. 따라서, 본 발명에서는, 운동 영상에서 보이지 않는 비가시 관절 포인트에 대한 분석도 가능하다. 한편, 운동 치료 제공 시스템은, 환자 단말기에서 운동 영상이 촬영되는 것에 연동하여, 실시간으로 운동 영상으로부터 키포인트(P1, P2)를 추출할 수 있다. 그리고, 운동 치료 제공 시스템은, 환자가, 운동 동작에 대해 분석이 이루어지는 관절 포인트를 직관적으로 인지할 수 있도록, 추출된 키포인트(P1, P2)를 실시 간으로 환자 단말기 상에 제공할 수 있다. 구체적으로, 도 6의 (b) 및 (c)에 도시된 것과 같이, 운동 치료 제공 시스템은, 환자 단말기에서 운 동 영상이 촬영되는 것에 연동하여, 환자 단말기 상에 운동 영상을 실시간으로 출력할 수 있다. 그리고, 운동 치료 제공 시스템은, 기 설정된 관절 포인트에 대응하는 피사체(U)의 일 영역에, 추출된 키 포인트(P1, P2)에 해당하는 그래픽 객체를 오버랩(overlap)하여 제공할 수 있다. 운동 영상에 키포인트 그래픽 객체를 오버랩하여 제공하는 데이터 처리는, 운동 치료 애플리케이션의 영상 처리부에 의해 이루어질 수 있다. 영상 처리부는, 추출된 키포인트(P1, P2)에 해당하는 그래픽 객체 각각을, 키포인트(P1, P2)에 매칭된 관절 포인트(P1, P2)에 대응하는 피사체(U)의 영역 상에 렌더링 (rendering)할 수 있다. 나아가, 영상 처리부는, 환자가 운동 동작을 수행함에 따라 기 설정된 관절 포인트의 위치가 변경되는 경 우, 변경된 관절 포인트에 대응하는 피사체(U)의 영역 상에, 키포인트 그래픽 객체를 오버랩하여 제공할 수 있 다. 즉, 영상 처리부는, 실시간으로 변경되는 관절 포인트의 위치가 반영되도록, 운동 영상에서, 관절 포 인트에 대응하는 영역 상에, 키포인트 그래픽 객체를 오버랩할 수 있다. 한편, 본 발명에서는, 관절 포인트와 관련된 학습 데이터를 이용하여 학습된 자세 추정 모델을 통해 추출된 키 포인트로부터, 키포인트 간의 상대적인 위치 관계를 분석하고, 상기 위치 관계에 대한 분석에 기초하여, 처방 운동에 대한 환자의 운동 동작을 분석하는 과정이 진행될 수 있다(S350, 도 3 참조). 키포인트 간의 상대적인 위치 분석은, 동작 분석부(120, 210)에 의하여 이루어질 수 있다. 특히, 동작 분석부의 인공지능 동작 분석부 (122, 212) 및 규칙기반 동작분석부(123, 213) 중 하나에 의하여, 운동 동작 분석이 이루어질 수 있다. 도 6의 (d)에 도시된 것과 같이, 운동 치료 애플리케이션은, 환자 단말기 상에, 분석 진행을 안내하는 안내 정보(ex: “결과값을 계산중입니다” 또는 “김철수님 운동 동작 분석 결과를 제공하겠습니다”)를 제공하 여, 환자에게 운동 동작 분석을 안내할 수 있다. 이하에서는 환자 운동 동작 분석 방법에 대해 자세하게 설명하 도록 한다. 운동 치료 제공 시스템은, 학습 데이터를 이용하여 학습된 자세 추정 모델로부터 추출된 키포인트를 이용 하여, 기 설정된 복수의 관절 포인트 각각에 대응하는 키포인트(P1, P2) 간의 상대 위치 관계를 분석할 수 있다. 운동 치료 제공 시스템은, 가시 관절 포인트에 대응하는 키포인트 및 비가시 관절 포인트에 대응하는 키 포인트를 모두 이용하여, 기 설정된 복수의 관절 포인트 각각에 대응하는 키포인트(P1, P2) 간의 상대적 위치를 분석할 수 있다. 여기에서, “키포인트 간의 상대적 위치”는, 적어도 두개의 키포인트(P1, P2) 사이에서, 특정 키포인트(예를 들어, 제1 키포인트, “P1”)를 기준으로 다른 키포인트(예를 들어, 제2 키포인트, “P2”)의 위치로 이해될 수 있다. 이하에서는 설명의 편의를 위하여, 가시 관절 포인트에 대응하는 키포인트를, “제1 타입의 키포인트”으로 명 명하고, 비가시 관절 포인트에 대응하는 키포인트를 “제2 타입의 키포인트”로 명명하여 설명하도록 한다. 운동 치료 제공 시스템은, i) 복수의 제1 타입의 키포인트들 간의 상대적 위치 관계, ii) 제1 타입의 키 포인트와 제2 타입의 키포인트 간의 상대적 위치 관계 및 iii) 복수의 제2 타입의 키포인트들 간의 상대적 위치관계 중 적어도 하나에 대한 분석을 수행할 수 있다. 이 경우, 운동 치료 제공 시스템은, 환자가 수행한 처방 운동 종류에 근거하여, 복수의 관절 포인트 중 일부 연관 키포인트 간의 상대적 위치 관계를 분석할 수 있다. 예를 들어, 운동 치료 제공 시스템은, 환자가 제1 운동 종류에 따른 처방 운동을 수행한 경우, 복수의 관 절 포인트 중 제1 관절 포인트 및 제2 관절 포인트 각각에 대응하는 키포인트 간의 상대적 위치 관계를 분석할 수 있다. 다른 예를 들어, 운동 치료 제공 시스템은, 환자가 상기 제1 운동 종류와는 다른 제2 운동 종류에 따른 처방 운동을 수행한 경우, 복수의 관절 포인트 중 제1 관절 포인트 및 제3 관절 포인트 각각에 대응하는 키포인 트 간의 상대적 위치 관계를 분석할 수 있다. 이러한 상대적인 위치 관계는 결과적으로, 동작 분석에 활용될 수 있다. 본 발명에 따른 운동 치료 제공 시스템에서 수행되는 동작 분석의 결과는 매우 다양할 수 있다. 예를 들 어, 운동 치료 제공 시스템은 추출된 키 포인트 또는 영상으로부터, 관절의 가동 범위, 가동 거리, 관절 의 움직임 속도(또는 가속도), 분석 대상 운동 영상에 포함된 피사체(환자에 대응)의 신체 밸런스, 신체 균형, 신체 정렬 상태(EX: 다리의 축 정렬 상태, 척추 정렬상태 등) 중 적어도 하나에 대한 분석을 수행할 수 있다.한 편, 본 발명에 따른 운동 치료 제공 시스템에서는, 처방 운동과 관련된 규칙 정보를 기준으로, 키포인트 간의 상대 위치 관계를 분석할 수 있다. 여기에서, 규칙 정보는, 키포인트 간의 상대 위치 관계를 분석하기 위하여 미리 규칙이 정의되어진 정보로 이해 될 수 있다. 운동 치료 제공 시스템은, 키 포인트 간의 상대 위치 관계가 규칙 정보를 만족하는지 판단하는 것을 통해, 환자의 운동 동작을 분석할 수 있다. 이하에서는 일 예로, 키포인트의 상대 위치 관계 및 규칙 정보를 기 반으로 관절 가동 범위를 분석하는 방법에 대해 설명하도록 한다. 다만, 이하에서 설명되는 내용은 키 포인트의 상대 위치 관계 및 규칙 정보 기반으로 환자의 동작을 분석하는 일 실시에에 불과하고, 본 발명에서는 키포인트 의 상대 위치 관계 및 규칙 정보 기반으로, 환자의 다양한 동작을 분석할 수 있다. 본 발명에 따른 운동 치료 제공 시스템에서 분석되는 관절 가동 범위에 대하여 보다 구체적으로 살펴본다. 운동 치료 제공 시스템은, 처방 운동과 관련된 기준 관절 가동 범위에 대한 규칙 정보를 기준 으로, 키포인트 간의 상대 위치 관계에 따른 환자의 관절 가동 범위에 대한 분석을 수행할 수 있다. 나아가, 운동 치료 제공 시스템은 처방 운동과 관련된 규칙 정보를 기준으로, 상기 키포인트 간의 상대 위치 관계를 분석할 수 있다. 그리고, 운동 치료 제공 시스템은 상기 키 포인트 간의 상대 위치 관계가 상기 규칙 정보를 만족하는지 판단하는 것을 통해 상기 환자의 운동 동작을 분석할 수 있다. 운동 치료 제공 시스템은, 특정 처방 운동과 관련된 복수의 연속 프레임으로부터, 특정 처방 운동에 매칭 된 연관 키포인트들 간의 상대 위치 관계를 추출하고, 추출된 상대 위치 관계를 이용하여 특정 처방 운동에 대 한 환자의 관절 가동 범위를 획득(또는 계산)할 수 있다. 구체적으로, 운동 영상이, 제1 처방 운동에 대응하는 제1 타입을 갖는 복수의 프레임 및 제2 처방 운동에 대응 하는 제2 타입을 갖는 복수의 프레임으로 이루어졌다고 가정하자. 운동 치료 제공 시스템은, 제1 처방 운동 및 제2 처방 운동 중 제1 처방 운동에 대한 환자의 운동 동작 분석이 이루어지는 경우, 제1 타입을 갖는 복수의 프레임으로부터 추출된 키포인트들을 이용하여, 환자의 운동 동작을 분석할 수 있다. 반면에, 운동 치료 제공 시스템은, 제2 처방 운동에 대한 환자의 운동 동작 분석이 이루어지는 경우, 제2 타입을 갖는 복수의 프레임으로부터 추출된 키포인트들을 이용하여, 환자의 운동 동작을 분석할 수 있다. 즉, 운동 치료 제공 시스템은 연속된 동작(또는 자세)에 대한 키포인트 위치 관계를 분석하여, 특정 처방 운동에 대한 환자의 운동 가동 범위를 획득(또는 계산)할 수 있다. 이하에서는 설명의 편의를 위하여, 특정 처방 운동(ex: 제1 처방 운동)에 대응하는 연속된 복수의 프레임(즉, 제1 타입을 갖는 복수의 프레임)을, 프레임이 형성되는 시간적 전후에 따라, “제1 분석 대상 프레임” 및 “제 2 분석 대상 프레임”으로 명명하도록 한다. 여기에서, 제1 분석 대상 프레임은 시간적으로 전(before)에 형성되고, 제2 분석 대상 프레임은 시간적으로 후 (after)에 형성되는 프레임으로 이해될 수 있다. 운동 치료 제공 시스템은, 제1 분석 대상 프레임 및 제2 분석 대상 프레임 각각에서, 키포인트를 추출할 수 있다. 제1 분석 대상 프레임에서. 복수의 관절 포인트 각각에 대응되는 제1 분석 대상 키포인트 그룹을 추출하고, 제2 분석 대상 프레임에서, 복수의 관절 포인트 각각에 대응되는 제2 분석 대상 키포인트 그룹을 추출할 수 있다. 운동 치료 제공 시스템은, 제1 분석 대상 키포인트 그룹에 포함된 키포인트 간의 “제1 위치 관계”를 분 석하여, 제1 분석 대상 프레임에 포함된 피사체(U)의 제1 동작 분석을 수행할 수 있다. 또한, 운동 치료 제공 시스템은, 제2 분석 대상 키포인트 그룹에 포함된 키포인트 간의 “제2 위치 관계”를 분석하여, 제2 분 석 대상 프레임에 포함된 피사체(U)의 제2 동작 분석을 수행할 수 있다. 운동 치료 제공 시스템은, 제1 키포인트 위치 관계 및 제2 키포인트 위치 관계에 기초하여, 특정 처방 운 동에 대한 환자의 관절 가동 범위를 획득(추출 또는 계산)할 수 있다. 이 경우, 운동 치료 제공 시스템은, 사용자 DB를 참조하여, 환자의 나이 정보, 성별 정보, 신장 정보, 체중 정보, 수술 이력 정보, 근골격계 질환 정보 중 적어도 하나를 고려하여, 환자의 관절 가동 범위를 획득할 수 있다. 한편, 운동 치료 제공 시스템은, 획득된 환자의 운동 가동 범위가, 특정 처방 운동과 관련된 규칙 정보에 대응하는 기준 관절 가동 범위를 만족하는지를 판단할 수 있다. 본 발명에서, 규칙 기반의 환자의 운동 가동 범 위에 대한 분석은, 인공지능 서버의 규칙 기반 동작 분석부에 의해 이루어질 수 있다(도 1 참조), 다 만, 규칙 기반 동작 분석부에 의해 분석이 이루어지는 것으로 한정하는 것은 아니다. 본 발명에는, 복수의 운동 종류 각각에 대해 기준 관절 가동 범위에 대한 규칙 정보가 존재할 수 있다. 이러한 규칙 정보는, 나이별, 성별, 신장별, 몸무게별, 근골격계 질환별로, 서로 다른 기준 관절 가동 범위에 대한 정 보를 포함할 수 있다. 운동 치료 제공 시스템은, 특정 처방 운동에 대한 환자의 관절 가동 범위와, 규칙 정보에 포함된 특정 처 방 운동에 대한 기준 관절 가동 범위를 비교하여, 환자의 관절 가동 범위가 기준 관절 가동 범위를 만족하는지 여부를 판단할 수 있다. 운동 치료 제공 시스템은, 판단 결과에 근거하여, 처방 운동에 대한 피드백으로서, 환자의 운동 동작에 대한 분석 결과를 환자 단말기 상에 제공할 수 한편, 본 발명에서는 환자의 운동 동작에 대한 분석 결과를, 환자 단말기에 전송하는 과정이 진행될 수 있다 (S360, 도 3 참조). 운동 치료 제공 시스템은, 환자가 운동 동작에 대한 분석 결과를 직관적으로 인식하고, 운동에 대한 환자 의 순응도를 높이기 위하여, 다양한 방법으로 동작 분석 결과를 제공할 수 있다. 운동 치료 제공 시스템은, 운동 영상이 환자 단말기에서 촬영되고 있는 상태에서, 키포인트(P1, P2)에 해당하는 그래픽 객체를 상기 운동 영상에 실시간으로 오버랩하여 제공할 수 있다(도 6 참조). 이 경우, 운동 치료 제공 시스템은, 환자의 관절 가동 범위 정보를, 관절 가동 범위와 관련된 키포인트 (P1, P2) 주변에, 위치시킬 수 있다. 나아가, 운동 치료 제공 시스템은, 환자가, 환자의 관절 가동 범위가, 기준 관절 가동 범위를 만족하는지 여부를 인지 가능하도록, 서로 다른 시각적 외관을 갖는 키포인트 그래픽 객체(또는 키포인트 간의 위치 관계에 해당하는 그래픽 객체)를 운동 영상에 오버랩하여 제공할 수 있다. 나아가, 운동 영상에 오버랩되는 그래픽 객체의 시각적 외관은, 추출된 상기 키포인트 간의 상대 위치 관계가 상기 규칙 정보를 만족하는지 여부에 따라 서로 다르게 구성될 수 있다. 예를 들어, 환자의 관절 가동 범위가 기준 관절 가동 범위를 만족하는 경우, 제1 시각적 외관을 갖는 그래픽 객체(A)가 운동 영상에 오버랩될 수 있다. 반면에, 환자의 관절 가동 범위가 기준 관절 가동 범위를 만족 하지 않는 경우, 상기 제1 시각적 외관과는 다른 제2 시각적 외관을 갖는 그래픽 객체(B)가 운동 영상에 오버랩될 수 있다. 나아가, 운동 치료 제공 시스템은, 운동 영상을 구성하는 복수의 프레임들 각각으로부터 추출된 키 포인트에 기초하여 처방 운동에 대한 환자의 평가 점수(ex: “김우영님의 스쿼트 자세는 70점입니다”)를 동작 분석 결과로서 제공할 수 있다. 한편, 본 발명에서는, 환자 단말기에 설치된 운동 치료 애플리케이션 및 인공지능 서버는, 각각 운동 동작에 대한 분석을 수행하고, 운동 동작 분석 결과를 생성할 수 있다. 예를 들어, 운동 치료 애플리케이션은, 운동 영상에 실시간으로 키포인트(P1, P2)에 해당하는 그래픽 객체 를 오버랩하여 제1 결과 분석으로서 생성할 수 있다. 다른 예를 들어, 클라우드 서버로 이루어진 인공지능 서버는, 운동 영상을 구성하는 복수의 프레임들 각각 으로부터 추출된 키포인트에 기초하여 처방 운동에 대한 환자의 평가 점수를, 제2 분석 결과로서 생성할 수 있 다. 운동 치료 제공 시스템은, 운동 치료 애플리케이션에서 생성한 제1 분석 결과 및 인공지능 서버 에서 생성한 제2 분석 결과를 포함하는 환자의 운동 동작에 대한 분석 결과를, 환자 단말기 상에 제공 할 수 있다. 한편, 운동 치료 제공 시스템은, 환자의 운동 동작 분석 결과를 의사 단말기로 전송할 수 있다. 의사 단말기에는 상기 제1 분석 결과 및 제2 분석 결과가 모두 제공될 수 있다. 이와 같이, 본 발명에서는 환자가 운동 동작에 대한 분석 결과를 직관적으로 인식할 수 있도록, 분석 결과 제공 과 관련된 다양한 사용자 환경을 제공하고 있다. 분석 결과 제공과 관련된 다른 실시예에 대한 설명은 후술하도 록 한다. 한편, 도 7에 도시된 것과 같이, 본 발명은 환자 단말기로부터 수신되는 운동 영상에 기반하여, 운동 영상에 포함된 환자(U)의 운동 동작을 분석하고, 분석 결과를 제공하기 위한 것이다. 특히, 본 발명은, 인 공지능에 기반하여 환자의 운동 동작을 분석하기 위해, 중요 관절 포인트를 중심으로 학습 데이터 세트(Data set)를 가공하고, 이를 학습하는 방법에 대한 것이다. 이하에서는, 본 발명에서 자세 추정 모델이 학습하는 학습 데이터에 대해 구체적으로 설명하도록 한다. 도 7에 도시된 것과 같이, 데이터베이스는 학습 데이터 세트(Data set)가 저장된 저장소로, 본 발명에 따른 운동 치료 제공 시스템 자체에 구비되거나 외부 저장소(또는 외부 DB)로 이루어질 수 있다. 본 발명에 따 른 데이터베이스는, 학습 데이터 세트가 저장되어 있는 공간이면 충분하며, 물리적인 공간에 대한 제약은 없는 것으로 이해될 수 있다. 데이터베이스(Data Base, 40), 자세 추정 서버 및 운동 치료 제공 시스템 중 적어도 하나의 구성을 포함하여 이루어질 수 있다. 데이터베이스에는, 자세 추정 모델을 학습을 학습시키기 위한 한 학습 데이터가, 학습 데이터 세트로서 저장되어 존재할 수 있다. 도 8b에 도시된 것과 같이, 본 발명에서의 학습 데이터 세트는, 서로 다른 정보 속성(410a 내지 450a) 각 각에 대응되는 복수의 데이터 그룹(410 내지 450)으로 구성될 수 있다. 복수의 데이터 그룹(410 내지 450) 각각 에 포함된 정보는, 운동 동작을 수행하는 피사체(U)를 포함하는 운동 영상으로부터 추출되어 구성될 수 있 다. 여기에서, “운동 영상”은, 도 8a에 도시된 것과 같이, 사용자가 운동 동작을 수행하는 과정이 촬영(포함)된 영상(이미지 또는 동영상)으로, 사용자(U)의 신체 중 적어도 일부가 포함될 수 있다. 본 발명에서는, 운동 영상에 포함된 사용자 객체를, “피사체(U)”로 명명하여 설명할 수 있다. 본 발명에 서 “피사체(U)”는 운동 영상에서 운동하는 사용자 또는 사용자의 신체 일부를 의미할 수 있다. 이에, 본 발명 에서는, “피사체”와 “사용자”를 혼용하여 사용할 수 있으며, 동일한 도면부호 “U”를 부여하여 설명할 수 있다. 한편, 본 발명에서 설명되는 “운동 영상”은, “분석 대상 운동 영상” 및 “학습 대상 운동 영상”을 포 함할 수 있다. “분석 대상 운동 영상”은, 피사체(U)의 자세 추정 분석 대상이 되는 운동 영상이고, “학습 대상 운동 영상” 은, 자세 추정 모델을 위한 기계 학습의 대상이 되는 운동 영상으로 이해될 수 있다. 여기에서, 자세 추정 분석 은, 영상으로부터 키포인트를 추출하는 것을 의미할 수 있다. 학습부는 학습 대상 운동 영상에 기반하여 자세 추정 모델을 위한 학습을 수행하도록 이루어질 수 있 다. 학습부는 학습 데이터를 이용하여, 자세 추정 모델을 학습시킬 수 있다. 도 8b의 (a)에 도시된 것과 같이, 학습부는 학습 대상 운동 영상에서 피사체(U)를 탐지하고, 탐지된 피사체(U)로부터 운동 자세 추정에 이용되는 다양한 학습 데이터를 추출할 수 있다. 이러한 학습 데이터는, “ 정보” 또는 “데이터” 또는 “데이터 값” 또는 “데이터 밸류(value)”와 혼용되어 사용될 수 있다. 한편, 학습 데이터의 추출은, 학습부가 아닌 다른 수단에 의해서도 이루어질 수 있다. 학습부는, 학습 대상 운동 영상으로부터 피사체(U)를 탐지하기 위하여, 다양한 객체 탐지(Object Detection)를 위한 알고리즘을 이용할 수 있다. 예를 들어, 학습부는 예를 들어, 복수의 바운딩 박스 (Bounding Box)를 앙상블(ensemble)하는 알고리즘(Weighted Box Fusion, WBF)을 이용할 수 있다. 다만, 학습부 는 상술한 객체 탐지 알고리즘에 한정되지 않고, 학습 대상 운동 영상으로부터 피사체(U)에 대응하는 객체를 탐지할 수 있는 다양한 객체 탐지 알고리즘을 이용할 수 있음은 당연하다. 학습부는 추출된 학습 데이터를, 서로 다른 복수의 정보 속성(410a 내지 450a) 각각에 대응하는 복수의 데 이터 그룹(Group, 410 내지 450) 중 어느 하나로 분류할 수 있다. 본 발명에서 설명되는 서로 다른 복수의 정보 속성(410a 내지 450a)은, 도 8b의 (b)에 도시된 것과 같이, 기 정 의되어 존재할 수 있다. 그리고, 복수의 정보 속성(410a 내지 450a) 각각에 대응되는 복수의 데이터 그룹(410 내지 450)은, 기 정의된 정보 속성에 대응하는 학습 데이터가 포함할 수 있다. 예를 들어, i) 제1 정보 속성(410a)에 대응하는 데이터 그룹은 피사체(U)의 관절 포인트 위치 정보를 포함 하고, ii) 제2 정보 속성(420a)에 대응하는 데이터 그룹은 피사체(U)의 관절 포인트 가시(visible) 여부를 나타내는 정보를 포함할 수 있다. 그리고, iii) 제3 정보 속성(430a)에 대응하는 데이터 그룹은 피사체 (U)의 촬영 방향에 대한 정보를 포함하고, iv) 제4 정보 속성(440a)에 대응하는 데이터 그룹은 피사체(U) 가 수행하는 운동 동작(또는 운동 종류)을 구분하는 운동 코드(code) 정보를 포함하고, v) 제5 정보 속성(450 a)에 대응하는 데이터 그룹은, 피사체(U)에 대한 바운딩 박스(Bounding box)의 사이즈(Size) 및 중심 위치 정보를 포함할 수 있다. 여기에서, “관절 포인트(P1, P2)”는, 사용자의 관절 또는 운동 영상에서 피사체(U)의 관절에 대응되는 일 영역을 의미할 수 있다. 학습부는, 학습 대상 운동 영상으로부터 추출된 복수의 데이터 그룹(410 내지 450)을 서로 연계하여, 학습 대상 운동 영상에 대한 데이터 세트를 생성(구성)할 수 있다. 그리고, 학습부는 생성된 학습 데 이터 세트를 데이터베이스에 저장할 수 있다. 데이터베이스는 학습부에서 생성된 학습 데이터 세트가 저장되는 것에 근거하여, 자세 추정 모델을 위한 데이터베이스로 구축되어질 수 있다. 나아가, 학습부는 데이터베이스에 존재하는 학습 데이터 세트에 기반하여, 자세 추정 모델을 위한 학습을 수행할 수 있다. 앞서 설명한 것과 같이, 학습 데이터 세트는, 관절 포인트의 위치 정보를 포 함할 수 있다. 자세 추정 모델은, 관절 포인트에 대한 위치 정보를 포함하는 학습 데이터 세트(Data set)를 이용하여 학습 된 자세 추정 모델로서, 분석 대상 운동 영상으로부터 피사체(U)의 운동 자세를 추정할 수 있다. 한편, 자세 추정 모델은 학습부에서 생성된 학습 데이터 세트를 이용하여, 운동 영상으로부 터 피사체의 관절 포인트에 해당하는 키포인트를 추출하고, 인공 지능 동작 분석부(122, 212) 및 규칙기반 동작 분석부(123, 213) 중 적어도 하나는, 추출된 키포인트를 이용하여, 운동 영상에서의 피사체의 운동 동작을 분석할 수 있다. 자세 추정 모델로부터 추정된 키포인트를 이용하여, 분석 대상 운동 영상으로부터 추정 가능한 피사체 (U)의 운동 자세는 다양할 수 있다. 예를 들어, 인공 지능 동작 분석부(122, 212) 및 규칙기반 동작분석부(123, 213) 중 적어도 하나는, 피사체(U)에 대한 i) 관절 포인트의 위치, ii) 관절 포인트의 관절 가동 범위, iii) 관 절 포인트의 이동 경로, iv) 관절 포인트 간의 연결 관계, v) 관절 포인트의 대칭 관계 중 적어도 하나에 대한 정보를 추정 및 분석할 수 있다. 이외에도, 동작 분석부(122, 212)는, 분석 대상 운동 영상으로부터 추출된 키 포인트 또는 영상으로 부터, 관절의 가동 거리, 관절의 움직임 속도(또는 가속도), 분석 대상 운동 영상에 포함된 피사체(환자에 대응)의 신체 밸런스, 신체 균형, 신체 정렬 상태(EX: 다리의 축 정렬 상태, 척추 정렬상태 등) 중 적어도 하나 에 대한 분석을 수행할 수 있다. 본 발명에서, 자세 추정 모델은, 학습부를 포함하여 구성되는 것 또한 가능하다. 나아가, 이와 반대로 학습부는 자세 추정 모델을 포함할 수 있으며, 이 경우, 학습부에서 자세 추정 모델을 학습시 켜, 자세 추정 기능을 수행할 수 있다. 이에, 본 발명에서는, 자세 추정 모델에서 수행되는 기능을, 학습부 가 수행하는 것으로 혼용하여 설명할 수 있다. 한편, 사용자 단말기(10, 20)는, 자세 추정 모델에서 추출 및 추정된 키포인트에 기반하여 분석되는, 사용 자의 운동 동작 분석 결과(또는 운동 동작 분석 리포트,)를 사용자 단말(10, 20)에 제공하는 자세 분석 결과 서 비스 제공을 수행하도록 이루어질 수 있다(도 1 참조). 여기에서, 사용자 단말(10, 20)은 환자 단말기, 의사 단말기 및 제3자의 단말기 중 적어도 하나일 수 있다. 이러한 운동 치료 제공 시스템은, 사용자 단말(10, 20)과의 통신을 수행하도록 이루어질 수 있다. 본 발 명에서, 운동 치료 제공 시스템가 통신을 수행하는 것은, 운동 치료 제공 시스템의 통신부에 의해 이루어지는 것으로도 이해될 수 있다. 예를 들어, 운동 치료 제공 시스템의 통신부는, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi- Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G(5th Generation Mobile Telecommunication ), 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra-Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 사용자 단말(10, 20)과 통신하도록 이루어질 수 있다. 한편, 본 발명에서 설명되는 사용자 단말(10, 20)은, 전자기기를 의미하는 것으로서, 스마트폰(smart phone), 휴대폰, 태블릿 PC, 키오스크(KIOSK), 컴퓨터, 노트북, 디지털방송용 단말, PDA(Personal Digital Assistants), 및 PMP(Portable Multimedia Player) 중 적어도 하나를 포함할 수 있다. 나아가, 사용자 단말기 (10, 20)는, 사용자 계정(account)이 로그인된, 접속된 또는 등록된 전자기기 일 수 있다. 여기에서, 사용자 계정은, 본 발명에 따른 운동 치료 제공 시스템에 기 등록된 계정을 의미할 수 있다. 이러한 사용자 계정은, 사용자 ID(identification, identification number)로 이해되어질 수 있다. 한편, 본 발명에서는 사용자 단말(10, 20)로부터, 운동 영상을 수신하는 과정이 진행될 수 있다. 운동 치료 제 공 시스템은 사용자 단말(10, 20)과의 통신을 통해, 사용자가 운동 동작을 수행하는 모습이 촬영된 운동 영상을 수신할 수 있다. 이 경우, 운동 치료 제공 시스템가 사용자 단말(10, 20)로부터 수신하는 운동 영상은, 사용자에 대 한 운동 동작 분석의 대상이 되는 분석 대상 운동 영상으로 이해될 수 있다. 운동 치료 제공 시스템은 다양한 시점 및 경로에 따라 사용자 단말(10, 20)로부터 분석 대상 운동 영상을 수신할 수 있다. 예를 들어, 도 1에 도시된 것과 같이, 운동 치료 제공 시스템은 사용자 단말(10, 20)로부터 “운동 시작 ”에 대응되는 그래픽 객체가 선택되는 것에 근거하여, 사용자 단말(10, 20)에 구비된 카메라가 분석 대상 운동 영상을 촬영하도록, 카메라 상태를 활성화 상태로 제어할 수 있다. 그리고, 운동 치료 제공 시스템 은 카메라로부터 촬영된 분석 대상 운동 영상을 실시간 또는 사용자의 운동이 완료되는 것에 근거하여, 사 용자 단말(10, 20)로부터 수신할 수 있다. 다음으로, 본 발명에서는 관절 포인트에 대한 위치 정보를 포함하는 학습 데이터 세트(Data set)를 이용하여 학 습된 자세 추정 모델로부터 추출된 키포인트에 기반하여, 운동 영상에 포함된 사용자의 특정 운동 동작과 관련 된 운동 동작을 분석하는 과정이 진행될 수 있다. 학습부는, 사용자 단말(10, 20)로부터 분석 대상 운동 영상을 수신하는 경우, 학습 대상 운동 영상을 이용하여 학습된 자세 추정 모델에 기반하여, 분석 대상 운동 영상에 포함된 사용자(U)의 관절 포인트에 해 당하는 키포인트를 추출할 수 있다. 그리고, 인공 지능 동작 분석부(122, 212) 및 규칙기반 동작분석부(123, 213) 중 적어도 하나는, 추출된 키포인트를 이용하여, 운동 영상에서의 피사체의 운동 동작을 분석할 수 있다. 학습부가 추정하는 사용자(U)의 자세 추정 정보는 다양한 정보를 포함할 수 있다. 예를 들어, 학습부는 피사체(U)의 관절 포인트(P1, P2)의 위치 정보, ii) 피사체(U)의 관절 가동 범위 정보(각도 정보)를 추정할 수 있다. 다음으로, 본 발명에서는 상기 분석이 완료되는 것에 근거하여, 특정 운동 동작과 관련된 사용자(U)의 운동 동 작 분석 결과를 사용자 단말(10, 20)로 제공하는 과정이 진행될 수 있다. 운동 치료 제공 시스템은, 사용자 운동 동작에 대한 분석 결과를 가공하여, 운동 동작 분석 리포트를 생 성할 수 있다. 그리고, 운동 치료 제공 시스템은 사용자 단말(10, 20) 상에 운동 동작 분석 리포트를 제 공할 수 있다. 예를 들어, 도 1에 도시된 것과 같이, 운동 치료 제공 시스템은, 사용자의 운동 영상에, 사용자(U)의 관 절 포인트(P1, P2)에 대응하는 위치에, 관절 포인트(P1, P2) 각각에 대응하는 관절 포인트 그래픽 객체를 렌더 링(rendering)하여 제공할 수 있다. 그리고, 운동 치료 제공 시스템은, 특정 관절 포인트(P1) 주변에, 특 정 관절 포인트(P1)의 관절 가동 범위 정보를 표시할 수 있다. 이와 같이, 본 발명에 따른 운동 치료 제공 시스템은, 학습 대상 운동 영상에 기반하여 구축된 데이 터베이스를 이용하여, 자세 추정 모델을 위한 학습을 수행할 수 있다. 그리고, 자세 추정 모델을 이용하여, 사용자의 운동 자세를 추정하고, 추정된 자세에 기반하여 운동 동작 분석 결과 제공 서비스를 수행할 수 있다. 분석 결과에 포함되는 정보는 다양할 수 있다. 예를 들어, 분석 결과에는, 추출된 키 포인트 또는 영상으로부터 분석된, 관절의 가동 범위, 가동 거리, 관절의 움직임 속도(또는 가속도), 분석 대상 운동 영상에 포함된 피사 체(환자에 대응)의 신체 밸런스, 신체 균형, 신체 정렬 상태(EX: 다리의 축 정렬 상태, 척추 정렬상태 등) 중 적어도 하나에 대한 분석 정보가 포함될 수 있다. 나아가, 이러한 분석 정보는, 점수(SCORE)를 더 포함할 수 있으며, 이러한 점수는, 사용자의 운동 동작(또는 자 세)에 대한 분석 점수일 수 있다. 이러한 분석 점수는, 다양한 방법(EX: 기 설정된 기준을 근거로한 규칙 기반 분석 또는 인공 지능 알고리즘에 의한 분석)에 근거하여 산출되는 것이 가능하다. 데이터베이스에는, 학습부에 의해 학습 대상 운동 영상으로부터 추출 및 생성된 학습 데이터 세트 가 저장되어 존재할 수 있다. 이하에서는, 사용자의 운동 자세 추정에 이용되는 학습 데이터 세트에 대해 보다 자세하게 설명하도록 한 다. 도 8a에 도시된 것과 같이, 학습 데이터 세트는, 학습 대상 운동 영상 으로부터 추출된 피사체(U)와 관련된 데이터를 포함하여 구성될 수 있다. 학습부는 학습 대상 운동 영상으로부터, 피사체(U)에 대한 데이터를 추출하여 학습 데이터 세트 를 구성할 수 있다. 이러한 학습 데이터 세트는, 복수의 서브 데이터 세트(401 내지 403)으로 이루어질 수 있다. 본 발명에서, 학습 데이터 세트(300a)는, 상위 개념에 해당하고, 서브 데이터 세트(401 내지 403)는 하위 개념에 해당하 는 데이터 세트로 이해될 수 있다. 학습부는, 학습 대상 운동 영상을 구성하는 복수의 프레임들 중 기 설정된 기준에 근거하여 선별된 기 준 프레임(301 내지 306) 각각으로부터, 피사체(U)에 대한 데이터를 추출하여, 서브 데이터 세트(401 내지 40 3)를 구성될 수 있다. 학습부는 다양한 기준에 근거하여 기준 프레임(301 내지 306)을 선별할 수 있다. 학습 대상 운동 영상(30 0)은 동영상일 수 있고, 복수의 정적인 이미지일 수 있다.학습 대상 운동 영상이 동영상인 경우, 학습부는 학습 대상 운동 영상을 구성하는 복수의 프레임 중 일정 시간 간격(T)을 기준으로 기준 프레임(301 내지 306)을 선별할 수 있다. 다른 예를 들어, 학습부는, 전후 프레임에 포함된 피사체의 동작 변화량이 일정 변화량 이상에 대응되는 경우, 전후 프레임 을 기준 프레임(301 내지 306)으로 선별할 수 있다. 본 발명에 따른 학습 데이터 세트에 포함된 학습 데이터는, 학습 대상 운동 영상을 구성하는 복수의 프레임들 중 기 설정된 기준에 근거하여 선별된 기준 프레임들 각각으로부터, 상기 학습 대상 운동 영상에 포함된 상기 피사체를 중심으로 추출된 학습 데이터로 구성될 수 있다. 이하에서는 설명의 편의를 위하여, “학습 데이터 세트”와 “서브 데이터 세트(401 내지 403)”를 별도로 구분하지 않고, “학습 데이터 세트”를 기준으로 설명하도록 한다. 이하에서 설명되는 학습 데이터 세트 에 포함된 정보는, 서브 데이터 세트(401 내지 403)에 포함된 정보일 있다. 이 경우, 본 발명에 따른 학습 데이터 세트는, 이하에서 설명되는 정보를 포함하는 복수의 서브 데이터 세트(401 내지 403)를 포함하는 것으로 이해될 수 있다. 한편, 도 8b의 (a)에 도시된 것과 같이, 학습 데이터 세트는 서로 다른 복수의 정보 속성 각각에 대응되는 복수의 데이터 그룹(410 내지 460)으로 구성될 수 있다. 학습부는, 학습 대상 운동 영상으로부터 복수의 정보 속성 각각에 대응되는 데이터를 추출하고, 추출된 데 이터의 정보 속성이 동일한 데이터들을, 동일한 데이터 그룹으로 분류(또는 매칭)하여, 학습 데이터 세트 룰 생성할 수 있다. 여기에서, 복수의 정보 속성(410a 내지 450a)은, 학습 대상 운동 영상으로부터 피사체(U)의 운동 자세 추 정을 위하여 필요한 정보의 타입을 구분하는 기준으로 이해될 수 있다. 도 8b의 (b)에 도시된 것과 같이, 본 발 명에서는 서로 다른 복수의 정보 속성(제1 정보 속성 내지 제5 정보 속성, 410a 내지 450a)이 미리 정의되어 존 재할 수 있다. 학습부는, 학습 대상 운동 영상으로부터, 상기 복수의 정보 속성(410a 내지 450a)에 각각에 대응되는 학습 데이터를 추출하고, 동일한 정보 속성에 대응되는 학습 데이터를 동일한 데이터 그룹으로 분류하여 학습 데이터 세트룰 생성할 수 있다. 나아가, 학습부는. 상기 복수의 정보 속성(410a 내지 450a) 사이의 연관성에 근거하여, 복수의 데이터 그룹 (410 내지 460) 사이의 그룹별 연관성을 특정하고, 학습 데이터 세트 및 그룹별 연관성에 대한 학습을 수 행할 수 있다. 이하에서는, 복수의 데이터 그룹 및 그룹별 연관성에 대해서 구체적으로 설명하도록 한다. 도 8c에 도시된 것과 같이, 복수의 데이터 그룹(410 내지 450) 중 제1 데이터 그룹은, 운동 영상에 포함된 피사체(U)의 관절 포인트(P1, P2)에 대한 위치 정보(411, 412)를 포함할 수 있다. 도 8c의 (a)에 도시된 것과 같이, 본 발명에서 관절 포인트(P1, P2)는, 학습 대상 운동 영상에서 사용자의 관절에 대응되는 피사체(U)의 일 영역을 의미할 수 있다. 그리고, 도 5의 (b)에 도시된 것과 같이, 관절 포인트 에 대한 위치 정보(411, 412)는, 학습 대상 운동 영상 내 관절 포인트(P1, P2)가 위치하는 영역의 위치 로 이해될 수 있다. 한편, 인체는 200여개의 뼈로 이루어져 있으며, 관절은, 뼈와 뼈가 연결되는 부분으로, 인체는 복수의 관절로 구성될 수 있다. 학습부는, 피사체(U)의 복수의 관절 포인트 중, 학습 대상이 되는 관절 포인트가, 기 정의되어 존재할 수 있다. 즉, 본 발명에서 설명되는 “학습 대상 관절 포인트”는, 사용자의 복수의 관절 포인트 중 본 발명에서 학습을 위해 기 정의된 관절 포인트로 이해될 수 있다. 도 8d에 도시된 것과 같이, 데이터베이스에는, 복수의 관절 포인트 중 자세 추정 모델의 학습 대상이 되는 학습 대상 관절 포인트가 미리 지정되어, 참조 정보로서 존재할 수 있다. 그리고, 참조 정보에는, 복 수의 학습 대상 관절 포인트에 대한 순서가 미리 정의되어 존재할 수 있다. 제1 학습 대상 관절 포인트는, 머리중심(Center Of Head)으로 정의될 수 있다. 보다 구체적으로, 제1 학습 대상 관절 포인트는, 경추 1번 레벨로 유추(예측 또는 대응)되는 지점으로 이해될 수 있다. 제2 학습 대상 관절 포인트는, 목 중심(Center Of Neck)으로 정의될 수 있다. 보다 구체적으로, 제2 학습 대상 관절 포인트는, Neck Lordotic Curve의 중심인 C3-C4 레벨로, 정면에서 1번과 3번의 가운데 레벨에서 중앙 지점 으로 이해될 수 있다. 제3 학습 대상 관절 포인트는, 목 아래 끝(Lower End Of Neck)으로 정의될 수 있다. 보다 구체적으로, 제3 학습 대상 관절 포인트는, C7-T1 level이며, 양쪽 쇄골 level을 연결하는 선의 중앙 지점으로 이해될 수 있다. 제4 학습 대상 관절 포인트는, 어깨중심으로 정의될 수 있다. 보다 구체적으로, 제4 학습 대상 관절 포인트는, 위팔뼈 머리 중심(Humerus Head)이며, 어깨 관절 회전 운동의 중심 축인 위치로 팔을 외전(abduction)하는 회전 동작 상에서 연속 동작의 회전 중심에 해당하는 위치로 이해될 수 있다. 회전 운동 연속 동작이 아닌 이미지에 서는, 어깨 중심의 예측 위치 정보에 대응하는 지점을, 제4 학습 대상 관절 포인트에 해당할 수 있다. 그리고, 제4 학습 대상 관절 포인트는, 좌측 어깨 중심 및 우측 어깨 중심 각각에 존재할 수 있다. 제5 학습 대상 관절 포인트는, 팔꿈치 중심으로 정의될 수 있다. 보다 구체적으로, 제5 학습 대상 관절 포인트 는, 안쪽-바깥쪽 위관절융기 중심(Humerus Medial-Lateral Epicodyle)에 해당하는 부위이며, 팔꿈치 레벨에서 중앙점으로 이해될 수 있다. 제5 학습 대상 관절 포인트는 좌측 팔꿈치 중심 및 우측 팔꿈치 중심 각각에 존재 할 수 있다. 제6 학습 대상 관절 포인트는, 손목 중심으로 정의될 수 있다. 보다 구체적으로, 제6 학습 대상 관절 포인트는, 노뼈-자뼈 붓돌기 중심(radius-ulnar styloid process)이며, 손목 레벨에서 중앙점으로 이해될 수 있다. 제6 학 습 대상 관절 포인트는, 좌측 손목 중심 및 우측 손목 중심 각각에 존재할 수 있다. 제7 학습 대상 관절 포인트는, 손 중심으로 정의될 수 있다. 보다 구체적으로, 제7 학습 대상 관절 포인트는, 3 번째 손허리뼈 머리(3rd Metacarpal Head)에 해당하는 곳으로 이해될 수 있으며, 좌측 손 중심 및 우측 손 중심 각각에 존재할 수 있다. 제8 학습 대상 관절 포인트는, 고관절 중심(Femoral Head 중심)으로 정의될 수 있다. 보다 구체적으로 제8 학습 대상 관절 포인트는, 고관절 회전 운동의 중심 축인 위치이며, 다리를 외전(abduction)하는 회전 동작에서 연속 동작의 회전 중심에 해당하는 위치로 이해될 수 있다. 회전 운동 연속 동작이 아닌 이미지에서는, 고관절 중심 의 예측 위치 정보에 대응하는 지점을, 제8 학습 대상 관절 포인트로 이해할 수 있다. 제8 학습 대상 관절 포인 트는, 좌측 고관절 중심 및 우측 고관절 중심 각각에 존재할 수 있다. 제9 학습 대상 관절 포인트는, 무릎 중심으로 이해될 수 있다. 보다 구체적으로, 제9 학습 대상 관절 포인트는, Femur Medial-Lateral Epicondyle 중심으로, 무릎 레벨에서 중앙점으로 이해될 수 있다. 제9 학습 대상 관절 포인트는, 좌측 무릎 중심 및 우측 무릎 중심 각각에 존재할 수 있다. 제10 학습 대상 관절 포인트는, 발목 중심으로 정의될 수 있다. 보다 구체적으로, 제10 학습 대상 관절 포인트 는, Medial-Lateral Malleolus 중심으로 발목 레벨에서 중앙점으로 이해될 수 있다. 제10 학습 대상 관절 포인 트는, 좌측 발목 중심 및 우측 발목 중심에 각각 존재할 수 있다. 제11 학습 대상 관절 포인트는, 발 중심으로 정의될 수 있다. 보다 구체적으로, 제11 학습 대상 관절 포인트는, 두번째 발허리뼈(2nd Metatarsal Head)에 해당하는 곳으로, 좌측 발중심 및 우측 발중심 각각에 존재할 수 있다. 제12 학습 대상 관절 포인트는, 발뒤꿈치로 정의될 수 있다. 보다 구체적으로, 제12 학습 대상 관절 포인트는, 발뒤꿈치가 바닥에 닿는 레벨로, 좌측 발뒤꿈치 및 우측 발뒤꿈치 각각에 존재할 수 있다. 제12 학습 대상 관절 포인트는, 이미지에서 피사체(U)가 완전 정면으로 서 있는 경우에는 안보일 수 있으나, 발이 약간이라도 틀어지 는 경우 보일 수 있다. 제13 학습 대상 관절 포인트는, 요추커브시작(SUP. END OF LORDOSIS)으로 정의될 수 있다. 보다 구체적으로, 제 13 학습 대상 관절 포인트는 Zypoid Of Sternum 레벨로 8-10T Spine정도 레벨이며, 양쪽 4번의 평균 레벨과 양 쪽 8번의 평균 레벨의 Mid 레벨에서 중앙점으로 이해될 수 있다. 제14 학습 대상 관절 포인트는, 요추커브중심(Center Of Lordosis)으로 정의될 수 있다. 보다 구체적으로, 제14 학습 대상 관절 포인트는, 대략 L2-4 Spine정도 레벨이며, 13번 레벨과 양쪽 8번의 평균 레벨의 Mid 레벨에서 중앙점으로 이해될 수 있다. 제15 학습 대상 관절 포인트는, 요추커브끝(INF. END OF LORDOSIS)으로 정의될 수 있다. 보다 구체적으로, 제15 학습 대상 관절 포인트는, 대략 S1-2 spine정도 레벨이며, 14번 레벨과 양쪽 8번의 평균레벨의 Mid레벨에서 중 앙점을 이해될 수 있다. 한편, 제1 학습 대상 관절 포인트(P1)는 머리 중심으로 정의되고, 제2 학습 대상 관절 포인트(P2)는 목 중 심으로 미리 정의되어 존재할 수 있다. 그리고, 제1 학습 대상 관절 포인트(P1)에는 가장 우선 순서인 제1 순서가 정의되고, 제2 학습 대상 관절 포인트(P2)에는, 상기 제2 순서보다 후순위인 제2 순서가 정의되어 존재 할 수 있다. 이 경우, 피사체(U)의 좌우 각각에 대응되어 존재하는 학습 대상 관절 포인트에 대한 순서는, 신체 제1 측(ex: 좌측)에 대응되는 학습 대상 관절 포인트가, 신체 제2 측(x: 우측)에 대응되는 학습 대상 관절 포인트보다 우선 할 수 있다. 예를 들어, 왼쪽 손목 중심에 대응되는 학습 대상 관절 포인트(P3)에는, 오른쪽 어깨 중심 에 대응되는 학습 대상 관절 포인트(P4)보다 우선하는 순서가 정의되어 매칭될 수 있다. 학습부는 학습 대상 운동 영상으로부터 기 지정된 복수의 학습 대상 관절 포인트(P1, P2) 각각의 위치 정보(411, 412) 로서 좌표 정보를 추출할 수 있다. 좌표 정보는, 2차원 또는 3차원 좌표 중 적어도 하나를 포함할 수 있다. 2차원 좌표 정보가 추출되는 경우, 학 습부는 학습 대상 운동 영상으로부터, 복수의 학습 대상 관절 포인트(P1, P2) 각각의 x, y축 좌표 정 보를 추출할 수 있다. 이와 달리, 2차원 좌표 정보가 추출되는 경우, 학습부는 학습 대상 운동 영상 으로부터, 복수의 학습 대상 관절 포인트(P1, P2) 각각의 x, y, z축 좌표 정보를 추출할 수 있다. 좌표 정보는 다양한 방법을 통하여 추출될 수 있다. 특히, z축의 좌표 정보는 카메라(ex: RGB카메라 등) 또는 다양한 방식의 센서(EX: 거리 측정 센서 등)로부터 추출될 수 있다. 나아가, z축의 좌표 정보는 다양한 방식의 인공지능 알고리즘을 통해, 학습 대상 영상으로부터 추출될 수 있다. 인공지능 알고리즘을 통해, z축의 좌 표 정보가 추출는 경우, z축의 좌표 정보가 “추정” 또는 “예측”되었다고 표현될 수 있다. 한편, 학습부는 복수의 학습 대상 관절 포인트(P1, P2) 각각의 위치 정보(411, 412)가, 제1 정보 속성 (410a)에 대응되는 것에 근거하여, 제1 데이터 그룹으로 분류하여 제1 데이터 그룹을 생성하고, 제1 데이터 그룹을 포함하는 학습 데이터 세트를 생성할 수 있다. 2차원 좌표 정보(x, y좌표 정보)가 추출됨을 예를 들어 살펴보면, 학습부는 복수의 학습 대상 관절 포인트 (P1, P2) 각각의 위치 정보(411, 412)를, x축, y축 좌표 정보가 쌍을 이룬 형태로 추출할 수 있다. 학습부 는 제1 학습 대상 관절 포인트(P1)의 위치 정보 “[599, 436]”을 추출하고, 제2 학습 대상 관절 포인트(P2)의 위치 정보 “[599, 436]”를 추출할 수 있다. 그리고, 학습부는 상기 “[599, 436]” 및 “[599, 436]”를 포함하는 제1 데이터 그룹으로 구성되는 학습 데이터 세트를 생성할 수 있다. 학습부는, 제1 데이터 그룹을 구성하는 학습 대상 관절 포인트(P1, P2)의 위치 정보(411, 412)를 기반 으로, 학습 대상 운동 영상에 포함된 피사체(U)의 관절 포인트(P1, P2)의 위치를 추정하는 학습을 수행할 수 있다. 한편, 도 8c의 (b)에 도시된 것과 같이, 학습부는, 복수의 학습 대상 관절 포인트(P1, P2) 각각의 위치 정 보(411, 412)를, 상기 복수의 학습 대상 관절 포인트(P1, P2)들 간에 기 정의된 순서에 기반하여, 제1 데이터 그룹 내에서 순차적으로 배열하여, 학습 데이터 세트를 구성(생성)할 수 있다. 앞서 설명한 것과 같이, 데이터베이스에는 복수의 학습 대상 관절 포인트(P1, P2)에 대한 순서가 미리 정의 되어 존재할 수 있다. 학습부는 데이터베이스를 참조하여, 복수의 학습 대상 관절 포인트(P1, P2)의 위치 정보(411, 412)를, 학습 대상 관절 포인트(P1, P2)에 대응하는 순서에 따라 제1 데이터 그룹 내에서 순차적으로 배치하여, 학 습 데이터 세트를 생성할 수 있다. 그리고, 이러한 학습 데이터 세트는 데이터베이스에 저장되어, 자세 추정을 위한 데이터베이스를 구축할 수 있다. 구체적으로, 도 8c의 (b)에 도시된 것과 같이, 학습부는 제1 데이터 그룹 내에서, 제1 순서에 대응되 는 제1 학습 대상 관절 포인트(P1)의 제1 위치 정보를 우선하여 배열하고, 상기 제1 위치 정보에 이 어서, 제2 순서에 대응되는 제1 학습 대상 관절 포인트(P2)의 제2 위치 정보를 배열할 수 있다. 한편, 학습부는, 운동 영상에서 학습 대상 관절 포인트(P1, P2)의 가시(visible) 여부에 근거하여, 학 습 대상 관절 포인트(P1, P2)의 위치 정보(411, 412)를 제1 프로세스 및 제2 프로세스 중 어느 하나의 프로세스에 따라 추출(또는 특정)할 수 있다. 본 발명에서, 학습 대상 관절 포인트의 가시 여부는, 학습 대상 운동 영상에서 학습 대상 관절 포인트(P1, P2)가 보이는지 여부를 의미하는 것으로 이해될 수 있다. 본 발명에서는, 학습 대상 운동 영상에서의 가시 가능한 관절 포인트를, “학습 대상 가시 관절 포인트”로 명 명하고, 학습 대상 운동 영상에서의 비가시(invisible) 관절 포인트를 “학습 대상 비가시 관절 포인트”로 명 명할 수 있다. 학습부는, 학습 대상 운동 영상에, 학습 대상 관절 포인트(P1, P2)에 대응하는 피사체(U)의 신체 일부 가 포함되어 있으면, 학습 대상 운동 영상에서 학습 대상 관절 포인트가 보이는 것으로 판단할 수 있다. 학습부는, 학습 대상 운동 영상에서 학습 대상 관절 포인트(P1, P2) 가 보이는 것에 근거하여, 제1 프 로세스에 따라, 학습 대상 운동 영상으로부터, 학습 대상 관절 포인트(P1, P2)가 위치하는 실제 위치의 위 치 정보를 추출할 수 있다. 본 발명에서는 제1 프로세스에 따라 추출된 학습 대상 관절 포인트(P1, P2)의 위치 정보를, “제1 타입의 정보 (제1 타입의 위치 정보)” 또는 “실체 위치 정보”로 명명하여 설명할 수 있다. 반면에, 학습부는 운동 영상에 학습 대상 관절 포인트(P1, P2)에 대응하는 피사체(U)의 신체 일부가 포함되어 있지 않으면, 학습 대상 운동 영상에서 학습 대상 관절 포인트(P1, P2)가 보이지 않는 것으로 판 단할 수 있다. 학습부는, 운동 영상에서 학습 대상 관절 포인트(P1, P2)가 보이지 않는 것에 근거하여, 제2 프로세스 에 따라, 학습 대상 관절 포인트(P1, P2)의 예상 위치를 예측하여, 예측 위치 정보를 추출(또는 특정)할 수 있 다. 본 발명에서는 제2 프로세스에 따라 추출된 학습 대상 관절 포인트(P1, P2)의 위치 정보를, “제2 타입의 정보 (제2 타입의 위치 정보)” 또는 “예측 위치 정보”로 명명하여 설명할 수 있다. 이와 같이, 본 발명에서, 제1 데이터 그룹에 포함된 복수의 위치 정보(411, 412)는, 학습 대상 운동 영상 에서 복수의 학습 대상 관절 포인트(P1, P2)의 가시(visible) 여부에 따라, 추출 프로세스 및 타입 정보가 서로 다르게 정의될 수 있다. 한편, 제2 프로세스는, 운동 영상에서 보이지 않는 학습 대상 관절 포인트(P1, P2)의 예상 위치 정보를 추 출(특정)하는 다양한 데이터 처리를 포함할 수 있다. 예를 들어, 제2 프로세스에 따라 예상 위치 정보를 추출하는 학습부는, 운동 영상에서 보이는 학습 대 상 관절 포인트의 실제 위치 정보에 근거하여, 운동 영상에서 보이지 않는 학습 대상 관절 포인트(P1, P 2)의 예측 위치 정보를 예측할 수 있다. 이 경우, 학습부는 운동 영상에서 보이는 복수의 학습 대상 관절 포인트(P1, P2)에 대해, 운동 영상 에서 보이지 않는 학습 대상 관절 포인트(P1, P2)와의 연관성에 근거한 가중치를 부여하여, 예측 위치 정 보를 특정할 수 있다. 예를 들어, 학습 대상 관절 포인트 사이의 연관성은, 학습 대상 관절 포인트(P1, P2)에 대응되는 순서가 가까울 수록 높게 설정될 수 있다. 제3 순서에 대응되는 학습 대상 관절 포인트와의 연관성은, 제2 순서에 대응되는 학 습 대상 관절 포인트가, 제1 순서에 대응되는 학습 대상 관절 포인트 보다 높게 설정될 수 있다. 다른 예를 들어, 학습 대상 관절 포인트(P1, P2) 사이의 연관성은, 피사체(U)의 좌우 각각에 대응되어 존재하는 학습 대상 관절 포인트(P1, P2) 사이에서 가장 높게 설정될 수 있다. 예를 들어, 왼쪽 손목 중심에 대응하는 학 습 대상 관절 포인트(P3)와의 연관성은, 오른쪽 손목 중심에 대응하는 학습 대상 관절 포인트(P3)가 가장 높게 설정될 수 있다(도 8c의 (a) 참조). 나아가, 학습부는 운동 영상에서 피사체(U)가 수행하는 운동 동작의 모션(motion) 정보에 근거하여, 운동 영상에서 보이지 않는 학습 대상 관절 포인트(P1, P2)의 예측 위치 정보를 추출할 수 있다. 데이터베이스에는, 운동 동작에 따른 신체(또는 관절 포인트)의 이동 경로(ex: 이동 위치, 이동 방향)를 포 함하는 모션 정보가 저장되어 존재할 수 있다. 학습부는, 운동 영상에서 보이는 학습 대상 관절 포인트(P1, P2)의 위치 정보 및 데이터베이스의 모션 정보를 참조하여, 운동 영상에서 보이지 않는 학습 대상 관절의 예상 위치 정보를 특정할 수 있다. 한편, 도 8c에 도시된 것과 같이, 복수의 데이터 그룹(410 내지 450) 중 제2 데이터 그룹은, 운동 영상 에 포함된 피사체(U)의 학습 대상 관절 포인트(P1, P2)의 가시(visible) 여부를 나타내는 데이터 값 (value, 421, 422)으로 이루어질 수 있다. 도 5의 (b)에 도시된 것과 같이, 제2 데이터 그룹에 포함된 데이터(421, 422)의 데이터 값은, 학습 대상 관절 포인트(P1, P2)의 가시 여부에 대응하여, 제1 데이터 값(ex: “1”) 및 제2 데이터 값(ex: “2”) 중 어느 하나로 이루어질 수 있다. 제1 데이터 값(ex: “1”)을 갖는 데이터는, 운동 영상에서 학습 대상 관절 포인트(P1, P2)가 보이는 것을 나태나는 데이터로, 제1 데이터 그룹에 포함된 위치 정보가 제1 타입(실제 위치 정보)임을 나타내는 정보 로 이해될 수 있다. 학습부는, 운동 영상에서 학습 대상 관절 포인트(P1, P2)가 보이는 경우, 학습 대상 관절 포인트의 제 1 타입의 위치 정보(실제 위치 정보)를 추출할 수 있다. 학습부는 운동 영상으로부터 제1 타입의 위치 정보(실제 위치 정보)를 추출한 것에 근거하여, 제2 데이터 그룹에 제1 데이터 값(ex: “1”)을 갖는 데이 터를 포함시켜 학습 데이터 세트를 생성(구성)할 수 있다. 반면에, 제2 데이터 값(ex: “2”)은, 운동 영상에서 학습 대상 관절 포인트(P1, P2)가 보이지 않는 것을 나타내는 데이터로, 제1 데이터 그룹에 포함된 위치 정보가 제2 타입(예측 위치 정보)임을 나타내는 정보 로 이해될 수 있다. 학습부는, 운동 영상에서 학습 대상 관절 포인트가 보이지 않는 경우, 학습 대상 관절 포인트의 제2 타입의 위치 정보(실제 위치 정보)를 추출(또는 특정)할 수 있다. 학습부는 운동 영상으로부터 제2 타 입의 위치 정보(예측 위치 정보)를 추출(또는 특정)한 것에 근거하여, 제2 데이터 값(ex: “2”)을 갖는 데이터 를, 제2 데이터 그룹에 포함시켜습 데이터 세트를 생성(구성)할 수 있다. 한편, 도 8c의 (b)에 도시된 것과 같이, 학습부는, 제2 데이터 그룹에 포함된 데이터(또는 데이터 값, 421, 422)는, 복수의 학습 대상 관절 포인트(P1, P2) 각각의 가시 여부를 나타내도록, 복수의 학습 대상 관절 포인트 각각의 위치 정보(411, 412)가 배열된 기 정의된 순서와 동일한 순서로, 제2 데이터 그룹 내에서 배열하여, 학습 데이터 세트를 생성(구성)할 수 있다. 학습부는, 복수의 학습 대상 관절 포인트 각각의 가시 여부를 나태내는 데이터(421, 422)를, 복수의 학습 대상 관절 포인트(P1, P2)들 간에 기 정의된 순서에 기반하여, 제2 데이터 그룹 내에서 순차적으로 배열할 수 있다. 예를 들어, 도 8c의 (b)에 도시된 것과 같이, 학습부는, 제1 학습 대상 관절 포인트(P1)가 운동 영상 에서 보이는 것에 근거하여, 제2 데이터 그룹 내에서, 제1 학습 대상 관절 포인트(P1)에 대응되는 제1 순 서상에, 제1 데이터 값(ex: “1”)을 갖는 데이터를 배열할 수 있다. 그리고, 비록 도 8c의 (a) 도면에서는, 제2 학습 대상 관절 포인트(P2)가 운동 영상에서 보이는 것으로 도 시되어 있으나, 제2 학습 대상 관절 포인트(P2)가 운동 영상에서 보이지 않는다고 가정하자. 학습부는, 제2 학습 대상 관절 포인트(P2)가 운동 영상에서 보이는 것에 근거하여, 제2 학습 대상 관 절 포인트(P2)에 대응되는 제2 순서상에, 제2 데이터 값(ex: “2”)을 갖는 데이터를 배열할 수 있다. 한편, 본 발명에서, 제1 데이터 그룹에 포함된 위치 정보에 대한 타입의 정의는, 제2 데이터 그룹에 포함된 데이터가 갖는 데이터 값에 의해 이루어지는 것으로 이해될 수 있다. 도 5의 (b)에 도시된 것과 같이, 제2 데이터 그룹 내에, 제1 순서에 배열된 데이터는 제1 데이터 값 (ex: “1”)을 갖고, 제2 순서에 배열된 데이터는 제2 데이터 값(ex: “2”)을 갖는 경우를 가정하자. 본 발명에서는, 제2 데이터 그룹 내에, 제1 순서에 배열된 데이터가 제1 데이터 값(ex: “1”)을 갖 는 것에 근거하여, 제1 데이터 그룹 내에서 제1 순서에 배열된 위치 정보의 타입을, 제1 타입의 위치 정보(실제 위치 정보)로 정의될 수 있다. 반면에, 제2 데이터 그룹 내에, 제2 순서에 배열된 데이터가 제2 데이터 값(ex: “2”)을 갖는 것에 근거하여, 제1 데이터 그룹 내에서 제2 순서에 배열된 위치 정보의 타입을, 제2 타입의 위치 정보(예 측 위치 정보)로 정의될 수 있다.한편, 본 발명에 따른 자세 추정 모델은, 제2 데이터 그룹에 포함된 데이터 값에 근거하여, 제1 데이 터 그룹에 포함된 복수의 학습 대상 관절 포인트 각각의 위치 정보(411, 412)에 대한 학습 가중치를 다르 게 설정하여, 학습을 수행할 수 있다. 구체적으로, 제2 데이터 그룹 내에, 제1 순서에 배열된 데이터가, 제1 데이터 값(ex: “1”)을 갖는 경우, 자세 추정 모델은, 제1 데이터 그룹 내에서 제1 순서에 배열된 위치 정보에 대해 제1 학습 가중치를 설정하여 학습을 수행할 수 있다. 반면에, 제2 데이터 그룹 내에, 제2 순서에 배열된 데이터가, 제2 데이터 값(ex: “2”)을 갖는 경우, 자세 추정 모델은, 제1 데이터 그룹 내에서 제2 순서에 배열된 위치 정보에 대해 제2 학습 가중치를 설정하여 학습을 수행할 수 있다. 즉, 자세 추정 모델은, 제2 데이터 그룹의 데이터 값에 근거하여, 제1 타입의 위치 정보(실제 위치 정 보)와, 제2 타입의 위치 정보(예측 위치 정보) 각각에 서로 다른 학습 가중치를 설정하여 학습을 수행할 수 있 다. 이 경우, 자세 추정 모델은, 제1 학습 가중치를 제2 학습 가중치보다 높게 설정할 수 있다. 한편, 도 8b에 도시된 것과 같이, 복수의 데이터 그룹(410 내지 450)은 운동 영상에 포함된 피사체에 대한 촬영 방향과 관련된 정보를 포함하는 제3 데이터 그룹을 더 포함할 수 있다. 제3 데이터 그룹에는, 운동 영상에 포함된 피사체(U)가 촬영된 촬영 방향을 나타내는 데이터 값(value)으로 이루어질 수 있다. 도 8e의 (a)에 도시된 것과 같이, 피사체(U)는, 서로 다른 촬영 방향(ex: “정면” 또는 “측면”)에서 촬영될 수 있다. 여기에서 “촬영 방향”은, 피사체(U)에 대한 카메라(도 1에서 도면부호 “201” 참조) 축의 방향으로 이해될 수 있다. 여기에서, 카메라는, 피사체(U)가 포함된 운동 영상을 촬영한 카메라로 이해될 수 있 다. 이러한 카메라는 사용자 단말(10, 20)에 구비된 카메라를 포함할 수 있다. 도 8e (b)에 도시된 제3 데이터 그룹에 포함된 데이터 값은, 피사체(U)에 대한 촬영 방향에 대응하여, 서 로 다른 데이터 값(ex: “0” 또는 “1”)을 가질 수 있다. 제3 데이터 그룹에 포함된 데이터 값은, 상기 피사 체를 촬영한 카메라를 기준으로 하는, 상기 피사체의 촬영 방향에 따라 서로 다른 데이터 값을 갖도록 이루어질 수 있다. 이하에서는 제2 데이터 그룹에 포함된 데이터 값과의 용어 혼동을 피하기 위하여, 촬영 방향에 대응하는 데이터 값을, “데이터 객체 값”으로 명명하여 설명하도록 한다. 제1 데이터 객체 값(ex: “0”)을 갖는 데이터는, 학습 대상 운동 영상에 대한 촬영 방향이 제1 방향(ex: 정면 방향)을 나타내는 데이터로 이해될 수 있다(도 8e의 (b) 참조). 학습부는, 학습 대상 운동 영상에 포함된 피사체(U)에 대한 촬영 방향이, 제1 방향(ex: 정면 방향)에 해당하는 것에 근거하여, 제3 데이터 그룹에 제1 데이터 객체 값(ex: “0”)을 갖는 데이터를 포함시켜 학 습 데이터 세트를 생성할 수 있다. 반면에, 제2 데이터 객체 값(ex: “1”)은, 운동 영상에 대한 촬영 방향이 제1 방향과는 다른 제2 방향 (ex: 측면 방향)을 나타내는 데이터로 이해될 수 있다(도 8e의 (b) 참조). 학습부는, 운동 영상에 포함된 피사체(U)에 대한 촬영 방향이, 제2 방향(ex: 측면 방향)에 해당하는 것에 근거하여, 제3 데이터 그룹에 제2 데이터 객체 값(ex: “1”)을 갖는 데이터를 포함시켜 학습 데이터 세트를 생성할 수 있다. 나아가, 비록 도시되지는 않았지만, 제3 데이터 객체 값(ex: “2”)은, 운동 영상에 대한 촬영 방향이 제1 방향 및 제2 방향과는 다른 제3 방향(ex: 사선 방향)을 나태나는 데이터로 이해될 수 있다. 학습부는 학습 대상 운동 영상에 포함된 피사체(U)에 대한 촬영 방향이, 제3 방향(ex: 사선 방향)에 해당하는 것에 근거하여, 제3 데이터 그룹에 제3 데이터 객체 값(ex: “2”)을 갖는 데이터를 포함시켜 데 이터베이스에 저장할 수 있다. 한편, 본 발명에서 설명되는 제1 방향 내지 제3 방향은, 피사체(U)와 카메라 축이, 기 설정된 방향(ex: 시 계 방향)을 기준으로 이루는 각도가, 제1 범위 내지 제3 범위 각각에 대응되는 경우로 이해될 수 있다. 예를 들어, 제1 방향은, 피사체(U)와 카메라 축이 이루는 각도가, 제1 각도에서 상기 제1 각도 보다 큰 제 2 각도 범위 사이에 대응하는 것으로 이해될 수 있다. 제2 방향은, 피사체(U)와 카메라 축이 이루는 각도 가 제2 각도에서 제2 각도 보다 큰 제3 각도 범위 사이에 대응하는 것으로 이해될 수 있다. 그리고, 제3 방향은, 피사체(U)와 카메라 축이 이루는 각도가 제2 각도에서 제2 각도 보다 큰 제3 각도 범위 사이에 대 응하는 것으로 이해될 수 있다. 한편, 학습부는, 피사체(U)와 카메라 축이, 기 설정된 방향(ex: 시계 방향)을 기준으로 이루는 각도 (또는 각도 값)를, 제3 데이터 그룹에 포함된 데이터의 데이터 값으로 구성할 수 있다. 예를 들어, 피사체 (U)와 카메라 축이 시계 방향을 기준을 직각을 이루는 경우, 학습부는 “90”의 데이터 값을 제3 데이 터 그룹의 데이터로 구성할 수 있다. 한편, 학습부는, 제3 데이터 그룹에 포함된 촬영 방향 정보 가 서로 다른 학습 데이터 세트를 연계하여, 피사체(U)의 자세 추정을 위한 학습을 수행할 수 있다. 예를 들어, 제3 데이터 그룹에 포함된 데이터가, 제1 데이터 객체 값(ex: “0”)을 갖는 제1 학습 데이터 세트와, 제2 데이터 객체 값(ex: “1”)을 갖는 제2 학습 데이터 세트가 존재한다고 가정하자. 학습부는 제 1 데이터 세트에 포함된 제1 데이터 그룹의 위치 정보와, 제2 데이터 세트에 포함된 제1 데이터 그룹의 위 치 정보를 서로 연계하여, 피사체(U)의 자세 추정에 대한 학습을 수행할 수 있다. 한편, 학습부는, 제1 방향에서 촬영된 분석 대상 운동 영상으로부터 피사체(U)의 운동 자세를 추정하는 경 우, 제1 방향에서 촬영된 학습 대상 운동 영상에서 촬영된 학습 대상 운동 영상에 대해 학습을 수행 한 자세 추정 모델에 기반하여, 피사체(U)의 운동 자세를 추정할 수 있다. 본 발명에 따른 운동 치료 제공 시스템은 분석 대상 운동 영상의 촬영 방향에 대응하는 촬영 방향 정보 (데이터 객체 값 또는 데이터 값)을 포함하는 학습 데이터 세트를 이용하여 학습된 자세 추정 모델로부터 추출되는 키포인트에 기반하여, 피사체(U)의 운동 동작을 분석할 수 있다. 한편, 동작 분석부(120, 210)는 제1 방향에서 촬영된 분석 대상 운동 영상으로부터 피사체(U)의 운동 자세 를 추정하는 경우, 제1 방향 및 제2 방향 각각에서 촬영된 학습 대상 운동 영상에 대해 학습을 수행한 자 세 추정 모델로부터 추정되는 자세 추정 정보를 이용하여, 피사체(U)의 운동 동작을 분석할 수 있다. 즉, 동작 분석부(120, 210)는, 제1 촬영 방향으로 촬영된 분석 대상 운동 영상으로부터 피사체(U)의 운동 동작이 촬영되는 경우, 제1 촬영 방향에 대응하는 데이터 객체 값을 포함하는 제1 학습 데이터 세트 및, 상기 제1 촬영 방향과는 다른 제2 촬영 방향에 대응하는 데이터 객체 값을 포함하는 제2 학습 데이터 세트에 대해 학 습을 수행한 자세 추정 모델로부터 추정되는 자세 추정 정보를 이용하여, 피사체(U)의 운동 동작을 분석할 수 있다. 이 경우, 자세 추정 모델은, 제1 학습 데이터 세트에 대해 가중치를 설정하여 학습을 수행한 자세 추정 모델에 해당할 수 있다. 이와 같이, 자세 추정 모델은, 학습 대상 영상에 포함된 피사체의 촬영 방향에 따라 서로 다른 데이터 값을 갖는 상기 학습 데이터 세트를 통해, 상기 피사체의 촬영 방향이 고려되어 학습되도록 이루어질 수 있다. 나아 가, 사용자의 운동 동작 분석 결과는, 자세 추정 모델에서 상기 운동 영상에 포함된 상기 사용자의 촬영 방향이 고려되어 추출된 자세 추정 정보에 기반하여, 상기 사용자의 특정 운동 동작이 분석된 결과일 수 있다. 한편, 도 8b에 도시된 것과 같이, 복수의 데이터 그룹 중 제4 데이터 그룹은, 학습 대상 운동 영상에 포함된 피사체(U)가 수행하는 운동 동작에 매칭된 운동 코드(Code)를 포함할 수 있다. 도 8f에 도시된 것과 같이, 데이터베이스에는, 서로 다른 복수의 운동 동작(710, 720, 730) 각각에는, 서로 다른 운동 코드(ex: “502”, “503”, “504”)가 매칭되어 존재할 수 있다. 본 발명에서 설명되는 “운동 코드”는, 서로 다른 운동 동작을 구분하는 데이터 값으로, “운동 키(Key)”, “ 동작 코드”, “동작 키” 와 혼용되어 사용될 수 있다. 학습부는, 제4 데이터 그룹에, 학습 대상 운동 영상에 포함된 피사체(U)가 수행하는 특정 운동 동작(ex: “한발 서서 앞으로 발 뻗기”, 710)에 매칭된 특정 운동 코드(“502”)를 포함시켜 학습 데이터 세트 를 생성할 수 있다. 학습부는, 동일한 운동 코드를 포함하는 복수의 학습 데이터 세트를 서로 연계하여, 자세 추정을 위한 학습을 수행할 수 있다. 예를 들어, 제1 학습 대상 운동 영상에 기반한 제1 학습 데이터 세트와, 제2 학습 대상 운동 영상에 기반 한 제2 학습 데이터 세트가, 존재한다고 가정하자. 학습부는 제1 학습 데이터 세트와 제2 학습 데이터 세트 에 포함된 운동 코드(ex: “502)”가 동일한 것에 근거하여, 제1 학습 데이터 세트와 제2 학습 데이터 세트를 서로 연계하여, 자세 추정을 위한 학습을 수행할 수 있다. 이러한 운동 코드는, 사용자 단말(10, 20)로부터 수신된 정보, 시스템 관리자 또는 학습부 중 적어도 하나 에 의해 피사체(U)가 수행하는 운동 동작이 특정되는 것에 근거하여, 제4 데이터 그룹에 포함될 수 있다. 학습부는, 사용자 단말(10, 20)로부터 수신되는 정보에 근거하여, 피사체(U)가 수행하는 운동 동작을 특정 할 수 있다. 예를 들어, 학습부는 사용자 단말(10, 20)로부터 “운동 시작”에 대응되는 그래픽 객체가 선 택되는 것에 근거하여, 사용자 단말(10, 20)에 구비된 카메라가 운동 영상을 촬영하도록, 카메라 상 태를 활성화 상태로 제어할 수 있다. 이 경우, 그래픽 객체는, 특정 운동 동작에 대응될 수 있으며, 학습부는 사용자 단말(10, 20)로부터 수신되 는 운동 영상에 포함된 피사체(U)가, 특정 운동 동작을 수행한 것으로 판단할 수 있다. 나아가, 학습부는, 시스템 관리자가 입력하는 정보에 근거하여, 피사체(U)가 수행하는 운동 동작을 특정할 수 있다. 나아가, 학습부는, 운동 영상에 포함된 피사체(U)의 학습 대상 관절의 위치 정보에 근거하여, 피사체 (U)가 수행하는 운동 동작을 특정할 수 있다. 이 경우, 데이터베이스에 저장된 운동 동작에 대한 모션 정보 를 참조하여, 피사체(U)가 수행하는 운동 동작을 특정할 수 있다. 한편, 학습부는 제4 데이터 그룹에 포함된 운동 코드를 기준으로, 동일한 운동 코드를 포함하는 복수 의 학습 데이터 세트를 서로 매칭하여, 데이터베이스 상에 저장할 수 있다. 이 경우, 학습부는 학습 코드를 기준으로, 데이터베이스의 메모리(또는 메모리 공간)을 구분하여 할당 할 수 있다. 본 발명에서, 데이터베이스의 메모리(또는 메모리 공간)을 구분한다는 것은, 운동 코드를 기준 으로 데이터베이스 상에 폴더(folder)를 생성하는 것으로 이해할 수 있다. 그리고, 학습부는 특정 운동 코드에 대응하는 폴더 내에, 특정 운동 코드를 포함하는 학습 데이터 세트를 저장할 수 있다. 한편, 동작 분석부(120, 210)는, 분석 대상 운동 영상에서, 피사체(U)가 수행하는 특정 운동 동작에 대응하는 운동 코드를 포함하는 학습 데이터 세트를 이용하여 학습된 자세 추정 모델로부터 추정되는 자세 추정 정보를 이용하여, 운동 동작을 분석할 수 있다. 나아가, 동작 분석부(120, 210)는, 분석 운동 대상에 포함된 피사체(U)와 동일한 특정 운동 동작과 관련된 학습 대상 운동 영상에 기반하여 학습된 자세 추정 모델로부터 추정된 자세 추정 정보를 이용하여, 이용하여, 특정 운동 동작에 대한 피사체(U)의 운동 동작을 추정할 수 있다. 한편, 도 8c에 도시된 것과 같이, 복수의 데이터 그룹(410 내지 450) 중 제5 데이터 그룹은, 학습 대상 운 동 영상에 포함된 피사체(U)에 대한 바운딩 박스(bounding box, 301)의 사이즈(Size) 정보 및 상기 바운딩 박스 중심의 위치 정보를 포함할 수 있다. 본 발명에서, 바운딩 박스의 “사이즈 정보”는, “스케일(scale)”과 혼용될 수 있다. 학습부는, 학습 대상 운동 영상에서 탐지된 피사체(U)에 대응되는 바운딩 박스의 사이즈 정보 을 추출하고, 바운딩 박스의 중심 위치 정보를 추출하고, 이를 제5 데이터 그룹에 포함시 켜 학습 데이터 세트를 생성할 수 있다. 앞서 설명한 것과 같이, 학습부는, 학습 대상 운동 영상으로부터 피사체(U)를 탐지하기 위하여, 다양 한 객체 탐지(Object Detection)를 위한 알고리즘을 이용할 수 있다. 예를 들어, 학습부는 예를 들어, 복수 의 바운딩 박스(Bounding Box)를 앙상블(ensemble)하는 알고리즘(Weighted Box Fusion, WBF)을 이용할 수 있다. 다만, 학습부는 상술한 객체 탐지 알고리즘에 한정되지 않고, 학습 대상 운동 영상으로부터 피 사체(U)에 대응하는 객체를 탐지할 수 있는 다양한 객체 탐지 알고리즘을 이용할 수 있음은 당연하다. 학습부는, 객체 탐지 알고리즘에 기반하여, 학습 대상 영상으로부터 피사체(U)에 대응하는 바운딩 박 스의 사이즈 정보 및 중심 위치 정보를 추출하고, 상기 사이즈 정보 및 중심 위치 정보를 제5 데이터 그룹에 포함시켜, 학습 데이터 세트를 생성할 수 있다. 이 경우, 학습부는 바운딩 박스의 중심 위치 정보를, x축, y축 좌표 정보가 쌍을 이룬 형태로 추 출할 수 있다. 한편, 학습부는, 학습 대상 운동 영상의 영상 식별 정보를 포함시켜 학습 데이터 세트를 구성할 수 있다. 여기에서, “영상 식별 정보”는, 학습 데이터 세트에 포함된 정보가 추출된 영상을 식별하기 위한 정보로, 예를 들어, 학습 대상 운동 영상의 파일명 정보, 파일 포맷 타입 정보(또는 확장자 정보, ex: “ JPG”, “TIF”)를 포함할 수 있다. 본 발명에서는, 영상 식별 정보를, 제6 정보 속성에 대응하는 제6 데이터 그룹으로 몀명할 수 있다. 학습부는, 영상 식별 정보로 구성된 제6 데이터 그룹을 포함시켜, 학습 데이터 세트를 생성할 수 있다. 한편, 본 발명에서는, 동작 분석부(120, 210)에 기반하여, 환자의 운동 동작에 대한 분석이 완료되는 것에 근거 하여, 운동 동작 분석 결과를 환자 단말기에 제공할 수 있다. 도 9a, 도 9b 및 도 9c에 도시된 것과 같이, 운동 동작 분석 결과는, 환자 단말기에 설치된 운동 치료 애플리케이션을 통해, 제공될 수 있다. 도 9a의 (a)에 도시된 것과 같이, 운동 치료 애플리케이션은, 본 발명에서 제공하는 복수의 서비스 각각에 접근 가능하도록 이루어진 서비스 페이지를, 환자 단말기 상에 제공할 수 있다. 예를 들어, 상기 서비스 페 이지는, i) 환자 계정에 할당된 운동 플랜에 대한 운동 가이드 정보 제공 기능에 연계된 운동 가이드 페이지, ii) 환자 계정에 할당된 운동 플랜 수행과 관련된 운동 페이지(도 9a의 (b) 참조), iii) 기능 평가에 연계된 기 능 평가 페이지(도 9a의 (c) 참조) 및 iv) 운동 플랜 평가 기능에 연계된 플랜 평가 페이지 중 적어도 하나에 접근 가능하도록 이루어질 수 있다. 나아가, 도 9b에 도시된 것과 같이, 운동 치료 애플리케이션은, 운동 동작 분석 결과 및 운동 수행 결과에 기초한 운동 리포트를 제공하는 운동 리포트 페이지를, 환자 단말기 상에 제공할 수 있다. 예를 들어, 운동 리포트 페이지에는, 운동 수행률 정보(도 9b의 (a) 및 (b) 참조) 및 운동 플랜 난이도 정보(도 9b의 (c) 참고) 중 적어도 하나를 포함할 수 있다. 나아가, 도 9c에 도시된 것과 같이, 운동 치료 애플리케이션은, 환자의 운동 동작 분석 결과를 환자 단말 기 상에 제공할 수 있다. 도9c의 (a)에 도시된 것과 같이, 운동 치료 애플리케이션은, 특정 처방 운동(ex: “옆으로 팔 벌리기”)을 수행하는 피사체(U)의, 복수의 관절 포인트 별 운동 동작 분석 정보를 환자 단말기상에 제공할 수 있다. 예 를 들어, 운동 치료 애플리케이션은, 환자의 제1 측(ex: 왼쪽)에 위치하는 관절 포인트의 관절 가동 범위 및 제2 측(ex: 오른쪽)에 위치하는 관절 포인트의 관절 가동 범위를 그래프로, 환자 단말기상에 제공할 수 있다. 도 9c의 (b)에 도시된 것과 같이, 운동 치료 애플리케이션은, 일정 기간에 운동 플랜에 따라 처방 운동을 수행한 환자의, 운동 동작 분석 결과를, 일별로 제공할 수 있다. 예를 들어, 운동 치료 애플리케이션은 제 1 운동일에 대응하는 관절 가동 범위 정보 및 제2 운동일에 대응하는 관절 가동 범위 정보를 제공할 수 있다. 그리고, 운동 치료 애플리케이션은 제1 운동일 및 제2 운동일의 평균 관절 가동 범위를 제공할 수 있다. 도 9c의 (c)에 도시된 것과 같이, 운동 치료 애플리케이션는, 운동 영상에 키포인트(P1, P2)에 대응 하는 그래픽 객체를 렌더링(rendering)하여 환자 단말기상에 제공할 수 있다. 이 경우, 운동 치료 애플리케 이션은, 환자의 관절 가동 범위 정보(각도 정보)를 함께 제공할 수 있다. 한편, 본 발명에 따른 운동 치료 제공 시스템은, 의사가, 환자의 운동 플랜 수행에 대한 모니터링을 수행 할 수 있도록, 환자 단말기에 제공하는 운동 동작 분석 결과를 의사 단말기에도 제공할 수 있다. 위에서 살펴본 것과 같이, 본 발명에 따른 인공 지능 자세 추정 모델 및 동작 분석 모델을 이용한 운동 치료 제 공 시스템 및 방법은, 의사(doctor) 단말기로부터, 환자(patient)에 대한 운동과 관련된 처방 정보를 수신하고, 상기 처방 정보에 근거하여, 상기 환자의 계정에, 적어도 하나의 처방 운동을 포함하는 운동 플랜을 할당할 수 있다. 이를 통해, 근골격계 질환에 대한 운동 치료를 위해 의사와 환자의 대면이 없더라도, 의사는 환자에게 처 방이 가능하고, 환자는 의사의 처방에 따른 운동 플랜을 제공받음으로써, 운동 치료에 대한 장소적, 시간적, 경 제적 제약을 해결하고, 운동 치료에 대한 접근성을 높일 수 있다. 나아가, 본 발명에 따른 인공, 지능 자세 추정 모델 및 동작 분석 모델을 이용한 운동 치료 제공 시스템 및 방 법은, 상기 운동 영상으로부터, 기 설정된 복수의 관절 포인트에 각각 대응되는 키포인트를 추출함으로써, 근골 격계 질환의 운동 치료에 필요한 관절에 포커스(Focus)를 맞추어 사용자의 운동 동작을 분석할 수 있다. 나아가, 본 발명에 따른 인공, 지능 자세 추정 모델 및 동작 분석 모델을 이용한 운동 치료 제공 시스템 및 방 법은, 관절 포인트에 대한 위치 정보를 포함하는 학습 데이터 세트(data set)를 이용하여 학습된 자세 추정 모 델에 기반하여, 운동 영상에 포함된 사용자의 특정 운동 동작과 관련된 운동 동작을 분석할 수 있다. 이를 통해, 본 발명에서는 운동 영상으로부터 환자의 자세에 대한 정확한 분석이 가능하며, 특히, 환자의 관절 가동 범위, 정렬 상태 및 이탈 상태 등에 대한 정보를 획득하여 의료 서비스의 퀄리티(quality)를 향상시킬 수 있다. 나아가, 본 발명에 따른 인공, 지능 자세 추정 모델 및 동작 분석 모델을 이용한 운동 치료 제공 시스템 및 방 법은, 환자의 운동 동작에 대한 분석 결과를, 상기 환자 단말기에 전송함으로써, 환자는 먼 거리에 위치하는 병 원에 직접 방문하지 않더라도 운동 영상에 대한 피드백(feedback)을 제공받아 운동 치료 효과를 제고할 수 있다. 한편, 위에서 살펴본 본 발명은, 컴퓨터에서 하나 이상의 프로세스에 의하여 실행되며, 이러한 컴퓨터로 판독될 수 있는 매체(또는 기록 매체)에 저장 가능한 프로그램으로서 구현될 수 있다. 나아가, 위에서 살펴본 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드 또는 명령어로서 구 현하는 것이 가능하다. 즉, 본 발명은 프로그램의 형태로 제공될 수 있다. 한편, 컴퓨터가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 나아가, 컴퓨터가 읽을 수 있는 매체는, 저장소를 포함하며 전자기기가 통신을 통하여 접근할 수 있는 서버 또 는 클라우드 저장소일 수 있다. 이 경우, 컴퓨터는 유선 또는 무선 통신을 통하여, 서버 또는 클라우드 저장소 로부터 본 발명에 따른 프로그램을 다운로드 받을 수 있다. 나아가, 본 발명에서는 위에서 설명한 컴퓨터는 프로세서, 즉 CPU(Central Processing Unit, 중앙처리장치)가 탑재된 전자기기로서, 그 종류에 대하여 특별한 한정을 두지 않는다. 한편, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5 도면6 도면7 도면8a 도면8b 도면8c 도면8d 도면8e 도면8f 도면9a 도면9b 도면9c"}
{"patent_id": "10-2023-0101837", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 운동 치료 제공 시스템을 설명하기 위한 개념도이다. 도 2 및 도 3은 본 따른 운동 치료 제공 방법을 설명하기 위한 흐름도들이다. 도 4a 및 도 4b는 의사의 처방을 설명하기 위한 개념도들이다. 도 5 및 도 6은 운동 영상으로부터 환자의 운동 동작을 분석하는 방법을 설명하기 위한 개념도들이다. 도7, 도 8a 도 8b, 도 8c, 도 8d, 도 8e 및 도 8f은 인공 지능 자세 추정 모델을 설명하기 위한 개념도들이다. 도 9a, 도 9b 및 도9c는 환자의 운동 동작 분석 결과가 제공되는 사용자 환경을 설명하기 위한 개념도들이다."}
