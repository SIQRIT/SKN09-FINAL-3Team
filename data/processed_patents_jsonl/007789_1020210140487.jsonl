{"patent_id": "10-2021-0140487", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0056856", "출원번호": "10-2021-0140487", "발명의 명칭": "차량에 탑재된 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "김영일"}}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량에 탑재된 전자 장치에 있어서, 통신 인터페이스; 사용자 입력부; 디스플레이부; 상기 차량에 탑재되고, 상기 차량의 주변 환경을 촬영함으로써 주변 환경 이미지를 획득하는 카메라; 적어도 하나의 명령어들(instructions)을 저장하는 메모리; 및 상기 메모리에 저장된 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로세서는, 객체 인식 모델을 이용하여 상기 주변 환경 이미지로부터 적어도 하나의 객체를 인식하고, 상기 통신 인터페이스를 통해, 상기 적어도 하나의 객체 또는 RSU(Road Side Unit)으로부터 상기 적어도 하나의객체에 관한 정보를 포함하는 V2X 데이터 셋을 수신하고, 상기 사용자 입력부를 통해 수신된 사용자 입력에 기초하여, 상기 인식된 적어도 하나의 객체 중 제1 객체를 선택하고, 상기 주변 환경 이미지의 인식 결과 및 상기 수신된 V2X 데이터 셋을 이용하여, 상기 제1 객체의 타입(type)에관한 정보를 획득하고, 상기 제1 객체의 타입에 관한 정보에 기초하여, 상기 제1 객체와 무선 통신 연결을 위한 UI(User Interface)를상기 디스플레이부 상에 디스플레이하고, 상기 UI는 상기 제1 객체의 타입에 기초하여 결정된 기능 또는 동작을 수행하기 위하여 선택 가능한 메뉴 UI를포함하는, 전자 장치."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 프로세서는, 상기 선택된 제1 객체와의 무선 통신의 연결 전, 연결 중, 및 연결 후에 따라 상기 UI를 각각 다른 컬러 및 형태로 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 프로세서는, 상기 적어도 하나의 객체의 타입에 따라 상기 주변 환경 이미지에 포함된 상기 적어도 하나의 객체를 서로 다른컬러의 이미지로 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치. 공개특허 10-2023-0056856-3-청구항 4 제1 항에 있어서,상기 프로세서는, 상기 제1 객체의 프로필 정보, 무선 통신 연결 신호 세기, 배터리 레벨, 및 이동 속도 중 적어도 하나를 포함하는 객체 정보를 문자, 숫자, 기호, 도형, 및 아이콘 중 적어도 하나로 나타내는 객체 정보 UI를 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 프로세서는, 상기 주변 환경 이미지 상에 상기 제1 객체에 대응되는 이미지를 둘러싸는 도형 또는 기호로 구성된 포커싱UI(Focusing UI)를 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 프로세서는, 상기 제1 객체를 둘러싸는 상기 포커싱 UI를 상기 제1 객체의 이동 속도에 따라 서로 다른 컬러로 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 프로세서는, 상기 통신 인터페이스를 통해 상기 제1 객체로부터 광고 영상 또는 소개 영상을 포함하는 컨텐트 영상을 수신하고, 상기 수신된 컨텐트 영상을 디스플레이하도록 상기 디스플레이부를 제어하고, 상기 UI는 상기 컨텐트 영상이 디스플레이된 이후에 디스플레이되는, 전자 장치."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서, 상기 디스플레이부는,상기 차량의 증강 현실 HUD(Head Up Display), 상기 차량의 윈드 쉴드 상에 형성되는 투명 디스플레이, 상기 차량의 CID(Center Information Display), 상기 차량의 네비게이션 장치, 및 계기판 디스플레이 중 어느 하나로구성되는, 전자 장치."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서, 공개특허 10-2023-0056856-4-상기 프로세서는, 상기 주변 환경 이미지로부터 상기 제1 객체의 번호판 정보, 위치 정보, 타입 정보, 및 예측 속도 정보 중 적어도 하나의 정보를 획득하고, 상기 획득된 정보와 상기 수신된 V2X 데이터 셋에 포함된 정보를 매칭하고,매칭 결과에 기초하여, 상기 V2X 데이터 셋으로부터 상기 제1 객체의 식별 정보 및 타입 정보를 추출하는, 전자장치."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서, 상기 프로세서는, 상기 추출된 식별 정보를 이용하여, 상기 제1 객체와 무선 통신 연결을 수행하도록 상기 통신 인터페이스를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "차량에 탑재된 전자 장치의 동작 방법에 있어서, 차량 전방에 탑재된 카메라를 이용하여 상기 차량의 주변을 촬영함으로써, 주변 환경 이미지를 획득하는 단계;인공지능 모델을 이용하여, 상기 주변 환경 이미지로부터 적어도 하나의 객체를 인식하는 단계;상기 적어도 하나의 객체 또는 RSU(Road Side Unit)으로부터 상기 적어도 하나의 객체와 관련된 정보를 포함하는 V2X 데이터 셋(V2X data set)을 수신하는 단계; 사용자 입력에 기초하여, 상기 인식된 적어도 하나의 객체 중 제1 객체를 선택하는 단계; 상기 주변 환경 이미지의 인식 결과 및 상기 수신된 V2X 데이터 셋을 이용하여, 상기 선택된 제1 객체의 타입(type)에 관한 정보를 획득하는 단계; 및상기 제1 객체의 타입에 관한 정보에 기초하여, 상기 제1 객체와 무선 통신 연결을 위한 UI(User Interface)를디스플레이하는 단계;를 포함하고, 상기 UI는 상기 제1 객체의 타입에 기초하여 결정된 기능 또는 동작을 수행하기 위하여 선택 가능한 메뉴 UI를포함하는, 방법."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서, 상기 UI를 디스플레이하는 단계는, 상기 선택된 제1 객체와의 무선 통신의 연결 전, 연결 중, 및 연결 후에 따라 상기 UI를 각각 다른 컬러 및 형태로 디스플레이하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항에 있어서,공개특허 10-2023-0056856-5-상기 UI를 디스플레이하는 단계는, 상기 적어도 하나의 객체의 타입에 따라 상기 주변 환경 이미지에 포함된 상기 적어도 하나의 객체를 서로 다른컬러의 이미지로 디스플레이하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11 항에 있어서,상기 UI를 디스플레이하는 단계는, 상기 제1 객체의 프로필 정보, 무선 통신 연결 신호 세기, 배터리 레벨, 및 이동 속도 중 적어도 하나를 포함하는 객체 정보를 문자, 숫자, 기호, 도형, 및 아이콘 중 적어도 하나로 나타내는 객체 정보 UI를 디스플레이하는단계;를 포함하는, 방법."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항에 있어서,상기 UI를 디스플레이하는 단계는, 상기 주변 환경 이미지 상에 상기 제1 객체에 대응되는 이미지를 둘러싸는 도형 또는 기호로 구성된 포커싱UI(Focusing UI)를 디스플레이하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 포커싱 UI를 디스플레이하는 단계는, 상기 제1 객체를 둘러싸는 상기 포커싱 UI를 상기 제1 객체의 이동 속도에 따라 서로 다른 컬러로 디스플레이하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11 항에 있어서,상기 제1 객체로부터 수신된 광고 컨텐트 또는 소개 영상을 디스플레이하는 단계;를 더 포함하고, 상기 UI를 디스플레이하는 단계는, 상기 광고 컨텐트 또는 소개 영상이 디스플레이된 이후에 수행되는, 방법."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11 항에 있어서, 상기 UI를 디스플레이하는 단계는,공개특허 10-2023-0056856-6-상기 차량의 증강 현실 HUD(Head Up Display), 상기 차량의 윈드 쉴드 상에 형성되는 투명 디스플레이, 상기 차량의 CID(Center Information Display), 상기 차량의 네비게이션 장치, 및 계기판 디스플레이 중 어느 하나에상기 UI를 디스플레이하는, 방법."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11 항에 있어서, 상기 제1 객체의 타입에 관한 정보를 획득하는 단계는, 상기 주변 환경 이미지로부터 상기 제1 객체의 번호판 정보, 위치 정보, 타입 정보, 및 예측 속도 정보 중 적어도 하나의 정보를 획득하는 단계; 상기 획득된 정보와 상기 수신된 V2X 데이터 셋에 포함된 정보를 매칭하는 단계; 및매칭 결과에 기초하여, 상기 V2X 데이터 셋으로부터 상기 제1 객체의 식별 정보 및 타입 정보를 추출하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2021-0140487", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11 항 내지 제19항 중 어느 하나의 항에 기재된 방법을 구현하기 위한 적어도 하나의 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0140487", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "차량에 탑재된 전자 장치 및 그 동작 방법을 제공한다. 본 개시의 일 실시예에 따른 전자 장치는, 카메라를 이용 하여 차량 주변을 촬영함으로써, 주변 환경 이미지를 획득하고, 인공지능 모델을 이용하여 주변 환경 이미지로부 터 적어도 하나의 객체를 인식하고, 적어도 하나의 객체와 관련된 정보를 포함하는 V2X 데이터 셋을 수신하고, 사용자 입력에 기초하여 적어도 하나의 객체 중 제1 객체를 선택하고, 주변 환경 이미지의 인식 결과 및 수신된 V2X 데이터 셋을 이용하여 제1 객체의 타입(type)에 관한 정보를 획득하고, 제1 객체의 타입에 관한 정보에 기초 하여 제1 객체와 무선 통신 연결을 위한 UI(User Interface)를 디스플레이할 수 있다."}
{"patent_id": "10-2021-0140487", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 차량에 탑재된 전자 장치 및 그 동작 방법에 관한 것이다. 구체적으로, 본 개시는 차량 주변의 타 차 량, 보행자, 신호등, 간판 등 객체와 양방향 무선 통신 연결을 수행하는 방법 및 전자 장치를 제공한다."}
{"patent_id": "10-2021-0140487", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에는 차량을 중심으로 유무선 통신 네트워크를 통해 데이터를 송수신하는 V2X 통신(Vehicle to Everything communication)이 사용되고 있다. V2X 통신은 차량이 유무선 통신 네트워크를 통해 타 차량 및 도로 등 인프라 가 구축된 객체와 데이터를 송수신하는 기술을 의미하며, V2V(Vehicle to Vehicle), V2I(Vehicle to Infrastructure), V2P(Vehicle to Pedestrian), 및 V2N(Vehicle to Network)를 총칭한다. 기존 V2X 통신 기술은 타 차량 또는 객체로부터 주로 일방적으로 정보 또는 데이터를 수신하는 용도로만 제한적 으로 사용되고 있다. 예를 들어, 차량에 탑재된 전자 장치는 V2X 통신을 이용하여 타 차량의 속도 정보를 수신 하거나, 거리의 간판을 통해 상점의 정보를 획득하는 등 정보를 수신하는 기능만을 수행하고 있다. 차량에 탑재된 전자 장치가 타 차량, 보행자, 신호등, 또는 간판 등 객체와 V2X 통신을 수행함으로써, 정보를 수신할 뿐만 아니라 객체에 대한 기능 또는 동작을 수행하도록 하는 양방향 V2X 통신 서비스가 요구되고 있다. 사용자가 양방향 V2X 통신 서비스를 편리하게 이용하기 위하여, 전자 장치는 차량 주변의 다른 객체와 통신 연 결하고, 객체와 관련되는 기능 또는 동작을 수행하기 위한 UI(User Interface)를 제공할 필요가 있다."}
{"patent_id": "10-2021-0140487", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 차량 주변의 객체와 양방향 무선 통신 연결을 수행하는 전자 장치 및 그 동작 방법을 제공한다. 본 개시의 다양한 실시예는, 차량 주변의 객체를 인식하고, 사용자 입력에 의해 선택된 객체와 무선 통신 연결을 위한 UI(User Interface)를 제공하는 전자 장치 및 그 동작 방법을 제공할 수 있다."}
{"patent_id": "10-2021-0140487", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위하여 본 개시는 일 실시예는, 차량에 탑재된 전자 장치를 제공한다. 본 개시 의 일 실시예에 따른 전자 장치는 통신 인터페이스, 사용자 입력부, 디스플레이부, 상기 차량에 탑재되고, 상기 차량의 주변 환경을 촬영함으로써 주변 환경 이미지를 획득하는 카메라, 적어도 하나의 명령어들(instruction s)을 저장하는 메모리, 및 상기 메모리에 저장된 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는 객체 인식 모델을 이용하여 상기 주변 환경 이미지로부터 적어도 하 나의 객체를 인식하고, 상기 통신 인터페이스를 통해, 상기 적어도 하나의 객체 또는 RSU(Road Side Unit)으로 부터 상기 적어도 하나의 객체에 관한 정보를 포함하는 V2X 데이터 셋을 수신하고, 상기 사용자 입력부를 통해 수신된 사용자 입력에 기초하여, 상기 인식된 적어도 하나의 객체 중 제1 객체를 선택하고, 상기 주변 환경 이 미지의 인식 결과 및 상기 수신된 V2X 데이터 셋을 이용하여, 상기 제1 객체의 타입(type)에 관한 정보를 획득 하고, 상기 제1 객체의 타입에 관한 정보에 기초하여, 상기 제1 객체와 무선 통신 연결을 위한 UI(User Interface)를 상기 디스플레이부 상에 디스플레이하고, 상기 UI는 상기 제1 객체의 타입에 기초하여 결정된 기 능 또는 동작을 수행하기 위하여 선택 가능한 메뉴 UI를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 프로세서는 상기 선택된 제1 객체와의 무선 통신의 연결 전, 연결 중, 및 연결 후에 따라 상기 UI를 각각 다른 컬러 및 형태로 디스플레이하도록 상기 디스플레이부를 제어할 수 있다. 본 개시의 일 실시예에서, 상기 프로세서는 상기 적어도 하나의 객체의 타입에 따라 상기 주변 환경 이미지에 포함된 상기 적어도 하나의 객체를 서로 다른 컬러의 이미지로 디스플레이하도록 상기 디스플레이부를 제어할 수 있다. 본 개시의 일 실시예에서, 상기 프로세서는 상기 제1 객체의 프로필 정보, 무선 통신 연결 신호 세기, 배터리 레벨, 및 이동 속도 중 적어도 하나를 포함하는 객체 정보를 문자, 숫자, 기호, 도형, 및 아이콘 중 적어도 하 나로 나타내는 객체 정보 UI를 디스플레이하도록 상기 디스플레이부를 제어할 수 있다. 본 개시의 일 실시예에서, 상기 프로세서는 상기 주변 환경 이미지 상에 상기 제1 객체에 대응되는 이미지를 둘 러싸는 도형 또는 기호로 구성된 포커싱 UI(Focusing UI)를 디스플레이하도록 상기 디스플레이부를 제어할 수 있다. 본 개시의 일 실시예에서, 상기 프로세서는 상기 제1 객체를 둘러싸는 상기 포커싱 UI를 상기 제1 객체의 이동 속도에 따라 서로 다른 컬러로 디스플레이하도록 상기 디스플레이부를 제어할 수 있다. 본 개시의 일 실시예에서, 상기 프로세서는 상기 통신 인터페이스를 통해 상기 제1 객체로부터 광고 영상 또는 소개 영상을 포함하는 컨텐트 영상을 수신하고, 상기 수신된 컨텐트 영상을 디스플레이하도록 상기 디스플레이 부를 제어하고, 상기 UI는 상기 컨텐트 영상이 디스플레이된 이후에 디스플레이될 수 있다. 본 개시의 일 실시예에서, 상기 디스플레이부는 상기 차량의 증강 현실 HUD(Head Up Display), 상기 차량의 윈 드 쉴드 상에 형성되는 투명 디스플레이, 상기 차량의 CID(Center Information Display), 상기 차량의 네비게이 션 장치, 및 계기판 디스플레이 중 어느 하나로 구성될 수 있다. 본 개시의 일 실시예에서, 상기 프로세서는 상기 주변 환경 이미지로부터 상기 제1 객체의 번호판 정보, 위치 정보, 타입 정보, 및 예측 속도 정보 중 적어도 하나의 정보를 획득하고, 상기 획득된 정보와 상기 수신된 V2X 데이터 셋에 포함된 정보를 매칭하고, 매칭 결과에 기초하여 상기 V2X 데이터 셋으로부터 상기 제1 객체의 식별 정보 및 타입 정보를 추출할 수 있다. 본 개시의 일 실시예에서, 상기 프로세서는 상기 추출된 식별 정보를 이용하여, 상기 제1 객체와 무선 통신 연 결을 수행하도록 상기 통신 인터페이스를 제어할 수 있다. 상술한 기술적 과제를 해결하기 위하여 본 개시의 다른 실시예는, 차량에 탑재된 전자 장치의 동작 방법을 제공 한다. 본 개시의 일 실시예에 따른 전자 장치의 동작 방법은, 차량 전방에 탑재된 카메라를 이용하여 상기 차량 의 주변을 촬영함으로써, 주변 환경 이미지를 획득하는 단계, 인공지능 모델을 이용하여 상기 주변 환경 이미지 로부터 적어도 하나의 객체를 인식하는 단계, 상기 적어도 하나의 객체 또는 RSU(Road Side Unit)으로부터 상기적어도 하나의 객체와 관련된 정보를 포함하는 V2X 데이터 셋(V2X data set)을 수신하는 단계, 사용자 입력에 기초하여 상기 인식된 적어도 하나의 객체 중 제1 객체를 선택하는 단계, 상기 주변 환경 이미지의 인식 결과 및 상기 수신된 V2X 데이터 셋을 이용하여 상기 선택된 제1 객체의 타입(type)에 관한 정보를 획득하는 단계, 및 상기 제1 객체의 타입에 관한 정보에 기초하여, 상기 제1 객체와 무선 통신 연결을 위한 UI(User Interfac e)를 디스플레이하는 단계를 포함하고, 상기 UI는 상기 제1 객체의 타입에 기초하여 결정된 기능 또는 동작을 수행하기 위하여 선택 가능한 메뉴 UI를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 UI를 디스플레이하는 단계는 상기 선택된 제1 객체와의 무선 통신의 연결 전, 연결 중, 및 연결 후에 따라 상기 UI를 각각 다른 컬러 및 형태로 디스플레이하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 UI를 디스플레이하는 단계는 상기 적어도 하나의 객체의 타입에 따라 상기 주변 환경 이미지에 포함된 상기 적어도 하나의 객체를 서로 다른 컬러의 이미지로 디스플레이하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 UI를 디스플레이하는 단계는 상기 제1 객체의 프로필 정보, 무선 통신 연결 신 호 세기, 배터리 레벨, 및 이동 속도 중 적어도 하나를 포함하는 객체 정보를 문자, 숫자, 기호, 도형, 및 아이 콘 중 적어도 하나로 나타내는 객체 정보 UI를 디스플레이하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 UI를 디스플레이하는 단계는 상기 주변 환경 이미지 상에 상기 제1 객체에 대응 되는 이미지를 둘러싸는 도형 또는 기호로 구성된 포커싱 UI(Focusing UI)를 디스플레이하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 포커싱 UI를 디스플레이하는 단계는 상기 제1 객체를 둘러싸는 상기 포커싱 UI 를 상기 제1 객체의 이동 속도에 따라 서로 다른 컬러로 디스플레이하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 방법은 상기 제1 객체로부터 수신된 광고 컨텐트 또는 소개 영상을 디스플레이 하는 단계를 더 포함하고, 상기 UI를 디스플레이하는 단계는 상기 광고 컨텐트 또는 소개 영상이 디스플레이된 이후에 수행될 수 있다. 본 개시의 일 실시예에서, 상기 UI를 디스플레이하는 단계에서 상기 차량의 증강 현실 HUD(Head Up Display), 상기 차량의 윈드 쉴드 상에 형성되는 투명 디스플레이, 상기 차량의 CID(Center Information Display), 상기 차량의 네비게이션 장치, 및 계기판 디스플레이 중 어느 하나에 상기 UI를 디스플레이할 수 있다. 본 개시의 일 실시예에서, 상기 제1 객체의 타입에 관한 정보를 획득하는 단계는 상기 주변 환경 이미지로부터 상기 제1 객체의 번호판 정보, 위치 정보, 타입 정보, 및 예측 속도 정보 중 적어도 하나의 정보를 획득하는 단 계, 상기 획득된 정보와 상기 수신된 V2X 데이터 셋에 포함된 정보를 매칭하는 단계, 및 매칭 결과에 기초하여, 상기 V2X 데이터 셋으로부터 상기 제1 객체의 식별 정보 및 타입 정보를 추출하는 단계를 포함할 수 있다. 상술한 기술적 과제를 해결하기 위하여, 본 개시의 다른 실시예는 컴퓨터에서 실행시키기 위한 프로그램을 기록 한 컴퓨터로 읽을 수 있는 기록매체를 제공한다."}
{"patent_id": "10-2021-0140487", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기재 된 \"...부\", \"...모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하도 록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 시스템\"이라는 표현은, 그 시 스템이 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 또한, 본 개시에서 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존 재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것 이다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 이하에서는 도면을 참조하여 본 개시의 실시예들을 상세하게 설명한다. 도 1은 본 개시의 본 개시의 전자 장치가 차량 주변의 객체와 무선 통신 연결을 수행하기 위한 UI(110-1 내지 110-5)를 디스플레이하는 실시예를 도시한 개념도이다. 도 1을 참조하면, 전자 장치는 차량 내에 배치되고, 디스플레이부를 포함할 수 있다. 도 1에 도시 된 실시예에서, 디스플레이부는 프로젝터를 이용하여 차량의 윈드 쉴드 상에 가상 이미지를 투사하 는 증강 현실 HUD(Augmented Reality Head Up Display, AR HUD)일 수 있다. 그러나, 이에 한정되는 것은 아니 고, 디스플레이부는 예를 들어, 차량의 윈드 쉴드 상에 형성되는 투명 디스플레이, CID(Center Information Display), 네비게이션 장치, 계기판 디스플레이, 또는 조수석 디스플레이 중 적어도 하나로 구성될 수 있다. 전자 장치는 카메라를 이용하여 차량 주변에 위치하거나 이동 중인 적어도 하나의 객체(101 내지 105)를 촬영함으로써, 적어도 하나의 객체(101 내지 105)를 포함하는 주변 환경 이미지를 획득할 수 있다. 적어도 하나 의 객체(101 내지 105)는 예를 들어, 차량 주변의 타 차량, 보행자, 신호등, 광고판, 또는 간판 중 적어도 하나 일 수 있으나, 이에 한정되는 것은 아니다. 도 1에 도시된 실시예에서, 제1 객체 및 제2 객체는 차량 주변에서 이동 중인 타 차량이고, 제3 객체는 차량 주변에 위치하는 보행자이고, 제4 객체는 음식점 의 간판이며, 제5 객체는 극장의 간판일 수 있다. 전자 장치는 인공지능 모델을 이용하여 주변 환경 이미지로부터 적어도 하나의 객체(101 내지 105)를 인 식할 수 있다. 인공지능 모델은 딥 러닝(Deep Learning) 기반의 객체 인식 모델로 구성될 수 있다. 일 실시예에 서, 객체 인식 모델은 수만 내지 수억 장의 이미지를 입력 데이터로 적용하고, 이미지에 포함되는 객체의 라벨 값(label)을 출력 정답값(groundtruth)로 적용하여 학습된(trained) 모델 파라미터로 구성되는 심층 신경망 모 델(Deep Neural Network)을 포함할 수 있다. 일 실시예에서, 전자 장치는 객체 인식 모델을 이용한 추론 을 통해 적어도 하나의 객체(101 내지 105)의 타입(type)을 인식할 수 있다. 예를 들어, 전자 장치는 제1 객체 및 제2 객체의 타입이 차량이고, 제3 객체의 타입이 사람이라고 인식할 수 있다. 마찬가지 로, 전자 장치는 제4 객체 및 제5 객체의 타입이 간판이라고 인식할 수 있다. 일 실시예에서, 전자 장치는 적어도 하나의 객체(101 내지 105)의 타입에 따라, 적어도 하나의 객체(101 내지 105)를 서로 다른 컬러로 표시할 수 있다. 도 1에 도시된 실시예에서, 차량인 제1 객체와 제2 객체 는 빨간색으로, 보행자인 제3 객체는 노란색으로, 간판인 제4 객체 및 제5 객체는 녹색으 로 표시할 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 적어도 하나의 객체(101 내지 105) 또는 RSU(Road Side Unit)으로부터 V2X 데이터 셋(V2X data set)을 수신할 수 있다. V2X 데이터 셋은 적어도 하나의 객체(101 내지 105)와 관련된 정보를 포함할 수 있다. 예를 들어, V2X 데이터 셋은 적어도 하나의 객체(101 내지 105) 각각의 식별 정보(id 정보), 수신 일자, 번호판 정보, 타입 정보, 위치 정보, 방향 정보 및 속도 정보 중 적어도 하나를 포함할 수 있다. 전자 장치는 사용자로부터 적어도 하나의 객체(101 내지 105) 중 어느 하나의 객체를 선택하는 입력을 수 신할 수 있다. 일 실시예에서, 전자 장치는 핸드 트래킹, 시선 추적, 입력 컨트롤러 등 증강 현실 포인팅 (AR pointing) 입력을 통해 어느 하나의 객체를 선택하는 사용자 입력을 수신할 수 있다. 도 1에 도시된 실시예 에서, 전자 장치는 사용자의 손가락의 위치를 추적하는 핸드 트래킹 장치를 이용하여 제1 객체를 선택하는 사용자 입력을 수신할 수 있다. 그러나, 전자 장치가 증강 현실 포인팅 입력만을 수신하는 것은 아니다. 다른 실시예에서, 전자 장치는 터치 입력, 제스처 입력, 또는 음성 입력 등을 통해 적어도 하나 의 객체(101 내지 105) 중 제1 객체를 선택하는 사용자 입력을 수신할 수 있다. 전자 장치는 사용자 입력에 기초하여, 적어도 하나의 객체(101 내지 105) 중 제1 객체를 선택할 수 있다. 전자 장치는 주변 환경 이미지로부터의 인식 결과 및 V2X 데이터 셋을 이용하여, 제1 객체에 관한 식별 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 주변 환경 이미지로부터 인식된 제1 객체 의 번호판 정보, 위치 정보, 타입 정보, 및 예측 속도 정보 중 적어도 하나의 정보를 획득하고, 획득된 정 보와 V2X 데이터 셋에 포함된 정보를 매칭함으로써, 제1 객체에 관한 식별 정보를 획득할 수 있다. 전자 장치는 제1 객체와 무선 통신 연결을 수행하기 위한 적어도 하나의 UI(User Interface)(110-1 내지 110-5)를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 증강 현실 HUD로 구성된 디스플레이부 상에 프로젝터를 이용하여 가상 이미지를 투사함으로써, 적어도 하나의 UI(110-1 내지 110-5)를 디스플 레이할 수 있다. 그러나, 이에 한정되는 것은 아니고, 다른 실시예에서 전자 장치는 CID(Center Information Display), 네비게이션 장치, 계기판 디스플레이, 또는 조수석 디스플레이 중 적어도 하나에 UI(110-1 내지 110-5)를 디스플레이할 수 있다. 적어도 하나의 UI(110-1 내지 110-5)는 적어도 하나의 객체(101 내지 105)에 각각 대응되고, 적어도 하나의 객 체(101 내지 105)와 인접한 위치에 디스플레이될 수 있다. 적어도 하나의 UI(110-1 내지 110-5)는 적어도 하나 의 객체(101 내지 105)의 타입에 따라 맞춤형 메뉴를 제공하는 상황 맞춤형 UI(contextual menu UI)일 수 있다. 일 실시예에서, 적어도 하나의 UI(110-1 내지 110-5)는 적어도 하나의 객체(101 내지 105)의 타입에 기초하여 결정된 기능 또는 동작을 수행하기 위하여 선택 가능한 메뉴 UI를 포함할 수 있다. 메뉴 UI는 적어도 하나의 객체(101 내지 105) 각각에 대하여 수행할 수 있는 기능 또는 동작을 선택하는 사용자 입력을 수신하기 위한 복수의 항목들을 포함할 수 있다. 도 1에 도시된 실시예에서, 제1 UI(110-1)는 제1 객체 의 타입이 차량이라는 점에 기초하여 결정된 동작들, 예를 들어 차량에 메시지 보내지, 차량 정보 획득, 및 위험 알림 신호 전송 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들을 포함 할 수 있다. 제3 UI(110-3)는 제3 객체의 타입이 보행자이므로, 보행자에 대하여 수행 가능한 동작들, 예 를 들어 메시지 보내기, 전화, 및 위험 알림 신호 전송 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들을 포함할 수 있다. 제4 UI(110-4)는 제4 객체의 타입이 음식점의 간판이라는 점에 기초하여 결정된 동작들, 예를 들어 음식점 정보 획득, 음식 메뉴 주문, 및 예약 중 적어도 하나의 동작을 수행 하기 위한 사용자 입력을 수신하는 복수의 항목들을 포함할 수 있다. 마찬가지로, 제5 UI(110-5)는 제5 객체 가 간판이라는 점에 기초하여 결정된 동작들, 예를 들어 정보 획득 및 간판 램프 점등 시간 알아보기 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들을 포함할 수 있다. 전자 장치는 사용자 입력에 의해 선택된 제1 객체의 식별 정보에 기초하여, 제1 객체와 무선 통신 연결을 수행할 수 있다. 일 실시예에서, 전자 장치는 제1 객체와 양방향 V2X 통신 연결을 수행 할 수 있다. 전자 장치는 제1 객체에 대응되는 제1 UI(110-1)에 포함된 복수의 항목들 중 사용자 입 력에 따라 선택된 항목에 해당되는 기능 또는 동작을 수행할 수 있다. 예를 들어, 사용자 입력에 의해 제1 UI(110-1)를 통해 메시지를 전송하는 항목이 선택된 경우, 전자 장치는 제1 객체에 메시지를 전송하 는 동작을 수행할 수 있다. 기존 V2X 통신 기술은 타 차량 또는 객체로부터 정보 또는 데이터를 일방적으로 수신하는 용도로만 제한적으로 사용되었다. 예를 들어, 차량에 탑재된 전자 장치는 V2X 통신을 이용하여 타 차량의 속도 정보를 수신하거나, 거리의 간판을 통해 상점의 정보를 획득하는 등 정보를 수신하는 기능만을 수행하고 있다. 차량에 탑재된 전자 장치가 타 차량, 보행자, 신호등, 또는 간판 등 객체와 V2X 통신을 수행함으로써, 정보를 수신할 뿐만 아니라 객체에 대한 기능 또는 동작을 수행하도록 하는 양방향 V2X 통신 서비스가 요구되고 있다. 본 개시의 일 실시예에 따른 전자 장치는 단순히 타 차량 또는 간판으로부터 정보를 획득하는 동작을 수 행하는 것으로 제한되지 않고, 타 차량, 보행자, 신호등, 간판 등 적어도 하나의 객체(101 내지 105)와 양방향 V2X 통신 연결을 수행하며, 적어도 하나의 객체(101 내지 105) 각각의 타입에 기초하여 결정된 기능 또는 동작 을 수행하기 위한 상황 맞춤형 UI인 적어도 하나의 UI(110-1 내지 110-5)를 디스플레이함으로써, 사용자 편의성 을 향상시킬 수 있다. 또한, 본 개시의 일 실시예에 따른 전자 장치는 사용자에게 친숙한 그래픽 UI를 디 스플레이함으로써, 양방향 V2X 통신의 사용 빈도를 높이고, 사용성을 강화할 수 있다. 도 2는 본 개시의 일 실시예에 따른 전자 장치의 구성 요소를 도시한 블록도이다. 전자 장치는 차량의 내부에 탑재되거나, 또는 차량의 외부 구조물에 장착될 수 있다. 일 실시예에서, 전 자 장치는 차량 내부의 ECU(Electonic Control Unit)를 구성하는 하나 이상의 전자 회로를 포함할 수 있 다. 그러나, 이에 한정되는 것은 아니다. 도 2를 참조하면, 전자 장치는 카메라, 통신 인터페이스, 프로세서, 메모리, 사용자 입력부, 및 디스플레이부를 포함할 수 있다. 카메라, 통신 인터페이스, 프로세 서, 메모리, 사용자 입력부, 및 디스플레이부는 각각 전기적 및/또는 물리적으로 서로 연결될 수 있다. 도 2에 도시된 구성 요소는 본 개시의 일 실시예에 따른 것일 뿐, 전자 장치가 포함하고 있는 구성 요소 가 도 2에 도시된 것으로 한정되는 것은 아니다. 전자 장치는 도 2에 도시된 구성 요소 중 일부를 포함하 지 않을 수 있고, 도 2에 도시되지 않은 구성 요소를 더 포함할 수도 있다. 예를 들어, 전자 장치는 차량 의 현재 위치에 관한 정보를 획득하기 위한 GPS 센서 또는 차량 주변의 객체와의 거리를 측정하기 위한 라이다 (Light Detection And Ranging, LiDAR) 센서를 더 포함할 수 있다. 카메라는 차량의 외부에 배치될 수 있다. 일 실시예에서, 카메라는 차량의 전방, 좌측, 우측, 및 후방에 배치되고, 복수 개로 구성될 수 있다. 카메라는 차량의 주변 환경을 촬영함으로써, 주변 환경 이미지를 획득할 수 있다. 카메라는 차량 주변의 타 차량, 보행자, 신호등, 교통 표지판, 간판, 또는 광고판 중 적어도 하나를 포함하는 객체를 촬영하고, 객체를 포함하는 주변 환경 이미지를 획득할 수 있다. 카메라는 이미지 센서 및 영상 처리 모듈을 포함할 수 있다. 카메라는 이미지 센서(예를 들어, CMOS 또는 CCD)에 의해 얻어지는 정지 이미지 또는 동영상을 획득할 수 있다. 영상 처리 모듈은 이미지 센서를 통해 획득된 정지 이미지 또는 동영상을 가공하여, 필요한 정보를 추출하고, 추출된 정보를 프로세서에 전달할 수 있다. 통신 인터페이스는 차량 외부의 객체와 무선 통신 네트워크를 통해 연결되고, 객체와 데이터 송수신을 수 행하도록 구성된다. 통신 인터페이스는 예를 들어, WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), WiFi-Direct, RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), 또는 블루투스(Bluetooth™)와 같은 근거리 무선 데이터 통신 뿐만 아니라, CDMA, WCDMA, 3G, 4G, 및/또는 5G, 밀리미터파(mmWAVE)와 같은 이동 통신 네트워크를 이용하여 데이터 송수신을 수행 할 수 있다. 통신 인터페이스는 차량 외부의 객체, RSU(Road Side Unit), 또는 서버와 V2X 통신 연결을 통해, 무선으 로 데이터를 송수신할 수 있다. 일 실시예에서, 통신 인터페이스는 차량 주변의 객체 또는 RSU로부터 객 체에 관한 정보를 포함하는 V2X 데이터 셋(V2X data set)을 수신할 수 있다. 이 경우, 통신 인터페이스는 V2X 통신 연결을 위한 OBU(On Board Unit)을 포함할 수 있다. 일 실시예에서, 통신 인터페이스는 외부 객체 또는 서버로부터 날씨 정보, 도로의 교통 상황 정보(예를 들어, TPEG(Transport Protocol Expert Group))정보를 수신할 수 있다. 프로세서는 메모리에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 한정되는 것은 아니다. 도 2에는 프로세서가 하나의 엘리먼트로 도시되었으나, 이에 한정되는 것은 아니다. 일 실시예에서, 프로 세서는 하나 또는 하나 이상의 복수 개로 구성될 수 있다. 메모리에는 전자 장치의 기능 또는 동작을 실행하기 위한 명령어들(instructions)이 저장될 수 있 다. 일 실시예에서, 메모리에는 프로세서가 판독할 수 있는 명령어들 및 프로그램 코드(program code)가 저장될 수 있다. 이하의 실시예에서, 프로세서는 메모리에 저장된 명령어들 또는 프로그램 코드들을 실행함으로써 구현될 수 있다. 메모리는 예를 들어, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티 미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 또는 광 디스크 중 적어도 하나의 타입의 저장매체로 구성될 수 있다. 프로세서는 메모리에 저장된 명령어들 또는 프로그램 코드들을 실행함으로써 이하의 실시예들을 구 현할 수 있다. 프로세서는 카메라에 의해 촬영된 주변 환경 이미지를 획득하고, 주변 환경 이미지로부터 적어도 하나의 객체를 인식할 수 있다. 일 실시예에서, 프로세서는 인공지능 모델을 이용하여, 주변 환경 이미지 로부터 적어도 하나의 객체를 인식할 수 있다. 인공지능 모델은 카메라로부터 입력받은 이미지 데이터로 부터 객체를 인식하고, 객체를 타입에 따라 분류(classify)하도록 학습된 심층 신경망 모델을 포함할 수 있다. 인공지능 모델은 메모리에 저장될 수 있지만, 이에 한정되는 것은 아니다. 일 실시예에서, 인공지능 모델 은 차량 외부의 서버에 저장되어 있고, 전자 장치은 서버에 이미지 데이터를 전송하고, 서버의 인공지능 모델로부터 추론 결과인 객체의 타입에 관한 정보를 수신할 수도 있다. 인공지능 모델은 수만 내지 수억장의 이미지를 입력 데이터로 적용하고, 이미지에 포함되는 객체의 라벨값 (label)을 출력 정답값(groundtruth)로 적용하여 학습된(trained) 모델 파라미터로 구성되는 심층 신경망 모델 (Deep Neural Network)을 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델 (Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심 층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 그러나, 인공지능 모델이 심층 신경망 모 델만을 포함하는 것은 아니고, SVM(Support Vector Machine), 선형 회귀(linear regression), 로지스틱 회귀 (logistic regression), 나이브 베이즈 분류(Naive Bayes), 랜덤 포레스트(random forest), decision tree, 또 는 k-nearest neighbor algorithm 중 적어도 하나로 구성될 수도 있다. 프로세서는 인공지능(AI) 프로세서를 포함할 수 있다. 인공 지능(AI) 프로세서는, 인공 지능(AI)을 위한 전용 하드웨어 칩 형태로 구성될 수도 있고, 범용 프로세서(예를 들어, CPU 또는 애플리케이션 프로세서) 또는 그래픽 전용 프로세서(예를 들어, GPU)의 일부로서 프로세서에 포함될 수 있다. 인공지능 프로세서는 인 공지능 모델을 이용하여, 카메라로부터 획득된 주변 환경 이미지로부터 적어도 하나의 객체를 인식할 수 있다. 인공지능 모델은 객체 인식 결과를 출력할 수 있다. 일 실시예에서, 객체 인식 결과는 입력받은 주변 환경 이미 지로부터 추론된 객체의 타입에 관한 적어도 하나의 라벨값 및 적어도 하나의 라벨값에 관한 신뢰도 값을 포함 할 수 있다. 여기서, '신뢰도 값'은 주변 환경 이미지로부터 추론된 객체의 타입에 특정 타입으로 추론될 수 있 는 확률값을 나타낸다. 인공지능 프로세서는 인공지능 모델에 의해 출력된 라벨값과 신뢰도 값에 기초하여, 객 체의 타입에 관한 정보를 획득할 수 있다. 예를 들어, 인공지능 프로세서는 주변 환경 이미지로부터 적어도 하 나의 객체를 인식하고, 적어도 하나의 객체를 타 차량, 보행자, 신호등, 교통 표지판, 간판, 또는 광고판 중 적 어도 하나의 타입으로 분류할 수 있다. 프로세서는 사용자 입력부를 통해 수신된 사용자 입력에 기초하여, 주변 환경 이미지로부터 인식된 적어도 하나의 객체 중 어느 하나의 객체를 선택할 수 있다. 사용자 입력부는 핸드 트래킹, 시선 추적(eye tracking), 또는 입력 컨트롤러 중 적어도 하나를 포함하는 증강 현실 포인팅(AR pointing) 입력을 통해 어느 하나의 객체를 선택하는 사용자 입력을 수신할 수 있다. 일 실시예에서, 사용자 입력부는 사용자의 손의 위치 또는 손가락 끝점의 위치를 인식하고, 트래킹하는 제스 처 센서를 포함할 수 있다. 다른 실시예에서, 사용자 입력부는 사용자의 양안의 시선 방향을 추적하고, 양안의 시선이 수렴하는 응시점(gaze point)의 위치를 감지하는 시선 추적 센서를 포함할 수 있다. 다른 실시예 에서, 사용자 입력부는 사용자의 신체 일부에 장착되거나, 사용자가 휴대하는 입력 컨트롤러의 위치를 추적하는 센서를 포함할 수 있다. 입력 컨트롤러 센서는 입력 컨트롤러와 차량의 윈드 쉴드(160, 도 1 참조) 간의 상대 위치 및 절대 위치를 추적할 수 있는 관성 측정 센서(예를 들어, gyroscope, accelerometer, magnetometer), 무선 통신 모듈(예를 들어, UWB, WiFi, Bluetooth) 및 터치 센서(Touch-Sensitive Surface) 중 적어도 하나와 페어링(pairing)되어 입력 컨트롤러의 위치 좌표값을 획득하도록 구성될 수 있다. 그러나, 사용자 입력부가 전술한 바와 같은 증강 현실 포인팅 입력만을 수신하는 것으로 한정되는 것은 아니다. 일 실시예에서, 사용자 입력부는 사용자의 터치 입력을 수신하는 터치 센서 또는 사용자의 음성 입력을 수신하는 마이크로폰을 포함할 수도 있다. 프로세서는 사용자 입력부를 통해 입력된 사용자 입력에 기초하여 선택된 객체에 관한 식별 정보 (예를 들어, id 정보) 및 타입 정보를 획득할 수 있다. 일 실시예에서, 프로세서는 주변 환경 이미지로부 터의 적어도 하나의 객체에 관한 인식 결과 및 통신 인터페이스를 통해 수신한 적어도 하나의 객체에 관 한 V2X 데이터 셋을 비교함으로써, 사용자 입력을 통해 선택된 객체에 관한 식별 정보 및 타입 정보를 획득할 수 있다. 일 실시예에서, 프로세서는 주변 환경 이미지로부터 객체의 번호판 정보, 위치 정보, 타입 정보, 및 예측 속도 정보 중 적어도 하나의 정보를 획득하고, 획득된 정보를 통신 인터페이스를 통해 획 득한 V2X 데이터 셋에 포함된 정보와 매칭할 수 있다. 프로세서는 매칭 결과에 기초하여, V2X 데이터 셋 에 포함된 정보 중 사용자 입력을 통해 선택된 객체에 관한 식별 정보 및 타입 정보를 추출할 수 있다. 프로세 서가 주변 환경 이미지의 인식 결과 및 V2X 데이터 셋을 이용하여, 사용자 입력을 통해 선택된 객체에 관 한 식별 정보 및 타입 정보를 획득하는 구체적인 방법에 대해서는 도 6 내지 도 9에서 상세하게 설명하기로 한 다. 프로세서는 선택된 객체와 무선 통신 연결을 수행하기 위한 UI(User Interface)를 디스플레이부 상 에 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 가상 이미지를 투사하도록 구성되는 프로젝터 (projector)를 더 포함하고, 프로세서는 증강 현실 HUD로 구성된 디스플레이부 상에 UI를 구성하는 가상 이미지를 투사하도록 프로젝터를 제어함으로써, UI를 디스플레이할 수 있다. 그러나, 이에 한정되는 것은 아니고, 다른 실시예에서 프로세서는 CID(Center Information Display), 네비게이션 장치, 계기판 디스 플레이, 또는 조수석 디스플레이 중 적어도 하나로 구성되는 디스플레이부 상에 UI를 디스플레이할 수 있 다. 디스플레이부 상에 디스플레이되는 UI는 객체의 타입에 따라 맞춤형 메뉴를 제공하는 상황 맞춤형 메뉴 UI(contextual menu UI)를 포함할 수 있다. 일 실시예에서, 프로세서는 객체의 타입에 기초하여 결정된 기능 또는 동작을 수행하기 위하여 선택 가능한 복수의 항목들을 포함하는 메뉴 UI를 디스플레이할 수 있다. 객 체의 타입이 차량인 경우, 메뉴 UI는 '차량'이라는 객체 타입에 기초하여 결정된 동작들, 예를 들어 차량에 메 시지 보내지, 차량 정보 획득, 및 위험 알림 신호 전송 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들과 관련된 UI를 포함할 수 있다. 객체의 타입이 보행자인 경우, 메뉴 UI는 보행자 타입 에 기초하여 결정된 동작들, 예를 들어 메시지 보내기, 전화, 및 위험 알림 신호 전송 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들과 관련된 UI를 포함할 수 있다. 객체의 타입이 음식점의 간판인 경우, 메뉴 UI는 음식점의 간판이라는 타입에 기초하여 결정된 동작들, 예를 들어 음식점 정보 획득, 음 식 메뉴 주문, 및 예약 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들과 관련 된 UI를 포함할 수 있다. 일 실시예에서, 프로세서는 객체와의 무선 통신이 연결되기 전, 연결 중, 및 연결 후에 따라 각각 다른 컬러 및 형태의 UI를 디스플레이할 수 있다. 예를 들어, 객체와의 무선 통신이 연결되기 전인 경우, 프로세서 는 메뉴 UI를 디스플레이하지 않고, 객체의 타입에 따라 객체를 서로 다른 컬러로 디스플레이하는 UI를 디스플레이할 수 있다. 객체와의 무선 통신이 연결되는 중인 경우, 프로세서는 연결 대상 객체의 위치를 트래킹하고, 연결 상태를 나타내는 트래킹 UI(130, 도 11a 참조)를 디스플레이할 수 있다. 객체와의 무선 통신 연결이 완료된 경우, 프로세서는 객체의 타입에 따라 결정된 기능 또는 동작을 수행하기 위한 복수의 항 목들을 나타내는 UI 뿐만 아니라, 객체의 프로필 정보, 무선 통신 연결 신호 세기, 배터리 레벨, 및 이동 속도 중 적어도 하나를 포함하는 객체 정보를 나타내는 객체 정보 UI(112 내지 115, 도 12 참조)를 디스플레이할 수 있다. 프로세서가 객체와의 무선 통신 연결 상태에 따라 서로 다른 UI를 디스플레이하는 구체적인 실시예 에 대해서는 도 10 내지 도 12에서 상세하게 설명하기로 한다. 일 실시예에서, 프로세서는 주변 환경 이미지 내에서 사용자 입력에 의해 선택된 객체에 대응되는 이미지 를 둘러싸는 도형 또는 기호로 구성된 포커싱 UI(140, 도 13a 내지 도 13c 참조)를 디스플레이할 수 있다. 프로세서는 포커싱 UI를 객체의 이동 속도에 따라 다른 컬러로 디스플레이할 수 있다. 포커싱 UI에 대해서는 도 13a 내지 도 13c에서 상세하게 설명하기로 한다. 일 실시예에서, 프로세서는 객체로부터 수신된 광고 영상 또는 소개 영상을 디스플레이할 수 있다. 일 실 시예에서, 프로세서는 객체의 광고 영상 또는 소개 영상을 포함하는 컨텐트 영상(142, 도 14 참조)을 디 스플레이한 이후, 객체와 관련된 메뉴 UI를 디스플레이할 수 있다. 프로세서가 객체의 광고 컨텐트 또는 소개 영상을 디스플레이하는 구체적인 실시예에 대해서는 도 14에서 상세하게 설명하기로 한다. 프로세서는 객체의 식별 정보를 이용하여 객체와 무선 통신 연결을 수행하도록 통신 인터페이스를 제어할 수 있다. 프로세서는 통신 인터페이스를 통해 객체와 양방향 V2X 통신 연결을 수행할 수 있 다. 디스플레이부는 증강 현실 HUD(Augmented Reality Head Up Display), 차량의 윈드 쉴드 상에 형성되는 투명 디스플레이, CID(Center Information Display), 네비게이션 장치, 계기판 디스플레이, 또는 조수석 디스플 레이 중 적어도 하나로 구성될 수 있다. 디스플레이부가 증강 현실 HUD로 구현되는 경우, 프로젝터를 통 해 차량의 윈드 쉴드에 구비되는 투명 디스플레이 상에 가상 이미지를 투사함으로써, UI를 디스플레이할 수 있 다. 디스플레이부가 CID, 네비게이션 장치, 계기판 디스플레이 또는 조수석 디스플레이 중 적어도 하나로 구 성되는 경우, 디스플레이부는 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디 스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light- emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디 스플레이(e-ink display) 중에서 적어도 하나로 구현될 수 있다. 이 경우, 디스플레이부는 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 도 3은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시한 흐름도이다. 단계 S310에서, 전자 장치는 카메라를 이용하여 차량 주변을 촬영함으로써, 주변 환경 이미지를 획득한다. 일 실시예에서, 전자 장치는 카메라를 이용하여 차량 주변의 타 차량, 보행자, 신호등, 교통 표지판, 간판, 또는 광고판 중 적어도 하나를 포함하는 객체를 촬영하여, 객체를 포함하는 주변 환경 이미지를 획득할 수 있다. 단계 S320에서, 전자 장치는 인공지능 모델을 이용하여, 주변 환경 이미지로부터 적어도 하나의 객체를 인식한다. 인공지능 모델은 주변 환경 이미지로부터 객체를 인식하고, 객체를 타입에 따라 분류(classify)하도 록 학습된 심층 신경망 모델을 포함할 수 있다. 인공지능 모델은 전자 장치의 메모리(1400, 도 2 참조)에 저장될 수 있지만, 이에 한정되는 것은 아니다. 인공지능 모델은 수만 내지 수억장의 이미지를 입력 데이터로 적용하고, 이미지에 포함되는 객체의 라벨값 (label)을 출력 정답값(groundtruth)로 적용하여 학습된(trained) 모델 파라미터로 구성되는 심층 신경망 모델 (Deep Neural Network)을 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델 (Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심 층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 그러나, 인공지능 모델이 심층 신경망 모 델만을 포함하는 것은 아니고, SVM(Support Vector Machine), 선형 회귀(linear regression), 로지스틱 회귀 (logistic regression), 나이브 베이즈 분류(Naive Bayes), 랜덤 포레스트(random forest), decision tree, 또 는 k-nearest neighbor algorithm 중 적어도 하나로 구성될 수도 있다. 전자 장치는 인공지능 모델을 이용하여, 주변 환경 이미지로부터 타 차량, 보행자, 신호등, 교통 표지판, 간판, 또는 광고판 중 적어도 하나를 포함하는 객체를 인식할 수 있다. 단계 S330에서, 전자 장치는 적어도 하나의 객체 또는 RSU(Road Side Unit)으로부터 적어도 하나의 객체 와 관련된 정보를 포함하는 V2X 데이터 셋을 수신한다. 일 실시예에서, 전자 장치는 통신 인터페이스 (1200, 도 2 참조)를 통해 적어도 하나의 객체 또는 RSU로부터 V2X 데이터 셋을 수신할 수 있다. V2X 데이터 셋 은 적어도 하나의 객체와 관련된 정보, 예를 들어 식별 정보(id 정보), 데이터 수신 일자, 번호판 정보, 타입 정보, 위치 정보, 방향 정보 및 속도 정보 중 적어도 하나를 포함할 수 있다. V2X 데이터 셋에 포함되는 정보에대해서는 도 5에서 상세하게 설명하기로 한다. 단계 S340에서, 전자 장치는 사용자 입력에 기초하여, 적어도 하나의 객체 중 제1 객체를 선택한다. 전자 장치는 주변 환경 이미지 내에 포함되는 적어도 하나의 객체 중 제1 객체를 선택하는 사용자 입력을 수신 할 수 있다. 일 실시예에서, 전자 장치는 사용자 입력부(1500, 도 2 참조)에 포함되는 핸드 트래킹 센서, 시선 추적 센서(eye tracking sensor), 또는 입력 컨트롤러 중 적어도 하나를 통해 증강 현실 포인팅(AR pointing) 입력을 수신할 수 있다. 일 실시예에서, 전자 장치는 증강 현실 HUD 상에 디스플레이되는 적어 도 하나의 객체에 대응되는 이미지 중 사용자 입력에 따라 제1 객체를 선택할 수 있다. 그러나, 이에 한정되는 것은 아니고, 전자 장치는 네비게이션 장치, CID(Center Information Display), 계기판 디스플레이, 또는 조수석 디스플레이 중 어느 하나에 디스플레이되는 주변 환경 이미지 내에 포함되는 적어도 하나의 객체에 대응되는 이미지 중 제1 객체를 선택하는 터치 입력을 수신할 수도 있다. 다른 실시예에 서, 전자 장치는 적어도 하나의 객체 중 제1 객체의 타입 또는 위치를 발화하는 음성 입력을 수신할 수도 있다. 전자 장치는 전술한 터치 입력 또는 음성 입력에 기초하여, 주변 환경 이미지에 포함되는 적어도 하나의 객체 중 제1 객체를 선택할 수 있다. 단계 S350에서, 전자 장치는 주변 환경 이미지의 인식 결과 및 수신된 V2X 데이터 셋을 이용하여, 제1 객 체에 관한 정보를 획득한다. 일 실시예에서, 전자 장치는 주변 환경 이미지로부터의 적어도 하나의 객체 에 관한 인식 결과 및 통신 인터페이스(1200, 도 2 참조)를 통해 수신한 적어도 하나의 객체에 관한 V2X 데이터 셋을 비교함으로써, 제1 객체에 관한 식별 정보 및 타입 정보를 획득할 수 있다. 일 실시예에서, 전자 장치 는 주변 환경 이미지로부터 객체의 번호판 정보, 위치 정보, 타입 정보, 및 예측 속도 정보 중 적어도 하 나의 정보를 획득하고, 획득된 정보를 통신 인터페이스를 통해 획득한 V2X 데이터 셋에 포함된 정보와 매 칭할 수 있다. 전자 장치는 매칭 결과에 기초하여, V2X 데이터 셋에 포함된 정보 중 사용자 입력을 통해 선택된 객체에 관한 식별 정보 및 타입 정보를 추출할 수 있다. 단계 S360에서, 전자 장치는 제1 객체에 관한 정보에 기초하여, 제1 객체와 무선 통신 연결을 위한 UI(User Interface)를 디스플레이한다. 일 실시예에서, 전자 장치는 제1 객체와 무선 통신 연결을 위한 UI를 차량의 윈드 쉴드에 프로젝터를 이용하여 가상 이미지를 투사함으로써, 증강 현실 HUD(Augmented Reality Head Up Display)에 UI를 디스플레이할 수 있다. 그러나, 이에 한정되는 것은 아니고, 다른 실시예에서 전자 장 치는 차량의 CID(Center Information Display), 네비게이션 장치, 계기판 디스플레이, 또는 조수석 디스 플레이 중 적어도 하나에 UI를 디스플레이 할 수 있다. 제1 객체와 무선 통신 연결을 위한 UI는 제1 객체의 타입에 기초하여 결정된 기능 또는 동작을 수행하기 위하여 사용자에 의해 선택 가능한 메뉴 UI를 포함할 수 있다. 일 실시예에서, 메뉴 UI는 제1 객체에 대하여 수행 가능 한 기능 또는 동작들을 나타내는 복수의 항목들에 관한 UI를 포함할 수 있다. 객체의 타입이 차량인 경우, 메뉴 UI는 '차량'이라는 객체 타입에 기초하여 결정된 동작들, 예를 들어 차량에 메시지 보내지, 차량 정보 획득, 및 위험 알림 신호 전송 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들과 관련된 UI를 포함할 수 있다. 객체의 타입이 보행자인 경우, 메뉴 UI는 '보행자' 타입에 기초하여 결정된 동작들, 예를 들어 메시지 보내기, 전화, 및 위험 알림 신호 전송 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수 신하는 복수의 항목들과 관련된 UI를 포함할 수 있다. 객체의 타입이 음식점의 간판인 경우, 메뉴 UI는 '음식점 의 간판'이라는 타입에 기초하여 결정된 동작들, 예를 들어 음식점 정보 획득, 음식 메뉴 주문, 및 예약 중 적 어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들과 관련된 UI를 포함할 수 있다. 일 실시예에서, 전자 장치는 메뉴 UI 뿐만 아니라, 제1 객체의 프로필 정보, 무선 통신 연결 신호 세기, 배터리 레벨, 및 이동 속도 중 적어도 하나를 포함하는 객체 정보를 나타내는 객체 정보 UI를 디스플레이할 수 있다. 전자 장치는 제1 객체의 객체 정보를 문자, 숫자, 기호, 도형, 및 아이콘 중 적어도 하나의 형태로 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 제1 객체와의 무선 통신이 연결되기 전, 연결 중, 및 연결 후에 따라 각각 다른 컬러 및 형태의 UI를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 주변 환경 이미지로부터 인식된 적어도 하나의 객체를 객체의 타입에 따라 서로 다른 컬러의 이미지로 디스플레이할 수 있다. 도 4는 본 개시의 일 실시예에 따른 전자 장치가 차량 주변의 객체들과 V2X 연결을 통해 V2X 데이터 셋 (V2X data set)을 수신하는 동작을 설명하기 위한 도면이다. 도 4를 참조하면, 전자 장치는 차량에 탑재되고, 차량의 주변의 객체(200, 310), RSU, 및 서버 중 적어도 하나로부터 객체(200, 310)와 관련된 정보를 포함하는 V2X 데이터 셋(V2X data set)을 수신할 수 있다. 일 실시예에서, 전자 장치는 차량 주변에 위치하거나 주행 중인 타 차량과 차량 간 연결 (Vehicle to Vehicle, V2V)을 수행함으로써, 타 차량에 탑재된 무선 통신 장치로부터 타 차량의 V2X 데이터 셋을 수신할 수 있다. 일 실시예에서, 전자 장치는 보행자가 보유하거나 휴대하고 있는 모바 일 디바이스와 차량-보행자 간 연결(Vehicle to Pedestrian, V2P)을 수행함으로써, 모바일 디바이스(31 0)로부터 보행자와 관련된 정보를 포함하는 V2X 데이터 셋을 수신할 수 있다. 일 실시예에서, 전자 장치 는 RSU(Road Side Unit)와 차량-인프라 연결(Vehicle to Infrastructure, V2I)을 수행함으로써, RSU로부터 차량의 주변의 객체(예를 들어, 타 차량 및 보행자)에 관한 V2X 데이터 셋을 수 신할 수 있다. RSU는 도로 변 기지국으로서, RSU가 설치된 위치로부터 기 설정된 범위 내에 위치하거 나 이동 중인 적어도 하나의 객체에 관한 V2X 데이터 셋을 수신하고, V2X 데이터베이스를 구축할 수 있다. RSU는 구축된 V2X 데이터베이스를 기 설정된 범위 내의 객체에 전송할 수 있다. 일 실시예에서, 전자 장치 는 차량 외부의 서버와 차량-서버 간 연결(Vehicle to Server, V2S)을 수행함으로써, 서버 로부터 차량 주변의 객체(예를 들어, 타 차량 및 보행자)에 관한 V2X 데이터 셋을 수신할 수 있다. V2X 데이터 셋에 포함되는 객체에 관한 정보에 대해서는 도 5에서 상세하게 설명하기로 한다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 차량 주변의 객체들로부터 수신한 V2X 데이터 셋에 포함되는 정보를 도시한 표이다. 도 5를 참조하면, V2X 데이터 셋은 차량 주변의 적어도 하나의 객체와 관련된 일자 정보, OBU 식별 정보, RSU 식별 정보, 수신 일자 정보, 번호판 정보, 차량 타입 정보, 위치 좌표 정 보, 방향 정보, 및 속도 정보을 포함할 수 있다. 도 5는 V2X 데이터 셋의 예시를 도시한 표일 뿐, 본 개시의 V2X 데이터 셋이 도 5에 도시된 정보만을 포함하는 것으로 한정되는 것은 아니다. 일 실시예에서, V2X 데이터 셋은 도 5에 도시된 정보들 중 적어도 하나를 포함하지 않을 수 있고, 도 5에 도 시되지 않은 정보들을 더 포함할 수도 있다. 일자 정보는 현재 날짜에 관한 정보를 나타낸다. 도 5에 도시된 실시예에서, 일자 정보는 2021년 6월 13일을 나타낸다. OBU 식별 정보는 차량 내 V2X 통신 단말인 OBU(On Board Unit)의 식별 정보를 나타낸다. 도 5에 도시된 실시예에서, OBU 식별 정보는 7001FF68이다. RSU 식별 정보는 차량 내 V2X 통신 단말이 V2X 데이터 셋을 수신한 RSU의 식별 정보를 나타낸다. 도 5에 도시된 실시예에서, RSU 식별 정보는 객체에 따라 각각 다르지만, 이에 한정되는 것은 아니다. 수신 일자 정보는 V2X 데이터 셋이 수신된 일자에 관한 정보를 나타낸다. 도 5에 도시된 실시예에서, 수신 일자 정보는 2021년 6월 13일이다. 번호판 정보는 객체가 차량인 경우, 차량의 번호판에 관한 정보를 나타낸다. 도 5에 도시된 실시예에서의 번호판 정보를 참조하면, 제1 타 차량의 번호판은 29머3924이고, 제2 타 차량의 번호판은 34더3925이고, 제3 타 차량의 번호판은 21가3926이며, 제4 타 차량의 번호판은 27자3845이다. 차량 타입 정보는 객체가 차량인 경우, 차량의 타입을 대응되는 식별 번호로 나타낸다. 차량의 타입은 예 를 들어, 승용차, SUV(Sport-Utility Vehicle), MPV(Multi-Utility Vehicle), 픽업 트럭, 또는 상용차 (commercial vehicle) 등으로 분류될 수 있으나, 이에 한정되는 것은 아니다. 도 5에 도시된 실시예에서, '4'는 승용차에 대응되는 식별 번호일 수 있으나, 이에 한정되는 것은 아니다. 도 5에는 도시되지 않았지만, 차량 타입 정보는 객체 타입 정보로 대체될 수 있다. 객체 타입 정보는, 차 량(100, 도 4 참조) 주변의 객체(200, 300, 도 4 참조)의 타입을 나타내는 정보로서, 예를 들어, 타 차량, 보행 자, 신호등, 교통 표지판, 간판, 또는 광고판 등을 포함할 수 있다. 위치 좌표 정보는 객체의 3차원 위치 좌표 정보를 나타낸다. 위치 좌표 정보는 X좌표, Y좌표 , 및 Z좌표을 포함할 수 있다. 일 실시예에서, 위치 좌표 정보는 GPS 정보로부터 획득한 위도 및 경도 정보를 포함할 수 있다. 방향 정보는 객체가 향하는 방향에 관한 정보를 나타낸다. 이동 속도 정보는 객체의 이동 속도에 관한 정보를 나타낸다. 전자 장치는 V2X 데이터 셋 및 주변 환경 이미지로부터 획득된 정보를 이용하여, 객체의 식별 정보 및 타입 정보를 획득하고, 객체와 양방향 V2X 통신 연결을 위한 UI를 디스플레이할 수 있다. 이에 관한 구체적 인 실시예는 도 6 내지 도 9에서 상세하게 설명하기로 한다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 차량 주변의 객체와 무선 통신 연결을 수행하는 방법을 도시한 흐름도이다. 도 6에 도시된 단계들 중 S610 내지 S630은 도 3에 도시된 단계 S350을 구체화한 단계들이다. 단계 S610은 도 3 에 도시된 단계 S340이 수행된 이후 수행될 수 있다. 도 6에 도시된 단계 S640은 도 3에 도시된 단계 S360을 구 체화한 단계이다. 단계 S610에서, 전자 장치는 주변 환경 이미지로부터 제1 객체의 번호판 정보, 위치 정보, 타입 정보, 및 예측 속도 정보 중 적어도 하나의 정보를 획득한다. 전자 장치는 카메라를 이용하여 획득한 차량 주변에 관한 주변 환경 이미지로부터, 타 차량의 번호판을 인식할 수 있다. 일 실시예에서, 전자 장치는 인공지능 모델을 이용하는 추론을 통해, 주변 환경 이미지 로부터 타 차량 및 타 차량의 번호판을 인식할 수 있다. 그러나, 이에 한정되는 것은 아니고, 전자 장치 는 공지의 이미지 프로세싱 기술을 통해, 주변 환경 이미지로부터 타 차량 및 타 차량의 번호판을 인식할 수 있 다. 전자 장치는 인식된 번호판으로부터 타 차량의 번호판 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 OCR 기술(Optical Character Recognition)을 사용하거나, 또는 머신 러닝을 이용하여 번호판으로 부터 타 차량의 번호판 정보를 나타내는 문자 및 숫자를 식별할 수 있다. 전자 장치는 주변 환경 이미지로부터 인식된 객체의 위치 정보를 획득할 수 있다. 일 실시예에서 전자 장 치는 주변 환경 이미지로부터 인식된 객체와 전자 장치가 탑재된 자 차량 간의 거리 및 방향을 계 산할 수 있다. 전자 장치는 예를 들어, 이미지 프로세싱 기술을 이용하여 자 차량과 객체 간의 거리 및 방향에 관한 정보를 획득할 수 있으나, 이에 한정되는 것은 아니다. 다른 예를 들어, 전자 장치는 심층 신경망 모델을 이용하여 자 차량과 객체 간의 거리 및 방향을 예측할 수 있다. 전자 장치는 자 차량과 객 체 간의 거리 및 방향에 관한 정보와 GPS 등을 통해 획득한 자 차량의 위치 정보에 기초하여, 객체의 위도 및 경도를 예측할 수 있다. 전자 장치는 주변 환경 이미지로부터 인식된 객체의 타입에 관한 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 인공지능 모델을 이용하여 주변 환경 이미지로부터 객체를 인식하고, 객체를 타입에 따라 분 류할 수 있다. 인공지능 모델은 주변 환경 이미지로부터 객체를 인식하고, 인식된 객체를 타입에 따라 분류 (classify)하도록 학습된 심층 신경망 모델을 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델(Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 그러나, 인공지능 모델이 심층 신경망 모델만을 포함하는 것은 아니고, SVM(Support Vector Machine), 선형 회귀(linear regression), 로지스틱 회귀(logistic regression), 나이브 베이즈 분류(Naive Bayes), 랜덤 포레스트(random forest), decision tree, 또는 k-nearest neighbor algorithm 중 적어도 하나로 구성될 수도 있다. 전자 장치는 인공지능 모델을 이용하여, 주변 환경 이미지로부터 인식된 객체를 타 차량, 보행자, 신호등, 교통 표지판, 간 판, 또는 광고판 중 적어도 하나의 타입으로 분류할 수 있다. 전자 장치는 주변 환경 이미지 내의 객체를 시간의 흐름에 따라 트래킹하고, 객체의 위치 변화를 복수의 시점에 따라 획득함으로써, 객체의 속도를 예측할 수 있다. 일 실시예에서, 전자 장치는 제1 시점에서의 주변 환경 이미지 내의 객체의 제1 위치와 제2 시점에서의 객체의 제2 위치 간의 차이 값을 계산하고, 계산된 차이값을 제1 시점과 제2 시점 간의 시간 간격으로 나누는 연산을 통해 객체의 속도를 예측할 수 있다. 단계 S620에서, 전자 장치는 주변 환경 이미지로부터 획득된 객체의 정보와 V2X 데이터 셋에 포함된 정보 를 매칭한다. 일 실시예에서, 전자 장치는 주변 환경 이미지로부터 식별된 객체의 번호판 정보를 V2X 데 이터 셋(500, 도 5 참조)에 포함된 번호판 정보(550, 도 5 참조)와 매칭할 수 있다. 일 실시예에서, 전자 장치 는 주변 환경 이미지로부터 획득한 객체의 위치 정보를 V2X 데이터 셋에 포함된 위치 좌표 정보 (570, 도 5 참조)와 매칭할 수 있다. 일 실시예에서, 전자 장치는 주변 환경 이미지로부터 인식된 객체의 타입 정보를 V2X 데이터 셋에 포함된 차량 타입 정보(560, 도 5 참조)와 매칭할 수 있다. 일 실시예에서, 전자 장치는 주변 환경 이미지로부터 예측된 객체의 속도를 V2X 데이터 셋에 포함된 속도 정보(590, 도 5 참조)와 매칭할 수 있다. 단계 S630에서, 전자 장치는 매칭 결과에 기초하여, V2X 데이터 셋으로부터 제1 객체의 식별 정보 및 타 입 정보를 추출한다. 일 실시예에서, 전자 장치는 주변 환경 이미지로부터 식별된 번호판과 V2X 데이터 셋의 번호판 정보 를 비교하고, 비교 결과 동일한 번호판으로 매칭된 객체의 식별 정보 및 타입 정보를 V2X 데이터 셋 으로부터 추출할 수 있다. 전자 장치가 번호판 정보를 이용하여, V2X 데이터 셋으로부터 객체의 식 별 정보 및 타입 정보를 추출하는 구체적인 실시예에 대해서는 도 7에서 상세하게 설명하기로 한다. 일 실시예에서, 전자 장치는 주변 환경 이미지로부터 예측된 객체의 위치 정보와 V2X 데이터 셋의 위치 좌표 정보를 비교하고, 매칭되는 좌표 정보를 갖는 객체의 식별 정보 및 타입 정보를 V2X 데이터 셋 으로부터 추출할 수 있다. 전자 장치가 객체의 위치 정보의 매칭 결과를 이용하여, V2X 데이터 셋 으로부터 객체의 식별 정보 및 타입 정보를 추출하는 구체적인 실시예에 대해서는 도 8에서 상세하게 설명 하기로 한다. 일 실시예에서, 전자 장치는 주변 환경 이미지로부터 인식된 객체의 타입을 V2X 데이터 셋에 포함된 차량 타입 정보와 비교하고, 비교 결과에 따라 동일한 타입을 갖는 객체의 식별 정보를 V2X 데이터 셋 으로부터 추출할 수 있다. 일 실시예에서, 전자 장치는 주변 환경 이미지로부터 획득된 객체의 예측 속도 정보를 V2X 데이터 셋 에 포함된 속도 정보와 비교하고, 비교 결과에 따라 동일한 속도로 이동하는 객체의 식별 정보 및 타 입 정보를 V2X 데이터 셋으로부터 추출할 수 있다. 전자 장치가 시간의 흐름에 따라 복수의 시점에 서 객체의 이동 속도를 예측하고, V2X 데이터 셋으로부터 객체의 식별 정보 및 타입 정보를 추출하는 구체 적인 실시예에 대해서는 도 9에서 상세하게 설명하기로 한다. 단계 S640에서, 전자 장치는 제1 객체의 식별 정보 및 타입 정보에 기초하여, 제1 객체와 무선 통신 연결 을 위한 UI를 디스플레이한다. 도 7은 본 개시의 일 실시예에 따른 전자 장치가 타 차량의 번호판에 관한 정보에 기초하여, 타 차량의 식별 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 7을 참조하면, 전자 장치는 차량의 윈드 쉴드 상에 표시되는 주변 환경 이미지로부터 타 차량 을 인식할 수 있다. 주변 환경 이미지는 카메라를 이용하여 차량의 주변에서 이동하고 있는 타 차량 을 촬영함으로써 획득될 수 있다. 전자 장치는 주변 환경 이미지로부터, 타 차량의 번호판을 인식할 수 있다. 일 실시예에서, 전 자 장치는 인공지능 모델을 이용하는 추론을 통해, 주변 환경 이미지로부터 타 차량 및 타 차량의 번호판을 인식할 수 있다. 그러나, 이에 한정되는 것은 아니고, 전자 장치는 공지의 이미지 프로세 싱 기술을 통해, 주변 환경 이미지로부터 타 차량 및 타 차량의 번호판을 인식할 수 있다. 전자 장치 는 인식된 번호판으로부터 타 차량의 번호판 정보를 획득할 수 있다. 일 실시예에서, 전자 장 치는 OCR 기술(Optical Character Recognition)을 사용하거나, 또는 머신 러닝을 이용하여 번호판으로부 터 타 차량의 번호판 정보를 나타내는 문자 및 숫자를 식별할 수 있다. 도 7에 도시된 실시예에서, 전자 장치는 타 차량의 번호판으로부터 29머3924라는 문자 및 숫자로 구성된 번호판 정보를 식별할 수 있다. 전자 장치는 식별된 타 차량의 번호판 정보와 V2X 데이터 셋(500, 도 5 참조)의 번호판 정보(550, 도 5 참조)를 매칭할 수 있다. 도 5를 함께 참조하면, V2X 데이터 셋의 번호판 정보 중 '29머3924'라는 정보를 갖는 객체는 1번 객체이다. 전자 장치는 주변 환경 이미지로부터 식별된 타 차량의 번호 판 정보와 V2X 데이터 셋을 비교함으로써, 동일한 번호판 정보(예를 들어, 29머3924)를 갖는 1번 객체를 식별할 수 있다. 전자 장치는 식별된 1번 객체의 식별 정보 및 타입 정보를 V2X 데이터 셋으로부터 추출할 수 있다. 도 5에 도시된 실시예를 함께 참조하면, 전자 장치는 V2X 데이터 셋으로부터 1번 객체의 OBU 식별 정보(520, 도 5 참조), RSU 식별 정보(530, 도 5 참조), 수신 일자 정보(540, 도 5 참조), 및 차량 타입 정보 (560, 도 5 참조)를 획득할 수 있다. 그러나, 이에 한정되는 것은 아니고, 전자 장치는 V2X 데이터 셋 으로부터 제1 객체의 위치 정보(570, 도 5 참조), 방향 정보(580, 도 5 참조) 및 속도 정보(590, 도 5 참 조)를 획득할 수도 있다. 전자 장치는 V2X 데이터 셋으로부터 추출된 1번 객체의 식별 정보 및 타입 정보를 이용하여, 1번 객 체와 무선 통신 연결을 위한 UI를 디스플레이할 수 있다. 도 8은 본 개시의 일 실시예에 따른 전자 장치가 차량과 객체(810, 820, 830)와의 위치 관계에 기초 하여 객체(810, 820, 830)의 식별 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 8을 참조하면, 카메라를 이용하여 복수의 객체(810, 820, 830)를 촬영함으로써 획득된 주변 환경 이미지로부 터 복수의 객체(810, 820, 830)의 위치 정보를 획득할 수 있다. 일 실시예에서 전자 장치는 주변 환경 이 미지로부터 인식된 복수의 객체(810, 820, 830)와 전자 장치가 탑재된 자 차량 간의 거리 및 방향을 계산할 수 있다. 전자 장치는 예를 들어, 이미지 프로세싱 기술을 이용하여 자 차량과 복수의 객체 (810, 820, 830) 각각과의 거리 및 방향에 관한 정보를 획득할 수 있다. 그러나, 이에 한정되는 것은 아니고, 전자 장치는 심층 신경망 모델을 이용하여 자 차량과 복수의 객체(810, 820, 830) 간의 거리 및 방 향을 예측할 수 있다. 도 8에 도시된 실시예에서, 전자 장치는 주변 환경 이미지로부터 자 차량과 제1 객체 간의 거리가 5.2m이고, 방향은 30˚로 예측할 수 있다. 마찬가지로, 전자 장치는 자 차량 과 제2 객체 간의 거리는 4.8m이고, 방향은 0˚이며, 자 차량과 제3 객체 간의 거리는 2.8m이고, 방향은 300˚로 예측할 수 있다. 전자 장치는 GPS 센서 등을 이용하여, 자 차량의 위치 좌표 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 CAN(Controller Area Network) 통신을 통해 자 차량에 포함되는 GPS 센서로부터 자 차 량의 위도 및 경도 정보를 획득할 수 있다. 그러나, 이에 한정되는 것은 아니고, 전자 장치는 자체 적으로 GPS 센서를 포함하고, GPS 센서를 이용하여 전자 장치가 탑재된 자 차량의 위도 및 경도 정 보를 획득할 수 있다. 도 8에 도시된 실시예에서, 자 차량의 위도는 37.4˚N이고,경도는 127˚W일 수 있다. 전자 장치는 자 차량과 복수의 객체(810, 820, 830) 간의 거리 및 방향에 관한 정보와 GPS 센서를 이용하여 획득한 자 차량의 위치 정보(예를 들어, 위도 및 경도 정보)에 기초하여, 복수의 객체(810, 820, 830)의 위도 및 경도를 예측할 수 있다. 전자 장치는 예측된 복수의 객체(810, 820, 830)의 위치 정보와 V2X 데이터 셋(500, 도 5 참조)의 위치 좌표 정보(570, 도 5 참조)를 비교하고, 매칭되는 좌표 정보를 갖는 객 체의 식별 정보 및 타입 정보를 V2X 데이터 셋으로부터 추출할 수 있다. 도 5에 도시된 실시예를 함께 참 조하면, 전자 장치는 제1 객체에 대하여 예측된 위치 좌표 정보가 (127.2673, 34.68578, 567)로 예 측된 경우, V2X 데이터 셋의 위치 좌표 정보와 비교하고, 동일하거나 유사한 위치 좌표를 갖는 객체 의 OBU 식별 정보(520, 도 5 참조), RSU 식별 정보(530, 도 5 참조), 수신 일자 정보(540, 도 5 참조), 및 차 량 타입 정보(560, 도 5 참조)를 획득할 수 있다. 도 9는 본 개시의 일 실시예에 따른 전자 장치가 객체(910, 920)의 시간의 흐름에 따른 위치 관계 변화에 기초하여 객체(910, 920)의 식별 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 9를 참조하면, 전자 장치는 카메라를 이용하여 복수의 객체(910, 920)를 촬영함으로써 주변 환경 이미 지를 획득할 수 있다. 전자 장치는 주변 환경 이미지 내의 복수의 객체(910, 920)를 시간의 흐름에 따라 트래킹하고, 복수의 객체(910, 920)의 위치 변화를 복수의 시점에 따라 실시간으로 획득함으로써, 객체의 속도 를 예측할 수 있다. 도 9에 도시된 실시예에 따르면, 제1 시점(t1)에서 전자 장치가 탑재된 자 차량과 제1 객체 간의 거리는 10m이고, 제1 객체의 속도는 80km/h로 예측된다. 또한, 제1 시점(t1)에서 자 차량과 제2 객체 간의 거리는 10m이고, 제2 객체의 속도는 60km/h로 예측된다. 도 9에 도시 된 실시예에서, 시간의 흐름에 따라 제2 시점(t2)이 된 경우, 제2 시점(t2)에서 자 차량과 제1 객체 간의 거리는 30m로 변경되고, 자 차량과 제2 객체 간의 거리는 20m로 변경된 것으로 예측될 수 있다. 전자 장치는 제1 시점(t1)에서의 자 차량과 복수의 객체(910, 920) 간의 거리와 제2 시점(t2)에서의 복수의 객체(910, 920) 간의 거리의 차이 값을 계산하고, 계산된 차이값을 제1 시점(t1)과 제2 시점(t2) 간의 시 간 간격(△t)으로 나누는 연산을 통해 복수의 객체(910, 920)의 속도 변화를 예측할 수 있다. 도 9에 도시된 실 시예에서, 전자 장치는 제2 시점(t2)에서 자 차량과 제1 객체 간의 거리가 10m에서 30m로 변경 된 것을 예측하고, 거리의 차이값인 20m를 제1 시점(t1)과 제2 시점(t2) 간의 시간 간격(△t)으로 나누는 연산을 통해 제1 객체의 속도가 85km/h로 변경된 것을 예측할 수 있다. 동일한 방법으로, 전자 장치는 제2 객체의 속도가 70km/h로 변경된 것을 예측할 수 있다. 전자 장치는 시간의 흐름에 따라 변경된 복수의 객체(910, 920)의 속도를 V2X 데이터 셋(500, 도 5 참 조)에 포함된 속도 정보(590, 도 5 참조)와 비교하고, 비교 결과에 따라 동일한 속도로 이동하는 객체의 식별 정보 및 타입 정보를 V2X 데이터 셋으로부터 추출할 수 있다. 예를 들어, 제2 객체에 대하여 제2 시 점(t2)에서 예측된 속도가 70km/h인 경우, 전자 장치는 V2X 데이터 셋의 속도 정보와 비교하고, 비교 결과 동일한 70km/h의 속도로 이동하는 4번 객체의 OBU 식별 정보(520, 도 5 참조), RSU 식별 정보(530, 도 5 참조), 수신 일자 정보(540, 도 5 참조), 및 차량 타입 정보(560, 도 5 참조)를 V2X 데이터 셋 으로부터 획득할 수 있다. 일 실시예에서, 전자 장치는 시간의 흐름에 따라 복수의 객체(910, 920)의 변경된 속도 정보 뿐만 아니라, 각 시점에서의 복수의 객체(910, 920)의 위치 정보를 실시간으로 획득하고, 획득된 복수의 객체(910, 920)의 실시간 위치 정보를 V2X 데이터 셋에 포함된 위치 좌표 정보(570, 도 5 참조)와 비교할 수 있다. 전자 장치는 비교 결과에 따라 복수의 객체(910, 920)에 대응되는 객체를 V2X 데이터 셋으로부터 식 별하고, V2X 데이터 셋으로부터 복수의 객체(910, 920)에 관한 식별 정보 및 타입 정보를 획득할 수 있다. 전자 장치는 복수의 시점에서 예측한 복수의 객체(910, 920)의 속도 정보 뿐만 아니라, 복수의 객체(910, 920)의 실시간 위치 정보를 V2X 데이터 셋에 포함된 정보와 비교함으로써, 매칭 정확도를 향상시키고, 복 수의 객체(910, 920)에 관한 정확한 식별 정보 및 타입 정보를 획득할 수 있다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 객체와의 무선 통신 연결이 수행되기 전에 디스플레이 하는 UI의 예시를 도시한 도면이다. 전자 장치는 객체와의 무선 통신이 연결되기 전, 연결 중, 및 연결 후 각각의 경우에 따라 서로 다른 UI 를 디스플레이할 수 있다. 도 10을 참조하면, 전자 장치는 증강 현실 HUD로 구성된 디스플레이부 상에 복수의 객체(101 내지 105)에 대응되는 이미지들 및 클러스터링 UI를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 프로젝터를 이용하여 차량의 윈드 쉴드 상에 가상 이미지를 투사함으로써, 증강 현실 HUD를 구현할 수 있 다. 그러나, 이에 한정되는 것은 아니고, 다른 실시예에서 전자 장치는 차량 내의 CID(Center Information Display), 네비게이션 장치, 계기판 디스플레이, 또는 조수석 디스플레이 중 적어도 하나에 UI를 디스플레이할 수 있다. 전자 장치는 디스플레이부 상에 표시되는 복수의 객체(101 내지 105)에 대응되는 이미지를 복수의 객체(101 내지 105)의 타입에 따라 서로 다른 컬러로 디스플레이할 수 있다. 일 실시예에서, 전자 장치의 프로세서(1300, 도 2 참조)는 카메라(1100, 도 2 참조)를 이용하여 차량 주변의 복수의 객체(101 내지 105)를 촬영함으로써 획득된 주변 환경 이미지로부터 복수의 객체(101 내지 105) 각각의 타입을 인식할 수 있다. 프로 세서가 주변 환경 이미지로부터 복수의 객체(101 내지 105)의 타입을 인식하는 구체적인 방법에 대해서는 도 1 및 도 2에서의 설명과 동일하므로, 중복되는 설명은 생략한다. 일 실시예에서, 프로세서는 인식된 복수의 객체(101 내지 105)의 타입에 따라 복수의 객체(101 내지 105) 각각에 대하여 서로 다른 컬러를 할당할 수 있다. 예를 들어, 타 차량으로 인식되는 제1 객체 및 제2 객체에는 빨간색을 할당하고, 보행자로 인식된 제3 객체에는 노란색을 할당하고, 광고판으로 인식된 제4 객체에는 녹색을 할당하며, 신호등으로 인식된 제5 객체에는 파란색을 할당할 수 있다. 프로세서는 주변 환경 이미지 내의 복수의 객 체(101 내지 105)에 대응되는 위치에 할당된 컬러를 나타내는 이미지를 오버랩하여 표시함으로써, 복수의 객체 (101 내지 105)를 타입에 따라 서로 다른 컬러로 디스플레이할 수 있다. 일 실시예에서, 디스플레이부가 증강 현실 HUD로 구현되는 경우, 프로세서는 프로젝터를 이용하여 복수의 객체(101 내지 105)의 위치에 할당된 컬러를 나타내는 이미지를 투사할 수 있다. 그러나, 이에 한정되는 것은 아니고, 다른 실시예에서 디스플레이부가 CID, 네비게이션 장치, 계기판 디스플레이, 또는 조 수석 디스플레이 중 적어도 하나로 구현되는 경우, 프로세서는 이미지 프로세싱을 통해 복수의 객체(101 내지 105)를 타입에 따라 서로 다른 컬러로 디스플레이할 수 있다. 프로세서는 차량의 위치로부터 기 설정된 거리 보다 멀리 이격되어 있는 복수의 객체들이 겹쳐있는 경우, 겹쳐있는 복수의 객체들의 수를 나타내는 클러스터링 UI(clustering User Interface)를 디스플레이할 수 있다. 클러스터링 UI는 겹쳐진 복수의 객체의 수를 숫자로 나타내는 아이콘으로 구성될 수 있다. 클러스터 링 UI를 선택하는 사용자 입력이 수신되는 경우, 프로세서는 겹쳐져 있는 복수의 객체 중 어느 하나 를 선택할 수 있는 복수의 항목들로 구성된 UI를 디스플레이할 수 있다. 도 10에 도시된 실시예에 따른 전자 장치는 무선 통신 연결 대상인 복수의 객체(101 내지 105)를 타입에 따라 서로 다른 컬러로 디스플레이하는 바, 사용자가 차량, 보행자, 신호등, 광고판, 간판 등 객체의 타입에 따 라 연결하고자 하는 대상을 쉽게 인지하고, 구별할 수 있게 하여 사용자 편의성을 향상시킬 수 있다. 또한, 본 개시의 일 실시예에 따른 전자 장치는 자 차량과 일정 거리 이상으로 이격된 복수의 객체들의 수를 나타 내는 클러스터링 UI를 통해, 사용자가 멀리 떨어진 복수의 객체들의 개수가 몇인지 직관적으로 인지할 수 있게 하는 기술적 효과를 제공한다. 도 11a는 본 개시의 일 실시예에 따른 전자 장치가 객체와의 무선 통신 연결이 수행되는 중에 디스플레이 하는 UI의 예시를 도시한 도면이다. 도 11a를 참조하면, 증강 현실 HUD로 구성된 디스플레이부 상에 사용자에 의해 선택된 제1 객체와의 연결 상태를 나타내는 트래킹 UI를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 프로젝터를 이용하여 차량의 윈드 쉴드 상에 트래킹 UI에 대응되는 가상 이미지를 투사함으로써, 증강 현실 HUD 를 구현할 수 있다. 그러나, 이에 한정되는 것은 아니고, 다른 실시예에서 전자 장치는 차량 내의 CID(Center Information Display), 네비게이션 장치, 계기판 디스플레이, 또는 조수석 디스플레이 중 적 어도 하나에 트래킹 UI를 디스플레이할 수 있다. 일 실시예에서, 전자 장치의 프로세서(1300, 도 2 참조)는 사용자 입력부(1500, 도 2 참조)로부터 입력받 은 사용자 입력에 기초하여 디스플레이부 상에 디스플레이되는 복수의 객체 중 제1 객체를 선택하고, 선택된 제1 객체의 위치를 트래킹할 수 있다. 프로세서는 제1 객체의 위치를 가리키 는 화살표 형태의 트래킹 UI를 디스플레이할 수 있다. 일 실시예에서, 프로세서는 제1 객체와의 무선 통신 연결 상태에 기초하여, 트래킹 UI의 컬러 를 다르게 변형하여 디스플레이할 수 있다. 프로세서가 트래킹 UI의 컬러를 변형하여 디스플레이하 는 구체적인 실시예에 대해서는 도 11b에서 상세하게 설명하기로 한다. 도 11b는 본 개시의 일 실시예에 따른 전자 장치가 객체와의 무선 통신 연결이 진행됨에 따라 변화되는 트래킹 UI(130a, 130b, 130c)의 예시를 도시한 도면이다. 도 11b를 참조하면, 전자 장치의 프로세서(1300, 도 2 참조)는 제1 객체(101, 도 11a 참조)와의 무선 통 신 연결의 상태에 기초하여, 트래킹 UI(130a, 130b, 130c)의 컬러를 변경하여 디스플레이할 수 있다. 일 실시예에서, 프로세서는 제1 객체와 무선 통신 연결이 되지 않은 상태에서는 트래킹 UI(130a)를 흰색으로 표시하거나, 또는 컬러 없이 빈 도형의 형태로 디스플레이할 수 있다. 트래킹 UI(130a)를 구성하는 도 형은 예를 들어, 삼각형 또는 화살표의 형태를 가질 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 프로세서는 제1 객체와의 무선 통신 연결 중인 상태에서는, 트래킹 UI(130b)에 포함 되는 복수의 도형을 나타내는 컬러의 농도 또는 채도를 단계적으로 변경하는 그라데이션(gradation) 형태로 디스플레이할 수 있다. 일 실시예에서, 프로세서는 제1 객체와의 무선 통신 연결이 완료된 상태에서는, 트래킹 UI(130c)에 포함되는 복수의 도형을 단일 컬러로 디스플레이할 수 있다. 예를 들어, 무선 통신 연결이 완료된 상태에서 트 래킹 UI(130c)는, 무선 통신 연결 중인 상태에서의 트래킹 UI(130b)에 포함되는 복수의 도형의 컬러 중 최대 농 도를 갖는 컬러와 동일한 컬러로 디스플레이될 수 있다. 그러나, 이에 한정되는 것은 아니다. 도 11a 및 도 11b에 도시된 실시예에서, 전자 장치는 제1 객체와의 무선 통신 연결 상태에 따라 트 래킹 UI(130a, 130b, 130c)의 컬러를 변경하여 디스플레이함으로써, 사용자가 트래킹 UI(130a, 130b, 130c)를 통해 제1 객체와의 무선 통신 연결 상태를 직관적으로 인지할 수 있게 하는 기술적 효과를 제공한다. 이를 통해, 사용자 편의성이 향상될 수 있다. 도 12는 본 개시의 일 실시예에 따른 전자 장치가 제1 객체와의 무선 통신 연결이 수행된 이후에 디 스플레이하는 UI의 예시를 도시한 도면이다. 도 12를 참조하면, 전자 장치는 증강 현실 HUD로 구성된 디스플레이부 상에 제1 객체에 관한 정보를 나타내는 UI를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 프로젝터를 이용하여 차 량의 윈드 쉴드 상에 UI를 구성하는 가상 이미지를 투사함으로써, 증강 현실 HUD를 구현할 수 있다. 그러나, 이에 한정되는 것은 아니고, 다른 실시예에서 전자 장치는 차량 내의 CID(Center Information Display), 네비게이션 장치, 계기판 디스플레이, 또는 조수석 디스플레이 중 적어도 하나에 UI를 디 스플레이할 수 있다. 전자 장치의 프로세서는 제1 객체와 관련된 UI를 제1 객체가 표시되는 위치와 인접 한 위치에 디스플레이할 수 있다. UI는 제1 객체의 타입에 따라 맞춤형 메뉴를 제공하는 상황 맞춤형 UI(contextual menu UI)일 수 있다. UI는 제1 객체에 대하여 수행 가능한 기능 또는 동작을 나타내 는 메뉴 UI 및 제1 객체의 프로필 정보 및 상태 정보를 나타내는 객체 정보 UI(112 내지 115)를 포함 할 수 있다. 메뉴 UI는 전자 장치와 무선 통신 연결이 수행된 제1 객체에 대하여 수행할 수 있는 기능 또는 동작을 선택하는 사용자 입력을 수신하기 위한 복수의 항목들을 포함할 수 있다. 도 12에 도시된 실시예에서, 제1 객체의 타입은 차량이고, 메뉴 UI는 제1 객체의 타입이 차량이라는 점에 기초하여 결정된 동작들, 예를 들어 차량에 메시지 보내지, 차량 정보 획득, 및 위험 알림 신호 전송 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들을 포함할 수 있다. 사용자는 복수의 항목들 중 어느 하나 의 항목을 선택하고, 전자 장치는 사용자 입력에 따라 선택된 항목에 대응되는 기능 또는 동작을 수행할 수 있다. 도 12에 도시된 실시예와는 달리, 제1 객체의 타입이 보행자인 경우, 메뉴 UI는 보행자에 대하여 수 행 가능한 동작들, 예를 들어 메시지 보내기, 전화, 및 위험 알림 신호 전송 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들을 포함할 수 있다. 또한, 제1 객체의 타입이 음식점의 간판 또는 광고판인 경우, 메뉴 UI는 제1 객체의 타입이 간판 또는 광고판이라는 점에 기초하여 결정된 동 작들, 예를 들어 음식점 정보 획득, 음식 메뉴 주문, 및 예약 중 적어도 하나의 동작을 수행하기 위한 사용자 입력을 수신하는 복수의 항목들을 포함할 수 있다. 객체 정보 UI(112 내지 115)는 제1 객체의 프로필 정보, 무선 통신 연결 신호 세기, 배터리 레벨, 및 이동 속도 중 적어도 하나를 포함하는 객체 정보를 문자, 숫자, 기호, 도형, 및 아이콘 중 적어도 하나로 나타내는 UI이다. 일 실시예에서, 객체 정보 UI(112 내지 115)는 제1 객체로부터 수신한 제1 객체의 프로필 이 미지 및 제1 객체의 프로필 문구를 포함할 수 있다. 일 실시예에서, 객체 정보 UI(112 내지 115)는 제1 객체에 의해 제공되는 프로필 음악을 플레이하기 위한 프로필 뮤직 UI를 더 포함할 수 있 다. 일 실시예에서, 객체 정보 UI(112 내지 115)는 제1 객체와의 무선 통신 연결 상태를 나타내는 제1 아 이콘 및 제1 객체의 배터리 잔여 용량을 나타내는 제2 아이콘을 포함하는 상태 정보 UI를 포함할 수 있다. 도 12에 도시된 실시예에서, 전자 장치는 무선 통신 연결이 수행된 제1 객체에 관한 상황 맞춤형 UI(contextual menu UI)를 디스플레이함으로써, 사용자가 제1 객체와 관련된 기능 또는 동작을 직관적으로 선택할 수 있도록 하는 기술적 효과를 제공한다. 또한, 본 개시의 일 실시예에 따른 전자 장치는 제1 객체의 프로필 정보, 무선 통신 연결 신호 세기, 배터리 레벨, 및 이동 속도 중 적어도 하나를 포함하는 객 체 정보를 문자, 숫자, 기호, 도형, 및 아이콘 중 적어도 하나로 나타내는 UI를 디스플레이함으로써, 사용자가 제1 객체의 상태를 직관적으로 인식할 수 있도록 하고, 이를 통해 사용자 편의성을 향상시킬 수 있다. 본 개시의 일 실시예에 따른 전자 장치는, 제1 객체에 대응되는 이미지를 둘러싸는 도형 또는 기호 로 구성된 포커싱 UI를 디스플레이부 상에 디스플레이할 수 있다. 포커싱 UI에 대해서는 도 13a 내지 도 13c에서 상세하게 설명하기로 한다. 도 13a 내지 도 13c는 본 개시의 일 실시예에 따른 전자 장치가 객체의 주행 속도에 따라 디스플레이하는 UI의 예시를 도시한 도면이다. 전자 장치는 디스플레이부(1600, 도 12 참조) 상에 디스플레이되는 제1 객체에 대응되는 이미지를 둘러싸는 포커싱 UI를 디스플레이할 수 있다. 포커싱 UI는 제1 객체의 이미지의 네 모서리 부분 을 둘러싸는 도형 또는 기호로 구성될 수 있다. 일 실시예에서, 전자 장치는 제1 객체의 주행 속도 를 모니터링하고, 제1 객체의 주행 속도에 따라 포커싱 UI의 컬러를 다르게 변경하여 디스플레이할 수 있다. 도 13a를 참조하면, 제1 객체가 급 감속 주행하는 경우, 전자 장치는 포커싱 UI를 파란 색으로 디스플레이할 수 있다. 도 13b를 참조하면, 제1 객체가 정속 주행하는 경우, 전자 장치는 포커싱 UI를 노란 색으로 디 스플레이할 수 있다. 도 13c를 참조하면, 제1 객체가 급 가속 주행하는 경우, 전자 장치는 포커싱 UI를 빨간 색으로 디스플레이할 수 있다. 도 13a 내지 도 13c에 도시된 실시예에서, 포커싱 UI의 컬러는 예시적인 것이고, 설명한 것과 같은 컬러로 한정되는 것은 아니다. 도 13a 내지 도 13c에 도시된 실시예에 따른 전자 장치는 무선 통신 연결이 수행된 제1 객체에 대응 되는 이미지를 둘러싸는 포커싱 UI를 제1 객체의 주행 속도에 따라 서로 다른 컬러로 디스플레이함으 로써, 사용자가 제1 객체의 속도를 직관적으로 파악할 수 있도록 하는 기술적 효과를 제공한다. 도 14는 본 개시의 일 실시예에 따른 전자 장치가 객체에 의해 제공되는 컨텐트를 디스플레이한 이후, 무 선 통신 연결과 관련된 UI를 디스플레이하는 동작을 설명하기 위한 도면이다. 도 14를 참조하면, 전자 장치는 무선 통신 연결된 제1 객체와 관련된 상업 광고 영상(Commercial Film, CF) 또는 소개 영상을 포함하는 컨텐트 영상을 디스플레이할 수 있다. 컨텐트 영상은 제1 객체 로부터 수신된 광고 영상 또는 소개 영상을 포함할 수 있다. 일 실시예에서, 컨텐트 영상은 제1 객체 의 광고 대상 또는 소개 대상을 나타내는 명함 또는 프로필 정보를 포함할 수도 있다. 컨텐트 영상은 복수의 이미지 프레임을 시간의 흐름에 따라 순차적으로 디스플레이하는 동영상일 수 있다. 이 경우, 전자 장치 는 컨텐트 영상을 구성하는 복수의 이미지 프레임이 모두 플레이되는 시간 동안 컨텐트 영상을 디스플레이할 수 있다. 그러나, 이에 한정되는 것은 아니고, 컨텐트 영상은 단일 이미지 프레임으로 구성 될 수도 있다. 전자 장치는 컨텐트 영상이 디스플레이된 이후, 제1 객체에 관한 UI를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 기 설정된 시간 동안 컨텐트 영상을 디스플레이하고, 기 설정된 시간이 경과한 이후에 UI를 디스플레이할 수 있다. UI는 도 12에 도시된 UI(110, 도 12 참조)와 동일 하므로, 중복되는 설명은 생략한다. 도 15는 본 개시의 일 실시예에 따른 전자 장치가 인공 지능 기술을 이용하여 수행되는 동작을 설명하기 위한 도면이다.구체적으로, 전자 장치에 의해 수행되는 i) 차량 전방에 탑재된 카메라를 이용하여 차량의 주변을 촬영함 으로써, 주변 환경 이미지를 획득하는 동작, ii) 인공지능 모델을 이용하여, 주변 환경 이미지로부터 적어도 하나의 객체를 인식하는 동작, iii) 적어도 하나의 객체 또는 RSU(Road Side Unit)으로부터 적어도 하나의 객체 와 관련된 정보를 포함하는 V2X 데이터 셋(V2X data set)을 수신하는 동작, iv) 사용자 입력에 기초하여, 인식 된 적어도 하나의 객체 중 제1 객체를 선택하는 동작, v) 주변 환경 이미지의 인식 결과 및 수신된 V2X 데이터 셋을 이용하여, 제1 객체의 타입(type)에 관한 정보를 획득하는 동작, 및 vi) 제1 객체의 타입에 관한 정보에 기초하여, 제1 객체와 무선 통신 연결을 위한 UI(User Interface)를 디스플레이하는 동작 중 적어도 하나는, 신 경망(neural network)을 통한 연산을 수행하는 인공지능(AI: Artificial Intelligence) 기술을 이용하여 수행 될 수 있다. 인공 지능 기술(이하, 'AI 기술')은 신경망(Neural Network)을 통한 연산을 기반으로 입력 데이터를 분석 및/또 는 분류 등과 같은 처리를 하여 목적하는 결과를 획득하는 기술이다. 이러한 AI 기술은 알고리즘을 활용하여 구현될 수 있다. 여기서, AI 기술을 구현하기 위한 알고리즘 또는 알고 리즘의 집합을 신경망(Neural Network)이라 한다. 여기서, 신경망은 입력 데이터를 입력받고, 전술한 분석 및/ 또는 분류를 위한 연산을 수행하여, 결과 데이터를 출력할 수 있다. 신경망이 입력 데이터에 대응되는 결과 데 이터를 정확하게 출력하기 위해서는, 신경망을 학습(training)시킬 필요가 있다. 여기서, '학습(training)'은 신경망에 대한 입력 데이터들을 분석하는 방법, 입력 데이터들을 분류하는 방법, 및/또는 입력 데이터들에서 결 과 데이터 생성에 필요한 특징을 추출하는 방법 등을 신경망이 스스로 발견 또는 터득할 수 있도록 훈련시키는 것을 의미할 수 있다. 구체적으로, 학습 과정을 통하여, 신경망은 학습 데이터(예를 들어, 서로 다른 복수의 이 미지들)를 학습(training)하여 신경망 내부의 가중치(weight) 값들을 최적화할 수 있다. 그리고, 최적화된 가중 치 값을 가지는 신경망을 통하여, 입력 데이터를 처리함으로써, 목적하는 결과를 출력한다. 신경망은 연산을 수행하는 내부의 레이어(layer)인 은닉 레이어(hidden layer)의 개수가 복수일 경우, 즉 연산 을 수행하는 신경망의 심도(depth)가 증가하는 경우, 심층 신경망으로 분류될 수 있다. 신경망은 예를 들어, CNN (Convolutional Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트 워크 (Deep Q-Networks) 등을 포함하고, 전술한 예시에 한정되지 않는다. 또한, 신경망은 세분화될 수 있다. 예 를 들어, CNN 신경망은 D-CNN(Deep Convolution Neural Network) 또는 캡스넷(Capsnet) 신경망(미도시) 등으로 세분화 될 수 있다. 'AI 모델'은 입력 데이터를 수신하고 목적하는 결과를 출력하도록 동작하는 적어도 하나의 레이어를 포함하는 신경망을 의미할 수 있다. 또한, 'AI 모델'은 신경망을 통한 연산을 수행하여 목적하는 결과를 출력하는 알고리 즘, 복수의 알고리즘의 집합, 알고리즘(또는 알고리즘의 집합)을 실행하기 위한 프로세서(processor), 알고리즘 (또는 알고리즘의 집합)을 실행하기 위한 소프트웨어, 또는 알고리즘(또는 알고리즘의 집합)을 실행하기 위한 하드웨어를 의미할 수 있다. 전술한 i) 차량 전방에 탑재된 카메라를 이용하여 차량의 주변을 촬영함으로써, 주변 환경 이미지를 획득하는 동작, ii) 인공지능 모델을 이용하여, 주변 환경 이미지로부터 적어도 하나의 객체를 인식하는 동작, iii) 적 어도 하나의 객체 또는 RSU(Road Side Unit)으로부터 적어도 하나의 객체와 관련된 정보를 포함하는 V2X 데이터 셋(V2X data set)을 수신하는 동작, iv) 사용자 입력에 기초하여, 인식된 적어도 하나의 객체 중 제1 객체를 선 택하는 동작, v) 주변 환경 이미지의 인식 결과 및 수신된 V2X 데이터 셋을 이용하여, 제1 객체의 타입(type)에 관한 정보를 획득하는 동작, 및 vi) 제1 객체의 타입에 관한 정보에 기초하여, 제1 객체와 무선 통신 연결을 위 한 UI(User Interface)를 디스플레이하는 동작 중 적어도 하나는 AI 모델 기반으로 수행될 수 있다. 도 15를 참조하면, 신경망은 학습 데이터(training data)를 입력받아 트레이닝(training)될 수 있다. 그리 고, 학습된 신경망은 입력단으로 입력 데이터를 입력받고, 입력단, 은닉 레이어(hidden layer) 및 출력단은 입력 데이터 및 이전 레이어로부터 전달된 데이터를 분석하여 출력 데이터 를 출력하기 위한 연산을 수행할 수 있다. 도 15에서는 은닉 레이어가 1개의 계층인 것으로 도시되어 있으나, 이는 예시일 뿐이고, 은닉 레이어는 복수의 계층으로 이루어질 수도 있다. 개시된 실시예에서 신경망은, 제1 객체의 타입에 기초하여 결정된 기능 또는 동작을 수행하기 위하여 선택 가능한 메뉴 UI를 디스플레이하도록 학습될 수 있다. 개시된 실시예에서 신경망은, 선택된 제1 객체와의 무선 통신의 연결 전, 연결 중, 및 연결 후에 따라 각 각 다른 컬러 및 형태의 UI를 디스플레이하도록 학습될 수 있다. 개시된 실시예에서 신경망은, 적어도 하나의 객체의 타입에 따라 주변 환경 이미지 내에 포함된 적어도 하 나의 객체를 서로 다른 컬러의 이미지로 디스플레이하도록 학습될 수 있다. 개시된 실시예에서 신경망은, 사용자 입력에 의해 선택된 제1 객체의 프로필 정보, 무선 통신 연결 신호 세기, 배터리 레벨, 및 이동 속도 중 적어도 하나를 포함하는 객체 정보를 문자, 숫자, 기호, 도형, 및 아이콘 중 적어도 하나로 나타내는 객체 정보 UI를 디스플레이하도록 학습될 수 있다. 개시된 실시예에서 신경망은, 주변 환경 이미지 상에 제1 객체에 대응되는 이미지를 둘러싸는 도형 또는 기호로 구성된 포커싱 UI(Focusing UI)를 디스플레이하고, 포커싱 UI를 제1 객체의 이동 속도에 따라 서로 다른 컬러로 디스플레이하도록 학습될 수 있다. 개시된 실시예에서 신경망은, 제1 객체로부터 수신된 광고 컨텐트 또는 소개 영상을 디스플레이하고, 광고 컨텐트 또는 소개 영상이 디스플레이된 이후 제1 객체와 관련된 UI를 디스플레이하도록 학습될 수 있다. 개시된 실시예에서, 전술한 i) 차량 전방에 탑재된 카메라를 이용하여 차량의 주변을 촬영함으로써, 주변 환경 이미지를 획득하는 동작, ii) 인공지능 모델을 이용하여, 주변 환경 이미지로부터 적어도 하나의 객체를 인식 하는 동작, iii) 적어도 하나의 객체 또는 RSU(Road Side Unit)으로부터 적어도 하나의 객체와 관련된 정보를 포함하는 V2X 데이터 셋(V2X data set)을 수신하는 동작, iv) 사용자 입력에 기초하여, 인식된 적어도 하나의 객체 중 제1 객체를 선택하는 동작, v) 주변 환경 이미지의 인식 결과 및 수신된 V2X 데이터 셋을 이용하여, 제 1 객체의 타입(type)에 관한 정보를 획득하는 동작, 및 vi) 제1 객체의 타입에 관한 정보에 기초하여, 제1 객체 와 무선 통신 연결을 위한 UI(User Interface)를 디스플레이하는 동작 중 적어도 하나를 수행하는 신경망 과 관련된 데이터 또는 프로그램 코드는 메모리(1400, 도 2 참조)에 저장되고, 신경망을 이용하는 학습은 프로세서(1300, 도 2 참조)에 의해 수행될 수 있다. 이 경우, 프로세서는 인공지능 프로세서(AI processor)를 포함할 수 있다. 또는, 전술한 i) 차량 전방에 탑재된 카메라를 이용하여 차량의 주변을 촬영함으로써, 주변 환경 이미지를 획득 하는 동작, ii) 인공지능 모델을 이용하여, 주변 환경 이미지로부터 적어도 하나의 객체를 인식하는 동작, iii) 적어도 하나의 객체 또는 RSU(Road Side Unit)으로부터 적어도 하나의 객체와 관련된 정보를 포함하는 V2X 데이터 셋(V2X data set)을 수신하는 동작, iv) 사용자 입력에 기초하여, 인식된 적어도 하나의 객체 중 제1 객 체를 선택하는 동작, v) 주변 환경 이미지의 인식 결과 및 수신된 V2X 데이터 셋을 이용하여, 제1 객체의 타입 (type)에 관한 정보를 획득하는 동작, 및 vi) 제1 객체의 타입에 관한 정보에 기초하여, 제1 객체와 무선 통신 연결을 위한 UI(User Interface)를 디스플레이하는 동작 중 적어도 하나를 수행하는 신경망은 전자 장치 와 구별된 별도의 디바이스(미도시) 또는 프로세서(미도시) 내에 구현될 수 있다. 전술한 신경망을 통한 연산은 일 실시예에 따른 전자 장치와 무선 통신 네트워크를 통해 통신할 수 있는 서버(2000, 도 16 및 도 17 참조)에 의해 수행될 수도 있다. 전자 장치와 서버 간의 통신은 도 16 및 도 17을 참조하여 설명한다. 도 16은 서버와 연동하여 동작하는 개시된 실시예에 따른 전자 장치를 나타내는 도면이다. 서버는 통신 네트워크를 통하여 전자 장치와 데이터를 송수신하며 데이터를 처리할 수 있다. 도 17을 함께 참조하면, 서버는 전자 장치와 통신하는 통신부, 적어도 하나의 인스트럭션을 수행하는 프로세서, 및 데이터베이스를 포함할 수 있다. 서버는 AI 모델을 훈련시키고, 훈련된 AI 모델을 저장하고 있을 수 있다. 그리고, 서버는 훈련된 AI 모델을 이용하여 전술한 i) 차량 전방에 탑재된 카메라를 이용하여 차량의 주변을 촬영함으로써, 주변 환경 이미지를 획득하는 동작, ii) 인공지능 모델을 이용하여, 주변 환경 이미지로부터 적어도 하나의 객체를 인식 하는 동작, iii) 적어도 하나의 객체 또는 RSU(Road Side Unit)으로부터 적어도 하나의 객체와 관련된 정보를 포함하는 V2X 데이터 셋(V2X data set)을 수신하는 동작, iv) 사용자 입력에 기초하여, 인식된 적어도 하나의 객체 중 제1 객체를 선택하는 동작, v) 주변 환경 이미지의 인식 결과 및 수신된 V2X 데이터 셋을 이용하여, 제 1 객체의 타입(type)에 관한 정보를 획득하는 동작, 및 vi) 제1 객체의 타입에 관한 정보에 기초하여, 제1 객체 와 무선 통신 연결을 위한 UI(User Interface)를 디스플레이하는 동작 중 적어도 하나를 수행할 수 있다. 일반적으로, 전자 장치는 메모리 저장 용량, 연산의 처리 속도, 학습 데이터 셋의 수집 능력 등이 서버 에 비하여 제한적일 수 있다. 따라서, 대용량 데이터의 저장 및 대용량의 연산량이 필요한 동작은 서버 에서 수행한 후, 통신 네트워크를 통하여 필요한 데이터 및/또는 AI 모델을 전자 장치에 전송할 수 있다. 그러면, 전자 장치는 대용량의 메모리 및 빠른 연산 능력을 갖는 프로세서 없이도, 서버를 통하여 필요한 데이터 및/또는 AI 모델을 수신하여 이용함으로써, 빠르고 용이하게 필요한 동작을 수행할 수 있 다. 개시된 실시예에서, 서버는 도 15에서 설명한 신경망을 포함할 수 있다. 도 17은 도 16을 상세하게 설명하기 위한 도면이다. 도 17을 참조하면, 서버는 통신부, 프로세서, 및 데이터베이스를 포함할 수 있다. 통신부는 무선 통신 네트워크를 통해서 외부 장치와 통신을 수행한다. 여기서, 외부 장치(미도시)는 전자 장치가 필요로 하는 연산 중 적어도 하나를 수행하거나, 전자 장치가 필요로 하는 데이터 등을 송 신할 수 있는 서버를 포함할 수 있다. 통신부는, 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈, 방송 수신 모듈 등과 같은 적어도 하나의 통신 모듈을 포함한다. 여기서, 적어도 하나의 통신 모듈은 방송 수신을 수행하는 튜너, 블루투스, WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), WiMAX(World Interoperability for Microwave Access), CDMA, WCDMA, 인터넷, 3G, 4G, 5G 및/또는 밀리미터 파(mmwave)를 이용한 통신 방식과 같은 통신 규 격을 따르는 네트워크를 통하여 데이터 송수신을 수행할 수 있는 통신 모듈을 의미한다. 예를 들어, 통신부가 밀리미터 파(mmWAVE)를 이용하여 통신을 수행하면, 대용량의 데이터를 빠르게 송수 신할 수 있다. 구체적으로, 차량은 밀리미터파를 이용하여 대용량의 데이터를 빠르게 수신하고, 차량과 관련된 정보를 포함하는 V2X 데이터 셋, 객체와 관련된 정보(예를 들어, 객체의 프로필 정보, 무선 통신 연결 신호 세 기, 배터리 레벨, 이동 속도 등) 등을 빠르게 제공할 수 있다. 통신부에 포함되는 이동 통신 모듈은 3G, 4G, 및/또는 5G 등의 통신 규격에 따르는 통신 네트워크를 통하 여 원거리에 위치하는 다른 장치(예를 들어, 전자 장치)와 통신을 수행할 수 있다. 여기서, 원거리에 위 치하는 다른 장치와 통신을 수행하는 통신 모듈을 '원거리 통신 모듈'이라 칭할 수 있다. 일 실시예에서, 통신 부는 전자 장치의 통신 인터페이스와 유선 또는 무선으로 데이터를 송수신할 수 있다. 프로세서는 서버의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 서버의 적어도 하나의 인스트럭션(instructions), 및 프로그램들 중 적어도 하나를 실행함으로써, 요구되는 동작들을 수행할 수 있다. 데이터베이스는 메모리(미도시)를 포함할 수 있으며, 메모리(미도시) 내에 서버가 소정 동작을 수 행하기 위해서 필요한 적어도 하나의 인스트럭션, 프로그램, 데이터 중 적어도 하나를 저장할 수 있다. 또한, 데이터베이스는 서버가 신경망에 따른 연산을 수행하기 위해서 필요한 데이터들을 저장할 수 있다. 개시된 실시예에서, 서버는 도 15에서 설명한 신경망을 저장하고 있을 수 있다. 신경망은 프로 세서 및 데이터베이스 중 적어도 하나에 저장될 수 있다. 서버가 포함하는 신경망은 학 습이 완료된 신경망이 될 수 있다. 또한, 서버는 학습이 완료된 신경망을 통신부를 통하여 전자 장치의 통신 인터페이스 로 전송할 수 있다. 그러면, 전자 장치는 학습이 완료된 신경망을 획득 및 저장하고, 신경망을 통하여 목 적하는 출력 데이터를 획득할 수 있다. 본 명세서에서 설명된 전자 장치에 의해 실행되는 프로그램은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 프로그램은 컴퓨터로 읽을 수 있는 명령어들을 수행할 수 있는 모든 시스템에 의해 수행될 수 있다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령어(instruction), 또는 이들 중 하나 이상 의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처리 장치를 명령할 수 있다. 소프트웨어는, 컴퓨터로 읽을 수 있는 저장 매체(computer-readable storage media)에 저장된 명령어를 포함하 는 컴퓨터 프로그램으로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록 매체로는, 예를 들어 마그네틱 저장 매체 (예컨대, ROM(read-only memory), RAM(random-access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판 독 매체(예컨대, 시디롬(CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등이 있다. 컴퓨터가 읽을 수 있 는 기록 매체는 네트워크로 연결된 컴퓨터 시스템들에 분산되어, 분산 방식으로 컴퓨터가 판독 가능한 코드가 저장되고 실행될 수 있다. 매체는 컴퓨터에 의해 판독가능하며, 메모리에 저장되고, 프로세서에서 실행될 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비 일시적'은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매 체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 예를 들어, '비일시적 저장매체'는 데이터가 임시적 으로 저장되는 버퍼를 포함할 수 있다. 또한, 본 명세서에 개시된 실시예들에 따른 프로그램은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 소프트웨어 프로그램, 소프트웨어 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체 를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예를 들어, 삼성 갤럭시 스토어TM, 구글 플레이 스토어TM, 앱 스토어TM)을 통해 전자적으로 배포되는 소프트웨어 프로그램 형태의 상품(예를 들어, 다운로드 가능한 애플리케이션(downloadable application))을 포함할 수 있다. 전자적 배포를 위하여, 소프트웨어 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저장 매체는 차량 또는 전자 장치의 제조사의 서버, 전자 마켓의 서버, 또는 소프트웨어 프로그램을 임시 적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 전자 장치, 서버(2000, 도 16 및 도 17 참조), 및 타 전자 장치로 구성되는 시 스템에서, 서버의 저장매체 또는 전자 장치의 저장매체를 포함할 수 있다. 또는, 전자 장치와 통 신 연결되는 제3 장치(예를 들어, 스마트 폰)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프로그램 제품은 전자 장치로부터 전자 장치 또는 제3 장치로 전송되거나, 제3 장치로부터 전자 장치로 전송되는 소프트웨어 프로그램 자체를 포함할 수 있다. 이 경우, 전자 장치, 전자 장치, 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예 들에 따른 방법을 수행할 수 있다. 또는, 전자 장치, 전자 장치, 및 제3 장치 중 둘 이상이 컴퓨터 프로 그램 제품을 실행하여 개시된 실시예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 전자 장치가 메모리(1400, 도 2 참조)에 저장된 컴퓨터 프로그램 제품을 실행하여, 전자 장치 와 통신 연결된 타 전자 장치가 개시된 실시예들에 따른 방법을 수행하도록 제어할 수 있다. 또 다른 예로, 제3 장치가 컴퓨터 프로그램 제품을 실행하여, 제3 장치와 통신 연결된 전자 장치가 개시된 실시 예에 따른 방법을 수행하도록 제어할 수 있다. 제3 장치가 컴퓨터 프로그램 제품을 실행하는 경우, 제3 장치는 전자 장치로부터 컴퓨터 프로그램 제품을 다운로드하고, 다운로드된 컴퓨터 프로그램 제품을 실행할 수 있다. 또는, 제3 장치는 프리로드(pre-load)된 상 태로 제공된 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 수행할 수도 있다."}
{"patent_id": "10-2021-0140487", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 컴퓨터 시스템 또는 모듈 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11a 도면11b 도면12 도면13a 도면13b 도면13c 도면14 도면15 도면16 도면17"}
{"patent_id": "10-2021-0140487", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시는, 다음의 자세한 설명과 그에 수반되는 도면들의 결합으로 쉽게 이해될 수 있으며, 참조 번호 (reference numerals)들은 구조적 구성요소(structural elements)를 의미한다. 도 1은 본 개시의 전자 장치가 차량 주변의 객체와 무선 통신 연결을 수행하기 위한 UI를 디스플레이하는 실시 예를 도시한 개념도이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치의 구성 요소를 도시한 블록도이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시한 흐름도이다. 도 4는 본 개시의 일 실시예에 따른 전자 장치가 차량 주변의 객체들과 V2X 연결을 통해 V2X 데이터 셋(V2X data set)을 수신하는 동작을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 차량 주변의 객체들로부터 수신한 V2X 데이터 셋에 포함되는 정보를 도시한 표이다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 차량 주변의 객체와 무선 통신 연결을 수행하는 방법을 도시한 흐름도이다. 도 7은 본 개시의 일 실시예에 따른 전자 장치가 타 차량의 번호판에 관한 정보에 기초하여 타 차량의 식별 정 보를 획득하는 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 전자 장치가 차량과 객체와의 위치 관계에 기초하여 객체의 식별 정보를 획 득하는 동작을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시예에 따른 전자 장치가 객체의 시간의 흐름에 따른 위치 관계 변화에 기초하여 객체의 식별 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 객체와의 무선 통신 연결이 수행되기 전에 디스플레이하는 UI 의 예시를 도시한 도면이다. 도 11a는 본 개시의 일 실시예에 따른 전자 장치가 객체와의 무선 통신 연결이 수행되는 중에 디스플레이하는 UI의 예시를 도시한 도면이다. 도 11b는 본 개시의 일 실시예에 따른 전자 장치가 객체와의 무선 통신 연결이 진행됨에 따라 변화되는 UI의 예 시를 도시한 도면이다. 도 12는 본 개시의 일 실시예에 따른 전자 장치가 객체와의 무선 통신 연결이 수행된 이후에 디스플레이하는 UI 의 예시를 도시한 도면이다. 도 13a 내지 도 13c는 본 개시의 일 실시예에 따른 전자 장치가 객체의 주행 속도에 따라 디스플레이하는 UI의 예시를 도시한 도면이다. 도 14는 본 개시의 일 실시예에 따른 전자 장치가 객체에 의해 제공되는 컨텐트를 디스플레이한 이후, 무선 통 신 연결과 관련된 UI를 디스플레이하는 동작을 설명하기 위한 도면이다. 도 15는 본 개시의 전자 장치가 인공 지능 기술을 이용하여 수행하는 동작을 설명하기 위한 도면이다. 도 16은 본 개시의 전자 장치가 서버와 연동하여 동작하는 개시된 실시예를 도시한 도면이다. 도 17은 도 16을 상세하게 설명하기 위한 도면이다."}
