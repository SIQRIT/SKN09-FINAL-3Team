{"patent_id": "10-2021-0156317", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0070585", "출원번호": "10-2021-0156317", "발명의 명칭": "동영상에서 주역 및 배경인물 감지 방법", "출원인": "한국전자기술연구원", "발명자": "박용석"}}
{"patent_id": "10-2021-0156317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "에 있어서,구분 단계는,인물 별로 ID를 할당하고 ID 프로파일을 생성하는 단계;인물 별 ID 프로파일 정보를 프레임 별로 통계적으로 분석하는 단계; 및통계적 분석 정보를 기초로, 각 인물이 주역인지 배경인물인지 판단하는 단계;를 포함하는 것을 특징으로 하는인물 감지 방법."}
{"patent_id": "10-2021-0156317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,검출 단계는,인물이 착용하고 있는 의류와 액세서리도 함께 검출하여, 인물을 기준으로 그룹화하는 것을 특징으로 하는 인물감지 방법."}
{"patent_id": "10-2021-0156317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,검출 단계는,인물의 특성을 파악하며,특성은,인물의 크기 및 화면 중심부로부터의 거리를 포함하는 것을 특징으로 하는 인물 감지 방법."}
{"patent_id": "10-2021-0156317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,구분 단계는,각 프레임에 등장하는 인물들의 동일 여부를 식별하는 단계; 및동일 인물들로 식별된 각 인물의 중요도를 통계적으로 분석하여, 각 인물을 주역 또는 배경인물로 판단하는 단계;를 포함하는 것을 특징으로 하는 인물 감지 방법."}
{"patent_id": "10-2021-0156317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,메타데이터 정보는,동영상에 등장하는 인물을 검색하고, 인물에 대한 후처리 작업에 참조되는 것을 특징으로 하는 인물 감지 방법.공개특허 10-2023-0070585-3-청구항 6"}
{"patent_id": "10-2021-0156317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,통계적 분석 정보는,각 프레임에서의 발생 빈도, 각 프레임에서의 크기 분포 및 각 프레임에서의 위치 분포를 포함하는 것을 특징으로 하는 인물 감지 방법."}
{"patent_id": "10-2021-0156317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "동영상을 입력받아, 동영상을 구성하는 프레임들을 추출하는 영상 입력부;추출된 각 프레임에 등장하는 인물들을 검출하는 프레임 분석부;검출된 각 프레임의 인물 정보들을 취합하여, 인물들을 주역과 배경인물로 구분하는 영상 분석부; 및각 프레임에 대해 각 인물들에 대한 메타데이터 정보를 생성하는 메타데이터 생성부;를 포함하는 것을 특징으로하는 인물 감지 시스템."}
{"patent_id": "10-2021-0156317", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "동영상에서 주역 및 배경인물 감지 방법이 제공된다. 본 발명의 실시예에 따른 인물 감지 방법은, 동영상을 입력 받아 동영상을 구성하는 프레임들을 추출하고, 추출된 각 프레임에 등장하는 인물들을 검출하며, 검출된 각 프레 임의 인물 정보들을 취합하여 인물들을 주역과 배경인물로 구분하고, 각 프레임에 대해 각 인물에 대한 메타데이 터 정보를 생성한다. 이에 의해, 동영상에 등장하는 각 인물객체들을 주역 및 배경인물로 구분하여 줌으로써 동 영상 편집 작업 속도를 향상시킬 수 있고, 인물객체 정보를 기반으로 비식별화와 같은 다양한 후처리 작업이 가 능하며, 영상 내 특정 인물에 대해 검색이 가능해진다."}
{"patent_id": "10-2021-0156317", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상처리 기반의 객체검출 방법에 관한 것으로, 영상에 출연하는 사람들을 주역 또는 배경인물로 구 분하는 방법에 관한 것이다."}
{"patent_id": "10-2021-0156317", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "유튜브, 틱톡 등 소셜 미디어 기반의 동영상 공유 플랫폼이 활성화고 인기를 누리면서 많은 사람들이 동영상 콘 텐츠를 제작을 하고 있다. 이러한 미디어 콘텐츠 제작은 기획, 촬영, 편집 등 전 단계에 걸쳐 많은 시간과 비용 이 소요된다. 실생활의 영상으로 콘텐츠를 제작하는 경우, 영상 배경에 의도치 않게 불특정 사람들이 포착되어 포함되는 경우가 발생한다. 식별 가능한 사람들이 영상에 포함될 경우, 초상권 침해로 인한 소송 및 여러 사회 적인 문제가 발생할 수 있다. 또한 당사자들이 요구할 경우 어렵게 제작한 동영상을 편집 또는 삭제해야 하는 경우가 발생할 수 있다. 따라서 이런 문제점을 방지하기 위해 영상 편집 단계에서 식별 가능한 배경인물에 대한 비식별화 작업을 진행하게 된다. 동영상을 구성하는 모든 프레임에서 수동으로 사람들을 구분하고 비식별화 작업을 하는 것은 시간이 많이 소요 되고 매우 번거롭기 때문에 대다수의 영상편집 도구에서는 인공지능 기반의 얼굴감지(face detection) 모델을 사용하여 모든 프레임에서 자동으로 사람들의 얼굴부분을 감지하고 블러(blur), 모자이크 등 비식별화 필터처리 를 진행해준다. 단순히 클래스(사람 얼굴)로 객체 감지를 진행하여 일괄적으로 비식별화 필터를 적용할 경우, 불특정 배경인물 뿐만 아니라 영상의 주역/주인공도 비식별화가 되는 현상이 발생할 수 있다. 이를 방지하기 위해 감지된 인물들 을 주역 인물(주시 객체)과 배경인물(비주시 객체)로 구분해 줄 필요가 있다. 인물들이 구분이 되면 적절한 편 집 효과를 해당 객체에게만 적용해주면 된다. 인공지능 기반 영상처리 분야에서는 주목도 감지(saliency detection) 기법을 통해 이미지에서의 중심적인 관심 객체 또는 주시객체를 감지한다. 하지만 이러한 방법은 학습 데이터 생성을 위해 사람의 시선을 추적하는 장비 가 사용되거나, depth map 생성 등 복잡한 연산이 요구된다."}
{"patent_id": "10-2021-0156317", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 목적은, 얼굴감지(face detection), 얼굴인식(face recognition), 객체추적(object tracking) 알고리즘을 이용하여 동영상에 등장하는 인물들에 대한 정보를 수집하고, 수집된 정보를 이용한 통계적 분석을 통해 각 등장인물 객체를 주역 및 배경인 물로 구분하여 동영상 편집 작업에 활용 가능한 객체 메타데이터 정보를 제공하는 인물 감지 방법 및 시스템을 제공함에 있다."}
{"patent_id": "10-2021-0156317", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른, 인물 감지 방법은, 동영상을 입력받아, 동영상을 구성 하는 프레임들을 추출하는 단계; 추출된 각 프레임에 등장하는 인물들을 검출하는 단계; 검출된 각 프레임의 인 물 정보들을 취합하여, 인물들을 주역과 배경인물로 구분하는 단계; 각 프레임에 대해 각 인물에 대한 메타데이 터 정보를 생성하는 단계;를 포함한다. 검출 단계는, 인물이 착용하고 있는 의류와 액세서리도 함께 검출하여, 인물을 기준으로 그룹화할 수 있다. 검출 단계는, 인물의 특성을 파악하며, 특성은, 인물의 크기 및 화면 중심부로부터의 거리를 포함할 수 있다. 구분 단계는, 각 프레임에 등장하는 인물들의 동일 여부를 식별하는 단계; 동일 인물들로 식별된 각 인물의 중 요도를 통계적으로 분석하여, 각 인물을 주역 또는 배경인물로 판단하는 단계;를 포함할 수 있다. 메타데이터 정보는, 동영상에 등장하는 인물을 검색하고, 인물에 대한 후처리 작업에 참조될 수 있다. 구분 단계는, 인물 별로 ID를 할당하고 ID 프로파일을 생성하는 단계; 인물 별 ID 프로파일 정보를 프레임 별로 통계적으로 분석하는 단계; 및 통계적 분석 정보를 기초로, 각 인물이 주역인지 배경인물인지 판단하는 단계;를 포함할 수 있다. 통계적 분석 정보는, 각 프레임에서의 발생 빈도, 각 프레임에서의 크기 분포 및 각 프레임에서의 위치 분포를 포함할 수 있다. 한편, 본 발명의 다른 실시예에 따른, 인물 감지 시스템은, 동영상을 입력받아, 동영상을 구성하는 프레임들을 추출하는 영상 입력부; 추출된 각 프레임에 등장하는 인물들을 검출하는 프레임 분석부; 검출된 각 프레임의 인 물 정보들을 취합하여, 인물들을 주역과 배경인물로 구분하는 영상 분석부; 각 프레임에 대해 각 인물들에 대한 메타데이터 정보를 생성하는 메타데이터 생성부;를 포함한다."}
{"patent_id": "10-2021-0156317", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상 설명한 바와 같이, 본 발명의 실시예들에 따르면, 동영상에 등장하는 각 인물객체들을 주역 및 배경인물로 구분하여 줌으로써 동영상 편집 작업 속도를 향상시킬 수 있고, 인물객체 정보를 기반으로 비식별화와 같은 다 양한 후처리 작업이 가능하며, 영상 내 특정 인물에 대해 검색이 가능해진다."}
{"patent_id": "10-2021-0156317", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 본 발명의 실시예에서는 동영상에서 주역 및 배경인물을 감지하는 방법을 제시한다. 본 발명의 실시예에서는 단 순 클래스 기반의 객체 구분이 아닌 콘텍스트 기반의 객체 구분을 통해, 주시(注視) 인물은 주역(관심인물)으로 비주시(非注視) 인물은 배경인물로 구분한다. 도 1은 본 발명의 일 실시예에 따른 인물 감지 시스템의 블럭도이다. 본 발명의 실시예에 따른 인물 감지 시스 템은, 동영상 내에서 등장하는 인물을 검출하고, 검출된 인물의 정보를 메타데이터 형태로 생성한다. 이와 같은 기능을 수행하는 본 발명의 실시예에 따른 인물 감지 시스템은, 도시된 바와 같이, 영상 입력부 , 프레임 분석부, 영상 분석부 및 메타데이터 생성부를 포함하여 구성된다. 영상 입력부는 편집 대상 동영상 소스(source)를 입력으로 받고 비디오 디코더(코덱)를 이용하여 영상을 구성하는 개별 프레임들을 추출한다. 동영상 입력 소스는 파일 또는 스트리밍 형태로 제공될 수 있다. 프레임 분석부는 영상 입력부로부터 전달받은 프레임을 객체검출(object detection) 모델을 사용하여 각 프레임에서 발견되는 인물들의 영역을 검출한다. 객체검출 시 기본적으로 \"사람\"과 \"얼굴\"이 검출되며 설정에 따라 검출된 인물이 착용하고 있는 각종 의류 및 액세서리도 함께 검출할 수 있다. 검출 가능한 객체(object)는 학습된 객체검출 모델에 따라 달라진다. 객체검출 모델은 사용자의 목적과 의도에 따라 선택 가능하다. 검출된 객체 정보는 각 프레임별로 구분하여 저 장된다. 영상 분석부는 프레임 분석부를 통해 수집된 각 프레임의 인물 및 착용 물품 정보를 취합하여 분석을 진행한다. 구체적으로 영상 분석부는 얼굴인식과 착용 아이템 분석을 통해 동일인물 여부를 식별한다. 또 한 영상 분석부는 인물 식별작업 진행 후 인물의 중요도를 통계적으로 분석하여 특정 인물에 대하여 주역 또는 배경인물 여부를 판단한다. 메타데이터 생성부는 영상 분석부의 분석 결과를 활용하여 각 프레임에 해당되는 인물 메타데이터 정 보를 생성한다. 사용자는 생성된 메타데이터 정보를 이용하여 영상 내 등장인물 관련 정보를 검색할 수 있다. 또한 메타데이터 정보를 이용하여 다양한 후처리 작업(예. 인물 비식별화 처리)을 진행할 수 있다. 도 2는 도 1에 도시된 프레임 분석부의 프로세스를 나타낸 도면이다. 도시된 바와 같이, 프레임 분석부 는 먼저 사용자가 선택한 검출대상 아이템을 바탕으로, 선택된 아이템을 검출할 수 있는 학습 모델을 선택 한다(S210). 다음 프레임 분석부는 입력 프레임에 대해서 사람 감지, 얼굴 감지, 아이템 감지를 수행하고, 감지된 사람 의 영역을 기준으로 감지된 다른 객체 영역들과의 중첩 정도를 분석하여 감지된 얼굴과 아이템들이 어떤 사람에 게 해당되는지 파악하고 그룹화 한다(S220). 이후 프레임 분석부는 S220단계에서 추출된 객체들의 특성을 파악한다(S230). 구체적으로 프레임 분석부 는 사람 객체에 대해서는 객체의 크기 정보를 이용하여 프레임 크기 대비 차지하는 면적 비율을 계산하고, 화면 중심부로부터의 거리 등을 계산한다. 또한 아이템들에 대해서는 구성 색상 정보 등을 추출한다.도 3은 도 2의 S230단계에서 프레임으로부터 인물 객체 정보를 추출하는 예시를 보여준다. 감지된 각 객체에 대 해서 프레임 크기 대비 구성면적 비율(예. 18%, 6% 등)과 프레임 중심으로부터의 거리(예. 0.5, 3,1 등)를 계산 한다. 마지막으로 프레임 분석부는 S220단계 및 S230단계에서 추출 및 분석된 프레임별 객체들의 정보를 통합 저장장치에 저장한다(S240). 도 4는 영상 분석부의 세부 프로세스를 보여준다. 도시된 바와 같이, 영상 분석부는 먼저 사람 객체 간 얼굴 특성과 착용 아이템 비교를 통해 객체별 고유 ID(Identifier, 식별자)를 할당하고, 프로파일(profile) 을 생성한다(S310). 도 5는 객체 식별 단계(S310)의 세부 프로세스를 보여준다. 도시된 바와 같이, 영상 분석부는 먼저 얼굴인 식(recognition) 알고리즘을 이용한 얼굴특성과 착용 아이템의 특성을 바탕으로 객체의 특성 정보를 생성한다 (S405). 얼굴특성 파악이 불가능할 경우, 착용 아이템 특성만을 사용한다. 기존 ID 프로파일이 없을 경우(S410-아니오), 영상 분석부는 새로운 고유 ID를 할당하고(S445), ID 프로파 일을 생성한다(S450). ID 프로파일은 고유 ID, 객체 특정 정보, 발생 프레임 번호 및 프레임 내 객체 번호 등의 정보를 포함한다. 반면 기존 ID 프로파일이 존재할 경우(S410-예), 영상 분석부는 해당 프로파일의 객체 특성 정보와 비교한 다(S415 & S420). 동일 특성을 가진 ID 프로파일이 발견될 경우(S430-예), 영상 분석부는 해당 ID 프로파 일에서 발생 프레임 번호와 프레임 내 객체 번호 정보를 업데이트 한다(S435). 도 6은 ID 프로파일의 생성과 업 데이트 예시를 보여준다. S420단계에서의 객체 특성 정보 비교는 동일 특성을 가진 ID 프로파일이 발견될 때까지 반복된다(S440-아니오 & S425). 다시 도 4를 참조하여 설명한다. 객체 식별 단계(S310)가 완료되면, 영상 분석부는 ID 프로파일 정보를 이 용하여 프레임별 객체 정보를 통계적으로 분석한다(S320). 통계적 분석 정보는 다음을 포함할 수 있다: 객체 발생 횟수(예. 도 3을 기준으로 A: 3회, B: 2회, C: 2회, D: 1회) 객체 구성 비율(예. A: 16~20%=3회, B: 6~10%=2회, C: 6~10%=2회, D: 6~10%=1회) 객체 중심위치 비중(예. A: 상=3회, B: 중=1회, 하=1회, C: 중=1회, 하=1회, D: 중=1회) 영상 분석부는 통계적 분석 정보와 판단 규칙(rule)을 바탕으로 검출된 인물 객체이 주역인지 배경인물인 지 여부를 판단하고, 판단 결과를 ID 프로파일에 업데이트 한다. 예를 들어 주역 객체는 영상 촬영 시 가장 빈 번하게 등장하게 되며(다수의 프레임에서 발생), 전면에 등장하게 되며(큰 크기의 객체), 화면의 중심부에 위치 하게 된다(초점 대상). 이런 조건들의 조합된 규칙을 바탕으로 주역, 배경인물 객체 여부를 판단한다. 도 7에는 주역과 배경인물을 구분한 결과를 예시하였다. 도시된 바와 같이, 사용자가 주역 인물을 구분할 수 있 는 데이터(사진)를 제공할 경우, ID 프로파일의 객체특성 정보를 비교하여 주역, 배경인물 여부를 판단할 수 있 다. 지금까지, 동영상에서 주역 및 배경인물을 감지하는 방법에 대해 바람직한 실시예를 들어 상세히 설명하였다. 본 발명의 실시예에서는, 얼굴감지, 얼굴인식, 객체추적 알고리즘을 이용하여 동영상에 등장하는 인물들에 대한 정보를 수집하고, 수집된 정보를 이용한 통계적 분석을 통해 각 등장인물 객체를 주역 및 배경인물로 구분하여 동영상 편집 작업에 활용 가능한 객체 메타데이터 정보를 제공하였다. 이를 통해, 주역, 배경인물 객체 구분 정보를 제공하여 동영상 편집 작업 속도를 향상시킬 수 있고, 인물객체 정보를 기반으로 다양한 후처리 작업이 가능해지며, 생성된 메타데이터 정보를 기반으로 영상 내 특정 인물의 검색이 가능하고 용이해진다. 한편, 본 실시예에 따른 장치와 방법의 기능을 수행하게 하는 컴퓨터 프로그램을 수록한 컴퓨터로 읽을 수 있는 기록매체에도 본 발명의 기술적 사상이 적용될 수 있음은 물론이다. 또한, 본 발명의 다양한 실시예에 따른 기 술적 사상은 컴퓨터로 읽을 수 있는 기록매체에 기록된 컴퓨터로 읽을 수 있는 코드 형태로 구현될 수도 있다. 컴퓨터로 읽을 수 있는 기록매체는 컴퓨터에 의해 읽을 수 있고 데이터를 저장할 수 있는 어떤 데이터 저장 장 치이더라도 가능하다. 예를 들어, 컴퓨터로 읽을 수 있는 기록매체는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광디스크, 하드 디스크 드라이브, 등이 될 수 있음은 물론이다. 또한, 컴퓨터로 읽을 수 있는 기록매체 에 저장된 컴퓨터로 읽을 수 있는 코드 또는 프로그램은 컴퓨터간에 연결된 네트워크를 통해 전송될 수도 있다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2021-0156317", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2021-0156317", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1. 본 발명의 일 실시예에 따른 인물 감지 시스템의 블럭도 도 2. 프레임 분석부의 프로세스 도 3. 프레임에서 인물 객체 정보 추출 및 수집 예시 도 4. 영상 분석부의 프로세스 도 5. 객체식별 단계의 세부 프로세스 도 6. ID 프로파일 생성/업데이트 예시 도 7. 주역과 배경인물 구분 예시"}
