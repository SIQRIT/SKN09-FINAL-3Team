{"patent_id": "10-2024-7031306", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0155266", "출원번호": "10-2024-7031306", "발명의 명칭": "특징 영역 광학 흐름 결정 방법 및 관련 디바이스", "출원인": "후아웨이 테크놀러지 컴퍼니 리미티드", "발명자": "게 윤잉"}}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "특징 영역 광학 흐름(feature domain optical flow) 결정 방법으로서, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득하는 단계와, 상기 참조 프레임에 대해 다중 스케일(multi-scale) 특징 추출을 수행하여 상기 참조 프레임의 M개 - M은 1 이상의 정수임 - 의 특징 맵을 획득하는 단계와, 상기 참조 프레임의 상기 M개의 특징 맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 참조 프레임의 상기 M개의 특징맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 제1 특징 영역 광학 흐름에 대해 적응 처리(adaptive processing)를 수행하여 제2 특징 영역 광학 흐름을 획득하는 단계를 포함하되, 상기 M 특징 영역 광학 흐름은 상기 제2 특징 영역 광학 흐름인, 방법."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 참조 프레임의 상기 M개의 특징맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 상기 현재 프레임의 특징 맵, 상기 타겟 특징 맵 및 상기 제1 특징 영역 광학 흐름에 기초하여 적어도 1회 반복처리를 수행하여, 제3 특징 영역 광학 흐름을 획득하는 단계 - 여기서, M 특징 영역 광학 흐름은 제3 특징 영역광학 흐름임 - 와, j번째 반복 처리가 수행되는 경우, 상기 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 상기 현재 프레임의 예측공개특허 10-2024-0155266-3-특징 맵()을 획득하는 단계 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 상기 특징 영역 광학 흐름()은 상기 제1 특징 영역 광학 흐름임 - 와, 상기 타겟 특징 맵, 상기 현재 프레임의 특징 맵, 및 상기 현재 프레임의 상기 예측 특징 맵()에 기초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름()을 획득하는 단계와, 상기 미세 조정된 특징 영역 광학 흐름()과 특징 영역 광학 흐름()을 융합하여 특징 영역 광학 흐름()을 획득하는 단계 - 여기서 j=1인 경우, 상기 특징 영역 광학 흐름()은 제1 특징 영역 광학 흐름임- 와, 상기 특징 영역 광학 흐름()에 기초하여 특징 영역 광학 흐름()을 결정하는 단계 - 여기서, 상기 특징영역 광학 흐름()이 최종 반복 처리를 통해 획득되는 경우, 상기 특징 영역 광학 흐름()은 상기 제3특징 영역 광학 흐름임 - 를 포함하는, 방법."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 참조 프레임의 상기 M개의 특징맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 제1 특징 영역 광학 흐름에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득하는 단계와, 상기 현재 프레임의 특징 맵, 상기 타겟 특징 맵 및 상기 제2 특징 영역 광학 흐름에 기초하여 적어도 1회의 반복 처리를 수행하여, 제3 특징 영역 광학 흐름을 획득하는 단계 - 여기서, 상기 M 특징 영역 광학 흐름은 상기제3 특징 영역 광학 흐름임 - 와, j번째 반복 처리가 수행되는 경우, 상기 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 현재 프레임의 예측 특징맵()을 획득하는 단계 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 상기 특징 영역 광학 흐름()은 상기 제2 특징 영역 광학 흐름임 - 와, 상기 타겟 특징 맵, 상기 현재 프레임의 특징 맵, 및 상기 현재 프레임의 상기 예측 특징 맵()에 기초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름()을 획득하는 단계와, 상기 미세 조정된 특징 영역 광학 흐름()과 특징 영역 광학 흐름()을 융합하여 특징 영역 광학 흐름()을 획득하는 단계 - 여기서 j=1인 경우, 상기 특징 영역 광학 흐름()은 제1 특징 영역 광학 흐름임- 와, 공개특허 10-2024-0155266-4-상기 특징 영역 광학 흐름()에 기초하여 특징 영역 광학 흐름()을 결정하는 단계 - 여기서, 상기 특징영역 광학 흐름()이 최종 반복 처리를 통해 획득되는 경우, 상기 특징 영역 광학 흐름()은 제3 특징영역 광학 흐름임 - 를 포함하는, 방법."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항 또는 제4항에 있어서, 상기 특징 영역 광학 흐름()에 기초하여 특징 영역 광학 흐름()을 결정하는 단계는, 상기 특징 영역 광학 흐름()을 상기 특징 영역 광학 흐름()으로 결정하는 단계, 또는 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 특징 영역 광학 흐름()에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름()을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항 내지 제5항 중 어느 한 항에 있어서, 상기 방법은, 상기 M 특징 영역 광학 흐름에 대해 코딩 처리를 수행하여 제4 특징 영역 광학 흐름을 획득하는 단계와, 상기 제4 특징 영역 광학 흐름과 상기 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 상기 현재 프레임의 제1예측 특징 맵을 획득하는 단계와, 상기 현재 프레임의 특징 맵과 상기 제1 예측 특징 맵에 기초하여 특징 영역 잔차 맵을 획득하는 단계와, 상기 특징 영역 잔차 맵을 인코딩하여 특징 영역 잔차 비트스트림을 획득하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항 내지 제5항 중 어느 한 항에 있어서, 상기 방법은, 상기 M 특징 영역 광학 흐름과 상기 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 상기 현재 프레임의 제2예측 특징 맵을 획득하는 단계와, 상기 현재 프레임의 특징 맵과 상기 제2 예측 특징 맵에 기초하여 특징 융합을 수행하여 상기 현재 프레임의 향상된 특징 맵을 획득하는 단계와, 상기 향상된 특징 맵에 대해 픽처 재구성을 수행하여 상기 현재 프레임의 재구성된 픽처를 획득하는 단계를 더포함하는, 방법.공개특허 10-2024-0155266-5-청구항 8 제1항에 있어서, M은 1보다 크고, 상기 참조 프레임의 상기 M개의 특징 맵은 서로 다른 스케일의 상기 참조 프레임의 M개의 특징맵이며, 상기 방법은, 상기 현재 프레임의 M개의 예측 특징 맵에 기초하여 M회의 특징 재구성 처리를 수행하여 상기 현재 프레임의 재구성된 픽처를 획득하는 단계를 더 포함하며, 처리된 비디오는 상기 현재 프레임의 상기 재구성된 픽처를 포함하고, 상기 현재 프레임의 상기 M개의 예측 특징 맵은 상기 M 특징 영역 광학 흐름 및 서로 다른 스케일의 상기 참조 프레임의 상기 M개의 특징 맵에 대해 개별적으로 특징 정렬 처리를 수행하여 획득되는, 방법."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 참조 프레임의 상기 M개의 특징 맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, i번째 특징 영역 광학 흐름 추정이 수행되는 경우, 픽처 영역 광학 흐름 특징 맵()에 기초하여 광학 흐름추정을 수행하여, 픽처 영역 광학 흐름 특징 맵()을 획득하는 단계 - 여기서 i는 0보다 크고 M보다 크지 않은 정수이며, i=1인 경우, 상기 픽처 영역 광학 흐름 특징 맵()은 상기 현재 프레임과 상기 참조 프레임사이의 상기 픽처 영역 광학 흐름임 - 와, 상기 참조 프레임의 특징 맵(), 상기 픽처 영역 광학 흐름 특징 맵(), 및 상기 현재 프레임의 예측 특징 맵()에 기초하여 적응 처리를 수행하여, 특징 영역 광학 흐름 특징 맵()을 획득하는 단계를 포함하되, 상기 참조 프레임의 상기 특징 맵()은 상기 참조 프레임의 특징 맵()에 대해 특징 추출을 수행하여획득되고, 상기 참조 프레임의 상기 특징 맵() 및 상기 참조 프레임의 특징 맵()은 제각기 상기 참조프레임의 상기 M개의 특징 맵 중 두 특징 맵이며, i=M인 경우, 상기 현재 프레임의 상기 예측 특징()은 상수이고, 상기 M 특징 영역 광학 흐름은 상기 특징 영역 광학 흐름 특징 맵()을 포함하며, 상기 현재 프레임의 상기예측 특징()는 상기 참조 프레임의 특징 맵()과 특징 영역 광학 흐름 특징()에 대해 특징 정렬처리를 수행하여 획득되는, 방법."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "단말 디바이스로서, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득하도록 구성된 획득 유닛과, 상기 참조 프레임에 대해 다중 스케일 특징 추출을 수행하여, 상기 참조 프레임의 M개 - M은 1보다 크거나 같은정수임 - 의 특징 맵을 획득하도록 구성된 특징 추출 유닛과, 상기 참조 프레임의 상기 M개의 특징 맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학공개특허 10-2024-0155266-6-흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하도록 구성된 광학 흐름 추정 유닛을 포함하는,단말 디바이스."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 광학 흐름 추정 유닛은 또한, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 제1 특징 영역 광학 흐름에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득하도록 구성되되, 상기 M 특징 영역 광학 흐름은 상기 제2 특징 영역 광학 흐름인, 단말 디바이스."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 광학 흐름 추정 유닛은 또한, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 상기 현재 프레임의 특징 맵, 상기 타겟 특징 맵 및 상기 제1 특징 영역 광학 흐름에 기초하여 적어도 1회 반복처리를 수행하여, 제3 특징 영역 광학 흐름을 획득하며 - 여기서, 상기 M 특징 영역 광학 흐름은 제3 특징 영역광학 흐름임 -, j번째 반복 처리가 수행되는 경우, 상기 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 상기 현재 프레임의 예측특징 맵()을 획득하고 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 상기 특징 영역 광학 흐름()은 상기 제1 특징 영역 광학 흐름임 -, 상기 타겟 특징 맵, 상기 현재 프레임의 특징 맵, 및 상기 현재 프레임의 상기 예측 특징 맵()에 기초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름()을 획득하며, 상기 미세 조정된 특징 영역 광학 흐름()과 특징 영역 광학 흐름()을 융합하여 특징 영역 광학 흐름()을 획득하고 - 여기서 j=1인 경우, 상기 특징 영역 광학 흐름()은 제1 특징 영역 광학 흐름임 -, 상기 특징 영역 광학 흐름()에 기초하여 특징 영역 광학 흐름()을 결정하도록 구성되되, 상기 특징 영역 광학 흐름()이 최종 반복 처리를 통해 획득되는 경우, 상기 특징 영역 광학 흐름()은 상기 제3 특징 영역 광학 흐름인, 공개특허 10-2024-0155266-7-단말 디바이스."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 광학 흐름 추정 유닛은 또한, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 제1 특징 영역 광학 흐름에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득하며, 상기 현재 프레임의 특징 맵, 상기 타겟 특징 맵 및 상기 제2 특징 영역 광학 흐름에 기초하여 적어도 1회의 반복 처리를 수행하여, 제3 특징 영역 광학 흐름을 획득하고 - 여기서, 상기 M 특징 영역 광학 흐름은 상기 제3특징 영역 광학 흐름임 -, j번째 반복 처리가 수행되는 경우, 상기 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 현재 프레임의 예측 특징맵()을 획득하며 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 상기 특징 영역 광학 흐름()은 상기 제2특징 영역 광학 흐름임 -, 상기 타겟 특징 맵, 상기 현재 프레임의 특징 맵, 및 상기 현재 프레임의 상기 예측 특징 맵()에 기초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름()을 획득하며, 상기 미세 조정된 특징 영역 광학 흐름()과 특징 영역 광학 흐름()을 융합하여 특징 영역 광학 흐름()을 획득하고 - 여기서 j=1인 경우, 상기 특징 영역 광학 흐름()은 제1 특징 영역 광학 흐름임 -, 상기 특징 영역 광학 흐름()에 기초하여 특징 영역 광학 흐름()을 결정하도록 구성되되, 상기 특징 영역 광학 흐름()이 최종 반복 처리를 통해 획득되는 경우, 상기 특징 영역 광학 흐름()은 제3 특징 영역 광학 흐름인, 단말 디바이스."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항 또는 제13항에 있어서, 상기 특징 영역 광학 흐름()에 기초하여 특징 영역 광학 흐름()을 결정하는 경우, 상기 광학 흐름 추정 유닛은 또한, 상기 특징 영역 광학 흐름()을 상기 특징 영역 광학 흐름()으로 결정하거나, 또는 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 특징 영역 광학 흐름()에 대해 적응 처리를 수행하여 특징 영역 광학 흐름()을 획득하도록 구성되는, 공개특허 10-2024-0155266-8-단말 디바이스."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항 내지 제4항 중 어느 한 항에 있어서, 상기 단말 디바이스는, 상기 M 특징 영역 광학 흐름에 대해 코딩 처리를 수행하여 제4 특징 영역 광학 흐름을 획득하고, 상기 제4 특징영역 광학 흐름과 상기 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 상기 현재 프레임의 제1 예측 특징 맵을 획득하며, 상기 현재 프레임의 특징 맵과 상기 제1 예측 특징 맵에 기초하여 특징 영역 잔차 맵을 획득하고,상기 특징 영역 잔차 맵을 인코딩하여 특징 영역 잔차 비트스트림을 획득하도록 구성된 후처리 유닛을 더 포함하는, 단말 디바이스."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항 내지 제4항 중 어느 한 항에 있어서, 상기 단말 디바이스는, 상기 M 특징 영역 광학 흐름과 상기 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 상기 현재 프레임의 제2예측 특징 맵을 획득하고, 상기 현재 프레임의 특징 맵과 상기 제2 예측 특징 맵에 기초하여 특징 융합을 수행하여 상기 현재 프레임의 향상된 특징 맵을 획득하며, 상기 향상된 특징 맵에 대해 픽처 재구성을 수행하여 상기 현재 프레임의 재구성된 픽처를 획득하도록 구성된 후처리 유닛을 더 포함하는, 단말 디바이스."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서, M은 1보다 크고, 상기 참조 프레임의 상기 M개의 특징 맵은 서로 다른 스케일의 상기 참조 프레임의 M개의 특징맵이며, 상기 단말 디바이스는, 상기 현재 프레임의 M개의 예측 특징 맵에 기초하여 M회의 특징 재구성 처리를 수행하여 상기 현재 프레임의 재구성된 픽처를 획득하도록 구성된 후처리 유닛을 더 포함하며, 처리된 비디오는 상기 현재 프레임의 상기 재구성된 픽처를 포함하고, 상기 현재 프레임의 상기 M개의 예측 특징 맵은 상기 M 특징 영역 광학 흐름 및 서로 다른 스케일의 상기 참조 프레임의 상기 M개의 특징 맵에 대해 개별적으로 특징 정렬 처리를 수행하여 획득되는, 단말 디바이스."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 광학 흐름 추정 유닛은 또한, i번째 특징 영역 광학 흐름 추정이 수행되는 경우, 픽처 영역 광학 흐름 특징 맵()에 기초하여 광학 흐름추정을 수행하여, 픽처 영역 광학 흐름 특징 맵()을 획득하고 - 여기서 i는 0보다 크고 M보다 크지 않은 정수이며, i=1인 경우, 상기 픽처 영역 광학 흐름 특징 맵()은 상기 현재 프레임과 상기 참조 프레임 사이공개특허 10-2024-0155266-9-의 상기 픽처 영역 광학 흐름임 -, 상기 참조 프레임의 특징 맵(), 상기 픽처 영역 광학 흐름 특징 맵(), 및 상기 현재 프레임의 예측 특징 맵()에 기초하여 적응 처리를 수행하여, 특징 영역 광학 흐름 특징 맵()을 획득하도록 구성되되, 상기 참조 프레임의 상기 특징 맵()은 상기 참조 프레임의 특징 맵()에 대해 특징 추출을 수행하여 획득되고, 상기 참조 프레임의 상기 특징 맵() 및 상기 참조 프레임의 특징 맵()은 제각기 상기 참조 프레임의 상기 M개의 특징 맵 중 두 특징 맵이며, i=M인 경우, 상기 현재 프레임의 상기 예측 특징()은 상수이고, 상기 M 특징 영역 광학 흐름은 상기 특징 영역 광학 흐름 특징 맵()을 포함하며, 상기 현재 프레임의 상기예측 특징()는 상기 참조 프레임의 특징 맵()과 특징 영역 광학 흐름 특징()에 대해 특징 정렬처리를 수행하여 획득되는, 단말 디바이스."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1항 내지 제9항 중 어느 한 항에 따른 방법을 수행하도록 구성된 처리 회로를 포함하는, 인코더."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "프로그램 코드를 포함하는 컴퓨터 프로그램 제품으로서, 상기 프로그램 코드가 컴퓨터 또는 프로세서에서 실행될 경우, 제1항 내지 제9항 중 어느 한 항에 따른 방법이수행되는, 컴퓨터 프로그램 제품."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "전자 디바이스로서, 하나 이상의 프로세서와, 상기 프로세서에 결합되고, 상기 프로세서에 의해 실행되는 프로그램을 저장하는 비일시적 컴퓨터 판독 가능 저장 매체를 포함하며, 상기 프로세서에 의해 상기 프로그램이 실행될 경우, 상기 전자 디바이스가 제1항 내지 제9항 중 어느 한 항에따른 방법을 수행할 수 있는, 전자 디바이스."}
{"patent_id": "10-2024-7031306", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "프로그램 코드를 포함하는 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 프로그램 코드가 컴퓨터 디바이스에 의해 실행될 경우, 제1항 내지 제9항 중 어느 한 항에 따른 방법이 수행되는, 공개특허 10-2024-0155266-10-컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7031306", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 특징 영역 광학 흐름 결정 방법 및 관련 디바이스를 제공하며, 인공지능(AI)에 기반한 비디오 또는 픽 처 압축"}
{"patent_id": "10-2024-7031306", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것이다. 이 방법은 구체적으로, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득하는 단계와, 참조 프레임에 대해 다중 스케일 특징 추출을 수행하여 참조 프레임의 M개 - M은 1 이 상의 정수 - 의 특징 맵을 획득하는 단계와, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 상기 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획 득하는 단계를 포함한다. 본 출원의 솔루션을 사용하여 획득된 특징 영역 광학 흐름은 더욱 정확하고 안정적이 므로 상호 예측 정확도가 향상된다. 대 표 도 - 도6"}
{"patent_id": "10-2024-7031306", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2024-0155266 CPC특허분류 H04N 19/172 (2015.01)명 세 서 청구범위 청구항 1 특징 영역 광학 흐름(feature domain optical flow) 결정 방법으로서, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득하는 단계와, 상기 참조 프레임에 대해 다중 스케일(multi-scale) 특징 추출을 수행하여 상기 참조 프레임의 M개 - M은 1 이 상의 정수임 - 의 특징 맵을 획득하는 단계와, 상기 참조 프레임의 상기 M개의 특징 맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계를 포함 하는, 방법. 청구항 2 제1항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 참조 프레임의 상기 M개의 특징 맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 제1 특징 영역 광학 흐름에 대해 적응 처리 (adaptive processing)를 수행하여 제2 특징 영역 광학 흐름을 획득하는 단계를 포함하되, 상기 M 특징 영역 광학 흐름은 상기 제2 특징 영역 광학 흐름인, 방법. 청구항 3 제1항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 참조 프레임의 상기 M개의 특징 맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 상기 현재 프레임의 특징 맵, 상기 타겟 특징 맵 및 상기 제1 특징 영역 광학 흐름에 기초하여 적어도 1회 반복 처리를 수행하여, 제3 특징 영역 광학 흐름을 획득하는 단계 - 여기서, M 특징 영역 광학 흐름은 제3 특징 영역 광학 흐름임 - 와, j번째 반복 처리가 수행되는 경우, 상기 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 상기 현재 프레임의 예측특징 맵()을 획득하는 단계 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 상기 특징 영역 광학 흐름() 은 상기 제1 특징 영역 광학 흐름임 - 와, 상기 타겟 특징 맵, 상기 현재 프레임의 특징 맵, 및 상기 현재 프레임의 상기 예측 특징 맵()에 기초하여 미 세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하는 단계와, 상기 미세 조정된 특징 영역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름 ( )을 획득하는 단계 - 여기서 j=1인 경우, 상기 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 - 와, 상기 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 단계 - 여기서, 상기 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되는 경우, 상기 특징 영역 광학 흐름( )은 상기 제3 특징 영역 광학 흐름임 - 를 포함하는, 방법. 청구항 4 제1항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 참조 프레임의 상기 M개의 특징 맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 제1 특징 영역 광학 흐름에 대해 적응 처리 를 수행하여 제2 특징 영역 광학 흐름을 획득하는 단계와, 상기 현재 프레임의 특징 맵, 상기 타겟 특징 맵 및 상기 제2 특징 영역 광학 흐름에 기초하여 적어도 1회의 반 복 처리를 수행하여, 제3 특징 영역 광학 흐름을 획득하는 단계 - 여기서, 상기 M 특징 영역 광학 흐름은 상기 제3 특징 영역 광학 흐름임 - 와, j번째 반복 처리가 수행되는 경우, 상기 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 현재 프레임의 예측 특징 맵()을 획득하는 단계 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 상기 특징 영역 광학 흐름()은 상 기 제2 특징 영역 광학 흐름임 - 와, 상기 타겟 특징 맵, 상기 현재 프레임의 특징 맵, 및 상기 현재 프레임의 상기 예측 특징 맵()에 기초하여 미 세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하는 단계와, 상기 미세 조정된 특징 영역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름 ( )을 획득하는 단계 - 여기서 j=1인 경우, 상기 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 - 와, 상기 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 단계 - 여기서, 상기 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되는 경우, 상기 특징 영역 광학 흐름( )은 제3 특징 영역 광학 흐름임 - 를 포함하는, 방법. 청구항 5 제3항 또는 제4항에 있어서, 상기 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 단계는, 상기 특징 영역 광학 흐름( )을 상기 특징 영역 광학 흐름( )으로 결정하는 단계, 또는 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 특징 영역 광학 흐름( )에 대해 적응 처 리를 수행하여 제2 특징 영역 광학 흐름( )을 획득하는 단계를 포함하는, 방법. 청구항 6 제2항 내지 제5항 중 어느 한 항에 있어서, 상기 방법은, 상기 M 특징 영역 광학 흐름에 대해 코딩 처리를 수행하여 제4 특징 영역 광학 흐름을 획득하는 단계와, 상기 제4 특징 영역 광학 흐름과 상기 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 상기 현재 프레임의 제1 예측 특징 맵을 획득하는 단계와, 상기 현재 프레임의 특징 맵과 상기 제1 예측 특징 맵에 기초하여 특징 영역 잔차 맵을 획득하는 단계와, 상기 특징 영역 잔차 맵을 인코딩하여 특징 영역 잔차 비트스트림을 획득하는 단계를 더 포함하는, 방법. 청구항 7 제2항 내지 제5항 중 어느 한 항에 있어서, 상기 방법은, 상기 M 특징 영역 광학 흐름과 상기 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 상기 현재 프레임의 제2 예측 특징 맵을 획득하는 단계와, 상기 현재 프레임의 특징 맵과 상기 제2 예측 특징 맵에 기초하여 특징 융합을 수행하여 상기 현재 프레임의 향 상된 특징 맵을 획득하는 단계와, 상기 향상된 특징 맵에 대해 픽처 재구성을 수행하여 상기 현재 프레임의 재구성된 픽처를 획득하는 단계를 더 포함하는, 방법.청구항 8 제1항에 있어서, M은 1보다 크고, 상기 참조 프레임의 상기 M개의 특징 맵은 서로 다른 스케일의 상기 참조 프레임의 M개의 특징 맵이며, 상기 방법은, 상기 현재 프레임의 M개의 예측 특징 맵에 기초하여 M회의 특징 재구성 처리를 수행하여 상기 현재 프레임의 재 구성된 픽처를 획득하는 단계를 더 포함하며, 처리된 비디오는 상기 현재 프레임의 상기 재구성된 픽처를 포함하고, 상기 현재 프레임의 상기 M개의 예측 특 징 맵은 상기 M 특징 영역 광학 흐름 및 서로 다른 스케일의 상기 참조 프레임의 상기 M개의 특징 맵에 대해 개 별적으로 특징 정렬 처리를 수행하여 획득되는, 방법. 청구항 9 제8항에 있어서, 상기 참조 프레임의 상기 M개의 특징 맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, i번째 특징 영역 광학 흐름 추정이 수행되는 경우, 픽처 영역 광학 흐름 특징 맵( )에 기초하여 광학 흐름 추정을 수행하여, 픽처 영역 광학 흐름 특징 맵()을 획득하는 단계 - 여기서 i는 0보다 크고 M보다 크지 않 은 정수이며, i=1인 경우, 상기 픽처 영역 광학 흐름 특징 맵( )은 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름임 - 와, 상기 참조 프레임의 특징 맵(), 상기 픽처 영역 광학 흐름 특징 맵(), 및 상기 현재 프레임의 예측 특 징 맵( )에 기초하여 적응 처리를 수행하여, 특징 영역 광학 흐름 특징 맵()을 획득하는 단계를 포함하 되, 상기 참조 프레임의 상기 특징 맵()은 상기 참조 프레임의 특징 맵( )에 대해 특징 추출을 수행하여 획득되고, 상기 참조 프레임의 상기 특징 맵( ) 및 상기 참조 프레임의 특징 맵()은 제각기 상기 참조 프레임의 상기 M개의 특징 맵 중 두 특징 맵이며, i=M인 경우, 상기 현재 프레임의 상기 예측 특징( )은 상 수이고, 상기 M 특징 영역 광학 흐름은 상기 특징 영역 광학 흐름 특징 맵()을 포함하며, 상기 현재 프레임의 상기 예측 특징( )는 상기 참조 프레임의 특징 맵( )과 특징 영역 광학 흐름 특징( )에 대해 특징 정렬 처리를 수행하여 획득되는, 방법. 청구항 10 단말 디바이스로서, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득하도록 구성된 획득 유닛과, 상기 참조 프레임에 대해 다중 스케일 특징 추출을 수행하여, 상기 참조 프레임의 M개 - M은 1보다 크거나 같은 정수임 - 의 특징 맵을 획득하도록 구성된 특징 추출 유닛과, 상기 참조 프레임의 상기 M개의 특징 맵과 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하도록 구성된 광 학 흐름 추정 유닛을 포함하는, 단말 디바이스. 청구항 11 제10항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 광학 흐름 추정 유닛은 또한, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 제1 특징 영역 광학 흐름에 대해 적응 처리 를 수행하여 제2 특징 영역 광학 흐름을 획득하도록 구성되되, 상기 M 특징 영역 광학 흐름은 상기 제2 특징 영역 광학 흐름인, 단말 디바이스. 청구항 12 제10항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 광학 흐름 추정 유닛은 또한, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 상기 현재 프레임의 특징 맵, 상기 타겟 특징 맵 및 상기 제1 특징 영역 광학 흐름에 기초하여 적어도 1회 반복 처리를 수행하여, 제3 특징 영역 광학 흐름을 획득하며 - 여기서, 상기 M 특징 영역 광학 흐름은 제3 특징 영역 광학 흐름임 -, j번째 반복 처리가 수행되는 경우, 상기 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 상기 현재 프레임의 예측 특징 맵()을 획득하고 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 상기 특징 영역 광학 흐름()은 상 기 제1 특징 영역 광학 흐름임 -, 상기 타겟 특징 맵, 상기 현재 프레임의 특징 맵, 및 상기 현재 프레임의 상기 예측 특징 맵()에 기초하여 미 세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하며, 상기 미세 조정된 특징 영역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름 ( )을 획득하고 - 여기서 j=1인 경우, 상기 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 -, 상기 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하도록 구성되되, 상기 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되는 경우, 상기 특징 영역 광학 흐름( ) 은 상기 제3 특징 영역 광학 흐름인, 단말 디바이스. 청구항 13 제10항에 있어서, M=1인 경우, 상기 참조 프레임의 상기 M개의 특징 맵은 타겟 특징 맵이고, 상기 광학 흐름 추정 유닛은 또한, 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름 및 상기 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 제1 특징 영역 광학 흐름에 대해 적응 처리 를 수행하여 제2 특징 영역 광학 흐름을 획득하며, 상기 현재 프레임의 특징 맵, 상기 타겟 특징 맵 및 상기 제2 특징 영역 광학 흐름에 기초하여 적어도 1회의 반 복 처리를 수행하여, 제3 특징 영역 광학 흐름을 획득하고 - 여기서, 상기 M 특징 영역 광학 흐름은 상기 제3 특징 영역 광학 흐름임 -, j번째 반복 처리가 수행되는 경우, 상기 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 현재 프레임의 예측 특징 맵()을 획득하며 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 상기 특징 영역 광학 흐름()은 상기 제2 특징 영역 광학 흐름임 -, 상기 타겟 특징 맵, 상기 현재 프레임의 특징 맵, 및 상기 현재 프레임의 상기 예측 특징 맵()에 기초하여 미 세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하며, 상기 미세 조정된 특징 영역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름 ( )을 획득하고 - 여기서 j=1인 경우, 상기 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 -, 상기 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하도록 구성되되, 상기 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되는 경우, 상기 특징 영역 광학 흐름( ) 은 제3 특징 영역 광학 흐름인, 단말 디바이스. 청구항 14 제12항 또는 제13항에 있어서, 상기 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 경우, 상기 광학 흐름 추 정 유닛은 또한, 상기 특징 영역 광학 흐름( )을 상기 특징 영역 광학 흐름( )으로 결정하거나, 또는 상기 현재 프레임의 특징 맵과 상기 타겟 특징 맵에 기초하여 상기 특징 영역 광학 흐름( )에 대해 적응 처 리를 수행하여 특징 영역 광학 흐름( )을 획득하도록 구성되는, 단말 디바이스. 청구항 15 제11항 내지 제4항 중 어느 한 항에 있어서, 상기 단말 디바이스는, 상기 M 특징 영역 광학 흐름에 대해 코딩 처리를 수행하여 제4 특징 영역 광학 흐름을 획득하고, 상기 제4 특징 영역 광학 흐름과 상기 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 상기 현재 프레임의 제1 예측 특징 맵 을 획득하며, 상기 현재 프레임의 특징 맵과 상기 제1 예측 특징 맵에 기초하여 특징 영역 잔차 맵을 획득하고, 상기 특징 영역 잔차 맵을 인코딩하여 특징 영역 잔차 비트스트림을 획득하도록 구성된 후처리 유닛을 더 포함 하는, 단말 디바이스. 청구항 16 제11항 내지 제4항 중 어느 한 항에 있어서, 상기 단말 디바이스는, 상기 M 특징 영역 광학 흐름과 상기 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 상기 현재 프레임의 제2 예측 특징 맵을 획득하고, 상기 현재 프레임의 특징 맵과 상기 제2 예측 특징 맵에 기초하여 특징 융합을 수행 하여 상기 현재 프레임의 향상된 특징 맵을 획득하며, 상기 향상된 특징 맵에 대해 픽처 재구성을 수행하여 상 기 현재 프레임의 재구성된 픽처를 획득하도록 구성된 후처리 유닛을 더 포함하는, 단말 디바이스. 청구항 17 제10항에 있어서, M은 1보다 크고, 상기 참조 프레임의 상기 M개의 특징 맵은 서로 다른 스케일의 상기 참조 프레임의 M개의 특징 맵이며, 상기 단말 디바이스는, 상기 현재 프레임의 M개의 예측 특징 맵에 기초하여 M회의 특징 재구성 처리를 수행하여 상기 현재 프레임의 재 구성된 픽처를 획득하도록 구성된 후처리 유닛을 더 포함하며, 처리된 비디오는 상기 현재 프레임의 상기 재구성된 픽처를 포함하고, 상기 현재 프레임의 상기 M개의 예측 특 징 맵은 상기 M 특징 영역 광학 흐름 및 서로 다른 스케일의 상기 참조 프레임의 상기 M개의 특징 맵에 대해 개 별적으로 특징 정렬 처리를 수행하여 획득되는, 단말 디바이스. 청구항 18 제17항에 있어서, 상기 광학 흐름 추정 유닛은 또한, i번째 특징 영역 광학 흐름 추정이 수행되는 경우, 픽처 영역 광학 흐름 특징 맵( )에 기초하여 광학 흐름 추정을 수행하여, 픽처 영역 광학 흐름 특징 맵()을 획득하고 - 여기서 i는 0보다 크고 M보다 크지 않은 정 수이며, i=1인 경우, 상기 픽처 영역 광학 흐름 특징 맵( )은 상기 현재 프레임과 상기 참조 프레임 사이의 상기 픽처 영역 광학 흐름임 -, 상기 참조 프레임의 특징 맵(), 상기 픽처 영역 광학 흐름 특징 맵(), 및 상기 현재 프레임의 예측 특 징 맵( )에 기초하여 적응 처리를 수행하여, 특징 영역 광학 흐름 특징 맵()을 획득하도록 구성되되, 상 기 참조 프레임의 상기 특징 맵()은 상기 참조 프레임의 특징 맵( )에 대해 특징 추출을 수행하여 획득 되고, 상기 참조 프레임의 상기 특징 맵( ) 및 상기 참조 프레임의 특징 맵()은 제각기 상기 참조 프레 임의 상기 M개의 특징 맵 중 두 특징 맵이며, i=M인 경우, 상기 현재 프레임의 상기 예측 특징( )은 상수이 고, 상기 M 특징 영역 광학 흐름은 상기 특징 영역 광학 흐름 특징 맵()을 포함하며, 상기 현재 프레임의 상기 예측 특징( )는 상기 참조 프레임의 특징 맵( )과 특징 영역 광학 흐름 특징( )에 대해 특징 정렬 처리를 수행하여 획득되는, 단말 디바이스. 청구항 19 제1항 내지 제9항 중 어느 한 항에 따른 방법을 수행하도록 구성된 처리 회로를 포함하는, 인코더. 청구항 20 프로그램 코드를 포함하는 컴퓨터 프로그램 제품으로서, 상기 프로그램 코드가 컴퓨터 또는 프로세서에서 실행될 경우, 제1항 내지 제9항 중 어느 한 항에 따른 방법이 수행되는, 컴퓨터 프로그램 제품. 청구항 21 전자 디바이스로서, 하나 이상의 프로세서와, 상기 프로세서에 결합되고, 상기 프로세서에 의해 실행되는 프로그램을 저장하는 비일시적 컴퓨터 판독 가능 저 장 매체를 포함하며, 상기 프로세서에 의해 상기 프로그램이 실행될 경우, 상기 전자 디바이스가 제1항 내지 제9항 중 어느 한 항에 따른 방법을 수행할 수 있는, 전자 디바이스. 청구항 22 프로그램 코드를 포함하는 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 프로그램 코드가 컴퓨터 디바이스에 의해 실행될 경우, 제1항 내지 제9항 중 어느 한 항에 따른 방법이 수 행되는, 컴퓨터 판독 가능 저장 매체. 발명의 설명 기 술 분 야 본 출원은, 2022년 3월 4일 중국특허청에 출원된, 발명의 명칭이 \"특징 영역 광학 흐름 결정 방법 및 관련 디바 이스(FEATURE DOMAIN OPTICAL FLOW DETERMINING METHOD AND RELATED DEVICE)\"인 중국 특허출원번호 제 202210215293.X호를 우선권 주장하며, 그 전체가 참조로 본 명세서에 포함된다."}
{"patent_id": "10-2024-7031306", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 3, "content": "기술분야 본 출원은 비디오 및 픽처 분야, 구체적으로는 특징 영역 광학 흐름 결정 방법 및 관련 디바이스에 관한 것이다."}
{"patent_id": "10-2024-7031306", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "비디오 코딩 분야에서, 코딩은 비디오 압축(deep video compression, DVC) 아키텍처, FVC 아키텍처 또는 유사한 아키텍처를 사용하여 픽처 영역(picture domain) 또는 특징 영역(feature domain)에서 수행된다. DVC 아키텍 처에 기반한 비디오 코딩 절차는, 인코더 측이 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 추출 하고, 픽처 영역 광학 흐름에 대해 코딩을 수행하여 디코딩된 광학 흐름을 획득하며, 참조 프레임과 디코딩된 광학 흐름에 기초하여 예측을 수행하여 현재 프레임의 예측 값을 획득하고, 현재 프레임과 현재 프레임의 예측 값에 기초하여 잔차(residual)를 결정하며, 잔차를 인코딩하여 잔차 비트스트림을 획득하는 것을 포함한다. 디 코더 측은 잔차 비트스트림을 디코딩하여 디코딩된 잔차를 획득하고, 디코딩된 잔차와 현재 프레임의 예측 값에 기초하여 현재 프레임의 재구성된 픽처를 획득한다. 그러나, 두 프레임 사이의 픽처 영역 광학 흐름을 획득하 는 데는 특정 오차가 존재하며, 픽처 영역 광학 흐름에 기초하여 현재 프레임을 예측하는 것은 픽처 영역 광학 흐름을 사용하여 획득한 정밀도에 매우 민감하다. 그 결과, 픽처 영역 광학 흐름의 약간의 변화도 예측 값에 심각한 영향을 미친다. FVC 아키텍처에 기반한 비디오 코딩 절차는, 인코더 측이 현재 프레임의 특징과 참조 프레임의 특징을 별도로 추출하고, 참조 프레임의 특징과 현재 프레임의 특징에 기초하여 특징 영역 광학 흐름을 추정하며, 특징 영역 광학 흐름에 대해 코딩을 수행하여 디코딩된 특징 영역 광학 흐름을 획득하고, 참조 프레임의 특징 및 디코딩된 특징 영역 광학 흐름에 기초하여 예측을 수행하여 현재 프레임의 예측된 특징을 획득하며, 현재 프레임의 특징 및 현재 프레임의 예측된 특징에 기초하여 특징 영역 잔차를 획득하고, 특징 영역 잔차를 인코딩하여 특징 영역 잔차 비트스트림을 획득하는 것을 포함한다. 디코더 측은 특징 영역 잔차 비트스트림을 디코딩하여 디코딩된 특징 영역 잔차를 획득하고, 디코딩된 특징 영역 잔차와 현재 프레임의 예측 특징에 기초하여 현재 프레임의 재 구성된 특징을 획득하며, 현재 프레임의 재구성된 특징에 기초하여 현재 프레임의 재구성된 픽처를 획득한다. 그러나, 현재 프레임의 특징과 참조 프레임의 특징에 기초하여 특징 영역 광학 흐름을 결정하는 데 효과적인 모 니터링이 잘 구현되지 않는다. 그 결과, 특징 영역 광학 흐름을 높은 정밀도로 얻기가 어렵다. 이는 압축 성 능에 영향을 미친다. 본 출원은 특징 영역 광학 흐름 결정 방법 및 관련 디바이스를 제공한다. 본 출원의 솔루션을 사용하면 고정밀 도의 특징 영역 광학 흐름을 얻을 수 있어, 영상 압축 품질을 개선하고 비트 레이트를 절약할 수 있다. 특정 실시예는 첨부된 독립 청구항에 개략적으로 설명되어 있으며, 다른 실시예는 종속 청구항에 설명되어 있다. 제1 양태에 따르면, 본 출원은 특징 영역 광학 흐름 결정 방법과 관련된다. 이 방법은 단말 디바이스에 의해 수행될 수 있다. 이 방법은, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득하는 단계와, 참조 프레임에 대해 다중 스케일 특징 추출을 수행하여 참조 프레임의 M개 - M은 1 이상의 정수 - 의 특징 맵을 획득하는 단계와, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐 름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계를 포함한다. 현재 프레임과 참조 프레임은 비디오에서 두 개의 프레임일 수 있다. 선택적으로, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름은 현재 프레임으로부터 참조 프레임으로의 픽처 영역 광학 흐름일 수도 있고, 또는 참조 프레임으로부터 현재 프레임으로의 픽처 영역 광학 흐름일 수 있 다. 픽처 영역 광학 흐름은 픽처의 두 프레임에서의 각 픽셀의 움직임 속도와 움직임 방향을 나타낸다. 픽처 영역 광학 흐름에 기초하여 얻은 특징 영역 광학 흐름은 더욱 정확하고 안정적이므로 상호 예측 정확도가 향상된다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 M 회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 제1 특징 영역 광학 흐름에 대해 적응 처리(adaptive processing)를 수행하여 제2 특징 영역 광학 흐름을 획득 하는 단계를 포함하되, 여기서 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제1 특징 영역 광학 흐름 을 사용하여 획득된 정밀도보다 높고, M 특징 영역 광학 흐름은 제2 특징 영역 광학 흐름이다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 M 회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 현재 프레임의 특징 맵, 타겟 특징 맵 및 제1 특징 영역 광학 흐름에 기초하여 적어도 1회 반복 처리를 수행하 여, 제3 특징 영역 광학 흐름을 획득하는 단계 - 여기서, M 특징 영역 광학 흐름은 제3 특징 영역 광학 흐름임 - 와, j번째 반복 처리가 수행되는 경우, 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하 여, 현재 프레임의 예측 특징 맵()을 획득하는 단계 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 특징 영 역 광학 흐름()은 제1 특징 영역 광학 흐름임 - 와, 타겟 특징 맵, 현재 프레임의 특징 맵, 및 현재 프레임 의 예측 특징 맵()에 기초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하 는 단계와, 미세 조정된 특징 영역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름( )을 획득하는 단계 - 여기서 j=1인 경우, 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 - 와, 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 단계를 포함한다. 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되면, 특징 영역 광학 흐름( )은 제3 특징 영역 광학 흐름이다. 제3 특징 영역 광학 흐름( )을 사용하여 획득된 정밀도는 제2 특징 영역 광학 흐름()을 사용하여 획득 된 정밀도보다 높다. 제3 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제2 특징 영역 광학 흐름을 사용하 여 획득된 정밀도보다 높다. 획득된 특징 영역 광학 흐름에 대해 미세 조정 처리가 수행되어, 특징 영역 광학 흐름을 사용하여 획득된 정밀도를 더욱 향상시킨다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 제1 특징 영역 광학 흐름에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득하는 단계와, 현재 프레임의 특징 맵, 타겟 특징 맵 및 제2 특징 영역 광학 흐름에 기초하여 적어도 1회의 반복 처리를 수행 하여, 제3 특징 영역 광학 흐름을 획득하는 단계 - 여기서, M 특징 영역 광학 흐름은 제3 특징 영역 광학 흐름 임 - 와, j번째 반복 처리가 수행되는 경우, 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 현재 프레임의 예측 특징 맵 ()을 획득하는 단계 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 특징 영역 광학 흐름()은 제2 특징 영역 광학 흐름임 - 와, 타겟 특징 맵, 현재 프레임의 특징 맵, 및 현재 프레임의 예측 특징 맵()에 기초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하는 단계와, 미세 조정된 특징 영 역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름( )을 획득하는 단계 - 여기서 j=1인 경우, 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 - 와, 특징 영역 광학 흐름 ( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 단계를 포함한다. 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되면, 특징 영역 광학 흐름( )은 제3 특징 영역 광학 흐름이다. 제3 특징 영역 광학 흐름( )을 사용하여 획득된 정밀도는 제2 특징 영역 광학 흐름()을 사용하여 획득 된 정밀도보다 높다. 제3 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제2 특징 영역 광학 흐름을 사용하 여 획득된 정밀도보다 높다. 획득된 특징 영역 광학 흐름에 대해 미세 조정 처리가 수행되어, 특징 영역 광학 흐름을 사용하여 획득된 정밀도를 더욱 향상시킨다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 단계는, 특징 영역 광학 흐름( )을 특징 영역 광학 흐름( )으로 결정하는 단계, 또는 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 특징 영역 광학 흐름( )에 대해 적응 처리를 수행하여 제 2 특징 영역 광학 흐름( )을 획득하는 단계를 포함하며, 여기서 특징 영역 광학 흐름( )을 사용하여 획득된 정밀도는 특징 영역 광학 흐름( )을 사용하여 획득된 정밀도보다 더 높다. 획득된 특징 영역 광학 흐름에 대해 미세 조정 처리가 더 수행되어, 특징 영역 광학 흐름을 사용하여 획득된 정 밀도를 더욱 향상시킨다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, 본 출원의 방법은, M 특징 영역 광학 흐름에 대해 코딩 처리를 수행하여 제4 특징 영역 광학 흐름을 획득하는 단계와, 제4 특징 영 역 광학 흐름과 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제1 예측 특징 맵을 획득하는 단계와, 현재 프레임의 특징 맵과 제1 예측 특징 맵에 기초하여 특징 영역 잔차 맵을 획득하는 단계와, 특징 영 역 잔차 맵을 인코딩하여 특징 영역 잔차 비트스트림을 획득하는 단계를 더 포함한다. 획득된 특징 영역 광학 흐름은 비디오 압축 분야에 적용되어, 비트 레이트를 절약하고 품질을 보장한다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, 본 출원의 방법은, M 특징 영역 광학 흐름과 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제2 예측 특징 맵을 획득하는 단계 - 제4 특징 영역 광학 흐름은 제1 특징 영역 광학 흐름, 제2 특징 영역 광학 흐름, 또는 제3 특 징 영역 광학 흐름임 - 와, 현재 프레임의 특징 맵과 제2 예측 특징 맵에 기초하여 특징 융합을 수행하여 현재 프레임의 향상된 특징 맵을 획득하는 단계와, 향상된 특징 맵에 대해 픽처 재구성을 수행하여 현재 프레임의 재 구성된 픽처를 획득하는 단계를 더 포함한다. 획득된 특징 영역 광학 흐름은 비디오 인핸스먼트 향상 분야에 적용되어, 비디오 인핸스먼트 효과를 향상시키고 비디오 품질을 향상시킨다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, M은 1보다 크고, 참조 프레임의 M개의 특징 맵은 서로 다른 스케일의 참조 프레임의 M개의 특징 맵이며, 본 출원의 방법은, 현재 프레임의 M개의 예측 특징 맵에 기초하여 M회의 특징 재구성 처리를 수행하여 현재 프레임의 재구성된 픽 처를 획득하는 단계를 더 포함하며, 여기서 처리된 비디오는 현재 프레임의 재구성된 픽처를 포함하고, 현재 프 레임의 M개의 예측 특징 맵은 M 특징 영역 광학 흐름 및 서로 다른 스케일의 참조 프레임의 M개의 특징 맵에 대 해 개별적으로 특징 정렬 처리를 수행하여 획득된다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프 레임 사이의 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, i번째 특징 영역 광학 흐름 추정이 수행되는 경우, 픽처 영역 광학 흐름 특징 맵( )에 기초하여 광학 흐름 추정을 수행하여, 픽처 영역 광학 흐름 특징 맵()을 획득하는 단계 - 여기서 i는 0보다 크고 M보다 크지 않 은 정수이며, i=1인 경우, 픽처 영역 광학 흐름 특징 맵( )은 현재 프레임과 참조 프레임 사이의 픽처 영 역 광학 흐름임 - 와, 참조 프레임의 특징 맵(), 픽처 영역 광학 흐름 특징 맵(), 및 현재 프레임의 예 측 특징 맵( )에 기초하여 적응 처리를 수행하여, 특징 영역 광학 흐름 특징 맵()을 획득하는 단계를 포 함하되, 참조 프레임의 특징 맵()은 참조 프레임의 특징 맵( )에 대해 특징 추출을 수행하여 획득되고, 참조 프레임의 특징 맵( ) 및 참조 프레임의 특징 맵()은 제각기 참조 프레임의 M개의 특징 맵 중 두 특 징 맵이며, i=M인 경우, 현재 프레임의 예측 특징( )은 상수이고, M 특징 영역 광학 흐름은 특징 영역 광학 흐름 특징 맵()을 포함하며, 현재 프레임의 예측 특징( )는 참조 프레임의 특징 맵( )과 특징 영역 광학 흐름 특징( )에 대해 특징 정렬 처리를 수행하여 획득된다. 복수의 스케일의 특징 영역 광학 흐름에 대해 모니터링이 수행되어, 복수의 스케일의 획득된 특징 영역 광학 흐 름의 정확도를 향상시킨다. 제2 양태에 따르면, 본 출원은 단말 디바이스와 관련된다. 유익한 효과에 대해서는 제1 양태의 설명을 참조한 다. 자세한 내용은 여기서 다시 설명하지 않는다. 단말 디바이스는 제1 양태의 방법 실시예에서의 동작들을 구현하는 기능을 갖는다. 이 기능은 하드웨어에 의해 구현될 수도 있고, 또는 대응하는 소프트웨어를 실행하는 하드웨어에 의해 구현될 수도 있다. 하드웨어 또는 소프트웨어는 전술한 기능에 대응하는 하나 이상의 모듈을 포함한다. 단말 디바이스는, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득하도록 구성된 획득 유닛 - 여기서 현재 프레임 과 참조 프레임은 비디오 내의 2개의 프레임임- 과, 참조 프레임에 대해 다중 스케일 특징 추출을 수행하여, 참조 프레임의 M개 - 여기서 M은 1보다 크거나 같은 정 수임 - 의 특징 맵을 획득하도록 구성된 특징 추출 유닛과, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하도록 구성된 광학 흐름 추정 유닛을 포함한다. 제2 양태의 단말 디바이스와 관련하여, 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 광학 흐름 추정 유닛은 또한, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 제1 특 징 영역 광학 흐름에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득하도록 구성되되, 여기서 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제1 특징 영역 광학 흐름을 사용하여 획득된 정밀도보다 더 높고, M 특징 영역 광학 흐름은 제2 특징 영역 광학 흐름이다. 제2 양태의 단말 디바이스와 관련하여, 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 광학 흐름 추정 유닛은 또한, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 현재 프레임의 특징 맵, 타겟 특징 맵 및 제1 특징 영역 광학 흐름에 기초하여 적어도 1회 반복 처리를 수행하 여, 제3 특징 영역 광학 흐름을 획득하며 - 여기서, M 특징 영역 광학 흐름은 제3 특징 영역 광학 흐름임 -, j번째 반복 처리가 수행되는 경우, 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하 여, 현재 프레임의 예측 특징 맵()을 획득하고 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 특징 영역 광 학 흐름()은 제1 특징 영역 광학 흐름임 -, 타겟 특징 맵, 현재 프레임의 특징 맵, 및 현재 프레임의 예측 특징 맵()에 기초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하며, 미세 조정된 특징 영역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름( )을 획 득하고 - 여기서 j=1인 경우, 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 -, 특징 영역 광학 흐 름( )에 기초하여 특징 영역 광학 흐름( )을 결정하도록 구성된다. 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되는 경우, 특징 영역 광학 흐름( )은 제3 특징 영역 광학 흐름이다. 제2 양태의 단말 디바이스와 관련하여, 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 광학 흐름 추정 유닛은 또한, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 제1 특 징 영역 광학 흐름에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득하며, 현재 프레임의 특징 맵, 타겟 특징 맵 및 제2 특징 영역 광학 흐름에 기초하여 적어도 1회의 반복 처리를 수행 하여, 제3 특징 영역 광학 흐름을 획득하고 - 여기서, M 특징 영역 광학 흐름은 제3 특징 영역 광학 흐름임 -, j번째 반복 처리가 수행되는 경우, 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 현재 프레임의 예측 특징 맵 ()을 획득하며 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 특징 영역 광학 흐름()은 제2 특징 영역 광학 흐름임 -, 타겟 특징 맵, 현재 프레임의 특징 맵, 및 현재 프레임의 예측 특징 맵()에 기초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하며, 미세 조정된 특징 영역 광학 흐름 ( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름( )을 획득하고 - 여기서 j=1인 경우, 특징 영역 광학 흐름()은 제1 특징 영역 광학 흐름임 -, 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하도록 구성된다. 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되 면, 특징 영역 광학 흐름( )은 제3 특징 영역 광학 흐름이다. 제2 양태의 단말 디바이스와 관련하여, 실현 가능한 실시예에서, 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 경우, 광학 흐름 추정 유닛은 또한, 특징 영역 광학 흐름( )을 특징 영역 광학 흐름( )으로 결정하거나, 또는 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 특징 영역 광학 흐름( )에 대해 적응 처리를 수행하여 특 징 영역 광학 흐름( )을 획득하도록 구성되며, 특징 영역 광학 흐름( )을 사용하여 획득된 정밀도는 특징 영역 광학 흐름()을 사용하여 획득된 정밀도보다 높다. 제2 양태의 단말 디바이스와 관련하여, 실현 가능한 실시예에서, 단말 디바이스는, M 특징 영역 광학 흐름에 대해 코딩 처리를 수행하여 제4 특징 영역 광학 흐름을 획득하고, 제4 특징 영역 광학 흐름과 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제1 예측 특징 맵을 획득하며, 현재 프 레임의 특징 맵과 제1 예측 특징 맵에 기초하여 특징 영역 잔차 맵을 획득하고, 특징 영역 잔차 맵을 인코딩하 여 특징 영역 잔차 비트스트림을 획득하도록 구성된 후처리 유닛을 더 포함한다. 제2 양태의 단말 디바이스와 관련하여, 실현 가능한 실시예에서, 단말 디바이스는, M 특징 영역 광학 흐름과 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제2 예측 특징 맵을 획득하고 - 여기서 제4 특징 영역 광학 흐름은 제1 특징 영역 광학 흐름, 제2 특징 영역 광학 흐름, 또는 제3 특징 영역 광학 흐름임 -, 현재 프레임의 특징 맵과 제2 예측 특징 맵에 기초하여 특징 융합을 수행하여 현재 프레임의 향상된 특징 맵을 획득하며, 향상된 특징 맵에 대해 픽처 재구성을 수행하여 현재 프레임의 재구성된 픽처를 획득하도록 구성된 후처리 유닛을 더 포함한다. 제2 양태의 단말 디바이스와 관련하여, 실현 가능한 실시예에서, M이 1보다 큰 경우, 참조 프레임의 M개의 특징 맵은 서로 다른 스케일의 참조 프레임의 M개의 특징 맵이며, 단말 디바이스는, 현재 프레임의 M개의 예측 특징 맵에 기초하여 M회의 특징 재구성 처리를 수행하여 현재 프레임의 재구성된 픽 처를 획득하도록 구성된 후처리 유닛을 더 포함하며, 여기서 처리된 비디오는 현재 프레임의 재구성된 픽처를 포함하고, 현재 프레임의 M개의 예측 특징 맵은 M 특징 영역 광학 흐름 및 서로 다른 스케일의 참조 프레임의 M 개의 특징 맵에 대해 개별적으로 특징 정렬 처리를 수행하여 획득된다. 제2 양태의 단말 디바이스와 관련하여, 실현 가능한 실시예에서, 광학 흐름 추정 유닛은 구체적으로, i번째 특징 영역 광학 흐름 추정이 수행되는 경우, 픽처 영역 광학 흐름 특징 맵( )에 기초하여 광학 흐름 추정을 수행하여, 픽처 영역 광학 흐름 특징 맵()을 획득하고 - 여기서 i는 0보다 크고 M보다 크지 않은 정 수이며, i=1인 경우, 픽처 영역 광학 흐름 특징 맵( )은 현재 프레임과 참조 프레임 사이의 픽처 영역 광 학 흐름임 -, 참조 프레임의 특징 맵(), 픽처 영역 광학 흐름 특징 맵(), 및 현재 프레임의 예측 특징 맵( )에 기초하여 적응 처리를 수행하여, 특징 영역 광학 흐름 특징 맵()을 획득하도록 구성되되, 참조 프레임의 특징 맵()은 참조 프레임의 특징 맵( )에 대해 특징 추출을 수행하여 획득되고, 참조 프레임의특징 맵( ) 및 참조 프레임의 특징 맵()은 제각기 참조 프레임의 M개의 특징 맵 중 두 특징 맵이며, i=M인 경우, 현재 프레임의 예측 특징( )은 상수이고, M 특징 영역 광학 흐름은 특징 영역 광학 흐름 특징 맵()을 포함하며, 현재 프레임의 예측 특징( )는 참조 프레임의 특징 맵( )과 특징 영역 광학 흐름 특징( )에 대해 특징 정렬 처리를 수행하여 획득된다. 본 출원의 제1 양태의 방법은 본 출원의 제2 양태의 장치에 의해 수행될 수 있다. 본 출원의 제1 양태의 방법 의 다른 특징들 및 구현예들은 본 출원의 제2 양태의 장치의 기능 및 구현예에 직접적으로 의존한다. 제3 양태에 따르면, 본 출원은 프로세서 및 메모리를 포함하는 전자 디바이스와 관련된다. 메모리는 프로세서 로 하여금 제1 양태에 따른 방법을 수행할 수 있게 하는 명령어를 저장한다. 제4 양태에 따르면, 컴퓨터 판독 가능한 저장 매체가 제공된다. 명령어는 컴퓨터 판독 가능한 저장 매체에 저 장된다. 명령어가 실행되는 경우, 하나 이상의 프로세서는 비디오 데이터를 인코딩할 수 있다. 명령어는 하나 이상의 프로세서로 하여금 제1 양태의 임의의 가능한 실시예의 방법을 수행할 수 있게 한다. 제5 양태에 따르면, 본 출원은 프로그램 코드를 포함하는 컴퓨터 프로그램 제품과 관련된다. 프로그램 코드가 실행될 경우, 제1 양태의 임의의 가능한 실시예의 방법이 수행된다. 제6 양태에 따르면, 본 출원은 제1 양태의 임의의 가능한 실시예의 방법을 수행하도록 구성된 인코더와 관련된 다. 하나 이상의 실시예에 대한 세부 사항은 첨부된 도면과 아래의 설명에 명시되어 있다. 다른 특징, 목적 및 장 점은 설명, 도면 및 청구 범위로부터 명백하다."}
{"patent_id": "10-2024-7031306", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 출원의 실시예는 AI 기반의 비디오 픽처 압축 기술을 제공하며, 구체적으로는 신경망 기반의 비디오 압축 기 술을 제공하며, 특히 확률 분포 및 샘플링 기반의 디코딩 방법을 제공하여 기존의 하이브리드 비디오 코딩 시스 템을 개선한다. 비디오 코딩은 일반적으로 비디오 또는 비디오 시퀀스를 형성하는 픽처 시퀀스의 처리를 나타낸다. 비디오 코 딩 분야에서, '픽처(picture)', '프레임(frame)', '이미지(image)'라는 용어를 동의어로 사용될 수 있다. 비디 오 코딩(또는 일반적으로 코딩)은 비디오 인코딩과 비디오 디코딩의 두 부분을 포함한다. 비디오 인코딩은 소 스 측에서 수행되며, 일반적으로 원본 비디오 픽처를 처리(예컨대, 압축)하여 (보다 효율적인 저장 및/또는 전 송을 위해) 비디오 픽처를 표현하는 데 필요한 데이터의 양을 줄이는 것을 포함한다. 비디오 디코딩은 목적지 측에서 수행되며, 일반적으로 인코더의 처리와 비교하여 비디오 픽처를 재구성하는 역처리를 포함한다. 실시예 들에서 비디오 픽처(또는 일반적으로 픽처)의 \"코딩\"은 비디오 픽처 또는 비디오 시퀀스의 \"인코딩\" 또는 \"디코 딩\"으로 이해해야 한다. 인코딩 부분과 디코딩 부분의 조합을 인코딩/디코딩(encoding and decoding, CODEC)이 라고도 한다. 무손실 비디오 코딩의 경우, 원본 비디오 픽처가 재구성될 수 있다. 즉, 재구성된 비디오 픽처는 원본 비디오 픽처와 동일한 품질을 갖는다(저장 또는 전송 중에 전송 손실이나 어떠한 다른 데이터 손실도 발생하지 않는다 고 가정할 때). 손실 비디오 코딩의 경우, 비디오 픽처를 표현하는 데 필요한 데이터 용량을 줄이기 위해 양자 화 등을 통해 추가 압축이 수행되며, 디코더 측에서 비디오 픽처는 완전히 재구성될 수 없다. 즉, 재구성된 비 디오 픽처의 품질이 원본 비디오 픽처의 품질보다 낮거나 또는 떨어진다. 본 출원의 실시예는 신경망의 적용과 관련된다. 이해를 돕기 위해, 다음은 본 출원의 실시예에서 사용되는 일"}
{"patent_id": "10-2024-7031306", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "부 명사 또는 용어를 먼저 설명한다. 명사 또는 용어는 또한 본 발명의 내용의 일부로 사용된다. 신경망 신경망은 뉴런을 포함할 수 있다. 뉴런은 xs와 인터셉트 1을 입력으로 사용하는 연산 유닛일 수 있다. 연산 유닛의 출력은 다음과 같다."}
{"patent_id": "10-2024-7031306", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, s=1, 2, ..., 또는 n이고, n은 1보다 큰 자연수이며, Ws는 xs의 가중치이고, b는 뉴런의 바이어스이며, f는 뉴런의 활성화 함수(activation function)로, 뉴런의 입력 신호를 출력 신호로 변환하기 위해 신경망에 비 선형 특징을 도입하는 데 사용된다. 활성화 함수의 출력 신호는 다음 컨볼루션 층의 입력으로 사용될 수 있다. 활성화 함수는 시그모이드 함수(sigmoid function)일 수 있다. 신경망은 복수의 단일 뉴런들을 서로 연결하여 구성된 네트워크이다. 구체적으로, 한 뉴런의 출력은 다른 뉴런의 입력일 수 있다. 각 뉴런의 입력은 이전 층 의 국소 수용 필드에 연결되어 국소 수용 필드(local receptive field)의 특징을 추출할 수 있다. 국소 수용 필드는 여러 뉴런을 포함하는 영역일 수 있다. 심층 신경망 다층 신경망이라고도 하는 심층 신경망(deep neural network, DNN)은 복수의 은닉층(hidden layer)을 갖는 신 경망으로 이해할 수 있다. DNN은 서로 다른 층의 위치에 따라 나뉜다. DNN의 신경망은 입력층, 은닉층, 출력 층의 세 가지 층으로 나누어질 수 있다. 일반적으로 제1 층이 입력층, 마지막 층이 출력층, 중간층이 은닉층이 다. 층들은 완전히 연결되어 있다. 구체적으로, i번째 층의 어떠한 뉴런도 반드시 (i+1)번째 층의 모든 뉴런에 연결된다. DNN은 복잡해 보이지만, 각 층의 작업 양태에서 보면 복잡하지 않다. 간단히 말해서, DNN은 다음 선형 표현식, 즉 인데, 여기서, 는 입력 벡터이고, 는 출력 벡터이며, 는 오프셋 벡터이고, W는 가중 치 행렬(계수라고도 함)이며, a()는 활성화 함수이다. 각 층에서, 입력 벡터 에 대해 이러한 간단한 연산을 수행하여, 출력 벡터 를 획득한다. DNN은 다수의 층을 포함하기 때문에, 다수의 계수 W 및 오프셋 벡터 가 존재한다. DNN에서 이들 파라미터의 정의는 다음과 같다: 계수 W를 예로 사용한다. 3층 DNN에서, 제2 층의 제 4 뉴런으로부터 제3 층의 제2 뉴런까지의 선형 계수는 으로 정의된다고 가정한다. 위첨자 3은 계수 W가 위 치하는 층을 나타내며, 아래첨자는 출력 제3층 인덱스 2와 입력 제2층 인덱스 4에 해당한다. 결론적으로, (L-1) 층의 k번째 뉴런으로부터 L 층의 j번째 뉴런까지의 계수는 로 정의된다. 입력층에 대한 파라미터 W가 없다는 점에 유의해야 한다. 심층 신경망은 네트워크에 더 많은 은닉층을 사용하 여 현실 세계의 복잡한 사례를 더 잘 설명할 수 있다. 이론적으로, 파라미터가 많은 모델은 복잡도가 더 높고 '용량'이 더 크다. 이는 모델이 더 복잡한 학습 작업을 완료할 수 있음을 나타낸다. 심층 신경망 트레이닝은 가중치 행렬을 학습하는 프로세스이다. 트레이닝의 최종 목표는 트레이닝된 심층 신경망의 모든 층의 가중 행 렬(여러 층에서 벡터 W에 의해 셩성된 가중 행렬)을 구하는 것이다. 컨볼루션 신경망 컨볼루션 신경망(convolutional neuron network, CNN)은 컨볼루션 구조를 가진 심층 신경망이다. 컨볼루션 신 경망은 컨볼루션 층과 서브샘플링 층을 포함하는 특징 추출기를 포함한다. 특징 추출기는 필터로 간주될 수 있 다. 컨볼루션 층은 컨볼루션 신경망에 있는 뉴런 층으로, 여기서 입력 신호에 대해 컨볼루션 처리가 수행된다. 컨볼루션 신경망의 컨볼루션 층에서, 하나의 뉴런은 일부 인접한 층의 뉴런에만 연결될 수 있다. 하나의 컨볼 루션 층은 일반적으로 여러 개의 특징 면(feature plane)을 포함하며, 각 특징 면은 직사각형 배열의 일부 뉴런 을 포함할 수 있다. 동일한 특징 면의 뉴런은 가중치를 공유한다. 여기서 공유되는 가중치는 컨볼루션 커널이 다. 가중치 공유는 픽처 정보 추출 방식이 위치와 무관하다는 의미로 이해될 수 있다. 컨볼루션 커널은 임의 의 크기의 행렬 형태로 초기화될 수 있다. 컨볼루션 신경망의 트레이닝 프로세스에서 컨볼루션 커널은 학습을 통해 적절한 가중치를 얻을 수 있다. 또한, 가중치 공유를 통해 직접적으로 얻을 수 있는 이점은 컨볼루션 신 경망의 층들 사이의 연결이 줄어들고 과적합(overfitting) 위험이 줄어든다는 점이다. 시퀀스 데이터를 처리하는 데 순환신경망(recurrent neural network, RNN)이 사용된다. 기존 신경망 모델 에서는 입력층으로부터 은닉층, 출력 층까지 층이 완전히 연결되고 각 층의 노드들은 연결되지 않는다. 이들 공통 신경망을 사용하여 여러 문제를 해결한다. 이 공통 신경망을 사용하여 해결할 수 없는 여러 문제가 여전 히 존재한다. 예를 들어, 문장의 다음 단어를 예측하려면, 문장의 이전 단어와 다음 단어가 독립적이지 않기 때문에, 일반적으로 이전 단어를 사용할 필요가 있다. RNN을 순환 신경망이라고 부르는 이유는 시퀀스의 현재 출력이 이전 출력과도 관련이 있기 때문이다. 구체적인 표현 형태는 네트워크가 이전 정보를 기억하고 현재 출 력을 계산하는 데 이전 정보를 적용하는 것이다. 구체적으로, 은닉층의 노드들이 연결되어 있으며, 은닉층의 입력은 입력층의 출력뿐만 아니라 이전 시점의 은닉층의 출력도 포함한다. 이론적으로, RNN은 어떠한 길이의 시퀀스 데이터도 처리할 수 있다. RNN에 대한 트레이닝은 기존 CNN 또는 DNN에 대한 트레이닝과 동일하다. RNN은 기계가 사람처럼 암기할 수 있도록 하기 위한 것이다. 따라서, RNN의 출력은 현재 입력 정보와 과거에 기억된 정보에 의존할 필요가 있다. 손실 함수 심층 신경망의 트레이닝 프로세스에서, 심층 신경망의 출력이 실제로 예측될 것으로 기대되는 값에 최대한 근접 해야 하므로, 현재 네트워크의 예측 값과 실제로 기대되는 목표 값을 비교한 후, 예측 값과 목표 값의 차이에 기초하여 신경망의 각 층의 가중치 벡터가 업데이트된다(물론 첫 업데이트 전에 일반적으로 초기화 프로세스가 있으며, 구체적으로 심층 신경망의 모든 층에 파라미터가 미리 설정되어 있다). 예를 들어, 네트워크의 예측값 이 크면, 가중치 벡터를 조정하여 예측값을 낮추고, 심층 신경망이 실제로 예상되는 목표값 또는 실제로 예상되 는 목표값에 매우 가까운 값을 예측할 수 있을 때까지 지속적으로 조정이 수행된다. 따라서, \"예측값과 목표값 의 차이를 비교를 통해 구하는 방법\"이 미리 정의될 필요가 있다. 이를 손실 함수(loss function) 또는 목적 함수(objective function)라고 한다. 손실 함수와 목적 함수는 예측 값과 목표 값의 차이를 측정하는 데 중요한 방정식이다. 손실 함수를 예로서 사용한다. 손실 함수의 출력 값(손실)이 높을수록 차이가 더 크다는 것을 나타낸다. 따라서, 심층 신경망의 트레이닝은 손실을 최대한 최소화하는 프로세스이다. 역전파 알고리즘 신경망은 트레이닝 프로세스에서 오차 역전파(back propagation, BP) 알고리즘을 사용하여 초기 신경망 모델의 파라미터 값을 수정하여, 신경망 모델의 재구성 오차 손실이 점점 작아지도록 할 수 있다. 구체적으로, 입력 신호를 출력에서 오차 손실이 발생할 때까지 순방향으로 전달하고, 오차 손실에 대한 정보를 역전파하여 초기 신경망 모델의 파라미터를 업데이트하여 오차 손실을 수렴한다. 역전파 알고리즘은 최적의 신경망 모델의 가중 행렬과 같은 파라미터를 얻기 위한 오차 손실 중심의 역전파 동작이다. 코딩 시스템의 다음 실시예들에서, 인코더 및 디코더는 도 1 내지 도 3에 기초하여 설명된다. 도 1은 본 출원의 기술을 활용할 수 있는 코딩 시스템, 예를 들어 비디오 코딩 시스템(또는 간단히 코 딩 시스템이라 함)의 일 실시예의 개략적인 블록도이다. 비디오 코딩 시스템의 비디오 인코더(또 는 간단히 인코더라 함)와 비디오 디코더(또는 간단히 디코더라 함)는 본 출원에서 설명되는 다양 한 예에 따라 다양한 기술을 수행하도록 구성될 수 있는 디바이스의 예를 나타낸다. 도 1에 도시된 바와 같이, 코딩 시스템은 소스 디바이스를 포함한다. 소스 디바이스는 인코딩된 픽처 등의 인코딩된 픽처 데이터를, 예컨대 인코딩된 픽처 데이터를 디코딩하기 위한 목적지 디바이스 에 제공하도록 구성된다. 소스 디바이스는 인코더를 포함하며, 추가로, 즉 선택적으로, 픽처 소스, 픽처 전처리기와 같은 전 처리기(또는 전처리 유닛) 및 통신 인터페이스(또는 통신 유닛)를 포함할 수 있다. 픽처 소스는 현실 세계 픽처 등을 캡처하기 위한 임의의 유형의 픽처 캡처 디바이스 및/또는 임의의 유형의 픽처 생성 디바이스, 예컨대 컴퓨터 애니메이션 픽처를 생성하기 위한 컴퓨터 그래픽 처리 유닛 또는 현실 세계 픽처, 컴퓨터 생성 픽처(예컨대, 스크린 컨텐츠 및/또는 가상 현실(VR) 픽처) 및/또는 이들의 임의의 조합(예컨 대, 증강 현실(augmented reality, AR) 픽처)을 획득 및/또는 제공하기 위한 임의의 유형의 디바이스일 수도 있 고 또는 이들을 포함할 수도 있다. 픽처 소스는 전술한 픽처들 중 임의의 것을 저장하는 임의의 유형의 메모리 또는 저장소일 수 있다. 전처리기(또는 전처리 유닛)에 의해 수행되는 처리를 구별하기 위해, 이 픽처(또는 픽처 데이터)를 원시 픽 처(또는 원시 픽처 데이터)라고도 한다. 전처리기는 (원시) 픽처 데이터를 수신하고, 픽처 데이터에 대한 전처리를 수행하여 전처리된 픽처 (또는 전처리된 픽처 데이터)를 얻도록 구성된다. 예를 들어, 전처리기에 의해 수행되는 전처리는 트 리밍, 컬러 포맷 변환(예컨대, RGB에서 YCbCr로), 컬러 보정 또는 노이즈 제거를 포함할 수 있다. 전처리 유닛 은 선택적 구성 요소일 수 있다는 것을 이해할 수 있을 것이다. 비디오 인코더(또는 인코더)는 전처리된 픽처 데이터를 수신하고 인코딩된 픽처 데이터를 제공하도 록 구성된다(자세한 내용은, 예컨대 도 2에 기초하여 아래에 설명한다). 소스 디바이스의 통신 인터페이스는 인코딩된 픽처 데이터를 수신하고, 인코딩된 픽처 데이터(21 또는 이의 추가 처리된 버전)를 저장 또는 직접 재구성을 위해 통신 채널을 통해 다른 디바이스, 예컨대, 목적지 디바이스 또는 다른 디바이스로 전송하도록 구성될 수 있다. 목적지 디바이스는 디코더를 포함하며, 추가로, 즉 선택적으로, 통신 인터페이스(또는 통신 유닛), 후처리기(또는 후처리 유닛) 및 디스플레이 디바이스를 포함할 수 있다. 목적지 디바이스의 통신 인터페이스는 소스 디바이스 또는 저장 디바이스와 같은 다른 소스 디바이 스, 예를 들어 인코딩된 픽처 데이터 저장 디바이스로부터 직접 인코딩된 픽처 데이터(또는 그 추가 처리된 버전)를 수신하고, 인코딩된 픽처 데이터를 디코더에 제공하도록 구성된다. 통신 인터페이스 및 통신 인터페이스는 소스 디바이스와 목적지 디바이스 사이의 직접 통신 링 크(예컨대, 직접 유선 또는 무선 연결)를 통해, 또는 임의의 유형의 네트워크(예컨대, 유선 또는 무선 네트워크 또는 이들의 임의의 조합), 또는 임의의 유형의 사설 및 공용 네트워크 또는 이들의 임의의 조합을 통해 인코딩 된 픽처 데이터(또는 인코딩된 데이터)를 송신 또는 수신하도록 구성될 수 있다.예를 들어, 통신 인터페이스는 인코딩된 픽처 데이터를 적절한 포맷, 예컨대 패킷으로 패키징하거나, 통신 링크 또는 통신 네트워크를 통해 전송하기 위한 임의의 유형의 전송 인코딩 또는 처리를 사용하여 인코딩 된 픽처 데이터를 처리하도록 구성될 수 있다. 통신 인터페이스는 통신 인터페이스에 대응하며, 예를 들어, 전송된 데이터를 수신하고 임의의 유형의 대응하는 전송 디코딩 또는 처리 및/또는 디패키징을 통해 전송 데이터를 처리하여 인코딩된 픽처 데이터를 획득하도록 구성될 수 있다. 통신 인터페이스 및 통신 인터페이스는 도 1에서 소스 디바이스로부터 목적지 디바이스로 향하 는 통신 채널을 화살표로 표시한 단방향 통신 인터페이스 또는 양방향 통신 인터페이스로 구성될 수 있으며, 메시지 등의 송수신, 연결 설정, 인코딩된 픽처 데이터의 전송과 같은 통신 링크 및 데이터 전송과 관 련된 기타 정보의 확인 및 교환을 위해 구성될 수 있다. 비디오 디코더(또는 디코더)는 인코딩된 픽처 데이터를 수신하고 디코딩된 픽처 데이터(또는 디코딩된 데이터)를 제공하도록 구성된다(자세한 내용은 도 3 등을 참조하여 이하에서 더 설명한다). 후처리기는 디코딩된 픽처과 같은 디코딩된 픽처 데이터(재구성된 픽처 데이터라고도 함)를 후처리하여, 후처리된 픽처와 같은 후처리된 픽처 데이터를 얻도록 구성된다. 후처리 유닛에 의해 수 행되는 후처리는, 예를 들어, 디스플레이 디바이스 등에 의해 디스플레이하기 위한 디코딩된 픽처 데이터 를 생성하기 위한 컬러 포맷 변환(예컨대, YCbCr에서 RGB로), 컬러 보정, 트리밍, 리샘플링 또는 임의의 다 른 처리를 포함할 수 있다. 디스플레이 디바이스는 사용자, 뷰어 등에게 픽처를 표시하기 위해 후처리된 픽처 데이터를 수신하도록 구성된다. 디스플레이 디바이스는 재구성된 픽처를 표현하기 위한 임의의 유형의 디스플레이, 예를 들어, 통합 또는 외부 디스플레이 또는 디스플레이 디바이스일 수 있거나 포함할 수 있다. 예를 들어, 디스플레이는 액정 디스플레이(liquid crystal display, LCD), 유기 발광 다이오드(organic light emitting diode, OLED) 디 스플레이, 플라즈마 디스플레이, 프로젝터, 마이크로 LED 디스플레이, 액정 온 실리콘(liquid crystal on silicon, LCoS), 디지털 조명 프로세서(digital light processor, DLP) 또는 임의의 다른 유형의 디스플레이를 포함할 수 있다. 코딩 시스템은 트레이닝 엔진을 더 포함한다. 트레이닝 엔진에 의해 구현되는 특정 트레이닝 프로 세스에 대해서는 후속 설명을 참조한다. 자세한 내용은 여기서 다시 설명하지 않는다. 도 1에 도시된 바와 같이, 소스 디바이스와 목적지 디바이스는 별개의 디바이스이다. 그러나, 디바이 스 실시예는 소스 디바이스와 목적지 디바이스를 모두 포함하거나, 소스 디바이스와 목적지 디바이 스 모두의 기능을 포함하는, 즉 소스 디바이스 또는 대응 기능 및 목적지 디바이스 또는 대응 기능 을 모두 포함할 수도 있다. 이러한 실시예들에서, 소스 디바이스 또는 대응하는 기능 및 목적지 디바이스 또는 대응하는 기능은 동일한 하드웨어 및/또는 소프트웨어 또는 별도의 하드웨어 및/또는 소프트웨어 또 는 이들의 임의의 조합에 의해 구현될 수 있다. 설명에 기초하여, 도 1에 도시된 소스 디바이스 및/또는 목적지 디바이스의 상이한 유닛 또는 기능의 존재 및 (정확한) 구분은 실제 디바이스 및 응용에 따라 달라질 수 있음이 당업자에게 명백하다. 인코더(예컨대, 비디오 인코더) 또는 디코더(예컨대, 비디오 디코더) 또는 둘 다는 하나 이상 의 마이크로프로세서, 디지털 신호 프로세서(digital signal processor, DSP), 애플리케이션 특정 집적 회로 (application-specific integrated circuit, ASIC), 필드 프로그래머블 게이트 어레이(field-programmable gate array, FPGA), 개별 로직, 하드웨어, 비디오 인코딩 전용 프로세서 또는 이들의 임의의 조합과 같은 도 2 에 도시된 처리 회로를 통해 구현될 수 있다. 인코더는 도 2의 인코더 및/또는 본 명세서에 설명된 임 의의 다른 인코더 시스템 또는 서브시스템과 관련하여 설명된 다양한 모듈을 구현하기 위해, 처리 회로를 통해 구현될 수 있다. 디코더는 도 3의 디코더 및/또는 본 명세서에서 설명된 다른 디코더 시스템 또 는 서브시스템과 관련하여 설명된 다양한 모듈을 구현하기 위해, 처리 회로를 통해 구현될 수 있다. 처리 회로는 아래에 설명된 다양한 동작을 수행하도록 구성될 수 있다. 도 4에 도시된 바와 같이, 일부 기술이 소프트웨어로 구현되는 경우, 디바이스는 소프트웨어 명령어를 적절한 비일시적 컴퓨터 판독 가능 저장 매체에 저장하고, 하나 이상의 프로세서를 사용하여 하드웨어로 명령어를 실행하여 본 출원의 기술들을 수행할 수 있다. 비디오 인코더와 비디오 디코더 중 어느 하나는 도 2에 도시된 바와 같이 결합된 코덱 (coder/decoder, CODEC)의 일부로서 단일 디바이스에 통합될 수 있다.소스 디바이스 및 목적지 디바이스는 임의의 유형의 핸드헬드 또는 고정 디바이스, 예를 들어 노트북 컴퓨터, 랩톱 컴퓨터, 휴대폰, 스마트폰, 태블릿, 태블릿 컴퓨터, 카메라, 데스크톱 컴퓨터, 셋톱박스, 텔레비 전, 디스플레이 디바이스, 디지털 미디어 플레이어, 비디오 게임 콘솔, 비디오 스트리밍 디바이스(예컨대, 콘텐 츠 서비스 서버 또는 콘텐츠 전달 서버), 브로드캐스트 수신 디바이스, 브로드캐스트 전송 디바이스 등을 포함 하는 다양한 디바이스 중 어느 하나를 포함할 수 있으며, 임의의 유형의 운영 체제를 사용하거나 사용하지 않을 수 있다. 경우에 따라, 소스 디바이스와 목적지 디바이스는 무선 통신 구성 요소를 구비할 수 있다. 따라서, 소스 디바이스 및 목적지 디바이스는 무선 통신 디바이스일 수 있다. 경우에 따라, 도 1에 도시된 비디오 코딩 시스템은 단지 예일 뿐이며, 본 출원에서 제공되는 기술은 비디오 코딩 설정(예컨대, 비디오 인코딩 또는 비디오 디코딩)에 적용될 수 있다. 이러한 설정은 반드시 인코딩 디바 이스와 디코딩 디바이스 간의 데이터 통신을 포함할 필요는 없다. 다른 예에서는, 데이터가 로컬 메모리에서 검색되거나 네트워크를 통해 전송되는 등의 방식으로 이루어진다. 비디오 인코딩 디바이스는 데이터를 인코딩 하고 인코딩된 데이터를 메모리에 저장할 수 있으며, 그리고/또는 비디오 디코딩 디바이스는 메모리에서 데이터 를 검색하고 데이터를 디코딩할 수 있다. 일부 예에서, 인코딩 및 디코딩은, 서로 통신하지 않고 단순히 데이 터를 메모리에 인코딩하거나 메모리에서 데이터를 검색하고 데이터를 디코딩하는 디바이스에 의해 수행된다. 도 2는 일 실시예에 따라 도 2의 비디오 인코더 및/또는 도 3의 비디오 디코더를 포함하는 비디오 코딩 시스템의 예를 도시한 도면이다. 비디오 코딩 시스템은 이미징 디바이스, 비디오 인코더, 비 디오 디코더(및/또는 처리 회로에 의해 구현된 비디오 인코더/디코더), 안테나, 하나 이상의 프로 세서, 하나 이상의 메모리 및/또는 디스플레이 디바이스를 포함할 수 있다. 도 2에 도시된 바와 같이, 이미징 디바이스, 안테나, 처리 회로, 비디오 인코더, 비디오 디코 더, 프로세서, 메모리 및/또는 디스플레이 디바이스는 서로 통신할 수 있다. 비디오 코딩 시 스템은 다른 실시예에서 비디오 인코더 또는 비디오 디코더만 포함할 수도 있다. 일부 예들에서, 안테나는 인코딩된 비디오 데이터의 비트스트림을 송신 또는 수신하도록 구성될 수 있다. 또한, 일부 예들에서, 디스플레이 디바이스는 비디오 데이터를 표시하도록 구성될 수 있다. 처리 회로(4 6)는 애플리케이션 특정 집적 회로(application-specific integrated circuit, ASIC) 로직, 그래픽 처리 유닛, 범용 프로세서 등을 포함할 수 있다. 비디오 코딩 시스템은 또한 선택적 프로세서를 포함할 수도 있다. 선택적 프로세서는 유사하게 애플리케이션 특정 집적 회로(application-specific integrated circuit, ASIC) 로직, 그래픽 처리 유닛, 범용 프로세서 등을 포함할 수 있다. 또한, 메모리는 임의의 유 형의 메모리, 예를 들어 휘발성 메모리(예컨대, 정적 랜덤 액세스 메모리(static random access memory, SRAM) 또는 동적 랜덤 액세스 메모리(dynamic random access memory, DRAM)) 또는 비휘발성 메모리(예컨대, 플래시 메모리)일 수 있다. 비제한적인 예에서, 메모리는 캐시 메모리에 의해 구현될 수 있다. 다른 예들에서, 처리 회로는 픽처 버퍼를 구현하기 위한 메모리(예컨대, 캐시)를 포함할 수 있다. 일부 예들에서, 논리 회로를 사용하여 구현된 비디오 인코더는 픽처 버퍼(예컨대, 처리 회로 또는 메모 리에 의해 구현됨) 및 그래픽 처리 유닛(예컨대, 처리 회로에 의해 구현됨)을 포함할 수 있다. 그래픽 처리 유닛은 픽처 버퍼에 통신가능하게 결합될 수 있다. 그래픽 처리 유닛은 도 2와 관련하여 설명한 모듈들 및/또는 본 명세서에 설명된 다른 인코더 시스템 또는 서브시스템을 구현하기 위해, 처리 회로를 사용하여 구현된 비디오 인코더에 포함될 수 있다. 논리 회로는 본 명세서에 설명된 다양한 연산을 수행하도록 구성 될 수 있다. 일부 예들에서, 비디오 디코더는, 도 3의 비디오 디코더와 관련하여 설명된 다양한 모듈 및/또는 본 명 세서에 설명된 다른 디코더 시스템 또는 서브시스템을 구현하기 위해, 유사한 방식으로 처리 회로에 의해 구현될 수 있다. 일부 예들에서, 논리 회로를 사용하여 구현된 비디오 디코더는 픽처 버퍼(처리 회로 또는 메모리에 의해 구현됨) 및 그래픽 처리 유닛(예컨대, 처리 회로에 의해 구현됨)을 포함할 수 있다. 그래픽 처리 유닛은 픽처 버퍼에 통신가능하게 결합될 수 있다. 그래픽 처리 유닛은 처리 회로를 사용하여 구현된 비디오 디코더에 포함되어, 도 3과 관련하여 설명한 모듈들 및/또는 본 명세서에 설명된 다른 디코더 시스템 또는 서브시스템을 구현할 수 있다. 일부 예에서, 안테나는 인코딩된 비디오 데이터의 비트스트림을 수신하도록 구성될 수 있다. 전술한 바와 같이, 인코딩된 비트스트림은 본 명세서에 설명된 비디오 프레임 인코딩과 관련된 데이터, 표시기, 인덱스 값, 모드 선택 데이터 등, 예컨대 인코딩 분할과 관련된 데이터(예컨대, 변환 계수 또는 양자화 변환 계수, (전술한) 선택적 표시기 및/또는 인코딩 분할을 정의하는 데이터) 등을 포함할 수 있다. 비디오 코딩 시스템은, 안테나에 결합되고 인코딩된 비트스트림을 디코딩하도록 구성되는 비디오 디코더를 더 포함할 수 있다. 디스플레이 디바이스는 비디오 프레임을 표시하도록 구성된다. 본 출원의 본 실시예에서, 비디오 인코더와 관련하여 설명된 예에 대해, 비디오 디코더는 역방향 프로 세스를 수행하도록 구성될 수 있음을 이해해야 한다. 신호 구문 요소와 관련하여, 비디오 디코더는 그러한 구문 요소를 수신 및 구문 분석하고 그에 대응하여 관련 비디오 데이터를 디코딩하도록 구성될 수 있다. 일부 예들에서, 비디오 인코더는 구문 요소에 대해 엔트로피 인코딩을 수행하여 인코딩된 비디오 비트스트림을 획득할 수 있다. 이러한 예들에서, 비디오 디코더는 그러한 구문 요소를 파싱하고 그에 대응하여 관련 비 디오 데이터를 디코딩할 수 있다. 설명을 쉽게 하기 위해, 본 출원의 실시예는 ITU-T 비디오 코딩 전문가 그룹(Video Coding Experts Group, VCEG)과 ISO/IEC 영화 전문가 그룹(Motion Picture Experts Group, MPEG)이 설립한 비디오 코딩 공동 협력팀 (Joint Collaboration Team on Video Coding, JCT-VC)이 개발한 다목적 비디오 코딩(Versatile video coding, VVC) 참조 소프트웨어 또는 고효율 비디오 코딩(HEVC, High-Efficiency Video Coding)을 참조하여 설명한다. 당업자는 본 출원의 실시예가 HEVC 또는 VVC에 한정되지 않음을 이해할 수 있을 것이다. 도 3은 본 출원의 실시예에 따른 비디오 코딩 디바이스의 도면이다. 비디오 코딩 디바이스는 본 명 세서에 설명된 개시된 실시예를 구현하는 데 적합하다. 일 실시예에서, 비디오 코딩 디바이스는 도 1의 비디오 디코더와 같은 디코더이거나, 도 1의 비디오 인코더와 같은 인코더일 수 있다. 비디오 코딩 디바이스는 데이터를 수신하도록 구성된 인그레스 포트(또는 입력 포트) 및 수신 유닛(수신 유닛, Rx); 데이터를 처리하도록 구성된 프로세서, 논리 유닛 또는 중앙 처리 유닛(central processing unit, CPU); 데이터를 전송하도록 구성된 송신 유닛(transmitter unit, Tx) 및 송출 포 트(또는 출력 포트); 데이터를 저장하도록 구성된 메모리를 포함할 수 있다. 예를 들어, 프로 세서는 신경망 처리 유닛일 수 있다. 비디오 코딩 디바이스는 또한, 인그레스 포트, 수신 유닛, 송신 유닛 및 이그레스 포트에 결합되며 광 신호 또는 전기 신호의 이그레스 또는 인그레 스로 사용되는 광 대 전기(optical-to-electrical, OE) 구성 요소 및 전기 대 광(electrical-to-optical, EO) 구성 요소를 더 포함할 수 있다. 프로세서는 하드웨어 및 소프트웨어에 의해 구현된다. 프로세서는 하나 이상의 프로세서 칩, 코어 (예컨대, 멀티코어 프로세서), FPGA, ASIC 및 DSP로 구현될 수 있다. 프로세서는 인그레스 포트, 수 신 유닛, 송신 유닛, 이그레스 포트 및 메모리와 통신한다. 프로세서는 코딩 모듈 (예컨대, 신경망 NN 기반 코딩 모듈)을 포함한다. 코딩 모듈은 위에서 설명한 개시된 실시예를 구현한다. 예를 들어, 코딩 모듈은 다양한 코딩 동작을 수행, 처리, 준비 또는 제공한다. 따라서, 코딩 모듈은 비디오 코딩 디바이스의 기능을 실질적으로 개선하고, 비디오 코딩 디바이스의 상이한 상태 간 전환에 영향을 미친다. 또는, 코딩 모듈은 메모리에 저장되고 프로세서에 의해 실행되 는 명령어를 사용하여 구현될 수 있다. 메모리는 하나 이상의 자기 디스크, 테이프 드라이브 및 솔리드 스테이트 드라이브를 포함하고, 오버플로 우 데이터 저장 디바이스로 사용될 수 있으며, 그러한 프로그램이 실행을 위해 선택될 때 프로그램을 저장하고, 프로그램의 실행 중에 판독되는 명령어 및 데이터를 저장하도록 구성된다. 메모리는 휘발성 및/또는 비휘 발성일 수 있으며, 읽기 전용 메모리(read-only memory, ROM), 랜덤 액세스 메모리(random access memory, RAM), 삼원 콘텐츠 어드레서블 메모리(ternary content-addressable memory, TCAM) 및/또는 정적 랜덤 액세스 메모리(static random access memory, SRAM)일 수 있다. 도 4는 일 실시예에 따른 장치의 일례의 단순화된 블록도이다. 장치는 도 1의 소스 디바이스 및 목적지 디바이스 중 하나 또는 둘 모두로 사용될 수 있다. 장치의 프로세서는 중앙 처리 유닛일 수 있다. 또는, 프로세서는 현재 존재하거나 미래에 개발 될 정보를 조작하거나 처리할 수 있는 다른 유형의 디바이스 또는 복수의 디바이스일 수 있다. 개시된 구현예 들은, 예를 들어, 도면에 도시된 프로세서와 같은 단일 프로세서를 사용하여 구현될 수 있지만, 하나 이상 의 프로세서를 사용함으로써 더 빠른 속도 및 더 높은 효율을 달성할 수 있다. 구현예에서, 장치의 메모리는 읽기 전용 메모리(ROM) 디바이스 또는 랜덤 액세스 메모리(RAM) 디바이 스일 수 있다. 임의의 다른 적절한 유형의 저장 디바이스가 메모리로 사용될 수 있다. 메모리는 버 스를 통해 프로세서에 의해 액세스되는 코드 및 데이터를 포함할 수 있다. 메모리는 운영체제 및 애플리케이션을 더 포함할 수 있다. 애플리케이션은 프로세서가 본 명세서에 설 명된 방법들을 수행할 수 있도록 하는 적어도 하나의 프로그램을 포함한다. 예를 들어, 애플리케이션은 애플리케이션 1 내지 N을 포함할 수 있고, 본 명세서에 설명된 방법들을 수행하기 위한 비디오 코딩 애플리케이 션을 더 포함할 수 있다. 장치는 디스플레이와 같은 하나 이상의 출력 디바이스를 더 포함할 수 있다. 일예에서, 디스플레이 는 터치 입력을 감지하도록 구성될 수 있는 터치 감지 소자와 디스플레이를 결합하는 터치 감지 디스플레 이일 수 있다. 디스플레이는 버스를 통해 프로세서에 결합될 수 있다. 본 명세서에서 장치의 버스는 단일 버스로 도시되어 있지만, 버스는 복수의 버스를 포함할 수 있다. 또한, 보조 저장 장치가 장치의 다른 구성 요소에 직접 결합되거나 네트워크를 통해 액세스될 수 있으며, 메모리 카드와 같은 단일 통합 유닛 또는 복수의 메모리 카드와 같은 복수의 유닛을 포함할 수 있다. 장치는 다양한 구성으로 구현될 수 있다. 본 출원의 응용 시나리오를 먼저 설명한다. 본 출원의 솔루션의 응용 시나리오는 화웨이 클라우드, 비디오 감 시, 비디오 앨범, 라이브 스트리밍, 단말기 비디오 녹화, 저장, 전송 등을 포함하지만 이에 국한되지 않는다. 본 출원의 방법은 비디오 압축, 비디오 예측, 비디오 프레임 보간, 비디오 인핸스먼트 및 비디오 분석과 같이 비디오 프레임 간 특징 융합/정렬이 필요한 모든 분야에 적용될 수 있다. 도 5a는 본 발명의 실시예에 따른 비디오 코딩 아키텍처를 도시한 도면이다. 도 5a에 도시된 바와 같이, 아키 텍처는 인코딩 디바이스, 저장/전송 모듈 및 디코딩 디바이스를 포함한다. 인코딩 디바이스는 획득한 비디오를 인코딩하여 비트스트림을 획득한다. 저장/전송 모듈은 비트스트 림을 저장하거나 또는 비트스트림을 디코딩 디바이스로 전송한다. 디코딩 디바이스는 비트스트림을 디코딩하여 재구성된 비디오를 획득한다. 도 5b가 예시로 사용된다. 인코딩 디바이스는 AI 인코딩 유닛 과 엔트로피 인코딩 유닛을 포함한다. 디코딩 디바이스는 AI 디코딩 유닛과 엔트로피 디 코딩 유닛을 포함한다. AI 인코딩 유닛, 엔트로피 인코딩 유닛, AI 디코딩 유닛 및 엔트 로피 디코딩 유닛의 기능에 대한 구체적인 설명은 다음의 관련 설명을 참조한다. 예를 들어, 특정 시나리오가 단말기 화면 녹화 또는 비디오 감시인 경우, 저장/전송 모듈은 비트스트림을 저장하며, 또는 특정 시나리오가 화웨이 클라우드 또는 라이브 스트리밍인 경우, 저장/전송 모듈은 해당 디바이스로 비트스트림을 전송한다. 도 5b는 본 출원의 실시예에 따른 비디오 저장 애플리케이션 아키텍처의 도면이다. 도 5b에 도시된 바와 같이, 아키텍처는 AI 인코딩 유닛, 엔트로피 인코딩 유닛, 저장 유닛, 로딩 유닛, 엔트로피 디코 딩 유닛 및 AI 디코딩 유닛을 포함한다. 본 출원의 방법에 기초하여, AI 인코딩 유닛은, 현재 프레임과 참조 프레임 사이의 특징 영역 광학 흐름을 획득하고, 특징 영역 광학 흐름을 인코딩하여 특징 영역 광학 흐름의 인코딩된 특징을 획득하며, 특징 영역 광 학 흐름의 인코딩된 특징을 디코딩하여 디코딩된 특징 영역 광학 흐름을 획득하고, 참조 프레임의 특징 맵 및 디코딩된 특징 영역 광학 흐름에 기초하여 현재 프레임의 예측 특징을 획득하며, 현재 프레임의 특징 및 현재 프레임의 예측 특징에 기초하여 현재 프레임의 특징 영역 잔차를 획득하고, 현재 프레임의 특징 영역 잔차를 인 코딩하여 특징 영역 잔차 특징을 획득한다. 현재 프레임과 참조 프레임은 비디오에서 두 개의 프레임일 수 있 다. 엔트로피 인코딩 유닛은 특징 영역 광학 흐름에 대해 무손실 인코딩을 수행하여 특징 영역 광학 흐름 비트 스트림을 획득하고, 특징 영역 잔차 특징에 대해 무손실 압축을 수행하여 특징 영역 잔차 비트스트림을 획득한 다. 획득된 특징 영역 광학 흐름 비트스트림과 특징 영역 잔차 비트스트림은 압축 파일, 즉 도 5b에 표시된 파 일로 간주될 수 있다. 저장 디바이스는 압축 파일을 저장한다. 로딩 유닛은 파일을 저장하기 위해 디바이스에서 비트스트림을 로드한다. 엔트로피 디코딩 유닛은 특징 영역 광학 흐름 비트스트림을 디코딩하여 특징 영역 광학 흐름의 인코딩된 특징을 획득하고, 특징 영역 잔차 비트스트림을 디코딩하여 특징 영역 잔차 특징을 획득한다. AI 디코딩 유닛은 특징 영역 광학 흐름의 인코딩된 특징을 디코딩하여 디코딩된 특징 영역 광학 흐름을 획 득하고, 특징 영역 잔차 특징을 디코딩하여 디코딩된 특징 영역 잔차를 획득하며, 참조 프레임의 특징 맵과 디 코딩된 특징 영역 광학 흐름에 기초하여 현재 프레임의 예측 특징을 획득하고, 현재 프레임의 예측 특징과 디코 딩된 특징 영역 잔차에 기초하여 현재 프레임의 디코딩된 특징을 획득하며, 현재 프레임의 디코딩된 특징에 대 해 재구성을 수행하여 현재 프레임의 디코딩된 픽처, 즉 현재 프레임의 재구성된 픽처를 획득한다. 도 5c는 본 출원의 실시예에 따른 라이브 스트리밍 아키텍처의 도면이다. 도 5c에 도시된 바와 같이, 아키텍처 는 AI 인코딩 유닛, 엔트로피 인코딩 유닛, 서버 클러스터, 엔트로피 디코딩 유닛 및 AI 디코딩 유닛을 포함한다. 본 출원의 방법에 기초하여, AI 인코딩 유닛은, 현재 프레임과 참조 프레임 사이의 특징 영역 광학 흐름을 획득하고, 특징 영역 광학 흐름을 인코딩하여 특징 영역 광학 흐름의 인코딩된 특징을 획득하며, 특징 영역 광 학 흐름의 인코딩된 특징을 디코딩하여 디코딩된 특징 영역 광학 흐름을 획득하고, 참조 프레임의 특징 맵 및 디코딩된 특징 영역 광학 흐름에 기초하여 현재 프레임의 예측 특징을 획득하며, 현재 프레임의 특징 및 현재 프레임의 예측 특징에 기초하여 현재 프레임의 특징 영역 잔차를 획득하고, 현재 프레임의 특징 영역 잔차를 인 코딩하여 특징 영역 잔차 특징을 획득한다. 현재 프레임과 참조 프레임은 비디오에서 두 개의 프레임일 수 있 다. 엔트로피 인코딩 유닛은 특징 영역 광학 흐름에 대해 무손실 인코딩을 수행하여 특징 영역 광학 흐름 비트 스트림을 획득하고, 특징 영역 잔차 특징에 대해 무손실 압축을 수행하여 특징 영역 잔차 비트스트림을 획득한 다. 서버 클러스터는 특징 영역 광학 흐름 비트스트림과 특징 영역 잔차 비트스트림을 수집하고, 수집된 비트 스트림을 사용자 장비에 전달한다. 사용자 장비의 엔트로피 디코딩 유닛은 특징 영역 광학 흐름 비트스트림을 디코딩하여 특징 영역 광학 흐 름의 인코딩된 특징을 획득하고, 특징 영역 잔차 비트스트림을 디코딩하여 특징 영역 잔차 특징을 획득한다. 사용자 장비의 AI 디코딩 유닛은 특징 영역 광학 흐름의 인코딩된 특징을 디코딩하여 디코딩된 특징 영역 광학 흐름을 획득하고, 특징 영역 잔차 특징을 디코딩하여 디코딩된 특징 영역 잔차를 획득하며, 참조 프레임의 특징 맵과 디코딩된 특징 영역 광학 흐름에 기초하여 현재 프레임의 예측 특징을 획득하고, 현재 프레임의 예측 특징과 디코딩된 특징 영역 잔차에 기초하여 현재 프레임의 디코딩된 특징을 획득하며, 현재 프레임의 디코딩된 특징에 대해 재구성을 수행하여 현재 프레임의 디코딩된 픽처, 즉 현재 프레임의 재구성된 픽처를 획득한다. AI 인코딩 유닛 및 AI 디코딩 유닛의 기능은 NPU에 의해 구현된다. 저장 유닛, 로딩 유닛 , 엔트로피 인코딩 유닛, 엔트로피 디코딩 유닛의 기능은 CPU에 의해 구현된다. 도 5d는 본 출원의 실시예에 따른 비디오 인핸스먼트 아키텍처의 도면이다. 도 5d에 도시된 바와 같이, 비디오 인핸스먼트 아키텍처는 주로 비디오 인핸스먼트 유닛을 포함한다. 본 출원의 방법에 기초하여, 비디오 인핸스먼트 유닛은 현재 프레임과 참조 프레임 사이의 특징 영역 광학 흐름을 획득하고, 참조 프레임의 특징 맵과 특징 영역 광학 흐름에 기초하여 현재 프레임의 예측 특징을 획득하 고, 현재 프레임의 특징 맵과 현재 프레임의 특징에 기초하여 특징 융합 및 특징 재구성을 수행하여 현재 프레 임의 향상된 픽처를 획득한다. 비디오 인핸스먼트 유닛의 기능은 NPU에 의해 구현된다. 다음은 특징 영역 광학 흐름 결정 방법의 구체적인 프로세스에 대해 구체적으로 설명한다. 도 6은 본 출원의 실시예에 따른 특징 영역 광학 흐름 결정 방법의 개략적인 흐름도이다. 도 6에 도시된 바와 같이, 이 방법은 다음 단계들을 포함한다. S601: 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득한다. 현재 프레임과 참조 프레임은 비디오에서 두 개의 프레임일 수 있다. 선택적으로, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 얻는 방식은 딥 러닝에 기반한 광학 흐 름 알고리즘, 예컨대 RAFT(recurrent all-pairs field transform)일 수도 있고, 또는 종래의 방법에 기반한 광 학 흐름 알고리즘이 사용될 수도 있다. 광학 흐름은 인접한 두 픽처 프레임에서 각 픽셀의 움직임 속도와 움직임 방향을 나타낸다. 광학 흐름은 시간 차원에서 각각 이전 프레임을부터 현재 프레임으로의 광학 흐름과 현재 프레임으로부터 이전 프레임으로의 광학 흐름이라는 두 가지 방향을 갖는다. 한 방향의 광학 흐름은 일반적으로 3차원 배열(2, h, w)을 사용하여 디지 털 방식으로 표현한다. 제1 채널은 오프셋 방향과 x 방향의 픽처 크기를 나타낸다. 제2 채널은 y 방향의 오프 셋 방향과 픽처의 크기를 나타낸다. 여기서 h와 w는 각각 픽처의 높이와 너비를 나타낸다. x 방향에서, 양수 값은 객체가 왼쪽으로 이동함을 나타내고, 음수 값은 객체가 오른쪽으로 이동함을 나타낸다. y 방향에서, 양수 값은 객체가 위쪽으로 이동하함을 나타내고, 음수 값은 객체가 아래쪽으로 이동함을 나타낸다. 선택적으로, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름은 현재 프레임으로부터 참조 프레임으로의 광학 흐름일 수도 있고, 참조 프레임으로부터 현재 프레임으로의 광학 흐름일 수도 있다. S602: 참조 프레임에서 다중 스케일 특징 추출을 수행하여 참조 프레임의 M개의 특징 맵을 획득하는데, 여기서 M은 1보다 크거나 같은 정수이다. 구체적으로, M이 1보다 큰 경우에 참조 프레임의 M개의 특징 맵은 서로 다른 스케일의 참조 프레임의 M개의 특 징 맵이다. 특징 추출은 참조 프레임(xt-1)에 대해 수행되어 참조 프레임의 특징 맵()을 획득하고, 특징 추 출은 참조 프레임의 특징 맵()에 대해 수행되어 참조 프레임의 특징 맵( )을 획득하며, ..., 특징 추출 은 참조 프레임의 특징 맵( )에서 수행되어 참조 프레임의 특징 맵( )을 획득한다. 다중 스케일 특징 추출은 이러한 방식으로 수행되어 서로 다른 스케일의 참조 프레임의 M개의 특징 맵을 획득한다. M=1인 경우, 특징 추출은 참조 프레임 픽처에 대해 한 번만 수행된다. 즉, 참조 프레임의 제M 특징 맵은 참조 프레임의 특 징 맵()이다. 참조 프레임의 특징 맵()을 타겟 특징 맵이라고 할 수 있다. 본 출원에서 일부 기호의 아래첨자 t는 해당 기호에 해당하는 데이터가 현재 프레임과 관련됨을 나타낸다. 예 를 들어 ft는 현재 프레임의 특징 맵을 나타내고 는 현재 프레임의 예측 특징을 나타낸다. 일부 기호의 아래 첨자 t-1은 이들 기호에 해당하는 데이터가 참조 프레임과 관련됨을 나타낸다. 예를 들어 ft-1은 참조 프레임의 특징 맵을 나타낸다. 본 출원에서 일부 기호의 아래첨자는 t1 및 t2이다. 아래 첨자가 t1과 t2인 기호는 상이 한 데이터를 나타낸다. S603: 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 M 회 의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득한다. 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정 을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 제1 특징 영역 광학 흐름에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득하는 단계를 포함하되, 여기서 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제1 특징 영역 광학 흐름을 사용하여 획득된 정밀 도보다 높고, M 특징 영역 광학 흐름은 제2 특징 영역 광학 흐름이다. 구체적으로, 광학 흐름 추정 네트워크는 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름()과 타겟 특징 맵()에 기초하여 특징 영역 광학 흐름 추정을 수행하여 제1 특징 영역 광학 흐름을 획득할 수 있다. 광학 흐름 추정 네트워크는 신경망에 기초하여 구현된다. 일 예에서, 도 7은 광학 흐름 추정 네트워크를 예시 적으로 보여준다. 도 7에서 볼 수 있듯이, 광학 흐름 추정 네트워크는 두 개의 컨볼루션 층과 하나의 ReLu 활 성화 층을 포함하는데, 이들은 인터리브되고 캐스케이드되어 있다. 각 컨볼루션 층의 컨볼루션 커널 크기는 3x3이다. 특징 맵 출력 채널은 N개이다. 제1 컨볼루션 층은 현재 프레임과 참조 프레임 사이의 입력 픽처 영 역 광학 흐름()의 높이와 너비에 대해 2의 배수만큼 다운샘플링을 수행한다. 현재 프레임과 참조 프레임 사 이의 픽처 영역 광학 흐름()의 크기는 [N, H, W]라고 가정한다. 이 경우, 광학 흐름 추정에 의해 출력되는 특징 영역 광학 흐름 특징 맵()의 크기는 [N, H/2, W/2], 즉 제1 특징 영역 광학 흐름이다. 광학 흐름 추 정 네트워크의 경우, 입력은 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름이고, 출력은 제1 특징 영역 광학 흐름이다. 제1 특징 영역 광학 흐름의 크기는 현재 프레임의 크기와 일치한다. 광학 흐름 추정 네트워크의 아키텍처는 본 명세서에서 제한되지 않는다는 점에 유의해야 한다. 예를 들어, 컨 볼루션 커널의 크기, 특징 맵 채널의 수, 다운샘플링 위치, 컨볼루션 층의 수 및 네트워크 활성화 층이 모두 조 정될 수 있고, 또는 더 복잡한 네트워크 구조가 사용될 수 있다. 이는 도 7에 도시된 아키텍처에 국한되지 않 는다. 제1 어댑티브 네트워크(adaptive network)는 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 제1 특징 영역 광학 흐름에 대한 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득한다. 제1 어댑티브 네트워크는 신경 망에 기초하여 구현된다. 일례로, 제1 어댑티브 네트워크는 컨볼루션 커널의 크기가 3x3이고, 컨볼루션 층에 의해 출력되는 특징 맵의 채널 수가 N인 컨볼루션 층에 기초하여 구현된다. 제1 어댑티브 네트워크의 경우, 입 력은 현재 프레임의 특징 맵, 참조 프레임의 특징 맵 및 제1 특징 영역 광학 흐름이고, 출력은 현재 프레임의 특징 맵과 참조 프레임의 특징 맵 사이의 특징 영역 광학 흐름이다. 본 명세서에서는 제1 어댑티브 네트워크의 아키텍처가 본 명세서에서 제한되지 않는다는 점에 유의해야 한다. 예를 들어, 컨볼루션 커널의 크기, 특징 맵 채널의 수, 컨볼루션 층의 수가 모두 조정될 수 있으며, 또는 더 복 잡한 네트워크 구조가 사용될 수 있다. 제1 특징 영역 광학 흐름에 적응 처리를 수행하여 얻은 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제1 특징 영역 광학 흐름을 사용하여 획득된 정밀도보다 높다. 여기서, 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀도가 제1 특징 영역 광학 흐름을 사용하여 획득된 정 밀도보다 높다는 것은 구체적으로 픽처 또는 비디오 처리 작업에서, 제2 특징 영역 광학 흐름을 사용하여 획득 된 전반적인 효과가 제1 특징 영역 광학 흐름을 사용하여 획득된 전반적인 효과보다 우수하다는 것을 나타낸다 는 점에 유의해야 한다. 예를 들어, 픽처 또는 비디오 인핸스먼트 작업에서 제2 특징 영역 광학 흐름을 사용하 여 획득된 향상된 픽처 또는 비디오의 품질이 제1 특징 영역 광학 흐름을 사용하여 획득된 향상된 픽처 또는 비 디오의 품질보다 더 높다. 다른 예로, 픽처 또는 비디오 압축 작업에서, 제2 특징 영역 광학 흐름을 사용하여 수행된 압축의 압축 비율이 제1 특징 영역 광학 흐름을 사용하여 수행된 압축의 압축 비율보다 더 높다. 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정 을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 제1 특징 영역 광학 흐름에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득하는 단계와, 현재 프레임의 특징 맵, 타겟 특징 맵 및 제2 특징 영역 광학 흐름에 기초하여 적어도 1회의 반복 처리를 수행 하여, 제3 특징 영역 광학 흐름을 획득하는 단계 - 여기서, M 특징 영역 광학 흐름은 제3 특징 영역 광학 흐름 이고, 제3 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀 도보다 높음 - 와, j번째 반복 처리가 수행되는 경우, 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하 여, 현재 프레임의 예측 특징 맵()을 획득하는 단계 - 여기서, j=1인 경우, 특징 영역 광학 흐름()은 제2 특징 영역 광학 흐름임 - 와, 타겟 특징 맵, 현재 프레임의 특징 맵, 및 현재 프레임의 예측 특징 맵()에 기 초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하는 단계와, 미세 조정된 특징 영역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름( )을 획득하는 단계 - 여기서 j=1인 경우, 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 - 와, 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 단계를 포함한다. 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되면, 특징 영역 광학 흐름( )은 제3 특징 영역 광학 흐름이고, 특징 영역 광학 흐름( )을 사용하여 획득된 정밀도는 특징 영역 광학 흐름()을 사용하 여 획득된 정밀도보다 높다. 특정 예에서, 현재 프레임의 특징 맵(ft), 타겟 특징 맵(ft-1) 및 제2 특징 영역 광학 흐름에 기초하여 적어도 한 번 반복 처리를 수행하여 제3 특징 영역 광학 흐름을 획득한다. 제3 특징 영역 광학 흐름을 사용하여 획득 된 정밀도는 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀도보다 높다. 반복 처리가 한 번만 수행되는 경우, 제2 특징 영역 광학 흐름이 획득된 후, 타겟 특징 맵(ft-1)과 제2 특징 영 역 광학 흐름에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징을 획득하고, 현재 프레임의 특징 맵 (ft), 타겟 특징 맵(ft-1)및 현재 프레임의 예측된 특징에 기초하여 미세 조정 처리를 수행하여 미세 조정된 특징 영역 광학 흐름을 획득하며, 미세 조정된 특징 영역 광학 흐름과 제1 특징 영역 광학 흐름을 융합하여 특징 영 역 광학 흐름( )을 획득한다. 예를 들어, 특징 영역 광학 흐름( )은 제3 특징 영역 광학 흐름이다. 선 택적으로, 특징 영역 광학 흐름( )이 획득된 후, 현재 프레임의 특징 맵(ft) 및 타겟 특징 맵(ft-1)에 기초하 여 특징 영역 광학 흐름에 대해 적응 처리가 수행되고, 획득된 특징 영역 광학 흐름은 제3 특징 영역 광학 흐름 이다. 도 8에 도시된 바와 같이 복수의 반복을 수행하는 경우, 제2 특징 영역 광학 흐름이 획득된 후, 타겟 특징 맵 (ft-1) 및 제2 특징 영역 광학 흐름에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징()을 획득하 고, 현재 프레임의 특징 맵(ft), 타겟 특징 맵(ft-1) 및 현재 프레임의 예측 특징()에 기초하여 미세 조정 처 리를 수행하여, 미세 조정된 특징 영역 광학 흐름()을 획득하며, 미세 조정된 특징 영역 광학 흐름() 및 제1 특징 영역 광학 흐름을 융합하여 특징 영역 광학 흐름( )을 획득한다. 예를 들어, 특징 영역 광학 흐름( )은 특징 영역 광학 흐름( )이다. 선택적으로, 특징 영역 광학 흐름( )이 획득된 후, 현재 프 레임의 특징 맵(ft) 및 타겟 특징 맵(ft-1)에 기초하여 특징 영역 광학 흐름( )에 대해 적응 처리가 수행되고, 획득된 특징 영역 광학 흐름은 특징 영역 광학 흐름( )이다. 특징 정렬 처리는 타겟 특징 맵(ft-1) 및 특징 영역 광학흐름( )에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징()을 획득한다. 미 세 조정 처리는 현재 프레임의 특징 맵(ft), 타겟 특징 맵(ft-1) 및 현재 프레임의 예측 특징()에 기초하여 미 세조정 처리를 수행하여 미세 조정된 특징 영역 광학 흐름()을 획득한다. 미세 조정된 특징 영역 광학 흐 름() 및 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름( )을 획득한다. 예를 들어, 특징 영역 광학 흐름( )은 특징 영역 광학 흐름( )이다. 선택적으로, 특징 영역 광학 흐름( )이 획득된 후, 현재 프레임의 특징 맵(ft) 및 타겟 특징 맵(ft-1)에 기초하여 특징 영역 광학 흐름( )에 대해 적응 처리 가 수행되고, 획득된 특징 영역 광학 흐름은 특징 영역 광학 흐름( )이다. 여기서는 두 번의 반복 처리가 수행되었다. j번째 반복 처리가 수행되는 경우, 타겟 특징 맵(ft-1) 및 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징()을 획득한다. 현재 프레임의 특징 맵(ft), 타겟 특징 맵(ft- 1) 및 현재 프레임의 예측 특징()에 기초하여 미세 조정 처리가 수행되어, 미세 조정된 특징 영역 광학 흐름 ( )을 획득한다. 미세 조정된 특징 영역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름( )을 획득한다. 예를 들어, 특징 영역 광학 흐름( )은 특징 영역 광학흐름( )이다. 선택적으로, 특징 영역 광학 흐름( )이 획득된 후, 현재 프레임의 특징 맵(ft) 및 타겟 특징 맵(ft-1)에 기초하여 특징 영역 광학 흐름( )에 대해 적응 처리가 수행되고, 획득된 특징 영역 광학 흐 름은 특징 영역 광학 흐름( )이다. 이런 방식으로, 제3 특징 영역 광학 흐름을 얻을 수 있다. 여기서, 제3 특징 영역 광학 흐름을 사용하여 획득된 정밀도가 제1 특징 영역 광학 흐름을 사용하여 획득된 정 밀도보다 높다는 것은, 구체적으로 픽처 또는 비디오 처리 작업에서 제3 특징 영역 광학 흐름을 사용하여 획득 된 전반적인 효과가 제1 특징 영역 광학 흐름을 사용하여 획득된 전반적인 효과보다 더 우수하다는 것을 나타낸 다는 점에 유의해야 한다. 예를 들어, 픽처 또는 비디오 인핸스먼트 작업에서, 제3 특징 영역 광학 흐름을 사 용하여 획득된 향상된 픽처 또는 비디오의 품질이 제1 특징 영역 광학 흐름을 사용하여 획득된 향상된 픽처 또 는 비디오의 품질보다 더 높다. 다른 예로, 픽처 또는 비디오 압축 작업에서, 제 3 특징 영역 광학 흐름을 사 용하여 수행된 압축의 압축 비율이 제1 특징 영역 광학 흐름을 사용하여 수행된 압축의 압축 비율보다 더 높다. 본 출원의 다른 부분에서 두 가지 특징 영역 광학 흐름을 사용하여 획득된 정밀도의 구체적인 의미에 대해서는 전술한 관련 설명을 참조할 수 있음을 이해해야 한다. 자세한 내용은 여기서 다시 설명하지 않는다. 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 M회의 특징 영역 광학 흐름 추정 을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하는 단계와, 현재 프레임의 특징 맵, 타겟 특징 맵 및 제1 특징 영역 광학 흐름에 기초하여 적어도 1회 반복 처리를 수행하 여, 제3 특징 영역 광학 흐름을 획득하는 단계 - 여기서, 제3 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제1 특징 영역 광학 흐름을 사용하여 획득된 정밀도보다 높고, M 특징 영역 광학 흐름은 제3 특징 영역 광학 흐 름임 - 와, j번째 반복 처리가 수행되는 경우, 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하 여, 현재 프레임의 예측 특징 맵()을 획득하는 단계 - 여기서, j=1인 경우, 특징 영역 광학 흐름()은 제1 특징 영역 광학 흐름임 - 와, 타겟 특징 맵, 현재 프레임의 특징 맵, 및 현재 프레임의 예측 특징 맵()에 기 초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하는 단계와, 미세 조정된 특징 영역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름( )을 획득하는 단계 - 여기서 j=1인 경우, 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 - 와, 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 단계를 포함한다. 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되면, 특징 영역 광학 흐름( )은 제3 특징 영역 광학 흐름이고, 특징 영역 광학 흐름( )을 사용하여 획득된 정밀도는 특징 영역 광학 흐름()을 사용하 여 획득된 정밀도보다 높다. 도 8에 도시된 아키텍처에 기초하여, 제2 특징 영역 광학 흐름은 제1 특징 영역 광학 흐름으로 대체될 수 있으 며, 다른 처리는 변경되지 않는다는 점에 유의해야 한다. 반복 처리를 중지하는 조건은 반복 횟수가 미리 설정된 횟수에 도달하거나 특정 반복 처리 횟수를 통해 얻은 특 징 영역 광학 흐름을 사용하여 획득된 정밀도가 미리 설정된 정밀도에 도달하는 경우이다. 특징 정렬 처리의 특정 구현은 워핑 및 변형 가능한 컨볼루션 네트워크(deformable convolutional network, DCN)를 포함하지만 이에 국한되지 않으며, 물론 특징 정렬 처리가 구현될 수 있는 다른 방식이 있을 수 있다는점에 유의해야 한다. 예를 들어, 미세 조정 네트워크는 현재 프레임의 특징 맵(ft), 타겟 특징 맵(ft-1)및 현재 프레임의 예측 특징에 기초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름을 획득할 수 있다. 미세 조정 네트워 크는 신경망에 기초하여 구현된다. 예를 들어, 미세 조정 네트워크에는 인터리브 및 캐스케이드되는 두 개의 컨볼루션 층과 하나의 relu 활성화 층을 포함한다. 각 컨볼루션 층의 컨볼루션 커널 크기는 3x3이다. 미세 조 정 네트워크에 의해 출력되는 특징 영역 광학 흐름의 채널 수는 N개이다. 입력되는 현재 프레임의 특징 맵(f t)의 크기, 타겟 특징 맵(ft-1) 및 현재 프레임의 예측 특징의 크기는 [N, H/s, W/s]이고, 출력 특징 영역 광학 흐름의 크기는 [N, H/s, W/s]이라고 가정한다. 여기서 미세 조정 네트워크의 아키텍처는 제한되지 않는다는 점에 유의해야 한다. 예를 들어, 컨볼루션 커널의 크기, 특징 맵 채널의 수, 업샘플링/다운샘플링 팩터, 업샘플링/다운샘플링 횟수, 컨볼루션 층의 수, 네트워크 활성화 층이 모두 조정되거나 더 복잡한 네트워크 구조가 사용될 수 있다. 제2 어댑티브 네트워크는 현재 프레임의 특징 맵(ft)과 타겟 특징 맵(ft-1)에 기초하여 특징 영역 광학 흐름에 대 해 적응 처리를 특별히 수행할 수 있다. 제2 어댑티브 네트워크는 신경망에 기초하여 구현된다. 선택적으로, 제2 어댑티브 네트워크의 아키텍처는 제1 어댑티브 네트워크의 아키텍처와 동일학나 또는 상이하며, 예를 들어 컨볼루션 커널의 크기, 컨볼루션 층의 수 및 ReLu 활성화 층이 상이할 수 있다. 실현 가능한 실시예에서, 본 출원의 방법은, M 특징 영역 광학 흐름에 대해 코딩 처리를 수행하여 제4 특징 영역 광학 흐름을 획득하는 단계와, 제4 특징 영 역 광학 흐름과 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제1 예측 특징 맵을 획득하는 단계와, 현재 프레임의 특징 맵과 제1 예측 특징 맵에 기초하여 특징 영역 잔차 맵을 획득하는 단계와, 특징 영 역 잔차 맵을 인코딩하여 특징 영역 잔차 비트스트림을 획득하는 단계를 더 포함한다. 선택적으로, M 특징 영역 광학 흐름은 제1 특징 영역 광학 흐름, 제2 특징 영역 광학 흐름 또는 제3 특징 영역 광학 흐름일 수 있다. 구체적으로, 도 9에 도시된 바와 같이, 현재 프레임과 참조 프레임에 대해 별도로 특징 추출을 수행하여 현재 프레임의 특징(ft)과 참조 프레임의 특징(ft-1) 을 획득하고, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득하며, 현재 프레임의 특징 맵, 참조 프레임의 특징 맵 및 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 전술한 방식으로 제1 특징 영역 광학 흐름, 제2 특징 영역 광학 흐름 또는 제3 특징 영역 광학 흐름을 획득한다. 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제1 특징 영역 광학 흐름을 사용하여 획득된 정밀도보다 높다. 제3 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀도보다 높다. 특징 영역 광학 흐름 비트스트림을 얻기 위해 M 특징 영역 광학 흐 름이 인코딩된다. M 특징 영역 광학 흐름(들)은 제1 특징 영역 광학 흐름, 제2 특징 영역 광학 흐름 또는 제3 특징 영역 광학 흐름일 수 있다. 특징 영역 광학 흐름 비트스트림을 디코딩하여 제4 특징 영역 광학 흐름을 획 득한다. 참조 프레임의 특징 맵(ft-1) 및 제4 특징 영역 광학 흐름맵에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제1 예측 특징 맵을 획득한다. 특징 정렬 처리는 워핑 또는 DCN 방식으로 수행될 수도 있고, 또는 특 징 정렬을 구현할 수 있는 다른 방식으로 수행될 수도 있다. 이는 본 명세서에 한정되지 않는다. 특징 영역 잔차 맵은 현재 프레임의 특징 맵(ft) 및 현재 프레임의 제1 예측 특징 맵에 기초하여 얻어진다. 특징 영역 잔 차 맵은 현재 프레임의 특징 맵(ft) 및 현재 프레임의 제1 예측 특징 맵 사이의 잔차이다. 특징 영역 잔차 맵 을 인코딩하여 특징 영역 잔차 비트스트림을 획득한다. 전술한 방식으로, 비디오 압축 또는 코딩이 완료될 수 있다. 비디오 압축의 경우, 비디오 압축 후 얻어진 파일은 위에서 얻은 특징 영역 광학 흐름 비트스트림과 특 징 영역 잔차 비트스트림을 포함한다. 선택적으로, M 특징 영역 광학 흐름은 제1 특징 영역 광학 흐름, 제2 특징 영역 광학 흐름 또는 제3 특징 영역 광학 흐름일 수 있다. 비디오 압축 또는 코딩을 통해 얻은 비트스트림을 디코딩하는 프로세스는, 참조 프레임에서 특징 추출을 수행하여 참조 프레임의 특징 맵을 획득하는 단계와, 특징 영역 광학 흐름 비트스 트림을 디코딩하여 제5 특징 영역 광학 흐름을 획득하는 단계와, 참조 프레임의 특징 맵(ft-1) 및 제5 특징 영역광학 흐름에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제1 예측 특징을 획득하는 단계와, 특징 영역 잔차 비트스트림을 디코딩하여 특징 영역 잔차 맵을 획득하는 단계와, 현재 프레임의 제1 예측 특징 및 특징 영역 잔 차 맵에 기초하여 현재 프레임의 제3 예측 특징 맵을 획득하는 단계와, 현재 프레임의 제3 예측 특징 맵에 기초 하여 픽처 재구성을 수행하여 현재 프레임의 재구성된 픽처를 획득하는 단계를 포함한다. 도 10의 a에 표시된 특징 추출 네트워크는 현재 프레임과 참조 프레임에 대해 특징 추출을 수행할 수 있다. 특 징 추출 네트워크는 신경망에 기초하여 구현된다. 특징 추출 네트워크는 하나의 컨볼루션 층과 3개의 잔차 블 록에 의해 구현된다. 도 10의 b에 표시된 재구성 네트워크는 현재 프레임의 제3 예측 특징 맵에 기초하여 픽처 재구성을 수행할 수 있다. 재구성 네트워크는 신경망에 기초하여 구현된다. 재구성 네트워크는 3개의 잔차 블 록과 하나의 디컨볼루션 층에 의해 구현된다. 도 10의 a와 b에 표시된 잔차 블록의 구조는 도 10의 c에 표시되 어 있다. 잔차 블록은 두 개의 컨볼루션 층과 하나의 relu 활성화 층에 의해 구현된다. 도 11의 a에 표시된 인코딩 네트워크는 M 특징 영역 광학 흐름(들)을 인코딩하고 특징 영역 잔차 맵을 인코딩할 수 있다. 인코딩 네트워크는 신경망에 기초하여 구현된다. 인코딩 네트워크는 3개의 컨볼루션 층과 9개의 잔 차 블록을 포함한다. 도 11의 b에 표시된 디코딩 네트워크는 특징 영역 광학 흐름 비트스트림과 특징 영역 잔 차 비트스트림을 디코딩할 수 있다. 디코딩 네트워크는 신경망에 기초하여 구현된다. 디코딩 네트워크는 3개 의 디컨볼루션 층과 9개의 잔차 블록을 포함한다. 도 11의 a와 b에 표시된 잔차 블록의 구조는 도 11의 c에 표 시되어 있다. 잔차 블록은 두 개의 컨볼루션 층과 하나의 relu 활성화 층에 의해 구현된다. 도 10 및 도 11에 도시된 네트워크는 단지 예일 뿐이며, 본 출원을 제한하기 위한 것이 아니라는 점에 유의해야 한다. 도 10 및 도 11에 도시된 네트워크에서 컨볼루션 커널의 크기, 특징 맵 채널의 수, 업샘플링/다운샘플링 팩터, 업샘플링/다운샘플링 횟수, 컨볼루션 층의 수 및 네트워크 활성화 층은 모두 조정될 수 있다. 물론, 특 징 추출 네트워크, 재구성 네트워크, 인코딩 네트워크 및 디코딩 네트워크는 각각 다른 형태의 네트워크 구조일 수 있다. 본 출원에서의 방식으로 결정된 광학 흐름은 비디오 압축 또는 비디오 코딩 프로세스에서 사용되므로, 비트 레 이트를 절약하고 품질을 보장한다. 다른 실행 가능한 실시예에서, 본 출원의 방법은, M 특징 영역 광학 흐름(들)과 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제2 예측 특징 맵 을 획득하는 단계 - 여기서 M 특징 영역 광학 흐름(들)은 제1 특징 영역 광학 흐름, 제2 특징 영역 광학 흐름, 또는 제3 특징 영역 광학 흐름임 - 와, 현재 프레임의 특징 맵과 제2 예측 특징 맵에 기초하여 특징 융합을 수 행하여 현재 프레임의 향상된 특징 맵을 획득하는 단계와, 향상된 특징 맵에 대해 픽처 재구성을 수행하여 현재 프레임의 재구성된 픽처를 획득하는 단계를 더 포함한다. 본 출원의 방법에서 결정된 광학 흐름을 비디오 인핸스먼트 분야에 적용하는 것을 구체적으로 설명한다. 구체 적으로, 도 12a에 도시된 바와 같이, 현재 프레임과 참조 프레임에 대해 특징 추출을 별도로 수행하여 현재 프 레임과 참조 프레임의 특징(ft) 및 참조 프레임의 특징(ft-1)를 획득한다. 특징 추출 방식에 대해서는 전술한 관 련 설명을 참조한다. 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득하며, 현재 프레임의 특징 맵, 참조 프레임의 특징 맵 및 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 전술한 방식 으로 제1 특징 영역 광학 흐름, 제2 특징 영역 광학 흐름 또는 제3 특징 영역 광학 흐름을 획득할 수 있다. 제 2 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제1 특징 영역 광학 흐름을 사용하여 획득된 정밀도보다 높 다. 제3 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀도 보다 높다. 특징 정렬 처리는 M 특징 영역 광학 흐름과 참조 프레임의 특징 맵(ft-1)에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제2 예측 특징 맵을 획득한다. 특징 정렬 처리는 워핑 또는 DCN 방식으로 수행될 수도 있고, 또는 특징 정렬을 구현할 수 있는 다른 방식으로 수행될 수도 있다. 이는 본 명세서에 한정되지 않는다. 특징 융합은 현재 프레임의 특징 맵과 제2 예측된 특징 맵에 기초하여 수행되어 현재 프레임의 향상된 특징 맵 을 획득한다. 향상된 특징 맵에 대해 픽처 재구성이 수행되어 현재 프레임의 재구성된 픽처를 획득한다. 도 11의 b에 도시된 재구성 네트워크 또는 다른 네트워크는 강화된 특징 맵에 대해 픽처 재구성을 수행할 수 있 다. 예를 들어, 다른 네트워크는 도 11의 b에 도시된 재구성 네트워크에 기초하여 컨볼루션 커널의 크기, 특징 맵 채널의 수, 업샘플링 팩터, 업샘플링 횟수, 컨볼루션 층의 수량 및 네트워크 활성화 층 중 적어도 하나를 조 정하여 얻은 네트워크일 수 있다.본 출원의 방법을 사용하여 수행한 비디오 압축의 이점은 다음 실험을 통해 알아볼 수 있다. 테스트 세트는 제각기 해상도 1080P의 HEVC_B, 해상도 832x480의 HEVC_C, 해상도 416x240의 HEVC_D의 세 가지 유형의 비디오를 사용한다. 각 유형의 비디오는 약 4~5개의 비디오를 포함한다. 프레임 레이트의 범위는 24 fps 내지 60 fps이다. 각 비디오의 처음 100 프레임이 테스트된다. 비교 방법에서, 본 출원에서의 방법을 사용한 경우와 본 출원에서의 방법을 사용하지 않은 경우를 비교한다. 실험 결과는 도 12b에 도시되어 있다. 두 개의 파선이 있다. 어두운 선은 본 출원의 방법이 사용되었음을 나 타낸다. 밝은 선은 본 출원의 방법이 사용되지 않았음을 나타낸다. 도 12b에서 볼 수 있듯이, 이 실험의 결론 은 두 차원, 즉 피크 신호 대 잡음비(peak signal-to-noise ratio, PSNR)와 픽셀당 비트 수(bits per pixel, BPP)에서 설명된다. 픽셀당 비트 수가 동일한 경우, 본 출원의 방법을 사용할 때의 비디오의 피크 신호 대 잡 음비가 본 출원의 방법을 사용하지 않을 때의 비디오의 피크 신호 대 잡음비보다 높은데, 즉 본 출원의 방법을 사용할 때의 비디오의 품질이 본 출원의 방법을 사용하지 않을 때의 비디오의 품질보다 높다. 피크 신호 대 잡 음비가 동일한 경우, 본 출원의 방법을 사용할 때의 비디오의 픽셀당 비트 수가 본 출원의 방법을 사용하지 않 을 때의 비디오의 픽셀당 비트 수보다 적다. 즉, 비디오 압축을 수행하는 경우, 본 출원의 방법을 사용할 때 비트 레이트가 본 출원의 방법을 사용하지 않을 때보다 더 잘 저장된다. 본 실시예에서, 본 출원의 방식으로 결정된 특징 영역 광학 흐름은 비디오 인핸스먼트에 적용되며, 비디오 압축 의 후처리에서 사용될 수 있다. 픽처 영역 광학 흐름에 기초하여 특징 영역 광학 흐름을 모니터링하는 것에 의 해 특징 예측 정확도를 향상시킴으로써, 비디오 향상 효과를 높이고 비디오 품질을 향상시킬 수 있다. 실현 가능한 실시예에서, 참조 프레임의 M개의 특징 맵은 서로 다른 스케일의 참조 프레임의 M개의 특징 맵이며, 이 방법은 현재 프레임의 M개의 예측 특징 맵에 기초하여 M회의 특징 재구성 처리를 수행하여 현재 프레임의 재구성된 픽 처를 획득하는 단계를 더 포함하며, 여기서 처리된 비디오는 현재 프레임의 재구성된 픽처를 포함하고, 현재 프 레임의 M개의 예측 특징 맵은 M 특징 영역 광학 흐름과 참조 프레임의 M개의 특징 맵에 대해 개별적으로 특징 정렬 처리를 수행하여 획득된다. 실현 가능한 실시예에서, 참조 프레임의 M개의 특징 맵과 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐 름에 기초하여 M회의 특징 영역 광학 흐름 추정을 수행하여, M 특징 영역 광학 흐름을 획득하는 단계는, i번째 특징 영역 광학 흐름 추정이 수행되는 경우, 픽처 영역 광학 흐름 특징 맵( )에 기초하여 광학 흐름 추정을 수행하여, 픽처 영역 광학 흐름 특징 맵()을 획득하는 단계 - 여기서 i는 0보다 크고 M보다 크지 않 은 정수이며, i=1인 경우, 픽처 영역 광학 흐름 특징 맵( )은 현재 프레임과 참조 프레임 사이의 픽처 영 역 광학 흐름임 - 와, 참조 프레임의 특징 맵(), 픽처 영역 광학 흐름 특징 맵(), 및 현재 프레임의 예 측 특징 맵( )에 기초하여 적응 처리를 수행하여, 특징 영역 광학 흐름 특징 맵()을 획득하는 단계를 포 함하되, 참조 프레임의 특징 맵()은 참조 프레임의 특징 맵( )에 대해 특징 추출을 수행하여 획득되고, 참조 프레임의 특징 맵( ) 및 참조 프레임의 특징 맵()은 제각기 참조 프레임의 M개의 특징 맵 중 두 특 징 맵이며, i=M인 경우, 현재 프레임의 예측 특징( )은 상수이다. M 특징 영역 광학 흐름은 특징 영역 광학 흐름 특징 맵()을 포함하며, 현재 프레임의 예측 특징( )는 참 조 프레임의 특징 맵( )과 특징 영역 광학 흐름 특징( )에 대해 특징 정렬 처리를 수행하여 획득된다. 구체적으로, 도 13에 도시된 바와 같이, 참조 프레임에 대해 특징 추출을 수행하여 참조 프레임의 특징 맵 ()을 획득하고, 참조 프레임의 특징 맵()에 대해 특징 추출을 수행하여 참조 프레임의 특징 맵()을 획득한다. 이런 방식으로, 복수의 스케일의 참조 프레임의 특징 맵, 즉 참조 프레임의 M개의 특징 맵을 얻을 수 있다. 도 13에 도시된 특징 영역 광학 흐름 추정은 도 14에 도시된 네트워크 구조에 기초하여 구현된다. 첫 번째 특징 영역 광학 흐름 추정이 수행될 때, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 광학 흐름 추정을 수행하여 픽처 영역 광학 흐름 특징 맵()을 획득하고, 참조 프레임의 특징 맵 () 및 픽처 영역 광학 흐름 특징 맵()에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징 맵 ()를 획득한다. 선택적으로, 특징 정렬 처리가 수행되기 전에, 픽처 영역 광학 흐름 특징 맵(), 참조 프레임의 특징 맵(), 및 현재 프레임의 예측 특징 맵()에 기초하여 적응 처리를 수행하여 특징 영역 광 학 흐름 특징 맵()을 획득한다. 그 다음에, 참조 프레임의 특징 맵()과 특징 영역 광학 흐름 특징 맵 ()에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징 맵()을 획득한다. 두 번째 특징 영역 광학 흐름 추정이 수행될 때, 픽처 영역 광학 흐름 특징 맵()에 기초하여 광학 흐름 추 정을 수행하여 픽처 영역 광학 흐름 특징 맵()을 획득하고, 참조 프레임과 픽처 영역 광학 흐름 특징 맵 ()에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징 맵()을 획득한다. 선택적으로, 특징 정 렬 처리가 수행되기 전에, 픽처 영역 광학 흐름 특징 맵(), 참조 프레임의 특징 맵(), 및 현재 프레임 의 예측 특징 맵()에 기초하여 적응 처리를 수행하여 특징 영역 광학 흐름 특징 맵( )을 획득한다. 그 다음에, 참조 프레임의 특징 맵()과 특징 영역 광학 흐름 특징 맵( )에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징 맵()을 획득한다. 세 번째 특징 영역 광학 흐름 추정이 수행될 때, 픽처 영역 광학 흐름 특징 맵()에 기초하여 광학 흐름 추 정을 수행하여 픽처 영역 광학 흐름 특징 맵()을 획득하고, 참조 프레임의 특징 맵( ) 및 픽처 영역 광 학 흐름 특징 맵()에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징 맵()를 획득한다. 선택 적으로, 특징 정렬 처리가 수행되기 전에, 픽처 영역 광학 흐름 특징 맵(), 참조 프레임의 특징 맵(), 및 현재 프레임의 예측 특징 맵()에 기초하여 적응 처리를 수행하여 특징 영역 광학 흐름 특징 맵()을 획득한다. 그 다음에, 참조 프레임의 특징 맵과 특징 영역의 특징 맵( ) 및 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 현재 프레임의 예측 특징 맵()을 획득한다. M번째 특징 영역 광학 흐름 추정이 수행될 때, 픽처 영역 광학 흐름 특징 맵( )에 기초하여 광학 흐름 추 정을 수행하여 픽처 영역 광학 흐름 특징 맵( )을 획득하고, 참조 프레임의 특징 맵() 및 픽처 영역 광 학 흐름 특징 맵( )에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징 맵()을 획득한다. 선 택적으로, 특징 정렬 처리가 수행되기 전에, 픽처 영역 광학 흐름 특징 맵( ), 참조 프레임의 특징 맵 (), 및 현재 프레임의 예측 특징 맵( )에 기초하여 적응 처리를 수행하여, 특징 영역 광학 흐름 특징 맵( )을 획득한다. 그 다음에, 참조 프레임의 특징 맵() 및 특징 영역 광학 흐름 특징 맵( )에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징 맵()을 획득한다. 현재 프레임의 예측 특징 맵 ( )은 상수이거나 존재하지 않는다. 즉, 현재 프레임의 예측 특징 맵( )은 특징 영역 광학 흐름 추정 의 M번째에 사용되지 않는다. 전술한 방법으로, 현재 프레임의 M개의 예측 특징 맵을 얻을 수 있다. 현재 프레임의 M개의 예측 특징 맵을 획 득한 후, 현재 프레임의 예측 특징 맵()에 대해 특징 재구성을 수행하여 현재 프레임의 재구성된 특징 맵()을 획득하고, 현재 프레임의 재구성된 특징 맵()과 현재 프레임의 예측 특징 맵( )에 대해 특징 재 구성을 수행하여 현재 프레임의 재구성된 특징 맵( )을 획득하며, ..., 현재 프레임의 재구성된 특징 맵 ()과 현재 프레임의 예측 특징 맵()에 대해 특징 재구성을 수행하여 현재 프레임의 재구성된 특징 맵 ()을 획득하고, 현재 프레임의 재구성된 특징 맵()과 현재 프레임의 예측 특징 맵()에 대해 특징 재구 성을 수행하여 현재 프레임의 재구성된 픽처를 획득한다. 여기서, 현재 프레임의 예측 특징 맵()이 획득될 때 현재 프레임의 예측 특징 맵( )이 사용된다는 점에 유의해야 한다. 현재 프레임의 예측된 특징 맵( )은 현재 프레임의 예측 특징 맵() 이전에 획득되기 때 문에, 이는 모순되지 않는다. 다음은 전술한 프로세스를 다른 관점에서 설명한다. 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름이 획득되는 경우, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 대해 광학 흐름 추정을 수행하여 픽 처 영역 광학 흐름 특징 맵()을 획득하고, 픽처 영역 광학 흐름 특징 맵()에 기초하여 광학 흐름 추정 을 수행하여 픽처 영역 광학 흐름 특징 맵()을 획득하며, 픽처 영역 광학 흐름 특징 맵()에 기초하여 광학 흐름 추정을 수행하여 픽처 영역 광학 흐름 특징 맵()을 획득하고, ..., 픽처 영역 광학 흐름 특징 맵 ( )에 기초하여 광학 흐름 추정을 수행하여 픽처 영역 광학 흐름 특징 맵( )을 획득하며, 픽처 영 역 광학 흐름 특징 맵( ), 참조 프레임의 특징 맵( ), 및 현재 프레임의 예측 특징 맵( )에 기초하 여 적응 처리를 수행하여 특징 영역 광학 흐름 특징 맵( )을 획득하고, 참조 프레임의 특징 맵( ) 및 특 징 영역 광학 흐름 특징 맵( )에 기초하여 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징 맵()을 획득한다. 현재 프레임의 예측 특징 맵( )은 상수이거나 존재하지 않는다. 픽처 영역 광학 흐름 특징 맵 ( ), 참조 프레임의 특징 맵( ), 및 현재 프레임의 예측 특징 맵()에 기초하여 적응 처리를 수행 하여 특징 영역 광학 흐름 특징 맵( )를 획득하고, 참조 프레임의 특징 맵( ) 및 특징 영역 광학 흐 름 특징 맵( )에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징 맵( )을 획득하며, ..., 픽처 영역 광학 흐름 특징 맵(), 참조 프레임의 특징 맵(), 및 현재 프레임의 예측 특징 맵()에 기 초하여 적응 처리를 수행하여 특징 영역 광학 흐름 특징 맵()을 획득하고, 참조 프레임의 특징 맵() 및 특징 영역 광학 흐름 특징 맵()에 대해 특징 정렬 처리를 수행하여 현재 프레임의 예측 특징 맵()을 획득 한다. 현재 프레임의 예측 특징 맵( )은 현재 프레임의 예측 특징 맵을 획득하는 데 사용된다. 이것은 모 순되지 않는다. 일례로, 도 15에 도시된 어댑티브 네트워크는 참조 프레임의 특징 맵( ), 픽처 영역 광학 흐름 특징 맵 (), 및 현재 프레임의 예측 특징 맵( )에 기초하여 적응 처리를 수행하여 특징 영역 광학 흐름 특징 맵 ()을 획득하는 특정 구현 프로세스를 구현할 수 있다. 도 15에 도시된 바와 같이, 어댑티브 네트워크는 하 나의 디컨볼루션 층, 두 개의 컨볼루션 층 및 하나의 relu 활성화 층을 포함한다. 도 15에 표시된 어댑티브 네 트워크는 단지 예시일 뿐이며 본 출원을 제한하기 위한 것이 아니라는 점에 유의해야 한다. 특징 추출, 광학 흐름 추정, 특징 정렬 및 특징 재구성의 구체적인 구현 프로세스에 대해서는 전술한 실시예의 관련 설명을 참조할 수 있다는 점에 유의해야 한다. 자세한 내용은 여기서 다시 설명하지 않는다.본 실시예에서, 참조 프레임의 M개의 특징 맵은 참조 프레임을 더 포함할 수 있고, 이 참조 프레임은 가장 큰 스케일의 참조 프레임의 특징 맵이며, 참조 프레임은 참조 프레임에 대해 특수 특징 추출을 한 번 수행하여 얻 은 것으로 간주될 수 있음을 이해해야 한다. 전술한 실시예에서, 참조 프레임의 M개의 특징 맵이 참조 프레임 을 포함하는 경우, 타겟 특징 맵은 참조 프레임의 M개의 특징 맵에서 가장 큰 스케일의 특징 맵, 즉 참조 프레 임일 수 있다. 참조 프레임의 M개의 특징 맵이 참조 프레임을 포함하지 않고, M=1인 경우, 타겟 특징 맵은 참 조 프레임에 대해 특징 추출을 한 번 수행하여 얻은 특징 맵이다. 도 16은 본 출원의 실시예에 따른 단말 디바이스의 구조를 도시한 도면이다. 도 16에 도시된 바와 같이, 단말 디바이스는 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름을 획득하도록 구성된 획득 유닛 - 여기서, 현재 프레임과 참조 프레임은 비디오 내의 두 프레임임 - 과, 참조 프레임에 대해 다중 스케일 특징 추출을 수행하여 참조 프레임의 M개의 특징 맵(들)을 획득하도록 구성된 특징 추출 유닛 - 여기서, M은 1보다 크거나 동일한 정수임 - 과, 참조 프레임의 M개의 특징 맵(들) 및 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름에 기초하여 특징 영역 광학 흐름 추정을 M회 수행하여 M개의 특징 영역 광학 흐름을 획득하도록 구성된 광학 흐름 추정 유닛 을 포함한다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 광학 흐름 추정 유닛은 구체적으로, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 제1 특 징 영역 광학 흐름에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득하도록 구성되되, 여기서 제2 특징 영역 광학 흐름을 사용하여 획득된 정밀도는 제1 특징 영역 광학 흐름을 사용하여 획득된 정밀도보다 더 높고, M 특징 영역 광학 흐름은 제2 특징 영역 광학 흐름이다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 광학 흐름 추정 유닛은 구체적으로, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 현재 프레임의 특징 맵, 타겟 특징 맵 및 제1 특징 영역 광학 흐름에 기초하여 적어도 1회 반복 처리를 수행하 여, 제3 특징 영역 광학 흐름을 획득하며 - 여기서, M 특징 영역 광학 흐름은 제3 특징 영역 광학 흐름임 -, j번째 반복 처리가 수행되는 경우, 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하 여, 현재 프레임의 예측 특징 맵()을 획득하고 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 특징 영역 광 학 흐름()은 제1 특징 영역 광학 흐름임 -, 타겟 특징 맵, 현재 프레임의 특징 맵, 및 현재 프레임의 예측 특징 맵()에 기초하여 미세 조정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하며, 미세 조정된 특징 영역 광학 흐름( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름( )을 획 득하고 - 여기서 j=1인 경우, 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 -, 특징 영역 광학 흐 름( )에 기초하여 특징 영역 광학 흐름( )을 결정하도록 구성된다. 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획득되면, 특징 영역 광학 흐름( )은 제3 특징 영역 광학 흐름이다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, M=1인 경우, 참조 프레임의 M개의 특징 맵은 타겟 특징 맵이고, 광학 흐름 추정 유닛은 구체적으로, 현재 프레임과 참조 프레임 사이의 픽처 영역 광학 흐름 및 타겟 특징 맵에 기초하여 특징 영역 광학 흐름 추정 을 수행하여, 제1 특징 영역 광학 흐름을 획득하고, 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 제1 특 징 영역 광학 흐름에 대해 적응 처리를 수행하여 제2 특징 영역 광학 흐름을 획득하며, 현재 프레임의 특징 맵, 타겟 특징 맵 및 제2 특징 영역 광학 흐름에 기초하여 적어도 1회의 반복 처리를 수행 하여, 제3 특징 영역 광학 흐름을 획득하고 - 여기서, M 특징 영역 광학 흐름은 제3 특징 영역 광학 흐름임 -, j번째 반복 처리가 수행되는 경우, 타겟 특징 맵과 특징 영역 광학 흐름()에 대해 특징 정렬 처리를 수행하여, 현재 프레임의 예측 특징 맵 ()을 획득하며 - 여기서, j는 0보다 큰 정수이고, j=1인 경우, 특징 영역 광학 흐름()은 제2 특징 영역 광학 흐름임 -, 타겟 특징 맵, 현재 프레임의 특징 맵, 및 현재 프레임의 예측 특징 맵()에 기초하여 미세 조 정 처리를 수행하여, 미세 조정된 특징 영역 광학 흐름( )을 획득하며, 미세 조정된 특징 영역 광학 흐름 ( )과 특징 영역 광학 흐름( )을 융합하여 특징 영역 광학 흐름( )을 획득하고 - 여기서 j=1인 경우, 특징 영역 광학 흐름( )은 제1 특징 영역 광학 흐름임 -, 특징 영역 광학 흐름( )에 기초하여 특 징 영역 광학 흐름( )을 결정하도록 구성된다. 특징 영역 광학 흐름( )이 최종 반복 처리를 통해 획 득되면, 특징 영역 광학 흐름( )은 제3 특징 영역 광학 흐름이다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, 특징 영역 광학 흐름( )에 기초하여 특징 영역 광학 흐름( )을 결정하는 경우, 광학 흐름 추정 유닛은 또한, 특징 영역 광학 흐름( )을 특징 영역 광학 흐름( )으로 결정하거나, 또는 현재 프레임의 특징 맵과 타겟 특징 맵에 기초하여 특징 영역 광학 흐름( )에 대해 적응 처리를 수행하여 특 징 영역 광학 흐름( )을 획득하도록 구성되며, 특징 영역 광학 흐름( )을 사용하여 획득된 정밀도는 특징 영역 광학 흐름()을 사용하여 획득된 정밀도보다 높다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, 단말 디바이스는, M 특징 영역 광학 흐름에 대해 코딩 처리를 수행하여 제4 특징 영역 광학 흐름을 획득하고, 제4 특징 영역 광학 흐름과 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제1 예측 특징 맵을 획득하며, 현재 프 레임의 특징 맵과 제1 예측 특징 맵에 기초하여 특징 영역 잔차 맵을 획득하고, 특징 영역 잔차 맵을 인코딩하 여 특징 영역 잔차 비트스트림을 획득하도록 구성된 후처리 유닛을 더 포함한다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, 단말 디바이스는, M 특징 영역 광학 흐름과 타겟 특징 맵에 대해 특징 정렬 처리를 수행하여 현재 프레임의 제2 예측 특징 맵을 획득하고 - 여기서 제4 특징 영역 광학 흐름은 제1 특징 영역 광학 흐름, 제2 특징 영역 광학 흐름, 또는 제3 특징 영역 광학 흐름임 -, 현재 프레임의 특징 맵과 제2 예측 특징 맵에 기초하여 특징 융합을 수행하여 현재 프레임의 향상된 특징 맵을 획득하며, 향상된 특징 맵에 대해 픽처 재구성을 수행하여 현재 프레임의 재구성된 픽처를 획득하도록 구성된 후처리 유닛을 더 포함한다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, M이 1보다 큰 경우, 참조 프레임의 M개의 특징 맵은 서 로 다른 스케일의 참조 프레임의 M개의 특징 맵이며, 단말 디바이스는, 현재 프레임의 M개의 예측 특징 맵에 기초하여 M회의 특징 재구성 처리를 수행하여 현재 프레임의 재구성된 픽 처를 획득하도록 구성된 후처리 유닛을 더 포함하며, 여기서 처리된 비디오는 현재 프레임의 재구성된 픽처를 포함하고, 현재 프레임의 M개의 예측 특징 맵은 M 특징 영역 광학 흐름 및 서로 다른 스케일의 참조 프레 임의 M개의 특징 맵에 대해 개별적으로 특징 정렬 처리를 수행하여 획득된다. 제1 양태의 방법과 관련하여, 실현 가능한 실시예에서, 광학 흐름 추정 유닛은 구체적으로, i번째 특징 영역 광학 흐름 추정이 수행되는 경우, 픽처 영역 광학 흐름 특징 맵( )에 기초하여 광학 흐름 추정을 수행하여, 픽처 영역 광학 흐름 특징 맵()을 획득하고 - 여기서 i는 0보다 크고 M보다 크지 않은 정 수이며, i=1인 경우, 픽처 영역 광학 흐름 특징 맵( )은 현재 프레임과 참조 프레임 사이의 픽처 영역 광 학 흐름임 -, 참조 프레임의 특징 맵(), 픽처 영역 광학 흐름 특징 맵(), 및 현재 프레임의 예측 특징 맵( )에 기초하여 적응 처리를 수행하여, 특징 영역 광학 흐름 특징 맵()을 획득하도록 구성되되, 참조 프레임의 특징 맵()은 참조 프레임의 특징 맵( )에 대해 특징 추출을 수행하여 획득되고, 참조 프레임의 특징 맵( ) 및 참조 프레임의 특징 맵()은 제각기 참조 프레임의 M개의 특징 맵 중 두 특징 맵이며, i=M인 경우, 현재 프레임의 예측 특징( )은 상수이고, M 특징 영역 광학 흐름은 특징 영역 광학 흐름 특징 맵()을 포함하며, 현재 프레임의 예측 특징( )는 참조 프레임의 특징 맵( )과 특징 영역 광학 흐름 특징( )에 대해 특징 정렬 처리를 수행하여 획득된다. 전술한 유닛들(획득 유닛, 특징 추출 유닛, 광학 흐름 추정 유닛 및 후처리 유닛)은 전술한 방법의 관련 단계를 수행하도록 구성된다는 점에 유의해야 한다. 따라서, 유닛들에 의해 달성될 수 있 는 유익한 효과에 대해서는 상술한 해당 방법의 유익한 효과를 참조한다. 자세한 내용은 여기서 다시 설명하지 않는다. 예를 들어, 획득 유닛은 S601의 관련 내용을 수행하도록 구성되고, 특징 추출 유닛은 S602의 관련 내용을 수행하도록 구성되며, 광학 흐름 추정 유닛 및 후처리 유닛은 S603의 관련 내 용을 수행하도록 구성된다. 당업자는 본 명세서에 개시되고 설명된 다양한 예시적인 논리 블록, 모듈 및 알고리즘 단계를 참조하여 설명된 기능들이 하드웨어, 소프트웨어, 펌웨어 또는 이들의 임의의 조합에 의해 구현될 수 있음을 이해할 수 있을 것 이다. 소프트웨어가 구현에 사용되는 경우, 예시적인 논리 블록, 모듈 및 단계를 참조하여 설명된 기능은 하나 이상의 명령어 또는 코드로서 컴퓨터 판독 가능 매체에 저장되거나 컴퓨터 판독 가능 매체를 통해 전송되어 하 드웨어 기반 처리 유닛에 의해 실행될 수 있다. 컴퓨터 판독 가능 매체는 데이터 저장 매체와 같은 유형의 매 체에 대응하는 컴퓨터 판독 가능 저장 매체 또는 컴퓨터 프로그램을 한 장소에서 다른 장소로 전송하는 것을 용 이하게 하는 통신 매체(예컨대, 통신 프로토콜에 따라)를 포함할 수 있다. 이런 방식으로, 컴퓨터 판독 가능 매체는 일반적으로, 비일시적인 유형의 컴퓨터 판독 가능 저장 매체 또는 통신 매체(예컨대, 신호 또는 캐리어)에 대응할 수 있다. 데이터 저장 매체는 본 출원에서 설명된 기술을 구현하기 위한 명령어, 코드 및/또 는 데이터 구조를 검색하기 위해 하나 이상의 컴퓨터 또는 하나 이상의 프로세서에 의해 액세스될 수 있는 모든 사용 가능한 매체일 수 있다. 컴퓨터 프로그램 제품은 컴퓨터 판독 가능 매체를 포함할 수 있다. 제한이 아닌 예로서, 이러한 컴퓨터 판독 가능 저장 매체는 RAM, ROM, EEPROM, CD-ROM 또는 다른 컴팩트 디스크 저장 디바이스, 자기 디스크 저장 디바이스 또는 다른 자기 저장 장치, 플래시 메모리 또는 필요한 프로그램 코 드를 명령어 또는 데이터 구조의 형태로 저장할 수 있고 컴퓨터에 의해 액세스될 수 있는 기타 매체를 포함할 수 있다. 또한, 모든 연결은 컴퓨터 판독가능 매체로 적절히 지칭된다. 예를 들어 웹사이트, 서버 또는 다른 원격 소스로부터 동축 케이블, 광섬유, 연선, 디지털 가입자 회선(digital subscriber line, DSL) 또는 적외선, 라디오, 마이크로파 등의 무선 기술을 통해 명령어가 전송되는 경우, 동축 케이블, 광섬유, 연선, DSL 또는 적 외선, 라디오, 마이크로파 등의 무선 기술이 매체의 정의에 포함된다. 그러나, 컴퓨터 판독 가능 저장 매체 및 데이터 저장 매체는 연결, 캐리어, 신호 또는 기타 일시적인 매체를 포함하지 않으며, 실제로는 일시적이지 않 은 유형의 저장 매체를 의미한다는 점을 이해해야 한다. 본 명세서에서 사용되는 디스크는 컴팩트 디스크 (compact disc, CD), 레이저 디스크, 광 디스크, 디지털 다목적 디스크(digital versatile disc, DVD) 및 블루 레이 디스크를 포함한다. 디스크는 일반적으로 자기적으로 데이터를 재생하는 반면, 광디스크는 레이저를 통해 광학적으로 데이터를 재생한다. 앞서 언급한 항목들의 조합도 컴퓨터 판독 가능 매체의 범위에 포함되어야 한다. 명령어는 하나 이상의 디지털 신호 처리기(DSP), 범용 마이크로프로세서, 애플리케이션 특정 집적 회로(ASIC), 필드 프로그래머블 게이트 어레이(FPGA) 또는 기타 동등한 집적 또는 개별 논리 회로와 같은 하나 이상의 프로 세서에 의해 실행될 수 있다. 따라서, 본 명세서에서 사용되는 \"프로세서\"라는 용어는 전술한 구조 또는 본 명 세서에 설명된 기술의 구현에 적합한 다른 구조를 나타낼 수 있다. 또한, 일부 양태에서, 본 명세서에 설명된 예시적인 논리 블록, 모듈 및 단계를 참조하여 설명된 기능은 인코딩 및 디코딩을 위해 구성된 전용 하드웨어 및/또는 소프트웨어 모듈 내에서 제공되거나, 또는 결합된 코덱에 통합될 수 있다. 또한, 이들 기술은 모두 하 나 이상의 회로 또는 논리 소자로 구현될 수 있다. 본 출원의 기술은 무선 핸드셋, 집적 회로(integrated circuit, IC) 또는 IC 세트(예컨대, 칩 세트)를 포함한 다양한 장치 또는 디바이스에서 구현될 수 있다. 본 출원에서는 개시된 기술을 수행하도록 구성된 장치의 기능 적 양태를 강조하기 위해 다양한 구성요소, 모듈 또는 유닛이 설명되지만, 반드시 상이한 하드웨어 유닛들로 구 현될 필요는 없다. 실제로, 전술한 바와 같이, 다양한 유닛은 적절한 소프트웨어 및/또는 펌웨어와 함께 코덱 하드웨어 유닛으로 결합되거나, 또는 상호 운용 가능한 하드웨어 유닛(전술한 하나 이상의 프로세서를 포함)에 의해 제공될 수 있다. 전술한 설명은 본 출원의 구체적인 구현의 예일 뿐이며, 본 출원의 보호 범위를 제한하려는 의도는 없다. 본 출원에 개시된 기술 범위 내에서 당업자가 쉽게 파악할 수 있는 모든 변형 또는 대체물은 본 출원의 보호 범위 에 속한다. 따라서 본 출원의 보호 범위는 청구항의 보호 범위에 따른다."}
{"patent_id": "10-2024-7031306", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 출원의 실시예 또는 종래 기술에서의 기술 솔루션을 보다 명확하게 설명하기 위해, 이하에서는 실시예 또는 종래 기술을 설명하는 데 사용된 첨부 도면을 간략하게 설명한다. 이하의 설명에서 첨부 도면들은 본 출원의 일부 실시예를 보여주고 있으며, 당업자는 창의적인 노력 없이도 이들 첨부 도면으로부터 다른 도면을 도출할 수 있음은 명백하다. 도 1은 본 출원의 실시예를 구현하기 위한 비디오 코딩 시스템의 일례의 블록도이다. 도 2는 본 출원의 실시예를 구현하기 위한 비디오 코딩 시스템의 또 다른 예의 블록도이다. 도 3은 본 출원의 실시예를 구현하기 위한 비디오 코딩 장치의 블록도이다. 도 4는 본 출원의 실시예를 구현하기 위한 비디오 코딩 장치의 블록도이다. 도 5a는 본 출원의 실시예에 따른 비디오 코딩 아키텍처의 도면이다. 도 5b는 본 출원의 실시예에 따른 비디오 저장 애플리케이션 아키텍처의 도면이다. 도 5c는 본 출원의 실시예에 따른 라이브 스트리밍 아키텍처의 도면이다. 도 5d는 본 출원의 실시예에 따른 비디오 인핸스먼트 아키텍처의 도면이다. 도 6은 본 출원의 실시예에 따른 특징 영역 광학 흐름 결정 방법의 개략적인 흐름도이다. 도 7은 본 출원의 실시예에 따른 광학 흐름 추정 네트워크의 아키텍처를 나타낸 도면이다. 도 8은 본 출원의 실시예에 따른 특징 영역 광학 흐름 추정 아키텍처의 도면이다. 도 9는 본 출원의 실시예에 따른 비디오 압축 프로세스의 도면이다. 도 10은 본 출원의 실시예에 따른 특징 추출 네트워크, 특징 재구성 및 잔차 블록의 아키텍처를 도시한 도면이 다. 도 11은 본 출원의 실시예에 따른 인코딩 네트워크, 디코딩 네트워크 및 잔차 블록의 아키텍처를 도시한 도면이 다.도 12a는 본 출원의 실시예에 따른 비디오 인핸스먼트 프로세스의 도면이다. 도 12b는 본 출원의 실시예에 따른 비디오 인핸스먼트 효과를 나타낸 도면이다. 도 13은 본 출원의 실시예에 따른 다중 스케일 특징 영역 광학 흐름 결정 프로세스의 도면이다. 도 14는 본 출원의 실시예에 따른 특징 영역 광학 흐름 추정 프로세스의 도면이다. 도 15는 본 출원의 실시예에 따른 어댑티브 네트워크의 구조를 도시한 도면이다. 도 16은 본 출원의 실시예에 따른 단말 디바이스의 구조를 도시한 도면이다."}
