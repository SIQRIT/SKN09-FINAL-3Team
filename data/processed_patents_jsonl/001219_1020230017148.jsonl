{"patent_id": "10-2023-0017148", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0124533", "출원번호": "10-2023-0017148", "발명의 명칭": "영상 내 특징점 검출을 위한 인공지능 모델의 학습 장치 및 그 방법", "출원인": "프로메디우스 주식회사", "발명자": "이가은"}}
{"patent_id": "10-2023-0017148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 내 포함된 복수의 특징점을 검출하기 위한 인공지능 모델의 인공지능 모델 학습 장치에 있어서,영상을 입력 받도록 이루어지는 통신부; 인공지능 모델 관련 정보를 저장하는 저장부; 및상기 통신부 및 상기 저장부를 제어하도록 이루어지는 프로세서를 포함하고,상기 프로세서는,상기 입력된 영상에 포함된 N개의 특징점들에 대한 N깊이의 히트맵을 생성하도록 이루어지는 히트맵 생성 모듈;상기 특징점들 각각에 대한 히트맵이 서로 겹치는 영역을 제거하도록 이루어지는 히트맵 분리 모듈; 및상기 서로 겹치는 영역이 제거된 히트맵을 기반으로, 상기 인공지능 모델을 학습하도록 이루어지는 인공지능 모듈을 포함하는 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0017148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 히트맵 분리 모듈은,상기 N깊이의 히트맵에 포함된 상기 특징점들 각각에 대한 히트맵을 서로 중첩시키고, 중첩된 히트맵에서 서로 겹치는 영역이 존재하는지 판단하고, 상기 중첩된 영역이 존재하는 경우, 상기 중첩된 영역을 제거하는 것을 특징으로 하는 인공지능 모델 학습장치."}
{"patent_id": "10-2023-0017148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 특징점들은 히트맵에 서로 겹치는 영역이 존재하는 제1특징점 및 제2특징점을 포함하고,상기 히트맵 분리 모듈은,상기 제1특징점에 대응되는 히트맵에서 상기 제2특징점에 대응되는 히트맵과 겹치는 영역을 제거하고,상기 제2특징점에 대응되는 히트맵에서 상기 제1특징점에 대응되는 히트맵과 겹치는 영역을 제거하는 것을 특징으로 하는 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0017148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 인공지능 모듈은,상기 입력 영상을 입력값으로하여, 상기 서로 겹치는 영역이 제거된 히트맵을 출력하도록, 상기 인공지능 모델을 학습하는 것을 특징으로 하는 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0017148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 인공지능 모델은 L1 손실함수 및 Dice coefficient 손실함수 각각을 포함하는 것을 특징으로 하는 인공지능 모델 학습 장치.공개특허 10-2024-0124533-3-청구항 6 통신부 및 프로세서를 포함하는 인공지능 모델 학습 장치를 활용한, 영상 내 포함된 복수의 특징점을 검출하기위한 인공지능 모델의 학습 방법에 있어서,상기 통신부가 복수의 특징점을 포함하는 영상을 입력 받는 단계; 상기 프로세서가 상기 입력된 영상에 포함된 N개의 특징점들에 대한 N깊이의 히트맵을 생성하는 단계;상기 프로세서가 상기 특징점들 각각에 대한 히트맵이 서로 겹치는 영역을 제거하는 단계; 및상기 프로세서가 상기 서로 겹치는 영역이 제거된 히트맵을 기반으로, 상기 인공지능 모델을 학습하는 단계를포함하는 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0017148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서가 상기 특징점들 각각에 대한 히트맵이 서로 겹치는 영역을 제거하는 단계는,상기 프로세서가 상기 N깊이의 히트맵에 포함된 상기 특징점들 각각에 대한 히트맵을 서로 중첩시키는 단계; 상기 프로세서가 상기 중첩된 히트맵에서 서로 겹치는 영역이 존재하는지 판단하는 단계; 및 상기 중첩된 영역이 존재하는 경우, 상기 프로세서가 상기 중첩된 영역을 제거하는 단계를 포함하는 것을 특징으로 하는 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0017148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 특징점들은 히트맵에 서로 겹치는 영역이 존재하는 제1특징점 및 제2특징점을 포함하고,상기 프로세서가 상기 특징점들 각각에 대한 히트맵이 서로 겹치는 영역을 제거하는 단계는,상기 제1특징점에 대응되는 히트맵에서 상기 제2특징점에 대응되는 히트맵과 겹치는 영역을 제거하고, 상기 제2특징점에 대응되는 히트맵에서 상기 제1특징점에 대응되는 히트맵과 겹치는 영역을 제거하는 것임을 특징으로하는 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0017148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 인공지능 모델은 상기 입력 영상을 입력값으로 하여, 상기 서로 겹치는 영역이 제거된 히트맵을 출력하도록 학습되는 것을 특징으로 하는 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0017148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터와 결합되어, 제6항 내지 제9항 중 어느 한 항의 질병 예측 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 프로그램."}
{"patent_id": "10-2023-0017148", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 영상에서 복수의 특징점 검출을 위한 인공지능 모델의 인공지능 모델 학습 장치 및 그 방법에 관한 것 이다. 본 개시에 일 측면에 따른 장치는, 영상을 입력 받도록 이루어지는 통신부, 인공지능 모델 관련 정보를 저 장하는 저장부 및 상기 통신부 및 상기 저장부를 제어하도록 이루어지는 프로세서를 포함하고, 상기 프로세서는 상기 입력된 영상에 포함된 N개의 특징점들에 대한 N깊이의 히트맵을 생성하도록 이루어지는 히트맵 생성 모듈, 상기 특징점들 각각에 대한 히트맵이 서로 겹치는 영역을 제거하도록 이루어지는 히트맵 분리 모듈 및 상기 서로 겹치는 영역이 제거된 히트맵을 기반으로, 상기 인공지능 모델을 학습하도록 이루어지는 인공지능 모듈을 포함하 는 인공지능 모델 학습 장치를 제공할 수 있다."}
{"patent_id": "10-2023-0017148", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 영상에서 복수의 특징점 검출을 위한 인공지능 모델의 학습 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0017148", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "합성곱 신경망으로 영상의 한 점을 검출하기위해 보통 크게 3가지 방법을 사용한다. 첫 번째는 학습네트워크가 직접적으로 점을 검출하는 방법으로 가장 직관적이다. 그러나 점의 좌표를 바로 출력 하도록 학습되기 때문에 지도학습을 위한 데이터 구축시 생기는 휴먼에러를 고스란히 안고 가야하는 위험이 있 으며, 찾아야 하는 점(화소 하나)에비해 큰 입력정보(영상 크기)로 인해 세밀하게 점을 찾기 어렵고 좌표를 직접 반영함으로써 안정적인 수렴으로의 학습이 어렵다. 두 번째는 하나의 화소에 국한된 점을 팽창시켜 객체분할 영역으로 해석하는 방법으로 첫번째 방법보다 휴먼에 러의 반영이 덜되는 편이다. 그러나 얼마나 팽창시켜야 하는지는 데이터마다 달라 추가실험이 필요하고 정교함 이 떨어진다. 세번째 방법은 하나의 화소에 국한된 점을 팽창시키되 점과 가까워질수록 큰 가중치의 값을 가지도록 하는 방법 이다. 첫번째 방법보다 휴먼에러에도 대비가 되고 두번째 방법보다 정교함도 높일 수 있는 방법이다. 대한민국 특허등록공고 제10-1461343호는 치아 랜드마크의 좌표를 입력으로 가우시안 분포를 따른 3D 히트맵으로 변환하 는 것이 개시되어 있으나, 복수의 특징점을 검출하는데 효과적인 방법을 제시하지 못하고 있다. 이에, 영상 내 복수의 특징점을 검출할 수 있는 인공지능 모델의 학습 방법에 대한 니즈가 여전히 존재한다."}
{"patent_id": "10-2023-0017148", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에 개시된 실시예는 영상 내 복수의 특징점 검출할 수 있는 인공지능 모델의 학습에 활용되는 학습데이 터의 휴먼에러를 최소화할 수 있는 인공지능 모델의 학습 장치 및 방법을 제공하는데 그 목적이 있다. 본 개시가 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0017148", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 개시에 일 측면에 따른 장치는, 영상을 입력 받도록 이루어지는 통신부, 인공지능 모델 관련 정보를 저장하는 저장부 및 상기 통신부 및 상기 저장부를 제어하도록 이루어지는 프로세서를 포함하고, 상기 프로세서는 상기 입력된 영상에 포함된 N개의 특징점들에 대한 N깊이의 히트맵을 생 성하도록 이루어지는 히트맵 생성 모듈, 상기 특징점들 각각에 대한 히트맵이 서로 겹치는 영역을 제거하도록 이루어지는 히트맵 분리 모듈 및 상기 서로 겹치는 영역이 제거된 히트맵을 기반으로, 상기 인공지능 모델을 학 습하도록 이루어지는 인공지능 모듈을 포함하는 인공지능 모델 학습 장치를 제공할 수 있다. 또한, 본 개시에 일 측면에 따른 방법은 통신부 및 프로세서를 포함하는 인공지능 모델 학습 장치를 활용한, 영 상 내 포함된 복수의 특징점을 검출하기 위한 인공지능 모델의 학습 방법을 제공할 수 있다. 상기 방법은 상기 통신부가 복수의 특징점을 포함하는 영상을 입력 받는 단계, 상기 프로세서가 상기 입력된 영상에 포함된 N개의 특징점들에 대한 N깊이의 히트맵을 생성하는 단계, 상기 프로세서가 상기 특징점들 각각에 대한 히트맵이 서로 겹치는 영역을 제거하는 단계 및 상기 프로세서가 상기 서로 겹치는 영역이 제거된 히트맵을 기반으로, 상기 인 공지능 모델을 학습하는 단계를 포함할 수 있다. 이 외에도, 본 개시를 구현하기 위한 실행하기 위한 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램이 더 제공될 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기 록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2023-0017148", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 전술한 과제 해결 수단에 의하면, 영상에 포함된 특징점을 직접적으로 학습하지 않고, 점의 좌표를 중심으로 가우시안 형태의 가중치를 적용하여 학습함으로써 지도학습을 위한 데이터 구축에서 발생되는 휴먼에 러를 예방하고 정답을 찾아가는 학습과정에 안정성을 높여줄 수 있다. 나아가, 본 개시에 따르면, 입력 영상에 대한 히트맵 생성 후 겹치는 영역을 제거함으로써, 다수의 특징점을 포 함하는 영상에 대한 학습 혼란을 최소화할 수 있다. 본 개시의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0017148", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2023-0017148", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 '부, 모듈, 부재, 블록'이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블 록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '본 개시에 따른 시스템'은 연산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치 들이 모두 포함된다. 예를 들어, 본 개시에 따른 장치는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거 나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 이하에서는, 본 개시에 따른 인공지능 모델 학습 장치에 대하여 설명한다. 본 개시에 따른 인공지능 모델 학습 장치는 서버 및 단말기 중 적어도 하나에 의해 구현될 수 있다. 구체적으로, 본 개시에 따른 인공지능 모델 학습 장치는 서버 및 단말기 중 어느 하나에 의해 구현되거나, 서버 및 단말기 간의 데이터 송수신을 통해 시스템으로 구현될 수 있다. 이하에서는, 본 개시에 따른 인공지능 모델 학습 장치를 구현하기 위한 서버 및 단말기 각각에 대하여 설명한다. 도 1은 본 개시의 인공지능 모델 학습 장치에 포함된 서버의 블록도이다. 본 개시에 따른 서버는 통신부, 저장부 및 프로세서 중 적어도 하나를 포함할 수 있다. 통신부는 단말기, 외부 저장소(예를 들어, 데이터베이스(database, 140)), 외부 서버 및 클라우드 서버 중 적어도 하나와 통신을 수행할 수 있다. 한편, 외부 서버 또는 클라우드 서버에서는, 프로세서의 적어도 일부의 역할을 수행하도록 구성될 수 있다. 즉, 데이터 처리 또는 데이터 연산 등의 수행은 외부 서버 또는 클라우드 서버에서 이루어지는 것이 가능 하며, 본 발명에서는 이러한 방식에 대한 특별한 제한을 두지 않는다. 한편, 통신부는 통신하는 대상(예를 들어, 전자기기, 외부 서버, 디바이스 등)의 통신 규격에 따라 다양한 통신 방식을 지원할 수 있다. 예를 들어, 통신부는, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G(5th Generation Mobile Telecommunication ), 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra-Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 통신 대상과 통신하도록 이루 어질 수 있다. 다음으로 저장부는, 본 발명과 관련된 다양한 정보를 저장하도록 이루어질 수 있다. 본 발명에서 저장부 는 본 발명에 따른 장치 자체에 구비될 수 있다. 이와 다르게, 저장부의 적어도 일부는, 데이터베이 스(database: DB, 140) 클라우드 저장소(또는 클라우드 서버) 중 적어도 하나를 의미할 수 있다. 즉, 저장부 는 본 발명에 따른 장치 및 방법을 위하여 필요한 정보가 저장되는 공간이면 충분하며, 물리적인 공간에 대한 제약은 없는 것으로 이해될 수 있다. 이에, 이하에서는, 저장부, 데이터베이스, 외부 저장소, 클라우드 저장소(또는 클라우드 서버)를 별도로 구분하지 않고, 모두 저장부라고 표현하도록 한다. 다음으로, 프로세서는 본 발명과 관련된 장치의 전반적인 동작을 제어하도록 이루어질 수 있다. 프로세서 는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거나 사용자에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 프로세서는 적어도 하나의 CPU(Central Processing Unit, 중앙처리장치)를 포함하여, 본 발명에 따른 기능 을 수행할 수 있다. 한편, 서버는 학습 데이터를 이용하여 인공지능 모델을 학습시킬 수 있다. 인공지능 모델은 서버 내 저장될 수 있다. 다만, 이에 한정되지 않고, 상기 인공지능 모델은 별도의 서버 또는 클라우드에 저장되고, 서 버는 상기 서버 또는 클라우드에 접속하여 상기 인공지능 모델을 활용할 수 있다. 상기 인공지능 모델에 대하여는 후술한다. 도 1에 도시된 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구 성 요소들의 상호 위치는 장치의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통상의 지식을 가진 자에게 용이하게 이해될 것이다. 이하, 본 개시의 인공지능 모델 학습 장치에 포함된 단말기에 대하여 구체적으로 설명한다. 도 2는 본 개시의 인공지능 모델 학습 장치에 포함된 단말기의 블록도이다. 도 2를 참고하면, 본 개시에 따른 단말기는 통신부, 입력부, 표시부 및 프로세서 등 을 포함할 수 있다. 도 3에 도시된 구성요소들은 본 개시에 따른 인공지능 모델 학습 장치를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 단말기는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 상기 구성요소들 중 통신부는 외부 장치와 통신을 가능하게 하는 하나 이상의 구성 요소를 포함할 수 있으 며, 예를 들어, 방송 수신 모듈, 유선통신 모듈, 무선통신 모듈, 근거리 통신 모듈, 위치정보 모듈 중 적어도 하나를 포함할 수 있다. 유선 통신 모듈은, 지역 통신(Local Area Network; LAN) 모듈, 광역 통신(Wide Area Network; WAN) 모듈 또는 부가가치 통신(Value Added Network; VAN) 모듈 등 다양한 유선 통신 모듈뿐만 아니라, USB(Universal Serial Bus), HDMI(High Definition Multimedia Interface), DVI(Digital Visual Interface), RS-1302(recommended standard1302), 전력선 통신, 또는 POTS(plain old telephone service) 등 다양한 케이블 통신 모듈을 포함할 수 있다. 무선 통신 모듈은 와이파이(Wifi) 모듈, 와이브로(Wireless broadband) 모듈 외에도, GSM(global System for Mobile Communication), CDMA(Code Division Multiple Access), WCDMA(Wideband Code Division Multiple Access), UMTS(universal mobile telecommunications system), TDMA(Time Division Multiple Access), LTE(Long Term Evolution), 4G, 5G, 6G 등 다양한 무선 통신 방식을 지원하는 무선 통신 모듈을 포함할 수 있 다. 입력부는 영상 정보(또는 신호), 오디오 정보(또는 신호), 데이터, 또는 사용자로부터 입력되는 정보의 입 력을 위한 것으로서, 적어도 하나의 카메라, 적어도 하나의 마이크로폰 및 사용자 입력부 중 적어도 하나를 포 함할 수 있다. 입력부에서 수집한 음성 데이터나 이미지 데이터는 분석되어 사용자의 제어명령으로 처리될 수 있다. 표시부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 디스플레이부, 음향 출력부, 햅팁 모듈 및 광 출력부 중 적어도 하나를 포함할 수 있다. 디스플레이부는 터치 센서와 상호 레이어 구조를 이 루거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이러한 터치 스크린은, 본 장치와 사용자 사 이의 입력 인터페이스를 제공하는 사용자 입력부로써 기능함과 동시에, 본 장치와 사용자 간에 출력 인터페이스 를 제공할 수 있다. 디스플레이부는 본 장치에서 처리되는 정보를 표시(출력)한다. 예를 들어, 디스플레이부는 본 장치에서 구동되 는 응용 프로그램(일 예로, 어플리케이션)의 실행화면 정보, 또는 이러한 실행화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 상술한 구성요소 외에, 상술한 단말기는 인터페이스부 및 메모리를 더 포함할 수 있다. 인터페이스부는 본 장치에 연결되는 다양한 종류의 외부 기기와의 통로 역할을 수행한다. 이러한 인터페이스부 는 유/무선 헤드셋 포트(port), 외부 충전기 포트(port), 유/무선 데이터 포트(port), 메모리 카드(memory card) 포트, 식별 모듈(SIM)이 구비된 장치를 연결하는 포트(port), 오디오 I/O(Input/Output) 포트(port), 비 디오 I/O(Input/Output) 포트(port), 이어폰 포트(port) 중 적어도 하나를 포함할 수 있다. 본 장치에서는, 상 기 인터페이스부에 연결된 외부 기기와 관련된 적절한 제어를 수행할 수 있다. 메모리는 본 장치의 다양한 기능을 지원하는 데이터와, 프로세서의 동작을 위한 프로그램을 저장할 수 있고, 입 /출력되는 데이터들(예를 들어, 음악 파일, 정지영상, 동영상 등)을 저장할 있고, 본 장치에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 본 장치의 동작을 위한 데이터들, 명령 어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 이러한, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입(Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스 크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 메모리는 본 장치와는 분리되어 있으나, 유선 또는 무선으로 연결된 데이터베이스가 될 수도 있다. 한편, 상술한 단말기는 프로세서를 포함한다. 프로세서는 본 장치 내의 구성요소들의 동작을 제어하기 위 한 알고리즘 또는 알고리즘을 재현한 프로그램에 대한 데이터를 저장하는 메모리, 및 메모리에 저장된 데이터를이용하여 전술한 동작을 수행하는 적어도 하나의 프로세서(미도시)로 구현될 수 있다. 이때, 메모리와 프로세서 는 각각 별개의 칩으로 구현될 수 있다. 또는, 메모리와 프로세서는 단일 칩으로 구현될 수도 있다. 또한, 프로세서는 이하의 도면에서 설명되는 본 개시에 따른 다양한 실시 예들을 본 장치 상에서 구현하기 위하 여, 위에서 살펴본 구성요소들을 중 어느 하나 또는 복수를 조합하여 제어할 수 있다. 한편, 도 1 및 2에 도시된 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있 다. 또한, 구성 요소들의 상호 위치는 장치의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분 야에서 통상의 지식을 가진 자에게 용이하게 이해될 것이다. 이하에서는, 본 발명에서 서술되는 인공지능에 대하여 구체적으로 설명한다. 본 개시에 따른 인공지능과 관련된 기능은 상술한 서버 및 단말기에 탑재된 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래 픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 인공지능을 구현할 수 있다. 인공지능이란 사람의 신경세포 (biological neuron)를 모사하여 기계가 학습하도록 하는 인공신경망(Artificial Neural Network) 기반의 기계 학습법을 의미한다. 인공지능의 방법론에는 학습 방식에 따라 훈련데이터로서 입력데이터와 출력데이터가 같이 제공됨으로써 문제(입력데이터)의 해답(출력데이터)이 정해져 있는 지도학습(supervised learning), 및 출력데 이터 없이 입력데이터만 제공되어 문제(입력데이터)의 해답(출력데이터)이 정해지지 않는 비지도학습 (unsupervised learning), 및 현재의 상태(State)에서 어떤 행동(Action)을 취할 때마다 외부 환경에서 보상 (Reward)이 주어지는데, 이러한 보상을 최대화하는 방향으로 학습을 진행하는 강화학습(reinforcement learning)으로 구분될 수 있다. 또한, 인공지능의 방법론은 학습 모델의 구조인 아키텍처에 따라 구분될 수도 있는데, 널리 이용되는 딥러닝 기술의 아키텍처는, 합성곱신경망(CNN; Convolutional Neural Network), 순환신 경망(RNN; Recurrent Neural Network), 트랜스포머(Transformer), 생성적 대립 신경망(GAN; generative adversarial networks) 등으로 구분될 수 있다. 본 장치와 시스템은 인공지능 모델을 포함할 수 있다. 인공지능 모델은 하나의 인공지능 모델일 수 있고, 복수 의 인공지능 모델로 구현될 수도 있다. 인공지능 모델은 뉴럴 네트워크(또는 인공 신경망)로 구성될 수 있으며, 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘을 포함할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해 결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 예시적으로, 장치는 input layer, hidden layer, output layer를 포함할 수 있다. 장치를 구성하는 뉴 럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력(input)으로부터 예측하고자 하는 결과 (output)를 추론할 수 있다. 프로세서는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train, 또는 학습(learn)하거나, 수신되는 입력 데이터를 기초로 연산을 수행하고, 수행 결과를 기초로 정보 신호(information signal)를 생성하거나, 뉴럴 네 트워크를 재훈련(retrain)할 수 있다. 뉴럴 네트워크의 모델들은 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network 등 다양한 종류의 모델들을 포함할 수 있으나 이에 제한되지는 않는다. 프로세서는 뉴럴 네트워크의 모델들에 따른 연산을 수행하기 위한 하나 이상의 프로세서를 포함할 수 있다. 예를 들어 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론(multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함 할 수 있으나 이에 한정되는 것이 아닌 임의의 뉴럴 네트워크를 포함할 수 있음은 통상의 기술자가 이해할 것이다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network, Generative Modeling, eXplainable AI, Continual AI, Representation Learning, AI for Material Design, 자 연어 처리를 위한 BERT, SP-BERT, MRC/QA, Text Analysis, Dialog System, GPT-3, GPT-4, 비전 처리를 위한 Visual Analytics, Visual Understanding, Video Synthesis, ResNet 데이터 지능을 위한 Anomaly Detection, Prediction, Time-Series Forecasting, Optimization, Recommendation, Data Creation 등 다양한 인공지능 구 조 및 알고리즘을 이용할 수 있으며, 이에 제한되지 않는다. 이하에서는, 상술한 장치를 인공지능 모델 학습 방법에 대해 구체적으로 설명한다. 후술하는 인공지능 모델 학 습 방법은 상술한 서버 및 단말기 중 어느 하나에 의해 독립적으로 구현되거나, 서버 및 단말기 간 데이터 송수 신을 통해 구현될 수 있다. 한편, 도 3과 같이, 서버 및 단말기 중 적어도 하나에 포함된 프로세서는 후술할 인공지능 모델 학습 방법을 구 현하기 위한 복수의 모듈을 포함할 수 있다. 구체적으로, 프로세서는 히트맵 생성 모듈, 히트맵 분리 모듈 및 인공지능 모듈을 포함할 수 있다. 후술하는 인공지능 모델 학습 방법은 상기 모듈들의 동작 에 의해 구현되는 것으로 서술하나, 후술하는 각 단계의 동작의 수행이 반드시 상기 모듈들에 의해 수행될 필요 는 없다. 이하, 첨부된 도면을 참조하여 본 개시의 실시예를 상세하게 설명한다. 도 4는 본 개시에 따른 인공지능 모델 학습 방법의 흐름도이다. 도 4를 참조하면, 영상을 입력 받는 단계가 진행된다(S110). 영상은 복수의 특징점을 포함할 수 있다. 복수의 랜드마크 점 각각은 고유의 좌표를 가진다. 상기 영상은 히트 맵으로 변환되고, 생성된 히트맵은 특징점의 좌표 예측을 위한 인공지능 모델의 학습에 활용된다. 일 실시 예로 상기 영상은 1024×1024 크기의 영상일 수 있으며, 5개의 특징점을 포함할 수 있다. 이하에서는 상술한 영상을 일 실시 예로 설명하나, 본 발명에 따른 인공지능 모델의 학습에 활용되는 영상이 상술한 영상에 한정되는 것은 아니다. 서버 또는 단말기가 상기 영상을 입력 받으면, 상기 영상은 히트맵 생성 모듈로 전달된다. 다음으로, 히트맵 생성 모듈이 영상에 포함된 N개의 특징점들에 대해 N 깊이의 히트맵 생성을 수행하는 단 계가 진행된다(S120). 히트맵 생성 모듈은 입력 영상에 포함된 복수의 특징점 각각을 중심으로 히트맵을 형성한다. 도 5를 참조하면, 히트맵 생성 모듈은 특징점이 가우시안 형태로 팽창되도록 히트맵을 형성한다. 여기서, 가우시안 형태의 히트맵은 특징점의 좌표와 가까울수록 붉은색을 띄고, 특징점의 좌표와 멀어질수록 푸른색을 띈다. 한편, 히트맵의 특정 영역이 특징점의 좌표와 가까울수록 높은 가중치를 가지며, 특징점의 좌표와 멀어질수록 낮은 가중치를 가진다. 이에 따르면, 히트맵의 붉은 영역은 높은 가중치를 나타내며, 푸른 영역은 낮은 가중치 를 나타낸다. 한편, 히트맵 생성 모듈은 영상에 포함된 특징점 각각에 대한 히트맵을 별도로 생성한다. 즉, 히트맵 생성 모듈은 영상에 포함된 특징점의 개수를 고려하여, 생성되는 히트맵의 깊이를 다르게 할 수 있다. 예를 들 어, 입력 영상에 포함된 히트맵의 개수가 5개인 경우, 히트맵 생성 모듈은 5깊이의 히트맵을 생성하여 상 술한 가중치를 포함하는 객체로 생성할 수 있다. 일 실시 예에 있어서, 입력 영상이 1024×1024 크기의 영상이고, 5개의 특징점을 포함하는 경우, 히트맵 생성 모듈은 1024×1024×5크기의 히트맵을 생성할 수 있다. 본 명세서에서는 복수의 특징점 전체에 대해 히트맵 생성 모듈이 생성한 객체를 “N깊이의 히트맵”이라 칭한다. N깊이의 히트맵은 복수의 특징점 각각에 대응되는 히트맵을 포함할 수 있다. 본 명세서에서 특정 특징 점에 대응되는 히트맵이라함은 N깊이의 히트맵에 포함된 히트맵을 의미한다. 히트맵 생성 모듈이 N개의 특징점에 대한 N깊이의 히트맵 생성을 완료하면, 생성된 히트맵을 히트맵 분리 모듈로 전달한다. 이후, 히트맵 분리 모듈이 특징점들간 겹치는 부분을 제거하는 단계가 진행된다(S130). N개의 특징점 중 서로 가깝게 위치한 일부는 특징점 각각에 대응되는 히트맵을 서로 중첩시켰을 때, 겹치는 영 역이 존재할 수 있다. 예를 들어, 도 6의 첫번째 그림을 참조하면, 인접한 특징점은 히트맵을 서로 중첩시켰을 때, 서로 겹치는 영역이 존재하는 것을 확인활 수 있다. 히트맵 분리 모듈은 생성된 N깊이의 히트맵을 하나의 영상으로 중첩시키고, 중첩 영상에서 서로 겹치는 영 역이 있는지 판단한다. 서로 겹치는 영역이 존재하는 경우, 히트맵 분리 모듈은 상기 겹치는 영역을 제거 할 수 있다. 한편, 상기 겹치는 영역에 대한 제거는 각 특징점에 대응되는 히트맵 각각에 대하여 수행될 수 있다. 구체적으 로, 입력 영상에 서로 인접한 제1특징점 및 제2특징점이 존재하고, 상기 두 특징점 각각에 대응되는 히트맵에 서로 겹치는 영역이 존재하는 경우, 히트맵 분리 모듈은 제1특징점에 대응되는 히트맵에서 상기 제2특징점 에 대응되는 히트맵과 겹치는 영역을 제거하고, 제2특징점에 대응되는 히트맵에서 상기 제1특징점에 대응되는 히트맵과 겹치는 영역을 제거할 수 있다. 예를 들어, 도 6의 두 번째 및 세 번째 영역을 참조하면, 오른쪽 특징점에 대응되는 히트맵에서 왼쪽 특징점에 대응되는 히트맵과 겹치는 영역이 제거되었으며, 왼쪽 특징점에 대응되는 히트맵에서 오른쪽 특징점에 대응되는 히트맵과 겹치는 영역이 제거된 것을 확인할 수 있다. 히트맵 분리 모듈은 서로 겹치는 영역이 제거된 히트맵을 인공지능 모듈로 전달한다. 마지막으로, 인공지능 모듈이 겹치는 부분이 제거된 히트맵을 활용하여 인공지능 모델을 학습하는 단계 (S140)가 진행된다. 인공지능 모듈에는 학습하고자 하는 인공지능 모델이 포함될 수 있다. 여기서, 인공지능 모델은 입력 영상 을 통해 히트맵을 예측할 수 있는 합성곱 신경망일 수 있다. 한편, 학습은 지도 학습으로 수행될 수 있다. 즉, 인공지능 모델은 입력 영상을 입력값(문제)으로 하고, 상기 히트맵 분리 모듈로부터 전달받은 서로 겹치는 영역이 제거된 히트맵을 출력(해답)으로 하는 지도 학습을 통해 학습될 수 있다. 구체적으로, 인공지능 모델은 영상을 입력 받은 후, N깊이의 히트맵을 생성하도록 학습될 수 있다. 이때, N깊이 의 히트맵에 포함된, 특징점 각각에 대한 히트맵은 인접한 특징점에 대한 히트맵과 겹치는 부분이 제거된 객체 일 수 있다. 예를 들어, 충분히 학습된 인공지능 모델이 출력하는 입력 영상에 대한 객체는 도 6의 두 번째 및 세 번째 그림 과 같을 것이며, 이러한 출력 객체를 통해 특징점 좌표를 산출할 수 있다. 한편, 인공지능 모델 학습을 위한 손실함수로, L1 손실함수와 Dice coefficient 손실함수가 혼합 사용될 수 있 다. L1 손실함수는 지향하는 객체 그대로를 출력할 수 있도록 학습 가중치를 반영하지만 배경이 많은 객체에 적용할 경우 학습후 테스트시 거짓양성(False Positive)가 많아질 수 있다. 이를 보완하기 위해, 히트맵 생성 모듈 및 히트맵 분리 모듈에 의해 생성된 객체는 가중치가 낮은 영역, 즉 배경부분이 많기 때문에 전경에 대해 상대적으로 높은 학습 가중치를 두었다. 일 실시 예에 있어서, 히트맵 생성 모듈 및 히트맵 분리 모듈에 의해 생성된 객체에서 가중치가 3시 그마 이하인 경우 배경부분으로, 가중치가 3시그마 초과인 경우 전경으로 정의될 수 있다. 또한, 객체 분할에 많이 쓰이는 Dice coefficient 손실함수로 L1 손실함수만을 사용했을때 나타날 수 있는 거짓 양성 취약성을 보완할 수 있다. 상술한 바와 같이 본 발명에 따르면, 영상에 포함된 특징점을 직접적으로 학습하지 않고, 점의 좌표를 중심으로 가우시안 형태의 가중치를 적용하여 학습함으로써 지도학습을 위한 데이터 구축에서 발생되는 휴먼에러를 예방 하고 정답을 찾아가는 학습과정에 안정성을 높여줄 수 있다. 나아가, 본 발명에 따르면, 입력 영상에 대한 히트맵 생성 후 겹치는 영역을 제거함으로써, 다수의 특징점을 포 함하는 영상에 대한 학습 혼란을 최소화할 수 있다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플 래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다."}
{"patent_id": "10-2023-0017148", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2023-0017148", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 인공지능 모델 학습 장치에 포함된 서버의 블록도이다. 도 2는 본 개시의 인공지능 모델 학습 장치에 포함된 단말기의 블록도이다. 도 3은 본 개시의 인공지능 모델 학습 장치에 포함된 프로세서의 블록도이다. 도 4는 본 개시에 따른 인공지능 모델 학습 방법의 흐름도이다. 도 5는 본 개시에 따른 인공지능 모델 학습 장치가 생성한 히트맵을 나타내는 개념도이다. 도 6은 본 개시에 따른 인공지능 모델 학습 장치가 생성한 히트맵에서 서로 겹치는 영역을 제거한 모습을 나타 내는 개념도이다."}
