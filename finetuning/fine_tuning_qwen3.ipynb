{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f9bad5-f58b-4dcf-bcae-e7c8a68180c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U accelerate \n",
    "%pip install -U peft \n",
    "%pip install -U trl \n",
    "%pip install --upgrade bitsandbytes\n",
    "%pip install -U transformers\n",
    "%pip install --upgrade typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe2db1-f238-4f40-8c7f-013c5b836804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "hf_token = \"\"\n",
    "\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de1c28d6-b235-4344-b236-c8dc62cf7e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20395517f0ba46b996cb9acf843fcac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e078cd710145e7921d188127134b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ed617212754dfe92361cf28a8fa7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fb110a11c5428396e908aefdbb2940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef23397f32444458e8897e0a55038a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dab0ad77bdf4e2c91feae52510423eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/32.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469283753c3e4b0fa67e4c4ebb3195cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4277ae30af1e4787bb2ee81a4968c045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98724e3377441c7abe5fb680a38aa32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d52a465f89a4de7847988d56b0f431a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2679feef3274848b48ae6245ab72ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c383403673f413e995890d2908690c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8635de5aa2d8457c8fee2198d3d6c5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0f5a3f8087461d951fe1326e2c9f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import json, random\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model_dir = \"Qwen/Qwen3-8B-Base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    quantization_config=bnb_config,   \n",
    "    device_map=\"auto\",  \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True             \n",
    ")\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a924a4-0a53-42c1-9fd7-815eb36bbb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompt_style = \"\"\"Below is a fixed instruction that guides the assistant to write a Korean patent specification in full compliance with Korean Patent Law. \n",
    "The assistant must use the provided invention details to generate a structured patent section in Korean.\n",
    "Think step-by-step before responding\n",
    "The final response should be written in Korean and follow the 2007 model specification guidelines.\n",
    "**Respond in Korean.**\n",
    "\n",
    "### Task Type: {task_type}\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Output:\n",
    "{output}\"\"\"\n",
    "\n",
    "# 각 태스크별 instruction 정의\n",
    "TASK_INSTRUCTIONS = {\n",
    "    \"PATENT_FORM\": \"\"\"당신은 대한민국 특허법에 따라 명세서를 작성하는 특허 어시스턴트입니다. 아래의 구성요소별로 정확하고 구조화된 문서를 생성해야 합니다. \n",
    "모든 항목은 특허법 제42조 및 시행규칙 제21조, 개정된 모범 명세서 작성법(2007.07.01. 이후 적용)을 철저히 준수해야 합니다.\n",
    "\n",
    "1. [발명의 명칭] - 발명의 내용을 간명하게 표현하는 명칭을 작성합니다. 영문명을 {{}} 안에 함께 기재합니다.\n",
    "2. [기술분야] - 본 발명이 속하는 기술분야를 간결하게 설명합니다.\n",
    "3. [배경기술] - 종래 기술을 서술하고, 가능하면 문헌 인용을 포함합니다.\n",
    "4. [해결하려는 과제] - 기존 기술의 문제점과 해결하고자 하는 과제를 기술합니다.\n",
    "5. [과제의 해결 수단] - 본 발명이 과제를 어떻게 해결하는지를 구체적으로 기술하고, 청구항과 연결합니다.\n",
    "6. [발명의 효과] - 본 발명이 제공하는 구체적이고 비교 가능한 기술적 효과를 기술합니다.\n",
    "7. [발명을 실시하기 위한 구체적인 내용] - 실시예, 수단, 수치 등을 포함하여, 평균 기술자가 재현 가능하도록 작성합니다.\n",
    "8. [도면의 간단한 설명] - 도면이 있을 경우, 각 도면이 무엇을 나타내는지 기술합니다.\n",
    "9. [특허청구범위] - 독립항 및 종속항을 번호와 함께 명확히 구분하여 작성합니다.\"\"\",\n",
    "\n",
    "    \"PATENT_EVALUATION\": \"\"\"제출된 특허 문서 또는 아이디어를 평가하고 개선 방향을 제안하세요. \n",
    "다음 기준에 따라 분석하고 점수와 구체적인 개선사항을 제시하세요:\n",
    "1. [신규성] - 동일한 발명이 이미 국내외에 공개된 경우 특허를 받을 수 없습니다.\n",
    "2. [진보성] - 해당 기술이 통상의 기술자에게 자명한 경우 특허를 받을 수 없습니다.\n",
    "3. [산업적 이용 가능성] - 발명이 산업적으로 활용 가능해야 합니다.\n",
    "4. [기재불비] - 명세서에 발명의 내용을 명확하고 완전하게 기재해야 하며, 통상의 기술자가 이를 재현할 수 있어야 합니다.\n",
    "각 항목별로 점수(1-10점)와 상세한 평가 의견을 제공하세요.\"\"\",\n",
    "\n",
    "#     \"PATENT_RECOMMENDATION\": \"\"\"평가에서 지적된 부분을 반영하여 명세서를 개선하되, 모든 항목(제목 포함)을 생략하지 말고 그대로 유지하세요. \n",
    "# 항목 이름, 순서, 구성은 유지하되, 각 항목의 문장이나 내용을 평가에 따라 보완하거나 개선하세요.\n",
    "# 기존 명세서의 전체 구조를 유지하면서 평가 의견을 반영한 수정된 전체 명세서를 제공하세요.\"\"\",\n",
    "\n",
    "    \"PATENT_MODIFICATION\": \"\"\"당신은 특허 명세서 작성 전문가입니다. \n",
    "사용자의 요청에 따라 특허 명세서를 전문적이고 정확하게 수정하며, 섹션 간의 일관성을 유지합니다.\n",
    "수정 시 특허법 및 관련 규정을 준수하고, 기술적 정확성과 법적 유효성을 확보하세요.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648f94f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading multi-task data...\n",
      "Loading data/patent_data.jsonl for PATENT_FORM...\n",
      "  Loaded 1000 samples for PATENT_FORM\n",
      "Loading data/evaluation_data.jsonl for PATENT_EVALUATION...\n",
      "  Loaded 1997 samples for PATENT_EVALUATION\n",
      "Loading data/ai_revise_data.jsonl for PATENT_MODIFICATION...\n",
      "  Loaded 3022 samples for PATENT_MODIFICATION\n",
      "\n",
      "Total unified data: 6019\n",
      "Task distribution:\n",
      "  PATENT_FORM: 1000\n",
      "  PATENT_EVALUATION: 1997\n",
      "  PATENT_MODIFICATION: 3022\n",
      "\n",
      "🔄 Creating balanced dataset...\n",
      "PATENT_EVALUATION: 2000 samples (original: 1997)\n",
      "PATENT_MODIFICATION: 2000 samples (original: 3022)\n",
      "PATENT_FORM: 2000 samples (original: 1000)\n",
      "\n",
      "✅ Final balanced dataset size: 6000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a23bc18a2704908bceb925f017e6207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset after prompt formatting: 6000\n",
      "\n",
      "📋 Sample data preview:\n",
      "--------------------------------------------------\n",
      "Below is a fixed instruction that guides the assistant to work as a Korean patent AI assistant.\n",
      "The assistant must identify the task type and respond accordingly in Korean.\n",
      "Think step-by-step before responding.\n",
      "The final response should be written in Korean.\n",
      "**Respond in Korean.**\n",
      "\n",
      "### Task Type: PATENT_FORM\n",
      "\n",
      "### Instruction:\n",
      "당신은 대한민국 특허법에 따라 명세서를 작성하는 특허 어시스턴트입니다. 아래의 구성요소별로 정확하고 구조화된 문서를 생성해야 합니다. \n",
      "모든 항목은 특허법 제42조 및 시행규칙 제21조, 개정된 모범 명세서 작성법(2007.07.01. 이후 적용)을 철저히 준수해야 합니다.\n",
      "\n",
      "1. [발명의 명칭] - 발명의 내용을 간명하게 표현하는 명칭을 작성합니다. 영문명을 {{}} 안에 함께 기재합니다.\n",
      "2. [기술분야] - 본 발명이 속하는 기술분야를 간결하게 설명합니다.\n",
      "3. [배경기술] - 종래 기술을 서술하고, 가능하면 문헌 인용을 포함합니다.\n",
      "4. [해결하려는 과제] - 기존 기술의 문제점과 해결하고자 하는 과제를 기술합니다.\n",
      "5. [과제의 해결 수단] - 본 발명이 과제를 어떻게 해결하는지를 구체적으로 기술하고, 청구항과 연결합니다.\n",
      "6. [발명의 효과] - 본 발명이 제공하는 구체적이고 비교 가능한 기술적 효과를 기술합니다.\n",
      "7. [...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "import json\n",
    "import random\n",
    "from datasets import Dataset\n",
    "\n",
    "# 통합 프롬프트 템플릿 (Cell 4에서 복사)\n",
    "unified_prompt_style = \"\"\"Below is a fixed instruction that guides the assistant to work as a Korean patent AI assistant.\n",
    "The assistant must identify the task type and respond accordingly in Korean.\n",
    "Think step-by-step before responding.\n",
    "The final response should be written in Korean.\n",
    "**Respond in Korean.**\n",
    "\n",
    "### Task Type: {task_type}\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Output:\n",
    "{output}\"\"\"\n",
    "\n",
    "def load_jsonl_dataset(path):\n",
    "    \"\"\"JSONL 파일을 로드하여 리스트로 반환\"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    return data\n",
    "\n",
    "def load_and_process_multi_task_data():\n",
    "    \"\"\"3개의 태스크 데이터를 로드하고 통합 (추천 데이터 제외)\"\"\"\n",
    "    \n",
    "    # 파일명과 태스크 타입 매핑 (추천 데이터 주석처리)\n",
    "    file_task_mapping = {\n",
    "        \"data/patent_data.jsonl\": \"PATENT_FORM\",\n",
    "        \"data/evaluation_data.jsonl\": \"PATENT_EVALUATION\", \n",
    "        # \"recomend_data.jsonl\": \"PATENT_RECOMMENDATION\",  # TODO: 추천 데이터 준비되면 주석 해제\n",
    "        \"data/ai_revise_data.jsonl\": \"PATENT_MODIFICATION\"\n",
    "    }\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for filename, task_type in file_task_mapping.items():\n",
    "        print(f\"Loading {filename} for {task_type}...\")\n",
    "        \n",
    "        try:\n",
    "            # JSONL 파일 로드\n",
    "            task_data = load_jsonl_dataset(filename)\n",
    "            \n",
    "            # 통합 형태로 변환 (모든 값을 문자열로 강제 변환)\n",
    "            for item in task_data:\n",
    "                unified_item = {\n",
    "                    \"task_type\": task_type,\n",
    "                    \"instruction\": TASK_INSTRUCTIONS[task_type],\n",
    "                    \"context\": str(item.get(\"context\", \"없음\")),  # str() 추가\n",
    "                    \"input\": str(item[\"input\"]),                  # str() 추가\n",
    "                    \"output\": str(item[\"output\"])                 # str() 추가\n",
    "                }\n",
    "                all_data.append(unified_item)\n",
    "            \n",
    "            print(f\"  Loaded {len(task_data)} samples for {task_type}\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"  Warning: {filename} not found, skipping...\")\n",
    "            continue\n",
    "    \n",
    "    # 데이터 셔플\n",
    "    random.shuffle(all_data)\n",
    "    \n",
    "    print(f\"\\nTotal unified data: {len(all_data)}\")\n",
    "    print(\"Task distribution:\")\n",
    "    for task_type in set(item[\"task_type\"] for item in all_data):\n",
    "        count = sum(1 for item in all_data if item[\"task_type\"] == task_type)\n",
    "        print(f\"  {task_type}: {count}\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def create_balanced_dataset(all_data, min_samples_per_task=2000):\n",
    "    \"\"\"각 태스크별로 균형잡힌 데이터셋 생성\"\"\"\n",
    "    task_data = {}\n",
    "    \n",
    "    # 태스크별로 데이터 분리\n",
    "    for item in all_data:\n",
    "        task_type = item[\"task_type\"]\n",
    "        if task_type not in task_data:\n",
    "            task_data[task_type] = []\n",
    "        task_data[task_type].append(item)\n",
    "    \n",
    "    # 각 태스크별로 샘플링\n",
    "    balanced_data = []\n",
    "    for task_type, data in task_data.items():\n",
    "        if len(data) >= min_samples_per_task:\n",
    "            # 충분한 데이터가 있으면 랜덤 샘플링\n",
    "            sampled = random.sample(data, min_samples_per_task)\n",
    "        else:\n",
    "            # 부족하면 오버샘플링 (중복 허용)\n",
    "            sampled = data * (min_samples_per_task // len(data) + 1)\n",
    "            sampled = sampled[:min_samples_per_task]\n",
    "        \n",
    "        balanced_data.extend(sampled)\n",
    "        print(f\"{task_type}: {len(sampled)} samples (original: {len(data)})\")\n",
    "    \n",
    "    random.shuffle(balanced_data)\n",
    "    return balanced_data\n",
    "\n",
    "def formatting_unified_prompts_func(examples):\n",
    "    \"\"\"통합 데이터를 프롬프트 형태로 변환\"\"\"\n",
    "    task_types = examples[\"task_type\"]\n",
    "    instructions = examples[\"instruction\"] \n",
    "    contexts = examples[\"context\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    for task_type, instruction, context, inp, out in zip(\n",
    "        task_types, instructions, contexts, inputs, outputs\n",
    "    ):\n",
    "        if not out.endswith(EOS_TOKEN):\n",
    "            out += EOS_TOKEN\n",
    "            \n",
    "        text = unified_prompt_style.format(\n",
    "            task_type=task_type,\n",
    "            instruction=instruction,\n",
    "            context=context,\n",
    "            input=inp,\n",
    "            output=out\n",
    "        )\n",
    "        texts.append(text)\n",
    "    \n",
    "    return {\"text\": texts}\n",
    "\n",
    "# 데이터 로드 및 처리\n",
    "print(\"🔄 Loading multi-task data...\")\n",
    "all_data = load_and_process_multi_task_data()\n",
    "\n",
    "print(\"\\n🔄 Creating balanced dataset...\")\n",
    "balanced_data = create_balanced_dataset(all_data, min_samples_per_task=2000)\n",
    "\n",
    "print(f\"\\n✅ Final balanced dataset size: {len(balanced_data)}\")\n",
    "\n",
    "# Dataset 객체 생성\n",
    "dataset = Dataset.from_list(balanced_data)\n",
    "\n",
    "# 프롬프트 형태로 변환\n",
    "dataset = dataset.map(\n",
    "    formatting_unified_prompts_func,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "print(f\"✅ Dataset after prompt formatting: {len(dataset)}\")\n",
    "print(\"\\n📋 Sample data preview:\")\n",
    "print(\"-\" * 50)\n",
    "print(dataset[\"text\"][0][:800] + \"...\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07427da0-5f73-4010-88e6-477d02704dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e6602-c71a-423c-9ccd-9c278d52f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,                           # Scaling factor for LoRA\n",
    "    lora_dropout=0.05,                       # Add slight dropout for regularization\n",
    "    r=64,                                    # Rank of the LoRA update matrices\n",
    "    bias=\"none\",                             # No bias reparameterization\n",
    "    task_type=\"CAUSAL_LM\",                   # Task type: Causal Language Modeling\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # Target modules for LoRA\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15453947-e297-4321-af2b-57f1c5943b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0a9024119b494590921e3ea8e2de60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (146822 > 131072). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "def filter_too_long(example):\n",
    "    tokenized = tokenizer(example[\"text\"], truncation=False, return_tensors=\"pt\")\n",
    "    return tokenized[\"input_ids\"].shape[1] <= 131072\n",
    "\n",
    "dataset = dataset.filter(filter_too_long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc151d-5b97-480e-9f4c-9ee8f9b9bee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train dataset: 5398\n",
      "✅ Eval dataset: 600\n",
      "\n",
      "📊 Train Task Distribution:\n",
      "  PATENT_EVALUATION: 1789 (33.1%)\n",
      "  PATENT_FORM: 1803 (33.4%)\n",
      "  PATENT_MODIFICATION: 1806 (33.5%)\n",
      "\n",
      "📊 Eval Task Distribution:\n",
      "  PATENT_FORM: 197 (32.8%)\n",
      "  PATENT_MODIFICATION: 193 (32.2%)\n",
      "  PATENT_EVALUATION: 210 (35.0%)\n"
     ]
    }
   ],
   "source": [
    "# 1. Dataset 분할\n",
    "split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(f\"✅ Train dataset: {len(train_dataset)}\")\n",
    "print(f\"✅ Eval dataset: {len(eval_dataset)}\")\n",
    "\n",
    "# 2. Metrics 함수 (optional)\n",
    "import math\n",
    "def compute_metrics(eval_preds):\n",
    "    loss = eval_preds.loss\n",
    "    return {\n",
    "        \"eval_loss\": loss,\n",
    "        \"perplexity\": math.exp(loss) if loss < 100 else float(\"inf\")\n",
    "    }\n",
    "\n",
    "# 3. 각 데이터셋에서 태스크 분포 확인\n",
    "def check_task_distribution(dataset_split, split_name):\n",
    "    print(f\"\\n📊 {split_name} Task Distribution:\")\n",
    "    task_counts = {}\n",
    "    for example in dataset_split:\n",
    "        # 프롬프트에서 태스크 타입 추출\n",
    "        text = example[\"text\"]\n",
    "        # 추천 제외\n",
    "        for task_type in [\"PATENT_FORM\", \"PATENT_EVALUATION\", \"PATENT_MODIFICATION\"]:\n",
    "            if f\"Task Type: {task_type}\" in text:\n",
    "                task_counts[task_type] = task_counts.get(task_type, 0) + 1\n",
    "                break\n",
    "    \n",
    "    for task, count in task_counts.items():\n",
    "        percentage = (count / len(dataset_split)) * 100\n",
    "        print(f\"  {task}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "check_task_distribution(train_dataset, \"Train\")\n",
    "check_task_distribution(eval_dataset, \"Eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d83f1cc-7c6a-4532-9fab-20d45323937f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcf3d86d49944a2b0820121c16c2797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/5398 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5af2d1ad424826945eed2e907c91ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/5398 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c541331b0e924465af7e5b954285d715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/5398 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231592734c544a58b24600420ba9eaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/5398 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c595065900f44b3a4066602a29d2134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb023a9f68840f1bfbacf389acd2424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb75b80a33e4e87805e84c9076e1611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2082faf1f84349ba928455f5e1eb6941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "\n",
    "# Training Arguments\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    eval_strategy=\"steps\",   # ✅ 평가 실행 조건\n",
    "    eval_steps=100,                 # ✅ 50 스텝마다 평가\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=50,\n",
    "    warmup_steps=20,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=1e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=3,      # 최대 3개 체크포인트 유지\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=peft_config,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef451e13-300e-48ea-adf9-f514fe1bff7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5900' max='8097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5900/8097 2:11:56 < 49:08, 0.75 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.602700</td>\n",
       "      <td>0.590532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.587200</td>\n",
       "      <td>0.573379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.538700</td>\n",
       "      <td>0.566305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.606900</td>\n",
       "      <td>0.560636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.574800</td>\n",
       "      <td>0.556949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.560400</td>\n",
       "      <td>0.551803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.549200</td>\n",
       "      <td>0.550315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.532600</td>\n",
       "      <td>0.546494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.545700</td>\n",
       "      <td>0.544862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.541330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>0.540293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.517300</td>\n",
       "      <td>0.538450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.542900</td>\n",
       "      <td>0.536074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.543900</td>\n",
       "      <td>0.535226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>0.533162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.542800</td>\n",
       "      <td>0.530900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.567100</td>\n",
       "      <td>0.528768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.533600</td>\n",
       "      <td>0.526952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.504700</td>\n",
       "      <td>0.525673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.529600</td>\n",
       "      <td>0.523783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.555400</td>\n",
       "      <td>0.522282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.521176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>0.520605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.536400</td>\n",
       "      <td>0.520167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.514400</td>\n",
       "      <td>0.518718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.516231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.508600</td>\n",
       "      <td>0.515392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>0.515475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.495500</td>\n",
       "      <td>0.515264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.492500</td>\n",
       "      <td>0.514344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.496600</td>\n",
       "      <td>0.513500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>0.513551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.491600</td>\n",
       "      <td>0.513138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>0.512160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.510490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.487900</td>\n",
       "      <td>0.511233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.509079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.473400</td>\n",
       "      <td>0.507678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>0.506498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.466100</td>\n",
       "      <td>0.505721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.504017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.496900</td>\n",
       "      <td>0.503490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.502380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.507400</td>\n",
       "      <td>0.502677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.501538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.479800</td>\n",
       "      <td>0.500083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.486100</td>\n",
       "      <td>0.500048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.450200</td>\n",
       "      <td>0.498686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.485900</td>\n",
       "      <td>0.497155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.498200</td>\n",
       "      <td>0.495605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.494835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0.494499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.437700</td>\n",
       "      <td>0.493792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.458200</td>\n",
       "      <td>0.493300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.423500</td>\n",
       "      <td>0.496333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.419500</td>\n",
       "      <td>0.494921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.494803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.495708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.424900</td>\n",
       "      <td>0.495238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5900, training_loss=0.5070423585277493, metrics={'train_runtime': 7918.2825, 'train_samples_per_second': 2.045, 'train_steps_per_second': 1.023, 'total_flos': 5.613608276852736e+17, 'train_loss': 0.5070423585277493})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53cea42-4dae-4dc3-b6ae-b9a4bd2551ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('best_model/tokenizer_config.json',\n",
       " 'best_model/special_tokens_map.json',\n",
       " 'best_model/chat_template.jinja',\n",
       " 'best_model/vocab.json',\n",
       " 'best_model/merges.txt',\n",
       " 'best_model/added_tokens.json',\n",
       " 'best_model/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 부분 이상함\n",
    "# 학습 완료 후 가장 좋은 모델 저장\n",
    "trainer.save_model(\"best_model\")  # 디렉토리 이름은 원하는 대로\n",
    "\n",
    "# tokenizer도 함께 저장 (권장)\n",
    "tokenizer.save_pretrained(\"best_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
